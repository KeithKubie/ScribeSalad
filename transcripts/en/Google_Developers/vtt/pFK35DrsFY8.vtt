WEBVTT
Kind: captions
Language: en

00:00:01.690 --> 00:00:03.730
JOHN LUTHER: Good morning.

00:00:03.730 --> 00:00:06.050
How's everybody?

00:00:06.050 --> 00:00:07.980
OK, Glass present slide.

00:00:07.980 --> 00:00:09.230
Now wait a minute.

00:00:11.810 --> 00:00:13.010
It's fun to pretend, right?

00:00:13.010 --> 00:00:14.920
FRANK GALLIGAN: We're not cool
enough to have Glass.

00:00:14.920 --> 00:00:17.080
JOHN LUTHER: You'd think
we would be.

00:00:17.080 --> 00:00:17.850
Good morning.

00:00:17.850 --> 00:00:20.350
Welcome to our session on WebM,

00:00:20.350 --> 00:00:22.670
demystifying video coding.

00:00:22.670 --> 00:00:23.445
My name's John Luther.

00:00:23.445 --> 00:00:26.500
I'm the Product Manager at
Google for WebM and for video

00:00:26.500 --> 00:00:28.640
technology in the
Chrome browser.

00:00:28.640 --> 00:00:32.090
And this is my colleague and
co-presenter Frank Galligan,

00:00:32.090 --> 00:00:36.130
Staff Software Engineer at
Google also working on WebM

00:00:36.130 --> 00:00:37.860
and Chrome.

00:00:37.860 --> 00:00:39.720
And they tell you to
open with a joke.

00:00:39.720 --> 00:00:41.210
And my joke is my picture.

00:00:44.830 --> 00:00:46.865
This looks so sad
about something.

00:00:46.865 --> 00:00:47.910
FRANK GALLIGAN: You
look orange.

00:00:47.910 --> 00:00:48.480
JOHN LUTHER: I know.

00:00:48.480 --> 00:00:48.920
All right.

00:00:48.920 --> 00:00:50.780
So what's to demystify?

00:00:50.780 --> 00:00:52.850
First, I'm going to just give
sort of an overview of what

00:00:52.850 --> 00:00:57.230
WebM is and VP8, but mostly
going to focus on the video

00:00:57.230 --> 00:01:04.050
side with WebM today, and then
the reasons why WebM is a

00:01:04.050 --> 00:01:07.650
great choice for developers
to do video in their apps.

00:01:07.650 --> 00:01:10.890
I'm going to give some examples
of how to encode WebM

00:01:10.890 --> 00:01:16.200
video using ffmpeg, which is a
very popular command line and

00:01:16.200 --> 00:01:20.140
coding tool used by pretty much
every video service on

00:01:20.140 --> 00:01:23.280
earth these days, including
YouTube.

00:01:23.280 --> 00:01:28.790
So Frank will then do his part
of the presentation on how to

00:01:28.790 --> 00:01:31.920
actually build WebM into apps
using our open source

00:01:31.920 --> 00:01:35.880
libraries, libvpx, the WebM
container library which is our

00:01:35.880 --> 00:01:40.940
wrapper format and libvorbis,
which is our audio encoder.

00:01:40.940 --> 00:01:41.840
He'll then--

00:01:41.840 --> 00:01:44.680
if everything goes according
to plan--

00:01:44.680 --> 00:01:48.370
encode a video on an Android
device, upload it to YouTube

00:01:48.370 --> 00:01:52.110
where it will instantaneously
appear to the world.

00:01:52.110 --> 00:01:54.110
And then I'll just touch briefly
on what we're up to

00:01:54.110 --> 00:01:57.300
next, which is our VP9,
which is our next

00:01:57.300 --> 00:01:59.320
generation video codec.

00:01:59.320 --> 00:02:01.650
And we'll have a quick
Q&amp;A. And then we'll

00:02:01.650 --> 00:02:02.910
let you go to lunch.

00:02:02.910 --> 00:02:06.670
So how many people know
what WebM is?

00:02:06.670 --> 00:02:07.170
That's OK.

00:02:07.170 --> 00:02:08.070
That's good.

00:02:08.070 --> 00:02:11.490
For those of you who don't, WebM
is a high-quality, open,

00:02:11.490 --> 00:02:13.930
royalty-free alternative
for web video.

00:02:13.930 --> 00:02:14.710
What does that mean?

00:02:14.710 --> 00:02:17.030
That means that it's
three things.

00:02:17.030 --> 00:02:19.840
That's this is how we define
WebM for consistency's sake.

00:02:19.840 --> 00:02:22.610
It's the VP8 video codec.

00:02:22.610 --> 00:02:25.420
Soon we're going to add VP9.

00:02:25.420 --> 00:02:29.430
Vorbis audio, which is a
royalty-free, very good audio

00:02:29.430 --> 00:02:32.500
codec that's developed by
the Xiph foundation.

00:02:32.500 --> 00:02:34.580
And it's a Matroska-based
file container.

00:02:34.580 --> 00:02:37.620
What that means is the audio
and video streams are

00:02:37.620 --> 00:02:41.420
contained in a Matroska file
container, but we use a file

00:02:41.420 --> 00:02:44.720
extension WebM to differentiate
it from other

00:02:44.720 --> 00:02:49.190
files, because any user agent
or client, we want to make

00:02:49.190 --> 00:02:53.460
sure that when they receive
a file of .webm type or

00:02:53.460 --> 00:02:56.830
MIME-type WebM that they can
always know that it's going to

00:02:56.830 --> 00:03:02.300
be these three things, and
later VP9 and opus.

00:03:02.300 --> 00:03:04.050
So benefits for developers.

00:03:04.050 --> 00:03:06.310
Why would a developer
want to use WebM?

00:03:06.310 --> 00:03:09.420
Well, more than anything, of
course, is the video quality.

00:03:09.420 --> 00:03:12.260
The VP8 Kodak was developed by a
small company called on OnTo

00:03:12.260 --> 00:03:14.910
Technologies, where Frank
and I came from.

00:03:14.910 --> 00:03:17.520
Google acquired OnTo
in 2010 and open

00:03:17.520 --> 00:03:21.050
sourced VP8 for the world.

00:03:21.050 --> 00:03:24.730
So if you look at the quality
that VP8 can achieve just sort

00:03:24.730 --> 00:03:28.200
of as a base to judge
these things--

00:03:28.200 --> 00:03:32.870
1080p HD video is obviously
very difficult to transmit

00:03:32.870 --> 00:03:34.840
over networks, because
it's so many

00:03:34.840 --> 00:03:36.610
gigantic frames of pixels.

00:03:36.610 --> 00:03:42.730
But with VP8, we can achieve
very good-looking, high PSNR,

00:03:42.730 --> 00:03:46.090
which is how these things
are usually measured.

00:03:46.090 --> 00:03:48.990
1080p at about three megabits.

00:03:48.990 --> 00:03:55.300
So most residential, consumer,
internet connections nowadays,

00:03:55.300 --> 00:03:57.690
they're getting there, to the
point where people have a sort

00:03:57.690 --> 00:03:59.460
of predictable--

00:03:59.460 --> 00:04:02.340
at least, we would hope-- three
megabits connection.

00:04:02.340 --> 00:04:04.630
But you could even do 720
at lower than this.

00:04:04.630 --> 00:04:07.890
So that's one gauge of
how you can judge it.

00:04:07.890 --> 00:04:09.100
Simplicity of design.

00:04:09.100 --> 00:04:14.420
So VP8 is unlike other codecs
that you might know of in that

00:04:14.420 --> 00:04:18.790
we design it to be completely
compliant across any decoder.

00:04:18.790 --> 00:04:24.470
So if any valid VP8 stream that
you create will decode

00:04:24.470 --> 00:04:29.630
and playback in any compliant
VP8 decoder--

00:04:29.630 --> 00:04:31.100
Why is that different
than other codecs.

00:04:31.100 --> 00:04:34.780
Well, other codecs, let's say,
for example, H.264--

00:04:34.780 --> 00:04:37.700
they have different profiles
that are defined.

00:04:37.700 --> 00:04:40.990
So H.264 baseline, H.264 main.

00:04:40.990 --> 00:04:44.480
This leads one to believe that
those are inter-compatible but

00:04:44.480 --> 00:04:45.390
they're not.

00:04:45.390 --> 00:04:47.190
The main profile decoder cannot

00:04:47.190 --> 00:04:49.860
decode a baseline bitstream.

00:04:49.860 --> 00:04:52.120
They're essentially three
different codecs or more.

00:04:52.120 --> 00:04:54.750
There's baseline,
main and high.

00:04:54.750 --> 00:04:57.470
So with VP8, you never have
to worry about that.

00:04:57.470 --> 00:05:01.480
So if you have, for example, if
you want to serve video to

00:05:01.480 --> 00:05:06.110
Glass users as well as users on
MacBooks, the Glass users,

00:05:06.110 --> 00:05:08.340
Glass only supports baseline.

00:05:08.340 --> 00:05:09.650
These support high profile.

00:05:09.650 --> 00:05:11.940
So you'd have to have different
bitstreams for

00:05:11.940 --> 00:05:12.670
different clients.

00:05:12.670 --> 00:05:15.910
And you'd always have to be
doing user agent checking.

00:05:15.910 --> 00:05:17.400
What does this one support,
and so on.

00:05:17.400 --> 00:05:20.110
With VP8, you don't have to
worry about that, because

00:05:20.110 --> 00:05:21.350
there are no profiles.

00:05:21.350 --> 00:05:25.770
There are no levels, which is
another way that codecs were

00:05:25.770 --> 00:05:30.520
defined by what's the maximum
frame size of this video, bit

00:05:30.520 --> 00:05:31.980
rate, so forth.

00:05:31.980 --> 00:05:36.030
We don't do B-frames, which are
kind of a way to predict

00:05:36.030 --> 00:05:38.190
forward or backward
in the video.

00:05:38.190 --> 00:05:39.280
No IDR frames.

00:05:39.280 --> 00:05:42.460
We try to keep it as simple as
possible, yet we do achieve

00:05:42.460 --> 00:05:48.930
the same quality as something
like H.264 High Profile.

00:05:48.930 --> 00:05:52.370
On the other side of the
equation, the decoding, we try

00:05:52.370 --> 00:05:57.810
to keep it very low complexity,
meaning that it's

00:05:57.810 --> 00:06:01.510
very important for us that VVP8
run fast in software,

00:06:01.510 --> 00:06:03.360
even on lower power devices.

00:06:03.360 --> 00:06:06.810
I think a lot of times we in the
Western world forget that

00:06:06.810 --> 00:06:08.990
not everybody buys a new
computer every year

00:06:08.990 --> 00:06:11.660
or every two years.

00:06:11.660 --> 00:06:14.390
There's still a lot of devices
in the world that have a very

00:06:14.390 --> 00:06:16.620
hard time decoding other
codecs and software.

00:06:16.620 --> 00:06:22.030
VP8 opens that world up to more
users, because it can

00:06:22.030 --> 00:06:26.850
decode on an even lower power,
older generation ARM

00:06:26.850 --> 00:06:29.450
processors, which-- there are
still many, many of those in

00:06:29.450 --> 00:06:30.700
the world today.

00:06:32.730 --> 00:06:34.290
It's also very widely
supported.

00:06:34.290 --> 00:06:37.270
So WebM, as a format, in the
video tag in desktop web

00:06:37.270 --> 00:06:40.120
browsers, this is just some
data I pulled from

00:06:40.120 --> 00:06:41.360
StatCounter.

00:06:41.360 --> 00:06:45.090
So native WebM meaning you
install the browser.

00:06:45.090 --> 00:06:46.750
It's WebM capable
out of the box.

00:06:46.750 --> 00:06:50.700
Has about 60% of browsers in
use in the world today.

00:06:50.700 --> 00:06:57.030
So that means Chrome, Firefox,
Opera a browser that's built

00:06:57.030 --> 00:07:00.860
on top of chromium.

00:07:00.860 --> 00:07:02.805
It's in the chromium source.

00:07:02.805 --> 00:07:06.570
It's in Firefox-- you know
the gecko stuff?

00:07:06.570 --> 00:07:09.880
Anyway the light green segment
is browsers that we can

00:07:09.880 --> 00:07:13.280
address with plug-ins, which
are freely available and

00:07:13.280 --> 00:07:15.330
downloadable from our website.

00:07:15.330 --> 00:07:22.430
This is primarily IE9 and 10
and Safari 5 and later.

00:07:22.430 --> 00:07:27.050
The gray slice is browsers that
not necessarily don't

00:07:27.050 --> 00:07:30.380
support WebM, but just simply
don't support HTML5 video

00:07:30.380 --> 00:07:34.470
which is IE8, IE7, a lot of the
older browsers that are

00:07:34.470 --> 00:07:36.770
still out there in use today,
but don't have the

00:07:36.770 --> 00:07:38.080
capabilities.

00:07:38.080 --> 00:07:43.480
So adding it all up, the dark
green wedge is actually

00:07:43.480 --> 00:07:45.570
growing pretty fast over time.

00:07:45.570 --> 00:07:50.840
So you can be pretty confident
that in some way your users

00:07:50.840 --> 00:07:53.080
will be able to play WebM.

00:07:53.080 --> 00:07:54.360
So also as an--

00:07:54.360 --> 00:07:57.840
I was curious about mobile.

00:07:57.840 --> 00:08:00.240
Tablets are obviously very
becoming very important

00:08:00.240 --> 00:08:02.690
platforms for media consumption,
playing videos,

00:08:02.690 --> 00:08:07.280
so I wondered OK, well, in the
aggregate worldwide, what

00:08:07.280 --> 00:08:10.470
percentage of tablets support
WebM natively.

00:08:10.470 --> 00:08:14.160
And it turns out it's
about 43.4%.

00:08:14.160 --> 00:08:17.480
So this is obviously--

00:08:17.480 --> 00:08:19.530
a lot of this is Android.

00:08:19.530 --> 00:08:23.370
And as you heard yesterday in
the keynote, Android is

00:08:23.370 --> 00:08:26.390
growing at a kind of
a moderate rate, I

00:08:26.390 --> 00:08:27.780
guess you might say.

00:08:27.780 --> 00:08:30.420
So anywhere where Android grows,
WebM grows, because

00:08:30.420 --> 00:08:33.690
it's supported in the
Android source

00:08:33.690 --> 00:08:35.659
repository out of the box.

00:08:35.659 --> 00:08:38.320
There's also more hardware
coming online for VP8.

00:08:38.320 --> 00:08:42.159
This is a topic that everybody
likes to discuss.

00:08:42.159 --> 00:08:43.419
VP8--

00:08:43.419 --> 00:08:47.800
hardware support is important to
devices, low power devices

00:08:47.800 --> 00:08:50.320
especially, something that's
not plugged into a wall.

00:08:50.320 --> 00:08:52.380
So if it has a battery, you want
to conserve as much of

00:08:52.380 --> 00:08:53.980
that battery as possible.

00:08:53.980 --> 00:08:56.770
Doing video, encoding and
decoding operations and

00:08:56.770 --> 00:09:00.000
hardware is much, much
less power intense

00:09:00.000 --> 00:09:01.200
than doing it in software.

00:09:01.200 --> 00:09:02.700
So anyway, a lot of that's
started to come

00:09:02.700 --> 00:09:03.340
in the market now.

00:09:03.340 --> 00:09:08.100
Their VP8 decoder's coming to
market pretty much every major

00:09:08.100 --> 00:09:13.536
SOC vendor, which is SOC-- the
ARM chip vendors, who have--

00:09:13.536 --> 00:09:15.015
there's an arm corps
of the sock.

00:09:15.015 --> 00:09:16.840
But then it has blocks for
hardware operations

00:09:16.840 --> 00:09:18.370
like video and audio.

00:09:18.370 --> 00:09:21.340
Pretty much every major
arm-based sock vendor is now

00:09:21.340 --> 00:09:24.280
much shipping chips
with VP8 decoding.

00:09:24.280 --> 00:09:26.960
And they're starting to come in
the market and things like

00:09:26.960 --> 00:09:31.360
the Samsung Chromebooks, Nexus
10, Samsung Galaxy S4, those

00:09:31.360 --> 00:09:34.150
types of devices.

00:09:34.150 --> 00:09:35.730
So as an example of what
I mentioned about the

00:09:35.730 --> 00:09:40.510
complexity, YouTube obviously
wanted to support the Wii.

00:09:40.510 --> 00:09:42.490
There's many of those devices
in the world.

00:09:42.490 --> 00:09:43.530
And a lot of users love them.

00:09:43.530 --> 00:09:45.070
They want to play YouTube
video on them.

00:09:45.070 --> 00:09:48.070
But the problem they kept
running into is due to some

00:09:48.070 --> 00:09:50.830
platform limitations that
Nintendo puts in place, they

00:09:50.830 --> 00:09:55.980
couldn't access the hardware to
do the video in hardware.

00:09:55.980 --> 00:09:58.430
And they're doing it in
software, they had other

00:09:58.430 --> 00:10:02.650
limitations where the .264
streams didn't have the

00:10:02.650 --> 00:10:04.310
horsepower to play them back.

00:10:04.310 --> 00:10:06.340
And then the .263 streams, they
just weren't getting the

00:10:06.340 --> 00:10:08.485
quality that they thought
the users deserved.

00:10:08.485 --> 00:10:12.160
So they said what about VP8?

00:10:12.160 --> 00:10:16.220
We ported and optimized VP8 for
that platform, and now Wii

00:10:16.220 --> 00:10:18.100
client in the world
gets WebM video.

00:10:18.100 --> 00:10:20.850
And that market is now open
to all those users.

00:10:20.850 --> 00:10:24.940
So that's an example where the
simplicity of the designs that

00:10:24.940 --> 00:10:30.790
we always strive for end up
paying off in the end.

00:10:30.790 --> 00:10:36.200
So perhaps most importantly,
WebM is free.

00:10:36.200 --> 00:10:39.020
That means both senses of the
word as people know it--

00:10:39.020 --> 00:10:42.210
beer and speech.

00:10:42.210 --> 00:10:44.650
We don't charge any
money for WebM.

00:10:44.650 --> 00:10:50.000
VP8, Matroska, Vorbis are all
royalty-free technologies.

00:10:50.000 --> 00:10:52.490
And it's all open source.

00:10:52.490 --> 00:10:55.300
The VP8 codec is in a
repository in the

00:10:55.300 --> 00:10:56.820
WebMproject.org website.

00:10:56.820 --> 00:10:59.215
Anybody's free to use it.

00:10:59.215 --> 00:11:01.690
It's under a BSD license,
which is one of the more

00:11:01.690 --> 00:11:02.940
liberal open source licenses.

00:11:02.940 --> 00:11:05.420
It means anybody can fork it.

00:11:05.420 --> 00:11:12.160
I've even had customers ask me
if I use it, do I have to

00:11:12.160 --> 00:11:13.110
still call VP8.

00:11:13.110 --> 00:11:13.840
And you don't.

00:11:13.840 --> 00:11:15.370
You can call it whatever
you want.

00:11:15.370 --> 00:11:18.220
That's the beauty of
the BSD license.

00:11:18.220 --> 00:11:20.720
So why is this important
to developers.

00:11:20.720 --> 00:11:23.240
It's important because other
codecs can cost you millions

00:11:23.240 --> 00:11:24.490
of dollars a year.

00:11:24.490 --> 00:11:26.980
And that's not an
exaggeration.

00:11:26.980 --> 00:11:30.730
A lot of standards-based
codecs have royalties

00:11:30.730 --> 00:11:31.760
associated with them.

00:11:31.760 --> 00:11:34.590
It has nothing to do with
the standards groups.

00:11:34.590 --> 00:11:36.130
They just assemble
the technologies

00:11:36.130 --> 00:11:37.030
and write the specs.

00:11:37.030 --> 00:11:39.290
It's the people on patents that
are relevant to those

00:11:39.290 --> 00:11:43.390
standards that then form pools
to charge royalties for them.

00:11:43.390 --> 00:11:49.100
The H.264 and VC-1 royalty
pools today have maximum

00:11:49.100 --> 00:11:53.340
annual royalties of $6.5
million a year.

00:11:53.340 --> 00:11:59.150
For apps, it's sort of a scaling
sliding scale, but

00:11:59.150 --> 00:12:02.590
it's basically $0.20 a unit of
every app that you sell.

00:12:02.590 --> 00:12:03.690
So what does that mean to you?

00:12:03.690 --> 00:12:06.640
Let's say you're an Android
developer, and you have an app

00:12:06.640 --> 00:12:08.590
that you want to do video coding
like Frank's going to

00:12:08.590 --> 00:12:11.140
demonstrate.

00:12:11.140 --> 00:12:13.380
Let's say you put it in the
Play Store, and you charge

00:12:13.380 --> 00:12:14.886
$0.99 for it.

00:12:14.886 --> 00:12:18.830
$0.20 of every sale you make
goes to a pooling organization

00:12:18.830 --> 00:12:22.156
called [INAUDIBLE], up
to the cap of $6 and

00:12:22.156 --> 00:12:24.730
1/2 million a year.

00:12:24.730 --> 00:12:29.490
This is even applicable if your
app is free, because the

00:12:29.490 --> 00:12:30.960
royalty is to use
the technology.

00:12:30.960 --> 00:12:33.960
It's not a share of the money
you make or anything else.

00:12:33.960 --> 00:12:38.390
If your app has just does
content in those formats--

00:12:38.390 --> 00:12:41.540
let's say, you are able to sort
of take advantage of the

00:12:41.540 --> 00:12:45.770
codec that's in the Android
platform SDK or hardware, if

00:12:45.770 --> 00:12:48.870
you're charging users any amount
of money to consume

00:12:48.870 --> 00:12:51.490
that content, you're going
to owe royalties as well.

00:12:51.490 --> 00:12:54.420
So none of this, thankfully,
applies to WebM.

00:12:54.420 --> 00:12:55.140
It's all free.

00:12:55.140 --> 00:12:55.770
It's all open.

00:12:55.770 --> 00:13:00.600
Anybody can use it, and now
owe anybody any money.

00:13:00.600 --> 00:13:03.800
So that's all the great
properties of it.

00:13:03.800 --> 00:13:06.690
I'm just going to show you
how to actually make

00:13:06.690 --> 00:13:07.940
one of these files.

00:13:10.430 --> 00:13:13.490
Who understands how video
compression works?

00:13:13.490 --> 00:13:15.890
Probably most of you, right?

00:13:15.890 --> 00:13:17.810
OK.

00:13:17.810 --> 00:13:21.020
The primary aim of any kind of
compression but particularly

00:13:21.020 --> 00:13:24.190
video is to remove redundancies
of data.

00:13:24.190 --> 00:13:27.670
With video, you have
redundancies within frames of

00:13:27.670 --> 00:13:30.010
video that's called spatial
redundancy.

00:13:30.010 --> 00:13:32.750
Temporal redundancy is things
that are similar in

00:13:32.750 --> 00:13:34.560
a sequence of frames.

00:13:34.560 --> 00:13:36.770
You can get rid of
all that stuff.

00:13:36.770 --> 00:13:38.960
Statistical redundancy--

00:13:38.960 --> 00:13:42.800
redundancy in the data stream
itself00 the ones and zeros.

00:13:42.800 --> 00:13:43.720
Take those out.

00:13:43.720 --> 00:13:45.510
There's perceptual--

00:13:45.510 --> 00:13:47.360
it's called redundancy,
but it's not quite.

00:13:47.360 --> 00:13:50.110
It's just things that the human
eye can't even perceive.

00:13:50.110 --> 00:13:51.090
Just take those out.

00:13:51.090 --> 00:13:54.130
So you take all these things out
with the ultimate goal of

00:13:54.130 --> 00:13:58.080
removing them, yet keeping the
quality as close as you

00:13:58.080 --> 00:14:00.870
possibly can to the original
source video.

00:14:00.870 --> 00:14:04.070
This is the way this is the
art of the technology.

00:14:04.070 --> 00:14:07.410
How do you do all this, yet when
you reconstruct the image

00:14:07.410 --> 00:14:10.750
from the compressed bitstream,
what the user sees is, you

00:14:10.750 --> 00:14:13.760
hope, imperceptible from
what you started from.

00:14:13.760 --> 00:14:15.990
So raw video--

00:14:15.990 --> 00:14:19.410
video right off of a camera and
editing deck, whatever--

00:14:19.410 --> 00:14:21.450
if you just have all those
full pixels, it's not

00:14:21.450 --> 00:14:22.620
compressed at all.

00:14:22.620 --> 00:14:23.870
It's gigantic.

00:14:23.870 --> 00:14:25.750
So let's say this video
that I'm going to

00:14:25.750 --> 00:14:28.610
encode is not even HD.

00:14:28.610 --> 00:14:31.180
It's around standard
definition.

00:14:31.180 --> 00:14:35.560
It's 17 seconds long, just for
the sake of brevity here.

00:14:35.560 --> 00:14:40.400
Yet it's 320 megabytes,
that file.

00:14:40.400 --> 00:14:44.440
So I don't know about you, but
my network at home can't serve

00:14:44.440 --> 00:14:46.520
that data rate.

00:14:46.520 --> 00:14:49.800
I don't know, maybe if you had
fiber, maybe, but even then

00:14:49.800 --> 00:14:50.930
probably not.

00:14:50.930 --> 00:14:52.570
Audio, same case.

00:14:52.570 --> 00:14:56.870
The raw audio stream I'm going
to use, which is PCM samples,

00:14:56.870 --> 00:14:58.490
is three megabytes.

00:14:58.490 --> 00:15:00.730
I got 17 seconds.

00:15:00.730 --> 00:15:06.970
So how are we going to get 323
megabytes of data over a

00:15:06.970 --> 00:15:09.730
network to a user
in 17 seconds.

00:15:09.730 --> 00:15:12.900
Well, we're going to use ffmpeg
We're going to combine

00:15:12.900 --> 00:15:16.950
these streams, which is called
muxing, multiplexing.

00:15:16.950 --> 00:15:19.630
We're then going to run
them through ffmpeg.

00:15:19.630 --> 00:15:24.880
And this is represented by this
clever spinning logo.

00:15:24.880 --> 00:15:27.240
This is where all that magic
that I talked about happens.

00:15:27.240 --> 00:15:31.520
This is where the codec is going
to look at these frames

00:15:31.520 --> 00:15:34.520
of video and look at all the
redundancies and just pull

00:15:34.520 --> 00:15:38.390
them all out, compress it
all down into a stream.

00:15:38.390 --> 00:15:39.440
And the final result
is going to be a

00:15:39.440 --> 00:15:43.060
WebM file of 1.9 megabytes.

00:15:43.060 --> 00:15:47.980
So we took 323 megabytes worth
of raw data, and now this is

00:15:47.980 --> 00:15:53.140
something that 17 seconds, 1.9
megabytes, easily can be

00:15:53.140 --> 00:15:58.730
served to pretty much any user,
even maybe even over a

00:15:58.730 --> 00:16:00.280
3G connection.

00:16:00.280 --> 00:16:03.560
So let's look at how
this is done.

00:16:03.560 --> 00:16:04.480
This is the example.

00:16:04.480 --> 00:16:05.780
I have a couple examples
in this slide.

00:16:05.780 --> 00:16:08.810
You'll be able to download them
later on and play around

00:16:08.810 --> 00:16:09.370
with them yourself.

00:16:09.370 --> 00:16:10.260
You can modify them.

00:16:10.260 --> 00:16:11.240
There are other options.

00:16:11.240 --> 00:16:14.330
You can go as deep into this
stuff as you want.

00:16:14.330 --> 00:16:17.790
But one of the beauties of VP8
and WebM is that we have,

00:16:17.790 --> 00:16:21.120
again, with simplicity in mind,
you don't have to be an

00:16:21.120 --> 00:16:22.200
expert in this stuff.

00:16:22.200 --> 00:16:25.040
You don't have to hire
consultants to show you

00:16:25.040 --> 00:16:28.230
exactly every parameter
required to do this.

00:16:28.230 --> 00:16:32.870
Pretty much if you put a video
into the libvpx compressor, it

00:16:32.870 --> 00:16:34.630
makes a lot of the hard
decisions for you.

00:16:34.630 --> 00:16:37.840
What comes out there is, in
most cases, pretty great.

00:16:37.840 --> 00:16:41.740
So let's just step through
these parameters here.

00:16:41.740 --> 00:16:42.880
First is the binary--

00:16:42.880 --> 00:16:43.590
ffmpeg.

00:16:43.590 --> 00:16:45.252
That's the program.

00:16:45.252 --> 00:16:48.820
The dot i is the input video.

00:16:48.820 --> 00:16:52.550
Again, this is a raw stream,
Y4M, just raw pixel data.

00:16:52.550 --> 00:16:56.090
Same with the audio, just
a WAV file, PCM samples.

00:16:56.090 --> 00:16:58.890
This -c v parameter is libvpx.

00:16:58.890 --> 00:17:02.500
That's the library that we
at the WebM project make

00:17:02.500 --> 00:17:05.740
available in source or binary
from the website.

00:17:05.740 --> 00:17:09.480
Does all the VP8
encoding magic.

00:17:09.480 --> 00:17:11.329
-b v is the bit rate.

00:17:11.329 --> 00:17:14.280
So I'm going to set the target
bit-rate of this file to 800

00:17:14.280 --> 00:17:16.839
kilobits per second.

00:17:16.839 --> 00:17:17.569
What does that mean?

00:17:17.569 --> 00:17:22.560
That means I tell the encoder I
say OK, if you could encode

00:17:22.560 --> 00:17:26.430
any frame or segment or one
second's worth of video in

00:17:26.430 --> 00:17:30.360
these streams, with using less
than 800 kilobits of

00:17:30.360 --> 00:17:32.600
data, go for it.

00:17:32.600 --> 00:17:33.160
That's great.

00:17:33.160 --> 00:17:35.320
Yet don't exceed that.

00:17:35.320 --> 00:17:38.600
Because my target use case,
I know that my users--

00:17:38.600 --> 00:17:41.830
let's say, I know from market
research, whatever-- that most

00:17:41.830 --> 00:17:45.520
of my users don't have any more
than a megabit reliable

00:17:45.520 --> 00:17:46.740
connectivity.

00:17:46.740 --> 00:17:49.810
So with overhead and audio, I
want to keep that well below

00:17:49.810 --> 00:17:51.190
one megabit a second.

00:17:51.190 --> 00:17:53.020
So I'm going to specify
800 kilobits as

00:17:53.020 --> 00:17:56.110
my target data rate.

00:17:56.110 --> 00:17:57.520
Quality setting is just--

00:17:57.520 --> 00:17:59.750
in the VP8 coder, there's
three settings--

00:17:59.750 --> 00:18:01.650
real time, best and good.

00:18:01.650 --> 00:18:05.620
Best and good are kind of
misnomers, in that yes, best

00:18:05.620 --> 00:18:08.110
will give you the absolute
best quality.

00:18:08.110 --> 00:18:10.550
But in most cases, good
is just that.

00:18:10.550 --> 00:18:11.610
It's good enough.

00:18:11.610 --> 00:18:12.620
And it runs faster.

00:18:12.620 --> 00:18:16.780
The best quality will give you
the best output, but it is, in

00:18:16.780 --> 00:18:20.160
some cases, depending on the
material, can be significantly

00:18:20.160 --> 00:18:23.260
more intense and take
longer to encode.

00:18:23.260 --> 00:18:26.755
So this next is just the
video filter, the -vf.

00:18:26.755 --> 00:18:29.300
There are a number of filters
that you can use an ffmpeg to

00:18:29.300 --> 00:18:32.150
do all sorts of things like--

00:18:32.150 --> 00:18:33.640
scaling is one of them.

00:18:33.640 --> 00:18:35.390
So I'm going to scale
this video.

00:18:35.390 --> 00:18:38.460
Right now, it's a little bit
bigger than standard

00:18:38.460 --> 00:18:39.390
definition.

00:18:39.390 --> 00:18:42.160
I'm going to scale down to
standard definition, which is

00:18:42.160 --> 00:18:44.990
480 pixels high.

00:18:44.990 --> 00:18:49.240
The negative one is I'm saying
OK, I want you make it 480

00:18:49.240 --> 00:18:51.820
pixels high, but the width--

00:18:51.820 --> 00:18:55.260
I want you to keep it
proportional to the input, to

00:18:55.260 --> 00:18:57.580
that Y4M file.

00:18:57.580 --> 00:18:59.890
So this means that it's going
to scale it proportionally.

00:18:59.890 --> 00:19:02.020
Whatever that width ends
up being, that's what

00:19:02.020 --> 00:19:02.460
it's going to be.

00:19:02.460 --> 00:19:06.390
This prevents things like if you
use the defaults, in some

00:19:06.390 --> 00:19:10.460
cases it'll scale-- if you say
scale 480, but you don't

00:19:10.460 --> 00:19:13.420
preserve the aspect, you get
these videos with people

00:19:13.420 --> 00:19:16.030
stretched out or squished.

00:19:16.030 --> 00:19:19.260
So in pretty much every case,
you want to preserve the

00:19:19.260 --> 00:19:21.170
aspect ratio.

00:19:21.170 --> 00:19:23.675
Last arguments are just
for libvorbis.

00:19:23.675 --> 00:19:26.200
This is the audio encoder,
also freely available.

00:19:26.200 --> 00:19:29.130
And I'm just going to use the
default settings there, which

00:19:29.130 --> 00:19:30.940
are good enough for
this use case.

00:19:30.940 --> 00:19:34.560
And the last one is the output
file, which is cleverly enough

00:19:34.560 --> 00:19:38.940
called of W480.webm.

00:19:38.940 --> 00:19:41.410
So just like on the old cooking
shows, through the

00:19:41.410 --> 00:19:44.000
magic of technology, I happen
to have one of these already

00:19:44.000 --> 00:19:45.910
ready to go.

00:19:45.910 --> 00:19:49.220
So let's see what happens.

00:19:49.220 --> 00:19:52.020
Now it just spit out a bunch
of scary looking stuff.

00:19:52.020 --> 00:19:52.900
It's not that scary.

00:19:52.900 --> 00:19:56.650
All this is mostly some
information about how this

00:19:56.650 --> 00:19:59.940
particular instance of ffmpeg
was compiled-- all the flags

00:19:59.940 --> 00:20:00.330
and things.

00:20:00.330 --> 00:20:03.270
The interesting stuff here is
the sort of purple text.

00:20:03.270 --> 00:20:07.450
So it's saying OK, I see that
you've handed me a Y4M file.

00:20:07.450 --> 00:20:11.630
It does some piping magic to
handle those types of files.

00:20:11.630 --> 00:20:13.280
These are the properties
of it.

00:20:13.280 --> 00:20:17.285
It's just telling me look, there
are no time codes or

00:20:17.285 --> 00:20:17.920
anything here.

00:20:17.920 --> 00:20:19.060
So this might be inaccurate.

00:20:19.060 --> 00:20:19.700
I'm going to guess.

00:20:19.700 --> 00:20:21.510
That's usually good enough.

00:20:21.510 --> 00:20:22.340
Same with the audio.

00:20:22.340 --> 00:20:24.810
It says OK, this is what
you're hading me.

00:20:24.810 --> 00:20:27.130
You already have one of these
files there, because you've

00:20:27.130 --> 00:20:29.490
tested it in your hotel
room this morning.

00:20:29.490 --> 00:20:31.200
Are you sure you want
to blow that away?

00:20:31.200 --> 00:20:34.380
And I say sure, let's
go for it.

00:20:34.380 --> 00:20:35.730
So now the magic starts.

00:20:35.730 --> 00:20:37.470
All those things I talked
about, again, with the

00:20:37.470 --> 00:20:43.180
redundancies, removing all
these things that are not

00:20:43.180 --> 00:20:45.790
needed to reconstruct this
image later using a

00:20:45.790 --> 00:20:47.500
decompressor.

00:20:47.500 --> 00:20:49.510
So you can see down at
the bottom, the final

00:20:49.510 --> 00:20:51.040
file size is growing.

00:20:51.040 --> 00:20:53.780
The bit-rate, in some sections,
is exceeding but

00:20:53.780 --> 00:20:57.720
overall, it's going-- across the
breadth of it should stay

00:20:57.720 --> 00:20:59.530
below and we're done.

00:20:59.530 --> 00:21:03.610
So let's see how we did.

00:21:03.610 --> 00:21:09.870
As I said, the aim of this is
to make what comes out as

00:21:09.870 --> 00:21:16.911
close as possible to what went
in from visual perspective.

00:21:16.911 --> 00:21:21.360
So we forgot to plug
in the audio.

00:21:21.360 --> 00:21:22.340
Trust me, there's audio.

00:21:22.340 --> 00:21:26.170
And these screen, it's
always hard.

00:21:26.170 --> 00:21:28.670
Projectors don't--
the fidelity's

00:21:28.670 --> 00:21:29.500
usually not so great.

00:21:29.500 --> 00:21:32.440
But you can see this looks
pretty good, right?

00:21:32.440 --> 00:21:35.500
This is only 800 kilobits a
second of data, which Frank

00:21:35.500 --> 00:21:38.780
and I've been in this business
for probably--

00:21:38.780 --> 00:21:39.285
I don't want--

00:21:39.285 --> 00:21:40.030
FRANK GALLIGAN: 15?

00:21:40.030 --> 00:21:41.460
JOHN LUTHER: Long enough for
you to gray hairs in your

00:21:41.460 --> 00:21:43.440
[INAUDIBLE].

00:21:43.440 --> 00:21:46.130
When we started in this, the
idea of doing a standard

00:21:46.130 --> 00:21:49.470
definition video at 800 kilobits
was preposterous.

00:21:49.470 --> 00:21:52.560
Back then, we were using 300
kilobits to do little postage

00:21:52.560 --> 00:21:53.130
size videos.

00:21:53.130 --> 00:21:58.650
So it's pretty remarkable how
far the technology has come.

00:21:58.650 --> 00:22:01.350
OK, so I have a number
of these examples.

00:22:01.350 --> 00:22:03.710
I want to give Frank his time.

00:22:03.710 --> 00:22:05.770
So you can look through these
later when you download.

00:22:05.770 --> 00:22:08.230
Just two pass, again,
more quality,

00:22:08.230 --> 00:22:09.270
but it'll take longer.

00:22:09.270 --> 00:22:11.530
This is an example here of
running the encoder in a real

00:22:11.530 --> 00:22:15.540
time mode to make it run faster,
which will slightly

00:22:15.540 --> 00:22:19.030
degrade the quality, but it
will be done in real time.

00:22:19.030 --> 00:22:20.920
And I just have an example here
of how you would do this

00:22:20.920 --> 00:22:23.210
for a mobile use case.

00:22:23.210 --> 00:22:25.560
So there's lots of information
on our site

00:22:25.560 --> 00:22:26.540
and around the internet.

00:22:26.540 --> 00:22:29.880
I put some links in here
about using ffmpeg

00:22:29.880 --> 00:22:31.560
and some other things.

00:22:31.560 --> 00:22:33.743
And this is where I hand
it over to Frank.

00:22:33.743 --> 00:22:36.240
FRANK GALLIGAN: Thanks, John.

00:22:36.240 --> 00:22:40.950
So John showed you one way to
encode videos on the desktop.

00:22:40.950 --> 00:22:44.180
I'm going to show you another
method of adding audio and

00:22:44.180 --> 00:22:47.085
video coding to your Android
applications.

00:22:47.085 --> 00:22:52.316
I'm going to use a project
called WebM JNI bindings.

00:22:52.316 --> 00:22:53.660
I have two demos.

00:22:53.660 --> 00:22:55.500
And then I'm going
take a little--

00:22:55.500 --> 00:23:00.410
time permitting-- a little
closer look at the code.

00:23:00.410 --> 00:23:07.760
So the WebM JNI bindings
allows your Android

00:23:07.760 --> 00:23:13.460
applications to interface with
five open source projects.

00:23:13.460 --> 00:23:17.010
The code in the green boxes is
the Java JNI code that your

00:23:17.010 --> 00:23:20.050
application will call.

00:23:20.050 --> 00:23:24.120
The code in the orange
box is the C, C++

00:23:24.120 --> 00:23:29.800
code of the JNI bindings.

00:23:29.800 --> 00:23:34.140
Most of the code in the orange
box is just a pass through

00:23:34.140 --> 00:23:36.380
from the Java NI bindings
to the C,

00:23:36.380 --> 00:23:39.230
C++ open source projects.

00:23:39.230 --> 00:23:43.840
There is a Vorbis encoder object
class that makes it

00:23:43.840 --> 00:23:46.300
easier to add Vorbis encoding.

00:23:46.300 --> 00:23:50.330
Also has some specific functions
for Vorbis with

00:23:50.330 --> 00:23:51.580
regards to WebM files.

00:23:54.030 --> 00:23:58.670
And all the code in the green
and orange boxes is what's

00:23:58.670 --> 00:24:01.200
comprising the WebM
JNI bindings.

00:24:01.200 --> 00:24:04.640
The code in the blue boxes is
the open source code that

00:24:04.640 --> 00:24:08.490
really does all the heavy
lifting, does the converting,

00:24:08.490 --> 00:24:11.310
does the encoding,
does the muxing.

00:24:11.310 --> 00:24:14.340
And most of the code in the blue
boxes is hand optimized

00:24:14.340 --> 00:24:17.930
for ARM, as well as x86.

00:24:17.930 --> 00:24:22.040
Also in the JNI bindings is
a readme.android file.

00:24:22.040 --> 00:24:25.460
The readme tells you how to set
everything up, where to

00:24:25.460 --> 00:24:29.430
get the open source code, how
to build them and how to get

00:24:29.430 --> 00:24:34.070
ready to add audio and video
encoding to your project.

00:24:34.070 --> 00:24:37.120
So with that, I'll show
our first demo.

00:24:44.730 --> 00:24:50.740
So what I'm going to do is I'm
going to add audio and-- oops,

00:24:50.740 --> 00:24:52.310
should be coming soon-- anyways,
I'm going to add

00:24:52.310 --> 00:24:56.000
audio and video encoding to an
Android device using the WebM

00:24:56.000 --> 00:24:58.830
JNI bindings.

00:24:58.830 --> 00:25:01.920
I'm using one of the example
functions from the bindings,

00:25:01.920 --> 00:25:08.030
which basically takes a raw
video input, raw audio input,

00:25:08.030 --> 00:25:09.600
and output to WebM
file on a device.

00:25:12.180 --> 00:25:15.240
What I did, I already created
the new application.

00:25:15.240 --> 00:25:19.810
Here's the main activity file
which you probably all know.

00:25:19.810 --> 00:25:22.610
And I already downloaded the
NI bindings, set them up.

00:25:22.610 --> 00:25:25.380
I already downloaded all the
dependent open source projects

00:25:25.380 --> 00:25:27.351
and set them up.

00:25:27.351 --> 00:25:31.125
I did that basically from
the readme.android.

00:25:31.125 --> 00:25:34.790
It gives you all the steps how
to do it, run through.

00:25:34.790 --> 00:25:35.740
It's pretty easy.

00:25:35.740 --> 00:25:40.120
We actually had a demo of when
I tried to create a new

00:25:40.120 --> 00:25:43.420
project from scratch, download
everything, add the audio and

00:25:43.420 --> 00:25:44.860
video encoding and show
the video file

00:25:44.860 --> 00:25:45.800
in under five minutes.

00:25:45.800 --> 00:25:48.580
It works sometimes, but we had
to cut it, because it was a

00:25:48.580 --> 00:25:49.320
little confusing.

00:25:49.320 --> 00:25:50.980
And we didn't have much time.

00:25:50.980 --> 00:25:54.560
We're already kind of running
a little late, as it is.

00:25:54.560 --> 00:25:59.470
So I'm going to copy the code
from the readme.android and

00:25:59.470 --> 00:26:03.300
add it to my main
file on Create.

00:26:03.300 --> 00:26:08.940
This is the code that will do
the audio and video encoding.

00:26:08.940 --> 00:26:12.800
I will update my includes.

00:26:12.800 --> 00:26:21.850
And I'm going to set my video
input file that I already

00:26:21.850 --> 00:26:23.780
pushed in my device on
external storage.

00:26:23.780 --> 00:26:26.780
I'm going to set
my audio file.

00:26:26.780 --> 00:26:28.930
Again, I already pushed.

00:26:28.930 --> 00:26:32.280
Save this, and now I'm
going to switch

00:26:32.280 --> 00:26:33.530
to the Android device.

00:26:40.350 --> 00:26:42.905
So this is probably the
simplest example.

00:26:42.905 --> 00:26:46.810
I'm just reading the audio and
video input file on the device

00:26:46.810 --> 00:26:48.700
in external storage
and writing it

00:26:48.700 --> 00:26:50.900
out to external storage.

00:26:50.900 --> 00:26:58.350
So let me show you that there is
no WebM file on the device.

00:26:58.350 --> 00:26:59.543
I kind of feel like
a magician.

00:26:59.543 --> 00:27:03.102
There's no cards up my sleeve.

00:27:03.102 --> 00:27:08.650
And now I'm going to run the
application on the device.

00:27:12.010 --> 00:27:14.760
So it's a pretty boring
application.

00:27:14.760 --> 00:27:17.260
It won't do too much.

00:27:21.820 --> 00:27:22.280
OK.

00:27:22.280 --> 00:27:23.530
I agree.

00:27:26.560 --> 00:27:27.830
There we go.

00:27:27.830 --> 00:27:29.065
I said it's not going
to do too much.

00:27:29.065 --> 00:27:32.290
It'll either say success,
it's done, or error.

00:27:32.290 --> 00:27:33.160
OK, good.

00:27:33.160 --> 00:27:35.290
Success.

00:27:35.290 --> 00:27:38.786
So let's go back to
the explorer.

00:27:38.786 --> 00:27:40.600
Hit refresh.

00:27:40.600 --> 00:27:43.721
Should have a WebM file.

00:27:43.721 --> 00:27:45.040
Let me play it.

00:27:45.040 --> 00:27:45.539
[VIDEO PLAYBACK]

00:27:45.539 --> 00:27:46.038
-Drop!

00:27:46.038 --> 00:27:50.030
[GUN SHOT]

00:27:50.030 --> 00:27:51.028
[EXPLOSION]

00:27:51.028 --> 00:27:51.527
[END VIDEO PLAYBACK]

00:27:51.527 --> 00:27:54.600
FRANK GALLIGAN: There we go.

00:27:54.600 --> 00:27:55.660
So it worked.

00:27:55.660 --> 00:27:58.130
It's nice when your first
demo works, you know.

00:27:58.130 --> 00:27:59.336
AUDIENCE: [APPLAUSE]

00:27:59.336 --> 00:28:00.230
FRANK GALLIGAN: You
do it 100 times.

00:28:00.230 --> 00:28:01.180
It works every time.

00:28:01.180 --> 00:28:03.610
You get up here, and
everything changes.

00:28:03.610 --> 00:28:07.230
So now I'll go back
to the slides.

00:28:12.920 --> 00:28:14.170
Maybe.

00:28:16.790 --> 00:28:18.750
All right.

00:28:18.750 --> 00:28:21.710
So I'm going to go into a little
bit of the code, the

00:28:21.710 --> 00:28:26.530
example code, that I used from
the bindings project.

00:28:26.530 --> 00:28:29.850
The first set of slides is
setting up the audio and video

00:28:29.850 --> 00:28:32.650
encoders, also the muxer.

00:28:32.650 --> 00:28:37.710
You can see we're creating
libvpx configure object.

00:28:37.710 --> 00:28:39.740
We're passing in the width
and the height

00:28:39.740 --> 00:28:41.980
of the source video.

00:28:41.980 --> 00:28:43.890
This is really important
because libvpx

00:28:43.890 --> 00:28:46.090
not scale the video.

00:28:46.090 --> 00:28:47.340
At this point, neither
will the binding.

00:28:47.340 --> 00:28:51.110
So whenever you're creating on
the input, it's going to be on

00:28:51.110 --> 00:28:52.360
the output.

00:28:54.750 --> 00:28:57.440
I'm also, in the example code
I'm showing, setting the

00:28:57.440 --> 00:29:00.300
target bitrate to
1,000 kilobits.

00:29:00.300 --> 00:29:01.790
This is your most important
setting.

00:29:01.790 --> 00:29:04.250
This is a setting you will
always change depending on

00:29:04.250 --> 00:29:07.270
your use case for your
application.

00:29:07.270 --> 00:29:09.640
For example, you could have--

00:29:09.640 --> 00:29:12.980
creating a really small
video, like 160 by 120

00:29:12.980 --> 00:29:13.750
for whatever reason.

00:29:13.750 --> 00:29:15.360
You're going to set your target
bit, right, maybe to

00:29:15.360 --> 00:29:16.790
100 kilobits.

00:29:16.790 --> 00:29:20.280
Or you could be encoding
HD, and you

00:29:20.280 --> 00:29:21.500
set it at three megabits.

00:29:21.500 --> 00:29:24.300
Whatever it is, this is the one
you're going to change.

00:29:24.300 --> 00:29:28.200
As John said before, a nice
feature of libvpx is the most

00:29:28.200 --> 00:29:31.370
part, most of your applications,
you don't have

00:29:31.370 --> 00:29:33.020
to change the other settings.

00:29:33.020 --> 00:29:37.715
The defaults will be fine for
95% of the applications.

00:29:37.715 --> 00:29:41.150
If you do have a very specific
need, there are other options

00:29:41.150 --> 00:29:44.980
like if you need to set the key
frame target, if you have

00:29:44.980 --> 00:29:48.420
certain seeking requirements or
maybe the quantizer values,

00:29:48.420 --> 00:29:52.560
depending if you want to not go
too high- the bit rate to

00:29:52.560 --> 00:29:54.260
not go too high or go too low.

00:29:54.260 --> 00:29:56.520
But for the most part, you set
the target bit rate, and

00:29:56.520 --> 00:29:59.800
everything else is fine.

00:29:59.800 --> 00:30:02.840
Here I'm just creating the
Vorbis configure object for

00:30:02.840 --> 00:30:05.730
passing in a number of channels,
sample rate, bits

00:30:05.730 --> 00:30:07.910
per sample of the audio.

00:30:07.910 --> 00:30:09.160
It's pretty easy.

00:30:11.240 --> 00:30:15.805
This code is setting the time
base for both the VP8 encoder

00:30:15.805 --> 00:30:17.630
and the Vorbis encoder.

00:30:17.630 --> 00:30:21.440
This is really a convenience
function because the muxer,

00:30:21.440 --> 00:30:26.300
the WebM expects the time base
to be nanosecond units.

00:30:26.300 --> 00:30:27.840
And the only reason we're doing
this is that we don't

00:30:27.840 --> 00:30:31.230
have to translate the
time stamps later.

00:30:31.230 --> 00:30:34.680
If you didn't do this, the video
default time base is

00:30:34.680 --> 00:30:37.390
milliseconds, and the audio
default time base is samples

00:30:37.390 --> 00:30:40.390
per second.

00:30:40.390 --> 00:30:40.880
Oop--

00:30:40.880 --> 00:30:43.770
a nanoseconds unit.

00:30:43.770 --> 00:30:46.430
Here, we're just creating
the encoder and

00:30:46.430 --> 00:30:47.780
passing config objects--

00:30:47.780 --> 00:30:48.820
config fig objects--

00:30:48.820 --> 00:30:50.210
very simple.

00:30:50.210 --> 00:30:54.100
At this point, both the
VP8 and the Vorbis

00:30:54.100 --> 00:30:55.230
encoder are set up.

00:30:55.230 --> 00:30:57.220
They're ready to start
encoding data.

00:30:57.220 --> 00:31:00.510
The next two lines are
setting up the muxer.

00:31:00.510 --> 00:31:04.330
The first line is we're creating
a writer object.

00:31:04.330 --> 00:31:08.200
And basically what that is is
it implements a very simple

00:31:08.200 --> 00:31:09.980
I/O interface.

00:31:09.980 --> 00:31:14.790
So if your application had
different I/O needs, maybe you

00:31:14.790 --> 00:31:17.970
had a packed file, whatever it
is, you can create your own

00:31:17.970 --> 00:31:21.580
writer object that implements
the MPAV writer interface.

00:31:21.580 --> 00:31:24.020
And you pass that
to the muxer.

00:31:24.020 --> 00:31:25.880
They did the default
writer interface--

00:31:25.880 --> 00:31:29.120
just uses the standard I/O,
f-open, f-write, f-close.

00:31:32.350 --> 00:31:37.800
Here we're telling it the file
to write to, just a string, a

00:31:37.800 --> 00:31:41.560
path and a file name output.

00:31:41.560 --> 00:31:45.160
And if you're writing to
external storage in the

00:31:45.160 --> 00:31:47.290
device, you just have to make
sure that you set the correct

00:31:47.290 --> 00:31:49.680
permission on your Android
application.

00:31:49.680 --> 00:31:51.580
Otherwise it won't work, and
it might get a little

00:31:51.580 --> 00:31:52.770
confusing as to why
it's not working.

00:31:52.770 --> 00:31:57.200
But there it is right there.

00:31:57.200 --> 00:31:58.870
Here we're just creating
the muxer object

00:31:58.870 --> 00:32:01.950
passing in the writer.

00:32:01.950 --> 00:32:05.210
Now we're adding the audio
and video track.

00:32:05.210 --> 00:32:08.020
We save the track numbers
for later.

00:32:08.020 --> 00:32:09.780
This is how the muxer
distinguishes between the

00:32:09.780 --> 00:32:13.520
different tracks is you pass
it the track number.

00:32:13.520 --> 00:32:16.160
The first two parameters are
both pretty self-explanatory,

00:32:16.160 --> 00:32:18.200
same as the config objects.

00:32:18.200 --> 00:32:22.610
The third parameter to the ad
track is if you explicitly

00:32:22.610 --> 00:32:25.330
need to set a track number.

00:32:25.330 --> 00:32:27.820
For most applications,
you won't need it.

00:32:27.820 --> 00:32:32.380
Passing in zero to libwebm
says you pick the number.

00:32:32.380 --> 00:32:35.220
I'm OK with that.

00:32:35.220 --> 00:32:39.990
And the last part of this set up
for the muxer is the Vorbis

00:32:39.990 --> 00:32:43.230
audio needs some private data.

00:32:43.230 --> 00:32:45.710
So you have to set the codec
private, which is basically

00:32:45.710 --> 00:32:47.770
what it says.

00:32:47.770 --> 00:32:51.440
It's data that's only
interpreted by the codec.

00:32:51.440 --> 00:32:54.575
Again, if you use the Vorbis
encoder from the orange boxes,

00:32:54.575 --> 00:32:55.690
it makes it pretty simple.

00:32:55.690 --> 00:32:57.310
You call codec private.

00:32:57.310 --> 00:33:01.050
It'll return the data in the
correct format, you set it,

00:33:01.050 --> 00:33:02.300
and you're good to go.

00:33:04.620 --> 00:33:05.670
So at this point, everything's
set up.

00:33:05.670 --> 00:33:09.540
And now we're getting into
our encoding loop.

00:33:09.540 --> 00:33:10.750
I kind of have some
pseudo-code.

00:33:10.750 --> 00:33:12.800
I just say get the raw frame.

00:33:12.800 --> 00:33:15.050
The audio--

00:33:15.050 --> 00:33:21.650
the raw data is just an array
of PCM samples per-- libvpx,

00:33:21.650 --> 00:33:25.990
the raw data is an I420
or YV12 frame.

00:33:25.990 --> 00:33:28.730
I'll talk a little bit more
about color formats when we

00:33:28.730 --> 00:33:30.730
get to the encode call.

00:33:30.730 --> 00:33:36.770
If the raw data is audio,
it's pretty simple.

00:33:36.770 --> 00:33:39.630
We just call encode, give
it the raw data.

00:33:39.630 --> 00:33:42.140
Then we get the compress
frame.

00:33:42.140 --> 00:33:47.420
I see I'm getting close on time,
so I'll try to go quick.

00:33:47.420 --> 00:33:50.800
For Vorbis, you had to check to
make sure the encoded frame

00:33:50.800 --> 00:33:54.900
is not null, because Vorbis
needs a certain amount of

00:33:54.900 --> 00:33:56.710
input samples before
it'll start passing

00:33:56.710 --> 00:33:58.600
back encoded data.

00:33:58.600 --> 00:34:01.030
First parameter is the
encoded frame.

00:34:01.030 --> 00:34:02.750
Second parameter is the
track number that

00:34:02.750 --> 00:34:04.720
we passed back before.

00:34:04.720 --> 00:34:07.200
Time stamp, already in the
correct time base.

00:34:07.200 --> 00:34:10.429
And the last parameter is a
flag, a boolean saying if it's

00:34:10.429 --> 00:34:12.810
a key frame or not.

00:34:12.810 --> 00:34:16.120
All Vorbis audio frames
are key frames.

00:34:16.120 --> 00:34:17.130
It's video.

00:34:17.130 --> 00:34:20.350
Again, we pass the encode
frame I420.

00:34:20.350 --> 00:34:24.020
We also have another function
call, because libvpx will only

00:34:24.020 --> 00:34:26.480
take I420 or YB12.

00:34:26.480 --> 00:34:30.469
But the libvpx wrapper will take
some RGB color space as

00:34:30.469 --> 00:34:32.750
well as some other
YUV color spaces.

00:34:32.750 --> 00:34:37.060
And what it'll do is it'll get
the raw frames, send it to

00:34:37.060 --> 00:34:40.650
libyuv to convert it to I420
and then send it to libvpx.

00:34:40.650 --> 00:34:45.050
Time stamp duration has to
be in time stamp units.

00:34:45.050 --> 00:34:47.210
The libvpx encode
frame returns an

00:34:47.210 --> 00:34:48.765
array of encoded packets.

00:34:48.765 --> 00:34:52.889
This is because the libvpx
encoder can create what we

00:34:52.889 --> 00:34:56.280
call altref frame, which is
basically a frame that must be

00:34:56.280 --> 00:34:59.660
decoded in order
but not shown.

00:34:59.660 --> 00:35:04.630
We loop through the array
of encoded packets.

00:35:04.630 --> 00:35:06.520
The only real difference
at the end--

00:35:06.520 --> 00:35:10.770
we check to see if the libvpx
packet is a key frame.

00:35:10.770 --> 00:35:12.652
Then we pass that.

00:35:12.652 --> 00:35:14.500
Oop-- hit the wrong button.

00:35:14.500 --> 00:35:17.240
And finally we tell the muxer
segment to finalize the

00:35:17.240 --> 00:35:20.980
segment which basically will
output seek points if you want

00:35:20.980 --> 00:35:23.000
then, which by default
was yes.

00:35:23.000 --> 00:35:25.130
And it will also seek back to
the beginning and update

00:35:25.130 --> 00:35:27.180
header values so the file
will be playable.

00:35:30.520 --> 00:35:33.110
John, you want to go to--

00:35:33.110 --> 00:35:34.520
JOHN LUTHER: Why don't
you do your slides?

00:35:34.520 --> 00:35:36.300
I'll do the YouTube demo,
because it can

00:35:36.300 --> 00:35:37.550
take a little while.

00:35:57.670 --> 00:36:01.270
Anyway, this is where you
can download this stuff.

00:36:01.270 --> 00:36:03.980
I'm just going to talk very
briefly about VP9, which is

00:36:03.980 --> 00:36:06.960
our next generation codec.

00:36:06.960 --> 00:36:08.490
It's also free, open.

00:36:08.490 --> 00:36:12.040
We don't charge any
money for it.

00:36:12.040 --> 00:36:17.055
The big point with
VP9 is shhhh.

00:36:17.055 --> 00:36:21.170
He uses the same quality as
VP8 and H.264 high profile

00:36:21.170 --> 00:36:23.330
using up to half the data.

00:36:23.330 --> 00:36:24.250
Saw it during the keynote.

00:36:24.250 --> 00:36:28.230
Linus Upson demonstrated VP9
playing side by side with a

00:36:28.230 --> 00:36:32.000
264 video and you could
see that the 264

00:36:32.000 --> 00:36:33.000
data rate was up here.

00:36:33.000 --> 00:36:35.425
VP9 was about half.

00:36:35.425 --> 00:36:36.860
This'll start rolling
out in YouTube and

00:36:36.860 --> 00:36:39.760
Chrome in Q3 of 2013.

00:36:39.760 --> 00:36:41.820
We're getting pretty aggressive
about rolling this

00:36:41.820 --> 00:36:45.610
out, because everybody involved
is pretty excited

00:36:45.610 --> 00:36:47.480
about the data savings.

00:36:47.480 --> 00:36:52.010
Bandwidth is still extremely
expensive business cost.

00:36:52.010 --> 00:36:54.780
People keep thinking that it's
free or that it's going to

00:36:54.780 --> 00:36:57.430
become cheaper, but
it never does.

00:36:57.430 --> 00:36:59.640
So anyway, there was a
session yesterday.

00:36:59.640 --> 00:37:02.730
You can watch the video on
YouTube later or download the

00:37:02.730 --> 00:37:03.360
slides from that.

00:37:03.360 --> 00:37:04.485
And that's all I'm going
to say on VP9.

00:37:04.485 --> 00:37:06.600
You all get to the really
exciting demo.

00:37:06.600 --> 00:37:07.850
FRANK GALLIGAN: Right.

00:37:12.870 --> 00:37:18.530
So the YouTube demo, it captured
video and audio from

00:37:18.530 --> 00:37:21.530
the camera and the microphone,
press in real time, then

00:37:21.530 --> 00:37:22.510
uploaded to YouTube.

00:37:22.510 --> 00:37:24.140
Just looking at it, wait
and processing.

00:37:24.140 --> 00:37:26.350
If it comes up, maybe
we can play it.

00:37:26.350 --> 00:37:28.880
Otherwise we can take some
really, really quick

00:37:28.880 --> 00:37:33.340
questions, if anybody has any.

00:37:33.340 --> 00:37:35.810
Just step up to the mike.

00:37:35.810 --> 00:37:38.110
And then we'll also have
Q&amp;A afterwards too.

00:37:38.110 --> 00:37:39.940
JOHN LUTHER: Yeah, you can
find us afterwards.

00:37:39.940 --> 00:37:41.200
AUDIENCE: Glad to hear you
guys are from OnTo.

00:37:41.200 --> 00:37:43.420
I actually used the OnTo encoder
probably a decade ago

00:37:43.420 --> 00:37:45.540
to do some video for web.

00:37:45.540 --> 00:37:46.765
Great quality at the time.

00:37:46.765 --> 00:37:50.600
A question for you is for
people that are video

00:37:50.600 --> 00:37:55.240
producers, is it easy to
integrate the encoder into

00:37:55.240 --> 00:37:58.500
something like Sony Vegas on the
PC or whatever's commonly

00:37:58.500 --> 00:37:59.840
used on the Mac?

00:37:59.840 --> 00:38:02.020
JOHN LUTHER: We have DirectShow
and QuickTime

00:38:02.020 --> 00:38:05.070
components for the encoder and
decoder that plug into pretty

00:38:05.070 --> 00:38:08.250
much all those tools.

00:38:08.250 --> 00:38:09.230
AUDIENCE: Hi.

00:38:09.230 --> 00:38:10.165
I'm a computer engineer.

00:38:10.165 --> 00:38:12.090
And for us, it's always beat
into us that there's

00:38:12.090 --> 00:38:13.340
always a trade off.

00:38:13.340 --> 00:38:15.120
And when you guys are talking
about this, you're saying it's

00:38:15.120 --> 00:38:18.980
low CP utilization, very good
compression ratio, and it

00:38:18.980 --> 00:38:19.640
still looks as good.

00:38:19.640 --> 00:38:21.800
It makes me wonder like
what's the catch?

00:38:21.800 --> 00:38:24.570
And if there isn't, why isn't
there one and why have all the

00:38:24.570 --> 00:38:28.730
previous ones failed to do
it as good as this has.

00:38:28.730 --> 00:38:30.410
FRANK GALLIGAN: There's
no catch.

00:38:30.410 --> 00:38:32.670
I mean, encoding
video is a very

00:38:32.670 --> 00:38:34.510
expensive operation, right?

00:38:34.510 --> 00:38:39.970
So when we say it's
low quality--

00:38:39.970 --> 00:38:41.830
I mean, it's high quality,
Low CPU--

00:38:41.830 --> 00:38:44.820
it's compared to what the
other current codec is.

00:38:44.820 --> 00:38:45.020
JOHN LUTHER: Right.

00:38:45.020 --> 00:38:49.020
And the other thing is you are
losing something in that the

00:38:49.020 --> 00:38:51.580
raw source has everything.

00:38:51.580 --> 00:38:54.570
Even like I said, that stuff
that your eye can't even see.

00:38:54.570 --> 00:38:56.360
So throw all that out.

00:38:56.360 --> 00:38:59.200
Like in editing bays, and people
who do pre-production,

00:38:59.200 --> 00:39:03.800
they keep lost lists versions of
files around to do editing.

00:39:03.800 --> 00:39:06.000
But then once it's encoded,
there's so much in that you

00:39:06.000 --> 00:39:07.310
just really--

00:39:07.310 --> 00:39:10.450
for the human eye to see
or anything else, you

00:39:10.450 --> 00:39:12.329
just don't need it.

00:39:12.329 --> 00:39:13.880
AUDIENCE: Thank you.

00:39:13.880 --> 00:39:14.275
FRANK GALLIGAN: Here.

00:39:14.275 --> 00:39:17.820
I think this is what we took,
so hopefully, it'll--

00:39:17.820 --> 00:39:17.860
JOHN LUTHER: Aaww.

00:39:17.860 --> 00:39:19.535
There's a kitty.

00:39:19.535 --> 00:39:21.585
FRANK GALLIGAN: So we had a
little Easter egg, too.

00:39:21.585 --> 00:39:24.950
We had to show this little cat
that we overlaid on the video

00:39:24.950 --> 00:39:27.230
that we upload to encode.

00:39:27.230 --> 00:39:31.730
AUDIENCE: [APPLAUSE]

00:39:31.730 --> 00:39:34.690
JOHN LUTHER: I think we could
do one more question.

00:39:34.690 --> 00:39:35.690
There's also hats.

00:39:35.690 --> 00:39:37.230
It wouldn't be I/O
without swag.

00:39:37.230 --> 00:39:40.620
So anybody who wants a free hat
with a handsome WebM logo,

00:39:40.620 --> 00:39:41.720
see me afterwards.

00:39:41.720 --> 00:39:42.606
Sorry, go ahead.

00:39:42.606 --> 00:39:43.650
AUDIENCE: Hi, name
is Mauricio.

00:39:43.650 --> 00:39:47.665
I like to know you see VP8 and
VP9 being used for video

00:39:47.665 --> 00:39:49.686
calling in mobile devices.

00:39:49.686 --> 00:39:52.180
FRANK GALLIGAN:
Video-conferencing?

00:39:52.180 --> 00:39:52.740
AUDIENCE: Used for

00:39:52.740 --> 00:39:54.780
videocalling from mobile devices.

00:39:54.780 --> 00:39:56.400
Either VP8 or VP9.

00:39:56.400 --> 00:39:59.015
JOHN LUTHER: I mean, part
of the webRTC--

00:39:59.015 --> 00:40:01.020
are you familiar with WebRTC?

00:40:01.020 --> 00:40:06.020
We're trying to recommend it
or we have as a mandatory

00:40:06.020 --> 00:40:07.940
implement code for WebRTC.

00:40:07.940 --> 00:40:11.255
It's what you were using with
our WebRTC at Google.

00:40:11.255 --> 00:40:12.630
It's one of things that--

00:40:12.630 --> 00:40:14.380
we had so little time.

00:40:14.380 --> 00:40:18.460
I had an earlier draft of these
gone into why VP is also

00:40:18.460 --> 00:40:22.060
a very, very good codec, maybe
in some ways better than for

00:40:22.060 --> 00:40:23.630
visual, for video on demand.

00:40:23.630 --> 00:40:27.680
Its real time capabilities for
RTC are pretty amazing.

00:40:27.680 --> 00:40:30.740
So the answer is yes.

00:40:30.740 --> 00:40:32.970
AUDIENCE: So on the same line,
one of the great things about

00:40:32.970 --> 00:40:35.200
the opus codec, which you
mentioned is coming in WebM,

00:40:35.200 --> 00:40:36.860
is its real time performance.

00:40:36.860 --> 00:40:38.520
It's very, very low latency.

00:40:38.520 --> 00:40:43.140
What kind of latencies can you
achieve with VP8 or VP9.

00:40:43.140 --> 00:40:45.930
FRANK GALLIGAN: Well, VP8, you
can achieve some frame-- so

00:40:45.930 --> 00:40:47.300
one frame latency.

00:40:47.300 --> 00:40:50.280
AUDIENCE: So like like 8,
9, 10 milliseconds.

00:40:50.280 --> 00:40:50.730
FRANK GALLIGAN: Yeah.

00:40:50.730 --> 00:40:52.670
I mean, it depends
on your options.

00:40:52.670 --> 00:40:57.630
Whatever options you pick,
we try to keep it like 30

00:40:57.630 --> 00:40:58.670
milliseconds or whatever.

00:40:58.670 --> 00:41:00.180
Maybe one frame latency.

00:41:00.180 --> 00:41:05.060
You can always turn off your
options to get it to 8, 9, 10

00:41:05.060 --> 00:41:05.840
milliseconds latency.

00:41:05.840 --> 00:41:07.490
But then your quality might
not be as good.

00:41:07.490 --> 00:41:07.980
AUDIENCE: Right.

00:41:07.980 --> 00:41:11.680
FRANK GALLIGAN: So we try to
keep it to one-frame latency.

00:41:11.680 --> 00:41:12.420
VP9--

00:41:12.420 --> 00:41:15.860
we'll still working on it, but
we have the same target when

00:41:15.860 --> 00:41:16.330
it comes out.

00:41:16.330 --> 00:41:19.010
I think it's Q3 or
4 this year.

00:41:19.010 --> 00:41:19.750
JOHN LUTHER: Q3.

00:41:19.750 --> 00:41:20.840
I mean, the bitstream is--

00:41:20.840 --> 00:41:21.750
FRANK GALLIGAN: For real time.

00:41:21.750 --> 00:41:23.960
JOHN LUTHER: The bitstream
will be frozen in June.

00:41:23.960 --> 00:41:24.725
And then--

00:41:24.725 --> 00:41:26.320
FRANK GALLIGAN: Yeah, for
real times, it's Q--

00:41:26.320 --> 00:41:28.540
JOHN LUTHER: For real time, I'm
sorry, Q4, yeah, when we

00:41:28.540 --> 00:41:30.060
build it in real time.

00:41:30.060 --> 00:41:32.180
They keep giving us more time.

00:41:32.180 --> 00:41:34.460
It's like it's running backwards
or something.

00:41:34.460 --> 00:41:37.060
So anyway, it you want a
hat, come and see us.

00:41:37.060 --> 00:41:38.580
If you have any other questions,
feel free.

00:41:38.580 --> 00:41:39.450
FRANK GALLIGAN: And
we'll be out.

00:41:39.450 --> 00:41:40.160
And it's online.

00:41:40.160 --> 00:41:41.130
JOHN LUTHER: We'll be
out in the booth.

00:41:41.130 --> 00:41:42.540
So thanks everybody.

00:41:42.540 --> 00:41:43.790
FRANK GALLIGAN: Thank you.

