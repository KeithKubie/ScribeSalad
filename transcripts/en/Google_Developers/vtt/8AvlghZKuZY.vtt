WEBVTT
Kind: captions
Language: en

00:00:00.499 --> 00:00:04.120
Hello everybody
and good morning.

00:00:04.120 --> 00:00:07.540
Thank you guys for getting
up and joining me here today.

00:00:07.540 --> 00:00:11.010
I know it was a
late night for me.

00:00:11.010 --> 00:00:15.000
My name's Eitan, and I lead
the developer engineering

00:00:15.000 --> 00:00:17.120
team on Project Tango.

00:00:17.120 --> 00:00:19.700
And today, I want to
walk you through some

00:00:19.700 --> 00:00:22.080
of the capabilities
of the device.

00:00:22.080 --> 00:00:23.910
But more specifically,
I want to focus

00:00:23.910 --> 00:00:27.290
on how you might build
an augmented reality

00:00:27.290 --> 00:00:30.270
experience with Project Tango.

00:00:30.270 --> 00:00:33.810
So I know we've been
relatively popular here

00:00:33.810 --> 00:00:36.440
at I/O. How many of you
have seen a Project Tango

00:00:36.440 --> 00:00:38.950
demo while you've been here?

00:00:38.950 --> 00:00:40.340
Yeah, did you like it?

00:00:40.340 --> 00:00:41.640
Yeah?

00:00:41.640 --> 00:00:44.520
All right, great.

00:00:44.520 --> 00:00:46.860
So that's a lot of you,
but not all of you.

00:00:46.860 --> 00:00:49.490
Just a quick shout-out--
we will have the sandbox

00:00:49.490 --> 00:00:51.590
going throughout the day today.

00:00:51.590 --> 00:00:54.340
So after this talk, if you
want to go by and check it out,

00:00:54.340 --> 00:00:57.610
you should definitely get your
hands on Tango for yourselves,

00:00:57.610 --> 00:01:00.004
do a demo.

00:01:00.004 --> 00:01:01.420
All right, so for
those of you who

00:01:01.420 --> 00:01:03.230
haven't heard of
the platform, I'm

00:01:03.230 --> 00:01:05.190
going to do a brief overview.

00:01:05.190 --> 00:01:06.860
I'll keep it relatively brief.

00:01:06.860 --> 00:01:11.810
I really do want to spend most
of my time talking about how

00:01:11.810 --> 00:01:14.970
we actually build
applications for the platform,

00:01:14.970 --> 00:01:18.190
as well as the APIs that we
provide for augmented reality

00:01:18.190 --> 00:01:20.860
content.

00:01:20.860 --> 00:01:24.800
Clicker-- awesome, right.

00:01:24.800 --> 00:01:29.070
So our brief overview--
Project Tango fundamentally

00:01:29.070 --> 00:01:31.740
is about extending
the capabilities

00:01:31.740 --> 00:01:35.360
of our mobile devices
beyond the screen.

00:01:35.360 --> 00:01:38.790
If you look at your phone today,
you interact with it mostly

00:01:38.790 --> 00:01:42.210
with your head down,
touching different buttons,

00:01:42.210 --> 00:01:43.670
maybe swiping through photos.

00:01:43.670 --> 00:01:46.440
Really, the only way that your
phone interacts with the world

00:01:46.440 --> 00:01:48.650
is through pictures and videos.

00:01:48.650 --> 00:01:51.460
And Tango seeks to
enable your phone

00:01:51.460 --> 00:01:54.970
to do much more, to
gain an understanding

00:01:54.970 --> 00:01:58.220
of the physical space
of your environment,

00:01:58.220 --> 00:02:01.160
to be able to track the
position of your device

00:02:01.160 --> 00:02:03.540
as you move through
space, and also

00:02:03.540 --> 00:02:08.710
to be able to sense the geometry
of your environment as well.

00:02:08.710 --> 00:02:11.270
When you have
these capabilities,

00:02:11.270 --> 00:02:14.970
it allows us to turn your
device into a magic window

00:02:14.970 --> 00:02:16.420
into the world.

00:02:16.420 --> 00:02:20.800
We can play games like
Jenga from Schell Games,

00:02:20.800 --> 00:02:23.610
where you place a
virtual Jenga tower

00:02:23.610 --> 00:02:27.140
on a table in front of you,
and you don't have to clean up.

00:02:27.140 --> 00:02:31.260
We can do things like
measure your sofa.

00:02:31.260 --> 00:02:33.950
You can measure the height
from the ceiling to the floor

00:02:33.950 --> 00:02:36.760
without playing the game
where you see if your tape

00:02:36.760 --> 00:02:38.620
measure falls over.

00:02:38.620 --> 00:02:43.320
And we can also, towards the
future, navigate from point A

00:02:43.320 --> 00:02:45.410
to B in space.

00:02:45.410 --> 00:02:48.390
So imagine going into
a mall and wanting

00:02:48.390 --> 00:02:50.710
to know even where your
friend is in the mall,

00:02:50.710 --> 00:02:53.870
and being directed in an
augmented reality view to them.

00:02:53.870 --> 00:02:57.600
So that's kind of
what we're working on,

00:02:57.600 --> 00:03:00.460
and to enable these
kinds of applications,

00:03:00.460 --> 00:03:04.670
we provide a couple of core
technologies to developers.

00:03:04.670 --> 00:03:06.150
And you've probably
heard of these

00:03:06.150 --> 00:03:09.120
if you've been to some
of our other talks.

00:03:09.120 --> 00:03:13.000
But they are motion
tracking, depth perception,

00:03:13.000 --> 00:03:14.430
and area learning.

00:03:14.430 --> 00:03:17.080
And I'll go through
each of them briefly

00:03:17.080 --> 00:03:20.190
over the next couple slides.

00:03:20.190 --> 00:03:24.480
So motion tracking is
really the core technology

00:03:24.480 --> 00:03:28.280
upon which Tango is built.
And motion tracking allows

00:03:28.280 --> 00:03:33.540
Tango devices to understand
their relative position

00:03:33.540 --> 00:03:36.610
and orientation to
where they started.

00:03:36.610 --> 00:03:39.870
So if I just use my
device as a prop,

00:03:39.870 --> 00:03:43.260
as I move with my Tango
device in the world,

00:03:43.260 --> 00:03:47.170
it knows that I've walked,
say, a meter forward

00:03:47.170 --> 00:03:49.710
and turned 90
degrees to the left.

00:03:49.710 --> 00:03:52.760
And this is the motion tracking
capability of the device.

00:03:52.760 --> 00:03:55.370
It's using visual features
in the environment,

00:03:55.370 --> 00:04:00.910
combining that with inertial
sensors to estimate position.

00:04:00.910 --> 00:04:04.710
The second piece of technology
that we expose through our APIs

00:04:04.710 --> 00:04:06.210
is depth perception.

00:04:06.210 --> 00:04:10.230
And depth perception allows
our Tango devices to see in 3D.

00:04:10.230 --> 00:04:14.930
So on our tablet here we've
got a special depth camera,

00:04:14.930 --> 00:04:18.079
and it projects infrared
light out into the world.

00:04:18.079 --> 00:04:20.850
And it has a camera that
can see that infrared light.

00:04:20.850 --> 00:04:25.080
And by seeing the pattern,
it can judge, OK, my device

00:04:25.080 --> 00:04:28.110
is a meter to this surface.

00:04:28.110 --> 00:04:30.700
And so I can start
combining motion tracking

00:04:30.700 --> 00:04:32.310
with depth perception
to do things

00:04:32.310 --> 00:04:34.850
like real-time meshing
of environments.

00:04:34.850 --> 00:04:36.237
It's very powerful.

00:04:36.237 --> 00:04:37.820
Now you have an
understanding of where

00:04:37.820 --> 00:04:41.696
a table is, where a chair
is, and where objects

00:04:41.696 --> 00:04:43.320
are in the world,
and your applications

00:04:43.320 --> 00:04:46.580
can start to take
advantage of it.

00:04:46.580 --> 00:04:50.510
And the third capability of
Tango devices is area learning.

00:04:50.510 --> 00:04:53.720
And Wim gave a talk-- I
believe two days ago--

00:04:53.720 --> 00:04:55.210
on area learning.

00:04:55.210 --> 00:04:57.790
But it's the memory
of the device.

00:04:57.790 --> 00:04:59.840
It's the ability
of Tango devices

00:04:59.840 --> 00:05:04.517
to remember where they've been
before and to recognize spaces.

00:05:04.517 --> 00:05:06.350
So if you think about
coming into this room,

00:05:06.350 --> 00:05:09.370
and maybe you see the
Exit sign at the back,

00:05:09.370 --> 00:05:11.380
if the device saw
the same thing,

00:05:11.380 --> 00:05:14.400
it remembers roughly
how the Exit sign looks.

00:05:14.400 --> 00:05:17.690
It remembers how the scaffolding
here looks around it.

00:05:17.690 --> 00:05:21.760
And so when you walk back into
that space a different time,

00:05:21.760 --> 00:05:24.190
or if you have
multiple devices, they

00:05:24.190 --> 00:05:26.750
recognize where they are
relative to that landmark

00:05:26.750 --> 00:05:28.160
in the world.

00:05:28.160 --> 00:05:31.690
And with that, you can enable
multiplayer experiences,

00:05:31.690 --> 00:05:34.580
because you have a shared
reference frame for Tango

00:05:34.580 --> 00:05:37.410
devices, and you
can also enable,

00:05:37.410 --> 00:05:40.350
towards the future, things
like this indoor navigation use

00:05:40.350 --> 00:05:43.570
case, going from point A to
B, because the device knows

00:05:43.570 --> 00:05:44.480
what space it's in.

00:05:47.100 --> 00:05:48.480
OK.

00:05:48.480 --> 00:05:51.620
So at this point,
we have actually

00:05:51.620 --> 00:05:54.860
gone through everything that
I normally get to talk about.

00:05:54.860 --> 00:05:59.400
I have never gotten to go deeper
on Tango technology than this.

00:05:59.400 --> 00:06:04.170
And here, we're through it
in, like, seven-ish minutes.

00:06:04.170 --> 00:06:06.860
So I feel pretty
good, and I'm really

00:06:06.860 --> 00:06:08.240
excited about this next part.

00:06:08.240 --> 00:06:10.610
We're going to go
deep on how you build

00:06:10.610 --> 00:06:15.170
for AR, the considerations
that you take into account,

00:06:15.170 --> 00:06:18.120
the different pieces
of Tango technology

00:06:18.120 --> 00:06:21.220
that enable you on a journey
to better and better AR,

00:06:21.220 --> 00:06:22.870
and also we're going
to talk about some

00:06:22.870 --> 00:06:26.560
of the limitations of
augmented reality, as well,

00:06:26.560 --> 00:06:29.510
and how you can be creative
in building applications that

00:06:29.510 --> 00:06:32.430
work around it.

00:06:32.430 --> 00:06:35.200
And so for something
of this magnitude,

00:06:35.200 --> 00:06:37.000
I was thinking to
myself, you know, OK,

00:06:37.000 --> 00:06:38.290
what are we going to build?

00:06:38.290 --> 00:06:40.000
What am I going to show here?

00:06:40.000 --> 00:06:42.730
And I was browsing the
internet and looking around,

00:06:42.730 --> 00:06:46.120
and thought what really
represents the internet?

00:06:46.120 --> 00:06:48.370
What really brings it
to life in front of us?

00:06:48.370 --> 00:06:51.720
What can we do that just
represents the magnitude

00:06:51.720 --> 00:06:53.130
and scale of the occasion?

00:06:53.130 --> 00:06:59.020
And so we are going to build a
cat game in augmented reality

00:06:59.020 --> 00:07:03.040
in front of you-- the most
majestic of creatures.

00:07:03.040 --> 00:07:07.594
And specifically, we're
going to take virtual cats,

00:07:07.594 --> 00:07:09.760
and we're going to put them
into our physical world.

00:07:13.180 --> 00:07:15.800
Also, in preparing
for this talk,

00:07:15.800 --> 00:07:17.810
I was procrastinating
a little bit.

00:07:17.810 --> 00:07:20.752
This Wikipedia page is
way better than you think,

00:07:20.752 --> 00:07:21.918
if you want to check it out.

00:07:24.330 --> 00:07:24.830
I know.

00:07:24.830 --> 00:07:27.080
It's surprising, right?

00:07:27.080 --> 00:07:29.880
All right, so back to our cats.

00:07:29.880 --> 00:07:33.590
Let say our idea is to bring
as many cats as possible

00:07:33.590 --> 00:07:37.990
from virtual space into
our physical environment.

00:07:37.990 --> 00:07:42.360
We've got 3D models
of all of these cats,

00:07:42.360 --> 00:07:44.870
and we want to bring
them to life in 3D.

00:07:44.870 --> 00:07:48.080
So where do you even start?

00:07:48.080 --> 00:07:50.670
This picture is
kind of the ideal

00:07:50.670 --> 00:07:55.190
of what we'd be going for, but
it's really hard to achieve.

00:07:55.190 --> 00:07:57.590
So we're going to take
some steps along the way.

00:07:57.590 --> 00:07:59.540
And we're not going to
get all the way there,

00:07:59.540 --> 00:08:02.310
but starting is hard.

00:08:02.310 --> 00:08:05.050
So first, I'm going to take
a step back a little bit.

00:08:05.050 --> 00:08:08.400
How many of you have
experience with linear algebra,

00:08:08.400 --> 00:08:10.543
3D geometry, coordinate
frame transforms?

00:08:13.350 --> 00:08:17.880
You know, for an audience,
that's pretty good.

00:08:17.880 --> 00:08:20.810
But I'm going to do a
little bit of a refresher,

00:08:20.810 --> 00:08:26.620
and also, just as comfort
for everyone else,

00:08:26.620 --> 00:08:28.720
I'm not going to go
too deep into that.

00:08:28.720 --> 00:08:31.560
We're going to keep
it fairly high level.

00:08:31.560 --> 00:08:34.500
But mostly I'm going to talk
about the coordinate frames

00:08:34.500 --> 00:08:38.570
that Tango defines as
they relate to each other

00:08:38.570 --> 00:08:43.409
and as they relate to the device
as you move it through space.

00:08:43.409 --> 00:08:45.590
All right, we're
back to our cats.

00:08:45.590 --> 00:08:48.860
So the goal, again, is
to take a virtual cat

00:08:48.860 --> 00:08:50.810
and to put it in
our physical world.

00:08:50.810 --> 00:08:52.750
So here we've got a living room.

00:08:52.750 --> 00:08:54.840
We've got our virtual
cat, and we want

00:08:54.840 --> 00:08:57.360
to place it on the ottoman.

00:08:57.360 --> 00:09:00.360
And the cat should stay
fixed in the environment

00:09:00.360 --> 00:09:02.280
as we move around it.

00:09:02.280 --> 00:09:04.644
And ideally, it
would even interact

00:09:04.644 --> 00:09:06.060
with the environment
a little bit,

00:09:06.060 --> 00:09:09.980
so maybe the cat jumps down
from the ottoman to the floor,

00:09:09.980 --> 00:09:12.650
or it jumps up on the
table-- just a little bit

00:09:12.650 --> 00:09:17.340
of playfulness-- so easy enough.

00:09:17.340 --> 00:09:20.780
All right, we've got a couple
of things going on here

00:09:20.780 --> 00:09:22.590
that we need to cover first.

00:09:22.590 --> 00:09:24.510
We've got the camera feed.

00:09:24.510 --> 00:09:29.020
So the camera is the 2D
projection of the 3D world

00:09:29.020 --> 00:09:33.570
onto an image plane, as
seen through the lens.

00:09:33.570 --> 00:09:37.750
And it comes in at 30 frames
a second on Tango devices.

00:09:37.750 --> 00:09:39.970
So as I move my camera
around the world,

00:09:39.970 --> 00:09:45.520
I might get a different view
of sofa, of the fireplace,

00:09:45.520 --> 00:09:47.570
of the TV and the table.

00:09:47.570 --> 00:09:52.650
And that 3D view is compressed
onto this 2D image plane,

00:09:52.650 --> 00:09:54.520
and it's in color.

00:09:54.520 --> 00:09:57.280
And in the real world when
you're walking around,

00:09:57.280 --> 00:09:59.900
you don't have to worry about
much beyond this, right?

00:09:59.900 --> 00:10:01.040
Physics takes care of it.

00:10:01.040 --> 00:10:02.990
Physics is awesome.

00:10:02.990 --> 00:10:05.590
And the light comes
in, and you just get

00:10:05.590 --> 00:10:09.110
different perspectives,
based on how you walk around.

00:10:09.110 --> 00:10:13.420
But now we're talking about
compositing a virtual character

00:10:13.420 --> 00:10:16.590
into this physical scene,
and it gets a little bit more

00:10:16.590 --> 00:10:17.740
complicated.

00:10:17.740 --> 00:10:21.850
The cat doesn't actually
exist in the real world.

00:10:21.850 --> 00:10:25.390
So to understand how we
render this cat as if it's

00:10:25.390 --> 00:10:28.530
in the real world, let's forget
about the real world entirely

00:10:28.530 --> 00:10:31.640
for just a moment and
explore this problem.

00:10:31.640 --> 00:10:35.620
So say, instead of in the real
world, we've got a virtual cat,

00:10:35.620 --> 00:10:38.890
and we want to render it on
the screen of our device.

00:10:38.890 --> 00:10:41.450
We want to place it
approximately two meters

00:10:41.450 --> 00:10:44.850
in front of the device
and hold it fixed

00:10:44.850 --> 00:10:47.230
and just move around it.

00:10:47.230 --> 00:10:49.750
For those who are familiar
with building 3D games,

00:10:49.750 --> 00:10:52.290
this is very, very
similar to how

00:10:52.290 --> 00:10:56.150
a camera system in a standard
rendering engine works.

00:10:56.150 --> 00:10:59.570
We're going to place our object
in a coordinate frame, called

00:10:59.570 --> 00:11:02.450
the world frame, of the
game, and then we're

00:11:02.450 --> 00:11:05.750
going to render it relative
to the frame of our camera

00:11:05.750 --> 00:11:07.035
as it moves around it.

00:11:07.035 --> 00:11:10.190
And at the start, we'll
view the cat from the left,

00:11:10.190 --> 00:11:12.240
and at the end of our
motion around the cat,

00:11:12.240 --> 00:11:14.550
we'd like to see
it from the right.

00:11:14.550 --> 00:11:18.200
And it always stays fixed.

00:11:18.200 --> 00:11:23.640
So with Tango, this is
exactly what we'll do.

00:11:23.640 --> 00:11:26.940
It's just that instead of
programmatically setting

00:11:26.940 --> 00:11:31.440
the transform of the camera
as it moves in the world,

00:11:31.440 --> 00:11:35.410
we're going to get it from
the Tango device itself.

00:11:35.410 --> 00:11:37.570
Tango has a couple
of coordinate frames

00:11:37.570 --> 00:11:39.670
I'll talk about that
are relevant for this.

00:11:39.670 --> 00:11:43.050
So the world frame for
Tango is represented

00:11:43.050 --> 00:11:45.540
as start of service,
and it's wherever

00:11:45.540 --> 00:11:47.390
you started with the device.

00:11:47.390 --> 00:11:51.370
And the device frame is
wherever you currently

00:11:51.370 --> 00:11:53.130
are with the device.

00:11:53.130 --> 00:11:57.200
So if I start here, that
defines start of service.

00:11:57.200 --> 00:12:00.990
And if I ask for the transform,
between start of service

00:12:00.990 --> 00:12:03.440
and device, when
device is here, it

00:12:03.440 --> 00:12:06.330
will give me sort of two meters.

00:12:06.330 --> 00:12:10.020
OK, so now to show
this a little bit

00:12:10.020 --> 00:12:14.208
I'm going to give a demo of
what this looks like in action.

00:12:18.505 --> 00:12:19.005
OK.

00:12:24.300 --> 00:12:28.880
So here I've got a
completely virtual world,

00:12:28.880 --> 00:12:30.050
and I've got this ca.

00:12:30.050 --> 00:12:32.420
We'll call him Mittens, I guess.

00:12:32.420 --> 00:12:36.830
And as I move around
Mittens, he stays

00:12:36.830 --> 00:12:39.880
fixed in the virtual world.

00:12:39.880 --> 00:12:43.200
But he's not tied to my
physical space in any way.

00:12:43.200 --> 00:12:45.130
I can make him
walk, but it's just

00:12:45.130 --> 00:12:48.180
on a plane that exists in space.

00:12:48.180 --> 00:12:52.468
And he can also paw on the
camera when I get close to him.

00:12:52.468 --> 00:12:55.720
[APPLAUSE]

00:12:55.720 --> 00:12:57.320
It gets better.

00:12:57.320 --> 00:12:59.030
I promise.

00:12:59.030 --> 00:13:00.540
All right, we'll go back.

00:13:08.020 --> 00:13:10.130
To make this a
little more concrete,

00:13:10.130 --> 00:13:12.520
I want to just show
the calls that you

00:13:12.520 --> 00:13:16.640
need to make in our APIs
to be able to do this.

00:13:16.640 --> 00:13:20.800
So Tango provides a function
called getPoseAtTime,

00:13:20.800 --> 00:13:24.650
and you can pass it the base
coordinate frame that you would

00:13:24.650 --> 00:13:27.550
like, as well as the target
coordinate frame that you would

00:13:27.550 --> 00:13:30.800
like, and it will
return you the transform

00:13:30.800 --> 00:13:32.740
at that point in time.

00:13:32.740 --> 00:13:36.840
So here you can see I'm
defining a frame pair, where

00:13:36.840 --> 00:13:40.980
I want to ask where is the
device, relative to the start

00:13:40.980 --> 00:13:41.480
of service?

00:13:41.480 --> 00:13:44.250
So my base frame is
start of service,

00:13:44.250 --> 00:13:47.850
and my target frame
is device, and I say

00:13:47.850 --> 00:13:53.750
get me the transform at time
T, where maybe time is now.

00:13:53.750 --> 00:13:56.310
And that timestamp
actually turns out

00:13:56.310 --> 00:13:58.260
to be really
important when you're

00:13:58.260 --> 00:14:01.610
trying to do things like
composites onto an image,

00:14:01.610 --> 00:14:04.560
because the camera
takes an image at a very

00:14:04.560 --> 00:14:06.364
particular point in time.

00:14:06.364 --> 00:14:07.780
And so that's
something that we'll

00:14:07.780 --> 00:14:10.630
be coming back to to
make sure that the cat is

00:14:10.630 --> 00:14:12.470
well registered
with the environment

00:14:12.470 --> 00:14:14.170
when we go to composite it.

00:14:14.170 --> 00:14:16.070
But overall, this is
pretty simple, right?

00:14:16.070 --> 00:14:18.830
You can just at any
time ask for where

00:14:18.830 --> 00:14:21.050
the device is in the world.

00:14:21.050 --> 00:14:25.152
And boom, you know, you've
got a handheld AR cat viewer.

00:14:25.152 --> 00:14:28.320
All right, so it's not exactly
what we're looking for, though.

00:14:28.320 --> 00:14:32.630
The goal, again, is to place
the virtual cat on the ottoman

00:14:32.630 --> 00:14:35.250
in the physical world.

00:14:35.250 --> 00:14:37.540
And the first thing you
might think of doing

00:14:37.540 --> 00:14:40.110
is just taking the RGB
image, and we're just

00:14:40.110 --> 00:14:43.107
going to slap the cat
onto the RGB image.

00:14:43.107 --> 00:14:44.190
And it's going to be fine.

00:14:44.190 --> 00:14:47.140
We'll just use that
as a background.

00:14:47.140 --> 00:14:50.300
But it's not going
to look quite right.

00:14:50.300 --> 00:14:53.330
This slide demonstrates
it, but I'll go to a demo,

00:14:53.330 --> 00:14:55.458
again, just to make it
a little more clear.

00:15:03.000 --> 00:15:03.500
All right.

00:15:03.500 --> 00:15:09.780
So now we've got Mittens, but
he's not looking super awesome.

00:15:09.780 --> 00:15:13.180
He's just floating in
space in front of me.

00:15:13.180 --> 00:15:20.350
And here, I really would
rather he be on the ground.

00:15:20.350 --> 00:15:22.980
So that's what we're
going to work to do.

00:15:22.980 --> 00:15:25.850
But if you were to build
an application like, say,

00:15:25.850 --> 00:15:28.810
a sun with planets
orbiting around it,

00:15:28.810 --> 00:15:31.090
this could be an
appropriate visualization.

00:15:31.090 --> 00:15:34.200
But for Mittens, it's
really just all wrong.

00:15:34.200 --> 00:15:38.090
So we'll go back to
our slides, and we'll

00:15:38.090 --> 00:15:40.880
see that it is
really, really wrong.

00:15:44.550 --> 00:15:49.270
I really I hadn't looked at that
image in a while, so I like it.

00:15:49.270 --> 00:15:51.160
All right, so what
can we do to fix this?

00:15:51.160 --> 00:15:53.460
Well, there are a couple
of things that we can try.

00:15:53.460 --> 00:15:55.280
Before we go down this
road, though, it's

00:15:55.280 --> 00:15:59.130
worth mentioning again that
perfect augmented reality is

00:15:59.130 --> 00:16:01.134
largely an unsolved problem.

00:16:01.134 --> 00:16:02.800
So we're going to
talk about some things

00:16:02.800 --> 00:16:05.730
to make the cat look better, but
it's not going to be perfect.

00:16:05.730 --> 00:16:07.400
I've learned to
manage expectations,

00:16:07.400 --> 00:16:10.680
so you'll see me doing
this throughout the talk.

00:16:10.680 --> 00:16:13.250
But we're going to
get better, and we'll

00:16:13.250 --> 00:16:16.220
talk about the limitations
in detail at the end.

00:16:20.580 --> 00:16:21.080
OK.

00:16:21.080 --> 00:16:24.190
So with that public service
announcement out of the way,

00:16:24.190 --> 00:16:27.260
how far down the road
can we go with Tango?

00:16:27.260 --> 00:16:31.120
Step one is that we can tie the
cat into the environment using

00:16:31.120 --> 00:16:33.460
Tango's depth-sensing APIs.

00:16:33.460 --> 00:16:35.790
So I mentioned before that
the device doesn't just

00:16:35.790 --> 00:16:38.160
understand its
position in space,

00:16:38.160 --> 00:16:41.000
it also understands the
geometry of the environment.

00:16:41.000 --> 00:16:43.490
So maybe we can use
the Tango device

00:16:43.490 --> 00:16:46.540
to actually decide
where to place the cat,

00:16:46.540 --> 00:16:49.210
to recognize surfaces
in the environments,

00:16:49.210 --> 00:16:52.860
and then we can tie it to
the floor at the correct size

00:16:52.860 --> 00:16:54.770
and scale.

00:16:54.770 --> 00:16:58.740
And Tango provides
exactly these capabilities

00:16:58.740 --> 00:17:01.210
through our support
libraries to developers.

00:17:01.210 --> 00:17:05.150
You can essentially ask for
a given pixel in an image,

00:17:05.150 --> 00:17:11.060
give me the point and normal in
the world frame of that pixel.

00:17:11.060 --> 00:17:12.770
And then we can
place the cat there.

00:17:17.240 --> 00:17:21.069
And to show this,
you can see that this

00:17:21.069 --> 00:17:28.630
is the code needed to compute
the points and normal in space.

00:17:28.630 --> 00:17:31.880
So the first thing
that we do, is

00:17:31.880 --> 00:17:39.080
we need to get the relative pose
of the depth to the RGB image.

00:17:39.080 --> 00:17:42.650
And this is a little bit subtle,
so as you're walking around,

00:17:42.650 --> 00:17:44.920
we're taking RGB
images all the time,

00:17:44.920 --> 00:17:47.220
but we're also firing
the depth camera.

00:17:47.220 --> 00:17:50.160
But they're not actually
taken at the exact same time.

00:17:50.160 --> 00:17:52.320
There's a little bit
of an offset there.

00:17:52.320 --> 00:17:55.820
So if I naively
took the point cloud

00:17:55.820 --> 00:17:58.400
at the timestamp
of the RGB camera

00:17:58.400 --> 00:18:01.860
and just selected a point,
it would be off a little bit.

00:18:01.860 --> 00:18:03.300
It wouldn't look correct.

00:18:03.300 --> 00:18:06.350
And what I need to do
is actually transform

00:18:06.350 --> 00:18:10.240
the depth information into
the frame of the RGB camera.

00:18:10.240 --> 00:18:12.800
So here what you can see
is we're calling a support

00:18:12.800 --> 00:18:15.850
function that says
calculate the relative pose

00:18:15.850 --> 00:18:19.260
between the color camera
and the depth camera

00:18:19.260 --> 00:18:22.630
at the last time I had a
color image and the last time

00:18:22.630 --> 00:18:24.520
I had a point cloud.

00:18:24.520 --> 00:18:28.910
And then from there, we
call fitPlaneModelNearClick,

00:18:28.910 --> 00:18:30.780
and we pass in the point cloud.

00:18:30.780 --> 00:18:32.840
We pass in the
color image, and we

00:18:32.840 --> 00:18:35.950
pass in the relative
transform between the two,

00:18:35.950 --> 00:18:38.260
which helps us do
that alignment.

00:18:38.260 --> 00:18:42.530
And then we get back a
point and a plane model

00:18:42.530 --> 00:18:44.780
for that pixel in the image.

00:18:48.710 --> 00:18:52.440
And after this call, we've
got a point and a normal

00:18:52.440 --> 00:18:56.700
that we can use to place the
cat on the correct surface

00:18:56.700 --> 00:18:57.950
in the environment.

00:18:57.950 --> 00:19:00.350
And we can put it
in the real world.

00:19:00.350 --> 00:19:03.230
So I'm going to show
a demo of that now.

00:19:14.850 --> 00:19:18.880
So here you'll see that
Mittens is actually

00:19:18.880 --> 00:19:21.090
looking pretty good.

00:19:21.090 --> 00:19:23.740
He can move around the world.

00:19:23.740 --> 00:19:28.410
And every time I tap, I'm
getting that detection.

00:19:28.410 --> 00:19:33.740
And you can see that I can
make Mittens sort of interact

00:19:33.740 --> 00:19:36.676
with the surfaces and the
geometry of the environment.

00:19:36.676 --> 00:19:39.120
[APPLAUSE]

00:19:40.740 --> 00:19:43.290
OK, we'll still get cooler.

00:19:43.290 --> 00:19:45.130
I like the enthusiasm, though.

00:19:45.130 --> 00:19:47.550
It's sort of building over time.

00:19:47.550 --> 00:19:51.120
So I can have Mittens
jump on this, as well.

00:19:51.120 --> 00:19:53.380
And he can jump down.

00:19:53.380 --> 00:19:58.190
And if we like, we can also
change Mittens to Rufus.

00:19:58.190 --> 00:20:00.094
All right, so let's
go back to the slides.

00:20:03.680 --> 00:20:07.020
OK, so we're getting better.

00:20:07.020 --> 00:20:08.790
But you'll notice
that I didn't have

00:20:08.790 --> 00:20:11.730
the cat go behind anything.

00:20:11.730 --> 00:20:13.310
And the reason I
didn't do that is

00:20:13.310 --> 00:20:19.290
because we don't have support
in that demo for occlusion.

00:20:19.290 --> 00:20:21.850
What that means is if
I had placed Mittens

00:20:21.850 --> 00:20:25.540
behind the podium and
looked at it from kind

00:20:25.540 --> 00:20:29.050
of the incorrect angle, I would
have seen through the podium,

00:20:29.050 --> 00:20:33.070
and Mittens wouldn't have
rendered realistically.

00:20:33.070 --> 00:20:37.040
And so, what can
we do along the way

00:20:37.040 --> 00:20:40.220
to maybe do more about
understanding our scene

00:20:40.220 --> 00:20:42.340
and our geometry and
our environments,

00:20:42.340 --> 00:20:46.600
to make Mittens look even
better and even more realistic?

00:20:46.600 --> 00:20:50.790
Well, Tango can create
rough 3D reconstructions

00:20:50.790 --> 00:20:52.800
of the world environment.

00:20:52.800 --> 00:20:54.920
And it provides developers
with these meshes

00:20:54.920 --> 00:20:58.020
in real time, which is
really-- it's kind of crazy

00:20:58.020 --> 00:20:59.870
when you think about it.

00:20:59.870 --> 00:21:05.400
And perhaps we can use these
meshes to help a little bit

00:21:05.400 --> 00:21:07.060
with our occlusion problem.

00:21:07.060 --> 00:21:09.880
So now, instead of
using a single point

00:21:09.880 --> 00:21:11.740
to determine how
to render the cat,

00:21:11.740 --> 00:21:14.630
and to have Mittens jump
from the table to the chair

00:21:14.630 --> 00:21:18.580
to the floor, we can use
the full 3D structure

00:21:18.580 --> 00:21:23.070
of the environment and
aggregate many points over time.

00:21:23.070 --> 00:21:24.900
So under the hood,
when Tango is meshing,

00:21:24.900 --> 00:21:28.360
it's actually taking many,
many different viewpoints,

00:21:28.360 --> 00:21:30.420
doing sort of that
same transform I talked

00:21:30.420 --> 00:21:34.040
about to get the point
cloud into the world frame,

00:21:34.040 --> 00:21:39.160
and binning them over time,
and creating a representation

00:21:39.160 --> 00:21:41.910
of this surface that gets
better, actually, the more

00:21:41.910 --> 00:21:43.620
that you look at a
surface because you

00:21:43.620 --> 00:21:49.740
get more points of data and a
better accurate of the surface.

00:21:49.740 --> 00:21:55.120
And this process
is pretty complex.

00:21:55.120 --> 00:21:59.100
But it is, again, abstracted
for us by the SDK.

00:21:59.100 --> 00:22:02.510
And we've got a meshing library
that you can use in C++,

00:22:02.510 --> 00:22:06.890
or we've hooked it up directly
to Unity, for Unity developers,

00:22:06.890 --> 00:22:10.140
that gives you the mesh inside
the game engine in real time.

00:22:10.140 --> 00:22:13.290
And that makes it really easy
to use it in our depth buffer

00:22:13.290 --> 00:22:14.560
as we render.

00:22:14.560 --> 00:22:17.706
So to see this, we're going
to check out another demo.

00:22:26.850 --> 00:22:29.980
All right, so we'll put
Mittens over here for now.

00:22:29.980 --> 00:22:35.090
So you can see that as I
move around the podium,

00:22:35.090 --> 00:22:41.490
I'm starting to build
up a rough mesh of it.

00:22:41.490 --> 00:22:43.660
That's probably
good enough for now.

00:22:43.660 --> 00:22:47.480
And we'll put Mittens
in the background.

00:22:47.480 --> 00:22:54.560
And as I move, you can
see he becomes occluded.

00:22:54.560 --> 00:22:59.390
And we think that this is
a really powerful thing

00:22:59.390 --> 00:23:02.490
for building AR applications.

00:23:02.490 --> 00:23:04.311
We can sort of bring him out.

00:23:04.311 --> 00:23:06.155
[APPLAUSE]

00:23:08.000 --> 00:23:12.340
So one thing that you'll notice
is that the mesh isn't perfect.

00:23:12.340 --> 00:23:13.950
And so we'll play some tricks.

00:23:13.950 --> 00:23:17.140
Like, we actually alpha
blend on the edge of Mittens

00:23:17.140 --> 00:23:18.400
as he goes behind.

00:23:18.400 --> 00:23:21.810
And here, we've even shown
you his silhouette when

00:23:21.810 --> 00:23:24.110
he's behind the
podium, to give you

00:23:24.110 --> 00:23:26.370
a sense that he's still there.

00:23:26.370 --> 00:23:30.040
I'm going to show another
version right now that

00:23:30.040 --> 00:23:32.830
does a similar
thing, but it's not

00:23:32.830 --> 00:23:35.730
going to show the silhouettes.

00:23:35.730 --> 00:23:39.240
So Mittens will
be fully occluded,

00:23:39.240 --> 00:23:42.710
and you'll get to see
how that looks as well.

00:23:42.710 --> 00:23:44.808
Should've saved my mesh.

00:23:48.060 --> 00:23:50.170
So probably good enough.

00:23:50.170 --> 00:23:53.560
All right, so now we'll
put Mittens behind again,

00:23:53.560 --> 00:24:00.100
and you can see as I go, he
kind of pops out over time.

00:24:00.100 --> 00:24:02.610
And there's alpha
blending on the edges

00:24:02.610 --> 00:24:06.210
that we're using to sort of
make him fade in and out.

00:24:06.210 --> 00:24:12.820
So it's not perfect, but
it does give the illusion

00:24:12.820 --> 00:24:16.790
of a more real experience.

00:24:16.790 --> 00:24:18.460
All right, let's go
back to the slides.

00:24:25.610 --> 00:24:28.440
So at this point,
we've actually created

00:24:28.440 --> 00:24:31.540
a pretty compelling augmented
reality application,

00:24:31.540 --> 00:24:33.470
I would say.

00:24:33.470 --> 00:24:35.162
We've taken Mittens.

00:24:35.162 --> 00:24:37.060
We've placed him in the world.

00:24:37.060 --> 00:24:38.640
He can walk on surfaces.

00:24:38.640 --> 00:24:40.300
He can jump on chairs.

00:24:40.300 --> 00:24:42.140
And now he can
actually be occluded

00:24:42.140 --> 00:24:43.800
by objects in the scene.

00:24:43.800 --> 00:24:45.540
So you've got a lot
of the components

00:24:45.540 --> 00:24:48.880
of making a compelling augmented
reality experience right

00:24:48.880 --> 00:24:51.180
there in front of you.

00:24:51.180 --> 00:24:53.780
But it can be a lot better.

00:24:53.780 --> 00:24:55.290
And one thing I'll
say-- have you

00:24:55.290 --> 00:24:59.806
guys noticed anything weird
about this picture up here?

00:24:59.806 --> 00:25:04.390
Does something look
fake to you, maybe--

00:25:04.390 --> 00:25:09.520
yeah, people are nodding,
audience participation.

00:25:09.520 --> 00:25:11.470
The Lamborghini's fake.

00:25:11.470 --> 00:25:12.480
It's fake.

00:25:12.480 --> 00:25:17.610
So the front one is
actually not a real car.

00:25:17.610 --> 00:25:20.120
And the reason that
this looks so good

00:25:20.120 --> 00:25:23.180
is that we're doing
a lot in terms

00:25:23.180 --> 00:25:25.850
of lighting and reflection.

00:25:25.850 --> 00:25:27.850
We've placed it
exactly where we want.

00:25:27.850 --> 00:25:30.280
We've done very detailed
compositing of it.

00:25:30.280 --> 00:25:32.650
And this is kind of like
the holy grail, right?

00:25:32.650 --> 00:25:35.290
This is the holy grail of AR.

00:25:35.290 --> 00:25:39.080
And this slide is really just
to say that this is a journey.

00:25:39.080 --> 00:25:43.150
And we're moving along this
path, moving towards things

00:25:43.150 --> 00:25:45.800
that we hope someday
can look like this.

00:25:45.800 --> 00:25:48.910
But this is not, I
guess, the expectation

00:25:48.910 --> 00:25:51.030
to have today for where we are.

00:25:55.110 --> 00:25:57.630
And as an application
developer, it's

00:25:57.630 --> 00:26:00.250
important to remember that.

00:26:00.250 --> 00:26:03.890
So if you're building something,
you want to ask yourself,

00:26:03.890 --> 00:26:07.910
is it appropriate for the
technology that I have at hand?

00:26:07.910 --> 00:26:09.890
And everything
from the art assets

00:26:09.890 --> 00:26:13.980
that you use to the
gameplay that you design

00:26:13.980 --> 00:26:21.300
can help to set
expectations for your users.

00:26:21.300 --> 00:26:25.020
And you can still make
really compelling experiences

00:26:25.020 --> 00:26:29.090
that use maybe a subset
of the technology as well.

00:26:29.090 --> 00:26:33.580
So you could put a
solar system in space.

00:26:33.580 --> 00:26:38.110
You could have your cat walk
on planes but not be occluded.

00:26:38.110 --> 00:26:41.790
Or you could have objects
in games that take advantage

00:26:41.790 --> 00:26:43.330
of the scene geometry.

00:26:43.330 --> 00:26:46.110
But all of them are compelling
in their own rights.

00:26:46.110 --> 00:26:48.170
And with a little
bit of creativity,

00:26:48.170 --> 00:26:49.900
you can actually
make experiences

00:26:49.900 --> 00:26:52.540
that feel really good to people,
even if you're not leveraging

00:26:52.540 --> 00:26:55.110
the full capabilities
of AR, and even

00:26:55.110 --> 00:26:58.330
if you don't get to the holy
grail of Lamborghini rendering.

00:27:02.470 --> 00:27:04.100
And to illustrate
this I guess I'll

00:27:04.100 --> 00:27:07.630
provide two examples of
augmented reality applications

00:27:07.630 --> 00:27:12.210
that I really like that
don't even use depth.

00:27:12.210 --> 00:27:15.130
So the first one I've been
alluding to for a while.

00:27:15.130 --> 00:27:17.010
This was done by
some of our friends

00:27:17.010 --> 00:27:19.240
at San Francisco
State University,

00:27:19.240 --> 00:27:23.130
and it allows you to explore the
solar system by placing planets

00:27:23.130 --> 00:27:24.590
in a line in your room.

00:27:24.590 --> 00:27:26.310
And I'll show a
demo of that now.

00:27:41.490 --> 00:27:47.320
All right, so here I'm going
to tap to place the sun.

00:27:47.320 --> 00:27:50.940
And now I'm going to walk.

00:27:50.940 --> 00:27:53.900
And I guess it recommends
I go further than this,

00:27:53.900 --> 00:27:57.420
but this is about
as far as I get.

00:27:57.420 --> 00:27:59.620
And I'll tap to place Neptune.

00:27:59.620 --> 00:28:03.320
So now as I walk
back towards the sun,

00:28:03.320 --> 00:28:09.680
I can see the scale of the
planets relative to each other.

00:28:09.680 --> 00:28:12.390
And it's actually
correct, and I can

00:28:12.390 --> 00:28:16.790
zoom into each one of the
planets, and if I want,

00:28:16.790 --> 00:28:21.600
I can start to see
how orbits work.

00:28:21.600 --> 00:28:25.180
And as an educational
tool, this is spectacular.

00:28:25.180 --> 00:28:27.600
And from an augmented
reality perspective,

00:28:27.600 --> 00:28:29.770
it's actually remarkably simple.

00:28:29.770 --> 00:28:33.800
I mean, this is the floating cat
that we all laughed at before.

00:28:33.800 --> 00:28:35.964
But for the appropriate
application,

00:28:35.964 --> 00:28:37.255
it's actually quite compelling.

00:28:41.270 --> 00:28:43.420
We'll go back to the
slides for a second.

00:28:47.670 --> 00:28:49.890
The second application
I want to talk about

00:28:49.890 --> 00:28:54.810
is a game from our
friends at Trixi Studios,

00:28:54.810 --> 00:28:56.380
and it's called "Phantogeist."

00:28:56.380 --> 00:28:59.800
And how many of you actually
went to our after hours event

00:28:59.800 --> 00:29:01.881
and got to play "Phantogeist?"

00:29:01.881 --> 00:29:05.460
Oh, that is way too few of you.

00:29:05.460 --> 00:29:09.060
All right, so
"Phantogeist" is a game,

00:29:09.060 --> 00:29:12.870
and the premise is that aliens
have invaded your world,

00:29:12.870 --> 00:29:16.180
and you need to zap them before
they take over the world.

00:29:16.180 --> 00:29:19.250
And it's not good
for us at the end.

00:29:19.250 --> 00:29:22.637
But anyway, there are a bunch
of design considerations

00:29:22.637 --> 00:29:24.470
that went into this
game that I really like.

00:29:24.470 --> 00:29:27.470
So the characters are
actually semi transparent.

00:29:27.470 --> 00:29:30.300
They feel like they're
coming out of the wall.

00:29:30.300 --> 00:29:33.080
And they're very
clever about using

00:29:33.080 --> 00:29:35.670
the position of the device
and making assumptions

00:29:35.670 --> 00:29:41.630
about free space to
interact with the world,

00:29:41.630 --> 00:29:44.970
even though they don't
know where surfaces are.

00:29:44.970 --> 00:29:49.320
And I'll show a brief
demo of this, actually.

00:29:49.320 --> 00:29:52.080
So I'm going to go
to bonus content.

00:29:55.700 --> 00:29:59.270
And we'll do a giant worm thing.

00:29:59.270 --> 00:30:01.840
All right, so you
can tell they're

00:30:01.840 --> 00:30:04.060
already setting the
mood with the music

00:30:04.060 --> 00:30:06.120
that they have for this.

00:30:06.120 --> 00:30:10.570
And what happens is,
as I start, the device

00:30:10.570 --> 00:30:13.380
records my position in space.

00:30:13.380 --> 00:30:16.310
Can we turn down the lights?

00:30:16.310 --> 00:30:17.330
Awesome.

00:30:17.330 --> 00:30:20.350
So we'll get a
brief text message

00:30:20.350 --> 00:30:22.800
that says something
like the aliens

00:30:22.800 --> 00:30:26.560
will get you, or clear the area.

00:30:26.560 --> 00:30:33.460
And so as I move, you'll see
something strange happens.

00:30:33.460 --> 00:30:35.960
[ALARM]

00:30:47.200 --> 00:30:51.340
So here we've ripped a
hole in the actual floor.

00:30:51.340 --> 00:30:53.180
And we can see into-- whoa.

00:31:13.802 --> 00:31:14.911
All right, we're safe.

00:31:18.210 --> 00:31:21.450
So if we switch back to
the slides, real quick.

00:31:27.540 --> 00:31:29.920
I think it's pretty cool.

00:31:29.920 --> 00:31:35.250
All right, so everything that
you saw there used only motion

00:31:35.250 --> 00:31:36.520
tracking.

00:31:36.520 --> 00:31:39.160
There was no depth.

00:31:39.160 --> 00:31:40.910
There was no occlusion.

00:31:40.910 --> 00:31:42.340
And it's kind of shocking.

00:31:42.340 --> 00:31:45.000
I'm actually impressed with
how well they pulled it off,

00:31:45.000 --> 00:31:46.520
but they're playing tricks.

00:31:46.520 --> 00:31:50.140
They're making some assumptions
and building gameplay that

00:31:50.140 --> 00:31:52.460
just works for the environment.

00:31:52.460 --> 00:31:55.930
And so really this
is to say that there

00:31:55.930 --> 00:31:58.890
are ways in gameplay
to make things

00:31:58.890 --> 00:32:02.440
feel real and immersive, even
with our most basic APIs.

00:32:02.440 --> 00:32:07.880
And as you start to move down
the road, it gets better.

00:32:07.880 --> 00:32:09.430
And with all that
said, I've said

00:32:09.430 --> 00:32:13.050
a lot of managing
expectations type stuff,

00:32:13.050 --> 00:32:15.140
but we're continuing to improve.

00:32:15.140 --> 00:32:17.550
We're always working
on new things.

00:32:17.550 --> 00:32:25.530
And in fact, we're rolling
out some drift correction code

00:32:25.530 --> 00:32:28.160
into our SDKs over the
next couple months.

00:32:28.160 --> 00:32:31.570
So Wim talked about this
before, but another problem

00:32:31.570 --> 00:32:33.160
that you have with
augmented reality

00:32:33.160 --> 00:32:37.860
is that when I place the cat
in the world-- actually, let's

00:32:37.860 --> 00:32:40.470
switch back to the
demo, just real quick.

00:32:40.470 --> 00:32:41.806
I think it's easy to show.

00:32:51.420 --> 00:32:54.330
So you can see that the
cat is on a surface.

00:32:54.330 --> 00:32:59.180
It's relatively robust when
I move the device around

00:32:59.180 --> 00:33:00.940
because our tracking
is relatively good.

00:33:00.940 --> 00:33:06.950
But if I'm really mean,
the cat is gone, right?

00:33:06.950 --> 00:33:08.750
It drifted off into space.

00:33:08.750 --> 00:33:10.234
So we can go back to the slides.

00:33:14.140 --> 00:33:17.270
So we've actually
built software that

00:33:17.270 --> 00:33:19.530
allows us to correct for that.

00:33:19.530 --> 00:33:22.500
And so when the cat goes
drifting off into space,

00:33:22.500 --> 00:33:24.140
we recover very, very quickly.

00:33:24.140 --> 00:33:27.800
It takes about a second, but
you stop, look at the world,

00:33:27.800 --> 00:33:30.180
and the cat shows up back
in the correct place.

00:33:30.180 --> 00:33:32.190
And this is really just
one of the improvements

00:33:32.190 --> 00:33:34.330
that we're working to
roll out and that we're

00:33:34.330 --> 00:33:36.860
working to bring to you,
our developer community.

00:33:36.860 --> 00:33:38.710
We're working on
things like modeling

00:33:38.710 --> 00:33:42.620
the lighting in the room to give
you realistic shadows, things

00:33:42.620 --> 00:33:46.200
like improving our meshing
and doing texturing as well,

00:33:46.200 --> 00:33:50.210
to give realistic textured
meshes inside of Unity

00:33:50.210 --> 00:33:52.170
that maybe you could
use in other games

00:33:52.170 --> 00:33:54.720
and even import them into
different game worlds.

00:33:54.720 --> 00:33:58.950
We're just kind of taking steps
along this journey to getting

00:33:58.950 --> 00:34:01.240
to that Lamborghini,
to getting to really,

00:34:01.240 --> 00:34:04.780
really good and immersive
and solid augmented reality.

00:34:04.780 --> 00:34:06.500
But we don't have to wait.

00:34:06.500 --> 00:34:09.630
We can already do
a lot right now

00:34:09.630 --> 00:34:12.850
and build compelling
experiences today.

00:34:12.850 --> 00:34:17.570
I also want to talk a little
bit about the tradeoffs

00:34:17.570 --> 00:34:19.159
that you make as you
start to use more

00:34:19.159 --> 00:34:21.870
and more of this technology.

00:34:21.870 --> 00:34:24.690
So heat is your enemy
on a mobile device.

00:34:24.690 --> 00:34:27.030
If any of you have used
a mobile phone before,

00:34:27.030 --> 00:34:29.150
you know it gets hot.

00:34:29.150 --> 00:34:30.370
It's hot in your pocket.

00:34:30.370 --> 00:34:34.920
You're using Google Maps,
and it's just burning up.

00:34:34.920 --> 00:34:38.909
And it is a very real tradeoff.

00:34:38.909 --> 00:34:43.139
So we've worked hard to
optimize our algorithms,

00:34:43.139 --> 00:34:45.969
to optimize our computer
vision software,

00:34:45.969 --> 00:34:50.330
and to make it run as quickly
and efficiently as possible.

00:34:50.330 --> 00:34:52.730
But the more
capabilities you use,

00:34:52.730 --> 00:34:56.760
the more heat and CPU and
compute you use, as well.

00:34:56.760 --> 00:35:00.300
So if you can make an experience
work with motion tracking,

00:35:00.300 --> 00:35:04.490
then you have a lot more that
you can throw at your game.

00:35:04.490 --> 00:35:06.910
But if you go all the
way to full meshing,

00:35:06.910 --> 00:35:10.450
maybe you should be using
some low poly models.

00:35:10.450 --> 00:35:13.100
And it's just important to
be aware of the tradeoffs

00:35:13.100 --> 00:35:15.920
that you make when you
think about the applications

00:35:15.920 --> 00:35:16.820
that you could build.

00:35:21.120 --> 00:35:26.530
If I could sum up my talk
with one cheesy statement,

00:35:26.530 --> 00:35:30.650
I would do it with
"creativity is king."

00:35:30.650 --> 00:35:33.300
When you're developing
for a new platform,

00:35:33.300 --> 00:35:35.100
there are limitations.

00:35:35.100 --> 00:35:37.450
And we're super fortunate to
have partnered with people

00:35:37.450 --> 00:35:39.720
who can be creative,
and who have

00:35:39.720 --> 00:35:42.960
worked around the
different capabilities

00:35:42.960 --> 00:35:46.640
and technologies of the device,
as well as their limitations.

00:35:46.640 --> 00:35:48.640
And we're really looking
forward to seeing

00:35:48.640 --> 00:35:50.090
what kind of
creative applications

00:35:50.090 --> 00:35:53.660
can be enabled by what is
super powerful technology

00:35:53.660 --> 00:35:54.882
over the coming months.

00:35:57.440 --> 00:36:00.170
There's a bunch that
you should check out

00:36:00.170 --> 00:36:03.600
at our sandbox to get a picture
of what developers are up to.

00:36:03.600 --> 00:36:06.229
If you haven't done that,
I really encourage it.

00:36:06.229 --> 00:36:08.020
And there are a couple
of things that we've

00:36:08.020 --> 00:36:10.380
done that are really exciting
at the platform level,

00:36:10.380 --> 00:36:12.900
too, looking forward.

00:36:12.900 --> 00:36:16.150
So first, we believe that
Project Tango technology

00:36:16.150 --> 00:36:17.490
should become ubiquitous.

00:36:17.490 --> 00:36:19.210
All devices should
have the ability

00:36:19.210 --> 00:36:21.240
to understand where
they are in space

00:36:21.240 --> 00:36:24.010
and to understand the
geometry of their environment.

00:36:24.010 --> 00:36:26.720
And one thing that we've
done is we've worked closely

00:36:26.720 --> 00:36:29.270
with our friends
at the Android team

00:36:29.270 --> 00:36:33.120
to start moving some of
Tango's APIs into core Android.

00:36:33.120 --> 00:36:35.120
And so in Android
N, you can actually

00:36:35.120 --> 00:36:38.140
ask for the six
degree-of-freedom pose

00:36:38.140 --> 00:36:40.450
of the device
through Android APIs.

00:36:40.450 --> 00:36:43.440
And Android N also
supports depth sensors.

00:36:43.440 --> 00:36:46.730
And over time we hope to expose
more of Tango's capabilities

00:36:46.730 --> 00:36:49.140
in this way.

00:36:49.140 --> 00:36:52.330
And we're at the beginning of
a very, very exciting journey

00:36:52.330 --> 00:36:54.850
on the consumer front.

00:36:54.850 --> 00:36:57.880
So we have announced
a partnership

00:36:57.880 --> 00:37:01.470
with Lenovo, where we will
be shipping Project Tango

00:37:01.470 --> 00:37:04.800
smartphones later this summer.

00:37:04.800 --> 00:37:05.750
And this is huge.

00:37:05.750 --> 00:37:06.920
This is a big deal.

00:37:06.920 --> 00:37:09.460
This has been a three
year journey for us,

00:37:09.460 --> 00:37:12.620
to take this technology
from the prototype stage

00:37:12.620 --> 00:37:14.680
all the way to something
that you can actually

00:37:14.680 --> 00:37:16.280
hold in your hands.

00:37:16.280 --> 00:37:18.280
And a lot of the applications
we're showing here

00:37:18.280 --> 00:37:22.400
start to show the power of
these devices for consumers.

00:37:22.400 --> 00:37:25.990
So now is really the
time to get on board.

00:37:25.990 --> 00:37:29.410
The train is sort of leaving
the proverbial station.

00:37:29.410 --> 00:37:32.692
And I'm really excited to see
what we can build together.

00:37:32.692 --> 00:37:34.650
It's a great time to get
your foot in the door.

00:37:34.650 --> 00:37:37.150
If you haven't been thinking
about augmented reality

00:37:37.150 --> 00:37:40.210
applications, I
encourage you to do so.

00:37:40.210 --> 00:37:42.070
And it's also a
unique opportunity

00:37:42.070 --> 00:37:43.790
to partner with Google.

00:37:43.790 --> 00:37:46.960
So we're always looking
for interesting ideas.

00:37:46.960 --> 00:37:50.230
We like to feature our
partners at things like talks.

00:37:50.230 --> 00:37:53.300
And on occasion we
even put out RFPs

00:37:53.300 --> 00:37:55.906
for unique augmented
reality content.

00:37:55.906 --> 00:37:57.280
And this all
happens because it's

00:37:57.280 --> 00:37:58.910
a new and budding ecosystem.

00:37:58.910 --> 00:38:01.980
It's just an exciting time
to take the first step

00:38:01.980 --> 00:38:03.142
in this journey together.

00:38:07.480 --> 00:38:09.350
And with that, I'm
ending my talk.

00:38:09.350 --> 00:38:11.920
Hopefully this gave
you an idea of the kind

00:38:11.920 --> 00:38:15.650
of applications that are
possible with Project Tango,

00:38:15.650 --> 00:38:17.420
as well as some of
the considerations

00:38:17.420 --> 00:38:20.710
that you need to be aware
of when you're building

00:38:20.710 --> 00:38:23.180
augmented reality content.

00:38:23.180 --> 00:38:25.890
I think it's a
really exciting time.

00:38:25.890 --> 00:38:28.110
I'm really happy
to be here, feel

00:38:28.110 --> 00:38:30.130
fortunate to be on the team.

00:38:30.130 --> 00:38:33.710
Thank you guys so much for
your time this morning,

00:38:33.710 --> 00:38:36.600
and I hope you enjoy
the rest of I/O.

00:38:36.600 --> 00:38:39.950
[MUSIC PLAYING]

