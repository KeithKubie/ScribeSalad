WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.000
So let's remember the code we had at the end of unit 2 for crawling the web.

00:00:04.000 --> 00:00:09.000
So we used 2 variables. We initialized "tocrawl" to the seed, a list containing just the seed,

00:00:09.000 --> 00:00:12.000
and we're going to use "tocrawl" to keep track of the pages to crawl.

00:00:12.000 --> 00:00:19.000
We initialized "crawled" to the empty list, and we're keeping track of the pages we found using "crawled."

00:00:19.000 --> 00:00:23.000
Then we had a loop that would continue as long as there were pages left to crawl.

00:00:23.000 --> 00:00:25.000
We'd pop the last page off the "tocrawl" list.

00:00:25.000 --> 00:00:32.000
If it's not already crawled, then we'll union into "tocrawl" all the links that we can find on that page,

00:00:32.000 --> 00:00:36.000
and then we'll add that page to the list of pages we've already crawled.

00:00:36.000 --> 00:00:41.000
So now we want to figure out how to change this so instead of just finding all the URLs,

00:00:41.000 --> 00:00:42.000
we're building up our index.

00:00:42.000 --> 00:00:46.000
We're looking at the actual content of the pages, and we're adding it to our index.

00:00:46.000 --> 00:00:52.000
So the first change to make, we're updating the index, and we're going to change the return result.

00:00:52.000 --> 00:00:56.000
So instead of returning "crawled" what we want to return at the end is the index.

00:00:56.000 --> 00:01:02.000
`If we wanted to keep track of all the URLs crawled, we could still return "crawled" and return both "crawled" and "index,"

00:01:02.000 --> 00:01:05.000
but let's keep things simple and just return "index."

00:01:05.000 --> 00:01:09.000
That's what we really want for being able to respond to search queries.

00:01:09.000 --> 00:01:12.000
So now we have one other change to make, and this is the important one.

00:01:12.000 --> 00:01:19.000
We need to find a way to update the index to reflect all the words that are found on the page that we've just crawled.

00:01:19.000 --> 00:01:22.000
I'm going to make one change before we do that.

00:01:22.000 --> 00:01:28.000
Since both "get<u>all</u>links" and what we need to do to add the words to the index depend on the page,

00:01:28.000 --> 00:01:33.000
let's introduce a new variable and store the content of the page in that variable.

00:01:33.000 --> 00:01:37.000
This will save us from having to call "get_page" twice. "Get_page" is fairly expensive.

00:01:37.000 --> 00:01:40.000
It requires a web request to get the content of the page.

00:01:40.000 --> 00:01:45.000
It makes a lot more sense to store that in a new variable, and that will simplify this code.

00:01:45.000 --> 00:01:48.000
So now we just need to pass in content.

00:01:48.000 --> 00:01:51.000
So we have one missing statement,

00:01:51.000 --> 00:01:56.000
and I'll leave it to you to see if you can figure out statement we need there to finish the web crawler.

00:01:56.000 --> 00:01:59.000
When it's done, the result of "crawl-web," what we return as "index"

00:01:59.000 --> 00:02:02.000
should be an index of all the content we find starting from the seed.

