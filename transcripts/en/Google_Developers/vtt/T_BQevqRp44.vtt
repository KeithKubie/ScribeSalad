WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.920
[MUSIC PLAYING]

00:00:07.920 --> 00:00:10.230
MALE SPEAKER: Shanghai
GDG is a very

00:00:10.230 --> 00:00:12.010
interesting developer community.

00:00:12.010 --> 00:00:13.140
FEMALE SPEAKER: I'm
glad somebody

00:00:13.140 --> 00:00:14.025
has asked this question.

00:00:14.025 --> 00:00:15.560
MALE SPEAKER: This is where
the magic happens.

00:00:15.560 --> 00:00:16.870
FEMALE SPEAKER: This is
primarily a question and

00:00:16.870 --> 00:00:17.770
answer show.

00:00:17.770 --> 00:00:19.745
So if any of you out there would
like to ask questions?

00:00:24.520 --> 00:00:27.150
FRED SAUER: All right,
welcome everyone.

00:00:27.150 --> 00:00:28.520
Thanks for joining today.

00:00:28.520 --> 00:00:29.580
My name is Fred Sauer.

00:00:29.580 --> 00:00:31.850
I'm a developer advocate
working on App Engine.

00:00:31.850 --> 00:00:33.245
And with me today--

00:00:33.245 --> 00:00:34.070
IEIN VALDEZ: Iein Valdez.

00:00:34.070 --> 00:00:37.290
I'm also a developer advocate
working on Google App Engine.

00:00:37.290 --> 00:00:39.190
FRED SAUER: So today we thought
we'd talk to you a

00:00:39.190 --> 00:00:42.360
little bit about load testing
on App Engine and some

00:00:42.360 --> 00:00:45.840
performance tuning tips, so how
to get prepared for when

00:00:45.840 --> 00:00:50.070
your app is finally
successful.

00:00:50.070 --> 00:00:52.780
So I wanted to start off and
just share with you a few

00:00:52.780 --> 00:00:55.025
graphs from one of
our customers.

00:00:55.025 --> 00:00:58.620
I picked out some of the bigger
events that they had.

00:00:58.620 --> 00:01:01.710
This is a company that
does social events.

00:01:01.710 --> 00:01:04.360
So they have a gadget that they
put on other people's

00:01:04.360 --> 00:01:08.590
websites, and people can chat
on this gadget and interact

00:01:08.590 --> 00:01:09.870
with each other.

00:01:09.870 --> 00:01:12.990
And depending on the excitement
of the event, be it

00:01:12.990 --> 00:01:18.480
a sporting event or something
like that, different things

00:01:18.480 --> 00:01:19.670
happen to the traffic
patterns.

00:01:19.670 --> 00:01:22.750
So at any point when you're
looking at the traffic graphs,

00:01:22.750 --> 00:01:24.000
you don't know what it's
going to do next.

00:01:24.000 --> 00:01:24.640
Is it going to go up?

00:01:24.640 --> 00:01:25.690
Is it going down?

00:01:25.690 --> 00:01:27.690
Are you going to get 10x the
traffic that you had a few

00:01:27.690 --> 00:01:28.590
minutes ago?

00:01:28.590 --> 00:01:30.400
Or are you going to get
half the traffic?

00:01:30.400 --> 00:01:33.280
And, so you see the
graphs here.

00:01:33.280 --> 00:01:37.720
And a couple of interesting
things is that, well, these

00:01:37.720 --> 00:01:41.220
are the most popular events
between the smallest one--

00:01:41.220 --> 00:01:45.070
I've left out the -scale here,
but there's a 10x difference

00:01:45.070 --> 00:01:48.810
between the largest event and
the smallest one shown here.

00:01:48.810 --> 00:01:51.390
The other thing is, if you look
at the time scale, this

00:01:51.390 --> 00:01:52.950
is over several hours.

00:01:52.950 --> 00:01:57.160
So even though there's really
kind of sharp increases, if

00:01:57.160 --> 00:01:59.550
you were to zoom in, kind of on
a minute scale, you would

00:01:59.550 --> 00:02:03.050
still see what we call kind of
a gradual ramp, and I'll come

00:02:03.050 --> 00:02:03.700
back to that in a moment--

00:02:03.700 --> 00:02:06.880
IEIN VALDEZ: So these are good
graphs, is what you're saying.

00:02:06.880 --> 00:02:07.929
This is ideal performance?

00:02:07.929 --> 00:02:10.830
FRED SAUER: This is just
input to the system.

00:02:10.830 --> 00:02:13.950
This is customers showing up on
your website, knocking on

00:02:13.950 --> 00:02:15.835
the door, and saying I
want to do something.

00:02:15.835 --> 00:02:16.300
IEIN VALDEZ: Right.

00:02:16.300 --> 00:02:18.810
But in other words, it didn't
like drop off to zero?

00:02:18.810 --> 00:02:19.970
In other words, it
didn't lock up.

00:02:19.970 --> 00:02:20.830
FRED SAUER: This is success.

00:02:20.830 --> 00:02:21.880
IEIN VALDEZ: OK, that's--

00:02:21.880 --> 00:02:24.570
yeah, so these are good
graphs, I guess, OK.

00:02:24.570 --> 00:02:27.040
FRED SAUER: Yeah, and then on
the edges of these graphs,

00:02:27.040 --> 00:02:29.170
there's pretty much
nothing going on.

00:02:29.170 --> 00:02:32.970
When the gadget's not live on an
event, there's pretty much

00:02:32.970 --> 00:02:35.470
no traffic, just a little bit
of background with people

00:02:35.470 --> 00:02:38.870
refreshing maybe a homepage
or something like that.

00:02:38.870 --> 00:02:40.270
So App Engine is this

00:02:40.270 --> 00:02:42.040
distributed computing platform.

00:02:42.040 --> 00:02:45.830
And to really understand how it
works, and do performance

00:02:45.830 --> 00:02:48.840
tuning, and understand how your
load tests are kind of

00:02:48.840 --> 00:02:51.230
flowing through the system,
you need to kind of break

00:02:51.230 --> 00:02:55.560
apart the different components
and understand why we call it

00:02:55.560 --> 00:02:58.270
a distributed system and why
that's really important to the

00:02:58.270 --> 00:03:00.200
characteristics of App Engine.

00:03:00.200 --> 00:03:03.620
So if you kind of look here from
left to right, you have

00:03:03.620 --> 00:03:08.430
the clients that are producing
traffic-- so web browsers,

00:03:08.430 --> 00:03:09.830
mobile phones--

00:03:09.830 --> 00:03:12.130
and they're sending requests
into App Engine.

00:03:12.130 --> 00:03:13.860
And the first thing they
do is they hit

00:03:13.860 --> 00:03:15.150
the front end servers.

00:03:15.150 --> 00:03:19.160
These are the servers that take
care of opening up the

00:03:19.160 --> 00:03:22.960
HTTP communication with the
client serving the responses,

00:03:22.960 --> 00:03:26.290
and then they direct the traffic
down deeper into the

00:03:26.290 --> 00:03:29.030
depths of the Google
App Engine network

00:03:29.030 --> 00:03:30.440
and on to other servers.

00:03:30.440 --> 00:03:32.860
You may have back end servers.

00:03:32.860 --> 00:03:37.430
You may be using the datastore
or memcache, or maybe the

00:03:37.430 --> 00:03:39.260
image manipulation service.

00:03:39.260 --> 00:03:43.330
And so each time you make a
call, you're going from an app

00:03:43.330 --> 00:03:47.960
server, which is running your
code, down another layer into

00:03:47.960 --> 00:03:50.430
datastore, memcache,
et cetera.

00:03:50.430 --> 00:03:57.040
Now to zoom in a little bit on
the datastore there, when you

00:03:57.040 --> 00:04:01.800
write an entity to the
datastore, say, and then that

00:04:01.800 --> 00:04:03.960
makes an RPC-- a Remote
Procedure Call--

00:04:03.960 --> 00:04:07.800
to a tablet server, that tablet
server is responsible

00:04:07.800 --> 00:04:11.870
for a chunk of your data, and
that tablet server then has to

00:04:11.870 --> 00:04:13.580
write to a physical disk.

00:04:13.580 --> 00:04:17.474
So I haven't listed all the
layers here, but you see we

00:04:17.474 --> 00:04:18.730
already have--

00:04:18.730 --> 00:04:20.720
after the client, we
have a front end.

00:04:20.720 --> 00:04:21.829
There's an app server.

00:04:21.829 --> 00:04:23.230
There's a tablet server.

00:04:23.230 --> 00:04:26.090
Then there's the physical disk,
and there's a few more

00:04:26.090 --> 00:04:28.330
bits of infrastructure
in between there.

00:04:28.330 --> 00:04:32.880
IEIN VALDEZ: I guess the thing
to point out is that the front

00:04:32.880 --> 00:04:35.800
ends and the tablet servers
and all that stuff is auto

00:04:35.800 --> 00:04:36.830
scaled for you.

00:04:36.830 --> 00:04:38.660
You don't really actually
have to manage it.

00:04:38.660 --> 00:04:42.410
So whether you have one request
coming in or 10,000,

00:04:42.410 --> 00:04:44.920
that is all scaled by
the infrastructure.

00:04:44.920 --> 00:04:46.210
FRED SAUER: Exactly.

00:04:46.210 --> 00:04:51.540
And so our mission today is to
understand how to utilize this

00:04:51.540 --> 00:04:55.740
infrastructure in a way that it
continues to scale for us,

00:04:55.740 --> 00:04:58.780
that we don't introduce--

00:04:58.780 --> 00:05:01.540
use any patterns where we
actually kind of defeat the

00:05:01.540 --> 00:05:04.500
system and turn it into a
non-distributed system.

00:05:04.500 --> 00:05:07.650
Because that's really the one
way in which you can hurt the

00:05:07.650 --> 00:05:08.730
performance of your
application.

00:05:08.730 --> 00:05:10.346
IEIN VALDEZ: Cool.

00:05:10.346 --> 00:05:13.220
FRED SAUER: So we'll talk about
that a little bit more.

00:05:13.220 --> 00:05:16.570
So still zooming in on the
datastore at the very lowest

00:05:16.570 --> 00:05:20.520
level, every entity that you
store in the datastore is

00:05:20.520 --> 00:05:24.360
ultimately stored in a big table
row in this giant key

00:05:24.360 --> 00:05:25.440
value store.

00:05:25.440 --> 00:05:29.550
So every entity that you have
has a key, and then in the

00:05:29.550 --> 00:05:31.380
data portion, you have all
the properties, the

00:05:31.380 --> 00:05:33.440
values of your entity.

00:05:33.440 --> 00:05:37.070
Even the index entries
are in this form.

00:05:37.070 --> 00:05:41.810
So if you have an entity, say,
a customer, and you have a

00:05:41.810 --> 00:05:44.320
first name and a last name,
and both properties are

00:05:44.320 --> 00:05:46.990
indexed, you'll actually
have one row in this

00:05:46.990 --> 00:05:48.790
table for the entity.

00:05:48.790 --> 00:05:51.940
You'll have another row for
the built-in index entity.

00:05:51.940 --> 00:05:55.270
And then you'll have
four different

00:05:55.270 --> 00:05:56.640
rows for the property.

00:05:56.640 --> 00:05:59.280
You'll actually have a first
name ascending index, a

00:05:59.280 --> 00:06:01.980
descending, and a last name
ascending and descending.

00:06:01.980 --> 00:06:06.910
So think of your data as spread
out in this giant table

00:06:06.910 --> 00:06:09.870
of key value pairs, and
every bit of data is

00:06:09.870 --> 00:06:11.600
addressable by key.

00:06:11.600 --> 00:06:13.690
And then there's some
data associated with

00:06:13.690 --> 00:06:15.200
it, which is useful.

00:06:15.200 --> 00:06:19.860
Now, this is really important
because different parts of

00:06:19.860 --> 00:06:24.240
your data live in different
parts of the disk.

00:06:24.240 --> 00:06:30.290
And in order to take advantage
of the distributed nature of

00:06:30.290 --> 00:06:34.260
App Engine, you need to make
sure that not all your quests

00:06:34.260 --> 00:06:38.070
from all your users are
going to a single

00:06:38.070 --> 00:06:41.020
block of data on disk.

00:06:41.020 --> 00:06:43.560
Because if you do that,
there's ultimately--

00:06:43.560 --> 00:06:46.880
somewhere in a Google data
center, there's a server that

00:06:46.880 --> 00:06:50.680
is responsible for, let's say,
this little red block of data

00:06:50.680 --> 00:06:51.510
right there.

00:06:51.510 --> 00:06:53.760
Just these few rows of data,
there's one server that's

00:06:53.760 --> 00:06:54.680
responsible.

00:06:54.680 --> 00:06:58.230
And it has to be just one server
because we want to

00:06:58.230 --> 00:07:01.220
allow atomic transactions
on that data.

00:07:01.220 --> 00:07:02.550
So think about it that way.

00:07:02.550 --> 00:07:05.520
Now, imagine that one of these
rows of red data is some

00:07:05.520 --> 00:07:07.550
global state in your
application.

00:07:07.550 --> 00:07:11.910
Maybe it's a page counter, and
every time a visitor comes to

00:07:11.910 --> 00:07:14.970
the site, you want to increment
this counter and

00:07:14.970 --> 00:07:17.590
record the fact that you
had another visitor.

00:07:17.590 --> 00:07:20.970
Now, let's say you are very
successful, and you're serving

00:07:20.970 --> 00:07:23.140
1,000 requests per second,
maybe 10,000

00:07:23.140 --> 00:07:24.750
requests per second.

00:07:24.750 --> 00:07:27.220
All those requests have to
then funnel down from all

00:07:27.220 --> 00:07:29.490
these different front end
servers to all these different

00:07:29.490 --> 00:07:32.750
datastore servers, all the way
down to the single tablet

00:07:32.750 --> 00:07:35.840
server, which is now very much
getting overloaded because

00:07:35.840 --> 00:07:41.170
it's having to write to disk
10,000 times a second.

00:07:41.170 --> 00:07:43.815
And if you know anything about
disk hardware, you know that

00:07:43.815 --> 00:07:46.360
that's just simply
not possible.

00:07:46.360 --> 00:07:50.100
So one of the key strategies
in utilizing App Engine is

00:07:50.100 --> 00:07:53.250
making sure that you distribute
your load.

00:07:53.250 --> 00:07:55.980
So if you wanted to have this
page counter and you wanted to

00:07:55.980 --> 00:08:01.200
be able to update it at, say,
10,000 requests per second,

00:08:01.200 --> 00:08:02.590
that's absolutely possible.

00:08:02.590 --> 00:08:04.610
You just need to distribute
it over many

00:08:04.610 --> 00:08:06.350
different blocks of data.

00:08:06.350 --> 00:08:10.520
And this is a strategy called
sharding or partitioning.

00:08:10.520 --> 00:08:13.120
And what you do is you say,
well, instead of having one

00:08:13.120 --> 00:08:17.710
counter that we store in one
row in the datastore, let's

00:08:17.710 --> 00:08:22.970
make 1,000 counters, and let's
randomize the keys.

00:08:22.970 --> 00:08:24.220
They don't have to
be truly random.

00:08:24.220 --> 00:08:26.960
They just have to be distributed
over key space.

00:08:26.960 --> 00:08:29.710
So just for the sake
of argument, let's

00:08:29.710 --> 00:08:32.380
say we had 26 keys.

00:08:32.380 --> 00:08:38.020
We could prefix our global page
visitor counter with the

00:08:38.020 --> 00:08:38.860
letter of the alphabet.

00:08:38.860 --> 00:08:42.140
So we could have A page counter,
B page counter, C

00:08:42.140 --> 00:08:45.300
page, all the way to
Z page counter.

00:08:45.300 --> 00:08:49.130
And then any time a request
comes in and we want to bump

00:08:49.130 --> 00:08:52.040
up this page counter, we pick
one of the keys at random-- it

00:08:52.040 --> 00:08:54.000
really doesn't matter
which one--

00:08:54.000 --> 00:08:57.690
so we could just take a random
function times 1,000, or 26,

00:08:57.690 --> 00:08:59.740
or however many characters
we have, and then

00:08:59.740 --> 00:09:01.090
we update that row.

00:09:01.090 --> 00:09:03.940
And now what suddenly has
happened, instead of having

00:09:03.940 --> 00:09:06.980
10,000 requests going to a
single tablet server, we've

00:09:06.980 --> 00:09:11.620
distributed over, say, 1,000
tablets servers, each one

00:09:11.620 --> 00:09:13.660
doing only 10 requests
per second.

00:09:13.660 --> 00:09:14.950
That's maybe a lot
more reasonable.

00:09:14.950 --> 00:09:18.470
IEIN VALDEZ: So, you're
basically reducing the lock

00:09:18.470 --> 00:09:22.350
and write contention over
a set of keys by

00:09:22.350 --> 00:09:23.220
distributing it out.

00:09:23.220 --> 00:09:25.150
So it's sort of a fan
out pattern--

00:09:25.150 --> 00:09:25.930
FRED SAUER: Exactly.

00:09:25.930 --> 00:09:27.920
IEIN VALDEZ: --to increase
the amount of

00:09:27.920 --> 00:09:29.190
concurrency in the system.

00:09:29.190 --> 00:09:31.550
FRED SAUER: Yeah.

00:09:31.550 --> 00:09:36.810
So you can see that what we're
kind of saying here is that

00:09:36.810 --> 00:09:39.390
App Engine has this massive
distributed

00:09:39.390 --> 00:09:40.900
infrastructure for you.

00:09:40.900 --> 00:09:43.660
But you can definitely defeat
that infrastructure, if you

00:09:43.660 --> 00:09:48.150
send all your writes to a single
key, if you choose your

00:09:48.150 --> 00:09:50.960
keys poorly, or choose
your indexes poorly.

00:09:50.960 --> 00:09:55.030
So there's a little bit of, I
guess, forethought that needs

00:09:55.030 --> 00:09:58.600
to go into choices
of your design.

00:09:58.600 --> 00:10:00.320
And you do that, and then
everything scales very nicely.

00:10:00.320 --> 00:10:02.630
IEIN VALDEZ: And when we talk
about Bigtable, or the picture

00:10:02.630 --> 00:10:05.010
we have here, we're talking now
in the new world sort of

00:10:05.010 --> 00:10:08.300
in the high-replication
datastore world, which is

00:10:08.300 --> 00:10:11.400
there's also issues you have
to worry about in terms of

00:10:11.400 --> 00:10:14.380
consistency and how you
structure your entity groups

00:10:14.380 --> 00:10:15.926
and whatnot as well.

00:10:15.926 --> 00:10:18.530
FRED SAUER: Yeah, there's
definitely some design choices

00:10:18.530 --> 00:10:22.210
to make beyond just selecting
your keys.

00:10:22.210 --> 00:10:25.850
You talk about consistency, so
App Engine has this notion of

00:10:25.850 --> 00:10:26.940
entity groups.

00:10:26.940 --> 00:10:34.570
These are groups of entities
in which you can do atomic

00:10:34.570 --> 00:10:35.210
operations.

00:10:35.210 --> 00:10:37.780
So you can create a transaction,
and you can

00:10:37.780 --> 00:10:41.540
manipulate multiple rows or
entities within that entity

00:10:41.540 --> 00:10:42.895
group in a single transaction.

00:10:42.895 --> 00:10:43.720
IEIN VALDEZ: Right.

00:10:43.720 --> 00:10:46.940
FRED SAUER: And then new--

00:10:46.940 --> 00:10:48.480
well, not quite so
new anymore.

00:10:48.480 --> 00:10:51.270
It's probably been about six
or eight months now.

00:10:51.270 --> 00:10:55.280
We have cross-group
transactions, XG transactions,

00:10:55.280 --> 00:10:58.940
which if you're a long-time
customer of App Engine, you'll

00:10:58.940 --> 00:11:00.850
remember the day when you
could only transact on a

00:11:00.850 --> 00:11:02.130
single entity group.

00:11:02.130 --> 00:11:04.250
Now you can actually do up to
five entity groups in a single

00:11:04.250 --> 00:11:04.520
transaction.

00:11:04.520 --> 00:11:06.310
IEIN VALDEZ: This is
transactions across entity

00:11:06.310 --> 00:11:10.300
groups, and so this is really
nice for those complex

00:11:10.300 --> 00:11:10.860
transactions.

00:11:10.860 --> 00:11:14.010
FRED SAUER: Yeah, the canonical
case is I have money

00:11:14.010 --> 00:11:16.270
in two bank accounts, and I'd
like to transfer money.

00:11:16.270 --> 00:11:19.540
I want to deduct $10 out of this
account and add $10 to

00:11:19.540 --> 00:11:21.960
that account, and I want to do
it in a single transaction.

00:11:21.960 --> 00:11:22.740
And you can do that.

00:11:22.740 --> 00:11:25.484
IEIN VALDEZ: Very cool.

00:11:25.484 --> 00:11:28.800
FRED SAUER: So there's a number
of tools that App

00:11:28.800 --> 00:11:31.010
Engine provides for your
tools for the trade.

00:11:31.010 --> 00:11:33.400
One of them is called
Appstats.

00:11:33.400 --> 00:11:37.200
And actually, in the 1.7.1
release that just went out

00:11:37.200 --> 00:11:40.160
last week, there's an
enhancement that's not even

00:11:40.160 --> 00:11:41.600
represented here
in screenshot.

00:11:41.600 --> 00:11:45.310
There's a little shell mode
that allows you to type a

00:11:45.310 --> 00:11:48.760
snippet of Python code and
actually see what the Appstats

00:11:48.760 --> 00:11:51.650
would look like for that without
having to deploy your

00:11:51.650 --> 00:11:53.000
application or test it.

00:11:53.000 --> 00:11:56.660
So you can work on snippets
of code and optimize them.

00:11:56.660 --> 00:11:58.190
Now, this is a great tool.

00:11:58.190 --> 00:12:00.930
I love the quote here. "I used
to be blind, but now I can

00:12:00.930 --> 00:12:06.180
see." And what the person meant
here is that they used

00:12:06.180 --> 00:12:08.460
to blind to what was going
on in their application.

00:12:08.460 --> 00:12:11.260
They could certainly read
through their code and see how

00:12:11.260 --> 00:12:14.760
many datastore calls they
thought they were making.

00:12:14.760 --> 00:12:16.790
But when you turn on Appstats,
you actually

00:12:16.790 --> 00:12:18.350
get a visual overview.

00:12:18.350 --> 00:12:22.590
And you can see that in this
case, there's kind of this

00:12:22.590 --> 00:12:26.200
staircase effect, where one RPC
happens after the other,

00:12:26.200 --> 00:12:27.120
after the other.

00:12:27.120 --> 00:12:30.630
And that actually slows down
the requests quite a bit.

00:12:30.630 --> 00:12:32.630
And it gives you hints.

00:12:32.630 --> 00:12:36.640
I guess looking at this, you
can say, maybe I should use

00:12:36.640 --> 00:12:38.260
some asynchronous fetches
so I can do

00:12:38.260 --> 00:12:40.080
more things in parallel.

00:12:40.080 --> 00:12:41.660
Maybe I can do a more
efficient query.

00:12:41.660 --> 00:12:45.090
IEIN VALDEZ: You can batch
requests together so you can

00:12:45.090 --> 00:12:48.470
make one round trip versus 100,
if you wanted to fetch

00:12:48.470 --> 00:12:49.795
100 entities, for example.

00:12:49.795 --> 00:12:51.560
FRED SAUER: Yes, exactly.

00:12:51.560 --> 00:12:54.380
So first thing you should do
if you're optimizing your

00:12:54.380 --> 00:12:56.820
application is turn
on Appstats.

00:12:56.820 --> 00:12:59.380
You can use it in the
development server.

00:12:59.380 --> 00:13:01.250
You can use it in production.

00:13:01.250 --> 00:13:03.410
If you don't want to turn it
on for all of your live

00:13:03.410 --> 00:13:06.280
traffic, you can deploy to
a separate version, a

00:13:06.280 --> 00:13:08.250
non-default version of your
application, and turn it on

00:13:08.250 --> 00:13:12.200
there, and then just play
with it yourself.

00:13:12.200 --> 00:13:17.800
So let's start off with some
load testing guidelines.

00:13:17.800 --> 00:13:20.430
First of all, your load
tests should really be

00:13:20.430 --> 00:13:25.280
representative of the real
traffic that you expect.

00:13:25.280 --> 00:13:30.120
That means the rate at which
you on-ramp traffic.

00:13:30.120 --> 00:13:33.110
You should let traffic
ramp up over many

00:13:33.110 --> 00:13:35.420
minutes when you're--

00:13:35.420 --> 00:13:37.916
IEIN VALDEZ: You don't just have
a million users come to

00:13:37.916 --> 00:13:41.290
your site right away, so testing
it in that example

00:13:41.290 --> 00:13:42.010
probably is not--

00:13:42.010 --> 00:13:43.110
FRED SAUER: And even if you--

00:13:43.110 --> 00:13:44.680
people talk about getting
on slash dotted.

00:13:44.680 --> 00:13:48.890
Or maybe you're on a popular
talk show, and you get

00:13:48.890 --> 00:13:51.690
mentioned live on air, and you
think that everyone's going

00:13:51.690 --> 00:13:53.490
to, at the same time,
hit the Enter key

00:13:53.490 --> 00:13:54.720
and go to your website.

00:13:54.720 --> 00:13:57.870
Well, in reality, some people
have the computer sitting on

00:13:57.870 --> 00:13:58.350
their couch.

00:13:58.350 --> 00:14:00.310
Other people have to get
up and walk over.

00:14:00.310 --> 00:14:04.650
And the reality is, that even
then with some of the largest

00:14:04.650 --> 00:14:06.920
events, you'll see
traffic ramp up.

00:14:06.920 --> 00:14:07.560
IEIN VALDEZ: It ramps up.

00:14:07.560 --> 00:14:08.730
FRED SAUER: So your
load test should

00:14:08.730 --> 00:14:09.980
absolutely reflect that.

00:14:12.870 --> 00:14:15.510
So this is not what
your traffic

00:14:15.510 --> 00:14:16.850
graph should look like.

00:14:16.850 --> 00:14:19.380
Save the example, right?

00:14:19.380 --> 00:14:22.020
FRED SAUER: And you're just
going to see problems if

00:14:22.020 --> 00:14:22.600
you're doing that.

00:14:22.600 --> 00:14:26.050
It's the same thing if you're
driving a car, and you're at a

00:14:26.050 --> 00:14:28.840
light, and you say, OK
go 100 miles an hour.

00:14:28.840 --> 00:14:31.670
You don't pop the clutch and
instantly go 100 miles an

00:14:31.670 --> 00:14:32.240
hour, right?

00:14:32.240 --> 00:14:35.950
You have to pull out of your
spot, and you can go fast in a

00:14:35.950 --> 00:14:39.020
short amount of time,
but take it easy.

00:14:39.020 --> 00:14:42.680
So something like this is a lot
better, kind of ramped up.

00:14:42.680 --> 00:14:45.996
And if you really wanted to do
it nice, you kind of smooth in

00:14:45.996 --> 00:14:50.240
and out of the traffic.

00:14:50.240 --> 00:14:52.560
So let's look at a basic
recipe here.

00:14:56.240 --> 00:14:59.360
When you want to test traffic,
let's say your goal is 1,000

00:14:59.360 --> 00:15:02.850
qps, 1,000 requests
per second.

00:15:02.850 --> 00:15:06.470
If you were to just throw 1,000
on there, and even if

00:15:06.470 --> 00:15:09.490
you use that nice little curve
from before, but let's say you

00:15:09.490 --> 00:15:12.000
have some inefficiencies in
your app that you haven't

00:15:12.000 --> 00:15:17.640
worked through yet, and those
inefficiencies would normally

00:15:17.640 --> 00:15:22.710
kick up or start acting up at
20 requests per second.

00:15:22.710 --> 00:15:25.360
If you then throw 1,000 at it,
you're not only going to see

00:15:25.360 --> 00:15:29.270
all the errors caused by going
over the 20, but you're going

00:15:29.270 --> 00:15:32.090
to see all the snowball
effect of that.

00:15:32.090 --> 00:15:37.230
And your error logs are just
going to be a big mess, and

00:15:37.230 --> 00:15:39.480
you won't be able to tell what's
going on because you've

00:15:39.480 --> 00:15:43.480
just completely overloaded the
contentious spots in your

00:15:43.480 --> 00:15:44.510
application.

00:15:44.510 --> 00:15:48.810
And so what we want to do is
have a recipe where we get you

00:15:48.810 --> 00:15:53.310
to 1,000, which is your target,
very quickly, But we

00:15:53.310 --> 00:15:56.190
stop along the way to make sure
that we're in good shape,

00:15:56.190 --> 00:15:57.630
and we can handle that
amount of traffic.

00:15:57.630 --> 00:16:00.610
IEIN VALDEZ: And so we're sort
of progressively revealing

00:16:00.610 --> 00:16:03.560
maybe performance problems as
you kind of go through.

00:16:03.560 --> 00:16:06.520
Maybe there's five or six
different problems versus you

00:16:06.520 --> 00:16:08.710
see all five or six at once, and
you can't actually figure

00:16:08.710 --> 00:16:09.410
out what's going on.

00:16:09.410 --> 00:16:11.210
FRED SAUER: That's
exactly right.

00:16:11.210 --> 00:16:16.100
And I haven't met an application
that I wrote or

00:16:16.100 --> 00:16:19.270
anyone else that I know wrote,
and I'm sure there's people

00:16:19.270 --> 00:16:21.620
out there that write perfect
applications the first time.

00:16:21.620 --> 00:16:25.780
But there's always scenarios you
haven't thought through.

00:16:25.780 --> 00:16:28.300
Maybe there's places where you
said, oh, I'll come back and

00:16:28.300 --> 00:16:31.170
do that, and then you've
got distracted.

00:16:31.170 --> 00:16:33.440
And there's maybe
some unknowns.

00:16:33.440 --> 00:16:34.250
So exactly.

00:16:34.250 --> 00:16:36.120
We want to find those problems,
but we want to find

00:16:36.120 --> 00:16:37.390
them one at a time.

00:16:37.390 --> 00:16:41.410
Because problems generally are
really easy to address if you

00:16:41.410 --> 00:16:42.960
have just that one problem.

00:16:42.960 --> 00:16:47.490
If you have, for example, that
global page counter, that

00:16:47.490 --> 00:16:49.650
problem is actually pretty easy
to find if that's the

00:16:49.650 --> 00:16:51.510
only thing going on.

00:16:51.510 --> 00:16:52.825
So here's a recipe.

00:16:52.825 --> 00:16:56.820
We'll start out with something
small, like 5 qps, 5 requests

00:16:56.820 --> 00:16:57.630
per second.

00:16:57.630 --> 00:17:02.110
And we just keep sending 5
requests per second, and we

00:17:02.110 --> 00:17:03.590
look for any problems.

00:17:03.590 --> 00:17:06.630
If you actually had a global
page counter, this would

00:17:06.630 --> 00:17:11.040
already show up at 5 qps,
because entity groups are

00:17:11.040 --> 00:17:14.240
designed to handle
at least 1 qps.

00:17:14.240 --> 00:17:16.670
Sometimes you can get a little
bit more out of it--

00:17:16.670 --> 00:17:20.609
depending on whether you're
master, slave, it's your D--

00:17:20.609 --> 00:17:23.634
but 5pqs is enough to find
issues like that.

00:17:23.634 --> 00:17:25.910
And that's a small amount of
traffic where you can actually

00:17:25.910 --> 00:17:28.682
just look through the logs
and you can see things.

00:17:28.682 --> 00:17:32.050
But let's say you don't
have any issues there.

00:17:32.050 --> 00:17:33.750
So what do you do?

00:17:33.750 --> 00:17:36.810
You wait about 15 to 20 minutes,
and what you're

00:17:36.810 --> 00:17:40.670
looking for is the dashboards
in the admin console.

00:17:40.670 --> 00:17:44.110
You want to see essentially
a number of flat lines.

00:17:44.110 --> 00:17:48.060
You want to see no quota
denials, which you certainly

00:17:48.060 --> 00:17:52.030
won't see at this rate,
very low error rate.

00:17:52.030 --> 00:17:55.100
There's always going to maybe be
some background error rate,

00:17:55.100 --> 00:17:58.200
because you're in a large
distributed system.

00:17:58.200 --> 00:17:59.370
You want to make sure
that your task

00:17:59.370 --> 00:18:01.040
queues are keeping up.

00:18:01.040 --> 00:18:05.395
You may want to ratchet up the
number of concurrent requests

00:18:05.395 --> 00:18:08.720
there if you need to, and
no elevated datastore

00:18:08.720 --> 00:18:10.310
contentions, so you don't
want to see a number

00:18:10.310 --> 00:18:12.510
of datastore errors.

00:18:12.510 --> 00:18:17.980
And so then what we do is we
double our traffic, but we do

00:18:17.980 --> 00:18:20.630
it slowly over a period
of several minutes.

00:18:20.630 --> 00:18:23.000
And what we're looking for
is the next application

00:18:23.000 --> 00:18:23.930
bottleneck.

00:18:23.930 --> 00:18:25.910
Now, if everything goes
smoothly, and again, we see

00:18:25.910 --> 00:18:30.170
these flat lines, very low error
rate, no quota denials,

00:18:30.170 --> 00:18:34.390
task queues are keeping up, we
just keep moving on, and we

00:18:34.390 --> 00:18:38.990
repeat, and repeat until we
reach that 1,000 qps, or that

00:18:38.990 --> 00:18:42.540
30 qps, or whatever number
we're shooting for there.

00:18:42.540 --> 00:18:46.546
And once we're happy and we've
gotten to the desired amount

00:18:46.546 --> 00:18:49.560
of traffic and have a very
stable, consistently

00:18:49.560 --> 00:18:53.470
performing application, then we
plan our next feature and

00:18:53.470 --> 00:18:55.430
go through the load testing
process again once we've

00:18:55.430 --> 00:18:59.290
rolled out a major feature or
done any refactoring in the

00:18:59.290 --> 00:19:00.300
application.

00:19:00.300 --> 00:19:04.670
IEIN VALDEZ: is there a best
practice in terms of how

00:19:04.670 --> 00:19:08.690
frequently you actually
do these things?

00:19:08.690 --> 00:19:11.490
Or is it just when you're making
a major change, you

00:19:11.490 --> 00:19:12.480
sort of do that?

00:19:12.480 --> 00:19:13.195
I'm not sure what--

00:19:13.195 --> 00:19:16.250
FRED SAUER: I think there's
always a trade-off.

00:19:16.250 --> 00:19:19.220
In an ideal world,
you would have a

00:19:19.220 --> 00:19:20.680
dedicated QA team, right?

00:19:20.680 --> 00:19:23.280
And they would run your
application through the paces

00:19:23.280 --> 00:19:26.350
for every single release
and make sure it works.

00:19:26.350 --> 00:19:31.110
I know many of you, you might be
working by yourself or just

00:19:31.110 --> 00:19:33.710
with one colleague, and
everything's a judgment call,

00:19:33.710 --> 00:19:34.910
everything's a trade-off.

00:19:34.910 --> 00:19:38.290
If you spend the day on load
testing, you don't get to

00:19:38.290 --> 00:19:39.380
write this feature.

00:19:39.380 --> 00:19:42.520
And so you really have to
decide, did I do some major

00:19:42.520 --> 00:19:43.250
refactoring?

00:19:43.250 --> 00:19:46.010
Or is this really just a tweak
to the CSS of the site?

00:19:46.010 --> 00:19:47.690
IEIN VALDEZ: But it's definitely
the type of thing,

00:19:47.690 --> 00:19:50.080
like if you're launching, you
probably want to do a major

00:19:50.080 --> 00:19:51.070
load test run.

00:19:51.070 --> 00:19:53.720
But then post-launch, let's
say you've ironed out.

00:19:53.720 --> 00:19:54.770
You've got some minor
features.

00:19:54.770 --> 00:19:57.830
Maybe it's not, but maybe if
you're changing the way you're

00:19:57.830 --> 00:20:00.170
storing your data or you're
changing your queries, maybe

00:20:00.170 --> 00:20:04.240
that would require something
like this.

00:20:04.240 --> 00:20:05.510
FRED SAUER: Absolutely.

00:20:05.510 --> 00:20:10.130
You should have a load test
before you launch big.

00:20:10.130 --> 00:20:15.700
And any type of re-factoring
work's important.

00:20:15.700 --> 00:20:17.280
IEIN VALDEZ: Make sure
you have billing on.

00:20:17.280 --> 00:20:18.210
FRED SAUER: Oh, yes.

00:20:18.210 --> 00:20:19.710
IEIN VALDEZ: Ratio is one of
those other things that some

00:20:19.710 --> 00:20:22.480
people forget to turn on
until the last minute.

00:20:22.480 --> 00:20:25.350
FRED SAUER: Yeah, so that's
a really good point there.

00:20:25.350 --> 00:20:31.290
Because App Engine has these
free quotas, but your

00:20:31.290 --> 00:20:34.670
application is much more
throttled because it's living

00:20:34.670 --> 00:20:36.020
in this free world.

00:20:36.020 --> 00:20:38.760
As soon as you turn on billing,
some of those

00:20:38.760 --> 00:20:42.630
constraints come off and your
application is ready for some

00:20:42.630 --> 00:20:43.235
really traffic.

00:20:43.235 --> 00:20:46.200
IEIN VALDEZ: OK, cool.

00:20:46.200 --> 00:20:50.040
FRED SAUER: So this slide here
is just to make a point about

00:20:50.040 --> 00:20:54.580
the difference between the
amount of time that it takes

00:20:54.580 --> 00:20:59.110
in our infrastructure if you
were running your own servers

00:20:59.110 --> 00:21:02.320
to write to disk versus
to write to

00:21:02.320 --> 00:21:05.270
memory over the network.

00:21:05.270 --> 00:21:09.610
So when we start out building
applications, almost every

00:21:09.610 --> 00:21:12.210
application needs some sort
of persistence in storage.

00:21:12.210 --> 00:21:14.560
So we're always using the
datastore writing data to

00:21:14.560 --> 00:21:19.680
disks, but we should really
realize that if you're doing

00:21:19.680 --> 00:21:26.860
the lookup to disk, you'll lose
at least 20 milliseconds.

00:21:26.860 --> 00:21:29.250
You might be closer to 50
or might even be 100

00:21:29.250 --> 00:21:31.310
milliseconds, depending
on what's going on.

00:21:31.310 --> 00:21:35.410
But doing a lookup over the
network, that can happen in

00:21:35.410 --> 00:21:38.210
order of 10x faster.

00:21:38.210 --> 00:21:40.910
So it's an order of
magnitude faster.

00:21:40.910 --> 00:21:43.410
Now, if you're, in a single
request having to pull a

00:21:43.410 --> 00:21:45.670
number of pieces of data
together that's 20

00:21:45.670 --> 00:21:48.020
milliseconds here, 50
milliseconds there, another 30

00:21:48.020 --> 00:21:52.750
there, that pretty soon starts
to add up to real change.

00:21:52.750 --> 00:21:57.490
Whereas if you're making a few
calls to memcache, you can

00:21:57.490 --> 00:22:00.470
make 10 of those, and you still
are only up to the speed

00:22:00.470 --> 00:22:03.620
of one datastore call.

00:22:03.620 --> 00:22:07.040
Now, for Python users out there,
I should just really

00:22:07.040 --> 00:22:11.390
make a call out to NDB,
the new database API.

00:22:11.390 --> 00:22:13.820
It does this for you
automatically.

00:22:13.820 --> 00:22:18.550
So it introduces a caching
layer, and when you fetch from

00:22:18.550 --> 00:22:20.950
the datastore, it automatically

00:22:20.950 --> 00:22:22.240
checks memcache first.

00:22:22.240 --> 00:22:24.630
In fact, it has another layer
in front of this that's even

00:22:24.630 --> 00:22:27.470
faster, which is the context
memory of the instance.

00:22:27.470 --> 00:22:28.370
IEIN VALDEZ: Instance caching.

00:22:28.370 --> 00:22:32.040
FRED SAUER: Yeah, and for Java
users out there, there's

00:22:32.040 --> 00:22:36.700
Objectify, which has a caching
scheme called Objectify Cache.

00:22:36.700 --> 00:22:38.330
And you can turn that
on, and it gets a

00:22:38.330 --> 00:22:39.400
lot of the same benefits.

00:22:39.400 --> 00:22:41.415
IEIN VALDEZ: Awesome.

00:22:41.415 --> 00:22:46.500
FRED SAUER: Now, let's talk
about free lunch.

00:22:46.500 --> 00:22:50.070
I know right here in Mountain
View, it's not lunchtime yet.

00:22:50.070 --> 00:22:51.620
But this looks pretty
tasty here.

00:22:51.620 --> 00:22:52.452
IEIN VALDEZ: It does
look pretty good.

00:22:52.452 --> 00:22:55.070
FRED SAUER: So how do you
get a free lunch?

00:22:55.070 --> 00:22:57.550
There's a saying that there's no
such thing as a free lunch,

00:22:57.550 --> 00:23:00.190
but I think there actually is.

00:23:00.190 --> 00:23:01.440
Let me talk about that.

00:23:04.110 --> 00:23:07.260
I just mentioned
using memcache.

00:23:07.260 --> 00:23:11.140
But another thing that many
developers forget is to turn

00:23:11.140 --> 00:23:13.900
on or use static resources.

00:23:13.900 --> 00:23:17.780
So there are a lot of files in
your application which don't

00:23:17.780 --> 00:23:20.960
change or change very
infrequently.

00:23:20.960 --> 00:23:23.490
And you can turn those into
static resources, and they get

00:23:23.490 --> 00:23:26.890
served through a different
path in App Engine's

00:23:26.890 --> 00:23:29.380
infrastructure, a path
that doesn't even

00:23:29.380 --> 00:23:30.520
take instance hours.

00:23:30.520 --> 00:23:34.340
So you're saving yourself
instance hours.

00:23:34.340 --> 00:23:39.020
The responses are faster for
your users, and ISPs and

00:23:39.020 --> 00:23:42.390
others downstream can cache
this content as well.

00:23:42.390 --> 00:23:45.730
IEIN VALDEZ: So let's just say
that I'm hosting a website

00:23:45.730 --> 00:23:47.470
with some dynamic and
static content.

00:23:47.470 --> 00:23:50.610
So like the images, the static
HTML, that stuff

00:23:50.610 --> 00:23:51.335
you could serve up.

00:23:51.335 --> 00:23:54.960
FRED SAUER: Exactly, put that
in the static resources.

00:23:54.960 --> 00:23:57.910
And then even for your dynamic
requests, let's say you have

00:23:57.910 --> 00:24:00.940
the homepage which you
dynamically put together, and

00:24:00.940 --> 00:24:04.726
you have the top things that
just happened, and you have a

00:24:04.726 --> 00:24:05.960
little news snippet,
and you have some

00:24:05.960 --> 00:24:06.750
other stuff going on.

00:24:06.750 --> 00:24:09.020
You say, well, I have to
generate that dynamically.

00:24:09.020 --> 00:24:10.780
I can't do that statically.

00:24:10.780 --> 00:24:15.030
Well, in fact, you don't need
that information probably to

00:24:15.030 --> 00:24:19.050
be up to the microsecond, up to
date, every single time the

00:24:19.050 --> 00:24:20.320
user requests the data.

00:24:20.320 --> 00:24:23.350
Maybe it can be a few
seconds stale.

00:24:23.350 --> 00:24:26.880
Maybe you could, if you have a
lot of traffic, only update

00:24:26.880 --> 00:24:29.220
that data every 20 seconds.

00:24:29.220 --> 00:24:31.270
Maybe every two minutes
is enough.

00:24:31.270 --> 00:24:34.050
So if you set your cache control
headers and say this

00:24:34.050 --> 00:24:36.860
page content, as it's generated,
is good for the

00:24:36.860 --> 00:24:39.630
next two minutes, then every
user that comes in the next

00:24:39.630 --> 00:24:42.420
two minutes, they can take
advantage of that cache

00:24:42.420 --> 00:24:45.430
content, get a much faster
response, lower the load on

00:24:45.430 --> 00:24:49.490
your site, lower your instance
hours, et cetera.

00:24:49.490 --> 00:24:50.240
Saves you bandwidth.

00:24:50.240 --> 00:24:52.322
IEIN VALDEZ: Very cool.

00:24:52.322 --> 00:24:55.840
FRED SAUER: And that's where
the free lunch comes in.

00:24:55.840 --> 00:25:00.340
When this content is cached
downstream at the ISP, say,

00:25:00.340 --> 00:25:02.050
Iein and I live in the same
neighborhood, and we

00:25:02.050 --> 00:25:03.380
have the same ISP.

00:25:03.380 --> 00:25:05.640
And I just went and fetched
this page from this very

00:25:05.640 --> 00:25:08.390
popular website, and then a few
minutes later, Iein goes

00:25:08.390 --> 00:25:09.980
out and gets that same page.

00:25:09.980 --> 00:25:12.480
That request might
never actually

00:25:12.480 --> 00:25:13.690
come over to App Engine.

00:25:13.690 --> 00:25:16.850
It might be served directly
out of the ISP's cache.

00:25:16.850 --> 00:25:18.150
That's the free lunch
right there.

00:25:18.150 --> 00:25:18.760
IEIN VALDEZ: Very cool.

00:25:18.760 --> 00:25:23.343
So this is really important
for people

00:25:23.343 --> 00:25:24.550
who are hosting websites.

00:25:24.550 --> 00:25:26.896
Even if you're doing things in
the Chrome Web Store, we have

00:25:26.896 --> 00:25:29.040
a lot of people hosting Chrome
Web apps that have all these

00:25:29.040 --> 00:25:31.630
static resources.

00:25:31.630 --> 00:25:33.070
That's really who should
take note.

00:25:33.070 --> 00:25:35.890
FRED SAUER: And even little
bits of dynamic content.

00:25:35.890 --> 00:25:40.980
Like you might have a leader
board showing the top five

00:25:40.980 --> 00:25:42.230
players in your game.

00:25:42.230 --> 00:25:44.560
Well, that information doesn't
change second by second.

00:25:44.560 --> 00:25:45.180
IEIN VALDEZ: Right.

00:25:45.180 --> 00:25:47.720
So maybe having a slightly
out-of-date copy every 30

00:25:47.720 --> 00:25:49.200
seconds or minute
type of thing--

00:25:49.200 --> 00:25:49.920
FRED SAUER: Exactly.

00:25:49.920 --> 00:25:50.590
IEIN VALDEZ: --might be OK.

00:25:50.590 --> 00:25:51.160
FRED SAUER: Yep.

00:25:51.160 --> 00:25:51.926
IEIN VALDEZ: Very cool.

00:25:51.926 --> 00:25:56.640
FRED SAUER: So just with some
small tweaks, you can reduce

00:25:56.640 --> 00:26:00.390
the freshness of the data only
a tiny bit, but perhaps gain

00:26:00.390 --> 00:26:01.660
very significantly.

00:26:01.660 --> 00:26:05.780
And the nice thing is that these
caching benefits, they

00:26:05.780 --> 00:26:08.000
actually are much more
prominent the

00:26:08.000 --> 00:26:09.480
larger your site is.

00:26:09.480 --> 00:26:11.790
The more traffic you're serving,
the more users, the

00:26:11.790 --> 00:26:13.530
more opportunities
these caches have

00:26:13.530 --> 00:26:15.110
to serve cache content.

00:26:15.110 --> 00:26:17.100
So these things kind of
compound themselves.

00:26:20.230 --> 00:26:22.670
So a couple more best practices,
and this is

00:26:22.670 --> 00:26:25.940
particularly geared towards
those of you that are mobile

00:26:25.940 --> 00:26:27.520
developers out there.

00:26:27.520 --> 00:26:33.170
Because you have clients out
there, mobile devices, that

00:26:33.170 --> 00:26:34.290
are running your software.

00:26:34.290 --> 00:26:37.470
So maybe you've written an
Android app, and these

00:26:37.470 --> 00:26:40.320
applications are under
your control.

00:26:40.320 --> 00:26:45.060
And you can program them to call
home to request data from

00:26:45.060 --> 00:26:46.380
your application.

00:26:46.380 --> 00:26:50.780
So now instead of humans, who
are a little bit unpredictable

00:26:50.780 --> 00:26:53.740
and they'll log on to your site
at different times of

00:26:53.740 --> 00:26:57.950
day, now you have all these
Android devices out there in

00:26:57.950 --> 00:27:01.910
the wild, maybe spread out
through your country or spread

00:27:01.910 --> 00:27:05.590
out around the world, and
they're all sync to the same

00:27:05.590 --> 00:27:08.170
network time, and they all
obey the same list of

00:27:08.170 --> 00:27:09.230
instructions.

00:27:09.230 --> 00:27:13.980
And what you have is actually a
mini botnet that is wired up

00:27:13.980 --> 00:27:16.800
to connect to your
application.

00:27:16.800 --> 00:27:20.040
So, this traffic graph right
here shows one of the bad

00:27:20.040 --> 00:27:24.870
things that can happen when,
let's say you decide, I want

00:27:24.870 --> 00:27:27.680
my Android app to call
home every day

00:27:27.680 --> 00:27:30.580
at, let's say, midnight.

00:27:30.580 --> 00:27:31.970
And you get a few users.

00:27:31.970 --> 00:27:33.080
You get your friends using it.

00:27:33.080 --> 00:27:33.740
It's fine.

00:27:33.740 --> 00:27:35.560
And then suddenly, your
application becomes a little

00:27:35.560 --> 00:27:38.890
bit popular, and now you have
thousands of people using your

00:27:38.890 --> 00:27:39.720
application.

00:27:39.720 --> 00:27:41.730
So there's thousands of Android
phones out there that

00:27:41.730 --> 00:27:44.800
all at midnight, call home, call
your application at the

00:27:44.800 --> 00:27:47.820
exact same time requesting
the same information.

00:27:47.820 --> 00:27:52.820
And so you get these crazy
little spikes that happen.

00:27:52.820 --> 00:27:55.140
And so you want to avoid that.

00:27:55.140 --> 00:27:58.360
And it's quite easy to do.

00:27:58.360 --> 00:28:02.190
You simply want to randomize
the check-in times.

00:28:02.190 --> 00:28:04.440
So every client picks
a random time.

00:28:04.440 --> 00:28:07.210
And if you still want to do it
at night, you could say, OK,

00:28:07.210 --> 00:28:11.400
between 2:00 and 4:00 AM,
pick a random time on

00:28:11.400 --> 00:28:12.260
the check-in net.

00:28:12.260 --> 00:28:16.110
That's still a lot better than
a single point in time.

00:28:16.110 --> 00:28:24.110
The other thing that once people
have tackled that is

00:28:24.110 --> 00:28:26.800
developers will have
a built-in retry.

00:28:26.800 --> 00:28:30.070
So if everything's
successful, fine.

00:28:30.070 --> 00:28:31.710
Keep going on, pick
a random time.

00:28:31.710 --> 00:28:35.710
But if the device encounters any
kind of error, then maybe

00:28:35.710 --> 00:28:38.610
it retries say, two
minutes later.

00:28:38.610 --> 00:28:42.530
Well, what happens when your
site goes down for

00:28:42.530 --> 00:28:43.700
maintenance, for example?

00:28:43.700 --> 00:28:46.840
So suddenly your site becomes
available to all clients.

00:28:46.840 --> 00:28:50.470
And so they all start retrying
on, let's say,

00:28:50.470 --> 00:28:51.910
a two-minute schedule.

00:28:51.910 --> 00:28:53.670
And what you'll get is
actually one of these

00:28:53.670 --> 00:28:59.470
heartbeat graphs, where every
two minutes, all these clients

00:28:59.470 --> 00:29:02.030
try at the same time
to reach your site.

00:29:02.030 --> 00:29:06.270
But that's too much of an
instantaneous and unrealistic

00:29:06.270 --> 00:29:08.550
load, and so many of these
clients actually will get an

00:29:08.550 --> 00:29:09.580
error message again.

00:29:09.580 --> 00:29:12.450
So they'll retry two minutes
later, and so you create this

00:29:12.450 --> 00:29:15.650
crazy little heartbeat.

00:29:15.650 --> 00:29:19.190
So pretty simple, you do
something called exponential

00:29:19.190 --> 00:29:22.690
backoff, which is you basically
do something like

00:29:22.690 --> 00:29:25.390
double the retry time
every time you fail.

00:29:25.390 --> 00:29:29.860
So you retry after 2 minutes,
then 4, then 8, then 16.

00:29:29.860 --> 00:29:34.320
And this way, your overtime
reducing the load to your site

00:29:34.320 --> 00:29:36.630
so that eventually it
will recover from

00:29:36.630 --> 00:29:39.000
your own little botnet.

00:29:39.000 --> 00:29:41.090
But the important thing that you
shouldn't forget here is,

00:29:41.090 --> 00:29:42.120
again, the fuzz factor.

00:29:42.120 --> 00:29:43.740
You have to randomize
it a bit.

00:29:43.740 --> 00:29:45.750
Otherwise, these heartbeats just
become more spread out.

00:29:48.800 --> 00:29:51.430
So there's a number
of best practices.

00:29:51.430 --> 00:29:52.585
We have this article.

00:29:52.585 --> 00:29:53.660
It's great.

00:29:53.660 --> 00:29:57.450
It's kind of a checklist to go
through of performance issues

00:29:57.450 --> 00:29:59.670
that you want to look at.

00:29:59.670 --> 00:30:04.970
And it gives you some tools
to adjust between

00:30:04.970 --> 00:30:07.740
performance and cost.

00:30:07.740 --> 00:30:10.430
For some of your applications,
performance is the most

00:30:10.430 --> 00:30:12.630
important thing, and you're
trying to get the most out of

00:30:12.630 --> 00:30:15.650
App Engine as far as
serving resources

00:30:15.650 --> 00:30:17.060
as quickly as possible.

00:30:17.060 --> 00:30:20.800
For others of you, budget is a
little bit more important, and

00:30:20.800 --> 00:30:24.740
you want to get more out of the
resources that you have.

00:30:24.740 --> 00:30:28.560
And this article shows you some
of the trade-offs and is

00:30:28.560 --> 00:30:32.110
at least a checklist of things
you should be aware of and

00:30:32.110 --> 00:30:35.130
then you can dive deeper into to
each of the details there.

00:30:38.020 --> 00:30:41.990
Here's a list, for example, of
ways to reduce instance hours,

00:30:41.990 --> 00:30:45.710
which is when the primary
cost of--

00:30:45.710 --> 00:30:49.950
primary sources of cost
for applications.

00:30:49.950 --> 00:30:52.550
And the other one
is datastore.

00:30:55.380 --> 00:30:59.860
We kind of did an informal
survey of how developers are

00:30:59.860 --> 00:31:01.330
using their datastore.

00:31:01.330 --> 00:31:05.970
And what we find is that almost
all developers are

00:31:05.970 --> 00:31:10.310
using the datastore less
efficiently than they could.

00:31:10.310 --> 00:31:15.160
One of the common ways to get
data back is to use a query.

00:31:15.160 --> 00:31:19.410
In many cases, a query can be
replaced by a direct fetch to

00:31:19.410 --> 00:31:22.920
an entity, which is
half the work.

00:31:22.920 --> 00:31:26.200
Because a query involves first
doing a scan to an index, then

00:31:26.200 --> 00:31:27.650
figuring out the keys,
and actually going

00:31:27.650 --> 00:31:28.960
fetching those keys.

00:31:28.960 --> 00:31:32.640
When you do a direct fetch for
a key, you skip that first

00:31:32.640 --> 00:31:34.280
step entirely.

00:31:34.280 --> 00:31:36.770
But even a fetch can
be more efficient.

00:31:36.770 --> 00:31:40.750
If you only need to know the key
of an entity, you can do a

00:31:40.750 --> 00:31:41.510
keys only query.

00:31:41.510 --> 00:31:42.940
IEIN VALDEZ: There's projection
queries now.

00:31:42.940 --> 00:31:46.240
FRED SAUER: Projection queries,
very good, yep, where

00:31:46.240 --> 00:31:50.720
you pull in only the properties
you need.

00:31:50.720 --> 00:31:50.990
IEIN VALDEZ: Right.

00:31:50.990 --> 00:31:53.870
So if I have an entity with
maybe 100 properties but I

00:31:53.870 --> 00:31:55.640
only need three at the moment,
I can just fetch those.

00:31:55.640 --> 00:31:55.895
Those three--

00:31:55.895 --> 00:31:56.950
FRED SAUER: Yes, exactly.

00:31:56.950 --> 00:31:58.650
IEIN VALDEZ: -- and the cost
will reflect that.

00:31:58.650 --> 00:32:01.040
FRED SAUER: Yeah, you'll get a
small datastore opp instead of

00:32:01.040 --> 00:32:05.440
a large one, which there's
a big difference there.

00:32:05.440 --> 00:32:08.320
Now a while back, we introduced,
in the admin

00:32:08.320 --> 00:32:11.930
console, some of these
performance knobs.

00:32:11.930 --> 00:32:15.830
And you won't see
these knobs--

00:32:15.830 --> 00:32:18.090
you won't see all of them unless
you turn billing on.

00:32:18.090 --> 00:32:20.710
So it's another reason
to turn on billing.

00:32:20.710 --> 00:32:26.270
And these four knobs right here
really represent a way of

00:32:26.270 --> 00:32:29.640
tuning cost versus
performance.

00:32:29.640 --> 00:32:33.030
So a couple of the typical
things that you'll do is if

00:32:33.030 --> 00:32:35.470
you want to make sure that your
application is all warmed

00:32:35.470 --> 00:32:38.120
up, and you're ready to serve
a lot of traffic in a very

00:32:38.120 --> 00:32:40.550
short period of time, and that's
the most important

00:32:40.550 --> 00:32:43.446
thing for you, then you probably
want to raise Min

00:32:43.446 --> 00:32:45.510
Idle Instances.

00:32:45.510 --> 00:32:48.190
And that tells App Engine--

00:32:48.190 --> 00:32:51.380
that's a signal to App Engine
to keep more instances warm

00:32:51.380 --> 00:32:55.740
and ready in case there's a
sudden increase in traffic.

00:32:55.740 --> 00:32:59.940
On the other hand, if you're
very cost sensitive and you'd

00:32:59.940 --> 00:33:04.100
rather App Engine not spin up
another instance if it doesn't

00:33:04.100 --> 00:33:07.560
need to because there's a short
little blip in traffic,

00:33:07.560 --> 00:33:10.920
you can increase the Min
Pending Latency.

00:33:10.920 --> 00:33:13.970
And that allows requests to
sit in a pending queue a

00:33:13.970 --> 00:33:17.500
little while before
they trigger a new

00:33:17.500 --> 00:33:18.590
instance to be started.

00:33:18.590 --> 00:33:19.840
IEIN VALDEZ: Right.

00:33:23.100 --> 00:33:26.750
I guess one of the things
I see a lot of is that

00:33:26.750 --> 00:33:28.320
developers are always kind
of fiddling with these.

00:33:28.320 --> 00:33:30.580
But sort of out of the box,
don't we say that that's

00:33:30.580 --> 00:33:31.350
basically--

00:33:31.350 --> 00:33:33.890
the settings that we give you
by default are pretty much

00:33:33.890 --> 00:33:35.155
optimal to start with.

00:33:35.155 --> 00:33:35.900
FRED SAUER: Absolutely.

00:33:35.900 --> 00:33:37.150
IEIN VALDEZ: You should try
starting with those settings

00:33:37.150 --> 00:33:40.860
before you actually mess with
the sliders and then sort of

00:33:40.860 --> 00:33:43.650
tune your application
after that.

00:33:43.650 --> 00:33:46.960
FRED SAUER: Yes, that's
a good point.

00:33:46.960 --> 00:33:49.390
These are advanced settings.

00:33:49.390 --> 00:33:52.530
And if you are having any
trouble with your application,

00:33:52.530 --> 00:33:56.730
you should set these all back
to automatic and test there.

00:33:56.730 --> 00:34:00.540
And then only when you
need something

00:34:00.540 --> 00:34:02.460
in addition to those--

00:34:02.460 --> 00:34:04.560
IEIN VALDEZ: Or maybe you need
to control your costs a little

00:34:04.560 --> 00:34:06.980
bit or start making some
performance trade-offs.

00:34:06.980 --> 00:34:10.360
Because I think that's the thing
I see a lot of beginners

00:34:10.360 --> 00:34:12.670
or even intermediate people
tweaking this without really

00:34:12.670 --> 00:34:13.679
understanding what's going on.

00:34:13.679 --> 00:34:16.889
And there's these side effects
that they see in their

00:34:16.889 --> 00:34:19.429
application that as soon as
they put the knobs back to

00:34:19.429 --> 00:34:21.389
automatic, they sort
of go away.

00:34:21.389 --> 00:34:22.639
FRED SAUER: Yeah.

00:34:25.659 --> 00:34:28.500
When people reach out to us and
say they're having issues

00:34:28.500 --> 00:34:31.350
with their application, if
they've adjusted these

00:34:31.350 --> 00:34:33.610
settings, the very first
thing we'll say is,

00:34:33.610 --> 00:34:34.750
let's put them back.

00:34:34.750 --> 00:34:38.030
Let's do a load test or look at
traffic with everything set

00:34:38.030 --> 00:34:40.929
to automatic, and then let's
make some small adjustments

00:34:40.929 --> 00:34:41.989
from there.

00:34:41.989 --> 00:34:44.560
These are definitely not knobs
that you swing from one

00:34:44.560 --> 00:34:45.960
extreme to the other.

00:34:45.960 --> 00:34:49.900
These are very fine tuning
for those advanced

00:34:49.900 --> 00:34:50.840
users and use cases.

00:34:50.840 --> 00:34:53.530
IEIN VALDEZ: And the other thing
I was going to ask is

00:34:53.530 --> 00:34:55.909
front-end instance class.

00:34:55.909 --> 00:34:58.540
So talk a little bit about that,
because that's actually

00:34:58.540 --> 00:35:01.555
one thing in particular I'm
always interested in.

00:35:01.555 --> 00:35:04.330
And I think a lot of developers
wonder what's the

00:35:04.330 --> 00:35:07.310
difference between the F1
all the way up to the--

00:35:07.310 --> 00:35:08.280
practice what you see.

00:35:08.280 --> 00:35:09.820
FRED SAUER: OK, that's
a good point.

00:35:09.820 --> 00:35:12.700
So we have front-ends
and back-ends.

00:35:12.700 --> 00:35:15.550
Back-ends have instance
classes called

00:35:15.550 --> 00:35:17.910
B1, B2, B4, and B8.

00:35:17.910 --> 00:35:24.030
And those represent different
amounts of CPU and memory.

00:35:24.030 --> 00:35:27.315
And then on the front end we
have F1, F2, and F4, I

00:35:27.315 --> 00:35:30.710
believe, is the largest
instance.

00:35:30.710 --> 00:35:37.960
So for most applications, the
defaults of F1 are fine, but

00:35:37.960 --> 00:35:42.430
for certain types of
applications it can be very

00:35:42.430 --> 00:35:46.150
advantageous to actually switch
to a higher class.

00:35:46.150 --> 00:35:51.320
And the reasons you would do
this, a very simple one is if

00:35:51.320 --> 00:35:54.790
you need to have a lot of
instance memory, like there's

00:35:54.790 --> 00:35:56.740
a lot of state that
you want to key.

00:35:56.740 --> 00:35:58.680
IEIN VALDEZ: Like I have a lot
of data structures that I'm

00:35:58.680 --> 00:35:59.400
storing locally.

00:35:59.400 --> 00:36:00.220
FRED SAUER: Exactly.

00:36:00.220 --> 00:36:03.150
So if you're running out of
memory, that's kind of an

00:36:03.150 --> 00:36:06.050
automatic trigger you need to be
in a higher instance class.

00:36:06.050 --> 00:36:09.260
And that's kind of
the easy case.

00:36:09.260 --> 00:36:14.120
The trickier one to understand
is the CPU one.

00:36:14.120 --> 00:36:19.930
So the way it works is when you
have an F1 instance, think

00:36:19.930 --> 00:36:26.160
of it as having a fraction of a
CPU, the way that we used to

00:36:26.160 --> 00:36:27.170
do time sharing.

00:36:27.170 --> 00:36:33.480
So in, say, a second, 1,000
milliseconds, you get time

00:36:33.480 --> 00:36:39.060
slices within that for your
request to be handled.

00:36:39.060 --> 00:36:41.280
If you have multithreading
turned on, you actually have

00:36:41.280 --> 00:36:43.280
multiple requests going
through your

00:36:43.280 --> 00:36:45.460
instance at the same time.

00:36:45.460 --> 00:36:49.030
But those requests, they run for
a little bit, and then you

00:36:49.030 --> 00:36:51.760
can think of them as being
paused, and then running again

00:36:51.760 --> 00:36:54.240
if they're on an F1 class.

00:36:54.240 --> 00:36:58.950
Now, if you have a pretty simple
application and you're

00:36:58.950 --> 00:37:01.510
not doing a lot of
CPU, most of it's

00:37:01.510 --> 00:37:03.330
what we call I/O bound.

00:37:03.330 --> 00:37:07.070
So you get a request, and you
immediately make a call to the

00:37:07.070 --> 00:37:08.420
data store, and then you're
just waiting for the

00:37:08.420 --> 00:37:10.050
datastore to return.

00:37:10.050 --> 00:37:13.050
And then you put together a
bunch of strings, template,

00:37:13.050 --> 00:37:14.770
then ship the result out.

00:37:14.770 --> 00:37:19.275
That's a very CPU un-intensive
application.

00:37:19.275 --> 00:37:21.400
IEIN VALDEZ: So F1 is great,
perfect for that.

00:37:21.400 --> 00:37:24.710
FRED SAUER: F1 is probably
just great for that.

00:37:24.710 --> 00:37:28.510
But if you're doing some
computation or you're waiting

00:37:28.510 --> 00:37:33.250
less, there's less I/O going
on, you may actually end up

00:37:33.250 --> 00:37:34.860
being CPU bound.

00:37:34.860 --> 00:37:38.980
That is, your application is
ready to do some calculations,

00:37:38.980 --> 00:37:42.390
and then it's actually idled for
a short while, and then it

00:37:42.390 --> 00:37:44.550
comes back alive,
and idled again.

00:37:44.550 --> 00:37:49.320
And what's happening is your
requests are thereby taking

00:37:49.320 --> 00:37:53.280
longer than they
really need to.

00:37:53.280 --> 00:37:56.200
So by switching to a higher
instance class, you actually

00:37:56.200 --> 00:37:59.580
get a fuller fraction
of the CPU.

00:37:59.580 --> 00:38:03.230
And that allows your request to
actually keep running until

00:38:03.230 --> 00:38:06.520
it's finished, and then
immediately return.

00:38:06.520 --> 00:38:09.270
And so depending on your
application, it may very well

00:38:09.270 --> 00:38:13.757
be that, if you switched to
a F4 front-end class, even

00:38:13.757 --> 00:38:17.130
though those instance hours are
more expensive, it may be

00:38:17.130 --> 00:38:19.430
cheaper to run your
application on

00:38:19.430 --> 00:38:20.355
that instance class.

00:38:20.355 --> 00:38:22.660
IEIN VALDEZ: Because I can get
more in that request versus

00:38:22.660 --> 00:38:25.630
maybe a bunch of F1s that would
take me to process that.

00:38:25.630 --> 00:38:30.160
FRED SAUER: Yeah, your request
will finish sooner, which

00:38:30.160 --> 00:38:33.770
means, in total, you need fewer
instances running to

00:38:33.770 --> 00:38:35.205
handle all your concurrent
requests.

00:38:35.205 --> 00:38:37.125
IEIN VALDEZ: Now, would Appstats
help me figure that

00:38:37.125 --> 00:38:37.830
out a little bit?

00:38:37.830 --> 00:38:39.320
Or is that--

00:38:39.320 --> 00:38:40.060
FRED SAUER: A little bit.

00:38:40.060 --> 00:38:41.100
IEIN VALDEZ: Because I'm trying
to figure out how do

00:38:41.100 --> 00:38:44.110
you actually figure that
out when I need to--

00:38:44.110 --> 00:38:46.420
or is it sort of just the
fiddling with it and sort of

00:38:46.420 --> 00:38:47.100
experimentation?

00:38:47.100 --> 00:38:51.790
FRED SAUER: I think really the
best way of doing this is to

00:38:51.790 --> 00:38:56.050
actually change the instance
hours in a controlled setting.

00:38:56.050 --> 00:38:58.900
So a load test is
a great example.

00:38:58.900 --> 00:39:03.790
Run a load test, and once the
load test is clean, it's error

00:39:03.790 --> 00:39:06.330
free, you figured out your
bottlenecks, and now the thing

00:39:06.330 --> 00:39:10.420
is just running very smoothly,
get one of these slow ramp-up

00:39:10.420 --> 00:39:14.210
load tests to your target,
say, that was 1,000 qps.

00:39:14.210 --> 00:39:17.650
And you let it run for
half an hour on F1s.

00:39:17.650 --> 00:39:20.390
And you let it do the same thing
over again you run it

00:39:20.390 --> 00:39:21.930
for half an hour on F4s.

00:39:21.930 --> 00:39:24.600
And just see what the instance
hours looks like, what the

00:39:24.600 --> 00:39:25.420
costs look like.

00:39:25.420 --> 00:39:27.130
IEIN VALDEZ: I could look at
the request latency, and

00:39:27.130 --> 00:39:29.275
probably see other things
just to sort of see--

00:39:29.275 --> 00:39:32.890
FRED SAUER: The cost might be
identical, but your clients

00:39:32.890 --> 00:39:36.010
might receive responses
more quickly.

00:39:36.010 --> 00:39:38.630
So your users are happier, which
means more usage to your

00:39:38.630 --> 00:39:41.040
site, maybe more traffic,
more revenue.

00:39:41.040 --> 00:39:42.150
IEIN VALDEZ: Very cool.

00:39:42.150 --> 00:39:44.930
FRED SAUER: So that's a great
feature that people

00:39:44.930 --> 00:39:46.430
need to look at.

00:39:46.430 --> 00:39:49.540
And also the Page Speed service,
which we launched at

00:39:49.540 --> 00:39:53.560
Google I/O, takes care of all
these static resource

00:39:53.560 --> 00:39:59.060
optimizations, rewriting HTML,
and CSS, and JavaScript, and

00:39:59.060 --> 00:40:00.520
just optimizing the resources.

00:40:00.520 --> 00:40:03.512
IEIN VALDEZ: So that's one
level further than the

00:40:03.512 --> 00:40:05.340
original caching we talked
about, where it actually

00:40:05.340 --> 00:40:09.410
introspects into your HTML, CSS,
JavaScript, and rewrites

00:40:09.410 --> 00:40:09.980
stuff for you.

00:40:09.980 --> 00:40:11.270
FRED SAUER: Exactly.

00:40:11.270 --> 00:40:12.600
It takes all the white
space out.

00:40:12.600 --> 00:40:14.410
It takes the comments out.

00:40:14.410 --> 00:40:17.120
It can actually change the
JavaScript and take these long

00:40:17.120 --> 00:40:21.760
variable names and squish them
down to little ones, making

00:40:21.760 --> 00:40:23.640
things more efficient.

00:40:23.640 --> 00:40:24.880
It has a number of default

00:40:24.880 --> 00:40:27.090
settings and default rewriters.

00:40:27.090 --> 00:40:29.150
But if you do some
experimentation, there's some

00:40:29.150 --> 00:40:33.020
optional ones that you can turn
on that will actually in

00:40:33.020 --> 00:40:36.940
line more JavaScript
more aggressively.

00:40:36.940 --> 00:40:41.940
So the way the Page Speed
service works is there's say

00:40:41.940 --> 00:40:45.900
20 rewriters, and each one has
a specific capability.

00:40:45.900 --> 00:40:48.540
There's a CSS rewriter that gets
rid of white space and

00:40:48.540 --> 00:40:55.550
comments and gets rid of CSS
that is orphaned, things that

00:40:55.550 --> 00:40:56.740
won't do anything.

00:40:56.740 --> 00:40:58.020
There's an HTML rewriter.

00:40:58.020 --> 00:40:59.920
There's a JavaScript rewriter.

00:40:59.920 --> 00:41:03.320
And so a number of those are
generally safe, and they're

00:41:03.320 --> 00:41:04.430
turned on by default.

00:41:04.430 --> 00:41:07.460
And there's some that are
potentially unsafe, depending

00:41:07.460 --> 00:41:08.730
on your application.

00:41:08.730 --> 00:41:11.240
And those you can turn on
manually after you've

00:41:11.240 --> 00:41:14.820
confirmed that they basically
don't hurt your application.

00:41:14.820 --> 00:41:18.620
And if you turn all the
aggressive options on, you can

00:41:18.620 --> 00:41:22.220
really get some nice
improvements as far as

00:41:22.220 --> 00:41:24.260
response times from
your application.

00:41:24.260 --> 00:41:26.210
IEIN VALDEZ: Very cool.

00:41:26.210 --> 00:41:27.810
Before you go to the next slide,
I just wanted to remind

00:41:27.810 --> 00:41:30.560
everyone that's watching us
live, we're going to the

00:41:30.560 --> 00:41:32.890
questions in a bit.

00:41:32.890 --> 00:41:34.990
So if you have specific
performance questions that you

00:41:34.990 --> 00:41:37.920
want Fred and I to talk about,
go ahead and put them in the

00:41:37.920 --> 00:41:38.850
Moderator link.

00:41:38.850 --> 00:41:40.270
Now would be a great
time to do that.

00:41:40.270 --> 00:41:42.030
And then, in a few
minutes, we'll

00:41:42.030 --> 00:41:43.066
go through the questions.

00:41:43.066 --> 00:41:44.472
FRED SAUER: Great.

00:41:44.472 --> 00:41:45.750
IEIN VALDEZ: Sorry, just
don't want people to

00:41:45.750 --> 00:41:46.195
miss out on the questions.

00:41:46.195 --> 00:41:47.140
FRED SAUER: We want more.

00:41:47.140 --> 00:41:48.180
We want more of your
questions.

00:41:48.180 --> 00:41:51.560
We're here to answer
them for you.

00:41:51.560 --> 00:41:55.510
Now one thing to not forget,
and I know the way that

00:41:55.510 --> 00:41:58.240
happens with presentations is
you hear a lot of this stuff,

00:41:58.240 --> 00:41:59.930
and you kind of remember the
first thing that was said, and

00:41:59.930 --> 00:42:01.120
the last thing that was said.

00:42:01.120 --> 00:42:04.100
So one of the last slides here,
I wanted to make sure

00:42:04.100 --> 00:42:06.300
would be one of the things you
would remember, which is to

00:42:06.300 --> 00:42:07.810
enable warmup requests.

00:42:07.810 --> 00:42:11.720
And the App Engine Scheduler
has this job of trying to

00:42:11.720 --> 00:42:14.550
predict what your traffic's
going to look like, say, a

00:42:14.550 --> 00:42:15.260
second from now.

00:42:15.260 --> 00:42:17.310
So it looks at all the traffic
that's coming in.

00:42:17.310 --> 00:42:20.470
It looks at all the requests
that are in flight and what

00:42:20.470 --> 00:42:23.510
the average latency or the
average response time of those

00:42:23.510 --> 00:42:26.520
requests is, and then it tries
to predict whether it will

00:42:26.520 --> 00:42:30.550
soon, momentarily, need
a new instance or not.

00:42:30.550 --> 00:42:37.270
But it can only warm up
instances in advance if it

00:42:37.270 --> 00:42:40.410
predicts so, or you tell it so
with Min Idle Instances, and

00:42:40.410 --> 00:42:43.140
only if you enable
warmup requests.

00:42:43.140 --> 00:42:47.410
Now, warmup requests are kind of
a special internal request

00:42:47.410 --> 00:42:50.230
that App Engine will send
to new instances of your

00:42:50.230 --> 00:42:53.580
application to make them ready
to serve live traffic.

00:42:53.580 --> 00:42:58.360
Without this, you'll have what
we call a cold instance, one

00:42:58.360 --> 00:43:01.770
that hasn't seen any traffic
yet, hasn't been initialized.

00:43:01.770 --> 00:43:04.490
And one of your user requests is
going to come to your site

00:43:04.490 --> 00:43:06.970
and say, I'd like the
homepage, please.

00:43:06.970 --> 00:43:09.730
This request will go to this
cold instance, and the request

00:43:09.730 --> 00:43:13.360
is going to have to sit there
and wait for your application

00:43:13.360 --> 00:43:14.380
to initialize.

00:43:14.380 --> 00:43:17.940
Maybe you fetch some global
data, and you have to make a

00:43:17.940 --> 00:43:20.130
few round trips to the datastore
and collect a few

00:43:20.130 --> 00:43:23.310
things and kind of get your
house of cards in order before

00:43:23.310 --> 00:43:24.970
you're able to serve
that response.

00:43:24.970 --> 00:43:27.740
That's all time that your
client is waiting.

00:43:27.740 --> 00:43:31.620
When you have a warmup request,
App Engine can,

00:43:31.620 --> 00:43:35.330
without affecting user latency,
send a special little

00:43:35.330 --> 00:43:37.530
request to your application.

00:43:37.530 --> 00:43:39.400
Your application can initialize

00:43:39.400 --> 00:43:40.890
quietly behind the scenes.

00:43:40.890 --> 00:43:44.280
And then when it's all ready to
go, it's nice and hot, then

00:43:44.280 --> 00:43:47.750
the first user request comes
along and hits that instance.

00:43:47.750 --> 00:43:50.640
So be sure to enable
warmup requests.

00:43:50.640 --> 00:43:54.300
When you have them, you'll see
these requests in the log

00:43:54.300 --> 00:43:55.550
/_ah/warmup.

00:43:57.740 --> 00:44:00.440
There's some default behavior
that you can read.

00:44:00.440 --> 00:44:03.380
Particularly, this is enabled
by default in Java, but

00:44:03.380 --> 00:44:05.050
disabled for Python.

00:44:05.050 --> 00:44:08.640
So in Python, you definitely
want to turn that on manually.

00:44:08.640 --> 00:44:12.260
And then there's some ways to
override the servlet handler

00:44:12.260 --> 00:44:14.832
there for Java applications.

00:44:14.832 --> 00:44:16.860
Now, I said that was
the last thing.

00:44:16.860 --> 00:44:22.210
There's one little tiny tip
here, which is avoid the

00:44:22.210 --> 00:44:25.160
default error message pages.

00:44:25.160 --> 00:44:28.070
When you have problems with
your application, you can

00:44:28.070 --> 00:44:32.480
define your own error pages,
both in Java and Python.

00:44:32.480 --> 00:44:36.040
It's pretty simple, just a few
lines of configuration.

00:44:36.040 --> 00:44:38.080
And you pointed at a
nice pretty file.

00:44:38.080 --> 00:44:39.495
IEIN VALDEZ: So, you can make
a beautiful error page.

00:44:39.495 --> 00:44:41.630
FRED SAUER: You make a
beautiful error page.

00:44:41.630 --> 00:44:44.970
Now maybe one with kind of a
robot that's all broken in

00:44:44.970 --> 00:44:47.421
parts or something like that.

00:44:47.421 --> 00:44:48.380
IEIN VALDEZ: Very cool.

00:44:48.380 --> 00:44:51.630
FRED SAUER: So I think we have
some questions lined up.

00:44:51.630 --> 00:44:52.970
IEIN VALDEZ: Yep, there
are some questions.

00:44:52.970 --> 00:44:56.320
So I'm going to go ahead and go
to the Moderator, and I'll

00:44:56.320 --> 00:44:58.950
just read through the ones we
have, and we'll try to answer

00:44:58.950 --> 00:45:01.400
them as best we can.

00:45:01.400 --> 00:45:04.610
So I'll just read them
out to you, Fred.

00:45:04.610 --> 00:45:08.170
So here's one, from DP in Italy,
which is, "Do task

00:45:08.170 --> 00:45:09.650
queues influence performance?

00:45:09.650 --> 00:45:12.340
Any tips about task queue
performances?"

00:45:12.340 --> 00:45:15.260
FRED SAUER: There's a lot to
say about task queues.

00:45:18.880 --> 00:45:22.510
The way we kind of refer to
requests, there's two types.

00:45:22.510 --> 00:45:25.700
We have online requests
and offline.

00:45:25.700 --> 00:45:29.150
Online is anything user facing,
so a client coming in

00:45:29.150 --> 00:45:31.300
making a live request.

00:45:31.300 --> 00:45:34.560
Kind of think of it as a live
body or a hot Android device

00:45:34.560 --> 00:45:35.600
behind that request.

00:45:35.600 --> 00:45:38.000
And then offline requests are
all the background stuff.

00:45:38.000 --> 00:45:42.670
So that's a task
queue in CRON.

00:45:42.670 --> 00:45:47.870
And the App Engine scheduler
treats online requests and

00:45:47.870 --> 00:45:49.430
off-line requests a little
bit separately.

00:45:49.430 --> 00:45:54.390
It knows that you might have
offline requests that are a

00:45:54.390 --> 00:45:56.740
lot slower than online ones.

00:45:56.740 --> 00:45:59.140
In fact, if you have any kind of
slow operation, you should

00:45:59.140 --> 00:46:02.200
probably move it to a task
queue so that your online

00:46:02.200 --> 00:46:04.840
requests stay nice and fast.

00:46:04.840 --> 00:46:08.500
But App Engine will treat those
two classes of requests

00:46:08.500 --> 00:46:09.340
differently.

00:46:09.340 --> 00:46:10.840
In fact, it will look
at the different

00:46:10.840 --> 00:46:11.980
queues that you have.

00:46:11.980 --> 00:46:15.770
So if you have a named queue Fu
and another queue named Bar

00:46:15.770 --> 00:46:18.430
and they have different
performance characteristics,

00:46:18.430 --> 00:46:23.460
App Engine scheduler will take
care of them separately.

00:46:23.460 --> 00:46:27.180
There are a number of knobs
that you can tune in the

00:46:27.180 --> 00:46:32.170
queues.yaml in Python or the App
Engine queue.xml in Java.

00:46:32.170 --> 00:46:37.420
You can configure the maximum
rate of each queue, I think,

00:46:37.420 --> 00:46:39.750
up to 100 requests per second.

00:46:39.750 --> 00:46:40.500
IEIN VALDEZ: 100 is
the max, yeah.

00:46:40.500 --> 00:46:43.770
FRED SAUER: And then you can
also configure, I believe, the

00:46:43.770 --> 00:46:45.500
number of concurrent requests.

00:46:45.500 --> 00:46:46.000
At least--

00:46:46.000 --> 00:46:46.920
IEIN VALDEZ: There's a rate.

00:46:46.920 --> 00:46:48.470
There's a rate, and
then there's a

00:46:48.470 --> 00:46:49.935
bucket size, and something.

00:46:49.935 --> 00:46:53.420
FRED SAUER: Yeah, buckets
and refill size.

00:46:53.420 --> 00:46:56.620
We have a nice link to a
Wikipedia article about bucket

00:46:56.620 --> 00:46:59.180
counters and how they work.

00:46:59.180 --> 00:47:02.800
But the main thing there is
you can crank up the rate.

00:47:02.800 --> 00:47:05.050
IEIN VALDEZ: And I'd also say
I think we did a couple of

00:47:05.050 --> 00:47:08.040
Hangouts recently specifically
on task queues.

00:47:08.040 --> 00:47:09.780
Amy did one, and
then I think--

00:47:09.780 --> 00:47:10.810
FRED SAUER: That
was a good one.

00:47:10.810 --> 00:47:12.350
IEIN VALDEZ: Danny
did one as well.

00:47:12.350 --> 00:47:14.340
So there's some good-- you
should look at the Hangout

00:47:14.340 --> 00:47:17.035
resources recently that we've
done specifically to task

00:47:17.035 --> 00:47:17.992
queues I think that
were pretty cool.

00:47:17.992 --> 00:47:20.390
FRED SAUER: But I think to
come back to the main

00:47:20.390 --> 00:47:26.010
question, you shouldn't worry
about tasks influencing the

00:47:26.010 --> 00:47:30.110
performance of your
online requests.

00:47:30.110 --> 00:47:31.000
IEIN VALDEZ: So they're
sort of orthogonal.

00:47:31.000 --> 00:47:35.370
FRED SAUER: Yeah, so what you do
in the background in batch

00:47:35.370 --> 00:47:39.426
shouldn't negatively impact
the user experience.

00:47:42.140 --> 00:47:46.740
In fact, I would also say
the reverse that--

00:47:46.740 --> 00:47:50.070
or sorry, say something
different, which is anything

00:47:50.070 --> 00:47:52.730
that is slow in your
online requests.

00:47:52.730 --> 00:47:55.890
So if you have a request that
takes a long time, you should

00:47:55.890 --> 00:48:00.270
almost always see if you can
move that, perhaps to a task

00:48:00.270 --> 00:48:02.380
and respond back to the
client more quickly.

00:48:02.380 --> 00:48:05.150
Because what you want on
the front end is really

00:48:05.150 --> 00:48:07.300
performance requests,
and on the back end.

00:48:07.300 --> 00:48:10.770
You want these slow
batch things.

00:48:10.770 --> 00:48:11.790
Hope that answers
the question.

00:48:11.790 --> 00:48:13.220
IEIN VALDEZ: OK, cool.

00:48:13.220 --> 00:48:13.800
Yeah, all right.

00:48:13.800 --> 00:48:15.290
Let's go--

00:48:15.290 --> 00:48:17.150
there's a couple of new
ones popped up here.

00:48:17.150 --> 00:48:19.250
One that we'll just deal with
real quick, which is from

00:48:19.250 --> 00:48:20.860
Anonymous/Other.

00:48:20.860 --> 00:48:23.340
"Any plans to create cloud
endpoint generation scripts

00:48:23.340 --> 00:48:24.780
for Python with ProtoRPC?"

00:48:24.780 --> 00:48:27.570
So this is just a random App
Engine question, but it's

00:48:27.570 --> 00:48:29.330
related to Cloud endpoints.

00:48:29.330 --> 00:48:30.820
I don't know the answer
to that question.

00:48:30.820 --> 00:48:34.660
Dan Holevoet, who is running the
Trusted Tester Program for

00:48:34.660 --> 00:48:37.440
Cloud Endpoints would be happy
to answer that question.

00:48:37.440 --> 00:48:40.720
So if you're not already in the
Trusted Tester Program for

00:48:40.720 --> 00:48:44.180
Cloud Endpoints, go ahead
and join, and Dan

00:48:44.180 --> 00:48:46.300
can answer your question.

00:48:46.300 --> 00:48:48.650
There's a whole forum
set up for that.

00:48:48.650 --> 00:48:50.150
Good question.

00:48:50.150 --> 00:48:50.870
OK, here we go.

00:48:50.870 --> 00:48:54.540
Here's one from Nelson
in San Francisco.

00:48:54.540 --> 00:48:56.450
This is a Python one.

00:48:56.450 --> 00:49:00.280
"How does the number of WSGI
app instances affect

00:49:00.280 --> 00:49:01.820
performance?

00:49:01.820 --> 00:49:05.460
Is it generally better to try
to bundle URL routes into a

00:49:05.460 --> 00:49:08.300
fewer number of apps or split
URL routes across multiple app

00:49:08.300 --> 00:49:09.455
instances?"

00:49:09.455 --> 00:49:11.580
FRED SAUER: Across multiple
app instances?

00:49:11.580 --> 00:49:18.950
Oh, I would say that doesn't
really matter.

00:49:18.950 --> 00:49:22.270
What does matter is perhaps the
overall memory footprint

00:49:22.270 --> 00:49:24.300
of your instance.

00:49:24.300 --> 00:49:28.610
So if you're duplicating some
data across those app

00:49:28.610 --> 00:49:33.740
instances, that's not going to
help, although in most cases

00:49:33.740 --> 00:49:36.060
it probably won't matter,
because you're probably not

00:49:36.060 --> 00:49:43.430
hitting an instance threshold of
your F1 class or F2 class.

00:49:43.430 --> 00:49:48.100
These types of tweaks are
unlikely to really help.

00:49:48.100 --> 00:49:51.450
What you do want to do is
absolutely make sure that you

00:49:51.450 --> 00:49:56.150
have Thread Safe set to true,
so you have multithreading

00:49:56.150 --> 00:49:57.830
enabled for Python.

00:49:57.830 --> 00:50:00.370
That only works in Python
2.7, of course.

00:50:00.370 --> 00:50:03.880
You should be using Python 2.7,
which is better at of

00:50:03.880 --> 00:50:05.130
scheduling.

00:50:08.190 --> 00:50:09.240
IEIN VALDEZ: Yeah, I agree.

00:50:09.240 --> 00:50:11.640
I think that you don't really
gain anything by it.

00:50:11.640 --> 00:50:12.900
FRED SAUER: Don't
worry about it.

00:50:12.900 --> 00:50:16.800
Organize your code, especially
in Python, for the way that

00:50:16.800 --> 00:50:18.760
makes sense and productive
for you.

00:50:18.760 --> 00:50:22.080
The big things to worry about
are enable multithreading

00:50:22.080 --> 00:50:26.450
using Python 2.7, using the
task queue where you can.

00:50:26.450 --> 00:50:29.930
The really big hits that you
can do are those datastore

00:50:29.930 --> 00:50:34.110
performance tips, like doing
fetches instead of queries.

00:50:34.110 --> 00:50:39.420
And wherever you're making a
call to another App Engine

00:50:39.420 --> 00:50:44.160
back-end service, whether it's
memcache, or datastore, or

00:50:44.160 --> 00:50:47.950
even URL fetch, do those
asynchronously, if you can, if

00:50:47.950 --> 00:50:51.480
you're doing multiple, so that
you can do them in parallel.

00:50:51.480 --> 00:50:54.180
If you need to fetch five
things from another web

00:50:54.180 --> 00:50:58.630
service, issue those five calls
via an async call, and

00:50:58.630 --> 00:50:59.840
then wait for the response.

00:50:59.840 --> 00:51:03.050
And all five will happen at once
rather than sequentially.

00:51:03.050 --> 00:51:04.852
Those are the big wins.

00:51:04.852 --> 00:51:08.020
IEIN VALDEZ: OK, here's another
question from Nelson.

00:51:08.020 --> 00:51:10.390
This is sort of a general
purpose question, which is,

00:51:10.390 --> 00:51:13.970
"Is it possible for App Engine
to release global stats for

00:51:13.970 --> 00:51:17.350
some benchmarks to help drive
design and modeling of

00:51:17.350 --> 00:51:18.050
applications?

00:51:18.050 --> 00:51:21.290
So, for example, what's the
average upper bound for entity

00:51:21.290 --> 00:51:23.140
write opps?

00:51:23.140 --> 00:51:27.390
Is 20 write opps average for an
entity with end properties?

00:51:27.390 --> 00:51:33.130
Is 40 too high?" So, yeah, I
don't know what the guidance

00:51:33.130 --> 00:51:35.050
is on like specific bounds.

00:51:35.050 --> 00:51:38.280
FRED SAUER: Yeah, so these sorts
of things really depend

00:51:38.280 --> 00:51:41.112
on the types of application
you have.

00:51:41.112 --> 00:51:45.340
You can take some hints from our
examples and the way are

00:51:45.340 --> 00:51:46.620
our APIs are going.

00:51:46.620 --> 00:51:52.760
So if you look at, in Python the
DB API versus NDB, you see

00:51:52.760 --> 00:51:58.400
that in NDB, the newer API, we
support structured properties,

00:51:58.400 --> 00:52:01.550
which are kind of nested
properties within a single

00:52:01.550 --> 00:52:03.860
entity group.

00:52:03.860 --> 00:52:08.900
I think we've done a better job
now at telling you to make

00:52:08.900 --> 00:52:11.490
sure that your properties are
not indexed by default,

00:52:11.490 --> 00:52:14.100
because you have the extra
costs that the datastore

00:52:14.100 --> 00:52:16.260
writes every time you update
the properties.

00:52:16.260 --> 00:52:19.820
We've added support for
projection queries so that you

00:52:19.820 --> 00:52:22.690
don't have to fetch all the
properties from the datastore.

00:52:22.690 --> 00:52:27.110
So you see some strong hints
there that more properties are

00:52:27.110 --> 00:52:29.870
definitely expensive.

00:52:29.870 --> 00:52:32.380
We have support for list
properties, which is a way of

00:52:32.380 --> 00:52:35.480
kind of efficiently
packing things.

00:52:35.480 --> 00:52:38.820
So I'm not sure that
those statistics

00:52:38.820 --> 00:52:40.750
would be that useful.

00:52:40.750 --> 00:52:46.100
But the practical advice of
fewer properties, fetch only

00:52:46.100 --> 00:52:47.590
what you need.

00:52:47.590 --> 00:52:48.940
Do it as efficiently
as possible.

00:52:48.940 --> 00:52:51.040
Pick your keys.

00:52:51.040 --> 00:52:53.690
Turn off indexes for things
you don't need.

00:52:53.690 --> 00:52:57.580
All of those things will have
fairly big impacts.

00:52:57.580 --> 00:53:00.205
But at the end of the day, if
you need another property on

00:53:00.205 --> 00:53:02.150
an entity, you should have it.

00:53:02.150 --> 00:53:08.470
What you should be wary of is
lots and lots of properties,

00:53:08.470 --> 00:53:10.670
lots and lots of indexes.

00:53:10.670 --> 00:53:13.890
If you get anywhere close
to the limits of--

00:53:13.890 --> 00:53:17.210
I think you can have 200
custom indexes on an

00:53:17.210 --> 00:53:19.760
application or something like
that, if you're anywhere even

00:53:19.760 --> 00:53:24.770
in the ballpark of that, you're
probably not organizing

00:53:24.770 --> 00:53:27.720
your application the
way you want.

00:53:27.720 --> 00:53:30.080
You may actually have an
application that's more suited

00:53:30.080 --> 00:53:34.000
for using Cloud SQL rather than
the datastore, which you

00:53:34.000 --> 00:53:34.820
can do in App Engine.

00:53:34.820 --> 00:53:38.250
You can use a SQL instance
that will allow you the

00:53:38.250 --> 00:53:40.620
relational queries and the
indexes that you need.

00:53:40.620 --> 00:53:42.600
IEIN VALDEZ: Right.

00:53:42.600 --> 00:53:43.120
OK.

00:53:43.120 --> 00:53:43.850
Couple--

00:53:43.850 --> 00:53:47.090
let's say we have about five
minutes, so we have a couple

00:53:47.090 --> 00:53:48.830
short ones here, and then
there's kind of a bigger one

00:53:48.830 --> 00:53:50.660
we can deal with at the end.

00:53:50.660 --> 00:53:53.140
One is, "Should you be
doing async calls in

00:53:53.140 --> 00:53:59.312
deferred/offline tasks too?"

00:53:59.312 --> 00:54:03.790
FRED SAUER: If it allows you
to do things in parallel,

00:54:03.790 --> 00:54:05.880
absolutely, yes.

00:54:05.880 --> 00:54:10.330
So when you can make two URL
fetch calls at once instead of

00:54:10.330 --> 00:54:15.610
after each other sequentially,
or you can do a batch get from

00:54:15.610 --> 00:54:19.280
memcache to fetch three keys
instead of fetching one after

00:54:19.280 --> 00:54:23.450
the other, those are
always beneficial.

00:54:23.450 --> 00:54:25.310
The number of instance
hours that your

00:54:25.310 --> 00:54:27.770
application needs is--

00:54:27.770 --> 00:54:30.850
in an ideal world, it's very
simple to calculate.

00:54:30.850 --> 00:54:34.120
You look at the average response
time for a request.

00:54:34.120 --> 00:54:36.580
Let's say it's 100
milliseconds.

00:54:36.580 --> 00:54:39.030
And if you're in a
single-threaded environment,

00:54:39.030 --> 00:54:41.930
that means you can handle
10 requests

00:54:41.930 --> 00:54:44.360
per second, per instance.

00:54:44.360 --> 00:54:47.280
Now, with multithreading, you
can do a little bit more.

00:54:47.280 --> 00:54:52.600
In the real world, your input
traffic is a little more--

00:54:52.600 --> 00:54:55.160
what we call stochastic
or random.

00:54:55.160 --> 00:54:59.120
So requests don't come in like
a heartbeat, where every 100

00:54:59.120 --> 00:55:01.310
milliseconds you have a
new user coming in.

00:55:01.310 --> 00:55:03.880
They come in kind of
bursts, and there's

00:55:03.880 --> 00:55:05.050
some peaks and valleys.

00:55:05.050 --> 00:55:08.400
And so the schedule has to
deal with kind of those

00:55:08.400 --> 00:55:11.430
inefficiencies, and your
application does.

00:55:11.430 --> 00:55:14.540
But your goal as a developer
is really to make your

00:55:14.540 --> 00:55:19.470
requests finish as quickly
as possible.

00:55:19.470 --> 00:55:21.320
That means doing things in
parallel, doing things

00:55:21.320 --> 00:55:24.470
efficiently, and the faster you
get done, the happier your

00:55:24.470 --> 00:55:26.420
users will be, the fewer
instance hours you will need,

00:55:26.420 --> 00:55:28.830
the more efficient the
scheduler can be.

00:55:28.830 --> 00:55:31.120
IEIN VALDEZ: Cool.

00:55:31.120 --> 00:55:34.660
OK here's a question from
Joaquin in Sweden, which is,

00:55:34.660 --> 00:55:40.140
"Are there any gains in speed to
be made by rearranging the

00:55:40.140 --> 00:55:43.776
filters of a merge/join Query?"
I don't know the

00:55:43.776 --> 00:55:45.498
answer to this one, actually.

00:55:45.498 --> 00:55:48.430
FRED SAUER: There are--

00:55:48.430 --> 00:55:50.900
so I'm probably not the best
person to answer that.

00:55:50.900 --> 00:55:57.760
But I will say one thing that
would matter, which is in the

00:55:57.760 --> 00:56:01.070
Dev App server when you run
different queries, it will

00:56:01.070 --> 00:56:04.560
automatically update your
index.yaml or your App Engine

00:56:04.560 --> 00:56:08.640
indexes.xml, and it will put
all the custom indexes that

00:56:08.640 --> 00:56:09.790
you need in there.

00:56:09.790 --> 00:56:13.260
Now, each of those indexes has
a write cost associated with

00:56:13.260 --> 00:56:17.220
it for all the properties that
are referenced in that index.

00:56:17.220 --> 00:56:21.860
If you set up your filters and
your queries in such a way

00:56:21.860 --> 00:56:27.180
that you somehow are able to
reuse some of the indexes,

00:56:27.180 --> 00:56:30.970
then any time you do a write
to any of those entities

00:56:30.970 --> 00:56:34.780
affected, you would have fewer
writes, and those costs could

00:56:34.780 --> 00:56:38.840
potentially be significant
or at least noticeable.

00:56:38.840 --> 00:56:44.320
I'm not sure that it matters
too much to rearrange the

00:56:44.320 --> 00:56:48.980
filter operations within a
single query, but it certainly

00:56:48.980 --> 00:56:51.780
helps to think globally about
the types of indexes that you

00:56:51.780 --> 00:56:57.510
have and to see where you can
have reuse and have fewer

00:56:57.510 --> 00:56:59.645
index writes.

00:56:59.645 --> 00:57:01.840
IEIN VALDEZ: Yeah, for sure.

00:57:01.840 --> 00:57:05.040
And by the way, this is a great
question to post on

00:57:05.040 --> 00:57:07.050
Stack Overflow.

00:57:07.050 --> 00:57:10.740
So a lot of our team actually
monitors Stack Overflow as

00:57:10.740 --> 00:57:11.830
well as some of the
engineering team.

00:57:11.830 --> 00:57:16.680
So if you're not satisfied with
this answer, put it on

00:57:16.680 --> 00:57:19.440
Stack Overflow using the
Google App Engine tag.

00:57:19.440 --> 00:57:22.150
FRED SAUER: Yeah, that's a
good one for an in-depth

00:57:22.150 --> 00:57:23.430
analysis discussion.

00:57:23.430 --> 00:57:25.570
IEIN VALDEZ: Yeah, this
is a really good one

00:57:25.570 --> 00:57:27.560
to talk about there.

00:57:27.560 --> 00:57:29.175
So we have time for
one last question.

00:57:31.720 --> 00:57:34.370
Basically, there's a discussion
in the public App

00:57:34.370 --> 00:57:38.170
Engine group related to Deadline
Exceeded Exceptions

00:57:38.170 --> 00:57:40.660
for big jar files.

00:57:40.660 --> 00:57:43.300
So I think this is
like loading.

00:57:43.300 --> 00:57:48.350
And the gist of the question
is, well, what are the

00:57:48.350 --> 00:57:48.720
conclusions?

00:57:48.720 --> 00:57:50.850
And I guess you have to look at
the thread, and we probably

00:57:50.850 --> 00:57:52.230
don't have time to do
that right now.

00:57:52.230 --> 00:57:55.860
But the subject is Java instance
startup time, and I

00:57:55.860 --> 00:57:59.840
think it's related to having big
jar files and some errors

00:57:59.840 --> 00:58:02.532
that that can cause you upon
loading requests and so forth.

00:58:02.532 --> 00:58:06.000
FRED SAUER: I think this is
actually probably another good

00:58:06.000 --> 00:58:08.780
question for Stack Overflow.

00:58:08.780 --> 00:58:13.470
This is also a question where
the answer six months ago

00:58:13.470 --> 00:58:14.370
probably would have
been a little

00:58:14.370 --> 00:58:15.650
different than it is today.

00:58:15.650 --> 00:58:19.120
We've done a number of things
to really help Java

00:58:19.120 --> 00:58:23.910
applications out during their
startup and initialization.

00:58:23.910 --> 00:58:27.710
It still remains true that the
fewer jar files you have, the

00:58:27.710 --> 00:58:30.480
less work that you do in
initialization, the more that

00:58:30.480 --> 00:58:32.990
you turn on warmup requests,
these things will help.

00:58:35.930 --> 00:58:39.540
App Engine is a little bit
different from a lot of

00:58:39.540 --> 00:58:44.790
infrastructure that many of us
are used to for on premise and

00:58:44.790 --> 00:58:50.320
infrastructure as a
service in that

00:58:50.320 --> 00:58:51.510
there's a lot of popular--

00:58:51.510 --> 00:58:52.260
let me say it this way.

00:58:52.260 --> 00:58:56.360
There's a lot of popular Java
frameworks that were built and

00:58:56.360 --> 00:59:01.060
designed when the way to run a
web service or an application

00:59:01.060 --> 00:59:05.880
was to have a number
of servers,

00:59:05.880 --> 00:59:07.490
let's say five servers.

00:59:07.490 --> 00:59:11.690
And they all start up, and it's
OK for them to take 5, 10

00:59:11.690 --> 00:59:14.290
minutes to physically start up
all the way up and running,

00:59:14.290 --> 00:59:17.120
and then to leave them running
for days or weeks and do

00:59:17.120 --> 00:59:18.370
occasional maintenance
windows.

00:59:18.370 --> 00:59:19.760
You know, on Sunday
night, we'll shut

00:59:19.760 --> 00:59:21.080
down for a few hours.

00:59:21.080 --> 00:59:23.260
App Engine is a very different
environment, where we're

00:59:23.260 --> 00:59:25.510
constantly spinning up new
instances to handle new

00:59:25.510 --> 00:59:30.890
traffic, shutting others down,
more than 100,000 applications

00:59:30.890 --> 00:59:35.200
on App Engine right now that are
all kind of vying for the

00:59:35.200 --> 00:59:37.450
same shared resources.

00:59:37.450 --> 00:59:40.750
So the engineering trade-offs
are a little bit different.

00:59:40.750 --> 00:59:45.690
We're looking for very fast
startup so that we can adjust

00:59:45.690 --> 00:59:49.160
the scheduler in a very
fine-grained manner to adjust

00:59:49.160 --> 00:59:50.410
to your traffic.

00:59:52.530 --> 00:59:55.020
Now, if you have one of these
applications that uses these

00:59:55.020 --> 00:59:57.770
kind of heavier frameworks
that just need longer

00:59:57.770 --> 01:00:00.530
initialization time to
really come from--

01:00:00.530 --> 01:00:06.250
I don't want to say an era of,
but a time not that long ago,

01:00:06.250 --> 01:00:10.300
where these are the types of
framework that we used, App

01:00:10.300 --> 01:00:12.380
Engine does have some
knobs for you.

01:00:12.380 --> 01:00:15.520
Those performance-tuning knobs
I mentioned before, there's

01:00:15.520 --> 01:00:17.620
that Min Idle Instances.

01:00:17.620 --> 01:00:20.760
And if you enable warmup
requests, and you just crank

01:00:20.760 --> 01:00:24.690
up the Min Idle Instances, maybe
even just a little bit,

01:00:24.690 --> 01:00:27.520
App Engine will always keep
however many you specify

01:00:27.520 --> 01:00:31.880
instances ready that are
pre-warmed up, ready to take

01:00:31.880 --> 01:00:33.970
on new traffic, not having
to wait for the

01:00:33.970 --> 01:00:35.220
initialization time.

01:00:37.700 --> 01:00:41.790
In the extreme case, there's
kind of an advance tip that I

01:00:41.790 --> 01:00:44.250
can go into.

01:00:44.250 --> 01:00:49.130
This is not for everyone, but
this is one technique

01:00:49.130 --> 01:00:51.850
that you can use.

01:00:51.850 --> 01:00:54.850
If you have an application that
really wants to do a lot

01:00:54.850 --> 01:01:00.010
of startup initialization, and
it's going to take you even

01:01:00.010 --> 01:01:03.730
more than the 60 seconds, and
you've exhausted Min Idle

01:01:03.730 --> 01:01:08.580
Instances, for those Java
applications, be sure you're

01:01:08.580 --> 01:01:13.250
trying the F4 front-end
instances or even starting up

01:01:13.250 --> 01:01:15.330
maybe a back-end instance in
doing a B8 because it will

01:01:15.330 --> 01:01:17.870
give you more CPUs, start
up more quickly.

01:01:17.870 --> 01:01:21.700
If you've exhausted all of that,
there is a technique

01:01:21.700 --> 01:01:24.540
that you can use, which is
when you've received your

01:01:24.540 --> 01:01:30.360
first request, do some of
the initialization.

01:01:30.360 --> 01:01:33.160
Let's say do half the
work that you can.

01:01:33.160 --> 01:01:36.830
And you set a little global flag
and a static variable and

01:01:36.830 --> 01:01:39.340
say, OK, I've done the first
half of my initialization.

01:01:39.340 --> 01:01:41.730
And then instead of returning
the response, because you know

01:01:41.730 --> 01:01:45.380
you're not fully initialized,
you actually send back a 302

01:01:45.380 --> 01:01:48.140
redirect to the client, and you
tell it to go back to the

01:01:48.140 --> 01:01:51.130
exact same URL that
it just requested.

01:01:51.130 --> 01:01:54.850
So that client gets the redirect
response, and it will

01:01:54.850 --> 01:01:57.520
just send that request again.

01:01:57.520 --> 01:01:59.800
And hopefully, it will hit a
different instance that's

01:01:59.800 --> 01:02:02.410
already warm and the client's
taken care of.

01:02:02.410 --> 01:02:04.670
If it's unlucky enough to hit
the same instance, that's

01:02:04.670 --> 01:02:05.770
still all right.

01:02:05.770 --> 01:02:08.780
Now your instance has gotten the
second request, but it's

01:02:08.780 --> 01:02:12.800
had those 60 seconds to do the
first half of the warmup.

01:02:12.800 --> 01:02:14.440
You look at the static variable,
you go, oh, I need

01:02:14.440 --> 01:02:16.860
to do the second half of
my initialization.

01:02:16.860 --> 01:02:19.085
You do that, and then you
serve your response.

01:02:19.085 --> 01:02:20.450
IEIN VALDEZ: That's tricky.

01:02:20.450 --> 01:02:23.900
FRED SAUER: So it's is a complex
case, but what we're

01:02:23.900 --> 01:02:25.760
really doing here is we're
saying, well, the

01:02:25.760 --> 01:02:29.530
initialization time of your
application, because of the

01:02:29.530 --> 01:02:33.530
frameworks you're using and what
you're doing, if you add

01:02:33.530 --> 01:02:37.360
that plus the time it takes to
handle an individual response,

01:02:37.360 --> 01:02:41.230
those two together, if they
exceed that 60-second limit on

01:02:41.230 --> 01:02:46.450
an F4 class instance, then this
is a technique to break

01:02:46.450 --> 01:02:47.540
those apart.

01:02:47.540 --> 01:02:50.220
The warmup request tries to
break up the first part from

01:02:50.220 --> 01:02:51.400
the second.

01:02:51.400 --> 01:02:53.530
This kind of advanced technique
I described is a way

01:02:53.530 --> 01:02:56.710
to take that initial part and
even break that further down

01:02:56.710 --> 01:02:57.960
into pieces.

01:02:57.960 --> 01:03:00.195
So those are tricks
that you can use.

01:03:00.195 --> 01:03:01.190
IEIN VALDEZ: Very awesome.

01:03:01.190 --> 01:03:04.060
FRED SAUER: But higher
instance classes can

01:03:04.060 --> 01:03:05.950
definitely help there.

01:03:05.950 --> 01:03:06.695
That's what they're there for.

01:03:06.695 --> 01:03:08.280
IEIN VALDEZ: Perfect.

01:03:08.280 --> 01:03:09.045
Awesome, I think we're
out of time.

01:03:09.045 --> 01:03:10.170
FRED SAUER: OK.

01:03:10.170 --> 01:03:11.395
Well, thanks for--

01:03:11.395 --> 01:03:12.370
IEIN VALDEZ: Thank you
for having me.

01:03:12.370 --> 01:03:13.270
FRED SAUER: I enjoyed
it, yeah.

01:03:13.270 --> 01:03:14.900
And thank you for all
your questions.

01:03:14.900 --> 01:03:17.165
Really appreciate it and
hope to be back soon.

01:03:17.165 --> 01:03:20.010
IEIN VALDEZ: OK, and we'll see
you next week, and be sure to

01:03:20.010 --> 01:03:21.840
check out Stack Overflow
as well.

01:03:21.840 --> 01:03:24.810
That's a great resource for
questions and answers.

01:03:24.810 --> 01:03:25.660
FRED SAUER: Yep,
we're on there.

01:03:25.660 --> 01:04:00.100
[MUSIC PLAYING]

