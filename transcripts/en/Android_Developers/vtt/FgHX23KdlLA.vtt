WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:05.215
[MUSIC PLAYING]

00:00:05.215 --> 00:00:06.590
SPEAKER 1: In the
previous video,

00:00:06.590 --> 00:00:09.460
we saw just how important
low latency is when creating

00:00:09.460 --> 00:00:11.080
interactive audio experiences.

00:00:11.080 --> 00:00:14.350
But how can you actually
achieve this in your app?

00:00:14.350 --> 00:00:16.930
In this video, I'll show
you how the Oboe library

00:00:16.930 --> 00:00:19.480
helps you to create a
low latency audio stream

00:00:19.480 --> 00:00:21.340
for playing sound.

00:00:21.340 --> 00:00:22.930
You can play sound
through a number

00:00:22.930 --> 00:00:26.590
of different audio devices, such
as the built-in speakers, wired

00:00:26.590 --> 00:00:30.700
headphones, USB audio
devices, or over Bluetooth.

00:00:30.700 --> 00:00:32.770
An audio stream is
used to move data

00:00:32.770 --> 00:00:36.610
from your app to an audio
device so that it can be played.

00:00:36.610 --> 00:00:40.120
To create an audio stream, we
use an audio stream builder.

00:00:40.120 --> 00:00:42.870
This allows us to set
properties on the stream.

00:00:42.870 --> 00:00:45.880
It's best to leave most
properties unspecified to allow

00:00:45.880 --> 00:00:50.050
Oboe to pick the optimal values
for the default audio device.

00:00:50.050 --> 00:00:53.680
However, to create a stream with
the lowest possible latency,

00:00:53.680 --> 00:00:57.490
there are a few properties
which we should always set.

00:00:57.490 --> 00:01:00.280
The performance mode should
be set to low latency,

00:01:00.280 --> 00:01:03.370
and the sharing mode
should be set to exclusive.

00:01:03.370 --> 00:01:05.300
Once the stream
properties have been set,

00:01:05.300 --> 00:01:07.750
we can open the stream
by passing a reference

00:01:07.750 --> 00:01:09.730
to an audio stream pointer.

00:01:09.730 --> 00:01:12.070
Be sure to check the
stream open successfully.

00:01:12.070 --> 00:01:14.770
Otherwise, you won't have
a valid stream object.

00:01:14.770 --> 00:01:17.290
If there was a problem,
you can convert the error

00:01:17.290 --> 00:01:20.470
to a human readable string
using convert to text.

00:01:20.470 --> 00:01:23.770
In fact, convert to text can
be used to convert many Oboe

00:01:23.770 --> 00:01:25.600
objects to text.

00:01:25.600 --> 00:01:27.790
Once the stream has been
successfully opened,

00:01:27.790 --> 00:01:30.040
you can start it asynchronously.

00:01:30.040 --> 00:01:33.340
You can now send data
to the audio device.

00:01:33.340 --> 00:01:35.230
To put data into
an audio stream,

00:01:35.230 --> 00:01:37.290
we can either write
directly into it

00:01:37.290 --> 00:01:40.840
or have the audio stream
request data using a callback.

00:01:40.840 --> 00:01:43.130
Callbacks give us
the lowest latency,

00:01:43.130 --> 00:01:46.030
so it's best to use them
for interactive audio apps.

00:01:46.030 --> 00:01:49.120
To create a callback object,
subclass audio stream

00:01:49.120 --> 00:01:53.300
callback and override
the onAudioReady method.

00:01:53.300 --> 00:01:55.660
This method is called when
the audio stream requires

00:01:55.660 --> 00:01:57.190
more data.

00:01:57.190 --> 00:02:00.330
It has three parameters-- a
pointer to the audio stream

00:02:00.330 --> 00:02:02.560
object, a container
array-- which we

00:02:02.560 --> 00:02:05.200
can write our audio data into.

00:02:05.200 --> 00:02:08.350
This has type void star, because
the format of the audio stream

00:02:08.350 --> 00:02:11.380
can either be 16-bit
integers or floats.

00:02:11.380 --> 00:02:14.320
It's up to us to cast
to the correct format.

00:02:14.320 --> 00:02:17.620
Lastly, numFrames tell us
how many frames of audio

00:02:17.620 --> 00:02:18.880
are required.

00:02:18.880 --> 00:02:21.310
Each frame contains
one or more samples.

00:02:21.310 --> 00:02:23.740
The number of samples will
depend on the streams channel

00:02:23.740 --> 00:02:24.400
count.

00:02:24.400 --> 00:02:28.480
For example, a stereo stream
has two samples per frame--

00:02:28.480 --> 00:02:31.090
one for the left channel and
one for the right channel.

00:02:31.090 --> 00:02:33.640
NumFrames also tells
us the maximum time

00:02:33.640 --> 00:02:35.260
we have to create the data.

00:02:35.260 --> 00:02:37.450
Failure to supply
data within this time

00:02:37.450 --> 00:02:39.790
is known as an underrun.

00:02:39.790 --> 00:02:41.830
As an example, if
our audio stream

00:02:41.830 --> 00:02:45.130
has a sample rate of
48,000 samples per second,

00:02:45.130 --> 00:02:49.270
and 192 frames are requested,
this gives us 4 milliseconds

00:02:49.270 --> 00:02:51.100
to create this data.

00:02:51.100 --> 00:02:54.100
In the real world, we want to
keep well under this deadline

00:02:54.100 --> 00:02:57.560
to allow for system
overhead and late callbacks.

00:02:57.560 --> 00:03:00.490
To give you the best chance of
meeting this audio deadline,

00:03:00.490 --> 00:03:03.550
onAudioReady is called
on a high priority system

00:03:03.550 --> 00:03:06.700
thread, which means it won't
be preempted by lower priority

00:03:06.700 --> 00:03:07.780
threads.

00:03:07.780 --> 00:03:10.120
But it's critical that
you don't do too much work

00:03:10.120 --> 00:03:12.509
or block inside this method.

00:03:12.509 --> 00:03:14.800
More detailed guidance on
what you should and shouldn't

00:03:14.800 --> 00:03:18.820
do here can be found in the
full guide to Oboe on GitHub.

00:03:18.820 --> 00:03:21.820
Inside, onAudioReady, we
write the requested number

00:03:21.820 --> 00:03:24.820
of audio frames into
the audio data array.

00:03:24.820 --> 00:03:27.400
This could be generated
using digital synthesis

00:03:27.400 --> 00:03:30.650
or be supplied from
prerecorded audio data.

00:03:30.650 --> 00:03:33.430
Finally, return a
data callback result.

00:03:33.430 --> 00:03:35.200
This can either
be continue, which

00:03:35.200 --> 00:03:38.830
indicates that we want the
callbacks to continue, or stop,

00:03:38.830 --> 00:03:40.510
which indicates that
the stream should

00:03:40.510 --> 00:03:43.300
stop with no more callbacks.

00:03:43.300 --> 00:03:45.550
Once you've finished creating
your callback object,

00:03:45.550 --> 00:03:47.140
you can link it to
your stream using

00:03:47.140 --> 00:03:49.780
the builder we created earlier.

00:03:49.780 --> 00:03:51.580
There's one final
step we need to take

00:03:51.580 --> 00:03:54.910
to ensure our audio stream has
the lowest possible latency--

00:03:54.910 --> 00:03:57.160
setting its buffer size.

00:03:57.160 --> 00:03:59.410
The audio streams buffer
size affects the time

00:03:59.410 --> 00:04:02.500
it takes for an audio frame
to travel through the stream

00:04:02.500 --> 00:04:04.030
to the audio device.

00:04:04.030 --> 00:04:06.100
The larger the buffer,
the longer it takes,

00:04:06.100 --> 00:04:08.110
and the higher the latency.

00:04:08.110 --> 00:04:11.050
An optimally sized buffer
provides a good trade off

00:04:11.050 --> 00:04:14.680
between latency and
underrun protection.

00:04:14.680 --> 00:04:17.440
The buffer size must be a
multiple of the stream's burst

00:04:17.440 --> 00:04:20.230
size, which is the number
of frames the audio device

00:04:20.230 --> 00:04:22.720
consumes in a single read.

00:04:22.720 --> 00:04:26.440
A good rule of thumb is to
use twice this burst size.

00:04:26.440 --> 00:04:28.570
This means that
if, occasionally,

00:04:28.570 --> 00:04:30.730
we miss our audio
callback deadline,

00:04:30.730 --> 00:04:33.160
the user will not
hear an audio glitch

00:04:33.160 --> 00:04:36.330
as long as the next
callback runs on time.

00:04:36.330 --> 00:04:38.890
Use getFramesPerBurst
to get the burst size,

00:04:38.890 --> 00:04:42.910
and set buffer size in frames
to set the buffer size.

00:04:42.910 --> 00:04:44.770
Now that all the stream
properties are set,

00:04:44.770 --> 00:04:46.120
we can start the stream.

00:04:46.120 --> 00:04:48.372
Callbacks will
start immediately.

00:04:48.372 --> 00:04:50.080
And once you've finished
with the stream,

00:04:50.080 --> 00:04:51.760
remember to close it.

00:04:51.760 --> 00:04:54.694
After you close a stream, it
cannot be accessed anymore.

00:04:54.694 --> 00:04:56.110
You should now
have everything you

00:04:56.110 --> 00:04:59.590
need to play audio using a
low latency audio stream.

00:04:59.590 --> 00:05:02.710
For a working example, check
out the Hello Oboe" sample

00:05:02.710 --> 00:05:05.760
on GitHub, which shows you how
create a simple synthesizer

00:05:05.760 --> 00:05:06.720
app.

00:05:06.720 --> 00:05:09.150
It also demonstrates how
to handle audio device

00:05:09.150 --> 00:05:12.330
changes, such as when the
user connects the headphones.

00:05:12.330 --> 00:05:14.590
A link can be found below.

00:05:14.590 --> 00:05:16.170
In the next episode,
I'll show you

00:05:16.170 --> 00:05:18.630
how to record sound
through a microphone using

00:05:18.630 --> 00:05:20.610
low latency input streams.

00:05:20.610 --> 00:05:21.600
That's all for now.

00:05:21.600 --> 00:05:23.670
So good luck and
go make some noise.

00:05:23.670 --> 00:05:27.620
[MUSIC PLAYING]

