WEBVTT
Kind: captions
Language: en

00:00:01.430 --> 00:00:04.220
&gt;&gt;All right, [INDISTINCT]
&gt;&gt; Yes.

00:00:04.220 --> 00:00:11.920
&gt;&gt; Yes. Are you ready?
&gt;&gt; ERICKSON: All right. All right, my name

00:00:11.920 --> 00:00:16.170
is Tyler Erickson, and I'm a research scientist
at Michigan Tech Research Institute in Ann

00:00:16.170 --> 00:00:22.750
Arbor, Michigan. And today, I'll be talking
about building visualizations of environmental

00:00:22.750 --> 00:00:28.289
data, particularly space-time data, and also
about how to build data systems that can officially

00:00:28.289 --> 00:00:35.760
generate complex KML that can display that
type of spatial and temporal data. The Earth

00:00:35.760 --> 00:00:41.360
is a pretty complex place. There's processes
that happen in space and time and are quite

00:00:41.360 --> 00:00:45.800
variable. And the representations of them
are always in the geospatial world who don't

00:00:45.800 --> 00:00:51.790
necessarily convey the amount of complexity
that--that is really actually going on in

00:00:51.790 --> 00:00:56.290
natural world. But when people actually see
a visualization, some type of time series

00:00:56.290 --> 00:00:59.510
like a movie or something like that, they
can get a better understanding of what is

00:00:59.510 --> 00:01:04.140
going on. But, unfortunately, for many of
these visualizations, like a video like this,

00:01:04.140 --> 00:01:08.320
there's no kind of interactive aspect. And
that's one of the things I've seen as really

00:01:08.320 --> 00:01:13.410
good about the virtual globe type of technology
that you can actually embed spatial and temporal

00:01:13.410 --> 00:01:17.920
data into a virtual involved environment that
allows users to actually touch the data and

00:01:17.920 --> 00:01:23.600
play with it, you know, navigate, turn on
and turn off different layers, and actually

00:01:23.600 --> 00:01:27.280
navigate the space and time to actually have
more of the interactive learning experience

00:01:27.280 --> 00:01:34.030
with the dataset. So today I'm going to talk
about one particular spatial temporal dataset

00:01:34.030 --> 00:01:38.840
and it is model output that has to do with
global climate change. And so--to just to

00:01:38.840 --> 00:01:45.250
give a quick overview of a rather complex
subject, I'm going to go over the 90 second

00:01:45.250 --> 00:01:51.640
version of global climate change. All right.
To provide--let see--the land surface, oceans,

00:01:51.640 --> 00:01:55.840
atmosphere, and subsurface are all carbon
reservoirs. Carbon in the atmosphere exists

00:01:55.840 --> 00:02:00.170
as carbon dioxide, a green house gas. And
increases in green house gas concentrations

00:02:00.170 --> 00:02:04.479
contribute to the warming of the Earth's surface.
What has changed in modern times is that the

00:02:04.479 --> 00:02:09.100
humans had become very good at transferring
carbon from deep underground to the atmosphere

00:02:09.100 --> 00:02:14.811
via the burning of fossil fuels. This activity
has caused carbon dioxide concentrations in

00:02:14.811 --> 00:02:19.349
the atmosphere to steadily increase. These
two plots show the trend in carbon dioxide

00:02:19.349 --> 00:02:23.959
concentrations measured over the last three
decades at various locations around the globe.

00:02:23.959 --> 00:02:28.769
The animated plot on the left shows carbon
dioxide concentrations as a function of latitude

00:02:28.769 --> 00:02:32.659
with the South Pole on the left and the North
Pole on the right. And the plot on the right

00:02:32.659 --> 00:02:37.290
shows the temporal progression of these two
long term monitoring stations: one in Mauna

00:02:37.290 --> 00:02:42.669
Loa in Hawaii and one at the South Pole. The
time series show consistently increasing levels

00:02:42.669 --> 00:02:46.599
of carbon dioxide with the seasonal cycle
which is particularly strong for measurement

00:02:46.599 --> 00:02:51.900
stations in the Northern Hemisphere. So to
quote some numbers, human activity is releasing

00:02:51.900 --> 00:02:57.549
about 8 gigatons of carbon per year into the
atmosphere. About half of this remains there,

00:02:57.549 --> 00:03:01.349
causing the massive carbon in the atmosphere
to increase at the rate of around 4 gigatons

00:03:01.349 --> 00:03:06.230
per year. The remaining carbon is taken up
by the oceans and the land surface. However,

00:03:06.230 --> 00:03:10.480
it's difficult to determine exactly when and
where the carbon goes because the additional

00:03:10.480 --> 00:03:14.800
amount is small relative to the gross exchange
between the reservoirs and the exchange can

00:03:14.800 --> 00:03:20.569
be highly variable in space and time. Understanding
where this carbon dioxide goes and the spatial

00:03:20.569 --> 00:03:24.480
and temporal variability of processes that
control it is critical for accurately predicting

00:03:24.480 --> 00:03:29.040
future climate change. Will the land and oceans
continue to absorb a large part of the excess

00:03:29.040 --> 00:03:34.010
CO2 regenerate or will these processes stop
or reverse leaving to even higher rates of

00:03:34.010 --> 00:03:41.080
global warming? Any questions? So if you knew,
there's a little conference that's going on

00:03:41.080 --> 00:03:45.639
right now in Copenhagen where they're trying
to nail out some of these issues, kind of

00:03:45.639 --> 00:03:49.839
a plan for what we're going to do in the future,
trying to get political leaders, business

00:03:49.839 --> 00:03:54.219
leaders all in the same place to agree on
how to address the release of carbon into

00:03:54.219 --> 00:04:01.439
the atmosphere and how that causes global
warming. It's really hard to get people to

00:04:01.439 --> 00:04:08.469
agree to cuts in emissions because that normally
requires a change to your economic status

00:04:08.469 --> 00:04:12.979
of a country or even a business, but luckily,
some are coming to the table now especially

00:04:12.979 --> 00:04:18.810
when they can find other way to make money
off of climate change. For example, Samsung

00:04:18.810 --> 00:04:23.229
has found a way to actually start selling
TVs with climate change as a feature. If you

00:04:23.229 --> 00:04:27.630
look here, one of the features that they are
asking, whether it's important to you, is

00:04:27.630 --> 00:04:36.419
whether the temperature in New York at 88
degrees Celsius is a desirable feature. So

00:04:36.419 --> 00:04:42.650
enough on the background. Now onto the geospatial
tools. So the basic overview of what I'd like

00:04:42.650 --> 00:04:47.939
to talk about is the problem of trying to
get complex spatial temporal model data into

00:04:47.939 --> 00:04:53.760
a format that can be visualized in the virtual
world for KML. But to get to that path, it

00:04:53.760 --> 00:04:58.270
requires something in between; a Geospatial
Data System that can actually manage the ingestion,

00:04:58.270 --> 00:05:02.889
storage, how to filter that data, how to format
it correctly and finally, to deliver it as

00:05:02.889 --> 00:05:08.969
a KML file to the client. So I'm going to
go over the components of that system. But

00:05:08.969 --> 00:05:15.310
first, I'm going to start with the visualization
client, or virtual globe, or Google Earth.

00:05:15.310 --> 00:05:20.620
And the main benefits of visualization climate--or
client like this is that it allows you to

00:05:20.620 --> 00:05:26.750
see your data in a geospatial and temporal
context. You can upload data of your own via

00:05:26.750 --> 00:05:34.000
KML language. Google Earth itself offers a
rich set of reference imagery that can be

00:05:34.000 --> 00:05:39.509
used for putting your data into context. And
the KML language allows you to talk to external

00:05:39.509 --> 00:05:46.280
servers for loading up additional KML as users
navigate around the globe and space. And also

00:05:46.280 --> 00:05:50.710
there is some temporal functionality, but
unfortunately, it's a bit limited compared

00:05:50.710 --> 00:05:55.680
to the spatial functionality of the KML language
and Google Earth. Here is a table that kind

00:05:55.680 --> 00:06:01.439
of gives an overview of the things that you
can and can't to do at current with KML language.

00:06:01.439 --> 00:06:07.479
And in terms of attributing objects, there's
the ability to put attributes of both space

00:06:07.479 --> 00:06:12.169
and time unto your objects so you can view
around and see in both space and time. The

00:06:12.169 --> 00:06:17.590
Google extensions to KML allow you to tour
both in space and time. But after this, the

00:06:17.590 --> 00:06:21.569
functionality kind of breaks down and there's
less support for time especially in terms

00:06:21.569 --> 00:06:26.909
of navigation. You have the ability to navigate
in time but only data that you have loaded

00:06:26.909 --> 00:06:31.030
up in the past. You can't navigate beyond
the bounds of the data that you have loaded.

00:06:31.030 --> 00:06:36.819
Also, it doesn't allow you to request data
from external servers via network links that

00:06:36.819 --> 00:06:41.360
give you an understanding of what time you
are actually interested in looking at. And

00:06:41.360 --> 00:06:46.669
then also regions and overlays; two powerful
tools for managing large amounts of spatial

00:06:46.669 --> 00:06:53.090
data don't quite add the equivalent in the
temporal domains. You can't overlay or originate

00:06:53.090 --> 00:06:58.330
in terms of time and attributes. So since
Christmas is coming up, I thought I'd like

00:06:58.330 --> 00:07:02.730
to put in my wish list for what would be nice
to see in the KML language and in Google Earth

00:07:02.730 --> 00:07:08.520
in the future. Most of the time, Google Earth
is used to, what I'd call, just kind of points

00:07:08.520 --> 00:07:12.210
on the map. And this is valuable of course.
It actually gives you a kind of a spatial

00:07:12.210 --> 00:07:17.080
context for where your data is located. But
KML itself is a very rich language and many

00:07:17.080 --> 00:07:23.960
of the features of it are underutilized by
the--most of the KML files are out there,

00:07:23.960 --> 00:07:29.069
whether it's 90%, or 95%, or 99%. We don't
make much use of the advanced stages of KML.

00:07:29.069 --> 00:07:35.020
So in order to do that, you can use the KML
Authoring library to actually give you access

00:07:35.020 --> 00:07:40.639
to efficiently writing some of the more complex
elements of KML language. And up here, given

00:07:40.639 --> 00:07:46.610
the example of using a libkml which is a C++
library that can be used to programmatically

00:07:46.610 --> 00:07:52.629
create KML documents. That's a C++ library
that has interfaces in Python and Java that

00:07:52.629 --> 00:07:58.620
allow you to create KML efficiently. This
is the--here's an example of using libkml

00:07:58.620 --> 00:08:04.020
with the Python interface to create a simple
place mark, but it's not really Python. I

00:08:04.020 --> 00:08:09.779
think you are more familiar with that language.
So what we've done at [INDISTINCT] is create

00:08:09.779 --> 00:08:15.290
a [INDISTINCT] for the libkml language called
pylibkml that gives you a more Pythonic way

00:08:15.290 --> 00:08:22.139
of describing how to create a place mark or
any other KML feature that exist there. So

00:08:22.139 --> 00:08:25.639
now, onto the components of the geospatial
data system. The first one I want to talk

00:08:25.639 --> 00:08:30.469
about is the spatial database. And what we
use is the PostgreSQL open source relational

00:08:30.469 --> 00:08:36.190
database modified with the addition of geospatial
libraries like GEOS and Proj 4 that allow

00:08:36.190 --> 00:08:42.760
you to do 2G--2D geometry manipulations and
rejections. The result of this is the open

00:08:42.760 --> 00:08:47.820
source spatial database called PostGIS which
has been pretty revolutionary in terms of

00:08:47.820 --> 00:08:54.899
what it allows users to do with their spatial
data. Example of what you can use PostgreSQL

00:08:54.899 --> 00:09:00.870
for is answering questions like this; at database
level, you can say, "Where has clear clip--clearcut

00:09:00.870 --> 00:09:05.310
logging occurred within 20 meters of a stream
or a river?" And the SQL statement at the

00:09:05.310 --> 00:09:09.370
bottom shows an example of that. In addition
to having spatial data that's stored in the

00:09:09.370 --> 00:09:14.290
database that has the ability to run geospatial
operators like intersections, buffers, a lot

00:09:14.290 --> 00:09:19.260
of the more common geospatial commands that
you might have found in like a desktop GIS.

00:09:19.260 --> 00:09:26.990
We can do that very efficiently at the database
level. We also--another part of the data system

00:09:26.990 --> 00:09:33.260
that is needed is a Web framework; something
that automates the task that--for setting

00:09:33.260 --> 00:09:38.070
up a website that allows you to connect to
a database and efficiently create Web pages

00:09:38.070 --> 00:09:46.120
or other HTTP delivered content. And so [INDISTINCT]
we use Django, a Python based framework. And

00:09:46.120 --> 00:09:50.910
once again, it's modified with a number of
geospatial library, GEOS, Proj, and GDAL,

00:09:50.910 --> 00:09:55.860
for manipulating vector and raster data. And
the result of that is a project, an extension

00:09:55.860 --> 00:10:01.050
of Django, called GeoDjango. It's quite flexible
because Python is somewhat of a [INDISTINCT]

00:10:01.050 --> 00:10:06.670
language and anything that--a lot of scientific
tools will all have some type of Python interface

00:10:06.670 --> 00:10:12.080
that can allow you to connect to GeoDjango.
Example of how GeoDjango is typically used

00:10:12.080 --> 00:10:17.529
is to create HTML pages with maps embed. So
here's an example of the Represent page for

00:10:17.529 --> 00:10:23.160
New York City which allows users to declare
where they live by street address and it looks

00:10:23.160 --> 00:10:28.709
up counsel members at various levels that
are representatives of yourself. And you can

00:10:28.709 --> 00:10:33.810
actually monitor what they are doing on a
daily basis. So that's a typical use of GeoDjango,

00:10:33.810 --> 00:10:40.459
but it's not just HTML pages that it can create.
It can create any type of format. It can be

00:10:40.459 --> 00:10:45.490
communicated with HTTP. In this case, we're
going to be using it to create KML. So putting

00:10:45.490 --> 00:10:51.870
it all together, GeoDjango is kind of the
core framework that we're customizing here.

00:10:51.870 --> 00:10:57.670
We designed it so we can store our data in
PostGIS spatial data. And then we'll take

00:10:57.670 --> 00:11:03.459
scientific model data, run it through Python
libraries, SciPy and Rpy, which understand

00:11:03.459 --> 00:11:10.160
a wide variety of different data formats into
GeoDjango and then into PostGIS for storage

00:11:10.160 --> 00:11:14.389
and then to--when we're accessing it, we want
to format in another representation. So we'll

00:11:14.389 --> 00:11:20.890
hook up GeoDjango to pylibkml and libkml,
and the result is you can output KML documents.

00:11:20.890 --> 00:11:29.022
So to see them in action, here is just a recording
of--starting up a Django run server or a Django

00:11:29.022 --> 00:11:35.890
Web server, and you can ask--access content
that's within Django through a browser or

00:11:35.890 --> 00:11:41.660
anything that speaks HTTP. And so here, I'm
loading up a certain KML file which is "Particles

00:11:41.660 --> 00:11:46.000
That Are Trapped the Atmosphere." And you
can either load them up in a browser or you

00:11:46.000 --> 00:11:51.829
can actually make network links within Google
Earth that can talk to the Web server itself,

00:11:51.829 --> 00:11:57.000
retrieving KML from the Web server. So in
this case, it's going to load up particles

00:11:57.000 --> 00:12:01.350
for a particular time, simulated particles
that were released in the atmosphere. And

00:12:01.350 --> 00:12:06.079
as you see in the upper left, there is a log
of the GeoDjango file going on there and you're

00:12:06.079 --> 00:12:10.830
starting to see hits against the Web server.
And back in Google Earth, you can start to

00:12:10.830 --> 00:12:15.720
see the data that's being load--loaded as
it talks to the Web server and requests KML

00:12:15.720 --> 00:12:23.230
content. And from there, you can start navigating
in Google Earth the content. So this next

00:12:23.230 --> 00:12:30.130
example is more back to the carbon story.
And this is a series of towers that NOM runs

00:12:30.130 --> 00:12:37.440
in the United States that sample a long time
series of very accurate carbon dioxide measurements.

00:12:37.440 --> 00:12:41.940
And what is this? It's being shown here the
visualization is using KML and a combination

00:12:41.940 --> 00:12:47.959
of model and scaling tags in order to show
a time series of measured CO2 concentrations

00:12:47.959 --> 00:12:52.840
at a particular tower. When it's blue, it's
above the background concentration of CO2,

00:12:52.840 --> 00:12:59.720
and when it's green, it's below. But in order
to make use of that data, you want to figure

00:12:59.720 --> 00:13:04.720
out where that carbon dioxide in the air has
come from. So the next thing I'm going to

00:13:04.720 --> 00:13:09.199
be showing here is the output from some particle
tracking simulations for particles that were

00:13:09.199 --> 00:13:15.100
collected at the--or air masses that was collected
at the LEF tower. And we're going to do--type

00:13:15.100 --> 00:13:20.069
of atmospheric model that tracks these particles
backward in time to see where they have been

00:13:20.069 --> 00:13:24.031
over the last 10 days. So we're starting to
go a little bit farther backward in time.

00:13:24.031 --> 00:13:28.370
You can see there's about--showing about 100
particles here. But typically, these are run

00:13:28.370 --> 00:13:33.010
for hundreds to thousands of particles at
a time. And this is the tracks of where they've

00:13:33.010 --> 00:13:38.370
been over the last 10 days. The symbology
I'm using there for the tracks is gray when

00:13:38.370 --> 00:13:43.259
the particles are above the atmospheric boundary
layer or somewhat isolated from the surface

00:13:43.259 --> 00:13:47.690
and green when they're below the atmospheric
boundary layer or near the surface and can

00:13:47.690 --> 00:13:52.220
exchange carbon dioxide with the land surface
and the air. So it's picking up the information

00:13:52.220 --> 00:13:57.079
where it's green. Google Earth, a powerful
use of it is that you can actually see kind

00:13:57.079 --> 00:14:01.680
of the forest and the trees at the same time.
So right now, we're zooming into the details

00:14:01.680 --> 00:14:05.980
of these particles clicking on one of the
particles that has been attributed with the

00:14:05.980 --> 00:14:10.920
information from the STILT Atmospheric Model.
And this can show scientists a lot of details

00:14:10.920 --> 00:14:17.940
about the model outputs, once again, providing
a very detailed spatial and temporal context

00:14:17.940 --> 00:14:23.480
for the data that they might be using. So
particles are nice and they're actually kind

00:14:23.480 --> 00:14:28.120
of fun to track around and watch, but the
real information that we're trying to get

00:14:28.120 --> 00:14:33.529
out of the particles is how sensitive are
these carbon dioxide measurements at the towers?

00:14:33.529 --> 00:14:38.240
How sensitive are they to processes that are
going on the Earth's surface? So this next

00:14:38.240 --> 00:14:45.080
animation is going to be of sensitivity maps
showing the sensitivity of one particular

00:14:45.080 --> 00:14:51.329
tower to processes that are going on--in--on
the Earth's surface and this is based on the

00:14:51.329 --> 00:14:55.490
results of those particle tracks and where
they happened to be near the Earth's surface.

00:14:55.490 --> 00:15:02.240
So this is showing a constantly changing map
of where that tower in Wisconsin, the LEF

00:15:02.240 --> 00:15:07.150
tower, is sensitive to. Right now, there's
particles that are starting to simulate it

00:15:07.150 --> 00:15:11.390
that are coming down from Canada, and you'll
see that they start to line up with the sensitivity

00:15:11.390 --> 00:15:16.660
map. I should say that for the map, the heights
of the blocks that are being animated here

00:15:16.660 --> 00:15:21.699
is proportional to how sensitive the tower
is to processes that are going on in that

00:15:21.699 --> 00:15:27.199
region based on the particle tracker. You
can put several of these together to start

00:15:27.199 --> 00:15:32.279
getting the idea of what parts of the United
States are being represented by these towers

00:15:32.279 --> 00:15:37.960
and the concentrations that they're sampling.
So here's three towers; the WKT Tower in Texas,

00:15:37.960 --> 00:15:45.050
LEF Tower in Wisconsin, the AMT Tower in Maine.
And you can see quite often the sensitivity

00:15:45.050 --> 00:15:50.750
of these two towers overlaps and that's just
because of the way the wind is blowing. It's

00:15:50.750 --> 00:15:55.550
like it's carrying information along--pass
two towers at the same time. Since you have

00:15:55.550 --> 00:16:00.230
it in Google Earth, you can actually overlay
it by other data sets. This is a land covered

00:16:00.230 --> 00:16:04.320
map that actually was one of the products
that one of our other speakers presented on

00:16:04.320 --> 00:16:10.430
today. But it gives you an idea of what land
covers maybe contributing to carbon release

00:16:10.430 --> 00:16:17.920
or uptake at different regions. So to give
a little summary of what I've been showing

00:16:17.920 --> 00:16:22.410
and what the next steps are, first, I was
talking about Concentration Measurements.

00:16:22.410 --> 00:16:29.899
And these are kind of an animation of a piece
of data that is fixed in 3D space and variable

00:16:29.899 --> 00:16:35.199
on time. So, you have X, Y, Z, and the time
of capture of the particles, and also showing

00:16:35.199 --> 00:16:40.540
Sensitivity Maps. And these are 3D maps in
X and Y, but they also have two times associated

00:16:40.540 --> 00:16:45.990
on; the time of flux or the exchange of carbon
dioxide between the land surface and the atmosphere,

00:16:45.990 --> 00:16:51.209
and also the time of capture that is happening
at the tower. Sometime it takes, you know,

00:16:51.209 --> 00:16:55.310
up to 10 days for those to be connected due
to the--the way that the particles are [INDISTINCT]

00:16:55.310 --> 00:16:59.829
by the wind. And for the animations I was
showing, I was actually showing the first

00:16:59.829 --> 00:17:03.779
three variables of the time of the flux rather
than the time of capture although the time

00:17:03.779 --> 00:17:08.490
of capture is interesting to some of the scientist
that actually work on the towers themselves

00:17:08.490 --> 00:17:13.000
and are trying to interpret their data. But
really, what we're after is Flux Estimates

00:17:13.000 --> 00:17:17.730
of carbon dioxide and how it's being exchanged
between the land and ocean surfaces and the

00:17:17.730 --> 00:17:23.080
atmosphere. And so in order to get from what
I've shown so far to the Flux Estimates, scientist

00:17:23.080 --> 00:17:27.300
do something called an Inverse Modeling, because
what we're looking at in terms of concentration

00:17:27.300 --> 00:17:31.890
is the result of the process but we're actually
wanting to know what the actual source of

00:17:31.890 --> 00:17:37.480
that is; the flux of the emissions. So with
Inverse Modeling, you can combine the Concentration

00:17:37.480 --> 00:17:42.880
Measurements and Auxiliary Datasets together,
and then relate them to the fluxes by that

00:17:42.880 --> 00:17:47.230
mapping of the sensitivity that we have, and
it gives you a probabilistic estimate of what

00:17:47.230 --> 00:17:52.120
is coming out or what is happening in terms
of carbon dioxide flux. And that also has

00:17:52.120 --> 00:17:58.040
two spatial dimensions and one temporal dimension.
Most interesting though is that this is not

00:17:58.040 --> 00:18:05.320
a--just a single estimate but it's a probabilistic
estimate. So in addition to the Flux Estimates,

00:18:05.320 --> 00:18:11.400
you have some measure of the errors or how
errors are correlated in space; the Estimation

00:18:11.400 --> 00:18:16.250
Covariance measures. In this case, we have
four spatial dimensions representing two pairs

00:18:16.250 --> 00:18:22.440
of locations and also element of time. So
that's kind of one of the next steps is trying

00:18:22.440 --> 00:18:29.550
to use Google Earth to go forth and go beyond
3D space in time but actually start doing

00:18:29.550 --> 00:18:33.710
visualizations of these higher dimensional
datasets. We have some pretty good ideas about

00:18:33.710 --> 00:18:40.000
how the styling can be used to do so. So a
lot of this work I've been presenting, the

00:18:40.000 --> 00:18:44.810
datasets have come from other research groups
that has spent a lot of time generating the

00:18:44.810 --> 00:18:49.670
Atmospheric Transport Models and the use of
the--and aggregating that data together into

00:18:49.670 --> 00:18:54.270
sensitivity maps for the carbon cycle science.
So I do want to acknowledge Professor Anna

00:18:54.270 --> 00:18:58.510
Michalak, the University of Michigan, and
the PUORG Research Group that provided several

00:18:58.510 --> 00:19:02.900
of the climate datasets that I've shown in
the visualizations today, and also Professor

00:19:02.900 --> 00:19:07.790
John Lin at the University of Waterloo in
Canada who is the creator of the STILT Atmospheric

00:19:07.790 --> 00:19:14.730
Transport Model. In addition, this work relies
heavily on many Open Source Projects. So I'd

00:19:14.730 --> 00:19:19.520
like to thank those projects, their contributors,
and their benevolent dictators. I've met a

00:19:19.520 --> 00:19:23.810
few of these along the way and more often
by e-mail than in person. But I'd really like

00:19:23.810 --> 00:19:30.220
to call out, in particular, Justin Bronn.
Justin was studying to be a lawyer at the

00:19:30.220 --> 00:19:34.410
time in law school when he wrote the extension
to Django that's called GeoDjango which has

00:19:34.410 --> 00:19:39.870
been pretty revolutionary for the type of
data that we work with. So he has successfully

00:19:39.870 --> 00:19:47.810
passed the bar after creating the GeoDjango.
And finally, I just want to say that there

00:19:47.810 --> 00:19:53.100
is--this is just one type of spatial and temporal
data, and there is almost an unlimited amount

00:19:53.100 --> 00:19:57.710
that is out there in terms of complex, space,
and time data that are being generated in

00:19:57.710 --> 00:20:02.460
models in the scientific community. And so
I think it's a real challenge and opportunity

00:20:02.460 --> 00:20:07.470
to put those data in a form that's more readily
accessible by the general public decision

00:20:07.470 --> 00:20:12.150
makers and such. And Google Earth is a great
tool for trying to communicate this type of

00:20:12.150 --> 00:20:17.950
spatial and temporal data. I've also put up
their links to project--an open source project

00:20:17.950 --> 00:20:22.490
in the repository that you can download if
you want to see how the GeoDjango works that

00:20:22.490 --> 00:20:32.220
I've described in this talk, and also a link
to the pylibkml project. And that's it. Thank

00:20:32.220 --> 00:20:39.080
you.
&gt;&gt; All right. Well, any questions for Tyler?

00:20:39.080 --> 00:20:43.910
&gt;&gt; Just a classic example of "A picture's
worth a thousand words," because I actually

00:20:43.910 --> 00:20:50.150
understood more of inverse modeling from your
talk than I have in reading. Nice try there.

00:20:50.150 --> 00:20:53.590
&gt;&gt; ERICKSON: Well, that's great. And we're--we're
going to do more...

