WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.480
in a previous video you saw how looking

00:00:02.480 --> 00:00:02.490
in a previous video you saw how looking
 

00:00:02.490 --> 00:00:04.519
in a previous video you saw how looking
at training error and Deborah can help

00:00:04.519 --> 00:00:04.529
at training error and Deborah can help
 

00:00:04.529 --> 00:00:06.079
at training error and Deborah can help
you diagnose whether your algorithm has

00:00:06.079 --> 00:00:06.089
you diagnose whether your algorithm has
 

00:00:06.089 --> 00:00:08.690
you diagnose whether your algorithm has
a bias or variance problem or maybe both

00:00:08.690 --> 00:00:08.700
a bias or variance problem or maybe both
 

00:00:08.700 --> 00:00:11.030
a bias or variance problem or maybe both
it turns out that this information that

00:00:11.030 --> 00:00:11.040
it turns out that this information that
 

00:00:11.040 --> 00:00:13.339
it turns out that this information that
lets you much more systematically using

00:00:13.339 --> 00:00:13.349
lets you much more systematically using
 

00:00:13.349 --> 00:00:15.829
lets you much more systematically using
what I call a basic recipe for machine

00:00:15.829 --> 00:00:15.839
what I call a basic recipe for machine
 

00:00:15.839 --> 00:00:17.269
what I call a basic recipe for machine
learning that lets you much more

00:00:17.269 --> 00:00:17.279
learning that lets you much more
 

00:00:17.279 --> 00:00:19.160
learning that lets you much more
systematically go about improving your

00:00:19.160 --> 00:00:19.170
systematically go about improving your
 

00:00:19.170 --> 00:00:21.050
systematically go about improving your
algorithms performance let's take a look

00:00:21.050 --> 00:00:21.060
algorithms performance let's take a look
 

00:00:21.060 --> 00:00:23.269
algorithms performance let's take a look
when training your network which is a

00:00:23.269 --> 00:00:23.279
when training your network which is a
 

00:00:23.279 --> 00:00:25.460
when training your network which is a
basic recipe I will use after having

00:00:25.460 --> 00:00:25.470
basic recipe I will use after having
 

00:00:25.470 --> 00:00:27.439
basic recipe I will use after having
trained an initial model I will first

00:00:27.439 --> 00:00:27.449
trained an initial model I will first
 

00:00:27.449 --> 00:00:30.200
trained an initial model I will first
ask does your algorithm have high bias

00:00:30.200 --> 00:00:30.210
ask does your algorithm have high bias
 

00:00:30.210 --> 00:00:32.840
ask does your algorithm have high bias
and so the child evaluate if this high

00:00:32.840 --> 00:00:32.850
and so the child evaluate if this high
 

00:00:32.850 --> 00:00:35.750
and so the child evaluate if this high
bias so you should look at really the

00:00:35.750 --> 00:00:35.760
bias so you should look at really the
 

00:00:35.760 --> 00:00:38.080
bias so you should look at really the
training set of the training data

00:00:38.080 --> 00:00:38.090
training set of the training data
 

00:00:38.090 --> 00:00:42.560
training set of the training data
performance right and so if it does have

00:00:42.560 --> 00:00:42.570
performance right and so if it does have
 

00:00:42.570 --> 00:00:44.209
performance right and so if it does have
high bias it's not even fitting the

00:00:44.209 --> 00:00:44.219
high bias it's not even fitting the
 

00:00:44.219 --> 00:00:46.340
high bias it's not even fitting the
training set to that well some things

00:00:46.340 --> 00:00:46.350
training set to that well some things
 

00:00:46.350 --> 00:00:48.889
training set to that well some things
you could try would be to try to canet

00:00:48.889 --> 00:00:48.899
you could try would be to try to canet
 

00:00:48.899 --> 00:00:51.799
you could try would be to try to canet
work such as what layer's or more hidden

00:00:51.799 --> 00:00:51.809
work such as what layer's or more hidden
 

00:00:51.809 --> 00:00:54.439
work such as what layer's or more hidden
units or you could trim it longer you

00:00:54.439 --> 00:00:54.449
units or you could trim it longer you
 

00:00:54.449 --> 00:00:56.959
units or you could trim it longer you
know maybe run gains and longer or try

00:00:56.959 --> 00:00:56.969
know maybe run gains and longer or try
 

00:00:56.969 --> 00:00:57.950
know maybe run gains and longer or try
some more advanced optimization

00:00:57.950 --> 00:00:57.960
some more advanced optimization
 

00:00:57.960 --> 00:00:59.569
some more advanced optimization
algorithms which we'll talk about later

00:00:59.569 --> 00:00:59.579
algorithms which we'll talk about later
 

00:00:59.579 --> 00:01:02.840
algorithms which we'll talk about later
in this course or you can also try this

00:01:02.840 --> 00:01:02.850
in this course or you can also try this
 

00:01:02.850 --> 00:01:05.990
in this course or you can also try this
kind of a maybe a work maybe it won't

00:01:05.990 --> 00:01:06.000
kind of a maybe a work maybe it won't
 

00:01:06.000 --> 00:01:07.850
kind of a maybe a work maybe it won't
but we'll see later that there are a lot

00:01:07.850 --> 00:01:07.860
but we'll see later that there are a lot
 

00:01:07.860 --> 00:01:09.649
but we'll see later that there are a lot
of different neural network

00:01:09.649 --> 00:01:09.659
of different neural network
 

00:01:09.659 --> 00:01:12.200
of different neural network
architectures and maybe even find in

00:01:12.200 --> 00:01:12.210
architectures and maybe even find in
 

00:01:12.210 --> 00:01:13.789
architectures and maybe even find in
your network architecture that's better

00:01:13.789 --> 00:01:13.799
your network architecture that's better
 

00:01:13.799 --> 00:01:15.920
your network architecture that's better
suited for this problem putting this in

00:01:15.920 --> 00:01:15.930
suited for this problem putting this in
 

00:01:15.930 --> 00:01:17.210
suited for this problem putting this in
parentheses because all those things

00:01:17.210 --> 00:01:17.220
parentheses because all those things
 

00:01:17.220 --> 00:01:19.550
parentheses because all those things
that you know you just have to try maybe

00:01:19.550 --> 00:01:19.560
that you know you just have to try maybe
 

00:01:19.560 --> 00:01:22.399
that you know you just have to try maybe
to make work maybe not whereas getting a

00:01:22.399 --> 00:01:22.409
to make work maybe not whereas getting a
 

00:01:22.409 --> 00:01:24.230
to make work maybe not whereas getting a
bigger Network almost always selves and

00:01:24.230 --> 00:01:24.240
bigger Network almost always selves and
 

00:01:24.240 --> 00:01:26.570
bigger Network almost always selves and
training longer well doesn't always help

00:01:26.570 --> 00:01:26.580
training longer well doesn't always help
 

00:01:26.580 --> 00:01:28.880
training longer well doesn't always help
it associate never hurts but so when

00:01:28.880 --> 00:01:28.890
it associate never hurts but so when
 

00:01:28.890 --> 00:01:30.440
it associate never hurts but so when
training learning other I would try

00:01:30.440 --> 00:01:30.450
training learning other I would try
 

00:01:30.450 --> 00:01:32.450
training learning other I would try
these things until I can at least get

00:01:32.450 --> 00:01:32.460
these things until I can at least get
 

00:01:32.460 --> 00:01:34.580
these things until I can at least get
rid of the bias problems as if go back

00:01:34.580 --> 00:01:34.590
rid of the bias problems as if go back
 

00:01:34.590 --> 00:01:37.999
rid of the bias problems as if go back
after I've tried this until and she's

00:01:37.999 --> 00:01:38.009
after I've tried this until and she's
 

00:01:38.009 --> 00:01:40.609
after I've tried this until and she's
doing that until I can fit at least fit

00:01:40.609 --> 00:01:40.619
doing that until I can fit at least fit
 

00:01:40.619 --> 00:01:42.770
doing that until I can fit at least fit
the training set pretty well and usually

00:01:42.770 --> 00:01:42.780
the training set pretty well and usually
 

00:01:42.780 --> 00:01:44.990
the training set pretty well and usually
if you have a big enough network you can

00:01:44.990 --> 00:01:45.000
if you have a big enough network you can
 

00:01:45.000 --> 00:01:46.429
if you have a big enough network you can
you should usually be able to fit

00:01:46.429 --> 00:01:46.439
you should usually be able to fit
 

00:01:46.439 --> 00:01:49.399
you should usually be able to fit
between training day so well so long

00:01:49.399 --> 00:01:49.409
between training day so well so long
 

00:01:49.409 --> 00:01:53.300
between training day so well so long
this is a problem that is possible for

00:01:53.300 --> 00:01:53.310
this is a problem that is possible for
 

00:01:53.310 --> 00:01:55.190
this is a problem that is possible for
someone to generate an image is very

00:01:55.190 --> 00:01:55.200
someone to generate an image is very
 

00:01:55.200 --> 00:01:57.020
someone to generate an image is very
observing it may be impossible to fit it

00:01:57.020 --> 00:01:57.030
observing it may be impossible to fit it
 

00:01:57.030 --> 00:01:59.179
observing it may be impossible to fit it
but if at least a human can do on the

00:01:59.179 --> 00:01:59.189
but if at least a human can do on the
 

00:01:59.189 --> 00:02:00.920
but if at least a human can do on the
tall so do you think Bayes error is not

00:02:00.920 --> 00:02:00.930
tall so do you think Bayes error is not
 

00:02:00.930 --> 00:02:03.109
tall so do you think Bayes error is not
too hard and by training a bigger than

00:02:03.109 --> 00:02:03.119
too hard and by training a bigger than
 

00:02:03.119 --> 00:02:04.700
too hard and by training a bigger than
network you should be able to hopefully

00:02:04.700 --> 00:02:04.710
network you should be able to hopefully
 

00:02:04.710 --> 00:02:07.130
network you should be able to hopefully
do well at least on the training set so

00:02:07.130 --> 00:02:07.140
do well at least on the training set so
 

00:02:07.140 --> 00:02:09.300
do well at least on the training set so
these fit to over 30 trainees

00:02:09.300 --> 00:02:09.310
these fit to over 30 trainees
 

00:02:09.310 --> 00:02:12.170
these fit to over 30 trainees
once you've reduced buyers to a

00:02:12.170 --> 00:02:12.180
once you've reduced buyers to a
 

00:02:12.180 --> 00:02:14.910
once you've reduced buyers to a
acceptable amount I would then ask do

00:02:14.910 --> 00:02:14.920
acceptable amount I would then ask do
 

00:02:14.920 --> 00:02:17.460
acceptable amount I would then ask do
you have a variance problem and so to

00:02:17.460 --> 00:02:17.470
you have a variance problem and so to
 

00:02:17.470 --> 00:02:19.800
you have a variance problem and so to
evaluate that I would look at the guest

00:02:19.800 --> 00:02:19.810
evaluate that I would look at the guest
 

00:02:19.810 --> 00:02:21.750
evaluate that I would look at the guest
set performance are you able to

00:02:21.750 --> 00:02:21.760
set performance are you able to
 

00:02:21.760 --> 00:02:24.300
set performance are you able to
generalize from a pretty good training

00:02:24.300 --> 00:02:24.310
generalize from a pretty good training
 

00:02:24.310 --> 00:02:26.640
generalize from a pretty good training
set performance to having a pretty good

00:02:26.640 --> 00:02:26.650
set performance to having a pretty good
 

00:02:26.650 --> 00:02:29.580
set performance to having a pretty good
job set performance and if you have high

00:02:29.580 --> 00:02:29.590
job set performance and if you have high
 

00:02:29.590 --> 00:02:30.270
job set performance and if you have high
variance

00:02:30.270 --> 00:02:30.280
variance
 

00:02:30.280 --> 00:02:32.400
variance
well best way to solve the high variance

00:02:32.400 --> 00:02:32.410
well best way to solve the high variance
 

00:02:32.410 --> 00:02:34.710
well best way to solve the high variance
problem is get more data if you can get

00:02:34.710 --> 00:02:34.720
problem is get more data if you can get
 

00:02:34.720 --> 00:02:38.430
problem is get more data if you can get
it this node can only help but sometimes

00:02:38.430 --> 00:02:38.440
it this node can only help but sometimes
 

00:02:38.440 --> 00:02:42.210
it this node can only help but sometimes
you can't get more data or you could try

00:02:42.210 --> 00:02:42.220
you can't get more data or you could try
 

00:02:42.220 --> 00:02:44.160
you can't get more data or you could try
regularization which we'll talk about in

00:02:44.160 --> 00:02:44.170
regularization which we'll talk about in
 

00:02:44.170 --> 00:02:46.290
regularization which we'll talk about in
the next video to try to reduce over 15

00:02:46.290 --> 00:02:46.300
the next video to try to reduce over 15
 

00:02:46.300 --> 00:02:49.290
the next video to try to reduce over 15
and then also again this is a sometimes

00:02:49.290 --> 00:02:49.300
and then also again this is a sometimes
 

00:02:49.300 --> 00:02:51.900
and then also again this is a sometimes
adjusted to try it but if you can find a

00:02:51.900 --> 00:02:51.910
adjusted to try it but if you can find a
 

00:02:51.910 --> 00:02:53.310
adjusted to try it but if you can find a
more appropriate neural network

00:02:53.310 --> 00:02:53.320
more appropriate neural network
 

00:02:53.320 --> 00:02:55.800
more appropriate neural network
architecture sometimes that can reduce

00:02:55.800 --> 00:02:55.810
architecture sometimes that can reduce
 

00:02:55.810 --> 00:02:57.809
architecture sometimes that can reduce
your variance problem as well as well as

00:02:57.809 --> 00:02:57.819
your variance problem as well as well as
 

00:02:57.819 --> 00:03:00.150
your variance problem as well as well as
reduce earlier your bias problem but how

00:03:00.150 --> 00:03:00.160
reduce earlier your bias problem but how
 

00:03:00.160 --> 00:03:02.040
reduce earlier your bias problem but how
to do that is harder to be totally

00:03:02.040 --> 00:03:02.050
to do that is harder to be totally
 

00:03:02.050 --> 00:03:04.410
to do that is harder to be totally
systematic how you do that but start

00:03:04.410 --> 00:03:04.420
systematic how you do that but start
 

00:03:04.420 --> 00:03:05.820
systematic how you do that but start
writing a savings in collective going

00:03:05.820 --> 00:03:05.830
writing a savings in collective going
 

00:03:05.830 --> 00:03:08.640
writing a savings in collective going
back and so hopefully you find something

00:03:08.640 --> 00:03:08.650
back and so hopefully you find something
 

00:03:08.650 --> 00:03:11.280
back and so hopefully you find something
with both global buyers and low variance

00:03:11.280 --> 00:03:11.290
with both global buyers and low variance
 

00:03:11.290 --> 00:03:15.390
with both global buyers and low variance
whereupon you would be done so a couple

00:03:15.390 --> 00:03:15.400
whereupon you would be done so a couple
 

00:03:15.400 --> 00:03:17.759
whereupon you would be done so a couple
points to notice first is that depending

00:03:17.759 --> 00:03:17.769
points to notice first is that depending
 

00:03:17.769 --> 00:03:19.199
points to notice first is that depending
on whether you have high bias or high

00:03:19.199 --> 00:03:19.209
on whether you have high bias or high
 

00:03:19.209 --> 00:03:21.120
on whether you have high bias or high
variance the set of things you should

00:03:21.120 --> 00:03:21.130
variance the set of things you should
 

00:03:21.130 --> 00:03:24.810
variance the set of things you should
try could be quite different so I'll

00:03:24.810 --> 00:03:24.820
try could be quite different so I'll
 

00:03:24.820 --> 00:03:26.490
try could be quite different so I'll
usually use the training depth set to

00:03:26.490 --> 00:03:26.500
usually use the training depth set to
 

00:03:26.500 --> 00:03:28.979
usually use the training depth set to
try to diagnose if you have a bias or

00:03:28.979 --> 00:03:28.989
try to diagnose if you have a bias or
 

00:03:28.989 --> 00:03:30.840
try to diagnose if you have a bias or
variance problem and then use that to

00:03:30.840 --> 00:03:30.850
variance problem and then use that to
 

00:03:30.850 --> 00:03:32.460
variance problem and then use that to
select the appropriate substantive

00:03:32.460 --> 00:03:32.470
select the appropriate substantive
 

00:03:32.470 --> 00:03:35.370
select the appropriate substantive
things to try so for example if you

00:03:35.370 --> 00:03:35.380
things to try so for example if you
 

00:03:35.380 --> 00:03:36.920
things to try so for example if you
actually have a high bias problem

00:03:36.920 --> 00:03:36.930
actually have a high bias problem
 

00:03:36.930 --> 00:03:39.150
actually have a high bias problem
getting more training data is actually

00:03:39.150 --> 00:03:39.160
getting more training data is actually
 

00:03:39.160 --> 00:03:41.729
getting more training data is actually
not going to help where this is not the

00:03:41.729 --> 00:03:41.739
not going to help where this is not the
 

00:03:41.739 --> 00:03:44.520
not going to help where this is not the
most efficient thing to do so being

00:03:44.520 --> 00:03:44.530
most efficient thing to do so being
 

00:03:44.530 --> 00:03:46.470
most efficient thing to do so being
clear on how much of a bias problem or

00:03:46.470 --> 00:03:46.480
clear on how much of a bias problem or
 

00:03:46.480 --> 00:03:48.750
clear on how much of a bias problem or
variance problem or both can help you

00:03:48.750 --> 00:03:48.760
variance problem or both can help you
 

00:03:48.760 --> 00:03:51.030
variance problem or both can help you
focus on selecting the most useful

00:03:51.030 --> 00:03:51.040
focus on selecting the most useful
 

00:03:51.040 --> 00:03:55.289
focus on selecting the most useful
things to try second in the earlier

00:03:55.289 --> 00:03:55.299
things to try second in the earlier
 

00:03:55.299 --> 00:03:57.120
things to try second in the earlier
error of machine learning there used to

00:03:57.120 --> 00:03:57.130
error of machine learning there used to
 

00:03:57.130 --> 00:03:59.370
error of machine learning there used to
be a lot of discussion on what's called

00:03:59.370 --> 00:03:59.380
be a lot of discussion on what's called
 

00:03:59.380 --> 00:04:02.819
be a lot of discussion on what's called
the bias variance trade-off and the

00:04:02.819 --> 00:04:02.829
the bias variance trade-off and the
 

00:04:02.829 --> 00:04:05.069
the bias variance trade-off and the
reason for that was that for a lot of

00:04:05.069 --> 00:04:05.079
reason for that was that for a lot of
 

00:04:05.079 --> 00:04:06.840
reason for that was that for a lot of
the things you could try you could

00:04:06.840 --> 00:04:06.850
the things you could try you could
 

00:04:06.850 --> 00:04:09.360
the things you could try you could
increase buyers and reduce variance or

00:04:09.360 --> 00:04:09.370
increase buyers and reduce variance or
 

00:04:09.370 --> 00:04:12.020
increase buyers and reduce variance or
reduce bodies and increase variance but

00:04:12.020 --> 00:04:12.030
reduce bodies and increase variance but
 

00:04:12.030 --> 00:04:15.630
reduce bodies and increase variance but
back in the pre deep learning era we

00:04:15.630 --> 00:04:15.640
back in the pre deep learning era we
 

00:04:15.640 --> 00:04:17.729
back in the pre deep learning era we
didn't have many tools we didn't have as

00:04:17.729 --> 00:04:17.739
didn't have many tools we didn't have as
 

00:04:17.739 --> 00:04:20.310
didn't have many tools we didn't have as
many tools that just reduced bias or

00:04:20.310 --> 00:04:20.320
many tools that just reduced bias or
 

00:04:20.320 --> 00:04:22.240
many tools that just reduced bias or
that just reduce variance

00:04:22.240 --> 00:04:22.250
that just reduce variance
 

00:04:22.250 --> 00:04:25.840
that just reduce variance
hurting the other one but in the modern

00:04:25.840 --> 00:04:25.850
hurting the other one but in the modern
 

00:04:25.850 --> 00:04:29.410
hurting the other one but in the modern
deep learning baked into error so long

00:04:29.410 --> 00:04:29.420
deep learning baked into error so long
 

00:04:29.420 --> 00:04:31.600
deep learning baked into error so long
as you can keep trading a bigger network

00:04:31.600 --> 00:04:31.610
as you can keep trading a bigger network
 

00:04:31.610 --> 00:04:33.460
as you can keep trading a bigger network
and so long as you keep getting more

00:04:33.460 --> 00:04:33.470
and so long as you keep getting more
 

00:04:33.470 --> 00:04:35.620
and so long as you keep getting more
data which isn't always the case of

00:04:35.620 --> 00:04:35.630
data which isn't always the case of
 

00:04:35.630 --> 00:04:37.260
data which isn't always the case of
either of these but if that's the case

00:04:37.260 --> 00:04:37.270
either of these but if that's the case
 

00:04:37.270 --> 00:04:39.880
either of these but if that's the case
then getting a bigger network almost

00:04:39.880 --> 00:04:39.890
then getting a bigger network almost
 

00:04:39.890 --> 00:04:41.800
then getting a bigger network almost
always just reduces your bias without

00:04:41.800 --> 00:04:41.810
always just reduces your bias without
 

00:04:41.810 --> 00:04:44.290
always just reduces your bias without
nest recruiting iberians so long as a

00:04:44.290 --> 00:04:44.300
nest recruiting iberians so long as a
 

00:04:44.300 --> 00:04:47.230
nest recruiting iberians so long as a
you regularize appropriately and getting

00:04:47.230 --> 00:04:47.240
you regularize appropriately and getting
 

00:04:47.240 --> 00:04:49.240
you regularize appropriately and getting
more data pretty much always reduces

00:04:49.240 --> 00:04:49.250
more data pretty much always reduces
 

00:04:49.250 --> 00:04:51.460
more data pretty much always reduces
your variance and doesn't hurt your bias

00:04:51.460 --> 00:04:51.470
your variance and doesn't hurt your bias
 

00:04:51.470 --> 00:04:53.920
your variance and doesn't hurt your bias
much so what's really happened is that

00:04:53.920 --> 00:04:53.930
much so what's really happened is that
 

00:04:53.930 --> 00:04:56.380
much so what's really happened is that
with these two steps the ability to

00:04:56.380 --> 00:04:56.390
with these two steps the ability to
 

00:04:56.390 --> 00:04:58.690
with these two steps the ability to
train bigger network or get more data we

00:04:58.690 --> 00:04:58.700
train bigger network or get more data we
 

00:04:58.700 --> 00:05:01.750
train bigger network or get more data we
now have tools to drive down bias and

00:05:01.750 --> 00:05:01.760
now have tools to drive down bias and
 

00:05:01.760 --> 00:05:03.909
now have tools to drive down bias and
just drive down bias or drive down

00:05:03.909 --> 00:05:03.919
just drive down bias or drive down
 

00:05:03.919 --> 00:05:06.040
just drive down bias or drive down
variance and just drive down there and

00:05:06.040 --> 00:05:06.050
variance and just drive down there and
 

00:05:06.050 --> 00:05:08.500
variance and just drive down there and
without really hurting the other thing

00:05:08.500 --> 00:05:08.510
without really hurting the other thing
 

00:05:08.510 --> 00:05:10.990
without really hurting the other thing
that much and I think this has been one

00:05:10.990 --> 00:05:11.000
that much and I think this has been one
 

00:05:11.000 --> 00:05:13.420
that much and I think this has been one
of the big reasons that deep learning

00:05:13.420 --> 00:05:13.430
of the big reasons that deep learning
 

00:05:13.430 --> 00:05:15.730
of the big reasons that deep learning
has been so useful for supervised

00:05:15.730 --> 00:05:15.740
has been so useful for supervised
 

00:05:15.740 --> 00:05:17.890
has been so useful for supervised
learning that there's much less of this

00:05:17.890 --> 00:05:17.900
learning that there's much less of this
 

00:05:17.900 --> 00:05:19.480
learning that there's much less of this
trade-off where you have to carefully

00:05:19.480 --> 00:05:19.490
trade-off where you have to carefully
 

00:05:19.490 --> 00:05:22.000
trade-off where you have to carefully
balance bias and variance but sometimes

00:05:22.000 --> 00:05:22.010
balance bias and variance but sometimes
 

00:05:22.010 --> 00:05:24.400
balance bias and variance but sometimes
you just have more options for reducing

00:05:24.400 --> 00:05:24.410
you just have more options for reducing
 

00:05:24.410 --> 00:05:26.650
you just have more options for reducing
bias and reduce or reducing variance

00:05:26.650 --> 00:05:26.660
bias and reduce or reducing variance
 

00:05:26.660 --> 00:05:28.930
bias and reduce or reducing variance
without necessarily increasing the other

00:05:28.930 --> 00:05:28.940
without necessarily increasing the other
 

00:05:28.940 --> 00:05:32.590
without necessarily increasing the other
one and in fact so as you have a well

00:05:32.590 --> 00:05:32.600
one and in fact so as you have a well
 

00:05:32.600 --> 00:05:34.090
one and in fact so as you have a well
regularize network will talk about

00:05:34.090 --> 00:05:34.100
regularize network will talk about
 

00:05:34.100 --> 00:05:36.370
regularize network will talk about
regularization starting learning video

00:05:36.370 --> 00:05:36.380
regularization starting learning video
 

00:05:36.380 --> 00:05:39.040
regularization starting learning video
training a bigger network almost never

00:05:39.040 --> 00:05:39.050
training a bigger network almost never
 

00:05:39.050 --> 00:05:41.350
training a bigger network almost never
hurts and the main calls to training in

00:05:41.350 --> 00:05:41.360
hurts and the main calls to training in
 

00:05:41.360 --> 00:05:43.230
hurts and the main calls to training in
your network that's to base is just

00:05:43.230 --> 00:05:43.240
your network that's to base is just
 

00:05:43.240 --> 00:05:45.280
your network that's to base is just
computational time so long as your

00:05:45.280 --> 00:05:45.290
computational time so long as your
 

00:05:45.290 --> 00:05:47.500
computational time so long as your
regularizing so I hope this gives you a

00:05:47.500 --> 00:05:47.510
regularizing so I hope this gives you a
 

00:05:47.510 --> 00:05:49.330
regularizing so I hope this gives you a
sense of the basic structure of how to

00:05:49.330 --> 00:05:49.340
sense of the basic structure of how to
 

00:05:49.340 --> 00:05:51.760
sense of the basic structure of how to
organize your machine learning problems

00:05:51.760 --> 00:05:51.770
organize your machine learning problems
 

00:05:51.770 --> 00:05:53.590
organize your machine learning problems
to diagnose bias and variance and I try

00:05:53.590 --> 00:05:53.600
to diagnose bias and variance and I try
 

00:05:53.600 --> 00:05:55.600
to diagnose bias and variance and I try
to select the right operation for you to

00:05:55.600 --> 00:05:55.610
to select the right operation for you to
 

00:05:55.610 --> 00:05:57.640
to select the right operation for you to
make progress on your problem one of the

00:05:57.640 --> 00:05:57.650
make progress on your problem one of the
 

00:05:57.650 --> 00:05:58.960
make progress on your problem one of the
things I mentioned several times in the

00:05:58.960 --> 00:05:58.970
things I mentioned several times in the
 

00:05:58.970 --> 00:06:01.840
things I mentioned several times in the
video is regularization is a very useful

00:06:01.840 --> 00:06:01.850
video is regularization is a very useful
 

00:06:01.850 --> 00:06:04.150
video is regularization is a very useful
technique for reducing Berens there is a

00:06:04.150 --> 00:06:04.160
technique for reducing Berens there is a
 

00:06:04.160 --> 00:06:06.070
technique for reducing Berens there is a
little bit of advisor and trade-off when

00:06:06.070 --> 00:06:06.080
little bit of advisor and trade-off when
 

00:06:06.080 --> 00:06:07.870
little bit of advisor and trade-off when
use regularization it might increase the

00:06:07.870 --> 00:06:07.880
use regularization it might increase the
 

00:06:07.880 --> 00:06:10.450
use regularization it might increase the
bias a little bit although often not too

00:06:10.450 --> 00:06:10.460
bias a little bit although often not too
 

00:06:10.460 --> 00:06:12.420
bias a little bit although often not too
much if you have a huge enough network

00:06:12.420 --> 00:06:12.430
much if you have a huge enough network
 

00:06:12.430 --> 00:06:15.520
much if you have a huge enough network
but let's dive into more details in the

00:06:15.520 --> 00:06:15.530
but let's dive into more details in the
 

00:06:15.530 --> 00:06:17.740
but let's dive into more details in the
next video so going to understand how to

00:06:17.740 --> 00:06:17.750
next video so going to understand how to
 

00:06:17.750 --> 00:06:22.150
next video so going to understand how to
apply regularization to on your network

