WEBVTT
Kind: captions
Language: en

00:00:01.930 --> 00:00:02.430
KYLE: OK.

00:00:02.430 --> 00:00:03.950
So my name's Kyle.

00:00:03.950 --> 00:00:05.910
I'm here to introduce
Professor Raphael Calvo.

00:00:05.910 --> 00:00:09.540
He's here to talk to us
about positive computing.

00:00:09.540 --> 00:00:11.680
He's the director of the
positive computing lab

00:00:11.680 --> 00:00:12.940
at the University of Sydney.

00:00:12.940 --> 00:00:16.650
And, along with Dorian Peters,
who's in the audience here,

00:00:16.650 --> 00:00:18.780
co-author of a book
about positive computing.

00:00:18.780 --> 00:00:20.321
And we actually have
a limited number

00:00:20.321 --> 00:00:23.110
of copies of those available
outside for the $10 subsidy.

00:00:23.110 --> 00:00:26.500
So please take
advantage of that.

00:00:26.500 --> 00:00:29.610
So in addition to the
positive computing lab work,

00:00:29.610 --> 00:00:32.080
he's the co-director of the
Software Engineering Group,

00:00:32.080 --> 00:00:34.930
focusing on mental health
medicine and education.

00:00:34.930 --> 00:00:36.916
He has a PhD in
artificial intelligence.

00:00:36.916 --> 00:00:39.290
And in addition to being an
expert on positive computing,

00:00:39.290 --> 00:00:42.410
he's done significant work on
effective computing, learning

00:00:42.410 --> 00:00:44.120
systems, and web engineering.

00:00:44.120 --> 00:00:46.940
So please join me in
welcoming Professor Calvo.

00:00:46.940 --> 00:00:49.390
[APPLAUSE]

00:00:49.390 --> 00:00:51.680
RAPHAEL CALVO: Thank you.

00:00:51.680 --> 00:00:54.270
Thank you very much for your
kind introduction, Kyle.

00:00:54.270 --> 00:00:57.170
As you said, I'm from
the University of Sydney.

00:00:57.170 --> 00:00:59.740
This was the first
university in Australia.

00:00:59.740 --> 00:01:02.320
Now they has about
50,000 students,

00:01:02.320 --> 00:01:04.890
and just over 7,000 staff.

00:01:04.890 --> 00:01:07.080
Sydney has a very
strong relationship

00:01:07.080 --> 00:01:09.855
with the beaches and the natural
beauty across the country,

00:01:09.855 --> 00:01:11.120
as you might know.

00:01:11.120 --> 00:01:15.910
You might also know about its
reputation for sports, and some

00:01:15.910 --> 00:01:18.530
of the iconic buildings,
like the opera house there

00:01:18.530 --> 00:01:21.540
that was finished in 1973.

00:01:21.540 --> 00:01:24.490
Now, back then in the
1970s, most people

00:01:24.490 --> 00:01:27.150
were foreign to
digital experiences,

00:01:27.150 --> 00:01:32.120
both here in the US, in
Australia, everywhere else.

00:01:32.120 --> 00:01:35.920
Only in the 1980s
digital experiences

00:01:35.920 --> 00:01:40.580
began to get into our homes
through personal computers

00:01:40.580 --> 00:01:42.580
and gaming consoles.

00:01:42.580 --> 00:01:45.850
In the 1990s, those
clunky mobile phones

00:01:45.850 --> 00:01:49.310
started becoming smaller,
cooler, and more common.

00:01:49.310 --> 00:01:51.090
And then these
mobile phones started

00:01:51.090 --> 00:01:54.260
being able to do more than
just making phone calls.

00:01:54.260 --> 00:01:57.750
And in just the last five
years, digital experiences

00:01:57.750 --> 00:02:01.180
have begun become part
of everything we do,

00:02:01.180 --> 00:02:04.565
from work, business,
friendships, relationships,

00:02:04.565 --> 00:02:05.065
romance.

00:02:08.846 --> 00:02:12.550
And one critical
question remains.

00:02:12.550 --> 00:02:18.230
All these digital experiences--
are they making us any happier?

00:02:18.230 --> 00:02:21.060
Is all this effort,
all this investment,

00:02:21.060 --> 00:02:23.840
all this carbon emissions
having an impact

00:02:23.840 --> 00:02:26.870
on our overall well-being?

00:02:26.870 --> 00:02:30.400
Incredibly, according to
the statistics, it isn't.

00:02:30.400 --> 00:02:31.780
It's not having any impact.

00:02:31.780 --> 00:02:34.620
Populations surveys
for the last 50 years

00:02:34.620 --> 00:02:37.460
or so show that wealth,
and, therefore, also

00:02:37.460 --> 00:02:41.050
digital devices and
experiences, have

00:02:41.050 --> 00:02:43.390
quadrupled in some countries.

00:02:43.390 --> 00:02:47.470
Yet well-being has
hardly changed.

00:02:47.470 --> 00:02:50.930
Now, as an engineer,
I have to ask myself

00:02:50.930 --> 00:02:53.080
if technologies
are being developed

00:02:53.080 --> 00:02:57.060
to improve people's lives,
why is the correlation so low?

00:03:00.280 --> 00:03:04.500
So we have, over the
last few decades,

00:03:04.500 --> 00:03:09.210
been designing for things
like productivity, efficiency,

00:03:09.210 --> 00:03:11.940
accuracy, speed, and so on.

00:03:11.940 --> 00:03:14.090
And only very
recently we have begun

00:03:14.090 --> 00:03:18.580
to work on things like
satisfaction, pleasure, desire.

00:03:18.580 --> 00:03:21.680
Productivity has always
played a starring role.

00:03:21.680 --> 00:03:24.580
Productivity is generally
easy to measure.

00:03:24.580 --> 00:03:27.870
It's easy to design for.

00:03:27.870 --> 00:03:31.880
Computers, in general,
began as a tool for work.

00:03:31.880 --> 00:03:34.760
And now, this has
gone way beyond this.

00:03:34.760 --> 00:03:37.900
Now, computers are
in every aspect

00:03:37.900 --> 00:03:42.130
of our moment-to-moment
lived experience.

00:03:42.130 --> 00:03:47.010
Now, they see in us track,
measure, compare, judge,

00:03:47.010 --> 00:03:50.080
everything we do, from the
number of steps we walk

00:03:50.080 --> 00:03:54.540
and miles we run,
the friends we have,

00:03:54.540 --> 00:03:57.440
even the number of
times we make love.

00:03:57.440 --> 00:03:59.860
Yes, there is an app for that.

00:03:59.860 --> 00:04:02.600
So we measure
literally everything.

00:04:02.600 --> 00:04:07.360
This has created what we see as
a tyranny of productivity that

00:04:07.360 --> 00:04:10.710
makes it all the more
difficult to focus

00:04:10.710 --> 00:04:13.140
on one thing at a
time, to be mindful--

00:04:13.140 --> 00:04:16.160
so I love that this
week is mindfulness week

00:04:16.160 --> 00:04:20.510
here in Google-- to
pause, to disconnect,

00:04:20.510 --> 00:04:24.640
to pay attention to
quality over quantity,

00:04:24.640 --> 00:04:30.170
to take the time to
be kind, compassionate

00:04:30.170 --> 00:04:33.000
towards other people, et cetera.

00:04:33.000 --> 00:04:35.930
All things that
are very well known

00:04:35.930 --> 00:04:37.150
to be critical to well-being.

00:04:40.010 --> 00:04:43.580
In other words, we have
been designing for proxies.

00:04:43.580 --> 00:04:48.060
We design for things like
productivity, wealth, pleasure,

00:04:48.060 --> 00:04:51.000
because we think those
things will make us happier,

00:04:51.000 --> 00:04:52.730
live a better life.

00:04:52.730 --> 00:04:56.400
But now we know from
psychology that those are not

00:04:56.400 --> 00:04:58.210
very good proxies.

00:04:58.210 --> 00:05:00.570
The correlation of those
things with happiness

00:05:00.570 --> 00:05:02.740
is not that high.

00:05:02.740 --> 00:05:06.080
So we have been designing
for all these proxies,

00:05:06.080 --> 00:05:09.140
but we have not been
designing directly

00:05:09.140 --> 00:05:12.650
for the thing that matters most.

00:05:12.650 --> 00:05:15.750
So if we want to
change or develop

00:05:15.750 --> 00:05:19.200
technologies that increase
worldwide well-being,

00:05:19.200 --> 00:05:23.040
we have to design for
well-being directly.

00:05:23.040 --> 00:05:24.080
Directly.

00:05:24.080 --> 00:05:27.350
In fact, we believe that all
technologies, all the products

00:05:27.350 --> 00:05:30.960
that Google develops, all the
products that all the software

00:05:30.960 --> 00:05:33.770
industry develops, all
digital experiences,

00:05:33.770 --> 00:05:37.387
should be designed to support
psychological well-being.

00:05:37.387 --> 00:05:39.220
And this is what we
call positive computing.

00:05:39.220 --> 00:05:41.460
The research and
development of technology

00:05:41.460 --> 00:05:43.970
to support well-being
and human potential.

00:05:43.970 --> 00:05:47.490
And that's a shameless
plug for our book

00:05:47.490 --> 00:05:49.450
here with Dorian Peters.

00:05:49.450 --> 00:05:52.405
Now, when I give a talk to
engineers-- how many of you

00:05:52.405 --> 00:05:54.271
are engineers here?

00:05:54.271 --> 00:05:54.770
OK.

00:05:54.770 --> 00:05:55.660
The majority.

00:05:55.660 --> 00:05:58.530
The first thing that
people tend to ask--

00:05:58.530 --> 00:06:01.980
is that something that we
can study scientifically?

00:06:01.980 --> 00:06:06.190
Is that something that
we can actually measure?

00:06:06.190 --> 00:06:08.260
Well, yes.

00:06:08.260 --> 00:06:09.170
You can measure it.

00:06:09.170 --> 00:06:11.440
And there are many
different ways of doing so.

00:06:11.440 --> 00:06:14.005
I'm going to be covering
some of them today.

00:06:17.370 --> 00:06:21.430
Psychologists, and particularly
behavioral economists,

00:06:21.430 --> 00:06:23.740
have been working on many
different methodologies

00:06:23.740 --> 00:06:26.820
that you can use to
measure well-being.

00:06:26.820 --> 00:06:29.910
But first what I want to do
is to review a little bit

00:06:29.910 --> 00:06:32.460
about how technologies
are changing us.

00:06:32.460 --> 00:06:35.580
And then I will tell you some of
the different disciplines that

00:06:35.580 --> 00:06:40.366
can contribute to different
ways of measuring well-being.

00:06:40.366 --> 00:06:41.740
And then I will
tell you a little

00:06:41.740 --> 00:06:44.370
but about our own projects.

00:06:44.370 --> 00:06:48.320
So we know our brains are
adapting to technology.

00:06:48.320 --> 00:06:52.180
Technology is changing the
way we remember things.

00:06:52.180 --> 00:06:56.900
Technology is changing the
way we relate to each other.

00:06:56.900 --> 00:06:58.980
Technology is even
changing the way

00:06:58.980 --> 00:07:02.230
that we understand ourselves.

00:07:02.230 --> 00:07:05.470
So the ubiquity
of digital devices

00:07:05.470 --> 00:07:11.020
means that digital experiences
are slithering their way

00:07:11.020 --> 00:07:13.410
into every aspect of our life.

00:07:13.410 --> 00:07:15.960
Every aspect that
psychologists know

00:07:15.960 --> 00:07:19.370
influence our
psychological well-being.

00:07:19.370 --> 00:07:22.200
Obviously, the relationship
between technology

00:07:22.200 --> 00:07:24.740
and well-being is
very, very complex.

00:07:24.740 --> 00:07:26.890
There is lot of
research in this area,

00:07:26.890 --> 00:07:32.470
particularly around social
networking frameworks.

00:07:32.470 --> 00:07:35.660
So I have chosen here
a number of papers that

00:07:35.660 --> 00:07:37.697
talk about this complexity.

00:07:37.697 --> 00:07:39.030
So there are hundreds of papers.

00:07:39.030 --> 00:07:44.770
Some of them talk about how
social networking decline,

00:07:44.770 --> 00:07:48.480
produce declines in
subjective well-being.

00:07:48.480 --> 00:07:52.940
Other ones have focused
on emotional contagion.

00:07:52.940 --> 00:07:54.450
Other ones, that
are considered some

00:07:54.450 --> 00:08:00.180
of the more nuanced approaches,
like the one by Maria Burke,

00:08:00.180 --> 00:08:03.990
look into, or have seen,
that the impact really

00:08:03.990 --> 00:08:08.250
depends on what you're
doing with those tools.

00:08:08.250 --> 00:08:13.994
These papers show
about the impact.

00:08:13.994 --> 00:08:16.410
There are other ones, like "A
Wandering Mind Is an Unhappy

00:08:16.410 --> 00:08:20.320
Mind" by Killingsworth, that
talk about the new tools

00:08:20.320 --> 00:08:22.390
that we can use to
measure well-being.

00:08:22.390 --> 00:08:25.360
So that one in a particular
uses mobile phone technologies

00:08:25.360 --> 00:08:27.180
to use experience sampling.

00:08:27.180 --> 00:08:29.640
And what they did it they
had 5,000 participants.

00:08:29.640 --> 00:08:32.570
And they asked people,
what are you doing?

00:08:32.570 --> 00:08:34.380
What are you thinking about?

00:08:34.380 --> 00:08:36.760
And how do you feel?

00:08:36.760 --> 00:08:38.669
The first very
interesting outcome

00:08:38.669 --> 00:08:43.130
was that up to 50% of the time,
we are thinking about something

00:08:43.130 --> 00:08:45.310
else to what we're doing.

00:08:45.310 --> 00:08:48.140
So roughly, maybe
half of you might

00:08:48.140 --> 00:08:52.040
be thinking about something
else than my seminar.

00:08:52.040 --> 00:08:54.650
The other interesting outcome
is that it doesn't depend

00:08:54.650 --> 00:08:56.190
on the quantity of my seminar.

00:08:56.190 --> 00:08:59.300
It doesn't depend on the
quality of our experience.

00:08:59.300 --> 00:09:03.430
Our mind wanders no matter
what we're doing, OK?

00:09:03.430 --> 00:09:06.760
For all type of
day-to-day activities.

00:09:06.760 --> 00:09:09.120
Even in making love,
people were distracted

00:09:09.120 --> 00:09:11.940
or thinking about something
else up to 30% of the time.

00:09:15.410 --> 00:09:18.080
So this is one of the
many tools that we

00:09:18.080 --> 00:09:22.590
can use to understand
people's experiences.

00:09:22.590 --> 00:09:25.470
If you thought that 5,000
people was a large number,

00:09:25.470 --> 00:09:27.630
think about the other
experiment here.

00:09:27.630 --> 00:09:29.490
61 million participants.

00:09:29.490 --> 00:09:33.500
It was a Facebook study that
show that different user

00:09:33.500 --> 00:09:38.880
interfaces can change the
way people seek information

00:09:38.880 --> 00:09:40.150
and vote.

00:09:40.150 --> 00:09:45.120
And this was done in the
2010 congressional election.

00:09:45.120 --> 00:09:51.744
So the input on behavior and on
people's experiences is huge.

00:09:51.744 --> 00:09:53.410
Now, there are many
different techniques

00:09:53.410 --> 00:09:57.390
that we can use to understand
people's experiences.

00:09:57.390 --> 00:10:00.022
I, and a lot of people in the
human-computer interaction

00:10:00.022 --> 00:10:01.480
community, have
worked on something

00:10:01.480 --> 00:10:03.000
we call cognitive computing.

00:10:03.000 --> 00:10:05.310
It's trying to understand
where people think.

00:10:05.310 --> 00:10:07.390
And we particular
have been working

00:10:07.390 --> 00:10:12.870
for a few years on technologies
around writing, particularly

00:10:12.870 --> 00:10:14.130
academic writing.

00:10:14.130 --> 00:10:16.920
One of the cool things about
writing, studying writing,

00:10:16.920 --> 00:10:19.550
is that when people write,
is very hard for them

00:10:19.550 --> 00:10:22.690
to be thinking about
something else.

00:10:22.690 --> 00:10:24.580
So within that, what
we have been doing

00:10:24.580 --> 00:10:27.120
is working, developing
concept map summaries,

00:10:27.120 --> 00:10:29.230
different type of tools
and visualizations

00:10:29.230 --> 00:10:31.910
that help us understand that.

00:10:31.910 --> 00:10:34.620
And then those are
feedback interventions

00:10:34.620 --> 00:10:36.320
that we can give
writers for them

00:10:36.320 --> 00:10:38.410
to reflect on what the right.

00:10:38.410 --> 00:10:41.130
Now, one of the best things
that we can do to help people

00:10:41.130 --> 00:10:42.420
is to provide feedback.

00:10:42.420 --> 00:10:44.380
But it's very
challenging to understand

00:10:44.380 --> 00:10:46.800
the impact of that
feedback, to know which

00:10:46.800 --> 00:10:48.110
is the best type of feedback.

00:10:48.110 --> 00:10:51.270
So we have using
behavioral analytics tools

00:10:51.270 --> 00:10:54.270
and visualizations,
like in this study.

00:10:54.270 --> 00:10:57.820
So I hear different roles
or different writer.

00:10:57.820 --> 00:11:01.000
Each of the is green balls
is a writing session.

00:11:01.000 --> 00:11:02.640
So you can see
there's people that

00:11:02.640 --> 00:11:04.390
spend more time writing,
other people that

00:11:04.390 --> 00:11:07.020
spend less time writing.

00:11:07.020 --> 00:11:10.840
And then we have two
types of intervention.

00:11:10.840 --> 00:11:13.606
So the triangles are
reflective feedback,

00:11:13.606 --> 00:11:15.230
and the squares are
directive feedback.

00:11:15.230 --> 00:11:17.520
So in on one type of
feedback, we tell the person,

00:11:17.520 --> 00:11:19.290
there's something wrong
in what you wrote.

00:11:19.290 --> 00:11:21.540
And in the other one, we
say, there's something wrong.

00:11:21.540 --> 00:11:23.501
This is what you
should do to fix it.

00:11:23.501 --> 00:11:25.500
The cool thing with these
tools is that then you

00:11:25.500 --> 00:11:29.536
can tracks and see if people
is reading the feedback,

00:11:29.536 --> 00:11:30.910
if people is going
and addressing

00:11:30.910 --> 00:11:33.960
the feedback, how much time they
spend addressing the feedback,

00:11:33.960 --> 00:11:34.560
and so on.

00:11:38.160 --> 00:11:40.670
The third type of
techniques that we are using

00:11:40.670 --> 00:11:44.070
is affective computing,
so detecting emotions.

00:11:44.070 --> 00:11:48.070
In this case, we have facial
expression recognition.

00:11:48.070 --> 00:11:50.140
So the writer is working there.

00:11:50.140 --> 00:11:51.870
And you can detect
if the person is

00:11:51.870 --> 00:11:56.040
being bored, confused,
delighted, et cetera.

00:11:56.040 --> 00:11:56.890
Here's another plug.

00:11:56.890 --> 00:11:59.700
That's "Oxford Handbook
of Affective Computing"

00:11:59.700 --> 00:12:01.660
that was also
released last month.

00:12:01.660 --> 00:12:03.450
And that brings
research literature

00:12:03.450 --> 00:12:04.710
from the whole discipline.

00:12:04.710 --> 00:12:06.840
So the 50 chapters
cover everything

00:12:06.840 --> 00:12:10.260
in the area of
affective computing.

00:12:10.260 --> 00:12:14.070
The second thing that we're
doing with these tools

00:12:14.070 --> 00:12:18.390
is looking at how they
can be used in training.

00:12:18.390 --> 00:12:22.100
This is in medical education,
so we're using it in telehealth,

00:12:22.100 --> 00:12:26.350
trying to help future doctors
connect better to patients,

00:12:26.350 --> 00:12:29.110
interact better to patients,
through telehealth system.

00:12:29.110 --> 00:12:33.290
So the system detects basic
emotions and acknowledgment

00:12:33.290 --> 00:12:33.890
expressions.

00:12:33.890 --> 00:12:36.070
So it could be
nodding and shaking,

00:12:36.070 --> 00:12:39.600
turn-taking, et cetera.

00:12:39.600 --> 00:12:42.020
And you can use different
modalities, not just

00:12:42.020 --> 00:12:42.920
computer vision.

00:12:42.920 --> 00:12:46.070
In this video, we have an
intelligent tutoring system

00:12:46.070 --> 00:12:48.830
that is teaching the person
about information technologies.

00:12:48.830 --> 00:12:49.960
And it will ask questions.

00:12:49.960 --> 00:12:51.400
And the person replies.

00:12:51.400 --> 00:12:54.490
So what you see there
on the top is what

00:12:54.490 --> 00:12:56.150
the person sees on the screen.

00:12:56.150 --> 00:12:59.440
And he's plugged to a number
of physiological sensors.

00:12:59.440 --> 00:13:01.859
You can--

00:13:01.859 --> 00:13:04.150
ON-SCREEN NARRATOR: Faster
and more efficient than CIFC

00:13:04.150 --> 00:13:05.800
processors.

00:13:05.800 --> 00:13:08.170
RISC has a reduced
instruction set,

00:13:08.170 --> 00:13:11.330
which prevents fewer
bottlenecks in processing.

00:13:11.330 --> 00:13:15.130
Also, RISC processors can
execute multiple instructions

00:13:15.130 --> 00:13:16.410
simultaneously.

00:13:16.410 --> 00:13:17.955
Let's go on to something else.

00:13:22.330 --> 00:13:24.942
Take a close look at
these four pictures.

00:13:24.942 --> 00:13:26.400
RAPHAEL CALVO: So
here what you can

00:13:26.400 --> 00:13:28.980
see is the different
physiological signals are being

00:13:28.980 --> 00:13:30.980
used, these machine
learning techniques,

00:13:30.980 --> 00:13:33.540
to detect the
different emotions.

00:13:33.540 --> 00:13:35.820
And the system can
then be adapted

00:13:35.820 --> 00:13:37.330
to what the person is feeling.

00:13:37.330 --> 00:13:39.090
If the person is
feeling confused,

00:13:39.090 --> 00:13:41.029
you might give him
more explanations.

00:13:41.029 --> 00:13:42.570
If the person is
bored, you can raise

00:13:42.570 --> 00:13:43.861
the challenge of the questions.

00:13:46.590 --> 00:13:48.780
Now, if we have
new techniques that

00:13:48.780 --> 00:13:53.240
allow us to understand people's
cognitions, people's behaviors,

00:13:53.240 --> 00:13:56.190
and people's
emotions, shouldn't we

00:13:56.190 --> 00:13:58.170
be using these to
improve well-being?

00:14:00.900 --> 00:14:03.200
And this is the
new field-- I think

00:14:03.200 --> 00:14:05.130
it's a very interdisciplinary
field-- that we

00:14:05.130 --> 00:14:06.690
call positive computing.

00:14:06.690 --> 00:14:09.440
And so the disciplines include,
of course, all the ones

00:14:09.440 --> 00:14:12.280
from psychology
and brain sciences.

00:14:12.280 --> 00:14:14.140
Computing, there's
a lot of work being

00:14:14.140 --> 00:14:16.740
done in the areas of
affective computing,

00:14:16.740 --> 00:14:19.590
personal informatics,
persuasive technologies,

00:14:19.590 --> 00:14:22.300
attentive technologies.

00:14:22.300 --> 00:14:24.540
Very interestingly, there's
some work in education,

00:14:24.540 --> 00:14:28.910
and a lot of work on behavioral
economics on well-being.

00:14:28.910 --> 00:14:31.580
And finally, in design,
human-computer interaction,

00:14:31.580 --> 00:14:33.885
value-sensitive
design, et cetera.

00:14:33.885 --> 00:14:35.510
People there have
been working on this.

00:14:35.510 --> 00:14:38.020
Now, this is a highly
interdisciplinary area.

00:14:38.020 --> 00:14:39.890
So when we were
writing the book,

00:14:39.890 --> 00:14:43.184
we sought advice from experts
in those different disciplines.

00:14:43.184 --> 00:14:44.100
We're all [INAUDIBLE].

00:14:44.100 --> 00:14:46.890
So here we have people
from positive psychology

00:14:46.890 --> 00:14:48.015
and emotional intelligence.

00:14:50.620 --> 00:14:54.960
Maybe the most commonly
used instrument

00:14:54.960 --> 00:15:02.410
to measure well-being is the
DSM diagnosis statistical manual

00:15:02.410 --> 00:15:03.350
depression scale.

00:15:03.350 --> 00:15:05.010
They see as the
depression scale,

00:15:05.010 --> 00:15:09.470
Center for Epidemiological
Studies depression scale.

00:15:09.470 --> 00:15:11.470
These are small
questionnaires that

00:15:11.470 --> 00:15:13.870
are considered so
reliable, for example

00:15:13.870 --> 00:15:16.410
by insurance companies,
that if you score very

00:15:16.410 --> 00:15:20.880
high on those surveys,
the insurance company is

00:15:20.880 --> 00:15:23.580
willing to pay for
your treatment.

00:15:23.580 --> 00:15:27.200
In these model, depression--
or the absence of depression--

00:15:27.200 --> 00:15:29.330
means you're doing well.

00:15:29.330 --> 00:15:31.340
That's the definition
of well-being--

00:15:31.340 --> 00:15:34.340
the absence of illness.

00:15:34.340 --> 00:15:36.620
Positive psychology
is a movement

00:15:36.620 --> 00:15:41.630
that arose from the critics
of this clinical model.

00:15:41.630 --> 00:15:44.850
People like Martin
Seligman, [INAUDIBLE],

00:15:44.850 --> 00:15:47.930
Felicia Huppert,
they were focusing

00:15:47.930 --> 00:15:50.070
on looking at the
factors that we

00:15:50.070 --> 00:15:53.200
can use to identify those
peoples that are flourishing,

00:15:53.200 --> 00:15:57.720
that are very high in
the well-being scale,

00:15:57.720 --> 00:16:01.040
and then in studying
how those factors can

00:16:01.040 --> 00:16:04.640
be promoted across population.

00:16:04.640 --> 00:16:07.320
One of these factors,
or set of factors,

00:16:07.320 --> 00:16:09.360
would be the socio-emotional
intelligence.

00:16:09.360 --> 00:16:12.160
This is something that people
in human resources in business

00:16:12.160 --> 00:16:15.390
has focused a lot, but
also in psychology.

00:16:15.390 --> 00:16:21.660
And looking at how being able
to recognize our own emotions

00:16:21.660 --> 00:16:24.370
and regulate them, how
being able to recognize

00:16:24.370 --> 00:16:28.800
other people's emotions and
regulate them, and maintain

00:16:28.800 --> 00:16:31.450
relationships, how
all those skills

00:16:31.450 --> 00:16:38.420
help us live better lives, be
more productive, et cetera.

00:16:38.420 --> 00:16:40.270
But mostly about well-being.

00:16:40.270 --> 00:16:43.190
Some of these
factors also include,

00:16:43.190 --> 00:16:45.840
in self-determination
theory and other theories,

00:16:45.840 --> 00:16:50.250
things like autonomy,
competence, connectedness.

00:16:50.250 --> 00:16:54.760
And generally, different
psychological theories

00:16:54.760 --> 00:16:56.390
will have different factors.

00:16:56.390 --> 00:16:58.330
Another approach
that has been taken,

00:16:58.330 --> 00:17:02.780
especially by economists like
Nobel Prize winner Daniel

00:17:02.780 --> 00:17:06.089
Kahneman, has been to follow
subjective well-being.

00:17:06.089 --> 00:17:09.400
Ask people about
their subjective,

00:17:09.400 --> 00:17:12.390
their personal experience.

00:17:12.390 --> 00:17:14.740
Of course, asking people
directly what they think

00:17:14.740 --> 00:17:19.520
sometimes is troublesome.

00:17:19.520 --> 00:17:22.260
But using experience sampling
and other techniques that

00:17:22.260 --> 00:17:26.450
have been developed by
economists and psychologists,

00:17:26.450 --> 00:17:31.560
you can get a quite accurate
measure over a period of time.

00:17:31.560 --> 00:17:34.900
Another approach is,
obviously, using neuroscience.

00:17:34.900 --> 00:17:36.950
People like Richard
Davidson, for example,

00:17:36.950 --> 00:17:39.740
has been studying the impact
of mindfulness training

00:17:39.740 --> 00:17:40.760
on the brain.

00:17:40.760 --> 00:17:43.690
So you can see how when you
promote certain factors,

00:17:43.690 --> 00:17:48.100
you can see how that change your
brain over a period of time.

00:17:48.100 --> 00:17:50.030
So different
psychological theories

00:17:50.030 --> 00:17:52.430
will contribute to
our understanding

00:17:52.430 --> 00:17:55.660
of these different factors--
autonomy, connectedness,

00:17:55.660 --> 00:17:59.190
competence, meaning positive
emotions, engagement,

00:17:59.190 --> 00:18:00.780
et cetera.

00:18:00.780 --> 00:18:03.260
Now as a human-computer
interaction,

00:18:03.260 --> 00:18:06.410
I don't have to
become a psychologist,

00:18:06.410 --> 00:18:08.520
although, obviously, we
need to work with them.

00:18:08.520 --> 00:18:12.310
We can combine some of these
different factors, some

00:18:12.310 --> 00:18:15.640
of these different theories, and
look into how we can use them

00:18:15.640 --> 00:18:16.855
into our own designs.

00:18:20.896 --> 00:18:22.270
Economists, as I
was saying, have

00:18:22.270 --> 00:18:26.590
been using measures of
well-being significantly.

00:18:26.590 --> 00:18:28.370
The World Happiness
Report, for example,

00:18:28.370 --> 00:18:32.000
provides a summary of the
statistics across the world.

00:18:32.000 --> 00:18:34.420
This is something that
is done frequently.

00:18:34.420 --> 00:18:36.920
Last one, I think, was 2012.

00:18:36.920 --> 00:18:39.600
In the United Kingdom,
the government

00:18:39.600 --> 00:18:42.280
actually has a special
unit of goals and surveys,

00:18:42.280 --> 00:18:44.740
and measures well-being
across the country.

00:18:44.740 --> 00:18:48.080
And here you'll see a map,
and the different regions

00:18:48.080 --> 00:18:51.570
are mapped and measured, and
they use this in policy-making.

00:18:51.570 --> 00:18:55.310
So they make decisions on where
to invest government money, tax

00:18:55.310 --> 00:18:58.260
money, depending on the
impact it has on well-being.

00:18:58.260 --> 00:19:00.910
And this has been done
across Europe, as well.

00:19:00.910 --> 00:19:02.800
In the US, rather
than governments,

00:19:02.800 --> 00:19:05.310
a lot of the initiatives
are commercial.

00:19:05.310 --> 00:19:09.042
The Gallup Healthways survey
is done, actually, every day.

00:19:09.042 --> 00:19:10.250
So they have the [INAUDIBLE].

00:19:10.250 --> 00:19:11.534
You can go to a website.

00:19:11.534 --> 00:19:13.200
And they give you
measures of well-being

00:19:13.200 --> 00:19:17.020
in different
regions, done daily.

00:19:17.020 --> 00:19:19.280
So all these are different
ways of measuring

00:19:19.280 --> 00:19:20.930
subjective well-being.

00:19:20.930 --> 00:19:24.260
And we have used
experience utility.

00:19:24.260 --> 00:19:28.090
Those are of the measures
introduced by Daniel Kahneman,

00:19:28.090 --> 00:19:29.250
other people.

00:19:29.250 --> 00:19:31.440
You can also use experience
sampling techniques,

00:19:31.440 --> 00:19:34.210
like the study I mentioned
on mind wandering.

00:19:34.210 --> 00:19:37.910
Nowadays, we can start using
affective computing techniques

00:19:37.910 --> 00:19:41.100
to automatically detect
things like engagement,

00:19:41.100 --> 00:19:44.540
to understand better about
people's emotions, et cetera.

00:19:44.540 --> 00:19:49.860
So you don't have to be
interrupting users that often.

00:19:49.860 --> 00:19:51.440
Now, of course,
we're talking here

00:19:51.440 --> 00:19:53.170
about well-being promotion.

00:19:53.170 --> 00:19:55.190
Many mental health
professionals,

00:19:55.190 --> 00:19:57.870
as the ones that we work
with, have to understandably

00:19:57.870 --> 00:20:00.910
be focusing on mental illness.

00:20:00.910 --> 00:20:03.220
But in this diagram
by Felicia Huppert,

00:20:03.220 --> 00:20:04.970
I think it's very
interesting, because she

00:20:04.970 --> 00:20:11.890
shows how moving the mean
can improve well-being

00:20:11.890 --> 00:20:13.020
across the population.

00:20:13.020 --> 00:20:15.520
So it can increase the number
of people who are flourishing,

00:20:15.520 --> 00:20:19.810
and reduce the number of people
who have a mental disorder.

00:20:19.810 --> 00:20:25.990
So that we should be using the
technologies, the approaches,

00:20:25.990 --> 00:20:29.020
for mental health
promotion in the design

00:20:29.020 --> 00:20:32.280
of all our technologies.

00:20:32.280 --> 00:20:33.760
This is, I think,
where technology

00:20:33.760 --> 00:20:36.300
can have the most impact.

00:20:36.300 --> 00:20:39.260
And to design for
well-being, we could

00:20:39.260 --> 00:20:41.690
look into the different
factors that psychologists

00:20:41.690 --> 00:20:43.160
have identified.

00:20:43.160 --> 00:20:45.810
These are some of the ones
that we cover in the book.

00:20:45.810 --> 00:20:49.232
They are covered
there in more detail.

00:20:49.232 --> 00:20:52.810
And for each of them, we have
looked into the literature that

00:20:52.810 --> 00:20:55.970
shows that they are correlated,
strongly correlated,

00:20:55.970 --> 00:20:58.210
or have an impact on well-being.

00:20:58.210 --> 00:21:01.950
And there are a number
of interventions

00:21:01.950 --> 00:21:07.550
that have shown to be successful
in improving each of these.

00:21:07.550 --> 00:21:09.500
So for example, in
positive emotions,

00:21:09.500 --> 00:21:13.520
is probably the one
that we focus most often

00:21:13.520 --> 00:21:15.650
in human-computer interaction.

00:21:15.650 --> 00:21:19.860
Designers generally talk about
delight, pleasure, and fun,

00:21:19.860 --> 00:21:22.550
to describe their design briefs.

00:21:22.550 --> 00:21:26.350
Now, generally, when we talk
about pleasure, fun, et cetera,

00:21:26.350 --> 00:21:29.160
we do it because we
know that it will

00:21:29.160 --> 00:21:32.630
make the product sell more.

00:21:32.630 --> 00:21:36.780
People will spend more time
on the websites, et cetera.

00:21:36.780 --> 00:21:38.780
There's very little
research looking

00:21:38.780 --> 00:21:42.320
at the effect of the impact of
positive emotions in long term

00:21:42.320 --> 00:21:44.400
well-being.

00:21:44.400 --> 00:21:46.890
Some of that is done, for
example, by Jane McGonigal, who

00:21:46.890 --> 00:21:49.470
has looked at them by the
impact of positive emotions

00:21:49.470 --> 00:21:52.170
triggered by games, et
cetera, on personal change.

00:21:52.170 --> 00:21:56.030
Don Norman has worked a
lot on emotional design,

00:21:56.030 --> 00:21:58.195
the impact of how we can
use positive emotions.

00:22:00.700 --> 00:22:03.920
So both of them also have
contribute to the book.

00:22:03.920 --> 00:22:06.510
Another area that
we have worked on

00:22:06.510 --> 00:22:09.950
is how you can use technologies
to develop empathy.

00:22:09.950 --> 00:22:12.950
Often, here, it's about
role-playing games,

00:22:12.950 --> 00:22:15.120
like in this one,
the Frontiers game,

00:22:15.120 --> 00:22:19.820
that allows you to play either
the side of a person escaping

00:22:19.820 --> 00:22:22.740
Africa, the refugee
into Europe, or the side

00:22:22.740 --> 00:22:28.290
of a policeman whose job
is to stop these people.

00:22:28.290 --> 00:22:30.850
Or this other one,
the Peacemaker game,

00:22:30.850 --> 00:22:34.570
that you can play the role of
the prime minister of Israel

00:22:34.570 --> 00:22:35.850
or Palestine.

00:22:35.850 --> 00:22:39.370
And you can see what is the
impact of your decisions.

00:22:39.370 --> 00:22:44.040
They have gone through so many
phases and decision-making

00:22:44.040 --> 00:22:46.520
there, that they have
actual video that

00:22:46.520 --> 00:22:49.650
shows when you take this
decision, this is what happens.

00:22:54.010 --> 00:22:55.880
Developing altruism.

00:22:55.880 --> 00:22:59.380
Here in Stanford, Jeremy
Bailenson , for example,

00:22:59.380 --> 00:23:03.960
has works a lot on interventions
that can help people become

00:23:03.960 --> 00:23:07.820
more altruistic and more
helpful towards others.

00:23:07.820 --> 00:23:11.810
So in this experiment, he
allows you to play either

00:23:11.810 --> 00:23:16.250
the side of Superman, so you go
flying around the city trying

00:23:16.250 --> 00:23:19.310
to find a kid who needs help.

00:23:19.310 --> 00:23:21.860
Or you fly around the
city, but your character

00:23:21.860 --> 00:23:23.680
is just in a
helicopter, just doing

00:23:23.680 --> 00:23:26.990
a tourist trip around the city.

00:23:26.990 --> 00:23:30.060
then something happens when
you come out of the lab.

00:23:30.060 --> 00:23:32.620
A person has an emergency.

00:23:32.620 --> 00:23:36.630
And they measure how
much people help.

00:23:36.630 --> 00:23:39.460
And the people who have
played Superman's role

00:23:39.460 --> 00:23:42.170
is much more likely to help.

00:23:42.170 --> 00:23:45.720
And they spend more time
helping the person that need.

00:23:49.090 --> 00:23:52.650
We can introduce this in
everyday software designs.

00:23:52.650 --> 00:23:57.330
I think praise, praise is
such an important element

00:23:57.330 --> 00:23:59.760
in our relationship with others.

00:23:59.760 --> 00:24:04.230
And in online systems,
we can actually

00:24:04.230 --> 00:24:07.730
tend to optimise too
much through usability,

00:24:07.730 --> 00:24:10.440
so if you look at the
design of LinkedIn,

00:24:10.440 --> 00:24:14.270
and you probably have seen the
endorsements feature there.

00:24:14.270 --> 00:24:18.560
Is so easy to endorse other
people for whatever skill

00:24:18.560 --> 00:24:20.930
that it becomes meaningless.

00:24:20.930 --> 00:24:25.410
Because I have been
endorsed for Microsoft Word.

00:24:25.410 --> 00:24:29.450
It's like, what does it mean?

00:24:29.450 --> 00:24:31.780
What does it mean when
you endorse someone else?

00:24:31.780 --> 00:24:35.510
And the problem is that we have
made it so efficient, so easy

00:24:35.510 --> 00:24:38.170
to endorse other people,
that people just do it.

00:24:38.170 --> 00:24:41.240
Now, Yammer does
a much better job,

00:24:41.240 --> 00:24:45.130
because you have to explain why
you are praising someone else.

00:24:45.130 --> 00:24:46.920
And because of efficiency,
we are actually

00:24:46.920 --> 00:24:49.540
missing the opportunity
of helping the two sides--

00:24:49.540 --> 00:24:51.460
on the one hand, the
person who is helping,

00:24:51.460 --> 00:24:54.230
and on the other, the person,
obviously, who receives

00:24:54.230 --> 00:24:58.360
the help or the praise.

00:24:58.360 --> 00:25:02.720
So what we have been doing
is working with organizations

00:25:02.720 --> 00:25:07.070
like Google and others,
looking into how

00:25:07.070 --> 00:25:09.880
we can introduce
positive computing

00:25:09.880 --> 00:25:13.640
approaches into the development
of everyday software.

00:25:13.640 --> 00:25:17.860
And we look at-- we call them
the happy camper factors--

00:25:17.860 --> 00:25:20.180
because is just to
remember the acronym.

00:25:20.180 --> 00:25:23.460
So you have competence,
autonomy, meaning,

00:25:23.460 --> 00:25:26.760
positive emotions,
engagement, and relatedness.

00:25:26.760 --> 00:25:27.350
OK?

00:25:27.350 --> 00:25:30.440
This is a combination from
self-determination theory

00:25:30.440 --> 00:25:31.810
and from PERMA.

00:25:31.810 --> 00:25:36.920
That is one of the most popular
positive psychology theories.

00:25:36.920 --> 00:25:40.840
And these factors have shown
to be effective in promoting

00:25:40.840 --> 00:25:41.340
well-being.

00:25:41.340 --> 00:25:49.080
And there are interventions that
we know work in promoting them.

00:25:49.080 --> 00:25:52.030
I'm not going to go through
the details of each of them,

00:25:52.030 --> 00:25:55.370
but the important thing here
is that software engineers can

00:25:55.370 --> 00:25:59.590
go look at the impact this
has on their trade-off,

00:25:59.590 --> 00:26:01.790
on their designs.

00:26:01.790 --> 00:26:03.280
And the way you
can do that is you

00:26:03.280 --> 00:26:05.880
can use those as
hypotheses, and then you

00:26:05.880 --> 00:26:08.630
can do different designs,
and do AB testing,

00:26:08.630 --> 00:26:14.320
and see which one has a positive
impact on any of those factors.

00:26:14.320 --> 00:26:17.140
So when you introduce a new
product, you see, oh, OK.

00:26:17.140 --> 00:26:19.100
I changed the interface
for Google Drive.

00:26:19.100 --> 00:26:21.660
Is it increasing people's
sense of autonomy?

00:26:21.660 --> 00:26:23.031
Or is it decreasing it?

00:26:23.031 --> 00:26:24.405
Do people feel
that they are more

00:26:24.405 --> 00:26:27.180
in control of the outcomes?

00:26:27.180 --> 00:26:30.670
Or do they feel they are less in
control of the outcomes of what

00:26:30.670 --> 00:26:33.390
is happening?

00:26:33.390 --> 00:26:36.330
And studies have used
different approaches

00:26:36.330 --> 00:26:39.660
to measure the impact of
the designs on well-being.

00:26:39.660 --> 00:26:43.350
On this study, for example,
by people in Facebook

00:26:43.350 --> 00:26:45.630
detecting emotional
contagion, they

00:26:45.630 --> 00:26:49.799
looked into how
emotions propagate

00:26:49.799 --> 00:26:50.840
through a social network.

00:26:50.840 --> 00:26:53.510
And they used a very nifty
statistical technique.

00:26:53.510 --> 00:26:55.650
So it was not an
experimental design.

00:26:55.650 --> 00:26:57.010
They used weather.

00:26:57.010 --> 00:27:00.630
So obviously, our emotions
do not influence weather,

00:27:00.630 --> 00:27:02.970
but we are influenced
by the weather.

00:27:02.970 --> 00:27:03.480
OK?

00:27:03.480 --> 00:27:05.021
So if you have a
friend in Australia,

00:27:05.021 --> 00:27:07.440
and he's enjoying
nice weather, he

00:27:07.440 --> 00:27:14.280
will influence your emotions
through the social network.

00:27:14.280 --> 00:27:17.170
So that's a really
interesting outcome.

00:27:17.170 --> 00:27:21.530
Well, one, we already know
people are happier on weekends,

00:27:21.530 --> 00:27:22.460
on sunny days.

00:27:22.460 --> 00:27:24.470
And they use that fact.

00:27:24.470 --> 00:27:28.900
But also, happiness spreads
more than negative emotions.

00:27:28.900 --> 00:27:30.730
Positive posts
decrease the number

00:27:30.730 --> 00:27:35.690
of negative emotions 1.8,
while negative posts,

00:27:35.690 --> 00:27:37.610
and negative posts by
one of your friends,

00:27:37.610 --> 00:27:40.410
decreases 1.26
the positive ones.

00:27:43.340 --> 00:27:46.450
Another design that
was controversial,

00:27:46.450 --> 00:27:51.020
because used an
experimental approach,

00:27:51.020 --> 00:27:54.730
was this other study by Facebook
that you might have read.

00:27:54.730 --> 00:27:58.040
And it also was looking
into how emotions propagate

00:27:58.040 --> 00:27:59.470
through the social network.

00:27:59.470 --> 00:28:04.640
So in this case, they had a
negativity-reduced design,

00:28:04.640 --> 00:28:07.610
where the filter
in the news feed

00:28:07.610 --> 00:28:12.019
show fewer news stories
from your contacts.

00:28:12.019 --> 00:28:14.060
And another one there was
the positivity reviews.

00:28:14.060 --> 00:28:19.446
So they show fewer positive
posts from your contacts.

00:28:19.446 --> 00:28:20.820
And this, you
might have read it,

00:28:20.820 --> 00:28:26.600
it was a very controversial
study, because is raised issues

00:28:26.600 --> 00:28:29.810
about ethics, if
companies should

00:28:29.810 --> 00:28:34.790
have different obligations,
ethical obligations.

00:28:34.790 --> 00:28:36.930
I personally think
that it raised

00:28:36.930 --> 00:28:40.330
an issue of the
value of autonomy

00:28:40.330 --> 00:28:43.140
in design, because people
felt that they wanted to have

00:28:43.140 --> 00:28:45.840
been able to change the filter.

00:28:48.780 --> 00:28:51.940
And there is also
technical issue is,

00:28:51.940 --> 00:28:56.340
are the things that we say
online a sign of empathy

00:28:56.340 --> 00:28:58.090
or compassionate distress?

00:28:58.090 --> 00:29:00.320
Is it always about
our own emotions?

00:29:00.320 --> 00:29:02.040
So the interpretation
of the data

00:29:02.040 --> 00:29:07.530
also is something
that could be debated.

00:29:07.530 --> 00:29:12.400
So we have been looking at four
different ways of introducing

00:29:12.400 --> 00:29:15.170
positive computing in design.

00:29:15.170 --> 00:29:18.810
The first one is actually
not positive computing.

00:29:18.810 --> 00:29:22.790
That is what we mostly do when
we're developing software.

00:29:22.790 --> 00:29:25.590
So we do not
consider well-being.

00:29:25.590 --> 00:29:28.810
The second one is what I will
call preventative integration.

00:29:28.810 --> 00:29:30.560
So if you have an
application, and there's

00:29:30.560 --> 00:29:33.670
a lot of trolling or
anti-social behavior,

00:29:33.670 --> 00:29:39.070
you do a new design to try to
reduce anti-social behavior.

00:29:39.070 --> 00:29:42.530
So basically, the
obstacles or problems

00:29:42.530 --> 00:29:46.020
are considered like a bug,
and you go and fix them.

00:29:46.020 --> 00:29:48.270
The next one is what I will
call active integration.

00:29:48.270 --> 00:29:50.950
This is where we go and
introduce new features

00:29:50.950 --> 00:29:54.280
that we think would
promote certain factors.

00:29:54.280 --> 00:29:58.230
So we could go and
introduce a new word

00:29:58.230 --> 00:30:02.280
processor that
promotes flow, that

00:30:02.280 --> 00:30:04.760
has fewer distractions around.

00:30:04.760 --> 00:30:08.330
So the person is
just concentrating

00:30:08.330 --> 00:30:09.960
in that particular task.

00:30:09.960 --> 00:30:11.140
Less mind wandering.

00:30:13.980 --> 00:30:17.300
Another one could be a
social media, Google+,

00:30:17.300 --> 00:30:20.530
that promotes
social intelligence,

00:30:20.530 --> 00:30:21.490
emotional intelligence.

00:30:24.070 --> 00:30:25.530
Finally-- and maybe
this is the one

00:30:25.530 --> 00:30:27.820
that has received the most
attention-- is what I will

00:30:27.820 --> 00:30:30.060
call dedicated integration.

00:30:30.060 --> 00:30:34.540
So this is when you build an
app specifically for developing,

00:30:34.540 --> 00:30:36.360
let's say, mindfulness training.

00:30:36.360 --> 00:30:37.550
Goal-setting.

00:30:37.550 --> 00:30:40.410
So the whole app is
just dedicated to that.

00:30:43.020 --> 00:30:45.960
And here, you'll have to
read the whole-- it's mostly

00:30:45.960 --> 00:30:49.240
a summary of the factors that
we have taken into account.

00:30:49.240 --> 00:30:51.220
Each of them has a theory.

00:30:51.220 --> 00:30:53.670
And each of them have
proven strategies

00:30:53.670 --> 00:30:59.350
that have shown to work
in developing that factor.

00:30:59.350 --> 00:31:02.420
And there are methods and
measures that you guys can use.

00:31:02.420 --> 00:31:04.080
These are
questionnaires, surveys,

00:31:04.080 --> 00:31:06.840
that have already been tested
for reliability, et cetera,

00:31:06.840 --> 00:31:07.890
by psychologists.

00:31:07.890 --> 00:31:09.640
And many of them you
can just go and use,

00:31:09.640 --> 00:31:12.030
and see if that one
is having an impact,

00:31:12.030 --> 00:31:15.830
for example, in building
resilience, building motivation

00:31:15.830 --> 00:31:18.020
and engagement, et cetera.

00:31:18.020 --> 00:31:21.390
And then we divided them in
self, social, and transcendent.

00:31:21.390 --> 00:31:24.040
Self are those factors that
have to do just with you,

00:31:24.040 --> 00:31:24.700
are internal.

00:31:24.700 --> 00:31:27.390
Things like mindfulness
in mindfulness week.

00:31:27.390 --> 00:31:31.700
Social are the ones that
depend on more than one person,

00:31:31.700 --> 00:31:33.970
or what relationship
with others.

00:31:33.970 --> 00:31:36.020
And finally,
transcendent is those

00:31:36.020 --> 00:31:39.010
that depend on where we
care about other people

00:31:39.010 --> 00:31:41.230
with whom, maybe, we
don't have a relationship.

00:31:41.230 --> 00:31:44.520
Things like compassion
and altruism.

00:31:44.520 --> 00:31:46.450
There are strategies
for each of them

00:31:46.450 --> 00:31:49.010
that we can use and have
been proven by psychologists.

00:31:49.010 --> 00:31:51.200
And we should be
introducing more of those

00:31:51.200 --> 00:31:53.460
into our applications.

00:31:53.460 --> 00:31:56.190
So again, we have
gone and asked others,

00:31:56.190 --> 00:31:58.330
because this is such an
interdisciplinary work,

00:31:58.330 --> 00:32:02.006
we have asked experts
in other disciplines

00:32:02.006 --> 00:32:06.860
to provide and contribute their
personal, professional opinions

00:32:06.860 --> 00:32:10.120
on how we can
support well-being.

00:32:10.120 --> 00:32:12.750
And these are some of them.

00:32:12.750 --> 00:32:15.950
And some of them are
collaborating with us

00:32:15.950 --> 00:32:17.310
in a number of projects.

00:32:17.310 --> 00:32:19.980
In this one is with the
Young and Well Comparative

00:32:19.980 --> 00:32:24.000
Research Center in
Australia and retail.com.

00:32:24.000 --> 00:32:28.840
That is mental health
organization for young people.

00:32:28.840 --> 00:32:32.430
And what we're doing here
is helping moderators

00:32:32.430 --> 00:32:39.300
in these social networks who
have to go, read posts, read

00:32:39.300 --> 00:32:42.380
them by other people, detect
people that might be at risk,

00:32:42.380 --> 00:32:44.070
and answered questions.

00:32:44.070 --> 00:32:48.030
So these are things,
issues on relationships,

00:32:48.030 --> 00:32:50.950
coming out, sexuality.

00:32:50.950 --> 00:32:54.320
These are young people
that are seeking help.

00:32:54.320 --> 00:32:56.920
And what we're trying
to help the moderators

00:32:56.920 --> 00:33:03.170
be able to reach out to more
people, be more efficient,

00:33:03.170 --> 00:33:08.870
but also enjoy and find
more meaning in their work.

00:33:08.870 --> 00:33:11.370
In this work, we obviously
collaborate a lot

00:33:11.370 --> 00:33:13.070
with psychologists,
psychiatrists,

00:33:13.070 --> 00:33:14.840
from Brain and Mind
Research Institute,

00:33:14.840 --> 00:33:18.220
and from these
other institutions.

00:33:18.220 --> 00:33:22.750
So what we do here is
we automatically you

00:33:22.750 --> 00:33:26.330
and grab the data from
their social media platform.

00:33:26.330 --> 00:33:28.440
We process it
automatically using

00:33:28.440 --> 00:33:30.200
machine learning algorithms.

00:33:30.200 --> 00:33:33.350
And we can classify
what the post is about.

00:33:33.350 --> 00:33:34.470
Is a person depressed?

00:33:34.470 --> 00:33:35.510
Is a person anxious?

00:33:35.510 --> 00:33:37.060
Is he seeking help?

00:33:37.060 --> 00:33:41.590
And then we can automatically
generate some interventions

00:33:41.590 --> 00:33:43.940
that are psychologically
informed.

00:33:43.940 --> 00:33:46.479
So it could be a cognitive
behavioral therapy type

00:33:46.479 --> 00:33:47.020
intervention.

00:33:47.020 --> 00:33:50.940
It could be a psychoeducation
type intervention.

00:33:50.940 --> 00:33:53.450
And the moderator
goes, sees the template

00:33:53.450 --> 00:33:55.440
that we have generated
that is personalized

00:33:55.440 --> 00:33:58.760
with information about
the particular individual.

00:33:58.760 --> 00:34:00.300
And they can customize it.

00:34:00.300 --> 00:34:02.546
So a lot of these
moderators are people

00:34:02.546 --> 00:34:03.920
that have lived
experiences, that

00:34:03.920 --> 00:34:09.090
have themselves suffer from
depression, anxiety, et cetera.

00:34:09.090 --> 00:34:11.880
And then, so they can contribute
that to the other person.

00:34:11.880 --> 00:34:14.360
There's a lot of human contact.

00:34:14.360 --> 00:34:15.949
And then the
moderator changes it,

00:34:15.949 --> 00:34:19.210
and it can go back to the users.

00:34:19.210 --> 00:34:24.840
So, well, this is
moderator assistant.

00:34:24.840 --> 00:34:27.790
And again, what we're trying
to do is use one factor here.

00:34:27.790 --> 00:34:28.820
That is compassion.

00:34:28.820 --> 00:34:33.030
It's trying to help the
moderators help other people.

00:34:33.030 --> 00:34:35.210
In another two
projects, we're working

00:34:35.210 --> 00:34:39.530
with young people in one
that have cystic fibrosis

00:34:39.530 --> 00:34:43.570
or diabetes Type 1, in the
other one that have asthma.

00:34:43.570 --> 00:34:45.550
And what the two
projects have in common

00:34:45.550 --> 00:34:48.110
is that we're trying to
find ways in which we

00:34:48.110 --> 00:34:50.639
can promote autonomy.

00:34:50.639 --> 00:34:54.100
Doctors, medical professionals,
call this self-management

00:34:54.100 --> 00:34:55.130
of the disease.

00:34:55.130 --> 00:34:57.970
So they're looking for
new ways in which patients

00:34:57.970 --> 00:35:02.650
can go out, and do what is
needed to do without having

00:35:02.650 --> 00:35:06.830
to remind them all the
time, and controlling them,

00:35:06.830 --> 00:35:09.280
so it's self-management
of the disease.

00:35:09.280 --> 00:35:13.150
So we're looking for
new ways of doing

00:35:13.150 --> 00:35:15.165
that using mobile phone
and other technologies.

00:35:17.710 --> 00:35:21.360
Another project we are studying
now, it's in the workplace,

00:35:21.360 --> 00:35:25.810
particularly in
male-dominated industries.

00:35:25.810 --> 00:35:29.990
Males have a particular
mental health risk profile,

00:35:29.990 --> 00:35:34.620
often because we don't go and
seek help when we need it.

00:35:34.620 --> 00:35:37.700
We are working with the
police department, the fire

00:35:37.700 --> 00:35:40.190
department, and
ambulance services

00:35:40.190 --> 00:35:43.260
in New South Wales
in Australia, looking

00:35:43.260 --> 00:35:46.490
at how we can detect
people at risk,

00:35:46.490 --> 00:35:49.270
and then provide
them with services

00:35:49.270 --> 00:35:50.710
help that they might need.

00:35:53.520 --> 00:35:56.000
Another project that
we have been working on

00:35:56.000 --> 00:35:58.890
is a new fellowship
that is basically

00:35:58.890 --> 00:36:02.020
coming and talking with
organizations here like Google,

00:36:02.020 --> 00:36:07.890
trying to collaborate, find
ways in which we can inform

00:36:07.890 --> 00:36:11.930
engineers, developers, in the
different industries on how

00:36:11.930 --> 00:36:14.980
to develop software
that takes into account

00:36:14.980 --> 00:36:18.310
psychological well-being,
or takes into account

00:36:18.310 --> 00:36:21.960
all the factors that
we just mentioned.

00:36:21.960 --> 00:36:25.060
And this, obviously,
requires talking

00:36:25.060 --> 00:36:26.780
with people from
multiple disciplines,

00:36:26.780 --> 00:36:29.700
not just engineers or
psychologists in the company,

00:36:29.700 --> 00:36:31.930
but the people in
other organizations

00:36:31.930 --> 00:36:35.680
like mental health
charities, et cetera.

00:36:35.680 --> 00:36:40.480
So just as a summary, we know
that technology is changing us.

00:36:40.480 --> 00:36:45.750
There are psychological factors
we know increase well-being.

00:36:45.750 --> 00:36:49.330
And these factors often,
very often, can be used

00:36:49.330 --> 00:36:53.280
and introduced into the design
of the platforms we build.

00:36:53.280 --> 00:36:55.215
And they would be
promoting well-being.

00:36:55.215 --> 00:36:58.110
And positive computing
provides a framework

00:36:58.110 --> 00:37:01.840
to support well-being
by considering

00:37:01.840 --> 00:37:05.760
this multidisciplinary
work and targeting

00:37:05.760 --> 00:37:10.470
the promotion of flourishing
in the software platforms.

00:37:10.470 --> 00:37:11.295
Thank you.

00:37:11.295 --> 00:37:14.145
[APPLAUSE]

00:37:17.950 --> 00:37:20.960
AUDIENCE: I really
enjoyed the talk.

00:37:20.960 --> 00:37:22.740
I agree with a lot
of what you said.

00:37:22.740 --> 00:37:25.460
But one of things that
I've asked myself a lot

00:37:25.460 --> 00:37:28.470
is let me go back to the
first graph you showed right

00:37:28.470 --> 00:37:34.540
at the beginning about how gross
national product has increased,

00:37:34.540 --> 00:37:39.272
but some measure of
happiness is not.

00:37:39.272 --> 00:37:40.980
Whenever I've looked
at graphs like that,

00:37:40.980 --> 00:37:42.380
I've always had two questions.

00:37:42.380 --> 00:37:47.360
Is the gross national
product, has the GNP accounted

00:37:47.360 --> 00:37:49.890
for inflation?

00:37:49.890 --> 00:37:52.350
And B, are there
actually examples

00:37:52.350 --> 00:37:55.340
of graphs where life
satisfaction has increased,

00:37:55.340 --> 00:37:57.490
and not reverted back
to a mean, right?

00:37:57.490 --> 00:37:59.670
So I was hoping to hear
your thoughts on that.

00:37:59.670 --> 00:38:00.503
RAPHAEL CALVO: Yeah.

00:38:00.503 --> 00:38:01.800
Very good question.

00:38:01.800 --> 00:38:02.300
Yes.

00:38:02.300 --> 00:38:03.730
The first one,
economists are very

00:38:03.730 --> 00:38:07.880
aware of how to take into
account inflation and so on.

00:38:07.880 --> 00:38:12.520
We have become wealthier, a
lot wealthier, some people more

00:38:12.520 --> 00:38:13.560
than others.

00:38:13.560 --> 00:38:17.840
But in general, across
society, societies

00:38:17.840 --> 00:38:20.260
in both poor and
developed countries

00:38:20.260 --> 00:38:24.050
have become much,
much wealthier.

00:38:24.050 --> 00:38:26.200
The second one is
related to something

00:38:26.200 --> 00:38:28.140
called hedonic treadmill.

00:38:28.140 --> 00:38:29.870
Maybe that you have heard?

00:38:29.870 --> 00:38:34.520
And there is some evidence
that after you've enjoyed,

00:38:34.520 --> 00:38:37.480
you buy something that
gives you positive emotions.

00:38:37.480 --> 00:38:40.640
Let's say you buy
a new mobile phone.

00:38:40.640 --> 00:38:41.610
And you enjoy it.

00:38:41.610 --> 00:38:45.810
And after a little while,
the new gadget you bought

00:38:45.810 --> 00:38:47.100
doesn't mean much.

00:38:47.100 --> 00:38:49.880
And your positive
emotions go down.

00:38:49.880 --> 00:38:53.080
And then you seek
the next product.

00:38:53.080 --> 00:38:56.170
Now, that refers to
hedonic well-being.

00:38:56.170 --> 00:38:59.760
That is only the
positive emotions aspect,

00:38:59.760 --> 00:39:04.310
the ephemeral aspect
of well-being.

00:39:04.310 --> 00:39:08.380
And that's why there is
many other factors that

00:39:08.380 --> 00:39:10.710
support well-being, not
just positive emotions.

00:39:10.710 --> 00:39:11.940
Meaning.

00:39:11.940 --> 00:39:15.050
If you find meaning
in what you do,

00:39:15.050 --> 00:39:19.770
that will have a positive
impact across your life.

00:39:19.770 --> 00:39:23.830
It's not going to fade
away after a few days.

00:39:23.830 --> 00:39:29.030
If you involve yourself
in helping others,

00:39:29.030 --> 00:39:31.590
being compassionate
or altruistic,

00:39:31.590 --> 00:39:33.950
or if you work for
a not-for-profit,

00:39:33.950 --> 00:39:36.380
that will have a positive
impact on your life

00:39:36.380 --> 00:39:38.370
beyond one or two days.

00:39:38.370 --> 00:39:44.350
So there are ways of changing
that kind of baseline that

00:39:44.350 --> 00:39:50.250
expands for all your life, for
an extended period of time.

00:39:50.250 --> 00:39:53.040
AUDIENCE: So there are obviously
a lot of subtle software

00:39:53.040 --> 00:39:55.610
and user interface issues here.

00:39:55.610 --> 00:39:59.110
All I'm wondering
if also the way

00:39:59.110 --> 00:40:03.140
we interact with these
devices, we hold them and touch

00:40:03.140 --> 00:40:06.859
them and look at them
then, and we talk to them

00:40:06.859 --> 00:40:08.400
and they talk to
us, and they measure

00:40:08.400 --> 00:40:11.400
our physiological
functions and so forth.

00:40:11.400 --> 00:40:15.220
And from a McLuhaneque
point of view,

00:40:15.220 --> 00:40:18.790
you might think that the actual
physical interactions that we

00:40:18.790 --> 00:40:23.260
have with these devices might
also have a pretty profound,

00:40:23.260 --> 00:40:26.606
regardless of the
details of the interface,

00:40:26.606 --> 00:40:28.480
just the basic interactions
with these things

00:40:28.480 --> 00:40:30.640
might have an impact
on our well-being.

00:40:30.640 --> 00:40:34.390
And I wonder if there's any data
available, even tentatively,

00:40:34.390 --> 00:40:36.060
on that.

00:40:36.060 --> 00:40:40.530
RAPHAEL CALVO: The research, for
example, using seeing internet

00:40:40.530 --> 00:40:47.240
and viewing TV, numbers of
TV hours, is very complex.

00:40:47.240 --> 00:40:51.550
So I've seen papers where it
says that if you have a TV,

00:40:51.550 --> 00:40:54.037
you will increase
your well-being.

00:40:54.037 --> 00:40:55.620
And there are studies
that, obviously,

00:40:55.620 --> 00:40:57.429
show exactly the opposite.

00:40:57.429 --> 00:40:59.720
And then there are studies
that show if you have the TV

00:40:59.720 --> 00:41:04.175
and you have the internet,
your decrease goes down.

00:41:04.175 --> 00:41:05.180
And sometimes no.

00:41:05.180 --> 00:41:09.746
If you have the two
together, it goes up.

00:41:09.746 --> 00:41:13.530
I think we still have to
work on the methodologies

00:41:13.530 --> 00:41:14.239
to measure that.

00:41:14.239 --> 00:41:16.030
Some of those studies
are a little bit off.

00:41:16.030 --> 00:41:20.110
The approaches that you have
for tracking and understanding

00:41:20.110 --> 00:41:25.930
what people is doing with
those devices has changed.

00:41:25.930 --> 00:41:28.240
So I don't have a simple answer.

00:41:28.240 --> 00:41:30.470
I think there is studies.

00:41:30.470 --> 00:41:36.820
In general, they are
very subtle differences

00:41:36.820 --> 00:41:39.619
that can have an impact, no?

00:41:39.619 --> 00:41:41.910
And you really have to go
into the details of the study

00:41:41.910 --> 00:41:46.090
to see what is happening.

00:41:46.090 --> 00:41:48.910
I think with the new
techniques that we

00:41:48.910 --> 00:41:51.120
have to track people's
views of these devices,

00:41:51.120 --> 00:41:54.640
then we will have a
better way of doing,

00:41:54.640 --> 00:41:56.990
of understanding
what's happening.

00:41:56.990 --> 00:41:59.800
AUDIENCE: So for many years
we brought people into labs.

00:41:59.800 --> 00:42:01.260
We've stuck stuff to them.

00:42:01.260 --> 00:42:03.490
We've pointed cameras
at them and et cetera

00:42:03.490 --> 00:42:06.010
to sort of understand
these things, when we ever

00:42:06.010 --> 00:42:09.880
bothered to look, which
wasn't very often.

00:42:09.880 --> 00:42:14.280
Now that these things mobile,
people are all over the planet.

00:42:14.280 --> 00:42:16.260
You can't bring
them in to study.

00:42:16.260 --> 00:42:20.180
They're using devices like
the Fitbits and other things,

00:42:20.180 --> 00:42:21.530
and all kinds of stuff.

00:42:21.530 --> 00:42:28.160
And I'm wondering, what
are emerging technologies

00:42:28.160 --> 00:42:31.740
and approaches to handling this
multi-device world in which we

00:42:31.740 --> 00:42:35.220
are trying to understand the
technology impact on wellness

00:42:35.220 --> 00:42:36.450
and happiness?

00:42:36.450 --> 00:42:39.320
RAPHAEL CALVO: I think
that when we are developing

00:42:39.320 --> 00:42:43.120
these new gadgets
like the Fitbit,

00:42:43.120 --> 00:42:45.950
the different technology
for activity tracking,

00:42:45.950 --> 00:42:50.435
they can have a very positive
impact on improving health,

00:42:50.435 --> 00:42:53.450
and, possibly, well-being.

00:42:53.450 --> 00:42:56.680
On the other hand,
you have to take

00:42:56.680 --> 00:42:59.680
into account psychological
well-being that sometimes

00:42:59.680 --> 00:43:03.410
is different to
the physical one,

00:43:03.410 --> 00:43:08.510
and see if it's not
creating or triggering

00:43:08.510 --> 00:43:10.880
different consequences
on different people.

00:43:10.880 --> 00:43:13.280
So if you're
obsessive compulsive,

00:43:13.280 --> 00:43:16.200
you might be more inclined
to use a particular tool that

00:43:16.200 --> 00:43:18.950
tracks everything, et cetera.

00:43:18.950 --> 00:43:21.610
The tool is not necessarily
helping you come out

00:43:21.610 --> 00:43:25.410
of this pattern
that you have that

00:43:25.410 --> 00:43:29.410
is likely to be affecting
your well-being.

00:43:29.410 --> 00:43:32.300
So sometimes we do
studies where we

00:43:32.300 --> 00:43:36.410
assume the whole population
will received these new tools

00:43:36.410 --> 00:43:37.640
in the same way.

00:43:37.640 --> 00:43:39.320
But that you have
people that have

00:43:39.320 --> 00:43:41.530
the different
personal attributes,

00:43:41.530 --> 00:43:43.280
and will react to them
in different ways.

00:43:43.280 --> 00:43:46.280
And I think the devices
that you're thinking about,

00:43:46.280 --> 00:43:48.450
like the Fitbit, et
cetera, sometimes

00:43:48.450 --> 00:43:51.820
we look for general solutions,
design approaches that

00:43:51.820 --> 00:43:53.010
will apply to everybody.

00:43:53.010 --> 00:43:55.250
And different people will
have different impact.

00:43:55.250 --> 00:44:01.360
If you have an eating
disorder, if you're

00:44:01.360 --> 00:44:07.180
focusing on weight too much,
the impact can be negative.

00:44:07.180 --> 00:44:09.930
Maybe for the
majority, the average

00:44:09.930 --> 00:44:11.430
maybe is moving positive.

00:44:11.430 --> 00:44:14.820
But then maybe you might
be affecting people who

00:44:14.820 --> 00:44:18.070
need it most in a negative way.

00:44:18.070 --> 00:44:21.490
So what I'm going
to there is that we

00:44:21.490 --> 00:44:23.620
need to look at the
different groups of people

00:44:23.620 --> 00:44:24.286
personalisation.

00:44:24.286 --> 00:44:26.180
And when you design,
consider ways

00:44:26.180 --> 00:44:28.240
of not designing
in a general way,

00:44:28.240 --> 00:44:30.930
but also taking into
account minorities--

00:44:30.930 --> 00:44:36.320
for example, people that might
be at risk of mental health

00:44:36.320 --> 00:44:43.930
problems, or might be at risk
of physical problems, et cetera.

00:44:43.930 --> 00:44:45.470
That was an issue,
for example, that

00:44:45.470 --> 00:44:48.200
arose in that controversial
study by Facebook.

00:44:48.200 --> 00:44:52.700
People argue, well, a number of
people that have mental health

00:44:52.700 --> 00:44:56.390
problems, so if you are
driving and pushing them

00:44:56.390 --> 00:44:59.256
towards more negative
emotions, that can

00:44:59.256 --> 00:45:03.110
have very serious consequences.

00:45:03.110 --> 00:45:06.090
AUDIENCE: I can see thinking of
an organization like Facebook

00:45:06.090 --> 00:45:09.470
or Google, or a company
that's not Fitbit,

00:45:09.470 --> 00:45:11.680
not directly trying to
create software that's

00:45:11.680 --> 00:45:14.360
going to increase an
aspect of well-being,

00:45:14.360 --> 00:45:17.260
I can see a strong
incentive for-- I

00:45:17.260 --> 00:45:20.570
forget your exact term--
reactive design for well-being.

00:45:20.570 --> 00:45:23.340
You don't want trolls on
your service, for instance.

00:45:23.340 --> 00:45:26.110
What are the incentives,
do they exist right now,

00:45:26.110 --> 00:45:28.780
for companies to take an
active interest in increasing

00:45:28.780 --> 00:45:31.030
well-being, even if that's
not the main purpose

00:45:31.030 --> 00:45:31.927
of their product?

00:45:31.927 --> 00:45:32.760
RAPHAEL CALVO: Yeah.

00:45:32.760 --> 00:45:34.950
That's a fantastic question.

00:45:34.950 --> 00:45:37.910
I think yes.

00:45:37.910 --> 00:45:40.780
Europe and Australia,
in many countries,

00:45:40.780 --> 00:45:43.160
just to give you an
example, organizations

00:45:43.160 --> 00:45:48.490
are liable for mental
disabilities caused by stress,

00:45:48.490 --> 00:45:51.200
for example.

00:45:51.200 --> 00:45:54.820
And they have initiated a
number of well-being programs.

00:45:54.820 --> 00:45:56.990
So there's hundreds
of companies that

00:45:56.990 --> 00:46:00.510
are looking at providing
servicing the industry that

00:46:00.510 --> 00:46:04.930
helps those organizations reduce
the likelihood of having people

00:46:04.930 --> 00:46:07.140
burn out, et cetera.

00:46:07.140 --> 00:46:09.620
Now, you guys view the
software that those companies

00:46:09.620 --> 00:46:14.049
are building to serve
the employees, right?

00:46:14.049 --> 00:46:15.590
So if you can build
software that you

00:46:15.590 --> 00:46:19.680
show reduces the
likelihood of burnout,

00:46:19.680 --> 00:46:21.640
if you design a new
type of email system

00:46:21.640 --> 00:46:29.010
that reduces the likelihood
of people working late hours,

00:46:29.010 --> 00:46:34.840
that has a strong impact
on mental illness,

00:46:34.840 --> 00:46:37.180
that's a fantastic sales point.

00:46:37.180 --> 00:46:40.320
I think I will
love, and I would be

00:46:40.320 --> 00:46:42.820
willing to pay extra,
if I have software

00:46:42.820 --> 00:46:47.660
that I knew will
help my kids grow up

00:46:47.660 --> 00:46:52.860
as stronger individuals, more
compassionate individuals.

00:46:52.860 --> 00:46:54.930
A software or
platform that allow

00:46:54.930 --> 00:46:57.590
them to have more
emotional intelligence.

00:46:57.590 --> 00:47:03.590
And if they are relating to
other through social media,

00:47:03.590 --> 00:47:06.200
if they use Google+,
if they use Facebook,

00:47:06.200 --> 00:47:08.860
if they use any of those
products to connect,

00:47:08.860 --> 00:47:10.800
and learn about other
people's emotions,

00:47:10.800 --> 00:47:13.200
about interacting
with other people,

00:47:13.200 --> 00:47:17.800
those platforms need to include
the things that psychologists

00:47:17.800 --> 00:47:21.410
know promote prosocial
behaviors, promoting empathy,

00:47:21.410 --> 00:47:22.295
promote compassion.

00:47:25.160 --> 00:47:29.720
As a consumer, I will look
for that type of product.

00:47:29.720 --> 00:47:33.110
As a person that works
in a large organization,

00:47:33.110 --> 00:47:36.970
I know my organization will
like to know of products

00:47:36.970 --> 00:47:37.840
that can offer that.

00:47:37.840 --> 00:47:39.965
And there is already
companies that are doing that.

00:47:39.965 --> 00:47:41.860
Yammer, for example,
has a number

00:47:41.860 --> 00:47:45.930
of companies that are
providing services

00:47:45.930 --> 00:47:47.530
that allow organizations
to understand

00:47:47.530 --> 00:47:49.550
what is happening internally.

00:47:49.550 --> 00:47:52.010
Like when a manager
changes a policy,

00:47:52.010 --> 00:47:54.280
you can see, well, this
is what has happened.

00:47:54.280 --> 00:47:56.590
Emotional state of the
organization changed.

00:47:56.590 --> 00:47:59.760
Or it has activities
for people to engage

00:47:59.760 --> 00:48:05.050
improving the connection
between the employees.

00:48:05.050 --> 00:48:07.090
KYLE: Well, let's thank
Professor Calvo again.

00:48:07.090 --> 00:48:07.690
Thanks.

00:48:07.690 --> 00:48:10.440
[APPLAUSE]

