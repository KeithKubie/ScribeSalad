WEBVTT
Kind: captions
Language: en

00:00:00.027 --> 00:00:01.860
JARED COHEN: I'm really
delighted to be here

00:00:01.860 --> 00:00:06.170
with a colleague and dear friend
of mine, Alec Ross, author

00:00:06.170 --> 00:00:10.240
of the New York Times bestseller
"Industries of the Future."

00:00:10.240 --> 00:00:12.000
I would say you should
go out and buy it,

00:00:12.000 --> 00:00:15.160
which you should, but all of you
have free copies, which means,

00:00:15.160 --> 00:00:18.780
go out and buy copies for
all your friends and family.

00:00:18.780 --> 00:00:20.770
It's really an
extraordinary book.

00:00:20.770 --> 00:00:23.300
It covers everything
from robotics

00:00:23.300 --> 00:00:29.160
to genomics, to geopolitics,
to how to be a good parent.

00:00:29.160 --> 00:00:31.900
And Alec has really
done incredible job

00:00:31.900 --> 00:00:34.690
traversing the globe,
trying to understand

00:00:34.690 --> 00:00:36.790
what the next wave of
globalization looks

00:00:36.790 --> 00:00:41.510
like, really across a
diverse array of sectors.

00:00:41.510 --> 00:00:44.234
Before we get into
this, I wanted

00:00:44.234 --> 00:00:46.150
to share a little bit
about Alec's background,

00:00:46.150 --> 00:00:49.550
because we've known each
other for quite some time.

00:00:49.550 --> 00:00:51.700
We've gotten into some
mischief together.

00:00:51.700 --> 00:00:53.700
We've been in and our of
trouble over the course

00:00:53.700 --> 00:00:55.850
of the last decade.

00:00:55.850 --> 00:00:58.830
We had a chance to work together
for Secretary of State Hillary

00:00:58.830 --> 00:01:01.460
Clinton, possibly
soon to be President

00:01:01.460 --> 00:01:03.530
Clinton, the second one.

00:01:03.530 --> 00:01:06.920
And Alec was Hillary's
first ever senior advisor

00:01:06.920 --> 00:01:08.160
for innovation.

00:01:08.160 --> 00:01:10.940
And it was a position
that she created for him.

00:01:10.940 --> 00:01:14.740
And what was more amazing
about it is Alec had run a tech

00:01:14.740 --> 00:01:17.840
policy and innovation for
the Obama '08 campaign,

00:01:17.840 --> 00:01:21.220
and was the sole Obama
person who managed to land

00:01:21.220 --> 00:01:22.240
in the State Department.

00:01:22.240 --> 00:01:24.860
I think we all
remember that tension

00:01:24.860 --> 00:01:28.030
that existed between the Hillary
Clinton camp and the Obama

00:01:28.030 --> 00:01:28.530
camp.

00:01:28.530 --> 00:01:32.270
And he made innovation a part
of American foreign policy

00:01:32.270 --> 00:01:34.696
in a way that really
didn't exist before.

00:01:34.696 --> 00:01:36.820
So I want to start by
thanking you for your service

00:01:36.820 --> 00:01:41.200
to the country, but also thank
you for joining us today.

00:01:41.200 --> 00:01:44.980
This book is as much about
the industries of the future

00:01:44.980 --> 00:01:48.390
as it is an individual
sitting next to me

00:01:48.390 --> 00:01:50.700
who has spent his
entire life trying

00:01:50.700 --> 00:01:53.969
to answer a fundamental question
about what's happening next.

00:01:53.969 --> 00:01:55.760
And I want to start
with the first sentence

00:01:55.760 --> 00:01:58.350
of the book, which
is, "it's 3:00 AM,

00:01:58.350 --> 00:02:00.670
and I'm mopping up
whiskey smelling puke

00:02:00.670 --> 00:02:04.470
after a country music concert
in Charleston, West Virginia."

00:02:04.470 --> 00:02:06.730
And this is a book about
industries of the future,

00:02:06.730 --> 00:02:09.880
so take us from mopping
up puke in West Virginia

00:02:09.880 --> 00:02:12.530
to the person who
ended up writing

00:02:12.530 --> 00:02:15.527
a book about what the next wave
of globalization looks like.

00:02:15.527 --> 00:02:17.860
ALEC ROSS: Well, thank you,
Jared for that introduction,

00:02:17.860 --> 00:02:21.710
and thank you all for
coming out this afternoon.

00:02:21.710 --> 00:02:23.641
So it's 3 o'clock
in the morning.

00:02:23.641 --> 00:02:25.140
I'm mopping up
whiskey smelling puke

00:02:25.140 --> 00:02:27.610
after a country music concert
in Charleston, West Virginia.

00:02:27.610 --> 00:02:30.870
Why was I doing that?

00:02:30.870 --> 00:02:35.735
Well, when I was in college,
having grown up a public school

00:02:35.735 --> 00:02:39.260
kid in West Virginia,
while most of my classmates

00:02:39.260 --> 00:02:42.070
at my fancy college were
off doing unpaid internships

00:02:42.070 --> 00:02:44.840
at investment banks, or law
firms, or tech companies,

00:02:44.840 --> 00:02:47.450
or their parents had gotten
them apartments in Washington

00:02:47.450 --> 00:02:49.840
DC so they could be
interns in Congress,

00:02:49.840 --> 00:02:52.960
I had to actually make
money when I was in college.

00:02:52.960 --> 00:02:55.440
And so what that meant
for me going home

00:02:55.440 --> 00:02:59.240
was the jobs that I had
were working on a beer truck

00:02:59.240 --> 00:03:01.810
and working as a
midnight janitor.

00:03:01.810 --> 00:03:04.120
And so growing up
in West Virginia,

00:03:04.120 --> 00:03:09.492
I thought that my reality was
like everybody's reality, which

00:03:09.492 --> 00:03:11.700
is, from an economic
standpoint, what you're actually

00:03:11.700 --> 00:03:16.080
trying to do is just manage
decline as best you can.

00:03:16.080 --> 00:03:20.040
And so it wasn't until
I left West Virginia

00:03:20.040 --> 00:03:21.940
and I entered the
work world, and I

00:03:21.940 --> 00:03:24.910
was very blessed and privileged
to get to spend a couple

00:03:24.910 --> 00:03:30.120
decades as an entrepreneur,
in politics, in government,

00:03:30.120 --> 00:03:34.440
as an author, till I fully
understood that globalization

00:03:34.440 --> 00:03:37.990
was not about managing
dissent, that, point

00:03:37.990 --> 00:03:41.790
in fact, globalization was
overwhelmingly positive.

00:03:41.790 --> 00:03:44.210
But in the community
that I grew up in,

00:03:44.210 --> 00:03:46.020
it was not entirely positive.

00:03:46.020 --> 00:03:48.660
And so was the process
of writing the book,

00:03:48.660 --> 00:03:51.880
the reason why I open
up with that story

00:03:51.880 --> 00:03:58.380
is I try to give a balanced
perspective on a view

00:03:58.380 --> 00:03:59.210
into the future.

00:03:59.210 --> 00:04:01.860
Most people who write
books about the future

00:04:01.860 --> 00:04:05.450
write either utopian
books or dystopian books.

00:04:05.450 --> 00:04:07.150
It's either, we're
going to live to be

00:04:07.150 --> 00:04:09.880
150 years old, happy,
healthy, wealthy,

00:04:09.880 --> 00:04:13.270
wanting for nothing,
nothing but abundance.

00:04:13.270 --> 00:04:16.420
Or it's written from the
fetal position, sort of eyes

00:04:16.420 --> 00:04:22.570
closed, fists clenched, usually
shaking a fist at you guys.

00:04:22.570 --> 00:04:25.660
But I think the reality is
much more up the middle,

00:04:25.660 --> 00:04:27.930
and net optimistic.

00:04:27.930 --> 00:04:31.000
I think that tomorrow
will be better than today.

00:04:31.000 --> 00:04:33.640
But in examining the
industries of the future,

00:04:33.640 --> 00:04:36.220
it was important for
me from the very outset

00:04:36.220 --> 00:04:41.200
to do some framing just so
that it would be understood

00:04:41.200 --> 00:04:44.390
that it was viewed through the
eyes of a public school kid

00:04:44.390 --> 00:04:46.850
from West Virginia,
who put himself

00:04:46.850 --> 00:04:49.610
through college by working
as a midnight janitor,

00:04:49.610 --> 00:04:54.815
as opposed to from a position
of lifelong privilege.

00:04:54.815 --> 00:04:56.190
JARED COHEN: So
I want to ask you

00:04:56.190 --> 00:04:58.680
one question about your time
at the State Department.

00:04:58.680 --> 00:05:00.054
Before I do that,
Sam's giving me

00:05:00.054 --> 00:05:02.750
a look, because I realize I
forgot to introduce myself.

00:05:02.750 --> 00:05:05.460
Jared Cohen, president
of Jigsaw alphabet,

00:05:05.460 --> 00:05:07.739
and advisor to Eric
Schmidt as well.

00:05:07.739 --> 00:05:09.530
ALEC ROSS: I bet they
all know who you are.

00:05:09.530 --> 00:05:12.055
I'm happy to speak at great
length about who you are.

00:05:12.055 --> 00:05:12.888
JARED COHEN: No, no.

00:05:12.888 --> 00:05:14.460
Let's go back to you.

00:05:14.460 --> 00:05:16.660
So you went to the
State Department.

00:05:16.660 --> 00:05:18.170
You had never met
Hillary Clinton

00:05:18.170 --> 00:05:19.730
before you started
working for her.

00:05:19.730 --> 00:05:20.870
Is that correct?

00:05:20.870 --> 00:05:22.710
ALEC ROSS: I had
actually met her before.

00:05:22.710 --> 00:05:24.720
JARED COHEN: What
was the context.

00:05:24.720 --> 00:05:26.770
ALEC ROSS: The context
was my social enterprise

00:05:26.770 --> 00:05:28.853
had done some work in
partnership with her office,

00:05:28.853 --> 00:05:29.805
but we were not close.

00:05:29.805 --> 00:05:30.730
JARED COHEN: And
she's a politician.

00:05:30.730 --> 00:05:32.025
They don't remember anything.

00:05:32.025 --> 00:05:33.775
ALEC ROSS: Yeah, she
shakes lots of hands.

00:05:33.775 --> 00:05:35.691
JARED COHEN: So what is
the first conversation

00:05:35.691 --> 00:05:37.380
about innovation
with her look like?

00:05:37.380 --> 00:05:39.690
She's just lost an election.

00:05:39.690 --> 00:05:42.730
It looked like she was
heading to retirement.

00:05:42.730 --> 00:05:45.840
She gets resurrected
as Secretary of State,

00:05:45.840 --> 00:05:47.770
and then you appear.

00:05:47.770 --> 00:05:49.779
And you have a conversation
about innovation.

00:05:49.779 --> 00:05:50.820
What does that look like?

00:05:50.820 --> 00:05:52.945
ALEC ROSS: It was a fairly
remarkable conversation.

00:05:52.945 --> 00:05:55.110
I mean, I was on the
presidential transition team,

00:05:55.110 --> 00:05:57.455
and I was busy trying to
figure out which fancy job I

00:05:57.455 --> 00:05:58.230
was going to take.

00:05:58.230 --> 00:06:00.063
You know, the White
House, or Chief of Staff

00:06:00.063 --> 00:06:01.780
of this, or doing that.

00:06:01.780 --> 00:06:04.240
And I was summoned to
see Hillary Clinton.

00:06:04.240 --> 00:06:06.250
And I was like, why
does she want to see me?

00:06:06.250 --> 00:06:08.550
Does she want to yell at me?

00:06:08.550 --> 00:06:11.450
Because I had run technology and
media policy for the campaign

00:06:11.450 --> 00:06:12.820
to beat her.

00:06:12.820 --> 00:06:15.600
And she sat me down,
and she said, Alec,

00:06:15.600 --> 00:06:17.770
I thought I was going
to be president.

00:06:17.770 --> 00:06:21.910
And she said, and I have lots
of very capable people, who

00:06:21.910 --> 00:06:23.660
I know and like, who
were going to fill up

00:06:23.660 --> 00:06:26.240
the executive ranks of the
politically appointed offices

00:06:26.240 --> 00:06:27.862
across the federal government.

00:06:27.862 --> 00:06:30.320
She's like, now I need to fit
them all into one department,

00:06:30.320 --> 00:06:31.760
into the State Department.

00:06:31.760 --> 00:06:34.030
She goes, but I need
to make one exception.

00:06:34.030 --> 00:06:38.260
She goes, I need one
of you internet people.

00:06:38.260 --> 00:06:41.190
One of you innovation people.

00:06:41.190 --> 00:06:44.460
She said, I think the promise
and peril of the 21st century

00:06:44.460 --> 00:06:49.960
is no longer contained by vast
distances or national borders.

00:06:49.960 --> 00:06:52.560
And I think the internet is
going to be a big part of that.

00:06:52.560 --> 00:06:54.476
Now, I should say at
this point that I did not

00:06:54.476 --> 00:06:55.360
set up her emails.

00:06:55.360 --> 00:06:56.350
so--

00:06:56.350 --> 00:06:57.630
[LAUGHTER]

00:06:57.630 --> 00:06:58.130
I did not.

00:06:58.130 --> 00:06:59.535
So for those of
you in this room,

00:06:59.535 --> 00:07:01.410
I would think that most
of you could probably

00:07:01.410 --> 00:07:04.820
set up homebrewed servers in
basements, but for those few

00:07:04.820 --> 00:07:07.560
of you who work at Google
who can't, if you are here

00:07:07.560 --> 00:07:10.185
at this session to learn
how to do that, this

00:07:10.185 --> 00:07:11.060
is the wrong session.

00:07:11.060 --> 00:07:13.060
That was another guy.

00:07:13.060 --> 00:07:14.520
JARED COHEN: Who
just got immunity.

00:07:14.520 --> 00:07:15.770
ALEC ROSS: He did
just get immunity.

00:07:15.770 --> 00:07:17.270
He actually applied
to me for a job,

00:07:17.270 --> 00:07:18.560
and actually didn't get a job.

00:07:18.560 --> 00:07:21.870
But we'll leave that aside.

00:07:21.870 --> 00:07:25.190
The point being is that
she recognized early.

00:07:25.190 --> 00:07:28.810
She saw in her own
campaign how the internet

00:07:28.810 --> 00:07:33.030
was something that
significantly impacted

00:07:33.030 --> 00:07:34.330
her campaign for the worse.

00:07:34.330 --> 00:07:38.340
She ran a good 20th
century campaign.

00:07:38.340 --> 00:07:41.650
Senator Obama ran a good
21st century campaign.

00:07:41.650 --> 00:07:45.100
And so her theory becoming
Secretary of State

00:07:45.100 --> 00:07:49.950
was that information
networks would impact

00:07:49.950 --> 00:07:52.670
the conduct of diplomacy.

00:07:52.670 --> 00:07:56.010
And it proved to be right,
for better, for worse,

00:07:56.010 --> 00:07:59.860
from WikiLeaks on, what
was thought, at the time,

00:07:59.860 --> 00:08:02.170
to be the negative
side, to programs we

00:08:02.170 --> 00:08:03.460
built on the positive science.

00:08:03.460 --> 00:08:08.442
So basically, her theory,
which Jared and I and a woman

00:08:08.442 --> 00:08:10.150
named Anne Marie
Slaughter then built out

00:08:10.150 --> 00:08:13.020
some intellectual
architecture below,

00:08:13.020 --> 00:08:15.960
was that the
internet would change

00:08:15.960 --> 00:08:20.530
the traditional
relationships in diplomacy

00:08:20.530 --> 00:08:24.834
beyond the formal architecture
of 196 sovereign nation states.

00:08:24.834 --> 00:08:26.250
JARED COHEN: And
it's worth adding

00:08:26.250 --> 00:08:31.446
that if we actually reflect
back, this was not so obvious

00:08:31.446 --> 00:08:31.946
back then.

00:08:31.946 --> 00:08:35.020
To all of you, it would have
been obvious, but to the stodgy

00:08:35.020 --> 00:08:38.380
halls of government, back
then, you more of less

00:08:38.380 --> 00:08:41.450
got laughed out of the room
for talking about the internet

00:08:41.450 --> 00:08:43.360
or technology in
any public sector

00:08:43.360 --> 00:08:46.190
context that wasn't the FCC.

00:08:46.190 --> 00:08:48.730
Let's turn to your book.

00:08:48.730 --> 00:08:51.280
One of the things that's
interesting about your book

00:08:51.280 --> 00:08:57.120
is you move beyond the jargon
of today, where people talk

00:08:57.120 --> 00:09:01.620
so much about AI, and
disruption, and innovation,

00:09:01.620 --> 00:09:04.530
and machine learning, that
these words and terms,

00:09:04.530 --> 00:09:06.830
they're used and overused,
in context, out of context--

00:09:06.830 --> 00:09:08.824
ALEC ROSS: I don't know
what they mean anymore.

00:09:08.824 --> 00:09:10.990
JARED COHEN: Essentially
they've lost their meaning.

00:09:10.990 --> 00:09:13.810
You argue in the book
that globalization

00:09:13.810 --> 00:09:15.120
is an ongoing process.

00:09:15.120 --> 00:09:16.420
It never finishes.

00:09:16.420 --> 00:09:19.220
And you spend a lot
of time focusing less

00:09:19.220 --> 00:09:22.100
on the jargon of today, and
where this is all going.

00:09:22.100 --> 00:09:25.400
What is the next wave of
globalization that excites you?

00:09:25.400 --> 00:09:27.812
And where are we
today in the process?

00:09:27.812 --> 00:09:29.520
ALEC ROSS: The next
wave of globalization

00:09:29.520 --> 00:09:33.800
that most excites
me is-- I think

00:09:33.800 --> 00:09:38.010
that a substantial number
of today's frontier markets

00:09:38.010 --> 00:09:39.540
will become
tomorrow's developing

00:09:39.540 --> 00:09:42.050
markets, and a substantial
number of today's developing

00:09:42.050 --> 00:09:44.350
markets will be tomorrow's
developed markets.

00:09:44.350 --> 00:09:47.590
So the real story, if
you just do the math,

00:09:47.590 --> 00:09:50.790
the great story of globalization
in the last 25 years

00:09:50.790 --> 00:09:52.890
is the story of India and China.

00:09:52.890 --> 00:09:56.920
Nearly a billion, billion with
a B, nearly a billion people

00:09:56.920 --> 00:10:01.030
migrated out of poverty into
the working and middle classes

00:10:01.030 --> 00:10:02.240
from China and India.

00:10:02.240 --> 00:10:04.350
And so I think
that that is really

00:10:04.350 --> 00:10:06.764
the big story of the last
stage of globalization.

00:10:06.764 --> 00:10:08.930
But I think what will be
the story of the next stage

00:10:08.930 --> 00:10:14.260
of globalization are markets
that we think of as largely

00:10:14.260 --> 00:10:16.700
inaccessible, suddenly
becoming accessible.

00:10:16.700 --> 00:10:18.200
And I think that
this is going to be

00:10:18.200 --> 00:10:21.180
a byproduct in part of the
combination of hardware

00:10:21.180 --> 00:10:22.870
and software innovation.

00:10:22.870 --> 00:10:25.915
And so if I can
take a minute or two

00:10:25.915 --> 00:10:29.640
to describe one of this
weirder predictions of mine

00:10:29.640 --> 00:10:32.520
from the book, but which I--
God's honest truth-- I believe

00:10:32.520 --> 00:10:33.580
is going to be true.

00:10:33.580 --> 00:10:35.800
So right now, there's
some very difficult access

00:10:35.800 --> 00:10:39.137
to markets like, Papua
New Guinea, and Indonesia.

00:10:39.137 --> 00:10:41.470
And, Jared, I hope you and I
travel to Papua New Guinea.

00:10:41.470 --> 00:10:42.678
JARED COHEN: I would love to.

00:10:42.678 --> 00:10:46.335
ALEC ROSS: Yes, before
it gets overrun by guys

00:10:46.335 --> 00:10:49.460
in white shirts and red ties.

00:10:49.460 --> 00:10:53.480
Papua New Guinea is largely
inaccessible for most

00:10:53.480 --> 00:10:58.090
businesses right now, because
they speak over 800 languages.

00:10:58.090 --> 00:11:02.797
It might seem like a ridiculous
reason for barrier to entry,

00:11:02.797 --> 00:11:05.130
but it's actually why people
have a very hard time doing

00:11:05.130 --> 00:11:05.970
business there.

00:11:05.970 --> 00:11:07.860
Similarly, Indonesia.

00:11:07.860 --> 00:11:11.470
There are enough people
in Jakarta and Bali

00:11:11.470 --> 00:11:15.680
who speak English or French
that you can do business

00:11:15.680 --> 00:11:17.720
in Jakarta and
Bali, but there are

00:11:17.720 --> 00:11:21.990
over 1,100 islands and over
700 of other languages spoken.

00:11:21.990 --> 00:11:25.600
So the vast majority of
Indonesia, for example,

00:11:25.600 --> 00:11:27.612
is largely inaccessible.

00:11:27.612 --> 00:11:29.070
And so what I
believe is that there

00:11:29.070 --> 00:11:33.390
will be a device, that if you
travel to Papua New Guinea,

00:11:33.390 --> 00:11:37.130
and somebody is speaking
one of those 800 languages,

00:11:37.130 --> 00:11:40.150
there will be an earpiece
that you can put in your ear,

00:11:40.150 --> 00:11:43.700
and as someone is speaking
to you in whatever language,

00:11:43.700 --> 00:11:48.730
at the speed of sound, the
voice that you hear in your ear

00:11:48.730 --> 00:11:50.970
will be the language
that you want to hear.

00:11:50.970 --> 00:11:52.800
And it won't be Siri's voice.

00:11:52.800 --> 00:11:55.590
It will measure the
frequency, wavelength,

00:11:55.590 --> 00:11:58.950
and sound intensity, and
other properties of the voice,

00:11:58.950 --> 00:12:03.700
and translate the voice that
you are hearing in your ear,

00:12:03.700 --> 00:12:05.520
very closely
approximating the speaker.

00:12:05.520 --> 00:12:08.536
And so I think that that kind
of thing, like literally being

00:12:08.536 --> 00:12:09.910
able to pop
something in your ear

00:12:09.910 --> 00:12:14.460
and be able to speak to
anybody in any language

00:12:14.460 --> 00:12:19.310
is going to do more to unleash
the next wave of globalization

00:12:19.310 --> 00:12:20.466
than anything else.

00:12:20.466 --> 00:12:21.840
JARED COHEN: On
the device thing,

00:12:21.840 --> 00:12:25.610
I can't resist the urge to ask,
if there's a friend of mine

00:12:25.610 --> 00:12:27.940
that I think has a
particularly soothing voice

00:12:27.940 --> 00:12:30.865
or an endearing voice,
can I have that voice?

00:12:30.865 --> 00:12:32.920
Or am I stuck with
some version of my own?

00:12:32.920 --> 00:12:35.500
ALEC ROSS: So for those of
you who don't know Jared,

00:12:35.500 --> 00:12:38.000
this is a characteristically
Jared question.

00:12:38.000 --> 00:12:39.227
Of course, Jared.

00:12:39.227 --> 00:12:41.310
JARED COHEN: Can you do
your mother-in-law, or no?

00:12:41.310 --> 00:12:44.104
ALEC ROSS: I'm sure you can
do an Australian accent.

00:12:44.104 --> 00:12:45.520
JARED COHEN: Can
you combine them?

00:12:45.520 --> 00:12:48.790
Could I do Australian
accent on Tuesday, ,

00:12:48.790 --> 00:12:52.240
mother-in-law on Thursday,
best friend on Friday?

00:12:52.240 --> 00:12:54.970
ALEC ROSS: You know, given
the product hasn't actually

00:12:54.970 --> 00:12:59.290
been invented yet,
when I invent it,

00:12:59.290 --> 00:13:01.790
I'll be sure to keep these
design features in mind.

00:13:01.790 --> 00:13:04.180
JARED COHEN: And it is fun to
speculate about the future.

00:13:04.180 --> 00:13:05.596
The best part is,
if you're right,

00:13:05.596 --> 00:13:06.980
everyone thinks you're a genius.

00:13:06.980 --> 00:13:09.640
If you speculate far enough into
the future, and you're wrong,

00:13:09.640 --> 00:13:11.582
nobody remembers,
and you can deny it.

00:13:11.582 --> 00:13:13.040
ALEC ROSS: What I
did in this book,

00:13:13.040 --> 00:13:15.250
I tried to keep
things bounded 20

00:13:15.250 --> 00:13:17.890
years at the outermost limit.

00:13:17.890 --> 00:13:21.117
Because beyond that,
it gets a little silly.

00:13:21.117 --> 00:13:22.700
And I also think
that things are going

00:13:22.700 --> 00:13:25.732
to change rather substantially
over the next 20 years.

00:13:25.732 --> 00:13:28.190
JARED COHEN: So I want to ask
you a little bit about norms.

00:13:28.190 --> 00:13:30.356
Because obviously, this
group understands technology

00:13:30.356 --> 00:13:32.830
very well, probably better
than any other groups

00:13:32.830 --> 00:13:36.125
that you've spoken to while
you've been on book tour.

00:13:36.125 --> 00:13:37.580
But norms matter a lot.

00:13:37.580 --> 00:13:40.754
And you have a really
interesting couple chapters

00:13:40.754 --> 00:13:41.920
where you touch on robotics.

00:13:41.920 --> 00:13:43.760
And one of the
things you observe

00:13:43.760 --> 00:13:47.960
is it seems that in the
US, the notion of robotics

00:13:47.960 --> 00:13:51.670
is scary to the general
populace and evokes images

00:13:51.670 --> 00:13:52.460
of Terminator.

00:13:52.460 --> 00:13:54.600
And maybe that's because
"Terminator 2" was

00:13:54.600 --> 00:13:56.990
a very popular American movie.

00:13:56.990 --> 00:13:58.950
But then you go to
Japan, and you spend time

00:13:58.950 --> 00:14:02.960
with robotics companies there,
and it's wildly embraced.

00:14:02.960 --> 00:14:07.505
Talk about what is it
about culture in Japan

00:14:07.505 --> 00:14:09.130
and elsewhere that
leads people to have

00:14:09.130 --> 00:14:11.586
a totally different
interpretation of what

00:14:11.586 --> 00:14:12.960
is, in fact, the
same technology.

00:14:12.960 --> 00:14:14.418
ALEC ROSS: It's
really interesting.

00:14:14.418 --> 00:14:18.090
So in Western societies,
Western religions,

00:14:18.090 --> 00:14:23.750
our mythology, our culture,
tells us, reinforces the idea

00:14:23.750 --> 00:14:27.400
that we ought to guard
against animating,

00:14:27.400 --> 00:14:31.370
bringing to life that
which perhaps we ought not.

00:14:31.370 --> 00:14:36.440
So from Icarus's waxed
wings to Frankenstein,

00:14:36.440 --> 00:14:41.150
we're continually warned in
our mythology, in our culture,

00:14:41.150 --> 00:14:43.090
in our fiction,
against such things.

00:14:43.090 --> 00:14:48.540
By contrast, in Japan, for
example, 80% of Japanese people

00:14:48.540 --> 00:14:51.470
practice Shinto, the
religion of Shinto.

00:14:51.470 --> 00:14:54.190
In Shinto, they
believe in animism,

00:14:54.190 --> 00:14:59.110
which holds that objects,
like humans, have souls.

00:14:59.110 --> 00:15:05.380
And so one of the, I think,
quite interesting innovations

00:15:05.380 --> 00:15:08.610
that I described that's
happening right now

00:15:08.610 --> 00:15:12.094
is the move towards elder
care robots in Japan.

00:15:12.094 --> 00:15:13.760
JARED COHEN: How many
of you have heard?

00:15:13.760 --> 00:15:14.426
Raise your hand.

00:15:14.426 --> 00:15:17.260
How many of you have heard of
elder care robots in Japan?

00:15:17.260 --> 00:15:19.400
The highest penetration
in any audience

00:15:19.400 --> 00:15:19.760
of people that
have heard of that.

00:15:19.760 --> 00:15:21.950
ALEC ROSS: I was about
to say, that's bananas.

00:15:21.950 --> 00:15:24.850
I must be at Google.

00:15:24.850 --> 00:15:27.960
For the 40% of you who
have not heard of this,

00:15:27.960 --> 00:15:30.990
Japan has the world's
longest living citizens.

00:15:30.990 --> 00:15:34.480
I think it's 83 for
women, 79 for men.

00:15:34.480 --> 00:15:36.430
And they are growing
older because

00:15:36.430 --> 00:15:39.300
of relatively
restrictive immigration

00:15:39.300 --> 00:15:41.400
policies and low birth rates.

00:15:41.400 --> 00:15:43.150
There are not enough
grandchildren to take

00:15:43.150 --> 00:15:44.530
care of grandparents.

00:15:44.530 --> 00:15:48.950
And so Honda and Toyota, yes,
the auto makers, as well as

00:15:48.950 --> 00:15:52.600
some startups, are looking
at literally creating--

00:15:52.600 --> 00:15:56.140
they are creating home care
robots which do everything

00:15:56.140 --> 00:15:58.750
from lift the
grandparents out of bed

00:15:58.750 --> 00:16:04.050
to entertain them with violin
playing and other such things.

00:16:04.050 --> 00:16:06.370
But what's interesting
to me is the degree

00:16:06.370 --> 00:16:11.810
to which culture is
deterministic in terms

00:16:11.810 --> 00:16:17.350
of the creation of these robots
and the degree to which people

00:16:17.350 --> 00:16:19.735
are and are not comfortable
with the technology.

00:16:19.735 --> 00:16:21.110
And so I think
that this is going

00:16:21.110 --> 00:16:25.040
to effect-- when you look at
the 196 country chess board,

00:16:25.040 --> 00:16:29.320
if you think of robots as being
one of the industries that

00:16:29.320 --> 00:16:30.850
is consequential
today, but which

00:16:30.850 --> 00:16:33.730
will be substantially more
consequential tomorrow,

00:16:33.730 --> 00:16:37.334
I think a lot of it is going to
come from East Asian societies,

00:16:37.334 --> 00:16:39.833
in part because they don't have
the cultural package that we

00:16:39.833 --> 00:16:41.280
do in the West.

00:16:41.280 --> 00:16:44.510
JARED COHEN: So I want to
stay on this theme of norms,

00:16:44.510 --> 00:16:48.620
because I think it's something
that we at Google and Alphabet

00:16:48.620 --> 00:16:52.010
and more broadly could probably
spend a little bit more time

00:16:52.010 --> 00:16:53.100
thinking about.

00:16:53.100 --> 00:16:56.680
And nuanced differences
between robotics

00:16:56.680 --> 00:16:59.990
evoking fears of
terminator in the West

00:16:59.990 --> 00:17:02.770
and being wildly embraced
in the East, that's

00:17:02.770 --> 00:17:05.140
subtle compared to some of
the more complex normative

00:17:05.140 --> 00:17:05.710
challenges.

00:17:05.710 --> 00:17:08.500
So one of the things you
talk a lot about in your book

00:17:08.500 --> 00:17:11.990
is the commercialization of
genomics and life sciences

00:17:11.990 --> 00:17:13.602
more broadly.

00:17:13.602 --> 00:17:15.060
When we talk about
these things, we

00:17:15.060 --> 00:17:19.310
talk as if there is one of
the jurisdiction on Earth.

00:17:19.310 --> 00:17:21.890
And it makes all that
the ethical conversations

00:17:21.890 --> 00:17:26.510
and debates that we have
miss the larger point, which

00:17:26.510 --> 00:17:29.810
is there's 196 different
jurisdictions on Earth.

00:17:29.810 --> 00:17:32.620
And they range from North
Korea to the United States

00:17:32.620 --> 00:17:35.180
and everything in between.

00:17:35.180 --> 00:17:37.700
So you have a situation
where countries

00:17:37.700 --> 00:17:41.950
have different sets of values,
and ethics, and ambitions,

00:17:41.950 --> 00:17:44.600
and aspirations, and so let's
take a very controversial

00:17:44.600 --> 00:17:46.150
debate that we're
all familiar with,

00:17:46.150 --> 00:17:50.320
which is the process
of editing genes

00:17:50.320 --> 00:17:54.690
to improve an unborn child.

00:17:54.690 --> 00:17:57.100
There are lots of regulations
in the United States,

00:17:57.100 --> 00:18:00.500
for instance, that will protect
against the productization

00:18:00.500 --> 00:18:02.220
of babies.

00:18:02.220 --> 00:18:05.190
But what happens when
some entrepreneur decides,

00:18:05.190 --> 00:18:07.134
OK, I can't do this
in China, but Qatar

00:18:07.134 --> 00:18:08.800
will let me build a
multi-billion dollar

00:18:08.800 --> 00:18:12.580
company that does gene editing
to get the right eye color,

00:18:12.580 --> 00:18:15.420
or gene editing to
get the right height?

00:18:15.420 --> 00:18:19.280
How do you handle that kind
of an ethical asymmetry?

00:18:19.280 --> 00:18:22.150
And who ends up winning
in that situation?

00:18:22.150 --> 00:18:23.620
Is it the
jurisdictions that have

00:18:23.620 --> 00:18:27.004
the right ethical
standards, if you can answer

00:18:27.004 --> 00:18:28.170
the question of who's right?

00:18:28.170 --> 00:18:31.050
Or is it the
jurisdictions that have

00:18:31.050 --> 00:18:34.506
a very lax and irresponsible
attitude about this?

00:18:34.506 --> 00:18:36.380
ALEC ROSS: So let's
unpack that a little bit.

00:18:36.380 --> 00:18:41.000
So for context, the norms that
exist in terms of governance

00:18:41.000 --> 00:18:43.940
on the internet,
exist dating back

00:18:43.940 --> 00:18:48.130
to a period when nobody was
really paying attention.

00:18:48.130 --> 00:18:50.890
So you know I'm sure
most of this audience

00:18:50.890 --> 00:18:53.270
is familiar with the
multi-stakeholder model

00:18:53.270 --> 00:18:55.150
for internet governance
that is inclusive

00:18:55.150 --> 00:18:57.710
of the private sector,
government, academia,

00:18:57.710 --> 00:18:59.940
civil society, and
it's international,

00:18:59.940 --> 00:19:01.770
though the United
States has a pretty

00:19:01.770 --> 00:19:05.860
heavy thumb on the scale on
policy issues of consequence.

00:19:05.860 --> 00:19:09.330
To be able to create the
governance model, which

00:19:09.330 --> 00:19:15.190
in turn dominates the norms
setting for the internet,

00:19:15.190 --> 00:19:18.430
it would be impossible to
reconstitute that today.

00:19:18.430 --> 00:19:20.260
They were only able
to do it at the time

00:19:20.260 --> 00:19:23.570
because there was insufficient
attention given to the issue,

00:19:23.570 --> 00:19:25.126
and there was
remarkable asymmetry

00:19:25.126 --> 00:19:26.500
in terms of the
capability, where

00:19:26.500 --> 00:19:29.820
the capabilities were largely
domiciled in the United States.

00:19:29.820 --> 00:19:32.230
So the United States got
to dominate the process

00:19:32.230 --> 00:19:35.070
for establishing
governance of the internet

00:19:35.070 --> 00:19:38.050
and the subsequent
norms setting.

00:19:38.050 --> 00:19:40.940
Now I think that for the
industries of the future,

00:19:40.940 --> 00:19:43.520
and let's stick to the
commercialization of genomics,

00:19:43.520 --> 00:19:47.690
which you brought up,
everybody has two eyes open.

00:19:47.690 --> 00:19:51.720
And so the idea that the
rules and regulations that

00:19:51.720 --> 00:19:55.660
are set in the United
States and the norms,

00:19:55.660 --> 00:19:58.700
that which is considered to
be acceptable or unacceptable

00:19:58.700 --> 00:20:00.840
independent of
regulation and statute,

00:20:00.840 --> 00:20:05.920
the idea that our country,
which constitutes fewer than 5%

00:20:05.920 --> 00:20:09.390
of the globe's
population, is going

00:20:09.390 --> 00:20:12.960
to be able to dictate what the
95% of the rest of the world

00:20:12.960 --> 00:20:16.720
thinks, does, and
accepts, is naive.

00:20:16.720 --> 00:20:19.910
Especially, since there
are other states out there,

00:20:19.910 --> 00:20:24.426
like China, for example,
which are investing very, very

00:20:24.426 --> 00:20:26.050
aggressively in the
space, so that they

00:20:26.050 --> 00:20:31.830
can be the headquarters to
the Googles of genomics.

00:20:31.830 --> 00:20:34.230
The world's last
trillion dollar industry

00:20:34.230 --> 00:20:36.162
was created out
of computer code.

00:20:36.162 --> 00:20:37.870
The world's next
trillion dollar industry

00:20:37.870 --> 00:20:40.770
is going to be created
out of genetic code.

00:20:40.770 --> 00:20:45.320
And it is an open
question where the HQs

00:20:45.320 --> 00:20:48.870
will be for the trillion
dollar industry of the future.

00:20:48.870 --> 00:20:51.570
And so getting back to
this question of norms,

00:20:51.570 --> 00:20:57.710
what I believe is going to
happen is that if the United

00:20:57.710 --> 00:21:03.270
States significantly regulates
what can and cannot be done

00:21:03.270 --> 00:21:06.040
with gene editing,
then we will see,

00:21:06.040 --> 00:21:11.960
in the same way in which
Switzerland created

00:21:11.960 --> 00:21:18.660
a permissionless environment
for decades in banking,

00:21:18.660 --> 00:21:22.310
I think that we will see the
equivalent of what Switzerland

00:21:22.310 --> 00:21:25.610
was to banking will
be-- you said Qatar--

00:21:25.610 --> 00:21:30.360
will be any of 10 or 12 states
around the globe for genomics.

00:21:30.360 --> 00:21:34.670
So that an expectant
mother, who is

00:21:34.670 --> 00:21:38.400
newly in her second
trimester, who do

00:21:38.400 --> 00:21:41.690
has seen that there
is a mutation,

00:21:41.690 --> 00:21:47.290
a specific protein is
misfiring on a gene

00:21:47.290 --> 00:21:49.700
and she wants it fixed,
but it countervails

00:21:49.700 --> 00:21:52.840
the laws in the United States,
then she'll get on a plane,

00:21:52.840 --> 00:21:56.520
and she will fly to whatever
country does allow it.

00:21:56.520 --> 00:22:00.590
And so what I think is that is
interesting is that I do think

00:22:00.590 --> 00:22:05.540
that, ultimately, these
countries-- these companies

00:22:05.540 --> 00:22:08.010
that all are
commercializing genomics

00:22:08.010 --> 00:22:14.780
will set up in the
most lax environment.

00:22:14.780 --> 00:22:17.040
From a regulatory
standpoint, we already

00:22:17.040 --> 00:22:20.070
see within the
life sciences lots

00:22:20.070 --> 00:22:23.580
of companies moving
their headquarters abroad

00:22:23.580 --> 00:22:24.620
for tax purposes.

00:22:24.620 --> 00:22:27.699
So, bluntly, there's already
a culture within the field

00:22:27.699 --> 00:22:28.740
of saying, you know what?

00:22:28.740 --> 00:22:32.100
We don't have to be
an American company.

00:22:32.100 --> 00:22:36.400
And then, as we all know, they
can create corporate vehicles,

00:22:36.400 --> 00:22:38.420
even if they do have
most of their employees

00:22:38.420 --> 00:22:39.820
in the United States.

00:22:39.820 --> 00:22:41.990
They'll create different
corporate vehicles

00:22:41.990 --> 00:22:43.823
and structures to allow
them to end up doing

00:22:43.823 --> 00:22:45.390
whatever they want abroad.

00:22:45.390 --> 00:22:47.210
So I think that
government actually

00:22:47.210 --> 00:22:51.660
has significantly
limited power to curtail

00:22:51.660 --> 00:22:55.750
innovation and privatization
in this space, norms be damned.

00:22:55.750 --> 00:22:57.610
Because somebody
somewhere will create

00:22:57.610 --> 00:23:00.220
an environment that allows
people to you whatever

00:23:00.220 --> 00:23:01.860
you want.

00:23:01.860 --> 00:23:06.500
JARED COHEN: And what's the
regulatory reaction to that?

00:23:06.500 --> 00:23:09.586
You have a bunch of
companies out there

00:23:09.586 --> 00:23:12.175
that are difficult to
regulate, and maybe they're

00:23:12.175 --> 00:23:13.800
doing something
disruptive, but they're

00:23:13.800 --> 00:23:16.110
difficult to regulate
because of the jurisdictions

00:23:16.110 --> 00:23:18.230
that they're headquartered in.

00:23:18.230 --> 00:23:20.925
Is there a risk that the
companies that are doing it

00:23:20.925 --> 00:23:26.530
right, that are operating in
stricter jurisdictions end up

00:23:26.530 --> 00:23:30.710
getting the wrath of government,
because they can be scrutinized

00:23:30.710 --> 00:23:32.730
whereas some of
the others can't?

00:23:32.730 --> 00:23:34.230
ALEC ROSS: I mean,
so yes, but let's

00:23:34.230 --> 00:23:35.980
also back up a little bit.

00:23:35.980 --> 00:23:37.130
Back up.

00:23:37.130 --> 00:23:40.320
And let's actually
ask the question--

00:23:40.320 --> 00:23:45.760
should parents be able to
do gene edit so that instead

00:23:45.760 --> 00:23:50.840
of having a son who's projected
to be between 5'5 and 5'7, they

00:23:50.840 --> 00:23:52.180
want to add inches.

00:23:52.180 --> 00:23:55.230
They want them to be
between 6'2 and 6'4.

00:23:55.230 --> 00:23:59.720
They want to not just
repair damaged DNA,

00:23:59.720 --> 00:24:02.890
but they want to make what they
consider to be an enhancement.

00:24:05.440 --> 00:24:07.310
I could argue that both ways.

00:24:07.310 --> 00:24:09.470
I really could.

00:24:09.470 --> 00:24:12.005
What constitutes an enhancement?

00:24:12.005 --> 00:24:12.880
And what do we allow?

00:24:12.880 --> 00:24:14.090
What do we disallow?

00:24:14.090 --> 00:24:16.540
Do we allow eye
color to be changed?

00:24:16.540 --> 00:24:20.220
Do we allow height and
height to be changed?

00:24:20.220 --> 00:24:22.870
Do we allow weight, projected
weight to be changed,

00:24:22.870 --> 00:24:26.900
if there is a genetic
indicator that

00:24:26.900 --> 00:24:29.560
indicates that this child
will likely be obese?

00:24:29.560 --> 00:24:34.040
I mean, there's so much
subjectivity baked into this

00:24:34.040 --> 00:24:35.630
that I actually
think we need to ask

00:24:35.630 --> 00:24:38.820
the second, third, and
fourth question here, and not

00:24:38.820 --> 00:24:42.640
be a solution in
search of a problem.

00:24:42.640 --> 00:24:47.500
So while my wife and I might
make choices to not gene

00:24:47.500 --> 00:24:51.030
edit a child in
utero, I'm not yet

00:24:51.030 --> 00:25:00.330
ready to concede the point that
anything beyond addressing what

00:25:00.330 --> 00:25:07.126
we know to be malignancies
in our genetic profile

00:25:07.126 --> 00:25:08.250
is necessarily a bad thing.

00:25:08.250 --> 00:25:10.804
I tend to be in favor of more
freedom than less freedom.

00:25:10.804 --> 00:25:12.970
JARED COHEN: So speaking
of less freedom, let's talk

00:25:12.970 --> 00:25:14.900
about China for a minute.

00:25:14.900 --> 00:25:17.525
Because you mentioned it before.

00:25:17.525 --> 00:25:21.840
So China, in many respects,
is a fascinating case study

00:25:21.840 --> 00:25:25.370
for a lot of the things that
you mentioned in the book,

00:25:25.370 --> 00:25:27.110
and how will it play out.

00:25:27.110 --> 00:25:30.270
Let me ask you two different
China question, one about

00:25:30.270 --> 00:25:32.910
innovation, one about
the increased complexity

00:25:32.910 --> 00:25:35.890
of geopolitics, and then
maybe a leadership question,

00:25:35.890 --> 00:25:38.750
and then I'll open it
up to the audience.

00:25:38.750 --> 00:25:42.510
So when I look at China,
they are competing

00:25:42.510 --> 00:25:44.160
in two capitalist systems.

00:25:44.160 --> 00:25:46.670
They compete in one
capitalist system, that

00:25:46.670 --> 00:25:50.240
allows them to innovate by
stealing intellectual property,

00:25:50.240 --> 00:25:52.970
and then scaling
coffee companies

00:25:52.970 --> 00:25:56.510
on the foundation of that
stolen intellectual property.

00:25:56.510 --> 00:25:58.960
And then they also compete
in the same capitalist system

00:25:58.960 --> 00:26:02.240
that the United States is
part of, which is basically

00:26:02.240 --> 00:26:03.750
legitimate innovation.

00:26:03.750 --> 00:26:05.040
And they're able to do both.

00:26:05.040 --> 00:26:07.440
There's a lot of legitimate
innovation in China,

00:26:07.440 --> 00:26:09.710
and then, of course,
there's some stolen

00:26:09.710 --> 00:26:11.040
intellectual property.

00:26:11.040 --> 00:26:13.260
So there's an asymmetry here.

00:26:13.260 --> 00:26:16.810
And in a world where China
can play in two systems,

00:26:16.810 --> 00:26:20.820
and innovate in
ways that countries

00:26:20.820 --> 00:26:23.000
that abide by different
sets of norms and laws

00:26:23.000 --> 00:26:26.470
can't, it doesn't seem
to me like a fair fight.

00:26:26.470 --> 00:26:29.040
So how does that
play out in terms

00:26:29.040 --> 00:26:33.300
of the competition over
building the next innovative,

00:26:33.300 --> 00:26:35.050
multi-billion dollar company?

00:26:35.050 --> 00:26:37.383
ALEC ROSS: So this is going
to be terrible undiplomatic,

00:26:37.383 --> 00:26:40.350
but I'm not a diplomat
anymore, so I don't care.

00:26:40.350 --> 00:26:42.510
I actually would
argue against-- I

00:26:42.510 --> 00:26:46.930
mean, what innovation
has come from China

00:26:46.930 --> 00:26:50.280
that's rooted in the internet?

00:26:50.280 --> 00:26:51.870
Not a lot.

00:26:51.870 --> 00:26:54.102
I mean, you'd be hard pressed.

00:26:54.102 --> 00:26:55.310
And most of it is derivative.

00:26:55.310 --> 00:26:56.430
It's a little tweak here.

00:26:56.430 --> 00:26:57.670
It's a little tweak there.

00:26:57.670 --> 00:27:04.740
I actually think that,
overwhelmingly, China

00:27:04.740 --> 00:27:06.980
has built big
internet businesses

00:27:06.980 --> 00:27:09.240
because it has stolen
intellectual property

00:27:09.240 --> 00:27:10.420
from abroad.

00:27:10.420 --> 00:27:12.140
When I was in government,
we declassified

00:27:12.140 --> 00:27:15.680
a National Intelligence Estimate
report, which we really did,

00:27:15.680 --> 00:27:19.020
which pegged the annual
intellectual theft

00:27:19.020 --> 00:27:21.200
about $300 billion a year.

00:27:21.200 --> 00:27:23.740
I mean, if you go into
the source code of Renren,

00:27:23.740 --> 00:27:26.700
it says "A Mark Zuckerberg
Production" on it.

00:27:26.700 --> 00:27:28.050
Literally.

00:27:28.050 --> 00:27:30.820
Because Mark did a vanity
thing in the source code

00:27:30.820 --> 00:27:32.720
for Facebook, and they stole it.

00:27:32.720 --> 00:27:34.305
We literally saw it in Renren.

00:27:34.305 --> 00:27:36.110
It's hilarious.

00:27:36.110 --> 00:27:40.350
So I actually think
that while they

00:27:40.350 --> 00:27:42.580
have built some good
internet based businesses,

00:27:42.580 --> 00:27:45.760
I think they're largely
a product of theft

00:27:45.760 --> 00:27:47.950
than mercantilism.

00:27:47.950 --> 00:27:52.160
And so the question now is
the industries of the future.

00:27:52.160 --> 00:27:55.150
Will they be able to
innovate in fields

00:27:55.150 --> 00:27:58.750
like the commercialization
of genomics, big data, cyber

00:27:58.750 --> 00:28:00.860
security, and other such fields.

00:28:00.860 --> 00:28:02.450
And I think the
answer is, yes and no.

00:28:02.450 --> 00:28:03.825
I think that there
will be fields

00:28:03.825 --> 00:28:08.840
where they create things, where
imagination and invention turns

00:28:08.840 --> 00:28:11.550
to commercialization, and they
build legitimate businesses.

00:28:11.550 --> 00:28:14.750
I think there will be
fields where they do that.

00:28:14.750 --> 00:28:16.840
I think that the
commercialization of genomics

00:28:16.840 --> 00:28:20.140
is likely to be an especially
good place for them.

00:28:20.140 --> 00:28:22.760
BGI, what was formerly called
the Beijing Genomics Institute,

00:28:22.760 --> 00:28:25.380
is now actually the largest.

00:28:25.380 --> 00:28:29.087
It does more gene sequencing
than any place on planet Earth.

00:28:29.087 --> 00:28:31.170
And in genomics, for
example, unlike the internet,

00:28:31.170 --> 00:28:34.120
where they built their
internet based businesses,

00:28:34.120 --> 00:28:38.470
being content from
the outset to wall off

00:28:38.470 --> 00:28:40.660
their population of
1.3 billion people,

00:28:40.660 --> 00:28:42.750
so long as they
could dominate China,

00:28:42.750 --> 00:28:46.410
they didn't mind that they
were not largely exporting.

00:28:46.410 --> 00:28:48.760
It aws really Jack
Ma and Ali Baba

00:28:48.760 --> 00:28:53.260
who first asserted that Chinese
companies can and should

00:28:53.260 --> 00:28:54.190
export.

00:28:54.190 --> 00:28:59.270
And as Ali Baba, on the
consumer facing side,

00:28:59.270 --> 00:29:02.950
it was walled away on
the enterprise side.

00:29:02.950 --> 00:29:04.640
And now we see with
Xiaomi and others,

00:29:04.640 --> 00:29:06.542
they are growing more assertive.

00:29:06.542 --> 00:29:09.000
What do you think is that for
the industries of the future,

00:29:09.000 --> 00:29:10.583
I don't think that
they're going to be

00:29:10.583 --> 00:29:15.601
content to view their own home
market as an end unto itself

00:29:15.601 --> 00:29:16.100
initially.

00:29:16.100 --> 00:29:18.940
And I think they're going to
be more inherently global.

00:29:18.940 --> 00:29:20.480
And as a result of
that, I actually

00:29:20.480 --> 00:29:23.010
think that they will be
more rights respecting.

00:29:23.010 --> 00:29:24.580
In the commercialization
of genomics,

00:29:24.580 --> 00:29:27.100
for example, I would
be very surprised

00:29:27.100 --> 00:29:31.090
if BGI, or any of the
other large institutions,

00:29:31.090 --> 00:29:35.590
get into the pattern of IP theft
and state supported IP theft,

00:29:35.590 --> 00:29:39.230
that their internet-based
businesses did.

00:29:39.230 --> 00:29:41.870
And I think that that is largely
because of if they position

00:29:41.870 --> 00:29:45.020
themselves in the
marketplace like that,

00:29:45.020 --> 00:29:47.730
then they will have a
very difficult time doing

00:29:47.730 --> 00:29:49.930
the necessary partnering
and other exercises

00:29:49.930 --> 00:29:54.220
it will take to eventually
become the deca-billion billion

00:29:54.220 --> 00:29:56.520
company HQed in China.

00:29:56.520 --> 00:30:02.540
So as much as I bashed China on
their practices in the internet

00:30:02.540 --> 00:30:05.400
space, and-- full disclosure,
my name was a banned search term

00:30:05.400 --> 00:30:07.600
on the internet in
China for two years,

00:30:07.600 --> 00:30:13.830
and I spent $100 million of
taxpayer dollars on different

00:30:13.830 --> 00:30:16.130
technologies to allow people
to get around government

00:30:16.130 --> 00:30:19.940
firewalls, most of which
you've probably used-- I--

00:30:19.940 --> 00:30:22.510
JARED COHEN: I do think that
would get your name banned.

00:30:22.510 --> 00:30:23.300
That would do it.

00:30:23.300 --> 00:30:24.970
ALEC ROSS: Yeah.

00:30:24.970 --> 00:30:28.810
I do think that I take a more
optimistic view of the future,

00:30:28.810 --> 00:30:32.220
because I do think that
the entrepreneurs in China

00:30:32.220 --> 00:30:35.890
are thinking globally now
as opposed to locally,

00:30:35.890 --> 00:30:37.970
the way that their
internet-based businesses did,

00:30:37.970 --> 00:30:41.807
beginning the late '90s until
three, four, five years ago.

00:30:41.807 --> 00:30:43.640
JARED COHEN: We've
talked about this before.

00:30:43.640 --> 00:30:46.730
There's also, especially
with the younger generation

00:30:46.730 --> 00:30:48.230
of entrepreneurs,
there's a badge

00:30:48.230 --> 00:30:49.980
of honor associated
with being able to say

00:30:49.980 --> 00:30:51.467
they did it legitimately.

00:30:51.467 --> 00:30:53.050
Let me ask you a
geopolitical question

00:30:53.050 --> 00:30:55.497
about China, then one quick
one on leadership/parenting.

00:30:55.497 --> 00:30:56.580
And then we'll open it up.

00:31:00.600 --> 00:31:03.540
One of the things you
talk about is the impact

00:31:03.540 --> 00:31:06.380
that all of these innovation
industries of the future

00:31:06.380 --> 00:31:10.450
will have on just the
International dynamics that we

00:31:10.450 --> 00:31:11.980
see play out in geopolitics.

00:31:11.980 --> 00:31:15.800
So last time I checked, there
was one international system.

00:31:15.800 --> 00:31:18.360
It has a physical front,
and it has a digital front.

00:31:18.360 --> 00:31:22.970
Yet when you look at the
foreign policies of states,

00:31:22.970 --> 00:31:24.840
their policies in
one domain, at times,

00:31:24.840 --> 00:31:25.590
will contradict the other.

00:31:25.590 --> 00:31:27.715
So let me give an example,
in the context of the US

00:31:27.715 --> 00:31:28.570
and China.

00:31:28.570 --> 00:31:32.340
What is the relationship between
the United States and China?

00:31:32.340 --> 00:31:34.740
Well, in the physical
domain, at worst,

00:31:34.740 --> 00:31:37.064
it's frenemies, at
best, it's partners.

00:31:37.064 --> 00:31:38.730
In the digital domain,
the two countries

00:31:38.730 --> 00:31:41.870
are in a perpetual state of
war, and the relationship

00:31:41.870 --> 00:31:44.680
is more kinetic and adversarial
than the physical one

00:31:44.680 --> 00:31:46.860
between the United
States and North Korea.

00:31:46.860 --> 00:31:50.020
So the problem I have is these
are still only two countries.

00:31:50.020 --> 00:31:52.710
Their foreign policies
contradict each other

00:31:52.710 --> 00:31:54.030
across the two domains.

00:31:54.030 --> 00:31:57.850
So is there are a point at which
nefarious cyber activity spills

00:31:57.850 --> 00:32:01.625
over and potentially fuels
a physical world conflict?

00:32:01.625 --> 00:32:02.250
ALEC ROSS: Yes.

00:32:02.250 --> 00:32:07.020
So we were talking earlier
about norm setting.

00:32:07.020 --> 00:32:09.840
What's interesting
about the cyber domain

00:32:09.840 --> 00:32:13.955
is there essentially are no
norms that have been set.

00:32:13.955 --> 00:32:17.110
There are very few things
in the ways of treaties.

00:32:17.110 --> 00:32:19.470
There are very few
multilateral institutions

00:32:19.470 --> 00:32:20.680
that are functional.

00:32:20.680 --> 00:32:24.840
It's not like the frameworks
that were built in the '50s

00:32:24.840 --> 00:32:30.710
through the '80s around
nuclear arms, which

00:32:30.710 --> 00:32:35.130
we were able to forge agreements
with the USSR in large part

00:32:35.130 --> 00:32:36.370
because of mutual interest.

00:32:36.370 --> 00:32:39.650
Right now, the United States
and China, for example,

00:32:39.650 --> 00:32:41.900
have such a different
set of values

00:32:41.900 --> 00:32:44.650
around what it is
and is not permitted

00:32:44.650 --> 00:32:45.739
in the internet space.

00:32:45.739 --> 00:32:47.280
So the United States,
for example, we

00:32:47.280 --> 00:32:52.090
will not give any ground
on, and we will not

00:32:52.090 --> 00:32:57.950
be party to any treaty that
curtails our ability to engage

00:32:57.950 --> 00:33:00.540
in intelligence activities.

00:33:00.540 --> 00:33:01.230
We won't.

00:33:01.230 --> 00:33:03.360
We won't be a signatory
to any of that.

00:33:03.360 --> 00:33:06.510
And because we won't be a
signatory to any of that, which

00:33:06.510 --> 00:33:09.020
is a precondition
for the Chinese

00:33:09.020 --> 00:33:11.660
to engage with us on
anything, the Chinese

00:33:11.660 --> 00:33:15.990
will not be a signatory to
anything meaningful that

00:33:15.990 --> 00:33:20.220
curtails their work in
economic espionage, IP theft.

00:33:20.220 --> 00:33:23.780
And so what you get is,
in the Venn diagram,

00:33:23.780 --> 00:33:26.700
there is very little
overlapping space.

00:33:26.700 --> 00:33:29.860
And what happens
is we end up having

00:33:29.860 --> 00:33:33.500
a very different relationship
in the internet space,

00:33:33.500 --> 00:33:37.680
in the cyber domain, than
we do in the physical world,

00:33:37.680 --> 00:33:38.840
in the polite world.

00:33:38.840 --> 00:33:41.260
What I will say, though, is
we're talking governments.

00:33:41.260 --> 00:33:42.926
What would actually
be interesting to me

00:33:42.926 --> 00:33:44.980
is the relationship not
just country to country,

00:33:44.980 --> 00:33:46.760
but country to company.

00:33:46.760 --> 00:33:50.180
So I remember, for example,
when Google was cyber attacked

00:33:50.180 --> 00:33:55.220
in 2010, I think it was.

00:33:55.220 --> 00:33:59.750
I think it was 2000-- maybe
it's the end of 2009, 2009.

00:33:59.750 --> 00:34:02.950
And your then-CEO, Eric
Schmidt, picked up the phone

00:34:02.950 --> 00:34:05.750
and called us, and described
to us what had happened.

00:34:05.750 --> 00:34:08.190
Google was one of 35
large enterprises,

00:34:08.190 --> 00:34:10.199
like Raytheon,
Boeing, and others,

00:34:10.199 --> 00:34:13.429
that had been significantly
cyber attacked by the Chinese.

00:34:13.429 --> 00:34:14.969
And so what was
interesting to me

00:34:14.969 --> 00:34:18.332
is, these companies were large
and well established companies,

00:34:18.332 --> 00:34:20.290
that, after being cyber
attacked, what they did

00:34:20.290 --> 00:34:22.581
is they picked up the phone
and they called Washington.

00:34:24.870 --> 00:34:29.100
But I imagine, what if it
was, instead of Eric Schmidt,

00:34:29.100 --> 00:34:35.290
CEO of Google, what if
it was a 28 year-old who

00:34:35.290 --> 00:34:37.810
had absolutely no interest
in what Washington

00:34:37.810 --> 00:34:39.350
thought about any of this.

00:34:39.350 --> 00:34:41.590
And after being
attacked, and after,

00:34:41.590 --> 00:34:43.639
say, identifying the
point of attack coming

00:34:43.639 --> 00:34:47.670
from unit 63198 of the People's
Liberation Army of China,

00:34:47.670 --> 00:34:50.480
and you were able to identify
the very specific facilities

00:34:50.480 --> 00:34:52.510
in the [? Bhutan ?]
district of Shanghai that

00:34:52.510 --> 00:34:54.178
was the point of
origin of the attack,

00:34:54.178 --> 00:34:56.469
instead of picking up the
phone and calling Washington,

00:34:56.469 --> 00:34:59.230
what if they said,
let's take them out?

00:34:59.230 --> 00:35:01.660
And so what's really
interesting, to me,

00:35:01.660 --> 00:35:03.670
is the idea that the
conflict doesn't just

00:35:03.670 --> 00:35:05.490
have to be country to country.

00:35:05.490 --> 00:35:08.586
It could actually be
country to company,

00:35:08.586 --> 00:35:10.520
and company to country.

00:35:10.520 --> 00:35:13.850
And so Sony, for example,
after Sony was attacked,

00:35:13.850 --> 00:35:15.930
now, Sony has absolutely
no cyber chops,

00:35:15.930 --> 00:35:20.310
so they could not have fought
back against the North Koreans,

00:35:20.310 --> 00:35:21.860
but what if they did?

00:35:21.860 --> 00:35:25.107
And what if, instead
of after having

00:35:25.107 --> 00:35:27.190
been hacked, what if they
had said, you know what?

00:35:27.190 --> 00:35:30.260
We're now going to go after them
to the maximum extent possible?

00:35:30.260 --> 00:35:33.430
So I also think
that companies play

00:35:33.430 --> 00:35:36.260
an increasingly consequential
role in all this [INAUDIBLE].

00:35:36.260 --> 00:35:38.426
JARED COHEN: And of course,
not every private sector

00:35:38.426 --> 00:35:39.490
is the same.

00:35:39.490 --> 00:35:41.930
In this country, you have the
private sector as distinct

00:35:41.930 --> 00:35:43.570
from the public sector.

00:35:43.570 --> 00:35:45.510
In some countries, it's
an arm of the state.

00:35:45.510 --> 00:35:47.750
In other countries, it's
a mixture of the two

00:35:47.750 --> 00:35:49.470
and more complex.

00:35:49.470 --> 00:35:52.179
Last question before we open it
up, and we'll be brief on this,

00:35:52.179 --> 00:35:53.720
but I think it's
relevant to everyone

00:35:53.720 --> 00:35:56.260
here-- as somebody who's
worked at the highest

00:35:56.260 --> 00:35:58.920
level in the public
sector, who's

00:35:58.920 --> 00:36:01.430
studied all the industries
that are going to fundamentally

00:36:01.430 --> 00:36:04.600
alter our world, you look
out at the audience here,

00:36:04.600 --> 00:36:07.190
and you have the most
brilliant minds, in my opinion,

00:36:07.190 --> 00:36:09.844
in the entire world,
people that are actually

00:36:09.844 --> 00:36:11.260
building the things
that are going

00:36:11.260 --> 00:36:15.950
to shape our future,
president, and going forward,

00:36:15.950 --> 00:36:19.470
there's also an activist spirit
that we have at this company.

00:36:19.470 --> 00:36:22.690
So what is the role of a
Google employee, for instance,

00:36:22.690 --> 00:36:23.790
going forward?

00:36:23.790 --> 00:36:27.140
How should we all, beyond
the day jobs that we have,

00:36:27.140 --> 00:36:29.230
how should we be thinking
about our contributions

00:36:29.230 --> 00:36:31.200
to the industries of the future?

00:36:31.200 --> 00:36:32.741
ALEC ROSS: That's
really interesting.

00:36:32.741 --> 00:36:34.480
That's a really
interesting question.

00:36:34.480 --> 00:36:37.505
I'd say first, I'm really glad
that Google is doing things

00:36:37.505 --> 00:36:41.920
like actually establishing
a company called Jigsaw,

00:36:41.920 --> 00:36:43.410
and to actually be
able to organize

00:36:43.410 --> 00:36:45.040
its activities in this space.

00:36:45.040 --> 00:36:47.750
So I think that's and
a great first step

00:36:47.750 --> 00:36:50.067
that many companies
are not taking,

00:36:50.067 --> 00:36:52.650
in part, because they don't have
the capabilities that you do.

00:36:55.260 --> 00:36:56.870
I would say two other things.

00:36:56.870 --> 00:37:00.480
I would say, first of
all, don't rule out

00:37:00.480 --> 00:37:03.770
the possibility of going to work
in government at some point.

00:37:03.770 --> 00:37:06.670
Government, there are
aspects of government

00:37:06.670 --> 00:37:08.510
that would infuriate
you, but you

00:37:08.510 --> 00:37:12.560
get to work on incredibly
consequential stuff.

00:37:12.560 --> 00:37:16.150
And there are certain
things that you simply

00:37:16.150 --> 00:37:19.320
can't do as Google employees.

00:37:19.320 --> 00:37:24.550
You cannot wipe out GPS in Syria
to prevent surgical political

00:37:24.550 --> 00:37:27.059
assassinations because of the
collaboration between Syriatel

00:37:27.059 --> 00:37:28.600
and the Syrian
intelligence services.

00:37:28.600 --> 00:37:30.550
JARED COHEN: Maybe
[INAUDIBLE] can.

00:37:30.550 --> 00:37:34.050
ALEC ROSS: Well, but if he
did, he'd be breaking the law.

00:37:34.050 --> 00:37:35.730
Actually, in our country.

00:37:35.730 --> 00:37:39.940
So I would actually
encourage you all

00:37:39.940 --> 00:37:41.460
to think about public service.

00:37:41.460 --> 00:37:43.920
For those of you that are happy
with your lives at Google,

00:37:43.920 --> 00:37:46.210
and I think, certainly
just walking around here,

00:37:46.210 --> 00:37:49.660
you ought to be, the other
thing that I would say

00:37:49.660 --> 00:37:54.740
is, think about,
with your 20% time,

00:37:54.740 --> 00:37:59.250
as well as with your
life outside of work,

00:37:59.250 --> 00:38:02.620
how you can take the
skills that you have

00:38:02.620 --> 00:38:08.030
and put it to work on
those public policy issues

00:38:08.030 --> 00:38:09.040
that you care.

00:38:09.040 --> 00:38:13.680
There's a huge amount of
asymmetry between civil society

00:38:13.680 --> 00:38:17.050
and, say, this room full
of employees at Google.

00:38:17.050 --> 00:38:19.630
Civil society,
non-profits, for example,

00:38:19.630 --> 00:38:23.660
thirsts for the kind
of skills that you have

00:38:23.660 --> 00:38:26.490
that they simply can't hire.

00:38:26.490 --> 00:38:29.990
So to the extent that you can
use whatever time you have here

00:38:29.990 --> 00:38:35.430
as well as outside of work
to meaningfully contribute

00:38:35.430 --> 00:38:37.970
to public policy issues,
I think you're going

00:38:37.970 --> 00:38:40.475
to find it quite rewarding.

00:38:40.475 --> 00:38:42.100
JARED COHEN: Let's
take some questions.

00:38:42.100 --> 00:38:44.180
Just wave your hand.

00:38:44.180 --> 00:38:46.420
There's microphones here.

00:38:46.420 --> 00:38:48.290
You can test your
vocal chops and scream

00:38:48.290 --> 00:38:49.850
or you can go up
to the microphone.

00:38:49.850 --> 00:38:51.060
I think you're supposed to
go to the microphone because

00:38:51.060 --> 00:38:52.300
of the video.

00:38:52.300 --> 00:38:53.260
I see you nodding.

00:38:53.260 --> 00:38:55.650
And just introduce
yourself as well.

00:38:55.650 --> 00:38:57.139
AUDIENCE: Hi, my name's--

00:38:57.139 --> 00:38:58.180
JARED COHEN: You're good.

00:38:58.180 --> 00:38:59.390
AUDIENCE: Oh, you can hear?

00:38:59.390 --> 00:39:01.223
ALEC ROSS: You need to
to turn on the thing.

00:39:01.223 --> 00:39:02.741
AUDIENCE: OK.

00:39:02.741 --> 00:39:03.240
Hi.

00:39:03.240 --> 00:39:05.290
My name is Donny Greenberg.

00:39:05.290 --> 00:39:06.920
I'm new here.

00:39:06.920 --> 00:39:08.480
I'm just wondering.

00:39:08.480 --> 00:39:11.389
I think that a lot of what
you're talking about in terms

00:39:11.389 --> 00:39:13.930
of, like, the last 50 years is
a story of global homogeneity,

00:39:13.930 --> 00:39:19.120
just rights and norms becoming
more homogeneous as barriers

00:39:19.120 --> 00:39:21.220
break down, people
have exposure to ideals

00:39:21.220 --> 00:39:23.130
that they might not
have heard before.

00:39:23.130 --> 00:39:24.505
And then you talk
about genomics,

00:39:24.505 --> 00:39:26.030
and you talk about
how countries are

00:39:26.030 --> 00:39:28.540
going to have very different
perspectives on what's allowed.

00:39:28.540 --> 00:39:30.290
Do you think that going
forward, the story

00:39:30.290 --> 00:39:32.685
becomes more heterogeneous
as people build up walls

00:39:32.685 --> 00:39:35.420
to support their positions with
respect to what's OK ethically?

00:39:35.420 --> 00:39:37.930
Or do you think it
becomes more homogeneous

00:39:37.930 --> 00:39:43.120
as the barrier, the force of the
people pushes down those walls?

00:39:43.120 --> 00:39:44.050
Thank you.

00:39:44.050 --> 00:39:45.530
ALEC ROSS: So I think that
there are two things that

00:39:45.530 --> 00:39:46.363
are going to happen.

00:39:46.363 --> 00:39:48.460
Let's go back to
Papua New Guinea.

00:39:48.460 --> 00:39:52.430
So I think that as a frontier
economies are brought

00:39:52.430 --> 00:39:56.370
into the economic mainstream,
and in the global markets, what

00:39:56.370 --> 00:40:00.510
we will see is a process of
homogenization, which is not

00:40:00.510 --> 00:40:02.460
to say that Papua New
Guinea is suddenly

00:40:02.460 --> 00:40:04.070
going to look like South Korea.

00:40:04.070 --> 00:40:05.310
It's not.

00:40:05.310 --> 00:40:07.220
But what you are going
to see is it is going

00:40:07.220 --> 00:40:11.290
to tilt toward homogeneity.

00:40:11.290 --> 00:40:14.874
The question about
heterogeneity is really, for me,

00:40:14.874 --> 00:40:15.790
one about competition.

00:40:19.950 --> 00:40:22.370
Is it going to be a
Chinese set of norms,

00:40:22.370 --> 00:40:25.740
an American set of norms,
a European set of norms,

00:40:25.740 --> 00:40:28.010
something else?

00:40:28.010 --> 00:40:33.980
And so here, I think that we're
going to see more fragmentation

00:40:33.980 --> 00:40:39.120
, but I don't know that I
would call it walling off.

00:40:39.120 --> 00:40:42.470
I'd rather see it as
competition, and largely

00:40:42.470 --> 00:40:48.490
a competition for wealth, and
geopolitical and geoeconomic

00:40:48.490 --> 00:40:49.090
dominance.

00:40:49.090 --> 00:40:51.710
So when a state or
society is making

00:40:51.710 --> 00:40:54.270
a choice about the
degree to which it's

00:40:54.270 --> 00:40:57.620
going to be open or closed,
permissive or restrictive,

00:40:57.620 --> 00:40:59.820
or other such things,
at the end of the day,

00:40:59.820 --> 00:41:02.990
they're trying to maximize for
one of two things- geopolitical

00:41:02.990 --> 00:41:05.390
power or geoeconomic power.

00:41:05.390 --> 00:41:09.015
And how that makes it
distinct, or heterogeneous

00:41:09.015 --> 00:41:11.890
to use your word,
or looking more

00:41:11.890 --> 00:41:15.050
like what exists across
the ocean, homogeneous,

00:41:15.050 --> 00:41:17.930
I think will be
also of a question

00:41:17.930 --> 00:41:21.025
on the part of the
entrepreneurial models, which

00:41:21.025 --> 00:41:23.760
are not necessarily
going to in the state.

00:41:23.760 --> 00:41:26.590
So there's a chapter in the
book called the geography

00:41:26.590 --> 00:41:27.850
of future markets.

00:41:27.850 --> 00:41:30.040
And one of the
things that I posit

00:41:30.040 --> 00:41:36.280
is that as much of the trillions
of dollars of wealth creation

00:41:36.280 --> 00:41:39.240
that have taken place in the
last 25 years with the internet

00:41:39.240 --> 00:41:42.680
has flowed through
a 30 mile long,

00:41:42.680 --> 00:41:47.540
15 mile wide area of California
called Silicon Valley.

00:41:47.540 --> 00:41:50.240
I think that Silicon Valley
will remain strong, maybe even

00:41:50.240 --> 00:41:53.110
strongest, in the next
wave of innovation,

00:41:53.110 --> 00:41:55.160
but what I do posit is
that there will probably

00:41:55.160 --> 00:41:58.680
be between 12 and 15
global foci, through 12

00:41:58.680 --> 00:42:02.090
to 15 other places
around the world, which

00:42:02.090 --> 00:42:05.490
will be significant centers of
innovation and wealth creation.

00:42:05.490 --> 00:42:08.410
But where they are will be-- I
think it will be interesting.

00:42:08.410 --> 00:42:10.450
They won't
necessarily be defined

00:42:10.450 --> 00:42:12.850
by the national character.

00:42:12.850 --> 00:42:14.860
It will be certainly
be influenced by it,

00:42:14.860 --> 00:42:18.620
but we think about cities
like Dubai, or Cape Town,

00:42:18.620 --> 00:42:22.520
or Shanghai, or Seoul,
or Sao Paulo, certainly

00:42:22.520 --> 00:42:24.460
their products are part
of the nation state,

00:42:24.460 --> 00:42:25.940
but they're also
something fairly

00:42:25.940 --> 00:42:28.060
distinct unto themselves.

00:42:28.060 --> 00:42:32.570
And in my own travels, what
I've come to understand

00:42:32.570 --> 00:42:35.740
is that I'm much more likely
to see one of my peers

00:42:35.740 --> 00:42:38.170
in any one of
those cities than I

00:42:38.170 --> 00:42:42.120
am to see them in my native
West Virginia or something

00:42:42.120 --> 00:42:42.950
like that.

00:42:42.950 --> 00:42:47.110
And so I do think that as much
as the character of the nation

00:42:47.110 --> 00:42:50.660
state will inform
how things look,

00:42:50.660 --> 00:42:54.440
I also think that there is
an entrepreneurial class that

00:42:54.440 --> 00:42:56.770
moves around the
globe, that congregates

00:42:56.770 --> 00:42:59.760
in certain kinds of places
and will create businesses

00:42:59.760 --> 00:43:02.580
there, that doesn't
necessarily comport entirely

00:43:02.580 --> 00:43:04.103
with the national character.

00:43:04.103 --> 00:43:05.311
JARED COHEN: Other questions?

00:43:09.920 --> 00:43:11.410
[INAUDIBLE] much.

00:43:11.410 --> 00:43:12.570
AUDIENCE: Hello.

00:43:12.570 --> 00:43:13.640
I'm Dan.

00:43:13.640 --> 00:43:16.870
So you've spoken very
compellingly about winners,

00:43:16.870 --> 00:43:20.945
industries that are emerging,
but in the spirit of President

00:43:20.945 --> 00:43:23.820
Trump, can you talk a
little bit about losers?

00:43:23.820 --> 00:43:25.643
[LAUGHTER]

00:43:26.810 --> 00:43:29.370
What are the issues of
the past that we may not

00:43:29.370 --> 00:43:32.672
expect to diminish?

00:43:32.672 --> 00:43:34.380
AUDIENCE: We almost
made it the full hour

00:43:34.380 --> 00:43:36.057
without talking
about Donald Trump.

00:43:36.057 --> 00:43:37.750
[LAUGHTER]

00:43:38.250 --> 00:43:41.930
ALEC ROSS: Vulgar,
demented Donald Trump.

00:43:41.930 --> 00:43:45.450
We're all in trouble if
he becomes president.

00:43:45.450 --> 00:43:49.970
So when I think about winners
and losers, the binary I think

00:43:49.970 --> 00:43:52.620
of, I think the principal
political and economic binary

00:43:52.620 --> 00:43:55.940
of the 20th century
was left versus right.

00:43:55.940 --> 00:43:58.580
I think the dominant
political and economic binary

00:43:58.580 --> 00:44:03.020
of the 21st century
is open versus closed.

00:44:03.020 --> 00:44:05.570
And by open, what do I mean?

00:44:05.570 --> 00:44:12.170
I mean is upward social and
economic mobility confined

00:44:12.170 --> 00:44:13.280
to elites?

00:44:13.280 --> 00:44:15.930
Or can public school
kids from West Virginia

00:44:15.930 --> 00:44:17.440
make their way upward?

00:44:17.440 --> 00:44:23.470
Are our cultural and religious
norms dictated from on high?

00:44:23.470 --> 00:44:27.490
Or is it a rights
respecting country?

00:44:27.490 --> 00:44:30.360
Religious, ethnic,
sexual minorities,

00:44:30.360 --> 00:44:34.010
are women fully
empowered in the economy?

00:44:34.010 --> 00:44:36.730
And recognizing that there
are no perfectly open

00:44:36.730 --> 00:44:38.890
or closed societies,
the closest to either

00:44:38.890 --> 00:44:44.370
might be North Korea being
closest to a closed society,

00:44:44.370 --> 00:44:47.220
I think that that which
is going to most determine

00:44:47.220 --> 00:44:49.570
who the winners are
and who the losers are,

00:44:49.570 --> 00:44:52.604
is that I think that the
most open societies will

00:44:52.604 --> 00:44:54.770
be those that are most
competitive in the industries

00:44:54.770 --> 00:44:55.950
of the future.

00:44:55.950 --> 00:44:57.840
Because going back
to my previous point

00:44:57.840 --> 00:45:00.910
about the class of
entrepreneurs and innovators,

00:45:00.910 --> 00:45:04.250
I see them increasingly want
to congregate and create

00:45:04.250 --> 00:45:08.396
businesses and live and work
in the most open societies

00:45:08.396 --> 00:45:10.220
possible.

00:45:10.220 --> 00:45:13.840
I also think that these are
the places where capital flows

00:45:13.840 --> 00:45:18.630
the most freely, where somebody
who dropped out of college

00:45:18.630 --> 00:45:22.050
can get a significant seed
round and take their idea

00:45:22.050 --> 00:45:24.000
and try to create a
product out of it.

00:45:24.000 --> 00:45:27.910
I think it is the kind of place
where crazy ideas, and usually

00:45:27.910 --> 00:45:32.130
a big business starts with a
crazy idea, where a crazy idea

00:45:32.130 --> 00:45:34.830
actually gets a good chance.

00:45:34.830 --> 00:45:38.630
So not thinking so
much about industries

00:45:38.630 --> 00:45:41.540
that will be the quote
unquote losers of the future,

00:45:41.540 --> 00:45:44.320
but when I think
about the places,

00:45:44.320 --> 00:45:49.710
it will be those places that are
most closed, much more so than

00:45:49.710 --> 00:45:52.727
during the last wave of
globalization, where the quote

00:45:52.727 --> 00:45:55.340
unquote losers were
largely determined

00:45:55.340 --> 00:46:00.160
by one of two factors-- what
are your relative labor costs,

00:46:00.160 --> 00:46:04.570
and to what degree did you
adapt your economy from being

00:46:04.570 --> 00:46:07.290
industrial to knowledge-based.

00:46:07.290 --> 00:46:09.380
JARED COHEN: Other questions?

00:46:09.380 --> 00:46:10.880
While we're waiting,
I have another.

00:46:10.880 --> 00:46:11.290
Do you have one?

00:46:11.290 --> 00:46:11.994
AUDIENCE: Yeah.

00:46:11.994 --> 00:46:12.660
JARED COHEN: OK.

00:46:12.660 --> 00:46:15.899
And don't forget to
introduce yourself.

00:46:15.899 --> 00:46:16.440
AUDIENCE: Hi.

00:46:16.440 --> 00:46:18.240
My name's Yura.

00:46:18.240 --> 00:46:22.370
And I'm very interested in what
you mentioned about robotics.

00:46:22.370 --> 00:46:24.020
So I'm wondering
what you exactly

00:46:24.020 --> 00:46:27.830
see in Japan about the
home care robotics,

00:46:27.830 --> 00:46:31.410
and what is actually the
customer reaction to it?

00:46:31.410 --> 00:46:35.010
And also, what do you think
about industrial robotics?

00:46:35.010 --> 00:46:37.680
And do you see a
difference between the US

00:46:37.680 --> 00:46:39.430
and these things that's
actually happening

00:46:39.430 --> 00:46:42.790
in Japan our Asian countries?

00:46:42.790 --> 00:46:45.020
ALEC ROSS: So let me
back up a little bit

00:46:45.020 --> 00:46:48.450
and say that, I think that
the robots of the cartoon

00:46:48.450 --> 00:46:50.060
and movies of the
1970s are going

00:46:50.060 --> 00:46:52.807
to be the reality of the 2020s.

00:46:52.807 --> 00:46:55.390
And I think that's largely going
to be because of two things--

00:46:55.390 --> 00:46:57.590
first of all,
mapping belief space.

00:46:57.590 --> 00:46:59.310
You know, the
mathematical breakthroughs

00:46:59.310 --> 00:47:01.890
that have allowed us
to take historically

00:47:01.890 --> 00:47:05.000
difficulty robotic
tasks like grasping

00:47:05.000 --> 00:47:08.400
and make them more
programmable, and taking robots

00:47:08.400 --> 00:47:11.450
from being dominantly two
dimensional beings to three

00:47:11.450 --> 00:47:15.580
dimensional beings,
that and cloud robotics.

00:47:15.580 --> 00:47:18.730
This is fundamentally changing
the economics of robotics.

00:47:18.730 --> 00:47:21.220
So let's think about one
of the movies of the 1970s.

00:47:21.220 --> 00:47:23.215
Let's think about--

00:47:23.215 --> 00:47:25.375
AUDIENCE: Was anyone
here alive in the 1970s?

00:47:25.375 --> 00:47:26.460
ALEC ROSS: Yeah, right?

00:47:26.460 --> 00:47:28.935
they watched the movies
from the 1970s, Jared.

00:47:28.935 --> 00:47:30.805
So let's think about C3PO.

00:47:30.805 --> 00:47:35.390
If C3PO walked in here right
now and interrupted us,

00:47:35.390 --> 00:47:38.560
he would say, oh dear, oh my!

00:47:38.560 --> 00:47:42.880
And go find, choo-choo-choo,
an open seat right now.

00:47:42.880 --> 00:47:44.410
And so what would be happening?

00:47:44.410 --> 00:47:45.826
So what would be
happening, if you

00:47:45.826 --> 00:47:51.194
think about the cognition
necessary for C3PO to recognize

00:47:51.194 --> 00:47:52.610
that he had
interrupted a lecture?

00:47:56.860 --> 00:48:00.430
Speaking, excusing himself,
the sensory ability

00:48:00.430 --> 00:48:03.240
to identify an open
seat, and the mobility

00:48:03.240 --> 00:48:04.740
to then be able to take a seat.

00:48:04.740 --> 00:48:07.040
As a practical matter,
we know that he amount

00:48:07.040 --> 00:48:09.660
of hardware and
software whirring

00:48:09.660 --> 00:48:14.850
in that gold-plated body
would be consequential, right?

00:48:14.850 --> 00:48:19.970
With cloud robotics, C3PO will
be a cloud-connected device.

00:48:19.970 --> 00:48:23.380
So as he walks in and interrupts
us, he'll ping the cloud.

00:48:23.380 --> 00:48:26.830
And the impact of this is one,
principally, of economics.

00:48:26.830 --> 00:48:30.150
So I'm sure you're all
familiar with Foxconn.

00:48:30.150 --> 00:48:33.390
Terry Gou, the CEO of Foxconn
explained the economics

00:48:33.390 --> 00:48:34.840
of robotics to me.

00:48:34.840 --> 00:48:43.180
He said humans are
little capex, a opex.

00:48:43.180 --> 00:48:47.500
And robots are all
capex, no opex.

00:48:47.500 --> 00:48:50.090
When you hire a human
being, maybe you

00:48:50.090 --> 00:48:53.950
get a phone, or a computer,
business cards, not very much.

00:48:53.950 --> 00:48:56.290
But every two weeks,
you want to get paid.

00:48:56.290 --> 00:48:59.860
So very little upfront
cost, lots of opex.

00:48:59.860 --> 00:49:03.430
By contrast, with robots
you have to buy the robot.

00:49:03.430 --> 00:49:04.960
You have to buy the
expensive robot.

00:49:04.960 --> 00:49:08.560
But once you do, you can
work him for 24 hours.

00:49:08.560 --> 00:49:10.070
You don't have to
pay him a salary.

00:49:10.070 --> 00:49:11.640
He's not going to get sick.

00:49:11.640 --> 00:49:13.100
He's not going to unionize.

00:49:13.100 --> 00:49:14.440
And so very little opex.

00:49:14.440 --> 00:49:17.370
And so what's interesting
with cloud robots

00:49:17.370 --> 00:49:19.440
is we're seeing new
equilibrium points

00:49:19.440 --> 00:49:24.310
in the tradeoff between whether
it's worth hiring a human

00:49:24.310 --> 00:49:25.300
or buying a robot.

00:49:25.300 --> 00:49:29.180
And to your question
about the home care robots

00:49:29.180 --> 00:49:33.150
in Japan, what we're seeing,
because of these two things,

00:49:33.150 --> 00:49:36.460
mapping belief space
and cloud robotics,

00:49:36.460 --> 00:49:39.490
we're seeing robots being
able to act in a whole nother

00:49:39.490 --> 00:49:43.140
level of sophistication that was
largely unimaginable just three

00:49:43.140 --> 00:49:44.430
years ago.

00:49:44.430 --> 00:49:48.860
And so this has facilitated
their entry into the home.

00:49:48.860 --> 00:49:50.670
And even though
it's not being done

00:49:50.670 --> 00:49:55.010
on a very significant scale yet,
it's largely being accepted.

00:49:55.010 --> 00:49:57.110
And I think it's largely
being accepted, in part,

00:49:57.110 --> 00:50:02.180
because those who are actually
allowing for elder care robots

00:50:02.180 --> 00:50:05.640
to be brought into their home
are doing so voluntarily.

00:50:05.640 --> 00:50:06.219
Right?

00:50:06.219 --> 00:50:07.510
It's not being imposed on them.

00:50:07.510 --> 00:50:10.230
They're the early adopters.

00:50:10.230 --> 00:50:14.370
And also, because, again,
going back to cultural norms.

00:50:14.370 --> 00:50:18.460
There isn't the cultural
headwind that says,

00:50:18.460 --> 00:50:21.657
you really shouldn't let your
grandmother be picked up out

00:50:21.657 --> 00:50:24.340
of bed by a robot.

00:50:24.340 --> 00:50:27.880
On to the question of how this
relates to industrial robots,

00:50:27.880 --> 00:50:30.280
here too, it's
really interesting.

00:50:30.280 --> 00:50:33.140
Out of the 196 countries
on planet Earth,

00:50:33.140 --> 00:50:34.700
there are basically
only five that

00:50:34.700 --> 00:50:38.770
matter in robot production, both
consumer and industrial robot

00:50:38.770 --> 00:50:44.010
production-- the United
States, Germany, Japan,

00:50:44.010 --> 00:50:45.610
South Korea, and China.

00:50:45.610 --> 00:50:48.020
Those five countries are
the only ones that matter.

00:50:48.020 --> 00:50:50.810
South Korea, a country
of 50 million people,

00:50:50.810 --> 00:50:55.260
produces more industrial robots
then the 3 billion people that

00:50:55.260 --> 00:50:59.370
live in India, Russia,
Africa, South America,

00:50:59.370 --> 00:51:02.550
Central America combined.

00:51:02.550 --> 00:51:06.563
What's interesting with
industrial robotics

00:51:06.563 --> 00:51:12.440
is the move here is it's taking
robotic labor and automation

00:51:12.440 --> 00:51:17.230
from doing work that is merely
manual and routine to cognitive

00:51:17.230 --> 00:51:18.660
and non-routine.

00:51:18.660 --> 00:51:21.510
So if you think about it, the
industrial robots of the past,

00:51:21.510 --> 00:51:23.660
it largely displaced
the work of men

00:51:23.660 --> 00:51:27.020
with big, strong shoulders
working in ports, factories,

00:51:27.020 --> 00:51:28.250
mills, and mines.

00:51:28.250 --> 00:51:33.270
Move object A to object
B. An industrial robot who

00:51:33.270 --> 00:51:36.060
can move bigger projects,
do it more reliably,

00:51:36.060 --> 00:51:38.830
and with less liability.

00:51:38.830 --> 00:51:42.220
So what's interesting
now is, again,

00:51:42.220 --> 00:51:46.330
because of AI, with
industrial robots being

00:51:46.330 --> 00:51:48.960
able to view things
with more cognition,

00:51:48.960 --> 00:51:52.850
and being able to do tasks
that are non-routine,

00:51:52.850 --> 00:51:55.280
we're seeing new forms
of labor displacement,

00:51:55.280 --> 00:51:58.500
and we're seeing new kinds
of industrial processes

00:51:58.500 --> 00:52:00.310
that I think are
really interesting.

00:52:00.310 --> 00:52:05.230
And the vast majority of it
is coming from South Korea

00:52:05.230 --> 00:52:06.292
and Japan right now.

00:52:06.292 --> 00:52:07.500
JARED COHEN: Other questions?

00:52:14.509 --> 00:52:15.050
AUDIENCE: Hi.

00:52:15.050 --> 00:52:16.260
I'm Andrew.

00:52:16.260 --> 00:52:19.660
You mentioned labor
displacement there at the end.

00:52:19.660 --> 00:52:25.100
And you talk about these
dystopian and utopian futures,

00:52:25.100 --> 00:52:26.890
and you also mentioned
that you don't

00:52:26.890 --> 00:52:30.470
look more than 20 years ahead,
or else it just gets silly.

00:52:30.470 --> 00:52:33.940
Do we see a basic income being
required in the next 20 years?

00:52:33.940 --> 00:52:36.400
Or is that still too
silly to consider?

00:52:36.400 --> 00:52:40.020
ALEC ROSS: No, I don't think
it's too silly to consider.

00:52:40.020 --> 00:52:43.240
What's interesting
is I'm now asked

00:52:43.240 --> 00:52:46.000
about a universal basic income
in pretty much every book

00:52:46.000 --> 00:52:48.150
talk I do.

00:52:48.150 --> 00:52:50.460
But this is a product
of the last six months.

00:52:50.460 --> 00:52:52.170
If I had done this
six months ago,

00:52:52.170 --> 00:52:53.920
I might have gotten
one question about it.

00:52:53.920 --> 00:52:55.295
So this is something
that I think

00:52:55.295 --> 00:52:58.440
there is an increasing public
recognition around this issue

00:52:58.440 --> 00:53:00.482
of labor displacement.

00:53:00.482 --> 00:53:02.190
Well, first of all,
we ought to recognize

00:53:02.190 --> 00:53:04.580
that lots of countries
are already doing this.

00:53:04.580 --> 00:53:05.940
Lots of places.

00:53:05.940 --> 00:53:08.320
We know the example of
Scandinavian countries,

00:53:08.320 --> 00:53:11.240
but I think that there will
be other places, especially

00:53:11.240 --> 00:53:14.300
with high per capita
GDPs, which can basically

00:53:14.300 --> 00:53:18.240
create welfare systems
without it being

00:53:18.240 --> 00:53:20.220
too big a drag on the economy.

00:53:20.220 --> 00:53:21.940
The problem in
the United States,

00:53:21.940 --> 00:53:25.140
why I don't see it happening
over the next 10 years,

00:53:25.140 --> 00:53:28.130
is because a universal
basic income would be

00:53:28.130 --> 00:53:31.740
a massive entitlement program.

00:53:31.740 --> 00:53:35.670
and as long as we are running
the kinds of budget deficits

00:53:35.670 --> 00:53:38.700
that we are, it's not realistic.

00:53:38.700 --> 00:53:41.070
We would have to
fundamentally change programs

00:53:41.070 --> 00:53:44.170
like Medicare, Medicaid,
or our defense spending,

00:53:44.170 --> 00:53:47.589
to be able to afford a UBI,
a universal basic income.

00:53:47.589 --> 00:53:50.130
The other thing that makes me
think that the United States is

00:53:50.130 --> 00:53:52.430
going to be ready for
it in the next 10 years

00:53:52.430 --> 00:53:56.340
is because if you look at the
last entitlement program that

00:53:56.340 --> 00:53:59.750
was just expanded,
Obamacare, I mean,

00:53:59.750 --> 00:54:02.900
you would have thought we
burned the country down,

00:54:02.900 --> 00:54:05.030
the kind of reaction
that it got.

00:54:05.030 --> 00:54:07.890
And the establishment of
a universal basic income

00:54:07.890 --> 00:54:09.800
would be far bigger
than Obamacare.

00:54:13.239 --> 00:54:14.780
The last thing that
I think, presents

00:54:14.780 --> 00:54:17.980
a real headwind for the
idea of the establishment

00:54:17.980 --> 00:54:20.880
of a universal basic
income in the United States

00:54:20.880 --> 00:54:25.480
is we tend to be a more
individualist society

00:54:25.480 --> 00:54:27.540
than a collectivist society.

00:54:27.540 --> 00:54:31.680
So the collectivist societies
are dominantly European

00:54:31.680 --> 00:54:35.540
and have set up UBIs, have
a very different character

00:54:35.540 --> 00:54:40.190
than most of America, which
is fiercely individualistic.

00:54:40.190 --> 00:54:42.930
And I think that,
interestingly, a lot

00:54:42.930 --> 00:54:45.550
of the opposition for a
universal basic income

00:54:45.550 --> 00:54:47.800
would actually come from
the segments of society that

00:54:47.800 --> 00:54:50.140
actually might be
its beneficiary.

00:54:50.140 --> 00:54:53.115
So in my native West
Virginia, nobody

00:54:53.115 --> 00:54:57.020
is more vulnerable
to be permanently

00:54:57.020 --> 00:54:59.890
outside of the economic
mainstream than working class

00:54:59.890 --> 00:55:01.480
West Virginians.

00:55:01.480 --> 00:55:04.980
Yet they will vote against
their economic interests

00:55:04.980 --> 00:55:09.670
because the perception will
be that somebody else will

00:55:09.670 --> 00:55:12.641
be taking advantage,
that it will be unfair.

00:55:12.641 --> 00:55:14.455
And these are the
people who are going

00:55:14.455 --> 00:55:16.329
to be voting against
their economic interests

00:55:16.329 --> 00:55:18.421
when they vote for Donald Trump.

00:55:18.421 --> 00:55:20.670
JARED COHEN: Let me take the
liberty, as the moderator

00:55:20.670 --> 00:55:24.600
to ask one final question
before we wrap up, which is,

00:55:24.600 --> 00:55:27.180
there's a lot I want to ask you
about, from cryptocurrencies

00:55:27.180 --> 00:55:28.800
to urbanization, and so forth.

00:55:28.800 --> 00:55:31.120
But I want to ask you a
question about the one topic

00:55:31.120 --> 00:55:33.661
that is heavily
pronounced in your book

00:55:33.661 --> 00:55:35.160
that we haven't
discussed yet, which

00:55:35.160 --> 00:55:36.780
is the last chapter,
which is called

00:55:36.780 --> 00:55:39.170
"the most important
job you'll ever have,

00:55:39.170 --> 00:55:43.960
the future of parenting."

00:55:43.960 --> 00:55:45.555
I said at the
beginning that what

00:55:45.555 --> 00:55:49.180
makes this book so interesting
is the methodology that Alec

00:55:49.180 --> 00:55:50.810
used to write it.

00:55:50.810 --> 00:55:55.090
And he literally traveled
around, asking generals,

00:55:55.090 --> 00:55:56.970
and admirals, and
presidents of countries,

00:55:56.970 --> 00:55:59.710
and dissidents, and
people from this country

00:55:59.710 --> 00:56:02.340
and that country,
geneticists, et cetera,

00:56:02.340 --> 00:56:04.420
all the same question
about what makes

00:56:04.420 --> 00:56:06.050
a good parent in the future.

00:56:06.050 --> 00:56:07.570
What types of issues
and challenges

00:56:07.570 --> 00:56:10.290
will a parent have to
contend with in the future?

00:56:10.290 --> 00:56:14.570
So what does parenting
look like in the future?

00:56:14.570 --> 00:56:19.420
And what it is the wackiest
most complex thing that we'll

00:56:19.420 --> 00:56:21.160
have to deal with as a parent?

00:56:21.160 --> 00:56:23.360
ALEC ROSS: So first
of all, I don't

00:56:23.360 --> 00:56:25.810
pretend to be a parenting
guru in the book.

00:56:25.810 --> 00:56:28.135
My children would be
the first point out

00:56:28.135 --> 00:56:30.920
I should be pretending
to be a parenting guru.

00:56:30.920 --> 00:56:36.480
But what I did do is, everybody
who's really impressive, whom

00:56:36.480 --> 00:56:38.790
I interviewed for the book
on their domain expertise,

00:56:38.790 --> 00:56:41.570
I put these questions
about parenting to them.

00:56:41.570 --> 00:56:44.650
And there were a couple of
interesting points of consensus

00:56:44.650 --> 00:56:46.080
that emerged.

00:56:46.080 --> 00:56:49.160
The first is the importance of
inter-disciplinary learning.

00:56:49.160 --> 00:56:52.090
So people always say STEM, STEM,
STEM, STEM, STEM, STEM, STEM.

00:56:52.090 --> 00:56:54.720
And yes, science, technology,
engineering, and mathematics

00:56:54.720 --> 00:56:56.040
are very important.

00:56:56.040 --> 00:56:58.590
But the indication that
I got is that the people

00:56:58.590 --> 00:57:00.750
who will not just be
employed in the future,

00:57:00.750 --> 00:57:04.360
but who will actually
be leaders in the future

00:57:04.360 --> 00:57:07.690
will be those who are
able to combine levels

00:57:07.690 --> 00:57:11.330
of scientific or
technological literacy

00:57:11.330 --> 00:57:13.850
with aptitudes that
we think of as being

00:57:13.850 --> 00:57:17.710
in the humanities, like
behavioral psychology,

00:57:17.710 --> 00:57:20.860
economics, communications,
and other such things.

00:57:20.860 --> 00:57:25.830
So being able to break down
the silos between, say computer

00:57:25.830 --> 00:57:28.220
science and political
science, the people

00:57:28.220 --> 00:57:29.970
who really break
down those barriers,

00:57:29.970 --> 00:57:35.180
as you've done in
your career, Jared,

00:57:35.180 --> 00:57:39.320
are really going to be
important leaders of the future.

00:57:39.320 --> 00:57:43.200
The second thing that I would
say, the anti for tomorrow

00:57:43.200 --> 00:57:47.320
is in many respects, I
think, going to be languages.

00:57:47.320 --> 00:57:49.726
Computer languages
and foreign languages.

00:57:49.726 --> 00:57:51.350
Absent our having
the device in our ear

00:57:51.350 --> 00:57:54.840
that understands everything
that everybody is telling us,

00:57:54.840 --> 00:57:57.580
I do think that getting
good old fashioned ink

00:57:57.580 --> 00:58:01.430
stamps in your passport is
going to be increasingly

00:58:01.430 --> 00:58:06.830
necessary if you're going to be
a leader in tomorrow's economy.

00:58:06.830 --> 00:58:10.730
As our economy grows more
interconnected, people

00:58:10.730 --> 00:58:14.554
who are willing and able to move
around to frontier economies

00:58:14.554 --> 00:58:16.470
and be a part of the
growth of, say, Papua New

00:58:16.470 --> 00:58:18.805
Guinea in the same way
in which people were

00:58:18.805 --> 00:58:22.560
a part of the growth of
China beginning 15 years ago,

00:58:22.560 --> 00:58:26.450
that's really where a lot of
the great fortunes will be made.

00:58:26.450 --> 00:58:28.830
What are they the
craziest challenges?

00:58:28.830 --> 00:58:32.700
I think a lot of
it goes to privacy.

00:58:32.700 --> 00:58:35.560
I am one of those people who
believes that privacy as we

00:58:35.560 --> 00:58:40.100
traditionally know it is
gone and not coming back.

00:58:40.100 --> 00:58:44.670
Today, March of 2016, we live
in a world of about 16 billion

00:58:44.670 --> 00:58:46.510
internet-connected devices.

00:58:46.510 --> 00:58:49.420
By 2020, that's going
to be 40 billion.

00:58:49.420 --> 00:58:53.380
And so in a world of 40 billion
internet-connected devices,

00:58:53.380 --> 00:58:58.900
which will probably be creating
about 20 zetabytes of data

00:58:58.900 --> 00:59:03.340
every year, the kind
of transparency,

00:59:03.340 --> 00:59:06.210
not from surveillance so
much as from sousveillance,

00:59:06.210 --> 00:59:11.190
I think is going to create a
digital profile for everybody.

00:59:11.190 --> 00:59:14.290
And I think that the real norm
shifting is that everybody's

00:59:14.290 --> 00:59:16.760
going to have a scandal.

00:59:16.760 --> 00:59:21.320
And I think that in a world
where all of our lives

00:59:21.320 --> 00:59:23.950
are consistently
documented, I think

00:59:23.950 --> 00:59:26.540
that the norms that are
going to shift, I think

00:59:26.540 --> 00:59:30.690
is we're going to increasingly
accept human fallibility.

00:59:30.690 --> 00:59:36.220
The kinds of things
that JFK did,

00:59:36.220 --> 00:59:40.180
we know, today would
never remain private,

00:59:40.180 --> 00:59:42.070
would never remain secret.

00:59:42.070 --> 00:59:46.940
But as more of our lives
become less secret,

00:59:46.940 --> 00:59:49.435
instead of our
summarily condemning

00:59:49.435 --> 00:59:51.143
more and more people,
I think we're going

00:59:51.143 --> 00:59:52.990
grow more and more accepting.

00:59:52.990 --> 00:59:56.020
I think about a corrupt use of
the presidency, for example.

00:59:56.020 --> 01:00:00.220
In 1992, it was a legitimate
political issue did.

01:00:00.220 --> 01:00:02.770
Bill Clinton inhale?

01:00:02.770 --> 01:00:05.780
Did he take a drag on a joint?

01:00:05.780 --> 01:00:07.350
And this was a question.

01:00:07.350 --> 01:00:10.790
If he inhaled, is he
fit to be president?

01:00:10.790 --> 01:00:14.710
Fast forward 16 years, Barack
Obama's running for president.

01:00:14.710 --> 01:00:16.530
He's like, oh, I inhaled.

01:00:16.530 --> 01:00:18.830
I inhaled a lot, and I liked it.

01:00:18.830 --> 01:00:21.480
And oh, by the way, I did coke.

01:00:21.480 --> 01:00:22.830
Non-issue.

01:00:22.830 --> 01:00:24.440
Think about homosexuality.

01:00:24.440 --> 01:00:27.020
I mean, when I was in college
20 something years ago,

01:00:27.020 --> 01:00:29.620
homosexuality was
still this thing

01:00:29.620 --> 01:00:34.650
that was considered aberrant
and almost scandalous.

01:00:34.650 --> 01:00:37.130
There's the gay guy.

01:00:37.130 --> 01:00:39.350
Whereas on university
campuses today,

01:00:39.350 --> 01:00:42.210
we accept that there's a
fairly significant percentage

01:00:42.210 --> 01:00:44.850
of everybody who's going
to be homosexual, right?

01:00:44.850 --> 01:00:45.830
What happened?

01:00:45.830 --> 01:00:47.230
Norms shifted.

01:00:47.230 --> 01:00:49.350
And so I really think
that the big change is

01:00:49.350 --> 01:00:52.470
going to be, like for
example with my kids, 9, 11,

01:00:52.470 --> 01:00:58.000
and 13 years-old, as they grow
older in a world with so much

01:00:58.000 --> 01:01:02.720
more transparency and so
much digital documentation,

01:01:02.720 --> 01:01:05.980
I think that there's going to
be less privacy of the type

01:01:05.980 --> 01:01:07.490
that we now know it.

01:01:07.490 --> 01:01:10.690
And as a result of that, we are
going to increasingly accept

01:01:10.690 --> 01:01:11.440
human fallibility.

01:01:11.440 --> 01:01:13.815
JARED COHEN: Well, Alec, you've
written a brilliant book.

01:01:13.815 --> 01:01:16.632
I'm almost impressed that Papua
New Guinea got three shoutouts

01:01:16.632 --> 01:01:17.590
in the span of an hour.

01:01:17.590 --> 01:01:22.321
That's more than probably they
ever get throughout history.

01:01:22.321 --> 01:01:23.320
This book's exceptional.

01:01:25.980 --> 01:01:29.060
And even more than the
ambition of the project,

01:01:29.060 --> 01:01:30.690
and the breadth
of the interviews,

01:01:30.690 --> 01:01:34.440
and the places that you
went to write this book,

01:01:34.440 --> 01:01:39.350
is your masterful translation
of very complex topics

01:01:39.350 --> 01:01:43.210
to audiences that will find
it interesting from the most

01:01:43.210 --> 01:01:44.990
technical to the
least technical.

01:01:44.990 --> 01:01:46.916
You've written a really
truly accessible book

01:01:46.916 --> 01:01:47.790
and a brilliant book.

01:01:47.790 --> 01:01:49.800
It's called "Industries
of the Future."

01:01:49.800 --> 01:01:51.040
You all have free copies.

01:01:51.040 --> 01:01:52.650
Go buy some for your friends.

01:01:52.650 --> 01:01:54.030
Alec Ross, thank you very much.

01:01:54.030 --> 01:01:54.905
ALEC ROSS: Thank you.

01:01:54.905 --> 01:01:57.380
[APPLAUSE]

