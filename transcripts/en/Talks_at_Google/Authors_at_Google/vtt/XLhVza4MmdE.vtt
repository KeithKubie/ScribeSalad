WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.860
[MUSIC PLAYING]

00:00:05.860 --> 00:00:07.670
BRIAN WELLE: Hello, everybody.

00:00:07.670 --> 00:00:09.320
Thank you so much
for coming today.

00:00:09.320 --> 00:00:10.770
My name is Brian Welle.

00:00:10.770 --> 00:00:13.300
I'm in People Operations, and
one of the teams that I lead

00:00:13.300 --> 00:00:14.770
is the People
Innovation Lab, where

00:00:14.770 --> 00:00:16.780
we happen to know
that social science is

00:00:16.780 --> 00:00:18.410
the coolest thing ever.

00:00:18.410 --> 00:00:23.740
So it is my sincere pleasure to
welcome Dolly Chugh to Google

00:00:23.740 --> 00:00:26.440
to talk about a fantastic
book that she just

00:00:26.440 --> 00:00:29.710
wrote called, "How Good
People Fight Bias, The Person

00:00:29.710 --> 00:00:31.210
You Mean to Be."

00:00:31.210 --> 00:00:33.190
Dolly is a social psychologist.

00:00:33.190 --> 00:00:36.040
She's a Professor of
Management at NYU,

00:00:36.040 --> 00:00:40.270
and she is writing about things
that so many of us at Google

00:00:40.270 --> 00:00:43.650
care desperately
about and articulates

00:00:43.650 --> 00:00:45.850
a journey that I feel like
we, as an organization,

00:00:45.850 --> 00:00:46.510
are on today.

00:00:46.510 --> 00:00:48.840
So it is such a pleasure
to have you here today.

00:00:48.840 --> 00:00:50.180
DOLLY CHUGH: It is such
an honor to be here.

00:00:50.180 --> 00:00:51.980
Thank you so much ,
everybody, for coming,

00:00:51.980 --> 00:00:53.650
especially after a long weekend.

00:00:53.650 --> 00:00:56.109
BRIAN WELLE: Well, I have to
start by confessing something.

00:00:56.109 --> 00:00:57.983
DOLLY CHUGH: Uh-oh, this
is going to be good.

00:00:57.983 --> 00:00:59.730
BRIAN WELLE: I have
been known to say

00:00:59.730 --> 00:01:03.050
after reviewing all of the
unconscious bias literature,

00:01:03.050 --> 00:01:05.131
helping to put together
trainings and workshops,

00:01:05.131 --> 00:01:07.630
and talking to Googlers about
it, at the end of all of this,

00:01:07.630 --> 00:01:10.360
I often say, social
scientists have

00:01:10.360 --> 00:01:13.240
been great at demonstrating
that we have a problem.

00:01:13.240 --> 00:01:16.180
But they have been terrible
at telling us how to fix it,

00:01:16.180 --> 00:01:18.760
and I thought that was true
until I read your book.

00:01:18.760 --> 00:01:23.080
And you have done
such a wonderful job

00:01:23.080 --> 00:01:25.870
at piecing together
narrative across lots

00:01:25.870 --> 00:01:28.870
of different studies and taking
the results of those studies

00:01:28.870 --> 00:01:31.990
and translating them into
practical advice for those

00:01:31.990 --> 00:01:33.439
of us who want to be better.

00:01:33.439 --> 00:01:34.730
DOLLY CHUGH: I appreciate that.

00:01:34.730 --> 00:01:36.440
Thank you, Brian.

00:01:36.440 --> 00:01:38.890
I think part of my
motivation to write this book

00:01:38.890 --> 00:01:43.150
was that I'm as confused
as everyone else in trying

00:01:43.150 --> 00:01:47.500
to navigate the confusing
space of trying to be as

00:01:47.500 --> 00:01:49.510
good a person as I want to be.

00:01:49.510 --> 00:01:51.010
And it occurred to
me that there is

00:01:51.010 --> 00:01:54.640
some stuff in these dusty,
academic journals that no one

00:01:54.640 --> 00:01:56.800
reads, that could be helpful.

00:01:56.800 --> 00:01:58.990
And my goal was, a lot of
the research isn't mine,

00:01:58.990 --> 00:02:00.930
but I thought I could
curate it, throw mine

00:02:00.930 --> 00:02:03.880
in, add some fantastic
stories and interviews,

00:02:03.880 --> 00:02:04.930
and bring it to life.

00:02:04.930 --> 00:02:07.030
BRIAN WELLE: Well, you
definitely didn't do that.

00:02:07.030 --> 00:02:07.988
DOLLY CHUGH: Thank you.

00:02:07.988 --> 00:02:10.500
BRIAN WELLE: So I have
so many questions.

00:02:10.500 --> 00:02:13.810
We had the chance to have
lunch before and poor Dolly,

00:02:13.810 --> 00:02:15.660
she's like, I need to
go to the restroom.

00:02:15.660 --> 00:02:17.076
We didn't see her
for a long time,

00:02:17.076 --> 00:02:17.400
and I think she was just--

00:02:17.400 --> 00:02:19.210
DOLLY CHUGH: Just for a
minute-- just brush my hair.

00:02:19.210 --> 00:02:21.126
BRIAN WELLE: Getting a
rest from my questions.

00:02:21.126 --> 00:02:25.360
So here are some that I
thought our audience would

00:02:25.360 --> 00:02:27.310
like to hear the answers to.

00:02:27.310 --> 00:02:31.480
And by the way, we'll have
a Q&amp;A for about 40 minutes,

00:02:31.480 --> 00:02:35.090
and then we will open up the
mics to your questions as well.

00:02:35.090 --> 00:02:38.680
So first, I want to
start with something

00:02:38.680 --> 00:02:41.380
that is so central to your
book, that if you don't

00:02:41.380 --> 00:02:43.135
get this concept
and agree with it,

00:02:43.135 --> 00:02:45.010
you shouldn't even read
the rest of the book.

00:02:45.010 --> 00:02:46.400
DOLLY CHUGH: That's not a
good sales pitch at all.

00:02:46.400 --> 00:02:47.980
It's a terrible
sales pitch, Brian.

00:02:47.980 --> 00:02:49.813
BRIAN WELLE: Hopefully,
we can all be there.

00:02:49.813 --> 00:02:51.400
But I thought we
had to start there,

00:02:51.400 --> 00:02:55.267
and that is with the concept
of bounded ethicality.

00:02:55.267 --> 00:02:57.100
I'm going to quote
something from your book.

00:02:57.100 --> 00:03:01.330
"Bounded ethicality is the
psychology of good-ish people.

00:03:01.330 --> 00:03:04.810
Good-ish people are sometimes
good and sometimes not,

00:03:04.810 --> 00:03:08.710
sometimes intentionally and
sometimes not, like all of us.

00:03:08.710 --> 00:03:11.170
This model of bounded
ethicality challenges

00:03:11.170 --> 00:03:13.540
ways of thinking and
talking, in which

00:03:13.540 --> 00:03:17.020
you are either a good person
or not, a racist or not,

00:03:17.020 --> 00:03:18.760
an unethical human or not.

00:03:18.760 --> 00:03:22.330
We argue that this binary notion
is seductive, but misleading

00:03:22.330 --> 00:03:24.560
and scientifically inaccurate."

00:03:24.560 --> 00:03:27.220
So this seems obvious when it's
spelled out this way, at least

00:03:27.220 --> 00:03:28.130
to me.

00:03:28.130 --> 00:03:30.290
But what does it
mean to internalize

00:03:30.290 --> 00:03:31.970
bounded ethicality
for ourselves,

00:03:31.970 --> 00:03:33.690
and why is it so hard to do so?

00:03:33.690 --> 00:03:36.510
DOLLY CHUGH: Thank you so much.

00:03:36.510 --> 00:03:39.340
So we've got a
really tight corner

00:03:39.340 --> 00:03:45.930
that we put ourselves in when we
think about who we want to be.

00:03:45.930 --> 00:03:49.830
Research shows that on a
1 to 7 scale, most of us

00:03:49.830 --> 00:03:51.930
put the importance of
thinking of ourselves

00:03:51.930 --> 00:03:54.510
as a good person above a 6.

00:03:54.510 --> 00:03:57.120
It's really important to us,
not like Mother Theresa good,

00:03:57.120 --> 00:03:59.100
but just having
an identity where

00:03:59.100 --> 00:04:02.130
we think of ourselves
as the kind of person

00:04:02.130 --> 00:04:04.729
that we would call
a good person.

00:04:04.729 --> 00:04:07.020
Your definition and your
definition and your definition

00:04:07.020 --> 00:04:08.950
may be different of
what a good person is.

00:04:08.950 --> 00:04:10.740
But whatever your
own definition is,

00:04:10.740 --> 00:04:13.470
that is something that
most of us hold dear to us,

00:04:13.470 --> 00:04:15.760
and we feel really
threatened when

00:04:15.760 --> 00:04:18.120
there's anything that
suggests we're not

00:04:18.120 --> 00:04:21.120
hitting that good person
bar, some minimum threshold

00:04:21.120 --> 00:04:24.420
of being a good person.

00:04:24.420 --> 00:04:25.500
I know I feel that way.

00:04:25.500 --> 00:04:30.780
I got an email from
a student telling me

00:04:30.780 --> 00:04:34.530
that I had assigned a
sexist reading to class,

00:04:34.530 --> 00:04:35.850
and it was a female student.

00:04:35.850 --> 00:04:38.510
And I consider
myself a feminist.

00:04:38.510 --> 00:04:40.070
I have two daughters.

00:04:40.070 --> 00:04:42.840
I am trying hard to
raise them as feminists.

00:04:42.840 --> 00:04:46.230
And to get an email like
this feels very threatening.

00:04:46.230 --> 00:04:48.210
I'm like, this is,
oh my god, you've

00:04:48.210 --> 00:04:50.840
totally threatened
my good person bar,

00:04:50.840 --> 00:04:53.130
my good person identity.

00:04:53.130 --> 00:04:55.320
But the truth is, when
I reread the reading,

00:04:55.320 --> 00:04:59.010
I was like, ooh, that
is a little like, wow.

00:04:59.010 --> 00:05:01.650
What is the whole thing about,
like women just love to shop.

00:05:01.650 --> 00:05:04.710
There was some stuff in that
article that really should have

00:05:04.710 --> 00:05:07.650
caught my eye, but I
had my own blind spots,

00:05:07.650 --> 00:05:09.420
that it just went right by me.

00:05:09.420 --> 00:05:12.660
And the problem is,
as a good person,

00:05:12.660 --> 00:05:15.320
if I have to be in a super
tight corner, where there

00:05:15.320 --> 00:05:19.150
is no room for blind spots
and no room for mistakes,

00:05:19.150 --> 00:05:20.710
I will not grow
from that mistake.

00:05:20.710 --> 00:05:23.050
I will dismiss that
email from that student.

00:05:23.050 --> 00:05:25.470
I will not learn from what
she has helped me see.

00:05:25.470 --> 00:05:27.120
I will keep assigning
that reading,

00:05:27.120 --> 00:05:30.540
because I won't see the
value in her critique.

00:05:30.540 --> 00:05:34.980
And as a result, my
desire to be a good person

00:05:34.980 --> 00:05:38.940
is going to hold me back
from being a better person.

00:05:38.940 --> 00:05:41.090
Our research on
bounded ethicality--

00:05:41.090 --> 00:05:43.740
and when I say our
research, I mean our field,

00:05:43.740 --> 00:05:47.460
like psychologists for
the last 40 years--

00:05:47.460 --> 00:05:50.100
have shown in so
many different ways

00:05:50.100 --> 00:05:52.950
that we do have blind spots,
that we do have lapses,

00:05:52.950 --> 00:05:54.930
that we do make mistakes.

00:05:54.930 --> 00:05:58.380
And we do have unconscious bias.

00:05:58.380 --> 00:06:00.540
We are prone to conflicts
of interest outside

00:06:00.540 --> 00:06:02.040
of our awareness.

00:06:02.040 --> 00:06:04.860
In every one of those
examples, the question

00:06:04.860 --> 00:06:08.100
is, for me, are we just
going to deny that,

00:06:08.100 --> 00:06:10.090
or are we going to grow from it?

00:06:10.090 --> 00:06:13.170
And so what I'm proposing
is, given that the research

00:06:13.170 --> 00:06:17.640
on bounded ethicality is clear,
let's break out of that corner,

00:06:17.640 --> 00:06:20.550
that super tight, either/or--
either I'm a good person

00:06:20.550 --> 00:06:21.900
or I'm not corner--

00:06:21.900 --> 00:06:24.270
and give ourselves room to grow.

00:06:24.270 --> 00:06:26.370
And what that means is
setting a higher standard.

00:06:26.370 --> 00:06:29.220
Being a good-ish person,
instead of a good person,

00:06:29.220 --> 00:06:32.280
is someone who doesn't
necessarily make more mistakes,

00:06:32.280 --> 00:06:34.110
but they do acknowledge
more mistakes.

00:06:34.110 --> 00:06:36.950
They do own more
mistakes, and they

00:06:36.950 --> 00:06:39.180
do learn from more
mistakes than someone

00:06:39.180 --> 00:06:41.730
who simply is in that
tight good person corner.

00:06:41.730 --> 00:06:44.810
BRIAN WELLE: Now, when I read
that portion of your book,

00:06:44.810 --> 00:06:48.210
it called to mind
all the ways that we

00:06:48.210 --> 00:06:50.940
reinforce the binary in how
we talk about other people.

00:06:50.940 --> 00:06:54.030
We will talk about
people as evil,

00:06:54.030 --> 00:06:57.150
or this person is
such a great person,

00:06:57.150 --> 00:06:58.530
or this person is a criminal.

00:06:58.530 --> 00:07:01.137
It's almost like we've created
the boundaries already,

00:07:01.137 --> 00:07:02.220
and then you exist within.

00:07:02.220 --> 00:07:05.386
And it doesn't lend itself
to a growth mindset,

00:07:05.386 --> 00:07:06.510
which you talk a lot about.

00:07:06.510 --> 00:07:07.385
DOLLY CHUGH: Exactly.

00:07:07.385 --> 00:07:10.010
And that growth mindset is
that work in progress mindset,

00:07:10.010 --> 00:07:14.400
as everyone here is familiar,
that we're not either/or good,

00:07:14.400 --> 00:07:16.530
we are always getting
better, no matter where

00:07:16.530 --> 00:07:17.540
our starting point is.

00:07:17.540 --> 00:07:19.440
And one of the things
that I learned the most

00:07:19.440 --> 00:07:22.800
from in writing the
book was the people

00:07:22.800 --> 00:07:25.620
I interviewed-- some
of whom are icons,

00:07:25.620 --> 00:07:30.450
like Joe McNeil of the
Greensboro Four, 1960

00:07:30.450 --> 00:07:32.520
Woolworth's lunch
counter sit-ins,

00:07:32.520 --> 00:07:36.390
led the sit-in movement, someone
who is truly a civil rights

00:07:36.390 --> 00:07:40.380
giant speaking candidly about
his efforts to have a growth

00:07:40.380 --> 00:07:42.290
mindset about gay rights.

00:07:42.290 --> 00:07:46.200
A really moving story to me
that says, this either/or

00:07:46.200 --> 00:07:47.700
binary is going to hold us back.

00:07:47.700 --> 00:07:51.536
We have to find the
work in progress inside.

00:07:51.536 --> 00:07:53.820
BRIAN WELLE: You use
concepts in your books

00:07:53.820 --> 00:07:56.341
that were like seeing
old friends to me,

00:07:56.341 --> 00:07:58.590
because they're concepts
that are very important to us

00:07:58.590 --> 00:08:02.090
at Google and ones that we have
been doing our own research on

00:08:02.090 --> 00:08:04.110
and have found to be
internally important.

00:08:04.110 --> 00:08:06.820
So growth mindset
versus a fixed mindset,

00:08:06.820 --> 00:08:12.000
which is this notion that
we all have things to learn.

00:08:12.000 --> 00:08:13.260
We can all grow.

00:08:13.260 --> 00:08:14.179
We can get better.

00:08:14.179 --> 00:08:15.720
We should be
incorporating feedback--

00:08:15.720 --> 00:08:18.090
is so important to how we
try to engage with our work

00:08:18.090 --> 00:08:19.530
and with each other.

00:08:19.530 --> 00:08:22.300
There is another concept
of psychological safety,

00:08:22.300 --> 00:08:24.900
and that is creating
environments

00:08:24.900 --> 00:08:27.460
where it's safe to express
yourself, to admit mistakes,

00:08:27.460 --> 00:08:28.570
and to learn.

00:08:28.570 --> 00:08:30.540
We have done our own
research on teamwork,

00:08:30.540 --> 00:08:32.789
and we found psychological
safety is the number one

00:08:32.789 --> 00:08:36.870
predictor of whether teams are
successful in their endeavors.

00:08:36.870 --> 00:08:39.900
What I loved about your
book is that you actually

00:08:39.900 --> 00:08:42.690
showed a pathway
from growth mindset

00:08:42.690 --> 00:08:46.440
to psychological safety,
to fighting bias.

00:08:46.440 --> 00:08:48.307
Can you talk about
those connections?

00:08:48.307 --> 00:08:49.200
DOLLY CHUGH: Sure.

00:08:49.200 --> 00:08:51.210
And this is where I
took the liberties

00:08:51.210 --> 00:08:54.750
that you can't take within
science, where in science, we

00:08:54.750 --> 00:08:58.050
would have all been
in a very narrow silo.

00:08:58.050 --> 00:08:59.631
Carol Dweck is a psychologist.

00:08:59.631 --> 00:09:02.130
Her and her colleagues have
done the work on growth mindset.

00:09:02.130 --> 00:09:05.370
Amy Edmondson is the
organizational behavior scholar

00:09:05.370 --> 00:09:06.690
with psychological safety.

00:09:06.690 --> 00:09:08.730
Unconscious bias,
Mahzarin Banaji.

00:09:08.730 --> 00:09:11.190
And they're each doing
really deep, deep work

00:09:11.190 --> 00:09:14.160
in those areas, along with
their labs and colleagues.

00:09:14.160 --> 00:09:17.190
But what that means is
that connecting those

00:09:17.190 --> 00:09:19.380
doesn't happen within science.

00:09:19.380 --> 00:09:23.350
Those things sit separately
within our journals.

00:09:23.350 --> 00:09:25.740
And so what I tried
to do is step outside

00:09:25.740 --> 00:09:27.390
of the science a little bit.

00:09:27.390 --> 00:09:29.160
I say in the
beginning of the book,

00:09:29.160 --> 00:09:30.750
I'm going to step
outside the science,

00:09:30.750 --> 00:09:33.900
because I feel like
we don't have time

00:09:33.900 --> 00:09:36.660
to wait 50 years
before somebody is

00:09:36.660 --> 00:09:38.670
going to actually
run the studies that

00:09:38.670 --> 00:09:40.170
connect all those things.

00:09:40.170 --> 00:09:43.590
I think we can use our common
sense to see the connections.

00:09:43.590 --> 00:09:45.450
Growth mindset on
an individual level,

00:09:45.450 --> 00:09:48.270
seeing yourself as a work in
progress, seeing someone--

00:09:48.270 --> 00:09:51.517
seeing yourself as someone
who can grow from mistakes,

00:09:51.517 --> 00:09:53.850
rather than when you hit an
obstacle and make a mistake,

00:09:53.850 --> 00:09:56.756
you shut down, you
cheat, you quit.

00:09:56.756 --> 00:09:58.380
That's what happens
in a fixed mindset.

00:09:58.380 --> 00:10:02.550
Well, psychological safety is
the same concept in a team.

00:10:02.550 --> 00:10:04.470
Do we shut down as a team?

00:10:04.470 --> 00:10:06.220
Do we not talk about mistakes?

00:10:06.220 --> 00:10:08.280
Do we not verbalize
vulnerability?

00:10:08.280 --> 00:10:10.470
Or do we create a
space where we can

00:10:10.470 --> 00:10:12.960
talk about, I think
I messed that up, I

00:10:12.960 --> 00:10:15.450
think I dropped the ball,
I'm really scared about

00:10:15.450 --> 00:10:16.920
what's coming next.

00:10:16.920 --> 00:10:21.280
That's growth mindset
to me on a team level.

00:10:21.280 --> 00:10:25.800
And I think that then
sets the stage for topics

00:10:25.800 --> 00:10:27.150
like unconscious bias.

00:10:30.887 --> 00:10:32.970
I think we've gotten to
the point where we believe

00:10:32.970 --> 00:10:35.670
the science on unconscious
bias, but it's still

00:10:35.670 --> 00:10:37.830
tough to believe that
it might sometimes

00:10:37.830 --> 00:10:42.600
leak into our behavior, that
we might sometimes enact harm.

00:10:42.600 --> 00:10:46.207
And so that's where that
psychological safety

00:10:46.207 --> 00:10:47.790
in a team where you
can talk about it,

00:10:47.790 --> 00:10:50.220
growth mindset within
the individual,

00:10:50.220 --> 00:10:53.080
sets us up to do the
work on unconscious bias.

00:10:53.080 --> 00:10:56.340
The thing that makes me
saddest about the way

00:10:56.340 --> 00:10:59.580
the public dialogue has
moved on unconscious bias

00:10:59.580 --> 00:11:03.660
is that we sometimes
seem to be saying, well,

00:11:03.660 --> 00:11:08.130
because it's unconscious,
I'm no longer accountable.

00:11:08.130 --> 00:11:11.040
That's like saying
because I was drunk,

00:11:11.040 --> 00:11:14.580
I'm not accountable
for the harm I did

00:11:14.580 --> 00:11:16.320
when I was behind the wheel.

00:11:16.320 --> 00:11:18.720
Absolutely, you are
still accountable.

00:11:18.720 --> 00:11:20.940
The question is,
how are we going

00:11:20.940 --> 00:11:23.280
to take ownership and
learn from it, especially

00:11:23.280 --> 00:11:25.650
when, as scientists, we have
not cracked the code on how

00:11:25.650 --> 00:11:27.090
to debias our brains yet?

00:11:27.090 --> 00:11:29.580
So in the meantime,
we're going to have

00:11:29.580 --> 00:11:31.800
to use the growth mindset
and psychological safety

00:11:31.800 --> 00:11:32.955
as our tools.

00:11:32.955 --> 00:11:34.580
BRIAN WELLE: That is
definitely a theme

00:11:34.580 --> 00:11:37.030
I saw throughout the
book, which is noticing.

00:11:37.030 --> 00:11:40.620
The first step is just
noticing and being aware.

00:11:40.620 --> 00:11:43.320
DOLLY CHUGH: Exactly,
being a first class noticer

00:11:43.320 --> 00:11:44.890
is a big part of it.

00:11:44.890 --> 00:11:46.740
And then starting
to think about,

00:11:46.740 --> 00:11:48.600
if we can't debias
the brain, how can we

00:11:48.600 --> 00:11:52.400
debias the process, the team,
the system, the structures?

00:11:52.400 --> 00:11:55.740
BRIAN WELLE: A story you were
telling me earlier just stuck

00:11:55.740 --> 00:11:59.370
with me about being
willing to not

00:11:59.370 --> 00:12:03.300
just notice, but to
acknowledge when each of us

00:12:03.300 --> 00:12:07.200
has had a stereotype thought
or expressed unconscious bias,

00:12:07.200 --> 00:12:09.000
and we made it conscious.

00:12:09.000 --> 00:12:12.324
And it had to do with your
work in prisons and people

00:12:12.324 --> 00:12:13.240
who were incarcerated.

00:12:13.240 --> 00:12:14.850
Can you talk a
little bit about what

00:12:14.850 --> 00:12:16.380
you're doing with
prison population,

00:12:16.380 --> 00:12:19.290
and how you felt when you first
went into that environment,

00:12:19.290 --> 00:12:21.030
and how that affected you?

00:12:21.030 --> 00:12:24.330
DOLLY CHUGH: So I've had this
really wonderful opportunity

00:12:24.330 --> 00:12:28.000
to get involved with the NYU
Prison Education Program.

00:12:28.000 --> 00:12:31.740
And during the year, I
spent working on this book,

00:12:31.740 --> 00:12:33.600
I had two priorities.

00:12:33.600 --> 00:12:36.570
I took a sabbatical to work with
the Prison Education Program

00:12:36.570 --> 00:12:37.740
and to write the book.

00:12:37.740 --> 00:12:41.040
And what that meant is, I was
teaching a four college credit

00:12:41.040 --> 00:12:43.170
course, really
similar to the one

00:12:43.170 --> 00:12:46.860
I teach MBA students at Stern
on leadership, management,

00:12:46.860 --> 00:12:48.690
and negotiation skills.

00:12:48.690 --> 00:12:52.830
And I was going to do it in
a prison in upstate New York.

00:12:52.830 --> 00:12:58.380
And what I realize
now when I look back,

00:12:58.380 --> 00:13:01.290
is that one of the traps
I describe in the book--

00:13:01.290 --> 00:13:05.130
that I was probably writing that
chapter while I was actually

00:13:05.130 --> 00:13:07.050
displaying the behavior--

00:13:07.050 --> 00:13:09.360
was, I talk about
the savior trap,

00:13:09.360 --> 00:13:13.290
about having this vision of
yourself as being a do-gooder,

00:13:13.290 --> 00:13:17.610
who's going to save the day and
have that feel-good feeling,

00:13:17.610 --> 00:13:20.580
that warm glow that comes
from saving someone else.

00:13:20.580 --> 00:13:24.750
And I can now see how
that was motivating me

00:13:24.750 --> 00:13:27.910
into wanting to do the
teaching in prison.

00:13:27.910 --> 00:13:29.880
But the problem
with the savior trap

00:13:29.880 --> 00:13:33.510
is that it's still
puts me above,

00:13:33.510 --> 00:13:37.230
and it otherizes the
people I'm engaging with.

00:13:37.230 --> 00:13:39.510
And I saw that in the
first couple of classes

00:13:39.510 --> 00:13:44.580
when I was teaching, that I was
super scared of my students,

00:13:44.580 --> 00:13:51.120
and I definitely was not
viewing them as individuals.

00:13:51.120 --> 00:13:52.980
But within a couple
of classes, it

00:13:52.980 --> 00:13:57.110
was weirdly normal
to teach in a prison.

00:13:57.110 --> 00:13:58.684
My students were
just-- and I know

00:13:58.684 --> 00:14:00.850
there's some alums in the
room-- but they would just

00:14:00.850 --> 00:14:03.310
like you guys.

00:14:03.310 --> 00:14:06.175
They were funny, and they were
quiet, and they were serious.

00:14:06.175 --> 00:14:08.550
And they were more prepared,
and they were less prepared.

00:14:08.550 --> 00:14:11.650
They had a whole range
of personalities,

00:14:11.650 --> 00:14:15.640
and they were just
individuals who

00:14:15.640 --> 00:14:19.010
were super motivated to learn.

00:14:19.010 --> 00:14:23.380
Now, do I know that
some of them did things

00:14:23.380 --> 00:14:26.440
that created real
harm for people, that

00:14:26.440 --> 00:14:27.850
led to them being in prison?

00:14:27.850 --> 00:14:29.290
Some of them did.

00:14:29.290 --> 00:14:33.130
There is all sorts of injustices
in the system as well.

00:14:33.130 --> 00:14:34.600
And is that confusing to me?

00:14:34.600 --> 00:14:36.550
And does it create
all sorts of like,

00:14:36.550 --> 00:14:39.010
oh my god, the long drives
home from the prison

00:14:39.010 --> 00:14:45.440
were real confusing,
mental times for me?

00:14:45.440 --> 00:14:47.590
But what I realized
by the third class was

00:14:47.590 --> 00:14:49.530
I had dehumanized my students.

00:14:49.530 --> 00:14:52.300
I came in thinking, I'm going
to teach a group of felons.

00:14:52.300 --> 00:14:53.770
I'm going to redeem them.

00:14:53.770 --> 00:14:58.136
And that, in and of itself,
created this savior mentality,

00:14:58.136 --> 00:15:00.010
where I was never going
to be useful to them,

00:15:00.010 --> 00:15:02.690
because I wasn't seeing
them as human beings.

00:15:02.690 --> 00:15:07.360
And so it clicked into
place by class three,

00:15:07.360 --> 00:15:11.110
that I had a bunch of
just individuals that I

00:15:11.110 --> 00:15:12.890
was going to interact with.

00:15:12.890 --> 00:15:15.880
And one of them had read
106 books the year before

00:15:15.880 --> 00:15:17.530
and showed me the
list of his books.

00:15:17.530 --> 00:15:19.270
And the other one
cried when we role

00:15:19.270 --> 00:15:21.700
played difficult
conversations, because he

00:15:21.700 --> 00:15:23.080
was thinking about his son.

00:15:23.080 --> 00:15:24.400
And they were people.

00:15:24.400 --> 00:15:27.100
And now, about
3/4 of my students

00:15:27.100 --> 00:15:28.460
have been released from prison.

00:15:28.460 --> 00:15:32.580
And when I encounter them and
interact with them in the city

00:15:32.580 --> 00:15:36.200
and they're in normal
clothes, I truly

00:15:36.200 --> 00:15:40.070
realize that I had created this
image, this uniformed image,

00:15:40.070 --> 00:15:46.385
of an imprisoned person that
was absent of any humanity.

00:15:46.385 --> 00:15:49.280
BRIAN WELLE: Talking about
prisons in the criminal justice

00:15:49.280 --> 00:15:53.300
system, actually brings up
another aspect of your book.

00:15:53.300 --> 00:15:55.730
Now, the first
portion of your book

00:15:55.730 --> 00:15:59.480
is about taking social science
and helping us understand

00:15:59.480 --> 00:16:03.260
how each of us can notice
and change our behaviors,

00:16:03.260 --> 00:16:06.052
and to relate to people
and have a growth mindset.

00:16:06.052 --> 00:16:07.760
There's another thread
through your book,

00:16:07.760 --> 00:16:10.130
which is about systems.

00:16:10.130 --> 00:16:14.750
And so sometimes, the
biases that we encounter

00:16:14.750 --> 00:16:17.450
are a byproduct of systems
that we've created.

00:16:17.450 --> 00:16:20.110
And you talk about this in terms
of headwinds and tailwinds.

00:16:20.110 --> 00:16:23.420
I'm wondering, can you tell
me, what do those terms mean,

00:16:23.420 --> 00:16:28.170
and is there any research that
you can tell us about that

00:16:28.170 --> 00:16:29.420
demonstrates how that happens?

00:16:29.420 --> 00:16:30.169
DOLLY CHUGH: Sure.

00:16:30.169 --> 00:16:30.740
Absolutely.

00:16:30.740 --> 00:16:33.530
So I stole the metaphor
of headwinds and tailwinds

00:16:33.530 --> 00:16:35.060
from Debbie Irving.

00:16:35.060 --> 00:16:38.210
And she talks
about forces like--

00:16:38.210 --> 00:16:46.160
so imagine I'm jogging
so slowly, really slow.

00:16:46.160 --> 00:16:50.150
But if I'm jogging and I've
got a good tailwind going,

00:16:50.150 --> 00:16:54.530
I might improve my time
from it's usual 10 minute,

00:16:54.530 --> 00:16:58.010
30 second mile to a 10
minute, 15 second mile,

00:16:58.010 --> 00:17:00.200
because I've got that
tailwind pushing me along.

00:17:00.200 --> 00:17:03.650
But I don't get a sense
that I've got a tailwind.

00:17:03.650 --> 00:17:05.579
You don't even feel
tailwinds, really.

00:17:05.579 --> 00:17:07.819
You just feel like you're
rocking it that morning,

00:17:07.819 --> 00:17:09.277
and you're just
like, I don't know,

00:17:09.277 --> 00:17:13.550
it was maybe those eggs I ate.

00:17:13.550 --> 00:17:15.920
But then when you make
that run and then you

00:17:15.920 --> 00:17:20.869
do the U-turn to come back, and
now, you've got the headwind,

00:17:20.869 --> 00:17:22.880
you feel every bit of it.

00:17:22.880 --> 00:17:24.200
And it does slow you down.

00:17:24.200 --> 00:17:26.960
And your time shows it,
and your fatigue shows it,

00:17:26.960 --> 00:17:29.330
and your motivation shows it.

00:17:29.330 --> 00:17:32.150
That headwind is much
more visible to us

00:17:32.150 --> 00:17:35.690
than the tailwind, much
more feelable to us.

00:17:35.690 --> 00:17:38.660
And what a systems
approach is about

00:17:38.660 --> 00:17:40.400
is, what are the
ways in which we

00:17:40.400 --> 00:17:47.690
create very visible headwinds
and less visible tailwinds?

00:17:47.690 --> 00:17:52.084
What are the ways those are
built into how we operate?

00:17:52.084 --> 00:17:59.510
So when I sent this book
proposal off to publishers,

00:17:59.510 --> 00:18:01.910
I literally didn't have
the word system in it.

00:18:01.910 --> 00:18:05.349
I didn't have system or systemic
anywhere in the proposal.

00:18:05.349 --> 00:18:06.890
I thought this was
going to be a book

00:18:06.890 --> 00:18:11.870
purely on the individual
level about unconscious bias.

00:18:11.870 --> 00:18:14.900
And it was as I started
talking to people and looking

00:18:14.900 --> 00:18:17.570
at the research, that it
became clear to me that,

00:18:17.570 --> 00:18:21.350
even if I somehow won the
Nobel Prize and was the one who

00:18:21.350 --> 00:18:23.710
figured out how to
debias unconscious bias--

00:18:23.710 --> 00:18:28.430
say that was my claim to
fame, wave the magic wand--

00:18:28.430 --> 00:18:30.260
I still would not have
solved the problem,

00:18:30.260 --> 00:18:36.080
because our systems would still
have so much bias built in.

00:18:36.080 --> 00:18:39.620
For example, I used to work in
professional services firms,

00:18:39.620 --> 00:18:41.780
like investment
banking and consulting.

00:18:41.780 --> 00:18:44.330
And when we would
interview, a big part

00:18:44.330 --> 00:18:46.130
of the way we would
interview would be we

00:18:46.130 --> 00:18:50.140
would look for fit, cultural
fit, like is this the person

00:18:50.140 --> 00:18:54.560
we-- the classic, do you
want to go on a long plane

00:18:54.560 --> 00:18:55.672
ride sitting next to them?

00:18:55.672 --> 00:18:57.380
Would you want to be
sitting next to them

00:18:57.380 --> 00:18:59.540
on a flight to Asia?

00:18:59.540 --> 00:19:01.370
Cultural fit.

00:19:01.370 --> 00:19:03.200
And I was part of that system.

00:19:03.200 --> 00:19:05.810
I interviewed people
using those criteria.

00:19:05.810 --> 00:19:09.050
But now, when I look
back and I understand

00:19:09.050 --> 00:19:13.150
better how systems
work, I realize

00:19:13.150 --> 00:19:15.970
I created a huge
headwind for people

00:19:15.970 --> 00:19:19.930
who didn't go to the same
alma mater as me, who didn't

00:19:19.930 --> 00:19:21.340
have the same hobbies as me.

00:19:21.340 --> 00:19:23.740
Because those were
the kinds of questions

00:19:23.740 --> 00:19:25.840
that were the fit conversation.

00:19:25.840 --> 00:19:28.780
Could we banter about
common interests?

00:19:28.780 --> 00:19:31.000
In fact, Lauren
Rivera, a sociologist,

00:19:31.000 --> 00:19:32.980
did an in-depth
ethnography, where

00:19:32.980 --> 00:19:35.974
she looked at hiring
practices of elite firms.

00:19:35.974 --> 00:19:37.390
And that's exactly
what she found,

00:19:37.390 --> 00:19:39.670
was that what we
call fit, that's

00:19:39.670 --> 00:19:43.780
meant to capture performance
aspects of a job,

00:19:43.780 --> 00:19:48.550
was, in fact, capturing things
like passion hobbies and shared

00:19:48.550 --> 00:19:51.880
academic backgrounds, things
that weren't necessarily

00:19:51.880 --> 00:19:54.280
tied directly to the job.

00:19:54.280 --> 00:19:57.670
That's an example of a
headwind where there's

00:19:57.670 --> 00:19:59.170
people from a whole
bunch of schools

00:19:59.170 --> 00:20:02.650
who could do the job, who aren't
going to get a chance at it.

00:20:02.650 --> 00:20:04.870
There's people who
have varied interests,

00:20:04.870 --> 00:20:07.390
who have varied cultural
backgrounds, who have varied

00:20:07.390 --> 00:20:08.980
family backgrounds,
who aren't going

00:20:08.980 --> 00:20:12.130
to fit the mold of
the kind of banter

00:20:12.130 --> 00:20:14.020
that we would do in interviews.

00:20:14.020 --> 00:20:18.610
And people like me benefit
from that tailwind,

00:20:18.610 --> 00:20:20.290
because I did go
to those schools,

00:20:20.290 --> 00:20:22.690
and I do have those hobbies.

00:20:22.690 --> 00:20:25.660
I can talk about
marathon running.

00:20:25.660 --> 00:20:27.736
I just don't say my time.

00:20:27.736 --> 00:20:30.850
BRIAN WELLE: I thought it
was very interesting that you

00:20:30.850 --> 00:20:35.470
and your collaborator, Katie
Milkman, took these notions

00:20:35.470 --> 00:20:37.743
and applied it to your own
academic community, which,

00:20:37.743 --> 00:20:41.860
I think, many
universities, would

00:20:41.860 --> 00:20:45.910
like to believe that they are
probably the most egalitarian

00:20:45.910 --> 00:20:48.010
institutions you
can be a part of.

00:20:48.010 --> 00:20:49.980
But you did a study
that showed otherwise.

00:20:49.980 --> 00:20:51.855
DOLLY CHUGH: Katie
Milkman, who's at Wharton,

00:20:51.855 --> 00:20:55.090
and Modupe Akinola, who's
at Columbia Business

00:20:55.090 --> 00:20:57.520
School, the three of us went
to grad school together.

00:20:57.520 --> 00:20:59.560
And a really common
practice before you

00:20:59.560 --> 00:21:02.340
apply to a PhD program is--

00:21:02.340 --> 00:21:05.245
when I say really common, really
common if you're on the inside

00:21:05.245 --> 00:21:09.580
and someone tells you to do
this, so it's not so common--

00:21:09.580 --> 00:21:12.730
is to email faculty
at the PhD program

00:21:12.730 --> 00:21:15.697
you're interested in and
signal that you're interested

00:21:15.697 --> 00:21:18.280
and ask if they'd be willing to
tell you about their research.

00:21:18.280 --> 00:21:20.830
And you do all this before
you send your application in,

00:21:20.830 --> 00:21:25.000
so it's totally outside the
official formal process.

00:21:25.000 --> 00:21:27.580
And all three of
us as grad students

00:21:27.580 --> 00:21:29.860
had been advised to do that
by people in our network,

00:21:29.860 --> 00:21:30.550
and we did that.

00:21:30.550 --> 00:21:33.133
And we did get into grad school,
and we did get great mentors.

00:21:33.133 --> 00:21:35.710
And everything worked out
happily ever after for us.

00:21:35.710 --> 00:21:37.600
But we were wondering
what happens

00:21:37.600 --> 00:21:40.240
to people who aren't
as networked as us

00:21:40.240 --> 00:21:42.610
or maybe people who
do get this advice

00:21:42.610 --> 00:21:47.710
but don't quite match the
profile that unconsciously

00:21:47.710 --> 00:21:50.405
maybe faculty, despite
their egalitarian aims,

00:21:50.405 --> 00:21:51.280
might be looking for.

00:21:51.280 --> 00:21:53.690
So we did something
kind of sneaky.

00:21:53.690 --> 00:21:56.670
It was a sting operation,
which as social scientists,

00:21:56.670 --> 00:21:59.760
we call an audit study
or a field experiment.

00:21:59.760 --> 00:22:02.260
I know at Google, you are
very familiar with field

00:22:02.260 --> 00:22:02.810
experiments.

00:22:02.810 --> 00:22:05.830
So what we did was we
created email addresses

00:22:05.830 --> 00:22:07.090
using peoples' names.

00:22:07.090 --> 00:22:09.850
We pre-tested these names
to either be male-sounding

00:22:09.850 --> 00:22:13.360
or female-sounding-- please
forgive the gender binary--

00:22:13.360 --> 00:22:15.160
and then white-sounding,
black-sounding,

00:22:15.160 --> 00:22:16.780
Hispanic-sounding,
Chinese-sounding,

00:22:16.780 --> 00:22:18.190
or Indian-sounding.

00:22:18.190 --> 00:22:20.350
So those are five racial
ethnic identities,

00:22:20.350 --> 00:22:21.580
two gender identities.

00:22:21.580 --> 00:22:22.540
We crossed them.

00:22:22.540 --> 00:22:24.760
We have 10 identities now.

00:22:24.760 --> 00:22:26.740
We created multiple
names for each identity,

00:22:26.740 --> 00:22:31.450
so we don't have any particular
name effect for an identity.

00:22:31.450 --> 00:22:33.280
And then we created
an email address

00:22:33.280 --> 00:22:36.340
for every one of those
fictional students.

00:22:36.340 --> 00:22:39.040
We took the "US News and
World Report" rankings

00:22:39.040 --> 00:22:41.230
of the top 260 schools.

00:22:41.230 --> 00:22:44.620
For every PhD granting
department in those schools,

00:22:44.620 --> 00:22:47.110
we randomly picked the
name of one professor.

00:22:47.110 --> 00:22:50.549
And remember, in academia,
all our information

00:22:50.549 --> 00:22:51.340
is on the internet.

00:22:51.340 --> 00:22:53.680
We're really easy to
find, slash, stalk.

00:22:56.510 --> 00:22:58.950
So it was really
easy to do this.

00:22:58.950 --> 00:23:01.900
It was a lot of work,
but it was simple.

00:23:01.900 --> 00:23:04.000
So now, we've got our
fictional students,

00:23:04.000 --> 00:23:07.060
and we've got one professor from
every PhD granting department.

00:23:07.060 --> 00:23:10.540
And what we did was we
said, every professor

00:23:10.540 --> 00:23:13.870
received one email from
one of those identities.

00:23:13.870 --> 00:23:16.720
And our dependent variable
was, would the professor

00:23:16.720 --> 00:23:19.207
write back to a cold call
email from a stranger

00:23:19.207 --> 00:23:21.040
saying they were
interested in learning more

00:23:21.040 --> 00:23:23.144
about this PhD program.

00:23:23.144 --> 00:23:25.310
There's a little more nuance
that I'm going to skip.

00:23:25.310 --> 00:23:26.950
But if you're ever
interested, we've

00:23:26.950 --> 00:23:29.620
got some papers that
get into the details.

00:23:29.620 --> 00:23:32.920
But if I cut to
the chase, we were

00:23:32.920 --> 00:23:35.140
comparing the
white male identity

00:23:35.140 --> 00:23:40.150
to all those not-white male
identities of the students.

00:23:40.150 --> 00:23:45.790
And what we found was that, if
you were a white male student,

00:23:45.790 --> 00:23:49.180
you had about a 87% chance
of getting a response

00:23:49.180 --> 00:23:50.262
to your email.

00:23:50.262 --> 00:23:51.970
And if you were not
a white male student,

00:23:51.970 --> 00:23:56.020
you had a 62% chance of getting
a response to your email.

00:23:56.020 --> 00:24:00.250
And this is identical emails
being sent in identical time

00:24:00.250 --> 00:24:02.860
with an identical request.

00:24:02.860 --> 00:24:08.140
And so even in our world of
academia where, if anything,

00:24:08.140 --> 00:24:11.220
we're stereotyped as being--
you know how we're stereotyped,

00:24:11.220 --> 00:24:15.990
like being bleeding
heart liberals--

00:24:15.990 --> 00:24:18.630
we were seeing what
I have to assume

00:24:18.630 --> 00:24:20.660
was mostly unconscious bias.

00:24:20.660 --> 00:24:24.630
There very well is probably
some conscious in there as well,

00:24:24.630 --> 00:24:28.400
but I think there was at least
some unconscious bias at work.

00:24:28.400 --> 00:24:30.920
BRIAN WELLE: Sobering.

00:24:30.920 --> 00:24:33.220
I'd like to shift focus
to work organizations.

00:24:33.220 --> 00:24:35.010
So you happen to
be sitting in one.

00:24:35.010 --> 00:24:38.470
I'm going to ask you
for some advice here.

00:24:38.470 --> 00:24:40.300
You devote a portion
of your writing

00:24:40.300 --> 00:24:42.490
to what happens
within organizations,

00:24:42.490 --> 00:24:45.370
and for good reason, because we
spend much of our lives here.

00:24:45.370 --> 00:24:48.880
And a lot of what we get--

00:24:48.880 --> 00:24:52.430
money, status, authority--
comes through work.

00:24:52.430 --> 00:24:56.680
So first of all, I found
your definition of diversity

00:24:56.680 --> 00:24:58.760
and inclusion very interesting.

00:24:58.760 --> 00:25:01.040
So you define each
of them differently.

00:25:01.040 --> 00:25:03.700
Let's start with how
you view diversity

00:25:03.700 --> 00:25:04.960
and how you view inclusion.

00:25:04.960 --> 00:25:06.760
DOLLY CHUGH: Yes, thanks.

00:25:06.760 --> 00:25:08.140
And these words
are often bundled

00:25:08.140 --> 00:25:10.390
together, diversity and
inclusion, D and I. Sometimes,

00:25:10.390 --> 00:25:12.280
you throw in a B for belonging.

00:25:12.280 --> 00:25:15.940
But they actually do
mean different things.

00:25:15.940 --> 00:25:17.620
And if we're really
to measure success,

00:25:17.620 --> 00:25:20.560
we're going to need
to know what we mean.

00:25:20.560 --> 00:25:22.480
The metaphor I've been
using for diversity

00:25:22.480 --> 00:25:25.840
is, I think of it as
the gateway, the getting

00:25:25.840 --> 00:25:28.240
of the job, the getting
into the school, the

00:25:28.240 --> 00:25:31.210
getting on the team, the
getting the promotion.

00:25:31.210 --> 00:25:34.810
So it's a formal process.

00:25:34.810 --> 00:25:39.070
It's often got
some legal guidance

00:25:39.070 --> 00:25:42.190
over what appropriate
process is.

00:25:42.190 --> 00:25:46.330
It is relatively
easy to measure,

00:25:46.330 --> 00:25:50.110
and it sets someone up
to get through the entry

00:25:50.110 --> 00:25:52.000
point, the gateway.

00:25:52.000 --> 00:25:55.770
Inclusion I think
of as the pathway.

00:25:55.770 --> 00:25:58.660
And the pathway is what
leads up to that gateway

00:25:58.660 --> 00:26:01.120
and what comes after that
gateway, what comes before it

00:26:01.120 --> 00:26:02.520
and what comes after.

00:26:02.520 --> 00:26:05.620
So this study I just
described, the audit study,

00:26:05.620 --> 00:26:08.290
is an example of
a pathway study.

00:26:08.290 --> 00:26:11.080
It was not the formal
application process

00:26:11.080 --> 00:26:12.700
into the PhD program.

00:26:12.700 --> 00:26:15.130
It was this informal,
if you were in the know,

00:26:15.130 --> 00:26:19.000
you sent the email, and it
started this little banter

00:26:19.000 --> 00:26:20.620
with a professor.

00:26:20.620 --> 00:26:23.680
That is very much
a pathway process.

00:26:23.680 --> 00:26:25.930
In pathway processes,
we don't measure.

00:26:25.930 --> 00:26:27.160
They're hard to measure.

00:26:27.160 --> 00:26:29.740
They can be as fluid
as who interrupts who

00:26:29.740 --> 00:26:32.905
at a meeting, who goes
to drinks with who,

00:26:32.905 --> 00:26:37.510
who gives eye contact to
who, who sits next to who.

00:26:37.510 --> 00:26:41.020
These are the
everyday moments that

00:26:41.020 --> 00:26:44.740
can have a real
influence on how people

00:26:44.740 --> 00:26:47.020
experience an organization.

00:26:47.020 --> 00:26:51.700
But we're not as equipped
to measure them as we go,

00:26:51.700 --> 00:26:53.680
and that falls into
the inclusion side.

00:26:53.680 --> 00:26:55.930
BRIAN WELLE: So if you think
about inclusion this way,

00:26:55.930 --> 00:26:58.380
there are hundreds
of these moments that

00:26:58.380 --> 00:27:00.100
occur every single day.

00:27:00.100 --> 00:27:01.900
You devote a
portion of your book

00:27:01.900 --> 00:27:04.430
on meetings, which
I found fascinating.

00:27:04.430 --> 00:27:07.360
So if I work an
8-hour day, it feels

00:27:07.360 --> 00:27:09.516
like I spend 10 hours a day.

00:27:09.516 --> 00:27:12.310
So that's, I think, the culture
that we have here at Google.

00:27:15.960 --> 00:27:18.250
You're very
optimistic, I will say,

00:27:18.250 --> 00:27:21.290
throughout your book, which
made it a pleasure to read.

00:27:21.290 --> 00:27:24.580
But I think that the title
of this section of your book

00:27:24.580 --> 00:27:27.265
was "Meetings Present
Opportunities."

00:27:27.265 --> 00:27:28.500
I like that.

00:27:28.500 --> 00:27:29.680
I thought it was great.

00:27:29.680 --> 00:27:32.770
So if you think about
meetings as opportunities

00:27:32.770 --> 00:27:36.970
to be inclusive and to
check your unconscious bias,

00:27:36.970 --> 00:27:38.950
what are the tangible
pieces of advice

00:27:38.950 --> 00:27:41.200
you would have for all of
us who are spending our days

00:27:41.200 --> 00:27:41.650
[INAUDIBLE]?

00:27:41.650 --> 00:27:42.670
DOLLY CHUGH: Absolutely.

00:27:42.670 --> 00:27:46.700
Thank you for letting
me share that.

00:27:46.700 --> 00:27:48.596
The Oktoberfest
conference room that we

00:27:48.596 --> 00:27:50.470
were in before we walked
into here, I noticed

00:27:50.470 --> 00:27:55.840
had a run inclusive
meetings placard up

00:27:55.840 --> 00:27:57.430
there, which was fascinating.

00:27:57.430 --> 00:28:00.010
And it mirrored some of
the ideas in the book.

00:28:00.010 --> 00:28:01.930
So Tony Prophet is
the chief equality

00:28:01.930 --> 00:28:05.080
officer at Salesforce.com, and
I interviewed him for the book.

00:28:05.080 --> 00:28:08.320
And when you have a title
like chief equality officer,

00:28:08.320 --> 00:28:10.960
I thought, OK, let's find
out what the chief equality

00:28:10.960 --> 00:28:11.920
officer recommends.

00:28:11.920 --> 00:28:14.980
And I'm expecting
some really big plans.

00:28:14.980 --> 00:28:17.660
And I'm sure Tony has big plans.

00:28:17.660 --> 00:28:20.950
I'm not in any way
suggesting he doesn't.

00:28:20.950 --> 00:28:24.130
But what struck me is
what his first answer was

00:28:24.130 --> 00:28:27.370
to my question of, what do
you think is most important?

00:28:27.370 --> 00:28:29.650
He said, run better meetings.

00:28:29.650 --> 00:28:32.270
I'm like, run better meetings?

00:28:32.270 --> 00:28:34.650
Everyone knows meetings suck.

00:28:34.650 --> 00:28:39.250
That just part of
organizational life.

00:28:39.250 --> 00:28:40.070
And he said, no.

00:28:40.070 --> 00:28:43.630
He said, your meetings
mirror your organization.

00:28:43.630 --> 00:28:45.370
Whatever the headwinds
and tailwinds

00:28:45.370 --> 00:28:49.070
are in your organization are
happening in your meetings.

00:28:49.070 --> 00:28:51.940
But your meetings are
a little easier to--

00:28:51.940 --> 00:28:53.290
you can get a grip on that.

00:28:53.290 --> 00:28:54.610
You can start somewhere.

00:28:54.610 --> 00:28:56.800
You can think about, who
should be in the room,

00:28:56.800 --> 00:28:58.930
and who isn't in the
room who should be?

00:28:58.930 --> 00:29:02.440
You can think about, are
we balancing air time?

00:29:02.440 --> 00:29:04.540
That's a measurable thing.

00:29:04.540 --> 00:29:08.380
You can think about, did
we interrupt people or not?

00:29:08.380 --> 00:29:12.490
You can think about, did
we create an environment

00:29:12.490 --> 00:29:14.530
in which people disagreed
with each other,

00:29:14.530 --> 00:29:16.990
or did we have a meeting--

00:29:16.990 --> 00:29:21.646
which I use when I teach
about meetings to my students

00:29:21.646 --> 00:29:23.020
in our managerial
skills class, I

00:29:23.020 --> 00:29:27.880
call it the most precious real
estate, that we treat meetings

00:29:27.880 --> 00:29:33.440
like it's some little piece
of desert land in an area

00:29:33.440 --> 00:29:35.640
that nobody wants that land.

00:29:35.640 --> 00:29:37.910
They're paying you
to take that land.

00:29:37.910 --> 00:29:39.140
That's how we treat meetings.

00:29:39.140 --> 00:29:40.306
We just throw them together.

00:29:40.306 --> 00:29:42.326
Not here, I mean, like
in other companies.

00:29:44.950 --> 00:29:49.400
But the truth is, meetings are
like Fifth Avenue real estate.

00:29:49.400 --> 00:29:51.920
Getting multiple people in
the room at the same time,

00:29:51.920 --> 00:29:53.780
thinking about the
same thing, that's

00:29:53.780 --> 00:29:55.710
Fifth Avenue real estate.

00:29:55.710 --> 00:29:57.470
And that's how we
should treat it.

00:29:57.470 --> 00:30:01.010
You wouldn't just throw any
old thing on Fifth Avenue.

00:30:01.010 --> 00:30:03.980
You would really put a lot
of thought into designing it.

00:30:03.980 --> 00:30:06.410
And that's, in fact, what we
do want to do in meetings,

00:30:06.410 --> 00:30:08.885
is put that level
of thought into it.

00:30:08.885 --> 00:30:11.260
And if you're going to put
that level of thought into it,

00:30:11.260 --> 00:30:13.670
and if you're going to use that
level of precious real estate,

00:30:13.670 --> 00:30:16.128
what is the point of having a
meeting where everyone agrees

00:30:16.128 --> 00:30:17.560
with each other?

00:30:17.560 --> 00:30:20.030
Did you actually need
the meeting for everyone

00:30:20.030 --> 00:30:22.070
to agree with each
other, or could you

00:30:22.070 --> 00:30:26.160
have just agreed to agree
and not have the meeting?

00:30:26.160 --> 00:30:28.700
So if you're not
running a meeting where

00:30:28.700 --> 00:30:31.520
there is room for disagreement,
then the question is,

00:30:31.520 --> 00:30:33.420
why did you have the meeting?

00:30:33.420 --> 00:30:35.660
Some of the benefits of
diversity and inclusion

00:30:35.660 --> 00:30:40.400
are a range of perspectives,
are a range of opinions.

00:30:40.400 --> 00:30:42.665
Is this a meeting where
you can actually do that?

00:30:42.665 --> 00:30:45.740
BRIAN WELLE: One of
the dynamics that we

00:30:45.740 --> 00:30:50.840
know can happen in meetings is
that people who you would not

00:30:50.840 --> 00:30:53.450
expect to have a
legitimate point of view

00:30:53.450 --> 00:30:56.780
on any particular
topic are marginalized.

00:30:56.780 --> 00:30:59.090
So you can have wonderful
things being expressed

00:30:59.090 --> 00:31:00.950
that are simply not heard.

00:31:00.950 --> 00:31:03.620
And in the book, you talk about
your dissertation research,

00:31:03.620 --> 00:31:07.160
which actually, demonstrated
in a really profound way,

00:31:07.160 --> 00:31:09.650
I thought, with some actual
statistics behind it.

00:31:09.650 --> 00:31:11.570
Can you tell us, what
was that research,

00:31:11.570 --> 00:31:13.800
and what did you find?

00:31:13.800 --> 00:31:16.050
DOLLY CHUGH: That takes us back.

00:31:16.050 --> 00:31:19.180
So in my dissertation,
here's what I did.

00:31:19.180 --> 00:31:21.835
I asked people to
be in a game show,

00:31:21.835 --> 00:31:23.210
but it wasn't
really a game show.

00:31:23.210 --> 00:31:24.710
It was just me and
my laptop walking

00:31:24.710 --> 00:31:27.200
around South Station in
Boston, asking strangers

00:31:27.200 --> 00:31:30.250
to play this game with me.

00:31:30.250 --> 00:31:31.410
They were different times.

00:31:31.410 --> 00:31:33.260
You could do that.

00:31:33.260 --> 00:31:34.950
So the game I would
ask them to play

00:31:34.950 --> 00:31:38.540
is, I would say, I'm going to
show you photographs, and I

00:31:38.540 --> 00:31:41.855
want you to guess how many
jelly beans are in the jar,

00:31:41.855 --> 00:31:44.300
or how much this huge
piece of machinery weighs,

00:31:44.300 --> 00:31:47.390
questions that would be kind
of hard to know the answer to

00:31:47.390 --> 00:31:49.730
without some special knowledge.

00:31:49.730 --> 00:31:53.330
And I'm going to pay you
for how well you guess.

00:31:53.330 --> 00:31:55.626
The closer you get,
the better you do.

00:31:55.626 --> 00:31:56.750
But it's going to be like--

00:31:56.750 --> 00:31:58.791
I forget which game show,
is it Hollywood Squares

00:31:58.791 --> 00:32:01.882
that does this, where
you first get to guess,

00:32:01.882 --> 00:32:04.340
and then you get to listen to
someone else's point of view.

00:32:04.340 --> 00:32:06.200
And then you get to
revise your guess.

00:32:06.200 --> 00:32:08.720
So the question is,
do you use the advice

00:32:08.720 --> 00:32:10.190
that someone else
gives you or not?

00:32:13.340 --> 00:32:15.090
The questions were the
same for everybody,

00:32:15.090 --> 00:32:17.770
but the thing I varied is
whose advice they heard.

00:32:17.770 --> 00:32:20.540
And they would just listen
to it in little headphones.

00:32:20.540 --> 00:32:25.610
And so the advice might be
someone with a Hispanic accent.

00:32:25.610 --> 00:32:27.767
It might be someone
with a white-sounding--

00:32:27.767 --> 00:32:29.600
I realize those are not
mutually exclusive--

00:32:29.600 --> 00:32:31.370
but white-sounding accent.

00:32:31.370 --> 00:32:35.540
It might be someone who sounds
African American, male, female.

00:32:35.540 --> 00:32:37.640
It just had a bunch
of different voices.

00:32:37.640 --> 00:32:41.090
And of course, I
rigged the whole thing

00:32:41.090 --> 00:32:43.760
so that all the advice
was 100% correct.

00:32:43.760 --> 00:32:47.010
So everybody heard
the correct answers,

00:32:47.010 --> 00:32:50.120
and it was just a matter of
whether you trusted the advice

00:32:50.120 --> 00:32:52.700
from this unknown voice.

00:32:52.700 --> 00:32:56.120
And what I found was, I
called it a stereotype tax,

00:32:56.120 --> 00:32:57.850
that the people,
for example, who

00:32:57.850 --> 00:33:01.010
had a female
advisor in their ear

00:33:01.010 --> 00:33:02.630
were less likely to
take that advice.

00:33:02.630 --> 00:33:03.439
I think they made--

00:33:03.439 --> 00:33:04.230
BRIAN WELLE: $0.69.

00:33:04.230 --> 00:33:06.950
DOLLY CHUGH: $0.69 on
the dollar for people

00:33:06.950 --> 00:33:09.050
who had a male
advisor, because they

00:33:09.050 --> 00:33:11.690
were so much less likely
to take the advice

00:33:11.690 --> 00:33:13.430
of the female advisor.

00:33:13.430 --> 00:33:16.250
And I tried to standardize
a whole bunch of things,

00:33:16.250 --> 00:33:19.040
like the tone of the
voice and everything that

00:33:19.040 --> 00:33:21.260
would make something
sound different, other

00:33:21.260 --> 00:33:23.390
than just the gender.

00:33:23.390 --> 00:33:26.870
And so the
dissertation, the idea

00:33:26.870 --> 00:33:29.720
there was to show, even in
these really fluid moments,

00:33:29.720 --> 00:33:31.940
like in meetings, for
example, when somebody throws

00:33:31.940 --> 00:33:34.800
an idea out, and we have to
make that split second of,

00:33:34.800 --> 00:33:38.600
do we keep going with
that, or do we move on?

00:33:38.600 --> 00:33:41.750
Those little, quick
moments, we are potentially

00:33:41.750 --> 00:33:44.050
discounting points of view.

00:33:44.050 --> 00:33:45.620
BRIAN WELLE: And
I know it can be

00:33:45.620 --> 00:33:46.844
difficult to counteract that.

00:33:46.844 --> 00:33:48.260
If there were an
easy solution, we

00:33:48.260 --> 00:33:50.000
would implement it right
now, and all the meetings

00:33:50.000 --> 00:33:50.708
would be amazing.

00:33:50.708 --> 00:33:52.700
And you would take
all points of view

00:33:52.700 --> 00:33:54.680
into account that were
good points of view.

00:33:58.096 --> 00:34:00.840
Maybe I demonstrated
it's problematic

00:34:00.840 --> 00:34:04.280
thinking right there.

00:34:04.280 --> 00:34:06.470
In your book, you are
prescriptive about things

00:34:06.470 --> 00:34:07.100
that we can do.

00:34:07.100 --> 00:34:11.929
One of the things
that I noted was for--

00:34:11.929 --> 00:34:15.360
if you walk into a setting and
you have ordinary privilege,

00:34:15.360 --> 00:34:17.150
you are walking in
with a stereotype

00:34:17.150 --> 00:34:19.154
that operates on your behalf.

00:34:19.154 --> 00:34:20.570
And you are a
person with a growth

00:34:20.570 --> 00:34:24.469
mindset, someone who is on
the journey to being a better

00:34:24.469 --> 00:34:25.219
person.

00:34:25.219 --> 00:34:27.925
And you hear ideas using
your ordinary privilege

00:34:27.925 --> 00:34:30.326
to stand up for
someone else's idea,

00:34:30.326 --> 00:34:31.409
was one way of doing that.

00:34:31.409 --> 00:34:32.760
DOLLY CHUGH: Exactly.

00:34:32.760 --> 00:34:33.480
Amplified.

00:34:33.480 --> 00:34:36.120
BRIAN WELLE: Any
other tangible advice

00:34:36.120 --> 00:34:40.856
to help us really
hear good ideas?

00:34:40.856 --> 00:34:43.230
DOLLY CHUGH: I also, sometimes,
do the thought experiment

00:34:43.230 --> 00:34:47.489
in my head, of when I can feel
myself dismissing someone,

00:34:47.489 --> 00:34:51.537
I imagine the same idea
coming out of someone else.

00:34:51.537 --> 00:34:53.370
I'm not going to say
who, but right now, I'm

00:34:53.370 --> 00:34:57.450
picturing two colleagues in
my mind in my work world.

00:34:57.450 --> 00:35:00.240
And if I take the idea
out of one person's mouth

00:35:00.240 --> 00:35:04.287
and I put it in another, would
I be listening more carefully,

00:35:04.287 --> 00:35:06.370
or would I be tuning out
in the meeting right now?

00:35:06.370 --> 00:35:08.640
And the truth is, with the
two people I have in mind,

00:35:08.640 --> 00:35:12.850
I might be tuning out less if
it was coming from someone else.

00:35:12.850 --> 00:35:16.080
And so I think, while it's
hard to debias the brain,

00:35:16.080 --> 00:35:18.150
it isn't so hard
to do the noticing,

00:35:18.150 --> 00:35:22.950
to actually just put yourself
in that counter-factual of, what

00:35:22.950 --> 00:35:24.606
if?

00:35:24.606 --> 00:35:27.030
BRIAN WELLE: I'm going to
ask you another question,

00:35:27.030 --> 00:35:29.990
but I will take audience
questions in just a minute.

00:35:29.990 --> 00:35:32.230
So if you have one,
there are two mics

00:35:32.230 --> 00:35:33.750
and please make
your way up there,

00:35:33.750 --> 00:35:36.220
and you can ask your question.

00:35:36.220 --> 00:35:40.130
So what you've
described in your book

00:35:40.130 --> 00:35:42.050
is a process that we
can all go through.

00:35:42.050 --> 00:35:45.730
And many people are engaged in
that journey, but many are not.

00:35:45.730 --> 00:35:48.580
And based on some research
that you had reviewed,

00:35:48.580 --> 00:35:52.880
you summed up three kinds
of people, the 20/60/20s.

00:35:52.880 --> 00:35:54.320
You've got the easy 20s.

00:35:54.320 --> 00:35:56.240
These are people who
are intrinsically

00:35:56.240 --> 00:35:58.240
motivated to be unbiased.

00:35:58.240 --> 00:35:59.390
They are really working.

00:35:59.390 --> 00:36:01.340
And you know you
can talk to them,

00:36:01.340 --> 00:36:04.190
and you'll have kindred spirit.

00:36:04.190 --> 00:36:08.050
Then you've got this middle
60, who's really nowhere.

00:36:08.050 --> 00:36:09.500
They're silent.

00:36:09.500 --> 00:36:11.390
They're not really
paying attention,

00:36:11.390 --> 00:36:15.030
and these issues just have
not surfaced for them yet.

00:36:15.030 --> 00:36:16.940
And then you've
got the stuck 20.

00:36:16.940 --> 00:36:22.340
This is a 20% of people who
are really set and entrenched

00:36:22.340 --> 00:36:23.960
in their ideas.

00:36:23.960 --> 00:36:26.760
They are not willing
to listen or to change,

00:36:26.760 --> 00:36:29.330
and, I think, we all
probably have some people

00:36:29.330 --> 00:36:30.932
like that in our lives.

00:36:30.932 --> 00:36:32.390
The thing that
struck me about that

00:36:32.390 --> 00:36:35.810
is your advice for
the stuck 20 is,

00:36:35.810 --> 00:36:38.839
you can choose to engage
or not engage with them.

00:36:38.839 --> 00:36:40.880
It's important to make
your points of view known,

00:36:40.880 --> 00:36:42.710
but don't expect,
necessarily, that they're

00:36:42.710 --> 00:36:44.180
going to change along the way.

00:36:44.180 --> 00:36:48.440
It's an agreement that you come
to with yourself and with them.

00:36:48.440 --> 00:36:50.430
In a workplace,
that's problematic,

00:36:50.430 --> 00:36:53.750
because let's presume that
a portion of those 20%

00:36:53.750 --> 00:36:55.490
are working here with us.

00:36:55.490 --> 00:36:58.820
We are in an organization that
is trying very hard to have

00:36:58.820 --> 00:37:01.924
bias-free systems and
processes, to hold ourselves up

00:37:01.924 --> 00:37:03.590
to higher standards,
to make sure we all

00:37:03.590 --> 00:37:06.290
have growth mindsets.

00:37:06.290 --> 00:37:10.190
What advice do you have
for organizations that have

00:37:10.190 --> 00:37:13.010
portions of these 20% in there?

00:37:13.010 --> 00:37:15.830
And we want them to
thrive and add value,

00:37:15.830 --> 00:37:19.005
but we also need
them to be operating

00:37:19.005 --> 00:37:21.380
in a way that is living up to
the cultural standard we're

00:37:21.380 --> 00:37:22.255
trying to set.

00:37:22.255 --> 00:37:23.900
DOLLY CHUGH: Absolutely.

00:37:23.900 --> 00:37:27.270
So the 20/60/20 rule can
be applied to anything.

00:37:27.270 --> 00:37:28.910
It's not specific to bias.

00:37:28.910 --> 00:37:32.090
In fact, I learned it
from organizational change

00:37:32.090 --> 00:37:36.630
consultant, Susan Nunzio,
who I used to work with.

00:37:36.630 --> 00:37:38.960
Academia is a second career.

00:37:38.960 --> 00:37:40.740
Consulting, banking
was first career.

00:37:40.740 --> 00:37:43.460
And when I worked with her, she
would use this as an approach

00:37:43.460 --> 00:37:46.760
to any cultural change
in an organization.

00:37:46.760 --> 00:37:53.000
And the 20/60/20,
what it does is not

00:37:53.000 --> 00:37:57.860
say that we have to
forget about the stuck 20,

00:37:57.860 --> 00:38:01.070
but it does say to be
really careful of how

00:38:01.070 --> 00:38:02.990
you use your energy there.

00:38:02.990 --> 00:38:07.460
Because the stuck 20 tends to
be vocal, and the middle 60

00:38:07.460 --> 00:38:09.380
tends to be quiet.

00:38:09.380 --> 00:38:11.750
And so what we can
easily have happen

00:38:11.750 --> 00:38:15.980
is that all of our energy and
focus goes to the stuck 20.

00:38:15.980 --> 00:38:18.740
And you find yourself
in those arguments

00:38:18.740 --> 00:38:21.530
that nobody's listening to,
but you're doubling down,

00:38:21.530 --> 00:38:23.140
and they're doubling down.

00:38:23.140 --> 00:38:26.690
And the middle 60 is
tuning out, because this

00:38:26.690 --> 00:38:29.540
has gotten pretty boring.

00:38:29.540 --> 00:38:31.540
And you've missed
the opportunity

00:38:31.540 --> 00:38:35.030
to either engage
with the stuck 20,

00:38:35.030 --> 00:38:38.384
knowing you have a hidden
audience in the middle 60.

00:38:38.384 --> 00:38:39.800
So if you're going
to engage here,

00:38:39.800 --> 00:38:43.640
at least know the middle 60 is
listening or could be listening

00:38:43.640 --> 00:38:45.290
if you could be engaging.

00:38:45.290 --> 00:38:48.560
So rather than it being, you're
trying to convince this person,

00:38:48.560 --> 00:38:52.880
think of it as, I'm trying to
actually shape a larger group's

00:38:52.880 --> 00:38:54.370
perspective.

00:38:54.370 --> 00:38:57.677
And in doing that, you
are going to shift norms.

00:38:57.677 --> 00:39:00.260
So when you move the middle 60--
which could go this way or it

00:39:00.260 --> 00:39:01.400
could go this way--

00:39:01.400 --> 00:39:02.870
you're shaping the norms.

00:39:02.870 --> 00:39:06.710
And those norms are going to
do the work on your stuck 20.

00:39:06.710 --> 00:39:11.450
Norms are incredibly
powerful shapers of behavior.

00:39:11.450 --> 00:39:14.550
And so you may not be able
to convince the stuck 20,

00:39:14.550 --> 00:39:17.780
but you are able to
shape norms and influence

00:39:17.780 --> 00:39:19.700
the views of people around you.

00:39:19.700 --> 00:39:21.710
And that will do the work.

00:39:21.710 --> 00:39:22.850
That's a powerful lever.

00:39:22.850 --> 00:39:29.000
BRIAN WELLE: I found it amazing
to read about how you interact

00:39:29.000 --> 00:39:30.800
over social media
with people who had

00:39:30.800 --> 00:39:32.810
very contrarian points of view.

00:39:32.810 --> 00:39:35.630
And you write that you will
engage with them, knowing

00:39:35.630 --> 00:39:37.430
that the 60% are reading.

00:39:37.430 --> 00:39:39.470
So you're really engaging
them for the 60%,

00:39:39.470 --> 00:39:42.102
and not with any expectation
of changing the person you're

00:39:42.102 --> 00:39:42.935
exactly [INAUDIBLE].

00:39:42.935 --> 00:39:44.660
DOLLY CHUGH: Exactly.

00:39:44.660 --> 00:39:46.790
I know when I'm not
going to get anywhere

00:39:46.790 --> 00:39:48.650
in one of those
social media things

00:39:48.650 --> 00:39:51.420
that we all find ourselves in.

00:39:51.420 --> 00:39:54.410
But what I do do is speak to
the lurkers, because I know--

00:39:54.410 --> 00:39:55.610
because I lurk, too--

00:39:55.610 --> 00:39:58.730
I know there's a whole bunch
of people lurking and waiting

00:39:58.730 --> 00:40:01.190
for the fight to begin.

00:40:01.190 --> 00:40:03.110
And instead of
going into the fight

00:40:03.110 --> 00:40:05.180
now that I've got
their attention,

00:40:05.180 --> 00:40:07.520
I just use it as an
opportunity to speak.

00:40:07.520 --> 00:40:09.910
And sometimes, I literally
just speak past the person

00:40:09.910 --> 00:40:12.050
arguing with me.

00:40:12.050 --> 00:40:12.740
I'm respectful.

00:40:12.740 --> 00:40:15.080
I'm always respectful,
but I don't even

00:40:15.080 --> 00:40:17.630
worry about getting into
what they're saying.

00:40:17.630 --> 00:40:21.320
I just say what I wish the
middle 60 knew and use it

00:40:21.320 --> 00:40:25.860
as that moment now that
I've got the fight--

00:40:25.860 --> 00:40:27.575
their attention on the fight.

00:40:27.575 --> 00:40:29.930
BRIAN WELLE: There
was a powerful moment

00:40:29.930 --> 00:40:32.210
in your interview
with Joe McNeil.

00:40:32.210 --> 00:40:34.852
And you had asked him
whether, in hindsight,

00:40:34.852 --> 00:40:37.310
he would have done anything
differently when he was sitting

00:40:37.310 --> 00:40:38.715
at that counter at Woolworth's.

00:40:38.715 --> 00:40:39.590
DOLLY CHUGH: Exactly.

00:40:39.590 --> 00:40:43.400
Joe McNeil, Greensboro Four,
who we talked about earlier.

00:40:43.400 --> 00:40:46.040
First I asked him, would
you have done anything

00:40:46.040 --> 00:40:48.170
differently looking back?

00:40:48.170 --> 00:40:50.326
He's in his mid-70s now.

00:40:50.326 --> 00:40:54.200
At first, he's like, no,
I think we did it right.

00:40:54.200 --> 00:40:58.894
And then he took a sip of
his coffee, and then he said,

00:40:58.894 --> 00:41:00.770
you know what I would have done?

00:41:00.770 --> 00:41:04.580
I would have spoken more to
the people who were silent.

00:41:04.580 --> 00:41:07.010
Basically, he was
saying the middle 60.

00:41:07.010 --> 00:41:10.400
I would have given them a chance
to be a better person, too.

00:41:10.400 --> 00:41:12.170
That's what I would have done.

00:41:12.170 --> 00:41:15.620
And I just thought that
was such a powerful insight

00:41:15.620 --> 00:41:17.780
from somebody who was
really on the front lines

00:41:17.780 --> 00:41:21.445
risking everything,
his life, everything.

00:41:21.445 --> 00:41:24.730
BRIAN WELLE: Any
questions from any of you?

00:41:29.197 --> 00:41:29.780
I've got more.

00:41:29.780 --> 00:41:30.860
DOLLY CHUGH: Good.

00:41:30.860 --> 00:41:33.860
BRIAN WELLE: So
the growth mindset

00:41:33.860 --> 00:41:37.670
that you described
in the book will

00:41:37.670 --> 00:41:40.220
lead us to ask a lot more
questions than we're probably

00:41:40.220 --> 00:41:42.230
asking today.

00:41:42.230 --> 00:41:45.200
It will lead us to take
seriously the things

00:41:45.200 --> 00:41:47.390
that people tell us, that
we may have dismissed,

00:41:47.390 --> 00:41:48.980
our old self may have dismissed.

00:41:48.980 --> 00:41:52.560
But the new self is
actually reflecting on it,

00:41:52.560 --> 00:41:55.580
seeing if there's
some truth to it.

00:41:55.580 --> 00:41:57.530
In the process of having
this growth mindset

00:41:57.530 --> 00:41:59.750
and being on this
journey, you're

00:41:59.750 --> 00:42:04.070
asking the people who may
be most disadvantaged, most

00:42:04.070 --> 00:42:08.600
marginalized, the ones who
are the negative recipients

00:42:08.600 --> 00:42:11.960
of the unconscious bias, to do
a lot of educating and engaging.

00:42:11.960 --> 00:42:13.506
Is that fair?

00:42:13.506 --> 00:42:17.900
DOLLY CHUGH: I don't want to
put that burden of education--

00:42:17.900 --> 00:42:20.925
so this is where those of us
who have ordinary privilege--

00:42:20.925 --> 00:42:22.925
ordinary privilege is the
piece of your identity

00:42:22.925 --> 00:42:24.110
you think least about.

00:42:24.110 --> 00:42:27.020
We all have multiple
facets for identity.

00:42:27.020 --> 00:42:27.945
I'm straight.

00:42:27.945 --> 00:42:30.320
I can go weeks and months
without thinking about the fact

00:42:30.320 --> 00:42:31.860
that I'm straight.

00:42:31.860 --> 00:42:33.777
The world is set up for me.

00:42:33.777 --> 00:42:35.360
Someone asked what
I did this weekend.

00:42:35.360 --> 00:42:38.360
It's easy to just
share, my husband

00:42:38.360 --> 00:42:39.750
and I did this or whatever.

00:42:39.750 --> 00:42:41.480
I can put pictures
of my family, and I

00:42:41.480 --> 00:42:44.950
don't worry about
being penalized

00:42:44.950 --> 00:42:46.970
in some conscious or
unconscious way at work.

00:42:46.970 --> 00:42:48.690
Ordinary privilege is a
piece of your identity

00:42:48.690 --> 00:42:50.231
you think least
about, because that's

00:42:50.231 --> 00:42:51.680
where you have the tailwinds.

00:42:51.680 --> 00:42:55.640
And that's also where you
have surprising influence.

00:42:55.640 --> 00:42:57.980
And so studies show
that, let's say,

00:42:57.980 --> 00:43:00.320
a black person says
something about a racist joke

00:43:00.320 --> 00:43:02.060
versus a white person
saying something

00:43:02.060 --> 00:43:03.680
about the same racist joke.

00:43:03.680 --> 00:43:06.320
The black person is
perceived as being whiny,

00:43:06.320 --> 00:43:08.420
whereas the white person
will have more influence

00:43:08.420 --> 00:43:10.830
than they expect they're
going to have in that moment.

00:43:10.830 --> 00:43:12.871
There's been multiple
studies that have basically

00:43:12.871 --> 00:43:14.390
shown that same pattern.

00:43:14.390 --> 00:43:16.070
That in the piece
of your identity

00:43:16.070 --> 00:43:19.480
where you have ordinary
privilege, what

00:43:19.480 --> 00:43:22.340
ordinary privilege brings
is unexpected influence.

00:43:22.340 --> 00:43:27.260
And so this is where so many
of us feel helpless right now.

00:43:27.260 --> 00:43:30.530
We actually have reason
to be optimistic,

00:43:30.530 --> 00:43:32.590
that we have more
influence than we realize,

00:43:32.590 --> 00:43:36.260
not to speak over
or for someone else,

00:43:36.260 --> 00:43:39.980
but to take some ownership,
so that the same people aren't

00:43:39.980 --> 00:43:44.995
doing the same work educating
others time and time again.

00:43:44.995 --> 00:43:46.370
The other thing
I really liked is

00:43:46.370 --> 00:43:50.030
I interviewed Subha Barry, who's
held a number of senior roles

00:43:50.030 --> 00:43:52.580
in financial
services and is now,

00:43:52.580 --> 00:43:55.730
I think, the President
of Working Mother Media.

00:43:55.730 --> 00:43:59.270
And she's been fighting a
bunch of fights for decades,

00:43:59.270 --> 00:44:04.160
trying to create more equity
and equality in organizations.

00:44:04.160 --> 00:44:07.200
And I asked her how she
sustains herself in that.

00:44:07.200 --> 00:44:10.100
And she described flipping
channels on the TV

00:44:10.100 --> 00:44:13.040
once and running across
this "National Geographic"

00:44:13.040 --> 00:44:14.990
special about birds.

00:44:14.990 --> 00:44:17.240
And it was all about
the V-formation

00:44:17.240 --> 00:44:18.600
that some birds fly in.

00:44:18.600 --> 00:44:20.090
Have you ever noticed that?

00:44:20.090 --> 00:44:22.970
And what she did know, and I
didn't know till she told me,

00:44:22.970 --> 00:44:26.140
is that when you see that
V-formation in the sky

00:44:26.140 --> 00:44:28.070
and it looks like
it's just static,

00:44:28.070 --> 00:44:30.170
the same birds, that
what's actually happening

00:44:30.170 --> 00:44:33.080
is the lead bird
rotates to the back.

00:44:33.080 --> 00:44:36.110
There's this constant
rotation, and that's

00:44:36.110 --> 00:44:40.100
because the lead bird is the
one who's taking the headwinds.

00:44:40.100 --> 00:44:43.390
That's the hardest job, to
break the wind up front,

00:44:43.390 --> 00:44:45.600
and it's the most exhausting.

00:44:45.600 --> 00:44:47.930
So the way the birds
are able to sustain this

00:44:47.930 --> 00:44:51.710
is by not always having
the same lead bird.

00:44:51.710 --> 00:44:54.360
And I think that's
another piece of this.

00:44:54.360 --> 00:44:56.460
In the areas in which we
have ordinary privilege,

00:44:56.460 --> 00:44:59.300
how can we step into
that lead bird role,

00:44:59.300 --> 00:45:01.880
again, not speaking
over or for people,

00:45:01.880 --> 00:45:03.980
but taking some
ownership for trying

00:45:03.980 --> 00:45:06.927
to create the kind of
environment, culture, workplace

00:45:06.927 --> 00:45:07.510
that we value?

00:45:10.656 --> 00:45:14.030
AUDIENCE: Hi, professor.

00:45:14.030 --> 00:45:16.862
So in your amazing
class at Stern,

00:45:16.862 --> 00:45:18.320
you taught us that
there were a lot

00:45:18.320 --> 00:45:21.290
of different types of cultures
that could be successful.

00:45:21.290 --> 00:45:23.180
But building off
the conversation

00:45:23.180 --> 00:45:26.990
about bias and hiring
practices, how do you

00:45:26.990 --> 00:45:31.580
have a hiring practice that gets
the right person for culture

00:45:31.580 --> 00:45:35.030
without culture fit being
synonymous for some sort

00:45:35.030 --> 00:45:37.080
of implicit bias in that?

00:45:37.080 --> 00:45:38.240
DOLLY CHUGH: Absolutely.

00:45:38.240 --> 00:45:42.320
So I think it's a matter
of thinking about what

00:45:42.320 --> 00:45:44.150
it is about that
cultural fit that's

00:45:44.150 --> 00:45:46.880
going to enhance performance
and actually getting into what

00:45:46.880 --> 00:45:48.560
the behavioral indicators are.

00:45:48.560 --> 00:45:52.430
So if what's needed
is that we need

00:45:52.430 --> 00:45:54.290
to be able to spend
long periods of time

00:45:54.290 --> 00:45:56.960
together without driving
each other crazy,

00:45:56.960 --> 00:45:58.610
we can do that
without necessarily

00:45:58.610 --> 00:46:01.350
having to have gone to the
same cluster of colleges.

00:46:01.350 --> 00:46:05.210
It's more a matter of maybe
what you do in your interviewing

00:46:05.210 --> 00:46:06.170
or hiring process--

00:46:06.170 --> 00:46:07.670
is you actually
screen for, what is

00:46:07.670 --> 00:46:09.470
it like to spend time
with this person,

00:46:09.470 --> 00:46:11.330
or how do they
react under stress,

00:46:11.330 --> 00:46:14.780
as opposed to relying on the
more informal banter that makes

00:46:14.780 --> 00:46:17.300
assumptions that, just because
we went to the same schools,

00:46:17.300 --> 00:46:20.280
we would have the
same comfort level.

00:46:20.280 --> 00:46:22.400
And I realize it's
not that explicit.

00:46:22.400 --> 00:46:25.700
The processes I was
part of and advanced,

00:46:25.700 --> 00:46:27.492
we were never that
explicit that we were

00:46:27.492 --> 00:46:28.700
looking for the same schools.

00:46:28.700 --> 00:46:31.310
But that is what
we ended up doing.

00:46:31.310 --> 00:46:32.210
AUDIENCE: Thank you.

00:46:32.210 --> 00:46:33.168
DOLLY CHUGH: Thank you.

00:46:33.168 --> 00:46:35.224
Nice to see you.

00:46:35.224 --> 00:46:36.019
AUDIENCE: Hi.

00:46:36.019 --> 00:46:38.185
Thanks for coming here and
having this conversation.

00:46:38.185 --> 00:46:39.670
DOLLY CHUGH: Thank
you for having me.

00:46:39.670 --> 00:46:41.545
AUDIENCE: I was wondering
what your advice is

00:46:41.545 --> 00:46:44.900
for when you make a mistake,
particularly in the workplace,

00:46:44.900 --> 00:46:46.530
how do you recover from that?

00:46:46.530 --> 00:46:50.510
How do make sure you repair
the harm that you've done,

00:46:50.510 --> 00:46:51.960
and how does that work?

00:46:51.960 --> 00:46:53.120
DOLLY CHUGH: Absolutely.

00:46:53.120 --> 00:46:56.210
So I think it's like in
all other parts of our life

00:46:56.210 --> 00:46:59.900
when we have some sort
of faux pas or error

00:46:59.900 --> 00:47:03.260
that creates negative
impact on others.

00:47:03.260 --> 00:47:06.440
The ways in which we know,
taking accountability,

00:47:06.440 --> 00:47:07.820
works here, too.

00:47:07.820 --> 00:47:11.480
So we'll use an example.

00:47:11.480 --> 00:47:17.090
It's not, I'm sorry you
were offended by that.

00:47:17.090 --> 00:47:20.180
It's, I'm sorry that I did harm.

00:47:20.180 --> 00:47:23.060
I'm sorry for my
error in judgment.

00:47:23.060 --> 00:47:25.130
I'm sorry for my ignorance.

00:47:25.130 --> 00:47:27.410
And then where you
can go with that is,

00:47:27.410 --> 00:47:31.490
you can ask if the other person
is interested in educating you

00:47:31.490 --> 00:47:33.420
about the harm you've done.

00:47:33.420 --> 00:47:35.540
But you don't expect
them to do it,

00:47:35.540 --> 00:47:39.170
because that is putting
labor on the other person

00:47:39.170 --> 00:47:41.630
to then go through-- not
only has harm been done,

00:47:41.630 --> 00:47:44.420
now it's my job to educate
you about your blind spots

00:47:44.420 --> 00:47:46.700
and deal with all your
emotional reactions

00:47:46.700 --> 00:47:49.260
and not offending you and
all that sort of stuff.

00:47:49.260 --> 00:47:51.640
So I think it's
first the apology.

00:47:51.640 --> 00:47:53.480
You can make an invitation.

00:47:53.480 --> 00:47:55.040
If the person is into it, great.

00:47:55.040 --> 00:47:56.840
If they're not, it's
your job to go figure

00:47:56.840 --> 00:47:58.630
out how to educate yourself.

00:47:58.630 --> 00:47:59.860
AUDIENCE: Thank you.

00:47:59.860 --> 00:48:01.226
DOLLY CHUGH: Thank you.

00:48:01.226 --> 00:48:03.130
BRIAN WELLE: In your
book, you read a bit

00:48:03.130 --> 00:48:08.570
about traumatic events that have
been happening in the United

00:48:08.570 --> 00:48:12.310
States, whether it's
the shooting in Orlando

00:48:12.310 --> 00:48:17.784
at a gay nightclub or the police
shootings that have happened.

00:48:17.784 --> 00:48:20.200
And we know people who are
members of the communities that

00:48:20.200 --> 00:48:21.790
would have been affected.

00:48:21.790 --> 00:48:24.280
And you profiled
different people

00:48:24.280 --> 00:48:26.110
and how they've
processed that, or how

00:48:26.110 --> 00:48:28.270
they've provided support.

00:48:28.270 --> 00:48:31.110
What is a lesson that
you learned from them

00:48:31.110 --> 00:48:35.326
that you would pass on to us?

00:48:35.326 --> 00:48:38.310
DOLLY CHUGH: So psychologists
call this hidden grief.

00:48:38.310 --> 00:48:41.820
That at any given
moment, including now,

00:48:41.820 --> 00:48:44.220
one out of four of
us is sitting here

00:48:44.220 --> 00:48:47.070
in this room with
real hidden grief,

00:48:47.070 --> 00:48:49.630
whether it's the
loss of a loved one,

00:48:49.630 --> 00:48:52.060
whether it's a traumatic
event in your life,

00:48:52.060 --> 00:48:55.320
whether it's something
happening in the news that

00:48:55.320 --> 00:48:57.750
feels very personal to you.

00:49:00.360 --> 00:49:04.080
There's a lot of work you're
doing just to hold it together

00:49:04.080 --> 00:49:05.910
at any given moment.

00:49:05.910 --> 00:49:09.720
And in what I read about and
learned about with hidden grief

00:49:09.720 --> 00:49:13.050
and thinking about it in the
context of national events

00:49:13.050 --> 00:49:16.150
and international events
and how they affect,

00:49:16.150 --> 00:49:17.850
for example, my students--

00:49:17.850 --> 00:49:19.410
I teach at NYU.

00:49:19.410 --> 00:49:22.290
I deal with students on--

00:49:22.290 --> 00:49:26.940
not on a daily basis,
but on a flowing basis

00:49:26.940 --> 00:49:31.080
where I see them over the
stretch of an entire semester.

00:49:31.080 --> 00:49:33.850
And things happen in the
world during that time.

00:49:33.850 --> 00:49:37.190
And it used to be that just
if I didn't know what to say,

00:49:37.190 --> 00:49:38.250
I'd say nothing.

00:49:38.250 --> 00:49:39.990
And I have to confess
that there's still

00:49:39.990 --> 00:49:42.160
a portion of times when
that's exactly what happens.

00:49:42.160 --> 00:49:45.630
But I think what I learned from
the hidden grief research was

00:49:45.630 --> 00:49:50.190
just the noticing that
someone's grief is there

00:49:50.190 --> 00:49:52.890
and the acknowledging that
you see it, the bearing

00:49:52.890 --> 00:49:56.610
witness of it-- not inserting
myself, not making myself

00:49:56.610 --> 00:50:00.160
the savior, not
cookie-seeking, meaning,

00:50:00.160 --> 00:50:03.120
cookie-seeking is like looking
for their validation of how

00:50:03.120 --> 00:50:06.510
awesome it was that
I checked in on them.

00:50:06.510 --> 00:50:09.120
But just saying, hey,
how are you holding up?

00:50:09.120 --> 00:50:11.577
And that's actually
a phrase that I

00:50:11.577 --> 00:50:13.410
learned from one of my
former students, the,

00:50:13.410 --> 00:50:15.060
how are you holding up?

00:50:15.060 --> 00:50:18.570
It allows the other person to
go in any number of directions.

00:50:18.570 --> 00:50:20.910
They can say, oh my
god, I'm falling apart,

00:50:20.910 --> 00:50:22.510
I need to tell you everything.

00:50:22.510 --> 00:50:26.190
Or they can be like, oh
good, everything's great.

00:50:26.190 --> 00:50:29.490
They can use that question
to go as deep or as

00:50:29.490 --> 00:50:33.180
lightly as they want, but
they know that they're seen.

00:50:33.180 --> 00:50:36.379
And so I think the
hidden grief piece

00:50:36.379 --> 00:50:37.920
is one of the places
where I'm trying

00:50:37.920 --> 00:50:39.990
to do the most work,
of figuring out

00:50:39.990 --> 00:50:44.070
how to not allow silence to look
like indifference to others.

00:50:44.070 --> 00:50:48.084
And that is how it's often
perceived in the workplace.

00:50:48.084 --> 00:50:48.940
Should I go there?

00:50:48.940 --> 00:50:49.440
Hi.

00:50:49.440 --> 00:50:50.231
AUDIENCE: Hi there.

00:50:50.231 --> 00:50:52.680
First of all, I wanted to
say, Brian, thank you so much.

00:50:52.680 --> 00:50:54.500
You ran the unbiasing video.

00:50:54.500 --> 00:50:57.030
I'm a new-gler, so I
saw an hour and a half

00:50:57.030 --> 00:50:58.140
of unbiasing training.

00:50:58.140 --> 00:50:59.889
And now, I'm having a
little Google crush.

00:50:59.889 --> 00:51:01.512
You're doing a great job.

00:51:01.512 --> 00:51:02.720
DOLLY CHUGH: That's so sweet.

00:51:02.720 --> 00:51:05.053
AUDIENCE: Thank you for putting
together these programs.

00:51:05.053 --> 00:51:08.970
I'm definitely part
of the 20% here,

00:51:08.970 --> 00:51:11.580
in part, because I want
to be a better person,

00:51:11.580 --> 00:51:14.250
and I want to be
a better coworker.

00:51:14.250 --> 00:51:16.980
And I'm a sociologist,
so I'm constantly

00:51:16.980 --> 00:51:21.360
thinking about the group
and the systematic biases.

00:51:21.360 --> 00:51:23.820
And I think being
at Google has really

00:51:23.820 --> 00:51:26.550
challenged me to see where I
fit at the individual level

00:51:26.550 --> 00:51:28.530
and really what's
going on there.

00:51:28.530 --> 00:51:32.080
And you said, changing
the unconscious bias

00:51:32.080 --> 00:51:35.755
using our brain is really
hard and then you move on.

00:51:35.755 --> 00:51:38.170
And I want to open
that up a little bit.

00:51:38.170 --> 00:51:40.740
What is it that I
could do or anybody

00:51:40.740 --> 00:51:43.320
could do to really
push ourselves

00:51:43.320 --> 00:51:45.180
to find the blind spots.

00:51:45.180 --> 00:51:49.240
Because naturally, our brain
doesn't want to find them.

00:51:49.240 --> 00:51:50.910
How do we push
ourselves to become

00:51:50.910 --> 00:51:53.250
more comfortable
with these truths

00:51:53.250 --> 00:51:55.507
that maybe we didn't want
to acknowledge before?

00:51:55.507 --> 00:51:56.340
Are there exercises?

00:51:56.340 --> 00:51:59.230
Are there great podcasts?

00:51:59.230 --> 00:52:00.149
Well, there might be.

00:52:00.149 --> 00:52:00.690
I don't know.

00:52:00.690 --> 00:52:01.520
DOLLY CHUGH: There might be.

00:52:01.520 --> 00:52:02.340
AUDIENCE: So any thoughts
there would be great.

00:52:02.340 --> 00:52:03.340
DOLLY CHUGH: Absolutely.

00:52:03.340 --> 00:52:05.055
Thank you.

00:52:05.055 --> 00:52:06.930
You may have already
done this, but I'll just

00:52:06.930 --> 00:52:08.760
throw out ideas for everyone.

00:52:08.760 --> 00:52:11.290
So there's the Implicit
Association Test,

00:52:11.290 --> 00:52:13.570
which is called the IAT.

00:52:13.570 --> 00:52:15.529
Would they have done that
through the training?

00:52:15.529 --> 00:52:16.444
BRIAN WELLE: Possibly.

00:52:16.444 --> 00:52:17.090
It's mentioned.

00:52:17.090 --> 00:52:19.615
DOLLY CHUGH: So
implicit.harvard.edu

00:52:19.615 --> 00:52:21.780
is the site where
you can find it.

00:52:21.780 --> 00:52:23.460
You can do it
completely anonymously.

00:52:23.460 --> 00:52:25.770
It's about a 10 minute
test on the internet.

00:52:25.770 --> 00:52:27.495
It is not a perfect test.

00:52:27.495 --> 00:52:31.950
It is an in-progress scientific
method that we are trying

00:52:31.950 --> 00:52:32.670
to improve--

00:52:32.670 --> 00:52:35.160
we, meaning, we the field.

00:52:35.160 --> 00:52:38.910
But it will give you a sense
of where your blind spots are.

00:52:38.910 --> 00:52:40.480
You can pick different topics.

00:52:40.480 --> 00:52:43.770
There's at least 20 tests up
there, race, gender, skin tone,

00:52:43.770 --> 00:52:44.820
physical ability.

00:52:44.820 --> 00:52:48.360
It goes on and on, sexual
orientation, religion.

00:52:48.360 --> 00:52:49.635
So that's one place to start.

00:52:49.635 --> 00:52:51.150
The second thing
you can do, there's

00:52:51.150 --> 00:52:54.030
a great story in the book about
Rick Klau, who some of you

00:52:54.030 --> 00:52:58.350
may know at Google Ventures, who
I met at the same conference I

00:52:58.350 --> 00:53:02.005
met you at, Brian, at the Rework
Conference a few years ago.

00:53:02.005 --> 00:53:03.630
BRIAN WELLE: When
you wrote in the book

00:53:03.630 --> 00:53:06.330
that there was that moment
of awkwardness when you were

00:53:06.330 --> 00:53:07.755
trying to get your taxi back.

00:53:07.755 --> 00:53:09.029
It made me feel bad.

00:53:09.029 --> 00:53:10.445
DOLLY CHUGH: It
made you feel bad?

00:53:10.445 --> 00:53:11.730
BRIAN WELLE: I was
like, Dolly, I'm

00:53:11.730 --> 00:53:13.640
so glad you didn't get your
taxi to go back to the airport,

00:53:13.640 --> 00:53:14.270
and you came back.

00:53:14.270 --> 00:53:15.330
DOLLY CHUGH: I was
just saying, they

00:53:15.330 --> 00:53:17.460
had the opening dinner
for the conference.

00:53:17.460 --> 00:53:19.320
And you know when you
arrive at something,

00:53:19.320 --> 00:53:22.650
and there's going to be
that networking thing.

00:53:22.650 --> 00:53:25.326
And you get there, and
there's that moment

00:53:25.326 --> 00:53:26.700
where you have
nobody to talk to,

00:53:26.700 --> 00:53:28.200
and you're just standing there.

00:53:28.200 --> 00:53:31.240
And I just wanted to run
and get my taxi back.

00:53:31.240 --> 00:53:33.540
I could still see it out
of the corner of my eye.

00:53:33.540 --> 00:53:39.890
And then Rick Klau saved the
day and said, hi, I'm Rick.

00:53:39.890 --> 00:53:42.660
So I ended up having what
would have been a small talky

00:53:42.660 --> 00:53:44.220
conversation at the
entrance of what

00:53:44.220 --> 00:53:48.139
was a fantastic conference
in every way with Rick Klau.

00:53:48.139 --> 00:53:49.680
And one of the things
he talked about

00:53:49.680 --> 00:53:54.060
was after he took the IAT,
he got a gender result

00:53:54.060 --> 00:53:55.230
that he wasn't happy with.

00:53:55.230 --> 00:53:58.957
It didn't match his
perception of himself as--

00:53:58.957 --> 00:54:00.540
I'm putting this in
quotes, because he

00:54:00.540 --> 00:54:02.130
cringes every time I say it--

00:54:02.130 --> 00:54:04.230
as one of the "good
guys," meaning someone

00:54:04.230 --> 00:54:07.920
who hires women, promotes
women, creates opportunities

00:54:07.920 --> 00:54:09.690
for under-represented groups.

00:54:09.690 --> 00:54:12.060
He really saw
himself as the person

00:54:12.060 --> 00:54:14.220
who didn't need the
unconscious bias training, who

00:54:14.220 --> 00:54:15.690
didn't need to take the IAT.

00:54:15.690 --> 00:54:19.410
And then when he got the
result, he was taken aback.

00:54:19.410 --> 00:54:22.650
And he thought,
well, I don't know,

00:54:22.650 --> 00:54:25.260
I don't think that's true.

00:54:25.260 --> 00:54:27.090
He's very active
on social media.

00:54:27.090 --> 00:54:29.790
And I think in his particular
role at Google Ventures,

00:54:29.790 --> 00:54:32.790
social media is a really
important part of the platform

00:54:32.790 --> 00:54:34.361
and influence he has.

00:54:34.361 --> 00:54:36.610
So he's like, I don't know
what they're talking about.

00:54:36.610 --> 00:54:39.330
And he starts going through
and running some algorithms

00:54:39.330 --> 00:54:42.960
on who he follows on
LinkedIn, on Twitter,

00:54:42.960 --> 00:54:45.480
who he retweets, who
he's connected with,

00:54:45.480 --> 00:54:46.260
things like that.

00:54:46.260 --> 00:54:52.490
And he kept getting that
his network was 80% male,

00:54:52.490 --> 00:54:55.260
and this was not what
he expected at all.

00:54:55.260 --> 00:54:57.560
And it was consistent
across all the platforms.

00:54:57.560 --> 00:54:59.360
Then he started
noticing on his calendar

00:54:59.360 --> 00:55:03.620
that he'd been sitting on
all-male panels, again,

00:55:03.620 --> 00:55:07.340
an important place where
his voice and platform have

00:55:07.340 --> 00:55:08.330
influence.

00:55:08.330 --> 00:55:11.601
And so he realized through
this little self audit he did--

00:55:11.601 --> 00:55:13.850
and so that would be the
second thing I would suggest,

00:55:13.850 --> 00:55:15.290
is a self audit.

00:55:15.290 --> 00:55:18.950
In his case, he felt like this
network was an important place.

00:55:18.950 --> 00:55:21.350
For you, it might be,
who are the last 10

00:55:21.350 --> 00:55:24.470
people you had coffee chats
with to network about--

00:55:24.470 --> 00:55:27.680
I'm sure you all have friends
who want to work at Google.

00:55:27.680 --> 00:55:29.540
Who are the people
that you're having

00:55:29.540 --> 00:55:31.700
those informal
conversations with?

00:55:31.700 --> 00:55:36.260
If you're a big movie
person or book person,

00:55:36.260 --> 00:55:39.800
what are the last 10 books
or movies you consumed?

00:55:39.800 --> 00:55:42.200
How different were the
voices and experiences

00:55:42.200 --> 00:55:44.480
in those books and
movies from your own,

00:55:44.480 --> 00:55:46.430
versus how similar were
they to each other?

00:55:50.450 --> 00:55:52.730
We're not just dealing with
our implicit associations

00:55:52.730 --> 00:55:55.640
that we've built over
our lives until now.

00:55:55.640 --> 00:55:57.300
We're creating new
ones right now.

00:55:57.300 --> 00:55:59.510
Which ones are you
creating right now?

00:55:59.510 --> 00:56:01.640
Those are things we
can actively change.

00:56:01.640 --> 00:56:03.260
You can change who's
in your network.

00:56:03.260 --> 00:56:05.410
You can change what
you're consuming, what

00:56:05.410 --> 00:56:07.430
you're feeding your brain with.

00:56:07.430 --> 00:56:10.250
I think those are immediate
steps we can take,

00:56:10.250 --> 00:56:16.140
where we don't have to do the
bigger work of systemic change.

00:56:16.140 --> 00:56:17.850
Thank you for your question.

00:56:17.850 --> 00:56:20.000
BRIAN WELLE: We're coming
at the end of time.

00:56:20.000 --> 00:56:23.880
Dolly, thank you so much for
spending time with us today.

00:56:23.880 --> 00:56:27.420
As our new-gler mentioned,
we have an unconscious bias

00:56:27.420 --> 00:56:28.380
curriculum.

00:56:28.380 --> 00:56:30.430
All new hires are invited
to watch this video

00:56:30.430 --> 00:56:31.179
to learn about it.

00:56:31.179 --> 00:56:34.290
And we'll get e-mails
every single week

00:56:34.290 --> 00:56:35.580
after the video goes out.

00:56:35.580 --> 00:56:38.830
And the most common email
is, I want to learn more,

00:56:38.830 --> 00:56:40.770
and I want to know
what I can do.

00:56:40.770 --> 00:56:43.590
And from this point forward, I'm
going to say, read your book,

00:56:43.590 --> 00:56:45.820
because there's a lot of
practical advice there.

00:56:45.820 --> 00:56:46.790
So thank you for
sharing it with us.

00:56:46.790 --> 00:56:48.456
DOLLY CHUGH: I have
such a crush on you.

00:56:48.456 --> 00:56:49.369
[LAUGHTER]

00:56:49.369 --> 00:56:50.410
Thank you so much, Brian.

00:56:50.410 --> 00:56:51.410
Thank you.

00:56:51.410 --> 00:56:52.310
Thank you, everybody.

00:56:52.310 --> 00:56:54.160
[APPLAUSE]

