WEBVTT
Kind: captions
Language: en

00:00:00.050 --> 00:00:05.480
and now for something different a living

00:00:05.480 --> 00:00:05.490
and now for something different a living
 

00:00:05.490 --> 00:00:08.750
and now for something different a living
lab for global impact we're going to try

00:00:08.750 --> 00:00:08.760
lab for global impact we're going to try
 

00:00:08.760 --> 00:00:10.610
lab for global impact we're going to try
and rift off the inspiration that we've

00:00:10.610 --> 00:00:10.620
and rift off the inspiration that we've
 

00:00:10.620 --> 00:00:13.310
and rift off the inspiration that we've
had from last night this morning in this

00:00:13.310 --> 00:00:13.320
had from last night this morning in this
 

00:00:13.320 --> 00:00:16.189
had from last night this morning in this
afternoon so without further ado I'm

00:00:16.189 --> 00:00:16.199
afternoon so without further ado I'm
 

00:00:16.199 --> 00:00:17.480
afternoon so without further ado I'm
going to turn to Jay we're going to

00:00:17.480 --> 00:00:17.490
going to turn to Jay we're going to
 

00:00:17.490 --> 00:00:20.210
going to turn to Jay we're going to
introduce and then I'm gonna lay out a

00:00:20.210 --> 00:00:20.220
introduce and then I'm gonna lay out a
 

00:00:20.220 --> 00:00:24.650
introduce and then I'm gonna lay out a
vision my name's Jay apt I'm a professor

00:00:24.650 --> 00:00:24.660
vision my name's Jay apt I'm a professor
 

00:00:24.660 --> 00:00:27.500
vision my name's Jay apt I'm a professor
here at temper and also in the

00:00:27.500 --> 00:00:27.510
here at temper and also in the
 

00:00:27.510 --> 00:00:29.300
here at temper and also in the
Department of Engineering public policy

00:00:29.300 --> 00:00:29.310
Department of Engineering public policy
 

00:00:29.310 --> 00:00:32.510
Department of Engineering public policy
in CIT my colleague Ranger Morgan and I

00:00:32.510 --> 00:00:32.520
in CIT my colleague Ranger Morgan and I
 

00:00:32.520 --> 00:00:34.340
in CIT my colleague Ranger Morgan and I
co-direct the Carnegie Mellon

00:00:34.340 --> 00:00:34.350
co-direct the Carnegie Mellon
 

00:00:34.350 --> 00:00:37.220
co-direct the Carnegie Mellon
electricity industry Center our Advisory

00:00:37.220 --> 00:00:37.230
electricity industry Center our Advisory
 

00:00:37.230 --> 00:00:38.889
electricity industry Center our Advisory
Committee tells us we're the largest

00:00:38.889 --> 00:00:38.899
Committee tells us we're the largest
 

00:00:38.899 --> 00:00:40.729
Committee tells us we're the largest
interdisciplinary Center in the world

00:00:40.729 --> 00:00:40.739
interdisciplinary Center in the world
 

00:00:40.739 --> 00:00:43.160
interdisciplinary Center in the world
studying how the electric power industry

00:00:43.160 --> 00:00:43.170
studying how the electric power industry
 

00:00:43.170 --> 00:00:47.720
studying how the electric power industry
of tomorrow will get created my name is

00:00:47.720 --> 00:00:47.730
of tomorrow will get created my name is
 

00:00:47.730 --> 00:00:49.639
of tomorrow will get created my name is
Anita Williams Willie I'm an associate

00:00:49.639 --> 00:00:49.649
Anita Williams Willie I'm an associate
 

00:00:49.649 --> 00:00:51.619
Anita Williams Willie I'm an associate
professor of organizational behavior in

00:00:51.619 --> 00:00:51.629
professor of organizational behavior in
 

00:00:51.629 --> 00:00:54.139
professor of organizational behavior in
theory here at The Temper school I study

00:00:54.139 --> 00:00:54.149
theory here at The Temper school I study
 

00:00:54.149 --> 00:00:56.060
theory here at The Temper school I study
collective intelligence and we would

00:00:56.060 --> 00:00:56.070
collective intelligence and we would
 

00:00:56.070 --> 00:00:59.000
collective intelligence and we would
like to find a way to raise levels of

00:00:59.000 --> 00:00:59.010
like to find a way to raise levels of
 

00:00:59.010 --> 00:01:00.889
like to find a way to raise levels of
collective intelligence in groups and

00:01:00.889 --> 00:01:00.899
collective intelligence in groups and
 

00:01:00.899 --> 00:01:02.689
collective intelligence in groups and
across the globe higher than the world

00:01:02.689 --> 00:01:02.699
across the globe higher than the world
 

00:01:02.699 --> 00:01:06.590
across the globe higher than the world
has ever seen I'm a professor in the

00:01:06.590 --> 00:01:06.600
has ever seen I'm a professor in the
 

00:01:06.600 --> 00:01:08.780
has ever seen I'm a professor in the
robotics Institute I am here to

00:01:08.780 --> 00:01:08.790
robotics Institute I am here to
 

00:01:08.790 --> 00:01:10.219
robotics Institute I am here to
represent the AI and robotics

00:01:10.219 --> 00:01:10.229
represent the AI and robotics
 

00:01:10.229 --> 00:01:12.980
represent the AI and robotics
perspective through the work of all of

00:01:12.980 --> 00:01:12.990
perspective through the work of all of
 

00:01:12.990 --> 00:01:14.480
perspective through the work of all of
my colleagues in the robotics Institute

00:01:14.480 --> 00:01:14.490
my colleagues in the robotics Institute
 

00:01:14.490 --> 00:01:17.960
my colleagues in the robotics Institute
of which I am the director I'm Jay

00:01:17.960 --> 00:01:17.970
of which I am the director I'm Jay
 

00:01:17.970 --> 00:01:19.969
of which I am the director I'm Jay
Aronson not J apt and I was actually

00:01:19.969 --> 00:01:19.979
Aronson not J apt and I was actually
 

00:01:19.979 --> 00:01:21.440
Aronson not J apt and I was actually
afraid that J Whittaker would be here

00:01:21.440 --> 00:01:21.450
afraid that J Whittaker would be here
 

00:01:21.450 --> 00:01:23.660
afraid that J Whittaker would be here
and that would be really confusing but

00:01:23.660 --> 00:01:23.670
and that would be really confusing but
 

00:01:23.670 --> 00:01:26.570
and that would be really confusing but
but he's not here today I am a professor

00:01:26.570 --> 00:01:26.580
but he's not here today I am a professor
 

00:01:26.580 --> 00:01:28.340
but he's not here today I am a professor
of science technology and society in the

00:01:28.340 --> 00:01:28.350
of science technology and society in the
 

00:01:28.350 --> 00:01:30.560
of science technology and society in the
history department and I also found it

00:01:30.560 --> 00:01:30.570
history department and I also found it
 

00:01:30.570 --> 00:01:32.539
history department and I also found it
and direct the Center for human rights

00:01:32.539 --> 00:01:32.549
and direct the Center for human rights
 

00:01:32.549 --> 00:01:34.520
and direct the Center for human rights
science and the goal of the center is

00:01:34.520 --> 00:01:34.530
science and the goal of the center is
 

00:01:34.530 --> 00:01:35.780
science and the goal of the center is
really to level the playing field

00:01:35.780 --> 00:01:35.790
really to level the playing field
 

00:01:35.790 --> 00:01:38.090
really to level the playing field
between government corporate and

00:01:38.090 --> 00:01:38.100
between government corporate and
 

00:01:38.100 --> 00:01:39.740
between government corporate and
military actors who start with a great

00:01:39.740 --> 00:01:39.750
military actors who start with a great
 

00:01:39.750 --> 00:01:41.929
military actors who start with a great
technological advantage and the human

00:01:41.929 --> 00:01:41.939
technological advantage and the human
 

00:01:41.939 --> 00:01:44.359
technological advantage and the human
rights advocates and institutions who

00:01:44.359 --> 00:01:44.369
rights advocates and institutions who
 

00:01:44.369 --> 00:01:46.730
rights advocates and institutions who
hold them accountable I'm Sarah

00:01:46.730 --> 00:01:46.740
hold them accountable I'm Sarah
 

00:01:46.740 --> 00:01:48.350
hold them accountable I'm Sarah
Mendelson I'm the head of the Hyatts

00:01:48.350 --> 00:01:48.360
Mendelson I'm the head of the Hyatts
 

00:01:48.360 --> 00:01:50.389
Mendelson I'm the head of the Hyatts
program in Washington DC and a

00:01:50.389 --> 00:01:50.399
program in Washington DC and a
 

00:01:50.399 --> 00:01:51.920
program in Washington DC and a
distinguished service professor of

00:01:51.920 --> 00:01:51.930
distinguished service professor of
 

00:01:51.930 --> 00:01:54.649
distinguished service professor of
public policy I'm also a Human Rights

00:01:54.649 --> 00:01:54.659
public policy I'm also a Human Rights
 

00:01:54.659 --> 00:01:57.670
public policy I'm also a Human Rights
practitioner and scholar Russia scholar

00:01:57.670 --> 00:01:57.680
practitioner and scholar Russia scholar
 

00:01:57.680 --> 00:02:01.340
practitioner and scholar Russia scholar
and development specialist and I'm going

00:02:01.340 --> 00:02:01.350
and development specialist and I'm going
 

00:02:01.350 --> 00:02:03.649
and development specialist and I'm going
to talk to you today about growing the

00:02:03.649 --> 00:02:03.659
to talk to you today about growing the
 

00:02:03.659 --> 00:02:05.840
to talk to you today about growing the
generation that will demand and deliver

00:02:05.840 --> 00:02:05.850
generation that will demand and deliver
 

00:02:05.850 --> 00:02:10.999
generation that will demand and deliver
the sustainable development goals can we

00:02:10.999 --> 00:02:11.009
the sustainable development goals can we
 

00:02:11.009 --> 00:02:12.770
the sustainable development goals can we
have the periodic chart up there we go

00:02:12.770 --> 00:02:12.780
have the periodic chart up there we go
 

00:02:12.780 --> 00:02:14.000
have the periodic chart up there we go
the what this

00:02:14.000 --> 00:02:14.010
the what this
 

00:02:14.010 --> 00:02:16.789
the what this
stainable Development Goals so three

00:02:16.789 --> 00:02:16.799
stainable Development Goals so three
 

00:02:16.799 --> 00:02:20.479
stainable Development Goals so three
years ago in September 2015 we the

00:02:20.479 --> 00:02:20.489
years ago in September 2015 we the
 

00:02:20.489 --> 00:02:22.160
years ago in September 2015 we the
international community did something

00:02:22.160 --> 00:02:22.170
international community did something
 

00:02:22.170 --> 00:02:25.369
international community did something
truly remarkable we agreed on an agenda

00:02:25.369 --> 00:02:25.379
truly remarkable we agreed on an agenda
 

00:02:25.379 --> 00:02:29.839
truly remarkable we agreed on an agenda
that will run through till 2030 to make

00:02:29.839 --> 00:02:29.849
that will run through till 2030 to make
 

00:02:29.849 --> 00:02:32.449
that will run through till 2030 to make
the world a more peaceful just inclusive

00:02:32.449 --> 00:02:32.459
the world a more peaceful just inclusive
 

00:02:32.459 --> 00:02:35.210
the world a more peaceful just inclusive
planet to radically reduce poverty and

00:02:35.210 --> 00:02:35.220
planet to radically reduce poverty and
 

00:02:35.220 --> 00:02:38.960
planet to radically reduce poverty and
to address climate change among 17 other

00:02:38.960 --> 00:02:38.970
to address climate change among 17 other
 

00:02:38.970 --> 00:02:42.349
to address climate change among 17 other
goals 169 targets you're looking at the

00:02:42.349 --> 00:02:42.359
goals 169 targets you're looking at the
 

00:02:42.359 --> 00:02:43.220
goals 169 targets you're looking at the
periodic chart

00:02:43.220 --> 00:02:43.230
periodic chart
 

00:02:43.230 --> 00:02:45.530
periodic chart
now this agenda called the sustainable

00:02:45.530 --> 00:02:45.540
now this agenda called the sustainable
 

00:02:45.540 --> 00:02:48.500
now this agenda called the sustainable
development goals or the SDGs emerged

00:02:48.500 --> 00:02:48.510
development goals or the SDGs emerged
 

00:02:48.510 --> 00:02:50.780
development goals or the SDGs emerged
after years of negotiation and

00:02:50.780 --> 00:02:50.790
after years of negotiation and
 

00:02:50.790 --> 00:02:52.520
after years of negotiation and
engagement with millions of people

00:02:52.520 --> 00:02:52.530
engagement with millions of people
 

00:02:52.530 --> 00:02:54.979
engagement with millions of people
around the world especially with young

00:02:54.979 --> 00:02:54.989
around the world especially with young
 

00:02:54.989 --> 00:02:58.280
around the world especially with young
people this agenda applies to all of us

00:02:58.280 --> 00:02:58.290
people this agenda applies to all of us
 

00:02:58.290 --> 00:03:01.309
people this agenda applies to all of us
and I think it is a great framework for

00:03:01.309 --> 00:03:01.319
and I think it is a great framework for
 

00:03:01.319 --> 00:03:02.990
and I think it is a great framework for
the work that goes on at Carnegie Mellon

00:03:02.990 --> 00:03:03.000
the work that goes on at Carnegie Mellon
 

00:03:03.000 --> 00:03:05.809
the work that goes on at Carnegie Mellon
University that these goals are

00:03:05.809 --> 00:03:05.819
University that these goals are
 

00:03:05.819 --> 00:03:09.229
University that these goals are
universal represents a pretty profound

00:03:09.229 --> 00:03:09.239
universal represents a pretty profound
 

00:03:09.239 --> 00:03:11.390
universal represents a pretty profound
paradigm shift in Development Studies

00:03:11.390 --> 00:03:11.400
paradigm shift in Development Studies
 

00:03:11.400 --> 00:03:13.580
paradigm shift in Development Studies
this is not about the global North

00:03:13.580 --> 00:03:13.590
this is not about the global North
 

00:03:13.590 --> 00:03:15.800
this is not about the global North
talking to the global South this is

00:03:15.800 --> 00:03:15.810
talking to the global South this is
 

00:03:15.810 --> 00:03:18.890
talking to the global South this is
about recognizing that all of us every

00:03:18.890 --> 00:03:18.900
about recognizing that all of us every
 

00:03:18.900 --> 00:03:21.020
about recognizing that all of us every
country every society we in the United

00:03:21.020 --> 00:03:21.030
country every society we in the United
 

00:03:21.030 --> 00:03:23.360
country every society we in the United
States also are in a process of

00:03:23.360 --> 00:03:23.370
States also are in a process of
 

00:03:23.370 --> 00:03:26.180
States also are in a process of
developing maybe the most important

00:03:26.180 --> 00:03:26.190
developing maybe the most important
 

00:03:26.190 --> 00:03:29.119
developing maybe the most important
aspect of this is the need to listen and

00:03:29.119 --> 00:03:29.129
aspect of this is the need to listen and
 

00:03:29.129 --> 00:03:32.180
aspect of this is the need to listen and
respond to citizens to people whether in

00:03:32.180 --> 00:03:32.190
respond to citizens to people whether in
 

00:03:32.190 --> 00:03:35.089
respond to citizens to people whether in
downtown Pittsburgh in Paris in Prague

00:03:35.089 --> 00:03:35.099
downtown Pittsburgh in Paris in Prague
 

00:03:35.099 --> 00:03:38.599
downtown Pittsburgh in Paris in Prague
or in Panama City and while this agenda

00:03:38.599 --> 00:03:38.609
or in Panama City and while this agenda
 

00:03:38.609 --> 00:03:40.460
or in Panama City and while this agenda
was launched at the UN where I had the

00:03:40.460 --> 00:03:40.470
was launched at the UN where I had the
 

00:03:40.470 --> 00:03:43.189
was launched at the UN where I had the
privilege to serve in order for this

00:03:43.189 --> 00:03:43.199
privilege to serve in order for this
 

00:03:43.199 --> 00:03:46.039
privilege to serve in order for this
agenda to have an impact it has to be

00:03:46.039 --> 00:03:46.049
agenda to have an impact it has to be
 

00:03:46.049 --> 00:03:48.800
agenda to have an impact it has to be
locally owned you shouldn't think about

00:03:48.800 --> 00:03:48.810
locally owned you shouldn't think about
 

00:03:48.810 --> 00:03:51.289
locally owned you shouldn't think about
these as the UN goals you should think

00:03:51.289 --> 00:03:51.299
these as the UN goals you should think
 

00:03:51.299 --> 00:03:53.300
these as the UN goals you should think
of them as our goals or the global goals

00:03:53.300 --> 00:03:53.310
of them as our goals or the global goals
 

00:03:53.310 --> 00:03:55.789
of them as our goals or the global goals
now this agenda can help address

00:03:55.789 --> 00:03:55.799
now this agenda can help address
 

00:03:55.799 --> 00:03:58.129
now this agenda can help address
pressing issues that are before our

00:03:58.129 --> 00:03:58.139
pressing issues that are before our
 

00:03:58.139 --> 00:04:00.500
pressing issues that are before our
country and I would argue it can help

00:04:00.500 --> 00:04:00.510
country and I would argue it can help
 

00:04:00.510 --> 00:04:03.470
country and I would argue it can help
support democracy dignity truth and

00:04:03.470 --> 00:04:03.480
support democracy dignity truth and
 

00:04:03.480 --> 00:04:06.319
support democracy dignity truth and
freedom of expression in other words

00:04:06.319 --> 00:04:06.329
freedom of expression in other words
 

00:04:06.329 --> 00:04:09.289
freedom of expression in other words
these goals can help shore up what we

00:04:09.289 --> 00:04:09.299
these goals can help shore up what we
 

00:04:09.299 --> 00:04:11.089
these goals can help shore up what we
call the liberal world order so that's

00:04:11.089 --> 00:04:11.099
call the liberal world order so that's
 

00:04:11.099 --> 00:04:13.580
call the liberal world order so that's
all good news the less good news is that

00:04:13.580 --> 00:04:13.590
all good news the less good news is that
 

00:04:13.590 --> 00:04:16.339
all good news the less good news is that
very few people know about the SDGs now

00:04:16.339 --> 00:04:16.349
very few people know about the SDGs now
 

00:04:16.349 --> 00:04:18.379
very few people know about the SDGs now
I think this is about to change and it's

00:04:18.379 --> 00:04:18.389
I think this is about to change and it's
 

00:04:18.389 --> 00:04:19.789
I think this is about to change and it's
going to change for a couple reasons

00:04:19.789 --> 00:04:19.799
going to change for a couple reasons
 

00:04:19.799 --> 00:04:22.580
going to change for a couple reasons
not the least of which is that in 2019

00:04:22.580 --> 00:04:22.590
not the least of which is that in 2019
 

00:04:22.590 --> 00:04:24.110
not the least of which is that in 2019
they're going to be several heads of

00:04:24.110 --> 00:04:24.120
they're going to be several heads of
 

00:04:24.120 --> 00:04:27.480
they're going to be several heads of
state meetings on the SDGs and that

00:04:27.480 --> 00:04:27.490
state meetings on the SDGs and that
 

00:04:27.490 --> 00:04:30.749
state meetings on the SDGs and that
a tendency to propel action so it's

00:04:30.749 --> 00:04:30.759
a tendency to propel action so it's
 

00:04:30.759 --> 00:04:33.330
a tendency to propel action so it's
gonna be in the air but we need to grow

00:04:33.330 --> 00:04:33.340
gonna be in the air but we need to grow
 

00:04:33.340 --> 00:04:35.939
gonna be in the air but we need to grow
now the generation that is going to

00:04:35.939 --> 00:04:35.949
now the generation that is going to
 

00:04:35.949 --> 00:04:38.700
now the generation that is going to
demand and deliver the SDGs what I call

00:04:38.700 --> 00:04:38.710
demand and deliver the SDGs what I call
 

00:04:38.710 --> 00:04:40.490
demand and deliver the SDGs what I call
cohort 2030

00:04:40.490 --> 00:04:40.500
cohort 2030
 

00:04:40.500 --> 00:04:45.029
cohort 2030
what's cohort 2030 these are global

00:04:45.029 --> 00:04:45.039
what's cohort 2030 these are global
 

00:04:45.039 --> 00:04:47.909
what's cohort 2030 these are global
citizens born after 1980 who are tech

00:04:47.909 --> 00:04:47.919
citizens born after 1980 who are tech
 

00:04:47.919 --> 00:04:50.360
citizens born after 1980 who are tech
savvy they're are digitally fluent and

00:04:50.360 --> 00:04:50.370
savvy they're are digitally fluent and
 

00:04:50.370 --> 00:04:53.309
savvy they're are digitally fluent and
generally they want to use their their

00:04:53.309 --> 00:04:53.319
generally they want to use their their
 

00:04:53.319 --> 00:04:55.950
generally they want to use their their
tech skills to solve societal problems

00:04:55.950 --> 00:04:55.960
tech skills to solve societal problems
 

00:04:55.960 --> 00:04:57.420
tech skills to solve societal problems
these are the Public Interest

00:04:57.420 --> 00:04:57.430
these are the Public Interest
 

00:04:57.430 --> 00:04:59.790
these are the Public Interest
technologists they tend to be very

00:04:59.790 --> 00:04:59.800
technologists they tend to be very
 

00:04:59.800 --> 00:05:02.129
technologists they tend to be very
intolerant of corruption and this is a

00:05:02.129 --> 00:05:02.139
intolerant of corruption and this is a
 

00:05:02.139 --> 00:05:03.600
intolerant of corruption and this is a
real Achilles heel for a lot of

00:05:03.600 --> 00:05:03.610
real Achilles heel for a lot of
 

00:05:03.610 --> 00:05:05.820
real Achilles heel for a lot of
dictators around the world they're very

00:05:05.820 --> 00:05:05.830
dictators around the world they're very
 

00:05:05.830 --> 00:05:08.430
dictators around the world they're very
focused on reducing inequality a lot of

00:05:08.430 --> 00:05:08.440
focused on reducing inequality a lot of
 

00:05:08.440 --> 00:05:09.899
focused on reducing inequality a lot of
these people you see it in their

00:05:09.899 --> 00:05:09.909
these people you see it in their
 

00:05:09.909 --> 00:05:11.640
these people you see it in their
applications they live through the

00:05:11.640 --> 00:05:11.650
applications they live through the
 

00:05:11.650 --> 00:05:14.070
applications they live through the
global recession of 2008 they're very

00:05:14.070 --> 00:05:14.080
global recession of 2008 they're very
 

00:05:14.080 --> 00:05:14.969
global recession of 2008 they're very
sensitive to it

00:05:14.969 --> 00:05:14.979
sensitive to it
 

00:05:14.979 --> 00:05:17.279
sensitive to it
they are generally very interested in

00:05:17.279 --> 00:05:17.289
they are generally very interested in
 

00:05:17.289 --> 00:05:20.339
they are generally very interested in
diversity inclusivity whether it's on

00:05:20.339 --> 00:05:20.349
diversity inclusivity whether it's on
 

00:05:20.349 --> 00:05:23.640
diversity inclusivity whether it's on
LGBT gender disabilities of course they

00:05:23.640 --> 00:05:23.650
LGBT gender disabilities of course they
 

00:05:23.650 --> 00:05:26.040
LGBT gender disabilities of course they
want to address climate change generally

00:05:26.040 --> 00:05:26.050
want to address climate change generally
 

00:05:26.050 --> 00:05:27.689
want to address climate change generally
they're interested in ethically sourced

00:05:27.689 --> 00:05:27.699
they're interested in ethically sourced
 

00:05:27.699 --> 00:05:31.010
they're interested in ethically sourced
products sounds like CMU students right

00:05:31.010 --> 00:05:31.020
products sounds like CMU students right
 

00:05:31.020 --> 00:05:33.570
products sounds like CMU students right
so the challenge is how do we grow

00:05:33.570 --> 00:05:33.580
so the challenge is how do we grow
 

00:05:33.580 --> 00:05:36.270
so the challenge is how do we grow
cohort 2030 and what I'm laying out here

00:05:36.270 --> 00:05:36.280
cohort 2030 and what I'm laying out here
 

00:05:36.280 --> 00:05:38.999
cohort 2030 and what I'm laying out here
for you is in the early months of

00:05:38.999 --> 00:05:39.009
for you is in the early months of
 

00:05:39.009 --> 00:05:40.920
for you is in the early months of
starting this now I'm also in the early

00:05:40.920 --> 00:05:40.930
starting this now I'm also in the early
 

00:05:40.930 --> 00:05:42.480
starting this now I'm also in the early
months of being part of the CMU

00:05:42.480 --> 00:05:42.490
months of being part of the CMU
 

00:05:42.490 --> 00:05:44.909
months of being part of the CMU
community this work is being done in

00:05:44.909 --> 00:05:44.919
community this work is being done in
 

00:05:44.919 --> 00:05:47.189
community this work is being done in
collaboration with the Rockefeller

00:05:47.189 --> 00:05:47.199
collaboration with the Rockefeller
 

00:05:47.199 --> 00:05:48.689
collaboration with the Rockefeller
Foundation but also an organization

00:05:48.689 --> 00:05:48.699
Foundation but also an organization
 

00:05:48.699 --> 00:05:50.310
Foundation but also an organization
called the International Youth

00:05:50.310 --> 00:05:50.320
called the International Youth
 

00:05:50.320 --> 00:05:53.010
called the International Youth
Foundation the president of which is a

00:05:53.010 --> 00:05:53.020
Foundation the president of which is a
 

00:05:53.020 --> 00:05:54.749
Foundation the president of which is a
woman named Susan Reich Lee who has been

00:05:54.749 --> 00:05:54.759
woman named Susan Reich Lee who has been
 

00:05:54.759 --> 00:05:57.330
woman named Susan Reich Lee who has been
an adjunct faculty member for heights in

00:05:57.330 --> 00:05:57.340
an adjunct faculty member for heights in
 

00:05:57.340 --> 00:06:00.089
an adjunct faculty member for heights in
Washington DC for several years so

00:06:00.089 --> 00:06:00.099
Washington DC for several years so
 

00:06:00.099 --> 00:06:01.709
Washington DC for several years so
here's what we're trying to do together

00:06:01.709 --> 00:06:01.719
here's what we're trying to do together
 

00:06:01.719 --> 00:06:04.770
here's what we're trying to do together
the first strategy is we're trying to

00:06:04.770 --> 00:06:04.780
the first strategy is we're trying to
 

00:06:04.780 --> 00:06:07.529
the first strategy is we're trying to
identify outstanding examples of cohort

00:06:07.529 --> 00:06:07.539
identify outstanding examples of cohort
 

00:06:07.539 --> 00:06:09.749
identify outstanding examples of cohort
2030 young people who are already

00:06:09.749 --> 00:06:09.759
2030 young people who are already
 

00:06:09.759 --> 00:06:11.820
2030 young people who are already
working on the SDGs and bring them

00:06:11.820 --> 00:06:11.830
working on the SDGs and bring them
 

00:06:11.830 --> 00:06:14.300
working on the SDGs and bring them
together so can we go to the next slide

00:06:14.300 --> 00:06:14.310
together so can we go to the next slide
 

00:06:14.310 --> 00:06:17.610
together so can we go to the next slide
this is ladies and gentlemen cohort 2030

00:06:17.610 --> 00:06:17.620
this is ladies and gentlemen cohort 2030
 

00:06:17.620 --> 00:06:20.100
this is ladies and gentlemen cohort 2030
this is at the Bellagio Center in Italy

00:06:20.100 --> 00:06:20.110
this is at the Bellagio Center in Italy
 

00:06:20.110 --> 00:06:22.890
this is at the Bellagio Center in Italy
this summer after an international

00:06:22.890 --> 00:06:22.900
this summer after an international
 

00:06:22.900 --> 00:06:25.649
this summer after an international
competition we were able to select 20

00:06:25.649 --> 00:06:25.659
competition we were able to select 20
 

00:06:25.659 --> 00:06:27.990
competition we were able to select 20
people from around the world including a

00:06:27.990 --> 00:06:28.000
people from around the world including a
 

00:06:28.000 --> 00:06:31.230
people from around the world including a
Heinz alum which was a random thing we

00:06:31.230 --> 00:06:31.240
Heinz alum which was a random thing we
 

00:06:31.240 --> 00:06:33.180
Heinz alum which was a random thing we
didn't set out to choose or include a

00:06:33.180 --> 00:06:33.190
didn't set out to choose or include a
 

00:06:33.190 --> 00:06:36.260
didn't set out to choose or include a
Heinz person but she she really shone

00:06:36.260 --> 00:06:36.270
Heinz person but she she really shone
 

00:06:36.270 --> 00:06:39.409
Heinz person but she she really shone
another strategy is addressing data gaps

00:06:39.409 --> 00:06:39.419
another strategy is addressing data gaps
 

00:06:39.419 --> 00:06:41.439
another strategy is addressing data gaps
we really want to know

00:06:41.439 --> 00:06:41.449
we really want to know
 

00:06:41.449 --> 00:06:43.769
we really want to know
at cohort 2030 in any given location

00:06:43.769 --> 00:06:43.779
at cohort 2030 in any given location
 

00:06:43.779 --> 00:06:46.540
at cohort 2030 in any given location
thinks about where their passion points

00:06:46.540 --> 00:06:46.550
thinks about where their passion points
 

00:06:46.550 --> 00:06:49.390
thinks about where their passion points
are related to the SDGs we want the data

00:06:49.390 --> 00:06:49.400
are related to the SDGs we want the data
 

00:06:49.400 --> 00:06:51.399
are related to the SDGs we want the data
to be able to impact policy and we look

00:06:51.399 --> 00:06:51.409
to be able to impact policy and we look
 

00:06:51.409 --> 00:06:52.749
to be able to impact policy and we look
forward to working with cities and

00:06:52.749 --> 00:06:52.759
forward to working with cities and
 

00:06:52.759 --> 00:06:55.450
forward to working with cities and
especially mayor's who are interested in

00:06:55.450 --> 00:06:55.460
especially mayor's who are interested in
 

00:06:55.460 --> 00:06:57.969
especially mayor's who are interested in
the sustainable development goals what

00:06:57.969 --> 00:06:57.979
the sustainable development goals what
 

00:06:57.979 --> 00:07:00.339
the sustainable development goals what
better place to start than in Pittsburgh

00:07:00.339 --> 00:07:00.349
better place to start than in Pittsburgh
 

00:07:00.349 --> 00:07:02.230
better place to start than in Pittsburgh
and we have a private sector partner

00:07:02.230 --> 00:07:02.240
and we have a private sector partner
 

00:07:02.240 --> 00:07:04.360
and we have a private sector partner
who'll be doing that with us in the

00:07:04.360 --> 00:07:04.370
who'll be doing that with us in the
 

00:07:04.370 --> 00:07:06.519
who'll be doing that with us in the
coming months the most important

00:07:06.519 --> 00:07:06.529
coming months the most important
 

00:07:06.529 --> 00:07:08.469
coming months the most important
long-term strategy for growing cohort

00:07:08.469 --> 00:07:08.479
long-term strategy for growing cohort
 

00:07:08.479 --> 00:07:10.980
long-term strategy for growing cohort
2030 is of course the university

00:07:10.980 --> 00:07:10.990
2030 is of course the university
 

00:07:10.990 --> 00:07:13.749
2030 is of course the university
teaching training and researching the

00:07:13.749 --> 00:07:13.759
teaching training and researching the
 

00:07:13.759 --> 00:07:16.839
teaching training and researching the
SDGs it's about field building the next

00:07:16.839 --> 00:07:16.849
SDGs it's about field building the next
 

00:07:16.849 --> 00:07:19.600
SDGs it's about field building the next
generation of solvers skilled and using

00:07:19.600 --> 00:07:19.610
generation of solvers skilled and using
 

00:07:19.610 --> 00:07:23.409
generation of solvers skilled and using
data and tech to deliver the SDGs this

00:07:23.409 --> 00:07:23.419
data and tech to deliver the SDGs this
 

00:07:23.419 --> 00:07:25.510
data and tech to deliver the SDGs this
of course includes high it's college but

00:07:25.510 --> 00:07:25.520
of course includes high it's college but
 

00:07:25.520 --> 00:07:27.579
of course includes high it's college but
it could also include computer science

00:07:27.579 --> 00:07:27.589
it could also include computer science
 

00:07:27.589 --> 00:07:30.640
it could also include computer science
social scientists business engineering

00:07:30.640 --> 00:07:30.650
social scientists business engineering
 

00:07:30.650 --> 00:07:35.769
social scientists business engineering
and arts and entertainment the strategy

00:07:35.769 --> 00:07:35.779
and arts and entertainment the strategy
 

00:07:35.779 --> 00:07:37.649
and arts and entertainment the strategy
also includes experimental learning

00:07:37.649 --> 00:07:37.659
also includes experimental learning
 

00:07:37.659 --> 00:07:40.749
also includes experimental learning
capstone students capstone projects that

00:07:40.749 --> 00:07:40.759
capstone students capstone projects that
 

00:07:40.759 --> 00:07:43.389
capstone students capstone projects that
students are already doing on the SDGs

00:07:43.389 --> 00:07:43.399
students are already doing on the SDGs
 

00:07:43.399 --> 00:07:45.850
students are already doing on the SDGs
it's about our alums who for example are

00:07:45.850 --> 00:07:45.860
it's about our alums who for example are
 

00:07:45.860 --> 00:07:48.010
it's about our alums who for example are
working on reducing food waste here in

00:07:48.010 --> 00:07:48.020
working on reducing food waste here in
 

00:07:48.020 --> 00:07:50.529
working on reducing food waste here in
Pittsburgh now while not necessarily

00:07:50.529 --> 00:07:50.539
Pittsburgh now while not necessarily
 

00:07:50.539 --> 00:07:52.959
Pittsburgh now while not necessarily
under the rubric of the SDGs there is

00:07:52.959 --> 00:07:52.969
under the rubric of the SDGs there is
 

00:07:52.969 --> 00:07:55.480
under the rubric of the SDGs there is
obviously a ton of work going on at CMU

00:07:55.480 --> 00:07:55.490
obviously a ton of work going on at CMU
 

00:07:55.490 --> 00:07:56.829
obviously a ton of work going on at CMU
I think you've even heard about it this

00:07:56.829 --> 00:07:56.839
I think you've even heard about it this
 

00:07:56.839 --> 00:07:58.959
I think you've even heard about it this
afternoon that could be considered

00:07:58.959 --> 00:07:58.969
afternoon that could be considered
 

00:07:58.969 --> 00:08:01.420
afternoon that could be considered
relevant including at the Scott

00:08:01.420 --> 00:08:01.430
relevant including at the Scott
 

00:08:01.430 --> 00:08:03.639
relevant including at the Scott
Institute for energy innovation the

00:08:03.639 --> 00:08:03.649
Institute for energy innovation the
 

00:08:03.649 --> 00:08:06.189
Institute for energy innovation the
Steinbrenner Institute for environment

00:08:06.189 --> 00:08:06.199
Steinbrenner Institute for environment
 

00:08:06.199 --> 00:08:08.260
Steinbrenner Institute for environment
education and research the work that

00:08:08.260 --> 00:08:08.270
education and research the work that
 

00:08:08.270 --> 00:08:11.439
education and research the work that
goes on at metro 21 and the block Center

00:08:11.439 --> 00:08:11.449
goes on at metro 21 and the block Center
 

00:08:11.449 --> 00:08:13.869
goes on at metro 21 and the block Center
for technology in society there is room

00:08:13.869 --> 00:08:13.879
for technology in society there is room
 

00:08:13.879 --> 00:08:15.879
for technology in society there is room
for growth the strategy could involve

00:08:15.879 --> 00:08:15.889
for growth the strategy could involve
 

00:08:15.889 --> 00:08:18.670
for growth the strategy could involve
educating undergraduates to be literate

00:08:18.670 --> 00:08:18.680
educating undergraduates to be literate
 

00:08:18.680 --> 00:08:20.649
educating undergraduates to be literate
in the SDGs it could involve

00:08:20.649 --> 00:08:20.659
in the SDGs it could involve
 

00:08:20.659 --> 00:08:23.019
in the SDGs it could involve
collaboration with other great American

00:08:23.019 --> 00:08:23.029
collaboration with other great American
 

00:08:23.029 --> 00:08:25.269
collaboration with other great American
universities that are already aligning

00:08:25.269 --> 00:08:25.279
universities that are already aligning
 

00:08:25.279 --> 00:08:27.939
universities that are already aligning
with the SDGs it could involve CMU

00:08:27.939 --> 00:08:27.949
with the SDGs it could involve CMU
 

00:08:27.949 --> 00:08:31.179
with the SDGs it could involve CMU
Africa and the SDG Center for Africa

00:08:31.179 --> 00:08:31.189
Africa and the SDG Center for Africa
 

00:08:31.189 --> 00:08:33.600
Africa and the SDG Center for Africa
which is also based in Kigali Rwanda

00:08:33.600 --> 00:08:33.610
which is also based in Kigali Rwanda
 

00:08:33.610 --> 00:08:35.800
which is also based in Kigali Rwanda
together supporting experimental

00:08:35.800 --> 00:08:35.810
together supporting experimental
 

00:08:35.810 --> 00:08:38.050
together supporting experimental
learning and research it could mean

00:08:38.050 --> 00:08:38.060
learning and research it could mean
 

00:08:38.060 --> 00:08:40.110
learning and research it could mean
working on delivering outstanding

00:08:40.110 --> 00:08:40.120
working on delivering outstanding
 

00:08:40.120 --> 00:08:43.449
working on delivering outstanding
rankings as Times Higher Education in

00:08:43.449 --> 00:08:43.459
rankings as Times Higher Education in
 

00:08:43.459 --> 00:08:46.750
rankings as Times Higher Education in
2019 begins to measure how universities

00:08:46.750 --> 00:08:46.760
2019 begins to measure how universities
 

00:08:46.760 --> 00:08:49.540
2019 begins to measure how universities
are advancing the SDGs you get the point

00:08:49.540 --> 00:08:49.550
are advancing the SDGs you get the point
 

00:08:49.550 --> 00:08:51.730
are advancing the SDGs you get the point
there's a significant amount of work

00:08:51.730 --> 00:08:51.740
there's a significant amount of work
 

00:08:51.740 --> 00:08:53.679
there's a significant amount of work
that funders are doing foundations

00:08:53.679 --> 00:08:53.689
that funders are doing foundations
 

00:08:53.689 --> 00:08:55.150
that funders are doing foundations
corporations

00:08:55.150 --> 00:08:55.160
corporations
 

00:08:55.160 --> 00:08:56.860
corporations
creating partnerships to deliver the

00:08:56.860 --> 00:08:56.870
creating partnerships to deliver the
 

00:08:56.870 --> 00:08:59.949
creating partnerships to deliver the
SDGs around the globe by aligning the

00:08:59.949 --> 00:08:59.959
SDGs around the globe by aligning the
 

00:08:59.959 --> 00:09:02.619
SDGs around the globe by aligning the
work with st geez we not only have a

00:09:02.619 --> 00:09:02.629
work with st geez we not only have a
 

00:09:02.629 --> 00:09:04.869
work with st geez we not only have a
common framework we'd be able to

00:09:04.869 --> 00:09:04.879
common framework we'd be able to
 

00:09:04.879 --> 00:09:07.389
common framework we'd be able to
highlight our global impact for this

00:09:07.389 --> 00:09:07.399
highlight our global impact for this
 

00:09:07.399 --> 00:09:10.360
highlight our global impact for this
next generation as it is determined to

00:09:10.360 --> 00:09:10.370
next generation as it is determined to
 

00:09:10.370 --> 00:09:11.710
next generation as it is determined to
leave no one behind

00:09:11.710 --> 00:09:11.720
leave no one behind
 

00:09:11.720 --> 00:09:14.619
leave no one behind
reduce corruption increase education for

00:09:14.619 --> 00:09:14.629
reduce corruption increase education for
 

00:09:14.629 --> 00:09:17.230
reduce corruption increase education for
girls and human trafficking reduce

00:09:17.230 --> 00:09:17.240
girls and human trafficking reduce
 

00:09:17.240 --> 00:09:20.139
girls and human trafficking reduce
violence make electricity accessible for

00:09:20.139 --> 00:09:20.149
violence make electricity accessible for
 

00:09:20.149 --> 00:09:22.509
violence make electricity accessible for
all so let me stop there and say that

00:09:22.509 --> 00:09:22.519
all so let me stop there and say that
 

00:09:22.519 --> 00:09:23.980
all so let me stop there and say that
anyone in the university who wants to

00:09:23.980 --> 00:09:23.990
anyone in the university who wants to
 

00:09:23.990 --> 00:09:26.740
anyone in the university who wants to
know more about cohort 2030 or the SDGs

00:09:26.740 --> 00:09:26.750
know more about cohort 2030 or the SDGs
 

00:09:26.750 --> 00:09:29.319
know more about cohort 2030 or the SDGs
their email address at the bottom cohort

00:09:29.319 --> 00:09:29.329
their email address at the bottom cohort
 

00:09:29.329 --> 00:09:33.790
their email address at the bottom cohort
2030 at andrews CMU edu or email me s

00:09:33.790 --> 00:09:33.800
2030 at andrews CMU edu or email me s
 

00:09:33.800 --> 00:09:38.230
2030 at andrews CMU edu or email me s
Mendelson at CMU edu now rather than

00:09:38.230 --> 00:09:38.240
Mendelson at CMU edu now rather than
 

00:09:38.240 --> 00:09:41.679
Mendelson at CMU edu now rather than
think of the SDGs as 17 separate goals

00:09:41.679 --> 00:09:41.689
think of the SDGs as 17 separate goals
 

00:09:41.689 --> 00:09:44.230
think of the SDGs as 17 separate goals
the best practice these days is to think

00:09:44.230 --> 00:09:44.240
the best practice these days is to think
 

00:09:44.240 --> 00:09:46.540
the best practice these days is to think
in terms of interconnectedness the

00:09:46.540 --> 00:09:46.550
in terms of interconnectedness the
 

00:09:46.550 --> 00:09:48.910
in terms of interconnectedness the
clusters whether it's in climate change

00:09:48.910 --> 00:09:48.920
clusters whether it's in climate change
 

00:09:48.920 --> 00:09:51.340
clusters whether it's in climate change
or the cluster that Isak human rights

00:09:51.340 --> 00:09:51.350
or the cluster that Isak human rights
 

00:09:51.350 --> 00:09:53.619
or the cluster that Isak human rights
activism particularly interested in the

00:09:53.619 --> 00:09:53.629
activism particularly interested in the
 

00:09:53.629 --> 00:09:56.110
activism particularly interested in the
goal of making our societies more

00:09:56.110 --> 00:09:56.120
goal of making our societies more
 

00:09:56.120 --> 00:09:59.079
goal of making our societies more
peaceful just and inclusive now let's

00:09:59.079 --> 00:09:59.089
peaceful just and inclusive now let's
 

00:09:59.089 --> 00:10:00.999
peaceful just and inclusive now let's
talk about interconnectedness for the

00:10:00.999 --> 00:10:01.009
talk about interconnectedness for the
 

00:10:01.009 --> 00:10:03.340
talk about interconnectedness for the
work that we're doing aspects including

00:10:03.340 --> 00:10:03.350
work that we're doing aspects including
 

00:10:03.350 --> 00:10:07.269
work that we're doing aspects including
culture politics economics societal

00:10:07.269 --> 00:10:07.279
culture politics economics societal
 

00:10:07.279 --> 00:10:09.249
culture politics economics societal
issues all come into play

00:10:09.249 --> 00:10:09.259
issues all come into play
 

00:10:09.259 --> 00:10:11.769
issues all come into play
probably in energy you see as much the

00:10:11.769 --> 00:10:11.779
probably in energy you see as much the
 

00:10:11.779 --> 00:10:15.100
probably in energy you see as much the
politics of anything i as in in any of

00:10:15.100 --> 00:10:15.110
politics of anything i as in in any of
 

00:10:15.110 --> 00:10:16.689
politics of anything i as in in any of
the work that we're doing so Jay why

00:10:16.689 --> 00:10:16.699
the work that we're doing so Jay why
 

00:10:16.699 --> 00:10:18.579
the work that we're doing so Jay why
don't we kick it off with you I'd be

00:10:18.579 --> 00:10:18.589
don't we kick it off with you I'd be
 

00:10:18.589 --> 00:10:21.150
don't we kick it off with you I'd be
happy to build on what you said about

00:10:21.150 --> 00:10:21.160
happy to build on what you said about
 

00:10:21.160 --> 00:10:24.910
happy to build on what you said about
access of electricity to all if I could

00:10:24.910 --> 00:10:24.920
access of electricity to all if I could
 

00:10:24.920 --> 00:10:28.210
access of electricity to all if I could
have the first slide in the u.s. we use

00:10:28.210 --> 00:10:28.220
have the first slide in the u.s. we use
 

00:10:28.220 --> 00:10:31.840
have the first slide in the u.s. we use
now 14 times more electricity than we

00:10:31.840 --> 00:10:31.850
now 14 times more electricity than we
 

00:10:31.850 --> 00:10:34.809
now 14 times more electricity than we
did when I was born in the next slide

00:10:34.809 --> 00:10:34.819
did when I was born in the next slide
 

00:10:34.819 --> 00:10:37.929
did when I was born in the next slide
you can see in the world we're using

00:10:37.929 --> 00:10:37.939
you can see in the world we're using
 

00:10:37.939 --> 00:10:41.170
you can see in the world we're using
about double the electricity that we did

00:10:41.170 --> 00:10:41.180
about double the electricity that we did
 

00:10:41.180 --> 00:10:44.549
about double the electricity that we did
in 1990 and it's doubling every 23 years

00:10:44.549 --> 00:10:44.559
in 1990 and it's doubling every 23 years
 

00:10:44.559 --> 00:10:46.870
in 1990 and it's doubling every 23 years
that means we get the opportunity to

00:10:46.870 --> 00:10:46.880
that means we get the opportunity to
 

00:10:46.880 --> 00:10:48.939
that means we get the opportunity to
build a whole new electricity system

00:10:48.939 --> 00:10:48.949
build a whole new electricity system
 

00:10:48.949 --> 00:10:54.040
build a whole new electricity system
every 23 years well unfortunately in the

00:10:54.040 --> 00:10:54.050
every 23 years well unfortunately in the
 

00:10:54.050 --> 00:10:57.929
every 23 years well unfortunately in the
past that growth has been accompanied by

00:10:57.929 --> 00:10:57.939
past that growth has been accompanied by
 

00:10:57.939 --> 00:11:01.869
past that growth has been accompanied by
tremendous pollution you heard and saw

00:11:01.869 --> 00:11:01.879
tremendous pollution you heard and saw
 

00:11:01.879 --> 00:11:04.499
tremendous pollution you heard and saw
in some of Ellis slides the results of

00:11:04.499 --> 00:11:04.509
in some of Ellis slides the results of
 

00:11:04.509 --> 00:11:08.650
in some of Ellis slides the results of
that pollution and you have to look no

00:11:08.650 --> 00:11:08.660
that pollution and you have to look no
 

00:11:08.660 --> 00:11:09.070
that pollution and you have to look no
further

00:11:09.070 --> 00:11:09.080
further
 

00:11:09.080 --> 00:11:11.320
further
than Beijing to see what happens when

00:11:11.320 --> 00:11:11.330
than Beijing to see what happens when
 

00:11:11.330 --> 00:11:14.320
than Beijing to see what happens when
you have unscrewed coal plants putting

00:11:14.320 --> 00:11:14.330
you have unscrewed coal plants putting
 

00:11:14.330 --> 00:11:17.079
you have unscrewed coal plants putting
out electricity and pollution but in

00:11:17.079 --> 00:11:17.089
out electricity and pollution but in
 

00:11:17.089 --> 00:11:22.960
out electricity and pollution but in
1970 CMU economists showed for the first

00:11:22.960 --> 00:11:22.970
1970 CMU economists showed for the first
 

00:11:22.970 --> 00:11:24.790
1970 CMU economists showed for the first
time rigorously the connection between

00:11:24.790 --> 00:11:24.800
time rigorously the connection between
 

00:11:24.800 --> 00:11:27.400
time rigorously the connection between
air pollution and human health that led

00:11:27.400 --> 00:11:27.410
air pollution and human health that led
 

00:11:27.410 --> 00:11:31.990
air pollution and human health that led
directly to the Clean Air Act of 1970

00:11:31.990 --> 00:11:32.000
directly to the Clean Air Act of 1970
 

00:11:32.000 --> 00:11:34.870
directly to the Clean Air Act of 1970
and the low pollution electric power

00:11:34.870 --> 00:11:34.880
and the low pollution electric power
 

00:11:34.880 --> 00:11:38.500
and the low pollution electric power
that we see today that provides about

00:11:38.500 --> 00:11:38.510
that we see today that provides about
 

00:11:38.510 --> 00:11:42.220
that we see today that provides about
40% of u.s. electricity now we're a long

00:11:42.220 --> 00:11:42.230
40% of u.s. electricity now we're a long
 

00:11:42.230 --> 00:11:45.340
40% of u.s. electricity now we're a long
way behind Europe where they have 55%

00:11:45.340 --> 00:11:45.350
way behind Europe where they have 55%
 

00:11:45.350 --> 00:11:48.550
way behind Europe where they have 55%
low pollution power wind power actually

00:11:48.550 --> 00:11:48.560
low pollution power wind power actually
 

00:11:48.560 --> 00:11:50.740
low pollution power wind power actually
got its start in Europe due to

00:11:50.740 --> 00:11:50.750
got its start in Europe due to
 

00:11:50.750 --> 00:11:54.340
got its start in Europe due to
government policies and let me show you

00:11:54.340 --> 00:11:54.350
government policies and let me show you
 

00:11:54.350 --> 00:11:55.900
government policies and let me show you
in the next slide if we can get the

00:11:55.900 --> 00:11:55.910
in the next slide if we can get the
 

00:11:55.910 --> 00:11:58.630
in the next slide if we can get the
animation working wind powers growth in

00:11:58.630 --> 00:11:58.640
animation working wind powers growth in
 

00:11:58.640 --> 00:12:00.040
animation working wind powers growth in
Europe that's an outline of Europe

00:12:00.040 --> 00:12:00.050
Europe that's an outline of Europe
 

00:12:00.050 --> 00:12:01.420
Europe that's an outline of Europe
although it's a little light in here to

00:12:01.420 --> 00:12:01.430
although it's a little light in here to
 

00:12:01.430 --> 00:12:02.829
although it's a little light in here to
see the country boundary but you can see

00:12:02.829 --> 00:12:02.839
see the country boundary but you can see
 

00:12:02.839 --> 00:12:05.170
see the country boundary but you can see
when growing from Denmark and then

00:12:05.170 --> 00:12:05.180
when growing from Denmark and then
 

00:12:05.180 --> 00:12:07.329
when growing from Denmark and then
spreading to the rest of Europe Germany

00:12:07.329 --> 00:12:07.339
spreading to the rest of Europe Germany
 

00:12:07.339 --> 00:12:11.340
spreading to the rest of Europe Germany
first Spain next France and England and

00:12:11.340 --> 00:12:11.350
first Spain next France and England and
 

00:12:11.350 --> 00:12:15.760
first Spain next France and England and
this growth has just been phenomenal but

00:12:15.760 --> 00:12:15.770
this growth has just been phenomenal but
 

00:12:15.770 --> 00:12:18.460
this growth has just been phenomenal but
still wind and solar power provide only

00:12:18.460 --> 00:12:18.470
still wind and solar power provide only
 

00:12:18.470 --> 00:12:21.670
still wind and solar power provide only
15 percent of Europe's electric power

00:12:21.670 --> 00:12:21.680
15 percent of Europe's electric power
 

00:12:21.680 --> 00:12:24.280
15 percent of Europe's electric power
and about half that in the US but it is

00:12:24.280 --> 00:12:24.290
and about half that in the US but it is
 

00:12:24.290 --> 00:12:25.780
and about half that in the US but it is
growing the next slide will show you

00:12:25.780 --> 00:12:25.790
growing the next slide will show you
 

00:12:25.790 --> 00:12:28.900
growing the next slide will show you
country by country in these animations

00:12:28.900 --> 00:12:28.910
country by country in these animations
 

00:12:28.910 --> 00:12:32.800
country by country in these animations
done by ILA's create lab how wind power

00:12:32.800 --> 00:12:32.810
done by ILA's create lab how wind power
 

00:12:32.810 --> 00:12:35.699
done by ILA's create lab how wind power
has grown and China is coming on strong

00:12:35.699 --> 00:12:35.709
has grown and China is coming on strong
 

00:12:35.709 --> 00:12:38.170
has grown and China is coming on strong
although they have a lot of wind they

00:12:38.170 --> 00:12:38.180
although they have a lot of wind they
 

00:12:38.180 --> 00:12:39.639
although they have a lot of wind they
have a lot of electricity and so it's

00:12:39.639 --> 00:12:39.649
have a lot of electricity and so it's
 

00:12:39.649 --> 00:12:43.360
have a lot of electricity and so it's
still a small percentage of power but

00:12:43.360 --> 00:12:43.370
still a small percentage of power but
 

00:12:43.370 --> 00:12:46.180
still a small percentage of power but
the thing that ties this together with

00:12:46.180 --> 00:12:46.190
the thing that ties this together with
 

00:12:46.190 --> 00:12:48.340
the thing that ties this together with
what sarah has been saying is that wind

00:12:48.340 --> 00:12:48.350
what sarah has been saying is that wind
 

00:12:48.350 --> 00:12:51.220
what sarah has been saying is that wind
solar hydroelectric and biomass power

00:12:51.220 --> 00:12:51.230
solar hydroelectric and biomass power
 

00:12:51.230 --> 00:12:55.120
solar hydroelectric and biomass power
they've all run into opposition because

00:12:55.120 --> 00:12:55.130
they've all run into opposition because
 

00:12:55.130 --> 00:12:58.480
they've all run into opposition because
they use a lot of land they for example

00:12:58.480 --> 00:12:58.490
they use a lot of land they for example
 

00:12:58.490 --> 00:13:01.360
they use a lot of land they for example
the cape winds project off Cape Cod was

00:13:01.360 --> 00:13:01.370
the cape winds project off Cape Cod was
 

00:13:01.370 --> 00:13:05.350
the cape winds project off Cape Cod was
stopped dead this year because it marred

00:13:05.350 --> 00:13:05.360
stopped dead this year because it marred
 

00:13:05.360 --> 00:13:09.730
stopped dead this year because it marred
the view CMU psychologist Baruch

00:13:09.730 --> 00:13:09.740
the view CMU psychologist Baruch
 

00:13:09.740 --> 00:13:13.630
the view CMU psychologist Baruch
fish-off and I have collaborated on a

00:13:13.630 --> 00:13:13.640
fish-off and I have collaborated on a
 

00:13:13.640 --> 00:13:15.670
fish-off and I have collaborated on a
bunch of projects to try to understand

00:13:15.670 --> 00:13:15.680
bunch of projects to try to understand
 

00:13:15.680 --> 00:13:19.300
bunch of projects to try to understand
how energy projects and people can work

00:13:19.300 --> 00:13:19.310
how energy projects and people can work
 

00:13:19.310 --> 00:13:22.590
how energy projects and people can work
together to get acceptable outcomes

00:13:22.590 --> 00:13:22.600
together to get acceptable outcomes
 

00:13:22.600 --> 00:13:25.540
together to get acceptable outcomes
if I get over the next slide I want to

00:13:25.540 --> 00:13:25.550
if I get over the next slide I want to
 

00:13:25.550 --> 00:13:27.160
if I get over the next slide I want to
come back to something that Sarah said

00:13:27.160 --> 00:13:27.170
come back to something that Sarah said
 

00:13:27.170 --> 00:13:29.710
come back to something that Sarah said
about access this is a of course a

00:13:29.710 --> 00:13:29.720
about access this is a of course a
 

00:13:29.720 --> 00:13:32.110
about access this is a of course a
famous picture of nightlights

00:13:32.110 --> 00:13:32.120
famous picture of nightlights
 

00:13:32.120 --> 00:13:33.790
famous picture of nightlights
taken from the defense meteorological

00:13:33.790 --> 00:13:33.800
taken from the defense meteorological
 

00:13:33.800 --> 00:13:35.470
taken from the defense meteorological
satellite program there's a lot of areas

00:13:35.470 --> 00:13:35.480
satellite program there's a lot of areas
 

00:13:35.480 --> 00:13:37.840
satellite program there's a lot of areas
that don't have lights and the next

00:13:37.840 --> 00:13:37.850
that don't have lights and the next
 

00:13:37.850 --> 00:13:41.110
that don't have lights and the next
billion people to get electric power are

00:13:41.110 --> 00:13:41.120
billion people to get electric power are
 

00:13:41.120 --> 00:13:42.580
billion people to get electric power are
going to get in a very different way

00:13:42.580 --> 00:13:42.590
going to get in a very different way
 

00:13:42.590 --> 00:13:46.120
going to get in a very different way
than the people who have electric power

00:13:46.120 --> 00:13:46.130
than the people who have electric power
 

00:13:46.130 --> 00:13:49.120
than the people who have electric power
now our students have brought

00:13:49.120 --> 00:13:49.130
now our students have brought
 

00:13:49.130 --> 00:13:51.460
now our students have brought
engineering and business expertise

00:13:51.460 --> 00:13:51.470
engineering and business expertise
 

00:13:51.470 --> 00:13:53.950
engineering and business expertise
together to provide unconventional

00:13:53.950 --> 00:13:53.960
together to provide unconventional
 

00:13:53.960 --> 00:13:56.470
together to provide unconventional
solutions with companies like earth

00:13:56.470 --> 00:13:56.480
solutions with companies like earth
 

00:13:56.480 --> 00:13:59.230
solutions with companies like earth
spark and spark meter and we've done a

00:13:59.230 --> 00:13:59.240
spark and spark meter and we've done a
 

00:13:59.240 --> 00:14:02.500
spark and spark meter and we've done a
report for the UN foundation on best

00:14:02.500 --> 00:14:02.510
report for the UN foundation on best
 

00:14:02.510 --> 00:14:05.800
report for the UN foundation on best
practices for Rural Electric micro grids

00:14:05.800 --> 00:14:05.810
practices for Rural Electric micro grids
 

00:14:05.810 --> 00:14:08.230
practices for Rural Electric micro grids
all those solutions recognize that

00:14:08.230 --> 00:14:08.240
all those solutions recognize that
 

00:14:08.240 --> 00:14:10.990
all those solutions recognize that
people and technology are equally

00:14:10.990 --> 00:14:11.000
people and technology are equally
 

00:14:11.000 --> 00:14:14.530
people and technology are equally
important Anita what about the role of

00:14:14.530 --> 00:14:14.540
important Anita what about the role of
 

00:14:14.540 --> 00:14:16.500
important Anita what about the role of
diversity and getting better outcomes

00:14:16.500 --> 00:14:16.510
diversity and getting better outcomes
 

00:14:16.510 --> 00:14:19.930
diversity and getting better outcomes
well many of the problems that we have

00:14:19.930 --> 00:14:19.940
well many of the problems that we have
 

00:14:19.940 --> 00:14:23.140
well many of the problems that we have
been describing really rely on groups to

00:14:23.140 --> 00:14:23.150
been describing really rely on groups to
 

00:14:23.150 --> 00:14:25.750
been describing really rely on groups to
collaborate and so it's written some of

00:14:25.750 --> 00:14:25.760
collaborate and so it's written some of
 

00:14:25.760 --> 00:14:27.700
collaborate and so it's written some of
the problems persist because groups fail

00:14:27.700 --> 00:14:27.710
the problems persist because groups fail
 

00:14:27.710 --> 00:14:29.350
the problems persist because groups fail
to collaborate to come up with good

00:14:29.350 --> 00:14:29.360
to collaborate to come up with good
 

00:14:29.360 --> 00:14:33.310
to collaborate to come up with good
policy solutions to implement so we've

00:14:33.310 --> 00:14:33.320
policy solutions to implement so we've
 

00:14:33.320 --> 00:14:34.590
policy solutions to implement so we've
been looking at this problem of

00:14:34.590 --> 00:14:34.600
been looking at this problem of
 

00:14:34.600 --> 00:14:36.820
been looking at this problem of
collaboration in the framework of

00:14:36.820 --> 00:14:36.830
collaboration in the framework of
 

00:14:36.830 --> 00:14:39.610
collaboration in the framework of
collective intelligence historically

00:14:39.610 --> 00:14:39.620
collective intelligence historically
 

00:14:39.620 --> 00:14:40.990
collective intelligence historically
when we've thought about collective

00:14:40.990 --> 00:14:41.000
when we've thought about collective
 

00:14:41.000 --> 00:14:42.700
when we've thought about collective
intelligence it's been as a function of

00:14:42.700 --> 00:14:42.710
intelligence it's been as a function of
 

00:14:42.710 --> 00:14:44.920
intelligence it's been as a function of
the the skills of individual people we

00:14:44.920 --> 00:14:44.930
the the skills of individual people we
 

00:14:44.930 --> 00:14:47.050
the the skills of individual people we
think if we educate students well they

00:14:47.050 --> 00:14:47.060
think if we educate students well they
 

00:14:47.060 --> 00:14:49.360
think if we educate students well they
should go off and make smart teams well

00:14:49.360 --> 00:14:49.370
should go off and make smart teams well
 

00:14:49.370 --> 00:14:51.070
should go off and make smart teams well
in our research we haven't found that to

00:14:51.070 --> 00:14:51.080
in our research we haven't found that to
 

00:14:51.080 --> 00:14:52.900
in our research we haven't found that to
be the case that there really is a

00:14:52.900 --> 00:14:52.910
be the case that there really is a
 

00:14:52.910 --> 00:14:55.060
be the case that there really is a
quality that enables groups to

00:14:55.060 --> 00:14:55.070
quality that enables groups to
 

00:14:55.070 --> 00:14:56.560
quality that enables groups to
collaborate more effectively than others

00:14:56.560 --> 00:14:56.570
collaborate more effectively than others
 

00:14:56.570 --> 00:14:59.320
collaborate more effectively than others
that has thing has to do with other

00:14:59.320 --> 00:14:59.330
that has thing has to do with other
 

00:14:59.330 --> 00:15:00.790
that has thing has to do with other
aspects of the group

00:15:00.790 --> 00:15:00.800
aspects of the group
 

00:15:00.800 --> 00:15:04.000
aspects of the group
and so we've been doing a variety of

00:15:04.000 --> 00:15:04.010
and so we've been doing a variety of
 

00:15:04.010 --> 00:15:05.530
and so we've been doing a variety of
research studies over the last couple of

00:15:05.530 --> 00:15:05.540
research studies over the last couple of
 

00:15:05.540 --> 00:15:08.320
research studies over the last couple of
years both to measure collective

00:15:08.320 --> 00:15:08.330
years both to measure collective
 

00:15:08.330 --> 00:15:10.870
years both to measure collective
intelligence as well as to look at what

00:15:10.870 --> 00:15:10.880
intelligence as well as to look at what
 

00:15:10.880 --> 00:15:12.850
intelligence as well as to look at what
really leads to higher collective

00:15:12.850 --> 00:15:12.860
really leads to higher collective
 

00:15:12.860 --> 00:15:15.370
really leads to higher collective
intelligence and groups and so while we

00:15:15.370 --> 00:15:15.380
intelligence and groups and so while we
 

00:15:15.380 --> 00:15:17.200
intelligence and groups and so while we
have found that it's it's not about

00:15:17.200 --> 00:15:17.210
have found that it's it's not about
 

00:15:17.210 --> 00:15:20.440
have found that it's it's not about
individual IQ necessarily we have found

00:15:20.440 --> 00:15:20.450
individual IQ necessarily we have found
 

00:15:20.450 --> 00:15:22.360
individual IQ necessarily we have found
some other elements so one thing that we

00:15:22.360 --> 00:15:22.370
some other elements so one thing that we
 

00:15:22.370 --> 00:15:24.040
some other elements so one thing that we
have found and I think that's the yes

00:15:24.040 --> 00:15:24.050
have found and I think that's the yes
 

00:15:24.050 --> 00:15:25.180
have found and I think that's the yes
okay

00:15:25.180 --> 00:15:25.190
okay
 

00:15:25.190 --> 00:15:27.760
okay
one thing that we found initially we

00:15:27.760 --> 00:15:27.770
one thing that we found initially we
 

00:15:27.770 --> 00:15:29.350
one thing that we found initially we
found a correlation with the proportion

00:15:29.350 --> 00:15:29.360
found a correlation with the proportion
 

00:15:29.360 --> 00:15:30.760
found a correlation with the proportion
of women in the group and collective

00:15:30.760 --> 00:15:30.770
of women in the group and collective
 

00:15:30.770 --> 00:15:32.470
of women in the group and collective
intelligence and we thought it initially

00:15:32.470 --> 00:15:32.480
intelligence and we thought it initially
 

00:15:32.480 --> 00:15:34.930
intelligence and we thought it initially
it was a linear correlation now that

00:15:34.930 --> 00:15:34.940
it was a linear correlation now that
 

00:15:34.940 --> 00:15:35.530
it was a linear correlation now that
we've collected

00:15:35.530 --> 00:15:35.540
we've collected
 

00:15:35.540 --> 00:15:37.420
we've collected
data on several hundred groups we find

00:15:37.420 --> 00:15:37.430
data on several hundred groups we find
 

00:15:37.430 --> 00:15:38.949
data on several hundred groups we find
that actually it's it's a curvilinear

00:15:38.949 --> 00:15:38.959
that actually it's it's a curvilinear
 

00:15:38.959 --> 00:15:41.620
that actually it's it's a curvilinear
correlation so in this graph what you

00:15:41.620 --> 00:15:41.630
correlation so in this graph what you
 

00:15:41.630 --> 00:15:43.960
correlation so in this graph what you
see is that groups off will oscillate

00:15:43.960 --> 00:15:43.970
see is that groups off will oscillate
 

00:15:43.970 --> 00:15:45.460
see is that groups off will oscillate
around average collective intelligence

00:15:45.460 --> 00:15:45.470
around average collective intelligence
 

00:15:45.470 --> 00:15:48.670
around average collective intelligence
until they have majority women and

00:15:48.670 --> 00:15:48.680
until they have majority women and
 

00:15:48.680 --> 00:15:50.290
until they have majority women and
that's when they're reliably above

00:15:50.290 --> 00:15:50.300
that's when they're reliably above
 

00:15:50.300 --> 00:15:52.569
that's when they're reliably above
average collective intelligence and then

00:15:52.569 --> 00:15:52.579
average collective intelligence and then
 

00:15:52.579 --> 00:15:57.670
average collective intelligence and then
thank you and then but when it's all

00:15:57.670 --> 00:15:57.680
thank you and then but when it's all
 

00:15:57.680 --> 00:15:59.559
thank you and then but when it's all
women it goes back to being average so

00:15:59.559 --> 00:15:59.569
women it goes back to being average so
 

00:15:59.569 --> 00:16:02.740
women it goes back to being average so
there is a there is a benefit to having

00:16:02.740 --> 00:16:02.750
there is a there is a benefit to having
 

00:16:02.750 --> 00:16:06.220
there is a there is a benefit to having
gender diversity but with a tilt toward

00:16:06.220 --> 00:16:06.230
gender diversity but with a tilt toward
 

00:16:06.230 --> 00:16:08.259
gender diversity but with a tilt toward
having more women and one of the things

00:16:08.259 --> 00:16:08.269
having more women and one of the things
 

00:16:08.269 --> 00:16:10.210
having more women and one of the things
that we find when groups have more women

00:16:10.210 --> 00:16:10.220
that we find when groups have more women
 

00:16:10.220 --> 00:16:12.819
that we find when groups have more women
is that the quality of communication

00:16:12.819 --> 00:16:12.829
is that the quality of communication
 

00:16:12.829 --> 00:16:14.590
is that the quality of communication
tends to be higher there tends to be a

00:16:14.590 --> 00:16:14.600
tends to be higher there tends to be a
 

00:16:14.600 --> 00:16:16.329
tends to be higher there tends to be a
higher level of communication and more

00:16:16.329 --> 00:16:16.339
higher level of communication and more
 

00:16:16.339 --> 00:16:18.309
higher level of communication and more
equality in contribution to

00:16:18.309 --> 00:16:18.319
equality in contribution to
 

00:16:18.319 --> 00:16:20.559
equality in contribution to
communication and so that's one of the

00:16:20.559 --> 00:16:20.569
communication and so that's one of the
 

00:16:20.569 --> 00:16:23.829
communication and so that's one of the
reasons why we see this effect but said

00:16:23.829 --> 00:16:23.839
reasons why we see this effect but said
 

00:16:23.839 --> 00:16:26.439
reasons why we see this effect but said
another way as men become more skilled

00:16:26.439 --> 00:16:26.449
another way as men become more skilled
 

00:16:26.449 --> 00:16:29.710
another way as men become more skilled
in some of these collaboration abilities

00:16:29.710 --> 00:16:29.720
in some of these collaboration abilities
 

00:16:29.720 --> 00:16:32.199
in some of these collaboration abilities
then we should see maybe the effect of

00:16:32.199 --> 00:16:32.209
then we should see maybe the effect of
 

00:16:32.209 --> 00:16:35.550
then we should see maybe the effect of
simple gender composition decrease so

00:16:35.550 --> 00:16:35.560
simple gender composition decrease so
 

00:16:35.560 --> 00:16:38.470
simple gender composition decrease so
another thing that we find that enhances

00:16:38.470 --> 00:16:38.480
another thing that we find that enhances
 

00:16:38.480 --> 00:16:40.090
another thing that we find that enhances
collective intelligence is cognitive

00:16:40.090 --> 00:16:40.100
collective intelligence is cognitive
 

00:16:40.100 --> 00:16:42.639
collective intelligence is cognitive
diversity so we've measured a variety of

00:16:42.639 --> 00:16:42.649
diversity so we've measured a variety of
 

00:16:42.649 --> 00:16:44.410
diversity so we've measured a variety of
cognitive styles that actually

00:16:44.410 --> 00:16:44.420
cognitive styles that actually
 

00:16:44.420 --> 00:16:46.720
cognitive styles that actually
differentiate people who work in

00:16:46.720 --> 00:16:46.730
differentiate people who work in
 

00:16:46.730 --> 00:16:48.400
differentiate people who work in
different academic fields like we see at

00:16:48.400 --> 00:16:48.410
different academic fields like we see at
 

00:16:48.410 --> 00:16:50.470
different academic fields like we see at
CMU some of these cognitive styles are

00:16:50.470 --> 00:16:50.480
CMU some of these cognitive styles are
 

00:16:50.480 --> 00:16:52.019
CMU some of these cognitive styles are
predominant in engineering and

00:16:52.019 --> 00:16:52.029
predominant in engineering and
 

00:16:52.029 --> 00:16:55.389
predominant in engineering and
mathematics others and the arts and

00:16:55.389 --> 00:16:55.399
mathematics others and the arts and
 

00:16:55.399 --> 00:16:58.990
mathematics others and the arts and
still others in the humanities and so we

00:16:58.990 --> 00:16:59.000
still others in the humanities and so we
 

00:16:59.000 --> 00:17:01.420
still others in the humanities and so we
find in when we don't intervene that

00:17:01.420 --> 00:17:01.430
find in when we don't intervene that
 

00:17:01.430 --> 00:17:03.579
find in when we don't intervene that
groups that have at least a moderate

00:17:03.579 --> 00:17:03.589
groups that have at least a moderate
 

00:17:03.589 --> 00:17:06.340
groups that have at least a moderate
level of diversity tend to reach the

00:17:06.340 --> 00:17:06.350
level of diversity tend to reach the
 

00:17:06.350 --> 00:17:07.659
level of diversity tend to reach the
highest levels of collective

00:17:07.659 --> 00:17:07.669
highest levels of collective
 

00:17:07.669 --> 00:17:10.030
highest levels of collective
intelligence when we actually in some

00:17:10.030 --> 00:17:10.040
intelligence when we actually in some
 

00:17:10.040 --> 00:17:11.980
intelligence when we actually in some
studies intervene to help the diverse

00:17:11.980 --> 00:17:11.990
studies intervene to help the diverse
 

00:17:11.990 --> 00:17:13.809
studies intervene to help the diverse
groups collaborate more effectively we

00:17:13.809 --> 00:17:13.819
groups collaborate more effectively we
 

00:17:13.819 --> 00:17:15.699
groups collaborate more effectively we
see more of a linear effect where our

00:17:15.699 --> 00:17:15.709
see more of a linear effect where our
 

00:17:15.709 --> 00:17:18.010
see more of a linear effect where our
diversity continues to have greater

00:17:18.010 --> 00:17:18.020
diversity continues to have greater
 

00:17:18.020 --> 00:17:20.699
diversity continues to have greater
advantages but one thing we know from

00:17:20.699 --> 00:17:20.709
advantages but one thing we know from
 

00:17:20.709 --> 00:17:23.260
advantages but one thing we know from
trends you know across the world is that

00:17:23.260 --> 00:17:23.270
trends you know across the world is that
 

00:17:23.270 --> 00:17:25.720
trends you know across the world is that
if left to their own devices groups tend

00:17:25.720 --> 00:17:25.730
if left to their own devices groups tend
 

00:17:25.730 --> 00:17:28.030
if left to their own devices groups tend
not to be diverse we like to hang out

00:17:28.030 --> 00:17:28.040
not to be diverse we like to hang out
 

00:17:28.040 --> 00:17:30.490
not to be diverse we like to hang out
with people who are like us and so

00:17:30.490 --> 00:17:30.500
with people who are like us and so
 

00:17:30.500 --> 00:17:32.560
with people who are like us and so
groups won't achieve the highest levels

00:17:32.560 --> 00:17:32.570
groups won't achieve the highest levels
 

00:17:32.570 --> 00:17:34.270
groups won't achieve the highest levels
of collective intelligence unless they

00:17:34.270 --> 00:17:34.280
of collective intelligence unless they
 

00:17:34.280 --> 00:17:37.120
of collective intelligence unless they
make an active effort to increase their

00:17:37.120 --> 00:17:37.130
make an active effort to increase their
 

00:17:37.130 --> 00:17:40.270
make an active effort to increase their
diversity and so and that's true here at

00:17:40.270 --> 00:17:40.280
diversity and so and that's true here at
 

00:17:40.280 --> 00:17:43.750
diversity and so and that's true here at
CMU and in every organization across the

00:17:43.750 --> 00:17:43.760
CMU and in every organization across the
 

00:17:43.760 --> 00:17:46.419
CMU and in every organization across the
globe you've just given great empirical

00:17:46.419 --> 00:17:46.429
globe you've just given great empirical
 

00:17:46.429 --> 00:17:48.270
globe you've just given great empirical
cases for why the STG

00:17:48.270 --> 00:17:48.280
cases for why the STG
 

00:17:48.280 --> 00:17:51.930
cases for why the STG
is under goal five reducing inequality

00:17:51.930 --> 00:17:51.940
is under goal five reducing inequality
 

00:17:51.940 --> 00:17:54.200
is under goal five reducing inequality
increasing diversity makes sense

00:17:54.200 --> 00:17:54.210
increasing diversity makes sense
 

00:17:54.210 --> 00:17:56.730
increasing diversity makes sense
Marshall what about in your world

00:17:56.730 --> 00:17:56.740
Marshall what about in your world
 

00:17:56.740 --> 00:18:01.830
Marshall what about in your world
interconnectedness in robotics human

00:18:01.830 --> 00:18:01.840
interconnectedness in robotics human
 

00:18:01.840 --> 00:18:06.300
interconnectedness in robotics human
human aspects of yes much of the work in

00:18:06.300 --> 00:18:06.310
human aspects of yes much of the work in
 

00:18:06.310 --> 00:18:07.950
human aspects of yes much of the work in
robotics does not have to do with robots

00:18:07.950 --> 00:18:07.960
robotics does not have to do with robots
 

00:18:07.960 --> 00:18:10.110
robotics does not have to do with robots
it has to do with people understanding

00:18:10.110 --> 00:18:10.120
it has to do with people understanding
 

00:18:10.120 --> 00:18:12.450
it has to do with people understanding
people understanding their behavior

00:18:12.450 --> 00:18:12.460
people understanding their behavior
 

00:18:12.460 --> 00:18:14.910
people understanding their behavior
understanding their motion next one

00:18:14.910 --> 00:18:14.920
understanding their motion next one
 

00:18:14.920 --> 00:18:19.500
understanding their motion next one
please thank you

00:18:19.500 --> 00:18:19.510
please thank you
 

00:18:19.510 --> 00:18:21.000
please thank you
this is an example here from our

00:18:21.000 --> 00:18:21.010
this is an example here from our
 

00:18:21.010 --> 00:18:24.210
this is an example here from our
computer vision group of analysis of

00:18:24.210 --> 00:18:24.220
computer vision group of analysis of
 

00:18:24.220 --> 00:18:26.910
computer vision group of analysis of
people again understanding their action

00:18:26.910 --> 00:18:26.920
people again understanding their action
 

00:18:26.920 --> 00:18:28.170
people again understanding their action
understanding their behavior

00:18:28.170 --> 00:18:28.180
understanding their behavior
 

00:18:28.180 --> 00:18:31.410
understanding their behavior
understanding their their internal

00:18:31.410 --> 00:18:31.420
understanding their their internal
 

00:18:31.420 --> 00:18:33.510
understanding their their internal
states etc once we have those

00:18:33.510 --> 00:18:33.520
states etc once we have those
 

00:18:33.520 --> 00:18:37.470
states etc once we have those
capabilities we can we can develop new

00:18:37.470 --> 00:18:37.480
capabilities we can we can develop new
 

00:18:37.480 --> 00:18:39.870
capabilities we can we can develop new
applications this is an example here

00:18:39.870 --> 00:18:39.880
applications this is an example here
 

00:18:39.880 --> 00:18:42.930
applications this is an example here
next one please this is an example here

00:18:42.930 --> 00:18:42.940
next one please this is an example here
 

00:18:42.940 --> 00:18:44.880
next one please this is an example here
of an interaction between a protection

00:18:44.880 --> 00:18:44.890
of an interaction between a protection
 

00:18:44.890 --> 00:18:48.210
of an interaction between a protection
on your child in an autism study we can

00:18:48.210 --> 00:18:48.220
on your child in an autism study we can
 

00:18:48.220 --> 00:18:50.550
on your child in an autism study we can
now automatically analyze those

00:18:50.550 --> 00:18:50.560
now automatically analyze those
 

00:18:50.560 --> 00:18:53.460
now automatically analyze those
interactions and extract information we

00:18:53.460 --> 00:18:53.470
interactions and extract information we
 

00:18:53.470 --> 00:18:56.580
interactions and extract information we
can also analyze people in a deeper way

00:18:56.580 --> 00:18:56.590
can also analyze people in a deeper way
 

00:18:56.590 --> 00:18:59.250
can also analyze people in a deeper way
by recognizing their intent for example

00:18:59.250 --> 00:18:59.260
by recognizing their intent for example
 

00:18:59.260 --> 00:19:01.350
by recognizing their intent for example
if I move in this direction you can

00:19:01.350 --> 00:19:01.360
if I move in this direction you can
 

00:19:01.360 --> 00:19:04.200
if I move in this direction you can
guess that I'm trying to grasp this this

00:19:04.200 --> 00:19:04.210
guess that I'm trying to grasp this this
 

00:19:04.210 --> 00:19:06.900
guess that I'm trying to grasp this this
glass we can use this capability to now

00:19:06.900 --> 00:19:06.910
glass we can use this capability to now
 

00:19:06.910 --> 00:19:09.360
glass we can use this capability to now
have tied to interaction between systems

00:19:09.360 --> 00:19:09.370
have tied to interaction between systems
 

00:19:09.370 --> 00:19:11.730
have tied to interaction between systems
and people this is an example here from

00:19:11.730 --> 00:19:11.740
and people this is an example here from
 

00:19:11.740 --> 00:19:13.920
and people this is an example here from
experiment from Professor Han he had

00:19:13.920 --> 00:19:13.930
experiment from Professor Han he had
 

00:19:13.930 --> 00:19:16.860
experiment from Professor Han he had
money studying the effect of combining

00:19:16.860 --> 00:19:16.870
money studying the effect of combining
 

00:19:16.870 --> 00:19:19.080
money studying the effect of combining
the intent prediction from the system

00:19:19.080 --> 00:19:19.090
the intent prediction from the system
 

00:19:19.090 --> 00:19:22.290
the intent prediction from the system
with the actual person interaction with

00:19:22.290 --> 00:19:22.300
with the actual person interaction with
 

00:19:22.300 --> 00:19:24.660
with the actual person interaction with
the with the robot we can go much

00:19:24.660 --> 00:19:24.670
the with the robot we can go much
 

00:19:24.670 --> 00:19:27.000
the with the robot we can go much
further than that if we extend our reach

00:19:27.000 --> 00:19:27.010
further than that if we extend our reach
 

00:19:27.010 --> 00:19:30.270
further than that if we extend our reach
the next slide please this is an example

00:19:30.270 --> 00:19:30.280
the next slide please this is an example
 

00:19:30.280 --> 00:19:31.920
the next slide please this is an example
here of a collaboration between the

00:19:31.920 --> 00:19:31.930
here of a collaboration between the
 

00:19:31.930 --> 00:19:33.360
here of a collaboration between the
robotics team here at CMU the

00:19:33.360 --> 00:19:33.370
robotics team here at CMU the
 

00:19:33.370 --> 00:19:35.490
robotics team here at CMU the
engineering team at CMU and the

00:19:35.490 --> 00:19:35.500
engineering team at CMU and the
 

00:19:35.500 --> 00:19:37.320
engineering team at CMU and the
neurobiology department at the

00:19:37.320 --> 00:19:37.330
neurobiology department at the
 

00:19:37.330 --> 00:19:38.970
neurobiology department at the
University of Pittsburgh this is an

00:19:38.970 --> 00:19:38.980
University of Pittsburgh this is an
 

00:19:38.980 --> 00:19:42.180
University of Pittsburgh this is an
example here where a tetraplegic patient

00:19:42.180 --> 00:19:42.190
example here where a tetraplegic patient
 

00:19:42.190 --> 00:19:44.640
example here where a tetraplegic patient
a paralyzed patient is connected to a

00:19:44.640 --> 00:19:44.650
a paralyzed patient is connected to a
 

00:19:44.650 --> 00:19:46.580
a paralyzed patient is connected to a
robot arm using a brain computer

00:19:46.580 --> 00:19:46.590
robot arm using a brain computer
 

00:19:46.590 --> 00:19:48.210
robot arm using a brain computer
interface BCI

00:19:48.210 --> 00:19:48.220
interface BCI
 

00:19:48.220 --> 00:19:51.540
interface BCI
interface through this interface is able

00:19:51.540 --> 00:19:51.550
interface through this interface is able
 

00:19:51.550 --> 00:19:53.850
interface through this interface is able
to control the manipulator using a brain

00:19:53.850 --> 00:19:53.860
to control the manipulator using a brain
 

00:19:53.860 --> 00:19:56.340
to control the manipulator using a brain
signal basically using thoughts the

00:19:56.340 --> 00:19:56.350
signal basically using thoughts the
 

00:19:56.350 --> 00:19:57.600
signal basically using thoughts the
problem of course with this kind of

00:19:57.600 --> 00:19:57.610
problem of course with this kind of
 

00:19:57.610 --> 00:19:59.940
problem of course with this kind of
system is that they are limited in what

00:19:59.940 --> 00:19:59.950
system is that they are limited in what
 

00:19:59.950 --> 00:20:00.470
system is that they are limited in what
the

00:20:00.470 --> 00:20:00.480
the
 

00:20:00.480 --> 00:20:03.440
the
execute now if we can use what I just

00:20:03.440 --> 00:20:03.450
execute now if we can use what I just
 

00:20:03.450 --> 00:20:06.260
execute now if we can use what I just
said about recognizing intent the system

00:20:06.260 --> 00:20:06.270
said about recognizing intent the system
 

00:20:06.270 --> 00:20:09.200
said about recognizing intent the system
now can guess and understand what the

00:20:09.200 --> 00:20:09.210
now can guess and understand what the
 

00:20:09.210 --> 00:20:11.540
now can guess and understand what the
person is trying to do and now intervene

00:20:11.540 --> 00:20:11.550
person is trying to do and now intervene
 

00:20:11.550 --> 00:20:14.540
person is trying to do and now intervene
to actually help the system carry out

00:20:14.540 --> 00:20:14.550
to actually help the system carry out
 

00:20:14.550 --> 00:20:16.490
to actually help the system carry out
the task that she really wants to do the

00:20:16.490 --> 00:20:16.500
the task that she really wants to do the
 

00:20:16.500 --> 00:20:18.860
the task that she really wants to do the
night result next next one please and

00:20:18.860 --> 00:20:18.870
night result next next one please and
 

00:20:18.870 --> 00:20:20.930
night result next next one please and
you can play the movie is that now she's

00:20:20.930 --> 00:20:20.940
you can play the movie is that now she's
 

00:20:20.940 --> 00:20:24.320
you can play the movie is that now she's
able to carry out a task that was

00:20:24.320 --> 00:20:24.330
able to carry out a task that was
 

00:20:24.330 --> 00:20:26.630
able to carry out a task that was
absolutely impossible before for example

00:20:26.630 --> 00:20:26.640
absolutely impossible before for example
 

00:20:26.640 --> 00:20:28.820
absolutely impossible before for example
desta's which requires a rotational

00:20:28.820 --> 00:20:28.830
desta's which requires a rotational
 

00:20:28.830 --> 00:20:31.730
desta's which requires a rotational
motion which is impossible to brain the

00:20:31.730 --> 00:20:31.740
motion which is impossible to brain the
 

00:20:31.740 --> 00:20:33.920
motion which is impossible to brain the
right brain control it is now possible

00:20:33.920 --> 00:20:33.930
right brain control it is now possible
 

00:20:33.930 --> 00:20:35.470
right brain control it is now possible
because the system is able to recognize

00:20:35.470 --> 00:20:35.480
because the system is able to recognize
 

00:20:35.480 --> 00:20:40.040
because the system is able to recognize
her intent so this is an example where

00:20:40.040 --> 00:20:40.050
her intent so this is an example where
 

00:20:40.050 --> 00:20:42.680
her intent so this is an example where
we're giving a completely new capability

00:20:42.680 --> 00:20:42.690
we're giving a completely new capability
 

00:20:42.690 --> 00:20:45.770
we're giving a completely new capability
that was impossible before thanks to

00:20:45.770 --> 00:20:45.780
that was impossible before thanks to
 

00:20:45.780 --> 00:20:48.290
that was impossible before thanks to
this deeper understanding of people and

00:20:48.290 --> 00:20:48.300
this deeper understanding of people and
 

00:20:48.300 --> 00:20:53.000
this deeper understanding of people and
their interaction so Jake talk to us

00:20:53.000 --> 00:20:53.010
their interaction so Jake talk to us
 

00:20:53.010 --> 00:20:55.700
their interaction so Jake talk to us
about the combination of social economic

00:20:55.700 --> 00:20:55.710
about the combination of social economic
 

00:20:55.710 --> 00:20:57.650
about the combination of social economic
and cultural issues and how their inner

00:20:57.650 --> 00:20:57.660
and cultural issues and how their inner
 

00:20:57.660 --> 00:21:02.060
and cultural issues and how their inner
woven in technology so I think I I'm

00:21:02.060 --> 00:21:02.070
woven in technology so I think I I'm
 

00:21:02.070 --> 00:21:04.400
woven in technology so I think I I'm
gonna make a statement that is

00:21:04.400 --> 00:21:04.410
gonna make a statement that is
 

00:21:04.410 --> 00:21:06.080
gonna make a statement that is
potentially controversial at Carnegie

00:21:06.080 --> 00:21:06.090
potentially controversial at Carnegie
 

00:21:06.090 --> 00:21:08.000
potentially controversial at Carnegie
Mellon Farnum said it was okay if we

00:21:08.000 --> 00:21:08.010
Mellon Farnum said it was okay if we
 

00:21:08.010 --> 00:21:11.390
Mellon Farnum said it was okay if we
were troublemakers so so I feel like I

00:21:11.390 --> 00:21:11.400
were troublemakers so so I feel like I
 

00:21:11.400 --> 00:21:14.570
were troublemakers so so I feel like I
feel like I'm on the panel that's yeah

00:21:14.570 --> 00:21:14.580
feel like I'm on the panel that's yeah
 

00:21:14.580 --> 00:21:17.180
feel like I'm on the panel that's yeah
that's that's my job and what what I

00:21:17.180 --> 00:21:17.190
that's that's my job and what what I
 

00:21:17.190 --> 00:21:18.860
that's that's my job and what what I
think I really want to say is that

00:21:18.860 --> 00:21:18.870
think I really want to say is that
 

00:21:18.870 --> 00:21:21.080
think I really want to say is that
technology itself does not make the

00:21:21.080 --> 00:21:21.090
technology itself does not make the
 

00:21:21.090 --> 00:21:23.750
technology itself does not make the
world a better place it doesn't solve

00:21:23.750 --> 00:21:23.760
world a better place it doesn't solve
 

00:21:23.760 --> 00:21:26.140
world a better place it doesn't solve
social and political problems on its own

00:21:26.140 --> 00:21:26.150
social and political problems on its own
 

00:21:26.150 --> 00:21:28.660
social and political problems on its own
but it can play a very important role

00:21:28.660 --> 00:21:28.670
but it can play a very important role
 

00:21:28.670 --> 00:21:31.640
but it can play a very important role
and that's because technological systems

00:21:31.640 --> 00:21:31.650
and that's because technological systems
 

00:21:31.650 --> 00:21:36.560
and that's because technological systems
are incredibly complex mixtures of

00:21:36.560 --> 00:21:36.570
are incredibly complex mixtures of
 

00:21:36.570 --> 00:21:41.120
are incredibly complex mixtures of
networks people ideas social entities

00:21:41.120 --> 00:21:41.130
networks people ideas social entities
 

00:21:41.130 --> 00:21:44.660
networks people ideas social entities
practices behavior and things that we

00:21:44.660 --> 00:21:44.670
practices behavior and things that we
 

00:21:44.670 --> 00:21:47.510
practices behavior and things that we
don't even know about so if you want

00:21:47.510 --> 00:21:47.520
don't even know about so if you want
 

00:21:47.520 --> 00:21:49.730
don't even know about so if you want
technology to make a difference

00:21:49.730 --> 00:21:49.740
technology to make a difference
 

00:21:49.740 --> 00:21:51.950
technology to make a difference
you really have to design and engineer

00:21:51.950 --> 00:21:51.960
you really have to design and engineer
 

00:21:51.960 --> 00:21:54.860
you really have to design and engineer
these networks to do what you want them

00:21:54.860 --> 00:21:54.870
these networks to do what you want them
 

00:21:54.870 --> 00:21:56.750
these networks to do what you want them
to do because if you just put technology

00:21:56.750 --> 00:21:56.760
to do because if you just put technology
 

00:21:56.760 --> 00:21:59.450
to do because if you just put technology
out into the world it only replicates

00:21:59.450 --> 00:21:59.460
out into the world it only replicates
 

00:21:59.460 --> 00:22:01.580
out into the world it only replicates
the situation that it enters into it

00:22:01.580 --> 00:22:01.590
the situation that it enters into it
 

00:22:01.590 --> 00:22:04.190
the situation that it enters into it
might disrupt it and change things but

00:22:04.190 --> 00:22:04.200
might disrupt it and change things but
 

00:22:04.200 --> 00:22:06.200
might disrupt it and change things but
at the end of the day if you want

00:22:06.200 --> 00:22:06.210
at the end of the day if you want
 

00:22:06.210 --> 00:22:07.610
at the end of the day if you want
technology to make the world a better

00:22:07.610 --> 00:22:07.620
technology to make the world a better
 

00:22:07.620 --> 00:22:09.260
technology to make the world a better
place you have to develop an engineer

00:22:09.260 --> 00:22:09.270
place you have to develop an engineer
 

00:22:09.270 --> 00:22:13.430
place you have to develop an engineer
that technology to do so fortunately for

00:22:13.430 --> 00:22:13.440
that technology to do so fortunately for
 

00:22:13.440 --> 00:22:14.370
that technology to do so fortunately for
me and I think

00:22:14.370 --> 00:22:14.380
me and I think
 

00:22:14.380 --> 00:22:15.960
me and I think
one of the main reasons why I'm doing

00:22:15.960 --> 00:22:15.970
one of the main reasons why I'm doing
 

00:22:15.970 --> 00:22:17.640
one of the main reasons why I'm doing
what I'm doing today and not something

00:22:17.640 --> 00:22:17.650
what I'm doing today and not something
 

00:22:17.650 --> 00:22:19.320
what I'm doing today and not something
else is that Carnegie Mellon is actually

00:22:19.320 --> 00:22:19.330
else is that Carnegie Mellon is actually
 

00:22:19.330 --> 00:22:21.600
else is that Carnegie Mellon is actually
one of the few places in the world where

00:22:21.600 --> 00:22:21.610
one of the few places in the world where
 

00:22:21.610 --> 00:22:23.549
one of the few places in the world where
the kinds of interdisciplinary teams

00:22:23.549 --> 00:22:23.559
the kinds of interdisciplinary teams
 

00:22:23.559 --> 00:22:26.490
the kinds of interdisciplinary teams
necessary to do that are possible to put

00:22:26.490 --> 00:22:26.500
necessary to do that are possible to put
 

00:22:26.500 --> 00:22:29.220
necessary to do that are possible to put
together so I just wanted to tell a

00:22:29.220 --> 00:22:29.230
together so I just wanted to tell a
 

00:22:29.230 --> 00:22:30.810
together so I just wanted to tell a
little story

00:22:30.810 --> 00:22:30.820
little story
 

00:22:30.820 --> 00:22:35.789
little story
so back in 2010-2011 I was doing work on

00:22:35.789 --> 00:22:35.799
so back in 2010-2011 I was doing work on
 

00:22:35.799 --> 00:22:37.470
so back in 2010-2011 I was doing work on
civilian casualty recording and

00:22:37.470 --> 00:22:37.480
civilian casualty recording and
 

00:22:37.480 --> 00:22:39.870
civilian casualty recording and
estimation in times of conflict how many

00:22:39.870 --> 00:22:39.880
estimation in times of conflict how many
 

00:22:39.880 --> 00:22:42.600
estimation in times of conflict how many
people are dying in a conflict it turns

00:22:42.600 --> 00:22:42.610
people are dying in a conflict it turns
 

00:22:42.610 --> 00:22:44.340
people are dying in a conflict it turns
out that that's an incredibly difficult

00:22:44.340 --> 00:22:44.350
out that that's an incredibly difficult
 

00:22:44.350 --> 00:22:49.710
out that that's an incredibly difficult
task to carry out and so we were working

00:22:49.710 --> 00:22:49.720
task to carry out and so we were working
 

00:22:49.720 --> 00:22:51.720
task to carry out and so we were working
with statisticians we were working with

00:22:51.720 --> 00:22:51.730
with statisticians we were working with
 

00:22:51.730 --> 00:22:53.039
with statisticians we were working with
people in the field we were working with

00:22:53.039 --> 00:22:53.049
people in the field we were working with
 

00:22:53.049 --> 00:22:55.799
people in the field we were working with
demographers survey designers people at

00:22:55.799 --> 00:22:55.809
demographers survey designers people at
 

00:22:55.809 --> 00:22:57.060
demographers survey designers people at
human rights groups just trying to

00:22:57.060 --> 00:22:57.070
human rights groups just trying to
 

00:22:57.070 --> 00:22:59.220
human rights groups just trying to
figure out what's the best way of doing

00:22:59.220 --> 00:22:59.230
figure out what's the best way of doing
 

00:22:59.230 --> 00:23:00.870
figure out what's the best way of doing
this and you know I would go out and

00:23:00.870 --> 00:23:00.880
this and you know I would go out and
 

00:23:00.880 --> 00:23:02.760
this and you know I would go out and
talk to them and and and interview them

00:23:02.760 --> 00:23:02.770
talk to them and and and interview them
 

00:23:02.770 --> 00:23:04.110
talk to them and and and interview them
and at the end of the interviews they

00:23:04.110 --> 00:23:04.120
and at the end of the interviews they
 

00:23:04.120 --> 00:23:05.970
and at the end of the interviews they
would invariably say hey you're from

00:23:05.970 --> 00:23:05.980
would invariably say hey you're from
 

00:23:05.980 --> 00:23:08.070
would invariably say hey you're from
Carnegie Mellon I have this problem and

00:23:08.070 --> 00:23:08.080
Carnegie Mellon I have this problem and
 

00:23:08.080 --> 00:23:09.720
Carnegie Mellon I have this problem and
I don't really know how to solve it and

00:23:09.720 --> 00:23:09.730
I don't really know how to solve it and
 

00:23:09.730 --> 00:23:12.779
I don't really know how to solve it and
I need some help can you help me and in

00:23:12.779 --> 00:23:12.789
I need some help can you help me and in
 

00:23:12.789 --> 00:23:14.520
I need some help can you help me and in
some cases I said no we just don't have

00:23:14.520 --> 00:23:14.530
some cases I said no we just don't have
 

00:23:14.530 --> 00:23:17.100
some cases I said no we just don't have
that but in many of the cases actually

00:23:17.100 --> 00:23:17.110
that but in many of the cases actually
 

00:23:17.110 --> 00:23:19.140
that but in many of the cases actually
there was expertise here at Carnegie

00:23:19.140 --> 00:23:19.150
there was expertise here at Carnegie
 

00:23:19.150 --> 00:23:20.909
there was expertise here at Carnegie
Mellon that could have a direct impact

00:23:20.909 --> 00:23:20.919
Mellon that could have a direct impact
 

00:23:20.919 --> 00:23:24.060
Mellon that could have a direct impact
on data challenges that human rights

00:23:24.060 --> 00:23:24.070
on data challenges that human rights
 

00:23:24.070 --> 00:23:26.640
on data challenges that human rights
groups who are having and one of the big

00:23:26.640 --> 00:23:26.650
groups who are having and one of the big
 

00:23:26.650 --> 00:23:29.250
groups who are having and one of the big
ones was at this time the Syria conflict

00:23:29.250 --> 00:23:29.260
ones was at this time the Syria conflict
 

00:23:29.260 --> 00:23:31.890
ones was at this time the Syria conflict
was was just beginning and there was a

00:23:31.890 --> 00:23:31.900
was was just beginning and there was a
 

00:23:31.900 --> 00:23:34.649
was was just beginning and there was a
lot of video coming out there were you

00:23:34.649 --> 00:23:34.659
lot of video coming out there were you
 

00:23:34.659 --> 00:23:36.539
lot of video coming out there were you
know hundreds or thousands of videos

00:23:36.539 --> 00:23:36.549
know hundreds or thousands of videos
 

00:23:36.549 --> 00:23:38.940
know hundreds or thousands of videos
being posted to social media from Syria

00:23:38.940 --> 00:23:38.950
being posted to social media from Syria
 

00:23:38.950 --> 00:23:42.299
being posted to social media from Syria
any given day when I when I really

00:23:42.299 --> 00:23:42.309
any given day when I when I really
 

00:23:42.309 --> 00:23:44.250
any given day when I when I really
started a particular partnership that

00:23:44.250 --> 00:23:44.260
started a particular partnership that
 

00:23:44.260 --> 00:23:46.049
started a particular partnership that
I'll tell you about in a second when I

00:23:46.049 --> 00:23:46.059
I'll tell you about in a second when I
 

00:23:46.059 --> 00:23:47.100
I'll tell you about in a second when I
when we started that there were about

00:23:47.100 --> 00:23:47.110
when we started that there were about
 

00:23:47.110 --> 00:23:50.490
when we started that there were about
600,000 videos that was 2013 today I

00:23:50.490 --> 00:23:50.500
600,000 videos that was 2013 today I
 

00:23:50.500 --> 00:23:52.380
600,000 videos that was 2013 today I
don't even know nobody really knows how

00:23:52.380 --> 00:23:52.390
don't even know nobody really knows how
 

00:23:52.390 --> 00:23:54.570
don't even know nobody really knows how
many million and a half arm or not all

00:23:54.570 --> 00:23:54.580
many million and a half arm or not all
 

00:23:54.580 --> 00:23:56.310
many million and a half arm or not all
of them are relevant but a lot of them

00:23:56.310 --> 00:23:56.320
of them are relevant but a lot of them
 

00:23:56.320 --> 00:23:58.799
of them are relevant but a lot of them
give you information about human rights

00:23:58.799 --> 00:23:58.809
give you information about human rights
 

00:23:58.809 --> 00:24:02.010
give you information about human rights
violations and the the people who I was

00:24:02.010 --> 00:24:02.020
violations and the the people who I was
 

00:24:02.020 --> 00:24:04.289
violations and the the people who I was
trying to talk to about statistics and

00:24:04.289 --> 00:24:04.299
trying to talk to about statistics and
 

00:24:04.299 --> 00:24:06.450
trying to talk to about statistics and
survey design and demography and this

00:24:06.450 --> 00:24:06.460
survey design and demography and this
 

00:24:06.460 --> 00:24:08.880
survey design and demography and this
and that any other had videos that could

00:24:08.880 --> 00:24:08.890
and that any other had videos that could
 

00:24:08.890 --> 00:24:11.760
and that any other had videos that could
give them information about the problems

00:24:11.760 --> 00:24:11.770
give them information about the problems
 

00:24:11.770 --> 00:24:13.260
give them information about the problems
that we were all trying to address but

00:24:13.260 --> 00:24:13.270
that we were all trying to address but
 

00:24:13.270 --> 00:24:15.510
that we were all trying to address but
they didn't know how to to deal with

00:24:15.510 --> 00:24:15.520
they didn't know how to to deal with
 

00:24:15.520 --> 00:24:17.700
they didn't know how to to deal with
this massive volume and they said listen

00:24:17.700 --> 00:24:17.710
this massive volume and they said listen
 

00:24:17.710 --> 00:24:19.080
this massive volume and they said listen
it would really it would be really cool

00:24:19.080 --> 00:24:19.090
it would really it would be really cool
 

00:24:19.090 --> 00:24:22.680
it would really it would be really cool
if there was some system that could just

00:24:22.680 --> 00:24:22.690
if there was some system that could just
 

00:24:22.690 --> 00:24:24.330
if there was some system that could just
help us find things like tanks or

00:24:24.330 --> 00:24:24.340
help us find things like tanks or
 

00:24:24.340 --> 00:24:26.630
help us find things like tanks or
explosions or particular words

00:24:26.630 --> 00:24:26.640
explosions or particular words
 

00:24:26.640 --> 00:24:30.080
explosions or particular words
or even particular scenes or places is

00:24:30.080 --> 00:24:30.090
or even particular scenes or places is
 

00:24:30.090 --> 00:24:31.940
or even particular scenes or places is
there anyone at Carnegie Mellon who can

00:24:31.940 --> 00:24:31.950
there anyone at Carnegie Mellon who can
 

00:24:31.950 --> 00:24:33.770
there anyone at Carnegie Mellon who can
help help with this and I was like I

00:24:33.770 --> 00:24:33.780
help help with this and I was like I
 

00:24:33.780 --> 00:24:36.440
help help with this and I was like I
don't know I have no idea and one day I

00:24:36.440 --> 00:24:36.450
don't know I have no idea and one day I
 

00:24:36.450 --> 00:24:38.450
don't know I have no idea and one day I
was dropping my kids off or picking them

00:24:38.450 --> 00:24:38.460
was dropping my kids off or picking them
 

00:24:38.460 --> 00:24:39.740
was dropping my kids off or picking them
up actually from from daycare and

00:24:39.740 --> 00:24:39.750
up actually from from daycare and
 

00:24:39.750 --> 00:24:41.240
up actually from from daycare and
someone said well you should go talk to

00:24:41.240 --> 00:24:41.250
someone said well you should go talk to
 

00:24:41.250 --> 00:24:43.970
someone said well you should go talk to
yasser sheikh he's a he's a computer

00:24:43.970 --> 00:24:43.980
yasser sheikh he's a he's a computer
 

00:24:43.980 --> 00:24:45.980
yasser sheikh he's a he's a computer
vision person and I was like okay I'll

00:24:45.980 --> 00:24:45.990
vision person and I was like okay I'll
 

00:24:45.990 --> 00:24:47.510
vision person and I was like okay I'll
go talk to you sir so I went to talk to

00:24:47.510 --> 00:24:47.520
go talk to you sir so I went to talk to
 

00:24:47.520 --> 00:24:49.220
go talk to you sir so I went to talk to
you sir and he said listen this isn't

00:24:49.220 --> 00:24:49.230
you sir and he said listen this isn't
 

00:24:49.230 --> 00:24:51.169
you sir and he said listen this isn't
really what I work on but why don't you

00:24:51.169 --> 00:24:51.179
really what I work on but why don't you
 

00:24:51.179 --> 00:24:53.350
really what I work on but why don't you
come give a talk at the computer vision

00:24:53.350 --> 00:24:53.360
come give a talk at the computer vision
 

00:24:53.360 --> 00:24:56.330
come give a talk at the computer vision
seminar that we have weekly and he gave

00:24:56.330 --> 00:24:56.340
seminar that we have weekly and he gave
 

00:24:56.340 --> 00:24:58.010
seminar that we have weekly and he gave
me a slot and he said you know it's

00:24:58.010 --> 00:24:58.020
me a slot and he said you know it's
 

00:24:58.020 --> 00:24:59.360
me a slot and he said you know it's
actually the largest collection of

00:24:59.360 --> 00:24:59.370
actually the largest collection of
 

00:24:59.370 --> 00:25:00.799
actually the largest collection of
computer vision specialists in the world

00:25:00.799 --> 00:25:00.809
computer vision specialists in the world
 

00:25:00.809 --> 00:25:03.350
computer vision specialists in the world
and I was I mean I had no idea of my

00:25:03.350 --> 00:25:03.360
and I was I mean I had no idea of my
 

00:25:03.360 --> 00:25:05.000
and I was I mean I had no idea of my
background is in genetics and history

00:25:05.000 --> 00:25:05.010
background is in genetics and history
 

00:25:05.010 --> 00:25:06.919
background is in genetics and history
and science policy and you know pretty

00:25:06.919 --> 00:25:06.929
and science policy and you know pretty
 

00:25:06.929 --> 00:25:08.510
and science policy and you know pretty
diverse but nothing having to do with

00:25:08.510 --> 00:25:08.520
diverse but nothing having to do with
 

00:25:08.520 --> 00:25:11.390
diverse but nothing having to do with
how do you analyze video so I came and I

00:25:11.390 --> 00:25:11.400
how do you analyze video so I came and I
 

00:25:11.400 --> 00:25:14.750
how do you analyze video so I came and I
brought slides and I showed you know I

00:25:14.750 --> 00:25:14.760
brought slides and I showed you know I
 

00:25:14.760 --> 00:25:18.860
brought slides and I showed you know I
showed some some videos from Syria and I

00:25:18.860 --> 00:25:18.870
showed some some videos from Syria and I
 

00:25:18.870 --> 00:25:20.360
showed some some videos from Syria and I
said it would be really cool if we could

00:25:20.360 --> 00:25:20.370
said it would be really cool if we could
 

00:25:20.370 --> 00:25:21.980
said it would be really cool if we could
just have some system that tells us

00:25:21.980 --> 00:25:21.990
just have some system that tells us
 

00:25:21.990 --> 00:25:24.020
just have some system that tells us
about tanks you know when there are

00:25:24.020 --> 00:25:24.030
about tanks you know when there are
 

00:25:24.030 --> 00:25:25.730
about tanks you know when there are
explosions gunshots those kinds of

00:25:25.730 --> 00:25:25.740
explosions gunshots those kinds of
 

00:25:25.740 --> 00:25:27.350
explosions gunshots those kinds of
things when people say Allah Akbar or

00:25:27.350 --> 00:25:27.360
things when people say Allah Akbar or
 

00:25:27.360 --> 00:25:29.539
things when people say Allah Akbar or
something like that I know it's gonna

00:25:29.539 --> 00:25:29.549
something like that I know it's gonna
 

00:25:29.549 --> 00:25:31.039
something like that I know it's gonna
take millions of dollars and you know

00:25:31.039 --> 00:25:31.049
take millions of dollars and you know
 

00:25:31.049 --> 00:25:32.870
take millions of dollars and you know
five or six years but if anyone has any

00:25:32.870 --> 00:25:32.880
five or six years but if anyone has any
 

00:25:32.880 --> 00:25:34.700
five or six years but if anyone has any
ideas let me know so people raise their

00:25:34.700 --> 00:25:34.710
ideas let me know so people raise their
 

00:25:34.710 --> 00:25:36.049
ideas let me know so people raise their
hands and gave me some interesting

00:25:36.049 --> 00:25:36.059
hands and gave me some interesting
 

00:25:36.059 --> 00:25:39.470
hands and gave me some interesting
advice and at the end Alex Hoffman and I

00:25:39.470 --> 00:25:39.480
advice and at the end Alex Hoffman and I
 

00:25:39.480 --> 00:25:40.850
advice and at the end Alex Hoffman and I
apologize there are actually some people

00:25:40.850 --> 00:25:40.860
apologize there are actually some people
 

00:25:40.860 --> 00:25:43.150
apologize there are actually some people
from the an event I did in Philadelphia

00:25:43.150 --> 00:25:43.160
from the an event I did in Philadelphia
 

00:25:43.160 --> 00:25:45.830
from the an event I did in Philadelphia
in the audience and I told the story

00:25:45.830 --> 00:25:45.840
in the audience and I told the story
 

00:25:45.840 --> 00:25:47.390
in the audience and I told the story
then but I'm telling it again I told it

00:25:47.390 --> 00:25:47.400
then but I'm telling it again I told it
 

00:25:47.400 --> 00:25:49.400
then but I'm telling it again I told it
with Alex the last time but Alex comes

00:25:49.400 --> 00:25:49.410
with Alex the last time but Alex comes
 

00:25:49.410 --> 00:25:51.770
with Alex the last time but Alex comes
up to me after and he says hey I'm Alex

00:25:51.770 --> 00:25:51.780
up to me after and he says hey I'm Alex
 

00:25:51.780 --> 00:25:53.990
up to me after and he says hey I'm Alex
I just wanted to let you know that the

00:25:53.990 --> 00:25:54.000
I just wanted to let you know that the
 

00:25:54.000 --> 00:25:55.520
I just wanted to let you know that the
US government has given me ten million

00:25:55.520 --> 00:25:55.530
US government has given me ten million
 

00:25:55.530 --> 00:25:58.810
US government has given me ten million
dollars to solve this problem and it's

00:25:58.810 --> 00:25:58.820
dollars to solve this problem and it's
 

00:25:58.820 --> 00:26:01.970
dollars to solve this problem and it's
basically solved and because it's basic

00:26:01.970 --> 00:26:01.980
basically solved and because it's basic
 

00:26:01.980 --> 00:26:04.040
basically solved and because it's basic
science you're welcome to share it and

00:26:04.040 --> 00:26:04.050
science you're welcome to share it and
 

00:26:04.050 --> 00:26:06.799
science you're welcome to share it and
so with that I started sharing this

00:26:06.799 --> 00:26:06.809
so with that I started sharing this
 

00:26:06.809 --> 00:26:07.940
so with that I started sharing this
technology with the human rights

00:26:07.940 --> 00:26:07.950
technology with the human rights
 

00:26:07.950 --> 00:26:09.770
technology with the human rights
community and it's now I can't really

00:26:09.770 --> 00:26:09.780
community and it's now I can't really
 

00:26:09.780 --> 00:26:11.870
community and it's now I can't really
say who's using it but a lot of big

00:26:11.870 --> 00:26:11.880
say who's using it but a lot of big
 

00:26:11.880 --> 00:26:13.669
say who's using it but a lot of big
organizations and smaller organizations

00:26:13.669 --> 00:26:13.679
organizations and smaller organizations
 

00:26:13.679 --> 00:26:16.549
organizations and smaller organizations
are using it there was I think my time

00:26:16.549 --> 00:26:16.559
are using it there was I think my time
 

00:26:16.559 --> 00:26:19.220
are using it there was I think my time
is up but there was a video we've been

00:26:19.220 --> 00:26:19.230
is up but there was a video we've been
 

00:26:19.230 --> 00:26:22.010
is up but there was a video we've been
involved in some work in sin in Ukraine

00:26:22.010 --> 00:26:22.020
involved in some work in sin in Ukraine
 

00:26:22.020 --> 00:26:23.780
involved in some work in sin in Ukraine
and we've brought together collections

00:26:23.780 --> 00:26:23.790
and we've brought together collections
 

00:26:23.790 --> 00:26:26.990
and we've brought together collections
of people experts in architecture people

00:26:26.990 --> 00:26:27.000
of people experts in architecture people
 

00:26:27.000 --> 00:26:28.669
of people experts in architecture people
who do computer vision machine learning

00:26:28.669 --> 00:26:28.679
who do computer vision machine learning
 

00:26:28.679 --> 00:26:31.400
who do computer vision machine learning
someone like me who does who does

00:26:31.400 --> 00:26:31.410
someone like me who does who does
 

00:26:31.410 --> 00:26:34.700
someone like me who does who does
history and political work lawyers we've

00:26:34.700 --> 00:26:34.710
history and political work lawyers we've
 

00:26:34.710 --> 00:26:36.049
history and political work lawyers we've
brought people who are experts in

00:26:36.049 --> 00:26:36.059
brought people who are experts in
 

00:26:36.059 --> 00:26:38.060
brought people who are experts in
bringing evidence and visualizing data

00:26:38.060 --> 00:26:38.070
bringing evidence and visualizing data
 

00:26:38.070 --> 00:26:40.750
bringing evidence and visualizing data
and and it's only through these

00:26:40.750 --> 00:26:40.760
and and it's only through these
 

00:26:40.760 --> 00:26:45.620
and and it's only through these
intentional groups where you have a goal

00:26:45.620 --> 00:26:45.630
intentional groups where you have a goal
 

00:26:45.630 --> 00:26:47.030
intentional groups where you have a goal
and our goal is to make the world a

00:26:47.030 --> 00:26:47.040
and our goal is to make the world a
 

00:26:47.040 --> 00:26:48.620
and our goal is to make the world a
slightly better place by bringing human

00:26:48.620 --> 00:26:48.630
slightly better place by bringing human
 

00:26:48.630 --> 00:26:51.410
slightly better place by bringing human
rights violations to light that you can

00:26:51.410 --> 00:26:51.420
rights violations to light that you can
 

00:26:51.420 --> 00:26:53.240
rights violations to light that you can
actually create technologies that the

00:26:53.240 --> 00:26:53.250
actually create technologies that the
 

00:26:53.250 --> 00:26:55.640
actually create technologies that the
human rights community can use because

00:26:55.640 --> 00:26:55.650
human rights community can use because
 

00:26:55.650 --> 00:26:57.110
human rights community can use because
when this stuff is just sitting in

00:26:57.110 --> 00:26:57.120
when this stuff is just sitting in
 

00:26:57.120 --> 00:26:59.480
when this stuff is just sitting in
someone's lab or being used by the

00:26:59.480 --> 00:26:59.490
someone's lab or being used by the
 

00:26:59.490 --> 00:27:00.740
someone's lab or being used by the
intelligence community in the United

00:27:00.740 --> 00:27:00.750
intelligence community in the United
 

00:27:00.750 --> 00:27:03.049
intelligence community in the United
States or the military or big companies

00:27:03.049 --> 00:27:03.059
States or the military or big companies
 

00:27:03.059 --> 00:27:05.390
States or the military or big companies
the human rights community doesn't know

00:27:05.390 --> 00:27:05.400
the human rights community doesn't know
 

00:27:05.400 --> 00:27:07.250
the human rights community doesn't know
it exists and so we there has to be some

00:27:07.250 --> 00:27:07.260
it exists and so we there has to be some
 

00:27:07.260 --> 00:27:09.770
it exists and so we there has to be some
kind of interface and Carnegie Mellon

00:27:09.770 --> 00:27:09.780
kind of interface and Carnegie Mellon
 

00:27:09.780 --> 00:27:12.320
kind of interface and Carnegie Mellon
has become one of those interfaces and

00:27:12.320 --> 00:27:12.330
has become one of those interfaces and
 

00:27:12.330 --> 00:27:13.940
has become one of those interfaces and
it's really because I can go talk to

00:27:13.940 --> 00:27:13.950
it's really because I can go talk to
 

00:27:13.950 --> 00:27:15.410
it's really because I can go talk to
people in computer science and they're

00:27:15.410 --> 00:27:15.420
people in computer science and they're
 

00:27:15.420 --> 00:27:17.150
people in computer science and they're
happy to talk to me and we can work

00:27:17.150 --> 00:27:17.160
happy to talk to me and we can work
 

00:27:17.160 --> 00:27:19.220
happy to talk to me and we can work
together that we can do this we're gonna

00:27:19.220 --> 00:27:19.230
together that we can do this we're gonna
 

00:27:19.230 --> 00:27:21.130
together that we can do this we're gonna
stay on the theme of just

00:27:21.130 --> 00:27:21.140
stay on the theme of just
 

00:27:21.140 --> 00:27:23.210
stay on the theme of just
interdisciplinary in a second I just

00:27:23.210 --> 00:27:23.220
interdisciplinary in a second I just
 

00:27:23.220 --> 00:27:25.640
interdisciplinary in a second I just
wanted to add two points one is the

00:27:25.640 --> 00:27:25.650
wanted to add two points one is the
 

00:27:25.650 --> 00:27:27.740
wanted to add two points one is the
number that 200,000 people were killed

00:27:27.740 --> 00:27:27.750
number that 200,000 people were killed
 

00:27:27.750 --> 00:27:30.950
number that 200,000 people were killed
in Bosnia in the war in Bosnia was a

00:27:30.950 --> 00:27:30.960
in Bosnia in the war in Bosnia was a
 

00:27:30.960 --> 00:27:32.720
in Bosnia in the war in Bosnia was a
number that came out very early in the

00:27:32.720 --> 00:27:32.730
number that came out very early in the
 

00:27:32.730 --> 00:27:34.250
number that came out very early in the
war there was no actual empirical

00:27:34.250 --> 00:27:34.260
war there was no actual empirical
 

00:27:34.260 --> 00:27:36.799
war there was no actual empirical
evidence but it drove policy

00:27:36.799 --> 00:27:36.809
evidence but it drove policy
 

00:27:36.809 --> 00:27:38.390
evidence but it drove policy
conversations over and over and over

00:27:38.390 --> 00:27:38.400
conversations over and over and over
 

00:27:38.400 --> 00:27:40.310
conversations over and over and over
again when you think about the war in

00:27:40.310 --> 00:27:40.320
again when you think about the war in
 

00:27:40.320 --> 00:27:42.590
again when you think about the war in
Syria this is the most photographed war

00:27:42.590 --> 00:27:42.600
Syria this is the most photographed war
 

00:27:42.600 --> 00:27:45.799
Syria this is the most photographed war
ever it's great that ten million dollars

00:27:45.799 --> 00:27:45.809
ever it's great that ten million dollars
 

00:27:45.809 --> 00:27:47.930
ever it's great that ten million dollars
went into this but ultimately we haven't

00:27:47.930 --> 00:27:47.940
went into this but ultimately we haven't
 

00:27:47.940 --> 00:27:50.360
went into this but ultimately we haven't
solved the problem obviously and this

00:27:50.360 --> 00:27:50.370
solved the problem obviously and this
 

00:27:50.370 --> 00:27:53.180
solved the problem obviously and this
war continues the thing that that

00:27:53.180 --> 00:27:53.190
war continues the thing that that
 

00:27:53.190 --> 00:27:56.510
war continues the thing that that
evidence will be helpful for is the

00:27:56.510 --> 00:27:56.520
evidence will be helpful for is the
 

00:27:56.520 --> 00:27:59.810
evidence will be helpful for is the
eventual war crimes trials so let's talk

00:27:59.810 --> 00:27:59.820
eventual war crimes trials so let's talk
 

00:27:59.820 --> 00:28:02.830
eventual war crimes trials so let's talk
about the most interdisciplinary

00:28:02.830 --> 00:28:02.840
about the most interdisciplinary
 

00:28:02.840 --> 00:28:05.600
about the most interdisciplinary
collection working on energy

00:28:05.600 --> 00:28:05.610
collection working on energy
 

00:28:05.610 --> 00:28:10.230
collection working on energy
apparently anywhere in the world Jay

00:28:10.230 --> 00:28:10.240
 

00:28:10.240 --> 00:28:15.630
very challenge yeah microphone please

00:28:15.630 --> 00:28:15.640
very challenge yeah microphone please
 

00:28:15.640 --> 00:28:20.310
very challenge yeah microphone please
microphone is is climate change and you

00:28:20.310 --> 00:28:20.320
microphone is is climate change and you
 

00:28:20.320 --> 00:28:22.500
microphone is is climate change and you
know we've been successful in this

00:28:22.500 --> 00:28:22.510
know we've been successful in this
 

00:28:22.510 --> 00:28:25.590
know we've been successful in this
country in putting a fence around

00:28:25.590 --> 00:28:25.600
country in putting a fence around
 

00:28:25.600 --> 00:28:27.990
country in putting a fence around
conventional pollution when I started

00:28:27.990 --> 00:28:28.000
conventional pollution when I started
 

00:28:28.000 --> 00:28:30.120
conventional pollution when I started
studying this 15 years ago we were

00:28:30.120 --> 00:28:30.130
studying this 15 years ago we were
 

00:28:30.130 --> 00:28:32.730
studying this 15 years ago we were
killing 40,000 people a year prematurely

00:28:32.730 --> 00:28:32.740
killing 40,000 people a year prematurely
 

00:28:32.740 --> 00:28:35.400
killing 40,000 people a year prematurely
by pollution from electric power plants

00:28:35.400 --> 00:28:35.410
by pollution from electric power plants
 

00:28:35.410 --> 00:28:36.780
by pollution from electric power plants
in the u.s. now it's down to a little

00:28:36.780 --> 00:28:36.790
in the u.s. now it's down to a little
 

00:28:36.790 --> 00:28:40.970
in the u.s. now it's down to a little
bit below 10,000 that's a big success

00:28:40.970 --> 00:28:40.980
bit below 10,000 that's a big success
 

00:28:40.980 --> 00:28:45.390
bit below 10,000 that's a big success
but I am sorry to have to tell you that

00:28:45.390 --> 00:28:45.400
but I am sorry to have to tell you that
 

00:28:45.400 --> 00:28:50.190
but I am sorry to have to tell you that
we are solidly on track for putting four

00:28:50.190 --> 00:28:50.200
we are solidly on track for putting four
 

00:28:50.200 --> 00:28:52.169
we are solidly on track for putting four
times the amount of co2 in our

00:28:52.169 --> 00:28:52.179
times the amount of co2 in our
 

00:28:52.179 --> 00:28:55.230
times the amount of co2 in our
atmosphere then we had before the

00:28:55.230 --> 00:28:55.240
atmosphere then we had before the
 

00:28:55.240 --> 00:28:58.230
atmosphere then we had before the
Industrial Revolution four times

00:28:58.230 --> 00:28:58.240
Industrial Revolution four times
 

00:28:58.240 --> 00:29:01.260
Industrial Revolution four times
pre-industrial co2 is going to guarantee

00:29:01.260 --> 00:29:01.270
pre-industrial co2 is going to guarantee
 

00:29:01.270 --> 00:29:04.380
pre-industrial co2 is going to guarantee
us something like 11 degrees Fahrenheit

00:29:04.380 --> 00:29:04.390
us something like 11 degrees Fahrenheit
 

00:29:04.390 --> 00:29:07.380
us something like 11 degrees Fahrenheit
warmer planet then when my father

00:29:07.380 --> 00:29:07.390
warmer planet then when my father
 

00:29:07.390 --> 00:29:12.230
warmer planet then when my father
studied mechanical engineering right and

00:29:12.230 --> 00:29:12.240
studied mechanical engineering right and
 

00:29:12.240 --> 00:29:18.570
studied mechanical engineering right and
that is a different planet people here

00:29:18.570 --> 00:29:18.580
that is a different planet people here
 

00:29:18.580 --> 00:29:20.669
that is a different planet people here
have looked at what that does for

00:29:20.669 --> 00:29:20.679
have looked at what that does for
 

00:29:20.679 --> 00:29:23.940
have looked at what that does for
example to the output of power plants

00:29:23.940 --> 00:29:23.950
example to the output of power plants
 

00:29:23.950 --> 00:29:29.390
example to the output of power plants
but CMU is going to have to lead the way

00:29:29.390 --> 00:29:29.400
but CMU is going to have to lead the way
 

00:29:29.400 --> 00:29:33.270
but CMU is going to have to lead the way
in figuring out how to put teams

00:29:33.270 --> 00:29:33.280
in figuring out how to put teams
 

00:29:33.280 --> 00:29:38.040
in figuring out how to put teams
together of engineers scientists

00:29:38.040 --> 00:29:38.050
together of engineers scientists
 

00:29:38.050 --> 00:29:41.160
together of engineers scientists
economists and people who understand

00:29:41.160 --> 00:29:41.170
economists and people who understand
 

00:29:41.170 --> 00:29:46.110
economists and people who understand
behavior to figure out what that hotter

00:29:46.110 --> 00:29:46.120
behavior to figure out what that hotter
 

00:29:46.120 --> 00:29:48.840
behavior to figure out what that hotter
world is going to look like from an

00:29:48.840 --> 00:29:48.850
world is going to look like from an
 

00:29:48.850 --> 00:29:52.530
world is going to look like from an
engineering standpoint our students are

00:29:52.530 --> 00:29:52.540
engineering standpoint our students are
 

00:29:52.540 --> 00:29:54.840
engineering standpoint our students are
going to have to operate in that hot

00:29:54.840 --> 00:29:54.850
going to have to operate in that hot
 

00:29:54.850 --> 00:29:57.780
going to have to operate in that hot
planet 11 degrees Fahrenheit hotter than

00:29:57.780 --> 00:29:57.790
planet 11 degrees Fahrenheit hotter than
 

00:29:57.790 --> 00:30:01.010
planet 11 degrees Fahrenheit hotter than
we have and that is a tremendous

00:30:01.010 --> 00:30:01.020
we have and that is a tremendous
 

00:30:01.020 --> 00:30:05.070
we have and that is a tremendous
opportunity for a breathtaking change in

00:30:05.070 --> 00:30:05.080
opportunity for a breathtaking change in
 

00:30:05.080 --> 00:30:07.110
opportunity for a breathtaking change in
our curriculum and it's an

00:30:07.110 --> 00:30:07.120
our curriculum and it's an
 

00:30:07.120 --> 00:30:10.410
our curriculum and it's an
interdisciplinary one Nina can you talk

00:30:10.410 --> 00:30:10.420
interdisciplinary one Nina can you talk
 

00:30:10.420 --> 00:30:13.049
interdisciplinary one Nina can you talk
to us about collaboration in physical

00:30:13.049 --> 00:30:13.059
to us about collaboration in physical
 

00:30:13.059 --> 00:30:16.560
to us about collaboration in physical
space absolutely you know all of the

00:30:16.560 --> 00:30:16.570
space absolutely you know all of the
 

00:30:16.570 --> 00:30:17.970
space absolutely you know all of the
work that we're doing on collective

00:30:17.970 --> 00:30:17.980
work that we're doing on collective
 

00:30:17.980 --> 00:30:19.230
work that we're doing on collective
intelligence is inherently

00:30:19.230 --> 00:30:19.240
intelligence is inherently
 

00:30:19.240 --> 00:30:21.480
intelligence is inherently
interdisciplinary we can't connect

00:30:21.480 --> 00:30:21.490
interdisciplinary we can't connect
 

00:30:21.490 --> 00:30:23.710
interdisciplinary we can't connect
problem solvers across the globe

00:30:23.710 --> 00:30:23.720
problem solvers across the globe
 

00:30:23.720 --> 00:30:26.770
problem solvers across the globe
without heavy involvement from folks in

00:30:26.770 --> 00:30:26.780
without heavy involvement from folks in
 

00:30:26.780 --> 00:30:28.659
without heavy involvement from folks in
computer science as well as people who

00:30:28.659 --> 00:30:28.669
computer science as well as people who
 

00:30:28.669 --> 00:30:31.090
computer science as well as people who
understand behavior you know both

00:30:31.090 --> 00:30:31.100
understand behavior you know both
 

00:30:31.100 --> 00:30:32.710
understand behavior you know both
cognitive psychology social psychology

00:30:32.710 --> 00:30:32.720
cognitive psychology social psychology
 

00:30:32.720 --> 00:30:36.549
cognitive psychology social psychology
people who study culture and so here

00:30:36.549 --> 00:30:36.559
people who study culture and so here
 

00:30:36.559 --> 00:30:38.590
people who study culture and so here
it's been very easy to accomplish this

00:30:38.590 --> 00:30:38.600
it's been very easy to accomplish this
 

00:30:38.600 --> 00:30:40.570
it's been very easy to accomplish this
both in terms of you know physical

00:30:40.570 --> 00:30:40.580
both in terms of you know physical
 

00:30:40.580 --> 00:30:41.919
both in terms of you know physical
layout especially now that we've

00:30:41.919 --> 00:30:41.929
layout especially now that we've
 

00:30:41.929 --> 00:30:44.500
layout especially now that we've
relocated here it's easy to entice my

00:30:44.500 --> 00:30:44.510
relocated here it's easy to entice my
 

00:30:44.510 --> 00:30:46.840
relocated here it's easy to entice my
computer science colleagues to come

00:30:46.840 --> 00:30:46.850
computer science colleagues to come
 

00:30:46.850 --> 00:30:48.460
computer science colleagues to come
across the street and see the new

00:30:48.460 --> 00:30:48.470
across the street and see the new
 

00:30:48.470 --> 00:30:51.430
across the street and see the new
building and get some good coffee so you

00:30:51.430 --> 00:30:51.440
building and get some good coffee so you
 

00:30:51.440 --> 00:30:54.270
building and get some good coffee so you
know stuff like that matters but also

00:30:54.270 --> 00:30:54.280
know stuff like that matters but also
 

00:30:54.280 --> 00:30:56.770
know stuff like that matters but also
you know just in terms of the the

00:30:56.770 --> 00:30:56.780
you know just in terms of the the
 

00:30:56.780 --> 00:30:59.590
you know just in terms of the the
culture of the school you know there are

00:30:59.590 --> 00:30:59.600
culture of the school you know there are
 

00:30:59.600 --> 00:31:02.049
culture of the school you know there are
places where you know certain kinds of

00:31:02.049 --> 00:31:02.059
places where you know certain kinds of
 

00:31:02.059 --> 00:31:03.880
places where you know certain kinds of
publications wouldn't count you know

00:31:03.880 --> 00:31:03.890
publications wouldn't count you know
 

00:31:03.890 --> 00:31:06.279
publications wouldn't count you know
before you have tenure in here that that

00:31:06.279 --> 00:31:06.289
before you have tenure in here that that
 

00:31:06.289 --> 00:31:07.810
before you have tenure in here that that
kind of thing has never been an issue or

00:31:07.810 --> 00:31:07.820
kind of thing has never been an issue or
 

00:31:07.820 --> 00:31:09.730
kind of thing has never been an issue or
who you get grants with and and that

00:31:09.730 --> 00:31:09.740
who you get grants with and and that
 

00:31:09.740 --> 00:31:11.799
who you get grants with and and that
sort of thing and so you know that's

00:31:11.799 --> 00:31:11.809
sort of thing and so you know that's
 

00:31:11.809 --> 00:31:16.120
sort of thing and so you know that's
been a critical part of fostering the

00:31:16.120 --> 00:31:16.130
been a critical part of fostering the
 

00:31:16.130 --> 00:31:17.710
been a critical part of fostering the
kinds of things that we've been able to

00:31:17.710 --> 00:31:17.720
kinds of things that we've been able to
 

00:31:17.720 --> 00:31:19.659
kinds of things that we've been able to
do the platform's that we've created for

00:31:19.659 --> 00:31:19.669
do the platform's that we've created for
 

00:31:19.669 --> 00:31:21.970
do the platform's that we've created for
collecting data and for fostering

00:31:21.970 --> 00:31:21.980
collecting data and for fostering
 

00:31:21.980 --> 00:31:24.010
collecting data and for fostering
collaboration across the universities

00:31:24.010 --> 00:31:24.020
collaboration across the universities
 

00:31:24.020 --> 00:31:27.159
collaboration across the universities
who are involved in the projects it's so

00:31:27.159 --> 00:31:27.169
who are involved in the projects it's so
 

00:31:27.169 --> 00:31:28.570
who are involved in the projects it's so
clear that if you're gonna solve these

00:31:28.570 --> 00:31:28.580
clear that if you're gonna solve these
 

00:31:28.580 --> 00:31:31.630
clear that if you're gonna solve these
complex problems you have to have people

00:31:31.630 --> 00:31:31.640
complex problems you have to have people
 

00:31:31.640 --> 00:31:34.029
complex problems you have to have people
hope that have different skills the rest

00:31:34.029 --> 00:31:34.039
hope that have different skills the rest
 

00:31:34.039 --> 00:31:35.470
hope that have different skills the rest
of our conversation is going to riff

00:31:35.470 --> 00:31:35.480
of our conversation is going to riff
 

00:31:35.480 --> 00:31:39.010
of our conversation is going to riff
back and forth between both the positive

00:31:39.010 --> 00:31:39.020
back and forth between both the positive
 

00:31:39.020 --> 00:31:41.350
back and forth between both the positive
and the negative aspects of Technology

00:31:41.350 --> 00:31:41.360
and the negative aspects of Technology
 

00:31:41.360 --> 00:31:43.840
and the negative aspects of Technology
we're gonna turn to Marshall now to show

00:31:43.840 --> 00:31:43.850
we're gonna turn to Marshall now to show
 

00:31:43.850 --> 00:31:46.360
we're gonna turn to Marshall now to show
us for lack of a better word some very

00:31:46.360 --> 00:31:46.370
us for lack of a better word some very
 

00:31:46.370 --> 00:31:49.630
us for lack of a better word some very
cool applications of Technology and how

00:31:49.630 --> 00:31:49.640
cool applications of Technology and how
 

00:31:49.640 --> 00:31:52.720
cool applications of Technology and how
they intersect with with humans thank

00:31:52.720 --> 00:31:52.730
they intersect with with humans thank
 

00:31:52.730 --> 00:31:55.450
they intersect with with humans thank
you yes let me show you a couple of

00:31:55.450 --> 00:31:55.460
you yes let me show you a couple of
 

00:31:55.460 --> 00:31:59.169
you yes let me show you a couple of
example of evolving technology from the

00:31:59.169 --> 00:31:59.179
example of evolving technology from the
 

00:31:59.179 --> 00:32:02.460
example of evolving technology from the
initial stage to applications that

00:32:02.460 --> 00:32:02.470
initial stage to applications that
 

00:32:02.470 --> 00:32:05.740
initial stage to applications that
matter to people let me start with the

00:32:05.740 --> 00:32:05.750
matter to people let me start with the
 

00:32:05.750 --> 00:32:08.289
matter to people let me start with the
first example here this is an example

00:32:08.289 --> 00:32:08.299
first example here this is an example
 

00:32:08.299 --> 00:32:11.700
first example here this is an example
from the our bio robotics lab this is a

00:32:11.700 --> 00:32:11.710
from the our bio robotics lab this is a
 

00:32:11.710 --> 00:32:14.080
from the our bio robotics lab this is a
collection of robots that was developed

00:32:14.080 --> 00:32:14.090
collection of robots that was developed
 

00:32:14.090 --> 00:32:16.000
collection of robots that was developed
over the years for a number of

00:32:16.000 --> 00:32:16.010
over the years for a number of
 

00:32:16.010 --> 00:32:17.770
over the years for a number of
applications from manufacturing

00:32:17.770 --> 00:32:17.780
applications from manufacturing
 

00:32:17.780 --> 00:32:21.580
applications from manufacturing
inspection evolving to search-and-rescue

00:32:21.580 --> 00:32:21.590
inspection evolving to search-and-rescue
 

00:32:21.590 --> 00:32:27.520
inspection evolving to search-and-rescue
et cetera next one please if you make

00:32:27.520 --> 00:32:27.530
et cetera next one please if you make
 

00:32:27.530 --> 00:32:29.590
et cetera next one please if you make
this this robot small enough you can

00:32:29.590 --> 00:32:29.600
this this robot small enough you can
 

00:32:29.600 --> 00:32:32.200
this this robot small enough you can
actually get inside the body this is an

00:32:32.200 --> 00:32:32.210
actually get inside the body this is an
 

00:32:32.210 --> 00:32:34.360
actually get inside the body this is an
example here with the thing beating on

00:32:34.360 --> 00:32:34.370
example here with the thing beating on
 

00:32:34.370 --> 00:32:35.950
example here with the thing beating on
you on your right is their heart and the

00:32:35.950 --> 00:32:35.960
you on your right is their heart and the
 

00:32:35.960 --> 00:32:36.420
you on your right is their heart and the
robot

00:32:36.420 --> 00:32:36.430
robot
 

00:32:36.430 --> 00:32:38.250
robot
quarreling on the surface of the heart

00:32:38.250 --> 00:32:38.260
quarreling on the surface of the heart
 

00:32:38.260 --> 00:32:41.340
quarreling on the surface of the heart
this robot is now certified for surgery

00:32:41.340 --> 00:32:41.350
this robot is now certified for surgery
 

00:32:41.350 --> 00:32:42.840
this robot is now certified for surgery
in fact a surgical team at the

00:32:42.840 --> 00:32:42.850
in fact a surgical team at the
 

00:32:42.850 --> 00:32:44.760
in fact a surgical team at the
University of Pittsburgh Medical Center

00:32:44.760 --> 00:32:44.770
University of Pittsburgh Medical Center
 

00:32:44.770 --> 00:32:48.690
University of Pittsburgh Medical Center
next door uses it for major surgery such

00:32:48.690 --> 00:32:48.700
next door uses it for major surgery such
 

00:32:48.700 --> 00:32:52.230
next door uses it for major surgery such
as throat cancer removal and surgery

00:32:52.230 --> 00:32:52.240
as throat cancer removal and surgery
 

00:32:52.240 --> 00:32:56.100
as throat cancer removal and surgery
like this this leads to the vision of

00:32:56.100 --> 00:32:56.110
like this this leads to the vision of
 

00:32:56.110 --> 00:32:59.280
like this this leads to the vision of
surgery without incision which basically

00:32:59.280 --> 00:32:59.290
surgery without incision which basically
 

00:32:59.290 --> 00:33:02.280
surgery without incision which basically
is a saving life-saving type of type of

00:33:02.280 --> 00:33:02.290
is a saving life-saving type of type of
 

00:33:02.290 --> 00:33:04.740
is a saving life-saving type of type of
surgery so this is an example here where

00:33:04.740 --> 00:33:04.750
surgery so this is an example here where
 

00:33:04.750 --> 00:33:07.860
surgery so this is an example here where
the initial research limited to robotics

00:33:07.860 --> 00:33:07.870
the initial research limited to robotics
 

00:33:07.870 --> 00:33:10.500
the initial research limited to robotics
leads to an application that is

00:33:10.500 --> 00:33:10.510
leads to an application that is
 

00:33:10.510 --> 00:33:14.310
leads to an application that is
literally life life-saving let me show

00:33:14.310 --> 00:33:14.320
literally life life-saving let me show
 

00:33:14.320 --> 00:33:18.060
literally life life-saving let me show
you another another example this example

00:33:18.060 --> 00:33:18.070
you another another example this example
 

00:33:18.070 --> 00:33:20.340
you another another example this example
comes from our applied machine learning

00:33:20.340 --> 00:33:20.350
comes from our applied machine learning
 

00:33:20.350 --> 00:33:22.500
comes from our applied machine learning
group from Professor Archer Dubrowski

00:33:22.500 --> 00:33:22.510
group from Professor Archer Dubrowski
 

00:33:22.510 --> 00:33:24.720
group from Professor Archer Dubrowski
that lab worked for many years on

00:33:24.720 --> 00:33:24.730
that lab worked for many years on
 

00:33:24.730 --> 00:33:26.850
that lab worked for many years on
basically data analytics machine

00:33:26.850 --> 00:33:26.860
basically data analytics machine
 

00:33:26.860 --> 00:33:29.490
basically data analytics machine
learning technology for variety of

00:33:29.490 --> 00:33:29.500
learning technology for variety of
 

00:33:29.500 --> 00:33:31.670
learning technology for variety of
applications predictive maintenance etc

00:33:31.670 --> 00:33:31.680
applications predictive maintenance etc
 

00:33:31.680 --> 00:33:35.070
applications predictive maintenance etc
then this lab linked up with a student

00:33:35.070 --> 00:33:35.080
then this lab linked up with a student
 

00:33:35.080 --> 00:33:36.780
then this lab linked up with a student
actually a student from the Hine school

00:33:36.780 --> 00:33:36.790
actually a student from the Hine school
 

00:33:36.790 --> 00:33:39.540
actually a student from the Hine school
Emily Kennedy who was interested in

00:33:39.540 --> 00:33:39.550
Emily Kennedy who was interested in
 

00:33:39.550 --> 00:33:43.080
Emily Kennedy who was interested in
policy and a societal issue and there

00:33:43.080 --> 00:33:43.090
policy and a societal issue and there
 

00:33:43.090 --> 00:33:45.390
policy and a societal issue and there
again the connection of the technology

00:33:45.390 --> 00:33:45.400
again the connection of the technology
 

00:33:45.400 --> 00:33:48.780
again the connection of the technology
with the human application area led to

00:33:48.780 --> 00:33:48.790
with the human application area led to
 

00:33:48.790 --> 00:33:51.060
with the human application area led to
the realization that this technology

00:33:51.060 --> 00:33:51.070
the realization that this technology
 

00:33:51.070 --> 00:33:53.600
the realization that this technology
could be used very effectively for

00:33:53.600 --> 00:33:53.610
could be used very effectively for
 

00:33:53.610 --> 00:33:56.970
could be used very effectively for
combating human trafficking this led to

00:33:56.970 --> 00:33:56.980
combating human trafficking this led to
 

00:33:56.980 --> 00:34:00.450
combating human trafficking this led to
an extensive research program this led

00:34:00.450 --> 00:34:00.460
an extensive research program this led
 

00:34:00.460 --> 00:34:02.040
an extensive research program this led
to accompany this led to a suite of

00:34:02.040 --> 00:34:02.050
to accompany this led to a suite of
 

00:34:02.050 --> 00:34:04.350
to accompany this led to a suite of
software that is now used by hundreds of

00:34:04.350 --> 00:34:04.360
software that is now used by hundreds of
 

00:34:04.360 --> 00:34:07.050
software that is now used by hundreds of
law enforcement organization throughout

00:34:07.050 --> 00:34:07.060
law enforcement organization throughout
 

00:34:07.060 --> 00:34:09.120
law enforcement organization throughout
the country and has led to arrests of

00:34:09.120 --> 00:34:09.130
the country and has led to arrests of
 

00:34:09.130 --> 00:34:10.760
the country and has led to arrests of
traffickers and most importantly

00:34:10.760 --> 00:34:10.770
traffickers and most importantly
 

00:34:10.770 --> 00:34:13.399
traffickers and most importantly
liberation of victims including children

00:34:13.399 --> 00:34:13.409
liberation of victims including children
 

00:34:13.409 --> 00:34:17.399
liberation of victims including children
so those are examples were the initial

00:34:17.399 --> 00:34:17.409
so those are examples were the initial
 

00:34:17.409 --> 00:34:20.040
so those are examples were the initial
technology development through the

00:34:20.040 --> 00:34:20.050
technology development through the
 

00:34:20.050 --> 00:34:23.070
technology development through the
connectedness with other other part of

00:34:23.070 --> 00:34:23.080
connectedness with other other part of
 

00:34:23.080 --> 00:34:24.600
connectedness with other other part of
the universities other part of the

00:34:24.600 --> 00:34:24.610
the universities other part of the
 

00:34:24.610 --> 00:34:27.780
the universities other part of the
ecosystem leads to new applications that

00:34:27.780 --> 00:34:27.790
ecosystem leads to new applications that
 

00:34:27.790 --> 00:34:30.899
ecosystem leads to new applications that
are in this case literally life saving

00:34:30.899 --> 00:34:30.909
are in this case literally life saving
 

00:34:30.909 --> 00:34:32.880
are in this case literally life saving
your life transforming so Marshall

00:34:32.880 --> 00:34:32.890
your life transforming so Marshall
 

00:34:32.890 --> 00:34:34.020
your life transforming so Marshall
didn't know it but he's out there

00:34:34.020 --> 00:34:34.030
didn't know it but he's out there
 

00:34:34.030 --> 00:34:36.090
didn't know it but he's out there
advancing five point two eight point

00:34:36.090 --> 00:34:36.100
advancing five point two eight point
 

00:34:36.100 --> 00:34:37.680
advancing five point two eight point
seven and sixteen point two which are

00:34:37.680 --> 00:34:37.690
seven and sixteen point two which are
 

00:34:37.690 --> 00:34:39.720
seven and sixteen point two which are
all commitments that we globally have

00:34:39.720 --> 00:34:39.730
all commitments that we globally have
 

00:34:39.730 --> 00:34:41.669
all commitments that we globally have
made to end human trafficking so thank

00:34:41.669 --> 00:34:41.679
made to end human trafficking so thank
 

00:34:41.679 --> 00:34:43.020
made to end human trafficking so thank
you for your work

00:34:43.020 --> 00:34:43.030
you for your work
 

00:34:43.030 --> 00:34:47.780
you for your work
Anita talk to us about the way in which

00:34:47.780 --> 00:34:47.790
Anita talk to us about the way in which
 

00:34:47.790 --> 00:34:49.710
Anita talk to us about the way in which
you know a lot of times we're worried

00:34:49.710 --> 00:34:49.720
you know a lot of times we're worried
 

00:34:49.720 --> 00:34:50.070
you know a lot of times we're worried
about

00:34:50.070 --> 00:34:50.080
about
 

00:34:50.080 --> 00:34:52.770
about
technology replacing people certainly

00:34:52.770 --> 00:34:52.780
technology replacing people certainly
 

00:34:52.780 --> 00:34:54.480
technology replacing people certainly
the work of the black Center is going to

00:34:54.480 --> 00:34:54.490
the work of the black Center is going to
 

00:34:54.490 --> 00:34:56.400
the work of the black Center is going to
be looking a lot at the future of work

00:34:56.400 --> 00:34:56.410
be looking a lot at the future of work
 

00:34:56.410 --> 00:35:01.200
be looking a lot at the future of work
and workers yeah absolutely and actually

00:35:01.200 --> 00:35:01.210
and workers yeah absolutely and actually
 

00:35:01.210 --> 00:35:02.640
and workers yeah absolutely and actually
some of our work with collective

00:35:02.640 --> 00:35:02.650
some of our work with collective
 

00:35:02.650 --> 00:35:04.890
some of our work with collective
intelligence is now being folded in with

00:35:04.890 --> 00:35:04.900
intelligence is now being folded in with
 

00:35:04.900 --> 00:35:06.810
intelligence is now being folded in with
what the block Center is doing in a

00:35:06.810 --> 00:35:06.820
what the block Center is doing in a
 

00:35:06.820 --> 00:35:09.600
what the block Center is doing in a
variety of different organizations but

00:35:09.600 --> 00:35:09.610
variety of different organizations but
 

00:35:09.610 --> 00:35:12.180
variety of different organizations but
as as I described when I was talking

00:35:12.180 --> 00:35:12.190
as as I described when I was talking
 

00:35:12.190 --> 00:35:13.800
as as I described when I was talking
about what contributes to collective

00:35:13.800 --> 00:35:13.810
about what contributes to collective
 

00:35:13.810 --> 00:35:15.630
about what contributes to collective
intelligence you know what we see is

00:35:15.630 --> 00:35:15.640
intelligence you know what we see is
 

00:35:15.640 --> 00:35:18.150
intelligence you know what we see is
essentially collective intelligence is

00:35:18.150 --> 00:35:18.160
essentially collective intelligence is
 

00:35:18.160 --> 00:35:20.610
essentially collective intelligence is
built upon both the quality of some

00:35:20.610 --> 00:35:20.620
built upon both the quality of some
 

00:35:20.620 --> 00:35:22.860
built upon both the quality of some
qualities or skills of the people in the

00:35:22.860 --> 00:35:22.870
qualities or skills of the people in the
 

00:35:22.870 --> 00:35:25.320
qualities or skills of the people in the
in the collective as well as the quality

00:35:25.320 --> 00:35:25.330
in the collective as well as the quality
 

00:35:25.330 --> 00:35:28.290
in the collective as well as the quality
of their connections and so a lot of

00:35:28.290 --> 00:35:28.300
of their connections and so a lot of
 

00:35:28.300 --> 00:35:30.030
of their connections and so a lot of
times when we think about technology

00:35:30.030 --> 00:35:30.040
times when we think about technology
 

00:35:30.040 --> 00:35:32.520
times when we think about technology
especially in AI and when you read about

00:35:32.520 --> 00:35:32.530
especially in AI and when you read about
 

00:35:32.530 --> 00:35:33.990
especially in AI and when you read about
the fear that's out there in

00:35:33.990 --> 00:35:34.000
the fear that's out there in
 

00:35:34.000 --> 00:35:35.880
the fear that's out there in
organizations and in the general public

00:35:35.880 --> 00:35:35.890
organizations and in the general public
 

00:35:35.890 --> 00:35:38.340
organizations and in the general public
it's it's really fear about you know the

00:35:38.340 --> 00:35:38.350
it's it's really fear about you know the
 

00:35:38.350 --> 00:35:40.980
it's it's really fear about you know the
robots coming and taking over jobs and

00:35:40.980 --> 00:35:40.990
robots coming and taking over jobs and
 

00:35:40.990 --> 00:35:43.530
robots coming and taking over jobs and
you know making certain skills obsolete

00:35:43.530 --> 00:35:43.540
you know making certain skills obsolete
 

00:35:43.540 --> 00:35:45.420
you know making certain skills obsolete
and that falls into the category of what

00:35:45.420 --> 00:35:45.430
and that falls into the category of what
 

00:35:45.430 --> 00:35:47.280
and that falls into the category of what
we call production technologies the

00:35:47.280 --> 00:35:47.290
we call production technologies the
 

00:35:47.290 --> 00:35:48.840
we call production technologies the
computer is taking in the place of

00:35:48.840 --> 00:35:48.850
computer is taking in the place of
 

00:35:48.850 --> 00:35:51.090
computer is taking in the place of
humans or at least making them more

00:35:51.090 --> 00:35:51.100
humans or at least making them more
 

00:35:51.100 --> 00:35:53.070
humans or at least making them more
efficient such that fewer humans are

00:35:53.070 --> 00:35:53.080
efficient such that fewer humans are
 

00:35:53.080 --> 00:35:55.620
efficient such that fewer humans are
needed to do the work and that's that's

00:35:55.620 --> 00:35:55.630
needed to do the work and that's that's
 

00:35:55.630 --> 00:35:57.960
needed to do the work and that's that's
an issue societally that we need to

00:35:57.960 --> 00:35:57.970
an issue societally that we need to
 

00:35:57.970 --> 00:36:00.420
an issue societally that we need to
really deal with there's another class

00:36:00.420 --> 00:36:00.430
really deal with there's another class
 

00:36:00.430 --> 00:36:02.070
really deal with there's another class
of technology however and it's the one

00:36:02.070 --> 00:36:02.080
of technology however and it's the one
 

00:36:02.080 --> 00:36:03.930
of technology however and it's the one
that we focus on more in the work and

00:36:03.930 --> 00:36:03.940
that we focus on more in the work and
 

00:36:03.940 --> 00:36:06.330
that we focus on more in the work and
collective intelligence which we call

00:36:06.330 --> 00:36:06.340
collective intelligence which we call
 

00:36:06.340 --> 00:36:08.670
collective intelligence which we call
coordination technology and this is the

00:36:08.670 --> 00:36:08.680
coordination technology and this is the
 

00:36:08.680 --> 00:36:10.740
coordination technology and this is the
technology used to connect the humans to

00:36:10.740 --> 00:36:10.750
technology used to connect the humans to
 

00:36:10.750 --> 00:36:12.990
technology used to connect the humans to
enhance the collaboration that's

00:36:12.990 --> 00:36:13.000
enhance the collaboration that's
 

00:36:13.000 --> 00:36:15.450
enhance the collaboration that's
possible the nature of the communication

00:36:15.450 --> 00:36:15.460
possible the nature of the communication
 

00:36:15.460 --> 00:36:16.770
possible the nature of the communication
the amount and the quality of

00:36:16.770 --> 00:36:16.780
the amount and the quality of
 

00:36:16.780 --> 00:36:18.930
the amount and the quality of
communication and so that's what we are

00:36:18.930 --> 00:36:18.940
communication and so that's what we are
 

00:36:18.940 --> 00:36:20.610
communication and so that's what we are
really focusing on in our work on

00:36:20.610 --> 00:36:20.620
really focusing on in our work on
 

00:36:20.620 --> 00:36:22.410
really focusing on in our work on
collective intelligence how can we make

00:36:22.410 --> 00:36:22.420
collective intelligence how can we make
 

00:36:22.420 --> 00:36:25.200
collective intelligence how can we make
you know all collectives operate at the

00:36:25.200 --> 00:36:25.210
you know all collectives operate at the
 

00:36:25.210 --> 00:36:27.570
you know all collectives operate at the
highest level possible even if they

00:36:27.570 --> 00:36:27.580
highest level possible even if they
 

00:36:27.580 --> 00:36:29.580
highest level possible even if they
don't have the people with the social

00:36:29.580 --> 00:36:29.590
don't have the people with the social
 

00:36:29.590 --> 00:36:33.210
don't have the people with the social
skills for example can we men the nature

00:36:33.210 --> 00:36:33.220
skills for example can we men the nature
 

00:36:33.220 --> 00:36:35.850
skills for example can we men the nature
of the the communication processes so

00:36:35.850 --> 00:36:35.860
of the the communication processes so
 

00:36:35.860 --> 00:36:39.090
of the the communication processes so
that they're more effective can we you

00:36:39.090 --> 00:36:39.100
that they're more effective can we you
 

00:36:39.100 --> 00:36:41.580
that they're more effective can we you
know prime people so that they'll maybe

00:36:41.580 --> 00:36:41.590
know prime people so that they'll maybe
 

00:36:41.590 --> 00:36:43.260
know prime people so that they'll maybe
pay attention to the fact that they're

00:36:43.260 --> 00:36:43.270
pay attention to the fact that they're
 

00:36:43.270 --> 00:36:44.940
pay attention to the fact that they're
dominating the conversation and they

00:36:44.940 --> 00:36:44.950
dominating the conversation and they
 

00:36:44.950 --> 00:36:48.090
dominating the conversation and they
should let some other people in and so

00:36:48.090 --> 00:36:48.100
should let some other people in and so
 

00:36:48.100 --> 00:36:51.240
should let some other people in and so
we some work with Laura - over in HCI I

00:36:51.240 --> 00:36:51.250
we some work with Laura - over in HCI I
 

00:36:51.250 --> 00:36:54.150
we some work with Laura - over in HCI I
we look at synchrony and various

00:36:54.150 --> 00:36:54.160
we look at synchrony and various
 

00:36:54.160 --> 00:36:56.250
we look at synchrony and various
physiological cues and when people pick

00:36:56.250 --> 00:36:56.260
physiological cues and when people pick
 

00:36:56.260 --> 00:36:58.620
physiological cues and when people pick
up on the fact that others have negative

00:36:58.620 --> 00:36:58.630
up on the fact that others have negative
 

00:36:58.630 --> 00:37:00.630
up on the fact that others have negative
facial expressions and synchronize with

00:37:00.630 --> 00:37:00.640
facial expressions and synchronize with
 

00:37:00.640 --> 00:37:02.890
facial expressions and synchronize with
those we see that the group has

00:37:02.890 --> 00:37:02.900
those we see that the group has
 

00:37:02.900 --> 00:37:04.569
those we see that the group has
higher collective intelligence well is

00:37:04.569 --> 00:37:04.579
higher collective intelligence well is
 

00:37:04.579 --> 00:37:06.910
higher collective intelligence well is
there a way to actually you know prime

00:37:06.910 --> 00:37:06.920
there a way to actually you know prime
 

00:37:06.920 --> 00:37:09.069
there a way to actually you know prime
people to pay attention to these things

00:37:09.069 --> 00:37:09.079
people to pay attention to these things
 

00:37:09.079 --> 00:37:12.010
people to pay attention to these things
if they're not necessarily doing so on

00:37:12.010 --> 00:37:12.020
if they're not necessarily doing so on
 

00:37:12.020 --> 00:37:13.990
if they're not necessarily doing so on
their own so those are the kinds of

00:37:13.990 --> 00:37:14.000
their own so those are the kinds of
 

00:37:14.000 --> 00:37:16.240
their own so those are the kinds of
interventions that we're looking at in

00:37:16.240 --> 00:37:16.250
interventions that we're looking at in
 

00:37:16.250 --> 00:37:18.390
interventions that we're looking at in
using technology to foster better

00:37:18.390 --> 00:37:18.400
using technology to foster better
 

00:37:18.400 --> 00:37:22.240
using technology to foster better
communication across humans so we're

00:37:22.240 --> 00:37:22.250
communication across humans so we're
 

00:37:22.250 --> 00:37:24.160
communication across humans so we're
gonna dig deep now into this positive

00:37:24.160 --> 00:37:24.170
gonna dig deep now into this positive
 

00:37:24.170 --> 00:37:25.660
gonna dig deep now into this positive
and negative aspects

00:37:25.660 --> 00:37:25.670
and negative aspects
 

00:37:25.670 --> 00:37:28.359
and negative aspects
I'm gonna be teaching a course starting

00:37:28.359 --> 00:37:28.369
I'm gonna be teaching a course starting
 

00:37:28.369 --> 00:37:31.089
I'm gonna be teaching a course starting
in January that looks at advancing

00:37:31.089 --> 00:37:31.099
in January that looks at advancing
 

00:37:31.099 --> 00:37:32.289
in January that looks at advancing
democracy and human rights in the 21st

00:37:32.289 --> 00:37:32.299
democracy and human rights in the 21st
 

00:37:32.299 --> 00:37:35.230
democracy and human rights in the 21st
century which is code for how has

00:37:35.230 --> 00:37:35.240
century which is code for how has
 

00:37:35.240 --> 00:37:37.359
century which is code for how has
technology and innovation both helped

00:37:37.359 --> 00:37:37.369
technology and innovation both helped
 

00:37:37.369 --> 00:37:40.630
technology and innovation both helped
and hurt so on the positive side

00:37:40.630 --> 00:37:40.640
and hurt so on the positive side
 

00:37:40.640 --> 00:37:42.789
and hurt so on the positive side
you know the Twitter revolution the Arab

00:37:42.789 --> 00:37:42.799
you know the Twitter revolution the Arab
 

00:37:42.799 --> 00:37:45.279
you know the Twitter revolution the Arab
Awakening was really very much driven by

00:37:45.279 --> 00:37:45.289
Awakening was really very much driven by
 

00:37:45.289 --> 00:37:47.980
Awakening was really very much driven by
social media but then we have to deal

00:37:47.980 --> 00:37:47.990
social media but then we have to deal
 

00:37:47.990 --> 00:37:50.440
social media but then we have to deal
with the backlash and also the fact that

00:37:50.440 --> 00:37:50.450
with the backlash and also the fact that
 

00:37:50.450 --> 00:37:51.880
with the backlash and also the fact that
people didn't necessarily know how to

00:37:51.880 --> 00:37:51.890
people didn't necessarily know how to
 

00:37:51.890 --> 00:37:55.059
people didn't necessarily know how to
organize we have an ongoing mass

00:37:55.059 --> 00:37:55.069
organize we have an ongoing mass
 

00:37:55.069 --> 00:37:56.440
organize we have an ongoing mass
atrocity in rahega

00:37:56.440 --> 00:37:56.450
atrocity in rahega
 

00:37:56.450 --> 00:37:58.269
atrocity in rahega
with the wrecking go but we have drones

00:37:58.269 --> 00:37:58.279
with the wrecking go but we have drones
 

00:37:58.279 --> 00:38:01.000
with the wrecking go but we have drones
that are actually able to capture film

00:38:01.000 --> 00:38:01.010
that are actually able to capture film
 

00:38:01.010 --> 00:38:03.370
that are actually able to capture film
and that will be used both in the UN but

00:38:03.370 --> 00:38:03.380
and that will be used both in the UN but
 

00:38:03.380 --> 00:38:06.670
and that will be used both in the UN but
in in international courts I know Jay

00:38:06.670 --> 00:38:06.680
in in international courts I know Jay
 

00:38:06.680 --> 00:38:08.910
in in international courts I know Jay
that you have lots to say about this

00:38:08.910 --> 00:38:08.920
that you have lots to say about this
 

00:38:08.920 --> 00:38:11.349
that you have lots to say about this
certainly is a Russia specialist I've

00:38:11.349 --> 00:38:11.359
certainly is a Russia specialist I've
 

00:38:11.359 --> 00:38:14.170
certainly is a Russia specialist I've
been very focused on the impact of the

00:38:14.170 --> 00:38:14.180
been very focused on the impact of the
 

00:38:14.180 --> 00:38:16.450
been very focused on the impact of the
Russians not spending very much money

00:38:16.450 --> 00:38:16.460
Russians not spending very much money
 

00:38:16.460 --> 00:38:18.609
Russians not spending very much money
frankly I mean the the hacking the troll

00:38:18.609 --> 00:38:18.619
frankly I mean the the hacking the troll
 

00:38:18.619 --> 00:38:21.460
frankly I mean the the hacking the troll
farms you know a million here million

00:38:21.460 --> 00:38:21.470
farms you know a million here million
 

00:38:21.470 --> 00:38:24.099
farms you know a million here million
there all things said not a lot of money

00:38:24.099 --> 00:38:24.109
there all things said not a lot of money
 

00:38:24.109 --> 00:38:27.010
there all things said not a lot of money
given the amount of chaos and

00:38:27.010 --> 00:38:27.020
given the amount of chaos and
 

00:38:27.020 --> 00:38:28.510
given the amount of chaos and
uncertainty that they've they've

00:38:28.510 --> 00:38:28.520
uncertainty that they've they've
 

00:38:28.520 --> 00:38:32.589
uncertainty that they've they've
engendered so I just um if I may just

00:38:32.589 --> 00:38:32.599
engendered so I just um if I may just
 

00:38:32.599 --> 00:38:34.180
engendered so I just um if I may just
make a couple of quick points um one is

00:38:34.180 --> 00:38:34.190
make a couple of quick points um one is
 

00:38:34.190 --> 00:38:36.279
make a couple of quick points um one is
that I think my proudest achievement

00:38:36.279 --> 00:38:36.289
that I think my proudest achievement
 

00:38:36.289 --> 00:38:37.539
that I think my proudest achievement
here at Carnegie Mellon was actually

00:38:37.539 --> 00:38:37.549
here at Carnegie Mellon was actually
 

00:38:37.549 --> 00:38:39.849
here at Carnegie Mellon was actually
sending Emily over to talk to Artur I

00:38:39.849 --> 00:38:39.859
sending Emily over to talk to Artur I
 

00:38:39.859 --> 00:38:41.109
sending Emily over to talk to Artur I
don't know if you know this but Emily

00:38:41.109 --> 00:38:41.119
don't know if you know this but Emily
 

00:38:41.119 --> 00:38:43.210
don't know if you know this but Emily
was actually my student and she was

00:38:43.210 --> 00:38:43.220
was actually my student and she was
 

00:38:43.220 --> 00:38:44.529
was actually my student and she was
doing you know what I thought was

00:38:44.529 --> 00:38:44.539
doing you know what I thought was
 

00:38:44.539 --> 00:38:46.089
doing you know what I thought was
interesting research on how the Internet

00:38:46.089 --> 00:38:46.099
interesting research on how the Internet
 

00:38:46.099 --> 00:38:48.039
interesting research on how the Internet
is changing human trafficking and I was

00:38:48.039 --> 00:38:48.049
is changing human trafficking and I was
 

00:38:48.049 --> 00:38:50.920
is changing human trafficking and I was
like honestly Emily like we know that I

00:38:50.920 --> 00:38:50.930
like honestly Emily like we know that I
 

00:38:50.930 --> 00:38:52.510
like honestly Emily like we know that I
think what would be really interesting

00:38:52.510 --> 00:38:52.520
think what would be really interesting
 

00:38:52.520 --> 00:38:53.740
think what would be really interesting
if you actually tried to do something

00:38:53.740 --> 00:38:53.750
if you actually tried to do something
 

00:38:53.750 --> 00:38:55.180
if you actually tried to do something
about it why don't you go talk to the

00:38:55.180 --> 00:38:55.190
about it why don't you go talk to the
 

00:38:55.190 --> 00:38:57.359
about it why don't you go talk to the
people here at Carnegie Mellon who are

00:38:57.359 --> 00:38:57.369
people here at Carnegie Mellon who are
 

00:38:57.369 --> 00:38:59.980
people here at Carnegie Mellon who are
engaged in network analysis and see see

00:38:59.980 --> 00:38:59.990
engaged in network analysis and see see
 

00:38:59.990 --> 00:39:01.690
engaged in network analysis and see see
if there's anything to be done I had no

00:39:01.690 --> 00:39:01.700
if there's anything to be done I had no
 

00:39:01.700 --> 00:39:05.260
if there's anything to be done I had no
idea I mean I love I love Emily I I had

00:39:05.260 --> 00:39:05.270
idea I mean I love I love Emily I I had
 

00:39:05.270 --> 00:39:06.910
idea I mean I love I love Emily I I had
so much faith in her I had no idea what

00:39:06.910 --> 00:39:06.920
so much faith in her I had no idea what
 

00:39:06.920 --> 00:39:09.099
so much faith in her I had no idea what
she was going to do and I just it was

00:39:09.099 --> 00:39:09.109
she was going to do and I just it was
 

00:39:09.109 --> 00:39:12.010
she was going to do and I just it was
it's an amazing story like if if I never

00:39:12.010 --> 00:39:12.020
it's an amazing story like if if I never
 

00:39:12.020 --> 00:39:14.470
it's an amazing story like if if I never
do anything again I'll feel like I'll

00:39:14.470 --> 00:39:14.480
do anything again I'll feel like I'll
 

00:39:14.480 --> 00:39:15.910
do anything again I'll feel like I'll
have accomplished something by just

00:39:15.910 --> 00:39:15.920
have accomplished something by just
 

00:39:15.920 --> 00:39:16.480
have accomplished something by just
sending her

00:39:16.480 --> 00:39:16.490
sending her
 

00:39:16.490 --> 00:39:18.600
sending her
retired tourists it was cool to see that

00:39:18.600 --> 00:39:18.610
retired tourists it was cool to see that
 

00:39:18.610 --> 00:39:21.390
retired tourists it was cool to see that
so the second thing is the the

00:39:21.390 --> 00:39:21.400
so the second thing is the the
 

00:39:21.400 --> 00:39:23.800
so the second thing is the the
interactions that Marshall is showing

00:39:23.800 --> 00:39:23.810
interactions that Marshall is showing
 

00:39:23.810 --> 00:39:26.620
interactions that Marshall is showing
where that child the in the autism study

00:39:26.620 --> 00:39:26.630
where that child the in the autism study
 

00:39:26.630 --> 00:39:28.030
where that child the in the autism study
we're actually being done in a room in

00:39:28.030 --> 00:39:28.040
we're actually being done in a room in
 

00:39:28.040 --> 00:39:30.370
we're actually being done in a room in
the basement of Wien is in the basement

00:39:30.370 --> 00:39:30.380
the basement of Wien is in the basement
 

00:39:30.380 --> 00:39:36.430
the basement of Wien is in the basement
of lean and what's that room called so

00:39:36.430 --> 00:39:36.440
of lean and what's that room called so
 

00:39:36.440 --> 00:39:37.720
of lean and what's that room called so
so it's called the panopticon

00:39:37.720 --> 00:39:37.730
so it's called the panopticon
 

00:39:37.730 --> 00:39:41.050
so it's called the panopticon
essentially which is the picture that I

00:39:41.050 --> 00:39:41.060
essentially which is the picture that I
 

00:39:41.060 --> 00:39:43.450
essentially which is the picture that I
don't know if you'll is here but it's

00:39:43.450 --> 00:39:43.460
don't know if you'll is here but it's
 

00:39:43.460 --> 00:39:45.190
don't know if you'll is here but it's
it's really interesting that these

00:39:45.190 --> 00:39:45.200
it's really interesting that these
 

00:39:45.200 --> 00:39:47.800
it's really interesting that these
technologies have multiple valances and

00:39:47.800 --> 00:39:47.810
technologies have multiple valances and
 

00:39:47.810 --> 00:39:49.540
technologies have multiple valances and
many uses I'm teaching a course on

00:39:49.540 --> 00:39:49.550
many uses I'm teaching a course on
 

00:39:49.550 --> 00:39:51.460
many uses I'm teaching a course on
surveillance now and I actually start

00:39:51.460 --> 00:39:51.470
surveillance now and I actually start
 

00:39:51.470 --> 00:39:54.670
surveillance now and I actually start
with that image so it's very interesting

00:39:54.670 --> 00:39:54.680
with that image so it's very interesting
 

00:39:54.680 --> 00:39:57.640
with that image so it's very interesting
that the panopticon that's you know

00:39:57.640 --> 00:39:57.650
that the panopticon that's you know
 

00:39:57.650 --> 00:39:59.980
that the panopticon that's you know
watching us and and we're Marcia was

00:39:59.980 --> 00:39:59.990
watching us and and we're Marcia was
 

00:39:59.990 --> 00:40:01.840
watching us and and we're Marcia was
talking about a pen optic classroom

00:40:01.840 --> 00:40:01.850
talking about a pen optic classroom
 

00:40:01.850 --> 00:40:03.130
talking about a pen optic classroom
there's a lot of good that can come out

00:40:03.130 --> 00:40:03.140
there's a lot of good that can come out
 

00:40:03.140 --> 00:40:04.810
there's a lot of good that can come out
of that but there's also a lot of bad

00:40:04.810 --> 00:40:04.820
of that but there's also a lot of bad
 

00:40:04.820 --> 00:40:06.340
of that but there's also a lot of bad
that can come out of that like if the

00:40:06.340 --> 00:40:06.350
that can come out of that like if the
 

00:40:06.350 --> 00:40:09.580
that can come out of that like if the
university starts evaluating our

00:40:09.580 --> 00:40:09.590
university starts evaluating our
 

00:40:09.590 --> 00:40:11.340
university starts evaluating our
behavior in the classroom based on

00:40:11.340 --> 00:40:11.350
behavior in the classroom based on
 

00:40:11.350 --> 00:40:13.420
behavior in the classroom based on
cameras that they put how does that

00:40:13.420 --> 00:40:13.430
cameras that they put how does that
 

00:40:13.430 --> 00:40:15.070
cameras that they put how does that
change the relationship between the

00:40:15.070 --> 00:40:15.080
change the relationship between the
 

00:40:15.080 --> 00:40:16.930
change the relationship between the
student and the teacher so these are

00:40:16.930 --> 00:40:16.940
student and the teacher so these are
 

00:40:16.940 --> 00:40:18.250
student and the teacher so these are
these are things that we have to think

00:40:18.250 --> 00:40:18.260
these are things that we have to think
 

00:40:18.260 --> 00:40:22.900
these are things that we have to think
very carefully about one of the in in as

00:40:22.900 --> 00:40:22.910
very carefully about one of the in in as
 

00:40:22.910 --> 00:40:24.880
very carefully about one of the in in as
far as anita was talking one of the

00:40:24.880 --> 00:40:24.890
far as anita was talking one of the
 

00:40:24.890 --> 00:40:26.680
far as anita was talking one of the
things that I sort of enter into

00:40:26.680 --> 00:40:26.690
things that I sort of enter into
 

00:40:26.690 --> 00:40:28.090
things that I sort of enter into
conversations with human rights

00:40:28.090 --> 00:40:28.100
conversations with human rights
 

00:40:28.100 --> 00:40:30.430
conversations with human rights
colleagues is that AI and machine

00:40:30.430 --> 00:40:30.440
colleagues is that AI and machine
 

00:40:30.440 --> 00:40:33.160
colleagues is that AI and machine
learning cannot and will not and will

00:40:33.160 --> 00:40:33.170
learning cannot and will not and will
 

00:40:33.170 --> 00:40:35.950
learning cannot and will not and will
never replace human judgment and human

00:40:35.950 --> 00:40:35.960
never replace human judgment and human
 

00:40:35.960 --> 00:40:38.020
never replace human judgment and human
knowledge what they can do is like any

00:40:38.020 --> 00:40:38.030
knowledge what they can do is like any
 

00:40:38.030 --> 00:40:40.690
knowledge what they can do is like any
other power tool whether it's a saw or a

00:40:40.690 --> 00:40:40.700
other power tool whether it's a saw or a
 

00:40:40.700 --> 00:40:44.410
other power tool whether it's a saw or a
you know a screwdriver or something like

00:40:44.410 --> 00:40:44.420
you know a screwdriver or something like
 

00:40:44.420 --> 00:40:46.570
you know a screwdriver or something like
that no matter what it is they can make

00:40:46.570 --> 00:40:46.580
that no matter what it is they can make
 

00:40:46.580 --> 00:40:48.160
that no matter what it is they can make
the human more effective and more

00:40:48.160 --> 00:40:48.170
the human more effective and more
 

00:40:48.170 --> 00:40:50.230
the human more effective and more
efficient but I really don't think they

00:40:50.230 --> 00:40:50.240
efficient but I really don't think they
 

00:40:50.240 --> 00:40:52.480
efficient but I really don't think they
can replace the human you know maybe in

00:40:52.480 --> 00:40:52.490
can replace the human you know maybe in
 

00:40:52.490 --> 00:40:54.849
can replace the human you know maybe in
surgery we can argue that in some cases

00:40:54.849 --> 00:40:54.859
surgery we can argue that in some cases
 

00:40:54.859 --> 00:40:56.830
surgery we can argue that in some cases
they can but certainly when it comes to

00:40:56.830 --> 00:40:56.840
they can but certainly when it comes to
 

00:40:56.840 --> 00:40:58.240
they can but certainly when it comes to
human judgment we're never going to

00:40:58.240 --> 00:40:58.250
human judgment we're never going to
 

00:40:58.250 --> 00:41:01.630
human judgment we're never going to
replace human judgment so I always ask

00:41:01.630 --> 00:41:01.640
replace human judgment so I always ask
 

00:41:01.640 --> 00:41:03.940
replace human judgment so I always ask
human rights colleagues what is your

00:41:03.940 --> 00:41:03.950
human rights colleagues what is your
 

00:41:03.950 --> 00:41:06.609
human rights colleagues what is your
goal what's your intention and sometimes

00:41:06.609 --> 00:41:06.619
goal what's your intention and sometimes
 

00:41:06.619 --> 00:41:08.230
goal what's your intention and sometimes
technology can help get you there like

00:41:08.230 --> 00:41:08.240
technology can help get you there like
 

00:41:08.240 --> 00:41:10.990
technology can help get you there like
if you want to show that some particular

00:41:10.990 --> 00:41:11.000
if you want to show that some particular
 

00:41:11.000 --> 00:41:12.550
if you want to show that some particular
behavior is systemic and you have a

00:41:12.550 --> 00:41:12.560
behavior is systemic and you have a
 

00:41:12.560 --> 00:41:14.410
behavior is systemic and you have a
million and a half videos you're never

00:41:14.410 --> 00:41:14.420
million and a half videos you're never
 

00:41:14.420 --> 00:41:15.730
million and a half videos you're never
going to be able to get through them and

00:41:15.730 --> 00:41:15.740
going to be able to get through them and
 

00:41:15.740 --> 00:41:17.620
going to be able to get through them and
find all of the instances but machine

00:41:17.620 --> 00:41:17.630
find all of the instances but machine
 

00:41:17.630 --> 00:41:19.000
find all of the instances but machine
learning and computer vision can help

00:41:19.000 --> 00:41:19.010
learning and computer vision can help
 

00:41:19.010 --> 00:41:21.580
learning and computer vision can help
you in that case bringing it before a

00:41:21.580 --> 00:41:21.590
you in that case bringing it before a
 

00:41:21.590 --> 00:41:23.560
you in that case bringing it before a
judge and convincing a judge that this

00:41:23.560 --> 00:41:23.570
judge and convincing a judge that this
 

00:41:23.570 --> 00:41:25.480
judge and convincing a judge that this
is a pattern that actually matters and

00:41:25.480 --> 00:41:25.490
is a pattern that actually matters and
 

00:41:25.490 --> 00:41:28.630
is a pattern that actually matters and
that requires some form of justice and

00:41:28.630 --> 00:41:28.640
that requires some form of justice and
 

00:41:28.640 --> 00:41:30.220
that requires some form of justice and
accountability isn't something

00:41:30.220 --> 00:41:30.230
accountability isn't something
 

00:41:30.230 --> 00:41:31.240
accountability isn't something
that machine learning and computer

00:41:31.240 --> 00:41:31.250
that machine learning and computer
 

00:41:31.250 --> 00:41:34.630
that machine learning and computer
vision and AI can do so we need to we

00:41:34.630 --> 00:41:34.640
vision and AI can do so we need to we
 

00:41:34.640 --> 00:41:37.750
vision and AI can do so we need to we
need I think we need to learn when these

00:41:37.750 --> 00:41:37.760
need I think we need to learn when these
 

00:41:37.760 --> 00:41:39.700
need I think we need to learn when these
tools can help us and when we should

00:41:39.700 --> 00:41:39.710
tools can help us and when we should
 

00:41:39.710 --> 00:41:42.040
tools can help us and when we should
just put them down and go sit in a room

00:41:42.040 --> 00:41:42.050
just put them down and go sit in a room
 

00:41:42.050 --> 00:41:43.599
just put them down and go sit in a room
without cameras without technology

00:41:43.599 --> 00:41:43.609
without cameras without technology
 

00:41:43.609 --> 00:41:45.099
without cameras without technology
without our cell phones and actually

00:41:45.099 --> 00:41:45.109
without our cell phones and actually
 

00:41:45.109 --> 00:41:46.359
without our cell phones and actually
talk and try and figure out what matters

00:41:46.359 --> 00:41:46.369
talk and try and figure out what matters
 

00:41:46.369 --> 00:41:48.970
talk and try and figure out what matters
to us and so I think that Carnegie

00:41:48.970 --> 00:41:48.980
to us and so I think that Carnegie
 

00:41:48.980 --> 00:41:50.290
to us and so I think that Carnegie
Mellon is actually a place where you can

00:41:50.290 --> 00:41:50.300
Mellon is actually a place where you can
 

00:41:50.300 --> 00:41:52.859
Mellon is actually a place where you can
do that so I think I'll stop there and

00:41:52.859 --> 00:41:52.869
do that so I think I'll stop there and
 

00:41:52.869 --> 00:41:56.620
do that so I think I'll stop there and
let others this morning when I woke up

00:41:56.620 --> 00:41:56.630
let others this morning when I woke up
 

00:41:56.630 --> 00:42:00.910
let others this morning when I woke up
on MSNBC the editor of Wired was on and

00:42:00.910 --> 00:42:00.920
on MSNBC the editor of Wired was on and
 

00:42:00.920 --> 00:42:03.160
on MSNBC the editor of Wired was on and
there's gonna be a new issue called AI

00:42:03.160 --> 00:42:03.170
there's gonna be a new issue called AI
 

00:42:03.170 --> 00:42:05.680
there's gonna be a new issue called AI
and the cold war or the coming cold war

00:42:05.680 --> 00:42:05.690
and the cold war or the coming cold war
 

00:42:05.690 --> 00:42:09.010
and the cold war or the coming cold war
and it's looking at the role that AI is

00:42:09.010 --> 00:42:09.020
and it's looking at the role that AI is
 

00:42:09.020 --> 00:42:12.310
and it's looking at the role that AI is
how it's being used by various

00:42:12.310 --> 00:42:12.320
how it's being used by various
 

00:42:12.320 --> 00:42:13.630
how it's being used by various
governments that are trying to crack

00:42:13.630 --> 00:42:13.640
governments that are trying to crack
 

00:42:13.640 --> 00:42:16.300
governments that are trying to crack
down on their their population so it's

00:42:16.300 --> 00:42:16.310
down on their their population so it's
 

00:42:16.310 --> 00:42:18.730
down on their their population so it's
absolutely something that colleagues at

00:42:18.730 --> 00:42:18.740
absolutely something that colleagues at
 

00:42:18.740 --> 00:42:21.670
absolutely something that colleagues at
CMU would be in a great position to help

00:42:21.670 --> 00:42:21.680
CMU would be in a great position to help
 

00:42:21.680 --> 00:42:24.910
CMU would be in a great position to help
address it's it's critical for the kind

00:42:24.910 --> 00:42:24.920
address it's it's critical for the kind
 

00:42:24.920 --> 00:42:27.820
address it's it's critical for the kind
of future we want to see when we were

00:42:27.820 --> 00:42:27.830
of future we want to see when we were
 

00:42:27.830 --> 00:42:29.170
of future we want to see when we were
here yesterday talking among ourselves

00:42:29.170 --> 00:42:29.180
here yesterday talking among ourselves
 

00:42:29.180 --> 00:42:31.830
here yesterday talking among ourselves
and we were going down a sort of dark

00:42:31.830 --> 00:42:31.840
and we were going down a sort of dark
 

00:42:31.840 --> 00:42:34.630
and we were going down a sort of dark
hole and sort of saying things have

00:42:34.630 --> 00:42:34.640
hole and sort of saying things have
 

00:42:34.640 --> 00:42:35.980
hole and sort of saying things have
gotten worse

00:42:35.980 --> 00:42:35.990
gotten worse
 

00:42:35.990 --> 00:42:37.870
gotten worse
J was very smart to argue actually

00:42:37.870 --> 00:42:37.880
J was very smart to argue actually
 

00:42:37.880 --> 00:42:41.290
J was very smart to argue actually
things are better than they've been can

00:42:41.290 --> 00:42:41.300
things are better than they've been can
 

00:42:41.300 --> 00:42:42.400
things are better than they've been can
I ask you to talk a little bit about

00:42:42.400 --> 00:42:42.410
I ask you to talk a little bit about
 

00:42:42.410 --> 00:42:47.950
I ask you to talk a little bit about
that sure you can ask yourself are you

00:42:47.950 --> 00:42:47.960
that sure you can ask yourself are you
 

00:42:47.960 --> 00:42:52.900
that sure you can ask yourself are you
better off than your parents and if

00:42:52.900 --> 00:42:52.910
better off than your parents and if
 

00:42:52.910 --> 00:42:55.390
better off than your parents and if
you're in almost any country in the

00:42:55.390 --> 00:42:55.400
you're in almost any country in the
 

00:42:55.400 --> 00:42:55.930
you're in almost any country in the
world

00:42:55.930 --> 00:42:55.940
world
 

00:42:55.940 --> 00:42:58.990
world
the answer is dramatically better people

00:42:58.990 --> 00:42:59.000
the answer is dramatically better people
 

00:42:59.000 --> 00:43:02.020
the answer is dramatically better people
live longer they are wealthier and they

00:43:02.020 --> 00:43:02.030
live longer they are wealthier and they
 

00:43:02.030 --> 00:43:04.750
live longer they are wealthier and they
are much much healthier get on the

00:43:04.750 --> 00:43:04.760
are much much healthier get on the
 

00:43:04.760 --> 00:43:07.150
are much much healthier get on the
internet and look at the heat late

00:43:07.150 --> 00:43:07.160
internet and look at the heat late
 

00:43:07.160 --> 00:43:10.840
internet and look at the heat late
Hans roebling's videos where he has this

00:43:10.840 --> 00:43:10.850
Hans roebling's videos where he has this
 

00:43:10.850 --> 00:43:13.599
Hans roebling's videos where he has this
animated graph where he has wealth on a

00:43:13.599 --> 00:43:13.609
animated graph where he has wealth on a
 

00:43:13.609 --> 00:43:16.030
animated graph where he has wealth on a
logarithmic axis on the horizontal axis

00:43:16.030 --> 00:43:16.040
logarithmic axis on the horizontal axis
 

00:43:16.040 --> 00:43:20.560
logarithmic axis on the horizontal axis
and long life on the other axis in all

00:43:20.560 --> 00:43:20.570
and long life on the other axis in all
 

00:43:20.570 --> 00:43:23.020
and long life on the other axis in all
the countries in the MU in the world are

00:43:23.020 --> 00:43:23.030
the countries in the MU in the world are
 

00:43:23.030 --> 00:43:25.480
the countries in the MU in the world are
moving from the lower left to the upper

00:43:25.480 --> 00:43:25.490
moving from the lower left to the upper
 

00:43:25.490 --> 00:43:29.140
moving from the lower left to the upper
right rapidly and a lot of that is due

00:43:29.140 --> 00:43:29.150
right rapidly and a lot of that is due
 

00:43:29.150 --> 00:43:32.020
right rapidly and a lot of that is due
to technology including electricity the

00:43:32.020 --> 00:43:32.030
to technology including electricity the
 

00:43:32.030 --> 00:43:35.650
to technology including electricity the
Green Revolution vaccines and so we have

00:43:35.650 --> 00:43:35.660
Green Revolution vaccines and so we have
 

00:43:35.660 --> 00:43:40.930
Green Revolution vaccines and so we have
lots to be thankful for but human nature

00:43:40.930 --> 00:43:40.940
lots to be thankful for but human nature
 

00:43:40.940 --> 00:43:42.510
lots to be thankful for but human nature
doesn't change

00:43:42.510 --> 00:43:42.520
doesn't change
 

00:43:42.520 --> 00:43:44.790
doesn't change
and all of these technologies are used

00:43:44.790 --> 00:43:44.800
and all of these technologies are used
 

00:43:44.800 --> 00:43:47.400
and all of these technologies are used
for good and ill but the fact is that

00:43:47.400 --> 00:43:47.410
for good and ill but the fact is that
 

00:43:47.410 --> 00:43:51.150
for good and ill but the fact is that
the base rates of death early death the

00:43:51.150 --> 00:43:51.160
the base rates of death early death the
 

00:43:51.160 --> 00:43:54.840
the base rates of death early death the
base rates of disease and of poverty are

00:43:54.840 --> 00:43:54.850
base rates of disease and of poverty are
 

00:43:54.850 --> 00:43:59.100
base rates of disease and of poverty are
all getting much much better and you had

00:43:59.100 --> 00:43:59.110
all getting much much better and you had
 

00:43:59.110 --> 00:44:03.480
all getting much much better and you had
some statistics specific ones so there

00:44:03.480 --> 00:44:03.490
some statistics specific ones so there
 

00:44:03.490 --> 00:44:05.130
some statistics specific ones so there
was a predecessor to the sustainable

00:44:05.130 --> 00:44:05.140
was a predecessor to the sustainable
 

00:44:05.140 --> 00:44:06.900
was a predecessor to the sustainable
development goals called the Millennium

00:44:06.900 --> 00:44:06.910
development goals called the Millennium
 

00:44:06.910 --> 00:44:09.450
development goals called the Millennium
Development Goals which ran from 2000 to

00:44:09.450 --> 00:44:09.460
Development Goals which ran from 2000 to
 

00:44:09.460 --> 00:44:12.780
Development Goals which ran from 2000 to
2015 this was a set of goals that were

00:44:12.780 --> 00:44:12.790
2015 this was a set of goals that were
 

00:44:12.790 --> 00:44:15.420
2015 this was a set of goals that were
really put together by a handful of men

00:44:15.420 --> 00:44:15.430
really put together by a handful of men
 

00:44:15.430 --> 00:44:18.900
really put together by a handful of men
it was mostly men in a closed room but

00:44:18.900 --> 00:44:18.910
it was mostly men in a closed room but
 

00:44:18.910 --> 00:44:20.520
it was mostly men in a closed room but
they were they were aspirational and

00:44:20.520 --> 00:44:20.530
they were they were aspirational and
 

00:44:20.530 --> 00:44:22.200
they were they were aspirational and
they were about reducing poverty and

00:44:22.200 --> 00:44:22.210
they were about reducing poverty and
 

00:44:22.210 --> 00:44:28.170
they were about reducing poverty and
reducing maternal death and they had an

00:44:28.170 --> 00:44:28.180
reducing maternal death and they had an
 

00:44:28.180 --> 00:44:33.210
reducing maternal death and they had an
impact by 2015 the number of people

00:44:33.210 --> 00:44:33.220
impact by 2015 the number of people
 

00:44:33.220 --> 00:44:35.370
impact by 2015 the number of people
living in extreme poverty on the planet

00:44:35.370 --> 00:44:35.380
living in extreme poverty on the planet
 

00:44:35.380 --> 00:44:41.550
living in extreme poverty on the planet
had reduced from 26% in 2002 or 1990 to

00:44:41.550 --> 00:44:41.560
had reduced from 26% in 2002 or 1990 to
 

00:44:41.560 --> 00:44:44.280
had reduced from 26% in 2002 or 1990 to
10% in 2015

00:44:44.280 --> 00:44:44.290
10% in 2015
 

00:44:44.290 --> 00:44:47.280
10% in 2015
right so 26% to 10%

00:44:47.280 --> 00:44:47.290
right so 26% to 10%
 

00:44:47.290 --> 00:44:49.680
right so 26% to 10%
this is according to the World Bank that

00:44:49.680 --> 00:44:49.690
this is according to the World Bank that
 

00:44:49.690 --> 00:44:52.920
this is according to the World Bank that
is the power of collective action that

00:44:52.920 --> 00:44:52.930
is the power of collective action that
 

00:44:52.930 --> 00:44:57.000
is the power of collective action that
is what the MDGs delivered imagine what

00:44:57.000 --> 00:44:57.010
is what the MDGs delivered imagine what
 

00:44:57.010 --> 00:45:01.470
is what the MDGs delivered imagine what
it's like when that energy involves us

00:45:01.470 --> 00:45:01.480
it's like when that energy involves us
 

00:45:01.480 --> 00:45:04.020
it's like when that energy involves us
also working on us that it's the

00:45:04.020 --> 00:45:04.030
also working on us that it's the
 

00:45:04.030 --> 00:45:05.430
also working on us that it's the
sustainable development goals it's not

00:45:05.430 --> 00:45:05.440
sustainable development goals it's not
 

00:45:05.440 --> 00:45:07.470
sustainable development goals it's not
just about the global North talking

00:45:07.470 --> 00:45:07.480
just about the global North talking
 

00:45:07.480 --> 00:45:11.640
just about the global North talking
about the so-called global South that's

00:45:11.640 --> 00:45:11.650
about the so-called global South that's
 

00:45:11.650 --> 00:45:13.740
about the so-called global South that's
why I think there's an enormous power

00:45:13.740 --> 00:45:13.750
why I think there's an enormous power
 

00:45:13.750 --> 00:45:16.980
why I think there's an enormous power
and potential possibly but I welcome a

00:45:16.980 --> 00:45:16.990
and potential possibly but I welcome a
 

00:45:16.990 --> 00:45:18.900
and potential possibly but I welcome a
frank conversation about the pros and

00:45:18.900 --> 00:45:18.910
frank conversation about the pros and
 

00:45:18.910 --> 00:45:21.840
frank conversation about the pros and
cons the difficulties there's certain

00:45:21.840 --> 00:45:21.850
cons the difficulties there's certain
 

00:45:21.850 --> 00:45:23.460
cons the difficulties there's certain
aspects of the sustainable development

00:45:23.460 --> 00:45:23.470
aspects of the sustainable development
 

00:45:23.470 --> 00:45:25.440
aspects of the sustainable development
goals clearly that CMU is already

00:45:25.440 --> 00:45:25.450
goals clearly that CMU is already
 

00:45:25.450 --> 00:45:28.530
goals clearly that CMU is already
working on and their parts that they're

00:45:28.530 --> 00:45:28.540
working on and their parts that they're
 

00:45:28.540 --> 00:45:30.210
working on and their parts that they're
not gonna be able to work on but even to

00:45:30.210 --> 00:45:30.220
not gonna be able to work on but even to
 

00:45:30.220 --> 00:45:32.730
not gonna be able to work on but even to
be a first mover and champion other

00:45:32.730 --> 00:45:32.740
be a first mover and champion other
 

00:45:32.740 --> 00:45:34.950
be a first mover and champion other
universities I think it's it's an

00:45:34.950 --> 00:45:34.960
universities I think it's it's an
 

00:45:34.960 --> 00:45:37.260
universities I think it's it's an
extremely important time and it's an

00:45:37.260 --> 00:45:37.270
extremely important time and it's an
 

00:45:37.270 --> 00:45:40.440
extremely important time and it's an
extremely important role so I'm with

00:45:40.440 --> 00:45:40.450
extremely important role so I'm with
 

00:45:40.450 --> 00:45:42.570
extremely important role so I'm with
that I want to I want to thank our

00:45:42.570 --> 00:45:42.580
that I want to I want to thank our
 

00:45:42.580 --> 00:45:44.340
that I want to I want to thank our
colleagues if you have any parting shots

00:45:44.340 --> 00:45:44.350
colleagues if you have any parting shots
 

00:45:44.350 --> 00:45:45.540
colleagues if you have any parting shots
that you want to make this would be the

00:45:45.540 --> 00:45:45.550
that you want to make this would be the
 

00:45:45.550 --> 00:45:47.450
that you want to make this would be the
time

00:45:47.450 --> 00:45:47.460
time
 

00:45:47.460 --> 00:45:51.150
time
no I'm then I want to thank you very

00:45:51.150 --> 00:45:51.160
no I'm then I want to thank you very
 

00:45:51.160 --> 00:45:53.220
no I'm then I want to thank you very
much for your attention and I want to

00:45:53.220 --> 00:45:53.230
much for your attention and I want to
 

00:45:53.230 --> 00:45:56.390
much for your attention and I want to
invite president

00:45:56.390 --> 00:45:56.400
invite president
 

00:45:56.400 --> 00:46:01.100
invite president
which would you prefer president doctor

00:46:01.100 --> 00:46:01.110
 

00:46:01.110 --> 00:46:04.380
that's what I told her president dr.

00:46:04.380 --> 00:46:04.390
that's what I told her president dr.
 

00:46:04.390 --> 00:46:07.820
that's what I told her president dr.
Farnum dhania please come to the stage

00:46:07.820 --> 00:46:07.830
Farnum dhania please come to the stage
 

00:46:07.830 --> 00:46:25.040
Farnum dhania please come to the stage
[Applause]

00:46:25.040 --> 00:46:25.050
 

00:46:25.050 --> 00:46:28.350
well thank you Sarah for leading that

00:46:28.350 --> 00:46:28.360
well thank you Sarah for leading that
 

00:46:28.360 --> 00:46:32.760
well thank you Sarah for leading that
discussion and and many thanks to all of

00:46:32.760 --> 00:46:32.770
discussion and and many thanks to all of
 

00:46:32.770 --> 00:46:35.700
discussion and and many thanks to all of
our panelists this afternoon for

00:46:35.700 --> 00:46:35.710
our panelists this afternoon for
 

00:46:35.710 --> 00:46:39.660
our panelists this afternoon for
demonstrating how CMU's researchers are

00:46:39.660 --> 00:46:39.670
demonstrating how CMU's researchers are
 

00:46:39.670 --> 00:46:43.410
demonstrating how CMU's researchers are
enriching and impacting lives here in

00:46:43.410 --> 00:46:43.420
enriching and impacting lives here in
 

00:46:43.420 --> 00:46:45.720
enriching and impacting lives here in
our region as well as around the world

00:46:45.720 --> 00:46:45.730
our region as well as around the world
 

00:46:45.730 --> 00:46:47.520
our region as well as around the world
please join me once again

00:46:47.520 --> 00:46:47.530
please join me once again
 

00:46:47.530 --> 00:46:56.940
please join me once again
thank you CY my job is so easy I have to

00:46:56.940 --> 00:46:56.950
thank you CY my job is so easy I have to
 

00:46:56.950 --> 00:47:00.210
thank you CY my job is so easy I have to
represent this this is so remarkable so

00:47:00.210 --> 00:47:00.220
represent this this is so remarkable so
 

00:47:00.220 --> 00:47:04.410
represent this this is so remarkable so
amazing as we heard today the underlying

00:47:04.410 --> 00:47:04.420
amazing as we heard today the underlying
 

00:47:04.420 --> 00:47:07.890
amazing as we heard today the underlying
culture cultural social and economic

00:47:07.890 --> 00:47:07.900
culture cultural social and economic
 

00:47:07.900 --> 00:47:10.380
culture cultural social and economic
factors behind some of the society's

00:47:10.380 --> 00:47:10.390
factors behind some of the society's
 

00:47:10.390 --> 00:47:12.990
factors behind some of the society's
most complex challenges require

00:47:12.990 --> 00:47:13.000
most complex challenges require
 

00:47:13.000 --> 00:47:15.390
most complex challenges require
collaboration across many disciplines

00:47:15.390 --> 00:47:15.400
collaboration across many disciplines
 

00:47:15.400 --> 00:47:19.380
collaboration across many disciplines
here at CMU this collaboration is woven

00:47:19.380 --> 00:47:19.390
here at CMU this collaboration is woven
 

00:47:19.390 --> 00:47:22.050
here at CMU this collaboration is woven
into the fabric of our culture and our

00:47:22.050 --> 00:47:22.060
into the fabric of our culture and our
 

00:47:22.060 --> 00:47:25.590
into the fabric of our culture and our
human centered approach gives us a

00:47:25.590 --> 00:47:25.600
human centered approach gives us a
 

00:47:25.600 --> 00:47:27.750
human centered approach gives us a
unique advantage in understanding

00:47:27.750 --> 00:47:27.760
unique advantage in understanding
 

00:47:27.760 --> 00:47:31.890
unique advantage in understanding
behavior data and impact I hope all of

00:47:31.890 --> 00:47:31.900
behavior data and impact I hope all of
 

00:47:31.900 --> 00:47:34.500
behavior data and impact I hope all of
you enjoyed today's symposium as much as

00:47:34.500 --> 00:47:34.510
you enjoyed today's symposium as much as
 

00:47:34.510 --> 00:47:39.630
you enjoyed today's symposium as much as
I did I am so honored and humbled by

00:47:39.630 --> 00:47:39.640
I did I am so honored and humbled by
 

00:47:39.640 --> 00:47:41.880
I did I am so honored and humbled by
your presence at today's conversations

00:47:41.880 --> 00:47:41.890
your presence at today's conversations
 

00:47:41.890 --> 00:47:44.720
your presence at today's conversations
and at all the inauguration festivities

00:47:44.720 --> 00:47:44.730
and at all the inauguration festivities
 

00:47:44.730 --> 00:47:48.450
and at all the inauguration festivities
today each and every member of our

00:47:48.450 --> 00:47:48.460
today each and every member of our
 

00:47:48.460 --> 00:47:51.960
today each and every member of our
community has a role to play in writing

00:47:51.960 --> 00:47:51.970
community has a role to play in writing
 

00:47:51.970 --> 00:47:54.480
community has a role to play in writing
the next exciting chapter of Carnegie

00:47:54.480 --> 00:47:54.490
the next exciting chapter of Carnegie
 

00:47:54.490 --> 00:47:57.150
the next exciting chapter of Carnegie
Mellon University I think we all can

00:47:57.150 --> 00:47:57.160
Mellon University I think we all can
 

00:47:57.160 --> 00:47:59.670
Mellon University I think we all can
agree that our future is an inspiring

00:47:59.670 --> 00:47:59.680
agree that our future is an inspiring
 

00:47:59.680 --> 00:48:02.760
agree that our future is an inspiring
one this weekend's festivities actually

00:48:02.760 --> 00:48:02.770
one this weekend's festivities actually
 

00:48:02.770 --> 00:48:07.890
one this weekend's festivities actually
are not over it's Homecoming weekend for

00:48:07.890 --> 00:48:07.900
are not over it's Homecoming weekend for
 

00:48:07.900 --> 00:48:08.210
are not over it's Homecoming weekend for
us

00:48:08.210 --> 00:48:08.220
us
 

00:48:08.220 --> 00:48:11.000
us
so I hope that you will join me and our

00:48:11.000 --> 00:48:11.010
so I hope that you will join me and our
 

00:48:11.010 --> 00:48:12.859
so I hope that you will join me and our
colleagues for our homecoming

00:48:12.859 --> 00:48:12.869
colleagues for our homecoming
 

00:48:12.869 --> 00:48:16.280
colleagues for our homecoming
festivities tomorrow they start at 7:00

00:48:16.280 --> 00:48:16.290
festivities tomorrow they start at 7:00
 

00:48:16.290 --> 00:48:22.099
festivities tomorrow they start at 7:00
a.m. I'll be up and running and the game

00:48:22.099 --> 00:48:22.109
a.m. I'll be up and running and the game
 

00:48:22.109 --> 00:48:24.680
a.m. I'll be up and running and the game
against Geneva starts at 1:00 p.m.

00:48:24.680 --> 00:48:24.690
against Geneva starts at 1:00 p.m.
 

00:48:24.690 --> 00:48:26.960
against Geneva starts at 1:00 p.m.
p.m. I hope to see you all there and

00:48:26.960 --> 00:48:26.970
p.m. I hope to see you all there and
 

00:48:26.970 --> 00:48:29.240
p.m. I hope to see you all there and
thank you again for joining us enjoy

00:48:29.240 --> 00:48:29.250
thank you again for joining us enjoy
 

00:48:29.250 --> 00:48:30.460
thank you again for joining us enjoy
yours

00:48:30.460 --> 00:48:30.470
yours
 

00:48:30.470 --> 00:48:42.360
yours
[Applause]

00:48:42.360 --> 00:48:42.370
 

00:48:42.370 --> 00:48:44.430
you

