WEBVTT
Kind: captions
Language: en

00:00:00.120 --> 00:00:02.500
The following content is
provided under a Creative

00:00:02.500 --> 00:00:03.910
Commons license.

00:00:03.910 --> 00:00:06.950
Your support will help MIT
OpenCourseWare continue to

00:00:06.950 --> 00:00:10.600
offer high quality educational
resources for free.

00:00:10.600 --> 00:00:13.500
To make a donation or view
additional materials from

00:00:13.500 --> 00:00:17.430
hundreds of MIT courses, visit
MIT OpenCourseWare at

00:00:17.430 --> 00:00:18.680
ocw.mit.edu.

00:00:29.540 --> 00:00:30.010
PROFESSOR: All right.

00:00:30.010 --> 00:00:32.759
Can everyone hear me?

00:00:32.759 --> 00:00:35.960
So I guess it's 2:35, and we
might as well get started.

00:00:35.960 --> 00:00:39.110
So the calendar, I think, still
says that we have a

00:00:39.110 --> 00:00:42.690
guest lecture today but sorry to
disappoint you, there is no

00:00:42.690 --> 00:00:43.970
guest lecture.

00:00:43.970 --> 00:00:47.640
Instead we have a quiz for
you on Thursday, which is

00:00:47.640 --> 00:00:48.950
so much more fun.

00:00:48.950 --> 00:00:50.560
Not really.

00:00:50.560 --> 00:00:53.950
But I do realize that everybody
has a lot to do,

00:00:53.950 --> 00:00:55.300
even just for this class.

00:00:55.300 --> 00:00:57.300
You guys have your final
project and so on.

00:00:57.300 --> 00:00:59.360
So hopefully this
will be helpful.

00:00:59.360 --> 00:01:03.340
It won't take the entire 1 and
1/2 hours, I don't think.

00:01:03.340 --> 00:01:06.420
And the remaining time will be
up in office hours, answering

00:01:06.420 --> 00:01:08.880
questions about stuff.

00:01:08.880 --> 00:01:15.020
So the first thing is I decided
to run some stats that

00:01:15.020 --> 00:01:17.270
we haven't run before
for this class.

00:01:17.270 --> 00:01:20.100
These are your Project 42
4.2 final submissions.

00:01:20.100 --> 00:01:23.840
And in the red are your beta
submission run times.

00:01:23.840 --> 00:01:26.380
And in the blue are your
corresponding final

00:01:26.380 --> 00:01:28.540
submission run times.

00:01:28.540 --> 00:01:31.820
I thought it was just
interesting to see some groups

00:01:31.820 --> 00:01:36.590
did massive improvements, while
others didn't really

00:01:36.590 --> 00:01:39.020
change their programs much.

00:01:39.020 --> 00:01:43.890
And just to give you an idea,
a 90% for your performance

00:01:43.890 --> 00:01:48.090
grade is indicated by that
green line and below.

00:01:48.090 --> 00:01:50.470
So the majority of the class
did really well.

00:01:54.800 --> 00:01:55.240
All right.

00:01:55.240 --> 00:01:58.420
So the thing that everybody's
concerned about.

00:01:58.420 --> 00:02:03.070
So Quiz 2 will be in lecture
on Thursday.

00:02:03.070 --> 00:02:06.220
It'll be an 80 minute quiz,
similar in format to the

00:02:06.220 --> 00:02:07.680
previous one.

00:02:07.680 --> 00:02:12.400
And you guys once again are
allowed a one-page handwritten

00:02:12.400 --> 00:02:14.060
crib sheet.

00:02:14.060 --> 00:02:19.730
And it covers everything that
has been done since Quiz 1.

00:02:19.730 --> 00:02:22.340
It's not designed to be
cumulative, but unfortunately

00:02:22.340 --> 00:02:24.470
due to the nature of the class,
there's going to be

00:02:24.470 --> 00:02:28.130
some things from the previous
part of the class that you

00:02:28.130 --> 00:02:31.950
would need to know or it would
be helpful to know.

00:02:31.950 --> 00:02:36.100
Unlike last time, we didn't
post a practice quiz on

00:02:36.100 --> 00:02:39.410
Stellar, because it turns out
that the material and the

00:02:39.410 --> 00:02:41.650
order of the material gets
shuffled around quite a bit

00:02:41.650 --> 00:02:42.200
every year.

00:02:42.200 --> 00:02:43.970
And we have different focuses.

00:02:43.970 --> 00:02:46.720
So posting a practice quiz would
actually be pretty mean,

00:02:46.720 --> 00:02:49.330
because it would cause
you guys to study the

00:02:49.330 --> 00:02:51.690
wrong things instead.

00:02:51.690 --> 00:02:57.250
Instead I try to extract the
most useful things from our

00:02:57.250 --> 00:02:59.730
discussions of what the quiz
is going to be this time.

00:02:59.730 --> 00:03:03.010
So hopefully all this
information is helpful.

00:03:03.010 --> 00:03:04.800
Feel free to interrupt
me at any

00:03:04.800 --> 00:03:06.225
time if you have questions.

00:03:10.040 --> 00:03:13.790
So the first part, I would
roughly call analyzing and

00:03:13.790 --> 00:03:16.680
possibly writing parallel
programs.

00:03:16.680 --> 00:03:22.790
And to start off, is everybody
familiar with what one of

00:03:22.790 --> 00:03:24.500
these graphs represents?

00:03:24.500 --> 00:03:27.600
So you have work and then
each circle is a

00:03:27.600 --> 00:03:28.730
unit amount of work.

00:03:28.730 --> 00:03:32.460
And then the graph shows the
dependencies of the things.

00:03:32.460 --> 00:03:35.400
So just to start off with a
really simple question, what

00:03:35.400 --> 00:03:36.810
is the total amount of
work represented?

00:03:41.779 --> 00:03:45.707
AUDIENCE: [LAUGHTER]

00:03:45.707 --> 00:03:46.198
PROFESSOR: Uh oh.

00:03:46.198 --> 00:03:49.798
I heard 17, which is not what I
got when I counted this last

00:03:49.798 --> 00:03:50.617
night at 2:00.

00:03:50.617 --> 00:03:51.599
AUDIENCE: 26.

00:03:51.599 --> 00:03:52.849
AUDIENCE: 24.

00:03:55.050 --> 00:03:55.880
PROFESSOR: I like 24.

00:03:55.880 --> 00:03:57.750
AUDIENCE: [LAUGHTER]

00:03:57.750 --> 00:03:59.920
PROFESSOR: And I'm going to
assume it's 24, and not

00:03:59.920 --> 00:04:02.980
embarrass myself by trying
to count it.

00:04:02.980 --> 00:04:04.400
Now what is the span?

00:04:12.285 --> 00:04:14.265
AUDIENCE: 8.

00:04:14.265 --> 00:04:14.760
AUDIENCE: 8.

00:04:14.760 --> 00:04:15.750
AUDIENCE: 8.

00:04:15.750 --> 00:04:16.910
PROFESSOR: 8 sounds right.

00:04:16.910 --> 00:04:19.700
So the longest path-- there's
actually a couple different

00:04:19.700 --> 00:04:23.710
paths that end up being 8, but
I think 8's the right answer.

00:04:23.710 --> 00:04:25.982
So then parallelism?

00:04:25.982 --> 00:04:27.350
AUDIENCE: 3.

00:04:27.350 --> 00:04:28.870
PROFESSOR: Cool.

00:04:28.870 --> 00:04:30.760
All right.

00:04:30.760 --> 00:04:37.470
So now that we're done with
that, how about a little bit

00:04:37.470 --> 00:04:39.300
of background on caches.

00:04:39.300 --> 00:04:46.500
So when you run programs in
parallel, it causes some more

00:04:46.500 --> 00:04:49.450
interesting things to happen in
cache that did not happen

00:04:49.450 --> 00:04:50.980
with serial execution.

00:04:50.980 --> 00:04:55.280
One of those things
is true sharing--

00:04:55.280 --> 00:04:58.330
cache misses-- which are
caused when multiple

00:04:58.330 --> 00:05:01.920
processors, like multiple
threads, are trying to operate

00:05:01.920 --> 00:05:04.250
on the same piece of
data in memory.

00:05:04.250 --> 00:05:09.220
So as a result, your cache would
be forced to synchronize

00:05:09.220 --> 00:05:11.300
that cache line and
move it across--

00:05:11.300 --> 00:05:13.730
copy it from the freshest
processor to the other ones

00:05:13.730 --> 00:05:15.610
every time that it's
requested.

00:05:15.610 --> 00:05:19.570
And you end up with a lot
of overhead generated by

00:05:19.570 --> 00:05:21.580
continually doing
these copies.

00:05:21.580 --> 00:05:24.660
So ideally you don't
want to do this.

00:05:24.660 --> 00:05:28.380
But it's a lot easier
said than done.

00:05:28.380 --> 00:05:31.850
False sharing is a little bit
trickier because it's not

00:05:31.850 --> 00:05:34.930
immediately apparent from
looking at your program that

00:05:34.930 --> 00:05:36.600
you're having multiple
threads do the--

00:05:36.600 --> 00:05:38.100
operate on the same data.

00:05:38.100 --> 00:05:40.940
Instead with false sharing, you
have multiple processors

00:05:40.940 --> 00:05:45.080
that want to operate on
different locations in memory.

00:05:45.080 --> 00:05:48.240
But due to the way that your
computer's cache is organized,

00:05:48.240 --> 00:05:50.180
they just happen to be in
the same cache line.

00:05:50.180 --> 00:05:55.080
As a result, you end up with
the same memory, the same

00:05:55.080 --> 00:05:57.970
overhead, that you would
see with true sharing.

00:05:57.970 --> 00:06:00.930
But when you look at the code
itself, you don't think that

00:06:00.930 --> 00:06:04.430
you're doing anything that
involves multiple threads

00:06:04.430 --> 00:06:07.620
operating on the same data.

00:06:07.620 --> 00:06:12.840
And so with that, here's
a piece of code.

00:06:12.840 --> 00:06:17.910
And my question is this true
sharing or false sharing?

00:06:17.910 --> 00:06:18.540
Let's take a vote.

00:06:18.540 --> 00:06:21.790
How many people think
it's true sharing?

00:06:21.790 --> 00:06:22.770
Nobody.

00:06:22.770 --> 00:06:26.930
Well, how many people think
it's false sharing?

00:06:26.930 --> 00:06:27.410
Come on.

00:06:27.410 --> 00:06:28.790
You have to vote one
way or another.

00:06:31.850 --> 00:06:32.940
Let's try this again.

00:06:32.940 --> 00:06:35.650
True sharing?

00:06:35.650 --> 00:06:37.160
False sharing?

00:06:37.160 --> 00:06:38.060
That's better.

00:06:38.060 --> 00:06:40.440
All right, so it is indeed
false sharing.

00:06:40.440 --> 00:06:43.350
And can someone propose
a solution to fix it?

00:06:49.110 --> 00:06:49.530
Yes?

00:06:49.530 --> 00:06:51.878
AUDIENCE: Separate A
and B, and put them

00:06:51.878 --> 00:06:55.260
in different shelves.

00:06:55.260 --> 00:06:56.350
PROFESSOR: Would that
be sufficient?

00:06:56.350 --> 00:06:57.710
Putting them in different
trucks?

00:07:00.530 --> 00:07:02.890
AUDIENCE: Then, padding
the trucks.

00:07:02.890 --> 00:07:03.430
PROFESSOR: Yeah.

00:07:03.430 --> 00:07:04.630
Maybe with a little
bit of padding,

00:07:04.630 --> 00:07:05.820
depending on your system.

00:07:05.820 --> 00:07:07.890
But sure, I'll accept that.

00:07:10.900 --> 00:07:14.140
But on the quiz, you might be
asked to propose solutions to

00:07:14.140 --> 00:07:16.710
problems that you find.

00:07:16.710 --> 00:07:18.580
And hopefully those
will be easier.

00:07:18.580 --> 00:07:20.830
Now on to a more fun topic--

00:07:20.830 --> 00:07:21.710
synchronization.

00:07:21.710 --> 00:07:22.130
Yes?

00:07:22.130 --> 00:07:24.540
AUDIENCE: I have a question
on sharing.

00:07:24.540 --> 00:07:28.396
So if two programs only access
data, does that still count ?

00:07:33.230 --> 00:07:35.540
PROFESSOR: If you only access
the data and nothing in the

00:07:35.540 --> 00:07:38.100
cache line is being modified,
then you're safe, because

00:07:38.100 --> 00:07:40.690
every processor can
independently read from their

00:07:40.690 --> 00:07:41.820
own copy of that.

00:07:41.820 --> 00:07:42.640
AUDIENCE: So that
doesn't count.

00:07:42.640 --> 00:07:44.490
PROFESSOR: That doesn't
count, correct.

00:07:44.490 --> 00:07:48.430
But the problem is if your cache
line is 64 kilobytes,

00:07:48.430 --> 00:07:51.970
and any thread on any processor
changes one piece of

00:07:51.970 --> 00:07:54.000
data inside that cache,
then everybody

00:07:54.000 --> 00:07:55.250
has to pull new copies.

00:07:58.560 --> 00:08:02.760
So the classic example to
demonstrate synchronization

00:08:02.760 --> 00:08:08.680
correctness is the dining
philosophers problem, where

00:08:08.680 --> 00:08:10.880
you have n--

00:08:10.880 --> 00:08:12.450
I believe five in this case--

00:08:12.450 --> 00:08:16.050
philosophers, and
five chopsticks.

00:08:16.050 --> 00:08:18.560
And each philosopher
has to eat.

00:08:18.560 --> 00:08:22.210
So they use mutexes to--

00:08:22.210 --> 00:08:25.040
well, generally you need--

00:08:25.040 --> 00:08:29.070
each philosopher's code would be
pick up two chopsticks and

00:08:29.070 --> 00:08:32.320
then eat and then put down
their two chopsticks.

00:08:32.320 --> 00:08:36.039
It's somewhat of a contrived
example, but it actually comes

00:08:36.039 --> 00:08:37.549
up in a lot of cases.

00:08:37.549 --> 00:08:41.630
And one of the cases where it
comes up is in the system that

00:08:41.630 --> 00:08:45.480
I use to grade your
unit tests.

00:08:45.480 --> 00:08:50.130
So I got impatient about
running 200 or so

00:08:50.130 --> 00:08:51.420
unit test in series.

00:08:51.420 --> 00:08:55.450
And since I had about 200 cores
altogether on the cloud

00:08:55.450 --> 00:08:58.010
machines, I figured, why not
do them in parallel?

00:08:58.010 --> 00:09:00.860
But the problem is I need to
run-- if I have students A and

00:09:00.860 --> 00:09:04.690
B, I need to run student A's
test against student B's

00:09:04.690 --> 00:09:05.890
implementation.

00:09:05.890 --> 00:09:11.060
So the rough way that I did that
was I grabbed a lock on

00:09:11.060 --> 00:09:14.000
student A's repository, grabbed
a lock on student B's

00:09:14.000 --> 00:09:15.870
repository, and then
modified--

00:09:15.870 --> 00:09:19.370
swapped in their test files, did
all my testing, and then

00:09:19.370 --> 00:09:22.060
returned the files to the
original conditions, and then

00:09:22.060 --> 00:09:24.390
let go of the locks.

00:09:24.390 --> 00:09:26.720
Unfortunately, when you do that,
you run into much of the

00:09:26.720 --> 00:09:29.980
same problem as the dining
philosophers problems.

00:09:29.980 --> 00:09:36.310
So the naive strategy is for
each philosopher, you grab a

00:09:36.310 --> 00:09:38.770
lock on your left chopstick.

00:09:38.770 --> 00:09:42.370
You grab a lock on your right
one, with respect to you.

00:09:42.370 --> 00:09:47.590
And then you eat and then you
unlock them in the same order.

00:09:47.590 --> 00:09:50.210
So this has a bug.

00:09:50.210 --> 00:09:51.850
Can anyone point
out what it is?

00:09:54.694 --> 00:09:56.116
AUDIENCE: You want to unlock
in a certain order.

00:09:58.970 --> 00:10:00.730
PROFESSOR: Actually, it doesn't
matter which order you

00:10:00.730 --> 00:10:01.980
unlock in in in this case.

00:10:05.700 --> 00:10:09.230
So bad things happen if
everybody starts at

00:10:09.230 --> 00:10:10.700
the exact same time.

00:10:10.700 --> 00:10:13.330
So everybody grabs their left
chopstick. there's five

00:10:13.330 --> 00:10:15.320
people, five chopsticks,
so that works fine.

00:10:15.320 --> 00:10:17.450
Now everybody wants to
grab their right one,

00:10:17.450 --> 00:10:18.790
but it's not there.

00:10:18.790 --> 00:10:21.190
Because the person to the right
already grabbed it as

00:10:21.190 --> 00:10:22.070
their left.

00:10:22.070 --> 00:10:26.620
So they wait forever for the
right chopstick to appear and

00:10:26.620 --> 00:10:28.220
it never does.

00:10:28.220 --> 00:10:30.760
So the situation is
called a deadlock.

00:10:30.760 --> 00:10:33.970
And it's obvious to spot,
because all of your threads

00:10:33.970 --> 00:10:36.250
are going to be stuck doing
absolutely nothing.

00:10:36.250 --> 00:10:37.920
Your CPU is not doing
anything.

00:10:37.920 --> 00:10:41.020
And you're just sitting there.

00:10:41.020 --> 00:10:45.770
So a very common work-around
that people like for this is

00:10:45.770 --> 00:10:48.360
to use what's called
a try lock pattern.

00:10:48.360 --> 00:10:53.570
So what you do is you grab a
lock on one of them, like,

00:10:53.570 --> 00:10:54.840
say, your left one.

00:10:54.840 --> 00:10:57.490
And then for the right one,
instead of directly going and

00:10:57.490 --> 00:10:59.590
trying to grab the
lock, you ask--

00:10:59.590 --> 00:11:01.010
you basically do--

00:11:01.010 --> 00:11:03.520
if the thing is unlocked,
grab it.

00:11:03.520 --> 00:11:04.500
Otherwise, don't grab it.

00:11:04.500 --> 00:11:06.780
So it's a non-blocking
approach to

00:11:06.780 --> 00:11:07.870
trying to get a lock.

00:11:07.870 --> 00:11:09.815
So it either succeeds and
you have the lock, or

00:11:09.815 --> 00:11:11.480
it instantly fails.

00:11:11.480 --> 00:11:14.460
And if it fails, then you switch
the order of which--

00:11:14.460 --> 00:11:17.340
you put down the chopstick that
you grabbed, and then you

00:11:17.340 --> 00:11:18.280
try the next one.

00:11:18.280 --> 00:11:21.410
Maybe you wait a little
bit before then.

00:11:21.410 --> 00:11:26.510
This is more or less than what
I did for your beta test, for

00:11:26.510 --> 00:11:28.520
your unit test tester.

00:11:28.520 --> 00:11:30.020
When it fails to--

00:11:30.020 --> 00:11:32.790
if first grabs one student's
directory's locks.

00:11:32.790 --> 00:11:34.850
And then it tries to grab
the second one.

00:11:34.850 --> 00:11:37.970
If that fails, then it puts down
both locks, and then it

00:11:37.970 --> 00:11:40.420
waits a little bit, and
then it tries again.

00:11:40.420 --> 00:11:42.955
So what's the problem
with this approach?

00:11:50.290 --> 00:11:50.605
Yes?

00:11:50.605 --> 00:11:51.855
AUDIENCE: It can
still hold up.

00:11:54.380 --> 00:11:54.780
PROFESSOR: What's that?

00:11:54.780 --> 00:11:58.447
AUDIENCE: It can keep waiting
and grabbing, and sometimes it

00:11:58.447 --> 00:11:59.181
will contend.

00:11:59.181 --> 00:12:01.790
PROFESSOR: Yeah, pretty much,
the same problem happens.

00:12:01.790 --> 00:12:04.990
Only now you have the case where
everybody grabs their

00:12:04.990 --> 00:12:06.900
left, and now the right
one's gone.

00:12:06.900 --> 00:12:08.310
So they put down
their left one.

00:12:08.310 --> 00:12:10.420
And then they all go to
grab the right one.

00:12:10.420 --> 00:12:11.940
Now they have the right
one, and now they

00:12:11.940 --> 00:12:12.650
want the left one.

00:12:12.650 --> 00:12:14.100
But the left one not there.

00:12:14.100 --> 00:12:16.730
So in theory, they can end
up doing this for a

00:12:16.730 --> 00:12:17.980
very, very long time.

00:12:20.900 --> 00:12:23.410
But in practice what happens
is because of scheduling

00:12:23.410 --> 00:12:26.270
overhead, and the phase of the
moon and whatever else affects

00:12:26.270 --> 00:12:30.170
computing, you'll end up after
a while, this become distinct

00:12:30.170 --> 00:12:32.160
from this pattern and eventually
all the locks go

00:12:32.160 --> 00:12:33.740
through, and you're OK.

00:12:33.740 --> 00:12:36.940
But in the meantime, you spent a
lot of time spinning, trying

00:12:36.940 --> 00:12:38.190
to grab locks.

00:12:38.190 --> 00:12:41.610
And so this situation is
called a livelock.

00:12:41.610 --> 00:12:43.420
And it's a lot more
annoying than a

00:12:43.420 --> 00:12:45.160
deadlock because it happens--

00:12:45.160 --> 00:12:47.350
it tends to be less
reproducible.

00:12:47.350 --> 00:12:50.170
And it's harder to diagnose,
because if you're looking at

00:12:50.170 --> 00:12:52.480
top or your favorite CPU
monitor, you see that the

00:12:52.480 --> 00:12:54.400
program seems to be
making progress.

00:12:54.400 --> 00:12:57.200
Maybe some of them actually get
the lock and go through.

00:12:57.200 --> 00:12:58.480
But the rest of them don't.

00:12:58.480 --> 00:13:00.790
So it's hard to argue
whether or not

00:13:00.790 --> 00:13:02.830
there's correctness issue.

00:13:02.830 --> 00:13:07.030
Now there's various classes
of solutions to the dining

00:13:07.030 --> 00:13:09.700
philosophers problem, but you
guys can go look that up.

00:13:09.700 --> 00:13:13.430
I'm not going to go over them.

00:13:13.430 --> 00:13:19.770
So another issue with
synchronization is suppose you

00:13:19.770 --> 00:13:21.390
have two threads.

00:13:21.390 --> 00:13:25.110
Let's say this is a Mars Rover,
and it's on Mars.

00:13:25.110 --> 00:13:28.670
And the two things that the
programmer wanted to do are

00:13:28.670 --> 00:13:32.980
send back its debugging log, so
that the nerdier people at

00:13:32.980 --> 00:13:35.560
NASA, I suppose, can read
them over, or whatever

00:13:35.560 --> 00:13:37.040
they do with logs.

00:13:37.040 --> 00:13:40.060
And the high priority, what
everybody actually wants, is

00:13:40.060 --> 00:13:43.090
for the Rover to send
back pictures.

00:13:43.090 --> 00:13:45.420
Now both of these things require
access to the radio

00:13:45.420 --> 00:13:48.850
that's supposed to transfer
something.

00:13:48.850 --> 00:13:50.580
And only one thing can
transmit at time.

00:13:50.580 --> 00:13:52.000
Otherwise, the transmission
is garbled.

00:13:52.000 --> 00:13:55.870
So a reasonable approach might
be to just lock the radio in

00:13:55.870 --> 00:13:59.240
each thread before you transmit,
and then unlock

00:13:59.240 --> 00:14:01.330
after you transmit.

00:14:01.330 --> 00:14:04.100
So what could be a potential
issue with this?

00:14:10.004 --> 00:14:11.254
AUDIENCE: One might
get all the time.

00:14:13.460 --> 00:14:19.070
PROFESSOR: Let's say, the
scheduler interrupts every 10

00:14:19.070 --> 00:14:23.450
milliseconds, and then 1 out of
the 10 times, it allows 10

00:14:23.450 --> 00:14:24.420
logs to run.

00:14:24.420 --> 00:14:26.520
And then 9 out of the 10 times,
it will allow some

00:14:26.520 --> 00:14:27.290
pictures to run.

00:14:27.290 --> 00:14:32.280
So everybody gets
time scheduled.

00:14:32.280 --> 00:14:36.180
So I guess the easiest way to
illustrate this is what

00:14:36.180 --> 00:14:42.260
happens if it's currently
running said logs, and it

00:14:42.260 --> 00:14:43.580
grabs this lock.

00:14:43.580 --> 00:14:45.670
And then while it's
transmitting, let's say on the

00:14:45.670 --> 00:14:48.360
second megabyte, the scheduler
says your time is up.

00:14:48.360 --> 00:14:52.480
And then it swaps in this
program, and it tries to run.

00:14:52.480 --> 00:14:55.970
So now when this program runs,
it tries to lock the radio,

00:14:55.970 --> 00:14:57.770
but the radio's already
locked.

00:14:57.770 --> 00:14:59.610
And the one that locked
the radio is

00:14:59.610 --> 00:15:01.140
the send locks thread.

00:15:01.140 --> 00:15:04.100
And so it could sit there and
spin for a while waiting for

00:15:04.100 --> 00:15:06.810
the lock to be available.

00:15:06.810 --> 00:15:08.460
But that's not going
to happen.

00:15:08.460 --> 00:15:11.400
Because the guy that's holding
the lock is a bug.

00:15:11.400 --> 00:15:17.160
So in general, this is called
starvation, where in the

00:15:17.160 --> 00:15:21.050
process of having a shared
resource, you end up unfairly

00:15:21.050 --> 00:15:23.690
depriving someone else of
a resource when you're

00:15:23.690 --> 00:15:27.010
not truly using it.

00:15:27.010 --> 00:15:28.860
Well, I guess that's not the--

00:15:28.860 --> 00:15:32.030
I guess you are using it, but
you're using it for longer

00:15:32.030 --> 00:15:33.390
than is fair for you.

00:15:33.390 --> 00:15:36.380
Like in the scheduler you wanted
90% to one process and

00:15:36.380 --> 00:15:39.360
10% to the other, but in reality
you end up with a

00:15:39.360 --> 00:15:41.100
completely different
set of priorities.

00:15:41.100 --> 00:15:44.980
And this inversion of priorities
is commonly called

00:15:44.980 --> 00:15:48.200
priority inversion.

00:15:48.200 --> 00:15:49.450
Does that make sense?

00:15:51.510 --> 00:15:52.280
Cool.

00:15:52.280 --> 00:15:56.950
So on a completely
different topic.

00:15:56.950 --> 00:15:59.660
So Cilk hyperobjects
were covered

00:15:59.660 --> 00:16:00.860
extensively in lecture.

00:16:00.860 --> 00:16:03.790
You guys had a problem set on
it, although it was not

00:16:03.790 --> 00:16:07.100
received very warmly from
what I see in the

00:16:07.100 --> 00:16:08.970
problems sets write ups.

00:16:08.970 --> 00:16:14.020
But I think all of the basic
material for what a Cilk

00:16:14.020 --> 00:16:17.740
hyperobjects is and what it
does can be found in the

00:16:17.740 --> 00:16:19.970
lecture material.

00:16:19.970 --> 00:16:23.630
But more interesting, let's
explore what you can do with

00:16:23.630 --> 00:16:28.440
hyperobjects that aren't
in the documentation.

00:16:28.440 --> 00:16:32.540
So I'm going to define
a piece of code here.

00:16:32.540 --> 00:16:37.840
And it's C++ or Cilk++ code.

00:16:37.840 --> 00:16:40.320
And the first part of it
defines a very simple

00:16:40.320 --> 00:16:42.560
structure called a point.

00:16:42.560 --> 00:16:44.960
And it has three members.

00:16:44.960 --> 00:16:47.930
Or actually it has two members,
x and y, and it has

00:16:47.930 --> 00:16:51.660
three methods for setting the
values of x and y and also

00:16:51.660 --> 00:16:54.610
getting the values of x and y.

00:16:54.610 --> 00:16:55.910
Question?

00:16:55.910 --> 00:16:56.330
No?

00:16:56.330 --> 00:16:57.680
OK.

00:16:57.680 --> 00:17:02.370
And then there's also a
hyperpoint class which

00:17:02.370 --> 00:17:04.650
contains some extra Cilk junk.

00:17:04.650 --> 00:17:07.750
And it also implements the
same three methods.

00:17:07.750 --> 00:17:11.020
Set, get x, and get y.

00:17:11.020 --> 00:17:17.589
And if you look at the monoid
that it contains the point

00:17:17.589 --> 00:17:22.930
monoid it implements a
reduce function that

00:17:22.930 --> 00:17:26.530
just doesn't do anything.

00:17:26.530 --> 00:17:33.080
And for the public methods, the
setters and getters, they

00:17:33.080 --> 00:17:37.150
grab the point represented by
the local view to the reducer

00:17:37.150 --> 00:17:38.460
that it contains.

00:17:38.460 --> 00:17:44.730
And it calls the method that
you called on that point.

00:17:44.730 --> 00:17:49.310
So the question is what
does this thing do,

00:17:49.310 --> 00:17:50.560
the hyperpoint object?

00:17:55.840 --> 00:17:57.730
Anybody have any wild guesses
at this point?

00:18:01.730 --> 00:18:02.650
That's a no.

00:18:02.650 --> 00:18:03.990
So OK.

00:18:03.990 --> 00:18:06.150
Let's try using this code.

00:18:06.150 --> 00:18:08.370
So to put the example
into perspective.

00:18:08.370 --> 00:18:13.710
Suppose I have this artificially
contrived

00:18:13.710 --> 00:18:19.980
function that takes an array of
100 points, and it tries to

00:18:19.980 --> 00:18:24.120
do an in place reversal
of its elements.

00:18:24.120 --> 00:18:27.900
So one way that it can
do that is you have a

00:18:27.900 --> 00:18:30.450
global temporary point.

00:18:30.450 --> 00:18:35.770
And you, at every step of the
iteration, first you step

00:18:35.770 --> 00:18:37.010
through half of the list.

00:18:37.010 --> 00:18:42.310
And then at every step of the
iteration, you copy the ith

00:18:42.310 --> 00:18:45.710
element into the temporary
variable.

00:18:45.710 --> 00:18:54.040
And then you set the ith from
the other end to the--

00:18:54.040 --> 00:18:55.290
you swap the two.

00:18:55.290 --> 00:18:58.190
And then you--

00:18:58.190 --> 00:19:02.020
yeah, so if it is a
three-variable swap, I guess

00:19:02.020 --> 00:19:03.970
is the simplest way
of explaining it.

00:19:03.970 --> 00:19:07.790
It's a swap using a using
a temporary variable.

00:19:07.790 --> 00:19:11.080
Anyone not get what that code
does, despite my attempts to

00:19:11.080 --> 00:19:12.330
confuse you?

00:19:16.600 --> 00:19:23.520
So as far as this space
complexity of this procedure,

00:19:23.520 --> 00:19:28.110
really what it needs at minimum
is enough memory to

00:19:28.110 --> 00:19:32.580
store the temporary point, and
then one register to use to

00:19:32.580 --> 00:19:33.780
put in the temporary values.

00:19:33.780 --> 00:19:37.900
You can think of a solution that
uses only one register to

00:19:37.900 --> 00:19:41.800
update values within your
point structure.

00:19:41.800 --> 00:19:48.380
And so let's suppose I want
to do this in parallel.

00:19:48.380 --> 00:19:52.800
And so what I do is I call it
parallel reverse, and I

00:19:52.800 --> 00:19:56.100
replace for with Cilk for.

00:19:56.100 --> 00:20:00.610
So am I done?

00:20:00.610 --> 00:20:02.246
What's wrong with my code?

00:20:02.246 --> 00:20:03.950
AUDIENCE: Race.

00:20:03.950 --> 00:20:05.850
PROFESSOR: Yes.

00:20:05.850 --> 00:20:08.420
Well first it takes that much--
it takes the same

00:20:08.420 --> 00:20:09.550
amount of space.

00:20:09.550 --> 00:20:13.470
But there is a data race on
temp, because multiple threads

00:20:13.470 --> 00:20:15.690
could be updating temp.

00:20:15.690 --> 00:20:22.100
So now what I do is I replace
my point with a hyperpoint.

00:20:25.940 --> 00:20:28.720
So now what does the
hyperpoint do?

00:20:28.720 --> 00:20:38.020
So within each iteration of the
Cilk for loop, so if that

00:20:38.020 --> 00:20:40.840
iteration has been-- if the
work of that iteration has

00:20:40.840 --> 00:20:43.310
been stolen or spawned off.

00:20:43.310 --> 00:20:48.160
Then the hyperobject, because
it has a reducer within it,

00:20:48.160 --> 00:20:50.230
it'll get a new local
view which is a new

00:20:50.230 --> 00:20:52.510
point object to use.

00:20:52.510 --> 00:20:56.010
And if it's not still in that
it continues running in the

00:20:56.010 --> 00:20:59.120
same thread, then it actually
just continues using the local

00:20:59.120 --> 00:21:02.370
view that was previously
instantiated.

00:21:02.370 --> 00:21:07.050
So no matter what Cilk does
in the background, you're

00:21:07.050 --> 00:21:11.160
guaranteed to not have any data
races on temp, because

00:21:11.160 --> 00:21:14.430
whenever you spawn off a new
thread, the hyperobject will

00:21:14.430 --> 00:21:19.140
instantiate a new temp object
for you to use.

00:21:19.140 --> 00:21:22.140
And this is an example of what's
called thread local

00:21:22.140 --> 00:21:25.700
storage, so like a temporary
storage space for each thread.

00:21:28.450 --> 00:21:29.700
Any questions?

00:21:32.900 --> 00:21:34.150
Cool.

00:21:38.040 --> 00:21:44.020
So on the quiz, you might be
asked about various abusing of

00:21:44.020 --> 00:21:47.040
various other novel hyperobjects
that don't do the

00:21:47.040 --> 00:21:49.310
typical thing, which
is take a left and

00:21:49.310 --> 00:21:50.740
right and reduce them.

00:21:50.740 --> 00:21:52.900
They might do something
a little bit quirky.

00:21:52.900 --> 00:21:57.600
And you might be asked to
explain what they do.

00:21:57.600 --> 00:21:57.870
AUDIENCE: Maybe?

00:21:57.870 --> 00:21:58.842
PROFESSOR: Yes?

00:21:58.842 --> 00:21:59.786
Maybe.

00:21:59.786 --> 00:22:00.980
Maybe.

00:22:00.980 --> 00:22:04.924
AUDIENCE: But this is purely for
illustrating that you can

00:22:04.924 --> 00:22:07.882
do such a thing with
hyperobjects.

00:22:07.882 --> 00:22:12.320
Because you can always create
a temporary variable there.

00:22:12.320 --> 00:22:16.070
PROFESSOR: But suppose point
was a much larger object.

00:22:16.070 --> 00:22:19.750
Sure, this is a contrived
example.

00:22:19.750 --> 00:22:21.000
But yes.

00:22:24.630 --> 00:22:26.740
Anyone?

00:22:26.740 --> 00:22:28.838
Everyone gets this?

00:22:28.838 --> 00:22:33.329
So, in that case, why would that
problem be more efficient

00:22:33.329 --> 00:22:35.824
than creating a new copy of
it, say another point?

00:22:38.330 --> 00:22:40.630
PROFESSOR: Because if you think
about the case where

00:22:40.630 --> 00:22:44.430
this code runs on a single
processor with no work

00:22:44.430 --> 00:22:48.780
stealing, this version does the
exact same thing as the

00:22:48.780 --> 00:22:50.940
single threaded version.

00:22:50.940 --> 00:22:53.180
No extra objects are
being created.

00:22:53.180 --> 00:22:57.070
And if you're running on however
many processors and

00:22:57.070 --> 00:23:00.060
Cilk decides what to do in the
background as far as how many

00:23:00.060 --> 00:23:03.600
threads to allocate for you, and
your code doesn't have to

00:23:03.600 --> 00:23:06.568
know anything about that.

00:23:06.568 --> 00:23:09.907
AUDIENCE: What's the
monoid again?

00:23:09.907 --> 00:23:15.850
PROFESSOR: The monoid is the
associative operator that has

00:23:15.850 --> 00:23:20.570
an identity and a reduce
operation and some other

00:23:20.570 --> 00:23:21.820
things that I forgot.

00:23:33.310 --> 00:23:35.840
Any more questions?

00:23:35.840 --> 00:23:37.300
Cool.

00:23:37.300 --> 00:23:40.590
So switching gears, and this
time I actually have a

00:23:40.590 --> 00:23:48.150
placeholder slide for it, next
part is more about like the

00:23:48.150 --> 00:23:50.750
types of things that you might
have learned from doing or

00:23:50.750 --> 00:23:51.810
experience you might
have gained

00:23:51.810 --> 00:23:53.910
from doing your projects.

00:23:53.910 --> 00:23:58.790
And it primarily pertains to lab
oriented, like in practice

00:23:58.790 --> 00:24:02.460
hands on things, as opposed
to theoretical concepts.

00:24:02.460 --> 00:24:08.590
So just as a fun warm up,
everybody has hopefully at

00:24:08.590 --> 00:24:12.130
this point used some
STL data structure.

00:24:12.130 --> 00:24:14.650
Vectors should definitely
look familiar.

00:24:14.650 --> 00:24:18.720
So let's compare some operations
on these three.

00:24:18.720 --> 00:24:23.700
Because, as far as the API
is concerned, both list--

00:24:23.700 --> 00:24:26.900
all three of them support
almost the same set of

00:24:26.900 --> 00:24:32.780
functions, as far as Insert,
at pushback, pop front.

00:24:32.780 --> 00:24:35.890
All those operations are
supported by these things.

00:24:35.890 --> 00:24:36.980
So it's kind of--

00:24:36.980 --> 00:24:40.100
You might ask why would you
use one over the other?

00:24:40.100 --> 00:24:42.340
Well, it turns out that they
have slightly different

00:24:42.340 --> 00:24:45.510
performance characteristics
that are useful in noting.

00:24:45.510 --> 00:24:50.130
So anyone want to compare and
contrast like what data

00:24:50.130 --> 00:24:52.575
structure a list corresponds
to compared to a vector?

00:24:58.540 --> 00:25:02.760
So which one would be
like a linked list?

00:25:02.760 --> 00:25:04.640
List, yep.

00:25:04.640 --> 00:25:11.270
And then vector obviously is a
dynamically growing array.

00:25:11.270 --> 00:25:12.640
And a deque--

00:25:12.640 --> 00:25:15.540
how many people have
used the deque?

00:25:15.540 --> 00:25:15.860
Cool.

00:25:15.860 --> 00:25:16.130
One.

00:25:16.130 --> 00:25:18.290
How many people know what
deque does even if they

00:25:18.290 --> 00:25:21.090
haven't used it?

00:25:21.090 --> 00:25:21.740
Three?

00:25:21.740 --> 00:25:22.610
Four?

00:25:22.610 --> 00:25:23.240
OK.

00:25:23.240 --> 00:25:26.980
So a deque is actually
implemented similar to a

00:25:26.980 --> 00:25:30.760
vector, but it's dynamically
growing on both ends.

00:25:39.170 --> 00:25:41.710
OK, so let's start with
filling in the

00:25:41.710 --> 00:25:43.310
table for the list.

00:25:43.310 --> 00:25:47.650
So inserting and removing
at the end of a list.

00:25:47.650 --> 00:25:48.330
Constant time?

00:25:48.330 --> 00:25:50.930
Linear time?

00:25:50.930 --> 00:25:54.160
How many people say
constant time?

00:25:54.160 --> 00:25:56.360
Linear?

00:25:56.360 --> 00:25:57.930
Half and half, wow.

00:25:57.930 --> 00:26:00.120
Don't rely on your neighbor
during the test.

00:26:03.480 --> 00:26:05.180
So it's actually
constant time.

00:26:05.180 --> 00:26:09.460
If you think about appending to
the end of a linked list,

00:26:09.460 --> 00:26:14.070
it's just a matter of couple
pointer operations.

00:26:14.070 --> 00:26:17.280
How about inserting and
removing at the front?

00:26:17.280 --> 00:26:19.450
Constant?

00:26:19.450 --> 00:26:19.980
Cool.

00:26:19.980 --> 00:26:21.590
Linear?

00:26:21.590 --> 00:26:21.860
OK.

00:26:21.860 --> 00:26:23.340
I'll stop picking
on people now.

00:26:26.760 --> 00:26:30.930
So next is inserting and
removing an arbitrary offset.

00:26:30.930 --> 00:26:34.810
So what I mean by that is you
have an iterator to a

00:26:34.810 --> 00:26:37.520
particular point inside
the list.

00:26:37.520 --> 00:26:44.010
Now I say insert this element
five or n elements away from

00:26:44.010 --> 00:26:45.480
that iterator.

00:26:45.480 --> 00:26:47.070
How long does that
operation take?

00:26:50.660 --> 00:26:53.320
How many people say
constant time?

00:26:53.320 --> 00:26:53.980
Three people.

00:26:53.980 --> 00:26:57.220
How many people say some
sort of linear time?

00:26:57.220 --> 00:26:58.760
I agree with you guys.

00:26:58.760 --> 00:27:00.650
It is indeed a linear
time thing,

00:27:00.650 --> 00:27:01.990
because you have to traverse--

00:27:01.990 --> 00:27:04.640
you have to actually fall the
next pointers to the location

00:27:04.640 --> 00:27:06.410
or the previous pointers
to the location

00:27:06.410 --> 00:27:08.210
that you want to insert.

00:27:08.210 --> 00:27:13.630
So although list might appear
to support randomish axis,

00:27:13.630 --> 00:27:17.610
like you can add numbers to
the iterator, it doesn't

00:27:17.610 --> 00:27:20.490
actually support that operation
efficiently in the

00:27:20.490 --> 00:27:21.730
background.

00:27:21.730 --> 00:27:24.720
Now the next one is also
kind of tricky.

00:27:24.720 --> 00:27:25.620
Checking the size.

00:27:25.620 --> 00:27:28.690
Like checking how many elements
are calling the dot

00:27:28.690 --> 00:27:33.010
size method of a
standard list.

00:27:33.010 --> 00:27:36.224
How many people think
that's constant?

00:27:36.224 --> 00:27:36.670
Cool.

00:27:36.670 --> 00:27:38.110
About four or five.

00:27:38.110 --> 00:27:40.840
How many people think
that's linear?

00:27:40.840 --> 00:27:42.670
One.

00:27:42.670 --> 00:27:45.710
How many people think it's
possible to have a linked list

00:27:45.710 --> 00:27:49.200
data structure that's forced
constant time?

00:27:49.200 --> 00:27:50.180
There we go.

00:27:50.180 --> 00:27:55.506
Well, unfortunately, the STL
only requires you to have a

00:27:55.506 --> 00:27:59.730
big O of n time for this.

00:27:59.730 --> 00:28:04.440
In fact, I peeked inside the
code for glibc the lib

00:28:04.440 --> 00:28:07.300
standard C++ that is used
on the cloud machines.

00:28:07.300 --> 00:28:09.430
And in fact, what they do is
they actually walk through

00:28:09.430 --> 00:28:11.250
everything from start to
end, and they count up

00:28:11.250 --> 00:28:12.490
the number of times.

00:28:12.490 --> 00:28:15.270
So in fact, it is a linear time
operation, although I'm

00:28:15.270 --> 00:28:17.760
sure somewhere out in the
world, there exists a C

00:28:17.760 --> 00:28:22.030
library, C++ library that does
linear time, or constant time,

00:28:22.030 --> 00:28:23.130
size look ups.

00:28:23.130 --> 00:28:26.420
So you might want to be careful
about that one.

00:28:26.420 --> 00:28:29.380
On a different note, there's
actually a dot empty method

00:28:29.380 --> 00:28:32.680
for checking whether or not a
list is empty, and for any

00:28:32.680 --> 00:28:35.510
type of STL collection
that is guaranteed

00:28:35.510 --> 00:28:36.620
to be constant time.

00:28:36.620 --> 00:28:38.820
So if you just want to know
whether something's empty,

00:28:38.820 --> 00:28:42.700
don't use dot size equals 0.

00:28:42.700 --> 00:28:46.120
What about reversing a
linked list in place?

00:28:46.120 --> 00:28:48.460
Linear?

00:28:48.460 --> 00:28:50.210
More than linear?

00:28:50.210 --> 00:28:52.760
It's not a technical term, and
Charles is probably going to

00:28:52.760 --> 00:28:55.660
hurt me now.

00:28:55.660 --> 00:28:58.110
Linear?

00:28:58.110 --> 00:28:58.640
Yes.

00:28:58.640 --> 00:29:00.990
Linear.

00:29:00.990 --> 00:29:05.120
What about in place sorting
of a linked list?

00:29:05.120 --> 00:29:06.370
How many people think
it's N log(N)?

00:29:10.140 --> 00:29:12.900
One or two daring souls.

00:29:12.900 --> 00:29:13.940
Three daring souls.

00:29:13.940 --> 00:29:15.630
A well informed daring soul.

00:29:15.630 --> 00:29:17.470
How many people think it's
more than N log(N)?

00:29:22.030 --> 00:29:22.800
One.

00:29:22.800 --> 00:29:23.370
OK.

00:29:23.370 --> 00:29:25.780
So actually it is N log(N).

00:29:25.780 --> 00:29:28.980
And that's actually not
specified by the specs.

00:29:28.980 --> 00:29:30.680
But it happens to be.

00:29:30.680 --> 00:29:33.060
And it turns out that there is
a variant merge sort that

00:29:33.060 --> 00:29:36.220
works on link list
that is N log(N).

00:29:36.220 --> 00:29:38.950
I didn't know that,
but anyway.

00:29:38.950 --> 00:29:42.850
So how about let's fill this
in for the vector.

00:29:42.850 --> 00:29:45.560
Inserting and removing an
element at the end--

00:29:45.560 --> 00:29:47.660
constant time?

00:29:47.660 --> 00:29:50.250
Linear time?

00:29:50.250 --> 00:29:52.840
Nobody says linear time.

00:29:52.840 --> 00:29:55.950
So it's amortized constant
time, I guess.

00:29:55.950 --> 00:29:59.380
I'll just call it
constant time.

00:29:59.380 --> 00:30:00.990
What about inserting
or removing at

00:30:00.990 --> 00:30:03.500
the front of a vector--

00:30:03.500 --> 00:30:05.590
constant time?

00:30:05.590 --> 00:30:08.500
Linear time?

00:30:08.500 --> 00:30:09.130
Come on, guys.

00:30:09.130 --> 00:30:11.760
I'm getting like three hands for
linear time and zero for

00:30:11.760 --> 00:30:12.850
constant time.

00:30:12.850 --> 00:30:15.780
I guess that's reasonable.

00:30:15.780 --> 00:30:20.480
So it does, in fact,
insert one element.

00:30:20.480 --> 00:30:22.660
It puts the element in and then
it grows the vector in.

00:30:22.660 --> 00:30:24.540
It copies everything in.

00:30:24.540 --> 00:30:28.590
So don't insert at the front,
don't insert or remove at the

00:30:28.590 --> 00:30:29.540
front of a vector.

00:30:29.540 --> 00:30:33.160
It's a very bad idea if
you do that a lot.

00:30:33.160 --> 00:30:35.750
What about inserting or removing
at an arbitrary

00:30:35.750 --> 00:30:37.000
location inside a vector?

00:30:39.450 --> 00:30:43.790
Well, that one's fairly obvious
to be some sort of

00:30:43.790 --> 00:30:46.110
linear time too, because it
has to shift all of the

00:30:46.110 --> 00:30:49.020
elements after it.

00:30:49.020 --> 00:30:50.270
Checking the size
of the vector?

00:30:55.720 --> 00:30:59.030
Some people are getting
pessimistic about the STL.

00:30:59.030 --> 00:31:01.090
That's my personal opinion,
but I won't

00:31:01.090 --> 00:31:02.830
transfer that onto you.

00:31:02.830 --> 00:31:05.630
So it turns out that for a
vector, yes, it is constant

00:31:05.630 --> 00:31:07.070
time to check the size.

00:31:07.070 --> 00:31:09.020
So that's OK.

00:31:09.020 --> 00:31:11.980
In place reversal,
linear time.

00:31:11.980 --> 00:31:15.950
And sorting is N log(N),
which is not

00:31:15.950 --> 00:31:17.910
surprising by any means.

00:31:17.910 --> 00:31:19.990
So a deque?

00:31:19.990 --> 00:31:23.000
Inserting or removing
at the end--

00:31:23.000 --> 00:31:25.410
constant?

00:31:25.410 --> 00:31:27.060
Sure, constant.

00:31:27.060 --> 00:31:31.210
And inserting or removing
at the front?

00:31:31.210 --> 00:31:31.690
Cool.

00:31:31.690 --> 00:31:32.440
Constant.

00:31:32.440 --> 00:31:34.150
So that's the primary
difference between

00:31:34.150 --> 00:31:35.480
a deque and a vector.

00:31:35.480 --> 00:31:40.100
And for everything else, it
behaves exactly like a vector.

00:31:40.100 --> 00:31:42.880
Does that makes sense?

00:31:42.880 --> 00:31:43.380
Yes.

00:31:43.380 --> 00:31:46.990
AUDIENCE: So is list like
a doubly linked list?

00:31:46.990 --> 00:31:49.840
PROFESSOR: A standard list is in
fact a doubly linked list.

00:31:49.840 --> 00:31:52.520
So it supports both forward
and reverse traversal.

00:31:52.520 --> 00:31:56.590
There's a standard S list, which
is a singly linked list,

00:31:56.590 --> 00:31:58.240
and it only supports
forward traversal.

00:32:02.300 --> 00:32:03.550
Any other questions?

00:32:07.740 --> 00:32:11.730
Moving on to a slightly
different topic, can anyone

00:32:11.730 --> 00:32:14.580
point out what is bad
about this code?

00:32:14.580 --> 00:32:16.695
And I mean from a performance
standpoint.

00:32:20.980 --> 00:32:22.230
AUDIENCE: It's O of n.

00:32:32.870 --> 00:32:33.230
PROFESSOR: All right.

00:32:33.230 --> 00:32:35.800
Someone said it,
so it's O of n.

00:32:35.800 --> 00:32:41.900
So the vector that's passed in
here is passed in by value,

00:32:41.900 --> 00:32:45.490
which means whenever you call
this function, it'll actually

00:32:45.490 --> 00:32:47.780
make a brand new copy
of the vector and

00:32:47.780 --> 00:32:48.850
copy all of the elements.

00:32:48.850 --> 00:32:51.060
So it's linear time with respect
to the number of

00:32:51.060 --> 00:32:52.310
elements in the vector.

00:32:55.020 --> 00:32:57.660
PROFESSOR: So how
do you fix that?

00:32:57.660 --> 00:32:58.910
AUDIENCE: You can pass
in a pointer.

00:33:05.200 --> 00:33:08.220
PROFESSOR: So there's
two ways.

00:33:08.220 --> 00:33:11.160
So on the left is the original
code, and on the right are two

00:33:11.160 --> 00:33:15.540
different ways to pass in just
a pointer to the same thing.

00:33:15.540 --> 00:33:19.020
So you can do a reference
pass, which is the first

00:33:19.020 --> 00:33:20.470
version above.

00:33:20.470 --> 00:33:23.870
And then you can use a dot
to access the methods.

00:33:23.870 --> 00:33:26.500
Or you can pass in by pointer
which everyone is already

00:33:26.500 --> 00:33:27.580
familiar with.

00:33:27.580 --> 00:33:30.740
And that's where you
have to use arrows

00:33:30.740 --> 00:33:32.440
to access the elements.

00:33:32.440 --> 00:33:35.730
And then you also have to change
the way that you call

00:33:35.730 --> 00:33:36.580
the function.

00:33:36.580 --> 00:33:41.060
So oftentimes if you just catch
something in code, like

00:33:41.060 --> 00:33:44.520
say the final project where
something is passed by value,

00:33:44.520 --> 00:33:47.790
where it should be passed by
reference, oftentimes the

00:33:47.790 --> 00:33:50.970
easiest way to modify the code
is to just change it to use a

00:33:50.970 --> 00:33:52.220
reference rather
than a pointer.

00:33:54.890 --> 00:34:03.270
So the next thing that I want
to cover is a question type

00:34:03.270 --> 00:34:07.970
that will be on the final,
will be on the quiz.

00:34:07.970 --> 00:34:11.780
And I'll give some examples
of problems of this form.

00:34:11.780 --> 00:34:15.070
But most importantly, I want
everybody to be familiar with

00:34:15.070 --> 00:34:17.659
the form of the question, the
rules involving the question,

00:34:17.659 --> 00:34:21.010
so nobody accidentally loses
points for not reading the

00:34:21.010 --> 00:34:25.270
instructions, which nobody
seems to do on quizzes.

00:34:25.270 --> 00:34:30.070
So you are given two versions
of the same function written

00:34:30.070 --> 00:34:32.920
in C or C++.

00:34:32.920 --> 00:34:38.630
And you are to assume
that your compiler--

00:34:38.630 --> 00:34:42.159
well, the compiler, as far as
like what the CPU is executing

00:34:42.159 --> 00:34:44.409
is a literal interpretation
of the code you

00:34:44.409 --> 00:34:46.880
see before and after.

00:34:46.880 --> 00:34:49.790
By this point, everybody is
probably familiar with some of

00:34:49.790 --> 00:34:53.880
the simple tricks a compiler
does, like if you say int x

00:34:53.880 --> 00:34:57.280
equals 1 plus 1 there is no
circumstance in which the

00:34:57.280 --> 00:34:59.990
compiler actually puts two 1s in
two different registers and

00:34:59.990 --> 00:35:03.600
tells it to add it and
then put it in x.

00:35:03.600 --> 00:35:07.480
So you are assuming that your
compiler is doing a literal

00:35:07.480 --> 00:35:08.750
translation.

00:35:08.750 --> 00:35:11.760
And then you are asked to
determine three properties

00:35:11.760 --> 00:35:14.680
about the optimization,
so going from the

00:35:14.680 --> 00:35:17.090
before to the after.

00:35:17.090 --> 00:35:19.770
So the first thing is
whether or not the

00:35:19.770 --> 00:35:21.900
optimization is legal.

00:35:21.900 --> 00:35:25.760
And when we define legal, we
mean that the optimized

00:35:25.760 --> 00:35:27.930
version always has the same--

00:35:27.930 --> 00:35:31.010
preserves the same behavior
as the other version.

00:35:31.010 --> 00:35:34.470
It should be relatively simple
to infer from the code

00:35:34.470 --> 00:35:37.520
snippets that we give you, what
the intended purpose of a

00:35:37.520 --> 00:35:38.340
function is.

00:35:38.340 --> 00:35:41.330
And you are to determine whether
or not the optimized

00:35:41.330 --> 00:35:44.520
version acts like the
unoptimized version, as far as

00:35:44.520 --> 00:35:47.670
the correctness of the result.

00:35:47.670 --> 00:35:51.060
Second, you are asked to
determine whether or not this

00:35:51.060 --> 00:35:56.350
optimized version is faster
than the previous version.

00:35:56.350 --> 00:35:59.595
And by faster, we mean faster
in most conceivable cases.

00:36:04.960 --> 00:36:07.240
It's a short answer question so
you might want to explain

00:36:07.240 --> 00:36:07.750
what you mean.

00:36:07.750 --> 00:36:11.500
But we do expect a yes
or no answer to

00:36:11.500 --> 00:36:12.950
start off the question.

00:36:12.950 --> 00:36:15.470
And it should be pretty
clear whether the

00:36:15.470 --> 00:36:17.890
answer is yes or no.

00:36:17.890 --> 00:36:22.020
And then finally, I'm sure by
this point everybody knows

00:36:22.020 --> 00:36:26.430
that when you compile with gcc
-02 or -03, the compiler does

00:36:26.430 --> 00:36:27.900
a lot of things for you.

00:36:27.900 --> 00:36:30.860
So there's oftentimes no point
in writing certain

00:36:30.860 --> 00:36:32.960
optimizations by hand, when
you know when you hit the

00:36:32.960 --> 00:36:34.720
compile button, the compiler's
going to do it in the

00:36:34.720 --> 00:36:36.570
background anyway.

00:36:36.570 --> 00:36:40.830
So this question asks whether
or not you can reasonably

00:36:40.830 --> 00:36:43.730
assume that the optimizing
compilers, like the ones that

00:36:43.730 --> 00:36:45.850
you're using for your projects,
would do this

00:36:45.850 --> 00:36:48.510
optimization for you or should
you take the effort to

00:36:48.510 --> 00:36:51.800
actually do this optimization
by hand.

00:36:51.800 --> 00:36:57.770
And then, legalese, if the
optimization is illegal, let's

00:36:57.770 --> 00:37:00.860
not answer whether or not it's
faster or automatic.

00:37:00.860 --> 00:37:05.670
And if the optimization actually
makes things slower,

00:37:05.670 --> 00:37:09.230
then let's not answer whether
the compiler does it for you.

00:37:09.230 --> 00:37:10.850
Some of us have more cynical
views of the

00:37:10.850 --> 00:37:12.240
compiler than others.

00:37:12.240 --> 00:37:16.310
So we'll just disregard that.

00:37:16.310 --> 00:37:17.560
Any question on the rules?

00:37:20.532 --> 00:37:23.906
AUDIENCE: How are we supposed
to know what types of things

00:37:23.906 --> 00:37:25.752
the compiler's going to do,
can we just read the

00:37:25.752 --> 00:37:27.770
documentation?

00:37:27.770 --> 00:37:30.840
PROFESSOR: So there was a
lecture that Samaan gave

00:37:30.840 --> 00:37:34.340
called What Compilers
Can and Cannot Do.

00:37:34.340 --> 00:37:37.360
AUDIENCE: So it's just stuff
from that lecture?

00:37:37.360 --> 00:37:39.630
PROFESSOR: I would say most
of it is that lecture.

00:37:39.630 --> 00:37:42.830
And then other things-- we might
throw in a thing or two

00:37:42.830 --> 00:37:46.080
that you guys hopefully
learn from.

00:37:46.080 --> 00:37:49.760
So throughout the term, we've
been misguiding you on those

00:37:49.760 --> 00:37:52.460
walk through P-sets, suggesting
you to do things

00:37:52.460 --> 00:37:55.620
that actually don't help.

00:37:55.620 --> 00:37:57.220
And you guys have gotten
pretty pissed at

00:37:57.220 --> 00:37:58.185
us about that probably.

00:37:58.185 --> 00:38:01.420
But there was a method
to the madness.

00:38:01.420 --> 00:38:05.840
I mean, there was something to
be learned from that, whether

00:38:05.840 --> 00:38:08.830
or not we actually
meant to do it.

00:38:08.830 --> 00:38:13.680
So hopefully some level of
intuition would answer it, and

00:38:13.680 --> 00:38:15.980
you would get the bulk of the
points for just understanding

00:38:15.980 --> 00:38:20.310
the points raised
in the lecture.

00:38:20.310 --> 00:38:22.850
Any other questions
about the rules?

00:38:22.850 --> 00:38:23.170
All right.

00:38:23.170 --> 00:38:26.630
So I have a couple of examples
of these types of questions.

00:38:26.630 --> 00:38:31.380
So the first one is this.

00:38:31.380 --> 00:38:37.450
So it should be fairly obvious
what the code does.

00:38:37.450 --> 00:38:43.190
It takes your input, and it
wants to mod it by 256.

00:38:43.190 --> 00:38:45.985
So first question is this
a legal optimization?

00:38:49.640 --> 00:38:52.250
How many people say yes?

00:38:52.250 --> 00:38:53.230
A lot of people.

00:38:53.230 --> 00:38:54.480
Anybody say no?

00:38:57.580 --> 00:38:59.240
Reed almost scared me
for a moment there.

00:38:59.240 --> 00:39:00.490
He had his hand up.

00:39:02.990 --> 00:39:06.900
So yes, it is indeed legal.

00:39:06.900 --> 00:39:10.800
And it's a standard bit hack
for doing a modulo

00:39:10.800 --> 00:39:12.240
by a power of two.

00:39:12.240 --> 00:39:13.490
AUDIENCE: What if it's 257?

00:39:18.130 --> 00:39:21.110
PROFESSOR: I was fortunate
enough to make it a uint64.

00:39:21.110 --> 00:39:28.370
So next question is given that
it's legal, is it faster to do

00:39:28.370 --> 00:39:31.010
the and instead of the mod?

00:39:31.010 --> 00:39:33.850
How many people say yes?

00:39:33.850 --> 00:39:37.420
How many people say no?

00:39:37.420 --> 00:39:39.620
So a majority of the
class says yes, and

00:39:39.620 --> 00:39:40.780
some people say no.

00:39:40.780 --> 00:39:43.920
So what would be a reason why
you think it's not faster?

00:39:43.920 --> 00:39:46.156
AUDIENCE: Well, I didn't say
it's not faster faster.

00:39:46.156 --> 00:39:49.572
It's probably the same time,
because I assume the

00:39:49.572 --> 00:39:53.476
instruction for modding is not
actually dividing by it.

00:39:57.880 --> 00:39:59.880
PROFESSOR: So for the other
people who said no, how many

00:39:59.880 --> 00:40:03.100
people agree with that
line of reasoning?

00:40:03.100 --> 00:40:03.420
All right.

00:40:03.420 --> 00:40:04.700
Seems like everybody.

00:40:04.700 --> 00:40:09.020
So unfortunately,
it is faster.

00:40:09.020 --> 00:40:12.480
And it turns out, I compiled
down both of these pieces of

00:40:12.480 --> 00:40:15.670
code under-- well, actually,
the compiler--

00:40:15.670 --> 00:40:17.900
but anyway, I'll get
to that next.

00:40:17.900 --> 00:40:19.550
Not giving away any answers.

00:40:19.550 --> 00:40:23.040
But so I executed the assembly
instructions corresponding to

00:40:23.040 --> 00:40:24.830
both of these operations.

00:40:24.830 --> 00:40:28.400
And it does turn out that the
compiler, the CPU, when you

00:40:28.400 --> 00:40:31.796
ask it to take the mod of an
arbitrary number, usually it's

00:40:31.796 --> 00:40:33.780
an instruction called div mod.

00:40:33.780 --> 00:40:37.900
And what that does is that it
does a divided by b, and it

00:40:37.900 --> 00:40:40.310
puts the dividend in one
register and it puts the

00:40:40.310 --> 00:40:42.580
modulo in another register.

00:40:42.580 --> 00:40:47.480
And we do that for, let's say,
2 to the 63rd modulo 256,

00:40:47.480 --> 00:40:49.480
because it actually goes through
all the clock cycles

00:40:49.480 --> 00:40:51.130
for doing that division
process.

00:40:51.130 --> 00:40:54.660
And then it dumps out the
modulo at the end.

00:40:54.660 --> 00:40:59.420
So yes, this actually does
tend to be a lot faster.

00:40:59.420 --> 00:41:03.680
Now next question is will the
compiler do this for you?

00:41:03.680 --> 00:41:05.485
How many people say yes?

00:41:05.485 --> 00:41:06.610
Most of the class.

00:41:06.610 --> 00:41:08.910
Anybody say no?

00:41:08.910 --> 00:41:09.430
Good.

00:41:09.430 --> 00:41:11.710
We all trust the compiler
to some extent.

00:41:11.710 --> 00:41:15.280
So yeah, it turns out that gcc,
starting from 01, will do

00:41:15.280 --> 00:41:16.530
this for you.

00:41:20.500 --> 00:41:23.290
Any questions?

00:41:23.290 --> 00:41:25.430
All right.

00:41:25.430 --> 00:41:28.410
Next question.

00:41:28.410 --> 00:41:30.310
So you have a list.

00:41:30.310 --> 00:41:32.920
And you pushed in.

00:41:32.920 --> 00:41:34.840
You pushed at the end.

00:41:34.840 --> 00:41:36.750
It's 42, twice.

00:41:36.750 --> 00:41:39.960
And then you returned the result
of popping the front

00:41:39.960 --> 00:41:42.700
element and then popping the
back element, subtracted.

00:41:47.290 --> 00:41:49.760
So first of all, is this
a legal operation?

00:41:54.255 --> 00:41:57.420
Let me give everybody
a chance to think.

00:41:57.420 --> 00:42:02.170
AUDIENCE: Legal optimization
as opposed to an operation.

00:42:02.170 --> 00:42:03.420
PROFESSOR: Yeah.

00:42:05.550 --> 00:42:07.530
How many people vote yes,
this is going legal?

00:42:10.830 --> 00:42:11.690
Roughly half the class.

00:42:11.690 --> 00:42:14.800
How many people say no,
this is not legal?

00:42:14.800 --> 00:42:16.020
Two people.

00:42:16.020 --> 00:42:17.745
OK, so why would it
not be legal?

00:42:22.710 --> 00:42:25.090
You can't do that.

00:42:25.090 --> 00:42:26.158
Yes?

00:42:26.158 --> 00:42:27.408
AUDIENCE: There happens to be
wastefulness on some problems.

00:42:34.460 --> 00:42:36.090
PROFESSOR: Well, that could
certainly happen.

00:42:36.090 --> 00:42:37.890
But for the purpose of
these problems--

00:42:37.890 --> 00:42:40.890
see this is why I'm bringing up
these problems-- so for the

00:42:40.890 --> 00:42:43.270
purpose of these problems,
assume there's no man behind

00:42:43.270 --> 00:42:44.690
the curtain doing things.

00:42:44.690 --> 00:42:46.980
For any given problem, you
could say that's someone

00:42:46.980 --> 00:42:49.090
attaching a debugger to your
program and changing the

00:42:49.090 --> 00:42:50.750
memory between instructions.

00:42:50.750 --> 00:42:54.764
So let's just assume
that's happening.

00:42:54.764 --> 00:42:56.690
AUDIENCE: Also, who's
local, right?

00:42:56.690 --> 00:42:58.090
PROFESSOR: Yeah.

00:42:58.090 --> 00:43:01.050
Yea, Foo is actually local,
so if anybody else's doing

00:43:01.050 --> 00:43:04.490
anything to it, they're
a very bad person.

00:43:04.490 --> 00:43:06.090
So fine.

00:43:06.090 --> 00:43:08.630
It's a legal optimization.

00:43:08.630 --> 00:43:10.840
Now.

00:43:10.840 --> 00:43:12.090
is it faster?

00:43:15.440 --> 00:43:18.700
How many people think that
returning zero is slower than

00:43:18.700 --> 00:43:20.449
pushing two things up?

00:43:20.449 --> 00:43:22.894
AUDIENCE: [LAUGHTER]

00:43:22.894 --> 00:43:26.320
AUDIENCE: Depends upon
how big zero is.

00:43:26.320 --> 00:43:27.570
PROFESSOR: That's true.

00:43:31.670 --> 00:43:35.280
So OK, so yes, obviously,
it's faster to just

00:43:35.280 --> 00:43:36.910
directly return zero.

00:43:36.910 --> 00:43:41.250
And finally, is this an
automatic optimization?

00:43:41.250 --> 00:43:44.340
How many people say yes?

00:43:44.340 --> 00:43:44.680
Cool.

00:43:44.680 --> 00:43:45.600
Nobody said yes.

00:43:45.600 --> 00:43:46.850
How many people say no?

00:43:51.310 --> 00:43:56.320
People who say yes, if you
could work for compiler

00:43:56.320 --> 00:44:00.940
companies, I would appreciate
that a lot.

00:44:00.940 --> 00:44:04.920
So unfortunately, the compiler
does not make--

00:44:04.920 --> 00:44:08.830
cannot reason through how an
STL list works, and realize

00:44:08.830 --> 00:44:11.920
that what you're doing
is an no op.

00:44:11.920 --> 00:44:15.910
It turns out that for a related
set of questions, like

00:44:15.910 --> 00:44:18.790
have any of your mentors said
anything to-- so my mentor

00:44:18.790 --> 00:44:19.810
said this to me last year.

00:44:19.810 --> 00:44:23.020
And I was pretty interested
when I tried it out.

00:44:23.020 --> 00:44:25.795
Have you ever used a for loop to
set everything in an array

00:44:25.795 --> 00:44:27.045
to equals 0?

00:44:30.130 --> 00:44:32.000
Most people seem to
have done that.

00:44:32.000 --> 00:44:35.300
Who has used the memset or heard
of the memset set API

00:44:35.300 --> 00:44:37.550
call before?

00:44:37.550 --> 00:44:39.420
A good portion of the class.

00:44:39.420 --> 00:44:40.290
OK, so some people.

00:44:40.290 --> 00:44:41.770
So a little bit of
background then.

00:44:41.770 --> 00:44:45.700
Mem set instruction takes in an
array or a pointer rather,

00:44:45.700 --> 00:44:48.170
and a constant, and the
size of the array.

00:44:48.170 --> 00:44:52.050
And it sets that many elements
of the array to that constant.

00:44:52.050 --> 00:44:56.450
So it turns out that depending
on the machine that you're

00:44:56.450 --> 00:45:00.070
using, there is more efficient
and less efficient ways of

00:45:00.070 --> 00:45:02.960
setting all the elements
of an array to 0.

00:45:02.960 --> 00:45:05.760
And functions like mem set are
actually are several pages

00:45:05.760 --> 00:45:10.160
long of hand optimized assembly
to be optimal for

00:45:10.160 --> 00:45:12.620
your architecture.

00:45:12.620 --> 00:45:15.770
So it's always tempting to take
a for loop that iterates

00:45:15.770 --> 00:45:18.060
through an array, setting
everything to 0, and changing

00:45:18.060 --> 00:45:20.410
it to a single mem
set instruction.

00:45:20.410 --> 00:45:27.130
And it turns out that for both
gcc and icc, Intel C compiler,

00:45:27.130 --> 00:45:30.680
when you compile at sufficient
optimization level, the

00:45:30.680 --> 00:45:31.940
compiler actually does
this for you.

00:45:31.940 --> 00:45:35.000
It actually looks through
the arrays.

00:45:35.000 --> 00:45:37.050
It actually realizes that you're
setting all the members

00:45:37.050 --> 00:45:39.650
in the array to a constant, and
it does that optimization

00:45:39.650 --> 00:45:43.550
for you by replacing it
with a memset call.

00:45:43.550 --> 00:45:48.300
So just as a general question,
why could it be advantageous

00:45:48.300 --> 00:45:52.340
for you to write the four loop
as is, and have the compiler

00:45:52.340 --> 00:45:54.606
do the optimization for you?

00:45:54.606 --> 00:45:56.040
AUDIENCE: Because you later
might add code in the loop.

00:45:58.650 --> 00:45:59.250
PROFESSOR: True.

00:45:59.250 --> 00:46:00.618
Any other reasons?

00:46:00.618 --> 00:46:02.810
PROFESSOR: I didn't
hear question.

00:46:02.810 --> 00:46:04.510
PROFESSOR: You might want to
add code that changes the

00:46:04.510 --> 00:46:07.350
behavior inside the loop.

00:46:07.350 --> 00:46:09.690
AUDIENCE: It's much more
readable to have a for loop

00:46:09.690 --> 00:46:12.030
and you just read it, and I get
that's what he's doing.

00:46:12.030 --> 00:46:13.600
PROFESSOR: Yes, indeed.

00:46:13.600 --> 00:46:16.270
Looking over some of your code
submissions, it seems to be a

00:46:16.270 --> 00:46:19.000
non-trivial task of figuring out
the size of something when

00:46:19.000 --> 00:46:21.980
you call malloc or memset.

00:46:21.980 --> 00:46:27.050
And actually, it sometimes is
a non-trivial operation to

00:46:27.050 --> 00:46:32.540
figure out how big something
is in bytes, especially for

00:46:32.540 --> 00:46:33.560
structs and things like that.

00:46:33.560 --> 00:46:37.270
So it actually is easier to
let the compiler do the

00:46:37.270 --> 00:46:39.330
optimization for you, and you
don't make any embarrassing

00:46:39.330 --> 00:46:40.580
mistakes in the process.

00:46:44.860 --> 00:46:46.110
So next question.

00:46:48.830 --> 00:46:51.660
So here you have a
helper function.

00:46:51.660 --> 00:46:56.110
And in the after version,
seems to do the

00:46:56.110 --> 00:46:57.360
same thing, does it?

00:47:01.310 --> 00:47:04.015
So who thinks this is a
legal optimization?

00:47:14.350 --> 00:47:15.170
Half the class.

00:47:15.170 --> 00:47:16.420
Anyone think it's illegal?

00:47:19.220 --> 00:47:21.310
So yeah, it is legal.

00:47:21.310 --> 00:47:23.800
The only thing that I've done
is that I've copy pasted

00:47:23.800 --> 00:47:27.350
basically the function body
in the bottom example.

00:47:27.350 --> 00:47:32.790
And it's relatively easy to
prove that or infer that the

00:47:32.790 --> 00:47:35.330
two do the same thing.

00:47:35.330 --> 00:47:37.385
So is it faster?

00:47:40.010 --> 00:47:43.290
How many people say yes?

00:47:43.290 --> 00:47:45.580
How many people say no?

00:47:45.580 --> 00:47:47.450
One person said no.

00:47:47.450 --> 00:47:48.410
Why is it not faster?

00:47:48.410 --> 00:47:52.378
AUDIENCE: I mean, I've said
that it is the same speed,

00:47:52.378 --> 00:47:55.850
because so the only thing that
would make it slower would be

00:47:55.850 --> 00:47:58.826
the-- you need to actually
do like a compass switch.

00:47:58.826 --> 00:48:02.298
Because you need to call that
function every time.

00:48:02.298 --> 00:48:05.274
But I think it could provide
the concept for you-- like

00:48:05.274 --> 00:48:07.258
basically, it's a
static function.

00:48:07.258 --> 00:48:08.508
It would inline it even though
you don't have to declare it.

00:48:14.720 --> 00:48:15.030
PROFESSOR: OK.

00:48:15.030 --> 00:48:21.570
So if you recall the rules for
the question, so basically we

00:48:21.570 --> 00:48:24.290
want you to interpret the
code, as is, like a very

00:48:24.290 --> 00:48:27.100
literal interpretation as in--

00:48:27.100 --> 00:48:31.930
the point was raised that for
this function call, what you

00:48:31.930 --> 00:48:34.680
actually want to do is assume
that the compiler is setting

00:48:34.680 --> 00:48:36.700
up a function called by putting
the arguments in the

00:48:36.700 --> 00:48:38.990
right register and jumping
to the address of

00:48:38.990 --> 00:48:40.440
that function above.

00:48:40.440 --> 00:48:44.370
So for the case of this-- for
the matter-- for the purpose

00:48:44.370 --> 00:48:48.040
of this question, yes, it's
much faster to just do a

00:48:48.040 --> 00:48:51.290
multiply compared to setting up
a call stack and tearing it

00:48:51.290 --> 00:48:52.580
down after the function
is done.

00:48:55.740 --> 00:49:00.330
Now the next question is is this
automatic, which was more

00:49:00.330 --> 00:49:01.730
or less answered.

00:49:01.730 --> 00:49:04.240
And that's yes.

00:49:04.240 --> 00:49:08.210
So at a sufficient optimization
level which is

00:49:08.210 --> 00:49:13.530
-03 or -02 with dash f inline
functions, the compiler will

00:49:13.530 --> 00:49:17.760
actually use a heuristic that it
has for determining whether

00:49:17.760 --> 00:49:20.030
or not a function is a good
candidate for inlining.

00:49:20.030 --> 00:49:23.120
And for good candidates, it'll
do the inlining for you.

00:49:23.120 --> 00:49:25.230
Now the specific
heuristics vary

00:49:25.230 --> 00:49:27.040
from compiler to compiler.

00:49:27.040 --> 00:49:32.510
But for this specific problem
that we gave you, it's a prime

00:49:32.510 --> 00:49:36.260
candidate for inlining, because
it's declared as

00:49:36.260 --> 00:49:40.120
static, which means it's
local to this C file.

00:49:40.120 --> 00:49:44.070
And it does a very simple
task, a one-liner, so it

00:49:44.070 --> 00:49:46.020
almost certainly will
be inline for you.

00:49:49.320 --> 00:49:50.570
Any questions?

00:49:52.800 --> 00:49:54.050
Cool.

00:49:56.470 --> 00:49:58.260
So this one.

00:50:03.510 --> 00:50:04.010
Question?

00:50:04.010 --> 00:50:05.486
AUDIENCE: I don't get it.

00:50:05.486 --> 00:50:06.962
Could you explain again?

00:50:06.962 --> 00:50:09.914
I know I've asked this
before, like what's

00:50:09.914 --> 00:50:11.882
static, the static function?

00:50:11.882 --> 00:50:14.840
And it's different
than in Java?

00:50:14.840 --> 00:50:16.590
PROFESSOR: OK.

00:50:16.590 --> 00:50:22.320
So the question was what's a
static function in C. And so

00:50:22.320 --> 00:50:26.180
in C, a static function means
when you declare a function as

00:50:26.180 --> 00:50:30.440
static, it means that the
function is local to the

00:50:30.440 --> 00:50:32.750
current file that you're work--
the current module, the

00:50:32.750 --> 00:50:36.400
dot-o file, which is almost
always your dot-c file.

00:50:36.400 --> 00:50:41.125
So like the function only exists
within this dot-c file.

00:50:41.125 --> 00:50:43.090
A function in another
dot-c file

00:50:43.090 --> 00:50:45.600
cannot call this function.

00:50:45.600 --> 00:50:47.870
So it basically allows the
compiler to assume that

00:50:47.870 --> 00:50:50.640
there's no external effects on
this function that are not

00:50:50.640 --> 00:50:52.010
within this file.

00:50:52.010 --> 00:50:54.890
Remember the compiler compiles
object files one by one, and

00:50:54.890 --> 00:50:58.284
then the linker is the one that
brings it all together.

00:50:58.284 --> 00:51:00.882
AUDIENCE: So the important thing
is that it knows that it

00:51:00.882 --> 00:51:03.090
can just delete helper after
it's gotten rid of it.

00:51:03.090 --> 00:51:03.620
PROFESSOR: Right, right.

00:51:03.620 --> 00:51:04.790
That's another good point.

00:51:04.790 --> 00:51:07.350
So in this case, after inlining,
the compiler

00:51:07.350 --> 00:51:11.070
actually won't bother to put in
the function helper inside

00:51:11.070 --> 00:51:13.170
the actual object file.

00:51:13.170 --> 00:51:15.150
So you save on my code space.

00:51:15.150 --> 00:51:17.140
Because the compiler knows
that nowhere else this

00:51:17.140 --> 00:51:20.106
function can be called.

00:51:20.106 --> 00:51:24.100
AUDIENCE: What about
static in C++?

00:51:24.100 --> 00:51:31.400
PROFESSOR: Static in C++ when
used inside a class means that

00:51:31.400 --> 00:51:35.290
the function is a static
member function.

00:51:35.290 --> 00:51:38.960
So it's a function that's tied
to the class itself, rather

00:51:38.960 --> 00:51:41.550
than an object, and instance
of the class.

00:51:41.550 --> 00:51:43.270
AUDIENCE: Just like Java.

00:51:43.270 --> 00:51:44.520
PROFESSOR: Just like Java.

00:51:47.490 --> 00:51:50.570
More questions?

00:51:50.570 --> 00:51:51.450
Cool.

00:51:51.450 --> 00:51:52.760
So back to this code.

00:52:04.830 --> 00:52:07.900
First of all, is anyone not
familiar with the syntax or

00:52:07.900 --> 00:52:12.140
wants the syntax explained?

00:52:12.140 --> 00:52:13.120
OK, cool.

00:52:13.120 --> 00:52:17.010
So first question,
is it legal?

00:52:17.010 --> 00:52:18.260
How may people say yes?

00:52:21.100 --> 00:52:21.790
Half the class.

00:52:21.790 --> 00:52:23.040
How many people say no.

00:52:25.450 --> 00:52:27.000
Roughly half the class.

00:52:27.000 --> 00:52:33.020
Well, I and the people grading
the quiz will side with the

00:52:33.020 --> 00:52:38.410
people who say no, because down
here when you're doing--

00:52:38.410 --> 00:52:40.690
this is the correct version
of the XOR swap.

00:52:40.690 --> 00:52:42.860
I'm not trying to trick
anyone there.

00:52:42.860 --> 00:52:45.460
But it turns out--

00:52:45.460 --> 00:52:50.550
well, I'd rather not assume
that t, the arbitrary type

00:52:50.550 --> 00:52:54.530
name, has an operator XOR
defined for it that has all

00:52:54.530 --> 00:52:58.110
the properties that you need
in order for it to do this.

00:53:00.840 --> 00:53:04.710
Like the simplest example is
if I pass in a double, this

00:53:04.710 --> 00:53:07.840
would not work.

00:53:07.840 --> 00:53:10.280
Double does not have an operator
XOR defined for it.

00:53:15.060 --> 00:53:17.671
Some people look upset.

00:53:17.671 --> 00:53:22.860
AUDIENCE: [LAUGHTER]

00:53:22.860 --> 00:53:24.090
PROFESSOR: A list too
would not have an

00:53:24.090 --> 00:53:27.240
XOR defined for it.

00:53:27.240 --> 00:53:29.750
Anyone disagree with me?

00:53:29.750 --> 00:53:31.000
That's not a challenge.

00:53:33.520 --> 00:53:35.770
So yeah, some of these questions
require you to do a

00:53:35.770 --> 00:53:40.090
little bit of reasoning, like
reasonable reasoning, as far

00:53:40.090 --> 00:53:44.290
as what to assume for the
purposes of the question.

00:53:44.290 --> 00:53:46.530
So watch out for that.

00:53:46.530 --> 00:53:49.680
So in this case, it's not legal,
so you don't have to

00:53:49.680 --> 00:53:54.170
answer the next two questions.

00:53:54.170 --> 00:53:55.210
So OK.

00:53:55.210 --> 00:53:57.080
So let's fix this.

00:53:57.080 --> 00:54:00.130
And by fix it, I mean
not use templates.

00:54:00.130 --> 00:54:02.100
So now we're just operating
on ints.

00:54:02.100 --> 00:54:06.250
And ints do have the proper
operator XOR that has all the

00:54:06.250 --> 00:54:08.410
good properties that you want.

00:54:08.410 --> 00:54:08.870
Yes?

00:54:08.870 --> 00:54:10.660
AUDIENCE: What's the and
notation of the variable.

00:54:10.660 --> 00:54:14.030
PROFESSOR: It's a reference.

00:54:14.030 --> 00:54:15.110
So it's a reference to it.

00:54:15.110 --> 00:54:17.830
Because you need references,
because you actually want to

00:54:17.830 --> 00:54:21.110
swap the two items that
are being called in.

00:54:21.110 --> 00:54:21.380
Right?

00:54:21.380 --> 00:54:23.060
AUDIENCE: Can you use
like pointeres?

00:54:23.060 --> 00:54:25.680
PROFESSOR: Yes, so you can also
use a pointer for it.

00:54:25.680 --> 00:54:29.210
Pointers and references, C
will treat this use of

00:54:29.210 --> 00:54:33.830
references the same way as
if you use pointers.

00:54:33.830 --> 00:54:36.480
So references are
syntactic sugar.

00:54:36.480 --> 00:54:39.400
And what it basically allows you
to do is write code that

00:54:39.400 --> 00:54:42.740
looks like you're operating on
standard intervals, standard

00:54:42.740 --> 00:54:46.630
integers, but in fact that it's
a pointer to the value

00:54:46.630 --> 00:54:50.290
that the name of the variable
that's passed in here.

00:54:50.290 --> 00:54:52.715
Otherwise this code would be
riddled with a bunch of stars.

00:54:56.600 --> 00:54:58.890
Now is this legal?

00:54:58.890 --> 00:55:02.380
How many people say yes?

00:55:02.380 --> 00:55:03.560
Most of the class.

00:55:03.560 --> 00:55:06.870
How many people say no?

00:55:06.870 --> 00:55:07.710
One person.

00:55:07.710 --> 00:55:08.105
Yes?

00:55:08.105 --> 00:55:10.228
AUDIENCE: If A and B are
the same variable,

00:55:10.228 --> 00:55:11.530
you set it to zero.

00:55:11.530 --> 00:55:12.780
PROFESSOR: Yes, exactly.

00:55:14.830 --> 00:55:19.310
The XOR law has a nasty side
effect where you want to make

00:55:19.310 --> 00:55:22.030
sure that A and B are not
the same variable.

00:55:22.030 --> 00:55:24.310
Not they don't contain the
same-- they can contain the

00:55:24.310 --> 00:55:26.830
same value in different
variables, but they can't be

00:55:26.830 --> 00:55:28.710
the same variable or the
same register or

00:55:28.710 --> 00:55:30.840
the same memory location.

00:55:30.840 --> 00:55:34.920
Otherwise, when you do A equals
Ax or B, that's 0.

00:55:34.920 --> 00:55:38.000
And now both A and
B point to 0.

00:55:38.000 --> 00:55:41.240
And there's nothing you can do
to get your old value back.

00:55:41.240 --> 00:55:43.490
AUDIENCE: Can you check
for equivalence of

00:55:43.490 --> 00:55:46.400
recordkeeping in C++.

00:55:46.400 --> 00:55:47.590
PROFESSOR: Indeed, you can.

00:55:47.590 --> 00:55:49.750
If you take the address of the
reference, it gives you the

00:55:49.750 --> 00:55:53.160
address of the original value.

00:55:53.160 --> 00:55:58.660
So this would be the proper
way, I guess, of

00:55:58.660 --> 00:56:01.420
doing an XOR swap.

00:56:01.420 --> 00:56:06.090
So now that we've gotten over
all the trick questions, is

00:56:06.090 --> 00:56:08.920
this actually faster?

00:56:08.920 --> 00:56:10.170
How many people say yes?

00:56:12.940 --> 00:56:15.970
One, two, three, four.

00:56:15.970 --> 00:56:17.220
How many people say no?

00:56:20.730 --> 00:56:21.030
Cool.

00:56:21.030 --> 00:56:22.180
Most of the class.

00:56:22.180 --> 00:56:26.460
So this is another example
of a gray area question.

00:56:26.460 --> 00:56:30.750
So in this class, we primarily
talk about the cloud machines,

00:56:30.750 --> 00:56:33.130
as far as the performance
analysis that we've done.

00:56:33.130 --> 00:56:35.700
So on the cloud machines, and
this was mentioned in

00:56:35.700 --> 00:56:38.590
Charles's bit hacks lecture
which was, well, the second

00:56:38.590 --> 00:56:40.190
lecture in the course.

00:56:40.190 --> 00:56:43.650
This trick is not faster
on the cloud machines.

00:56:43.650 --> 00:56:46.100
Because what you end up doing
is you create a lot of

00:56:46.100 --> 00:56:49.860
dependencies between these
operands, so that the pipeline

00:56:49.860 --> 00:56:53.120
must execute these one
by one serially.

00:56:53.120 --> 00:56:55.980
So you introduce a lot
of delays by that.

00:56:55.980 --> 00:56:58.790
And plus now that we actually
want you to write a correct

00:56:58.790 --> 00:57:01.270
program, you have to
do this check, and

00:57:01.270 --> 00:57:02.820
that's an extra branch.

00:57:02.820 --> 00:57:06.210
And finally these XORs have to
be done by the ALU, and up to

00:57:06.210 --> 00:57:07.600
five execution ports.

00:57:07.600 --> 00:57:09.040
Only three of them are ALUs.

00:57:09.040 --> 00:57:11.750
The other two can do memory
operations just fine.

00:57:11.750 --> 00:57:15.270
So it turns out that for a
combination of these reasons,

00:57:15.270 --> 00:57:17.960
this version indeed with the
temporary register actually

00:57:17.960 --> 00:57:19.210
does run faster.

00:57:22.360 --> 00:57:23.610
Any questions?

00:57:26.537 --> 00:57:27.028
Yes.

00:57:27.028 --> 00:57:30.219
AUDIENCE: For branches, we
assume advanced features, like

00:57:30.219 --> 00:57:34.580
it will preload the exceptions
and only invalidates the thing

00:57:34.580 --> 00:57:37.210
when certain branches fail.

00:57:37.210 --> 00:57:39.650
PROFESSOR: Sure, you can assume
cool properties about

00:57:39.650 --> 00:57:42.270
the chip, such as speculative
execution,

00:57:42.270 --> 00:57:45.600
prefetching, and so on.

00:57:45.600 --> 00:57:48.800
But the problem is those tricks
are fine when you're

00:57:48.800 --> 00:57:51.720
doing things sparsely as in
you're sometimes doing work

00:57:51.720 --> 00:57:53.280
and other times not
doing work.

00:57:53.280 --> 00:57:57.450
But like speculative execution,
like when you

00:57:57.450 --> 00:58:01.790
execute both sides of a branch,
you're using more or

00:58:01.790 --> 00:58:04.010
less double your execution
or resources.

00:58:04.010 --> 00:58:07.040
And if you have all processors
running some intense piece of

00:58:07.040 --> 00:58:09.970
code that's doing swapping,
you don't have any extra

00:58:09.970 --> 00:58:12.790
resources to dedicate towards
running code that

00:58:12.790 --> 00:58:14.040
might not be useful.

00:58:17.430 --> 00:58:18.680
Any other questions?

00:58:21.290 --> 00:58:22.400
Cool.

00:58:22.400 --> 00:58:29.030
So finally, I got tired
of making slides.

00:58:29.030 --> 00:58:31.180
Well, actually that's
not true.

00:58:31.180 --> 00:58:33.640
It's more I'd rather concentrate
the slides on

00:58:33.640 --> 00:58:37.230
things that I think are more
useful than other things, as

00:58:37.230 --> 00:58:39.440
far as per preparation
for your quiz.

00:58:39.440 --> 00:58:41.230
All your time is valuable.

00:58:41.230 --> 00:58:44.190
And so there's other topics
that are fair game for the

00:58:44.190 --> 00:58:46.680
quiz, because they've been
mentioned in lectures up to

00:58:46.680 --> 00:58:47.540
this point.

00:58:47.540 --> 00:58:50.170
But I haven't prepared
any slides on them.

00:58:50.170 --> 00:58:54.870
And the fractal trees were
covered by the guest lecture

00:58:54.870 --> 00:58:55.870
by Bradley.

00:58:55.870 --> 00:58:57.670
And the slides are up.

00:58:57.670 --> 00:59:00.280
I suggest familiarizing yourself
with the basic

00:59:00.280 --> 00:59:02.450
workings of how the data
structure that

00:59:02.450 --> 00:59:05.630
he described works.

00:59:05.630 --> 00:59:09.580
And lock free data structures
were covered on your take home

00:59:09.580 --> 00:59:11.930
P set, and also in a lecture.

00:59:11.930 --> 00:59:13.940
So be prepared to
answer potential

00:59:13.940 --> 00:59:16.170
questions about that.

00:59:16.170 --> 00:59:19.590
And then finally the mechanism
behind the Cilk runtime, the

00:59:19.590 --> 00:59:23.330
work stealing scheduler, how
it's implemented on the Linux

00:59:23.330 --> 00:59:27.580
side, and also the basics of
what a Cilk hyperobject is,

00:59:27.580 --> 00:59:29.850
what a Cilk hyperobject
has to have.

00:59:29.850 --> 00:59:33.970
Advantages and disadvantages
of using them and so on.

00:59:33.970 --> 00:59:34.650
Yes.

00:59:34.650 --> 00:59:38.460
AUDIENCE: Are the grades
for the P-set out?

00:59:38.460 --> 00:59:40.750
PROFESSOR: No, they
are not out yet.

00:59:40.750 --> 00:59:45.260
AUDIENCE: Are there solutions
for the P-set?

00:59:45.260 --> 00:59:45.940
PROFESSOR: Not yet.

00:59:45.940 --> 00:59:47.290
But I believe we have something

00:59:47.290 --> 00:59:49.340
prepared for that, right?

00:59:49.340 --> 00:59:50.590
Somewhat?

00:59:53.100 --> 00:59:54.750
Yeah, it's somewhat prepared.

00:59:54.750 --> 00:59:58.000
If you have any questions about
like questions on the

00:59:58.000 --> 01:00:02.560
pset that you want answer to,
feel free to stop by office

01:00:02.560 --> 01:00:07.190
hours or email us and
we can help you.

01:00:07.190 --> 01:00:08.940
Yeah, apologies for not
getting that P set

01:00:08.940 --> 01:00:12.110
back to you in time.

01:00:12.110 --> 01:00:13.870
Any other questions relating
to the quiz.

01:00:16.480 --> 01:00:18.410
It's really all the material
I have as far as reviewing.

01:00:23.010 --> 01:00:23.500
Yes?

01:00:23.500 --> 01:00:24.730
AUDIENCE: Are you going to
put these slides up?

01:00:24.730 --> 01:00:26.080
AUDIENCE: Yeah, I'll
put these slides up

01:00:26.080 --> 01:00:28.950
right after the lecture.

01:00:28.950 --> 01:00:32.290
So as far as a general notes,
I guess you guys turned in

01:00:32.290 --> 01:00:37.855
your finals yesterday, and you
guys have a design report that

01:00:37.855 --> 01:00:39.190
you also turned in.

01:00:39.190 --> 01:00:43.920
Your POSSE members should have
contacted you by now, as far

01:00:43.920 --> 01:00:47.550
as scheduling a design
review session.

01:00:47.550 --> 01:00:53.960
Since this project is actually
due on next Thursday, it might

01:00:53.960 --> 01:00:57.150
be a good idea to get this done
by the end of the week.

01:00:57.150 --> 01:00:58.780
Otherwise, the design
review won't be

01:00:58.780 --> 01:01:01.710
a very useful process.

01:01:01.710 --> 01:01:04.530
AUDIENCE: There are a couple of
students without a mentor

01:01:04.530 --> 01:01:05.020
right now here.

01:01:05.020 --> 01:01:06.630
We are fixing that.

01:01:06.630 --> 01:01:06.950
PROFESSOR: Right.

01:01:06.950 --> 01:01:09.570
There's a couple of students
caught in limbo right now.

01:01:09.570 --> 01:01:11.960
Sorry about that.

01:01:11.960 --> 01:01:18.360
PROFESSOR: If you were--
previously dropped on Stellar,

01:01:18.360 --> 01:01:20.972
send us an email.

01:01:28.370 --> 01:01:31.471
If you haven't been to drop
through this course, there are

01:01:31.471 --> 01:01:33.420
no longer drops allowed.

01:01:33.420 --> 01:01:33.710
Yeah,

01:01:33.710 --> 01:01:36.520
AUDIENCE: So it's your
responsibility.

01:01:36.520 --> 01:01:37.850
I'm going to put
on my mean hat.

01:01:37.850 --> 01:01:41.350
It's your responsibility to
schedule a meeting with your

01:01:41.350 --> 01:01:44.670
POSSE member, and make sure
that it happens by

01:01:44.670 --> 01:01:45.480
the end of the week.

01:01:45.480 --> 01:01:47.525
And if it doesn't look like
it's going to happen, or

01:01:47.525 --> 01:01:49.310
you're having difficulties
getting in touch with your

01:01:49.310 --> 01:01:53.080
mentor, or you don't have one
yet, please drop us an email

01:01:53.080 --> 01:01:56.820
or come by office hours and
make sure that we know.

01:01:56.820 --> 01:01:57.390
All right.

01:01:57.390 --> 01:01:58.640
That's it.

