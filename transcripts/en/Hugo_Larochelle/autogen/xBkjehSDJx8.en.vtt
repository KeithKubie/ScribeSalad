WEBVTT
Kind: captions
Language: en

00:00:00.290 --> 00:00:09.030
 this capsule we will introduce the task 

00:00:02.520 --> 00:00:11.000
 of syntactical labeling then to more than 

00:00:09.030 --> 00:00:13.170
 the identity of words in a document 

00:00:11.000 --> 00:00:14.309
 in some treatment systems 

00:00:13.170 --> 00:00:15.900
 automatic language it's going to be as 

00:00:14.309 --> 00:00:18.810
 useful to know the label 

00:00:15.900 --> 00:00:22.289
 syntactical of each of the words by 

00:00:18.810 --> 00:00:24.199
 example if I have the sentence or the tip of 

00:00:22.289 --> 00:00:26.189
 sentence a visit to the farm 

00:00:24.199 --> 00:00:28.080
 I might be interested to know 

00:00:26.189 --> 00:00:28.800
 what is his label 

00:00:28.080 --> 00:00:30.420
 syntactic 

00:00:28.800 --> 00:00:32.870
 in this case are indicated syntax 

00:00:30.420 --> 00:00:35.790
 x and so have firm matches a name 

00:00:32.870 --> 00:00:36.270
 since in the sentence jean closes the 

00:00:35.790 --> 00:00:39.950
 door 

00:00:36.270 --> 00:00:43.739
 shut up from above if I play the role of a 

00:00:39.950 --> 00:00:45.750
 a syntactic tag of verbs and 

00:00:43.739 --> 00:00:48.690
 know this category 

00:00:45.750 --> 00:00:50.129
 grammatical there will allow to 

00:00:48.690 --> 00:00:53.039
 facilitate other tasks not by 

00:00:50.129 --> 00:00:55.829
 example in machine translation if I 

00:00:53.039 --> 00:00:57.210
 know that firm is a name had 

00:00:55.829 --> 00:00:59.640
 perhaps most likely in 

00:00:57.210 --> 00:01:02.660
 this case also that its production is 

00:00:59.640 --> 00:01:04.290
 form while if I know that firm 

00:01:02.660 --> 00:01:06.270
 corresponds to berne 

00:01:04.290 --> 00:01:10.049
 when if it fits maybe more 

00:01:06.270 --> 00:01:11.369
 opened my English running associate of 

00:01:10.049 --> 00:01:14.340
 information sometimes we want 

00:01:11.369 --> 00:01:16.710
 extracting documents from corpus that one 

00:01:14.340 --> 00:01:19.650
 has to solve a hostage like the 

00:01:16.710 --> 00:01:22.500
 automatic translation or for a 

00:01:19.650 --> 00:01:28.229
 answer questions related to 

00:01:22.500 --> 00:01:31.049
 documents instituted so let's see what 

00:01:28.229 --> 00:01:33.479
 approach we can follow to succeed 

00:01:31.049 --> 00:01:36.840
 this task of syntactic labeling with 

00:01:33.479 --> 00:01:39.990
 success so again will take 

00:01:36.840 --> 00:01:42.240
 an approach where in fact we will define a 

00:01:39.990 --> 00:01:44.009
 Bézian network allows for pleasures that 

00:01:42.240 --> 00:01:47.399
 will define a distribution on words 

00:01:44.009 --> 00:01:49.560
 and labels we will learn this 

00:01:47.399 --> 00:01:53.310
 beziers network there on a labeled corpus 

00:01:49.560 --> 00:01:54.689
 we are going to have collected and finally this 

00:01:53.310 --> 00:01:57.000
 Beziers loeb network to make 

00:01:54.689 --> 00:01:59.250
 predictions on new documents 

00:01:57.000 --> 00:02:00.869
 so in what if to label from 

00:01:59.250 --> 00:02:02.729
 new words in new documents 

00:02:00.869 --> 00:02:04.950
 but that's just fine 

00:02:02.729 --> 00:02:06.719
 to make inference in a pc network 

00:02:04.950 --> 00:02:08.940
 with the document association was doing 

00:02:06.719 --> 00:02:11.030
 the inference of the class the category the 

00:02:08.940 --> 00:02:12.520
 more likely given my 

00:02:11.030 --> 00:02:14.870
 and when if we will rather do 

00:02:12.520 --> 00:02:16.490
 the inference of the labels the most 

00:02:14.870 --> 00:02:19.130
 likely given the words in 

00:02:16.490 --> 00:02:21.350
 the document when knows we ready 

00:02:19.130 --> 00:02:22.910
 among other things as we return we are 

00:02:21.350 --> 00:02:24.410
 define a bezier network but I 

00:02:22.910 --> 00:02:26.450
 were starting to make things done 

00:02:24.410 --> 00:02:28.730
 a little more tangible define 

00:02:26.450 --> 00:02:30.709
 what to see the corpora labeled 

00:02:28.730 --> 00:02:33.290
 will use to make the labeling of 

00:02:30.709 --> 00:02:38.330
 taxis so we'll assume we have access 

00:02:33.290 --> 00:02:39.650
 to grant and corpus enacted summer and for 

00:02:38.330 --> 00:02:41.030
 simplify I guess and that all my 

00:02:39.650 --> 00:02:45.920
 documents to the facts correspond to 

00:02:41.030 --> 00:02:47.840
 individual phrases so to summer fact 

00:02:45.920 --> 00:02:49.730
 in this case too since they are 

00:02:47.840 --> 00:02:52.130
 corpus is dictated will not be 

00:02:49.730 --> 00:02:54.890
 only a sequence of a word w1 

00:02:52.130 --> 00:02:58.519
 up to wd but a sequence of 

00:02:54.890 --> 00:03:00.440
 father of a word w1 for example and his 

00:02:58.519 --> 00:03:03.680
 label that I want to note in this 

00:03:00.440 --> 00:03:07.160
 kind had such a wlt label or 

00:03:03.680 --> 00:03:09.019
 w16 the first word of the summer document and 

00:03:07.160 --> 00:03:11.870
 I'm trying so but labels for 

00:03:09.019 --> 00:03:14.060
 every single word in my document I 

00:03:11.870 --> 00:03:15.980
 also used the notation dt words 

00:03:14.060 --> 00:03:18.290
 to refer to the sequence only of 

00:03:15.980 --> 00:03:20.510
 words in the document and labels 

00:03:18.290 --> 00:03:23.329
 summer for the sequence only 

00:03:20.510 --> 00:03:26.989
 labels 1 up to india and in the 

00:03:23.329 --> 00:03:29.840
 document dt so often it'll take 

00:03:26.989 --> 00:03:31.670
 the shape of a text file or people 

00:03:29.840 --> 00:03:33.620
 even two columns separated by 

00:03:31.670 --> 00:03:35.180
 tabulations the first column okay 

00:03:33.620 --> 00:03:39.130
 to be the words the second column of 

00:03:35.180 --> 00:03:41.230
 labels like green bartier 

00:03:39.130 --> 00:03:43.510
 no huh if you'll be an example in 

00:03:41.230 --> 00:03:45.610
 what if only one document so a 

00:03:43.510 --> 00:03:48.880
 single sentence where each of the words and 

00:03:45.610 --> 00:03:50.800
 dictated by a syntactic category 

00:03:48.880 --> 00:03:52.570
 grammatical interests we are interested in 

00:03:50.800 --> 00:03:54.190
 often the punctuations actually goes their 

00:03:52.570 --> 00:03:56.320
 associate a label that exactly the 

00:03:54.190 --> 00:03:58.330
 same as conquest since jean 

00:03:56.320 --> 00:04:02.410
 for example what would be a firm no 

00:03:58.330 --> 00:04:03.910
 it's a verb is instituted ok so that's 

00:04:02.410 --> 00:04:04.960
 it's giving us labeled now 

00:04:03.910 --> 00:04:06.940
 let's see how are we 

00:04:04.960 --> 00:04:12.400
 define a bezier network on this type of 

00:04:06.940 --> 00:04:15.610
 data then a movie what are we going 

00:04:12.400 --> 00:04:17.380
 use his hmm so a model of 

00:04:15.610 --> 00:04:18.580
 markov hide as we saw in the 

00:04:17.380 --> 00:04:21.040
 capsules on Bezier networks 

00:04:18.580 --> 00:04:22.870
 dynamic so what we will ask in 

00:04:21.040 --> 00:04:24.910
 done is that the way that sentences 

00:04:22.870 --> 00:04:26.980
 were generated it's that firstly 

00:04:24.910 --> 00:04:30.810
 the person before writing it will do 

00:04:26.980 --> 00:04:33.970
 think about what would be the first 

00:04:30.810 --> 00:04:35.980
 the class where the grammatical category 

00:04:33.970 --> 00:04:37.360
 so the syntactic tag of the first 

00:04:35.980 --> 00:04:39.610
 word of the sentence as for example in 

00:04:37.360 --> 00:04:45.490
 the world example we choose that the 

00:04:39.610 --> 00:04:48.280
 first word made a name and then from 

00:04:45.490 --> 00:04:50.940
 that the person chooses his chasuble likes 

00:04:48.280 --> 00:04:57.010
 put a name as the first phase ii 

00:04:50.940 --> 00:04:59.080
 write like no fly then from 

00:04:57.010 --> 00:05:00.460
 spells assume that from only 

00:04:59.080 --> 00:05:02.110
 the syntactic tag the person 

00:05:00.460 --> 00:05:04.660
 chosen who after a number to do 

00:05:02.110 --> 00:05:07.720
 a well formed sentence among others I 

00:05:04.660 --> 00:05:09.640
 can choose to make a verb and to 

00:05:07.720 --> 00:05:11.470
 from this information there we go 

00:05:09.640 --> 00:05:13.720
 poses that knowing that we wanted to make a 

00:05:11.470 --> 00:05:17.950
 verb the person decided to put 

00:05:13.720 --> 00:05:19.810
 as a firm verb and we continue as 

00:05:17.950 --> 00:05:21.940
 that or from the syntactic tag 

00:05:19.810 --> 00:05:23.890
 previous it is assumed that the person 

00:05:21.940 --> 00:05:27.310
 chose the syntactic tag of the word 

00:05:23.890 --> 00:05:28.690
 next to know article knowing that the 

00:05:27.310 --> 00:05:29.800
 people stuck in arctic valve has 

00:05:28.690 --> 00:05:32.590
 decided to take 

00:05:29.800 --> 00:05:36.070
 among all articles the article there 

00:05:32.590 --> 00:05:37.300
 in this example if we continue like this 

00:05:36.070 --> 00:05:40.740
 until the end 

00:05:37.300 --> 00:05:40.740
 I know what happens to a point 

00:05:42.020 --> 00:05:45.710
 so that's the generative story that 

00:05:43.910 --> 00:05:47.870
 would be associated with a markov model 

00:05:45.710 --> 00:05:49.639
 hide them and the stamp will 

00:05:47.870 --> 00:05:52.190
 match the syntactic tags 

00:05:49.639 --> 00:05:55.610
 then what is observed will match 

00:05:52.190 --> 00:05:57.800
 to words so marked that this 

00:05:55.610 --> 00:05:59.270
 subtlety that is a little different from 

00:05:57.800 --> 00:06:02.479
 especially the example in fact we have 

00:05:59.270 --> 00:06:03.889
 processed in the capsules on the 

00:06:02.479 --> 00:06:05.690
 kosher markov models is that 

00:06:03.889 --> 00:06:07.729
 the set of possible values ​​for 

00:06:05.690 --> 00:06:09.500
 the hidden states is not the same as 

00:06:07.729 --> 00:06:11.900
 all the values ​​that by their 

00:06:09.500 --> 00:06:14.539
 possible for random variables 

00:06:11.900 --> 00:06:18.680
 so observe in the example we had 

00:06:14.539 --> 00:06:21.199
 does this relay markov module hide 

00:06:18.680 --> 00:06:24.710
 we had a message correspond to 

00:06:21.199 --> 00:06:26.990
 vip where we had beats in 0.1 in 

00:06:24.710 --> 00:06:29.509
 the hiding vise and in slaughterhouses 

00:06:26.990 --> 00:06:31.789
 observed because in what if 

00:06:29.509 --> 00:06:32.960
 really h with the syntax and so 

00:06:31.789 --> 00:06:35.509
 only all classes and 

00:06:32.960 --> 00:06:36.949
 possible toxicities while the facts 

00:06:35.509 --> 00:06:40.310
 observed it really helps words or 

00:06:36.949 --> 00:06:41.719
 punctuations alas from our 

00:06:40.310 --> 00:06:44.569
 training corpus what are we going 

00:06:41.719 --> 00:06:47.240
 wanting to do that is actually defining our 

00:06:44.569 --> 00:06:50.270
 productive transition from the hidden state 

00:06:47.240 --> 00:06:54.949
 towards observation or gives and hid to 

00:06:50.270 --> 00:06:56.539
 the esta y there just hidden value nesta and 

00:06:54.949 --> 00:06:58.789
 healthier and we will also see 

00:06:56.539 --> 00:07:02.779
 define the prior probability of 

00:06:58.789 --> 00:07:05.630
 first being hidden h1 so the first 

00:07:02.779 --> 00:07:07.430
 syntactic tag from 

00:07:05.630 --> 00:07:10.190
 only actually party dr smart 

00:07:07.430 --> 00:07:11.900
 coaches will be able to take 

00:07:10.190 --> 00:07:14.389
 calculate statistics to define 

00:07:11.900 --> 00:07:17.180
 our country h1 our country a score 

00:07:14.389 --> 00:07:17.630
 knowing buyers and our 2h pi like 

00:07:17.180 --> 00:07:21.919
 healthier 

00:07:17.630 --> 00:07:24.050
 hk so that's actually 

00:07:21.919 --> 00:07:26.150
 technically in in our 

00:07:24.050 --> 00:07:28.639
 application but our country of hk sacha 

00:07:26.150 --> 00:07:33.680
 is what knowing hk that will allow us 

00:07:28.639 --> 00:07:35.360
 to model for example that farm is 

00:07:33.680 --> 00:07:37.300
 a word that could be generated if I 

00:07:35.360 --> 00:07:42.550
 wanted to have 

00:07:37.300 --> 00:07:43.840
 instruct a name in my phase then it 

00:07:42.550 --> 00:07:46.300
 could be generated also if 

00:07:43.840 --> 00:07:48.909
 I wanted to generate a verb is by 

00:07:46.300 --> 00:07:51.159
 against that had dubbed m an article 

00:07:48.909 --> 00:07:52.870
 the protein the film would be very low so 

00:07:51.159 --> 00:07:56.250
 it means that the probability that hk 

00:07:52.870 --> 00:08:00.789
 be equal during politics 

00:07:56.250 --> 00:08:03.340
 sk is equal says since they 

00:08:00.789 --> 00:08:04.930
 hp tunes you arte from the 

00:08:03.340 --> 00:08:06.460
 statistics there are some good things that 

00:08:04.930 --> 00:08:08.740
 in fact this time the deadline is treated 

00:08:06.460 --> 00:08:15.310
 because it would be higher here at hk 

00:08:08.740 --> 00:08:16.840
 was rather a verb or a no so to 

00:08:15.310 --> 00:08:18.099
 from the statistics we hope in 

00:08:16.840 --> 00:08:19.270
 done is able to learn the 

00:08:18.099 --> 00:08:21.909
 policies continue like that they 

00:08:19.270 --> 00:08:24.430
 will reflect a little this edition there and 

00:08:21.909 --> 00:08:28.180
 then in the same way we go from 

00:08:24.430 --> 00:08:29.830
 statistics we will be able to determine the 

00:08:28.180 --> 00:08:32.409
 relationship between syntactic tags 

00:08:29.830 --> 00:08:35.050
 hadja seems so a barter we hope that 

00:08:32.409 --> 00:08:37.779
 noteworthy of port-nice conditional 

00:08:35.050 --> 00:08:39.190
 will learn the fact that we are expected 

00:08:37.779 --> 00:08:44.260
 not that two following articles 

00:08:39.190 --> 00:08:46.000
 after having them there in a sentence 

00:08:44.260 --> 00:08:49.570
 it's something that goes g to 

00:08:46.000 --> 00:08:51.700
 grammatiko grammatically correct so 

00:08:49.570 --> 00:08:53.829
 his real father is actually rather than 

00:08:51.700 --> 00:08:55.750
 doctors manually in notable of 

00:08:53.829 --> 00:08:57.459
 distribution will hope that are 

00:08:55.750 --> 00:08:58.990
 extracted from the statistics from a 

00:08:57.459 --> 00:09:01.450
 training corpus that we are going 

00:08:58.990 --> 00:09:04.029
 actually extra this information there 

00:09:01.450 --> 00:09:07.890
 actually practical have managed to 

00:09:04.029 --> 00:09:07.890
 do this from a labeled corpus 

00:09:09.180 --> 00:09:14.020
 so we learn the chain from 

00:09:12.160 --> 00:09:16.480
 statistics as we learn it dropped 

00:09:14.020 --> 00:09:19.240
 even normal ie the note 

00:09:16.480 --> 00:09:22.480
 probability estimates that h Coptic 

00:09:19.240 --> 00:09:24.399
 he got lost a handicap that I have 

00:09:22.480 --> 00:09:26.260
 noted also for simplicity given 

00:09:24.399 --> 00:09:29.020
 than the previous label so the rates 

00:09:26.260 --> 00:09:32.040
 almost hidden previous equals ap it goes 

00:09:29.020 --> 00:09:35.290
 to be simply the number of times that 

00:09:32.040 --> 00:09:37.149
 followed in the labels of 

00:09:35.290 --> 00:09:40.180
 documents from my old workout 

00:09:37.149 --> 00:09:42.610
 divided by the number of times that b 

00:09:40.180 --> 00:09:44.529
 followed by any other label 

00:09:42.610 --> 00:09:46.930
 in the labels of my pc body 

00:09:44.529 --> 00:09:48.370
 same dictation so 

00:09:46.930 --> 00:09:50.380
 so here we 

00:09:48.370 --> 00:09:51.790
 in the background a relative frequency on 

00:09:50.380 --> 00:09:53.950
 once again studied frequencies 

00:09:51.790 --> 00:09:58.360
 also relative to calculate the practice 

00:09:53.950 --> 00:10:01.990
 conditional that the corium my care w 

00:09:58.360 --> 00:10:04.000
 since the kosher label is 

00:10:01.990 --> 00:10:06.820
 equals the 10.4 syntactical be equal to 

00:10:04.000 --> 00:10:08.470
 ethics nb it's going to be just the 

00:10:06.820 --> 00:10:12.430
 frequency so the number of times that 

00:10:08.470 --> 00:10:16.830
 I saw that the word w was associated with 

00:10:12.430 --> 00:10:19.150
 the label b in my summer documents 

00:10:16.830 --> 00:10:21.550
 standardized by the number of times I have 

00:10:19.150 --> 00:10:24.850
 saw the stats associated with any 

00:10:21.550 --> 00:10:27.250
 what word in my documents pace and 

00:10:24.850 --> 00:10:28.810
 then finally my probity a priori that 

00:10:27.250 --> 00:10:30.580
 the first edition equals one 

00:10:28.810 --> 00:10:32.110
 label at savatan is simply 

00:10:30.580 --> 00:10:34.839
 the number of times that the first 

00:10:32.110 --> 00:10:37.210
 tag in my body chips and ip is 

00:10:34.839 --> 00:10:39.520
 equal to 1 in all documents divided 

00:10:37.210 --> 00:10:42.850
 by the number of documents so the 

00:10:39.520 --> 00:10:44.290
 number of sentences finally in in 

00:10:42.850 --> 00:10:50.350
 my set in my body all 

00:10:44.290 --> 00:10:52.630
 labeled and then finally commented on this 

00:10:50.350 --> 00:10:55.330
 what do I do to label a new 

00:10:52.630 --> 00:10:57.310
 sentence w1 until wt not do what 

00:10:55.330 --> 00:11:02.350
 I need to know it's given 

00:10:57.310 --> 00:11:03.459
 the value of rs 1 until s5 that I 

00:11:02.350 --> 00:11:05.470
 know now that I can 

00:11:03.459 --> 00:11:09.490
 conditioned on the fact that 

00:11:05.470 --> 00:11:11.680
 unfair because dct gala w1 until wb who 

00:11:09.490 --> 00:11:14.290
 my sentence observe what I have to do 

00:11:11.680 --> 00:11:19.810
 what is the sequence w1 

00:11:14.290 --> 00:11:23.200
 pardon h1 h2 h3 h4 and h5 which is 

00:11:19.810 --> 00:11:25.330
 finally the most likely so 

00:11:23.200 --> 00:11:28.300
 are also that it's the same thing as 

00:11:25.330 --> 00:11:31.089
 to maximize joint priority between 

00:11:28.300 --> 00:11:32.440
 the labels signed a sequence h 

00:11:31.089 --> 00:11:36.550
 stars that my most sequence 

00:11:32.440 --> 00:11:39.880
 plausible is that the words of my sentence 

00:11:36.550 --> 00:11:42.040
 be w1 up to wb so maximize its 

00:11:39.880 --> 00:11:45.279
 it's the same thing as maximizing 

00:11:42.040 --> 00:11:49.450
 quality of the sequence of labels and to 

00:11:45.279 --> 00:11:51.580
 give my my sentence observe and we saw 

00:11:49.450 --> 00:11:52.959
 in the hobbesian smile capsules that 

00:11:51.580 --> 00:11:55.670
 we can solve this problem there with 

00:11:52.959 --> 00:11:59.150
 the dynamic program that calculates us 

00:11:55.670 --> 00:12:00.650
 the alpha chart and you could 

00:11:59.150 --> 00:12:02.930
 remember that I encourage you to go 

00:12:00.650 --> 00:12:05.390
 see the capsules on the networks 

00:12:02.930 --> 00:12:07.940
 dynamic and specifically those that 

00:12:05.390 --> 00:12:10.850
 deal with calculating the explanation 

00:12:07.940 --> 00:12:13.570
 the most plausible in a model of 

00:12:10.850 --> 00:12:13.570
 markov hide 

