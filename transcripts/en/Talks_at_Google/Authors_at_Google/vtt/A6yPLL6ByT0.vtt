WEBVTT
Kind: captions
Language: en

00:00:06.334 --> 00:00:07.750
SPEAKER 1: So,
welcome, everybody.

00:00:07.750 --> 00:00:09.470
Thanks very much for
joining us today.

00:00:09.470 --> 00:00:12.760
We are lucky to have two
distinguished co-authors

00:00:12.760 --> 00:00:16.570
of the great, recent book
coming out very shortly,

00:00:16.570 --> 00:00:19.600
"Machine, Platform, Crowd."

00:00:19.600 --> 00:00:23.860
Let me introduce Andy McAfee
and Erik Brynjolfsson-- who

00:00:23.860 --> 00:00:26.200
are both distinguished
professors at the Sloan School

00:00:26.200 --> 00:00:29.470
at MIT, and co-directors
of the MIT initiative

00:00:29.470 --> 00:00:31.150
on the digital economy.

00:00:31.150 --> 00:00:33.610
I thought we'd start off
by asking them to tee up

00:00:33.610 --> 00:00:36.610
the thesis and main themes of
their books for a few minutes.

00:00:36.610 --> 00:00:38.950
I've got a few questions
to ask about both this book

00:00:38.950 --> 00:00:41.140
and their prior book,
"The Second Machine Age,"

00:00:41.140 --> 00:00:43.040
and we'd love to open
it up to all of you--

00:00:43.040 --> 00:00:46.764
both in the room, and in
offices around the country.

00:00:46.764 --> 00:00:48.430
So with that, let me
turn it over to you

00:00:48.430 --> 00:00:52.150
guys for a quick
overview of the book.

00:00:52.150 --> 00:00:53.880
We've known each
other for some years,

00:00:53.880 --> 00:00:55.339
in a variety of
different sessions,

00:00:55.339 --> 00:00:57.754
and my favorite description
of all of the wonderful things

00:00:57.754 --> 00:00:59.350
that could be said
about Andy and Erik

00:00:59.350 --> 00:01:02.170
is that the FT Review
called them the pinup

00:01:02.170 --> 00:01:04.060
boys for the Davos crowd.

00:01:04.060 --> 00:01:05.886
I'm not sure if
you can outdo that.

00:01:05.886 --> 00:01:06.760
But with that intro--

00:01:06.760 --> 00:01:08.176
ANDY McAFEE: Think
about what that

00:01:08.176 --> 00:01:10.090
says about the rest
of the Davos crowd.

00:01:10.090 --> 00:01:11.520
Just ponder that for a second.

00:01:11.520 --> 00:01:11.970
ERIK BRYNJOLFSSON: Yeah.

00:01:11.970 --> 00:01:13.090
Grading on a curve.

00:01:13.090 --> 00:01:15.460
But we would only be talking
for this session, though.

00:01:15.460 --> 00:01:20.007
Just to get your
expectations set properly.

00:01:20.007 --> 00:01:22.090
SPEAKER 1: So tell us a
little bit about the book.

00:01:22.090 --> 00:01:23.500
Coming off "The
Second Machine Age,"

00:01:23.500 --> 00:01:25.374
which is a lot about
the economic transitions

00:01:25.374 --> 00:01:28.690
of the United States,
what's the next chapter

00:01:28.690 --> 00:01:31.180
in that story that you wanted
to tell with this book?

00:01:31.180 --> 00:01:33.250
ERIK BRYNJOLFSSON: So,
coming off the last book,

00:01:33.250 --> 00:01:34.916
I think we heard a
lot of people saying,

00:01:34.916 --> 00:01:38.240
OK, we get what you're
saying-- the world is changing,

00:01:38.240 --> 00:01:41.080
there are these things
happening with technology,

00:01:41.080 --> 00:01:42.840
and the economy's
being affected.

00:01:42.840 --> 00:01:43.480
What now?

00:01:43.480 --> 00:01:45.700
What should we be doing
to take advantage?

00:01:45.700 --> 00:01:48.880
And a little bit more about
how businesses can react.

00:01:48.880 --> 00:01:52.300
And we saw, really, three
big rebalancings happening.

00:01:52.300 --> 00:01:54.610
One of them was between
mind and machine.

00:01:54.610 --> 00:01:57.142
One of them was between
product and platform.

00:01:57.142 --> 00:01:59.350
And the third one was between
the core and the crowd.

00:01:59.350 --> 00:02:01.641
First we thought we'd put
all those words in the title,

00:02:01.641 --> 00:02:03.880
but then our names wouldn't
fit in 18-point type.

00:02:03.880 --> 00:02:06.650
So we had to reduce the
number of words a little bit.

00:02:06.650 --> 00:02:08.590
So the first one is
one you guys are all

00:02:08.590 --> 00:02:10.840
very familiar with-- this
rebalancing between mind

00:02:10.840 --> 00:02:11.500
and machine.

00:02:11.500 --> 00:02:14.394
That machines, first off,
are helping a lot of humans

00:02:14.394 --> 00:02:15.310
make better decisions.

00:02:15.310 --> 00:02:18.550
Data-driven decision making--
whether it's helping the Golden

00:02:18.550 --> 00:02:21.100
State Warriors use
analytics to understand

00:02:21.100 --> 00:02:23.770
that three-point shots are
worth more than two-point shots.

00:02:23.770 --> 00:02:25.490
Other things like that.

00:02:25.490 --> 00:02:25.990
Or--

00:02:25.990 --> 00:02:27.610
SPEAKER 1: You wouldn't think
you'd need analytics for that.

00:02:27.610 --> 00:02:28.100
But--

00:02:28.100 --> 00:02:29.725
ERIK BRYNJOLFSSON:
Well, apparently, it

00:02:29.725 --> 00:02:31.730
wasn't well-understood
until recently.

00:02:31.730 --> 00:02:33.790
And there may have been
some more subtle things

00:02:33.790 --> 00:02:35.650
that they pulled out, as well.

00:02:35.650 --> 00:02:37.810
And of course, before that,
it was their neighbors,

00:02:37.810 --> 00:02:40.270
the Oakland A's,
and the Boston Red

00:02:40.270 --> 00:02:42.760
Sox-- who won a
series of three world

00:02:42.760 --> 00:02:44.890
championships between them.

00:02:44.890 --> 00:02:49.120
And then it's coming to
more and more businesses.

00:02:49.120 --> 00:02:52.810
We've got about a
three times increase

00:02:52.810 --> 00:02:54.790
in the use of
data-driven decision

00:02:54.790 --> 00:02:56.500
making-- that, by the
way, we measured it

00:02:56.500 --> 00:02:58.990
across American plants.

00:02:58.990 --> 00:03:02.050
And even in our own
industry-- tenure analytics.

00:03:02.050 --> 00:03:05.180
We're using analytics
to try to predict

00:03:05.180 --> 00:03:07.750
who is going to get tenure
at top universities, who's

00:03:07.750 --> 00:03:08.640
going to get prizes.

00:03:08.640 --> 00:03:11.150
And it turns out that it
can out-predict the tenure

00:03:11.150 --> 00:03:13.430
committees, in terms of who
does better performance.

00:03:13.430 --> 00:03:15.550
But that's just the
first part of that.

00:03:15.550 --> 00:03:18.970
More and more, as you guys
know, artificial intelligence

00:03:18.970 --> 00:03:20.494
is making decisions
on their own.

00:03:20.494 --> 00:03:21.910
And I won't even
go into all that,

00:03:21.910 --> 00:03:24.710
because you guys are
very familiar with that.

00:03:24.710 --> 00:03:28.210
The second big rebalancing is
between products and platforms.

00:03:28.210 --> 00:03:30.880
Five of the biggest
companies by market cap

00:03:30.880 --> 00:03:33.130
are platform companies--

00:03:33.130 --> 00:03:39.110
Google Alphabet, here, Facebook,
Amazon, Apple, and Microsoft.

00:03:39.110 --> 00:03:41.050
But there's lots of
smaller companies

00:03:41.050 --> 00:03:42.970
that are coming up and
growing-- sometimes,

00:03:42.970 --> 00:03:45.100
almost out of nowhere,
becoming multibillion dollar

00:03:45.100 --> 00:03:46.757
companies--
leveraging platforms,

00:03:46.757 --> 00:03:49.090
and trying to understand that
trade-off between products

00:03:49.090 --> 00:03:52.000
and platforms, and why those
are so much more powerful now.

00:03:52.000 --> 00:03:55.630
And thirdly, between
the core and the crowd.

00:03:55.630 --> 00:03:58.300
Tapping into the millions--
actually, billions--

00:03:58.300 --> 00:03:59.644
of brains around the planet.

00:03:59.644 --> 00:04:01.060
It's something
that we can do now,

00:04:01.060 --> 00:04:04.442
because we have a global,
interconnected digital network

00:04:04.442 --> 00:04:06.650
that allows people to
communicate that way-- in a way

00:04:06.650 --> 00:04:08.410
they couldn't have previously.

00:04:08.410 --> 00:04:10.300
And not just to
access information,

00:04:10.300 --> 00:04:12.380
but to contribute to it.

00:04:12.380 --> 00:04:14.519
So this helps us to
make sense of some

00:04:14.519 --> 00:04:16.810
of the weird things that are
happening in the economy--

00:04:16.810 --> 00:04:18.700
the companies that
are being destroyed,

00:04:18.700 --> 00:04:20.342
new companies being created.

00:04:20.342 --> 00:04:22.300
And there's some underlying
economic principles

00:04:22.300 --> 00:04:27.520
in each of these areas of
"Machine, Platform, and Crowd."

00:04:27.520 --> 00:04:30.430
And laying out
the phenomena that

00:04:30.430 --> 00:04:32.236
are happening with
lots of case studies,

00:04:32.236 --> 00:04:33.610
and then the
economic principles.

00:04:33.610 --> 00:04:35.200
In each case, it
turns out, there

00:04:35.200 --> 00:04:37.750
are some Nobel
Prize-winning economics that

00:04:37.750 --> 00:04:40.000
drive each of these changes.

00:04:40.000 --> 00:04:41.927
And that can help us
make sense of that.

00:04:41.927 --> 00:04:43.510
So that was the basic
strategy of what

00:04:43.510 --> 00:04:47.030
we were trying to do with
"Machine, Platform, and Crowd."

00:04:47.030 --> 00:04:49.471
And we're hoping
that we continue

00:04:49.471 --> 00:04:50.720
to have this kind of dialogue.

00:04:50.720 --> 00:04:52.180
We're looking forward to
some questions and comments

00:04:52.180 --> 00:04:54.970
from all of you, to see what
the challenges are that you're

00:04:54.970 --> 00:04:56.680
facing, the opportunities
you're facing,

00:04:56.680 --> 00:04:59.096
and see how well we can map
them into the frameworks we've

00:04:59.096 --> 00:04:59.910
developed.

00:04:59.910 --> 00:05:00.670
Andy?

00:05:00.670 --> 00:05:01.420
ANDY McAFEE: Yeah.

00:05:01.420 --> 00:05:02.737
What he said.

00:05:02.737 --> 00:05:04.570
First of all, Ken, thank
you for hosting us.

00:05:04.570 --> 00:05:06.653
It's a pleasure and a real
privilege to come back.

00:05:06.653 --> 00:05:08.630
We've learned a lot from
Google over the years.

00:05:08.630 --> 00:05:11.050
It's always a pleasure to come
back and talk with you all.

00:05:11.050 --> 00:05:14.950
I want to also thank Andrew
and your team at Google.org.

00:05:14.950 --> 00:05:18.130
Google.org is a supporter of our
Inclusive Innovation Challenge

00:05:18.130 --> 00:05:20.980
back at MIT, where we're
trying to reward innovators

00:05:20.980 --> 00:05:22.690
and entrepreneurs
who are improving

00:05:22.690 --> 00:05:27.190
economic prospects for average
income and below-average income

00:05:27.190 --> 00:05:27.769
workers.

00:05:27.769 --> 00:05:30.310
A lot of us in this room know
that the narrative, these days,

00:05:30.310 --> 00:05:32.110
is that technology
is killing jobs.

00:05:32.110 --> 00:05:34.490
And it's not too far
from that narrative to,

00:05:34.490 --> 00:05:36.430
"therefore, technology
is a bad thing."

00:05:36.430 --> 00:05:39.040
We think that's a really
harmful road to go down.

00:05:39.040 --> 00:05:42.550
So with the IIC, we're trying
to celebrate organizations

00:05:42.550 --> 00:05:45.550
that are using technology to
bring economic opportunity.

00:05:45.550 --> 00:05:48.010
We're really happy to have
Google.org on board with us

00:05:48.010 --> 00:05:48.830
for that.

00:05:48.830 --> 00:05:50.500
And then, finally, thank you
all for showing up today.

00:05:50.500 --> 00:05:52.480
I know you probably have
a lot of things to do.

00:05:52.480 --> 00:05:54.280
It's a pleasure
to have you here.

00:05:54.280 --> 00:05:57.040
I want to tell the origin
story of this book.

00:05:57.040 --> 00:05:59.560
Because Erik and I wrote "The
Second Machine Age" together.

00:05:59.560 --> 00:06:01.780
And, you know, we
kind of thought maybe

00:06:01.780 --> 00:06:05.890
we were done writing books
about this period of crazy tech

00:06:05.890 --> 00:06:07.810
progress that we were in.

00:06:07.810 --> 00:06:10.270
And we noticed, as soon
as we finished that book,

00:06:10.270 --> 00:06:12.970
that people who run companies
kept on approaching us

00:06:12.970 --> 00:06:15.880
in the hallways-- honestly--
of places like Davos,

00:06:15.880 --> 00:06:18.700
and they kept on
saying, essentially,

00:06:18.700 --> 00:06:20.500
"I believe your story--

00:06:20.500 --> 00:06:22.460
now what do I do?"

00:06:22.460 --> 00:06:24.790
And in some cases,
I got the impression

00:06:24.790 --> 00:06:27.340
that there was actually some
desperation behind the question

00:06:27.340 --> 00:06:28.600
that they were asking.

00:06:28.600 --> 00:06:29.960
These people were successful.

00:06:29.960 --> 00:06:32.420
They were running large,
successful organizations.

00:06:32.420 --> 00:06:33.878
And I started to
get the impression

00:06:33.878 --> 00:06:36.280
that they were at sea-- they
were really floundering,

00:06:36.280 --> 00:06:40.570
or foundering, about
this technology surge.

00:06:40.570 --> 00:06:42.700
That they understood,
at some level,

00:06:42.700 --> 00:06:44.680
they didn't have a
great way to think

00:06:44.680 --> 00:06:47.137
about what this was going
to do to their business,

00:06:47.137 --> 00:06:48.970
to their organization,
or to their industry.

00:06:48.970 --> 00:06:52.750
And that became this recurring
conversation that we had.

00:06:52.750 --> 00:06:54.820
And I found it
profoundly interesting,

00:06:54.820 --> 00:06:57.370
because I didn't understand, at
first, why they were so lost.

00:06:57.370 --> 00:07:01.120
These were smart, successful,
experienced, well-educated

00:07:01.120 --> 00:07:02.890
executives-- and
they felt, really,

00:07:02.890 --> 00:07:06.730
just "deer in headlights"
with what was coming at them.

00:07:06.730 --> 00:07:08.230
And then as Erik
and I did the work,

00:07:08.230 --> 00:07:11.140
I realized that I should have
been less surprised by that.

00:07:11.140 --> 00:07:12.760
Because the mantra
about technology

00:07:12.760 --> 00:07:14.830
that I'm repeating to
myself, these days,

00:07:14.830 --> 00:07:18.435
is that tech progress rewrites
the business playbook.

00:07:18.435 --> 00:07:20.560
And we're in one of those
stages right now-- where,

00:07:20.560 --> 00:07:22.720
the two of us believe,
the playbook for how

00:07:22.720 --> 00:07:25.570
you run a successful business
is being substantially

00:07:25.570 --> 00:07:29.140
rewritten by the kinds of new
technologies that we're seeing.

00:07:29.140 --> 00:07:30.790
The last time I
think this happened

00:07:30.790 --> 00:07:32.950
was just about a
century ago, when

00:07:32.950 --> 00:07:36.010
manufacturing went from
being steam-powered to being

00:07:36.010 --> 00:07:37.360
electric-powered.

00:07:37.360 --> 00:07:39.609
And there was a naive way
to think about that-- which

00:07:39.609 --> 00:07:41.650
was take out the big steam
engine in the basement

00:07:41.650 --> 00:07:44.019
of the factory, and replace
it with a big electric motor

00:07:44.019 --> 00:07:45.310
in the basement of the factory.

00:07:45.310 --> 00:07:46.900
And a lot of companies did that.

00:07:46.900 --> 00:07:49.460
That was kind of a no-brainer.

00:07:49.460 --> 00:07:51.430
What we've learned
from business history

00:07:51.430 --> 00:07:54.760
is that the companies
and business leaders who

00:07:54.760 --> 00:07:57.019
grew up in the era of steam--

00:07:57.019 --> 00:07:58.810
it's not that they were
unwilling to invest

00:07:58.810 --> 00:07:59.960
in electricity.

00:07:59.960 --> 00:08:02.040
It's not that they thought
electricity sucked.

00:08:02.040 --> 00:08:03.700
It's that, honestly,
they could not--

00:08:03.700 --> 00:08:06.640
their minds did not
admit the possibility

00:08:06.640 --> 00:08:10.520
of an overhead crane, or a
conveyor belt, or an assembly

00:08:10.520 --> 00:08:11.020
line.

00:08:11.020 --> 00:08:13.450
These things did not
make sense if you

00:08:13.450 --> 00:08:15.970
had a factory powered by
belts, and shafts, and pulleys,

00:08:15.970 --> 00:08:17.240
and steam in the basement.

00:08:17.240 --> 00:08:18.589
This was just crazy talk.

00:08:18.589 --> 00:08:20.380
And you can go back
and read the literature

00:08:20.380 --> 00:08:22.660
from those early decades
of the 20th century,

00:08:22.660 --> 00:08:24.940
and there were these
vicious debates about,

00:08:24.940 --> 00:08:27.820
"should we put a motor on
every machine in the factory?"

00:08:27.820 --> 00:08:30.130
That was nutty, for decades--

00:08:30.130 --> 00:08:32.470
even though it's completely
obvious in retrospect.

00:08:32.470 --> 00:08:34.030
So the homework
that Erik and I had

00:08:34.030 --> 00:08:37.600
for ourselves was to
think of, these days,

00:08:37.600 --> 00:08:40.419
what are the equivalents of
overhead cranes, and assembly

00:08:40.419 --> 00:08:44.200
lines, and conveyor belts, that
forward-thinking companies are

00:08:44.200 --> 00:08:47.320
on top of, and that the
ones who are trapped

00:08:47.320 --> 00:08:50.020
in previous mindsets and
previous ways of thinking

00:08:50.020 --> 00:08:51.580
are just not going to see?

00:08:51.580 --> 00:08:53.460
And that led to our
three-part answer--

00:08:53.460 --> 00:08:55.550
I see a lot of companies
underestimating

00:08:55.550 --> 00:08:58.390
the power of machines, a lot
of companies underestimating

00:08:58.390 --> 00:09:00.490
the power platforms,
and a lot of companies

00:09:00.490 --> 00:09:03.924
not doing a great job of tapping
into the crowd out there.

00:09:03.924 --> 00:09:05.590
SPEAKER 1: So, for a
company like ours--

00:09:05.590 --> 00:09:08.980
we feel very much in the middle
of a lot of these phenomena.

00:09:08.980 --> 00:09:11.080
You start your book with
examples of AlphaGo,

00:09:11.080 --> 00:09:12.449
with DeepMind.

00:09:12.449 --> 00:09:14.740
The platform-- obviously, we
have a number of different

00:09:14.740 --> 00:09:16.740
things that have platform-like
characteristics--

00:09:16.740 --> 00:09:17.980
Android, and a lot of others.

00:09:17.980 --> 00:09:20.230
And even on crowd, you can
argue that Google search is

00:09:20.230 --> 00:09:23.040
the greatest man-machine
collaboration in history,

00:09:23.040 --> 00:09:25.420
as people use our systems
and improve the systems

00:09:25.420 --> 00:09:27.084
through their clicks.

00:09:27.084 --> 00:09:28.750
So what would be your
advice for Google?

00:09:28.750 --> 00:09:30.333
What do you think
we're getting wrong?

00:09:30.333 --> 00:09:33.950
What do you think we should
be doing differently?

00:09:33.950 --> 00:09:35.650
And I see we're just
about out of time.

00:09:35.650 --> 00:09:37.071
Thank you all for coming in.

00:09:37.071 --> 00:09:37.570
[LAUGHTER]

00:09:37.570 --> 00:09:39.819
ERIK BRYNJOLFSSON: You're
doing a lot of things right.

00:09:39.819 --> 00:09:42.860
And so I think that one of
the risks is that, in a way,

00:09:42.860 --> 00:09:44.434
you may become too successful.

00:09:44.434 --> 00:09:46.850
And I think one of the things
that we don't talk that much

00:09:46.850 --> 00:09:50.210
about in the book, but I think
we're going to see, is that,

00:09:50.210 --> 00:09:53.270
as we get more of a
winner-take-most economy,

00:09:53.270 --> 00:09:56.004
and very successful companies
are able to use these

00:09:56.004 --> 00:09:57.920
technologies to dominate
market after market--

00:09:57.920 --> 00:10:00.200
because they
understand those three,

00:10:00.200 --> 00:10:02.900
and other companies are
just beginning to get them--

00:10:02.900 --> 00:10:06.480
then there can be a backlash,
and a push-back against that.

00:10:06.480 --> 00:10:10.790
And one of the questions is,
what kind of economy are we in,

00:10:10.790 --> 00:10:11.650
going forward?

00:10:11.650 --> 00:10:14.870
Is it one where there
is monopoly capitalism?

00:10:14.870 --> 00:10:16.870
Or is it what we've
talked about in the book--

00:10:16.870 --> 00:10:19.790
more of a Schumpeterian
creative destruction,

00:10:19.790 --> 00:10:22.850
where there's always a
risk of one platform being

00:10:22.850 --> 00:10:24.650
displaced by another?

00:10:24.650 --> 00:10:26.691
But understanding
that economics are

00:10:26.691 --> 00:10:28.940
a little bit different in a
world where there are very

00:10:28.940 --> 00:10:32.360
strong network effects, or
even two-sided network effects,

00:10:32.360 --> 00:10:35.420
and there are some big scale
economies, and very rapid

00:10:35.420 --> 00:10:36.527
technological change.

00:10:36.527 --> 00:10:38.360
And that's something
that I know that you're

00:10:38.360 --> 00:10:39.320
very much on top of--

00:10:39.320 --> 00:10:42.400
understanding those
kinds of dynamics.

00:10:42.400 --> 00:10:45.980
And, relatedly-- something we
touched on in the last book--

00:10:45.980 --> 00:10:48.380
is this winner-take-all or
winner-take-most dynamic

00:10:48.380 --> 00:10:49.713
doesn't just apply to companies.

00:10:49.713 --> 00:10:51.720
It can apply to
individuals, as well.

00:10:51.720 --> 00:10:53.825
So we're seeing
growing inequality

00:10:53.825 --> 00:10:55.200
on a lot of
different dimensions.

00:10:55.200 --> 00:10:57.440
And it's great-- as Andy
mentioned-- that Google.org

00:10:57.440 --> 00:11:04.160
is helping to identify business
models that can create more

00:11:04.160 --> 00:11:07.250
broadly-shared prosperity
as another counterweight

00:11:07.250 --> 00:11:12.090
against a world where all
of the wealth, and perhaps

00:11:12.090 --> 00:11:13.757
political power, gets
more concentrated.

00:11:13.757 --> 00:11:15.881
ANDY McAFEE: Ken, I think
this is a great question.

00:11:15.881 --> 00:11:18.230
I want to answer, not
specifically about Google,

00:11:18.230 --> 00:11:20.077
but about companies
full of smart people.

00:11:20.077 --> 00:11:22.160
And at the risk of flattering
people in this room,

00:11:22.160 --> 00:11:23.290
and watching us--

00:11:23.290 --> 00:11:25.760
OK, there are a lot of smart
people working at Google.

00:11:25.760 --> 00:11:28.490
The single biggest
failure mode that I've

00:11:28.490 --> 00:11:30.950
observed, related to the
content of the book, when

00:11:30.950 --> 00:11:33.290
I talk to audiences
of very smart people,

00:11:33.290 --> 00:11:35.120
is that smart
people tend to have

00:11:35.120 --> 00:11:37.970
an exaggerated version
of a failure mode

00:11:37.970 --> 00:11:39.890
that everybody has--

00:11:39.890 --> 00:11:43.910
which is to be too fond, and
too confident, and too reliant

00:11:43.910 --> 00:11:48.620
on their own intuition,
judgment, experience,

00:11:48.620 --> 00:11:50.120
intelligence.

00:11:50.120 --> 00:11:53.240
And they are very
often guilty of some

00:11:53.240 --> 00:11:55.250
of these cognitive biases--

00:11:55.250 --> 00:11:57.500
Erik mentioned Nobel Prizes--
that Daniel Kahneman got

00:11:57.500 --> 00:12:00.200
a Nobel Prize for figuring out.

00:12:00.200 --> 00:12:02.630
The failure mode among
really smart people

00:12:02.630 --> 00:12:04.149
is to trust themselves too much.

00:12:04.149 --> 00:12:06.440
And one of the points we
make-- the broad point we make

00:12:06.440 --> 00:12:08.510
in the first section
of the book is, look,

00:12:08.510 --> 00:12:10.490
your intuition is awesome.

00:12:10.490 --> 00:12:14.540
It is demonstrably buggy
and failure-ridden,

00:12:14.540 --> 00:12:17.810
and it's got all kinds of
really powerful, pretty bad-news

00:12:17.810 --> 00:12:18.770
failure modes.

00:12:18.770 --> 00:12:21.410
The fact that your IQ is
well above the average

00:12:21.410 --> 00:12:23.326
does not insulate you from that.

00:12:23.326 --> 00:12:25.700
And in some ways, it can make
that worse-- overconfidence

00:12:25.700 --> 00:12:28.922
bias tends to be worse
among really smart people.

00:12:28.922 --> 00:12:31.130
So the point we make in the
first section of the book

00:12:31.130 --> 00:12:33.005
is to hammer that point
home, and make people

00:12:33.005 --> 00:12:34.116
feel bad about themselves.

00:12:34.116 --> 00:12:36.740
But then, to say, look-- we have
these awesome colleagues, now,

00:12:36.740 --> 00:12:40.130
called machines, that have
very different failure modes

00:12:40.130 --> 00:12:41.480
than people do.

00:12:41.480 --> 00:12:42.800
They're not inconsistent.

00:12:42.800 --> 00:12:44.120
They're not overconfident.

00:12:44.120 --> 00:12:46.430
But they're really
stupid about the world.

00:12:46.430 --> 00:12:48.500
There's are a wonderful
concept from linguistics.

00:12:48.500 --> 00:12:51.320
It's called the intuition
of the native speaker.

00:12:51.320 --> 00:12:55.997
I can recognize a grammatically
faulty English sentence

00:12:55.997 --> 00:12:57.830
[SNAPS FINGERS] just
in the blink of an eye.

00:12:57.830 --> 00:12:58.670
Immediately.

00:12:58.670 --> 00:13:00.920
And people who don't speak
English as a first language

00:13:00.920 --> 00:13:02.150
can't do that.

00:13:02.150 --> 00:13:04.640
Reason I bring that up--
we have native speaker

00:13:04.640 --> 00:13:06.930
intuition about the world.

00:13:06.930 --> 00:13:08.780
Even with all the work
you guys are doing,

00:13:08.780 --> 00:13:10.790
our machines don't
have that yet.

00:13:10.790 --> 00:13:12.500
So one of the broad
points we try to make

00:13:12.500 --> 00:13:14.540
is, let's bring
together the strengths

00:13:14.540 --> 00:13:16.820
of minds and machines.

00:13:16.820 --> 00:13:19.160
If we do that correctly,
I think we can cancel out

00:13:19.160 --> 00:13:21.110
each other's failure modes.

00:13:21.110 --> 00:13:23.390
The big homework,
especially for smart people,

00:13:23.390 --> 00:13:26.450
is to become more aware of
the failure modes of humanity.

00:13:26.450 --> 00:13:28.760
And more willing to
question yourself,

00:13:28.760 --> 00:13:29.840
second guess yourself.

00:13:29.840 --> 00:13:33.380
Use data, use machines
to buttress the mistakes

00:13:33.380 --> 00:13:34.432
that our wetware has.

00:13:34.432 --> 00:13:36.890
ERIK BRYNJOLFSSON: And there
are lessons from the other two

00:13:36.890 --> 00:13:38.450
sections of the book, as well.

00:13:38.450 --> 00:13:41.390
I mean, you guys know
Joy's Law-- that no matter

00:13:41.390 --> 00:13:43.562
what company you work for,
most of the smart people

00:13:43.562 --> 00:13:45.270
in the world don't
work for your company.

00:13:45.270 --> 00:13:47.250
And it's probably
even true for Google.

00:13:47.250 --> 00:13:50.210
That may be the edge case.

00:13:50.210 --> 00:13:53.330
And so it's great that
Google-- we were just,

00:13:53.330 --> 00:13:55.810
last night, with
Anthony Goldbloom,

00:13:55.810 --> 00:13:57.260
co-founder of Kaggle.

00:13:57.260 --> 00:13:59.180
And it's great to
see Google tapping

00:13:59.180 --> 00:14:02.107
into the power of the crowd,
and all of those smart people

00:14:02.107 --> 00:14:03.440
elsewhere that are contributing.

00:14:03.440 --> 00:14:05.930
And the AI initiatives
that are allowing people

00:14:05.930 --> 00:14:07.340
to contribute in
different ways--

00:14:07.340 --> 00:14:09.310
use TensorFlow,
and other things,

00:14:09.310 --> 00:14:13.520
to tap into that
crowd knowledge.

00:14:13.520 --> 00:14:15.560
And on platforms--
I mean, yes, Google

00:14:15.560 --> 00:14:18.205
has not just one, but
multiple great platforms.

00:14:18.205 --> 00:14:20.990
But as we describe in the book,
those are constantly evolving.

00:14:20.990 --> 00:14:23.120
As the technology
changes, there's always

00:14:23.120 --> 00:14:24.680
a risk of them being displaced.

00:14:24.680 --> 00:14:26.510
And of course, there's
new ones rising up.

00:14:26.510 --> 00:14:27.540
As you go from--

00:14:27.540 --> 00:14:28.970
as Sundar Pichai said--

00:14:28.970 --> 00:14:31.310
a mobile-first to
an AI-first world,

00:14:31.310 --> 00:14:32.840
that kind of
transition-- you know,

00:14:32.840 --> 00:14:34.350
Microsoft kind of bobbled that.

00:14:34.350 --> 00:14:37.560
Going from desktops to mobile.

00:14:37.560 --> 00:14:39.300
And there's these
constant risks.

00:14:39.300 --> 00:14:42.570
So because of the rapid
change that we were just

00:14:42.570 --> 00:14:45.420
talking about, you can't
sit back and feel like,

00:14:45.420 --> 00:14:47.400
OK, we've got the problem
solved, et cetera.

00:14:47.400 --> 00:14:49.320
We can just relax.

00:14:49.320 --> 00:14:52.070
I think the lessons in all
three sections of the book

00:14:52.070 --> 00:14:53.064
apply to Google.

00:14:53.064 --> 00:14:55.230
SPEAKER 1: Let's talk a
little bit about time scale.

00:14:55.230 --> 00:14:56.790
We get very excited about this.

00:14:56.790 --> 00:14:57.350
We feel it.

00:14:57.350 --> 00:14:59.040
It's the ocean we swim in.

00:14:59.040 --> 00:15:02.190
And yet-- Andy, your example
about electrification--

00:15:02.190 --> 00:15:06.600
it took 50 years to disseminate
the effects of electrification

00:15:06.600 --> 00:15:08.100
through society in a broad way.

00:15:08.100 --> 00:15:10.016
If you look at something
like the cell phone--

00:15:10.016 --> 00:15:15.930
it was conceived of in 1947,
demoed in 1973, sold in '83.

00:15:15.930 --> 00:15:18.570
And it really wasn't until the
turn of the century, or later,

00:15:18.570 --> 00:15:20.700
until it became widely adopted.

00:15:20.700 --> 00:15:22.359
So are we overestimating
how quickly

00:15:22.359 --> 00:15:23.400
all this is coming along?

00:15:23.400 --> 00:15:25.400
Or do you think this is
right around the corner?

00:15:25.400 --> 00:15:28.260
ANDY McAFEE: I think
especially the geekier set is

00:15:28.260 --> 00:15:31.050
overestimating how quickly these
things are going to happen--

00:15:31.050 --> 00:15:33.391
how quickly the cars are
going to drive themselves,

00:15:33.391 --> 00:15:35.640
and we talk to AI in our
homes and everything happens,

00:15:35.640 --> 00:15:37.110
and the drones deliver stuff.

00:15:37.110 --> 00:15:39.270
I think we are
overestimating that.

00:15:39.270 --> 00:15:41.520
However, I do think
that a lot of people

00:15:41.520 --> 00:15:43.140
are underestimating that.

00:15:43.140 --> 00:15:45.630
And in the communities that
Erik and I try to be part of,

00:15:45.630 --> 00:15:48.330
there's a super active
debate about how soon

00:15:48.330 --> 00:15:49.932
is x going to happen.

00:15:49.932 --> 00:15:52.140
And a lot of people rely on
those historical examples

00:15:52.140 --> 00:15:54.015
that you just brought
up, and say, look, this

00:15:54.015 --> 00:15:55.470
is a decades-long process.

00:15:55.470 --> 00:15:57.390
My favorite counter to that is--

00:15:57.390 --> 00:15:59.790
how old is Facebook?

00:15:59.790 --> 00:16:00.831
2004-ish?

00:16:00.831 --> 00:16:01.830
ERIK BRYNJOLFSSON: Yeah.

00:16:01.830 --> 00:16:02.610
Five, yeah.

00:16:02.610 --> 00:16:06.090
ANDY McAFEE: Facebook has 1.9
billion users around the world.

00:16:06.090 --> 00:16:10.140
Close to a third of humanity
has adopted this technology,

00:16:10.140 --> 00:16:11.880
in the space of 15 years.

00:16:11.880 --> 00:16:14.260
We have never, ever
seen this before.

00:16:14.260 --> 00:16:16.590
So in a world that
is interconnected

00:16:16.590 --> 00:16:20.550
with pretty powerful devices,
and where the cloud is

00:16:20.550 --> 00:16:23.560
available on demand
almost everywhere,

00:16:23.560 --> 00:16:25.560
and where really powerful
tools are being put up

00:16:25.560 --> 00:16:27.330
into the cloud,
the time scales can

00:16:27.330 --> 00:16:28.581
be quicker than we're used to.

00:16:28.581 --> 00:16:30.038
ERIK BRYNJOLFSSON:
And I would make

00:16:30.038 --> 00:16:32.280
a distinction between those
two examples you gave.

00:16:32.280 --> 00:16:35.220
I think Andy is exactly
right, that the technology is

00:16:35.220 --> 00:16:38.970
evolving a lot faster
than the cell phone did.

00:16:38.970 --> 00:16:41.340
But what doesn't seem to
be moving a lot faster

00:16:41.340 --> 00:16:44.550
is our ability to adapt the
business process to change.

00:16:44.550 --> 00:16:46.260
And that's what held
back electricity.

00:16:46.260 --> 00:16:50.010
Electricity was-- the
technology was there

00:16:50.010 --> 00:16:53.310
for a good several decades
before the factories reinvented

00:16:53.310 --> 00:16:56.470
their business processes and
reinvented their organizations.

00:16:56.470 --> 00:16:58.110
And there are some
technologies that

00:16:58.110 --> 00:17:01.080
can be adopted without a whole
lot of business process change,

00:17:01.080 --> 00:17:03.846
like a consumer-facing
product, like Facebook.

00:17:03.846 --> 00:17:05.220
But a lot of the
ones that really

00:17:05.220 --> 00:17:08.640
have big societal
changes are going

00:17:08.640 --> 00:17:10.520
to require a lot
more adjustment.

00:17:10.520 --> 00:17:12.150
And self-driving
cars-- it's going

00:17:12.150 --> 00:17:14.099
to be not just a
matter of having

00:17:14.099 --> 00:17:15.140
to navigate the vehicles.

00:17:15.140 --> 00:17:18.834
There's a whole set of
laws, ethics, customs that

00:17:18.834 --> 00:17:20.000
are going to have to evolve.

00:17:20.000 --> 00:17:21.270
SPEAKER 1: This must
keep you up at night,

00:17:21.270 --> 00:17:23.400
thinking about all the
barriers that come up.

00:17:23.400 --> 00:17:25.108
ERIK BRYNJOLFSSON:
And those don't evolve

00:17:25.108 --> 00:17:26.799
at Moore's Law types of speeds.

00:17:26.799 --> 00:17:28.590
One of the big reasons
we wrote this book--

00:17:28.590 --> 00:17:30.410
SPEAKER 1: Lawyers
like geologic time.

00:17:30.410 --> 00:17:30.760
ERIK BRYNJOLFSSON: Yeah.

00:17:30.760 --> 00:17:31.230
More like geological time.

00:17:31.230 --> 00:17:32.270
ANDY McAFEE: They
go backwards slowly.

00:17:32.270 --> 00:17:33.180
ERIK BRYNJOLFSSON: And
that's why we wrote the book.

00:17:33.180 --> 00:17:35.760
But hopefully that we can move
the dial a little bit on that.

00:17:35.760 --> 00:17:38.241
I think if people understand
how to take advantage

00:17:38.241 --> 00:17:39.990
of these technologies,
and they understand

00:17:39.990 --> 00:17:42.500
the process of change
that's necessary,

00:17:42.500 --> 00:17:45.210
we can make it happen
a little bit faster--

00:17:45.210 --> 00:17:47.700
once we give them a bit of
a playbook about what works

00:17:47.700 --> 00:17:48.720
and what doesn't work.

00:17:48.720 --> 00:17:50.640
ANDY McAFEE: And it's also true
that the progress is really

00:17:50.640 --> 00:17:51.730
going to be piecemeal.

00:17:51.730 --> 00:17:55.570
So nationwide,
fully-autonomous cars--

00:17:55.570 --> 00:17:57.630
that might be a bit off.

00:17:57.630 --> 00:17:59.700
We were talking to
Vinod Khosla yesterday,

00:17:59.700 --> 00:18:02.850
and he brought up that one
company that he's aware of

00:18:02.850 --> 00:18:06.540
is trying to just think about
automating driving trucks

00:18:06.540 --> 00:18:07.860
between-- what was it, Dallas?

00:18:07.860 --> 00:18:08.550
ERIK BRYNJOLFSSON:
Phoenix and LA, I think.

00:18:08.550 --> 00:18:10.350
ANDY McAFEE: Dallas and LA.

00:18:10.350 --> 00:18:11.670
He said, let's just do that.

00:18:11.670 --> 00:18:13.860
There's a billion
dollars of commerce--

00:18:13.860 --> 00:18:16.260
that's a billion dollar
market, just driving trucks

00:18:16.260 --> 00:18:18.480
back and forth between
those two cities.

00:18:18.480 --> 00:18:21.210
Can we get regulatory approval
from the states on the route?

00:18:21.210 --> 00:18:23.010
And can we-- that's one route.

00:18:23.010 --> 00:18:24.820
We know how to map
that pretty easily.

00:18:24.820 --> 00:18:26.270
So that can happen
pretty quickly.

00:18:26.270 --> 00:18:26.790
ERIK BRYNJOLFSSON:
And part of it

00:18:26.790 --> 00:18:29.610
was not to do all the little
side streets at each city.

00:18:29.610 --> 00:18:31.140
Get it onto the
highway, and boom.

00:18:31.140 --> 00:18:31.770
And they go.

00:18:31.770 --> 00:18:34.394
ANDY McAFEE: And then text some
person to show up and drive it.

00:18:34.394 --> 00:18:37.212
It's going to take a while
to completely rewire and put

00:18:37.212 --> 00:18:38.670
sensors all over
the electric grid,

00:18:38.670 --> 00:18:41.610
and get the efficiencies that
we were hoping for with that.

00:18:41.610 --> 00:18:44.100
At the same time, the
thought experiment that I run

00:18:44.100 --> 00:18:46.530
is, how much work would
it be for some kind

00:18:46.530 --> 00:18:50.190
of industrial facility to
slap sensors on everything,

00:18:50.190 --> 00:18:54.930
give it to TensorFlow, and maybe
get the kind of 15-ish percent

00:18:54.930 --> 00:18:58.260
step change improvement that
the Google data center saw when

00:18:58.260 --> 00:19:01.730
they turned over operations
to a cousin of the AlphaGo

00:19:01.730 --> 00:19:02.700
technology?

00:19:02.700 --> 00:19:04.890
So there are going to
be relatively quick

00:19:04.890 --> 00:19:08.284
big wins happening all
over the economy, I think.

00:19:08.284 --> 00:19:09.700
SPEAKER 1: Now
let's talk a little

00:19:09.700 --> 00:19:11.490
about the social
implications of that.

00:19:11.490 --> 00:19:13.560
And it's something you covered
in depth in "The Second Machine

00:19:13.560 --> 00:19:15.361
Age," but continues
to be very relevant.

00:19:15.361 --> 00:19:16.860
When you talk about
driverless cars,

00:19:16.860 --> 00:19:19.151
immediately there's concern
about employment transition

00:19:19.151 --> 00:19:20.890
and displacement.

00:19:20.890 --> 00:19:23.490
The standard response
is, more training,

00:19:23.490 --> 00:19:26.130
and perhaps either
earned income tax credit

00:19:26.130 --> 00:19:27.750
or universal basic income.

00:19:27.750 --> 00:19:31.540
Yet, training has been kind
of a mixed success rate.

00:19:31.540 --> 00:19:33.720
There are not a lot of
great case studies there.

00:19:33.720 --> 00:19:35.700
People trying to do new things--

00:19:35.700 --> 00:19:37.260
online training, and the like.

00:19:37.260 --> 00:19:38.760
Interested in your
thoughts on that.

00:19:38.760 --> 00:19:40.950
And, more generally, on the
balance between our need

00:19:40.950 --> 00:19:43.410
for growing productivity
as our workforce ages,

00:19:43.410 --> 00:19:47.580
and potential impacts on social
structures and employment.

00:19:47.580 --> 00:19:49.770
ERIK BRYNJOLFSSON: There's
no silver bullet here.

00:19:49.770 --> 00:19:51.030
And I think there
are a lot of people--

00:19:51.030 --> 00:19:53.190
and Vinod was one of them--
if you look far enough ahead,

00:19:53.190 --> 00:19:55.356
it's going to be very hard
for education to keep up.

00:19:55.356 --> 00:19:57.490
But I think where we
are right now, in 2017--

00:19:57.490 --> 00:20:00.960
and as far as I can tell, for
the next five, 10 more years--

00:20:00.960 --> 00:20:04.290
training and education is
probably at the top of my list.

00:20:04.290 --> 00:20:06.125
I think most economists lists--

00:20:06.125 --> 00:20:07.500
ANDY McAFEE:
[WHISPERS] Not mine.

00:20:07.500 --> 00:20:07.800
ERIK BRYNJOLFSSON: OK.

00:20:07.800 --> 00:20:08.790
ANDY McAFEE: Not mine.

00:20:08.790 --> 00:20:10.917
ERIK BRYNJOLFSSON: So
Andy can weigh in on that.

00:20:10.917 --> 00:20:13.000
But there's different kinds
of training education.

00:20:13.000 --> 00:20:15.540
So some of them give
very specific tasks.

00:20:15.540 --> 00:20:18.360
You know, what Sebastian Thrun's
company are doing at Udacity.

00:20:18.360 --> 00:20:20.460
You can learn some
skills quite rapidly,

00:20:20.460 --> 00:20:22.080
and add a great deal of value.

00:20:22.080 --> 00:20:24.480
Tom Kalil described
something that DARPA did,

00:20:24.480 --> 00:20:28.140
called the Education Dominance
Program, that in 90 or 120 days

00:20:28.140 --> 00:20:31.200
would give people some very
concrete skills that massively

00:20:31.200 --> 00:20:32.620
increased their value.

00:20:32.620 --> 00:20:34.200
The more lasting
skills are going

00:20:34.200 --> 00:20:36.750
to be the ones around
interpersonal skills,

00:20:36.750 --> 00:20:40.230
creativity, teamwork,
persuasion-- some of the softer

00:20:40.230 --> 00:20:42.312
skills that machines
aren't very good at.

00:20:42.312 --> 00:20:43.770
I don't think our
schools are doing

00:20:43.770 --> 00:20:46.830
a very good job of teaching
those-- or, worse yet,

00:20:46.830 --> 00:20:49.290
I think many of
them are actually

00:20:49.290 --> 00:20:51.840
crushing them, and
making them less salient.

00:20:51.840 --> 00:20:52.380
So if--

00:20:52.380 --> 00:20:53.070
ANDY McAFEE: How many
of us feel like we

00:20:53.070 --> 00:20:54.640
had some of the love
of learning crushed out

00:20:54.640 --> 00:20:55.690
of us by our education?

00:20:55.690 --> 00:20:57.060
Just-- honestly, show of hands.

00:20:57.060 --> 00:20:57.620
Yeah.

00:20:57.620 --> 00:20:58.920
Way up in the air, please.

00:20:58.920 --> 00:21:00.220
Look around the room.

00:21:00.220 --> 00:21:01.160
This is a crime.

00:21:01.160 --> 00:21:01.690
ERIK BRYNJOLFSSON:
This is a crime.

00:21:01.690 --> 00:21:03.610
Because, I think, most
kids, actually, they

00:21:03.610 --> 00:21:04.480
love being creative.

00:21:04.480 --> 00:21:05.530
You put a pile of
blocks in front

00:21:05.530 --> 00:21:06.670
of a three-year-old, the
first thing they'll do

00:21:06.670 --> 00:21:07.836
is start building something.

00:21:07.836 --> 00:21:09.280
Or crayons.

00:21:09.280 --> 00:21:12.130
Kids-- humans-- love creating.

00:21:12.130 --> 00:21:14.830
And if we can nurture
that, let that flourish,

00:21:14.830 --> 00:21:16.622
that is what machines
are not very good at.

00:21:16.622 --> 00:21:18.788
Playing and interacting
with other people, teamwork.

00:21:18.788 --> 00:21:20.660
That's what machines
aren't very good at.

00:21:20.660 --> 00:21:23.045
So it's not just a matter of
spending more on education--

00:21:23.045 --> 00:21:24.190
though I don't think
that would hurt.

00:21:24.190 --> 00:21:25.000
I think that would help.

00:21:25.000 --> 00:21:27.220
But it's a matter of more
fundamentally reinventing

00:21:27.220 --> 00:21:28.270
education.

00:21:28.270 --> 00:21:30.250
There are so many
tasks in our economy,

00:21:30.250 --> 00:21:32.300
still, that only humans can do.

00:21:32.300 --> 00:21:34.540
And that's the way it's
going to be for a while.

00:21:34.540 --> 00:21:36.820
So I'm not ready to
write off human skills.

00:21:36.820 --> 00:21:38.300
I think we should
invest, and make

00:21:38.300 --> 00:21:40.240
people ready to do all
those different kinds

00:21:40.240 --> 00:21:40.960
of human tasks--

00:21:40.960 --> 00:21:45.220
health care, education
child care, creative works.

00:21:45.220 --> 00:21:48.316
And that's going to be,
I think, one of the ways

00:21:48.316 --> 00:21:49.690
to create more
shared prosperity.

00:21:49.690 --> 00:21:50.620
But you may disagree, Andy.

00:21:50.620 --> 00:21:52.745
ANDY McAFEE: I agree with
everything you just said.

00:21:52.745 --> 00:21:57.220
Here's why I disagree with
an "education reform first"

00:21:57.220 --> 00:21:58.510
approach to fixing things.

00:21:58.510 --> 00:22:00.926
My thought experiment is, let's
say there's a pot of money

00:22:00.926 --> 00:22:03.630
available, and you can do
only one thing with it.

00:22:03.630 --> 00:22:06.710
And I have three prime
candidates in my mind.

00:22:06.710 --> 00:22:08.227
Number one is reform education.

00:22:08.227 --> 00:22:10.060
And let's say it's going
to cost something--

00:22:10.060 --> 00:22:10.240
ERIK BRYNJOLFSSON: Wait.

00:22:10.240 --> 00:22:11.230
What number was that?

00:22:11.230 --> 00:22:11.980
ANDY McAFEE: What?

00:22:11.980 --> 00:22:12.790
The amount of money?

00:22:12.790 --> 00:22:12.940
ERIK BRYNJOLFSSON: No.

00:22:12.940 --> 00:22:13.670
What number was that?

00:22:13.670 --> 00:22:14.520
That was number one?

00:22:14.520 --> 00:22:16.957
ANDY McAFEE: Not in
descending order.

00:22:16.957 --> 00:22:18.040
ERIK BRYNJOLFSSON: Oh, OK.

00:22:18.040 --> 00:22:18.540
All right.

00:22:18.540 --> 00:22:21.160
ANDY McAFEE: Option A
is to reform education.

00:22:21.160 --> 00:22:24.220
Option B is to figure out why
entrepreneurship in America

00:22:24.220 --> 00:22:28.540
has been on a long, slow, steady
decline, and reverse that.

00:22:28.540 --> 00:22:31.720
Option C is to bring our
infrastructure up from a grade

00:22:31.720 --> 00:22:36.640
of D+ to, maybe, a solid B.
I would actually take either

00:22:36.640 --> 00:22:40.259
option B or C over option A.
I'm not saying that I'm right.

00:22:40.259 --> 00:22:41.800
And I'm not saying
it's a no-brainer.

00:22:41.800 --> 00:22:45.220
But I would love to solve either
of those latter two problems

00:22:45.220 --> 00:22:45.970
first.

00:22:45.970 --> 00:22:48.280
I fall back on something
that Larry Summers

00:22:48.280 --> 00:22:52.000
says, in his inimitable fashion,
whenever somebody brings up

00:22:52.000 --> 00:22:52.600
education.

00:22:52.600 --> 00:22:55.240
He said, "education
reform is kind of a dodge.

00:22:55.240 --> 00:22:57.850
And unless we grow
the economy faster,

00:22:57.850 --> 00:23:00.550
we're not going to be doing
a lot for jobs and wages."

00:23:00.550 --> 00:23:02.440
That's a very strong
way to say it.

00:23:02.440 --> 00:23:04.120
But to grow the
economy faster, I

00:23:04.120 --> 00:23:06.460
would love to figure out why
entrepreneurship is sucking

00:23:06.460 --> 00:23:09.610
in America and I would love to
fix our infrastructure-- which

00:23:09.610 --> 00:23:11.580
is just the biggest
no-brainer out there.

00:23:11.580 --> 00:23:12.160
ERIK BRYNJOLFSSON:
But the good news

00:23:12.160 --> 00:23:14.270
is, we don't have to
choose just one of those.

00:23:14.270 --> 00:23:17.050
I think that there is no
silver bullet, like I said.

00:23:17.050 --> 00:23:19.301
We should be doing all of
these things simultaneously.

00:23:19.301 --> 00:23:21.091
And some of them,
government can help with.

00:23:21.091 --> 00:23:23.280
A lot of things we can do
without having government

00:23:23.280 --> 00:23:23.790
involved.

00:23:23.790 --> 00:23:26.500
It may be-- depending on which
way the winds are blowing--

00:23:26.500 --> 00:23:28.583
it may be that we have to
take more responsibility

00:23:28.583 --> 00:23:30.250
as individuals,
or organizations,

00:23:30.250 --> 00:23:32.170
to step up some of
these other dimensions.

00:23:32.170 --> 00:23:32.920
ANDY McAFEE: Yeah.

00:23:32.920 --> 00:23:35.419
I completely agree with that,
without reservation this time.

00:23:35.419 --> 00:23:37.809
And one of the really
encouraging things-- sorry--

00:23:37.809 --> 00:23:39.850
one of the really encouraging
things in education

00:23:39.850 --> 00:23:42.160
is the rise of these
really alternative ways

00:23:42.160 --> 00:23:45.040
to get really powerful
skills, to get credentials,

00:23:45.040 --> 00:23:47.410
and to signal how
good you are at stuff.

00:23:47.410 --> 00:23:49.660
That's a case where the
government has been lagging,

00:23:49.660 --> 00:23:51.140
in many cases.

00:23:51.140 --> 00:23:53.200
And, in fact, because
student loans are only

00:23:53.200 --> 00:23:55.570
given to accredited
institutions, in some ways

00:23:55.570 --> 00:23:58.124
the government is impeding
progress in these areas.

00:23:58.124 --> 00:24:00.040
Now, I don't think I'm
a frothing-at-the-mouth

00:24:00.040 --> 00:24:04.570
libertarian, but I would like
to see that situation change.

00:24:04.570 --> 00:24:06.956
SPEAKER 1: So let me
ask one more question,

00:24:06.956 --> 00:24:08.830
then open it up to
questions from all of you.

00:24:08.830 --> 00:24:10.288
We don't have mics
around the room,

00:24:10.288 --> 00:24:12.092
so please just shout
out the question.

00:24:12.092 --> 00:24:14.050
We'll repeat it back so
we catch it on the mic,

00:24:14.050 --> 00:24:14.540
and for people remotely.

00:24:14.540 --> 00:24:16.330
ERIK BRYNJOLFSSON: And
can people at the desks

00:24:16.330 --> 00:24:16.990
ask questions, too?

00:24:16.990 --> 00:24:17.610
Is there a way to get--

00:24:17.610 --> 00:24:18.400
SPEAKER 1: Yes.

00:24:18.400 --> 00:24:20.781
I was going to say, so Andrew
has the Dory available,

00:24:20.781 --> 00:24:22.780
which is running a constant
number of questions,

00:24:22.780 --> 00:24:24.025
and actually voting
on those questions.

00:24:24.025 --> 00:24:24.691
ANDY McAFEE: Oh.

00:24:24.691 --> 00:24:26.160
And you have a
retinal implant that

00:24:26.160 --> 00:24:26.830
is giving you access to this.

00:24:26.830 --> 00:24:27.290
SPEAKER 1: Exactly.

00:24:27.290 --> 00:24:28.123
We're tracking them.

00:24:28.123 --> 00:24:29.285
It's all in TensorFlow.

00:24:29.285 --> 00:24:31.120
The best questions will
surface to the top.

00:24:31.120 --> 00:24:33.634
But let me step back, before
we open it up to everybody,

00:24:33.634 --> 00:24:35.550
and ask about the global
implications of this.

00:24:35.550 --> 00:24:39.100
There have been some who
have argued that the growing

00:24:39.100 --> 00:24:41.170
use of robots and
industrialization

00:24:41.170 --> 00:24:43.570
is blocking paths to development
that have traditionally

00:24:43.570 --> 00:24:46.420
been available for
evolving countries.

00:24:46.420 --> 00:24:49.420
Daron Acemoglu argues that
every time you employ a robot,

00:24:49.420 --> 00:24:52.090
you don't employ
three to five people.

00:24:52.090 --> 00:24:53.380
What's your take on that?

00:24:53.380 --> 00:24:54.820
How do you see this
playing out globally?

00:24:54.820 --> 00:24:56.370
ERIK BRYNJOLFSSON: Well, let's
touch on the global one first.

00:24:56.370 --> 00:24:59.410
Andy and I, along with Michael
Spence-- one of our friendly,

00:24:59.410 --> 00:25:01.690
Nobel Prize-winning colleagues--

00:25:01.690 --> 00:25:03.880
wrote an article about
some of those implications

00:25:03.880 --> 00:25:05.210
of globalization.

00:25:05.210 --> 00:25:07.750
And that was a couple of
years ago, in foreign affairs.

00:25:07.750 --> 00:25:10.270
And we talked about
this challenge

00:25:10.270 --> 00:25:12.859
that, in many ways--
although technology's

00:25:12.859 --> 00:25:15.150
been one of the best things
that has happened globally,

00:25:15.150 --> 00:25:17.400
and as you probably know,
there are a lot fewer people

00:25:17.400 --> 00:25:19.626
in poverty now than
there were 20 years ago,

00:25:19.626 --> 00:25:21.250
and a lot of the
trends are very good--

00:25:21.250 --> 00:25:23.530
but if you look a little
further into the future,

00:25:23.530 --> 00:25:24.850
there are some storm clouds.

00:25:24.850 --> 00:25:28.210
And in particular, countries
that are, right now, depending

00:25:28.210 --> 00:25:30.820
on manufacturing to be that
engine to lift them out

00:25:30.820 --> 00:25:33.340
of poverty, are very
much in the bullseye

00:25:33.340 --> 00:25:34.600
of a lot of the automation.

00:25:34.600 --> 00:25:39.160
You go visit China, and you
see thousands of people working

00:25:39.160 --> 00:25:41.525
side by side, doing very
routine, simple tasks--

00:25:41.525 --> 00:25:43.900
tasks that a lot of you guys
could probably write up some

00:25:43.900 --> 00:25:44.956
code to get--

00:25:44.956 --> 00:25:46.330
ANDY McAFEE: In
about 20 minutes.

00:25:46.330 --> 00:25:48.288
ERIK BRYNJOLFSSON: --a
robot to do those tasks.

00:25:48.288 --> 00:25:50.260
And, you know,
those workers were

00:25:50.260 --> 00:25:53.200
able to compete very effectively
against American or German or

00:25:53.200 --> 00:25:54.797
Swiss workers at lower wages.

00:25:54.797 --> 00:25:57.130
But you don't want to be
competing on the basis of wages

00:25:57.130 --> 00:25:58.480
against a robot.

00:25:58.480 --> 00:26:00.660
And so that means that
that middle class that's

00:26:00.660 --> 00:26:03.360
been created in a lot
of developing countries

00:26:03.360 --> 00:26:05.320
is now going to have
to compete with robots

00:26:05.320 --> 00:26:09.420
that can work for $4, $2,
$1 an hour equivalent.

00:26:09.420 --> 00:26:11.130
And that's not a
good place to be.

00:26:11.130 --> 00:26:13.652
They need to leapfrog
to a situation

00:26:13.652 --> 00:26:16.110
where they're doing more of
that creative and interpersonal

00:26:16.110 --> 00:26:16.740
work.

00:26:16.740 --> 00:26:18.330
You know, for better
or worse, there's

00:26:18.330 --> 00:26:21.420
not that many manufacturing
workers in American factories

00:26:21.420 --> 00:26:22.210
anymore.

00:26:22.210 --> 00:26:24.540
I mean, it's less than
10% of the workforce.

00:26:24.540 --> 00:26:26.880
You go to most factories,
it's kind of lights out.

00:26:26.880 --> 00:26:29.910
So we are, in some
ways, going to be

00:26:29.910 --> 00:26:34.260
less affected by that kind
of automation of factory work

00:26:34.260 --> 00:26:35.760
than those developing countries.

00:26:35.760 --> 00:26:38.850
And it may make it harder for
them to make that transition.

00:26:38.850 --> 00:26:41.910
Some countries, like China, they
have a very sophisticated tech

00:26:41.910 --> 00:26:42.870
economy, as well.

00:26:42.870 --> 00:26:44.910
So they've got a
big chunk of people

00:26:44.910 --> 00:26:47.100
on the other side of that curve.

00:26:47.100 --> 00:26:49.680
Other countries, like
Vietnam and the Philippines,

00:26:49.680 --> 00:26:52.480
are going to have a harder
time making that transition.

00:26:52.480 --> 00:26:54.646
ANDY McAFEE: The way I look
at your question-- there

00:26:54.646 --> 00:26:57.746
are two unmistakable, big,
big global trends related

00:26:57.746 --> 00:26:59.370
to the things that
we're talking about.

00:26:59.370 --> 00:27:02.430
One is betterment-- improvement
of the human condition.

00:27:02.430 --> 00:27:04.935
We've had the largest
declines in dire poverty

00:27:04.935 --> 00:27:06.310
we've ever seen
around the world.

00:27:06.310 --> 00:27:08.310
We've had the biggest
increases in human health,

00:27:08.310 --> 00:27:10.690
in recent decades, that we've
ever seen around the world.

00:27:10.690 --> 00:27:13.050
Do you all know the
site Our World In Data?

00:27:13.050 --> 00:27:14.310
This is my favorite site.

00:27:14.310 --> 00:27:16.750
Because you walk away
just happy after you

00:27:16.750 --> 00:27:19.130
look at almost any aspect of it.

00:27:19.130 --> 00:27:21.120
So the first one is
that the world, almost

00:27:21.120 --> 00:27:23.220
without exception, is
getting better in the areas

00:27:23.220 --> 00:27:23.920
that we care about.

00:27:23.920 --> 00:27:24.900
That's the first trend.

00:27:24.900 --> 00:27:26.680
The second one is concentration.

00:27:26.680 --> 00:27:28.800
And when it gets to
this notion that we

00:27:28.800 --> 00:27:30.930
are doing more and more
manufacturing in a smaller

00:27:30.930 --> 00:27:33.150
and smaller geographic
footprint, a smaller

00:27:33.150 --> 00:27:34.750
and smaller
employment footprint,

00:27:34.750 --> 00:27:37.740
a smaller and smaller number
of companies footprint.

00:27:37.740 --> 00:27:39.240
Wealth is getting
more concentrated,

00:27:39.240 --> 00:27:40.874
income is getting
more concentrated.

00:27:40.874 --> 00:27:42.540
It almost doesn't
matter where you look.

00:27:42.540 --> 00:27:44.560
This trend is really pronounced.

00:27:44.560 --> 00:27:46.920
Now, I don't know if
those two trends are

00:27:46.920 --> 00:27:49.830
going to continue
to interact happily,

00:27:49.830 --> 00:27:51.690
or if there's kind of
a clash of the Titans

00:27:51.690 --> 00:27:55.140
that's coming, when these cost
declines implicit in Moore's

00:27:55.140 --> 00:27:58.290
law meet rising wages
in Bangladesh and China,

00:27:58.290 --> 00:27:59.400
and places like that.

00:27:59.400 --> 00:28:02.439
Those two trends could run
headlong into each other.

00:28:02.439 --> 00:28:04.230
I don't know that's
what's going to happen,

00:28:04.230 --> 00:28:07.067
but that's something
to keep our eyes on.

00:28:07.067 --> 00:28:07.650
SPEAKER 1: OK.

00:28:07.650 --> 00:28:09.120
So let's open it up the room.

00:28:09.120 --> 00:28:11.380
And Andrew's ready, if
we don't have questions.

00:28:11.380 --> 00:28:11.880
But first--

00:28:11.880 --> 00:28:13.296
ERIK BRYNJOLFSSON:
So the question

00:28:13.296 --> 00:28:15.000
has to do with, on
one hand, we see

00:28:15.000 --> 00:28:18.810
increasing returns to scale,
and perhaps more concentration

00:28:18.810 --> 00:28:19.650
of wealth.

00:28:19.650 --> 00:28:21.050
Certainly we have seen that.

00:28:21.050 --> 00:28:24.150
And on the other hand, we see
this decline in productivity.

00:28:24.150 --> 00:28:25.741
And are those two--

00:28:25.741 --> 00:28:26.990
not a decline of productivity.

00:28:26.990 --> 00:28:28.290
Let me be more precise.

00:28:28.290 --> 00:28:30.200
A slower rate of
productivity growth.

00:28:30.200 --> 00:28:31.590
It's still growing.

00:28:31.590 --> 00:28:33.550
And are these
possibly connected.

00:28:33.550 --> 00:28:35.274
And I think there
are some people who

00:28:35.274 --> 00:28:36.190
are making that case--

00:28:36.190 --> 00:28:37.910
Joe Stiglitz, and
others-- that there's

00:28:37.910 --> 00:28:40.110
this big rise of
a rentier economy.

00:28:40.110 --> 00:28:42.259
People rent seeking.

00:28:42.259 --> 00:28:43.300
I don't see it quite yet.

00:28:43.300 --> 00:28:45.360
It's something I'd like
to keep my eyes open,

00:28:45.360 --> 00:28:46.980
and take a look at.

00:28:46.980 --> 00:28:48.930
I think that some of
the areas where you're

00:28:48.930 --> 00:28:51.140
seeing these increasing
returns to scale

00:28:51.140 --> 00:28:53.997
are actually some of the more
dynamic parts of the economy.

00:28:53.997 --> 00:28:55.080
So I would look elsewhere.

00:28:55.080 --> 00:28:56.370
If you look at the
part where there's

00:28:56.370 --> 00:28:58.020
been less entrepreneurship,
where there

00:28:58.020 --> 00:29:00.450
are fewer young
new firms, they're

00:29:00.450 --> 00:29:02.340
not in those parts
of the economy where

00:29:02.340 --> 00:29:05.717
we're seeing the network
effects, and so forth.

00:29:05.717 --> 00:29:07.050
So I would look to other things.

00:29:07.050 --> 00:29:09.974
There's issues around
occupational licensing.

00:29:09.974 --> 00:29:11.640
There's just the aging
of the workforce.

00:29:11.640 --> 00:29:13.306
And I see everyone
here is pretty young,

00:29:13.306 --> 00:29:14.894
but sadly, when
people get older,

00:29:14.894 --> 00:29:16.560
they don't get to be
as entrepreneurial.

00:29:16.560 --> 00:29:19.010
ANDY McAFEE: Trust us, there are
old people working in America.

00:29:19.010 --> 00:29:20.280
I know that's weird
for you all to believe.

00:29:20.280 --> 00:29:21.738
ERIK BRYNJOLFSSON:
And most of them

00:29:21.738 --> 00:29:22.880
are not starting companies.

00:29:22.880 --> 00:29:24.930
So that's part of it.

00:29:24.930 --> 00:29:27.122
It is, obviously, a
little bit of a mystery

00:29:27.122 --> 00:29:29.580
to people who study this, like
John Haltiwanger and others.

00:29:29.580 --> 00:29:31.830
They're not quite sure
what's going on there,

00:29:31.830 --> 00:29:34.170
in terms of that effect.

00:29:34.170 --> 00:29:37.620
In terms of the other drivers
of productivity I think we see,

00:29:37.620 --> 00:29:39.700
we've been talking about
these wondrous things.

00:29:39.700 --> 00:29:42.200
The other thing we have to bear
in mind is that most of them

00:29:42.200 --> 00:29:43.910
haven't really hit
the marketplace yet.

00:29:43.910 --> 00:29:46.410
You know, Andy and I rode in a
self-driving car in the first

00:29:46.410 --> 00:29:48.570
book, and again more recently--

00:29:48.570 --> 00:29:49.980
which is a lot of fun.

00:29:49.980 --> 00:29:53.250
But there aren't a whole lot of
them out there on the highways.

00:29:53.250 --> 00:29:55.607
Or most of the other
amazing technologies.

00:29:55.607 --> 00:29:57.690
We're excited, and I think
folks in Silicon Valley

00:29:57.690 --> 00:30:01.170
are excited, because we can
see what's in the pipeline.

00:30:01.170 --> 00:30:04.020
But in terms of measurable
effects on productivity?

00:30:04.020 --> 00:30:05.580
Right now, we are
really harvesting

00:30:05.580 --> 00:30:09.360
more what happened in the
1990s in terms of technology.

00:30:09.360 --> 00:30:12.870
I mean, back in 1997, the
same Silicon Valley folks

00:30:12.870 --> 00:30:15.070
were excited about e-commerce.

00:30:15.070 --> 00:30:17.610
But did it really make a dent
on traditional retailing?

00:30:17.610 --> 00:30:19.135
Not until 2017.

00:30:19.135 --> 00:30:20.760
And you know, the
past couple of weeks,

00:30:20.760 --> 00:30:22.630
you've been reading
a lot about that.

00:30:22.630 --> 00:30:24.480
So there's a pretty
significant lag

00:30:24.480 --> 00:30:27.125
between when you see these
wondrous technologies,

00:30:27.125 --> 00:30:28.500
and when they're
going to show up

00:30:28.500 --> 00:30:30.330
in the productivity statistics.

00:30:30.330 --> 00:30:33.190
And that, I think,
is probably more

00:30:33.190 --> 00:30:35.400
of the explanation behind
some of those two trends

00:30:35.400 --> 00:30:36.030
you describe.

00:30:36.030 --> 00:30:38.876
ANDY McAFEE: We have a rock
star colleague back at MIT,

00:30:38.876 --> 00:30:41.250
named John Van Reenen, who
dove into exactly the question

00:30:41.250 --> 00:30:42.210
that you're asking.

00:30:42.210 --> 00:30:44.954
And he documented that, in
industry after industry,

00:30:44.954 --> 00:30:47.120
there are these superstar
firms that are appearing--

00:30:47.120 --> 00:30:48.540
a small number of them.

00:30:48.540 --> 00:30:51.030
They're sucking up a
lot of the revenue.

00:30:51.030 --> 00:30:53.040
Lots and lots of the
profits in industry

00:30:53.040 --> 00:30:55.320
after industry-- not
just in high tech.

00:30:55.320 --> 00:30:57.880
And he says that might
explain some of the trends

00:30:57.880 --> 00:30:59.130
that you brought up.

00:30:59.130 --> 00:31:00.930
So the interesting
thought experiment--

00:31:00.930 --> 00:31:05.700
is Amazon good or bad for
overall retail productivity?

00:31:05.700 --> 00:31:08.620
And my initial answer is,
it's got to be awesome for it.

00:31:08.620 --> 00:31:11.190
Well, if all the other
companies in retail

00:31:11.190 --> 00:31:13.140
are seeing slowly
eroding revenue,

00:31:13.140 --> 00:31:15.680
and they're not laying
off people in droves yet,

00:31:15.680 --> 00:31:17.430
then overall productivity
from that sector

00:31:17.430 --> 00:31:21.770
could actually be slowing down
or declining because of Amazon

00:31:21.770 --> 00:31:24.800
sucking all the energy up into
one really concentrated place.

00:31:24.800 --> 00:31:27.430
So the data-- we've got
to dive deeper into it.

00:31:27.430 --> 00:31:29.470
Because it's a fundamentally
important question.

00:31:29.470 --> 00:31:31.595
And there are a couple of
different promising lines

00:31:31.595 --> 00:31:32.780
of research, here.

00:31:32.780 --> 00:31:34.070
ERIK BRYNJOLFSSON: And one
more, to just touch on briefly--

00:31:34.070 --> 00:31:35.528
that the Amazon
one reminds me of--

00:31:35.528 --> 00:31:37.650
is there's a measurement
issue, as well.

00:31:37.650 --> 00:31:40.530
That our GDP statistics
are just horrifically

00:31:40.530 --> 00:31:42.720
bad at capturing the
value of free goods,

00:31:42.720 --> 00:31:44.610
like Google, Facebook,
and a lot of others.

00:31:44.610 --> 00:31:44.745
ANDY McAFEE: Right.

00:31:44.745 --> 00:31:45.705
You all shrink GDP.

00:31:45.705 --> 00:31:47.130
Did you realize that?

00:31:47.130 --> 00:31:47.670
Stop it.

00:31:47.670 --> 00:31:49.961
ERIK BRYNJOLFSSON: When you
take Brittanica and turn it

00:31:49.961 --> 00:31:51.240
into Wikipedia, GDP goes down.

00:31:51.240 --> 00:31:52.680
But welfare goes up.

00:31:52.680 --> 00:31:57.710
And Amazon is providing a lot
more product variety, choice,

00:31:57.710 --> 00:32:00.240
timeliness--

00:32:00.240 --> 00:32:02.700
and none of those show up in
the GDP statistics, either.

00:32:02.700 --> 00:32:04.290
So we have a bit of a mismatch.

00:32:04.290 --> 00:32:07.130
If you go back to Simon
Kuznets, who invented the GDP--

00:32:07.130 --> 00:32:09.130
one of the great inventions
of the 20th century,

00:32:09.130 --> 00:32:10.680
Paul Samuelson said--

00:32:10.680 --> 00:32:13.110
one of the first things he
said was, please, please

00:32:13.110 --> 00:32:15.390
do not use this as a
measure of welfare.

00:32:15.390 --> 00:32:16.650
It is a measure of production.

00:32:16.650 --> 00:32:18.480
It's not a measure of
how well we're doing.

00:32:18.480 --> 00:32:20.146
But of course, the
first thing everybody

00:32:20.146 --> 00:32:23.030
started doing was assuming
GDP equals welfare.

00:32:23.030 --> 00:32:24.580
And that's just
mathematically wrong.

00:32:24.580 --> 00:32:25.330
ANDY McAFEE: Yeah.

00:32:25.330 --> 00:32:27.360
SPEAKER 1: We should cut
over to the Putin-ese model

00:32:27.360 --> 00:32:28.425
of gross national happiness.

00:32:28.425 --> 00:32:29.830
ERIK BRYNJOLFSSON: Well,
that may be going too far.

00:32:29.830 --> 00:32:31.770
I mean, I think
one of the problems

00:32:31.770 --> 00:32:33.432
is that the nice
thing about GDP is

00:32:33.432 --> 00:32:35.640
you can measure it to, like,
nine significant digits.

00:32:35.640 --> 00:32:37.709
And it's very, very
satisfying to be able to,

00:32:37.709 --> 00:32:38.500
each quarter, say--

00:32:38.500 --> 00:32:40.460
ANDY McAFEE: And
you can decompose it

00:32:40.460 --> 00:32:41.590
into four other things.

00:32:41.590 --> 00:32:41.970
ERIK BRYNJOLFSSON: Yeah.

00:32:41.970 --> 00:32:43.160
It went up two-- no, sorry.

00:32:43.160 --> 00:32:43.980
It was 2.4%.

00:32:43.980 --> 00:32:44.910
ANDY McAFEE: Woo-hoo!

00:32:44.910 --> 00:32:46.326
ERIK BRYNJOLFSSON:
And, you know--

00:32:46.326 --> 00:32:47.640
gross national happiness?

00:32:47.640 --> 00:32:50.030
I'd be lucky to get the first
significant digit right.

00:32:50.030 --> 00:32:52.113
SPEAKER 1: Your comment
about the aging population

00:32:52.113 --> 00:32:54.930
and productivity reminds me of
a most astonishing statistic

00:32:54.930 --> 00:32:56.520
I've seen, perhaps, this year--

00:32:56.520 --> 00:32:58.799
that within three
decades, taking out

00:32:58.799 --> 00:33:00.840
Africa and population
growth there-- for the rest

00:33:00.840 --> 00:33:02.370
of the world, within
three decades,

00:33:02.370 --> 00:33:04.800
the average age of humans
on the planet Earth

00:33:04.800 --> 00:33:05.742
will be 60 years old.

00:33:05.742 --> 00:33:06.450
ANDY McAFEE: Wow.

00:33:06.450 --> 00:33:07.200
ERIK BRYNJOLFSSON: Wow.

00:33:07.200 --> 00:33:08.850
SPEAKER 1: That is
a dramatic change

00:33:08.850 --> 00:33:11.320
in the ratio of productive
people in the workforce.

00:33:11.320 --> 00:33:13.350
Unless the useful-- your
time in the workforce

00:33:13.350 --> 00:33:15.600
changes dramatically,
and requires

00:33:15.600 --> 00:33:17.809
an awful lot more productivity
to help adjust for it.

00:33:17.809 --> 00:33:19.058
ERIK BRYNJOLFSSON: Well, yeah.

00:33:19.058 --> 00:33:20.670
And there may be a good thing--

00:33:20.670 --> 00:33:22.980
Rod Brooks, and others, have
really emphasized this--

00:33:22.980 --> 00:33:25.090
let's bring on the
robots as fast as we can,

00:33:25.090 --> 00:33:28.160
so they can help take
care of us in our old age.

00:33:28.160 --> 00:33:31.560
SPEAKER 1: So Andrew,
question from the Dory?

00:33:31.560 --> 00:33:32.310
ANDREW: All right.

00:33:32.310 --> 00:33:34.530
So we have a question from
Miguel, who's in New York.

00:33:34.530 --> 00:33:36.390
And he asks, given your
research on the rates

00:33:36.390 --> 00:33:38.348
of technological change,
what are your thoughts

00:33:38.348 --> 00:33:39.660
on universal basic income?

00:33:39.660 --> 00:33:41.710
Reeducating everyone
should be the goal.

00:33:41.710 --> 00:33:43.945
But if this can take
years, or not happen,

00:33:43.945 --> 00:33:45.570
given the emergence
of multiple pilots,

00:33:45.570 --> 00:33:47.580
do you think of UBI as
a potential solution?

00:33:49.940 --> 00:33:50.940
ANDY McAFEE: Absolutely.

00:33:50.940 --> 00:33:52.540
People should be
researching UBI.

00:33:52.540 --> 00:33:54.752
I think the experiments that
are happening in Finland

00:33:54.752 --> 00:33:55.710
are really interesting.

00:33:55.710 --> 00:33:58.140
I think what Y Combinator is
doing is pretty interesting.

00:33:58.140 --> 00:34:00.270
By all means, let's
do the research.

00:34:00.270 --> 00:34:02.640
Let me tell you why I'm
skeptical about a Universal

00:34:02.640 --> 00:34:03.590
Basic Income.

00:34:03.590 --> 00:34:06.300
And it's extremely
straightforward-- a UBI,

00:34:06.300 --> 00:34:08.969
in its most classic
form, provides

00:34:08.969 --> 00:34:12.179
no direct incentive, no
direct encouragement, to work.

00:34:12.179 --> 00:34:16.080
And as Erik and I have
gone on with our work,

00:34:16.080 --> 00:34:18.340
I've become a
fanatic about work--

00:34:18.340 --> 00:34:22.505
about the value, the importance,
of something like a job.

00:34:22.505 --> 00:34:24.630
Not for some kind of
old-fashioned, Protestant work

00:34:24.630 --> 00:34:26.050
ethic reason, I don't think.

00:34:26.050 --> 00:34:27.900
But because the
evidence is overwhelming

00:34:27.900 --> 00:34:31.830
that, when work leaves a
community, bad things happen.

00:34:31.830 --> 00:34:33.239
Not good things.

00:34:33.239 --> 00:34:35.820
The research is just
overwhelming on this.

00:34:35.820 --> 00:34:38.250
You see marriages fall apart.

00:34:38.250 --> 00:34:39.750
You see couples not
getting married.

00:34:39.750 --> 00:34:41.708
You see kids not being
raised in nuclear homes.

00:34:41.708 --> 00:34:42.719
You can think, so what?

00:34:42.719 --> 00:34:44.820
You see crime going up.

00:34:44.820 --> 00:34:46.300
That's pretty unambiguous.

00:34:46.300 --> 00:34:47.730
So what?

00:34:47.730 --> 00:34:53.190
A lot of us know that
Angus Deaton and Anne

00:34:53.190 --> 00:34:56.340
Case highlighted this crazy
phenomenon, that we were

00:34:56.340 --> 00:34:58.290
unaware of, until recently--

00:34:58.290 --> 00:35:00.720
that death rates,
mortality rates

00:35:00.720 --> 00:35:02.550
among white,
middle-aged Americans,

00:35:02.550 --> 00:35:05.490
are actually increasing
instead of decreasing.

00:35:05.490 --> 00:35:07.140
And the reason
they're increasing

00:35:07.140 --> 00:35:09.780
is because of what they
call "deaths of despair"--

00:35:09.780 --> 00:35:15.150
suicide, chronic liver disease,
alcoholism, and drug overdoses.

00:35:15.150 --> 00:35:17.214
I can't tell a happy
story about that.

00:35:17.214 --> 00:35:18.630
Those deaths of
despair are really

00:35:18.630 --> 00:35:20.910
strongly concentrated
in exactly the kinds

00:35:20.910 --> 00:35:22.650
of communities and
demographics that

00:35:22.650 --> 00:35:24.520
are least likely to be working.

00:35:24.520 --> 00:35:26.280
So I think about
that, and I think,

00:35:26.280 --> 00:35:27.930
which of those
social problems will

00:35:27.930 --> 00:35:31.151
be fixed by a magical check
from the government showing up

00:35:31.151 --> 00:35:31.650
every month?

00:35:31.650 --> 00:35:34.454
And my answer, in that thought
experiment, is basically, none.

00:35:34.454 --> 00:35:36.870
ERIK BRYNJOLFSSON: And our
friend Bob Putnam really helped

00:35:36.870 --> 00:35:38.576
educate us about these issues.

00:35:38.576 --> 00:35:40.700
But I want to underscore
the first thing Andy said.

00:35:40.700 --> 00:35:42.410
You know, we're all
for experiments.

00:35:42.410 --> 00:35:44.670
And let's try some
different things.

00:35:44.670 --> 00:35:47.160
Because we can sit here
in our chairs, and say,

00:35:47.160 --> 00:35:49.780
hey, this is what we
think motivates people.

00:35:49.780 --> 00:35:52.710
But the truth is, there haven't
been that many real tests

00:35:52.710 --> 00:35:54.110
of some of these theories.

00:35:54.110 --> 00:35:56.070
And it could be done
in different ways.

00:35:56.070 --> 00:35:59.020
Norway has been fabulously
successful with their oil

00:35:59.020 --> 00:36:02.220
wealth-- giving people longer
vacations, a lot of childcare,

00:36:02.220 --> 00:36:04.920
taking care of people, and
maintaining a pretty high level

00:36:04.920 --> 00:36:06.000
of satisfaction.

00:36:06.000 --> 00:36:08.100
Other oil-rich
countries have not

00:36:08.100 --> 00:36:11.130
been successful in navigating
that level of wealth.

00:36:11.130 --> 00:36:14.430
So I think that there's clearly
some devils in the details,

00:36:14.430 --> 00:36:15.930
in terms of how you
structure things

00:36:15.930 --> 00:36:17.610
and how you help
people, that can

00:36:17.610 --> 00:36:19.690
lead to very different
kinds of outcomes.

00:36:19.690 --> 00:36:20.430
ANDY McAFEE: The
other thing to say

00:36:20.430 --> 00:36:22.680
on this point-- this is a
really fundamental question.

00:36:22.680 --> 00:36:25.230
Another reason that I'm not a
fan of the UBI is because it

00:36:25.230 --> 00:36:29.130
might be a solution
in a post-work world--

00:36:29.130 --> 00:36:31.980
in a world where we just don't
need a lot of human labor.

00:36:31.980 --> 00:36:33.870
There is nothing in
the evidence that

00:36:33.870 --> 00:36:36.200
says we're heading
into that world, yet.

00:36:36.200 --> 00:36:39.540
We've added net jobs in America,
month by month, for, I believe,

00:36:39.540 --> 00:36:41.490
75 months straight.

00:36:41.490 --> 00:36:44.130
And you can go graph the
number of hours of labor

00:36:44.130 --> 00:36:46.920
required to generate
America's economic output--

00:36:46.920 --> 00:36:50.790
it has gone up in
lockstep with GDP, ever

00:36:50.790 --> 00:36:52.350
since the end of
the Great Recession.

00:36:52.350 --> 00:36:53.850
So when you look
at the trend lines,

00:36:53.850 --> 00:36:56.040
you don't see any
plateauing or leveling off.

00:36:56.040 --> 00:36:57.710
You don't see the end of work.

00:36:57.710 --> 00:37:00.100
I'll become a lot more
excited about a UBI

00:37:00.100 --> 00:37:02.430
when the amount of
labor hours needed

00:37:02.430 --> 00:37:05.700
to generate economic
output starts to level off.

00:37:05.700 --> 00:37:08.220
SPEAKER 1: So America has
high rates of labor mobility.

00:37:08.220 --> 00:37:11.370
Is that something we should be
encouraging, or discouraging?

00:37:11.370 --> 00:37:11.960
ERIK BRYNJOLFSSON: High rates?

00:37:11.960 --> 00:37:13.251
SPEAKER 1: Relatively speaking.

00:37:13.251 --> 00:37:15.900
ERIK BRYNJOLFSSON: Well, I think
actually, one of the concerns

00:37:15.900 --> 00:37:18.070
is that, actually, that number
has been falling quite a bit.

00:37:18.070 --> 00:37:18.450
But go ahead.

00:37:18.450 --> 00:37:20.616
SPEAKER 1: So is it a good
thing to encourage people

00:37:20.616 --> 00:37:21.690
to go where the jobs are?

00:37:21.690 --> 00:37:23.670
Or does that risk hollowing
out the communities

00:37:23.670 --> 00:37:25.260
that Andy is talking about?

00:37:25.260 --> 00:37:26.760
ANDY McAFEE: It's
better than trying

00:37:26.760 --> 00:37:28.940
to will those communities
back into existence,

00:37:28.940 --> 00:37:30.420
if that's not going to work.

00:37:30.420 --> 00:37:31.670
ERIK BRYNJOLFSSON: Absolutely.

00:37:31.670 --> 00:37:34.590
I think that one of the
most misguided policies

00:37:34.590 --> 00:37:38.910
is trying to target land or
geography, rather than people.

00:37:38.910 --> 00:37:40.920
What we want to do
is help the people.

00:37:40.920 --> 00:37:44.250
And if we can get them
to match to jobs better,

00:37:44.250 --> 00:37:45.540
matched to work better--

00:37:45.540 --> 00:37:48.370
mobility is one of our
best tools in America.

00:37:48.370 --> 00:37:50.460
As you said, it has
historically been one

00:37:50.460 --> 00:37:52.190
of the most mobile societies.

00:37:52.190 --> 00:37:55.949
It's becoming more and more
stagnated and ossified.

00:37:55.949 --> 00:37:57.990
And that is exactly what
we want to lean against.

00:37:57.990 --> 00:38:00.090
Some of our policy, I
think, is a little backward.

00:38:00.090 --> 00:38:02.349
We have big subsidies
for homeownership--

00:38:02.349 --> 00:38:03.640
which sounds like a good thing.

00:38:03.640 --> 00:38:06.337
But it can lock
people in to a home.

00:38:06.337 --> 00:38:07.920
And there are a lot
of other barriers,

00:38:07.920 --> 00:38:09.480
in terms of land
use and regulation,

00:38:09.480 --> 00:38:11.160
that have made it harder
for people to move.

00:38:11.160 --> 00:38:12.840
And maybe there's
some cultural things,

00:38:12.840 --> 00:38:14.520
as well, as
communities have become

00:38:14.520 --> 00:38:17.940
more Balkanized and stratified.

00:38:17.940 --> 00:38:21.540
So, you know, if
a group of people

00:38:21.540 --> 00:38:24.270
can find better work somewhere
else, I say hey, great.

00:38:24.270 --> 00:38:26.404
Let's find a way to
make it easy for them

00:38:26.404 --> 00:38:27.570
to find that and match them.

00:38:27.570 --> 00:38:29.194
And there are lots
of places in America

00:38:29.194 --> 00:38:30.570
that have a shortage of labor.

00:38:30.570 --> 00:38:32.577
There are other places
that have a surplus.

00:38:32.577 --> 00:38:34.410
You know, whether it's
"go west, young man,"

00:38:34.410 --> 00:38:36.470
or whatever the slogan
is, it's been something

00:38:36.470 --> 00:38:38.430
that's been part of
the DNA of America,

00:38:38.430 --> 00:38:39.780
to be dynamic in that way.

00:38:39.780 --> 00:38:42.360
ANDY McAFEE: So it's
weird that mobility--

00:38:42.360 --> 00:38:44.190
just moving around the
country-- is, again,

00:38:44.190 --> 00:38:45.610
on the decline in America.

00:38:45.610 --> 00:38:47.550
It's I think it's
really hard to see,

00:38:47.550 --> 00:38:50.010
when you sit in either
Cambridge, Massachusetts

00:38:50.010 --> 00:38:51.510
or Silicon Valley--

00:38:51.510 --> 00:38:54.090
but almost any measure
of business dynamism

00:38:54.090 --> 00:38:55.680
that you would care
about is heading

00:38:55.680 --> 00:38:57.138
in the wrong
direction in America--

00:38:57.138 --> 00:38:58.290
and has been for a while.

00:38:58.290 --> 00:38:59.730
ERIK BRYNJOLFSSON: How many
of the people in this room

00:38:59.730 --> 00:39:01.590
were born in Silicon Valley?

00:39:01.590 --> 00:39:02.760
Just kind of curious.

00:39:02.760 --> 00:39:03.590
OK.

00:39:03.590 --> 00:39:05.300
One, two, three-- five hands.

00:39:05.300 --> 00:39:06.050
ANDY McAFEE: Yeah.

00:39:06.050 --> 00:39:07.049
ERIK BRYNJOLFSSON: Yeah.

00:39:07.049 --> 00:39:08.370
So that, you know--

00:39:08.370 --> 00:39:11.110
and it's great that,
not just Silicon Valley,

00:39:11.110 --> 00:39:14.430
but America has been
a magnet for talent.

00:39:14.430 --> 00:39:15.674
And that's part of that.

00:39:15.674 --> 00:39:18.090
I wouldn't call it a secret
sauce, because it's not really

00:39:18.090 --> 00:39:18.630
a secret.

00:39:18.630 --> 00:39:20.910
You know, it attracts the
best and the brightest

00:39:20.910 --> 00:39:21.910
from around the world.

00:39:21.910 --> 00:39:23.993
And one of the things that
really saddens me, just

00:39:23.993 --> 00:39:26.400
to be very specific
to my area, is

00:39:26.400 --> 00:39:28.366
when we get these brilliant
grad students that

00:39:28.366 --> 00:39:29.490
come from other countries--

00:39:29.490 --> 00:39:32.855
China, India, or wherever-- and
then they've finished their PhD

00:39:32.855 --> 00:39:34.980
and they want to stay, and
the government says, no.

00:39:34.980 --> 00:39:35.880
You have to go back.

00:39:35.880 --> 00:39:37.140
We don't want you anymore.

00:39:37.140 --> 00:39:38.700
And they're like, no,
no, we want to stay.

00:39:38.700 --> 00:39:39.575
And they're like, OK.

00:39:39.575 --> 00:39:40.680
Go back, and look.

00:39:40.680 --> 00:39:42.930
I guess I have a cousin
working in Bangalore,

00:39:42.930 --> 00:39:45.360
I guess I'll go work
with him or her.

00:39:45.360 --> 00:39:47.037
And, you know,
eventually they're

00:39:47.037 --> 00:39:48.870
not even going to want
to come here anymore.

00:39:48.870 --> 00:39:50.290
And we'll have to beg them.

00:39:50.290 --> 00:39:54.224
And I think that's bad
for the United States,

00:39:54.224 --> 00:39:55.890
and I think it may
be bad for the world,

00:39:55.890 --> 00:39:59.070
because we're not getting the
optimal allocation of talent

00:39:59.070 --> 00:40:00.279
to where it can create value.

00:40:00.279 --> 00:40:01.861
ANDY McAFEE: And
I'll speak, you know,

00:40:01.861 --> 00:40:03.420
for the home team-- for America.

00:40:03.420 --> 00:40:05.520
This Kafkaesque
nightmare that we've

00:40:05.520 --> 00:40:08.370
created, that we've put in the
way of some of the world's most

00:40:08.370 --> 00:40:09.960
talented and
ambitious people, who

00:40:09.960 --> 00:40:13.105
want to come to this country and
build their lives and careers--

00:40:13.105 --> 00:40:14.730
that's what our
enemies would do to us.

00:40:14.730 --> 00:40:16.055
It makes no sense to me.

00:40:16.055 --> 00:40:17.430
SPEAKER 1: The
majority of people

00:40:17.430 --> 00:40:18.600
working in Silicon
Valley were actually

00:40:18.600 --> 00:40:20.010
born outside the United States.

00:40:20.010 --> 00:40:22.160
So we're working
to improve that.

00:40:22.160 --> 00:40:23.790
Question in front,
and then in back.

00:40:27.414 --> 00:40:29.280
ERIK BRYNJOLFSSON: Oh,
now we've got mics.

00:40:29.280 --> 00:40:30.430
Technology improves.

00:40:30.430 --> 00:40:31.305
AUDIENCE: Technology.

00:40:31.305 --> 00:40:32.340
Wow.

00:40:32.340 --> 00:40:34.770
Coming back to the developing
world for a second,

00:40:34.770 --> 00:40:36.630
you mentioned how
automation may be

00:40:36.630 --> 00:40:39.360
more dangerous in
manufacturing reliant

00:40:39.360 --> 00:40:42.900
countries than in the
United States, of course.

00:40:42.900 --> 00:40:45.900
I wanted your take on what
strategies these countries

00:40:45.900 --> 00:40:48.960
should try and develop
to anticipate that.

00:40:48.960 --> 00:40:50.880
And specifically, if
you think services

00:40:50.880 --> 00:40:52.870
can be an interesting
path for growth.

00:40:52.870 --> 00:40:55.380
And here I wanted to
trade of services.

00:40:55.380 --> 00:40:58.100
I think [INAUDIBLE] are
trading goods, these days.

00:40:58.100 --> 00:40:58.850
ANDY McAFEE: Yeah.

00:40:58.850 --> 00:41:00.380
It's a super tough question.

00:41:00.380 --> 00:41:03.260
Because the path to
prosperity, or the path

00:41:03.260 --> 00:41:05.330
to being a middle class
country, was pretty clear

00:41:05.330 --> 00:41:06.860
in the 20th century.

00:41:06.860 --> 00:41:09.452
And to speak a
little bit bluntly,

00:41:09.452 --> 00:41:10.910
you went through
a sweatshop phase.

00:41:10.910 --> 00:41:13.280
you went through that phase
of heavy industrialization.

00:41:13.280 --> 00:41:15.080
A decent portion
of the population

00:41:15.080 --> 00:41:18.710
worked in manufacturing, in
factories and sweatshops.

00:41:18.710 --> 00:41:20.780
And then, over time, you
developed a more robust

00:41:20.780 --> 00:41:22.850
economy, a more diverse one.

00:41:22.850 --> 00:41:24.560
Civil institutions
came along with that.

00:41:24.560 --> 00:41:26.101
They became pretty
healthy countries.

00:41:26.101 --> 00:41:28.740
We saw that playbook
in the 20th century.

00:41:28.740 --> 00:41:30.590
Danny Roderick is a
really good economist,

00:41:30.590 --> 00:41:32.840
who has documented
that that playbook is

00:41:32.840 --> 00:41:35.960
looking less and less
likely in the 21st century--

00:41:35.960 --> 00:41:39.124
mainly because, we
believe, robots,

00:41:39.124 --> 00:41:40.790
and to a lesser extent,
the fact that we

00:41:40.790 --> 00:41:43.910
have tons of capacity in
countries like America

00:41:43.910 --> 00:41:45.480
and China and Germany.

00:41:45.480 --> 00:41:48.200
So your question, which
I'm really stalling on,

00:41:48.200 --> 00:41:50.030
is what's the new
path to prosperity?

00:41:50.030 --> 00:41:53.450
And the reason I'm stalling is I
don't think it's clear, at all.

00:41:53.450 --> 00:41:56.780
I don't know about the template
for the 21st century path

00:41:56.780 --> 00:41:59.150
to prosperity that
doesn't include either

00:41:59.150 --> 00:42:05.087
a phase of industrialization,
or a resource endowment.

00:42:05.087 --> 00:42:06.420
What you say sounds right to me.

00:42:06.420 --> 00:42:09.200
It has to do with human
capital, and services that can

00:42:09.200 --> 00:42:10.880
be delivered over a distance.

00:42:10.880 --> 00:42:13.260
I don't know the shining
example of that, yet.

00:42:13.260 --> 00:42:16.077
ERIK BRYNJOLFSSON: Well, for
better or worse, unfortunately,

00:42:16.077 --> 00:42:17.660
I think it has to
be a playbook that's

00:42:17.660 --> 00:42:19.951
more and more similar to what
developed countries have.

00:42:19.951 --> 00:42:22.490
Because we could be coming
globally and interconnected,

00:42:22.490 --> 00:42:25.160
which means you have to have
an educated workforce that

00:42:25.160 --> 00:42:29.360
can deliver some kind of
value that's greater than what

00:42:29.360 --> 00:42:30.890
other people are delivering.

00:42:30.890 --> 00:42:33.560
And getting people up to
speed on that is hard.

00:42:33.560 --> 00:42:36.440
There are some
digital tools that

00:42:36.440 --> 00:42:38.960
can speed that process a bit.

00:42:38.960 --> 00:42:40.890
And so that's going
to be part of it.

00:42:40.890 --> 00:42:44.690
There may be options in services
that can help a little bit.

00:42:44.690 --> 00:42:46.840
Personal services
tend to be localized,

00:42:46.840 --> 00:42:49.580
and they are somewhat
insulated from globalization.

00:42:49.580 --> 00:42:53.172
But it's a tough
question, and one

00:42:53.172 --> 00:42:54.630
that I think we
should worry about.

00:42:54.630 --> 00:42:56.421
ANDY McAFEE: The clearest
example, I think,

00:42:56.421 --> 00:42:58.050
is the Indian high tech sector--

00:42:58.050 --> 00:43:00.980
which is a fairly small industry
in a very, very big country.

00:43:00.980 --> 00:43:03.080
So I don't know how
well that scales.

00:43:03.080 --> 00:43:05.870
But my playbook for the 21st
century will be kind of,

00:43:05.870 --> 00:43:07.820
bathe your country
and bandwidth,

00:43:07.820 --> 00:43:10.250
get cheap devices
to the people, help

00:43:10.250 --> 00:43:14.330
point them toward these amazing
educational resources online,

00:43:14.330 --> 00:43:16.280
and entrepreneurs will
find that human capital

00:43:16.280 --> 00:43:17.330
and put it to work.

00:43:17.330 --> 00:43:19.080
That's easy to say,
and really hard to do.

00:43:19.080 --> 00:43:20.538
ERIK BRYNJOLFSSON:
Another example,

00:43:20.538 --> 00:43:23.240
that's a bit like that, is
that burgeoning O-to-O sector

00:43:23.240 --> 00:43:25.760
in places like China--
online-to-offline--

00:43:25.760 --> 00:43:28.610
where these technologies have
allowed lots of entrepreneurs

00:43:28.610 --> 00:43:31.670
to create many, many services.

00:43:31.670 --> 00:43:33.542
New kinds of products
and services that

00:43:33.542 --> 00:43:35.000
wouldn't have been
possible before.

00:43:35.000 --> 00:43:39.345
And so you have an explosion of
small-scale entrepreneurship.

00:43:39.345 --> 00:43:40.220
SPEAKER 1: All right.

00:43:40.220 --> 00:43:41.150
So we're running up on time.

00:43:41.150 --> 00:43:42.390
I see two questions in back.

00:43:42.390 --> 00:43:43.460
Let's do a mini speed round.

00:43:43.460 --> 00:43:45.140
Why don't you both throw
your questions out there,

00:43:45.140 --> 00:43:47.060
and I'll let you
answer them quickly.

00:43:47.060 --> 00:43:48.840
AUDIENCE: OK.

00:43:48.840 --> 00:43:50.690
Well, I was wondering,
when you said

00:43:50.690 --> 00:43:53.600
that there are a lot of
the jobs being created,

00:43:53.600 --> 00:43:58.250
are they manual labor, or are
they different kind of jobs?

00:43:58.250 --> 00:44:01.370
And what do you think the
average person is going

00:44:01.370 --> 00:44:06.980
to do in 30 or 50 years, or
whenever every manual labor is

00:44:06.980 --> 00:44:08.030
fully automated?

00:44:08.030 --> 00:44:10.172
Like, do you have any
thoughts or ideas on that?

00:44:10.172 --> 00:44:10.880
ANDY McAFEE: Yep.

00:44:10.880 --> 00:44:12.680
I'll try to do that
one super quickly.

00:44:12.680 --> 00:44:14.390
The engine of job
creation in America

00:44:14.390 --> 00:44:17.210
has downshifted from
classic middle class jobs

00:44:17.210 --> 00:44:18.530
to lower-middle class jobs.

00:44:18.530 --> 00:44:20.057
They tend to be
service sector jobs.

00:44:20.057 --> 00:44:21.890
They tend to be jobs
that involve doing work

00:44:21.890 --> 00:44:23.310
in the physical world.

00:44:23.310 --> 00:44:26.600
So home health aide, gardener,
short order cook kinds

00:44:26.600 --> 00:44:27.170
of things--

00:44:27.170 --> 00:44:29.600
the robots can't
do those jobs yet.

00:44:29.600 --> 00:44:33.500
Your question is, what
does the world of work

00:44:33.500 --> 00:44:36.950
look like in 30 or 50 years
of continued tech progress?

00:44:36.950 --> 00:44:37.910
I want to be clear--

00:44:37.910 --> 00:44:40.700
I have no idea.

00:44:40.700 --> 00:44:44.510
ERIK BRYNJOLFSSON: Let me
just append to Andy's answer.

00:44:44.510 --> 00:44:46.940
There's a big chunk of growth
at one end of this big kind

00:44:46.940 --> 00:44:48.020
of polarization.

00:44:48.020 --> 00:44:49.670
There's also been
some very high end

00:44:49.670 --> 00:44:50.836
jobs that have been created.

00:44:50.836 --> 00:44:53.290
It's the middle that's been
hollowed out the worst.

00:44:53.290 --> 00:44:54.450
So there's high end
jobs, like the ones

00:44:54.450 --> 00:44:55.866
of the people in
this room-- a lot

00:44:55.866 --> 00:44:59.280
of people who have creative,
technical skills can command

00:44:59.280 --> 00:45:00.030
much higher wages.

00:45:00.030 --> 00:45:02.390
And there's probably no
better time in human history

00:45:02.390 --> 00:45:06.076
to be somebody with those kinds
of skills, or talent, or luck.

00:45:06.076 --> 00:45:07.700
And there's no worse
time to be someone

00:45:07.700 --> 00:45:10.970
with just routine,
middle class skills that

00:45:10.970 --> 00:45:13.607
are increasingly automated.

00:45:13.607 --> 00:45:14.190
SPEAKER 1: OK.

00:45:14.190 --> 00:45:16.100
One last question, in the very
back, that I had promised.

00:45:16.100 --> 00:45:17.060
I'm sorry.

00:45:17.060 --> 00:45:19.190
Please.

00:45:19.190 --> 00:45:22.230
AUDIENCE: I wanted to ask
about labor and capital,

00:45:22.230 --> 00:45:24.620
and how this is affecting--

00:45:24.620 --> 00:45:27.080
so do you think this
trend plays into that?

00:45:27.080 --> 00:45:29.650
Where corporate profits
are at an all-time high,

00:45:29.650 --> 00:45:33.200
and the wage share of the
economy has been dropping?

00:45:33.200 --> 00:45:36.830
And do you think that there is
this u-shaped curve in labor,

00:45:36.830 --> 00:45:39.770
where low-skill jobs are safe,
very high-skill jobs are safe,

00:45:39.770 --> 00:45:43.290
and middle-skill jobs are
kind of taking the fall.

00:45:43.290 --> 00:45:45.680
Or do you think it's like,
all of labor as a whole

00:45:45.680 --> 00:45:48.580
is going to take a fall
compared to the capital

00:45:48.580 --> 00:45:50.034
of the corporate profits?

00:45:50.034 --> 00:45:51.950
ANDY McAFEE: The recent
trend is fairly clear.

00:45:51.950 --> 00:45:54.170
And you pointed it out--
it's increasing share

00:45:54.170 --> 00:45:56.780
of GDP going to capital,
and a decreasing

00:45:56.780 --> 00:45:57.720
share going to labor.

00:45:57.720 --> 00:45:59.361
For a lot of the
post-war decades,

00:45:59.361 --> 00:46:00.860
we thought that
capitalism was going

00:46:00.860 --> 00:46:04.610
to lead to greater
equality of income,

00:46:04.610 --> 00:46:06.140
and of financial outcomes.

00:46:06.140 --> 00:46:07.740
I don't believe that anymore.

00:46:07.740 --> 00:46:09.680
I think that the trend,
like I said earlier,

00:46:09.680 --> 00:46:11.210
is toward concentration.

00:46:11.210 --> 00:46:13.170
There are things we
can do about that.

00:46:13.170 --> 00:46:14.480
It's called redistribution.

00:46:14.480 --> 00:46:16.130
It's called tax and transfer.

00:46:16.130 --> 00:46:17.340
It's called wage subsidy.

00:46:17.340 --> 00:46:20.560
This is not an unsolvable
problem, at all.

00:46:20.560 --> 00:46:24.330
And I'm less bothered about that
problem than some other people.

00:46:24.330 --> 00:46:29.150
But refusing to address it
is the cardinal mistake.

00:46:29.150 --> 00:46:31.250
ERIK BRYNJOLFSSON: And
looking to the future,

00:46:31.250 --> 00:46:32.690
we have to be careful
about just extrapolating

00:46:32.690 --> 00:46:33.794
what happened in the past.

00:46:33.794 --> 00:46:35.960
A lot of what happened in
the past couple of decades

00:46:35.960 --> 00:46:39.410
was the first wave
of computerization--

00:46:39.410 --> 00:46:41.589
automating routine
work, repetitive work.

00:46:41.589 --> 00:46:43.880
Looking forward to what
artificial intelligence can do,

00:46:43.880 --> 00:46:45.710
there are a lot of
other types of tasks--

00:46:45.710 --> 00:46:47.750
someone mentioned manual tasks.

00:46:47.750 --> 00:46:48.980
Some very creative work.

00:46:48.980 --> 00:46:53.660
Last night Vinod was
talking about oncologists

00:46:53.660 --> 00:46:55.560
and radiologists--

00:46:55.560 --> 00:46:57.230
these are very highly paid jobs.

00:46:57.230 --> 00:46:59.000
So we may see a
different thing going on.

00:46:59.000 --> 00:47:01.410
I think the only sure thing
is that the pace of change

00:47:01.410 --> 00:47:03.090
is increasing.

00:47:03.090 --> 00:47:05.130
And we need to have a
lot more flexibility.

00:47:05.130 --> 00:47:08.540
We need to be able to sense and
respond, and be active in how

00:47:08.540 --> 00:47:11.180
we do that, and not just sit
back passively, thinking,

00:47:11.180 --> 00:47:12.560
well, I hope it
works out for us.

00:47:12.560 --> 00:47:15.530
Because we think there's a
lot of things that we can do--

00:47:15.530 --> 00:47:18.620
as individuals, as
organizations, as a society--

00:47:18.620 --> 00:47:20.780
to help shape the path
we're going towards.

00:47:20.780 --> 00:47:22.610
And if we do this
right, this is going

00:47:22.610 --> 00:47:25.430
to be the best thing that's
ever happened to humanity.

00:47:25.430 --> 00:47:27.860
We're going to have a lot
more wealth, a lot less need

00:47:27.860 --> 00:47:28.449
for work.

00:47:28.449 --> 00:47:29.990
We're going to have
healthier people.

00:47:29.990 --> 00:47:32.210
But there's absolutely
no guarantee

00:47:32.210 --> 00:47:34.140
that we will hit on all
of those dimensions.

00:47:34.140 --> 00:47:37.040
It's quite possible we could
have a much more dystopian

00:47:37.040 --> 00:47:39.680
scenario, where there's a
tremendous concentration

00:47:39.680 --> 00:47:43.127
of wealth-- and other outcomes
that we aren't as happy with.

00:47:43.127 --> 00:47:45.210
But ultimately, it's not
the choice of technology.

00:47:45.210 --> 00:47:47.820
It's going to be our
choices that determine that.

00:47:47.820 --> 00:47:49.970
And the reason we wrote
these books was to help

00:47:49.970 --> 00:47:52.550
provide a little bit of guidance
on what some of our options

00:47:52.550 --> 00:47:53.120
are.

00:47:53.120 --> 00:47:54.680
And then we have to
apply our values,

00:47:54.680 --> 00:47:56.490
and see if we want to
go in that direction.

00:47:56.490 --> 00:47:57.880
ANDY McAFEE: This is
the headline to end on,

00:47:57.880 --> 00:47:58.820
and this is awesome.

00:47:58.820 --> 00:48:02.602
Overall human prosperity is
about to increase even faster

00:48:02.602 --> 00:48:03.560
than it has been doing.

00:48:03.560 --> 00:48:05.270
We're heading into
a different chapter.

00:48:05.270 --> 00:48:08.930
If we blow the distribution,
the sharing of that prosperity--

00:48:08.930 --> 00:48:10.170
shame on us.

00:48:10.170 --> 00:48:11.660
SPEAKER 1: Andy, Erik.

00:48:11.660 --> 00:48:15.177
"Machine, Platform, Crowd"-- a
new guide to the 21st century.

00:48:15.177 --> 00:48:16.010
Thank you very much.

00:48:16.010 --> 00:48:16.270
[APPLAUSE]

00:48:16.270 --> 00:48:17.811
ERIK BRYNJOLFSSON:
Ken, thanks a lot.

00:48:17.811 --> 00:48:18.970
Thank you all for coming.

00:48:18.970 --> 00:48:21.120
ANDY McAFEE: We appreciate it.

