WEBVTT
Kind: captions
Language: en

00:00:00.370 --> 00:00:02.680
Okay, Michael, so we've gotten through that quiz and you see

00:00:02.680 --> 00:00:06.090
that Bayes' rule actually gives you some information. It actually helps

00:00:06.090 --> 00:00:08.860
you make a decision. So I'm going to suggest that, that whole

00:00:08.860 --> 00:00:12.090
exercise we went through was actually our way of walking through

00:00:12.090 --> 00:00:16.790
an algorithm. So here's a particular algorithm that follows from what

00:00:16.790 --> 00:00:18.220
we just did. And let me just write that down for

00:00:18.220 --> 00:00:20.670
you. All right, so here's the algorithm, Michael, so it's very

00:00:20.670 --> 00:00:25.590
simple. For each H in H, that is, each candidate hypothesis

00:00:25.590 --> 00:00:27.090
in our in our hypothesis space, simply

00:00:27.090 --> 00:00:30.170
calculate the probability of that hypothesis given

00:00:30.170 --> 00:00:33.570
the data W which we know is equal to the probability of the data given

00:00:33.570 --> 00:00:36.210
that hypothesis times the prior probability of

00:00:36.210 --> 00:00:38.300
the hypothesis, divided by the probability of

00:00:38.300 --> 00:00:40.490
the data. And then simply output whichever

00:00:40.490 --> 00:00:43.630
hypothesis has maximum probability. Does that make sense?

00:00:43.630 --> 00:00:44.350
&gt;&gt; Yeah.

00:00:44.350 --> 00:00:46.560
&gt;&gt; Okay, so I do want to point out that since

00:00:46.560 --> 00:00:50.710
all we care about is computing the argmax, as before,

00:00:50.710 --> 00:00:53.164
we don't actually ever have to compute that little bit

00:00:53.164 --> 00:00:56.150
so, and that's a good thing because we don't always know

00:00:56.150 --> 00:00:58.500
what the prior probability on the data is, so we

00:00:58.500 --> 00:01:02.170
can ignore it for the purposes of finding the maximal hypothesis.

00:01:02.170 --> 00:01:05.910
&gt;&gt; So the place you removed it from, it seems like that's not actually valid,

00:01:05.910 --> 00:01:08.880
because it's not the case that the probability of h given d equals, it's the

00:01:08.880 --> 00:01:11.800
probability of d given h times the probability of h. It just means that we

00:01:11.800 --> 00:01:13.340
don't care what the probability is when

00:01:13.340 --> 00:01:15.630
we go to compute the argmax. That's right,

00:01:15.630 --> 00:01:20.970
so, in fact, it's probably better to say that I'm going to approximate

00:01:20.970 --> 00:01:23.000
the probability hypothesis given the data

00:01:23.000 --> 00:01:24.660
by just calculating the probability of the

00:01:24.660 --> 00:01:28.540
data given the hypothesis times the probability of the hypothesis and just go

00:01:28.540 --> 00:01:30.560
ahead and ignore the denominator. Precissely

00:01:30.560 --> 00:01:33.300
because it doesn't change hte maximal age.

00:01:33.300 --> 00:01:35.100
&gt;&gt; Yeah, so it's, it's nice that that goes away.

00:01:35.100 --> 00:01:38.220
&gt;&gt; Right, because it's hard to know, often what

00:01:38.220 --> 00:01:40.440
the prior, what the prior probability over the data is.

00:01:40.440 --> 00:01:40.940
&gt;&gt; It would

00:01:40.940 --> 00:01:42.840
be nice if we didn't have to worry about the other one, either.

00:01:42.840 --> 00:01:44.120
&gt;&gt; Which other one?

00:01:44.120 --> 00:01:46.710
&gt;&gt; The probability of h, where's that coming from?

00:01:46.710 --> 00:01:48.200
&gt;&gt; right, so where does that come from? So that's

00:01:48.200 --> 00:01:51.980
a deep philosophical question. Sometimes it's just something you believe, and

00:01:51.980 --> 00:01:54.540
you can write down. And sometimes it's a little harder. And

00:01:54.540 --> 00:01:56.820
that's actually good that you bring that up. When we compute,

00:01:59.480 --> 00:02:02.080
our probabilities this way so it's actually got a name,

00:02:02.080 --> 00:02:05.360
it's the MAP or the maximum a posteriori hypothesis and that

00:02:05.360 --> 00:02:08.180
makes sense, it's the biggest posterior given all of your

00:02:08.180 --> 00:02:11.140
priors. But you're right Michael that often it's just as hard

00:02:11.140 --> 00:02:14.470
to say anything particular about your prior over the hypothesis

00:02:14.470 --> 00:02:16.740
as it is to say something about your prior of the

00:02:16.740 --> 00:02:21.040
data and, so it is very common to drop that. And,

00:02:21.040 --> 00:02:25.500
in dropping that, we're actually computing the argmax over the probability

00:02:25.500 --> 00:02:27.800
of the data given the hypothesis. And,

00:02:27.800 --> 00:02:31.870
that is known as the maximum likelihood hypothesis.

00:02:31.870 --> 00:02:34.750
&gt;&gt; I guess you can't call it the maximum

00:02:34.750 --> 00:02:37.410
A priori hypothesis, because then it would also be MAP.

00:02:37.410 --> 00:02:40.990
&gt;&gt; Exactly, although I've never thought about that before.

00:02:40.990 --> 00:02:42.570
By the way, just just to be clear, we're

00:02:42.570 --> 00:02:45.170
not really dropping this, in this case, what we

00:02:45.170 --> 00:02:50.790
really said, is that, our prior belief is that

00:02:50.790 --> 00:02:53.550
all hypotheses are equally likely. So we

00:02:53.550 --> 00:02:56.050
have a uniform prior that is, the probability

00:02:56.050 --> 00:02:58.730
of any given hypothesis is exactly the same

00:02:58.730 --> 00:03:00.980
as the probability as any other given hypothesis.

00:03:00.980 --> 00:03:02.820
&gt;&gt; I see, so you're saying if, if we assume

00:03:02.820 --> 00:03:06.140
that they all are equally likely, then, the choice of

00:03:06.140 --> 00:03:09.070
hypothesis doesn't change that term at all, the p of

00:03:09.070 --> 00:03:11.540
h term, so it really is equivalent to just ignoring it.

00:03:11.540 --> 00:03:13.190
&gt;&gt; Exactly, in some constant, we don't even have

00:03:13.190 --> 00:03:15.701
to know what the constant is. But whatever it is,

00:03:15.701 --> 00:03:18.298
it's the same everywhere and therefor it doesn't affect

00:03:18.298 --> 00:03:21.660
the other terms or, in particular, affect the argmax computation.

00:03:21.660 --> 00:03:23.420
&gt;&gt; So that's actually pretty cool right?

00:03:23.420 --> 00:03:24.990
Once you think about what we just did.

00:03:24.990 --> 00:03:26.656
We just took something that was very

00:03:26.656 --> 00:03:29.900
hard. Computing the probability of a hypothesis given

00:03:29.900 --> 00:03:31.970
the data and turned it into something

00:03:31.970 --> 00:03:35.670
much easier that is... Computing the probability of

00:03:35.670 --> 00:03:37.610
you seeing the data labels given a particular

00:03:37.610 --> 00:03:40.740
hypothesis and it turns out that those are

00:03:40.740 --> 00:03:42.970
effectively the same thing if you don't have

00:03:42.970 --> 00:03:46.330
a strong prior. So that's really cool, so we're

00:03:46.330 --> 00:03:48.980
done right? We now know how to find

00:03:48.980 --> 00:03:51.620
the best hypothesis You're just finding the most likely

00:03:51.620 --> 00:03:53.920
hypothesis or the most probable one and that

00:03:53.920 --> 00:03:55.460
turns out to be the same thing as just

00:03:55.460 --> 00:03:58.010
simply finding the hypothesis that best matches the

00:03:58.010 --> 00:04:01.021
data. We're done its all, its easy. Everythings good.

00:04:01.021 --> 00:04:03.212
&gt;&gt; So,the math seems very nice and pretty and easy

00:04:03.212 --> 00:04:06.050
but is isn't it hiding a lot of work to actually

00:04:06.050 --> 00:04:07.450
do these computations?

00:04:07.450 --> 00:04:09.610
&gt;&gt; Well, sure well well look you know

00:04:09.610 --> 00:04:11.400
how to do multiplication that's pretty easy right?

00:04:11.400 --> 00:04:11.500
&gt;&gt; [LAUGH].

00:04:11.500 --> 00:04:13.500
&gt;&gt; So I guess the only hard part

00:04:13.500 --> 00:04:16.440
is we have to look at every single hypothesis.

00:04:16.440 --> 00:04:18.990
&gt;&gt; Yeah, that's just a slight, little, you know, issue.

00:04:18.990 --> 00:04:22.390
&gt;&gt; So, mathematically meaningful, but computationally questionable.

00:04:22.390 --> 00:04:22.990
&gt;&gt; Hm.

00:04:22.990 --> 00:04:27.450
&gt;&gt; So, the big point there, is that it's not practical. Well, unless the

00:04:27.450 --> 00:04:31.100
number of hypotheses is really, really small. But as we know, a lot of

00:04:31.100 --> 00:04:34.820
the hypotheses spaces that we care about, like, for example, linear separators,

00:04:34.820 --> 00:04:37.860
are actually infinite. And so it's going to be very difficult to use

00:04:37.860 --> 00:04:40.960
this algorithm directly. But despite all that, I think that there's still

00:04:40.960 --> 00:04:43.490
something important that we get out of thinking about it this way

00:04:43.490 --> 00:04:45.680
in just the same way that we get something important out of

00:04:45.680 --> 00:04:48.750
thinking about vc dimension. Even if we're not entirely sure how to

00:04:48.750 --> 00:04:52.220
compute it in some particular case. This really gives us a gold

00:04:52.220 --> 00:04:54.090
standard, right? We have an algorithm,

00:04:54.090 --> 00:04:56.250
at least a conceptual algorithm, that tells

00:04:56.250 --> 00:04:59.160
us what the right thing to do would be if we're

00:04:59.160 --> 00:05:02.900
capable of computing it directly. So, that's good because we can

00:05:02.900 --> 00:05:05.890
maybe prove things about this and compare results that we get

00:05:05.890 --> 00:05:09.500
from some Real live algorithms to what we might expect to

00:05:09.500 --> 00:05:12.320
get but also it turns out it's pretty cute because it

00:05:12.320 --> 00:05:15.670
helps us to say other things about what it is we

00:05:15.670 --> 00:05:17.630
actually expect to learn. And I'm going to give you a couple

00:05:17.630 --> 00:05:21.050
examples of those just to sort of prove my point, sound good?

00:05:21.050 --> 00:05:21.830
&gt;&gt; Yeah.

00:05:21.830 --> 00:05:22.340
&gt;&gt; Okay.

