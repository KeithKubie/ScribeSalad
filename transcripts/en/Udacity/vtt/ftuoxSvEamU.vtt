WEBVTT
Kind: captions
Language: en

00:00:00.290 --> 00:00:03.140
Let's think about what
these things imply.

00:00:03.140 --> 00:00:07.210
So the value of a state, well under
the Bellman equation is this and

00:00:07.210 --> 00:00:10.690
nothing scary here right this
is all stuff that you know.

00:00:10.690 --> 00:00:12.330
So now, the next thing we're
going to do is we're going to say,

00:00:12.330 --> 00:00:16.340
well the value of the state that we
end up in since we're in average land.

00:00:16.340 --> 00:00:20.930
We can write that as the sum over
all the anchor points of how related

00:00:20.930 --> 00:00:25.150
this state s prime is or what the wait
is between s prime and that basis point.

00:00:25.150 --> 00:00:27.398
And then whatever value we set for
the basis point.

00:00:27.398 --> 00:00:28.190
&gt;&gt; Sure
&gt;&gt; All right so

00:00:28.190 --> 00:00:31.070
here it is in the context of
the whole Bellman equation.

00:00:31.070 --> 00:00:34.770
So this is cool to write I just
changed the order of summation and

00:00:34.770 --> 00:00:36.660
kind of regrouped a little bit.

00:00:36.660 --> 00:00:41.680
So now, we've got max over actions
the reward of that action for

00:00:41.680 --> 00:00:42.600
the state that we started.

00:00:42.600 --> 00:00:45.900
And now, we're summing now
instead of over all next states,

00:00:45.900 --> 00:00:48.080
we're stepping over
just the basis points.

00:00:48.080 --> 00:00:48.880
Sure.

00:00:48.880 --> 00:00:53.220
We're multiplying some quantity
time's the value of the basis point.

00:00:53.220 --> 00:00:55.310
What can we say about this value here.

00:00:55.310 --> 00:00:58.150
If we write it let's say like this.

00:00:58.150 --> 00:01:03.140
So we can write this as some function
T of the state, the action and

00:01:03.140 --> 00:01:04.450
the basis point.

00:01:04.450 --> 00:01:07.490
And the sum over next states is kind
of already built in here, right?

00:01:07.490 --> 00:01:08.390
&gt;&gt; Yes, yes, yes.

00:01:08.390 --> 00:01:10.410
&gt;&gt; [LAUGH] I gave this a name.

00:01:10.410 --> 00:01:15.650
I called it T prime, because i wanted
you to see a connection between this and

00:01:15.650 --> 00:01:16.760
transition functions.

00:01:16.760 --> 00:01:18.650
So, how is this like
a transition function?

00:01:18.650 --> 00:01:21.710
&gt;&gt; Well, choose a state,
you take an action.

00:01:21.710 --> 00:01:23.790
What basis functions
will you go to next?

00:01:23.790 --> 00:01:24.690
&gt;&gt; Right which you don't.

00:01:24.690 --> 00:01:27.650
The actual MDP,
you don't go to the basis function.

00:01:27.650 --> 00:01:30.070
But the point is that

00:01:30.070 --> 00:01:34.070
this acts like a transition function
in that it's nonnegative, right?

00:01:35.430 --> 00:01:38.290
And, when you sum up over all SBs,

00:01:38.290 --> 00:01:40.970
over all the anchor points,
it sums up to one.

00:01:40.970 --> 00:01:42.520
&gt;&gt; RIght.
&gt;&gt; Why does it sum up to one?

00:01:42.520 --> 00:01:47.140
Because this is a convex combination,
and this is a convex combination, and

00:01:47.140 --> 00:01:49.740
so, when we combine them,
we get a convex combination.

00:01:49.740 --> 00:01:51.920
We could do the algebra for that,
but i don't think we need to.

00:01:51.920 --> 00:01:55.180
And so
it acts just like a transition function.

00:01:55.180 --> 00:01:58.550
So we can actually fold
the function approximate to itself.

00:01:58.550 --> 00:02:00.490
Into the transitions.

00:02:00.490 --> 00:02:03.410
And all we get at
the end of it is an MVP.

00:02:03.410 --> 00:02:06.920
So why does it actually do
the right thing because MVP's have

00:02:06.920 --> 00:02:09.180
a well defined unique value function and

00:02:09.180 --> 00:02:13.080
that you can find it using things
like Q learning in value iteration.

00:02:13.080 --> 00:02:14.220
&gt;&gt; That's beautiful.

00:02:14.220 --> 00:02:15.370
&gt;&gt; Isn't it, though?

00:02:15.370 --> 00:02:18.430
So, what we do is, we end up with
something that is actually a reasonable

00:02:18.430 --> 00:02:19.600
function approximator.

00:02:19.600 --> 00:02:22.870
It's taking the value of some state,
S prime, and

00:02:22.870 --> 00:02:25.160
writing it as a combination
of other states.

00:02:25.160 --> 00:02:27.770
And then we just we turn it into,
over series of steps,

00:02:27.770 --> 00:02:32.410
into a new Markov decision process over
a smaller set of states, specifically,

00:02:32.410 --> 00:02:33.820
over just the basis states.

00:02:33.820 --> 00:02:37.430
And at the end of the day We know that
this is going to be well behaved,

00:02:37.430 --> 00:02:39.110
we know that it's going to
approximate things.

00:02:39.110 --> 00:02:41.460
Well, we don't know that it's going to
approximate things reasonably but

00:02:41.460 --> 00:02:45.690
at least without blowing up
in a convergent sort of way.

00:02:45.690 --> 00:02:47.220
Because we know a lot
of stuff about MDPs.

00:02:47.220 --> 00:02:48.830
&gt;&gt; That's kind of insane.

00:02:48.830 --> 00:02:50.600
&gt;&gt; It's very clever.

00:02:50.600 --> 00:02:51.610
&gt;&gt; No no, it's very very clever.

00:02:51.610 --> 00:02:54.580
So if I were going to make
too fine of a point on it,

00:02:54.580 --> 00:02:58.910
what would I end up with aA kind of
interpretation here might think the MDP

00:02:58.910 --> 00:03:02.380
are moving over is sort of
basis state to basis state?

00:03:02.380 --> 00:03:03.890
&gt;&gt; Yeah,
I think that's a good question so

00:03:03.890 --> 00:03:08.350
it's as if we're going from a state
to some next state which is S prime.

00:03:08.350 --> 00:03:12.380
And then, from there we're making
an additional mini transition

00:03:12.380 --> 00:03:16.270
to the basis states the SBs
&gt;&gt; And the weights

00:03:16.270 --> 00:03:18.800
on these put these probabilities
are the combination weights,

00:03:18.800 --> 00:03:21.770
are the convex combination weights.

00:03:21.770 --> 00:03:24.060
Convex combination weights
look a lot like probabilities.

00:03:24.060 --> 00:03:24.830
&gt;&gt; Right, they do.

00:03:24.830 --> 00:03:28.350
&gt;&gt; So it's as if each time we make
a transition to a next state s prime

00:03:28.350 --> 00:03:32.830
we make an additional little transition
to each of the basis states, and

00:03:32.830 --> 00:03:33.860
from there we continue.

00:03:33.860 --> 00:03:38.200
And so, we can actually solve out What
the value function is over everything

00:03:38.200 --> 00:03:41.740
by just solving the MDP
over the basis states.

00:03:41.740 --> 00:03:43.340
And then, we can extrapolate that or

00:03:43.340 --> 00:03:45.050
interpolate that to
anything that we want.

00:03:45.050 --> 00:03:45.870
&gt;&gt; I love it.
And it makes some

00:03:45.870 --> 00:03:48.640
sense because the basis states
sort of represent a set of states.

00:03:48.640 --> 00:03:51.210
So really what you're talking about is
you're averaging over the set of states

00:03:51.210 --> 00:03:53.050
that kind of get aliased
through the basis functions.

00:03:53.050 --> 00:03:54.100
I think that's beautiful.

00:03:54.100 --> 00:03:54.690
&gt;&gt; Yeah, exactly.

00:03:54.690 --> 00:04:00.140
So yeah, we fold our function
approximater into the MDP itself.

00:04:00.140 --> 00:04:00.670
&gt;&gt; Done.

00:04:00.670 --> 00:04:02.580
&gt;&gt; Very cool.
So, the good news is,

00:04:02.580 --> 00:04:05.710
here's a value function approximator
that is very well behaved.

00:04:05.710 --> 00:04:07.720
The bad news is,
it's hard to do some things with it,

00:04:07.720 --> 00:04:10.815
because value functions aren't
always very well represented.

00:04:10.815 --> 00:04:15.725
As average or type things there's
often kind of weird cliffs and

00:04:15.725 --> 00:04:19.334
so forth in the value function
that are not well captured by just

00:04:19.334 --> 00:04:20.714
smoothing everything out.

00:04:20.714 --> 00:04:22.885
But still this is a really nice idea.

00:04:22.885 --> 00:04:23.485
&gt;&gt; Beautiful.

