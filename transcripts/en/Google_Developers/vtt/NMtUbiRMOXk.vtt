WEBVTT
Kind: captions
Language: en

00:00:08.095 --> 00:00:09.220
FRANCESC CAMPOY FLORES: Hi.

00:00:09.220 --> 00:00:12.740
I am Francesc Campoy, and I'm
a developer programs engineer

00:00:12.740 --> 00:00:15.140
for the Go team here at
Google in Mountain View.

00:00:15.140 --> 00:00:16.762
And today I'm with Kurt.

00:00:16.762 --> 00:00:17.470
KURT SCHWEHR: Hi.

00:00:17.470 --> 00:00:18.500
I'm Kurt Schwehr.

00:00:18.500 --> 00:00:21.790
I'm on the Google
Maps Ocean's team.

00:00:21.790 --> 00:00:25.110
And I work on ocean data with
all sorts of different things.

00:00:25.110 --> 00:00:27.640
But here today I'd like to
talk to you about ships.

00:00:27.640 --> 00:00:30.000
And we like to look at all
the ships in the world.

00:00:30.000 --> 00:00:31.280
There's a lot of them.

00:00:31.280 --> 00:00:34.450
And what we have
is a visualization

00:00:34.450 --> 00:00:37.382
here that shows you a
wide range of what's

00:00:37.382 --> 00:00:39.340
out there, about all
these boats moving around.

00:00:39.340 --> 00:00:40.173
They're pretty cool.

00:00:40.173 --> 00:00:41.610
Lots of fun stuff going on.

00:00:41.610 --> 00:00:44.080
But what this really is,
is a nice visualization

00:00:44.080 --> 00:00:46.900
of the economic activity
of our entire world.

00:00:46.900 --> 00:00:49.810
So this is really a global
scale problem to look at,

00:00:49.810 --> 00:00:52.690
and what we've got are each
individual ship making up

00:00:52.690 --> 00:00:55.100
just a small fraction
of this visualization.

00:00:55.100 --> 00:00:58.125
The ship starts off with a
red at the newest point where

00:00:58.125 --> 00:01:01.140
it is, and then over time it
fades out to a blue color,

00:01:01.140 --> 00:01:03.860
and it gives you this nice,
streaky pattern that shows you

00:01:03.860 --> 00:01:06.583
where the shipping lanes are,
where the people run around

00:01:06.583 --> 00:01:10.625
in circles fishing, where people
are doing all of that business

00:01:10.625 --> 00:01:11.970
that they do on ships.

00:01:11.970 --> 00:01:13.920
It really is an
indicator of what's

00:01:13.920 --> 00:01:16.250
going on in each
particular environment.

00:01:16.250 --> 00:01:18.790
And what we're getting
here is the messages

00:01:18.790 --> 00:01:21.240
are actually being broadcast
by the ships themselves.

00:01:21.240 --> 00:01:24.230
And we're picking this up with
a satellite going over the top.

00:01:24.230 --> 00:01:26.850
And a company called
SpaceQuest has been kind enough

00:01:26.850 --> 00:01:29.050
to lend us the data to
do this example with,

00:01:29.050 --> 00:01:31.216
and they're actually
collecting these ship positions

00:01:31.216 --> 00:01:33.730
as they fly over, and they're
reporting them back to us.

00:01:33.730 --> 00:01:35.960
And what we'd like to do
is, get millions of points

00:01:35.960 --> 00:01:38.230
together and look at the
overall patterns and trends

00:01:38.230 --> 00:01:41.250
to see what's happening
in our world here.

00:01:41.250 --> 00:01:43.525
And it's a lot of
data, and if you just

00:01:43.525 --> 00:01:45.775
work on a small laptop in
your own little environment,

00:01:45.775 --> 00:01:48.540
it gets very challenging,
and your laptop

00:01:48.540 --> 00:01:50.360
melts under the
load of all this,

00:01:50.360 --> 00:01:51.980
and you don't get very far.

00:01:51.980 --> 00:01:54.060
So now, we're looking at
this great visualization

00:01:54.060 --> 00:01:55.930
here, Francesc,
that we've built.

00:01:55.930 --> 00:01:57.513
How did we get here
to the point where

00:01:57.513 --> 00:01:59.450
we have this amazing
ship traffic going on?

00:01:59.450 --> 00:02:02.280
How do we build something
to get from that raw data

00:02:02.280 --> 00:02:03.382
to this visualization?

00:02:03.382 --> 00:02:04.590
FRANCESC CAMPOY FLORES: Yeah.

00:02:04.590 --> 00:02:07.980
So that's actually a pretty
complex problem to solve,

00:02:07.980 --> 00:02:12.170
and we ended up creating
this diagram here

00:02:12.170 --> 00:02:15.030
where we can see all of
the different companies

00:02:15.030 --> 00:02:16.490
that we ended up using.

00:02:16.490 --> 00:02:22.370
So we have the ships sending
data through their GPS, the GPS

00:02:22.370 --> 00:02:26.040
data, and then we
get that huge amount

00:02:26.040 --> 00:02:29.420
of data, lots of points
for lots of ships.

00:02:29.420 --> 00:02:31.570
And we want to extract
information off that.

00:02:31.570 --> 00:02:35.650
We decided to use BigQuery
because you can actually

00:02:35.650 --> 00:02:39.250
extract information really
easily, and iterate very fast,

00:02:39.250 --> 00:02:43.740
and just have fun, and
find cool data about it

00:02:43.740 --> 00:02:45.440
from huge amount of data.

00:02:45.440 --> 00:02:48.750
But we had a little
problem-- that we

00:02:48.750 --> 00:02:52.110
had to upload something
which is made of columns.

00:02:52.110 --> 00:02:55.070
And actually the data
we get from the ships

00:02:55.070 --> 00:02:59.140
is not at all made of columns or
at least doesn't look like it.

00:02:59.140 --> 00:03:00.650
It's pretty cryptic.

00:03:00.650 --> 00:03:02.480
So we had to decode it first.

00:03:02.480 --> 00:03:04.177
So how did we do that?

00:03:04.177 --> 00:03:05.010
You actually did it.

00:03:05.010 --> 00:03:05.801
KURT SCHWEHR: Yeah.

00:03:05.801 --> 00:03:09.010
So definitely, it's not
just encoded, it's armored.

00:03:09.010 --> 00:03:11.010
So this data comes
out in a way that

00:03:11.010 --> 00:03:14.290
is completely unreadable
to a normal human being.

00:03:14.290 --> 00:03:17.010
But I had a C++ library that
I wrote over the last couple

00:03:17.010 --> 00:03:19.710
years that actually just takes
that data and converts it

00:03:19.710 --> 00:03:24.719
into a CSV column format
that's pretty manageable.

00:03:24.719 --> 00:03:26.510
And then I wrote a
little Python wraparound

00:03:26.510 --> 00:03:28.510
that to make it a little
bit easier to call.

00:03:28.510 --> 00:03:30.570
That's great, but
you can't run that

00:03:30.570 --> 00:03:33.230
on an App Engine, which is
where we're trying to get to.

00:03:33.230 --> 00:03:36.070
So what we did instead was we
brought up a Compute Engine

00:03:36.070 --> 00:03:38.480
instance with a little
Linux virtual machine.

00:03:38.480 --> 00:03:41.610
And right there, we can run
the C++ code that I wrote,

00:03:41.610 --> 00:03:44.160
and it then takes this
sort of cron job style,

00:03:44.160 --> 00:03:46.340
takes data in from
cloud storage,

00:03:46.340 --> 00:03:50.170
turns into a nice column
formatted text format,

00:03:50.170 --> 00:03:52.860
and then loads it right
back into cloud storage

00:03:52.860 --> 00:03:54.610
into a different bucket
where [INAUDIBLE].

00:03:54.610 --> 00:03:57.700
FRANCESC CAMPOY FLORES: So it
ends up a CSV file pretty much

00:03:57.700 --> 00:03:58.200
on--

00:03:58.200 --> 00:03:58.480
KURT SCHWEHR: Exactly.

00:03:58.480 --> 00:04:00.146
FRANCESC CAMPOY FLORES:
--cloud storage.

00:04:00.146 --> 00:04:04.270
And then once we have that,
loading that data into BigQuery

00:04:04.270 --> 00:04:05.520
it's really simple.

00:04:05.520 --> 00:04:08.740
Just have to do a REST
code and just say, OK.

00:04:08.740 --> 00:04:09.840
There's this new file.

00:04:09.840 --> 00:04:13.970
I want you to load the data set.

00:04:13.970 --> 00:04:17.510
And now we can actually start
having fun and iterating really

00:04:17.510 --> 00:04:19.760
fast and finding cool data.

00:04:19.760 --> 00:04:24.260
So we could find faulty
GPS signals or ships that

00:04:24.260 --> 00:04:26.945
were fishing and all of
that really-- not really

00:04:26.945 --> 00:04:29.570
simply, because this is actually
a pretty complicated problem--

00:04:29.570 --> 00:04:30.740
but very fast.

00:04:30.740 --> 00:04:34.840
You can actually just
write your query, run it,

00:04:34.840 --> 00:04:38.590
and in a matter of seconds
you can get that response.

00:04:38.590 --> 00:04:41.630
Then to show them the
map, what we had to do

00:04:41.630 --> 00:04:45.360
is getting that
through App Engine app

00:04:45.360 --> 00:04:47.730
and encode it somehow.

00:04:47.730 --> 00:04:50.020
So we decided to
encode it in binary.

00:04:50.020 --> 00:04:53.430
But that means that every
single time that there was query

00:04:53.430 --> 00:04:56.315
coming from the browser
the App Engine app

00:04:56.315 --> 00:04:59.150
could query BigQuery,
get that information,

00:04:59.150 --> 00:05:00.775
and encode it and
send it to a browser.

00:05:00.775 --> 00:05:02.649
KURT SCHWEHR: So that
was pretty fast, right?

00:05:02.649 --> 00:05:04.400
FRANCESC CAMPOY
FLORES: Well, that's

00:05:04.400 --> 00:05:07.310
around in the tens of
seconds every single time.

00:05:07.310 --> 00:05:09.270
BigQuery is really
fast actually,

00:05:09.270 --> 00:05:10.270
when you think about it.

00:05:10.270 --> 00:05:12.100
Considering the huge amount
of data that we have,

00:05:12.100 --> 00:05:13.850
tens of seconds is
actually pretty good.

00:05:13.850 --> 00:05:17.580
But it's definitely not fast
enough for a web application,

00:05:17.580 --> 00:05:18.200
definitely.

00:05:18.200 --> 00:05:24.230
So that's why we added this
intermediary storage, which

00:05:24.230 --> 00:05:25.140
is Datastore.

00:05:25.140 --> 00:05:29.430
So regularly the App Engine
app could go to BigQuery,

00:05:29.430 --> 00:05:32.590
up turn the latest data,
and store it in Datastore.

00:05:32.590 --> 00:05:34.950
And now every time that
you get a query, instead

00:05:34.950 --> 00:05:36.930
of going to BigQuery,
we could just

00:05:36.930 --> 00:05:38.750
get the data from Datastore.

00:05:38.750 --> 00:05:40.025
So that makes it faster.

00:05:40.025 --> 00:05:41.770
KURT SCHWEHR: But
that's not fast enough?

00:05:41.770 --> 00:05:42.840
I can see that.

00:05:42.840 --> 00:05:43.660
Really?

00:05:43.660 --> 00:05:44.790
You don't think
that's fast enough.

00:05:44.790 --> 00:05:45.915
FRANCESC CAMPOY FLORES: No.

00:05:45.915 --> 00:05:47.310
It's fast, but not fast enough.

00:05:47.310 --> 00:05:49.390
It's going to take
less than 1 second,

00:05:49.390 --> 00:05:51.390
but still around 1 second.

00:05:51.390 --> 00:05:54.040
And it's taking long
because actually when

00:05:54.040 --> 00:05:56.600
we get the data from
Datastore, we still

00:05:56.600 --> 00:05:59.110
have to encode it
into binary format,

00:05:59.110 --> 00:06:01.730
and actually that's
slightly complicated to do.

00:06:01.730 --> 00:06:05.800
So what we decided to do
on top of the Datastore

00:06:05.800 --> 00:06:09.590
is we get data from Datastore,
we encode it into binary,

00:06:09.590 --> 00:06:11.940
and then we store
it in memcache.

00:06:11.940 --> 00:06:14.690
And now every time that we
have a query, what happens--

00:06:14.690 --> 00:06:15.080
KURT SCHWEHR: Is that fast?

00:06:15.080 --> 00:06:16.954
FRANCESC CAMPOY FLORES:
--is we get directly,

00:06:16.954 --> 00:06:20.510
we get just a blob of
binary data from memcache,

00:06:20.510 --> 00:06:22.940
and we send it back through
the HTTP connection.

00:06:22.940 --> 00:06:24.000
KURT SCHWEHR: Now that's
fast enough, right?

00:06:24.000 --> 00:06:24.990
FRANCESC CAMPOY FLORES:
Now, that's fast enough.

00:06:24.990 --> 00:06:25.489
Yes.

00:06:25.489 --> 00:06:27.482
KURT SCHWEHR: So
that's great, but why

00:06:27.482 --> 00:06:28.940
did you have to go
with binary data

00:06:28.940 --> 00:06:31.795
when most other web applications
you use just an ASCII JSON?

00:06:31.795 --> 00:06:32.420
FRANCESC CAMPOY FLORES: Yes.

00:06:32.420 --> 00:06:33.660
So that's a good question.

00:06:33.660 --> 00:06:35.340
We started JSON, actually.

00:06:35.340 --> 00:06:39.170
And we realized that we had
this problem where we're

00:06:39.170 --> 00:06:42.582
sending a lot of numbers,
latitude, longitude,

00:06:42.582 --> 00:06:44.040
everything are
numbers pretty much.

00:06:44.040 --> 00:06:47.121
And we're sending
them in JSON, which

00:06:47.121 --> 00:06:48.370
means that we have the number.

00:06:48.370 --> 00:06:51.410
We encode it in
JSON, therefore text.

00:06:51.410 --> 00:06:54.130
And then it gets to the
browser, and the browser

00:06:54.130 --> 00:06:57.130
has to decode it from
text back to a number.

00:06:57.130 --> 00:07:00.730
And actually that decoding
encoding, it takes time.

00:07:00.730 --> 00:07:01.800
It takes CPU time.

00:07:01.800 --> 00:07:06.450
So what we did was just decide
to encode everything in binary

00:07:06.450 --> 00:07:12.540
and use binary arrays
in JavaScript, which

00:07:12.540 --> 00:07:15.690
means that now we can actually
get that binary code that we

00:07:15.690 --> 00:07:20.290
get directly from the HTTP
response, put it into memory,

00:07:20.290 --> 00:07:23.525
and just interpret it as
a binary array, an array

00:07:23.525 --> 00:07:27.260
of floats in our case, and
just use that directly as data.

00:07:27.260 --> 00:07:29.490
So you skip that encoding
and decoding part.

00:07:29.490 --> 00:07:30.580
KURT SCHWEHR: And this
is why we have millions

00:07:30.580 --> 00:07:32.060
of points in the
browser so quickly.

00:07:32.060 --> 00:07:32.410
FRANCESC CAMPOY FLORES: Yes.

00:07:32.410 --> 00:07:35.130
That's why you can actually
go through the application

00:07:35.130 --> 00:07:38.970
and just pan around
or shift and decide,

00:07:38.970 --> 00:07:40.850
I want to see the
data for this day,

00:07:40.850 --> 00:07:42.670
and you won't have to
wait for 10 seconds.

00:07:42.670 --> 00:07:45.317
This day will just appear
automatically instantly.

00:07:45.317 --> 00:07:46.150
KURT SCHWEHR: Great.

00:07:46.150 --> 00:07:47.858
FRANCESC CAMPOY FLORES:
What was the part

00:07:47.858 --> 00:07:50.160
that you learned-- what
was the most interesting

00:07:50.160 --> 00:07:51.375
for you out of this project?

00:07:51.375 --> 00:07:53.541
KURT SCHWEHR: For me, this
was my first time working

00:07:53.541 --> 00:07:55.560
in the cloud kind
of architecture,

00:07:55.560 --> 00:07:58.830
and I was worried
that I would have

00:07:58.830 --> 00:08:00.360
to wait for my team
members to work

00:08:00.360 --> 00:08:02.160
on different parts
of the system.

00:08:02.160 --> 00:08:05.880
And the neat thing is that I
just got to work on my pieces

00:08:05.880 --> 00:08:08.420
and all these systems
let me decouple and work

00:08:08.420 --> 00:08:10.710
in my particular favorite
language, which is Python.

00:08:10.710 --> 00:08:12.150
I'm most comfortable there.

00:08:12.150 --> 00:08:15.000
While you, for instance, were
in Go, and I didn't have to one,

00:08:15.000 --> 00:08:17.454
worry about the fact
you were working in Go,

00:08:17.454 --> 00:08:18.870
and I didn't have
to wait for you.

00:08:18.870 --> 00:08:20.770
So for me that was
pretty exciting.

00:08:20.770 --> 00:08:23.594
How did we pass data back and
forth that made that so easy?

00:08:23.594 --> 00:08:24.760
FRANCESC CAMPOY FLORES: Yes.

00:08:24.760 --> 00:08:28.960
So since we had different
independent components,

00:08:28.960 --> 00:08:34.650
so we had these data loggers
and the data transformation

00:08:34.650 --> 00:08:36.520
and the App Engine
app, and all that.

00:08:36.520 --> 00:08:38.850
We're completely independent
and communicating only

00:08:38.850 --> 00:08:42.650
through Datastore and just
passing the data around

00:08:42.650 --> 00:08:44.400
and using task queues.

00:08:44.400 --> 00:08:48.410
And task queues to let the
other part of the application

00:08:48.410 --> 00:08:51.177
know that there's
something to do about it.

00:08:51.177 --> 00:08:52.760
And that is actually
one of the things

00:08:52.760 --> 00:08:55.190
that I learned and I
discovered that it was really

00:08:55.190 --> 00:08:57.850
powerful that using
task queues, it

00:08:57.850 --> 00:09:01.160
allows you to have a
very robust system pretty

00:09:01.160 --> 00:09:04.130
much without doing much.

00:09:04.130 --> 00:09:07.560
Because you know that you're
going to try something,

00:09:07.560 --> 00:09:09.680
and even if your
program is faulty

00:09:09.680 --> 00:09:14.870
and you have some bugs,
things that happen sometimes,

00:09:14.870 --> 00:09:16.250
you won't lose that data.

00:09:16.250 --> 00:09:20.810
You will actually just fail
and send back a message saying,

00:09:20.810 --> 00:09:21.310
oops.

00:09:21.310 --> 00:09:22.030
Sorry.

00:09:22.030 --> 00:09:24.840
And it will be ultimately
we'll try later on.

00:09:24.840 --> 00:09:26.969
So you know that that
data will never be lost.

00:09:26.969 --> 00:09:28.510
KURT SCHWEHR: So
task queue will pick

00:09:28.510 --> 00:09:29.820
back up when your
code recovers from--

00:09:29.820 --> 00:09:30.986
FRANCESC CAMPOY FLORES: Yes.

00:09:30.986 --> 00:09:34.210
You can, of course, change the
settings to add more backup

00:09:34.210 --> 00:09:35.180
time or whatever.

00:09:35.180 --> 00:09:38.650
But the default, actually we're
using the default settings,

00:09:38.650 --> 00:09:40.650
and it works perfectly for us.

00:09:40.650 --> 00:09:43.900
And then the second part,
for me, well I'm a gopher,

00:09:43.900 --> 00:09:46.740
so of course, I use
Go for App Engine.

00:09:46.740 --> 00:09:51.330
And I found out that using
Go on the App Engine part

00:09:51.330 --> 00:09:53.150
was actually a big
win because most

00:09:53.150 --> 00:09:55.130
of the time on the
cloud, what you're doing

00:09:55.130 --> 00:09:59.800
is waiting for things to happen
or doing a lot of things all

00:09:59.800 --> 00:10:01.610
of a sudden very, very fast.

00:10:01.610 --> 00:10:04.040
So the fact that you can
actually do all of those things

00:10:04.040 --> 00:10:07.040
very fast at the same
using concurrency,

00:10:07.040 --> 00:10:08.760
it's something really important.

00:10:08.760 --> 00:10:12.520
And doing it in Go is
actually really easy.

00:10:12.520 --> 00:10:15.770
You just have to add some Go
routines and different channels

00:10:15.770 --> 00:10:18.100
and four or five
lines of code, you

00:10:18.100 --> 00:10:19.600
get something that
runs concurrently

00:10:19.600 --> 00:10:21.535
and you get really
big win in efficiency.

00:10:21.535 --> 00:10:22.910
KURT SCHWEHR: This
is what let us

00:10:22.910 --> 00:10:25.420
scale when we start loading
huge blocks of stuff

00:10:25.420 --> 00:10:25.700
in multiple [? browsers. ?]

00:10:25.700 --> 00:10:25.960
FRANCESC CAMPOY FLORES: Yeah.

00:10:25.960 --> 00:10:28.376
Especially when you have to
load a lot of different things

00:10:28.376 --> 00:10:31.280
from Datastore, the fact
that you can load all of them

00:10:31.280 --> 00:10:36.810
at the same time and just wait
for the slowest one, that's

00:10:36.810 --> 00:10:39.080
a big win rather than
doing sequentially.

00:10:39.080 --> 00:10:43.530
And if you have 1,000, well, you
have to wait for 1,000 times n,

00:10:43.530 --> 00:10:44.030
so, yeah.

00:10:44.030 --> 00:10:45.738
KURT SCHWEHR: So this
is pretty exciting.

00:10:45.738 --> 00:10:47.500
So now that we have
this new architecture,

00:10:47.500 --> 00:10:49.291
what do we need
to do next to this

00:10:49.291 --> 00:10:51.040
or where are we going
to be going with it?

00:10:51.040 --> 00:10:51.670
FRANCESC CAMPOY FLORES: Yeah.

00:10:51.670 --> 00:10:54.110
So I think that the architecture
is pretty much ready

00:10:54.110 --> 00:10:55.870
to be used.

00:10:55.870 --> 00:10:59.830
And so the cool
thing now is that we

00:10:59.830 --> 00:11:03.082
could consider using this
same architecture for very

00:11:03.082 --> 00:11:04.040
different applications.

00:11:04.040 --> 00:11:09.400
So the same way you are actually
showing here ships on a map,

00:11:09.400 --> 00:11:13.280
you could also use it to
track whales in the ocean,

00:11:13.280 --> 00:11:15.590
or you could use
it to track cars

00:11:15.590 --> 00:11:18.130
on the highways, or anything
you can think about.

00:11:18.130 --> 00:11:20.260
Or even not related to
Maps, you could actually

00:11:20.260 --> 00:11:22.790
use the same
architecture as some way

00:11:22.790 --> 00:11:25.300
to filter huge amounts
of data and extract

00:11:25.300 --> 00:11:29.440
some information that is
something really small,

00:11:29.440 --> 00:11:31.480
and it's like very
valuable information

00:11:31.480 --> 00:11:33.580
out of a huge amount of data.

00:11:33.580 --> 00:11:34.350
So yeah.

00:11:34.350 --> 00:11:37.150
I think that the
next step is just

00:11:37.150 --> 00:11:39.350
find out what's the
new cool application

00:11:39.350 --> 00:11:41.360
to go with this architecture.

00:11:41.360 --> 00:11:43.166
KURT SCHWEHR: Great.

00:11:43.166 --> 00:11:46.195
FRANCESC CAMPOY
FLORES: So also, if you

00:11:46.195 --> 00:11:49.370
are interested in knowing
more about this architecture

00:11:49.370 --> 00:11:52.980
and how we built it,
and what we did with it,

00:11:52.980 --> 00:11:56.240
we gave a talk in the
last edition of Google I/O

00:11:56.240 --> 00:12:00.150
here in San Francisco, and
you can find the link here

00:12:00.150 --> 00:12:01.360
in the description.

00:12:01.360 --> 00:12:03.300
So look at it.

00:12:03.300 --> 00:12:05.075
Have a look and enjoy it.

00:12:05.075 --> 00:12:06.740
KURT SCHWEHR: And
just so you know,

00:12:06.740 --> 00:12:10.194
we've released the decoding
library, LIB IAS for the ship

00:12:10.194 --> 00:12:12.360
messages if you are interested
in playing with that,

00:12:12.360 --> 00:12:14.110
and we hope to be
working through the rest

00:12:14.110 --> 00:12:15.902
of open sourcing of
our little [INAUDIBLE].

00:12:15.902 --> 00:12:17.110
FRANCESC CAMPOY FLORES: Yeah.

00:12:17.110 --> 00:12:19.330
We we'll definitely open
source on the App Engine app

00:12:19.330 --> 00:12:22.390
code, and probably the data
logger, and all the rest.

00:12:22.390 --> 00:12:25.520
So thanks for watching, and
keep an eye on Google Developers

00:12:25.520 --> 00:12:28.930
Live channel for more
videos about our projects

00:12:28.930 --> 00:12:31.670
using different Google products.

