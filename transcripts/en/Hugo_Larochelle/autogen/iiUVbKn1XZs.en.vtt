WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.270
 in this capsule we will see 

00:00:01.439 --> 00:00:07.950
 the iteration algorithm by vara then one 

00:00:06.270 --> 00:00:09.450
 saw in a previous capsule the 

00:00:07.950 --> 00:00:12.080
 equations of herself that we 

00:00:09.450 --> 00:00:16.230
 identify a condition 

00:00:12.080 --> 00:00:18.900
 on the values ​​associated with the plan 

00:00:16.230 --> 00:00:21.869
 optimum for a decision process 

00:00:18.900 --> 00:00:24.300
 mark comes to give and we mentioned 

00:00:21.869 --> 00:00:26.580
 which existed two algorithms that are going 

00:00:24.300 --> 00:00:29.789
 exploit this condition there for in 

00:00:26.580 --> 00:00:31.019
 get to find the timmer plan ago 

00:00:29.789 --> 00:00:34.110
 a first a great we see now 

00:00:31.019 --> 00:00:36.420
 left rations by values ​​where one says by 

00:00:34.110 --> 00:00:38.430
 value or English you is the origin 

00:00:36.420 --> 00:00:41.129
 because at each iteration it's the 

00:00:38.430 --> 00:00:43.530
 values ​​of the estimated plan we are going to put to 

00:00:41.129 --> 00:00:46.890
 day in autumn another pace and that 

00:00:43.530 --> 00:00:48.719
 sees in a subsequent capsule that 

00:00:46.890 --> 00:00:51.629
 is the iterations by policy or 

00:00:48.719 --> 00:00:53.670
 rather than rice tea or change the 

00:00:51.629 --> 00:00:55.469
 Plastinated values ​​at each iteration 

00:00:53.670 --> 00:00:58.170
 will rather be in charge of politics 

00:00:55.469 --> 00:01:00.449
 so is it now now let's start 

00:00:58.170 --> 00:01:05.600
 by the val nutrition algorithm we 

00:01:00.449 --> 00:01:08.159
 iteration gets the voice if the algorithm 

00:01:05.600 --> 00:01:10.500
 which is really not really understood in 

00:01:08.159 --> 00:01:12.570
 do so we'll start with 

00:01:10.500 --> 00:01:15.060
 initialize our estimate of the 

00:01:12.570 --> 00:01:18.360
 plan value at 0 for all states 

00:01:15.060 --> 00:01:19.860
 possible s is what we will do is 

00:01:18.360 --> 00:01:22.140
 we go on the ground and we want to repeat 

00:01:19.860 --> 00:01:24.180
 until our estimate of the 

00:01:22.140 --> 00:01:26.159
 value does not change so the 

00:01:24.180 --> 00:01:28.590
 changes in the destination either 

00:01:26.159 --> 00:01:30.270
 negligible and at each iteration this 

00:01:28.590 --> 00:01:34.409
 what we will do is that for each 

00:01:30.270 --> 00:01:38.220
 state s will calculate a new one will 

00:01:34.409 --> 00:01:39.990
 update our estimated value of 

00:01:38.220 --> 00:01:42.240
 planty evil that I'm going to call some 

00:01:39.990 --> 00:01:45.299
 bonuses this is the new value from 

00:01:42.240 --> 00:01:47.880
 of current estimates v of the 

00:01:45.299 --> 00:01:50.000
 value of the optimal plan is what we are going 

00:01:47.880 --> 00:01:54.240
 to make a fact we will just apply 

00:01:50.000 --> 00:01:55.740
 the right hand side of the equations of 

00:01:54.240 --> 00:01:57.210
 bleating so it's like we're taking 

00:01:55.740 --> 00:01:59.299
 the equation of bleating we were doing 

00:01:57.210 --> 00:02:02.070
 an assignment from right to left 

00:01:59.299 --> 00:02:04.380
 in the field like that until that 

00:02:02.070 --> 00:02:05.969
 converge so we recognize here this 

00:02:04.380 --> 00:02:07.590
 part there it's the right part of 

00:02:05.969 --> 00:02:09.410
 amman equations then we compute them 

00:02:07.590 --> 00:02:12.569
 but from our in their life 

00:02:09.410 --> 00:02:13.319
 current and it gives us a new 

00:02:12.569 --> 00:02:17.909
 value 

00:02:13.319 --> 00:02:18.980
 for winter for the optimal plan we 

00:02:17.909 --> 00:02:21.180
 call for bonuses 

00:02:18.980 --> 00:02:23.489
 so after making this assignment 

00:02:21.180 --> 00:02:26.879
 there for all states s I check is 

00:02:23.489 --> 00:02:29.939
 what my previous life value and my 

00:02:26.879 --> 00:02:31.920
 new value of the premiums are very 

00:02:29.939 --> 00:02:33.930
 different for all states when I 

00:02:31.920 --> 00:02:35.519
 calculates the difference in absolute value 

00:02:33.930 --> 00:02:37.260
 right now on all the steps 

00:02:35.519 --> 00:02:39.180
 possible if it is smaller than 

00:02:37.260 --> 00:02:42.290
 certain tolerance that must not but that 

00:02:39.180 --> 00:02:46.349
 I have to specify I stop 

00:02:42.290 --> 00:02:49.260
 and if not I'll use bonuses 

00:02:46.349 --> 00:02:51.150
 like and to my new value v estimated 

00:02:49.260 --> 00:02:54.680
 for my plan and I start again so I 

00:02:51.150 --> 00:02:57.719
 will update my values 

00:02:54.680 --> 00:02:59.669
 calculating a table v premium 

00:02:57.719 --> 00:03:02.549
 I check if bonuses have changed 

00:02:59.669 --> 00:03:05.760
 a lot compared to life if that's the 

00:03:02.549 --> 00:03:10.590
 case it becomes repressed if not I stop and 

00:03:05.760 --> 00:03:13.439
 I manage to converge and so that allowed me 

00:03:10.590 --> 00:03:16.049
 to converge to the virtual value 

00:03:13.439 --> 00:03:16.349
 planty badly under the conditions of 

00:03:16.049 --> 00:03:19.139
 tomorrow 

00:03:16.349 --> 00:03:21.540
 and finally to get what is the 

00:03:19.139 --> 00:03:23.280
 plan team by associating it with what we do 

00:03:21.540 --> 00:03:25.199
 that's what I described previously 

00:03:23.280 --> 00:03:27.060
 that is, my plan is going 

00:03:25.199 --> 00:03:30.479
 match to take the action to who has 

00:03:27.060 --> 00:03:34.439
 the best future reward hope 

00:03:30.479 --> 00:03:37.079
 given my estimate v of the 

00:03:34.439 --> 00:03:38.759
 optima plan value so what that 

00:03:37.079 --> 00:03:40.919
 does it mean that my plan pi2 is this 

00:03:38.759 --> 00:03:44.069
 that I will return with the result 

00:03:40.919 --> 00:03:46.650
 of my to heal that will match a 

00:03:44.069 --> 00:03:50.060
 pitiful is they returning the action 

00:03:46.650 --> 00:03:54.120
 who is the most valuable 

00:03:50.060 --> 00:03:57.209
 so the biggest estimates of the 

00:03:54.120 --> 00:04:03.409
 future reward hope who is so in 

00:03:57.209 --> 00:04:07.759
 is the sum of dvds premium weighted by 

00:04:03.409 --> 00:04:09.930
 if you are at your premium 

00:04:07.759 --> 00:04:12.090
 lure that will be chosen the one who steals 

00:04:09.930 --> 00:04:15.930
 the greatest value of that term there 

00:04:12.090 --> 00:04:17.549
 also the future reward hope to see 

00:04:15.930 --> 00:04:20.609
 an example of running the algorithm 

00:04:17.549 --> 00:04:23.370
 iteration by values ​​will start with 

00:04:20.609 --> 00:04:25.349
 define a mdp a decision process 

00:04:23.370 --> 00:04:26.050
 brand is very simple or even three 

00:04:25.349 --> 00:04:29.800
 states 

00:04:26.050 --> 00:04:33.190
 01 16 2 and our goal is going to be 

00:04:29.800 --> 00:04:34.750
 to reach state s2 and we have them 

00:04:33.190 --> 00:04:36.490
 transitions here that are labeled so 

00:04:34.750 --> 00:04:39.490
 if I'm at zero and I take 

00:04:36.490 --> 00:04:43.000
 action at a general of 0.21 gas quoted at 

00:04:39.490 --> 00:04:44.919
 0 an incoming producer 0.8 is a 

00:04:43.000 --> 00:04:47.259
 on the other hand if I had taken the action to 

00:04:44.919 --> 00:04:50.800
 two managers profit and one to stay at 

00:04:47.259 --> 00:04:53.639
 0-0 to go to soissons or s21 

00:04:50.800 --> 00:04:56.020
 so I'm guaranteed to stay at 0 

00:04:53.639 --> 00:04:58.990
 now is this so I take 

00:04:56.020 --> 00:05:04.690
 the action odh two young people colleter 1 

00:04:58.990 --> 00:05:05.229
 tomorrow to come back as 0 and 1 0 to the park 0 

00:05:04.690 --> 00:05:07.240
 to go elsewhere 

00:05:05.229 --> 00:05:09.550
 if I had taken the action instead 

00:05:07.240 --> 00:05:12.520
 three days a profit of 1.2 get me to 

00:05:09.550 --> 00:05:15.099
 state s2 then finally she is in 

00:05:12.520 --> 00:05:18.490
 two days before a probability of 1 of 

00:05:15.099 --> 00:05:20.110
 recite s2 cij projection to 5 

00:05:18.490 --> 00:05:25.479
 and if I take the place the action to 

00:05:20.110 --> 00:05:27.039
 four kinds a priority one of hazards and 

00:05:25.479 --> 00:05:29.500
 in this case the possible actions to 

00:05:27.039 --> 00:05:32.020
 from scratch it is at a1 and a2 the 

00:05:29.500 --> 00:05:33.819
 possible actions from s1 co2 and 

00:05:32.020 --> 00:05:39.789
 to troyes then possible actions to 

00:05:33.819 --> 00:05:41.139
 from s2c to 5 and to 4 for 

00:05:39.789 --> 00:05:43.750
 represent my goal that is to achieve 

00:05:41.139 --> 00:05:45.340
 is hard I'm going to express it in the form 

00:05:43.750 --> 00:05:46.419
 of a function to reward what I 

00:05:45.340 --> 00:05:48.130
 have to do in a mdp 

00:05:46.419 --> 00:05:52.870
 so in fact I gave recopa 

00:05:48.130 --> 00:05:55.900
 reward 2-0 as0 and s1 but she 

00:05:52.870 --> 00:05:58.120
 positive reward of 1.6 I am to be 

00:05:55.900 --> 00:06:00.490
 ok so clearly he sees an incentive 

00:05:58.120 --> 00:06:03.490
 clear to get to it is to stay 

00:06:00.490 --> 00:06:05.710
 s2 as long as possible 

00:06:03.490 --> 00:06:08.199
 the rewards factor while 

00:06:05.710 --> 00:06:10.960
 the second we will use its 0.5 y 

00:06:08.199 --> 00:06:12.279
 define more clearly here then in the 

00:06:10.960 --> 00:06:13.750
 swimming I'm going to use in rest 

00:06:12.279 --> 00:06:16.509
 of the example to simplify I'm going 

00:06:13.750 --> 00:06:19.840
 noted m the reward of the vice and if 

00:06:16.509 --> 00:06:26.259
 as being small harry then the value 

00:06:19.840 --> 00:06:27.940
 estimated from for the optimal plan that I 

00:06:26.259 --> 00:06:31.800
 am looking for the state and 

00:06:27.940 --> 00:06:31.800
 if I will note it as being v 

00:06:34.270 --> 00:06:41.550
 then first step we initialize the 

00:06:36.820 --> 00:06:41.550
 values ​​that génissiat read all to zero 

00:06:42.750 --> 00:06:50.860
 and then I update my values ​​of 

00:06:46.090 --> 00:06:54.040
 life by calculating the right theme in 

00:06:50.860 --> 00:06:57.930
 the bellemene equation from my 

00:06:54.040 --> 00:07:01.450
 current estimates of 0.2 v1 and v2 

00:06:57.930 --> 00:07:04.120
 so this here fits the theme of 

00:07:01.450 --> 00:07:05.950
 right i have the rewards in zero plus 

00:07:04.120 --> 00:07:10.500
 the factor d second time the maximum 

00:07:05.950 --> 00:07:13.480
 between doing the action has one that fits 

00:07:10.500 --> 00:07:16.540
 therefore to vegetables products of 0.2 remaining 

00:07:13.480 --> 00:07:19.570
 to stay as0 so in this case this 

00:07:16.540 --> 00:07:23.770
 would that correspond to seeing 0.2 times the 

00:07:19.570 --> 00:07:27.640
 value 1 0 plus a priority of 0.8 

00:07:23.770 --> 00:07:31.500
 staying in agen so over 0.8 times the 

00:07:27.640 --> 00:07:34.210
 value of associated with the state is healthy 

00:07:31.500 --> 00:07:36.190
 the other possible action it would be smells 

00:07:34.210 --> 00:07:39.370
 and in this case I dream Promethean of 

00:07:36.190 --> 00:07:42.610
 stay at 0 so I'll just have it here 

00:07:39.370 --> 00:07:44.980
 the heroes and the subject replaces 0 and 

00:07:42.610 --> 00:07:48.550
 ensuring by their present value which 0 

00:07:44.980 --> 00:07:51.760
 I get 100.5 0-0 match that gives me 

00:07:48.550 --> 00:07:56.860
 10 0 if I did it had one now 

00:07:51.760 --> 00:08:00.760
 the reward in v1 and zero plus zero 

00:07:56.860 --> 00:08:04.180
 point 5 times the maximum between the action at 

00:08:00.760 --> 00:08:07.840
 2 which corresponds with 21.2 to get me to 

00:08:04.180 --> 00:08:10.780
 she 0 so the maximum between will aim 

00:08:07.840 --> 00:08:14.740
 so this is once the value of the state 

00:08:10.780 --> 00:08:18.310
 associated with the action at 2 which is zero so 

00:08:14.740 --> 00:08:21.070
 the value of heroes so the center guy 

00:08:18.310 --> 00:08:22.870
 action room at 2 and the action at three that 

00:08:21.070 --> 00:08:26.860
 associates a probability of 1.2 make me 

00:08:22.870 --> 00:08:29.140
 at s2 so the maximum of zero and v2 

00:08:26.860 --> 00:08:32.130
 again I replace on the 

00:08:29.140 --> 00:08:35.740
 some sum gives and finally for 

00:08:32.130 --> 00:08:37.660
 the state s2 the value are you 2 

00:08:35.740 --> 00:08:40.690
 both i'm going to update her as 

00:08:37.660 --> 00:08:42.700
 being the reward an s2 which is 1 

00:08:40.690 --> 00:08:43.720
 so we remember s2 that's my goal I 

00:08:42.700 --> 00:08:46.540
 will give rewards 

00:08:43.720 --> 00:08:47.260
 I associate a reward of 1 l and s 

00:08:46.540 --> 00:08:50.890
 2 

00:08:47.260 --> 00:08:54.820
 plus 0.5 times the maximum between the action 

00:08:50.890 --> 00:08:59.230
 at 4 which would correspond to a s1 so the 

00:08:54.820 --> 00:09:02.770
 maximum in v1 and the action to five have a 

00:08:59.230 --> 00:09:07.420
 part of the hours to stay as2 so the 

00:09:02.770 --> 00:09:09.190
 maximum v1 and v2 I'm replaced that me 

00:09:07.420 --> 00:09:10.570
 gives new value for b2 which will be 

00:09:09.190 --> 00:09:12.760
 more than zero but Cuba is equal 

00:09:10.570 --> 00:09:14.830
 now at the hospital had to invest 

00:09:12.760 --> 00:09:21.160
 we can change but the value of v2 has 

00:09:14.830 --> 00:09:26.530
 changed now we restore the 

00:09:21.160 --> 00:09:27.730
 new values ​​of v10 v1 v2 so we 

00:09:26.530 --> 00:09:30.100
 mark all that has changed is the 

00:09:27.730 --> 00:09:31.060
 value transition products 

00:09:30.100 --> 00:09:33.820
 stay the same 

00:09:31.060 --> 00:09:38.050
 and I did my calculations what gives me 

00:09:33.820 --> 00:09:40.240
 new values ​​here 0.5 1.5 but if 

00:09:38.050 --> 00:09:43.720
 it stays at zero so now I have some 

00:09:40.240 --> 00:09:49.890
 new values ​​d 00 points its part 11 

00:09:43.720 --> 00:09:49.890
 020 had built 0.5 v2 of the guys at 1.5 

00:09:50.770 --> 00:09:54.340
 I do a third iteration I 

00:09:52.120 --> 00:09:57.430
 replaces right by the news 

00:09:54.340 --> 00:09:59.740
 values ​​2-0 v1 v2 which gives me 

00:09:57.430 --> 00:10:08.350
 new values ​​for heroes of 0.2 

00:09:59.740 --> 00:10:10.390
 for v12 0.75 for v2 of 1.75 and 

00:10:08.350 --> 00:10:12.040
 now suppose we stop after 

00:10:10.390 --> 00:10:14.320
 these three iterations there ie that 

00:10:12.040 --> 00:10:16.960
 suppose my tolerance rate but 

00:10:14.320 --> 00:10:18.790
 indicated that the changes of both 

00:10:16.960 --> 00:10:21.280
 iterations was not big enough for 

00:10:18.790 --> 00:10:23.680
 justify an operation and that I stop 

00:10:21.280 --> 00:10:25.600
 to estimate values ​​now for 

00:10:23.680 --> 00:10:29.290
 get my plan I will use my 

00:10:25.600 --> 00:10:30.730
 values ​​of life 0 v1 educated for 

00:10:29.290 --> 00:10:34.080
 estimate my policy 

00:10:30.730 --> 00:10:39.250
 an optimal policy in this case 

00:10:34.080 --> 00:10:43.420
 then 2 0 that would be the action so the hac 

00:10:39.250 --> 00:10:44.350
 max between the future reward hope to 

00:10:43.420 --> 00:10:49.090
 take the action 

00:10:44.350 --> 00:10:53.560
 men 1 again one who with a share of 

00:10:49.090 --> 00:10:57.560
 0.2 to get me to stay at 0 

00:10:53.560 --> 00:11:01.460
 part 0.8 will take me 0 to dethrone 

00:10:57.560 --> 00:11:04.190
 a care that I'm going this way this is where 

00:11:01.460 --> 00:11:06.920
 my estimate of the future reward 

00:11:04.190 --> 00:11:08.690
 hope if I take the action to 1 then 

00:11:06.920 --> 00:11:11.060
 my estimate of the reward on 

00:11:08.690 --> 00:11:14.990
 species of the action pole at 2 this is the 

00:11:11.060 --> 00:11:16.820
 estimated value bone 0 so the heroes 

00:11:14.990 --> 00:11:19.670
 why because with a quality a 

00:11:16.820 --> 00:11:23.300
 game stays at zero if I take the action 

00:11:19.670 --> 00:11:27.040
 by two so if I do the calculations I 

00:11:23.300 --> 00:11:30.050
 replaces with my estimate 2 0 and 

00:11:27.040 --> 00:11:30.589
 v1 then if i just saw talk about 

00:11:30.050 --> 00:11:32.839
 transition 

00:11:30.589 --> 00:11:36.380
 it turns out that this term here is 

00:11:32.839 --> 00:11:38.480
 greater than 0.2 which is the estimate 

00:11:36.380 --> 00:11:41.060
 of future reward hope if I 

00:11:38.480 --> 00:11:44.470
 take action two so the tarmac 

00:11:41.060 --> 00:11:47.990
 it's the action that maximizes 

00:11:44.470 --> 00:11:49.760
 rewards future hope six years I 

00:11:47.990 --> 00:11:52.339
 can not be the same as the same calculation for 

00:11:49.760 --> 00:11:54.380
 s1 and s2 I take the action that maximizes 

00:11:52.339 --> 00:11:56.150
 the future recompose hope and when 

00:11:54.380 --> 00:11:59.080
 it would give me the action at 3 for the 

00:11:56.150 --> 00:12:03.589
 rate us 1 and 1.5 for the Hebrew state 

00:11:59.080 --> 00:12:05.210
 and so we mac logically what they 

00:12:03.589 --> 00:12:06.980
 found was that as0 of the 

00:12:05.210 --> 00:12:08.030
 production has one that brings me back the most 

00:12:06.980 --> 00:12:09.770
 possible to the right 

00:12:08.030 --> 00:12:11.450
 is it a game to take the action back to 

00:12:09.770 --> 00:12:14.330
 you who once again delight me the most 

00:12:11.450 --> 00:12:16.160
 possible right to s 2 ps2 but 

00:12:14.330 --> 00:12:18.010
 I try to stay as 2 taking 

00:12:16.160 --> 00:12:20.960
 the action of 5 

00:12:18.010 --> 00:12:23.210
 it is actually that if we had 

00:12:20.960 --> 00:12:25.880
 continued to make the hang of iterations 

00:12:23.210 --> 00:12:27.020
 unfortunately we would not have changed the 

00:12:25.880 --> 00:12:28.970
 political ie we would have 

00:12:27.020 --> 00:12:31.690
 converge towards place so it's beautiful 

00:12:28.970 --> 00:12:34.460
 and well the final plan even if we actually 

00:12:31.690 --> 00:12:37.330
 an estimate that is far from 

00:12:34.460 --> 00:12:40.010
 accurate for the value of the optimal plan 

00:12:37.330 --> 00:12:41.660
 so we are first 

00:12:40.010 --> 00:12:43.760
 iteration by value you in 

00:12:41.660 --> 00:12:46.790
 disadvantage we want is that in fact we 

00:12:43.760 --> 00:12:49.430
 at this threshold to be determined on when is this 

00:12:46.790 --> 00:12:51.860
 to stop estimating the value of the plan 

00:12:49.430 --> 00:12:54.980
 optimal and so that could have been that 

00:12:51.860 --> 00:12:56.240
 would have determined when we decided 

00:12:54.980 --> 00:12:57.560
 to stop too much water and that finally 

00:12:56.240 --> 00:13:00.080
 have not yet converged on the 

00:12:57.560 --> 00:13:01.459
 optimal plan so really to have the 

00:13:00.080 --> 00:13:03.350
 guaranteed to find the small male plane 

00:13:01.459 --> 00:13:04.690
 you actually have to key yourself up 

00:13:03.350 --> 00:13:07.470
 convergent 

00:13:04.690 --> 00:13:09.840
 but in practice actually 

00:13:07.470 --> 00:13:11.700
 these posts so when up 

00:13:09.840 --> 00:13:13.440
 convergence through to convergence of 

00:13:11.700 --> 00:13:14.850
 values ​​but in fact it's possible to 

00:13:13.440 --> 00:13:17.460
 find the plan the title well the sale 

00:13:14.850 --> 00:13:20.190
 have accurately estimated the 

00:13:17.460 --> 00:13:22.650
 values ​​associated with the optimum plan so 

00:13:20.190 --> 00:13:28.560
 that's the iteration algorithm by 

00:13:22.650 --> 00:13:31.110
 value or balue and orrit and finally 

00:13:28.560 --> 00:13:34.980
 I will add that if you want to see a 

00:13:31.110 --> 00:13:36.600
 example a little more interesting you 

00:13:34.980 --> 00:13:39.690
 invite to see this address here where 

00:13:36.600 --> 00:13:41.280
 there is a small demonstration of 

00:13:39.690 --> 00:13:43.230
 the iteration algorithm by value 

00:13:41.280 --> 00:13:48.050
 in an example with a little more of 

00:13:43.230 --> 00:13:48.050
 tops then a little more complex 

