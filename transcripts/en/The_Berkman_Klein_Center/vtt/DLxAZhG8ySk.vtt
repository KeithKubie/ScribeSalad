WEBVTT
Kind: captions
Language: en

00:00:04.705 --> 00:00:07.551
I'm mathematical biologist here at Harvard

00:00:07.551 --> 00:00:08.720
and before I begin my talk

00:00:08.720 --> 00:00:11.375
I would like to tell you what a mathematical biologist is.

00:00:11.375 --> 00:00:13.931
And it's best explained with a short story.

00:00:13.931 --> 00:00:16.514
So there is a shepherd and a flock of sheep

00:00:16.514 --> 00:00:17.974
and a man comes by it says:

00:00:17.974 --> 00:00:20.740
"If I guess the correct number of sheep in your flock

00:00:20.740 --> 00:00:21.728
can I have one?"

00:00:21.728 --> 00:00:23.487
And the shepherd says: "OK, try it."

00:00:23.487 --> 00:00:25.940
So the man looks and says: "83."

00:00:25.940 --> 00:00:27.902
And the shepherd is completely amazed,

00:00:27.902 --> 00:00:29.200
because it is right number.

00:00:29.200 --> 00:00:31.824
So the man picks up a sheep and wants to walk away.

00:00:31.824 --> 00:00:32.878
The shepherd says:

00:00:32.878 --> 00:00:34.700
"Hang on. If I guess you profession

00:00:34.700 --> 00:00:35.994
can I have my sheep back?"

00:00:36.535 --> 00:00:37.562
"OK, try it."

00:00:37.562 --> 00:00:39.502
"You must be a mathematical biologist."

00:00:39.502 --> 00:00:40.660
"How did you know?"

00:00:40.660 --> 00:00:42.501
"Because you picked up my dog!"

00:00:45.780 --> 00:00:49.163
So in my field it's important to get the numbers right.

00:00:49.634 --> 00:00:52.793
And today I'm talking about the evolution of cooperation.

00:00:53.088 --> 00:00:54.604
Which is a very big topic

00:00:54.604 --> 00:00:57.928
because Darwinian evolution based on natural selection,

00:00:57.928 --> 00:01:00.749
and natural selection is a struggling for competition.

00:01:00.749 --> 00:01:03.025
And in such a struggling the question would be:

00:01:03.025 --> 00:01:05.141
"Why would we ever help anybody else?

00:01:05.141 --> 00:01:08.686
Why should I reduce my own fitness, so to say,

00:01:08.686 --> 00:01:10.768
to increase the fitness of somebody else?"

00:01:10.951 --> 00:01:13.324
And that's a problem of evolution of cooperation.

00:01:13.324 --> 00:01:15.849
So in the atomic interaction here

00:01:15.849 --> 00:01:18.524
we have two people, say, or two cells, you know...

00:01:18.524 --> 00:01:20.149
but let's talk about people here.

00:01:20.149 --> 00:01:22.746
And one is a donor, and the other is a recipient.

00:01:22.746 --> 00:01:23.994
Donor pays a cost.

00:01:23.994 --> 00:01:25.875
And the recipient gets a benefit.

00:01:25.875 --> 00:01:29.251
Cost and benefit are measured in reproductive success.

00:01:29.251 --> 00:01:32.682
And reproduction can be genetic or cultural.

00:01:32.682 --> 00:01:35.226
So we use the same framework to describe, say,

00:01:35.226 --> 00:01:38.968
people learning how to behave without genetic reproduction,

00:01:38.968 --> 00:01:41.313
we talk about cultural evolution here.

00:01:42.225 --> 00:01:43.418
So if we have this framework

00:01:43.418 --> 00:01:46.524
and if both people have to make a choice simultaneously

00:01:46.524 --> 00:01:48.004
between cooperation and defection,

00:01:48.004 --> 00:01:49.654
we get a very famous game.

00:01:49.654 --> 00:01:52.746
It's a game in sence of game theory,

00:01:52.746 --> 00:01:55.511
a field of mathematics that was invented by John von Neumann.

00:01:55.926 --> 00:01:59.318
And so what you see here is that my choice and your choice.

00:01:59.318 --> 00:02:00.714
And that what is written in a red

00:02:00.714 --> 00:02:03.502
is what you would get if these were the outcomes.

00:02:03.502 --> 00:02:05.672
So you have to look at this payoff matrix

00:02:05.672 --> 00:02:07.815
and now you have to decide for an action.

00:02:07.815 --> 00:02:10.012
Either to cooperate or to defect.

00:02:10.012 --> 00:02:12.680
And I will also decide between cooperation and defection

00:02:12.680 --> 00:02:14.552
so we will play the game simultaniously.

00:02:14.552 --> 00:02:17.290
So please look at the matrix and make a choice.

00:02:17.956 --> 00:02:20.819
Who wants to cooperate with me? Raise your hand.

00:02:22.812 --> 00:02:24.148
Who wants to defect?

00:02:26.362 --> 00:02:28.527
Very few defectors so some people...

00:02:28.527 --> 00:02:30.311
many people haven't actually decided

00:02:30.311 --> 00:02:32.458
so I should say that it is not an optional game.

00:02:32.776 --> 00:02:36.167
In game theory we also have optional games

00:02:36.167 --> 00:02:39.000
with that a third column which means "do nothing."

00:02:39.000 --> 00:02:39.822
But this is not...

00:02:39.822 --> 00:02:40.951
the prisoner's dillema,

00:02:40.951 --> 00:02:42.502
you have to make a choice essentially.

00:02:42.694 --> 00:02:45.226
So this is how you should think about it.

00:02:45.783 --> 00:02:47.029
You don't know what I will do.

00:02:47.029 --> 00:02:48.662
Let's assume I cooperate.

00:02:49.214 --> 00:02:53.431
If I cooperate you have a choice between 'b - c' and 'b'.

00:02:53.757 --> 00:02:56.349
So 'b' is greater than 'b - c'

00:02:56.349 --> 00:02:58.295
because 'b' greater than 'c' greater than 0.

00:02:58.295 --> 00:03:01.466
So if I cooperate you want to defect.

00:03:01.466 --> 00:03:05.605
If I defect you have a choice between '-c' and 0.

00:03:05.605 --> 00:03:08.482
So 0 is greater than '-c', so if I defect

00:03:08.482 --> 00:03:09.769
you also want to defect.

00:03:10.211 --> 00:03:13.244
Therefore, no matter what I might to be doing

00:03:13.244 --> 00:03:15.225
it is better for you to defect.

00:03:15.734 --> 00:03:18.381
And now if I analyse the game in a same way

00:03:18.381 --> 00:03:22.183
we both end up with defection, we both get 0 points.

00:03:22.183 --> 00:03:23.557
And that be very disappointed

00:03:23.557 --> 00:03:26.790
because over there we would have had 'b - c' points

00:03:26.790 --> 00:03:28.489
had we both cooperated.

00:03:29.007 --> 00:03:32.951
And that precisely why it's called a dilemma.

00:03:32.951 --> 00:03:36.161
So the dilemma is that there is incentive to defect,

00:03:36.161 --> 00:03:39.304
but two cooperators are better than two defectors.

00:03:39.304 --> 00:03:42.016
For the group it is better to cooperate

00:03:42.016 --> 00:03:45.260
but for the individual there is always a temptation to defect.

00:03:45.848 --> 00:03:47.142
And that's the problem here.

00:03:47.142 --> 00:03:49.731
What I gave you it's so-called rational analysis

00:03:49.731 --> 00:03:51.978
that is offered by game theorists and economists

00:03:51.978 --> 00:03:56.080
to say that you cannot cooperate in a prisoners dilemma

00:03:56.080 --> 00:03:57.660
as written here.

00:03:57.660 --> 00:03:59.650
But we have seen that people cooperated.

00:03:59.650 --> 00:04:01.872
It is also pointed out in experiments.

00:04:01.872 --> 00:04:04.867
So the question is: "Why do people cooperate?"

00:04:07.706 --> 00:04:09.878
I should say that as biologists

00:04:09.878 --> 00:04:12.229
we analyse the games slightly differently,

00:04:12.229 --> 00:04:14.912
we don't need the concept of rationality.

00:04:14.912 --> 00:04:17.257
What I gave you was this rational analysis

00:04:17.257 --> 00:04:21.589
and a rational player is defined in the game theory sence

00:04:21.589 --> 00:04:24.128
as somebody who realizes what a Nash equilibrium is

00:04:24.128 --> 00:04:25.675
and placed in a Nash equilibrium.

00:04:25.675 --> 00:04:28.788
But most experiments showed that people are not... rational.

00:04:28.788 --> 00:04:29.774
So the interesting thing is

00:04:29.774 --> 00:04:32.114
biologists don't make use of that concept

00:04:32.114 --> 00:04:34.101
but come to the same conclusion.

00:04:34.101 --> 00:04:37.987
So if we have a mixed population of cooperators and defectors

00:04:37.987 --> 00:04:41.829
a defector always has a higher payoff than a cooperator.

00:04:41.829 --> 00:04:44.697
So therefore, defection becomes more and more popular

00:04:44.697 --> 00:04:46.030
because this is how you make money.

00:04:46.030 --> 00:04:47.271
You make more and more money

00:04:47.271 --> 00:04:51.077
until everybody is a defector and the system breaks down.

00:04:51.458 --> 00:04:54.297
So here natural selection destroys cooperation,

00:04:54.297 --> 00:04:56.661
opposes what would be good for the population

00:04:56.661 --> 00:04:59.884
and leaves the population in state of just defection.

00:05:01.678 --> 00:05:03.969
So therefore, natural selection needs help

00:05:03.969 --> 00:05:06.295
to favor cooperation over defection.

00:05:06.295 --> 00:05:13.097
And this help is something that I summarized in five mechanisms.

00:05:13.097 --> 00:05:15.823
So there has been work on this over the last forty years

00:05:15.823 --> 00:05:17.363
and there have been many hundreds

00:05:17.363 --> 00:05:19.824
or thousands of papers actually written on this.

00:05:19.824 --> 00:05:21.911
And I categorized these papers

00:05:21.911 --> 00:05:24.361
as belong it to one of five mechanisms.

00:05:24.361 --> 00:05:25.147
And these mechanisms are:

00:05:25.147 --> 00:05:28.876
kin selection, direct reciprocity, indirect reciprocity,

00:05:28.876 --> 00:05:30.761
spatial selection, group selection.

00:05:30.761 --> 00:05:33.742
And for the purpose of this meeting here

00:05:33.742 --> 00:05:36.258
I want to discuss direct and inderect reciprocity,

00:05:36.258 --> 00:05:38.725
if I'll have time, a little bit about spatial selection.

00:05:38.725 --> 00:05:42.792
I'm happy to take a questions about the other mechanisms also.

00:05:43.885 --> 00:05:47.400
So direct reciprocity is the idea "I help you, you help me."

00:05:47.895 --> 00:05:50.763
And this was written in the important paper

00:05:50.763 --> 00:05:53.018
by Robert Trivers in 1971.

00:05:53.018 --> 00:05:54.928
So direct reciprocity leads

00:05:54.928 --> 00:05:57.275
to the so-called repeated prisoner's dilemma.

00:05:57.275 --> 00:05:59.966
We'd play this game that we just played not once

00:05:59.966 --> 00:06:01.149
but several times.

00:06:01.149 --> 00:06:02.912
If we played several times

00:06:02.912 --> 00:06:06.064
it is no longer the case that the best thing is just to defect.

00:06:06.064 --> 00:06:08.789
Because if I defect with you in a first round

00:06:08.789 --> 00:06:10.209
that might upset you

00:06:10.209 --> 00:06:12.405
and than you will never cooperate with me again, kind of.

00:06:12.405 --> 00:06:13.830
But if I cooperate with you,

00:06:14.089 --> 00:06:15.335
it is costly for me,

00:06:15.335 --> 00:06:17.318
but it might lead you to cooperate with me.

00:06:18.389 --> 00:06:22.241
So economists can prove a theorem called the Folk theorem

00:06:22.241 --> 00:06:25.668
that it is possible to find cooperative Nash equilibrium

00:06:25.668 --> 00:06:27.304
in the repeated prisoner's dilemma.

00:06:27.925 --> 00:06:30.529
But the question is: "How does one play this game?"

00:06:31.036 --> 00:06:33.976
And this question was asked in an imporant study

00:06:33.976 --> 00:06:36.514
by a political scientist at the Ann Arbor University

00:06:36.514 --> 00:06:38.279
in the late 70's, Robert Axelrod.

00:06:38.279 --> 00:06:41.358
He said: "Let's have computer tournaments to playing this game."

00:06:41.358 --> 00:06:43.523
So people send him computer strategies

00:06:43.523 --> 00:06:45.186
to play the repeated prisoners dilemma

00:06:45.186 --> 00:06:46.644
and he evaluate it then,

00:06:46.644 --> 00:06:48.261
they beared each other up.

00:06:48.261 --> 00:06:49.952
And then he announce the winner.

00:06:50.246 --> 00:06:51.891
And the amazing thing is even though

00:06:51.891 --> 00:06:54.329
many of the entries with smart strategies

00:06:54.329 --> 00:06:57.049
that tried to predict, that tried to perceive...

00:06:57.875 --> 00:06:59.943
in two consequentive tournaments

00:06:59.943 --> 00:07:02.306
the simplest of all strategies won.

00:07:02.306 --> 00:07:05.467
And the simplest strategy was a three-line computer program

00:07:05.935 --> 00:07:09.134
sent by game theorist Anatol Rapaport and it says...

00:07:09.134 --> 00:07:10.488
it's 'tit-for-tat'.

00:07:10.488 --> 00:07:12.313
So I start with cooperation

00:07:12.313 --> 00:07:14.998
and then I do whetever you did last round.

00:07:16.178 --> 00:07:17.774
So without maybe...

00:07:17.774 --> 00:07:20.596
without you ever noticed that you are playing yourself.

00:07:20.596 --> 00:07:22.528
You are playing youself once removed

00:07:22.528 --> 00:07:24.975
because I do exactly what you did last time.

00:07:26.570 --> 00:07:30.296
And that strategy... at that time was considered

00:07:30.296 --> 00:07:32.735
kind of a world champion in the prisoner's dilemma,

00:07:33.157 --> 00:07:34.462
but it has a problem.

00:07:34.462 --> 00:07:35.775
It has a following problem:

00:07:35.775 --> 00:07:38.034
if two 'tit-for-tat' players play against each other

00:07:38.034 --> 00:07:39.583
and there is a mistake...

00:07:39.583 --> 00:07:42.703
One by accident defects the other one will hit back.

00:07:43.053 --> 00:07:46.996
And this endless cycle of retaliation destroys cooperation.

00:07:47.293 --> 00:07:49.472
So 'tit-for-tat' is unforgiving.

00:07:49.888 --> 00:07:52.656
But to do well in a world with errors,

00:07:52.656 --> 00:07:54.346
which was not in Axelrod's tournament,

00:07:54.346 --> 00:07:56.672
but if you want to think about a realistic world

00:07:56.672 --> 00:07:57.851
where people make mistakes,

00:07:57.851 --> 00:07:59.926
you need a mechanism for forgiveness.

00:08:00.221 --> 00:08:01.889
And 'tit-for-tat' doesn't do that.

00:08:02.755 --> 00:08:06.282
So in my Ph.D. thesis I had natural selection

00:08:06.606 --> 00:08:08.856
run a tournament on the computer

00:08:08.856 --> 00:08:10.149
and then mathematical analisys

00:08:10.149 --> 00:08:12.152
and do analyze what is happening

00:08:12.152 --> 00:08:15.713
if we put it in the context where errors are always occuring

00:08:15.713 --> 00:08:18.833
and not where we play arbitrary strategies sent by people

00:08:18.833 --> 00:08:22.418
but natural selection chooses in spaces of strategies.

00:08:22.418 --> 00:08:24.670
So I start with a random assemble of strategies.

00:08:24.670 --> 00:08:27.256
The first thing that you get is "always defect".

00:08:27.256 --> 00:08:30.512
So if people play randomly the best thing is to defect.

00:08:31.265 --> 00:08:34.659
But fortunately for my Ph.D. thesis it wasn't over here.

00:08:34.659 --> 00:08:36.190
Something interesting happened.

00:08:36.190 --> 00:08:37.693
Tit-for-tat came in.

00:08:37.693 --> 00:08:39.745
And you can actually prove that 'tit-for-tat'

00:08:39.745 --> 00:08:43.104
is a very good catalyst for the emergence of cooperation.

00:08:43.104 --> 00:08:46.054
It is a harsh vitaliator which you need

00:08:46.054 --> 00:08:47.877
when almost everybody's defecting

00:08:47.877 --> 00:08:51.096
to get some small cluster of cooperation going.

00:08:51.096 --> 00:08:52.277
But amazingly

00:08:52.277 --> 00:08:55.692
'tit-for-tat' was imediately replaced by another strategy.

00:08:55.692 --> 00:08:58.344
And that other strategy was 'generous tit-for-tat'...

00:08:58.344 --> 00:08:59.993
there's a formatting problem here.

00:08:59.993 --> 00:09:03.158
So 'generous tit-for-tat' replaced 'tit-for-tat' immediately.

00:09:03.158 --> 00:09:04.831
And what is 'generous tit-for-tat'?

00:09:04.831 --> 00:09:07.127
If you cooperate I will always cooperate,

00:09:07.127 --> 00:09:08.558
but if you defect

00:09:08.558 --> 00:09:11.176
I will still cooperate with a certain probability.

00:09:11.720 --> 00:09:14.518
And that also a recipe how to save many marriages.

00:09:14.518 --> 00:09:16.512
In a kitchen counter at home you have dice.

00:09:16.512 --> 00:09:17.541
You know, you roll dice

00:09:17.541 --> 00:09:19.984
and then you decide whether to forgive or not.

00:09:19.984 --> 00:09:21.967
And that would be a stable, kind of...

00:09:21.967 --> 00:09:24.195
because you need a probabilistic strategy,

00:09:24.195 --> 00:09:27.353
because a deterministic strategy could be exploited.

00:09:27.697 --> 00:09:29.704
So this is a mathematical model

00:09:29.704 --> 00:09:31.689
for the evolution of forgiveness.

00:09:33.027 --> 00:09:35.977
But the interesting thing that happened next is

00:09:35.977 --> 00:09:38.301
if everybody here plays 'generous tit-for-tat'

00:09:38.301 --> 00:09:40.184
and I'd play 'always cooperate'

00:09:40.184 --> 00:09:42.823
I have no disadvantage because everybody is nice

00:09:43.203 --> 00:09:46.581
and I do never ever retaliate, you know,

00:09:46.581 --> 00:09:48.537
but that doesn't matter because nobody exploits me.

00:09:48.843 --> 00:09:51.636
So this is nowdays called in biology "random drift".

00:09:51.636 --> 00:09:53.154
I mean neutral mutant.

00:09:53.758 --> 00:09:55.438
But there is no pressure for this...

00:09:55.438 --> 00:09:58.267
'generous tit-for-tat' like strategy to be maintained

00:09:58.267 --> 00:10:01.426
random drift eliminates it to brings it "always cooperate."

00:10:01.426 --> 00:10:04.608
It's like birds on an island without predators

00:10:04.608 --> 00:10:06.130
loose their ability to fly.

00:10:06.801 --> 00:10:09.513
A biological trait has to be under selection pressure

00:10:09.513 --> 00:10:10.465
to be maintained.

00:10:10.903 --> 00:10:13.111
So we drift to "always cooperate".

00:10:13.111 --> 00:10:15.244
But you can guess what happens next.

00:10:15.244 --> 00:10:17.910
You invite the invasion of "always defectors".

00:10:17.910 --> 00:10:20.830
And we have a simple mathematical model of human history

00:10:20.830 --> 00:10:23.993
and people have written books on such oscillations

00:10:23.993 --> 00:10:25.459
between war and peace.

00:10:25.836 --> 00:10:28.125
But the interesting thing in all my work

00:10:28.125 --> 00:10:30.539
on evolution of cooperation over the last 20 years,

00:10:30.539 --> 00:10:32.655
I've always find oscillations.

00:10:32.905 --> 00:10:35.361
Cooperation is never stable.

00:10:35.361 --> 00:10:37.987
There is no stable equilibrium.

00:10:37.987 --> 00:10:39.981
How much cooperation you get in the system

00:10:39.981 --> 00:10:43.142
depends completely how long you can hold it

00:10:43.142 --> 00:10:45.527
and how quickly you can rebuild it

00:10:45.527 --> 00:10:47.457
after it has been destroyed.

00:10:48.143 --> 00:10:50.053
And that what you need in human society.

00:10:50.053 --> 00:10:53.480
You need structures that rebuild cooperation quickly

00:10:53.480 --> 00:10:55.055
after it has been destroyed.

00:10:55.417 --> 00:10:58.077
Because you can bet on it that it will be destroyed.

00:10:58.077 --> 00:10:59.404
It will always be destroyed.

00:11:00.079 --> 00:11:01.613
And this oscillations we also see

00:11:01.613 --> 00:11:04.563
in the oscillations of the financial system, for example.

00:11:06.788 --> 00:11:08.116
There is the simple rule

00:11:08.116 --> 00:11:10.736
and I like simple mathematical results

00:11:10.736 --> 00:11:14.084
of this direct reciprocity allows evolution of cooperation

00:11:14.084 --> 00:11:16.594
if the probability of playing another round is greater

00:11:16.594 --> 00:11:18.790
than cost to benefit ratio.

00:11:19.087 --> 00:11:21.003
So the overall mathematics is complicated

00:11:21.003 --> 00:11:24.452
but there are some simple rules occasionally emerging.

00:11:24.452 --> 00:11:26.767
But let me go to indirect reciprocity

00:11:26.767 --> 00:11:28.614
because maybe that's even more important

00:11:28.614 --> 00:11:30.259
for the context of this meeting.

00:11:30.259 --> 00:11:33.229
So this is a Vincent Van Gogh painting of the good Samaritan.

00:11:33.229 --> 00:11:35.199
And we don't really know the motive

00:11:35.199 --> 00:11:37.189
of the good Samaritan to help this person,

00:11:37.189 --> 00:11:38.850
but presumanbly he was not thinking:

00:11:38.850 --> 00:11:41.908
"What if it is the first round of repetated prisoner's dilemma

00:11:41.908 --> 00:11:43.710
and I should better cooperate you."

00:11:44.499 --> 00:11:46.585
Instead the good Samaritan helps

00:11:46.585 --> 00:11:48.657
and maybe the good Samaritan thinks:

00:11:48.657 --> 00:11:51.043
"I help you, somebody will help me.

00:11:51.043 --> 00:11:52.472
You know, if I'm in such a situation,

00:11:52.472 --> 00:11:54.204
somebody might help me."

00:11:55.663 --> 00:11:58.134
So how do we get indirect reciprocity to work?

00:11:58.757 --> 00:12:02.097
If you can assign reputation to the players...

00:12:02.788 --> 00:12:06.743
So here player A helps B and that the reputation of A increases.

00:12:07.038 --> 00:12:12.630
Where A does not helped B and the reputation of A decreases.

00:12:13.916 --> 00:12:16.958
So then you need natural selection to choose strategies

00:12:16.958 --> 00:12:20.278
who based the decision to help on the reputation of others.

00:12:20.641 --> 00:12:24.562
So here we need mechanisms that assign reputation.

00:12:26.011 --> 00:12:28.372
And a web is perfect in doing such things,

00:12:28.372 --> 00:12:31.003
this reputation mechanisms come in Ebay auctions

00:12:31.003 --> 00:12:33.865
and in buyng and selling relationships.

00:12:33.865 --> 00:12:35.824
So there was... this was a theory

00:12:35.824 --> 00:12:38.417
that I've worked out with Karl Sigmund in the late 90's.

00:12:38.417 --> 00:12:41.909
And experimental confirmation was published in 2000

00:12:41.909 --> 00:12:44.382
where people did experiments with students

00:12:44.382 --> 00:12:45.695
sitting in front of computers

00:12:45.695 --> 00:12:48.197
and they find that people help whose who help others

00:12:48.197 --> 00:12:51.097
and helpful people have a higher payoff in the end.

00:12:52.336 --> 00:12:55.584
What you need for indirect reciprocity is gossip.

00:12:55.584 --> 00:12:58.223
So people... there is some action going on between two people,

00:12:58.223 --> 00:12:59.353
others observe it.

00:12:59.353 --> 00:13:02.198
And then gossip spreads in the population.

00:13:02.643 --> 00:13:04.421
And empirical observations such as

00:13:04.421 --> 00:13:06.580
that humans are obsessed with gossip,

00:13:06.580 --> 00:13:08.533
we are talking about others,

00:13:08.533 --> 00:13:11.062
we are talking with others about others.

00:13:11.062 --> 00:13:13.584
So people have done experiments in British trains

00:13:13.584 --> 00:13:16.856
going up and down listening to what people are talking about.

00:13:16.856 --> 00:13:18.676
I don't know if that is kind of legal, you know,

00:13:18.676 --> 00:13:20.386
but 60% of this topics

00:13:20.386 --> 00:13:23.878
were about inderect reciprocity in the certain sence.

00:13:23.878 --> 00:13:25.344
So the very interesting thing is

00:13:25.344 --> 00:13:27.973
for perfect mechanism of indirect reciprocity

00:13:27.973 --> 00:13:29.338
you need human language.

00:13:29.709 --> 00:13:33.148
So the human history you could eye this was the selection pressure

00:13:33.148 --> 00:13:36.646
that led to social intelligence and to human language,

00:13:36.646 --> 00:13:38.112
because you need to understand

00:13:38.112 --> 00:13:40.146
who does what to whom in the social network

00:13:40.146 --> 00:13:42.225
and you need to be able to talk about it.

00:13:43.962 --> 00:13:47.244
My friend David Haig at Harvard said beautifully:

00:13:47.244 --> 00:13:50.086
"For direct reciprocity you need a face.

00:13:50.669 --> 00:13:53.087
And for indirect reciprocity you need a name."

00:13:53.835 --> 00:13:56.495
So there is a lot in our brain that is just there

00:13:56.495 --> 00:13:59.249
to recognize faces and reading actions into faces

00:13:59.249 --> 00:14:01.370
and try to understand what people might be doing,

00:14:01.370 --> 00:14:03.533
but that's not enough to indirect reciprocity.

00:14:03.741 --> 00:14:06.709
For indirect reciprocity you need to be able to talk about others.

00:14:07.245 --> 00:14:11.108
And that's seems to be typically human characteristic.

00:14:11.672 --> 00:14:14.525
Again there is the simple rule here

00:14:14.525 --> 00:14:16.102
and this is that natural selection

00:14:16.102 --> 00:14:18.600
can favor cooperation by indirect reciprocity

00:14:18.600 --> 00:14:20.954
if the probability to know someone's reputation

00:14:20.954 --> 00:14:23.162
exceeds the cost to benefit ratio.

00:14:24.888 --> 00:14:26.271
So you need mechanisms

00:14:26.271 --> 00:14:29.975
such that interations are not completely anonymous.

00:14:29.975 --> 00:14:31.817
If these actions are completely anonymous

00:14:31.995 --> 00:14:33.390
you run into a problem.

00:14:34.646 --> 00:14:36.503
But you also run into second problem

00:14:36.503 --> 00:14:38.881
and this is that assigment of reputation

00:14:38.881 --> 00:14:42.045
so to say the gossip itself has to be a game

00:14:42.045 --> 00:14:44.428
that has to be conducted honestly.

00:14:44.428 --> 00:14:48.099
So this is on the higher level a cooperation/defection problem.

00:14:48.751 --> 00:14:50.040
Which is really studied.

00:14:53.918 --> 00:14:54.802
Almost over...

00:14:55.096 --> 00:14:57.816
So then spatial selection is just the idea

00:14:57.816 --> 00:14:59.420
that neighbors help each other.

00:14:59.420 --> 00:15:04.042
So you get cooperation emerging if cooperators can form clusters.

00:15:04.042 --> 00:15:08.399
And then clusters of cooperators can prevail against defectors.

00:15:08.742 --> 00:15:10.943
And this is something we study on graphs.

00:15:11.643 --> 00:15:14.476
And we have studied this on all sorts of networks.

00:15:14.476 --> 00:15:17.485
A random regular graphs, random graphs, scale-free networks.

00:15:17.771 --> 00:15:19.113
And to our great surprise

00:15:19.113 --> 00:15:21.833
we've found a beautiful simple mathematical rule

00:15:21.833 --> 00:15:23.983
that these graphs selection favors cooperation

00:15:23.983 --> 00:15:26.312
if the benefit to costs ratio is greater

00:15:26.312 --> 00:15:27.958
than the average number of neighbors.

00:15:28.167 --> 00:15:30.184
So this spatial selection works

00:15:30.184 --> 00:15:32.266
if you have a few close friends.

00:15:32.623 --> 00:15:35.679
If you interact loosely with a very large number of people

00:15:35.679 --> 00:15:38.262
that is much harder for that mechanism to work.

00:15:39.090 --> 00:15:41.579
Something else with this evolutionary set theory

00:15:41.579 --> 00:15:43.313
where people belong to sets.

00:15:43.313 --> 00:15:45.295
They interact with others in the sets

00:15:45.295 --> 00:15:47.563
and they join successful sets.

00:15:47.563 --> 00:15:49.564
And that is also something that leads

00:15:49.564 --> 00:15:51.650
to the right spatial stucturing

00:15:51.650 --> 00:15:53.982
that can be a powerful mechanism for cooperators

00:15:53.982 --> 00:15:55.643
to find each other in sets.

00:15:55.643 --> 00:15:58.504
So you hear about groups that work well together

00:15:58.504 --> 00:15:59.855
and you want to join that group.

00:15:59.855 --> 00:16:01.910
And that can be a powerful mechanism.

00:16:02.941 --> 00:16:04.922
So there five mechanisms.

00:16:04.922 --> 00:16:06.423
I've discussed three of them.

00:16:06.705 --> 00:16:09.652
And there are simple rules for all five of them.

00:16:10.018 --> 00:16:12.824
And these are the cooperators in my group here at Harvard.

00:16:13.012 --> 00:16:15.985
And recently I wrote a book called "Super cooperators"

00:16:15.985 --> 00:16:18.612
where I summarized some of these ideas.

00:16:18.612 --> 00:16:19.838
Thank you very much.

00:16:31.940 --> 00:16:35.541
Question for Martin while Nicolas is setting up the slides.

00:16:35.774 --> 00:16:38.281
But with the spatial selection

00:16:38.281 --> 00:16:40.501
one way of thinking about that there is...

00:16:40.501 --> 00:16:41.132
I think it's actually...

00:16:41.132 --> 00:16:42.709
I think it's done how it's work

00:16:42.709 --> 00:16:45.090
which was listen to gossip on trains.

00:16:45.090 --> 00:16:49.966
And that brings in a whole other issue around privacy

00:16:49.966 --> 00:16:51.917
which is the notion of networks

00:16:51.917 --> 00:16:56.185
and our technologies making it possible for us

00:16:56.185 --> 00:17:00.645
to have much larger networks of stronger ties.

00:17:00.645 --> 00:17:03.400
So when you said that a...

00:17:03.971 --> 00:17:07.987
that a larger networks didn't have the same level of cooperation

00:17:07.987 --> 00:17:10.511
with that because they were larger

00:17:10.511 --> 00:17:13.414
or because they were weakly connected?

00:17:14.412 --> 00:17:18.957
So what we call a "well-mixed population" is a complete graph

00:17:18.957 --> 00:17:22.577
where everybody interacts with everybody else equally strongly.

00:17:22.839 --> 00:17:26.214
And this does not provide selection pressure for cooperation.

00:17:27.246 --> 00:17:31.132
What you want is that you have a few connections

00:17:32.176 --> 00:17:35.305
with people and these are cooperators.

00:17:35.305 --> 00:17:37.212
But there is a very interesting tradeoff,

00:17:37.212 --> 00:17:40.235
because I can achieve it by saying I only have one friend

00:17:40.235 --> 00:17:43.313
and we will cooperate and we can never be exploited.

00:17:43.313 --> 00:17:46.186
But then it there somebody else showing up, you know,

00:17:46.186 --> 00:17:48.065
I could increase my overall income

00:17:48.065 --> 00:17:49.568
by also making this connection.

00:17:49.568 --> 00:17:51.364
So we build a bigger network.

00:17:51.364 --> 00:17:53.372
And what we found in the recent study

00:17:53.372 --> 00:17:55.650
is that the network as it becomes bigger and bigger,

00:17:55.650 --> 00:17:57.427
generates more and more wealth,

00:17:57.427 --> 00:18:00.060
but becomes more and more vulnerable

00:18:00.060 --> 00:18:02.000
to the exploitation of defectors.

00:18:02.000 --> 00:18:04.463
And at the point where defectors can destroy it

00:18:04.463 --> 00:18:06.137
you have the largest wealth.

00:18:07.101 --> 00:18:10.137
So there is a tradeoff between wealth and stability.

