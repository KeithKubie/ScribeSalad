WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:11.740
-- is the next group of topics
in 6.033 call fault tolerance.

00:00:11.740 --> 00:00:16.900
And the goal here is to learn
how to build reliable systems.

00:00:16.900 --> 00:00:19.730
An extreme case, or at
least our ideal goal,

00:00:19.730 --> 00:00:22.310
is to try to build systems
that will never fail.

00:00:22.310 --> 00:00:24.490
And what will find is that
we really can't do that,

00:00:24.490 --> 00:00:26.250
but what we'll try
to do is to build

00:00:26.250 --> 00:00:31.560
systems which maybe fail less
often than if you built them

00:00:31.560 --> 00:00:35.041
without the principles that
we're going to talk about.

00:00:35.041 --> 00:00:36.916
So the idea is how to
build reliable systems.

00:00:41.080 --> 00:00:43.610
So in order to understand how
to build reliable systems,

00:00:43.610 --> 00:00:46.460
we need to understand what
makes systems unreliable.

00:00:46.460 --> 00:00:52.260
And that has to do with
understanding what faults are.

00:00:52.260 --> 00:00:57.170
What problems occur in systems
that cause systems to fail?

00:00:57.170 --> 00:01:00.200
And you've actually seen many
examples of faults already.

00:01:00.200 --> 00:01:02.340
Informally, a fault
is just some kind

00:01:02.340 --> 00:01:08.151
of a flaw or a mistake that
causes a component or a module

00:01:08.151 --> 00:01:10.150
not to perform the way
it's supposed to perform.

00:01:10.150 --> 00:01:12.530
And we'll formalize
this notion a little bit

00:01:12.530 --> 00:01:14.690
today as we go along.

00:01:14.690 --> 00:01:17.289
So there are many examples
of faults, several of which

00:01:17.289 --> 00:01:18.705
you've already seen.

00:01:18.705 --> 00:01:20.580
A system could fail
because it has a software

00:01:20.580 --> 00:01:23.950
fault, a bug in a piece of
software, so when you run it,

00:01:23.950 --> 00:01:26.680
it doesn't work according
to the way you expect.

00:01:26.680 --> 00:01:30.560
And that causes
something bad to happen.

00:01:30.560 --> 00:01:34.539
You might have hardware faults.

00:01:34.539 --> 00:01:35.789
You store some data on a disk.

00:01:35.789 --> 00:01:36.660
You go back and read it.

00:01:36.660 --> 00:01:37.509
And it isn't there.

00:01:37.509 --> 00:01:39.020
But it's been corrupted.

00:01:39.020 --> 00:01:40.940
And that's an example
of a fault that

00:01:40.940 --> 00:01:42.700
might cause bad things
to happen if you

00:01:42.700 --> 00:01:48.690
build a system that relies on a
disk storing data persistently.

00:01:48.690 --> 00:01:54.500
You might have design faults
where a design fault might

00:01:54.500 --> 00:01:58.130
be something where
you try to, let's say,

00:01:58.130 --> 00:02:01.720
figure out how much buffering
to put into a network switch.

00:02:01.720 --> 00:02:03.200
And you put into
little buffering.

00:02:03.200 --> 00:02:05.616
So what ends up happening is
too many packets get dropped.

00:02:05.616 --> 00:02:09.610
So you might actually just
have some bad logic in there,

00:02:09.610 --> 00:02:13.730
and that causes you to design
something that isn't quite

00:02:13.730 --> 00:02:15.514
going to work out.

00:02:15.514 --> 00:02:17.680
And you might, of course,
have implementation faults

00:02:17.680 --> 00:02:19.650
where you have a design,
and then you implement it,

00:02:19.650 --> 00:02:21.700
and you made a mistake
in how it's implemented.

00:02:21.700 --> 00:02:24.700
And that could cause
faults as well.

00:02:24.700 --> 00:02:26.760
And another example
of the kind of faults

00:02:26.760 --> 00:02:30.700
is an operational fault
sometimes called a human error

00:02:30.700 --> 00:02:33.220
where a user actually
does something

00:02:33.220 --> 00:02:35.960
that you didn't anticipate
or was told not to do,

00:02:35.960 --> 00:02:39.841
and that caused bad
things to happen.

00:02:39.841 --> 00:02:41.550
For all of these
faults, there are really

00:02:41.550 --> 00:02:43.370
two categories of
faults regardless

00:02:43.370 --> 00:02:45.840
of what kind of fault it is.

00:02:45.840 --> 00:02:48.954
The first category of
faults are latent faults.

00:02:51.860 --> 00:02:54.250
So an example of
a latent fault is,

00:02:54.250 --> 00:02:57.810
let's say you have a
bug in a program where

00:02:57.810 --> 00:03:00.550
instead of testing
if A less than B,

00:03:00.550 --> 00:03:02.540
you test if A greater than B.

00:03:02.540 --> 00:03:05.630
So that's a bug in a program.

00:03:05.630 --> 00:03:08.640
But until it actually runs,
until that line of code runs,

00:03:08.640 --> 00:03:10.319
this fault in the
program isn't actually

00:03:10.319 --> 00:03:11.360
going to do anything bad.

00:03:11.360 --> 00:03:14.330
It isn't going to have
any adverse effect.

00:03:14.330 --> 00:03:17.030
And therefore, this fault is
an example of a latent fault.

00:03:17.030 --> 00:03:20.410
And nothing is happening
until it gets triggered.

00:03:20.410 --> 00:03:22.970
And when it gets triggered,
that latent fault

00:03:22.970 --> 00:03:28.751
might become an active fault.

00:03:28.751 --> 00:03:31.250
Now, the problem when a latent
fault becomes an active fault

00:03:31.250 --> 00:03:35.150
is that when you run
that line of code,

00:03:35.150 --> 00:03:38.030
you might have a mistake
coming out at the output,

00:03:38.030 --> 00:03:40.820
which we're going
to call an error.

00:03:40.820 --> 00:03:43.590
So when an active
fault is exercised,

00:03:43.590 --> 00:03:45.370
it leads to an error.

00:03:45.370 --> 00:03:48.326
And the problem with errors
is that if you're not

00:03:48.326 --> 00:03:49.950
careful about how
you deal with errors,

00:03:49.950 --> 00:03:51.570
and most of what we're
going to talk about

00:03:51.570 --> 00:03:53.380
is how to deal with
errors, if you're not

00:03:53.380 --> 00:03:56.300
careful about how you deal with
errors that leads to a failure.

00:04:02.040 --> 00:04:03.530
So somewhat more
formally, a fault

00:04:03.530 --> 00:04:06.020
is just any flaw in an
underlying component

00:04:06.020 --> 00:04:09.710
or underlying subsystem
that your system is using.

00:04:09.710 --> 00:04:13.172
Now, if the fault turns out
not to be exercised then.

00:04:13.172 --> 00:04:13.880
There's no error.

00:04:13.880 --> 00:04:15.520
There's no error that
results, and there's

00:04:15.520 --> 00:04:16.519
no failure that results.

00:04:16.519 --> 00:04:18.320
It's only when you
have an active fault

00:04:18.320 --> 00:04:19.990
that you might have an error.

00:04:19.990 --> 00:04:22.736
And when you have an error,
you might have a failure.

00:04:22.736 --> 00:04:24.110
And what we're
going to try to do

00:04:24.110 --> 00:04:27.780
is to understand how to
deal with these errors

00:04:27.780 --> 00:04:29.450
so that when errors
occur we're going

00:04:29.450 --> 00:04:32.710
to try to hide them or
mask them, or do something

00:04:32.710 --> 00:04:35.900
such that these errors don't
propagate and cause failures.

00:04:40.330 --> 00:04:42.150
So the general goal,
as I mentioned before,

00:04:42.150 --> 00:04:46.850
is to build systems
that don't fail.

00:04:46.850 --> 00:04:49.200
So, in order to build
systems that don't fail,

00:04:49.200 --> 00:04:52.440
there are two approaches
at a 50,000 foot level.

00:04:52.440 --> 00:04:54.590
One approach to build a
system that doesn't fail

00:04:54.590 --> 00:04:56.058
is to build it
out of, make sure,

00:04:56.058 --> 00:04:57.600
every system is
going to be built out

00:04:57.600 --> 00:04:58.642
of components or modules.

00:04:58.642 --> 00:05:00.433
And those modules are
going to be built out

00:05:00.433 --> 00:05:01.590
of modules themselves.

00:05:01.590 --> 00:05:04.050
One approach might be to
make sure that no module ever

00:05:04.050 --> 00:05:06.960
fails, that no component that
you use to build your bigger

00:05:06.960 --> 00:05:08.750
system ever fails.

00:05:08.750 --> 00:05:11.360
And it'll turn out that for
reasons that will become clear

00:05:11.360 --> 00:05:13.200
based on an understanding
of the techniques

00:05:13.200 --> 00:05:16.670
we are going to employ to
build systems that don't fail,

00:05:16.670 --> 00:05:19.205
it'll turn out that this
is extremely expensive.

00:05:19.205 --> 00:05:21.330
It's just not going to work
out for us to make sure

00:05:21.330 --> 00:05:23.750
that our disks never
fail, and memory never

00:05:23.750 --> 00:05:26.530
fails, and our networks
never fail, and so on.

00:05:26.530 --> 00:05:29.774
It's just too expensive
and nearly impossible.

00:05:29.774 --> 00:05:31.190
So what we're going
to do actually

00:05:31.190 --> 00:05:33.100
is to start with
unreliable components.

00:05:40.150 --> 00:05:42.170
And we're going to build
reliable systems out

00:05:42.170 --> 00:05:46.940
of unreliable components
or modules more generally.

00:05:49.450 --> 00:05:53.310
And what this means is that
the system that you build

00:05:53.310 --> 00:05:57.060
had better be tolerant of
faults that these underlying

00:05:57.060 --> 00:06:00.780
components have, which is
why the design of systems

00:06:00.780 --> 00:06:04.960
that don't fail or rarely
fail is essentially

00:06:04.960 --> 00:06:07.480
the same as designing systems
that are tolerant of faults,

00:06:07.480 --> 00:06:08.680
hence fault tolerance.

00:06:08.680 --> 00:06:13.710
So that's the reason why we
care about fault tolerance.

00:06:13.710 --> 00:06:15.720
So let's take the
example of the kinds

00:06:15.720 --> 00:06:19.500
of, just to crystallize these
notions of faults and failures

00:06:19.500 --> 00:06:20.420
a little bit more.

00:06:20.420 --> 00:06:23.460
So let's say you have a big
system that has a module.

00:06:23.460 --> 00:06:24.620
Let's call it M1.

00:06:24.620 --> 00:06:30.970
And this module uses a couple
of other modules, M2 and M3.

00:06:30.970 --> 00:06:34.990
And let's say M2 uses
another module, M4,

00:06:34.990 --> 00:06:36.850
where users might
be an invocation.

00:06:36.850 --> 00:06:40.570
Or imagine this is an
RPC call, for example.

00:06:43.420 --> 00:06:46.800
And, let's say that M4 in here
has some component inside M4

00:06:46.800 --> 00:06:49.970
like a disk or something,
some piece of software in M4.

00:06:49.970 --> 00:06:53.020
And, let's say that that fails.

00:06:53.020 --> 00:06:53.840
So, it has a fault.

00:06:53.840 --> 00:06:54.690
It gets triggered.

00:06:54.690 --> 00:06:56.368
It becomes active,
leads to an error.

00:06:56.368 --> 00:06:58.076
It actually fails,
that little component.

00:07:01.100 --> 00:07:03.890
So when this fault becomes a
failure, a couple of things

00:07:03.890 --> 00:07:05.340
could happen.

00:07:05.340 --> 00:07:14.069
M4, which is the module to which
this little failure belongs,

00:07:14.069 --> 00:07:15.110
can do one of two things.

00:07:15.110 --> 00:07:18.500
One possibility
is that this fault

00:07:18.500 --> 00:07:21.310
that caused the failure
gets exposed to the caller.

00:07:21.310 --> 00:07:23.800
So, M4 hasn't
managed to figure out

00:07:23.800 --> 00:07:27.160
a way to hide this failure
from M2, which means

00:07:27.160 --> 00:07:29.170
that the fault propagates up.

00:07:29.170 --> 00:07:32.690
The failure gets visible, and
the fault propagates up to M2.

00:07:32.690 --> 00:07:38.920
And now, M2 actually sees the
underlying component's failure.

00:07:38.920 --> 00:07:42.670
So the point here is that
this little component fault

00:07:42.670 --> 00:07:44.620
caused a failure
here which caused

00:07:44.620 --> 00:07:49.610
M4 itself to fail because M4 now
couldn't hide this underlying

00:07:49.610 --> 00:07:52.020
failure, and reported
something that

00:07:52.020 --> 00:07:54.880
was a failure, that
was an output that

00:07:54.880 --> 00:07:59.030
didn't conform to the
specification of M4 out to M2.

00:07:59.030 --> 00:08:02.810
Now, as far as M2 is concerned,
all that has happened so far

00:08:02.810 --> 00:08:06.240
is that the failure
of this module, M4,

00:08:06.240 --> 00:08:10.250
has shown up as a
fault to M2, right,

00:08:10.250 --> 00:08:12.780
because an underlying
module has failed.

00:08:12.780 --> 00:08:14.590
It doesn't mean
that M2 has failed.

00:08:14.590 --> 00:08:17.510
It just means that M2
has now seen a fault.

00:08:17.510 --> 00:08:21.150
And M2 now might manage
to hide this fault, which

00:08:21.150 --> 00:08:23.400
would mean that M1 doesn't
actually see anything.

00:08:23.400 --> 00:08:26.480
It doesn't see the
underlying fault

00:08:26.480 --> 00:08:28.600
that caused the failure at all.

00:08:28.600 --> 00:08:30.940
But of course, if M2
now couldn't hide this

00:08:30.940 --> 00:08:33.000
or couldn't mask
this failure, then it

00:08:33.000 --> 00:08:36.010
would propagate an
erroneous output out

00:08:36.010 --> 00:08:37.808
to M1, an output
that didn't conform

00:08:37.808 --> 00:08:40.570
to the specification
of M2, leading M1

00:08:40.570 --> 00:08:43.070
to observe this as
a fault, and so on.

00:08:43.070 --> 00:08:47.100
So, the general idea is
that failures of sub-modules

00:08:47.100 --> 00:08:49.550
tend to show up as faults
in the higher level module.

00:08:53.240 --> 00:08:55.240
And our goal is to
try to somehow design

00:08:55.240 --> 00:08:57.480
these systems that use lots
of modules and components

00:08:57.480 --> 00:09:00.370
where at some level
in the end we would

00:09:00.370 --> 00:09:02.610
like to avoid failing overall.

00:09:02.610 --> 00:09:06.270
But inside here, we won't
be able to go about making

00:09:06.270 --> 00:09:08.340
everything failure-free.

00:09:08.340 --> 00:09:10.660
I mean, there might be
failures inside sub-modules.

00:09:10.660 --> 00:09:13.410
But the idea is to
ensure, or try to ensure,

00:09:13.410 --> 00:09:15.920
that M1 itself, the highest
level system, doesn't fail.

00:09:18.700 --> 00:09:20.225
So let's start with
a few examples.

00:09:24.427 --> 00:09:27.010
In fact, these all examples of
things that we've already seen.

00:09:27.010 --> 00:09:29.650
And even though we haven't
discussed it as such,

00:09:29.650 --> 00:09:32.720
we've seen a lot of examples
of fault tolerance in the class

00:09:32.720 --> 00:09:33.220
so far.

00:09:33.220 --> 00:09:37.885
So, for example, if you have
bad synchronization code

00:09:37.885 --> 00:09:40.010
like you didn't use the
locking discipline properly

00:09:40.010 --> 00:09:44.870
or didn't use any of the other
synchronization primitives

00:09:44.870 --> 00:09:50.520
properly, you might have a
software fault that leads

00:09:50.520 --> 00:09:53.740
to the failure of a module.

00:09:53.740 --> 00:09:56.650
Another example that we saw
when we talk about networking

00:09:56.650 --> 00:10:02.450
is when we talk about routing
where the idea in here

00:10:02.450 --> 00:10:04.880
was that we talked about
rat in protocols that

00:10:04.880 --> 00:10:06.350
could handle failures of links.

00:10:06.350 --> 00:10:09.070
So, certain links could fail,
leading to certain paths

00:10:09.070 --> 00:10:10.700
to not be usable.

00:10:10.700 --> 00:10:13.060
But, the routing system
managed to find other paths

00:10:13.060 --> 00:10:13.980
around the network.

00:10:13.980 --> 00:10:15.500
And that was because
there were other parts

00:10:15.500 --> 00:10:16.999
available because
the network itself

00:10:16.999 --> 00:10:19.350
was built with some degree
of redundancy underneath.

00:10:19.350 --> 00:10:24.440
And the routing protocol
was able to exploit that.

00:10:24.440 --> 00:10:27.440
Another example that we
saw again from networks

00:10:27.440 --> 00:10:30.474
is packet loss.

00:10:30.474 --> 00:10:32.640
We had best effort networks
that would lose packets.

00:10:32.640 --> 00:10:35.590
And it didn't mean that
your actual transfer

00:10:35.590 --> 00:10:38.760
of a file at the ends and
where would miss data.

00:10:38.760 --> 00:10:41.370
We came up with
retransmissions as a mechanism

00:10:41.370 --> 00:10:44.120
to use, again, another
form of redundancy

00:10:44.120 --> 00:10:46.620
where you try the same thing
again to get your data through.

00:10:50.090 --> 00:10:52.930
Another example of the failure
that we saw was congestion

00:10:52.930 --> 00:10:53.904
collapse --

00:10:56.810 --> 00:11:02.500
-- where there was too much data
being sent out into the network

00:11:02.500 --> 00:11:04.500
too fast, and the
network would collapse.

00:11:04.500 --> 00:11:06.350
And our solution to
this problem was really

00:11:06.350 --> 00:11:09.800
to shed load was to run the
system slower than it otherwise

00:11:09.800 --> 00:11:12.100
would, by having
the people sending

00:11:12.100 --> 00:11:16.440
data send data slower in order
to alleviate this problem.

00:11:16.440 --> 00:11:18.930
Another example which
we saw last time was,

00:11:18.930 --> 00:11:22.590
or briefly saw last time was
the domain name system where

00:11:22.590 --> 00:11:24.320
the domain name
servers are replicated.

00:11:24.320 --> 00:11:26.900
So, if you couldn't reach one
to resolve your domain name,

00:11:26.900 --> 00:11:28.830
you could go to another one.

00:11:28.830 --> 00:11:30.290
And all of these,
or most of these

00:11:30.290 --> 00:11:33.159
actually use the same techniques
that we're going to talk about.

00:11:33.159 --> 00:11:34.700
And all of these
techniques are built

00:11:34.700 --> 00:11:39.880
around some form of redundancy
on another except probably

00:11:39.880 --> 00:11:40.630
the locking thing.

00:11:40.630 --> 00:11:43.830
But all of the others are built
around some form of redundancy.

00:11:43.830 --> 00:11:46.940
And we'll understand this
more systematically today

00:11:46.940 --> 00:11:49.740
and in the next
couple of classes.

00:11:49.740 --> 00:11:52.401
So our goal here is to develop
a systematic approach --

00:11:55.490 --> 00:12:02.640
-- to building systems
that are fault tolerant.

00:12:02.640 --> 00:12:04.940
And the general approach for
all fault tolerant systems

00:12:04.940 --> 00:12:06.750
is to use three techniques.

00:12:06.750 --> 00:12:09.180
So the first one we've
already seen, which is

00:12:09.180 --> 00:12:10.550
don't build a monolithic system.

00:12:10.550 --> 00:12:11.841
Always build it around modules.

00:12:15.110 --> 00:12:16.750
And the reason is
that it will that

00:12:16.750 --> 00:12:20.580
be easier for us to isolate
these modules firstly

00:12:20.580 --> 00:12:21.660
one from another.

00:12:21.660 --> 00:12:24.180
But then, when
modules fail, it will

00:12:24.180 --> 00:12:26.660
be easier for us to treat
those failures as faults,

00:12:26.660 --> 00:12:28.670
and then try to
hide those faults,

00:12:28.670 --> 00:12:33.090
and apply the same
technique, which brings us

00:12:33.090 --> 00:12:36.890
to the second step, which is
when failures occur causing

00:12:36.890 --> 00:12:41.110
errors, we need a plan
for the higher level

00:12:41.110 --> 00:12:42.680
module to detect errors.

00:12:47.010 --> 00:12:48.420
So failure results in an error.

00:12:48.420 --> 00:12:51.180
We have to know
that it's happened,

00:12:51.180 --> 00:12:53.796
which means we need
techniques to detect it.

00:12:53.796 --> 00:12:55.420
And, of course, once
we detect an error

00:12:55.420 --> 00:12:57.230
we have a bunch of things
we could do with it.

00:12:57.230 --> 00:12:58.688
But ideally, if
you want to prevent

00:12:58.688 --> 00:13:01.640
the failure of that system, of
a system that's observed errors,

00:13:01.640 --> 00:13:04.820
you need a way to
hide these errors.

00:13:04.820 --> 00:13:06.790
The jargon for this
is mask errors.

00:13:12.110 --> 00:13:14.390
And if we do this, if we
build systems that do this,

00:13:14.390 --> 00:13:16.250
then it's possible
for us to build

00:13:16.250 --> 00:13:18.330
systems that can form to spec.

00:13:18.330 --> 00:13:20.585
So the goal here is to try
to make sure that systems

00:13:20.585 --> 00:13:21.835
conform to some specification.

00:13:25.922 --> 00:13:27.880
And if things don't
conform to a specification,

00:13:27.880 --> 00:13:31.390
then that's when we
call it a failure.

00:13:31.390 --> 00:13:32.840
And sometimes we
play some tricks

00:13:32.840 --> 00:13:36.760
where in order to build
systems that "never fail",

00:13:36.760 --> 00:13:39.670
we'll scale back the
specification to actually allow

00:13:39.670 --> 00:13:43.670
for things that would in
fact be considered failures,

00:13:43.670 --> 00:13:46.120
but are things that still
would conform to the spec.

00:13:46.120 --> 00:13:48.180
So we relax the
specification to make sure

00:13:48.180 --> 00:13:53.130
that we could still meet the
notion of a failure free system

00:13:53.130 --> 00:13:54.290
or a fault tolerant system.

00:13:54.290 --> 00:13:56.280
And we'll see some
examples of that

00:13:56.280 --> 00:13:57.700
actually in the next lecture.

00:14:00.410 --> 00:14:02.840
And I've already mentioned,
the general trick

00:14:02.840 --> 00:14:06.240
for all of these systems
that we're going to study,

00:14:06.240 --> 00:14:07.750
examples that we're
going to study,

00:14:07.750 --> 00:14:09.890
is to use some
form of redundance.

00:14:12.779 --> 00:14:15.070
And that's the way in which
we're going to mask errors.

00:14:15.070 --> 00:14:19.560
And almost all systems,
or every system

00:14:19.560 --> 00:14:21.060
that I know of
that's fault tolerant

00:14:21.060 --> 00:14:23.160
uses redundancy in
some form or another.

00:14:23.160 --> 00:14:25.150
And often it's not
obvious how it uses it.

00:14:25.150 --> 00:14:27.020
But it does actually
use redundancy.

00:14:32.160 --> 00:14:35.260
So I'm going to now give an
example that will turn out

00:14:35.260 --> 00:14:38.070
to be the same example we'll
use for the next three or four

00:14:38.070 --> 00:14:38.800
lectures.

00:14:38.800 --> 00:14:40.947
And so, you may as well,
you should probably

00:14:40.947 --> 00:14:42.780
get familiar with this
example because we're

00:14:42.780 --> 00:14:44.400
going to see this
over and over again.

00:14:44.400 --> 00:14:47.970
It's a really simple example,
but it's complicated enough

00:14:47.970 --> 00:14:50.670
that everything we want to
learn about fault tolerance

00:14:50.670 --> 00:14:52.907
will be visible in this example.

00:14:52.907 --> 00:14:54.490
So it starts with
the person who wants

00:14:54.490 --> 00:15:03.640
to do a bank transaction at an
ATM, or a PC, or on a computer.

00:15:03.640 --> 00:15:05.140
You want to do a
bank transaction.

00:15:05.140 --> 00:15:07.580
And the way this works, as
you probably know, is it

00:15:07.580 --> 00:15:11.150
goes over some
kind of a network.

00:15:11.150 --> 00:15:14.600
And then, if you want to
do this bank transaction,,

00:15:14.600 --> 00:15:20.060
it goes to a server,
which is run by your bank.

00:15:20.060 --> 00:15:21.640
And the way this
normally works is

00:15:21.640 --> 00:15:24.250
that the server
has a module that

00:15:24.250 --> 00:15:32.870
uses a database system,
which deals with managing

00:15:32.870 --> 00:15:34.530
your account information.

00:15:34.530 --> 00:15:36.921
And because you
don't want to forget,

00:15:36.921 --> 00:15:39.170
and the bank shouldn't forget
how much money you have,

00:15:39.170 --> 00:15:42.960
there is data that's
stored on disk.

00:15:42.960 --> 00:15:45.750
And we're going to be
doing things that are

00:15:45.750 --> 00:15:47.810
actions of the following form.

00:15:47.810 --> 00:15:53.540
We're going to be
asking the transfer

00:15:53.540 --> 00:15:58.340
from some account to another
account some amount of money.

00:16:02.530 --> 00:16:05.290
And now, of course, anything
could fail in between.

00:16:05.290 --> 00:16:08.200
So, for example, there could
be a problem in the network.

00:16:08.200 --> 00:16:09.470
And the network could fail.

00:16:09.470 --> 00:16:11.320
Or the software running
on the server could fail.

00:16:11.320 --> 00:16:13.153
Or the software running
this database system

00:16:13.153 --> 00:16:17.580
could crash or report
bad values or something.

00:16:17.580 --> 00:16:19.150
The disc could fail.

00:16:19.150 --> 00:16:22.790
And do we want systematic
techniques by which this

00:16:22.790 --> 00:16:25.720
transfer here or
all of these calls

00:16:25.720 --> 00:16:29.260
that look a lot like
transfer do the right thing?

00:16:29.260 --> 00:16:31.250
And so, this doing
the right thing

00:16:31.250 --> 00:16:34.150
is an informal way of
saying meet a specification.

00:16:34.150 --> 00:16:38.190
So, we first have to decide what
we want for a specification.

00:16:38.190 --> 00:16:40.290
That has to hold true
no matter what happens,

00:16:40.290 --> 00:16:41.810
no matter what failures occur.

00:16:41.810 --> 00:16:43.730
So one example of
a specification

00:16:43.730 --> 00:16:47.410
might be to say, no matter
what happens, if I invoke this

00:16:47.410 --> 00:16:51.140
and it returns, then
this amount of money

00:16:51.140 --> 00:16:53.430
has to be transferred
from here to here.

00:16:53.430 --> 00:16:57.170
So that could be a specification
that you might expect.

00:16:57.170 --> 00:16:59.420
It also turns out this
specification is extremely hard

00:16:59.420 --> 00:16:59.750
to meet.

00:16:59.750 --> 00:17:01.010
And we're not even
going to try to do it.

00:17:01.010 --> 00:17:03.259
And this is the weasel
wording I said before about,

00:17:03.259 --> 00:17:04.750
we'll modify the specification.

00:17:04.750 --> 00:17:07.358
So, we'll change the
specification going forward

00:17:07.358 --> 00:17:11.079
for this example to mean,
if this call returns,

00:17:11.079 --> 00:17:14.160
then no matter what
failures occur,

00:17:14.160 --> 00:17:17.348
either a transfer has
happened exactly once,

00:17:17.348 --> 00:17:20.450
or the state of the system is as
if the transfer didn't even get

00:17:20.450 --> 00:17:23.770
started, OK, which
is reasonable.

00:17:23.770 --> 00:17:27.249
I mean, and then if you really
care about moving the money,

00:17:27.249 --> 00:17:29.290
and you are determined
that it hasn't been moved,

00:17:29.290 --> 00:17:31.340
you or some program
might try it again,

00:17:31.340 --> 00:17:34.460
which actually is another
form of using redundancy where

00:17:34.460 --> 00:17:37.500
you just try it over again.

00:17:37.500 --> 00:17:41.280
And we won't
understand completely

00:17:41.280 --> 00:17:45.130
why a specification that says
you have to do this exactly

00:17:45.130 --> 00:17:47.940
once if it returns, why
that's hard to implement,

00:17:47.940 --> 00:17:49.801
why that's hard to
achieve, we'll see that

00:17:49.801 --> 00:17:51.050
in the next couple of classes.

00:17:51.050 --> 00:17:53.550
So, for now, just realized
that the specification here

00:17:53.550 --> 00:17:55.750
is it should happen
exactly once or it should

00:17:55.750 --> 00:18:00.527
be as if no partial
action corresponding

00:18:00.527 --> 00:18:02.610
to the [UNINTELLIGIBLE]
of this transfer happened.

00:18:02.610 --> 00:18:05.710
So the state of the system
must be as if the system never

00:18:05.710 --> 00:18:06.810
saw this transfer request.

00:18:10.350 --> 00:18:11.750
So any module could failure.

00:18:11.750 --> 00:18:13.560
So, let's take some
examples of failures

00:18:13.560 --> 00:18:15.820
in order to get some
terminology that'll

00:18:15.820 --> 00:18:18.471
help us understand faults.

00:18:18.471 --> 00:18:20.220
So one thing that could
happen is that you

00:18:20.220 --> 00:18:22.780
could have a disk failure.

00:18:22.780 --> 00:18:24.360
So the disc could just fail.

00:18:24.360 --> 00:18:28.130
And one example of a disk
failure is the disk fails

00:18:28.130 --> 00:18:30.385
and then it just stops working.

00:18:30.385 --> 00:18:32.010
And it tells the
database system that's

00:18:32.010 --> 00:18:34.510
trying to read and write data
from it that it isn't working.

00:18:36.720 --> 00:18:40.192
So if that kind of failure
happens where this module here

00:18:40.192 --> 00:18:41.650
with this component
just completely

00:18:41.650 --> 00:18:44.870
stops and tells the higher-level
module that it stopped,

00:18:44.870 --> 00:18:46.230
that's an example of a failure.

00:18:46.230 --> 00:18:47.646
That's called a
fail stop failure.

00:18:50.522 --> 00:18:51.980
And more generally,
any module that

00:18:51.980 --> 00:18:54.370
tells the higher-level
module that it just

00:18:54.370 --> 00:18:58.430
stops working without reporting
anything else, no outputs,

00:18:58.430 --> 00:19:00.070
that's fail stop.

00:19:00.070 --> 00:19:04.020
Of course, you could have disks.

00:19:04.020 --> 00:19:07.430
And you might have failures
that aren't fail stop.

00:19:07.430 --> 00:19:09.870
You might have
something where there

00:19:09.870 --> 00:19:11.990
is some kind of error
checking associated

00:19:11.990 --> 00:19:13.570
with every sector on your disk.

00:19:13.570 --> 00:19:17.650
And, disk might start
reporting errors that

00:19:17.650 --> 00:19:19.557
say that this is a bad sector.

00:19:19.557 --> 00:19:21.890
So, it doesn't fail stop, but
it tells the higher level,

00:19:21.890 --> 00:19:25.100
the database system in this
case that some data that's read,

00:19:25.100 --> 00:19:27.260
or some data that's
been written,

00:19:27.260 --> 00:19:29.740
there's a bad
sector, which means

00:19:29.740 --> 00:19:34.450
that the checksum doesn't match
the data that's being read.

00:19:34.450 --> 00:19:37.730
When you have an
error like that where

00:19:37.730 --> 00:19:39.720
it doesn't stop working
but it tells you

00:19:39.720 --> 00:19:42.780
that something bad is going on,
that's an example of a failure.

00:19:42.780 --> 00:19:44.250
That's called a
fail fast failure.

00:19:47.041 --> 00:19:49.540
I actually don't think these
terms, that most of these terms

00:19:49.540 --> 00:19:50.665
are particularly important.

00:19:50.665 --> 00:19:52.834
Fail stop is usually
important and worth knowing,

00:19:52.834 --> 00:19:54.500
but the reason to go
through these terms

00:19:54.500 --> 00:19:57.900
is more to understand that there
are various kinds of failures

00:19:57.900 --> 00:19:58.470
possible.

00:19:58.470 --> 00:20:00.094
So in one case it stops working.

00:20:00.094 --> 00:20:01.510
In another case,
it just tells you

00:20:01.510 --> 00:20:03.770
that it's not working
but continues working.

00:20:03.770 --> 00:20:06.240
It tells you that
certain operations

00:20:06.240 --> 00:20:07.640
haven't been correctly done.

00:20:10.610 --> 00:20:13.420
Now, another thing that could
happen when, for example,

00:20:13.420 --> 00:20:19.430
the disc has fail
stop, has fail fast

00:20:19.430 --> 00:20:21.420
is that the database
system might decide

00:20:21.420 --> 00:20:25.980
that right operations, you're
not allowed to write things

00:20:25.980 --> 00:20:30.050
to disk because the disk is
either fail completely or is

00:20:30.050 --> 00:20:31.240
fail fast.

00:20:31.240 --> 00:20:35.700
But it might allow actions or
requests that are read only.

00:20:35.700 --> 00:20:37.290
So, for example, it
might allow users

00:20:37.290 --> 00:20:38.890
to come up to an ATM
machine, and just

00:20:38.890 --> 00:20:40.890
read how much money they
have from their account

00:20:40.890 --> 00:20:43.850
because it might be that there
is a cache of the data that's

00:20:43.850 --> 00:20:45.940
in memory in the database.

00:20:45.940 --> 00:20:49.170
So it might allow read-only
actions, in which case

00:20:49.170 --> 00:20:53.670
the system's perform
is functioning

00:20:53.670 --> 00:20:55.720
with only a subset
of the actions

00:20:55.720 --> 00:20:57.440
that it's supposed to be taking.

00:20:57.440 --> 00:20:59.460
And if that happens,
that kind of failure

00:20:59.460 --> 00:21:07.560
is called a fail soft failure,
where not all of the interfaces

00:21:07.560 --> 00:21:09.620
are available, but a
subset of the interfaces

00:21:09.620 --> 00:21:11.120
are available and
correctly working.

00:21:14.424 --> 00:21:16.340
And the last kind of
failure that could happen

00:21:16.340 --> 00:21:21.334
is that in this
example, let's say

00:21:21.334 --> 00:21:23.000
that failures are
occurring when there's

00:21:23.000 --> 00:21:27.100
a large number of people trying
to make these requests at ATMs.

00:21:27.100 --> 00:21:31.080
And, there is some
problems that have arisen.

00:21:31.080 --> 00:21:33.840
And somebody determines
that the problem

00:21:33.840 --> 00:21:35.640
arises when there
is too many people

00:21:35.640 --> 00:21:38.465
gaining access to the
system at the same time.

00:21:38.465 --> 00:21:40.090
And the system might
now move to a mold

00:21:40.090 --> 00:21:42.980
where it allows only a small
number of actions at a time,

00:21:42.980 --> 00:21:44.970
a small number of concurrent
actions at a time,

00:21:44.970 --> 00:21:46.330
or maybe one action at a time.

00:21:46.330 --> 00:21:49.320
So, one user can come at a
time to the system, which

00:21:49.320 --> 00:21:52.990
means the systems, there
has been a failure,

00:21:52.990 --> 00:21:55.690
but the way the system's dealing
with it is that it determines

00:21:55.690 --> 00:22:01.210
that the failure doesn't get
triggered when the load is low.

00:22:01.210 --> 00:22:04.334
So it might function
at low performance.

00:22:04.334 --> 00:22:06.000
It still provides all
of the interfaces,

00:22:06.000 --> 00:22:09.190
but just at very low performance
or at lower performance.

00:22:09.190 --> 00:22:11.315
And that kind of behavior
is called failsafe.

00:22:14.120 --> 00:22:17.450
So it's moved to a mode
where it's just scaled back

00:22:17.450 --> 00:22:19.310
how much work it's
willing to do,

00:22:19.310 --> 00:22:21.365
and does it at
degraded performance.

00:22:42.830 --> 00:22:49.030
OK, so the plan now is
for the rest of today,

00:22:49.030 --> 00:22:51.130
so tomorrow from
the next lecture on,

00:22:51.130 --> 00:22:53.470
what we're going to do
is understand algorithms

00:22:53.470 --> 00:22:57.500
for how we go about and how
you build systems that actually

00:22:57.500 --> 00:23:00.720
do one or all of these in
order to meet the specification

00:23:00.720 --> 00:23:02.055
that we want.

00:23:02.055 --> 00:23:04.430
But before we do that you have
to understand a little bit

00:23:04.430 --> 00:23:06.652
about models for faults.

00:23:06.652 --> 00:23:08.360
In order to build
fault tolerant systems,

00:23:08.360 --> 00:23:10.420
it's usually a good
idea to understand

00:23:10.420 --> 00:23:18.634
a little bit more
quantitatively models or faults

00:23:18.634 --> 00:23:19.550
that occur in systems.

00:23:19.550 --> 00:23:21.010
And primarily,
this discussion is

00:23:21.010 --> 00:23:23.590
going to be focused
on hardware faults

00:23:23.590 --> 00:23:26.060
because most people don't
understand how software

00:23:26.060 --> 00:23:27.682
faults are to be modeled.

00:23:27.682 --> 00:23:29.140
But since all our
systems are going

00:23:29.140 --> 00:23:31.127
to be built on hardware,
for example discs

00:23:31.127 --> 00:23:32.710
are going to be
really, really common.

00:23:32.710 --> 00:23:34.418
Our network links are
going to be common.

00:23:34.418 --> 00:23:36.990
And all of those conform
nicely to models.

00:23:36.990 --> 00:23:39.230
It's worth understanding
how that works.

00:23:39.230 --> 00:23:43.230
So, for example, a
disk manufacturer

00:23:43.230 --> 00:23:47.750
might report that the error rate
of undetected errors, so disks

00:23:47.750 --> 00:23:50.180
usually have a fair amount
of error detection in them.

00:23:50.180 --> 00:23:53.320
But, they might report that the
error rate of undetected errors

00:23:53.320 --> 00:23:56.100
is, say, ten to the minus
12 or ten to the minus 13.

00:23:56.100 --> 00:23:57.840
And that number
looks really small.

00:23:57.840 --> 00:24:00.180
That says that out
of that many bits,

00:24:00.180 --> 00:24:03.362
maybe one bit is corrupted,
and you can't detect it.

00:24:03.362 --> 00:24:04.820
But, you have to
realize that given

00:24:04.820 --> 00:24:07.650
modern workloads, for example
take Google as an example

00:24:07.650 --> 00:24:09.757
that you saw from
last recitation,

00:24:09.757 --> 00:24:12.340
the amount of data that's being
stored in the system like that

00:24:12.340 --> 00:24:16.160
or in the world in general is
so huge that a ten to the minus

00:24:16.160 --> 00:24:18.230
13th error rate means
that you're probably

00:24:18.230 --> 00:24:21.570
seeing some bad data and
file that you can never fix

00:24:21.570 --> 00:24:26.700
or never detect
every couple of days.

00:24:26.700 --> 00:24:29.750
Network people would
tell you that fiber optic

00:24:29.750 --> 00:24:32.994
links have an error rate of
one error in ten to the 12th.

00:24:32.994 --> 00:24:35.160
But you have to realize
that these links are sending

00:24:35.160 --> 00:24:37.940
so many gigabits per second
that one error in ten

00:24:37.940 --> 00:24:39.980
to the 12th means
something like there's

00:24:39.980 --> 00:24:46.204
an error that you can't detect
maybe every couple of hours.

00:24:46.204 --> 00:24:48.370
What that really means is
that at the higher layers,

00:24:48.370 --> 00:24:49.744
you need to do
more work in order

00:24:49.744 --> 00:24:52.350
to make sure that your data
is protected because you can't

00:24:52.350 --> 00:24:55.110
actually rely on the fact that
your underlying components have

00:24:55.110 --> 00:24:57.680
these amazingly low numbers
because there's so much data

00:24:57.680 --> 00:25:00.827
going on, being sent or
being stored on these systems

00:25:00.827 --> 00:25:03.160
that you need to have other
techniques at a higher layer

00:25:03.160 --> 00:25:05.359
to protect, if you really
care about the integrity

00:25:05.359 --> 00:25:05.900
of your data.

00:25:08.430 --> 00:25:10.170
In addition to
these raw numbers,

00:25:10.170 --> 00:25:12.770
there's two or
three other metrics

00:25:12.770 --> 00:25:17.922
that people use to understand
faults and failures.

00:25:17.922 --> 00:25:20.005
The first one is the number
of tolerated failures.

00:25:25.330 --> 00:25:28.760
So, for example, if you
build a system to store data

00:25:28.760 --> 00:25:32.550
and you're worried about discs
failing or discs reporting

00:25:32.550 --> 00:25:35.010
at [earnest?] values, you might
replicate that data across

00:25:35.010 --> 00:25:36.440
many, many discs.

00:25:36.440 --> 00:25:38.040
And then when you
design your system,

00:25:38.040 --> 00:25:40.289
one of the things you would
want to analyze and report

00:25:40.289 --> 00:25:42.830
is the number of tolerated
failures of discs.

00:25:42.830 --> 00:25:46.350
So, for example, if you build
a system out of seven discs,

00:25:46.350 --> 00:25:49.740
you might say that you can
handle up to two failed disks,

00:25:49.740 --> 00:25:51.540
or simply like that,
depending on how

00:25:51.540 --> 00:25:53.610
you've designed your system.

00:25:53.610 --> 00:25:56.160
And that's usually a good thing
to report because then people

00:25:56.160 --> 00:25:58.300
who use your system can
know how to provision

00:25:58.300 --> 00:26:04.260
or engineer your system.

00:26:04.260 --> 00:26:06.360
The second metric
which we're going

00:26:06.360 --> 00:26:08.619
to spend a few more minutes
on is something called

00:26:08.619 --> 00:26:09.660
the mean time to failure.

00:26:21.400 --> 00:26:24.750
And what this says is
it takes a model where

00:26:24.750 --> 00:26:26.880
you have a system that
starts at time zero,

00:26:26.880 --> 00:26:27.800
and it's running fine.

00:26:27.800 --> 00:26:30.190
And then at some point
in time, it fails.

00:26:30.190 --> 00:26:33.570
And then, when it
fails, that error

00:26:33.570 --> 00:26:36.660
is made known to an operator.

00:26:36.660 --> 00:26:38.090
Or it's made known
to some higher

00:26:38.090 --> 00:26:40.420
level that has a plan
to work around it

00:26:40.420 --> 00:26:42.232
to repair this failure.

00:26:42.232 --> 00:26:43.940
And then, once the
failure gets repaired,

00:26:43.940 --> 00:26:46.064
it takes some time for the
failure to get repaired.

00:26:46.064 --> 00:26:48.240
And once it's repaired
it starts running again.

00:26:48.240 --> 00:26:51.100
And then it fails at some
other point in the future.

00:26:51.100 --> 00:26:53.640
And when it goes through the
cycle of failures and repairs,

00:26:53.640 --> 00:26:57.300
you end up with a timeline
that looks like this.

00:26:57.300 --> 00:27:00.160
So you might start at time zero.

00:27:00.160 --> 00:27:03.450
And the system is working fine.

00:27:03.450 --> 00:27:06.350
And then there is a
failure that happens here.

00:27:06.350 --> 00:27:09.820
And then the system is down
for a certain period of time.

00:27:09.820 --> 00:27:13.560
And then somebody
repairs the system,

00:27:13.560 --> 00:27:15.902
and then it continues to work.

00:27:15.902 --> 00:27:17.360
And then it fails
again, and so on.

00:27:27.050 --> 00:27:28.860
And so, for each of
the durations of time

00:27:28.860 --> 00:27:30.520
that the system
is working, let's

00:27:30.520 --> 00:27:32.730
assume it's starting
at zero, each of these

00:27:32.730 --> 00:27:35.460
defines a period of
time that I'm going

00:27:35.460 --> 00:27:38.090
to call TTF or time to fail.

00:27:38.090 --> 00:27:41.780
OK, so this is the first
time to fail interval.

00:27:41.780 --> 00:27:53.710
This is the second time to
fail This is the second time

00:27:53.710 --> 00:27:55.710
to fail interval,
time to repair,

00:27:55.710 --> 00:27:59.770
and this is the third time
to fail interval, and so on.

00:27:59.770 --> 00:28:02.320
And analogously
in between here, I

00:28:02.320 --> 00:28:04.330
could define these time
to repair intervals,

00:28:04.330 --> 00:28:09.940
TTR1, TTR2, and so on.

00:28:09.940 --> 00:28:13.380
So, the mean time to failure is
just the mean of these values.

00:28:13.380 --> 00:28:14.840
There's some duration of time.

00:28:14.840 --> 00:28:16.298
You're like, three
hours the system

00:28:16.298 --> 00:28:18.330
worked, and then it crashed.

00:28:18.330 --> 00:28:19.220
That's TTF1.

00:28:19.220 --> 00:28:22.020
And then, somebody to repair
it worked now for six hours.

00:28:22.020 --> 00:28:23.300
That's TTF2, and so on.

00:28:23.300 --> 00:28:26.140
If you run your system for
a long enough period of time

00:28:26.140 --> 00:28:28.750
like a disk or anything
else, and then you

00:28:28.750 --> 00:28:33.190
observe all these time
to fail samples, and take

00:28:33.190 --> 00:28:36.870
the mean of that, that tells
you a mean time to failure.

00:28:36.870 --> 00:28:38.300
The reason this
is interesting is

00:28:38.300 --> 00:28:40.960
that you could run your system
for a really long period

00:28:40.960 --> 00:28:44.620
of time, and build up a
metric called availability.

00:28:49.800 --> 00:28:52.380
So, for example, if
you're running a website,

00:28:52.380 --> 00:28:54.760
and the way this
website works is it

00:28:54.760 --> 00:28:57.640
runs for a while and then every
once in awhile it crashes.

00:28:57.640 --> 00:29:00.629
So its network crashes and
people can't get to you.

00:29:00.629 --> 00:29:02.670
So you could run this for
months or years on end,

00:29:02.670 --> 00:29:05.439
and then observe these values.

00:29:05.439 --> 00:29:06.730
You could run this every month.

00:29:06.730 --> 00:29:08.510
You could decide what
availability is, and decide

00:29:08.510 --> 00:29:09.926
if it's good enough
or if you want

00:29:09.926 --> 00:29:11.660
to make it higher or lower.

00:29:11.660 --> 00:29:14.310
So you could now define
your availability

00:29:14.310 --> 00:29:18.540
to be the fraction of time that
your system is up and running.

00:29:18.540 --> 00:29:21.050
And the fraction of time that
the system is up and running

00:29:21.050 --> 00:29:23.250
is the fraction of
time on this timeline

00:29:23.250 --> 00:29:29.240
that you have this
kind of shaded thing.

00:29:29.240 --> 00:29:31.740
OK, so that's just equal
to the sum of all the time

00:29:31.740 --> 00:29:35.970
to failure numbers
divided by the total time.

00:29:35.970 --> 00:29:38.540
And the total time is
just the sum of all

00:29:38.540 --> 00:29:40.260
the TTF's and the TTR's.

00:29:46.150 --> 00:29:49.880
OK, and that's what availability
means is the fraction of time

00:29:49.880 --> 00:29:54.030
that your system
is available is up.

00:29:54.030 --> 00:29:57.120
Now, if you divide both the
top and the bottom by N,

00:29:57.120 --> 00:30:06.560
this number works out to
be the mean time to failure

00:30:06.560 --> 00:30:10.410
divided by the mean time to
failure plus the mean time

00:30:10.410 --> 00:30:10.930
to repair.

00:30:18.420 --> 00:30:20.890
So this is a useful notion
because now it tells you that

00:30:20.890 --> 00:30:23.640
you can [point?] your system
for a very long period of time,

00:30:23.640 --> 00:30:26.994
and build up a mean estimate,
mean values of the time

00:30:26.994 --> 00:30:28.410
to failure and the
time to repair,

00:30:28.410 --> 00:30:32.140
and just come up with the
notion of what the availability

00:30:32.140 --> 00:30:33.020
of the system is.

00:30:33.020 --> 00:30:35.850
And then, decide based on
whether it's high enough or not

00:30:35.850 --> 00:30:38.762
whether you want to improve
some aspect of the system

00:30:38.762 --> 00:30:39.970
and whether it's worth doing.

00:30:44.540 --> 00:30:47.820
So it turns out this
mean time to failure,

00:30:47.820 --> 00:30:52.840
and therefore availability
is related for components

00:30:52.840 --> 00:30:56.300
to a notion called
the failure rate.

00:30:56.300 --> 00:30:58.270
So let me define
the failure rate.

00:31:09.200 --> 00:31:12.840
So the failure rate
is defined, it's

00:31:12.840 --> 00:31:14.460
also called a hazard function.

00:31:14.460 --> 00:31:16.930
That's what people use the
term H of T, the hazard rate.

00:31:16.930 --> 00:31:18.510
That's defined as
the probability

00:31:18.510 --> 00:31:25.780
that you have a failure of a
system or a component in time,

00:31:25.780 --> 00:31:31.950
T to T plus delta T,
given that it's working,

00:31:31.950 --> 00:31:36.360
we'll say, OK, at time T, OK?

00:31:36.360 --> 00:31:37.910
So it's a conditional
probability.

00:31:37.910 --> 00:31:40.160
It's the probability that
you'll fail in the next time

00:31:40.160 --> 00:31:42.702
instant given that it's
correctly working and has

00:31:42.702 --> 00:31:43.660
been correctly working.

00:31:43.660 --> 00:31:46.120
It's correctly
working at time T.

00:31:46.120 --> 00:31:48.720
So, if you look at
this for a disk,

00:31:48.720 --> 00:31:52.270
most discs look like the
picture shown up here.

00:31:52.270 --> 00:31:53.900
This is also called
the bathtub curve

00:31:53.900 --> 00:31:56.480
because it looks like a bathtub.

00:31:56.480 --> 00:31:58.960
What you see at the left
end here are new discs.

00:31:58.960 --> 00:32:01.490
So, the X axis here shows time.

00:32:01.490 --> 00:32:03.319
I guess it's a
little shifted below.

00:32:03.319 --> 00:32:05.610
You can't read some stuff
that's written at the bottom.

00:32:05.610 --> 00:32:07.840
But the X axis shows
time, and the Y axis

00:32:07.840 --> 00:32:09.300
shows the failure rate.

00:32:09.300 --> 00:32:11.740
So, when you take a new
component like a new light bulb

00:32:11.740 --> 00:32:14.970
or a new disc or anything new,
there is a pretty high chance

00:32:14.970 --> 00:32:18.730
that it'll actually fail because
manufacturers, when they sell

00:32:18.730 --> 00:32:21.120
you stuff, don't
actually sell you things

00:32:21.120 --> 00:32:23.411
without actually
burning them in first.

00:32:23.411 --> 00:32:25.410
So for semiconductors,
that's also called yield.

00:32:25.410 --> 00:32:27.160
They make a whole
number of chips,

00:32:27.160 --> 00:32:28.840
and then they're
burning a few, and then

00:32:28.840 --> 00:32:30.360
they only give you the rest.

00:32:30.360 --> 00:32:32.520
And the stuff that's...
survive the burn in

00:32:32.520 --> 00:32:34.680
and the fraction that
survives the burning

00:32:34.680 --> 00:32:36.570
is also called the yield.

00:32:36.570 --> 00:32:39.180
So what you see on our left,
the colorful term for that

00:32:39.180 --> 00:32:41.330
is infant mortality.

00:32:41.330 --> 00:32:45.270
So it's things that die when
they are really, really young.

00:32:45.270 --> 00:32:48.220
And then, once you get
past the early mortality,

00:32:48.220 --> 00:32:52.660
you end up with a flat failure,
a conditional probability

00:32:52.660 --> 00:32:53.950
for failure.

00:32:53.950 --> 00:32:57.100
And what this says
is that, and I'll

00:32:57.100 --> 00:32:58.490
get to this and a little bit.

00:32:58.490 --> 00:33:01.370
But what this says is that once
you are in the flat region,

00:33:01.370 --> 00:33:03.360
it says that the
probability of failure

00:33:03.360 --> 00:33:06.110
is essentially independent of
what's happened in the past.

00:33:09.240 --> 00:33:11.170
And then you stay
here for a while.

00:33:11.170 --> 00:33:13.721
And then if the system
has been operating

00:33:13.721 --> 00:33:15.470
like a disk has been
operating for awhile,

00:33:15.470 --> 00:33:17.970
let's say three years or five
years typically for discs,

00:33:17.970 --> 00:33:19.590
then the probability
of failure starts

00:33:19.590 --> 00:33:22.630
going up again because that's
usually due to wear and tear,

00:33:22.630 --> 00:33:26.750
which for hardware components
is certainly the case.

00:33:28.724 --> 00:33:30.390
There are a couple
of interesting things

00:33:30.390 --> 00:33:33.640
about this curve that you
should realize, particularly

00:33:33.640 --> 00:33:37.120
when you read specifications
for things like discs.

00:33:37.120 --> 00:33:39.540
Disc manufacturers
will report a number,

00:33:39.540 --> 00:33:41.982
like the mean time
to failure number.

00:33:41.982 --> 00:33:43.440
And the mean time
to failure number

00:33:43.440 --> 00:33:44.981
that the report
might usually, I mean

00:33:44.981 --> 00:33:48.767
for discs might be 200,000
hours or 300,000 hours.

00:33:48.767 --> 00:33:50.600
I mean, that's a really
long period of time.

00:33:50.600 --> 00:33:52.780
That's 30 years.

00:33:52.780 --> 00:33:54.460
So when you look at
a number like that,

00:33:54.460 --> 00:33:56.750
you have to ask
whether what it means

00:33:56.750 --> 00:33:58.390
is that discs really
survive 30 years.

00:33:58.390 --> 00:34:00.970
And anybody who
is on the computer

00:34:00.970 --> 00:34:06.750
knows, you know, most discs
don't survive 30 years.

00:34:06.750 --> 00:34:09.250
So they are actually
reporting one

00:34:09.250 --> 00:34:12.219
over the reciprocal of this
thing at the flat region

00:34:12.219 --> 00:34:14.830
of the curve because this
conditional failure probability

00:34:14.830 --> 00:34:19.750
rate, at this operation
time when the only reason

00:34:19.750 --> 00:34:21.940
things fail is completely
random failures

00:34:21.940 --> 00:34:24.060
not related to wear and tear.

00:34:24.060 --> 00:34:26.120
So when disc manufacturers
report a mean time

00:34:26.120 --> 00:34:28.520
to failure number, they are
actually reporting something

00:34:28.520 --> 00:34:33.719
that that's the time that
you're disc is likely to work.

00:34:33.719 --> 00:34:37.710
What that number really says is
that during the period of time

00:34:37.710 --> 00:34:39.550
that the disc is
normally working,

00:34:39.550 --> 00:34:41.989
the probability of
a random failure

00:34:41.989 --> 00:34:45.344
is one over the mean
time to failure.

00:34:45.344 --> 00:34:46.469
That's what it really says.

00:34:46.469 --> 00:34:49.960
So the other number that
they also report, often

00:34:49.960 --> 00:34:53.462
in smaller print, is it the
expected operational lifetime.

00:34:53.462 --> 00:34:55.920
And that's usually something
like three years or four years

00:34:55.920 --> 00:34:58.310
or five years, whatever
it is they report.

00:34:58.310 --> 00:35:00.490
And that's where this
thing starts going up,

00:35:00.490 --> 00:35:04.066
and beyond a point where
the probability of failures

00:35:04.066 --> 00:35:05.440
above some threshold,
they report

00:35:05.440 --> 00:35:09.410
that as the expected
operational lifetime.

00:35:09.410 --> 00:35:12.390
Now, for software, this
curve doesn't actually apply,

00:35:12.390 --> 00:35:16.119
or at least nobody really knows
what the curve is for software.

00:35:16.119 --> 00:35:18.410
What is true for software,
though, is infant mortality,

00:35:18.410 --> 00:35:20.493
things were the conditional
probability of failure

00:35:20.493 --> 00:35:23.420
is high for new software, which
is why you are sort of well

00:35:23.420 --> 00:35:25.800
advised, the moment the
new upgrade of something

00:35:25.800 --> 00:35:28.250
comes around, most
people who are prudent

00:35:28.250 --> 00:35:31.352
wait a little bit to just make
sure all the bugs are out,

00:35:31.352 --> 00:35:32.810
and things get a
little bit stable.

00:35:32.810 --> 00:35:33.893
So they wait a few months.

00:35:33.893 --> 00:35:36.260
You are always a couple
of revisions behind.

00:35:36.260 --> 00:35:39.300
So I do believe that for
software, the left side

00:35:39.300 --> 00:35:40.530
of the curve holds.

00:35:40.530 --> 00:35:42.640
It's totally unclear that
there is a flat region,

00:35:42.640 --> 00:35:44.210
and it's totally
unclear that things

00:35:44.210 --> 00:35:50.240
start rising again with age.

00:35:50.240 --> 00:35:52.420
So the reason for
this curve, being

00:35:52.420 --> 00:35:55.950
the way it is, is a lot of
this is based on the fact

00:35:55.950 --> 00:35:58.060
that things are mechanical
and have wear and tear.

00:35:58.060 --> 00:35:59.830
But the motivation
for this kind of curve

00:35:59.830 --> 00:36:04.120
actually comes from demographics
and from human lifespans.

00:36:04.120 --> 00:36:07.380
So this is a picture
that I got from,

00:36:07.380 --> 00:36:10.030
it's a website
called mortality.org,

00:36:10.030 --> 00:36:17.010
which is a research project
run by demographers.

00:36:17.010 --> 00:36:18.430
And they have amazing data.

00:36:18.430 --> 00:36:21.460
There's way more data available
but human life expectancy

00:36:21.460 --> 00:36:24.800
and demographics than
anything about software.

00:36:24.800 --> 00:36:27.100
What this shows here is
actually the same bathtub curve

00:36:27.100 --> 00:36:28.360
as in the previous chart.

00:36:28.360 --> 00:36:30.480
It just doesn't look
like that because the Y

00:36:30.480 --> 00:36:32.940
axis is on a log scale.

00:36:32.940 --> 00:36:35.280
So given that it's
rising linearly

00:36:35.280 --> 00:36:38.730
between 0.001 and 0.01,
on a linear scale that

00:36:38.730 --> 00:36:40.360
looks essentially flat.

00:36:40.360 --> 00:36:44.500
So human beings for the
probability of death,

00:36:44.500 --> 00:36:46.300
at a certain time,
given that

00:36:46.300 --> 00:36:48.540
you are alive at a
certain time, that

00:36:48.540 --> 00:36:51.500
follows this curve here,
essentially a bathtub curve.

00:36:52.480 --> 00:36:54.320
At the left hand, of course,
there is infant mortality.

00:36:54.320 --> 00:36:55.680
This I think I pulled the data down.

00:36:55.680 --> 00:36:57.080
This is from an
article that appeared

00:36:57.080 --> 00:37:00.380
where the data for the
US population 1999.

00:37:00.380 --> 00:37:02.720
It starts off again
with infant mortality.

00:37:02.720 --> 00:37:04.890
And then it's flat for a while.

00:37:04.890 --> 00:37:07.114
Then it rises up.

00:37:07.114 --> 00:37:08.530
Now, there's a lot
of controversy,

00:37:08.530 --> 00:37:12.230
it turns out, for whether the
bathtub curve at the right end

00:37:12.230 --> 00:37:13.520
holds for human beings or not.

00:37:13.520 --> 00:37:14.895
And, some people
believe it does,

00:37:14.895 --> 00:37:16.490
and some people
believe it doesn't.

00:37:16.490 --> 00:37:18.720
But the point here is that
for human beings anyway,

00:37:18.720 --> 00:37:22.470
the rule of thumb that insurance
companies use for determining

00:37:22.470 --> 00:37:27.200
insurance premiums is
that the log of the death

00:37:27.200 --> 00:37:30.740
rate, the log of the probability
of dying in a certain age

00:37:30.740 --> 00:37:35.986
grows linearly with the time
that somebody has been alive.

00:37:35.986 --> 00:37:37.360
And that's what
this graph shows,

00:37:37.360 --> 00:37:40.710
that on large scale on
the Y axis, you have a line.

00:37:40.710 --> 00:37:43.950
And that's what they use for
determining insurance premiums.

00:37:47.310 --> 00:37:51.700
OK, so the reason this bathtub
curve is actually useful

00:37:51.700 --> 00:37:56.180
is, so if you go back,
let's go back here.

00:37:56.180 --> 00:37:57.890
The reason both these
numbers are useful,

00:37:57.890 --> 00:37:59.520
the flat portion of
the bathtub curve

00:37:59.520 --> 00:38:02.190
and the expected operational
lifetime is the following.

00:38:02.190 --> 00:38:04.090
It's not like this flat
portion of the curve

00:38:04.090 --> 00:38:06.360
where the disc manufacturer
reports the mean time

00:38:06.360 --> 00:38:06.860
to failure.

00:38:06.860 --> 00:38:08.000
That's 30 years.

00:38:08.000 --> 00:38:10.384
It's not like
that's useless even

00:38:10.384 --> 00:38:12.800
though you're disc only might
run for three to four years.

00:38:12.800 --> 00:38:17.390
The reason is that if you
have a project, if you have

00:38:17.390 --> 00:38:19.850
a system where you
are willing to upgrade

00:38:19.850 --> 00:38:22.020
your disk every three
years where you've budgeted

00:38:22.020 --> 00:38:26.070
for upgrading your discs
every said three years, then

00:38:26.070 --> 00:38:30.290
you might be better off buying a
disk whose expected lifetime is

00:38:30.290 --> 00:38:36.230
only five years but whose
flat portion is really low.

00:38:36.230 --> 00:38:40.050
So in particular, if you're
given to discs, one of which

00:38:40.050 --> 00:38:41.970
has a curve that
looks like that,

00:38:41.970 --> 00:38:49.350
and another that has a curve
that looks like that, and let's

00:38:49.350 --> 00:38:55.410
say this is five years,
and this is three years.

00:38:55.410 --> 00:38:57.290
If you're building
a system and you've

00:38:57.290 --> 00:38:59.740
budgeted for upgrading your
discs every four years,

00:38:59.740 --> 00:39:03.080
then you're probably
better off using the thing

00:39:03.080 --> 00:39:05.510
with the lower
value of mean time

00:39:05.510 --> 00:39:07.822
to failure because its
expected lifetime is longer.

00:39:07.822 --> 00:39:10.030
But if you're willing to
upgrade your discs every two

00:39:10.030 --> 00:39:12.730
years or one year,
then you might

00:39:12.730 --> 00:39:15.225
be better off with this thing
here with the lower meantime

00:39:15.225 --> 00:39:17.600
to failure, even though its
expected operational lifetime

00:39:17.600 --> 00:39:18.240
is smaller.

00:39:18.240 --> 00:39:20.300
So both of these numbers
are actually meaningful,

00:39:20.300 --> 00:39:24.111
and it depends a lot on how
you're planning to use it.

00:39:24.111 --> 00:39:26.110
I mean, it's a lot like
spare tires on your car.

00:39:26.110 --> 00:39:28.310
I mean, the spare tire
was run perfectly fine

00:39:28.310 --> 00:39:30.560
as long as you don't
exceed 100 miles.

00:39:30.560 --> 00:39:32.280
And the moment you
exceed 100 miles, then

00:39:32.280 --> 00:39:33.750
you don't want to use it at all.

00:39:33.750 --> 00:39:35.650
And it might be a lot cheaper
to build the spare tire

00:39:35.650 --> 00:39:37.660
that runs just 100 miles
because the users, you

00:39:37.660 --> 00:39:40.440
are guaranteed that you
will get to a repair shop

00:39:40.440 --> 00:39:41.420
within 100 miles.

00:39:41.420 --> 00:39:46.000
It's the same concept.

00:39:46.000 --> 00:39:47.620
OK.

00:40:02.020 --> 00:40:03.680
So one of the things
that we can define,

00:40:03.690 --> 00:40:06.140
once we have this
condition of failure rate

00:40:06.140 --> 00:40:08.820
is the reliability
of the system.

00:40:13.860 --> 00:40:16.597
We'll define that as
the probability, R of T,

00:40:16.597 --> 00:40:18.430
is the probability that
the system's working

00:40:18.430 --> 00:40:22.520
at time T, given that it
was working at time zero,

00:40:22.520 --> 00:40:24.840
or more generally assuming
that everything is always

00:40:24.840 --> 00:40:27.610
working at time zero,
it's the probability

00:40:27.610 --> 00:40:37.220
that you're OK at time T.

00:40:37.220 --> 00:40:40.630
And it turns out that for
components in the flat region

00:40:40.630 --> 00:40:45.160
of this curve, H of T, the
conditional failure rate is

00:40:45.160 --> 00:40:50.260
a constant, on systems
that satisfy that,

00:40:50.260 --> 00:40:53.020
and would satisfy the property
that the actual unconditional

00:40:53.020 --> 00:40:56.070
failure rate is a [memory-less?]
process where the probability

00:40:56.070 --> 00:40:58.980
of failure doesn't depend on how
long the system's been running.

00:40:58.980 --> 00:41:00.563
It turns out that
for the systems that

00:41:00.563 --> 00:41:03.480
satisfy those conditions,
which apparently discs

00:41:03.480 --> 00:41:06.900
do in the operation
when they're actually

00:41:06.900 --> 00:41:09.730
not at the right edge of
the curve, which discs do,

00:41:09.730 --> 00:41:13.170
the reliability,
this function goes

00:41:13.170 --> 00:41:15.520
as the very nice,
simple function, which

00:41:15.520 --> 00:41:18.580
is an exponential decaying
function, E to the minus

00:41:18.580 --> 00:41:20.200
T over MTTF.

00:41:20.200 --> 00:41:21.710
And this is under
two conditions.

00:41:21.710 --> 00:41:24.340
H of T has to be flat, and
the unconditional failure rate

00:41:24.340 --> 00:41:26.256
has to be something that
doesn't depend on how

00:41:26.256 --> 00:41:27.880
long the system's been running.

00:41:27.880 --> 00:41:30.570
And for those systems,
it's not hard to show

00:41:30.570 --> 00:41:33.110
that your reliability is
just an exponential decaying

00:41:33.110 --> 00:41:35.110
function, which means you
can do a lot of things

00:41:35.110 --> 00:41:37.530
like predict how long the
system is likely to be running,

00:41:37.530 --> 00:41:39.490
and so on.

00:41:39.490 --> 00:41:43.760
And that will tell you
when to upgrade things.

00:41:43.760 --> 00:41:48.090
OK, so given all of
this stuff, we now

00:41:48.090 --> 00:41:50.610
want techniques to cope with
failures, cope with faults.

00:41:50.610 --> 00:41:52.318
And that's what we're
going to be looking

00:41:52.318 --> 00:41:55.100
at for the next
few lectures, let's

00:41:55.100 --> 00:42:00.537
take one simple example
of a system first.

00:42:00.537 --> 00:42:02.370
And like I said before,
all of these systems

00:42:02.370 --> 00:42:04.390
use redundancy in some form.

00:42:04.390 --> 00:42:06.650
So the disk fails
at a certain rate.

00:42:06.650 --> 00:42:09.510
Just put in multiple disks,
replicate the data across them,

00:42:09.510 --> 00:42:10.940
and then hope that
things survive.

00:42:14.280 --> 00:42:17.170
So the first kind of
redundancy that you

00:42:17.170 --> 00:42:20.080
might have in the
example that I just

00:42:20.080 --> 00:42:24.130
talked about, spatial
redundancy, where the idea is

00:42:24.130 --> 00:42:27.270
that you have multiple
copies of the same thing,

00:42:27.270 --> 00:42:29.790
and the games we're
going to play all

00:42:29.790 --> 00:42:33.790
have to do with how we're going
to manage all these copies.

00:42:33.790 --> 00:42:37.180
And actually, this will turn
out to be quite complicated.

00:42:37.180 --> 00:42:40.360
We'll use these special copies
in a number of different ways.

00:42:40.360 --> 00:42:43.420
In some examples, we'll
apply error correcting codes

00:42:43.420 --> 00:42:48.790
to make copies of the data or
use other codes to replicate

00:42:48.790 --> 00:42:49.290
the data.

00:42:52.660 --> 00:42:54.970
We might replicate
data and make copies

00:42:54.970 --> 00:42:57.219
of data in the form of
logs which keep track of,

00:42:57.219 --> 00:42:58.510
you know, you run an operation.

00:42:58.510 --> 00:42:59.780
You store some results.

00:42:59.780 --> 00:43:02.100
But at the same time, before
you store those results,

00:43:02.100 --> 00:43:04.840
you also store something
in a log [surf?],

00:43:04.840 --> 00:43:07.200
the original data went away;
your log can tell you what

00:43:07.200 --> 00:43:09.540
to do.

00:43:09.540 --> 00:43:13.300
Or you might just do
plain and simple copies

00:43:13.300 --> 00:43:18.030
followed by voting.

00:43:18.030 --> 00:43:21.550
So the idea is that you have
multiple copies of something,

00:43:21.550 --> 00:43:23.590
and then you write
to all of them.

00:43:23.590 --> 00:43:25.350
In the simplest of schemes,
you might write to all of them,

00:43:25.350 --> 00:43:26.740
and then when you want
to read something,

00:43:26.740 --> 00:43:28.110
you read from all of them.

00:43:28.110 --> 00:43:30.350
And then just what?

00:43:30.350 --> 00:43:31.690
And go with the majority.

00:43:31.690 --> 00:43:35.339
So intuitively that can tolerate
a certain number of failures.

00:43:35.339 --> 00:43:37.130
And all of these
approaches have been used.

00:43:37.130 --> 00:43:39.690
And people will continue
to build systems

00:43:39.690 --> 00:43:41.930
along all of these ideas.

00:43:41.930 --> 00:43:44.270
But in addition,
we're also going

00:43:44.270 --> 00:43:48.460
to look at temporal redundancy.

00:43:48.460 --> 00:43:51.850
And the idea here
is try it again.

00:43:51.850 --> 00:43:54.890
So this is different
from copies.

00:43:54.890 --> 00:43:56.440
What it says is
you try something.

00:43:56.440 --> 00:43:58.856
If it doesn't work and you
determine that it doesn't work,

00:43:58.856 --> 00:44:01.570
try it again.

00:44:01.570 --> 00:44:05.040
So retry is an example
of temporal tricks.

00:44:05.040 --> 00:44:08.070
But it will turn out will also
use not just moving forward

00:44:08.070 --> 00:44:10.840
and retrying something that
we know should be retried,

00:44:10.840 --> 00:44:12.700
we'll also use the
trick of undoing things

00:44:12.700 --> 00:44:14.130
that we have done.

00:44:14.130 --> 00:44:16.860
So we'll move both
directions on the time axis.

00:44:16.860 --> 00:44:19.170
We'll retry stuff,
but at the same time

00:44:19.170 --> 00:44:22.630
we'll also undo things because
sometimes things have happened

00:44:22.630 --> 00:44:24.280
that shouldn't have happened.

00:44:24.280 --> 00:44:25.380
Things went half way.

00:44:25.380 --> 00:44:28.170
And we really want
to back things out.

00:44:28.170 --> 00:44:31.725
And we were going to use
both of these techniques.

00:44:35.980 --> 00:44:41.830
So one example of spatial
redundancy is a voting scheme.

00:44:46.360 --> 00:44:50.730
And you can apply this to many
different kinds of systems.

00:44:50.730 --> 00:44:53.800
But let's just apply it
to a simple example of,

00:44:53.800 --> 00:44:55.970
there is data stored
in multiple occasions.

00:44:55.970 --> 00:44:57.624
And then whenever
data is written,

00:44:57.624 --> 00:44:58.790
it's written to all of them.

00:44:58.790 --> 00:45:01.160
And then when you read it,
you read from all them,

00:45:01.160 --> 00:45:02.530
and then you vote.

00:45:05.700 --> 00:45:07.960
And in a simple model
where these components are

00:45:07.960 --> 00:45:10.660
fail stop, which means that
they fail; they just fail.

00:45:13.210 --> 00:45:17.910
Excuse me, on a simple
model where things are not

00:45:17.910 --> 00:45:21.550
fail stop or fail fast, but just
report back this data to you,

00:45:21.550 --> 00:45:24.035
so you are voting on it,
and these results come back.

00:45:24.035 --> 00:45:26.660
You've written something in them
and when you read things back,

00:45:26.660 --> 00:45:29.180
arbitrary values might get
returned if there's a failure.

00:45:29.180 --> 00:45:31.830
And if there's no failure here,
correct values get returned.

00:45:31.830 --> 00:45:34.572
Then as long as two of these
copies are correctly working,

00:45:34.572 --> 00:45:36.530
or two of these versions
are correctly working,

00:45:36.530 --> 00:45:38.238
then the vote will
actually return to you

00:45:38.238 --> 00:45:40.034
at the correct output.

00:45:40.034 --> 00:45:41.450
And that's the
idea behind voting.

00:45:41.450 --> 00:45:46.500
So if the reliability of each
of these components is some R,

00:45:46.500 --> 00:45:49.070
that's the probability that
the system's working at time T

00:45:49.070 --> 00:45:51.814
according to that
definition of reliability.

00:45:51.814 --> 00:45:53.980
Then, under the assumption
that these are completely

00:45:53.980 --> 00:45:55.810
independent of each other,
which is a big assumption,

00:45:55.810 --> 00:45:57.250
particularly for software.

00:45:57.250 --> 00:45:59.590
But it might be a reasonable
assumption for something

00:45:59.590 --> 00:46:01.430
like a disk, under the
assumption that these

00:46:01.430 --> 00:46:04.080
are completely independent,
then you could write out

00:46:04.080 --> 00:46:07.180
the reliability of this
three-voting scheme

00:46:07.180 --> 00:46:11.212
of this thing where you are
voting on three outputs.

00:46:11.212 --> 00:46:12.920
But you know that the
system is correctly

00:46:12.920 --> 00:46:16.230
working if any two of these
are correctly working.

00:46:16.230 --> 00:46:18.660
So that happens
under two conditions.

00:46:18.660 --> 00:46:22.930
Firstly, all three are
correctly working, right?

00:46:22.930 --> 00:46:25.050
Or, some two of the three
are correctly working.

00:46:25.050 --> 00:46:27.466
And, there's three ways in
which you could choose some two

00:46:27.466 --> 00:46:29.410
of the three.

00:46:29.410 --> 00:46:33.020
And, one of them
is wrongly working.

00:46:33.020 --> 00:46:34.870
And it turns out that
this number actually

00:46:34.870 --> 00:46:39.870
is very, very large, much larger
than R, when R is close to one.

00:46:39.870 --> 00:46:44.140
And, in general,
this is bigger than R

00:46:44.140 --> 00:46:47.170
when each of the components
has high enough reliability,

00:46:47.170 --> 00:46:48.290
namely, bigger than half.

00:46:54.650 --> 00:46:57.390
And so, let's say that
each of these components

00:46:57.390 --> 00:47:00.670
has a reliability of 95%.

00:47:00.670 --> 00:47:02.830
If you work this number
out, it turns out

00:47:02.830 --> 00:47:04.830
to be a pretty big number,
much higher than 95%,

00:47:04.830 --> 00:47:06.810
much closer to one.

00:47:06.810 --> 00:47:08.884
And, of course,
this kind of voting

00:47:08.884 --> 00:47:11.050
is a bad idea if the
reliability of these components

00:47:11.050 --> 00:47:11.840
is really low.

00:47:11.840 --> 00:47:14.492
I mean, if it's below one
half, then chances are that

00:47:14.492 --> 00:47:16.700
you're more likely the two
of them are just wrong,

00:47:16.700 --> 00:47:18.170
and you agree on that result.

00:47:18.170 --> 00:47:22.780
And it turns out to reduce
the reliability of the system.

00:47:22.780 --> 00:47:26.170
Now, in general, you might think
that you can build systems out

00:47:26.170 --> 00:47:30.010
of this basic voting idea,
and for various reasons

00:47:30.010 --> 00:47:32.310
it turns out that this idea
has limited applicability

00:47:32.310 --> 00:47:34.840
for the kinds of
things we want to do.

00:47:34.840 --> 00:47:36.950
And a lot of that
stems from the fact

00:47:36.950 --> 00:47:39.649
that these are not, in
general, in computer systems.

00:47:39.649 --> 00:47:41.940
It's very hard to design
components that are completely

00:47:41.940 --> 00:47:43.770
independent of each other.

00:47:43.770 --> 00:47:47.430
It might work out OK for certain
hardware components where

00:47:47.430 --> 00:47:49.480
you might do this
voting or other forms

00:47:49.480 --> 00:47:51.980
of spatial redundancy
that gives you

00:47:51.980 --> 00:47:55.130
these impressive
reliability numbers.

00:47:55.130 --> 00:47:57.490
But for software, this
independent assumption

00:47:57.490 --> 00:47:59.230
turns out to be
really hard to meet.

00:47:59.230 --> 00:48:01.230
And there is an approach to
building software like this.

00:48:01.230 --> 00:48:02.646
It's called N
version programming.

00:48:02.646 --> 00:48:04.550
And it's still a
topic of research

00:48:04.550 --> 00:48:08.681
where people are trying to build
software systems out of voting.

00:48:08.681 --> 00:48:11.180
But you have to pay a lot of
attention and care to make sure

00:48:11.180 --> 00:48:13.270
that these software
components that

00:48:13.270 --> 00:48:16.030
are doing the same function
are actually independent,

00:48:16.030 --> 00:48:18.400
maybe written by
different people running

00:48:18.400 --> 00:48:20.320
on different operating
systems, and so on.

00:48:20.320 --> 00:48:23.800
And that turns out to be a
pretty expensive undertaking.

00:48:23.800 --> 00:48:25.510
It's still sometimes
necessary if you

00:48:25.510 --> 00:48:27.400
want to build something
highly reliable.

00:48:27.400 --> 00:48:31.620
But because of its
cost it's not something

00:48:31.620 --> 00:48:34.190
that is the sort of
cookie-cutter technique

00:48:34.190 --> 00:48:36.862
for achieving highly
reliable software systems.

00:48:36.862 --> 00:48:39.070
And so what we're going to
see starting for next time

00:48:39.070 --> 00:48:40.986
is a somewhat different
approach for achieving

00:48:40.986 --> 00:48:43.742
software reliability that
doesn't rely on voting, which

00:48:43.742 --> 00:48:45.950
won't actually achieve the
same degree of reliability

00:48:45.950 --> 00:48:49.642
as these kinds of
systems, but will achieve

00:48:49.642 --> 00:48:51.600
a different kind of
reliability that we'll talk

00:48:51.600 --> 00:48:54.310
about starting from next time.

