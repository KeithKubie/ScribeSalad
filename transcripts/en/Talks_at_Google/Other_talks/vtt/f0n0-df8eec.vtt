WEBVTT
Kind: captions
Language: en

00:00:05.890 --> 00:00:07.890
MALE SPEAKER: Today, our
guest is Aneesh Chopra,

00:00:07.890 --> 00:00:11.180
who's the first CTO of
the United States, which

00:00:11.180 --> 00:00:11.930
is quite an honor.

00:00:11.930 --> 00:00:13.900
He was appointed
by President Obama.

00:00:13.900 --> 00:00:16.855
And he's written a book
called "Innovation State."

00:00:16.855 --> 00:00:18.230
And my first
question, of course,

00:00:18.230 --> 00:00:20.280
is, what motivated you
to write this book?

00:00:20.280 --> 00:00:22.060
Why did you feel the
need to get it out?

00:00:22.060 --> 00:00:23.640
ANEESH CHOPRA:
Well, first I have

00:00:23.640 --> 00:00:26.430
a sense of hope for the
country that may not

00:00:26.430 --> 00:00:28.510
be the current refrain
about Washington,

00:00:28.510 --> 00:00:30.316
looking a bit dysfunctional.

00:00:30.316 --> 00:00:31.690
I have a sense of
hope that we're

00:00:31.690 --> 00:00:35.180
going to solve the biggest
challenges of our generation.

00:00:35.180 --> 00:00:37.320
And we're going to
do it this decade.

00:00:37.320 --> 00:00:40.240
I also wanted to take a step
back and look historically.

00:00:40.240 --> 00:00:41.910
Have we had a
pioneering government?

00:00:41.910 --> 00:00:45.180
Has government been at pace
with the private sector

00:00:45.180 --> 00:00:47.640
and the incorporation of new
techniques, new technologies,

00:00:47.640 --> 00:00:51.780
new approaches to managing
and operating on work?

00:00:51.780 --> 00:00:54.030
And then last but not
least, I had accumulated

00:00:54.030 --> 00:00:56.310
a set of techniques
during my service

00:00:56.310 --> 00:01:00.050
to the President, what I call an
open innovators toolkit, that I

00:01:00.050 --> 00:01:03.300
thought if more
widely understood

00:01:03.300 --> 00:01:06.870
might help to arm up a
generation of entrepreneurs

00:01:06.870 --> 00:01:07.620
and innovators.

00:01:07.620 --> 00:01:09.440
Whether you were
inside the government

00:01:09.440 --> 00:01:11.270
or outside the
government, but looking

00:01:11.270 --> 00:01:14.050
to find ways to join in this
cause to solve problems.

00:01:14.050 --> 00:01:17.770
So the book is all three--
communicating a sense of hope,

00:01:17.770 --> 00:01:21.190
putting it in historical context
that we've been here before,

00:01:21.190 --> 00:01:23.640
and then last but not
least, a set of news

00:01:23.640 --> 00:01:25.520
you can use--
ideas that can help

00:01:25.520 --> 00:01:27.495
to bring about this
more innovative state.

00:01:27.495 --> 00:01:29.245
MALE SPEAKER: I'm glad
you're an optimist.

00:01:29.245 --> 00:01:31.203
I'm glad there's some
optimist still out there.

00:01:31.203 --> 00:01:33.460
I'd like to think I'm
an optimist as well.

00:01:33.460 --> 00:01:37.120
Do you think things are trending
more recently more negatively?

00:01:37.120 --> 00:01:38.804
I mean, given
things like Snowden

00:01:38.804 --> 00:01:40.720
and how that's impacting
the idea of open data

00:01:40.720 --> 00:01:42.960
for government, is that a
real challenge right now?

00:01:42.960 --> 00:01:48.690
ANEESH CHOPRA: The great news
is that in the wake of Snowden,

00:01:48.690 --> 00:01:52.600
you saw the political system
take a step back and say, what

00:01:52.600 --> 00:01:55.115
is the right role of
government on the issue of data

00:01:55.115 --> 00:01:56.450
and privacy?

00:01:56.450 --> 00:01:58.450
And here's where it's
actually a positive

00:01:58.450 --> 00:01:59.990
if you want to
spin a positive off

00:01:59.990 --> 00:02:03.260
of what obviously is a
difficult circumstance.

00:02:03.260 --> 00:02:06.140
The president's team just
released a big data and privacy

00:02:06.140 --> 00:02:10.870
report that outlined a model
for how information should

00:02:10.870 --> 00:02:12.560
flow in the internet economy.

00:02:12.560 --> 00:02:14.230
And that model starts
with the premise

00:02:14.230 --> 00:02:16.860
that individuals are
entitled to electronic copies

00:02:16.860 --> 00:02:18.520
of their own data.

00:02:18.520 --> 00:02:20.140
Now, the reason why
that's important

00:02:20.140 --> 00:02:24.100
is it's actually creating more
data liquidity in the regulated

00:02:24.100 --> 00:02:25.100
sectors of the economy.

00:02:25.100 --> 00:02:28.130
So if you're a student and you
have your data in the student

00:02:28.130 --> 00:02:32.190
information system at a
college or a K-12 school,

00:02:32.190 --> 00:02:35.260
you're entitled to an electronic
copy-- machine readable--

00:02:35.260 --> 00:02:37.767
of that data that you
might want to then share

00:02:37.767 --> 00:02:39.850
with someone who can build
a personalized tutoring

00:02:39.850 --> 00:02:41.130
service for you.

00:02:41.130 --> 00:02:44.180
Today, you really can't get an
electronic copy of that data.

00:02:44.180 --> 00:02:47.680
You get a transcript, basically,
and that's what you get.

00:02:47.680 --> 00:02:49.370
Or your doctor.

00:02:49.370 --> 00:02:51.810
You can say to your doctor,
I'd like an electronic copy

00:02:51.810 --> 00:02:55.640
of my medical data so that I
might have a digital tutor that

00:02:55.640 --> 00:02:57.487
might help me
navigate, if you will,

00:02:57.487 --> 00:02:59.945
the health care system to figure
out what I should be doing

00:02:59.945 --> 00:03:02.380
that I'm not so that
I can stay healthier.

00:03:02.380 --> 00:03:05.360
So I think you're
seeing the negative

00:03:05.360 --> 00:03:08.050
into a positive asserting
a new framework.

00:03:08.050 --> 00:03:11.740
I own the data and I want
the ability to share it,

00:03:11.740 --> 00:03:13.910
especially data held
in the government.

00:03:13.910 --> 00:03:17.080
Even the IRS, by the way,
now allows every American

00:03:17.080 --> 00:03:21.010
to download a machine
readable copy of their filing

00:03:21.010 --> 00:03:25.740
so that if they want to go shop
around for a new filing support

00:03:25.740 --> 00:03:28.980
service, they can now take
their data with them to do so.

00:03:28.980 --> 00:03:30.900
MALE SPEAKER: I mean,
if you think about it,

00:03:30.900 --> 00:03:33.150
before we had blue
buttons and red buttons.

00:03:33.150 --> 00:03:35.340
People didn't know if people
even wanted this data.

00:03:35.340 --> 00:03:37.240
And so you put it out there
and now we kind of assume it,

00:03:37.240 --> 00:03:38.835
that this should be out
there, we should need it,

00:03:38.835 --> 00:03:40.430
we want to get access to it.

00:03:40.430 --> 00:03:41.870
What's the next forefront?

00:03:41.870 --> 00:03:43.845
What's the next
breakthrough on open data?

00:03:43.845 --> 00:03:45.720
And the reason why I
ask, I feel like there's

00:03:45.720 --> 00:03:47.645
a certain amount
of-- expectations

00:03:47.645 --> 00:03:50.231
are always going higher
and higher and faster.

00:03:50.231 --> 00:03:52.230
Are we actually outstripping
those expectations?

00:03:52.230 --> 00:03:54.860
Are we able to fulfill
on that promise?

00:03:54.860 --> 00:03:58.190
ANEESH CHOPRA: So I have
a colleague of mine,

00:03:58.190 --> 00:04:03.460
Sanju Bansal, who has long
stated that the value-- true

00:04:03.460 --> 00:04:05.380
value, occurs at
the intersection

00:04:05.380 --> 00:04:07.050
of multiple disciplines.

00:04:07.050 --> 00:04:09.750
And if you take that
into the context of data,

00:04:09.750 --> 00:04:13.540
it's not just the collection
of data that's useful.

00:04:13.540 --> 00:04:16.700
It's the ability to mash
up data from, perhaps,

00:04:16.700 --> 00:04:18.790
government sources
with private sources.

00:04:18.790 --> 00:04:21.829
And that really is
very early days.

00:04:21.829 --> 00:04:24.590
So you could
imagine, for example,

00:04:24.590 --> 00:04:27.380
a veteran who's
got a profile, say,

00:04:27.380 --> 00:04:29.990
on LinkedIn, or Monster, or
any one of the other companies

00:04:29.990 --> 00:04:34.150
where they've got their profile,
and they could combine what

00:04:34.150 --> 00:04:36.360
they self-entered
as their profile

00:04:36.360 --> 00:04:39.580
with the official transcript
of all the skills they acquired

00:04:39.580 --> 00:04:40.940
in the military.

00:04:40.940 --> 00:04:44.550
We blue buttoned a version
of what's called the DD214.

00:04:44.550 --> 00:04:47.180
So any veteran can now
download a soft copy

00:04:47.180 --> 00:04:49.620
of their military transcript.

00:04:49.620 --> 00:04:53.220
Imagine combining that with
one of these social profiles,

00:04:53.220 --> 00:04:55.750
or Google+.

00:04:55.750 --> 00:04:59.830
And what I could do is unlock
all kinds of opportunities

00:04:59.830 --> 00:05:02.410
to connect to people who
will help me find a job,

00:05:02.410 --> 00:05:04.700
pick a college or a university
that's right for me.

00:05:04.700 --> 00:05:06.150
But it's at that intersection.

00:05:06.150 --> 00:05:07.810
So I think the next
chapter is going

00:05:07.810 --> 00:05:10.620
to be entrepreneurs and
innovators who are mashing up

00:05:10.620 --> 00:05:14.760
data sets in health, energy,
even education markets as we've

00:05:14.760 --> 00:05:18.159
just described in new and
creative ways to add value.

00:05:18.159 --> 00:05:19.700
MALE SPEAKER: Have
you been surprised

00:05:19.700 --> 00:05:22.430
by the pace, or lack
thereof actually,

00:05:22.430 --> 00:05:23.839
of the startups in this space?

00:05:23.839 --> 00:05:25.880
There was this hope that
all this open data would

00:05:25.880 --> 00:05:27.420
be created, and these
startups would come out there

00:05:27.420 --> 00:05:28.669
and make all these cool ideas.

00:05:28.669 --> 00:05:30.809
And make like your own
DMV app, or whatever

00:05:30.809 --> 00:05:32.350
it is-- the equivalent
of that stuff.

00:05:32.350 --> 00:05:34.600
Has that been slower or
faster than you expected?

00:05:34.600 --> 00:05:36.140
Do you see it
turning the corner?

00:05:36.140 --> 00:05:40.450
ANEESH CHOPRA: So I would say
slow and fast with an asterisk.

00:05:40.450 --> 00:05:43.160
Fast in health care,
slow out of health care.

00:05:43.160 --> 00:05:47.130
And the reason for
that is my successor.

00:05:47.130 --> 00:05:50.270
Todd Park came out of the
Department of Health and Human

00:05:50.270 --> 00:05:50.780
Services.

00:05:50.780 --> 00:05:53.230
And he had a very
interesting insight.

00:05:53.230 --> 00:05:55.640
Opening up data
is the equivalent

00:05:55.640 --> 00:05:57.470
of a tree falling in the woods.

00:05:57.470 --> 00:06:00.670
It doesn't necessarily
mean people know about it.

00:06:00.670 --> 00:06:04.790
And so the key had been to
reach out to the community

00:06:04.790 --> 00:06:07.810
to inform people that
all of this information

00:06:07.810 --> 00:06:09.250
is now available.

00:06:09.250 --> 00:06:12.680
So in health care, there's
actually now an ecosystem.

00:06:12.680 --> 00:06:16.835
Thousands of people gather
every year at an initiative

00:06:16.835 --> 00:06:21.560
he called Health Datapalooza
where-- now four or five years

00:06:21.560 --> 00:06:25.460
running, McKinsey has
estimated over 200 new products

00:06:25.460 --> 00:06:28.300
and services have been
born on account of the fact

00:06:28.300 --> 00:06:31.870
that people-- many of these data
sets were publicly available.

00:06:31.870 --> 00:06:34.100
It's not like they
were hidden from view.

00:06:34.100 --> 00:06:37.700
It's just now they're organized
in an easier-to-find manner,

00:06:37.700 --> 00:06:39.800
and there's a proactive
system in place

00:06:39.800 --> 00:06:41.900
to go inform people about it.

00:06:41.900 --> 00:06:43.690
I also put an asterisk
in health care

00:06:43.690 --> 00:06:49.530
because you have to operate
in a revenue model or business

00:06:49.530 --> 00:06:52.140
model that makes sense for you.

00:06:52.140 --> 00:06:55.010
In health care today, we
are changing the underlying

00:06:55.010 --> 00:06:58.560
incentives to reward
people who stay healthy

00:06:58.560 --> 00:07:01.200
versus rewarding
doctors and hospitals

00:07:01.200 --> 00:07:03.220
who treat you when you're sick.

00:07:03.220 --> 00:07:06.410
In that transition,
there is now a premium

00:07:06.410 --> 00:07:08.720
on understanding or
predicting someone

00:07:08.720 --> 00:07:10.724
before they get really
sick because it's cheaper

00:07:10.724 --> 00:07:12.640
to treat them when they're
only slightly sick,

00:07:12.640 --> 00:07:14.490
or even before they're sick.

00:07:14.490 --> 00:07:17.300
So there's now a
market incentive

00:07:17.300 --> 00:07:20.350
to develop products and services
born on this more population

00:07:20.350 --> 00:07:21.770
health database.

00:07:21.770 --> 00:07:24.960
And that business condition,
in addition to the fact

00:07:24.960 --> 00:07:26.480
the people now know
about the data,

00:07:26.480 --> 00:07:28.350
now they can make
money off the data.

00:07:28.350 --> 00:07:31.550
That's why health is
really scaling as a place

00:07:31.550 --> 00:07:33.750
for open data innovation.

00:07:33.750 --> 00:07:36.070
We're starting to see
that begin to emerge.

00:07:36.070 --> 00:07:39.200
There are new business
models in education.

00:07:39.200 --> 00:07:41.610
Slow, but competency-based
learning models,

00:07:41.610 --> 00:07:44.880
getting accreditation and
the ability to get reimbursed

00:07:44.880 --> 00:07:46.960
is going to create
more opportunity

00:07:46.960 --> 00:07:49.460
for learning technologies.

00:07:49.460 --> 00:07:51.240
As well as energy efficiency.

00:07:51.240 --> 00:07:54.620
States like California that
have proactive policies that

00:07:54.620 --> 00:07:59.350
reward their utility to
help folks save money

00:07:59.350 --> 00:08:00.950
on their energy
bill will encourage

00:08:00.950 --> 00:08:03.140
them to open up the
data and create apps.

00:08:03.140 --> 00:08:05.580
And so you're seeing that
where the business models are

00:08:05.580 --> 00:08:07.430
in place and people
are aware, it's

00:08:07.430 --> 00:08:09.490
actually scaling it
at a pretty good clip.

00:08:09.490 --> 00:08:12.190
MALE SPEAKER: What can Google
do to help foster that ecosystem

00:08:12.190 --> 00:08:13.966
as a partner to the government?

00:08:13.966 --> 00:08:15.840
ANEESH CHOPRA: Well, I
was sharing the story.

00:08:15.840 --> 00:08:18.210
Google has already done it.

00:08:18.210 --> 00:08:20.520
And I want to just make
sure folks know the story

00:08:20.520 --> 00:08:22.790
because it's an
important one to realize

00:08:22.790 --> 00:08:24.340
how we can all play a role.

00:08:24.340 --> 00:08:27.440
The whole point of innovative
state is that every one of us

00:08:27.440 --> 00:08:32.250
can contribute as a unit
within Google, or a company,

00:08:32.250 --> 00:08:33.919
or as individuals.

00:08:33.919 --> 00:08:37.926
And I shared this story and I'll
share it briefly if it's OK.

00:08:37.926 --> 00:08:40.179
The President handed
me an assignment.

00:08:40.179 --> 00:08:42.809
It was August of 2011.

00:08:42.809 --> 00:08:46.860
He had just given a speech or
was preparing to give a speech

00:08:46.860 --> 00:08:49.610
announcing a challenge
to the private sector--

00:08:49.610 --> 00:08:53.840
please hire the 100,000-plus
veterans who are coming home

00:08:53.840 --> 00:08:55.550
from Iraq and Afghanistan.

00:08:55.550 --> 00:08:57.940
And that this was going to
grow over the coming years.

00:08:57.940 --> 00:08:59.900
And we wanted more
and more companies

00:08:59.900 --> 00:09:03.000
to make an explicit
veteran-hiring commitment.

00:09:03.000 --> 00:09:07.410
And we had a data problem, which
is, how will a veteran know

00:09:07.410 --> 00:09:09.840
which employers made
this commitment?

00:09:09.840 --> 00:09:11.665
Is there going to
be one website,

00:09:11.665 --> 00:09:18.104
www.findveteranfriendlyemployers.gov?

00:09:18.104 --> 00:09:19.020
Who would maintain it?

00:09:19.020 --> 00:09:21.060
Where would that be built?

00:09:21.060 --> 00:09:23.910
Or, I called Vint Cerf,
who's a friend and a mentor.

00:09:23.910 --> 00:09:26.624
And I said Vint, I'd love
to find a creative approach

00:09:26.624 --> 00:09:29.040
to this problem because I'm
not sure I'm thinking about it

00:09:29.040 --> 00:09:30.240
the right way.

00:09:30.240 --> 00:09:32.170
And his immediate
reaction was, you

00:09:32.170 --> 00:09:36.570
have to talk to Guha, who is one
of the fellows here at Google,

00:09:36.570 --> 00:09:39.100
one of the smartest folks I've
had the pleasure of knowing.

00:09:39.100 --> 00:09:42.800
And he told me, this is
a search problem, not

00:09:42.800 --> 00:09:44.220
a database problem.

00:09:44.220 --> 00:09:47.900
And that what we could
do is get the ecosystem

00:09:47.900 --> 00:09:51.290
to standardize a very simple
piece of metadata that

00:09:51.290 --> 00:09:53.540
says, if you're an employer
and you have a job posting

00:09:53.540 --> 00:09:56.110
and you want to make it
clear that you want to offer

00:09:56.110 --> 00:09:59.620
a veteran-hiring commitment,
add this little bit of metadata

00:09:59.620 --> 00:10:03.330
to your job posting page and
we can crawl the internet

00:10:03.330 --> 00:10:05.540
and find all job
postings associated

00:10:05.540 --> 00:10:07.270
with veteran-hiring commitment.

00:10:07.270 --> 00:10:11.230
It took 30 days to get
the schema.org community

00:10:11.230 --> 00:10:13.180
to embrace this standard.

00:10:13.180 --> 00:10:15.540
And it took another
30 days to get

00:10:15.540 --> 00:10:17.890
folks to commit to
adopt the standard.

00:10:17.890 --> 00:10:20.500
But within 90 days of
the President's speech,

00:10:20.500 --> 00:10:23.740
we were in the Rose Garden
at the White House announcing

00:10:23.740 --> 00:10:27.650
that Google, LinkedIn,
Monster, a variety

00:10:27.650 --> 00:10:30.140
of other stakeholders,
voluntarily

00:10:30.140 --> 00:10:32.810
pledged to make this
service available.

00:10:32.810 --> 00:10:36.247
And today, literally millions
of job postings associated

00:10:36.247 --> 00:10:37.830
with those employer-hiring
commitments

00:10:37.830 --> 00:10:39.930
are now discoverable
through this collaborative.

00:10:39.930 --> 00:10:44.210
So what I mean by that is--
I think of life in threes--

00:10:44.210 --> 00:10:45.530
light, medium, and heavy.

00:10:45.530 --> 00:10:48.440
The light is when
you have spare time

00:10:48.440 --> 00:10:50.580
and you want to
commit to a problem,

00:10:50.580 --> 00:10:54.410
visit challenge.gov and see if
you or a group of your friends

00:10:54.410 --> 00:10:57.030
and teammates might bring
creative ideas to a problem

00:10:57.030 --> 00:10:59.861
that's now been organized
in a structured way

00:10:59.861 --> 00:11:00.610
by the government.

00:11:00.610 --> 00:11:03.480
So think about contributing or
participating in challenge.gov.

00:11:03.480 --> 00:11:06.130
Medium is actually
thinking about a problem

00:11:06.130 --> 00:11:07.920
that motivates you.

00:11:07.920 --> 00:11:10.900
And figure out,
what can I do if I

00:11:10.900 --> 00:11:13.750
were to ask for data
that's not today available?

00:11:13.750 --> 00:11:17.170
Or find ways to tap into
other aspects of this,

00:11:17.170 --> 00:11:20.760
whether it be data standards,
or prizes and challenges,

00:11:20.760 --> 00:11:25.050
and find a way to
build my project.

00:11:25.050 --> 00:11:27.130
That is, something I
want the world to have.

00:11:27.130 --> 00:11:30.000
Powered in part by open
data, open government.

00:11:30.000 --> 00:11:31.800
Or three, heavy.

00:11:31.800 --> 00:11:35.760
I wouldn't say leave Google,
but take a sabbatical.

00:11:35.760 --> 00:11:38.730
We encourage folks to sign
up as Presidential Innovation

00:11:38.730 --> 00:11:39.640
Fellows.

00:11:39.640 --> 00:11:43.360
We're disciples of Eric Ries
lean startup methodology.

00:11:43.360 --> 00:11:45.830
And every year
now, we have dozens

00:11:45.830 --> 00:11:48.000
of entrepreneurs
coming in to Washington

00:11:48.000 --> 00:11:51.200
to spend six months
or a year really

00:11:51.200 --> 00:11:54.430
scrubbing in with
entrepreneurs inside government

00:11:54.430 --> 00:11:56.330
to go after
well-defined problems

00:11:56.330 --> 00:11:58.290
that the agency leadership
has said we really

00:11:58.290 --> 00:12:00.300
want your brain
power to help solve.

00:12:00.300 --> 00:12:03.750
And we just closed the
round of the current batch

00:12:03.750 --> 00:12:06.290
of Presidential Fellows, but
we'll have more opportunity.

00:12:06.290 --> 00:12:07.980
And so think about
actually dedicating

00:12:07.980 --> 00:12:10.000
some time would be
my third option.

00:12:10.000 --> 00:12:11.040
Light, medium, heavy.

00:12:11.040 --> 00:12:12.700
MALE SPEAKER: That's great.

00:12:12.700 --> 00:12:15.754
So one question about
technology outside

00:12:15.754 --> 00:12:17.920
of government and innovation
outside of government--

00:12:17.920 --> 00:12:19.461
the role government
can play in that.

00:12:19.461 --> 00:12:21.680
You talk about the narrative
you're trying to change,

00:12:21.680 --> 00:12:23.013
which is not about big or small.

00:12:23.013 --> 00:12:26.570
It's about just being smarter,
which sounds very noble.

00:12:26.570 --> 00:12:27.810
I hope we can do that.

00:12:27.810 --> 00:12:30.040
But I guess one question
is, when government

00:12:30.040 --> 00:12:34.440
tries to spark innovation
outside in certain sectors,

00:12:34.440 --> 00:12:37.560
through prizes or challenges,
whatever, and takes on risk

00:12:37.560 --> 00:12:40.190
that the market is
unwilling to take on,

00:12:40.190 --> 00:12:42.650
but it seems very unwilling
to accept those risks when

00:12:42.650 --> 00:12:44.130
they sometimes fail.

00:12:44.130 --> 00:12:47.000
We have a venture capital
group within Google

00:12:47.000 --> 00:12:49.460
and so we know sometimes they'll
win, sometimes they fail.

00:12:49.460 --> 00:12:50.560
And we accept that.

00:12:50.560 --> 00:12:53.180
How does government, with
accountability and so forth,

00:12:53.180 --> 00:12:57.610
with a pluralist society deal
with that kind of outcome?

00:12:57.610 --> 00:13:00.194
ANEESH CHOPRA: So let me
start with a framework.

00:13:00.194 --> 00:13:02.110
In the first year of the
Obama administration,

00:13:02.110 --> 00:13:05.200
he unveiled the strategy
for American innovation--

00:13:05.200 --> 00:13:08.390
whitehouse.gov/innovation if
any of you want to read it.

00:13:08.390 --> 00:13:10.210
And it articulates
the role of government

00:13:10.210 --> 00:13:12.350
to foster innovation in society.

00:13:12.350 --> 00:13:15.110
And it starts at the foundation
of our society, which

00:13:15.110 --> 00:13:17.340
is we typically see
government play a role

00:13:17.340 --> 00:13:18.710
investing in infrastructure.

00:13:18.710 --> 00:13:21.790
And what we suggested in
this particular strategy

00:13:21.790 --> 00:13:25.140
is that roadways, railways, and
runways were the infrastructure

00:13:25.140 --> 00:13:27.100
of the 20th century economy.

00:13:27.100 --> 00:13:29.400
And that digital
is, in many ways,

00:13:29.400 --> 00:13:32.840
an important part of our
infrastructure in the 21st.

00:13:32.840 --> 00:13:35.980
So whatever we can do to
make it easier and better

00:13:35.980 --> 00:13:38.302
to build up our
digital infrastructure.

00:13:38.302 --> 00:13:39.760
The good news is
that's bipartisan.

00:13:39.760 --> 00:13:42.700
We had a national wireless
initiative opening up

00:13:42.700 --> 00:13:46.350
airwaves for more commercial
services for broadband

00:13:46.350 --> 00:13:49.800
and opening up government
spectrum for commercial use

00:13:49.800 --> 00:13:52.350
as an example where both sides
of the aisle came together

00:13:52.350 --> 00:13:54.170
and said, let's do this.

00:13:54.170 --> 00:13:56.520
We're also using
that program to help

00:13:56.520 --> 00:13:58.910
build a next-generation
capability for cops

00:13:58.910 --> 00:14:01.599
and firefighters and emergency
services professionals

00:14:01.599 --> 00:14:02.515
to better communicate.

00:14:02.515 --> 00:14:04.780
The last recommendation
of the 9/11 Commission

00:14:04.780 --> 00:14:06.620
to allow for interoperable
communications.

00:14:06.620 --> 00:14:08.270
So get infrastructure right.

00:14:08.270 --> 00:14:10.160
Second, we need
rules of the road.

00:14:10.160 --> 00:14:13.390
So what are the rules of the
road on privacy and security

00:14:13.390 --> 00:14:16.690
to maximize the opportunity
for at least the digital side

00:14:16.690 --> 00:14:18.230
of the innovation economy?

00:14:18.230 --> 00:14:20.590
And again, we
embrace the framework

00:14:20.590 --> 00:14:24.320
of collaboration,
enforceable codes of conduct.

00:14:24.320 --> 00:14:27.680
So we've invited stakeholders
to think about ways to honor,

00:14:27.680 --> 00:14:31.232
for example, the Do Not Track
flag, which was not maybe

00:14:31.232 --> 00:14:32.940
the most successful
program was launched.

00:14:32.940 --> 00:14:37.380
But at least it was an enabling
part of the policy ledger

00:14:37.380 --> 00:14:40.480
so we could get more privacy
protection in the existing

00:14:40.480 --> 00:14:41.320
economy.

00:14:41.320 --> 00:14:43.060
But last but certainly
not least, we

00:14:43.060 --> 00:14:46.480
said there are a few sectors
where government needs

00:14:46.480 --> 00:14:49.520
to play at least a convening
role and maybe an investing

00:14:49.520 --> 00:14:51.820
role to catalyze breakthroughs
in health, energy,

00:14:51.820 --> 00:14:53.200
and education.

00:14:53.200 --> 00:14:56.160
And here, I wrote in the
book, I borrowed heavily

00:14:56.160 --> 00:14:58.860
from models in the
private sector for what

00:14:58.860 --> 00:15:01.680
we would call innovation
pipeline management.

00:15:01.680 --> 00:15:04.600
There's actually a science to
bringing new ideas to life.

00:15:04.600 --> 00:15:06.747
You just don't want
experimentation,

00:15:06.747 --> 00:15:08.830
throw some money here, see
if it works or doesn't.

00:15:08.830 --> 00:15:10.324
There's a methodology.

00:15:10.324 --> 00:15:12.740
And some organizations are
good about it and some are not.

00:15:12.740 --> 00:15:14.698
And I write in the book
about the negative case

00:15:14.698 --> 00:15:17.660
study of Kodak, which was
particularly awkward for me,

00:15:17.660 --> 00:15:20.067
because here I am
growing up in an era

00:15:20.067 --> 00:15:21.650
where Kodak is sort
of second to none.

00:15:21.650 --> 00:15:23.358
The most innovative
company in the world,

00:15:23.358 --> 00:15:26.230
invented the VCR, invented
digital photography,

00:15:26.230 --> 00:15:28.980
commercialized neither of
them because management chose

00:15:28.980 --> 00:15:31.200
not to invest in
these opportunities.

00:15:31.200 --> 00:15:34.570
They had a breakdown in their
innovation management pipeline.

00:15:34.570 --> 00:15:35.980
And what was
particularly awkward

00:15:35.980 --> 00:15:38.180
for us is that the
First Lady invited

00:15:38.180 --> 00:15:40.530
Mike Krieger, the
co-founder of Instagram,

00:15:40.530 --> 00:15:42.780
a Brazilian
immigrant, to her box.

00:15:42.780 --> 00:15:44.410
And as you know,
the year Instagram

00:15:44.410 --> 00:15:46.635
gets acquired for
some ungodly sum

00:15:46.635 --> 00:15:49.010
of money-- a billion dollars,
whatever it is by Facebook,

00:15:49.010 --> 00:15:51.260
is the year Kodak
declares bankruptcy.

00:15:51.260 --> 00:15:55.590
And largely, on account of their
management failure to innovate.

00:15:55.590 --> 00:15:58.240
So my suggestion
was that we create

00:15:58.240 --> 00:16:02.790
the capacity for innovation
management in the same way.

00:16:02.790 --> 00:16:06.060
So even if we take a risk,
it's understood and managed.

00:16:06.060 --> 00:16:08.810
We have, for example, now
in statute the Centers

00:16:08.810 --> 00:16:12.800
for Medicare and Medicaid
Innovation in the Affordable

00:16:12.800 --> 00:16:13.320
Care Act.

00:16:13.320 --> 00:16:16.550
Instantiating the authority
to experiment with new ways

00:16:16.550 --> 00:16:20.680
to pay doctors and hospitals
to keep people healthy.

00:16:20.680 --> 00:16:23.700
Not every idea that the
Innovation Center will launch

00:16:23.700 --> 00:16:27.140
will be successful, but
it's designed into its DNA.

00:16:27.140 --> 00:16:28.850
And there's actually a backstop.

00:16:28.850 --> 00:16:32.000
If they can prove that their
payment reforms improved

00:16:32.000 --> 00:16:35.940
quality and lowered cost, then
the actuary of the department,

00:16:35.940 --> 00:16:39.820
who's not political, can
certify it met those conditions,

00:16:39.820 --> 00:16:43.090
now it can be a payment model
that's available to all doctors

00:16:43.090 --> 00:16:45.980
and hospitals without having
to go back to Congress.

00:16:45.980 --> 00:16:49.037
Innovation pipeline management
an important aspect of this.

00:16:49.037 --> 00:16:50.870
And I think you're going
to see some of that

00:16:50.870 --> 00:16:54.420
even with ARPA-E in energy.

00:16:54.420 --> 00:16:56.670
And we called for an
APRA-ED in education.

00:16:56.670 --> 00:16:58.800
Similar principles
to DARPA, which

00:16:58.800 --> 00:17:00.459
offers this kind of
innovation pipeline

00:17:00.459 --> 00:17:01.792
work for the defense department.

00:17:01.792 --> 00:17:03.640
MALE SPEAKER: Who
now works at Google.

00:17:03.640 --> 00:17:05.890
ANEESH CHOPRA: And all of
the DARPA-funded projects

00:17:05.890 --> 00:17:06.880
are all employees at Google.

00:17:06.880 --> 00:17:07.796
MALE SPEAKER: Exactly.

00:17:07.796 --> 00:17:08.380
Well, great.

00:17:08.380 --> 00:17:10.220
We're going to open
this up to questions

00:17:10.220 --> 00:17:11.180
from the audience
in a few minutes.

00:17:11.180 --> 00:17:13.270
So if you have any questions,
start thinking about them.

00:17:13.270 --> 00:17:14.670
One question I had
to ask, you allude

00:17:14.670 --> 00:17:16.160
to a little bit in the book
because it was still hot

00:17:16.160 --> 00:17:17.920
in the press, which
is healthcare.gov.

00:17:17.920 --> 00:17:18.520
ANEESH CHOPRA: Yes.

00:17:18.520 --> 00:17:19.740
MALE SPEAKER: So I want
to get your opinion

00:17:19.740 --> 00:17:21.060
about what went wrong.

00:17:21.060 --> 00:17:23.185
And this is more of a
question about the operations

00:17:23.185 --> 00:17:24.880
of government's
IT infrastructure

00:17:24.880 --> 00:17:25.670
and how it works.

00:17:25.670 --> 00:17:28.720
What do you think went wrong,
from your perspective now?

00:17:28.720 --> 00:17:30.202
And how we dealt
with the problem,

00:17:30.202 --> 00:17:32.660
and how we prevent that kind
of thing from happening again.

00:17:32.660 --> 00:17:34.560
ANEESH CHOPRA: This is
unbelievably frustrating,

00:17:34.560 --> 00:17:35.150
right?

00:17:35.150 --> 00:17:37.610
As an American,
as someone who has

00:17:37.610 --> 00:17:41.310
been a fan of President
Obama's, like everyone,

00:17:41.310 --> 00:17:44.760
we were sort of shocked that
despite all the successes

00:17:44.760 --> 00:17:49.070
politically, the Supreme Court--
how could literally a website

00:17:49.070 --> 00:17:52.780
be the demise, if you
will, of the program?

00:17:52.780 --> 00:17:56.250
My early read was
that procurement

00:17:56.250 --> 00:17:59.149
remains a significant
problem in government.

00:17:59.149 --> 00:18:00.690
Everyone in this
room, if they wanted

00:18:00.690 --> 00:18:04.240
to participate in
government as an individual,

00:18:04.240 --> 00:18:06.800
they could volunteer their time.

00:18:06.800 --> 00:18:08.370
Like Guha, they
could actually help

00:18:08.370 --> 00:18:10.830
design a public-private
collaborative.

00:18:10.830 --> 00:18:13.590
But the minute money's
involved, if someone

00:18:13.590 --> 00:18:16.530
wants to get paid for that work,
which is inevitable-- you want

00:18:16.530 --> 00:18:19.170
to get paid for work--
then it triggers

00:18:19.170 --> 00:18:22.640
a whole machine called
the Federal Acquisition

00:18:22.640 --> 00:18:23.980
Regulations.

00:18:23.980 --> 00:18:26.920
And it's become so
broken in Washington

00:18:26.920 --> 00:18:29.900
the Defense Department
wrote a memo and said,

00:18:29.900 --> 00:18:32.110
we almost have to avoid
fair and open procurements.

00:18:32.110 --> 00:18:35.050
They didn't use that language,
I want to be careful about it.

00:18:35.050 --> 00:18:38.100
But that what happens today
is, if there was truly

00:18:38.100 --> 00:18:41.990
a fair and open competition,
then the culture

00:18:41.990 --> 00:18:46.250
is anyone who loses
immediately protests, which

00:18:46.250 --> 00:18:49.444
delays the project about
a year, on average.

00:18:49.444 --> 00:18:51.110
And the people who
suffer are the people

00:18:51.110 --> 00:18:52.790
who want the
program to go alive,

00:18:52.790 --> 00:18:54.470
not the vendors
fighting over each other

00:18:54.470 --> 00:18:56.580
about who won and
lost the contract.

00:18:56.580 --> 00:18:58.970
So my instinct-- it
hasn't been reported

00:18:58.970 --> 00:19:01.660
and I don't know if the agency
will get that level of detail

00:19:01.660 --> 00:19:02.159
out.

00:19:02.159 --> 00:19:05.300
But my instinct is one of
the root cause problems is

00:19:05.300 --> 00:19:08.440
that they didn't have a truly
fair and open procurement.

00:19:08.440 --> 00:19:10.640
They had to go to
a list of a dozen

00:19:10.640 --> 00:19:14.540
or so pre-qualified vendors who
were already allowed to do work

00:19:14.540 --> 00:19:16.580
for the government,
irrespective if they had

00:19:16.580 --> 00:19:20.510
any experience building an
exchange like healthcare.gov.

00:19:20.510 --> 00:19:22.220
So when you have a
limited pool of people

00:19:22.220 --> 00:19:27.800
that you can tap into because
of these acquisition problems,

00:19:27.800 --> 00:19:29.670
you have a bit of a
recipe for problems.

00:19:29.670 --> 00:19:32.170
And then you can go into all
of the other aspects of testing

00:19:32.170 --> 00:19:34.350
and so forth, which
really build off

00:19:34.350 --> 00:19:36.030
of that fundamental problem.

00:19:36.030 --> 00:19:38.320
But let me flip
the positive side.

00:19:38.320 --> 00:19:40.860
Healthcare.gov is one of
my favorite case studies

00:19:40.860 --> 00:19:45.120
in the book as an example
of an innovative state.

00:19:45.120 --> 00:19:48.202
The version that went
live in July of 2010.

00:19:48.202 --> 00:19:49.660
How many of you
knew that there was

00:19:49.660 --> 00:19:52.454
a version that went
live in July of 2010?

00:19:52.454 --> 00:19:53.370
No one's hands are up.

00:19:53.370 --> 00:19:55.020
On the web, I'm sure you're
going to say the same.

00:19:55.020 --> 00:19:55.800
Well, one of you did.

00:19:55.800 --> 00:19:56.270
OK, fine.

00:19:56.270 --> 00:19:56.440
One of you.

00:19:56.440 --> 00:19:57.200
MALE SPEAKER: Read the book.

00:19:57.200 --> 00:19:58.408
ANEESH CHOPRA: Read the book.

00:19:58.408 --> 00:20:02.320
Here's the point, the bill
was signed into law March,

00:20:02.320 --> 00:20:05.290
I think 9 or 10, 2010.

00:20:05.290 --> 00:20:07.340
And the very first
IT deliverable

00:20:07.340 --> 00:20:10.550
was a comprehensive catalog of
all public and private health

00:20:10.550 --> 00:20:13.830
insurance options that had
never been amassed before.

00:20:13.830 --> 00:20:17.870
A data set that had never been
collected, let alone released.

00:20:17.870 --> 00:20:20.737
So that's a little over 90 days.

00:20:20.737 --> 00:20:22.320
We didn't have time
for a procurement.

00:20:22.320 --> 00:20:25.042
My successor, Todd
Park, was CTO at HHS.

00:20:25.042 --> 00:20:27.250
And we worked it out that
him and my colleague, Macon

00:20:27.250 --> 00:20:29.680
Phillips, would kind
of lead this startup

00:20:29.680 --> 00:20:31.540
to create healthcare.gov.

00:20:31.540 --> 00:20:34.060
Who was their lead designer?

00:20:34.060 --> 00:20:35.960
During the debate
on healthcare.gov,

00:20:35.960 --> 00:20:37.710
a young man from
New Jersey called

00:20:37.710 --> 00:20:39.770
Edward Mullen
thought that it would

00:20:39.770 --> 00:20:42.710
be better if he could put
his design talent to work

00:20:42.710 --> 00:20:44.420
to help explain to
the American people

00:20:44.420 --> 00:20:47.360
that this is what it will mean
for you if this law passes.

00:20:47.360 --> 00:20:50.560
And he created myhealth.gov,
a nice visual experience.

00:20:50.560 --> 00:20:53.010
And he just posted
a screenshot of it

00:20:53.010 --> 00:20:56.260
and tweeted at my colleague
Macon at the White House.

00:20:56.260 --> 00:20:59.030
Macon sees the at mention,
sees the image, and says,

00:20:59.030 --> 00:21:00.710
this is pretty good stuff.

00:21:00.710 --> 00:21:03.130
And long and short of
it, we bring Ed in.

00:21:03.130 --> 00:21:05.570
He was not a government
contractor, procurement

00:21:05.570 --> 00:21:08.810
process, just a talented person
passionate about the issue.

00:21:08.810 --> 00:21:11.940
Ends up becoming the lead
designer on healthcare.gov.

00:21:11.940 --> 00:21:15.500
They built the system
with openness in mind,

00:21:15.500 --> 00:21:18.930
so that when the data was
made available on the website,

00:21:18.930 --> 00:21:22.340
it was also available in machine
readable form for others.

00:21:22.340 --> 00:21:25.870
To this day, the US News and
World Report Health Insurance

00:21:25.870 --> 00:21:28.180
Finder is still
powered by the data

00:21:28.180 --> 00:21:30.300
from that original
healthcare.gov.

00:21:30.300 --> 00:21:33.160
The point is lots
of shots on goal.

00:21:33.160 --> 00:21:35.450
There should be millions of
websites that give people

00:21:35.450 --> 00:21:36.908
information about
their health care

00:21:36.908 --> 00:21:39.640
and let them find whatever
path is right for them

00:21:39.640 --> 00:21:41.800
through a broker,
through a website,

00:21:41.800 --> 00:21:43.670
through their neighbor,
or the government

00:21:43.670 --> 00:21:46.220
directly, to get the
care they deserve.

00:21:46.220 --> 00:21:49.000
You will see this
fall-- my hope, a return

00:21:49.000 --> 00:21:52.770
to that principle, opening
up of those data assets

00:21:52.770 --> 00:21:56.040
so that more and more sites
can be built, not just one,

00:21:56.040 --> 00:21:57.019
to allow folks to shop.

00:21:57.019 --> 00:21:59.060
And that'll be an example
of an innovative state.

00:21:59.060 --> 00:22:00.810
MALE SPEAKER: So a
different architecture.

00:22:00.810 --> 00:22:03.940
Do we have any questions
from the audience?

00:22:03.940 --> 00:22:05.880
While you're thinking,
I will add one more.

00:22:05.880 --> 00:22:07.130
So on the international front.

00:22:07.130 --> 00:22:09.900
So I'd like to think the
US is a leading innovation

00:22:09.900 --> 00:22:12.080
country in many ways.

00:22:12.080 --> 00:22:14.070
I don't know, are we
a leading innovator

00:22:14.070 --> 00:22:17.030
in state craft, or running
a country, or government

00:22:17.030 --> 00:22:17.580
operations?

00:22:17.580 --> 00:22:19.163
Other places we can
at least point to,

00:22:19.163 --> 00:22:21.250
like maybe ARPA-E or
something like that.

00:22:21.250 --> 00:22:22.610
ANEESH CHOPRA: Yeah.

00:22:22.610 --> 00:22:23.580
MALE SPEAKER: What
areas are we not?

00:22:23.580 --> 00:22:25.913
What countries do you see
doing really innovative things

00:22:25.913 --> 00:22:27.790
that we should learn from?

00:22:27.790 --> 00:22:29.420
ANEESH CHOPRA:
President Obama convened

00:22:29.420 --> 00:22:32.400
on the sidelines of
the UN General Assembly

00:22:32.400 --> 00:22:37.812
Meeting about 50 heads
of state back in 2010.

00:22:37.812 --> 00:22:39.390
Well, he issued a
challenge in 2010

00:22:39.390 --> 00:22:44.450
and he began the
convenings in 2011, to say,

00:22:44.450 --> 00:22:46.640
let's all do this together.

00:22:46.640 --> 00:22:50.720
Let's create an international
movement of open government.

00:22:50.720 --> 00:22:52.940
And the only prerequisite
for signing up

00:22:52.940 --> 00:22:56.280
was you had the pledge to
commit to an open government

00:22:56.280 --> 00:22:59.560
plan that's written
with your civil society.

00:22:59.560 --> 00:23:02.510
And that you got to publish
that plan in an open format.

00:23:02.510 --> 00:23:04.680
And countries all over
the world demonstrated

00:23:04.680 --> 00:23:08.440
their real powerful
case studies.

00:23:08.440 --> 00:23:12.170
Brazil has their people
participate in their budgeting

00:23:12.170 --> 00:23:14.490
process, setting priorities.

00:23:14.490 --> 00:23:17.280
One of my favorite examples
actually has to do with India

00:23:17.280 --> 00:23:19.460
and it is not IT-specific.

00:23:19.460 --> 00:23:22.100
They disclosed all
the folks that get

00:23:22.100 --> 00:23:24.590
paid-- they have the equivalent
of a works progress--

00:23:24.590 --> 00:23:27.270
WPA, a Works Progress
Administration.

00:23:27.270 --> 00:23:28.830
People get paid to
do work as a way

00:23:28.830 --> 00:23:31.960
to create jobs in rural
villages throughout the country.

00:23:31.960 --> 00:23:36.700
And they decided to make an
open data set out of, what is it

00:23:36.700 --> 00:23:38.280
that these people
are paid to do?

00:23:38.280 --> 00:23:40.780
So I'm getting paid
to fix the well,

00:23:40.780 --> 00:23:44.360
or open up a water
fountain, or create

00:23:44.360 --> 00:23:46.350
something else in
the neighborhood.

00:23:46.350 --> 00:23:48.390
So they began publishing
the data sets.

00:23:48.390 --> 00:23:51.930
In villages in India,
there are NGOs, nonprofits,

00:23:51.930 --> 00:23:57.698
who take it and write with
chalk on a wall, literally,

00:23:57.698 --> 00:23:59.156
these are the people
in our village

00:23:59.156 --> 00:24:01.930
who have been paid
to do these things.

00:24:01.930 --> 00:24:04.710
And the level of accountability
that created-- because they go,

00:24:04.710 --> 00:24:05.550
wait a minute.

00:24:05.550 --> 00:24:08.590
He was paid to build that,
but it's not built yet.

00:24:08.590 --> 00:24:09.570
What are you doing?

00:24:09.570 --> 00:24:10.660
MALE SPEAKER: Or the
teacher didn't show up.

00:24:10.660 --> 00:24:12.535
ANEESH CHOPRA: Or the
teacher didn't show up.

00:24:12.535 --> 00:24:17.030
So you have open data even
without a digital interface

00:24:17.030 --> 00:24:18.520
in that case study.

00:24:18.520 --> 00:24:22.340
And you'll see others moving
towards electronic voting

00:24:22.340 --> 00:24:25.770
and other ways to
strengthen democracy

00:24:25.770 --> 00:24:28.700
that I think are useful
to learn as case studies.

00:24:28.700 --> 00:24:32.460
And the good news is-- what
I try to say in this book,

00:24:32.460 --> 00:24:34.770
this is less about
an ideological fight

00:24:34.770 --> 00:24:38.270
between the left and the
right even around the world.

00:24:38.270 --> 00:24:41.540
It's really about a collective
capacity issue, which

00:24:41.540 --> 00:24:43.750
is, if we can become more
innovative in the delivery

00:24:43.750 --> 00:24:45.470
of services, let's
have the debate

00:24:45.470 --> 00:24:47.040
what government should do.

00:24:47.040 --> 00:24:49.040
But once that's
settled, let's do it

00:24:49.040 --> 00:24:51.440
in the most efficient and
effective manner, which

00:24:51.440 --> 00:24:54.750
will inevitably involve a
digital aspect in today's

00:24:54.750 --> 00:24:55.510
environment.

00:24:55.510 --> 00:24:58.420
And better to do that with
the opportunity for others

00:24:58.420 --> 00:25:00.609
to co-create and
build on that success.

00:25:00.609 --> 00:25:02.900
And America is leading in
that co-creation, co-building

00:25:02.900 --> 00:25:03.710
aspect.

00:25:03.710 --> 00:25:04.100
MALE SPEAKER: That's great.

00:25:04.100 --> 00:25:06.058
And I think you give a
great historical context

00:25:06.058 --> 00:25:08.800
about where we come in this
process and where we're going.

00:25:08.800 --> 00:25:11.310
I think the concern
would be that it may not

00:25:11.310 --> 00:25:12.372
be a bifurcated process.

00:25:12.372 --> 00:25:14.330
That you don't first
decide what you want to do

00:25:14.330 --> 00:25:16.420
and then we always pick the best
way of doing it, because then

00:25:16.420 --> 00:25:17.770
people will try to game it.

00:25:17.770 --> 00:25:20.030
They lost the debate
in the first part,

00:25:20.030 --> 00:25:22.790
so they'll undermine the
actual implementation.

00:25:22.790 --> 00:25:25.960
Kind of with healthcare.gov
was a little bit happening.

00:25:25.960 --> 00:25:28.090
The other side would be
happy that it was failing.

00:25:28.090 --> 00:25:29.790
Not because they want the
government to fail on its own.

00:25:29.790 --> 00:25:31.560
They just didn't want us
to be doing that thing.

00:25:31.560 --> 00:25:33.268
ANEESH CHOPRA: The
most depressing aspect

00:25:33.268 --> 00:25:35.360
of that for me, just
to hit the point,

00:25:35.360 --> 00:25:39.780
there were seven states
early in the process that

00:25:39.780 --> 00:25:42.600
were awarded about a
quarter of a billion dollars

00:25:42.600 --> 00:25:46.660
to pre-load or pre-develop
modules of healthcare.gov

00:25:46.660 --> 00:25:48.670
that they pledged
to make reusable

00:25:48.670 --> 00:25:52.930
by other states, this
collective benefit opportunity.

00:25:52.930 --> 00:25:55.000
Two of those states
had an election

00:25:55.000 --> 00:26:00.310
in the midst of the grant cycle
where Republican leadership

00:26:00.310 --> 00:26:02.910
took over-- Oklahoma and Kansas.

00:26:02.910 --> 00:26:06.240
The Oklahoma team,
the staffers who

00:26:06.240 --> 00:26:09.520
wrote the proposal on what
they envisioned the Oklahoma

00:26:09.520 --> 00:26:12.520
digital experience to be for
shopping for health care--

00:26:12.520 --> 00:26:14.310
in my humble opinion, I read it.

00:26:14.310 --> 00:26:16.120
I had no hand in
the selection of it.

00:26:16.120 --> 00:26:18.411
After they were awarded, I
went through and reviewed it

00:26:18.411 --> 00:26:19.400
and met the team.

00:26:19.400 --> 00:26:23.570
One of the most ambitious,
impressive, and bold, exciting

00:26:23.570 --> 00:26:26.400
examples of how they
were envisioning

00:26:26.400 --> 00:26:30.360
combining the healthcare.gov
concept with their existing

00:26:30.360 --> 00:26:32.190
services for the poor.

00:26:32.190 --> 00:26:33.830
Beautiful vision.

00:26:33.830 --> 00:26:36.000
But new governor is elected.

00:26:36.000 --> 00:26:37.860
Can't touch Obamacare.

00:26:37.860 --> 00:26:40.750
Says, I am not accepting a
nickel of Obamacare money,

00:26:40.750 --> 00:26:43.330
which means this brilliant
idea that my staff developed

00:26:43.330 --> 00:26:45.610
that's good for my
people, throw it away.

00:26:45.610 --> 00:26:48.312
And it was like $60 some-odd
million of investment that

00:26:48.312 --> 00:26:50.020
would've been wonderful
to build a better

00:26:50.020 --> 00:26:51.230
service to their folks.

00:26:51.230 --> 00:26:52.790
But it had Obamacare
on it and so

00:26:52.790 --> 00:26:55.870
she turned it away, as did
the governor of Kansas.

00:26:55.870 --> 00:26:57.950
And so two of the
seven states just

00:26:57.950 --> 00:27:03.750
really politicized what
professionals in those states

00:27:03.750 --> 00:27:06.170
had worked really
hard to want to do.

00:27:06.170 --> 00:27:08.170
And that's disheartening.

00:27:08.170 --> 00:27:09.636
That part's disheartening.

00:27:09.636 --> 00:27:12.010
MALE SPEAKER: Let me ask you--
I know you're an optimist,

00:27:12.010 --> 00:27:15.620
but do you worry
about some paths

00:27:15.620 --> 00:27:17.325
that things can go in a bad way?

00:27:17.325 --> 00:27:18.700
I mean, people
always are worried

00:27:18.700 --> 00:27:19.850
about security and terrorism.

00:27:19.850 --> 00:27:20.130
ANEESH CHOPRA: Privacy.

00:27:20.130 --> 00:27:21.626
MALE SPEAKER: And privacy.

00:27:21.626 --> 00:27:23.000
So what's an
example of something

00:27:23.000 --> 00:27:25.760
which may happen
which might undermine

00:27:25.760 --> 00:27:28.020
the movement towards open
data and more innovation,

00:27:28.020 --> 00:27:29.450
technology enabled--

00:27:29.450 --> 00:27:31.300
ANEESH CHOPRA: Health care.

00:27:31.300 --> 00:27:36.210
We have a longstanding tradition
that both sides of the aisle

00:27:36.210 --> 00:27:39.230
said, if we put more
digitization into health care,

00:27:39.230 --> 00:27:42.570
and we open up more data, and
we change the payment models

00:27:42.570 --> 00:27:44.250
to reward the kinds
of products that you

00:27:44.250 --> 00:27:48.300
need to create people-- more
prevention-oriented mindset,

00:27:48.300 --> 00:27:51.040
that that's the
formula for success.

00:27:51.040 --> 00:27:56.230
One of the challenges
has been our privacy laws

00:27:56.230 --> 00:27:59.760
across the 50 states are
pretty tight and variable.

00:27:59.760 --> 00:28:01.982
And the challenge
is, for the folks

00:28:01.982 --> 00:28:04.190
who want a simple solution
to health care information

00:28:04.190 --> 00:28:06.290
exchange, they're
basically saying,

00:28:06.290 --> 00:28:07.650
avoid the privacy rules.

00:28:07.650 --> 00:28:10.750
Let's just create this
one big health care cloud.

00:28:10.750 --> 00:28:13.437
Let's put everyone's
data in the cloud.

00:28:13.437 --> 00:28:15.020
And then, let's
allow-- so that if you

00:28:15.020 --> 00:28:17.750
get injured in an emergency
room and you're unconscious,

00:28:17.750 --> 00:28:20.970
that that doctor can access
the cloud, find your records,

00:28:20.970 --> 00:28:21.880
and treat you well.

00:28:26.100 --> 00:28:28.250
Even though I understand
the value of that,

00:28:28.250 --> 00:28:30.910
I believe there's too much
risk on the privacy front.

00:28:30.910 --> 00:28:34.400
Health care data, your
learning records data,

00:28:34.400 --> 00:28:36.880
these are really
sensitive data sets.

00:28:36.880 --> 00:28:39.580
I'm hopeful that--
what I'm fearful of is

00:28:39.580 --> 00:28:41.960
well-intentioned souls who
say, let's put this data

00:28:41.960 --> 00:28:45.550
in the cloud and we'll give
the data back to the consumer.

00:28:45.550 --> 00:28:47.937
But it's still
sitting in the cloud

00:28:47.937 --> 00:28:49.395
without their
immediate permission.

00:28:53.770 --> 00:28:56.130
This story doesn't
end well, with a data

00:28:56.130 --> 00:28:57.630
breach or a problem.

00:28:57.630 --> 00:29:00.900
What I'd rather do is have
kind of in these examples,

00:29:00.900 --> 00:29:02.910
people think about
new architectures.

00:29:02.910 --> 00:29:04.990
And the one like we said
in healthcare.gov, new

00:29:04.990 --> 00:29:07.380
architecture to me--
empowering patients

00:29:07.380 --> 00:29:10.260
with digital copies of their own
data going back to blue button,

00:29:10.260 --> 00:29:11.660
and then having
doctors do things

00:29:11.660 --> 00:29:13.990
like ask patients for
that blue button file--

00:29:13.990 --> 00:29:16.390
are critical to that success.

00:29:16.390 --> 00:29:18.560
MALE SPEAKER: I think having
some first-- not first,

00:29:18.560 --> 00:29:21.000
but the next few steps
need to be cautious still

00:29:21.000 --> 00:29:24.780
as we go because there is a
risk of basically poisoning

00:29:24.780 --> 00:29:26.982
the well if we don't do that.

00:29:26.982 --> 00:29:28.050
Well, great.

00:29:28.050 --> 00:29:29.085
Are there any questions
from the group?

00:29:29.085 --> 00:29:29.585
Please.

00:29:29.585 --> 00:29:30.200
Hey.

00:29:30.200 --> 00:29:32.699
Use the microphone if you would
because there's an audience.

00:29:36.010 --> 00:29:36.810
AUDIENCE: Hello.

00:29:36.810 --> 00:29:37.490
ANEESH CHOPRA: Hello.

00:29:37.490 --> 00:29:38.780
AUDIENCE: Thanks for coming
in and speaking to us,

00:29:38.780 --> 00:29:39.790
and writing the
book, and working

00:29:39.790 --> 00:29:40.990
in this really important area.

00:29:40.990 --> 00:29:42.220
ANEESH CHOPRA: Thanks for
wearing a Sunlight Foundation

00:29:42.220 --> 00:29:42.720
shirt.

00:29:42.720 --> 00:29:45.880
AUDIENCE: It's total
coincidence, actually.

00:29:45.880 --> 00:29:47.580
It was the only clean
shirt I had left.

00:29:47.580 --> 00:29:48.641
ANEESH CHOPRA: Exactly.

00:29:48.641 --> 00:29:50.140
AUDIENCE: So my
question is actually

00:29:50.140 --> 00:29:52.780
just your vision about what
the future of democracy

00:29:52.780 --> 00:29:54.520
looks like in a digital age.

00:29:54.520 --> 00:29:57.240
And by democracy, I mean
it in its purest form.

00:29:57.240 --> 00:29:59.155
So a group of people
coming together

00:29:59.155 --> 00:30:02.100
and trying to make a decision
about some sort of shared

00:30:02.100 --> 00:30:02.600
issue.

00:30:02.600 --> 00:30:04.558
And how does that look
different in the future?

00:30:04.558 --> 00:30:06.060
And as a little
bit of a context,

00:30:06.060 --> 00:30:07.780
I think it's pretty
easy to observe

00:30:07.780 --> 00:30:12.090
as different industries,
as it were, digitize.

00:30:12.090 --> 00:30:14.660
It's not just about
moving stuff online.

00:30:14.660 --> 00:30:17.222
Like the nature of the services,
the nature of the industry

00:30:17.222 --> 00:30:18.250
has absolutely changed.

00:30:18.250 --> 00:30:21.490
Just ask anybody who's in
journalism or music, et cetera.

00:30:21.490 --> 00:30:24.410
But when we look at our own
democracy in a digital age,

00:30:24.410 --> 00:30:27.570
basically the way that
the processes work

00:30:27.570 --> 00:30:28.710
are exactly the same.

00:30:28.710 --> 00:30:31.907
So Congress is operating
basically the way it used to.

00:30:31.907 --> 00:30:32.990
Legislatures are the same.

00:30:32.990 --> 00:30:36.100
So really, how does this kind
of collective decision-making

00:30:36.100 --> 00:30:39.410
process, ie democracy, look
different in a digital age

00:30:39.410 --> 00:30:42.425
once it's sort of disrupted
like other industries have been?

00:30:42.425 --> 00:30:43.800
ANEESH CHOPRA:
One attribute will

00:30:43.800 --> 00:30:46.630
be frictionless participation.

00:30:46.630 --> 00:30:50.050
What I mean by that
is we all have--

00:30:50.050 --> 00:30:52.420
we're a nation of
300 million people

00:30:52.420 --> 00:30:54.760
with 3 million
government employees.

00:30:54.760 --> 00:30:57.510
And if we can embrace
the spirit that

00:30:57.510 --> 00:31:01.670
tapping into the 300
million, or 297 beyond the 3,

00:31:01.670 --> 00:31:05.070
is a critical path
to solving problems.

00:31:05.070 --> 00:31:07.920
One important way of
doing that is to make it

00:31:07.920 --> 00:31:09.259
frictionless participation.

00:31:09.259 --> 00:31:10.800
You might think of
that as government

00:31:10.800 --> 00:31:14.480
by APIs, as one technical model.

00:31:14.480 --> 00:31:16.970
But let me give you
a couple of examples

00:31:16.970 --> 00:31:19.720
because we're starting to
see this come into play.

00:31:19.720 --> 00:31:23.600
In the wake of
Wall Street reform,

00:31:23.600 --> 00:31:27.270
huge political backlash
around big banks.

00:31:27.270 --> 00:31:32.000
Big fight in Congress
over new regulations

00:31:32.000 --> 00:31:34.650
to curtail, "too
big to fail," and do

00:31:34.650 --> 00:31:37.030
other things-- big
political fight.

00:31:37.030 --> 00:31:41.130
And in the law are
two pretty interesting

00:31:41.130 --> 00:31:46.450
new government roles that had
completely different outcomes

00:31:46.450 --> 00:31:48.650
on what happened on the
implementation side.

00:31:48.650 --> 00:31:51.710
One is the creation of a
Consumer Protection Bureau

00:31:51.710 --> 00:31:54.994
to advocate for
the American people

00:31:54.994 --> 00:31:57.160
to make sure that they're
not swindled, if you will,

00:31:57.160 --> 00:32:02.650
on what my friend, now
Senator Elizabeth Warren,

00:32:02.650 --> 00:32:06.930
talks about tricks and
traps in the fine print.

00:32:06.930 --> 00:32:10.040
The other was the
establishment of a new rule

00:32:10.040 --> 00:32:13.190
basically banning proprietary
trading inside banks.

00:32:13.190 --> 00:32:15.060
It's called the Volcker Rule.

00:32:15.060 --> 00:32:17.570
These are two of the more
controversial features

00:32:17.570 --> 00:32:19.900
of the Dodd-Frank bill.

00:32:19.900 --> 00:32:21.280
Well, what happened?

00:32:21.280 --> 00:32:23.940
The Consumer Protection Bureau,
because Elizabeth Warren

00:32:23.940 --> 00:32:26.530
was named as the first
sort of launcher of it,

00:32:26.530 --> 00:32:29.330
we met very early
in her appointment.

00:32:29.330 --> 00:32:31.310
And I sort of asked
her the question,

00:32:31.310 --> 00:32:35.110
would you like to lead the
last agency of the 20th century

00:32:35.110 --> 00:32:37.705
or the first agency
born in the 21st?

00:32:37.705 --> 00:32:38.830
And you know what she said.

00:32:38.830 --> 00:32:40.550
She's a data queen.

00:32:40.550 --> 00:32:42.570
So she said, no, I
want to be more open,

00:32:42.570 --> 00:32:43.870
data driven, et cetera.

00:32:43.870 --> 00:32:46.770
So I dispatched my deputy
to kind of be an interim CTO

00:32:46.770 --> 00:32:48.760
as they got that
agency off the ground.

00:32:48.760 --> 00:32:51.400
And they launched a
crowd-sourcing program

00:32:51.400 --> 00:32:53.530
called Know Before You Owe.

00:32:53.530 --> 00:32:56.800
The idea was the
mortgage disclosure forms

00:32:56.800 --> 00:32:57.670
are complicated.

00:32:57.670 --> 00:32:59.240
And there are more than one.

00:32:59.240 --> 00:33:02.010
And one of the reasons people--
one potential reason why

00:33:02.010 --> 00:33:03.580
they bought bad
mortgages was they

00:33:03.580 --> 00:33:06.660
didn't fully appreciate the
risks that they were assuming.

00:33:06.660 --> 00:33:08.467
So if we did a better
job of informing them

00:33:08.467 --> 00:33:10.550
through the mortgage forms
that they complete what

00:33:10.550 --> 00:33:11.860
the risks are that
they're taking,

00:33:11.860 --> 00:33:13.670
maybe we could solve
the problem or prevent

00:33:13.670 --> 00:33:15.600
this happening in the future.

00:33:15.600 --> 00:33:20.710
30,000 Americans visited
knowbeforeyouowe.gov

00:33:20.710 --> 00:33:25.060
and basically gave commentary
and feedback on not one,

00:33:25.060 --> 00:33:27.080
but two-- kind of
like, am I hot or not?

00:33:27.080 --> 00:33:28.670
Remember that awkward thing?

00:33:28.670 --> 00:33:31.562
We created an, am I hot
or not for mortgage forms.

00:33:31.562 --> 00:33:32.520
Which form do you like?

00:33:32.520 --> 00:33:33.820
Which ones don't you like?

00:33:33.820 --> 00:33:36.280
And give us your
feedback as to why.

00:33:36.280 --> 00:33:39.280
Tons of participation, which
meant long before the official

00:33:39.280 --> 00:33:41.604
rulemaking process
even happened,

00:33:41.604 --> 00:33:43.020
the president of
the United States

00:33:43.020 --> 00:33:46.370
could hold a copy of
the American-made form

00:33:46.370 --> 00:33:49.080
and say that this will be the
disclosure form going forward,

00:33:49.080 --> 00:33:51.900
and then eventually made
its way through regulation.

00:33:51.900 --> 00:33:55.840
In contrast, the
Volcker Rule, back-door

00:33:55.840 --> 00:33:59.322
secretive society kind of stuff.

00:33:59.322 --> 00:34:01.780
Technically, the American people
could have given feedback.

00:34:01.780 --> 00:34:03.810
It was available
on the internet.

00:34:03.810 --> 00:34:09.260
But like maybe 20 comments
were posted on that rule.

00:34:09.260 --> 00:34:11.040
Now, I don't want
to be a cynic, but I

00:34:11.040 --> 00:34:14.570
think that 30,000 beats 20
on the quality of feedback

00:34:14.570 --> 00:34:16.610
and the ability to
get rules right.

00:34:16.610 --> 00:34:18.920
And that's a metaphor for
all these other aspects

00:34:18.920 --> 00:34:23.889
of digital service, which is the
president had a review of all

00:34:23.889 --> 00:34:27.210
of the voting technologies
and voting problems.

00:34:27.210 --> 00:34:30.239
Why do we have to wait in
line for six hours to vote?

00:34:30.239 --> 00:34:34.710
If I can use my smartphone to
check-in to my flight, which

00:34:34.710 --> 00:34:37.510
has all the TSA sensitivity
and I can do that,

00:34:37.510 --> 00:34:39.570
why can't I check-in to vote?

00:34:39.570 --> 00:34:41.530
So in fact, now there's
an open collaboration

00:34:41.530 --> 00:34:44.320
to try to build those
technologies to allow folks

00:34:44.320 --> 00:34:45.739
to check-in to vote.

00:34:45.739 --> 00:34:47.030
And more will come.

00:34:47.030 --> 00:34:49.590
And it has a lot more
to do with understanding

00:34:49.590 --> 00:34:53.080
the potential of mobile,
cloud, and big data

00:34:53.080 --> 00:34:56.000
in ways that we hadn't
imagined them in our democracy.

00:34:56.000 --> 00:34:58.280
So I have hope, but
I also understand

00:34:58.280 --> 00:35:00.030
that it's going to
take time to get there.

00:35:00.030 --> 00:35:02.190
And that Dodd-Frank
bill is a study

00:35:02.190 --> 00:35:04.060
in those two different worlds.

00:35:04.060 --> 00:35:05.920
Other questions?

00:35:05.920 --> 00:35:06.420
Yes, please.

00:35:09.080 --> 00:35:10.670
AUDIENCE: I know
open data is quite

00:35:10.670 --> 00:35:13.830
vital for creating
innovation economy concept.

00:35:13.830 --> 00:35:16.752
Do you see open source software
having a role in that as well?

00:35:16.752 --> 00:35:18.960
ANEESH CHOPRA: Yes, so this
is an important question.

00:35:18.960 --> 00:35:20.650
I'm often asked,
should the government

00:35:20.650 --> 00:35:24.080
make a preference for open
source over proprietary code?

00:35:24.080 --> 00:35:26.850
And actually, I am on
the side of the folks

00:35:26.850 --> 00:35:28.890
that say no, we should
not take preference.

00:35:28.890 --> 00:35:30.970
And the reason is,
I don't particularly

00:35:30.970 --> 00:35:34.320
care about who owns
the code base that

00:35:34.320 --> 00:35:37.230
facilitates social good.

00:35:37.230 --> 00:35:39.290
I care that they're
open interfaces.

00:35:39.290 --> 00:35:41.360
So let's just take
medical records again.

00:35:41.360 --> 00:35:43.900
I don't necessarily think
that every hospital and doctor

00:35:43.900 --> 00:35:46.340
in America needs to
have an open source

00:35:46.340 --> 00:35:48.640
electronic medical
records software package.

00:35:48.640 --> 00:35:52.070
But what I want is whatever
proprietary systems exist,

00:35:52.070 --> 00:35:54.120
that they should give
every patient the ability

00:35:54.120 --> 00:35:56.810
to view, download, and
transfer that medical record

00:35:56.810 --> 00:36:00.610
file to whomever they
want frictionlessly.

00:36:00.610 --> 00:36:04.910
And that's a difference, open
interface versus open source.

00:36:04.910 --> 00:36:08.050
Now, there's a moment where open
source has its benefits, too.

00:36:08.050 --> 00:36:13.050
The VA, as a government agency
and sensitive to its cost

00:36:13.050 --> 00:36:15.540
structure, is
actually doubling down

00:36:15.540 --> 00:36:19.640
on its open source instance
of its Vista software package

00:36:19.640 --> 00:36:21.970
to help doctors
and patients have

00:36:21.970 --> 00:36:24.030
healthier experiences in the VA.

00:36:24.030 --> 00:36:25.785
And so you'll see a
lot more opportunity

00:36:25.785 --> 00:36:30.180
to create modules to plug-in
aspects of new technologies

00:36:30.180 --> 00:36:31.110
into that environment.

00:36:31.110 --> 00:36:33.730
And they're going to make
the code base open source

00:36:33.730 --> 00:36:35.520
so anyone can write to it.

00:36:35.520 --> 00:36:38.070
But that's not something
I'd impose on the society

00:36:38.070 --> 00:36:41.020
as a whole, that's a judgment
that that agency made based

00:36:41.020 --> 00:36:43.642
on its cost benefit analysis.

00:36:43.642 --> 00:36:45.600
And I think that's the
right posture generally,

00:36:45.600 --> 00:36:47.720
when thinking about
how we solve problems.

00:36:47.720 --> 00:36:49.540
AUDIENCE: So
collaboration in the space

00:36:49.540 --> 00:36:51.190
of building the
software, but not-- but

00:36:51.190 --> 00:36:53.440
like just to open data totally
separate kind of thing.

00:36:53.440 --> 00:36:54.315
ANEESH CHOPRA: Right.

00:36:54.315 --> 00:36:56.320
One of the points of
history in the book I write

00:36:56.320 --> 00:36:58.740
is that Herbert
Hoover-- we're not

00:36:58.740 --> 00:37:01.430
far from the Hoover
Institute-- not normally cited

00:37:01.430 --> 00:37:03.530
as like the greatest
president of all time.

00:37:03.530 --> 00:37:05.520
In fact, quite the opposite.

00:37:05.520 --> 00:37:08.860
But when he was
Secretary of Commerce,

00:37:08.860 --> 00:37:11.820
issued a vision of the role
of government in society.

00:37:11.820 --> 00:37:14.330
Not picking winners and
losers, ie proprietary

00:37:14.330 --> 00:37:16.550
versus open source,
but to establish

00:37:16.550 --> 00:37:19.950
a mechanism for pre-competitive
R&amp;D-- my language.

00:37:19.950 --> 00:37:23.700
He called it the associative
state, where we work together.

00:37:23.700 --> 00:37:29.230
And that example was that
Boeing and Douglas at the time

00:37:29.230 --> 00:37:31.209
were airline manufacturers.

00:37:31.209 --> 00:37:32.750
After the end of
World War I, America

00:37:32.750 --> 00:37:34.830
wasn't a leader in
airline manufacturing.

00:37:34.830 --> 00:37:38.090
European countries were
investing and subsidizing

00:37:38.090 --> 00:37:39.520
competitors.

00:37:39.520 --> 00:37:41.460
And we had some
fundamental problems.

00:37:41.460 --> 00:37:43.960
We didn't know how to make air
foils the right way or engine

00:37:43.960 --> 00:37:45.140
cowlings.

00:37:45.140 --> 00:37:48.120
So Hoover says that
that's pre-competitive

00:37:48.120 --> 00:37:51.790
R&amp;D. Let's fund it, but open
up the intellectual property

00:37:51.790 --> 00:37:57.300
so that both Boeing's
247 and the DC-3

00:37:57.300 --> 00:37:59.930
can compete on
what they do on top

00:37:59.930 --> 00:38:01.690
of that pre-competitive
component,

00:38:01.690 --> 00:38:05.280
so that their final product
is most certainly proprietary

00:38:05.280 --> 00:38:07.740
but it is powered
by this asset which

00:38:07.740 --> 00:38:10.240
was built in part by a
collaboration with government.

00:38:10.240 --> 00:38:12.867
So these are the nuances I
try to highlight in the book,

00:38:12.867 --> 00:38:14.200
at least as to my point of view.

00:38:14.200 --> 00:38:15.380
AUDIENCE: Yeah, thanks.

00:38:15.380 --> 00:38:17.580
ANEESH CHOPRA: Yes, sir.

00:38:17.580 --> 00:38:20.942
AUDIENCE: So I love the idea of
this opendata.gov initiative.

00:38:20.942 --> 00:38:23.150
Is there an important
difference we should understand

00:38:23.150 --> 00:38:27.270
between a newly created
government data set and a data

00:38:27.270 --> 00:38:31.290
set maybe created through
government funding?

00:38:31.290 --> 00:38:32.680
ANEESH CHOPRA: Great question.

00:38:32.680 --> 00:38:34.820
And in the spirit
of depression, this

00:38:34.820 --> 00:38:37.540
is the Aaron Swartz
story, which is

00:38:37.540 --> 00:38:42.540
to say government funds basic
research and development.

00:38:42.540 --> 00:38:45.600
And as a matter of
principle, that knowledge

00:38:45.600 --> 00:38:46.830
should be freely available.

00:38:46.830 --> 00:38:49.240
But because of the
way publishing works,

00:38:49.240 --> 00:38:54.400
there's a private intermediary
that commercializes and funds

00:38:54.400 --> 00:38:58.294
all of the necessary work to
select the quality articles

00:38:58.294 --> 00:38:59.710
and to choose which
ones are worth

00:38:59.710 --> 00:39:01.420
publishing and all of that.

00:39:01.420 --> 00:39:03.810
And so I don't bemoan
the fact that we

00:39:03.810 --> 00:39:06.710
need a part of our economy
to filter and to have

00:39:06.710 --> 00:39:09.750
that editorial role and to
produce these documents.

00:39:09.750 --> 00:39:12.590
But the tension is,
how do we open up

00:39:12.590 --> 00:39:15.030
the data in
government-funded work?

00:39:15.030 --> 00:39:17.200
And I think we struck
a happy medium, which

00:39:17.200 --> 00:39:22.210
is the publishers get to
retain a year of rights,

00:39:22.210 --> 00:39:25.200
at least that's the
default setting.

00:39:25.200 --> 00:39:28.480
And that upon that
year coming up,

00:39:28.480 --> 00:39:32.770
it moves into more of an open
model-- open access model.

00:39:32.770 --> 00:39:36.640
I think individual case examples
of government-funded research

00:39:36.640 --> 00:39:38.510
will have different
flavors of this.

00:39:38.510 --> 00:39:40.470
And there's a beautiful
debate in our society

00:39:40.470 --> 00:39:42.390
around the degree
to which we want

00:39:42.390 --> 00:39:44.500
technology transfer
in commercialization.

00:39:44.500 --> 00:39:46.690
In some cases, agencies
will do it for free.

00:39:46.690 --> 00:39:48.510
I write the story
of Procter &amp; Gamble

00:39:48.510 --> 00:39:52.940
that commercialized modeling
and simulation product out

00:39:52.940 --> 00:39:56.570
of the national labs
to help them remove

00:39:56.570 --> 00:39:59.780
particle dust from the facility.

00:39:59.780 --> 00:40:03.120
Procter &amp; Gamble was able
to repurpose that technology

00:40:03.120 --> 00:40:05.050
into their diaper
manufacturing operation,

00:40:05.050 --> 00:40:07.710
improving their cash flow
about a billion dollars

00:40:07.710 --> 00:40:10.870
over the course
of several years.

00:40:10.870 --> 00:40:13.220
And they've gone back
and contributed back

00:40:13.220 --> 00:40:17.484
to the Department of Energy more
modeling and simulation tools

00:40:17.484 --> 00:40:19.150
that could be made
available for others.

00:40:19.150 --> 00:40:23.070
So there's not a requirement,
but a collaboration mindset

00:40:23.070 --> 00:40:24.650
that created an opportunity.

00:40:24.650 --> 00:40:27.950
So you're going to see different
examples that are there.

00:40:27.950 --> 00:40:30.874
As long as there's a path
to have that conversation,

00:40:30.874 --> 00:40:32.040
I think we're in safe hands.

00:40:32.040 --> 00:40:33.700
AUDIENCE: Could I ask
one quick follow-up?

00:40:33.700 --> 00:40:34.616
ANEESH CHOPRA: Please.

00:40:34.616 --> 00:40:36.520
AUDIENCE: Have you
guys thought about ways

00:40:36.520 --> 00:40:39.229
to solicit feedback about
what public data sets

00:40:39.229 --> 00:40:40.270
people would like to see?

00:40:40.270 --> 00:40:41.103
ANEESH CHOPRA: 100%.

00:40:41.103 --> 00:40:43.800
This is the most important
part of the journey

00:40:43.800 --> 00:40:46.367
because we started it--
to create the culture

00:40:46.367 --> 00:40:48.450
change, of course you have
President Obama saying,

00:40:48.450 --> 00:40:49.500
this is a priority.

00:40:49.500 --> 00:40:51.682
Day one in office sets this.

00:40:51.682 --> 00:40:53.390
In the midst of the
economic crisis says,

00:40:53.390 --> 00:40:55.540
I want to open up data.

00:40:55.540 --> 00:40:59.070
And I'm directing my newly
created CTO and my management

00:40:59.070 --> 00:41:02.560
and budget team to put rules
in place to make this happen.

00:41:02.560 --> 00:41:05.400
When we wrote the rules,
one of the key aspects

00:41:05.400 --> 00:41:11.320
was, you have like 45 days to
publish 3 high-value data sets.

00:41:11.320 --> 00:41:12.570
We didn't care what they were.

00:41:12.570 --> 00:41:15.630
You have to say what you
deem to be high value.

00:41:15.630 --> 00:41:19.660
Now, it's a joke, but the
CIA published their cafeteria

00:41:19.660 --> 00:41:20.290
menus.

00:41:20.290 --> 00:41:22.540
MALE SPEAKER: Which are very
important at Google, too.

00:41:22.540 --> 00:41:24.085
ANEESH CHOPRA: Very
important here at Google.

00:41:24.085 --> 00:41:26.660
We got to know which building
to go to for the Chinese menu

00:41:26.660 --> 00:41:27.150
and which for the Indian food.

00:41:27.150 --> 00:41:27.510
MALE SPEAKER: Google Data.

00:41:27.510 --> 00:41:28.801
ANEESH CHOPRA: Yeah, of course.

00:41:28.801 --> 00:41:33.560
But the point is we also
said that they must open up

00:41:33.560 --> 00:41:36.770
channels of participation so
that people can share feedback

00:41:36.770 --> 00:41:37.590
in.

00:41:37.590 --> 00:41:41.650
I give that a C on its
execution because there really

00:41:41.650 --> 00:41:43.090
hasn't been a lot of demand.

00:41:43.090 --> 00:41:45.750
What you see is the
Sunlight Foundation,

00:41:45.750 --> 00:41:47.560
accountability
organizations that

00:41:47.560 --> 00:41:52.770
want spending data,
lobbyist data, sort of data

00:41:52.770 --> 00:41:55.570
on the political
side of government.

00:41:55.570 --> 00:41:57.809
They've been the most
aggressive in asking.

00:41:57.809 --> 00:41:59.350
So we publish the
White House visitor

00:41:59.350 --> 00:42:01.044
logs in response
to that request.

00:42:01.044 --> 00:42:03.710
You could see everybody who came
to visit me at the White House,

00:42:03.710 --> 00:42:06.730
for example.

00:42:06.730 --> 00:42:11.150
But for commercial use, there
aren't as many people thinking

00:42:11.150 --> 00:42:15.480
in their mind, I want to build
a MOOC that has the ability

00:42:15.480 --> 00:42:18.680
to access records from the
Department of Education

00:42:18.680 --> 00:42:20.000
or states.

00:42:20.000 --> 00:42:22.380
And I want to incorporate
that into my algorithm

00:42:22.380 --> 00:42:25.050
to predict which
module of the lesson

00:42:25.050 --> 00:42:28.300
plan should I put in front
of which student based

00:42:28.300 --> 00:42:32.560
on my sense of their profile.

00:42:32.560 --> 00:42:35.270
I wish more folks said that
because that would open up

00:42:35.270 --> 00:42:37.600
a new conversation which
says, oh, well, we may not

00:42:37.600 --> 00:42:39.804
be collecting it in
that format today,

00:42:39.804 --> 00:42:41.220
but let's work
together to see how

00:42:41.220 --> 00:42:42.830
we could exercise that muscle.

00:42:42.830 --> 00:42:44.539
The reason the book
to me is so critical,

00:42:44.539 --> 00:42:46.538
not only for the private
sector to understand it

00:42:46.538 --> 00:42:48.230
but in the government
is, if I work

00:42:48.230 --> 00:42:50.930
in the Department of Education
and my mission objective

00:42:50.930 --> 00:42:55.200
is that I want every child to
have access to a great math

00:42:55.200 --> 00:42:58.709
education, regardless of their
race and their income status.

00:42:58.709 --> 00:43:00.250
If you came to me
and said, I'm going

00:43:00.250 --> 00:43:03.062
to create a digital tutor
for every one of those kids,

00:43:03.062 --> 00:43:05.520
it would be really helpful if
I had access to such and such

00:43:05.520 --> 00:43:06.410
and such.

00:43:06.410 --> 00:43:08.470
Boy, that's a different
conversation than,

00:43:08.470 --> 00:43:11.650
can I get a government
contract to go build something

00:43:11.650 --> 00:43:12.730
on your behalf?

00:43:12.730 --> 00:43:15.114
Or can you put a new
regulation in place

00:43:15.114 --> 00:43:17.530
where you have a little bit
more of the traditional levers

00:43:17.530 --> 00:43:18.113
of government?

00:43:18.113 --> 00:43:22.570
So C moving to B, maybe to
A as more of the ecosystem

00:43:22.570 --> 00:43:25.510
is aware of the possibilities
of new data sets

00:43:25.510 --> 00:43:28.430
to be made available.

00:43:28.430 --> 00:43:30.320
MALE SPEAKER: Any
other questions?

00:43:30.320 --> 00:43:32.190
It's one last one.

00:43:32.190 --> 00:43:34.500
Are you worried about--
with the potential change

00:43:34.500 --> 00:43:36.530
of administration,
and potentially change

00:43:36.530 --> 00:43:38.855
of party, who knows,
what will come?

00:43:38.855 --> 00:43:41.870
Are you worried about some of
these advances being undone?

00:43:41.870 --> 00:43:43.590
Or is this inevitable,
this movement?

00:43:43.590 --> 00:43:45.520
ANEESH CHOPRA: So the
reason I'm so hopeful

00:43:45.520 --> 00:43:49.230
is that this is the one area
where both sides seem to agree.

00:43:49.230 --> 00:43:52.450
And just to give
you an example, I

00:43:52.450 --> 00:43:55.140
served as Virginia's
Secretary of Technology,

00:43:55.140 --> 00:43:57.540
which was essentially a
cabinet-level position

00:43:57.540 --> 00:44:00.670
akin to what President Obama
set up at the White House.

00:44:00.670 --> 00:44:02.720
A Republican
governor of Virginia

00:44:02.720 --> 00:44:06.320
created the nation's first
Secretary of Technology,

00:44:06.320 --> 00:44:08.810
carried on by
Democratic governor.

00:44:08.810 --> 00:44:10.280
And again, a
Republican governor.

00:44:10.280 --> 00:44:11.655
And again, a
Democratic governor.

00:44:11.655 --> 00:44:13.130
And now we have
this culture where

00:44:13.130 --> 00:44:16.240
that's a novel idea
that's instantiated

00:44:16.240 --> 00:44:20.830
into the DNA of what is deemed
by the objective measures best

00:44:20.830 --> 00:44:22.970
managed state in
America according

00:44:22.970 --> 00:44:24.700
to "Governing" magazine.

00:44:24.700 --> 00:44:28.300
And now at the federal
level, opening up data

00:44:28.300 --> 00:44:32.230
actually got a unanimous
vote in the Congress--

00:44:32.230 --> 00:44:33.900
a unanimous vote.

00:44:33.900 --> 00:44:38.715
Mark Warner and Eric Cantor, a
Republican member of the House,

00:44:38.715 --> 00:44:40.520
the majority leader
of the House,

00:44:40.520 --> 00:44:43.030
and a Democratic senator
both from Virginia

00:44:43.030 --> 00:44:47.050
don't normally see eye to eye
and hang out and collaborate.

00:44:47.050 --> 00:44:50.479
They patroned this data
act, which in this case

00:44:50.479 --> 00:44:52.770
opened up financial transactions
data in the government

00:44:52.770 --> 00:44:54.330
on a standardized format.

00:44:54.330 --> 00:44:57.470
And the president
signs this into law.

00:44:57.470 --> 00:44:59.550
So my hope is
whomever is elected

00:44:59.550 --> 00:45:03.130
president next will
build on this foundation

00:45:03.130 --> 00:45:04.890
and we'll start
to see a new army.

00:45:04.890 --> 00:45:07.330
I went to the Kennedy
School of Government,

00:45:07.330 --> 00:45:12.000
and I was never trained
on the power of open data

00:45:12.000 --> 00:45:13.190
as a policy lever.

00:45:13.190 --> 00:45:16.200
I was trained on, how do you
get Congress to take an action?

00:45:16.200 --> 00:45:19.740
How do you move the executive
branch in regulation?

00:45:19.740 --> 00:45:21.320
But this idea that
there could be

00:45:21.320 --> 00:45:23.420
ways to collect data
and disseminate it

00:45:23.420 --> 00:45:26.890
in a more friendly manner for
entrepreneurs and innovators,

00:45:26.890 --> 00:45:28.540
didn't have a
single course on it.

00:45:28.540 --> 00:45:32.280
So I think as a new army
of government employees

00:45:32.280 --> 00:45:35.650
understand this as a viable
path to achieve their mission

00:45:35.650 --> 00:45:38.310
objective, you're going to see
the whole ecosystem respond

00:45:38.310 --> 00:45:38.829
better.

00:45:38.829 --> 00:45:41.370
Entrepreneurs see the chance to
commercialize and make money.

00:45:41.370 --> 00:45:44.280
If you make a billion
dollars selling

00:45:44.280 --> 00:45:48.350
a startup who closed the
educational achievement gap,

00:45:48.350 --> 00:45:52.360
I would say thank you on
behalf of our country.

00:45:52.360 --> 00:45:55.330
We wouldn't-- oh, how dare you
make a billion dollars doing

00:45:55.330 --> 00:45:55.830
this?

00:45:55.830 --> 00:45:58.070
No, make two.

00:45:58.070 --> 00:45:59.810
Close the achievement gap.

00:45:59.810 --> 00:46:04.110
So we will see a new era of
entrepreneurs succeed in this.

00:46:04.110 --> 00:46:06.780
We're going to see more
data sets come to life.

00:46:06.780 --> 00:46:09.980
And I hope we're going to see
the political will to treat

00:46:09.980 --> 00:46:12.770
this as a very important--
and if not equal to,

00:46:12.770 --> 00:46:15.260
but a very important
lever in addition

00:46:15.260 --> 00:46:17.290
to the traditional models
of government spending

00:46:17.290 --> 00:46:18.230
and regulation.

00:46:18.230 --> 00:46:19.980
MALE SPEAKER: On that
very optimistic note

00:46:19.980 --> 00:46:21.740
and hopeful as well,
let's end there.

00:46:21.740 --> 00:46:22.829
Thank you very much.

00:46:22.829 --> 00:46:25.370
ANEESH CHOPRA: Thanks for having
me, and I wish you all well.

00:46:25.370 --> 00:46:29.230
[APPLAUSE]

