WEBVTT
Kind: captions
Language: en

00:00:00.319 --> 00:00:02.570 align:start position:0%
 
if<00:00:01.319><c> you're</c><00:00:01.530><c> building</c><00:00:01.709><c> a</c><00:00:01.949><c> computer</c><00:00:02.220><c> vision</c>

00:00:02.570 --> 00:00:02.580 align:start position:0%
if you're building a computer vision
 

00:00:02.580 --> 00:00:04.849 align:start position:0%
if you're building a computer vision
application<00:00:03.270><c> rather</c><00:00:03.870><c> than</c><00:00:04.080><c> training</c><00:00:04.560><c> the</c>

00:00:04.849 --> 00:00:04.859 align:start position:0%
application rather than training the
 

00:00:04.859 --> 00:00:06.619 align:start position:0%
application rather than training the
waste<00:00:05.100><c> from</c><00:00:05.370><c> scratch</c><00:00:05.819><c> from</c><00:00:06.150><c> random</c>

00:00:06.619 --> 00:00:06.629 align:start position:0%
waste from scratch from random
 

00:00:06.629 --> 00:00:08.660 align:start position:0%
waste from scratch from random
initialization<00:00:07.379><c> you</c><00:00:07.859><c> often</c><00:00:08.189><c> make</c><00:00:08.370><c> much</c>

00:00:08.660 --> 00:00:08.670 align:start position:0%
initialization you often make much
 

00:00:08.670 --> 00:00:10.520 align:start position:0%
initialization you often make much
faster<00:00:09.059><c> progress</c><00:00:09.510><c> if</c><00:00:09.690><c> you</c><00:00:09.809><c> download</c><00:00:10.260><c> weights</c>

00:00:10.520 --> 00:00:10.530 align:start position:0%
faster progress if you download weights
 

00:00:10.530 --> 00:00:12.499 align:start position:0%
faster progress if you download weights
that<00:00:11.040><c> someone</c><00:00:11.460><c> else</c><00:00:11.580><c> has</c><00:00:11.790><c> already</c><00:00:11.820><c> trained</c><00:00:12.360><c> on</c>

00:00:12.499 --> 00:00:12.509 align:start position:0%
that someone else has already trained on
 

00:00:12.509 --> 00:00:14.660 align:start position:0%
that someone else has already trained on
the<00:00:12.599><c> network</c><00:00:12.929><c> architecture</c><00:00:13.110><c> and</c><00:00:13.740><c> use</c><00:00:14.250><c> that</c><00:00:14.460><c> as</c>

00:00:14.660 --> 00:00:14.670 align:start position:0%
the network architecture and use that as
 

00:00:14.670 --> 00:00:17.390 align:start position:0%
the network architecture and use that as
pre-training<00:00:15.299><c> and</c><00:00:15.599><c> transfer</c><00:00:16.470><c> that</c><00:00:16.500><c> to</c><00:00:17.160><c> a</c><00:00:17.190><c> new</c>

00:00:17.390 --> 00:00:17.400 align:start position:0%
pre-training and transfer that to a new
 

00:00:17.400 --> 00:00:19.849 align:start position:0%
pre-training and transfer that to a new
task<00:00:17.699><c> that</c><00:00:18.060><c> you</c><00:00:18.210><c> might</c><00:00:18.449><c> be</c><00:00:18.570><c> interested</c><00:00:19.050><c> in</c><00:00:19.230><c> do</c>

00:00:19.849 --> 00:00:19.859 align:start position:0%
task that you might be interested in do
 

00:00:19.859 --> 00:00:21.650 align:start position:0%
task that you might be interested in do
you<00:00:19.949><c> computer</c><00:00:20.430><c> vision</c><00:00:20.699><c> research</c><00:00:20.850><c> community</c>

00:00:21.650 --> 00:00:21.660 align:start position:0%
you computer vision research community
 

00:00:21.660 --> 00:00:24.230 align:start position:0%
you computer vision research community
has<00:00:21.990><c> been</c><00:00:22.170><c> pretty</c><00:00:22.439><c> good</c><00:00:22.680><c> at</c><00:00:23.130><c> posting</c><00:00:23.760><c> lots</c><00:00:24.029><c> of</c>

00:00:24.230 --> 00:00:24.240 align:start position:0%
has been pretty good at posting lots of
 

00:00:24.240 --> 00:00:26.029 align:start position:0%
has been pretty good at posting lots of
data<00:00:24.480><c> sense</c><00:00:24.810><c> on</c><00:00:25.019><c> the</c><00:00:25.289><c> internet</c><00:00:25.710><c> so</c><00:00:25.920><c> if</c><00:00:25.980><c> you</c>

00:00:26.029 --> 00:00:26.039 align:start position:0%
data sense on the internet so if you
 

00:00:26.039 --> 00:00:28.310 align:start position:0%
data sense on the internet so if you
hear<00:00:26.310><c> of</c><00:00:26.430><c> things</c><00:00:26.760><c> like</c><00:00:26.939><c> image</c><00:00:27.599><c> net</c><00:00:27.810><c> or</c><00:00:28.050><c> and</c><00:00:28.199><c> as</c>

00:00:28.310 --> 00:00:28.320 align:start position:0%
hear of things like image net or and as
 

00:00:28.320 --> 00:00:30.800 align:start position:0%
hear of things like image net or and as
Coco<00:00:28.769><c> or</c><00:00:29.070><c> as</c><00:00:29.550><c> gal</c><00:00:29.880><c> all</c><00:00:30.029><c> types</c><00:00:30.240><c> of</c><00:00:30.300><c> data</c><00:00:30.449><c> says</c>

00:00:30.800 --> 00:00:30.810 align:start position:0%
Coco or as gal all types of data says
 

00:00:30.810 --> 00:00:32.720 align:start position:0%
Coco or as gal all types of data says
these<00:00:31.320><c> are</c><00:00:31.380><c> the</c><00:00:31.650><c> names</c><00:00:31.890><c> of</c><00:00:32.099><c> different</c><00:00:32.520><c> data</c>

00:00:32.720 --> 00:00:32.730 align:start position:0%
these are the names of different data
 

00:00:32.730 --> 00:00:34.670 align:start position:0%
these are the names of different data
sets<00:00:33.059><c> that</c><00:00:33.270><c> people</c><00:00:33.329><c> have</c><00:00:33.630><c> posted</c><00:00:33.840><c> online</c><00:00:34.200><c> and</c>

00:00:34.670 --> 00:00:34.680 align:start position:0%
sets that people have posted online and
 

00:00:34.680 --> 00:00:36.200 align:start position:0%
sets that people have posted online and
that<00:00:35.309><c> a</c><00:00:35.370><c> lot</c><00:00:35.670><c> of</c><00:00:35.700><c> computer</c><00:00:36.120><c> vision</c>

00:00:36.200 --> 00:00:36.210 align:start position:0%
that a lot of computer vision
 

00:00:36.210 --> 00:00:38.209 align:start position:0%
that a lot of computer vision
researchers<00:00:36.870><c> have</c><00:00:37.260><c> trained</c><00:00:37.770><c> their</c>

00:00:38.209 --> 00:00:38.219 align:start position:0%
researchers have trained their
 

00:00:38.219 --> 00:00:40.729 align:start position:0%
researchers have trained their
algorithms<00:00:39.090><c> on</c><00:00:39.329><c> sometimes</c><00:00:40.290><c> this</c><00:00:40.440><c> training</c>

00:00:40.729 --> 00:00:40.739 align:start position:0%
algorithms on sometimes this training
 

00:00:40.739 --> 00:00:43.639 align:start position:0%
algorithms on sometimes this training
takes<00:00:41.280><c> several</c><00:00:41.850><c> weeks</c><00:00:42.000><c> and</c><00:00:42.540><c> might</c><00:00:43.079><c> take</c><00:00:43.290><c> many</c>

00:00:43.639 --> 00:00:43.649 align:start position:0%
takes several weeks and might take many
 

00:00:43.649 --> 00:00:46.520 align:start position:0%
takes several weeks and might take many
many<00:00:43.829><c> GPUs</c><00:00:44.520><c> and</c><00:00:44.879><c> the</c><00:00:45.450><c> fact</c><00:00:45.719><c> that</c><00:00:45.840><c> someone</c><00:00:46.140><c> else</c>

00:00:46.520 --> 00:00:46.530 align:start position:0%
many GPUs and the fact that someone else
 

00:00:46.530 --> 00:00:48.049 align:start position:0%
many GPUs and the fact that someone else
has<00:00:46.680><c> done</c><00:00:46.710><c> this</c><00:00:46.980><c> and</c><00:00:47.489><c> gone</c><00:00:47.700><c> through</c><00:00:47.879><c> the</c>

00:00:48.049 --> 00:00:48.059 align:start position:0%
has done this and gone through the
 

00:00:48.059 --> 00:00:49.279 align:start position:0%
has done this and gone through the
painful<00:00:48.300><c> high-performance</c><00:00:49.050><c> research</c>

00:00:49.279 --> 00:00:49.289 align:start position:0%
painful high-performance research
 

00:00:49.289 --> 00:00:50.990 align:start position:0%
painful high-performance research
process<00:00:49.739><c> means</c><00:00:50.399><c> that</c><00:00:50.610><c> you</c><00:00:50.670><c> can</c><00:00:50.820><c> often</c>

00:00:50.990 --> 00:00:51.000 align:start position:0%
process means that you can often
 

00:00:51.000 --> 00:00:53.779 align:start position:0%
process means that you can often
download<00:00:51.960><c> open</c><00:00:52.710><c> source</c><00:00:52.980><c> weights</c><00:00:53.280><c> that</c><00:00:53.579><c> took</c>

00:00:53.779 --> 00:00:53.789 align:start position:0%
download open source weights that took
 

00:00:53.789 --> 00:00:55.760 align:start position:0%
download open source weights that took
someone<00:00:54.180><c> else</c><00:00:54.360><c> many</c><00:00:54.840><c> weeks</c><00:00:55.140><c> or</c><00:00:55.379><c> months</c><00:00:55.739><c> to</c>

00:00:55.760 --> 00:00:55.770 align:start position:0%
someone else many weeks or months to
 

00:00:55.770 --> 00:00:58.420 align:start position:0%
someone else many weeks or months to
figure<00:00:56.219><c> out</c><00:00:56.399><c> and</c><00:00:56.670><c> use</c><00:00:57.239><c> that</c><00:00:57.449><c> it's</c><00:00:57.719><c> a</c><00:00:57.780><c> very</c><00:00:57.960><c> good</c>

00:00:58.420 --> 00:00:58.430 align:start position:0%
figure out and use that it's a very good
 

00:00:58.430 --> 00:01:00.590 align:start position:0%
figure out and use that it's a very good
initialization<00:00:59.430><c> for</c><00:00:59.879><c> your</c><00:01:00.059><c> own</c><00:01:00.239><c> neural</c>

00:01:00.590 --> 00:01:00.600 align:start position:0%
initialization for your own neural
 

00:01:00.600 --> 00:01:03.349 align:start position:0%
initialization for your own neural
network<00:01:00.989><c> and</c><00:01:01.230><c> use</c><00:01:02.129><c> transfer</c><00:01:02.699><c> learning</c><00:01:02.910><c> to</c>

00:01:03.349 --> 00:01:03.359 align:start position:0%
network and use transfer learning to
 

00:01:03.359 --> 00:01:05.149 align:start position:0%
network and use transfer learning to
sort<00:01:03.600><c> of</c><00:01:03.660><c> transfer</c><00:01:04.140><c> knowledge</c><00:01:04.439><c> was</c><00:01:04.830><c> on</c><00:01:05.010><c> these</c>

00:01:05.149 --> 00:01:05.159 align:start position:0%
sort of transfer knowledge was on these
 

00:01:05.159 --> 00:01:07.850 align:start position:0%
sort of transfer knowledge was on these
very<00:01:05.729><c> large</c><00:01:06.060><c> public</c><00:01:06.360><c> datasets</c><00:01:06.840><c> to</c><00:01:07.560><c> your</c><00:01:07.710><c> own</c>

00:01:07.850 --> 00:01:07.860 align:start position:0%
very large public datasets to your own
 

00:01:07.860 --> 00:01:10.520 align:start position:0%
very large public datasets to your own
problem<00:01:08.460><c> let's</c><00:01:09.270><c> take</c><00:01:09.450><c> a</c><00:01:09.479><c> deeper</c><00:01:09.869><c> look</c><00:01:09.900><c> at</c><00:01:10.229><c> how</c>

00:01:10.520 --> 00:01:10.530 align:start position:0%
problem let's take a deeper look at how
 

00:01:10.530 --> 00:01:14.030 align:start position:0%
problem let's take a deeper look at how
to<00:01:10.590><c> do</c><00:01:10.830><c> this</c><00:01:10.909><c> let's</c><00:01:11.909><c> start</c><00:01:12.420><c> an</c><00:01:12.600><c> example</c><00:01:13.140><c> let's</c>

00:01:14.030 --> 00:01:14.040 align:start position:0%
to do this let's start an example let's
 

00:01:14.040 --> 00:01:16.280 align:start position:0%
to do this let's start an example let's
say<00:01:14.220><c> you're</c><00:01:14.400><c> building</c><00:01:14.790><c> a</c><00:01:14.970><c> CAD</c><00:01:15.420><c> detector</c><00:01:15.990><c> to</c>

00:01:16.280 --> 00:01:16.290 align:start position:0%
say you're building a CAD detector to
 

00:01:16.290 --> 00:01:20.539 align:start position:0%
say you're building a CAD detector to
recognize<00:01:16.830><c> your</c><00:01:17.189><c> own</c><00:01:17.430><c> pet</c><00:01:18.270><c> cat</c><00:01:18.600><c> so</c><00:01:19.549><c> according</c>

00:01:20.539 --> 00:01:20.549 align:start position:0%
recognize your own pet cat so according
 

00:01:20.549 --> 00:01:23.840 align:start position:0%
recognize your own pet cat so according
to<00:01:20.580><c> the</c><00:01:20.759><c> internet</c><00:01:21.240><c> on</c><00:01:21.860><c> Tigger</c><00:01:22.860><c> is</c><00:01:23.250><c> a</c><00:01:23.310><c> common</c>

00:01:23.840 --> 00:01:23.850 align:start position:0%
to the internet on Tigger is a common
 

00:01:23.850 --> 00:01:30.800 align:start position:0%
to the internet on Tigger is a common
cat<00:01:24.090><c> name</c><00:01:24.420><c> and</c><00:01:25.549><c> Mistie</c><00:01:26.549><c> is</c><00:01:26.610><c> another</c><00:01:29.810><c> common</c>

00:01:30.800 --> 00:01:30.810 align:start position:0%
cat name and Mistie is another common
 

00:01:30.810 --> 00:01:35.569 align:start position:0%
cat name and Mistie is another common
cat's<00:01:31.049><c> name</c><00:01:33.530><c> and</c><00:01:34.530><c> let's</c><00:01:34.740><c> say</c><00:01:34.920><c> your</c><00:01:35.130><c> cats</c><00:01:35.400><c> are</c>

00:01:35.569 --> 00:01:35.579 align:start position:0%
cat's name and let's say your cats are
 

00:01:35.579 --> 00:01:35.929 align:start position:0%
cat's name and let's say your cats are
called

00:01:35.929 --> 00:01:35.939 align:start position:0%
called
 

00:01:35.939 --> 00:01:39.920 align:start position:0%
called
Tigger<00:01:36.210><c> and</c><00:01:36.570><c> Misty</c><00:01:37.049><c> and</c><00:01:37.759><c> there's</c><00:01:38.759><c> also</c><00:01:38.970><c> you</c>

00:01:39.920 --> 00:01:39.930 align:start position:0%
Tigger and Misty and there's also you
 

00:01:39.930 --> 00:01:41.899 align:start position:0%
Tigger and Misty and there's also you
know<00:01:40.079><c> neither</c><00:01:40.670><c> so</c><00:01:41.670><c> you</c><00:01:41.729><c> have</c><00:01:41.880><c> a</c>

00:01:41.899 --> 00:01:41.909 align:start position:0%
know neither so you have a
 

00:01:41.909 --> 00:01:43.429 align:start position:0%
know neither so you have a
classification<00:01:42.210><c> problem</c><00:01:42.540><c> with</c><00:01:43.170><c> three</c>

00:01:43.429 --> 00:01:43.439 align:start position:0%
classification problem with three
 

00:01:43.439 --> 00:01:46.039 align:start position:0%
classification problem with three
classes<00:01:43.950><c> as</c><00:01:44.610><c> this</c><00:01:44.790><c> picture</c><00:01:45.000><c> Tigger</c>

00:01:46.039 --> 00:01:46.049 align:start position:0%
classes as this picture Tigger
 

00:01:46.049 --> 00:01:49.550 align:start position:0%
classes as this picture Tigger
or<00:01:46.409><c> is</c><00:01:46.470><c> it</c><00:01:46.560><c> misty</c><00:01:46.979><c> or</c><00:01:47.159><c> is</c><00:01:47.729><c> it</c><00:01:47.880><c> neither</c><00:01:48.600><c> and</c><00:01:49.259><c> what</c>

00:01:49.550 --> 00:01:49.560 align:start position:0%
or is it misty or is it neither and what
 

00:01:49.560 --> 00:01:51.170 align:start position:0%
or is it misty or is it neither and what
you<00:01:49.619><c> know</c><00:01:49.799><c> the</c><00:01:49.979><c> case</c><00:01:50.189><c> of</c><00:01:50.460><c> both</c><00:01:50.670><c> of</c><00:01:50.850><c> you</c><00:01:50.939><c> has</c>

00:01:51.170 --> 00:01:51.180 align:start position:0%
you know the case of both of you has
 

00:01:51.180 --> 00:01:54.830 align:start position:0%
you know the case of both of you has
appearing<00:01:51.990><c> in</c><00:01:52.140><c> a</c><00:01:52.290><c> picture</c><00:01:53.119><c> now</c><00:01:54.119><c> you</c><00:01:54.420><c> probably</c>

00:01:54.830 --> 00:01:54.840 align:start position:0%
appearing in a picture now you probably
 

00:01:54.840 --> 00:01:56.719 align:start position:0%
appearing in a picture now you probably
don't<00:01:55.170><c> have</c><00:01:55.320><c> a</c><00:01:55.380><c> lot</c><00:01:55.619><c> of</c><00:01:55.649><c> pictures</c><00:01:55.950><c> of</c><00:01:56.189><c> Tigger</c>

00:01:56.719 --> 00:01:56.729 align:start position:0%
don't have a lot of pictures of Tigger
 

00:01:56.729 --> 00:01:59.810 align:start position:0%
don't have a lot of pictures of Tigger
or<00:01:57.090><c> misty</c><00:01:57.840><c> so</c><00:01:58.560><c> your</c><00:01:58.799><c> training</c><00:01:59.189><c> set</c><00:01:59.399><c> will</c><00:01:59.670><c> be</c>

00:01:59.810 --> 00:01:59.820 align:start position:0%
or misty so your training set will be
 

00:01:59.820 --> 00:02:02.990 align:start position:0%
or misty so your training set will be
small<00:02:00.210><c> so</c><00:02:00.990><c> what</c><00:02:01.229><c> can</c><00:02:01.380><c> you</c><00:02:01.500><c> do</c><00:02:01.649><c> I</c><00:02:01.890><c> recommend</c><00:02:02.729><c> you</c>

00:02:02.990 --> 00:02:03.000 align:start position:0%
small so what can you do I recommend you
 

00:02:03.000 --> 00:02:05.719 align:start position:0%
small so what can you do I recommend you
go<00:02:03.180><c> online</c><00:02:03.329><c> and</c><00:02:03.780><c> download</c><00:02:04.290><c> some</c><00:02:05.040><c> open</c><00:02:05.490><c> source</c>

00:02:05.719 --> 00:02:05.729 align:start position:0%
go online and download some open source
 

00:02:05.729 --> 00:02:08.109 align:start position:0%
go online and download some open source
implementation<00:02:06.659><c> of</c><00:02:06.869><c> a</c><00:02:06.990><c> new</c><00:02:07.020><c> network</c><00:02:07.469><c> and</c>

00:02:08.109 --> 00:02:08.119 align:start position:0%
implementation of a new network and
 

00:02:08.119 --> 00:02:11.540 align:start position:0%
implementation of a new network and
download<00:02:09.119><c> not</c><00:02:09.330><c> just</c><00:02:09.690><c> the</c><00:02:09.929><c> code</c><00:02:10.259><c> but</c><00:02:10.649><c> also</c><00:02:10.830><c> the</c>

00:02:11.540 --> 00:02:11.550 align:start position:0%
download not just the code but also the
 

00:02:11.550 --> 00:02:12.830 align:start position:0%
download not just the code but also the
weight

00:02:12.830 --> 00:02:12.840 align:start position:0%
weight
 

00:02:12.840 --> 00:02:15.920 align:start position:0%
weight
and<00:02:12.930><c> there</c><00:02:13.560><c> are</c><00:02:13.620><c> a</c><00:02:13.650><c> lot</c><00:02:13.800><c> of</c><00:02:14.540><c> networks</c><00:02:15.540><c> and</c>

00:02:15.920 --> 00:02:15.930 align:start position:0%
and there are a lot of networks and
 

00:02:15.930 --> 00:02:17.870 align:start position:0%
and there are a lot of networks and
there<00:02:16.200><c> lot</c><00:02:16.380><c> of</c><00:02:16.410><c> networks</c><00:02:16.920><c> can</c><00:02:17.099><c> download</c><00:02:17.340><c> that</c>

00:02:17.870 --> 00:02:17.880 align:start position:0%
there lot of networks can download that
 

00:02:17.880 --> 00:02:19.790 align:start position:0%
there lot of networks can download that
have<00:02:18.120><c> been</c><00:02:18.300><c> trained</c><00:02:18.660><c> on</c><00:02:18.959><c> for</c><00:02:19.349><c> example</c><00:02:19.440><c> the</c>

00:02:19.790 --> 00:02:19.800 align:start position:0%
have been trained on for example the
 

00:02:19.800 --> 00:02:23.449 align:start position:0%
have been trained on for example the
image<00:02:20.310><c> net</c><00:02:20.700><c> data</c><00:02:21.120><c> set</c><00:02:21.420><c> which</c><00:02:22.110><c> has</c><00:02:22.140><c> a</c><00:02:22.620><c> thousand</c>

00:02:23.449 --> 00:02:23.459 align:start position:0%
image net data set which has a thousand
 

00:02:23.459 --> 00:02:25.280 align:start position:0%
image net data set which has a thousand
different<00:02:23.580><c> classes</c><00:02:24.209><c> so</c><00:02:24.510><c> the</c><00:02:24.660><c> network</c><00:02:25.110><c> might</c>

00:02:25.280 --> 00:02:25.290 align:start position:0%
different classes so the network might
 

00:02:25.290 --> 00:02:28.940 align:start position:0%
different classes so the network might
have<00:02:25.530><c> a</c><00:02:25.770><c> soft</c><00:02:26.489><c> max</c><00:02:26.730><c> unit</c><00:02:27.180><c> that</c><00:02:27.720><c> outputs</c><00:02:28.200><c> one</c><00:02:28.770><c> of</c>

00:02:28.940 --> 00:02:28.950 align:start position:0%
have a soft max unit that outputs one of
 

00:02:28.950 --> 00:02:31.699 align:start position:0%
have a soft max unit that outputs one of
a<00:02:29.069><c> thousand</c><00:02:29.550><c> possible</c><00:02:30.000><c> classes</c><00:02:30.410><c> what</c><00:02:31.410><c> you</c><00:02:31.530><c> can</c>

00:02:31.699 --> 00:02:31.709 align:start position:0%
a thousand possible classes what you can
 

00:02:31.709 --> 00:02:34.490 align:start position:0%
a thousand possible classes what you can
do<00:02:31.890><c> is</c><00:02:32.250><c> then</c><00:02:32.550><c> get</c><00:02:33.239><c> rid</c><00:02:33.450><c> of</c><00:02:33.510><c> the</c><00:02:33.720><c> soft</c><00:02:33.959><c> max</c><00:02:34.230><c> layer</c>

00:02:34.490 --> 00:02:34.500 align:start position:0%
do is then get rid of the soft max layer
 

00:02:34.500 --> 00:02:40.100 align:start position:0%
do is then get rid of the soft max layer
and<00:02:35.010><c> create</c><00:02:35.940><c> your</c><00:02:36.239><c> own</c><00:02:36.800><c> soft</c><00:02:37.800><c> max</c><00:02:38.040><c> unit</c><00:02:39.110><c> that</c>

00:02:40.100 --> 00:02:40.110 align:start position:0%
and create your own soft max unit that
 

00:02:40.110 --> 00:02:41.630 align:start position:0%
and create your own soft max unit that
outputs<00:02:40.650><c> tigger</c>

00:02:41.630 --> 00:02:41.640 align:start position:0%
outputs tigger
 

00:02:41.640 --> 00:02:47.750 align:start position:0%
outputs tigger
or<00:02:41.880><c> misty</c><00:02:42.690><c> or</c><00:02:43.250><c> neither</c><00:02:45.140><c> and</c><00:02:46.140><c> in</c><00:02:46.950><c> terms</c><00:02:47.370><c> of</c><00:02:47.549><c> the</c>

00:02:47.750 --> 00:02:47.760 align:start position:0%
or misty or neither and in terms of the
 

00:02:47.760 --> 00:02:50.090 align:start position:0%
or misty or neither and in terms of the
network<00:02:48.000><c> i'd</c><00:02:48.630><c> encourage</c><00:02:48.989><c> you</c><00:02:49.350><c> to</c><00:02:49.680><c> think</c><00:02:49.709><c> of</c>

00:02:50.090 --> 00:02:50.100 align:start position:0%
network i'd encourage you to think of
 

00:02:50.100 --> 00:02:53.780 align:start position:0%
network i'd encourage you to think of
all<00:02:50.700><c> of</c><00:02:51.150><c> these</c><00:02:51.330><c> layers</c><00:02:51.660><c> as</c><00:02:52.110><c> frozen</c><00:02:52.730><c> so</c><00:02:53.730><c> you</c>

00:02:53.780 --> 00:02:53.790 align:start position:0%
all of these layers as frozen so you
 

00:02:53.790 --> 00:02:57.350 align:start position:0%
all of these layers as frozen so you
freeze<00:02:54.530><c> the</c><00:02:55.530><c> parameters</c><00:02:56.160><c> in</c><00:02:56.430><c> all</c><00:02:56.819><c> of</c><00:02:57.180><c> these</c>

00:02:57.350 --> 00:02:57.360 align:start position:0%
freeze the parameters in all of these
 

00:02:57.360 --> 00:02:59.960 align:start position:0%
freeze the parameters in all of these
layers<00:02:57.660><c> of</c><00:02:57.900><c> the</c><00:02:57.989><c> network</c><00:02:58.380><c> and</c><00:02:58.709><c> you</c><00:02:59.640><c> would</c><00:02:59.790><c> then</c>

00:02:59.960 --> 00:02:59.970 align:start position:0%
layers of the network and you would then
 

00:02:59.970 --> 00:03:02.930 align:start position:0%
layers of the network and you would then
just<00:03:00.209><c> train</c><00:03:00.890><c> the</c><00:03:01.890><c> parameters</c><00:03:02.519><c> associated</c>

00:03:02.930 --> 00:03:02.940 align:start position:0%
just train the parameters associated
 

00:03:02.940 --> 00:03:06.500 align:start position:0%
just train the parameters associated
with<00:03:03.420><c> your</c><00:03:04.170><c> soft</c><00:03:04.470><c> bands</c><00:03:04.680><c> layer</c><00:03:05.330><c> which</c><00:03:06.330><c> is</c><00:03:06.360><c> a</c>

00:03:06.500 --> 00:03:06.510 align:start position:0%
with your soft bands layer which is a
 

00:03:06.510 --> 00:03:08.030 align:start position:0%
with your soft bands layer which is a
soft<00:03:06.840><c> matte</c><00:03:06.989><c> layer</c><00:03:07.260><c> with</c><00:03:07.560><c> three</c><00:03:07.769><c> possible</c>

00:03:08.030 --> 00:03:08.040 align:start position:0%
soft matte layer with three possible
 

00:03:08.040 --> 00:03:11.059 align:start position:0%
soft matte layer with three possible
outputs<00:03:08.700><c> you</c><00:03:09.030><c> know</c><00:03:09.120><c> take</c><00:03:09.420><c> a</c><00:03:09.450><c> misty</c><00:03:10.049><c> or</c><00:03:10.349><c> neither</c>

00:03:11.059 --> 00:03:11.069 align:start position:0%
outputs you know take a misty or neither
 

00:03:11.069 --> 00:03:15.979 align:start position:0%
outputs you know take a misty or neither
and<00:03:11.720><c> by</c><00:03:13.250><c> using</c><00:03:14.250><c> someone</c><00:03:14.790><c> else's</c><00:03:15.000><c> free</c><00:03:15.690><c> train</c>

00:03:15.979 --> 00:03:15.989 align:start position:0%
and by using someone else's free train
 

00:03:15.989 --> 00:03:17.900 align:start position:0%
and by using someone else's free train
weights<00:03:16.319><c> you</c><00:03:16.709><c> might</c><00:03:16.739><c> prefer</c><00:03:17.190><c> get</c><00:03:17.519><c> pretty</c><00:03:17.850><c> good</c>

00:03:17.900 --> 00:03:17.910 align:start position:0%
weights you might prefer get pretty good
 

00:03:17.910 --> 00:03:20.810 align:start position:0%
weights you might prefer get pretty good
performance<00:03:18.150><c> on</c><00:03:18.660><c> this</c><00:03:18.870><c> even</c><00:03:19.650><c> with</c><00:03:19.859><c> a</c><00:03:20.130><c> small</c>

00:03:20.810 --> 00:03:20.820 align:start position:0%
performance on this even with a small
 

00:03:20.820 --> 00:03:24.050 align:start position:0%
performance on this even with a small
data<00:03:21.239><c> set</c><00:03:22.280><c> fortunately</c><00:03:23.280><c> a</c><00:03:23.310><c> lot</c><00:03:23.730><c> of</c><00:03:23.880><c> deep</c>

00:03:24.050 --> 00:03:24.060 align:start position:0%
data set fortunately a lot of deep
 

00:03:24.060 --> 00:03:26.240 align:start position:0%
data set fortunately a lot of deep
learning<00:03:24.299><c> frameworks</c><00:03:24.959><c> support</c><00:03:25.620><c> this</c><00:03:25.980><c> mode</c><00:03:26.220><c> of</c>

00:03:26.240 --> 00:03:26.250 align:start position:0%
learning frameworks support this mode of
 

00:03:26.250 --> 00:03:29.120 align:start position:0%
learning frameworks support this mode of
operation<00:03:26.549><c> and</c><00:03:27.390><c> in</c><00:03:27.540><c> fact</c><00:03:27.780><c> depending</c><00:03:28.769><c> on</c><00:03:29.040><c> the</c>

00:03:29.120 --> 00:03:29.130 align:start position:0%
operation and in fact depending on the
 

00:03:29.130 --> 00:03:31.449 align:start position:0%
operation and in fact depending on the
framework<00:03:29.400><c> it</c><00:03:29.880><c> might</c><00:03:30.150><c> have</c><00:03:30.359><c> things</c><00:03:30.780><c> like</c>

00:03:31.449 --> 00:03:31.459 align:start position:0%
framework it might have things like
 

00:03:31.459 --> 00:03:35.210 align:start position:0%
framework it might have things like
trainable<00:03:32.459><c> parameter</c><00:03:33.620><c> equals</c><00:03:34.620><c> zero</c><00:03:34.980><c> you</c>

00:03:35.210 --> 00:03:35.220 align:start position:0%
trainable parameter equals zero you
 

00:03:35.220 --> 00:03:36.979 align:start position:0%
trainable parameter equals zero you
might<00:03:35.370><c> set</c><00:03:35.640><c> that</c><00:03:35.850><c> for</c><00:03:36.090><c> some</c><00:03:36.269><c> of</c><00:03:36.359><c> these</c><00:03:36.480><c> earlier</c>

00:03:36.979 --> 00:03:36.989 align:start position:0%
might set that for some of these earlier
 

00:03:36.989 --> 00:03:39.440 align:start position:0%
might set that for some of these earlier
layers<00:03:37.230><c> in</c><00:03:37.920><c> order</c><00:03:38.100><c> to</c><00:03:38.370><c> just</c><00:03:38.609><c> say</c><00:03:38.790><c> you</c><00:03:39.299><c> know</c>

00:03:39.440 --> 00:03:39.450 align:start position:0%
layers in order to just say you know
 

00:03:39.450 --> 00:03:41.960 align:start position:0%
layers in order to just say you know
don't<00:03:39.720><c> train</c><00:03:39.989><c> those</c><00:03:40.200><c> weights</c><00:03:40.500><c> or</c><00:03:41.459><c> sometimes</c>

00:03:41.960 --> 00:03:41.970 align:start position:0%
don't train those weights or sometimes
 

00:03:41.970 --> 00:03:44.870 align:start position:0%
don't train those weights or sometimes
you<00:03:42.120><c> have</c><00:03:42.239><c> a</c><00:03:42.269><c> parameter</c><00:03:42.630><c> like</c><00:03:43.079><c> freeze</c><00:03:43.880><c> equals</c>

00:03:44.870 --> 00:03:44.880 align:start position:0%
you have a parameter like freeze equals
 

00:03:44.880 --> 00:03:48.080 align:start position:0%
you have a parameter like freeze equals
one<00:03:45.650><c> and</c><00:03:46.650><c> these</c><00:03:46.889><c> are</c><00:03:46.980><c> different</c><00:03:47.700><c> ways</c><00:03:47.850><c> and</c>

00:03:48.080 --> 00:03:48.090 align:start position:0%
one and these are different ways and
 

00:03:48.090 --> 00:03:49.670 align:start position:0%
one and these are different ways and
different<00:03:48.150><c> deep</c><00:03:49.019><c> learning</c><00:03:49.170><c> premium</c>

00:03:49.670 --> 00:03:49.680 align:start position:0%
different deep learning premium
 

00:03:49.680 --> 00:03:51.920 align:start position:0%
different deep learning premium
frameworks<00:03:50.100><c> that</c><00:03:50.280><c> let</c><00:03:50.609><c> you</c><00:03:50.730><c> specify</c><00:03:51.000><c> whether</c>

00:03:51.920 --> 00:03:51.930 align:start position:0%
frameworks that let you specify whether
 

00:03:51.930 --> 00:03:53.990 align:start position:0%
frameworks that let you specify whether
or<00:03:52.139><c> not</c><00:03:52.319><c> to</c><00:03:52.650><c> train</c><00:03:53.010><c> the</c><00:03:53.250><c> weights</c><00:03:53.489><c> associated</c>

00:03:53.990 --> 00:03:54.000 align:start position:0%
or not to train the weights associated
 

00:03:54.000 --> 00:03:56.960 align:start position:0%
or not to train the weights associated
or<00:03:54.930><c> a</c><00:03:54.959><c> particular</c><00:03:55.470><c> layer</c><00:03:55.650><c> and</c><00:03:56.040><c> so</c><00:03:56.730><c> in</c><00:03:56.850><c> this</c>

00:03:56.960 --> 00:03:56.970 align:start position:0%
or a particular layer and so in this
 

00:03:56.970 --> 00:03:59.420 align:start position:0%
or a particular layer and so in this
case<00:03:57.269><c> you</c><00:03:57.600><c> will</c><00:03:57.720><c> train</c><00:03:58.079><c> only</c><00:03:58.590><c> the</c><00:03:59.040><c> softmax</c>

00:03:59.420 --> 00:03:59.430 align:start position:0%
case you will train only the softmax
 

00:03:59.430 --> 00:04:02.000 align:start position:0%
case you will train only the softmax
layers<00:03:59.880><c> ways</c><00:04:00.180><c> but</c><00:04:00.780><c> freeze</c><00:04:01.170><c> all</c><00:04:01.620><c> of</c><00:04:01.680><c> the</c>

00:04:02.000 --> 00:04:02.010 align:start position:0%
layers ways but freeze all of the
 

00:04:02.010 --> 00:04:05.900 align:start position:0%
layers ways but freeze all of the
earlier<00:04:02.459><c> layers</c><00:04:03.060><c> weights</c><00:04:04.400><c> one</c><00:04:05.400><c> other</c><00:04:05.639><c> neat</c>

00:04:05.900 --> 00:04:05.910 align:start position:0%
earlier layers weights one other neat
 

00:04:05.910 --> 00:04:07.819 align:start position:0%
earlier layers weights one other neat
trick<00:04:06.239><c> that</c><00:04:06.780><c> may</c><00:04:07.200><c> help</c><00:04:07.410><c> for</c><00:04:07.680><c> some</c>

00:04:07.819 --> 00:04:07.829 align:start position:0%
trick that may help for some
 

00:04:07.829 --> 00:04:10.490 align:start position:0%
trick that may help for some
implementations<00:04:08.639><c> is</c><00:04:08.940><c> that</c><00:04:09.480><c> because</c><00:04:10.290><c> all</c><00:04:10.470><c> of</c>

00:04:10.490 --> 00:04:10.500 align:start position:0%
implementations is that because all of
 

00:04:10.500 --> 00:04:13.129 align:start position:0%
implementations is that because all of
these<00:04:10.739><c> early</c><00:04:11.130><c> layers</c><00:04:11.370><c> are</c><00:04:11.579><c> frozen</c><00:04:12.150><c> there</c><00:04:13.049><c> is</c>

00:04:13.129 --> 00:04:13.139 align:start position:0%
these early layers are frozen there is
 

00:04:13.139 --> 00:04:14.960 align:start position:0%
these early layers are frozen there is
some<00:04:13.350><c> fixed</c><00:04:13.739><c> function</c><00:04:13.889><c> that</c><00:04:14.430><c> doesn't</c><00:04:14.819><c> change</c>

00:04:14.960 --> 00:04:14.970 align:start position:0%
some fixed function that doesn't change
 

00:04:14.970 --> 00:04:16.580 align:start position:0%
some fixed function that doesn't change
because<00:04:15.329><c> you're</c><00:04:15.480><c> not</c><00:04:15.540><c> changing</c><00:04:16.049><c> it</c><00:04:16.200><c> you're</c>

00:04:16.580 --> 00:04:16.590 align:start position:0%
because you're not changing it you're
 

00:04:16.590 --> 00:04:18.409 align:start position:0%
because you're not changing it you're
not<00:04:16.680><c> training</c><00:04:17.010><c> it</c><00:04:17.250><c> that</c><00:04:17.760><c> takes</c><00:04:18.060><c> this</c><00:04:18.180><c> input</c>

00:04:18.409 --> 00:04:18.419 align:start position:0%
not training it that takes this input
 

00:04:18.419 --> 00:04:21.680 align:start position:0%
not training it that takes this input
image<00:04:18.930><c> X</c><00:04:19.229><c> and</c><00:04:19.530><c> maps</c><00:04:20.280><c> it</c><00:04:20.579><c> to</c><00:04:20.760><c> some</c><00:04:21.419><c> set</c><00:04:21.659><c> of</c>

00:04:21.680 --> 00:04:21.690 align:start position:0%
image X and maps it to some set of
 

00:04:21.690 --> 00:04:23.180 align:start position:0%
image X and maps it to some set of
activations

00:04:23.180 --> 00:04:23.190 align:start position:0%
activations
 

00:04:23.190 --> 00:04:25.610 align:start position:0%
activations
than<00:04:23.400><c> there</c><00:04:23.670><c> so</c><00:04:24.540><c> one</c><00:04:24.870><c> of</c><00:04:24.900><c> the</c><00:04:25.110><c> treatment</c><00:04:25.590><c> that</c>

00:04:25.610 --> 00:04:25.620 align:start position:0%
than there so one of the treatment that
 

00:04:25.620 --> 00:04:27.530 align:start position:0%
than there so one of the treatment that
could<00:04:25.950><c> speed</c><00:04:26.250><c> up</c><00:04:26.280><c> training</c><00:04:26.730><c> is</c><00:04:27.090><c> you</c><00:04:27.240><c> just</c>

00:04:27.530 --> 00:04:27.540 align:start position:0%
could speed up training is you just
 

00:04:27.540 --> 00:04:31.690 align:start position:0%
could speed up training is you just
precompute<00:04:28.410><c> that</c><00:04:29.190><c> layer</c><00:04:30.140><c> the</c><00:04:31.140><c> features</c>

00:04:31.690 --> 00:04:31.700 align:start position:0%
precompute that layer the features
 

00:04:31.700 --> 00:04:32.840 align:start position:0%
precompute that layer the features
reactivations

00:04:32.840 --> 00:04:32.850 align:start position:0%
reactivations
 

00:04:32.850 --> 00:04:35.390 align:start position:0%
reactivations
from<00:04:33.390><c> that</c><00:04:33.570><c> layer</c><00:04:33.780><c> and</c><00:04:34.140><c> just</c><00:04:34.170><c> saved</c><00:04:34.980><c> them</c><00:04:35.190><c> to</c>

00:04:35.390 --> 00:04:35.400 align:start position:0%
from that layer and just saved them to
 

00:04:35.400 --> 00:04:38.390 align:start position:0%
from that layer and just saved them to
disk<00:04:35.700><c> and</c><00:04:36.200><c> what</c><00:04:37.200><c> you're</c><00:04:37.320><c> doing</c><00:04:37.470><c> is</c><00:04:37.860><c> it</c><00:04:38.040><c> using</c>

00:04:38.390 --> 00:04:38.400 align:start position:0%
disk and what you're doing is it using
 

00:04:38.400 --> 00:04:41.840 align:start position:0%
disk and what you're doing is it using
this<00:04:38.670><c> fixed</c><00:04:39.540><c> function</c><00:04:39.750><c> in</c><00:04:40.590><c> this</c><00:04:41.340><c> first</c><00:04:41.610><c> part</c>

00:04:41.840 --> 00:04:41.850 align:start position:0%
this fixed function in this first part
 

00:04:41.850 --> 00:04:43.790 align:start position:0%
this fixed function in this first part
of<00:04:42.000><c> the</c><00:04:42.060><c> neural</c><00:04:42.300><c> network</c><00:04:42.420><c> to</c><00:04:43.350><c> take</c><00:04:43.530><c> as</c><00:04:43.680><c> input</c>

00:04:43.790 --> 00:04:43.800 align:start position:0%
of the neural network to take as input
 

00:04:43.800 --> 00:04:47.600 align:start position:0%
of the neural network to take as input
any<00:04:44.190><c> input</c><00:04:44.550><c> any</c><00:04:45.150><c> image</c><00:04:45.570><c> X</c><00:04:45.840><c> and</c><00:04:46.080><c> compute</c><00:04:46.890><c> some</c>

00:04:47.600 --> 00:04:47.610 align:start position:0%
any input any image X and compute some
 

00:04:47.610 --> 00:04:49.700 align:start position:0%
any input any image X and compute some
feature<00:04:47.910><c> vector</c><00:04:48.390><c> for</c><00:04:48.660><c> it</c><00:04:48.840><c> and</c><00:04:49.080><c> then</c><00:04:49.560><c> your</c>

00:04:49.700 --> 00:04:49.710 align:start position:0%
feature vector for it and then your
 

00:04:49.710 --> 00:04:52.940 align:start position:0%
feature vector for it and then your
training<00:04:49.950><c> a</c><00:04:50.340><c> shallow</c><00:04:51.060><c> softmax</c><00:04:51.780><c> model</c><00:04:52.380><c> from</c>

00:04:52.940 --> 00:04:52.950 align:start position:0%
training a shallow softmax model from
 

00:04:52.950 --> 00:04:55.970 align:start position:0%
training a shallow softmax model from
this<00:04:53.160><c> feature</c><00:04:53.760><c> vector</c><00:04:54.320><c> to</c><00:04:55.320><c> make</c><00:04:55.590><c> a</c><00:04:55.620><c> prediction</c>

00:04:55.970 --> 00:04:55.980 align:start position:0%
this feature vector to make a prediction
 

00:04:55.980 --> 00:04:59.150 align:start position:0%
this feature vector to make a prediction
and<00:04:56.400><c> so</c><00:04:56.850><c> one</c><00:04:57.750><c> step</c><00:04:58.050><c> that</c><00:04:58.110><c> could</c><00:04:58.770><c> help</c><00:04:59.010><c> your</c>

00:04:59.150 --> 00:04:59.160 align:start position:0%
and so one step that could help your
 

00:04:59.160 --> 00:05:02.180 align:start position:0%
and so one step that could help your
computation<00:04:59.880><c> is</c><00:05:00.060><c> you</c><00:05:00.210><c> just</c><00:05:00.450><c> pre</c><00:05:01.020><c> compute</c><00:05:01.560><c> that</c>

00:05:02.180 --> 00:05:02.190 align:start position:0%
computation is you just pre compute that
 

00:05:02.190 --> 00:05:04.610 align:start position:0%
computation is you just pre compute that
layers<00:05:02.610><c> activation</c><00:05:03.540><c> for</c><00:05:03.840><c> all</c><00:05:04.050><c> the</c><00:05:04.290><c> examples</c>

00:05:04.610 --> 00:05:04.620 align:start position:0%
layers activation for all the examples
 

00:05:04.620 --> 00:05:06.560 align:start position:0%
layers activation for all the examples
in<00:05:04.950><c> training</c><00:05:05.370><c> set</c><00:05:05.580><c> and</c><00:05:05.820><c> save</c><00:05:06.000><c> them</c><00:05:06.210><c> to</c><00:05:06.330><c> disk</c>

00:05:06.560 --> 00:05:06.570 align:start position:0%
in training set and save them to disk
 

00:05:06.570 --> 00:05:08.390 align:start position:0%
in training set and save them to disk
and<00:05:06.690><c> then</c><00:05:07.320><c> just</c><00:05:07.560><c> train</c><00:05:07.830><c> a</c><00:05:07.860><c> soft</c><00:05:08.220><c> mass</c>

00:05:08.390 --> 00:05:08.400 align:start position:0%
and then just train a soft mass
 

00:05:08.400 --> 00:05:10.610 align:start position:0%
and then just train a soft mass
classifier<00:05:08.940><c> on</c><00:05:09.090><c> top</c><00:05:09.300><c> of</c><00:05:09.480><c> that</c><00:05:09.570><c> all</c><00:05:10.470><c> right</c><00:05:10.590><c> so</c>

00:05:10.610 --> 00:05:10.620 align:start position:0%
classifier on top of that all right so
 

00:05:10.620 --> 00:05:12.860 align:start position:0%
classifier on top of that all right so
the<00:05:10.950><c> advantage</c><00:05:11.340><c> of</c><00:05:11.520><c> safety</c><00:05:12.270><c> disks</c><00:05:12.570><c> or</c><00:05:12.630><c> the</c><00:05:12.720><c> pre</c>

00:05:12.860 --> 00:05:12.870 align:start position:0%
the advantage of safety disks or the pre
 

00:05:12.870 --> 00:05:14.660 align:start position:0%
the advantage of safety disks or the pre
compute<00:05:13.290><c> method</c><00:05:13.590><c> to</c><00:05:13.680><c> save</c><00:05:13.830><c> to</c><00:05:13.980><c> disk</c><00:05:14.130><c> method</c><00:05:14.340><c> is</c>

00:05:14.660 --> 00:05:14.670 align:start position:0%
compute method to save to disk method is
 

00:05:14.670 --> 00:05:16.970 align:start position:0%
compute method to save to disk method is
that<00:05:14.880><c> you</c><00:05:15.420><c> don't</c><00:05:15.630><c> need</c><00:05:15.750><c> to</c><00:05:15.960><c> recompute</c><00:05:16.620><c> those</c>

00:05:16.970 --> 00:05:16.980 align:start position:0%
that you don't need to recompute those
 

00:05:16.980 --> 00:05:20.030 align:start position:0%
that you don't need to recompute those
activations<00:05:17.660><c> every</c><00:05:18.660><c> time</c><00:05:18.900><c> you</c><00:05:19.170><c> take</c><00:05:19.650><c> a</c><00:05:19.710><c> leap</c>

00:05:20.030 --> 00:05:20.040 align:start position:0%
activations every time you take a leap
 

00:05:20.040 --> 00:05:21.920 align:start position:0%
activations every time you take a leap
off<00:05:20.250><c> or</c><00:05:20.520><c> take</c><00:05:20.910><c> a</c><00:05:20.940><c> pass</c><00:05:21.180><c> through</c><00:05:21.600><c> your</c><00:05:21.720><c> training</c>

00:05:21.920 --> 00:05:21.930 align:start position:0%
off or take a pass through your training
 

00:05:21.930 --> 00:05:25.130 align:start position:0%
off or take a pass through your training
set<00:05:22.430><c> so</c><00:05:23.430><c> this</c><00:05:23.730><c> is</c><00:05:23.880><c> what</c><00:05:24.060><c> you</c><00:05:24.180><c> do</c><00:05:24.330><c> if</c><00:05:24.600><c> you</c><00:05:24.720><c> have</c><00:05:24.930><c> a</c>

00:05:25.130 --> 00:05:25.140 align:start position:0%
set so this is what you do if you have a
 

00:05:25.140 --> 00:05:28.100 align:start position:0%
set so this is what you do if you have a
pretty<00:05:25.530><c> small</c><00:05:26.100><c> training</c><00:05:27.060><c> set</c><00:05:27.180><c> for</c><00:05:27.660><c> your</c><00:05:27.780><c> task</c>

00:05:28.100 --> 00:05:28.110 align:start position:0%
pretty small training set for your task
 

00:05:28.110 --> 00:05:32.150 align:start position:0%
pretty small training set for your task
whatever<00:05:29.070><c> larger</c><00:05:29.820><c> training</c><00:05:30.330><c> set</c><00:05:30.560><c> so</c><00:05:31.560><c> one</c><00:05:31.919><c> rule</c>

00:05:32.150 --> 00:05:32.160 align:start position:0%
whatever larger training set so one rule
 

00:05:32.160 --> 00:05:34.700 align:start position:0%
whatever larger training set so one rule
of<00:05:32.220><c> thumb</c><00:05:32.520><c> is</c><00:05:32.820><c> if</c><00:05:33.300><c> you</c><00:05:33.570><c> have</c><00:05:33.750><c> a</c><00:05:33.780><c> larger</c><00:05:34.350><c> label</c>

00:05:34.700 --> 00:05:34.710 align:start position:0%
of thumb is if you have a larger label
 

00:05:34.710 --> 00:05:36.500 align:start position:0%
of thumb is if you have a larger label
data<00:05:34.860><c> set</c><00:05:35.190><c> so</c><00:05:35.430><c> maybe</c><00:05:35.640><c> you</c><00:05:35.760><c> just</c><00:05:35.790><c> have</c><00:05:36.090><c> a</c><00:05:36.120><c> ton</c><00:05:36.480><c> of</c>

00:05:36.500 --> 00:05:36.510 align:start position:0%
data set so maybe you just have a ton of
 

00:05:36.510 --> 00:05:40.190 align:start position:0%
data set so maybe you just have a ton of
pictures<00:05:36.840><c> of</c><00:05:37.080><c> Tigger</c><00:05:37.620><c> misty</c><00:05:38.550><c> as</c><00:05:39.240><c> was</c><00:05:39.630><c> against</c>

00:05:40.190 --> 00:05:40.200 align:start position:0%
pictures of Tigger misty as was against
 

00:05:40.200 --> 00:05:42.350 align:start position:0%
pictures of Tigger misty as was against
pictures<00:05:40.530><c> of</c><00:05:40.680><c> neither</c><00:05:40.860><c> of</c><00:05:41.130><c> them</c><00:05:41.280><c> one</c><00:05:42.150><c> thing</c>

00:05:42.350 --> 00:05:42.360 align:start position:0%
pictures of neither of them one thing
 

00:05:42.360 --> 00:05:45.440 align:start position:0%
pictures of neither of them one thing
you<00:05:42.480><c> could</c><00:05:42.660><c> do</c><00:05:42.810><c> is</c><00:05:43.169><c> then</c><00:05:43.500><c> freeze</c><00:05:44.030><c> fewer</c><00:05:45.030><c> layers</c>

00:05:45.440 --> 00:05:45.450 align:start position:0%
you could do is then freeze fewer layers
 

00:05:45.450 --> 00:05:48.710 align:start position:0%
you could do is then freeze fewer layers
so<00:05:46.140><c> maybe</c><00:05:46.440><c> your</c><00:05:46.680><c> freeze</c><00:05:47.060><c> just</c><00:05:48.060><c> these</c><00:05:48.300><c> layers</c>

00:05:48.710 --> 00:05:48.720 align:start position:0%
so maybe your freeze just these layers
 

00:05:48.720 --> 00:05:52.570 align:start position:0%
so maybe your freeze just these layers
and<00:05:49.190><c> then</c><00:05:50.190><c> train</c><00:05:50.669><c> these</c><00:05:51.390><c> later</c><00:05:51.780><c> layers</c>

00:05:52.570 --> 00:05:52.580 align:start position:0%
and then train these later layers
 

00:05:52.580 --> 00:05:55.040 align:start position:0%
and then train these later layers
although<00:05:53.580><c> if</c><00:05:53.730><c> the</c><00:05:53.820><c> output</c><00:05:54.270><c> layer</c><00:05:54.480><c> has</c>

00:05:55.040 --> 00:05:55.050 align:start position:0%
although if the output layer has
 

00:05:55.050 --> 00:05:57.170 align:start position:0%
although if the output layer has
different<00:05:55.470><c> causes</c><00:05:55.919><c> then</c><00:05:56.220><c> you</c><00:05:56.400><c> need</c><00:05:56.580><c> to</c><00:05:56.760><c> you</c>

00:05:57.170 --> 00:05:57.180 align:start position:0%
different causes then you need to you
 

00:05:57.180 --> 00:05:59.360 align:start position:0%
different causes then you need to you
know<00:05:57.300><c> have</c><00:05:57.330><c> your</c><00:05:57.660><c> own</c><00:05:57.840><c> output</c><00:05:58.800><c> unit</c>

00:05:59.360 --> 00:05:59.370 align:start position:0%
know have your own output unit
 

00:05:59.370 --> 00:06:05.810 align:start position:0%
know have your own output unit
anyway<00:06:00.470><c> take</c><00:06:01.470><c> a</c><00:06:01.530><c> misty</c><00:06:02.160><c> or</c><00:06:02.370><c> neither</c><00:06:02.880><c> and</c><00:06:04.820><c> there</c>

00:06:05.810 --> 00:06:05.820 align:start position:0%
anyway take a misty or neither and there
 

00:06:05.820 --> 00:06:08.120 align:start position:0%
anyway take a misty or neither and there
are<00:06:05.880><c> a</c><00:06:05.910><c> couple</c><00:06:05.940><c> ways</c><00:06:06.270><c> to</c><00:06:06.330><c> do</c><00:06:06.600><c> this</c><00:06:06.780><c> you</c><00:06:07.770><c> could</c>

00:06:08.120 --> 00:06:08.130 align:start position:0%
are a couple ways to do this you could
 

00:06:08.130 --> 00:06:12.110 align:start position:0%
are a couple ways to do this you could
take<00:06:08.970><c> the</c><00:06:09.120><c> last</c><00:06:09.330><c> few</c><00:06:09.570><c> layers</c><00:06:10.520><c> and</c><00:06:11.520><c> there</c><00:06:12.090><c> a</c>

00:06:12.110 --> 00:06:12.120 align:start position:0%
take the last few layers and there a
 

00:06:12.120 --> 00:06:14.030 align:start position:0%
take the last few layers and there a
couple<00:06:12.300><c> ways</c><00:06:12.960><c> to</c><00:06:13.020><c> do</c><00:06:13.320><c> this</c><00:06:13.440><c> you</c><00:06:13.650><c> could</c><00:06:13.830><c> take</c>

00:06:14.030 --> 00:06:14.040 align:start position:0%
couple ways to do this you could take
 

00:06:14.040 --> 00:06:15.740 align:start position:0%
couple ways to do this you could take
the<00:06:14.160><c> loss</c><00:06:14.340><c> view</c><00:06:14.580><c> as</c><00:06:14.730><c> weights</c><00:06:15.120><c> and</c><00:06:15.419><c> just</c><00:06:15.540><c> use</c>

00:06:15.740 --> 00:06:15.750 align:start position:0%
the loss view as weights and just use
 

00:06:15.750 --> 00:06:17.270 align:start position:0%
the loss view as weights and just use
that<00:06:15.960><c> as</c><00:06:16.110><c> initialization</c><00:06:16.590><c> and</c><00:06:16.980><c> do</c><00:06:17.130><c> great</c>

00:06:17.270 --> 00:06:17.280 align:start position:0%
that as initialization and do great
 

00:06:17.280 --> 00:06:20.030 align:start position:0%
that as initialization and do great
descent<00:06:17.700><c> from</c><00:06:17.880><c> there</c><00:06:18.090><c> or</c><00:06:18.630><c> you</c><00:06:18.870><c> can</c><00:06:18.990><c> also</c><00:06:19.169><c> blow</c>

00:06:20.030 --> 00:06:20.040 align:start position:0%
descent from there or you can also blow
 

00:06:20.040 --> 00:06:22.640 align:start position:0%
descent from there or you can also blow
away<00:06:20.160><c> these</c><00:06:20.520><c> lost</c><00:06:20.880><c> few</c><00:06:21.120><c> layers</c><00:06:21.300><c> and</c><00:06:21.690><c> just</c><00:06:22.320><c> you</c>

00:06:22.640 --> 00:06:22.650 align:start position:0%
away these lost few layers and just you
 

00:06:22.650 --> 00:06:25.670 align:start position:0%
away these lost few layers and just you
know<00:06:22.680><c> use</c><00:06:23.190><c> your</c><00:06:23.790><c> own</c><00:06:24.360><c> new</c><00:06:24.630><c> hidden</c><00:06:25.020><c> units</c><00:06:25.380><c> and</c>

00:06:25.670 --> 00:06:25.680 align:start position:0%
know use your own new hidden units and
 

00:06:25.680 --> 00:06:28.570 align:start position:0%
know use your own new hidden units and
in<00:06:26.130><c> your</c><00:06:26.280><c> own</c><00:06:26.310><c> final</c><00:06:27.090><c> softmax</c><00:06:27.480><c> output</c><00:06:27.990><c> so</c>

00:06:28.570 --> 00:06:28.580 align:start position:0%
in your own final softmax output so
 

00:06:28.580 --> 00:06:30.980 align:start position:0%
in your own final softmax output so
either<00:06:29.580><c> of</c><00:06:29.820><c> these</c><00:06:29.910><c> methods</c><00:06:30.240><c> could</c><00:06:30.660><c> be</c><00:06:30.780><c> worth</c>

00:06:30.980 --> 00:06:30.990 align:start position:0%
either of these methods could be worth
 

00:06:30.990 --> 00:06:31.840 align:start position:0%
either of these methods could be worth
trying

00:06:31.840 --> 00:06:31.850 align:start position:0%
trying
 

00:06:31.850 --> 00:06:34.300 align:start position:0%
trying
but<00:06:32.360><c> maybe</c><00:06:32.600><c> one</c><00:06:32.900><c> pattern</c><00:06:33.410><c> is</c><00:06:33.620><c> if</c><00:06:34.010><c> you</c><00:06:34.220><c> have</c>

00:06:34.300 --> 00:06:34.310 align:start position:0%
but maybe one pattern is if you have
 

00:06:34.310 --> 00:06:36.370 align:start position:0%
but maybe one pattern is if you have
more<00:06:34.460><c> data</c><00:06:34.730><c> the</c><00:06:35.480><c> number</c><00:06:35.780><c> of</c><00:06:35.870><c> layers</c><00:06:36.110><c> you</c>

00:06:36.370 --> 00:06:36.380 align:start position:0%
more data the number of layers you
 

00:06:36.380 --> 00:06:39.220 align:start position:0%
more data the number of layers you
freeze<00:06:36.790><c> could</c><00:06:37.790><c> be</c><00:06:37.850><c> smaller</c><00:06:38.270><c> and</c><00:06:38.600><c> then</c><00:06:39.050><c> the</c>

00:06:39.220 --> 00:06:39.230 align:start position:0%
freeze could be smaller and then the
 

00:06:39.230 --> 00:06:41.980 align:start position:0%
freeze could be smaller and then the
number<00:06:39.530><c> of</c><00:06:39.620><c> layers</c><00:06:39.950><c> you</c><00:06:40.190><c> train</c><00:06:40.550><c> on</c><00:06:40.790><c> top</c><00:06:41.150><c> could</c>

00:06:41.980 --> 00:06:41.990 align:start position:0%
number of layers you train on top could
 

00:06:41.990 --> 00:06:45.070 align:start position:0%
number of layers you train on top could
be<00:06:42.050><c> greater</c><00:06:42.890><c> and</c><00:06:43.340><c> the</c><00:06:44.150><c> idea</c><00:06:44.510><c> is</c><00:06:44.750><c> that</c><00:06:44.780><c> if</c>

00:06:45.070 --> 00:06:45.080 align:start position:0%
be greater and the idea is that if
 

00:06:45.080 --> 00:06:46.690 align:start position:0%
be greater and the idea is that if
you're<00:06:45.200><c> bigger</c><00:06:45.470><c> data</c><00:06:45.740><c> set</c><00:06:46.040><c> then</c><00:06:46.280><c> maybe</c><00:06:46.490><c> of</c>

00:06:46.690 --> 00:06:46.700 align:start position:0%
you're bigger data set then maybe of
 

00:06:46.700 --> 00:06:49.030 align:start position:0%
you're bigger data set then maybe of
enough<00:06:46.970><c> data</c><00:06:47.150><c> not</c><00:06:47.900><c> just</c><00:06:48.170><c> to</c><00:06:48.260><c> Train</c><00:06:48.530><c> a</c><00:06:48.560><c> single</c>

00:06:49.030 --> 00:06:49.040 align:start position:0%
enough data not just to Train a single
 

00:06:49.040 --> 00:06:51.850 align:start position:0%
enough data not just to Train a single
softmax<00:06:49.430><c> unit</c><00:06:49.880><c> but</c><00:06:50.420><c> to</c><00:06:50.540><c> Train</c><00:06:50.840><c> some</c><00:06:51.470><c> you</c><00:06:51.740><c> know</c>

00:06:51.850 --> 00:06:51.860 align:start position:0%
softmax unit but to Train some you know
 

00:06:51.860 --> 00:06:54.640 align:start position:0%
softmax unit but to Train some you know
mother<00:06:52.160><c> size</c><00:06:52.550><c> new</c><00:06:53.060><c> network</c><00:06:53.570><c> that</c><00:06:54.200><c> comprises</c>

00:06:54.640 --> 00:06:54.650 align:start position:0%
mother size new network that comprises
 

00:06:54.650 --> 00:06:58.240 align:start position:0%
mother size new network that comprises
the<00:06:55.070><c> last</c><00:06:55.310><c> few</c><00:06:55.550><c> layers</c><00:06:55.790><c> of</c><00:06:56.150><c> this</c><00:06:57.250><c> final</c>

00:06:58.240 --> 00:06:58.250 align:start position:0%
the last few layers of this final
 

00:06:58.250 --> 00:07:01.750 align:start position:0%
the last few layers of this final
network<00:06:58.610><c> the</c><00:06:58.760><c> end</c><00:06:58.910><c> up</c><00:06:59.060><c> using</c><00:06:59.240><c> and</c><00:07:00.760><c> then</c>

00:07:01.750 --> 00:07:01.760 align:start position:0%
network the end up using and then
 

00:07:01.760 --> 00:07:04.390 align:start position:0%
network the end up using and then
finally<00:07:02.330><c> if</c><00:07:02.480><c> you</c><00:07:02.570><c> have</c><00:07:02.660><c> a</c><00:07:02.690><c> lot</c><00:07:02.960><c> of</c><00:07:02.990><c> data</c><00:07:03.400><c> one</c>

00:07:04.390 --> 00:07:04.400 align:start position:0%
finally if you have a lot of data one
 

00:07:04.400 --> 00:07:06.790 align:start position:0%
finally if you have a lot of data one
thing<00:07:04.610><c> you</c><00:07:04.760><c> might</c><00:07:04.880><c> do</c><00:07:05.120><c> is</c><00:07:05.150><c> take</c><00:07:05.840><c> this</c><00:07:06.050><c> open</c>

00:07:06.790 --> 00:07:06.800 align:start position:0%
thing you might do is take this open
 

00:07:06.800 --> 00:07:09.850 align:start position:0%
thing you might do is take this open
source<00:07:07.010><c> network</c><00:07:07.370><c> and</c><00:07:07.820><c> wait</c><00:07:08.030><c> and</c><00:07:08.620><c> use</c><00:07:09.620><c> the</c>

00:07:09.850 --> 00:07:09.860 align:start position:0%
source network and wait and use the
 

00:07:09.860 --> 00:07:13.180 align:start position:0%
source network and wait and use the
whole<00:07:10.130><c> thing</c><00:07:10.840><c> just</c><00:07:11.840><c> as</c><00:07:11.990><c> initialization</c><00:07:12.590><c> and</c>

00:07:13.180 --> 00:07:13.190 align:start position:0%
whole thing just as initialization and
 

00:07:13.190 --> 00:07:15.970 align:start position:0%
whole thing just as initialization and
train<00:07:13.910><c> the</c><00:07:14.630><c> whole</c><00:07:14.870><c> network</c><00:07:15.380><c> although</c><00:07:15.620><c> again</c>

00:07:15.970 --> 00:07:15.980 align:start position:0%
train the whole network although again
 

00:07:15.980 --> 00:07:19.750 align:start position:0%
train the whole network although again
if<00:07:16.280><c> this</c><00:07:17.150><c> was</c><00:07:17.330><c> a</c><00:07:17.390><c> thousand</c><00:07:18.260><c> node</c><00:07:18.410><c> softmax</c><00:07:19.310><c> and</c>

00:07:19.750 --> 00:07:19.760 align:start position:0%
if this was a thousand node softmax and
 

00:07:19.760 --> 00:07:21.310 align:start position:0%
if this was a thousand node softmax and
you<00:07:19.880><c> have</c><00:07:20.000><c> just</c><00:07:20.150><c> three</c><00:07:20.450><c> outputs</c><00:07:20.900><c> you</c><00:07:21.080><c> need</c>

00:07:21.310 --> 00:07:21.320 align:start position:0%
you have just three outputs you need
 

00:07:21.320 --> 00:07:24.280 align:start position:0%
you have just three outputs you need
your<00:07:21.530><c> own</c><00:07:21.940><c> softmax</c><00:07:22.940><c> output</c><00:07:23.450><c> to</c><00:07:23.870><c> output</c><00:07:24.200><c> the</c>

00:07:24.280 --> 00:07:24.290 align:start position:0%
your own softmax output to output the
 

00:07:24.290 --> 00:07:28.660 align:start position:0%
your own softmax output to output the
labels<00:07:24.680><c> you</c><00:07:24.740><c> care</c><00:07:25.070><c> about</c><00:07:25.540><c> but</c><00:07:27.220><c> the</c><00:07:28.220><c> more</c><00:07:28.460><c> label</c>

00:07:28.660 --> 00:07:28.670 align:start position:0%
labels you care about but the more label
 

00:07:28.670 --> 00:07:30.880 align:start position:0%
labels you care about but the more label
data<00:07:29.090><c> you</c><00:07:29.300><c> have</c><00:07:29.540><c> for</c><00:07:29.780><c> your</c><00:07:29.930><c> tasks</c><00:07:30.440><c> so</c><00:07:30.590><c> the</c><00:07:30.710><c> more</c>

00:07:30.880 --> 00:07:30.890 align:start position:0%
data you have for your tasks so the more
 

00:07:30.890 --> 00:07:32.770 align:start position:0%
data you have for your tasks so the more
pictures<00:07:31.280><c> you</c><00:07:31.400><c> have</c><00:07:31.580><c> of</c><00:07:31.610><c> take</c><00:07:32.000><c> a</c><00:07:32.030><c> misty</c><00:07:32.570><c> and</c>

00:07:32.770 --> 00:07:32.780 align:start position:0%
pictures you have of take a misty and
 

00:07:32.780 --> 00:07:35.410 align:start position:0%
pictures you have of take a misty and
neither<00:07:33.350><c> the</c><00:07:33.800><c> more</c><00:07:34.400><c> layers</c><00:07:34.580><c> you</c><00:07:34.730><c> could</c><00:07:35.120><c> train</c>

00:07:35.410 --> 00:07:35.420 align:start position:0%
neither the more layers you could train
 

00:07:35.420 --> 00:07:38.680 align:start position:0%
neither the more layers you could train
and<00:07:35.690><c> in</c><00:07:36.080><c> the</c><00:07:36.110><c> extreme</c><00:07:36.560><c> case</c><00:07:36.620><c> you</c><00:07:37.160><c> could</c><00:07:37.690><c> use</c>

00:07:38.680 --> 00:07:38.690 align:start position:0%
and in the extreme case you could use
 

00:07:38.690 --> 00:07:40.210 align:start position:0%
and in the extreme case you could use
the<00:07:38.900><c> way</c><00:07:39.050><c> to</c><00:07:39.110><c> download</c><00:07:39.530><c> just</c><00:07:40.010><c> as</c>

00:07:40.210 --> 00:07:40.220 align:start position:0%
the way to download just as
 

00:07:40.220 --> 00:07:42.130 align:start position:0%
the way to download just as
initialization<00:07:40.820><c> so</c><00:07:41.540><c> they</c><00:07:41.660><c> would</c><00:07:41.780><c> replace</c>

00:07:42.130 --> 00:07:42.140 align:start position:0%
initialization so they would replace
 

00:07:42.140 --> 00:07:44.890 align:start position:0%
initialization so they would replace
random<00:07:42.830><c> initialization</c><00:07:43.670><c> and</c><00:07:43.850><c> you</c><00:07:44.570><c> could</c><00:07:44.750><c> do</c>

00:07:44.890 --> 00:07:44.900 align:start position:0%
random initialization and you could do
 

00:07:44.900 --> 00:07:47.650 align:start position:0%
random initialization and you could do
gradient<00:07:45.200><c> descent</c><00:07:45.910><c> training</c><00:07:46.910><c> updating</c><00:07:47.450><c> all</c>

00:07:47.650 --> 00:07:47.660 align:start position:0%
gradient descent training updating all
 

00:07:47.660 --> 00:07:49.060 align:start position:0%
gradient descent training updating all
the<00:07:47.840><c> ways</c><00:07:48.020><c> in</c><00:07:48.260><c> all</c><00:07:48.470><c> the</c><00:07:48.620><c> layers</c><00:07:48.830><c> of</c><00:07:48.920><c> the</c>

00:07:49.060 --> 00:07:49.070 align:start position:0%
the ways in all the layers of the
 

00:07:49.070 --> 00:07:52.840 align:start position:0%
the ways in all the layers of the
network<00:07:50.140><c> so</c><00:07:51.140><c> that's</c><00:07:51.470><c> transfer</c><00:07:52.160><c> learning</c><00:07:52.610><c> for</c>

00:07:52.840 --> 00:07:52.850 align:start position:0%
network so that's transfer learning for
 

00:07:52.850 --> 00:07:55.450 align:start position:0%
network so that's transfer learning for
the<00:07:52.910><c> training</c><00:07:53.210><c> of</c><00:07:53.480><c> confidence</c><00:07:54.140><c> in</c><00:07:54.830><c> practice</c>

00:07:55.450 --> 00:07:55.460 align:start position:0%
the training of confidence in practice
 

00:07:55.460 --> 00:07:57.730 align:start position:0%
the training of confidence in practice
because<00:07:55.760><c> the</c><00:07:56.330><c> open</c><00:07:56.900><c> datasets</c><00:07:57.260><c> on</c><00:07:57.620><c> the</c>

00:07:57.730 --> 00:07:57.740 align:start position:0%
because the open datasets on the
 

00:07:57.740 --> 00:08:00.250 align:start position:0%
because the open datasets on the
Internet<00:07:58.130><c> are</c><00:07:58.220><c> so</c><00:07:58.550><c> big</c><00:07:58.820><c> and</c><00:07:59.030><c> the</c><00:07:59.660><c> ways</c><00:07:59.930><c> you</c><00:08:00.110><c> can</c>

00:08:00.250 --> 00:08:00.260 align:start position:0%
Internet are so big and the ways you can
 

00:08:00.260 --> 00:08:02.230 align:start position:0%
Internet are so big and the ways you can
download<00:08:00.500><c> that</c><00:08:01.010><c> someone</c><00:08:01.610><c> else</c><00:08:01.760><c> has</c><00:08:01.970><c> spent</c>

00:08:02.230 --> 00:08:02.240 align:start position:0%
download that someone else has spent
 

00:08:02.240 --> 00:08:04.750 align:start position:0%
download that someone else has spent
weeks<00:08:02.870><c> training</c><00:08:03.290><c> has</c><00:08:03.890><c> learned</c><00:08:04.190><c> from</c><00:08:04.340><c> so</c><00:08:04.610><c> much</c>

00:08:04.750 --> 00:08:04.760 align:start position:0%
weeks training has learned from so much
 

00:08:04.760 --> 00:08:07.360 align:start position:0%
weeks training has learned from so much
data<00:08:05.060><c> you</c><00:08:05.690><c> find</c><00:08:06.050><c> that</c><00:08:06.260><c> for</c><00:08:06.590><c> a</c><00:08:06.620><c> lot</c><00:08:06.920><c> of</c><00:08:07.070><c> computer</c>

00:08:07.360 --> 00:08:07.370 align:start position:0%
data you find that for a lot of computer
 

00:08:07.370 --> 00:08:09.520 align:start position:0%
data you find that for a lot of computer
vision<00:08:07.460><c> applications</c><00:08:07.730><c> you</c><00:08:08.630><c> just</c><00:08:08.900><c> do</c><00:08:09.260><c> much</c>

00:08:09.520 --> 00:08:09.530 align:start position:0%
vision applications you just do much
 

00:08:09.530 --> 00:08:11.680 align:start position:0%
vision applications you just do much
better<00:08:09.800><c> if</c><00:08:10.220><c> you</c><00:08:10.430><c> download</c><00:08:10.940><c> someone</c><00:08:11.330><c> else's</c>

00:08:11.680 --> 00:08:11.690 align:start position:0%
better if you download someone else's
 

00:08:11.690 --> 00:08:13.600 align:start position:0%
better if you download someone else's
open<00:08:11.990><c> source</c><00:08:12.200><c> ways</c><00:08:12.440><c> and</c><00:08:12.680><c> use</c><00:08:13.160><c> that</c><00:08:13.370><c> as</c>

00:08:13.600 --> 00:08:13.610 align:start position:0%
open source ways and use that as
 

00:08:13.610 --> 00:08:16.660 align:start position:0%
open source ways and use that as
initialization<00:08:14.510><c> for</c><00:08:14.930><c> your</c><00:08:15.110><c> problem</c><00:08:15.620><c> so</c><00:08:16.340><c> in</c>

00:08:16.660 --> 00:08:16.670 align:start position:0%
initialization for your problem so in
 

00:08:16.670 --> 00:08:18.610 align:start position:0%
initialization for your problem so in
all<00:08:16.970><c> the</c><00:08:17.330><c> different</c><00:08:17.660><c> disciplines</c><00:08:18.320><c> and</c><00:08:18.500><c> all</c>

00:08:18.610 --> 00:08:18.620 align:start position:0%
all the different disciplines and all
 

00:08:18.620 --> 00:08:21.040 align:start position:0%
all the different disciplines and all
the<00:08:18.770><c> different</c><00:08:18.950><c> applications</c><00:08:19.280><c> of</c><00:08:20.090><c> deep</c>

00:08:21.040 --> 00:08:21.050 align:start position:0%
the different applications of deep
 

00:08:21.050 --> 00:08:23.380 align:start position:0%
the different applications of deep
learning<00:08:21.230><c> I</c><00:08:21.650><c> think</c><00:08:21.980><c> that</c><00:08:22.490><c> computer</c><00:08:22.910><c> vision</c><00:08:23.240><c> is</c>

00:08:23.380 --> 00:08:23.390 align:start position:0%
learning I think that computer vision is
 

00:08:23.390 --> 00:08:25.450 align:start position:0%
learning I think that computer vision is
one<00:08:23.630><c> where</c><00:08:23.990><c> transfer</c><00:08:24.710><c> learning</c><00:08:24.920><c> is</c><00:08:25.280><c> something</c>

00:08:25.450 --> 00:08:25.460 align:start position:0%
one where transfer learning is something
 

00:08:25.460 --> 00:08:28.540 align:start position:0%
one where transfer learning is something
that<00:08:25.880><c> you</c><00:08:26.300><c> should</c><00:08:26.330><c> almost</c><00:08:27.020><c> always</c><00:08:27.230><c> do</c><00:08:27.680><c> unless</c>

00:08:28.540 --> 00:08:28.550 align:start position:0%
that you should almost always do unless
 

00:08:28.550 --> 00:08:30.460 align:start position:0%
that you should almost always do unless
you<00:08:29.030><c> actually</c><00:08:29.450><c> have</c><00:08:29.540><c> a</c><00:08:29.570><c> very</c><00:08:29.930><c> very</c><00:08:30.230><c> large</c>

00:08:30.460 --> 00:08:30.470 align:start position:0%
you actually have a very very large
 

00:08:30.470 --> 00:08:32.230 align:start position:0%
you actually have a very very large
unless<00:08:30.920><c> you</c><00:08:31.070><c> have</c><00:08:31.220><c> an</c><00:08:31.340><c> exceptionally</c><00:08:32.060><c> large</c>

00:08:32.230 --> 00:08:32.240 align:start position:0%
unless you have an exceptionally large
 

00:08:32.240 --> 00:08:34.540 align:start position:0%
unless you have an exceptionally large
dataset<00:08:32.719><c> they</c><00:08:33.320><c> train</c><00:08:33.560><c> everything</c><00:08:33.830><c> else</c><00:08:34.130><c> from</c>

00:08:34.540 --> 00:08:34.550 align:start position:0%
dataset they train everything else from
 

00:08:34.550 --> 00:08:37.029 align:start position:0%
dataset they train everything else from
scratch<00:08:34.910><c> himself</c><00:08:35.180><c> but</c><00:08:35.750><c> transfer</c><00:08:36.469><c> learning</c><00:08:36.890><c> is</c>

00:08:37.029 --> 00:08:37.039 align:start position:0%
scratch himself but transfer learning is
 

00:08:37.039 --> 00:08:40.020 align:start position:0%
scratch himself but transfer learning is
just<00:08:37.070><c> very</c><00:08:37.880><c> worth</c><00:08:38.270><c> seriously</c><00:08:38.900><c> considering</c><00:08:39.380><c> on</c>

00:08:40.020 --> 00:08:40.030 align:start position:0%
just very worth seriously considering on
 

00:08:40.030 --> 00:08:41.910 align:start position:0%
just very worth seriously considering on
you<00:08:40.270><c> have</c><00:08:40.480><c> an</c><00:08:40.660><c> exceptionally</c><00:08:41.230><c> large</c><00:08:41.470><c> dataset</c>

00:08:41.910 --> 00:08:41.920 align:start position:0%
you have an exceptionally large dataset
 

00:08:41.920 --> 00:08:44.070 align:start position:0%
you have an exceptionally large dataset
and<00:08:42.340><c> a</c><00:08:42.610><c> very</c><00:08:42.790><c> large</c><00:08:43.060><c> computational</c><00:08:43.720><c> budget</c>

00:08:44.070 --> 00:08:44.080 align:start position:0%
and a very large computational budget
 

00:08:44.080 --> 00:08:46.620 align:start position:0%
and a very large computational budget
they<00:08:44.470><c> trade</c><00:08:44.710><c> everything</c><00:08:44.980><c> from</c><00:08:45.730><c> scratch</c><00:08:46.000><c> by</c>

00:08:46.620 --> 00:08:46.630 align:start position:0%
they trade everything from scratch by
 

00:08:46.630 --> 00:08:49.050 align:start position:0%
they trade everything from scratch by
yourself

