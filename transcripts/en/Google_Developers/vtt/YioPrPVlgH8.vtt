WEBVTT
Kind: captions
Language: en

00:00:00.307 --> 00:00:01.640
STEPHAN SOMOGYI: Good afternoon.

00:00:01.640 --> 00:00:04.770
Welcome to the session about
Security At Scale at Google,

00:00:04.770 --> 00:00:07.532
where hopefully, I will
be able to give you

00:00:07.532 --> 00:00:09.740
an idea of how we approach
security at Google, Google

00:00:09.740 --> 00:00:12.120
WIDEOUT, at Google Scale.

00:00:12.120 --> 00:00:14.450
Just in terms of defining
the problem space,

00:00:14.450 --> 00:00:16.160
the way we think
about security is

00:00:16.160 --> 00:00:19.080
protecting our users
and their data.

00:00:19.080 --> 00:00:20.970
And that is admittedly
a very broad scope,

00:00:20.970 --> 00:00:23.620
but that's exactly
how we think about it.

00:00:23.620 --> 00:00:24.610
So this is me.

00:00:24.610 --> 00:00:26.110
You can tell a resemblance.

00:00:26.110 --> 00:00:28.360
How many of you recognize
this particular symbol?

00:00:28.360 --> 00:00:30.579
This is my G+ avatar.

00:00:30.579 --> 00:00:33.120
This should shake out anybody
who knows their science fiction

00:00:33.120 --> 00:00:35.260
movies.

00:00:35.260 --> 00:00:37.580
Anybody?

00:00:37.580 --> 00:00:38.660
Go ahead.

00:00:38.660 --> 00:00:40.230
It's Tron, indeed.

00:00:40.230 --> 00:00:44.350
And even auto-complete
tells us what Tron does.

00:00:44.350 --> 00:00:46.370
And so that's kind
of setting the stage.

00:00:46.370 --> 00:00:48.080
I also have the
good fortune to work

00:00:48.080 --> 00:00:50.330
with some of Google Ventures'
portfolio companies.

00:00:50.330 --> 00:00:52.320
So a lot of people
sometimes think

00:00:52.320 --> 00:00:54.310
that Google is
extremely insular in how

00:00:54.310 --> 00:00:55.800
it approaches what it does.

00:00:55.800 --> 00:00:58.760
And I actually have the benefit
of also having some insight

00:00:58.760 --> 00:01:00.420
into what smaller
companies are doing.

00:01:00.420 --> 00:01:02.140
And that definitely
informs what I'm

00:01:02.140 --> 00:01:04.340
going to talk to
you about today.

00:01:04.340 --> 00:01:06.000
So the most important
thing to remember

00:01:06.000 --> 00:01:08.330
is I'm just one guy up there.

00:01:08.330 --> 00:01:10.440
And I stand on the
shoulders of giants.

00:01:10.440 --> 00:01:14.000
We have literally hundreds of
people, both in Core security

00:01:14.000 --> 00:01:17.000
and Android security and Chrome
security, Gmail security,

00:01:17.000 --> 00:01:18.720
working on this stuff.

00:01:18.720 --> 00:01:20.820
So I stand before
you here purely

00:01:20.820 --> 00:01:24.440
as a representative of a lot
of very hardworking people who

00:01:24.440 --> 00:01:27.285
keep our users safe
24/7, all over the world.

00:01:27.285 --> 00:01:28.910
So what we're going
to talk about today

00:01:28.910 --> 00:01:31.326
is security that we
do on the Google side.

00:01:31.326 --> 00:01:33.950
I will talk in some detail about
End-To-End, a Chrome extension

00:01:33.950 --> 00:01:35.670
that we released
about three weeks ago.

00:01:35.670 --> 00:01:37.940
We'll talk about the
Transparency Report, where

00:01:37.940 --> 00:01:40.800
we release data, some of which
is quite security related

00:01:40.800 --> 00:01:43.700
and might actually quite
useful to folks on the outside.

00:01:43.700 --> 00:01:46.310
We'll also talk about Safe
Browsing, a very large system,

00:01:46.310 --> 00:01:49.230
that actively hunts
malice out on the internet

00:01:49.230 --> 00:01:51.050
and helps protect our users.

00:01:51.050 --> 00:01:53.300
Then we'll go into a little
bit more about things

00:01:53.300 --> 00:01:57.540
that you can do as developers,
as companies, how you should,

00:01:57.540 --> 00:02:00.730
in our eyes, potentially
think about security and risk,

00:02:00.730 --> 00:02:03.220
and how to go about
prioritizing some the decisions

00:02:03.220 --> 00:02:04.094
that you make.

00:02:04.094 --> 00:02:06.260
And then we'll talk a little
bit more about security

00:02:06.260 --> 00:02:08.610
that you as individuals can do.

00:02:08.610 --> 00:02:11.400
And finally, we'll move to Q&amp;A.

00:02:11.400 --> 00:02:13.270
So in terms of
security that we do,

00:02:13.270 --> 00:02:15.510
it's important to start
thinking in terms of scale.

00:02:15.510 --> 00:02:18.490
Let's measure a
couple of things.

00:02:18.490 --> 00:02:20.560
As you can see at Google,
we have a large number

00:02:20.560 --> 00:02:22.150
of very colorful
tubes through which

00:02:22.150 --> 00:02:24.710
we pump a great deal of data.

00:02:24.710 --> 00:02:27.910
Mary Meeker released
her internet report

00:02:27.910 --> 00:02:29.620
about a month ago,
saying that there

00:02:29.620 --> 00:02:34.420
are about 2.6 billion
people online today.

00:02:34.420 --> 00:02:37.920
Safe Browsing covers over
1.1 billion of those.

00:02:37.920 --> 00:02:39.960
So we can confidently
say that we

00:02:39.960 --> 00:02:43.090
are protecting about 42% of
the entire online population

00:02:43.090 --> 00:02:47.290
of the world, just to give
you a point of reference.

00:02:47.290 --> 00:02:52.780
Chrome users number over
750 million 30-day actives.

00:02:52.780 --> 00:02:55.000
So they're also protected
by Safe Browsing

00:02:55.000 --> 00:02:59.060
and by a lot of the security
features that Chrome brings.

00:02:59.060 --> 00:03:02.510
And Gmail has over
425 million users,

00:03:02.510 --> 00:03:05.250
and they are protected not
only by Safe Browsing--

00:03:05.250 --> 00:03:08.580
and if you use Chrome,
the connection to Gmail

00:03:08.580 --> 00:03:11.420
via Chrome-- but they
have anti-spam measures

00:03:11.420 --> 00:03:14.640
and a variety of other systems,
including TLS encryption, that

00:03:14.640 --> 00:03:17.160
help protect our users.

00:03:17.160 --> 00:03:19.004
We also think in
terms of Android.

00:03:19.004 --> 00:03:20.670
As Sundar said in the
keynote yesterday,

00:03:20.670 --> 00:03:24.920
there are 1 billion 30-day
active Android users.

00:03:24.920 --> 00:03:27.640
And a large chunk
of those users have

00:03:27.640 --> 00:03:29.310
Verify Apps on their system.

00:03:29.310 --> 00:03:33.040
Now, the back end for Verify
Apps is part of Safe Browsing.

00:03:33.040 --> 00:03:36.350
So that's a different 1 billion,
a slightly different facet

00:03:36.350 --> 00:03:37.910
of how we look at
security and how

00:03:37.910 --> 00:03:40.207
we look at protecting our users.

00:03:40.207 --> 00:03:42.540
So as I said, occasionally
we are accused of insularism.

00:03:42.540 --> 00:03:45.150
I like to think of us as
building lots of bridges.

00:03:45.150 --> 00:03:46.960
And the important
part of this is

00:03:46.960 --> 00:03:50.040
where our bridges connect
to the outside world.

00:03:50.040 --> 00:03:52.370
We're very strong
believers in open standards

00:03:52.370 --> 00:03:53.680
and open standards bodies.

00:03:53.680 --> 00:03:56.040
We were one of the
first adopters of DKIM.

00:03:56.040 --> 00:03:57.360
We use OAuth.

00:03:57.360 --> 00:03:58.930
We use OpenID.

00:03:58.930 --> 00:04:01.230
We also work with other
parts of the industry.

00:04:01.230 --> 00:04:03.500
For example, together
with the Fido Alliance,

00:04:03.500 --> 00:04:06.010
we're working on open
interoperable standards

00:04:06.010 --> 00:04:07.880
for strong authentication.

00:04:07.880 --> 00:04:10.680
And we're also helping fund the
Core Infrastructure Initiative,

00:04:10.680 --> 00:04:14.370
which is working to
find and identify

00:04:14.370 --> 00:04:16.765
particularly key
pieces of software

00:04:16.765 --> 00:04:18.890
or other bits of infrastructure
out there that need

00:04:18.890 --> 00:04:22.120
help keeping them secure.

00:04:22.120 --> 00:04:24.740
And indeed, economics is
a key part of security.

00:04:24.740 --> 00:04:27.970
The reason that criminals
continue to do this

00:04:27.970 --> 00:04:29.880
is because it's
profitable for them.

00:04:29.880 --> 00:04:31.770
So they have a very
strong profit motive,

00:04:31.770 --> 00:04:34.110
a very compelling
financial incentive.

00:04:34.110 --> 00:04:37.020
We like to use the money
that we have for good.

00:04:37.020 --> 00:04:39.410
So we have a Vulnerability
Rewards Program,

00:04:39.410 --> 00:04:42.220
where we pay out,
depending on severity

00:04:42.220 --> 00:04:45.820
of exploitable
vulnerability, various--

00:04:45.820 --> 00:04:48.240
we pay for bugs that
can be exploited

00:04:48.240 --> 00:04:49.660
against Google products.

00:04:49.660 --> 00:04:52.970
There's also a separate program
called the Patch Rewards

00:04:52.970 --> 00:04:56.485
Program, where we will actually
pay for people to patch

00:04:56.485 --> 00:04:57.860
other pieces of
software that are

00:04:57.860 --> 00:04:59.693
non-Google pieces of
software, that increase

00:04:59.693 --> 00:05:02.060
the security of the
internet at large.

00:05:04.760 --> 00:05:09.550
This is a perfect example of
the dynamic nature of security.

00:05:09.550 --> 00:05:13.100
A couple of years back,
it was very, very common

00:05:13.100 --> 00:05:15.220
to worry exclusively
about things

00:05:15.220 --> 00:05:17.950
that could gain root access
onto your local device,

00:05:17.950 --> 00:05:22.090
whether it's mobile, or
whether it's desktop or laptop.

00:05:22.090 --> 00:05:25.690
These days, the platforms have
become a lot more hardened.

00:05:25.690 --> 00:05:27.990
And so a lot of the
interesting information

00:05:27.990 --> 00:05:29.100
remains in user land.

00:05:29.100 --> 00:05:30.880
So actually rooting a
machine is no longer

00:05:30.880 --> 00:05:35.640
necessary to get a lot of
very, very interesting stuff.

00:05:35.640 --> 00:05:38.482
And we expect in a
couple of years from now

00:05:38.482 --> 00:05:40.440
there will be other things
that we worry about.

00:05:40.440 --> 00:05:43.290
We also know that most
mobile platforms today, out

00:05:43.290 --> 00:05:46.210
of the box, as
shipped to end users,

00:05:46.210 --> 00:05:49.870
are not easily susceptible to
things like drive-by downloads,

00:05:49.870 --> 00:05:53.720
which some desktop operating
systems still struggle with.

00:05:53.720 --> 00:05:55.530
So the world is
constantly changing.

00:05:55.530 --> 00:05:56.600
The stuff that I
tell you about here

00:05:56.600 --> 00:05:57.975
today will have
changed in a year

00:05:57.975 --> 00:06:01.400
from now, when I give
the update to this.

00:06:01.400 --> 00:06:04.020
And that's one of the reasons
that Chrome and Chrome security

00:06:04.020 --> 00:06:05.830
works quite the way it does.

00:06:05.830 --> 00:06:06.840
We fix bugs.

00:06:06.840 --> 00:06:08.020
We update users.

00:06:08.020 --> 00:06:11.370
And speed is
absolutely critical.

00:06:11.370 --> 00:06:14.170
This is a chart of
how updates happen

00:06:14.170 --> 00:06:16.480
across multiple stable
versions of Chrome.

00:06:16.480 --> 00:06:19.380
And as you can
see, the transition

00:06:19.380 --> 00:06:22.740
from one version to the
next is fairly quick.

00:06:22.740 --> 00:06:27.680
When we first
launched auto update,

00:06:27.680 --> 00:06:30.640
the user populous
in general was not

00:06:30.640 --> 00:06:33.240
unreservedly
enthusiastic about this.

00:06:33.240 --> 00:06:34.460
We were considered arrogant.

00:06:34.460 --> 00:06:37.872
How was Google to know best when
to update a piece of software?

00:06:37.872 --> 00:06:39.330
Except that at the
time, we already

00:06:39.330 --> 00:06:41.510
had a fairly good
idea of the fact

00:06:41.510 --> 00:06:44.890
that if we could push
updates to people quickly,

00:06:44.890 --> 00:06:48.310
we could very, very quickly
eliminate attack surface out

00:06:48.310 --> 00:06:50.270
there, and protect
our users better.

00:06:50.270 --> 00:06:52.900
Several years later
since we've done this,

00:06:52.900 --> 00:06:56.460
auto updates of security patches
have become a best practice,

00:06:56.460 --> 00:06:59.460
and not just within Google,
but throughout the industry.

00:06:59.460 --> 00:07:03.180
The ability to quickly
deliver security fixes

00:07:03.180 --> 00:07:05.760
is now the common denominator.

00:07:05.760 --> 00:07:07.470
Sundar also said in
his keynote yesterday

00:07:07.470 --> 00:07:12.430
that 93% of Google Play
users are running the most

00:07:12.430 --> 00:07:14.430
recent version of
Google Play services,

00:07:14.430 --> 00:07:16.800
including the latest
security fixes.

00:07:16.800 --> 00:07:18.580
And that's absolutely
critical, and it's

00:07:18.580 --> 00:07:21.660
a testament to the fact
that this stuff works.

00:07:21.660 --> 00:07:24.720
But it would never
have been accepted

00:07:24.720 --> 00:07:28.750
if we would have pushed live
versions of Chrome that somehow

00:07:28.750 --> 00:07:31.890
destabilized users' machines.

00:07:31.890 --> 00:07:35.680
So from the non-obvious facet
of security-- reliability,

00:07:35.680 --> 00:07:38.980
good engineering practices, good
testing practices, things that

00:07:38.980 --> 00:07:42.110
make your software not mess
with your users machines--

00:07:42.110 --> 00:07:44.020
those are actually
security characteristics

00:07:44.020 --> 00:07:47.530
because they engender trust,
and they increase trust.

00:07:47.530 --> 00:07:50.116
And when it's time
to absolutely upgrade

00:07:50.116 --> 00:07:51.990
your users because if
you don't upgrade them,

00:07:51.990 --> 00:07:53.690
they will be
vulnerable, that's when

00:07:53.690 --> 00:08:00.090
you need that trust to have them
allow you to actually update.

00:08:00.090 --> 00:08:02.630
Now, we also know that
some of our users out there

00:08:02.630 --> 00:08:04.410
in the world are targeted.

00:08:04.410 --> 00:08:08.880
In the summer of 2011, we
became aware of an attack

00:08:08.880 --> 00:08:11.120
on users in Iran.

00:08:11.120 --> 00:08:12.580
And the way we
found out about this

00:08:12.580 --> 00:08:16.910
is that Chrome started
reporting this error to users.

00:08:16.910 --> 00:08:19.345
We have a feature in Chrome
called certificate pinning,

00:08:19.345 --> 00:08:22.920
where Chrome is aware of
which certificates Google uses

00:08:22.920 --> 00:08:24.599
as part of its HTTPS.

00:08:24.599 --> 00:08:26.640
And Chrome in this case
encountered a certificate

00:08:26.640 --> 00:08:29.880
claiming to be from Google,
but it wasn't one of ours.

00:08:29.880 --> 00:08:31.350
And we started alerting users.

00:08:31.350 --> 00:08:34.260
The users then started
blogging about this error.

00:08:34.260 --> 00:08:36.970
And we ultimately were able
to discover that a certificate

00:08:36.970 --> 00:08:38.990
authority based
in the Netherlands

00:08:38.990 --> 00:08:42.530
had been issuing certificates on
behalf of Google, which was not

00:08:42.530 --> 00:08:45.030
something that we had authorized
them to do in any way.

00:08:45.030 --> 00:08:46.780
And it turns out the
certificate authority

00:08:46.780 --> 00:08:48.849
had been compromised
months earlier.

00:08:48.849 --> 00:08:50.890
And they had issued
certificates not just for us,

00:08:50.890 --> 00:08:53.150
but for a variety
of other companies.

00:08:53.150 --> 00:08:57.580
Now, certificate authorities
need to be very carefully run.

00:08:57.580 --> 00:09:02.400
And as a result of this and
subsequent publication of all

00:09:02.400 --> 00:09:05.460
of the things that we found,
this certificate authority

00:09:05.460 --> 00:09:06.980
is actually no more.

00:09:06.980 --> 00:09:10.700
You cannot run a certificate
authority that issues random

00:09:10.700 --> 00:09:13.356
certificates and nobody notices.

00:09:13.356 --> 00:09:14.980
How many of you
recognize this picture?

00:09:14.980 --> 00:09:16.550
It's from not that far ago.

00:09:19.080 --> 00:09:21.750
So I never thought in
my technology career

00:09:21.750 --> 00:09:24.310
that I would see people
spray painting IP addresses

00:09:24.310 --> 00:09:27.410
to the sides of buildings
in civil disobedience.

00:09:27.410 --> 00:09:29.700
This was really cool.

00:09:29.700 --> 00:09:33.202
Now, these IP addresses are
for Google's DNS service.

00:09:33.202 --> 00:09:35.410
And this is a picture from
this past March in Turkey,

00:09:35.410 --> 00:09:37.660
where the Turkish
government compelled

00:09:37.660 --> 00:09:40.190
Turkish ISPs to block Twitter.

00:09:40.190 --> 00:09:42.910
And the solution was
start spray painting

00:09:42.910 --> 00:09:46.750
the Google DNS IP addresses
to buildings, to bus stops,

00:09:46.750 --> 00:09:49.530
and all over the place.

00:09:49.530 --> 00:09:53.780
And this is another non-obvious
facet of security and of trust.

00:09:53.780 --> 00:09:56.320
People knew that if they could
get their DNS information

00:09:56.320 --> 00:09:57.640
from the Google servers,
they would actually

00:09:57.640 --> 00:09:59.056
be able to get
through to Twitter.

00:09:59.056 --> 00:10:02.310
And this worked until these IP
addresses were blocked as well.

00:10:02.310 --> 00:10:05.430
But even just for a couple
of days, this was worthwhile.

00:10:05.430 --> 00:10:08.060
But this was really
kind of cool.

00:10:08.060 --> 00:10:10.790
We also know, and have been
talking about publicly,

00:10:10.790 --> 00:10:14.910
that some of our users are
very carefully targeted.

00:10:14.910 --> 00:10:18.050
And since 2012, for
those users where

00:10:18.050 --> 00:10:22.330
we determine that they are
the subject of attention

00:10:22.330 --> 00:10:24.260
by state-sponsored
actors, we will actually

00:10:24.260 --> 00:10:27.390
give them specific
alerts to that effect.

00:10:27.390 --> 00:10:30.070
We will also give them a link
that gives them some advice

00:10:30.070 --> 00:10:34.410
to very specifically help in
improving their protection

00:10:34.410 --> 00:10:37.540
online, because we don't want
their accounts compromised.

00:10:37.540 --> 00:10:40.730
We don't want their
machines compromised.

00:10:40.730 --> 00:10:42.610
Which brings us to
End-To-End, which

00:10:42.610 --> 00:10:44.690
is a Chrome extension
for encryption

00:10:44.690 --> 00:10:47.020
that we announced and
shipped the source

00:10:47.020 --> 00:10:49.770
code to approximately
three weeks ago.

00:10:49.770 --> 00:10:52.670
The way End-To-End works is
that without End-To-End, you're

00:10:52.670 --> 00:10:56.730
typing away in Chrome, and
you're creating your mail.

00:10:56.730 --> 00:10:59.609
And we know that the connection
between Chrome and Gmail

00:10:59.609 --> 00:11:00.150
is encrypted.

00:11:00.150 --> 00:11:01.130
We can mandate that.

00:11:01.130 --> 00:11:02.310
That is a requirement.

00:11:02.310 --> 00:11:04.950
We have control over
this connection.

00:11:04.950 --> 00:11:08.030
But once Gmail sends
out that email,

00:11:08.030 --> 00:11:09.805
you may or may not get TLS.

00:11:09.805 --> 00:11:13.750
It is entirely dependent on
the receiving email server.

00:11:13.750 --> 00:11:15.320
We have no control over that.

00:11:15.320 --> 00:11:17.627
We will absolutely support
it if the recipient does.

00:11:17.627 --> 00:11:19.085
But if the recipient
doesn't, there

00:11:19.085 --> 00:11:21.050
is nothing we can do about this.

00:11:21.050 --> 00:11:23.210
We certainly have no
control over the connection

00:11:23.210 --> 00:11:25.270
between the receiving
email server

00:11:25.270 --> 00:11:27.470
and the actual
recipient machine.

00:11:27.470 --> 00:11:32.960
So we go from really quite
secure to cloud of uncertainty,

00:11:32.960 --> 00:11:35.560
all the way through
to maybe possibly.

00:11:35.560 --> 00:11:39.160
With End-To-End installed in
Chrome on the sender's machine,

00:11:39.160 --> 00:11:42.280
we know that the message
body is definitely encrypted.

00:11:42.280 --> 00:11:43.780
And in this case,
you've also got

00:11:43.780 --> 00:11:46.520
encryption of the
connection by TLS.

00:11:46.520 --> 00:11:51.370
You know that as it traverses
the internet to the receiving

00:11:51.370 --> 00:11:53.750
email server, you will
also have the message

00:11:53.750 --> 00:11:56.170
body of this email encrypted.

00:11:56.170 --> 00:11:59.360
And we know that the message
will stay encrypted all the way

00:11:59.360 --> 00:12:01.350
to the end, to the
recipient, where

00:12:01.350 --> 00:12:03.990
they can use any open
PGP-compatible software

00:12:03.990 --> 00:12:06.610
to decrypt the message.

00:12:06.610 --> 00:12:08.310
Now you might be
thinking, why on earth

00:12:08.310 --> 00:12:10.100
would Google do such a thing?

00:12:10.100 --> 00:12:13.060
Well, we know that
we have users who

00:12:13.060 --> 00:12:16.450
need more protection than
our high common denominator

00:12:16.450 --> 00:12:19.020
of security that
we provide today.

00:12:19.020 --> 00:12:20.870
And this is our
focus on the user.

00:12:20.870 --> 00:12:22.120
This is why we are doing it.

00:12:22.120 --> 00:12:26.000
We want to be able to give
tools to the journalists,

00:12:26.000 --> 00:12:28.150
to the human rights
workers, to the dissidents

00:12:28.150 --> 00:12:31.520
out there who need that
extra bit of security.

00:12:31.520 --> 00:12:33.775
And we want to make
these widely available.

00:12:33.775 --> 00:12:35.900
So the extension is not
available in the Chrome Web

00:12:35.900 --> 00:12:39.742
Store today, because it
is not a best practice

00:12:39.742 --> 00:12:41.700
to write a whole bunch
of brand new crypto code

00:12:41.700 --> 00:12:44.150
and then unleash
it upon the world.

00:12:44.150 --> 00:12:46.220
It needs time to mature.

00:12:46.220 --> 00:12:47.720
And so we're going
to take our time.

00:12:47.720 --> 00:12:49.600
We're going to
actively encourage

00:12:49.600 --> 00:12:52.090
the community to
review our code.

00:12:52.090 --> 00:12:54.630
This extension is already part
of our Vulnerability Rewards

00:12:54.630 --> 00:12:55.130
program.

00:12:55.130 --> 00:12:58.230
So exploitable
vulnerabilities can indeed

00:12:58.230 --> 00:13:00.870
get rewarded, financially.

00:13:00.870 --> 00:13:02.470
What we'd like the
community to do

00:13:02.470 --> 00:13:07.090
is go to our Google code
page, download the software,

00:13:07.090 --> 00:13:08.590
and take a look at it.

00:13:08.590 --> 00:13:11.126
Tell us about stuff that
we haven't noticed yet.

00:13:11.126 --> 00:13:13.250
We have a bunch of stuff
that we know that we still

00:13:13.250 --> 00:13:15.240
want to work on before
we feel it's ready.

00:13:15.240 --> 00:13:17.390
But we are positively,
absolutely not

00:13:17.390 --> 00:13:19.160
going to put it in
the Chrome Web Store

00:13:19.160 --> 00:13:21.450
until we think it's ready.

00:13:21.450 --> 00:13:28.490
Here's the URL, if you want to
go check it out, g.co/endtoend.

00:13:28.490 --> 00:13:31.590
Now, Transparency Report
is also really cool.

00:13:31.590 --> 00:13:34.830
We started it in 2010
and have been reporting

00:13:34.830 --> 00:13:38.620
on various things that we
are in a unique position

00:13:38.620 --> 00:13:40.540
to have the information about.

00:13:40.540 --> 00:13:43.350
Last September, for
example, in 2013,

00:13:43.350 --> 00:13:45.770
we sued the US
government to be allowed

00:13:45.770 --> 00:13:50.120
to report in some detail about
requests for user information

00:13:50.120 --> 00:13:53.340
that we received
as part of FISA.

00:13:53.340 --> 00:13:55.640
And starting this
March, we were actually

00:13:55.640 --> 00:13:58.200
able to start reporting
that information.

00:13:58.200 --> 00:14:01.450
We actually spend lawyer
hours suing the US government

00:14:01.450 --> 00:14:05.800
in order to be able to
be more transparent.

00:14:05.800 --> 00:14:09.600
More recently, we also released
an encryption-related email

00:14:09.600 --> 00:14:15.000
report in June, that talks about
how many external parties we

00:14:15.000 --> 00:14:19.330
are able to exchange
encrypted email via TLS with.

00:14:22.210 --> 00:14:26.630
A year ago, the second
most recent security report

00:14:26.630 --> 00:14:28.700
was related to Safe
Browsing and talked

00:14:28.700 --> 00:14:31.710
about the view we
have of malware

00:14:31.710 --> 00:14:34.350
and of phishing and
some associated stats.

00:14:34.350 --> 00:14:37.590
So let's talk about
some of those.

00:14:37.590 --> 00:14:40.280
The upper graph
here describes users

00:14:40.280 --> 00:14:42.610
who see browser warnings
in terms of how many

00:14:42.610 --> 00:14:45.490
of those per week, and it
fluctuates considerably.

00:14:45.490 --> 00:14:47.520
But we do pay close
attention to this

00:14:47.520 --> 00:14:50.440
because we want to understand
exactly how often people

00:14:50.440 --> 00:14:51.960
encounter these
types of warnings.

00:14:51.960 --> 00:14:54.730
We also provide warnings
in our search results,

00:14:54.730 --> 00:14:56.430
and that's the bottom graph.

00:14:56.430 --> 00:14:58.570
One of the more
interesting graphs

00:14:58.570 --> 00:15:01.550
is our detection of
sites that host malware,

00:15:01.550 --> 00:15:03.430
and we aggregate them per week.

00:15:03.430 --> 00:15:06.610
And as you will see, the green
sites are compromised sites.

00:15:06.610 --> 00:15:08.930
These are entirely
legitimate sites

00:15:08.930 --> 00:15:13.020
that have somehow been
owned by an adversary.

00:15:13.020 --> 00:15:15.700
It's that tiny
little blue fraction

00:15:15.700 --> 00:15:17.390
that is the actual
attack sites that

00:15:17.390 --> 00:15:21.690
have no other purpose other
than to deliver malware.

00:15:21.690 --> 00:15:24.110
And so we feel
it's very important

00:15:24.110 --> 00:15:27.020
to reach out to all of
these compromised sites

00:15:27.020 --> 00:15:28.210
and help them clean it up.

00:15:28.210 --> 00:15:31.410
And the mechanism that we use
for that is Webmaster Tools.

00:15:31.410 --> 00:15:33.317
So those of you who
have websites today

00:15:33.317 --> 00:15:35.900
and have not yet signed up for
Google's Webmaster Tools, which

00:15:35.900 --> 00:15:39.410
is a free service, you should
do that as quickly as possible.

00:15:39.410 --> 00:15:43.020
That is the way that we
can notify you most quickly

00:15:43.020 --> 00:15:45.120
if there is something
wrong with your website.

00:15:45.120 --> 00:15:47.550
And we will give you
pointers and assistance

00:15:47.550 --> 00:15:51.150
to help clean things up.

00:15:51.150 --> 00:15:53.740
We also track things like
how quickly webmasters

00:15:53.740 --> 00:15:56.180
respond to such warnings.

00:15:56.180 --> 00:15:58.900
And even more interestingly
in many ways--

00:15:58.900 --> 00:16:01.070
the recidivism
rate on the bottom.

00:16:01.070 --> 00:16:05.130
So if we discover that a site
has a problem and we report it,

00:16:05.130 --> 00:16:09.320
and the site cleans it up but is
then re-infected, or otherwise

00:16:09.320 --> 00:16:12.981
re compromised, that's something
that we pay close attention to.

00:16:12.981 --> 00:16:14.980
How many of you knew that
this data has been out

00:16:14.980 --> 00:16:17.000
there for over a year?

00:16:17.000 --> 00:16:19.832
How many of you had no idea?

00:16:19.832 --> 00:16:22.040
And of those with their
hands raised, how many of you

00:16:22.040 --> 00:16:25.288
think this is interesting data?

00:16:25.288 --> 00:16:27.576
OK.

00:16:27.576 --> 00:16:29.450
So let's talk about
email encryption transit.

00:16:32.270 --> 00:16:34.820
As of early June,
approximately 70%

00:16:34.820 --> 00:16:38.310
of the messages that Gmail
sends to other providers

00:16:38.310 --> 00:16:40.200
are encrypted by TLS.

00:16:40.200 --> 00:16:42.700
So we have 30% more to go.

00:16:42.700 --> 00:16:45.210
On the inbound, it's only 53%.

00:16:45.210 --> 00:16:47.540
Now remember, this
is not something

00:16:47.540 --> 00:16:48.980
that is under our control.

00:16:48.980 --> 00:16:52.380
We will support TLS encryption
if the other end does.

00:16:52.380 --> 00:16:56.620
So it's very helpful to find
ways to provide incentive

00:16:56.620 --> 00:16:58.750
for the other end to
participate in this.

00:16:58.750 --> 00:17:01.330
And as you can see in the
lower left-hand corner,

00:17:01.330 --> 00:17:03.190
there's a Download Data button.

00:17:03.190 --> 00:17:04.419
Please use this data.

00:17:04.419 --> 00:17:05.960
That's why we're
making it available.

00:17:05.960 --> 00:17:08.695
We spend engineering
hours collecting this data

00:17:08.695 --> 00:17:10.780
and making it usable
to the outside world.

00:17:10.780 --> 00:17:12.200
That's what it's there for.

00:17:12.200 --> 00:17:13.890
Please use it.

00:17:13.890 --> 00:17:17.089
And if there are any skeptics
out there who are uncertain as

00:17:17.089 --> 00:17:19.589
to the value of exposing
this type of data

00:17:19.589 --> 00:17:22.069
to the outside world,
you should take a look

00:17:22.069 --> 00:17:25.290
at that Comcast curve there.

00:17:25.290 --> 00:17:26.960
It's more of a hockey stick.

00:17:26.960 --> 00:17:29.480
So within two days
of us releasing

00:17:29.480 --> 00:17:33.130
this report and Comcast's
customers tweeting

00:17:33.130 --> 00:17:36.760
and emailing quite
vocally to Comcast,

00:17:36.760 --> 00:17:39.560
Comcast had turned on TLS
for all of their mail servers

00:17:39.560 --> 00:17:40.860
here in the US.

00:17:40.860 --> 00:17:46.570
So this kind of stuff does
have a very, very real effect.

00:17:46.570 --> 00:17:49.970
More information, lots more
data for you guys to use--

00:17:49.970 --> 00:17:53.774
go to
google.com/transparencyreport/.

00:17:53.774 --> 00:17:56.580
Now, let's talk about
a Safe Browsing, which

00:17:56.580 --> 00:17:59.690
is a system that's
been around since 2007

00:17:59.690 --> 00:18:03.240
and has been, in that
time, looking ever more

00:18:03.240 --> 00:18:06.630
carefully for various
forms of malware

00:18:06.630 --> 00:18:09.652
and of social engineering
and, particularly, phishing.

00:18:09.652 --> 00:18:11.110
And we've been
collecting that data

00:18:11.110 --> 00:18:13.835
and putting it together
and providing it

00:18:13.835 --> 00:18:16.990
as a database that can be
searched locally, but also

00:18:16.990 --> 00:18:19.180
as an API that's freely
accessible out there

00:18:19.180 --> 00:18:21.100
in the world.

00:18:21.100 --> 00:18:23.590
A typical browser
will continually

00:18:23.590 --> 00:18:27.750
update its local database
of Safe Browsing data

00:18:27.750 --> 00:18:31.220
in order to present an error
or an alert to the user

00:18:31.220 --> 00:18:34.020
if they try and surf there,
because we want to even try

00:18:34.020 --> 00:18:35.880
to prevent the user
from even contacting

00:18:35.880 --> 00:18:41.320
that site in the eventuality
that a mere contact can already

00:18:41.320 --> 00:18:43.010
lead to a malware infection.

00:18:43.010 --> 00:18:44.970
This is what's
called a drive-by.

00:18:44.970 --> 00:18:47.589
Now this is something that we
could have kept for Chrome,

00:18:47.589 --> 00:18:49.130
but we actually
didn't feel that it's

00:18:49.130 --> 00:18:51.370
in the interest of the
internet as a whole to do so.

00:18:51.370 --> 00:18:53.420
And we make this data
widely available.

00:18:53.420 --> 00:18:56.760
And as a result, Firefox
uses the Google Safe Browsing

00:18:56.760 --> 00:19:00.510
data to protect its users, and
Safari uses our Safe Browsing

00:19:00.510 --> 00:19:04.330
data to protect
its users as well.

00:19:04.330 --> 00:19:05.830
Now, no developer
conference would

00:19:05.830 --> 00:19:08.700
be complete without at least one
announcement of something new.

00:19:08.700 --> 00:19:11.870
So at noon today, we push
live the documentation

00:19:11.870 --> 00:19:14.450
to Safe Browsing
protocol version 3.

00:19:14.450 --> 00:19:17.010
So those of you who are
already using the Safe Browsing

00:19:17.010 --> 00:19:21.130
protocol will have some new
stuff to take advantage of.

00:19:21.130 --> 00:19:23.740
One of the most
important aspects of this

00:19:23.740 --> 00:19:26.570
is that we actually provide
the same amount of data

00:19:26.570 --> 00:19:29.060
with a much smaller data size.

00:19:29.060 --> 00:19:32.130
We've got approximately
40% to 60% saving.

00:19:32.130 --> 00:19:36.170
So you get approximately
2x the protection per bit.

00:19:36.170 --> 00:19:39.950
And we want to do
this because we

00:19:39.950 --> 00:19:42.920
feel that getting this
information down to the client

00:19:42.920 --> 00:19:46.170
device as quickly as possible
is best for everyone.

00:19:46.170 --> 00:19:46.930
It's best for us.

00:19:46.930 --> 00:19:49.309
It's best for the client device.

00:19:49.309 --> 00:19:51.850
If you want to learn more about
the Safe Browsing API and how

00:19:51.850 --> 00:19:54.040
you can take advantage of
it to protect your users,

00:19:54.040 --> 00:19:59.850
go to
 developers.google.com/safe-browsing/.

00:19:59.850 --> 00:20:02.560
So let's talk a bit about things
that you can do as developers,

00:20:02.560 --> 00:20:06.240
as a company, and how you
might want to think about risk.

00:20:06.240 --> 00:20:09.440
So given a shed of
arbitrary color,

00:20:09.440 --> 00:20:11.380
how would you go
about protecting it?

00:20:11.380 --> 00:20:13.180
Would you put a
padlock on the door?

00:20:13.180 --> 00:20:17.340
Or would you spend many
thousands of dollars, or euros,

00:20:17.340 --> 00:20:20.040
for a very elaborate
security system?

00:20:20.040 --> 00:20:22.840
Well, it depends entirely
on what's inside the shed.

00:20:22.840 --> 00:20:25.680
And so whatever risk mitigation
you have in place needs

00:20:25.680 --> 00:20:29.200
to be commensurate with
the threat and the risk

00:20:29.200 --> 00:20:32.800
if something winds
up going wrong.

00:20:32.800 --> 00:20:35.090
When we think about
risks of this nature,

00:20:35.090 --> 00:20:36.870
we think about scale.

00:20:36.870 --> 00:20:39.950
It's possible to
steal a single laptop.

00:20:39.950 --> 00:20:43.670
It's possible to get
a USB device somewhere

00:20:43.670 --> 00:20:46.520
onto a USB bus
associated with that.

00:20:46.520 --> 00:20:47.640
But that doesn't scale.

00:20:47.640 --> 00:20:48.530
That's very targeted.

00:20:48.530 --> 00:20:49.680
That's very limited to one.

00:20:49.680 --> 00:20:51.700
We worry about the
things that can

00:20:51.700 --> 00:20:55.230
affect very, very large
numbers of users very easily.

00:20:55.230 --> 00:20:56.640
And that's how phishing works.

00:20:56.640 --> 00:20:58.870
That's how a lot of
malware distribution works.

00:20:58.870 --> 00:21:02.060
So we focus on the things that
deliver the most protection

00:21:02.060 --> 00:21:05.510
to the largest number of users.

00:21:05.510 --> 00:21:08.680
We also believe very
strongly in defense in depth.

00:21:08.680 --> 00:21:10.680
There is no single
defensive barrier

00:21:10.680 --> 00:21:15.250
that you can put up that will
withstand all possible attacks.

00:21:15.250 --> 00:21:19.010
So assume that each individual
one of your defense layers

00:21:19.010 --> 00:21:21.270
will at some point
fall and that you

00:21:21.270 --> 00:21:23.670
need all of them
working together

00:21:23.670 --> 00:21:29.020
to make sure that your users
are not adversely affected.

00:21:29.020 --> 00:21:32.090
Make sure also that you
don't obsess too much

00:21:32.090 --> 00:21:36.310
about one facet of your
overall security architecture.

00:21:36.310 --> 00:21:38.934
It's really, really easy
to get completely obsessed

00:21:38.934 --> 00:21:40.600
about picking the
right crypto algorithm

00:21:40.600 --> 00:21:42.400
and the right key length.

00:21:42.400 --> 00:21:44.730
But if your website
is vulnerable

00:21:44.730 --> 00:21:47.470
to cross-site scripting,
all the crypto in the world

00:21:47.470 --> 00:21:49.810
isn't going to help you, no
matter how correctly it's

00:21:49.810 --> 00:21:50.700
implemented.

00:21:50.700 --> 00:21:51.830
So think holistically.

00:21:51.830 --> 00:21:53.340
Think about the entire system.

00:21:53.340 --> 00:21:57.540
Think about how users actually
use your stuff and all

00:21:57.540 --> 00:22:00.080
the paths that your
users will take in order

00:22:00.080 --> 00:22:03.040
to get at your services.

00:22:03.040 --> 00:22:05.470
Do use TLS whenever possible.

00:22:05.470 --> 00:22:07.100
And please do get it right.

00:22:07.100 --> 00:22:10.090
How many of you were here at
the HTTPS Everywhere session

00:22:10.090 --> 00:22:12.450
yesterday in this room?

00:22:12.450 --> 00:22:14.840
Well one of the
presenters, Ilya,

00:22:14.840 --> 00:22:17.950
has put up a site called
isTLSfastyet, because that's

00:22:17.950 --> 00:22:21.330
one of the biggest
criticisms of implementing

00:22:21.330 --> 00:22:23.760
TLS-- is oh my gosh,
it'll slow things down.

00:22:23.760 --> 00:22:26.030
It actually won't, but
there's an awful lot

00:22:26.030 --> 00:22:28.750
of very, very good
information on that website.

00:22:28.750 --> 00:22:31.090
You should definitely
check it out.

00:22:31.090 --> 00:22:35.430
But much more tactically,
if people try and come

00:22:35.430 --> 00:22:37.880
to your site and they
get a big red screen

00:22:37.880 --> 00:22:40.944
saying there's something wrong
with the security certificate,

00:22:40.944 --> 00:22:42.610
there's plenty of
research that tells us

00:22:42.610 --> 00:22:47.570
that you're going to see a drop
in traffic, easily 30% or more.

00:22:47.570 --> 00:22:51.330
So please, don't
just implement TLS.

00:22:51.330 --> 00:22:54.570
Please get it done because we're
trying to run an internet here.

00:22:54.570 --> 00:22:57.080
And we also don't
want you to start

00:22:57.080 --> 00:23:00.550
training your users to
ignore security warnings,

00:23:00.550 --> 00:23:03.740
because you don't want them
to ignore a warning when

00:23:03.740 --> 00:23:06.520
it's extremely real.

00:23:06.520 --> 00:23:09.810
So as individuals, there's a
variety of stuff you can do.

00:23:09.810 --> 00:23:14.070
Number one most important thing,
don't reuse the same password

00:23:14.070 --> 00:23:15.950
across multiple websites.

00:23:15.950 --> 00:23:19.440
This is an attack that
scales extremely well.

00:23:19.440 --> 00:23:22.296
If an attacker
compromises one website

00:23:22.296 --> 00:23:24.170
and they get a
username/password combination,

00:23:24.170 --> 00:23:25.586
they're going to
go and try it out

00:23:25.586 --> 00:23:26.932
on a whole bunch of other sites.

00:23:26.932 --> 00:23:29.140
And if you reuse your password
across multiple sites,

00:23:29.140 --> 00:23:30.990
they will probably
be successful.

00:23:30.990 --> 00:23:33.330
So please don't.

00:23:33.330 --> 00:23:35.390
Once you've taken
care of that, enable

00:23:35.390 --> 00:23:37.760
two-factor authentication
wherever possible.

00:23:37.760 --> 00:23:39.710
This is the icon for
Google Authenticator.

00:23:39.710 --> 00:23:42.570
It's available on
Android and on iOS.

00:23:42.570 --> 00:23:45.104
Please enable it for
your Google accounts.

00:23:45.104 --> 00:23:46.770
Please encourage your
friends and family

00:23:46.770 --> 00:23:49.170
to enable it on
all your accounts.

00:23:49.170 --> 00:23:50.930
And if you use
other systems that

00:23:50.930 --> 00:23:54.660
have the capability for enabling
two-factor authentication,

00:23:54.660 --> 00:23:56.430
please turn it on.

00:23:56.430 --> 00:23:59.010
It really does help.

00:23:59.010 --> 00:24:01.670
If you see from Chrome, or
any of the other browsers

00:24:01.670 --> 00:24:04.540
that support the Safe
Browsing data and use it,

00:24:04.540 --> 00:24:08.270
a warning that says phishing
ahead, don't ignore it please.

00:24:08.270 --> 00:24:11.270
We have a very good reason
why we put it there.

00:24:11.270 --> 00:24:13.450
Our user experience
researchers find

00:24:13.450 --> 00:24:15.950
that sometimes users,
particularly nontechnical

00:24:15.950 --> 00:24:18.170
users, will say, well, I
come to this site every day.

00:24:18.170 --> 00:24:19.880
Clearly this is the anomaly.

00:24:19.880 --> 00:24:22.420
This is the mistake, so I'll
just go right through it.

00:24:22.420 --> 00:24:25.010
Except that this
super popular site

00:24:25.010 --> 00:24:28.530
got exploited and compromised
overnight last night,

00:24:28.530 --> 00:24:31.480
precisely because it
was super popular.

00:24:31.480 --> 00:24:35.750
So it is actually likelier that
this is a very real warning

00:24:35.750 --> 00:24:38.880
and is very actively
trying to protect the user.

00:24:38.880 --> 00:24:42.462
So it's unhelpful if users
get trained to ignore them.

00:24:42.462 --> 00:24:44.920
Similarly, if you see a message
that says the website ahead

00:24:44.920 --> 00:24:47.790
contains malware,
don't keep going.

00:24:47.790 --> 00:24:49.670
And for those particularly
stubborn people,

00:24:49.670 --> 00:24:52.510
we've actually included the
little international do not

00:24:52.510 --> 00:24:56.860
enter symbol before that binary
actually gets downloaded.

00:24:56.860 --> 00:24:57.880
Don't ignore this stuff.

00:24:57.880 --> 00:24:59.088
We put up there for a reason.

00:24:59.088 --> 00:25:01.456
We really do want
to prevent malware

00:25:01.456 --> 00:25:02.830
from winding up
on your machines.

00:25:02.830 --> 00:25:05.850
And we do want to prevent
you from getting phished.

00:25:05.850 --> 00:25:08.000
But this isn't just
a desktop thing.

00:25:08.000 --> 00:25:12.450
You may very well see this
error on your Android device.

00:25:12.450 --> 00:25:13.780
Please do not continue.

00:25:13.780 --> 00:25:16.380
We have a very good reason
for putting up this error

00:25:16.380 --> 00:25:19.800
and for trying to prevent
you from installing this app.

00:25:19.800 --> 00:25:22.000
Don't ignore it.

00:25:22.000 --> 00:25:25.860
So today we've talked
about security that we do.

00:25:25.860 --> 00:25:28.630
We've talked about End-To-End,
the Transparency Report

00:25:28.630 --> 00:25:31.844
and Safe Browsing, and
stuff that you guys can do.

00:25:31.844 --> 00:25:33.760
I'm going to start Q&amp;A
in a couple of moments.

00:25:33.760 --> 00:25:35.426
So anybody who has
any questions, please

00:25:35.426 --> 00:25:36.440
line up at the mics.

00:25:36.440 --> 00:25:40.850
But before then, a quick
anecdote about scale.

00:25:40.850 --> 00:25:44.900
In 2005, in March,
there was a drawing

00:25:44.900 --> 00:25:46.130
of the Powerball lottery.

00:25:46.130 --> 00:25:50.190
And Powerball people are
headquartered in Iowa.

00:25:50.190 --> 00:25:52.305
And uncharacteristically
that evening,

00:25:52.305 --> 00:25:56.280
they had a disproportionately
large incidence

00:25:56.280 --> 00:25:57.285
of winning numbers.

00:25:57.285 --> 00:26:00.690
Now, they didn't get all six,
but they got five out of six.

00:26:00.690 --> 00:26:03.490
And statistically, it
was completely improbable

00:26:03.490 --> 00:26:04.950
that this would happen.

00:26:04.950 --> 00:26:07.650
The geographic distribution
was also extremely wide.

00:26:07.650 --> 00:26:12.600
It was from the East Coast, all
the way to Idaho and Arizona.

00:26:12.600 --> 00:26:14.380
There were also multiples.

00:26:14.380 --> 00:26:18.320
It wasn't just one person
here, one person there.

00:26:18.320 --> 00:26:20.540
So their first thought
was, their systems have

00:26:20.540 --> 00:26:23.270
been compromised, or
there was fraud involved.

00:26:23.270 --> 00:26:26.110
Something bad was
clearly going on.

00:26:26.110 --> 00:26:28.361
So they put people on
planes over the weekend

00:26:28.361 --> 00:26:30.860
because they knew where there
winning tickets had been sold.

00:26:30.860 --> 00:26:34.830
And they wanted to be ready
for when the winners showed

00:26:34.830 --> 00:26:37.270
up and claimed their winnings.

00:26:37.270 --> 00:26:39.330
And when they asked
the winners where

00:26:39.330 --> 00:26:42.630
they had gotten the numbers,
the vast majority of them

00:26:42.630 --> 00:26:45.620
said that they had gotten
them from a fortune cookie.

00:26:45.620 --> 00:26:47.860
And it turns out that
a single fortune cookie

00:26:47.860 --> 00:26:50.780
factory in Long
Island City, Queens,

00:26:50.780 --> 00:26:54.320
supplied a very significant
number of fortune cookies

00:26:54.320 --> 00:26:57.900
all across the country.

00:26:57.900 --> 00:27:01.700
So this is a lesson, not just
about the scale of the fortune

00:27:01.700 --> 00:27:05.110
cookie business, but
also not to overreact

00:27:05.110 --> 00:27:07.610
in the face of a whole bunch
of signals that suggest

00:27:07.610 --> 00:27:09.890
to you as a security
practitioner

00:27:09.890 --> 00:27:12.200
that clearly something
criminal is going on.

00:27:12.200 --> 00:27:15.570
Sometimes people
just play the numbers

00:27:15.570 --> 00:27:18.020
on their fortune cookies.

00:27:18.020 --> 00:27:19.270
So that's all I've got.

00:27:19.270 --> 00:27:22.190
If you have any questions,
that'd be great.

00:27:22.190 --> 00:27:24.162
If you could bring
the house lights up.

00:27:24.162 --> 00:27:28.110
[APPLAUSE]

00:27:28.110 --> 00:27:30.324
Please do submit your feedback.

00:27:30.324 --> 00:27:31.490
That's very important to us.

00:27:31.490 --> 00:27:35.189
It feeds back directly into the
session planning for next year.

00:27:35.189 --> 00:27:36.730
So we'd really like
to hear from you.

00:27:40.300 --> 00:27:41.955
I can't believe no
one has a question.

00:27:45.040 --> 00:27:47.564
Please go to the mics because
this is being recorded,

00:27:47.564 --> 00:27:48.480
and ask your question.

00:27:52.617 --> 00:27:53.450
AUDIENCE: Hi, there.

00:27:53.450 --> 00:27:53.840
STEPHAN SOMOGYI: Hi.

00:27:53.840 --> 00:27:55.715
AUDIENCE: I have a
question about End-To-End.

00:27:55.715 --> 00:27:56.880
STEPHAN SOMOGYI: Sure.

00:27:56.880 --> 00:27:58.180
AUDIENCE: As I understand
IT, most of the crypto

00:27:58.180 --> 00:27:59.560
is done in JavaScript,
is that right?

00:27:59.560 --> 00:28:00.760
STEPHAN SOMOGYI:
That is correct.

00:28:00.760 --> 00:28:02.301
AUDIENCE: Any reason
not to have used

00:28:02.301 --> 00:28:05.490
Web Crypto to push that
forward quicker to enable it?

00:28:05.490 --> 00:28:08.290
STEPHAN SOMOGYI: So we have
nothing against Web Crypto.

00:28:08.290 --> 00:28:10.350
We use Web Crypto's RNG.

00:28:10.350 --> 00:28:13.190
We use a couple of other
things in Web Crypto.

00:28:13.190 --> 00:28:17.395
At the moment, Web Crypto has
not settled down completely.

00:28:17.395 --> 00:28:19.170
And so I think it
is very safe to say

00:28:19.170 --> 00:28:21.480
that we will use Web
Crypto over time.

00:28:21.480 --> 00:28:24.060
One of the things though
that was most important to us

00:28:24.060 --> 00:28:27.380
is the auditability and the
reviewability of our code.

00:28:27.380 --> 00:28:28.940
It is extremely
important that people

00:28:28.940 --> 00:28:31.060
be able to trust End-To-End.

00:28:31.060 --> 00:28:35.130
And JavaScript is much more
reviewable and much more

00:28:35.130 --> 00:28:37.400
auditable a in this context.

00:28:37.400 --> 00:28:40.800
So there are a variety of
factors that factored into it.

00:28:40.800 --> 00:28:43.240
We also discovered
early on in our research

00:28:43.240 --> 00:28:46.130
that there wasn't a
JavaScript crypto library

00:28:46.130 --> 00:28:48.110
that we were particularly
comfortable with.

00:28:48.110 --> 00:28:50.830
So we also felt it
would be a useful thing

00:28:50.830 --> 00:28:54.570
for the world at large to
have a solid JavaScript crypto

00:28:54.570 --> 00:28:55.540
library out there.

00:28:55.540 --> 00:28:59.160
So it was one of many
motivations for us to do this.

00:28:59.160 --> 00:29:00.495
AUDIENCE: All right, thanks.

00:29:00.495 --> 00:29:01.780
STEPHAN SOMOGYI: Sir.

00:29:01.780 --> 00:29:04.020
AUDIENCE: Google's
turned down some

00:29:04.020 --> 00:29:08.390
of their scouring of the
text for mail and, I think,

00:29:08.390 --> 00:29:10.820
apps for education
and paid apps,

00:29:10.820 --> 00:29:13.750
but since that is rather
prevalent with End-To-End,

00:29:13.750 --> 00:29:16.080
are you guys forfeiting
some of your ad revenues

00:29:16.080 --> 00:29:18.300
because you won't be able
to get as accurate ads?

00:29:18.300 --> 00:29:21.984
And is there fear that
everyone would do this

00:29:21.984 --> 00:29:24.150
if it's super easy, since
you're making it a browser

00:29:24.150 --> 00:29:27.374
plug-in, which should just be
relatively easy to install?

00:29:27.374 --> 00:29:29.790
STEPHAN SOMOGYI: It'll be as
easy to install as the Chrome

00:29:29.790 --> 00:29:33.860
Web Store lets us at the
time that that happens.

00:29:33.860 --> 00:29:36.690
As I said, we're going
to focus on the user.

00:29:36.690 --> 00:29:38.680
We know we have
users who require

00:29:38.680 --> 00:29:40.450
that additional
level of protection.

00:29:40.450 --> 00:29:42.900
And we think it's the right
thing to do to provide that.

00:29:42.900 --> 00:29:44.870
So all else will follow.

00:29:44.870 --> 00:29:47.080
If that has other
ramifications, we

00:29:47.080 --> 00:29:50.560
are perfectly willing
to have those occur.

00:29:50.560 --> 00:29:53.630
But at the same time,
I've lived in environments

00:29:53.630 --> 00:29:57.100
where the vast, vast majority
of email is encrypted,

00:29:57.100 --> 00:29:59.780
and I'm here to tell
you it is not fun.

00:29:59.780 --> 00:30:04.470
So you don't actually want,
in terms of usability,

00:30:04.470 --> 00:30:07.940
to have a world where
100% of your email

00:30:07.940 --> 00:30:11.280
is, in terms of the
message body, encrypted.

00:30:11.280 --> 00:30:14.082
We absolutely want a
world with 100% TLS.

00:30:14.082 --> 00:30:15.540
And that's one of
the reasons we're

00:30:15.540 --> 00:30:17.373
doing what we're doing
with the Transparency

00:30:17.373 --> 00:30:18.720
Report and other things.

00:30:18.720 --> 00:30:20.540
But things get very,
very complicated

00:30:20.540 --> 00:30:24.360
unless you can get whatever
message body encryption

00:30:24.360 --> 00:30:27.970
you use truly
pervasive overnight,

00:30:27.970 --> 00:30:31.674
and that turns out
to actually be hard.

00:30:31.674 --> 00:30:33.090
AUDIENCE: Is there
a way on the UI

00:30:33.090 --> 00:30:36.540
to know if TLS was used on
the transport of emails--

00:30:36.540 --> 00:30:39.050
for instance, a lock
icon next to an email

00:30:39.050 --> 00:30:43.550
address to know that no
one else has easy access

00:30:43.550 --> 00:30:45.890
to view this email in transport?

00:30:45.890 --> 00:30:49.769
STEPHAN SOMOGYI: There is-- it
depends on your mail client.

00:30:49.769 --> 00:30:50.560
You could eyeball--

00:30:50.560 --> 00:30:52.020
AUDIENCE: Well, let's
say directly in Gmail.

00:30:52.020 --> 00:30:53.790
Is there any user
indication that SSL

00:30:53.790 --> 00:30:55.702
was used or will be used?

00:30:55.702 --> 00:30:57.410
STEPHAN SOMOGYI: Gmail
does not currently

00:30:57.410 --> 00:31:00.020
have any such indication.

00:31:00.020 --> 00:31:03.260
And my first inclination
would be look at the headers.

00:31:03.260 --> 00:31:06.182
The problem is headers are
not always 100% trustable.

00:31:06.182 --> 00:31:07.640
So you could wind
up in a situation

00:31:07.640 --> 00:31:10.970
where you report
falsely either way.

00:31:10.970 --> 00:31:15.140
Since we don't have full
control over every single hop

00:31:15.140 --> 00:31:18.900
along the way, how
much do we actually

00:31:18.900 --> 00:31:22.510
believe an entity
that just claims it?

00:31:22.510 --> 00:31:24.610
There's some interesting
attack opportunities.

00:31:24.610 --> 00:31:27.190
If you want to create a
false sense of security,

00:31:27.190 --> 00:31:30.080
awesome way to do it-- somewhere
along the way say, hey,

00:31:30.080 --> 00:31:32.280
this has actually
been fully encrypted,

00:31:32.280 --> 00:31:33.660
except where it wasn't.

00:31:33.660 --> 00:31:35.550
But that MTA is misreporting.

00:31:35.550 --> 00:31:38.300
So it's fraught with more
danger then you might suspect.

00:31:38.300 --> 00:31:40.200
And one thing that
we're very, very clear

00:31:40.200 --> 00:31:41.340
about is we do
not want to create

00:31:41.340 --> 00:31:42.423
a false sense of security.

00:31:46.127 --> 00:31:47.960
AUDIENCE: So do you
have any recommendations

00:31:47.960 --> 00:31:51.050
on how to educate users?

00:31:51.050 --> 00:31:53.220
Some things that work
better than other things?

00:31:53.220 --> 00:31:55.940
STEPHAN SOMOGYI: It depends very
much on the user population.

00:31:55.940 --> 00:31:58.730
Humans are a very diverse bunch.

00:31:58.730 --> 00:32:01.170
There are many
cultural differences.

00:32:01.170 --> 00:32:03.110
There are many
linguistic differences.

00:32:03.110 --> 00:32:05.400
I don't think that there
is a one size fits all.

00:32:05.400 --> 00:32:09.470
One of the things that our user
experience researchers focus on

00:32:09.470 --> 00:32:11.920
is, how do we make
the warnings that we

00:32:11.920 --> 00:32:13.860
present as effective
as possible?

00:32:13.860 --> 00:32:17.030
How do we prevent people
from just clicking through

00:32:17.030 --> 00:32:19.830
in the face of something that
we know is a very active threat?

00:32:19.830 --> 00:32:22.150
And it turns out
to be quite hard.

00:32:22.150 --> 00:32:24.980
So it is an unsolved problem.

00:32:24.980 --> 00:32:26.660
I think you have
so much variability

00:32:26.660 --> 00:32:30.000
in the human psyche that I'm
doubtful that it will ever

00:32:30.000 --> 00:32:31.440
be solved perfectly.

00:32:31.440 --> 00:32:34.070
But there are a lot of people
working very, very hard

00:32:34.070 --> 00:32:36.390
on this notion of
usable security.

00:32:36.390 --> 00:32:37.860
There's a lot of
research going on.

00:32:37.860 --> 00:32:40.480
There's an existing
large corpus of research,

00:32:40.480 --> 00:32:41.540
but it's far from solved.

00:32:45.370 --> 00:32:47.350
Any more questions?

00:32:47.350 --> 00:32:48.820
Going once.

00:32:48.820 --> 00:32:51.080
Going twice.

00:32:51.080 --> 00:32:52.010
OK thanks very much.

00:32:52.010 --> 00:32:54.160
[APPLAUSE]

