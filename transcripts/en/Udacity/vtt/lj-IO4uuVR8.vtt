WEBVTT
Kind: captions
Language: en

00:00:00.300 --> 00:00:01.980
Okay Michael, you got answers for me?

00:00:01.980 --> 00:00:05.450
&gt;&gt; Yeah, I think so. The first thing I notice is that if I put

00:00:05.450 --> 00:00:08.350
equal weights on all four examples, like

00:00:08.350 --> 00:00:10.140
I, I decided that instead of solving this

00:00:10.140 --> 00:00:13.920
problem by thinking, I would just try a couple examples, and see if I found

00:00:13.920 --> 00:00:18.890
things in both boxes. So, if I put equal weight on X1, X2, X3, X4.

00:00:18.890 --> 00:00:19.900
&gt;&gt; Mm-hm.

00:00:19.900 --> 00:00:23.430
&gt;&gt; Then hypothesis one, H1 gets three

00:00:23.430 --> 00:00:25.370
out of four correct, that's three quarters.

00:00:25.370 --> 00:00:27.260
That's better than a half. So.

00:00:27.260 --> 00:00:27.540
&gt;&gt; Well done.

00:00:27.540 --> 00:00:31.920
&gt;&gt; Then I fill that in, in the good boxes, quarters all the way down.

00:00:31.920 --> 00:00:34.102
&gt;&gt; That's a turtle, 'because it's turtles all the way down [LAUGH].

00:00:34.102 --> 00:00:36.200
&gt;&gt; No, no, it's not though, it should be quarters all

00:00:36.200 --> 00:00:37.860
the way down. I thought you'd may be draw a quarter.

00:00:37.860 --> 00:00:41.410
&gt;&gt; I, I can't draw a quarter, also I can't draw a turtle obviously but still.

00:00:41.410 --> 00:00:44.420
&gt;&gt; [LAUGH] Agreed. Alright, good.

00:00:44.420 --> 00:00:45.900
&gt;&gt; You'd think, anyone, do you think anyone listening to

00:00:45.900 --> 00:00:47.730
this is old enough to get turtles all the way down.

00:00:47.730 --> 00:00:49.860
&gt;&gt; Yeah, that's a great joke. Everybody knows that joke.

00:00:49.860 --> 00:00:50.370
&gt;&gt; And

00:00:50.370 --> 00:00:53.360
if people don't know the joke, then we should pause this thing right now, and

00:00:53.360 --> 00:00:57.100
you should go look up turtles all the way down. And then come back. Okay.

00:00:57.100 --> 00:00:59.530
&gt;&gt; It's a, it's a really great joke if you're computer scientist.

00:00:59.530 --> 00:01:00.970
&gt;&gt; Yes, and if you don't think it's a good

00:01:00.970 --> 00:01:03.220
joke then you should probably be in a different field. Okay.

00:01:03.220 --> 00:01:03.260
&gt;&gt; [LAUGH]

00:01:03.260 --> 00:01:04.680
&gt;&gt; What about the evil distribution?

00:01:04.680 --> 00:01:06.330
&gt;&gt; So then I started to generate. Okay, well what

00:01:06.330 --> 00:01:09.550
if, the, the, the issue here is that, because we spread

00:01:09.550 --> 00:01:13.070
all the, the, the, the probability out in the first hypothesis

00:01:13.070 --> 00:01:15.520
really good. So I said okay, well let me put all

00:01:15.520 --> 00:01:17.950
the weight on the first example. The x1.

00:01:17.950 --> 00:01:19.430
&gt;&gt; Okay. So what did that look like.

00:01:19.430 --> 00:01:22.400
&gt;&gt; Now h1 did very badly. It gets, it's 100 percent error. And

00:01:22.400 --> 00:01:26.800
h2 is 100 percent error. But h3 is 0 percent errors. So so.

00:01:26.800 --> 00:01:26.890
&gt;&gt; yes.

00:01:26.890 --> 00:01:29.050
&gt;&gt; So, so putting it all putting all the weight on x1 is no

00:01:29.050 --> 00:01:32.640
good. And if you look x2, x3, x4, they all have the property that there's

00:01:32.640 --> 00:01:34.750
always a hypothesis that gets them right.

00:01:34.750 --> 00:01:35.960
So I started to think, well maybe there

00:01:35.960 --> 00:01:40.700
isn't an evil distribution. And I kind of lucked into putting a half on both

00:01:40.700 --> 00:01:43.270
the first and the second one. because i figured that, that

00:01:43.270 --> 00:01:46.080
ought to work, but then i realized, oh wait a second that's

00:01:46.080 --> 00:01:50.570
an evil distribution, because if you choose h1, h2, or h3,

00:01:50.570 --> 00:01:55.580
they all have exactly 50% error on the half a half distribution.

00:01:55.580 --> 00:02:01.700
&gt;&gt; Very good. So 1/2, 1/2, zero, zero, is a correct answer.

00:02:01.700 --> 00:02:05.835
&gt;&gt; Now I don't know if there's others. You know, certainly X, putting all

00:02:05.835 --> 00:02:09.185
the weight on X2 and X3 is no good, because H2 and H1

00:02:09.185 --> 00:02:12.290
both get those. Putting all the weight on X3 and X4 are no

00:02:12.290 --> 00:02:16.000
good, because H1 gets all of those correct. In fact we have to

00:02:16.000 --> 00:02:19.420
have some weight on X1, right. Otherwise H1 is the way to go.

00:02:19.420 --> 00:02:23.290
&gt;&gt; Right. So, yeah. No, that's interesting.

00:02:23.290 --> 00:02:24.900
So what does that mean in this case?

00:02:24.900 --> 00:02:26.200
&gt;&gt; What do you mean, what does that mean?

00:02:26.200 --> 00:02:27.920
&gt;&gt; So what does this tell us about, how

00:02:27.920 --> 00:02:30.020
do we build a weak learner for this example?

00:02:30.020 --> 00:02:30.890
&gt;&gt; So what it

00:02:30.890 --> 00:02:32.260
tells us is that since there is a

00:02:32.260 --> 00:02:35.250
distribution for which none of these hypotheses will

00:02:35.250 --> 00:02:37.310
be better than chance, there is no weak

00:02:37.310 --> 00:02:40.917
learner for this hypothesis space, on this instant set.

00:02:40.917 --> 00:02:42.510
&gt;&gt; Interesting. Now is there a way that

00:02:42.510 --> 00:02:44.860
we can, like, okay, so this example has no

00:02:44.860 --> 00:02:46.570
weak learner. Is there a way to change

00:02:46.570 --> 00:02:48.470
this example so it would have a weak learner?

00:02:48.470 --> 00:02:50.530
&gt;&gt; Um...I'm sure there is.

00:02:50.530 --> 00:02:55.320
&gt;&gt; Like if we change that x2, x, h3, if that was a check instead of an X.

00:02:55.320 --> 00:02:57.218
&gt;&gt; Which one?

00:02:57.218 --> 00:02:59.512
X2 H3.

00:02:59.512 --> 00:03:01.840
&gt;&gt; So if we made that a green one, here I'll,

00:03:01.840 --> 00:03:04.530
I'll make it a green one. By using the power of computers.

00:03:04.530 --> 00:03:06.130
&gt;&gt; Woah, special effect.

00:03:06.130 --> 00:03:06.770
&gt;&gt; Yes.

00:03:06.770 --> 00:03:08.890
&gt;&gt; So now there's no way to put weight

00:03:08.890 --> 00:03:11.780
on any two things and have it fail. I don't

00:03:11.780 --> 00:03:13.890
know, my intuition now is that this, this should have

00:03:13.890 --> 00:03:16.760
a weak learner. Okay, well, how would we prove that?

00:03:16.760 --> 00:03:19.290
&gt;&gt; I don't know, but may be we should end this quiz.

00:03:19.290 --> 00:03:22.360
&gt;&gt; Yeah, I think, we should end this quiz. And leave it as an exercise

00:03:22.360 --> 00:03:26.020
to the listener. I'm pretty sure I can figure this out.

00:03:26.020 --> 00:03:27.630
By the way, we should point a couple of things here

00:03:27.630 --> 00:03:30.963
though, Michael. That one is that, the if it weren't the

00:03:30.963 --> 00:03:35.720
case, if we had more hypotheses and more examples. Perhaps an odd

00:03:35.720 --> 00:03:38.070
number of them and we have the x's and the y's

00:03:38.070 --> 00:03:40.600
in the right places then there'd be lots of ways to

00:03:40.600 --> 00:03:44.720
get weak learners for all the distributions just because you'd have

00:03:44.720 --> 00:03:47.390
more choices to choose from. What made this one particularly hard is

00:03:47.390 --> 00:03:50.090
that you only had three hypotheses and none of

00:03:50.090 --> 00:03:52.890
them was, not all of them were particularly good.

00:03:52.890 --> 00:03:54.920
&gt;&gt; Sure, yeah. I mean if you have a bun-, you can have many,

00:03:54.920 --> 00:03:56.860
many hypotheses and they're all pretty bad

00:03:56.860 --> 00:03:58.320
then you're not going to do very well.

00:03:58.320 --> 00:04:00.030
&gt;&gt; Well, it would depend upon if

00:04:00.030 --> 00:04:01.830
they're bad on very different things. But you're

00:04:01.830 --> 00:04:05.750
right, if you have a whole lot of hypotheses that are bad at everything, you're

00:04:05.750 --> 00:04:08.680
going to have a very hard time with a weak learner. And if you have a

00:04:08.680 --> 00:04:10.140
whole bunch of hypotheses that are good at

00:04:10.140 --> 00:04:12.400
almost everything, then it's pretty easy to have

00:04:12.400 --> 00:04:12.850
a weak learner.

00:04:12.850 --> 00:04:14.700
&gt;&gt; Interesting. Okay, this is more subtle

00:04:14.700 --> 00:04:16.579
than I thought. So that's, that's interesting.

00:04:16.579 --> 00:04:18.320
&gt;&gt; Right. So what the lesson you should take away

00:04:18.320 --> 00:04:21.209
from this is. If you were just, to think about it

00:04:21.209 --> 00:04:23.340
for 2 seconds you might think okay weak learner. That

00:04:23.340 --> 00:04:26.900
seems easy. And often it is, but if you think about

00:04:26.900 --> 00:04:29.600
for 4 seconds you realize that's actually a pretty strong

00:04:29.600 --> 00:04:32.750
condition. You're going to have to have a lot of hypotheses that

00:04:32.750 --> 00:04:34.430
are, many of which are going to have to do good on

00:04:34.430 --> 00:04:37.520
lots of different examples, or otherwise, you're not always going to be

00:04:37.520 --> 00:04:39.320
able to find one that does well no matter what the

00:04:39.320 --> 00:04:43.420
distribution is. So it's actually a fairly strong, and important condition.

