WEBVTT
Kind: captions
Language: en

00:00:01.360 --> 00:00:02.009
SVEN MAWSON: All right,
thank you.

00:00:02.009 --> 00:00:04.570
Thank you all for coming.

00:00:04.570 --> 00:00:07.040
I'm going to get started now
as a couple more people

00:00:07.040 --> 00:00:07.680
straggle in.

00:00:07.680 --> 00:00:09.300
I appreciate everyone
coming to this.

00:00:09.300 --> 00:00:10.460
My name is Sven Mawson.

00:00:10.460 --> 00:00:14.210
I'm going to be talking to you
about optimizing your code,

00:00:14.210 --> 00:00:17.000
and in particular about
optimizing API access to

00:00:17.000 --> 00:00:18.520
Google's APIs.

00:00:18.520 --> 00:00:20.450
So we're not going to cover
all of optimization.

00:00:20.450 --> 00:00:21.640
That's a pretty wide topic.

00:00:21.640 --> 00:00:25.240
There's a lot of interesting
talks at Google I/O to go

00:00:25.240 --> 00:00:28.220
learn about such things, but I'm
going to be focused really

00:00:28.220 --> 00:00:30.690
on what you can do with the
features that we provide as

00:00:30.690 --> 00:00:33.990
part of the APIs to make your
life much easier and make your

00:00:33.990 --> 00:00:36.880
code run a lot faster.

00:00:36.880 --> 00:00:41.020
And again you can use
the hashtag #io12 to

00:00:41.020 --> 00:00:42.780
discuss this talk.

00:00:42.780 --> 00:00:43.100
All right.

00:00:43.100 --> 00:00:48.370
So why would you be interested
in optimizing your API access?

00:00:48.370 --> 00:00:50.890
Well, why are you interested
in optimizing

00:00:50.890 --> 00:00:54.100
your code in general?

00:00:54.100 --> 00:00:57.190
If you're a web developer or
a mobile developer, you're

00:00:57.190 --> 00:01:00.910
probably well aware of the
limitations of those platforms

00:01:00.910 --> 00:01:04.019
in terms of some of the CPU
constraints and some of the

00:01:04.019 --> 00:01:05.239
bandwidth constraints.

00:01:05.239 --> 00:01:08.870
So you really want to make your
code as fast as possible

00:01:08.870 --> 00:01:10.130
to make your user experience
better.

00:01:10.130 --> 00:01:15.430
So speed really is one of the
features of your applications.

00:01:15.430 --> 00:01:16.890
It's not an afterthought.

00:01:16.890 --> 00:01:19.300
It's actually one of the prime,

00:01:19.300 --> 00:01:20.430
most important features.

00:01:20.430 --> 00:01:23.010
And we at Google especially
know this.

00:01:23.010 --> 00:01:25.350
You're all familiar with how
fast Google searches.

00:01:25.350 --> 00:01:28.910
We put a lot of effort into
that, and it really shows and

00:01:28.910 --> 00:01:32.850
it makes the user experience
so, so much better.

00:01:32.850 --> 00:01:36.940
And in fact, it actually can
lead directly to more users

00:01:36.940 --> 00:01:40.810
coming in because if your
application is faster than

00:01:40.810 --> 00:01:43.430
your competitors, it's a huge
competitive advantage and

00:01:43.430 --> 00:01:44.250
you'll win every time.

00:01:44.250 --> 00:01:47.040
So it's really important.

00:01:47.040 --> 00:01:50.390
Not only that, but also
bandwidth is very important

00:01:50.390 --> 00:01:52.180
because it's expensive.

00:01:52.180 --> 00:01:54.410
It's hard to read that.

00:01:54.410 --> 00:01:57.380
Bandwidth costs money, not only
to you if you're, for

00:01:57.380 --> 00:01:58.660
example, using App
Engine, you're

00:01:58.660 --> 00:02:00.330
paying for the bandwidth.

00:02:00.330 --> 00:02:02.870
But to users as well, if they're
on mobile plans that

00:02:02.870 --> 00:02:06.020
are not unlimited, which almost
none of them are these

00:02:06.020 --> 00:02:08.820
days, your users are actually
paying for the bandwidth.

00:02:08.820 --> 00:02:11.250
So if you're writing a mobile
application, you really want

00:02:11.250 --> 00:02:14.850
to be careful to use as little
bandwidth as possible.

00:02:14.850 --> 00:02:19.780
And along with saving your users
money, you also actually

00:02:19.780 --> 00:02:22.680
make your app faster in the
process, because it uses less

00:02:22.680 --> 00:02:24.720
memory, it uses less CPU.

00:02:24.720 --> 00:02:27.350
Things are really,
really nice.

00:02:27.350 --> 00:02:28.120
All right.

00:02:28.120 --> 00:02:31.860
To sort of frame this discussion
of how to make your

00:02:31.860 --> 00:02:34.640
API access faster, I'm going
to show you an example

00:02:34.640 --> 00:02:38.740
application I built just really
to show what you can do

00:02:38.740 --> 00:02:40.670
with Google APIs and how
to make them faster.

00:02:40.670 --> 00:02:43.960
So this application is
built on App Engine.

00:02:43.960 --> 00:02:46.170
Hopefully you all are familiar
with App Engine.

00:02:46.170 --> 00:02:48.480
And it's a task management
application.

00:02:48.480 --> 00:02:52.370
So it's very similar to the
TaskList that Google provides.

00:02:52.370 --> 00:02:56.380
It lets you create lists
of items and add them.

00:02:56.380 --> 00:02:58.930
And it's integrated with a
couple different Google APIs.

00:02:58.930 --> 00:03:01.750
So the first one it's integrated
with is Google

00:03:01.750 --> 00:03:05.000
Drive, and this lets you
actually store the Tasks

00:03:05.000 --> 00:03:07.590
inside Google Drive as
little documents.

00:03:07.590 --> 00:03:11.050
So each TaskList is a document
in Google Drive.

00:03:11.050 --> 00:03:12.920
You can actually share
them with people.

00:03:12.920 --> 00:03:14.090
You can edit them.

00:03:14.090 --> 00:03:15.910
There's no collaborative editing
yet because I built

00:03:15.910 --> 00:03:17.920
this on Drive SDK 1.

00:03:17.920 --> 00:03:19.690
SDK 2 actually has collaborative
editing.

00:03:19.690 --> 00:03:22.410
So if I'm feeling ambitious,
I might extend my

00:03:22.410 --> 00:03:24.260
application with that.

00:03:24.260 --> 00:03:27.820
It integrates with Tasks, so it
actually can sync back to

00:03:27.820 --> 00:03:30.430
the Google Tasks API, and it's
also integrated with Calendar,

00:03:30.430 --> 00:03:34.070
so you can set due dates on your
Tasks and have them show

00:03:34.070 --> 00:03:34.640
up in Calendar.

00:03:34.640 --> 00:03:36.000
So I'm going to give you
a little demo of

00:03:36.000 --> 00:03:39.110
how that all works.

00:03:39.110 --> 00:03:45.270
So I actually have, already in
My Drive, some TaskLists.

00:03:45.270 --> 00:03:47.250
Actually I call them
super lists.

00:03:47.250 --> 00:03:49.180
So we can click on
one, for example.

00:03:49.180 --> 00:03:52.055
This will load up my application
on App Spot, as

00:03:52.055 --> 00:03:52.950
you can see.

00:03:52.950 --> 00:03:54.910
It's an App Engine
application.

00:03:54.910 --> 00:03:56.390
It's quite an ugly UI.

00:03:56.390 --> 00:03:57.210
I apologize.

00:03:57.210 --> 00:03:59.880
I'm a back-end engineer, not
a front-end engineer.

00:03:59.880 --> 00:04:03.820
So things are a little ugly.

00:04:03.820 --> 00:04:07.930
And in fact, you can
open a new one.

00:04:07.930 --> 00:04:12.100
If I go look at My Tasks, for
example, you can see this.

00:04:12.100 --> 00:04:13.900
I think that's the
same one, yeah.

00:04:13.900 --> 00:04:14.980
So, related sessions.

00:04:14.980 --> 00:04:21.019
Let's say I decide that I want
another one in here.

00:04:21.019 --> 00:04:23.280
Actually, let's not
do it in this one.

00:04:23.280 --> 00:04:24.360
Let's do it over here.

00:04:24.360 --> 00:04:30.470
So let's add a new session
to go see.

00:04:30.470 --> 00:04:32.690
Anyone have an example, a good
session they're interested in

00:04:32.690 --> 00:04:37.350
seeing that I should
add to this list?

00:04:37.350 --> 00:04:38.120
Anyone, anyone?

00:04:38.120 --> 00:04:39.290
No?

00:04:39.290 --> 00:04:39.460
Endpoints?

00:04:39.460 --> 00:04:39.840
Yeah.

00:04:39.840 --> 00:04:41.200
You should definitely learn
about endpoints.

00:04:41.200 --> 00:04:47.040
So Google Cloud Endpoints,
which is awesome.

00:04:47.040 --> 00:04:47.350
All right.

00:04:47.350 --> 00:04:52.730
So if I save that, I can save
it, then in theory it will

00:04:52.730 --> 00:04:58.160
show up, when it finishes
saving, back in here.

00:04:58.160 --> 00:05:01.300
I might have to refresh it.

00:05:01.300 --> 00:05:01.740
There it is.

00:05:01.740 --> 00:05:02.070
OK.

00:05:02.070 --> 00:05:04.590
So the sync, very exciting.

00:05:04.590 --> 00:05:06.290
I can add a due date to that.

00:05:06.290 --> 00:05:11.370
Let's see, I should
see that today.

00:05:11.370 --> 00:05:12.630
Save that.

00:05:12.630 --> 00:05:14.970
And in theory, this will of
course save into calendar.

00:05:14.970 --> 00:05:15.670
Things sync.

00:05:15.670 --> 00:05:16.920
Things take time.

00:05:19.390 --> 00:05:20.510
There it is.

00:05:20.510 --> 00:05:20.810
Voila.

00:05:20.810 --> 00:05:21.200
OK.

00:05:21.200 --> 00:05:23.100
So you've seen the
application.

00:05:23.100 --> 00:05:25.010
Very exciting.

00:05:25.010 --> 00:05:29.260
It's integrated with those
various systems, but

00:05:29.260 --> 00:05:29.940
it's not that fast.

00:05:29.940 --> 00:05:31.400
So we're going to
make it faster.

00:05:31.400 --> 00:05:32.970
First of all, I'm just going
to go through some of the

00:05:32.970 --> 00:05:35.250
code, so you see the
starting place.

00:05:35.250 --> 00:05:38.640
And then from there, we'll work
towards actually making

00:05:38.640 --> 00:05:40.780
it move along quickly.

00:05:40.780 --> 00:05:42.760
So the first thing I'm going
to talk about is really,

00:05:42.760 --> 00:05:44.440
really briefly, authentication.

00:05:44.440 --> 00:05:46.460
There are many talks about
authentication.

00:05:46.460 --> 00:05:50.160
You all know it's a pretty
painful subject.

00:05:50.160 --> 00:05:53.170
I cheat by just using the code
that the Drive team already

00:05:53.170 --> 00:05:53.760
wrote for me.

00:05:53.760 --> 00:05:58.400
So on the Drive documentation
site, there's an example in

00:05:58.400 --> 00:06:01.690
Java, called Doctor Edit, that
does the Drive authentication

00:06:01.690 --> 00:06:02.380
basically for you.

00:06:02.380 --> 00:06:04.120
I just pulled that code in.

00:06:04.120 --> 00:06:05.750
You create it, you
call, get active

00:06:05.750 --> 00:06:06.840
credential, and you're done.

00:06:06.840 --> 00:06:07.630
You don't worry about
anything.

00:06:07.630 --> 00:06:09.630
So it's very simple.

00:06:09.630 --> 00:06:12.020
I recommend checking that out
if you're doing a Drive app.

00:06:12.020 --> 00:06:13.960
Make your life much easier.

00:06:13.960 --> 00:06:14.320
OK.

00:06:14.320 --> 00:06:16.400
So let's say we have that.

00:06:16.400 --> 00:06:18.870
How do I actually call
the Drive API?

00:06:18.870 --> 00:06:22.160
So it's actually very easy.

00:06:22.160 --> 00:06:24.510
I should preface this by
saying that all of the

00:06:24.510 --> 00:06:28.110
examples are going to be using
the Java client library for

00:06:28.110 --> 00:06:29.490
Google APIs.

00:06:29.490 --> 00:06:32.300
Most of this is applicable
to other client

00:06:32.300 --> 00:06:34.600
libraries as well.

00:06:34.600 --> 00:06:37.170
The Java client is the farthest
along with the

00:06:37.170 --> 00:06:40.000
performance features, so I'm
going to focus on that.

00:06:40.000 --> 00:06:41.630
But if you're using a different
library, different

00:06:41.630 --> 00:06:43.230
language, don't worry.

00:06:43.230 --> 00:06:44.710
We have you covered.

00:06:44.710 --> 00:06:45.040
OK.

00:06:45.040 --> 00:06:51.180
So in Java, we create a
Drive service here.

00:06:51.180 --> 00:06:53.680
And then if I want to get a
particular file, I just call

00:06:53.680 --> 00:06:55.460
service.files.get.

00:06:55.460 --> 00:06:57.210
That creates a request object.

00:06:57.210 --> 00:06:59.820
If anyone was here in the
previous session about the

00:06:59.820 --> 00:07:02.660
JavaScript API, it's
very similar.

00:07:02.660 --> 00:07:05.790
You execute methods that create
request objects, and

00:07:05.790 --> 00:07:07.340
then you call execute on them.

00:07:07.340 --> 00:07:09.930
And you'll see the reason
for that later.

00:07:09.930 --> 00:07:12.380
But in this case, then we just
call execute, and we get back

00:07:12.380 --> 00:07:15.170
a file object which has all
of the file metadata.

00:07:15.170 --> 00:07:18.240
Now in Drive, files are
split into two parts.

00:07:18.240 --> 00:07:20.000
There's the metadata part,
which has things like the

00:07:20.000 --> 00:07:25.520
title, the last modified time,
the text search metadata.

00:07:25.520 --> 00:07:27.040
You can add things like that.

00:07:27.040 --> 00:07:28.680
There's actually a fair
amount in there.

00:07:28.680 --> 00:07:31.420
But the actual content of the
file is stored as a binary

00:07:31.420 --> 00:07:34.120
blob, and it's not stored
in that file.

00:07:34.120 --> 00:07:35.550
After you get back, you have
to make another call.

00:07:35.550 --> 00:07:38.340
So that's what this
second section is.

00:07:38.340 --> 00:07:41.030
So this is the important
part right here.

00:07:41.030 --> 00:07:43.270
That request object we've
created earlier actually has

00:07:43.270 --> 00:07:46.800
this cool Get Media HTTP
Downloader method on it that

00:07:46.800 --> 00:07:48.430
gives you this downloader
object.

00:07:48.430 --> 00:07:51.360
You call download
with the URL.

00:07:51.360 --> 00:07:54.140
In this case, the URL that
we're using is from that

00:07:54.140 --> 00:07:55.000
initial request.

00:07:55.000 --> 00:07:58.160
So the way Drive works is to
get the content, you first

00:07:58.160 --> 00:07:59.690
have to get the metadata,
which includes

00:07:59.690 --> 00:08:00.920
a link to the content.

00:08:00.920 --> 00:08:03.040
And that's a secure link.

00:08:03.040 --> 00:08:03.950
So you have to do it that way.

00:08:03.950 --> 00:08:06.250
You have to do two requests
to get it.

00:08:06.250 --> 00:08:09.690
And then in my application,
I'm storing this as a JSON

00:08:09.690 --> 00:08:11.430
blob, so it's just text data.

00:08:11.430 --> 00:08:13.600
So I create a string
from the bytes.

00:08:13.600 --> 00:08:15.460
Because the Drive API doesn't
know what you're

00:08:15.460 --> 00:08:16.945
going to do with it.

00:08:16.945 --> 00:08:20.900
It could be an image,
for all it knows.

00:08:20.900 --> 00:08:22.080
OK, so that's Drive.

00:08:22.080 --> 00:08:22.950
What about the other APIs.

00:08:22.950 --> 00:08:26.450
So the next one I integrated
with was TaskList.

00:08:26.450 --> 00:08:28.620
One of the things they didn't
show you in the very quick

00:08:28.620 --> 00:08:31.750
demo there is that you can
actually take one of my super

00:08:31.750 --> 00:08:34.630
lists and just create
a TaskList from it.

00:08:34.630 --> 00:08:36.830
So here's how you
would do that.

00:08:36.830 --> 00:08:39.090
You just create the object.

00:08:39.090 --> 00:08:40.429
Well, first you do the
same kind of thing.

00:08:40.429 --> 00:08:41.690
You create the Task service.

00:08:41.690 --> 00:08:45.190
It's identical to Drive,
just a different name.

00:08:45.190 --> 00:08:48.910
Then you create a TaskList,
set the title, call

00:08:48.910 --> 00:08:51.680
Tasklists.Insert right here.

00:08:51.680 --> 00:08:53.280
You get that TaskList,
and again it

00:08:53.280 --> 00:08:54.730
creates a request object.

00:08:54.730 --> 00:08:59.020
You call execute on that, and it
gives you back your result.

00:08:59.020 --> 00:09:01.390
And we actually need the result,
because we're going to

00:09:01.390 --> 00:09:02.750
insert a bunch of
items into it.

00:09:02.750 --> 00:09:04.810
And to insert the items,
you need the ID.

00:09:04.810 --> 00:09:06.590
And the ID you got back from
that first request.

00:09:06.590 --> 00:09:10.050
So pretty standard.

00:09:10.050 --> 00:09:14.530
You create Tasks, call insert,
give it the ID and object.

00:09:14.530 --> 00:09:16.740
It gives you back the
inserted one.

00:09:16.740 --> 00:09:19.320
Actually, it gives you back
the request insert.

00:09:19.320 --> 00:09:21.560
You execute that, and it gives
you back the inserted one.

00:09:21.560 --> 00:09:23.090
All I care about is the
ID, because I'm

00:09:23.090 --> 00:09:24.030
actually going to do sync.

00:09:24.030 --> 00:09:27.280
So I need the IDs to do
the synchronization.

00:09:27.280 --> 00:09:30.480
So I keep track of that
in item.taskid.

00:09:30.480 --> 00:09:31.420
Very simple.

00:09:31.420 --> 00:09:34.840
Not too exciting.

00:09:34.840 --> 00:09:37.960
Similar idea with Calendar.

00:09:37.960 --> 00:09:40.530
You just create a calendar
service.

00:09:40.530 --> 00:09:42.250
You call events.get.

00:09:42.250 --> 00:09:44.940
In this case, I'm going to use
the user's primary calendar.

00:09:44.940 --> 00:09:48.020
I don't feel like putting up
a picker to let them choose

00:09:48.020 --> 00:09:48.960
which calendar to use.

00:09:48.960 --> 00:09:51.130
I just always use
the primary one.

00:09:51.130 --> 00:09:53.880
Save myself some effort.

00:09:53.880 --> 00:09:56.390
And in this case, we're
actually doing a sync.

00:09:56.390 --> 00:09:59.810
So I want to get the existing
calendar event to figure out

00:09:59.810 --> 00:10:02.780
its due date and title to see
if I need to update them.

00:10:02.780 --> 00:10:06.820
So first I get them all, and
then in a loop I go over them

00:10:06.820 --> 00:10:10.240
and update them all.

00:10:10.240 --> 00:10:10.600
All right.

00:10:10.600 --> 00:10:14.830
So that's the code of how the
application works, but again,

00:10:14.830 --> 00:10:16.970
what we really care about is
making this fast, right?

00:10:16.970 --> 00:10:19.600
So the first thing, if you're
ever trying to make an

00:10:19.600 --> 00:10:22.420
application fast, is understand
where it's slow.

00:10:22.420 --> 00:10:26.330
So we've all heard early
optimization is

00:10:26.330 --> 00:10:28.820
the root of all evil.

00:10:28.820 --> 00:10:32.570
I think a more appropriate term
would be optimization

00:10:32.570 --> 00:10:35.120
without profiling is the
root of all evil.

00:10:35.120 --> 00:10:39.270
If you're spending all of your
time on optimizing 10% of the

00:10:39.270 --> 00:10:42.115
actual time spent by your
application, you're not going

00:10:42.115 --> 00:10:43.500
to make any big gain.

00:10:43.500 --> 00:10:46.430
So we really need to know, where
is our time being spent,

00:10:46.430 --> 00:10:48.960
so we can actually
upgrade things.

00:10:48.960 --> 00:10:51.900
So in this case, I'm going to
look at four different actions

00:10:51.900 --> 00:10:54.840
that the user initiates.

00:10:54.840 --> 00:10:55.890
The first is just load.

00:10:55.890 --> 00:11:00.200
So if I ever go to one of my
lists and just hit refresh,

00:11:00.200 --> 00:11:01.900
that's a load action.

00:11:01.900 --> 00:11:06.090
You can see, I'll actually
show you on this.

00:11:06.090 --> 00:11:10.990
If I just hit refresh,
that's a load.

00:11:10.990 --> 00:11:13.920
And the metrics on the
right-hand side there are all

00:11:13.920 --> 00:11:15.550
my information about
what took time.

00:11:15.550 --> 00:11:19.680
So I'll talk about that now.

00:11:19.680 --> 00:11:22.600
The other actions are saving,
and then syncing to Tasks and

00:11:22.600 --> 00:11:23.290
syncing to Calendar.

00:11:23.290 --> 00:11:26.750
So we have our actions, and then
we also have the things

00:11:26.750 --> 00:11:27.620
that we're actually measuring.

00:11:27.620 --> 00:11:30.720
So for this talk, we're going
to be focused on both speed

00:11:30.720 --> 00:11:31.450
and bandwidth.

00:11:31.450 --> 00:11:34.510
So latency, how long the
actions took, and then

00:11:34.510 --> 00:11:39.090
bandwidth, how much of the wire
did it actually use up?

00:11:39.090 --> 00:11:41.950
And for the bandwidth, we're
actually only going to look at

00:11:41.950 --> 00:11:43.020
response size.

00:11:43.020 --> 00:11:45.490
There's a lot more things you
could look at, but just to

00:11:45.490 --> 00:11:49.240
keep things simple for the sake
of this demo and talk.

00:11:49.240 --> 00:11:51.600
So how do we actually do this?

00:11:51.600 --> 00:11:55.560
Who here is familiar with
Guava for Java?

00:11:55.560 --> 00:11:57.050
Anyone?

00:11:57.050 --> 00:11:58.730
You all should go get familiar,
if you're Java

00:11:58.730 --> 00:12:00.530
engineers, get familiar
with Guava.

00:12:00.530 --> 00:12:01.720
It's awesome.

00:12:01.720 --> 00:12:04.280
Guava is a set of libraries
that Google provides.

00:12:04.280 --> 00:12:07.030
It's sort of the best of.

00:12:07.030 --> 00:12:10.410
You could think of it as the
greatest hits of internal Java

00:12:10.410 --> 00:12:12.200
development at Google.

00:12:12.200 --> 00:12:13.900
I don't just say that because
my name is on some of the

00:12:13.900 --> 00:12:16.460
code, because it's actually
really cool.

00:12:16.460 --> 00:12:18.960
My name is not on Stopwatch,
which I'm using here.

00:12:18.960 --> 00:12:21.450
But Stopwatch is awesome.

00:12:21.450 --> 00:12:23.530
It's really just a very
easy way to do timing.

00:12:23.530 --> 00:12:27.400
So you create a stopwatch, you
call start, you call stop.

00:12:27.400 --> 00:12:29.590
And it has this really nice
two-string method that you

00:12:29.590 --> 00:12:30.540
just give it.

00:12:30.540 --> 00:12:32.590
There is actually a default of
four, but you can give it the

00:12:32.590 --> 00:12:34.280
number of significant digits.

00:12:34.280 --> 00:12:37.150
And it'll print it in an
appropriate unit based on how

00:12:37.150 --> 00:12:37.680
long it took.

00:12:37.680 --> 00:12:41.370
So if it was in millisecond
range, it'll say 10.56

00:12:41.370 --> 00:12:42.710
milliseconds or whatever.

00:12:42.710 --> 00:12:43.800
If it was in seconds,
it'll print in that.

00:12:43.800 --> 00:12:45.940
If it's in minutes, it'll
print in that.

00:12:45.940 --> 00:12:47.695
You don't have to write that
code that I'm sure all of you

00:12:47.695 --> 00:12:51.050
have written, where you take a
timer and you're like, OK, is

00:12:51.050 --> 00:12:52.515
it less than 1,000?

00:12:52.515 --> 00:12:54.660
And you try and figure out
what it fits into.

00:12:54.660 --> 00:12:56.900
That's all taken care
of for you.

00:12:56.900 --> 00:13:00.370
And I put it into this metrics
map that you saw on the

00:13:00.370 --> 00:13:00.900
right-hand side.

00:13:00.900 --> 00:13:01.690
It had all those metrics.

00:13:01.690 --> 00:13:04.050
And I'm just printing that out
through the side channel

00:13:04.050 --> 00:13:07.550
there, just to make my life
a little bit easier.

00:13:07.550 --> 00:13:10.740
If you were doing this in more
of a real application, you'd

00:13:10.740 --> 00:13:14.060
probably log this somewhere that
you can then analyze it

00:13:14.060 --> 00:13:18.210
in more detail later, or use
something like analytics.

00:13:18.210 --> 00:13:19.340
OK.

00:13:19.340 --> 00:13:20.730
So that's latency.

00:13:20.730 --> 00:13:23.150
Bandwidth, as I mentioned,
I'm only looking at

00:13:23.150 --> 00:13:24.080
the response sizes.

00:13:24.080 --> 00:13:27.330
And in fact, I'm only looking at
the response bodies just to

00:13:27.330 --> 00:13:29.590
make things much simpler.

00:13:29.590 --> 00:13:33.760
And part of the reason for this
is, the application is a

00:13:33.760 --> 00:13:37.590
App Engine app that's talking
to Google APIs.

00:13:37.590 --> 00:13:40.320
So there's nowhere in
that interaction for

00:13:40.320 --> 00:13:42.940
me to insert myself.

00:13:42.940 --> 00:13:45.920
You could run it locally and use
something like Wireshark

00:13:45.920 --> 00:13:50.850
in the dev server mode and try
and get it, but I wanted the

00:13:50.850 --> 00:13:53.290
what's going on in the real
world when it's actually

00:13:53.290 --> 00:13:54.320
deployed situation.

00:13:54.320 --> 00:13:56.296
So I'm just using the
content length from

00:13:56.296 --> 00:13:57.500
the response headers.

00:13:57.500 --> 00:13:59.390
So really I'm trusting
Google to give me the

00:13:59.390 --> 00:14:01.600
right content length.

00:14:01.600 --> 00:14:04.620
And since I was the one that set
that content length, I'm

00:14:04.620 --> 00:14:05.800
trusting myself.

00:14:05.800 --> 00:14:08.290
So you do what you've
got to do.

00:14:08.290 --> 00:14:11.290
But really it's just we're
tracking response length.

00:14:11.290 --> 00:14:12.210
Not too exciting.

00:14:12.210 --> 00:14:15.070
So let's look at some
numbers from the

00:14:15.070 --> 00:14:17.210
first draft of my code.

00:14:17.210 --> 00:14:21.020
So we have a load that is a
read from Drive and a read

00:14:21.020 --> 00:14:21.930
from Tasks.

00:14:21.930 --> 00:14:25.350
You saw on the demo, on the
left-hand side it shows all

00:14:25.350 --> 00:14:26.690
the TaskLists.

00:14:26.690 --> 00:14:28.040
That's that read.

00:14:28.040 --> 00:14:30.650
We also have the read of
the current content.

00:14:30.650 --> 00:14:32.610
And again, that's both
phases of that.

00:14:32.610 --> 00:14:35.580
That's reading the metadata
and reading the content.

00:14:35.580 --> 00:14:36.860
Save is similar.

00:14:36.860 --> 00:14:39.290
It's a read from Drive, in this
case only the metadata,

00:14:39.290 --> 00:14:40.860
so it's shorter.

00:14:40.860 --> 00:14:44.190
And a write to Drive of both
metadata and the content.

00:14:44.190 --> 00:14:49.870
And then Tasks and Events are
similarly again read, write.

00:14:49.870 --> 00:14:53.820
So we read all the current
Tasks, we write them all to

00:14:53.820 --> 00:14:56.077
the server, we read all the
current Events, we write them

00:14:56.077 --> 00:14:56.490
all to the server.

00:14:56.490 --> 00:14:58.420
It takes a lot of time.

00:14:58.420 --> 00:15:01.760
And I should mention that in
all of these cases, I'm

00:15:01.760 --> 00:15:03.550
looking at a list of 20 items.

00:15:03.550 --> 00:15:06.850
So it's important when
you do profiling to

00:15:06.850 --> 00:15:07.880
compare apples to apples.

00:15:07.880 --> 00:15:10.100
You actually want to make sure
you control for things.

00:15:10.100 --> 00:15:13.590
So you don't want different
sized lists each time.

00:15:13.590 --> 00:15:15.460
You want to actually make sure
you're doing the same thing,

00:15:15.460 --> 00:15:16.680
and in fact the same actions.

00:15:16.680 --> 00:15:20.270
So in this case, I do five
inserts, five updates, and

00:15:20.270 --> 00:15:25.440
five deletes, in both cases, of
the Tasks and Events, just

00:15:25.440 --> 00:15:28.850
to make sure things
are consistent.

00:15:28.850 --> 00:15:29.120
All right.

00:15:29.120 --> 00:15:30.580
So that was latency.

00:15:30.580 --> 00:15:32.140
What about bandwidth?

00:15:32.140 --> 00:15:34.930
This is, again, response
bandwidth.

00:15:34.930 --> 00:15:38.930
And they're basically the exact
same actions, or service

00:15:38.930 --> 00:15:39.810
calls, you saw.

00:15:39.810 --> 00:15:44.010
So there's reads from the
different services and writes.

00:15:44.010 --> 00:15:45.050
Again, not very interesting.

00:15:45.050 --> 00:15:47.340
But you see that events,
for example,

00:15:47.340 --> 00:15:49.570
take up a lot of space.

00:15:49.570 --> 00:15:51.070
Maybe we should focus on that.

00:15:51.070 --> 00:15:54.270
You can take this information
and try and figure out what to

00:15:54.270 --> 00:15:56.150
do with it.

00:15:56.150 --> 00:15:56.450
All right.

00:15:56.450 --> 00:16:01.420
So that's all the prequel, the
background information.

00:16:01.420 --> 00:16:02.710
Now let's actually
make things fast.

00:16:02.710 --> 00:16:06.770
So the zero thing you should
do, because you should have

00:16:06.770 --> 00:16:08.952
done this way before you even
started looking at any of

00:16:08.952 --> 00:16:11.380
this, is turn on GZip.

00:16:11.380 --> 00:16:13.570
If you don't have GZip,
you're wasting a

00:16:13.570 --> 00:16:16.020
huge amount of bandwidth.

00:16:16.020 --> 00:16:18.980
And in fact, if you're on a
mobile device or whatever,

00:16:18.980 --> 00:16:22.030
you're actually also wasting
latency because those devices

00:16:22.030 --> 00:16:24.620
maybe aren't fast enough
that the bandwidth

00:16:24.620 --> 00:16:25.440
doesn't really matter.

00:16:25.440 --> 00:16:30.300
So you should always both get
GZipped responses and send you

00:16:30.300 --> 00:16:31.490
GZipped requests.

00:16:31.490 --> 00:16:33.520
The easiest way to do this
is just to use our Client

00:16:33.520 --> 00:16:35.810
Libraries, which all do
this automatically.

00:16:35.810 --> 00:16:39.140
If you want to do it manually,
it's sometimes a little bit

00:16:39.140 --> 00:16:41.720
more of a pain because you have
to do things like, in the

00:16:41.720 --> 00:16:45.190
user agent, put GZip in there
and fiddle with things to make

00:16:45.190 --> 00:16:47.680
sure you're actually getting
a GZipped response.

00:16:47.680 --> 00:16:50.540
It's not too bad, but it's much
easier just to say, why

00:16:50.540 --> 00:16:52.320
not just use our Client
Libraries?

00:16:52.320 --> 00:16:55.700
And just as a quick example, if
you look at our discovery

00:16:55.700 --> 00:17:01.730
API, the plain, unGZipped
version of it is about 24 kB.

00:17:01.730 --> 00:17:04.380
GZipped, it's only
11% of that size.

00:17:04.380 --> 00:17:07.660
It's down to about 2.5 kB.

00:17:07.660 --> 00:17:11.589
So it saves you a lot.

00:17:11.589 --> 00:17:13.369
All right.

00:17:13.369 --> 00:17:17.650
And that of course has almost
nothing to do with our APIs

00:17:17.650 --> 00:17:20.690
except that our Client Libraries
do it for you.

00:17:20.690 --> 00:17:22.859
What about things we can
actually take advantage of in

00:17:22.859 --> 00:17:23.829
the APIs themselves?

00:17:23.829 --> 00:17:25.650
So the first one we're going to
talk about is something we

00:17:25.650 --> 00:17:27.410
call partial responses.

00:17:27.410 --> 00:17:30.730
Who here is familiar with
partial responses?

00:17:30.730 --> 00:17:31.800
Some of you, but not that many?

00:17:31.800 --> 00:17:32.470
OK.

00:17:32.470 --> 00:17:33.060
Good.

00:17:33.060 --> 00:17:34.880
So you all should use this.

00:17:34.880 --> 00:17:36.440
It's pretty cool.

00:17:36.440 --> 00:17:39.610
The goal here is again to
save bandwidth, mostly.

00:17:39.610 --> 00:17:42.190
And as a side effect, get a
latency benefit because the

00:17:42.190 --> 00:17:43.910
server's sending less stuff,
so we have less things to

00:17:43.910 --> 00:17:46.870
parse, et cetera, et cetera.

00:17:46.870 --> 00:17:49.500
The way you do this is you
request only the portion of

00:17:49.500 --> 00:17:51.090
the resource you care about.

00:17:51.090 --> 00:17:54.790
So for example, if you have a
really big resource like that

00:17:54.790 --> 00:17:57.680
discovery document, and you
only care about one or two

00:17:57.680 --> 00:18:01.390
fields like in this example, I
only care about the IDs of the

00:18:01.390 --> 00:18:05.920
APIs, getting all that other
stuff sent to you is just a

00:18:05.920 --> 00:18:06.850
horrible waste of time.

00:18:06.850 --> 00:18:10.340
So we have this query parameter
that you can add to

00:18:10.340 --> 00:18:12.620
any of the discoverable APIs.

00:18:12.620 --> 00:18:15.770
You just set the field's query
parameter to what you care

00:18:15.770 --> 00:18:18.170
about, and it gives you
back only those parts.

00:18:18.170 --> 00:18:22.590
And in this case, it gave us
back 6% of the total size.

00:18:22.590 --> 00:18:26.410
And I'm using the non-GZipped
numbers here.

00:18:26.410 --> 00:18:29.140
Under GZipped things would be
a little bit different.

00:18:29.140 --> 00:18:31.630
It might save a little
bit more space

00:18:31.630 --> 00:18:34.320
on the initial version.

00:18:34.320 --> 00:18:35.510
So maybe it'd be
more like 10%.

00:18:35.510 --> 00:18:37.840
But it's still a huge savings.

00:18:37.840 --> 00:18:42.020
So just as a quick way to show
you how you can do this, I'm

00:18:42.020 --> 00:18:43.800
going to use the APIs Explorer,
which hopefully you

00:18:43.800 --> 00:18:46.240
guys have been hearing
a lot about.

00:18:46.240 --> 00:18:48.130
So let's go back to my
other thing here.

00:18:48.130 --> 00:18:51.950
And here is the APIs Explorer
that I already have loaded up.

00:18:51.950 --> 00:18:55.310
I'm going to look at the book's
API, and I'm going to

00:18:55.310 --> 00:18:58.830
query for a search.

00:18:58.830 --> 00:19:00.770
So I'm going to do a search
for some books.

00:19:00.770 --> 00:19:03.876
So anyone have book
recommendations?

00:19:03.876 --> 00:19:06.280
AUDIENCE: Ender's Game.

00:19:06.280 --> 00:19:08.590
SVEN MAWSON: Ender's Game,
one of my favorites.

00:19:08.590 --> 00:19:09.360
Ender's Game.

00:19:09.360 --> 00:19:09.660
OK.

00:19:09.660 --> 00:19:12.080
So if I go to Ender's Game,
there's a whole bunch of stuff

00:19:12.080 --> 00:19:12.640
I can put in here.

00:19:12.640 --> 00:19:16.530
But when I execute, it gives
me back, hopefully you guys

00:19:16.530 --> 00:19:18.270
can see this.

00:19:18.270 --> 00:19:21.660
It gives back an object that
tells you how many items.

00:19:21.660 --> 00:19:23.440
606, that's quite a lot.

00:19:23.440 --> 00:19:25.440
And then an array of all
the items with a

00:19:25.440 --> 00:19:27.000
whole bunch of fields.

00:19:27.000 --> 00:19:29.890
It's got the ID, it's got the
kind, the [? e-tag, ?]

00:19:29.890 --> 00:19:32.380
the self link.

00:19:32.380 --> 00:19:35.830
Information about the volume,
the publisher, all kinds of

00:19:35.830 --> 00:19:40.150
stuff, the description, ISBN
numbers, how many pages, all

00:19:40.150 --> 00:19:40.730
this stuff.

00:19:40.730 --> 00:19:42.060
I don't care about
any of that.

00:19:42.060 --> 00:19:45.730
I just want to know the
title and description.

00:19:45.730 --> 00:19:49.890
So if I just want that
information, I can go up here

00:19:49.890 --> 00:19:51.470
and put in the fields thing.

00:19:51.470 --> 00:19:53.470
And you could type this manually
if you want, but one

00:19:53.470 --> 00:19:55.550
of the cool things about it API
Explorer is it actually

00:19:55.550 --> 00:20:01.060
lets you edit this using
a tree-based system.

00:20:01.060 --> 00:20:05.280
So I said I wanted just, and
look at all these fields that

00:20:05.280 --> 00:20:06.220
I'm going to ignore.

00:20:06.220 --> 00:20:08.010
This is pretty fun.

00:20:08.010 --> 00:20:12.950
Well, let's get the author,
let's get the description, and

00:20:12.950 --> 00:20:14.930
let's get the title.

00:20:14.930 --> 00:20:16.620
So I do that.

00:20:16.620 --> 00:20:19.600
It creates this nice string
for me that has all the

00:20:19.600 --> 00:20:23.110
fields, and then if I execute
that, the result

00:20:23.110 --> 00:20:24.620
is much, much smaller.

00:20:24.620 --> 00:20:27.830
So you just have just the things
you care about, the

00:20:27.830 --> 00:20:29.800
title, authors, the
description.

00:20:29.800 --> 00:20:33.670
Much, much smaller request
makes things nice.

00:20:37.050 --> 00:20:40.320
So now I'm going to show you how
you actually add that to

00:20:40.320 --> 00:20:41.480
your Java code here.

00:20:41.480 --> 00:20:45.770
And this is very similar for
other API client libraries,

00:20:45.770 --> 00:20:50.330
but in the Java Client Library,
remember that request

00:20:50.330 --> 00:20:51.650
object I was talking about?

00:20:51.650 --> 00:20:53.780
Well, every single one of those
request objects has a

00:20:53.780 --> 00:20:55.100
set fields method.

00:20:55.100 --> 00:20:59.080
So you can just call set fields
on that request object

00:20:59.080 --> 00:21:01.660
before executing it, and
it'll do this for you.

00:21:01.660 --> 00:21:05.860
So in this case, for Drive, I
want the title, the download

00:21:05.860 --> 00:21:07.570
URL, that was the one to figure
out how to get the

00:21:07.570 --> 00:21:12.200
media, and then I want to know
what access the user has so if

00:21:12.200 --> 00:21:15.680
I shared it with someone and
only give them view access,

00:21:15.680 --> 00:21:17.490
when I get back into my
application I don't want to

00:21:17.490 --> 00:21:18.340
let them edit it, right?

00:21:18.340 --> 00:21:20.080
I want them just to be
able to view it.

00:21:20.080 --> 00:21:23.790
So I get that back, and
then execute it.

00:21:23.790 --> 00:21:27.040
For Tasks, it's very similar.

00:21:27.040 --> 00:21:29.440
When I inserted it, the only
thing I needed back from the

00:21:29.440 --> 00:21:32.780
insert was the ID, so why
not just get that?

00:21:32.780 --> 00:21:34.030
Whoa, sorry about that.

00:21:37.910 --> 00:21:41.330
I shouldn't have tried and
scrolled with the two fingers.

00:21:41.330 --> 00:21:42.570
All right.

00:21:42.570 --> 00:21:45.160
And again, you can see down here
the same kind of thing.

00:21:45.160 --> 00:21:47.720
I just want the IDs back to
store them for syncing, so

00:21:47.720 --> 00:21:49.670
much nicer.

00:21:49.670 --> 00:21:52.240
With Calendar, this is actually
a little bit more

00:21:52.240 --> 00:21:53.830
interesting situation.

00:21:53.830 --> 00:21:58.260
I'd like to be able to set the
fields up here when I am

00:21:58.260 --> 00:22:00.610
looking up the events so
I can get only the

00:22:00.610 --> 00:22:01.720
fields I care about.

00:22:01.720 --> 00:22:04.080
But the problem is, I'm
going to update these.

00:22:04.080 --> 00:22:06.840
And if I only got the fields I
cared about, that would mean I

00:22:06.840 --> 00:22:09.050
would be in effect deleting
the things I didn't care

00:22:09.050 --> 00:22:10.150
about, which isn't
what I want.

00:22:10.150 --> 00:22:12.950
So I actually have to
get everything.

00:22:12.950 --> 00:22:16.730
So I can't do a fields
call here.

00:22:16.730 --> 00:22:18.400
Instead, I get the
whole object.

00:22:18.400 --> 00:22:21.550
But when I actually update
them, at least I can only

00:22:21.550 --> 00:22:22.380
request the ID.

00:22:22.380 --> 00:22:25.200
I don't have to request
everything.

00:22:25.200 --> 00:22:27.340
So what does this do for us?

00:22:27.340 --> 00:22:29.920
Well, latency-wise,
not a whole lot.

00:22:29.920 --> 00:22:33.110
Actually there's a little noise
in here, so basically

00:22:33.110 --> 00:22:35.670
it's the same thing.

00:22:35.670 --> 00:22:37.190
Latency didn't really affect.

00:22:37.190 --> 00:22:40.140
And part of the reason for this
is, this is App Engine

00:22:40.140 --> 00:22:44.470
making a call to a Google API.

00:22:44.470 --> 00:22:48.580
So from App Engine in Google's
cloud to an API in Google's

00:22:48.580 --> 00:22:51.100
cloud, we have quite
a lot of bandwidth.

00:22:51.100 --> 00:22:54.380
So it doesn't actually make much
of a latency difference.

00:22:54.380 --> 00:22:57.230
If I had an example on, say, a
mobile application, this might

00:22:57.230 --> 00:22:59.230
actually be a bigger
difference here.

00:22:59.230 --> 00:23:01.490
But where you can really, really
see the difference is

00:23:01.490 --> 00:23:03.510
when we look at the
bandwidth used.

00:23:03.510 --> 00:23:07.420
So load didn't reduce that much,
because I actually have

00:23:07.420 --> 00:23:10.600
to get back that whole object
from Drive, the media.

00:23:10.600 --> 00:23:14.790
But on save, I used to get back
this huge document of the

00:23:14.790 --> 00:23:16.540
result of saving, which
I didn't care about.

00:23:16.540 --> 00:23:17.440
I just wanted the ID.

00:23:17.440 --> 00:23:20.220
So just getting the ID cuts
that way, way down.

00:23:20.220 --> 00:23:25.290
Similarly with Tasks and with
the Events, that initial read,

00:23:25.290 --> 00:23:27.400
unfortunately I can't
do anything about.

00:23:27.400 --> 00:23:28.590
I have to get the
whole object.

00:23:28.590 --> 00:23:32.520
But then when I rate it, I can
basically ignore the result

00:23:32.520 --> 00:23:33.620
and save a lot there.

00:23:33.620 --> 00:23:39.160
So cut it by maybe a third
in both of those cases.

00:23:39.160 --> 00:23:39.400
OK.

00:23:39.400 --> 00:23:43.020
So I keep mentioning that on
these update cases, these sync

00:23:43.020 --> 00:23:45.310
cases, when I read and then
write, I have to read the

00:23:45.310 --> 00:23:46.570
whole object.

00:23:46.570 --> 00:23:48.360
Well, not so fast.

00:23:48.360 --> 00:23:49.550
We actually have a solution
for that.

00:23:49.550 --> 00:23:52.040
So we call this patch.

00:23:52.040 --> 00:23:54.460
So rather than doing a PUT where
you update the entire

00:23:54.460 --> 00:23:56.150
resource, you do a
PATCH of just the

00:23:56.150 --> 00:23:57.400
things you care about.

00:23:57.400 --> 00:23:58.310
And this does two things.

00:23:58.310 --> 00:24:01.440
One, it reduces the upstream
bandwidth that you're sending

00:24:01.440 --> 00:24:02.610
to the server.

00:24:02.610 --> 00:24:04.970
And two, it actually lets you,
when you're doing that read

00:24:04.970 --> 00:24:07.010
modify write cycle, only read
the things you want.

00:24:07.010 --> 00:24:10.200
So it actually reduces your
read bandwidth as well.

00:24:10.200 --> 00:24:12.510
So it saves on both sides.

00:24:12.510 --> 00:24:15.120
And again, we're saving
bandwidth, which we're

00:24:15.120 --> 00:24:16.220
hopefully saving latency.

00:24:16.220 --> 00:24:21.190
Although in the App Engine to
Google APIs case, not so much.

00:24:21.190 --> 00:24:24.960
So the only difference actually
for Google servers is

00:24:24.960 --> 00:24:28.370
you send a PATCH verb
instead of PUT.

00:24:28.370 --> 00:24:31.560
And in the client libraries,
this will be a PATCH method

00:24:31.560 --> 00:24:34.410
instead of an update method, for
the ones that support it.

00:24:34.410 --> 00:24:36.740
So I've just put in a couple
examples here of what this

00:24:36.740 --> 00:24:40.080
looks like from an
HTTP perspective.

00:24:40.080 --> 00:24:43.120
If I was updating a Task,
normally I'd have the entire

00:24:43.120 --> 00:24:46.240
thing, even though all I'm doing
is changing the title.

00:24:46.240 --> 00:24:50.870
If I use PATCH, though, I can
just send that little bit.

00:24:50.870 --> 00:24:53.920
And it's only 8% of the size, so
actually it lets me cut out

00:24:53.920 --> 00:24:56.750
quite a lot.

00:24:56.750 --> 00:24:57.910
So how do we actually do this?

00:24:57.910 --> 00:25:02.460
Well, it's again very,
very simple.

00:25:02.460 --> 00:25:06.820
In this case, this is imagining
an update of an

00:25:06.820 --> 00:25:08.130
existing object.

00:25:08.130 --> 00:25:11.350
And I kept mentioning the read
modify write cycle, but with

00:25:11.350 --> 00:25:13.770
PATCH, you can actually skip the
read, if you know what you

00:25:13.770 --> 00:25:16.060
want to change, and just go
straight to the update.

00:25:16.060 --> 00:25:17.750
So this is what I'm
doing here.

00:25:17.750 --> 00:25:20.900
Actually, instead of reading
the TaskList to change the

00:25:20.900 --> 00:25:22.960
name, I just change the name.

00:25:22.960 --> 00:25:24.230
Because I don't care what
it is right now.

00:25:24.230 --> 00:25:25.270
I'm just going to
overwrite it.

00:25:25.270 --> 00:25:29.210
So I create a new one
called a Patch verb.

00:25:29.210 --> 00:25:31.430
It gives me back that
request object.

00:25:31.430 --> 00:25:34.340
And again, I can set fields on
it, just like I could before.

00:25:34.340 --> 00:25:38.270
Execute that, no problem.

00:25:38.270 --> 00:25:41.960
And in Calendar now,
I'm pretty excited.

00:25:41.960 --> 00:25:44.910
I can set that fields thing I
couldn't set before, so I set

00:25:44.910 --> 00:25:48.440
the fields I care about,
and then I call PATCH

00:25:48.440 --> 00:25:49.400
and submit an update.

00:25:49.400 --> 00:25:52.580
And everything else
is just magic.

00:25:52.580 --> 00:25:52.940
OK.

00:25:52.940 --> 00:25:54.760
So does this help our latency?

00:25:54.760 --> 00:25:56.030
Unfortunately, not so much.

00:25:56.030 --> 00:25:58.670
We're in App Engine.

00:25:58.670 --> 00:26:00.250
Bandwidth isn't helping.

00:26:00.250 --> 00:26:03.740
But it does cut bandwidth
in those last two cases.

00:26:03.740 --> 00:26:06.950
So when we were reading all
those Tasks and getting all

00:26:06.950 --> 00:26:08.960
that extra information,
we can cut that out.

00:26:08.960 --> 00:26:11.120
And even more so with Events.

00:26:11.120 --> 00:26:13.540
Calendar is sending us all kinds
of stuff we don't care

00:26:13.540 --> 00:26:14.180
anything about.

00:26:14.180 --> 00:26:17.350
So we just throw that away, and
in fact we actually ask

00:26:17.350 --> 00:26:19.860
the server to throw
it away for us.

00:26:19.860 --> 00:26:24.150
Save some time so we get
quite a bit smaller.

00:26:24.150 --> 00:26:27.150
It's actually less than
half the size.

00:26:27.150 --> 00:26:30.550
So save a lot of bandwidth
there.

00:26:30.550 --> 00:26:30.910
All right.

00:26:30.910 --> 00:26:33.340
So that was PATCH.

00:26:33.340 --> 00:26:36.090
The last thing I'm going to talk
about is actually doing

00:26:36.090 --> 00:26:37.370
something about this
latency problem.

00:26:37.370 --> 00:26:38.540
So we haven't really
been helping our

00:26:38.540 --> 00:26:40.720
latency with all these.

00:26:40.720 --> 00:26:44.160
One of the things my app does
that's probably not really

00:26:44.160 --> 00:26:46.860
smart is, it's executing all
these things in serial.

00:26:46.860 --> 00:26:53.200
So for example, if I'm updating
15 Calendar events,

00:26:53.200 --> 00:26:57.520
I'm updating 15 Tasks, I'm
updating a Drive metadata, I'm

00:26:57.520 --> 00:26:58.880
doing all these things,
and I'm actually

00:26:58.880 --> 00:26:59.550
doing them in serial.

00:26:59.550 --> 00:27:02.160
So I'm executing one, waiting
for it to return, executing

00:27:02.160 --> 00:27:04.090
the other, waiting
for it to return.

00:27:04.090 --> 00:27:06.070
Not the smartest way to write
and app, but actually getting

00:27:06.070 --> 00:27:07.130
around this is kind of a pain.

00:27:07.130 --> 00:27:09.640
You have to spin up some
threads, make everything

00:27:09.640 --> 00:27:12.250
asynchronous, maybe start
throwing in some futures.

00:27:12.250 --> 00:27:15.670
You have to do a lot of work to
make your life easier, to

00:27:15.670 --> 00:27:17.350
make your life faster,
I should say.

00:27:17.350 --> 00:27:18.990
And instead, we'll
do that for you.

00:27:18.990 --> 00:27:23.900
So we have a feature called
Batch on all of our APIs that

00:27:23.900 --> 00:27:26.820
lets you send all of your
requests at once, and we'll

00:27:26.820 --> 00:27:29.460
execute them for you and
send them back to you.

00:27:29.460 --> 00:27:33.460
And in fact, you can actually
send these on

00:27:33.460 --> 00:27:34.740
multiple APIs at once.

00:27:34.740 --> 00:27:37.690
So you can actually send that
request to Drive, to Calendar,

00:27:37.690 --> 00:27:40.090
and Tasks all at the same
time in a single Batch,

00:27:40.090 --> 00:27:41.500
and it'll just work.

00:27:41.500 --> 00:27:43.000
It's very cool.

00:27:43.000 --> 00:27:46.020
And the way this is done at
the HTTP level is through

00:27:46.020 --> 00:27:46.840
multipart/mixed.

00:27:46.840 --> 00:27:49.350
So you have a single
HTTP request.

00:27:49.350 --> 00:27:50.590
It's a multipart.

00:27:50.590 --> 00:27:53.530
Each of those parts is actually
another HTTP request.

00:27:53.530 --> 00:27:58.190
So you just put them in a big
payload and send them off.

00:27:58.190 --> 00:27:59.790
The Client Library hides
all this from you, so

00:27:59.790 --> 00:28:00.520
don't worry about it.

00:28:00.520 --> 00:28:03.000
But that's what actually
happens on the wire.

00:28:03.000 --> 00:28:05.010
The server does the
parallelization for you, so

00:28:05.010 --> 00:28:07.570
you don't have to deal with
threads and asynchronous

00:28:07.570 --> 00:28:08.310
requests and all that.

00:28:08.310 --> 00:28:09.560
You just send it up.

00:28:13.510 --> 00:28:15.770
There is a slight bandwidth
costs for this because of that

00:28:15.770 --> 00:28:16.690
envelope I was talking about.

00:28:16.690 --> 00:28:20.930
So you have this big multipart
request, you have that outer

00:28:20.930 --> 00:28:24.270
multipart envelope for it, and
then you also have a little

00:28:24.270 --> 00:28:27.590
envelope around each
object for wrapping

00:28:27.590 --> 00:28:29.820
it as an HTTP request.

00:28:29.820 --> 00:28:31.370
Very slight cost, and
you'll see that

00:28:31.370 --> 00:28:33.120
actually in the numbers.

00:28:33.120 --> 00:28:35.550
The latency from this is
actually pretty variable.

00:28:35.550 --> 00:28:37.840
It depends on what you
were doing before.

00:28:37.840 --> 00:28:41.150
So if you were doing what I was
doing, and just executing

00:28:41.150 --> 00:28:43.680
these in serial, it's going
to be a huge win for you.

00:28:43.680 --> 00:28:46.360
If you already were doing all
this parallelization, it may

00:28:46.360 --> 00:28:47.400
or may not be a win for you.

00:28:47.400 --> 00:28:49.720
Actually it depends
on the API.

00:28:49.720 --> 00:28:53.670
Some APIs, for example Task, as
you'll see, actually locks

00:28:53.670 --> 00:28:54.400
its resources.

00:28:54.400 --> 00:28:57.590
So if you're editing a TaskList,
you can only execute

00:28:57.590 --> 00:29:01.490
one operation on that at once,
and it actually locks it.

00:29:01.490 --> 00:29:03.950
So if you tried to do them in
parallel, in fact it would be

00:29:03.950 --> 00:29:05.550
serial and you just
wouldn't see that.

00:29:05.550 --> 00:29:06.950
It'd be serial on the server.

00:29:06.950 --> 00:29:11.480
One would have to wait for the
lock to free to do it.

00:29:11.480 --> 00:29:15.060
So if the API actually supports
making that faster,

00:29:15.060 --> 00:29:18.050
which in fact Task doesn't but
Calendar does, which you'll

00:29:18.050 --> 00:29:20.560
see, it can be a big win.

00:29:20.560 --> 00:29:22.740
So we do recommend using it,
even if you've already done

00:29:22.740 --> 00:29:23.400
all the hard work of

00:29:23.400 --> 00:29:25.660
parallelization on your client.

00:29:25.660 --> 00:29:28.050
It's probably better to
do it on the server.

00:29:28.050 --> 00:29:28.330
OK.

00:29:28.330 --> 00:29:29.690
So how do you actually
do this?

00:29:29.690 --> 00:29:32.190
Again, it's pretty simple.

00:29:32.190 --> 00:29:35.330
And you may have seen this
in some other talks.

00:29:35.330 --> 00:29:38.330
Rather than executing each of
those requests objects that

00:29:38.330 --> 00:29:40.920
we've been creating, you
add them to a Batch.

00:29:40.920 --> 00:29:44.490
So the way this works, you
create an outer Batch.

00:29:44.490 --> 00:29:46.300
In this case, I'm using the
Drive service to do it.

00:29:46.300 --> 00:29:47.940
It actually doesn't matter
what service you use.

00:29:47.940 --> 00:29:49.890
They're all the same object.

00:29:49.890 --> 00:29:51.935
So we just call
driveService.batch, because

00:29:51.935 --> 00:29:54.350
it's a backup Batch object,
and then we queue it up.

00:29:54.350 --> 00:29:59.300
So we have this get file we
call queue, we give it the

00:29:59.300 --> 00:30:02.800
Batch to add itself to, and
we give it a call back.

00:30:02.800 --> 00:30:07.420
And to make my life a little
easier when I built this, one

00:30:07.420 --> 00:30:09.240
of the things you may or may not
have seen in that simple

00:30:09.240 --> 00:30:11.530
application on the bottom
left, here, I'll

00:30:11.530 --> 00:30:13.910
actually show you it.

00:30:13.910 --> 00:30:17.700
On the bottom left of it, you
can actually choose what

00:30:17.700 --> 00:30:19.540
features to enable.

00:30:19.540 --> 00:30:21.640
In a real application, of course
you'd always have all

00:30:21.640 --> 00:30:23.540
of these on because I'm
teaching about how

00:30:23.540 --> 00:30:24.530
awesome they are.

00:30:24.530 --> 00:30:28.300
But to make it easier for me to
actually test things, I had

00:30:28.300 --> 00:30:30.130
to be able to turn these things
on and off, which

00:30:30.130 --> 00:30:32.160
complicated the code
quite a bit.

00:30:32.160 --> 00:30:36.140
One way I uncomplicated that
for myself is creating this

00:30:36.140 --> 00:30:39.780
callback, and I'll show you
a slide with that next.

00:30:39.780 --> 00:30:40.810
But then once you
have all these

00:30:40.810 --> 00:30:42.290
queued, it's really simple.

00:30:42.290 --> 00:30:44.910
You just call execute, and
that execute call is

00:30:44.910 --> 00:30:46.920
synchronous, and will
execute it.

00:30:46.920 --> 00:30:51.810
And it'll actually, that call
will not return until all of

00:30:51.810 --> 00:30:52.863
the callbacks have
been executed.

00:30:52.863 --> 00:30:56.190
So you execute it, and all
the callbacks happen.

00:30:56.190 --> 00:30:57.530
So the way I made
my life easier

00:30:57.530 --> 00:30:58.940
here is Future Callback.

00:31:01.830 --> 00:31:04.830
I'm actually using again
two features out

00:31:04.830 --> 00:31:07.490
of the Guava library.

00:31:07.490 --> 00:31:11.240
So there's something called
Settable Future, that does

00:31:11.240 --> 00:31:13.995
have my name on it, and also
Listenable Future, which I

00:31:13.995 --> 00:31:15.530
also wrote.

00:31:15.530 --> 00:31:18.630
So a little plug for
myself there.

00:31:18.630 --> 00:31:19.950
Bit I use what I know.

00:31:19.950 --> 00:31:20.950
So I made these things.

00:31:20.950 --> 00:31:23.700
You don't actually have to
get this complicated.

00:31:23.700 --> 00:31:27.100
The actual callback methods
are very simple.

00:31:27.100 --> 00:31:28.780
There's an onSuccess
and onFailure.

00:31:28.780 --> 00:31:32.380
So you could do the code here
that deals with it.

00:31:32.380 --> 00:31:36.610
You could use, for example,
atomic reference or something,

00:31:36.610 --> 00:31:39.870
or even just a ray or a volatile
field or whatever

00:31:39.870 --> 00:31:41.720
just to pass the data back.

00:31:41.720 --> 00:31:44.780
And then onFailure, I'm doing
the really stupid thing of

00:31:44.780 --> 00:31:46.720
just throwing a runtime
exception.

00:31:46.720 --> 00:31:48.480
You'll probably want to handle
these a little smarter.

00:31:48.480 --> 00:31:51.360
Maybe if there's multiple errors
in the Batch, handle

00:31:51.360 --> 00:31:53.990
them in a somewhat intelligent
way, and maybe display them

00:31:53.990 --> 00:31:54.800
all to the user.

00:31:54.800 --> 00:31:58.320
I just throw the first one
because it's a demo.

00:31:58.320 --> 00:32:03.970
So that was a quick segue on
futures, but let's get back to

00:32:03.970 --> 00:32:04.640
the actual code.

00:32:04.640 --> 00:32:07.240
So again, with Tasks,
very simple.

00:32:07.240 --> 00:32:08.960
We just queue things
in a Batch.

00:32:08.960 --> 00:32:10.720
And here, I'm using that Batch
I created earlier.

00:32:10.720 --> 00:32:11.730
I don't need to create
a new one.

00:32:11.730 --> 00:32:14.410
I can actually queue
them all up.

00:32:14.410 --> 00:32:18.050
You just cue up that, and
then we queue up these.

00:32:18.050 --> 00:32:22.810
And I'm actually not showing
here that in fact you needed

00:32:22.810 --> 00:32:23.800
to execute this.

00:32:23.800 --> 00:32:26.920
We'll see it on the next one.

00:32:26.920 --> 00:32:28.390
Yeah, this one has
the example.

00:32:28.390 --> 00:32:33.840
So if you're doing something
like you're inserting a new

00:32:33.840 --> 00:32:37.210
TaskList, and then you need that
ID to do more work, well

00:32:37.210 --> 00:32:38.730
you can't do those
all in one Batch.

00:32:38.730 --> 00:32:42.380
So you have to do a first phase
where you execute that

00:32:42.380 --> 00:32:45.200
first thing to get back an ID,
you read that, and then you

00:32:45.200 --> 00:32:46.940
use that to queue up
the next ones.

00:32:46.940 --> 00:32:49.760
So you have to do two phases
instead of being able to do it

00:32:49.760 --> 00:32:52.400
all in one.

00:32:52.400 --> 00:32:53.950
There's not really a way
around that without a

00:32:53.950 --> 00:32:58.420
complicated forwarding language
that we don't have.

00:32:58.420 --> 00:33:01.070
But the way you would do this
is, you just queue up the

00:33:01.070 --> 00:33:04.070
first set, execute it,
create a new Batch,

00:33:04.070 --> 00:33:04.880
queue up the next set.

00:33:04.880 --> 00:33:07.430
Pretty simple.

00:33:07.430 --> 00:33:08.310
So how about this?

00:33:08.310 --> 00:33:08.970
Did this help us?

00:33:08.970 --> 00:33:09.920
Well, yes.

00:33:09.920 --> 00:33:12.110
It actually did.

00:33:12.110 --> 00:33:15.340
And mostly it helped
with Calendar.

00:33:15.340 --> 00:33:20.690
So on load, as I mentioned
earlier, with the Drive API,

00:33:20.690 --> 00:33:26.280
you need to do get a read from
Drive to get the metadata to

00:33:26.280 --> 00:33:28.470
get the URL to download
the file.

00:33:28.470 --> 00:33:30.090
So you have to have
two requests.

00:33:30.090 --> 00:33:32.390
So we used to have
three requests.

00:33:32.390 --> 00:33:34.250
These were the Drive ones,
and this one was

00:33:34.250 --> 00:33:35.990
the call of the Tasks.

00:33:35.990 --> 00:33:38.183
Well, I got rid of the Tasks
one, but that wasn't that big

00:33:38.183 --> 00:33:39.330
of a savings.

00:33:39.330 --> 00:33:43.030
So it sped things up a little
bit, but not too much.

00:33:43.030 --> 00:33:45.220
Same kind of thing with save.

00:33:45.220 --> 00:33:46.920
I was doing a read and write.

00:33:46.920 --> 00:33:48.990
I still need to do the
read and write.

00:33:48.990 --> 00:33:50.750
So, don't save much.

00:33:50.750 --> 00:33:55.690
Task is interesting because we
would have thought that this

00:33:55.690 --> 00:33:58.420
would be a big win, that instead
of doing all these in

00:33:58.420 --> 00:34:01.490
serial, I'm sending it
in one big Batch.

00:34:01.490 --> 00:34:06.890
But as I mentioned, some back
ends don't actually support

00:34:06.890 --> 00:34:08.600
fast batch yet.

00:34:08.600 --> 00:34:11.210
So what this is actually doing
on the server is, you're

00:34:11.210 --> 00:34:15.290
putting them all in parallel to
the Tasks API, which then

00:34:15.290 --> 00:34:18.429
is blocking all of them except
one at a time, because it can

00:34:18.429 --> 00:34:19.800
only write one at a time.

00:34:19.800 --> 00:34:21.510
So kind of annoying.

00:34:21.510 --> 00:34:23.929
I actually talked to the Task
team about trying to fix this,

00:34:23.929 --> 00:34:25.679
because it annoyed me.

00:34:25.679 --> 00:34:28.280
So if you guys notice this on
any APIs you're using, which

00:34:28.280 --> 00:34:31.920
hopefully you won't, but if you
do, let us know and we'll

00:34:31.920 --> 00:34:33.489
try and get that team
to implement a

00:34:33.489 --> 00:34:34.699
faster Batch for you.

00:34:34.699 --> 00:34:36.770
So you can see, for example,
Calendar did.

00:34:36.770 --> 00:34:42.130
So the Calendar events are
actually batched all the way

00:34:42.130 --> 00:34:43.650
into the storage layer.

00:34:43.650 --> 00:34:47.270
And so you can write to one
calendar all at once, and this

00:34:47.270 --> 00:34:51.120
ends up being a pretty
big latency win.

00:34:51.120 --> 00:34:52.820
OK.

00:34:52.820 --> 00:34:55.960
So that was latency, but what
happens with bandwidth?

00:34:55.960 --> 00:34:59.260
Unfortunately, Batch actually
increases that bandwidth

00:34:59.260 --> 00:35:01.010
because of those envelopes
I was talking about.

00:35:01.010 --> 00:35:03.360
So you can see here, especially
on save, it

00:35:03.360 --> 00:35:07.650
increased it a bit, and
on Tasks, quite a lot.

00:35:07.650 --> 00:35:11.470
The response from Tasks was
so small that adding those

00:35:11.470 --> 00:35:13.550
envelopes to every single one
of those requests ended up

00:35:13.550 --> 00:35:14.800
being a lot more.

00:35:17.140 --> 00:35:22.250
So I'm going to give you a quick
demo of how this looks

00:35:22.250 --> 00:35:24.010
with everything put together.

00:35:26.940 --> 00:35:33.360
So let's actually create a
new Super List for this.

00:35:33.360 --> 00:35:36.880
So we're going to call
this Books to Read.

00:35:39.510 --> 00:35:42.960
And we said that we wanted
to do Ender's Game.

00:35:42.960 --> 00:35:47.820
And let's read, any
other books?

00:35:51.220 --> 00:35:51.680
Anyone?

00:35:51.680 --> 00:35:52.400
Come on.

00:35:52.400 --> 00:35:54.150
People like books
still, right?

00:35:54.150 --> 00:35:54.700
Movies?

00:35:54.700 --> 00:35:56.890
AUDIENCE: Name of the Wind.

00:35:56.890 --> 00:35:57.430
SVEN MAWSON: What was that?

00:35:57.430 --> 00:35:58.660
AUDIENCE: Name of the Wind.

00:35:58.660 --> 00:35:59.250
SVEN MAWSON: Name of the Wind.

00:35:59.250 --> 00:36:00.750
That's a good one.

00:36:00.750 --> 00:36:02.260
Name of the Wind.

00:36:02.260 --> 00:36:04.130
I see our audience likes
sci fi things.

00:36:04.130 --> 00:36:05.380
OK.

00:36:07.520 --> 00:36:08.430
Children of the Sky.

00:36:08.430 --> 00:36:09.230
I'm reading that now.

00:36:09.230 --> 00:36:12.220
Vernor Vinge, if any of
you guys know him.

00:36:12.220 --> 00:36:13.852
He came to Google recently.

00:36:13.852 --> 00:36:15.210
AUDIENCE: Cosmic Trigger.

00:36:15.210 --> 00:36:17.092
SVEN MAWSON: Cosmic Trigger.

00:36:17.092 --> 00:36:17.970
All right.

00:36:17.970 --> 00:36:20.450
OK So we have some books.

00:36:20.450 --> 00:36:24.160
Let's set some due
dates on these.

00:36:24.160 --> 00:36:26.060
When I should read these by, I
don't really know what due

00:36:26.060 --> 00:36:30.840
date means on a book,
but we'll set it.

00:36:30.840 --> 00:36:33.595
I'm going to read really fast
here, and I should finish all

00:36:33.595 --> 00:36:36.325
of this by the end
of next week.

00:36:39.120 --> 00:36:40.420
And let's actually--

00:36:40.420 --> 00:36:43.130
so we save that.

00:36:43.130 --> 00:36:45.660
And we're actually going to
also create a TaskList for

00:36:45.660 --> 00:36:50.160
this, so I can show you how to
link all these together.

00:36:50.160 --> 00:36:52.690
So this is actually creating
a list back in My

00:36:52.690 --> 00:36:53.960
TaskLists for this.

00:36:53.960 --> 00:36:54.720
And I can sync it.

00:36:54.720 --> 00:36:57.125
So let's just be quick
and add some items.

00:37:00.900 --> 00:37:04.550
Just to give you guys a flavor
for how this stuff works.

00:37:04.550 --> 00:37:06.260
I can edit some things.

00:37:06.260 --> 00:37:08.640
I don't think I'll finish
that quite then.

00:37:08.640 --> 00:37:10.900
All right.

00:37:10.900 --> 00:37:11.730
So here it is.

00:37:11.730 --> 00:37:13.755
Let's save it and let's see
how long this takes.

00:37:17.310 --> 00:37:20.440
Still going, still going,
still going.

00:37:20.440 --> 00:37:22.440
Doing all that in serial, you
can see all this stuff gets

00:37:22.440 --> 00:37:23.750
printed here.

00:37:23.750 --> 00:37:26.840
The whole thing took
seven seconds.

00:37:26.840 --> 00:37:28.440
So let's turn on all
of our features.

00:37:32.020 --> 00:37:33.490
Let's delete some items.

00:37:38.860 --> 00:37:40.240
Better item.

00:37:40.240 --> 00:37:43.830
Let's add some more things,
let's change some dates.

00:37:43.830 --> 00:37:45.470
Just to give it something
to do here.

00:37:48.980 --> 00:37:51.910
And then let's save it.

00:37:51.910 --> 00:37:55.450
And hopefully this will be
faster if the demigods are

00:37:55.450 --> 00:37:58.200
nice to me, but maybe not.

00:37:58.200 --> 00:38:00.390
Ooh, maybe not.

00:38:00.390 --> 00:38:01.030
Oh, it took longer.

00:38:01.030 --> 00:38:04.550
Well, let's pretend
it was faster.

00:38:04.550 --> 00:38:07.040
It was faster when I tried this
earlier, but, all right.

00:38:07.040 --> 00:38:10.290
So in the earlier version of
this that I tried, here's how

00:38:10.290 --> 00:38:12.800
much faster it was.

00:38:12.800 --> 00:38:15.950
Unfortunately, it didn't quite
work for the demo.

00:38:15.950 --> 00:38:19.910
And this is actually, what I
wanted to show you is how much

00:38:19.910 --> 00:38:22.530
Batch makes a difference
when you're doing a lot

00:38:22.530 --> 00:38:23.240
of actions at once.

00:38:23.240 --> 00:38:28.660
So I was showing you applying
a Batch just to read it from

00:38:28.660 --> 00:38:30.590
Drive, and then applying a Batch
just to read it from

00:38:30.590 --> 00:38:33.010
Calendar, and then applying a
Batch just to read from Tasks.

00:38:33.010 --> 00:38:35.040
But as I mentioned, you can
do this all at once.

00:38:35.040 --> 00:38:38.400
You don't have to just
do one API at a time.

00:38:38.400 --> 00:38:40.290
You can actually do everything
at once.

00:38:40.290 --> 00:38:41.880
And that means everything
gets parallelilized.

00:38:41.880 --> 00:38:45.870
Even in that annoying fact that
the Event stuff took a

00:38:45.870 --> 00:38:49.640
long time because the back end's
not optimized, so the

00:38:49.640 --> 00:38:52.280
amount of time that that took is
the time everything takes,

00:38:52.280 --> 00:38:53.440
because everything else
is done already.

00:38:53.440 --> 00:38:55.320
So here you can see that.

00:38:55.320 --> 00:38:58.506
The full sync is a save with a
bunch of items from Task I'm

00:38:58.506 --> 00:38:59.760
going to turn into Calendar.

00:38:59.760 --> 00:39:03.500
And it saves a whole
bunch of time.

00:39:03.500 --> 00:39:06.050
I actually wrote down, just
so I can tell you the cool

00:39:06.050 --> 00:39:08.340
numbers here.

00:39:08.340 --> 00:39:15.290
So this is 63% of the time, so
almost half the time got

00:39:15.290 --> 00:39:17.215
thrown away just because
I was using Batch.

00:39:17.215 --> 00:39:19.330
So it's pretty nice.

00:39:19.330 --> 00:39:24.180
And I should mention also the
quite rigorous testing

00:39:24.180 --> 00:39:28.330
principle here was I ran
this about 10 times

00:39:28.330 --> 00:39:29.050
and took the median.

00:39:29.050 --> 00:39:30.300
So not too exciting.

00:39:33.000 --> 00:39:33.640
OK.

00:39:33.640 --> 00:39:34.570
What about bandwidth, right?

00:39:34.570 --> 00:39:37.110
So same kind of thing,
full sync.

00:39:37.110 --> 00:39:41.170
You can see those first two
features on latency really

00:39:41.170 --> 00:39:42.580
didn't really make
a difference.

00:39:42.580 --> 00:39:45.420
On bandwidth, they were
a huge difference.

00:39:45.420 --> 00:39:49.890
Partial responses and Patch
cut out a lot of the time.

00:39:49.890 --> 00:39:51.870
Partial itself cut out
half the time.

00:39:51.870 --> 00:39:54.820
Patch cut out another
half of that.

00:39:54.820 --> 00:39:56.590
Unfortunately, the Batch, we're

00:39:56.590 --> 00:39:57.880
paying a slight overhead.

00:39:57.880 --> 00:40:01.080
So in order to get that fast
latency, we pay a little bit

00:40:01.080 --> 00:40:01.870
in the bandwidth.

00:40:01.870 --> 00:40:04.740
We're back up to 42%
of the original.

00:40:04.740 --> 00:40:06.350
Still better than just
Partial by itself.

00:40:09.190 --> 00:40:12.290
So in summary, how much
can you expect to

00:40:12.290 --> 00:40:13.340
save with these features?

00:40:13.340 --> 00:40:18.800
So GZip, Partial, and Patch,
I'm all marking as N/A for

00:40:18.800 --> 00:40:22.000
latency, because it's really the
bandwidth that may or may

00:40:22.000 --> 00:40:23.560
not save you the latency.

00:40:23.560 --> 00:40:26.160
They don't have a direct effect
on latency, but they do

00:40:26.160 --> 00:40:27.940
have a big savings
on bandwidth.

00:40:27.940 --> 00:40:30.970
So GZip by itself can
save you 79%,

00:40:30.970 --> 00:40:32.670
depending on your content.

00:40:32.670 --> 00:40:35.540
Things like a JSON payload,
which are APIs return, tend to

00:40:35.540 --> 00:40:37.460
be very regular.

00:40:37.460 --> 00:40:40.300
The same key names appear,
the same field names,

00:40:40.300 --> 00:40:42.110
often the same data.

00:40:42.110 --> 00:40:43.980
So it really can GZip
really, really well.

00:40:43.980 --> 00:40:47.100
So definitely use that.

00:40:47.100 --> 00:40:50.360
Partial can save, depending on
what field you use, between

00:40:50.360 --> 00:40:50.880
40% and 80%.

00:40:50.880 --> 00:40:52.465
Of course, if you ask for
everything, it doesn't save

00:40:52.465 --> 00:40:54.570
you anything.

00:40:54.570 --> 00:40:58.670
Patch can save an additional
40% to 70% on top of that.

00:40:58.670 --> 00:41:00.740
And then Batch, of course,
costs you that envelope

00:41:00.740 --> 00:41:03.600
overhead, but it can give you
huge latency savings.

00:41:03.600 --> 00:41:07.300
So it's definitely worth it.

00:41:07.300 --> 00:41:07.680
All right.

00:41:07.680 --> 00:41:09.760
So pretty much all I have.

00:41:09.760 --> 00:41:13.390
I just wanted to give you a
bunch of information about

00:41:13.390 --> 00:41:14.860
some links you can go
to to learn more.

00:41:14.860 --> 00:41:19.410
So on the Discovery API and
the Drive API, there's a

00:41:19.410 --> 00:41:20.640
performance page.

00:41:20.640 --> 00:41:22.190
The links are there.

00:41:22.190 --> 00:41:23.860
You can read about all
these features.

00:41:23.860 --> 00:41:25.520
Actually, I think you can't read
about Batch yet, because

00:41:25.520 --> 00:41:28.790
it's still pretty new.

00:41:28.790 --> 00:41:31.110
But we'll be adding
that very shortly.

00:41:31.110 --> 00:41:33.750
And then there's also a webinar
that you guys may or

00:41:33.750 --> 00:41:36.390
may not have seen on getting
started with our APIs.

00:41:36.390 --> 00:41:40.170
If any of you want to get up to
speed, you could use that.

00:41:40.170 --> 00:41:43.920
And then there's a whole bunch
of related sessions, on

00:41:43.920 --> 00:41:48.790
optimizing in general, there's
stuff about how to optimize

00:41:48.790 --> 00:41:52.380
the web applications, there's
one at 5:15 today.

00:41:52.380 --> 00:41:55.690
There's optimizing your Google
App Engine app, which I

00:41:55.690 --> 00:41:58.960
probably should've gone to, it
might have made my app faster.

00:41:58.960 --> 00:42:01.230
I think there's also some
mobile ones I don't have

00:42:01.230 --> 00:42:02.200
listed here.

00:42:02.200 --> 00:42:05.930
And then there's a bunch of
talks about how to use our API

00:42:05.930 --> 00:42:08.570
clients, so there was a talk
about using the JavaScript

00:42:08.570 --> 00:42:11.050
client, and there's a code
lab on it tomorrow.

00:42:11.050 --> 00:42:14.410
There's a talk about Android
applications, I think also at

00:42:14.410 --> 00:42:15.750
5:15 today.

00:42:15.750 --> 00:42:18.490
There's also a code lab
on that tomorrow.

00:42:18.490 --> 00:42:20.350
You can learn about
all these things.

00:42:20.350 --> 00:42:23.040
And then there's also this
really cool feature we just

00:42:23.040 --> 00:42:24.970
launched called Cloud Endpoints,
hopefully you guys

00:42:24.970 --> 00:42:27.080
know about.

00:42:27.080 --> 00:42:29.290
One of the very cool things
about that is it's built on

00:42:29.290 --> 00:42:33.480
our infrastructure, so you get
all of this stuff on your own

00:42:33.480 --> 00:42:35.740
APIs if you build on
Cloud Endpoints.

00:42:35.740 --> 00:42:37.650
So you get the partial feature,
you get the patch

00:42:37.650 --> 00:42:38.910
feature, and you get Batch.

00:42:38.910 --> 00:42:42.110
So it's pretty cool.

00:42:42.110 --> 00:42:42.380
All right.

00:42:42.380 --> 00:42:43.420
That is all I had.

00:42:43.420 --> 00:42:44.980
Thank you guys very much.

00:42:44.980 --> 00:42:47.620
And I will take questions, and
please use the microphones.

00:42:47.620 --> 00:43:00.300
[APPLAUSE]

00:43:00.300 --> 00:43:02.180
AUDIENCE: Hi.

00:43:02.180 --> 00:43:04.650
You mentioned how it'd
be better to use

00:43:04.650 --> 00:43:07.340
PATCH instead of PUT.

00:43:07.340 --> 00:43:09.360
Does AppEngine support PATCH?

00:43:09.360 --> 00:43:12.940
Because all our applications
are on AppEngine.

00:43:12.940 --> 00:43:15.310
SVEN MAWSON: So on sending
a patch, you mean?

00:43:15.310 --> 00:43:17.140
So if you use the--

00:43:17.140 --> 00:43:19.710
so actually, I'm using
AppEngine and I'm

00:43:19.710 --> 00:43:22.240
doing that in these.

00:43:22.240 --> 00:43:24.290
So hopefully you use our Client
Libraries, which will

00:43:24.290 --> 00:43:25.800
do it for you.

00:43:25.800 --> 00:43:28.950
That said, the way the Client
Library is probably doing it,

00:43:28.950 --> 00:43:32.800
I'm not 100% sure on this, is we
have a header that you can

00:43:32.800 --> 00:43:35.630
override the HTTP method in case
the environment you're

00:43:35.630 --> 00:43:37.320
using doesn't support it.

00:43:37.320 --> 00:43:40.305
So it might be doing that, but
our Client Libraries will do

00:43:40.305 --> 00:43:41.084
that for you.

00:43:41.084 --> 00:43:43.419
AUDIENCE: Thank you.

00:43:43.419 --> 00:43:44.360
AUDIENCE: Hello.

00:43:44.360 --> 00:43:51.950
You said we should ask to
compress the responses, right?

00:43:51.950 --> 00:43:54.250
At some point, I guess, we
need to uncompress them.

00:43:54.250 --> 00:43:57.150
Don't we lose time
when we do that?

00:43:57.150 --> 00:43:57.400
SVEN MAWSON: Right.

00:43:57.400 --> 00:44:01.460
So the CPU overhead of GZip?

00:44:01.460 --> 00:44:02.730
I skipped over that part.

00:44:02.730 --> 00:44:06.440
Yes, there is a CPU
overhead of GZip.

00:44:06.440 --> 00:44:09.560
Devices are so fast these days,
it's almost nonexistent.

00:44:09.560 --> 00:44:11.610
I mean, I would measure it.

00:44:11.610 --> 00:44:14.790
The rule number one of
performance is always measure.

00:44:14.790 --> 00:44:20.100
So test it out and see if GZip,
depending on the exact

00:44:20.100 --> 00:44:22.570
device you're targeting,
if it makes sense.

00:44:22.570 --> 00:44:25.420
Our Client Libraries enable
GZip by default, but they

00:44:25.420 --> 00:44:27.590
actually have an easy way to
turn it off, if you do need to

00:44:27.590 --> 00:44:28.530
turn it off.

00:44:28.530 --> 00:44:31.010
But I would say, don't turn it
off unless you have strong

00:44:31.010 --> 00:44:33.370
evidence that it's causing
a problem, because it'll

00:44:33.370 --> 00:44:35.080
actually save a lot of time.

00:44:35.080 --> 00:44:35.640
AUDIENCE: Thank you.

00:44:35.640 --> 00:44:36.890
SVEN MAWSON: Yeah.

00:44:40.530 --> 00:44:43.780
Any other questions?

00:44:43.780 --> 00:44:44.190
All right, you all.

00:44:44.190 --> 00:44:44.790
Thanks for your time.

00:44:44.790 --> 00:44:49.588
[APPLAUSE]

