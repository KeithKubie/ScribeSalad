WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.425
[MUSIC PLAYING]

00:00:05.335 --> 00:00:06.930
THERESA PAYTON:
Hello, everybody.

00:00:06.930 --> 00:00:09.530
I'm so excited to be
here with you today.

00:00:09.530 --> 00:00:11.000
Couple of things--

00:00:11.000 --> 00:00:12.840
I want to make sure
we have a dialogue.

00:00:12.840 --> 00:00:14.580
Because if all I
do is talk to you

00:00:14.580 --> 00:00:19.014
about maybe a few nightmares,
maybe a few scary things,

00:00:19.014 --> 00:00:20.430
tell you a few
White House stories

00:00:20.430 --> 00:00:23.520
and that's all that happened,
then I only did half my job.

00:00:23.520 --> 00:00:25.170
So I want to make
sure that you feel

00:00:25.170 --> 00:00:27.150
like you can ask me questions.

00:00:27.150 --> 00:00:31.040
And for those of you that
are live streaming in,

00:00:31.040 --> 00:00:33.750
your questions are going
to be moderated by Heather.

00:00:33.750 --> 00:00:36.720
And we were talking about making
sure everybody's questions get

00:00:36.720 --> 00:00:37.240
answered.

00:00:37.240 --> 00:00:38.781
We're going to find
a way to do that,

00:00:38.781 --> 00:00:40.780
even if we run out
of our time together.

00:00:40.780 --> 00:00:43.020
And then for those of
you that are in the room,

00:00:43.020 --> 00:00:46.440
your incentive plan
is to ask a question.

00:00:46.440 --> 00:00:48.300
And the first one
to ask a question,

00:00:48.300 --> 00:00:51.270
you get a signed copy of my
book, which my mother says

00:00:51.270 --> 00:00:52.900
is a must read.

00:00:52.900 --> 00:00:55.650
And then if you
don't ask questions,

00:00:55.650 --> 00:00:57.510
and you're too shy
to ask questions,

00:00:57.510 --> 00:00:59.380
then I ask random
people random questions.

00:00:59.380 --> 00:01:02.310
So that's your incentive plan
for asking me a question.

00:01:02.310 --> 00:01:04.739
I really want to make
sure we have a dialogue.

00:01:04.739 --> 00:01:07.350
I'm really honored to
be here with all of you

00:01:07.350 --> 00:01:10.110
for those of you who are live
streaming in, those of you who

00:01:10.110 --> 00:01:12.090
are here in person.

00:01:12.090 --> 00:01:15.270
Google is one of the power
brokers of the world.

00:01:15.270 --> 00:01:17.040
And I'm a big fan of Google.

00:01:17.040 --> 00:01:20.520
I've also held Google
accountable in talking

00:01:20.520 --> 00:01:23.070
about privacy and security,
but I'm a big fan.

00:01:23.070 --> 00:01:25.020
As a matter of fact, I power--

00:01:25.020 --> 00:01:27.330
our company's infrastructure--
a big part of it

00:01:27.330 --> 00:01:29.400
is on the Google Cloud.

00:01:29.400 --> 00:01:31.150
So big fan of Google.

00:01:31.150 --> 00:01:33.450
And I want to push you
out of your comfort zones.

00:01:33.450 --> 00:01:35.940
When I talked to the people
putting on this event,

00:01:35.940 --> 00:01:37.590
one of the things
they said is, try out

00:01:37.590 --> 00:01:41.190
some new concepts and new ideas,
and I'm going to do that today.

00:01:41.190 --> 00:01:43.670
Disagreement is always welcome.

00:01:43.670 --> 00:01:45.550
So you don't have
to agree with me.

00:01:45.550 --> 00:01:47.460
The only way I'm going
to learn is for people

00:01:47.460 --> 00:01:50.410
to share alternative
points of view and ideas.

00:01:50.410 --> 00:01:54.382
So your questions can
be anything, any topic,

00:01:54.382 --> 00:01:56.340
and feel free to push
back on anything that you

00:01:56.340 --> 00:01:58.080
hear me talk about today.

00:01:58.080 --> 00:02:00.820
Couple of quick pictures
from the family scrapbook--

00:02:00.820 --> 00:02:03.600
so you'll see in the family
photo I've got my two sons--

00:02:03.600 --> 00:02:04.350
Keiran and Aidan.

00:02:04.350 --> 00:02:06.600
I'm actually seven months
pregnant with my little girl

00:02:06.600 --> 00:02:07.644
Maeve there.

00:02:07.644 --> 00:02:09.810
And the gentleman next to
me with his arm around me,

00:02:09.810 --> 00:02:10.860
that's President Bush.

00:02:10.860 --> 00:02:14.040
And the dude next to him--
that's actually my husband.

00:02:14.040 --> 00:02:18.150
Then, I have another picture of
the White House press briefing

00:02:18.150 --> 00:02:19.380
room podium.

00:02:19.380 --> 00:02:21.930
And you can probably tell I'm
actually holding up my son

00:02:21.930 --> 00:02:23.670
and ducking behind him.

00:02:23.670 --> 00:02:25.830
And I love that
picture because it was

00:02:25.830 --> 00:02:28.530
one of those things where my--

00:02:28.530 --> 00:02:31.000
I commuted every week
for 2 and 1/2 years.

00:02:31.000 --> 00:02:33.240
I don't know if you know
this, but the shelf life

00:02:33.240 --> 00:02:37.920
of a political appointee CIO
is roughly 12 to 14 months.

00:02:37.920 --> 00:02:39.390
I did it for 2 and 1/2 years.

00:02:39.390 --> 00:02:43.800
So that either says I'm crazy,
or determined and stubborn,

00:02:43.800 --> 00:02:46.390
or maybe a little bit
of all of the above.

00:02:46.390 --> 00:02:48.060
But sometimes, instead
of me commuting,

00:02:48.060 --> 00:02:50.150
home my family would
actually come to see me.

00:02:50.150 --> 00:02:52.140
And senior staff
really encourage

00:02:52.140 --> 00:02:54.870
them to come and
experience the White House

00:02:54.870 --> 00:02:57.310
as I experienced it.

00:02:57.310 --> 00:03:00.060
And so on this particular day,
actually, the kids were like,

00:03:00.060 --> 00:03:03.224
mom, you have the coolest job in
the world, and they were right.

00:03:03.224 --> 00:03:05.140
And I still have the
coolest job in the world.

00:03:05.140 --> 00:03:06.510
It's just a different job.

00:03:06.510 --> 00:03:08.910
But this particular day,
they saw the president land

00:03:08.910 --> 00:03:11.820
on the South Lawn in
HMX-1, the helicopter.

00:03:11.820 --> 00:03:14.670
Then, they saw the president's
dogs Barney and Miss Beasley.

00:03:14.670 --> 00:03:16.470
And Barney was
outfitted with a camera,

00:03:16.470 --> 00:03:19.340
so you could see the White House
from Barney's point of view

00:03:19.340 --> 00:03:20.660
on Barney Cam.

00:03:20.660 --> 00:03:22.530
Then, people were
handing them presidential

00:03:22.530 --> 00:03:24.090
M&amp;M's everywhere they went.

00:03:24.090 --> 00:03:26.100
And they're like,
this job is amazing.

00:03:26.100 --> 00:03:29.010
You help the president
with this computer;

00:03:29.010 --> 00:03:31.249
you get to watch helicopters
land, play with dogs,

00:03:31.249 --> 00:03:33.540
and eat M&amp;M's-- kind of sounds
like Google, doesn't it?

00:03:33.540 --> 00:03:34.170
Right?

00:03:34.170 --> 00:03:37.392
And so we went into the
press briefing room,

00:03:37.392 --> 00:03:39.600
which is one of the few
places where I could actually

00:03:39.600 --> 00:03:41.010
talk about my job.

00:03:41.010 --> 00:03:43.060
And we were doing this
major modernization effort

00:03:43.060 --> 00:03:44.520
in the press briefing room.

00:03:44.520 --> 00:03:47.550
And behind that podium, which
if the president had been there,

00:03:47.550 --> 00:03:49.290
there'd actually be
a presidential seal

00:03:49.290 --> 00:03:52.410
on the podium, and its nickname
is called the Blue Goose.

00:03:52.410 --> 00:03:55.530
But behind that is almost its
own little city of cables,

00:03:55.530 --> 00:04:00.000
and wires, and programs running
things from the Blue Goose.

00:04:00.000 --> 00:04:01.526
My kids are bored at this point.

00:04:01.526 --> 00:04:02.900
So my oldest turns
to me, though,

00:04:02.900 --> 00:04:04.733
as we're getting ready
to leave and he says,

00:04:04.733 --> 00:04:07.050
Mama, I really want
to tell the news.

00:04:07.050 --> 00:04:08.880
And so as I ducked down
so my husband could

00:04:08.880 --> 00:04:11.338
take that picture of him telling
the news, it dawned on me,

00:04:11.338 --> 00:04:14.212
wouldn't it be great if we let
four-year-olds give the press

00:04:14.212 --> 00:04:15.420
briefings in the White House?

00:04:15.420 --> 00:04:18.690
I mean, think about the
honesty we would get, right?

00:04:18.690 --> 00:04:21.000
And then down at
the bottom, there's

00:04:21.000 --> 00:04:24.240
a picture of me in front of one
of the jets in the Air Force

00:04:24.240 --> 00:04:25.470
One fleet.

00:04:25.470 --> 00:04:29.130
And this is where the job that
you have and the job that I had

00:04:29.130 --> 00:04:31.427
are actually not too different.

00:04:31.427 --> 00:04:33.010
So if you think about
the White House,

00:04:33.010 --> 00:04:36.070
for starters, the
3,000 staff that

00:04:36.070 --> 00:04:38.070
work for the executive
office of the president--

00:04:38.070 --> 00:04:39.720
they're barely ever
at the White House.

00:04:39.720 --> 00:04:41.370
We don't all fit
in the White House.

00:04:41.370 --> 00:04:44.430
It was built for a kinder,
gentler, smaller time

00:04:44.430 --> 00:04:46.170
in our US government.

00:04:46.170 --> 00:04:46.800
They're mobile.

00:04:46.800 --> 00:04:47.880
They're global.

00:04:47.880 --> 00:04:51.750
They deserve and, in some cases,
demand the latest and greatest

00:04:51.750 --> 00:04:53.190
technology.

00:04:53.190 --> 00:04:55.980
How do you give them the
latest and greatest technology

00:04:55.980 --> 00:05:00.740
to enable them to do
their jobs without--

00:05:00.740 --> 00:05:03.010
for me, anyways,
putting a homing beacon

00:05:03.010 --> 00:05:05.415
in the president's pocket
was not an ideal thing to do.

00:05:05.415 --> 00:05:07.540
For you, it might be a
little different what you're

00:05:07.540 --> 00:05:09.490
worried about, but
you're still worried

00:05:09.490 --> 00:05:12.280
about the security
and the privacy

00:05:12.280 --> 00:05:14.747
in addition to
the functionality.

00:05:14.747 --> 00:05:16.330
And so if you think
about it, our jobs

00:05:16.330 --> 00:05:20.380
are not too dissimilar, in the
challenges we face every day.

00:05:20.380 --> 00:05:23.890
And we're at this really
exciting time in computing.

00:05:23.890 --> 00:05:27.550
And Heather and I were talking
about just how amazing it is.

00:05:27.550 --> 00:05:30.010
And we don't even know
what quantum computing is

00:05:30.010 --> 00:05:31.280
going to bring for all of us.

00:05:31.280 --> 00:05:33.730
And it's exciting and
scary at the same time.

00:05:33.730 --> 00:05:37.060
And we now have a point
where devices are collecting

00:05:37.060 --> 00:05:39.520
and interacting with
each other on our behalf

00:05:39.520 --> 00:05:41.330
without human intervention.

00:05:41.330 --> 00:05:44.380
It is an amazing
time of innovation.

00:05:44.380 --> 00:05:47.152
And the technology that's
being deployed is so cool.

00:05:47.152 --> 00:05:48.610
So I don't know
about you, when you

00:05:48.610 --> 00:05:51.520
think about commercial
travel and you

00:05:51.520 --> 00:05:53.695
think about elegant,
classy service,

00:05:53.695 --> 00:05:56.031
do you think flying on
airlines these days?

00:05:56.031 --> 00:05:56.530
Maybe?

00:05:56.530 --> 00:05:57.030
Maybe not?

00:05:57.030 --> 00:05:57.790
Probably not.

00:05:57.790 --> 00:06:00.550
I mean, I think Air Force One,
but I don't fly on that as much

00:06:00.550 --> 00:06:01.190
anymore.

00:06:01.190 --> 00:06:04.869
And so I think kind a the
second best is Virgin Airlines.

00:06:04.869 --> 00:06:06.910
I think they do a pretty
good job, whether you're

00:06:06.910 --> 00:06:09.120
in first class or in coach.

00:06:09.120 --> 00:06:10.450
And so how do they do that?

00:06:10.450 --> 00:06:12.250
And I looked into what
Virgin Airlines was doing.

00:06:12.250 --> 00:06:13.749
The first thing
they did was they've

00:06:13.749 --> 00:06:17.500
outfitted every plane with
Internet of Things devices

00:06:17.500 --> 00:06:20.827
from nose to tail, wing to
wing, inside and outside.

00:06:20.827 --> 00:06:22.660
Now that's not to say,
well, they're flying.

00:06:22.660 --> 00:06:24.410
They're all communicate
with the internet.

00:06:24.410 --> 00:06:27.170
But the devices are
collecting information,

00:06:27.170 --> 00:06:31.360
and that information is used
to think about safer flying,

00:06:31.360 --> 00:06:33.640
are there mechanical issues?

00:06:33.640 --> 00:06:35.410
More economical
flying-- so how do

00:06:35.410 --> 00:06:37.750
I give you elegant classy
service while having

00:06:37.750 --> 00:06:40.510
it be economical
at the same time

00:06:40.510 --> 00:06:43.210
and being on time--
so on-time records.

00:06:43.210 --> 00:06:45.100
How much data are
they collecting?

00:06:45.100 --> 00:06:50.320
One plane, one flight is
a half a terabyte of data.

00:06:50.320 --> 00:06:53.380
Now I know this group knows what
a half a terabyte of data is,

00:06:53.380 --> 00:06:55.870
but if your mom and
dad ask you what it is,

00:06:55.870 --> 00:06:59.230
it's the equivalent
of binge watching 250

00:06:59.230 --> 00:07:01.600
hours of your favorite shows--

00:07:01.600 --> 00:07:04.890
one plane, one flight,
Virgin Airlines.

00:07:04.890 --> 00:07:07.450
That is a massive
amount of data,

00:07:07.450 --> 00:07:10.650
but it's really cool
how it's being used.

00:07:10.650 --> 00:07:14.050
Now in some cases, where
we're headed with technology

00:07:14.050 --> 00:07:15.970
can even save lives.

00:07:15.970 --> 00:07:18.640
So in the UK, they actually
have Internet of Things lamps.

00:07:18.640 --> 00:07:23.590
And these lamps actually
detect glass breaking, yelling,

00:07:23.590 --> 00:07:26.470
banging, loud
noises, and the lamps

00:07:26.470 --> 00:07:29.500
actually glow
brighter and brighter.

00:07:29.500 --> 00:07:31.720
In some cases, a
camera will turn on,

00:07:31.720 --> 00:07:35.620
and they can deploy physical
security if they need to.

00:07:35.620 --> 00:07:38.950
These are really cool and
interesting uses of technology.

00:07:38.950 --> 00:07:41.680
And then of course, Google--
not to leave out Google--

00:07:41.680 --> 00:07:43.330
we have Google Home at my house.

00:07:43.330 --> 00:07:45.520
That was actually the
employee gift last year

00:07:45.520 --> 00:07:47.800
for Christmas for
everybody in our company.

00:07:47.800 --> 00:07:49.264
And everything has to be gold.

00:07:49.264 --> 00:07:50.680
That's given as
the employee gift,

00:07:50.680 --> 00:07:52.870
so we had to search for
the gold wrappers, which

00:07:52.870 --> 00:07:54.490
came later but--

00:07:54.490 --> 00:07:55.820
long story about that.

00:07:55.820 --> 00:07:59.320
But if you think about
the integration of some

00:07:59.320 --> 00:08:01.690
of this technology,
it's almost to the point

00:08:01.690 --> 00:08:04.820
where we don't even
realize it's there anymore.

00:08:04.820 --> 00:08:06.910
And the opportunity is huge.

00:08:06.910 --> 00:08:09.350
When you look at the
economic value for the world,

00:08:09.350 --> 00:08:12.670
we're looking at possibly
a $11 trillion dollar

00:08:12.670 --> 00:08:14.230
positive impact.

00:08:14.230 --> 00:08:18.430
And we've now outnumbers humans
with the number of IoT devices

00:08:18.430 --> 00:08:20.510
around the world.

00:08:20.510 --> 00:08:24.150
So where do we go from here?

00:08:24.150 --> 00:08:26.880
One of the first things I want
to be thinking about since it's

00:08:26.880 --> 00:08:30.450
Internet Safety Awareness
Month-- so National Cyber

00:08:30.450 --> 00:08:31.540
Security Awareness Month.

00:08:31.540 --> 00:08:33.990
It's also International Cyber
Security Awareness Month.

00:08:33.990 --> 00:08:36.330
And this is the 13th year
that we're doing this.

00:08:36.330 --> 00:08:37.320
Do you guys feel safer?

00:08:37.320 --> 00:08:39.260
I don't know about you; I don't.

00:08:39.260 --> 00:08:42.370
So 13 years in, lucky 13.

00:08:42.370 --> 00:08:44.590
First thing I want you
to think about changing

00:08:44.590 --> 00:08:46.930
is, how many of you have
heard the conventional wisdom

00:08:46.930 --> 00:08:49.570
that the human is the
weakest link in security?

00:08:49.570 --> 00:08:51.640
So we all say it.

00:08:51.640 --> 00:08:52.360
We all say it.

00:08:52.360 --> 00:08:53.650
I want to change the dialogue.

00:08:53.650 --> 00:08:57.790
So I want to push back
on everybody here and ask

00:08:57.790 --> 00:09:02.740
you to question why do we
still, after over a decade,

00:09:02.740 --> 00:09:07.380
rely on the human and say
they're the weakest link?

00:09:07.380 --> 00:09:11.450
Maybe, just maybe, I'll
push this idea out to you--

00:09:11.450 --> 00:09:13.140
that maybe given
the hockey sticks

00:09:13.140 --> 00:09:15.660
we have in cybercrime,
that maybe given

00:09:15.660 --> 00:09:17.520
the geopolitics of
the world-- and I

00:09:17.520 --> 00:09:19.620
don't know about you if
you're a history buff,

00:09:19.620 --> 00:09:21.360
it's never felt
more tense than it

00:09:21.360 --> 00:09:23.670
has for me based
on what I've read

00:09:23.670 --> 00:09:26.220
of ancient history
and modern history.

00:09:26.220 --> 00:09:27.460
It feels pretty tense to me.

00:09:27.460 --> 00:09:29.370
Maybe it's because
I'm living in it.

00:09:29.370 --> 00:09:31.290
Maybe it's because
we're all living in it.

00:09:31.290 --> 00:09:34.470
It feels more intense to us than
maybe World War I, or World War

00:09:34.470 --> 00:09:37.360
II, or the Cold War, right?

00:09:37.360 --> 00:09:41.200
But maybe we should be thinking
about, no, the weakest link

00:09:41.200 --> 00:09:42.220
is actually us.

00:09:42.220 --> 00:09:44.750
I started off as a developer.

00:09:44.750 --> 00:09:47.560
Maybe there is a
moral imperative

00:09:47.560 --> 00:09:50.780
that when we talk about
feature and functionality,

00:09:50.780 --> 00:09:52.630
the first thing we
should be talking about

00:09:52.630 --> 00:09:56.630
is, let's not depend on the
weakest link, the human.

00:09:56.630 --> 00:09:59.330
So I'm going to push that out
as something I want each of you

00:09:59.330 --> 00:10:00.620
to consider--

00:10:00.620 --> 00:10:02.540
is we need to change
that dialogue.

00:10:02.540 --> 00:10:04.380
Because if we keep
relying on the human,

00:10:04.380 --> 00:10:06.830
we're going to keep failing,
and we can't afford to fail.

00:10:06.830 --> 00:10:13.460
Cyber criminals have never been
more organized, more talented,

00:10:13.460 --> 00:10:16.650
and, in some cases,
more scalable.

00:10:16.650 --> 00:10:19.720
So we're seeing the attacks
cost a lot of money.

00:10:19.720 --> 00:10:22.310
So you don't even have
to be technical anymore.

00:10:22.310 --> 00:10:24.890
You can buy your way
into attacking companies.

00:10:27.460 --> 00:10:29.350
And so it all
starts with designs.

00:10:29.350 --> 00:10:32.020
I really want to push
hard on this concept of,

00:10:32.020 --> 00:10:34.120
how do we think
differently about design?

00:10:34.120 --> 00:10:38.450
And maybe some of it starts with
thinking about ethical hacking.

00:10:38.450 --> 00:10:40.990
So before you even build
that piece of functionality,

00:10:40.990 --> 00:10:42.850
maybe you bring the
ethical hacker in--

00:10:42.850 --> 00:10:44.650
not for them to
throw a wet blanket

00:10:44.650 --> 00:10:47.230
on your fire on the
great idea that you're

00:10:47.230 --> 00:10:50.050
trying to innovate but
to turn to them and say,

00:10:50.050 --> 00:10:51.280
so how would you break this?

00:10:51.280 --> 00:10:53.740
Before I even build it,
how would you break it?

00:10:53.740 --> 00:10:56.830
How would you take advantage
of the human that's using it?

00:10:56.830 --> 00:11:00.550
How do we not be reliant
upon the human that's

00:11:00.550 --> 00:11:03.220
the weakest link?

00:11:03.220 --> 00:11:05.580
And for me, I have to tell
you, one of my tipping

00:11:05.580 --> 00:11:07.610
points when I first got
to the White House--

00:11:07.610 --> 00:11:10.284
you know, I used to work in the
financial services industry.

00:11:10.284 --> 00:11:11.700
And so every time
bad things would

00:11:11.700 --> 00:11:13.630
happen in the financial
services industry,

00:11:13.630 --> 00:11:17.000
I'd think to myself, if I
could just get to every user.

00:11:17.000 --> 00:11:19.260
If I could just talk to
you for a little bit,

00:11:19.260 --> 00:11:21.120
and train you a
little bit better,

00:11:21.120 --> 00:11:23.370
and write the policies
a little bit better,

00:11:23.370 --> 00:11:25.496
life would be so much better.

00:11:25.496 --> 00:11:26.370
And that's all it is.

00:11:26.370 --> 00:11:27.360
It's communications.

00:11:27.360 --> 00:11:28.380
It's training.

00:11:28.380 --> 00:11:30.125
We just got to do this better.

00:11:30.125 --> 00:11:31.500
And when I got to
the White House

00:11:31.500 --> 00:11:32.874
and I realized,
OK wait a minute,

00:11:32.874 --> 00:11:34.530
OK, there's 3,000 people here.

00:11:34.530 --> 00:11:35.220
They're global.

00:11:35.220 --> 00:11:37.470
They're mobile-- just like
our banking customers were,

00:11:37.470 --> 00:11:39.420
so I didn't think that
was too different.

00:11:39.420 --> 00:11:41.700
But the threats that were
targeting the White House

00:11:41.700 --> 00:11:42.747
were ever-changing.

00:11:42.747 --> 00:11:44.580
And I thought, if I'm
going to try and brief

00:11:44.580 --> 00:11:48.720
everybody every day on what
I'm learning as different

00:11:48.720 --> 00:11:51.060
and I'm going to hold down
accountable for understanding

00:11:51.060 --> 00:11:54.070
how to protect themselves,
I'm going to fail.

00:11:54.070 --> 00:11:56.310
And that's when I realized
I wasn't always designing

00:11:56.310 --> 00:11:56.940
for the human.

00:11:56.940 --> 00:11:58.440
And I'll talk to
you in a little bit

00:11:58.440 --> 00:11:59.910
about how to think
about designing

00:11:59.910 --> 00:12:02.910
for the human in one of my aha
moments at the White House.

00:12:02.910 --> 00:12:05.961
But I've had a second
aha moment lately.

00:12:05.961 --> 00:12:07.960
And this really happened
to me in the last year,

00:12:07.960 --> 00:12:10.251
and it really came to the
forefront with the discussion

00:12:10.251 --> 00:12:14.230
around the election cycle--
not just in the US but over

00:12:14.230 --> 00:12:15.250
in Europe--

00:12:15.250 --> 00:12:19.570
and the potential for Russia,
possibly other countries,

00:12:19.570 --> 00:12:23.620
to use propaganda to change
people's minds and opinions

00:12:23.620 --> 00:12:26.870
and potentially have them
change how they vote.

00:12:26.870 --> 00:12:29.690
And that domain is we
were so focused on, OK,

00:12:29.690 --> 00:12:31.052
the humans the weakest link.

00:12:31.052 --> 00:12:32.510
And we need to
protect the servers.

00:12:32.510 --> 00:12:33.620
And we need to protect the data.

00:12:33.620 --> 00:12:35.036
And we need to
protect the devices

00:12:35.036 --> 00:12:40.070
that we forgot to protect
crowdsourcing and crowd

00:12:40.070 --> 00:12:41.730
thinking.

00:12:41.730 --> 00:12:44.550
And so in that effort to be
thinking about, how do we

00:12:44.550 --> 00:12:47.190
reach people, and how do
we stay interconnected,

00:12:47.190 --> 00:12:50.240
and how do we get
information in a way

00:12:50.240 --> 00:12:51.990
that we want to receive
it that's the most

00:12:51.990 --> 00:12:54.960
beneficial to us in that moment
that we receive it-- so if you

00:12:54.960 --> 00:12:56.730
order something on
Amazon, it tells you

00:12:56.730 --> 00:12:59.030
what other people who
ordered that ordered.

00:12:59.030 --> 00:13:01.071
And a lot of times you
think, that's pretty cool.

00:13:01.071 --> 00:13:02.900
I probably need that too.

00:13:02.900 --> 00:13:04.630
And that's helpful.

00:13:04.630 --> 00:13:07.620
But at the same time, as
that technology matured,

00:13:07.620 --> 00:13:10.650
it also created unintended
echo chambers, which

00:13:10.650 --> 00:13:12.550
I'll talk about in a moment.

00:13:12.550 --> 00:13:16.320
But I want you to be thinking
about the domain of security

00:13:16.320 --> 00:13:19.360
has now added a new domain.

00:13:19.360 --> 00:13:20.830
So it's not just data.

00:13:20.830 --> 00:13:22.290
It's not just devices.

00:13:22.290 --> 00:13:23.710
It's not just the humans.

00:13:23.710 --> 00:13:26.820
But it's actually the
social media content as well

00:13:26.820 --> 00:13:29.280
that needs to be protected.

00:13:29.280 --> 00:13:30.870
And if you read a
security briefing,

00:13:30.870 --> 00:13:35.670
I don't know how many of you
have the soul-crushing pleasure

00:13:35.670 --> 00:13:38.760
of reading security
reports on a regular basis,

00:13:38.760 --> 00:13:41.160
but they all pretty
much sound like this.

00:13:41.160 --> 00:13:42.690
The sky is falling.

00:13:42.690 --> 00:13:43.920
Data is at risk.

00:13:43.920 --> 00:13:45.570
Attacks are worsening.

00:13:45.570 --> 00:13:46.620
And the silly user--

00:13:46.620 --> 00:13:47.550
it's their problem.

00:13:47.550 --> 00:13:49.524
They pretty much
all sound that way.

00:13:49.524 --> 00:13:51.690
And I'm going to show you
a couple clips from Hunted

00:13:51.690 --> 00:13:55.080
to show you why it's really
not something that the user can

00:13:55.080 --> 00:13:55.706
always prevent.

00:13:55.706 --> 00:13:57.871
And so what you're going
to see in this first clip--

00:13:57.871 --> 00:13:59.100
and a couple of caveats.

00:13:59.100 --> 00:14:01.950
On Hunted, when you see the
command center, none of us

00:14:01.950 --> 00:14:03.290
are actors and actresses.

00:14:03.290 --> 00:14:04.770
We're just working cases.

00:14:04.770 --> 00:14:06.900
We're trying to forget
the cameras are there.

00:14:06.900 --> 00:14:08.131
It's not scripted.

00:14:08.131 --> 00:14:09.630
And so everything
you see that we're

00:14:09.630 --> 00:14:11.730
doing-- if we're trying
to hack into an account

00:14:11.730 --> 00:14:15.520
or get information,
it's all in real time.

00:14:15.520 --> 00:14:17.650
So in this first one,
I'll show you the video,

00:14:17.650 --> 00:14:19.870
and then I'll explain
to you what's going on.

00:14:19.870 --> 00:14:19.888
[VIDEO PLAYBACK]

00:14:19.888 --> 00:14:22.304
- In an effort to gain concrete
intel on David and Emily's

00:14:22.304 --> 00:14:25.690
whereabouts, former NSA
analyst Landon Stewart

00:14:25.690 --> 00:14:28.740
attempts to break into
David's online accounts.

00:14:28.740 --> 00:14:30.340
Windecher@gmail.com.

00:14:30.340 --> 00:14:31.960
- I'm going to get
into his Gmail.

00:14:31.960 --> 00:14:34.611
Let's mess this lumberjack up.

00:14:34.611 --> 00:14:36.610
When a fugitive goes on
the run, my first thing,

00:14:36.610 --> 00:14:38.401
because I'm a cyber
guy, I want to know how

00:14:38.401 --> 00:14:40.060
to leverage technology
against then.

00:14:40.060 --> 00:14:41.900
One of the security
questions for a reset

00:14:41.900 --> 00:14:43.670
is his favorite sports team.

00:14:43.670 --> 00:14:45.560
So what is his favorite
sports team, Charles?

00:14:46.350 --> 00:14:47.850
- Let me see here.

00:14:47.850 --> 00:14:49.434
Ah, I'm on his Instagram.

00:14:49.434 --> 00:14:51.320
- All right.

00:14:51.320 --> 00:14:52.630
- Which sport, though?

00:14:52.630 --> 00:14:53.685
Lakers?

00:14:53.685 --> 00:14:55.157
He's sitting at
the Atlanta Braves,

00:14:55.157 --> 00:14:56.740
but that's probably
the most favorite.

00:14:56.740 --> 00:14:57.580
- The Miami Heat.

00:14:57.580 --> 00:14:59.840
- Those photos of
him in a Heat jersey.

00:14:59.840 --> 00:15:01.260
- He's from Miami, right?

00:15:01.260 --> 00:15:03.640
- Miami Heat-- that
would be my bet.

00:15:03.640 --> 00:15:05.897
My only concern is--

00:15:05.897 --> 00:15:07.480
let's do our best
not to lock him out.

00:15:07.480 --> 00:15:08.880
- That's why I want
to have it verified

00:15:08.880 --> 00:15:09.880
by more than one source.

00:15:09.880 --> 00:15:10.546
- Oh, of course.

00:15:10.546 --> 00:15:11.910
- You guys are saying Heat, too?

00:15:11.910 --> 00:15:13.770
- Yeah, he's at the
game three weeks ago.

00:15:13.770 --> 00:15:14.814
- Let me see.

00:15:14.814 --> 00:15:15.722
Screw it.

00:15:15.722 --> 00:15:16.630
Screw it.

00:15:16.630 --> 00:15:18.529
Screw it.

00:15:18.529 --> 00:15:19.070
Let's try it.

00:15:23.462 --> 00:15:24.930
We got it.

00:15:24.930 --> 00:15:25.763
It's the Heat.

00:15:25.763 --> 00:15:27.785
- Oh, you rock.

00:15:27.785 --> 00:15:30.960
Last security question.

00:15:30.960 --> 00:15:32.700
When did you create
this Google account?

00:15:32.700 --> 00:15:33.660
[SIGH] Tough.

00:15:33.660 --> 00:15:38.490
- OK, let's try to
be smart about it.

00:15:38.490 --> 00:15:41.010
Let me Google the account and
see about when it appears.

00:15:41.010 --> 00:15:41.926
Just give me a second.

00:15:41.926 --> 00:15:43.080
- Yeah.

00:15:43.080 --> 00:15:46.410
- Let me see here.

00:15:46.410 --> 00:15:48.000
Here is the oldest one I see.

00:15:48.000 --> 00:15:50.450
It's January of 2014.

00:15:50.450 --> 00:15:52.080
It might be the
best shot you got.

00:15:52.080 --> 00:15:54.621
This is a crude way of doing
it, but it's the best one I got.

00:15:54.621 --> 00:15:56.955
- It could be that one,
but that's no guarantee.

00:16:01.410 --> 00:16:02.250
Oh my God.

00:16:02.250 --> 00:16:05.010
It worked.

00:16:05.010 --> 00:16:08.386
We've got all his contacts,
we have everybody.

00:16:08.386 --> 00:16:09.424
- Dude, that's awesome.

00:16:09.424 --> 00:16:10.382
[END OF VIDEO PLAYBACK]

00:16:10.382 --> 00:16:12.000
THERESA PAYTON: OK
so a couple of things

00:16:12.000 --> 00:16:13.249
about what you just saw there.

00:16:13.249 --> 00:16:16.312
First of all, whenever we heard
that the fugitives had a Google

00:16:16.312 --> 00:16:17.520
account, we would just groan.

00:16:17.520 --> 00:16:20.580
Because we're like, oh,
based on Google security--

00:16:20.580 --> 00:16:23.710
and privacy settings, they're
the hardest ones to get into.

00:16:23.710 --> 00:16:25.580
And so we'd actually
have to file--

00:16:25.580 --> 00:16:27.750
I'd have to send a written
thing to a judge I never

00:16:27.750 --> 00:16:31.570
got to meet with who always said
no to pretty much everything.

00:16:31.570 --> 00:16:33.620
So I would always
have to justify

00:16:33.620 --> 00:16:35.870
what our techniques were in
the cyber and intel group,

00:16:35.870 --> 00:16:37.320
and I finally got a yes.

00:16:37.320 --> 00:16:39.830
David Windecher used
to be a criminal.

00:16:39.830 --> 00:16:41.220
He's now a defense attorney.

00:16:41.220 --> 00:16:43.740
He was a formidable
opponent as a fugitive

00:16:43.740 --> 00:16:47.080
on the run-- just really, really
smart at what he was doing.

00:16:47.080 --> 00:16:50.010
And we had actually
recovered his laptop

00:16:50.010 --> 00:16:53.010
from the scene at which he fled.

00:16:53.010 --> 00:16:55.190
But he had logged
out of his account--

00:16:55.190 --> 00:16:56.910
didn't have two-factor
authentication on.

00:16:56.910 --> 00:16:59.919
And so we finally got
the OK from the judge

00:16:59.919 --> 00:17:00.960
to hack into the account.

00:17:00.960 --> 00:17:04.409
And we knew if we messed up
those questions too many times,

00:17:04.409 --> 00:17:05.700
we knew we would be locked out.

00:17:05.700 --> 00:17:07.859
And the judge said
we'd be on our own.

00:17:07.859 --> 00:17:10.680
And those clues
were critical to us.

00:17:10.680 --> 00:17:12.089
I won't give you
a spoiler alert,

00:17:12.089 --> 00:17:14.658
but they were
critical to the case.

00:17:14.658 --> 00:17:15.926
Oh, and by the way--

00:17:15.926 --> 00:17:17.550
Landon, who also
works for my company--

00:17:17.550 --> 00:17:20.091
I joked with him-- he's the only
one that throughout the show

00:17:20.091 --> 00:17:22.569
would get subtitles, and it's
because he's from Pittsburgh.

00:17:22.569 --> 00:17:24.819
And so I'm like, I guess
because you speak Pittsburgh,

00:17:24.819 --> 00:17:28.240
they have to do subtitles for
you and not everybody else.

00:17:28.240 --> 00:17:30.926
All right, so we'll
go to the next video.

00:17:30.926 --> 00:17:31.592
[VIDEO PLAYBACK]

00:17:31.592 --> 00:17:34.300
- I'm going to
assign this to Steve.

00:17:34.300 --> 00:17:37.720
- Former Naval Intelligence
Officer Steve Masterson

00:17:37.720 --> 00:17:39.940
begins to build a profile
on Troy and Chele.

00:17:39.940 --> 00:17:41.740
- Crosscheck public records--

00:17:41.740 --> 00:17:42.319
who are they?

00:17:42.319 --> 00:17:42.985
What do they do?

00:17:42.985 --> 00:17:43.810
- They've been married.

00:17:43.810 --> 00:17:44.635
They're high school sweethearts.

00:17:44.635 --> 00:17:45.844
They seem to be best friends.

00:17:45.844 --> 00:17:47.801
I don't think they're
going to separate at all.

00:17:47.801 --> 00:17:49.970
- So they obviously can
stand long hours together.

00:17:49.970 --> 00:17:50.590
- Yep.

00:17:50.590 --> 00:17:51.090
- Kids?

00:17:51.090 --> 00:17:51.640
- No kids.

00:17:51.640 --> 00:17:52.394
- OK.

00:17:52.394 --> 00:17:52.771
[END OF VIDEO PLAYBACK]

00:17:52.771 --> 00:17:54.812
THERESA PAYTON: So in this
particular one, again,

00:17:54.812 --> 00:17:57.050
just from a-- and realize
the bad guys do this,

00:17:57.050 --> 00:17:59.330
too, to your customers, right?

00:17:59.330 --> 00:18:01.580
So we were trying to
figure out Troy and Chele.

00:18:01.580 --> 00:18:04.200
I had the suspicion they
were hiding out in the swamp.

00:18:04.200 --> 00:18:06.507
They actually had
an airsoft business.

00:18:06.507 --> 00:18:08.090
They had done a lot
of camping as part

00:18:08.090 --> 00:18:10.256
of their airsoft business,
and the airsoft community

00:18:10.256 --> 00:18:11.990
was not talking us.

00:18:11.990 --> 00:18:14.090
And that's their
friends and family--

00:18:14.090 --> 00:18:15.500
was the airsoft community.

00:18:15.500 --> 00:18:18.160
So we were trying to figure
out from a social media profile

00:18:18.160 --> 00:18:19.250
like, do they have kids?

00:18:19.250 --> 00:18:20.750
Would the kids be a clue?

00:18:20.750 --> 00:18:21.290
No kids.

00:18:21.290 --> 00:18:24.237
But we did find out they had a
pet who meant a lot to Chele.

00:18:24.237 --> 00:18:25.820
And so we had a lot
of rules of things

00:18:25.820 --> 00:18:27.450
we couldn't do to lure people.

00:18:27.450 --> 00:18:29.060
But one of the
things I wanted to do

00:18:29.060 --> 00:18:33.390
is just have the vet call
Chele's mom just to check in

00:18:33.390 --> 00:18:35.780
and to see when Chele was
going to check in on the pet--

00:18:35.780 --> 00:18:37.488
not to say the pet
was sick-- because I'm

00:18:37.488 --> 00:18:39.549
a pet lover myself--
or anything.

00:18:39.549 --> 00:18:41.090
And at that point,
I was told, I know

00:18:41.090 --> 00:18:42.410
it's not written in
the rules, but you're

00:18:42.410 --> 00:18:45.080
a really cold person, and we're
writting it into the rules

00:18:45.080 --> 00:18:46.560
that you can't talk about pets.

00:18:46.560 --> 00:18:49.020
So anyways, pets were
taken off the table.

00:18:49.020 --> 00:18:52.850
But you can see how just
using a social media profile,

00:18:52.850 --> 00:18:55.370
we were trying to get a feel
for where they would be.

00:18:55.370 --> 00:18:58.340
They had 800,000 square miles
they were allowed to hide in.

00:18:58.340 --> 00:19:01.010
And just by studying
them on airsoft,

00:19:01.010 --> 00:19:02.300
I knew they weren't going--

00:19:02.300 --> 00:19:05.630
they were airsoft
enthusiasts, looking

00:19:05.630 --> 00:19:08.270
at their airsoft websites
that they would participate in

00:19:08.270 --> 00:19:11.514
as well as-- the two of them
got along so well, most likely,

00:19:11.514 --> 00:19:12.680
they weren't going to argue.

00:19:12.680 --> 00:19:15.700
They were going to be a good
support network for each other.

00:19:15.700 --> 00:19:17.314
All right, one more video.

00:19:17.314 --> 00:19:17.980
[VIDEO PLAYBACK]

00:19:17.980 --> 00:19:20.970
- Back at Command Center,
the cyber team's Facebook

00:19:20.970 --> 00:19:23.460
wanted poster is widening
the circle of associates

00:19:23.460 --> 00:19:25.370
for fugitives Troy and Chele.

00:19:25.370 --> 00:19:27.440
- Guys, don't pay
attention to this post.

00:19:27.440 --> 00:19:28.770
It is not Chele posting.

00:19:28.770 --> 00:19:30.210
Snitches get stitches.

00:19:30.210 --> 00:19:32.565
JD-- it says,
snitches get stitches.

00:19:32.565 --> 00:19:35.400
So I want to figure
out who your JD is.

00:19:35.400 --> 00:19:38.190
- I love the results of what's
happening on this Facebook

00:19:38.190 --> 00:19:39.420
wanted poster.

00:19:39.420 --> 00:19:42.300
We're getting new names and
contacts we didn't have access

00:19:42.300 --> 00:19:43.110
to before.

00:19:43.110 --> 00:19:44.460
It's incredibly helpful.

00:19:44.460 --> 00:19:46.585
[END OF VIDEO PLAYBACK]

00:19:46.585 --> 00:19:49.260
- So in this particular
one, again, the community

00:19:49.260 --> 00:19:52.020
was not talking to us, and so
we got permission from the judge

00:19:52.020 --> 00:19:53.550
to actually flip
their social media

00:19:53.550 --> 00:19:55.620
profile to a wanted poster.

00:19:55.620 --> 00:19:58.866
And I knew that they
weren't going to--

00:19:58.866 --> 00:20:00.240
nobody was going
to turn them in.

00:20:00.240 --> 00:20:01.560
I knew that.

00:20:01.560 --> 00:20:05.220
But what I knew was whoever
seemed to defend them

00:20:05.220 --> 00:20:07.830
the most was probably
somebody I wanted

00:20:07.830 --> 00:20:09.240
to put under surveillance.

00:20:09.240 --> 00:20:11.280
And that actually
ended up helping us

00:20:11.280 --> 00:20:14.310
out a lot in that case is
somebody who spoke up a lot

00:20:14.310 --> 00:20:15.690
and told people
not to talk to us

00:20:15.690 --> 00:20:18.630
and not to help-- we
actually went to her house,

00:20:18.630 --> 00:20:20.970
and we actually ended
up, in 24 hours,

00:20:20.970 --> 00:20:23.040
apprehending them with the tips.

00:20:23.040 --> 00:20:24.660
And nobody outed
them, but it was just

00:20:24.660 --> 00:20:28.800
the way people behaved on social
media gave us a clue that they

00:20:28.800 --> 00:20:30.886
might be their lifeline.

00:20:30.886 --> 00:20:32.010
And so what does that mean?

00:20:32.010 --> 00:20:34.551
So we still have-- not only do
we have sort of this new brave

00:20:34.551 --> 00:20:37.550
world of social engineering
where it's never been easier

00:20:37.550 --> 00:20:40.490
to do for the bad guys, but
we've got these old school

00:20:40.490 --> 00:20:42.530
breaches that are coming
up in the headlines,

00:20:42.530 --> 00:20:44.800
whether it's WannaCry,
Petya, NotPetya,

00:20:44.800 --> 00:20:47.690
the SEC Edgar
database, Equifax--

00:20:47.690 --> 00:20:49.400
and I'm not picking
on these companies.

00:20:49.400 --> 00:20:51.190
I mean, the way I
look at it is, they're

00:20:51.190 --> 00:20:52.490
a victim of a cyber crime.

00:20:52.490 --> 00:20:55.190
You may like what they
did before and after;

00:20:55.190 --> 00:20:58.080
and how they handled the breach,
you may agree or disagree,

00:20:58.080 --> 00:21:00.676
but they are victims of a crime.

00:21:00.676 --> 00:21:02.300
But we've got these
new school problems

00:21:02.300 --> 00:21:03.440
to deal with now, right?

00:21:03.440 --> 00:21:05.120
So we've got
misinformation, we've

00:21:05.120 --> 00:21:07.130
got the social
engineering, and what

00:21:07.130 --> 00:21:10.730
I call covert crowdsourcing--
so trying to get people

00:21:10.730 --> 00:21:13.370
into those echo chambers on
the different social media

00:21:13.370 --> 00:21:16.760
platforms and trying
to incite basically

00:21:16.760 --> 00:21:20.730
either positive or negative
emotions around certain topics.

00:21:20.730 --> 00:21:24.560
And then we also have this
misplaced faith in technology.

00:21:24.560 --> 00:21:26.960
So I don't know how
many of you spend time

00:21:26.960 --> 00:21:28.670
in security operations center.

00:21:28.670 --> 00:21:30.210
I've spent more
hours than I care to

00:21:30.210 --> 00:21:31.460
in security operations center.

00:21:31.460 --> 00:21:33.180
I know Heather as well.

00:21:33.180 --> 00:21:34.820
And so these
statistics are pretty

00:21:34.820 --> 00:21:36.740
staggering given
the amount of money

00:21:36.740 --> 00:21:39.140
we have spent on
security technology.

00:21:39.140 --> 00:21:43.250
So let's kind of just peel
back a little bit on these.

00:21:43.250 --> 00:21:47.610
56% of all alerts that go into
a security operations center

00:21:47.610 --> 00:21:51.020
are investigated, which
means that 44% are not even

00:21:51.020 --> 00:21:54.440
looked at at all because there's
just not enough time and talent

00:21:54.440 --> 00:21:56.210
to be able to run those down.

00:21:56.210 --> 00:22:01.000
And of those 56% alerts that
were actually looked at,

00:22:01.000 --> 00:22:04.060
only 28% are deemed legitimate.

00:22:04.060 --> 00:22:07.380
So the rest are just noise.

00:22:07.380 --> 00:22:11.690
72% are just noise.

00:22:11.690 --> 00:22:14.930
And then out of that smaller
subset now-- so remember,

00:22:14.930 --> 00:22:18.250
we went from 56% to 28%.

00:22:18.250 --> 00:22:25.100
So out of that 28%, only 46% of
those actually get remediated.

00:22:25.100 --> 00:22:29.930
Do we wonder why we have
the data breaches we do?

00:22:29.930 --> 00:22:33.350
Do we wonder why
our infrastructure,

00:22:33.350 --> 00:22:37.730
our cybersecurity resiliency
for companies is at risk?

00:22:37.730 --> 00:22:39.950
Do we wonder why
it's time to start

00:22:39.950 --> 00:22:44.630
naming the human something else
other than, they're the weakest

00:22:44.630 --> 00:22:45.590
link?

00:22:45.590 --> 00:22:49.380
We have to change
how we focus on this.

00:22:49.380 --> 00:22:52.080
Case in point, the elections.

00:22:52.080 --> 00:22:54.550
That better have been
our tsunami warning.

00:22:54.550 --> 00:22:57.450
I feel like a lot of times, the
data breaches that we have--

00:22:57.450 --> 00:22:59.370
we get excited
about it-- sort of

00:22:59.370 --> 00:23:02.640
like waking up really early in
the morning to go do something,

00:23:02.640 --> 00:23:04.880
and then somebody
hits the snooze alarm

00:23:04.880 --> 00:23:06.450
and goes back to sleep.

00:23:06.450 --> 00:23:08.670
We're all out of snooze alarms.

00:23:08.670 --> 00:23:11.220
And if Equifax
didn't do it for you,

00:23:11.220 --> 00:23:13.980
the early warning signs--
that tsunami bell going off

00:23:13.980 --> 00:23:16.020
with the elections
absolutely should.

00:23:16.020 --> 00:23:17.500
Because it's not
just in America.

00:23:17.500 --> 00:23:18.842
It's in other places.

00:23:18.842 --> 00:23:21.300
So let's talk about my point
of view on how I look at this.

00:23:21.300 --> 00:23:23.430
And I welcome any
questions, comments

00:23:23.430 --> 00:23:26.044
on this during the Q&amp;A portion.

00:23:26.044 --> 00:23:27.960
So I look at this in
kind of three components.

00:23:27.960 --> 00:23:31.740
And the first one being is the
voter registration databases.

00:23:31.740 --> 00:23:35.310
We know for a fact that those
were targeted by hackers.

00:23:35.310 --> 00:23:39.270
We know that the
state of Illinois

00:23:39.270 --> 00:23:41.400
had to take their voter
registration database

00:23:41.400 --> 00:23:44.250
offline for weeks
during the summer

00:23:44.250 --> 00:23:47.950
leading up to the
presidential election cycle,.

00:23:47.950 --> 00:23:50.940
They had had an incident, and
they felt the best thing to do

00:23:50.940 --> 00:23:53.850
was to take it offline
to remediate the incident

00:23:53.850 --> 00:23:55.290
before they came online.

00:23:55.290 --> 00:23:57.720
Did that impact anybody's
ability to vote?

00:23:57.720 --> 00:23:59.730
I don't know if it did or not.

00:23:59.730 --> 00:24:02.370
But I know during those weeks,
getting a voter registration

00:24:02.370 --> 00:24:04.350
and if you were
somebody new to Illinois

00:24:04.350 --> 00:24:07.430
was not easy to do
while that was down.

00:24:07.430 --> 00:24:09.930
So you have the voter
registration databases.

00:24:09.930 --> 00:24:14.010
You also have the polling
booths themselves.

00:24:14.010 --> 00:24:16.980
Now nobody has said that they
have found evidence of somebody

00:24:16.980 --> 00:24:20.046
went in and voted for one
person and, on the back end,

00:24:20.046 --> 00:24:21.420
a different person
was voted for.

00:24:21.420 --> 00:24:23.130
Nobody has said that yet.

00:24:23.130 --> 00:24:26.040
But ethical hackers
at Black Hat this year

00:24:26.040 --> 00:24:29.850
said, if I have proximity
and I have time,

00:24:29.850 --> 00:24:32.310
I can absolutely do just that.

00:24:32.310 --> 00:24:35.270
And you may or may not know
this, but at the state level,

00:24:35.270 --> 00:24:38.620
not only does every state get a
chance to do this differently,

00:24:38.620 --> 00:24:40.980
the counties and precincts
within those states

00:24:40.980 --> 00:24:42.870
may also do it differently.

00:24:42.870 --> 00:24:44.670
And up until this
election cycle,

00:24:44.670 --> 00:24:49.470
there was a race to go to the
electronic only with no paper

00:24:49.470 --> 00:24:50.529
trail for audit.

00:24:50.529 --> 00:24:52.320
I don't know about you,
I think that sounds

00:24:52.320 --> 00:24:53.340
like a really bad idea.

00:24:53.340 --> 00:24:56.160
I think we need a
trust-by-verify process here.

00:24:56.160 --> 00:24:58.320
And really smart people
are working on this problem

00:24:58.320 --> 00:25:01.020
to make sure, from a voter
registration database

00:25:01.020 --> 00:25:03.630
perspective, our
data is more secure,

00:25:03.630 --> 00:25:06.480
but this has to be solved
at the state level.

00:25:06.480 --> 00:25:09.750
Lots of really smart people are
working on the actual polling

00:25:09.750 --> 00:25:11.490
booths themselves
and making sure

00:25:11.490 --> 00:25:15.480
that we don't allow proximity
and we don't allow time

00:25:15.480 --> 00:25:18.460
because somebody with
motive could do that.

00:25:18.460 --> 00:25:21.364
And then the third piece
is what I talked about,

00:25:21.364 --> 00:25:23.280
which is our new domain
we need to be worrying

00:25:23.280 --> 00:25:26.370
about in security, which
is the whole social media

00:25:26.370 --> 00:25:29.130
and our interconnectedness
on the internet domain

00:25:29.130 --> 00:25:31.020
that needs to be thought
about differently.

00:25:31.020 --> 00:25:33.660
I'm just going to show you
a couple of quick headlines

00:25:33.660 --> 00:25:36.080
that have been in
the news recently.

00:25:36.080 --> 00:25:37.700
And it's every company.

00:25:37.700 --> 00:25:40.080
There is no one
company at fault here,

00:25:40.080 --> 00:25:41.550
but this better be
our wake-up call

00:25:41.550 --> 00:25:45.480
for how we think about what
happened during this election

00:25:45.480 --> 00:25:46.260
cycle.

00:25:46.260 --> 00:25:47.220
Now don't get me wrong.

00:25:47.220 --> 00:25:50.160
Political espionage
has been around

00:25:50.160 --> 00:25:52.740
since they were two
human beings on earth.

00:25:52.740 --> 00:25:54.630
So that's recorded history.

00:25:54.630 --> 00:25:59.730
We know that propaganda has
been around for all of mankind.

00:25:59.730 --> 00:26:04.040
But what happened this
particular cycle, both overseas

00:26:04.040 --> 00:26:09.230
and here in America, was being
able to produce propaganda,

00:26:09.230 --> 00:26:13.130
to push propaganda, leverage
these social media platforms

00:26:13.130 --> 00:26:16.250
that have been
designed to serve me

00:26:16.250 --> 00:26:19.400
and to give me things that
help me and assist me,

00:26:19.400 --> 00:26:22.600
which means they know my
likes and preferences--

00:26:22.600 --> 00:26:25.130
and because they do that,
these social media platforms

00:26:25.130 --> 00:26:27.620
were taken advantage of.

00:26:27.620 --> 00:26:30.170
And they were able to,
at a speed never seen

00:26:30.170 --> 00:26:34.940
before in the history of
pushing political propaganda,

00:26:34.940 --> 00:26:37.880
not only push it out but to
be able to see in real time

00:26:37.880 --> 00:26:39.560
whether or not they
had an impact on you

00:26:39.560 --> 00:26:44.406
and me based on likes, based
on shares, based on posts.

00:26:44.406 --> 00:26:45.530
They never had that before.

00:26:45.530 --> 00:26:47.320
They didn't know if
it was working or not.

00:26:47.320 --> 00:26:48.985
They had to put
boots on the ground,

00:26:48.985 --> 00:26:51.110
and they had to see whether
or not their grassroots

00:26:51.110 --> 00:26:53.040
campaign was working.

00:26:53.040 --> 00:26:55.070
So we have never
seen what was done

00:26:55.070 --> 00:26:58.740
at the speed and scale in which
it was done, not only to us,

00:26:58.740 --> 00:27:01.400
but the elections
going on overseas.

00:27:01.400 --> 00:27:03.320
And Google has recently
come forward and said,

00:27:03.320 --> 00:27:05.540
you've done your own
research, and you

00:27:05.540 --> 00:27:08.107
are taking this very seriously.

00:27:08.107 --> 00:27:09.440
There's actually a proposed law.

00:27:09.440 --> 00:27:12.110
And I always say, be careful
about new proposed laws,

00:27:12.110 --> 00:27:15.690
because they typically
are not going to stop

00:27:15.690 --> 00:27:16.930
bad things from happening.

00:27:16.930 --> 00:27:19.471
And in some cases, they're going
to create a situation that's

00:27:19.471 --> 00:27:23.405
so expensive for you to comply
with that it kind of loses

00:27:23.405 --> 00:27:24.780
the spirit in
which it was meant.

00:27:24.780 --> 00:27:29.640
But there is a law around
sort of the safety of ads

00:27:29.640 --> 00:27:31.710
in the political
cycle act that's

00:27:31.710 --> 00:27:34.740
being looked at on
the Hill right now.

00:27:34.740 --> 00:27:36.720
Let's bring it back
to the humans, though.

00:27:36.720 --> 00:27:41.010
So if you remember WannaCry,
which was really bad,

00:27:41.010 --> 00:27:42.510
especially for the UK.

00:27:42.510 --> 00:27:46.160
I was actually in London
the day WannaCry hit.

00:27:46.160 --> 00:27:50.030
And what struck me was,
this was different.

00:27:50.030 --> 00:27:52.280
Because typically,
ransomware is all about,

00:27:52.280 --> 00:27:55.430
how much bitcoin can I
get out of the victim,

00:27:55.430 --> 00:27:59.880
and how much havoc can I
wreak on them in the meantime?

00:27:59.880 --> 00:28:01.520
This was different.

00:28:01.520 --> 00:28:05.540
People showed up for
surgery and were told,

00:28:05.540 --> 00:28:08.450
I can't operate on you
today because we're

00:28:08.450 --> 00:28:10.040
under a ransomware attack.

00:28:10.040 --> 00:28:13.920
People showed up sick and
needing prescriptions,

00:28:13.920 --> 00:28:18.610
and they were told, we can't
write you a prescription today.

00:28:18.610 --> 00:28:19.720
That, to me, is--

00:28:19.720 --> 00:28:22.060
that's where this is not
about how much bitcoin

00:28:22.060 --> 00:28:23.890
did these guys get away with.

00:28:23.890 --> 00:28:29.700
But at this point, I think
human safety trumps security.

00:28:29.700 --> 00:28:33.180
And this is where we have to
be thinking about design a lot

00:28:33.180 --> 00:28:34.450
differently.

00:28:34.450 --> 00:28:36.927
And so for my Monty
Python fans, this

00:28:36.927 --> 00:28:38.760
is where I'm throwing
the holy hand grenade.

00:28:38.760 --> 00:28:40.730
Because we've been
doing security wrong,

00:28:40.730 --> 00:28:43.590
and we need to fix how
we're focusing on this.

00:28:43.590 --> 00:28:45.141
So what are some
lessons learned?

00:28:45.141 --> 00:28:46.890
And I don't know if
this, this is actually

00:28:46.890 --> 00:28:48.300
a picture of the White
House flower shop.

00:28:48.300 --> 00:28:49.091
Isn't it beautiful?

00:28:49.091 --> 00:28:53.190
So after all that dark talk,
it's time for a zen moment.

00:28:53.190 --> 00:28:56.130
And this is the beautiful
White House flower shop.

00:28:56.130 --> 00:28:57.900
Any Downtown Abbey fans--

00:28:57.900 --> 00:29:00.960
it's very much like that--
sort of the usher's office

00:29:00.960 --> 00:29:02.940
underneath the White
House that keeps

00:29:02.940 --> 00:29:06.330
that sense of history,
and protocol, and class,

00:29:06.330 --> 00:29:07.110
and elegance.

00:29:07.110 --> 00:29:09.600
And I remember when I
went into the White House

00:29:09.600 --> 00:29:11.100
and I did my walk
about-- so there's

00:29:11.100 --> 00:29:13.110
13 components that
make up the Executive

00:29:13.110 --> 00:29:14.370
Office of the President.

00:29:14.370 --> 00:29:16.380
And I went into the
White House flower shop,

00:29:16.380 --> 00:29:18.030
and it was just so beautiful.

00:29:18.030 --> 00:29:20.130
And I noticed that as she
was making these flower

00:29:20.130 --> 00:29:23.760
arrangements, they had barcodes
on every single flower.

00:29:23.760 --> 00:29:27.030
And she would scan the
flower with the barcode.

00:29:27.030 --> 00:29:29.680
She would cut it off and put
in the flower arrangement.

00:29:29.680 --> 00:29:31.346
And I thought, well,
that's interesting.

00:29:31.346 --> 00:29:33.100
I'm not really sure
what that's all about.

00:29:33.100 --> 00:29:34.410
So I go into the kitchen,
and they're getting

00:29:34.410 --> 00:29:35.610
ready to make a big dinner.

00:29:35.610 --> 00:29:38.280
And I notice that the chicken
breasts, and the pork chops,

00:29:38.280 --> 00:29:39.450
and the paper towels--

00:29:39.450 --> 00:29:40.500
they're all barcoded.

00:29:40.500 --> 00:29:43.407
And before they get
used, they're scanned.

00:29:43.407 --> 00:29:45.990
Barcodes are removed, and they
move on and what they're doing.

00:29:45.990 --> 00:29:49.800
I'm like, OK, I've read a lot
of Brad Thor novels and Vince

00:29:49.800 --> 00:29:50.460
Flynn novels.

00:29:50.460 --> 00:29:52.052
I think I know
what's going on here.

00:29:52.052 --> 00:29:53.760
It's like to make sure
there's no anthrax

00:29:53.760 --> 00:29:55.051
poisoning in everything, right?

00:29:55.051 --> 00:29:57.687
So it's not like, with love from
Russia or something like that.

00:29:57.687 --> 00:29:59.520
So I go up to somebody
in the usher's office

00:29:59.520 --> 00:30:01.860
and I said, what's going
on here with the barcodes?

00:30:01.860 --> 00:30:02.500
I think I know.

00:30:02.500 --> 00:30:04.041
And he says, what
do you think it is?

00:30:04.041 --> 00:30:06.242
And I said, it's to make
sure it's not poisoned.

00:30:06.242 --> 00:30:08.200
And he said, no, it
definitely helps with that,

00:30:08.200 --> 00:30:09.820
but that's not why.

00:30:09.820 --> 00:30:11.550
And I said, OK, oh, I know--

00:30:11.550 --> 00:30:14.130
like if Queen Mum were here,
you wouldn't want to run out

00:30:14.130 --> 00:30:15.072
of pork chops, right?

00:30:15.072 --> 00:30:16.030
That'd be embarrassing.

00:30:16.030 --> 00:30:18.240
You can't run to the
closest grocery store

00:30:18.240 --> 00:30:19.406
and get pork chops.

00:30:19.406 --> 00:30:20.280
So that's what it is.

00:30:20.280 --> 00:30:23.290
It's to make sure-- from
a supply chain standpoint?

00:30:23.290 --> 00:30:24.970
And he said, well,
it helps with that,

00:30:24.970 --> 00:30:26.652
but that's not the reason why.

00:30:26.652 --> 00:30:27.860
And I said, well, what is it?

00:30:27.860 --> 00:30:30.750
And he said, well, it has
to do with appropriations.

00:30:30.750 --> 00:30:34.170
Because you see, whoever's
going to eat that pork chop,

00:30:34.170 --> 00:30:37.950
if it's a political dinner
versus an international head

00:30:37.950 --> 00:30:40.330
of state visiting, it's a
different bucket of money,

00:30:40.330 --> 00:30:42.580
and we have to charge it to
the right bucket of money.

00:30:42.580 --> 00:30:44.830
Hey, this is your tax dollars
at work for those of you

00:30:44.830 --> 00:30:46.290
who are Americans here, OK?

00:30:46.290 --> 00:30:48.290
Not making this up.

00:30:48.290 --> 00:30:50.730
And so they had to scan it
against the buckets of money.

00:30:50.730 --> 00:30:52.830
So whoever was enjoying
the flower arrangement,

00:30:52.830 --> 00:30:55.410
we had to make sure the
right bucket of money

00:30:55.410 --> 00:30:58.555
went to pay for those flowers.

00:30:58.555 --> 00:31:00.180
So we were doing the
right thing there,

00:31:00.180 --> 00:31:05.090
but I ask you, when you think
about the humans and the humans

00:31:05.090 --> 00:31:07.430
involved in this, and you
think about the data--

00:31:07.430 --> 00:31:10.370
and all data is
not created equal--

00:31:10.370 --> 00:31:13.820
so if you think about protecting
data and putting stricter

00:31:13.820 --> 00:31:17.600
standards on some and
easier standards on other,

00:31:17.600 --> 00:31:19.760
when you compare the
number of chicken breasts

00:31:19.760 --> 00:31:21.800
and Baby's-breaths
scanned that day versus

00:31:21.800 --> 00:31:25.010
the president's schedule, which
has everyone he's meeting with,

00:31:25.010 --> 00:31:28.070
the Secret Service agents down
to the second where he's going

00:31:28.070 --> 00:31:32.310
to turn a corner, which
one's more valuable?

00:31:32.310 --> 00:31:34.180
President's schedule.

00:31:34.180 --> 00:31:36.180
The other thing I want
you to be thinking about,

00:31:36.180 --> 00:31:39.140
too, is that in my
walkabouts, I went and met

00:31:39.140 --> 00:31:40.640
with one of the
other components.

00:31:40.640 --> 00:31:42.056
And one of these
components travel

00:31:42.056 --> 00:31:43.580
with the president a lot.

00:31:43.580 --> 00:31:46.190
And most of what they did was
not on the classified systems,

00:31:46.190 --> 00:31:48.230
but we had a rule that
more than two pieces

00:31:48.230 --> 00:31:52.266
of unclassified data, basically,
created a classified situation.

00:31:52.266 --> 00:31:53.390
It was just very sensitive.

00:31:53.390 --> 00:31:56.350
Everything at the White House
is very sensitive information.

00:31:56.350 --> 00:31:58.659
And so as I'm meeting with
them, I said to them--

00:31:58.659 --> 00:32:00.200
I was just asking
everybody, is there

00:32:00.200 --> 00:32:02.830
anything we do that's
not working for you?

00:32:02.830 --> 00:32:04.400
And so I asked
them, I know you're

00:32:04.400 --> 00:32:05.930
under a lot of tight
deadlines when you're

00:32:05.930 --> 00:32:07.280
on the road with the president.

00:32:07.280 --> 00:32:10.190
Is there anything we ask you
to do in the name of security

00:32:10.190 --> 00:32:12.650
or in the name of logistics
that makes it hard

00:32:12.650 --> 00:32:14.270
for you to do your job?

00:32:14.270 --> 00:32:15.260
And they said, sure.

00:32:15.260 --> 00:32:16.340
And I said, well,
what do you do?

00:32:16.340 --> 00:32:17.780
Because you have these
really tight deadlines.

00:32:17.780 --> 00:32:19.219
They said, oh,
it's really simple.

00:32:19.219 --> 00:32:21.260
We either take a picture
of it or we print screen

00:32:21.260 --> 00:32:24.650
and we take it with us
to foreign countries.

00:32:24.650 --> 00:32:27.140
And to which I kind of
like had that moment--

00:32:27.140 --> 00:32:30.440
like that
pit-in-your-stomach moment.

00:32:30.440 --> 00:32:33.870
And the old me from financial
services who was all about,

00:32:33.870 --> 00:32:34.850
it's about training.

00:32:34.850 --> 00:32:37.150
It's just about
explaining to you--

00:32:37.150 --> 00:32:39.597
wanted to come back to the top.

00:32:39.597 --> 00:32:41.180
But the new me who
said, I'm not going

00:32:41.180 --> 00:32:42.510
to blame the human anymore.

00:32:42.510 --> 00:32:44.593
I'm not going to say the
human's the weakest link.

00:32:44.593 --> 00:32:45.710
I'm going to say I am.

00:32:45.710 --> 00:32:47.700
These are my designs.

00:32:47.700 --> 00:32:49.790
This is our team
doing the development.

00:32:49.790 --> 00:32:51.810
I own this.

00:32:51.810 --> 00:32:53.870
And so the new me listened.

00:32:53.870 --> 00:32:55.945
And the new me said, why
don't we get together

00:32:55.945 --> 00:32:59.750
and why don't you show
us what's going on here?

00:32:59.750 --> 00:33:02.750
Because I realize I
lost sight of data

00:33:02.750 --> 00:33:05.280
because I had a bad design.

00:33:05.280 --> 00:33:08.930
And so I want to push back
on you a little bit of--

00:33:08.930 --> 00:33:10.250
always be thinking.

00:33:10.250 --> 00:33:12.410
It's not just feature
and functionality

00:33:12.410 --> 00:33:14.180
from the user experience.

00:33:14.180 --> 00:33:15.890
Never lose that.

00:33:15.890 --> 00:33:18.480
Always have that at
the front of your mind.

00:33:18.480 --> 00:33:21.740
But I need to push
back, and I need to say,

00:33:21.740 --> 00:33:25.014
the weakest link is
actually in development.

00:33:25.014 --> 00:33:26.930
We need to stop relying
on the human for this.

00:33:26.930 --> 00:33:29.062
It's failing us
every single time.

00:33:29.062 --> 00:33:30.770
And then the last
thing that I've learned

00:33:30.770 --> 00:33:33.050
is you really need
a kill switch.

00:33:33.050 --> 00:33:34.020
And so Barbie--

00:33:34.020 --> 00:33:35.395
I don't know how
many of you know

00:33:35.395 --> 00:33:37.880
about talking
Barbie, but Barbie,

00:33:37.880 --> 00:33:38.922
when she first came out--

00:33:38.922 --> 00:33:41.421
most of these issues are fixed
that I'm going to talk to you

00:33:41.421 --> 00:33:44.270
about-- but when she first came
out, she had computer viruses,

00:33:44.270 --> 00:33:46.670
and she also talked
to any Wi-Fi network--

00:33:46.670 --> 00:33:50.000
not just your home network but
any that said Barbie in it--

00:33:50.000 --> 00:33:51.890
like wicked Barbie,
evil Barbie--

00:33:51.890 --> 00:33:53.977
like networks you
shouldn't talk to.

00:33:53.977 --> 00:33:55.560
And I was having one
of those moments.

00:33:55.560 --> 00:33:57.435
I was the kitchen, and
I heard my little girl

00:33:57.435 --> 00:33:59.120
Maeve say to her
older brothers, I

00:33:59.120 --> 00:34:00.860
think I'm going to
ask mama for a talking

00:34:00.860 --> 00:34:02.940
Barbie for my birthday.

00:34:02.940 --> 00:34:06.290
And so my middle one says,
well, how does she work, Maeve?

00:34:06.290 --> 00:34:08.960
And she says, well,
according to the commercial,

00:34:08.960 --> 00:34:11.510
I will talk to her,
she will listen to me,

00:34:11.510 --> 00:34:14.179
and she'll actually answer
me back-- like in real time,

00:34:14.179 --> 00:34:14.870
like no pause.

00:34:14.870 --> 00:34:16.630
She'll answer me back.

00:34:16.630 --> 00:34:18.546
And my oldest one
says, I don't think

00:34:18.546 --> 00:34:19.920
mama's going to
let you have that

00:34:19.920 --> 00:34:22.820
because I'm assuming she's
probably talking to the cloud.

00:34:22.820 --> 00:34:25.280
You're probably talking
to someone in the cloud.

00:34:25.280 --> 00:34:27.679
And my middle one says,
yeah, and some rando--

00:34:27.679 --> 00:34:29.900
and so if you don't have
millennials in your life--

00:34:29.900 --> 00:34:31.233
you know what a rando is, right?

00:34:31.233 --> 00:34:32.659
It's random people.

00:34:32.659 --> 00:34:34.850
So some rando
who's going to help

00:34:34.850 --> 00:34:37.159
the artificial intelligence
interpret everything

00:34:37.159 --> 00:34:39.101
you've said to give
you a good answer back.

00:34:39.101 --> 00:34:40.850
And she said, yeah,
you're probably right.

00:34:40.850 --> 00:34:43.310
I'm going to ask for an
Easy-Bake Oven instead.

00:34:43.310 --> 00:34:45.080
But my point in bringing
up Talking Barbie

00:34:45.080 --> 00:34:47.348
is, when she had those
computer viruses,

00:34:47.348 --> 00:34:49.639
when she was talking to my
Wi-Fi networks she shouldn't

00:34:49.639 --> 00:34:52.580
be talking to because you don't
know if they're trusted or not,

00:34:52.580 --> 00:34:54.620
you could turn off her
internet connection

00:34:54.620 --> 00:34:57.130
and still play with Barbie.

00:34:57.130 --> 00:35:00.100
Just like-- I remember reading
when the NEST had a software

00:35:00.100 --> 00:35:02.830
glitch and it wasn't
charging the battery--

00:35:02.830 --> 00:35:05.080
and so people on the local
news were like, oh my gosh.

00:35:05.080 --> 00:35:05.829
It's getting cold.

00:35:05.829 --> 00:35:07.030
What am I going to do?

00:35:07.030 --> 00:35:08.620
My NEST thermostat's
not working.

00:35:08.620 --> 00:35:11.740
And I'm thinking, you do know
you can walk to the furnace

00:35:11.740 --> 00:35:12.760
and flip it on, right?

00:35:12.760 --> 00:35:13.510
You do know that?

00:35:13.510 --> 00:35:15.580
Like, the thermostat's
just a helpful thing?

00:35:15.580 --> 00:35:17.999
And so that kill switch
to me is so vitally

00:35:17.999 --> 00:35:19.540
important with what's
going on today.

00:35:19.540 --> 00:35:23.650
If you think about the incidents
like WannaCry or Equifax--

00:35:23.650 --> 00:35:26.270
and the other PC need to
be asking yourself, though,

00:35:26.270 --> 00:35:29.350
is, when do I flip a
kill switch, right?

00:35:29.350 --> 00:35:30.730
So when do I flip it?

00:35:30.730 --> 00:35:33.730
What limited functionality
will be left?

00:35:33.730 --> 00:35:37.600
What are the rules of
engagement for this kill switch?

00:35:37.600 --> 00:35:40.670
And how do I educate
people to know it's there?

00:35:40.670 --> 00:35:42.800
So the next time-- if
somebody says, look,

00:35:42.800 --> 00:35:44.590
there's an Internet
of Things botnet--

00:35:44.590 --> 00:35:46.840
right, so we were talking
about REAPER last week

00:35:46.840 --> 00:35:51.040
or whatever it is, then you
have an easy, seamless way

00:35:51.040 --> 00:35:53.230
with your customers, whether
they're your business

00:35:53.230 --> 00:35:56.050
customers or your
consumer customers,

00:35:56.050 --> 00:35:59.770
to communicate with them,
everything's going to be OK.

00:35:59.770 --> 00:36:03.880
Here's the kill switch
in case it's not.

00:36:03.880 --> 00:36:06.370
So if you admit all
security's defeatable,

00:36:06.370 --> 00:36:08.740
if you think about the
adversarial targeting,

00:36:08.740 --> 00:36:12.160
like we did on Hunted-- because
the bad guys do this, too,

00:36:12.160 --> 00:36:13.750
if you have this
aggressive offensive

00:36:13.750 --> 00:36:16.291
and you're thinking ahead about,
how do I have a kill switch?

00:36:16.291 --> 00:36:18.070
How do I design for
you so you're not

00:36:18.070 --> 00:36:20.650
having to worry about
this and plan ahead,

00:36:20.650 --> 00:36:22.760
you're going to be
so much better off.

00:36:22.760 --> 00:36:24.814
So I want to leave you
with some new rules.

00:36:24.814 --> 00:36:26.980
And the first one is-- you
probably have never heard

00:36:26.980 --> 00:36:30.160
a security person say this,
but I want you to think about

00:36:30.160 --> 00:36:31.850
your development--

00:36:31.850 --> 00:36:35.304
where you're putting a warm hug
around the user for security.

00:36:35.304 --> 00:36:37.120
So where it's almost
like they don't even

00:36:37.120 --> 00:36:38.360
have to think about it.

00:36:38.360 --> 00:36:42.490
That's my timer to
get into our Q&amp;A here.

00:36:42.490 --> 00:36:45.640
New domains to protect-- so it's
not just the data, the devices,

00:36:45.640 --> 00:36:47.140
the hardware, the software.

00:36:47.140 --> 00:36:50.020
It's also social media,
and then the fact

00:36:50.020 --> 00:36:53.340
that there is no
perimeter to secure.

00:36:53.340 --> 00:36:57.300
Also, for those of you who are
interested in kind of diversity

00:36:57.300 --> 00:37:00.177
in STEM, we do have a
LinkedIn conversation

00:37:00.177 --> 00:37:01.260
called "Help A Sister Up."

00:37:01.260 --> 00:37:03.600
If you're interested in
it, it's just up there

00:37:03.600 --> 00:37:05.502
if you want to reach
out to us that way.

00:37:05.502 --> 00:37:06.960
And there's my
contact information.

00:37:06.960 --> 00:37:10.080
And with that let's
go to our Q&amp;A session.

00:37:10.080 --> 00:37:10.830
HOST: Great.

00:37:10.830 --> 00:37:12.370
So for those of you
in the audience,

00:37:12.370 --> 00:37:14.328
do you think of your
questions, but we're going

00:37:14.328 --> 00:37:16.140
to take a Dory question first.

00:37:16.140 --> 00:37:18.030
And that question
is, could you tell

00:37:18.030 --> 00:37:21.330
us more about how you became
interested in this kind of work

00:37:21.330 --> 00:37:23.160
and your journey into the field?

00:37:23.160 --> 00:37:24.365
THERESA PAYTON: Sure.

00:37:24.365 --> 00:37:25.740
And this is
something Sarah and I

00:37:25.740 --> 00:37:27.330
were talking about
a little bit, which

00:37:27.330 --> 00:37:30.300
I say I'm very blessed
that security actually

00:37:30.300 --> 00:37:31.860
came and found me.

00:37:31.860 --> 00:37:34.470
When I first came out
of graduate school

00:37:34.470 --> 00:37:37.050
at University of
Virginia, my vision

00:37:37.050 --> 00:37:40.510
was, I was going to work
on cutting-edge technology,

00:37:40.510 --> 00:37:43.200
innovative, things that
hadn't been dreamed of yet,

00:37:43.200 --> 00:37:45.010
and that's what I
was going to do.

00:37:45.010 --> 00:37:48.030
And then I married somebody
who was in the Navy,

00:37:48.030 --> 00:37:50.200
and we got stationed in
Jacksonville, Florida.

00:37:50.200 --> 00:37:52.170
And I went to work in banking.

00:37:52.170 --> 00:37:54.180
And I actually got to be--

00:37:54.180 --> 00:37:55.830
I got hired into a group.

00:37:55.830 --> 00:37:57.720
They kind of made
a role around me.

00:37:57.720 --> 00:38:01.080
And I was able to, in
addition to my day duties

00:38:01.080 --> 00:38:03.600
as a programmer
in trouble support

00:38:03.600 --> 00:38:07.470
and helping people with
their end-user computing,

00:38:07.470 --> 00:38:10.260
I was allowed to work on
innovative technologies.

00:38:10.260 --> 00:38:12.457
And in doing that,
for anybody who's

00:38:12.457 --> 00:38:14.790
worked with the financial
services industry, when you're

00:38:14.790 --> 00:38:16.206
on the leading
edge of technology,

00:38:16.206 --> 00:38:19.410
you're on the leading edge
of cybercrime, and money

00:38:19.410 --> 00:38:21.660
launderers, and terrorists.

00:38:21.660 --> 00:38:24.630
And that's really what
got me kind of passionate

00:38:24.630 --> 00:38:26.730
and fired up around
cybersecurity but,

00:38:26.730 --> 00:38:30.150
at the same time, creating it
in such a way that you still

00:38:30.150 --> 00:38:32.020
love doing business
with the bank

00:38:32.020 --> 00:38:34.050
but that we were
fighting on your behalf

00:38:34.050 --> 00:38:36.240
to keep the fraudsters
out of your account.

00:38:36.240 --> 00:38:38.490
And it really just
cemented, for me,

00:38:38.490 --> 00:38:41.820
when I got the opportunity
to work at the White House.

00:38:41.820 --> 00:38:45.094
And the briefings-- you know,
the classified briefings-- you

00:38:45.094 --> 00:38:47.010
walk into that thinking
you've kind of seen it

00:38:47.010 --> 00:38:51.480
all in financial services, and
you walk into these briefings

00:38:51.480 --> 00:38:54.960
and realize, I was looking
into a keyhole in a tiny room,

00:38:54.960 --> 00:38:59.710
and I had no real idea about the
capabilities of the adversary.

00:38:59.710 --> 00:39:02.790
That's when I made my commitment
that however many years I

00:39:02.790 --> 00:39:06.030
had left on this earth to work,
that I would use it to fiercely

00:39:06.030 --> 00:39:08.220
defend people, and
companies, and the government

00:39:08.220 --> 00:39:10.270
and our allies from bad people.

00:39:12.940 --> 00:39:14.040
AUDIENCE: Hey--

00:39:14.040 --> 00:39:15.660
THERESA PAYTON: Oh,
and you get a book

00:39:15.660 --> 00:39:16.600
for asking the first question.

00:39:16.600 --> 00:39:19.016
- I haven't even asked it yet,
and I already get the book?

00:39:19.016 --> 00:39:20.150
This is so exciting.

00:39:20.150 --> 00:39:20.650
Thank you.

00:39:20.650 --> 00:39:22.690
So the question actually
relates directly

00:39:22.690 --> 00:39:24.440
to the title of your book.

00:39:24.440 --> 00:39:27.020
I'm on the federated
identity team here at Google.

00:39:27.020 --> 00:39:30.580
So I think a lot about people's
identities on the internet.

00:39:30.580 --> 00:39:34.310
And something your demo
tape made me think about

00:39:34.310 --> 00:39:38.680
was that a lot of the ways
that when people strengthen

00:39:38.680 --> 00:39:40.300
their internet
identity-- like when

00:39:40.300 --> 00:39:42.091
we think of the early
days of the internet,

00:39:42.091 --> 00:39:44.830
people had very
anonymous identities.

00:39:44.830 --> 00:39:46.480
And now, more and
more, especially

00:39:46.480 --> 00:39:48.280
with Google products,
we're giving you

00:39:48.280 --> 00:39:51.220
a stronger and stronger
presence online.

00:39:51.220 --> 00:39:52.600
And on the product
side, we think

00:39:52.600 --> 00:39:55.120
of a lot of ways that
can be helpful for you.

00:39:55.120 --> 00:39:57.110
And then this video
reminded me that

00:39:57.110 --> 00:39:59.369
to people and, particularly,
to law enforcement,

00:39:59.369 --> 00:40:01.660
there are a lot of ways that
having a stronger identity

00:40:01.660 --> 00:40:04.870
is really great for being
tracked, or censored,

00:40:04.870 --> 00:40:09.200
or any of these other really
bad security-related issues.

00:40:09.200 --> 00:40:14.020
So I was wondering if you had
any ideas for addressing that

00:40:14.020 --> 00:40:17.960
or any examples that
you've seen in your career

00:40:17.960 --> 00:40:19.710
where having a stronger
internet identity

00:40:19.710 --> 00:40:23.710
can actually make you safer from
something malicious-- maybe not

00:40:23.710 --> 00:40:27.857
a valid police investigation
but a not-so-valid police

00:40:27.857 --> 00:40:28.440
investigation.

00:40:28.440 --> 00:40:30.250
THERESA PAYTON: Yeah, I think--

00:40:30.250 --> 00:40:33.340
well, for example, we
have had situations

00:40:33.340 --> 00:40:37.570
with mistaken identity where
because of that kind of lack

00:40:37.570 --> 00:40:39.580
of clarity around
identity, you've

00:40:39.580 --> 00:40:43.052
had people wrongly accused and
having to clear their name--

00:40:43.052 --> 00:40:45.010
police knocking at their
door and they're like,

00:40:45.010 --> 00:40:45.940
it really wasn't me.

00:40:45.940 --> 00:40:47.410
You've got the wrong person.

00:40:47.410 --> 00:40:50.620
And so I do think in creating--

00:40:50.620 --> 00:40:54.190
what I would say is that I think
there's a lot in the product

00:40:54.190 --> 00:40:56.410
development that Google's
doing right on this, which

00:40:56.410 --> 00:41:00.220
is you're informing people
on what to opt in and opt out

00:41:00.220 --> 00:41:03.040
on on kind of the
identity management,

00:41:03.040 --> 00:41:05.970
and I think it can be
a really good thing.

00:41:05.970 --> 00:41:09.955
At the same time, it does
create a little bit of a--

00:41:09.955 --> 00:41:12.671
I'm in a conundrum
about it myself.

00:41:12.671 --> 00:41:14.920
Because when I think about--
especially the generation

00:41:14.920 --> 00:41:19.420
coming up, they're
questioning and learning,

00:41:19.420 --> 00:41:23.810
and they're treating it all
as a conversation online.

00:41:23.810 --> 00:41:26.290
And there's a generation
ahead of them--

00:41:26.290 --> 00:41:30.700
maybe multiple generations ahead
of them that once it's written,

00:41:30.700 --> 00:41:33.890
it's now almost like
that's a fact about you

00:41:33.890 --> 00:41:37.880
versus a conversation
around the dinner table.

00:41:37.880 --> 00:41:43.000
And so I worry for people who
want to leverage the internet

00:41:43.000 --> 00:41:45.340
to reach out to other people
who don't think like them

00:41:45.340 --> 00:41:48.550
to challenge their own
intellectual thought

00:41:48.550 --> 00:41:50.740
process on different topics--

00:41:50.740 --> 00:41:52.510
that it's going to
be held against them.

00:41:52.510 --> 00:41:54.010
And that's unfortunate.

00:41:54.010 --> 00:41:57.140
And so that, I think, to me--
that's the conundrum I'm in,

00:41:57.140 --> 00:42:00.820
which is, I would like to
see stronger identity online.

00:42:00.820 --> 00:42:04.180
I'd like to see
better identity access

00:42:04.180 --> 00:42:06.850
management for more
security and privacy based

00:42:06.850 --> 00:42:08.220
on opting in opting out.

00:42:08.220 --> 00:42:10.840
But at the same time,
I'm hesitant because I'm

00:42:10.840 --> 00:42:16.110
worried that in kind of having
that identity that follows you,

00:42:16.110 --> 00:42:19.120
you don't get to choose what
people see and don't see.

00:42:19.120 --> 00:42:20.789
And that's a conundrum for me.

00:42:20.789 --> 00:42:23.080
And I don't actually have a
good answer for you on that

00:42:23.080 --> 00:42:25.330
except for, keep pushing.

00:42:25.330 --> 00:42:28.720
Keep pushing in your product
design and the developers

00:42:28.720 --> 00:42:31.120
around, what are the
long term impacts

00:42:31.120 --> 00:42:35.050
on people for things potentially
following their identity?

00:42:35.050 --> 00:42:36.790
And can you get a new identity?

00:42:36.790 --> 00:42:40.510
Can you decide, like, I've
grown up now, and that's not me.

00:42:40.510 --> 00:42:42.370
And can you leave that behind?

00:42:42.370 --> 00:42:45.656
And for many of us who are
digital immigrants and not

00:42:45.656 --> 00:42:48.280
digital natives-- yeah, I'd like
to think I'm a digital native,

00:42:48.280 --> 00:42:51.324
but technically, based
on birth year, I'm not.

00:42:51.324 --> 00:42:53.240
But you know, I started
programming in school.

00:42:53.240 --> 00:42:55.090
So for me, I think that way.

00:42:55.090 --> 00:42:57.040
But when you think about
true digital natives,

00:42:57.040 --> 00:43:01.520
there's no on and off the web.

00:43:01.520 --> 00:43:05.005
And so for them, that's
what I worry about.

00:43:05.005 --> 00:43:05.630
Great question.

00:43:05.630 --> 00:43:06.380
AUDIENCE: Awesome.

00:43:06.380 --> 00:43:07.590
Thank you.

00:43:07.590 --> 00:43:08.570
HOST: Great.

00:43:08.570 --> 00:43:10.619
And our next question is,
what do you think the--

00:43:10.619 --> 00:43:12.410
or what do you see as
the biggest challenge

00:43:12.410 --> 00:43:15.710
right now with the
Internet of Things?

00:43:15.710 --> 00:43:17.480
- You know what's interesting?

00:43:17.480 --> 00:43:21.050
On the Internet of
Things, I've noticed

00:43:21.050 --> 00:43:23.030
there tends to be-- in
the security industry,

00:43:23.030 --> 00:43:25.550
they're so focused on,
we need to make sure

00:43:25.550 --> 00:43:27.690
that that device itself--
that's gotta be secure,

00:43:27.690 --> 00:43:29.700
and that's the problem.

00:43:29.700 --> 00:43:32.270
And I am actually
pushing back on that

00:43:32.270 --> 00:43:33.829
and saying, if you think about--

00:43:33.829 --> 00:43:35.870
I had a picture in the
presentation of the Tacoma

00:43:35.870 --> 00:43:38.000
Narrows Bridge from the 1940s.

00:43:38.000 --> 00:43:40.110
The Tacoma Narrows Bridge,
if you look it up--

00:43:40.110 --> 00:43:42.230
it was built out of
concrete and steel--

00:43:42.230 --> 00:43:46.260
independently very
strong materials.

00:43:46.260 --> 00:43:49.440
We didn't think about the
enterprise architecture enough,

00:43:49.440 --> 00:43:51.877
and it literally looked like
a piece of taffy pulling--

00:43:51.877 --> 00:43:53.710
thankfully nobody lost
their lives that day,

00:43:53.710 --> 00:43:55.800
but the bridge collapsed
under, I think,

00:43:55.800 --> 00:43:58.750
40-mile-an-hour winds shears.

00:43:58.750 --> 00:44:00.880
And so the Internet of
Things, to me, I think--

00:44:00.880 --> 00:44:04.930
the biggest concern for
me is we're so focused on,

00:44:04.930 --> 00:44:06.670
how do I get that
component secure.

00:44:06.670 --> 00:44:08.170
We're not actually
thinking about,

00:44:08.170 --> 00:44:13.000
how is that component part of a
bigger enterprise architecture?

00:44:13.000 --> 00:44:16.671
And how do we know when that
component is behaving badly?

00:44:16.671 --> 00:44:18.670
Either because a bad guy
took it over or there's

00:44:18.670 --> 00:44:20.510
something wrong with it.

00:44:20.510 --> 00:44:23.650
And how do we know when
that technology is obsolete?

00:44:23.650 --> 00:44:26.560
And because it's so embedded
in what we're doing,

00:44:26.560 --> 00:44:27.989
we don't even know it's there.

00:44:27.989 --> 00:44:30.280
So kind of another story--
it's not Internet of Things,

00:44:30.280 --> 00:44:34.810
but there was a house
where the phone started

00:44:34.810 --> 00:44:41.320
dialing a random number several
times a day for six weeks,

00:44:41.320 --> 00:44:45.040
and nobody could figure out
why the phone was doing that.

00:44:45.040 --> 00:44:48.480
And what they realized
was is the previous owners

00:44:48.480 --> 00:44:51.760
had a now not used oil tank.

00:44:51.760 --> 00:44:53.770
And technology had been
fitted on the oil tank

00:44:53.770 --> 00:44:57.880
that when it went under a
certain level of being full,

00:44:57.880 --> 00:45:00.160
it would automatically
dial the oil company, which

00:45:00.160 --> 00:45:02.260
is now no longer in business.

00:45:02.260 --> 00:45:04.700
Owners changed
hands on the house.

00:45:04.700 --> 00:45:06.550
So when the new
owners come in, they

00:45:06.550 --> 00:45:10.210
reconnect the line
for the house.

00:45:10.210 --> 00:45:13.540
And all of a
sudden, the oil tank

00:45:13.540 --> 00:45:15.390
is now calling the now defunct--

00:45:15.390 --> 00:45:17.410
and now, that number
belongs to somebody else.

00:45:17.410 --> 00:45:19.390
And it took them six
weeks to figure it out.

00:45:19.390 --> 00:45:21.871
And everybody can have a
big laugh, but at the time,

00:45:21.871 --> 00:45:23.620
people were just like,
I don't understand.

00:45:23.620 --> 00:45:25.161
Like, is there a
ghost in this house?

00:45:25.161 --> 00:45:26.630
Like what is going on?

00:45:26.630 --> 00:45:29.170
And I worry about that for
the Internet of Things--

00:45:29.170 --> 00:45:31.570
is that we've had
them so embedded,

00:45:31.570 --> 00:45:34.450
that as that technology
becomes obsolete,

00:45:34.450 --> 00:45:37.090
are we going to
remember it's there?

00:45:37.090 --> 00:45:39.220
They think actually
a lightning strike is

00:45:39.220 --> 00:45:41.230
what turned everything back on.

00:45:41.230 --> 00:45:43.510
So it's almost like it
rebooted the program.

00:45:43.510 --> 00:45:49.201
And so what happens when
we forget they're there?

00:45:49.201 --> 00:45:49.700
Yes?

00:45:49.700 --> 00:45:51.116
AUDIENCE: Thank
you for your talk.

00:45:51.116 --> 00:45:53.390
I work in user experience
for security and privacy.

00:45:53.390 --> 00:45:55.600
So I appreciate a
lot of what you said.

00:45:55.600 --> 00:45:57.430
What are the top
pieces of advice

00:45:57.430 --> 00:46:00.700
you would give a consumer today
to protect themselves online?

00:46:00.700 --> 00:46:02.480
- Sure, a couple of things.

00:46:02.480 --> 00:46:06.990
One is never use free Wi-Fi.

00:46:06.990 --> 00:46:11.790
And it is one of those things--
so I took our intern Stephen

00:46:11.790 --> 00:46:15.510
to a coffee shop in Charlotte,
which is a huge banking town.

00:46:15.510 --> 00:46:17.370
And I told him,
take your pineapple.

00:46:17.370 --> 00:46:17.965
Take your Mac.

00:46:17.965 --> 00:46:19.590
I'm going to take my
Pineapple, my Mac,

00:46:19.590 --> 00:46:21.280
and I'm going to hack
you and see how you do.

00:46:21.280 --> 00:46:23.696
And then, you're going to hack
me back and see how you do.

00:46:23.696 --> 00:46:26.520
And because we have this whole
moral ethics code at Fortalice,

00:46:26.520 --> 00:46:29.107
where we say, just because you
can doesn't mean you should,

00:46:29.107 --> 00:46:30.690
he said to me, ma'am,
how are we going

00:46:30.690 --> 00:46:32.130
to make sure we
don't accidentally

00:46:32.130 --> 00:46:33.885
hack other people
in the coffee shop?

00:46:33.885 --> 00:46:35.340
And I said it's very simple.

00:46:35.340 --> 00:46:36.923
What we're going to
do is, we're going

00:46:36.923 --> 00:46:39.330
to name our Wi-Fi
hotspot something

00:46:39.330 --> 00:46:40.896
nobody would ever connect to.

00:46:40.896 --> 00:46:43.020
So we're not going to name
it the coffee shop name,

00:46:43.020 --> 00:46:46.320
we're going to name it
something ridiculous.

00:46:46.320 --> 00:46:50.100
The first iteration I named it,
and I named it "fake Wi-Fi."

00:46:50.100 --> 00:46:53.190
And five people
connected within minutes.

00:46:53.190 --> 00:46:55.020
And so people's
traffic were coming by,

00:46:55.020 --> 00:46:56.215
and Stephen's getting upset.

00:46:56.215 --> 00:46:57.840
And I said, that's
OK, we'll unplug it.

00:46:57.840 --> 00:46:59.560
Stephen, I'm going
to let you name it.

00:46:59.560 --> 00:47:03.150
So he says no one will ever
connect to this network.

00:47:03.150 --> 00:47:05.490
And he calls it, "data stealer."

00:47:05.490 --> 00:47:06.887
And 10 people connected.

00:47:06.887 --> 00:47:08.970
And so my point in bringing
this up is, it's like,

00:47:08.970 --> 00:47:10.290
you have people who--

00:47:10.290 --> 00:47:12.542
I know data plans
are really expensive,

00:47:12.542 --> 00:47:15.000
and so they're trying to use
free Wi-Fi everywhere they go,

00:47:15.000 --> 00:47:17.790
and they don't really realize
that they need to be using

00:47:17.790 --> 00:47:20.550
a virtual private network in
addition to using that free

00:47:20.550 --> 00:47:22.290
Wi-Fi to help not--

00:47:22.290 --> 00:47:24.360
that doesn't block
100% of all bad things,

00:47:24.360 --> 00:47:26.370
but it sure helps a ton.

00:47:26.370 --> 00:47:29.100
So that would be the first
thing is-- get a really good VPN

00:47:29.100 --> 00:47:30.780
that you're really
comfortable with,

00:47:30.780 --> 00:47:33.390
use it everywhere you go,
especially when you go overseas

00:47:33.390 --> 00:47:36.630
on vacation, because that's a
really popular time for people

00:47:36.630 --> 00:47:38.250
to get hit.

00:47:38.250 --> 00:47:41.100
Don't use free Wi-Fi; but if
you have to, have that VPN.

00:47:41.100 --> 00:47:42.824
I also say segment your life's.

00:47:42.824 --> 00:47:45.240
So just like we talked about
network segmentation and data

00:47:45.240 --> 00:47:48.150
segmentation really
briefly, segment your life.

00:47:48.150 --> 00:47:51.720
Have one email address
that you use with your bank

00:47:51.720 --> 00:47:53.100
that you don't
use anywhere else.

00:47:53.100 --> 00:47:55.200
Have one with your health care
because health insurance fraud

00:47:55.200 --> 00:47:56.660
is really high right now.

00:47:56.660 --> 00:47:59.580
Have one ease for sensitive,
confidential e-mails.

00:47:59.580 --> 00:48:02.229
I hate email; but
sometimes, the person

00:48:02.229 --> 00:48:04.770
on the other end of the line--
the only thing they want to do

00:48:04.770 --> 00:48:06.570
is send me this
confidential email,

00:48:06.570 --> 00:48:11.790
so I personally, for that, use a
whole different email platform.

00:48:11.790 --> 00:48:16.020
Two-factor authentication-- that
is annoying to most consumers.

00:48:16.020 --> 00:48:16.950
Just understand that.

00:48:16.950 --> 00:48:17.820
They don't like it.

00:48:17.820 --> 00:48:19.050
They don't want to do it.

00:48:19.050 --> 00:48:23.430
But if you're
somebody who's online

00:48:23.430 --> 00:48:26.790
and you've got that particular
email tied to other things,

00:48:26.790 --> 00:48:29.370
you need two-factor
authentication.

00:48:29.370 --> 00:48:32.370
And then the last
thing would be,

00:48:32.370 --> 00:48:36.450
as it relates to any of
the major issues that

00:48:36.450 --> 00:48:41.430
are going on in the world and in
this country, do your homework.

00:48:41.430 --> 00:48:45.440
Don't allow things that are
posted on your friend's walls

00:48:45.440 --> 00:48:46.820
and on your wall.

00:48:46.820 --> 00:48:49.880
Don't allow that to create
extreme emotions for you,

00:48:49.880 --> 00:48:52.350
whether those are highs or lows.

00:48:52.350 --> 00:48:53.330
Do your homework.

00:48:53.330 --> 00:48:55.550
Pick out your own
news organizations

00:48:55.550 --> 00:48:58.700
that are on both sides
of different arguments.

00:48:58.700 --> 00:49:03.390
And don't react to what
you're seeing right now,

00:49:03.390 --> 00:49:05.834
and make sure you
do your own homework

00:49:05.834 --> 00:49:07.500
so that you can really
think and make up

00:49:07.500 --> 00:49:08.670
your own mind for yourself.

00:49:08.670 --> 00:49:10.920
So those would be some
of the bigger things

00:49:10.920 --> 00:49:12.360
that I would advise.

00:49:12.360 --> 00:49:14.322
Yeah, great question.

00:49:14.322 --> 00:49:14.910
HOST: Great.

00:49:14.910 --> 00:49:16.680
Our next question
is, you mentioned

00:49:16.680 --> 00:49:19.380
being cautious of new
laws in this space.

00:49:19.380 --> 00:49:21.900
What steps should lawmakers
and/or the government

00:49:21.900 --> 00:49:25.380
in general be taking
to keep us safe online,

00:49:25.380 --> 00:49:27.520
especially when we consider
WannaCry and the impact

00:49:27.520 --> 00:49:28.895
that it had on
the health sector?

00:49:28.895 --> 00:49:30.894
THERESA PAYTON: Yeah,
it's a very fair question.

00:49:30.894 --> 00:49:34.620
And it's interesting.

00:49:34.620 --> 00:49:38.070
If anything actually
gets passed on the Hill--

00:49:38.070 --> 00:49:39.990
so that's kind of the
first big one, which is,

00:49:39.990 --> 00:49:41.073
they're not getting along.

00:49:41.073 --> 00:49:42.480
I don't know if you've noticed.

00:49:42.480 --> 00:49:45.070
Not a lot has been
passed in recent years.

00:49:45.070 --> 00:49:47.010
But if anything
were to pass given

00:49:47.010 --> 00:49:49.815
what's happened in
the past with OPM

00:49:49.815 --> 00:49:51.440
with some of the
credit card breaches--

00:49:51.440 --> 00:49:55.190
but when you look at Experian,
that's permanent data.

00:49:55.190 --> 00:49:57.460
So the last breaches
were a credit card--

00:49:57.460 --> 00:50:00.190
you get a new credit card,
basically, after a year,

00:50:00.190 --> 00:50:01.380
you should be fine.

00:50:01.380 --> 00:50:04.570
Experian, you're never getting
a new mothers maiden name,

00:50:04.570 --> 00:50:06.880
social security
number, date of birth.

00:50:06.880 --> 00:50:09.060
They can wait 10 years and
that data is still golden

00:50:09.060 --> 00:50:12.300
until America, as a
government, figures out

00:50:12.300 --> 00:50:14.550
what our new identification
schema is going

00:50:14.550 --> 00:50:17.290
to be for the different
parts of your life,

00:50:17.290 --> 00:50:20.620
whether it's the IRS or social
security, or whatever it is.

00:50:20.620 --> 00:50:23.580
And so I would be
a big fan of seeing

00:50:23.580 --> 00:50:28.170
some type of a consumer bill
of rights around data and data

00:50:28.170 --> 00:50:28.900
privacy.

00:50:28.900 --> 00:50:32.340
But I am hesitant to
push for something

00:50:32.340 --> 00:50:35.400
like that because I worry
that by the time it's enacted,

00:50:35.400 --> 00:50:36.180
it's out of date.

00:50:36.180 --> 00:50:41.070
And then, too, I worry that
well-meaning, well-intended,

00:50:41.070 --> 00:50:45.270
but not technical people will
be dictating for companies how

00:50:45.270 --> 00:50:47.530
to technically
take care of that.

00:50:47.530 --> 00:50:51.120
But if you were to ask
the Hill for anything,

00:50:51.120 --> 00:50:55.630
I would ask the Hill for things
that are incentive based.

00:50:55.630 --> 00:50:58.650
So for example, I would
love to see companies

00:50:58.650 --> 00:51:01.420
that invest in
security and privacy

00:51:01.420 --> 00:51:03.924
get an R&amp;D tax credit for that.

00:51:03.924 --> 00:51:06.090
How about the fact that
you're being a good citizen,

00:51:06.090 --> 00:51:09.060
and you're investing money in
thinking about this problem

00:51:09.060 --> 00:51:09.990
differently.

00:51:09.990 --> 00:51:12.310
Why not give you a tax
break for doing that?

00:51:12.310 --> 00:51:14.400
So why don't we think
instead about sort

00:51:14.400 --> 00:51:16.770
of onerous regulatory burdens.

00:51:16.770 --> 00:51:18.690
Why don't we think of
incentives and saying,

00:51:18.690 --> 00:51:21.630
for companies who
do right by this,

00:51:21.630 --> 00:51:24.960
let's give them a break
for designing differently

00:51:24.960 --> 00:51:28.170
and designing for the human
instead of designing and saying

00:51:28.170 --> 00:51:31.795
the humans the weakest link.

00:51:31.795 --> 00:51:33.905
HOST: And we'll take
one more question.

00:51:36.750 --> 00:51:38.350
This is, I think,
the most fun one.

00:51:38.350 --> 00:51:40.890
What was the most difficult
fugitive strategy to figure out

00:51:40.890 --> 00:51:41.700
on Hunted?

00:51:41.700 --> 00:51:45.690
Or otherwise, what were some of
the most creative and effective

00:51:45.690 --> 00:51:46.634
disappearances?

00:51:46.634 --> 00:51:48.300
THERESA PAYTON: Wow,
that's a good gone.

00:51:48.300 --> 00:51:53.319
I mean, candidly I'll give
Troy and Chele some real props.

00:51:53.319 --> 00:51:55.110
So what you need to
know for those of you--

00:51:55.110 --> 00:51:57.780
if you haven't watched the show
yet, you can binge watch it--

00:51:57.780 --> 00:52:00.030
and again, my mom says
it's a must-watch show--

00:52:00.030 --> 00:52:03.070
but you binge watch
it on CBS on Demand.

00:52:03.070 --> 00:52:04.560
And I it's on Hulu and Amazon.

00:52:04.560 --> 00:52:05.730
You can download the series.

00:52:05.730 --> 00:52:08.780
And one of the things
about Troy and Chele--

00:52:08.780 --> 00:52:10.890
well, for you to know
about all the fugitives--

00:52:10.890 --> 00:52:14.160
I had no idea what they went
through other than the capture.

00:52:14.160 --> 00:52:17.270
And they didn't let me see
it until the show aired.

00:52:17.270 --> 00:52:19.560
So I learned with
everybody at home

00:52:19.560 --> 00:52:22.950
where people really were and
the near misses that we had.

00:52:22.950 --> 00:52:25.260
And so Troy and Chele-- they
were actually in the swamp

00:52:25.260 --> 00:52:28.357
for 14 days straight--
canoeing past alligators--

00:52:28.357 --> 00:52:30.690
I don't know if you spent any
time in the Florida swamp,

00:52:30.690 --> 00:52:33.070
it is not a pretty place to be.

00:52:33.070 --> 00:52:36.180
And so I give them total
props for doing that.

00:52:36.180 --> 00:52:38.400
And it was really their
friends commenting

00:52:38.400 --> 00:52:43.860
on their wanted page that really
kind of helped us figure out

00:52:43.860 --> 00:52:46.950
who would be in the local area
that might be helping them.

00:52:46.950 --> 00:52:50.850
Another kind of creative
thing that David and Emily

00:52:50.850 --> 00:52:55.650
did was David had actually--

00:52:55.650 --> 00:52:59.880
in that first hour, they
were given a full hour ahead

00:52:59.880 --> 00:53:02.460
of us knowing who they
are to do anything

00:53:02.460 --> 00:53:03.750
they want to do to get ready.

00:53:03.750 --> 00:53:05.541
But they have to show
they're getting ready

00:53:05.541 --> 00:53:08.010
and that they weren't
a prepper in advance.

00:53:08.010 --> 00:53:11.520
And one of the
things he did was he

00:53:11.520 --> 00:53:15.480
called different people to
have them be lifelines in line

00:53:15.480 --> 00:53:18.060
over the course of the 28 days.

00:53:18.060 --> 00:53:20.760
And he set up-- basically,
they were three degrees

00:53:20.760 --> 00:53:24.000
of separation away from him, and
they did all the coordination

00:53:24.000 --> 00:53:25.290
for him.

00:53:25.290 --> 00:53:27.990
And so even though we're trying
to surveil him, and his family,

00:53:27.990 --> 00:53:30.450
and Emily, and her
family, really, he

00:53:30.450 --> 00:53:33.540
had gone way out of
his circle of trust.

00:53:33.540 --> 00:53:35.880
And so that made it harder
for us to figure out who--

00:53:35.880 --> 00:53:39.300
because you can only surveil
so many people in 28 days

00:53:39.300 --> 00:53:41.150
and convince the court--

00:53:41.150 --> 00:53:43.650
you have to have just cause to
put people under surveillance

00:53:43.650 --> 00:53:46.320
you have to have a really
well-written warrant for that.

00:53:46.320 --> 00:53:48.330
So that was another
really good strategy.

00:53:48.330 --> 00:53:51.540
And then it's interesting.

00:53:51.540 --> 00:53:53.310
The boys-- Will and Miles--

00:53:53.310 --> 00:53:55.230
what they basically
did was, they just

00:53:55.230 --> 00:53:57.940
lived off of the
kindness of strangers,

00:53:57.940 --> 00:54:03.690
which really was going to
work for them until one

00:54:03.690 --> 00:54:06.050
of the people who was
helping them out--

00:54:06.050 --> 00:54:08.361
the friend-- wanted
to go to a movie,

00:54:08.361 --> 00:54:10.860
and they didn't want to leave
the boys alone in the vacation

00:54:10.860 --> 00:54:13.380
rental, and so she actually
called her tip line

00:54:13.380 --> 00:54:16.204
and turned them in because she
was tired of them hanging out.

00:54:16.204 --> 00:54:17.745
So it's like, when
you do [INAUDIBLE]

00:54:17.745 --> 00:54:21.180
on the kindness of strangers--
they had no digital footprint.

00:54:21.180 --> 00:54:23.880
The only thing I thought was--
when I read their profile,

00:54:23.880 --> 00:54:25.680
I said, they're going
to go to the beach.

00:54:25.680 --> 00:54:27.300
Because the 100,000
square miles was

00:54:27.300 --> 00:54:28.599
the southeast for season one.

00:54:28.599 --> 00:54:30.390
So I said, they're
going to go to the beach

00:54:30.390 --> 00:54:32.370
because they can blend in.

00:54:32.370 --> 00:54:33.355
They're young men.

00:54:33.355 --> 00:54:34.980
They're going to
blend in at the beach.

00:54:34.980 --> 00:54:36.570
They like to have a good time.

00:54:36.570 --> 00:54:39.100
That's a great place to hide.

00:54:39.100 --> 00:54:41.760
But there's Myrtle Beach,
and there's Florida beaches,

00:54:41.760 --> 00:54:43.470
and there's all
kinds of beaches.

00:54:43.470 --> 00:54:45.690
And that really
was their undoing

00:54:45.690 --> 00:54:47.910
was living off the
kindness of strangers.

00:54:47.910 --> 00:54:50.610
And one of them got tired
of them and turned them in.

00:54:50.610 --> 00:54:51.360
HOST: Excellent.

00:54:51.360 --> 00:54:52.984
Well, this has been
really fascinating,

00:54:52.984 --> 00:54:54.969
and we do appreciate
you joining us today.

00:54:54.969 --> 00:54:56.885
So a big round of applause
for Theresa Payton.

00:54:56.885 --> 00:54:57.750
THERESA PAYTON:
Thank you, everybody.

00:54:57.750 --> 00:54:58.620
HOST: Thank you.

00:54:58.620 --> 00:55:01.670
[APPLAUSE]

