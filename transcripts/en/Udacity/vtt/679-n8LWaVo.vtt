WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.000
[Dave:] This is Brian Gawalt who works on text analysis,

00:00:03.000 --> 00:00:06.000
which is a really important problem for search engines if we want to be able to do

00:00:06.000 --> 00:00:08.000
a better job of identifying the right documents.

00:00:08.000 --> 00:00:10.000
Tell us how that works.

00:00:10.000 --> 00:00:14.000
[Brian:] There are lots of different approaches, but the model that we tend to take

00:00:14.000 --> 00:00:18.000
transforms them into a really nice hashtable representation.

00:00:18.000 --> 00:00:24.000
Text is long and unwieldy and unstructured and prose flows and goes,

00:00:24.000 --> 00:00:27.000
but computers like things that are nice and structured

00:00:27.000 --> 00:00:34.000
and amenable in familiar things like lists, hashtables, etc.

00:00:34.000 --> 00:00:38.000
What we've got is a way to turn unstructured text

00:00:38.000 --> 00:00:43.000
into a data structure that computers are really happy with.

00:00:43.000 --> 00:00:46.000
One of those is the hashtable and the ???.

00:00:46.000 --> 00:00:50.000
We can start with a document that says, "Obama announces candidacy,"

00:00:50.000 --> 00:00:55.000
and we can turn that into a representation of that document, and imperfect representation

00:00:55.000 --> 00:01:00.000
that just says let's keep track of every word and the number of times that word appeared

00:01:00.000 --> 00:01:02.000
in the document.

00:01:02.000 --> 00:01:06.000
We would just go through and say "Obama"--go to the hashtable and hash Obama

00:01:06.000 --> 00:01:09.000
and make sure the value associated with it is 1.

00:01:09.000 --> 00:01:13.000
Similarly, "announces" hashes to 1, and "candidacyO hashes to 1.

00:01:13.000 --> 00:01:16.000
If we were dealing with longer documents, these values would grow,

00:01:16.000 --> 00:01:19.000
and the number of elements in the hashtable would grow as well.

00:01:19.000 --> 00:01:23.000
Then we come across document 2, and we can represent that with a whole new hashtable.

00:01:23.000 --> 00:01:29.000
"Barak Obama elected"--Barak maps to 1, Obama maps to 1, and elected maps to 1.

00:01:29.000 --> 00:01:34.000
If it also said "President" down here, we'd add more and more keys

00:01:34.000 --> 00:01:36.000
and keep track of the value associated with each one.

00:01:36.000 --> 00:01:41.000
When it comes time to relate documents to each other, like we would do with our search engine,

00:01:41.000 --> 00:01:47.000
we can look and say, hey, there's an overlap between these two documents

00:01:47.000 --> 00:01:51.000
and the fact that they both used "Obama."

00:01:51.000 --> 00:01:54.000
If we've got enough documents and there are enough patterns between them,

00:01:54.000 --> 00:01:59.000
then we can start saying I'm seeing this pattern of "Barak" shows up in a lot of them

00:01:59.000 --> 00:02:02.000
or "candidacy" or "announcements" seem to come from him a lot.

00:02:02.000 --> 00:02:06.000
Now you've got a way of expanding this key word that maybe we're searching for "Obama"

00:02:06.000 --> 00:02:10.000
and the search engine can think when you say "Obama" you're really talking about

00:02:10.000 --> 00:02:16.000
this wide pantheon of topics that all of the do with the 44th presidency.

00:02:16.000 --> 00:02:18.000
[Dave:] How did you get started working on this?

00:02:18.000 --> 00:02:22.000
[Brian:] Well, I was an electrical engineer, and I went from circuits to signals

00:02:22.000 --> 00:02:26.000
to statistical signal processing, and it turns out I was working on how to tell

00:02:26.000 --> 00:02:31.000
if a cell phone is sending a 1 or a 0, and the math behind that wound up being

00:02:31.000 --> 00:02:35.000
broadly applicable to general problems, including how to tell if an email is spam or not.

00:02:35.000 --> 00:02:39.000
That's kind of the entrance to text processing in general from my background.

00:02:39.000 --> 00:02:41.000
[Dave:] I see. So what's the next step then?

00:02:41.000 --> 00:02:44.000
Well, a lot of the stuff that we work with all comes down to being able to compare

00:02:44.000 --> 00:02:47.000
two documents and then finding out how that comparison matches

00:02:47.000 --> 00:02:50.000
to whatever you're target is--detecting spam or not.

00:02:50.000 --> 00:02:53.000
All that works really well if the documents are next to each other,

00:02:53.000 --> 00:02:56.000
living close to each other within a single system,

00:02:56.000 --> 00:03:00.000
but that gives you a maximum of how many documents get analyzed.

00:03:00.000 --> 00:03:03.000
So distributing the solutions to these problems

00:03:03.000 --> 00:03:07.000
is, I think, where a lot of energy is being put forth.

