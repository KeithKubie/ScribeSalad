WEBVTT
Kind: captions
Language: en

00:00:00.430 --> 00:00:07.160
The product DQ, that is the data server query, and the rate of query

00:00:07.160 --> 00:00:13.320
that is coming into the server. This DQ represents some sort of system limit for

00:00:13.320 --> 00:00:16.170
a given server capacity the product DQ

00:00:16.170 --> 00:00:19.630
is a constant. Said differently for a different

00:00:19.630 --> 00:00:25.676
system capacity, we can increase the number of clients that we are serving if we

00:00:25.676 --> 00:00:29.050
reduce the amount of data that we're

00:00:29.050 --> 00:00:32.540
using to process the incoming queries. That is,

00:00:32.540 --> 00:00:39.000
we're increasing Q by decreasing the harvest or D. Or can do the opposite and

00:00:39.000 --> 00:00:44.750
that is, we can entertain a smaller set of queries. That is the yield will come

00:00:44.750 --> 00:00:50.760
down but we will be able to give the complete data that is needed

00:00:50.760 --> 00:00:53.160
for serving that query. An example of would

00:00:53.160 --> 00:00:56.610
be, if I am a client that is accessing

00:00:56.610 --> 00:01:02.140
a server for my mail, I would want to get all my mail, not part of the mail.

00:01:02.140 --> 00:01:08.050
So in that case, I will be happy if the server gives me a harvest of one, even

00:01:08.050 --> 00:01:12.000
it means that not all the incoming clients maybe

00:01:12.000 --> 00:01:16.240
served by the server due to the capacity limitation

00:01:16.240 --> 00:01:20.880
of the server at any point of time. So as a system administrator, we have some

00:01:20.880 --> 00:01:24.310
choices to play with. The important thing is

00:01:24.310 --> 00:01:28.730
that in giant's scale services. The performance is limited

00:01:28.730 --> 00:01:34.220
by network and not by the I/O capacity. We can have as much I/O capacity as we

00:01:34.220 --> 00:01:37.670
want by having more hardware resources here, but

00:01:37.670 --> 00:01:41.180
what we are bound by is the network capacity.

00:01:41.180 --> 00:01:45.920
So if we increase the capacity of a server, we have a choice as a system

00:01:45.920 --> 00:01:50.690
administrator. We can either increase the harvest, keeping

00:01:50.690 --> 00:01:54.302
the yield the same. Or, we can increase the

00:01:54.302 --> 00:01:57.030
number of clients we are serving. That is,

00:01:57.030 --> 00:01:59.800
we can increase the yield, keeping D a

00:01:59.800 --> 00:02:03.050
constant. That's the knob that a system administrator

00:02:03.050 --> 00:02:07.060
can play with in terms of dealing with capacity

00:02:07.060 --> 00:02:09.520
increases at the server. Similarly, if I am

00:02:09.520 --> 00:02:12.880
a system administrator, and some nodes in the server

00:02:12.880 --> 00:02:16.480
fail, then again we have a choice of

00:02:16.480 --> 00:02:20.990
either decreasing the harvest or decreasing the yield, in

00:02:20.990 --> 00:02:24.090
order to deal with reduced DQ value. Of

00:02:24.090 --> 00:02:26.980
course, it all depends on how the server itself

00:02:26.980 --> 00:02:29.510
is architected, if the failures can be hidden

00:02:29.510 --> 00:02:32.530
through replication and so on. But the important message

00:02:32.530 --> 00:02:38.860
I want to convey to you is that this DQ represents a system constant, so far

00:02:38.860 --> 00:02:41.170
as the server is concerned, in terms of

00:02:41.170 --> 00:02:43.970
the capacity. Given a particular capacity of the

00:02:43.970 --> 00:02:46.860
server, DQ is fixed. So as a system

00:02:46.860 --> 00:02:50.990
administrator you have a choice of either sacrificing

00:02:50.990 --> 00:02:54.180
yield for harvest or harvest for yield. You

00:02:54.180 --> 00:02:57.720
cannot increase both the harvest and yield without

00:02:57.720 --> 00:03:02.100
increasing the server capacity. At traditional measure that has been used in

00:03:02.100 --> 00:03:10.160
servers, is the notion of IOOPS, or I/O operations per second, and these are

00:03:10.160 --> 00:03:13.310
meaningful in database kinds of applications.

00:03:13.310 --> 00:03:16.670
Where the applications are disbound, but the

00:03:16.670 --> 00:03:20.070
giant scale applications are network bound,

00:03:20.070 --> 00:03:23.180
and for network bound applications this manager

00:03:23.180 --> 00:03:30.400
DQ is much more intuitive as to what is going on in terms of managing the

00:03:30.400 --> 00:03:33.950
incoming load to the server - And managing

00:03:33.950 --> 00:03:36.170
the corpus of data that the server has

00:03:36.170 --> 00:03:39.210
to look at in order to satisfy incoming

00:03:39.210 --> 00:03:43.210
queries. Another metric that system administrators have often

00:03:43.210 --> 00:03:45.330
used is what is called up time. You

00:03:45.330 --> 00:03:48.570
may have heard of terminologies like mean time

00:03:48.570 --> 00:03:52.010
between failure and mean time to repair.

00:03:52.010 --> 00:03:55.570
Meantime between failure is, what is the expected

00:03:55.570 --> 00:03:58.700
time between two successive failures inside a

00:03:58.700 --> 00:04:02.750
data center? And similarly meantime to repair is

00:04:02.750 --> 00:04:07.870
if a failure is detected, how much time does it take to bring up a failed

00:04:07.870 --> 00:04:13.880
server, that need time to repair. And the up-time is defined as the ratio of

00:04:13.880 --> 00:04:19.110
the difference between, mean time between failure and MTTR, that is mean time to

00:04:19.110 --> 00:04:27.190
repair, and MTBF, that is uptime is equal to MTBF minus MTTR

00:04:27.190 --> 00:04:32.930
divided my MTBF. That is uptime. And you want the the uptime to be

00:04:32.930 --> 00:04:38.750
close to one. And usually uptime is measured in nines. Meaning point nine,

00:04:38.750 --> 00:04:44.120
nine, nine, nine. Five nines or six nines and so on. So you want the up time to

00:04:44.120 --> 00:04:50.230
be as close to one as possible for giant scale services. But again, this up time

00:04:50.230 --> 00:04:54.590
as a metric is not very satisfying because

00:04:54.590 --> 00:04:57.800
if there are no queries giving the time that

00:04:57.800 --> 00:05:01.030
is needed for repairing, that is, during the MTT

00:05:01.030 --> 00:05:04.250
par, the mean time to repair, if no queries

00:05:04.250 --> 00:05:07.010
come into the server, then you haven't

00:05:07.010 --> 00:05:10.530
made anybody unhappy. In that sense, the uptime

00:05:10.530 --> 00:05:16.460
is not a very intuitive measure of how well a server is performing. It is better

00:05:16.460 --> 00:05:22.550
to look at yield as the output metric. And the harvest, again, is the output

00:05:22.550 --> 00:05:29.680
metric for say how well a server is able to deal with the dynamism and scale of

00:05:29.680 --> 00:05:33.380
requesting handled by a particular giant-scale service. We'll

00:05:33.380 --> 00:05:36.320
see that this DQ principle is very powerful

00:05:36.320 --> 00:05:40.200
in advising the system administrator on how to

00:05:40.200 --> 00:05:43.400
architect the system. How much to replicate? How

00:05:43.400 --> 00:05:48.430
much to partition in terms of the data set that the server is handling? How to

00:05:48.430 --> 00:05:51.210
deal with failures? How to gracefully degrade the

00:05:51.210 --> 00:05:55.240
servers when the volume of incoming traffic increases

00:05:55.240 --> 00:05:59.880
beyond a server capacity? All of these are questions that

00:05:59.880 --> 00:06:04.140
can be handled very elegantly using the DQ principle. And

00:06:04.140 --> 00:06:08.840
the key underlying assumption in the DQ principle, is that

00:06:08.840 --> 00:06:13.530
the giant scaled services are network bound, and not I/O bound.

