WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.340
[MUSIC PLAYING]

00:00:05.340 --> 00:00:06.840
ELISE ROY: You see this?

00:00:06.840 --> 00:00:09.070
This is my old hearing aid.

00:00:09.070 --> 00:00:10.630
And this?

00:00:10.630 --> 00:00:13.920
This is one that I wear today.

00:00:13.920 --> 00:00:15.820
What's different?

00:00:15.820 --> 00:00:19.980
This one's flesh-colored
and this one's red.

00:00:19.980 --> 00:00:26.020
It may seem like a small design
tweak, but it changed my life.

00:00:26.020 --> 00:00:30.610
It made me feel as
if I belong again.

00:00:30.610 --> 00:00:35.280
You see, right before fifth
grade, my mom sat me down

00:00:35.280 --> 00:00:41.670
and she said, you need to tell
Michelle about your hearing

00:00:41.670 --> 00:00:44.190
loss.

00:00:44.190 --> 00:00:48.570
Michelle was my best
friend, but I hadn't

00:00:48.570 --> 00:00:51.480
seen her all summer long.

00:00:51.480 --> 00:00:57.520
And two weeks before, I was told
that I was losing my hearing

00:00:57.520 --> 00:01:04.209
and it was going to just get
worse and worse and worse.

00:01:04.209 --> 00:01:06.820
But I was 10 years old.

00:01:06.820 --> 00:01:10.710
I didn't know how to deal
with heavy stuff like this.

00:01:10.710 --> 00:01:15.330
And so when I called her
up before school started,

00:01:15.330 --> 00:01:18.240
we talked about our summers,
we talked about sports,

00:01:18.240 --> 00:01:24.780
we talked about everything
but my hearing loss.

00:01:24.780 --> 00:01:28.620
On the second day of school,
she was standing behind me

00:01:28.620 --> 00:01:31.140
in line and she tapped
me on the shoulder,

00:01:31.140 --> 00:01:36.010
pointed to my hearing aid
and said, what's that?

00:01:36.010 --> 00:01:41.390
It was an innocent question, but
I didn't know how to respond,

00:01:41.390 --> 00:01:43.470
and so I said,
it's a hearing aid,

00:01:43.470 --> 00:01:48.720
as if she was
stupid not to know.

00:01:48.720 --> 00:01:51.145
And then there was just silence.

00:01:54.330 --> 00:01:59.690
And this silence followed us for
the rest of our relationship.

00:01:59.690 --> 00:02:03.760
She never asked me again
about my hearing loss,

00:02:03.760 --> 00:02:08.090
and I spent that year watching
her slowly drift away.

00:02:11.220 --> 00:02:15.930
I felt different, as
if I didn't belong,

00:02:15.930 --> 00:02:18.990
and she being just 10
years old didn't know how

00:02:18.990 --> 00:02:21.810
to deal with this difference.

00:02:21.810 --> 00:02:25.470
Many kids avoid difference
because they're just not

00:02:25.470 --> 00:02:28.120
sure what to do with it.

00:02:28.120 --> 00:02:31.800
And so I found out
quickly that I didn't

00:02:31.800 --> 00:02:34.890
want to be seen as different.

00:02:34.890 --> 00:02:38.430
And again, this
long struggle to try

00:02:38.430 --> 00:02:43.020
to prove that, although
I had a hearing loss, it

00:02:43.020 --> 00:02:43.890
didn't change me.

00:02:43.890 --> 00:02:46.970
I was still normal.

00:02:46.970 --> 00:02:51.125
And I did this by overachieving.

00:02:54.770 --> 00:03:00.530
Going-- when I went to
college, playing just one sport

00:03:00.530 --> 00:03:01.720
wasn't enough.

00:03:01.720 --> 00:03:03.320
I had to play two.

00:03:03.320 --> 00:03:05.510
I had to go to an Ivy League.

00:03:05.510 --> 00:03:10.790
I became one of the first
few deaf lawyers in the US.

00:03:10.790 --> 00:03:14.720
I did some work at
the United Nations,

00:03:14.720 --> 00:03:19.340
and then I became a designer.

00:03:19.340 --> 00:03:25.680
But somewhere along the
way, I realized something.

00:03:25.680 --> 00:03:29.090
I am the new normal.

00:03:29.090 --> 00:03:32.060
You know that TV show
"Orange is the New Black"?

00:03:32.060 --> 00:03:36.080
Well, I am the new normal.

00:03:36.080 --> 00:03:39.020
Difference is the new normal.

00:03:39.020 --> 00:03:42.620
Difference, even if it
seems like limitation,

00:03:42.620 --> 00:03:45.380
is what makes us thrive,
what makes us valuable.

00:03:49.138 --> 00:03:54.590
Now, I would like
to think about this.

00:03:57.980 --> 00:04:04.500
This body encompasses all of us.

00:04:04.500 --> 00:04:09.210
If we all live long enough,
we will all get disability

00:04:09.210 --> 00:04:11.950
at some point in our lives.

00:04:11.950 --> 00:04:16.589
And who here has broken
their legs or their arms?

00:04:16.589 --> 00:04:17.490
Really, that's it?

00:04:17.490 --> 00:04:17.990
Come on.

00:04:20.890 --> 00:04:25.260
That's an example of a
temporary disability.

00:04:25.260 --> 00:04:28.240
But what comes next is key.

00:04:28.240 --> 00:04:34.390
We also all experience something
called momentary disabilities.

00:04:34.390 --> 00:04:36.630
Now, I'd like to
call up a volunteer

00:04:36.630 --> 00:04:39.372
to come up and help me
demonstrate what they are.

00:04:39.372 --> 00:04:40.980
[APPLAUSE]

00:04:40.980 --> 00:04:44.670
What I'd like you
to do is to pick up

00:04:44.670 --> 00:04:47.370
that box and those
books, and then

00:04:47.370 --> 00:04:53.093
come over while carrying the
box, take sip of the water.

00:04:53.093 --> 00:04:54.760
You're going to have
to open it, though.

00:05:04.089 --> 00:05:05.360
You have to open it.

00:05:14.460 --> 00:05:15.585
That was pretty impressive.

00:05:15.585 --> 00:05:16.383
Most pe--

00:05:16.383 --> 00:05:18.195
AUDIENCE: [INAUDIBLE]

00:05:18.195 --> 00:05:20.460
[APPLAUSE]

00:05:20.460 --> 00:05:21.474
ELISE ROY: Was it easy?

00:05:21.474 --> 00:05:21.974
Hard?

00:05:21.974 --> 00:05:22.782
AUDIENCE: Totally.

00:05:22.782 --> 00:05:23.590
Kind of fun.

00:05:23.590 --> 00:05:25.170
ELISE ROY: Yes.

00:05:25.170 --> 00:05:29.430
So thank you very
much for your help.

00:05:29.430 --> 00:05:36.090
As we go about our lives,
we encounter situations

00:05:36.090 --> 00:05:39.900
where we will be
momentarily disabled,

00:05:39.900 --> 00:05:44.640
whether we're carrying box
and trying to open up a door.

00:05:44.640 --> 00:05:51.160
And so disability really
encompasses all of us.

00:05:51.160 --> 00:05:53.790
There are just some of
us that experience it

00:05:53.790 --> 00:05:55.370
a lot more than others.

00:06:00.760 --> 00:06:08.650
Now, as a lawyer, I fought
for equality and race, gender,

00:06:08.650 --> 00:06:11.520
disability, and you
would think that I

00:06:11.520 --> 00:06:15.600
would have been outfitted with
the skills necessary to feel

00:06:15.600 --> 00:06:19.020
accepted and valued by society.

00:06:19.020 --> 00:06:22.500
But to my surprise, I
found the strongest tools

00:06:22.500 --> 00:06:25.680
when I transitioned
from law to design.

00:06:25.680 --> 00:06:30.610
Design has this powerful
ability to shift perceptions,

00:06:30.610 --> 00:06:33.000
but it's up to you to use it.

00:06:33.000 --> 00:06:33.590
Up to you.

00:06:36.290 --> 00:06:41.090
So finally, it happened.

00:06:41.090 --> 00:06:45.530
After law school, I went
back to the audiologist

00:06:45.530 --> 00:06:48.050
to get a new hearing
aid, and I was

00:06:48.050 --> 00:06:50.900
thrilled because
they weren't just

00:06:50.900 --> 00:06:54.350
these awful flesh-colored
things anymore,

00:06:54.350 --> 00:06:58.920
but they invented red ones
and blue ones and green ones.

00:06:58.920 --> 00:07:02.570
So I opted for the
bright red one,

00:07:02.570 --> 00:07:06.410
and then something
magical happened--

00:07:06.410 --> 00:07:10.540
my hearing aid became cool.

00:07:10.540 --> 00:07:14.910
People started saying things
like, [GASP] love the red!

00:07:14.910 --> 00:07:20.110
This little thing created
this huge shift in my life.

00:07:20.110 --> 00:07:22.930
It allowed me to
celebrate my difference

00:07:22.930 --> 00:07:26.020
and it allowed others to
join in on celebrating

00:07:26.020 --> 00:07:28.450
this difference with me.

00:07:28.450 --> 00:07:31.720
This is because it
opened up the door

00:07:31.720 --> 00:07:34.390
to conversing about
difference without being

00:07:34.390 --> 00:07:38.740
focused on limitations.

00:07:38.740 --> 00:07:40.910
MICHAEL BRENNER: OK.

00:07:40.910 --> 00:07:41.660
Thank you, Elise.

00:07:41.660 --> 00:07:46.040
That was a beautiful talk, and
it was a very good introduction

00:07:46.040 --> 00:07:48.770
to our story, which we
call Project Euphonia.

00:07:48.770 --> 00:07:50.210
So we're going to
start the story

00:07:50.210 --> 00:07:55.290
by telling you a story about
one of our colleagues at Google.

00:07:55.290 --> 00:07:59.330
So this is Dimitri Kanevsky,
and Dimitri, it turns out,

00:07:59.330 --> 00:08:00.230
is a mathematician.

00:08:00.230 --> 00:08:03.920
He's worked at some of the great
institutions for mathematics

00:08:03.920 --> 00:08:05.460
in the world.

00:08:05.460 --> 00:08:07.250
But for the last
two decades, he's

00:08:07.250 --> 00:08:09.890
really been thinking
primarily about designing

00:08:09.890 --> 00:08:11.630
for accessibility--
that is, trying

00:08:11.630 --> 00:08:17.210
to invent technology that was
helpful in some way or other.

00:08:17.210 --> 00:08:21.260
So Dimitri himself has a
disability-- he's deaf--

00:08:21.260 --> 00:08:24.550
and he also has a very
strong Russian accent.

00:08:24.550 --> 00:08:27.260
So the first time that
at least I met Dimitri,

00:08:27.260 --> 00:08:29.510
I found it very
hard to understand

00:08:29.510 --> 00:08:31.353
what he was talking about.

00:08:31.353 --> 00:08:33.020
But, you know, hanging
out with Dimitri,

00:08:33.020 --> 00:08:34.710
eventually you get the idea.

00:08:34.710 --> 00:08:36.260
So it turns out
that our computers

00:08:36.260 --> 00:08:38.030
have the same problem--

00:08:38.030 --> 00:08:40.159
that is, when Dimitri
speaks to his phone

00:08:40.159 --> 00:08:42.620
as I might speak to
my phone, his phone

00:08:42.620 --> 00:08:44.370
doesn't understand
him very well.

00:08:44.370 --> 00:08:47.355
And this is a clip in which
he explains that himself.

00:09:04.320 --> 00:09:07.117
So what you see from this
is that the phone that

00:09:07.117 --> 00:09:09.450
was being showed was a phone
that was running the Google

00:09:09.450 --> 00:09:11.770
Cloud Speech Recognition Model.

00:09:11.770 --> 00:09:15.060
And what I would claim
is that if you only

00:09:15.060 --> 00:09:17.580
looked at the phone,
that you would not

00:09:17.580 --> 00:09:22.110
be able to really understand
the thread of what Dimitri

00:09:22.110 --> 00:09:23.590
was trying to communicate.

00:09:23.590 --> 00:09:27.160
And so we asked ourselves the
question, why is that the case?

00:09:27.160 --> 00:09:30.810
Why is it that the phone was
not able to understand Dimitri

00:09:30.810 --> 00:09:33.830
but, for example, it is
able to understand me?

00:09:33.830 --> 00:09:35.490
And in order to
explain this, I need

00:09:35.490 --> 00:09:39.030
to tell you a little bit about
how speech recognition works

00:09:39.030 --> 00:09:41.940
and why it is that speech
recognition has gotten so much

00:09:41.940 --> 00:09:44.650
better over the past
number of years.

00:09:44.650 --> 00:09:48.000
So when we speak, what we're
doing is creating a wave form.

00:09:48.000 --> 00:09:50.280
So a wave form is
just a sound wave

00:09:50.280 --> 00:09:53.310
and it looks rather
unintelligible.

00:09:53.310 --> 00:09:55.080
The job that we're
asking a computer to do

00:09:55.080 --> 00:09:57.360
is to take the
picture on the left

00:09:57.360 --> 00:10:01.050
and to somehow turn it into
the words that are being said.

00:10:01.050 --> 00:10:03.523
So as you all know, humans
have gotten very good

00:10:03.523 --> 00:10:05.190
at interpreting
pictures, and so the way

00:10:05.190 --> 00:10:08.220
that speech recognizes work
is we first take the wave form

00:10:08.220 --> 00:10:09.720
and turn it into a picture.

00:10:09.720 --> 00:10:11.460
The picture is
called a spectrogram

00:10:11.460 --> 00:10:13.080
and it's just a
picture of colors,

00:10:13.080 --> 00:10:16.680
but it's still unintelligible
as to what was being said.

00:10:16.680 --> 00:10:18.360
And then what we do
is take the picture

00:10:18.360 --> 00:10:20.430
and stick it into a
neural network, which

00:10:20.430 --> 00:10:23.590
is a big computer program that
has lots of parameters in it.

00:10:23.590 --> 00:10:26.130
And the idea is to make the
computer program so that it

00:10:26.130 --> 00:10:28.350
outputs what was being said.

00:10:28.350 --> 00:10:30.510
Now of course, just
like us, if you

00:10:30.510 --> 00:10:31.990
don't train the
computer program,

00:10:31.990 --> 00:10:34.900
it has no idea what
was being said.

00:10:34.900 --> 00:10:38.340
And so what we do is we take all
of the numbers in this computer

00:10:38.340 --> 00:10:41.190
program-- there are millions of
numbers that you have to tune--

00:10:41.190 --> 00:10:44.760
and we give it one sentence
at a time, somebody saying

00:10:44.760 --> 00:10:45.480
something.

00:10:45.480 --> 00:10:47.920
And the computer
predicts it's saying this

00:10:47.920 --> 00:10:50.130
and then it gets it wrong,
and we bang the computer

00:10:50.130 --> 00:10:53.040
over the head, twiddle the
parameters around a little bit

00:10:53.040 --> 00:10:56.310
until eventually by giving it
lots and lots of sentences,

00:10:56.310 --> 00:10:58.750
it gets better at
speech recognition.

00:10:58.750 --> 00:11:01.350
And we have phones
that work for people

00:11:01.350 --> 00:11:03.540
whom the computer has heard.

00:11:03.540 --> 00:11:07.620
Now in order to
do that, it takes

00:11:07.620 --> 00:11:09.340
huge numbers of sentences.

00:11:09.340 --> 00:11:11.845
So tens of millions,
say, of sentences

00:11:11.845 --> 00:11:13.470
need to be given to
the computer for it

00:11:13.470 --> 00:11:16.500
to develop a general
type of understanding.

00:11:16.500 --> 00:11:20.040
But the problem is that
for people like Dimitri,

00:11:20.040 --> 00:11:22.740
or indeed anyone who
speaks in a way that

00:11:22.740 --> 00:11:25.350
is different than
the pool of examples

00:11:25.350 --> 00:11:29.370
that the computer was given,
the phone can't understand them

00:11:29.370 --> 00:11:33.250
just because it's never
heard the example before.

00:11:33.250 --> 00:11:36.750
And so the question that we
asked, and this was a question

00:11:36.750 --> 00:11:40.020
that we started asking in
collaboration with an ALS

00:11:40.020 --> 00:11:41.790
foundation that we've
been working with--

00:11:41.790 --> 00:11:44.610
ALS TDI, who gave
me this T-shirt--

00:11:44.610 --> 00:11:50.130
so we asked whether or not
it's possible to basically fix

00:11:50.130 --> 00:11:52.680
the speech recognizers
to work for people

00:11:52.680 --> 00:11:54.140
who are hard to understood.

00:11:54.140 --> 00:11:58.810
And Dimitri is amazing and
he decided to take this on.

00:11:58.810 --> 00:12:01.380
So remember what I said--
it takes tens of millions

00:12:01.380 --> 00:12:03.600
of sentences to train
a speech recognizer.

00:12:03.600 --> 00:12:07.500
It's completely crazy to ask
someone to sit and record

00:12:07.500 --> 00:12:09.000
tens of millions of sentences.

00:12:09.000 --> 00:12:11.520
But Dimitri has a
great spirit, and so he

00:12:11.520 --> 00:12:13.440
sat in front of his
computer and he just

00:12:13.440 --> 00:12:15.130
started recording sentences.

00:12:15.130 --> 00:12:16.870
And so, for example,
here is a sentence--

00:12:16.870 --> 00:12:18.120
what is the temperature today?

00:12:18.120 --> 00:12:19.590
And so the computer
would say "What

00:12:19.590 --> 00:12:20.430
is the temperature today?"

00:12:20.430 --> 00:12:22.722
And Dimitri would read "What
is the temperature today?"

00:12:22.722 --> 00:12:25.950
And he sat there for days
recording these sentences,

00:12:25.950 --> 00:12:29.310
until he had reported
upwards of 15,000 sentences,

00:12:29.310 --> 00:12:32.610
and we then decided to
train the speech recognizer

00:12:32.610 --> 00:12:34.440
to see if it was able
to understand him.

00:12:34.440 --> 00:12:36.540
And I should tell
you that none of us

00:12:36.540 --> 00:12:39.690
knew whether or not it was even
conceivable that this could

00:12:39.690 --> 00:12:43.260
work because, as I said, it took
many more sentences to train

00:12:43.260 --> 00:12:45.420
the thing in the first
place for many people

00:12:45.420 --> 00:12:48.982
who speak in a way that is more
typical for speech recognizers.

00:12:48.982 --> 00:12:50.190
So here's Dimitri at the end.

00:12:50.190 --> 00:12:52.740
He was still happy
after doing this.

00:12:52.740 --> 00:12:54.540
And then here is the--

00:12:54.540 --> 00:12:57.120
I'm now going to show you a
quick clip of what happened.

00:13:15.930 --> 00:13:19.940
And so what you see is that
the device on the right

00:13:19.940 --> 00:13:23.280
was able to understand Dimitri,
whereas the device on the left,

00:13:23.280 --> 00:13:25.190
which is the Google
Cloud device, was not.

00:13:25.190 --> 00:13:26.810
And this really
gave us confidence

00:13:26.810 --> 00:13:30.690
that it was possible to
make progress on this task.

00:13:30.690 --> 00:13:34.110
And so we started working in
earnest with our collaborators

00:13:34.110 --> 00:13:36.200
ALS TDI and which we recruited.

00:13:36.200 --> 00:13:37.910
They recruited a
large number of people

00:13:37.910 --> 00:13:41.630
with ALS to start recording
sentences to see if this works.

00:13:41.630 --> 00:13:44.960
Now, of course, getting someone
to record 15,000 sentences

00:13:44.960 --> 00:13:46.040
is completely crazy.

00:13:46.040 --> 00:13:49.400
That's never going
to work at scale.

00:13:49.400 --> 00:13:51.560
And so instead we were
investigating technically

00:13:51.560 --> 00:13:54.470
whether or not it's possible
to make progress with smaller

00:13:54.470 --> 00:13:55.760
numbers of sentences.

00:13:55.760 --> 00:13:58.500
And what I can report to you
is that we're making progress.

00:13:58.500 --> 00:13:59.360
We're not there yet.

00:13:59.360 --> 00:14:01.975
We do not feel that we've
solved this problem in any way.

00:14:01.975 --> 00:14:03.350
But we're working
hard, and there

00:14:03.350 --> 00:14:05.720
are groups of engineers at
Google who are working hard.

00:14:05.720 --> 00:14:07.680
And this is just
a little example.

00:14:07.680 --> 00:14:10.340
So the last column is
the ground truth phrases,

00:14:10.340 --> 00:14:13.430
the rightmost column is
what Google Cloud recognizes

00:14:13.430 --> 00:14:16.460
on this particular person
who happens to have ALS,

00:14:16.460 --> 00:14:19.640
and the middle column is what
our recognizer is right now

00:14:19.640 --> 00:14:22.370
doing, and we're hard at
work trying to figure out

00:14:22.370 --> 00:14:25.730
if it is possible to
make this work for people

00:14:25.730 --> 00:14:28.290
without requiring so
much training data.

00:14:28.290 --> 00:14:30.130
So this is Dimitri
as of this week.

00:14:30.130 --> 00:14:32.210
So Dimitri now carries
around with him

00:14:32.210 --> 00:14:35.300
about five different phones
in his pocket, each of which

00:14:35.300 --> 00:14:38.750
has a different speech
recognizer on it,

00:14:38.750 --> 00:14:41.215
and he's testing and trying
to figure out the best way.

00:14:41.215 --> 00:14:42.590
And it is our hope
that if we can

00:14:42.590 --> 00:14:45.590
get this to work with Dimitri's
help and with all of your help,

00:14:45.590 --> 00:14:47.720
and hopefully
people will record,

00:14:47.720 --> 00:14:50.750
make recordings for us-- the
reason for this call for data

00:14:50.750 --> 00:14:55.100
that Sundar made is that we
need more data from people, just

00:14:55.100 --> 00:14:57.260
recordings to be able
to make this work.

00:14:57.260 --> 00:14:58.590
Hopefully we will get there.

00:14:58.590 --> 00:14:59.790
That is our goal.

00:14:59.790 --> 00:15:02.270
And so this sort of
is the general goal

00:15:02.270 --> 00:15:04.400
of Euphonia's
mission, which is what

00:15:04.400 --> 00:15:07.190
we would like to do is
to improve communication

00:15:07.190 --> 00:15:11.120
technology by including as many
people as possible, whatever

00:15:11.120 --> 00:15:13.100
features that the
people have and whatever

00:15:13.100 --> 00:15:14.480
means to communicate.

00:15:14.480 --> 00:15:17.580
Of course, speaking is an
important way of communicating,

00:15:17.580 --> 00:15:20.120
but it is not the only
way that we communicate.

00:15:20.120 --> 00:15:23.153
We communicate with each
other by looking, by feeling,

00:15:23.153 --> 00:15:24.570
by doing so many
different things.

00:15:24.570 --> 00:15:27.120
And there are people who don't
have the ability to speak,

00:15:27.120 --> 00:15:28.620
and so now I'm going
to turn it over

00:15:28.620 --> 00:15:31.220
to Irene, who will start to
talk about other speaking

00:15:31.220 --> 00:15:32.017
modalities.

00:15:32.017 --> 00:15:33.100
IRENE ALVARADO: All right.

00:15:33.100 --> 00:15:33.767
Thanks, Michael.

00:15:33.767 --> 00:15:35.662
[APPLAUSE]

00:15:38.110 --> 00:15:40.600
All right, so so far
we've talked about Dimitri

00:15:40.600 --> 00:15:44.270
and about speech, but what about
other forms of communication?

00:15:44.270 --> 00:15:47.260
What about folks who can't
communicate verbally?

00:15:47.260 --> 00:15:49.600
We want to show you
how we're approaching

00:15:49.600 --> 00:15:52.880
the research for those
types of cases as well.

00:15:52.880 --> 00:15:54.550
So for that, I'd
like to introduce

00:15:54.550 --> 00:15:58.300
our second protagonist for the
day, the amazing Steve Saling.

00:15:58.300 --> 00:15:59.720
He's an incredible person.

00:15:59.720 --> 00:16:03.070
He had a brilliant career
as a landscape architect

00:16:03.070 --> 00:16:05.650
and when he learned
that he has ALS,

00:16:05.650 --> 00:16:08.710
he set about to rethink how
people with his condition

00:16:08.710 --> 00:16:10.023
get care.

00:16:10.023 --> 00:16:11.440
He also started
thinking about how

00:16:11.440 --> 00:16:14.050
he could leverage technology
to create more independence

00:16:14.050 --> 00:16:15.580
for himself, so
that he didn't have

00:16:15.580 --> 00:16:18.440
to rely as much on other
people to take care of him.

00:16:18.440 --> 00:16:21.310
And one thing he
helped do is he helped

00:16:21.310 --> 00:16:23.920
create a smart
home-like system that

00:16:23.920 --> 00:16:27.130
lets him request an elevator
and close the blinds,

00:16:27.130 --> 00:16:29.380
turn on the music, all
by using his computer.

00:16:29.380 --> 00:16:30.860
It's really amazing.

00:16:30.860 --> 00:16:33.880
So Steve happened to be one of
the perfect persons to partner

00:16:33.880 --> 00:16:39.170
with for this research because
he is a technologist himself.

00:16:39.170 --> 00:16:40.600
And speaking of
computers, we want

00:16:40.600 --> 00:16:44.170
to show you how many folks who
have ALS communicate today.

00:16:44.170 --> 00:16:46.360
They use something called
an eye gaze pointer

00:16:46.360 --> 00:16:49.220
to type out letters one by one.

00:16:49.220 --> 00:16:51.230
So these are two
different systems

00:16:51.230 --> 00:16:53.230
that they can use either
a keyboard or something

00:16:53.230 --> 00:16:54.880
on the right called Dasher.

00:16:54.880 --> 00:16:56.810
And it works-- it does the job--

00:16:56.810 --> 00:17:00.550
but if you can imagine,
it's just a little bit slow.

00:17:00.550 --> 00:17:04.510
And what he's missing is a layer
of communication that all of us

00:17:04.510 --> 00:17:05.710
are familiar with--

00:17:05.710 --> 00:17:09.250
interruptions,
mannerisms, jokes, laughs.

00:17:09.250 --> 00:17:11.410
Synchronous communication
that comes by quickly.

00:17:11.410 --> 00:17:13.743
That's something that's really
hard for Steve and people

00:17:13.743 --> 00:17:16.119
with his condition to do.

00:17:16.119 --> 00:17:17.770
So something we
wanted to try with him

00:17:17.770 --> 00:17:22.420
was to see if he could train his
own personal machine learning

00:17:22.420 --> 00:17:25.030
models to classify
different face expressions,

00:17:25.030 --> 00:17:27.220
and the thought was,
is this even useful

00:17:27.220 --> 00:17:30.490
for him to be able to trigger
things more quickly so that he

00:17:30.490 --> 00:17:32.500
might be able to open
his mouth and trigger

00:17:32.500 --> 00:17:34.780
something on the computer
or raise his eyebrows

00:17:34.780 --> 00:17:36.040
and trigger something else?

00:17:36.040 --> 00:17:36.880
It was a question.

00:17:36.880 --> 00:17:38.120
It's a research question.

00:17:38.120 --> 00:17:39.860
And we didn't know the answer.

00:17:39.860 --> 00:17:43.780
So with Steve's feedback, his
ideas, and a lot of testing,

00:17:43.780 --> 00:17:45.370
we developed a
machine learning tool

00:17:45.370 --> 00:17:48.490
that anybody actually can
use to train classification

00:17:48.490 --> 00:17:50.660
models in the browser.

00:17:50.660 --> 00:17:53.080
And by classification,
I mean a model

00:17:53.080 --> 00:17:55.810
that tries to predict what
category a certain type

00:17:55.810 --> 00:17:57.370
of input belongs to.

00:17:57.370 --> 00:18:01.120
Let me show you an example
so you see how it works.

00:18:01.120 --> 00:18:04.330
This is my colleague Barron and
he's training two classes, one

00:18:04.330 --> 00:18:07.960
to detect his face and one to
detect this really cute cat

00:18:07.960 --> 00:18:09.247
pillow that he has.

00:18:09.247 --> 00:18:11.080
So he's giving the
computer a bunch of data.

00:18:11.080 --> 00:18:13.760
He's training it,
waiting for it to finish,

00:18:13.760 --> 00:18:16.990
and then he's testing
the model on the right.

00:18:16.990 --> 00:18:19.060
And then he publishes the model.

00:18:19.060 --> 00:18:22.090
All of this is happening in
the browser in real time,

00:18:22.090 --> 00:18:22.840
and the images--

00:18:22.840 --> 00:18:24.907
the processing is
happening in his computer,

00:18:24.907 --> 00:18:26.740
so the images aren't
being sent to a server.

00:18:26.740 --> 00:18:30.710
It's all happening in his
computer in the browser.

00:18:30.710 --> 00:18:32.560
So we're calling this
Teachable Machine.

00:18:32.560 --> 00:18:35.350
It's a tool for anybody
to train machine learning

00:18:35.350 --> 00:18:37.960
models in the browser without
having to know how to code.

00:18:37.960 --> 00:18:40.690
And it's actually built
on top of TensorFlow.js,

00:18:40.690 --> 00:18:43.270
so all of the underlying
technology is free

00:18:43.270 --> 00:18:46.850
and it's open source
for you to use.

00:18:46.850 --> 00:18:48.760
So, OK, how is Steve using this?

00:18:48.760 --> 00:18:52.030
Well, as I mentioned, he's
training face classification

00:18:52.030 --> 00:18:55.270
models for cases where he
might want a faster response

00:18:55.270 --> 00:18:58.960
time than what he can achieve
with his eye gaze pointer,

00:18:58.960 --> 00:19:01.240
and Teachable Machine
is the prototyping tool

00:19:01.240 --> 00:19:03.010
that's allowing him
to do this and explore

00:19:03.010 --> 00:19:06.580
what types of use cases are
actually helpful for him.

00:19:06.580 --> 00:19:08.810
So why is this useful?

00:19:08.810 --> 00:19:12.500
Well, Teachable Machine is
situational in two ways, right?

00:19:12.500 --> 00:19:15.400
ALS actually changes over time,
so people with the condition,

00:19:15.400 --> 00:19:17.060
they deteriorate over time.

00:19:17.060 --> 00:19:19.480
So Steve might be able
to do an expression today

00:19:19.480 --> 00:19:20.860
that he can't do in a year.

00:19:20.860 --> 00:19:24.010
He has to be able to retrain
those models on his own,

00:19:24.010 --> 00:19:28.967
perhaps week by week, month
by month, as he needs it.

00:19:28.967 --> 00:19:30.550
And the second thing
is that you might

00:19:30.550 --> 00:19:32.633
imagine that he might want
to use different models

00:19:32.633 --> 00:19:34.520
for different use cases.

00:19:34.520 --> 00:19:37.330
One thing that he
actually tried was

00:19:37.330 --> 00:19:41.350
training a model that
would trigger an air horn,

00:19:41.350 --> 00:19:44.590
like a sound of an air horn
when he opens his mouth,

00:19:44.590 --> 00:19:47.650
and to trigger a boo when
he raises his eyebrows.

00:19:47.650 --> 00:19:50.620
And he used it one night
to watch a basketball game

00:19:50.620 --> 00:19:54.580
with one of his favorite teams
to react quickly to the game

00:19:54.580 --> 00:19:55.690
as it progressed.

00:19:55.690 --> 00:19:58.360
Unfortunately that night,
his team didn't win,

00:19:58.360 --> 00:20:01.838
but it was actually
really fun to set up.

00:20:01.838 --> 00:20:03.880
So we've got a long way
to go with this research.

00:20:03.880 --> 00:20:05.880
This is really
only the beginning,

00:20:05.880 --> 00:20:07.720
and we hope to expand
the tool to support

00:20:07.720 --> 00:20:10.270
many more modes of input.

00:20:10.270 --> 00:20:12.460
The tool itself will be
available later this year

00:20:12.460 --> 00:20:14.570
for anyone to train their
classification models,

00:20:14.570 --> 00:20:16.840
but as I said before,
all of the technology

00:20:16.840 --> 00:20:20.960
is already available
on TensorFlow.js.

00:20:20.960 --> 00:20:24.440
We're committed to working with
people like Steve and Dimitri

00:20:24.440 --> 00:20:26.480
to make their
communication tools better,

00:20:26.480 --> 00:20:30.410
and the idea really is to start
with the hardest problems that

00:20:30.410 --> 00:20:33.110
might unlock innovations
for everyone.

00:20:33.110 --> 00:20:35.360
But it's our sincere hope
that this kind of research

00:20:35.360 --> 00:20:38.030
might help people with other
types of speech impairments--

00:20:38.030 --> 00:20:40.400
people with cerebral
palsy or Parkinson's

00:20:40.400 --> 00:20:42.530
or multiple sclerosis.

00:20:42.530 --> 00:20:44.927
And maybe, perhaps
one day, it could

00:20:44.927 --> 00:20:47.510
be helpful to even more people--
people who freely communicate

00:20:47.510 --> 00:20:53.285
today, maybe like folks who have
an accent in a second language.

00:20:53.285 --> 00:20:55.160
And in fact, we started
calling this approach

00:20:55.160 --> 00:20:59.300
to building "Start with
One, Invent for Many."

00:20:59.300 --> 00:21:01.040
We think anybody
can work this way,

00:21:01.040 --> 00:21:03.990
and you can apply to many
more types of problems.

00:21:03.990 --> 00:21:06.530
The idea is actually
quite simple--

00:21:06.530 --> 00:21:08.570
so start by working
together with one person

00:21:08.570 --> 00:21:11.870
to solve one problem, and that
way you can be sure that what

00:21:11.870 --> 00:21:13.940
you make for them will
be impactful to them

00:21:13.940 --> 00:21:15.750
and the people and their lives.

00:21:15.750 --> 00:21:17.570
And sometimes-- it
doesn't always happen,

00:21:17.570 --> 00:21:19.250
but sometimes-- what
you make together

00:21:19.250 --> 00:21:21.560
can go on to be useful
to many more people.

00:21:21.560 --> 00:21:24.668
Start with One, Invent for Many.

00:21:24.668 --> 00:21:26.960
If you'd like to hear more
about this project and Start

00:21:26.960 --> 00:21:29.730
with One, if you'd like to
hear more about Dimitri, Steve,

00:21:29.730 --> 00:21:31.430
and actually play
Teachable Machine,

00:21:31.430 --> 00:21:34.330
we have all of these projects
in the Experiment Sandbox

00:21:34.330 --> 00:21:37.550
tent, which is actually
really close to the stage.

00:21:37.550 --> 00:21:40.880
And finally, lastly,
we'd like to invite you

00:21:40.880 --> 00:21:42.440
to help this research effort.

00:21:42.440 --> 00:21:44.180
As Michael was saying,
we don't expect

00:21:44.180 --> 00:21:46.580
people to train 15,000
phrases in order

00:21:46.580 --> 00:21:49.010
to get a model like
this, so we actually

00:21:49.010 --> 00:21:52.010
need volunteers to share
their voice samples with us

00:21:52.010 --> 00:21:54.210
so that we may one day
generalize these models.

00:21:54.210 --> 00:21:57.520
So if you or anyone you know
has hard-to-understand speech,

00:21:57.520 --> 00:21:59.270
we'd like to invite
you to go to this link

00:21:59.270 --> 00:22:01.880
and submit some samples,
and hopefully one day we

00:22:01.880 --> 00:22:05.130
can make these models more
widely accessible to everyone.

00:22:05.130 --> 00:22:05.840
Thank you.

00:22:05.840 --> 00:22:07.040
[APPLAUSE]

00:22:10.340 --> 00:22:13.090
[MUSIC PLAYING]

