WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:02.480
PETER HODGSON: Hi,
I'm Peter Hodgson.

00:00:02.480 --> 00:00:04.830
I am an interaction designer
working on conversations

00:00:04.830 --> 00:00:06.420
with the Google Assistant.

00:00:06.420 --> 00:00:08.189
And over the next
few minutes, I'll

00:00:08.189 --> 00:00:11.010
be describing the core pillars
to be conscious of when

00:00:11.010 --> 00:00:13.350
you're designing
conversational experiences

00:00:13.350 --> 00:00:16.200
and some hard learned
design lessons.

00:00:16.200 --> 00:00:20.142
But first, let's talk
about conversation itself.

00:00:20.142 --> 00:00:22.350
For many people who are new
to designing and building

00:00:22.350 --> 00:00:24.900
conversational experiences,
this is the big question

00:00:24.900 --> 00:00:26.220
in their mind.

00:00:26.220 --> 00:00:27.720
I mean, you can talk.

00:00:27.720 --> 00:00:28.380
I can talk.

00:00:28.380 --> 00:00:30.486
How hard can it be?

00:00:30.486 --> 00:00:31.860
Well, it turns
out that we humans

00:00:31.860 --> 00:00:34.500
have had a lot of practice
with conversation.

00:00:34.500 --> 00:00:37.140
Recent evidence suggests that
humans have been conversing

00:00:37.140 --> 00:00:39.490
for up to half a million years.

00:00:39.490 --> 00:00:42.210
Researchers have discovered
that the common ancestor

00:00:42.210 --> 00:00:45.180
of Neanderthals and
Homo sapiens had

00:00:45.180 --> 00:00:49.470
the hyoid bone in their throat,
which controls the tongue.

00:00:49.470 --> 00:00:53.010
And conversation is inherently
social and contextual.

00:00:53.010 --> 00:00:55.650
Every one of us here has
been practicing speaking

00:00:55.650 --> 00:00:57.240
since before we could walk.

00:00:57.240 --> 00:01:00.390
So it's literally
instinctive to us,

00:01:00.390 --> 00:01:05.280
which makes it extremely complex
and subtle and hard to codify.

00:01:05.280 --> 00:01:07.350
As a colleague of
ours likes to say,

00:01:07.350 --> 00:01:10.020
we don't have to think about
conversation in the same way

00:01:10.020 --> 00:01:13.440
that fish don't have to
think about the water.

00:01:13.440 --> 00:01:15.420
The key point for us
all is that people

00:01:15.420 --> 00:01:18.940
aren't going to change how
they converse anytime soon.

00:01:18.940 --> 00:01:21.270
So we need to design
conversational interfaces

00:01:21.270 --> 00:01:23.970
to match people's expectations.

00:01:23.970 --> 00:01:26.910
We're teaching computers to
speak human, not the other way

00:01:26.910 --> 00:01:29.320
around.

00:01:29.320 --> 00:01:30.810
The good news is
that people have

00:01:30.810 --> 00:01:33.564
been studying and researching
language for a long time.

00:01:33.564 --> 00:01:34.980
And we can leverage
that knowledge

00:01:34.980 --> 00:01:37.830
when designing
conversational interfaces.

00:01:37.830 --> 00:01:40.380
And when you're starting
to design conversations

00:01:40.380 --> 00:01:42.990
there are three ideas
or pillars that I think

00:01:42.990 --> 00:01:45.570
you should pin on the wall.

00:01:45.570 --> 00:01:48.360
The first pillar is the
cooperative principle

00:01:48.360 --> 00:01:51.900
identified by the philosopher
of language Paul Grice.

00:01:51.900 --> 00:01:54.600
It describes the rules
and assumptions we all

00:01:54.600 --> 00:01:56.670
abide by in our conversations.

00:01:56.670 --> 00:01:59.550
And we do so entirely
subconsciously.

00:01:59.550 --> 00:02:04.230
His maxims of quality,
quantity, relevance, and manner

00:02:04.230 --> 00:02:06.600
can be used as
reliable guidelines

00:02:06.600 --> 00:02:09.389
when you're creating
conversations.

00:02:09.389 --> 00:02:11.009
For example, the
maxim of quantity

00:02:11.009 --> 00:02:14.700
says that we expect participants
in a conversation to

00:02:14.700 --> 00:02:17.430
and I quote, "not make
their contributions

00:02:17.430 --> 00:02:20.280
more or less informative
than is required

00:02:20.280 --> 00:02:22.830
to advance the conversation."

00:02:22.830 --> 00:02:25.050
And I'll bet you can
all recall conversations

00:02:25.050 --> 00:02:28.800
you've had with people who
are not abiding by this maxim.

00:02:28.800 --> 00:02:30.840
That's the person
who talks too much

00:02:30.840 --> 00:02:33.390
or the person who
doesn't say enough.

00:02:33.390 --> 00:02:36.390
So I encourage you all to
study the cooperative principle

00:02:36.390 --> 00:02:38.370
in detail.

00:02:38.370 --> 00:02:39.990
If the cooperative
principle deals

00:02:39.990 --> 00:02:43.110
with the content or the
fuel of a conversation,

00:02:43.110 --> 00:02:46.080
then turn taking is the
engine and the gearbox.

00:02:46.080 --> 00:02:48.870
And it is the second
pillar to bear in mind.

00:02:48.870 --> 00:02:50.790
Turn taking is the
mechanism by which

00:02:50.790 --> 00:02:54.270
we resolve ambiguity and
repair conversations in order

00:02:54.270 --> 00:02:57.300
to progress to a
final resolution.

00:02:57.300 --> 00:02:59.760
Linguists will refer to
people handing the turn

00:02:59.760 --> 00:03:02.050
or taking the turn
in a conversation.

00:03:02.050 --> 00:03:04.830
And in the real world we
use linguistic prompts--

00:03:04.830 --> 00:03:06.720
questions or just
body language--

00:03:06.720 --> 00:03:09.720
to signify when the
turn should be taken.

00:03:09.720 --> 00:03:11.550
For the moment,
Virtual Assistant

00:03:11.550 --> 00:03:14.610
understand none of these
subtle social cues.

00:03:14.610 --> 00:03:17.160
So turn taking for
conversational assistance

00:03:17.160 --> 00:03:19.000
has to be more explicit.

00:03:19.000 --> 00:03:21.960
And we have to manage this when
writing dialogue so it doesn't

00:03:21.960 --> 00:03:25.440
become unnatural or robotic.

00:03:25.440 --> 00:03:27.750
The third pillar is to
design conversations that

00:03:27.750 --> 00:03:30.000
work for the user's context.

00:03:30.000 --> 00:03:32.520
Talking to machines is
still in its infancy.

00:03:32.520 --> 00:03:35.280
And people still find
it socially awkward.

00:03:35.280 --> 00:03:38.340
So you should actively focus
on the user's physical context

00:03:38.340 --> 00:03:39.990
and the kinds of
conversations they're

00:03:39.990 --> 00:03:42.720
open to in that context.

00:03:42.720 --> 00:03:45.660
And look to design for
simple, intuitive, high value

00:03:45.660 --> 00:03:49.770
conversations while people are
in socially safe environments

00:03:49.770 --> 00:03:53.070
and where voice interactions
have less friction than touch.

00:03:53.070 --> 00:03:56.190
So the three pillars are the
cooperative principle, turn

00:03:56.190 --> 00:03:59.380
taking, and the user context.

00:03:59.380 --> 00:04:02.940
And here are my five
top lessons learned.

00:04:02.940 --> 00:04:05.940
First, persona-- designing
your system's persona

00:04:05.940 --> 00:04:07.090
is not a nice to have.

00:04:07.090 --> 00:04:08.740
It's a must have.

00:04:08.740 --> 00:04:10.440
There's another
video in this series.

00:04:10.440 --> 00:04:12.310
And it's a detailed
talk about this topic,

00:04:12.310 --> 00:04:14.160
which I encourage you to watch.

00:04:14.160 --> 00:04:15.750
But it's worth
highlighting here.

00:04:15.750 --> 00:04:18.630
A persona is a style
template for your brand.

00:04:18.630 --> 00:04:20.579
You should design it
and use it to provide

00:04:20.579 --> 00:04:23.730
a common understanding and
a reference for consistency

00:04:23.730 --> 00:04:25.830
during every step of your
conversational design

00:04:25.830 --> 00:04:27.090
development.

00:04:27.090 --> 00:04:29.700
As another colleague puts
it, if you don't clearly

00:04:29.700 --> 00:04:33.630
define your brand personas,
then your users will.

00:04:33.630 --> 00:04:35.850
Second-- and another must do--

00:04:35.850 --> 00:04:37.800
start with the sample dialog--

00:04:37.800 --> 00:04:40.320
whatever the platform,
you'll be deploying on.

00:04:40.320 --> 00:04:44.042
Create end-to-end sample dialogs
for the most likely cases.

00:04:44.042 --> 00:04:45.750
Writing the dialog
will help you discover

00:04:45.750 --> 00:04:48.510
more cases and the
conversational logic

00:04:48.510 --> 00:04:50.340
you'll need to build.

00:04:50.340 --> 00:04:51.660
Don't just write the dialog.

00:04:51.660 --> 00:04:53.740
Speak it out loud
with someone else.

00:04:53.740 --> 00:04:56.280
It'll change what
you've written.

00:04:56.280 --> 00:04:58.230
And present dialog
to stakeholders

00:04:58.230 --> 00:05:00.900
in the audio channel,
not as written text.

00:05:00.900 --> 00:05:03.270
You can record it
using a TTS engine

00:05:03.270 --> 00:05:05.160
and listen to the playback.

00:05:05.160 --> 00:05:07.620
After you've nailed the most
likely cases in the sample

00:05:07.620 --> 00:05:11.040
dialogs, then design
all the repair cases.

00:05:11.040 --> 00:05:12.690
Designing for
conversational repair

00:05:12.690 --> 00:05:14.190
is the topic of another video.

00:05:14.190 --> 00:05:16.764
But bear these things in mind.

00:05:16.764 --> 00:05:18.180
We need to make
conversations work

00:05:18.180 --> 00:05:20.010
well when it goes off track.

00:05:20.010 --> 00:05:22.440
These can be points of
great user frustration.

00:05:22.440 --> 00:05:24.900
And so if handled well,
they're great opportunities

00:05:24.900 --> 00:05:28.170
to rebuild user
trust and confidence.

00:05:28.170 --> 00:05:30.060
Your Assistants
should be forgiving.

00:05:30.060 --> 00:05:31.680
Remember, people
are instinctively

00:05:31.680 --> 00:05:33.030
trying to be cooperative.

00:05:33.030 --> 00:05:33.840
But we're human.

00:05:33.840 --> 00:05:35.160
And we make mistakes.

00:05:35.160 --> 00:05:38.010
So we need to be highly focused
on helping them get back

00:05:38.010 --> 00:05:40.710
on track as naturally
as possible.

00:05:40.710 --> 00:05:42.270
And here's a top tip.

00:05:42.270 --> 00:05:45.090
A key approach for
identifying repair cases

00:05:45.090 --> 00:05:47.310
is to prototype the
conversation as early

00:05:47.310 --> 00:05:49.170
as you can in the process.

00:05:49.170 --> 00:05:51.870
Write and perform the
conversations with real users.

00:05:51.870 --> 00:05:53.700
And use "Wizard
of Oz" techniques

00:05:53.700 --> 00:05:56.790
with audio recordings to test
your conversational structure

00:05:56.790 --> 00:05:58.860
and dialog.

00:05:58.860 --> 00:06:01.350
Next we're building
a system for users

00:06:01.350 --> 00:06:04.060
to access their
Assistant anywhere.

00:06:04.060 --> 00:06:06.570
So you must consider your
conversational experiences

00:06:06.570 --> 00:06:09.330
across modalities and surfaces.

00:06:09.330 --> 00:06:11.280
In some cases, the
conversational logic

00:06:11.280 --> 00:06:14.280
might have to change
depending on the surface.

00:06:14.280 --> 00:06:16.890
For example, presenting
choices to users on an eyes

00:06:16.890 --> 00:06:18.990
free device, such
as a Google Home

00:06:18.990 --> 00:06:21.390
requires different
dialog strategies

00:06:21.390 --> 00:06:25.172
than when the user can pick from
a list of choices on a screen.

00:06:25.172 --> 00:06:27.630
And designing for multi-modal
conversations with the screen

00:06:27.630 --> 00:06:28.710
is hard.

00:06:28.710 --> 00:06:30.420
The important thing
to remember is

00:06:30.420 --> 00:06:32.880
that in multi-modal
conversations

00:06:32.880 --> 00:06:36.510
the screen is only one output
of the conversational state.

00:06:36.510 --> 00:06:40.410
There's both audio and visual
channels to be choreographed.

00:06:40.410 --> 00:06:42.450
So think hard about
the best channels

00:06:42.450 --> 00:06:44.040
for information transfer.

00:06:44.040 --> 00:06:45.300
What's best on screen?

00:06:45.300 --> 00:06:46.800
What's best in audio?

00:06:46.800 --> 00:06:49.950
Where's the right balance
for your conversation?

00:06:49.950 --> 00:06:52.260
In a multi-modal
experience screens

00:06:52.260 --> 00:06:55.770
are really great for presenting
large amounts of information.

00:06:55.770 --> 00:06:57.660
They're great for
displaying touch avoidances

00:06:57.660 --> 00:07:00.150
to repair or to progress a
conversation more quickly

00:07:00.150 --> 00:07:02.370
than with another spoken turn.

00:07:02.370 --> 00:07:05.310
And the screens are useful
for orienting the user and way

00:07:05.310 --> 00:07:08.770
finding in a multi-step task.

00:07:08.770 --> 00:07:10.410
Finally, with the
Assistant you're

00:07:10.410 --> 00:07:13.099
designing for use over time.

00:07:13.099 --> 00:07:14.640
The second conversation
with the user

00:07:14.640 --> 00:07:16.740
will always be different
from the first.

00:07:16.740 --> 00:07:19.680
And the third may be
different from the second.

00:07:19.680 --> 00:07:21.570
We expect a
conversational Assistant

00:07:21.570 --> 00:07:23.790
to understand and remember us.

00:07:23.790 --> 00:07:26.910
So the conversations
should reflect that memory.

00:07:26.910 --> 00:07:29.880
Just keeping track of previous
conversations and a user's

00:07:29.880 --> 00:07:32.220
context and adjusting
the conversation

00:07:32.220 --> 00:07:34.320
based on these
cues will increase

00:07:34.320 --> 00:07:37.950
the perception of an
intelligent agent significantly.

00:07:37.950 --> 00:07:41.220
So design your persona.

00:07:41.220 --> 00:07:43.320
Always start with
the sample dialogs.

00:07:43.320 --> 00:07:45.810
Repair with context sensitivity.

00:07:45.810 --> 00:07:48.960
Design cross platform from
eyes free to multimodal.

00:07:48.960 --> 00:07:51.510
And design for frequency.

00:07:51.510 --> 00:07:54.044
And never forget the
cooperative principle.

00:07:54.044 --> 00:07:55.710
Good luck with your
conversation design.

00:07:55.710 --> 00:07:58.100
And thanks for listening.

