WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.070
So, the main topic for the next couple
lectures is continuous distributions.

00:00:05.070 --> 00:00:07.760
We've learned about the binomial,
and the poisson, and

00:00:07.760 --> 00:00:11.130
the hypergeometric, and so on, and
at this point we've covered all of

00:00:11.130 --> 00:00:16.220
the famous discreet distributions
that we need in this course.

00:00:16.220 --> 00:00:20.129
And no now is a good time to start talking
about the continuous distributions.

00:00:22.330 --> 00:00:25.208
I like to do discreet before continuous,

00:00:25.208 --> 00:00:29.577
because conceptually it's
simpler to think about discreet.

00:00:29.577 --> 00:00:32.789
But it doesn't mean that
continuous is harder, necessarily,

00:00:32.789 --> 00:00:35.975
because discreet is kind of
conceptually easier in a sense.

00:00:35.975 --> 00:00:39.905
But, on the other hand, we have all
these nasty sums that come up, and so

00:00:39.905 --> 00:00:44.285
we learn some ways to sometimes
avoid the sums using stories, and so

00:00:44.285 --> 00:00:47.665
on, but sometimes you just have
the sum you can't deal with.

00:00:47.665 --> 00:00:52.293
The continuous case, we'll be doing
integrals instead of sums, and even though

00:00:52.293 --> 00:00:57.270
this sounds counterintuitive, in general,
it's easier to do an integral than a sum.

00:00:57.270 --> 00:00:59.137
Although the same thing could come up,

00:00:59.137 --> 00:01:01.866
we could be faced with integrals
we don't know how to do.

00:01:01.866 --> 00:01:05.145
So again, we're gonna try to look for
kind of more clever,

00:01:05.145 --> 00:01:09.357
and more conceptual ways to avoid having
to do lots and lots of integration.

00:01:09.357 --> 00:01:12.280
But anyway, we'll come to that later.

00:01:12.280 --> 00:01:14.320
But, a lot of the ideas
are completely analogous.

00:01:14.320 --> 00:01:18.410
So, at this point, I'm assuming you
have a pretty good understanding of

00:01:18.410 --> 00:01:23.480
what a PMF is, and
what is a discreet distribution?

00:01:23.480 --> 00:01:28.320
What does it really mean, and the expected
value of a discreet distribution, and

00:01:28.320 --> 00:01:31.070
now we're just gonna move
into the continuous case.

00:01:31.070 --> 00:01:35.209
So, I think, and just for
having a big picture on this,

00:01:35.209 --> 00:01:38.832
it helps to just kind of
contrast the two things.

00:01:38.832 --> 00:01:44.410
So I'm gonna make kind of a dictionary
of discrete world and continuous worlds.

00:01:44.410 --> 00:01:49.110
So we can put discrete world over here and
continuous world over here.

00:01:53.470 --> 00:01:56.540
So we have a random variable
that we're looking at, and

00:01:56.540 --> 00:02:00.210
usually we've been calling our random
variable x in the discrete case,

00:02:00.210 --> 00:02:03.720
and usually we'll call it
x in the continuous case.

00:02:03.720 --> 00:02:05.970
So, so far it's completely analogous.

00:02:05.970 --> 00:02:07.860
We got discrete, continuous.

00:02:07.860 --> 00:02:12.709
Now in the discrete case, as you're very
familiar with by now, we have a PMF,

00:02:16.135 --> 00:02:22.980
Which you can just think of as the P(X=x),
viewed as a function of little x.

00:02:22.980 --> 00:02:27.050
So if it takes positive integer values,
then I would need to specify this for

00:02:27.050 --> 00:02:28.460
all positive integers x.

00:02:29.910 --> 00:02:37.137
In the continuous case, the [P(X=x)=0].

00:02:37.137 --> 00:02:41.987
So in that case we have a PDF instead,
which usually we would

00:02:41.987 --> 00:02:46.555
write as f(x), but
you can call it whatever you want.

00:02:46.555 --> 00:02:50.398
I'll call it f sub x (x) just to
emphasize that this is the PDF of x.

00:02:50.398 --> 00:02:54.544
So I'm gonna tell you what a PDF is,
but I'm just telling you now,

00:02:54.544 --> 00:02:56.483
that it's analogous to a PMF.

00:02:56.483 --> 00:03:03.619
The reason we need this
is that the [P(X=x)=0].

00:03:03.619 --> 00:03:08.121
So continuous, it means we're thinking of
random variables that could take on any

00:03:08.121 --> 00:03:11.340
real value, or
maybe any real number in some interval.

00:03:11.340 --> 00:03:13.650
So say we had the interval
from zero to one,

00:03:13.650 --> 00:03:18.060
and X is allowed to take on real
number value between zero and one.

00:03:20.760 --> 00:03:24.780
Well, I mean we could make up examples
where this not true, but in the continuous

00:03:24.780 --> 00:03:28.620
case every, there are uncountably many
real number between zero and one, and

00:03:28.620 --> 00:03:37.000
any specific number like Pi
over four has probability zero.

00:03:37.000 --> 00:03:40.640
So if we just try to write down a PMF
we would just say it's zero, and

00:03:40.640 --> 00:03:41.944
that would be useless.

00:03:41.944 --> 00:03:44.280
So that's why we need
something else instead.

00:03:44.280 --> 00:03:48.250
So, I'll tell you what a PDF is,
but that's the analogy.

00:03:48.250 --> 00:03:49.740
Just to continue this a little more,

00:03:49.740 --> 00:03:52.630
then I'll start telling you
more about what PDFs are.

00:03:54.160 --> 00:03:55.330
We have a CDF.

00:03:56.800 --> 00:04:02.190
That's this function F(x)=P(X&lt;/=x),

00:04:02.190 --> 00:04:06.140
and sometimes we'll subscript the x just
because maybe if we add another random

00:04:06.140 --> 00:04:11.160
variable y, we could write F sub y for
its CDF, okay?

00:04:11.160 --> 00:04:17.959
Well, in the continuous case we
have a CDF, exactly the same thing.

00:04:17.959 --> 00:04:21.432
So that's one advantage, and
we've seen in the discrete case,

00:04:21.432 --> 00:04:24.603
usually it's easier to deal
with the PMF than with the CDF.

00:04:24.603 --> 00:04:29.220
The CDF in the discrete case is a lot like
a step function with all these jumps.

00:04:29.220 --> 00:04:32.434
It's not so easy to deal with,
and this is much more direct.

00:04:32.434 --> 00:04:36.220
But one virtue of CDFs is
a CDF is completely general.

00:04:36.220 --> 00:04:40.020
So every random variable has a CDF, and so
we don't need to separate out the theory.

00:04:42.310 --> 00:04:46.199
Now, let's talk about PDFs.

00:04:48.349 --> 00:04:51.482
So, now this is a PMF.

00:04:51.482 --> 00:04:59.450
So the PDF is the most common way to
specify a continuous distribution.

00:04:59.450 --> 00:05:03.721
PDF stands for
probability density function,

00:05:03.721 --> 00:05:09.602
not portable document format,
probability density function.

00:05:13.844 --> 00:05:18.687
Okay, so the keyword here is density.

00:05:18.687 --> 00:05:21.830
The common mistake with PDFs is to
think that they're probabilities.

00:05:21.830 --> 00:05:24.359
It's not a probability,
it's a probability density.

00:05:24.359 --> 00:05:28.767
So you can think of density,
just in an intuitive sense as like,

00:05:28.767 --> 00:05:30.900
think of probability as mass.

00:05:30.900 --> 00:05:33.910
Remember if the pebbles with
the total mass equals one?

00:05:33.910 --> 00:05:38.071
But in the continuous case we can't think
of pebbles any more, it's more like

00:05:38.071 --> 00:05:42.250
we just have this kind of massive of mud
that we're smearing around the space.

00:05:42.250 --> 00:05:46.080
So I think of discrete as pebbles,
continuous as mud.

00:05:46.080 --> 00:05:51.030
The total mass of the mud is one,
and density, makes you think

00:05:51.030 --> 00:05:55.650
of mass per volume, mass per area,
things like that, mass per length.

00:05:55.650 --> 00:06:00.380
Okay, so it's probability per something,
but not probability.

00:06:01.760 --> 00:06:07.055
So we say that x, this is a definition.

00:06:07.055 --> 00:06:11.084
A random variable, X,

00:06:11.084 --> 00:06:16.523
has PDF F(x) if in order to find

00:06:16.523 --> 00:06:22.365
probabilities for X we can achieve

00:06:22.365 --> 00:06:27.413
that by integrating the PDF.

00:06:27.413 --> 00:06:32.787
So, if the probability of
let's say X is between a and

00:06:32.787 --> 00:06:36.370
b, that is X is in some interval a b,

00:06:36.370 --> 00:06:41.660
must be given by the integral
from a to b of f(x)dx.

00:06:41.660 --> 00:06:43.140
For all a and b.

00:06:48.268 --> 00:06:53.330
So, f(x) is not a probability, it's
what you integrate to get probability.

00:06:53.330 --> 00:06:55.869
Integrated density,
then you get a probability.

00:06:57.370 --> 00:07:04.040
So that's the definition, and let's see
how this relates to CDF and other things.

00:07:04.040 --> 00:07:06.850
Notice, by the way, that if we let a = b,

00:07:10.038 --> 00:07:14.930
Then we're integrating from a to a,
of f(x)dx.

00:07:14.930 --> 00:07:18.987
So that's the area under the curve
from a to a, which is zero,

00:07:18.987 --> 00:07:23.604
cuz you haven't actually specified
any interval, so that's zero.

00:07:26.766 --> 00:07:30.650
Which agrees with what I said there, the
probability of any specific point is zero.

00:07:30.650 --> 00:07:35.080
We need an interval of non-zero length.

00:07:35.080 --> 00:07:40.191
Okay, so that's called a PDF,
and to be valid, remember, for

00:07:40.191 --> 00:07:45.114
a PMF, I said that a PMF is valid
if they're non-negative and

00:07:45.114 --> 00:07:47.930
they sum up to one, right?

00:07:47.930 --> 00:07:53.052
So by analogy, for
a PDF we want them to be non-negative,

00:07:53.052 --> 00:07:57.240
and rather than summing to one,
it should integrate to one.

00:07:58.330 --> 00:08:02.840
Okay, so to be valid,
f(x) is greater than or equal to 0, and

00:08:02.840 --> 00:08:07.750
the integral of f(x) for
minus infinity to infinity should equal 1.

00:08:07.750 --> 00:08:12.240
Otherwise, we have not
specified a valid PDF.

00:08:12.240 --> 00:08:15.730
So it might look something like,

00:08:15.730 --> 00:08:20.973
just to draw a picture,
an example, maybe a PDF.

00:08:20.973 --> 00:08:25.490
A famous example would be the bell curve
type of thing that we'll get to later.

00:08:25.490 --> 00:08:28.460
But anyway, for
the purpose of the picture,

00:08:28.460 --> 00:08:33.512
I don't really care exactly what
the definition of this function is.

00:08:33.512 --> 00:08:37.030
But I'm just drawing some curve
from minus infinity to infinity.

00:08:37.030 --> 00:08:40.731
Now it might be that it's
0 on the negative side and

00:08:40.731 --> 00:08:46.771
only positive to the right or whatever,
but it's some continuous looking curve.

00:08:46.771 --> 00:08:51.038
And the total area, if I shaded
the whole area under this curve,

00:08:51.038 --> 00:08:52.630
I would get 1, right?

00:08:52.630 --> 00:08:57.168
And so larger points where the density,
I drew a symmetric one, but

00:08:57.168 --> 00:09:02.310
it doesn't have to be symmetric,
it could be some nasty looking curve.

00:09:02.310 --> 00:09:05.859
As long as it's non-negative and
the area under the curve is 1,

00:09:05.859 --> 00:09:07.483
those are the requirements.

00:09:11.277 --> 00:09:17.000
So to kind of interpret a little more
of what does the density really mean?

00:09:17.000 --> 00:09:18.570
Cuz I said it's not a probability.

00:09:19.770 --> 00:09:25.407
If we take f(x), let's say, at some
point x0, what is that really like?

00:09:25.407 --> 00:09:30.710
If we take some point x0 here and
we say the density is this number.

00:09:30.710 --> 00:09:31.650
What does that mean?

00:09:32.750 --> 00:09:35.220
It's possible that this
number is greater than 1, for

00:09:35.220 --> 00:09:38.990
example, because you can have a function
that sometimes is greater than 1, but

00:09:38.990 --> 00:09:42.220
the integral could still be 1, right?

00:09:42.220 --> 00:09:48.316
So we can't say that's a probability, but
what we can say is, so this is a density.

00:09:48.316 --> 00:09:53.879
So if you think of it as like
probability per unit of length,

00:09:53.879 --> 00:09:58.997
then if we multiply by some small number,
let's say,

00:09:58.997 --> 00:10:03.563
epsilon is approximately
the probability that x

00:10:03.563 --> 00:10:07.710
will fall in an interval
of length epsilon.

00:10:08.720 --> 00:10:15.823
Let's call this, let's say,
x0- epsilon/2, X0 + epsilon/2.

00:10:15.823 --> 00:10:18.362
So all I did was take x0.

00:10:18.362 --> 00:10:23.404
The probability of the random variable
exactly equaling x0 is 0, okay?

00:10:23.404 --> 00:10:26.799
But if we take some tiny,
so for epsilon, very small.

00:10:32.410 --> 00:10:37.939
So the probability is 0 of it equaling x0,
but we take some tiny little

00:10:37.939 --> 00:10:43.484
interval around x0, I just wrote
down an interval of length epsilon.

00:10:43.484 --> 00:10:48.850
Then the probability is approximately the
density times the length of that interval.

00:10:48.850 --> 00:10:52.430
But by multiplying by this epsilon here,
we're kind of converting it back into

00:10:52.430 --> 00:10:54.810
a probability scale instead
of a density scale.

00:10:56.280 --> 00:11:00.930
And to see, so this is kind of a good
intuitive way to think of a density.

00:11:00.930 --> 00:11:02.000
But I haven't yet

00:11:02.000 --> 00:11:06.570
shown you why is that equivalent to this
mathematical thing that I wrote here.

00:11:06.570 --> 00:11:10.594
But to see why this is true,
just by staring at this,

00:11:12.823 --> 00:11:16.160
If we wanna find the probability,
then what do we do?

00:11:16.160 --> 00:11:19.340
We integrate the pdf from here to here,
right?

00:11:19.340 --> 00:11:24.552
So imagine this integral where you're
integrating from here to here, okay?

00:11:24.552 --> 00:11:31.000
And then let's think about
what would that integral be.

00:11:31.000 --> 00:11:36.908
Well, I didn't just say epsilon was small,
I said epsilon is very small.

00:11:36.908 --> 00:11:38.680
I could have said very, very small.

00:11:40.080 --> 00:11:45.050
Now if epsilon is very,
very, very small, what that

00:11:45.050 --> 00:11:50.130
means is that in that tiny little
interval, f is not gonna change very much.

00:11:50.130 --> 00:11:53.950
So over that tiny miniscule interval,

00:11:53.950 --> 00:11:56.930
we can treat this function as
being approximately a constant.

00:11:56.930 --> 00:11:58.834
And it's easy to integrate a constant,

00:11:58.834 --> 00:12:02.651
the integral of a constant is just the
constant times the length of the interval.

00:12:02.651 --> 00:12:06.000
And that's all we did, so we're treating
it, if it's approximately this constant on

00:12:06.000 --> 00:12:08.240
that interval times
the length of the interval.

00:12:08.240 --> 00:12:10.160
So, that's why this follows from this.

00:12:10.160 --> 00:12:15.030
And this is more useful for driving
things, but this gives you some more

00:12:15.030 --> 00:12:19.530
intuition on what's the difference between
a probability density and a probability.

00:12:21.400 --> 00:12:27.905
Okay, so, let's see how is
this thing related to the CDF?

00:12:29.655 --> 00:12:35.071
So if x has PDF, little f,

00:12:35.071 --> 00:12:39.511
let's find the CDF.

00:12:44.567 --> 00:12:50.722
Well, by definition, the CDF is
the probability, That x is less than or

00:12:50.722 --> 00:12:55.357
equal to little x, but by definition,
I said the definition of a PDF is

00:12:55.357 --> 00:12:59.773
that's the thing that you integrate
to get probability, right?

00:12:59.773 --> 00:13:03.197
So if I wanna know what's
the probability that x is in any region,

00:13:03.197 --> 00:13:05.960
all I do is integrate
the PDF over that region.

00:13:05.960 --> 00:13:11.560
So here, it would simply integrate
from minus infinity to x of,

00:13:11.560 --> 00:13:16.540
I could call it f(x)dx, but it's a little
bit clearer to change the letter,

00:13:16.540 --> 00:13:18.070
so f(t)dt.

00:13:18.070 --> 00:13:19.830
t is just a dummy variable here.

00:13:19.830 --> 00:13:22.364
I just didn't want it
to clash with this x.

00:13:22.364 --> 00:13:27.090
That is, for any particular number x,
we're gonna take this curve.

00:13:27.090 --> 00:13:29.340
Let's say x is here.

00:13:31.840 --> 00:13:33.838
If this x is this x we're looking at,

00:13:33.838 --> 00:13:37.775
then we're saying just look at the area
under the curve up to this point.

00:13:37.775 --> 00:13:40.559
That would give us the CDF at that point,
all right?

00:13:40.559 --> 00:13:43.543
Because we wanna know the probability
of everything to the left, and

00:13:43.543 --> 00:13:46.125
probability is given just by
taking area under this curve.

00:13:46.125 --> 00:13:49.010
So it's just the area under the curve
from minus infinity up to x.

00:13:49.010 --> 00:13:50.900
That's all we're doing.

00:13:50.900 --> 00:13:56.721
So that shows how to get
from a PDF to a CDF, okay?

00:13:56.721 --> 00:14:03.430
Well, what about the other way around,
if we have a CDF, how do we get the PDF?

00:14:03.430 --> 00:14:11.320
So go the other way around,
if x has CDF, capital F, and of course,

00:14:11.320 --> 00:14:14.750
we're assuming it's a continuous
random variable, not a discrete one.

00:14:14.750 --> 00:14:19.614
So in the continuous case, by the way,
the terminology, it could be slightly

00:14:19.614 --> 00:14:23.744
confusing because when we say we
have a continuous distribution,

00:14:23.744 --> 00:14:26.346
it means capital F should be continuous.

00:14:26.346 --> 00:14:28.530
But we don't just want
it to be continuous,

00:14:28.530 --> 00:14:30.189
we want it to be differentiable.

00:14:30.189 --> 00:14:35.150
So the continuous refers to not so
much to F being a continuous function.

00:14:35.150 --> 00:14:38.830
It refers to the fact that x can
take on a whole continuum of values,

00:14:38.830 --> 00:14:42.570
rather than just discrete values, okay?

00:14:42.570 --> 00:14:48.831
So if it has CDF F, and
x is a continuous random variable,

00:14:48.831 --> 00:14:55.551
and then we want to get,
From the CDF to the PDF,

00:14:58.143 --> 00:15:04.831
So f(x) =, so let's think about that.

00:15:10.090 --> 00:15:13.364
This is the relationship between a CDF and
a PDF, okay?

00:15:13.364 --> 00:15:19.670
And but now I wanna say, if we know this
integral, how can we extract out this?

00:15:21.460 --> 00:15:26.116
Well, the answer is just take
the derivative, right, f(x) = F'(x).

00:15:28.356 --> 00:15:29.670
And why is that true?

00:15:31.220 --> 00:15:38.650
Your favorite theorem of calculus, that's
the fundamental theorem of calculus, FTC.

00:15:40.538 --> 00:15:43.889
Actually, we're gonna need both parts of
the fundamental theorem of calculus, so

00:15:43.889 --> 00:15:46.170
it's nice that actually that
it is pretty fundamental.

00:15:47.990 --> 00:15:51.560
At least the way I learned it, part one of
the fundamental theorem of calculus said

00:15:51.560 --> 00:15:55.450
if you have an integral that looks like
this, up to some indetermined upper limit,

00:15:55.450 --> 00:15:58.300
if you take the derivative of that,
then you just get this function.

00:15:58.300 --> 00:16:00.050
So that's the first part of
the fundamental theorem of calculus.

00:16:01.200 --> 00:16:06.073
The second part of the fundamental
theorem of calculus says that if you

00:16:06.073 --> 00:16:08.220
wanna do a definite integral,

00:16:08.220 --> 00:16:13.106
you find anti-derivative and
then evaluate it at the two end points.

00:16:13.106 --> 00:16:18.334
So okay, this is just saying
the derivative of the CDF is the PDF,

00:16:18.334 --> 00:16:20.344
in the continuous case.

00:16:20.344 --> 00:16:24.300
So it's a very straightforward
relationship between them.

00:16:24.300 --> 00:16:30.950
And if we wanted to know, this also kind
of confirms something we did earlier.

00:16:30.950 --> 00:16:35.214
Let's say we wanna know the probability
that x is between a and b.

00:16:35.214 --> 00:16:40.865
And in the discrete case it's crucial
whether less than or equal, and so on.

00:16:40.865 --> 00:16:44.793
In the continuous case, it makes no
difference if you write strict or

00:16:44.793 --> 00:16:45.828
not strict here.

00:16:45.828 --> 00:16:48.794
So according to the definition of a PDF,

00:16:48.794 --> 00:16:54.300
if we wanna get the probability of this
interval that x is in that interval.

00:16:54.300 --> 00:16:58.380
All we do is integrate
the PDF from there to there.

00:16:58.380 --> 00:17:01.981
But another way to think about this would
be, remember your fundamental theorem of

00:17:01.981 --> 00:17:04.462
calculus, and
the notation matches up pretty well too.

00:17:04.462 --> 00:17:09.029
Because, like in AP calculus, usually if
you have a function little f, usually it

00:17:09.029 --> 00:17:14.150
will call its anti-derivative capital F,
which is exactly what we're doing here.

00:17:14.150 --> 00:17:17.702
If we wanna do this integral,
we take some anti-derivative.

00:17:17.702 --> 00:17:19.910
Well, we already have one, that's the CDF.

00:17:19.910 --> 00:17:21.630
And then we evaluate here, evaluate there.

00:17:21.630 --> 00:17:25.060
So that's just F(b)- F(a).

00:17:25.060 --> 00:17:30.688
So that's also true by
fundamental theorem of calculus.

00:17:30.688 --> 00:17:35.435
And that's similar to a result
that we had earlier for CDFs, so

00:17:35.435 --> 00:17:39.500
it's consistent with earlier stuff, okay?

00:17:39.500 --> 00:17:42.640
So we'll do some examples
in a little while.

00:17:42.640 --> 00:17:47.820
But right now this is just the general
framework, and making the analogy, okay?

00:17:47.820 --> 00:17:54.620
So we have a CDF, and I'll just add here,
just to have it in this dictionary too.

00:17:54.620 --> 00:17:59.233
That's the derivative of the PDF is
the derivative of the CDF, question?

00:17:59.233 --> 00:18:07.213
&gt;&gt; [INAUDIBLE]
&gt;&gt; Yeah,

00:18:07.213 --> 00:18:11.130
and the question is, in this framework,
is big F always differentiable?

00:18:11.130 --> 00:18:13.650
Yeah, we have to assume
that it's differentiable.

00:18:13.650 --> 00:18:16.630
I mean, there are functions
that are continuous, but

00:18:16.630 --> 00:18:19.290
not differentiable everywhere.

00:18:19.290 --> 00:18:22.720
But in that case it would just
be a more complicated thing.

00:18:22.720 --> 00:18:27.680
And when we say continuous random variable
in this course it means we have a CDF

00:18:27.680 --> 00:18:29.420
which has a derivative.

00:18:29.420 --> 00:18:33.250
Because if we don't have a PDF then we're
not dealing with continuous distributions

00:18:33.250 --> 00:18:35.340
and things can be much nastier.

00:18:35.340 --> 00:18:40.026
So yeah we're assuming that
this derivative exists.

00:18:40.026 --> 00:18:46.099
Okay, so that's, So
in general if I ask you,

00:18:46.099 --> 00:18:50.165
find the distribution of whatever,
in the continuous case,

00:18:50.165 --> 00:18:54.220
in the discrete case,
you can either give the PMF or the CDF.

00:18:54.220 --> 00:18:57.330
Those are equally valid ways
to describe a distribution.

00:18:57.330 --> 00:19:01.350
In a continuous case, you can give the PDF
or the CDF, those are equally valid ways.

00:19:02.830 --> 00:19:06.130
Okay, so let's continue this list.

00:19:06.130 --> 00:19:11.352
In the discrete case,
we have the expected value, right?

00:19:11.352 --> 00:19:16.862
And remember the expected value,
we just take the sum

00:19:16.862 --> 00:19:23.140
of the values times the probability
of the values, okay?

00:19:23.140 --> 00:19:25.830
So in the continuous case,

00:19:25.830 --> 00:19:29.810
this would just be 0 because all of
these are 0, so that's no useful.

00:19:29.810 --> 00:19:34.020
But by analogy, instead of a sum,
we'll do an integral.

00:19:34.020 --> 00:19:39.033
S the definition of the expected
value in the continuous

00:19:39.033 --> 00:19:42.800
case is that we integrate x times the PDF.

00:19:42.800 --> 00:19:44.150
So it's completely analogous.

00:19:45.740 --> 00:19:48.704
In general we're gonna integrate
from minus infinity to infinity.

00:19:48.704 --> 00:19:52.120
And sometimes we'll deal with random
variables where the only possible

00:19:52.120 --> 00:19:53.691
values are say between 0 and 1.

00:19:53.691 --> 00:19:57.512
And in that case we're just integrating
0 outside of that interval.

00:19:57.512 --> 00:20:00.990
So then we would restrict it to
the region where it's non-zero.

00:20:00.990 --> 00:20:05.102
But in general that's best the definition,
okay?

00:20:05.102 --> 00:20:08.125
So that's completely analogous.

00:20:10.471 --> 00:20:17.435
Let's do one more concept that applies in
both the discrete and continuous cases.

00:20:17.435 --> 00:20:24.510
And that's the notion of variance, so
we've been talking about expected values.

00:20:24.510 --> 00:20:29.680
But that's just giving a one number
summary of the average, right?

00:20:29.680 --> 00:20:34.850
But it is not telling us anything about
the spread of the distribution, right?

00:20:34.850 --> 00:20:36.110
How spread out is it?

00:20:36.110 --> 00:20:41.330
So for that, we need the idea of variance,
and the definition of the variance.

00:20:43.420 --> 00:20:44.410
So intuitively,

00:20:44.410 --> 00:20:48.600
variance is just supposed to be a measure
of how spread out the distribution is.

00:20:48.600 --> 00:20:52.970
That is, on average,
how far is x from its mean?

00:20:54.260 --> 00:20:58.700
So we might start by trying to do
the expected value of x minus the expected

00:20:58.700 --> 00:21:00.220
value of x.

00:21:00.220 --> 00:21:02.281
Here's the mean.

00:21:02.281 --> 00:21:05.259
This is the difference between x and
its mean.

00:21:05.259 --> 00:21:07.715
But if we just did this though,
we would always get 0, though.

00:21:07.715 --> 00:21:11.033
Because by linearity,
that's E of X- E of E of X.

00:21:11.033 --> 00:21:11.883
But E of E of X isn't E of X.

00:21:11.883 --> 00:21:13.799
Because it's just a constant, so

00:21:13.799 --> 00:21:17.430
this would be useful because
that would just be zero.

00:21:17.430 --> 00:21:21.331
Okay, so then I guess the most
obvious thing to me to do to

00:21:21.331 --> 00:21:24.735
fix that problem is to
put absolute value signs.

00:21:24.735 --> 00:21:29.082
Because then we're making
it non-negative and

00:21:29.082 --> 00:21:34.393
then there won't be 0 anymore,
except if x is a constant.

00:21:34.393 --> 00:21:39.313
But absolute values
are annoying to deal with.

00:21:39.313 --> 00:21:42.642
For example, the absolute value function,
it's this V shaped thing right?

00:21:42.642 --> 00:21:46.480
It has a sharp corner,
it's not differentiable.

00:21:46.480 --> 00:21:48.740
It is difficult to work with.

00:21:48.740 --> 00:21:54.340
So the standard way to deal with this is
instead of absolute values, to square it.

00:21:54.340 --> 00:21:56.890
One reason as I said is
that the absolute value

00:21:56.890 --> 00:21:58.740
is just annoying because
it's not differential.

00:21:59.990 --> 00:22:04.774
Kind of a deeper reason though is that
the square, anytime you see squares,

00:22:04.774 --> 00:22:09.205
it should start to reminding you
of the Pythagorean theorem, right?

00:22:09.205 --> 00:22:11.385
It means that there's a lot of geometry,

00:22:11.385 --> 00:22:15.868
there's a lot of beautiful geometry that
goes on with squares, and sums of squares,

00:22:15.868 --> 00:22:19.830
and right triangles, and
Euclidean distance, and things like that.

00:22:19.830 --> 00:22:22.972
And you lose that geometry if
you're using absolute value, and

00:22:22.972 --> 00:22:24.612
there are other reasons as well.

00:22:24.612 --> 00:22:27.460
But anyway this is the standard
definition of variance.

00:22:27.460 --> 00:22:34.384
So this is on average, how far is x from
its mean, except that we're squaring it.

00:22:34.384 --> 00:22:39.225
One annoying thing about squaring it
though, is that we changed the units.

00:22:39.225 --> 00:22:45.043
So if x is like a measurement that
let's say it's measured in miles.

00:22:45.043 --> 00:22:48.115
We are measuring some distance
in miles and we square it,

00:22:48.115 --> 00:22:49.977
we've got miles squared, okay?

00:22:49.977 --> 00:22:54.871
And so that's no longer in the same
units as what we started with.

00:22:54.871 --> 00:22:59.600
So because of that, something more
interpretable is the standard deviation,

00:23:02.081 --> 00:23:05.010
Which is a familiar term.

00:23:05.010 --> 00:23:08.240
Standard deviation is defined as just
the square root of the variance.

00:23:10.470 --> 00:23:14.010
So this seems, at first, like a kind
of convoluted thing to be doing.

00:23:14.010 --> 00:23:17.350
First we square everything then we
take the average then we square

00:23:17.350 --> 00:23:20.838
root it back again.

00:23:20.838 --> 00:23:27.990
The reason is that the variances
has really nice properties, but

00:23:27.990 --> 00:23:31.030
on the other hand we changed the units,
so we just change it back at the end.

00:23:31.030 --> 00:23:33.990
So that's the definition
of standard deviation.

00:23:33.990 --> 00:23:38.000
In general, variance is a lot nicer to
work with than standard deviation as far

00:23:38.000 --> 00:23:39.820
as doing the math.

00:23:39.820 --> 00:23:43.653
But then at the end of the day when you
want to have something interpretable.

00:23:43.653 --> 00:23:46.947
It's easier to think about what
the standard deviation means,

00:23:46.947 --> 00:23:49.270
because you're back on the original units.

00:23:49.270 --> 00:23:52.124
Okay, and let's just write one.

00:23:52.124 --> 00:23:57.090
One nice thing about this letter E
notation, this is a really good notation.

00:23:58.140 --> 00:23:59.310
E for expectation.

00:23:59.310 --> 00:24:03.080
Because I could just write
down this one thing and

00:24:03.080 --> 00:24:06.000
I didn't assume here that X is
continuous or discrete or anything.

00:24:06.000 --> 00:24:08.760
This is just a general definition and
I didn't need to write

00:24:08.760 --> 00:24:12.350
a separate definition for
the discrete or for the continuous case.

00:24:12.350 --> 00:24:13.870
So this is a unified definition.

00:24:15.300 --> 00:24:18.815
Let's just write the other.

00:24:18.815 --> 00:24:23.842
Another way to compute variance,
rather than doing this, so

00:24:23.842 --> 00:24:30.020
another way to write variance which
is more commonly used than this one.

00:24:30.020 --> 00:24:32.960
This one's the usual definition but the
other way to write it which I'm about to

00:24:32.960 --> 00:24:36.120
show you is usually easier for
computing it.

00:24:36.120 --> 00:24:38.470
Not always, sometimes this one's easier.

00:24:38.470 --> 00:24:40.906
Another way to express variance.

00:24:46.680 --> 00:24:49.480
So we want the variance of X.

00:24:49.480 --> 00:24:52.030
Let's just expand this thing out.

00:24:53.610 --> 00:24:55.080
I'm just gonna multiply it out, right.

00:24:55.080 --> 00:24:56.252
So that's X squared.

00:24:56.252 --> 00:25:02.221
-2 X(EX) I'm just squaring

00:25:02.221 --> 00:25:07.980
this thing + (EX) squared.

00:25:07.980 --> 00:25:14.910
And let's use linearity this
is E(X) squared, minus.

00:25:14.910 --> 00:25:20.070
Now for this middle term, the 2 is
a constant and constants can come out.

00:25:20.070 --> 00:25:22.100
The E(X) is also a constant, right?

00:25:22.100 --> 00:25:24.780
X is a random variable,
E(X) is just a number.

00:25:24.780 --> 00:25:28.270
The 2 E(X) is just
a number that comes out.

00:25:28.270 --> 00:25:33.390
So that's 2 E(X), and
then what's left inside is still an E(X).

00:25:33.390 --> 00:25:38.620
So we have another E(X) there, and
then plus, this thing is also a constant.

00:25:38.620 --> 00:25:42.460
So taking its expected value does nothing
because it's just a constant already.

00:25:42.460 --> 00:25:46.411
So that's + E(X) squared, and so

00:25:46.411 --> 00:25:53.580
this whole thing just becomes
E(X) squared- E(X) squared.

00:25:53.580 --> 00:25:57.940
And it sounds like what I just said was 0,
but the parentheses are different.

00:26:01.800 --> 00:26:03.920
Here we square it first
then take the average.

00:26:03.920 --> 00:26:06.310
Here we take the average then square it.

00:26:08.920 --> 00:26:12.430
We take that difference, okay?

00:26:12.430 --> 00:26:15.100
So that's usually easier.

00:26:15.100 --> 00:26:21.576
And so that answers the age old question,
if you had, this question came up for

00:26:21.576 --> 00:26:26.188
me I think in seventh grade
science class where I had to,

00:26:26.188 --> 00:26:31.020
do a bunch of experiments and
then I got a bunch of numbers.

00:26:31.020 --> 00:26:34.020
And for some reason I was squaring
the numbers and I wanted the average.

00:26:34.020 --> 00:26:36.890
I didn't know whether I should
square first and then average or

00:26:36.890 --> 00:26:38.420
average first and then square.

00:26:40.540 --> 00:26:44.030
And I think I computed both ways and
I got a slightly different answer.

00:26:45.700 --> 00:26:47.772
Which one is correct?

00:26:47.772 --> 00:26:50.463
Well, this one doesn't say
which one is correct, but

00:26:50.463 --> 00:26:53.938
this says that this one will always
be bigger than or equal to this one.

00:26:53.938 --> 00:27:00.980
And equality holds only in
the case when X is a constant.

00:27:02.120 --> 00:27:07.770
So if X is a constant, then the variance
is 0 cuz X just equals its mean obviously.

00:27:07.770 --> 00:27:12.290
If X is not a constant, than what's
gonna happen is that this thing,

00:27:12.290 --> 00:27:16.940
that you're averaging some
numbers that may be sometimes 0.

00:27:16.940 --> 00:27:21.190
But it's certainly sometimes positive,
and you can't average positive things and

00:27:21.190 --> 00:27:22.970
get a negative number.

00:27:22.970 --> 00:27:25.740
You can't average positive things and
get 0.

00:27:25.740 --> 00:27:27.220
So it would be strictly positive.

00:27:27.220 --> 00:27:29.620
Which means this is
strictly greater than this.

00:27:30.800 --> 00:27:32.120
Except in the case of a constant.

00:27:33.430 --> 00:27:36.490
So, okay, that's the variance.

00:27:36.490 --> 00:27:41.908
And as far as notation,
it's standard to write

00:27:41.908 --> 00:27:47.060
E(X) squared for E(X) squared this way.

00:27:48.870 --> 00:27:50.330
That's just standard notation.

00:27:50.330 --> 00:27:54.900
So, if you see E(X) squared, you should
always interpret that as squaring first,

00:27:54.900 --> 00:27:55.910
and then take the E.

00:27:55.910 --> 00:27:58.360
That's just a convention,
a pretty standard convention.

00:27:59.360 --> 00:28:03.110
This way is a little more clearer,
to avoid any possible ambiguity.

00:28:03.110 --> 00:28:06.000
But, it's very common to
see it written this way.

00:28:06.000 --> 00:28:08.560
So interpret it as squaring first.

00:28:09.890 --> 00:28:16.575
Okay so that's variance, and over here
we can continue our little dictionary,

00:28:16.575 --> 00:28:21.393
variance of X = E (X squared)-
E (X) squared the other

00:28:21.393 --> 00:28:26.390
way, And then the continuous case,
same thing again.

00:28:35.220 --> 00:28:40.300
And the one difficulty with this is,
we've been talking

00:28:40.300 --> 00:28:45.480
on how do we compute E(X), but
how do we actually compute E(X) squared,

00:28:45.480 --> 00:28:47.940
that's the question that
we need to address.

00:28:47.940 --> 00:28:49.990
How do you actually compute that thing?

00:28:49.990 --> 00:28:52.330
So we'll talk about that a little later.

00:28:52.330 --> 00:28:58.440
But first, we should see at least one
example of a continuous distribution.

00:28:59.990 --> 00:29:02.677
The simplest one to start
with is called the uniform.

00:29:06.270 --> 00:29:08.080
As far as what you'll
need before the midterm,

00:29:08.080 --> 00:29:12.120
there are only two continuous
distributions that you need to know

00:29:12.120 --> 00:29:15.650
by name before the midterm,
and then we'll do more later.

00:29:15.650 --> 00:29:18.020
One is the uniform,
the other is the normal.

00:29:18.020 --> 00:29:20.580
Uniform is the simplest
continuous distribution, so

00:29:20.580 --> 00:29:22.650
we'll start with that one right now.

00:29:22.650 --> 00:29:28.300
Normal distribution we'll talk about
mostly for next week, and normal

00:29:28.300 --> 00:29:33.310
distribution is the most famous important
distribution in all of statistics.

00:29:33.310 --> 00:29:34.570
And the reasons why it's so

00:29:34.570 --> 00:29:39.410
important will kind of gradually
emerge over the semester.

00:29:39.410 --> 00:29:40.850
Let's start with the uniform.

00:29:42.220 --> 00:29:49.220
So here's the uniform distribution
on some interval on (a,b).

00:29:49.220 --> 00:29:51.470
So we have some interval from a to b.

00:29:54.160 --> 00:29:56.987
I'll say here's a, here's b.

00:29:59.653 --> 00:30:03.970
We wanna pick a random
point in this interval.

00:30:03.970 --> 00:30:05.543
I'll put random in quotes.

00:30:09.320 --> 00:30:10.120
In this interval.

00:30:12.830 --> 00:30:17.830
How do we do that,
the question is what does random mean?

00:30:17.830 --> 00:30:22.250
If it's sort of intuitively
random is too vague because that

00:30:22.250 --> 00:30:24.870
just means we have some
random variable okay?

00:30:24.870 --> 00:30:27.200
What if we said completely random.

00:30:29.860 --> 00:30:32.890
Like what's the most
random that it could be?

00:30:32.890 --> 00:30:34.900
Again that's a little bit vague but

00:30:34.900 --> 00:30:38.950
let's just kinda explore that intuition a
little bit and then write down a formula.

00:30:38.950 --> 00:30:43.630
If it's completely random see I can
just see the probability of any two

00:30:43.630 --> 00:30:49.040
points is the same because all real
numbers between here and here.

00:30:49.040 --> 00:30:51.370
Every individual number is probably 0.

00:30:51.370 --> 00:30:54.250
So it's not so interesting to say
all the probabilities are the same.

00:30:55.730 --> 00:31:00.022
So pick some random point say,
there, x but

00:31:00.022 --> 00:31:05.476
the problem if I got that
exact value right there was 0.

00:31:05.476 --> 00:31:07.953
Okay so that means we still have
the same way it does mean for

00:31:07.953 --> 00:31:09.750
it to be completely random.

00:31:09.750 --> 00:31:14.510
So well the intuitions
now is suppose we broke

00:31:14.510 --> 00:31:18.940
this interval into two halves
where this is the midpoint say.

00:31:20.700 --> 00:31:24.010
Intuitively, if it's completely
random it should be that this half is

00:31:24.010 --> 00:31:26.650
equally likely as this half.

00:31:26.650 --> 00:31:31.630
Cuz If it were not then it seems like we
would kind of prefer to be, you know,

00:31:31.630 --> 00:31:35.000
the random variable prefers to be
more to the right than to the left.

00:31:35.000 --> 00:31:37.840
And somehow we want a concept
where it's not gonna,

00:31:37.840 --> 00:31:41.370
it doesn't care where it is, right?

00:31:41.370 --> 00:31:45.850
So in other words we could
say that probability, so for

00:31:45.850 --> 00:31:51.390
the uniform means that probability
is proportional to length.

00:31:53.870 --> 00:31:56.270
That's a reasonable definition.

00:31:56.270 --> 00:31:59.080
That is, if we take two
intervals of the same length,

00:31:59.080 --> 00:32:01.200
they should have the same probability.

00:32:01.200 --> 00:32:03.170
If one interval is twice as long,

00:32:03.170 --> 00:32:06.270
it seems reasonable that that
one should be twice as likely.

00:32:06.270 --> 00:32:09.950
So we're just gonna write down
a continuous distribution

00:32:09.950 --> 00:32:12.220
where probability is
proportional to length.

00:32:14.700 --> 00:32:19.750
And so to specify this, we can
either write down the pdf and drive,

00:32:19.750 --> 00:32:23.840
the cdf, or we can try to figure out what
the cdf should be and derive the pdf.

00:32:23.840 --> 00:32:27.110
Let's start with the pdf here,
because we're trying to practice pdfs.

00:32:28.110 --> 00:32:31.170
So here's the pdf, it's a constant.

00:32:32.830 --> 00:32:39.673
If x is between a and
b and it's 0 otherwise,

00:32:42.051 --> 00:32:45.840
Because I want probability to
be 0 outside of this interval.

00:32:45.840 --> 00:32:50.790
Inside that interval I want the density
to be constant, because if the density

00:32:50.790 --> 00:32:53.620
were higher at one point than another,
that doesn't seem very uniform.

00:32:55.313 --> 00:33:00.160
So well of course, we could ask, what's c?

00:33:00.160 --> 00:33:03.950
Well it has to be that
the integral of the pdf is 1.

00:33:03.950 --> 00:33:07.470
And I could start out by integrating
from minus infinity to infinity, but

00:33:07.470 --> 00:33:10.960
of course we only need to integrate from
a to b, cuz it's zero outside of there.

00:33:10.960 --> 00:33:16.736
If we integrate this we have to get 1,

00:33:16.736 --> 00:33:22.336
therefore c equals1 over b minus a.

00:33:22.336 --> 00:33:24.930
So it's just one over
the length of the interval.

00:33:26.140 --> 00:33:29.220
It has to be this way otherwise
this would not be a valid pdf.

00:33:30.530 --> 00:33:32.070
Now suppose we want the cdf.

00:33:36.450 --> 00:33:41.605
So to get the cdf we just have to

00:33:41.605 --> 00:33:49.458
integrate this thing
minus infinity up to x.

00:33:53.037 --> 00:33:53.940
So how do we do that?

00:33:53.940 --> 00:33:58.000
Again, we don't really have to go
all the way from minus infinity

00:33:58.000 --> 00:34:00.019
we can just start it at a.

00:34:00.019 --> 00:34:06.140
f of t dt,
then we have to consider some cases.

00:34:07.850 --> 00:34:12.892
Well, first of all this
is 0 if x is less than a.

00:34:16.359 --> 00:34:21.097
Well, this expression here that I wrote
down is kind of already assuming that x is

00:34:21.097 --> 00:34:23.000
greater than a.

00:34:23.000 --> 00:34:24.940
So assume x is greater than a.

00:34:24.940 --> 00:34:30.690
If x is less than a, then the probability
is 0 so the cdf has to be 0.

00:34:30.690 --> 00:34:35.440
And we also know that it's 1 if well,
let me just write this separately.

00:34:35.440 --> 00:34:37.750
So here's the cdf,
if x is less than a it's 0.

00:34:37.750 --> 00:34:44.210
If x is greater than b it's 1, because
we know for sure that x is less than b.

00:34:44.210 --> 00:34:47.511
Now, the interesting case is
what happens in the middle.

00:34:49.865 --> 00:34:54.852
To get the thing in the middle, all we
have to do is integrate a constant and

00:34:54.852 --> 00:34:59.850
this is the constant with the integral so
that I plug in f of t equals c here.

00:35:01.430 --> 00:35:03.640
That's gonna be c times x minus a.

00:35:03.640 --> 00:35:04.840
Right just integrate the constant.

00:35:04.840 --> 00:35:06.330
It's a very easy integral.

00:35:06.330 --> 00:35:12.600
So that's just gonna be x
minus a over b minus a.

00:35:12.600 --> 00:35:14.772
If x is between a and b.

00:35:17.943 --> 00:35:21.489
And notice this makes sense because if
we let x equals to a here it reduces

00:35:21.489 --> 00:35:22.090
down to 0.

00:35:22.090 --> 00:35:24.310
And if we let x equal
to b it reduces to 1.

00:35:24.310 --> 00:35:26.500
So this is a continuous function.

00:35:28.868 --> 00:35:33.580
So it's saying intuitively,
this is a linear function of x.

00:35:34.640 --> 00:35:38.000
They're saying that the probability is,
as you increase x,

00:35:38.000 --> 00:35:41.720
the probability is increasing linearly.

00:35:41.720 --> 00:35:49.210
Which make sense, cuz you're
accumulating more and more stuff.

00:35:49.210 --> 00:35:51.214
So let's get the expected value of x.

00:35:55.073 --> 00:35:58.010
Expected value of x, again,
it's just gonna be an easy integral.

00:35:58.010 --> 00:36:03.420
Because we just have to
integrate from a to b of x times

00:36:03.420 --> 00:36:09.130
the pdf.

00:36:09.130 --> 00:36:11.650
So I just wrote down x times the pdf.

00:36:11.650 --> 00:36:16.360
So integrating x is easy,
it's just gonna be x squared over 2.

00:36:16.360 --> 00:36:21.430
So this is x squared
over 2 times b minus a.

00:36:21.430 --> 00:36:28.010
And we evaluate this
as x goes from a to b.

00:36:28.010 --> 00:36:31.416
So that's really just b squared.

00:36:31.416 --> 00:36:34.597
Let's factor our the 1
over two 2 b minus a.

00:36:36.842 --> 00:36:39.070
And then it's b squared minus a squared.

00:36:39.070 --> 00:36:42.514
But b squared minus a squared
is b minus a, b plus a.

00:36:42.514 --> 00:36:47.826
So we can actually cancel the b minus
a and we just get a plus b over 2.

00:36:50.926 --> 00:36:53.007
Just doing that easy integral.

00:36:53.007 --> 00:36:54.480
Well, that's a very intuitive answer.

00:36:54.480 --> 00:36:55.260
That's just the mid point.

00:36:55.260 --> 00:36:58.800
It says the average is in middle which
it would really be weird if that didn't

00:36:58.800 --> 00:37:00.200
happen cuz this is supposed to be uniform.

00:37:02.150 --> 00:37:04.450
Okay, so that was just check that.

00:37:04.450 --> 00:37:08.360
Now, we have a bit of a quandary though.

00:37:08.360 --> 00:37:10.500
For how to deal with the variants.

00:37:11.680 --> 00:37:13.300
So let's try to get the variants.

00:37:15.530 --> 00:37:21.392
So If

00:37:21.392 --> 00:37:25.885
we want the variants then that
means we need e of x squared.

00:37:25.885 --> 00:37:29.420
Because we know this part
we don't know this part.

00:37:29.420 --> 00:37:30.794
How do we get rid of x squared?

00:37:30.794 --> 00:37:37.538
Well, E of x squared,

00:37:39.803 --> 00:37:42.721
Equals?

00:37:42.721 --> 00:37:45.950
So if we think carefully about
this how do we get E of X squared?

00:37:45.950 --> 00:37:49.080
Well, X squared is a random variable.

00:37:49.080 --> 00:37:50.530
Let's call that thing Y.

00:37:50.530 --> 00:37:52.310
So let's let Y equal X squared.

00:37:55.870 --> 00:37:58.990
If we take a function of a random
variable it's a random variable.

00:37:58.990 --> 00:38:00.300
So Y equals X squared.

00:38:01.960 --> 00:38:02.940
So that's E of Y.

00:38:05.010 --> 00:38:07.250
And how do we get E of Y?

00:38:07.250 --> 00:38:11.590
Well to get E of Y then
we need to know the pdf,

00:38:11.590 --> 00:38:13.183
assuming X is continuous right now.

00:38:13.183 --> 00:38:17.253
To get E of Y then we need
to know the pdf of Y and

00:38:17.253 --> 00:38:21.880
then we integrate Y times the pdf of Y,
it'd be Y.

00:38:21.880 --> 00:38:24.170
So the question is do
we need the pdf of Y?

00:38:25.420 --> 00:38:30.230
But that sounds kind of annoying
because we don't know the pdf of Y.

00:38:30.230 --> 00:38:34.320
Now we can get the pdf of Y, and later in
the course we will talk about how do we

00:38:34.320 --> 00:38:37.240
get the pdf of Y, but right now that's
seems like a pretty annoying problem.

00:38:38.680 --> 00:38:40.990
So let's kind of do this
more carelessly instead.

00:38:42.340 --> 00:38:47.120
Let's just say well it's too
much hustle to get the pdf of Y.

00:38:47.120 --> 00:38:51.220
So instead I'm just gonna say
I'm gonna reason by analogy.

00:38:51.220 --> 00:38:55.082
And I'm looking at this
formula right now for E of X.

00:38:55.082 --> 00:38:56.567
But I don't want E of X.

00:38:56.567 --> 00:38:57.800
I want E of X squared.

00:38:57.800 --> 00:38:59.789
So I'm just gonna change
that to an X squared.

00:39:01.412 --> 00:39:06.650
All right, I want X squared, not X, so
I'm just gonna put down X squared there.

00:39:07.850 --> 00:39:10.430
And then I'll go f of x dx.

00:39:12.820 --> 00:39:14.570
That's the pdf of X, that's what I know.

00:39:14.570 --> 00:39:18.510
And I'm too lazy to find the pdf of Y,
so I'll just change X to X squared.

00:39:20.720 --> 00:39:22.898
Well, that doesn't sound very legitimate.

00:39:25.322 --> 00:39:29.750
This, what I just did is called the Law
of the Unconscious Statistician.

00:39:38.714 --> 00:39:41.470
Which has a nice acronym
that's just LOTUS.

00:39:43.650 --> 00:39:46.450
It's called that because that just
seems like if you're kind of like

00:39:46.450 --> 00:39:49.440
half asleep and
you just want to find this thing and

00:39:49.440 --> 00:39:54.386
you just kind of replace X by X
squared because X squared and

00:39:54.386 --> 00:39:57.640
it seems like something you might do
if you're not thinking very hard.

00:39:59.250 --> 00:40:02.090
So to state it in general
in the continuous case,

00:40:02.090 --> 00:40:04.750
we want the expected value
of a function of that.

00:40:04.750 --> 00:40:07.040
X is a random variable who's PDF we know.

00:40:07.040 --> 00:40:08.855
We want the expected
value of a function of X.

00:40:11.580 --> 00:40:15.570
So, the Principled Approach would be,

00:40:15.570 --> 00:40:19.710
find the distribution of this and
then work with that.

00:40:19.710 --> 00:40:23.770
The Lazy Approach would be,
still use the distribution of X but

00:40:23.770 --> 00:40:26.238
that sounds kind of too good to be true.

00:40:26.238 --> 00:40:27.890
So the Lazy Approach here would be well,

00:40:27.890 --> 00:40:31.910
I'm gonna take g of X I am
gonna change big X to little x.

00:40:33.310 --> 00:40:37.990
And then I am still gonna need
insist on using the density of x and

00:40:37.990 --> 00:40:38.890
not convert anything.

00:40:40.540 --> 00:40:42.253
Well, this turns out to be true.

00:40:44.270 --> 00:40:45.537
So I'll put a box around it.

00:40:48.393 --> 00:40:52.860
We can talk sometime next week
about the proof, why this is true.

00:40:52.860 --> 00:40:54.840
But this turns out to be true.

00:40:54.840 --> 00:40:59.750
And thus, even though it sounds too
good to be true, it actually is true.

00:40:59.750 --> 00:41:00.970
So that's called LOTUS.

00:41:00.970 --> 00:41:03.360
This is the continuous version.

00:41:03.360 --> 00:41:05.750
In the discrete let me
write both versions.

00:41:05.750 --> 00:41:09.920
So a continuous LOTUS is
that thing I just wrote,

00:41:09.920 --> 00:41:13.370
we have LOTUS so
same equation you can copy that there.

00:41:13.370 --> 00:41:16.080
And let me just write the discrete case,

00:41:16.080 --> 00:41:20.659
again we want the expect value
of some function g of S,

00:41:20.659 --> 00:41:24.890
so all I'm gonna do is take this.

00:41:24.890 --> 00:41:28.070
This is the definition
of the expected value.

00:41:28.070 --> 00:41:30.450
All I'm gonna do is change X to g of x.

00:41:30.450 --> 00:41:33.580
So this is gonna be g of
x times the PMF of x.

00:41:33.580 --> 00:41:38.000
It says we don't need to convert and
get a distribution for g of x.

00:41:38.000 --> 00:41:39.320
We just do that.

00:41:39.320 --> 00:41:40.560
This is also valid.

00:41:40.560 --> 00:41:42.060
We'll talk more about why later.

00:41:42.060 --> 00:41:43.730
But it's useful to know that right now.

00:41:45.820 --> 00:41:49.410
So coming back to this
problem about the uniform,

00:41:49.410 --> 00:41:54.150
if we want the variance of the uniform so

00:41:54.150 --> 00:41:58.850
let's let, just for simplicity let's
let u be uniform between 0 and 1.

00:41:58.850 --> 00:42:00.820
And suppose we want the variance.

00:42:02.530 --> 00:42:10.100
So we know the expected value of u,
Is one-half, just the midpoint.

00:42:10.100 --> 00:42:12.272
And if we want E of u squared.

00:42:14.099 --> 00:42:20.220
According to LOTUS, we don't need
to first find the PDF of u squared.

00:42:20.220 --> 00:42:24.920
We can just directly write down
the integral 0 to 1 of u squared

00:42:26.530 --> 00:42:32.810
times the PDF times the PDF f
sub u of u du as the PDF, but

00:42:32.810 --> 00:42:36.860
this PDF is actually equal to a constant
and that constant is 1 in this case.

00:42:36.860 --> 00:42:40.600
So this is just equal to,
this part is just one.

00:42:40.600 --> 00:42:44.611
So it's the integral of u squared,

00:42:44.611 --> 00:42:48.680
the u, u cubed over 3, which is 1/3.

00:42:48.680 --> 00:42:54.630
So therefore the variance
of u equals e of u squared,

00:42:54.630 --> 00:42:56.210
minus e of u squared the other way.

00:42:59.250 --> 00:43:05.015
And that's one-third minus
one-quarter equals one twelfth.

00:43:09.729 --> 00:43:12.181
So the variants of a uniform
zero one is a one twelfth and

00:43:12.181 --> 00:43:15.378
that was a very easy calculation
because we were able to use lotus here,

00:43:15.378 --> 00:43:18.610
which we haven't proven yet but
we will talk more about that later.

00:43:18.610 --> 00:43:22.240
I'm showing you how to use it right now,
then we'll justify it more.

00:43:22.240 --> 00:43:24.350
So that thing that's too good
to be true actually works.

00:43:24.350 --> 00:43:25.980
So that's Lotus.

00:43:27.710 --> 00:43:31.150
One more thing about
the uniform distribution.

00:43:32.180 --> 00:43:36.770
It seems like the uniform is the simplest

00:43:36.770 --> 00:43:40.390
continuous distribution that
you could possibly imagine.

00:43:41.820 --> 00:43:44.030
Because the PDF it's just a constant.

00:43:45.520 --> 00:43:47.040
On some interval and

00:43:47.040 --> 00:43:51.450
one other point about this is we have
to have some bounded interval here.

00:43:51.450 --> 00:43:54.840
We cannot define a uniform
distribution on the entire real line.

00:43:54.840 --> 00:43:57.740
Sometimes that it's a bit
annoying if there isn't one.

00:43:57.740 --> 00:44:02.620
But if the whole real line there
will be no way to normalize it,

00:44:02.620 --> 00:44:05.280
there'd be no way to find a constant and
make it disintegrate to one.

00:44:07.720 --> 00:44:10.230
So it sounds like this is
an extremely simple distribution.

00:44:10.230 --> 00:44:14.200
And it is,
it's just constant PDF on some interval.

00:44:14.200 --> 00:44:15.480
Extremely easy.

00:44:15.480 --> 00:44:18.360
So start with the uniform zero one,
it seems very simple, but

00:44:18.360 --> 00:44:25.920
actually uniform zero one
has the property that if

00:44:27.390 --> 00:44:32.060
you give me one uniform random variable
and you're interested in some other

00:44:32.060 --> 00:44:38.100
distribution, there is a way to
convert it and simulate that.

00:44:38.100 --> 00:44:41.010
That is from the uniformed
zero one you can simulate or

00:44:41.010 --> 00:44:45.760
generate from any distribution
no matter how complicated it is.

00:44:45.760 --> 00:44:47.060
At least in principle.

00:44:47.060 --> 00:44:51.630
As a matter of computation that may be
easy or hard, but in principle from

00:44:51.630 --> 00:44:57.600
the uniform you can get anything, so
I call that universality of the uniform.

00:45:02.330 --> 00:45:07.130
Universality of the uniform means
that given a uniform you can

00:45:07.130 --> 00:45:09.190
create any distribution that you want.

00:45:11.250 --> 00:45:15.740
So that's kind of theoretically nice
in that it kind of unifies concepts and

00:45:15.740 --> 00:45:19.330
says this things that's seems very,
very simple to just one uniform.

00:45:19.330 --> 00:45:21.920
You can actually use it to generate
something that's as complicated

00:45:21.920 --> 00:45:22.450
as you want.

00:45:22.450 --> 00:45:28.610
That's kind of cool but it's also useful
in practice where most computers programs

00:45:28.610 --> 00:45:33.040
can generate random numbers between zero
and one, it's actually pseudo random.

00:45:33.040 --> 00:45:37.420
But they not know how to generate
whatever complicated distribution you're

00:45:37.420 --> 00:45:38.090
interested in.

00:45:38.090 --> 00:45:41.430
And this, in many cases gives you away to

00:45:41.430 --> 00:45:45.780
convert from the random uniforms
to whatever you want to simulate.

00:45:46.820 --> 00:45:48.550
So I want to show why that's true.

00:45:50.240 --> 00:45:54.000
So the statement is that,
we're gonna start with the uniform

00:45:56.650 --> 00:46:01.640
between 0 and 1 and

00:46:01.640 --> 00:46:05.220
let F be a CDF, that we're interested in.

00:46:05.220 --> 00:46:08.960
So usually we've been talking about here's
the random variable and then find in CDF.

00:46:08.960 --> 00:46:12.310
Here we're going the other way
in the sense that we assume

00:46:12.310 --> 00:46:14.740
that we have some CDF
that's of interest to us.

00:46:14.740 --> 00:46:19.210
But we do not yet have access to
a random variable that has that CDF.

00:46:21.080 --> 00:46:27.570
So let F be a CDF and
it's possible to generalize this further.

00:46:27.570 --> 00:46:34.770
But to make this something that we can
do fairly quickly let's assume that F is

00:46:35.940 --> 00:46:40.760
strictly increasing, so
we don't have to deal with flat regions.

00:46:42.480 --> 00:46:49.370
And let's also assume that F
is continuous as a function.

00:46:51.100 --> 00:46:53.580
Just so that we don't have to
think about jumps right now,

00:46:53.580 --> 00:46:55.730
although you can generalize this.

00:46:57.460 --> 00:47:02.170
Now then the theorem says that if we let

00:47:03.890 --> 00:47:07.650
X define X to be F inverse of u.

00:47:09.180 --> 00:47:13.570
So the inverse function exists in this
case because I took something that was

00:47:13.570 --> 00:47:16.400
continuously and strictly increasing,
it will have an inverse.

00:47:16.400 --> 00:47:19.510
So we take the inverse and we plug in u.

00:47:20.510 --> 00:47:27.226
Then the statement is that X
is distributed according to F.

00:47:29.640 --> 00:47:33.260
That is the CDF of X is F.

00:47:33.260 --> 00:47:37.230
So what this says is we have
this CDF we're interested in.

00:47:37.230 --> 00:47:42.160
We take the inverse CDF, plug in
the uniform, and then we've constructed

00:47:42.160 --> 00:47:46.630
a random draw from that distribution
we're interested in, capital F.

00:47:46.630 --> 00:47:48.353
So let's prove this very quickly.

00:47:50.735 --> 00:47:54.160
And the proof doesn't require
anything fancy at all.

00:47:54.160 --> 00:47:58.800
It doesn't require anything, except for
understanding what a CDF is.

00:47:58.800 --> 00:48:01.740
So another reason I like to talk about
this is it's just good practice with

00:48:01.740 --> 00:48:03.670
really understanding what a CDF is.

00:48:04.980 --> 00:48:10.030
Cuz the better you understand CDFs, then
the easier it is to see why this is true.

00:48:10.030 --> 00:48:13.210
So to prove this, all we need to
do is to compute the CDF of X.

00:48:14.770 --> 00:48:20.800
This notation means that X has the CDF F,
that is, X follows this distribution.

00:48:20.800 --> 00:48:26.010
So all we have to do is compute the CDF
of X, but that's actually pretty easy.

00:48:26.010 --> 00:48:31.561
Because by definition, X is F inverse
of u, I'm just plugging in what X is.

00:48:35.384 --> 00:48:39.920
Now let's apply capital F to both side.

00:48:39.920 --> 00:48:42.580
So I am just putting F here and F here.

00:48:42.580 --> 00:48:46.724
And that's an equivalent because I made
these nice assumptions about F that's

00:48:46.724 --> 00:48:50.930
an equivalent to n,
u is less than and equal to F of x.

00:48:53.100 --> 00:48:55.888
You know if we didn't have
an increasing function then if

00:48:55.888 --> 00:48:59.679
I apply both sides by minus one then
the inequality flips, things like that.

00:48:59.679 --> 00:49:03.330
But since we have an increasing
function then It's preserved.

00:49:03.330 --> 00:49:04.530
And since its invertible,

00:49:04.530 --> 00:49:07.240
this is really the same event
just written in a different way.

00:49:07.240 --> 00:49:10.540
Now we are done with that, because what
the probability that u is less than or

00:49:10.540 --> 00:49:11.350
equal to F of x.

00:49:11.350 --> 00:49:12.870
I'll just draw a simple little picture.

00:49:14.440 --> 00:49:19.560
U is uniform from 0 to 1, and F of x,
remember that's a probability,

00:49:19.560 --> 00:49:24.670
so that's just some number between 0 and
1, let's say it's there F of x.

00:49:24.670 --> 00:49:29.090
Now I said that probability is
proportional to length for a uniform and

00:49:29.090 --> 00:49:32.730
in this case that proportionality
constant is just 1 because the length

00:49:32.730 --> 00:49:34.290
of the whole interval is 1.

00:49:34.290 --> 00:49:39.940
So for uniforms 0 and 1, the probability
of an interval is its length.

00:49:39.940 --> 00:49:42.670
So we want to know, what's the probability
that u is between here and here.

00:49:42.670 --> 00:49:46.812
That's just the length of
the interval that's F of X.

00:49:46.812 --> 00:49:47.370
And that's the end.

00:49:49.640 --> 00:49:50.450
That's the end of the lecture.

00:49:51.490 --> 00:49:52.890
So have a good weekend.

00:49:55.500 --> 00:49:56.000
Thanks.

