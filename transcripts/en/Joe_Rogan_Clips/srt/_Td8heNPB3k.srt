1
00:00:00,990 --> 00:00:02,490
The Joe Rogan experience.

2
00:00:03,540 --> 00:00:07,050
That's an interesting thing for someone
who studies artificial intelligence.

3
00:00:07,080 --> 00:00:10,140
I mean if anybody listen to this podcast,
like what the fuck did I do?

4
00:00:10,470 --> 00:00:14,910
So many reservoir dogs, they talk
about movies. So many people.

5
00:00:14,911 --> 00:00:19,620
And you're talking about autonomous
vehicles. We have plenty of time, sir.

6
00:00:19,621 --> 00:00:22,560
We have plenty of time. But that's the
beautiful thing about this podcast.

7
00:00:22,590 --> 00:00:25,920
We're just talking. So tell me what
you got here with your notes man.

8
00:00:26,150 --> 00:00:30,660
I mean you are fucking prepared. I
mean you have a lot of shit here. Many,

9
00:00:30,661 --> 00:00:34,470
many pages for sure. I don't want to
miss out on this stuff. I mean there's a,

10
00:00:34,740 --> 00:00:38,730
there's been a lot of exciting stuff on
the autonomous vehicle space since you

11
00:00:38,731 --> 00:00:39,330
came on.

12
00:00:39,330 --> 00:00:43,350
I got a Tesla and I've experienced with
that thing is like when I put it on

13
00:00:43,351 --> 00:00:46,080
autopilot and it's stunning. Yeah, crazy.

14
00:00:46,400 --> 00:00:49,860
I mean this is the performance
of the v amazing well in,

15
00:00:49,861 --> 00:00:54,840
in terms of its ability to change lanes
and its ability to drive without you

16
00:00:54,841 --> 00:00:55,620
doing anything.

17
00:00:55,620 --> 00:00:58,680
I just put my hand on the wheel and
hold it there and it does all the work.

18
00:00:59,130 --> 00:01:02,520
So because like one or two
people listen to this podcast,

19
00:01:02,760 --> 00:01:06,810
I want to take this opportunity and
tell people, if you drive a Tesla,

20
00:01:07,140 --> 00:01:10,410
whether you listen to this now or a
year from now, two years from now,

21
00:01:10,770 --> 00:01:14,760
Tesla or any other car,
keep your damn eyes on the road.

22
00:01:15,330 --> 00:01:18,390
So whatever you think
the system is able to do,

23
00:01:18,930 --> 00:01:23,930
you will have to still monitor the road
and you still have to take over when it

24
00:01:24,001 --> 00:01:28,110
fails,
if when really.

25
00:01:28,920 --> 00:01:32,880
So
we're throwing,

26
00:01:33,360 --> 00:01:36,000
this is like the moment we're
throwing down right now.

27
00:01:36,030 --> 00:01:39,810
I think it's an your level of
expertise obviously. I mean,

28
00:01:39,811 --> 00:01:43,620
I'm not throwing down with you on that.
No, I think it's really important to,

29
00:01:43,950 --> 00:01:47,610
in this transitionary phase,
whatever the car company, uh,

30
00:01:47,611 --> 00:01:52,170
whatever the system that we
don't overtrust a system,
we don't become complacent.

31
00:01:52,170 --> 00:01:55,230
We don't think he could do
more than they can. Currently.

32
00:01:55,440 --> 00:01:59,070
40,000 people die in the United
States from, from fatal crashes.

33
00:01:59,340 --> 00:02:03,690
The number one reason for that is
distraction. So texting smart phones,

34
00:02:03,720 --> 00:02:08,230
how much has it gone up since smart
phones, people don't, exactly,

35
00:02:08,250 --> 00:02:09,480
they're trying to understand that.

36
00:02:10,050 --> 00:02:13,470
There's a lot of studies showing
that it's significant increases,

37
00:02:13,471 --> 00:02:16,860
but it's hard to say it's because of
smartphones, but it's almost obvious.

38
00:02:17,110 --> 00:02:18,650
It's pretty obvious.
The,

39
00:02:18,680 --> 00:02:22,920
the flip side is even though
everybody's not using a smart phone,

40
00:02:22,921 --> 00:02:26,520
texting and so on, they've become
better at using the smartphone.

41
00:02:26,940 --> 00:02:31,530
So they're better at texting and
driving the better balancing that.

42
00:02:31,710 --> 00:02:35,880
Now this is a horrible thing to do.
So if you're listening to this podcast,

43
00:02:36,240 --> 00:02:36,990
you should,
uh,

44
00:02:36,990 --> 00:02:40,920
listen to it in your car and keep
your eyes on the road and not text.

45
00:02:40,980 --> 00:02:45,980
I think worst was Pokemon
when Pokemon was in its prime.

46
00:02:46,440 --> 00:02:50,280
I was watching a guy on the highway
playing Pokemon as he was driving.

47
00:02:50,780 --> 00:02:52,680
No more than one person.
Two people, a guy.

48
00:02:52,681 --> 00:02:57,000
And I saw a girl do it once to holding
the phone on the steering wheel.

49
00:02:57,030 --> 00:03:01,150
Playing Pokemon. Yeah. Yeah. It's
incredible. What are you doing Jamie?

50
00:03:02,910 --> 00:03:04,750
That's GRANDPA's. Oh Shit. Sorry.

51
00:03:07,600 --> 00:03:11,440
I'm confused. What does this,
uh, this grandpa in Japan,
he drives around on a bike.

52
00:03:11,560 --> 00:03:15,300
Oh, my phones playing
Pokemon all at the same time.

53
00:03:15,580 --> 00:03:20,140
This guy is 15 phones. It's ridiculous.
This guy needs to find hookers.

54
00:03:20,141 --> 00:03:23,380
There's people that do this also in
their car with maybe four or five doing

55
00:03:23,381 --> 00:03:27,190
exactly what you're saying. This man needs
a better hobby. This is preposterous.

56
00:03:29,530 --> 00:03:31,420
He can't see what the fuck's
going on in front of him.

57
00:03:32,050 --> 00:03:37,050
He spends about $300 a month to
buy virtual currencies in the game.

58
00:03:38,230 --> 00:03:42,340
Wow. That guy's board or
in an innovative genius,

59
00:03:42,640 --> 00:03:44,470
depending on the perspective.
One eye,

60
00:03:45,250 --> 00:03:48,790
people misuse their
innovative Josie innovative.

61
00:03:48,791 --> 00:03:51,430
He's just playing a stupid game while
he's driving around on his bike like an

62
00:03:51,431 --> 00:03:56,380
asshole. Well, he's doing in fact
instead set of a woman thing.

63
00:03:56,800 --> 00:04:00,360
It's passion. It's the most amazing
moment of his life playing Pokemon.

64
00:04:00,640 --> 00:04:02,110
I'm sure most people are on my side.

65
00:04:02,111 --> 00:04:06,220
Sensible woman versus do you think
most people are on your side?

66
00:04:06,221 --> 00:04:08,410
They think Sonneville woman's the
greatest movie, all that to a woman,

67
00:04:08,411 --> 00:04:10,600
but I was defending
godfather sent to a woman.

68
00:04:10,720 --> 00:04:12,520
You weren't defending
godfather against me. I mean,

69
00:04:12,540 --> 00:04:14,330
I'm going to throw you under the band.
Okay.

70
00:04:15,910 --> 00:04:19,720
I'm going to manipulate this conversation.
Jamie, can you edit this in post?

71
00:04:19,900 --> 00:04:24,900
Did you see the video that just came
out yesterday of a Tesla on autopilot?

72
00:04:25,001 --> 00:04:29,140
Avoiding a crash. All right, so yeah,
I have and there's a lot of exams.

73
00:04:29,150 --> 00:04:31,330
Quite a few of those. Yeah, of course.

74
00:04:31,331 --> 00:04:34,540
It's like hard to prove exactly what
happened and where the auto Paul was

75
00:04:34,541 --> 00:04:36,220
involved.
Just like on the flip side,

76
00:04:36,221 --> 00:04:39,370
it's hard to prove that autopilot
was involved in the dangerous stuff.

77
00:04:39,520 --> 00:04:41,950
But I think by any measure,

78
00:04:42,100 --> 00:04:46,480
the media is really negative in terms
of their reporting on tests that there,

79
00:04:46,930 --> 00:04:47,763
I think,

80
00:04:48,580 --> 00:04:52,360
I think you've talked to this about
before in general and negativity gets more

81
00:04:52,361 --> 00:04:53,540
clicks,
right?

82
00:04:53,920 --> 00:04:58,510
And I think Tesla negative stuff
on Tesla gets a lot of clicks,

83
00:04:59,050 --> 00:05:01,450
so,
well not Tesla.

84
00:05:01,650 --> 00:05:05,440
Let me speak more broadly about autonomous
vehicles. If there's any fatality,

85
00:05:05,470 --> 00:05:09,040
any crash, it's overrepresented.
It's over reported on.

86
00:05:09,420 --> 00:05:14,420
So I need to meet people
who are interested in AI
helping save lives in these

87
00:05:15,521 --> 00:05:16,690
systems like autopilot.

88
00:05:17,420 --> 00:05:22,420
I feel you carry the responsibility of
being at least as good at as a driver.

89
00:05:23,021 --> 00:05:26,050
You are. I want it under manual
control. So don't text and drive.

90
00:05:26,200 --> 00:05:27,280
Keep your eyes on the road.

91
00:05:27,610 --> 00:05:32,080
If I say anything over and over on this
podcast is that drunk driving, of course,

92
00:05:32,081 --> 00:05:34,600
is the other one,
and so don't drink and drive,

93
00:05:34,601 --> 00:05:37,030
but the number one thing
is distracted driving.

