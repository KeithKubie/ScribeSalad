WEBVTT
Kind: captions
Language: en

00:00:03.300 --> 00:00:06.250
JUSTIN: I'm Justin, tech
lead for the WebRTC project

00:00:06.250 --> 00:00:07.890
at Google.

00:00:07.890 --> 00:00:10.700
And today, we're going
to talk about using audio

00:00:10.700 --> 00:00:11.690
in the web platform.

00:00:11.690 --> 00:00:16.900
The web platform has come a long
way on both mobile and desktop.

00:00:16.900 --> 00:00:20.870
And using technologies like the
Media Capture API, Web Audio,

00:00:20.870 --> 00:00:26.010
and WebRTC, it's now super easy
to record, process, and send

00:00:26.010 --> 00:00:27.750
audio and video in your app.

00:00:27.750 --> 00:00:30.080
To demonstrate this,
we're going to try

00:00:30.080 --> 00:00:32.200
something we've
never done before.

00:00:32.200 --> 00:00:34.940
We're going to use this
session to record a theme

00:00:34.940 --> 00:00:39.010
song for Google I/O. And
you're going to help.

00:00:39.010 --> 00:00:41.120
So I'm pretty jazzed about this.

00:00:41.120 --> 00:00:44.156
I played in some bands back
in the day, a little keyboard,

00:00:44.156 --> 00:00:45.480
a bit of bass.

00:00:45.480 --> 00:00:50.260
And I remember what it was
like to make music back then.

00:00:50.260 --> 00:00:53.240
To get that perfect
sound, we had

00:00:53.240 --> 00:00:56.510
to tote around a whole bunch
of gear, all sorts of effects

00:00:56.510 --> 00:01:02.210
pedals-- overdrive, chorus,
flanger, wah-wah-- amps and EQs

00:01:02.210 --> 00:01:06.240
to get the right tone, and a
four track to record it all.

00:01:06.240 --> 00:01:08.540
And that was a big
investment for us.

00:01:08.540 --> 00:01:12.160
But that's what it took to
sound like real rock stars.

00:01:12.160 --> 00:01:15.250
So we'd all have been
blown away to know

00:01:15.250 --> 00:01:17.841
that this whole basement
of audio processing gear

00:01:17.841 --> 00:01:19.965
would soon be able to be
replaced by a web browser.

00:01:23.130 --> 00:01:24.900
In the modern web
platform, we now

00:01:24.900 --> 00:01:26.710
have the power to
do incredible things

00:01:26.710 --> 00:01:29.040
with media on any device.

00:01:29.040 --> 00:01:32.340
And one great example of
this is a new third party

00:01:32.340 --> 00:01:35.090
app called Soundtrap.

00:01:35.090 --> 00:01:39.000
Built on Web Audio,
WebRTC, and Dart,

00:01:39.000 --> 00:01:41.620
this app is like a set of
instruments, a recording

00:01:41.620 --> 00:01:45.190
studio, and a musical
collaboration tool

00:01:45.190 --> 00:01:46.525
all rolled into one.

00:01:46.525 --> 00:01:49.810
And we're going to use
it to record our song.

00:01:49.810 --> 00:01:54.550
So musical inspiration can
strike you at any time.

00:01:54.550 --> 00:01:58.990
So imagine I'm just sitting
on the train with my Nexus 7,

00:01:58.990 --> 00:02:02.040
and I get the idea
for a great song.

00:02:02.040 --> 00:02:04.936
So let me show you
how this works.

00:02:04.936 --> 00:02:07.290
I'll plug in the Nexus 7.

00:02:07.290 --> 00:02:08.520
Let's make this real.

00:02:08.520 --> 00:02:12.460
So I'm running the Soundtrap
app in Chrome for Android.

00:02:12.460 --> 00:02:16.620
And the first thing we need
is a driving percussion track.

00:02:16.620 --> 00:02:19.120
So let me go ahead and check
out the drum loops we have here

00:02:19.120 --> 00:02:23.460
and figure out what's the
right thing for our song.

00:02:23.460 --> 00:02:27.380
[BEAT PLAYING]

00:02:27.380 --> 00:02:30.943
Mm, let's see what else.

00:02:30.943 --> 00:02:34.310
[BEAT PLAYING]

00:02:34.310 --> 00:02:37.070
I think I want something
that has a bit more rock.

00:02:37.070 --> 00:02:38.680
[BEAT PLAYING]

00:02:38.680 --> 00:02:40.840
Yeah, OK, that's the one.

00:02:40.840 --> 00:02:47.730
So let me just tap that and
add that to our song-- perfect.

00:02:47.730 --> 00:02:50.910
OK, so we've got our
percussion track.

00:02:50.910 --> 00:02:53.826
But now, to complete
our rhythm section,

00:02:53.826 --> 00:02:55.200
we need to get a
bass line going.

00:03:02.730 --> 00:03:05.172
So fortunately, I've
just arrived home,

00:03:05.172 --> 00:03:06.130
where I've got my bass.

00:03:08.760 --> 00:03:12.420
And now, using the Media
Capture API, also known

00:03:12.420 --> 00:03:15.450
as getUserMedia, I can
record my instrument right

00:03:15.450 --> 00:03:18.274
inside my laptop.

00:03:18.274 --> 00:03:19.690
So let me show you
how this works.

00:03:24.980 --> 00:03:29.370
I'm going to plug in here
just using a standard cable

00:03:29.370 --> 00:03:34.240
right into the microphone
jack on my laptop--

00:03:34.240 --> 00:03:35.755
no special hardware or cables.

00:03:37.996 --> 00:03:40.245
And there's my drum track I
already added from before.

00:03:47.350 --> 00:03:49.700
All right, I got
a sweet bass amp.

00:03:49.700 --> 00:03:51.290
[BASS PLAYING]

00:03:51.290 --> 00:03:55.255
Let me just make sure
I'm in tune here.

00:03:55.255 --> 00:03:59.390
[BASS TUNING]

00:03:59.390 --> 00:04:06.760
All right, perfect.

00:04:06.760 --> 00:04:10.737
All right, let me just play a
couple notes to get started.

00:04:10.737 --> 00:04:12.320
This one might sound
kind of familiar,

00:04:12.320 --> 00:04:13.840
although our
attorneys have told us

00:04:13.840 --> 00:04:16.209
that it can't
sound too familiar.

00:04:16.209 --> 00:04:20.700
[BASS PLAYING]

00:04:26.750 --> 00:04:29.210
All right, how does that sound?

00:04:29.210 --> 00:04:30.050
All right.

00:04:30.050 --> 00:04:33.110
[APPLAUSE]

00:04:33.110 --> 00:04:34.760
This is sounding great.

00:04:34.760 --> 00:04:36.530
And this is simply
incredible to have

00:04:36.530 --> 00:04:39.340
this kind of power
in a web application.

00:04:39.340 --> 00:04:41.845
So let's go ahead and record
a bass line for our song.

00:04:41.845 --> 00:04:45.710
So right here in Soundtrap, I'm
just going to start recording.

00:04:45.710 --> 00:04:47.909
And I'm going to
add this bass line

00:04:47.909 --> 00:04:49.950
right on top of the drum
part that we had before.

00:04:57.435 --> 00:05:01.926
[BASS PLAYING OVER DRUMS]

00:05:13.887 --> 00:05:15.720
All right, I was a
little bit early on that.

00:05:15.720 --> 00:05:17.095
So let me try that
one more time.

00:05:20.025 --> 00:05:24.480
[BASS PLAYING OVER DRUMS]

00:05:35.380 --> 00:05:38.470
All right, so there we've
got our great bass line.

00:05:38.470 --> 00:05:41.206
Let's save that out.

00:05:41.206 --> 00:05:43.610
And that's what we've
got for our bass track.

00:05:43.610 --> 00:05:47.286
So onto our next
part-- let's talk

00:05:47.286 --> 00:05:49.160
about the technology
behind what we just did.

00:05:57.740 --> 00:06:01.060
So in the Media Capture
API, the key method

00:06:01.060 --> 00:06:03.900
is called getUserMedia.

00:06:03.900 --> 00:06:07.170
And this call opens up
the microphone-- oops.

00:06:10.210 --> 00:06:12.500
This call opens up the
microphone, asking the user

00:06:12.500 --> 00:06:15.320
for permission the first time,
and gives us a Media Stream

00:06:15.320 --> 00:06:19.050
object that represents the
audio coming from my bass.

00:06:19.050 --> 00:06:21.340
Now, the same
getUserMedia API can also

00:06:21.340 --> 00:06:24.130
be used to get access to
the microphone for speech

00:06:24.130 --> 00:06:27.320
or a webcam for video.

00:06:27.320 --> 00:06:30.190
Now normally, when we call
getUserMedia to get access

00:06:30.190 --> 00:06:31.825
to the mic, the
mic signal is going

00:06:31.825 --> 00:06:34.460
to get routed through a
bunch of processing stages

00:06:34.460 --> 00:06:37.050
to make sure we get
a good speech signal.

00:06:37.050 --> 00:06:39.260
Now, we're also going
to apply auto gain

00:06:39.260 --> 00:06:41.960
control to make sure
the levels are correct,

00:06:41.960 --> 00:06:43.760
as well as acoustic
echo cancellation

00:06:43.760 --> 00:06:46.400
to make sure any of the sound
coming out from the speakers

00:06:46.400 --> 00:06:48.800
doesn't also get
picked up by the mic.

00:06:48.800 --> 00:06:50.960
However, when we're
recording an instrument,

00:06:50.960 --> 00:06:52.460
we don't want any
of that processing

00:06:52.460 --> 00:06:56.270
to occur so we get as pure
of a tone as possible.

00:06:56.270 --> 00:06:59.910
So when we call getUserMedia,
we're going to turn that off.

00:06:59.910 --> 00:07:03.060
So here's a typical
call to getUserMedia.

00:07:03.060 --> 00:07:05.010
We make it on the
Navigator object.

00:07:05.010 --> 00:07:07.600
And we ask, in this
case, for a media stream

00:07:07.600 --> 00:07:10.300
that contains
audio from the mic.

00:07:10.300 --> 00:07:12.400
We'll get our stream
back asynchronously.

00:07:12.400 --> 00:07:15.190
And then, we can actually
do something with it.

00:07:15.190 --> 00:07:17.320
If the syntax looks
kind of unfamiliar here,

00:07:17.320 --> 00:07:20.610
this is making use of
Dart's Future concept.

00:07:20.610 --> 00:07:23.540
The .then at the end of the
statement allows us to say

00:07:23.540 --> 00:07:29.210
easily what should get executed
when we get our stream back.

00:07:29.210 --> 00:07:30.902
So when we call
getUserMedia, we're

00:07:30.902 --> 00:07:32.360
now going to specify
the parameters

00:07:32.360 --> 00:07:35.110
we want to the audio stream.

00:07:35.110 --> 00:07:37.140
And here, we're going
to ask for audio

00:07:37.140 --> 00:07:40.520
and specify we want the
AEC turned off-- simple.

00:07:40.520 --> 00:07:42.770
So this way, it's what we're
doing inside of Soundtrap

00:07:42.770 --> 00:07:46.160
to get access to the microphone
to record bass, guitar,

00:07:46.160 --> 00:07:47.590
or any other instrument.

00:07:47.590 --> 00:07:52.282
And now, let's turn
it up a little bit.

00:07:52.282 --> 00:07:54.990
Because Media Capture
is really cool.

00:07:54.990 --> 00:07:56.860
But it totally
comes to life when

00:07:56.860 --> 00:07:59.210
we connect it with
a Web Audio API.

00:07:59.210 --> 00:08:02.415
And that's where we can do
some amazing audio processing.

00:08:02.415 --> 00:08:06.830
So to demonstrate this, let
me welcome Per on stage.

00:08:06.830 --> 00:08:10.142
Per is one of the
co-founders of Soundtrap.

00:08:10.142 --> 00:08:14.875
[APPLAUSE]

00:08:14.875 --> 00:08:15.375
Per.

00:08:15.375 --> 00:08:16.999
Is one of the
co-founders of Soundtrap,

00:08:16.999 --> 00:08:19.234
and also a bit of a guitar hero.

00:08:19.234 --> 00:08:19.900
PER: Hi, Justin.

00:08:19.900 --> 00:08:21.270
JUSTIN: Great to have
you here on stage, Per.

00:08:21.270 --> 00:08:23.060
PER: Thank you very
much for having us.

00:08:23.060 --> 00:08:24.650
JUSTIN: So do you think you
could play a couple guitar

00:08:24.650 --> 00:08:25.380
riffs for us?

00:08:25.380 --> 00:08:26.660
PER: Maybe I can do that.

00:08:26.660 --> 00:08:30.675
I have a guitar [INAUDIBLE],
so let me mic up.

00:08:30.675 --> 00:08:32.799
JUSTIN: So Per is going to
play some guitar for us.

00:08:32.799 --> 00:08:35.257
And we're going to use that to
demonstrate the effects that

00:08:35.257 --> 00:08:36.890
are possible using Web Audio.

00:08:42.280 --> 00:08:45.050
PER: So we're using
Web Audio to build up

00:08:45.050 --> 00:08:46.440
a whole set of effects.

00:08:46.440 --> 00:08:48.780
And I'll show you
some of the presets

00:08:48.780 --> 00:08:53.320
that we have if I get
some volume, yeah?

00:08:53.320 --> 00:08:56.250
So this is just an acoustic
sound with no effects

00:08:56.250 --> 00:08:57.160
on at all.

00:08:57.160 --> 00:09:00.769
[GUITAR PLAYING]

00:09:03.400 --> 00:09:06.640
Like-- and then we
can do something else.

00:09:06.640 --> 00:09:10.274
JUSTIN: All right, let's
go a little harder.

00:09:10.274 --> 00:09:14.250
[DISTORTED GUITAR PLAYING]

00:09:20.220 --> 00:09:21.015
We call that one--

00:09:21.015 --> 00:09:25.850
[APPLAUSE]

00:09:25.850 --> 00:09:29.960
We call that one
"Fumes on the Ocean."

00:09:29.960 --> 00:09:31.650
So let's kick it into overdrive.

00:09:31.650 --> 00:09:35.626
[OVERDRIVE GUITAR PLAYING]

00:09:43.385 --> 00:09:44.847
We call that one
"Insane Bus Ride."

00:09:44.847 --> 00:09:45.430
Is that right?

00:09:45.430 --> 00:09:46.721
PER: Yeah, something like that.

00:09:46.721 --> 00:09:48.740
JUSTIN: OK, all right,
now let's take it back

00:09:48.740 --> 00:09:50.676
to the origins of rock and roll.

00:09:50.676 --> 00:10:11.540
[SLAP DELAYED GUITAR PLAYING]

00:10:11.540 --> 00:10:14.660
OK, ladies and gentlemen, Per.

00:10:14.660 --> 00:10:18.424
[APPLAUSE]

00:10:18.424 --> 00:10:20.090
So to have this kind
of processing power

00:10:20.090 --> 00:10:22.810
on the web-- simply fantastic.

00:10:22.810 --> 00:10:24.810
Let's talk about the magic
behind these effects.

00:10:24.810 --> 00:10:27.570
PER: Yeah, so let's talk about
this simple one, actually.

00:10:27.570 --> 00:10:30.845
So this is called
a slap back effect.

00:10:30.845 --> 00:10:32.060
[SLAP DELAYED GUITAR PLAYING]

00:10:32.060 --> 00:10:33.072
Exactly, that's right.

00:10:33.072 --> 00:10:34.530
JUSTIN: So most of
you are probably

00:10:34.530 --> 00:10:39.090
familiar with the HTML5
audio and video elements that

00:10:39.090 --> 00:10:42.500
load, decode, and play
out audio and video.

00:10:42.500 --> 00:10:44.820
But Web Audio goes
beyond that and gives you

00:10:44.820 --> 00:10:47.120
super low delay
and precise control

00:10:47.120 --> 00:10:49.450
over each one of
these steps, including

00:10:49.450 --> 00:10:52.195
scheduling sounds down to
sampling level accuracy.

00:10:52.195 --> 00:10:55.520
And this time is particularly
important for games, as well as

00:10:55.520 --> 00:10:58.610
pro audio apps like Soundtrap.

00:10:58.610 --> 00:11:02.790
Web Audio also allows
powerful synthesis,

00:11:02.790 --> 00:11:07.140
processing, and routing tools.

00:11:07.140 --> 00:11:09.700
So this lets us do all sorts
of great stuff, everything

00:11:09.700 --> 00:11:13.490
you see here-- synthesizers,
effects, visualizers--

00:11:13.490 --> 00:11:16.720
everything you
need for pro audio.

00:11:16.720 --> 00:11:19.865
So from the API
perspective, Web Audio

00:11:19.865 --> 00:11:23.260
is based on a simple
concept-- the audio pipeline.

00:11:23.260 --> 00:11:27.640
And in the API, we refer to this
pipeline as an AudioContext.

00:11:27.640 --> 00:11:30.770
We can build out our pipeline
by taking inputs either

00:11:30.770 --> 00:11:34.050
from a file, microphone,
or synthesizer,

00:11:34.050 --> 00:11:36.850
and processing it using
what we call nodes.

00:11:36.850 --> 00:11:38.910
And these nodes can do
various different things.

00:11:38.910 --> 00:11:40.120
They can apply gain.

00:11:40.120 --> 00:11:41.560
They can apply delay.

00:11:41.560 --> 00:11:43.610
They can even send the
data to JavaScript,

00:11:43.610 --> 00:11:46.080
where JavaScript can
change the sample values.

00:11:46.080 --> 00:11:48.320
Finally, we send it all
out to a destination--

00:11:48.320 --> 00:11:50.280
typically the audio output.

00:11:50.280 --> 00:11:51.830
Now I'm going to
hand it over to Per

00:11:51.830 --> 00:11:57.110
to explain how we get
from this to this.

00:11:57.110 --> 00:12:00.000
PER: Yeah, so now I'm going
to show you the slap back.

00:12:00.000 --> 00:12:02.140
So that was a very
simple effect.

00:12:02.140 --> 00:12:03.605
So you can hear it here.

00:12:03.605 --> 00:12:05.300
So there's a direct
signal, and then

00:12:05.300 --> 00:12:07.487
one small delayed
signal after that.

00:12:07.487 --> 00:12:08.695
[SLAP DELAYED GUITAR PLAYING]

00:12:08.695 --> 00:12:09.960
OK, you can hear that?

00:12:09.960 --> 00:12:15.080
So that can be represented
in a diagram like this.

00:12:15.080 --> 00:12:17.780
So we have the audio
coming from the guitar,

00:12:17.780 --> 00:12:19.450
and then routed
directly to the speaker.

00:12:19.450 --> 00:12:20.700
That's the up line.

00:12:20.700 --> 00:12:23.530
And then, we're adding
one delay signal.

00:12:23.530 --> 00:12:24.660
And then we gain that.

00:12:24.660 --> 00:12:27.160
We lower the volume a
little bit on that one.

00:12:27.160 --> 00:12:33.110
So then you will have that
very simple effect, yeah?

00:12:33.110 --> 00:12:34.850
So the good thing
with Web Audio is

00:12:34.850 --> 00:12:36.980
that it makes it very
easy to actually program

00:12:36.980 --> 00:12:37.920
effects like this.

00:12:37.920 --> 00:12:40.825
Because you have all the
different types of nodes

00:12:40.825 --> 00:12:42.200
you would like to combine.

00:12:42.200 --> 00:12:44.140
And you can do that
in very simple ways.

00:12:44.140 --> 00:12:46.140
So I will just show
you the code here

00:12:46.140 --> 00:12:49.960
that you can use to implement
[INAUDIBLE] like this.

00:12:49.960 --> 00:12:51.850
So first, we need
to get the context.

00:12:51.850 --> 00:12:53.070
We talked about that.

00:12:53.070 --> 00:12:54.320
So you're getting the context.

00:12:54.320 --> 00:12:57.290
And you will use that
object to, for example,

00:12:57.290 --> 00:12:58.870
create the nodes later on.

00:12:58.870 --> 00:13:00.700
And then we're also
getting the user media.

00:13:00.700 --> 00:13:04.070
So that was what we
just showed before.

00:13:04.070 --> 00:13:06.140
So once we get the
user media back,

00:13:06.140 --> 00:13:09.410
we'll start by actually
creating the guitar node here

00:13:09.410 --> 00:13:11.870
by using the Context
object, and then just

00:13:11.870 --> 00:13:14.600
call createMediaStreamSource
on that stream

00:13:14.600 --> 00:13:16.870
that we returned from
the getUserMedia.

00:13:16.870 --> 00:13:20.010
And then, we also get the
reference to the speaker.

00:13:20.010 --> 00:13:23.620
So then, we have our
two nodes to connect.

00:13:23.620 --> 00:13:25.990
Then, we just hook the
first two up together.

00:13:25.990 --> 00:13:28.410
So we say, guitar
connect to speaker.

00:13:28.410 --> 00:13:32.540
So then we have the
direct path here.

00:13:32.540 --> 00:13:35.290
Then, we're using the context
again to create a delay.

00:13:35.290 --> 00:13:37.990
So that's all in the
Web Audio API here.

00:13:37.990 --> 00:13:39.570
So we create the delay node.

00:13:39.570 --> 00:13:42.674
And then we hook the guitar
up with the delay node.

00:13:42.674 --> 00:13:44.090
And then again,
we use the context

00:13:44.090 --> 00:13:45.870
object to create the gain node.

00:13:45.870 --> 00:13:48.770
And then we hook the delay
up with the gain node.

00:13:48.770 --> 00:13:53.080
And then we connect the
gain node with the speaker.

00:13:53.080 --> 00:13:55.220
So it's not many
lines of code you

00:13:55.220 --> 00:13:57.480
need to actually create
an effect like that.

00:13:57.480 --> 00:13:59.700
Then, of course, that's one
of the more simpler ones.

00:13:59.700 --> 00:14:02.740
So we have much more
complex ones that we show.

00:14:02.740 --> 00:14:08.706
So that's the whole
snippet you need, OK?

00:14:12.180 --> 00:14:14.470
JUSTIN: OK, so now we're
going to add a lead guitar

00:14:14.470 --> 00:14:15.900
part to our song.

00:14:15.900 --> 00:14:17.730
And to get a great
guitar sound, we're

00:14:17.730 --> 00:14:19.910
going to combine a whole
pipeline of the effects

00:14:19.910 --> 00:14:21.905
that Per just demonstrated.

00:14:21.905 --> 00:14:24.630
We're going to add delay,
chorus, compression,

00:14:24.630 --> 00:14:28.520
and fuzz to create
a truly sweet tone.

00:14:28.520 --> 00:14:30.365
So let me show you
how that works.

00:14:33.200 --> 00:14:36.630
[GUITAR PLAYING WITH EFFECTS]

00:15:00.400 --> 00:15:01.929
PER: Yeah, something like that.

00:15:01.929 --> 00:15:03.470
But what we're going
to do now, we're

00:15:03.470 --> 00:15:05.260
going to play some
melody on top of our song

00:15:05.260 --> 00:15:05.960
that we're building up.

00:15:05.960 --> 00:15:07.910
And I would like you to
try to remember that.

00:15:07.910 --> 00:15:11.920
Because you could be asked later
on to actually remember it,

00:15:11.920 --> 00:15:12.835
just to let you know.

00:15:12.835 --> 00:15:14.620
JUSTIN: All right,
that's a great sound.

00:15:14.620 --> 00:15:17.140
Per, give us a killer melody.

00:15:17.140 --> 00:15:17.919
PER: Yeah.

00:15:17.919 --> 00:15:18.710
JUSTIN: Here we go.

00:15:22.678 --> 00:15:24.166
[TRACK PLAYING]

00:15:24.166 --> 00:15:28.630
[GUITAR PLAYING WITH EFFECTS]

00:15:40.038 --> 00:15:41.030
JUSTIN: All right.

00:15:41.030 --> 00:15:42.022
PER: Simple, yeah.

00:15:42.022 --> 00:15:42.699
[APPLAUSE]

00:15:42.699 --> 00:15:43.740
JUSTIN: That was rocking.

00:15:43.740 --> 00:15:44.180
PER: Think you
can remember that?

00:15:44.180 --> 00:15:45.495
Try to remember that.

00:15:48.610 --> 00:15:54.750
JUSTIN: All right, we've got
all our parts right here.

00:15:54.750 --> 00:15:58.780
OK, so the next thing
we need for our song

00:15:58.780 --> 00:16:00.300
is a groovy keyboard part.

00:16:00.300 --> 00:16:03.050
And unfortunately, we don't
have any keyboard players

00:16:03.050 --> 00:16:04.140
hiding backstage.

00:16:04.140 --> 00:16:07.210
But Per, do you know
anyone who plays keys?

00:16:07.210 --> 00:16:09.380
PER: Actually, I do.

00:16:09.380 --> 00:16:12.780
As a matter of fact, our
founder and CTO Bjorn

00:16:12.780 --> 00:16:14.430
is rather good at
keyboard, actually.

00:16:14.430 --> 00:16:16.720
JUSTIN: Huh, do you think
he could play for us?

00:16:16.720 --> 00:16:18.050
PER: So what if I call him up?

00:16:18.050 --> 00:16:20.650
JUSTIN: Well, let's do that.

00:16:20.650 --> 00:16:24.930
So over in Soundtrap,
we have the ability

00:16:24.930 --> 00:16:28.000
to invite Bjorn to our song.

00:16:33.017 --> 00:16:34.350
Let's see if he can help us out.

00:16:39.924 --> 00:16:41.340
Soundtrap is located
in Stockholm.

00:16:41.340 --> 00:16:42.500
So I guess it might
take a little while.

00:16:42.500 --> 00:16:43.250
PER: So Bjorn just
joined the chat.

00:16:43.250 --> 00:16:43.865
JUSTIN: OK, great.

00:16:43.865 --> 00:16:45.656
Well, let's see if he
can help us out here.

00:16:52.810 --> 00:16:54.020
PER: Hi, Bjorn.

00:16:54.020 --> 00:16:54.980
BJORN: Hi, Justin.

00:16:54.980 --> 00:16:55.940
Hi, Per.

00:16:55.940 --> 00:16:57.484
PER: Hi, how are you?

00:16:57.484 --> 00:16:58.150
BJORN: I'm fine.

00:16:58.150 --> 00:16:59.250
How are you?

00:16:59.250 --> 00:17:01.110
PER: Very good, thanks.

00:17:01.110 --> 00:17:03.990
JUSTIN: So Per tells me
you play a little keys.

00:17:03.990 --> 00:17:06.450
And that's just what
we need for a song.

00:17:06.450 --> 00:17:08.474
We're here at Google
I/O recording a song,

00:17:08.474 --> 00:17:10.510
a theme song for
Google I/O. Do you

00:17:10.510 --> 00:17:12.079
think maybe you
could help us out?

00:17:12.079 --> 00:17:16.980
BJORN: Well, you know, I
have this MIDI keyboard here.

00:17:16.980 --> 00:17:20.599
So I can give it a try.

00:17:20.599 --> 00:17:22.349
It's just a regular
MIDI keyboard.

00:17:22.349 --> 00:17:27.020
And it's connected to my
laptop using a USB cable.

00:17:27.020 --> 00:17:29.615
So I'm going to be
recording some organ here.

00:17:29.615 --> 00:17:33.052
And this is all done
using the Web Media API.

00:17:33.052 --> 00:17:35.670
So let's see here, I'm
going to be adding a track.

00:17:38.191 --> 00:17:39.440
Let's see if we can get some--

00:17:44.560 --> 00:17:47.955
[ORGAN PLAYING]

00:17:47.955 --> 00:17:48.925
JUSTIN: All right.

00:17:48.925 --> 00:17:50.800
BJORN: So did you hear that?

00:17:50.800 --> 00:17:51.920
JUSTIN: Yep.

00:17:51.920 --> 00:17:53.630
BJORN: Cool, so here we go then.

00:17:53.630 --> 00:17:54.880
I'm going to record something.

00:17:59.320 --> 00:18:03.010
[ORGAN PLAYING OVER TRACK]

00:18:17.250 --> 00:18:18.410
Now let me just save that.

00:18:20.891 --> 00:18:21.640
JUSTIN: All right.

00:18:21.640 --> 00:18:22.350
PER: Very good, thanks.

00:18:22.350 --> 00:18:23.308
BJORN: So there you go.

00:18:23.308 --> 00:18:25.618
[APPLAUSE]

00:18:25.618 --> 00:18:26.550
Thank you.

00:18:29.350 --> 00:18:30.804
JUSTIN: So that
was really great.

00:18:30.804 --> 00:18:32.970
Do you think maybe you could
help us out a bit more,

00:18:32.970 --> 00:18:35.030
maybe add a few backing
tracks to the song?

00:18:35.030 --> 00:18:36.330
BJORN: Yeah sure, why not?

00:18:36.330 --> 00:18:37.890
Let me give it a try.

00:18:37.890 --> 00:18:38.610
JUSTIN: OK.

00:18:38.610 --> 00:18:40.670
Well, Bjorn is also
in our project.

00:18:40.670 --> 00:18:42.220
And so it's in the cloud.

00:18:42.220 --> 00:18:44.420
And we'll be notified
when his updates are

00:18:44.420 --> 00:18:48.180
finished so we can
check them out.

00:18:48.180 --> 00:18:52.410
All right, so let's talk
about what we just saw there.

00:18:52.410 --> 00:18:54.800
We did collaboration onstage.

00:18:54.800 --> 00:18:58.300
We did collaboration
with WebRTC.

00:18:58.300 --> 00:19:00.810
WebRTC is all
about communication

00:19:00.810 --> 00:19:03.450
and collaboration,
the ability to connect

00:19:03.450 --> 00:19:07.440
with anyone, any time, anywhere.

00:19:07.440 --> 00:19:09.690
And to be able to make music
together collaboratively,

00:19:09.690 --> 00:19:12.660
this is a perfect use of WebRTC.

00:19:12.660 --> 00:19:16.140
Now technically, WebRTC
provides apps with an API

00:19:16.140 --> 00:19:19.430
to establish a real-time
peer to peer connection.

00:19:19.430 --> 00:19:21.170
And in using that
connection, you

00:19:21.170 --> 00:19:25.890
can send audio, video,
or arbitrary data.

00:19:25.890 --> 00:19:28.870
Now, the API that we used for
making this P2P connection

00:19:28.870 --> 00:19:32.035
is called, naturally,
Peer Connection.

00:19:32.035 --> 00:19:33.410
And if you take
the media streams

00:19:33.410 --> 00:19:36.770
that we got earlier
using getUserMedia,

00:19:36.770 --> 00:19:38.906
we can now attach these
to a Peer Connection.

00:19:38.906 --> 00:19:40.280
And the Peer
Connection will take

00:19:40.280 --> 00:19:43.420
care of the hard work of setting
up a peer to peer connection

00:19:43.420 --> 00:19:46.220
and streaming that audio and
video across the network.

00:19:46.220 --> 00:19:49.780
And this all works great, even
on the real world internet,

00:19:49.780 --> 00:19:51.720
as you heard from Bjorn.

00:19:51.720 --> 00:19:54.610
Now Soundtrap, for the musical
collaboration you just saw,

00:19:54.610 --> 00:19:56.840
they needed a few more
extra features from WebRTC.

00:19:56.840 --> 00:19:58.890
So Per, can you tell
us more about that?

00:19:58.890 --> 00:20:04.150
PER: Yeah sure, so
there's like three things

00:20:04.150 --> 00:20:07.176
we need to be able to
do this in a good way.

00:20:07.176 --> 00:20:08.550
So the use case
for us is that we

00:20:08.550 --> 00:20:11.819
will need to be able to hear
what he is playing, of course.

00:20:11.819 --> 00:20:13.360
We need to be able
to speak with him.

00:20:13.360 --> 00:20:16.500
And we need to be able
to see him, right?

00:20:16.500 --> 00:20:18.800
So we need to have a
video chat functionality.

00:20:18.800 --> 00:20:21.070
We need to have high
quality stereo audio.

00:20:21.070 --> 00:20:24.070
And we need to have the
input that was already

00:20:24.070 --> 00:20:25.450
kind of processed in Web Audio.

00:20:25.450 --> 00:20:27.420
So if I were playing
with my guitar,

00:20:27.420 --> 00:20:29.400
I can have a multitude
of effects added on.

00:20:29.400 --> 00:20:33.920
So I need to have that also
heard over the network.

00:20:33.920 --> 00:20:35.545
Bjorn here was playing
our synthesizer.

00:20:35.545 --> 00:20:37.790
And that is also
done using Web Audio.

00:20:37.790 --> 00:20:41.230
So we heard that, the organ.

00:20:41.230 --> 00:20:44.450
So here's kind of
the setup we need.

00:20:44.450 --> 00:20:48.687
So we need the input
from the upper part

00:20:48.687 --> 00:20:51.110
here, which is the stuff
we already showed you,

00:20:51.110 --> 00:20:53.760
and the effects or any
synthesizers or anything

00:20:53.760 --> 00:20:55.400
created using Web Audio.

00:20:55.400 --> 00:20:58.500
We need the input from
the actual computer mic.

00:20:58.500 --> 00:21:01.260
So that needs to be mixed in
with the other stuff coming

00:21:01.260 --> 00:21:02.300
from Web Audio.

00:21:02.300 --> 00:21:04.060
And then, we need
the webcam stream.

00:21:04.060 --> 00:21:05.930
And we put that into
the Peer Connection.

00:21:05.930 --> 00:21:08.740
And then the magic
happens, yeah?

00:21:08.740 --> 00:21:10.575
So let's look at
the code for that.

00:21:10.575 --> 00:21:13.140
So we're using the
getUserMedia API again here.

00:21:13.140 --> 00:21:15.120
But instead of
fetching the audio,

00:21:15.120 --> 00:21:17.050
we're fetching the video part.

00:21:17.050 --> 00:21:19.800
And when that is returning,
then the then clause

00:21:19.800 --> 00:21:21.580
here is executed.

00:21:21.580 --> 00:21:24.536
So the first thing-- if
you see in the bottom here,

00:21:24.536 --> 00:21:26.910
we have actually received an
access to our webcam stream.

00:21:29.780 --> 00:21:32.590
Then, we are taking the
musicOut object, which

00:21:32.590 --> 00:21:34.840
is the output and
the mix of everything

00:21:34.840 --> 00:21:37.560
we've done in Web Audio,
including the mic,

00:21:37.560 --> 00:21:39.890
and we create a
MediaStream destination

00:21:39.890 --> 00:21:41.817
using that musicOut object.

00:21:41.817 --> 00:21:43.650
And then, we're getting
the stream for that.

00:21:43.650 --> 00:21:45.890
So then, we have our
stereo music stream.

00:21:45.890 --> 00:21:48.270
Then, we are hooking up
both the stereo music stream

00:21:48.270 --> 00:21:50.580
and the webcam stream
to the Peer Connection.

00:21:50.580 --> 00:21:52.250
So this is also
Dart syntax, so we

00:21:52.250 --> 00:21:55.400
can use the dot
dot notation here.

00:21:55.400 --> 00:21:57.320
And once we have
added the stereo music

00:21:57.320 --> 00:21:59.920
stream and the webcam stream
to the Peer Connection,

00:21:59.920 --> 00:22:02.270
we just start to call
on the Peer Connection.

00:22:02.270 --> 00:22:06.260
And then they start to talk
to each other, the two peers,

00:22:06.260 --> 00:22:07.850
right?

00:22:07.850 --> 00:22:08.745
JUSTIN: Very cool.

00:22:08.745 --> 00:22:09.370
PER: Very good.

00:22:12.930 --> 00:22:17.430
JUSTIN: So that's all
about Peer Connection.

00:22:17.430 --> 00:22:19.559
So now let's go see
if Bjorn is finished

00:22:19.559 --> 00:22:20.725
adding those backing tracks.

00:22:37.700 --> 00:22:40.520
It seems like we're waiting
for a second on those backing

00:22:40.520 --> 00:22:41.600
tracks.

00:22:41.600 --> 00:22:46.550
So while we're waiting, a
proton walks into a bar.

00:22:46.550 --> 00:22:49.510
He sees an electron
sitting there and says,

00:22:49.510 --> 00:22:52.048
I feel there's an
attraction between us.

00:22:52.048 --> 00:22:55.640
PER: Yeah, here it is.

00:22:55.640 --> 00:22:58.440
JUSTIN: All right, so now
we've got these backing tracks.

00:22:58.440 --> 00:23:00.620
Let's go and check out
what our song sounds like.

00:23:05.580 --> 00:23:06.220
Here we go.

00:23:06.220 --> 00:23:09.636
[MUSIC PLAYING]

00:23:23.467 --> 00:23:24.550
JUSTIN: What do you think?

00:23:24.550 --> 00:23:26.905
[APPLAUSE]

00:23:26.905 --> 00:23:30.210
PER: Quite cool.

00:23:30.210 --> 00:23:33.810
JUSTIN: OK, but we're missing
one thing-- the vocals.

00:23:33.810 --> 00:23:36.280
And so we've
collaborated on stage.

00:23:36.280 --> 00:23:38.550
We've collaborated
across the internet.

00:23:38.550 --> 00:23:41.110
And now, we're going to do
some collaboration with you.

00:23:41.110 --> 00:23:43.390
So you're all going to sing
the vocals for the song.

00:23:43.390 --> 00:23:45.639
And I'm going to go out in
the audience and record it.

00:23:45.639 --> 00:23:49.090
And to do that, I've got
my Nexus 5 right here.

00:23:49.090 --> 00:23:54.030
And I'm logged into Soundtrap
using Chrome for Android.

00:23:54.030 --> 00:23:56.900
Now, Per's singing voice
is a little bit better

00:23:56.900 --> 00:23:58.360
than me-- classically trained.

00:23:58.360 --> 00:24:00.410
And so he's going
to lead you on this.

00:24:00.410 --> 00:24:01.650
Per?

00:24:01.650 --> 00:24:03.860
PER: Yeah, yeah, sure, sure.

00:24:03.860 --> 00:24:06.160
So I told you to
remember the melody part.

00:24:06.160 --> 00:24:09.440
So we're actually going to put
some lyrics on top of that.

00:24:09.440 --> 00:24:14.320
And you may imagine already,
so it's Google I/O, Google I/O,

00:24:14.320 --> 00:24:17.039
Google I/O, Google
I/O four times, OK?

00:24:17.039 --> 00:24:17.830
So it's quite easy.

00:24:17.830 --> 00:24:20.197
JUSTIN: If you forget,
it's like right here.

00:24:20.197 --> 00:24:22.280
PER: So what we'll do is
you've heard the song now

00:24:22.280 --> 00:24:23.280
a couple of times.

00:24:23.280 --> 00:24:25.340
So we'll do a rehearsal first.

00:24:25.340 --> 00:24:28.560
And when we rehearse, after the
second time we have sung it,

00:24:28.560 --> 00:24:30.250
we'll actually turn
down the volume.

00:24:30.250 --> 00:24:33.600
But you should continue
singing anyway with me, right?

00:24:33.600 --> 00:24:37.460
And then we'll do a take
after that, promise.

00:24:37.460 --> 00:24:39.775
Sing from your toes,
as we say in Swedish.

00:24:39.775 --> 00:24:43.160
[SPEAKING SWEDISH], yeah, OK?

00:24:43.160 --> 00:24:44.810
OK, let's try it.

00:24:44.810 --> 00:24:45.640
Should we--

00:24:45.640 --> 00:24:46.390
JUSTIN: All right.

00:24:46.390 --> 00:24:49.810
PER: Play, yeah?

00:24:49.810 --> 00:24:50.798
JUSTIN: Here we go.

00:24:55.250 --> 00:24:57.692
PER: I'll take the
practice round first.

00:24:57.692 --> 00:24:58.650
JUSTIN: OK, here we go.

00:25:06.020 --> 00:25:08.180
PER: One moment.

00:25:08.180 --> 00:25:09.960
[MUSIC PLAYING]

00:25:09.960 --> 00:25:20.420
[SINGING] Google I/O-- help me
out-- Google I/O, Google I/O,

00:25:20.420 --> 00:25:24.729
Google I/O.

00:25:24.729 --> 00:25:26.020
So that's how it's going to be.

00:25:26.020 --> 00:25:27.103
That was a practice round.

00:25:27.103 --> 00:25:29.940
Now you know.

00:25:29.940 --> 00:25:33.602
We're going to be-- we'll try
to record it on the Nexus 5.

00:25:33.602 --> 00:25:35.310
So you can lean over
to that one as well.

00:25:35.310 --> 00:25:37.540
Because there's the mic.

00:25:37.540 --> 00:25:38.347
Let's do it, then.

00:25:38.347 --> 00:25:40.180
JUSTIN: All right, that
sounded pretty good.

00:25:40.180 --> 00:25:41.880
But I think they can
be a little louder.

00:25:41.880 --> 00:25:42.380
PER: Yeah.

00:25:42.380 --> 00:25:44.230
JUSTIN: That was maybe singing
from the knees, not quite

00:25:44.230 --> 00:25:44.980
the toes.

00:25:44.980 --> 00:25:46.570
PER: Yeah, yeah, exactly.

00:25:46.570 --> 00:25:49.050
JUSTIN: All right,
so one more time.

00:25:49.050 --> 00:25:49.725
Let's do it.

00:25:52.852 --> 00:25:54.434
[MUSIC PLAYING]

00:25:54.434 --> 00:26:05.910
AUDIENCE: [SINGING] Google
I/O, Google I/O, Google I/O,

00:26:05.910 --> 00:26:09.820
Google I/O.

00:26:09.820 --> 00:26:10.640
PER: Great.

00:26:10.640 --> 00:26:13.979
[APPLAUSE]

00:26:13.979 --> 00:26:16.850
Very good.

00:26:16.850 --> 00:26:18.200
JUSTIN: You guys were fantastic.

00:26:18.200 --> 00:26:19.010
PER: Definitely.

00:26:19.010 --> 00:26:21.240
JUSTIN: That was
definitely all the way down

00:26:21.240 --> 00:26:25.222
to the soles of the feet.

00:26:25.222 --> 00:26:26.930
All right, so we're
now going to kick off

00:26:26.930 --> 00:26:29.240
the final mix down for the song.

00:26:29.240 --> 00:26:31.100
And so while we
wait for that, let's

00:26:31.100 --> 00:26:34.560
talk about what Soundtrap needed
from an application platform.

00:26:39.730 --> 00:26:43.320
In building a cloud-based
musical collaboration app,

00:26:43.320 --> 00:26:45.400
Soundtrap knew they
needed a platform that

00:26:45.400 --> 00:26:47.030
was familiar to
their developers,

00:26:47.030 --> 00:26:51.170
and yet would scale as the
project became more complex.

00:26:51.170 --> 00:26:52.814
And as a small
startup, they also

00:26:52.814 --> 00:26:54.480
want to make sure
their developers could

00:26:54.480 --> 00:26:57.010
be as productive as possible.

00:26:57.010 --> 00:26:59.760
So I want to talk
about these in turn.

00:26:59.760 --> 00:27:02.170
This is why
Soundtrap chose Dart,

00:27:02.170 --> 00:27:06.120
a new platform for
scalable web engineering.

00:27:06.120 --> 00:27:10.210
Let's look at what Dart provides
that makes it so attractive.

00:27:10.210 --> 00:27:14.840
First, familiarity-- Dart
feels like JavaScript.

00:27:14.840 --> 00:27:19.270
Semicolons, curly braces
for a reason, classes,

00:27:19.270 --> 00:27:22.260
single inheritance-- everything
familiar to people who are

00:27:22.260 --> 00:27:26.040
using JavaScript or other
languages like Java or C++.

00:27:26.040 --> 00:27:30.040
And because of that, Dart
was designed explicitly

00:27:30.040 --> 00:27:32.000
to be easy to learn.

00:27:32.000 --> 00:27:34.790
Google's run numerous internal
and external hackathons.

00:27:34.790 --> 00:27:37.830
And everybody picks
it up super fast.

00:27:37.830 --> 00:27:40.320
Now, the Dart team also
took the opportunity

00:27:40.320 --> 00:27:43.630
to go a bit beyond JavaScript
to clean some things up.

00:27:43.630 --> 00:27:47.980
While Dart is familiar, it also
makes things easy and terse.

00:27:47.980 --> 00:27:50.340
So here, we're
declaring the user class

00:27:50.340 --> 00:27:52.830
with two fields--
username and password.

00:27:52.830 --> 00:27:54.700
This code sample should
look very natural.

00:27:57.594 --> 00:27:59.510
We can also add things
like name constructors.

00:27:59.510 --> 00:28:01.705
You can create
different constructors

00:28:01.705 --> 00:28:02.580
with different names.

00:28:02.580 --> 00:28:06.440
And it's very
clear what they do.

00:28:06.440 --> 00:28:10.250
We can also add getters and
setters when you need them.

00:28:10.250 --> 00:28:12.400
And we can do a simple
getter in just one line.

00:28:12.400 --> 00:28:14.820
You can look at this fat
arrow syntax where we check,

00:28:14.820 --> 00:28:16.810
is this username valid?

00:28:16.810 --> 00:28:21.510
Super easy to write single
line functions and methods.

00:28:21.510 --> 00:28:24.160
Now let's address scalability.

00:28:24.160 --> 00:28:27.280
Typical web app development
starts out as small scripts

00:28:27.280 --> 00:28:30.380
and grows to very
large, complicated apps.

00:28:30.380 --> 00:28:32.370
But we want to make
sure as that app grows

00:28:32.370 --> 00:28:36.410
from 100 to 100,000
lines of code,

00:28:36.410 --> 00:28:39.970
the environment is there with
you to help you scale up.

00:28:39.970 --> 00:28:42.530
So Soundtrap started out
just like this-- few files

00:28:42.530 --> 00:28:43.470
and scripts.

00:28:43.470 --> 00:28:44.860
And they grew over time.

00:28:44.860 --> 00:28:48.700
But they made use of stuff like
Dart's libraries and packages

00:28:48.700 --> 00:28:51.260
to keep things organized.

00:28:51.260 --> 00:28:53.260
As the app grew in size,
the Soundtrap engineers

00:28:53.260 --> 00:28:54.885
didn't have to slow
their productivity.

00:28:57.040 --> 00:28:59.310
Here, Dart can bundle
code into libraries.

00:28:59.310 --> 00:29:01.140
And libraries are
like modules of code.

00:29:01.140 --> 00:29:03.640
And from the dart:async
library, we're going to pull

00:29:03.640 --> 00:29:05.630
in the Future class.

00:29:05.630 --> 00:29:08.244
We've seen futures before
when we used getUserMedia.

00:29:08.244 --> 00:29:09.660
And futures are
these objects that

00:29:09.660 --> 00:29:11.630
represent things
that don't exist yet.

00:29:11.630 --> 00:29:14.230
But they will in
the future, get it?

00:29:14.230 --> 00:29:16.555
So they're much easier
than call backs.

00:29:16.555 --> 00:29:18.760
And so also, like other
structured languages,

00:29:18.760 --> 00:29:21.360
Dart classes can
have static methods.

00:29:21.360 --> 00:29:24.340
Here, our load method is
going to return a future that

00:29:24.340 --> 00:29:28.474
will resolve when the back end
service completes its query.

00:29:28.474 --> 00:29:31.040
Last, let's talk
about productivity.

00:29:31.040 --> 00:29:32.920
Soundtrap is able
to be productive

00:29:32.920 --> 00:29:35.665
because tools like the Dart
Editor and the Dart Analyzer

00:29:35.665 --> 00:29:38.890
are able to statically
analyze the code.

00:29:38.890 --> 00:29:40.460
Because of things
like static typing,

00:29:40.460 --> 00:29:42.235
they can provide
real-time feedback

00:29:42.235 --> 00:29:44.210
when you do something wrong.

00:29:44.210 --> 00:29:47.060
Here, we're notified
immediately by the Dart Editor

00:29:47.060 --> 00:29:48.410
that we misspelled a field.

00:29:48.410 --> 00:29:50.532
We don't need to go run
our app or fail our unit

00:29:50.532 --> 00:29:52.240
test to know that we
did something wrong.

00:29:52.240 --> 00:29:54.610
The tools tell us proactively.

00:29:54.610 --> 00:29:59.527
And as the code grows to
many packages and libraries,

00:29:59.527 --> 00:30:01.860
it's really hard for a developer
to keep all of the APIs

00:30:01.860 --> 00:30:02.825
in their head.

00:30:02.825 --> 00:30:05.540
And the Dart Editor
comes in handy there.

00:30:05.540 --> 00:30:07.250
The Dart Editor gives
this real-time code

00:30:07.250 --> 00:30:11.990
completion like any sort
of modern, mature IDE.

00:30:11.990 --> 00:30:15.720
Last, because of the static
typing and static [INAUDIBLE]

00:30:15.720 --> 00:30:20.160
analysis, the tools know
what types the objects are.

00:30:20.160 --> 00:30:22.810
The developer can
always stay in the flow.

00:30:22.810 --> 00:30:28.800
So Dart-- familiarity,
scalability, productivity.

00:30:28.800 --> 00:30:30.422
Now let's talk to Per.

00:30:30.422 --> 00:30:31.505
You guys worked with this.

00:30:31.505 --> 00:30:33.820
Can you talk more about
what specifically Dart

00:30:33.820 --> 00:30:34.984
helped you do?

00:30:34.984 --> 00:30:36.400
PER: This is one
of many examples,

00:30:36.400 --> 00:30:39.240
of course, why Dart
is so important for us

00:30:39.240 --> 00:30:40.021
and good for us.

00:30:40.021 --> 00:30:41.520
So we've seen it
now a couple times.

00:30:41.520 --> 00:30:44.430
We need to load the project
and the tracks in the project.

00:30:44.430 --> 00:30:45.780
And it's a cloud-based service.

00:30:45.780 --> 00:30:48.580
So we would like to do that
as fast as possible because we

00:30:48.580 --> 00:30:51.630
synchronize in between
the devices all the time.

00:30:51.630 --> 00:30:55.140
Asynchronous program is a little
bit tricky in other languages,

00:30:55.140 --> 00:30:56.970
like for example JavaScript.

00:30:56.970 --> 00:31:03.750
But it makes it very easy using
the Future mechanism in Dart.

00:31:03.750 --> 00:31:06.720
So let's say that we have a
project with three tracks.

00:31:06.720 --> 00:31:08.690
So we define a
method loadProject,

00:31:08.690 --> 00:31:10.210
which returns a future.

00:31:10.210 --> 00:31:13.910
And then, when the HTTP request
here actually also returns

00:31:13.910 --> 00:31:17.480
a future, when that is
done, then we parse to JSON.

00:31:17.480 --> 00:31:20.470
So that is what is
done in this method.

00:31:20.470 --> 00:31:23.540
Then, we define a second
method to load the audio

00:31:23.540 --> 00:31:25.320
and do exactly the same thing.

00:31:25.320 --> 00:31:28.760
But we decode in the
audio data, the blob.

00:31:28.760 --> 00:31:30.530
So then, we hook
the two methods up.

00:31:30.530 --> 00:31:32.410
So first, we load the project.

00:31:32.410 --> 00:31:34.900
And when it's executed
loading the project,

00:31:34.900 --> 00:31:37.710
and then we have our
kind of information

00:31:37.710 --> 00:31:41.020
about the product and the
tracks, then we return.

00:31:41.020 --> 00:31:42.920
We will have the
project instance here.

00:31:42.920 --> 00:31:44.200
So we can work on that.

00:31:44.200 --> 00:31:46.970
And then, we're using something
that's called a wait method.

00:31:46.970 --> 00:31:48.650
That means that
everything-- so you

00:31:48.650 --> 00:31:50.920
can pass in a list of futures.

00:31:50.920 --> 00:31:53.380
And when all the
futures have executed,

00:31:53.380 --> 00:31:57.000
their job actually continues.

00:31:57.000 --> 00:32:01.190
So in the Future.wait method,
we pass in a list of futures

00:32:01.190 --> 00:32:04.370
from the loadAudio method.

00:32:04.370 --> 00:32:08.040
And that can also be done
very neatly in Dart here.

00:32:08.040 --> 00:32:09.539
So we have the project instance.

00:32:09.539 --> 00:32:10.580
We're calling the tracks.

00:32:10.580 --> 00:32:13.121
And we're using something that's
called a map, which actually

00:32:13.121 --> 00:32:16.000
collects all the futures
from the loadAudio method

00:32:16.000 --> 00:32:20.280
calls into a list and pass
that into the Future.wait.

00:32:20.280 --> 00:32:23.399
So it's quite a very
dense way of doing

00:32:23.399 --> 00:32:24.440
asynchronous programming.

00:32:28.014 --> 00:32:28.960
OK.

00:32:28.960 --> 00:32:32.360
JUSTIN: So Soundtrap is a great
demonstration of the modern web

00:32:32.360 --> 00:32:34.760
platform using
APIs covering media

00:32:34.760 --> 00:32:37.860
capture, audio processing,
real-time communication,

00:32:37.860 --> 00:32:38.950
and more.

00:32:38.950 --> 00:32:42.370
But these APIs aren't
just for Chrome.

00:32:42.370 --> 00:32:44.820
These APIs belong
to the open web.

00:32:44.820 --> 00:32:47.240
And they're available on
multiple modern browsers

00:32:47.240 --> 00:32:50.220
on both mobile and desktop.

00:32:50.220 --> 00:32:55.320
So for example, Web Audio is
available on over 2 billion

00:32:55.320 --> 00:32:58.520
devices, of which over
a billion are mobile,

00:32:58.520 --> 00:33:01.750
including Android and iOS.

00:33:01.750 --> 00:33:05.630
WebRTC-- over 1.5
billion browsers

00:33:05.630 --> 00:33:08.660
and 300 million mobile devices.

00:33:08.660 --> 00:33:12.210
We're seeing great growth
across the WebRTC ecosystem

00:33:12.210 --> 00:33:15.930
on both desktop and mobile
with multiple major players

00:33:15.930 --> 00:33:18.360
shipping apps built on WebRTC.

00:33:18.360 --> 00:33:21.220
Some examples--
Snapchat's video chat,

00:33:21.220 --> 00:33:26.140
powered by WebRTC, TokBox,
and Amazon's Mayday service,

00:33:26.140 --> 00:33:29.480
all powered by the
WebRTC platform.

00:33:29.480 --> 00:33:32.260
I've also been in touch with
all the major WebRTC app

00:33:32.260 --> 00:33:33.240
developers.

00:33:33.240 --> 00:33:35.910
And there's going to be several
more major announcements later

00:33:35.910 --> 00:33:36.410
this year.

00:33:41.350 --> 00:33:47.540
Finally, we're super excited
to announce that in Android L,

00:33:47.540 --> 00:33:53.190
the WebView v36 fully supports
Web Audio and WebRTC, allowing

00:33:53.190 --> 00:33:56.050
those building native apps
to bring these technologies

00:33:56.050 --> 00:34:01.042
to the over 1 billion
Android 30 day active users.

00:34:01.042 --> 00:34:05.762
[APPLAUSE]

00:34:08.610 --> 00:34:10.389
So the mixing is finished.

00:34:10.389 --> 00:34:12.540
Let's come full circle
back to my Nexus

00:34:12.540 --> 00:34:14.659
7 and listen to our song.

00:34:30.371 --> 00:34:33.935
Well, it looks like our Nexus 7
has decided it has other plans.

00:34:43.261 --> 00:34:44.010
That's no problem.

00:34:56.441 --> 00:34:56.940
Here we go.

00:35:03.336 --> 00:35:06.780
[MUSIC PLAYING]

00:35:20.064 --> 00:35:24.000
[APPLAUSE]

00:35:27.950 --> 00:35:29.840
JUSTIN: So give
yourselves a hand.

00:35:29.840 --> 00:35:31.320
You guys were fantastic.

00:35:31.320 --> 00:35:32.870
Thanks for singing.

00:35:32.870 --> 00:35:34.370
And if you want to
listen again, you

00:35:34.370 --> 00:35:37.410
can download the song
from the Soundtrap site.

00:35:37.410 --> 00:35:40.840
[APPLAUSE]

00:35:43.979 --> 00:35:46.020
So now that we've got you
all inspired about what

00:35:46.020 --> 00:35:48.010
the modern web
platform can do, you

00:35:48.010 --> 00:35:49.260
can try it out for yourselves.

00:35:49.260 --> 00:35:51.390
If you haven't already
checked it out,

00:35:51.390 --> 00:35:54.770
come get your hands dirty at the
WebRTC Code Lab, running here

00:35:54.770 --> 00:35:57.740
at I/O until the end of today,
and also available later

00:35:57.740 --> 00:35:58.896
online.

00:35:58.896 --> 00:36:01.740
There are also some great
resources on WebRTC,

00:36:01.740 --> 00:36:06.670
Web Audio, and Dart written
by experts in an excellent way

00:36:06.670 --> 00:36:09.410
to try out these technologies.

00:36:09.410 --> 00:36:11.370
And that wraps up our
session for today.

00:36:11.370 --> 00:36:12.860
Now we want to hear from you.

00:36:12.860 --> 00:36:15.090
You can give us
feedback on the session

00:36:15.090 --> 00:36:16.620
at the address listed here.

00:36:16.620 --> 00:36:19.290
And we also have a few minutes
to take audience requests,

00:36:19.290 --> 00:36:20.010
I mean questions.

00:36:22.770 --> 00:36:23.760
Thank you.

00:36:23.760 --> 00:36:28.143
[APPLAUSE]

00:36:28.143 --> 00:36:31.310
PER: Thank you very
much, thank you.

00:36:31.310 --> 00:36:36.240
AUDIENCE: So first of all,
thank you for the great talk.

00:36:36.240 --> 00:36:37.640
It was very inspiring.

00:36:37.640 --> 00:36:40.200
And the song is really cool.

00:36:40.200 --> 00:36:45.590
I wanted to ask about
audio latency on Android.

00:36:45.590 --> 00:36:48.960
Did you get it low enough?

00:36:48.960 --> 00:36:51.334
JUSTIN: So that's a bit
of a work in progress

00:36:51.334 --> 00:36:52.250
I'll have to tell you.

00:36:52.250 --> 00:36:56.725
We've made a lot of improvements
to latency through ICS, Jelly

00:36:56.725 --> 00:36:58.564
Bean and KitKat.

00:36:58.564 --> 00:36:59.980
We're still not
to the point where

00:36:59.980 --> 00:37:01.760
we can get the--
what we really want

00:37:01.760 --> 00:37:05.535
is like 20 millisecond
latency on Android.

00:37:05.535 --> 00:37:08.160
We're doing a lot of work there,
including being able to expose

00:37:08.160 --> 00:37:12.569
all the APIs through OpenSL,
through the C++ layer,

00:37:12.569 --> 00:37:14.610
so that we can have the
minimum latency possible.

00:37:14.610 --> 00:37:17.640
So we're not where
we want to be yet.

00:37:17.640 --> 00:37:19.540
But we're spending a
ton of energy on it.

00:37:19.540 --> 00:37:22.756
AUDIENCE: For L, are
we going to have it?

00:37:22.756 --> 00:37:25.050
JUSTIN: Ah, I'm not going
to make any promises.

00:37:25.050 --> 00:37:26.761
Just we're working
very hard on it.

00:37:26.761 --> 00:37:27.635
AUDIENCE: OK, thanks.

00:37:32.079 --> 00:37:33.620
AUDIENCE: Hi, I
missed the beginning.

00:37:33.620 --> 00:37:34.911
Maybe you guys touched on this.

00:37:34.911 --> 00:37:37.100
But I was curious
about MIDI support

00:37:37.100 --> 00:37:38.630
and being able to
hook up a synth

00:37:38.630 --> 00:37:42.550
and maybe get down with the
piano or organ or something

00:37:42.550 --> 00:37:43.080
like that.

00:37:43.080 --> 00:37:48.130
PER: Yeah, it's Web MIDI, which
is also part of the standard.

00:37:48.130 --> 00:37:50.612
So we hook up the MIDI
directly to the USB port.

00:37:50.612 --> 00:37:52.850
JUSTIN: Right, so
Web MIDI is kind

00:37:52.850 --> 00:37:54.480
of a very nascent standard.

00:37:54.480 --> 00:37:56.520
It's supported
provisionally within Chrome.

00:37:56.520 --> 00:38:00.162
We hope to promote it in
the next version or two

00:38:00.162 --> 00:38:05.175
to be full API and see it
picked up by other browsers.

00:38:05.175 --> 00:38:07.567
But you saw Web MIDI
in action here when

00:38:07.567 --> 00:38:08.650
they played the keys part.

00:38:08.650 --> 00:38:11.180
And Soundtrap is making
full use of this.

00:38:11.180 --> 00:38:13.060
And it is a great API
in the web platform.

00:38:19.036 --> 00:38:20.432
PER: Yeah.

00:38:20.432 --> 00:38:22.140
AUDIENCE: Sorry, what
kind of server side

00:38:22.140 --> 00:38:23.860
is included in this demo?

00:38:23.860 --> 00:38:28.420
So I wanted to ask how the
tracks are joined together

00:38:28.420 --> 00:38:32.954
when you publish the
track, the project.

00:38:32.954 --> 00:38:34.120
PER: How they work together?

00:38:34.120 --> 00:38:36.570
AUDIENCE: On the server
side or on the client side

00:38:36.570 --> 00:38:37.982
here in Soundtrap?

00:38:37.982 --> 00:38:40.190
PER: Yeah, so the music is
stored on the server side,

00:38:40.190 --> 00:38:40.689
yeah.

00:38:40.689 --> 00:38:43.370
But then, it pushed
out to the client.

00:38:43.370 --> 00:38:45.545
So we're using a
Play framework--

00:38:45.545 --> 00:38:47.670
I don't know if you know
that-- on the server side.

00:38:47.670 --> 00:38:49.825
But it's Dart on
the client side.

00:38:49.825 --> 00:38:50.700
AUDIENCE: [INAUDIBLE]

00:38:50.700 --> 00:38:51.200
PER: Sorry?

00:38:51.200 --> 00:38:52.700
AUDIENCE: It's mixed online?

00:38:55.320 --> 00:38:56.720
PER: It's mixed on the server.

00:38:56.720 --> 00:38:58.420
But when you play
it in the studio,

00:38:58.420 --> 00:38:59.890
it's played directly
on the client.

00:38:59.890 --> 00:39:04.340
But the last mix that you heard
was mixed on the server, right?

00:39:04.340 --> 00:39:14.309
JUSTIN: Right, so in the actual
editor, when all the tracks are

00:39:14.309 --> 00:39:15.850
being played, it
plays in the client.

00:39:15.850 --> 00:39:18.308
But when we do the final mix
down to make the actual output

00:39:18.308 --> 00:39:20.421
MP3 file, then
that's going to go

00:39:20.421 --> 00:39:21.795
and be done by
the cloud service.

00:39:24.800 --> 00:39:28.030
PER: I see, this is
only the [INAUDIBLE].

00:39:28.030 --> 00:39:31.460
JUSTIN: Oh, right.

00:39:31.460 --> 00:39:33.205
So when we're in
here in the studio--

00:39:38.015 --> 00:39:40.265
PER: Everything here is
played directly in the client,

00:39:40.265 --> 00:39:41.733
in the studio.

00:39:41.733 --> 00:39:47.914
So if I-- oh, now we have
no audio anymore, I think.

00:39:47.914 --> 00:39:49.902
[MUSIC PLAYING]

00:39:49.902 --> 00:39:52.884
So that's played
directly on the client.

00:39:56.363 --> 00:39:59.337
Yeah.

00:39:59.337 --> 00:40:01.170
JUSTIN: OK, thank you,
everyone, for coming.

00:40:01.170 --> 00:40:02.250
Have a great rest of I/O.

00:40:02.250 --> 00:40:03.800
[APPLAUSE]

