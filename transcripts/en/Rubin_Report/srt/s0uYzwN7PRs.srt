1
00:00:00,070 --> 00:00:03,420
[inaudible].

2
00:00:05,060 --> 00:00:08,510
We're continuing our partnership with
learn liberty today and joining me as an

3
00:00:08,511 --> 00:00:12,740
author and associate
professor of Philosophy at the
College of William and Mary.

4
00:00:12,920 --> 00:00:16,370
Chris Fryman. Welcome to the Rubin report.
Thanks for having me. All right man.

5
00:00:16,430 --> 00:00:19,610
We're going to do philosophy for an
hour. Are you ready? Sounds good. Yeah,

6
00:00:20,180 --> 00:00:24,380
you are prepared. I feel the jacket,
shirt combo. It's very philosophy.

7
00:00:24,850 --> 00:00:28,530
Give me the Rubin. That's what this
is my Tyler came up with. All right,

8
00:00:28,610 --> 00:00:32,180
let's talk philosophy because I think one
of the things that I try to do on this

9
00:00:32,181 --> 00:00:37,040
show is I talk about philosophies more
than people, ideas more than people.

10
00:00:37,041 --> 00:00:40,730
And it seems to me we live in a time
where we don't do a lot of philosophy and

11
00:00:40,731 --> 00:00:44,240
ideas stuff. Well, and I guess that's
maybe why, why people are watching this.

12
00:00:44,241 --> 00:00:47,990
So let's do a little philosophy
you want to one with you.

13
00:00:49,060 --> 00:00:51,860
Give me just some of the basics of
what people should understand about

14
00:00:51,861 --> 00:00:52,530
philosophy.

15
00:00:52,530 --> 00:00:55,920
Okay. Well, yeah, that's a great question.
How's that for an open ended question?

16
00:00:55,980 --> 00:01:00,720
Discharge? Uh, yeah, something might
take the hour. But uh, yeah, so I think,

17
00:01:01,260 --> 00:01:05,610
you know, at the fundamental
level philosophy is about
challenging assumptions.

18
00:01:05,820 --> 00:01:09,120
I think one thing that makes philosophy
different from other sorts of academic

19
00:01:09,121 --> 00:01:12,990
disciplines is that you can't
really take anything for granted.

20
00:01:13,200 --> 00:01:15,900
So when you're, you
know, doing philosophy,

21
00:01:16,050 --> 00:01:20,160
you have to justify why killing
people is wrong. For example,

22
00:01:20,400 --> 00:01:22,260
why feeding the hungry is good.

23
00:01:22,530 --> 00:01:27,030
And all of these things that we take for
granted at the level of everyday life

24
00:01:27,031 --> 00:01:29,850
philosophy calls into question.
And I think that's really important.

25
00:01:30,210 --> 00:01:34,170
And so the kinds of philosophical
questions that I'm most
interested in are ones

26
00:01:34,171 --> 00:01:38,520
having to do with moral right
and wrong justice, injustice,

27
00:01:38,700 --> 00:01:43,250
the moral importance of economic equality,
these sorts of things. Uh, and also the,

28
00:01:43,260 --> 00:01:45,690
the ethics of public policy.
So for example,

29
00:01:46,380 --> 00:01:51,380
one thing that non
philosophical disciplines can
do is make predictions about

30
00:01:52,380 --> 00:01:54,180
what a given policy is likely to do.

31
00:01:54,181 --> 00:01:58,950
So we'll opening the borders lead
to higher unemployment, higher GDP,

32
00:01:58,951 --> 00:02:02,070
something like that. Um,
but all things considered,

33
00:02:02,071 --> 00:02:04,410
they can't really tell us what the
right thing to do is. We say, okay,

34
00:02:04,411 --> 00:02:09,300
suppose it turns out that opening
borders will slightly increase domestic

35
00:02:09,330 --> 00:02:10,163
unemployment,

36
00:02:10,320 --> 00:02:15,180
but it also will mean that a certain
workers and the developing world will see

37
00:02:15,181 --> 00:02:17,790
their incomes rise by 300%.
For example,

38
00:02:18,030 --> 00:02:19,950
this leaves open the question
of what should we do?

39
00:02:20,100 --> 00:02:21,660
Is that a trade off that we should make?

40
00:02:21,990 --> 00:02:25,800
And that's really what philosophy
tries to answer is what should we do?

41
00:02:25,801 --> 00:02:26,850
All things considered.

42
00:02:26,950 --> 00:02:27,231
All right,

43
00:02:27,231 --> 00:02:30,890
so in a little bit we're going to get
to some of your moral philosophies that

44
00:02:30,891 --> 00:02:33,530
you care about, an economic
philosophies and, and uh,

45
00:02:33,680 --> 00:02:37,070
immigration and a bunch of other
things in just a little bit. Uh,

46
00:02:37,130 --> 00:02:41,210
but first I'm curious,
what got you interested in
philosophy in the first place?

47
00:02:41,810 --> 00:02:43,340
That's a good question.
Uh,

48
00:02:43,490 --> 00:02:46,580
so I think it was doing philosophy
before I realized I was doing philosophy

49
00:02:46,581 --> 00:02:48,530
because arguing,

50
00:02:48,531 --> 00:02:52,370
let's say good natured arguing was
the family tradition in my household.

51
00:02:52,371 --> 00:02:57,020
So ever since I was a little kid, uh,
you know, my parents and my sister and I,

52
00:02:57,021 --> 00:03:01,510
we would argue about religion and in
these sorts of things, right and wrong,

53
00:03:01,780 --> 00:03:05,020
the economy.
And when I got a little bit older,

54
00:03:05,021 --> 00:03:08,110
I started reading things in
philosophy and economics, columns,

55
00:03:08,111 --> 00:03:09,490
articles and things like that.

56
00:03:09,880 --> 00:03:14,650
And I realized that there was this kind
of formal discipline called philosophy

57
00:03:14,651 --> 00:03:17,800
where you could argue about right
and wrong and justice and injustice.

58
00:03:18,100 --> 00:03:20,450
And if you were very lucky you
could get a job doing this.

59
00:03:20,770 --> 00:03:24,520
If I get paid to do this,
not a lot. Not a lot of jobs,

60
00:03:24,521 --> 00:03:27,160
not paid very much either, but
it's kind of like saying, you know,

61
00:03:27,161 --> 00:03:29,610
you can get paid to eat ice cream for
a living. I thought, okay, that's,

62
00:03:29,700 --> 00:03:31,150
that's a pretty good gig if I can get it.

63
00:03:31,151 --> 00:03:34,840
And so that was kind of the start
of the trajectory into philosophy.

64
00:03:34,910 --> 00:03:35,421
Yeah.
You know,

65
00:03:35,421 --> 00:03:38,750
it's interesting because I came from a
very similar family in that regard where

66
00:03:38,751 --> 00:03:43,520
we argued about everything from economics
and religion and all of those things.

67
00:03:43,521 --> 00:03:46,850
And I guess perhaps if
this is what led you here,

68
00:03:46,851 --> 00:03:50,300
it's kind of what led me here as well.
But we're missing that these days.

69
00:03:50,301 --> 00:03:53,330
Don't you think like that must infuriate
you as someone that cares about ideas.

70
00:03:53,331 --> 00:03:56,310
When you watch the news and
watch all these people that are,

71
00:03:56,390 --> 00:04:00,200
aren't arguing from like a principal
position or something like a,

72
00:04:00,201 --> 00:04:01,880
a philosophically thought out position,

73
00:04:01,881 --> 00:04:05,660
but just from like a party place or
a partisan plays must drive you nuts.

74
00:04:05,720 --> 00:04:08,450
It does. It does because
right. I care about ideas.

75
00:04:08,451 --> 00:04:10,610
I care fundamentally about good arguments.

76
00:04:10,760 --> 00:04:15,440
So this is something that I hope happens
to my students in my classes is they

77
00:04:15,441 --> 00:04:18,470
come in with a set of
preconceptions. They have, you know,

78
00:04:18,471 --> 00:04:20,570
their partisan political beliefs.
Everybody does.

79
00:04:20,571 --> 00:04:21,950
I have my partisan political beliefs,

80
00:04:22,220 --> 00:04:26,960
but I hope we can try as hard as we
can to just focus on the arguments then

81
00:04:26,961 --> 00:04:31,610
critically and maybe change our minds
even if it means admitting that we were

82
00:04:31,611 --> 00:04:34,070
wrong or uh,
you know,

83
00:04:34,071 --> 00:04:36,680
finding out that we have different
political or religious beliefs from our

84
00:04:36,681 --> 00:04:39,830
friends. We should really just follow
wherever the arguments lead us.

85
00:04:40,150 --> 00:04:42,730
I actually like it when you find
out you were wrong on something.

86
00:04:42,731 --> 00:04:44,990
Cause when I've had the
moment on this show and the,

87
00:04:44,991 --> 00:04:47,410
and the most famous one is
when I had Larry elder in here.

88
00:04:47,411 --> 00:04:51,490
And he just kind of beat me senseless
with facts and we've since become friends

89
00:04:51,491 --> 00:04:56,470
and he was on just recently. And I loved
the guy that it was scary in the moment.

90
00:04:56,500 --> 00:04:59,200
Like sitting there in the moment
of being beaten is not fun,

91
00:04:59,500 --> 00:05:03,070
but afterwards when you go,
Whoa, that's what it's about.

92
00:05:03,071 --> 00:05:04,120
It's actually pretty cool.

93
00:05:04,510 --> 00:05:08,740
Yes. So I don't like, like you said in the
moment, I don't like being burdened by,

94
00:05:08,750 --> 00:05:12,430
cause I got a couple of things I'm going
to play pretty good. Nothing was, yeah,

95
00:05:13,060 --> 00:05:15,940
yeah. But, but long term, I think
that's right. It shows growth.

96
00:05:15,970 --> 00:05:20,230
And the funny thing is that what are we
afraid of when it comes to changing our

97
00:05:20,231 --> 00:05:23,440
minds and admitting when we're wrong?
What's really the harm in that?

98
00:05:23,620 --> 00:05:27,220
And I really, I like the process
of arguing it's, you know,

99
00:05:27,221 --> 00:05:31,360
a form of recreation or something,
like a form of exercise. Um, I think,

100
00:05:31,630 --> 00:05:33,430
I think it was Edmund Burke
who said something like,

101
00:05:33,431 --> 00:05:36,520
the person who challenged my
adversary is actually my best friend,

102
00:05:36,521 --> 00:05:37,221
or something like that.

103
00:05:37,221 --> 00:05:41,590
So the person that is willing to argue
with you in good faith and genuinely

104
00:05:41,591 --> 00:05:46,591
cares about getting at what's true rather
than what maybe confirms their prior

105
00:05:46,931 --> 00:05:48,430
political beliefs, that's, you know,

106
00:05:48,460 --> 00:05:50,890
that's the person that I want to hang
out with us. First. I want to talk with

107
00:05:51,010 --> 00:05:54,460
one of my best friends growing
up. Uh, his name is Arie Greek.

108
00:05:54,550 --> 00:05:56,380
So he was willing to Greek
philosophy and all that,

109
00:05:56,381 --> 00:05:59,150
and he was my sparring
partner for them from,

110
00:05:59,300 --> 00:06:03,560
from literally from 12 years old
until, well past college. Even now.

111
00:06:03,561 --> 00:06:06,920
And we ironically, we actually
agree more now than ever before,

112
00:06:06,921 --> 00:06:10,150
which is sort of weird because
we both had sort of reverse, uh,

113
00:06:10,390 --> 00:06:12,530
philosophical journeys
or political journeys,

114
00:06:12,531 --> 00:06:14,720
but that's actually what it's all about.

115
00:06:14,721 --> 00:06:17,750
So tell me a little bit about some of
the philosophers that have affected you.

116
00:06:18,740 --> 00:06:21,080
So one of my favorites is
probably John Stuart Mill.

117
00:06:21,260 --> 00:06:24,350
So he was a classical liberal. He, uh,

118
00:06:24,440 --> 00:06:26,330
so here's what's known as a utilitarian,

119
00:06:26,510 --> 00:06:30,200
and this is a moral theory
that essentially says the
right thing to do is the

120
00:06:30,201 --> 00:06:32,180
thing that has the best consequences.

121
00:06:32,181 --> 00:06:35,090
I think that produces the most
happiness for everybody who's affected.

122
00:06:35,240 --> 00:06:38,960
I find that view attractive and
moral philosophy. But he was also,

123
00:06:39,050 --> 00:06:43,640
he was a classical liberal politically.
Uh, he was a big defender of free speech,

124
00:06:43,830 --> 00:06:46,270
a free discussion in particular.
His book on

125
00:06:46,370 --> 00:06:49,970
Brady is probably the single greatest
defense of freedom of speech.

126
00:06:50,060 --> 00:06:52,580
I travel with it, you know, I'm on
tour right now. I travel with it.

127
00:06:52,581 --> 00:06:55,810
It's a thin book. Everyone should
have it under your pillow. But yeah,

128
00:06:55,820 --> 00:06:59,780
that's about it. Yeah, that's
right. Yeah. So what, okay,

129
00:06:59,781 --> 00:07:02,510
so you mentioned classical liberalism.
Okay. Everyone knows my feelings on this.

130
00:07:02,511 --> 00:07:06,020
Do you see any meaningful distinction
between classical liberalism and

131
00:07:06,021 --> 00:07:07,730
libertarianism at this point?

132
00:07:09,380 --> 00:07:14,380
I think that libertarianism is
probably a bit narrower than classical

133
00:07:14,481 --> 00:07:17,150
liberalism. So, but this
is a matter of debate.

134
00:07:17,151 --> 00:07:20,120
I don't have a very firm opinion on this,
but when I think of a libertarian,

135
00:07:20,121 --> 00:07:24,860
I think of somebody who says the state
should do the following three things,

136
00:07:25,070 --> 00:07:29,360
have a court system,
have police force, um,

137
00:07:29,870 --> 00:07:33,110
and maybe enforced contracts,
something like that, no more,

138
00:07:33,111 --> 00:07:36,280
maybe some kind of very
small social minimum, uh,

139
00:07:36,320 --> 00:07:38,510
Milton Friedman negative
income tax type thing.

140
00:07:38,840 --> 00:07:43,610
Whereas I think classical liberals are
more friendly to a, a more active state.

141
00:07:43,760 --> 00:07:47,090
But I would also say that I'm happy to
say that Libertarians are a part of the

142
00:07:47,091 --> 00:07:48,650
classical liberal family.

143
00:07:48,770 --> 00:07:50,950
Yeah. It's funny because, uh,

144
00:07:50,980 --> 00:07:55,250
I had done Boudreaux and here are a couple
of weeks ago talking about this and I

145
00:07:55,251 --> 00:07:59,740
fall on that path where the more I go down
the libertarian roots, I really liked.

146
00:07:59,750 --> 00:08:03,500
I like that line of thinking. I still
think there's some utility of the state,

147
00:08:03,770 --> 00:08:07,340
but I think the more that you
have these conversations, for me,

148
00:08:07,341 --> 00:08:10,820
I'm finding it harder and harder to
defend anything related to the state.

149
00:08:10,821 --> 00:08:11,654
Which is it,

150
00:08:11,870 --> 00:08:15,580
I guess I'm taking a philosophically fair
approach to this because I'm taking in

151
00:08:15,581 --> 00:08:16,330
new information.

152
00:08:16,330 --> 00:08:21,020
Yeah. Yeah. I, I'm, I'm the
same way. So I think that the,

153
00:08:21,030 --> 00:08:25,750
the best arguments for something like
classical liberalism or libertarianism is

154
00:08:25,751 --> 00:08:29,020
just the pervasiveness of
government failure. So, you know,

155
00:08:29,021 --> 00:08:33,010
you look at where actual government
money goes, not just not in theory,

156
00:08:33,011 --> 00:08:35,290
but in practice where it goes,
um,

157
00:08:35,440 --> 00:08:38,680
what sorts of groups are advantaged
and disadvantaged by the state?

158
00:08:38,760 --> 00:08:41,770
I think that the government
just doesn't work very well.

159
00:08:41,950 --> 00:08:45,370
And so the same reasons why we don't
want the government producing food,

160
00:08:45,371 --> 00:08:46,210
for example,

161
00:08:46,590 --> 00:08:49,720
are also reasons why we might not want
the government and the business of say,

162
00:08:49,721 --> 00:08:50,554
running schools fools.

163
00:08:50,680 --> 00:08:53,530
Right. So do you think it would be
fair to say that if it ran well,

164
00:08:53,560 --> 00:08:56,040
if this thing was a slim operation

165
00:08:56,040 --> 00:09:00,150
and it was financially sensible and we
had people of good moral character in the

166
00:09:00,151 --> 00:09:01,110
government and the rest of it,

167
00:09:01,410 --> 00:09:04,350
but you'd actually have no reason to be
certainly a libertarian and meet perhaps

168
00:09:04,351 --> 00:09:05,190
even a classical liberal,

169
00:09:05,191 --> 00:09:09,690
you might actually be more of some sort
of big government democrat or something

170
00:09:09,691 --> 00:09:13,440
like that. I think that's right. At
least from my perspective. So, as I said,

171
00:09:13,441 --> 00:09:15,420
I'm a fan of mill and utilitarianism.

172
00:09:15,421 --> 00:09:18,360
The idea that the right thing is the
thing that produces the best results.

173
00:09:18,690 --> 00:09:23,670
And so I think in a world in which the
state was run by angels, very wise people,

174
00:09:23,671 --> 00:09:25,860
very benevolent people,
and it produced good results.

175
00:09:26,160 --> 00:09:28,400
I would be happy to accept a,

176
00:09:28,450 --> 00:09:31,710
a big activist government or
regulatory and redistributive state.

177
00:09:31,890 --> 00:09:35,190
But I think that are very powerful
reasons for thinking that that's not the

178
00:09:35,191 --> 00:09:38,280
world that we live in.
So I think that some of my audience,

179
00:09:38,281 --> 00:09:41,670
when they hear you talk about mail
and what's what's best for everyone,

180
00:09:41,671 --> 00:09:44,820
they're going to view that through
some sort of lens of collectivism,

181
00:09:44,821 --> 00:09:48,480
which is going to set some bells off. So
can you unpack that a little bit? Right?

182
00:09:48,780 --> 00:09:51,810
Yeah. So, so for, for what it's worth,

183
00:09:51,840 --> 00:09:56,520
my view is that a system that produces
the most happiness, the most flourishing,

184
00:09:56,521 --> 00:10:00,090
the most prosperity is something
like a libertarian, minimal state,

185
00:10:00,091 --> 00:10:02,190
perhaps with a,
a small social minimum.

186
00:10:02,520 --> 00:10:06,810
So when you look historically
at collectivist regimes,

187
00:10:06,870 --> 00:10:09,780
say the Soviet Union or North
Korea or something like that,

188
00:10:09,960 --> 00:10:12,900
these don't have a good track
record of making people happy.

189
00:10:13,050 --> 00:10:17,550
When you look at the societies that
actually make people happy compared to the

190
00:10:17,551 --> 00:10:22,170
alternatives, they tend to be a
limited government free market,

191
00:10:22,250 --> 00:10:25,830
a civil libertarian ish kind of states.
All right.

192
00:10:25,831 --> 00:10:29,850
So what other philosophers that's
affected you? You're one for one. Yeah,

193
00:10:30,240 --> 00:10:33,270
John Stuart Mill. Right up the top. I'll
give you somebody who you might not like,

194
00:10:33,271 --> 00:10:34,470
although we might not
be familiar with them.

195
00:10:34,740 --> 00:10:39,540
Peter Singer who is a contemporary
utilitarian and a lot of people,

196
00:10:39,670 --> 00:10:43,200
I think a lot of classical
liberals and Libertarians, uh,

197
00:10:43,470 --> 00:10:48,450
aren't big fans of his, although I
think they need not, not be fans of his.

198
00:10:48,690 --> 00:10:50,850
So he's uh,
he's famous for a number of things.

199
00:10:50,851 --> 00:10:54,610
He has a number of very controversial
positions on a lot of things. Um,

200
00:10:54,870 --> 00:10:59,700
but one of his more famous thought
experiments involves you imagining that

201
00:10:59,710 --> 00:11:04,380
you're a walking somewhere and you
pass a small child who's drowning in a

202
00:11:04,381 --> 00:11:08,970
shallow pond and you can save this
child at a very low cost to you all.

203
00:11:08,980 --> 00:11:12,640
All that's required is that you step
into the pond to get your shoes muddy and

204
00:11:12,660 --> 00:11:13,530
pull the child out.

205
00:11:13,530 --> 00:11:16,350
But this means you'll have to spend
that at all 100 bucks on new shoes.

206
00:11:16,770 --> 00:11:17,131
And he says,

207
00:11:17,131 --> 00:11:22,110
clearly the sacrifice of $100 worth
of shoes is worth saving this child.

208
00:11:22,410 --> 00:11:25,720
And so this suggests that we
have strong obligations, uh,

209
00:11:25,740 --> 00:11:28,410
to make personal sacrifices for
the betterment of the world's poor.

210
00:11:28,490 --> 00:11:32,490
And I think that's right, uh, as at the
level of moral principle, for example.

211
00:11:32,580 --> 00:11:36,810
But I think a lot of libertarians and
classical liberals worry that what this is

212
00:11:36,811 --> 00:11:40,710
going to mean is we ought to
have large welfare states.

213
00:11:40,711 --> 00:11:44,940
We ought to have billions of dollars
channeled into foreign aid and so on.

214
00:11:44,941 --> 00:11:48,600
And I can understand why they make that
leap, but I don't think that follows,

215
00:11:48,601 --> 00:11:49,321
especially again,

216
00:11:49,321 --> 00:11:52,980
if you look at the track record of whether
or not the government does a good job

217
00:11:52,990 --> 00:11:55,800
of helping the poor and I think
it generally doesn't. Yeah. So,

218
00:11:55,801 --> 00:11:57,790
and I definitely want to get
to your thoughts on that.

219
00:11:57,790 --> 00:12:01,210
So do you view that sort of is like
that sort of like a micro macro argument

220
00:12:01,211 --> 00:12:03,760
that at a micro level,
yeah, you'd probably do it.

221
00:12:03,761 --> 00:12:05,830
Like I'm sure if either one of
us were walking down the street,

222
00:12:06,160 --> 00:12:08,740
we wouldn't care that much about
our shoes enabled to save somebody.

223
00:12:08,741 --> 00:12:12,610
But at a societal level we'd probably
gets to a lot of your economic arguments

224
00:12:12,611 --> 00:12:15,070
as well. The more that you
keep giving over to society,

225
00:12:15,071 --> 00:12:20,071
the more that it keeps taking in essence
individuals in their private lives.

226
00:12:21,670 --> 00:12:21,940
Uh,

227
00:12:21,940 --> 00:12:25,330
if they do a good job of saying when you
searching which private charities do a

228
00:12:25,331 --> 00:12:27,940
good job of alleviating poverty
in the developing worlds.

229
00:12:27,941 --> 00:12:28,960
And I think there are some,

230
00:12:29,290 --> 00:12:33,820
then we would have in some time in some
sense of societal obligation to help

231
00:12:34,200 --> 00:12:39,200
just in the sense that most people of
means have this obligation to say donate

232
00:12:39,671 --> 00:12:42,880
some of their paycheck to the against
malaria foundation, for example.

233
00:12:43,120 --> 00:12:47,620
But I think that doesn't justify saying
we want the state in the business of

234
00:12:47,621 --> 00:12:50,050
redistributing income,
uh,

235
00:12:50,200 --> 00:12:53,860
on a global level if only because it
just doesn't do a very good job of it and

236
00:12:53,861 --> 00:12:56,980
oftentimes makes poverty even worse.
All right,

237
00:12:56,981 --> 00:13:00,460
so you are a blogger at
bleeding heart libertarian. Yes.

238
00:13:01,180 --> 00:13:03,700
Now I've seen this site before and
I checked it out again before, uh,

239
00:13:03,730 --> 00:13:07,300
before you got here. I thought, all right,
the phrase bleeding heart, libertarians,

240
00:13:07,430 --> 00:13:10,600
that sorta sounds like what a
classical liberal is like, right?

241
00:13:10,601 --> 00:13:11,434
We've got a little,

242
00:13:11,470 --> 00:13:15,730
a little more heart in essence are we
were okay with a little more state to

243
00:13:15,731 --> 00:13:18,760
hopefully make sure that people
who need it the most are okay. Uh,

244
00:13:18,761 --> 00:13:21,850
but I think a lot of people will see
those terms at odds. Bleeding, heart,

245
00:13:21,851 --> 00:13:25,510
libertarian. Yeah. No, and that's
a great, uh, a great point too.

246
00:13:25,510 --> 00:13:29,200
In light of the conversation about Peter
Singer because I do think that we have,

247
00:13:29,201 --> 00:13:32,080
and I think a lot of classical
liberals agree that we have this strong

248
00:13:32,290 --> 00:13:37,290
obligation to uphold political
institutions that work
particularly well for the

249
00:13:37,841 --> 00:13:41,860
poor. And this isn't, even though the
term bleeding heart, libertarians is new.

250
00:13:42,040 --> 00:13:44,770
This isn't just something that popped
up in the last five or six years.

251
00:13:44,771 --> 00:13:47,700
If you go all the way back to Adam Smith,
he has this,

252
00:13:47,720 --> 00:13:52,480
this argument about the division of
Labor and free trade. He says, you know,

253
00:13:52,510 --> 00:13:55,690
you're sitting at your desk trying
to make pins all by yourself.

254
00:13:55,691 --> 00:13:57,280
Maybe you could do two or three in a day.

255
00:13:57,460 --> 00:14:01,330
You have a division of labor where one
person straightened up the wire or the

256
00:14:01,331 --> 00:14:03,760
other person's putting the pin on the,
on the wire and so forth,

257
00:14:03,970 --> 00:14:07,390
makes us massively more productive
than we otherwise could be.

258
00:14:07,540 --> 00:14:10,840
And then through free trade are,
everybody's welfare is increased,

259
00:14:11,110 --> 00:14:15,640
but he stresses that this is particularly
good for the poor because he says a

260
00:14:15,641 --> 00:14:19,750
society in which we're very productive
and we have this abundance of material

261
00:14:19,751 --> 00:14:23,470
goods is a society in which these sorts
of goods are going to be a lot cheaper.

262
00:14:23,471 --> 00:14:25,340
And this is in fact what we see.
Uh,

263
00:14:25,350 --> 00:14:29,590
and so a society in which the real
price of not just necessities,

264
00:14:29,591 --> 00:14:32,680
but also things that we might consider
luxuries like smartphones or something,

265
00:14:32,860 --> 00:14:36,340
a society that makes those abundant and
cheap as a society that's very good for

266
00:14:36,341 --> 00:14:37,150
the poor.

267
00:14:37,150 --> 00:14:41,470
So I think a bleeding heart libertarian
or classical perspective is hundreds of

268
00:14:41,470 --> 00:14:42,780
years old.
Although you probably,

269
00:14:43,030 --> 00:14:46,000
we haven't done a good job of
marketing ourselves, perhaps. Yeah.

270
00:14:46,180 --> 00:14:49,710
How would you actually
define what good is? I mean,

271
00:14:49,711 --> 00:14:53,540
I know that that's a tough
one. That's right. Yeah, that's
a, that's a big question.

272
00:14:53,750 --> 00:14:56,500
So here's the evasive answer is there,

273
00:14:56,501 --> 00:15:00,350
it depends on which philosopher you're
talking to. Right? So, yeah. So,

274
00:15:00,351 --> 00:15:02,210
so some philosophers think that,

275
00:15:02,290 --> 00:15:06,230
so mill has this view that the
could consists of pleasure,

276
00:15:06,260 --> 00:15:10,310
but it's a sophisticated view where some
pleasures are of higher quality than

277
00:15:10,311 --> 00:15:12,920
others. So if, I dunno,

278
00:15:13,040 --> 00:15:17,480
you have pleasure as a result of
shooting up heroin and that's equal in

279
00:15:17,481 --> 00:15:20,780
intensity and duration to the pleasure
that you get from reading Shakespeare.

280
00:15:20,990 --> 00:15:24,500
There's something qualitatively
better about the Shakespeare than,

281
00:15:24,530 --> 00:15:28,220
than the heroin. Um, and so that's his
view is that it's a life of pleasure.

282
00:15:28,221 --> 00:15:31,970
But where are you have these hot, higher
and lower pleasures? Other people,

283
00:15:31,971 --> 00:15:36,320
other utilitarians then, oh, pleasures
created equal. Other people have,

284
00:15:36,730 --> 00:15:41,540
uh, maybe more complicated views where
a bunch of stuff makes a life good.

285
00:15:41,930 --> 00:15:44,600
So it's pleasure,
it's knowledge,

286
00:15:44,630 --> 00:15:47,180
it's living a morally
virtuous life and so on.

287
00:15:47,450 --> 00:15:52,450
And this is a debate that we've been
having for 208 or 2,500 years with no end

288
00:15:53,931 --> 00:15:56,270
in sight. I sense, I know
where you stand on that,

289
00:15:56,271 --> 00:16:00,260
but you want to elaborate on that a little
bit more? Well, so I think that the,

290
00:16:00,470 --> 00:16:04,910
yeah, so it's a good question.
Yeah, no, as long as I'm
here. So what, what is good?

291
00:16:05,210 --> 00:16:09,700
Well, so I think the good for a
particular person is probably, um,

292
00:16:10,010 --> 00:16:13,520
what a philosopher would call the
satisfaction of your informed preferences.

293
00:16:13,760 --> 00:16:18,470
So essentially getting what you want, if
you know what it is that you're getting.

294
00:16:18,471 --> 00:16:19,490
So for example,

295
00:16:19,700 --> 00:16:24,320
you might want the liquid that is in
our glass right now because you have the

296
00:16:24,321 --> 00:16:26,810
belief that it's water.
But if you have the fall,

297
00:16:26,840 --> 00:16:29,780
if that belief is false because it turns
out to be vodka or something like that,

298
00:16:29,781 --> 00:16:31,280
you might have a desire
for what's in there.

299
00:16:31,490 --> 00:16:34,790
But the desire is in some sense
informed by this false belief.

300
00:16:34,910 --> 00:16:39,130
But if you have perfectly true beliefs
about the world and then you desired, uh,

301
00:16:39,170 --> 00:16:41,810
say that cup of water, I said, well
that's good for you to get that water.

302
00:16:41,811 --> 00:16:43,340
You're getting what you want.
Yeah.

303
00:16:43,580 --> 00:16:47,870
So you basically believe
that selfishness is good? No,

304
00:16:47,871 --> 00:16:49,580
because I think that a lot of people,

305
00:16:49,581 --> 00:16:52,760
I think most people in
fact have preferences,

306
00:16:53,120 --> 00:16:57,590
rational preferences for the welfare of
other people. So I would say, you know,

307
00:16:57,591 --> 00:16:59,720
most can you make it a
selfish argument for that?

308
00:17:00,080 --> 00:17:01,610
Because the way I've
always sort of understand,

309
00:17:01,611 --> 00:17:05,910
or at least the way I use these words
now is that by doing what is good for me,

310
00:17:05,911 --> 00:17:09,200
I, that doesn't mean I want to
ransack the entire world, right?

311
00:17:09,230 --> 00:17:12,470
I want to do good so that
it's good for my community.

312
00:17:12,471 --> 00:17:15,560
I want to take care of my own
house so that my neighbor,

313
00:17:15,561 --> 00:17:16,610
hopefully it will be like I,

314
00:17:16,630 --> 00:17:19,250
I'm next door to someone with a nice
house and you're going to take care of

315
00:17:19,251 --> 00:17:20,750
their eyes.
So I view selfish.

316
00:17:20,820 --> 00:17:23,630
I guess that's a little more of an
ran thing where I've used selfishness

317
00:17:23,870 --> 00:17:25,970
actually as a virtue.
Yeah.

318
00:17:25,971 --> 00:17:29,420
So I think the difference would be in
at say a case where you're, you're, uh,

319
00:17:29,480 --> 00:17:33,650
walking and see the child drowning in
the shallow pond, the question would be,

320
00:17:33,651 --> 00:17:37,640
well, what is the reason why you're saving
this child and, and ruining your boots?

321
00:17:37,641 --> 00:17:39,560
I think a good answer to that as well,

322
00:17:39,561 --> 00:17:41,930
because they care about
the child's welfare. Um,

323
00:17:41,960 --> 00:17:44,780
and then sometimes it's true that
that's a preference that you have.

324
00:17:44,900 --> 00:17:47,840
So it's your preference until you
could call it a sort of, I don't know,

325
00:17:47,841 --> 00:17:49,800
self guided or self preference,

326
00:17:50,070 --> 00:17:54,720
but I wouldn't call it a
selfish preference in the
sense that you expect in some

327
00:17:54,721 --> 00:17:55,780
sense,
uh,

328
00:17:55,830 --> 00:18:00,420
this child's welfare to directly
translate into benefits for you. Right.

329
00:18:00,421 --> 00:18:02,580
But you would feel good after I get it.

330
00:18:02,580 --> 00:18:05,410
Like you wouldn't if you'd be a pretty
twisted person if you were like, well,

331
00:18:05,730 --> 00:18:09,290
walking by like, well, how's that gonna
make me feel after low, you should,

332
00:18:09,291 --> 00:18:10,530
you should do what to write.

333
00:18:10,531 --> 00:18:14,760
But I know what's right can often
lead to all sorts of bad things. Um,

334
00:18:14,970 --> 00:18:18,210
but I think you could make a selfish
argument for that. Like, you know,

335
00:18:18,211 --> 00:18:20,550
that if you walk by a child that
you could easily help and you don't,

336
00:18:20,551 --> 00:18:25,170
you're going to feel shitty after if you
have any shred of conscious. Well, right.

337
00:18:25,190 --> 00:18:25,880
So I hope,
right.

338
00:18:25,880 --> 00:18:30,390
[inaudible] sociopaths I hope have
that have that sort of psychological

339
00:18:30,391 --> 00:18:32,540
disposition.
And as far as sort of ones.

340
00:18:32,560 --> 00:18:35,670
So I think also what morality is more
concerned with is not just the good of the

341
00:18:35,671 --> 00:18:37,410
individual,
but sort of the good of all.

342
00:18:37,560 --> 00:18:41,540
So I think sort of what the morally
right thing to do is figuring out that

343
00:18:41,541 --> 00:18:42,030
decision.

344
00:18:42,030 --> 00:18:45,600
So this is the kind of million utilitarian
view that the right thing to do is

345
00:18:45,601 --> 00:18:48,980
basically that which produces
the most good for everybody,

346
00:18:49,010 --> 00:18:52,620
not just an individual person. So
it could be in some cases that, uh,

347
00:18:52,860 --> 00:18:57,150
a person's individual good, uh,
comes apart from what's morally good.

348
00:18:57,151 --> 00:19:00,780
So you could imagine somebody who just
has no desire to help other people.

349
00:19:00,870 --> 00:19:03,510
I would still say they're doing something
morally wrong if they fell to help

350
00:19:03,511 --> 00:19:06,750
other people because they're not taking
that person's welfare into account.

351
00:19:06,810 --> 00:19:10,320
Right.
So where do you think morals come from?

352
00:19:10,500 --> 00:19:13,810
This has been an ongoing discussion
on this show between, you know,

353
00:19:13,830 --> 00:19:16,990
talking to Jordan Peters and adventure
peer and Sam Harris and Michael Shermer,

354
00:19:16,991 --> 00:19:20,160
Dennis Prager, and many others. And
there's sort of a religious argument.

355
00:19:20,161 --> 00:19:23,130
I think there's a secular argument for it.
Um,

356
00:19:23,131 --> 00:19:24,960
I think I'm somewhere in the middle.

357
00:19:24,961 --> 00:19:28,170
I think it's a really rich spot to figure
out what people think about things.

358
00:19:28,560 --> 00:19:31,760
Yeah. So that's, that's a,
that's a hard question. Uh,

359
00:19:31,860 --> 00:19:33,980
I'm not sure I have a
satisfying answer to that,

360
00:19:34,020 --> 00:19:36,600
but maybe in terms of
the religious question,

361
00:19:36,780 --> 00:19:39,450
there's this very old argument from
Plato at the Youth of flow dilemma.

362
00:19:39,451 --> 00:19:43,200
I'm not sure if that's ever popped up in
conversation, but the idea is basically,

363
00:19:43,640 --> 00:19:44,221
uh,
does,

364
00:19:44,221 --> 00:19:49,221
does God wills something because it's
pious independently of God's will or is it

365
00:19:49,231 --> 00:19:53,930
pious because God wills it and
Plato's view was, well, uh, it,

366
00:19:53,940 --> 00:19:58,080
it doesn't quite make sense to say that
it's pious just because God wills it.

367
00:19:58,260 --> 00:20:02,130
Because you could imagine as a thought
experiment that God willing all sorts of

368
00:20:02,160 --> 00:20:05,250
terrible things just as, as a
thought experiment that, you know,

369
00:20:05,460 --> 00:20:10,050
if God wills us to torture it doesn't
seem like that would make torture good.

370
00:20:10,440 --> 00:20:14,450
Um, and so it seems more
plausible to think that, uh,

371
00:20:14,520 --> 00:20:17,700
there is sort of an independent
standard of goodness. Even,

372
00:20:17,730 --> 00:20:19,590
even if you are a theist,
for example,

373
00:20:19,680 --> 00:20:22,890
and you believe in God and you believe
God has this intimate connection to

374
00:20:22,891 --> 00:20:27,130
morality, I think even on views like
that, it makes sense to say that, um,

375
00:20:27,210 --> 00:20:30,600
goodness is in some sense
independent of the will of God.

376
00:20:30,930 --> 00:20:35,370
And so in terms of what more,
that's again, sort of an
evasive answer as to what,

377
00:20:35,371 --> 00:20:39,870
it's not a, where morality comes from.
I mean, I'm inclined to say, I mean,

378
00:20:39,871 --> 00:20:44,370
it comes from sort of what's good for
human beings and maybe other sentient

379
00:20:44,371 --> 00:20:48,280
animals. So what sorts of things satisfy
or interest satisfy our preferences,

380
00:20:48,281 --> 00:20:50,580
causes us pleasure and pain,
these sorts of things.

381
00:20:50,610 --> 00:20:52,170
Do you think that subjective though,

382
00:20:52,230 --> 00:20:56,590
that different cultures obviously have
different beliefs in different, you know,

383
00:20:56,790 --> 00:20:58,170
moralities and all sorts of things?

384
00:20:58,540 --> 00:21:03,310
I would say it is not subjective
in the, in the sense that, uh,

385
00:21:03,640 --> 00:21:04,473
different,

386
00:21:04,540 --> 00:21:08,680
different cultures having different moral
beliefs would show that nobody's wrong

387
00:21:08,710 --> 00:21:11,680
in those debates. So it might be very
difficult to determine who is wrong,

388
00:21:11,860 --> 00:21:15,100
but I don't think the mere fact that
different cultures have moral standards

389
00:21:15,280 --> 00:21:18,760
shows that it's subjective.
So by analogy, uh,

390
00:21:18,940 --> 00:21:22,960
you could imagine different cultures
having different beliefs about astrology,

391
00:21:22,961 --> 00:21:23,531
for example.

392
00:21:23,531 --> 00:21:26,890
So some cultures think that astrology
is legitimate enterprise are the ones,

393
00:21:26,891 --> 00:21:28,810
don't they disagree about that?

394
00:21:28,900 --> 00:21:32,710
But I think it's safe to say that there
is in some sense and objectively correct

395
00:21:32,711 --> 00:21:37,030
answer about that. Uh, same thing with
other sorts of scientific disputes. Right?

396
00:21:37,100 --> 00:21:38,980
But do you think that
that objective place,

397
00:21:38,981 --> 00:21:43,430
does that have to come from God per
say? Or can it come from, I mean, the,

398
00:21:43,431 --> 00:21:45,830
the discussion that we've had a lot around
here and that a lot of people in this

399
00:21:45,831 --> 00:21:50,831
space talk about basically
is does objective morality
either come from God and

400
00:21:51,201 --> 00:21:54,320
religion or does it come
from enlightenment values?

401
00:21:54,530 --> 00:21:58,790
And then there's other arguments that
it's only through religion that we got to

402
00:21:58,791 --> 00:22:00,440
enlightenment values in the first.

403
00:22:01,400 --> 00:22:02,960
Yeah,
that's tough.

404
00:22:03,480 --> 00:22:08,140
My hunch is that something like
enlightenment values. Um, so I,

405
00:22:08,141 --> 00:22:12,770
I don't know, I'm somewhere in the
agnostic space, uh, myself. Uh,

406
00:22:13,250 --> 00:22:17,090
and so I think that sort of philosophy
guy, right, exactly. So it's hard not to,

407
00:22:17,091 --> 00:22:20,990
it's, it's hard not to be an
agnostic. So yeah. So I'm agnostic,

408
00:22:20,991 --> 00:22:25,310
but I'm also Jewish. And so there's,
it's all part of the kind of questioning,

409
00:22:25,311 --> 00:22:27,590
lack of certainty and so forth.
Um,

410
00:22:27,890 --> 00:22:32,360
so I think that there is that there's
enough reason to think that we have

411
00:22:32,361 --> 00:22:36,830
objective morality, even if you're not
certain about the existence of God. Um,

412
00:22:36,890 --> 00:22:37,641
that,
yeah,

413
00:22:37,641 --> 00:22:42,470
we shouldn't worry that morality is going
to collapse if people become atheist

414
00:22:42,471 --> 00:22:43,020
and agnostic.

415
00:22:43,020 --> 00:22:46,290
Right? Because when I've
had this discussion, usually
with conservatives, you know,

416
00:22:46,291 --> 00:22:49,620
they love to say, well, God gave
us morality. You know what I mean?

417
00:22:49,621 --> 00:22:53,100
Your rights come from God. And for
me it's like, I think you have,

418
00:22:53,580 --> 00:22:55,890
whether they're god,
the God given rights,

419
00:22:55,920 --> 00:23:00,180
or it's your right freedom is your right
as a human being or as optimus prime

420
00:23:00,181 --> 00:23:03,870
said, freedom is the right of all
sentient beings. You don't even like,

421
00:23:03,871 --> 00:23:05,970
I think you are born free.
I just think that's a,

422
00:23:06,150 --> 00:23:08,170
that's a humanistic approach
or you're born free.

423
00:23:08,171 --> 00:23:11,280
The government can take away your freedom,
but it doesn't give it to you.

424
00:23:11,610 --> 00:23:14,970
And I think that's just a
really interesting place to
go for all these political

425
00:23:14,971 --> 00:23:15,390
discussions.

426
00:23:15,390 --> 00:23:16,230
I agree.

427
00:23:16,231 --> 00:23:19,350
So I that that's what I think that there
are no right and wrong ways to treat

428
00:23:19,351 --> 00:23:23,790
other human beings that are just true
independently of whether or not the state

429
00:23:23,791 --> 00:23:27,120
happens to respect them. And as soon
as the kind of enlightenment thought,

430
00:23:27,121 --> 00:23:29,160
so John Locke's,
I'd look in the state of nature,

431
00:23:29,490 --> 00:23:33,720
I would be wrong to kill you or
assault you or steal your property.

432
00:23:33,870 --> 00:23:35,790
This is just the wrong
way to treat human beings.

433
00:23:35,791 --> 00:23:37,620
It doesn't really have
anything to do with the state.

434
00:23:37,800 --> 00:23:41,000
Now he might want the state to
come in and protect those rights,

435
00:23:41,001 --> 00:23:43,650
enforce those rights and so on.
But the rights of themselves,

436
00:23:43,860 --> 00:23:47,030
the standard of the right and wrong way
to treat other people does not itself

437
00:23:47,031 --> 00:23:50,030
come from the state. So before
we get into some of your, your,

438
00:23:50,031 --> 00:23:52,310
the specific arguments that you
make on economics into a budget,

439
00:23:52,340 --> 00:23:56,360
how do you think are our founders
got so much of this stuff right?

440
00:23:56,420 --> 00:23:58,580
If I'm going on the assumption
you believe they did,

441
00:23:58,910 --> 00:24:02,990
but I mean every time I go to DC and I
go to the monuments and I read all of

442
00:24:02,991 --> 00:24:05,660
this stuff and I just
was in Philly yesterday,

443
00:24:05,661 --> 00:24:08,510
I mentioned to you and I have now
a copy of the I that little copy,

444
00:24:08,520 --> 00:24:11,960
like an old Republican senator of the
declaration and the Declaration of

445
00:24:11,961 --> 00:24:15,280
independence had gone off the alarm at
the, there was this thing with like,

446
00:24:15,310 --> 00:24:18,980
it would set off the Tsa alarms at
the, Oh, this one's just standard,

447
00:24:19,220 --> 00:24:22,220
simple paper or whatever. It's probably,
we'll set up some alarm somewhere.

448
00:24:22,221 --> 00:24:26,040
I'm sure. Um, if I go to San Francisco
or something, I'm sure a constitution,

449
00:24:26,041 --> 00:24:28,820
it would set off an alarm. But, um, uh,

450
00:24:29,030 --> 00:24:31,970
I assume you think that they got
a much of this stuff correctly.

451
00:24:31,971 --> 00:24:36,830
How do you think they, they did it?
Yeah, so I think that, I don't know.

452
00:24:36,831 --> 00:24:39,560
So I think that some of it,
and this is a bit outside of my own area,

453
00:24:39,561 --> 00:24:43,490
but I think that a lot of them were
influenced by a smart philosophers.

454
00:24:43,491 --> 00:24:45,020
People like,
so I think the law,

455
00:24:45,050 --> 00:24:48,590
the influence of someone like lock on
the constitution is pretty evident.

456
00:24:49,010 --> 00:24:53,810
The influence of somebody like David
Hume on, uh, people like, uh, Madison.

457
00:24:53,811 --> 00:24:56,480
I think that's, I think that maybe that's
a matter of controversy and history,

458
00:24:56,481 --> 00:24:58,220
but I think there's some
evidence to suggest that.

459
00:24:58,610 --> 00:25:02,570
So I think that they were students
of history students, a philosophy,

460
00:25:02,571 --> 00:25:05,750
students of economics, and this helped
them get a lot. Right. And I think I,

461
00:25:05,840 --> 00:25:06,050
you know,

462
00:25:06,050 --> 00:25:09,260
obviously I think there were mistakes
and the way that they applied it and, um,

463
00:25:09,320 --> 00:25:12,650
you know, the way that,
uh, like Jefferson's, uh,

464
00:25:12,770 --> 00:25:15,380
omission of mentions of
slavery and things like that.

465
00:25:15,381 --> 00:25:17,510
But I think in terms of
like the fundamentals,

466
00:25:17,890 --> 00:25:22,890
a lot of that was informed by really
smart philosophers and economists.

