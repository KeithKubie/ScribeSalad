WEBVTT
Kind: captions
Language: en

00:00:02.800 --> 00:00:05.320 align:start position:0%
 
good<00:00:03.800><c> afternoon</c><00:00:04.040><c> everyone</c><00:00:04.670><c> thank</c><00:00:05.120><c> you</c><00:00:05.210><c> all</c>

00:00:05.320 --> 00:00:05.330 align:start position:0%
good afternoon everyone thank you all
 

00:00:05.330 --> 00:00:07.150 align:start position:0%
good afternoon everyone thank you all
for<00:00:05.479><c> joining</c><00:00:05.510><c> us</c><00:00:05.840><c> my</c><00:00:06.350><c> name</c><00:00:06.380><c> is</c><00:00:06.560><c> Alexandra</c>

00:00:07.150 --> 00:00:07.160 align:start position:0%
for joining us my name is Alexandra
 

00:00:07.160 --> 00:00:09.100 align:start position:0%
for joining us my name is Alexandra
Meany<00:00:07.399><c> and</c><00:00:07.640><c> one</c><00:00:08.120><c> of</c><00:00:08.210><c> the</c><00:00:08.299><c> course</c><00:00:08.510><c> organizers</c>

00:00:09.100 --> 00:00:09.110 align:start position:0%
Meany and one of the course organizers
 

00:00:09.110 --> 00:00:12.430 align:start position:0%
Meany and one of the course organizers
for<00:00:09.500><c> six</c><00:00:09.770><c> s-191</c><00:00:10.490><c> this</c><00:00:11.389><c> is</c><00:00:11.540><c> mi</c><00:00:11.780><c> t--'s</c><00:00:11.990><c> official</c>

00:00:12.430 --> 00:00:12.440 align:start position:0%
for six s-191 this is mi t--'s official
 

00:00:12.440 --> 00:00:14.230 align:start position:0%
for six s-191 this is mi t--'s official
course<00:00:12.679><c> on</c><00:00:13.009><c> introduction</c><00:00:13.580><c> to</c><00:00:13.820><c> deep</c><00:00:14.059><c> learning</c>

00:00:14.230 --> 00:00:14.240 align:start position:0%
course on introduction to deep learning
 

00:00:14.240 --> 00:00:16.929 align:start position:0%
course on introduction to deep learning
and<00:00:15.009><c> this</c><00:00:16.009><c> is</c><00:00:16.099><c> actually</c><00:00:16.340><c> the</c><00:00:16.460><c> third</c><00:00:16.490><c> year</c><00:00:16.910><c> that</c>

00:00:16.929 --> 00:00:16.939 align:start position:0%
and this is actually the third year that
 

00:00:16.939 --> 00:00:19.359 align:start position:0%
and this is actually the third year that
we're<00:00:17.210><c> offering</c><00:00:17.570><c> this</c><00:00:17.720><c> course</c><00:00:18.050><c> and</c><00:00:18.439><c> we've</c><00:00:19.220><c> got</c>

00:00:19.359 --> 00:00:19.369 align:start position:0%
we're offering this course and we've got
 

00:00:19.369 --> 00:00:20.650 align:start position:0%
we're offering this course and we've got
a<00:00:19.399><c> really</c><00:00:19.579><c> good</c><00:00:19.790><c> one</c><00:00:19.849><c> in</c><00:00:20.090><c> store</c><00:00:20.239><c> for</c><00:00:20.419><c> you</c><00:00:20.509><c> this</c>

00:00:20.650 --> 00:00:20.660 align:start position:0%
a really good one in store for you this
 

00:00:20.660 --> 00:00:22.900 align:start position:0%
a really good one in store for you this
year<00:00:20.930><c> with</c><00:00:21.050><c> a</c><00:00:21.079><c> lot</c><00:00:21.200><c> of</c><00:00:21.410><c> awesome</c><00:00:21.770><c> updates</c><00:00:22.189><c> so</c><00:00:22.880><c> I</c>

00:00:22.900 --> 00:00:22.910 align:start position:0%
year with a lot of awesome updates so I
 

00:00:22.910 --> 00:00:24.780 align:start position:0%
year with a lot of awesome updates so I
really<00:00:23.270><c> hope</c><00:00:23.419><c> that</c><00:00:23.450><c> you</c><00:00:23.720><c> enjoy</c><00:00:23.989><c> it</c>

00:00:24.780 --> 00:00:24.790 align:start position:0%
really hope that you enjoy it
 

00:00:24.790 --> 00:00:28.389 align:start position:0%
really hope that you enjoy it
so<00:00:25.790><c> what</c><00:00:26.300><c> is</c><00:00:26.419><c> this</c><00:00:26.540><c> course</c><00:00:26.779><c> all</c><00:00:27.140><c> about</c><00:00:27.380><c> this</c><00:00:28.220><c> is</c>

00:00:28.389 --> 00:00:28.399 align:start position:0%
so what is this course all about this is
 

00:00:28.399 --> 00:00:30.670 align:start position:0%
so what is this course all about this is
a<00:00:28.430><c> one-week</c><00:00:28.820><c> intensive</c><00:00:29.140><c> boot</c><00:00:30.140><c> camp</c><00:00:30.470><c> on</c>

00:00:30.670 --> 00:00:30.680 align:start position:0%
a one-week intensive boot camp on
 

00:00:30.680 --> 00:00:31.929 align:start position:0%
a one-week intensive boot camp on
everything<00:00:31.160><c> deep</c><00:00:31.399><c> learning</c>

00:00:31.929 --> 00:00:31.939 align:start position:0%
everything deep learning
 

00:00:31.939 --> 00:00:33.970 align:start position:0%
everything deep learning
you'll<00:00:32.599><c> get</c><00:00:32.750><c> up</c><00:00:32.989><c> close</c><00:00:33.200><c> and</c><00:00:33.230><c> personal</c><00:00:33.440><c> with</c>

00:00:33.970 --> 00:00:33.980 align:start position:0%
you'll get up close and personal with
 

00:00:33.980 --> 00:00:35.320 align:start position:0%
you'll get up close and personal with
some<00:00:34.160><c> of</c><00:00:34.280><c> the</c><00:00:34.370><c> foundations</c><00:00:34.970><c> of</c><00:00:35.180><c> the</c>

00:00:35.320 --> 00:00:35.330 align:start position:0%
some of the foundations of the
 

00:00:35.330 --> 00:00:37.360 align:start position:0%
some of the foundations of the
algorithms<00:00:35.840><c> driving</c><00:00:36.350><c> this</c><00:00:36.470><c> remarkable</c><00:00:37.040><c> field</c>

00:00:37.360 --> 00:00:37.370 align:start position:0%
algorithms driving this remarkable field
 

00:00:37.370 --> 00:00:39.730 align:start position:0%
algorithms driving this remarkable field
and<00:00:37.700><c> you'll</c><00:00:38.660><c> actually</c><00:00:38.840><c> learn</c><00:00:39.200><c> how</c><00:00:39.440><c> to</c><00:00:39.470><c> build</c>

00:00:39.730 --> 00:00:39.740 align:start position:0%
and you'll actually learn how to build
 

00:00:39.740 --> 00:00:42.220 align:start position:0%
and you'll actually learn how to build
some<00:00:40.400><c> intelligent</c><00:00:41.090><c> algorithms</c><00:00:41.630><c> capable</c><00:00:42.140><c> of</c>

00:00:42.220 --> 00:00:42.230 align:start position:0%
some intelligent algorithms capable of
 

00:00:42.230 --> 00:00:46.720 align:start position:0%
some intelligent algorithms capable of
solving<00:00:42.700><c> incredibly</c><00:00:43.700><c> complex</c><00:00:44.120><c> problems</c><00:00:45.730><c> so</c>

00:00:46.720 --> 00:00:46.730 align:start position:0%
solving incredibly complex problems so
 

00:00:46.730 --> 00:00:48.610 align:start position:0%
solving incredibly complex problems so
over<00:00:47.450><c> the</c><00:00:47.540><c> past</c><00:00:47.660><c> couple</c><00:00:47.900><c> years</c><00:00:48.050><c> deep</c><00:00:48.440><c> learning</c>

00:00:48.610 --> 00:00:48.620 align:start position:0%
over the past couple years deep learning
 

00:00:48.620 --> 00:00:51.120 align:start position:0%
over the past couple years deep learning
has<00:00:48.890><c> revolutionized</c><00:00:49.700><c> many</c><00:00:50.120><c> aspects</c><00:00:50.780><c> of</c>

00:00:51.120 --> 00:00:51.130 align:start position:0%
has revolutionized many aspects of
 

00:00:51.130 --> 00:00:53.860 align:start position:0%
has revolutionized many aspects of
research<00:00:52.130><c> and</c><00:00:52.579><c> industry</c><00:00:53.090><c> including</c><00:00:53.630><c> things</c>

00:00:53.860 --> 00:00:53.870 align:start position:0%
research and industry including things
 

00:00:53.870 --> 00:00:56.440 align:start position:0%
research and industry including things
like<00:00:53.989><c> autonomous</c><00:00:54.980><c> vehicles</c><00:00:55.370><c> medicine</c><00:00:56.300><c> and</c>

00:00:56.440 --> 00:00:56.450 align:start position:0%
like autonomous vehicles medicine and
 

00:00:56.450 --> 00:00:58.830 align:start position:0%
like autonomous vehicles medicine and
healthcare<00:00:57.370><c> reinforcement</c><00:00:58.370><c> learning</c>

00:00:58.830 --> 00:00:58.840 align:start position:0%
healthcare reinforcement learning
 

00:00:58.840 --> 00:01:02.410 align:start position:0%
healthcare reinforcement learning
generative<00:00:59.840><c> modeling</c><00:01:00.670><c> robotics</c><00:01:01.670><c> and</c><00:01:02.000><c> a</c><00:01:02.180><c> whole</c>

00:01:02.410 --> 00:01:02.420 align:start position:0%
generative modeling robotics and a whole
 

00:01:02.420 --> 00:01:05.020 align:start position:0%
generative modeling robotics and a whole
host<00:01:02.870><c> of</c><00:01:03.079><c> other</c><00:01:03.380><c> applications</c><00:01:04.159><c> like</c><00:01:04.519><c> natural</c>

00:01:05.020 --> 00:01:05.030 align:start position:0%
host of other applications like natural
 

00:01:05.030 --> 00:01:07.530 align:start position:0%
host of other applications like natural
language<00:01:05.269><c> processing</c><00:01:05.770><c> finance</c><00:01:06.770><c> and</c><00:01:07.040><c> security</c>

00:01:07.530 --> 00:01:07.540 align:start position:0%
language processing finance and security
 

00:01:07.540 --> 00:01:09.969 align:start position:0%
language processing finance and security
but<00:01:08.540><c> before</c><00:01:08.840><c> we</c><00:01:08.930><c> talk</c><00:01:09.110><c> about</c><00:01:09.140><c> that</c><00:01:09.530><c> I</c><00:01:09.560><c> think</c><00:01:09.710><c> we</c>

00:01:09.969 --> 00:01:09.979 align:start position:0%
but before we talk about that I think we
 

00:01:09.979 --> 00:01:11.469 align:start position:0%
but before we talk about that I think we
should<00:01:10.130><c> start</c><00:01:10.370><c> by</c><00:01:10.490><c> taking</c><00:01:10.790><c> a</c><00:01:10.820><c> step</c><00:01:11.000><c> back</c><00:01:11.270><c> and</c>

00:01:11.469 --> 00:01:11.479 align:start position:0%
should start by taking a step back and
 

00:01:11.479 --> 00:01:13.810 align:start position:0%
should start by taking a step back and
talking<00:01:11.720><c> about</c><00:01:11.930><c> something</c><00:01:12.560><c> at</c><00:01:13.250><c> the</c><00:01:13.550><c> core</c><00:01:13.790><c> of</c>

00:01:13.810 --> 00:01:13.820 align:start position:0%
talking about something at the core of
 

00:01:13.820 --> 00:01:16.240 align:start position:0%
talking about something at the core of
this<00:01:14.060><c> class</c><00:01:14.300><c> which</c><00:01:14.570><c> is</c><00:01:14.720><c> intelligence</c><00:01:15.409><c> what</c><00:01:16.130><c> is</c>

00:01:16.240 --> 00:01:16.250 align:start position:0%
this class which is intelligence what is
 

00:01:16.250 --> 00:01:19.090 align:start position:0%
this class which is intelligence what is
intelligence<00:01:16.990><c> well</c><00:01:17.990><c> I</c><00:01:18.290><c> like</c><00:01:18.770><c> to</c><00:01:18.799><c> define</c>

00:01:19.090 --> 00:01:19.100 align:start position:0%
intelligence well I like to define
 

00:01:19.100 --> 00:01:21.430 align:start position:0%
intelligence well I like to define
intelligence<00:01:19.430><c> as</c><00:01:20.000><c> the</c><00:01:20.659><c> ability</c><00:01:21.080><c> to</c><00:01:21.110><c> process</c>

00:01:21.430 --> 00:01:21.440 align:start position:0%
intelligence as the ability to process
 

00:01:21.440 --> 00:01:24.780 align:start position:0%
intelligence as the ability to process
information<00:01:22.030><c> to</c><00:01:23.030><c> inform</c><00:01:23.210><c> future</c><00:01:23.659><c> decisions</c>

00:01:24.780 --> 00:01:24.790 align:start position:0%
information to inform future decisions
 

00:01:24.790 --> 00:01:27.490 align:start position:0%
information to inform future decisions
the<00:01:25.790><c> field</c><00:01:26.030><c> of</c><00:01:26.180><c> artificial</c><00:01:26.600><c> intelligence</c><00:01:26.840><c> is</c>

00:01:27.490 --> 00:01:27.500 align:start position:0%
the field of artificial intelligence is
 

00:01:27.500 --> 00:01:29.860 align:start position:0%
the field of artificial intelligence is
actually<00:01:27.950><c> building</c><00:01:28.400><c> algorithms</c><00:01:29.030><c> artificial</c>

00:01:29.860 --> 00:01:29.870 align:start position:0%
actually building algorithms artificial
 

00:01:29.870 --> 00:01:31.410 align:start position:0%
actually building algorithms artificial
algorithms<00:01:30.380><c> to</c><00:01:30.530><c> do</c><00:01:30.650><c> exactly</c><00:01:30.920><c> that</c>

00:01:31.410 --> 00:01:31.420 align:start position:0%
algorithms to do exactly that
 

00:01:31.420 --> 00:01:34.480 align:start position:0%
algorithms to do exactly that
bit<00:01:32.420><c> process</c><00:01:33.229><c> information</c><00:01:33.409><c> to</c><00:01:34.100><c> inform</c><00:01:34.430><c> future</c>

00:01:34.480 --> 00:01:34.490 align:start position:0%
bit process information to inform future
 

00:01:34.490 --> 00:01:37.539 align:start position:0%
bit process information to inform future
predictions<00:01:35.240><c> now</c><00:01:36.159><c> machine</c><00:01:37.159><c> learning</c><00:01:37.490><c> is</c>

00:01:37.539 --> 00:01:37.549 align:start position:0%
predictions now machine learning is
 

00:01:37.549 --> 00:01:39.340 align:start position:0%
predictions now machine learning is
simply<00:01:37.850><c> a</c><00:01:37.880><c> subset</c><00:01:38.450><c> of</c><00:01:38.690><c> artificial</c>

00:01:39.340 --> 00:01:39.350 align:start position:0%
simply a subset of artificial
 

00:01:39.350 --> 00:01:41.710 align:start position:0%
simply a subset of artificial
intelligence<00:01:39.440><c> or</c><00:01:39.950><c> AI</c><00:01:40.240><c> that</c><00:01:41.240><c> actually</c><00:01:41.570><c> focuses</c>

00:01:41.710 --> 00:01:41.720 align:start position:0%
intelligence or AI that actually focuses
 

00:01:41.720 --> 00:01:45.280 align:start position:0%
intelligence or AI that actually focuses
on<00:01:42.290><c> teaching</c><00:01:42.560><c> an</c><00:01:42.799><c> algorithm</c><00:01:43.340><c> how</c><00:01:44.090><c> to</c><00:01:44.290><c> take</c>

00:01:45.280 --> 00:01:45.290 align:start position:0%
on teaching an algorithm how to take
 

00:01:45.290 --> 00:01:48.039 align:start position:0%
on teaching an algorithm how to take
information<00:01:45.950><c> and</c><00:01:46.420><c> do</c><00:01:47.420><c> this</c><00:01:47.570><c> without</c>

00:01:48.039 --> 00:01:48.049 align:start position:0%
information and do this without
 

00:01:48.049 --> 00:01:50.020 align:start position:0%
information and do this without
explicitly<00:01:48.530><c> being</c><00:01:48.770><c> told</c><00:01:49.070><c> the</c><00:01:49.400><c> sequence</c><00:01:49.880><c> of</c>

00:01:50.020 --> 00:01:50.030 align:start position:0%
explicitly being told the sequence of
 

00:01:50.030 --> 00:01:52.800 align:start position:0%
explicitly being told the sequence of
rules<00:01:50.240><c> but</c><00:01:50.840><c> instead</c><00:01:51.290><c> learn</c><00:01:51.710><c> the</c><00:01:52.040><c> sequence</c><00:01:52.400><c> of</c>

00:01:52.800 --> 00:01:52.810 align:start position:0%
rules but instead learn the sequence of
 

00:01:52.810 --> 00:01:56.740 align:start position:0%
rules but instead learn the sequence of
patterns<00:01:53.810><c> from</c><00:01:54.020><c> the</c><00:01:54.110><c> data</c><00:01:54.409><c> itself</c><00:01:55.750><c> deep</c>

00:01:56.740 --> 00:01:56.750 align:start position:0%
patterns from the data itself deep
 

00:01:56.750 --> 00:01:58.359 align:start position:0%
patterns from the data itself deep
learning<00:01:56.930><c> is</c><00:01:57.200><c> simply</c><00:01:57.500><c> a</c><00:01:57.560><c> subset</c><00:01:57.920><c> of</c><00:01:57.979><c> machine</c>

00:01:58.359 --> 00:01:58.369 align:start position:0%
learning is simply a subset of machine
 

00:01:58.369 --> 00:02:00.010 align:start position:0%
learning is simply a subset of machine
learning<00:01:58.490><c> which</c><00:01:58.790><c> takes</c><00:01:59.030><c> this</c><00:01:59.180><c> idea</c><00:01:59.509><c> one</c><00:01:59.780><c> step</c>

00:02:00.010 --> 00:02:00.020 align:start position:0%
learning which takes this idea one step
 

00:02:00.020 --> 00:02:02.320 align:start position:0%
learning which takes this idea one step
further<00:02:00.259><c> and</c><00:02:00.650><c> actually</c><00:02:01.369><c> tries</c><00:02:01.790><c> to</c><00:02:01.909><c> extract</c>

00:02:02.320 --> 00:02:02.330 align:start position:0%
further and actually tries to extract
 

00:02:02.330 --> 00:02:04.510 align:start position:0%
further and actually tries to extract
these<00:02:02.479><c> patterns</c><00:02:03.009><c> automatically</c><00:02:04.009><c> from</c><00:02:04.250><c> raw</c>

00:02:04.510 --> 00:02:04.520 align:start position:0%
these patterns automatically from raw
 

00:02:04.520 --> 00:02:07.510 align:start position:0%
these patterns automatically from raw
data<00:02:04.549><c> without</c><00:02:05.360><c> being</c><00:02:05.810><c> needed</c><00:02:06.170><c> without</c><00:02:07.100><c> the</c>

00:02:07.510 --> 00:02:07.520 align:start position:0%
data without being needed without the
 

00:02:07.520 --> 00:02:10.839 align:start position:0%
data without being needed without the
need<00:02:07.759><c> to</c><00:02:08.319><c> for</c><00:02:09.319><c> the</c><00:02:09.439><c> human</c><00:02:09.950><c> to</c><00:02:10.129><c> actually</c><00:02:10.579><c> come</c>

00:02:10.839 --> 00:02:10.849 align:start position:0%
need to for the human to actually come
 

00:02:10.849 --> 00:02:13.330 align:start position:0%
need to for the human to actually come
in<00:02:11.029><c> and</c><00:02:11.239><c> annotate</c><00:02:11.989><c> these</c><00:02:12.529><c> rules</c><00:02:12.919><c> that</c><00:02:13.219><c> the</c>

00:02:13.330 --> 00:02:13.340 align:start position:0%
in and annotate these rules that the
 

00:02:13.340 --> 00:02:14.809 align:start position:0%
in and annotate these rules that the
system<00:02:13.700><c> needs</c><00:02:13.819><c> to</c><00:02:13.999><c> learn</c>

00:02:14.809 --> 00:02:14.819 align:start position:0%
system needs to learn
 

00:02:14.819 --> 00:02:18.030 align:start position:0%
system needs to learn
and<00:02:16.080><c> that's</c><00:02:17.080><c> what</c><00:02:17.200><c> this</c><00:02:17.290><c> class</c><00:02:17.470><c> is</c><00:02:17.530><c> all</c><00:02:17.800><c> about</c>

00:02:18.030 --> 00:02:18.040 align:start position:0%
and that's what this class is all about
 

00:02:18.040 --> 00:02:20.309 align:start position:0%
and that's what this class is all about
teaching<00:02:18.790><c> algorithms</c><00:02:19.420><c> how</c><00:02:19.599><c> to</c><00:02:19.660><c> learn</c><00:02:19.930><c> a</c><00:02:19.959><c> task</c>

00:02:20.309 --> 00:02:20.319 align:start position:0%
teaching algorithms how to learn a task
 

00:02:20.319 --> 00:02:23.250 align:start position:0%
teaching algorithms how to learn a task
from<00:02:20.890><c> raw</c><00:02:21.190><c> data</c><00:02:21.489><c> we</c><00:02:22.420><c> want</c><00:02:22.630><c> to</c><00:02:22.660><c> provide</c><00:02:23.050><c> you</c>

00:02:23.250 --> 00:02:23.260 align:start position:0%
from raw data we want to provide you
 

00:02:23.260 --> 00:02:25.920 align:start position:0%
from raw data we want to provide you
with<00:02:23.290><c> a</c><00:02:23.470><c> solid</c><00:02:23.860><c> foundation</c><00:02:24.390><c> that</c><00:02:25.390><c> so</c><00:02:25.630><c> that</c><00:02:25.780><c> you</c>

00:02:25.920 --> 00:02:25.930 align:start position:0%
with a solid foundation that so that you
 

00:02:25.930 --> 00:02:27.240 align:start position:0%
with a solid foundation that so that you
can<00:02:25.959><c> learn</c><00:02:26.290><c> how</c><00:02:26.349><c> these</c><00:02:26.680><c> algorithms</c><00:02:26.980><c> work</c>

00:02:27.240 --> 00:02:27.250 align:start position:0%
can learn how these algorithms work
 

00:02:27.250 --> 00:02:29.820 align:start position:0%
can learn how these algorithms work
under<00:02:27.730><c> the</c><00:02:27.849><c> hood</c><00:02:27.880><c> and</c><00:02:28.180><c> with</c><00:02:29.140><c> the</c><00:02:29.290><c> practical</c>

00:02:29.820 --> 00:02:29.830 align:start position:0%
under the hood and with the practical
 

00:02:29.830 --> 00:02:30.809 align:start position:0%
under the hood and with the practical
skills<00:02:30.190><c> so</c><00:02:30.370><c> that</c><00:02:30.489><c> you</c><00:02:30.580><c> can</c><00:02:30.700><c> actually</c>

00:02:30.809 --> 00:02:30.819 align:start position:0%
skills so that you can actually
 

00:02:30.819 --> 00:02:32.900 align:start position:0%
skills so that you can actually
implement<00:02:31.150><c> these</c><00:02:31.480><c> algorithms</c><00:02:31.780><c> from</c><00:02:32.170><c> scratch</c>

00:02:32.900 --> 00:02:32.910 align:start position:0%
implement these algorithms from scratch
 

00:02:32.910 --> 00:02:35.220 align:start position:0%
implement these algorithms from scratch
using<00:02:33.910><c> deep</c><00:02:34.269><c> learning</c><00:02:34.420><c> frameworks</c><00:02:35.019><c> like</c>

00:02:35.220 --> 00:02:35.230 align:start position:0%
using deep learning frameworks like
 

00:02:35.230 --> 00:02:37.259 align:start position:0%
using deep learning frameworks like
tensor<00:02:35.590><c> flow</c><00:02:35.680><c> which</c><00:02:35.950><c> is</c><00:02:35.980><c> the</c><00:02:36.280><c> current</c><00:02:36.610><c> most</c>

00:02:37.259 --> 00:02:37.269 align:start position:0%
tensor flow which is the current most
 

00:02:37.269 --> 00:02:39.059 align:start position:0%
tensor flow which is the current most
popular<00:02:37.810><c> deep</c><00:02:38.019><c> learning</c><00:02:38.170><c> framework</c><00:02:38.680><c> that</c><00:02:38.920><c> you</c>

00:02:39.059 --> 00:02:39.069 align:start position:0%
popular deep learning framework that you
 

00:02:39.069 --> 00:02:42.440 align:start position:0%
popular deep learning framework that you
can<00:02:39.280><c> code</c><00:02:40.150><c> some</c><00:02:40.390><c> of</c><00:02:40.540><c> neural</c><00:02:40.810><c> networks</c><00:02:41.140><c> and</c>

00:02:42.440 --> 00:02:42.450 align:start position:0%
can code some of neural networks and
 

00:02:42.450 --> 00:02:44.580 align:start position:0%
can code some of neural networks and
deep<00:02:43.450><c> learning</c><00:02:43.599><c> model</c><00:02:44.050><c> and</c><00:02:44.230><c> other</c><00:02:44.349><c> deep</c>

00:02:44.580 --> 00:02:44.590 align:start position:0%
deep learning model and other deep
 

00:02:44.590 --> 00:02:48.000 align:start position:0%
deep learning model and other deep
learning<00:02:44.890><c> models</c><00:02:46.200><c> we</c><00:02:47.200><c> have</c><00:02:47.350><c> an</c><00:02:47.440><c> amazing</c><00:02:47.650><c> set</c>

00:02:48.000 --> 00:02:48.010 align:start position:0%
learning models we have an amazing set
 

00:02:48.010 --> 00:02:49.830 align:start position:0%
learning models we have an amazing set
of<00:02:48.100><c> lectures</c><00:02:48.430><c> lined</c><00:02:48.640><c> up</c><00:02:48.760><c> for</c><00:02:48.880><c> you</c><00:02:49.000><c> this</c><00:02:49.360><c> week</c>

00:02:49.830 --> 00:02:49.840 align:start position:0%
of lectures lined up for you this week
 

00:02:49.840 --> 00:02:51.750 align:start position:0%
of lectures lined up for you this week
including<00:02:50.350><c> today</c><00:02:50.650><c> which</c><00:02:50.890><c> will</c><00:02:51.040><c> kick</c><00:02:51.250><c> off</c><00:02:51.430><c> an</c>

00:02:51.750 --> 00:02:51.760 align:start position:0%
including today which will kick off an
 

00:02:51.760 --> 00:02:54.289 align:start position:0%
including today which will kick off an
introduction<00:02:52.239><c> on</c><00:02:52.360><c> neural</c><00:02:52.660><c> networks</c><00:02:53.019><c> and</c>

00:02:54.289 --> 00:02:54.299 align:start position:0%
introduction on neural networks and
 

00:02:54.299 --> 00:02:56.340 align:start position:0%
introduction on neural networks and
sequence<00:02:55.299><c> based</c><00:02:55.540><c> modeling</c><00:02:56.049><c> which</c><00:02:56.200><c> you'll</c>

00:02:56.340 --> 00:02:56.350 align:start position:0%
sequence based modeling which you'll
 

00:02:56.350 --> 00:02:57.539 align:start position:0%
sequence based modeling which you'll
hear<00:02:56.500><c> about</c><00:02:56.590><c> in</c><00:02:56.799><c> the</c><00:02:56.890><c> second</c><00:02:57.250><c> part</c><00:02:57.370><c> of</c><00:02:57.430><c> the</c>

00:02:57.539 --> 00:02:57.549 align:start position:0%
hear about in the second part of the
 

00:02:57.549 --> 00:03:00.570 align:start position:0%
hear about in the second part of the
class<00:02:58.440><c> tomorrow</c><00:02:59.440><c> we'll</c><00:02:59.830><c> cover</c><00:03:00.010><c> some</c><00:03:00.130><c> about</c>

00:03:00.570 --> 00:03:00.580 align:start position:0%
class tomorrow we'll cover some about
 

00:03:00.580 --> 00:03:03.050 align:start position:0%
class tomorrow we'll cover some about
some<00:03:01.000><c> stuff</c><00:03:01.630><c> about</c><00:03:01.840><c> computer</c><00:03:02.410><c> vision</c><00:03:02.440><c> and</c>

00:03:03.050 --> 00:03:03.060 align:start position:0%
some stuff about computer vision and
 

00:03:03.060 --> 00:03:08.190 align:start position:0%
some stuff about computer vision and
deep<00:03:04.060><c> generative</c><00:03:04.569><c> modeling</c><00:03:04.989><c> and</c><00:03:07.049><c> the</c><00:03:08.049><c> day</c>

00:03:08.190 --> 00:03:08.200 align:start position:0%
deep generative modeling and the day
 

00:03:08.200 --> 00:03:09.470 align:start position:0%
deep generative modeling and the day
after<00:03:08.470><c> that</c><00:03:08.620><c> we'll</c><00:03:08.799><c> talk</c><00:03:09.010><c> even</c><00:03:09.250><c> about</c>

00:03:09.470 --> 00:03:09.480 align:start position:0%
after that we'll talk even about
 

00:03:09.480 --> 00:03:12.300 align:start position:0%
after that we'll talk even about
reinforcement<00:03:10.480><c> learning</c><00:03:10.599><c> and</c><00:03:10.989><c> end</c><00:03:11.680><c> on</c><00:03:12.040><c> some</c>

00:03:12.300 --> 00:03:12.310 align:start position:0%
reinforcement learning and end on some
 

00:03:12.310 --> 00:03:15.059 align:start position:0%
reinforcement learning and end on some
of<00:03:12.459><c> the</c><00:03:12.900><c> challenges</c><00:03:13.900><c> and</c><00:03:14.140><c> limitations</c><00:03:14.290><c> of</c><00:03:14.890><c> the</c>

00:03:15.059 --> 00:03:15.069 align:start position:0%
of the challenges and limitations of the
 

00:03:15.069 --> 00:03:17.460 align:start position:0%
of the challenges and limitations of the
current<00:03:15.099><c> deep</c><00:03:15.610><c> learning</c><00:03:15.760><c> approaches</c><00:03:16.420><c> and</c><00:03:16.660><c> and</c>

00:03:17.460 --> 00:03:17.470 align:start position:0%
current deep learning approaches and and
 

00:03:17.470 --> 00:03:19.349 align:start position:0%
current deep learning approaches and and
kind<00:03:17.980><c> of</c><00:03:18.069><c> touch</c><00:03:18.310><c> on</c><00:03:18.489><c> how</c><00:03:18.670><c> we</c><00:03:18.730><c> can</c><00:03:18.970><c> move</c><00:03:19.120><c> forward</c>

00:03:19.349 --> 00:03:19.359 align:start position:0%
kind of touch on how we can move forward
 

00:03:19.359 --> 00:03:22.800 align:start position:0%
kind of touch on how we can move forward
as<00:03:19.630><c> a</c><00:03:19.660><c> field</c><00:03:19.989><c> past</c><00:03:20.530><c> these</c><00:03:20.769><c> challenges</c><00:03:21.810><c> we'll</c>

00:03:22.800 --> 00:03:22.810 align:start position:0%
as a field past these challenges we'll
 

00:03:22.810 --> 00:03:24.509 align:start position:0%
as a field past these challenges we'll
also<00:03:22.959><c> spend</c><00:03:23.140><c> the</c><00:03:23.380><c> final</c><00:03:23.530><c> two</c><00:03:23.829><c> days</c><00:03:23.980><c> hearing</c>

00:03:24.509 --> 00:03:24.519 align:start position:0%
also spend the final two days hearing
 

00:03:24.519 --> 00:03:27.569 align:start position:0%
also spend the final two days hearing
from<00:03:24.730><c> some</c><00:03:25.299><c> guest</c><00:03:26.140><c> lectures</c><00:03:26.590><c> from</c><00:03:26.890><c> top</c><00:03:27.190><c> a</c><00:03:27.459><c> AI</c>

00:03:27.569 --> 00:03:27.579 align:start position:0%
from some guest lectures from top a AI
 

00:03:27.579 --> 00:03:31.229 align:start position:0%
from some guest lectures from top a AI
researchers<00:03:29.670><c> these</c><00:03:30.670><c> are</c><00:03:30.850><c> bound</c><00:03:31.030><c> to</c><00:03:31.150><c> be</c>

00:03:31.229 --> 00:03:31.239 align:start position:0%
researchers these are bound to be
 

00:03:31.239 --> 00:03:34.380 align:start position:0%
researchers these are bound to be
extremely<00:03:31.540><c> interesting</c><00:03:32.200><c> though</c><00:03:33.239><c> we</c><00:03:34.239><c> have</c>

00:03:34.380 --> 00:03:34.390 align:start position:0%
extremely interesting though we have
 

00:03:34.390 --> 00:03:37.530 align:start position:0%
extremely interesting though we have
speakers<00:03:34.989><c> from</c><00:03:35.260><c> Nvidia</c><00:03:35.829><c> IBM</c><00:03:36.579><c> Google</c><00:03:36.940><c> coming</c>

00:03:37.530 --> 00:03:37.540 align:start position:0%
speakers from Nvidia IBM Google coming
 

00:03:37.540 --> 00:03:39.030 align:start position:0%
speakers from Nvidia IBM Google coming
to<00:03:37.660><c> give</c><00:03:37.810><c> talks</c><00:03:38.019><c> so</c><00:03:38.620><c> I</c><00:03:38.650><c> highly</c><00:03:38.980><c> recommend</c>

00:03:39.030 --> 00:03:39.040 align:start position:0%
to give talks so I highly recommend
 

00:03:39.040 --> 00:03:42.240 align:start position:0%
to give talks so I highly recommend
attending<00:03:39.760><c> these</c><00:03:39.850><c> as</c><00:03:40.090><c> well</c><00:03:40.620><c> and</c><00:03:41.620><c> finally</c><00:03:42.040><c> the</c>

00:03:42.240 --> 00:03:42.250 align:start position:0%
attending these as well and finally the
 

00:03:42.250 --> 00:03:43.979 align:start position:0%
attending these as well and finally the
class<00:03:42.430><c> will</c><00:03:42.640><c> conclude</c><00:03:42.940><c> with</c><00:03:43.060><c> some</c><00:03:43.630><c> final</c>

00:03:43.979 --> 00:03:43.989 align:start position:0%
class will conclude with some final
 

00:03:43.989 --> 00:03:45.990 align:start position:0%
class will conclude with some final
project<00:03:44.410><c> presentations</c><00:03:45.069><c> from</c><00:03:45.340><c> students</c><00:03:45.850><c> like</c>

00:03:45.990 --> 00:03:46.000 align:start position:0%
project presentations from students like
 

00:03:46.000 --> 00:03:48.059 align:start position:0%
project presentations from students like
you<00:03:46.150><c> and</c><00:03:46.180><c> the</c><00:03:46.389><c> audience</c><00:03:46.510><c> will</c><00:03:47.410><c> where</c><00:03:47.859><c> you'll</c>

00:03:48.059 --> 00:03:48.069 align:start position:0%
you and the audience will where you'll
 

00:03:48.069 --> 00:03:50.129 align:start position:0%
you and the audience will where you'll
present<00:03:48.370><c> some</c><00:03:49.120><c> final</c><00:03:49.389><c> projects</c><00:03:49.900><c> for</c><00:03:50.049><c> this</c>

00:03:50.129 --> 00:03:50.139 align:start position:0%
present some final projects for this
 

00:03:50.139 --> 00:03:52.080 align:start position:0%
present some final projects for this
class<00:03:50.380><c> and</c><00:03:50.680><c> then</c><00:03:51.280><c> we'll</c><00:03:51.400><c> end</c><00:03:51.549><c> on</c><00:03:51.700><c> an</c><00:03:51.819><c> award</c>

00:03:52.080 --> 00:03:52.090 align:start position:0%
class and then we'll end on an award
 

00:03:52.090 --> 00:03:56.610 align:start position:0%
class and then we'll end on an award
ceremony<00:03:52.269><c> to</c><00:03:52.720><c> celebrate</c><00:03:54.630><c> so</c><00:03:55.630><c> as</c><00:03:56.260><c> you</c><00:03:56.500><c> might</c>

00:03:56.610 --> 00:03:56.620 align:start position:0%
ceremony to celebrate so as you might
 

00:03:56.620 --> 00:03:58.770 align:start position:0%
ceremony to celebrate so as you might
have<00:03:56.739><c> seen</c><00:03:57.220><c> or</c><00:03:57.519><c> heard</c><00:03:57.700><c> already</c><00:03:58.090><c> this</c><00:03:58.269><c> class</c><00:03:58.540><c> is</c>

00:03:58.770 --> 00:03:58.780 align:start position:0%
have seen or heard already this class is
 

00:03:58.780 --> 00:04:00.210 align:start position:0%
have seen or heard already this class is
offered<00:03:59.079><c> for</c><00:03:59.260><c> credit</c><00:03:59.620><c> you</c><00:03:59.769><c> can</c><00:03:59.889><c> take</c><00:04:00.069><c> this</c>

00:04:00.210 --> 00:04:00.220 align:start position:0%
offered for credit you can take this
 

00:04:00.220 --> 00:04:02.430 align:start position:0%
offered for credit you can take this
class<00:04:00.489><c> for</c><00:04:00.670><c> grade</c><00:04:00.910><c> and</c><00:04:01.180><c> if</c><00:04:01.900><c> you're</c><00:04:02.079><c> taking</c>

00:04:02.430 --> 00:04:02.440 align:start position:0%
class for grade and if you're taking
 

00:04:02.440 --> 00:04:03.690 align:start position:0%
class for grade and if you're taking
this<00:04:02.680><c> class</c><00:04:02.829><c> for</c><00:04:03.130><c> grade</c><00:04:03.310><c> you</c><00:04:03.430><c> have</c><00:04:03.549><c> two</c>

00:04:03.690 --> 00:04:03.700 align:start position:0%
this class for grade you have two
 

00:04:03.700 --> 00:04:04.949 align:start position:0%
this class for grade you have two
options<00:04:03.880><c> to</c><00:04:04.209><c> fulfill</c><00:04:04.630><c> your</c><00:04:04.780><c> grade</c>

00:04:04.949 --> 00:04:04.959 align:start position:0%
options to fulfill your grade
 

00:04:04.959 --> 00:04:07.979 align:start position:0%
options to fulfill your grade
requirement<00:04:05.639><c> first</c><00:04:06.639><c> option</c><00:04:07.209><c> is</c><00:04:07.389><c> that</c><00:04:07.720><c> you</c><00:04:07.840><c> can</c>

00:04:07.979 --> 00:04:07.989 align:start position:0%
requirement first option is that you can
 

00:04:07.989 --> 00:04:10.080 align:start position:0%
requirement first option is that you can
actually<00:04:08.170><c> do</c><00:04:08.380><c> a</c><00:04:08.410><c> project</c><00:04:08.620><c> proposal</c><00:04:09.280><c> where</c><00:04:09.880><c> you</c>

00:04:10.080 --> 00:04:10.090 align:start position:0%
actually do a project proposal where you
 

00:04:10.090 --> 00:04:12.360 align:start position:0%
actually do a project proposal where you
will<00:04:10.269><c> present</c><00:04:10.720><c> your</c><00:04:10.989><c> project</c><00:04:11.560><c> on</c><00:04:11.769><c> the</c><00:04:12.100><c> final</c>

00:04:12.360 --> 00:04:12.370 align:start position:0%
will present your project on the final
 

00:04:12.370 --> 00:04:13.530 align:start position:0%
will present your project on the final
day<00:04:12.489><c> of</c><00:04:12.519><c> class</c><00:04:12.819><c> that's</c><00:04:13.090><c> what</c><00:04:13.239><c> I</c><00:04:13.269><c> was</c><00:04:13.389><c> saying</c>

00:04:13.530 --> 00:04:13.540 align:start position:0%
day of class that's what I was saying
 

00:04:13.540 --> 00:04:15.360 align:start position:0%
day of class that's what I was saying
before<00:04:13.660><c> on</c><00:04:13.900><c> Friday</c><00:04:14.200><c> you</c><00:04:14.769><c> can</c><00:04:14.920><c> present</c><00:04:15.280><c> your</c>

00:04:15.360 --> 00:04:15.370 align:start position:0%
before on Friday you can present your
 

00:04:15.370 --> 00:04:17.610 align:start position:0%
before on Friday you can present your
project<00:04:15.819><c> and</c><00:04:16.030><c> this</c><00:04:16.720><c> is</c><00:04:16.780><c> just</c><00:04:17.079><c> a</c><00:04:17.200><c> three</c><00:04:17.440><c> minute</c>

00:04:17.610 --> 00:04:17.620 align:start position:0%
project and this is just a three minute
 

00:04:17.620 --> 00:04:19.440 align:start position:0%
project and this is just a three minute
presentation<00:04:18.340><c> we'll</c><00:04:18.579><c> be</c><00:04:18.700><c> very</c><00:04:18.850><c> strict</c><00:04:19.150><c> on</c><00:04:19.329><c> the</c>

00:04:19.440 --> 00:04:19.450 align:start position:0%
presentation we'll be very strict on the
 

00:04:19.450 --> 00:04:22.379 align:start position:0%
presentation we'll be very strict on the
time<00:04:19.660><c> here</c><00:04:19.959><c> and</c><00:04:20.109><c> we</c><00:04:20.820><c> realized</c><00:04:21.820><c> that</c><00:04:21.940><c> one</c><00:04:22.180><c> week</c>

00:04:22.379 --> 00:04:22.389 align:start position:0%
time here and we realized that one week
 

00:04:22.389 --> 00:04:24.089 align:start position:0%
time here and we realized that one week
is<00:04:22.570><c> a</c><00:04:22.599><c> super</c><00:04:23.050><c> short</c><00:04:23.229><c> time</c><00:04:23.530><c> to</c><00:04:23.680><c> actually</c><00:04:23.950><c> come</c>

00:04:24.089 --> 00:04:24.099 align:start position:0%
is a super short time to actually come
 

00:04:24.099 --> 00:04:25.649 align:start position:0%
is a super short time to actually come
up<00:04:24.130><c> with</c><00:04:24.280><c> a</c><00:04:24.430><c> deep</c><00:04:24.669><c> learning</c><00:04:24.820><c> project</c><00:04:25.390><c> so</c><00:04:25.510><c> we're</c>

00:04:25.649 --> 00:04:25.659 align:start position:0%
up with a deep learning project so we're
 

00:04:25.659 --> 00:04:27.360 align:start position:0%
up with a deep learning project so we're
not<00:04:25.780><c> going</c><00:04:26.050><c> to</c><00:04:26.140><c> actually</c><00:04:26.320><c> be</c><00:04:26.620><c> judging</c><00:04:27.010><c> you</c><00:04:27.159><c> on</c>

00:04:27.360 --> 00:04:27.370 align:start position:0%
not going to actually be judging you on
 

00:04:27.370 --> 00:04:28.320 align:start position:0%
not going to actually be judging you on
the<00:04:27.460><c> results</c>

00:04:28.320 --> 00:04:28.330 align:start position:0%
the results
 

00:04:28.330 --> 00:04:30.689 align:start position:0%
the results
you<00:04:28.479><c> create</c><00:04:28.810><c> during</c><00:04:28.990><c> this</c><00:04:29.229><c> week</c><00:04:29.470><c> instead</c><00:04:29.740><c> what</c>

00:04:30.689 --> 00:04:30.699 align:start position:0%
you create during this week instead what
 

00:04:30.699 --> 00:04:32.550 align:start position:0%
you create during this week instead what
we're<00:04:30.849><c> looking</c><00:04:31.180><c> for</c><00:04:31.210><c> is</c><00:04:31.569><c> the</c><00:04:31.840><c> novelty</c><00:04:32.169><c> of</c><00:04:32.289><c> the</c>

00:04:32.550 --> 00:04:32.560 align:start position:0%
we're looking for is the novelty of the
 

00:04:32.560 --> 00:04:34.409 align:start position:0%
we're looking for is the novelty of the
ideas<00:04:32.949><c> and</c><00:04:33.220><c> how</c><00:04:33.430><c> well</c><00:04:33.460><c> you</c><00:04:33.729><c> can</c><00:04:33.879><c> present</c><00:04:34.090><c> it</c>

00:04:34.409 --> 00:04:34.419 align:start position:0%
ideas and how well you can present it
 

00:04:34.419 --> 00:04:36.180 align:start position:0%
ideas and how well you can present it
given<00:04:34.930><c> such</c><00:04:35.139><c> a</c><00:04:35.169><c> short</c><00:04:35.440><c> amount</c><00:04:35.680><c> of</c><00:04:35.800><c> time</c><00:04:35.860><c> in</c>

00:04:36.180 --> 00:04:36.190 align:start position:0%
given such a short amount of time in
 

00:04:36.190 --> 00:04:40.110 align:start position:0%
given such a short amount of time in
three<00:04:36.400><c> minutes</c><00:04:37.349><c> and</c><00:04:38.520><c> we</c><00:04:39.520><c> kind</c><00:04:39.699><c> of</c><00:04:39.789><c> think</c><00:04:39.970><c> it's</c>

00:04:40.110 --> 00:04:40.120 align:start position:0%
three minutes and we kind of think it's
 

00:04:40.120 --> 00:04:41.939 align:start position:0%
three minutes and we kind of think it's
like<00:04:40.539><c> an</c><00:04:40.690><c> art</c><00:04:40.900><c> to</c><00:04:41.169><c> being</c><00:04:41.379><c> able</c><00:04:41.530><c> to</c><00:04:41.680><c> present</c>

00:04:41.939 --> 00:04:41.949 align:start position:0%
like an art to being able to present
 

00:04:41.949 --> 00:04:44.730 align:start position:0%
like an art to being able to present
something<00:04:42.580><c> in</c><00:04:42.759><c> just</c><00:04:43.000><c> three</c><00:04:43.539><c> minutes</c><00:04:43.690><c> so</c><00:04:44.080><c> we</c>

00:04:44.730 --> 00:04:44.740 align:start position:0%
something in just three minutes so we
 

00:04:44.740 --> 00:04:46.200 align:start position:0%
something in just three minutes so we
kind<00:04:45.069><c> of</c><00:04:45.129><c> want</c><00:04:45.280><c> to</c><00:04:45.340><c> hold</c><00:04:45.460><c> you</c><00:04:45.610><c> to</c><00:04:45.729><c> that</c><00:04:45.759><c> tight</c>

00:04:46.200 --> 00:04:46.210 align:start position:0%
kind of want to hold you to that tight
 

00:04:46.210 --> 00:04:48.899 align:start position:0%
kind of want to hold you to that tight
time<00:04:46.539><c> schedule</c><00:04:46.569><c> and</c><00:04:47.280><c> kind</c><00:04:48.280><c> of</c><00:04:48.310><c> enforce</c><00:04:48.729><c> it</c>

00:04:48.899 --> 00:04:48.909 align:start position:0%
time schedule and kind of enforce it
 

00:04:48.909 --> 00:04:50.850 align:start position:0%
time schedule and kind of enforce it
very<00:04:49.240><c> tightly</c><00:04:49.479><c> just</c><00:04:49.960><c> so</c><00:04:50.110><c> that</c><00:04:50.319><c> you're</c><00:04:50.500><c> forced</c>

00:04:50.850 --> 00:04:50.860 align:start position:0%
very tightly just so that you're forced
 

00:04:50.860 --> 00:04:52.860 align:start position:0%
very tightly just so that you're forced
to<00:04:50.949><c> really</c><00:04:51.340><c> think</c><00:04:51.550><c> about</c><00:04:51.789><c> what</c><00:04:52.360><c> is</c><00:04:52.479><c> the</c><00:04:52.629><c> core</c>

00:04:52.860 --> 00:04:52.870 align:start position:0%
to really think about what is the core
 

00:04:52.870 --> 00:04:54.540 align:start position:0%
to really think about what is the core
idea<00:04:53.169><c> that</c><00:04:53.379><c> you</c><00:04:53.470><c> want</c><00:04:53.680><c> to</c><00:04:53.740><c> present</c><00:04:53.919><c> to</c><00:04:54.159><c> us</c><00:04:54.370><c> on</c>

00:04:54.540 --> 00:04:54.550 align:start position:0%
idea that you want to present to us on
 

00:04:54.550 --> 00:04:58.830 align:start position:0%
idea that you want to present to us on
Friday<00:04:55.500><c> your</c><00:04:56.500><c> projects</c><00:04:57.370><c> your</c><00:04:57.840><c> presentations</c>

00:04:58.830 --> 00:04:58.840 align:start position:0%
Friday your projects your presentations
 

00:04:58.840 --> 00:05:00.990 align:start position:0%
Friday your projects your presentations
will<00:04:59.050><c> be</c><00:04:59.169><c> judged</c><00:04:59.470><c> by</c><00:04:59.770><c> a</c><00:04:59.800><c> panel</c><00:04:59.919><c> of</c><00:05:00.310><c> judges</c><00:05:00.370><c> and</c>

00:05:00.990 --> 00:05:01.000 align:start position:0%
will be judged by a panel of judges and
 

00:05:01.000 --> 00:05:05.219 align:start position:0%
will be judged by a panel of judges and
will<00:05:01.750><c> be</c><00:05:01.930><c> awarding</c><00:05:02.440><c> GPUs</c><00:05:03.400><c> and</c><00:05:03.729><c> some</c><00:05:04.360><c> home</c>

00:05:05.219 --> 00:05:05.229 align:start position:0%
will be awarding GPUs and some home
 

00:05:05.229 --> 00:05:07.950 align:start position:0%
will be awarding GPUs and some home
Google<00:05:05.919><c> home</c><00:05:06.190><c> AI</c><00:05:06.460><c> assistants</c><00:05:07.210><c> this</c><00:05:07.780><c> year</c>

00:05:07.950 --> 00:05:07.960 align:start position:0%
Google home AI assistants this year
 

00:05:07.960 --> 00:05:10.740 align:start position:0%
Google home AI assistants this year
we're<00:05:08.110><c> offering</c><00:05:08.469><c> three</c><00:05:08.830><c> NVIDIA</c><00:05:09.280><c> GPUs</c><00:05:09.819><c> each</c>

00:05:10.740 --> 00:05:10.750 align:start position:0%
we're offering three NVIDIA GPUs each
 

00:05:10.750 --> 00:05:13.320 align:start position:0%
we're offering three NVIDIA GPUs each
one<00:05:11.080><c> worth</c><00:05:11.289><c> over</c><00:05:11.680><c> $1,000</c><00:05:12.520><c> some</c><00:05:12.909><c> of</c><00:05:13.030><c> you</c><00:05:13.120><c> know</c>

00:05:13.320 --> 00:05:13.330 align:start position:0%
one worth over $1,000 some of you know
 

00:05:13.330 --> 00:05:16.409 align:start position:0%
one worth over $1,000 some of you know
these<00:05:14.080><c> GPUs</c><00:05:14.560><c> are</c><00:05:14.740><c> the</c><00:05:15.129><c> backbone</c><00:05:15.669><c> of</c><00:05:15.699><c> doing</c>

00:05:16.409 --> 00:05:16.419 align:start position:0%
these GPUs are the backbone of doing
 

00:05:16.419 --> 00:05:18.540 align:start position:0%
these GPUs are the backbone of doing
cutting-edge<00:05:17.050><c> deep</c><00:05:17.500><c> learning</c><00:05:17.680><c> research</c><00:05:18.219><c> and</c>

00:05:18.540 --> 00:05:18.550 align:start position:0%
cutting-edge deep learning research and
 

00:05:18.550 --> 00:05:21.659 align:start position:0%
cutting-edge deep learning research and
it's<00:05:19.180><c> really</c><00:05:19.449><c> foundational</c><00:05:20.080><c> or</c><00:05:20.680><c> essential</c><00:05:21.460><c> if</c>

00:05:21.659 --> 00:05:21.669 align:start position:0%
it's really foundational or essential if
 

00:05:21.669 --> 00:05:22.950 align:start position:0%
it's really foundational or essential if
you<00:05:22.000><c> want</c><00:05:22.030><c> to</c><00:05:22.270><c> be</c><00:05:22.389><c> doing</c><00:05:22.599><c> this</c><00:05:22.690><c> kind</c><00:05:22.900><c> of</c>

00:05:22.950 --> 00:05:22.960 align:start position:0%
you want to be doing this kind of
 

00:05:22.960 --> 00:05:24.689 align:start position:0%
you want to be doing this kind of
research<00:05:23.020><c> so</c><00:05:23.830><c> we're</c><00:05:23.979><c> really</c><00:05:24.129><c> happy</c><00:05:24.370><c> that</c><00:05:24.610><c> we</c>

00:05:24.689 --> 00:05:24.699 align:start position:0%
research so we're really happy that we
 

00:05:24.699 --> 00:05:26.700 align:start position:0%
research so we're really happy that we
can<00:05:24.849><c> offer</c><00:05:24.969><c> you</c><00:05:25.180><c> these</c><00:05:25.810><c> types</c><00:05:26.110><c> this</c><00:05:26.500><c> type</c><00:05:26.680><c> of</c>

00:05:26.700 --> 00:05:26.710 align:start position:0%
can offer you these types this type of
 

00:05:26.710 --> 00:05:30.390 align:start position:0%
can offer you these types this type of
hardware<00:05:28.560><c> the</c><00:05:29.560><c> second</c><00:05:29.889><c> option</c><00:05:30.159><c> if</c><00:05:30.280><c> you</c><00:05:30.370><c> don't</c>

00:05:30.390 --> 00:05:30.400 align:start position:0%
hardware the second option if you don't
 

00:05:30.400 --> 00:05:32.309 align:start position:0%
hardware the second option if you don't
want<00:05:30.819><c> to</c><00:05:30.909><c> do</c><00:05:31.030><c> the</c><00:05:31.150><c> project</c><00:05:31.509><c> presentation</c><00:05:32.139><c> but</c>

00:05:32.309 --> 00:05:32.319 align:start position:0%
want to do the project presentation but
 

00:05:32.319 --> 00:05:33.809 align:start position:0%
want to do the project presentation but
you<00:05:32.349><c> still</c><00:05:32.650><c> want</c><00:05:32.830><c> to</c><00:05:32.889><c> receive</c><00:05:33.159><c> credit</c><00:05:33.669><c> for</c>

00:05:33.809 --> 00:05:33.819 align:start position:0%
you still want to receive credit for
 

00:05:33.819 --> 00:05:35.700 align:start position:0%
you still want to receive credit for
this<00:05:34.000><c> class</c><00:05:34.300><c> you</c><00:05:34.509><c> can</c><00:05:34.539><c> do</c><00:05:34.930><c> the</c><00:05:35.020><c> second</c><00:05:35.349><c> option</c>

00:05:35.700 --> 00:05:35.710 align:start position:0%
this class you can do the second option
 

00:05:35.710 --> 00:05:37.950 align:start position:0%
this class you can do the second option
which<00:05:36.370><c> is</c><00:05:36.400><c> a</c><00:05:37.060><c> little</c><00:05:37.150><c> more</c><00:05:37.419><c> boring</c><00:05:37.750><c> in</c><00:05:37.930><c> my</c>

00:05:37.950 --> 00:05:37.960 align:start position:0%
which is a little more boring in my
 

00:05:37.960 --> 00:05:40.230 align:start position:0%
which is a little more boring in my
opinion<00:05:38.500><c> but</c><00:05:39.159><c> you</c><00:05:39.490><c> can</c><00:05:39.669><c> write</c><00:05:39.880><c> a</c><00:05:39.909><c> one-page</c>

00:05:40.230 --> 00:05:40.240 align:start position:0%
opinion but you can write a one-page
 

00:05:40.240 --> 00:05:43.709 align:start position:0%
opinion but you can write a one-page
review<00:05:40.840><c> of</c><00:05:41.050><c> a</c><00:05:41.139><c> deep</c><00:05:41.319><c> learning</c><00:05:41.500><c> paper</c><00:05:41.889><c> and</c><00:05:42.719><c> this</c>

00:05:43.709 --> 00:05:43.719 align:start position:0%
review of a deep learning paper and this
 

00:05:43.719 --> 00:05:45.330 align:start position:0%
review of a deep learning paper and this
will<00:05:43.870><c> be</c><00:05:43.960><c> doing</c><00:05:44.229><c> the</c><00:05:44.319><c> last</c><00:05:44.349><c> day</c><00:05:44.650><c> of</c><00:05:44.710><c> class</c><00:05:44.949><c> and</c>

00:05:45.330 --> 00:05:45.340 align:start position:0%
will be doing the last day of class and
 

00:05:45.340 --> 00:05:47.370 align:start position:0%
will be doing the last day of class and
this<00:05:46.180><c> is</c><00:05:46.360><c> for</c><00:05:46.690><c> people</c><00:05:46.810><c> I</c><00:05:46.960><c> don't</c><00:05:47.139><c> want</c><00:05:47.259><c> to</c><00:05:47.319><c> do</c>

00:05:47.370 --> 00:05:47.380 align:start position:0%
this is for people I don't want to do
 

00:05:47.380 --> 00:05:48.719 align:start position:0%
this is for people I don't want to do
the<00:05:47.469><c> project</c><00:05:47.590><c> presentation</c><00:05:48.340><c> but</c><00:05:48.460><c> you</c><00:05:48.490><c> still</c>

00:05:48.719 --> 00:05:48.729 align:start position:0%
the project presentation but you still
 

00:05:48.729 --> 00:05:53.580 align:start position:0%
the project presentation but you still
want<00:05:48.880><c> to</c><00:05:48.940><c> get</c><00:05:49.060><c> credit</c><00:05:49.870><c> for</c><00:05:50.050><c> this</c><00:05:50.139><c> class</c><00:05:52.590><c> please</c>

00:05:53.580 --> 00:05:53.590 align:start position:0%
want to get credit for this class please
 

00:05:53.590 --> 00:05:55.140 align:start position:0%
want to get credit for this class please
post<00:05:53.889><c> to</c><00:05:54.039><c> Piazza</c><00:05:54.430><c> if</c><00:05:54.520><c> you</c><00:05:54.610><c> have</c><00:05:54.729><c> questions</c>

00:05:55.140 --> 00:05:55.150 align:start position:0%
post to Piazza if you have questions
 

00:05:55.150 --> 00:05:57.180 align:start position:0%
post to Piazza if you have questions
about<00:05:55.389><c> the</c><00:05:55.599><c> labs</c><00:05:55.840><c> that</c><00:05:56.529><c> we'll</c><00:05:56.650><c> be</c><00:05:56.770><c> doing</c><00:05:57.009><c> today</c>

00:05:57.180 --> 00:05:57.190 align:start position:0%
about the labs that we'll be doing today
 

00:05:57.190 --> 00:05:59.399 align:start position:0%
about the labs that we'll be doing today
or<00:05:57.550><c> any</c><00:05:58.060><c> of</c><00:05:58.180><c> the</c><00:05:58.300><c> future</c><00:05:58.509><c> days</c><00:05:58.779><c> if</c><00:05:59.199><c> you</c><00:05:59.289><c> have</c>

00:05:59.399 --> 00:05:59.409 align:start position:0%
or any of the future days if you have
 

00:05:59.409 --> 00:06:00.570 align:start position:0%
or any of the future days if you have
questions<00:05:59.740><c> about</c><00:05:59.949><c> the</c><00:06:00.039><c> course</c><00:06:00.219><c> in</c><00:06:00.400><c> general</c>

00:06:00.570 --> 00:06:00.580 align:start position:0%
questions about the course in general
 

00:06:00.580 --> 00:06:02.670 align:start position:0%
questions about the course in general
there's<00:06:01.479><c> course</c><00:06:01.840><c> information</c><00:06:02.409><c> on</c><00:06:02.560><c> the</c>

00:06:02.670 --> 00:06:02.680 align:start position:0%
there's course information on the
 

00:06:02.680 --> 00:06:05.550 align:start position:0%
there's course information on the
website<00:06:02.860><c> enter</c><00:06:03.370><c> deep</c><00:06:03.759><c> learning</c><00:06:03.940><c> com</c>

00:06:05.550 --> 00:06:05.560 align:start position:0%
website enter deep learning com
 

00:06:05.560 --> 00:06:07.260 align:start position:0%
website enter deep learning com
along<00:06:06.039><c> with</c><00:06:06.159><c> announcements</c><00:06:06.430><c> digital</c>

00:06:07.260 --> 00:06:07.270 align:start position:0%
along with announcements digital
 

00:06:07.270 --> 00:06:09.570 align:start position:0%
along with announcements digital
recordings<00:06:07.779><c> as</c><00:06:08.469><c> well</c><00:06:08.650><c> as</c><00:06:08.740><c> slides</c><00:06:09.039><c> for</c><00:06:09.400><c> these</c>

00:06:09.570 --> 00:06:09.580 align:start position:0%
recordings as well as slides for these
 

00:06:09.580 --> 00:06:11.670 align:start position:0%
recordings as well as slides for these
classes<00:06:10.120><c> today's</c><00:06:10.840><c> slides</c><00:06:11.139><c> are</c><00:06:11.319><c> already</c>

00:06:11.670 --> 00:06:11.680 align:start position:0%
classes today's slides are already
 

00:06:11.680 --> 00:06:13.350 align:start position:0%
classes today's slides are already
released<00:06:12.009><c> so</c><00:06:12.400><c> you</c><00:06:12.789><c> can</c><00:06:12.940><c> find</c><00:06:13.150><c> everything</c>

00:06:13.350 --> 00:06:13.360 align:start position:0%
released so you can find everything
 

00:06:13.360 --> 00:06:15.450 align:start position:0%
released so you can find everything
online<00:06:13.629><c> and</c><00:06:14.050><c> of</c><00:06:14.889><c> course</c><00:06:15.099><c> if</c><00:06:15.250><c> you</c><00:06:15.340><c> have</c><00:06:15.430><c> any</c>

00:06:15.450 --> 00:06:15.460 align:start position:0%
online and of course if you have any
 

00:06:15.460 --> 00:06:17.399 align:start position:0%
online and of course if you have any
questions<00:06:16.000><c> you</c><00:06:16.150><c> can</c><00:06:16.180><c> email</c><00:06:16.449><c> us</c><00:06:16.779><c> at</c><00:06:16.990><c> intro</c><00:06:17.289><c> to</c>

00:06:17.399 --> 00:06:17.409 align:start position:0%
questions you can email us at intro to
 

00:06:17.409 --> 00:06:20.550 align:start position:0%
questions you can email us at intro to
deep<00:06:17.590><c> learning</c><00:06:17.740><c> -</c><00:06:18.219><c> staff</c><00:06:18.580><c> at</c><00:06:18.879><c> MIT</c><00:06:19.210><c> edu</c><00:06:19.870><c> this</c>

00:06:20.550 --> 00:06:20.560 align:start position:0%
deep learning - staff at MIT edu this
 

00:06:20.560 --> 00:06:22.140 align:start position:0%
deep learning - staff at MIT edu this
course<00:06:20.830><c> has</c><00:06:20.979><c> an</c><00:06:21.099><c> incredible</c><00:06:21.520><c> team</c><00:06:21.789><c> that</c><00:06:22.060><c> you</c>

00:06:22.140 --> 00:06:22.150 align:start position:0%
course has an incredible team that you
 

00:06:22.150 --> 00:06:23.490 align:start position:0%
course has an incredible team that you
can<00:06:22.300><c> reach</c><00:06:22.479><c> out</c><00:06:22.629><c> to</c><00:06:22.840><c> in</c><00:06:22.960><c> case</c><00:06:23.080><c> you</c><00:06:23.229><c> have</c><00:06:23.349><c> any</c>

00:06:23.490 --> 00:06:23.500 align:start position:0%
can reach out to in case you have any
 

00:06:23.500 --> 00:06:26.459 align:start position:0%
can reach out to in case you have any
questions<00:06:23.580><c> or</c><00:06:24.580><c> issues</c><00:06:24.819><c> about</c><00:06:25.300><c> anything</c><00:06:25.599><c> so</c>

00:06:26.459 --> 00:06:26.469 align:start position:0%
questions or issues about anything so
 

00:06:26.469 --> 00:06:28.890 align:start position:0%
questions or issues about anything so
please<00:06:26.620><c> don't</c><00:06:26.889><c> hesitate</c><00:06:27.009><c> to</c><00:06:27.340><c> reach</c><00:06:27.490><c> out</c><00:06:27.900><c> and</c>

00:06:28.890 --> 00:06:28.900 align:start position:0%
please don't hesitate to reach out and
 

00:06:28.900 --> 00:06:30.719 align:start position:0%
please don't hesitate to reach out and
finally<00:06:29.620><c> we</c><00:06:29.740><c> want</c><00:06:29.919><c> to</c><00:06:29.979><c> give</c><00:06:30.069><c> a</c><00:06:30.099><c> huge</c><00:06:30.250><c> thanks</c><00:06:30.699><c> to</c>

00:06:30.719 --> 00:06:30.729 align:start position:0%
finally we want to give a huge thanks to
 

00:06:30.729 --> 00:06:32.820 align:start position:0%
finally we want to give a huge thanks to
all<00:06:31.389><c> of</c><00:06:31.750><c> the</c><00:06:31.840><c> sponsors</c><00:06:32.289><c> that</c><00:06:32.529><c> made</c><00:06:32.680><c> this</c>

00:06:32.820 --> 00:06:32.830 align:start position:0%
all of the sponsors that made this
 

00:06:32.830 --> 00:06:36.659 align:start position:0%
all of the sponsors that made this
course<00:06:33.069><c> possible</c><00:06:34.650><c> so</c><00:06:35.650><c> now</c><00:06:35.800><c> let's</c><00:06:36.159><c> start</c><00:06:36.490><c> with</c>

00:06:36.659 --> 00:06:36.669 align:start position:0%
course possible so now let's start with
 

00:06:36.669 --> 00:06:39.180 align:start position:0%
course possible so now let's start with
the<00:06:36.789><c> fun</c><00:06:36.969><c> stuff</c><00:06:37.300><c> and</c><00:06:37.889><c> actually</c><00:06:38.889><c> let's</c><00:06:39.070><c> start</c>

00:06:39.180 --> 00:06:39.190 align:start position:0%
the fun stuff and actually let's start
 

00:06:39.190 --> 00:06:41.460 align:start position:0%
the fun stuff and actually let's start
by<00:06:39.370><c> asking</c><00:06:39.490><c> ourselves</c><00:06:39.940><c> a</c><00:06:40.449><c> question</c>

00:06:41.460 --> 00:06:41.470 align:start position:0%
by asking ourselves a question
 

00:06:41.470 --> 00:06:44.340 align:start position:0%
by asking ourselves a question
why<00:06:42.100><c> do</c><00:06:42.160><c> we</c><00:06:42.280><c> even</c><00:06:42.400><c> care</c><00:06:42.760><c> about</c><00:06:42.880><c> this</c><00:06:43.120><c> class</c><00:06:43.390><c> why</c>

00:06:44.340 --> 00:06:44.350 align:start position:0%
why do we even care about this class why
 

00:06:44.350 --> 00:06:46.470 align:start position:0%
why do we even care about this class why
did<00:06:44.500><c> you</c><00:06:44.620><c> all</c><00:06:44.740><c> come</c><00:06:44.770><c> here</c><00:06:45.160><c> today</c><00:06:45.340><c> what</c><00:06:46.120><c> is</c><00:06:46.210><c> why</c>

00:06:46.470 --> 00:06:46.480 align:start position:0%
did you all come here today what is why
 

00:06:46.480 --> 00:06:47.960 align:start position:0%
did you all come here today what is why
do<00:06:46.540><c> we</c><00:06:46.690><c> care</c><00:06:46.840><c> about</c><00:06:46.900><c> deep</c><00:06:47.200><c> learning</c><00:06:47.350><c> well</c>

00:06:47.960 --> 00:06:47.970 align:start position:0%
do we care about deep learning well
 

00:06:47.970 --> 00:06:50.330 align:start position:0%
do we care about deep learning well
traditional<00:06:48.970><c> machine</c><00:06:49.300><c> learning</c><00:06:49.690><c> algorithms</c>

00:06:50.330 --> 00:06:50.340 align:start position:0%
traditional machine learning algorithms
 

00:06:50.340 --> 00:06:53.160 align:start position:0%
traditional machine learning algorithms
typically<00:06:51.340><c> define</c><00:06:51.790><c> sets</c><00:06:52.300><c> of</c><00:06:52.510><c> rules</c><00:06:52.840><c> or</c>

00:06:53.160 --> 00:06:53.170 align:start position:0%
typically define sets of rules or
 

00:06:53.170 --> 00:06:57.300 align:start position:0%
typically define sets of rules or
features<00:06:54.270><c> that</c><00:06:55.270><c> you</c><00:06:56.170><c> want</c><00:06:56.350><c> to</c><00:06:56.590><c> extract</c><00:06:57.190><c> from</c>

00:06:57.300 --> 00:06:57.310 align:start position:0%
features that you want to extract from
 

00:06:57.310 --> 00:06:59.340 align:start position:0%
features that you want to extract from
the<00:06:57.700><c> data</c><00:06:57.880><c> usually</c><00:06:58.630><c> these</c><00:06:58.960><c> are</c><00:06:59.080><c> hand</c>

00:06:59.340 --> 00:06:59.350 align:start position:0%
the data usually these are hand
 

00:06:59.350 --> 00:07:00.960 align:start position:0%
the data usually these are hand
engineered<00:06:59.860><c> features</c><00:07:00.190><c> and</c><00:07:00.400><c> they</c><00:07:00.460><c> tend</c><00:07:00.730><c> to</c><00:07:00.790><c> be</c>

00:07:00.960 --> 00:07:00.970 align:start position:0%
engineered features and they tend to be
 

00:07:00.970 --> 00:07:03.060 align:start position:0%
engineered features and they tend to be
extremely<00:07:01.600><c> brittle</c><00:07:02.110><c> in</c><00:07:02.380><c> practice</c>

00:07:03.060 --> 00:07:03.070 align:start position:0%
extremely brittle in practice
 

00:07:03.070 --> 00:07:05.640 align:start position:0%
extremely brittle in practice
now<00:07:03.670><c> the</c><00:07:03.730><c> key</c><00:07:04.030><c> idea</c><00:07:04.510><c> is</c><00:07:04.660><c> a</c><00:07:04.750><c> key</c><00:07:04.960><c> insight</c><00:07:05.470><c> of</c>

00:07:05.640 --> 00:07:05.650 align:start position:0%
now the key idea is a key insight of
 

00:07:05.650 --> 00:07:08.490 align:start position:0%
now the key idea is a key insight of
deep<00:07:05.860><c> learning</c><00:07:06.040><c> is</c><00:07:06.520><c> that</c><00:07:07.090><c> let's</c><00:07:07.870><c> not</c><00:07:08.080><c> hand</c>

00:07:08.490 --> 00:07:08.500 align:start position:0%
deep learning is that let's not hand
 

00:07:08.500 --> 00:07:10.410 align:start position:0%
deep learning is that let's not hand
engineer<00:07:09.040><c> these</c><00:07:09.220><c> features</c><00:07:09.670><c> instead</c><00:07:10.210><c> let's</c>

00:07:10.410 --> 00:07:10.420 align:start position:0%
engineer these features instead let's
 

00:07:10.420 --> 00:07:13.020 align:start position:0%
engineer these features instead let's
learn<00:07:10.660><c> them</c><00:07:10.990><c> directly</c><00:07:11.830><c> from</c><00:07:12.100><c> raw</c><00:07:12.340><c> data</c><00:07:12.370><c> that</c>

00:07:13.020 --> 00:07:13.030 align:start position:0%
learn them directly from raw data that
 

00:07:13.030 --> 00:07:16.500 align:start position:0%
learn them directly from raw data that
is<00:07:13.780><c> can</c><00:07:14.170><c> we</c><00:07:14.320><c> learn</c><00:07:14.590><c> in</c><00:07:15.250><c> order</c><00:07:15.940><c> to</c><00:07:16.060><c> detect</c><00:07:16.390><c> the</c>

00:07:16.500 --> 00:07:16.510 align:start position:0%
is can we learn in order to detect the
 

00:07:16.510 --> 00:07:19.230 align:start position:0%
is can we learn in order to detect the
face<00:07:16.750><c> we</c><00:07:17.650><c> can</c><00:07:17.860><c> first</c><00:07:18.130><c> detect</c><00:07:18.580><c> the</c><00:07:18.730><c> edges</c><00:07:19.090><c> in</c>

00:07:19.230 --> 00:07:19.240 align:start position:0%
face we can first detect the edges in
 

00:07:19.240 --> 00:07:21.750 align:start position:0%
face we can first detect the edges in
the<00:07:19.480><c> picture</c><00:07:19.950><c> compose</c><00:07:20.950><c> these</c><00:07:21.160><c> edges</c><00:07:21.580><c> together</c>

00:07:21.750 --> 00:07:21.760 align:start position:0%
the picture compose these edges together
 

00:07:21.760 --> 00:07:24.570 align:start position:0%
the picture compose these edges together
to<00:07:22.530><c> start</c><00:07:23.530><c> detecting</c><00:07:23.980><c> things</c><00:07:24.100><c> like</c><00:07:24.340><c> eyes</c>

00:07:24.570 --> 00:07:24.580 align:start position:0%
to start detecting things like eyes
 

00:07:24.580 --> 00:07:27.210 align:start position:0%
to start detecting things like eyes
mouth<00:07:25.150><c> and</c><00:07:25.180><c> nose</c><00:07:25.540><c> and</c><00:07:26.020><c> then</c><00:07:26.530><c> composing</c><00:07:27.070><c> these</c>

00:07:27.210 --> 00:07:27.220 align:start position:0%
mouth and nose and then composing these
 

00:07:27.220 --> 00:07:30.570 align:start position:0%
mouth and nose and then composing these
features<00:07:27.580><c> together</c><00:07:27.790><c> to</c><00:07:28.890><c> detect</c><00:07:29.890><c> higher-level</c>

00:07:30.570 --> 00:07:30.580 align:start position:0%
features together to detect higher-level
 

00:07:30.580 --> 00:07:34.080 align:start position:0%
features together to detect higher-level
structures<00:07:31.390><c> in</c><00:07:31.630><c> the</c><00:07:31.750><c> face</c><00:07:32.370><c> and</c><00:07:33.370><c> and</c><00:07:33.790><c> this</c><00:07:33.940><c> is</c>

00:07:34.080 --> 00:07:34.090 align:start position:0%
structures in the face and and this is
 

00:07:34.090 --> 00:07:35.430 align:start position:0%
structures in the face and and this is
all<00:07:34.240><c> performed</c><00:07:34.690><c> in</c><00:07:34.780><c> a</c><00:07:34.840><c> hierarchical</c><00:07:35.260><c> manner</c>

00:07:35.430 --> 00:07:35.440 align:start position:0%
all performed in a hierarchical manner
 

00:07:35.440 --> 00:07:37.200 align:start position:0%
all performed in a hierarchical manner
so<00:07:35.890><c> the</c><00:07:36.040><c> question</c><00:07:36.370><c> of</c><00:07:36.490><c> deep</c><00:07:36.640><c> learning</c><00:07:36.820><c> is</c><00:07:37.060><c> how</c>

00:07:37.200 --> 00:07:37.210 align:start position:0%
so the question of deep learning is how
 

00:07:37.210 --> 00:07:40.560 align:start position:0%
so the question of deep learning is how
can<00:07:37.390><c> we</c><00:07:37.540><c> go</c><00:07:37.720><c> from</c><00:07:38.290><c> raw</c><00:07:38.590><c> image</c><00:07:39.010><c> pixels</c><00:07:39.640><c> or</c><00:07:39.910><c> raw</c>

00:07:40.560 --> 00:07:40.570 align:start position:0%
can we go from raw image pixels or raw
 

00:07:40.570 --> 00:07:44.520 align:start position:0%
can we go from raw image pixels or raw
data<00:07:40.870><c> in</c><00:07:41.200><c> general</c><00:07:41.800><c> to</c><00:07:42.700><c> a</c><00:07:43.000><c> more</c><00:07:43.780><c> complex</c><00:07:44.320><c> and</c>

00:07:44.520 --> 00:07:44.530 align:start position:0%
data in general to a more complex and
 

00:07:44.530 --> 00:07:46.530 align:start position:0%
data in general to a more complex and
complex<00:07:44.950><c> representation</c><00:07:45.669><c> as</c><00:07:45.850><c> the</c><00:07:46.060><c> data</c><00:07:46.240><c> flows</c>

00:07:46.530 --> 00:07:46.540 align:start position:0%
complex representation as the data flows
 

00:07:46.540 --> 00:07:50.580 align:start position:0%
complex representation as the data flows
through<00:07:46.780><c> the</c><00:07:46.900><c> model</c><00:07:48.210><c> and</c><00:07:49.350><c> actually</c><00:07:50.350><c> the</c>

00:07:50.580 --> 00:07:50.590 align:start position:0%
through the model and actually the
 

00:07:50.590 --> 00:07:52.620 align:start position:0%
through the model and actually the
fundamental<00:07:51.130><c> fundamental</c><00:07:51.490><c> building</c><00:07:52.180><c> blocks</c>

00:07:52.620 --> 00:07:52.630 align:start position:0%
fundamental fundamental building blocks
 

00:07:52.630 --> 00:07:54.390 align:start position:0%
fundamental fundamental building blocks
of<00:07:52.780><c> deep</c><00:07:53.140><c> learning</c><00:07:53.320><c> have</c><00:07:53.740><c> existed</c><00:07:54.220><c> for</c>

00:07:54.390 --> 00:07:54.400 align:start position:0%
of deep learning have existed for
 

00:07:54.400 --> 00:07:57.240 align:start position:0%
of deep learning have existed for
decades<00:07:54.430><c> and</c><00:07:55.120><c> their</c><00:07:55.960><c> underlying</c><00:07:56.250><c> algorithms</c>

00:07:57.240 --> 00:07:57.250 align:start position:0%
decades and their underlying algorithms
 

00:07:57.250 --> 00:08:00.390 align:start position:0%
decades and their underlying algorithms
have<00:07:57.550><c> been</c><00:07:57.580><c> studied</c><00:07:58.030><c> for</c><00:07:59.010><c> many</c><00:08:00.010><c> years</c><00:08:00.280><c> even</c>

00:08:00.390 --> 00:08:00.400 align:start position:0%
have been studied for many years even
 

00:08:00.400 --> 00:08:02.310 align:start position:0%
have been studied for many years even
before<00:08:00.700><c> that</c><00:08:00.910><c> so</c><00:08:01.450><c> why</c><00:08:01.600><c> are</c><00:08:01.690><c> we</c><00:08:01.840><c> studying</c><00:08:02.050><c> this</c>

00:08:02.310 --> 00:08:02.320 align:start position:0%
before that so why are we studying this
 

00:08:02.320 --> 00:08:06.720 align:start position:0%
before that so why are we studying this
now<00:08:02.500><c> well</c><00:08:03.310><c> for</c><00:08:03.520><c> one</c><00:08:04.380><c> data</c><00:08:05.380><c> has</c><00:08:05.620><c> become</c><00:08:06.010><c> so</c>

00:08:06.720 --> 00:08:06.730 align:start position:0%
now well for one data has become so
 

00:08:06.730 --> 00:08:08.340 align:start position:0%
now well for one data has become so
prevalent<00:08:07.030><c> in</c><00:08:07.390><c> today's</c><00:08:07.720><c> society</c><00:08:07.930><c> we're</c>

00:08:08.340 --> 00:08:08.350 align:start position:0%
prevalent in today's society we're
 

00:08:08.350 --> 00:08:11.250 align:start position:0%
prevalent in today's society we're
living<00:08:08.380><c> in</c><00:08:08.770><c> the</c><00:08:08.890><c> age</c><00:08:09.010><c> of</c><00:08:09.280><c> big</c><00:08:09.550><c> data</c><00:08:10.110><c> where</c><00:08:11.110><c> we</c>

00:08:11.250 --> 00:08:11.260 align:start position:0%
living in the age of big data where we
 

00:08:11.260 --> 00:08:12.900 align:start position:0%
living in the age of big data where we
have<00:08:11.350><c> more</c><00:08:11.620><c> access</c><00:08:11.860><c> to</c><00:08:12.280><c> data</c><00:08:12.490><c> than</c><00:08:12.760><c> ever</c>

00:08:12.900 --> 00:08:12.910 align:start position:0%
have more access to data than ever
 

00:08:12.910 --> 00:08:14.909 align:start position:0%
have more access to data than ever
before<00:08:13.330><c> and</c><00:08:13.510><c> these</c><00:08:13.630><c> models</c><00:08:13.930><c> are</c><00:08:14.260><c> hungry</c><00:08:14.740><c> for</c>

00:08:14.909 --> 00:08:14.919 align:start position:0%
before and these models are hungry for
 

00:08:14.919 --> 00:08:17.580 align:start position:0%
before and these models are hungry for
data<00:08:15.520><c> so</c><00:08:16.150><c> we</c><00:08:16.570><c> need</c><00:08:16.750><c> to</c><00:08:16.870><c> feed</c><00:08:17.080><c> them</c><00:08:17.290><c> with</c><00:08:17.410><c> all</c>

00:08:17.580 --> 00:08:17.590 align:start position:0%
data so we need to feed them with all
 

00:08:17.590 --> 00:08:19.290 align:start position:0%
data so we need to feed them with all
the<00:08:17.740><c> data</c><00:08:17.919><c> and</c><00:08:18.160><c> a</c><00:08:18.310><c> lot</c><00:08:18.490><c> of</c><00:08:18.520><c> this</c><00:08:18.730><c> datasets</c><00:08:19.180><c> that</c>

00:08:19.290 --> 00:08:19.300 align:start position:0%
the data and a lot of this datasets that
 

00:08:19.300 --> 00:08:21.210 align:start position:0%
the data and a lot of this datasets that
we<00:08:19.419><c> have</c><00:08:19.600><c> available</c><00:08:19.810><c> like</c><00:08:20.530><c> computer</c><00:08:20.950><c> vision</c>

00:08:21.210 --> 00:08:21.220 align:start position:0%
we have available like computer vision
 

00:08:21.220 --> 00:08:22.500 align:start position:0%
we have available like computer vision
datasets<00:08:21.580><c> natural</c><00:08:22.240><c> language</c><00:08:22.480><c> processing</c>

00:08:22.500 --> 00:08:22.510 align:start position:0%
datasets natural language processing
 

00:08:22.510 --> 00:08:25.320 align:start position:0%
datasets natural language processing
datasets<00:08:23.230><c> this</c><00:08:23.950><c> raw</c><00:08:24.280><c> amount</c><00:08:24.700><c> of</c><00:08:24.850><c> data</c><00:08:25.000><c> was</c>

00:08:25.320 --> 00:08:25.330 align:start position:0%
datasets this raw amount of data was
 

00:08:25.330 --> 00:08:27.570 align:start position:0%
datasets this raw amount of data was
just<00:08:25.600><c> not</c><00:08:25.870><c> available</c><00:08:26.080><c> when</c><00:08:26.950><c> these</c><00:08:27.070><c> algorithms</c>

00:08:27.570 --> 00:08:27.580 align:start position:0%
just not available when these algorithms
 

00:08:27.580 --> 00:08:30.810 align:start position:0%
just not available when these algorithms
were<00:08:27.700><c> created</c><00:08:28.800><c> second</c><00:08:29.800><c> these</c><00:08:30.220><c> algorithms</c>

00:08:30.810 --> 00:08:30.820 align:start position:0%
were created second these algorithms
 

00:08:30.820 --> 00:08:33.870 align:start position:0%
were created second these algorithms
require<00:08:30.940><c> or</c><00:08:31.840><c> these</c><00:08:32.469><c> albums</c><00:08:32.830><c> are</c><00:08:33.070><c> massively</c>

00:08:33.870 --> 00:08:33.880 align:start position:0%
require or these albums are massively
 

00:08:33.880 --> 00:08:36.029 align:start position:0%
require or these albums are massively
parallel<00:08:34.240><c> lies</c><00:08:34.599><c> about</c><00:08:34.900><c> their</c><00:08:35.289><c> core</c><00:08:35.620><c> at</c><00:08:35.860><c> their</c>

00:08:36.029 --> 00:08:36.039 align:start position:0%
parallel lies about their core at their
 

00:08:36.039 --> 00:08:37.469 align:start position:0%
parallel lies about their core at their
most<00:08:36.250><c> fundamental</c><00:08:36.400><c> building</c><00:08:36.969><c> blocks</c><00:08:37.360><c> that</c>

00:08:37.469 --> 00:08:37.479 align:start position:0%
most fundamental building blocks that
 

00:08:37.479 --> 00:08:39.060 align:start position:0%
most fundamental building blocks that
you'll<00:08:37.719><c> learn</c><00:08:37.810><c> today</c><00:08:38.140><c> they're</c><00:08:38.560><c> massively</c>

00:08:39.060 --> 00:08:39.070 align:start position:0%
you'll learn today they're massively
 

00:08:39.070 --> 00:08:41.219 align:start position:0%
you'll learn today they're massively
paralyzed<00:08:39.550><c> Abul</c><00:08:39.909><c> and</c><00:08:40.089><c> this</c><00:08:40.659><c> means</c><00:08:40.930><c> that</c><00:08:41.050><c> they</c>

00:08:41.219 --> 00:08:41.229 align:start position:0%
paralyzed Abul and this means that they
 

00:08:41.229 --> 00:08:43.230 align:start position:0%
paralyzed Abul and this means that they
can<00:08:41.380><c> benefit</c><00:08:41.800><c> tremendously</c><00:08:42.130><c> from</c><00:08:42.669><c> very</c>

00:08:43.230 --> 00:08:43.240 align:start position:0%
can benefit tremendously from very
 

00:08:43.240 --> 00:08:46.280 align:start position:0%
can benefit tremendously from very
specialized<00:08:43.870><c> hardware</c><00:08:44.800><c> such</c><00:08:45.220><c> as</c><00:08:45.250><c> GPUs</c><00:08:45.910><c> and</c>

00:08:46.280 --> 00:08:46.290 align:start position:0%
specialized hardware such as GPUs and
 

00:08:46.290 --> 00:08:50.100 align:start position:0%
specialized hardware such as GPUs and
again<00:08:47.290><c> technology</c><00:08:48.280><c> like</c><00:08:48.700><c> these</c><00:08:48.970><c> GPUs</c><00:08:49.420><c> simply</c>

00:08:50.100 --> 00:08:50.110 align:start position:0%
again technology like these GPUs simply
 

00:08:50.110 --> 00:08:52.680 align:start position:0%
again technology like these GPUs simply
did<00:08:50.290><c> not</c><00:08:50.320><c> exist</c><00:08:50.589><c> in</c><00:08:51.100><c> the</c><00:08:51.610><c> decades</c><00:08:52.030><c> that</c><00:08:52.450><c> deep</c>

00:08:52.680 --> 00:08:52.690 align:start position:0%
did not exist in the decades that deep
 

00:08:52.690 --> 00:08:54.450 align:start position:0%
did not exist in the decades that deep
learning<00:08:53.080><c> or</c><00:08:53.500><c> the</c><00:08:53.530><c> foundations</c><00:08:54.190><c> of</c><00:08:54.280><c> deep</c>

00:08:54.450 --> 00:08:54.460 align:start position:0%
learning or the foundations of deep
 

00:08:54.460 --> 00:08:55.290 align:start position:0%
learning or the foundations of deep
learning<00:08:54.640><c> were</c><00:08:54.910><c> devil</c>

00:08:55.290 --> 00:08:55.300 align:start position:0%
learning were devil
 

00:08:55.300 --> 00:08:57.990 align:start position:0%
learning were devil
and<00:08:55.830><c> finally</c><00:08:56.830><c> due</c><00:08:57.130><c> to</c><00:08:57.160><c> open-source</c><00:08:57.760><c> tool</c>

00:08:57.990 --> 00:08:58.000 align:start position:0%
and finally due to open-source tool
 

00:08:58.000 --> 00:08:59.670 align:start position:0%
and finally due to open-source tool
boxes<00:08:58.360><c> like</c><00:08:58.540><c> tensorflow</c><00:08:58.930><c> which</c><00:08:59.380><c> will</c><00:08:59.560><c> you</c>

00:08:59.670 --> 00:08:59.680 align:start position:0%
boxes like tensorflow which will you
 

00:08:59.680 --> 00:09:01.980 align:start position:0%
boxes like tensorflow which will you
learn<00:08:59.890><c> to</c><00:09:00.100><c> use</c><00:09:00.130><c> in</c><00:09:00.370><c> this</c><00:09:00.520><c> class</c><00:09:00.840><c> building</c><00:09:01.840><c> and</c>

00:09:01.980 --> 00:09:01.990 align:start position:0%
learn to use in this class building and
 

00:09:01.990 --> 00:09:04.260 align:start position:0%
learn to use in this class building and
deploying<00:09:02.110><c> these</c><00:09:02.500><c> models</c><00:09:02.890><c> has</c><00:09:03.100><c> become</c><00:09:03.490><c> more</c>

00:09:04.260 --> 00:09:04.270 align:start position:0%
deploying these models has become more
 

00:09:04.270 --> 00:09:05.880 align:start position:0%
deploying these models has become more
streamlined<00:09:04.750><c> than</c><00:09:04.900><c> ever</c><00:09:05.170><c> before</c><00:09:05.560><c> it</c><00:09:05.770><c> is</c>

00:09:05.880 --> 00:09:05.890 align:start position:0%
streamlined than ever before it is
 

00:09:05.890 --> 00:09:07.650 align:start position:0%
streamlined than ever before it is
becoming<00:09:06.190><c> increasingly</c><00:09:06.400><c> and</c><00:09:07.060><c> increasingly</c>

00:09:07.650 --> 00:09:07.660 align:start position:0%
becoming increasingly and increasingly
 

00:09:07.660 --> 00:09:11.340 align:start position:0%
becoming increasingly and increasingly
easy<00:09:08.350><c> to</c><00:09:09.130><c> abstract</c><00:09:10.000><c> away</c><00:09:10.270><c> all</c><00:09:10.600><c> of</c><00:09:10.630><c> the</c><00:09:10.870><c> details</c>

00:09:11.340 --> 00:09:11.350 align:start position:0%
easy to abstract away all of the details
 

00:09:11.350 --> 00:09:13.590 align:start position:0%
easy to abstract away all of the details
and<00:09:11.710><c> build</c><00:09:12.370><c> a</c><00:09:12.520><c> neural</c><00:09:12.760><c> network</c><00:09:12.940><c> and</c><00:09:13.360><c> train</c><00:09:13.570><c> a</c>

00:09:13.590 --> 00:09:13.600 align:start position:0%
and build a neural network and train a
 

00:09:13.600 --> 00:09:14.850 align:start position:0%
and build a neural network and train a
neural<00:09:13.780><c> network</c><00:09:14.110><c> and</c><00:09:14.200><c> then</c><00:09:14.350><c> deploy</c><00:09:14.650><c> that</c>

00:09:14.850 --> 00:09:14.860 align:start position:0%
neural network and then deploy that
 

00:09:14.860 --> 00:09:17.550 align:start position:0%
neural network and then deploy that
neural<00:09:15.070><c> network</c><00:09:15.370><c> in</c><00:09:15.580><c> practice</c><00:09:16.330><c> to</c><00:09:16.960><c> solve</c><00:09:17.440><c> a</c>

00:09:17.550 --> 00:09:17.560 align:start position:0%
neural network in practice to solve a
 

00:09:17.560 --> 00:09:19.860 align:start position:0%
neural network in practice to solve a
very<00:09:17.740><c> complex</c><00:09:18.130><c> problem</c><00:09:18.400><c> in</c><00:09:18.700><c> just</c><00:09:18.850><c> tens</c><00:09:19.690><c> of</c>

00:09:19.860 --> 00:09:19.870 align:start position:0%
very complex problem in just tens of
 

00:09:19.870 --> 00:09:21.390 align:start position:0%
very complex problem in just tens of
lines<00:09:20.050><c> of</c><00:09:20.200><c> code</c><00:09:20.410><c> you</c><00:09:20.560><c> can</c><00:09:20.710><c> solve</c><00:09:21.010><c> you</c><00:09:21.220><c> can</c>

00:09:21.390 --> 00:09:21.400 align:start position:0%
lines of code you can solve you can
 

00:09:21.400 --> 00:09:23.910 align:start position:0%
lines of code you can solve you can
create<00:09:21.910><c> a</c><00:09:21.970><c> facial</c><00:09:22.780><c> classifier</c><00:09:23.260><c> that's</c>

00:09:23.910 --> 00:09:23.920 align:start position:0%
create a facial classifier that's
 

00:09:23.920 --> 00:09:26.220 align:start position:0%
create a facial classifier that's
capable<00:09:24.430><c> of</c><00:09:24.790><c> recognizing</c><00:09:24.940><c> very</c><00:09:25.780><c> complex</c>

00:09:26.220 --> 00:09:26.230 align:start position:0%
capable of recognizing very complex
 

00:09:26.230 --> 00:09:30.930 align:start position:0%
capable of recognizing very complex
faces<00:09:27.010><c> from</c><00:09:27.250><c> the</c><00:09:27.490><c> environment</c><00:09:27.700><c> so</c><00:09:29.940><c> let's</c>

00:09:30.930 --> 00:09:30.940 align:start position:0%
faces from the environment so let's
 

00:09:30.940 --> 00:09:32.760 align:start position:0%
faces from the environment so let's
start<00:09:31.180><c> with</c><00:09:31.300><c> the</c><00:09:31.810><c> most</c><00:09:32.020><c> fundamental</c><00:09:32.110><c> building</c>

00:09:32.760 --> 00:09:32.770 align:start position:0%
start with the most fundamental building
 

00:09:32.770 --> 00:09:35.400 align:start position:0%
start with the most fundamental building
block<00:09:33.130><c> of</c><00:09:33.310><c> deep</c><00:09:33.640><c> learning</c><00:09:33.850><c> and</c><00:09:34.570><c> that's</c><00:09:35.200><c> the</c>

00:09:35.400 --> 00:09:35.410 align:start position:0%
block of deep learning and that's the
 

00:09:35.410 --> 00:09:36.870 align:start position:0%
block of deep learning and that's the
fundamental<00:09:35.590><c> building</c><00:09:36.040><c> block</c><00:09:36.370><c> that</c><00:09:36.520><c> makes</c><00:09:36.730><c> up</c>

00:09:36.870 --> 00:09:36.880 align:start position:0%
fundamental building block that makes up
 

00:09:36.880 --> 00:09:39.030 align:start position:0%
fundamental building block that makes up
a<00:09:36.970><c> neural</c><00:09:37.240><c> network</c><00:09:37.420><c> and</c><00:09:37.780><c> that</c><00:09:37.870><c> is</c><00:09:38.020><c> a</c><00:09:38.050><c> neuron</c><00:09:38.440><c> so</c>

00:09:39.030 --> 00:09:39.040 align:start position:0%
a neural network and that is a neuron so
 

00:09:39.040 --> 00:09:41.520 align:start position:0%
a neural network and that is a neuron so
what<00:09:39.220><c> is</c><00:09:39.310><c> the</c><00:09:39.400><c> neuron</c><00:09:39.640><c> in</c><00:09:40.080><c> deep</c><00:09:41.080><c> learning</c><00:09:41.260><c> we</c>

00:09:41.520 --> 00:09:41.530 align:start position:0%
what is the neuron in deep learning we
 

00:09:41.530 --> 00:09:44.280 align:start position:0%
what is the neuron in deep learning we
call<00:09:41.710><c> it</c><00:09:41.800><c> a</c><00:09:41.860><c> perceptron</c><00:09:42.550><c> and</c><00:09:43.110><c> how</c><00:09:44.110><c> does</c><00:09:44.170><c> it</c>

00:09:44.280 --> 00:09:44.290 align:start position:0%
call it a perceptron and how does it
 

00:09:44.290 --> 00:09:48.270 align:start position:0%
call it a perceptron and how does it
work<00:09:45.690><c> so</c><00:09:46.690><c> the</c><00:09:47.020><c> idea</c><00:09:47.290><c> of</c><00:09:47.320><c> a</c><00:09:47.440><c> perceptron</c><00:09:47.920><c> or</c><00:09:48.190><c> a</c>

00:09:48.270 --> 00:09:48.280 align:start position:0%
work so the idea of a perceptron or a
 

00:09:48.280 --> 00:09:51.450 align:start position:0%
work so the idea of a perceptron or a
single<00:09:48.580><c> neuron</c><00:09:48.970><c> is</c><00:09:49.300><c> very</c><00:09:49.630><c> simple</c><00:09:50.130><c> let's</c><00:09:51.130><c> start</c>

00:09:51.450 --> 00:09:51.460 align:start position:0%
single neuron is very simple let's start
 

00:09:51.460 --> 00:09:53.370 align:start position:0%
single neuron is very simple let's start
by<00:09:51.670><c> talking</c><00:09:51.910><c> about</c><00:09:52.150><c> and</c><00:09:52.570><c> describing</c><00:09:52.990><c> the</c>

00:09:53.370 --> 00:09:53.380 align:start position:0%
by talking about and describing the
 

00:09:53.380 --> 00:09:56.850 align:start position:0%
by talking about and describing the
feed-forward<00:09:54.990><c> information</c><00:09:55.990><c> of</c><00:09:56.170><c> information</c>

00:09:56.850 --> 00:09:56.860 align:start position:0%
feed-forward information of information
 

00:09:56.860 --> 00:09:59.970 align:start position:0%
feed-forward information of information
through<00:09:57.250><c> that</c><00:09:57.400><c> model</c><00:09:58.290><c> we</c><00:09:59.290><c> define</c><00:09:59.620><c> a</c><00:09:59.650><c> set</c><00:09:59.890><c> of</c>

00:09:59.970 --> 00:09:59.980 align:start position:0%
through that model we define a set of
 

00:09:59.980 --> 00:10:02.880 align:start position:0%
through that model we define a set of
inputs<00:10:00.400><c> x1</c><00:10:00.970><c> through</c><00:10:01.600><c> XM</c><00:10:02.020><c> which</c><00:10:02.500><c> you</c><00:10:02.620><c> can</c><00:10:02.740><c> see</c>

00:10:02.880 --> 00:10:02.890 align:start position:0%
inputs x1 through XM which you can see
 

00:10:02.890 --> 00:10:05.820 align:start position:0%
inputs x1 through XM which you can see
on<00:10:02.980><c> the</c><00:10:03.100><c> left</c><00:10:03.280><c> hand</c><00:10:03.460><c> side</c><00:10:03.670><c> and</c><00:10:04.530><c> each</c><00:10:05.530><c> of</c><00:10:05.710><c> these</c>

00:10:05.820 --> 00:10:05.830 align:start position:0%
on the left hand side and each of these
 

00:10:05.830 --> 00:10:07.440 align:start position:0%
on the left hand side and each of these
inputs<00:10:06.040><c> are</c><00:10:06.370><c> actually</c><00:10:06.670><c> multiplied</c><00:10:07.210><c> by</c><00:10:07.420><c> a</c>

00:10:07.440 --> 00:10:07.450 align:start position:0%
inputs are actually multiplied by a
 

00:10:07.450 --> 00:10:13.650 align:start position:0%
inputs are actually multiplied by a
corresponding<00:10:08.260><c> weight</c><00:10:08.470><c> w1</c><00:10:09.280><c> through</c><00:10:09.880><c> WM</c><00:10:12.660><c> so</c>

00:10:13.650 --> 00:10:13.660 align:start position:0%
corresponding weight w1 through WM so
 

00:10:13.660 --> 00:10:16.920 align:start position:0%
corresponding weight w1 through WM so
you<00:10:13.750><c> can</c><00:10:14.020><c> imagine</c><00:10:14.410><c> if</c><00:10:14.560><c> you</c><00:10:14.650><c> have</c><00:10:14.830><c> x1</c><00:10:15.580><c> you</c><00:10:15.970><c> x</c><00:10:16.330><c> w1</c>

00:10:16.920 --> 00:10:16.930 align:start position:0%
you can imagine if you have x1 you x w1
 

00:10:16.930 --> 00:10:20.100 align:start position:0%
you can imagine if you have x1 you x w1
you<00:10:17.260><c> have</c><00:10:17.350><c> x2</c><00:10:17.680><c> you</c><00:10:17.770><c> x</c><00:10:18.130><c> w2</c><00:10:18.670><c> and</c><00:10:18.940><c> so</c><00:10:19.210><c> on</c><00:10:19.390><c> you</c><00:10:19.900><c> take</c>

00:10:20.100 --> 00:10:20.110 align:start position:0%
you have x2 you x w2 and so on you take
 

00:10:20.110 --> 00:10:22.320 align:start position:0%
you have x2 you x w2 and so on you take
all<00:10:20.320><c> of</c><00:10:20.350><c> those</c><00:10:20.820><c> multiplications</c><00:10:21.820><c> and</c><00:10:22.030><c> you</c><00:10:22.180><c> add</c>

00:10:22.320 --> 00:10:22.330 align:start position:0%
all of those multiplications and you add
 

00:10:22.330 --> 00:10:24.390 align:start position:0%
all of those multiplications and you add
them<00:10:22.570><c> up</c><00:10:22.720><c> so</c><00:10:23.530><c> these</c><00:10:23.680><c> come</c><00:10:23.920><c> together</c><00:10:24.070><c> in</c><00:10:24.340><c> a</c>

00:10:24.390 --> 00:10:24.400 align:start position:0%
them up so these come together in a
 

00:10:24.400 --> 00:10:26.640 align:start position:0%
them up so these come together in a
summation<00:10:24.670><c> and</c><00:10:25.090><c> then</c><00:10:25.930><c> you</c><00:10:26.050><c> pass</c><00:10:26.320><c> this</c>

00:10:26.640 --> 00:10:26.650 align:start position:0%
summation and then you pass this
 

00:10:26.650 --> 00:10:29.250 align:start position:0%
summation and then you pass this
weighted<00:10:27.430><c> sum</c><00:10:27.760><c> through</c><00:10:28.480><c> a</c><00:10:28.510><c> nonlinear</c>

00:10:29.250 --> 00:10:29.260 align:start position:0%
weighted sum through a nonlinear
 

00:10:29.260 --> 00:10:31.230 align:start position:0%
weighted sum through a nonlinear
activation<00:10:29.650><c> function</c><00:10:30.190><c> to</c><00:10:30.430><c> produce</c><00:10:30.550><c> a</c><00:10:30.910><c> final</c>

00:10:31.230 --> 00:10:31.240 align:start position:0%
activation function to produce a final
 

00:10:31.240 --> 00:10:36.180 align:start position:0%
activation function to produce a final
output<00:10:31.750><c> which</c><00:10:32.200><c> we'll</c><00:10:32.440><c> call</c><00:10:32.740><c> Y</c><00:10:35.040><c> so</c><00:10:36.040><c> that's</c>

00:10:36.180 --> 00:10:36.190 align:start position:0%
output which we'll call Y so that's
 

00:10:36.190 --> 00:10:40.230 align:start position:0%
output which we'll call Y so that's
really<00:10:36.400><c> simple</c><00:10:36.780><c> let's</c><00:10:37.780><c> I</c><00:10:38.490><c> actually</c><00:10:39.490><c> left</c><00:10:40.060><c> out</c>

00:10:40.230 --> 00:10:40.240 align:start position:0%
really simple let's I actually left out
 

00:10:40.240 --> 00:10:41.820 align:start position:0%
really simple let's I actually left out
one<00:10:40.420><c> detail</c><00:10:40.600><c> in</c><00:10:40.870><c> that</c><00:10:40.990><c> previous</c><00:10:41.260><c> slide</c><00:10:41.380><c> so</c>

00:10:41.820 --> 00:10:41.830 align:start position:0%
one detail in that previous slide so
 

00:10:41.830 --> 00:10:44.280 align:start position:0%
one detail in that previous slide so
I'll<00:10:41.950><c> add</c><00:10:42.100><c> it</c><00:10:42.250><c> here</c><00:10:42.400><c> now</c><00:10:42.660><c> we</c><00:10:43.660><c> also</c><00:10:43.870><c> have</c><00:10:44.140><c> this</c>

00:10:44.280 --> 00:10:44.290 align:start position:0%
I'll add it here now we also have this
 

00:10:44.290 --> 00:10:46.830 align:start position:0%
I'll add it here now we also have this
other<00:10:44.440><c> turn</c><00:10:44.770><c> term</c><00:10:45.340><c> this</c><00:10:45.910><c> green</c><00:10:46.180><c> term</c><00:10:46.390><c> which</c><00:10:46.660><c> is</c>

00:10:46.830 --> 00:10:46.840 align:start position:0%
other turn term this green term which is
 

00:10:46.840 --> 00:10:48.960 align:start position:0%
other turn term this green term which is
a<00:10:47.020><c> bias</c><00:10:47.380><c> term</c><00:10:47.710><c> which</c><00:10:48.100><c> allows</c><00:10:48.370><c> you</c><00:10:48.550><c> to</c><00:10:48.670><c> shift</c>

00:10:48.960 --> 00:10:48.970 align:start position:0%
a bias term which allows you to shift
 

00:10:48.970 --> 00:10:51.030 align:start position:0%
a bias term which allows you to shift
your<00:10:49.150><c> activation</c><00:10:49.600><c> function</c><00:10:50.170><c> left</c><00:10:50.470><c> and</c><00:10:50.800><c> right</c>

00:10:51.030 --> 00:10:51.040 align:start position:0%
your activation function left and right
 

00:10:51.040 --> 00:10:54.330 align:start position:0%
your activation function left and right
and<00:10:52.290><c> now</c><00:10:53.290><c> on</c><00:10:53.440><c> the</c><00:10:53.530><c> right</c><00:10:53.680><c> side</c><00:10:53.890><c> you</c><00:10:54.010><c> can</c><00:10:54.040><c> kind</c>

00:10:54.330 --> 00:10:54.340 align:start position:0%
and now on the right side you can kind
 

00:10:54.340 --> 00:10:56.490 align:start position:0%
and now on the right side you can kind
of<00:10:54.400><c> see</c><00:10:54.700><c> this</c><00:10:55.090><c> diagram</c><00:10:55.540><c> illustrated</c><00:10:56.260><c> as</c><00:10:56.440><c> a</c>

00:10:56.490 --> 00:10:56.500 align:start position:0%
of see this diagram illustrated as a
 

00:10:56.500 --> 00:10:59.070 align:start position:0%
of see this diagram illustrated as a
mathematical<00:10:57.280><c> formula</c><00:10:57.730><c> as</c><00:10:57.910><c> a</c><00:10:58.630><c> single</c>

00:10:59.070 --> 00:10:59.080 align:start position:0%
mathematical formula as a single
 

00:10:59.080 --> 00:11:01.110 align:start position:0%
mathematical formula as a single
equation<00:10:59.290><c> we</c><00:11:00.100><c> can</c><00:11:00.250><c> actually</c><00:11:00.370><c> rewrite</c><00:11:00.730><c> this</c>

00:11:01.110 --> 00:11:01.120 align:start position:0%
equation we can actually rewrite this
 

00:11:01.120 --> 00:11:03.750 align:start position:0%
equation we can actually rewrite this
now<00:11:01.360><c> using</c><00:11:01.660><c> linear</c><00:11:02.080><c> algebra</c><00:11:02.590><c> using</c><00:11:03.010><c> vectors</c>

00:11:03.750 --> 00:11:03.760 align:start position:0%
now using linear algebra using vectors
 

00:11:03.760 --> 00:11:06.660 align:start position:0%
now using linear algebra using vectors
dot<00:11:04.300><c> products</c><00:11:04.690><c> and</c><00:11:04.870><c> matrices</c><00:11:05.370><c> so</c><00:11:06.370><c> let's</c><00:11:06.550><c> do</c>

00:11:06.660 --> 00:11:06.670 align:start position:0%
dot products and matrices so let's do
 

00:11:06.670 --> 00:11:09.240 align:start position:0%
dot products and matrices so let's do
that<00:11:07.140><c> so</c><00:11:08.140><c> now</c>

00:11:09.240 --> 00:11:09.250 align:start position:0%
that so now
 

00:11:09.250 --> 00:11:12.450 align:start position:0%
that so now
is<00:11:09.460><c> a</c><00:11:09.910><c> vector</c><00:11:10.600><c> of</c><00:11:10.810><c> our</c><00:11:10.930><c> inputs</c><00:11:11.350><c> x1</c><00:11:11.920><c> through</c><00:11:12.310><c> M</c>

00:11:12.450 --> 00:11:12.460 align:start position:0%
is a vector of our inputs x1 through M
 

00:11:12.460 --> 00:11:14.790 align:start position:0%
is a vector of our inputs x1 through M
so<00:11:13.270><c> instead</c><00:11:13.510><c> of</c><00:11:13.660><c> now</c><00:11:13.780><c> a</c><00:11:13.810><c> single</c><00:11:14.260><c> number</c><00:11:14.410><c> X</c>

00:11:14.790 --> 00:11:14.800 align:start position:0%
so instead of now a single number X
 

00:11:14.800 --> 00:11:17.160 align:start position:0%
so instead of now a single number X
capital<00:11:15.370><c> X</c><00:11:15.610><c> is</c><00:11:15.910><c> a</c><00:11:16.240><c> vector</c><00:11:16.540><c> of</c><00:11:16.720><c> all</c><00:11:16.930><c> of</c><00:11:17.050><c> the</c>

00:11:17.160 --> 00:11:17.170 align:start position:0%
capital X is a vector of all of the
 

00:11:17.170 --> 00:11:20.160 align:start position:0%
capital X is a vector of all of the
inputs<00:11:17.550><c> capital</c><00:11:18.550><c> W</c><00:11:19.000><c> is</c><00:11:19.210><c> a</c><00:11:19.270><c> vector</c><00:11:19.780><c> of</c><00:11:19.870><c> all</c><00:11:20.050><c> of</c>

00:11:20.160 --> 00:11:20.170 align:start position:0%
inputs capital W is a vector of all of
 

00:11:20.170 --> 00:11:22.860 align:start position:0%
inputs capital W is a vector of all of
the<00:11:20.320><c> weights</c><00:11:20.530><c> 1</c><00:11:21.040><c> through</c><00:11:21.250><c> m</c><00:11:21.460><c> and</c><00:11:21.720><c> we</c><00:11:22.720><c> can</c>

00:11:22.860 --> 00:11:22.870 align:start position:0%
the weights 1 through m and we can
 

00:11:22.870 --> 00:11:24.870 align:start position:0%
the weights 1 through m and we can
simply<00:11:23.200><c> take</c><00:11:23.410><c> their</c><00:11:23.650><c> weighted</c><00:11:24.010><c> sum</c><00:11:24.310><c> by</c><00:11:24.520><c> taking</c>

00:11:24.870 --> 00:11:24.880 align:start position:0%
simply take their weighted sum by taking
 

00:11:24.880 --> 00:11:26.340 align:start position:0%
simply take their weighted sum by taking
the<00:11:25.000><c> dot</c><00:11:25.210><c> product</c><00:11:25.540><c> between</c><00:11:25.930><c> these</c><00:11:26.290><c> two</c>

00:11:26.340 --> 00:11:26.350 align:start position:0%
the dot product between these two
 

00:11:26.350 --> 00:11:30.840 align:start position:0%
the dot product between these two
vectors<00:11:28.530><c> then</c><00:11:29.530><c> we</c><00:11:29.710><c> add</c><00:11:29.830><c> our</c><00:11:29.860><c> bias</c><00:11:30.220><c> like</c><00:11:30.550><c> I</c><00:11:30.670><c> said</c>

00:11:30.840 --> 00:11:30.850 align:start position:0%
vectors then we add our bias like I said
 

00:11:30.850 --> 00:11:33.060 align:start position:0%
vectors then we add our bias like I said
before<00:11:31.000><c> or</c><00:11:31.390><c> biased</c><00:11:32.110><c> now</c><00:11:32.260><c> is</c><00:11:32.410><c> a</c><00:11:32.440><c> single</c><00:11:32.680><c> number</c>

00:11:33.060 --> 00:11:33.070 align:start position:0%
before or biased now is a single number
 

00:11:33.070 --> 00:11:36.570 align:start position:0%
before or biased now is a single number
W<00:11:33.460><c> not</c><00:11:33.640><c> and</c><00:11:34.620><c> applying</c><00:11:35.620><c> that</c><00:11:35.710><c> non</c><00:11:36.010><c> linear</c><00:11:36.220><c> term</c>

00:11:36.570 --> 00:11:36.580 align:start position:0%
W not and applying that non linear term
 

00:11:36.580 --> 00:11:38.910 align:start position:0%
W not and applying that non linear term
so<00:11:36.820><c> the</c><00:11:37.360><c> nonlinear</c><00:11:37.810><c> term</c><00:11:38.050><c> transfers</c><00:11:38.650><c> that</c>

00:11:38.910 --> 00:11:38.920 align:start position:0%
so the nonlinear term transfers that
 

00:11:38.920 --> 00:11:41.520 align:start position:0%
so the nonlinear term transfers that
transforms<00:11:39.790><c> that</c><00:11:39.850><c> scalar</c><00:11:40.270><c> input</c><00:11:40.600><c> to</c><00:11:41.260><c> another</c>

00:11:41.520 --> 00:11:41.530 align:start position:0%
transforms that scalar input to another
 

00:11:41.530 --> 00:11:47.400 align:start position:0%
transforms that scalar input to another
scalar<00:11:42.010><c> output</c><00:11:42.190><c> Y</c><00:11:44.430><c> so</c><00:11:45.720><c> you</c><00:11:46.720><c> might</c><00:11:47.110><c> now</c><00:11:47.350><c> be</c>

00:11:47.400 --> 00:11:47.410 align:start position:0%
scalar output Y so you might now be
 

00:11:47.410 --> 00:11:49.380 align:start position:0%
scalar output Y so you might now be
wondering<00:11:47.980><c> what</c><00:11:48.550><c> is</c><00:11:48.580><c> this</c><00:11:48.880><c> thing</c><00:11:49.060><c> that</c><00:11:49.120><c> I've</c>

00:11:49.380 --> 00:11:49.390 align:start position:0%
wondering what is this thing that I've
 

00:11:49.390 --> 00:11:50.880 align:start position:0%
wondering what is this thing that I've
been<00:11:49.420><c> referring</c><00:11:49.690><c> to</c><00:11:49.960><c> as</c><00:11:50.080><c> an</c><00:11:50.530><c> activation</c>

00:11:50.880 --> 00:11:50.890 align:start position:0%
been referring to as an activation
 

00:11:50.890 --> 00:11:52.110 align:start position:0%
been referring to as an activation
function<00:11:51.100><c> I've</c><00:11:51.550><c> mentioned</c><00:11:51.940><c> it</c><00:11:52.000><c> a</c><00:11:52.090><c> couple</c>

00:11:52.110 --> 00:11:52.120 align:start position:0%
function I've mentioned it a couple
 

00:11:52.120 --> 00:11:53.970 align:start position:0%
function I've mentioned it a couple
times<00:11:52.540><c> I</c><00:11:52.750><c> called</c><00:11:53.200><c> it</c><00:11:53.320><c> by</c><00:11:53.410><c> a</c><00:11:53.440><c> couple</c><00:11:53.590><c> different</c>

00:11:53.970 --> 00:11:53.980 align:start position:0%
times I called it by a couple different
 

00:11:53.980 --> 00:11:55.890 align:start position:0%
times I called it by a couple different
names<00:11:54.160><c> first</c><00:11:54.460><c> was</c><00:11:54.760><c> a</c><00:11:54.970><c> nonlinear</c><00:11:55.720><c> function</c>

00:11:55.890 --> 00:11:55.900 align:start position:0%
names first was a nonlinear function
 

00:11:55.900 --> 00:11:58.410 align:start position:0%
names first was a nonlinear function
then<00:11:56.350><c> was</c><00:11:56.500><c> an</c><00:11:56.620><c> activation</c><00:11:56.950><c> function</c><00:11:57.300><c> what</c><00:11:58.300><c> is</c>

00:11:58.410 --> 00:11:58.420 align:start position:0%
then was an activation function what is
 

00:11:58.420 --> 00:11:58.680 align:start position:0%
then was an activation function what is
it

00:11:58.680 --> 00:11:58.690 align:start position:0%
it
 

00:11:58.690 --> 00:12:01.170 align:start position:0%
it
so<00:11:58.810><c> one</c><00:11:59.140><c> common</c><00:11:59.350><c> example</c><00:11:59.920><c> of</c><00:12:00.130><c> a</c><00:12:00.640><c> nonlinear</c>

00:12:01.170 --> 00:12:01.180 align:start position:0%
so one common example of a nonlinear
 

00:12:01.180 --> 00:12:02.850 align:start position:0%
so one common example of a nonlinear
activation<00:12:01.600><c> function</c><00:12:02.140><c> is</c><00:12:02.320><c> called</c><00:12:02.710><c> the</c>

00:12:02.850 --> 00:12:02.860 align:start position:0%
activation function is called the
 

00:12:02.860 --> 00:12:04.950 align:start position:0%
activation function is called the
sigmoid<00:12:03.130><c> function</c><00:12:03.820><c> and</c><00:12:04.030><c> you</c><00:12:04.420><c> can</c><00:12:04.570><c> see</c><00:12:04.750><c> one</c>

00:12:04.950 --> 00:12:04.960 align:start position:0%
sigmoid function and you can see one
 

00:12:04.960 --> 00:12:08.010 align:start position:0%
sigmoid function and you can see one
here<00:12:05.620><c> defined</c><00:12:06.250><c> on</c><00:12:06.370><c> the</c><00:12:06.520><c> bottom</c><00:12:06.820><c> right</c><00:12:07.060><c> this</c><00:12:07.870><c> is</c>

00:12:08.010 --> 00:12:08.020 align:start position:0%
here defined on the bottom right this is
 

00:12:08.020 --> 00:12:09.990 align:start position:0%
here defined on the bottom right this is
a<00:12:08.050><c> function</c><00:12:08.500><c> that</c><00:12:08.530><c> takes</c><00:12:08.680><c> as</c><00:12:09.130><c> input</c><00:12:09.460><c> any</c><00:12:09.670><c> real</c>

00:12:09.990 --> 00:12:10.000 align:start position:0%
a function that takes as input any real
 

00:12:10.000 --> 00:12:13.680 align:start position:0%
a function that takes as input any real
number<00:12:10.420><c> and</c><00:12:10.980><c> outputs</c><00:12:11.980><c> a</c><00:12:12.190><c> new</c><00:12:12.520><c> number</c><00:12:12.760><c> between</c>

00:12:13.680 --> 00:12:13.690 align:start position:0%
number and outputs a new number between
 

00:12:13.690 --> 00:12:16.260 align:start position:0%
number and outputs a new number between
0<00:12:14.200><c> and</c><00:12:14.290><c> 1</c><00:12:14.680><c> so</c><00:12:15.310><c> you</c><00:12:15.400><c> can</c><00:12:15.520><c> see</c><00:12:15.700><c> it's</c><00:12:15.820><c> essentially</c>

00:12:16.260 --> 00:12:16.270 align:start position:0%
0 and 1 so you can see it's essentially
 

00:12:16.270 --> 00:12:18.300 align:start position:0%
0 and 1 so you can see it's essentially
collapsing<00:12:16.930><c> your</c><00:12:17.080><c> input</c><00:12:17.470><c> between</c><00:12:17.680><c> this</c><00:12:18.100><c> range</c>

00:12:18.300 --> 00:12:18.310 align:start position:0%
collapsing your input between this range
 

00:12:18.310 --> 00:12:21.240 align:start position:0%
collapsing your input between this range
of<00:12:18.430><c> 0</c><00:12:18.730><c> and</c><00:12:18.880><c> 1</c><00:12:19.200><c> this</c><00:12:20.200><c> is</c><00:12:20.380><c> just</c><00:12:20.560><c> one</c><00:12:20.710><c> example</c><00:12:20.830><c> of</c>

00:12:21.240 --> 00:12:21.250 align:start position:0%
of 0 and 1 this is just one example of
 

00:12:21.250 --> 00:12:22.500 align:start position:0%
of 0 and 1 this is just one example of
an<00:12:21.370><c> activation</c><00:12:21.730><c> function</c><00:12:21.910><c> but</c><00:12:22.330><c> there</c><00:12:22.420><c> are</c>

00:12:22.500 --> 00:12:22.510 align:start position:0%
an activation function but there are
 

00:12:22.510 --> 00:12:24.510 align:start position:0%
an activation function but there are
many<00:12:22.810><c> many</c><00:12:23.050><c> many</c><00:12:23.350><c> activation</c><00:12:23.950><c> functions</c><00:12:24.340><c> used</c>

00:12:24.510 --> 00:12:24.520 align:start position:0%
many many many activation functions used
 

00:12:24.520 --> 00:12:25.350 align:start position:0%
many many many activation functions used
in<00:12:24.700><c> neural</c><00:12:24.910><c> networks</c>

00:12:25.350 --> 00:12:25.360 align:start position:0%
in neural networks
 

00:12:25.360 --> 00:12:28.020 align:start position:0%
in neural networks
here<00:12:26.200><c> are</c><00:12:26.290><c> some</c><00:12:26.410><c> common</c><00:12:26.590><c> ones</c><00:12:26.920><c> and</c><00:12:27.100><c> throughout</c>

00:12:28.020 --> 00:12:28.030 align:start position:0%
here are some common ones and throughout
 

00:12:28.030 --> 00:12:29.370 align:start position:0%
here are some common ones and throughout
this<00:12:28.150><c> presentation</c><00:12:28.450><c> you'll</c><00:12:28.930><c> see</c><00:12:29.170><c> these</c>

00:12:29.370 --> 00:12:29.380 align:start position:0%
this presentation you'll see these
 

00:12:29.380 --> 00:12:31.970 align:start position:0%
this presentation you'll see these
tensorflow<00:12:30.160><c> code</c><00:12:30.670><c> blocks</c><00:12:30.970><c> on</c><00:12:31.210><c> the</c><00:12:31.300><c> bottom</c>

00:12:31.970 --> 00:12:31.980 align:start position:0%
tensorflow code blocks on the bottom
 

00:12:31.980 --> 00:12:35.040 align:start position:0%
tensorflow code blocks on the bottom
like<00:12:32.980><c> like</c><00:12:33.280><c> this</c><00:12:33.490><c> for</c><00:12:33.640><c> example</c><00:12:33.880><c> and</c><00:12:34.240><c> I'll</c><00:12:34.720><c> just</c>

00:12:35.040 --> 00:12:35.050 align:start position:0%
like like this for example and I'll just
 

00:12:35.050 --> 00:12:37.380 align:start position:0%
like like this for example and I'll just
be<00:12:35.170><c> using</c><00:12:35.290><c> these</c><00:12:35.590><c> as</c><00:12:35.830><c> a</c><00:12:35.860><c> as</c><00:12:36.220><c> a</c><00:12:36.640><c> way</c><00:12:36.880><c> to</c><00:12:36.940><c> kind</c><00:12:37.240><c> of</c>

00:12:37.380 --> 00:12:37.390 align:start position:0%
be using these as a as a way to kind of
 

00:12:37.390 --> 00:12:39.810 align:start position:0%
be using these as a as a way to kind of
bridge<00:12:37.660><c> the</c><00:12:37.690><c> gap</c><00:12:38.650><c> between</c><00:12:38.680><c> the</c><00:12:39.400><c> theories</c><00:12:39.700><c> that</c>

00:12:39.810 --> 00:12:39.820 align:start position:0%
bridge the gap between the theories that
 

00:12:39.820 --> 00:12:41.430 align:start position:0%
bridge the gap between the theories that
you'll<00:12:39.970><c> learn</c><00:12:40.060><c> in</c><00:12:40.120><c> this</c><00:12:40.300><c> class</c><00:12:40.570><c> with</c><00:12:41.140><c> some</c><00:12:41.290><c> of</c>

00:12:41.430 --> 00:12:41.440 align:start position:0%
you'll learn in this class with some of
 

00:12:41.440 --> 00:12:42.870 align:start position:0%
you'll learn in this class with some of
the<00:12:41.530><c> tensor</c><00:12:41.860><c> flow</c><00:12:41.950><c> that</c><00:12:42.580><c> you'll</c><00:12:42.730><c> be</c>

00:12:42.870 --> 00:12:42.880 align:start position:0%
the tensor flow that you'll be
 

00:12:42.880 --> 00:12:45.330 align:start position:0%
the tensor flow that you'll be
practicing<00:12:43.120><c> in</c><00:12:43.720><c> the</c><00:12:43.900><c> labs</c><00:12:44.080><c> later</c><00:12:44.380><c> today</c><00:12:44.620><c> and</c>

00:12:45.330 --> 00:12:45.340 align:start position:0%
practicing in the labs later today and
 

00:12:45.340 --> 00:12:49.170 align:start position:0%
practicing in the labs later today and
through<00:12:46.180><c> the</c><00:12:46.240><c> week</c><00:12:46.500><c> so</c><00:12:47.500><c> the</c><00:12:48.490><c> sigmoid</c><00:12:48.880><c> function</c>

00:12:49.170 --> 00:12:49.180 align:start position:0%
through the week so the sigmoid function
 

00:12:49.180 --> 00:12:50.280 align:start position:0%
through the week so the sigmoid function
like<00:12:49.300><c> I</c><00:12:49.390><c> mentioned</c><00:12:49.720><c> before</c><00:12:49.810><c> which</c><00:12:50.110><c> you</c><00:12:50.170><c> can</c>

00:12:50.280 --> 00:12:50.290 align:start position:0%
like I mentioned before which you can
 

00:12:50.290 --> 00:12:52.470 align:start position:0%
like I mentioned before which you can
see<00:12:50.440><c> on</c><00:12:50.530><c> the</c><00:12:50.620><c> left-hand</c><00:12:50.920><c> side</c><00:12:51.130><c> is</c><00:12:51.700><c> useful</c><00:12:52.270><c> for</c>

00:12:52.470 --> 00:12:52.480 align:start position:0%
see on the left-hand side is useful for
 

00:12:52.480 --> 00:12:54.390 align:start position:0%
see on the left-hand side is useful for
modeling<00:12:52.960><c> probabilities</c><00:12:53.830><c> because</c><00:12:54.130><c> like</c><00:12:54.280><c> I</c>

00:12:54.390 --> 00:12:54.400 align:start position:0%
modeling probabilities because like I
 

00:12:54.400 --> 00:12:58.470 align:start position:0%
modeling probabilities because like I
said<00:12:54.460><c> it</c><00:12:54.990><c> collapses</c><00:12:55.990><c> your</c><00:12:56.170><c> your</c><00:12:56.470><c> input</c><00:12:57.480><c> to</c>

00:12:58.470 --> 00:12:58.480 align:start position:0%
said it collapses your your input to
 

00:12:58.480 --> 00:12:59.520 align:start position:0%
said it collapses your your input to
between<00:12:58.750><c> 0</c><00:12:59.170><c> &amp;</c><00:12:59.320><c> 1</c>

00:12:59.520 --> 00:12:59.530 align:start position:0%
between 0 &amp; 1
 

00:12:59.530 --> 00:13:01.350 align:start position:0%
between 0 &amp; 1
since<00:12:59.860><c> probabilities</c><00:13:00.460><c> are</c><00:13:00.610><c> modeled</c><00:13:00.970><c> between</c>

00:13:01.350 --> 00:13:01.360 align:start position:0%
since probabilities are modeled between
 

00:13:01.360 --> 00:13:03.990 align:start position:0%
since probabilities are modeled between
0<00:13:01.630><c> &amp;</c><00:13:01.810><c> 1</c><00:13:02.220><c> this</c><00:13:03.220><c> is</c><00:13:03.370><c> actually</c><00:13:03.670><c> the</c><00:13:03.760><c> perfect</c>

00:13:03.990 --> 00:13:04.000 align:start position:0%
0 &amp; 1 this is actually the perfect
 

00:13:04.000 --> 00:13:05.760 align:start position:0%
0 &amp; 1 this is actually the perfect
activation<00:13:04.780><c> function</c><00:13:05.110><c> for</c><00:13:05.290><c> the</c><00:13:05.380><c> end</c><00:13:05.530><c> of</c><00:13:05.650><c> your</c>

00:13:05.760 --> 00:13:05.770 align:start position:0%
activation function for the end of your
 

00:13:05.770 --> 00:13:07.230 align:start position:0%
activation function for the end of your
neural<00:13:06.040><c> network</c><00:13:06.310><c> if</c><00:13:06.460><c> you</c><00:13:06.580><c> want</c><00:13:06.760><c> to</c><00:13:06.910><c> predict</c>

00:13:07.230 --> 00:13:07.240 align:start position:0%
neural network if you want to predict
 

00:13:07.240 --> 00:13:08.940 align:start position:0%
neural network if you want to predict
probability<00:13:07.930><c> distributions</c><00:13:08.560><c> at</c><00:13:08.710><c> the</c><00:13:08.830><c> end</c>

00:13:08.940 --> 00:13:08.950 align:start position:0%
probability distributions at the end
 

00:13:08.950 --> 00:13:11.640 align:start position:0%
probability distributions at the end
another<00:13:09.880><c> popular</c><00:13:10.450><c> option</c><00:13:10.480><c> is</c><00:13:10.930><c> the</c><00:13:11.410><c> r</c><00:13:11.440><c> lu</c>

00:13:11.640 --> 00:13:11.650 align:start position:0%
another popular option is the r lu
 

00:13:11.650 --> 00:13:13.079 align:start position:0%
another popular option is the r lu
function<00:13:12.220><c> which</c><00:13:12.339><c> you</c><00:13:12.430><c> can</c><00:13:12.550><c> see</c><00:13:12.700><c> on</c><00:13:12.790><c> the</c><00:13:12.910><c> far</c>

00:13:13.079 --> 00:13:13.089 align:start position:0%
function which you can see on the far
 

00:13:13.089 --> 00:13:15.870 align:start position:0%
function which you can see on the far
right-hand<00:13:13.360><c> side</c><00:13:14.130><c> this</c><00:13:15.130><c> function</c><00:13:15.550><c> is</c><00:13:15.700><c> an</c>

00:13:15.870 --> 00:13:15.880 align:start position:0%
right-hand side this function is an
 

00:13:15.880 --> 00:13:17.579 align:start position:0%
right-hand side this function is an
extremely<00:13:16.450><c> simple</c><00:13:16.630><c> one</c><00:13:16.900><c> to</c><00:13:17.020><c> compute</c><00:13:17.320><c> it's</c>

00:13:17.579 --> 00:13:17.589 align:start position:0%
extremely simple one to compute it's
 

00:13:17.589 --> 00:13:20.640 align:start position:0%
extremely simple one to compute it's
piecewise<00:13:18.160><c> linear</c><00:13:18.700><c> and</c><00:13:19.110><c> it's</c><00:13:20.110><c> very</c><00:13:20.350><c> popular</c>

00:13:20.640 --> 00:13:20.650 align:start position:0%
piecewise linear and it's very popular
 

00:13:20.650 --> 00:13:22.889 align:start position:0%
piecewise linear and it's very popular
because<00:13:21.100><c> it's</c><00:13:21.400><c> so</c><00:13:21.610><c> easy</c><00:13:21.880><c> to</c><00:13:22.120><c> compute</c><00:13:22.420><c> but</c>

00:13:22.889 --> 00:13:22.899 align:start position:0%
because it's so easy to compute but
 

00:13:22.899 --> 00:13:25.799 align:start position:0%
because it's so easy to compute but
has<00:13:23.050><c> this</c><00:13:23.259><c> non-linearity</c><00:13:23.860><c> at</c><00:13:24.339><c> Z</c><00:13:25.180><c> equals</c><00:13:25.569><c> zero</c>

00:13:25.799 --> 00:13:25.809 align:start position:0%
has this non-linearity at Z equals zero
 

00:13:25.809 --> 00:13:29.609 align:start position:0%
has this non-linearity at Z equals zero
so<00:13:26.319><c> at</c><00:13:26.439><c> Z</c><00:13:27.279><c> less</c><00:13:27.519><c> than</c><00:13:27.550><c> 0</c><00:13:27.959><c> this</c><00:13:28.959><c> function</c><00:13:28.990><c> equals</c>

00:13:29.609 --> 00:13:29.619 align:start position:0%
so at Z less than 0 this function equals
 

00:13:29.619 --> 00:13:31.799 align:start position:0%
so at Z less than 0 this function equals
0<00:13:29.860><c> and</c><00:13:30.129><c> at</c><00:13:30.369><c> Z</c><00:13:30.399><c> greater</c><00:13:30.670><c> than</c><00:13:30.879><c> 0</c><00:13:31.240><c> it</c><00:13:31.480><c> just</c><00:13:31.660><c> equals</c>

00:13:31.799 --> 00:13:31.809 align:start position:0%
0 and at Z greater than 0 it just equals
 

00:13:31.809 --> 00:13:33.540 align:start position:0%
0 and at Z greater than 0 it just equals
the<00:13:32.199><c> input</c><00:13:32.350><c> and</c><00:13:32.740><c> because</c><00:13:33.339><c> of</c><00:13:33.369><c> this</c>

00:13:33.540 --> 00:13:33.550 align:start position:0%
the input and because of this
 

00:13:33.550 --> 00:13:35.369 align:start position:0%
the input and because of this
non-linearity<00:13:33.910><c> it's</c><00:13:34.480><c> still</c><00:13:34.720><c> able</c><00:13:34.899><c> to</c><00:13:35.050><c> capture</c>

00:13:35.369 --> 00:13:35.379 align:start position:0%
non-linearity it's still able to capture
 

00:13:35.379 --> 00:13:36.809 align:start position:0%
non-linearity it's still able to capture
all<00:13:35.769><c> of</c><00:13:35.800><c> the</c><00:13:36.009><c> great</c><00:13:36.160><c> properties</c><00:13:36.639><c> of</c>

00:13:36.809 --> 00:13:36.819 align:start position:0%
all of the great properties of
 

00:13:36.819 --> 00:13:38.730 align:start position:0%
all of the great properties of
activation<00:13:37.389><c> functions</c><00:13:37.809><c> while</c><00:13:38.290><c> still</c><00:13:38.589><c> being</c>

00:13:38.730 --> 00:13:38.740 align:start position:0%
activation functions while still being
 

00:13:38.740 --> 00:13:42.869 align:start position:0%
activation functions while still being
extremely<00:13:39.189><c> simple</c><00:13:39.550><c> to</c><00:13:39.579><c> compute</c><00:13:40.019><c> and</c><00:13:41.850><c> now</c><00:13:42.850><c> I</c>

00:13:42.869 --> 00:13:42.879 align:start position:0%
extremely simple to compute and now I
 

00:13:42.879 --> 00:13:45.179 align:start position:0%
extremely simple to compute and now I
want<00:13:43.179><c> to</c><00:13:43.240><c> talk</c><00:13:43.360><c> a</c><00:13:43.389><c> little</c><00:13:43.509><c> bit</c><00:13:43.839><c> about</c><00:13:43.869><c> why</c><00:13:44.529><c> do</c>

00:13:45.179 --> 00:13:45.189 align:start position:0%
want to talk a little bit about why do
 

00:13:45.189 --> 00:13:47.669 align:start position:0%
want to talk a little bit about why do
we<00:13:45.369><c> use</c><00:13:45.929><c> activation</c><00:13:46.929><c> functions</c><00:13:47.290><c> at</c><00:13:47.439><c> all</c><00:13:47.529><c> I</c>

00:13:47.669 --> 00:13:47.679 align:start position:0%
we use activation functions at all I
 

00:13:47.679 --> 00:13:49.230 align:start position:0%
we use activation functions at all I
think<00:13:47.769><c> a</c><00:13:47.980><c> great</c><00:13:48.189><c> part</c><00:13:48.429><c> of</c><00:13:48.519><c> this</c><00:13:48.579><c> class</c><00:13:48.819><c> is</c><00:13:49.059><c> to</c>

00:13:49.230 --> 00:13:49.240 align:start position:0%
think a great part of this class is to
 

00:13:49.240 --> 00:13:51.299 align:start position:0%
think a great part of this class is to
actually<00:13:49.509><c> ask</c><00:13:49.809><c> questions</c><00:13:49.869><c> and</c><00:13:50.499><c> not</c><00:13:51.069><c> take</c>

00:13:51.299 --> 00:13:51.309 align:start position:0%
actually ask questions and not take
 

00:13:51.309 --> 00:13:53.249 align:start position:0%
actually ask questions and not take
anything<00:13:51.550><c> for</c><00:13:51.819><c> granted</c><00:13:51.879><c> so</c><00:13:52.269><c> if</c><00:13:52.360><c> I</c><00:13:52.449><c> tell</c><00:13:52.629><c> you</c><00:13:52.779><c> we</c>

00:13:53.249 --> 00:13:53.259 align:start position:0%
anything for granted so if I tell you we
 

00:13:53.259 --> 00:13:55.109 align:start position:0%
anything for granted so if I tell you we
need<00:13:53.410><c> an</c><00:13:53.529><c> activation</c><00:13:53.920><c> function</c><00:13:54.100><c> the</c><00:13:54.879><c> first</c>

00:13:55.109 --> 00:13:55.119 align:start position:0%
need an activation function the first
 

00:13:55.119 --> 00:13:56.429 align:start position:0%
need an activation function the first
thing<00:13:55.300><c> that</c><00:13:55.480><c> should</c><00:13:55.749><c> come</c><00:13:55.929><c> to</c><00:13:56.019><c> your</c><00:13:56.110><c> mind</c><00:13:56.170><c> is</c>

00:13:56.429 --> 00:13:56.439 align:start position:0%
thing that should come to your mind is
 

00:13:56.439 --> 00:13:57.960 align:start position:0%
thing that should come to your mind is
well<00:13:56.649><c> why</c><00:13:56.740><c> do</c><00:13:56.800><c> we</c><00:13:57.009><c> need</c><00:13:57.160><c> that</c><00:13:57.220><c> activation</c>

00:13:57.960 --> 00:13:57.970 align:start position:0%
well why do we need that activation
 

00:13:57.970 --> 00:14:01.439 align:start position:0%
well why do we need that activation
function<00:13:58.470><c> so</c><00:13:59.699><c> activation</c><00:14:00.699><c> functions</c><00:14:01.149><c> the</c>

00:14:01.439 --> 00:14:01.449 align:start position:0%
function so activation functions the
 

00:14:01.449 --> 00:14:03.480 align:start position:0%
function so activation functions the
purpose<00:14:01.809><c> of</c><00:14:01.959><c> activation</c><00:14:02.439><c> functions</c><00:14:02.860><c> is</c><00:14:03.100><c> to</c>

00:14:03.480 --> 00:14:03.490 align:start position:0%
purpose of activation functions is to
 

00:14:03.490 --> 00:14:05.249 align:start position:0%
purpose of activation functions is to
introduce<00:14:03.899><c> nonlinearities</c><00:14:04.899><c> into</c><00:14:05.170><c> the</c>

00:14:05.249 --> 00:14:05.259 align:start position:0%
introduce nonlinearities into the
 

00:14:05.259 --> 00:14:08.040 align:start position:0%
introduce nonlinearities into the
network<00:14:05.639><c> this</c><00:14:06.639><c> is</c><00:14:06.699><c> extremely</c><00:14:07.509><c> important</c><00:14:07.959><c> in</c>

00:14:08.040 --> 00:14:08.050 align:start position:0%
network this is extremely important in
 

00:14:08.050 --> 00:14:09.809 align:start position:0%
network this is extremely important in
deep<00:14:08.230><c> learning</c><00:14:08.679><c> or</c><00:14:08.860><c> in</c><00:14:09.129><c> machine</c><00:14:09.490><c> learning</c><00:14:09.759><c> in</c>

00:14:09.809 --> 00:14:09.819 align:start position:0%
deep learning or in machine learning in
 

00:14:09.819 --> 00:14:12.389 align:start position:0%
deep learning or in machine learning in
general<00:14:09.850><c> because</c><00:14:10.600><c> in</c><00:14:10.839><c> real</c><00:14:11.050><c> life</c><00:14:11.129><c> data</c><00:14:12.129><c> is</c>

00:14:12.389 --> 00:14:12.399 align:start position:0%
general because in real life data is
 

00:14:12.399 --> 00:14:15.869 align:start position:0%
general because in real life data is
almost<00:14:12.790><c> always</c><00:14:13.119><c> very</c><00:14:13.649><c> nonlinear</c><00:14:14.790><c> imagine</c><00:14:15.790><c> I</c>

00:14:15.869 --> 00:14:15.879 align:start position:0%
almost always very nonlinear imagine I
 

00:14:15.879 --> 00:14:17.999 align:start position:0%
almost always very nonlinear imagine I
told<00:14:16.059><c> you</c><00:14:16.209><c> to</c><00:14:16.360><c> separate</c><00:14:16.809><c> here</c><00:14:17.170><c> the</c><00:14:17.499><c> green</c><00:14:17.769><c> from</c>

00:14:17.999 --> 00:14:18.009 align:start position:0%
told you to separate here the green from
 

00:14:18.009 --> 00:14:20.009 align:start position:0%
told you to separate here the green from
the<00:14:18.160><c> red</c><00:14:18.309><c> points</c><00:14:18.730><c> you</c><00:14:19.600><c> might</c><00:14:19.720><c> think</c><00:14:19.929><c> that's</c>

00:14:20.009 --> 00:14:20.019 align:start position:0%
the red points you might think that's
 

00:14:20.019 --> 00:14:21.540 align:start position:0%
the red points you might think that's
easy<00:14:20.259><c> but</c><00:14:20.529><c> then</c><00:14:20.619><c> what</c><00:14:20.800><c> if</c><00:14:20.889><c> I</c><00:14:20.949><c> told</c><00:14:21.160><c> you</c><00:14:21.309><c> you</c><00:14:21.429><c> had</c>

00:14:21.540 --> 00:14:21.550 align:start position:0%
easy but then what if I told you you had
 

00:14:21.550 --> 00:14:24.389 align:start position:0%
easy but then what if I told you you had
to<00:14:21.639><c> only</c><00:14:21.790><c> use</c><00:14:22.119><c> a</c><00:14:22.300><c> single</c><00:14:22.689><c> line</c><00:14:23.589><c> to</c><00:14:23.980><c> do</c><00:14:24.100><c> it</c>

00:14:24.389 --> 00:14:24.399 align:start position:0%
to only use a single line to do it
 

00:14:24.399 --> 00:14:27.299 align:start position:0%
to only use a single line to do it
well<00:14:24.970><c> now</c><00:14:25.089><c> it's</c><00:14:25.209><c> impossible</c><00:14:25.920><c> that</c><00:14:26.920><c> actually</c>

00:14:27.299 --> 00:14:27.309 align:start position:0%
well now it's impossible that actually
 

00:14:27.309 --> 00:14:28.919 align:start position:0%
well now it's impossible that actually
makes<00:14:27.459><c> the</c><00:14:27.550><c> problem</c><00:14:27.579><c> not</c><00:14:28.300><c> only</c><00:14:28.540><c> really</c><00:14:28.749><c> hard</c>

00:14:28.919 --> 00:14:28.929 align:start position:0%
makes the problem not only really hard
 

00:14:28.929 --> 00:14:30.480 align:start position:0%
makes the problem not only really hard
like<00:14:29.199><c> I</c><00:14:29.230><c> said</c><00:14:29.470><c> it</c><00:14:29.529><c> makes</c><00:14:29.649><c> it</c><00:14:29.800><c> impossible</c><00:14:29.889><c> in</c>

00:14:30.480 --> 00:14:30.490 align:start position:0%
like I said it makes it impossible in
 

00:14:30.490 --> 00:14:31.949 align:start position:0%
like I said it makes it impossible in
fact<00:14:30.670><c> if</c><00:14:30.819><c> you</c><00:14:30.910><c> use</c><00:14:30.939><c> linear</c><00:14:31.660><c> activation</c>

00:14:31.949 --> 00:14:31.959 align:start position:0%
fact if you use linear activation
 

00:14:31.959 --> 00:14:34.169 align:start position:0%
fact if you use linear activation
functions<00:14:32.679><c> in</c><00:14:32.829><c> a</c><00:14:32.949><c> neural</c><00:14:33.129><c> network</c><00:14:33.370><c> no</c><00:14:33.999><c> matter</c>

00:14:34.169 --> 00:14:34.179 align:start position:0%
functions in a neural network no matter
 

00:14:34.179 --> 00:14:37.009 align:start position:0%
functions in a neural network no matter
how<00:14:34.420><c> deep</c><00:14:34.779><c> or</c><00:14:35.019><c> wide</c><00:14:35.679><c> your</c><00:14:36.040><c> neural</c><00:14:36.279><c> network</c><00:14:36.579><c> is</c>

00:14:37.009 --> 00:14:37.019 align:start position:0%
how deep or wide your neural network is
 

00:14:37.019 --> 00:14:39.900 align:start position:0%
how deep or wide your neural network is
no<00:14:38.019><c> matter</c><00:14:38.170><c> how</c><00:14:38.259><c> many</c><00:14:38.529><c> neurons</c><00:14:38.740><c> it</c><00:14:39.040><c> has</c><00:14:39.189><c> this</c>

00:14:39.900 --> 00:14:39.910 align:start position:0%
no matter how many neurons it has this
 

00:14:39.910 --> 00:14:41.460 align:start position:0%
no matter how many neurons it has this
is<00:14:40.120><c> the</c><00:14:40.269><c> best</c><00:14:40.509><c> that</c><00:14:40.720><c> I</c><00:14:40.749><c> will</c><00:14:40.929><c> be</c><00:14:41.050><c> able</c><00:14:41.139><c> to</c><00:14:41.319><c> do</c>

00:14:41.460 --> 00:14:41.470 align:start position:0%
is the best that I will be able to do
 

00:14:41.470 --> 00:14:43.230 align:start position:0%
is the best that I will be able to do
produce<00:14:41.889><c> a</c><00:14:42.009><c> linear</c><00:14:42.399><c> decision</c><00:14:42.790><c> boundary</c>

00:14:43.230 --> 00:14:43.240 align:start position:0%
produce a linear decision boundary
 

00:14:43.240 --> 00:14:45.150 align:start position:0%
produce a linear decision boundary
between<00:14:43.449><c> the</c><00:14:43.809><c> red</c><00:14:43.990><c> and</c><00:14:44.199><c> the</c><00:14:44.290><c> green</c><00:14:44.379><c> points</c><00:14:44.860><c> and</c>

00:14:45.150 --> 00:14:45.160 align:start position:0%
between the red and the green points and
 

00:14:45.160 --> 00:14:46.590 align:start position:0%
between the red and the green points and
that's<00:14:45.370><c> because</c><00:14:45.699><c> it's</c><00:14:45.939><c> using</c><00:14:46.240><c> linear</c>

00:14:46.590 --> 00:14:46.600 align:start position:0%
that's because it's using linear
 

00:14:46.600 --> 00:14:49.079 align:start position:0%
that's because it's using linear
activation<00:14:47.110><c> functions</c><00:14:47.499><c> when</c><00:14:48.339><c> we</c><00:14:48.490><c> introduce</c><00:14:48.910><c> a</c>

00:14:49.079 --> 00:14:49.089 align:start position:0%
activation functions when we introduce a
 

00:14:49.089 --> 00:14:51.329 align:start position:0%
activation functions when we introduce a
nonlinear<00:14:49.689><c> activation</c><00:14:50.050><c> function</c><00:14:50.589><c> that</c>

00:14:51.329 --> 00:14:51.339 align:start position:0%
nonlinear activation function that
 

00:14:51.339 --> 00:14:53.549 align:start position:0%
nonlinear activation function that
allows<00:14:51.639><c> us</c><00:14:51.670><c> to</c><00:14:51.879><c> approximate</c><00:14:52.559><c> arbitrarily</c>

00:14:53.549 --> 00:14:53.559 align:start position:0%
allows us to approximate arbitrarily
 

00:14:53.559 --> 00:14:56.100 align:start position:0%
allows us to approximate arbitrarily
complex<00:14:54.189><c> functions</c><00:14:54.759><c> and</c><00:14:54.999><c> draw</c><00:14:55.449><c> arbitrarily</c>

00:14:56.100 --> 00:14:56.110 align:start position:0%
complex functions and draw arbitrarily
 

00:14:56.110 --> 00:14:58.139 align:start position:0%
complex functions and draw arbitrarily
complex<00:14:56.620><c> decision</c><00:14:57.189><c> boundaries</c><00:14:57.550><c> in</c><00:14:57.819><c> this</c>

00:14:58.139 --> 00:14:58.149 align:start position:0%
complex decision boundaries in this
 

00:14:58.149 --> 00:15:00.869 align:start position:0%
complex decision boundaries in this
feature<00:14:58.389><c> space</c><00:14:58.829><c> and</c><00:14:59.829><c> that's</c><00:15:00.160><c> exactly</c><00:15:00.550><c> what</c>

00:15:00.869 --> 00:15:00.879 align:start position:0%
feature space and that's exactly what
 

00:15:00.879 --> 00:15:02.429 align:start position:0%
feature space and that's exactly what
makes<00:15:00.999><c> neural</c><00:15:01.329><c> networks</c><00:15:01.629><c> so</c><00:15:01.809><c> powerful</c><00:15:02.319><c> in</c>

00:15:02.429 --> 00:15:02.439 align:start position:0%
makes neural networks so powerful in
 

00:15:02.439 --> 00:15:05.699 align:start position:0%
makes neural networks so powerful in
practice<00:15:03.870><c> so</c><00:15:04.870><c> let's</c><00:15:05.019><c> understand</c><00:15:05.439><c> this</c><00:15:05.529><c> with</c><00:15:05.679><c> a</c>

00:15:05.699 --> 00:15:05.709 align:start position:0%
practice so let's understand this with a
 

00:15:05.709 --> 00:15:08.189 align:start position:0%
practice so let's understand this with a
simple<00:15:05.949><c> example</c><00:15:06.540><c> imagine</c><00:15:07.540><c> I</c><00:15:07.839><c> give</c><00:15:08.049><c> you</c><00:15:08.170><c> a</c>

00:15:08.189 --> 00:15:08.199 align:start position:0%
simple example imagine I give you a
 

00:15:08.199 --> 00:15:11.489 align:start position:0%
simple example imagine I give you a
trains<00:15:08.589><c> Network</c><00:15:09.009><c> with</c><00:15:09.220><c> weights</c><00:15:09.519><c> W</c><00:15:10.360><c> on</c><00:15:10.540><c> the</c><00:15:11.319><c> top</c>

00:15:11.489 --> 00:15:11.499 align:start position:0%
trains Network with weights W on the top
 

00:15:11.499 --> 00:15:17.100 align:start position:0%
trains Network with weights W on the top
here<00:15:11.799><c> so</c><00:15:11.949><c> W</c><00:15:12.610><c> 0</c><00:15:13.299><c> is</c><00:15:13.660><c> 1</c><00:15:14.139><c> and</c><00:15:15.209><c> let's</c><00:15:16.209><c> say</c><00:15:16.329><c> W</c><00:15:16.660><c> 0</c><00:15:16.809><c> is</c><00:15:16.899><c> 1</c>

00:15:17.100 --> 00:15:17.110 align:start position:0%
here so W 0 is 1 and let's say W 0 is 1
 

00:15:17.110 --> 00:15:20.789 align:start position:0%
here so W 0 is 1 and let's say W 0 is 1
the<00:15:17.620><c> W</c><00:15:18.370><c> vector</c><00:15:18.579><c> is</c><00:15:19.029><c> 3</c><00:15:19.360><c> negative</c><00:15:19.720><c> 2</c><00:15:20.110><c> so</c><00:15:20.529><c> this</c><00:15:20.619><c> is</c>

00:15:20.789 --> 00:15:20.799 align:start position:0%
the W vector is 3 negative 2 so this is
 

00:15:20.799 --> 00:15:23.910 align:start position:0%
the W vector is 3 negative 2 so this is
a<00:15:20.829><c> trained</c><00:15:21.189><c> neural</c><00:15:22.119><c> network</c><00:15:22.389><c> and</c><00:15:22.689><c> I</c><00:15:23.499><c> want</c><00:15:23.709><c> to</c>

00:15:23.910 --> 00:15:23.920 align:start position:0%
a trained neural network and I want to
 

00:15:23.920 --> 00:15:26.910 align:start position:0%
a trained neural network and I want to
feed<00:15:24.249><c> in</c><00:15:24.399><c> a</c><00:15:24.549><c> new</c><00:15:24.759><c> input</c><00:15:24.999><c> to</c><00:15:25.839><c> this</c><00:15:25.959><c> network</c><00:15:26.230><c> well</c>

00:15:26.910 --> 00:15:26.920 align:start position:0%
feed in a new input to this network well
 

00:15:26.920 --> 00:15:28.919 align:start position:0%
feed in a new input to this network well
how<00:15:27.040><c> do</c><00:15:27.100><c> we</c><00:15:27.220><c> compute</c><00:15:27.610><c> the</c><00:15:27.699><c> output</c><00:15:27.929><c> remember</c>

00:15:28.919 --> 00:15:28.929 align:start position:0%
how do we compute the output remember
 

00:15:28.929 --> 00:15:31.499 align:start position:0%
how do we compute the output remember
from<00:15:29.079><c> before</c><00:15:29.379><c> it's</c><00:15:29.499><c> the</c><00:15:29.589><c> dot</c><00:15:29.889><c> product</c><00:15:30.360><c> we</c><00:15:31.360><c> add</c>

00:15:31.499 --> 00:15:31.509 align:start position:0%
from before it's the dot product we add
 

00:15:31.509 --> 00:15:33.660 align:start position:0%
from before it's the dot product we add
our<00:15:31.689><c> bias</c><00:15:31.899><c> and</c><00:15:32.379><c> we</c><00:15:32.860><c> compute</c><00:15:33.189><c> a</c><00:15:33.220><c> non-linearity</c>

00:15:33.660 --> 00:15:33.670 align:start position:0%
our bias and we compute a non-linearity
 

00:15:33.670 --> 00:15:35.670 align:start position:0%
our bias and we compute a non-linearity
there's<00:15:34.509><c> three</c><00:15:34.720><c> steps</c>

00:15:35.670 --> 00:15:35.680 align:start position:0%
there's three steps
 

00:15:35.680 --> 00:15:38.220 align:start position:0%
there's three steps
so<00:15:36.430><c> let's</c><00:15:36.610><c> take</c><00:15:36.790><c> a</c><00:15:36.819><c> look</c><00:15:36.999><c> at</c><00:15:37.240><c> what's</c><00:15:37.899><c> going</c><00:15:37.959><c> on</c>

00:15:38.220 --> 00:15:38.230 align:start position:0%
so let's take a look at what's going on
 

00:15:38.230 --> 00:15:40.710 align:start position:0%
so let's take a look at what's going on
here<00:15:38.290><c> what's</c><00:15:39.160><c> inside</c><00:15:39.490><c> of</c><00:15:39.519><c> this</c><00:15:39.819><c> nonlinear</c>

00:15:40.710 --> 00:15:40.720 align:start position:0%
here what's inside of this nonlinear
 

00:15:40.720 --> 00:15:42.840 align:start position:0%
here what's inside of this nonlinear
function<00:15:41.589><c> the</c><00:15:41.740><c> input</c><00:15:42.160><c> to</c><00:15:42.309><c> the</c><00:15:42.399><c> nonlinear</c>

00:15:42.840 --> 00:15:42.850 align:start position:0%
function the input to the nonlinear
 

00:15:42.850 --> 00:15:45.799 align:start position:0%
function the input to the nonlinear
function<00:15:43.240><c> well</c><00:15:43.629><c> this</c><00:15:43.749><c> is</c><00:15:43.869><c> just</c><00:15:44.199><c> a</c><00:15:44.350><c> 2d</c><00:15:44.740><c> line</c><00:15:45.009><c> in</c>

00:15:45.799 --> 00:15:45.809 align:start position:0%
function well this is just a 2d line in
 

00:15:45.809 --> 00:15:48.689 align:start position:0%
function well this is just a 2d line in
fact<00:15:46.809><c> we</c><00:15:47.170><c> can</c><00:15:47.319><c> actually</c><00:15:47.470><c> plot</c><00:15:47.860><c> this</c><00:15:48.100><c> 2d</c><00:15:48.459><c> line</c>

00:15:48.689 --> 00:15:48.699 align:start position:0%
fact we can actually plot this 2d line
 

00:15:48.699 --> 00:15:51.480 align:start position:0%
fact we can actually plot this 2d line
in<00:15:48.939><c> what</c><00:15:49.420><c> we</c><00:15:49.540><c> call</c><00:15:49.720><c> the</c><00:15:49.749><c> feature</c><00:15:50.139><c> space</c><00:15:50.589><c> so</c><00:15:51.369><c> on</c>

00:15:51.480 --> 00:15:51.490 align:start position:0%
in what we call the feature space so on
 

00:15:51.490 --> 00:15:54.449 align:start position:0%
in what we call the feature space so on
the<00:15:51.610><c> x</c><00:15:51.790><c> axis</c><00:15:52.029><c> you</c><00:15:52.480><c> can</c><00:15:52.509><c> see</c><00:15:52.660><c> X</c><00:15:53.050><c> 1</c><00:15:53.410><c> which</c><00:15:53.800><c> is</c><00:15:53.980><c> the</c>

00:15:54.449 --> 00:15:54.459 align:start position:0%
the x axis you can see X 1 which is the
 

00:15:54.459 --> 00:15:57.600 align:start position:0%
the x axis you can see X 1 which is the
first<00:15:54.759><c> input</c><00:15:55.089><c> and</c><00:15:55.869><c> on</c><00:15:56.829><c> the</c><00:15:56.949><c> y</c><00:15:57.040><c> axis</c><00:15:57.069><c> you</c><00:15:57.579><c> can</c>

00:15:57.600 --> 00:15:57.610 align:start position:0%
first input and on the y axis you can
 

00:15:57.610 --> 00:15:59.910 align:start position:0%
first input and on the y axis you can
see<00:15:57.759><c> X</c><00:15:58.089><c> 2</c><00:15:58.300><c> which</c><00:15:58.480><c> is</c><00:15:58.629><c> the</c><00:15:58.779><c> second</c><00:15:59.139><c> input</c><00:15:59.259><c> this</c>

00:15:59.910 --> 00:15:59.920 align:start position:0%
see X 2 which is the second input this
 

00:15:59.920 --> 00:16:02.910 align:start position:0%
see X 2 which is the second input this
neural<00:16:00.189><c> network</c><00:16:00.429><c> has</c><00:16:00.490><c> two</c><00:16:00.790><c> inputs</c><00:16:01.769><c> we</c><00:16:02.769><c> can</c>

00:16:02.910 --> 00:16:02.920 align:start position:0%
neural network has two inputs we can
 

00:16:02.920 --> 00:16:04.650 align:start position:0%
neural network has two inputs we can
plot<00:16:03.100><c> the</c><00:16:03.279><c> line</c><00:16:03.459><c> when</c><00:16:03.730><c> it</c><00:16:03.759><c> is</c><00:16:03.939><c> equal</c><00:16:04.269><c> to</c><00:16:04.300><c> zero</c>

00:16:04.650 --> 00:16:04.660 align:start position:0%
plot the line when it is equal to zero
 

00:16:04.660 --> 00:16:06.359 align:start position:0%
plot the line when it is equal to zero
and<00:16:04.869><c> you</c><00:16:04.929><c> can</c><00:16:05.139><c> actually</c><00:16:05.319><c> see</c><00:16:05.619><c> it</c><00:16:05.769><c> in</c><00:16:05.949><c> the</c>

00:16:06.359 --> 00:16:06.369 align:start position:0%
and you can actually see it in the
 

00:16:06.369 --> 00:16:09.329 align:start position:0%
and you can actually see it in the
feature<00:16:06.550><c> space</c><00:16:06.759><c> here</c><00:16:07.209><c> if</c><00:16:07.959><c> I</c><00:16:08.769><c> give</c><00:16:08.949><c> you</c><00:16:09.040><c> a</c><00:16:09.069><c> new</c>

00:16:09.329 --> 00:16:09.339 align:start position:0%
feature space here if I give you a new
 

00:16:09.339 --> 00:16:11.400 align:start position:0%
feature space here if I give you a new
point<00:16:09.670><c> a</c><00:16:09.879><c> new</c><00:16:10.360><c> input</c><00:16:10.839><c> to</c><00:16:10.959><c> this</c><00:16:11.110><c> neural</c><00:16:11.350><c> network</c>

00:16:11.400 --> 00:16:11.410 align:start position:0%
point a new input to this neural network
 

00:16:11.410 --> 00:16:13.889 align:start position:0%
point a new input to this neural network
you<00:16:12.160><c> can</c><00:16:12.339><c> also</c><00:16:12.550><c> plot</c><00:16:12.850><c> this</c><00:16:13.089><c> new</c><00:16:13.269><c> point</c><00:16:13.509><c> in</c><00:16:13.779><c> the</c>

00:16:13.889 --> 00:16:13.899 align:start position:0%
you can also plot this new point in the
 

00:16:13.899 --> 00:16:16.230 align:start position:0%
you can also plot this new point in the
same<00:16:14.079><c> feature</c><00:16:14.350><c> space</c><00:16:14.679><c> so</c><00:16:15.670><c> here's</c><00:16:15.910><c> the</c><00:16:16.059><c> point</c>

00:16:16.230 --> 00:16:16.240 align:start position:0%
same feature space so here's the point
 

00:16:16.240 --> 00:16:19.439 align:start position:0%
same feature space so here's the point
negative<00:16:16.540><c> 1</c><00:16:16.899><c> 2</c><00:16:17.610><c> you</c><00:16:18.610><c> can</c><00:16:18.759><c> plot</c><00:16:18.939><c> it</c><00:16:18.999><c> like</c><00:16:19.240><c> this</c>

00:16:19.439 --> 00:16:19.449 align:start position:0%
negative 1 2 you can plot it like this
 

00:16:19.449 --> 00:16:21.660 align:start position:0%
negative 1 2 you can plot it like this
and<00:16:19.720><c> actually</c><00:16:20.230><c> you</c><00:16:20.470><c> can</c><00:16:20.619><c> compute</c><00:16:21.069><c> the</c><00:16:21.220><c> output</c>

00:16:21.660 --> 00:16:21.670 align:start position:0%
and actually you can compute the output
 

00:16:21.670 --> 00:16:24.059 align:start position:0%
and actually you can compute the output
by<00:16:22.269><c> plugging</c><00:16:22.720><c> it</c><00:16:22.809><c> into</c><00:16:23.230><c> this</c><00:16:23.470><c> equation</c><00:16:23.709><c> that</c>

00:16:24.059 --> 00:16:24.069 align:start position:0%
by plugging it into this equation that
 

00:16:24.069 --> 00:16:26.699 align:start position:0%
by plugging it into this equation that
we<00:16:24.220><c> created</c><00:16:24.490><c> before</c><00:16:24.819><c> this</c><00:16:24.970><c> line</c><00:16:25.240><c> if</c><00:16:25.749><c> we</c><00:16:26.499><c> plug</c>

00:16:26.699 --> 00:16:26.709 align:start position:0%
we created before this line if we plug
 

00:16:26.709 --> 00:16:30.329 align:start position:0%
we created before this line if we plug
it<00:16:26.800><c> in</c><00:16:26.920><c> we</c><00:16:27.129><c> get</c><00:16:27.339><c> 1</c><00:16:27.730><c> minus</c><00:16:27.970><c> 3</c><00:16:28.629><c> minus</c><00:16:29.319><c> 4</c><00:16:29.529><c> right</c>

00:16:30.329 --> 00:16:30.339 align:start position:0%
it in we get 1 minus 3 minus 4 right
 

00:16:30.339 --> 00:16:32.369 align:start position:0%
it in we get 1 minus 3 minus 4 right
which<00:16:30.550><c> equals</c><00:16:30.850><c> minus</c><00:16:31.179><c> 6</c><00:16:31.420><c> that's</c><00:16:31.689><c> the</c><00:16:31.929><c> input</c><00:16:32.079><c> to</c>

00:16:32.369 --> 00:16:32.379 align:start position:0%
which equals minus 6 that's the input to
 

00:16:32.379 --> 00:16:34.859 align:start position:0%
which equals minus 6 that's the input to
our<00:16:32.470><c> activation</c><00:16:32.829><c> function</c><00:16:33.399><c> and</c><00:16:33.629><c> then</c><00:16:34.629><c> when</c><00:16:34.749><c> we</c>

00:16:34.859 --> 00:16:34.869 align:start position:0%
our activation function and then when we
 

00:16:34.869 --> 00:16:36.509 align:start position:0%
our activation function and then when we
feed<00:16:35.230><c> it</c><00:16:35.350><c> through</c><00:16:35.559><c> our</c><00:16:35.679><c> activation</c><00:16:36.009><c> function</c>

00:16:36.509 --> 00:16:36.519 align:start position:0%
feed it through our activation function
 

00:16:36.519 --> 00:16:38.660 align:start position:0%
feed it through our activation function
here<00:16:36.699><c> I'm</c><00:16:36.819><c> using</c><00:16:36.970><c> sigmoid</c><00:16:37.660><c> again</c><00:16:37.929><c> for</c><00:16:38.139><c> example</c>

00:16:38.660 --> 00:16:38.670 align:start position:0%
here I'm using sigmoid again for example
 

00:16:38.670 --> 00:16:41.910 align:start position:0%
here I'm using sigmoid again for example
our<00:16:39.670><c> final</c><00:16:40.059><c> output</c><00:16:40.149><c> is</c><00:16:40.509><c> zero</c><00:16:41.230><c> point</c><00:16:41.499><c> zero</c><00:16:41.679><c> zero</c>

00:16:41.910 --> 00:16:41.920 align:start position:0%
our final output is zero point zero zero
 

00:16:41.920 --> 00:16:45.030 align:start position:0%
our final output is zero point zero zero
two<00:16:42.660><c> ok</c><00:16:43.660><c> what</c><00:16:43.839><c> does</c><00:16:43.899><c> that</c><00:16:43.959><c> number</c><00:16:44.170><c> mean</c><00:16:44.319><c> let's</c>

00:16:45.030 --> 00:16:45.040 align:start position:0%
two ok what does that number mean let's
 

00:16:45.040 --> 00:16:46.590 align:start position:0%
two ok what does that number mean let's
go<00:16:45.160><c> back</c><00:16:45.370><c> to</c><00:16:45.550><c> this</c><00:16:45.639><c> illustration</c><00:16:46.089><c> of</c><00:16:46.420><c> the</c>

00:16:46.590 --> 00:16:46.600 align:start position:0%
go back to this illustration of the
 

00:16:46.600 --> 00:16:49.079 align:start position:0%
go back to this illustration of the
feature<00:16:46.809><c> space</c><00:16:47.139><c> again</c><00:16:47.730><c> what</c><00:16:48.730><c> this</c><00:16:48.910><c> feature</c>

00:16:49.079 --> 00:16:49.089 align:start position:0%
feature space again what this feature
 

00:16:49.089 --> 00:16:50.970 align:start position:0%
feature space again what this feature
space<00:16:49.449><c> is</c><00:16:49.600><c> doing</c><00:16:49.839><c> is</c><00:16:49.959><c> essentially</c><00:16:50.290><c> dividing</c>

00:16:50.970 --> 00:16:50.980 align:start position:0%
space is doing is essentially dividing
 

00:16:50.980 --> 00:16:54.269 align:start position:0%
space is doing is essentially dividing
the<00:16:51.189><c> space</c><00:16:51.309><c> into</c><00:16:51.699><c> two</c><00:16:52.059><c> hyperplanes</c><00:16:53.279><c> remember</c>

00:16:54.269 --> 00:16:54.279 align:start position:0%
the space into two hyperplanes remember
 

00:16:54.279 --> 00:16:57.059 align:start position:0%
the space into two hyperplanes remember
that<00:16:54.429><c> the</c><00:16:54.550><c> sigmoid</c><00:16:54.910><c> function</c><00:16:55.589><c> outputs</c><00:16:56.589><c> values</c>

00:16:57.059 --> 00:16:57.069 align:start position:0%
that the sigmoid function outputs values
 

00:16:57.069 --> 00:17:01.889 align:start position:0%
that the sigmoid function outputs values
between<00:16:57.249><c> 0</c><00:16:57.850><c> and</c><00:16:58.149><c> 1</c><00:16:58.569><c> and</c><00:16:59.519><c> at</c><00:17:00.519><c> z</c><00:17:01.029><c> equals</c><00:17:01.389><c> 0</c><00:17:01.600><c> when</c>

00:17:01.889 --> 00:17:01.899 align:start position:0%
between 0 and 1 and at z equals 0 when
 

00:17:01.899 --> 00:17:04.380 align:start position:0%
between 0 and 1 and at z equals 0 when
the<00:17:02.019><c> input</c><00:17:02.529><c> to</c><00:17:02.709><c> the</c><00:17:02.829><c> sigmoid</c><00:17:03.160><c> is</c><00:17:03.279><c> 0</c><00:17:03.519><c> the</c><00:17:03.910><c> output</c>

00:17:04.380 --> 00:17:04.390 align:start position:0%
the input to the sigmoid is 0 the output
 

00:17:04.390 --> 00:17:06.809 align:start position:0%
the input to the sigmoid is 0 the output
of<00:17:04.419><c> the</c><00:17:04.600><c> sigmoid</c><00:17:04.990><c> is</c><00:17:05.079><c> 0.5</c><00:17:05.589><c> so</c><00:17:06.370><c> essentially</c>

00:17:06.809 --> 00:17:06.819 align:start position:0%
of the sigmoid is 0.5 so essentially
 

00:17:06.819 --> 00:17:08.819 align:start position:0%
of the sigmoid is 0.5 so essentially
you're<00:17:07.000><c> splitting</c><00:17:07.270><c> your</c><00:17:07.480><c> space</c><00:17:07.779><c> into</c><00:17:08.319><c> two</c>

00:17:08.819 --> 00:17:08.829 align:start position:0%
you're splitting your space into two
 

00:17:08.829 --> 00:17:10.649 align:start position:0%
you're splitting your space into two
planes<00:17:09.130><c> one</c><00:17:09.429><c> where</c><00:17:09.610><c> Z</c><00:17:09.819><c> is</c><00:17:09.850><c> greater</c><00:17:10.089><c> than</c><00:17:10.270><c> zero</c>

00:17:10.649 --> 00:17:10.659 align:start position:0%
planes one where Z is greater than zero
 

00:17:10.659 --> 00:17:13.289 align:start position:0%
planes one where Z is greater than zero
and<00:17:11.110><c> one</c><00:17:11.289><c> more</c><00:17:11.439><c> Z</c><00:17:11.589><c> is</c><00:17:11.679><c> less</c><00:17:11.709><c> than</c><00:17:12.130><c> zero</c><00:17:12.370><c> and</c><00:17:12.640><c> one</c>

00:17:13.289 --> 00:17:13.299 align:start position:0%
and one more Z is less than zero and one
 

00:17:13.299 --> 00:17:15.449 align:start position:0%
and one more Z is less than zero and one
where<00:17:13.480><c> Y</c><00:17:13.659><c> is</c><00:17:13.720><c> greater</c><00:17:14.169><c> than</c><00:17:14.350><c> 0.5</c><00:17:14.679><c> and</c><00:17:15.130><c> one</c>

00:17:15.449 --> 00:17:15.459 align:start position:0%
where Y is greater than 0.5 and one
 

00:17:15.459 --> 00:17:17.340 align:start position:0%
where Y is greater than 0.5 and one
where<00:17:15.640><c> Y</c><00:17:15.819><c> is</c><00:17:15.880><c> less</c><00:17:16.209><c> than</c><00:17:16.270><c> 0.5</c><00:17:16.750><c> the</c><00:17:17.079><c> two</c><00:17:17.230><c> are</c>

00:17:17.340 --> 00:17:17.350 align:start position:0%
where Y is less than 0.5 the two are
 

00:17:17.350 --> 00:17:21.090 align:start position:0%
where Y is less than 0.5 the two are
synonymous<00:17:19.260><c> but</c><00:17:20.260><c> when</c><00:17:20.559><c> we're</c><00:17:20.709><c> dealing</c><00:17:20.890><c> with</c>

00:17:21.090 --> 00:17:21.100 align:start position:0%
synonymous but when we're dealing with
 

00:17:21.100 --> 00:17:23.429 align:start position:0%
synonymous but when we're dealing with
small<00:17:21.520><c> dimensional</c><00:17:22.390><c> input</c><00:17:22.630><c> data</c><00:17:22.959><c> like</c><00:17:23.199><c> here</c>

00:17:23.429 --> 00:17:23.439 align:start position:0%
small dimensional input data like here
 

00:17:23.439 --> 00:17:24.899 align:start position:0%
small dimensional input data like here
we're<00:17:23.589><c> dealing</c><00:17:23.770><c> with</c><00:17:23.919><c> only</c><00:17:24.159><c> two</c><00:17:24.370><c> dimensions</c>

00:17:24.899 --> 00:17:24.909 align:start position:0%
we're dealing with only two dimensions
 

00:17:24.909 --> 00:17:27.529 align:start position:0%
we're dealing with only two dimensions
we<00:17:25.419><c> can</c><00:17:25.569><c> make</c><00:17:25.720><c> these</c><00:17:25.870><c> beautiful</c><00:17:26.079><c> plots</c><00:17:26.559><c> and</c>

00:17:27.529 --> 00:17:27.539 align:start position:0%
we can make these beautiful plots and
 

00:17:27.539 --> 00:17:29.760 align:start position:0%
we can make these beautiful plots and
these<00:17:28.539><c> are</c><00:17:28.690><c> very</c><00:17:28.960><c> valuable</c><00:17:29.169><c> and</c><00:17:29.470><c> actually</c>

00:17:29.760 --> 00:17:29.770 align:start position:0%
these are very valuable and actually
 

00:17:29.770 --> 00:17:31.200 align:start position:0%
these are very valuable and actually
visualizing<00:17:30.190><c> the</c><00:17:30.490><c> learning</c><00:17:30.789><c> algorithm</c>

00:17:31.200 --> 00:17:31.210 align:start position:0%
visualizing the learning algorithm
 

00:17:31.210 --> 00:17:33.419 align:start position:0%
visualizing the learning algorithm
visualizing<00:17:31.840><c> how</c><00:17:32.380><c> our</c><00:17:32.590><c> output</c><00:17:32.919><c> is</c><00:17:33.039><c> relating</c>

00:17:33.419 --> 00:17:33.429 align:start position:0%
visualizing how our output is relating
 

00:17:33.429 --> 00:17:35.730 align:start position:0%
visualizing how our output is relating
to<00:17:33.460><c> our</c><00:17:33.640><c> input</c><00:17:33.970><c> we're</c><00:17:34.690><c> gonna</c><00:17:34.779><c> find</c><00:17:35.169><c> very</c><00:17:35.440><c> soon</c>

00:17:35.730 --> 00:17:35.740 align:start position:0%
to our input we're gonna find very soon
 

00:17:35.740 --> 00:17:38.340 align:start position:0%
to our input we're gonna find very soon
that<00:17:36.159><c> we</c><00:17:36.490><c> can't</c><00:17:36.789><c> really</c><00:17:37.000><c> do</c><00:17:37.270><c> this</c><00:17:37.450><c> for</c><00:17:38.230><c> all</c>

00:17:38.340 --> 00:17:38.350 align:start position:0%
that we can't really do this for all
 

00:17:38.350 --> 00:17:41.310 align:start position:0%
that we can't really do this for all
problems<00:17:38.890><c> because</c><00:17:39.809><c> while</c><00:17:40.809><c> here</c><00:17:41.140><c> we're</c>

00:17:41.310 --> 00:17:41.320 align:start position:0%
problems because while here we're
 

00:17:41.320 --> 00:17:42.720 align:start position:0%
problems because while here we're
dealing<00:17:41.440><c> with</c><00:17:41.559><c> only</c><00:17:41.830><c> two</c><00:17:42.010><c> inputs</c><00:17:42.460><c> in</c>

00:17:42.720 --> 00:17:42.730 align:start position:0%
dealing with only two inputs in
 

00:17:42.730 --> 00:17:44.549 align:start position:0%
dealing with only two inputs in
practical<00:17:43.360><c> applications</c><00:17:44.020><c> and</c><00:17:44.230><c> deep</c><00:17:44.409><c> neural</c>

00:17:44.549 --> 00:17:44.559 align:start position:0%
practical applications and deep neural
 

00:17:44.559 --> 00:17:46.080 align:start position:0%
practical applications and deep neural
networks<00:17:45.010><c> we're</c><00:17:45.399><c> gonna</c><00:17:45.520><c> be</c><00:17:45.700><c> dealing</c><00:17:45.850><c> with</c>

00:17:46.080 --> 00:17:46.090 align:start position:0%
networks we're gonna be dealing with
 

00:17:46.090 --> 00:17:47.879 align:start position:0%
networks we're gonna be dealing with
hundreds<00:17:46.510><c> thousands</c><00:17:47.049><c> or</c><00:17:47.110><c> even</c><00:17:47.169><c> millions</c><00:17:47.320><c> of</c>

00:17:47.879 --> 00:17:47.889 align:start position:0%
hundreds thousands or even millions of
 

00:17:47.889 --> 00:17:48.870 align:start position:0%
hundreds thousands or even millions of
inputs<00:17:48.309><c> to</c><00:17:48.399><c> the</c><00:17:48.580><c> network</c>

00:17:48.870 --> 00:17:48.880 align:start position:0%
inputs to the network
 

00:17:48.880 --> 00:17:51.960 align:start position:0%
inputs to the network
at<00:17:49.450><c> any</c><00:17:49.900><c> given</c><00:17:50.170><c> time</c><00:17:50.410><c> and</c><00:17:50.710><c> then</c><00:17:51.490><c> drawing</c><00:17:51.760><c> one</c>

00:17:51.960 --> 00:17:51.970 align:start position:0%
at any given time and then drawing one
 

00:17:51.970 --> 00:17:53.730 align:start position:0%
at any given time and then drawing one
of<00:17:52.060><c> these</c><00:17:52.180><c> plots</c><00:17:52.450><c> in</c><00:17:52.780><c> thousand</c><00:17:53.620><c> dimensional</c>

00:17:53.730 --> 00:17:53.740 align:start position:0%
of these plots in thousand dimensional
 

00:17:53.740 --> 00:17:58.170 align:start position:0%
of these plots in thousand dimensional
space<00:17:54.340><c> is</c><00:17:54.640><c> going</c><00:17:54.790><c> to</c><00:17:54.850><c> become</c><00:17:55.180><c> pretty</c><00:17:55.450><c> tough</c><00:17:57.180><c> so</c>

00:17:58.170 --> 00:17:58.180 align:start position:0%
space is going to become pretty tough so
 

00:17:58.180 --> 00:17:59.940 align:start position:0%
space is going to become pretty tough so
now<00:17:58.630><c> that</c><00:17:58.810><c> we</c><00:17:58.900><c> have</c><00:17:59.020><c> an</c><00:17:59.110><c> idea</c><00:17:59.350><c> of</c><00:17:59.380><c> the</c>

00:17:59.940 --> 00:17:59.950 align:start position:0%
now that we have an idea of the
 

00:17:59.950 --> 00:18:02.820 align:start position:0%
now that we have an idea of the
perceptron<00:18:00.850><c> a</c><00:18:01.120><c> single</c><00:18:01.600><c> neuron</c><00:18:01.780><c> let's</c><00:18:02.560><c> start</c>

00:18:02.820 --> 00:18:02.830 align:start position:0%
perceptron a single neuron let's start
 

00:18:02.830 --> 00:18:04.560 align:start position:0%
perceptron a single neuron let's start
by<00:18:02.950><c> building</c><00:18:03.190><c> neural</c><00:18:03.700><c> networks</c><00:18:04.090><c> from</c><00:18:04.390><c> the</c>

00:18:04.560 --> 00:18:04.570 align:start position:0%
by building neural networks from the
 

00:18:04.570 --> 00:18:06.990 align:start position:0%
by building neural networks from the
ground<00:18:04.810><c> up</c><00:18:05.020><c> using</c><00:18:05.290><c> one</c><00:18:05.620><c> neuron</c><00:18:05.830><c> and</c><00:18:06.160><c> seeing</c>

00:18:06.990 --> 00:18:07.000 align:start position:0%
ground up using one neuron and seeing
 

00:18:07.000 --> 00:18:10.080 align:start position:0%
ground up using one neuron and seeing
how<00:18:07.120><c> this</c><00:18:07.240><c> all</c><00:18:07.420><c> comes</c><00:18:07.630><c> together</c><00:18:09.090><c> let's</c>

00:18:10.080 --> 00:18:10.090 align:start position:0%
how this all comes together let's
 

00:18:10.090 --> 00:18:12.690 align:start position:0%
how this all comes together let's
revisit<00:18:10.360><c> our</c><00:18:10.630><c> diagram</c><00:18:11.050><c> of</c><00:18:11.230><c> the</c><00:18:11.350><c> perceptron</c><00:18:11.770><c> if</c>

00:18:12.690 --> 00:18:12.700 align:start position:0%
revisit our diagram of the perceptron if
 

00:18:12.700 --> 00:18:14.640 align:start position:0%
revisit our diagram of the perceptron if
there's<00:18:13.270><c> a</c><00:18:13.360><c> few</c><00:18:13.780><c> things</c><00:18:14.050><c> that</c><00:18:14.140><c> you</c><00:18:14.290><c> remember</c>

00:18:14.640 --> 00:18:14.650 align:start position:0%
there's a few things that you remember
 

00:18:14.650 --> 00:18:16.050 align:start position:0%
there's a few things that you remember
from<00:18:14.740><c> this</c><00:18:14.950><c> class</c><00:18:15.130><c> I</c><00:18:15.310><c> want</c><00:18:15.430><c> to</c><00:18:15.610><c> remember</c><00:18:15.820><c> this</c>

00:18:16.050 --> 00:18:16.060 align:start position:0%
from this class I want to remember this
 

00:18:16.060 --> 00:18:17.790 align:start position:0%
from this class I want to remember this
so<00:18:16.270><c> there's</c><00:18:16.480><c> three</c><00:18:16.720><c> steps</c><00:18:17.050><c> to</c><00:18:17.200><c> computing</c><00:18:17.650><c> the</c>

00:18:17.790 --> 00:18:17.800 align:start position:0%
so there's three steps to computing the
 

00:18:17.800 --> 00:18:20.790 align:start position:0%
so there's three steps to computing the
output<00:18:17.830><c> of</c><00:18:18.130><c> a</c><00:18:18.250><c> perceptron</c><00:18:18.760><c> dot</c><00:18:19.750><c> product</c><00:18:20.140><c> add</c><00:18:20.740><c> a</c>

00:18:20.790 --> 00:18:20.800 align:start position:0%
output of a perceptron dot product add a
 

00:18:20.800 --> 00:18:24.140 align:start position:0%
output of a perceptron dot product add a
bias<00:18:21.130><c> taking</c><00:18:21.850><c> non-linearity</c><00:18:22.480><c> three</c><00:18:23.050><c> steps</c>

00:18:24.140 --> 00:18:24.150 align:start position:0%
bias taking non-linearity three steps
 

00:18:24.150 --> 00:18:26.430 align:start position:0%
bias taking non-linearity three steps
let's<00:18:25.150><c> simplify</c><00:18:25.390><c> the</c><00:18:25.600><c> diagram</c><00:18:25.990><c> a</c><00:18:26.020><c> little</c><00:18:26.290><c> bit</c>

00:18:26.430 --> 00:18:26.440 align:start position:0%
let's simplify the diagram a little bit
 

00:18:26.440 --> 00:18:27.750 align:start position:0%
let's simplify the diagram a little bit
I<00:18:26.650><c> just</c><00:18:26.950><c> got</c><00:18:27.070><c> rid</c><00:18:27.190><c> of</c><00:18:27.250><c> the</c><00:18:27.400><c> bias</c>

00:18:27.750 --> 00:18:27.760 align:start position:0%
I just got rid of the bias
 

00:18:27.760 --> 00:18:29.310 align:start position:0%
I just got rid of the bias
I<00:18:28.000><c> removed</c><00:18:28.420><c> the</c><00:18:28.510><c> weights</c><00:18:28.750><c> just</c><00:18:29.110><c> for</c>

00:18:29.310 --> 00:18:29.320 align:start position:0%
I removed the weights just for
 

00:18:29.320 --> 00:18:31.700 align:start position:0%
I removed the weights just for
simplicity<00:18:29.890><c> to</c><00:18:30.040><c> keep</c><00:18:30.190><c> things</c><00:18:30.430><c> simple</c><00:18:30.760><c> and</c>

00:18:31.700 --> 00:18:31.710 align:start position:0%
simplicity to keep things simple and
 

00:18:31.710 --> 00:18:35.220 align:start position:0%
simplicity to keep things simple and
just<00:18:32.710><c> note</c><00:18:33.100><c> here</c><00:18:33.310><c> that</c><00:18:33.490><c> I'm</c><00:18:33.640><c> writing</c><00:18:34.090><c> Z</c><00:18:34.540><c> as</c><00:18:34.780><c> the</c>

00:18:35.220 --> 00:18:35.230 align:start position:0%
just note here that I'm writing Z as the
 

00:18:35.230 --> 00:18:38.520 align:start position:0%
just note here that I'm writing Z as the
input<00:18:35.770><c> to</c><00:18:36.490><c> the</c><00:18:36.820><c> to</c><00:18:37.780><c> the</c><00:18:37.930><c> activation</c><00:18:38.350><c> function</c>

00:18:38.520 --> 00:18:38.530 align:start position:0%
input to the to the activation function
 

00:18:38.530 --> 00:18:41.040 align:start position:0%
input to the to the activation function
so<00:18:39.220><c> this</c><00:18:39.400><c> is</c><00:18:39.580><c> the</c><00:18:40.420><c> weighted</c><00:18:40.900><c> combination</c>

00:18:41.040 --> 00:18:41.050 align:start position:0%
so this is the weighted combination
 

00:18:41.050 --> 00:18:45.210 align:start position:0%
so this is the weighted combination
essentially<00:18:41.920><c> of</c><00:18:42.070><c> your</c><00:18:42.280><c> inputs</c><00:18:43.710><c> Y</c><00:18:44.710><c> is</c><00:18:44.770><c> then</c>

00:18:45.210 --> 00:18:45.220 align:start position:0%
essentially of your inputs Y is then
 

00:18:45.220 --> 00:18:47.880 align:start position:0%
essentially of your inputs Y is then
taking<00:18:45.940><c> the</c><00:18:46.510><c> activation</c><00:18:47.200><c> function</c><00:18:47.230><c> with</c>

00:18:47.880 --> 00:18:47.890 align:start position:0%
taking the activation function with
 

00:18:47.890 --> 00:18:52.290 align:start position:0%
taking the activation function with
input<00:18:48.310><c> Z</c><00:18:49.980><c> so</c><00:18:50.980><c> the</c><00:18:51.250><c> final</c><00:18:51.520><c> output</c><00:18:51.640><c> like</c><00:18:52.000><c> I</c><00:18:52.120><c> said</c>

00:18:52.290 --> 00:18:52.300 align:start position:0%
input Z so the final output like I said
 

00:18:52.300 --> 00:18:55.530 align:start position:0%
input Z so the final output like I said
Y<00:18:52.510><c> is</c><00:18:52.780><c> is</c><00:18:53.740><c> on</c><00:18:54.490><c> the</c><00:18:54.520><c> right-hand</c><00:18:54.790><c> side</c><00:18:55.060><c> here</c><00:18:55.180><c> and</c>

00:18:55.530 --> 00:18:55.540 align:start position:0%
Y is is on the right-hand side here and
 

00:18:55.540 --> 00:18:58.590 align:start position:0%
Y is is on the right-hand side here and
it's<00:18:56.320><c> the</c><00:18:57.000><c> activation</c><00:18:58.000><c> function</c><00:18:58.300><c> applied</c><00:18:58.360><c> to</c>

00:18:58.590 --> 00:18:58.600 align:start position:0%
it's the activation function applied to
 

00:18:58.600 --> 00:19:01.440 align:start position:0%
it's the activation function applied to
this<00:18:58.840><c> weighted</c><00:18:59.200><c> sum</c><00:18:59.610><c> if</c><00:19:00.610><c> we</c><00:19:00.880><c> want</c><00:19:01.060><c> to</c><00:19:01.090><c> define</c><00:19:01.390><c> a</c>

00:19:01.440 --> 00:19:01.450 align:start position:0%
this weighted sum if we want to define a
 

00:19:01.450 --> 00:19:03.630 align:start position:0%
this weighted sum if we want to define a
multi<00:19:01.870><c> output</c><00:19:02.080><c> neural</c><00:19:02.500><c> network</c><00:19:02.830><c> now</c><00:19:03.250><c> all</c><00:19:03.490><c> we</c>

00:19:03.630 --> 00:19:03.640 align:start position:0%
multi output neural network now all we
 

00:19:03.640 --> 00:19:05.790 align:start position:0%
multi output neural network now all we
have<00:19:03.730><c> to</c><00:19:03.790><c> do</c><00:19:04.000><c> is</c><00:19:04.240><c> add</c><00:19:04.750><c> another</c><00:19:04.780><c> perceptron</c><00:19:05.650><c> to</c>

00:19:05.790 --> 00:19:05.800 align:start position:0%
have to do is add another perceptron to
 

00:19:05.800 --> 00:19:08.820 align:start position:0%
have to do is add another perceptron to
this<00:19:05.920><c> picture</c><00:19:07.050><c> now</c><00:19:08.050><c> we</c><00:19:08.080><c> have</c><00:19:08.260><c> two</c><00:19:08.440><c> outputs</c>

00:19:08.820 --> 00:19:08.830 align:start position:0%
this picture now we have two outputs
 

00:19:08.830 --> 00:19:10.800 align:start position:0%
this picture now we have two outputs
each<00:19:09.130><c> one</c><00:19:09.430><c> is</c><00:19:09.580><c> a</c><00:19:09.610><c> normal</c><00:19:10.060><c> perceptron</c><00:19:10.540><c> like</c><00:19:10.720><c> we</c>

00:19:10.800 --> 00:19:10.810 align:start position:0%
each one is a normal perceptron like we
 

00:19:10.810 --> 00:19:13.710 align:start position:0%
each one is a normal perceptron like we
defined<00:19:11.110><c> before</c><00:19:11.170><c> no</c><00:19:11.770><c> nothing</c><00:19:12.280><c> extra</c><00:19:12.610><c> and</c><00:19:12.820><c> each</c>

00:19:13.710 --> 00:19:13.720 align:start position:0%
defined before no nothing extra and each
 

00:19:13.720 --> 00:19:15.420 align:start position:0%
defined before no nothing extra and each
one<00:19:13.990><c> is</c><00:19:14.020><c> taking</c><00:19:14.500><c> all</c><00:19:14.680><c> the</c><00:19:14.800><c> inputs</c><00:19:15.160><c> from</c><00:19:15.310><c> the</c>

00:19:15.420 --> 00:19:15.430 align:start position:0%
one is taking all the inputs from the
 

00:19:15.430 --> 00:19:17.520 align:start position:0%
one is taking all the inputs from the
left-hand<00:19:15.790><c> side</c><00:19:16.110><c> computing</c><00:19:17.110><c> this</c><00:19:17.200><c> weighted</c>

00:19:17.520 --> 00:19:17.530 align:start position:0%
left-hand side computing this weighted
 

00:19:17.530 --> 00:19:21.570 align:start position:0%
left-hand side computing this weighted
sum<00:19:18.360><c> adding</c><00:19:19.360><c> a</c><00:19:19.420><c> bias</c><00:19:19.600><c> and</c><00:19:20.490><c> passing</c><00:19:21.490><c> it</c><00:19:21.550><c> through</c>

00:19:21.570 --> 00:19:21.580 align:start position:0%
sum adding a bias and passing it through
 

00:19:21.580 --> 00:19:24.510 align:start position:0%
sum adding a bias and passing it through
an<00:19:21.760><c> activation</c><00:19:22.090><c> function</c><00:19:23.160><c> let's</c><00:19:24.160><c> keep</c><00:19:24.280><c> going</c>

00:19:24.510 --> 00:19:24.520 align:start position:0%
an activation function let's keep going
 

00:19:24.520 --> 00:19:26.340 align:start position:0%
an activation function let's keep going
now<00:19:25.390><c> let's</c><00:19:25.600><c> take</c><00:19:25.780><c> a</c><00:19:25.810><c> look</c><00:19:25.960><c> at</c><00:19:26.080><c> a</c><00:19:26.140><c> single</c>

00:19:26.340 --> 00:19:26.350 align:start position:0%
now let's take a look at a single
 

00:19:26.350 --> 00:19:28.620 align:start position:0%
now let's take a look at a single
layered<00:19:26.680><c> neural</c><00:19:26.920><c> network</c><00:19:27.340><c> this</c><00:19:28.090><c> is</c><00:19:28.150><c> one</c><00:19:28.450><c> where</c>

00:19:28.620 --> 00:19:28.630 align:start position:0%
layered neural network this is one where
 

00:19:28.630 --> 00:19:30.300 align:start position:0%
layered neural network this is one where
we<00:19:28.720><c> have</c><00:19:28.840><c> a</c><00:19:28.870><c> single</c><00:19:29.170><c> hidden</c><00:19:29.560><c> layer</c><00:19:29.710><c> between</c>

00:19:30.300 --> 00:19:30.310 align:start position:0%
we have a single hidden layer between
 

00:19:30.310 --> 00:19:32.370 align:start position:0%
we have a single hidden layer between
our<00:19:30.430><c> inputs</c><00:19:30.760><c> and</c><00:19:30.910><c> our</c><00:19:31.000><c> outputs</c><00:19:31.330><c> we</c><00:19:32.050><c> call</c><00:19:32.230><c> it</c><00:19:32.320><c> a</c>

00:19:32.370 --> 00:19:32.380 align:start position:0%
our inputs and our outputs we call it a
 

00:19:32.380 --> 00:19:34.740 align:start position:0%
our inputs and our outputs we call it a
hidden<00:19:32.620><c> layer</c><00:19:32.770><c> because</c><00:19:33.160><c> unlike</c><00:19:34.060><c> the</c><00:19:34.300><c> input</c>

00:19:34.740 --> 00:19:34.750 align:start position:0%
hidden layer because unlike the input
 

00:19:34.750 --> 00:19:36.540 align:start position:0%
hidden layer because unlike the input
and<00:19:34.900><c> the</c><00:19:35.440><c> output</c><00:19:35.500><c> which</c><00:19:36.070><c> are</c><00:19:36.250><c> strictly</c>

00:19:36.540 --> 00:19:36.550 align:start position:0%
and the output which are strictly
 

00:19:36.550 --> 00:19:39.450 align:start position:0%
and the output which are strictly
observable<00:19:37.330><c> or</c><00:19:37.900><c> hidden</c><00:19:38.140><c> layers</c><00:19:38.410><c> learned</c><00:19:38.830><c> so</c>

00:19:39.450 --> 00:19:39.460 align:start position:0%
observable or hidden layers learned so
 

00:19:39.460 --> 00:19:42.240 align:start position:0%
observable or hidden layers learned so
we<00:19:39.580><c> don't</c><00:19:39.760><c> explicitly</c><00:19:40.180><c> enforce</c><00:19:40.810><c> any</c><00:19:41.250><c> behavior</c>

00:19:42.240 --> 00:19:42.250 align:start position:0%
we don't explicitly enforce any behavior
 

00:19:42.250 --> 00:19:43.770 align:start position:0%
we don't explicitly enforce any behavior
on<00:19:42.490><c> the</c><00:19:42.820><c> hidden</c><00:19:42.940><c> layer</c><00:19:43.210><c> and</c><00:19:43.390><c> that's</c><00:19:43.480><c> why</c><00:19:43.630><c> we</c>

00:19:43.770 --> 00:19:43.780 align:start position:0%
on the hidden layer and that's why we
 

00:19:43.780 --> 00:19:46.500 align:start position:0%
on the hidden layer and that's why we
call<00:19:43.900><c> it</c><00:19:43.930><c> hidden</c><00:19:44.200><c> in</c><00:19:44.440><c> that</c><00:19:44.650><c> sense</c><00:19:45.390><c> since</c><00:19:46.390><c> we</c>

00:19:46.500 --> 00:19:46.510 align:start position:0%
call it hidden in that sense since we
 

00:19:46.510 --> 00:19:48.000 align:start position:0%
call it hidden in that sense since we
now<00:19:46.660><c> have</c><00:19:46.840><c> a</c><00:19:46.870><c> transformation</c><00:19:47.620><c> from</c><00:19:47.890><c> the</c>

00:19:48.000 --> 00:19:48.010 align:start position:0%
now have a transformation from the
 

00:19:48.010 --> 00:19:50.190 align:start position:0%
now have a transformation from the
inputs<00:19:48.430><c> to</c><00:19:48.880><c> the</c><00:19:49.000><c> hidden</c><00:19:49.150><c> layer</c><00:19:49.390><c> and</c><00:19:49.630><c> hidden</c>

00:19:50.190 --> 00:19:50.200 align:start position:0%
inputs to the hidden layer and hidden
 

00:19:50.200 --> 00:19:53.040 align:start position:0%
inputs to the hidden layer and hidden
layer<00:19:50.380><c> to</c><00:19:50.620><c> the</c><00:19:50.710><c> outputs</c><00:19:51.720><c> we're</c><00:19:52.720><c> going</c><00:19:52.840><c> to</c><00:19:52.900><c> need</c>

00:19:53.040 --> 00:19:53.050 align:start position:0%
layer to the outputs we're going to need
 

00:19:53.050 --> 00:19:55.950 align:start position:0%
layer to the outputs we're going to need
two<00:19:53.380><c> weight</c><00:19:53.800><c> matrices</c><00:19:54.540><c> so</c><00:19:55.540><c> we're</c><00:19:55.780><c> going</c><00:19:55.900><c> to</c>

00:19:55.950 --> 00:19:55.960 align:start position:0%
two weight matrices so we're going to
 

00:19:55.960 --> 00:19:58.650 align:start position:0%
two weight matrices so we're going to
call<00:19:56.110><c> it</c><00:19:56.230><c> W</c><00:19:56.770><c> one</c><00:19:57.040><c> to</c><00:19:57.430><c> go</c><00:19:57.580><c> from</c><00:19:57.820><c> input</c><00:19:58.240><c> to</c><00:19:58.540><c> hidden</c>

00:19:58.650 --> 00:19:58.660 align:start position:0%
call it W one to go from input to hidden
 

00:19:58.660 --> 00:20:02.280 align:start position:0%
call it W one to go from input to hidden
layer<00:19:58.960><c> and</c><00:19:59.200><c> W</c><00:19:59.920><c> two</c><00:20:00.160><c> to</c><00:20:00.670><c> go</c><00:20:00.790><c> from</c><00:20:01.110><c> hidden</c><00:20:02.110><c> layer</c>

00:20:02.280 --> 00:20:02.290 align:start position:0%
layer and W two to go from hidden layer
 

00:20:02.290 --> 00:20:02.730 align:start position:0%
layer and W two to go from hidden layer
to

00:20:02.730 --> 00:20:02.740 align:start position:0%
to
 

00:20:02.740 --> 00:20:05.430 align:start position:0%
to
output<00:20:03.390><c> but</c><00:20:04.390><c> again</c><00:20:04.630><c> the</c><00:20:04.900><c> story</c><00:20:05.110><c> here's</c><00:20:05.290><c> the</c>

00:20:05.430 --> 00:20:05.440 align:start position:0%
output but again the story here's the
 

00:20:05.440 --> 00:20:08.970 align:start position:0%
output but again the story here's the
same<00:20:05.820><c> dot</c><00:20:06.820><c> product</c><00:20:07.240><c> add</c><00:20:07.450><c> a</c><00:20:07.510><c> bias</c><00:20:07.840><c> for</c><00:20:08.650><c> each</c><00:20:08.800><c> of</c>

00:20:08.970 --> 00:20:08.980 align:start position:0%
same dot product add a bias for each of
 

00:20:08.980 --> 00:20:10.200 align:start position:0%
same dot product add a bias for each of
the<00:20:09.160><c> neurons</c><00:20:09.580><c> and</c><00:20:09.670><c> then</c><00:20:09.820><c> compute</c><00:20:10.059><c> an</c>

00:20:10.200 --> 00:20:10.210 align:start position:0%
the neurons and then compute an
 

00:20:10.210 --> 00:20:12.990 align:start position:0%
the neurons and then compute an
activation<00:20:10.570><c> function</c><00:20:10.720><c> let's</c><00:20:11.620><c> zoom</c><00:20:12.040><c> in</c><00:20:12.220><c> now</c><00:20:12.429><c> to</c>

00:20:12.990 --> 00:20:13.000 align:start position:0%
activation function let's zoom in now to
 

00:20:13.000 --> 00:20:15.570 align:start position:0%
activation function let's zoom in now to
a<00:20:13.030><c> single</c><00:20:13.630><c> hidden</c><00:20:14.170><c> hidden</c><00:20:14.770><c> unit</c><00:20:15.280><c> in</c><00:20:15.400><c> this</c>

00:20:15.570 --> 00:20:15.580 align:start position:0%
a single hidden hidden unit in this
 

00:20:15.580 --> 00:20:17.820 align:start position:0%
a single hidden hidden unit in this
hidden<00:20:15.790><c> layer</c><00:20:16.000><c> if</c><00:20:16.929><c> we</c><00:20:17.080><c> look</c><00:20:17.260><c> at</c><00:20:17.350><c> the</c><00:20:17.470><c> single</c>

00:20:17.820 --> 00:20:17.830 align:start position:0%
hidden layer if we look at the single
 

00:20:17.830 --> 00:20:20.790 align:start position:0%
hidden layer if we look at the single
unit<00:20:18.190><c> take</c><00:20:18.400><c> z2</c><00:20:18.790><c> for</c><00:20:19.030><c> example</c><00:20:19.420><c> it</c><00:20:19.990><c> is</c><00:20:20.470><c> just</c><00:20:20.500><c> the</c>

00:20:20.790 --> 00:20:20.800 align:start position:0%
unit take z2 for example it is just the
 

00:20:20.800 --> 00:20:23.010 align:start position:0%
unit take z2 for example it is just the
same<00:20:20.980><c> perceptron</c><00:20:21.520><c> that</c><00:20:21.640><c> we</c><00:20:21.730><c> saw</c><00:20:21.880><c> before</c><00:20:22.059><c> I'm</c>

00:20:23.010 --> 00:20:23.020 align:start position:0%
same perceptron that we saw before I'm
 

00:20:23.020 --> 00:20:24.390 align:start position:0%
same perceptron that we saw before I'm
going<00:20:23.230><c> to</c><00:20:23.290><c> keep</c><00:20:23.440><c> repeating</c><00:20:23.679><c> myself</c>

00:20:24.390 --> 00:20:24.400 align:start position:0%
going to keep repeating myself
 

00:20:24.400 --> 00:20:26.669 align:start position:0%
going to keep repeating myself
we<00:20:24.580><c> took</c><00:20:24.730><c> a</c><00:20:24.790><c> dot</c><00:20:25.059><c> product</c><00:20:25.300><c> with</c><00:20:25.540><c> the</c><00:20:25.660><c> inputs</c><00:20:25.990><c> we</c>

00:20:26.669 --> 00:20:26.679 align:start position:0%
we took a dot product with the inputs we
 

00:20:26.679 --> 00:20:29.669 align:start position:0%
we took a dot product with the inputs we
applied<00:20:26.950><c> a</c><00:20:26.980><c> bias</c><00:20:27.280><c> and</c><00:20:27.750><c> then</c><00:20:28.750><c> actually</c><00:20:29.440><c> so</c>

00:20:29.669 --> 00:20:29.679 align:start position:0%
applied a bias and then actually so
 

00:20:29.679 --> 00:20:31.020 align:start position:0%
applied a bias and then actually so
since<00:20:29.890><c> it's</c><00:20:30.040><c> Z</c><00:20:30.190><c> we</c><00:20:30.370><c> had</c><00:20:30.490><c> not</c><00:20:30.640><c> applied</c><00:20:30.820><c> our</c>

00:20:31.020 --> 00:20:31.030 align:start position:0%
since it's Z we had not applied our
 

00:20:31.030 --> 00:20:33.540 align:start position:0%
since it's Z we had not applied our
activation<00:20:31.510><c> function</c><00:20:31.870><c> yet</c><00:20:32.080><c> so</c><00:20:32.980><c> it's</c><00:20:33.130><c> just</c><00:20:33.370><c> a</c>

00:20:33.540 --> 00:20:33.550 align:start position:0%
activation function yet so it's just a
 

00:20:33.550 --> 00:20:36.690 align:start position:0%
activation function yet so it's just a
dot<00:20:34.210><c> product</c><00:20:34.600><c> plus</c><00:20:34.660><c> a</c><00:20:34.900><c> bias</c><00:20:35.170><c> so</c><00:20:35.410><c> far</c><00:20:35.650><c> if</c><00:20:36.280><c> we</c>

00:20:36.690 --> 00:20:36.700 align:start position:0%
dot product plus a bias so far if we
 

00:20:36.700 --> 00:20:38.540 align:start position:0%
dot product plus a bias so far if we
took<00:20:36.970><c> it</c><00:20:37.120><c> and</c><00:20:37.240><c> took</c><00:20:37.660><c> a</c><00:20:37.780><c> look</c><00:20:37.900><c> at</c><00:20:38.080><c> a</c><00:20:38.110><c> different</c>

00:20:38.540 --> 00:20:38.550 align:start position:0%
took it and took a look at a different
 

00:20:38.550 --> 00:20:42.750 align:start position:0%
took it and took a look at a different
neuron<00:20:39.550><c> let's</c><00:20:39.790><c> say</c><00:20:39.940><c> z3</c><00:20:40.480><c> or</c><00:20:40.720><c> z4</c><00:20:41.370><c> the</c><00:20:42.370><c> idea</c><00:20:42.610><c> here</c>

00:20:42.750 --> 00:20:42.760 align:start position:0%
neuron let's say z3 or z4 the idea here
 

00:20:42.760 --> 00:20:43.950 align:start position:0%
neuron let's say z3 or z4 the idea here
is<00:20:42.790><c> gonna</c><00:20:42.970><c> be</c><00:20:43.059><c> the</c><00:20:43.240><c> same</c><00:20:43.450><c> but</c><00:20:43.750><c> we're</c><00:20:43.870><c> probably</c>

00:20:43.950 --> 00:20:43.960 align:start position:0%
is gonna be the same but we're probably
 

00:20:43.960 --> 00:20:46.020 align:start position:0%
is gonna be the same but we're probably
going<00:20:44.230><c> to</c><00:20:44.290><c> end</c><00:20:44.440><c> up</c><00:20:44.500><c> with</c><00:20:44.620><c> a</c><00:20:44.679><c> different</c><00:20:45.220><c> value</c>

00:20:46.020 --> 00:20:46.030 align:start position:0%
going to end up with a different value
 

00:20:46.030 --> 00:20:48.330 align:start position:0%
going to end up with a different value
for<00:20:46.300><c> Z</c><00:20:46.510><c> 3</c><00:20:46.900><c> and</c><00:20:47.020><c> C</c><00:20:47.140><c> 4</c><00:20:47.170><c> just</c><00:20:47.620><c> because</c><00:20:47.860><c> the</c><00:20:48.100><c> weights</c>

00:20:48.330 --> 00:20:48.340 align:start position:0%
for Z 3 and C 4 just because the weights
 

00:20:48.340 --> 00:20:51.210 align:start position:0%
for Z 3 and C 4 just because the weights
leading<00:20:49.150><c> from</c><00:20:49.420><c> Z</c><00:20:50.110><c> 3</c><00:20:50.350><c> to</c><00:20:50.530><c> the</c><00:20:50.650><c> inputs</c><00:20:51.010><c> are</c><00:20:51.160><c> going</c>

00:20:51.210 --> 00:20:51.220 align:start position:0%
leading from Z 3 to the inputs are going
 

00:20:51.220 --> 00:20:52.590 align:start position:0%
leading from Z 3 to the inputs are going
to<00:20:51.340><c> be</c><00:20:51.460><c> different</c><00:20:51.910><c> for</c><00:20:52.150><c> each</c><00:20:52.210><c> of</c><00:20:52.300><c> those</c>

00:20:52.590 --> 00:20:52.600 align:start position:0%
to be different for each of those
 

00:20:52.600 --> 00:20:55.380 align:start position:0%
to be different for each of those
neurons<00:20:53.580><c> so</c><00:20:54.580><c> this</c><00:20:54.730><c> picture</c><00:20:55.030><c> looks</c><00:20:55.210><c> a</c><00:20:55.300><c> little</c>

00:20:55.380 --> 00:20:55.390 align:start position:0%
neurons so this picture looks a little
 

00:20:55.390 --> 00:20:56.850 align:start position:0%
neurons so this picture looks a little
bit<00:20:55.570><c> messy</c><00:20:55.870><c> so</c><00:20:56.020><c> let's</c><00:20:56.170><c> clean</c><00:20:56.380><c> things</c><00:20:56.559><c> up</c><00:20:56.740><c> a</c>

00:20:56.850 --> 00:20:56.860 align:start position:0%
bit messy so let's clean things up a
 

00:20:56.860 --> 00:20:58.350 align:start position:0%
bit messy so let's clean things up a
little<00:20:56.980><c> bit</c><00:20:57.100><c> more</c><00:20:57.370><c> and</c><00:20:57.580><c> just</c><00:20:57.610><c> replace</c><00:20:58.090><c> all</c><00:20:58.300><c> of</c>

00:20:58.350 --> 00:20:58.360 align:start position:0%
little bit more and just replace all of
 

00:20:58.360 --> 00:21:00.030 align:start position:0%
little bit more and just replace all of
these<00:20:58.540><c> hidden</c><00:20:58.870><c> layers</c><00:20:59.080><c> all</c><00:20:59.380><c> these</c><00:20:59.830><c> lines</c>

00:21:00.030 --> 00:21:00.040 align:start position:0%
these hidden layers all these lines
 

00:21:00.040 --> 00:21:02.640 align:start position:0%
these hidden layers all these lines
between<00:21:00.250><c> the</c><00:21:00.460><c> hidden</c><00:21:00.670><c> layers</c><00:21:01.470><c> with</c><00:21:02.470><c> these</c>

00:21:02.640 --> 00:21:02.650 align:start position:0%
between the hidden layers with these
 

00:21:02.650 --> 00:21:04.380 align:start position:0%
between the hidden layers with these
symbols<00:21:02.920><c> these</c><00:21:03.490><c> symbols</c><00:21:03.850><c> denote</c><00:21:04.150><c> fully</c>

00:21:04.380 --> 00:21:04.390 align:start position:0%
symbols these symbols denote fully
 

00:21:04.390 --> 00:21:06.930 align:start position:0%
symbols these symbols denote fully
connected<00:21:04.870><c> layers</c><00:21:05.110><c> where</c><00:21:05.830><c> each</c><00:21:06.100><c> input</c><00:21:06.400><c> to</c><00:21:06.850><c> the</c>

00:21:06.930 --> 00:21:06.940 align:start position:0%
connected layers where each input to the
 

00:21:06.940 --> 00:21:09.210 align:start position:0%
connected layers where each input to the
layer<00:21:07.120><c> is</c><00:21:07.390><c> connected</c><00:21:08.200><c> to</c><00:21:08.290><c> each</c><00:21:08.440><c> output</c><00:21:08.950><c> of</c><00:21:09.130><c> the</c>

00:21:09.210 --> 00:21:09.220 align:start position:0%
layer is connected to each output of the
 

00:21:09.220 --> 00:21:11.280 align:start position:0%
layer is connected to each output of the
layer<00:21:09.370><c> another</c><00:21:10.179><c> common</c><00:21:10.510><c> name</c><00:21:10.540><c> for</c><00:21:10.690><c> these</c><00:21:10.990><c> is</c>

00:21:11.280 --> 00:21:11.290 align:start position:0%
layer another common name for these is
 

00:21:11.290 --> 00:21:15.470 align:start position:0%
layer another common name for these is
called<00:21:11.500><c> dense</c><00:21:11.920><c> layers</c><00:21:12.220><c> and</c><00:21:13.740><c> you</c><00:21:14.740><c> can</c><00:21:14.890><c> actually</c>

00:21:15.470 --> 00:21:15.480 align:start position:0%
called dense layers and you can actually
 

00:21:15.480 --> 00:21:18.840 align:start position:0%
called dense layers and you can actually
write<00:21:16.480><c> this</c><00:21:16.690><c> in</c><00:21:16.929><c> tensor</c><00:21:17.740><c> flow</c><00:21:17.860><c> using</c><00:21:18.520><c> just</c>

00:21:18.840 --> 00:21:18.850 align:start position:0%
write this in tensor flow using just
 

00:21:18.850 --> 00:21:20.549 align:start position:0%
write this in tensor flow using just
four<00:21:19.030><c> lines</c><00:21:19.179><c> of</c><00:21:19.390><c> code</c><00:21:19.450><c> so</c><00:21:19.840><c> this</c><00:21:19.960><c> neural</c>

00:21:20.549 --> 00:21:20.559 align:start position:0%
four lines of code so this neural
 

00:21:20.559 --> 00:21:22.260 align:start position:0%
four lines of code so this neural
network<00:21:20.590><c> which</c><00:21:21.040><c> is</c><00:21:21.160><c> a</c><00:21:21.190><c> single</c><00:21:21.580><c> layered</c><00:21:21.820><c> multi</c>

00:21:22.260 --> 00:21:22.270 align:start position:0%
network which is a single layered multi
 

00:21:22.270 --> 00:21:25.280 align:start position:0%
network which is a single layered multi
output<00:21:22.420><c> neural</c><00:21:22.990><c> network</c><00:21:23.350><c> can</c><00:21:23.590><c> be</c><00:21:24.280><c> called</c><00:21:24.610><c> by</c>

00:21:25.280 --> 00:21:25.290 align:start position:0%
output neural network can be called by
 

00:21:25.290 --> 00:21:27.990 align:start position:0%
output neural network can be called by
instantiating<00:21:26.290><c> your</c><00:21:26.530><c> inputs</c><00:21:26.890><c> feeding</c><00:21:27.850><c> those</c>

00:21:27.990 --> 00:21:28.000 align:start position:0%
instantiating your inputs feeding those
 

00:21:28.000 --> 00:21:30.120 align:start position:0%
instantiating your inputs feeding those
inputs<00:21:28.420><c> into</c><00:21:28.600><c> a</c><00:21:29.020><c> hidden</c><00:21:29.500><c> layer</c><00:21:29.650><c> like</c><00:21:30.010><c> I'm</c>

00:21:30.120 --> 00:21:30.130 align:start position:0%
inputs into a hidden layer like I'm
 

00:21:30.130 --> 00:21:31.740 align:start position:0%
inputs into a hidden layer like I'm
doing<00:21:30.520><c> here</c><00:21:30.700><c> which</c><00:21:30.880><c> is</c><00:21:31.030><c> just</c><00:21:31.059><c> defined</c><00:21:31.570><c> as</c><00:21:31.720><c> a</c>

00:21:31.740 --> 00:21:31.750 align:start position:0%
doing here which is just defined as a
 

00:21:31.750 --> 00:21:35.240 align:start position:0%
doing here which is just defined as a
single<00:21:32.200><c> dense</c><00:21:32.500><c> layer</c><00:21:32.800><c> and</c><00:21:33.190><c> then</c><00:21:33.910><c> taking</c><00:21:34.330><c> those</c>

00:21:35.240 --> 00:21:35.250 align:start position:0%
single dense layer and then taking those
 

00:21:35.250 --> 00:21:38.130 align:start position:0%
single dense layer and then taking those
hidden<00:21:36.250><c> outputs</c><00:21:36.700><c> feeding</c><00:21:37.510><c> that</c><00:21:37.660><c> into</c><00:21:37.929><c> another</c>

00:21:38.130 --> 00:21:38.140 align:start position:0%
hidden outputs feeding that into another
 

00:21:38.140 --> 00:21:42.780 align:start position:0%
hidden outputs feeding that into another
dense<00:21:38.679><c> layer</c><00:21:39.179><c> to</c><00:21:40.179><c> produce</c><00:21:40.360><c> your</c><00:21:40.570><c> outputs</c><00:21:41.790><c> the</c>

00:21:42.780 --> 00:21:42.790 align:start position:0%
dense layer to produce your outputs the
 

00:21:42.790 --> 00:21:44.070 align:start position:0%
dense layer to produce your outputs the
final<00:21:43.059><c> model</c><00:21:43.210><c> is</c><00:21:43.420><c> to</c><00:21:43.540><c> find</c><00:21:43.720><c> it</c><00:21:43.840><c> end</c><00:21:43.960><c> to</c><00:21:44.050><c> end</c>

00:21:44.070 --> 00:21:44.080 align:start position:0%
final model is to find it end to end
 

00:21:44.080 --> 00:21:46.140 align:start position:0%
final model is to find it end to end
with<00:21:44.380><c> that</c><00:21:44.470><c> single</c><00:21:44.830><c> line</c><00:21:44.950><c> at</c><00:21:45.130><c> the</c><00:21:45.220><c> end</c><00:21:45.370><c> model</c>

00:21:46.140 --> 00:21:46.150 align:start position:0%
with that single line at the end model
 

00:21:46.150 --> 00:21:47.820 align:start position:0%
with that single line at the end model
of<00:21:46.270><c> inputs</c><00:21:46.630><c> and</c><00:21:46.900><c> outputs</c><00:21:47.440><c> and</c><00:21:47.500><c> that</c><00:21:47.650><c> just</c>

00:21:47.820 --> 00:21:47.830 align:start position:0%
of inputs and outputs and that just
 

00:21:47.830 --> 00:21:49.799 align:start position:0%
of inputs and outputs and that just
essentially<00:21:48.280><c> connects</c><00:21:48.670><c> the</c><00:21:48.850><c> graph</c><00:21:49.059><c> and</c><00:21:49.330><c> to</c>

00:21:49.799 --> 00:21:49.809 align:start position:0%
essentially connects the graph and to
 

00:21:49.809 --> 00:21:53.940 align:start position:0%
essentially connects the graph and to
end<00:21:51.750><c> so</c><00:21:52.750><c> now</c><00:21:52.929><c> let's</c><00:21:53.290><c> keep</c><00:21:53.440><c> building</c><00:21:53.559><c> on</c><00:21:53.830><c> this</c>

00:21:53.940 --> 00:21:53.950 align:start position:0%
end so now let's keep building on this
 

00:21:53.950 --> 00:21:55.710 align:start position:0%
end so now let's keep building on this
idea<00:21:54.220><c> now</c><00:21:54.550><c> we</c><00:21:54.610><c> want</c><00:21:54.910><c> to</c><00:21:55.000><c> build</c><00:21:55.150><c> a</c><00:21:55.300><c> deep</c><00:21:55.510><c> neural</c>

00:21:55.710 --> 00:21:55.720 align:start position:0%
idea now we want to build a deep neural
 

00:21:55.720 --> 00:21:57.150 align:start position:0%
idea now we want to build a deep neural
network<00:21:56.140><c> what</c><00:21:56.320><c> is</c><00:21:56.440><c> the</c><00:21:56.530><c> deep</c><00:21:56.679><c> neural</c><00:21:56.830><c> network</c>

00:21:57.150 --> 00:21:57.160 align:start position:0%
network what is the deep neural network
 

00:21:57.160 --> 00:21:58.410 align:start position:0%
network what is the deep neural network
well<00:21:57.340><c> it's</c><00:21:57.490><c> just</c><00:21:57.580><c> one</c><00:21:57.940><c> where</c><00:21:58.150><c> we</c><00:21:58.240><c> keep</c>

00:21:58.410 --> 00:21:58.420 align:start position:0%
well it's just one where we keep
 

00:21:58.420 --> 00:22:00.360 align:start position:0%
well it's just one where we keep
stacking<00:21:58.840><c> these</c><00:21:59.200><c> hidden</c><00:21:59.590><c> layers</c><00:21:59.800><c> back</c><00:22:00.160><c> to</c>

00:22:00.360 --> 00:22:00.370 align:start position:0%
stacking these hidden layers back to
 

00:22:00.370 --> 00:22:01.680 align:start position:0%
stacking these hidden layers back to
back<00:22:00.550><c> to</c><00:22:00.700><c> back</c><00:22:00.730><c> to</c><00:22:00.910><c> back</c><00:22:01.150><c> to</c><00:22:01.210><c> create</c>

00:22:01.680 --> 00:22:01.690 align:start position:0%
back to back to back to create
 

00:22:01.690 --> 00:22:04.880 align:start position:0%
back to back to back to create
increasingly<00:22:02.730><c> deeper</c><00:22:03.730><c> and</c><00:22:03.880><c> deeper</c><00:22:04.179><c> models</c>

00:22:04.880 --> 00:22:04.890 align:start position:0%
increasingly deeper and deeper models
 

00:22:04.890 --> 00:22:07.200 align:start position:0%
increasingly deeper and deeper models
one<00:22:05.890><c> where</c><00:22:06.070><c> the</c><00:22:06.190><c> output</c><00:22:06.550><c> is</c><00:22:06.670><c> computed</c><00:22:07.090><c> by</c>

00:22:07.200 --> 00:22:07.210 align:start position:0%
one where the output is computed by
 

00:22:07.210 --> 00:22:08.970 align:start position:0%
one where the output is computed by
going<00:22:07.600><c> deeper</c><00:22:08.320><c> into</c><00:22:08.500><c> the</c><00:22:08.590><c> network</c><00:22:08.860><c> and</c>

00:22:08.970 --> 00:22:08.980 align:start position:0%
going deeper into the network and
 

00:22:08.980 --> 00:22:11.159 align:start position:0%
going deeper into the network and
computing<00:22:09.460><c> these</c><00:22:09.640><c> weighted</c><00:22:10.030><c> sums</c><00:22:10.360><c> over</c><00:22:10.630><c> and</c>

00:22:11.159 --> 00:22:11.169 align:start position:0%
computing these weighted sums over and
 

00:22:11.169 --> 00:22:12.360 align:start position:0%
computing these weighted sums over and
over<00:22:11.350><c> and</c><00:22:11.470><c> over</c><00:22:11.559><c> again</c><00:22:11.800><c> with</c><00:22:12.220><c> these</c>

00:22:12.360 --> 00:22:12.370 align:start position:0%
over and over again with these
 

00:22:12.370 --> 00:22:16.030 align:start position:0%
over and over again with these
activation<00:22:12.880><c> functions</c><00:22:13.270><c> repeatedly</c><00:22:13.840><c> applied</c>

00:22:16.030 --> 00:22:16.040 align:start position:0%
activation functions repeatedly applied
 

00:22:16.040 --> 00:22:17.980 align:start position:0%
activation functions repeatedly applied
so<00:22:16.670><c> this</c><00:22:16.790><c> is</c><00:22:16.910><c> awesome</c><00:22:17.240><c> now</c><00:22:17.420><c> we</c><00:22:17.450><c> have</c><00:22:17.660><c> an</c><00:22:17.750><c> idea</c>

00:22:17.980 --> 00:22:17.990 align:start position:0%
so this is awesome now we have an idea
 

00:22:17.990 --> 00:22:19.570 align:start position:0%
so this is awesome now we have an idea
on<00:22:18.200><c> how</c><00:22:18.350><c> to</c><00:22:18.380><c> actually</c><00:22:18.680><c> build</c><00:22:18.860><c> a</c><00:22:19.340><c> neural</c>

00:22:19.570 --> 00:22:19.580 align:start position:0%
on how to actually build a neural
 

00:22:19.580 --> 00:22:21.220 align:start position:0%
on how to actually build a neural
network<00:22:19.760><c> from</c><00:22:20.060><c> scratch</c><00:22:20.390><c> going</c><00:22:20.840><c> all</c><00:22:21.020><c> the</c><00:22:21.140><c> way</c>

00:22:21.220 --> 00:22:21.230 align:start position:0%
network from scratch going all the way
 

00:22:21.230 --> 00:22:24.460 align:start position:0%
network from scratch going all the way
from<00:22:21.500><c> a</c><00:22:21.710><c> single</c><00:22:22.280><c> perceptron</c><00:22:22.790><c> and</c><00:22:23.260><c> we</c><00:22:24.260><c> know</c><00:22:24.350><c> how</c>

00:22:24.460 --> 00:22:24.470 align:start position:0%
from a single perceptron and we know how
 

00:22:24.470 --> 00:22:25.870 align:start position:0%
from a single perceptron and we know how
to<00:22:24.500><c> compose</c><00:22:24.920><c> them</c><00:22:25.160><c> to</c><00:22:25.370><c> create</c><00:22:25.610><c> very</c><00:22:25.850><c> complex</c>

00:22:25.870 --> 00:22:25.880 align:start position:0%
to compose them to create very complex
 

00:22:25.880 --> 00:22:28.810 align:start position:0%
to compose them to create very complex
deep<00:22:26.540><c> neural</c><00:22:26.720><c> networks</c><00:22:27.110><c> as</c><00:22:27.260><c> well</c><00:22:27.640><c> let's</c><00:22:28.640><c> take</c>

00:22:28.810 --> 00:22:28.820 align:start position:0%
deep neural networks as well let's take
 

00:22:28.820 --> 00:22:30.730 align:start position:0%
deep neural networks as well let's take
a<00:22:28.850><c> look</c><00:22:29.060><c> at</c><00:22:29.180><c> how</c><00:22:29.300><c> we</c><00:22:29.360><c> can</c><00:22:29.600><c> apply</c><00:22:30.110><c> this</c><00:22:30.380><c> to</c><00:22:30.710><c> a</c>

00:22:30.730 --> 00:22:30.740 align:start position:0%
a look at how we can apply this to a
 

00:22:30.740 --> 00:22:33.130 align:start position:0%
a look at how we can apply this to a
very<00:22:30.980><c> real</c><00:22:31.250><c> problem</c><00:22:31.730><c> that</c><00:22:31.940><c> I</c><00:22:32.630><c> know</c><00:22:32.690><c> a</c><00:22:32.840><c> lot</c><00:22:33.110><c> of</c>

00:22:33.130 --> 00:22:33.140 align:start position:0%
very real problem that I know a lot of
 

00:22:33.140 --> 00:22:34.510 align:start position:0%
very real problem that I know a lot of
you<00:22:33.410><c> probably</c><00:22:33.830><c> care</c><00:22:34.040><c> about</c><00:22:34.250><c> so</c><00:22:34.400><c> I</c><00:22:34.430><c> was</c>

00:22:34.510 --> 00:22:34.520 align:start position:0%
you probably care about so I was
 

00:22:34.520 --> 00:22:37.050 align:start position:0%
you probably care about so I was
thinking<00:22:34.910><c> of</c><00:22:35.120><c> a</c><00:22:35.420><c> problem</c><00:22:35.660><c> potential</c><00:22:36.380><c> that</c>

00:22:37.050 --> 00:22:37.060 align:start position:0%
thinking of a problem potential that
 

00:22:37.060 --> 00:22:39.640 align:start position:0%
thinking of a problem potential that
some<00:22:38.060><c> of</c><00:22:38.180><c> you</c><00:22:38.270><c> might</c><00:22:38.450><c> care</c><00:22:38.660><c> about</c><00:22:38.690><c> it</c><00:22:38.990><c> took</c><00:22:39.500><c> me</c>

00:22:39.640 --> 00:22:39.650 align:start position:0%
some of you might care about it took me
 

00:22:39.650 --> 00:22:41.440 align:start position:0%
some of you might care about it took me
a<00:22:39.680><c> while</c><00:22:39.830><c> but</c><00:22:40.130><c> I</c><00:22:40.160><c> think</c><00:22:40.250><c> this</c><00:22:40.610><c> might</c><00:22:40.850><c> be</c><00:22:40.880><c> one</c><00:22:41.180><c> so</c>

00:22:41.440 --> 00:22:41.450 align:start position:0%
a while but I think this might be one so
 

00:22:41.450 --> 00:22:44.440 align:start position:0%
a while but I think this might be one so
at<00:22:42.410><c> MIT</c><00:22:42.740><c> we</c><00:22:43.040><c> care</c><00:22:43.280><c> a</c><00:22:43.310><c> lot</c><00:22:43.370><c> about</c><00:22:43.580><c> passing</c><00:22:44.360><c> our</c>

00:22:44.440 --> 00:22:44.450 align:start position:0%
at MIT we care a lot about passing our
 

00:22:44.450 --> 00:22:46.450 align:start position:0%
at MIT we care a lot about passing our
classes<00:22:44.930><c> so</c><00:22:45.320><c> I</c><00:22:45.350><c> think</c><00:22:45.530><c> a</c><00:22:45.770><c> very</c><00:22:46.040><c> good</c><00:22:46.340><c> example</c>

00:22:46.450 --> 00:22:46.460 align:start position:0%
classes so I think a very good example
 

00:22:46.460 --> 00:22:48.310 align:start position:0%
classes so I think a very good example
is<00:22:46.940><c> let's</c><00:22:47.540><c> train</c><00:22:47.720><c> a</c><00:22:47.750><c> neural</c><00:22:47.930><c> network</c><00:22:48.200><c> to</c>

00:22:48.310 --> 00:22:48.320 align:start position:0%
is let's train a neural network to
 

00:22:48.320 --> 00:22:49.750 align:start position:0%
is let's train a neural network to
determine<00:22:49.010><c> if</c><00:22:49.100><c> you're</c><00:22:49.220><c> gonna</c><00:22:49.340><c> pass</c><00:22:49.580><c> your</c>

00:22:49.750 --> 00:22:49.760 align:start position:0%
determine if you're gonna pass your
 

00:22:49.760 --> 00:22:53.320 align:start position:0%
determine if you're gonna pass your
class<00:22:51.310><c> so</c><00:22:52.310><c> to</c><00:22:52.340><c> do</c><00:22:52.550><c> this</c><00:22:52.670><c> let's</c><00:22:52.730><c> start</c><00:22:53.030><c> with</c><00:22:53.300><c> a</c>

00:22:53.320 --> 00:22:53.330 align:start position:0%
class so to do this let's start with a
 

00:22:53.330 --> 00:22:55.780 align:start position:0%
class so to do this let's start with a
simple<00:22:53.570><c> two</c><00:22:54.020><c> input</c><00:22:54.500><c> feature</c><00:22:54.740><c> model</c><00:22:55.040><c> one</c>

00:22:55.780 --> 00:22:55.790 align:start position:0%
simple two input feature model one
 

00:22:55.790 --> 00:22:57.280 align:start position:0%
simple two input feature model one
feature<00:22:56.060><c> is</c><00:22:56.300><c> the</c><00:22:56.480><c> number</c><00:22:56.780><c> of</c><00:22:56.900><c> lectures</c><00:22:57.080><c> that</c>

00:22:57.280 --> 00:22:57.290 align:start position:0%
feature is the number of lectures that
 

00:22:57.290 --> 00:22:59.500 align:start position:0%
feature is the number of lectures that
you<00:22:57.530><c> attend</c><00:22:57.890><c> the</c><00:22:58.640><c> other</c><00:22:58.790><c> feature</c><00:22:59.060><c> is</c><00:22:59.210><c> the</c>

00:22:59.500 --> 00:22:59.510 align:start position:0%
you attend the other feature is the
 

00:22:59.510 --> 00:23:01.120 align:start position:0%
you attend the other feature is the
number<00:22:59.870><c> of</c><00:22:59.900><c> hours</c><00:23:00.440><c> that</c><00:23:00.470><c> you</c><00:23:00.620><c> spend</c><00:23:00.920><c> on</c><00:23:01.040><c> the</c>

00:23:01.120 --> 00:23:01.130 align:start position:0%
number of hours that you spend on the
 

00:23:01.130 --> 00:23:05.380 align:start position:0%
number of hours that you spend on the
final<00:23:01.400><c> project</c><00:23:03.400><c> again</c><00:23:04.400><c> since</c><00:23:05.060><c> we</c><00:23:05.150><c> have</c><00:23:05.270><c> two</c>

00:23:05.380 --> 00:23:05.390 align:start position:0%
final project again since we have two
 

00:23:05.390 --> 00:23:06.790 align:start position:0%
final project again since we have two
inputs<00:23:05.720><c> we</c><00:23:05.840><c> can</c><00:23:05.960><c> plot</c><00:23:06.170><c> this</c><00:23:06.320><c> data</c><00:23:06.500><c> on</c><00:23:06.770><c> a</c>

00:23:06.790 --> 00:23:06.800 align:start position:0%
inputs we can plot this data on a
 

00:23:06.800 --> 00:23:09.340 align:start position:0%
inputs we can plot this data on a
feature<00:23:07.040><c> map</c><00:23:07.340><c> like</c><00:23:07.880><c> we</c><00:23:08.000><c> did</c><00:23:08.150><c> before</c><00:23:08.350><c> green</c>

00:23:09.340 --> 00:23:09.350 align:start position:0%
feature map like we did before green
 

00:23:09.350 --> 00:23:11.230 align:start position:0%
feature map like we did before green
points<00:23:09.680><c> here</c><00:23:09.860><c> represent</c><00:23:10.310><c> previous</c><00:23:10.760><c> students</c>

00:23:11.230 --> 00:23:11.240 align:start position:0%
points here represent previous students
 

00:23:11.240 --> 00:23:13.690 align:start position:0%
points here represent previous students
from<00:23:11.390><c> previous</c><00:23:12.050><c> years</c><00:23:12.440><c> that</c><00:23:12.650><c> pass</c><00:23:13.310><c> the</c><00:23:13.520><c> class</c>

00:23:13.690 --> 00:23:13.700 align:start position:0%
from previous years that pass the class
 

00:23:13.700 --> 00:23:15.460 align:start position:0%
from previous years that pass the class
red<00:23:14.270><c> points</c><00:23:14.540><c> represent</c><00:23:14.930><c> students</c><00:23:15.320><c> that</c>

00:23:15.460 --> 00:23:15.470 align:start position:0%
red points represent students that
 

00:23:15.470 --> 00:23:17.920 align:start position:0%
red points represent students that
failed<00:23:15.650><c> the</c><00:23:15.830><c> class</c><00:23:16.240><c> now</c><00:23:17.240><c> if</c><00:23:17.390><c> you</c><00:23:17.510><c> want</c><00:23:17.690><c> to</c><00:23:17.750><c> find</c>

00:23:17.920 --> 00:23:17.930 align:start position:0%
failed the class now if you want to find
 

00:23:17.930 --> 00:23:19.090 align:start position:0%
failed the class now if you want to find
out<00:23:18.080><c> if</c><00:23:18.230><c> you're</c><00:23:18.350><c> gonna</c><00:23:18.470><c> pass</c><00:23:18.710><c> or</c><00:23:18.920><c> fail</c><00:23:19.040><c> to</c>

00:23:19.090 --> 00:23:19.100 align:start position:0%
out if you're gonna pass or fail to
 

00:23:19.100 --> 00:23:20.800 align:start position:0%
out if you're gonna pass or fail to
class<00:23:19.400><c> you</c><00:23:19.640><c> can</c><00:23:19.790><c> also</c><00:23:19.940><c> apply</c><00:23:20.090><c> yourself</c><00:23:20.600><c> on</c>

00:23:20.800 --> 00:23:20.810 align:start position:0%
class you can also apply yourself on
 

00:23:20.810 --> 00:23:23.590 align:start position:0%
class you can also apply yourself on
this<00:23:20.960><c> map</c><00:23:21.200><c> you</c><00:23:21.800><c> spent</c><00:23:22.130><c> you</c><00:23:23.090><c> came</c><00:23:23.300><c> to</c><00:23:23.420><c> four</c>

00:23:23.590 --> 00:23:23.600 align:start position:0%
this map you spent you came to four
 

00:23:23.600 --> 00:23:25.330 align:start position:0%
this map you spent you came to four
lectures<00:23:23.810><c> spend</c><00:23:24.350><c> five</c><00:23:24.530><c> hours</c><00:23:24.560><c> on</c><00:23:24.950><c> your</c><00:23:25.040><c> final</c>

00:23:25.330 --> 00:23:25.340 align:start position:0%
lectures spend five hours on your final
 

00:23:25.340 --> 00:23:27.850 align:start position:0%
lectures spend five hours on your final
project<00:23:25.730><c> and</c><00:23:26.050><c> you</c><00:23:27.050><c> want</c><00:23:27.260><c> to</c><00:23:27.320><c> know</c><00:23:27.470><c> if</c><00:23:27.650><c> you're</c>

00:23:27.850 --> 00:23:27.860 align:start position:0%
project and you want to know if you're
 

00:23:27.860 --> 00:23:30.700 align:start position:0%
project and you want to know if you're
going<00:23:28.100><c> to</c><00:23:28.310><c> pass</c><00:23:28.490><c> or</c><00:23:28.790><c> fail</c><00:23:28.970><c> and</c><00:23:29.440><c> you</c><00:23:30.440><c> want</c><00:23:30.620><c> to</c>

00:23:30.700 --> 00:23:30.710 align:start position:0%
going to pass or fail and you want to
 

00:23:30.710 --> 00:23:31.960 align:start position:0%
going to pass or fail and you want to
actually<00:23:30.830><c> build</c><00:23:31.160><c> a</c><00:23:31.250><c> neural</c><00:23:31.490><c> networks</c><00:23:31.790><c> that's</c>

00:23:31.960 --> 00:23:31.970 align:start position:0%
actually build a neural networks that's
 

00:23:31.970 --> 00:23:34.390 align:start position:0%
actually build a neural networks that's
going<00:23:32.210><c> to</c><00:23:32.360><c> learn</c><00:23:32.750><c> this</c><00:23:32.990><c> look</c><00:23:33.680><c> at</c><00:23:33.800><c> the</c><00:23:33.950><c> old</c><00:23:34.100><c> the</c>

00:23:34.390 --> 00:23:34.400 align:start position:0%
going to learn this look at the old the
 

00:23:34.400 --> 00:23:36.460 align:start position:0%
going to learn this look at the old the
the<00:23:35.180><c> previous</c><00:23:35.360><c> people</c><00:23:35.690><c> that</c><00:23:35.930><c> took</c><00:23:36.080><c> the</c><00:23:36.200><c> scores</c>

00:23:36.460 --> 00:23:36.470 align:start position:0%
the previous people that took the scores
 

00:23:36.470 --> 00:23:38.680 align:start position:0%
the previous people that took the scores
and<00:23:36.710><c> determine</c><00:23:37.280><c> if</c><00:23:37.370><c> you</c><00:23:37.400><c> all</c><00:23:37.700><c> pass</c><00:23:38.060><c> or</c><00:23:38.300><c> fail</c><00:23:38.480><c> as</c>

00:23:38.680 --> 00:23:38.690 align:start position:0%
and determine if you all pass or fail as
 

00:23:38.690 --> 00:23:41.860 align:start position:0%
and determine if you all pass or fail as
well<00:23:40.390><c> so</c><00:23:41.390><c> let's</c><00:23:41.570><c> do</c><00:23:41.720><c> it</c>

00:23:41.860 --> 00:23:41.870 align:start position:0%
well so let's do it
 

00:23:41.870 --> 00:23:44.290 align:start position:0%
well so let's do it
we<00:23:42.680><c> have</c><00:23:42.770><c> two</c><00:23:42.920><c> inputs</c><00:23:43.250><c> one</c><00:23:43.580><c> is</c><00:23:43.700><c> four</c><00:23:43.940><c> one</c><00:23:44.150><c> is</c>

00:23:44.290 --> 00:23:44.300 align:start position:0%
we have two inputs one is four one is
 

00:23:44.300 --> 00:23:46.720 align:start position:0%
we have two inputs one is four one is
five<00:23:44.750><c> these</c><00:23:45.350><c> are</c><00:23:45.530><c> fed</c><00:23:45.740><c> into</c><00:23:45.950><c> a</c><00:23:46.070><c> single</c><00:23:46.520><c> layered</c>

00:23:46.720 --> 00:23:46.730 align:start position:0%
five these are fed into a single layered
 

00:23:46.730 --> 00:23:48.370 align:start position:0%
five these are fed into a single layered
neural<00:23:46.940><c> network</c><00:23:47.390><c> with</c><00:23:47.630><c> three</c><00:23:47.930><c> hidden</c><00:23:48.230><c> units</c>

00:23:48.370 --> 00:23:48.380 align:start position:0%
neural network with three hidden units
 

00:23:48.380 --> 00:23:50.620 align:start position:0%
neural network with three hidden units
and<00:23:48.890><c> we</c><00:23:49.670><c> see</c><00:23:49.820><c> that</c><00:23:49.940><c> the</c><00:23:50.090><c> final</c><00:23:50.450><c> output</c>

00:23:50.620 --> 00:23:50.630 align:start position:0%
and we see that the final output
 

00:23:50.630 --> 00:23:52.870 align:start position:0%
and we see that the final output
probability<00:23:51.380><c> that</c><00:23:52.010><c> you</c><00:23:52.310><c> will</c><00:23:52.430><c> pass</c><00:23:52.640><c> this</c>

00:23:52.870 --> 00:23:52.880 align:start position:0%
probability that you will pass this
 

00:23:52.880 --> 00:23:58.960 align:start position:0%
probability that you will pass this
class<00:23:53.060><c> is</c><00:23:53.470><c> 0.1</c><00:23:54.470><c> or</c><00:23:54.710><c> 10%</c><00:23:55.750><c> not</c><00:23:56.750><c> very</c><00:23:56.960><c> good</c><00:23:57.970><c> that's</c>

00:23:58.960 --> 00:23:58.970 align:start position:0%
class is 0.1 or 10% not very good that's
 

00:23:58.970 --> 00:24:00.550 align:start position:0%
class is 0.1 or 10% not very good that's
actually<00:23:59.240><c> really</c><00:23:59.570><c> bad</c><00:23:59.690><c> news</c><00:23:59.990><c> can</c><00:24:00.290><c> anyone</c>

00:24:00.550 --> 00:24:00.560 align:start position:0%
actually really bad news can anyone
 

00:24:00.560 --> 00:24:03.760 align:start position:0%
actually really bad news can anyone
guess<00:24:01.070><c> why</c><00:24:01.460><c> this</c><00:24:02.360><c> person</c><00:24:02.600><c> who</c><00:24:02.870><c> actually</c><00:24:02.990><c> was</c>

00:24:03.760 --> 00:24:03.770 align:start position:0%
guess why this person who actually was
 

00:24:03.770 --> 00:24:05.920 align:start position:0%
guess why this person who actually was
in<00:24:03.980><c> the</c><00:24:04.160><c> part</c><00:24:04.760><c> of</c><00:24:04.850><c> the</c><00:24:04.940><c> feature</c><00:24:05.120><c> space</c><00:24:05.390><c> it</c>

00:24:05.920 --> 00:24:05.930 align:start position:0%
in the part of the feature space it
 

00:24:05.930 --> 00:24:07.120 align:start position:0%
in the part of the feature space it
looked<00:24:06.170><c> like</c><00:24:06.290><c> they</c><00:24:06.440><c> were</c><00:24:06.470><c> actually</c><00:24:06.830><c> in</c><00:24:06.890><c> a</c><00:24:06.950><c> good</c>

00:24:07.120 --> 00:24:07.130 align:start position:0%
looked like they were actually in a good
 

00:24:07.130 --> 00:24:08.380 align:start position:0%
looked like they were actually in a good
part<00:24:07.370><c> of</c><00:24:07.400><c> this</c><00:24:07.490><c> feature</c><00:24:07.700><c> space</c><00:24:08.030><c> looked</c><00:24:08.270><c> like</c>

00:24:08.380 --> 00:24:08.390 align:start position:0%
part of this feature space looked like
 

00:24:08.390 --> 00:24:10.240 align:start position:0%
part of this feature space looked like
they<00:24:08.510><c> were</c><00:24:08.570><c> gonna</c><00:24:08.660><c> pass</c><00:24:08.990><c> the</c><00:24:09.140><c> class</c><00:24:09.290><c> why</c><00:24:10.010><c> did</c>

00:24:10.240 --> 00:24:10.250 align:start position:0%
they were gonna pass the class why did
 

00:24:10.250 --> 00:24:11.920 align:start position:0%
they were gonna pass the class why did
this<00:24:10.700><c> neural</c><00:24:11.000><c> network</c><00:24:11.030><c> give</c><00:24:11.360><c> me</c><00:24:11.480><c> such</c><00:24:11.690><c> a</c><00:24:11.720><c> bad</c>

00:24:11.920 --> 00:24:11.930 align:start position:0%
this neural network give me such a bad
 

00:24:11.930 --> 00:24:16.780 align:start position:0%
this neural network give me such a bad
prediction<00:24:12.440><c> here</c><00:24:14.830><c> yeah</c><00:24:15.830><c> exactly</c><00:24:16.160><c> so</c><00:24:16.640><c> the</c>

00:24:16.780 --> 00:24:16.790 align:start position:0%
prediction here yeah exactly so the
 

00:24:16.790 --> 00:24:19.090 align:start position:0%
prediction here yeah exactly so the
network<00:24:17.090><c> was</c><00:24:17.240><c> not</c><00:24:17.390><c> trained</c><00:24:17.980><c> essentially</c><00:24:18.980><c> this</c>

00:24:19.090 --> 00:24:19.100 align:start position:0%
network was not trained essentially this
 

00:24:19.100 --> 00:24:20.350 align:start position:0%
network was not trained essentially this
network<00:24:19.370><c> is</c><00:24:19.490><c> like</c><00:24:19.580><c> a</c><00:24:19.640><c> baby</c><00:24:19.940><c> that</c><00:24:20.090><c> was</c><00:24:20.330><c> just</c>

00:24:20.350 --> 00:24:20.360 align:start position:0%
network is like a baby that was just
 

00:24:20.360 --> 00:24:22.420 align:start position:0%
network is like a baby that was just
born<00:24:20.570><c> it</c><00:24:20.930><c> has</c><00:24:21.020><c> no</c><00:24:21.200><c> idea</c><00:24:21.530><c> of</c><00:24:21.680><c> what</c><00:24:21.860><c> lectures</c><00:24:22.250><c> are</c>

00:24:22.420 --> 00:24:22.430 align:start position:0%
born it has no idea of what lectures are
 

00:24:22.430 --> 00:24:24.100 align:start position:0%
born it has no idea of what lectures are
it<00:24:22.550><c> doesn't</c><00:24:22.700><c> know</c><00:24:22.850><c> where</c><00:24:22.970><c> final</c><00:24:23.300><c> labs</c><00:24:23.480><c> are</c><00:24:23.720><c> it</c>

00:24:24.100 --> 00:24:24.110 align:start position:0%
it doesn't know where final labs are it
 

00:24:24.110 --> 00:24:25.720 align:start position:0%
it doesn't know where final labs are it
doesn't<00:24:24.530><c> know</c><00:24:24.650><c> anything</c><00:24:24.680><c> about</c><00:24:25.160><c> this</c><00:24:25.520><c> world</c>

00:24:25.720 --> 00:24:25.730 align:start position:0%
doesn't know anything about this world
 

00:24:25.730 --> 00:24:28.180 align:start position:0%
doesn't know anything about this world
it's<00:24:26.450><c> these</c><00:24:26.720><c> are</c><00:24:26.780><c> just</c><00:24:27.020><c> numbers</c><00:24:27.230><c> to</c><00:24:27.620><c> it</c><00:24:27.770><c> it's</c>

00:24:28.180 --> 00:24:28.190 align:start position:0%
it's these are just numbers to it it's
 

00:24:28.190 --> 00:24:29.800 align:start position:0%
it's these are just numbers to it it's
been<00:24:28.370><c> randomly</c><00:24:28.760><c> initialized</c><00:24:29.330><c> it</c><00:24:29.540><c> has</c>

00:24:29.800 --> 00:24:29.810 align:start position:0%
been randomly initialized it has
 

00:24:29.810 --> 00:24:31.570 align:start position:0%
been randomly initialized it has
no<00:24:29.870><c> idea</c><00:24:30.140><c> about</c><00:24:30.290><c> the</c><00:24:30.410><c> problem</c><00:24:30.770><c> so</c><00:24:31.250><c> we</c><00:24:31.370><c> have</c><00:24:31.490><c> to</c>

00:24:31.570 --> 00:24:31.580 align:start position:0%
no idea about the problem so we have to
 

00:24:31.580 --> 00:24:32.860 align:start position:0%
no idea about the problem so we have to
actually<00:24:31.670><c> train</c><00:24:32.060><c> it</c><00:24:32.180><c> we</c><00:24:32.240><c> have</c><00:24:32.330><c> to</c><00:24:32.450><c> teach</c><00:24:32.660><c> it</c>

00:24:32.860 --> 00:24:32.870 align:start position:0%
actually train it we have to teach it
 

00:24:32.870 --> 00:24:36.160 align:start position:0%
actually train it we have to teach it
how<00:24:33.260><c> to</c><00:24:33.290><c> get</c><00:24:34.070><c> the</c><00:24:34.190><c> right</c><00:24:34.340><c> answer</c><00:24:34.870><c> so</c><00:24:35.870><c> the</c><00:24:35.960><c> first</c>

00:24:36.160 --> 00:24:36.170 align:start position:0%
how to get the right answer so the first
 

00:24:36.170 --> 00:24:37.360 align:start position:0%
how to get the right answer so the first
thing<00:24:36.290><c> that</c><00:24:36.320><c> we</c><00:24:36.500><c> have</c><00:24:36.590><c> to</c><00:24:36.620><c> do</c><00:24:36.770><c> is</c><00:24:36.860><c> tell</c><00:24:37.160><c> the</c>

00:24:37.360 --> 00:24:37.370 align:start position:0%
thing that we have to do is tell the
 

00:24:37.370 --> 00:24:39.370 align:start position:0%
thing that we have to do is tell the
network<00:24:37.550><c> when</c><00:24:38.030><c> it</c><00:24:38.180><c> makes</c><00:24:38.330><c> a</c><00:24:38.480><c> mistake</c><00:24:38.600><c> so</c><00:24:39.260><c> that</c>

00:24:39.370 --> 00:24:39.380 align:start position:0%
network when it makes a mistake so that
 

00:24:39.380 --> 00:24:41.380 align:start position:0%
network when it makes a mistake so that
we<00:24:39.500><c> can</c><00:24:39.650><c> correct</c><00:24:39.860><c> it</c><00:24:40.070><c> in</c><00:24:40.190><c> the</c><00:24:40.250><c> future</c><00:24:40.460><c> now</c><00:24:41.120><c> how</c>

00:24:41.380 --> 00:24:41.390 align:start position:0%
we can correct it in the future now how
 

00:24:41.390 --> 00:24:43.780 align:start position:0%
we can correct it in the future now how
do<00:24:41.450><c> we</c><00:24:41.540><c> do</c><00:24:41.690><c> this</c><00:24:41.810><c> in</c><00:24:41.990><c> neural</c><00:24:42.200><c> networks</c><00:24:42.790><c> the</c>

00:24:43.780 --> 00:24:43.790 align:start position:0%
do we do this in neural networks the
 

00:24:43.790 --> 00:24:45.430 align:start position:0%
do we do this in neural networks the
loss<00:24:44.000><c> of</c><00:24:44.210><c> a</c><00:24:44.300><c> network</c><00:24:44.630><c> is</c><00:24:44.810><c> actually</c><00:24:45.050><c> what</c>

00:24:45.430 --> 00:24:45.440 align:start position:0%
loss of a network is actually what
 

00:24:45.440 --> 00:24:47.860 align:start position:0%
loss of a network is actually what
defines<00:24:45.890><c> when</c><00:24:46.700><c> the</c><00:24:46.910><c> network</c><00:24:47.180><c> makes</c><00:24:47.420><c> the</c><00:24:47.750><c> wrong</c>

00:24:47.860 --> 00:24:47.870 align:start position:0%
defines when the network makes the wrong
 

00:24:47.870 --> 00:24:50.350 align:start position:0%
defines when the network makes the wrong
prediction<00:24:48.440><c> it</c><00:24:48.830><c> takes</c><00:24:49.220><c> the</c><00:24:49.430><c> input</c><00:24:49.610><c> and</c><00:24:50.060><c> the</c>

00:24:50.350 --> 00:24:50.360 align:start position:0%
prediction it takes the input and the
 

00:24:50.360 --> 00:24:53.200 align:start position:0%
prediction it takes the input and the
predicted<00:24:50.900><c> output</c><00:24:51.220><c> sorry</c><00:24:52.220><c> it</c><00:24:52.340><c> takes</c><00:24:52.490><c> as</c><00:24:52.790><c> input</c>

00:24:53.200 --> 00:24:53.210 align:start position:0%
predicted output sorry it takes as input
 

00:24:53.210 --> 00:24:55.810 align:start position:0%
predicted output sorry it takes as input
the<00:24:53.390><c> predicted</c><00:24:53.990><c> output</c><00:24:54.140><c> and</c><00:24:54.550><c> the</c><00:24:55.550><c> ground</c>

00:24:55.810 --> 00:24:55.820 align:start position:0%
the predicted output and the ground
 

00:24:55.820 --> 00:24:58.060 align:start position:0%
the predicted output and the ground
truth<00:24:56.090><c> actual</c><00:24:56.570><c> output</c><00:24:56.750><c> if</c><00:24:57.230><c> your</c><00:24:57.620><c> predicted</c>

00:24:58.060 --> 00:24:58.070 align:start position:0%
truth actual output if your predicted
 

00:24:58.070 --> 00:24:59.590 align:start position:0%
truth actual output if your predicted
output<00:24:58.220><c> and</c><00:24:58.550><c> your</c><00:24:58.610><c> ground</c><00:24:58.910><c> truth</c><00:24:59.120><c> output</c><00:24:59.480><c> are</c>

00:24:59.590 --> 00:24:59.600 align:start position:0%
output and your ground truth output are
 

00:24:59.600 --> 00:25:01.240 align:start position:0%
output and your ground truth output are
very<00:24:59.810><c> close</c><00:25:00.050><c> to</c><00:25:00.230><c> each</c><00:25:00.260><c> other</c><00:25:00.470><c> then</c><00:25:01.130><c> that</c>

00:25:01.240 --> 00:25:01.250 align:start position:0%
very close to each other then that
 

00:25:01.250 --> 00:25:03.070 align:start position:0%
very close to each other then that
essentially<00:25:01.670><c> means</c><00:25:02.000><c> that</c><00:25:02.150><c> your</c><00:25:02.660><c> loss</c><00:25:02.870><c> is</c>

00:25:03.070 --> 00:25:03.080 align:start position:0%
essentially means that your loss is
 

00:25:03.080 --> 00:25:04.390 align:start position:0%
essentially means that your loss is
going<00:25:03.200><c> to</c><00:25:03.290><c> be</c><00:25:03.350><c> very</c><00:25:03.590><c> low</c><00:25:03.800><c> you</c><00:25:04.070><c> didn't</c><00:25:04.250><c> make</c><00:25:04.370><c> a</c>

00:25:04.390 --> 00:25:04.400 align:start position:0%
going to be very low you didn't make a
 

00:25:04.400 --> 00:25:06.940 align:start position:0%
going to be very low you didn't make a
mistake<00:25:04.810><c> but</c><00:25:05.810><c> if</c><00:25:05.990><c> your</c><00:25:06.170><c> ground</c><00:25:06.440><c> truth</c><00:25:06.650><c> output</c>

00:25:06.940 --> 00:25:06.950 align:start position:0%
mistake but if your ground truth output
 

00:25:06.950 --> 00:25:08.350 align:start position:0%
mistake but if your ground truth output
is<00:25:07.040><c> very</c><00:25:07.160><c> far</c><00:25:07.430><c> away</c><00:25:07.610><c> from</c><00:25:07.670><c> your</c><00:25:07.910><c> predicted</c>

00:25:08.350 --> 00:25:08.360 align:start position:0%
is very far away from your predicted
 

00:25:08.360 --> 00:25:10.000 align:start position:0%
is very far away from your predicted
output<00:25:08.510><c> that</c><00:25:09.230><c> means</c><00:25:09.470><c> that</c><00:25:09.620><c> you</c><00:25:09.710><c> should</c><00:25:09.860><c> have</c><00:25:09.980><c> a</c>

00:25:10.000 --> 00:25:10.010 align:start position:0%
output that means that you should have a
 

00:25:10.010 --> 00:25:12.010 align:start position:0%
output that means that you should have a
very<00:25:10.280><c> high</c><00:25:10.490><c> loss</c><00:25:10.730><c> you</c><00:25:11.420><c> just</c><00:25:11.570><c> have</c><00:25:11.720><c> a</c><00:25:11.750><c> lot</c><00:25:11.870><c> of</c>

00:25:12.010 --> 00:25:12.020 align:start position:0%
very high loss you just have a lot of
 

00:25:12.020 --> 00:25:13.960 align:start position:0%
very high loss you just have a lot of
error<00:25:12.290><c> and</c><00:25:12.530><c> your</c><00:25:13.130><c> network</c><00:25:13.430><c> should</c><00:25:13.610><c> correct</c>

00:25:13.960 --> 00:25:13.970 align:start position:0%
error and your network should correct
 

00:25:13.970 --> 00:25:18.520 align:start position:0%
error and your network should correct
that<00:25:16.090><c> so</c><00:25:17.090><c> let's</c><00:25:17.660><c> assume</c><00:25:17.900><c> that</c><00:25:17.960><c> we</c><00:25:18.140><c> have</c><00:25:18.320><c> data</c>

00:25:18.520 --> 00:25:18.530 align:start position:0%
that so let's assume that we have data
 

00:25:18.530 --> 00:25:21.130 align:start position:0%
that so let's assume that we have data
not<00:25:18.800><c> just</c><00:25:18.860><c> from</c><00:25:19.160><c> one</c><00:25:19.220><c> student</c><00:25:19.850><c> now</c><00:25:20.000><c> but</c><00:25:20.960><c> we</c>

00:25:21.130 --> 00:25:21.140 align:start position:0%
not just from one student now but we
 

00:25:21.140 --> 00:25:22.540 align:start position:0%
not just from one student now but we
have<00:25:21.170><c> data</c><00:25:21.710><c> from</c><00:25:21.980><c> many</c><00:25:22.160><c> many</c><00:25:22.430><c> different</c>

00:25:22.540 --> 00:25:22.550 align:start position:0%
have data from many many different
 

00:25:22.550 --> 00:25:25.770 align:start position:0%
have data from many many different
students<00:25:23.300><c> passing</c><00:25:23.780><c> and</c><00:25:24.110><c> failing</c><00:25:24.140><c> the</c><00:25:24.470><c> class</c>

00:25:25.770 --> 00:25:25.780 align:start position:0%
students passing and failing the class
 

00:25:25.780 --> 00:25:28.360 align:start position:0%
students passing and failing the class
we<00:25:26.780><c> now</c><00:25:26.990><c> care</c><00:25:27.290><c> about</c><00:25:27.470><c> how</c><00:25:27.680><c> this</c><00:25:27.860><c> model</c><00:25:28.190><c> does</c>

00:25:28.360 --> 00:25:28.370 align:start position:0%
we now care about how this model does
 

00:25:28.370 --> 00:25:30.370 align:start position:0%
we now care about how this model does
not<00:25:28.400><c> just</c><00:25:28.910><c> on</c><00:25:29.030><c> that</c><00:25:29.180><c> one</c><00:25:29.360><c> student</c><00:25:29.780><c> but</c><00:25:29.960><c> across</c>

00:25:30.370 --> 00:25:30.380 align:start position:0%
not just on that one student but across
 

00:25:30.380 --> 00:25:33.790 align:start position:0%
not just on that one student but across
the<00:25:31.280><c> entire</c><00:25:31.370><c> population</c><00:25:32.120><c> of</c><00:25:32.630><c> students</c><00:25:33.020><c> and</c><00:25:33.260><c> we</c>

00:25:33.790 --> 00:25:33.800 align:start position:0%
the entire population of students and we
 

00:25:33.800 --> 00:25:35.800 align:start position:0%
the entire population of students and we
call<00:25:34.010><c> this</c><00:25:34.160><c> the</c><00:25:34.400><c> empirical</c><00:25:35.120><c> loss</c><00:25:35.360><c> and</c><00:25:35.660><c> that's</c>

00:25:35.800 --> 00:25:35.810 align:start position:0%
call this the empirical loss and that's
 

00:25:35.810 --> 00:25:37.540 align:start position:0%
call this the empirical loss and that's
just<00:25:35.990><c> the</c><00:25:36.140><c> mean</c><00:25:36.410><c> of</c><00:25:36.620><c> all</c><00:25:36.710><c> of</c><00:25:36.860><c> the</c><00:25:37.010><c> losses</c><00:25:37.220><c> for</c>

00:25:37.540 --> 00:25:37.550 align:start position:0%
just the mean of all of the losses for
 

00:25:37.550 --> 00:25:39.820 align:start position:0%
just the mean of all of the losses for
the<00:25:37.610><c> individual</c><00:25:38.120><c> students</c><00:25:38.510><c> we</c><00:25:39.380><c> can</c><00:25:39.530><c> do</c><00:25:39.620><c> it</c><00:25:39.710><c> by</c>

00:25:39.820 --> 00:25:39.830 align:start position:0%
the individual students we can do it by
 

00:25:39.830 --> 00:25:42.340 align:start position:0%
the individual students we can do it by
literally<00:25:40.340><c> just</c><00:25:40.640><c> computing</c><00:25:41.120><c> the</c><00:25:41.240><c> mean</c><00:25:41.480><c> sorry</c>

00:25:42.340 --> 00:25:42.350 align:start position:0%
literally just computing the mean sorry
 

00:25:42.350 --> 00:25:43.630 align:start position:0%
literally just computing the mean sorry
just<00:25:42.620><c> computing</c><00:25:43.010><c> the</c><00:25:43.100><c> loss</c><00:25:43.250><c> for</c><00:25:43.460><c> each</c><00:25:43.520><c> of</c>

00:25:43.630 --> 00:25:43.640 align:start position:0%
just computing the loss for each of
 

00:25:43.640 --> 00:25:45.390 align:start position:0%
just computing the loss for each of
these<00:25:43.730><c> students</c><00:25:44.030><c> and</c><00:25:44.180><c> taking</c><00:25:44.630><c> their</c><00:25:44.780><c> mean</c>

00:25:45.390 --> 00:25:45.400 align:start position:0%
these students and taking their mean
 

00:25:45.400 --> 00:25:48.010 align:start position:0%
these students and taking their mean
when<00:25:46.400><c> training</c><00:25:46.670><c> a</c><00:25:46.790><c> network</c><00:25:47.150><c> what</c><00:25:47.540><c> we</c><00:25:47.660><c> really</c>

00:25:48.010 --> 00:25:48.020 align:start position:0%
when training a network what we really
 

00:25:48.020 --> 00:25:50.290 align:start position:0%
when training a network what we really
want<00:25:48.170><c> to</c><00:25:48.260><c> do</c><00:25:48.530><c> is</c><00:25:48.800><c> not</c><00:25:49.340><c> minimize</c><00:25:49.760><c> the</c><00:25:49.940><c> loss</c><00:25:50.090><c> for</c>

00:25:50.290 --> 00:25:50.300 align:start position:0%
want to do is not minimize the loss for
 

00:25:50.300 --> 00:25:51.970 align:start position:0%
want to do is not minimize the loss for
any<00:25:50.420><c> particular</c><00:25:50.660><c> student</c><00:25:51.350><c> but</c><00:25:51.530><c> we</c><00:25:51.650><c> want</c><00:25:51.860><c> to</c>

00:25:51.970 --> 00:25:51.980 align:start position:0%
any particular student but we want to
 

00:25:51.980 --> 00:25:53.950 align:start position:0%
any particular student but we want to
minimize<00:25:52.340><c> the</c><00:25:52.550><c> loss</c><00:25:52.730><c> across</c><00:25:53.390><c> the</c><00:25:53.630><c> entire</c>

00:25:53.950 --> 00:25:53.960 align:start position:0%
minimize the loss across the entire
 

00:25:53.960 --> 00:25:58.840 align:start position:0%
minimize the loss across the entire
training<00:25:54.320><c> set</c><00:25:56.860><c> so</c><00:25:57.860><c> if</c><00:25:58.130><c> we</c><00:25:58.250><c> go</c><00:25:58.370><c> back</c><00:25:58.400><c> to</c><00:25:58.760><c> our</c>

00:25:58.840 --> 00:25:58.850 align:start position:0%
training set so if we go back to our
 

00:25:58.850 --> 00:26:01.600 align:start position:0%
training set so if we go back to our
problem<00:25:59.060><c> on</c><00:25:59.650><c> path</c><00:26:00.680><c> predicting</c><00:26:01.430><c> if</c><00:26:01.520><c> you'll</c>

00:26:01.600 --> 00:26:01.610 align:start position:0%
problem on path predicting if you'll
 

00:26:01.610 --> 00:26:03.610 align:start position:0%
problem on path predicting if you'll
pass<00:26:01.820><c> or</c><00:26:02.000><c> fail</c><00:26:02.120><c> to</c><00:26:02.180><c> class</c><00:26:02.510><c> this</c><00:26:03.050><c> is</c><00:26:03.230><c> a</c><00:26:03.260><c> problem</c>

00:26:03.610 --> 00:26:03.620 align:start position:0%
pass or fail to class this is a problem
 

00:26:03.620 --> 00:26:05.620 align:start position:0%
pass or fail to class this is a problem
of<00:26:03.680><c> binary</c><00:26:04.130><c> classification</c><00:26:04.550><c> your</c><00:26:05.090><c> output</c><00:26:05.480><c> is</c>

00:26:05.620 --> 00:26:05.630 align:start position:0%
of binary classification your output is
 

00:26:05.630 --> 00:26:08.230 align:start position:0%
of binary classification your output is
0<00:26:05.930><c> or</c><00:26:06.110><c> 1</c><00:26:06.290><c> we</c><00:26:07.010><c> already</c><00:26:07.280><c> learned</c><00:26:07.520><c> that</c><00:26:07.850><c> when</c>

00:26:08.230 --> 00:26:08.240 align:start position:0%
0 or 1 we already learned that when
 

00:26:08.240 --> 00:26:09.850 align:start position:0%
0 or 1 we already learned that when
outputs<00:26:08.600><c> are</c><00:26:08.720><c> 0</c><00:26:08.750><c> or</c><00:26:08.990><c> 1</c><00:26:09.200><c> you're</c><00:26:09.410><c> probably</c><00:26:09.620><c> going</c>

00:26:09.850 --> 00:26:09.860 align:start position:0%
outputs are 0 or 1 you're probably going
 

00:26:09.860 --> 00:26:13.360 align:start position:0%
outputs are 0 or 1 you're probably going
to<00:26:09.920><c> want</c><00:26:10.070><c> to</c><00:26:10.160><c> use</c><00:26:10.310><c> a</c><00:26:10.490><c> soft</c><00:26:11.000><c> max</c><00:26:11.360><c> output</c><00:26:12.370><c> for</c>

00:26:13.360 --> 00:26:13.370 align:start position:0%
to want to use a soft max output for
 

00:26:13.370 --> 00:26:15.190 align:start position:0%
to want to use a soft max output for
those<00:26:13.520><c> of</c><00:26:13.610><c> you</c><00:26:13.700><c> who</c><00:26:13.820><c> aren't</c><00:26:14.000><c> familiar</c><00:26:14.200><c> with</c>

00:26:15.190 --> 00:26:15.200 align:start position:0%
those of you who aren't familiar with
 

00:26:15.200 --> 00:26:17.050 align:start position:0%
those of you who aren't familiar with
cross<00:26:15.620><c> entropy</c><00:26:15.860><c> this</c><00:26:16.310><c> was</c><00:26:16.520><c> an</c><00:26:16.730><c> idea</c>

00:26:17.050 --> 00:26:17.060 align:start position:0%
cross entropy this was an idea
 

00:26:17.060 --> 00:26:19.060 align:start position:0%
cross entropy this was an idea
introduced<00:26:17.600><c> actually</c><00:26:18.110><c> at</c><00:26:18.230><c> MIT</c><00:26:18.620><c> and</c><00:26:19.010><c> a</c>

00:26:19.060 --> 00:26:19.070 align:start position:0%
introduced actually at MIT and a
 

00:26:19.070 --> 00:26:21.010 align:start position:0%
introduced actually at MIT and a
master's<00:26:19.460><c> thesis</c><00:26:19.490><c> here</c><00:26:20.060><c> over</c><00:26:20.330><c> 50</c><00:26:20.690><c> years</c><00:26:20.840><c> ago</c>

00:26:21.010 --> 00:26:21.020 align:start position:0%
master's thesis here over 50 years ago
 

00:26:21.020 --> 00:26:22.900 align:start position:0%
master's thesis here over 50 years ago
it's<00:26:21.230><c> widely</c><00:26:21.560><c> used</c><00:26:21.770><c> in</c><00:26:21.950><c> different</c><00:26:22.610><c> areas</c><00:26:22.880><c> like</c>

00:26:22.900 --> 00:26:22.910 align:start position:0%
it's widely used in different areas like
 

00:26:22.910 --> 00:26:24.580 align:start position:0%
it's widely used in different areas like
thermodynamics<00:26:23.570><c> and</c><00:26:24.050><c> we</c><00:26:24.110><c> use</c><00:26:24.260><c> it</c><00:26:24.440><c> here</c><00:26:24.470><c> in</c>

00:26:24.580 --> 00:26:24.590 align:start position:0%
thermodynamics and we use it here in
 

00:26:24.590 --> 00:26:26.110 align:start position:0%
thermodynamics and we use it here in
machine<00:26:24.890><c> learning</c><00:26:25.040><c> as</c><00:26:25.250><c> well</c><00:26:25.430><c> it's</c><00:26:25.790><c> used</c><00:26:25.970><c> all</c>

00:26:26.110 --> 00:26:26.120 align:start position:0%
machine learning as well it's used all
 

00:26:26.120 --> 00:26:29.680 align:start position:0%
machine learning as well it's used all
over<00:26:26.150><c> information</c><00:26:26.630><c> theory</c><00:26:27.200><c> and</c><00:26:28.360><c> what</c><00:26:29.360><c> this</c><00:26:29.540><c> is</c>

00:26:29.680 --> 00:26:29.690 align:start position:0%
over information theory and what this is
 

00:26:29.690 --> 00:26:31.330 align:start position:0%
over information theory and what this is
doing<00:26:29.870><c> here</c><00:26:29.990><c> is</c><00:26:30.230><c> essentially</c><00:26:30.590><c> computing</c><00:26:31.220><c> the</c>

00:26:31.330 --> 00:26:31.340 align:start position:0%
doing here is essentially computing the
 

00:26:31.340 --> 00:26:34.890 align:start position:0%
doing here is essentially computing the
loss<00:26:31.520><c> between</c><00:26:32.480><c> this</c><00:26:32.930><c> zero</c><00:26:33.230><c> one</c><00:26:33.470><c> output</c><00:26:33.680><c> and</c>

00:26:34.890 --> 00:26:34.900 align:start position:0%
loss between this zero one output and
 

00:26:34.900 --> 00:26:37.720 align:start position:0%
loss between this zero one output and
the<00:26:35.900><c> true</c><00:26:36.170><c> output</c><00:26:36.620><c> that</c><00:26:37.100><c> the</c><00:26:37.280><c> student</c><00:26:37.610><c> either</c>

00:26:37.720 --> 00:26:37.730 align:start position:0%
the true output that the student either
 

00:26:37.730 --> 00:26:40.360 align:start position:0%
the true output that the student either
passed<00:26:38.060><c> or</c><00:26:38.300><c> failed</c><00:26:38.360><c> to</c><00:26:38.720><c> class</c><00:26:39.160><c> let's</c><00:26:40.160><c> suppose</c>

00:26:40.360 --> 00:26:40.370 align:start position:0%
passed or failed to class let's suppose
 

00:26:40.370 --> 00:26:42.910 align:start position:0%
passed or failed to class let's suppose
instead<00:26:40.580><c> of</c><00:26:40.790><c> computing</c><00:26:41.390><c> a</c><00:26:41.630><c> zero</c><00:26:42.290><c> one</c><00:26:42.500><c> output</c>

00:26:42.910 --> 00:26:42.920 align:start position:0%
instead of computing a zero one output
 

00:26:42.920 --> 00:26:43.480 align:start position:0%
instead of computing a zero one output
now<00:26:43.070><c> we</c><00:26:43.130><c> want</c><00:26:43.340><c> to</c>

00:26:43.480 --> 00:26:43.490 align:start position:0%
now we want to
 

00:26:43.490 --> 00:26:45.010 align:start position:0%
now we want to
compute<00:26:43.760><c> the</c><00:26:43.850><c> actual</c><00:26:44.210><c> grade</c><00:26:44.510><c> that</c><00:26:44.780><c> you</c><00:26:44.900><c> will</c>

00:26:45.010 --> 00:26:45.020 align:start position:0%
compute the actual grade that you will
 

00:26:45.020 --> 00:26:47.380 align:start position:0%
compute the actual grade that you will
get<00:26:45.200><c> on</c><00:26:45.380><c> the</c><00:26:45.500><c> class</c><00:26:45.710><c> so</c><00:26:46.309><c> now</c><00:26:46.429><c> it's</c><00:26:46.550><c> not</c><00:26:46.670><c> 0-1</c><00:26:47.179><c> but</c>

00:26:47.380 --> 00:26:47.390 align:start position:0%
get on the class so now it's not 0-1 but
 

00:26:47.390 --> 00:26:49.419 align:start position:0%
get on the class so now it's not 0-1 but
it's<00:26:47.540><c> actually</c><00:26:47.840><c> a</c><00:26:47.870><c> grade</c><00:26:48.170><c> it</c><00:26:49.010><c> could</c><00:26:49.190><c> be</c><00:26:49.280><c> any</c>

00:26:49.419 --> 00:26:49.429 align:start position:0%
it's actually a grade it could be any
 

00:26:49.429 --> 00:26:52.480 align:start position:0%
it's actually a grade it could be any
number<00:26:49.520><c> actually</c><00:26:49.940><c> right</c><00:26:50.980><c> now</c><00:26:51.980><c> we</c><00:26:52.040><c> want</c><00:26:52.309><c> to</c><00:26:52.400><c> use</c>

00:26:52.480 --> 00:26:52.490 align:start position:0%
number actually right now we want to use
 

00:26:52.490 --> 00:26:54.190 align:start position:0%
number actually right now we want to use
a<00:26:52.520><c> different</c><00:26:52.760><c> loss</c><00:26:53.179><c> because</c><00:26:53.720><c> the</c><00:26:53.840><c> output</c><00:26:53.990><c> of</c>

00:26:54.190 --> 00:26:54.200 align:start position:0%
a different loss because the output of
 

00:26:54.200 --> 00:26:56.020 align:start position:0%
a different loss because the output of
our<00:26:54.380><c> net</c><00:26:54.620><c> of</c><00:26:55.010><c> our</c><00:26:55.220><c> neural</c><00:26:55.400><c> network</c><00:26:55.520><c> is</c>

00:26:56.020 --> 00:26:56.030 align:start position:0%
our net of our neural network is
 

00:26:56.030 --> 00:26:58.570 align:start position:0%
our net of our neural network is
different<00:26:56.540><c> and</c><00:26:56.950><c> defining</c><00:26:57.950><c> losses</c><00:26:58.460><c> is</c>

00:26:58.570 --> 00:26:58.580 align:start position:0%
different and defining losses is
 

00:26:58.580 --> 00:27:00.610 align:start position:0%
different and defining losses is
actually<00:26:58.940><c> kind</c><00:26:59.270><c> of</c><00:26:59.390><c> one</c><00:26:59.690><c> of</c><00:26:59.809><c> the</c><00:26:59.960><c> arts</c><00:27:00.230><c> in</c><00:27:00.410><c> deep</c>

00:27:00.610 --> 00:27:00.620 align:start position:0%
actually kind of one of the arts in deep
 

00:27:00.620 --> 00:27:01.750 align:start position:0%
actually kind of one of the arts in deep
learning<00:27:00.830><c> so</c><00:27:01.130><c> you</c><00:27:01.190><c> have</c><00:27:01.309><c> to</c><00:27:01.400><c> define</c><00:27:01.550><c> the</c>

00:27:01.750 --> 00:27:01.760 align:start position:0%
learning so you have to define the
 

00:27:01.760 --> 00:27:03.790 align:start position:0%
learning so you have to define the
questions<00:27:02.090><c> that</c><00:27:02.540><c> you're</c><00:27:02.690><c> asking</c><00:27:02.720><c> so</c><00:27:03.470><c> you</c><00:27:03.590><c> can</c>

00:27:03.790 --> 00:27:03.800 align:start position:0%
questions that you're asking so you can
 

00:27:03.800 --> 00:27:05.770 align:start position:0%
questions that you're asking so you can
define<00:27:04.160><c> the</c><00:27:04.490><c> loss</c><00:27:04.700><c> that</c><00:27:05.270><c> you</c><00:27:05.450><c> need</c><00:27:05.660><c> to</c>

00:27:05.770 --> 00:27:05.780 align:start position:0%
define the loss that you need to
 

00:27:05.780 --> 00:27:08.799 align:start position:0%
define the loss that you need to
optimize<00:27:05.960><c> over</c><00:27:07.000><c> so</c><00:27:08.000><c> here</c><00:27:08.270><c> in</c><00:27:08.390><c> this</c><00:27:08.480><c> example</c>

00:27:08.799 --> 00:27:08.809 align:start position:0%
optimize over so here in this example
 

00:27:08.809 --> 00:27:10.690 align:start position:0%
optimize over so here in this example
since<00:27:09.140><c> we're</c><00:27:09.320><c> not</c><00:27:09.410><c> optimizing</c><00:27:10.070><c> over</c><00:27:10.220><c> zero</c><00:27:10.490><c> one</c>

00:27:10.690 --> 00:27:10.700 align:start position:0%
since we're not optimizing over zero one
 

00:27:10.700 --> 00:27:12.760 align:start position:0%
since we're not optimizing over zero one
loss<00:27:10.730><c> we're</c><00:27:11.600><c> optimizing</c><00:27:11.960><c> over</c><00:27:12.350><c> any</c><00:27:12.500><c> real</c>

00:27:12.760 --> 00:27:12.770 align:start position:0%
loss we're optimizing over any real
 

00:27:12.770 --> 00:27:14.830 align:start position:0%
loss we're optimizing over any real
number<00:27:13.130><c> we're</c><00:27:13.700><c> gonna</c><00:27:13.790><c> use</c><00:27:14.030><c> a</c><00:27:14.210><c> mean</c><00:27:14.480><c> squared</c>

00:27:14.830 --> 00:27:14.840 align:start position:0%
number we're gonna use a mean squared
 

00:27:14.840 --> 00:27:17.160 align:start position:0%
number we're gonna use a mean squared
error<00:27:15.080><c> loss</c><00:27:15.230><c> and</c><00:27:15.740><c> that's</c><00:27:16.010><c> just</c><00:27:16.309><c> computing</c><00:27:16.940><c> the</c>

00:27:17.160 --> 00:27:17.170 align:start position:0%
error loss and that's just computing the
 

00:27:17.170 --> 00:27:19.419 align:start position:0%
error loss and that's just computing the
squared<00:27:18.170><c> error</c><00:27:18.410><c> so</c><00:27:18.740><c> you</c><00:27:19.010><c> take</c><00:27:19.190><c> the</c><00:27:19.309><c> difference</c>

00:27:19.419 --> 00:27:19.429 align:start position:0%
squared error so you take the difference
 

00:27:19.429 --> 00:27:21.130 align:start position:0%
squared error so you take the difference
between<00:27:19.790><c> what</c><00:27:20.120><c> you</c><00:27:20.210><c> expect</c><00:27:20.630><c> the</c><00:27:20.750><c> output</c><00:27:20.780><c> to</c><00:27:21.110><c> be</c>

00:27:21.130 --> 00:27:21.140 align:start position:0%
between what you expect the output to be
 

00:27:21.140 --> 00:27:23.919 align:start position:0%
between what you expect the output to be
and<00:27:21.470><c> what</c><00:27:21.920><c> you're</c><00:27:22.040><c> actually</c><00:27:22.429><c> output</c><00:27:23.030><c> was</c><00:27:23.240><c> you</c>

00:27:23.919 --> 00:27:23.929 align:start position:0%
and what you're actually output was you
 

00:27:23.929 --> 00:27:25.780 align:start position:0%
and what you're actually output was you
take<00:27:24.410><c> that</c><00:27:24.590><c> difference</c><00:27:24.770><c> you</c><00:27:25.160><c> square</c><00:27:25.490><c> it</c><00:27:25.640><c> and</c>

00:27:25.780 --> 00:27:25.790 align:start position:0%
take that difference you square it and
 

00:27:25.790 --> 00:27:27.010 align:start position:0%
take that difference you square it and
you<00:27:25.880><c> compute</c><00:27:26.179><c> the</c><00:27:26.270><c> mean</c><00:27:26.450><c> over</c><00:27:26.600><c> your</c><00:27:26.809><c> entire</c>

00:27:27.010 --> 00:27:27.020 align:start position:0%
you compute the mean over your entire
 

00:27:27.020 --> 00:27:30.730 align:start position:0%
you compute the mean over your entire
population<00:27:29.170><c> okay</c><00:27:30.170><c> great</c>

00:27:30.730 --> 00:27:30.740 align:start position:0%
population okay great
 

00:27:30.740 --> 00:27:32.620 align:start position:0%
population okay great
so<00:27:31.160><c> now</c><00:27:31.610><c> let's</c><00:27:31.850><c> put</c><00:27:31.940><c> some</c><00:27:32.120><c> of</c><00:27:32.510><c> this</c>

00:27:32.620 --> 00:27:32.630 align:start position:0%
so now let's put some of this
 

00:27:32.630 --> 00:27:33.970 align:start position:0%
so now let's put some of this
information<00:27:32.929><c> together</c><00:27:33.230><c> we've</c><00:27:33.620><c> learned</c><00:27:33.860><c> how</c>

00:27:33.970 --> 00:27:33.980 align:start position:0%
information together we've learned how
 

00:27:33.980 --> 00:27:35.860 align:start position:0%
information together we've learned how
to<00:27:34.010><c> build</c><00:27:34.250><c> neural</c><00:27:34.460><c> networks</c><00:27:34.910><c> we've</c><00:27:35.630><c> learned</c>

00:27:35.860 --> 00:27:35.870 align:start position:0%
to build neural networks we've learned
 

00:27:35.870 --> 00:27:38.230 align:start position:0%
to build neural networks we've learned
how<00:27:36.050><c> to</c><00:27:36.080><c> quantify</c><00:27:36.500><c> their</c><00:27:36.800><c> loss</c><00:27:36.980><c> now</c><00:27:37.910><c> we</c><00:27:37.970><c> can</c>

00:27:38.230 --> 00:27:38.240 align:start position:0%
how to quantify their loss now we can
 

00:27:38.240 --> 00:27:40.650 align:start position:0%
how to quantify their loss now we can
learn<00:27:38.360><c> how</c><00:27:38.570><c> to</c><00:27:38.600><c> actually</c><00:27:39.170><c> use</c><00:27:39.800><c> that</c><00:27:39.830><c> loss</c><00:27:40.309><c> to</c>

00:27:40.650 --> 00:27:40.660 align:start position:0%
learn how to actually use that loss to
 

00:27:40.660 --> 00:27:43.060 align:start position:0%
learn how to actually use that loss to
iteratively<00:27:41.660><c> update</c><00:27:42.290><c> and</c><00:27:42.470><c> train</c><00:27:42.770><c> the</c><00:27:42.950><c> neural</c>

00:27:43.060 --> 00:27:43.070 align:start position:0%
iteratively update and train the neural
 

00:27:43.070 --> 00:27:46.950 align:start position:0%
iteratively update and train the neural
network<00:27:43.490><c> over</c><00:27:43.850><c> time</c><00:27:43.880><c> given</c><00:27:44.420><c> some</c><00:27:44.690><c> data</c><00:27:45.250><c> and</c>

00:27:46.950 --> 00:27:46.960 align:start position:0%
network over time given some data and
 

00:27:46.960 --> 00:27:49.060 align:start position:0%
network over time given some data and
essentially<00:27:47.960><c> what</c><00:27:48.110><c> this</c><00:27:48.230><c> amounts</c><00:27:48.620><c> to</c><00:27:48.830><c> what</c>

00:27:49.060 --> 00:27:49.070 align:start position:0%
essentially what this amounts to what
 

00:27:49.070 --> 00:27:51.400 align:start position:0%
essentially what this amounts to what
this<00:27:49.220><c> boils</c><00:27:49.610><c> down</c><00:27:49.670><c> to</c><00:27:49.850><c> is</c><00:27:50.450><c> that</c><00:27:50.780><c> we</c><00:27:51.080><c> want</c><00:27:51.290><c> to</c>

00:27:51.400 --> 00:27:51.410 align:start position:0%
this boils down to is that we want to
 

00:27:51.410 --> 00:27:54.430 align:start position:0%
this boils down to is that we want to
find<00:27:51.679><c> the</c><00:27:52.250><c> weights</c><00:27:52.520><c> of</c><00:27:52.820><c> the</c><00:27:52.850><c> neural</c><00:27:53.120><c> network</c><00:27:53.440><c> W</c>

00:27:54.430 --> 00:27:54.440 align:start position:0%
find the weights of the neural network W
 

00:27:54.440 --> 00:27:58.750 align:start position:0%
find the weights of the neural network W
that<00:27:55.220><c> minimize</c><00:27:56.120><c> this</c><00:27:57.010><c> empirical</c><00:27:58.010><c> loss</c><00:27:58.250><c> so</c>

00:27:58.750 --> 00:27:58.760 align:start position:0%
that minimize this empirical loss so
 

00:27:58.760 --> 00:28:01.540 align:start position:0%
that minimize this empirical loss so
remember<00:27:59.090><c> again</c><00:27:59.179><c> the</c><00:27:59.420><c> empirical</c><00:27:59.870><c> loss</c><00:28:00.080><c> is</c><00:28:00.550><c> the</c>

00:28:01.540 --> 00:28:01.550 align:start position:0%
remember again the empirical loss is the
 

00:28:01.550 --> 00:28:03.040 align:start position:0%
remember again the empirical loss is the
loss<00:28:01.580><c> over</c><00:28:02.090><c> the</c><00:28:02.120><c> entire</c><00:28:02.480><c> training</c><00:28:02.750><c> set</c><00:28:02.929><c> it's</c>

00:28:03.040 --> 00:28:03.050 align:start position:0%
loss over the entire training set it's
 

00:28:03.050 --> 00:28:04.720 align:start position:0%
loss over the entire training set it's
the<00:28:03.170><c> mean</c><00:28:03.380><c> loss</c><00:28:03.590><c> of</c><00:28:03.800><c> all</c><00:28:03.980><c> of</c><00:28:04.100><c> the</c><00:28:04.220><c> popular</c><00:28:04.550><c> of</c>

00:28:04.720 --> 00:28:04.730 align:start position:0%
the mean loss of all of the popular of
 

00:28:04.730 --> 00:28:06.160 align:start position:0%
the mean loss of all of the popular of
all<00:28:04.940><c> of</c><00:28:05.090><c> the</c><00:28:05.210><c> individuals</c><00:28:05.690><c> in</c><00:28:05.809><c> the</c><00:28:05.900><c> training</c>

00:28:06.160 --> 00:28:06.170 align:start position:0%
all of the individuals in the training
 

00:28:06.170 --> 00:28:08.799 align:start position:0%
all of the individuals in the training
set<00:28:06.380><c> and</c><00:28:06.700><c> we</c><00:28:07.700><c> want</c><00:28:07.850><c> to</c><00:28:07.940><c> minimize</c><00:28:08.120><c> that</c><00:28:08.600><c> loss</c>

00:28:08.799 --> 00:28:08.809 align:start position:0%
set and we want to minimize that loss
 

00:28:08.809 --> 00:28:10.930 align:start position:0%
set and we want to minimize that loss
and<00:28:09.080><c> that</c><00:28:09.620><c> essentially</c><00:28:10.340><c> means</c><00:28:10.490><c> we</c><00:28:10.730><c> want</c><00:28:10.850><c> to</c>

00:28:10.930 --> 00:28:10.940 align:start position:0%
and that essentially means we want to
 

00:28:10.940 --> 00:28:13.870 align:start position:0%
and that essentially means we want to
find<00:28:11.030><c> the</c><00:28:11.450><c> weights</c><00:28:11.750><c> the</c><00:28:12.590><c> parameterization</c><00:28:13.250><c> of</c>

00:28:13.870 --> 00:28:13.880 align:start position:0%
find the weights the parameterization of
 

00:28:13.880 --> 00:28:16.450 align:start position:0%
find the weights the parameterization of
the<00:28:14.179><c> network</c><00:28:14.510><c> that</c><00:28:14.990><c> results</c><00:28:15.830><c> in</c><00:28:15.950><c> the</c><00:28:16.070><c> minimum</c>

00:28:16.450 --> 00:28:16.460 align:start position:0%
the network that results in the minimum
 

00:28:16.460 --> 00:28:20.799 align:start position:0%
the network that results in the minimum
loss<00:28:17.830><c> remember</c><00:28:18.830><c> again</c><00:28:19.100><c> that</c><00:28:19.130><c> W</c><00:28:19.760><c> here</c><00:28:20.090><c> is</c><00:28:20.240><c> just</c>

00:28:20.799 --> 00:28:20.809 align:start position:0%
loss remember again that W here is just
 

00:28:20.809 --> 00:28:22.600 align:start position:0%
loss remember again that W here is just
a<00:28:20.900><c> collection</c><00:28:21.110><c> it's</c><00:28:21.559><c> just</c><00:28:21.800><c> a</c><00:28:21.860><c> set</c><00:28:22.100><c> of</c><00:28:22.130><c> all</c><00:28:22.460><c> of</c>

00:28:22.600 --> 00:28:22.610 align:start position:0%
a collection it's just a set of all of
 

00:28:22.610 --> 00:28:24.520 align:start position:0%
a collection it's just a set of all of
the<00:28:22.730><c> weights</c><00:28:22.880><c> in</c><00:28:23.000><c> the</c><00:28:23.090><c> network</c><00:28:23.390><c> so</c><00:28:23.690><c> before</c><00:28:24.500><c> I</c>

00:28:24.520 --> 00:28:24.530 align:start position:0%
the weights in the network so before I
 

00:28:24.530 --> 00:28:27.490 align:start position:0%
the weights in the network so before I
define<00:28:24.950><c> W</c><00:28:25.280><c> as</c><00:28:25.400><c> W</c><00:28:25.429><c> 0</c><00:28:26.000><c> W</c><00:28:26.090><c> 1</c><00:28:26.450><c> which</c><00:28:26.870><c> is</c><00:28:27.020><c> the</c><00:28:27.230><c> weights</c>

00:28:27.490 --> 00:28:27.500 align:start position:0%
define W as W 0 W 1 which is the weights
 

00:28:27.500 --> 00:28:29.560 align:start position:0%
define W as W 0 W 1 which is the weights
for<00:28:27.740><c> the</c><00:28:27.800><c> first</c><00:28:27.980><c> layer</c><00:28:28.250><c> second</c><00:28:29.000><c> layer</c><00:28:29.030><c> third</c>

00:28:29.560 --> 00:28:29.570 align:start position:0%
for the first layer second layer third
 

00:28:29.570 --> 00:28:33.430 align:start position:0%
for the first layer second layer third
layer<00:28:29.809><c> etc</c><00:28:30.590><c> and</c><00:28:31.600><c> you</c><00:28:32.600><c> keep</c><00:28:32.840><c> stacking</c><00:28:33.050><c> all</c><00:28:33.320><c> of</c>

00:28:33.430 --> 00:28:33.440 align:start position:0%
layer etc and you keep stacking all of
 

00:28:33.440 --> 00:28:34.720 align:start position:0%
layer etc and you keep stacking all of
these<00:28:33.590><c> weights</c><00:28:33.770><c> together</c><00:28:34.070><c> you</c><00:28:34.250><c> combine</c><00:28:34.520><c> them</c>

00:28:34.720 --> 00:28:34.730 align:start position:0%
these weights together you combine them
 

00:28:34.730 --> 00:28:36.220 align:start position:0%
these weights together you combine them
and<00:28:34.880><c> you</c><00:28:34.970><c> want</c><00:28:35.120><c> to</c><00:28:35.300><c> compute</c><00:28:36.080><c> this</c>

00:28:36.220 --> 00:28:36.230 align:start position:0%
and you want to compute this
 

00:28:36.230 --> 00:28:38.320 align:start position:0%
and you want to compute this
optimization<00:28:36.740><c> problem</c><00:28:36.920><c> over</c><00:28:37.850><c> all</c><00:28:38.030><c> of</c><00:28:38.179><c> these</c>

00:28:38.320 --> 00:28:38.330 align:start position:0%
optimization problem over all of these
 

00:28:38.330 --> 00:28:43.930 align:start position:0%
optimization problem over all of these
weights<00:28:41.350><c> so</c><00:28:42.350><c> again</c><00:28:43.130><c> remember</c><00:28:43.280><c> our</c><00:28:43.670><c> loss</c>

00:28:43.930 --> 00:28:43.940 align:start position:0%
weights so again remember our loss
 

00:28:43.940 --> 00:28:45.669 align:start position:0%
weights so again remember our loss
function<00:28:44.510><c> what</c><00:28:44.840><c> does</c><00:28:44.929><c> our</c><00:28:45.050><c> loss</c><00:28:45.260><c> function</c>

00:28:45.669 --> 00:28:45.679 align:start position:0%
function what does our loss function
 

00:28:45.679 --> 00:28:47.710 align:start position:0%
function what does our loss function
look<00:28:45.860><c> like</c><00:28:46.040><c> it's</c><00:28:46.550><c> just</c><00:28:46.790><c> a</c><00:28:46.910><c> simple</c><00:28:47.210><c> function</c>

00:28:47.710 --> 00:28:47.720 align:start position:0%
look like it's just a simple function
 

00:28:47.720 --> 00:28:51.940 align:start position:0%
look like it's just a simple function
that<00:28:48.320><c> takes</c><00:28:48.559><c> as</c><00:28:48.770><c> inputs</c><00:28:49.190><c> our</c><00:28:49.400><c> weights</c><00:28:50.000><c> and</c><00:28:50.950><c> if</c>

00:28:51.940 --> 00:28:51.950 align:start position:0%
that takes as inputs our weights and if
 

00:28:51.950 --> 00:28:53.650 align:start position:0%
that takes as inputs our weights and if
we<00:28:52.700><c> have</c><00:28:52.820><c> two</c><00:28:53.000><c> weights</c><00:28:53.210><c> we</c><00:28:53.390><c> can</c><00:28:53.510><c> actually</c>

00:28:53.650 --> 00:28:53.660 align:start position:0%
we have two weights we can actually
 

00:28:53.660 --> 00:28:55.630 align:start position:0%
we have two weights we can actually
visualize<00:28:53.929><c> it</c><00:28:54.380><c> again</c><00:28:54.620><c> we</c><00:28:54.890><c> can</c><00:28:55.070><c> see</c><00:28:55.400><c> on</c><00:28:55.520><c> the</c>

00:28:55.630 --> 00:28:55.640 align:start position:0%
visualize it again we can see on the
 

00:28:55.640 --> 00:28:57.060 align:start position:0%
visualize it again we can see on the
x-axis

00:28:57.060 --> 00:28:57.070 align:start position:0%
x-axis
 

00:28:57.070 --> 00:28:59.590 align:start position:0%
x-axis
one<00:28:58.070><c> way</c><00:28:58.220><c> so</c><00:28:58.549><c> this</c><00:28:58.640><c> is</c><00:28:58.700><c> one</c><00:28:58.970><c> scaler</c><00:28:59.270><c> that</c><00:28:59.510><c> we</c>

00:28:59.590 --> 00:28:59.600 align:start position:0%
one way so this is one scaler that we
 

00:28:59.600 --> 00:29:01.299 align:start position:0%
one way so this is one scaler that we
can<00:28:59.750><c> change</c><00:29:00.020><c> and</c><00:29:00.260><c> another</c><00:29:00.559><c> way</c><00:29:00.740><c> on</c><00:29:00.980><c> the</c><00:29:01.159><c> y</c><00:29:01.279><c> axis</c>

00:29:01.299 --> 00:29:01.309 align:start position:0%
can change and another way on the y axis
 

00:29:01.309 --> 00:29:04.060 align:start position:0%
can change and another way on the y axis
and<00:29:01.909><c> on</c><00:29:02.720><c> the</c><00:29:02.750><c> z</c><00:29:03.049><c> axis</c><00:29:03.080><c> this</c><00:29:03.590><c> is</c><00:29:03.649><c> our</c><00:29:03.890><c> actual</c>

00:29:04.060 --> 00:29:04.070 align:start position:0%
and on the z axis this is our actual
 

00:29:04.070 --> 00:29:08.649 align:start position:0%
and on the z axis this is our actual
loss<00:29:05.409><c> if</c><00:29:06.409><c> we</c><00:29:07.220><c> want</c><00:29:07.399><c> to</c><00:29:07.520><c> find</c><00:29:07.760><c> the</c><00:29:07.940><c> lowest</c><00:29:08.179><c> point</c>

00:29:08.649 --> 00:29:08.659 align:start position:0%
loss if we want to find the lowest point
 

00:29:08.659 --> 00:29:10.480 align:start position:0%
loss if we want to find the lowest point
in<00:29:08.809><c> this</c><00:29:08.929><c> landscape</c><00:29:09.470><c> that</c><00:29:09.710><c> corresponds</c><00:29:10.460><c> to</c>

00:29:10.480 --> 00:29:10.490 align:start position:0%
in this landscape that corresponds to
 

00:29:10.490 --> 00:29:12.909 align:start position:0%
in this landscape that corresponds to
the<00:29:10.760><c> minimum</c><00:29:11.179><c> loss</c><00:29:11.450><c> and</c><00:29:11.870><c> we</c><00:29:12.470><c> want</c><00:29:12.620><c> to</c><00:29:12.710><c> find</c>

00:29:12.909 --> 00:29:12.919 align:start position:0%
the minimum loss and we want to find
 

00:29:12.919 --> 00:29:14.200 align:start position:0%
the minimum loss and we want to find
that<00:29:13.039><c> point</c><00:29:13.279><c> so</c><00:29:13.460><c> that</c><00:29:13.580><c> we</c><00:29:13.700><c> can</c><00:29:13.850><c> find</c><00:29:14.059><c> the</c>

00:29:14.200 --> 00:29:14.210 align:start position:0%
that point so that we can find the
 

00:29:14.210 --> 00:29:16.659 align:start position:0%
that point so that we can find the
corresponding<00:29:14.419><c> weights</c><00:29:15.020><c> that</c><00:29:15.710><c> were</c><00:29:16.100><c> set</c><00:29:16.490><c> to</c>

00:29:16.659 --> 00:29:16.669 align:start position:0%
corresponding weights that were set to
 

00:29:16.669 --> 00:29:20.680 align:start position:0%
corresponding weights that were set to
achieve<00:29:16.789><c> that</c><00:29:17.179><c> minimum</c><00:29:17.480><c> loss</c><00:29:19.450><c> so</c><00:29:20.450><c> how</c><00:29:20.570><c> do</c><00:29:20.630><c> we</c>

00:29:20.680 --> 00:29:20.690 align:start position:0%
achieve that minimum loss so how do we
 

00:29:20.690 --> 00:29:23.440 align:start position:0%
achieve that minimum loss so how do we
do<00:29:20.840><c> it</c><00:29:20.960><c> we</c><00:29:21.350><c> use</c><00:29:21.500><c> this</c><00:29:21.710><c> technique</c><00:29:22.460><c> called</c><00:29:22.730><c> loss</c>

00:29:23.440 --> 00:29:23.450 align:start position:0%
do it we use this technique called loss
 

00:29:23.450 --> 00:29:26.889 align:start position:0%
do it we use this technique called loss
optimization<00:29:24.230><c> through</c><00:29:24.590><c> gradient</c><00:29:25.010><c> descent</c><00:29:25.899><c> we</c>

00:29:26.889 --> 00:29:26.899 align:start position:0%
optimization through gradient descent we
 

00:29:26.899 --> 00:29:29.260 align:start position:0%
optimization through gradient descent we
start<00:29:27.200><c> by</c><00:29:27.320><c> picking</c><00:29:27.559><c> an</c><00:29:27.860><c> initial</c><00:29:28.520><c> point</c><00:29:29.000><c> on</c>

00:29:29.260 --> 00:29:29.270 align:start position:0%
start by picking an initial point on
 

00:29:29.270 --> 00:29:32.169 align:start position:0%
start by picking an initial point on
this<00:29:29.539><c> landscape</c><00:29:29.779><c> an</c><00:29:30.260><c> initial</c><00:29:30.770><c> w0</c><00:29:31.429><c> w1</c><00:29:31.490><c> so</c>

00:29:32.169 --> 00:29:32.179 align:start position:0%
this landscape an initial w0 w1 so
 

00:29:32.179 --> 00:29:35.139 align:start position:0%
this landscape an initial w0 w1 so
here's<00:29:32.390><c> this</c><00:29:32.570><c> point</c><00:29:32.870><c> this</c><00:29:33.020><c> black</c><00:29:34.010><c> cross</c><00:29:34.370><c> we</c>

00:29:35.139 --> 00:29:35.149 align:start position:0%
here's this point this black cross we
 

00:29:35.149 --> 00:29:38.230 align:start position:0%
here's this point this black cross we
start<00:29:35.480><c> at</c><00:29:35.570><c> this</c><00:29:35.690><c> point</c><00:29:36.789><c> we</c><00:29:37.789><c> compute</c><00:29:38.149><c> the</c>

00:29:38.230 --> 00:29:38.240 align:start position:0%
start at this point we compute the
 

00:29:38.240 --> 00:29:41.409 align:start position:0%
start at this point we compute the
gradient<00:29:38.270><c> at</c><00:29:38.929><c> this</c><00:29:39.230><c> local</c><00:29:39.679><c> point</c><00:29:39.919><c> and</c><00:29:40.270><c> in</c><00:29:41.270><c> this</c>

00:29:41.409 --> 00:29:41.419 align:start position:0%
gradient at this local point and in this
 

00:29:41.419 --> 00:29:43.000 align:start position:0%
gradient at this local point and in this
landscape<00:29:41.779><c> we</c><00:29:42.200><c> can</c><00:29:42.350><c> see</c><00:29:42.529><c> that</c><00:29:42.710><c> the</c><00:29:42.799><c> gradient</c>

00:29:43.000 --> 00:29:43.010 align:start position:0%
landscape we can see that the gradient
 

00:29:43.010 --> 00:29:47.039 align:start position:0%
landscape we can see that the gradient
tells<00:29:43.399><c> us</c><00:29:43.669><c> the</c><00:29:44.090><c> direction</c><00:29:44.600><c> of</c><00:29:44.750><c> maximal</c><00:29:45.289><c> ascent</c>

00:29:47.039 --> 00:29:47.049 align:start position:0%
tells us the direction of maximal ascent
 

00:29:47.049 --> 00:29:49.269 align:start position:0%
tells us the direction of maximal ascent
now<00:29:48.049><c> that</c><00:29:48.289><c> we</c><00:29:48.380><c> know</c><00:29:48.500><c> the</c><00:29:48.679><c> direction</c><00:29:49.039><c> of</c><00:29:49.220><c> the</c>

00:29:49.269 --> 00:29:49.279 align:start position:0%
now that we know the direction of the
 

00:29:49.279 --> 00:29:50.950 align:start position:0%
now that we know the direction of the
maximal<00:29:49.669><c> ascent</c><00:29:50.059><c> we</c><00:29:50.270><c> can</c><00:29:50.450><c> reverse</c><00:29:50.929><c> that</c>

00:29:50.950 --> 00:29:50.960 align:start position:0%
maximal ascent we can reverse that
 

00:29:50.960 --> 00:29:53.260 align:start position:0%
maximal ascent we can reverse that
gradient<00:29:51.710><c> and</c><00:29:51.950><c> actually</c><00:29:52.490><c> take</c><00:29:52.669><c> a</c><00:29:52.700><c> small</c><00:29:53.029><c> step</c>

00:29:53.260 --> 00:29:53.270 align:start position:0%
gradient and actually take a small step
 

00:29:53.270 --> 00:29:56.649 align:start position:0%
gradient and actually take a small step
in<00:29:53.450><c> the</c><00:29:53.600><c> opposite</c><00:29:54.020><c> direction</c><00:29:55.179><c> that</c><00:29:56.179><c> moves</c><00:29:56.510><c> us</c>

00:29:56.649 --> 00:29:56.659 align:start position:0%
in the opposite direction that moves us
 

00:29:56.659 --> 00:29:58.510 align:start position:0%
in the opposite direction that moves us
closer<00:29:56.990><c> towards</c><00:29:57.559><c> the</c><00:29:57.620><c> lowest</c><00:29:57.980><c> point</c><00:29:58.220><c> because</c>

00:29:58.510 --> 00:29:58.520 align:start position:0%
closer towards the lowest point because
 

00:29:58.520 --> 00:30:00.279 align:start position:0%
closer towards the lowest point because
we're<00:29:58.669><c> taking</c><00:29:58.850><c> a</c><00:29:59.090><c> greedy</c><00:29:59.450><c> approach</c><00:29:59.630><c> to</c><00:30:00.080><c> move</c>

00:30:00.279 --> 00:30:00.289 align:start position:0%
we're taking a greedy approach to move
 

00:30:00.289 --> 00:30:01.870 align:start position:0%
we're taking a greedy approach to move
in<00:30:00.500><c> the</c><00:30:00.860><c> opposite</c><00:30:01.309><c> direction</c><00:30:01.580><c> of</c><00:30:01.820><c> the</c>

00:30:01.870 --> 00:30:01.880 align:start position:0%
in the opposite direction of the
 

00:30:01.880 --> 00:30:04.750 align:start position:0%
in the opposite direction of the
gradient<00:30:02.350><c> we</c><00:30:03.350><c> can</c><00:30:03.500><c> iteratively</c><00:30:03.980><c> repeat</c><00:30:04.580><c> this</c>

00:30:04.750 --> 00:30:04.760 align:start position:0%
gradient we can iteratively repeat this
 

00:30:04.760 --> 00:30:07.029 align:start position:0%
gradient we can iteratively repeat this
process<00:30:04.970><c> over</c><00:30:05.450><c> and</c><00:30:05.630><c> over</c><00:30:05.809><c> and</c><00:30:06.049><c> over</c><00:30:06.289><c> again</c><00:30:06.409><c> we</c>

00:30:07.029 --> 00:30:07.039 align:start position:0%
process over and over and over again we
 

00:30:07.039 --> 00:30:08.860 align:start position:0%
process over and over and over again we
computing<00:30:07.549><c> the</c><00:30:07.669><c> gradient</c><00:30:07.700><c> at</c><00:30:08.179><c> each</c><00:30:08.330><c> time</c><00:30:08.600><c> and</c>

00:30:08.860 --> 00:30:08.870 align:start position:0%
computing the gradient at each time and
 

00:30:08.870 --> 00:30:11.560 align:start position:0%
computing the gradient at each time and
keep<00:30:09.500><c> moving</c><00:30:09.830><c> moving</c><00:30:10.190><c> closer</c><00:30:10.520><c> towards</c><00:30:10.970><c> that</c>

00:30:11.560 --> 00:30:11.570 align:start position:0%
keep moving moving closer towards that
 

00:30:11.570 --> 00:30:15.310 align:start position:0%
keep moving moving closer towards that
lowest<00:30:12.080><c> minimum</c><00:30:13.690><c> we</c><00:30:14.690><c> can</c><00:30:14.720><c> summarize</c><00:30:15.049><c> this</c>

00:30:15.310 --> 00:30:15.320 align:start position:0%
lowest minimum we can summarize this
 

00:30:15.320 --> 00:30:17.200 align:start position:0%
lowest minimum we can summarize this
algorithm<00:30:15.830><c> known</c><00:30:16.100><c> as</c><00:30:16.250><c> gradient</c><00:30:16.549><c> descent</c><00:30:16.760><c> in</c>

00:30:17.200 --> 00:30:17.210 align:start position:0%
algorithm known as gradient descent in
 

00:30:17.210 --> 00:30:20.919 align:start position:0%
algorithm known as gradient descent in
pseudocode<00:30:17.799><c> by</c><00:30:18.799><c> this</c><00:30:19.730><c> the</c><00:30:20.240><c> pseudocode</c><00:30:20.539><c> on</c><00:30:20.809><c> the</c>

00:30:20.919 --> 00:30:20.929 align:start position:0%
pseudocode by this the pseudocode on the
 

00:30:20.929 --> 00:30:23.230 align:start position:0%
pseudocode by this the pseudocode on the
left-hand<00:30:21.289><c> side</c><00:30:21.640><c> we</c><00:30:22.640><c> start</c><00:30:22.850><c> by</c><00:30:23.000><c> initializing</c>

00:30:23.230 --> 00:30:23.240 align:start position:0%
left-hand side we start by initializing
 

00:30:23.240 --> 00:30:25.419 align:start position:0%
left-hand side we start by initializing
our<00:30:23.720><c> weights</c><00:30:23.899><c> randomly</c><00:30:24.409><c> computing</c><00:30:25.279><c> this</c>

00:30:25.419 --> 00:30:25.429 align:start position:0%
our weights randomly computing this
 

00:30:25.429 --> 00:30:30.340 align:start position:0%
our weights randomly computing this
gradient<00:30:25.850><c> DJ</c><00:30:26.600><c> DW</c><00:30:28.480><c> then</c><00:30:29.480><c> updating</c><00:30:30.020><c> our</c><00:30:30.110><c> weights</c>

00:30:30.340 --> 00:30:30.350 align:start position:0%
gradient DJ DW then updating our weights
 

00:30:30.350 --> 00:30:31.960 align:start position:0%
gradient DJ DW then updating our weights
in<00:30:30.500><c> the</c><00:30:30.590><c> opposite</c><00:30:31.039><c> direction</c><00:30:31.159><c> of</c><00:30:31.640><c> that</c>

00:30:31.960 --> 00:30:31.970 align:start position:0%
in the opposite direction of that
 

00:30:31.970 --> 00:30:37.289 align:start position:0%
in the opposite direction of that
gradient<00:30:33.760><c> we</c><00:30:34.760><c> used</c><00:30:35.000><c> this</c><00:30:35.179><c> small</c><00:30:35.570><c> amount</c><00:30:35.750><c> ADA</c>

00:30:37.289 --> 00:30:37.299 align:start position:0%
gradient we used this small amount ADA
 

00:30:37.299 --> 00:30:40.750 align:start position:0%
gradient we used this small amount ADA
which<00:30:38.299><c> you</c><00:30:38.419><c> can</c><00:30:38.539><c> see</c><00:30:38.720><c> here</c><00:30:39.260><c> and</c><00:30:39.549><c> this</c><00:30:40.549><c> is</c>

00:30:40.750 --> 00:30:40.760 align:start position:0%
which you can see here and this is
 

00:30:40.760 --> 00:30:42.580 align:start position:0%
which you can see here and this is
essentially<00:30:41.240><c> what</c><00:30:41.270><c> we</c><00:30:41.539><c> call</c><00:30:41.840><c> the</c><00:30:42.230><c> learning</c>

00:30:42.580 --> 00:30:42.590 align:start position:0%
essentially what we call the learning
 

00:30:42.590 --> 00:30:44.440 align:start position:0%
essentially what we call the learning
rate<00:30:42.710><c> this</c><00:30:43.159><c> is</c><00:30:43.309><c> determining</c><00:30:43.820><c> how</c><00:30:43.880><c> much</c><00:30:44.210><c> of</c><00:30:44.390><c> a</c>

00:30:44.440 --> 00:30:44.450 align:start position:0%
rate this is determining how much of a
 

00:30:44.450 --> 00:30:46.480 align:start position:0%
rate this is determining how much of a
step<00:30:44.720><c> we</c><00:30:45.169><c> take</c><00:30:45.470><c> and</c><00:30:45.679><c> how</c><00:30:45.770><c> much</c><00:30:45.830><c> we</c><00:30:46.070><c> trust</c><00:30:46.279><c> that</c>

00:30:46.480 --> 00:30:46.490 align:start position:0%
step we take and how much we trust that
 

00:30:46.490 --> 00:30:48.430 align:start position:0%
step we take and how much we trust that
with<00:30:46.850><c> that</c><00:30:47.029><c> gradient</c><00:30:47.480><c> update</c><00:30:48.140><c> that</c><00:30:48.320><c> we</c>

00:30:48.430 --> 00:30:48.440 align:start position:0%
with that gradient update that we
 

00:30:48.440 --> 00:30:50.380 align:start position:0%
with that gradient update that we
computed<00:30:48.890><c> we'll</c><00:30:49.700><c> talk</c><00:30:49.880><c> more</c><00:30:50.029><c> about</c><00:30:50.090><c> this</c>

00:30:50.380 --> 00:30:50.390 align:start position:0%
computed we'll talk more about this
 

00:30:50.390 --> 00:30:53.409 align:start position:0%
computed we'll talk more about this
later<00:30:51.429><c> but</c><00:30:52.429><c> for</c><00:30:52.610><c> now</c><00:30:52.669><c> let's</c><00:30:52.970><c> take</c><00:30:53.120><c> a</c><00:30:53.149><c> look</c><00:30:53.330><c> at</c>

00:30:53.409 --> 00:30:53.419 align:start position:0%
later but for now let's take a look at
 

00:30:53.419 --> 00:30:56.950 align:start position:0%
later but for now let's take a look at
this<00:30:53.539><c> term</c><00:30:53.750><c> here</c><00:30:53.980><c> this</c><00:30:54.980><c> gradient</c><00:30:55.490><c> DJ</c><00:30:56.210><c> DW</c><00:30:56.779><c> is</c>

00:30:56.950 --> 00:30:56.960 align:start position:0%
this term here this gradient DJ DW is
 

00:30:56.960 --> 00:30:59.889 align:start position:0%
this term here this gradient DJ DW is
actually<00:30:57.470><c> explaining</c><00:30:58.399><c> how</c><00:30:58.760><c> the</c><00:30:58.820><c> lost</c><00:30:59.270><c> changes</c>

00:30:59.889 --> 00:30:59.899 align:start position:0%
actually explaining how the lost changes
 

00:30:59.899 --> 00:31:03.370 align:start position:0%
actually explaining how the lost changes
with<00:31:00.320><c> respect</c><00:31:00.860><c> to</c><00:31:01.100><c> each</c><00:31:01.399><c> of</c><00:31:01.760><c> the</c><00:31:02.000><c> weights</c><00:31:02.380><c> but</c>

00:31:03.370 --> 00:31:03.380 align:start position:0%
with respect to each of the weights but
 

00:31:03.380 --> 00:31:05.139 align:start position:0%
with respect to each of the weights but
I<00:31:03.440><c> never</c><00:31:03.649><c> actually</c><00:31:03.830><c> told</c><00:31:03.980><c> you</c><00:31:04.370><c> how</c><00:31:04.520><c> to</c><00:31:04.580><c> compute</c>

00:31:05.139 --> 00:31:05.149 align:start position:0%
I never actually told you how to compute
 

00:31:05.149 --> 00:31:07.510 align:start position:0%
I never actually told you how to compute
this<00:31:05.779><c> term</c><00:31:06.080><c> this</c><00:31:06.289><c> is</c><00:31:06.440><c> actually</c><00:31:06.830><c> a</c><00:31:06.980><c> crucial</c>

00:31:07.510 --> 00:31:07.520 align:start position:0%
this term this is actually a crucial
 

00:31:07.520 --> 00:31:09.310 align:start position:0%
this term this is actually a crucial
part<00:31:08.000><c> of</c><00:31:08.179><c> deep</c><00:31:08.600><c> learning</c><00:31:08.779><c> and</c><00:31:09.200><c> neural</c>

00:31:09.310 --> 00:31:09.320 align:start position:0%
part of deep learning and neural
 

00:31:09.320 --> 00:31:10.720 align:start position:0%
part of deep learning and neural
networks<00:31:09.770><c> in</c><00:31:09.889><c> general</c>

00:31:10.720 --> 00:31:10.730 align:start position:0%
networks in general
 

00:31:10.730 --> 00:31:12.460 align:start position:0%
networks in general
computing<00:31:11.210><c> this</c><00:31:11.330><c> term</c><00:31:11.540><c> is</c><00:31:11.690><c> essentially</c><00:31:12.080><c> all</c>

00:31:12.460 --> 00:31:12.470 align:start position:0%
computing this term is essentially all
 

00:31:12.470 --> 00:31:15.010 align:start position:0%
computing this term is essentially all
that<00:31:13.250><c> matters</c><00:31:13.670><c> when</c><00:31:14.060><c> you</c><00:31:14.330><c> try</c><00:31:14.480><c> and</c><00:31:14.600><c> optimize</c>

00:31:15.010 --> 00:31:15.020 align:start position:0%
that matters when you try and optimize
 

00:31:15.020 --> 00:31:17.140 align:start position:0%
that matters when you try and optimize
your<00:31:15.200><c> network</c><00:31:15.500><c> is</c><00:31:15.680><c> the</c><00:31:16.250><c> most</c><00:31:16.280><c> computational</c>

00:31:17.140 --> 00:31:17.150 align:start position:0%
your network is the most computational
 

00:31:17.150 --> 00:31:19.570 align:start position:0%
your network is the most computational
part<00:31:17.300><c> of</c><00:31:17.540><c> training</c><00:31:17.840><c> as</c><00:31:17.930><c> well</c><00:31:18.080><c> and</c><00:31:18.500><c> it's</c><00:31:19.370><c> known</c>

00:31:19.570 --> 00:31:19.580 align:start position:0%
part of training as well and it's known
 

00:31:19.580 --> 00:31:22.660 align:start position:0%
part of training as well and it's known
as<00:31:19.760><c> back</c><00:31:20.060><c> propagation</c><00:31:21.280><c> we'll</c><00:31:22.280><c> start</c><00:31:22.520><c> with</c><00:31:22.640><c> a</c>

00:31:22.660 --> 00:31:22.670 align:start position:0%
as back propagation we'll start with a
 

00:31:22.670 --> 00:31:24.850 align:start position:0%
as back propagation we'll start with a
very<00:31:22.760><c> simple</c><00:31:23.150><c> network</c><00:31:23.570><c> with</c><00:31:23.840><c> only</c><00:31:23.990><c> one</c><00:31:24.410><c> hidden</c>

00:31:24.850 --> 00:31:24.860 align:start position:0%
very simple network with only one hidden
 

00:31:24.860 --> 00:31:26.890 align:start position:0%
very simple network with only one hidden
input<00:31:25.190><c> sorry</c><00:31:25.700><c> with</c><00:31:25.850><c> one</c><00:31:26.060><c> input</c><00:31:26.210><c> one</c><00:31:26.540><c> hidden</c>

00:31:26.890 --> 00:31:26.900 align:start position:0%
input sorry with one input one hidden
 

00:31:26.900 --> 00:31:30.450 align:start position:0%
input sorry with one input one hidden
layer<00:31:27.640><c> one</c><00:31:28.640><c> handed</c><00:31:28.910><c> and</c><00:31:28.940><c> unit</c><00:31:29.270><c> and</c><00:31:29.450><c> one</c><00:31:29.780><c> output</c>

00:31:30.450 --> 00:31:30.460 align:start position:0%
layer one handed and unit and one output
 

00:31:30.460 --> 00:31:33.250 align:start position:0%
layer one handed and unit and one output
computing<00:31:31.460><c> the</c><00:31:31.580><c> gradient</c><00:31:31.610><c> of</c><00:31:32.270><c> our</c><00:31:32.810><c> loss</c><00:31:32.990><c> with</c>

00:31:33.250 --> 00:31:33.260 align:start position:0%
computing the gradient of our loss with
 

00:31:33.260 --> 00:31:37.090 align:start position:0%
computing the gradient of our loss with
respect<00:31:33.380><c> to</c><00:31:33.830><c> W</c><00:31:34.550><c> to</c><00:31:35.350><c> corresponds</c><00:31:36.350><c> to</c><00:31:36.410><c> telling</c>

00:31:37.090 --> 00:31:37.100 align:start position:0%
respect to W to corresponds to telling
 

00:31:37.100 --> 00:31:40.000 align:start position:0%
respect to W to corresponds to telling
us<00:31:37.250><c> how</c><00:31:37.580><c> much</c><00:31:37.820><c> a</c><00:31:37.850><c> small</c><00:31:38.090><c> change</c><00:31:38.600><c> in</c><00:31:38.780><c> our</c><00:31:38.870><c> and</c><00:31:39.560><c> W</c>

00:31:40.000 --> 00:31:40.010 align:start position:0%
us how much a small change in our and W
 

00:31:40.010 --> 00:31:45.910 align:start position:0%
us how much a small change in our and W
two<00:31:40.190><c> affects</c><00:31:41.060><c> our</c><00:31:41.380><c> output</c><00:31:42.380><c> or</c><00:31:42.560><c> loss</c><00:31:44.590><c> so</c><00:31:45.590><c> if</c><00:31:45.770><c> we</c>

00:31:45.910 --> 00:31:45.920 align:start position:0%
two affects our output or loss so if we
 

00:31:45.920 --> 00:31:48.490 align:start position:0%
two affects our output or loss so if we
write<00:31:46.100><c> this</c><00:31:46.220><c> as</c><00:31:46.340><c> a</c><00:31:46.670><c> derivative</c><00:31:47.330><c> we</c><00:31:47.990><c> can</c><00:31:48.170><c> start</c>

00:31:48.490 --> 00:31:48.500 align:start position:0%
write this as a derivative we can start
 

00:31:48.500 --> 00:31:50.410 align:start position:0%
write this as a derivative we can start
by<00:31:48.650><c> computing</c><00:31:49.070><c> this</c><00:31:49.220><c> by</c><00:31:49.520><c> simply</c><00:31:49.880><c> expanding</c>

00:31:50.410 --> 00:31:50.420 align:start position:0%
by computing this by simply expanding
 

00:31:50.420 --> 00:31:52.270 align:start position:0%
by computing this by simply expanding
this<00:31:50.510><c> derivative</c><00:31:51.020><c> into</c><00:31:51.350><c> a</c><00:31:51.380><c> chain</c><00:31:51.860><c> by</c><00:31:52.100><c> using</c>

00:31:52.270 --> 00:31:52.280 align:start position:0%
this derivative into a chain by using
 

00:31:52.280 --> 00:31:55.030 align:start position:0%
this derivative into a chain by using
the<00:31:52.490><c> chain</c><00:31:52.700><c> rule</c><00:31:53.440><c> backwards</c><00:31:54.440><c> from</c><00:31:54.710><c> the</c><00:31:54.860><c> loss</c>

00:31:55.030 --> 00:31:55.040 align:start position:0%
the chain rule backwards from the loss
 

00:31:55.040 --> 00:31:58.030 align:start position:0%
the chain rule backwards from the loss
through<00:31:55.670><c> the</c><00:31:56.090><c> output</c><00:31:56.500><c> and</c><00:31:57.500><c> that</c><00:31:57.560><c> looks</c><00:31:57.920><c> like</c>

00:31:58.030 --> 00:31:58.040 align:start position:0%
through the output and that looks like
 

00:31:58.040 --> 00:32:06.460 align:start position:0%
through the output and that looks like
this<00:31:58.250><c> so</c><00:31:58.520><c> DJ</c><00:31:59.800><c> DW</c><00:32:00.800><c> 2</c><00:32:00.980><c> becomes</c><00:32:01.370><c> DJ</c><00:32:02.200><c> dy</c><00:32:03.200><c> dy</c><00:32:03.860><c> DW</c><00:32:04.790><c> 2</c><00:32:05.470><c> ok</c>

00:32:06.460 --> 00:32:06.470 align:start position:0%
this so DJ DW 2 becomes DJ dy dy DW 2 ok
 

00:32:06.470 --> 00:32:07.930 align:start position:0%
this so DJ DW 2 becomes DJ dy dy DW 2 ok
and<00:32:06.650><c> that's</c><00:32:06.740><c> just</c><00:32:07.010><c> a</c><00:32:07.070><c> simple</c><00:32:07.220><c> application</c><00:32:07.850><c> of</c>

00:32:07.930 --> 00:32:07.940 align:start position:0%
and that's just a simple application of
 

00:32:07.940 --> 00:32:10.990 align:start position:0%
and that's just a simple application of
the<00:32:08.090><c> chain</c><00:32:08.270><c> rule</c><00:32:09.190><c> now</c><00:32:10.190><c> let's</c><00:32:10.430><c> suppose</c><00:32:10.550><c> instead</c>

00:32:10.990 --> 00:32:11.000 align:start position:0%
the chain rule now let's suppose instead
 

00:32:11.000 --> 00:32:13.180 align:start position:0%
the chain rule now let's suppose instead
of<00:32:11.060><c> computing</c><00:32:11.390><c> DJ</c><00:32:11.810><c> DW</c><00:32:12.320><c> 2</c><00:32:12.470><c> we</c><00:32:12.680><c> want</c><00:32:12.830><c> to</c><00:32:12.890><c> compute</c>

00:32:13.180 --> 00:32:13.190 align:start position:0%
of computing DJ DW 2 we want to compute
 

00:32:13.190 --> 00:32:17.320 align:start position:0%
of computing DJ DW 2 we want to compute
DJ<00:32:13.670><c> DW</c><00:32:14.420><c> 1</c><00:32:14.660><c> so</c><00:32:14.990><c> I've</c><00:32:15.080><c> changed</c><00:32:15.320><c> the</c><00:32:15.620><c> W</c><00:32:15.920><c> 1</c><00:32:16.130><c> the</c><00:32:16.850><c> W</c><00:32:17.180><c> 2</c>

00:32:17.320 --> 00:32:17.330 align:start position:0%
DJ DW 1 so I've changed the W 1 the W 2
 

00:32:17.330 --> 00:32:19.150 align:start position:0%
DJ DW 1 so I've changed the W 1 the W 2
to<00:32:17.510><c> a</c><00:32:17.540><c> W</c><00:32:17.900><c> 1</c><00:32:18.080><c> on</c><00:32:18.200><c> the</c><00:32:18.320><c> left</c><00:32:18.500><c> hand</c><00:32:18.680><c> side</c><00:32:18.830><c> and</c><00:32:19.070><c> now</c>

00:32:19.150 --> 00:32:19.160 align:start position:0%
to a W 1 on the left hand side and now
 

00:32:19.160 --> 00:32:21.580 align:start position:0%
to a W 1 on the left hand side and now
we<00:32:19.220><c> want</c><00:32:19.430><c> to</c><00:32:19.460><c> compute</c><00:32:19.700><c> this</c><00:32:20.290><c> well</c><00:32:21.290><c> we</c><00:32:21.440><c> can</c>

00:32:21.580 --> 00:32:21.590 align:start position:0%
we want to compute this well we can
 

00:32:21.590 --> 00:32:24.760 align:start position:0%
we want to compute this well we can
simply<00:32:21.920><c> apply</c><00:32:22.010><c> the</c><00:32:22.190><c> chain</c><00:32:22.490><c> rule</c><00:32:22.520><c> again</c><00:32:23.620><c> we</c><00:32:24.620><c> can</c>

00:32:24.760 --> 00:32:24.770 align:start position:0%
simply apply the chain rule again we can
 

00:32:24.770 --> 00:32:27.130 align:start position:0%
simply apply the chain rule again we can
take<00:32:25.010><c> that</c><00:32:25.520><c> middle</c><00:32:25.760><c> term</c><00:32:26.060><c> now</c><00:32:26.450><c> expand</c><00:32:26.930><c> it</c><00:32:27.050><c> out</c>

00:32:27.130 --> 00:32:27.140 align:start position:0%
take that middle term now expand it out
 

00:32:27.140 --> 00:32:29.080 align:start position:0%
take that middle term now expand it out
again<00:32:27.440><c> using</c><00:32:27.710><c> the</c><00:32:27.800><c> same</c><00:32:27.980><c> chain</c><00:32:28.250><c> rule</c><00:32:28.430><c> and</c><00:32:28.610><c> back</c>

00:32:29.080 --> 00:32:29.090 align:start position:0%
again using the same chain rule and back
 

00:32:29.090 --> 00:32:30.910 align:start position:0%
again using the same chain rule and back
propagate<00:32:29.660><c> those</c><00:32:29.870><c> gradients</c><00:32:30.140><c> even</c><00:32:30.740><c> further</c>

00:32:30.910 --> 00:32:30.920 align:start position:0%
propagate those gradients even further
 

00:32:30.920 --> 00:32:35.710 align:start position:0%
propagate those gradients even further
back<00:32:31.190><c> in</c><00:32:31.430><c> in</c><00:32:31.580><c> the</c><00:32:31.970><c> network</c><00:32:32.680><c> and</c><00:32:34.720><c> essentially</c>

00:32:35.710 --> 00:32:35.720 align:start position:0%
back in in the network and essentially
 

00:32:35.720 --> 00:32:37.240 align:start position:0%
back in in the network and essentially
we<00:32:35.870><c> keep</c><00:32:36.080><c> repeating</c><00:32:36.320><c> this</c><00:32:36.590><c> for</c><00:32:36.770><c> every</c><00:32:37.070><c> weight</c>

00:32:37.240 --> 00:32:37.250 align:start position:0%
we keep repeating this for every weight
 

00:32:37.250 --> 00:32:39.220 align:start position:0%
we keep repeating this for every weight
in<00:32:37.430><c> the</c><00:32:37.550><c> network</c><00:32:37.880><c> using</c><00:32:38.570><c> the</c><00:32:38.600><c> gradients</c><00:32:39.080><c> for</c>

00:32:39.220 --> 00:32:39.230 align:start position:0%
in the network using the gradients for
 

00:32:39.230 --> 00:32:41.140 align:start position:0%
in the network using the gradients for
later<00:32:39.410><c> layers</c><00:32:39.710><c> to</c><00:32:40.310><c> back</c><00:32:40.520><c> propagate</c><00:32:41.000><c> those</c>

00:32:41.140 --> 00:32:41.150 align:start position:0%
later layers to back propagate those
 

00:32:41.150 --> 00:32:43.540 align:start position:0%
later layers to back propagate those
errors<00:32:41.570><c> back</c><00:32:41.930><c> into</c><00:32:42.320><c> the</c><00:32:42.500><c> original</c><00:32:42.650><c> input</c><00:32:43.160><c> we</c>

00:32:43.540 --> 00:32:43.550 align:start position:0%
errors back into the original input we
 

00:32:43.550 --> 00:32:45.580 align:start position:0%
errors back into the original input we
do<00:32:43.700><c> this</c><00:32:43.820><c> for</c><00:32:43.970><c> all</c><00:32:44.120><c> of</c><00:32:44.150><c> the</c><00:32:44.330><c> weights</c><00:32:44.510><c> and</c><00:32:44.750><c> and</c>

00:32:45.580 --> 00:32:45.590 align:start position:0%
do this for all of the weights and and
 

00:32:45.590 --> 00:32:46.810 align:start position:0%
do this for all of the weights and and
that<00:32:45.860><c> gives</c><00:32:46.040><c> us</c><00:32:46.160><c> our</c><00:32:46.250><c> gradient</c><00:32:46.490><c> for</c><00:32:46.730><c> each</c>

00:32:46.810 --> 00:32:46.820 align:start position:0%
that gives us our gradient for each
 

00:32:46.820 --> 00:32:58.599 align:start position:0%
that gives us our gradient for each
weight

00:32:58.599 --> 00:32:58.609 align:start position:0%
 
 

00:32:58.609 --> 00:33:01.279 align:start position:0%
 
yeah<00:32:59.609><c> you're</c><00:32:59.850><c> completely</c><00:33:00.389><c> right</c><00:33:00.509><c> so</c><00:33:00.929><c> the</c>

00:33:01.279 --> 00:33:01.289 align:start position:0%
yeah you're completely right so the
 

00:33:01.289 --> 00:33:02.840 align:start position:0%
yeah you're completely right so the
question<00:33:01.559><c> is</c><00:33:01.739><c> how</c><00:33:02.070><c> do</c><00:33:02.129><c> you</c><00:33:02.190><c> ensure</c><00:33:02.519><c> that</c><00:33:02.549><c> this</c>

00:33:02.840 --> 00:33:02.850 align:start position:0%
question is how do you ensure that this
 

00:33:02.850 --> 00:33:04.759 align:start position:0%
question is how do you ensure that this
gives<00:33:02.999><c> you</c><00:33:03.119><c> a</c><00:33:03.179><c> global</c><00:33:03.479><c> minimum</c><00:33:03.989><c> instead</c><00:33:04.559><c> of</c><00:33:04.679><c> a</c>

00:33:04.759 --> 00:33:04.769 align:start position:0%
gives you a global minimum instead of a
 

00:33:04.769 --> 00:33:08.810 align:start position:0%
gives you a global minimum instead of a
local<00:33:05.070><c> minimum</c><00:33:05.190><c> right</c><00:33:05.700><c> so</c><00:33:06.769><c> you</c><00:33:07.769><c> don't</c><00:33:08.009><c> we</c><00:33:08.700><c> have</c>

00:33:08.810 --> 00:33:08.820 align:start position:0%
local minimum right so you don't we have
 

00:33:08.820 --> 00:33:10.519 align:start position:0%
local minimum right so you don't we have
no<00:33:08.970><c> guarantees</c><00:33:09.389><c> on</c><00:33:09.629><c> that</c><00:33:09.929><c> this</c><00:33:10.139><c> is</c><00:33:10.320><c> not</c><00:33:10.499><c> a</c>

00:33:10.519 --> 00:33:10.529 align:start position:0%
no guarantees on that this is not a
 

00:33:10.529 --> 00:33:14.269 align:start position:0%
no guarantees on that this is not a
global<00:33:10.859><c> minimum</c><00:33:12.169><c> the</c><00:33:13.169><c> whole</c><00:33:13.409><c> training</c><00:33:14.100><c> of</c>

00:33:14.269 --> 00:33:14.279 align:start position:0%
global minimum the whole training of
 

00:33:14.279 --> 00:33:15.769 align:start position:0%
global minimum the whole training of
stochastic<00:33:14.759><c> gradient</c><00:33:14.820><c> sent</c><00:33:15.210><c> is</c><00:33:15.359><c> a</c><00:33:15.389><c> greedy</c>

00:33:15.769 --> 00:33:15.779 align:start position:0%
stochastic gradient sent is a greedy
 

00:33:15.779 --> 00:33:17.269 align:start position:0%
stochastic gradient sent is a greedy
optimization<00:33:16.470><c> algorithm</c><00:33:16.919><c> so</c><00:33:17.070><c> you're</c><00:33:17.190><c> only</c>

00:33:17.269 --> 00:33:17.279 align:start position:0%
optimization algorithm so you're only
 

00:33:17.279 --> 00:33:18.649 align:start position:0%
optimization algorithm so you're only
taking<00:33:17.700><c> this</c><00:33:17.789><c> greedy</c><00:33:18.059><c> approach</c><00:33:18.210><c> and</c>

00:33:18.649 --> 00:33:18.659 align:start position:0%
taking this greedy approach and
 

00:33:18.659 --> 00:33:21.289 align:start position:0%
taking this greedy approach and
optimizing<00:33:19.350><c> only</c><00:33:19.649><c> a</c><00:33:19.679><c> local</c><00:33:19.859><c> minimum</c><00:33:20.340><c> there</c>

00:33:21.289 --> 00:33:21.299 align:start position:0%
optimizing only a local minimum there
 

00:33:21.299 --> 00:33:23.570 align:start position:0%
optimizing only a local minimum there
are<00:33:21.479><c> different</c><00:33:21.809><c> ways</c><00:33:22.340><c> extensions</c><00:33:23.340><c> of</c>

00:33:23.570 --> 00:33:23.580 align:start position:0%
are different ways extensions of
 

00:33:23.580 --> 00:33:25.129 align:start position:0%
are different ways extensions of
stochastic<00:33:23.879><c> gradient</c><00:33:24.149><c> descent</c><00:33:24.450><c> that</c><00:33:24.840><c> don't</c>

00:33:25.129 --> 00:33:25.139 align:start position:0%
stochastic gradient descent that don't
 

00:33:25.139 --> 00:33:27.560 align:start position:0%
stochastic gradient descent that don't
take<00:33:25.409><c> a</c><00:33:25.619><c> greedy</c><00:33:25.859><c> approach</c><00:33:26.369><c> they</c><00:33:27.210><c> take</c><00:33:27.450><c> an</c>

00:33:27.560 --> 00:33:27.570 align:start position:0%
take a greedy approach they take an
 

00:33:27.570 --> 00:33:29.090 align:start position:0%
take a greedy approach they take an
adaptive<00:33:28.019><c> approach</c><00:33:28.139><c> they</c><00:33:28.499><c> look</c><00:33:28.710><c> around</c><00:33:28.979><c> a</c>

00:33:29.090 --> 00:33:29.100 align:start position:0%
adaptive approach they look around a
 

00:33:29.100 --> 00:33:30.830 align:start position:0%
adaptive approach they look around a
little<00:33:29.220><c> bit</c><00:33:29.460><c> these</c><00:33:30.119><c> are</c><00:33:30.179><c> typically</c><00:33:30.629><c> more</c>

00:33:30.830 --> 00:33:30.840 align:start position:0%
little bit these are typically more
 

00:33:30.840 --> 00:33:33.259 align:start position:0%
little bit these are typically more
expensive<00:33:31.349><c> to</c><00:33:31.499><c> compute</c><00:33:31.999><c> stochastic</c><00:33:32.999><c> gradient</c>

00:33:33.259 --> 00:33:33.269 align:start position:0%
expensive to compute stochastic gradient
 

00:33:33.269 --> 00:33:35.210 align:start position:0%
expensive to compute stochastic gradient
side<00:33:33.629><c> is</c><00:33:33.720><c> extremely</c><00:33:34.259><c> cheap</c><00:33:34.440><c> to</c><00:33:34.649><c> compute</c><00:33:35.009><c> in</c>

00:33:35.210 --> 00:33:35.220 align:start position:0%
side is extremely cheap to compute in
 

00:33:35.220 --> 00:33:37.549 align:start position:0%
side is extremely cheap to compute in
practice<00:33:35.909><c> and</c><00:33:36.149><c> that's</c><00:33:36.989><c> one</c><00:33:37.139><c> of</c><00:33:37.200><c> the</c><00:33:37.289><c> reasons</c>

00:33:37.549 --> 00:33:37.559 align:start position:0%
practice and that's one of the reasons
 

00:33:37.559 --> 00:33:39.710 align:start position:0%
practice and that's one of the reasons
it's<00:33:37.710><c> used</c><00:33:38.009><c> the</c><00:33:38.609><c> second</c><00:33:38.970><c> reason</c><00:33:39.059><c> is</c><00:33:39.330><c> that</c><00:33:39.389><c> in</c>

00:33:39.710 --> 00:33:39.720 align:start position:0%
it's used the second reason is that in
 

00:33:39.720 --> 00:33:42.489 align:start position:0%
it's used the second reason is that in
practice<00:33:40.340><c> local</c><00:33:41.340><c> minimum</c><00:33:41.669><c> tend</c><00:33:41.970><c> to</c><00:33:42.119><c> be</c>

00:33:42.489 --> 00:33:42.499 align:start position:0%
practice local minimum tend to be
 

00:33:42.499 --> 00:33:47.960 align:start position:0%
practice local minimum tend to be
sufficient<00:33:46.309><c> so</c><00:33:47.309><c> that's</c><00:33:47.700><c> the</c><00:33:47.820><c> back</c>

00:33:47.960 --> 00:33:47.970 align:start position:0%
sufficient so that's the back
 

00:33:47.970 --> 00:33:51.440 align:start position:0%
sufficient so that's the back
propagation<00:33:48.359><c> algorithm</c><00:33:49.609><c> in</c><00:33:50.609><c> theory</c><00:33:51.239><c> it</c>

00:33:51.440 --> 00:33:51.450 align:start position:0%
propagation algorithm in theory it
 

00:33:51.450 --> 00:33:52.999 align:start position:0%
propagation algorithm in theory it
sounds<00:33:51.869><c> very</c><00:33:51.960><c> simple</c><00:33:52.289><c> it's</c><00:33:52.679><c> just</c><00:33:52.799><c> an</c>

00:33:52.999 --> 00:33:53.009 align:start position:0%
sounds very simple it's just an
 

00:33:53.009 --> 00:33:55.339 align:start position:0%
sounds very simple it's just an
application<00:33:53.190><c> of</c><00:33:53.639><c> the</c><00:33:53.729><c> chain</c><00:33:53.759><c> rule</c><00:33:54.239><c> but</c><00:33:55.169><c> now</c>

00:33:55.339 --> 00:33:55.349 align:start position:0%
application of the chain rule but now
 

00:33:55.349 --> 00:33:58.159 align:start position:0%
application of the chain rule but now
let's<00:33:55.559><c> touch</c><00:33:55.739><c> on</c><00:33:55.859><c> some</c><00:33:56.099><c> insights</c><00:33:56.549><c> on</c><00:33:57.169><c> training</c>

00:33:58.159 --> 00:33:58.169 align:start position:0%
let's touch on some insights on training
 

00:33:58.169 --> 00:33:59.779 align:start position:0%
let's touch on some insights on training
these<00:33:58.349><c> neural</c><00:33:58.619><c> networks</c><00:33:58.679><c> in</c><00:33:59.129><c> practice</c><00:33:59.609><c> that</c>

00:33:59.779 --> 00:33:59.789 align:start position:0%
these neural networks in practice that
 

00:33:59.789 --> 00:34:01.339 align:start position:0%
these neural networks in practice that
makes<00:33:59.940><c> it</c><00:34:00.090><c> incredibly</c><00:34:00.179><c> complex</c><00:34:00.929><c> and</c><00:34:01.229><c> this</c>

00:34:01.339 --> 00:34:01.349 align:start position:0%
makes it incredibly complex and this
 

00:34:01.349 --> 00:34:02.899 align:start position:0%
makes it incredibly complex and this
gets<00:34:01.529><c> back</c><00:34:01.679><c> to</c><00:34:01.830><c> that</c><00:34:01.859><c> that</c><00:34:02.279><c> previous</c><00:34:02.669><c> point</c>

00:34:02.899 --> 00:34:02.909 align:start position:0%
gets back to that that previous point
 

00:34:02.909 --> 00:34:04.549 align:start position:0%
gets back to that that previous point
that<00:34:03.299><c> previous</c><00:34:03.629><c> question</c><00:34:03.989><c> that</c><00:34:04.229><c> was</c><00:34:04.349><c> raised</c>

00:34:04.549 --> 00:34:04.559 align:start position:0%
that previous question that was raised
 

00:34:04.559 --> 00:34:07.129 align:start position:0%
that previous question that was raised
in<00:34:05.249><c> practice</c><00:34:06.210><c> training</c><00:34:06.389><c> neural</c><00:34:06.720><c> networks</c><00:34:07.019><c> is</c>

00:34:07.129 --> 00:34:07.139 align:start position:0%
in practice training neural networks is
 

00:34:07.139 --> 00:34:08.869 align:start position:0%
in practice training neural networks is
incredibly<00:34:07.679><c> difficult</c><00:34:07.950><c> this</c><00:34:08.669><c> is</c><00:34:08.730><c> a</c>

00:34:08.869 --> 00:34:08.879 align:start position:0%
incredibly difficult this is a
 

00:34:08.879 --> 00:34:11.089 align:start position:0%
incredibly difficult this is a
visualization<00:34:09.240><c> of</c><00:34:09.720><c> the</c><00:34:09.869><c> lost</c><00:34:10.109><c> landscape</c><00:34:10.740><c> of</c><00:34:10.950><c> a</c>

00:34:11.089 --> 00:34:11.099 align:start position:0%
visualization of the lost landscape of a
 

00:34:11.099 --> 00:34:14.389 align:start position:0%
visualization of the lost landscape of a
neural<00:34:11.339><c> network</c><00:34:11.700><c> in</c><00:34:11.909><c> practice</c><00:34:13.220><c> this</c><00:34:14.220><c> is</c><00:34:14.369><c> a</c>

00:34:14.389 --> 00:34:14.399 align:start position:0%
neural network in practice this is a
 

00:34:14.399 --> 00:34:16.250 align:start position:0%
neural network in practice this is a
paper<00:34:14.669><c> from</c><00:34:14.819><c> about</c><00:34:15.119><c> a</c><00:34:15.149><c> year</c><00:34:15.480><c> ago</c><00:34:15.569><c> and</c><00:34:15.960><c> the</c>

00:34:16.250 --> 00:34:16.260 align:start position:0%
paper from about a year ago and the
 

00:34:16.260 --> 00:34:17.720 align:start position:0%
paper from about a year ago and the
authors<00:34:16.559><c> visualize</c><00:34:17.069><c> what</c><00:34:17.339><c> a</c><00:34:17.369><c> deep</c><00:34:17.579><c> neural</c>

00:34:17.720 --> 00:34:17.730 align:start position:0%
authors visualize what a deep neural
 

00:34:17.730 --> 00:34:19.819 align:start position:0%
authors visualize what a deep neural
network<00:34:18.119><c> lost</c><00:34:18.629><c> landscape</c><00:34:19.139><c> really</c><00:34:19.500><c> looks</c><00:34:19.740><c> like</c>

00:34:19.819 --> 00:34:19.829 align:start position:0%
network lost landscape really looks like
 

00:34:19.829 --> 00:34:22.399 align:start position:0%
network lost landscape really looks like
you<00:34:20.309><c> can</c><00:34:20.429><c> see</c><00:34:20.579><c> many</c><00:34:20.849><c> many</c><00:34:21.179><c> many</c><00:34:21.569><c> local</c><00:34:22.079><c> minimum</c>

00:34:22.399 --> 00:34:22.409 align:start position:0%
you can see many many many local minimum
 

00:34:22.409 --> 00:34:24.829 align:start position:0%
you can see many many many local minimum
here<00:34:22.649><c> lot</c><00:34:23.609><c> minimizing</c><00:34:24.389><c> this</c><00:34:24.569><c> loss</c><00:34:24.809><c> and</c>

00:34:24.829 --> 00:34:24.839 align:start position:0%
here lot minimizing this loss and
 

00:34:24.839 --> 00:34:26.960 align:start position:0%
here lot minimizing this loss and
finally<00:34:25.319><c> the</c><00:34:25.440><c> optimal</c><00:34:25.919><c> true</c><00:34:26.280><c> minimum</c><00:34:26.669><c> is</c>

00:34:26.960 --> 00:34:26.970 align:start position:0%
finally the optimal true minimum is
 

00:34:26.970 --> 00:34:29.829 align:start position:0%
finally the optimal true minimum is
extremely<00:34:27.899><c> difficult</c>

00:34:29.829 --> 00:34:29.839 align:start position:0%
extremely difficult
 

00:34:29.839 --> 00:34:32.539 align:start position:0%
extremely difficult
now<00:34:30.839><c> recall</c><00:34:31.139><c> the</c><00:34:31.349><c> update</c><00:34:31.980><c> equation</c><00:34:32.339><c> that</c><00:34:32.460><c> we</c>

00:34:32.539 --> 00:34:32.549 align:start position:0%
now recall the update equation that we
 

00:34:32.549 --> 00:34:34.250 align:start position:0%
now recall the update equation that we
fought<00:34:32.760><c> defined</c><00:34:33.270><c> for</c><00:34:33.540><c> a</c><00:34:33.569><c> gradient</c><00:34:33.809><c> descent</c>

00:34:34.250 --> 00:34:34.260 align:start position:0%
fought defined for a gradient descent
 

00:34:34.260 --> 00:34:36.829 align:start position:0%
fought defined for a gradient descent
previously<00:34:34.799><c> we</c><00:34:35.190><c> take</c><00:34:35.399><c> our</c><00:34:35.579><c> weights</c><00:34:35.819><c> and</c><00:34:36.149><c> we</c>

00:34:36.829 --> 00:34:36.839 align:start position:0%
previously we take our weights and we
 

00:34:36.839 --> 00:34:40.280 align:start position:0%
previously we take our weights and we
subtract<00:34:37.379><c> we</c><00:34:38.309><c> move</c><00:34:38.549><c> towards</c><00:34:39.109><c> the</c><00:34:40.109><c> negative</c>

00:34:40.280 --> 00:34:40.290 align:start position:0%
subtract we move towards the negative
 

00:34:40.290 --> 00:34:41.899 align:start position:0%
subtract we move towards the negative
gradient<00:34:40.710><c> and</c><00:34:41.129><c> we</c><00:34:41.190><c> update</c><00:34:41.490><c> our</c><00:34:41.520><c> weights</c><00:34:41.790><c> in</c>

00:34:41.899 --> 00:34:41.909 align:start position:0%
gradient and we update our weights in
 

00:34:41.909 --> 00:34:46.490 align:start position:0%
gradient and we update our weights in
that<00:34:42.030><c> direction</c><00:34:42.210><c> I</c><00:34:45.139><c> didn't</c><00:34:46.139><c> talk</c><00:34:46.200><c> too</c><00:34:46.379><c> much</c>

00:34:46.490 --> 00:34:46.500 align:start position:0%
that direction I didn't talk too much
 

00:34:46.500 --> 00:34:48.980 align:start position:0%
that direction I didn't talk too much
about<00:34:46.559><c> this</c><00:34:46.859><c> parameter</c><00:34:47.399><c> heydo</c><00:34:47.750><c> this</c><00:34:48.750><c> is</c><00:34:48.869><c> what</c>

00:34:48.980 --> 00:34:48.990 align:start position:0%
about this parameter heydo this is what
 

00:34:48.990 --> 00:34:50.359 align:start position:0%
about this parameter heydo this is what
we<00:34:49.079><c> called</c><00:34:49.349><c> the</c><00:34:49.530><c> learning</c><00:34:49.710><c> rate</c><00:34:49.859><c> I</c><00:34:50.129><c> briefly</c>

00:34:50.359 --> 00:34:50.369 align:start position:0%
we called the learning rate I briefly
 

00:34:50.369 --> 00:34:52.339 align:start position:0%
we called the learning rate I briefly
touched<00:34:50.669><c> on</c><00:34:50.940><c> it</c><00:34:51.119><c> and</c><00:34:51.270><c> this</c><00:34:51.899><c> is</c><00:34:51.960><c> essentially</c>

00:34:52.339 --> 00:34:52.349 align:start position:0%
touched on it and this is essentially
 

00:34:52.349 --> 00:34:54.770 align:start position:0%
touched on it and this is essentially
determining<00:34:53.040><c> how</c><00:34:53.280><c> large</c><00:34:53.760><c> of</c><00:34:53.970><c> a</c><00:34:54.089><c> step</c><00:34:54.329><c> we</c><00:34:54.510><c> take</c>

00:34:54.770 --> 00:34:54.780 align:start position:0%
determining how large of a step we take
 

00:34:54.780 --> 00:34:57.890 align:start position:0%
determining how large of a step we take
at<00:34:55.020><c> each</c><00:34:55.260><c> iteration</c><00:34:55.559><c> in</c><00:34:56.569><c> practice</c><00:34:57.569><c> setting</c>

00:34:57.890 --> 00:34:57.900 align:start position:0%
at each iteration in practice setting
 

00:34:57.900 --> 00:34:59.120 align:start position:0%
at each iteration in practice setting
the<00:34:57.990><c> learning</c><00:34:58.290><c> rate</c><00:34:58.410><c> can</c><00:34:58.619><c> be</c><00:34:58.710><c> extremely</c>

00:34:59.120 --> 00:34:59.130 align:start position:0%
the learning rate can be extremely
 

00:34:59.130 --> 00:35:01.339 align:start position:0%
the learning rate can be extremely
difficult<00:34:59.369><c> and</c><00:34:59.970><c> actually</c><00:35:00.540><c> very</c><00:35:00.809><c> important</c>

00:35:01.339 --> 00:35:01.349 align:start position:0%
difficult and actually very important
 

00:35:01.349 --> 00:35:03.380 align:start position:0%
difficult and actually very important
for<00:35:01.440><c> making</c><00:35:02.010><c> sure</c><00:35:02.130><c> that</c><00:35:02.280><c> you</c><00:35:02.400><c> avoid</c><00:35:02.549><c> local</c>

00:35:03.380 --> 00:35:03.390 align:start position:0%
for making sure that you avoid local
 

00:35:03.390 --> 00:35:06.650 align:start position:0%
for making sure that you avoid local
minima<00:35:03.750><c> again</c><00:35:04.790><c> so</c><00:35:05.790><c> if</c><00:35:05.970><c> we</c><00:35:06.119><c> set</c><00:35:06.299><c> the</c><00:35:06.420><c> learning</c>

00:35:06.650 --> 00:35:06.660 align:start position:0%
minima again so if we set the learning
 

00:35:06.660 --> 00:35:08.480 align:start position:0%
minima again so if we set the learning
rate<00:35:06.779><c> to</c><00:35:07.020><c> slow</c><00:35:07.410><c> then</c><00:35:07.799><c> the</c><00:35:07.920><c> model</c><00:35:08.220><c> may</c><00:35:08.339><c> get</c>

00:35:08.480 --> 00:35:08.490 align:start position:0%
rate to slow then the model may get
 

00:35:08.490 --> 00:35:10.050 align:start position:0%
rate to slow then the model may get
stuck<00:35:08.819><c> in</c><00:35:09.000><c> local</c><00:35:09.029><c> minimum</c><00:35:09.660><c> like</c>

00:35:10.050 --> 00:35:10.060 align:start position:0%
stuck in local minimum like
 

00:35:10.060 --> 00:35:12.270 align:start position:0%
stuck in local minimum like
this<00:35:10.180><c> it</c><00:35:10.750><c> could</c><00:35:10.960><c> also</c><00:35:11.200><c> converge</c><00:35:11.680><c> very</c><00:35:11.710><c> slowly</c>

00:35:12.270 --> 00:35:12.280 align:start position:0%
this it could also converge very slowly
 

00:35:12.280 --> 00:35:13.680 align:start position:0%
this it could also converge very slowly
even<00:35:12.760><c> in</c><00:35:12.880><c> the</c><00:35:12.970><c> case</c><00:35:13.120><c> that</c><00:35:13.150><c> it</c><00:35:13.360><c> gets</c><00:35:13.510><c> to</c><00:35:13.570><c> a</c>

00:35:13.680 --> 00:35:13.690 align:start position:0%
even in the case that it gets to a
 

00:35:13.690 --> 00:35:16.320 align:start position:0%
even in the case that it gets to a
global<00:35:14.050><c> minimum</c><00:35:14.350><c> if</c><00:35:14.830><c> we</c><00:35:15.790><c> set</c><00:35:15.970><c> the</c><00:35:16.090><c> learning</c>

00:35:16.320 --> 00:35:16.330 align:start position:0%
global minimum if we set the learning
 

00:35:16.330 --> 00:35:19.260 align:start position:0%
global minimum if we set the learning
rate<00:35:16.450><c> too</c><00:35:16.630><c> large</c><00:35:17.430><c> the</c><00:35:18.430><c> gradients</c><00:35:18.790><c> essentially</c>

00:35:19.260 --> 00:35:19.270 align:start position:0%
rate too large the gradients essentially
 

00:35:19.270 --> 00:35:21.510 align:start position:0%
rate too large the gradients essentially
explodes<00:35:19.900><c> and</c><00:35:20.110><c> we</c><00:35:20.260><c> diverge</c><00:35:20.740><c> from</c><00:35:21.160><c> the</c><00:35:21.250><c> loss</c>

00:35:21.510 --> 00:35:21.520 align:start position:0%
explodes and we diverge from the loss
 

00:35:21.520 --> 00:35:24.750 align:start position:0%
explodes and we diverge from the loss
itself<00:35:21.910><c> and</c><00:35:22.600><c> it's</c><00:35:22.720><c> also</c><00:35:22.870><c> been</c><00:35:23.670><c> setting</c><00:35:24.670><c> the</c>

00:35:24.750 --> 00:35:24.760 align:start position:0%
itself and it's also been setting the
 

00:35:24.760 --> 00:35:26.760 align:start position:0%
itself and it's also been setting the
learning<00:35:25.060><c> rate</c><00:35:25.180><c> to</c><00:35:25.360><c> the</c><00:35:25.390><c> correct</c><00:35:25.810><c> amount</c><00:35:25.960><c> can</c>

00:35:26.760 --> 00:35:26.770 align:start position:0%
learning rate to the correct amount can
 

00:35:26.770 --> 00:35:28.620 align:start position:0%
learning rate to the correct amount can
be<00:35:26.800><c> extremely</c><00:35:27.310><c> tedious</c><00:35:27.610><c> in</c><00:35:28.030><c> practice</c><00:35:28.450><c> such</c>

00:35:28.620 --> 00:35:28.630 align:start position:0%
be extremely tedious in practice such
 

00:35:28.630 --> 00:35:30.180 align:start position:0%
be extremely tedious in practice such
that<00:35:28.810><c> we</c><00:35:28.930><c> overshoot</c><00:35:29.440><c> some</c><00:35:29.680><c> of</c><00:35:29.770><c> the</c><00:35:29.860><c> local</c>

00:35:30.180 --> 00:35:30.190 align:start position:0%
that we overshoot some of the local
 

00:35:30.190 --> 00:35:32.820 align:start position:0%
that we overshoot some of the local
minima<00:35:30.550><c> get</c><00:35:31.330><c> ourselves</c><00:35:31.480><c> into</c><00:35:31.930><c> a</c><00:35:32.110><c> reasonable</c>

00:35:32.820 --> 00:35:32.830 align:start position:0%
minima get ourselves into a reasonable
 

00:35:32.830 --> 00:35:35.190 align:start position:0%
minima get ourselves into a reasonable
local<00:35:33.220><c> global</c><00:35:33.580><c> minima</c><00:35:33.940><c> and</c><00:35:34.120><c> then</c><00:35:34.480><c> converge</c><00:35:34.960><c> in</c>

00:35:35.190 --> 00:35:35.200 align:start position:0%
local global minima and then converge in
 

00:35:35.200 --> 00:35:40.260 align:start position:0%
local global minima and then converge in
within<00:35:35.740><c> that</c><00:35:36.010><c> global</c><00:35:36.340><c> minima</c><00:35:38.520><c> how</c><00:35:39.520><c> can</c><00:35:39.700><c> we</c><00:35:39.790><c> do</c>

00:35:40.260 --> 00:35:40.270 align:start position:0%
within that global minima how can we do
 

00:35:40.270 --> 00:35:43.050 align:start position:0%
within that global minima how can we do
this<00:35:40.450><c> in</c><00:35:40.630><c> a</c><00:35:40.720><c> clever</c><00:35:40.930><c> way</c><00:35:41.080><c> so</c><00:35:42.010><c> one</c><00:35:42.340><c> option</c><00:35:42.550><c> is</c>

00:35:43.050 --> 00:35:43.060 align:start position:0%
this in a clever way so one option is
 

00:35:43.060 --> 00:35:45.150 align:start position:0%
this in a clever way so one option is
that<00:35:43.450><c> we</c><00:35:43.840><c> can</c><00:35:44.020><c> try</c><00:35:44.320><c> a</c><00:35:44.350><c> lot</c><00:35:44.740><c> of</c><00:35:44.800><c> different</c>

00:35:45.150 --> 00:35:45.160 align:start position:0%
that we can try a lot of different
 

00:35:45.160 --> 00:35:47.340 align:start position:0%
that we can try a lot of different
possible<00:35:46.090><c> learning</c><00:35:46.270><c> rates</c><00:35:46.570><c> see</c><00:35:46.960><c> what</c><00:35:47.140><c> works</c>

00:35:47.340 --> 00:35:47.350 align:start position:0%
possible learning rates see what works
 

00:35:47.350 --> 00:35:51.390 align:start position:0%
possible learning rates see what works
best<00:35:47.500><c> in</c><00:35:47.920><c> practice</c><00:35:48.340><c> and</c><00:35:49.260><c> in</c><00:35:50.260><c> practice</c><00:35:50.800><c> this</c><00:35:51.220><c> is</c>

00:35:51.390 --> 00:35:51.400 align:start position:0%
best in practice and in practice this is
 

00:35:51.400 --> 00:35:53.100 align:start position:0%
best in practice and in practice this is
actually<00:35:51.790><c> a</c><00:35:51.820><c> very</c><00:35:52.030><c> common</c><00:35:52.090><c> technique</c><00:35:52.510><c> so</c><00:35:52.930><c> a</c>

00:35:53.100 --> 00:35:53.110 align:start position:0%
actually a very common technique so a
 

00:35:53.110 --> 00:35:55.200 align:start position:0%
actually a very common technique so a
lot<00:35:53.530><c> of</c><00:35:53.650><c> people</c><00:35:53.950><c> just</c><00:35:53.980><c> try</c><00:35:54.520><c> a</c><00:35:54.550><c> lot</c><00:35:54.790><c> of</c><00:35:54.820><c> learning</c>

00:35:55.200 --> 00:35:55.210 align:start position:0%
lot of people just try a lot of learning
 

00:35:55.210 --> 00:35:57.540 align:start position:0%
lot of people just try a lot of learning
rates<00:35:55.390><c> and</c><00:35:55.600><c> see</c><00:35:55.960><c> what</c><00:35:56.110><c> works</c><00:35:56.410><c> best</c><00:35:56.530><c> let's</c><00:35:57.430><c> see</c>

00:35:57.540 --> 00:35:57.550 align:start position:0%
rates and see what works best let's see
 

00:35:57.550 --> 00:35:59.010 align:start position:0%
rates and see what works best let's see
if<00:35:57.640><c> we</c><00:35:57.760><c> can</c><00:35:57.910><c> do</c><00:35:58.240><c> something</c><00:35:58.600><c> a</c><00:35:58.630><c> bit</c><00:35:58.660><c> smarter</c>

00:35:59.010 --> 00:35:59.020 align:start position:0%
if we can do something a bit smarter
 

00:35:59.020 --> 00:36:01.500 align:start position:0%
if we can do something a bit smarter
than<00:35:59.290><c> that</c><00:35:59.350><c> as</c><00:35:59.620><c> well</c><00:35:59.770><c> how</c><00:36:00.550><c> about</c><00:36:00.640><c> we</c><00:36:00.850><c> design</c><00:36:01.300><c> an</c>

00:36:01.500 --> 00:36:01.510 align:start position:0%
than that as well how about we design an
 

00:36:01.510 --> 00:36:05.160 align:start position:0%
than that as well how about we design an
adaptive<00:36:02.050><c> algorithm</c><00:36:02.730><c> that</c><00:36:03.730><c> learnt</c><00:36:04.390><c> that</c><00:36:04.690><c> you</c>

00:36:05.160 --> 00:36:05.170 align:start position:0%
adaptive algorithm that learnt that you
 

00:36:05.170 --> 00:36:07.890 align:start position:0%
adaptive algorithm that learnt that you
that<00:36:05.530><c> adapts</c><00:36:06.310><c> its</c><00:36:06.460><c> learning</c><00:36:06.730><c> rate</c><00:36:07.060><c> according</c>

00:36:07.890 --> 00:36:07.900 align:start position:0%
that adapts its learning rate according
 

00:36:07.900 --> 00:36:10.590 align:start position:0%
that adapts its learning rate according
to<00:36:08.020><c> the</c><00:36:08.110><c> lost</c><00:36:08.290><c> landscape</c><00:36:08.830><c> so</c><00:36:09.460><c> this</c><00:36:09.880><c> can</c><00:36:10.090><c> take</c>

00:36:10.590 --> 00:36:10.600 align:start position:0%
to the lost landscape so this can take
 

00:36:10.600 --> 00:36:13.230 align:start position:0%
to the lost landscape so this can take
into<00:36:10.810><c> account</c><00:36:11.140><c> the</c><00:36:11.950><c> gradient</c><00:36:12.430><c> at</c><00:36:12.730><c> other</c>

00:36:13.230 --> 00:36:13.240 align:start position:0%
into account the gradient at other
 

00:36:13.240 --> 00:36:16.080 align:start position:0%
into account the gradient at other
locations<00:36:13.450><c> and</c><00:36:14.110><c> loss</c><00:36:14.410><c> it</c><00:36:15.280><c> can</c><00:36:15.550><c> take</c><00:36:15.910><c> into</c>

00:36:16.080 --> 00:36:16.090 align:start position:0%
locations and loss it can take into
 

00:36:16.090 --> 00:36:18.810 align:start position:0%
locations and loss it can take into
account<00:36:16.330><c> how</c><00:36:16.600><c> fast</c><00:36:16.930><c> we're</c><00:36:17.170><c> learning</c><00:36:17.410><c> how</c><00:36:18.310><c> how</c>

00:36:18.810 --> 00:36:18.820 align:start position:0%
account how fast we're learning how how
 

00:36:18.820 --> 00:36:20.550 align:start position:0%
account how fast we're learning how how
large<00:36:19.150><c> the</c><00:36:19.420><c> gradient</c><00:36:19.780><c> is</c><00:36:19.870><c> at</c><00:36:20.050><c> that</c><00:36:20.200><c> location</c>

00:36:20.550 --> 00:36:20.560 align:start position:0%
large the gradient is at that location
 

00:36:20.560 --> 00:36:23.460 align:start position:0%
large the gradient is at that location
or<00:36:20.920><c> many</c><00:36:21.700><c> other</c><00:36:21.850><c> options</c><00:36:22.090><c> but</c><00:36:22.930><c> now</c><00:36:23.080><c> since</c><00:36:23.140><c> our</c>

00:36:23.460 --> 00:36:23.470 align:start position:0%
or many other options but now since our
 

00:36:23.470 --> 00:36:25.290 align:start position:0%
or many other options but now since our
learning<00:36:23.740><c> rate</c><00:36:23.890><c> is</c><00:36:23.920><c> not</c><00:36:24.130><c> fixed</c><00:36:24.700><c> for</c><00:36:24.940><c> all</c><00:36:25.090><c> of</c>

00:36:25.290 --> 00:36:25.300 align:start position:0%
learning rate is not fixed for all of
 

00:36:25.300 --> 00:36:28.140 align:start position:0%
learning rate is not fixed for all of
the<00:36:25.920><c> iterations</c><00:36:26.920><c> of</c><00:36:27.040><c> gradient</c><00:36:27.100><c> descent</c><00:36:27.490><c> we</c>

00:36:28.140 --> 00:36:28.150 align:start position:0%
the iterations of gradient descent we
 

00:36:28.150 --> 00:36:29.670 align:start position:0%
the iterations of gradient descent we
have<00:36:28.270><c> a</c><00:36:28.300><c> bit</c><00:36:28.510><c> more</c><00:36:28.660><c> flexibility</c><00:36:29.260><c> now</c><00:36:29.440><c> in</c>

00:36:29.670 --> 00:36:29.680 align:start position:0%
have a bit more flexibility now in
 

00:36:29.680 --> 00:36:33.090 align:start position:0%
have a bit more flexibility now in
learning<00:36:30.090><c> in</c><00:36:31.110><c> fact</c><00:36:32.110><c> this</c><00:36:32.530><c> has</c><00:36:32.680><c> been</c><00:36:32.710><c> widely</c>

00:36:33.090 --> 00:36:33.100 align:start position:0%
learning in fact this has been widely
 

00:36:33.100 --> 00:36:34.800 align:start position:0%
learning in fact this has been widely
studied<00:36:33.310><c> as</c><00:36:33.730><c> well</c><00:36:33.940><c> there</c><00:36:34.390><c> are</c><00:36:34.420><c> many</c><00:36:34.540><c> many</c>

00:36:34.800 --> 00:36:34.810 align:start position:0%
studied as well there are many many
 

00:36:34.810 --> 00:36:36.630 align:start position:0%
studied as well there are many many
different<00:36:35.110><c> options</c><00:36:35.920><c> for</c><00:36:36.160><c> optimization</c>

00:36:36.630 --> 00:36:36.640 align:start position:0%
different options for optimization
 

00:36:36.640 --> 00:36:38.700 align:start position:0%
different options for optimization
schemes<00:36:37.150><c> that</c><00:36:37.540><c> are</c><00:36:37.660><c> present</c><00:36:38.080><c> in</c><00:36:38.230><c> tensorflow</c>

00:36:38.700 --> 00:36:38.710 align:start position:0%
schemes that are present in tensorflow
 

00:36:38.710 --> 00:36:41.220 align:start position:0%
schemes that are present in tensorflow
and<00:36:39.150><c> here</c><00:36:40.150><c> are</c><00:36:40.240><c> examples</c><00:36:40.480><c> of</c><00:36:40.780><c> some</c><00:36:40.990><c> of</c><00:36:41.080><c> them</c>

00:36:41.220 --> 00:36:41.230 align:start position:0%
and here are examples of some of them
 

00:36:41.230 --> 00:36:43.200 align:start position:0%
and here are examples of some of them
during<00:36:41.860><c> your</c><00:36:41.950><c> labs</c><00:36:42.220><c> I</c><00:36:42.340><c> encourage</c><00:36:42.670><c> you</c><00:36:42.790><c> to</c><00:36:42.820><c> try</c>

00:36:43.200 --> 00:36:43.210 align:start position:0%
during your labs I encourage you to try
 

00:36:43.210 --> 00:36:45.330 align:start position:0%
during your labs I encourage you to try
out<00:36:43.420><c> different</c><00:36:43.450><c> of</c><00:36:44.080><c> these</c><00:36:44.230><c> different</c><00:36:45.070><c> ones</c><00:36:45.220><c> of</c>

00:36:45.330 --> 00:36:45.340 align:start position:0%
out different of these different ones of
 

00:36:45.340 --> 00:36:47.850 align:start position:0%
out different of these different ones of
these<00:36:45.490><c> optimizers</c><00:36:46.210><c> and</c><00:36:46.450><c> see</c><00:36:47.110><c> how</c><00:36:47.680><c> they're</c>

00:36:47.850 --> 00:36:47.860 align:start position:0%
these optimizers and see how they're
 

00:36:47.860 --> 00:36:49.920 align:start position:0%
these optimizers and see how they're
different<00:36:48.010><c> which</c><00:36:48.580><c> works</c><00:36:48.910><c> best</c><00:36:49.180><c> which</c><00:36:49.420><c> doesn't</c>

00:36:49.920 --> 00:36:49.930 align:start position:0%
different which works best which doesn't
 

00:36:49.930 --> 00:36:51.720 align:start position:0%
different which works best which doesn't
work<00:36:50.050><c> so</c><00:36:50.260><c> well</c><00:36:50.410><c> for</c><00:36:50.470><c> your</c><00:36:50.800><c> particular</c><00:36:51.190><c> problem</c>

00:36:51.720 --> 00:36:51.730 align:start position:0%
work so well for your particular problem
 

00:36:51.730 --> 00:36:57.420 align:start position:0%
work so well for your particular problem
and<00:36:52.480><c> they're</c><00:36:52.720><c> all</c><00:36:52.870><c> adaptive</c><00:36:53.440><c> in</c><00:36:53.560><c> nature</c><00:36:56.430><c> so</c>

00:36:57.420 --> 00:36:57.430 align:start position:0%
and they're all adaptive in nature so
 

00:36:57.430 --> 00:36:58.800 align:start position:0%
and they're all adaptive in nature so
now<00:36:57.550><c> I</c><00:36:57.580><c> want</c><00:36:57.880><c> to</c><00:36:57.940><c> continue</c><00:36:58.120><c> talking</c><00:36:58.540><c> about</c>

00:36:58.800 --> 00:36:58.810 align:start position:0%
now I want to continue talking about
 

00:36:58.810 --> 00:37:00.990 align:start position:0%
now I want to continue talking about
tips<00:36:59.110><c> for</c><00:36:59.230><c> training</c><00:36:59.740><c> these</c><00:37:00.250><c> networks</c><00:37:00.700><c> in</c>

00:37:00.990 --> 00:37:01.000 align:start position:0%
tips for training these networks in
 

00:37:01.000 --> 00:37:03.660 align:start position:0%
tips for training these networks in
practice<00:37:01.480><c> and</c><00:37:01.690><c> focus</c><00:37:01.870><c> on</c><00:37:02.290><c> the</c><00:37:02.920><c> very</c><00:37:03.100><c> powerful</c>

00:37:03.660 --> 00:37:03.670 align:start position:0%
practice and focus on the very powerful
 

00:37:03.670 --> 00:37:06.410 align:start position:0%
practice and focus on the very powerful
idea<00:37:04.090><c> of</c><00:37:04.360><c> batching</c><00:37:05.260><c> gradient</c><00:37:05.830><c> descent</c><00:37:06.130><c> and</c>

00:37:06.410 --> 00:37:06.420 align:start position:0%
idea of batching gradient descent and
 

00:37:06.420 --> 00:37:10.170 align:start position:0%
idea of batching gradient descent and
batching<00:37:07.420><c> your</c><00:37:07.570><c> data</c><00:37:07.780><c> in</c><00:37:08.050><c> general</c><00:37:08.850><c> so</c><00:37:09.850><c> to</c><00:37:09.910><c> do</c>

00:37:10.170 --> 00:37:10.180 align:start position:0%
batching your data in general so to do
 

00:37:10.180 --> 00:37:12.870 align:start position:0%
batching your data in general so to do
this<00:37:10.360><c> let's</c><00:37:10.840><c> revisit</c><00:37:11.290><c> this</c><00:37:11.650><c> idea</c><00:37:11.800><c> of</c><00:37:12.220><c> gradient</c>

00:37:12.870 --> 00:37:12.880 align:start position:0%
this let's revisit this idea of gradient
 

00:37:12.880 --> 00:37:16.140 align:start position:0%
this let's revisit this idea of gradient
descent<00:37:13.350><c> very</c><00:37:14.350><c> quickly</c><00:37:14.590><c> so</c><00:37:14.920><c> the</c><00:37:15.700><c> gradient</c><00:37:15.940><c> is</c>

00:37:16.140 --> 00:37:16.150 align:start position:0%
descent very quickly so the gradient is
 

00:37:16.150 --> 00:37:18.270 align:start position:0%
descent very quickly so the gradient is
actually<00:37:16.300><c> very</c><00:37:16.810><c> computational</c><00:37:17.740><c> to</c><00:37:17.890><c> compute</c>

00:37:18.270 --> 00:37:18.280 align:start position:0%
actually very computational to compute
 

00:37:18.280 --> 00:37:20.190 align:start position:0%
actually very computational to compute
this<00:37:18.460><c> back</c><00:37:18.670><c> propagation</c><00:37:19.150><c> algorithm</c><00:37:19.600><c> if</c><00:37:19.990><c> you</c>

00:37:20.190 --> 00:37:20.200 align:start position:0%
this back propagation algorithm if you
 

00:37:20.200 --> 00:37:21.600 align:start position:0%
this back propagation algorithm if you
want<00:37:20.350><c> to</c><00:37:20.410><c> compute</c><00:37:20.710><c> it</c><00:37:20.800><c> for</c><00:37:20.830><c> all</c><00:37:21.130><c> of</c><00:37:21.160><c> the</c><00:37:21.460><c> data</c>

00:37:21.600 --> 00:37:21.610 align:start position:0%
want to compute it for all of the data
 

00:37:21.610 --> 00:37:23.340 align:start position:0%
want to compute it for all of the data
samples<00:37:22.150><c> in</c><00:37:22.300><c> your</c><00:37:22.330><c> training</c><00:37:22.690><c> data</c><00:37:22.960><c> set</c><00:37:23.200><c> which</c>

00:37:23.340 --> 00:37:23.350 align:start position:0%
samples in your training data set which
 

00:37:23.350 --> 00:37:23.910 align:start position:0%
samples in your training data set which
may<00:37:23.530><c> be</c>

00:37:23.910 --> 00:37:23.920 align:start position:0%
may be
 

00:37:23.920 --> 00:37:26.609 align:start position:0%
may be
massive<00:37:24.220><c> in</c><00:37:24.400><c> modern</c><00:37:25.059><c> data</c><00:37:25.270><c> sets</c><00:37:25.619><c> it's</c>

00:37:26.609 --> 00:37:26.619 align:start position:0%
massive in modern data sets it's
 

00:37:26.619 --> 00:37:28.710 align:start position:0%
massive in modern data sets it's
essentially<00:37:27.520><c> amounting</c><00:37:27.970><c> to</c><00:37:28.000><c> a</c><00:37:28.180><c> summation</c>

00:37:28.710 --> 00:37:28.720 align:start position:0%
essentially amounting to a summation
 

00:37:28.720 --> 00:37:32.010 align:start position:0%
essentially amounting to a summation
over<00:37:29.079><c> all</c><00:37:29.680><c> of</c><00:37:29.859><c> these</c><00:37:30.010><c> data</c><00:37:30.220><c> points</c><00:37:30.579><c> in</c><00:37:31.020><c> most</c>

00:37:32.010 --> 00:37:32.020 align:start position:0%
over all of these data points in most
 

00:37:32.020 --> 00:37:34.109 align:start position:0%
over all of these data points in most
real<00:37:32.260><c> life</c><00:37:32.440><c> problems</c><00:37:32.950><c> this</c><00:37:33.339><c> is</c><00:37:33.520><c> extremely</c>

00:37:34.109 --> 00:37:34.119 align:start position:0%
real life problems this is extremely
 

00:37:34.119 --> 00:37:35.760 align:start position:0%
real life problems this is extremely
computational<00:37:34.869><c> and</c><00:37:35.020><c> not</c><00:37:35.170><c> feasible</c><00:37:35.619><c> to</c>

00:37:35.760 --> 00:37:35.770 align:start position:0%
computational and not feasible to
 

00:37:35.770 --> 00:37:38.630 align:start position:0%
computational and not feasible to
compute<00:37:36.130><c> on</c><00:37:36.250><c> every</c><00:37:36.520><c> iteration</c><00:37:36.930><c> so</c><00:37:37.930><c> instead</c>

00:37:38.630 --> 00:37:38.640 align:start position:0%
compute on every iteration so instead
 

00:37:38.640 --> 00:37:41.069 align:start position:0%
compute on every iteration so instead
people<00:37:39.640><c> have</c><00:37:39.849><c> come</c><00:37:40.030><c> up</c><00:37:40.059><c> with</c><00:37:40.210><c> this</c><00:37:40.420><c> idea</c><00:37:40.599><c> of</c>

00:37:41.069 --> 00:37:41.079 align:start position:0%
people have come up with this idea of
 

00:37:41.079 --> 00:37:42.839 align:start position:0%
people have come up with this idea of
stochastic<00:37:41.559><c> gradient</c><00:37:41.950><c> descent</c><00:37:42.280><c> and</c><00:37:42.760><c> that</c>

00:37:42.839 --> 00:37:42.849 align:start position:0%
stochastic gradient descent and that
 

00:37:42.849 --> 00:37:44.970 align:start position:0%
stochastic gradient descent and that
involves<00:37:43.240><c> picking</c><00:37:43.540><c> a</c><00:37:43.809><c> single</c><00:37:44.290><c> point</c><00:37:44.589><c> in</c><00:37:44.859><c> your</c>

00:37:44.970 --> 00:37:44.980 align:start position:0%
involves picking a single point in your
 

00:37:44.980 --> 00:37:47.190 align:start position:0%
involves picking a single point in your
data<00:37:45.160><c> set</c><00:37:45.430><c> computing</c><00:37:46.420><c> the</c><00:37:46.599><c> gradient</c><00:37:46.630><c> with</c>

00:37:47.190 --> 00:37:47.200 align:start position:0%
data set computing the gradient with
 

00:37:47.200 --> 00:37:49.799 align:start position:0%
data set computing the gradient with
respect<00:37:47.230><c> to</c><00:37:47.619><c> that</c><00:37:47.829><c> point</c><00:37:48.130><c> and</c><00:37:48.480><c> then</c><00:37:49.480><c> using</c>

00:37:49.799 --> 00:37:49.809 align:start position:0%
respect to that point and then using
 

00:37:49.809 --> 00:37:51.690 align:start position:0%
respect to that point and then using
that<00:37:49.839><c> to</c><00:37:49.990><c> update</c><00:37:50.260><c> your</c><00:37:50.559><c> grade</c><00:37:50.799><c> to</c><00:37:51.040><c> update</c><00:37:51.460><c> your</c>

00:37:51.690 --> 00:37:51.700 align:start position:0%
that to update your grade to update your
 

00:37:51.700 --> 00:37:55.109 align:start position:0%
that to update your grade to update your
your<00:37:52.119><c> weights</c><00:37:53.579><c> so</c><00:37:54.579><c> this</c><00:37:54.730><c> is</c><00:37:54.880><c> great</c><00:37:55.089><c> because</c>

00:37:55.109 --> 00:37:55.119 align:start position:0%
your weights so this is great because
 

00:37:55.119 --> 00:37:57.180 align:start position:0%
your weights so this is great because
now<00:37:55.390><c> computing</c><00:37:56.260><c> a</c><00:37:56.319><c> gradient</c><00:37:56.530><c> of</c><00:37:56.829><c> a</c><00:37:56.920><c> single</c>

00:37:57.180 --> 00:37:57.190 align:start position:0%
now computing a gradient of a single
 

00:37:57.190 --> 00:37:58.589 align:start position:0%
now computing a gradient of a single
point<00:37:57.309><c> is</c><00:37:57.490><c> much</c><00:37:57.670><c> easier</c><00:37:58.000><c> than</c><00:37:58.059><c> computing</c><00:37:58.510><c> the</c>

00:37:58.589 --> 00:37:58.599 align:start position:0%
point is much easier than computing the
 

00:37:58.599 --> 00:38:01.799 align:start position:0%
point is much easier than computing the
gradient<00:37:58.630><c> over</c><00:37:59.530><c> many</c><00:37:59.799><c> points</c><00:38:00.510><c> but</c><00:38:01.510><c> at</c><00:38:01.690><c> the</c>

00:38:01.799 --> 00:38:01.809 align:start position:0%
gradient over many points but at the
 

00:38:01.809 --> 00:38:03.180 align:start position:0%
gradient over many points but at the
same<00:38:01.960><c> time</c><00:38:02.200><c> since</c><00:38:02.500><c> we're</c><00:38:02.680><c> only</c><00:38:02.770><c> looking</c><00:38:03.010><c> at</c>

00:38:03.180 --> 00:38:03.190 align:start position:0%
same time since we're only looking at
 

00:38:03.190 --> 00:38:05.329 align:start position:0%
same time since we're only looking at
one<00:38:03.280><c> point</c><00:38:03.670><c> this</c><00:38:04.030><c> can</c><00:38:04.210><c> be</c><00:38:04.329><c> extremely</c><00:38:04.660><c> noisy</c>

00:38:05.329 --> 00:38:05.339 align:start position:0%
one point this can be extremely noisy
 

00:38:05.339 --> 00:38:07.740 align:start position:0%
one point this can be extremely noisy
sure<00:38:06.339><c> we</c><00:38:06.490><c> take</c><00:38:06.670><c> a</c><00:38:06.730><c> different</c><00:38:06.940><c> point</c><00:38:07.210><c> each</c><00:38:07.450><c> time</c>

00:38:07.740 --> 00:38:07.750 align:start position:0%
sure we take a different point each time
 

00:38:07.750 --> 00:38:10.410 align:start position:0%
sure we take a different point each time
but<00:38:08.470><c> still</c><00:38:08.710><c> when</c><00:38:09.369><c> we</c><00:38:09.520><c> move</c><00:38:09.819><c> and</c><00:38:10.059><c> we</c><00:38:10.210><c> take</c><00:38:10.390><c> a</c>

00:38:10.410 --> 00:38:10.420 align:start position:0%
but still when we move and we take a
 

00:38:10.420 --> 00:38:12.930 align:start position:0%
but still when we move and we take a
step<00:38:10.720><c> in</c><00:38:10.900><c> that</c><00:38:10.930><c> direction</c><00:38:11.170><c> of</c><00:38:11.619><c> that</c><00:38:11.740><c> point</c><00:38:12.040><c> we</c>

00:38:12.930 --> 00:38:12.940 align:start position:0%
step in that direction of that point we
 

00:38:12.940 --> 00:38:14.849 align:start position:0%
step in that direction of that point we
may<00:38:13.150><c> be</c><00:38:13.210><c> going</c><00:38:13.450><c> in</c><00:38:13.690><c> in</c><00:38:14.079><c> a</c><00:38:14.200><c> step</c><00:38:14.410><c> that's</c><00:38:14.619><c> not</c>

00:38:14.849 --> 00:38:14.859 align:start position:0%
may be going in in a step that's not
 

00:38:14.859 --> 00:38:16.650 align:start position:0%
may be going in in a step that's not
necessarily<00:38:15.490><c> representative</c><00:38:16.030><c> of</c><00:38:16.329><c> the</c><00:38:16.420><c> entire</c>

00:38:16.650 --> 00:38:16.660 align:start position:0%
necessarily representative of the entire
 

00:38:16.660 --> 00:38:21.900 align:start position:0%
necessarily representative of the entire
data<00:38:16.900><c> set</c><00:38:19.260><c> so</c><00:38:20.260><c> is</c><00:38:20.589><c> there</c><00:38:20.950><c> a</c><00:38:21.130><c> middle</c><00:38:21.700><c> ground</c>

00:38:21.900 --> 00:38:21.910 align:start position:0%
data set so is there a middle ground
 

00:38:21.910 --> 00:38:23.640 align:start position:0%
data set so is there a middle ground
such<00:38:22.540><c> that</c><00:38:22.750><c> we</c><00:38:22.900><c> don't</c><00:38:23.140><c> have</c><00:38:23.319><c> to</c><00:38:23.470><c> have</c><00:38:23.619><c> a</c>

00:38:23.640 --> 00:38:23.650 align:start position:0%
such that we don't have to have a
 

00:38:23.650 --> 00:38:27.839 align:start position:0%
such that we don't have to have a
stochastic<00:38:24.160><c> a</c><00:38:25.920><c> stochastic</c><00:38:26.920><c> gradient</c><00:38:27.220><c> but</c><00:38:27.730><c> we</c>

00:38:27.839 --> 00:38:27.849 align:start position:0%
stochastic a stochastic gradient but we
 

00:38:27.849 --> 00:38:29.400 align:start position:0%
stochastic a stochastic gradient but we
can<00:38:28.030><c> still</c><00:38:28.240><c> be</c><00:38:28.329><c> kind</c><00:38:28.450><c> of</c><00:38:28.569><c> computationally</c>

00:38:29.400 --> 00:38:29.410 align:start position:0%
can still be kind of computationally
 

00:38:29.410 --> 00:38:32.940 align:start position:0%
can still be kind of computationally
efficient<00:38:29.829><c> in</c><00:38:29.980><c> the</c><00:38:30.069><c> sense</c><00:38:31.530><c> so</c><00:38:32.530><c> instead</c><00:38:32.890><c> of</c>

00:38:32.940 --> 00:38:32.950 align:start position:0%
efficient in the sense so instead of
 

00:38:32.950 --> 00:38:34.980 align:start position:0%
efficient in the sense so instead of
computing<00:38:33.460><c> a</c><00:38:33.520><c> noisy</c><00:38:34.000><c> gradient</c><00:38:34.420><c> of</c><00:38:34.599><c> a</c><00:38:34.690><c> single</c>

00:38:34.980 --> 00:38:34.990 align:start position:0%
computing a noisy gradient of a single
 

00:38:34.990 --> 00:38:36.900 align:start position:0%
computing a noisy gradient of a single
point<00:38:35.230><c> let's</c><00:38:35.770><c> get</c><00:38:35.920><c> a</c><00:38:35.950><c> better</c><00:38:36.190><c> estimate</c><00:38:36.730><c> by</c>

00:38:36.900 --> 00:38:36.910 align:start position:0%
point let's get a better estimate by
 

00:38:36.910 --> 00:38:40.410 align:start position:0%
point let's get a better estimate by
batching<00:38:37.450><c> our</c><00:38:37.599><c> data</c><00:38:37.839><c> into</c><00:38:38.530><c> mini</c><00:38:38.980><c> batches</c><00:38:39.250><c> of</c><00:38:39.670><c> B</c>

00:38:40.410 --> 00:38:40.420 align:start position:0%
batching our data into mini batches of B
 

00:38:40.420 --> 00:38:43.170 align:start position:0%
batching our data into mini batches of B
data<00:38:40.750><c> points</c><00:38:41.170><c> capital</c><00:38:41.559><c> B</c><00:38:41.680><c> data</c><00:38:41.920><c> points</c><00:38:42.309><c> so</c><00:38:42.490><c> now</c>

00:38:43.170 --> 00:38:43.180 align:start position:0%
data points capital B data points so now
 

00:38:43.180 --> 00:38:45.030 align:start position:0%
data points capital B data points so now
this<00:38:43.540><c> gives</c><00:38:43.750><c> us</c><00:38:43.900><c> an</c><00:38:44.049><c> estimate</c><00:38:44.559><c> of</c><00:38:44.619><c> the</c><00:38:44.710><c> true</c>

00:38:45.030 --> 00:38:45.040 align:start position:0%
this gives us an estimate of the true
 

00:38:45.040 --> 00:38:47.520 align:start position:0%
this gives us an estimate of the true
gradient<00:38:45.549><c> by</c><00:38:46.059><c> just</c><00:38:46.299><c> averaging</c><00:38:46.930><c> the</c><00:38:47.109><c> gradient</c>

00:38:47.520 --> 00:38:47.530 align:start position:0%
gradient by just averaging the gradient
 

00:38:47.530 --> 00:38:50.910 align:start position:0%
gradient by just averaging the gradient
from<00:38:47.710><c> each</c><00:38:47.890><c> of</c><00:38:48.040><c> these</c><00:38:48.160><c> points</c><00:38:49.530><c> this</c><00:38:50.530><c> is</c><00:38:50.589><c> great</c>

00:38:50.910 --> 00:38:50.920 align:start position:0%
from each of these points this is great
 

00:38:50.920 --> 00:38:53.309 align:start position:0%
from each of these points this is great
because<00:38:51.190><c> now</c><00:38:51.460><c> it's</c><00:38:52.329><c> much</c><00:38:52.510><c> easier</c><00:38:52.839><c> to</c><00:38:53.020><c> compute</c>

00:38:53.309 --> 00:38:53.319 align:start position:0%
because now it's much easier to compute
 

00:38:53.319 --> 00:38:56.640 align:start position:0%
because now it's much easier to compute
than<00:38:53.890><c> full</c><00:38:54.280><c> gradient</c><00:38:54.819><c> descent</c><00:38:55.290><c> it's</c><00:38:56.290><c> a</c><00:38:56.380><c> lot</c>

00:38:56.640 --> 00:38:56.650 align:start position:0%
than full gradient descent it's a lot
 

00:38:56.650 --> 00:38:58.440 align:start position:0%
than full gradient descent it's a lot
less<00:38:56.829><c> points</c><00:38:57.250><c> typically</c><00:38:57.579><c> B</c><00:38:57.880><c> is</c><00:38:58.030><c> on</c><00:38:58.180><c> the</c><00:38:58.270><c> order</c>

00:38:58.440 --> 00:38:58.450 align:start position:0%
less points typically B is on the order
 

00:38:58.450 --> 00:39:01.559 align:start position:0%
less points typically B is on the order
of<00:38:59.010><c> less</c><00:39:00.010><c> than</c><00:39:00.220><c> 100</c><00:39:00.640><c> or</c><00:39:00.819><c> approximately</c><00:39:01.480><c> in</c>

00:39:01.559 --> 00:39:01.569 align:start position:0%
of less than 100 or approximately in
 

00:39:01.569 --> 00:39:04.980 align:start position:0%
of less than 100 or approximately in
that<00:39:01.690><c> range</c><00:39:01.960><c> and</c><00:39:02.970><c> it's</c><00:39:03.970><c> a</c><00:39:04.089><c> lot</c><00:39:04.329><c> more</c><00:39:04.480><c> accurate</c>

00:39:04.980 --> 00:39:04.990 align:start position:0%
that range and it's a lot more accurate
 

00:39:04.990 --> 00:39:06.690 align:start position:0%
that range and it's a lot more accurate
than<00:39:05.230><c> stochastic</c><00:39:05.799><c> gradient</c><00:39:06.099><c> descent</c><00:39:06.369><c> because</c>

00:39:06.690 --> 00:39:06.700 align:start position:0%
than stochastic gradient descent because
 

00:39:06.700 --> 00:39:08.069 align:start position:0%
than stochastic gradient descent because
you're<00:39:07.000><c> considering</c><00:39:07.450><c> a</c><00:39:07.540><c> larger</c><00:39:07.930><c> population</c>

00:39:08.069 --> 00:39:08.079 align:start position:0%
you're considering a larger population
 

00:39:08.079 --> 00:39:12.329 align:start position:0%
you're considering a larger population
as<00:39:08.589><c> well</c><00:39:10.349><c> this</c><00:39:11.349><c> increase</c><00:39:11.799><c> in</c><00:39:11.950><c> gradient</c>

00:39:12.329 --> 00:39:12.339 align:start position:0%
as well this increase in gradient
 

00:39:12.339 --> 00:39:14.670 align:start position:0%
as well this increase in gradient
accuracy<00:39:12.849><c> estimation</c><00:39:13.450><c> actually</c><00:39:13.960><c> allows</c><00:39:14.470><c> us</c>

00:39:14.670 --> 00:39:14.680 align:start position:0%
accuracy estimation actually allows us
 

00:39:14.680 --> 00:39:16.500 align:start position:0%
accuracy estimation actually allows us
to<00:39:14.829><c> converge</c><00:39:15.220><c> much</c><00:39:15.520><c> quicker</c><00:39:15.849><c> as</c><00:39:16.119><c> well</c><00:39:16.299><c> because</c>

00:39:16.500 --> 00:39:16.510 align:start position:0%
to converge much quicker as well because
 

00:39:16.510 --> 00:39:17.609 align:start position:0%
to converge much quicker as well because
it<00:39:16.599><c> means</c><00:39:16.780><c> that</c><00:39:16.900><c> we</c><00:39:16.990><c> can</c><00:39:17.140><c> increase</c><00:39:17.410><c> our</c>

00:39:17.609 --> 00:39:17.619 align:start position:0%
it means that we can increase our
 

00:39:17.619 --> 00:39:18.980 align:start position:0%
it means that we can increase our
learning<00:39:17.950><c> rate</c><00:39:18.099><c> and</c><00:39:18.250><c> trust</c><00:39:18.549><c> our</c><00:39:18.730><c> gradient</c>

00:39:18.980 --> 00:39:18.990 align:start position:0%
learning rate and trust our gradient
 

00:39:18.990 --> 00:39:22.380 align:start position:0%
learning rate and trust our gradient
more<00:39:19.990><c> with</c><00:39:20.230><c> each</c><00:39:20.410><c> step</c><00:39:21.240><c> which</c><00:39:22.240><c> ultimately</c>

00:39:22.380 --> 00:39:22.390 align:start position:0%
more with each step which ultimately
 

00:39:22.390 --> 00:39:25.470 align:start position:0%
more with each step which ultimately
means<00:39:22.960><c> that</c><00:39:23.109><c> we</c><00:39:23.200><c> can</c><00:39:23.349><c> train</c><00:39:23.530><c> faster</c><00:39:24.480><c> this</c>

00:39:25.470 --> 00:39:25.480 align:start position:0%
means that we can train faster this
 

00:39:25.480 --> 00:39:27.210 align:start position:0%
means that we can train faster this
allows<00:39:25.780><c> for</c><00:39:25.809><c> massively</c><00:39:26.470><c> parallel</c><00:39:26.770><c> lyza</c>

00:39:27.210 --> 00:39:27.220 align:start position:0%
allows for massively parallel lyza
 

00:39:27.220 --> 00:39:28.980 align:start position:0%
allows for massively parallel lyza
become<00:39:27.579><c> potations</c><00:39:27.940><c> because</c><00:39:28.299><c> we</c><00:39:28.420><c> can</c><00:39:28.569><c> split</c><00:39:28.869><c> up</c>

00:39:28.980 --> 00:39:28.990 align:start position:0%
become potations because we can split up
 

00:39:28.990 --> 00:39:32.160 align:start position:0%
become potations because we can split up
batches<00:39:29.440><c> across</c><00:39:30.220><c> the</c><00:39:30.460><c> GPU</c><00:39:30.849><c> send</c><00:39:31.510><c> batches</c><00:39:31.900><c> all</c>

00:39:32.160 --> 00:39:32.170 align:start position:0%
batches across the GPU send batches all
 

00:39:32.170 --> 00:39:33.990 align:start position:0%
batches across the GPU send batches all
over<00:39:32.440><c> the</c><00:39:32.530><c> GPU</c><00:39:32.890><c> compute</c><00:39:33.430><c> their</c><00:39:33.579><c> gradients</c>

00:39:33.990 --> 00:39:34.000 align:start position:0%
over the GPU compute their gradients
 

00:39:34.000 --> 00:39:35.880 align:start position:0%
over the GPU compute their gradients
simultaneously<00:39:34.809><c> and</c><00:39:34.990><c> then</c><00:39:35.230><c> aggregate</c><00:39:35.710><c> them</c>

00:39:35.880 --> 00:39:35.890 align:start position:0%
simultaneously and then aggregate them
 

00:39:35.890 --> 00:39:36.550 align:start position:0%
simultaneously and then aggregate them
back

00:39:36.550 --> 00:39:36.560 align:start position:0%
back
 

00:39:36.560 --> 00:39:40.570 align:start position:0%
back
to<00:39:36.770><c> even</c><00:39:37.070><c> speed</c><00:39:37.460><c> up</c><00:39:37.610><c> even</c><00:39:38.090><c> further</c><00:39:39.220><c> now</c><00:39:40.220><c> the</c>

00:39:40.570 --> 00:39:40.580 align:start position:0%
to even speed up even further now the
 

00:39:40.580 --> 00:39:42.340 align:start position:0%
to even speed up even further now the
last<00:39:40.730><c> topic</c><00:39:40.940><c> I</c><00:39:41.120><c> want</c><00:39:41.300><c> to</c><00:39:41.360><c> address</c><00:39:41.510><c> before</c>

00:39:42.340 --> 00:39:42.350 align:start position:0%
last topic I want to address before
 

00:39:42.350 --> 00:39:45.640 align:start position:0%
last topic I want to address before
ending<00:39:42.830><c> is</c><00:39:43.040><c> this</c><00:39:43.640><c> idea</c><00:39:44.450><c> of</c><00:39:44.510><c> overfitting</c><00:39:45.080><c> this</c>

00:39:45.640 --> 00:39:45.650 align:start position:0%
ending is this idea of overfitting this
 

00:39:45.650 --> 00:39:49.030 align:start position:0%
ending is this idea of overfitting this
is<00:39:45.800><c> one</c><00:39:46.010><c> of</c><00:39:46.130><c> the</c><00:39:46.310><c> most</c><00:39:47.410><c> fundamental</c><00:39:48.410><c> problems</c>

00:39:49.030 --> 00:39:49.040 align:start position:0%
is one of the most fundamental problems
 

00:39:49.040 --> 00:39:51.460 align:start position:0%
is one of the most fundamental problems
in<00:39:49.670><c> machine</c><00:39:50.090><c> learning</c><00:39:50.540><c> as</c><00:39:50.720><c> a</c><00:39:50.960><c> whole</c><00:39:51.230><c> not</c><00:39:51.410><c> just</c>

00:39:51.460 --> 00:39:51.470 align:start position:0%
in machine learning as a whole not just
 

00:39:51.470 --> 00:39:55.390 align:start position:0%
in machine learning as a whole not just
deep<00:39:51.800><c> learning</c><00:39:51.980><c> and</c><00:39:53.710><c> at</c><00:39:54.710><c> its</c><00:39:54.890><c> core</c><00:39:54.980><c> it</c>

00:39:55.390 --> 00:39:55.400 align:start position:0%
deep learning and at its core it
 

00:39:55.400 --> 00:39:58.990 align:start position:0%
deep learning and at its core it
involves<00:39:56.080><c> understanding</c><00:39:57.340><c> the</c><00:39:58.340><c> complexity</c><00:39:58.970><c> of</c>

00:39:58.990 --> 00:39:59.000 align:start position:0%
involves understanding the complexity of
 

00:39:59.000 --> 00:40:00.790 align:start position:0%
involves understanding the complexity of
your<00:39:59.180><c> model</c><00:39:59.510><c> so</c><00:39:59.750><c> you</c><00:39:59.930><c> want</c><00:40:00.230><c> to</c><00:40:00.350><c> build</c><00:40:00.530><c> a</c><00:40:00.650><c> model</c>

00:40:00.790 --> 00:40:00.800 align:start position:0%
your model so you want to build a model
 

00:40:00.800 --> 00:40:02.800 align:start position:0%
your model so you want to build a model
that<00:40:01.100><c> performs</c><00:40:01.670><c> well</c><00:40:01.910><c> and</c><00:40:02.150><c> generalized</c><00:40:02.630><c> as</c>

00:40:02.800 --> 00:40:02.810 align:start position:0%
that performs well and generalized as
 

00:40:02.810 --> 00:40:04.780 align:start position:0%
that performs well and generalized as
well<00:40:02.990><c> not</c><00:40:03.530><c> just</c><00:40:03.770><c> to</c><00:40:03.860><c> your</c><00:40:03.920><c> training</c><00:40:04.370><c> set</c><00:40:04.580><c> but</c>

00:40:04.780 --> 00:40:04.790 align:start position:0%
well not just to your training set but
 

00:40:04.790 --> 00:40:09.010 align:start position:0%
well not just to your training set but
to<00:40:05.630><c> your</c><00:40:05.690><c> test</c><00:40:05.990><c> set</c><00:40:06.170><c> as</c><00:40:06.380><c> well</c><00:40:07.660><c> assume</c><00:40:08.660><c> that</c><00:40:08.900><c> you</c>

00:40:09.010 --> 00:40:09.020 align:start position:0%
to your test set as well assume that you
 

00:40:09.020 --> 00:40:10.180 align:start position:0%
to your test set as well assume that you
want<00:40:09.170><c> to</c><00:40:09.290><c> build</c><00:40:09.440><c> a</c><00:40:09.530><c> model</c><00:40:09.800><c> that</c><00:40:09.980><c> describes</c>

00:40:10.180 --> 00:40:10.190 align:start position:0%
want to build a model that describes
 

00:40:10.190 --> 00:40:13.120 align:start position:0%
want to build a model that describes
these<00:40:10.760><c> points</c><00:40:11.240><c> you</c><00:40:12.170><c> can</c><00:40:12.350><c> go</c><00:40:12.530><c> on</c><00:40:12.710><c> the</c><00:40:12.830><c> left-hand</c>

00:40:13.120 --> 00:40:13.130 align:start position:0%
these points you can go on the left-hand
 

00:40:13.130 --> 00:40:15.220 align:start position:0%
these points you can go on the left-hand
side<00:40:13.310><c> which</c><00:40:13.670><c> is</c><00:40:13.850><c> just</c><00:40:14.060><c> a</c><00:40:14.150><c> line</c><00:40:14.420><c> fitting</c><00:40:14.930><c> a</c><00:40:14.990><c> line</c>

00:40:15.220 --> 00:40:15.230 align:start position:0%
side which is just a line fitting a line
 

00:40:15.230 --> 00:40:16.870 align:start position:0%
side which is just a line fitting a line
through<00:40:15.410><c> these</c><00:40:15.560><c> points</c><00:40:15.770><c> this</c><00:40:16.040><c> is</c><00:40:16.220><c> under</c>

00:40:16.870 --> 00:40:16.880 align:start position:0%
through these points this is under
 

00:40:16.880 --> 00:40:19.420 align:start position:0%
through these points this is under
fitting<00:40:17.350><c> the</c><00:40:18.350><c> complexity</c><00:40:18.830><c> of</c><00:40:18.890><c> your</c><00:40:18.950><c> model</c><00:40:19.310><c> is</c>

00:40:19.420 --> 00:40:19.430 align:start position:0%
fitting the complexity of your model is
 

00:40:19.430 --> 00:40:21.610 align:start position:0%
fitting the complexity of your model is
not<00:40:19.610><c> large</c><00:40:19.940><c> enough</c><00:40:20.000><c> to</c><00:40:20.270><c> really</c><00:40:20.750><c> learn</c><00:40:21.320><c> the</c>

00:40:21.610 --> 00:40:21.620 align:start position:0%
not large enough to really learn the
 

00:40:21.620 --> 00:40:24.160 align:start position:0%
not large enough to really learn the
full<00:40:21.800><c> complexity</c><00:40:22.400><c> of</c><00:40:22.520><c> the</c><00:40:22.700><c> data</c><00:40:22.900><c> or</c><00:40:23.900><c> you</c><00:40:24.050><c> can</c>

00:40:24.160 --> 00:40:24.170 align:start position:0%
full complexity of the data or you can
 

00:40:24.170 --> 00:40:25.510 align:start position:0%
full complexity of the data or you can
go<00:40:24.290><c> on</c><00:40:24.410><c> the</c><00:40:24.530><c> right-hand</c><00:40:24.920><c> side</c><00:40:25.130><c> which</c><00:40:25.340><c> is</c>

00:40:25.510 --> 00:40:25.520 align:start position:0%
go on the right-hand side which is
 

00:40:25.520 --> 00:40:27.520 align:start position:0%
go on the right-hand side which is
overfitting<00:40:26.030><c> where</c><00:40:26.810><c> you're</c><00:40:26.930><c> essentially</c>

00:40:27.520 --> 00:40:27.530 align:start position:0%
overfitting where you're essentially
 

00:40:27.530 --> 00:40:30.130 align:start position:0%
overfitting where you're essentially
building<00:40:27.830><c> a</c><00:40:28.040><c> very</c><00:40:28.670><c> complex</c><00:40:29.030><c> model</c><00:40:29.450><c> to</c>

00:40:30.130 --> 00:40:30.140 align:start position:0%
building a very complex model to
 

00:40:30.140 --> 00:40:32.110 align:start position:0%
building a very complex model to
essentially<00:40:30.590><c> memorize</c><00:40:31.130><c> the</c><00:40:31.430><c> data</c><00:40:31.640><c> and</c><00:40:31.940><c> this</c>

00:40:32.110 --> 00:40:32.120 align:start position:0%
essentially memorize the data and this
 

00:40:32.120 --> 00:40:33.370 align:start position:0%
essentially memorize the data and this
is<00:40:32.240><c> not</c><00:40:32.390><c> useful</c><00:40:32.690><c> either</c><00:40:32.840><c> because</c><00:40:33.140><c> when</c><00:40:33.290><c> you</c>

00:40:33.370 --> 00:40:33.380 align:start position:0%
is not useful either because when you
 

00:40:33.380 --> 00:40:36.040 align:start position:0%
is not useful either because when you
show<00:40:33.530><c> a</c><00:40:33.560><c> new</c><00:40:33.800><c> data</c><00:40:34.040><c> it's</c><00:40:34.880><c> not</c><00:40:35.000><c> going</c><00:40:35.360><c> to</c><00:40:35.480><c> sense</c>

00:40:36.040 --> 00:40:36.050 align:start position:0%
show a new data it's not going to sense
 

00:40:36.050 --> 00:40:38.410 align:start position:0%
show a new data it's not going to sense
it's<00:40:36.320><c> not</c><00:40:36.410><c> going</c><00:40:36.650><c> to</c><00:40:36.740><c> perfectly</c><00:40:37.160><c> match</c><00:40:37.460><c> on</c><00:40:38.210><c> the</c>

00:40:38.410 --> 00:40:38.420 align:start position:0%
it's not going to perfectly match on the
 

00:40:38.420 --> 00:40:39.910 align:start position:0%
it's not going to perfectly match on the
training<00:40:38.870><c> data</c><00:40:39.110><c> and</c><00:40:39.440><c> it</c><00:40:39.530><c> means</c><00:40:39.620><c> that</c><00:40:39.710><c> you're</c>

00:40:39.910 --> 00:40:39.920 align:start position:0%
training data and it means that you're
 

00:40:39.920 --> 00:40:42.420 align:start position:0%
training data and it means that you're
going<00:40:40.070><c> to</c><00:40:40.100><c> have</c><00:40:40.220><c> high</c><00:40:40.720><c> generalization</c><00:40:41.720><c> error</c>

00:40:42.420 --> 00:40:42.430 align:start position:0%
going to have high generalization error
 

00:40:42.430 --> 00:40:44.800 align:start position:0%
going to have high generalization error
ideally<00:40:43.430><c> we</c><00:40:43.820><c> want</c><00:40:44.030><c> to</c><00:40:44.150><c> end</c><00:40:44.300><c> up</c><00:40:44.390><c> with</c><00:40:44.540><c> a</c><00:40:44.600><c> model</c>

00:40:44.800 --> 00:40:44.810 align:start position:0%
ideally we want to end up with a model
 

00:40:44.810 --> 00:40:46.960 align:start position:0%
ideally we want to end up with a model
in<00:40:45.020><c> the</c><00:40:45.110><c> middle</c><00:40:45.350><c> that</c><00:40:45.830><c> is</c><00:40:45.890><c> not</c><00:40:46.190><c> too</c><00:40:46.370><c> complex</c><00:40:46.760><c> to</c>

00:40:46.960 --> 00:40:46.970 align:start position:0%
in the middle that is not too complex to
 

00:40:46.970 --> 00:40:48.520 align:start position:0%
in the middle that is not too complex to
memorize<00:40:47.390><c> all</c><00:40:47.600><c> of</c><00:40:47.630><c> our</c><00:40:47.810><c> training</c><00:40:48.110><c> data</c><00:40:48.260><c> but</c>

00:40:48.520 --> 00:40:48.530 align:start position:0%
memorize all of our training data but
 

00:40:48.530 --> 00:40:51.130 align:start position:0%
memorize all of our training data but
still<00:40:49.220><c> able</c><00:40:49.520><c> to</c><00:40:49.760><c> generalize</c><00:40:50.270><c> and</c><00:40:50.480><c> perform</c>

00:40:51.130 --> 00:40:51.140 align:start position:0%
still able to generalize and perform
 

00:40:51.140 --> 00:40:53.350 align:start position:0%
still able to generalize and perform
well<00:40:51.350><c> even</c><00:40:51.710><c> we</c><00:40:51.890><c> have</c><00:40:52.070><c> when</c><00:40:52.490><c> we</c><00:40:52.610><c> have</c><00:40:52.640><c> brand</c><00:40:53.270><c> new</c>

00:40:53.350 --> 00:40:53.360 align:start position:0%
well even we have when we have brand new
 

00:40:53.360 --> 00:40:57.100 align:start position:0%
well even we have when we have brand new
training<00:40:53.990><c> and</c><00:40:54.110><c> testing</c><00:40:54.590><c> inputs</c><00:40:56.020><c> so</c><00:40:57.020><c> to</c>

00:40:57.100 --> 00:40:57.110 align:start position:0%
training and testing inputs so to
 

00:40:57.110 --> 00:40:58.960 align:start position:0%
training and testing inputs so to
address<00:40:57.530><c> this</c><00:40:57.710><c> problem</c><00:40:57.920><c> let's</c><00:40:58.610><c> talk</c><00:40:58.820><c> about</c>

00:40:58.960 --> 00:40:58.970 align:start position:0%
address this problem let's talk about
 

00:40:58.970 --> 00:41:01.030 align:start position:0%
address this problem let's talk about
regularization<00:40:59.630><c> for</c><00:41:00.320><c> deep</c><00:41:00.440><c> neural</c><00:41:00.590><c> networks</c>

00:41:01.030 --> 00:41:01.040 align:start position:0%
regularization for deep neural networks
 

00:41:01.040 --> 00:41:03.160 align:start position:0%
regularization for deep neural networks
deep<00:41:01.700><c> neural</c><00:41:01.850><c> regularization</c><00:41:02.630><c> is</c><00:41:03.140><c> a</c>

00:41:03.160 --> 00:41:03.170 align:start position:0%
deep neural regularization is a
 

00:41:03.170 --> 00:41:05.560 align:start position:0%
deep neural regularization is a
technique<00:41:03.590><c> that</c><00:41:03.800><c> you</c><00:41:04.520><c> can</c><00:41:04.700><c> introduce</c><00:41:04.940><c> to</c><00:41:05.450><c> your</c>

00:41:05.560 --> 00:41:05.570 align:start position:0%
technique that you can introduce to your
 

00:41:05.570 --> 00:41:08.170 align:start position:0%
technique that you can introduce to your
networks<00:41:05.900><c> that</c><00:41:06.860><c> will</c><00:41:07.010><c> discourage</c><00:41:07.460><c> complex</c>

00:41:08.170 --> 00:41:08.180 align:start position:0%
networks that will discourage complex
 

00:41:08.180 --> 00:41:12.880 align:start position:0%
networks that will discourage complex
models<00:41:08.660><c> from</c><00:41:08.810><c> being</c><00:41:09.110><c> learned</c><00:41:09.440><c> and</c><00:41:11.320><c> as</c><00:41:12.320><c> before</c>

00:41:12.880 --> 00:41:12.890 align:start position:0%
models from being learned and as before
 

00:41:12.890 --> 00:41:14.980 align:start position:0%
models from being learned and as before
we've<00:41:13.220><c> seen</c><00:41:13.460><c> that</c><00:41:13.580><c> it's</c><00:41:13.730><c> crucial</c><00:41:14.270><c> for</c><00:41:14.510><c> our</c>

00:41:14.980 --> 00:41:14.990 align:start position:0%
we've seen that it's crucial for our
 

00:41:14.990 --> 00:41:18.490 align:start position:0%
we've seen that it's crucial for our
models<00:41:15.350><c> to</c><00:41:15.470><c> be</c><00:41:15.560><c> able</c><00:41:15.710><c> to</c><00:41:15.860><c> generalize</c><00:41:16.340><c> to</c><00:41:17.500><c> data</c>

00:41:18.490 --> 00:41:18.500 align:start position:0%
models to be able to generalize to data
 

00:41:18.500 --> 00:41:20.500 align:start position:0%
models to be able to generalize to data
beyond<00:41:19.100><c> our</c><00:41:19.340><c> training</c><00:41:19.700><c> set</c><00:41:19.910><c> but</c><00:41:20.090><c> also</c><00:41:20.120><c> to</c>

00:41:20.500 --> 00:41:20.510 align:start position:0%
beyond our training set but also to
 

00:41:20.510 --> 00:41:22.990 align:start position:0%
beyond our training set but also to
generate<00:41:20.720><c> generalize</c><00:41:21.530><c> to</c><00:41:21.890><c> data</c><00:41:22.070><c> in</c><00:41:22.490><c> our</c>

00:41:22.990 --> 00:41:23.000 align:start position:0%
generate generalize to data in our
 

00:41:23.000 --> 00:41:26.620 align:start position:0%
generate generalize to data in our
testing<00:41:23.360><c> set</c><00:41:23.540><c> as</c><00:41:23.660><c> well</c><00:41:24.910><c> the</c><00:41:25.910><c> most</c><00:41:26.090><c> popular</c>

00:41:26.620 --> 00:41:26.630 align:start position:0%
testing set as well the most popular
 

00:41:26.630 --> 00:41:28.330 align:start position:0%
testing set as well the most popular
regularization<00:41:27.170><c> technique</c><00:41:28.010><c> in</c><00:41:28.160><c> deep</c>

00:41:28.330 --> 00:41:28.340 align:start position:0%
regularization technique in deep
 

00:41:28.340 --> 00:41:30.160 align:start position:0%
regularization technique in deep
learning<00:41:28.490><c> is</c><00:41:28.820><c> a</c><00:41:28.850><c> very</c><00:41:29.210><c> simple</c><00:41:29.510><c> idea</c><00:41:29.840><c> called</c>

00:41:30.160 --> 00:41:30.170 align:start position:0%
learning is a very simple idea called
 

00:41:30.170 --> 00:41:32.800 align:start position:0%
learning is a very simple idea called
dropout<00:41:30.620><c> let's</c><00:41:31.610><c> revisit</c><00:41:31.940><c> this</c><00:41:32.300><c> and</c><00:41:32.540><c> a</c><00:41:32.600><c> picture</c>

00:41:32.800 --> 00:41:32.810 align:start position:0%
dropout let's revisit this and a picture
 

00:41:32.810 --> 00:41:35.740 align:start position:0%
dropout let's revisit this and a picture
of<00:41:32.930><c> a</c><00:41:33.230><c> deep</c><00:41:33.410><c> neural</c><00:41:33.590><c> network</c><00:41:33.980><c> again</c><00:41:34.280><c> and</c><00:41:34.750><c> drop</c>

00:41:35.740 --> 00:41:35.750 align:start position:0%
of a deep neural network again and drop
 

00:41:35.750 --> 00:41:38.170 align:start position:0%
of a deep neural network again and drop
out<00:41:35.930><c> during</c><00:41:36.230><c> training</c><00:41:36.560><c> we</c><00:41:36.590><c> randomly</c><00:41:37.220><c> set</c><00:41:37.880><c> some</c>

00:41:38.170 --> 00:41:38.180 align:start position:0%
out during training we randomly set some
 

00:41:38.180 --> 00:41:40.090 align:start position:0%
out during training we randomly set some
of<00:41:38.330><c> our</c><00:41:38.450><c> activations</c><00:41:39.110><c> of</c><00:41:39.350><c> the</c><00:41:39.710><c> hidden</c><00:41:39.950><c> neurons</c>

00:41:40.090 --> 00:41:40.100 align:start position:0%
of our activations of the hidden neurons
 

00:41:40.100 --> 00:41:43.360 align:start position:0%
of our activations of the hidden neurons
to<00:41:40.760><c> 0</c><00:41:41.030><c> with</c><00:41:41.960><c> some</c><00:41:42.170><c> probability</c><00:41:42.350><c> that's</c><00:41:43.130><c> why</c><00:41:43.250><c> we</c>

00:41:43.360 --> 00:41:43.370 align:start position:0%
to 0 with some probability that's why we
 

00:41:43.370 --> 00:41:44.350 align:start position:0%
to 0 with some probability that's why we
call<00:41:43.490><c> it</c><00:41:43.580><c> dropping</c><00:41:43.910><c> out</c><00:41:44.000><c> because</c><00:41:44.210><c> we're</c>

00:41:44.350 --> 00:41:44.360 align:start position:0%
call it dropping out because we're
 

00:41:44.360 --> 00:41:46.810 align:start position:0%
call it dropping out because we're
essentially<00:41:44.600><c> killing</c><00:41:44.960><c> off</c><00:41:45.200><c> those</c><00:41:45.470><c> neurons</c><00:41:45.890><c> so</c>

00:41:46.810 --> 00:41:46.820 align:start position:0%
essentially killing off those neurons so
 

00:41:46.820 --> 00:41:48.130 align:start position:0%
essentially killing off those neurons so
let's<00:41:47.030><c> do</c><00:41:47.150><c> that</c><00:41:47.270><c> so</c><00:41:47.480><c> we</c><00:41:47.600><c> kill</c><00:41:47.810><c> off</c><00:41:47.960><c> these</c>

00:41:48.130 --> 00:41:48.140 align:start position:0%
let's do that so we kill off these
 

00:41:48.140 --> 00:41:49.930 align:start position:0%
let's do that so we kill off these
random<00:41:48.770><c> sample</c><00:41:49.130><c> of</c><00:41:49.220><c> neurons</c>

00:41:49.930 --> 00:41:49.940 align:start position:0%
random sample of neurons
 

00:41:49.940 --> 00:41:51.190 align:start position:0%
random sample of neurons
and<00:41:50.089><c> now</c><00:41:50.359><c> we've</c><00:41:50.510><c> created</c><00:41:50.690><c> a</c><00:41:51.020><c> different</c>

00:41:51.190 --> 00:41:51.200 align:start position:0%
and now we've created a different
 

00:41:51.200 --> 00:41:53.680 align:start position:0%
and now we've created a different
pathway<00:41:51.799><c> through</c><00:41:51.980><c> the</c><00:41:52.069><c> network</c><00:41:52.569><c> let's</c><00:41:53.569><c> say</c>

00:41:53.680 --> 00:41:53.690 align:start position:0%
pathway through the network let's say
 

00:41:53.690 --> 00:41:55.029 align:start position:0%
pathway through the network let's say
that<00:41:53.869><c> you</c><00:41:53.960><c> dropped</c><00:41:54.170><c> 50</c><00:41:54.470><c> percent</c><00:41:54.829><c> of</c><00:41:54.950><c> the</c>

00:41:55.029 --> 00:41:55.039 align:start position:0%
that you dropped 50 percent of the
 

00:41:55.039 --> 00:41:57.010 align:start position:0%
that you dropped 50 percent of the
neurons<00:41:55.339><c> this</c><00:41:55.579><c> means</c><00:41:55.819><c> that</c><00:41:56.059><c> those</c>

00:41:57.010 --> 00:41:57.020 align:start position:0%
neurons this means that those
 

00:41:57.020 --> 00:41:59.620 align:start position:0%
neurons this means that those
activations<00:41:57.740><c> are</c><00:41:57.890><c> set</c><00:41:58.069><c> to</c><00:41:58.250><c> zero</c><00:41:58.520><c> and</c><00:41:58.789><c> the</c>

00:41:59.620 --> 00:41:59.630 align:start position:0%
activations are set to zero and the
 

00:41:59.630 --> 00:42:01.539 align:start position:0%
activations are set to zero and the
network<00:41:59.930><c> is</c><00:42:00.049><c> not</c><00:42:00.260><c> going</c><00:42:00.559><c> to</c><00:42:00.770><c> rely</c><00:42:01.220><c> too</c><00:42:01.280><c> heavily</c>

00:42:01.539 --> 00:42:01.549 align:start position:0%
network is not going to rely too heavily
 

00:42:01.549 --> 00:42:03.640 align:start position:0%
network is not going to rely too heavily
on<00:42:01.970><c> any</c><00:42:02.329><c> particular</c><00:42:02.660><c> path</c><00:42:03.319><c> through</c><00:42:03.530><c> the</c>

00:42:03.640 --> 00:42:03.650 align:start position:0%
on any particular path through the
 

00:42:03.650 --> 00:42:05.380 align:start position:0%
on any particular path through the
network<00:42:03.680><c> but</c><00:42:04.309><c> it's</c><00:42:04.430><c> instead</c><00:42:04.760><c> going</c><00:42:04.940><c> to</c><00:42:05.000><c> find</c><00:42:05.210><c> a</c>

00:42:05.380 --> 00:42:05.390 align:start position:0%
network but it's instead going to find a
 

00:42:05.390 --> 00:42:07.120 align:start position:0%
network but it's instead going to find a
whole<00:42:05.750><c> ensemble</c><00:42:06.410><c> of</c><00:42:06.559><c> different</c><00:42:06.890><c> paths</c>

00:42:07.120 --> 00:42:07.130 align:start position:0%
whole ensemble of different paths
 

00:42:07.130 --> 00:42:08.799 align:start position:0%
whole ensemble of different paths
because<00:42:07.670><c> it</c><00:42:07.880><c> doesn't</c><00:42:08.150><c> know</c><00:42:08.210><c> which</c><00:42:08.359><c> path</c><00:42:08.599><c> is</c>

00:42:08.799 --> 00:42:08.809 align:start position:0%
because it doesn't know which path is
 

00:42:08.809 --> 00:42:10.120 align:start position:0%
because it doesn't know which path is
going<00:42:08.960><c> to</c><00:42:09.079><c> be</c><00:42:09.140><c> dropped</c><00:42:09.380><c> out</c><00:42:09.530><c> at</c><00:42:09.740><c> any</c><00:42:09.829><c> given</c>

00:42:10.120 --> 00:42:10.130 align:start position:0%
going to be dropped out at any given
 

00:42:10.130 --> 00:42:13.930 align:start position:0%
going to be dropped out at any given
time<00:42:10.309><c> we</c><00:42:11.920><c> repeat</c><00:42:12.920><c> this</c><00:42:13.039><c> process</c><00:42:13.250><c> on</c><00:42:13.609><c> every</c>

00:42:13.930 --> 00:42:13.940 align:start position:0%
time we repeat this process on every
 

00:42:13.940 --> 00:42:15.430 align:start position:0%
time we repeat this process on every
training<00:42:14.210><c> iteration</c><00:42:14.690><c> now</c><00:42:14.839><c> dropping</c><00:42:15.170><c> out</c><00:42:15.410><c> a</c>

00:42:15.430 --> 00:42:15.440 align:start position:0%
training iteration now dropping out a
 

00:42:15.440 --> 00:42:20.400 align:start position:0%
training iteration now dropping out a
new<00:42:15.890><c> set</c><00:42:16.160><c> of</c><00:42:16.190><c> 50</c><00:42:16.839><c> 50</c><00:42:17.839><c> %</c><00:42:18.140><c> of</c><00:42:18.260><c> the</c><00:42:18.319><c> neurons</c><00:42:18.710><c> and</c>

00:42:20.400 --> 00:42:20.410 align:start position:0%
new set of 50 50 % of the neurons and
 

00:42:20.410 --> 00:42:22.750 align:start position:0%
new set of 50 50 % of the neurons and
the<00:42:21.410><c> result</c><00:42:21.770><c> of</c><00:42:21.920><c> this</c><00:42:22.010><c> is</c><00:42:22.190><c> essentially</c><00:42:22.730><c> a</c>

00:42:22.750 --> 00:42:22.760 align:start position:0%
the result of this is essentially a
 

00:42:22.760 --> 00:42:25.359 align:start position:0%
the result of this is essentially a
model<00:42:23.299><c> that</c><00:42:24.020><c> like</c><00:42:24.200><c> I</c><00:42:24.319><c> said</c><00:42:24.349><c> creates</c><00:42:25.190><c> an</c>

00:42:25.359 --> 00:42:25.369 align:start position:0%
model that like I said creates an
 

00:42:25.369 --> 00:42:27.849 align:start position:0%
model that like I said creates an
ensemble<00:42:26.030><c> of</c><00:42:26.210><c> multiple</c><00:42:26.750><c> models</c><00:42:27.109><c> through</c><00:42:27.710><c> the</c>

00:42:27.849 --> 00:42:27.859 align:start position:0%
ensemble of multiple models through the
 

00:42:27.859 --> 00:42:29.559 align:start position:0%
ensemble of multiple models through the
paths<00:42:28.099><c> of</c><00:42:28.250><c> the</c><00:42:28.280><c> network</c><00:42:28.640><c> and</c><00:42:28.880><c> is</c><00:42:29.270><c> able</c><00:42:29.420><c> to</c>

00:42:29.559 --> 00:42:29.569 align:start position:0%
paths of the network and is able to
 

00:42:29.569 --> 00:42:35.740 align:start position:0%
paths of the network and is able to
generalize<00:42:29.990><c> better</c><00:42:30.980><c> to</c><00:42:31.460><c> unseen</c><00:42:31.880><c> test</c><00:42:32.839><c> data</c><00:42:34.750><c> so</c>

00:42:35.740 --> 00:42:35.750 align:start position:0%
generalize better to unseen test data so
 

00:42:35.750 --> 00:42:36.849 align:start position:0%
generalize better to unseen test data so
the<00:42:35.930><c> second</c><00:42:36.230><c> technique</c><00:42:36.349><c> for</c><00:42:36.799><c> a</c>

00:42:36.849 --> 00:42:36.859 align:start position:0%
the second technique for a
 

00:42:36.859 --> 00:42:41.260 align:start position:0%
the second technique for a
regularization<00:42:37.160><c> is</c><00:42:39.130><c> this</c><00:42:40.130><c> notion</c><00:42:40.490><c> that</c><00:42:41.000><c> we'll</c>

00:42:41.260 --> 00:42:41.270 align:start position:0%
regularization is this notion that we'll
 

00:42:41.270 --> 00:42:44.160 align:start position:0%
regularization is this notion that we'll
talk<00:42:41.420><c> about</c><00:42:41.720><c> which</c><00:42:41.930><c> is</c><00:42:42.109><c> early</c><00:42:42.619><c> stopping</c><00:42:43.039><c> and</c>

00:42:44.160 --> 00:42:44.170 align:start position:0%
talk about which is early stopping and
 

00:42:44.170 --> 00:42:46.990 align:start position:0%
talk about which is early stopping and
the<00:42:45.170><c> idea</c><00:42:45.440><c> here</c><00:42:45.650><c> is</c><00:42:45.680><c> also</c><00:42:46.039><c> extremely</c><00:42:46.609><c> simple</c>

00:42:46.990 --> 00:42:47.000 align:start position:0%
the idea here is also extremely simple
 

00:42:47.000 --> 00:42:48.460 align:start position:0%
the idea here is also extremely simple
let's<00:42:47.450><c> train</c><00:42:47.690><c> our</c><00:42:47.809><c> neural</c><00:42:48.049><c> network</c><00:42:48.109><c> like</c>

00:42:48.460 --> 00:42:48.470 align:start position:0%
let's train our neural network like
 

00:42:48.470 --> 00:42:51.099 align:start position:0%
let's train our neural network like
before<00:42:48.770><c> no</c><00:42:49.010><c> dropout</c><00:42:49.430><c> but</c><00:42:50.089><c> let's</c><00:42:50.329><c> just</c><00:42:50.510><c> stop</c>

00:42:51.099 --> 00:42:51.109 align:start position:0%
before no dropout but let's just stop
 

00:42:51.109 --> 00:42:52.630 align:start position:0%
before no dropout but let's just stop
training<00:42:51.559><c> before</c><00:42:51.950><c> we</c><00:42:52.099><c> have</c><00:42:52.190><c> a</c><00:42:52.220><c> chance</c><00:42:52.430><c> to</c>

00:42:52.630 --> 00:42:52.640 align:start position:0%
training before we have a chance to
 

00:42:52.640 --> 00:42:56.319 align:start position:0%
training before we have a chance to
overfit<00:42:53.319><c> so</c><00:42:54.319><c> we</c><00:42:54.680><c> start</c><00:42:54.920><c> training</c><00:42:55.099><c> and</c><00:42:55.460><c> the</c>

00:42:56.319 --> 00:42:56.329 align:start position:0%
overfit so we start training and the
 

00:42:56.329 --> 00:42:57.730 align:start position:0%
overfit so we start training and the
definition<00:42:56.750><c> of</c><00:42:56.869><c> overfitting</c><00:42:57.230><c> is</c><00:42:57.380><c> just</c><00:42:57.589><c> when</c>

00:42:57.730 --> 00:42:57.740 align:start position:0%
definition of overfitting is just when
 

00:42:57.740 --> 00:42:59.769 align:start position:0%
definition of overfitting is just when
our<00:42:57.859><c> model</c><00:42:58.279><c> starts</c><00:42:58.549><c> to</c><00:42:58.640><c> perform</c><00:42:58.819><c> worse</c><00:42:59.299><c> on</c><00:42:59.630><c> the</c>

00:42:59.769 --> 00:42:59.779 align:start position:0%
our model starts to perform worse on the
 

00:42:59.779 --> 00:43:04.269 align:start position:0%
our model starts to perform worse on the
test<00:43:00.020><c> set</c><00:43:00.609><c> then</c><00:43:01.609><c> on</c><00:43:02.329><c> the</c><00:43:02.660><c> training</c><00:43:02.839><c> set</c><00:43:03.109><c> so</c><00:43:03.559><c> we</c>

00:43:04.269 --> 00:43:04.279 align:start position:0%
test set then on the training set so we
 

00:43:04.279 --> 00:43:05.829 align:start position:0%
test set then on the training set so we
can<00:43:04.400><c> start</c><00:43:04.640><c> off</c><00:43:04.760><c> and</c><00:43:05.000><c> we</c><00:43:05.029><c> can</c><00:43:05.180><c> plot</c><00:43:05.390><c> how</c><00:43:05.660><c> our</c>

00:43:05.829 --> 00:43:05.839 align:start position:0%
can start off and we can plot how our
 

00:43:05.839 --> 00:43:07.450 align:start position:0%
can start off and we can plot how our
loss<00:43:06.049><c> is</c><00:43:06.079><c> going</c><00:43:06.470><c> for</c><00:43:06.680><c> both</c><00:43:06.859><c> the</c><00:43:06.980><c> training</c><00:43:07.220><c> and</c>

00:43:07.450 --> 00:43:07.460 align:start position:0%
loss is going for both the training and
 

00:43:07.460 --> 00:43:09.010 align:start position:0%
loss is going for both the training and
test<00:43:07.670><c> set</c><00:43:07.910><c> we</c><00:43:08.299><c> can</c><00:43:08.420><c> see</c><00:43:08.539><c> that</c><00:43:08.630><c> both</c><00:43:08.809><c> are</c>

00:43:09.010 --> 00:43:09.020 align:start position:0%
test set we can see that both are
 

00:43:09.020 --> 00:43:11.140 align:start position:0%
test set we can see that both are
decreasing<00:43:09.529><c> so</c><00:43:09.680><c> we</c><00:43:09.799><c> keep</c><00:43:09.980><c> training</c><00:43:10.220><c> now</c><00:43:11.089><c> we</c>

00:43:11.140 --> 00:43:11.150 align:start position:0%
decreasing so we keep training now we
 

00:43:11.150 --> 00:43:13.750 align:start position:0%
decreasing so we keep training now we
can<00:43:11.359><c> see</c><00:43:11.510><c> that</c><00:43:11.630><c> the</c><00:43:11.869><c> training</c><00:43:12.230><c> the</c><00:43:12.760><c> validation</c>

00:43:13.750 --> 00:43:13.760 align:start position:0%
can see that the training the validation
 

00:43:13.760 --> 00:43:14.890 align:start position:0%
can see that the training the validation
both<00:43:13.910><c> losses</c><00:43:14.150><c> are</c><00:43:14.390><c> kind</c><00:43:14.569><c> of</c><00:43:14.599><c> starting</c><00:43:14.750><c> to</c>

00:43:14.890 --> 00:43:14.900 align:start position:0%
both losses are kind of starting to
 

00:43:14.900 --> 00:43:17.349 align:start position:0%
both losses are kind of starting to
plateau<00:43:15.140><c> here</c><00:43:15.559><c> we</c><00:43:16.130><c> can</c><00:43:16.250><c> keep</c><00:43:16.400><c> going</c><00:43:16.789><c> the</c>

00:43:17.349 --> 00:43:17.359 align:start position:0%
plateau here we can keep going the
 

00:43:17.359 --> 00:43:19.210 align:start position:0%
plateau here we can keep going the
training<00:43:17.720><c> loss</c><00:43:17.900><c> is</c><00:43:18.049><c> always</c><00:43:18.260><c> going</c><00:43:18.589><c> to</c><00:43:18.680><c> decay</c>

00:43:19.210 --> 00:43:19.220 align:start position:0%
training loss is always going to decay
 

00:43:19.220 --> 00:43:20.440 align:start position:0%
training loss is always going to decay
it's<00:43:19.579><c> always</c><00:43:19.849><c> going</c><00:43:20.000><c> to</c><00:43:20.059><c> keep</c><00:43:20.240><c> decreasing</c>

00:43:20.440 --> 00:43:20.450 align:start position:0%
it's always going to keep decreasing
 

00:43:20.450 --> 00:43:22.660 align:start position:0%
it's always going to keep decreasing
because<00:43:21.039><c> especially</c><00:43:22.039><c> if</c><00:43:22.130><c> you</c><00:43:22.220><c> have</c><00:43:22.339><c> a</c><00:43:22.369><c> network</c>

00:43:22.660 --> 00:43:22.670 align:start position:0%
because especially if you have a network
 

00:43:22.670 --> 00:43:26.049 align:start position:0%
because especially if you have a network
that<00:43:23.210><c> is</c><00:43:23.619><c> having</c><00:43:24.619><c> such</c><00:43:25.039><c> a</c><00:43:25.069><c> large</c><00:43:25.309><c> capacity</c><00:43:25.940><c> to</c>

00:43:26.049 --> 00:43:26.059 align:start position:0%
that is having such a large capacity to
 

00:43:26.059 --> 00:43:28.450 align:start position:0%
that is having such a large capacity to
essentially<00:43:26.359><c> memorize</c><00:43:26.930><c> your</c><00:43:27.140><c> data</c><00:43:27.589><c> you</c><00:43:28.250><c> can</c>

00:43:28.450 --> 00:43:28.460 align:start position:0%
essentially memorize your data you can
 

00:43:28.460 --> 00:43:30.700 align:start position:0%
essentially memorize your data you can
always<00:43:28.670><c> perfectly</c><00:43:29.420><c> get</c><00:43:29.809><c> a</c><00:43:29.839><c> training</c><00:43:30.230><c> accuracy</c>

00:43:30.700 --> 00:43:30.710 align:start position:0%
always perfectly get a training accuracy
 

00:43:30.710 --> 00:43:33.130 align:start position:0%
always perfectly get a training accuracy
of<00:43:30.799><c> 0</c><00:43:31.039><c> that's</c><00:43:31.730><c> not</c><00:43:31.970><c> always</c><00:43:32.270><c> the</c><00:43:32.420><c> case</c><00:43:32.450><c> but</c><00:43:32.930><c> in</c><00:43:33.079><c> a</c>

00:43:33.130 --> 00:43:33.140 align:start position:0%
of 0 that's not always the case but in a
 

00:43:33.140 --> 00:43:34.359 align:start position:0%
of 0 that's not always the case but in a
lot<00:43:33.319><c> of</c><00:43:33.349><c> times</c><00:43:33.650><c> with</c><00:43:33.799><c> deep</c><00:43:33.950><c> neural</c><00:43:34.099><c> networks</c>

00:43:34.359 --> 00:43:34.369 align:start position:0%
lot of times with deep neural networks
 

00:43:34.369 --> 00:43:37.269 align:start position:0%
lot of times with deep neural networks
since<00:43:34.609><c> they're</c><00:43:34.819><c> so</c><00:43:35.619><c> expressive</c><00:43:36.619><c> and</c><00:43:36.799><c> have</c><00:43:37.069><c> so</c>

00:43:37.269 --> 00:43:37.279 align:start position:0%
since they're so expressive and have so
 

00:43:37.279 --> 00:43:39.039 align:start position:0%
since they're so expressive and have so
many<00:43:37.430><c> weights</c><00:43:37.760><c> they're</c><00:43:38.390><c> able</c><00:43:38.599><c> to</c><00:43:38.900><c> actually</c>

00:43:39.039 --> 00:43:39.049 align:start position:0%
many weights they're able to actually
 

00:43:39.049 --> 00:43:41.049 align:start position:0%
many weights they're able to actually
memorize<00:43:39.650><c> the</c><00:43:39.829><c> data</c><00:43:40.010><c> if</c><00:43:40.250><c> you</c><00:43:40.369><c> let</c><00:43:40.670><c> them</c><00:43:40.849><c> train</c>

00:43:41.049 --> 00:43:41.059 align:start position:0%
memorize the data if you let them train
 

00:43:41.059 --> 00:43:44.049 align:start position:0%
memorize the data if you let them train
for<00:43:41.299><c> too</c><00:43:41.390><c> long</c><00:43:41.680><c> if</c><00:43:42.680><c> we</c><00:43:43.309><c> keep</c><00:43:43.460><c> training</c><00:43:43.760><c> like</c>

00:43:44.049 --> 00:43:44.059 align:start position:0%
for too long if we keep training like
 

00:43:44.059 --> 00:43:46.630 align:start position:0%
for too long if we keep training like
you<00:43:44.210><c> see</c><00:43:44.470><c> the</c><00:43:45.470><c> training</c><00:43:45.710><c> set</c><00:43:45.950><c> continues</c><00:43:46.460><c> to</c>

00:43:46.630 --> 00:43:46.640 align:start position:0%
you see the training set continues to
 

00:43:46.640 --> 00:43:48.789 align:start position:0%
you see the training set continues to
decrease<00:43:46.940><c> now</c><00:43:47.420><c> the</c><00:43:47.480><c> validation</c><00:43:48.109><c> set</c><00:43:48.349><c> starts</c>

00:43:48.789 --> 00:43:48.799 align:start position:0%
decrease now the validation set starts
 

00:43:48.799 --> 00:43:53.109 align:start position:0%
decrease now the validation set starts
to<00:43:48.980><c> increase</c><00:43:49.779><c> and</c><00:43:51.490><c> if</c><00:43:52.490><c> we</c><00:43:52.579><c> keep</c><00:43:52.730><c> doing</c><00:43:53.000><c> this</c>

00:43:53.109 --> 00:43:53.119 align:start position:0%
to increase and if we keep doing this
 

00:43:53.119 --> 00:43:56.349 align:start position:0%
to increase and if we keep doing this
the<00:43:53.359><c> trend</c><00:43:53.599><c> continues</c><00:43:54.670><c> the</c><00:43:55.670><c> idea</c><00:43:55.940><c> of</c><00:43:56.000><c> early</c>

00:43:56.349 --> 00:43:56.359 align:start position:0%
the trend continues the idea of early
 

00:43:56.359 --> 00:43:57.970 align:start position:0%
the trend continues the idea of early
stopping<00:43:56.630><c> is</c><00:43:56.930><c> essentially</c><00:43:57.349><c> that</c><00:43:57.470><c> we</c><00:43:57.619><c> want</c><00:43:57.859><c> to</c>

00:43:57.970 --> 00:43:57.980 align:start position:0%
stopping is essentially that we want to
 

00:43:57.980 --> 00:44:00.250 align:start position:0%
stopping is essentially that we want to
focus<00:43:58.670><c> on</c><00:43:58.970><c> this</c><00:43:59.089><c> point</c><00:43:59.329><c> here</c><00:43:59.720><c> and</c><00:43:59.750><c> stop</c>

00:44:00.250 --> 00:44:00.260 align:start position:0%
focus on this point here and stop
 

00:44:00.260 --> 00:44:03.220 align:start position:0%
focus on this point here and stop
training<00:44:00.799><c> when</c><00:44:01.339><c> we</c><00:44:01.700><c> reach</c><00:44:02.210><c> this</c><00:44:02.539><c> point</c><00:44:02.869><c> so</c><00:44:03.109><c> we</c>

00:44:03.220 --> 00:44:03.230 align:start position:0%
training when we reach this point so we
 

00:44:03.230 --> 00:44:04.020 align:start position:0%
training when we reach this point so we
can<00:44:03.260><c> key</c>

00:44:04.020 --> 00:44:04.030 align:start position:0%
can key
 

00:44:04.030 --> 00:44:06.270 align:start position:0%
can key
basically<00:44:05.020><c> records</c><00:44:05.470><c> of</c><00:44:05.650><c> the</c><00:44:05.800><c> model</c><00:44:06.099><c> during</c>

00:44:06.270 --> 00:44:06.280 align:start position:0%
basically records of the model during
 

00:44:06.280 --> 00:44:09.150 align:start position:0%
basically records of the model during
training<00:44:06.760><c> and</c><00:44:07.140><c> once</c><00:44:08.140><c> we</c><00:44:08.320><c> start</c><00:44:08.680><c> to</c><00:44:08.710><c> detect</c>

00:44:09.150 --> 00:44:09.160 align:start position:0%
training and once we start to detect
 

00:44:09.160 --> 00:44:11.339 align:start position:0%
training and once we start to detect
overfitting<00:44:09.700><c> we</c><00:44:10.090><c> can</c><00:44:10.240><c> just</c><00:44:10.420><c> stop</c><00:44:10.660><c> and</c><00:44:10.840><c> take</c>

00:44:11.339 --> 00:44:11.349 align:start position:0%
overfitting we can just stop and take
 

00:44:11.349 --> 00:44:14.520 align:start position:0%
overfitting we can just stop and take
that<00:44:11.530><c> last</c><00:44:11.770><c> model</c><00:44:12.190><c> that</c><00:44:12.550><c> was</c><00:44:12.670><c> still</c><00:44:13.530><c> occurring</c>

00:44:14.520 --> 00:44:14.530 align:start position:0%
that last model that was still occurring
 

00:44:14.530 --> 00:44:18.390 align:start position:0%
that last model that was still occurring
before<00:44:14.800><c> the</c><00:44:14.980><c> overfitting</c><00:44:15.430><c> happened</c><00:44:17.010><c> right</c><00:44:18.010><c> so</c>

00:44:18.390 --> 00:44:18.400 align:start position:0%
before the overfitting happened right so
 

00:44:18.400 --> 00:44:20.460 align:start position:0%
before the overfitting happened right so
on<00:44:18.640><c> the</c><00:44:18.730><c> left</c><00:44:18.940><c> hand</c><00:44:19.119><c> side</c><00:44:19.300><c> you</c><00:44:20.020><c> can</c><00:44:20.170><c> see</c><00:44:20.200><c> the</c>

00:44:20.460 --> 00:44:20.470 align:start position:0%
on the left hand side you can see the
 

00:44:20.470 --> 00:44:22.349 align:start position:0%
on the left hand side you can see the
under<00:44:20.710><c> fitting</c><00:44:21.010><c> you</c><00:44:21.609><c> don't</c><00:44:21.820><c> want</c><00:44:21.970><c> to</c><00:44:22.030><c> stop</c><00:44:22.210><c> too</c>

00:44:22.349 --> 00:44:22.359 align:start position:0%
under fitting you don't want to stop too
 

00:44:22.359 --> 00:44:24.930 align:start position:0%
under fitting you don't want to stop too
early<00:44:22.720><c> you</c><00:44:23.500><c> want</c><00:44:23.650><c> to</c><00:44:23.830><c> let</c><00:44:24.010><c> the</c><00:44:24.160><c> model</c><00:44:24.369><c> get</c><00:44:24.760><c> the</c>

00:44:24.930 --> 00:44:24.940 align:start position:0%
early you want to let the model get the
 

00:44:24.940 --> 00:44:27.359 align:start position:0%
early you want to let the model get the
minimum<00:44:25.300><c> validation</c><00:44:25.990><c> set</c><00:44:26.230><c> accuracy</c><00:44:26.740><c> but</c><00:44:27.310><c> also</c>

00:44:27.359 --> 00:44:27.369 align:start position:0%
minimum validation set accuracy but also
 

00:44:27.369 --> 00:44:29.849 align:start position:0%
minimum validation set accuracy but also
you<00:44:27.730><c> don't</c><00:44:27.849><c> want</c><00:44:27.970><c> to</c><00:44:28.180><c> keep</c><00:44:28.540><c> training</c><00:44:29.140><c> such</c>

00:44:29.849 --> 00:44:29.859 align:start position:0%
you don't want to keep training such
 

00:44:29.859 --> 00:44:31.440 align:start position:0%
you don't want to keep training such
that<00:44:30.010><c> the</c><00:44:30.099><c> validation</c><00:44:30.490><c> accuracy</c><00:44:31.060><c> starts</c><00:44:31.330><c> the</c>

00:44:31.440 --> 00:44:31.450 align:start position:0%
that the validation accuracy starts the
 

00:44:31.450 --> 00:44:34.500 align:start position:0%
that the validation accuracy starts the
increase<00:44:31.780><c> on</c><00:44:31.930><c> the</c><00:44:32.050><c> other</c><00:44:32.170><c> end</c><00:44:32.410><c> as</c><00:44:32.560><c> well</c><00:44:33.510><c> so</c>

00:44:34.500 --> 00:44:34.510 align:start position:0%
increase on the other end as well so
 

00:44:34.510 --> 00:44:36.030 align:start position:0%
increase on the other end as well so
I'll<00:44:34.720><c> conclude</c><00:44:34.990><c> this</c><00:44:35.170><c> first</c><00:44:35.349><c> lecture</c><00:44:35.770><c> by</c>

00:44:36.030 --> 00:44:36.040 align:start position:0%
I'll conclude this first lecture by
 

00:44:36.040 --> 00:44:37.589 align:start position:0%
I'll conclude this first lecture by
summarizing<00:44:36.400><c> three</c><00:44:36.790><c> key</c><00:44:37.000><c> points</c><00:44:37.270><c> that</c><00:44:37.480><c> we</c>

00:44:37.589 --> 00:44:37.599 align:start position:0%
summarizing three key points that we
 

00:44:37.599 --> 00:44:40.200 align:start position:0%
summarizing three key points that we
have<00:44:37.750><c> covered</c><00:44:38.080><c> so</c><00:44:38.230><c> far</c><00:44:38.760><c> first</c><00:44:39.760><c> we</c><00:44:39.970><c> learned</c>

00:44:40.200 --> 00:44:40.210 align:start position:0%
have covered so far first we learned
 

00:44:40.210 --> 00:44:42.150 align:start position:0%
have covered so far first we learned
about<00:44:40.540><c> the</c><00:44:40.690><c> fundamental</c><00:44:41.290><c> building</c><00:44:41.500><c> blocks</c><00:44:41.920><c> of</c>

00:44:42.150 --> 00:44:42.160 align:start position:0%
about the fundamental building blocks of
 

00:44:42.160 --> 00:44:43.890 align:start position:0%
about the fundamental building blocks of
deep<00:44:42.430><c> learning</c><00:44:42.609><c> which</c><00:44:43.030><c> is</c><00:44:43.300><c> just</c><00:44:43.599><c> a</c><00:44:43.690><c> single</c>

00:44:43.890 --> 00:44:43.900 align:start position:0%
deep learning which is just a single
 

00:44:43.900 --> 00:44:46.560 align:start position:0%
deep learning which is just a single
neuron<00:44:44.230><c> or</c><00:44:44.590><c> called</c><00:44:44.830><c> the</c><00:44:44.950><c> perceptron</c><00:44:45.570><c> we</c>

00:44:46.560 --> 00:44:46.570 align:start position:0%
neuron or called the perceptron we
 

00:44:46.570 --> 00:44:48.480 align:start position:0%
neuron or called the perceptron we
learned<00:44:46.840><c> about</c><00:44:46.990><c> back</c><00:44:47.619><c> propagation</c><00:44:48.130><c> how</c><00:44:48.430><c> to</c>

00:44:48.480 --> 00:44:48.490 align:start position:0%
learned about back propagation how to
 

00:44:48.490 --> 00:44:51.420 align:start position:0%
learned about back propagation how to
stack<00:44:48.880><c> these</c><00:44:49.090><c> neurons</c><00:44:49.590><c> into</c><00:44:50.590><c> complex</c><00:44:51.220><c> deep</c>

00:44:51.420 --> 00:44:51.430 align:start position:0%
stack these neurons into complex deep
 

00:44:51.430 --> 00:44:53.190 align:start position:0%
stack these neurons into complex deep
neural<00:44:51.609><c> networks</c><00:44:52.060><c> how</c><00:44:52.330><c> to</c><00:44:52.390><c> back</c><00:44:52.660><c> propagate</c>

00:44:53.190 --> 00:44:53.200 align:start position:0%
neural networks how to back propagate
 

00:44:53.200 --> 00:44:55.920 align:start position:0%
neural networks how to back propagate
and<00:44:53.349><c> errors</c><00:44:54.040><c> through</c><00:44:54.550><c> them</c><00:44:54.730><c> and</c><00:44:54.940><c> learn</c>

00:44:55.920 --> 00:44:55.930 align:start position:0%
and errors through them and learn
 

00:44:55.930 --> 00:45:00.510 align:start position:0%
and errors through them and learn
complex<00:44:56.859><c> loss</c><00:44:57.640><c> functions</c><00:44:58.119><c> and</c><00:44:59.400><c> finally</c><00:45:00.400><c> we</c>

00:45:00.510 --> 00:45:00.520 align:start position:0%
complex loss functions and finally we
 

00:45:00.520 --> 00:45:02.400 align:start position:0%
complex loss functions and finally we
discussed<00:45:00.910><c> some</c><00:45:01.119><c> of</c><00:45:01.150><c> the</c><00:45:01.390><c> practical</c><00:45:01.930><c> details</c>

00:45:02.400 --> 00:45:02.410 align:start position:0%
discussed some of the practical details
 

00:45:02.410 --> 00:45:04.890 align:start position:0%
discussed some of the practical details
and<00:45:02.619><c> tricks</c><00:45:02.890><c> to</c><00:45:03.640><c> training</c><00:45:04.330><c> neural</c><00:45:04.570><c> networks</c>

00:45:04.890 --> 00:45:04.900 align:start position:0%
and tricks to training neural networks
 

00:45:04.900 --> 00:45:07.920 align:start position:0%
and tricks to training neural networks
that<00:45:05.800><c> are</c><00:45:06.700><c> really</c><00:45:07.000><c> crucial</c><00:45:07.210><c> today</c><00:45:07.570><c> if</c><00:45:07.810><c> you</c>

00:45:07.920 --> 00:45:07.930 align:start position:0%
that are really crucial today if you
 

00:45:07.930 --> 00:45:10.079 align:start position:0%
that are really crucial today if you
want<00:45:08.080><c> to</c><00:45:08.170><c> work</c><00:45:08.320><c> in</c><00:45:08.470><c> this</c><00:45:08.589><c> field</c><00:45:09.060><c> such</c><00:45:10.060><c> as</c>

00:45:10.079 --> 00:45:10.089 align:start position:0%
want to work in this field such as
 

00:45:10.089 --> 00:45:13.520 align:start position:0%
want to work in this field such as
batching<00:45:10.780><c> regularization</c><00:45:11.380><c> and</c><00:45:12.010><c> and</c><00:45:12.670><c> others</c>

00:45:13.520 --> 00:45:13.530 align:start position:0%
batching regularization and and others
 

00:45:13.530 --> 00:45:16.950 align:start position:0%
batching regularization and and others
so<00:45:14.530><c> now</c><00:45:14.740><c> I'll</c><00:45:15.010><c> take</c><00:45:15.400><c> any</c><00:45:15.609><c> questions</c><00:45:16.089><c> or</c><00:45:16.420><c> if</c>

00:45:16.950 --> 00:45:16.960 align:start position:0%
so now I'll take any questions or if
 

00:45:16.960 --> 00:45:19.079 align:start position:0%
so now I'll take any questions or if
there<00:45:17.530><c> are</c><00:45:17.619><c> no</c><00:45:17.740><c> questions</c><00:45:17.920><c> and</c><00:45:18.460><c> I'm</c><00:45:18.580><c> gonna</c>

00:45:19.079 --> 00:45:19.089 align:start position:0%
there are no questions and I'm gonna
 

00:45:19.089 --> 00:45:20.910 align:start position:0%
there are no questions and I'm gonna
hand<00:45:19.390><c> the</c><00:45:19.480><c> mic</c><00:45:19.630><c> over</c><00:45:19.810><c> to</c><00:45:19.930><c> ovah</c><00:45:20.290><c> who</c><00:45:20.650><c> will</c><00:45:20.770><c> talk</c>

00:45:20.910 --> 00:45:20.920 align:start position:0%
hand the mic over to ovah who will talk
 

00:45:20.920 --> 00:45:25.020 align:start position:0%
hand the mic over to ovah who will talk
about<00:45:21.070><c> sequence</c><00:45:21.820><c> modeling</c><00:45:22.470><c> thank</c><00:45:23.470><c> you</c>

00:45:25.020 --> 00:45:25.030 align:start position:0%
about sequence modeling thank you
 

00:45:25.030 --> 00:45:29.559 align:start position:0%
about sequence modeling thank you
[Applause]

