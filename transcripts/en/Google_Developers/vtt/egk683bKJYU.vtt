WEBVTT
Kind: captions
Language: en

00:00:00.210 --> 00:00:01.470
DAMIEN HENRY: Hello everyone.

00:00:01.470 --> 00:00:02.570
My name is Damien.

00:00:02.570 --> 00:00:06.590
And I feel very lucky today,
because two great artists,

00:00:06.590 --> 00:00:09.610
Cyril Diagne and
Mario Klingemann

00:00:09.610 --> 00:00:12.390
will join me on stage
in a few minutes

00:00:12.390 --> 00:00:18.290
so you can see what they do
when they use machine learning.

00:00:18.290 --> 00:00:21.350
So if you want to go to
the bathroom or text,

00:00:21.350 --> 00:00:23.290
please do it while
I'm doing the intro.

00:00:23.290 --> 00:00:27.530
But when they are there,
this is a really [INAUDIBLE].

00:00:27.530 --> 00:00:31.570
So I'm working for the
Cultural Institute in Paris.

00:00:31.570 --> 00:00:33.590
And the mission of
the Cultural Institute

00:00:33.590 --> 00:00:36.870
is to help to a
museum, an institution,

00:00:36.870 --> 00:00:42.010
to digitalize and to shared
their culture, their assets

00:00:42.010 --> 00:00:43.790
online.

00:00:43.790 --> 00:00:48.040
We are working with
more than 1,000 museums.

00:00:48.040 --> 00:00:50.410
And it means that if
you want to discover

00:00:50.410 --> 00:00:56.100
a new museum every week, it
will take you 20 years to do so.

00:00:56.100 --> 00:00:58.420
What we do in the Cultural
Institute is this app.

00:00:58.420 --> 00:01:01.620
It's named the Google
Arts and Culture App.

00:01:01.620 --> 00:01:03.020
It's really a beautiful app.

00:01:03.020 --> 00:01:06.990
And if you have not
downloaded yet, you should do.

00:01:06.990 --> 00:01:09.520
There are a ton of really
incredible features.

00:01:09.520 --> 00:01:13.330
And one of my favorites
is named Gigapixel.

00:01:13.330 --> 00:01:18.910
Gigapixel is done
using the art camera.

00:01:18.910 --> 00:01:22.010
And the art camera
is able to catch

00:01:22.010 --> 00:01:26.090
every detail in a painting-- so
every crack, every blue stuff,

00:01:26.090 --> 00:01:28.315
you can see them in the app.

00:01:28.315 --> 00:01:31.930
You can zoom in very
deeply in the app, to see,

00:01:31.930 --> 00:01:34.750
for instance, "Starry Night."

00:01:34.750 --> 00:01:36.600
But I'm not working on this app.

00:01:36.600 --> 00:01:38.704
I'm working in a
space named The Lab.

00:01:38.704 --> 00:01:39.870
It's in the middle of Paris.

00:01:39.870 --> 00:01:41.730
It's a beautiful space.

00:01:41.730 --> 00:01:44.980
I feel lucky every
day when I go there.

00:01:44.980 --> 00:01:48.500
And it's a space
dedicated for creativity.

00:01:48.500 --> 00:01:55.320
And just as a fun fact, it's
where the Cardboard is born.

00:01:55.320 --> 00:01:57.830
David Coz and I
use a laser cutter

00:01:57.830 --> 00:02:01.140
there to create the very first
Cardboard-- the one that was

00:02:01.140 --> 00:02:03.250
unveiled at I/O two years ago.

00:02:03.250 --> 00:02:06.070
That's what I have
to show today.

00:02:06.070 --> 00:02:07.861
And last year, we also
worked at the lab,

00:02:07.861 --> 00:02:09.110
for instance, on this picture.

00:02:09.110 --> 00:02:12.090
You can see some early
prototype of the Cardboard

00:02:12.090 --> 00:02:15.320
that was unveiled at
I/O Google last year.

00:02:15.320 --> 00:02:17.650
But here for the
Cardboard today,

00:02:17.650 --> 00:02:21.260
even if I have still a strange
relationship with the VR team,

00:02:21.260 --> 00:02:26.210
I also have a small team in
Paris that's is named CILEx.

00:02:26.210 --> 00:02:29.200
It stands for Cultural
Institute Experiment Team.

00:02:29.200 --> 00:02:31.630
And what we do,
we do experiments

00:02:31.630 --> 00:02:34.900
with creative
[INAUDIBLE] and artists.

00:02:34.900 --> 00:02:39.100
We are very passionate
about three different axes.

00:02:39.100 --> 00:02:43.360
We try to engage more
people to enjoy culture.

00:02:43.360 --> 00:02:48.500
So we try to find fun ways for
people to watch more paintings.

00:02:48.500 --> 00:02:52.200
We try to find also a new
way to organize information.

00:02:52.200 --> 00:02:56.520
So our user can have a
journey in our database,

00:02:56.520 --> 00:02:59.900
and [INAUDIBLE] can learn
something out of it.

00:02:59.900 --> 00:03:02.340
And obviously, because we
have seven million assets

00:03:02.340 --> 00:03:03.920
in the database,
we try to analyze

00:03:03.920 --> 00:03:06.095
them to discover new insights.

00:03:08.880 --> 00:03:13.060
So this talk is about
machine learning, obviously.

00:03:13.060 --> 00:03:18.802
And just take 30 seconds to
remind of the definition.

00:03:18.802 --> 00:03:20.510
Just to make things
simple, let's imagine

00:03:20.510 --> 00:03:22.430
that you are
writing an algorithm

00:03:22.430 --> 00:03:26.640
to check if a picture
is a cat picture.

00:03:26.640 --> 00:03:28.050
You can do it
yourself, by trying

00:03:28.050 --> 00:03:30.430
to analyze all the pixels
one by one, but obviously,

00:03:30.430 --> 00:03:35.110
it's difficult. Or what you can
do is, using machine learning,

00:03:35.110 --> 00:03:39.740
having an algorithm that
will learn by itself

00:03:39.740 --> 00:03:42.960
what are the good
features to check

00:03:42.960 --> 00:03:48.580
if a picture is a cat picture.

00:03:48.580 --> 00:03:54.910
So the key, I think, is
this is happening now.

00:03:54.910 --> 00:03:56.670
Machine learning
is not the future.

00:03:56.670 --> 00:03:59.290
Machine learning is something
that everybody in this audience

00:03:59.290 --> 00:04:00.560
can do, can try.

00:04:00.560 --> 00:04:04.120
If you know how to code, you
can try machine learning.

00:04:04.120 --> 00:04:06.290
For example, did
you know that you

00:04:06.290 --> 00:04:11.050
can create some "Mario Brothers"
levels just using a [INAUDIBLE]

00:04:11.050 --> 00:04:11.790
networks.

00:04:11.790 --> 00:04:15.950
Or you can make a color
movie from a black and white.

00:04:15.950 --> 00:04:19.459
Or you can make a 3D
movie from a 2D movie.

00:04:19.459 --> 00:04:22.580
So things that seem
difficult or impossible

00:04:22.580 --> 00:04:25.330
are something that you can
do now using machine learning

00:04:25.330 --> 00:04:27.360
and neural networks.

00:04:27.360 --> 00:04:30.460
And as an example, this one
is "Inside the Brother."

00:04:30.460 --> 00:04:34.480
It's David R from Japan,
designer and artist.

00:04:34.480 --> 00:04:36.420
And he just decided to
make these simple games

00:04:36.420 --> 00:04:38.430
with two volley players.

00:04:38.430 --> 00:04:42.040
And in fact, they play
extremely well just

00:04:42.040 --> 00:04:44.160
using a very, very
simple neural network

00:04:44.160 --> 00:04:48.410
that he displays on the screen.

00:04:48.410 --> 00:04:54.420
So because machine learning is
so useful and widespread now,

00:04:54.420 --> 00:04:57.740
there is no doubt that it
will have a huge impact

00:04:57.740 --> 00:05:01.680
on art and on artists.

00:05:01.680 --> 00:05:04.720
So that's why we decide
something like one year

00:05:04.720 --> 00:05:09.070
ago to create a machine
learning residency in the lab.

00:05:09.070 --> 00:05:13.870
So we asked artists to join us
and to create great experience.

00:05:13.870 --> 00:05:18.820
So now I will leave to Mario
Klingemann with our latest

00:05:18.820 --> 00:05:20.083
artist in residence.

00:05:20.083 --> 00:05:21.583
MARIO KLINGEMANN:
Thank you, Damien.

00:05:21.583 --> 00:05:25.530
[APPLAUSE]

00:05:25.530 --> 00:05:26.220
Hi, everybody.

00:05:26.220 --> 00:05:27.850
My name's Mario Klingemann.

00:05:27.850 --> 00:05:29.310
And I'm a code artists.

00:05:29.310 --> 00:05:33.710
And might sound like I'm kind
of really good at indentation

00:05:33.710 --> 00:05:35.260
or write beautiful code.

00:05:35.260 --> 00:05:37.760
But that's not
really what it is.

00:05:37.760 --> 00:05:42.220
It just says that I'm using
code and algorithms to produce

00:05:42.220 --> 00:05:43.520
things that look interesting.

00:05:43.520 --> 00:05:45.720
And some of them might
even be called art.

00:05:45.720 --> 00:05:48.880
I don't know-- I'm not
the one to decide that.

00:05:48.880 --> 00:05:52.780
Like any other artist,
I have this problem.

00:05:52.780 --> 00:05:55.680
You look around you, and
it looks like everything

00:05:55.680 --> 00:05:56.990
has already been done.

00:05:56.990 --> 00:06:01.590
I mean, in times of Google,
you come up with a great idea,

00:06:01.590 --> 00:06:04.730
you Google it, and think,
oh, well, OK, done already.

00:06:04.730 --> 00:06:07.640
So it seems there are no
empty spaces anymore--

00:06:07.640 --> 00:06:09.840
no white spaces where
you can make your mark,

00:06:09.840 --> 00:06:12.920
where you can kind
of be original.

00:06:12.920 --> 00:06:16.460
On the other hand,
if you look at it,

00:06:16.460 --> 00:06:19.470
there are no real-- humans
are incapable of having

00:06:19.470 --> 00:06:20.550
original ideas.

00:06:20.550 --> 00:06:24.610
Ideas are always just
recombination of something

00:06:24.610 --> 00:06:26.400
some other people
have done before.

00:06:26.400 --> 00:06:28.580
You take concept
A and constant B,

00:06:28.580 --> 00:06:32.300
and the idea is finding a
new connection between them.

00:06:32.300 --> 00:06:35.050
And so this is where, for
me, the computer can help

00:06:35.050 --> 00:06:37.240
me finding these connections.

00:06:37.240 --> 00:06:39.370
So in theory, all
I have to do is

00:06:39.370 --> 00:06:41.540
go through every
possible permutation.

00:06:41.540 --> 00:06:44.520
And the computer will offer
me new combinations that,

00:06:44.520 --> 00:06:46.510
hopefully, not have been done.

00:06:46.510 --> 00:06:48.930
And all I have to
do is sit back,

00:06:48.930 --> 00:06:52.120
and let the whatever
it has created pass by,

00:06:52.120 --> 00:06:54.030
and decide if I like it or not.

00:06:54.030 --> 00:06:59.060
So in a way, I'm becoming more
of a curator than a creator.

00:06:59.060 --> 00:07:00.440
I'll show you a short example.

00:07:00.440 --> 00:07:05.600
So this is a tool I call Ernst.

00:07:05.600 --> 00:07:09.820
It's a kind of an homage
to Max Ernst, an artist

00:07:09.820 --> 00:07:15.700
famous for his surreal collages
back in the early 20th century.

00:07:15.700 --> 00:07:19.330
And what he did, he created
these collages from things

00:07:19.330 --> 00:07:22.960
he found in papers, and
catalogs, et cetera.

00:07:22.960 --> 00:07:26.200
So I decided, well, maybe I'll
build my own collage tool.

00:07:26.200 --> 00:07:28.680
And in this case,
I'm using assets

00:07:28.680 --> 00:07:32.150
found in the vast collection
of public domain images

00:07:32.150 --> 00:07:34.800
by the Internet Archive.

00:07:34.800 --> 00:07:37.410
And I wrote me a tool that
helps me to automatically

00:07:37.410 --> 00:07:38.410
cut them out.

00:07:38.410 --> 00:07:41.440
And then I say, OK, if I give
you these five elements, what

00:07:41.440 --> 00:07:43.130
can you do with them?

00:07:43.130 --> 00:07:45.810
And then it produces
me stuff like these.

00:07:45.810 --> 00:07:48.720
And unlike Max Ernst,
I have the possibility

00:07:48.720 --> 00:07:52.130
to also scale material.

00:07:52.130 --> 00:07:53.370
And then you get these.

00:07:53.370 --> 00:07:55.880
If you have like pipes,
you get fractal structures,

00:07:55.880 --> 00:07:57.620
things that look like plants.

00:07:57.620 --> 00:07:59.120
And the process
is very like this.

00:07:59.120 --> 00:08:01.860
I have this tool with
all the library elements,

00:08:01.860 --> 00:08:05.310
and then it just starts
combining them in random ways.

00:08:05.310 --> 00:08:07.600
And sometimes, I see
something that I like.

00:08:07.600 --> 00:08:11.380
Very often I see things
that are just horrible,

00:08:11.380 --> 00:08:14.100
or just total chaos.

00:08:14.100 --> 00:08:17.230
But yet, sometimes there's
something that looks like this.

00:08:17.230 --> 00:08:19.840
I call that, for example,
"Run, Hipster, Run."

00:08:19.840 --> 00:08:23.520
And I must say, coming
up with funny titles

00:08:23.520 --> 00:08:26.500
or very interesting titles
is, of course, a nice perk

00:08:26.500 --> 00:08:28.282
of this way of working.

00:08:28.282 --> 00:08:29.990
But of course, there's
still this problem

00:08:29.990 --> 00:08:33.480
that I still have to look
through a lot of images which

00:08:33.480 --> 00:08:36.990
are just noise, just chaos.

00:08:36.990 --> 00:08:39.690
So wouldn't it be nice
if the machine could

00:08:39.690 --> 00:08:43.020
learn what I like, what my
tastes are, or, even better,

00:08:43.020 --> 00:08:44.150
what other people like.

00:08:44.150 --> 00:08:46.780
And then I can sell them better.

00:08:46.780 --> 00:08:50.640
So I realized I have
to first understand

00:08:50.640 --> 00:08:53.950
what do humans find
interesting in images?

00:08:53.950 --> 00:08:58.040
What is it that makes one image
more artful than another one?

00:08:58.040 --> 00:09:02.480
And this directed my view
to this growing amount

00:09:02.480 --> 00:09:03.750
of digital archives.

00:09:03.750 --> 00:09:07.900
And those are now-- there are
lots of museums and libraries

00:09:07.900 --> 00:09:10.700
out there that start
digitizing all their old books

00:09:10.700 --> 00:09:13.270
and paintings, just like
the Cultural Institute

00:09:13.270 --> 00:09:15.360
helps museums doing that.

00:09:15.360 --> 00:09:18.550
And so I first stumbled upon
this about two years ago,

00:09:18.550 --> 00:09:22.310
when the British Library
uploaded one million images

00:09:22.310 --> 00:09:25.400
that were automatically
extracted from books spanning

00:09:25.400 --> 00:09:28.680
from 1500 to 1899.

00:09:28.680 --> 00:09:32.570
There was only a little
kind of a problem with it,

00:09:32.570 --> 00:09:35.710
because all these
illustrations and photos

00:09:35.710 --> 00:09:37.400
were cut out automatically.

00:09:37.400 --> 00:09:41.940
So they had OCR
scans, and then they

00:09:41.940 --> 00:09:44.050
knew there would be an
image in a certain area.

00:09:44.050 --> 00:09:47.000
But unless you didn't look
yourself at the image,

00:09:47.000 --> 00:09:49.120
you wouldn't know
what's actually on it.

00:09:49.120 --> 00:09:50.590
So if you were
looking for, let's

00:09:50.590 --> 00:09:52.580
say, a portrait of
Shakespeare, you

00:09:52.580 --> 00:09:54.510
would have to manually
go through every image

00:09:54.510 --> 00:09:56.940
until you maybe struck upon it.

00:09:56.940 --> 00:09:58.910
So I thought that's
a bit tricky.

00:09:58.910 --> 00:10:03.760
Maybe I can help them with
classifying their material,

00:10:03.760 --> 00:10:05.320
and training the computer.

00:10:05.320 --> 00:10:06.470
OK, this is a portrait.

00:10:06.470 --> 00:10:07.880
This is a map.

00:10:07.880 --> 00:10:13.270
So I started in a way figuring
out ways how I could do that.

00:10:13.270 --> 00:10:16.750
And eventually,
I was able to tag

00:10:16.750 --> 00:10:18.880
about 400,000 images for them.

00:10:18.880 --> 00:10:20.740
I mean, this was a
kind of group effort.

00:10:20.740 --> 00:10:22.460
Everybody could join in.

00:10:22.460 --> 00:10:25.550
But working with this
material, I realized,

00:10:25.550 --> 00:10:28.754
is such a joyful experience,
because in the beginning,

00:10:28.754 --> 00:10:30.670
I was just interested
in the machine learning.

00:10:30.670 --> 00:10:33.040
But actually, you
suddenly realize

00:10:33.040 --> 00:10:38.100
there's this goldmine,
this huge mine of material.

00:10:38.100 --> 00:10:41.310
And sometimes, really,
you go through lots

00:10:41.310 --> 00:10:43.860
of things that seem to be boring
or you're not interested in.

00:10:43.860 --> 00:10:46.930
And then you strike upon
a beautiful illustration

00:10:46.930 --> 00:10:48.260
or something.

00:10:48.260 --> 00:10:53.210
And I realized that is
actually a huge part

00:10:53.210 --> 00:10:54.890
of the fun of the process.

00:10:54.890 --> 00:10:59.290
So for example, take
this rock or stone axe.

00:10:59.290 --> 00:11:01.430
Well, once you go
through this material,

00:11:01.430 --> 00:11:03.090
you start recognizing patterns.

00:11:03.090 --> 00:11:05.640
And so sometimes there
comes this rock by.

00:11:05.640 --> 00:11:07.710
And you say, OK,
well, I don't care.

00:11:07.710 --> 00:11:09.910
But then the second one,
and you say, oh, maybe I

00:11:09.910 --> 00:11:13.970
should start at a rock
collection or rock category.

00:11:13.970 --> 00:11:16.210
And then what
happens is, suddenly

00:11:16.210 --> 00:11:20.260
you are happy when every time
you come another one of those.

00:11:20.260 --> 00:11:23.340
And then, well,
what I do is I start

00:11:23.340 --> 00:11:27.070
arranging them, and putting
them kind of in a new context.

00:11:27.070 --> 00:11:29.310
And then you start
actually starting

00:11:29.310 --> 00:11:33.090
to appreciate the craftsmanship
that went into this.

00:11:33.090 --> 00:11:36.350
And also you can-- once you
put lots of very similar things

00:11:36.350 --> 00:11:38.710
together, you can much
better distinguish

00:11:38.710 --> 00:11:41.760
between the slight
differences in there.

00:11:41.760 --> 00:11:43.050
Yes, so I start doing this.

00:11:43.050 --> 00:11:44.970
For example, here
on the left side,

00:11:44.970 --> 00:11:48.560
you see a piece called
to 36 anonymous profiles.

00:11:48.560 --> 00:11:52.640
There's all these 100s, 1,000s
of geological profiles, which,

00:11:52.640 --> 00:11:55.590
again, you probably, if
you're not interested or are

00:11:55.590 --> 00:11:57.960
a geologist, you wouldn't care.

00:11:57.960 --> 00:12:00.690
But like this, it becomes
a really interesting field

00:12:00.690 --> 00:12:05.110
or just a way to bring these
things that maybe sometimes

00:12:05.110 --> 00:12:08.000
have been hidden for
100 years in a book,

00:12:08.000 --> 00:12:10.050
and nobody has watched them.

00:12:10.050 --> 00:12:12.010
And now you can bring
them back to life.

00:12:12.010 --> 00:12:16.140
Or on the right side, a piece
I call "16 Very Sad Girls."

00:12:16.140 --> 00:12:18.890
Again, I don't
know why they have

00:12:18.890 --> 00:12:20.300
so many sad girls in there.

00:12:20.300 --> 00:12:22.810
But of course, again, that
makes you question what

00:12:22.810 --> 00:12:24.040
was happening at that time?

00:12:24.040 --> 00:12:26.650
So it actually motivates
you to search back

00:12:26.650 --> 00:12:29.960
and, well, what's the
story behind this?

00:12:29.960 --> 00:12:32.960
But this all I started
kind of on my own.

00:12:32.960 --> 00:12:35.229
And this was not-- I
wouldn't say it wasn't

00:12:35.229 --> 00:12:36.520
deep learning what I was doing.

00:12:36.520 --> 00:12:38.540
It was more classical
machine learning.

00:12:38.540 --> 00:12:40.240
Because I was always
a little bit afraid

00:12:40.240 --> 00:12:41.660
of going down this path.

00:12:41.660 --> 00:12:44.230
I heard, oh, you need
expensive machines.

00:12:44.230 --> 00:12:46.950
And it's kind of hard
to set up the machine.

00:12:46.950 --> 00:12:51.180
So I needed something to
get me motivated to go

00:12:51.180 --> 00:12:54.150
through the painful process of
installing everything to get

00:12:54.150 --> 00:12:55.950
a machine learning system.

00:12:55.950 --> 00:12:59.040
Luckily, about a year
ago, this came along.

00:12:59.040 --> 00:13:00.960
I don't know if you
have seen this picture,

00:13:00.960 --> 00:13:03.020
but when I saw it,
thought, oh, my god.

00:13:03.020 --> 00:13:06.990
This looks kind of weird, and
I have never seen this before.

00:13:06.990 --> 00:13:10.790
Fortunately, about a week
later, after this leaked,

00:13:10.790 --> 00:13:15.080
it was clear some
engineers at Google

00:13:15.080 --> 00:13:17.450
had come up with this new
technique called Deep Dream.

00:13:17.450 --> 00:13:19.570
And it's based on
machine learning.

00:13:19.570 --> 00:13:22.920
So of course, I wanted to
know how can I do this myself?

00:13:22.920 --> 00:13:25.240
Fortunately, what they
did-- they actually

00:13:25.240 --> 00:13:27.770
shared an IPython
Notebook on GitHub,

00:13:27.770 --> 00:13:30.630
with all the source code,
even the trained model.

00:13:30.630 --> 00:13:34.350
And it was able to
dig myself into this.

00:13:34.350 --> 00:13:36.500
Back in the days, there
was no TensorFlow flow yet,

00:13:36.500 --> 00:13:38.600
so this was still in Caffe.

00:13:38.600 --> 00:13:43.310
But this allowed me to finally
kind of go by baby steps

00:13:43.310 --> 00:13:45.450
into learning this technique.

00:13:45.450 --> 00:13:49.020
And obviously, I started--
like probably a lot of us--

00:13:49.020 --> 00:13:51.540
I started to having a
lot of fun with this.

00:13:51.540 --> 00:13:53.840
You put in an image, and
you wonder, oh, my god,

00:13:53.840 --> 00:13:55.770
what I get out of this?

00:13:55.770 --> 00:13:57.230
Because that's what it is.

00:13:57.230 --> 00:13:58.340
You put something in.

00:13:58.340 --> 00:14:01.290
You had no idea
what you would get.

00:14:01.290 --> 00:14:05.170
So this was fun for,
let's say, a few weeks.

00:14:05.170 --> 00:14:08.380
But then I started
thinking, OK, I

00:14:08.380 --> 00:14:10.810
think I could make some
improvements to this code.

00:14:10.810 --> 00:14:13.080
And I would call
this Lucid Dreaming--

00:14:13.080 --> 00:14:18.420
so maybe get a little bit more
control or change the outcome.

00:14:18.420 --> 00:14:21.110
So I figured out
there are three points

00:14:21.110 --> 00:14:25.250
I might be able to turn it
into a different direction.

00:14:25.250 --> 00:14:28.300
So the first one-- I'm not
sure if you noticed it--

00:14:28.300 --> 00:14:31.530
these pictures all kind of
a bit psychedelic, colorful.

00:14:31.530 --> 00:14:34.100
So I'm from Germany.

00:14:34.100 --> 00:14:35.640
We are kind of very
earnest people,

00:14:35.640 --> 00:14:38.210
so I like it rather
a bit toned down.

00:14:38.210 --> 00:14:42.230
So very simple thing--
desaturated a bit.

00:14:42.230 --> 00:14:44.030
And desaturation is super easy.

00:14:44.030 --> 00:14:47.150
So all I needed was to add a
single line of code, which is

00:14:47.150 --> 00:14:48.530
the one you see at the bottom.

00:14:48.530 --> 00:14:51.780
What you do is you take the
average between the RGB values.

00:14:51.780 --> 00:14:54.020
And then you can have
a linear interpolation

00:14:54.020 --> 00:14:57.080
between the gray-scale
version and the color version.

00:14:57.080 --> 00:15:00.220
And depending on how
crazy you want it,

00:15:00.220 --> 00:15:02.020
you pick a factor in the middle.

00:15:02.020 --> 00:15:05.590
And so as an example
here, on the left side

00:15:05.590 --> 00:15:12.310
psychedelic Mario, on the right,
the puppy face gray-scale one.

00:15:12.310 --> 00:15:20.010
So the second thing--
that issue that you

00:15:20.010 --> 00:15:21.650
don't know what
you will get out,

00:15:21.650 --> 00:15:23.510
or when you get
something out, it

00:15:23.510 --> 00:15:27.990
will be a selection of
slug, puppy, or eye.

00:15:27.990 --> 00:15:30.780
So can I get a little
bit more control?

00:15:30.780 --> 00:15:33.690
Well, in order to
do that, we have

00:15:33.690 --> 00:15:36.250
to have a look at
how this thing works.

00:15:36.250 --> 00:15:41.010
So this is the classic
convolutional network, which

00:15:41.010 --> 00:15:42.460
is the Google Net in this case.

00:15:42.460 --> 00:15:44.390
That was also the
architecture that

00:15:44.390 --> 00:15:47.370
was used for the early
Deep Dream experiments.

00:15:47.370 --> 00:15:49.100
So what you do,
you put something

00:15:49.100 --> 00:15:51.150
in on the left--
an image-- and it

00:15:51.150 --> 00:15:53.500
passes through all these
convolutional layers,

00:15:53.500 --> 00:15:55.410
and soft Max.

00:15:55.410 --> 00:15:57.150
Well, we don't go
into depth there.

00:15:57.150 --> 00:16:03.100
In the end, you get out what the
machine thinks-- a probability

00:16:03.100 --> 00:16:05.130
for certain categories.

00:16:05.130 --> 00:16:08.330
What Deep Dream does is, you put
in an image at the beginning.

00:16:08.330 --> 00:16:11.900
But then, instead of going
all through all the network,

00:16:11.900 --> 00:16:13.580
you stop at a certain layer.

00:16:13.580 --> 00:16:17.470
And at that layer, there are
certain neurons activated.

00:16:17.470 --> 00:16:21.990
So depending on what the
network thinks it sees there,

00:16:21.990 --> 00:16:25.320
some neurons will get
activated and others will not.

00:16:25.320 --> 00:16:27.860
And what it does is
then it emphasizes

00:16:27.860 --> 00:16:31.550
those activations even more,
and sends it back up the chain.

00:16:31.550 --> 00:16:36.680
And then this will,
in a way, kind of

00:16:36.680 --> 00:16:38.330
emphasize all those elements.

00:16:38.330 --> 00:16:41.860
Where it thought it has
discovered, let's say, a cat.

00:16:41.860 --> 00:16:44.450
Then it will improve the
cattiness of that image.

00:16:48.000 --> 00:16:50.510
If you look at this,
what actually happens

00:16:50.510 --> 00:16:53.720
inside this network-- and
I'm coming from the kind of,

00:16:53.720 --> 00:16:55.480
let's say, a pixel
arts background,

00:16:55.480 --> 00:16:57.200
or I'm doing lots
of with bitmaps.

00:16:57.200 --> 00:16:59.250
So I look at it this way.

00:16:59.250 --> 00:17:02.310
Then it's actually
bitmaps all the way down.

00:17:02.310 --> 00:17:04.819
So in the top
layers, you can still

00:17:04.819 --> 00:17:06.770
see there is some
convolutions going

00:17:06.770 --> 00:17:08.790
on that reminds
you of sharpening

00:17:08.790 --> 00:17:10.569
filters or something.

00:17:10.569 --> 00:17:13.150
The deeper you go down
the net, actually, it

00:17:13.150 --> 00:17:14.859
gets more and more abstract.

00:17:14.859 --> 00:17:18.624
But for me, even those dots
are still little bitmaps.

00:17:18.624 --> 00:17:20.040
And then I can do
stuff with them.

00:17:20.040 --> 00:17:25.569
I can increase the brightness,
reduce or enhance the contrast,

00:17:25.569 --> 00:17:27.310
blur things.

00:17:27.310 --> 00:17:30.290
Or what I also can
do-- I can treat it

00:17:30.290 --> 00:17:32.450
like a brain surgeon in a way.

00:17:32.450 --> 00:17:35.520
Like I poke in, and say,
OK, when I poke in here,

00:17:35.520 --> 00:17:38.450
does the finger
wiggle or the toe?

00:17:38.450 --> 00:17:41.200
And what I can do
then is, I can just

00:17:41.200 --> 00:17:45.470
say, well, how about if
I turn every neuron off

00:17:45.470 --> 00:17:49.210
instead of, maybe, for example,
the 10 most activated ones,

00:17:49.210 --> 00:17:50.660
and send it back up?

00:17:50.660 --> 00:17:52.740
The code to do that is,
again, rather simple.

00:17:52.740 --> 00:17:56.570
So again, each of these
little bitmaps is-- well,

00:17:56.570 --> 00:17:59.380
for me, it's a bitmap or it's
a little array of numbers.

00:17:59.380 --> 00:18:01.540
So what I can do for
each of these cells,

00:18:01.540 --> 00:18:04.630
I just sum up all
the pixels in there.

00:18:04.630 --> 00:18:08.650
Then I sort them by how
much they summed up to.

00:18:08.650 --> 00:18:12.480
And in the end, I just keep the
top 10, for example-- or if I'm

00:18:12.480 --> 00:18:15.890
just interested in a single
category, the most activated

00:18:15.890 --> 00:18:19.370
one-- and replace all
the other values with 0,

00:18:19.370 --> 00:18:20.710
and send it back up.

00:18:20.710 --> 00:18:23.620
What I get then is something
that looks like this.

00:18:23.620 --> 00:18:26.770
So it's kind of just
reducing everything

00:18:26.770 --> 00:18:30.797
to a single category the
network thinks to have seen.

00:18:30.797 --> 00:18:32.880
And I like these, really,
because they are, again,

00:18:32.880 --> 00:18:34.280
totally out of this world.

00:18:34.280 --> 00:18:37.090
Some remind me of
organic patterns.

00:18:37.090 --> 00:18:39.500
Sometimes you can see,
OK, this might have come

00:18:39.500 --> 00:18:42.150
from an eye detector or so.

00:18:42.150 --> 00:18:46.500
But definitely, it
doesn't contain any traces

00:18:46.500 --> 00:18:50.570
of slugs or eyes again.

00:18:50.570 --> 00:18:52.780
But of course, there's
still this other issue.

00:18:52.780 --> 00:18:56.500
And I call it the PuppyLeak,
or rather, I kind of

00:18:56.500 --> 00:19:00.120
reveal why are there
so many puppies?

00:19:00.120 --> 00:19:05.490
Like why does Deep Dream
have such a love for puppies?

00:19:05.490 --> 00:19:08.970
Well, the reason is
that their network--

00:19:08.970 --> 00:19:11.290
the original network--
that was used

00:19:11.290 --> 00:19:13.870
for the first
release of Deep Dream

00:19:13.870 --> 00:19:18.150
was based on the ImageNet
Large Scale Visual Recognition

00:19:18.150 --> 00:19:21.730
Competition, which is kind
of the Olympics of image

00:19:21.730 --> 00:19:22.670
recognition.

00:19:22.670 --> 00:19:27.880
And in 2014, what they did--
they added 150 new categories.

00:19:27.880 --> 00:19:30.740
And it was all dog breeds.

00:19:30.740 --> 00:19:35.030
So that old rule applies--
gerbil in, gerbil out.

00:19:35.030 --> 00:19:38.840
So whatever you train it with,
that's what you will get.

00:19:38.840 --> 00:19:41.600
So then I thought,
OK, maybe I just

00:19:41.600 --> 00:19:45.180
have to train this network
with something else.

00:19:45.180 --> 00:19:49.090
But then kind of new to
it, I heard these stories

00:19:49.090 --> 00:19:52.720
that it takes four weeks
on a super-powerful GPU

00:19:52.720 --> 00:19:53.920
to train a network.

00:19:53.920 --> 00:19:56.310
And I'm a poor artist.

00:19:56.310 --> 00:20:00.680
I can't afford an NVIDIA
rack with these things.

00:20:00.680 --> 00:20:02.314
But then I came
across this technique

00:20:02.314 --> 00:20:03.480
which is really astonishing.

00:20:03.480 --> 00:20:05.660
It's called fine tuning.

00:20:05.660 --> 00:20:07.840
And what it does
is, you can take

00:20:07.840 --> 00:20:11.940
an already trained network,
for example, the Google Net.

00:20:11.940 --> 00:20:15.590
And all you have to do is
to cut off the bottom layer.

00:20:15.590 --> 00:20:19.340
And then you can retrain
it with new material.

00:20:19.340 --> 00:20:21.910
And what happens is,
all the top layers

00:20:21.910 --> 00:20:24.390
are pretty much the same, no
matter what you train it with,

00:20:24.390 --> 00:20:27.660
because they look for
abstract elements like edges,

00:20:27.660 --> 00:20:29.520
curvature, or things like that.

00:20:29.520 --> 00:20:31.800
So that doesn't need
to be retrained.

00:20:31.800 --> 00:20:35.010
So doing that, you can
take a trained network.

00:20:35.010 --> 00:20:36.600
You feed in new images.

00:20:36.600 --> 00:20:38.390
Instead of taking
four weeks, you

00:20:38.390 --> 00:20:40.410
can train a network overnight.

00:20:40.410 --> 00:20:44.240
And the way I do it--
well, I tried it with I

00:20:44.240 --> 00:20:47.880
called it MNIST with a twist.

00:20:47.880 --> 00:20:50.180
I in my works with
these archives,

00:20:50.180 --> 00:20:53.320
I come across a lot of
these decorative initials.

00:20:53.320 --> 00:20:57.840
And I thought, is there
a way I could actually

00:20:57.840 --> 00:21:01.750
train it to recognize
A, B, C that

00:21:01.750 --> 00:21:03.510
come in all different
kinds of shapes?

00:21:03.510 --> 00:21:05.090
Well, I tried.

00:21:05.090 --> 00:21:08.750
And I must admit, there is
a manual process involved.

00:21:08.750 --> 00:21:13.420
Because what I have to
do is, the way I do it,

00:21:13.420 --> 00:21:15.840
I really start folders
on my hard drive,

00:21:15.840 --> 00:21:20.050
and go manually, and drag and
drop whatever I find in this.

00:21:20.050 --> 00:21:23.240
Let's say, oh, another A.
I drop in the A folder.

00:21:23.240 --> 00:21:26.070
I don't have to do this with
the thousands of images.

00:21:26.070 --> 00:21:27.610
Actually, it turns
out I can just

00:21:27.610 --> 00:21:31.370
start with-- it's enough to
take 50 for each category.

00:21:31.370 --> 00:21:34.342
I'm pretty sure there are people
who know much more than me

00:21:34.342 --> 00:21:35.300
about machine learning.

00:21:35.300 --> 00:21:37.091
They say, oh, my god,
that will never work,

00:21:37.091 --> 00:21:38.430
and it will totally overfit.

00:21:38.430 --> 00:21:39.420
It doesn't matter.

00:21:39.420 --> 00:21:41.030
Actually, it works.

00:21:41.030 --> 00:21:46.160
So I start with just let's say
20 to 50 images per category,

00:21:46.160 --> 00:21:50.700
and then train the network
using the fine-tuning technique.

00:21:50.700 --> 00:21:53.290
I let it kind of
simmer for two hours,

00:21:53.290 --> 00:21:56.940
so it gets a little bit
accustomed to the data.

00:21:56.940 --> 00:21:59.950
And then I use this
to show me what

00:21:59.950 --> 00:22:01.470
it thinks these letters are.

00:22:01.470 --> 00:22:04.960
So I train it a bit.

00:22:04.960 --> 00:22:07.130
I give it a bunch
of random images.

00:22:07.130 --> 00:22:09.943
And it says, I think it's an
A. I say, no, it's not an A.

00:22:09.943 --> 00:22:10.900
And then a B?

00:22:10.900 --> 00:22:11.540
Oh, yes.

00:22:11.540 --> 00:22:14.170
And actually, it gets
better and better.

00:22:14.170 --> 00:22:16.530
Because what I do is,
whenever it finds something,

00:22:16.530 --> 00:22:18.440
it gets added to
my training set.

00:22:18.440 --> 00:22:21.910
And I can repeat this process.

00:22:21.910 --> 00:22:27.370
And in order to kind of help
me with this process of saying,

00:22:27.370 --> 00:22:32.250
yes/no, I realized that kind
of left-swipe right-swipe

00:22:32.250 --> 00:22:36.050
is a real popular way to decide
if you are into a specimen

00:22:36.050 --> 00:22:36.810
or not.

00:22:36.810 --> 00:22:40.560
And it's actually
a super-fast way.

00:22:40.560 --> 00:22:43.810
So I can go back and
forth, and in one hour

00:22:43.810 --> 00:22:49.370
I think I can go through 1,000
images and say if it's correct

00:22:49.370 --> 00:22:50.650
or not.

00:22:50.650 --> 00:22:53.320
And as a result-- so
for example here, this

00:22:53.320 --> 00:22:57.500
is stuff where it has correctly
recognized that it's an A.

00:22:57.500 --> 00:23:01.100
And you can see, it's
really surprising.

00:23:01.100 --> 00:23:03.440
It comes in so many
different shapes

00:23:03.440 --> 00:23:07.040
that, well, it's just
amazing how powerful

00:23:07.040 --> 00:23:08.920
these networks are.

00:23:08.920 --> 00:23:12.000
Then sometimes, it gives
me something like this.

00:23:12.000 --> 00:23:14.650
And I don't know.

00:23:14.650 --> 00:23:16.120
It looks like a ruin to me.

00:23:16.120 --> 00:23:22.570
So the machine said it's a
B. And then I said, no, hmm.

00:23:22.570 --> 00:23:25.340
So I actually went to the
original scan in the book

00:23:25.340 --> 00:23:26.470
to check it out.

00:23:26.470 --> 00:23:30.410
And indeed, it is a B
So it's really magic.

00:23:30.410 --> 00:23:32.860
And of course, if everything
you have is a hammer,

00:23:32.860 --> 00:23:34.180
everything looks like a nail.

00:23:34.180 --> 00:23:36.510
It start seeing
letters in everything.

00:23:36.510 --> 00:23:39.730
So it gives me these things.

00:23:39.730 --> 00:23:42.420
But again, it's beautiful,
so maybe something I

00:23:42.420 --> 00:23:44.160
have not been looking for.

00:23:44.160 --> 00:23:46.510
But of course, I was
about Deep Dreaming.

00:23:46.510 --> 00:23:50.090
So this is then what
happens if I use this newly

00:23:50.090 --> 00:23:53.030
trained network on material.

00:23:53.030 --> 00:23:54.960
And you can definitely
see it takes

00:23:54.960 --> 00:23:56.210
an entirely different twist.

00:23:56.210 --> 00:23:59.220
It suddenly has this
typographic feel to it.

00:23:59.220 --> 00:24:04.650
And another example-- not
sure if you recognize the lady

00:24:04.650 --> 00:24:06.740
on the left and the right.

00:24:06.740 --> 00:24:09.730
But it's actually
the Mona Lisa in,

00:24:09.730 --> 00:24:12.610
let's say it has a
linocut aspect to me.

00:24:12.610 --> 00:24:16.740
But yes, there's no more
puppies involved at all.

00:24:16.740 --> 00:24:21.960
But OK, one more
thing-- Deep Dream

00:24:21.960 --> 00:24:25.080
had this great opportunity
in the spring this year,

00:24:25.080 --> 00:24:29.470
where the Grey Area Foundation
located in San Francisco

00:24:29.470 --> 00:24:32.420
was doing a charity auction
to fund their projects.

00:24:32.420 --> 00:24:36.040
And I was really honored
to be invited to contribute

00:24:36.040 --> 00:24:37.610
some artworks there.

00:24:37.610 --> 00:24:41.550
So I kind of ate my
own dog food and tried

00:24:41.550 --> 00:24:44.520
to create something that is
not obviously Deep Dream.

00:24:44.520 --> 00:24:46.610
So I created this piece
called "The Archimedes

00:24:46.610 --> 00:24:51.940
Principle," which reminds me
of a ball floating in water.

00:24:51.940 --> 00:24:55.240
But the one thing I didn't
mention yet is my residency.

00:24:55.240 --> 00:24:57.180
And the reason is,
it just started.

00:24:57.180 --> 00:25:01.320
But I can tell you, I feel
like a child in a candy store.

00:25:01.320 --> 00:25:02.560
It's really amazing.

00:25:02.560 --> 00:25:05.830
I have this huge amount
of data to play with.

00:25:05.830 --> 00:25:08.220
I have kind of metadata.

00:25:08.220 --> 00:25:10.850
I have super-smart
people-- much smarter

00:25:10.850 --> 00:25:13.860
than me-- that I can ask
extremely stupid questions.

00:25:13.860 --> 00:25:16.280
And I've already
started working,

00:25:16.280 --> 00:25:19.450
but it's still something
I want to fine-tune.

00:25:19.450 --> 00:25:23.010
But I also had the privilege
to see what Cyril was actually

00:25:23.010 --> 00:25:24.360
doing there for a while.

00:25:24.360 --> 00:25:27.480
And so, with no
further ado, let's

00:25:27.480 --> 00:25:32.130
get Cyril onstage so he can
show you some awesome things.

00:25:32.130 --> 00:25:32.630
Thank you.

00:25:32.630 --> 00:25:33.499
[APPLAUSE]

00:25:33.499 --> 00:25:34.790
CYRIL DIAGNE: Thank you, Mario.

00:25:34.790 --> 00:25:38.680
Well, my name is Cyril Diagne.

00:25:38.680 --> 00:25:41.510
And I'm a digital
interaction artist.

00:25:41.510 --> 00:25:45.620
So a question I get often is,
what is a digital interaction

00:25:45.620 --> 00:25:46.330
artist?

00:25:46.330 --> 00:25:48.550
So it's actually very simple.

00:25:48.550 --> 00:25:51.890
I try to create poetic
moments for people

00:25:51.890 --> 00:25:54.710
when they are interacting
with digital systems.

00:25:54.710 --> 00:25:57.750
And the process is
also fairly simple.

00:25:57.750 --> 00:26:00.490
It basically boils
down to two steps.

00:26:00.490 --> 00:26:04.090
One step is just
plain, really-- just

00:26:04.090 --> 00:26:07.220
like a kid getting my
hands on some technology,

00:26:07.220 --> 00:26:08.870
and playing without
any goal, just

00:26:08.870 --> 00:26:13.040
for the pleasure of learning
new things and having fun.

00:26:13.040 --> 00:26:16.420
And then sometimes, a
poetic outcome appears.

00:26:16.420 --> 00:26:19.470
And what that lets you
do is, for example,

00:26:19.470 --> 00:26:23.830
swing through the stars,
or having your face covered

00:26:23.830 --> 00:26:29.030
with some generative masks,
or creating a video of people

00:26:29.030 --> 00:26:32.300
dancing together,
and so on, and so on,

00:26:32.300 --> 00:26:35.640
and other things that I've
been doing over the last years.

00:26:35.640 --> 00:26:40.730
But you might be wondering, OK,
what about machine learning?

00:26:40.730 --> 00:26:43.900
It turns out one year ago,
I didn't know anything

00:26:43.900 --> 00:26:44.910
about machine learning.

00:26:44.910 --> 00:26:48.520
It all started when
Damien came to me.

00:26:48.520 --> 00:26:51.140
He asked me, hi,
Cyril, how are you?

00:26:51.140 --> 00:26:52.260
I'm good, thanks.

00:26:52.260 --> 00:26:52.760
How are you?

00:26:52.760 --> 00:26:54.200
Not too bad.

00:26:54.200 --> 00:26:58.450
And he asked me, what
can you do with seven

00:26:58.450 --> 00:26:59.995
million cultural artifacts?

00:27:03.110 --> 00:27:05.330
I had to stop for a moment.

00:27:05.330 --> 00:27:07.710
What do you mean seven
million cultural artifacts?

00:27:07.710 --> 00:27:08.719
What can I do?

00:27:08.719 --> 00:27:10.510
He said, yeah, well,
the Cultural Institute

00:27:10.510 --> 00:27:12.410
has been working
for several years

00:27:12.410 --> 00:27:13.600
with thousands of partners.

00:27:13.600 --> 00:27:16.580
We have this great database
with amazing content.

00:27:16.580 --> 00:27:18.600
Well, what can you do with it?

00:27:18.600 --> 00:27:21.040
Well, I really had to
stop, because those

00:27:21.040 --> 00:27:25.400
are seven million opportunities
to learn something new

00:27:25.400 --> 00:27:27.950
about a culture,
about some events--

00:27:27.950 --> 00:27:30.650
really incredibly
high-quality content.

00:27:30.650 --> 00:27:33.960
So in order not to panic,
I did what every coder

00:27:33.960 --> 00:27:35.760
would do in this situation.

00:27:35.760 --> 00:27:38.850
I [INAUDIBLE] all the assets and
plotted to them in a sine wave.

00:27:38.850 --> 00:27:42.450
Because then, I did not have
to think about it anymore.

00:27:42.450 --> 00:27:43.850
That was done.

00:27:43.850 --> 00:27:48.580
And from there, well, I did
the most obvious things.

00:27:48.580 --> 00:27:52.560
I started to plot them by
time, by color, by medium.

00:27:52.560 --> 00:27:54.477
And, well, you find
some interesting things

00:27:54.477 --> 00:27:55.060
along the way.

00:27:55.060 --> 00:27:57.640
But you can't help
but think there's

00:27:57.640 --> 00:28:00.720
got to be more-- all
this great material, all

00:28:00.720 --> 00:28:02.490
this great technology--
there's got to be

00:28:02.490 --> 00:28:06.010
more that we can get out of it.

00:28:06.010 --> 00:28:10.930
And so this is where machine
learning came across.

00:28:10.930 --> 00:28:14.060
Especially when you go
to Google every day,

00:28:14.060 --> 00:28:16.020
doesn't take too long
until someone points you

00:28:16.020 --> 00:28:18.010
to some amazing things.

00:28:18.010 --> 00:28:23.220
And so one of the first
experiments that we did

00:28:23.220 --> 00:28:25.650
is using a popular
technology now,

00:28:25.650 --> 00:28:27.530
which is the machine
learning annotation.

00:28:27.530 --> 00:28:28.970
So it's the
technology that allows

00:28:28.970 --> 00:28:32.030
you to find the photos
that you took in the forest

00:28:32.030 --> 00:28:37.010
by typing "trees," the photos
of my friend Tony, et cetera.

00:28:37.010 --> 00:28:40.582
But what about the less
expected labels-- the labels

00:28:40.582 --> 00:28:42.790
you would not think in the
first place to write down?

00:28:42.790 --> 00:28:46.540
And what about less-expected
images as well--

00:28:46.540 --> 00:28:49.990
images that you would not
expect to find anywhere there?

00:28:49.990 --> 00:28:52.260
Well, we were curious as well.

00:28:52.260 --> 00:28:55.950
So we sent it all
over to the service.

00:28:55.950 --> 00:28:58.030
And when we got
the results back,

00:28:58.030 --> 00:28:59.464
well, I fell off my chair.

00:28:59.464 --> 00:29:00.130
I will show you.

00:29:00.130 --> 00:29:04.430
Can we get onto the demo?

00:29:04.430 --> 00:29:06.110
So basically, what
we can see here

00:29:06.110 --> 00:29:12.270
is that we got back around
4,000 different unique labels.

00:29:12.270 --> 00:29:14.490
And we had to spend hours.

00:29:14.490 --> 00:29:16.160
It was too amazing.

00:29:16.160 --> 00:29:18.960
The things that were detected
were really incredible.

00:29:18.960 --> 00:29:22.150
Let's go over one example
that you would expect to work,

00:29:22.150 --> 00:29:24.270
because it does, but in
quite an amazing way.

00:29:24.270 --> 00:29:27.962
So let's look for horses.

00:29:27.962 --> 00:29:30.680
There.

00:29:30.680 --> 00:29:34.130
So as you can see, some
beautiful artworks of horse.

00:29:34.130 --> 00:29:36.650
Let's just take this one, for
example-- beautiful painting

00:29:36.650 --> 00:29:39.220
from Xia Xiaowan.

00:29:39.220 --> 00:29:41.200
It's quite incredible,
because I don't

00:29:41.200 --> 00:29:46.100
know how he got his
inspiration to picture horses

00:29:46.100 --> 00:29:48.220
from this angle,
because I didn't even

00:29:48.220 --> 00:29:51.510
know it was possible, or
how the machine managed

00:29:51.510 --> 00:29:53.750
to detect that it was a horse.

00:29:53.750 --> 00:29:55.840
But it does.

00:29:55.840 --> 00:29:58.520
And, well, it's quite amazing.

00:29:58.520 --> 00:30:03.890
And also, you get examples
after examples of, well,

00:30:03.890 --> 00:30:05.940
really incredible
things like this,

00:30:05.940 --> 00:30:08.900
for example, calligraphic
artwork of, again, a horse.

00:30:08.900 --> 00:30:11.990
But that really goes toward
the abstract representation

00:30:11.990 --> 00:30:13.720
from Yuan Xikun.

00:30:13.720 --> 00:30:17.580
And again, a beautiful
artwork, but it quite blows

00:30:17.580 --> 00:30:21.310
my mind that now algorithms
are capable of distinguishing

00:30:21.310 --> 00:30:26.750
this much amount of
details in these images.

00:30:26.750 --> 00:30:31.060
So unfortunately, I can't
go over all those examples.

00:30:31.060 --> 00:30:34.470
But we are going to
release this online soon.

00:30:34.470 --> 00:30:37.610
So please take a day off
to go through all of them,

00:30:37.610 --> 00:30:39.900
because there are some
pretty amazing examples.

00:30:39.900 --> 00:30:43.750
And we said, OK, now that we
realize it really works, what

00:30:43.750 --> 00:30:45.429
about more tricky examples?

00:30:45.429 --> 00:30:46.970
Like for example,
let's put something

00:30:46.970 --> 00:30:50.720
that leans toward emotion,
like "calm," for example.

00:30:50.720 --> 00:30:52.900
Let's have a look.

00:30:52.900 --> 00:30:56.747
Calm-- there.

00:30:56.747 --> 00:30:59.330
Yeah, there is this thing where
we didn't know what to expect.

00:30:59.330 --> 00:31:02.480
When you click on the label and
when you look at the content,

00:31:02.480 --> 00:31:04.760
indeed, yes, I see.

00:31:04.760 --> 00:31:06.350
I understand your
reference, computer.

00:31:06.350 --> 00:31:11.460
These are indeed calm sceneries,
beautiful landscapes-- yeah,

00:31:11.460 --> 00:31:13.500
it's peaceful.

00:31:13.500 --> 00:31:17.360
So as we went over
and over, we came

00:31:17.360 --> 00:31:20.270
across also labels that we would
have not thought to write down.

00:31:20.270 --> 00:31:23.140
Like for example,
one that I quite

00:31:23.140 --> 00:31:24.710
like-- I didn't know
it was a thing--

00:31:24.710 --> 00:31:28.160
but we found this "lady
in waiting" collection,

00:31:28.160 --> 00:31:32.750
automatically created, and
sent back by the algorithms.

00:31:32.750 --> 00:31:35.870
But look at this
beautiful collection

00:31:35.870 --> 00:31:40.050
of incredible artworks
from various centuries of,

00:31:40.050 --> 00:31:41.830
I don't know, maybe--
I guess it was

00:31:41.830 --> 00:31:48.580
a thing-- "Lady in Waiting."

00:31:48.580 --> 00:31:51.360
Oh, well, apart from
that one, maybe.

00:31:54.930 --> 00:32:00.680
And then maybe one last
example-- this one I really

00:32:00.680 --> 00:32:01.690
fell off my chair.

00:32:04.420 --> 00:32:06.130
I had no idea what to expect.

00:32:06.130 --> 00:32:10.160
I was, like, that
must be some glitch.

00:32:10.160 --> 00:32:14.290
But then when it appeared,
well, it just makes sense.

00:32:14.290 --> 00:32:20.070
Yeah, I mean-- that's right.

00:32:22.920 --> 00:32:26.730
So yes we'll release
this online soon.

00:32:26.730 --> 00:32:28.900
We have to polish
a few things first.

00:32:28.900 --> 00:32:33.850
But what you can see is
before the neural net is

00:32:33.850 --> 00:32:37.940
able to label all
these images, first

00:32:37.940 --> 00:32:44.250
he is representing all the
images in highly dimensional

00:32:44.250 --> 00:32:45.350
world, let's say.

00:32:45.350 --> 00:32:47.360
But it really
qualifies as the world.

00:32:47.360 --> 00:32:50.690
Basically, the neural net, to
be able to apply those labels,

00:32:50.690 --> 00:32:54.410
he positions every assets
at a particular position

00:32:54.410 --> 00:32:55.930
in this world.

00:32:55.930 --> 00:32:59.140
Well, I don't know about you,
but I want to visit that world.

00:32:59.140 --> 00:33:01.310
What does it look like?

00:33:01.310 --> 00:33:06.130
Is there an island of the
Impressionists with blue hats,

00:33:06.130 --> 00:33:09.080
or the highway of Roman statues?

00:33:09.080 --> 00:33:12.560
I don't know, but what I
suggest is you hop on with me,

00:33:12.560 --> 00:33:14.870
and we just have a quick tour.

00:33:14.870 --> 00:33:16.650
I will give you a quick tour.

00:33:16.650 --> 00:33:20.830
OK, so let's start from
these two assets here.

00:33:20.830 --> 00:33:22.560
Well, they seem
to have in common

00:33:22.560 --> 00:33:24.390
that they are a landscape.

00:33:24.390 --> 00:33:27.440
But let's take a step back.

00:33:27.440 --> 00:33:31.310
We can see other artworks
appearing with, well,

00:33:31.310 --> 00:33:36.410
it looks like some series of
landscapes-- more landscapes.

00:33:36.410 --> 00:33:39.280
But if you look
around, then we can see

00:33:39.280 --> 00:33:41.110
that we're actually surrounded.

00:33:41.110 --> 00:33:46.000
We literally woke up in this, I
don't know, the Island of Art.

00:33:46.000 --> 00:33:51.880
And well, let's have
a tour, actually.

00:33:51.880 --> 00:34:01.870
So here we can see a scene
with animals, I guess.

00:34:01.870 --> 00:34:05.720
As we continue, I think
it's this direction.

00:34:05.720 --> 00:34:07.960
So let's give it a little
while for it to load.

00:34:07.960 --> 00:34:10.620
People start to
appear in the picture,

00:34:10.620 --> 00:34:13.850
along with those animals.

00:34:13.850 --> 00:34:18.230
And if we step back
even more, actually,

00:34:18.230 --> 00:34:20.409
let me take you to one
of my favorite spots

00:34:20.409 --> 00:34:24.020
directly-- this one.

00:34:24.020 --> 00:34:26.199
I call it "The
Shore of Portraits."

00:34:26.199 --> 00:34:27.171
Look at this.

00:34:30.089 --> 00:34:31.630
Let's give it a
little while to load.

00:34:37.210 --> 00:34:40.090
And so this-- sorry,
I'm going really quick,

00:34:40.090 --> 00:34:42.889
because we have a lot of
things that I want to show.

00:34:42.889 --> 00:34:46.380
But this is a TSNE Map.

00:34:46.380 --> 00:34:51.960
So TSNE stands for T-distributed
Stochastic Neighbor Editing,

00:34:51.960 --> 00:34:55.810
which basically thanks
all those 128 dimensions

00:34:55.810 --> 00:34:58.780
and flattens it to
just two dimensions,

00:34:58.780 --> 00:35:03.210
so that you can plot them, and
make it interactive, and easier

00:35:03.210 --> 00:35:05.330
to travel across.

00:35:05.330 --> 00:35:08.200
So here is a very
simplistic diagram

00:35:08.200 --> 00:35:10.930
that shows how you
can create the map.

00:35:10.930 --> 00:35:13.030
So basically, we take the image.

00:35:13.030 --> 00:35:14.690
We feed it into the
neural net which

00:35:14.690 --> 00:35:20.780
extracts the raw features, which
is a 128 dimensional vector.

00:35:20.780 --> 00:35:24.400
Then in two steps, we reduce
those dimensions to two.

00:35:24.400 --> 00:35:29.300
And then it becomes-- you choose
the way you want to plug them.

00:35:29.300 --> 00:35:34.640
But this you can do now
with eight lines of Python.

00:35:34.640 --> 00:35:37.850
So it's not something
that is reserved

00:35:37.850 --> 00:35:40.310
for scientists or researchers.

00:35:40.310 --> 00:35:43.630
Thanks to some amazing open
source libraries like sklearn,

00:35:43.630 --> 00:35:45.900
it is something you can do
with eight lines of Python.

00:35:45.900 --> 00:35:50.250
You just load the CSV
of your raw features.

00:35:50.250 --> 00:35:51.870
Well, I won't go
over all those lines,

00:35:51.870 --> 00:35:55.070
but you do a truncated SVD,
which is the first [INAUDIBLE]

00:35:55.070 --> 00:35:57.710
that reduces to 50 dimensions.

00:35:57.710 --> 00:36:02.170
And then the TSNE is able
to create this nice map

00:36:02.170 --> 00:36:05.530
of two-dimensional vectors.

00:36:05.530 --> 00:36:10.330
And then, as we saw the
"Shore of Portraits,"

00:36:10.330 --> 00:36:14.210
we got an idea,
which led to what

00:36:14.210 --> 00:36:16.090
we call the "Portrait Matcher."

00:36:16.090 --> 00:36:19.380
So basically, the
Cultural Institute--

00:36:19.380 --> 00:36:24.910
we detected in the Art Project
Channel about 40,000 faces.

00:36:24.910 --> 00:36:28.600
So the question came
quite naturally--

00:36:28.600 --> 00:36:33.510
what if you could browse this
database with your own face?

00:36:33.510 --> 00:36:36.420
And it has to be real time,
otherwise it did not happen.

00:36:36.420 --> 00:36:40.616
So can we switch
back to the demo?

00:36:40.616 --> 00:36:41.759
All right, let's try that.

00:36:41.759 --> 00:36:42.675
Let's see if it works.

00:36:45.760 --> 00:36:49.420
All right, so let's see.

00:36:53.630 --> 00:36:54.840
Oh, wow, OK.

00:36:54.840 --> 00:37:01.329
I think we might--
OK, so we still

00:37:01.329 --> 00:37:02.870
have to polish this
one a little bit.

00:37:06.630 --> 00:37:08.350
but if you come to
our lab in Paris,

00:37:08.350 --> 00:37:11.270
we have a much refined setup,
which works much better.

00:37:11.270 --> 00:37:12.750
But anyway, let's move on.

00:37:15.450 --> 00:37:16.658
All right, thank you.

00:37:16.658 --> 00:37:19.148
[APPLAUSE]

00:37:19.148 --> 00:37:24.020
OK, can we switch
back to the slides?

00:37:24.020 --> 00:37:27.290
All right, but one good thing
is that this experiment led us

00:37:27.290 --> 00:37:30.180
to another iteration.

00:37:30.180 --> 00:37:34.045
It came from another
popular thing that

00:37:34.045 --> 00:37:36.480
happens is when you're
in front of a painting,

00:37:36.480 --> 00:37:39.340
and you see someone drawn,
and you feel like, oh, I

00:37:39.340 --> 00:37:41.080
feel like I know this person.

00:37:41.080 --> 00:37:45.410
Or oh, that definitely looks
like my neighbor, Tony.

00:37:45.410 --> 00:37:48.690
And actually, as
it turns out, there

00:37:48.690 --> 00:37:51.940
is this great model that's
been done by some researchers

00:37:51.940 --> 00:37:55.350
at Google which
is called FaceNet.

00:37:55.350 --> 00:37:58.690
And this model is
able to achieve

00:37:58.690 --> 00:38:04.340
99.63% accuracy
on the label face

00:38:04.340 --> 00:38:07.110
in the wild, which is
the academic de facto

00:38:07.110 --> 00:38:10.010
for this type of research.

00:38:10.010 --> 00:38:16.670
So basically this neural net
embeds in an Euclidean space

00:38:16.670 --> 00:38:19.450
faces that are from
the same identity

00:38:19.450 --> 00:38:23.690
closer together than faces
with dissimilar identities.

00:38:23.690 --> 00:38:26.520
So basically, same people
are closer in this space

00:38:26.520 --> 00:38:28.950
than different people.

00:38:28.950 --> 00:38:31.130
And what it sends
you back, basically,

00:38:31.130 --> 00:38:36.230
is, again, 128
dimensional vector

00:38:36.230 --> 00:38:38.550
that represents the embedding.

00:38:38.550 --> 00:38:41.870
And so we had to give it a try.

00:38:41.870 --> 00:38:46.080
So who knows these guys?

00:38:46.080 --> 00:38:48.250
OK, they're very
popular in Europe, too.

00:38:48.250 --> 00:38:52.090
So we took them as
a starting point.

00:38:52.090 --> 00:38:53.560
Let's try to find.

00:38:53.560 --> 00:38:55.500
Let's see how well
this model performs.

00:38:55.500 --> 00:38:59.247
But let's not include in the
mix other pictures of them,

00:38:59.247 --> 00:39:01.580
because I'm sure it would
work, so that would be boring.

00:39:01.580 --> 00:39:04.360
What if, instead,
we forced the system

00:39:04.360 --> 00:39:07.870
to send us only pictures
that are paintings?

00:39:07.870 --> 00:39:11.340
Well, again, I can tell
you when I saw the result,

00:39:11.340 --> 00:39:12.550
I fell off my chair.

00:39:12.550 --> 00:39:14.670
And yes, I did spend a
lot of time on the ground

00:39:14.670 --> 00:39:16.750
during this residency.

00:39:16.750 --> 00:39:19.350
OK, I'm really excited to
press this next button.

00:39:22.030 --> 00:39:23.790
All right, this is
what we got back.

00:39:26.630 --> 00:39:30.250
I mean, Jared in the
middle-- even though there

00:39:30.250 --> 00:39:33.945
is a huge-- I mean, there
is a gender mismatch-- that

00:39:33.945 --> 00:39:35.070
could be his sister, right?

00:39:38.270 --> 00:39:41.110
Or even Richard Hendricks,
just on the right of him, like,

00:39:41.110 --> 00:39:44.250
it even got the
curliness of the hair.

00:39:44.250 --> 00:39:45.750
It is just amazing.

00:39:45.750 --> 00:39:47.490
So of course, you can
imagine from there

00:39:47.490 --> 00:39:50.510
how many tries we did.

00:39:50.510 --> 00:39:55.700
Everyone wants to find his
doppelganger in the database.

00:39:55.700 --> 00:39:58.390
And here, who would have known
that Richard Hendricks had

00:39:58.390 --> 00:40:03.490
in half-naked man painted at
the Tate Britain right now?

00:40:03.490 --> 00:40:05.150
Let's take these
guys, for example--

00:40:05.150 --> 00:40:07.230
some of my personal heroes.

00:40:07.230 --> 00:40:09.080
Let's see what we get.

00:40:09.080 --> 00:40:13.420
And there, again-- even
though this beautiful artwork

00:40:13.420 --> 00:40:17.850
from Shepard Fairey for
Obama campaign in 2008

00:40:17.850 --> 00:40:20.440
is highly stylized
with only four colors,

00:40:20.440 --> 00:40:23.930
the algorithm still managed
to find the matching.

00:40:23.930 --> 00:40:27.620
And yes, that is quite amazing.

00:40:27.620 --> 00:40:31.460
It would have not been fair
not to try it with ourselves.

00:40:31.460 --> 00:40:35.540
So we gave it a try here
at I/O. And sorry, Mario,

00:40:35.540 --> 00:40:45.370
but-- [LAUGHTER] the
blue suits you so well.

00:40:45.370 --> 00:40:47.810
So this is really fun.

00:40:47.810 --> 00:40:53.880
And thanks again, for
Damien and everyone

00:40:53.880 --> 00:40:56.050
at the Cultural
Institute for offering us

00:40:56.050 --> 00:40:57.980
this really great opportunity.

00:40:57.980 --> 00:40:59.860
And I will hand it
over to you again.

00:40:59.860 --> 00:41:01.199
So thank you very much.

00:41:01.199 --> 00:41:04.073
[APPLAUSE]

00:41:09.719 --> 00:41:11.010
DAMIEN HENRY: Thank you, Cyril.

00:41:11.010 --> 00:41:13.170
Thank you, Mario.

00:41:13.170 --> 00:41:15.410
I'm very happy to
work with these guys.

00:41:15.410 --> 00:41:17.550
And I'm very lucky, I guess.

00:41:17.550 --> 00:41:19.240
So what's next?

00:41:19.240 --> 00:41:21.880
So if you want to
stay in touch with us,

00:41:21.880 --> 00:41:23.920
please download our app.

00:41:23.920 --> 00:41:26.560
It's a way to keep
a link with you.

00:41:26.560 --> 00:41:31.160
And our goal is to inspire you
to try machine learning, too.

00:41:31.160 --> 00:41:35.160
So if you want to give it a
try, I recommend TensorFlow.

00:41:35.160 --> 00:41:39.510
It's an open-source
framework, easy to start with.

00:41:39.510 --> 00:41:43.900
As a tutorial, the one
done by Mr. Karpathy

00:41:43.900 --> 00:41:45.126
is really, really good.

00:41:45.126 --> 00:41:46.750
It really helps me
to understand what's

00:41:46.750 --> 00:41:49.300
going on with machine learning.

00:41:49.300 --> 00:41:52.700
And the Cultural Institute is
not the only team within Google

00:41:52.700 --> 00:41:54.780
that is really passionate
about machine learning.

00:41:54.780 --> 00:41:58.670
So for instance, there
is the MEI Initiative.

00:41:58.670 --> 00:42:03.060
And this link is
really good reading.

00:42:03.060 --> 00:42:05.070
So I encourage you to try it.

00:42:05.070 --> 00:42:06.960
And the last one
is about the team,

00:42:06.960 --> 00:42:11.960
named Magenta, completely
dedicated to generate art

00:42:11.960 --> 00:42:13.990
using machine learning.

00:42:13.990 --> 00:42:16.550
So thanks, you, thanks everyone.

00:42:16.550 --> 00:42:18.868
and that's it.

00:42:18.868 --> 00:42:22.347
[APPLAUSE]

00:42:22.347 --> 00:42:27.076
[MUSIC PLAYING]

