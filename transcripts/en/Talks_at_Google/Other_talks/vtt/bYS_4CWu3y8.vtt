WEBVTT
Kind: captions
Language: en

00:00:01.200 --> 00:00:01.860
FEMALE SPEAKER: Please
join me in

00:00:01.860 --> 00:00:03.230
welcoming Mr. Kenneth Cukier.

00:00:03.230 --> 00:00:07.230
[APPLAUSE]

00:00:07.230 --> 00:00:09.140
KENNETH CUKIER: Thank
you very much.

00:00:09.140 --> 00:00:11.400
You can probably appreciate the
fact that I've got a lot

00:00:11.400 --> 00:00:14.800
of trepidation coming here to
talk to you folks for the

00:00:14.800 --> 00:00:18.240
obvious reason that I'm
wearing a suit.

00:00:18.240 --> 00:00:20.086
And the truth is I had a
breakfast this morning at the

00:00:20.086 --> 00:00:23.540
Council on Foreign Relations
to talk to them about the

00:00:23.540 --> 00:00:25.420
international implications
and the foreign-policy

00:00:25.420 --> 00:00:28.200
implications of big data.

00:00:28.200 --> 00:00:31.350
That leads to the second
trepidation and the context of

00:00:31.350 --> 00:00:31.990
my remarks.

00:00:31.990 --> 00:00:35.460
So the second trepidation is
that this is a sort of

00:00:35.460 --> 00:00:36.790
homecoming for the book.

00:00:36.790 --> 00:00:40.580
Because my journey, so to speak,
in the world of big

00:00:40.580 --> 00:00:42.400
data started at Google
and started at the

00:00:42.400 --> 00:00:44.430
Googleplex in 2009.

00:00:44.430 --> 00:00:47.920
It was you folks who opened up
the kimono to what you were

00:00:47.920 --> 00:00:50.930
doing in very small
little slivers.

00:00:50.930 --> 00:00:53.330
I never got the full picture.

00:00:53.330 --> 00:00:56.360
But I was able to cobble it all
together and see something

00:00:56.360 --> 00:00:58.490
and then give it
a label to it.

00:00:58.490 --> 00:01:01.040
Luckily, there was a couple
of labels that we

00:01:01.040 --> 00:01:01.970
were thinking of.

00:01:01.970 --> 00:01:04.860
And I reached for one that
wasn't a popular term at the

00:01:04.860 --> 00:01:06.530
time, and the term
was big data.

00:01:06.530 --> 00:01:07.460
And that was really helpful.

00:01:07.460 --> 00:01:09.510
It was the cover story
of "The Economist"

00:01:09.510 --> 00:01:12.850
in February of 2010.

00:01:12.850 --> 00:01:14.400
It was called "The Data Deluge",
because they thought

00:01:14.400 --> 00:01:16.170
they would sell it better
than saying "big

00:01:16.170 --> 00:01:17.950
data." But big data--

00:01:17.950 --> 00:01:19.940
it was basically all about
that and about what

00:01:19.940 --> 00:01:20.560
you guys are doing.

00:01:20.560 --> 00:01:25.190
And so it brings me great fear
to walk into a room, because

00:01:25.190 --> 00:01:26.850
you guys have been doing
it for so long.

00:01:26.850 --> 00:01:28.640
And that brings me into
the context of my

00:01:28.640 --> 00:01:30.020
conversation today.

00:01:30.020 --> 00:01:32.460
I want it to be a
conversation.

00:01:32.460 --> 00:01:34.340
I was obviously just at the
Council on Foreign Relations

00:01:34.340 --> 00:01:37.900
thinking about this in ways that
I am sure your engineers

00:01:37.900 --> 00:01:42.530
never thought about
it 10 years ago.

00:01:42.530 --> 00:01:44.040
I may have heard a snort.

00:01:44.040 --> 00:01:47.930
But here's the thing.

00:01:47.930 --> 00:01:52.800
Many of you were thinking of
it as a technological issue

00:01:52.800 --> 00:01:55.760
when people around the world
think of it in terms of the

00:01:55.760 --> 00:01:59.340
competitivity of nations.

00:01:59.340 --> 00:02:02.720
Our book, which is being
released today in America, has

00:02:02.720 --> 00:02:04.260
already been available in
China, where it's been a

00:02:04.260 --> 00:02:05.360
best-seller.

00:02:05.360 --> 00:02:08.199
And when we hear questions from
Chinese journalists to

00:02:08.199 --> 00:02:11.090
us, they're all talking about
the national project that

00:02:11.090 --> 00:02:11.370
they're on.

00:02:11.370 --> 00:02:13.500
Is this the way for us to
leapfrog with the West?

00:02:13.500 --> 00:02:15.290
Is this one area of technology,
unlike the

00:02:15.290 --> 00:02:18.260
internet and computing,
where we can lead?

00:02:18.260 --> 00:02:20.050
So the implications
of this are vast.

00:02:20.050 --> 00:02:22.375
And the implications are more
than just technological.

00:02:22.375 --> 00:02:25.540
I'm at a technology company-- in
fact, the pioneer, in many

00:02:25.540 --> 00:02:26.860
respects, of big data.

00:02:26.860 --> 00:02:29.070
But I want to explain that I'm
here as a journalist, as

00:02:29.070 --> 00:02:34.310
someone who's looked in at your
world and now can serve

00:02:34.310 --> 00:02:35.180
as a sort of a filter.

00:02:35.180 --> 00:02:37.570
And what I'd like to do is show
you that world from a

00:02:37.570 --> 00:02:39.860
non-engineer's perspective,
from someone who just is

00:02:39.860 --> 00:02:42.550
curious about the world and
society and thinks deeply

00:02:42.550 --> 00:02:44.400
about these issues.

00:02:44.400 --> 00:02:47.900
Now there's a second disclosure
I have to make, and

00:02:47.900 --> 00:02:50.740
that is not only am I talking
about big data, but my

00:02:50.740 --> 00:02:52.650
presentation is big data.

00:02:52.650 --> 00:02:56.590
Because there's 70 slides.

00:02:56.590 --> 00:02:58.920
On top of it, I haven't actually
really seen the

00:02:58.920 --> 00:03:00.510
slides except for once or
twice, because they just

00:03:00.510 --> 00:03:03.500
arrived to my inbox this morning
from someone who was

00:03:03.500 --> 00:03:04.720
putting it together for me.

00:03:04.720 --> 00:03:08.150
This is actually the recipe for
disaster, so please have

00:03:08.150 --> 00:03:08.660
forbearance.

00:03:08.660 --> 00:03:09.940
I'm going to go really quickly,
and I'm probably

00:03:09.940 --> 00:03:12.510
going to skip through a couple
of these slides.

00:03:12.510 --> 00:03:15.140
So let me start with a story,
and the story is the story of

00:03:15.140 --> 00:03:16.290
a company called Farecast.

00:03:16.290 --> 00:03:19.120
And it begins in
the year 2003.

00:03:19.120 --> 00:03:22.070
A guy named Oren Etzioni at the
University of Washington

00:03:22.070 --> 00:03:23.220
is on an airplane.

00:03:23.220 --> 00:03:26.090
And he asks people how much
they paid for the seats.

00:03:26.090 --> 00:03:30.170
And it turns out, of course, for
one person paid one fare,

00:03:30.170 --> 00:03:32.130
and one person paid
another fare.

00:03:32.130 --> 00:03:34.490
But this made Oren Etzioni
really, really upset.

00:03:34.490 --> 00:03:37.830
And the reason why is that he
took the time to book his air

00:03:37.830 --> 00:03:40.790
ticket long in advance, figuring
he was going to pay

00:03:40.790 --> 00:03:41.730
the least amount of money.

00:03:41.730 --> 00:03:43.400
Because that's the way
the system worked.

00:03:43.400 --> 00:03:46.640
And then he realized actually
that that wasn't the case.

00:03:46.640 --> 00:03:49.360
When he figured that out,
he was really upset.

00:03:49.360 --> 00:03:54.220
And he figured, if only I could
knew what is the meaning

00:03:54.220 --> 00:03:55.820
behind airfare madness.

00:03:55.820 --> 00:03:59.510
How would I know if a price I'm
being presented with at an

00:03:59.510 --> 00:04:02.400
online travel site is a
good one or a bad one?

00:04:02.400 --> 00:04:03.720
And then he came up
with the insight.

00:04:03.720 --> 00:04:06.670
Because he's like you-- he's
a computer scientist--

00:04:06.670 --> 00:04:08.630
he realized actually--

00:04:08.630 --> 00:04:10.730
that's actually just an
information problem.

00:04:10.730 --> 00:04:12.730
And I bet I can get
the information.

00:04:12.730 --> 00:04:17.490
All I would need is
one simple thing--

00:04:17.490 --> 00:04:22.390
the flight price record of
every single flight in

00:04:22.390 --> 00:04:26.930
commercial aviation in the
United States for every single

00:04:26.930 --> 00:04:30.130
route, every flight, and to
identify every seat, and to

00:04:30.130 --> 00:04:33.660
identify how long in advance the
ticket was bought for the

00:04:33.660 --> 00:04:37.000
departure, and what price was
paid, and just run it through

00:04:37.000 --> 00:04:39.630
a couple computers, and then
make a prediction on whether

00:04:39.630 --> 00:04:43.320
the price is likely to rise or
fall, and score my degree of

00:04:43.320 --> 00:04:45.580
confidence in the prediction.

00:04:45.580 --> 00:04:47.470
Pretty simple.

00:04:47.470 --> 00:04:49.350
So he scraped some data.

00:04:49.350 --> 00:04:50.680
And it works pretty well.

00:04:50.680 --> 00:04:52.270
And he runs a system.

00:04:52.270 --> 00:04:52.730
It's great.

00:04:52.730 --> 00:04:55.880
The academic paper that he
writes is called "Hamlet--

00:04:55.880 --> 00:05:01.230
To Buy or Not To Buy, That Is
the Question." It works well,

00:05:01.230 --> 00:05:03.670
but then he realizes, hey, this
works so well, I'm going

00:05:03.670 --> 00:05:04.810
to get more data.

00:05:04.810 --> 00:05:07.760
And he gets more data, until he
has 20 billion flight-price

00:05:07.760 --> 00:05:10.170
records that he's crunching
to make his prediction.

00:05:10.170 --> 00:05:11.990
And now it works really well.

00:05:11.990 --> 00:05:15.660
Now it's saving customers
a lot of money.

00:05:15.660 --> 00:05:18.750
It gets a little bit of
traction, and Microsoft comes

00:05:18.750 --> 00:05:19.800
knocking on the door.

00:05:19.800 --> 00:05:20.920
He's in Washington.

00:05:20.920 --> 00:05:23.350
He sells it for about
$100 million--

00:05:23.350 --> 00:05:26.400
not bad for a couple years work,
and a couple PhDs in

00:05:26.400 --> 00:05:29.890
computer science that was
working with him.

00:05:29.890 --> 00:05:32.610
But behind this, the
key thing is this.

00:05:32.610 --> 00:05:35.300
He took data that was generated
for one purpose and

00:05:35.300 --> 00:05:36.720
reused it for another.

00:05:36.720 --> 00:05:38.410
When the Sabre database--

00:05:38.410 --> 00:05:41.085
at the time probably the airline
reservation system and

00:05:41.085 --> 00:05:43.810
one of the biggest, actually the
biggest civilian computer

00:05:43.810 --> 00:05:45.730
project at its time when
it was created in

00:05:45.730 --> 00:05:47.620
the '50s and '60s--

00:05:47.620 --> 00:05:49.850
was created by American
Airlines and IBM.

00:05:49.850 --> 00:05:53.820
They never imagined for a
million years that the data of

00:05:53.820 --> 00:05:56.930
the passenger manifest was
going to become the raw

00:05:56.930 --> 00:06:01.130
material for a new business, and
a new source of value, and

00:06:01.130 --> 00:06:02.540
a new form of economic
activity.

00:06:02.540 --> 00:06:06.600
And we're going to be creating
markets with this data.

00:06:06.600 --> 00:06:09.070
And if you want to understand
what big data is, at least

00:06:09.070 --> 00:06:12.050
from a person looking
into it--

00:06:12.050 --> 00:06:14.910
because Google's been doing
big data for a long time.

00:06:14.910 --> 00:06:17.480
What we're seeing across society
is what you folks have

00:06:17.480 --> 00:06:19.660
been doing for years.

00:06:19.660 --> 00:06:22.670
We're seeing that data
is becoming a new

00:06:22.670 --> 00:06:24.190
raw material of business.

00:06:24.190 --> 00:06:27.080
It is the oil, if you will, of
the information economy.

00:06:30.260 --> 00:06:32.490
There's a lot of data around
in the world today.

00:06:32.490 --> 00:06:33.500
You know this.

00:06:33.500 --> 00:06:35.970
The arresting statistics
are obvious.

00:06:35.970 --> 00:06:39.180
Whenever we put on a big
new sky survey--

00:06:39.180 --> 00:06:41.160
telescope for you and
me-- goes online.

00:06:41.160 --> 00:06:44.120
Whenever it goes online, it
usually ends up collecting as

00:06:44.120 --> 00:06:47.630
much data in the first night
or two as in the history of

00:06:47.630 --> 00:06:52.050
astronomy prior to
it going online.

00:06:52.050 --> 00:06:54.550
And obviously, the human
genome, et cetera.

00:06:54.550 --> 00:06:58.510
You all know the data about big
data, so I won't spend too

00:06:58.510 --> 00:07:01.030
much time there.

00:07:01.030 --> 00:07:03.830
But what we see behind big data
are three features of

00:07:03.830 --> 00:07:06.080
society, or shifts in the
way that we think about

00:07:06.080 --> 00:07:07.640
information in the world--

00:07:07.640 --> 00:07:10.460
more, messy, and correlations.

00:07:10.460 --> 00:07:11.090
So more.

00:07:11.090 --> 00:07:12.990
We're going from an environment
where we've always

00:07:12.990 --> 00:07:14.130
been information-starved--

00:07:14.130 --> 00:07:15.970
we've never had enough
information--

00:07:15.970 --> 00:07:18.210
to one where we-- that's
no longer the operative

00:07:18.210 --> 00:07:19.040
constraint.

00:07:19.040 --> 00:07:19.850
It's still a constraint.

00:07:19.850 --> 00:07:21.460
Of course, we never have
all the information.

00:07:21.460 --> 00:07:22.270
What is information?

00:07:22.270 --> 00:07:23.730
Is it really the real thing?

00:07:23.730 --> 00:07:26.250
But what's clear is that instead
of having to optimize

00:07:26.250 --> 00:07:29.140
our tools to presume that we can
only have a small sliver

00:07:29.140 --> 00:07:31.480
of information, when
that changes, we

00:07:31.480 --> 00:07:32.690
can get a lot more.

00:07:32.690 --> 00:07:33.950
And so what does more mean?

00:07:33.950 --> 00:07:36.260
Well, think of it as 23andMe.

00:07:36.260 --> 00:07:40.150
What they do is they actually
take a sample of your DNA, and

00:07:40.150 --> 00:07:42.470
they look for very
specific traits.

00:07:42.470 --> 00:07:44.690
Now that works well, but
it's imperfect as well.

00:07:44.690 --> 00:07:46.440
That's one reason why
it's only $100--

00:07:46.440 --> 00:07:48.870
a couple hundred dollars.

00:07:48.870 --> 00:07:53.080
When Steve Jobs had cancer,
he was one of the first

00:07:53.080 --> 00:07:55.210
individuals in the world to
have his entire genome

00:07:55.210 --> 00:07:58.090
sequenced and his tumor
sequenced as well.

00:07:58.090 --> 00:08:00.360
So he had personalized
medicine, and it was

00:08:00.360 --> 00:08:03.220
individually tailored
to the state of his

00:08:03.220 --> 00:08:04.870
health at that time.

00:08:04.870 --> 00:08:06.950
When one drug would work,
they'd continue.

00:08:06.950 --> 00:08:10.940
When the cells mutated and
blocked the drug from working,

00:08:10.940 --> 00:08:13.580
they routed around it and
tried something else.

00:08:13.580 --> 00:08:15.610
They were able to do that
because they had all of the

00:08:15.610 --> 00:08:17.560
data, not just some
of the data.

00:08:17.560 --> 00:08:20.315
And that's one of the shifts
that we're seeing

00:08:20.315 --> 00:08:22.210
from some to more.

00:08:22.210 --> 00:08:25.450
And in some cases, n equals
all the data.

00:08:25.450 --> 00:08:27.210
We also have messy data.

00:08:27.210 --> 00:08:28.650
That's another feature
as well.

00:08:28.650 --> 00:08:31.420
In the past, we had highly
curated databases--

00:08:31.420 --> 00:08:34.330
information that we optimized
our tools to get in the most

00:08:34.330 --> 00:08:35.750
pristine way as possible.

00:08:35.750 --> 00:08:37.450
And this was sensible.

00:08:37.450 --> 00:08:39.710
When there's only a small amount
of information that you

00:08:39.710 --> 00:08:43.520
can bother collecting and
processing, because the cost

00:08:43.520 --> 00:08:45.870
is so high and it's so
cumbersome, you have to make

00:08:45.870 --> 00:08:48.080
sure the information
you get is the best

00:08:48.080 --> 00:08:51.320
possible thing you can.

00:08:51.320 --> 00:08:54.090
But when you can avail yourself
of orders and orders

00:08:54.090 --> 00:08:58.210
of magnitude more information,
that constraint goes away.

00:08:58.210 --> 00:09:00.790
And suddenly, you can allow for
a little bit of messiness.

00:09:00.790 --> 00:09:02.510
Now, it can't be completely
wrong.

00:09:02.510 --> 00:09:04.540
But messiness is good.

00:09:04.540 --> 00:09:08.010
You folks are pioneers of this
in machine translation.

00:09:08.010 --> 00:09:12.630
And you know the famous Peter
Norvig, and Allen Harvey, and

00:09:12.630 --> 00:09:14.640
others' paper on the
unreasonable

00:09:14.640 --> 00:09:16.330
effectiveness of data.

00:09:16.330 --> 00:09:20.930
The idea here is that machine
translation worked actually--

00:09:20.930 --> 00:09:22.000
was a real step up.

00:09:22.000 --> 00:09:25.850
When IBM tried it in around '56
with 20 Russian phrases

00:09:25.850 --> 00:09:28.410
and English phrases that they
programmed the computer to

00:09:28.410 --> 00:09:31.520
translate, it looked
impressive.

00:09:31.520 --> 00:09:32.910
It was ridiculous, of course.

00:09:32.910 --> 00:09:33.800
We now know.

00:09:33.800 --> 00:09:35.860
It's like a punch card.

00:09:35.860 --> 00:09:39.820
Then when IBM's project Candide
came around in the

00:09:39.820 --> 00:09:42.970
'90s, actually that was not
machine translation.

00:09:42.970 --> 00:09:45.580
That was statistical machine
translation.

00:09:45.580 --> 00:09:49.360
That was really good,
relatively speaking.

00:09:49.360 --> 00:09:52.330
What they did is they took
the Canadian Hansard--

00:09:52.330 --> 00:09:54.490
the parliamentary transcripts
that were translated into both

00:09:54.490 --> 00:09:56.490
English and into French--

00:09:56.490 --> 00:09:59.190
and they just let the computer
make the inferences of when a

00:09:59.190 --> 00:10:01.840
word in French, and it would be
a useful substitute for the

00:10:01.840 --> 00:10:02.680
one in English.

00:10:02.680 --> 00:10:04.610
They didn't try to
presume what was

00:10:04.610 --> 00:10:05.560
right or what was wrong.

00:10:05.560 --> 00:10:08.180
They let the computer infer
that itself and score the

00:10:08.180 --> 00:10:10.310
probability that one would be
the right word or not in that

00:10:10.310 --> 00:10:12.470
particular context,
and go forward.

00:10:12.470 --> 00:10:13.350
C-Change--

00:10:13.350 --> 00:10:15.540
they tried to optimize it
and make it better.

00:10:15.540 --> 00:10:16.670
Couldn't.

00:10:16.670 --> 00:10:17.700
Couldn't at a reasonable way.

00:10:17.700 --> 00:10:18.620
It just was--

00:10:18.620 --> 00:10:20.700
it was a hard problem.

00:10:20.700 --> 00:10:22.790
Then Google came along.

00:10:22.790 --> 00:10:25.500
And you guys didn't avail
yourself of just the

00:10:25.500 --> 00:10:29.520
parliamentary transcripts in
French and English in Canada.

00:10:29.520 --> 00:10:31.660
You availed yourself of
the World Wide Web.

00:10:31.660 --> 00:10:33.555
It wasn't 1994.

00:10:33.555 --> 00:10:36.316
It was 2006.

00:10:36.316 --> 00:10:37.060
You poured in.

00:10:37.060 --> 00:10:38.840
You got all of the
European Union

00:10:38.840 --> 00:10:40.820
translations of all 21 languages.

00:10:40.820 --> 00:10:46.000
Your Google Books project became
a signal for what was

00:10:46.000 --> 00:10:47.720
good and not because of the
translations that you could

00:10:47.720 --> 00:10:49.110
find in the libraries.

00:10:49.110 --> 00:10:54.330
Now in many instances, the data
was far less clean than

00:10:54.330 --> 00:10:56.060
in the past when we tried
to do it with just a

00:10:56.060 --> 00:10:57.200
small amount of data.

00:10:57.200 --> 00:11:01.080
But the fact is more data
beat clean data.

00:11:01.080 --> 00:11:02.240
Messiness was good.

00:11:02.240 --> 00:11:04.850
And the final point, which is
obvious, is correlations.

00:11:04.850 --> 00:11:07.510
We have had a society in which
we've always looked for causes

00:11:07.510 --> 00:11:09.300
behind things, and that
made sense in a

00:11:09.300 --> 00:11:10.880
small-data world as well.

00:11:10.880 --> 00:11:13.080
In fact, causality is still
very useful to know.

00:11:13.080 --> 00:11:15.180
But for a lot of the problems
that we're dealing with these

00:11:15.180 --> 00:11:18.150
days, just knowing the
correlation is good enough.

00:11:18.150 --> 00:11:20.800
And in fact, what we're finding
is that often we think

00:11:20.800 --> 00:11:23.580
we see causality
when we don't.

00:11:23.580 --> 00:11:25.360
And it's hard to do.

00:11:25.360 --> 00:11:27.600
So there's going to be cases
where we actually still want

00:11:27.600 --> 00:11:29.320
to know the reasons why.

00:11:29.320 --> 00:11:32.500
But often, just knowing what is
good enough, because we can

00:11:32.500 --> 00:11:35.560
learn the correlation
and go with that.

00:11:35.560 --> 00:11:39.400
So a similar company like
Farecast is Decide.com.

00:11:39.400 --> 00:11:42.470
This is Oren Etzioni's company
again that basically looks

00:11:42.470 --> 00:11:45.590
across the web at all of the
prices online, not just of

00:11:45.590 --> 00:11:48.510
airlines, but of anything that
has lots of price data and

00:11:48.510 --> 00:11:51.440
high variability and just ranks
it to say, is this a

00:11:51.440 --> 00:11:52.160
good price or not?

00:11:52.160 --> 00:11:53.410
And it leads to new markets.

00:11:53.410 --> 00:11:57.930
It leads to transparency, which
is good for customers.

00:11:57.930 --> 00:12:02.140
More interestingly is what this
means for human health.

00:12:02.140 --> 00:12:06.740
Premature babies, known
as preemies.

00:12:06.740 --> 00:12:09.680
In the past, when we thought
about health care, we would

00:12:09.680 --> 00:12:14.550
take the vital signs of someone
maybe once or twice a

00:12:14.550 --> 00:12:17.220
day, couple more times if
it was important enough.

00:12:17.220 --> 00:12:19.320
And a doctor would look at the
clipboard at the edge of the

00:12:19.320 --> 00:12:21.610
bed and make a decision
on what to do.

00:12:21.610 --> 00:12:23.720
Feedback loop was really,
really long.

00:12:23.720 --> 00:12:25.290
Very, very imperfect.

00:12:25.290 --> 00:12:27.770
What we're now able to do-- some
researchers in Canada are

00:12:27.770 --> 00:12:32.970
doing this, is they're looking
at the real-time flow of 16

00:12:32.970 --> 00:12:37.170
different streams of vital signs
of premature babies.

00:12:37.170 --> 00:12:39.280
And they're able to score
it and look for

00:12:39.280 --> 00:12:40.230
correlations with it.

00:12:40.230 --> 00:12:43.070
And when they do that, they find
that they can spot the

00:12:43.070 --> 00:12:47.440
onset of infection 24 hours
before overt symptoms appear.

00:12:47.440 --> 00:12:49.660
By doing that, that means that
you can have an intervention

00:12:49.660 --> 00:12:52.390
sooner, see if the interventions
working better,

00:12:52.390 --> 00:12:54.700
react to it, and save lives.

00:12:54.700 --> 00:12:57.670
But you learn something
else as well.

00:12:57.670 --> 00:13:00.150
You would have thought-- and you
can imagine generations of

00:13:00.150 --> 00:13:03.160
doctors looking at the
clipboard, seeing the kid's

00:13:03.160 --> 00:13:06.230
vitals stabilizing, and thinking
it was safe to go

00:13:06.230 --> 00:13:08.190
home to supper, that things were
OK, and we'll treat the

00:13:08.190 --> 00:13:09.720
patient tomorrow.

00:13:09.720 --> 00:13:11.810
Just nurse, call me if
there's a problem.

00:13:11.810 --> 00:13:13.630
And then to get a frantic call
at midnight saying something

00:13:13.630 --> 00:13:15.440
had gone horribly wrong.

00:13:15.440 --> 00:13:17.220
The fact is, what we're finding
is that one of the

00:13:17.220 --> 00:13:20.810
best predictors that there is
going to be an onset of an

00:13:20.810 --> 00:13:26.560
infection is that the baby's
vital signs stabilize.

00:13:26.560 --> 00:13:27.550
Weird, right?

00:13:27.550 --> 00:13:27.910
Why?

00:13:27.910 --> 00:13:30.110
We don't actually really know
why, what's happening

00:13:30.110 --> 00:13:31.310
biologically.

00:13:31.310 --> 00:13:36.610
It kind of seems like the kid's
little organs are just

00:13:36.610 --> 00:13:40.440
battening down the hatches
for a rough night ahead.

00:13:40.440 --> 00:13:43.560
We don't know why, but we know
that with that correlation, we

00:13:43.560 --> 00:13:44.420
can do something better.

00:13:44.420 --> 00:13:45.770
We can save its life.

00:13:45.770 --> 00:13:49.000
And we didn't know that
before big data.

00:13:49.000 --> 00:13:52.460
Behind this is we have data.

00:13:52.460 --> 00:13:53.230
Why do we have data?

00:13:53.230 --> 00:13:54.840
Well, we're collecting more
data for things that we've

00:13:54.840 --> 00:13:56.120
always collected data on.

00:13:56.120 --> 00:13:56.820
Weather--

00:13:56.820 --> 00:13:57.790
great.

00:13:57.790 --> 00:13:58.820
That's fantastic.

00:13:58.820 --> 00:14:02.520
But it also is because we're
collecting things that was

00:14:02.520 --> 00:14:05.840
always informational but we
never treated as data

00:14:05.840 --> 00:14:08.650
before, like you.

00:14:08.650 --> 00:14:09.820
So you're all sitting.

00:14:09.820 --> 00:14:11.190
You're sitting down.

00:14:11.190 --> 00:14:13.680
And you are sitting different
than you, and you,

00:14:13.680 --> 00:14:15.900
and you, and you.

00:14:15.900 --> 00:14:17.000
You weigh different.

00:14:17.000 --> 00:14:18.070
Your legs are different.

00:14:18.070 --> 00:14:18.900
Your posture is different.

00:14:18.900 --> 00:14:20.160
The distribution of weight.

00:14:20.160 --> 00:14:23.560
And you know that if I have 20
sensors on your seat and on

00:14:23.560 --> 00:14:26.440
your seat back that I can
probably score with a high

00:14:26.440 --> 00:14:30.580
degree of accuracy who you are
based on the way you sit.

00:14:30.580 --> 00:14:31.860
Why is that useful?

00:14:31.860 --> 00:14:34.520
Well, for one purpose, you can
imagine that this would be a

00:14:34.520 --> 00:14:37.460
great anti-theft tool in cars.

00:14:37.460 --> 00:14:40.890
Put this in, and suddenly you
would know that the authorized

00:14:40.890 --> 00:14:43.790
driver of your Lamborghini
is you, and

00:14:43.790 --> 00:14:44.580
it's not someone else.

00:14:44.580 --> 00:14:47.310
Or if you have children,
likewise, hey, I told you you

00:14:47.310 --> 00:14:50.150
can't take the car out
after 10:00 PM.

00:14:50.150 --> 00:14:52.720
And so the engine didn't work
when you tried to sit down and

00:14:52.720 --> 00:14:55.160
turn the keys in the ignition.

00:14:55.160 --> 00:14:55.700
That's great.

00:14:55.700 --> 00:14:57.900
But what else can
you do with it?

00:14:57.900 --> 00:14:58.690
Well, think about it.

00:14:58.690 --> 00:15:03.780
If everybody has their car seat
instrumentized and you

00:15:03.780 --> 00:15:07.500
actually datify posture,
suddenly you would be able to,

00:15:07.500 --> 00:15:13.630
perhaps, identify the telltale
signs of a shift in posture 30

00:15:13.630 --> 00:15:16.360
seconds prior to an accident.

00:15:16.360 --> 00:15:19.400
The probability of you getting
into an accident by a shift in

00:15:19.400 --> 00:15:20.220
your posture.

00:15:20.220 --> 00:15:23.810
Maybe what we've datafied
is driver fatigue.

00:15:23.810 --> 00:15:25.400
And the service here would
be the car would

00:15:25.400 --> 00:15:26.900
send an internal alarm.

00:15:26.900 --> 00:15:29.180
Maybe the steering wheel would
vibrate, or there'd be a chime

00:15:29.180 --> 00:15:30.440
saying, hey, wake up.

00:15:30.440 --> 00:15:32.050
You have a high likelihood
of getting into an

00:15:32.050 --> 00:15:33.900
accident right now.

00:15:33.900 --> 00:15:36.780
That's the sort of thing that
is left to play for as we

00:15:36.780 --> 00:15:41.340
data-ize society in a
world of big data.

00:15:41.340 --> 00:15:43.310
So what we're seeing
is lots of things

00:15:43.310 --> 00:15:44.750
being datafied as well.

00:15:44.750 --> 00:15:48.160
Facebook datafies our
friendships; Twitter, our

00:15:48.160 --> 00:15:50.780
stray thoughts, our whispers;
LinkedIn, our

00:15:50.780 --> 00:15:53.190
professional contacts.

00:15:53.190 --> 00:15:56.340
Google datafies our
intentions.

00:15:56.340 --> 00:16:00.920
So obviously, Google Flu Trends
is a wonderful way to

00:16:00.920 --> 00:16:03.140
have a predictor of what
the likelihood of

00:16:03.140 --> 00:16:05.560
outbreaks of flu are.

00:16:05.560 --> 00:16:06.370
Now that's great.

00:16:06.370 --> 00:16:07.980
It's just you don't want to
have to know causality.

00:16:07.980 --> 00:16:08.510
You don't know why.

00:16:08.510 --> 00:16:10.870
It just is what it is.

00:16:10.870 --> 00:16:14.180
Now you may recall that there
was a little bit of a grumble

00:16:14.180 --> 00:16:16.870
in the scientific community
recently when they said, the

00:16:16.870 --> 00:16:20.215
CDC this year said that flu was
going to be right here--

00:16:20.215 --> 00:16:22.130
CDC, the Center of
Disease Controls.

00:16:22.130 --> 00:16:23.270
And Google Flu Trends
like this, it

00:16:23.270 --> 00:16:26.350
didn't work this year.

00:16:26.350 --> 00:16:28.820
Bullshit.

00:16:28.820 --> 00:16:29.850
How do we know?

00:16:29.850 --> 00:16:32.380
Because CDC is reported data.

00:16:32.380 --> 00:16:33.410
The person came in.

00:16:33.410 --> 00:16:36.610
Maybe because of the economic
crisis, people decided they

00:16:36.610 --> 00:16:38.950
had to show up at work and
didn't go see a doctor.

00:16:38.950 --> 00:16:41.240
Maybe the Google Flu Trends
is accurate, and

00:16:41.240 --> 00:16:42.150
that's what's real.

00:16:42.150 --> 00:16:45.930
And CDC is just reported
data, not observed

00:16:45.930 --> 00:16:48.230
behavior, isn't as good.

00:16:48.230 --> 00:16:49.480
No one thought of that.

00:16:53.170 --> 00:16:55.470
Big data has been with
us for a while.

00:16:55.470 --> 00:16:59.430
It turns out that there was an
American commodore who had

00:16:59.430 --> 00:17:05.645
data-ized all of the old
log books inside of

00:17:05.645 --> 00:17:08.829
the dusty Navy trunks.

00:17:08.829 --> 00:17:11.930
And with that, he was able to
create a whole new form of

00:17:11.930 --> 00:17:14.839
nautical map that told sailors
not just where they were but

00:17:14.839 --> 00:17:15.960
the patterns of the winds.

00:17:15.960 --> 00:17:19.089
No one realized that the world,
and the winds, and the

00:17:19.089 --> 00:17:22.109
waves conformed to
natural patterns.

00:17:22.109 --> 00:17:25.180
If you will, that the sea had
its own physical geography,

00:17:25.180 --> 00:17:27.230
and that if you [? allided ?]
yourself with those things,

00:17:27.230 --> 00:17:29.430
that you could have
a safer voyage.

00:17:29.430 --> 00:17:31.100
And we can do that now.

00:17:31.100 --> 00:17:34.950
But the problem is it took him
a decade and dozens of people

00:17:34.950 --> 00:17:37.990
to do it, and we do the same
sort of thing in about one

00:17:37.990 --> 00:17:40.280
sixth of a second every day.

00:17:40.280 --> 00:17:43.420
So it's a democratization play
of techniques that we have

00:17:43.420 --> 00:17:44.690
tried to do in the past.

00:17:44.690 --> 00:17:45.800
We've done sometimes.

00:17:45.800 --> 00:17:49.110
Obviously, censuses have been
around since Jesus was born.

00:17:49.110 --> 00:17:53.630
But now we're actually doing
it in a widespread way.

00:17:53.630 --> 00:17:55.690
Predictive maintenance is a
good example of taking the

00:17:55.690 --> 00:17:57.630
same idea about premature
babies and

00:17:57.630 --> 00:17:59.120
applying it to machines.

00:17:59.120 --> 00:18:01.440
When your car is about to break
down, it doesn't go

00:18:01.440 --> 00:18:02.940
kaput all at once.

00:18:02.940 --> 00:18:04.030
Usually, you can feel it.

00:18:04.030 --> 00:18:06.570
There's a grumble, or it just
doesn't drive right.

00:18:06.570 --> 00:18:10.960
Well, now what we can do is
instrumentize it, see what the

00:18:10.960 --> 00:18:14.200
data signature of the heat and
the vibration is, find out how

00:18:14.200 --> 00:18:17.420
it correlates with previous
incidences of a break down,

00:18:17.420 --> 00:18:20.720
and know, perhaps, two days in
advance that your fan belt is

00:18:20.720 --> 00:18:21.390
going to break.

00:18:21.390 --> 00:18:25.140
And that's happening today in
fleets of cars by UPS, and

00:18:25.140 --> 00:18:26.530
it's going to be in your
car tomorrow if

00:18:26.530 --> 00:18:28.750
it's not already there.

00:18:28.750 --> 00:18:30.235
The value of data is hidden.

00:18:30.235 --> 00:18:33.460
It's hidden not in the primary
purpose for what it was

00:18:33.460 --> 00:18:34.080
collected for.

00:18:34.080 --> 00:18:36.400
But now with big-data
techniques, it's often

00:18:36.400 --> 00:18:39.810
uncovered in its multiple
secondary uses that are just

00:18:39.810 --> 00:18:42.490
limited by our imagination.

00:18:42.490 --> 00:18:46.510
So INRIX is a car company that
takes the sat-nav system and

00:18:46.510 --> 00:18:48.500
makes a prediction on how long
it's going to take from one

00:18:48.500 --> 00:18:50.230
place to another.

00:18:50.230 --> 00:18:50.790
Sounds great.

00:18:50.790 --> 00:18:51.740
It's a good service.

00:18:51.740 --> 00:18:53.390
Use it.

00:18:53.390 --> 00:18:55.540
It's also used by economists
to understand

00:18:55.540 --> 00:18:56.550
the health of economies.

00:18:56.550 --> 00:18:59.840
Because they see how cars drive,
and the frequency and

00:18:59.840 --> 00:19:02.620
propensity of cars, and the
travel times as a proxy, an

00:19:02.620 --> 00:19:05.980
indicator, for the health of
a local municipal economy.

00:19:05.980 --> 00:19:09.050
Hedge funds use this information
to look at the car

00:19:09.050 --> 00:19:13.450
circulation in the areas near
a retailer on the weekends.

00:19:13.450 --> 00:19:15.590
And so prior to the quarterly
announcements, they have a

00:19:15.590 --> 00:19:17.560
good indicator whether the sales
are going to increase or

00:19:17.560 --> 00:19:21.190
decrease, and they can short
or go long on its shares.

00:19:21.190 --> 00:19:22.710
No one would have thought of
that in the past, that we

00:19:22.710 --> 00:19:23.960
could do that sort of thing
with information.

00:19:27.390 --> 00:19:30.120
Obviously, everything that we
do-- all of our interactions--

00:19:30.120 --> 00:19:31.750
give off lots of data exhaust.

00:19:31.750 --> 00:19:34.040
You folks are experienced with
that, because you treat all of

00:19:34.040 --> 00:19:37.280
the interactions of an
individual who goes to your

00:19:37.280 --> 00:19:39.690
website as a signal for
something else.

00:19:39.690 --> 00:19:43.240
You've built your systems and
optimized it based on that

00:19:43.240 --> 00:19:45.830
form of data exhaust, by
treating information as a new

00:19:45.830 --> 00:19:49.020
raw material that you can
recycle back into the system

00:19:49.020 --> 00:19:51.605
to improve it or to create a
whole new system altogether.

00:19:54.580 --> 00:19:57.350
There is going to be winners and
losers in this new world.

00:19:57.350 --> 00:20:00.660
There's three features that
seem to be distinguishing

00:20:00.660 --> 00:20:01.740
who's going to do well.

00:20:01.740 --> 00:20:04.950
And that's the skills, the
mindset, and the data.

00:20:04.950 --> 00:20:06.005
The skills are kind
of obvious.

00:20:06.005 --> 00:20:07.750
It's the people who have
technical knowledge, or it's

00:20:07.750 --> 00:20:09.610
the vendors who sell
you stuff.

00:20:09.610 --> 00:20:11.010
That's great.

00:20:11.010 --> 00:20:14.000
The mindset, in some ways, seems
to be more important.

00:20:14.000 --> 00:20:15.790
Because what you need is
not just the skills.

00:20:15.790 --> 00:20:17.860
That gets commoditized
first, obviously.

00:20:17.860 --> 00:20:20.110
History of computing
suggested that.

00:20:20.110 --> 00:20:23.550
The first computer scientists
in the '50s and '60s--

00:20:23.550 --> 00:20:24.690
actually, not the scientists.

00:20:24.690 --> 00:20:28.000
But these were the doers, the
software programmers.

00:20:28.000 --> 00:20:29.890
They looked like they were
sitting pretty wearing the

00:20:29.890 --> 00:20:30.680
white lab coats.

00:20:30.680 --> 00:20:34.140
But by the '70s and '80s, man,
just an ordinary rinky-dink

00:20:34.140 --> 00:20:36.740
software developer had been
largely commoditized.

00:20:36.740 --> 00:20:38.390
And we're going to see that
with big data as well.

00:20:38.390 --> 00:20:42.660
Today, some companies and people
are at the high end.

00:20:42.660 --> 00:20:43.830
It's going to filter
through as the PhD

00:20:43.830 --> 00:20:45.550
programs get forward.

00:20:45.550 --> 00:20:47.970
The mindset is going to be
critical and the creativity.

00:20:47.970 --> 00:20:50.330
But ultimately, both of
those things are going

00:20:50.330 --> 00:20:51.450
to go to the wayside.

00:20:51.450 --> 00:20:53.986
Because if you remember, Jeff
Bezos had a great dot-com

00:20:53.986 --> 00:20:58.480
mindset really early in '94
or so, and he executed

00:20:58.480 --> 00:20:59.610
brilliantly as well.

00:20:59.610 --> 00:21:01.610
But by the 2000, every
executive was

00:21:01.610 --> 00:21:02.370
thinking about the web.

00:21:02.370 --> 00:21:03.910
So we're going to have the
same thing with big data.

00:21:03.910 --> 00:21:06.310
That advantage doesn't
hold that long.

00:21:06.310 --> 00:21:10.080
The data, however-- who has
access to the data is going to

00:21:10.080 --> 00:21:10.780
be critical.

00:21:10.780 --> 00:21:12.300
That's the resource.

00:21:12.300 --> 00:21:16.640
So weirdly, and ironically,
what seems to be abundant

00:21:16.640 --> 00:21:23.300
today is actually the source of
scarcity, and vice versa.

00:21:23.300 --> 00:21:25.940
Now in New York, we
have a problem

00:21:25.940 --> 00:21:28.330
with overcrowded buildings.

00:21:28.330 --> 00:21:30.360
But before I tell you that
story, let me see much time we

00:21:30.360 --> 00:21:32.560
have, because I want to
get questions as well.

00:21:32.560 --> 00:21:34.940
I think we're doing OK.

00:21:34.940 --> 00:21:39.840
So tenements, overcrowded
buildings, and the problem of

00:21:39.840 --> 00:21:42.920
just stuffing 10 times as many
occupants into a single

00:21:42.920 --> 00:21:44.740
dwelling as it was
designed for.

00:21:44.740 --> 00:21:47.190
This is a bad thing, and
it's a bad thing

00:21:47.190 --> 00:21:48.780
because it leads to crime.

00:21:48.780 --> 00:21:50.390
It leads to drugs.

00:21:50.390 --> 00:21:52.570
It leads to violence.

00:21:52.570 --> 00:21:55.330
And it leads to fires, and not
just any kind of fires.

00:21:55.330 --> 00:21:57.810
Basically, these kind of fires
kill the occupants.

00:21:57.810 --> 00:22:01.390
And they also end up injuring
and killing at much greater

00:22:01.390 --> 00:22:03.630
rates the firefighters who
go to help it out.

00:22:03.630 --> 00:22:06.890
So this is a serious problem
for the city.

00:22:06.890 --> 00:22:11.060
The city gets something like
63,000 calls a year for

00:22:11.060 --> 00:22:13.160
complaints of illegal,

00:22:13.160 --> 00:22:15.690
overcrowded stuffing in buildings.

00:22:15.690 --> 00:22:18.460
And there's only 200 inspectors
at City Hall.

00:22:18.460 --> 00:22:19.800
So there you see a problem.

00:22:19.800 --> 00:22:21.440
But the problem is actually
a big-data problem.

00:22:21.440 --> 00:22:22.140
How can we solve it?

00:22:22.140 --> 00:22:26.270
Well, the first thing that they
do is they take a list, a

00:22:26.270 --> 00:22:30.230
database of every single
building in Manhattan and the

00:22:30.230 --> 00:22:34.360
five Boroughs, and that's
900,000, give or take.

00:22:34.360 --> 00:22:36.000
And then they look at everything
as a signal,

00:22:36.000 --> 00:22:38.810
whether it's going to be a
predictor that the thing is

00:22:38.810 --> 00:22:41.160
going to burst into flames, or
that it's going to actually

00:22:41.160 --> 00:22:43.080
improve the model by predicting
that it's not going

00:22:43.080 --> 00:22:44.180
to burst into flames.

00:22:44.180 --> 00:22:47.850
So they look at things like
ambulance calls, utility cuts.

00:22:47.850 --> 00:22:51.350
Has there been a lean against
the property?

00:22:51.350 --> 00:22:53.520
Is there complaints of
rodent infestation?

00:22:53.520 --> 00:22:56.990
So the number of rats in the
building is not datafied, but

00:22:56.990 --> 00:22:59.755
complaints to the city's
311 line is.

00:22:59.755 --> 00:23:01.850
So you find out the number
of rodent complaints.

00:23:01.850 --> 00:23:03.990
And all together,
you look at it.

00:23:03.990 --> 00:23:06.250
And you can score with a high
degree that the building's

00:23:06.250 --> 00:23:07.930
going to burst into flame.

00:23:07.930 --> 00:23:10.550
They looked at weird stuff, from
like the Department of

00:23:10.550 --> 00:23:14.040
Building Works on whether
exterior brickwork had been

00:23:14.040 --> 00:23:15.430
recently done to the building.

00:23:15.430 --> 00:23:16.550
That improved the model too.

00:23:16.550 --> 00:23:19.320
Because if brickwork was done
to the building, even if you

00:23:19.320 --> 00:23:22.440
had all these other problems
that were high indicators of a

00:23:22.440 --> 00:23:24.210
fire, it went down.

00:23:24.210 --> 00:23:27.605
When they pressed go on the
system, now what happens is an

00:23:27.605 --> 00:23:32.700
inspector, instead of going
in-- and about 15% of the

00:23:32.700 --> 00:23:34.390
times they would make a visit.

00:23:34.390 --> 00:23:37.350
In the past, they would issue
a vacate order, the stiffest

00:23:37.350 --> 00:23:41.060
sanction which basically says,
everyone out in 24 hours.

00:23:41.060 --> 00:23:43.410
Before it was 15% of the
time-- a high rate.

00:23:43.410 --> 00:23:45.050
So it tells you there's
a big problem.

00:23:45.050 --> 00:23:47.160
Now it's 70% of the time.

00:23:47.160 --> 00:23:49.775
And so what that means is that
they like it, the inspectors,

00:23:49.775 --> 00:23:51.130
because it's more effective.

00:23:51.130 --> 00:23:53.650
The fire department likes it,
because their firemen aren't

00:23:53.650 --> 00:23:56.010
dying as much.

00:23:56.010 --> 00:23:58.430
And it's just good for all of
us in our communities to see

00:23:58.430 --> 00:24:00.780
that people have good housing
and that these buildings don't

00:24:00.780 --> 00:24:01.710
catch on fire.

00:24:01.710 --> 00:24:04.270
And that was because they turned
the problem into a big

00:24:04.270 --> 00:24:06.980
data problem and solved it
successfully with information.

00:24:06.980 --> 00:24:09.580
And they gave up trying to
figure out the causality and

00:24:09.580 --> 00:24:12.950
just went with the
correlation.

00:24:12.950 --> 00:24:16.490
There, of course, are serious
issues of big data.

00:24:16.490 --> 00:24:18.570
One is going to be privacy.

00:24:18.570 --> 00:24:21.680
It's a problem now in
the small-data era.

00:24:21.680 --> 00:24:23.230
It's going to be a bigger
problem with big data.

00:24:23.230 --> 00:24:25.380
But there's going to be
something on top of that.

00:24:25.380 --> 00:24:29.100
And that is not privacy,
but propensity--

00:24:29.100 --> 00:24:31.010
but prediction.

00:24:31.010 --> 00:24:34.080
The idea is that we're going to
have algorithms predicting

00:24:34.080 --> 00:24:36.420
our likelihood to do things,
our behavior.

00:24:36.420 --> 00:24:38.140
And it's going to be obvious
that we're going to have

00:24:38.140 --> 00:24:41.140
governments try to-- or our
businesses sanction us on the

00:24:41.140 --> 00:24:43.150
basis of that prediction.

00:24:43.150 --> 00:24:45.550
It's going to look a little bit
like "Minority Report" and

00:24:45.550 --> 00:24:47.772
the idea of pre-crime.

00:24:47.772 --> 00:24:49.630
We're going to be denied a loan,
because we're going to

00:24:49.630 --> 00:24:50.870
not have the likelihood
to repay.

00:24:50.870 --> 00:24:54.220
But instead of this profiling
universe in which we take us

00:24:54.220 --> 00:24:55.400
as a big clump--

00:24:55.400 --> 00:24:57.610
and we have a small-data
problem.

00:24:57.610 --> 00:25:01.530
Here are the 13 predictors, and
this is the explicit rules

00:25:01.530 --> 00:25:03.070
by which we can tell
you the formula.

00:25:03.070 --> 00:25:05.030
Imagine if we have
1,000 variables.

00:25:05.030 --> 00:25:07.590
It's a machine learning
algorithm, and when we try to

00:25:07.590 --> 00:25:09.980
knock on the door in front of a
court and say, I was denied

00:25:09.980 --> 00:25:13.280
surgery because you said I had
a 90% mortality rate after

00:25:13.280 --> 00:25:17.490
five years with my individual
data, I want you to disclose

00:25:17.490 --> 00:25:18.740
to me how you came
to that decision

00:25:18.740 --> 00:25:20.460
because that seems unfair.

00:25:20.460 --> 00:25:25.470
They're going to say
I don't know.

00:25:25.470 --> 00:25:26.870
I can show you the formula.

00:25:26.870 --> 00:25:29.570
I've frozen every instantiation
of the data at

00:25:29.570 --> 00:25:32.180
every moment, because regulators
required me to.

00:25:32.180 --> 00:25:35.690
If I printed out the formula,
it would be on 600 pages.

00:25:35.690 --> 00:25:39.050
You need a PhD to
understand it.

00:25:39.050 --> 00:25:41.640
It's true you have only 40
strong signals, but you've got

00:25:41.640 --> 00:25:45.690
a long tail of 600 weak signals
that all went into it.

00:25:45.690 --> 00:25:47.630
I can't tell you why.

00:25:47.630 --> 00:25:49.590
And then the person's going to
say, OK, I don't even care

00:25:49.590 --> 00:25:50.030
about that.

00:25:50.030 --> 00:25:52.250
What makes you think I'm not
going to be part of the 10%

00:25:52.250 --> 00:25:54.480
that's going to live
past 10 years?

00:25:54.480 --> 00:25:56.830
Why are you denying me this
operation because you think

00:25:56.830 --> 00:26:00.000
I've got a high probability of
not surviving longer after it?

00:26:00.000 --> 00:26:00.945
I want to take the test.

00:26:00.945 --> 00:26:02.816
And you can imagine with
criminal-justice systems, it's

00:26:02.816 --> 00:26:04.640
going to be the exact
same thing.

00:26:04.640 --> 00:26:05.980
This is the issue
that we have.

00:26:05.980 --> 00:26:08.520
And so what do we have to
preserve in this instance?

00:26:08.520 --> 00:26:11.420
Well, if it's the case of
whether we think this fellow's

00:26:11.420 --> 00:26:14.880
going to shoplift in the next
12 months with a 99-degree

00:26:14.880 --> 00:26:18.680
percent probability, he can
rightly say, I don't even care

00:26:18.680 --> 00:26:20.600
about the mumbo-jumbo
of big data.

00:26:20.600 --> 00:26:23.300
I'm part of the 1% that's going
to exercise free will,

00:26:23.300 --> 00:26:25.890
moral choice, and do
the right thing.

00:26:25.890 --> 00:26:28.830
Now of course, all 100 of those
individuals will say the

00:26:28.830 --> 00:26:29.990
same argument.

00:26:29.990 --> 00:26:32.800
But it does mean that it seems
like we're going to have to

00:26:32.800 --> 00:26:35.570
create a new value
in our world.

00:26:35.570 --> 00:26:38.900
Just as the printing press gave
us the consciousness of

00:26:38.900 --> 00:26:39.930
free speech--

00:26:39.930 --> 00:26:43.050
prior to the printing press, we
didn't have a guarantee or

00:26:43.050 --> 00:26:44.130
the consciousness
of free speech.

00:26:44.130 --> 00:26:46.530
When Socrates drank the hemlock
for corrupting the

00:26:46.530 --> 00:26:49.010
youth of Athens, in his
apologia did he make a

00:26:49.010 --> 00:26:51.070
free-speech claim?

00:26:51.070 --> 00:26:52.930
No.

00:26:52.930 --> 00:26:54.710
It didn't exist.

00:26:54.710 --> 00:26:57.960
It took the printing press
to give us this idea that

00:26:57.960 --> 00:27:00.350
expression was something that
needed to be protected.

00:27:00.350 --> 00:27:03.440
What will need to be protected
in a world of big data?

00:27:03.440 --> 00:27:08.360
Well, maybe human volition,
free will, responsibility.

00:27:12.200 --> 00:27:14.690
We have always had the
risks of data.

00:27:14.690 --> 00:27:16.700
We're going to have to deal
with this even more as we

00:27:16.700 --> 00:27:19.880
become more respectful of data
and live with it in more parts

00:27:19.880 --> 00:27:21.530
of our lives.

00:27:21.530 --> 00:27:24.800
We've looked at data
in lots of ways.

00:27:24.800 --> 00:27:28.800
America went to war over a
statistic in a data point, and

00:27:28.800 --> 00:27:31.190
we saw the problems there.

00:27:31.190 --> 00:27:33.890
We're going to need regulators
to think about how we can

00:27:33.890 --> 00:27:36.690
adopt this and get the
most benefits of it.

00:27:36.690 --> 00:27:40.050
Probably one of the biggest is
going to be giving us a degree

00:27:40.050 --> 00:27:41.960
of transparency.

00:27:41.960 --> 00:27:44.240
When there was an information
explosion at the beginning of

00:27:44.240 --> 00:27:46.990
the 19th century and it was
financial information, we

00:27:46.990 --> 00:27:51.160
created accountants to do the
bookkeeping and auditors to do

00:27:51.160 --> 00:27:54.130
the surveillance function on
top of the accountants.

00:27:54.130 --> 00:27:56.100
And I think that in the future--
and we mention this

00:27:56.100 --> 00:27:57.210
in the book--

00:27:57.210 --> 00:27:58.540
that we're going to have
to create a new

00:27:58.540 --> 00:27:59.420
professional class.

00:27:59.420 --> 00:28:01.770
And we might as well call them
algorithmists, who are going

00:28:01.770 --> 00:28:04.610
to be trained in big-data
techniques and actually serve

00:28:04.610 --> 00:28:09.110
internal to companies, as well
as external in terms of an

00:28:09.110 --> 00:28:11.830
expert witness and a master
to a court, that they can

00:28:11.830 --> 00:28:13.850
actually understand what's
going on and serve as a

00:28:13.850 --> 00:28:17.050
translation function between the
public interest and what's

00:28:17.050 --> 00:28:19.670
happening in the mathematics.

00:28:19.670 --> 00:28:21.610
For privacy, the shift is
probably going to have to go

00:28:21.610 --> 00:28:24.920
from regulating the collection
of data, as we do now in these

00:28:24.920 --> 00:28:29.450
preposterous screens of 60 lines
of all-capped letters in

00:28:29.450 --> 00:28:31.600
which you just say, I agree with
the terms of service and

00:28:31.600 --> 00:28:33.740
not read it, to something
where we

00:28:33.740 --> 00:28:35.250
actually regulate use.

00:28:35.250 --> 00:28:37.970
And luckily, that seems to be
an idea that is actually

00:28:37.970 --> 00:28:38.770
gathering steam.

00:28:38.770 --> 00:28:40.940
It's a lot harder for
regulators, but it's

00:28:40.940 --> 00:28:42.580
definitely better
for businesses.

00:28:42.580 --> 00:28:45.690
And it's definitely better
for consumers.

00:28:45.690 --> 00:28:47.200
And of course, we're
going to have to

00:28:47.200 --> 00:28:50.120
sanctify human volition.

00:28:50.120 --> 00:28:53.540
There is a role for antitrust
regulators, as well.

00:28:53.540 --> 00:28:59.770
Antitrust turns out to be an
extremely fertile and fungible

00:28:59.770 --> 00:29:01.950
public policy, because it's
technology-neutral.

00:29:01.950 --> 00:29:04.610
It doesn't really make many
presumptions about what it's

00:29:04.610 --> 00:29:05.510
regulating.

00:29:05.510 --> 00:29:08.700
What it does is it just looks
at market concentration.

00:29:08.700 --> 00:29:10.900
So it looks like it's going to
be a very useful tool with

00:29:10.900 --> 00:29:14.070
which we try to understand what
to do and to create an

00:29:14.070 --> 00:29:15.530
open market.

00:29:15.530 --> 00:29:19.890
Now there's a problem in this
that I'm laying out, which is

00:29:19.890 --> 00:29:24.330
regulators can understand what
scale looks like when it's

00:29:24.330 --> 00:29:27.780
something tangible,
like a widget.

00:29:27.780 --> 00:29:30.130
Actually, the antitrust came out
of the railroad, so we'll

00:29:30.130 --> 00:29:33.940
say a car, a carriage.

00:29:33.940 --> 00:29:37.030
And then they applied it to
telephones, and they called it

00:29:37.030 --> 00:29:37.810
common carriage.

00:29:37.810 --> 00:29:40.200
There's still a Common Carrier
Bureau at the FCC.

00:29:40.200 --> 00:29:42.340
The carrier, if you will, was
from the Interstate Commerce

00:29:42.340 --> 00:29:44.640
Act where the language
was taken from.

00:29:44.640 --> 00:29:47.050
They then applied it to
software markets--

00:29:47.050 --> 00:29:48.360
Microsoft.

00:29:48.360 --> 00:29:50.410
What does scale mean in data?

00:29:50.410 --> 00:29:53.390
What does it mean when the data
is doubling every three

00:29:53.390 --> 00:29:54.400
years or so?

00:29:54.400 --> 00:29:56.800
What does it mean when the
market is changing form, that

00:29:56.800 --> 00:29:59.530
it's not the same market in
five years as it was five

00:29:59.530 --> 00:30:00.040
years earlier?

00:30:00.040 --> 00:30:01.470
The businesses look different.

00:30:01.470 --> 00:30:04.740
It is going to be really
difficult to do, but we're

00:30:04.740 --> 00:30:06.210
going to have to
try to do that.

00:30:06.210 --> 00:30:09.190
Because we're going to need
the assurances that we can

00:30:09.190 --> 00:30:11.960
have challengers as well
as incumbents.

00:30:11.960 --> 00:30:13.320
We need both.

00:30:13.320 --> 00:30:15.430
This is about the way
that we live.

00:30:15.430 --> 00:30:17.470
We're going to need
to act with our

00:30:17.470 --> 00:30:19.900
humility and our humanity.

00:30:19.900 --> 00:30:21.150
Thank you very much.

00:30:27.760 --> 00:30:30.130
There's time for questions,
so shout it out.

00:30:33.460 --> 00:30:34.755
There's microphones as well.

00:30:39.740 --> 00:30:40.970
Yeah, please.

00:30:40.970 --> 00:30:41.530
Go to the mike.

00:30:41.530 --> 00:30:42.780
Thanks.

00:30:44.910 --> 00:30:46.330
AUDIENCE: Hi, my name
is Cynthia Elliott.

00:30:46.330 --> 00:30:47.360
I have a question.

00:30:47.360 --> 00:30:52.330
So I can see this data being
very useful, like in let's say

00:30:52.330 --> 00:30:55.040
drafting of an athletic
player.

00:30:55.040 --> 00:30:58.570
Have you ever encountered
anything where colleges would

00:30:58.570 --> 00:31:01.310
want you to use this data to
determine who could have the

00:31:01.310 --> 00:31:03.990
athletic ability
to be drafted?

00:31:03.990 --> 00:31:09.100
KENNETH CUKIER: Yeah, well
colleges and professional

00:31:09.100 --> 00:31:11.870
sports are using the data
already right now quite a lot.

00:31:11.870 --> 00:31:13.930
The whole book and
movie "Moneyball"

00:31:13.930 --> 00:31:15.180
was just about that.

00:31:15.180 --> 00:31:18.300
Partially about new statistics
and new ways of examining it,

00:31:18.300 --> 00:31:20.760
but then partially just
applying data to it.

00:31:20.760 --> 00:31:23.770
And Nate Silver, of course
talks a lot about just

00:31:23.770 --> 00:31:25.840
trusting the data
and just doing--

00:31:25.840 --> 00:31:27.040
Nate Silver is not
doing big data.

00:31:27.040 --> 00:31:28.040
He's just doing data.

00:31:28.040 --> 00:31:32.480
He's doing statistics, but the
small difference is he's just

00:31:32.480 --> 00:31:33.260
listening to it.

00:31:33.260 --> 00:31:36.770
He's just doing it seriously
and trusting it.

00:31:36.770 --> 00:31:39.790
So this is going to actually
change lots of the ways that

00:31:39.790 --> 00:31:41.920
we evaluate people.

00:31:41.920 --> 00:31:46.720
So when we think about students
and education, right

00:31:46.720 --> 00:31:51.145
now what a teacher does is it
scores what every person in

00:31:51.145 --> 00:31:54.200
the class's grade and tells
everyone, this person got a

00:31:54.200 --> 00:31:58.060
95, and this person got an 85,
and this person got a 75.

00:31:58.060 --> 00:32:02.020
The teacher doesn't actually
look at what is the content of

00:32:02.020 --> 00:32:04.250
the-- or rarely, what is the
content of what was corrected

00:32:04.250 --> 00:32:05.130
and what was wrong.

00:32:05.130 --> 00:32:07.560
What if that teacher was to
find out that all of the

00:32:07.560 --> 00:32:10.770
students in a math exam got
the exact same-- not all.

00:32:10.770 --> 00:32:13.950
But let's say 80% of the
students got the exact same

00:32:13.950 --> 00:32:18.470
answer wrong with
the same answer.

00:32:18.470 --> 00:32:23.340
Suddenly, he or she might say,
hmm, I mistaught it.

00:32:23.340 --> 00:32:26.830
They inverted the algebraic
equation thinking that it

00:32:26.830 --> 00:32:28.060
could be a or b and b or a.

00:32:28.060 --> 00:32:30.370
But in fact, the sequence
matters, and I've got to go

00:32:30.370 --> 00:32:31.370
back and teach that.

00:32:31.370 --> 00:32:34.780
So not only does the student
learn more, but the teacher

00:32:34.780 --> 00:32:35.780
learns as well.

00:32:35.780 --> 00:32:38.390
So in terms of drafting, sports
is one of the first

00:32:38.390 --> 00:32:40.570
people to adopt these
techniques.

00:32:40.570 --> 00:32:44.790
And it's actually changing how
they think about their game.

00:32:44.790 --> 00:32:45.890
Certain players--

00:32:45.890 --> 00:32:49.040
why would you have a defense
for the opposing team?

00:32:49.040 --> 00:32:52.050
You want a defense for who the
player is because of his

00:32:52.050 --> 00:32:54.290
propensity to score a shot--
if it's basketball--

00:32:54.290 --> 00:32:56.910
from one part of the court
versus another.

00:32:56.910 --> 00:33:00.660
If that player on the left side
always misses the basket

00:33:00.660 --> 00:33:03.020
there, let him to take a shot.

00:33:03.020 --> 00:33:06.810
I'll take it on the rebound
and then pass it up.

00:33:06.810 --> 00:33:09.210
Versus oh, don't let this guy
get here into the key.

00:33:09.210 --> 00:33:10.460
Then we're really in trouble.

00:33:12.970 --> 00:33:15.000
AUDIENCE: With regulation,
I think it's a

00:33:15.000 --> 00:33:16.240
very different situation.

00:33:16.240 --> 00:33:20.790
Because in the previous
antitrust things, it's been

00:33:20.790 --> 00:33:23.240
actually pro-consumer
to limit the amount

00:33:23.240 --> 00:33:24.680
of data people have.

00:33:24.680 --> 00:33:26.530
There's a reason people go to
Amazon, because they've got

00:33:26.530 --> 00:33:28.500
more data and better data
than anybody else.

00:33:28.500 --> 00:33:31.560
So in fact if you use antitrust
against there, you

00:33:31.560 --> 00:33:33.090
may in fact make life
worse for the

00:33:33.090 --> 00:33:35.660
consumers rather than better.

00:33:35.660 --> 00:33:37.160
KENNETH CUKIER: That
is absolutely true.

00:33:37.160 --> 00:33:39.940
Now the question where this is
going to take us-- and we need

00:33:39.940 --> 00:33:43.500
to have a societal conversation
about it-- is

00:33:43.500 --> 00:33:44.720
whose data is it?

00:33:44.720 --> 00:33:47.510
Whose rights to the
data should it be?

00:33:47.510 --> 00:33:50.450
Does the individual own the data
because it's his or her

00:33:50.450 --> 00:33:51.080
click stream?

00:33:51.080 --> 00:33:52.070
That sounds logical.

00:33:52.070 --> 00:33:56.460
But of course, they decided to
go to that website, and that

00:33:56.460 --> 00:34:00.040
website invested in collecting
the data and analyzing it.

00:34:00.040 --> 00:34:02.630
Should they be required to hand
it over, particularly if

00:34:02.630 --> 00:34:04.010
they're going optimize--

00:34:04.010 --> 00:34:05.080
let's take Amazon--

00:34:05.080 --> 00:34:06.800
their own algorithms so that
they can make great

00:34:06.800 --> 00:34:07.580
recommendations.

00:34:07.580 --> 00:34:09.780
Why would they want to be able
to give that to the customer

00:34:09.780 --> 00:34:11.860
so they can hand it off
to Barnes and Noble?

00:34:11.860 --> 00:34:13.885
You're enriching your
competitor.

00:34:13.885 --> 00:34:15.190
That sounds almost like
eminent domain.

00:34:15.190 --> 00:34:18.040
That sounds like a governmental
takings.

00:34:18.040 --> 00:34:21.300
We don't know how to answer
these questions.

00:34:21.300 --> 00:34:26.300
But the point here is that
what rights does the

00:34:26.300 --> 00:34:28.489
individual have to
his or her data?

00:34:28.489 --> 00:34:29.510
Should it be transparent?

00:34:29.510 --> 00:34:31.830
Should there be data
portability?

00:34:31.830 --> 00:34:34.900
For telephone numbers, we had to
create number portability.

00:34:34.900 --> 00:34:37.020
And that seems to be a very good
way to get carriers to

00:34:37.020 --> 00:34:41.020
actually love us rather
than to lock us in.

00:34:41.020 --> 00:34:44.440
Do we need the same thing in
the world of big data?

00:34:44.440 --> 00:34:45.880
I think that your public-policy
people should be

00:34:45.880 --> 00:34:46.400
thinking about it.

00:34:46.400 --> 00:34:48.300
They probably already are.

00:34:48.300 --> 00:34:49.590
And we need to--

00:34:49.590 --> 00:34:51.909
and not coming up with answers,
but starting the

00:34:51.909 --> 00:34:53.600
discussion and having
the debate.

00:34:58.770 --> 00:34:59.460
Please.

00:34:59.460 --> 00:35:00.960
AUDIENCE: One of the three
things which you mentioned are

00:35:00.960 --> 00:35:02.670
important is mindset.

00:35:02.670 --> 00:35:05.740
So you have some framework or
principles that one can follow

00:35:05.740 --> 00:35:07.060
and improve on that?

00:35:07.060 --> 00:35:10.030
Because that's one thing which
is not as commoditized as with

00:35:10.030 --> 00:35:11.410
[INAUDIBLE].

00:35:11.410 --> 00:35:13.580
KENNETH CUKIER: Yeah, no.

00:35:13.580 --> 00:35:14.920
I don't have any--

00:35:14.920 --> 00:35:19.100
there's no simple list or
there's no recommendations I

00:35:19.100 --> 00:35:21.120
would put forward.

00:35:21.120 --> 00:35:24.850
Because this is sort of about
the spark of creativity.

00:35:24.850 --> 00:35:26.680
It's a little bit
da Vinci like.

00:35:26.680 --> 00:35:32.180
So I think what is required
is just for very creative

00:35:32.180 --> 00:35:35.910
individuals to look at what's
going on around them and

00:35:35.910 --> 00:35:40.360
breath the hurly-burly
of humanity and see

00:35:40.360 --> 00:35:41.610
the filament of it.

00:35:44.480 --> 00:35:48.170
The whole point of Google
was page rank.

00:35:48.170 --> 00:35:50.650
But that was just
the algorithm.

00:35:50.650 --> 00:35:54.120
The genius was to understand
that every single interaction

00:35:54.120 --> 00:35:59.550
with the content gave you
another signal to improve the

00:35:59.550 --> 00:36:01.170
search result.

00:36:01.170 --> 00:36:03.510
And that was, if you will,
all you need is one

00:36:03.510 --> 00:36:05.480
good idea in life.

00:36:05.480 --> 00:36:07.750
And if you really go
full-throttle with it-- and

00:36:07.750 --> 00:36:08.800
it's a good idea--

00:36:08.800 --> 00:36:10.230
it's limitless.

00:36:10.230 --> 00:36:13.740
So like Oren Etzioni just had
this idea that I can take

00:36:13.740 --> 00:36:15.850
something that nobody
knows the answer to.

00:36:15.850 --> 00:36:17.120
But the answer exists.

00:36:17.120 --> 00:36:18.490
It's hidden in plain sight.

00:36:18.490 --> 00:36:19.380
I can get the data.

00:36:19.380 --> 00:36:21.870
And if I do the right thing with
the data, I can actually

00:36:21.870 --> 00:36:24.010
transform it and get the insight
that we need and

00:36:24.010 --> 00:36:25.800
create new forms of value.

00:36:25.800 --> 00:36:29.260
There is no simple way to
develop that sort of mindset.

00:36:29.260 --> 00:36:30.770
A lot of it is luck.

00:36:30.770 --> 00:36:33.650
There are lots of people that
I know of prior to Oren

00:36:33.650 --> 00:36:36.720
Etzioni who had that idea.

00:36:36.720 --> 00:36:39.490
There was a company called
Strong Numbers in Boston about

00:36:39.490 --> 00:36:41.280
1998 by Jeff Hyatt.

00:36:41.280 --> 00:36:42.770
He wanted to be the Blue
Book for everything.

00:36:42.770 --> 00:36:44.390
He thought about all
the things that you

00:36:44.390 --> 00:36:46.802
could do with data.

00:36:46.802 --> 00:36:48.980
He was a little bit too early.

00:36:48.980 --> 00:36:51.870
Dot-com bubble burst, and
so did his dreams.

00:36:51.870 --> 00:36:53.740
Went on to build other
companies and do

00:36:53.740 --> 00:36:54.840
very well for himself.

00:36:54.840 --> 00:36:57.880
But it just shows that there's
a lot of factors involved.

00:37:00.990 --> 00:37:01.240
AUDIENCE: Hi.

00:37:01.240 --> 00:37:04.280
So my first question was
actually already answered by

00:37:04.280 --> 00:37:05.720
you in terms of who
owns the data.

00:37:05.720 --> 00:37:10.100
But more specifically with the
American Express example.

00:37:10.100 --> 00:37:12.130
So do you have to purchase
that data from--

00:37:12.130 --> 00:37:12.780
not American Express.

00:37:12.780 --> 00:37:13.720
American Airlines.

00:37:13.720 --> 00:37:15.870
Did he have to purchase the
data, or was he able to gain

00:37:15.870 --> 00:37:17.450
access to the data?

00:37:17.450 --> 00:37:18.180
KENNETH CUKIER: Great
question.

00:37:18.180 --> 00:37:21.970
So the point about American
Airlines was that was the

00:37:21.970 --> 00:37:25.100
airline carrier who built the
original airline computerized

00:37:25.100 --> 00:37:27.450
reservation network
called Sabre.

00:37:27.450 --> 00:37:32.400
So when Oren Etzioni wanted to
get the data, he wasn't going

00:37:32.400 --> 00:37:32.990
to go to Sabre.

00:37:32.990 --> 00:37:35.160
And the reason why is Sabre is
probably the biggest airline

00:37:35.160 --> 00:37:37.150
reservation network, and they
have no incentive to sell it.

00:37:37.150 --> 00:37:38.910
Because that's just
not what they do.

00:37:38.910 --> 00:37:41.500
So he had to go to one of the
start-ups, one of sort of the

00:37:41.500 --> 00:37:43.950
hungrier people that were
the challengers in

00:37:43.950 --> 00:37:44.760
there to get the data.

00:37:44.760 --> 00:37:48.550
And he found one called
ITA Software.

00:37:48.550 --> 00:37:50.350
OK, you see where this
story's going to end.

00:37:50.350 --> 00:37:51.260
This is great.

00:37:51.260 --> 00:37:53.830
So he goes to ITA Software
and says, will you do it?

00:37:53.830 --> 00:37:56.260
And man, they've got a problem
on their hands.

00:37:56.260 --> 00:37:58.720
Because on one hand, they need
the data from the airlines,

00:37:58.720 --> 00:38:00.720
and this is going to really
screw over the airlines.

00:38:00.720 --> 00:38:01.540
On the other hand.

00:38:01.540 --> 00:38:03.230
Oren's going to pay them a
little bit of money and give

00:38:03.230 --> 00:38:03.690
them a commission.

00:38:03.690 --> 00:38:05.220
So they don't know what to do.

00:38:05.220 --> 00:38:06.520
So actually, I interviewed--

00:38:06.520 --> 00:38:07.420
and they're just a bunch.

00:38:07.420 --> 00:38:09.290
Are these airline executives?

00:38:09.290 --> 00:38:09.470
No.

00:38:09.470 --> 00:38:12.410
These are a bunch of MIT PhDs
and stats who did it because

00:38:12.410 --> 00:38:13.720
they thought it was a really
complex problem

00:38:13.720 --> 00:38:14.870
and a lot of fun.

00:38:14.870 --> 00:38:16.870
So I interviewed one
of the co-founders.

00:38:16.870 --> 00:38:17.550
And I said, well,
what did you do?

00:38:17.550 --> 00:38:23.160
And he said, well, the truth is
we actually kind of came up

00:38:23.160 --> 00:38:24.830
with that idea ourselves
independently

00:38:24.830 --> 00:38:25.910
before Oren did it.

00:38:25.910 --> 00:38:28.580
And we did it internally just
for fun, but we could never

00:38:28.580 --> 00:38:30.330
release it as a product.

00:38:30.330 --> 00:38:32.570
Because we just knew it was
going to really harm us.

00:38:32.570 --> 00:38:34.210
We'd never be able to get
the data from people.

00:38:34.210 --> 00:38:36.440
But this was a way that we could
license the data at an

00:38:36.440 --> 00:38:40.270
arm's-length way and still get
a couple guineas for it.

00:38:40.270 --> 00:38:41.630
And he had the data.

00:38:41.630 --> 00:38:43.840
So it shows you that there's
these competitive interests.

00:38:43.840 --> 00:38:46.150
So what happened to
ITA Software?

00:38:46.150 --> 00:38:47.090
They were acquired.

00:38:47.090 --> 00:38:48.520
For how much?

00:38:48.520 --> 00:38:50.850
Between $700 million and
$800 million dollars?

00:38:50.850 --> 00:38:51.305
By whom?

00:38:51.305 --> 00:38:53.040
By Google.

00:38:53.040 --> 00:38:54.250
So why?

00:38:54.250 --> 00:38:56.010
Well, you guys can
answer that.

00:38:56.010 --> 00:38:59.780
I know that when I do my
searches, I see the airline

00:38:59.780 --> 00:39:01.170
listings in, and that's
a great feature.

00:39:01.170 --> 00:39:03.480
But I'm sure you're playing a
stronger hand and a lot more

00:39:03.480 --> 00:39:04.570
long-term one.

00:39:04.570 --> 00:39:05.890
The regulators walked in.

00:39:05.890 --> 00:39:09.530
It was one of the real first
substantial essentially

00:39:09.530 --> 00:39:11.910
antitrust remedies against
Google on this.

00:39:11.910 --> 00:39:14.960
And what it was it was sort of
a must-license provision with

00:39:14.960 --> 00:39:19.940
a reporting requirement going
back to the companies, and

00:39:19.940 --> 00:39:22.110
essentially to the FTC.

00:39:22.110 --> 00:39:24.110
For a period of a couple years--
maybe two or three,

00:39:24.110 --> 00:39:25.250
maybe five years--

00:39:25.250 --> 00:39:27.650
they couldn't actually cut off
the license that they had with

00:39:27.650 --> 00:39:29.550
people like Kayak, et cetera,
because they were afraid you

00:39:29.550 --> 00:39:31.210
were going to become the world's
biggest travel agent

00:39:31.210 --> 00:39:32.730
and dominate everyone.

00:39:32.730 --> 00:39:34.450
But the point here is this.

00:39:34.450 --> 00:39:36.320
Think about the sums.

00:39:36.320 --> 00:39:39.454
Oren Etzioni's Farecast,
$100 million.

00:39:39.454 --> 00:39:44.010
ITA Software, $700 million.

00:39:44.010 --> 00:39:48.290
The difference here is that the
algorithm and the skills

00:39:48.290 --> 00:39:49.960
is really good, and the service
is really good.

00:39:49.960 --> 00:39:51.950
But he who has the data--

00:39:51.950 --> 00:39:53.360
that's the gold.

00:39:59.340 --> 00:40:01.500
AUDIENCE: Do you see this
societal shifts, particularly

00:40:01.500 --> 00:40:02.170
in America?

00:40:02.170 --> 00:40:05.090
I think big data and
individualism is a really

00:40:05.090 --> 00:40:07.920
interesting area to think about
and whether this changes

00:40:07.920 --> 00:40:11.540
the way that we think about an
individual's role in society.

00:40:11.540 --> 00:40:14.710
The examples you were giving
of a criminal who is 99%

00:40:14.710 --> 00:40:18.910
likely to recommit versus 1%
likely to rebuild his life and

00:40:18.910 --> 00:40:22.560
be a productive member
of society.

00:40:22.560 --> 00:40:26.280
Hedging for the benefit of
society is to put all 100 back

00:40:26.280 --> 00:40:27.560
into jail and leave
them there.

00:40:27.560 --> 00:40:30.750
How does this impact how we
think about individual benefit

00:40:30.750 --> 00:40:31.930
versus societal benefit?

00:40:31.930 --> 00:40:35.990
And does this also play into
future governmental shifts?

00:40:35.990 --> 00:40:36.670
KENNETH CUKIER: OK.

00:40:36.670 --> 00:40:41.580
So in the case of a
criminal-justice system, let's

00:40:41.580 --> 00:40:43.380
have that debate.

00:40:43.380 --> 00:40:48.240
Because I think it's not an
easy one, and anyone who

00:40:48.240 --> 00:40:51.590
thinks it is doesn't understand
the problem.

00:40:51.590 --> 00:40:55.580
If I can tell you with a 99%
degree of accuracy that that

00:40:55.580 --> 00:41:00.330
man is going to commit a violent
crime, I would be

00:41:00.330 --> 00:41:02.235
remiss from intervening.

00:41:05.500 --> 00:41:09.010
And it would look like I'm
almost anti-science if I said,

00:41:09.010 --> 00:41:11.570
you know, I just
think that 1%--

00:41:11.570 --> 00:41:13.160
we got to give them the
benefit of the doubt.

00:41:13.160 --> 00:41:15.110
You just never know.

00:41:15.110 --> 00:41:18.210
It just doesn't look right.

00:41:18.210 --> 00:41:24.650
So on the other hand, this is
one of the most heinous

00:41:24.650 --> 00:41:27.330
affronts to the dignity
of the individual that

00:41:27.330 --> 00:41:29.810
we could ever conceive.

00:41:29.810 --> 00:41:31.850
And we don't have any experience
thinking through

00:41:31.850 --> 00:41:33.410
this issue.

00:41:33.410 --> 00:41:36.800
This is so essentially that we
figure it out, that we have

00:41:36.800 --> 00:41:39.860
the debate, that the
debate starts now.

00:41:39.860 --> 00:41:41.710
Now what about data
for individuals?

00:41:41.710 --> 00:41:42.480
What does that mean?

00:41:42.480 --> 00:41:45.500
Well, in Athens if you
were a male, you

00:41:45.500 --> 00:41:47.130
served in the military.

00:41:47.130 --> 00:41:51.030
If you didn't want to sever
in the military, leave.

00:41:51.030 --> 00:41:53.230
Right now, we think that one of
the most precious things we

00:41:53.230 --> 00:41:58.260
have is data about our bodies,
our health care, our privacy.

00:41:58.260 --> 00:41:59.650
Let's change the debate.

00:41:59.650 --> 00:42:01.810
Let's change the argument
entirely.

00:42:01.810 --> 00:42:03.290
Let's invert the burden
of proof.

00:42:03.290 --> 00:42:06.390
Let's just say that if you're
a citizen of a country, you

00:42:06.390 --> 00:42:09.460
have to share your data on your
health care in a global

00:42:09.460 --> 00:42:13.250
commons so that researchers can
learn from it and treat

00:42:13.250 --> 00:42:14.720
everyone's health better.

00:42:14.720 --> 00:42:16.300
You don't have to do that.

00:42:16.300 --> 00:42:17.950
Leave.

00:42:17.950 --> 00:42:20.100
It might sound draconian, but
the fact is do you have a

00:42:20.100 --> 00:42:23.370
property right, or some sort of
moral right to your data?

00:42:23.370 --> 00:42:26.450
Well, I don't to my image if I'm
walking down the street.

00:42:26.450 --> 00:42:28.770
And we do know that I can learn
a lot from the data.

00:42:28.770 --> 00:42:31.670
And we also know from stats that
if we allow some people

00:42:31.670 --> 00:42:33.930
to back out for whatever
reason, it really

00:42:33.930 --> 00:42:35.930
becomes very imperfect.

00:42:35.930 --> 00:42:38.300
So suddenly, I think that we
should change the debate.

00:42:38.300 --> 00:42:40.960
And I think the most obvious
one would be health care.

00:42:40.960 --> 00:42:43.510
But often, when you look at
these issues-- as you've

00:42:43.510 --> 00:42:45.960
pointed out to in big data--

00:42:45.960 --> 00:42:48.050
these are new issues that
we have for us.

00:42:48.050 --> 00:42:51.090
We've had a bit of sloppy
thinking about it lately,

00:42:51.090 --> 00:42:53.400
because we haven't had
to deal with it.

00:42:53.400 --> 00:42:56.890
And because the whole issue of
big data has been absconded

00:42:56.890 --> 00:42:59.510
with by the technology vendors
as the latest flavor of

00:42:59.510 --> 00:43:01.410
chocolate ice cream.

00:43:01.410 --> 00:43:04.110
But now, let's calm down, and
let's think about it.

00:43:04.110 --> 00:43:05.360
The debate should start now.

00:43:08.040 --> 00:43:09.640
AUDIENCE: My question is
kind of a follow-up.

00:43:09.640 --> 00:43:13.440
So let's assume that
all data is public.

00:43:13.440 --> 00:43:16.372
You don't have any
data barons.

00:43:16.372 --> 00:43:18.370
How does that influence
the game?

00:43:18.370 --> 00:43:23.230
And specifically, humans change
their behavior, and how

00:43:23.230 --> 00:43:27.340
does having data that's correct
as of yesterday based

00:43:27.340 --> 00:43:29.640
on what I can infer--

00:43:29.640 --> 00:43:30.310
I'm sorry--

00:43:30.310 --> 00:43:34.130
all of us in [INAUDIBLE] can
infer and predict what we all

00:43:34.130 --> 00:43:36.200
of us are going to do
tomorrow if we are

00:43:36.200 --> 00:43:38.150
reacting to this data?

00:43:38.150 --> 00:43:38.450
KENNETH CUKIER: Yeah.

00:43:38.450 --> 00:43:41.230
So yeah, there's a great
circularity that the data is

00:43:41.230 --> 00:43:42.250
going to be making
predictions.

00:43:42.250 --> 00:43:43.700
We're going to learn about these
predictions, and we're

00:43:43.700 --> 00:43:46.360
going to change our behavior
based on those

00:43:46.360 --> 00:43:48.940
predictions ever thus.

00:43:48.940 --> 00:43:49.620
Right?

00:43:49.620 --> 00:43:52.440
This is just going to be
the reality that we're

00:43:52.440 --> 00:43:53.280
going to live with.

00:43:53.280 --> 00:43:57.230
So in a way, the data will
always be fallible.

00:43:57.230 --> 00:43:59.380
You'll never have the
perfect prediction,

00:43:59.380 --> 00:44:00.890
because you can always--

00:44:00.890 --> 00:44:04.440
this individual will learn that
the algorithms nailed me

00:44:04.440 --> 00:44:07.200
for shoplifting before I've
even gone into the store.

00:44:07.200 --> 00:44:08.690
I'm not now going to go into
the store, and so the

00:44:08.690 --> 00:44:09.730
prediction was wrong.

00:44:09.730 --> 00:44:12.270
Now if we arrest him, the
burden of proof is gone.

00:44:12.270 --> 00:44:15.380
Because we can never actually
validate the fact the

00:44:15.380 --> 00:44:18.230
prediction was going to be
accurate, because we never

00:44:18.230 --> 00:44:20.160
allowed him to commit
the crime.

00:44:20.160 --> 00:44:21.340
This recursvity--

00:44:21.340 --> 00:44:25.270
this weird pernicious circle
in which we're constantly

00:44:25.270 --> 00:44:27.720
reacting to the algorithm,
and thereby changing the

00:44:27.720 --> 00:44:29.430
prediction that we're making,
is going to be

00:44:29.430 --> 00:44:30.630
a feature of life.

00:44:30.630 --> 00:44:33.070
And you can imagine that this
is another conversation we

00:44:33.070 --> 00:44:36.200
need to have, another thing
we have to think through.

00:44:36.200 --> 00:44:38.520
Yeah.

00:44:38.520 --> 00:44:39.830
Good.

00:44:39.830 --> 00:44:40.560
Thank you very much.

00:44:40.560 --> 00:44:41.810
It's been a delight.

