WEBVTT
Kind: captions
Language: en

00:00:00.507 --> 00:00:02.090
JAKE ARCHIBALD:
Hello, I'm Jake, and I

00:00:02.090 --> 00:00:03.760
work in Developer Relations.

00:00:03.760 --> 00:00:05.270
This means I live
in constant fear

00:00:05.270 --> 00:00:07.140
that my developer
skills are going to rot

00:00:07.140 --> 00:00:10.170
and fall off, because I spend
too much time doing stuff

00:00:10.170 --> 00:00:13.570
like this rather than
building actual real stuff.

00:00:13.570 --> 00:00:15.810
This is why when someone
in Dev Rel builds a thing,

00:00:15.810 --> 00:00:17.119
we won't shut up about it.

00:00:17.119 --> 00:00:19.160
It's our proof to the
world that we still got it.

00:00:19.160 --> 00:00:19.920
We're still cool.

00:00:19.920 --> 00:00:23.300
We're still one of
you, a developer.

00:00:23.300 --> 00:00:24.969
And on that note,
look what I made.

00:00:24.969 --> 00:00:26.510
It's a little
responsive web app that

00:00:26.510 --> 00:00:29.290
lets you search for and
read Wikipedia articles.

00:00:29.290 --> 00:00:31.310
Now I know what you're thinking.

00:00:31.310 --> 00:00:35.440
Hasn't this already been
created before by Wikipedia?

00:00:35.440 --> 00:00:36.500
Well, yes, shut up.

00:00:36.500 --> 00:00:37.430
Forget about that.

00:00:37.430 --> 00:00:38.720
That's not the point.

00:00:38.720 --> 00:00:40.870
I want to talk
about performance.

00:00:40.870 --> 00:00:42.800
First up, let's
immerse ourselves

00:00:42.800 --> 00:00:44.210
in the current load time.

00:00:44.210 --> 00:00:45.229
Ready, setty, go.

00:00:55.010 --> 00:00:56.520
That wasn't so fun.

00:00:56.520 --> 00:00:58.600
That was the load time
of one of the articles

00:00:58.600 --> 00:01:00.230
on a 3G connection.

00:01:00.230 --> 00:01:02.390
It's important to watch
the 3G load times,

00:01:02.390 --> 00:01:04.950
because even though we
have 4G now, those users

00:01:04.950 --> 00:01:07.660
are on 3G or worse
a lot of the time,

00:01:07.660 --> 00:01:10.030
a quarter of the time
in the US, half the time

00:01:10.030 --> 00:01:11.820
in large parts of Europe.

00:01:11.820 --> 00:01:12.880
So here's our problem.

00:01:12.880 --> 00:01:17.160
We saw 2.7 seconds of nothing
and a further 2.1 seconds

00:01:17.160 --> 00:01:19.810
of basic interface without
meaningful content,

00:01:19.810 --> 00:01:21.950
just a toolbar and a spinner.

00:01:21.950 --> 00:01:26.160
Even on 5 megabit, we're waiting
over two seconds for content.

00:01:26.160 --> 00:01:29.010
As users of the web, we
know this kind of load time

00:01:29.010 --> 00:01:32.070
is a bad experience, but
that bad experience directly

00:01:32.070 --> 00:01:35.150
impacts download conversions,
donation conversions,

00:01:35.150 --> 00:01:36.622
and outright revenue.

00:01:36.622 --> 00:01:38.080
And there are some
studies that you

00:01:38.080 --> 00:01:40.990
can throw at the money people to
convince them that performance

00:01:40.990 --> 00:01:43.370
really does matter.

00:01:43.370 --> 00:01:45.370
I'm going to show you how
you can slash the load

00:01:45.370 --> 00:01:46.953
time of something
like this, and we'll

00:01:46.953 --> 00:01:49.790
add in some cool new features
along the way as well.

00:01:49.790 --> 00:01:52.630
So here's the markup, roughly.

00:01:52.630 --> 00:01:57.030
It's got CSS, JavaScript,
and nothing else.

00:01:57.030 --> 00:01:59.310
I'm relying on JavaScript
for all my rendering,

00:01:59.310 --> 00:02:00.740
which is kind of bad.

00:02:00.740 --> 00:02:02.500
So don't do that.

00:02:02.500 --> 00:02:04.500
Our initial render
is pretty static.

00:02:04.500 --> 00:02:07.230
So let's do it
without JavaScript.

00:02:07.230 --> 00:02:09.699
So we'll add some markup
in for the title bar

00:02:09.699 --> 00:02:11.870
and mark the
JavaScript as async.

00:02:11.870 --> 00:02:14.650
Now it won't block rendering,
and it will execute

00:02:14.650 --> 00:02:16.660
whenever it finishes loading.

00:02:16.660 --> 00:02:19.180
Doing this knocks around half
a second off our first render

00:02:19.180 --> 00:02:20.490
time on 3G.

00:02:20.490 --> 00:02:22.150
And the bigger
your JavaScript is,

00:02:22.150 --> 00:02:24.550
the bigger gains you'll
see with this fix.

00:02:24.550 --> 00:02:25.960
But we're not done.

00:02:25.960 --> 00:02:28.180
We need to prioritize our CSS.

00:02:28.180 --> 00:02:31.290
We can't render until all
of our CSS is downloaded,

00:02:31.290 --> 00:02:33.440
but we only actually need
a tiny fraction of it

00:02:33.440 --> 00:02:34.720
for the first render.

00:02:34.720 --> 00:02:35.970
So we'll do this.

00:02:35.970 --> 00:02:37.720
We'll inline the bits
for the first render

00:02:37.720 --> 00:02:40.050
and then load the rest
asynchronously using

00:02:40.050 --> 00:02:41.440
JavaScript.

00:02:41.440 --> 00:02:44.500
The Filament Group created
loadCSS to do just that.

00:02:44.500 --> 00:02:47.390
It's a tiny script that you
can inline in your page.

00:02:47.390 --> 00:02:48.940
So that's what we'll do.

00:02:48.940 --> 00:02:51.100
We'll hide our article
element so we don't get

00:02:51.100 --> 00:02:52.780
a flash of unstyled content.

00:02:52.780 --> 00:02:55.280
We'll load our CSS,
and once it's ready,

00:02:55.280 --> 00:02:57.110
we'll show the article.

00:02:57.110 --> 00:02:59.770
This is a huge win for
slower connections.

00:02:59.770 --> 00:03:02.500
Only 1.4 second of
blank screen on 3G,

00:03:02.500 --> 00:03:04.380
that's a huge improvement.

00:03:04.380 --> 00:03:06.470
And the bigger your CSS
is, the bigger gains

00:03:06.470 --> 00:03:08.160
you'll see with this fix.

00:03:08.160 --> 00:03:11.280
Now, I realize there's been a
lot of code and graphs so far,

00:03:11.280 --> 00:03:13.350
and that actually goes
against the guidance we've

00:03:13.350 --> 00:03:15.030
had for creating these videos.

00:03:15.030 --> 00:03:17.380
So to address the
balance, here are

00:03:17.380 --> 00:03:19.130
some pictures I took at a zoo.

00:03:19.130 --> 00:03:21.430
[MUSIC PLAYING]

00:03:22.350 --> 00:03:23.620
Welcome back.

00:03:23.620 --> 00:03:27.240
So we're down to 1.4 second
on 3G, but all we've improved

00:03:27.240 --> 00:03:30.810
is the time to this,
not the actual content.

00:03:30.810 --> 00:03:31.890
Let's fix that.

00:03:31.890 --> 00:03:34.720
Our bottleneck is once
again our JavaScript.

00:03:34.720 --> 00:03:37.060
You see, the browser
makes a request.

00:03:37.060 --> 00:03:38.920
It gets back a
page, and that page

00:03:38.920 --> 00:03:41.831
tells the browser to go fetch
some JavaScript and CSS.

00:03:41.831 --> 00:03:43.580
And then that JavaScript
tells the browser

00:03:43.580 --> 00:03:45.530
to request the
article data, which

00:03:45.530 --> 00:03:49.880
we get from Wikipedia's
API plus a few alterations.

00:03:49.880 --> 00:03:51.060
You see the problem?

00:03:51.060 --> 00:03:53.580
We've made two back and
forths before we even think

00:03:53.580 --> 00:03:55.490
about downloading the content.

00:03:55.490 --> 00:03:57.690
This is super inefficient
and a big problem

00:03:57.690 --> 00:04:00.090
with JavaScript-rendered
sites, particularly those

00:04:00.090 --> 00:04:02.060
created with frameworks
as the JavaScript

00:04:02.060 --> 00:04:04.350
tends to be pretty big.

00:04:04.350 --> 00:04:07.690
Instead, let's render
the page on the server.

00:04:07.690 --> 00:04:09.890
So the request goes out,
we compile the content

00:04:09.890 --> 00:04:13.100
on the server, and
send back plain HTML.

00:04:13.100 --> 00:04:14.520
So how much quicker is that?

00:04:14.520 --> 00:04:17.829
It is worse.

00:04:17.829 --> 00:04:18.660
Can we cut?

00:04:18.660 --> 00:04:21.534
[MUSIC PLAYING]

00:04:21.534 --> 00:04:23.880
OK, OK, I figured it out.

00:04:23.880 --> 00:04:25.980
Wikipedia is a bit
of a bottleneck.

00:04:25.980 --> 00:04:29.990
Our API request to them takes
around 900 milliseconds.

00:04:29.990 --> 00:04:32.860
Probably because Wikipedia
contains five billion articles

00:04:32.860 --> 00:04:36.060
covering quantum physics,
the rule of threes,

00:04:36.060 --> 00:04:38.860
and they're being access
thousands of times a second.

00:04:38.860 --> 00:04:40.710
But you might run
into the same problem

00:04:40.710 --> 00:04:44.090
with many third-party APIs,
maybe even certain database

00:04:44.090 --> 00:04:46.390
requests on your own server.

00:04:46.390 --> 00:04:49.650
So our server gets the request,
it goes off to Wikipedia,

00:04:49.650 --> 00:04:52.890
takes that 900 millisecond
hit, and only then

00:04:52.890 --> 00:04:55.020
does it send stuff
back to the client.

00:04:55.020 --> 00:04:58.490
In the meantime, the user's
left looking at a blank screen.

00:04:58.490 --> 00:05:00.020
But there's a better way.

00:05:00.020 --> 00:05:03.690
We fix this by streaming the
response using chunked encoding

00:05:03.690 --> 00:05:07.670
or multiple data frames
if you're speaking HTTP/2.

00:05:07.670 --> 00:05:09.740
This allows us to
start sending the HTML

00:05:09.740 --> 00:05:11.920
before we have
the whole content.

00:05:11.920 --> 00:05:14.730
So we respond immediately
with our header and toolbar.

00:05:14.730 --> 00:05:16.760
That gets is this
fast first render

00:05:16.760 --> 00:05:20.110
and lets the browser know about
the JavaScript and extra CSS.

00:05:20.110 --> 00:05:22.550
Then as we get content
back from Wikipedia,

00:05:22.550 --> 00:05:25.800
we can transform it and
send it on to the browser.

00:05:25.800 --> 00:05:29.350
This is quite easy with a
no-js or golang backend.

00:05:29.350 --> 00:05:31.480
With no-js, I can just
call write whenever

00:05:31.480 --> 00:05:33.940
I have something worth
sending, or I can pipe a stream

00:05:33.940 --> 00:05:35.530
to the response.

00:05:35.530 --> 00:05:38.040
There's also the Dust.js
templating language.

00:05:38.040 --> 00:05:39.940
I don't much care
for the syntax,

00:05:39.940 --> 00:05:41.330
but it supports streaming.

00:05:41.330 --> 00:05:43.430
It'll output as much
as it can until it

00:05:43.430 --> 00:05:45.240
encounters a
template value that's

00:05:45.240 --> 00:05:47.180
either a promise or a stream.

00:05:47.180 --> 00:05:48.680
And then it'll wait
for that promise

00:05:48.680 --> 00:05:51.290
to fulfill or pipe the stream.

00:05:51.290 --> 00:05:54.280
And the result-- we fixed
our first render time

00:05:54.280 --> 00:05:57.730
and massively improved the
content rendering time.

00:05:57.730 --> 00:06:00.190
Let's look at that side
by side with the first

00:06:00.190 --> 00:06:01.810
JavaScript-driven iteration.

00:06:01.810 --> 00:06:05.330
We'll set them off
at the same time,

00:06:05.330 --> 00:06:07.160
and you can see the difference.

00:06:07.160 --> 00:06:08.650
We are now web
performance winners.

00:06:08.650 --> 00:06:11.830
[MUSIC PLAYING]

00:06:11.830 --> 00:06:15.970
But wait, what about the second
load with our populated cache?

00:06:15.970 --> 00:06:17.930
Currently cache
load times are not

00:06:17.930 --> 00:06:19.760
dissimilar to normal load times.

00:06:19.760 --> 00:06:21.270
Our bottlenecks are
making a request

00:06:21.270 --> 00:06:24.390
to the server and the server
getting data from Wikipedia,

00:06:24.390 --> 00:06:25.920
and that's the best case.

00:06:25.920 --> 00:06:28.740
We cannot rely on the browser
cache for performance.

00:06:28.740 --> 00:06:31.060
Stuff falls out of the
browser cache all the time,

00:06:31.060 --> 00:06:34.870
or we as developers invalidate
it by making code changes,

00:06:34.870 --> 00:06:37.109
because that's our job.

00:06:37.109 --> 00:06:39.400
Also, there's a connection
type we haven't catered for.

00:06:39.400 --> 00:06:42.700
No, not offline, this.

00:06:42.700 --> 00:06:44.540
I call it Lie-Fi.

00:06:44.540 --> 00:06:45.040
Offline?

00:06:45.040 --> 00:06:46.110
Offline is OK.

00:06:46.110 --> 00:06:47.045
At least it's honest.

00:06:47.045 --> 00:06:47.960
Can I fetch this?

00:06:47.960 --> 00:06:48.250
No.

00:06:48.250 --> 00:06:48.790
Can I go here?

00:06:48.790 --> 00:06:49.120
No.

00:06:49.120 --> 00:06:49.703
Can I do this?

00:06:49.703 --> 00:06:50.780
No.

00:06:50.780 --> 00:06:53.300
Lie-Fi is like offline,
but it trolls you

00:06:53.300 --> 00:06:55.014
by pretending to be online.

00:06:55.014 --> 00:06:56.930
It'll attempt to make a
connection for minutes

00:06:56.930 --> 00:06:58.850
and still fail.

00:06:58.850 --> 00:07:00.380
Let's fix this.

00:07:00.380 --> 00:07:02.810
Let's take control of
the cache and page loads

00:07:02.810 --> 00:07:04.150
using Service Worker.

00:07:04.150 --> 00:07:06.420
Now I'm not going to dive
into the ServiceWorker API.

00:07:06.420 --> 00:07:08.870
There's an HTML5 Rocks
article for that.

00:07:08.870 --> 00:07:11.210
But here's the concept.

00:07:11.210 --> 00:07:13.300
During the first
server-rendered load,

00:07:13.300 --> 00:07:15.239
we register for a ServiceWorker.

00:07:15.239 --> 00:07:17.280
Then it gets everything
it needs from the network

00:07:17.280 --> 00:07:21.010
to render a page-- the CSS,
JavaScript, and basic page

00:07:21.010 --> 00:07:21.950
shell.

00:07:21.950 --> 00:07:23.270
Then it puts them in a cache.

00:07:23.270 --> 00:07:25.270
Now, unlike the
standard browser cache,

00:07:25.270 --> 00:07:28.780
items aren't automatically
removed from this one.

00:07:28.780 --> 00:07:30.260
For the next page
load, we're going

00:07:30.260 --> 00:07:31.990
to go back to rendering
on the client,

00:07:31.990 --> 00:07:36.050
but this time, it's supercharged
by the ServiceWorker.

00:07:36.050 --> 00:07:38.310
The browser requests an
article, and the ServiceWorker

00:07:38.310 --> 00:07:41.430
responds with the HTML,
CSS, and JavaScript,

00:07:41.430 --> 00:07:42.930
and this is super
fast as it doesn't

00:07:42.930 --> 00:07:44.650
require the network at all.

00:07:44.650 --> 00:07:46.560
The connection type
doesn't even matter.

00:07:46.560 --> 00:07:49.020
It's all from a local cache.

00:07:49.020 --> 00:07:51.480
Now the page asks
for article content.

00:07:51.480 --> 00:07:54.080
This delay made our
client render slow before,

00:07:54.080 --> 00:07:56.790
but the ServiceWorker
preempted this request along

00:07:56.790 --> 00:08:00.820
with the initial page, and
it's already on its way.

00:08:00.820 --> 00:08:03.790
This absolutely slashes
our first render time

00:08:03.790 --> 00:08:07.790
to almost instant, but our
content render time kind of

00:08:07.790 --> 00:08:09.115
suffers.

00:08:09.115 --> 00:08:11.490
Remember the problem we saw
with our first server render?

00:08:11.490 --> 00:08:15.240
Well, we've kind of just
recreated that on the client.

00:08:15.240 --> 00:08:18.150
Our JavaScript pulls down
the full Wikipedia article

00:08:18.150 --> 00:08:20.219
before it puts it on the page.

00:08:20.219 --> 00:08:22.510
We're losing time here,
because we've got some content,

00:08:22.510 --> 00:08:25.440
but we're not showing
any of it to the user.

00:08:25.440 --> 00:08:28.430
Over the next year, you'll see a
new API learn to fix all this--

00:08:28.430 --> 00:08:30.110
the Streaming API.

00:08:30.110 --> 00:08:32.210
Parts of it are landing
in Canary already

00:08:32.210 --> 00:08:34.440
so we can make some use of it.

00:08:34.440 --> 00:08:36.360
Here I fetched the
article, but instead

00:08:36.360 --> 00:08:38.870
of getting the full text,
I get a screen reader

00:08:38.870 --> 00:08:41.760
and start siphoning off
the content as it arrives.

00:08:41.760 --> 00:08:44.820
I write the result once
when I have to first 9K,

00:08:44.820 --> 00:08:47.420
and then I write again
once I have to rest.

00:08:47.420 --> 00:08:51.300
Writing it to your HTML twice
like this is kind of hacky,

00:08:51.300 --> 00:08:53.790
but as streaming APIs
land in the browser,

00:08:53.790 --> 00:08:57.700
we'll get access to the
proper streaming HTML parser.

00:08:57.700 --> 00:08:59.900
But even this hacky solution
has improved things.

00:08:59.900 --> 00:09:02.070
We've retained the
quick first render,

00:09:02.070 --> 00:09:05.140
but now our content
render is much better.

00:09:05.140 --> 00:09:06.830
But now that we have
a ServiceWorker,

00:09:06.830 --> 00:09:10.010
we can make even
greater use of it.

00:09:10.010 --> 00:09:14.180
The final step-- if we've got
ServiceWorker caching assets,

00:09:14.180 --> 00:09:16.350
why not let it cache articles?

00:09:16.350 --> 00:09:18.450
You could cache
articles automatically,

00:09:18.450 --> 00:09:19.471
but I'm going let--

00:09:19.471 --> 00:09:19.970
[DING]

00:09:19.970 --> 00:09:21.790
--the user decide.

00:09:21.790 --> 00:09:24.040
With a full cached article,
the content load time

00:09:24.040 --> 00:09:26.270
drops into under
a half a second.

00:09:26.270 --> 00:09:30.710
Not only that, it's that fast on
Wi-Fi, it's that fast offline,

00:09:30.710 --> 00:09:33.600
and it's that fast on Lie-Fi.

00:09:33.600 --> 00:09:35.860
We don't leave users
with old content either.

00:09:35.860 --> 00:09:37.540
When the user looks
at a cached article,

00:09:37.540 --> 00:09:39.498
we can then go to the
network in the background

00:09:39.498 --> 00:09:40.940
and look for updates.

00:09:40.940 --> 00:09:43.780
If we find some, we can just
update the content on the page.

00:09:43.780 --> 00:09:45.184
[DING]

00:09:45.184 --> 00:09:46.600
When swapping
content on the page,

00:09:46.600 --> 00:09:49.790
we need to ensure it's not
disruptive to the user.

00:09:49.790 --> 00:09:53.480
Wikipedia changes are usually
small so it isn't particularly

00:09:53.480 --> 00:09:56.970
risky here, but we could detect
bigger changes in content

00:09:56.970 --> 00:09:59.645
and instead show a
notification inviting the user

00:09:59.645 --> 00:10:02.282
to click something in
order to see the updates.

00:10:02.282 --> 00:10:04.740
These are the things that make
the difference between a web

00:10:04.740 --> 00:10:09.690
app and a great web app-- get to
first render before JavaScript,

00:10:09.690 --> 00:10:12.490
render with minimal
inline CSS, render

00:10:12.490 --> 00:10:14.410
on the server with
response streaming,

00:10:14.410 --> 00:10:17.160
leverage the ServiceWorker for
caching your content shell,

00:10:17.160 --> 00:10:20.300
and even use it for
offline first content.

00:10:20.300 --> 00:10:23.620
This is how we
make the web fast.

00:10:23.620 --> 00:10:25.730
You can check out the
Wikipedia demo on GitHub,

00:10:25.730 --> 00:10:27.760
and if you're interested
in other smart uses

00:10:27.760 --> 00:10:30.740
of ServiceWorker, check
out the offline cookbook,

00:10:30.740 --> 00:10:35.114
SVGOMG, Trained to thrill,
and the Google I/O website.

00:10:35.114 --> 00:10:36.530
And next time
someone from Dev Rel

00:10:36.530 --> 00:10:39.180
shows you something they've
made, give them a hug

00:10:39.180 --> 00:10:43.270
and tell them they're a true
developer just like you.

00:10:43.270 --> 00:10:44.420
Seriously, we need this.

00:10:47.836 --> 00:10:55.163
[MUSIC PLAYING]

