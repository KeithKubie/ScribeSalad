WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.311
[MUSIC PLAYING]

00:00:05.676 --> 00:00:09.600
PRESENTER: I am so proud to
welcome you all here today

00:00:09.600 --> 00:00:14.530
for this very important
discussion that's

00:00:14.530 --> 00:00:16.890
for the Decoding Race talk.

00:00:16.890 --> 00:00:18.690
Over the past
couple of quarters,

00:00:18.690 --> 00:00:22.350
the Race at Google team has
invited national leaders,

00:00:22.350 --> 00:00:24.960
race experts, and
external luminaries

00:00:24.960 --> 00:00:29.370
to guide us through many
similar conversations on race

00:00:29.370 --> 00:00:31.610
and its intersections.

00:00:31.610 --> 00:00:35.790
We're thrilled to bring
the event today to Atlanta,

00:00:35.790 --> 00:00:39.930
covering the most important
topics of microaggressions

00:00:39.930 --> 00:00:43.290
and bringing our
own selves to work.

00:00:43.290 --> 00:00:47.430
Personally, I'm really glad to
see Google taking this subject

00:00:47.430 --> 00:00:48.910
head on.

00:00:48.910 --> 00:00:52.740
I think what we can all learn
by having the conversation,

00:00:52.740 --> 00:00:56.070
by carving out the time
to be here will help us

00:00:56.070 --> 00:00:59.730
at work and beyond and
will enable us to be better

00:00:59.730 --> 00:01:03.530
to our peers and team members.

00:01:03.530 --> 00:01:06.690
We've had a great
lineup for today.

00:01:06.690 --> 00:01:10.080
And I'm thrilled to welcome
Fabiola Charles Stokes

00:01:10.080 --> 00:01:13.800
and Michael Skolnik to talk us
through the agenda for today.

00:01:13.800 --> 00:01:14.728
Thank you.

00:01:14.728 --> 00:01:18.004
[APPLAUSE]

00:01:19.876 --> 00:01:21.060
MICHAEL SKOLNIK: Thank you.

00:01:21.060 --> 00:01:25.050
So I learned a few lessons this
morning that I want to share.

00:01:25.050 --> 00:01:29.080
First is I live in New
York City in Brooklyn.

00:01:29.080 --> 00:01:31.780
I got up at 4
o'clock this morning.

00:01:31.780 --> 00:01:32.665
And I cut my hair.

00:01:35.510 --> 00:01:37.340
And I was not expecting
to speak today.

00:01:37.340 --> 00:01:39.550
But I'm glad I cut
my hair because I

00:01:39.550 --> 00:01:40.660
am going to speak today.

00:01:40.660 --> 00:01:41.920
At least I have a hair cut.

00:01:41.920 --> 00:01:44.346
That's the first lesson is
you never know when they're

00:01:44.346 --> 00:01:45.940
going to call you to speak.

00:01:45.940 --> 00:01:48.700
The second lesson is don't
take a nap on the airplane.

00:01:48.700 --> 00:01:50.460
I never sleep on planes.

00:01:50.460 --> 00:01:53.122
And when I took a nap on
the plane from New York

00:01:53.122 --> 00:01:54.580
to Atlanta this
morning, I woke up.

00:01:54.580 --> 00:01:56.470
And sadly two of
our panelists had

00:01:56.470 --> 00:02:00.490
to cancel, one from New
York and one from Atlanta.

00:02:00.490 --> 00:02:04.340
The great news is Kimberly got
in the plane from California.

00:02:04.340 --> 00:02:07.030
So the one who came the
farthest didn't cancel.

00:02:09.580 --> 00:02:11.590
I am going to--

00:02:11.590 --> 00:02:12.490
this one, this one?

00:02:12.490 --> 00:02:13.060
Either one.

00:02:13.060 --> 00:02:13.768
CREW: Either one.

00:02:13.768 --> 00:02:14.990
MICHAEL SKOLNIK: Fantastic.

00:02:14.990 --> 00:02:18.700
I am going to lead
us in discussion

00:02:18.700 --> 00:02:21.970
with Kimberly Papillon today.

00:02:21.970 --> 00:02:25.820
Sadly, Sean and Theron
could not be with us today.

00:02:25.820 --> 00:02:28.300
But we are going to have
an incredible discussion

00:02:28.300 --> 00:02:29.500
on this topic.

00:02:29.500 --> 00:02:32.170
And our sincere apologies
for their cancellation.

00:02:32.170 --> 00:02:33.670
You now have me.

00:02:33.670 --> 00:02:36.520
My sincerest apologies
for having me.

00:02:36.520 --> 00:02:38.860
But we will have a really
robust conversation

00:02:38.860 --> 00:02:42.144
and look forward to the Q&amp;A
portion of the conversation,

00:02:42.144 --> 00:02:44.560
so we can hear what you all
have to say and your thoughts.

00:02:44.560 --> 00:02:45.984
Fabiola.

00:02:45.984 --> 00:02:49.181
[APPLAUSE]

00:02:49.562 --> 00:02:51.020
FABIOLA STOKES:
Thank you, Michael.

00:02:51.020 --> 00:02:55.970
Luckily, we are all really
apt at thinking on our feet.

00:02:55.970 --> 00:02:59.000
So we managed to switch
the format up just a little

00:02:59.000 --> 00:03:01.280
bit this morning so that we
could ensure that we still

00:03:01.280 --> 00:03:03.774
had a very robust
conversation and a dialogue

00:03:03.774 --> 00:03:04.940
with our esteemed panelists.

00:03:04.940 --> 00:03:09.560
So we are moving the
conversation event style

00:03:09.560 --> 00:03:13.610
from a panel into more
of a fireside chat.

00:03:13.610 --> 00:03:16.340
We'll have our two esteemed
thought leaders with us

00:03:16.340 --> 00:03:19.130
who helped to drive the
conversation followed by what

00:03:19.130 --> 00:03:22.280
we hope will be a very robust
Q&amp;A from those Googlers

00:03:22.280 --> 00:03:24.110
that we have here
with us in the room

00:03:24.110 --> 00:03:25.650
as well as those
on the livestream.

00:03:25.650 --> 00:03:29.520
So if you are watching from
afar, please log into the Dory.

00:03:29.520 --> 00:03:33.830
Its go slash decoding
race hyphen Dory.

00:03:33.830 --> 00:03:36.920
And drop in any questions that
you would like for us to share

00:03:36.920 --> 00:03:39.050
and have answered for you today.

00:03:39.050 --> 00:03:41.390
In addition, after
today's conversation,

00:03:41.390 --> 00:03:44.360
please stay connected
with us on this issue

00:03:44.360 --> 00:03:46.640
as well as others that
are being led by the team

00:03:46.640 --> 00:03:48.800
by signing up for the
race at mailing lists.

00:03:48.800 --> 00:03:49.850
So you can do those.

00:03:49.850 --> 00:03:52.940
All the links for those are
in the emails in the invite

00:03:52.940 --> 00:03:55.130
that we sent out for
the meeting today.

00:03:55.130 --> 00:03:58.520
So in introducing our speakers
for this morning, first

00:03:58.520 --> 00:04:01.340
we have with us
Michael Skolnik whom

00:04:01.340 --> 00:04:04.550
we got to hear from a
little bit just before me.

00:04:04.550 --> 00:04:08.510
Michael is the CEO of
SOZE, a creative agency

00:04:08.510 --> 00:04:10.580
focused on social
impact campaigns

00:04:10.580 --> 00:04:12.920
and triple bottom line
companies in addition

00:04:12.920 --> 00:04:16.670
to being a renowned movement
builder, activist, storyteller,

00:04:16.670 --> 00:04:18.519
and proud father.

00:04:18.519 --> 00:04:21.320
He's a celebrated leader in the
new social justice movement,

00:04:21.320 --> 00:04:22.910
who among other topics--

00:04:22.910 --> 00:04:25.370
excuse me-- help to
ignite conversations

00:04:25.370 --> 00:04:27.560
around America's
relationship with race,

00:04:27.560 --> 00:04:31.100
the death of Trayvon Martin,
Mike Brown and Eric Garner,

00:04:31.100 --> 00:04:33.530
as well as the Obama presidency.

00:04:33.530 --> 00:04:36.590
He's a prolific voice on social
media with more than a quarter

00:04:36.590 --> 00:04:39.290
million followers and a
regular commentator on outlets

00:04:39.290 --> 00:04:45.680
such as CNN, MSNBC,
Fox News, NPR, and HLN.

00:04:45.680 --> 00:04:47.720
From 2009 to 2015,
Michael served

00:04:47.720 --> 00:04:52.280
as president of globalgrind.com,
a millennial-driven news

00:04:52.280 --> 00:04:54.980
website founded by
Russell Simmons.

00:04:54.980 --> 00:04:56.750
And he currently
serves on the board

00:04:56.750 --> 00:04:59.420
of directors for the
Trayvon Martin Foundation,

00:04:59.420 --> 00:05:02.660
the Drug Policy Alliance,
Revolutions Per Minute,

00:05:02.660 --> 00:05:05.180
the Gathering for Justice,
and the Young Partner's

00:05:05.180 --> 00:05:07.250
Board of the Public Theater.

00:05:07.250 --> 00:05:09.770
Earlier in his career,
he spent over a decade

00:05:09.770 --> 00:05:12.470
as an award-winning film
director and producer.

00:05:12.470 --> 00:05:16.550
And we are glad to have
him with us here today.

00:05:16.550 --> 00:05:21.320
Our second speaker for this
afternoon is Kimberly Papillon.

00:05:21.320 --> 00:05:24.170
Kimberly is a nationally
recognized expert

00:05:24.170 --> 00:05:27.360
on medical, legal, and
judicial decision making.

00:05:27.360 --> 00:05:29.540
She has served as
regular faculty

00:05:29.540 --> 00:05:32.840
at the National Judicial
College since 2005

00:05:32.840 --> 00:05:35.570
and delivered over 400
lectures nationally

00:05:35.570 --> 00:05:39.320
and internationally on the
implications of neuroscience,

00:05:39.320 --> 00:05:41.720
psychology, and
implicit association

00:05:41.720 --> 00:05:43.640
in the analysis
of decision making

00:05:43.640 --> 00:05:46.490
in the fields of medicine,
business, education,

00:05:46.490 --> 00:05:48.020
and the justice system.

00:05:48.020 --> 00:05:49.906
If you think you're
in for a treat,

00:05:49.906 --> 00:05:52.850
this is going to be a
really great conversation.

00:05:52.850 --> 00:05:57.470
She has also lectured to judges
in over 20 states as well

00:05:57.470 --> 00:06:00.904
as the United States Securities
and Exchange Commission,

00:06:00.904 --> 00:06:02.570
the United States
Department of Justice,

00:06:02.570 --> 00:06:04.220
and the US Department
of Education.

00:06:06.760 --> 00:06:09.590
Kimberly is an attorney,
who previously served

00:06:09.590 --> 00:06:13.640
as a senior educator for the
California Judicial Council

00:06:13.640 --> 00:06:17.180
as well as represented Fortune
500 companies, government

00:06:17.180 --> 00:06:19.130
entities, and tech startups.

00:06:19.130 --> 00:06:22.790
She has a BA degree from
UC Berkeley and a JD

00:06:22.790 --> 00:06:25.640
from Columbia University
School of Law.

00:06:25.640 --> 00:06:30.140
So please join me in a rousing
welcome for our speakers today

00:06:30.140 --> 00:06:31.940
as they help to lead
us through this really

00:06:31.940 --> 00:06:33.440
critical and important
conversation.

00:06:33.440 --> 00:06:36.332
[APPLAUSE]

00:06:39.741 --> 00:06:41.550
MICHAEL SKOLNIK:
Thank you, Fabiola,

00:06:41.550 --> 00:06:42.990
for those kind introductions.

00:06:42.990 --> 00:06:45.455
I would-- you want the mic?

00:06:45.455 --> 00:06:47.330
Because this is just
for the livestream, huh?

00:06:47.330 --> 00:06:48.960
OK, so we can do mic.

00:06:52.540 --> 00:06:54.610
So thank you for those
kind of introductions.

00:06:54.610 --> 00:06:59.200
I would just give some quick
context to this conversation.

00:06:59.200 --> 00:07:03.100
We have been brought on to
help curate these conversations

00:07:03.100 --> 00:07:05.020
of the Decoding Race series.

00:07:05.020 --> 00:07:08.200
This is now, I think,
our eleventh or twelfth

00:07:08.200 --> 00:07:11.000
conversation that we've
had in this series.

00:07:11.000 --> 00:07:13.480
And we're beginning
to dive deeper

00:07:13.480 --> 00:07:15.370
into the conversations on race.

00:07:15.370 --> 00:07:17.650
So this conversation
is going to be focused

00:07:17.650 --> 00:07:20.050
around microaggressions
and bringing your most

00:07:20.050 --> 00:07:23.302
authentic self to work
here at Google and folks

00:07:23.302 --> 00:07:24.760
who are watching
around the country

00:07:24.760 --> 00:07:26.530
and certainly for
those who will see it

00:07:26.530 --> 00:07:30.140
on YouTube in a few weeks
from folks around the world.

00:07:30.140 --> 00:07:33.880
So if we don't get to
a topic, race obviously

00:07:33.880 --> 00:07:38.170
is a massive topic,
a big conversation,

00:07:38.170 --> 00:07:40.150
a big challenge we
face in this country

00:07:40.150 --> 00:07:41.740
and certainly around the world.

00:07:41.740 --> 00:07:43.480
If we don't get to
a subject matter

00:07:43.480 --> 00:07:45.820
that you thought we should
have talked about race,

00:07:45.820 --> 00:07:48.280
we are trying to get to
those and other conversations

00:07:48.280 --> 00:07:49.180
as well.

00:07:49.180 --> 00:07:52.930
We have one of the great
experts on this subject matter

00:07:52.930 --> 00:07:55.110
here with us today in Atlanta.

00:07:55.110 --> 00:07:59.110
And we are going to have
a phenomenal conversation.

00:07:59.110 --> 00:08:03.840
I just came from Washington
this past weekend

00:08:03.840 --> 00:08:06.010
for the March for Science.

00:08:06.010 --> 00:08:11.650
And I was the chair of the
board of the organization that

00:08:11.650 --> 00:08:13.100
produced the Women's March.

00:08:13.100 --> 00:08:16.150
So the Gathering for Justice
was founded by Harry Belafonte

00:08:16.150 --> 00:08:17.590
10 years ago.

00:08:17.590 --> 00:08:19.870
And I chaired the board
of that organization.

00:08:19.870 --> 00:08:22.360
And that organization, we
brought the Women's March

00:08:22.360 --> 00:08:23.644
into the organization.

00:08:23.644 --> 00:08:24.560
And then we organized.

00:08:24.560 --> 00:08:29.280
So Tamika Mallory, Carmen
Perez, Linda Sarsour, Bob Bland,

00:08:29.280 --> 00:08:30.670
the four co-chairs of the March.

00:08:30.670 --> 00:08:32.559
Three of them are part
of our organization.

00:08:32.559 --> 00:08:35.289
And all three of them have
all spoken here at Google

00:08:35.289 --> 00:08:36.799
as part of this series.

00:08:36.799 --> 00:08:41.670
So I have now offered
our services for free

00:08:41.670 --> 00:08:44.169
to the other marches that are
happening around this country.

00:08:44.169 --> 00:08:47.330
And the Science March
had requested some help.

00:08:47.330 --> 00:08:51.160
So I was in Washington
for the March for Science.

00:08:51.160 --> 00:08:55.120
It was amazing to be
around so many scientists

00:08:55.120 --> 00:08:57.060
and this conversation.

00:08:57.060 --> 00:09:02.270
To really look at the science
of this, how the brain operates,

00:09:02.270 --> 00:09:05.920
how when we see someone or meet
someone or hear someone's voice

00:09:05.920 --> 00:09:08.940
or see someone's name
what happens to our brain.

00:09:08.940 --> 00:09:10.760
And then how do
we act upon that.

00:09:10.760 --> 00:09:12.670
So Kimberly, welcome.

00:09:12.670 --> 00:09:14.235
KIMBERLY PAPILLON: Thank you.

00:09:14.235 --> 00:09:16.860
MICHAEL SKOLNIK: I know you took
a few planes to get here, too.

00:09:16.860 --> 00:09:18.010
KIMBERLY PAPILLON: Yes, yes.

00:09:18.010 --> 00:09:19.480
MICHAEL SKOLNIK: So
thank you for being here.

00:09:19.480 --> 00:09:20.688
KIMBERLY PAPILLON: Thank you.

00:09:20.688 --> 00:09:23.180
MICHAEL SKOLNIK: On behalf of
Google that I don't work for,

00:09:23.180 --> 00:09:26.180
I'm thanking you on behalf of
all these beautiful people.

00:09:26.180 --> 00:09:27.850
We don't get any
stock in the company.

00:09:27.850 --> 00:09:30.490
But we do get a free lunch.

00:09:30.490 --> 00:09:31.950
The lunch is always
good at Google.

00:09:31.950 --> 00:09:34.630
So thank you for
having both of us.

00:09:34.630 --> 00:09:37.870
Kimberly, if you
could just ground us

00:09:37.870 --> 00:09:40.420
for a moment in
this conversation.

00:09:40.420 --> 00:09:44.730
And we hear the term
microaggression a lot,

00:09:44.730 --> 00:09:46.275
or we may not hear it at all.

00:09:46.275 --> 00:09:47.650
Some of us might
know what it is.

00:09:47.650 --> 00:09:50.170
Some of us may not
know what it is.

00:09:50.170 --> 00:09:51.430
Can you just ground us in.

00:09:51.430 --> 00:09:55.150
What is a microaggression?

00:09:55.150 --> 00:09:56.200
How does it play out?

00:09:56.200 --> 00:10:00.600
And then how do we recognize it?

00:10:00.600 --> 00:10:01.840
KIMBERLY PAPILLON: Thank you.

00:10:01.840 --> 00:10:06.310
Microaggressions, the term,
racial microaggressions,

00:10:06.310 --> 00:10:08.582
was actually coined by
a man named Derald Wing

00:10:08.582 --> 00:10:11.670
Sue from Columbia University.

00:10:11.670 --> 00:10:13.090
But there's a way
to understand it

00:10:13.090 --> 00:10:15.548
that I think is better than
just reading the definition out

00:10:15.548 --> 00:10:16.114
of the book.

00:10:16.114 --> 00:10:18.280
There's a really great
example for microaggressions.

00:10:18.280 --> 00:10:19.988
Let's say you're
standing next to someone

00:10:19.988 --> 00:10:21.430
who is much younger than you.

00:10:21.430 --> 00:10:24.280
Let's say you're 20 years
older than they are.

00:10:24.280 --> 00:10:25.872
And they're talking.

00:10:25.872 --> 00:10:26.830
You're talking to them.

00:10:26.830 --> 00:10:28.440
And they say no, I'm
trying to remember.

00:10:28.440 --> 00:10:29.830
And they say, it's just on
the tip of their tongue.

00:10:29.830 --> 00:10:31.480
They can't remember what
they were about to say.

00:10:31.480 --> 00:10:33.280
It's just on the
tip of their tongue.

00:10:33.280 --> 00:10:35.697
And a few minutes later, you
forget what you were saying.

00:10:35.697 --> 00:10:37.280
And you say, I can't
remember what is.

00:10:37.280 --> 00:10:40.120
And they say, are you
having a senior moment?

00:10:40.120 --> 00:10:44.320
Now if you respond,
you're the problem.

00:10:44.320 --> 00:10:46.000
That's a microaggressions,
where there's

00:10:46.000 --> 00:10:48.730
a little bit of an insult,
a little bit of a statement

00:10:48.730 --> 00:10:50.195
that you find problematic.

00:10:50.195 --> 00:10:51.820
But, if you respond
you're the problem.

00:10:51.820 --> 00:10:54.080
You think of the response
in the car on the way home.

00:10:54.080 --> 00:10:55.913
You look in the rear
view mirror at yourself

00:10:55.913 --> 00:10:57.430
and you say, if I had just said.

00:10:57.430 --> 00:10:59.200
That's usually an
indication that there

00:10:59.200 --> 00:11:01.090
was a microaggression afoot.

00:11:01.090 --> 00:11:06.340
It's something that pokes at
you and, over a period of time,

00:11:06.340 --> 00:11:08.386
can have a significant effect.

00:11:08.386 --> 00:11:12.970
MICHAEL SKOLNIK: So this place
is very unique as you all know.

00:11:12.970 --> 00:11:15.130
You love VCs.

00:11:15.130 --> 00:11:18.160
You love Google Hangout.

00:11:18.160 --> 00:11:21.055
I've been on many of them.

00:11:21.055 --> 00:11:26.200
Well, I'd love to walk through
is in a place like Google

00:11:26.200 --> 00:11:31.990
how we meet somebody
from the very beginning--

00:11:31.990 --> 00:11:36.040
a new employee, a new colleague,
a new person in your team.

00:11:36.040 --> 00:11:38.980
You are spread out so
far around the world,

00:11:38.980 --> 00:11:40.870
and you work so
closely with each other

00:11:40.870 --> 00:11:44.290
on other campuses
across the world

00:11:44.290 --> 00:11:47.621
that oftentimes you've never
met each other in person.

00:11:47.621 --> 00:11:49.870
Oftentimes you're working
with a colleague in Mountain

00:11:49.870 --> 00:11:52.180
View or a colleague overseas.

00:11:52.180 --> 00:11:55.640
And you only meet that person
maybe once or twice a year.

00:11:55.640 --> 00:12:00.486
But Kimberly, walk us through
when you hear someone's name.

00:12:00.486 --> 00:12:02.980
KIMBERLY PAPILLON:
So for instance,

00:12:02.980 --> 00:12:06.137
the first way you may meet
someone is through a name,

00:12:06.137 --> 00:12:08.470
the name on the top of an
email; an announcement saying,

00:12:08.470 --> 00:12:12.010
new employee is coming
to work; the participants

00:12:12.010 --> 00:12:14.260
in a conference call; or a VC.

00:12:14.260 --> 00:12:16.430
How does that name affect
the way that we think?

00:12:16.430 --> 00:12:17.680
Well, before we go
there all the way,

00:12:17.680 --> 00:12:19.388
I just want to mention
that we're talking

00:12:19.388 --> 00:12:20.590
about unconscious processes.

00:12:20.590 --> 00:12:22.006
We're talking about
things that go

00:12:22.006 --> 00:12:24.160
on inside of the brain
that do not necessarily

00:12:24.160 --> 00:12:26.140
comport with our
conscious value system.

00:12:26.140 --> 00:12:28.240
They do not match the way
that we see ourselves.

00:12:28.240 --> 00:12:30.031
They do not align
themselves with our goals

00:12:30.031 --> 00:12:31.760
that they are unconscious.

00:12:31.760 --> 00:12:34.060
Scientists theorize
that in a single second,

00:12:34.060 --> 00:12:36.280
the conscious components
of the human brain

00:12:36.280 --> 00:12:38.440
can process 40 frames
of information.

00:12:38.440 --> 00:12:40.630
In a single second,
the conscious component

00:12:40.630 --> 00:12:44.010
of the human brain can process
40 frames of information.

00:12:44.010 --> 00:12:46.330
In that same second, the
unconscious components

00:12:46.330 --> 00:12:49.360
of the human brain can
process 1.2 million frames

00:12:49.360 --> 00:12:50.770
of information.

00:12:50.770 --> 00:12:53.110
So who is really
running the show?

00:12:53.110 --> 00:12:56.410
And some scientists theorize
that part of that 1.2 million

00:12:56.410 --> 00:12:59.240
in the background drives
our decision making.

00:12:59.240 --> 00:13:01.060
And part of that 40
in the foreground

00:13:01.060 --> 00:13:03.520
is what we use to rationalize
our decisions or make us

00:13:03.520 --> 00:13:06.110
feel better about our decisions.

00:13:06.110 --> 00:13:08.230
So we want to try to
figure out what's going on,

00:13:08.230 --> 00:13:11.290
comb through that data
in that 1.2 million.

00:13:11.290 --> 00:13:14.420
And what's in a name is a
really good place to start.

00:13:14.420 --> 00:13:18.970
So let's say I gave all
of us laptop computers.

00:13:18.970 --> 00:13:20.770
And I told you all,
you're going to have

00:13:20.770 --> 00:13:24.560
an email conversation with the
person in the room next door.

00:13:24.560 --> 00:13:26.560
They're going to share
their math and verbal SAT

00:13:26.560 --> 00:13:27.250
scores with you.

00:13:27.250 --> 00:13:30.550
What might affect your
ability to recall those scores

00:13:30.550 --> 00:13:31.854
once the conversation ends?

00:13:31.854 --> 00:13:34.270
Well, that's exactly what a
group of folks at Harvard did.

00:13:34.270 --> 00:13:36.370
They took a group of
undergrads, and they put them

00:13:36.370 --> 00:13:37.330
in front of the computer.

00:13:37.330 --> 00:13:38.788
And they said,
you're going to have

00:13:38.788 --> 00:13:41.206
an email conversation with a
person in the room next door.

00:13:41.206 --> 00:13:43.600
And the person in
the room next door

00:13:43.600 --> 00:13:46.420
is actually an underpaid
graduate student, let's assume.

00:13:46.420 --> 00:13:48.010
I know that's redundant.

00:13:48.010 --> 00:13:50.380
But they're a graduate student.

00:13:50.380 --> 00:13:52.450
Let's assume they're
given a script.

00:13:52.450 --> 00:13:54.555
So every single
conversation is the same.

00:13:54.555 --> 00:13:55.930
You and I, as the
undergrads, are

00:13:55.930 --> 00:13:57.400
going to type in the questions.

00:13:57.400 --> 00:13:58.900
We're going to send them
to the person next door.

00:13:58.900 --> 00:14:01.120
The person next door is going
to have the same answers

00:14:01.120 --> 00:14:01.911
to those questions.

00:14:01.911 --> 00:14:04.100
So each and every
conversation is the same.

00:14:04.100 --> 00:14:05.560
We need a variable.

00:14:05.560 --> 00:14:07.252
How about the email addresses?

00:14:07.252 --> 00:14:09.460
Some of the people are going
to get the email address

00:14:09.460 --> 00:14:10.900
to reach the graduate student.

00:14:10.900 --> 00:14:14.680
They're going to get the
email address, C-H-E-N, Chen,

00:14:14.680 --> 00:14:17.590
C-H-E-N, @wjh.harvard.edu.

00:14:17.590 --> 00:14:20.200
So basically chen@harvard.

00:14:20.200 --> 00:14:24.160
The other people are going to
get Amy, A-M-Y, @harvard.edu.

00:14:24.160 --> 00:14:26.500
Now they don't know
this is the variable.

00:14:26.500 --> 00:14:28.810
They think everybody has
Chen, or everybody has Amy.

00:14:28.810 --> 00:14:30.280
Conversation ensues.

00:14:30.280 --> 00:14:32.260
Math and verbal SAT
scores are shared.

00:14:32.260 --> 00:14:33.961
Conversation ends.

00:14:33.961 --> 00:14:35.710
Proctor walks back
into the room and says,

00:14:35.710 --> 00:14:38.110
do you recall the math
and the verbal SAT scores

00:14:38.110 --> 00:14:39.640
that were shared with you?

00:14:39.640 --> 00:14:41.420
So what do we think?

00:14:41.420 --> 00:14:44.060
So let's say the person at
the email address, Chen,

00:14:44.060 --> 00:14:48.190
do we think it's going to be
higher, lower, or the same?

00:14:48.190 --> 00:14:49.020
What do you think?

00:14:49.020 --> 00:14:49.780
AUDIENCE: Higher.

00:14:49.780 --> 00:14:50.010
KIMBERLY PAPILLON: Higher?

00:14:50.010 --> 00:14:50.635
What about Amy?

00:14:50.635 --> 00:14:52.890
Higher, lower, or the same?

00:14:52.890 --> 00:14:53.680
AUDIENCE: Lower.

00:14:53.680 --> 00:14:54.100
KIMBERLY PAPILLON: Lower?

00:14:54.100 --> 00:14:55.090
OK, so that's right.

00:14:55.090 --> 00:14:56.920
So what people who
used the email address,

00:14:56.920 --> 00:14:59.760
Chen, remembered the
math score as higher.

00:14:59.760 --> 00:15:02.387
One to seven points
higher is our range.

00:15:02.387 --> 00:15:03.970
People who had the
email address, Amy,

00:15:03.970 --> 00:15:04.810
remembered it lower.

00:15:04.810 --> 00:15:07.480
One to eight points lower
is our range for Amy.

00:15:07.480 --> 00:15:09.770
What's going to
happen with verbal?

00:15:09.770 --> 00:15:11.220
It flips.

00:15:11.220 --> 00:15:14.270
People who used the email
address, Chen, remember

00:15:14.270 --> 00:15:17.320
that individual
scoring lower in verbal

00:15:17.320 --> 00:15:18.380
than what they were told.

00:15:18.380 --> 00:15:19.838
People with the
email address, Amy,

00:15:19.838 --> 00:15:21.620
remembered that person
scoring higher than

00:15:21.620 --> 00:15:23.120
what they were told.

00:15:23.120 --> 00:15:26.000
Now remember, the people who
had the email address, Amy, they

00:15:26.000 --> 00:15:27.530
bring the score down for math.

00:15:27.530 --> 00:15:30.500
Those are the same people that
upgrade that person in verbal.

00:15:30.500 --> 00:15:32.200
And vice versa for Chen.

00:15:32.200 --> 00:15:33.950
Oh, there's something
I forgot to tell you

00:15:33.950 --> 00:15:35.780
about this particular study.

00:15:35.780 --> 00:15:37.616
When each and every
one of the undergrads

00:15:37.616 --> 00:15:38.990
walked into the
room, before they

00:15:38.990 --> 00:15:40.520
typed a single key
on the computer,

00:15:40.520 --> 00:15:42.260
they were all told
the exact same thing.

00:15:42.260 --> 00:15:44.960
They were all told,
you are about to have

00:15:44.960 --> 00:15:48.110
an email conversation with
an Asian-American woman

00:15:48.110 --> 00:15:49.610
by the name of Amy Chen.

00:15:52.300 --> 00:15:54.640
What do we do with that?

00:15:54.640 --> 00:15:56.200
There's this notion
of what we call

00:15:56.200 --> 00:15:57.970
perfect information
in this science

00:15:57.970 --> 00:15:59.809
called game theory,
perfect information.

00:15:59.809 --> 00:16:01.350
What if you have
perfect information?

00:16:01.350 --> 00:16:03.225
What if you know everything
you need to know?

00:16:03.225 --> 00:16:05.266
What if you have the resume
right in front of you

00:16:05.266 --> 00:16:07.540
with the person's experience
and their schooling?

00:16:07.540 --> 00:16:10.374
What if you have the
employee evaluations

00:16:10.374 --> 00:16:11.290
right in front of you?

00:16:11.290 --> 00:16:13.000
What if you have all
the emails of reports

00:16:13.000 --> 00:16:13.780
that person has read?

00:16:13.780 --> 00:16:15.280
What if you've
watched them at work?

00:16:15.280 --> 00:16:17.500
Is it possible you
can misremember some

00:16:17.500 --> 00:16:21.070
of the information-- not way
off, just a little askew--

00:16:21.070 --> 00:16:24.310
to change the way that you
think about that individual.

00:16:24.310 --> 00:16:26.577
So this is the notion
of having to template.

00:16:26.577 --> 00:16:28.660
I have a template for how
somebody should perform,

00:16:28.660 --> 00:16:32.080
what their character might be,
and what their skill set is.

00:16:32.080 --> 00:16:34.030
And then they demonstrate
their skill set,

00:16:34.030 --> 00:16:35.960
and they reveal their character.

00:16:35.960 --> 00:16:39.970
But I might morph that
information to fit my template.

00:16:39.970 --> 00:16:41.680
And that's one of
the concerns we have

00:16:41.680 --> 00:16:44.179
because that's just
what's in a name.

00:16:44.179 --> 00:16:45.970
MICHAEL SKOLNIK: Where
is that coming from?

00:16:45.970 --> 00:16:47.761
KIMBERLY PAPILLON: From
a number of places.

00:16:47.761 --> 00:16:49.360
So the hippocampus
is the main part

00:16:49.360 --> 00:16:53.044
of the brain that gathers and
stores data and information.

00:16:53.044 --> 00:16:54.460
If we're talking
about a computer,

00:16:54.460 --> 00:16:56.080
we would say data
collection and data

00:16:56.080 --> 00:16:58.810
storage at the beginning
of the process.

00:16:58.810 --> 00:17:00.880
So think of that data
collection and data

00:17:00.880 --> 00:17:04.220
storage occurring in the
brain in the hippocampus.

00:17:04.220 --> 00:17:07.390
And the possibility is that
the implicit association,

00:17:07.390 --> 00:17:10.076
these unconscious thoughts,
affect our ability

00:17:10.076 --> 00:17:12.700
to bring that data in and store
it correctly because it doesn't

00:17:12.700 --> 00:17:14.079
fit our template.

00:17:14.079 --> 00:17:16.810
So someone could come
in with great scores

00:17:16.810 --> 00:17:18.339
and perform very well.

00:17:18.339 --> 00:17:20.710
And we might recall
their mistakes

00:17:20.710 --> 00:17:22.990
more clearly if they
fit our template

00:17:22.990 --> 00:17:25.510
and fade out on some
of these successes.

00:17:25.510 --> 00:17:27.609
Just downgrade
them a little bit.

00:17:27.609 --> 00:17:31.540
I was giving a lecture to
a group of judges in DC.

00:17:31.540 --> 00:17:33.130
One of them said,
you know, you don't

00:17:33.130 --> 00:17:36.160
have to misremember
every single fact.

00:17:36.160 --> 00:17:38.350
We couldn't have gotten at
this point in our careers

00:17:38.350 --> 00:17:40.150
if we misremembered
every single fact.

00:17:40.150 --> 00:17:43.610
You just have to misremember
every 10th fact or every 15th

00:17:43.610 --> 00:17:46.360
fact-- and not way off,
just a little askew--

00:17:46.360 --> 00:17:48.730
to change the trajectory of
the complex decision making

00:17:48.730 --> 00:17:50.260
process.

00:17:50.260 --> 00:17:53.300
In Google, people meet
each other all the time.

00:17:53.300 --> 00:17:55.330
And so you have all of
this data coming in.

00:17:55.330 --> 00:17:57.100
You don't have to skew
each and every one

00:17:57.100 --> 00:17:58.270
of those pieces of data--

00:17:58.270 --> 00:18:00.730
just every 10th or 15th,
and just a little bit off--

00:18:00.730 --> 00:18:02.410
to change the overall
impression you

00:18:02.410 --> 00:18:04.044
might have of that individual.

00:18:04.044 --> 00:18:05.710
MICHAEL SKOLNIK: So
then that individual

00:18:05.710 --> 00:18:07.434
sends me, or gets
on my calendar,

00:18:07.434 --> 00:18:09.600
because here at Google,
they can go in your calendar

00:18:09.600 --> 00:18:12.775
to sign you up for VC.

00:18:12.775 --> 00:18:15.885
So they sign you up for VC,
and then you see their face.

00:18:15.885 --> 00:18:17.260
Talk to me about
seeing someone's

00:18:17.260 --> 00:18:20.271
face for the first time and
how that affects our decision

00:18:20.271 --> 00:18:20.770
making.

00:18:20.770 --> 00:18:22.270
KIMBERLY PAPILLON: So my
favorite part of the brain

00:18:22.270 --> 00:18:23.980
is the part of the brain
called the amygdala.

00:18:23.980 --> 00:18:25.960
Yes, I'm a big nerd to have
a favorite part of the brain.

00:18:25.960 --> 00:18:28.300
But I want everyone to have a
favorite part of their brain.

00:18:28.300 --> 00:18:30.410
So it's a part of the
brain called the amygdala.

00:18:30.410 --> 00:18:33.580
And the amygdala is implicated
in fear, threat, anxiety,

00:18:33.580 --> 00:18:34.510
and distress--

00:18:34.510 --> 00:18:36.670
fear, threat,
anxiety, and distress.

00:18:36.670 --> 00:18:39.790
They isolated the amygdala by
sliding people into the machine

00:18:39.790 --> 00:18:42.340
and flashing pictures
of spiders and snakes.

00:18:42.340 --> 00:18:43.840
And the amygdala lit up.

00:18:43.840 --> 00:18:46.090
So they can't keep doing
these studies on the amygdala

00:18:46.090 --> 00:18:48.190
because they'll never get tenure
if they just keep doing spiders

00:18:48.190 --> 00:18:48.820
and snakes, right?

00:18:48.820 --> 00:18:50.230
They've got to
kick it up a notch.

00:18:50.230 --> 00:18:51.771
So they decide
they're going to flash

00:18:51.771 --> 00:18:52.900
pictures of people's faces.

00:18:52.900 --> 00:18:55.360
They're going to flash a picture
of a man of African descent

00:18:55.360 --> 00:18:56.610
and a man of European descent.

00:18:56.610 --> 00:18:58.540
And I'll use the short
for black and white

00:18:58.540 --> 00:19:00.410
and African-American
and Caucasian,

00:19:00.410 --> 00:19:02.050
but we don't know
their nationality.

00:19:02.050 --> 00:19:04.383
We just know of African descent
and of European descent.

00:19:04.383 --> 00:19:05.957
And they're flashing
the pictures.

00:19:05.957 --> 00:19:07.540
They're going to
standardize the faces

00:19:07.540 --> 00:19:10.210
for parts of the face that
make no difference to how

00:19:10.210 --> 00:19:12.610
we tell who's of African and
who's of European descent.

00:19:12.610 --> 00:19:14.230
Cheekbones, we don't use that.

00:19:14.230 --> 00:19:16.570
Forehead size, chin,
that's not really

00:19:16.570 --> 00:19:19.551
dispositive in determining that.

00:19:19.551 --> 00:19:20.800
And they flashed the pictures.

00:19:20.800 --> 00:19:22.841
They want us figure out
who are they can get more

00:19:22.841 --> 00:19:24.730
of an amygdala activation for.

00:19:24.730 --> 00:19:27.610
So what they find is
something interesting.

00:19:27.610 --> 00:19:29.590
They get more of an
amygdala activation

00:19:29.590 --> 00:19:31.600
for the African-American
man's face

00:19:31.600 --> 00:19:33.307
than for the
Caucasian man's face.

00:19:33.307 --> 00:19:35.890
Now there's probably a question
burning in the room right now.

00:19:35.890 --> 00:19:37.510
Who was in the machine?

00:19:37.510 --> 00:19:38.710
Who was in the machine?

00:19:38.710 --> 00:19:40.847
So they put only
Caucasian people

00:19:40.847 --> 00:19:43.180
in the machine, who had been
living in the United States

00:19:43.180 --> 00:19:44.540
for a full generation.

00:19:44.540 --> 00:19:45.998
So that's the
information that they

00:19:45.998 --> 00:19:47.320
were able to gather from that.

00:19:47.320 --> 00:19:49.210
But what surprised
them actually was

00:19:49.210 --> 00:19:51.940
that the level of
amygdala activation

00:19:51.940 --> 00:19:54.460
matched directly with
people's scores on something

00:19:54.460 --> 00:19:56.916
called the
implicit-association test.

00:19:56.916 --> 00:19:58.540
So we can't all get
our brains scanned,

00:19:58.540 --> 00:20:00.600
but we can all take the
implicit-association test

00:20:00.600 --> 00:20:01.100
online.

00:20:01.100 --> 00:20:03.730
And as people had more
trouble on the test matching

00:20:03.730 --> 00:20:06.670
the idea of black
and good with faces

00:20:06.670 --> 00:20:09.310
of people who were of African
descent and words like love

00:20:09.310 --> 00:20:11.440
and pleasant and
things like that,

00:20:11.440 --> 00:20:13.690
they were having more
trouble making that match

00:20:13.690 --> 00:20:14.920
unconsciously.

00:20:14.920 --> 00:20:16.480
They would have
more of an amygdala,

00:20:16.480 --> 00:20:18.580
or spiders-like
activation, when viewing

00:20:18.580 --> 00:20:20.090
the African-American man's face.

00:20:20.090 --> 00:20:22.300
They kicked that up a
notch, too, by the way.

00:20:22.300 --> 00:20:24.700
They took people
with different levels

00:20:24.700 --> 00:20:26.980
of what we'll call
Afrocentric facial features,

00:20:26.980 --> 00:20:32.347
including different, what
we'll call, skin shades.

00:20:32.347 --> 00:20:33.430
Let me ask you a question.

00:20:33.430 --> 00:20:35.230
On a scale of one to
nine, if I tell you

00:20:35.230 --> 00:20:38.170
that Shaquille O'Neal
and Wesley Snipes

00:20:38.170 --> 00:20:41.050
are a nine on the Afrocentric
facial feature range

00:20:41.050 --> 00:20:43.060
and I tell you that
President Obama

00:20:43.060 --> 00:20:45.490
is like a three on the
Afrocentric facial feature.

00:20:45.490 --> 00:20:50.857
Where would Denzel Washington
fit on that scale, one to nine?

00:20:50.857 --> 00:20:51.440
Because he's--

00:20:51.440 --> 00:20:52.517
MICHAEL SKOLNIK: Eight.

00:20:52.517 --> 00:20:53.850
KIMBERLY PAPILLON: You think so?

00:20:53.850 --> 00:20:56.479
AUDIENCE: Four or five.

00:20:56.479 --> 00:20:57.520
KIMBERLY PAPILLON: Wrong.

00:20:57.520 --> 00:20:58.274
AUDIENCE: Six.

00:20:58.274 --> 00:20:59.190
KIMBERLY PAPILLON: 10.

00:20:59.190 --> 00:21:00.814
AUDIENCE: Why 10?

00:21:00.814 --> 00:21:02.703
KIMBERLY PAPILLON:
Denzel's always a 10.

00:21:02.703 --> 00:21:05.827
[LAUGHING]

00:21:05.827 --> 00:21:07.090
Are we correct about--

00:21:07.090 --> 00:21:09.805
we can't move on before
we get unanimity on--

00:21:09.805 --> 00:21:11.680
MICHAEL SKOLNIK: I'm
telling you, she's good.

00:21:11.680 --> 00:21:12.380
KIMBERLY PAPILLON:
I'm just making sure.

00:21:12.380 --> 00:21:13.226
MICHAEL SKOLNIK: I told you.

00:21:13.226 --> 00:21:14.285
KIMBERLY PAPILLON:
On this scale--

00:21:14.285 --> 00:21:15.826
MICHAEL SKOLNIK:
Oh, man, she got me.

00:21:15.826 --> 00:21:18.855
KIMBERLY PAPILLON: --scale,
he'll be maybe a 5.5 or a 6.

00:21:18.855 --> 00:21:20.230
Now let's take
all the people who

00:21:20.230 --> 00:21:23.170
identify as African-American
off of that scale.

00:21:23.170 --> 00:21:25.810
Let's put people who identify
as of European descent

00:21:25.810 --> 00:21:27.370
or Caucasian on that scale.

00:21:27.370 --> 00:21:30.370
We can have gradations
there, too, can't we?

00:21:30.370 --> 00:21:32.710
As the skin becomes darker,
as the nose becomes broader,

00:21:32.710 --> 00:21:34.270
starting from the top
as the lips become

00:21:34.270 --> 00:21:36.061
more full, and the hair
it becomes curlier,

00:21:36.061 --> 00:21:38.720
we can have more
one to nine scale

00:21:38.720 --> 00:21:42.100
if we put people of European
descent only on that scale.

00:21:42.100 --> 00:21:43.310
There's variations there.

00:21:43.310 --> 00:21:44.170
Let's take them off.

00:21:44.170 --> 00:21:47.380
Let's put people who are
Latino on that scale.

00:21:47.380 --> 00:21:50.080
We're back to almost where we
would be with African-American

00:21:50.080 --> 00:21:53.080
because we have to go
country by country by country

00:21:53.080 --> 00:21:54.890
to be very specific.

00:21:54.890 --> 00:21:57.010
We could put people who
are Asian on that scale,

00:21:57.010 --> 00:21:58.090
couldn't we?

00:21:58.090 --> 00:22:00.520
Asian-American or
Asian, correct?

00:22:00.520 --> 00:22:03.880
And then we'd have a lot of
leeway in terms of skin color

00:22:03.880 --> 00:22:05.740
at least in that conversation--

00:22:05.740 --> 00:22:07.790
Pacific Islander,
Native American as well.

00:22:07.790 --> 00:22:09.250
So what they found
is that as they

00:22:09.250 --> 00:22:10.587
flashed-- in the United States.

00:22:10.587 --> 00:22:12.670
This is US phenomena-- a
couple of other countries

00:22:12.670 --> 00:22:13.840
still with this as well.

00:22:13.840 --> 00:22:16.940
As they flashed pictures
of people with darker skin,

00:22:16.940 --> 00:22:19.362
they were getting higher
levels of amygdala activation.

00:22:19.362 --> 00:22:21.070
And they were flashing
pictures of people

00:22:21.070 --> 00:22:22.660
in different ethnic groups.

00:22:22.660 --> 00:22:24.670
So they were getting
this reaction.

00:22:24.670 --> 00:22:28.510
So we can see that phenomena
of the spider-snake reaction

00:22:28.510 --> 00:22:30.640
happening within
other ethnic groups

00:22:30.640 --> 00:22:33.220
as well, particularly when
we look at, once again,

00:22:33.220 --> 00:22:34.810
Latino and Asian.

00:22:34.810 --> 00:22:37.090
We can see that occurring.

00:22:37.090 --> 00:22:41.110
So this can manifest itself
in a number of different ways.

00:22:41.110 --> 00:22:41.980
You see their face.

00:22:44.560 --> 00:22:46.920
MICHAEL SKOLNIK: One of
the common microaggressions

00:22:46.920 --> 00:22:50.660
that we hear about
and talk about is

00:22:50.660 --> 00:22:52.840
seeing an African-American
woman and saying,

00:22:52.840 --> 00:22:55.680
can I touch your hair?

00:22:55.680 --> 00:23:01.050
So seeing someone's, as a white
person, can I touch your hair.

00:23:01.050 --> 00:23:05.220
And there's books
written about that,

00:23:05.220 --> 00:23:08.380
that one question,
can I touch your hair.

00:23:08.380 --> 00:23:10.120
And there was that
famous photograph

00:23:10.120 --> 00:23:12.970
of President Obama
and the little boy

00:23:12.970 --> 00:23:14.740
when he first came into office.

00:23:14.740 --> 00:23:16.634
And the little boy
asked President Obama--

00:23:16.634 --> 00:23:18.300
a young black boy
asked President Obama,

00:23:18.300 --> 00:23:19.237
can I touch your hair?

00:23:19.237 --> 00:23:20.945
Because he couldn't
believe the president

00:23:20.945 --> 00:23:23.610
had the same hair as him.

00:23:23.610 --> 00:23:29.640
So just on appearance, how
do microaggressions play out?

00:23:29.640 --> 00:23:32.120
KIMBERLY PAPILLON: That's
an excellent question.

00:23:32.120 --> 00:23:36.640
Imagine walking in first for the
first time in meeting someone.

00:23:36.640 --> 00:23:39.144
You watch the way
that they react.

00:23:39.144 --> 00:23:40.810
Do their eyes become
big because they're

00:23:40.810 --> 00:23:45.760
surprised because your
name didn't match the face?

00:23:45.760 --> 00:23:49.621
Perhaps they were able to see
something that you had written.

00:23:49.621 --> 00:23:51.370
Perhaps your title or
what you had written

00:23:51.370 --> 00:23:53.660
didn't match the face again.

00:23:53.660 --> 00:23:56.980
And that surprise may not
just be negative or positive,

00:23:56.980 --> 00:23:59.400
but it may be an indication
to the person who's walking in

00:23:59.400 --> 00:24:01.441
that that person has a
template, the person who's

00:24:01.441 --> 00:24:03.700
viewing them has a template.

00:24:03.700 --> 00:24:05.560
But it can also happen
in a meeting setting.

00:24:05.560 --> 00:24:07.270
Let's say I decide
that I'm going

00:24:07.270 --> 00:24:10.917
to be particularly verbose.

00:24:10.917 --> 00:24:12.500
Or maybe I'm just
going to participate

00:24:12.500 --> 00:24:13.480
in the meeting like anyone else.

00:24:13.480 --> 00:24:14.800
Let's say I'm just going
to raise my hand when

00:24:14.800 --> 00:24:16.591
the time comes and to
participate in the VC

00:24:16.591 --> 00:24:17.530
like anyone else.

00:24:17.530 --> 00:24:19.930
If you have a template of
me as being more aggressive,

00:24:19.930 --> 00:24:22.600
then you may see my
basic assertiveness

00:24:22.600 --> 00:24:25.510
and my contribution
as being overkill.

00:24:25.510 --> 00:24:27.820
I'm oversharing.

00:24:27.820 --> 00:24:29.961
Let's say I give a great idea.

00:24:29.961 --> 00:24:31.960
I gave a great idea 10
minutes into the meeting.

00:24:31.960 --> 00:24:33.501
And people say that
that's wonderful.

00:24:33.501 --> 00:24:34.241
That's great.

00:24:34.241 --> 00:24:36.490
But maybe it doesn't fit the
template you have for me.

00:24:36.490 --> 00:24:39.710
20 minutes later, someone
else gives a similar idea.

00:24:39.710 --> 00:24:42.520
And they say, Michael,
that was fantastic.

00:24:42.520 --> 00:24:46.120
You need to be the head of
the subcommittee on that idea

00:24:46.120 --> 00:24:50.020
because it seems like you could
run with that because that fits

00:24:50.020 --> 00:24:52.720
the template that I have
once again for the face

00:24:52.720 --> 00:24:54.700
or for the name.

00:24:54.700 --> 00:24:56.450
The notion of the
touching of the hair--

00:24:56.450 --> 00:25:00.100
there's a cultural competency
conversation in there, too.

00:25:00.100 --> 00:25:02.680
It may not be that I'm saying
there's something negative when

00:25:02.680 --> 00:25:04.060
I say I want to touch here.

00:25:04.060 --> 00:25:06.760
But the notion of you
are so different, you

00:25:06.760 --> 00:25:12.090
are so novel to me can be
disquieting to the person who's

00:25:12.090 --> 00:25:14.380
saying, I want to
be part of the team.

00:25:14.380 --> 00:25:16.120
I love my culture.

00:25:16.120 --> 00:25:18.040
I value who I am.

00:25:18.040 --> 00:25:20.680
But I also want you to see
me as part of this team

00:25:20.680 --> 00:25:23.620
and not someone so novel
that you have to pay me.

00:25:23.620 --> 00:25:25.220
If that makes sense?

00:25:25.220 --> 00:25:27.020
MICHAEL SKOLNIK: You
talked earlier today

00:25:27.020 --> 00:25:28.770
when I was speaking
with you with the idea

00:25:28.770 --> 00:25:31.570
of dehumanizing somebody.

00:25:31.570 --> 00:25:34.860
How does that land on somebody?

00:25:34.860 --> 00:25:37.310
KIMBERLY PAPILLON:
That's really important.

00:25:37.310 --> 00:25:40.030
So we do what's in a name.

00:25:40.030 --> 00:25:41.524
We see what's in
a face on the VC.

00:25:41.524 --> 00:25:43.190
That's the first thing
you're going to--

00:25:43.190 --> 00:25:46.330
see the face-- and
then what's in a voice.

00:25:46.330 --> 00:25:48.310
So we have a different
reaction to a pleasant

00:25:48.310 --> 00:25:51.400
versus an unpleasant voice.

00:25:51.400 --> 00:25:53.530
I was teaching a group
of judges in New York.

00:25:53.530 --> 00:25:57.130
And they agreed that, yes,
Fran Drescher of The Nanny

00:25:57.130 --> 00:26:01.552
would constitute an unpleasant
voice even for them.

00:26:01.552 --> 00:26:03.010
Even though that
voice is familiar,

00:26:03.010 --> 00:26:04.365
it can be seen as unpleasant.

00:26:04.365 --> 00:26:06.490
And we can actually have
a different brain reaction

00:26:06.490 --> 00:26:08.620
to that unpleasant voice.

00:26:08.620 --> 00:26:11.325
But with voices, we also
have an additional reaction.

00:26:11.325 --> 00:26:13.450
So what's in a name is the
hippocampus, the memory,

00:26:13.450 --> 00:26:14.530
how do we collect data.

00:26:14.530 --> 00:26:16.470
What's in a face, the amygdala.

00:26:16.470 --> 00:26:20.110
What's in a voice, we're looking
at the caudate and the putamen.

00:26:20.110 --> 00:26:23.200
We're looking at what we call
dehumanization but should

00:26:23.200 --> 00:26:25.870
be termed as encoding
is fully human.

00:26:25.870 --> 00:26:28.090
For me to see you
as fully human,

00:26:28.090 --> 00:26:33.770
I need to see as both warm
and smart, nice and competent,

00:26:33.770 --> 00:26:35.680
both of those things.

00:26:35.680 --> 00:26:37.270
If I just see you
as competent, I'm

00:26:37.270 --> 00:26:39.430
not encoding you in my
brain as fully human.

00:26:39.430 --> 00:26:41.550
If I just see was
warm and empathetic,

00:26:41.550 --> 00:26:43.889
I'm not encoding
you as fully human.

00:26:43.889 --> 00:26:45.430
So what we're finding
is if I let you

00:26:45.430 --> 00:26:47.500
listen to four separate voices.

00:26:47.500 --> 00:26:49.140
One is going to be--

00:26:49.140 --> 00:26:51.570
they're all going to
be accented voices--

00:26:51.570 --> 00:26:53.320
one is going to be a
person with what they

00:26:53.320 --> 00:26:55.030
call the Anglo-American accent.

00:26:55.030 --> 00:26:56.850
And that's Nebraska, folks.

00:26:56.850 --> 00:26:58.810
We required the
Nebraska accent of all

00:26:58.810 --> 00:27:03.430
of our national male anchors
for news, not the women

00:27:03.430 --> 00:27:06.280
and not the local anchors,
but the national male anchors.

00:27:06.280 --> 00:27:08.560
So people will
take classes to try

00:27:08.560 --> 00:27:11.620
to sound more Nebraska-like.

00:27:11.620 --> 00:27:13.797
And so we've got that voice.

00:27:13.797 --> 00:27:15.880
We'll get a "Harry Potter,
middle income" British,

00:27:15.880 --> 00:27:19.300
not Beatles British, not
aristocratic British.

00:27:19.300 --> 00:27:21.790
Then we'll get a native
Cantonese speaker And then

00:27:21.790 --> 00:27:24.257
a native Spanish
speaker from Mexico.

00:27:24.257 --> 00:27:26.590
And we're going to let you
listen to each of the voices.

00:27:26.590 --> 00:27:28.510
What will your brain
do with the voices?

00:27:28.510 --> 00:27:32.830
Well, we find that Harry
Potter and I'll say Dan Rather,

00:27:32.830 --> 00:27:33.880
I believe is from Texas.

00:27:33.880 --> 00:27:38.230
But he sounded like he was from
Nebraska when he took the desk.

00:27:38.230 --> 00:27:40.510
We'll say that those
two individuals clearly

00:27:40.510 --> 00:27:45.820
were encoded fully as warm and
smart, as nice and competent

00:27:45.820 --> 00:27:47.410
on a human encoding scale.

00:27:47.410 --> 00:27:49.600
The native Cantonese
speaker didn't score quite

00:27:49.600 --> 00:27:52.810
as well for warm, but for
the native Spanish speaker

00:27:52.810 --> 00:27:55.630
for Mexico, they
lost on both grounds,

00:27:55.630 --> 00:27:57.790
both warm and competent.

00:27:57.790 --> 00:27:59.350
So there are groups
that we may be

00:27:59.350 --> 00:28:03.700
failing to encode in our brains
as fully human on both scales.

00:28:03.700 --> 00:28:05.440
That'll reduce our
empathy for them.

00:28:05.440 --> 00:28:07.531
That will change the way
we allocate resources.

00:28:07.531 --> 00:28:09.280
That will alter the
way that we bring them

00:28:09.280 --> 00:28:11.200
into the team,
the access they'll

00:28:11.200 --> 00:28:17.890
have to have full contribution
making power into that team.

00:28:17.890 --> 00:28:18.780
Can I say something?

00:28:18.780 --> 00:28:19.840
Will it be heard?

00:28:19.840 --> 00:28:21.109
Will it be valued?

00:28:21.109 --> 00:28:23.650
MICHAEL SKOLNIK: I want to turn
to the audience for a second.

00:28:23.650 --> 00:28:26.230
There's a lot of amazing
things coming in.

00:28:26.230 --> 00:28:27.970
I don't want to do
a traditional just

00:28:27.970 --> 00:28:33.040
we speak Q&amp;A. I want to
take a moment to breathe.

00:28:33.040 --> 00:28:36.220
And if there's any comments
or thoughts or questions

00:28:36.220 --> 00:28:39.505
we have at this moment, I
certainly would welcome them.

00:28:39.505 --> 00:28:43.480
So if anybody has any comments
or questions or thoughts,

00:28:43.480 --> 00:28:45.130
the floor is yours.

00:28:45.130 --> 00:28:46.330
If not, I'll continue.

00:28:46.330 --> 00:28:48.250
But if you want to,
please raise your hand.

00:28:48.250 --> 00:28:49.930
Don't be shy.

00:28:49.930 --> 00:28:52.300
And we'll come back
to the audience.

00:28:52.300 --> 00:28:55.220
I'm going to come out there
and do my Phil Donahue,

00:28:55.220 --> 00:28:59.760
my Dan Rather with
not my raspy voice.

00:28:59.760 --> 00:29:01.390
So back to the voice.

00:29:01.390 --> 00:29:04.330
So you hear this voice, right?

00:29:04.330 --> 00:29:08.110
You make judgment on his voice.

00:29:08.110 --> 00:29:10.015
Where does the
microaggression come in?

00:29:10.015 --> 00:29:13.450
KIMBERLY PAPILLON: Let's say
that your voice wasn't what

00:29:13.450 --> 00:29:16.360
I was expecting in a number
of different respects.

00:29:16.360 --> 00:29:21.040
Let's say I say to you, oh,
you speak English so well.

00:29:21.040 --> 00:29:25.340
And your response is
yeah, I'm from Cleveland.

00:29:25.340 --> 00:29:27.040
There shouldn't be
a surprise here.

00:29:27.040 --> 00:29:28.635
But the notion that
you are surprised

00:29:28.635 --> 00:29:33.384
or that I am surprised that you
are able to navigate English

00:29:33.384 --> 00:29:35.800
as well as you do, the English
language as well as you do,

00:29:35.800 --> 00:29:39.240
is an indication that that
wasn't my template for you.

00:29:39.240 --> 00:29:40.420
Let's say--

00:29:40.420 --> 00:29:45.150
MICHAEL SKOLNIK: There
were some conversations

00:29:45.150 --> 00:29:47.880
when Barack Obama is running
for president how articulate he

00:29:47.880 --> 00:29:51.270
was, that Barack was
so articulate even

00:29:51.270 --> 00:29:55.090
by democrats, even by the man
who became his vice president.

00:29:55.090 --> 00:29:58.200
He used that during a
debate that he is articulate

00:29:58.200 --> 00:30:01.000
as if Barack Obama would be
anything different than being

00:30:01.000 --> 00:30:01.500
articulate.

00:30:01.500 --> 00:30:03.660
So those ideas of
judging someone

00:30:03.660 --> 00:30:07.805
by their use of language, their
use of the English language

00:30:07.805 --> 00:30:09.180
can lead to that
microaggression.

00:30:09.180 --> 00:30:11.190
KIMBERLY PAPILLON: And watch how
the microaggression works even

00:30:11.190 --> 00:30:12.310
in that respect.

00:30:12.310 --> 00:30:14.040
So each of those
microaggressions

00:30:14.040 --> 00:30:15.900
were compliments.

00:30:15.900 --> 00:30:18.330
If I say to you,
you're so articulate.

00:30:18.330 --> 00:30:22.380
And you then give me some kind
of surprise, negative response,

00:30:22.380 --> 00:30:23.152
then I say, what?

00:30:23.152 --> 00:30:24.360
I just gave you a compliment.

00:30:24.360 --> 00:30:25.065
What's the problem?

00:30:25.065 --> 00:30:26.160
MICHAEL SKOLNIK: Then
I become the problem.

00:30:26.160 --> 00:30:27.743
KIMBERLY PAPILLON:
You're the problem.

00:30:27.743 --> 00:30:29.860
You're playing the card,
whatever it might be.

00:30:29.860 --> 00:30:32.430
And so the notion inside
of microaggressions

00:30:32.430 --> 00:30:35.520
is that there's
a subtlety to it.

00:30:35.520 --> 00:30:37.980
And the fact that
you were surprised

00:30:37.980 --> 00:30:40.440
or that I was surprised
that you were articulate

00:30:40.440 --> 00:30:43.020
was the insult or
the aggression.

00:30:43.020 --> 00:30:45.570
But yes, it came in the
form of a compliment.

00:30:45.570 --> 00:30:47.476
And so the person
who's speaking it aloud

00:30:47.476 --> 00:30:49.600
doesn't believe that they're
saying anything other.

00:30:49.600 --> 00:30:51.090
In fact, they may
have been building up

00:30:51.090 --> 00:30:53.240
to finally want to say
something really nice to you.

00:30:53.240 --> 00:30:54.720
And that's the thing
that they could think of,

00:30:54.720 --> 00:30:56.670
and they tell you how
articulate you are.

00:30:56.670 --> 00:30:58.320
So they are taken aback.

00:30:58.320 --> 00:31:02.070
Now what you have is a
problem with perhaps some kind

00:31:02.070 --> 00:31:04.770
of discontinuity in
the workplace because I

00:31:04.770 --> 00:31:07.950
opened up and tried to
tell you something nice.

00:31:07.950 --> 00:31:10.095
And you gave back
something that indicated

00:31:10.095 --> 00:31:11.520
that I'd done something wrong.

00:31:11.520 --> 00:31:13.936
Now I just want to shut down
and not have the conversation

00:31:13.936 --> 00:31:16.380
anymore because
I don't even know

00:31:16.380 --> 00:31:17.850
how to communicate with you.

00:31:17.850 --> 00:31:19.830
I don't know how to even
give you a compliment.

00:31:19.830 --> 00:31:22.680
So the recognition that maybe
I don't know everything there

00:31:22.680 --> 00:31:24.780
is to know about communication.

00:31:24.780 --> 00:31:26.850
Maybe I should step
back for a moment

00:31:26.850 --> 00:31:29.790
and realize that some things may
mean something different to one

00:31:29.790 --> 00:31:31.320
person versus another.

00:31:31.320 --> 00:31:33.060
And a good way to
reflect on that

00:31:33.060 --> 00:31:36.750
is to think what might
I find to be problematic

00:31:36.750 --> 00:31:39.810
when people have said it to me
that I know other people say,

00:31:39.810 --> 00:31:41.050
no big deal.

00:31:41.050 --> 00:31:42.180
Let it go.

00:31:42.180 --> 00:31:43.780
And that begins to
build the empathy.

00:31:43.780 --> 00:31:46.890
Yes, there are things that are
specific to certain people that

00:31:46.890 --> 00:31:49.380
perhaps are problematic for
me to say because it makes

00:31:49.380 --> 00:31:52.410
it appear as if I'm surprised,
that they're doing that well,

00:31:52.410 --> 00:31:55.170
that they are that able
to navigate English,

00:31:55.170 --> 00:31:57.760
that they're that articulate,
those types of things.

00:31:57.760 --> 00:31:59.730
MICHAEL SKOLNIK: So let
me answer a question.

00:31:59.730 --> 00:32:04.980
And we'll come back to
meeting this new person.

00:32:04.980 --> 00:32:07.280
I'm not a HR person.

00:32:07.280 --> 00:32:11.940
So I was a theater major
for full disclosure.

00:32:11.940 --> 00:32:15.900
So we are not here to
have an HR discussion.

00:32:15.900 --> 00:32:21.580
Those are for other kinds of
professionals who do HR work.

00:32:21.580 --> 00:32:23.610
When this conversation
of microaggressions

00:32:23.610 --> 00:32:25.672
was proposed as
part of the series,

00:32:25.672 --> 00:32:27.630
there are many folks who
Google said, yes, this

00:32:27.630 --> 00:32:29.180
is the conversation
we need to have.

00:32:29.180 --> 00:32:30.510
Folks who are shaking their
head in your audience,

00:32:30.510 --> 00:32:31.801
I won't look in that direction.

00:32:31.801 --> 00:32:32.972
But I see some head nods.

00:32:32.972 --> 00:32:34.680
This is the conversation
we need to have.

00:32:34.680 --> 00:32:36.690
There are also folks
at Google who say,

00:32:36.690 --> 00:32:39.300
we actually have a really
healthy work environment here.

00:32:39.300 --> 00:32:42.300
I've heard words like family.

00:32:42.300 --> 00:32:46.170
I've heard words
like this is home.

00:32:46.170 --> 00:32:48.720
I've been to now
15 Google campuses,

00:32:48.720 --> 00:32:51.200
and I see an
amazing camaraderie.

00:32:51.200 --> 00:32:53.700
I see some folks who I met,
who came from the data center.

00:32:53.700 --> 00:32:55.950
This is their second time here.

00:32:55.950 --> 00:32:56.730
Welcome back.

00:33:00.450 --> 00:33:02.640
There is a sense of
wearing Google with pride.

00:33:02.640 --> 00:33:04.010
I'm a Googler.

00:33:04.010 --> 00:33:08.300
It's a way to identify yourself.

00:33:08.300 --> 00:33:12.840
But yeah, this
conversation oftentimes--

00:33:12.840 --> 00:33:15.670
and we're not trying to
open up a can of worms--

00:33:15.670 --> 00:33:19.530
but oftentimes gets shut down
as being politically correct.

00:33:19.530 --> 00:33:22.620
And certainly in this last
presidential election,

00:33:22.620 --> 00:33:24.830
those words are
being thrown around.

00:33:24.830 --> 00:33:27.510
Oh, they're just being
politically correct.

00:33:27.510 --> 00:33:30.770
Political correctness is the
reason we have this problem.

00:33:30.770 --> 00:33:34.230
And then I hear oftentimes
a criticism for me--

00:33:34.230 --> 00:33:37.497
if you stop talking about
race, racism will go away.

00:33:37.497 --> 00:33:39.330
But you're the problem
because you're always

00:33:39.330 --> 00:33:41.720
talking about race.

00:33:41.720 --> 00:33:46.090
So how do we have
these conversations

00:33:46.090 --> 00:33:50.040
in a healthy
environment but that

00:33:50.040 --> 00:33:54.010
are honest and that
if someone said,

00:33:54.010 --> 00:33:59.420
can touch my hair,
that might hurt me.

00:33:59.420 --> 00:34:01.450
And I don't understand,
as you said,

00:34:01.450 --> 00:34:03.190
how that hurts that person.

00:34:03.190 --> 00:34:06.010
How does that translate
into a conversation

00:34:06.010 --> 00:34:07.650
that is productive?

00:34:07.650 --> 00:34:09.971
KIMBERLY PAPILLON: That
makes a lot of sense.

00:34:09.971 --> 00:34:12.429
Political correctness is a term
that I think, you're right,

00:34:12.429 --> 00:34:15.040
has been a bit demonized.

00:34:15.040 --> 00:34:17.550
We'll challenge Google to
come up with a new term.

00:34:17.550 --> 00:34:18.135
MICHAEL SKOLNIK: Good idea.

00:34:18.135 --> 00:34:20.259
KIMBERLY PAPILLON: I think
that there are certainly

00:34:20.259 --> 00:34:21.219
able to do so.

00:34:21.219 --> 00:34:24.670
I'll wait to see that
news blast at any moment.

00:34:24.670 --> 00:34:25.989
But I will say this--

00:34:25.989 --> 00:34:28.389
microaggressions
have health effects,

00:34:28.389 --> 00:34:30.130
long-term and short-term
health effects.

00:34:30.130 --> 00:34:32.580
And there are a number of
studies that show that.

00:34:32.580 --> 00:34:35.920
Long-term, what we call
epigenetic health effects,

00:34:35.920 --> 00:34:39.670
changes in cortisol release,
long-term chronic disease

00:34:39.670 --> 00:34:40.170
effects.

00:34:40.170 --> 00:34:41.753
So the people who
are on the receiving

00:34:41.753 --> 00:34:44.830
end of microaggressions
constantly over and over

00:34:44.830 --> 00:34:45.610
again--

00:34:45.610 --> 00:34:48.469
because you can't really
speak about them out loud,

00:34:48.469 --> 00:34:50.230
because you can't
really voice them,

00:34:50.230 --> 00:34:52.420
and often you try to tell
yourself to ignore them,

00:34:52.420 --> 00:34:55.719
they seem to have a physiologic
effect on an individual's

00:34:55.719 --> 00:34:56.230
health.

00:34:56.230 --> 00:34:59.730
So it's not just simply can
we be more polite, which

00:34:59.730 --> 00:35:02.967
fork do you pick up, the kind
of Emily Post-type conversation.

00:35:02.967 --> 00:35:04.300
It really goes deeper than that.

00:35:04.300 --> 00:35:08.036
It goes to do I feel
as if I belong here.

00:35:08.036 --> 00:35:10.510
And how does that affect
me as a person who's

00:35:10.510 --> 00:35:13.845
trying to work in an
environment that I really love,

00:35:13.845 --> 00:35:15.970
where I really want to be
productive and contribute

00:35:15.970 --> 00:35:18.428
to the team, which is part of
the essence of a conversation

00:35:18.428 --> 00:35:19.750
at Google in my opinion.

00:35:19.750 --> 00:35:22.300
So they've got a
study that shows

00:35:22.300 --> 00:35:25.650
if you feel someone's
treating you unfairly,

00:35:25.650 --> 00:35:28.057
a part of your brain called
the insula activates.

00:35:28.057 --> 00:35:29.890
And the insula is the
same part of the brain

00:35:29.890 --> 00:35:33.520
that turns on when you
smell rotten garbage.

00:35:33.520 --> 00:35:35.350
That's an effect,
then, if I constantly

00:35:35.350 --> 00:35:38.410
believe I'm being treated
unfairly, small or large

00:35:38.410 --> 00:35:39.700
incidents.

00:35:39.700 --> 00:35:41.560
There's another study,
study at Stanford,

00:35:41.560 --> 00:35:43.350
and it kills me to say that.

00:35:43.350 --> 00:35:44.770
Go Bears.

00:35:44.770 --> 00:35:48.385
So they take 10 people,
put them all in a row,

00:35:48.385 --> 00:35:50.010
and they tell them
you're going to pass

00:35:50.010 --> 00:35:51.760
a ball around, one ball.

00:35:51.760 --> 00:35:54.370
And they say to 9
of the 10 people,

00:35:54.370 --> 00:35:56.950
don't give the ball
to person number 10.

00:35:56.950 --> 00:35:57.520
No problem.

00:35:57.520 --> 00:35:59.290
Person number 10 has no
idea what's going on.

00:35:59.290 --> 00:36:00.910
They pass the ball around
and pass the ball around

00:36:00.910 --> 00:36:02.170
and pass the ball around.

00:36:02.170 --> 00:36:04.900
And then they take person number
10 and they scan their brain.

00:36:04.900 --> 00:36:06.460
And they find that
person number 10

00:36:06.460 --> 00:36:08.530
has the same brain
reaction as if they've

00:36:08.530 --> 00:36:10.522
been punched in the gut.

00:36:10.522 --> 00:36:12.730
Now that's different from
getting punched in the arm.

00:36:12.730 --> 00:36:14.339
That's a pain conversation.

00:36:14.339 --> 00:36:15.880
But the part that's
unique to getting

00:36:15.880 --> 00:36:19.120
punched in the gut, the anxiety,
the helplessness, the panic,

00:36:19.120 --> 00:36:23.110
the fear, that is unique to
the gut punch, getting the wind

00:36:23.110 --> 00:36:24.520
knocked out of you.

00:36:24.520 --> 00:36:27.100
So there are people walking
around the workplace who

00:36:27.100 --> 00:36:29.230
feel like they can
smell rotten garbage

00:36:29.230 --> 00:36:31.690
and they got punched in the gut.

00:36:31.690 --> 00:36:33.970
That's got to really
reduce productivity.

00:36:33.970 --> 00:36:36.370
That's beyond the idea
of were we polite.

00:36:36.370 --> 00:36:39.070
That's the notion
of is someone having

00:36:39.070 --> 00:36:41.920
a neurophysiologic
reaction to being

00:36:41.920 --> 00:36:45.040
seen as other or less than.

00:36:45.040 --> 00:36:48.250
And can I touch your
hair says other.

00:36:48.250 --> 00:36:52.990
And you are so articulate, in a
surprised way, says less than.

00:36:52.990 --> 00:36:55.150
And in an organization
that wants nothing

00:36:55.150 --> 00:36:56.910
but the best from all
of their employees,

00:36:56.910 --> 00:36:58.840
nothing but the highest
level of productivity

00:36:58.840 --> 00:37:00.952
and creativity at
that, you really

00:37:00.952 --> 00:37:02.410
want to foster an
environment where

00:37:02.410 --> 00:37:04.240
people feel when
they walk in the door

00:37:04.240 --> 00:37:06.546
that they're there to belong.

00:37:06.546 --> 00:37:08.710
MICHAEL SKOLNIK:
So I'm a white man.

00:37:08.710 --> 00:37:13.830
And I don't think I'm racist.

00:37:13.830 --> 00:37:16.150
And I think I have
black friends.

00:37:16.150 --> 00:37:19.523
And I support Black
History Month.

00:37:19.523 --> 00:37:23.316
And I voted for Barack Obama.

00:37:23.316 --> 00:37:27.778
But yet I find
myself in a meeting--

00:37:27.778 --> 00:37:31.900
if I take a step back, oh,
I'm judging you as a woman.

00:37:31.900 --> 00:37:34.023
Or I'm judging you
as a black man.

00:37:34.023 --> 00:37:38.620
And how do I find
a solution for me

00:37:38.620 --> 00:37:42.610
as an individual in the
workplace to not be the one who

00:37:42.610 --> 00:37:44.405
says, can I touch your hair?

00:37:44.405 --> 00:37:47.140
KIMBERLY PAPILLON: Well,
one of the first steps

00:37:47.140 --> 00:37:50.920
is to reduce what we call the
level of moral credentialing.

00:37:50.920 --> 00:37:54.400
So I voted for Barack Obama.

00:37:54.400 --> 00:37:57.899
I vote for President Obama.

00:37:57.899 --> 00:38:00.190
Some of my best friends are
fill in the blank, whatever

00:38:00.190 --> 00:38:01.150
it might be.

00:38:01.150 --> 00:38:04.540
Those create a reaction called
moral credentialing, which

00:38:04.540 --> 00:38:08.200
is the brain reaction that's
akin to eating chocolate.

00:38:08.200 --> 00:38:09.310
I feel rewarded.

00:38:09.310 --> 00:38:10.335
And I reward myself.

00:38:10.335 --> 00:38:11.835
And whenever I come
into a situation

00:38:11.835 --> 00:38:14.110
where I think I might
mess up, I remind myself

00:38:14.110 --> 00:38:16.360
of the individuals who
I've reached out to,

00:38:16.360 --> 00:38:18.730
the young person that
I tutored at the school

00:38:18.730 --> 00:38:21.010
down the street,
all those people.

00:38:21.010 --> 00:38:22.690
That gives me a
better sense of I

00:38:22.690 --> 00:38:26.500
couldn't possibly have this
simplistic negative association

00:38:26.500 --> 00:38:27.310
in play.

00:38:27.310 --> 00:38:30.310
And that actually keeps
me from doing the work

00:38:30.310 --> 00:38:34.630
that I need to do to undo that
so-called unconscious bias

00:38:34.630 --> 00:38:36.790
because I tell myself it
couldn't have affected me

00:38:36.790 --> 00:38:39.490
because some of my best
friends are fill in the blank.

00:38:39.490 --> 00:38:43.100
That is actually a barrier
to getting to a solution.

00:38:43.100 --> 00:38:44.710
And the reason we
give it to ourselves

00:38:44.710 --> 00:38:48.400
is because people's value
system is I want to be fair.

00:38:48.400 --> 00:38:51.450
And when they see the spectrum
of unfairness raised, they say,

00:38:51.450 --> 00:38:54.540
let me remind myself of
how I'm definitely fair.

00:38:54.540 --> 00:38:56.150
I get that chocolate feeling.

00:38:56.150 --> 00:38:58.750
And now I can just
go on with my day.

00:38:58.750 --> 00:39:00.780
So if we can remove
the notion of needing

00:39:00.780 --> 00:39:04.230
to have the moral
credentialing, saying it's OK.

00:39:04.230 --> 00:39:05.790
This is a human reaction.

00:39:05.790 --> 00:39:07.576
It's not OK if it
manifests itself

00:39:07.576 --> 00:39:08.700
in a way that hurts people.

00:39:08.700 --> 00:39:10.408
But the fact that I
have these templates,

00:39:10.408 --> 00:39:12.510
this is something
that came into my mind

00:39:12.510 --> 00:39:15.570
when I was watching
Saturday morning cartoons.

00:39:15.570 --> 00:39:18.210
In the '50s, in the
'60s, the accent given

00:39:18.210 --> 00:39:21.810
to the bad guy in most children
shows was Russian and German.

00:39:21.810 --> 00:39:24.180
You grew up during that time,
Russian and German, that's

00:39:24.180 --> 00:39:25.680
the sound of the bad guy.

00:39:25.680 --> 00:39:28.470
In the '70s, we get
aristocratic British

00:39:28.470 --> 00:39:32.310
as the mastermind bad guy
and African-American ebonics.

00:39:32.310 --> 00:39:34.089
Ebonics is an antiquated term.

00:39:34.089 --> 00:39:36.630
If you're listening to a voice
and as you're listening to it,

00:39:36.630 --> 00:39:39.000
you can definitely tell that
the person who was speaking

00:39:39.000 --> 00:39:42.360
is African-American or the
rapper Eminem, either way,

00:39:42.360 --> 00:39:44.770
that's African-American ebonics.

00:39:44.770 --> 00:39:48.120
And then in the 1980s, we
add on a Latino accent.

00:39:48.120 --> 00:39:50.940
And there's multiple Latino
accents, so mostly Colombian,

00:39:50.940 --> 00:39:52.900
Puerto Rican, Mexican-American.

00:39:52.900 --> 00:39:55.100
Those will be the three
that we'll add in.

00:39:55.100 --> 00:39:57.570
And those are loose terms.

00:39:57.570 --> 00:40:00.270
And we find that these
become the villains.

00:40:00.270 --> 00:40:02.470
And we can look at
all kinds of examples,

00:40:02.470 --> 00:40:04.080
including even the
Lion King, where

00:40:04.080 --> 00:40:07.770
Scar is a lion on the African
desert, who was apparently

00:40:07.770 --> 00:40:10.120
educated at Oxford.

00:40:10.120 --> 00:40:12.490
And we're thinking, why is
this lion, who's the bad--

00:40:12.490 --> 00:40:14.370
but he's the mastermind bad guy.

00:40:14.370 --> 00:40:16.560
So we're replete
with these examples.

00:40:16.560 --> 00:40:19.110
Our brains are like
heat-seeking missiles.

00:40:19.110 --> 00:40:21.590
We're looking for templates.

00:40:21.590 --> 00:40:23.940
And so if we can
get past the guilt

00:40:23.940 --> 00:40:25.817
and stop dealing with
the moral credentialing

00:40:25.817 --> 00:40:27.900
and move onto the solution,
then we're on our way.

00:40:27.900 --> 00:40:30.108
And the solutions are based
in the neuroscience, too,

00:40:30.108 --> 00:40:31.740
of course.

00:40:31.740 --> 00:40:33.870
If I'm the manager and
I'm sitting in a meeting

00:40:33.870 --> 00:40:36.240
and I want to look at how
many times certain people are

00:40:36.240 --> 00:40:39.530
being interrupted over others,
I might not tell anybody.

00:40:39.530 --> 00:40:41.280
I'm not going to point
out which employees

00:40:41.280 --> 00:40:42.405
are doing the interrupting.

00:40:42.405 --> 00:40:44.910
I'm just going to note who gets
interrupted more frequently.

00:40:44.910 --> 00:40:46.110
And then afterwards,
I have the meeting.

00:40:46.110 --> 00:40:47.910
I say to everybody,
look, I'm going

00:40:47.910 --> 00:40:49.500
to be watching
whether or not we're

00:40:49.500 --> 00:40:51.570
letting people
finish their thoughts

00:40:51.570 --> 00:40:54.360
and whether or not we're
encouraging people to share

00:40:54.360 --> 00:40:55.670
inside of that meeting.

00:40:55.670 --> 00:40:57.660
Well, now there's a
part of my brain called

00:40:57.660 --> 00:41:00.090
the rostral anterior
cingulate cortex that's

00:41:00.090 --> 00:41:02.730
going to turn on whenever
I think I'm being monitored

00:41:02.730 --> 00:41:04.145
for race-related bias.

00:41:04.145 --> 00:41:06.270
My manager is not saying
it's going to be punitive.

00:41:06.270 --> 00:41:08.353
They're just saying, I'm
paying attention to this.

00:41:08.353 --> 00:41:09.480
I want us to do better.

00:41:09.480 --> 00:41:11.610
Now what if I start
self-monitoring.

00:41:11.610 --> 00:41:13.230
I don't need my manager, right?

00:41:13.230 --> 00:41:14.460
I can self-monitor.

00:41:14.460 --> 00:41:16.950
I'm going to note how
frequently I interrupt

00:41:16.950 --> 00:41:18.780
one person versus another.

00:41:18.780 --> 00:41:21.960
As soon as I start noting
it, my RACC turns on,

00:41:21.960 --> 00:41:25.260
and I stop interrupting people,
at least not as frequently

00:41:25.260 --> 00:41:26.280
one to the other.

00:41:26.280 --> 00:41:28.380
So the solutions are
based on the neuroscience.

00:41:28.380 --> 00:41:30.660
What part of the brain
do you need to turn on.

00:41:30.660 --> 00:41:32.850
When I give my
lectures, I tell people,

00:41:32.850 --> 00:41:35.310
the thesis of the
conversation is getting back

00:41:35.310 --> 00:41:37.320
control of your brain.

00:41:37.320 --> 00:41:39.210
If there's 1.2 million
in the background that

00:41:39.210 --> 00:41:41.100
is guiding our
decision-making and it

00:41:41.100 --> 00:41:43.140
doesn't align with
your value system,

00:41:43.140 --> 00:41:46.305
you need to get control
of your brain back.

00:41:46.305 --> 00:41:49.495
MICHAEL SKOLNIK: So our first
conversation that we had with--

00:41:49.495 --> 00:41:53.820
I actually was on the panel
with [INAUDIBLE] and [INAUDIBLE]

00:41:53.820 --> 00:41:54.860
We're in New York.

00:41:54.860 --> 00:41:56.390
I think, Dory, you were there.

00:41:56.390 --> 00:41:57.848
And there was a
young woman sitting

00:41:57.848 --> 00:41:59.395
in the front, a young
African-American woman sitting

00:41:59.395 --> 00:41:59.940
in the front.

00:41:59.940 --> 00:42:01.360
And she had a T-shirt on.

00:42:01.360 --> 00:42:03.610
And the T-shirt had the
names of the victims

00:42:03.610 --> 00:42:05.920
of police brutality.

00:42:05.920 --> 00:42:09.370
And afterwards I said to
her, do you feel comfortable

00:42:09.370 --> 00:42:12.100
wearing that T-shirt to work?

00:42:12.100 --> 00:42:16.057
And she says, I do, but I
get asked a lot of questions.

00:42:16.057 --> 00:42:16.890
What does that mean?

00:42:16.890 --> 00:42:17.931
Why are you wearing that?

00:42:17.931 --> 00:42:19.140
Who are those people?

00:42:19.140 --> 00:42:21.480
What do the names represent?

00:42:21.480 --> 00:42:23.430
So bringing your
most authentic self

00:42:23.430 --> 00:42:30.160
to work, how do
we do that with--

00:42:30.160 --> 00:42:34.170
and I'm saying me not be part
of the we as a white male who is

00:42:34.170 --> 00:42:38.350
never judged with how I dress
or what I have on my T-shirt--

00:42:38.350 --> 00:42:40.920
But how we, for
those who are judged

00:42:40.920 --> 00:42:43.300
or those who are
asked questions,

00:42:43.300 --> 00:42:47.280
how do we bring our most
authentic selves to work

00:42:47.280 --> 00:42:53.490
with pride and without
fear of retribution

00:42:53.490 --> 00:42:57.150
or fear of punishment or fear
of getting asked a question over

00:42:57.150 --> 00:43:00.030
and over again about your
hair or about your T-shirt

00:43:00.030 --> 00:43:04.099
or about the way you speak or
about the way your name is?

00:43:04.099 --> 00:43:05.640
How can someone in
this room or who's

00:43:05.640 --> 00:43:10.040
watching on the livestream
bring their most authentic self

00:43:10.040 --> 00:43:13.612
to work and still feel like they
can have a job the next day?

00:43:13.612 --> 00:43:15.570
KIMBERLY PAPILLON: That's
an excellent question

00:43:15.570 --> 00:43:16.830
because we want that.

00:43:16.830 --> 00:43:19.670
If I feel comfortable,
I'm more creative.

00:43:19.670 --> 00:43:22.170
Now there's some places where
we don't encourage creativity.

00:43:22.170 --> 00:43:22.370
MICHAEL SKOLNIK: I love that.

00:43:22.370 --> 00:43:22.995
Say that again.

00:43:22.995 --> 00:43:25.710
KIMBERLY PAPILLON: If I feel
comfortable, I'm more creative.

00:43:25.710 --> 00:43:29.010
And in those places where we
don't encourage creativity,

00:43:29.010 --> 00:43:32.010
then we can say, perhaps bring
your authentic self to work

00:43:32.010 --> 00:43:33.420
isn't as much of
a value in terms

00:43:33.420 --> 00:43:36.870
of the bottom line for the
organization or the company.

00:43:36.870 --> 00:43:38.470
But if we're looking
for creativity,

00:43:38.470 --> 00:43:41.670
if we're looking for
innovation, doing that

00:43:41.670 --> 00:43:45.720
is difficult in a
stressful environment.

00:43:45.720 --> 00:43:47.460
When I have an
amygdala activation,

00:43:47.460 --> 00:43:49.340
let's say I'm just
scared of being myself.

00:43:49.340 --> 00:43:52.150
I have to constantly
be on my Ps and Qs,

00:43:52.150 --> 00:43:54.170
an amygdala activation
actually depletes

00:43:54.170 --> 00:43:56.694
the executive
functioning of the brain.

00:43:56.694 --> 00:43:58.610
So we want to be really
careful to try to make

00:43:58.610 --> 00:43:59.610
people feel comfortable.

00:43:59.610 --> 00:44:02.000
Now we're not
running Google Camp.

00:44:02.000 --> 00:44:04.250
This isn't a place for
everybody to learn how to play.

00:44:04.250 --> 00:44:05.900
MICHAEL SKOLNIK: A little bit.

00:44:05.900 --> 00:44:07.646
KIMBERLY PAPILLON:
A little bit, right?

00:44:07.646 --> 00:44:09.770
We don't all have to hold
hands and sing "Kumbaya."

00:44:09.770 --> 00:44:11.728
But we do want to have
a situation where people

00:44:11.728 --> 00:44:13.340
feel like, I can wear this.

00:44:13.340 --> 00:44:14.960
It is appropriate in the office.

00:44:14.960 --> 00:44:18.620
But I won't be judged
negatively for it.

00:44:18.620 --> 00:44:20.330
People might ask questions.

00:44:20.330 --> 00:44:21.890
And I can explain
it and not feel

00:44:21.890 --> 00:44:24.780
as if I have to edit every
single term that I use.

00:44:24.780 --> 00:44:25.970
And that's what we want.

00:44:25.970 --> 00:44:27.500
And how to get that going--

00:44:27.500 --> 00:44:28.790
leadership.

00:44:28.790 --> 00:44:30.710
These kinds of conversations.

00:44:30.710 --> 00:44:33.680
Saying that this is an important
conversation for everyone

00:44:33.680 --> 00:44:34.460
to be having.

00:44:34.460 --> 00:44:37.340
And we want you to be
comfortable having it.

00:44:37.340 --> 00:44:40.220
Number two,
indictment goes down.

00:44:40.220 --> 00:44:43.070
We all have these various
ideas in our heads.

00:44:43.070 --> 00:44:45.740
Let's try to work
with them together.

00:44:45.740 --> 00:44:48.290
Number three, education.

00:44:48.290 --> 00:44:49.880
It's not a small thing.

00:44:49.880 --> 00:44:51.560
But learning about
one another so you

00:44:51.560 --> 00:44:53.480
don't have to get
your colleague, who

00:44:53.480 --> 00:44:55.850
fits in a particular
category, to be the professor

00:44:55.850 --> 00:44:57.764
on all things Latino.

00:44:57.764 --> 00:44:59.180
And suddenly they
have to tell you

00:44:59.180 --> 00:45:00.347
all about all things Latino.

00:45:00.347 --> 00:45:01.971
And they're thinking
that I don't think

00:45:01.971 --> 00:45:03.270
that's in my job description.

00:45:03.270 --> 00:45:06.110
So that distracts from what
they would be doing that day.

00:45:06.110 --> 00:45:08.060
It goes beyond the potluck.

00:45:08.060 --> 00:45:10.700
But leadership saying, we
care about these things

00:45:10.700 --> 00:45:14.180
and putting mechanisms in
place to make sure that that

00:45:14.180 --> 00:45:15.690
is part of the value system.

00:45:15.690 --> 00:45:19.220
There is software that Google
can put in place to make sure

00:45:19.220 --> 00:45:20.720
that people are all
getting a, quote

00:45:20.720 --> 00:45:24.260
unquote, "fair opportunity for
certain types of assignments."

00:45:24.260 --> 00:45:27.950
There are images that can be put
up inside of the workplace that

00:45:27.950 --> 00:45:30.320
demonstrate a certain
value for equity,

00:45:30.320 --> 00:45:32.551
that anyone can work
this particular job

00:45:32.551 --> 00:45:34.550
and look at the different
faces that are working

00:45:34.550 --> 00:45:36.320
in this particular job.

00:45:36.320 --> 00:45:38.930
Those types of conversations
are powerful because they're

00:45:38.930 --> 00:45:42.050
the same things that imprinted
us in the first place

00:45:42.050 --> 00:45:43.625
when we were children.

00:45:43.625 --> 00:45:45.890
These ideas of black,
good, white, bad,

00:45:45.890 --> 00:45:47.060
this is not universal.

00:45:47.060 --> 00:45:48.200
This is learned behavior.

00:45:48.200 --> 00:45:49.980
We're not born this way.

00:45:49.980 --> 00:45:53.390
We come to it through
images, through messages

00:45:53.390 --> 00:45:54.920
from all different portals.

00:45:54.920 --> 00:45:57.212
And so we have a way
to unlearn it as well.

00:45:57.212 --> 00:45:59.300
MICHAEL SKOLNIK: I would
love to turn to a reader

00:45:59.300 --> 00:46:01.008
the audience who wants
to ask a question.

00:46:03.070 --> 00:46:06.380
This gentleman in the back
with the beautiful shirt on.

00:46:06.380 --> 00:46:09.110
I love everyone's shirts today.

00:46:09.110 --> 00:46:12.710
I think I've got to give you
a microphone so our friends--

00:46:12.710 --> 00:46:13.280
come on up.

00:46:13.280 --> 00:46:14.140
The price is right.

00:46:14.140 --> 00:46:15.604
Spin the wheel!

00:46:15.604 --> 00:46:17.556
AUDIENCE: OK.

00:46:17.556 --> 00:46:18.532
Thank you, sir.

00:46:22.937 --> 00:46:25.020
Several things you said
bring up the same question

00:46:25.020 --> 00:46:26.920
in my mind, which
is if you're going

00:46:26.920 --> 00:46:29.430
to get control of
your behavior, then

00:46:29.430 --> 00:46:31.986
you need to know
what you should do.

00:46:31.986 --> 00:46:35.490
And many of these issues
around microaggressions,

00:46:35.490 --> 00:46:39.531
such as the example where
you had different assignments

00:46:39.531 --> 00:46:42.280
to different people, if you
want to recognize someone,

00:46:42.280 --> 00:46:44.379
how do you avoid-- you
can overdo it, right?

00:46:44.379 --> 00:46:45.420
KIMBERLY PAPILLON: Right.

00:46:45.420 --> 00:46:46.845
AUDIENCE: And that also makes
someone feel as though you're

00:46:46.845 --> 00:46:47.795
patronizing them.

00:46:47.795 --> 00:46:50.170
And so how do you
build the model

00:46:50.170 --> 00:46:54.279
for what you should do without
messing it up along the way?

00:46:54.279 --> 00:46:56.320
KIMBERLY PAPILLON: That
is an excellent question.

00:46:56.320 --> 00:46:58.210
That's an excellent question.

00:46:58.210 --> 00:47:00.750
So the first step in the
12-step program for solution

00:47:00.750 --> 00:47:02.380
is admit you have a problem.

00:47:02.380 --> 00:47:03.870
It just happened that way.

00:47:03.870 --> 00:47:07.200
Admit that implicit bias
exist or unconscious bias

00:47:07.200 --> 00:47:09.870
or negative associations
exist and that they affect

00:47:09.870 --> 00:47:13.650
your everyday decision-making,
that not implicit bias

00:47:13.650 --> 00:47:16.097
exist, and you really need
to talk to my colleagues.

00:47:16.097 --> 00:47:16.930
We're not there yet.

00:47:16.930 --> 00:47:18.638
It's implicit bias
exists, and it affects

00:47:18.638 --> 00:47:20.670
my everyday decision-making.

00:47:20.670 --> 00:47:25.320
But number two in our 12-step
program is take the test.

00:47:25.320 --> 00:47:27.535
Go on, and take the
implicit-association test.

00:47:27.535 --> 00:47:29.910
As your attorney, I tell you
not to print the results out

00:47:29.910 --> 00:47:31.746
and bring them back
to your colleagues.

00:47:31.746 --> 00:47:33.120
This is for your
own edification.

00:47:33.120 --> 00:47:35.430
But go online,
and take the test.

00:47:35.430 --> 00:47:37.667
And see where your
challenges might lie.

00:47:37.667 --> 00:47:39.125
They might not lie
where you think.

00:47:39.125 --> 00:47:41.060
MICHAEL SKOLNIK: --called
google.com, I'd Google what?

00:47:41.060 --> 00:47:42.101
KIMBERLY PAPILLON: Right.

00:47:42.101 --> 00:47:45.990
So you go implicit-association
tests or IAT Harvard.

00:47:45.990 --> 00:47:48.680
Harvard wants to make sure
they get their name in there.

00:47:48.680 --> 00:47:50.204
All right, so
either one of those.

00:47:50.204 --> 00:47:52.620
And then you go on, and you
can go ahead and take the test

00:47:52.620 --> 00:47:55.260
and take multiple tests.

00:47:55.260 --> 00:47:57.600
Take the sexual
orientation test.

00:47:57.600 --> 00:47:59.550
Take the weight test.

00:47:59.550 --> 00:48:01.260
Take the religion test.

00:48:01.260 --> 00:48:03.810
Take the gender-science test.

00:48:03.810 --> 00:48:07.290
Do we have a difficulty with
matching up the idea of woman

00:48:07.290 --> 00:48:08.500
with the hard sciences?

00:48:08.500 --> 00:48:09.450
So take those tests.

00:48:09.450 --> 00:48:11.280
There's a gender
career test as well.

00:48:11.280 --> 00:48:14.850
Do female in career not match
as well as male and career?

00:48:14.850 --> 00:48:16.060
Those conversations.

00:48:16.060 --> 00:48:17.850
So those are great
tests to take.

00:48:17.850 --> 00:48:20.670
Then how can I
actually look through

00:48:20.670 --> 00:48:22.800
and monitor my own behavior?

00:48:22.800 --> 00:48:23.820
Is there a template?

00:48:23.820 --> 00:48:26.236
We don't necessarily want
people to start creating scripts

00:48:26.236 --> 00:48:29.220
because that doesn't go for
the flow of the workplace.

00:48:29.220 --> 00:48:32.220
But recognize that we might
look at people differently.

00:48:32.220 --> 00:48:34.140
And a good way to bring
them into the circle

00:48:34.140 --> 00:48:36.680
is to do what we call
making them our Bob.

00:48:36.680 --> 00:48:38.354
It's a study called Bob and Jim.

00:48:38.354 --> 00:48:40.020
So they're going to
bring you in a room.

00:48:40.020 --> 00:48:42.260
Call your lawyer soon as
they bring you in the room

00:48:42.260 --> 00:48:44.550
because that there's-- a
study's about to begin.

00:48:44.550 --> 00:48:47.830
And you're going to need
some forms to be signed off.

00:48:47.830 --> 00:48:49.941
So you walk into the room.

00:48:49.941 --> 00:48:52.190
They're going to give you a
picture of two people, Bob

00:48:52.190 --> 00:48:53.040
and Jim.

00:48:53.040 --> 00:48:54.639
Now Bob and Jim
are both white men.

00:48:54.639 --> 00:48:56.430
Their eyes are equidistant
from the center.

00:48:59.190 --> 00:49:02.040
Their ears are the same
in terms of how close they

00:49:02.040 --> 00:49:03.000
are to the head.

00:49:03.000 --> 00:49:05.610
Their expression is
180 degrees across,

00:49:05.610 --> 00:49:06.990
eyes, all of those things.

00:49:06.990 --> 00:49:08.448
They couldn't be
brothers, but they

00:49:08.448 --> 00:49:10.950
might be cousins, Bob and Jim.

00:49:10.950 --> 00:49:13.614
And they're going to say
underneath the picture of Bob

00:49:13.614 --> 00:49:15.030
and underneath the
picture of Jim,

00:49:15.030 --> 00:49:17.100
they're going to put
some stereotypes for you.

00:49:17.100 --> 00:49:18.683
So underneath the
picture Bob, they're

00:49:18.683 --> 00:49:21.180
going to say Bob is
from the Midwest.

00:49:21.180 --> 00:49:23.190
He's an evangelical Christian.

00:49:23.190 --> 00:49:24.720
He's a registered Republican.

00:49:24.720 --> 00:49:26.674
And he considers himself
to be conservative.

00:49:26.674 --> 00:49:27.840
Got your stereotype for Bob?

00:49:27.840 --> 00:49:28.620
MICHAEL SKOLNIK: Mm-hmm.

00:49:28.620 --> 00:49:30.000
KIMBERLY PAPILLON:
OK, hold onto that.

00:49:30.000 --> 00:49:31.020
Next they've got Jim.

00:49:31.020 --> 00:49:32.850
Jim is from the East Coast.

00:49:32.850 --> 00:49:34.890
He's Christian but not
particularly regular

00:49:34.890 --> 00:49:36.270
in his religious practice.

00:49:36.270 --> 00:49:37.440
He's a registered democrat.

00:49:37.440 --> 00:49:39.570
He considers himself
to be liberal.

00:49:39.570 --> 00:49:41.310
Stereotype for Jim?

00:49:41.310 --> 00:49:43.574
Now they don't care that
they built the stereotypes.

00:49:43.574 --> 00:49:44.990
They care about
what happens next.

00:49:44.990 --> 00:49:47.614
They want you to pick who
you're more like, Bob or Jim.

00:49:47.614 --> 00:49:48.780
Doesn't matter who you pick.

00:49:48.780 --> 00:49:50.780
This is not about being
conservative or liberal.

00:49:50.780 --> 00:49:52.380
It's about who's most like you.

00:49:52.380 --> 00:49:54.870
So let's say I pick Bob.

00:49:54.870 --> 00:49:56.310
Now they're going
to ask me deep,

00:49:56.310 --> 00:49:58.770
meaningful, sociopolitical
questions about Bob,

00:49:58.770 --> 00:50:02.160
like does Bob like Oreo cookies?

00:50:02.160 --> 00:50:04.290
Does Bob do his
laundry once a week?

00:50:04.290 --> 00:50:06.840
Does Bob want to go home to see
his family for Thanksgiving?

00:50:06.840 --> 00:50:08.890
Does Bob like to tell the truth?

00:50:08.890 --> 00:50:11.610
And when they ask me these
questions, they scan my brain.

00:50:11.610 --> 00:50:13.344
And as I think
about and judge Bob,

00:50:13.344 --> 00:50:14.760
they find that a
part of my brain,

00:50:14.760 --> 00:50:16.980
called the ventral
prefrontal cortex, lights up,

00:50:16.980 --> 00:50:21.770
the vmPFC lights up when I
think about and judge Bob.

00:50:21.770 --> 00:50:23.370
Keep me in the
machine another round.

00:50:23.370 --> 00:50:25.672
They say, professor,
oh, now we want

00:50:25.672 --> 00:50:27.630
to ask you the same
questions in the same order

00:50:27.630 --> 00:50:28.980
but this time about Jim.

00:50:28.980 --> 00:50:30.630
Does Jim like Oreo cookies?

00:50:30.630 --> 00:50:31.980
Does he like to tell the truth?

00:50:31.980 --> 00:50:35.520
And they find that my dorsal,
not my ventral, but my dorsal

00:50:35.520 --> 00:50:38.460
medial PFC lights up when I
think about and judge Jim, when

00:50:38.460 --> 00:50:41.640
I assess his habits, when
I predict his preferences,

00:50:41.640 --> 00:50:43.500
when I analyze his character.

00:50:43.500 --> 00:50:46.860
A different part of my anatomy
lights up when I judge Jim,

00:50:46.860 --> 00:50:48.690
the person who I
said is not like me.

00:50:48.690 --> 00:50:50.790
Now if you said Jim
was like you, then

00:50:50.790 --> 00:50:52.440
this reaction would
happen for Bob.

00:50:52.440 --> 00:50:55.021
So once again, it's not
about political proclivity.

00:50:55.021 --> 00:50:56.520
They need a little
more grant money,

00:50:56.520 --> 00:50:58.620
so they keep it in the
machine one more time.

00:50:58.620 --> 00:50:59.430
And they say,
they're going to ask

00:50:59.430 --> 00:51:01.054
me the same questions
in the same order

00:51:01.054 --> 00:51:02.200
but this time about myself.

00:51:02.200 --> 00:51:03.540
Do I like Oreo cookies?

00:51:03.540 --> 00:51:05.310
Do I like to tell the truth?

00:51:05.310 --> 00:51:06.900
And they find that
my ventral, not

00:51:06.900 --> 00:51:09.450
my dorsal, but my
ventromedial PFC,

00:51:09.450 --> 00:51:11.280
the same part of the
brain that lit up

00:51:11.280 --> 00:51:13.380
for the person who was
like me, lights up when

00:51:13.380 --> 00:51:16.160
I think about and judge myself.

00:51:16.160 --> 00:51:18.075
Have you ever made a mistake?

00:51:18.075 --> 00:51:19.200
Don't answer that question.

00:51:19.200 --> 00:51:22.110
When you make mistakes, do you
look in the mirror and say,

00:51:22.110 --> 00:51:24.230
I am evil to the core.

00:51:24.230 --> 00:51:25.460
I am beyond redemption.

00:51:25.460 --> 00:51:28.980
There is no state or county
program that can help me now.

00:51:28.980 --> 00:51:32.280
No, you look in the mirror
you say, if I had more time,

00:51:32.280 --> 00:51:34.130
I would have done a better job--

00:51:34.130 --> 00:51:36.759
more resources, more
training, more support.

00:51:36.759 --> 00:51:39.050
If the person had gotten this
project before me had not

00:51:39.050 --> 00:51:41.600
completely messed it up
before they put it on my desk,

00:51:41.600 --> 00:51:43.010
I would have done a better job.

00:51:43.010 --> 00:51:44.210
That's the Bob reaction.

00:51:44.210 --> 00:51:45.770
That's the ventral
medial prefrontal

00:51:45.770 --> 00:51:48.080
cortex working to
let us give ourselves

00:51:48.080 --> 00:51:49.370
the benefit of the doubt.

00:51:49.370 --> 00:51:52.760
And we lend it to our
Bobs and not to our Jims.

00:51:52.760 --> 00:51:55.100
So one of the next parts
in the solution set

00:51:55.100 --> 00:51:59.660
is to make people our Bobs,
to connect to people so that--

00:51:59.660 --> 00:52:01.286
they may never get
to our original Bob.

00:52:01.286 --> 00:52:03.076
But we will feel like
they're more like us.

00:52:03.076 --> 00:52:04.700
And then we will
be more comfortable

00:52:04.700 --> 00:52:06.340
having the
conversations with them.

00:52:06.340 --> 00:52:08.090
And there's a lot of
things to bring out--

00:52:08.090 --> 00:52:11.060
in quick conversations, you
can create some small amount

00:52:11.060 --> 00:52:14.270
of Bob reaction-- dog
versus cat people, team

00:52:14.270 --> 00:52:17.480
that you like, sports team
that you like, hometown.

00:52:17.480 --> 00:52:18.830
Things like that kick in.

00:52:18.830 --> 00:52:21.950
But for long-term relationships,
integrated relationships,

00:52:21.950 --> 00:52:24.080
where you're able to
talk to people on the VC

00:52:24.080 --> 00:52:26.660
over and over again, you
can build even more detail

00:52:26.660 --> 00:52:29.160
into that Bob template
so that people,

00:52:29.160 --> 00:52:32.840
you're seeing them as more,
quote unquote, like you.

00:52:32.840 --> 00:52:36.830
And you remove this notion
of who's good and who's bad.

00:52:36.830 --> 00:52:39.925
Can I tell you one more
solution to match with--

00:52:39.925 --> 00:52:40.970
this one I love.

00:52:40.970 --> 00:52:43.040
They take a group of
people, and they give them

00:52:43.040 --> 00:52:45.850
the IAT, a bias-related
test, ahead of time.

00:52:45.850 --> 00:52:48.170
Then they have them
play flag football.

00:52:48.170 --> 00:52:50.180
Then they give them
the IAT afterwards.

00:52:50.180 --> 00:52:53.180
And their race level
of bias goes down.

00:52:53.180 --> 00:52:54.920
So what did they do?

00:52:54.920 --> 00:52:56.930
What they did is they
had team A and team

00:52:56.930 --> 00:52:59.330
B, two different ethnic groups.

00:52:59.330 --> 00:53:02.951
And they took a person who was
A and made them play on team B.

00:53:02.951 --> 00:53:05.450
Now that person has to cooperate
and collaborate with people

00:53:05.450 --> 00:53:09.350
who are like them and
compete against people

00:53:09.350 --> 00:53:10.594
who are like them.

00:53:10.594 --> 00:53:12.260
So cooperate and
collaborate with people

00:53:12.260 --> 00:53:14.260
who are not like them and
compete against people

00:53:14.260 --> 00:53:15.920
who are like them.

00:53:15.920 --> 00:53:17.210
Now what happens?

00:53:17.210 --> 00:53:20.450
They begin to remove that
line between what's us

00:53:20.450 --> 00:53:21.284
and what's them.

00:53:21.284 --> 00:53:22.700
They don't lose
their appreciation

00:53:22.700 --> 00:53:25.080
for their original
teammate, their culture,

00:53:25.080 --> 00:53:28.940
their background, their history,
but they add on a new team.

00:53:28.940 --> 00:53:30.920
This is my team, too.

00:53:30.920 --> 00:53:35.090
And that creates a different
notion of me versus them,

00:53:35.090 --> 00:53:37.920
us versus them, and it brings
down your level of bias.

00:53:37.920 --> 00:53:39.920
Now that means that
you'd have to be

00:53:39.920 --> 00:53:42.640
the only person
on that team that

00:53:42.640 --> 00:53:44.540
has that particular identity.

00:53:44.540 --> 00:53:46.310
It's not a bad exercise.

00:53:46.310 --> 00:53:49.210
It's not a bad thing to do in
a virtual reality environment.

00:53:49.210 --> 00:53:52.275
It's not a bad thing to do
in an actual play session

00:53:52.275 --> 00:53:53.900
that you would be
able to put together.

00:53:53.900 --> 00:53:55.566
But that team building
stuff that people

00:53:55.566 --> 00:53:59.270
think is so touchy-feely,
if it's mechanized

00:53:59.270 --> 00:54:01.670
so that it begins
to affect the brain

00:54:01.670 --> 00:54:04.340
and that these neural
reactions, then we can actually

00:54:04.340 --> 00:54:07.850
create a different notion
of who's us, who's them,

00:54:07.850 --> 00:54:09.650
and then we start to
treat people the way

00:54:09.650 --> 00:54:12.090
we would want to be
treated as opposed to gosh,

00:54:12.090 --> 00:54:14.450
you seem so interesting.

00:54:14.450 --> 00:54:16.042
Can I touch your hair?

00:54:16.042 --> 00:54:18.760
MICHAEL SKOLNIK: I think we
have a question from Dory.

00:54:18.760 --> 00:54:19.380
Fabiola?

00:54:19.380 --> 00:54:19.970
Is that where you're going?

00:54:19.970 --> 00:54:21.540
FABIOLA STOKES: Yes,
that's where we're going.

00:54:21.540 --> 00:54:22.280
MICHAEL SKOLNIK: Going to Dory.

00:54:22.280 --> 00:54:23.090
FABIOLA STOKES:
Lots of great tips.

00:54:23.090 --> 00:54:24.710
And we're going to take a couple
of questions from the Dory.

00:54:24.710 --> 00:54:25.970
So the first of these is--

00:54:25.970 --> 00:54:27.050
MICHAEL SKOLNIK: The Dory,
by the way, just so you know,

00:54:27.050 --> 00:54:29.600
is folks around the country and
the world can ask a question

00:54:29.600 --> 00:54:30.308
into [INAUDIBLE].

00:54:30.308 --> 00:54:32.744
KIMBERLY PAPILLON: So
we'll look at the--

00:54:32.744 --> 00:54:34.160
FABIOLA STOKES:
The first of these

00:54:34.160 --> 00:54:37.700
is can you suggest
tactful ways to respond

00:54:37.700 --> 00:54:40.970
to microaggressions
that are in the spirit

00:54:40.970 --> 00:54:41.970
of a teachable moment?

00:54:41.970 --> 00:54:43.469
So with the goal
of helping a person

00:54:43.469 --> 00:54:46.070
understand that they're
making a microaggression

00:54:46.070 --> 00:54:49.565
and why they should not
perhaps do that in the future

00:54:49.565 --> 00:54:51.350
or how they can
change their behavior.

00:54:51.350 --> 00:54:53.360
KIMBERLY PAPILLON:
That is best done

00:54:53.360 --> 00:54:57.770
in an environment where people
are speaking the same language.

00:54:57.770 --> 00:54:59.720
So the nomenclature,
microaggression,

00:54:59.720 --> 00:55:03.050
if everyone knows what that
means and everybody knows what

00:55:03.050 --> 00:55:05.240
implicit bias or
implicit association

00:55:05.240 --> 00:55:08.810
is and people know that this
is an unconscious process,

00:55:08.810 --> 00:55:10.956
then when someone engages
in a microaggression,

00:55:10.956 --> 00:55:13.580
you can say, now that might have
been a little microaggressive,

00:55:13.580 --> 00:55:14.788
and I know you did need that.

00:55:14.788 --> 00:55:17.281
Allow me to share
something with you.

00:55:17.281 --> 00:55:19.280
You can't do that in an
environment where people

00:55:19.280 --> 00:55:21.613
aren't speaking that same
language because all they hear

00:55:21.613 --> 00:55:23.450
is you're calling me an -ist--

00:55:23.450 --> 00:55:25.910
sexist, racist, ageist.

00:55:25.910 --> 00:55:28.190
So that's not the
conversation we're having.

00:55:28.190 --> 00:55:30.810
We're having a conversation
about unconscious thoughts.

00:55:30.810 --> 00:55:34.790
So getting everyone onboard,
having everyone not just

00:55:34.790 --> 00:55:36.290
learning about it
in the surface way

00:55:36.290 --> 00:55:38.084
but have it become
part of the dialogue.

00:55:38.084 --> 00:55:40.000
And that's the feedback
that I get back a lot.

00:55:40.000 --> 00:55:43.100
If I teach a group repeatedly
and with other individuals

00:55:43.100 --> 00:55:46.010
as well who go back and
teach groups repeatedly,

00:55:46.010 --> 00:55:49.640
they find that they get feedback
that a couple of months later,

00:55:49.640 --> 00:55:52.140
the conversation in their
meetings has changed.

00:55:52.140 --> 00:55:54.560
They are more comfortable
saying, now hold on a second,

00:55:54.560 --> 00:55:57.160
was that a gender interruption?

00:55:57.160 --> 00:55:58.822
That happens inside
of the meeting.

00:55:58.822 --> 00:55:59.780
Let's think about that.

00:55:59.780 --> 00:56:01.460
Was there some
implicit association

00:56:01.460 --> 00:56:04.850
there in our assumption of
who was more or less qualified

00:56:04.850 --> 00:56:06.470
as they're making
hiring decisions?

00:56:06.470 --> 00:56:08.570
And it doesn't feel
like an indictment.

00:56:08.570 --> 00:56:10.400
It feels like, OK,
we're just including

00:56:10.400 --> 00:56:13.700
that in the analytical
process of how we think.

00:56:13.700 --> 00:56:15.670
That's a safe space to be in.

00:56:15.670 --> 00:56:17.800
And what curious
people like at Google

00:56:17.800 --> 00:56:19.600
and intelligent people
who want to engage

00:56:19.600 --> 00:56:22.210
in that analytical process,
adding an additional factor

00:56:22.210 --> 00:56:23.740
shouldn't be scary.

00:56:23.740 --> 00:56:26.300
It should be like, OK, now
we've got more complexity.

00:56:26.300 --> 00:56:29.376
Now we're going to
be more thorough.

00:56:29.376 --> 00:56:31.480
FABIOLA STOKES: Great.

00:56:31.480 --> 00:56:31.980
Great.

00:56:35.100 --> 00:56:39.510
So Michael has sat onstage
with us today as an ally

00:56:39.510 --> 00:56:41.650
and has talked a
lot about his work

00:56:41.650 --> 00:56:43.870
in partnership with a
number of organizations.

00:56:43.870 --> 00:56:45.520
Can you tell us a
little bit about what

00:56:45.520 --> 00:56:47.860
some of the common
misconceptions

00:56:47.860 --> 00:56:50.350
are of allies or
others who really

00:56:50.350 --> 00:56:52.360
want to be helpful as
a part of this dialogue

00:56:52.360 --> 00:56:54.640
and what you wish
they knew to be

00:56:54.640 --> 00:56:57.460
able to mitigate against
potential issues in the future

00:56:57.460 --> 00:57:00.920
and really become great partners
as we work together in that?

00:57:00.920 --> 00:57:03.010
So this is both of you can.

00:57:03.010 --> 00:57:06.690
MICHAEL SKOLNIK: I would
just tell one quick story.

00:57:06.690 --> 00:57:11.860
I teach race to white
teachers of how to teach

00:57:11.860 --> 00:57:13.750
their students about race.

00:57:13.750 --> 00:57:16.600
Most teachers in this
country are white women.

00:57:16.600 --> 00:57:19.395
And many of them teach
children of color.

00:57:19.395 --> 00:57:21.910
And in the moment that
we're able to discuss this

00:57:21.910 --> 00:57:26.695
over some food earlier,
the advents of what you all

00:57:26.695 --> 00:57:30.000
have created, these devices
in everyone's pocket,

00:57:30.000 --> 00:57:32.890
and the communication change
in this country in the past 10

00:57:32.890 --> 00:57:39.340
years has brought the crises
of race in the immediate.

00:57:39.340 --> 00:57:40.964
So a child may come into school.

00:57:40.964 --> 00:57:42.880
And that morning, someone
might have been shot

00:57:42.880 --> 00:57:44.090
in his or her neighborhood.

00:57:44.090 --> 00:57:46.680
And they want to talk about it.

00:57:46.680 --> 00:57:48.490
And teachers are
often unequipped

00:57:48.490 --> 00:57:50.470
to have those kinds
of conversations.

00:57:50.470 --> 00:57:53.269
Or there might be a big
verdict over the weekend

00:57:53.269 --> 00:57:54.060
or a nonindictment.

00:57:54.060 --> 00:57:56.230
And they're having
protests in the streets.

00:57:56.230 --> 00:57:59.530
And the child's parents
might be in the protest,

00:57:59.530 --> 00:58:02.920
during the protest, and
they want to talk about it.

00:58:02.920 --> 00:58:09.130
So one exercise that we
do with white teachers is

00:58:09.130 --> 00:58:14.110
whenever let down
or not been there

00:58:14.110 --> 00:58:17.330
for a young black boy or girl?

00:58:17.330 --> 00:58:19.570
And we're teaching a
school in New York,

00:58:19.570 --> 00:58:20.880
and it's a private school.

00:58:20.880 --> 00:58:22.890
And we bring in teachers
and administrators.

00:58:22.890 --> 00:58:25.630
And people work in the
kitchen and all kinds of us.

00:58:25.630 --> 00:58:28.965
It's a white affinity group.

00:58:28.965 --> 00:58:30.160
And we go around the room.

00:58:30.160 --> 00:58:33.690
Everyone expresses when
they've let down somebody who's

00:58:33.690 --> 00:58:35.590
a young black boy or girl.

00:58:35.590 --> 00:58:37.140
And this one man.

00:58:37.140 --> 00:58:40.900
Who happened to be
in the IT department,

00:58:40.900 --> 00:58:43.930
he says, I hate this question.

00:58:43.930 --> 00:58:45.640
I'm not answering this question.

00:58:45.640 --> 00:58:48.820
This question is bull--

00:58:48.820 --> 00:58:50.090
I said, OK.

00:58:50.090 --> 00:58:50.920
Pass the mic.

00:58:50.920 --> 00:58:53.040
You don't have to
answer the question.

00:58:53.040 --> 00:58:55.630
I'm not racist.

00:58:55.630 --> 00:58:57.880
My partner in my IT
department is black.

00:58:57.880 --> 00:59:00.833
He's my best friend,
and I'm not racist.

00:59:00.833 --> 00:59:02.810
I said, OK, pass the mic.

00:59:02.810 --> 00:59:04.305
Next question.

00:59:04.305 --> 00:59:09.582
Then he starts sobbing like
a child, bawling like a baby.

00:59:09.582 --> 00:59:12.190
I said, what's going on?

00:59:12.190 --> 00:59:17.360
My whole life I've used the
excuse of not being racist.

00:59:17.360 --> 00:59:19.860
And I've never shown
up for young black boys

00:59:19.860 --> 00:59:21.910
and black girls.

00:59:21.910 --> 00:59:24.430
I always thought I
wasn't the problem,

00:59:24.430 --> 00:59:25.923
so I don't have to do the work.

00:59:29.170 --> 00:59:33.655
That moment for me,
as an ally, made

00:59:33.655 --> 00:59:35.890
me want to dig
deeper into the work

00:59:35.890 --> 00:59:38.480
amongst my white peers
and my white colleagues

00:59:38.480 --> 00:59:40.330
and my white family.

00:59:40.330 --> 00:59:46.840
And how do we dig deeper
into the work and show up?

00:59:46.840 --> 00:59:52.060
And so for those who are in
the room today, proud of you

00:59:52.060 --> 00:59:56.080
to come to this because we've
been at many other campuses

00:59:56.080 --> 00:59:58.230
across Google.

00:59:58.230 --> 01:00:01.370
And it's not as racially
diverse as this room, especially

01:00:01.370 --> 01:00:04.180
other topics of conversation.

01:00:04.180 --> 01:00:08.150
But after I'm proud of
you, as your white ally,

01:00:08.150 --> 01:00:12.904
I also challenge you to go back
to your stasis in this building

01:00:12.904 --> 01:00:14.320
and across [INAUDIBLE]
data center

01:00:14.320 --> 01:00:17.530
if you're coming from over there
and talk to white colleagues

01:00:17.530 --> 01:00:21.910
of what you learned today
or why they didn't come.

01:00:21.910 --> 01:00:25.050
Now some may have meetings
or out of town or travelling,

01:00:25.050 --> 01:00:28.590
but some may be down the hallway
or across the hallway having

01:00:28.590 --> 01:00:29.860
lunch.

01:00:29.860 --> 01:00:31.660
And this wasn't for them.

01:00:31.660 --> 01:00:35.540
So those are conversations as
white allies and white people

01:00:35.540 --> 01:00:37.100
we have to have with each other.

01:00:37.100 --> 01:00:41.110
Oftentimes I heard from many
people during the election

01:00:41.110 --> 01:00:44.320
after Trump won the election
that they didn't want

01:00:44.320 --> 01:00:47.540
to go home for Thanksgiving.

01:00:47.540 --> 01:00:49.950
They didn't want to have the
conversation with a family

01:00:49.950 --> 01:00:52.330
member who had voted for Trump.

01:00:52.330 --> 01:00:56.170
But those conversations,
those courageous conversations

01:00:56.170 --> 01:00:58.010
we have had.

01:00:58.010 --> 01:00:59.980
And so for that question,
where that question's

01:00:59.980 --> 01:01:04.600
coming from as an ally,
the first step for me

01:01:04.600 --> 01:01:06.574
is just showing up.

01:01:06.574 --> 01:01:07.990
And for many of
you, this might be

01:01:07.990 --> 01:01:09.070
the first time
you've been involved

01:01:09.070 --> 01:01:10.236
in a conversation like this.

01:01:10.236 --> 01:01:12.490
Or this might be your ten
thousandth conversation.

01:01:12.490 --> 01:01:15.290
But you're here today,
and that matters.

01:01:15.290 --> 01:01:17.140
That matters in this building.

01:01:17.140 --> 01:01:19.930
Folks of color in
this room see you.

01:01:19.930 --> 01:01:22.000
They may not know
you, but they see you.

01:01:22.000 --> 01:01:23.756
They see me.

01:01:23.756 --> 01:01:26.072
They say, OK, maybe
next week when

01:01:26.072 --> 01:01:27.604
I see that person
in the cafeteria,

01:01:27.604 --> 01:01:29.020
I've never met
that person before.

01:01:29.020 --> 01:01:31.103
But I can start a conversation
based on the shared

01:01:31.103 --> 01:01:33.904
experience we all had today.

01:01:33.904 --> 01:01:36.910
KIMBERLY PAPILLON:
That was powerful.

01:01:36.910 --> 01:01:39.400
I often say, the
most difficult people

01:01:39.400 --> 01:01:44.080
to teach fairness to are people
who value fairness the most.

01:01:44.080 --> 01:01:44.830
I'll say it again.

01:01:44.830 --> 01:01:47.250
The most difficult people
to teach fairness to

01:01:47.250 --> 01:01:50.830
are people who value
fairness the most.

01:01:50.830 --> 01:01:53.380
If you really care about
fairness, if you really

01:01:53.380 --> 01:01:56.560
care about equity, these
types of conversations

01:01:56.560 --> 01:01:58.270
can be painful.

01:01:58.270 --> 01:02:00.820
These types of conversations
can be disquieting.

01:02:03.550 --> 01:02:05.500
If we had the
PowerPoint slides up

01:02:05.500 --> 01:02:07.458
and we're going through
each of the studies one

01:02:07.458 --> 01:02:10.030
after the other, somebody proved
to you in a rigorous fashion

01:02:10.030 --> 01:02:11.950
that implicit bias exists
and that it affects

01:02:11.950 --> 01:02:14.650
your everyday decision-making
is not a comfortable place

01:02:14.650 --> 01:02:17.360
to be in if you value fairness.

01:02:17.360 --> 01:02:19.720
And so there is a rebound
effect, this notion of I

01:02:19.720 --> 01:02:22.690
don't want to hear this
because it's painful.

01:02:22.690 --> 01:02:24.310
The reason it's
painful is because I

01:02:24.310 --> 01:02:26.320
value fairness so highly.

01:02:26.320 --> 01:02:30.760
So getting past that notion
of yes, this is uncomfortable.

01:02:30.760 --> 01:02:34.750
But there is such extraordinary
reward in doing the work.

01:02:34.750 --> 01:02:39.370
And it's not what works solely
for the notion of someone else.

01:02:39.370 --> 01:02:43.390
That's what makes it hard,
the notion of someone else.

01:02:43.390 --> 01:02:47.814
It's not the idea of I'm going
to build a home for someone

01:02:47.814 --> 01:02:50.230
else in a completely different
environment in a completely

01:02:50.230 --> 01:02:51.250
different community.

01:02:51.250 --> 01:02:53.384
I'll probably never
drive by this home again.

01:02:53.384 --> 01:02:55.300
It feels good to have
completed this structure

01:02:55.300 --> 01:02:56.080
and help someone.

01:02:56.080 --> 01:02:57.610
But I probably won't
even meet the person

01:02:57.610 --> 01:02:58.651
who moves into that home.

01:02:58.651 --> 01:02:59.410
It's not that.

01:02:59.410 --> 01:03:00.710
It's not that at Google.

01:03:00.710 --> 01:03:03.970
It's the notion of I am going
to change the way that I

01:03:03.970 --> 01:03:05.320
take in information.

01:03:05.320 --> 01:03:08.180
I am going to regain
control of my own brain.

01:03:08.180 --> 01:03:08.710
Why?

01:03:08.710 --> 01:03:11.710
Because I don't want to
undervalue innovation coming

01:03:11.710 --> 01:03:13.360
from one person versus another.

01:03:13.360 --> 01:03:15.640
That affects my ability
to make good judgments

01:03:15.640 --> 01:03:16.840
and good decisions.

01:03:16.840 --> 01:03:18.820
I don't want to skip
over ideas because they

01:03:18.820 --> 01:03:21.610
came from that voice as
opposed to another voice.

01:03:21.610 --> 01:03:24.010
I don't want to discount
talent because the name

01:03:24.010 --> 01:03:27.700
at the top of the email or the
resume wasn't what I expected.

01:03:27.700 --> 01:03:30.310
That actually is not just
affecting the bottom line.

01:03:30.310 --> 01:03:33.639
That's affecting my ability
to do what I want to do.

01:03:33.639 --> 01:03:35.680
And if I want to not just
build a better society,

01:03:35.680 --> 01:03:38.080
but I want to build a
better workplace for me,

01:03:38.080 --> 01:03:40.630
then I want to join
in that process.

01:03:40.630 --> 01:03:43.000
You can have lots
of friends of color.

01:03:43.000 --> 01:03:46.780
We haven't found that having
one or two or even four or five

01:03:46.780 --> 01:03:48.730
friends who are of a
different ethnicity

01:03:48.730 --> 01:03:50.380
lowers your level
of implicit bias.

01:03:50.380 --> 01:03:53.740
What we find is that
we make that person

01:03:53.740 --> 01:03:55.000
feel like they're one of us.

01:03:55.000 --> 01:03:57.770
We do a Bob on them,
which is a good thing.

01:03:57.770 --> 01:04:00.280
But we want to do that
in a more grand sense.

01:04:00.280 --> 01:04:03.850
But if we only do that for a
few people, bring them in, what

01:04:03.850 --> 01:04:06.190
happens is we
maintain our template

01:04:06.190 --> 01:04:09.640
for all of the people, who are
also part of that community.

01:04:09.640 --> 01:04:10.930
We just pull out an exception.

01:04:10.930 --> 01:04:12.304
You've heard
somebody say, you're

01:04:12.304 --> 01:04:14.360
an honorary fill in the blank.

01:04:14.360 --> 01:04:17.020
That means that they
made you one of them

01:04:17.020 --> 01:04:19.526
but forgot to change the
template for what they

01:04:19.526 --> 01:04:20.650
have for the outside group.

01:04:20.650 --> 01:04:23.200
So that is the next step,
bringing everybody in.

01:04:23.200 --> 01:04:25.480
It's the first, or I
should say, third step.

01:04:25.480 --> 01:04:27.926
But that next step is let me
change the template that I

01:04:27.926 --> 01:04:29.050
have for the outside group.

01:04:29.050 --> 01:04:30.340
That requires reading.

01:04:30.340 --> 01:04:31.930
That requires education.

01:04:31.930 --> 01:04:34.915
That requires recognizing that
some of the things that we see,

01:04:34.915 --> 01:04:39.490
be it on the news or reading
the books or seen on television,

01:04:39.490 --> 01:04:42.520
may not be actual
indications of truth.

01:04:42.520 --> 01:04:43.630
MICHAEL SKOLNIK: Two more.

01:04:43.630 --> 01:04:45.488
I want to respect people's time.

01:04:45.488 --> 01:04:46.821
And it's the middle of the week.

01:04:46.821 --> 01:04:51.998
And a courageous
Googler from Atlanta

01:04:51.998 --> 01:04:55.155
has a question somewhere
in the audience?

01:04:55.155 --> 01:04:56.196
Are we to go to the Dory?

01:05:01.334 --> 01:05:02.958
AUDIENCE: I think
you've got an answer.

01:05:02.958 --> 01:05:05.460
MICHAEL SKOLNIK: We
have a woman here.

01:05:05.460 --> 01:05:06.490
Come on up.

01:05:06.490 --> 01:05:09.600
Thank you for your courage.

01:05:09.600 --> 01:05:12.408
AUDIENCE: Thank you.

01:05:12.408 --> 01:05:13.350
Hello.

01:05:13.350 --> 01:05:16.490
So my question is how do
we celebrate differences

01:05:16.490 --> 01:05:23.510
and diversity without creating
microaggressions and things

01:05:23.510 --> 01:05:25.285
like that?

01:05:25.285 --> 01:05:27.826
If I tell someone, oh, your hair
looks nice or something like

01:05:27.826 --> 01:05:31.071
that because it's different
than what my hair is like

01:05:31.071 --> 01:05:33.970
or something, how do we
celebrate those differences

01:05:33.970 --> 01:05:37.400
and have a culture of
celebration of the diversity as

01:05:37.400 --> 01:05:38.900
opposed to microaggressions?

01:05:38.900 --> 01:05:41.390
KIMBERLY PAPILLON:
Great question.

01:05:41.390 --> 01:05:43.920
I think saying,
your hair is nice,

01:05:43.920 --> 01:05:46.610
I like that shirt,
those types of things

01:05:46.610 --> 01:05:49.930
aren't going to be seen
as microaggressions.

01:05:49.930 --> 01:05:51.410
Once again, it's
the can I touch it

01:05:51.410 --> 01:05:54.000
because it's so different as
opposed to I can appreciate it.

01:05:54.000 --> 01:05:57.690
So actually what you said was
a celebration of the diversity.

01:05:57.690 --> 01:06:02.870
And I think number one,
celebrating includes

01:06:02.870 --> 01:06:05.840
recognizing that we get
more and more and more

01:06:05.840 --> 01:06:08.090
information about
various individuals.

01:06:08.090 --> 01:06:10.346
People always use holidays
as a way to celebrate it.

01:06:10.346 --> 01:06:12.470
We're going to do something
on Black History Month.

01:06:12.470 --> 01:06:15.930
But there is a more rigorous
way to go about that.

01:06:15.930 --> 01:06:19.850
Celebrating individuals
who have achieved

01:06:19.850 --> 01:06:22.920
in various areas of
technology and business,

01:06:22.920 --> 01:06:25.160
giving some historical
perspective.

01:06:25.160 --> 01:06:28.490
It is definitely helpful
for managers and supervisors

01:06:28.490 --> 01:06:31.100
to check and see are they
giving kudos all the same level

01:06:31.100 --> 01:06:33.230
to everybody across the board.

01:06:33.230 --> 01:06:35.180
Is everybody getting
the same clapping

01:06:35.180 --> 01:06:36.390
at the end of the meeting?

01:06:36.390 --> 01:06:37.848
Is it being mentioned
when somebody

01:06:37.848 --> 01:06:41.482
does a good job in each and
every respect across the board?

01:06:41.482 --> 01:06:43.940
If we're not going to mention
certain kinds of achievement,

01:06:43.940 --> 01:06:45.590
we should not mention
them for everyone.

01:06:45.590 --> 01:06:47.006
If we're going to
mention them, we

01:06:47.006 --> 01:06:50.540
should mention them for
everyone across the board.

01:06:50.540 --> 01:06:53.240
Celebration doesn't come first.

01:06:53.240 --> 01:06:55.640
Genuine celebration that's
helpful doesn't come first.

01:06:55.640 --> 01:06:59.522
Celebration that's helpful comes
after understanding is in place

01:06:59.522 --> 01:07:00.980
and after the
templates begin to be

01:07:00.980 --> 01:07:05.150
removed because then it truly is
celebration instead of novelty.

01:07:05.150 --> 01:07:06.980
So your question is excellent.

01:07:06.980 --> 01:07:08.882
But we usually start
with celebration.

01:07:08.882 --> 01:07:11.090
I think that that's going
to move into understanding.

01:07:11.090 --> 01:07:12.923
But what we're finding
is that understanding

01:07:12.923 --> 01:07:14.930
needs to come first,
which means we need

01:07:14.930 --> 01:07:16.340
to learn about one another.

01:07:16.340 --> 01:07:18.500
But we also need to
monitor our own behavior.

01:07:18.500 --> 01:07:21.030
I might never know about
people from Brooklyn.

01:07:21.030 --> 01:07:22.610
It may never happen.

01:07:22.610 --> 01:07:25.070
I could still see you as--

01:07:25.070 --> 01:07:26.780
I can encode you as fully human.

01:07:26.780 --> 01:07:29.900
I can take your ideas and
give them value and wait

01:07:29.900 --> 01:07:32.210
across the board
with equity if I

01:07:32.210 --> 01:07:36.710
am able to recognize
that I might have a bias

01:07:36.710 --> 01:07:39.140
and I need to not
morally credential myself

01:07:39.140 --> 01:07:42.500
and I need to recognize
what makes you valuable.

01:07:42.500 --> 01:07:45.170
I don't need to know about
your favorite holiday

01:07:45.170 --> 01:07:46.520
to get that right.

01:07:46.520 --> 01:07:48.230
And if there's a
culture and leadership

01:07:48.230 --> 01:07:49.730
has a culture of
inclusion and says,

01:07:49.730 --> 01:07:52.021
we're going to treat everybody
the same in the meeting.

01:07:52.021 --> 01:07:53.600
I'm going to monitor
this process.

01:07:53.600 --> 01:07:55.190
I'm not necessarily
being punitive.

01:07:55.190 --> 01:07:57.260
I'm saying that this is
important because this

01:07:57.260 --> 01:07:59.660
is what drives innovation.

01:07:59.660 --> 01:08:02.810
This is part of the culture
of this organization,

01:08:02.810 --> 01:08:04.890
that we are about
driving innovation.

01:08:04.890 --> 01:08:07.732
And we cannot have innovation
when people are stagnated.

01:08:07.732 --> 01:08:10.190
And so we've got to make sure
that those meetings have more

01:08:10.190 --> 01:08:12.929
meaning and that we're able to
open them up so that everybody

01:08:12.929 --> 01:08:15.470
who is considered talented, and
assuming you wouldn't be here

01:08:15.470 --> 01:08:17.803
if you weren't talented, so
that everybody is considered

01:08:17.803 --> 01:08:21.240
talented can actually
contribute in a meaningful way.

01:08:21.240 --> 01:08:22.990
MICHAEL SKOLNIK: This
has been incredible.

01:08:22.990 --> 01:08:23.824
You have a question?

01:08:23.824 --> 01:08:25.115
AUDIENCE: I do have a question.

01:08:25.115 --> 01:08:26.479
MICHAEL SKOLNIK: Oh, fantastic.

01:08:26.479 --> 01:08:27.864
Come on up.

01:08:27.864 --> 01:08:31.273
AUDIENCE: Thanks.

01:08:31.273 --> 01:08:32.260
Thank you.

01:08:32.260 --> 01:08:33.760
MICHAEL SKOLNIK:
I like your shoes.

01:08:33.760 --> 01:08:35.987
AUDIENCE: [INAUDIBLE]
by the way.

01:08:35.987 --> 01:08:37.237
MICHAEL SKOLNIK: There you go.

01:08:37.237 --> 01:08:40.099
AUDIENCE: They're comfortable.

01:08:40.099 --> 01:08:43.250
So we're talking about
celebration oftentimes comes

01:08:43.250 --> 01:08:44.979
first.

01:08:44.979 --> 01:08:48.050
I wonder sometimes, do
we have to care first?

01:08:48.050 --> 01:08:51.560
Because I feel like when I
look out in the audience,

01:08:51.560 --> 01:08:54.620
I'm preaching to the
choir at a point.

01:08:54.620 --> 01:08:57.590
And sometimes I
struggle with how do we

01:08:57.590 --> 01:08:58.670
expand the conversation?

01:08:58.670 --> 01:09:00.339
But I don't think
we can really, truly

01:09:00.339 --> 01:09:02.569
do that if people don't care.

01:09:02.569 --> 01:09:07.025
So how we get people
to care a bit deeper?

01:09:07.025 --> 01:09:08.390
Number one just for this group.

01:09:08.390 --> 01:09:10.056
And then I'm also
wondering, [INAUDIBLE]

01:09:10.056 --> 01:09:11.566
spend time with judges?

01:09:11.566 --> 01:09:13.149
And you talked about
those four things

01:09:13.149 --> 01:09:17.760
I can't remember-- competent,
nice, and et cetera.

01:09:17.760 --> 01:09:19.500
And it has to do
with whether or not

01:09:19.500 --> 01:09:22.459
they care about people and
how it might impact synthesis

01:09:22.459 --> 01:09:24.370
and things like that.

01:09:24.370 --> 01:09:26.840
I'm just curious to know
where does caring come

01:09:26.840 --> 01:09:30.340
into the picture, if at all.

01:09:30.340 --> 01:09:33.380
KIMBERLY PAPILLON: We think
caring is linked primarily

01:09:33.380 --> 01:09:36.029
to the notion of empathy
and helping behavior.

01:09:36.029 --> 01:09:37.819
And I like to also
think that empathy

01:09:37.819 --> 01:09:39.640
comes after understanding.

01:09:39.640 --> 01:09:42.979
So there is a
pain-empathy reaction

01:09:42.979 --> 01:09:46.890
called corticospinal inhibition,
corticospinal inhibition.

01:09:46.890 --> 01:09:49.310
When you get hurt,
a numbing sensation

01:09:49.310 --> 01:09:51.020
runs down to that
area that got hurt.

01:09:51.020 --> 01:09:53.000
You don't think that it
does, but if it does.

01:09:53.000 --> 01:09:55.670
Otherwise it would
hurt much more.

01:09:55.670 --> 01:09:59.850
But if I see somebody who
I care about get hurt,

01:09:59.850 --> 01:10:01.290
I don't get the pain reaction.

01:10:01.290 --> 01:10:02.900
But I get the same
numbing sensation

01:10:02.900 --> 01:10:05.510
to that part of the body
where they were injured.

01:10:05.510 --> 01:10:07.070
And sometimes you can feel it.

01:10:07.070 --> 01:10:10.970
You get a tingle up your
spine in a horror movie.

01:10:10.970 --> 01:10:13.190
Or you see a child fall
down and hurt their knee,

01:10:13.190 --> 01:10:15.080
and you grab your
knee and say, ouch.

01:10:15.080 --> 01:10:16.936
That must have hurt,
those kinds of things.

01:10:16.936 --> 01:10:18.560
So what we're finding
is that if people

01:10:18.560 --> 01:10:20.690
are looking at
hand that does not

01:10:20.690 --> 01:10:23.150
appear to look like
their own and we

01:10:23.150 --> 01:10:26.240
poke that hand with
a hypodermic needle,

01:10:26.240 --> 01:10:29.750
they're having a cortical spinal
inhibition for the hand that

01:10:29.750 --> 01:10:32.150
looks like they're own, a
pain-empathy, physiologic

01:10:32.150 --> 01:10:35.510
reaction we can measure, a
lack of one for the hand that

01:10:35.510 --> 01:10:38.390
doesn't look like theirs,
and a little bit of pain

01:10:38.390 --> 01:10:40.640
reaction among those who
are considered Caucasian

01:10:40.640 --> 01:10:41.810
in the United States
were finding they have

01:10:41.810 --> 01:10:44.434
a little bit of a pain reaction
for the purple hand, the Barney

01:10:44.434 --> 01:10:45.440
hand we like to call it.

01:10:45.440 --> 01:10:47.750
That needs to be studied
more, the Barney phenomenon.

01:10:47.750 --> 01:10:50.630
We're working on that one.

01:10:50.630 --> 01:10:53.330
But what's interesting
is that if we can create

01:10:53.330 --> 01:10:56.570
an empathetic reaction
for other individuals,

01:10:56.570 --> 01:10:58.970
then we can increase the caring.

01:10:58.970 --> 01:11:01.850
And what they found was if
they put somebody's hand

01:11:01.850 --> 01:11:05.900
behind a little curtain and
they put a little monitor

01:11:05.900 --> 01:11:08.300
right above the hand,
and they show you

01:11:08.300 --> 01:11:10.460
a picture of a hand that
doesn't look like yours--

01:11:10.460 --> 01:11:12.980
different skin color--
and they slowly

01:11:12.980 --> 01:11:16.110
brush on the top of that hand
in the movie or in the film,

01:11:16.110 --> 01:11:18.742
slowly brush it back and
forth on the top with a brush.

01:11:18.742 --> 01:11:20.450
And then your hand is
behind the curtain.

01:11:20.450 --> 01:11:22.100
And somebody does
the same thing to you

01:11:22.100 --> 01:11:24.470
in exactly the same
rhythm with a brush.

01:11:24.470 --> 01:11:26.780
You begin to lower your
level of implicit bias.

01:11:26.780 --> 01:11:32.000
You begin to take on the notion
of oh, that's like my own hand.

01:11:32.000 --> 01:11:34.012
It changes that neuroreaction.

01:11:34.012 --> 01:11:35.720
So it's different from
just saying I want

01:11:35.720 --> 01:11:37.400
to walk in someone's shoes.

01:11:37.400 --> 01:11:39.590
It's saying, I'm going
to figure out what

01:11:39.590 --> 01:11:41.630
it would be like to be them.

01:11:41.630 --> 01:11:44.390
I'm going to imagine what
it would be like to be them.

01:11:44.390 --> 01:11:46.340
And that builds the
caring and the empathy.

01:11:46.340 --> 01:11:48.920
But I can't make
that decision to make

01:11:48.920 --> 01:11:51.499
that notion of figuring out what
it would be like to be them.

01:11:51.499 --> 01:11:53.540
I'm not going to make that
decision until I first

01:11:53.540 --> 01:11:57.050
have understanding that I need
to do that because people want

01:11:57.050 --> 01:11:58.670
to talk a lot
about the solutions

01:11:58.670 --> 01:12:00.920
you all have done a great
job here because you've

01:12:00.920 --> 01:12:02.600
been willing to
identify the problems

01:12:02.600 --> 01:12:04.190
and the challenges first.

01:12:04.190 --> 01:12:07.130
Giving people solutions that
they don't think they need

01:12:07.130 --> 01:12:08.630
doesn't make much difference.

01:12:08.630 --> 01:12:11.690
Defining that there might be a
need first in convincing people

01:12:11.690 --> 01:12:13.940
is essential to
the conversation.

01:12:13.940 --> 01:12:17.300
You all have done, I want to
say, an excellent job of really

01:12:17.300 --> 01:12:20.360
working on these pieces of the
puzzle, not just in this one,

01:12:20.360 --> 01:12:22.010
but in all these conversations.

01:12:22.010 --> 01:12:24.860
It's a courageous thing to do.

01:12:24.860 --> 01:12:28.040
Google's best place to
also put things into action

01:12:28.040 --> 01:12:30.620
beyond the conversation.

01:12:30.620 --> 01:12:33.230
Bravo for this dialogue.

01:12:33.230 --> 01:12:35.540
What could be better
as an initial step?

01:12:35.540 --> 01:12:38.540
But the technology that
can be utilized and honed

01:12:38.540 --> 01:12:41.870
to change things, the access
to individuals out there

01:12:41.870 --> 01:12:45.050
in the great beyond who can
see various images, that's

01:12:45.050 --> 01:12:46.940
extraordinary power.

01:12:46.940 --> 01:12:49.930
And what better place than
this to have that happen.

01:12:49.930 --> 01:12:56.052
MICHAEL SKOLNIK: So I
would say, in closing,

01:12:56.052 --> 01:13:00.350
I often find myself
preaching to the choir.

01:13:00.350 --> 01:13:04.430
But I also know that
the choir has to be fed.

01:13:04.430 --> 01:13:14.430
And I hope, we hope, that this
session gave us some good food,

01:13:14.430 --> 01:13:19.196
some vegan treats,
healthy snacks because you

01:13:19.196 --> 01:13:24.920
do have 20% that as
Kimberly alludes to,

01:13:24.920 --> 01:13:26.970
I have no idea who
is in this room.

01:13:26.970 --> 01:13:30.850
I have no idea who is
watching across the world.

01:13:30.850 --> 01:13:34.970
But I do not go on
Google 47 times a day.

01:13:34.970 --> 01:13:40.430
So whatever you all have
created as a user is working.

01:13:40.430 --> 01:13:44.690
And you have in genius and
innovation and disruption

01:13:44.690 --> 01:13:48.230
in this company that
allows you to take that 20%

01:13:48.230 --> 01:13:50.510
and do what you
wish with that time.

01:13:50.510 --> 01:13:54.400
And someone in this room could
be fed from this conversation

01:13:54.400 --> 01:13:57.270
to then go create something
that could change the trajectory

01:13:57.270 --> 01:13:58.380
of my child's life.

01:13:58.380 --> 01:13:59.740
That's real talk.

01:13:59.740 --> 01:14:02.670
That's not hyperbole.

01:14:02.670 --> 01:14:06.530
My child goes to the TV screen
and does this on the TV screen

01:14:06.530 --> 01:14:09.750
thinking it's his device
from another company

01:14:09.750 --> 01:14:11.286
that you do this with.

01:14:11.286 --> 01:14:13.120
[INAUDIBLE] imagine.

01:14:13.120 --> 01:14:14.290
But he's four.

01:14:14.290 --> 01:14:16.800
And he thinks this is how
you turn on a television.

01:14:16.800 --> 01:14:20.690
So already technology
is implanted in his head

01:14:20.690 --> 01:14:21.820
how things work.

01:14:21.820 --> 01:14:25.430
And you are creating that
technology to change his life.

01:14:25.430 --> 01:14:28.290
So thank you to Google
for this conversation.

01:14:28.290 --> 01:14:30.920
But most importantly,
thank you to Kimberly

01:14:30.920 --> 01:14:34.250
for coming across the country
and joining us and giving us

01:14:34.250 --> 01:14:37.250
that food and that health, that
nourishment that we need so

01:14:37.250 --> 01:14:38.930
desperately during these times.

01:14:38.930 --> 01:14:39.530
Thank you all.

01:14:39.530 --> 01:14:42.880
[APPLAUSE]

