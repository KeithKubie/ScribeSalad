WEBVTT
Kind: captions
Language: en

00:00:02.620 --> 00:00:04.980
we've talked about how you want your

00:00:04.980 --> 00:00:04.990
we've talked about how you want your
 

00:00:04.990 --> 00:00:06.389
we've talked about how you want your
learning algorithm to do well on the

00:00:06.389 --> 00:00:06.399
learning algorithm to do well on the
 

00:00:06.399 --> 00:00:08.430
learning algorithm to do well on the
training set but sometimes you don't

00:00:08.430 --> 00:00:08.440
training set but sometimes you don't
 

00:00:08.440 --> 00:00:11.039
training set but sometimes you don't
actually want to do too well and knowing

00:00:11.039 --> 00:00:11.049
actually want to do too well and knowing
 

00:00:11.049 --> 00:00:13.230
actually want to do too well and knowing
what human level performance is can tell

00:00:13.230 --> 00:00:13.240
what human level performance is can tell
 

00:00:13.240 --> 00:00:15.840
what human level performance is can tell
you exactly how well but not too well

00:00:15.840 --> 00:00:15.850
you exactly how well but not too well
 

00:00:15.850 --> 00:00:17.070
you exactly how well but not too well
you want your algorithm to do on the

00:00:17.070 --> 00:00:17.080
you want your algorithm to do on the
 

00:00:17.080 --> 00:00:19.109
you want your algorithm to do on the
training set let me show you what I mean

00:00:19.109 --> 00:00:19.119
training set let me show you what I mean
 

00:00:19.119 --> 00:00:22.249
training set let me show you what I mean
we've used classification a lot and

00:00:22.249 --> 00:00:22.259
we've used classification a lot and
 

00:00:22.259 --> 00:00:26.130
we've used classification a lot and
given a picture let's say humans have

00:00:26.130 --> 00:00:26.140
given a picture let's say humans have
 

00:00:26.140 --> 00:00:28.230
given a picture let's say humans have
near perfect accuracy so the human level

00:00:28.230 --> 00:00:28.240
near perfect accuracy so the human level
 

00:00:28.240 --> 00:00:33.180
near perfect accuracy so the human level
error is 1% in that case if your

00:00:33.180 --> 00:00:33.190
error is 1% in that case if your
 

00:00:33.190 --> 00:00:35.790
error is 1% in that case if your
learning algorithm achieves 8% training

00:00:35.790 --> 00:00:35.800
learning algorithm achieves 8% training
 

00:00:35.800 --> 00:00:40.410
learning algorithm achieves 8% training
error and 10% def error then maybe you

00:00:40.410 --> 00:00:40.420
error and 10% def error then maybe you
 

00:00:40.420 --> 00:00:43.640
error and 10% def error then maybe you
wanted to do better on the training set

00:00:43.640 --> 00:00:43.650
wanted to do better on the training set
 

00:00:43.650 --> 00:00:46.800
wanted to do better on the training set
so the fact that there's a huge gap

00:00:46.800 --> 00:00:46.810
so the fact that there's a huge gap
 

00:00:46.810 --> 00:00:49.470
so the fact that there's a huge gap
between how well your algorithm does on

00:00:49.470 --> 00:00:49.480
between how well your algorithm does on
 

00:00:49.480 --> 00:00:51.360
between how well your algorithm does on
your training set versus how well humans

00:00:51.360 --> 00:00:51.370
your training set versus how well humans
 

00:00:51.370 --> 00:00:53.670
your training set versus how well humans
do shows that your algorithm isn't even

00:00:53.670 --> 00:00:53.680
do shows that your algorithm isn't even
 

00:00:53.680 --> 00:00:56.460
do shows that your algorithm isn't even
fitting the training set well so in

00:00:56.460 --> 00:00:56.470
fitting the training set well so in
 

00:00:56.470 --> 00:00:58.650
fitting the training set well so in
terms of tools to reduce bias or

00:00:58.650 --> 00:00:58.660
terms of tools to reduce bias or
 

00:00:58.660 --> 00:01:00.900
terms of tools to reduce bias or
variance in this case I would say focus

00:01:00.900 --> 00:01:00.910
variance in this case I would say focus
 

00:01:00.910 --> 00:01:04.530
variance in this case I would say focus
on reducing bias so you want to do

00:01:04.530 --> 00:01:04.540
on reducing bias so you want to do
 

00:01:04.540 --> 00:01:06.240
on reducing bias so you want to do
things like find a training bigger

00:01:06.240 --> 00:01:06.250
things like find a training bigger
 

00:01:06.250 --> 00:01:08.580
things like find a training bigger
neural network or run gradient descent

00:01:08.580 --> 00:01:08.590
neural network or run gradient descent
 

00:01:08.590 --> 00:01:10.889
neural network or run gradient descent
longer just try to do better on the

00:01:10.889 --> 00:01:10.899
longer just try to do better on the
 

00:01:10.899 --> 00:01:13.950
longer just try to do better on the
training set but now let's look at the

00:01:13.950 --> 00:01:13.960
training set but now let's look at the
 

00:01:13.960 --> 00:01:15.989
training set but now let's look at the
same training erin jeff error and

00:01:15.989 --> 00:01:15.999
same training erin jeff error and
 

00:01:15.999 --> 00:01:18.239
same training erin jeff error and
imagine that human level performance was

00:01:18.239 --> 00:01:18.249
imagine that human level performance was
 

00:01:18.249 --> 00:01:20.910
imagine that human level performance was
not 1 percent so miscopied is over but

00:01:20.910 --> 00:01:20.920
not 1 percent so miscopied is over but
 

00:01:20.920 --> 00:01:23.489
not 1 percent so miscopied is over but
you know in a different application or

00:01:23.489 --> 00:01:23.499
you know in a different application or
 

00:01:23.499 --> 00:01:25.739
you know in a different application or
maybe on a different data set let's say

00:01:25.739 --> 00:01:25.749
maybe on a different data set let's say
 

00:01:25.749 --> 00:01:29.489
maybe on a different data set let's say
that human level error is actually 7.5

00:01:29.489 --> 00:01:29.499
that human level error is actually 7.5
 

00:01:29.499 --> 00:01:31.590
that human level error is actually 7.5
percent maybe the images in your data

00:01:31.590 --> 00:01:31.600
percent maybe the images in your data
 

00:01:31.600 --> 00:01:34.080
percent maybe the images in your data
set are so very that even humans can

00:01:34.080 --> 00:01:34.090
set are so very that even humans can
 

00:01:34.090 --> 00:01:36.440
set are so very that even humans can
tell whether there's a cat in this

00:01:36.440 --> 00:01:36.450
tell whether there's a cat in this
 

00:01:36.450 --> 00:01:39.660
tell whether there's a cat in this
picture this is a this example is maybe

00:01:39.660 --> 00:01:39.670
picture this is a this example is maybe
 

00:01:39.670 --> 00:01:41.010
picture this is a this example is maybe
slightly contrived because humans

00:01:41.010 --> 00:01:41.020
slightly contrived because humans
 

00:01:41.020 --> 00:01:42.300
slightly contrived because humans
actually very good at looking at

00:01:42.300 --> 00:01:42.310
actually very good at looking at
 

00:01:42.310 --> 00:01:43.830
actually very good at looking at
pictures and telling there's a cat in it

00:01:43.830 --> 00:01:43.840
pictures and telling there's a cat in it
 

00:01:43.840 --> 00:01:45.959
pictures and telling there's a cat in it
or not but for the sake of this example

00:01:45.959 --> 00:01:45.969
or not but for the sake of this example
 

00:01:45.969 --> 00:01:49.020
or not but for the sake of this example
let's say your data sets images are so

00:01:49.020 --> 00:01:49.030
let's say your data sets images are so
 

00:01:49.030 --> 00:01:51.149
let's say your data sets images are so
very or so low resolution that given

00:01:51.149 --> 00:01:51.159
very or so low resolution that given
 

00:01:51.159 --> 00:01:55.169
very or so low resolution that given
humans get 7.5 percent error in this

00:01:55.169 --> 00:01:55.179
humans get 7.5 percent error in this
 

00:01:55.179 --> 00:01:57.690
humans get 7.5 percent error in this
case even though you're trading error in

00:01:57.690 --> 00:01:57.700
case even though you're trading error in
 

00:01:57.700 --> 00:01:59.399
case even though you're trading error in
dev there are the same as the other

00:01:59.399 --> 00:01:59.409
dev there are the same as the other
 

00:01:59.409 --> 00:02:02.219
dev there are the same as the other
example you see that maybe actually

00:02:02.219 --> 00:02:02.229
example you see that maybe actually
 

00:02:02.229 --> 00:02:03.749
example you see that maybe actually
doing just fine on the training set

00:02:03.749 --> 00:02:03.759
doing just fine on the training set
 

00:02:03.759 --> 00:02:06.719
doing just fine on the training set
doing only a little bit worse than human

00:02:06.719 --> 00:02:06.729
doing only a little bit worse than human
 

00:02:06.729 --> 00:02:09.090
doing only a little bit worse than human
level performance and in this second

00:02:09.090 --> 00:02:09.100
level performance and in this second
 

00:02:09.100 --> 00:02:12.030
level performance and in this second
example you would maybe want to focus on

00:02:12.030 --> 00:02:12.040
example you would maybe want to focus on
 

00:02:12.040 --> 00:02:15.059
example you would maybe want to focus on
reducing this components reducing

00:02:15.059 --> 00:02:15.069
reducing this components reducing
 

00:02:15.069 --> 00:02:16.630
reducing this components reducing
um

00:02:16.630 --> 00:02:16.640
um
 

00:02:16.640 --> 00:02:19.399
um
the variance in your learning algorithm

00:02:19.399 --> 00:02:19.409
the variance in your learning algorithm
 

00:02:19.409 --> 00:02:21.229
the variance in your learning algorithm
so you might try regularization to try

00:02:21.229 --> 00:02:21.239
so you might try regularization to try
 

00:02:21.239 --> 00:02:23.539
so you might try regularization to try
to bring your def error closer to your

00:02:23.539 --> 00:02:23.549
to bring your def error closer to your
 

00:02:23.549 --> 00:02:26.479
to bring your def error closer to your
training error for example so in the

00:02:26.479 --> 00:02:26.489
training error for example so in the
 

00:02:26.489 --> 00:02:29.509
training error for example so in the
earlier courses discussion on bias and

00:02:29.509 --> 00:02:29.519
earlier courses discussion on bias and
 

00:02:29.519 --> 00:02:32.030
earlier courses discussion on bias and
variance we were mainly assuming that

00:02:32.030 --> 00:02:32.040
variance we were mainly assuming that
 

00:02:32.040 --> 00:02:34.819
variance we were mainly assuming that
they were tasks where Bayes error is

00:02:34.819 --> 00:02:34.829
they were tasks where Bayes error is
 

00:02:34.829 --> 00:02:38.000
they were tasks where Bayes error is
nearly zero so to explain what just

00:02:38.000 --> 00:02:38.010
nearly zero so to explain what just
 

00:02:38.010 --> 00:02:40.910
nearly zero so to explain what just
happened here for our CAD classification

00:02:40.910 --> 00:02:40.920
happened here for our CAD classification
 

00:02:40.920 --> 00:02:47.140
happened here for our CAD classification
example think of human level error as a

00:02:47.140 --> 00:02:47.150
example think of human level error as a
 

00:02:47.150 --> 00:02:53.929
example think of human level error as a
proxy or as an estimate for Bayes error

00:02:53.929 --> 00:02:53.939
proxy or as an estimate for Bayes error
 

00:02:53.939 --> 00:02:56.899
proxy or as an estimate for Bayes error
alpha Bayes optimal error and for

00:02:56.899 --> 00:02:56.909
alpha Bayes optimal error and for
 

00:02:56.909 --> 00:02:59.479
alpha Bayes optimal error and for
computer vision tasks this is a pretty

00:02:59.479 --> 00:02:59.489
computer vision tasks this is a pretty
 

00:02:59.489 --> 00:03:01.580
computer vision tasks this is a pretty
reasonable proxy because humans are

00:03:01.580 --> 00:03:01.590
reasonable proxy because humans are
 

00:03:01.590 --> 00:03:03.170
reasonable proxy because humans are
actually very good at computer vision

00:03:03.170 --> 00:03:03.180
actually very good at computer vision
 

00:03:03.180 --> 00:03:06.379
actually very good at computer vision
and so whatever a human can do is maybe

00:03:06.379 --> 00:03:06.389
and so whatever a human can do is maybe
 

00:03:06.389 --> 00:03:09.020
and so whatever a human can do is maybe
not too far from Bayes error by

00:03:09.020 --> 00:03:09.030
not too far from Bayes error by
 

00:03:09.030 --> 00:03:11.149
not too far from Bayes error by
definition human level error is worse

00:03:11.149 --> 00:03:11.159
definition human level error is worse
 

00:03:11.159 --> 00:03:14.420
definition human level error is worse
than Bayes error because nothing can be

00:03:14.420 --> 00:03:14.430
than Bayes error because nothing can be
 

00:03:14.430 --> 00:03:16.399
than Bayes error because nothing can be
better than Bayes error but human level

00:03:16.399 --> 00:03:16.409
better than Bayes error but human level
 

00:03:16.409 --> 00:03:17.929
better than Bayes error but human level
error might not be too far from these

00:03:17.929 --> 00:03:17.939
error might not be too far from these
 

00:03:17.939 --> 00:03:21.379
error might not be too far from these
error so the surprising thing you saw

00:03:21.379 --> 00:03:21.389
error so the surprising thing you saw
 

00:03:21.389 --> 00:03:24.110
error so the surprising thing you saw
here is that depending on what human

00:03:24.110 --> 00:03:24.120
here is that depending on what human
 

00:03:24.120 --> 00:03:26.569
here is that depending on what human
level error is or really this is really

00:03:26.569 --> 00:03:26.579
level error is or really this is really
 

00:03:26.579 --> 00:03:30.199
level error is or really this is really
uh approximately Bayes error also we

00:03:30.199 --> 00:03:30.209
uh approximately Bayes error also we
 

00:03:30.209 --> 00:03:32.179
uh approximately Bayes error also we
assumed it to be but depending on what

00:03:32.179 --> 00:03:32.189
assumed it to be but depending on what
 

00:03:32.189 --> 00:03:36.199
assumed it to be but depending on what
we think is achievable with the same

00:03:36.199 --> 00:03:36.209
we think is achievable with the same
 

00:03:36.209 --> 00:03:40.039
we think is achievable with the same
training error and death error in these

00:03:40.039 --> 00:03:40.049
training error and death error in these
 

00:03:40.049 --> 00:03:42.830
training error and death error in these
two cases we decided to focus on bias

00:03:42.830 --> 00:03:42.840
two cases we decided to focus on bias
 

00:03:42.840 --> 00:03:45.080
two cases we decided to focus on bias
reduction tactics or on variance

00:03:45.080 --> 00:03:45.090
reduction tactics or on variance
 

00:03:45.090 --> 00:03:48.920
reduction tactics or on variance
reduction techniques and what happened

00:03:48.920 --> 00:03:48.930
reduction techniques and what happened
 

00:03:48.930 --> 00:03:51.530
reduction techniques and what happened
is in the example on the Left eight

00:03:51.530 --> 00:03:51.540
is in the example on the Left eight
 

00:03:51.540 --> 00:03:53.749
is in the example on the Left eight
percent training error is really high

00:03:53.749 --> 00:03:53.759
percent training error is really high
 

00:03:53.759 --> 00:03:55.789
percent training error is really high
when you think you could get it down to

00:03:55.789 --> 00:03:55.799
when you think you could get it down to
 

00:03:55.799 --> 00:03:59.089
when you think you could get it down to
one percent and so bias reduction

00:03:59.089 --> 00:03:59.099
one percent and so bias reduction
 

00:03:59.099 --> 00:04:00.770
one percent and so bias reduction
technique could help you do that

00:04:00.770 --> 00:04:00.780
technique could help you do that
 

00:04:00.780 --> 00:04:02.899
technique could help you do that
whereas in the example on the right if

00:04:02.899 --> 00:04:02.909
whereas in the example on the right if
 

00:04:02.909 --> 00:04:06.289
whereas in the example on the right if
you think that Bayes error is 7.5

00:04:06.289 --> 00:04:06.299
you think that Bayes error is 7.5
 

00:04:06.299 --> 00:04:08.780
you think that Bayes error is 7.5
percent and share we're using human

00:04:08.780 --> 00:04:08.790
percent and share we're using human
 

00:04:08.790 --> 00:04:10.729
percent and share we're using human
level error as an estimate or as a proxy

00:04:10.729 --> 00:04:10.739
level error as an estimate or as a proxy
 

00:04:10.739 --> 00:04:13.189
level error as an estimate or as a proxy
for Bayes error do you think that Bayes

00:04:13.189 --> 00:04:13.199
for Bayes error do you think that Bayes
 

00:04:13.199 --> 00:04:15.379
for Bayes error do you think that Bayes
error is close to 7.5% and you know

00:04:15.379 --> 00:04:15.389
error is close to 7.5% and you know
 

00:04:15.389 --> 00:04:16.909
error is close to 7.5% and you know
there's not that much Headroom for

00:04:16.909 --> 00:04:16.919
there's not that much Headroom for
 

00:04:16.919 --> 00:04:19.189
there's not that much Headroom for
reducing your training error further

00:04:19.189 --> 00:04:19.199
reducing your training error further
 

00:04:19.199 --> 00:04:21.560
reducing your training error further
down you don't really want it to be that

00:04:21.560 --> 00:04:21.570
down you don't really want it to be that
 

00:04:21.570 --> 00:04:24.320
down you don't really want it to be that
much better than 7.5% because you can

00:04:24.320 --> 00:04:24.330
much better than 7.5% because you can
 

00:04:24.330 --> 00:04:27.290
much better than 7.5% because you can
achieve that only by maybe song need to

00:04:27.290 --> 00:04:27.300
achieve that only by maybe song need to
 

00:04:27.300 --> 00:04:28.430
achieve that only by maybe song need to
over fit the training

00:04:28.430 --> 00:04:28.440
over fit the training
 

00:04:28.440 --> 00:04:31.630
over fit the training
and instead there's much more room for

00:04:31.630 --> 00:04:31.640
and instead there's much more room for
 

00:04:31.640 --> 00:04:34.970
and instead there's much more room for
improvement in terms of taking this 2%

00:04:34.970 --> 00:04:34.980
improvement in terms of taking this 2%
 

00:04:34.980 --> 00:04:38.450
improvement in terms of taking this 2%
gap and trying to reduce that by using

00:04:38.450 --> 00:04:38.460
gap and trying to reduce that by using
 

00:04:38.460 --> 00:04:40.490
gap and trying to reduce that by using
variance reduction techniques such as

00:04:40.490 --> 00:04:40.500
variance reduction techniques such as
 

00:04:40.500 --> 00:04:42.530
variance reduction techniques such as
regularization or maybe getting more

00:04:42.530 --> 00:04:42.540
regularization or maybe getting more
 

00:04:42.540 --> 00:04:46.070
regularization or maybe getting more
training data so to give these things a

00:04:46.070 --> 00:04:46.080
training data so to give these things a
 

00:04:46.080 --> 00:04:49.220
training data so to give these things a
couple names this is not widely used

00:04:49.220 --> 00:04:49.230
couple names this is not widely used
 

00:04:49.230 --> 00:04:51.830
couple names this is not widely used
terminology but I found this useful -

00:04:51.830 --> 00:04:51.840
terminology but I found this useful -
 

00:04:51.840 --> 00:04:53.780
terminology but I found this useful -
margin useful way of thinking about it

00:04:53.780 --> 00:04:53.790
margin useful way of thinking about it
 

00:04:53.790 --> 00:04:56.000
margin useful way of thinking about it
which is I'm going to call the

00:04:56.000 --> 00:04:56.010
which is I'm going to call the
 

00:04:56.010 --> 00:04:58.250
which is I'm going to call the
difference between Bayes error or

00:04:58.250 --> 00:04:58.260
difference between Bayes error or
 

00:04:58.260 --> 00:05:00.440
difference between Bayes error or
approximation of Bayes error and the

00:05:00.440 --> 00:05:00.450
approximation of Bayes error and the
 

00:05:00.450 --> 00:05:06.610
approximation of Bayes error and the
training error to be the avoidable bias

00:05:06.610 --> 00:05:06.620
 

00:05:06.620 --> 00:05:09.950
so what you want is to maybe keep

00:05:09.950 --> 00:05:09.960
so what you want is to maybe keep
 

00:05:09.960 --> 00:05:11.660
so what you want is to maybe keep
improving your training performance

00:05:11.660 --> 00:05:11.670
improving your training performance
 

00:05:11.670 --> 00:05:13.700
improving your training performance
until you get down to Bayes error but

00:05:13.700 --> 00:05:13.710
until you get down to Bayes error but
 

00:05:13.710 --> 00:05:15.710
until you get down to Bayes error but
you don't actually want to do better

00:05:15.710 --> 00:05:15.720
you don't actually want to do better
 

00:05:15.720 --> 00:05:17.660
you don't actually want to do better
than a zero you can't actually do better

00:05:17.660 --> 00:05:17.670
than a zero you can't actually do better
 

00:05:17.670 --> 00:05:19.490
than a zero you can't actually do better
than Bayes error unless you're

00:05:19.490 --> 00:05:19.500
than Bayes error unless you're
 

00:05:19.500 --> 00:05:22.940
than Bayes error unless you're
overfitting and this the difference

00:05:22.940 --> 00:05:22.950
overfitting and this the difference
 

00:05:22.950 --> 00:05:24.530
overfitting and this the difference
between your training error and def

00:05:24.530 --> 00:05:24.540
between your training error and def
 

00:05:24.540 --> 00:05:27.230
between your training error and def
error that's a measure still of the

00:05:27.230 --> 00:05:27.240
error that's a measure still of the
 

00:05:27.240 --> 00:05:29.620
error that's a measure still of the
variance problem of your algorithm and

00:05:29.620 --> 00:05:29.630
variance problem of your algorithm and
 

00:05:29.630 --> 00:05:33.020
variance problem of your algorithm and
the term avoidable bias acknowledges

00:05:33.020 --> 00:05:33.030
the term avoidable bias acknowledges
 

00:05:33.030 --> 00:05:36.260
the term avoidable bias acknowledges
that there's some bias or some minimum

00:05:36.260 --> 00:05:36.270
that there's some bias or some minimum
 

00:05:36.270 --> 00:05:38.690
that there's some bias or some minimum
level of error that you just cannot get

00:05:38.690 --> 00:05:38.700
level of error that you just cannot get
 

00:05:38.700 --> 00:05:41.930
level of error that you just cannot get
below which is that if Bayes error 7.5

00:05:41.930 --> 00:05:41.940
below which is that if Bayes error 7.5
 

00:05:41.940 --> 00:05:44.390
below which is that if Bayes error 7.5
percent you don't actually want to get

00:05:44.390 --> 00:05:44.400
percent you don't actually want to get
 

00:05:44.400 --> 00:05:47.720
percent you don't actually want to get
below that level of error so rather than

00:05:47.720 --> 00:05:47.730
below that level of error so rather than
 

00:05:47.730 --> 00:05:49.520
below that level of error so rather than
saying that if your training error is 8

00:05:49.520 --> 00:05:49.530
saying that if your training error is 8
 

00:05:49.530 --> 00:05:51.409
saying that if your training error is 8
percent then to 8 percent is a measure

00:05:51.409 --> 00:05:51.419
percent then to 8 percent is a measure
 

00:05:51.419 --> 00:05:54.110
percent then to 8 percent is a measure
Advisors in this example you're saying

00:05:54.110 --> 00:05:54.120
Advisors in this example you're saying
 

00:05:54.120 --> 00:05:59.810
Advisors in this example you're saying
that the avoidable bias is maybe 0.5% or

00:05:59.810 --> 00:05:59.820
that the avoidable bias is maybe 0.5% or
 

00:05:59.820 --> 00:06:02.320
that the avoidable bias is maybe 0.5% or
0.5% is a measure of the avoidable bias

00:06:02.320 --> 00:06:02.330
0.5% is a measure of the avoidable bias
 

00:06:02.330 --> 00:06:05.510
0.5% is a measure of the avoidable bias
whereas 2 percent is a measure of the

00:06:05.510 --> 00:06:05.520
whereas 2 percent is a measure of the
 

00:06:05.520 --> 00:06:07.580
whereas 2 percent is a measure of the
variance and so there's much more room

00:06:07.580 --> 00:06:07.590
variance and so there's much more room
 

00:06:07.590 --> 00:06:09.920
variance and so there's much more room
in reducing this to percents than in

00:06:09.920 --> 00:06:09.930
in reducing this to percents than in
 

00:06:09.930 --> 00:06:12.470
in reducing this to percents than in
reducing to 0.5 percent whereas in

00:06:12.470 --> 00:06:12.480
reducing to 0.5 percent whereas in
 

00:06:12.480 --> 00:06:14.630
reducing to 0.5 percent whereas in
contrast in the example on the left this

00:06:14.630 --> 00:06:14.640
contrast in the example on the left this
 

00:06:14.640 --> 00:06:18.980
contrast in the example on the left this
7 percent is a measure of the avoidable

00:06:18.980 --> 00:06:18.990
7 percent is a measure of the avoidable
 

00:06:18.990 --> 00:06:22.640
7 percent is a measure of the avoidable
buyers whereas 2 percent is a measure of

00:06:22.640 --> 00:06:22.650
buyers whereas 2 percent is a measure of
 

00:06:22.650 --> 00:06:24.800
buyers whereas 2 percent is a measure of
how much variance you have and so in

00:06:24.800 --> 00:06:24.810
how much variance you have and so in
 

00:06:24.810 --> 00:06:26.300
how much variance you have and so in
this example on the Left there's much

00:06:26.300 --> 00:06:26.310
this example on the Left there's much
 

00:06:26.310 --> 00:06:28.970
this example on the Left there's much
more potential in focusing on reducing

00:06:28.970 --> 00:06:28.980
more potential in focusing on reducing
 

00:06:28.980 --> 00:06:32.510
more potential in focusing on reducing
bands of avoidable bias so in this

00:06:32.510 --> 00:06:32.520
bands of avoidable bias so in this
 

00:06:32.520 --> 00:06:35.740
bands of avoidable bias so in this
example understanding human level error

00:06:35.740 --> 00:06:35.750
example understanding human level error
 

00:06:35.750 --> 00:06:37.969
example understanding human level error
understanding your estimate of Bayes are

00:06:37.969 --> 00:06:37.979
understanding your estimate of Bayes are
 

00:06:37.979 --> 00:06:39.830
understanding your estimate of Bayes are
already causes you in different

00:06:39.830 --> 00:06:39.840
already causes you in different
 

00:06:39.840 --> 00:06:41.010
already causes you in different
scenarios to go

00:06:41.010 --> 00:06:41.020
scenarios to go
 

00:06:41.020 --> 00:06:42.630
scenarios to go
on different tactics with a bias

00:06:42.630 --> 00:06:42.640
on different tactics with a bias
 

00:06:42.640 --> 00:06:45.000
on different tactics with a bias
avoidance tactic reverance avoidance

00:06:45.000 --> 00:06:45.010
avoidance tactic reverance avoidance
 

00:06:45.010 --> 00:06:47.220
avoidance tactic reverance avoidance
tactics there's quite a lot more nuance

00:06:47.220 --> 00:06:47.230
tactics there's quite a lot more nuance
 

00:06:47.230 --> 00:06:49.470
tactics there's quite a lot more nuance
how you factor in human level

00:06:49.470 --> 00:06:49.480
how you factor in human level
 

00:06:49.480 --> 00:06:50.850
how you factor in human level
performance into how you make decisions

00:06:50.850 --> 00:06:50.860
performance into how you make decisions
 

00:06:50.860 --> 00:06:54.360
performance into how you make decisions
in choosing what to focus on less in the

00:06:54.360 --> 00:06:54.370
in choosing what to focus on less in the
 

00:06:54.370 --> 00:06:55.950
in choosing what to focus on less in the
next video go deeper into understanding

00:06:55.950 --> 00:06:55.960
next video go deeper into understanding
 

00:06:55.960 --> 00:06:58.650
next video go deeper into understanding
of what human level performance really

00:06:58.650 --> 00:06:58.660
of what human level performance really
 

00:06:58.660 --> 00:07:00.990
of what human level performance really
means

