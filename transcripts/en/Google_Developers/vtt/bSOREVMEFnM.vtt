WEBVTT
Kind: captions
Language: en

00:00:02.970 --> 00:00:05.400
Memory churn is a constant
and serious problem

00:00:05.400 --> 00:00:07.360
for the performance
of your applications.

00:00:07.360 --> 00:00:09.250
Allocating loads of
temporary objects

00:00:09.250 --> 00:00:11.130
in a short period
of time puts a ton

00:00:11.130 --> 00:00:12.550
of pressure on
your memory heaps,

00:00:12.550 --> 00:00:15.270
resulting in more GC
events being kicked off.

00:00:15.270 --> 00:00:16.340
My name is Colt McAnlis.

00:00:16.340 --> 00:00:18.339
And rather than promoting
a bulk of your objects

00:00:18.339 --> 00:00:20.710
to static in order to solve
the memory churn problems,

00:00:20.710 --> 00:00:23.110
you can utilize an amazingly
powerful data structure

00:00:23.110 --> 00:00:24.876
known as an object pool.

00:00:24.876 --> 00:00:27.250
Typically, memory churn comes
from creating a whole group

00:00:27.250 --> 00:00:31.680
of temporarily resident objects,
like images, or views, paint

00:00:31.680 --> 00:00:33.450
objects, and even threads.

00:00:33.450 --> 00:00:36.000
They repeatedly get created,
exist for a little while,

00:00:36.000 --> 00:00:37.270
and then are freed.

00:00:37.270 --> 00:00:39.176
This action ends up
polluting and fragmenting

00:00:39.176 --> 00:00:41.550
the memory heap in a very
short amount of time, resulting

00:00:41.550 --> 00:00:43.779
in more GC events
being kicked off.

00:00:43.779 --> 00:00:45.320
When this happens
on a regular basis,

00:00:45.320 --> 00:00:47.320
you end up getting
a hoard of GC events

00:00:47.320 --> 00:00:49.142
that occur at a great frequency.

00:00:49.142 --> 00:00:51.600
But thankfully, there's a way
to get the same functionality

00:00:51.600 --> 00:00:55.520
of the allocation and freeing of
objects without the GC events,

00:00:55.520 --> 00:00:57.220
and it's called an object pool.

00:00:57.220 --> 00:00:59.190
Effectively, when you're
done with an object,

00:00:59.190 --> 00:01:01.190
rather than freeing it
back to the memory heap,

00:01:01.190 --> 00:01:04.514
you keep a reference to it in
a list of available objects.

00:01:04.514 --> 00:01:05.930
The next time you
need to allocate

00:01:05.930 --> 00:01:09.340
an object of that type, you can
repurpose an existing object

00:01:09.340 --> 00:01:12.100
from the pool rather than
grabbing a brand new one

00:01:12.100 --> 00:01:13.310
from the memory heap.

00:01:13.310 --> 00:01:14.895
Only when your pool
is empty does it

00:01:14.895 --> 00:01:16.270
make sense to go
back to the heap

00:01:16.270 --> 00:01:18.560
to allocate new objects,
which will eventually

00:01:18.560 --> 00:01:20.870
be freed back to
the pool, growing

00:01:20.870 --> 00:01:22.770
its potential size over time.

00:01:22.770 --> 00:01:24.665
The end result of
using an object pool

00:01:24.665 --> 00:01:26.790
is that instead of a
ton of heap fluctuation,

00:01:26.790 --> 00:01:29.510
you'll end up with stable
allocations or small growths

00:01:29.510 --> 00:01:32.060
over time, which, of course,
can lead to less GC events being

00:01:32.060 --> 00:01:35.460
kicked off, helping you
save precious frame time.

00:01:35.460 --> 00:01:37.334
But object pools are
tricky to get right.

00:01:37.334 --> 00:01:39.250
And I have a handful of
implementation caveats

00:01:39.250 --> 00:01:40.790
that you need to watch out for.

00:01:40.790 --> 00:01:43.680
Firstly, remember that there's
an overhead involved each time

00:01:43.680 --> 00:01:46.740
the object pool needs to go back
to the main heap to allocate

00:01:46.740 --> 00:01:47.240
memory.

00:01:47.240 --> 00:01:48.937
Now it may be small,
but it's there,

00:01:48.937 --> 00:01:50.270
and you should watch out for it.

00:01:50.270 --> 00:01:53.320
As such, rather than allocating
an object each time one is

00:01:53.320 --> 00:01:55.420
needed, it makes more
sense to allocate

00:01:55.420 --> 00:01:57.816
a group of free
objects at one time

00:01:57.816 --> 00:01:59.190
so that the overhead
is mitigated

00:01:59.190 --> 00:02:00.650
for future allocations.

00:02:00.650 --> 00:02:03.490
In addition, rather than waiting
for each empty pool request

00:02:03.490 --> 00:02:07.130
to make a new heap allocation,
instead fill your pool

00:02:07.130 --> 00:02:08.762
with objects at
application load time

00:02:08.762 --> 00:02:11.220
so the first group of objects
you're grabbing from the pool

00:02:11.220 --> 00:02:13.000
are as fast as possible.

00:02:13.000 --> 00:02:15.020
With a little statistics
gathering here,

00:02:15.020 --> 00:02:18.340
you could even figure out the
ideal preallocation amount

00:02:18.340 --> 00:02:20.507
so that you can fill
your pool ahead of time,

00:02:20.507 --> 00:02:23.090
minimizing the number of times
you have to go back to the heap

00:02:23.090 --> 00:02:25.070
during the lifetime
of your application.

00:02:25.070 --> 00:02:27.340
However, one of the
downsides of objects pools

00:02:27.340 --> 00:02:30.160
is that now you, the programmer,
are responsible for allocating

00:02:30.160 --> 00:02:34.080
and freeing objects manually
back to the object pool, which

00:02:34.080 --> 00:02:35.880
is a pattern that
very much resembles

00:02:35.880 --> 00:02:37.780
non-garbage collected languages.

00:02:37.780 --> 00:02:40.290
So you might want to limit
the usage of object pools

00:02:40.290 --> 00:02:42.900
to high churn object
sets that demand

00:02:42.900 --> 00:02:44.120
this level of interaction.

00:02:44.120 --> 00:02:45.710
Otherwise, you'd
be wasting a lot

00:02:45.710 --> 00:02:48.720
of features of the Java
garbage collected language.

00:02:48.720 --> 00:02:51.560
And finally, in order to make
sure that all of your objects

00:02:51.560 --> 00:02:53.260
are returned to
the pool properly,

00:02:53.260 --> 00:02:56.230
make sure that member
variables of these objects

00:02:56.230 --> 00:02:58.870
are properly cleaned up
so that it doesn't contain

00:02:58.870 --> 00:03:01.430
any references to any other
objects in memory that

00:03:01.430 --> 00:03:04.651
might be valid for the garbage
collector to clean up later.

00:03:04.651 --> 00:03:06.400
If you're not careful
here, you can end up

00:03:06.400 --> 00:03:08.710
creating a lot of
persistent memory leaks

00:03:08.710 --> 00:03:10.870
for these objects in your pools.

00:03:10.870 --> 00:03:14.220
There's some intuition involved
with finding the right places

00:03:14.220 --> 00:03:15.260
for these object pools.

00:03:15.260 --> 00:03:18.080
But if you're ever in doubt or
looking for new opportunities,

00:03:18.080 --> 00:03:21.330
you can use the allocation
tracker tool in Android Studio

00:03:21.330 --> 00:03:23.420
to identify any
areas where you may

00:03:23.420 --> 00:03:26.450
be seeing a horde of
similar object types coming

00:03:26.450 --> 00:03:30.180
from roughly the same call stack
in a very short period of time.

00:03:30.180 --> 00:03:32.532
This is a classic sign
of memory thrashing

00:03:32.532 --> 00:03:34.240
and easy to see that
it's the right place

00:03:34.240 --> 00:03:36.250
to start with object pools.

00:03:36.250 --> 00:03:38.370
Anyhow, using object
pools are a great way

00:03:38.370 --> 00:03:41.280
to reduce memory churn and
grab back critical performance

00:03:41.280 --> 00:03:42.070
resources.

00:03:42.070 --> 00:03:43.670
But like anything
else, this feature

00:03:43.670 --> 00:03:46.030
comes with a tradeoff
in additional code

00:03:46.030 --> 00:03:47.207
that makes it happen.

00:03:47.207 --> 00:03:49.540
If you're interested in other
tradeoffs for performance,

00:03:49.540 --> 00:03:51.998
make sure you check out the
rest of the Android Performance

00:03:51.998 --> 00:03:54.980
Patterns content and join our
Google+ page for more tips from

00:03:54.980 --> 00:03:56.340
other great developers.

00:03:56.340 --> 00:03:58.560
So keep calm, profile your
code, and always remember

00:03:58.560 --> 00:03:59.160
perf matters.

00:03:59.160 --> 00:04:02.510
[MUSIC PLAYING]

