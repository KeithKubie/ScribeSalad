WEBVTT
Kind: captions
Language: en

00:00:01.600 --> 00:00:02.810
VIVEK KWATRA: Hello everyone.

00:00:02.810 --> 00:00:03.550
I'm Vivek Kwatra.

00:00:03.550 --> 00:00:05.860
I'm a research scientist
at Google.

00:00:05.860 --> 00:00:07.495
I'm joined by my colleagues,
Matthias

00:00:07.495 --> 00:00:10.500
Grundmann and John Gregg.

00:00:10.500 --> 00:00:13.020
Today we will tell you about
the video stabilization

00:00:13.020 --> 00:00:16.520
technology that is available on
YouTube and also give you

00:00:16.520 --> 00:00:19.390
some insights on how it works
and how you can use it to

00:00:19.390 --> 00:00:21.460
improve your videos.

00:00:21.460 --> 00:00:24.410
We'll show you some fun videos
today, but along the way,

00:00:24.410 --> 00:00:26.850
we'll also try to tell you about
the technical details

00:00:26.850 --> 00:00:28.600
behind the algorithms.

00:00:28.600 --> 00:00:31.260
To give you an overview of the
talk, we will start by talking

00:00:31.260 --> 00:00:32.970
about video stabilization.

00:00:32.970 --> 00:00:36.770
Then, we will give you some
information about how we adapt

00:00:36.770 --> 00:00:39.550
that to work for mobile phones,
which have rolling

00:00:39.550 --> 00:00:41.200
shutter cameras.

00:00:41.200 --> 00:00:44.700
We will then take you through
the life of a video as it goes

00:00:44.700 --> 00:00:47.610
through the YouTube
stabilizer.

00:00:47.610 --> 00:00:50.580
And finally, we are announcing
new features in the YouTube

00:00:50.580 --> 00:00:54.555
upload API today that allow you
to apply enhancements to

00:00:54.555 --> 00:00:56.810
your videos programmatically.

00:00:56.810 --> 00:01:01.840
So if you want to find out how
to enhance your videos by

00:01:01.840 --> 00:01:06.060
adding some lines of code to
your programs, then stay to

00:01:06.060 --> 00:01:10.390
the end where we will show
you a demo of that.

00:01:10.390 --> 00:01:13.540
So let me start by showing you
an example of what we call a

00:01:13.540 --> 00:01:14.940
casual video.

00:01:14.940 --> 00:01:18.310
This video here is shot by
somebody running with a camera

00:01:18.310 --> 00:01:20.370
strapped onto their head.

00:01:20.370 --> 00:01:23.100
So it's amazing that we have
cameras which are light enough

00:01:23.100 --> 00:01:25.930
that you can strap them on
your head while running.

00:01:25.930 --> 00:01:28.190
But that does not prevent the
resulting video from giving

00:01:28.190 --> 00:01:31.030
you a headache.

00:01:31.030 --> 00:01:34.110
Thankfully, we have a solution
for that problem.

00:01:34.110 --> 00:01:37.230
So this is the same video after
it has been processed by

00:01:37.230 --> 00:01:38.780
the YouTube stabilizer.

00:01:38.780 --> 00:01:41.430
You'll note that the video is
much less shaky, the camera

00:01:41.430 --> 00:01:43.560
looks much more stable, and
the video is much more

00:01:43.560 --> 00:01:44.810
pleasant to watch.

00:01:46.810 --> 00:01:47.790
Here is the same video.

00:01:47.790 --> 00:01:50.790
We're showing you side by side
with the original on the left

00:01:50.790 --> 00:01:53.770
and the stabilized result
on the right.

00:01:53.770 --> 00:01:56.990
One thing to note here is that
to obtain this result, we only

00:01:56.990 --> 00:01:58.200
look at the pixels
in the video.

00:01:58.200 --> 00:01:59.870
We only analyze the pictures.

00:01:59.870 --> 00:02:01.240
We don't have any information
about the

00:02:01.240 --> 00:02:02.490
camera at this point.

00:02:05.150 --> 00:02:06.710
So how do you do this on
YouTube if you want to

00:02:06.710 --> 00:02:08.940
stabilize your own videos.

00:02:08.940 --> 00:02:12.420
If you go to the Watch page of
one of your own videos, then

00:02:12.420 --> 00:02:14.800
you will see these extra
buttons at the bottom.

00:02:14.800 --> 00:02:18.040
And one of these buttons is the
enhancement button, which

00:02:18.040 --> 00:02:20.480
takes you to the
enhancement UI.

00:02:20.480 --> 00:02:22.620
And here you can apply different
kinds of filters and

00:02:22.620 --> 00:02:24.130
effects to your videos.

00:02:24.130 --> 00:02:25.240
You can apply some
fun effects.

00:02:25.240 --> 00:02:29.240
You can color correct by
applying the art effects.

00:02:29.240 --> 00:02:31.640
And of course, you
can stabilize.

00:02:31.640 --> 00:02:34.640
And once you click on stabilize,
you'll see this

00:02:34.640 --> 00:02:37.580
split screen viewer, which gives
you a comparison between

00:02:37.580 --> 00:02:40.950
the original video and a preview
of the stabilized

00:02:40.950 --> 00:02:44.430
result so you can compare them
and see if you like it.

00:02:44.430 --> 00:02:46.800
Note that at this point the
stabilizer is actually running

00:02:46.800 --> 00:02:49.330
live at the back end and
streaming results to the user

00:02:49.330 --> 00:02:52.020
in real time, which is also why
the preview is run at a

00:02:52.020 --> 00:02:52.960
low resolution.

00:02:52.960 --> 00:02:55.780
The final video is processed at
a much higher resolution.

00:02:55.780 --> 00:02:57.480
And once you are satisfied with
the video, you can go to

00:02:57.480 --> 00:02:59.870
the top right where you
have the Save button.

00:02:59.870 --> 00:03:02.620
You can save it by overriding
the current video ID, or you

00:03:02.620 --> 00:03:05.990
can save it as a copy, which
creates a new video.

00:03:05.990 --> 00:03:09.970
And then the video is processed
for stabilization.

00:03:09.970 --> 00:03:12.860
And then you go to your video
manager or uploads page where

00:03:12.860 --> 00:03:16.400
you'll see a copy of the video
up here where you can play the

00:03:16.400 --> 00:03:19.780
video to see how the stabilized
result looks like.

00:03:19.780 --> 00:03:21.240
So now, we're going to
the watch page of

00:03:21.240 --> 00:03:22.540
the stabilized video.

00:03:22.540 --> 00:03:24.710
You can see the stabilized
video here.

00:03:24.710 --> 00:03:27.310
We're also showing you the
original video in the bottom

00:03:27.310 --> 00:03:30.770
left to compare the shaky result
with what you get after

00:03:30.770 --> 00:03:32.020
stabilization.

00:03:34.680 --> 00:03:38.080
Of course, you can apply this
effect on any video of your

00:03:38.080 --> 00:03:39.290
choice that you have uploaded.

00:03:39.290 --> 00:03:41.980
But we also try to try to help
by offering some suggestions

00:03:41.980 --> 00:03:45.040
when we detect automatically
that the video is shaky.

00:03:45.040 --> 00:03:47.120
So in this case, the blue bar
at the bottom is offering a

00:03:47.120 --> 00:03:49.450
suggestion to the user to
stabilize the video.

00:03:49.450 --> 00:03:51.890
You can click on the Preview
button, which again shows you

00:03:51.890 --> 00:03:55.590
the split screen UI but this
time right on the watch page.

00:03:55.590 --> 00:03:57.860
Again, you can compare
the before and after.

00:03:57.860 --> 00:04:01.510
Note that as a user, you don't
need to fiddle with any

00:04:01.510 --> 00:04:03.890
sliders or tweak
any parameters.

00:04:03.890 --> 00:04:05.860
It's just a one click
stabilization solution.

00:04:05.860 --> 00:04:07.300
You just click stabilize
and you get the result.

00:04:10.420 --> 00:04:13.270
So now that we've shown you some
videos, let's talk about

00:04:13.270 --> 00:04:15.650
how it actually works.

00:04:15.650 --> 00:04:19.300
When talking about
stabilization, one can broadly

00:04:19.300 --> 00:04:22.120
categorize into two
main types.

00:04:22.120 --> 00:04:24.670
You can talk about in-camera
stabilization where you

00:04:24.670 --> 00:04:27.420
perform stabilization on the
device while you are

00:04:27.420 --> 00:04:28.610
capturing the video.

00:04:28.610 --> 00:04:30.870
And when you do that, one issue
is that you're only

00:04:30.870 --> 00:04:33.540
looking at the video as you're
seeing it so far.

00:04:33.540 --> 00:04:35.810
You can't really see what's
going to happen in the future.

00:04:35.810 --> 00:04:38.570
And that limits your ability
to do stabilization.

00:04:38.570 --> 00:04:40.540
Also, you are limited by
the processing power

00:04:40.540 --> 00:04:43.810
of the single device.

00:04:43.810 --> 00:04:46.580
The second approach is what
we call post-process

00:04:46.580 --> 00:04:47.510
stabilization.

00:04:47.510 --> 00:04:50.040
This is where the video is
already captured and encoded,

00:04:50.040 --> 00:04:52.850
and in our case, uploaded
to YouTube.

00:04:52.850 --> 00:04:55.930
And we apply stabilization
after the fact.

00:04:55.930 --> 00:04:59.510
So our stabilization is a
post-process approach.

00:04:59.510 --> 00:05:02.110
And the advantage that we have
here is that since we have the

00:05:02.110 --> 00:05:06.350
entire video at our disposal,
we can do stabilization, for

00:05:06.350 --> 00:05:08.290
example, for the case
where you're

00:05:08.290 --> 00:05:09.810
walking with your camera.

00:05:09.810 --> 00:05:13.380
So there's low frequency
bouncing motions, which you

00:05:13.380 --> 00:05:16.140
can't stabilize if you're just
looking in the past.

00:05:16.140 --> 00:05:20.370
Also, you can distribute the
computation in the cloud in

00:05:20.370 --> 00:05:21.520
this post-process setting.

00:05:21.520 --> 00:05:23.780
So you can use multiple machines
to do much heavier

00:05:23.780 --> 00:05:25.720
processing than possible
in a single device.

00:05:28.250 --> 00:05:30.640
There are three main steps
in doing Post-process

00:05:30.640 --> 00:05:31.965
stabilization.

00:05:31.965 --> 00:05:34.370
You start by estimating
the shaky camera

00:05:34.370 --> 00:05:35.840
parts of the video.

00:05:35.840 --> 00:05:38.660
This is where you try to figure
out or recover how the

00:05:38.660 --> 00:05:43.170
user was moving the camera while
capturing the video.

00:05:43.170 --> 00:05:46.500
The second step is to smooth
the camera motion, the

00:05:46.500 --> 00:05:49.150
original shaky camera motion,
to obtain the stabilized

00:05:49.150 --> 00:05:50.620
camera path.

00:05:50.620 --> 00:05:52.610
And finally, you want to render
a new video or new

00:05:52.610 --> 00:05:56.500
movie from the viewpoints of
these stabilized camera parts.

00:05:56.500 --> 00:05:57.620
So let's look at an example.

00:05:57.620 --> 00:06:01.150
Here we have a shaky video that
we want to stabilize.

00:06:01.150 --> 00:06:06.140
And once we take it through
these three steps, we have the

00:06:06.140 --> 00:06:07.850
stabilized camera part.

00:06:07.850 --> 00:06:09.660
Now you see this red
rectangle here.

00:06:09.660 --> 00:06:14.340
This is our visualization of
this new camera position.

00:06:14.340 --> 00:06:17.110
You can think of this as a
virtual window that tries to

00:06:17.110 --> 00:06:20.620
move counter to the original
shaky camera motion.

00:06:20.620 --> 00:06:23.290
In other words, this tries to
stick to the background in the

00:06:23.290 --> 00:06:26.710
video so that you get
a stabilized result.

00:06:26.710 --> 00:06:28.570
And to get this stabilized
result, we essentially take

00:06:28.570 --> 00:06:31.090
the pixels within this rectangle
and render them in

00:06:31.090 --> 00:06:32.040
the final video.

00:06:32.040 --> 00:06:33.110
But it's not really final yet.

00:06:33.110 --> 00:06:35.620
So what you see in the top
is a stabilized video.

00:06:35.620 --> 00:06:37.790
But you also see these
extra black

00:06:37.790 --> 00:06:39.660
borders around the video.

00:06:39.660 --> 00:06:41.570
And that's because when there
is too much motion in the

00:06:41.570 --> 00:06:44.600
video, this virtual window
overcompensates for it and

00:06:44.600 --> 00:06:47.560
goes outside the valid
bounds of the video.

00:06:47.560 --> 00:06:48.340
And we don't really want that.

00:06:48.340 --> 00:06:50.160
That's sort of annoying
to watch.

00:06:50.160 --> 00:06:52.250
So a solution here
is what we call

00:06:52.250 --> 00:06:54.600
stabilization by cropping.

00:06:54.600 --> 00:06:56.810
And the idea here is that we
can start with the same

00:06:56.810 --> 00:06:57.790
virtual window.

00:06:57.790 --> 00:07:00.860
But we shrink it a little bit
to get rid of some of the

00:07:00.860 --> 00:07:03.370
contents around the border
of the frame.

00:07:03.370 --> 00:07:06.390
And more importantly, we force
this crop window to always

00:07:06.390 --> 00:07:09.310
stay within the bounds of
the frame rectangle.

00:07:09.310 --> 00:07:11.860
What that means is that while
you lose some content around

00:07:11.860 --> 00:07:15.210
the border, you always get
pixels which are well-defined.

00:07:15.210 --> 00:07:17.440
So you get a final stabilized
video, which

00:07:17.440 --> 00:07:18.230
looks nice to watch.

00:07:18.230 --> 00:07:19.920
There is some content
which is lost.

00:07:19.920 --> 00:07:21.490
But overall, the result
is better.

00:07:24.360 --> 00:07:26.410
So let's get back to the three
steps I talked about.

00:07:26.410 --> 00:07:28.970
And we'll talk about
them one by one.

00:07:28.970 --> 00:07:31.850
So let's talk about estimating
the shaky camera parts from a

00:07:31.850 --> 00:07:33.590
given video.

00:07:33.590 --> 00:07:36.150
Remember what I told you was
that we only look at the

00:07:36.150 --> 00:07:40.050
pixels within the video to
compute the camera motion.

00:07:40.050 --> 00:07:42.870
So in this case, what I'm
showing you here are these

00:07:42.870 --> 00:07:45.970
green dots, which are what
we call local features.

00:07:45.970 --> 00:07:49.110
These are pixels which have high
gradients in the x and y

00:07:49.110 --> 00:07:51.220
direction, which means these
are things like corners.

00:07:51.220 --> 00:07:53.520
So if you look at the windows
in the building, the corners

00:07:53.520 --> 00:07:55.920
of the window are good
places to track

00:07:55.920 --> 00:07:57.160
or have local features.

00:07:57.160 --> 00:07:58.770
And that is because you
can track them in

00:07:58.770 --> 00:07:59.410
the previous frame.

00:07:59.410 --> 00:08:02.290
By matching appearance, you can
figure out where did each

00:08:02.290 --> 00:08:06.030
of these points come from
in the previous frame?

00:08:06.030 --> 00:08:08.200
And once we have these features,
we want to fit a

00:08:08.200 --> 00:08:09.460
camera motion to them.

00:08:09.460 --> 00:08:11.985
But there is one important point
here, which is we don't

00:08:11.985 --> 00:08:14.320
want to treat all features
equally.

00:08:14.320 --> 00:08:17.290
Since the camera motion only
affects the pixels in the

00:08:17.290 --> 00:08:20.660
background, you don't want to
take into account things like

00:08:20.660 --> 00:08:22.115
a person walking in
the foreground or

00:08:22.115 --> 00:08:23.560
a car driving by.

00:08:23.560 --> 00:08:25.560
And we detect that automatically
and figure out

00:08:25.560 --> 00:08:28.170
which features are background
features, shown in green, and

00:08:28.170 --> 00:08:29.590
which features are foreground
features.

00:08:29.590 --> 00:08:31.370
And those features
are shown in red.

00:08:31.370 --> 00:08:34.510
And once we have these features
that we can use for

00:08:34.510 --> 00:08:37.070
motion estimation, we finally
compute what the actual shaky

00:08:37.070 --> 00:08:38.700
camera part was.

00:08:38.700 --> 00:08:41.429
At this point, I'll hand over to
Matthias who will tell you

00:08:41.429 --> 00:08:45.011
how we actually do the
motion estimation.

00:08:45.011 --> 00:08:46.000
MATTHIAS GRUNDMANN:
Thank you, Vivek.

00:08:46.000 --> 00:08:46.440
Hey.

00:08:46.440 --> 00:08:47.150
I'm Matthias.

00:08:47.150 --> 00:08:51.790
And I'm going to talk about how
we actually model the 2D

00:08:51.790 --> 00:08:52.910
camera path.

00:08:52.910 --> 00:08:57.000
So Vivek initially mentioned,
we start by having our

00:08:57.000 --> 00:09:01.480
original video, and we extract
features at these gradient

00:09:01.480 --> 00:09:04.180
locations and track them with
respect to the previous frame.

00:09:04.180 --> 00:09:06.720
So we get all these little
displacement vectors.

00:09:06.720 --> 00:09:09.020
Now in order to stabilize the
video, we would need to

00:09:09.020 --> 00:09:12.360
stabilize the motion of each
and every of these vectors,

00:09:12.360 --> 00:09:13.310
which is, of course,

00:09:13.310 --> 00:09:15.550
computationally quite expensive.

00:09:15.550 --> 00:09:19.180
So what we do instead is we try
to summarize the overall

00:09:19.180 --> 00:09:22.040
motion of all these feature
points with just a few

00:09:22.040 --> 00:09:24.780
numbers, what we call
a motion model.

00:09:24.780 --> 00:09:26.640
Let's look at some of the motion
models that one can

00:09:26.640 --> 00:09:28.600
employ in this setting.

00:09:28.600 --> 00:09:31.830
Well, the easiest motion model
is that of a translation.

00:09:31.830 --> 00:09:35.860
In a translation, we only have
translation x and y or

00:09:35.860 --> 00:09:37.050
superimposed.

00:09:37.050 --> 00:09:40.020
So altogether, we're looking
at two degrees of freedom.

00:09:40.020 --> 00:09:43.090
And if we use that to stabilize
the video, we see

00:09:43.090 --> 00:09:44.500
it's still very shaky.

00:09:44.500 --> 00:09:47.060
And it's very shaky because
there are some degrees of

00:09:47.060 --> 00:09:47.680
freedom missing.

00:09:47.680 --> 00:09:49.960
And that is the role
and the scale.

00:09:49.960 --> 00:09:53.460
So let's add that to
our motion model.

00:09:53.460 --> 00:09:55.250
In this case, we have
a similarity.

00:09:55.250 --> 00:09:58.930
A similarity has now translation
x and y as well as

00:09:58.930 --> 00:10:00.780
scale and rotation.

00:10:00.780 --> 00:10:03.450
So we're looking at four
degrees of freedom.

00:10:03.450 --> 00:10:06.990
And if we use that to stabilize
the video, we see it

00:10:06.990 --> 00:10:10.040
is not shaky, but it's
still quite wobbly.

00:10:10.040 --> 00:10:11.900
And that's because there are
additional degrees of freedom

00:10:11.900 --> 00:10:12.710
that are missing.

00:10:12.710 --> 00:10:16.570
And that is the yaw and the
pitch rotation of the camera.

00:10:16.570 --> 00:10:19.430
So if we add that to our motion
model, we obtain what

00:10:19.430 --> 00:10:20.780
he call a homography.

00:10:20.780 --> 00:10:22.880
So we have all the four degrees
of freedom of the

00:10:22.880 --> 00:10:26.360
previous motion model, but
now we also have skew and

00:10:26.360 --> 00:10:28.050
perspective degrees
of freedom.

00:10:28.050 --> 00:10:30.770
All together, we have eight
degrees of freedom here.

00:10:30.770 --> 00:10:34.610
And if we use that to stabilize
the video, we see

00:10:34.610 --> 00:10:37.790
this is adequate to summarize
the motion.

00:10:37.790 --> 00:10:39.790
So while we use this homography
in our back end,

00:10:39.790 --> 00:10:43.030
for the ease of explanation,
I will only focus on the

00:10:43.030 --> 00:10:46.410
similarity case, meaning four
degrees of freedom over time,

00:10:46.410 --> 00:10:49.780
translation x, y, scale,
and rotation.

00:10:49.780 --> 00:10:53.200
Now what we can do is we can
plot the amount of each degree

00:10:53.200 --> 00:10:54.600
of freedom over time.

00:10:54.600 --> 00:10:56.210
And so we get a curve.

00:10:56.210 --> 00:11:00.460
So here, first we show you the
translation of x over time,

00:11:00.460 --> 00:11:02.710
the blue curve.

00:11:02.710 --> 00:11:05.850
The translation y, you see it's
going up and down because

00:11:05.850 --> 00:11:09.700
that is the walking motion
that we measure.

00:11:09.700 --> 00:11:11.240
We're looking now
at the scale.

00:11:11.240 --> 00:11:12.890
You see the scale is going
down because we're

00:11:12.890 --> 00:11:15.350
moving into the scene.

00:11:15.350 --> 00:11:19.020
And finally, the rotation, which
is just wiggly, in this

00:11:19.020 --> 00:11:22.750
case, left and right.

00:11:22.750 --> 00:11:27.060
Now that we model basically
the 2D camera motion with

00:11:27.060 --> 00:11:30.770
these four degrees of freedom
over time, we can start

00:11:30.770 --> 00:11:33.670
stabilizing or smoothing them,
which is the second step of

00:11:33.670 --> 00:11:34.880
our algorithm.

00:11:34.880 --> 00:11:39.630
So here we just show the
translation x and the

00:11:39.630 --> 00:11:40.940
translation y.

00:11:40.940 --> 00:11:44.070
The original camera path
is shown in red.

00:11:44.070 --> 00:11:46.860
And we're trying to approximate
it with a stable

00:11:46.860 --> 00:11:48.080
path that is shown in blue.

00:11:48.080 --> 00:11:49.570
This is our result.

00:11:49.570 --> 00:11:52.230
So you see the stable path
has some properties.

00:11:52.230 --> 00:11:55.110
When we started our project, we
asked ourselves what would

00:11:55.110 --> 00:11:57.630
be the property of a good,
stable path if a

00:11:57.630 --> 00:11:59.890
cinematographer would
have captured it.

00:11:59.890 --> 00:12:02.350
Well, a cinematographer would
use stabilization equipment,

00:12:02.350 --> 00:12:04.370
for example, a tripod.

00:12:04.370 --> 00:12:08.650
So you would have segments in
your stabilized video that

00:12:08.650 --> 00:12:11.780
basically would have no motion
at all, meaning a constant

00:12:11.780 --> 00:12:14.430
segment shown here in green.

00:12:14.430 --> 00:12:17.380
Or a cinematographer would have
used a dolly or a pan

00:12:17.380 --> 00:12:20.720
where you have nice constant
velocity, which reflects

00:12:20.720 --> 00:12:25.600
itself in a linear path
shown here in yellow.

00:12:25.600 --> 00:12:30.290
You see the remaining arcs are
basically parabolic segments,

00:12:30.290 --> 00:12:33.170
what we call ease in and ease
out transitions so that you

00:12:33.170 --> 00:12:35.240
can transition between
the constant

00:12:35.240 --> 00:12:37.170
and the linear segments.

00:12:37.170 --> 00:12:41.100
And so our goal is now, given
this original shaky path shown

00:12:41.100 --> 00:12:45.750
in red, to compute this stable
path that is only composed out

00:12:45.750 --> 00:12:49.670
of linear, constant, and
parabolic paths under one very

00:12:49.670 --> 00:12:51.540
important constraint.

00:12:51.540 --> 00:12:54.470
And that is the size
of the crop window.

00:12:54.470 --> 00:12:56.750
When we look at the crop window,
as Vivek initially

00:12:56.750 --> 00:12:59.730
mentioned it, if we have a very
large crop window, and we

00:12:59.730 --> 00:13:02.490
have to stay within the frame
bound, we can't really move

00:13:02.490 --> 00:13:04.560
around without hitting
the frame border.

00:13:04.560 --> 00:13:07.490
So we can't really offset
any camera shake.

00:13:07.490 --> 00:13:10.460
Now the smaller the crop window,
the more shake we can

00:13:10.460 --> 00:13:11.730
compensate for.

00:13:11.730 --> 00:13:15.410
And this reflects itself very
nicely as an envelope around

00:13:15.410 --> 00:13:18.240
the shaky camera path
that we measure.

00:13:18.240 --> 00:13:21.960
So the smaller the crop window,
the larger an envelope

00:13:21.960 --> 00:13:24.050
around that shaky camera path.

00:13:24.050 --> 00:13:27.130
And now within this envelope,
we're trying to find our

00:13:27.130 --> 00:13:30.320
stable path that will be only
composed out of constant

00:13:30.320 --> 00:13:32.670
linear and parabolic segments.

00:13:32.670 --> 00:13:35.690
Let's look at a little
interactive visualization of

00:13:35.690 --> 00:13:37.800
how you can imagine this
solution works.

00:13:37.800 --> 00:13:41.250
So here we see our original
shaky path in red.

00:13:41.250 --> 00:13:44.320
And now we'll start increasing
the bounds over time, and you

00:13:44.320 --> 00:13:49.160
will see how more stable the
blue path will become.

00:13:49.160 --> 00:13:53.140
What's nice about our solution
is its robust perturbations.

00:13:53.140 --> 00:13:55.450
If I move it around, as long
as I'm staying within the

00:13:55.450 --> 00:13:57.670
envelope, the path
doesn't change.

00:13:57.670 --> 00:13:59.850
I can use only constant
paths to

00:13:59.850 --> 00:14:02.440
approximate the stable path.

00:14:02.440 --> 00:14:06.080
Or I can use linear paths, in
which case now I have these

00:14:06.080 --> 00:14:07.220
junctions here.

00:14:07.220 --> 00:14:10.480
I can also use just parabolic
paths, which are very smooth

00:14:10.480 --> 00:14:12.750
but nonzero throughout.

00:14:12.750 --> 00:14:15.410
Or I can use a specific
weighting that we employ in

00:14:15.410 --> 00:14:18.180
YouTube, which finds a nice
sweet spot between these three

00:14:18.180 --> 00:14:23.790
types of paths and
is shown here.

00:14:23.790 --> 00:14:25.880
Now that we have the original
path and we have the

00:14:25.880 --> 00:14:29.450
stabilized path, we can finally
synthesize a new movie

00:14:29.450 --> 00:14:31.680
that looks like as if it would
have been taken from this

00:14:31.680 --> 00:14:35.920
stable viewpoint, which is the
last step in our algorithm.

00:14:35.920 --> 00:14:40.270
The stable path, you can think
of as this virtual camera,

00:14:40.270 --> 00:14:43.580
that is shown here in red
at this crop window.

00:14:43.580 --> 00:14:47.010
And so in this step, really all
we need to do is simply

00:14:47.010 --> 00:14:48.080
apply a crop.

00:14:48.080 --> 00:14:51.190
And that will result in the
stable video at the top.

00:14:51.190 --> 00:14:54.490
So let's look at some few more
examples from YouTube.

00:14:54.490 --> 00:14:57.450
So here are some of the
properties highlighted in a

00:14:57.450 --> 00:14:58.850
real video.

00:14:58.850 --> 00:15:03.570
If we can fit a tripod model,
there will be no motion in the

00:15:03.570 --> 00:15:05.280
stable result at all.

00:15:05.280 --> 00:15:08.770
And now that the motion of the
original camera picks up, and

00:15:08.770 --> 00:15:11.370
the frame rectangle has to stay
within the frame bounds,

00:15:11.370 --> 00:15:13.970
you see there's also motion
in the stabilized result.

00:15:13.970 --> 00:15:15.820
But it's very nicely smooth.

00:15:15.820 --> 00:15:20.440
You have this constant
velocity pans.

00:15:20.440 --> 00:15:24.130
Again, no motion at all in the
beginning, nice tripod model.

00:15:24.130 --> 00:15:27.670
And now we have nice
accelerations, constant pans,

00:15:27.670 --> 00:15:29.380
nice decelerations.

00:15:29.380 --> 00:15:31.380
So the whole result
looks very smooth.

00:15:31.380 --> 00:15:34.890
And a lot of the shake that was
in the y direction is gone

00:15:34.890 --> 00:15:37.990
from the result.

00:15:37.990 --> 00:15:42.180
Another example here recorded
on a bike in Cairo.

00:15:42.180 --> 00:15:45.930
And so you see a lot of this
high frequency perturbations

00:15:45.930 --> 00:15:46.970
in the y direction.

00:15:46.970 --> 00:15:48.890
And it's completely gone in
the stabilized result.

00:15:48.890 --> 00:15:51.130
The stabilized result really
looks like just the handle

00:15:51.130 --> 00:15:52.910
bars moving very smoothly.

00:15:56.590 --> 00:15:58.190
In the second part, I
would like to talk

00:15:58.190 --> 00:15:59.360
about solving a problem.

00:15:59.360 --> 00:16:01.860
And that is rolling
shutter removal.

00:16:01.860 --> 00:16:04.630
It's a little bit independent
from video stabilization.

00:16:04.630 --> 00:16:07.510
To motivate the problem, let's
look at the following example.

00:16:07.510 --> 00:16:09.200
Here we took a video
that we recorded

00:16:09.200 --> 00:16:11.140
with an Android phone.

00:16:11.140 --> 00:16:13.030
And we deliberately
shook the camera.

00:16:13.030 --> 00:16:15.330
What you see, it's not
just camera shake.

00:16:15.330 --> 00:16:18.520
It's like these non rigid,
wobbly distortions that pose a

00:16:18.520 --> 00:16:19.740
problem here.

00:16:19.740 --> 00:16:23.100
And so our stabilization
algorithm does rolling shutter

00:16:23.100 --> 00:16:24.970
rectification as well.

00:16:24.970 --> 00:16:28.270
So we can take this original
video shown on left, we can

00:16:28.270 --> 00:16:32.000
produce this rolling shutter
removed result on the right.

00:16:32.000 --> 00:16:33.510
And you see it's
still a video.

00:16:33.510 --> 00:16:35.920
There's a person walking
on the bridge.

00:16:35.920 --> 00:16:38.250
But all the distortions
are gone.

00:16:38.250 --> 00:16:40.430
Let's look at a little bit
into the details why this

00:16:40.430 --> 00:16:42.170
problem actually exist.

00:16:42.170 --> 00:16:43.560
It exists because there
are two types

00:16:43.560 --> 00:16:45.100
of electronic shutters.

00:16:45.100 --> 00:16:48.930
The classic shutter is that
of a global shutter.

00:16:48.930 --> 00:16:51.300
In the global shutter, the
image is captured at one

00:16:51.300 --> 00:16:52.550
instant in time.

00:16:52.550 --> 00:16:55.920
So we snap a picture
or a video frame.

00:16:55.920 --> 00:16:58.510
Then we move the camera
slightly.

00:16:58.510 --> 00:16:59.970
We snap another picture.

00:16:59.970 --> 00:17:01.890
And then, we snap
another picture.

00:17:01.890 --> 00:17:05.040
However, most cellphones
use what is

00:17:05.040 --> 00:17:06.500
called a rolling shutter.

00:17:06.500 --> 00:17:08.640
So here is an image that's not
captured in one instant in

00:17:08.640 --> 00:17:11.770
time, but one scan
line at a time.

00:17:11.770 --> 00:17:15.839
So what you get is the camera is
moving during the capture.

00:17:15.839 --> 00:17:18.079
And so instead of a rectified
image, you

00:17:18.079 --> 00:17:19.750
get this good effect.

00:17:19.750 --> 00:17:22.540
And if the camera is actually
vibrating during the capture,

00:17:22.540 --> 00:17:24.460
you get this wobbly result.

00:17:24.460 --> 00:17:27.349
If you compare global with a
rolling shutter, you see the

00:17:27.349 --> 00:17:29.710
global shutter nicely rectified,
the rolling

00:17:29.710 --> 00:17:32.770
shutter, all the houses
are skewed.

00:17:32.770 --> 00:17:36.620
And so when you plot the scan
lines over time how they get

00:17:36.620 --> 00:17:39.980
recorded, what you basically
see is they are slanted.

00:17:39.980 --> 00:17:40.475
They are offset.

00:17:40.475 --> 00:17:44.560
The image is not captured at one
instant in time anymore.

00:17:44.560 --> 00:17:46.590
Now if you don't account
for this--

00:17:46.590 --> 00:17:51.680
here I'll show you an original
video taken from a helicopter.

00:17:51.680 --> 00:17:54.010
You see all these rolling
shutter distortions.

00:17:54.010 --> 00:17:58.430
And so in our initial launch of
the YouTube Stabilizer in

00:17:58.430 --> 00:18:01.330
2011, we didn't account for
rolling shutter yet.

00:18:01.330 --> 00:18:05.320
You see the result is more
stable, but there's still all

00:18:05.320 --> 00:18:08.240
these wobbly distortions
that remain.

00:18:08.240 --> 00:18:10.220
So how can we solve
this problem?

00:18:10.220 --> 00:18:14.370
Something that makes the
solution more challenging is

00:18:14.370 --> 00:18:17.550
that the speed of the readout
varies across cameras.

00:18:17.550 --> 00:18:20.480
So for more high end cameras,
you would basically have these

00:18:20.480 --> 00:18:22.340
blocks a little bit
more aligned.

00:18:22.340 --> 00:18:24.500
And then if the cameras take
longer, you will basically

00:18:24.500 --> 00:18:28.010
have a more slanted
arrangement.

00:18:28.010 --> 00:18:30.200
And at YouTube, we only
have the video.

00:18:30.200 --> 00:18:33.020
We don't know which camera,
which setting, or which scene

00:18:33.020 --> 00:18:33.930
you recorded.

00:18:33.930 --> 00:18:35.910
And so our solution is
calibration free.

00:18:35.910 --> 00:18:38.450
And the idea is basically
instead of using one motion

00:18:38.450 --> 00:18:40.300
model, we use multiple ones.

00:18:40.300 --> 00:18:43.760
We use one that describes
the motion of the

00:18:43.760 --> 00:18:45.490
top side of the frame.

00:18:45.490 --> 00:18:48.010
And then the camera moves to
a different configuration.

00:18:48.010 --> 00:18:50.240
So we have a motion model
for the middle frame.

00:18:50.240 --> 00:18:52.290
And we have a motion model
for the bottom frame.

00:18:52.290 --> 00:18:54.650
We actually use 10 motion models
and a little bit of

00:18:54.650 --> 00:18:56.960
interpolation, but this
is like the simplified

00:18:56.960 --> 00:18:59.030
explanation of it.

00:18:59.030 --> 00:19:03.220
When you use this new mixture
model to account for the

00:19:03.220 --> 00:19:05.470
camera motion, you can
take this video.

00:19:05.470 --> 00:19:08.510
And then after our launch of
rolling shutter removal in

00:19:08.510 --> 00:19:11.740
YouTube, we produced the
following result.

00:19:11.740 --> 00:19:14.030
Nicely accounts for all the
wobbly distortions.

00:19:17.860 --> 00:19:21.090
Here's another video from
Citizen Tube, also

00:19:21.090 --> 00:19:22.760
recorded on a bike.

00:19:22.760 --> 00:19:26.190
Citizen Tube is a crowd
casted news site.

00:19:26.190 --> 00:19:29.250
So you see a lot of wobbly
distortions in this case.

00:19:29.250 --> 00:19:33.340
And here is our rectified
and stabilized result.

00:19:33.340 --> 00:19:35.680
And one more time side by side
for better comparison.

00:19:43.940 --> 00:19:46.465
In the next part of the talk,
I would like to give you a

00:19:46.465 --> 00:19:49.560
little overview what's actually
happening behind the

00:19:49.560 --> 00:19:53.020
YouTube stabilizer that uses
those two algorithms to

00:19:53.020 --> 00:19:57.800
produce the result or some of
the results we earlier saw.

00:19:57.800 --> 00:19:59.910
So here just to motivate it, or
to remind you again, this

00:19:59.910 --> 00:20:04.150
is the enhancement UI
where we detect that

00:20:04.150 --> 00:20:05.610
your video is shaky.

00:20:05.610 --> 00:20:08.160
So we offer you this
preview button.

00:20:08.160 --> 00:20:09.730
You simply click
on the button.

00:20:09.730 --> 00:20:12.820
And then we compute the
stabilized result in real time

00:20:12.820 --> 00:20:14.330
and stream it to the user.

00:20:14.330 --> 00:20:17.230
We also detect that this video,
in addition to video

00:20:17.230 --> 00:20:19.150
shake, was corrupted
by rolling shutter.

00:20:19.150 --> 00:20:22.420
So we do rolling shutter
rectification in real time on

00:20:22.420 --> 00:20:24.980
top of the stabilization.

00:20:24.980 --> 00:20:27.640
Let's look at what's going
on behind the scenes.

00:20:27.640 --> 00:20:29.340
So we have our video here.

00:20:29.340 --> 00:20:32.480
And we start by clicking
on Preview.

00:20:32.480 --> 00:20:35.430
And the moment you click on
Preview, a server request is

00:20:35.430 --> 00:20:38.730
sent to our cloud to start
the stabilization.

00:20:38.730 --> 00:20:41.370
The first step is to compute
a camera path.

00:20:41.370 --> 00:20:43.490
Remember, this is just
extracting the features,

00:20:43.490 --> 00:20:46.740
getting displacement vectors,
and then getting

00:20:46.740 --> 00:20:48.390
the original 2D path.

00:20:48.390 --> 00:20:51.680
Because we only look
at frame pairs,

00:20:51.680 --> 00:20:53.070
this is highly parallel.

00:20:53.070 --> 00:20:55.250
So we can simply
distribute this

00:20:55.250 --> 00:20:57.060
across many, many machines.

00:20:57.060 --> 00:20:59.940
Once we have the 2D camera path,
we can then send it off

00:20:59.940 --> 00:21:03.210
to our stabilization engine
to compute the

00:21:03.210 --> 00:21:04.650
stable camera path.

00:21:04.650 --> 00:21:06.270
There's a little
addition here.

00:21:06.270 --> 00:21:08.470
And that is I haven't talked
about what's actually the size

00:21:08.470 --> 00:21:09.470
of the crop window.

00:21:09.470 --> 00:21:10.280
And we can do this
dynamically.

00:21:10.280 --> 00:21:12.650
And we'll look into
this in a bit.

00:21:12.650 --> 00:21:15.530
And the last part, once we have
our stable path, we can

00:21:15.530 --> 00:21:16.740
apply the cropping.

00:21:16.740 --> 00:21:17.860
Again, this is done on frame.

00:21:17.860 --> 00:21:20.900
So this can be done
in parallel.

00:21:20.900 --> 00:21:22.690
And then in the end,
we live-stream the

00:21:22.690 --> 00:21:24.590
result to the user.

00:21:24.590 --> 00:21:27.980
I'd like to highlight that
this pipeline can be run

00:21:27.980 --> 00:21:29.250
independently.

00:21:29.250 --> 00:21:33.210
So the actual throughput of our
system is so high that we

00:21:33.210 --> 00:21:36.960
can compute the stabilization
and rolling shutter

00:21:36.960 --> 00:21:40.300
rectification on low resolution
video in real time

00:21:40.300 --> 00:21:42.150
and stream it to you.

00:21:42.150 --> 00:21:45.720
I'd like to highlight two things
of this pipeline in

00:21:45.720 --> 00:21:46.720
more detail.

00:21:46.720 --> 00:21:48.310
First, you auto crop.

00:21:48.310 --> 00:21:52.000
So I haven't really talked about
what is the size of the

00:21:52.000 --> 00:21:53.010
crop window.

00:21:53.010 --> 00:21:55.360
What we would like to do is we
would like to maximize the

00:21:55.360 --> 00:21:58.000
crop window so that we can
offset most of the shake but

00:21:58.000 --> 00:22:00.330
also give you most of
your image content.

00:22:00.330 --> 00:22:01.600
Don't crop too much.

00:22:01.600 --> 00:22:03.650
What we do is we do
it adaptively.

00:22:03.650 --> 00:22:06.830
So what we see here is we start
with a crop window that

00:22:06.830 --> 00:22:09.410
is rather large because we don't
have a lot of shake in

00:22:09.410 --> 00:22:11.920
this segment of the video.

00:22:11.920 --> 00:22:14.740
And now the user will basically
start shaking the

00:22:14.740 --> 00:22:15.790
camera more.

00:22:15.790 --> 00:22:20.590
And so the crop window now
adaptively contracts over time

00:22:20.590 --> 00:22:23.670
to account for this.

00:22:23.670 --> 00:22:28.070
And here the user now will stop
shaking the camera as

00:22:28.070 --> 00:22:28.810
much as before.

00:22:28.810 --> 00:22:32.170
And so now the crop window will
smoothly and adaptively

00:22:32.170 --> 00:22:34.210
expand over time.

00:22:34.210 --> 00:22:35.580
So we measure the
amount of shake.

00:22:35.580 --> 00:22:39.160
And based on that, we size
the crop window.

00:22:39.160 --> 00:22:42.000
Another challenge that we face
at YouTube is that videos are

00:22:42.000 --> 00:22:44.640
often pre-composited in
some other software.

00:22:44.640 --> 00:22:46.310
So for example, you
have overlays.

00:22:46.310 --> 00:22:47.860
Overlays are not part
of the video.

00:22:47.860 --> 00:22:50.100
And so if you don't account
for that, what happens is

00:22:50.100 --> 00:22:52.160
these overlays dance around.

00:22:52.160 --> 00:22:53.860
And the user that's not
familiar with the

00:22:53.860 --> 00:22:55.980
video will see this.

00:22:55.980 --> 00:22:58.010
It's not a satisfactory
result.

00:22:58.010 --> 00:23:01.730
So what we do is we detect if
major overlays are present.

00:23:01.730 --> 00:23:04.690
And in that case, we don't
stabilize those parts of the

00:23:04.690 --> 00:23:06.590
video at all to avoid that.

00:23:06.590 --> 00:23:10.900
And once the overlay fades out,
we detect it and then

00:23:10.900 --> 00:23:13.630
nicely transition into the
stabilized result.

00:23:19.380 --> 00:23:21.410
So since we launched
our system, we have

00:23:21.410 --> 00:23:23.090
gathered user responses.

00:23:23.090 --> 00:23:28.930
And in particular, two of them
are A, when we detect that a

00:23:28.930 --> 00:23:32.000
video is shaky, and we suggest
stabilization to the user, how

00:23:32.000 --> 00:23:33.930
many actually accept
the suggestion?

00:23:33.930 --> 00:23:37.670
And of those that do, how many
keep the stabilized result?

00:23:37.670 --> 00:23:42.470
And the response is collected
over millions of videos is 55%

00:23:42.470 --> 00:23:45.100
accept stabilization after
we suggest that the

00:23:45.100 --> 00:23:46.360
video might be shaky.

00:23:46.360 --> 00:23:50.120
And of those that do, 95% keep
the stabilized result.

00:23:50.120 --> 00:23:53.670
So only 5% go back to the
original because they didn't

00:23:53.670 --> 00:23:54.890
like the stabilized result.

00:23:54.890 --> 00:23:59.620
Or the Stabilizer might have
not performed that well.

00:23:59.620 --> 00:24:02.800
So far I talked about
stabilization of videos.

00:24:02.800 --> 00:24:05.655
But what we can do is we can
actually do stabilization of

00:24:05.655 --> 00:24:07.150
photo bursts as well.

00:24:07.150 --> 00:24:12.010
And this is deployed in Google+
Auto Awesome feature

00:24:12.010 --> 00:24:15.120
that you heard about in
yesterday's keynote.

00:24:15.120 --> 00:24:19.400
So while there are many other
algorithms used in this suite,

00:24:19.400 --> 00:24:22.410
the Stabilization is used
prominently in three of them.

00:24:22.410 --> 00:24:24.910
That is Google+ MOTION, Google+

00:24:24.910 --> 00:24:28.480
HDR, and Google+ SMILE.

00:24:28.480 --> 00:24:32.680
In Google+ MOTION, what we do is
we take a photo burst, and

00:24:32.680 --> 00:24:36.180
we create this animation
shown on top out of it.

00:24:36.180 --> 00:24:39.500
And so what is desirable here
is basically to nicely align

00:24:39.500 --> 00:24:44.660
the background, get rid of all
the alignment issues so that

00:24:44.660 --> 00:24:46.260
the foreground really
pops, right?

00:24:46.260 --> 00:24:49.880
Now that the background is
aligned, the foreground object

00:24:49.880 --> 00:24:52.940
really comes out in
this animation.

00:24:52.940 --> 00:24:55.270
We also use it in Google+ HDR.

00:24:55.270 --> 00:24:59.070
When you take an exposure
stack, when you use your

00:24:59.070 --> 00:25:02.500
camera in bracketing mode, it's
rarely the case that you

00:25:02.500 --> 00:25:03.290
use a tripod.

00:25:03.290 --> 00:25:05.650
So there will be a little
bit of camera shake.

00:25:05.650 --> 00:25:08.720
And so what we do is we run the
stabilization upfront so

00:25:08.720 --> 00:25:12.030
that the images are nicely
aligned before we apply the

00:25:12.030 --> 00:25:16.180
HDR, which then reduces
ghosting.

00:25:16.180 --> 00:25:18.300
What we can also do is
we can align faces.

00:25:18.300 --> 00:25:23.630
So if you take a photo burst of
your family, we can align

00:25:23.630 --> 00:25:26.850
the faces and then create a new
composite that hasn't been

00:25:26.850 --> 00:25:30.790
taken by you where we try that
all the faces that are shown

00:25:30.790 --> 00:25:32.640
are smiling.

00:25:32.640 --> 00:25:36.180
And so here are some
more examples.

00:25:36.180 --> 00:25:40.200
You see the animation that we
created with foreground,

00:25:40.200 --> 00:25:45.530
waterfall, and finally
the smile where we

00:25:45.530 --> 00:25:49.230
create this new canvas.

00:25:49.230 --> 00:25:53.880
And with that, I hand
it over to John.

00:25:53.880 --> 00:25:55.800
JOHN GREGG: Thank
you, Matthias.

00:25:55.800 --> 00:25:56.510
Hi, my name is John.

00:25:56.510 --> 00:25:59.690
I'm an engineer on the video
editing team at YouTube.

00:25:59.690 --> 00:26:02.160
And just for the last part of
our talk, I'm going to talk to

00:26:02.160 --> 00:26:05.890
you about a new feature that
we're launching today, which

00:26:05.890 --> 00:26:10.220
allows developers to take
advantage of the stabilization

00:26:10.220 --> 00:26:13.685
feature in a new API for
enhancing uploads.

00:26:16.900 --> 00:26:19.970
So here you see the user-facing
enhancement API.

00:26:19.970 --> 00:26:22.600
There's a wide variety of
options, including these

00:26:22.600 --> 00:26:25.700
stylized filters, trimming your
video, color correction,

00:26:25.700 --> 00:26:27.200
and stabilize.

00:26:27.200 --> 00:26:30.100
And what we've done is taken the
two most popular features

00:26:30.100 --> 00:26:34.260
of enhancement, the stabilizer
and the Auto Fix, which we

00:26:34.260 --> 00:26:36.190
could talk in a lot
more detail about.

00:26:36.190 --> 00:26:40.110
But it's basically a histogram
stretcher that's temporally

00:26:40.110 --> 00:26:41.770
smooth over the video.

00:26:41.770 --> 00:26:45.730
So it improves the contrast
and colors in

00:26:45.730 --> 00:26:47.730
pretty much any video.

00:26:47.730 --> 00:26:49.370
We've taken those two features
and added them to

00:26:49.370 --> 00:26:51.080
the YouTube v3 API.

00:26:51.080 --> 00:26:55.050
So any application that uploads
to YouTube can add,

00:26:55.050 --> 00:26:58.760
with just a couple lines of
code, instructions to apply

00:26:58.760 --> 00:27:03.090
these effects after the
video's been uploaded.

00:27:03.090 --> 00:27:07.850
So I'm just going to walk
through a quick demo of it.

00:27:07.850 --> 00:27:11.900
So this is just running
an app engine.

00:27:11.900 --> 00:27:14.860
Imagine any application that's
capturing video and uploading

00:27:14.860 --> 00:27:15.980
it to YouTube.

00:27:15.980 --> 00:27:18.940
This one's just called
John's Uploader.

00:27:18.940 --> 00:27:25.060
So let's upload this video,
which didn't work.

00:27:25.060 --> 00:27:26.610
But it would look like this.

00:27:26.610 --> 00:27:30.850
So this is just playing the
raw file in the app.

00:27:30.850 --> 00:27:33.305
So in the camera, for example.

00:27:33.305 --> 00:27:35.290
And we're going to publish
this to YouTube.

00:27:35.290 --> 00:27:39.420
Just check a few boxes,
publish it.

00:27:39.420 --> 00:27:43.970
And here it's been published.

00:27:47.200 --> 00:27:49.930
You see a message that it's
processing and also that the

00:27:49.930 --> 00:27:51.600
video edits are being
processed.

00:27:51.600 --> 00:27:54.230
So while we can do the low
resolution preview nearly

00:27:54.230 --> 00:27:57.250
instantaneously, processing a
higher resolution does take a

00:27:57.250 --> 00:27:58.340
few minutes.

00:27:58.340 --> 00:28:01.120
But I happen to have already
uploaded a copy of this video.

00:28:04.890 --> 00:28:11.380
And you can see the stabilized
version on YouTube versus the

00:28:11.380 --> 00:28:13.340
shaky version in my app.

00:28:18.980 --> 00:28:21.640
So how did I do this?

00:28:21.640 --> 00:28:24.540
This is using the YouTube v3
API, which is where this new

00:28:24.540 --> 00:28:26.570
feature is now available.

00:28:26.570 --> 00:28:29.020
It's just two Boolean parameters
on the video's

00:28:29.020 --> 00:28:32.650
insert instructions called
autolevels and stabilize to

00:28:32.650 --> 00:28:34.040
apply each of those effects.

00:28:34.040 --> 00:28:37.170
These are simply Boolean
parameters.

00:28:37.170 --> 00:28:40.610
As we've already described, we
have pieces of a technology to

00:28:40.610 --> 00:28:43.520
automatically compute the
optimal parameters.

00:28:43.520 --> 00:28:45.800
So you don't have to
worry about sliders

00:28:45.800 --> 00:28:47.850
or complicated controls.

00:28:47.850 --> 00:28:49.650
The edits are all performed
in the cloud.

00:28:49.650 --> 00:28:51.350
So again, you don't have to
worry about implementing these

00:28:51.350 --> 00:28:55.120
things on a device, which also
allows the user to revert back

00:28:55.120 --> 00:28:57.630
to the original version, if for
whatever reason they're

00:28:57.630 --> 00:29:00.250
not satisfied.

00:29:00.250 --> 00:29:01.260
So here's a code sample.

00:29:01.260 --> 00:29:05.550
This is using the API library
for Python in App Engine.

00:29:05.550 --> 00:29:09.110
So this is just a request
setting the body and title,

00:29:09.110 --> 00:29:10.870
description, and the bytes
of the upload.

00:29:10.870 --> 00:29:13.010
And it really is just
two lines of code

00:29:13.010 --> 00:29:14.890
added to this request.

00:29:14.890 --> 00:29:17.250
This is actually taken from my
app so it's grabbing the

00:29:17.250 --> 00:29:20.205
values of those check boxes
and setting stabilize and

00:29:20.205 --> 00:29:21.890
autolevels parameters.

00:29:21.890 --> 00:29:24.800
And that's really
as easy as that.

00:29:24.800 --> 00:29:27.330
So this is available today.

00:29:27.330 --> 00:29:30.280
We hope app developers
find it useful.

00:29:30.280 --> 00:29:32.810
And with that, the
end of our talk.

00:29:32.810 --> 00:29:35.080
So just to summarize, we
talked about the video

00:29:35.080 --> 00:29:37.450
stabilization technology, which
compensates for a lot of

00:29:37.450 --> 00:29:41.780
the common problems with
casual video, including

00:29:41.780 --> 00:29:43.840
rolling shutter.

00:29:43.840 --> 00:29:48.210
And then the enhancement API,
which allows developers to add

00:29:48.210 --> 00:29:52.360
these corrections right
in the applications.

00:29:52.360 --> 00:29:55.500
So thank you for coming.

00:29:55.500 --> 00:29:57.510
One last example to
leave you with.

00:29:57.510 --> 00:29:59.880
And if you want to scan
this QR code, you

00:29:59.880 --> 00:30:01.390
can rate the talk.

00:30:01.390 --> 00:30:04.610
But with that, we'd be happy
to take any questions.

00:30:04.610 --> 00:30:05.540
Sure.

00:30:05.540 --> 00:30:06.120
AUDIENCE: Hi.

00:30:06.120 --> 00:30:08.650
Well, I've really enjoyed
using the stabilization.

00:30:08.650 --> 00:30:15.600
So I'm using a GoPro camera,
which I imagine a lot of users

00:30:15.600 --> 00:30:18.890
for kind of high action
photography are using

00:30:18.890 --> 00:30:20.530
a camera like that.

00:30:20.530 --> 00:30:22.270
But it has a very
wide angle lens.

00:30:22.270 --> 00:30:25.650
And I think the model that
you're using for stabilization

00:30:25.650 --> 00:30:28.130
doesn't account for the kind of
distortion that you'd get

00:30:28.130 --> 00:30:30.830
in an extremely wide angle
lens like that.

00:30:30.830 --> 00:30:34.030
So you get some very bizarre
kind of distortion effects

00:30:34.030 --> 00:30:37.870
that propagate across the field
of the virtual camera as

00:30:37.870 --> 00:30:38.700
you're moving it.

00:30:38.700 --> 00:30:43.580
And I was wondering if you're
aware of that and your plans

00:30:43.580 --> 00:30:48.030
to try to detect different lens
models to try to correct

00:30:48.030 --> 00:30:49.280
them more accurately?

00:30:51.300 --> 00:30:52.200
JOHN GREGG: Do you want
to talk about that?

00:30:52.200 --> 00:30:53.210
MATTHIAS GRUNDMANN: Yeah.

00:30:53.210 --> 00:30:57.030
So we are aware that there is
a problem with GoPro cameras

00:30:57.030 --> 00:30:59.700
because of the wide
field of view.

00:30:59.700 --> 00:31:01.400
This is actually
a GoPro camera.

00:31:01.400 --> 00:31:04.610
And if you use it in the
more narrow field of

00:31:04.610 --> 00:31:07.300
view, it works decent.

00:31:07.300 --> 00:31:11.640
But the wider field of
view is a challenge.

00:31:11.640 --> 00:31:13.870
There is a challenge to
basically detect which

00:31:13.870 --> 00:31:17.140
settings you use just
from the video file.

00:31:17.140 --> 00:31:19.410
But yeah, we are aware
of the problem.

00:31:19.410 --> 00:31:24.940
But it, so far, has been a
difficult problem to solve.

00:31:24.940 --> 00:31:26.956
AUDIENCE: I have another
question if nobody else is

00:31:26.956 --> 00:31:28.844
going to come up to
the microphone.

00:31:28.844 --> 00:31:29.320
MATTHIAS GRUNDMANN: Sure.

00:31:29.320 --> 00:31:33.740
AUDIENCE: So I've also been
doing photography mounted on a

00:31:33.740 --> 00:31:34.900
quadcopter.

00:31:34.900 --> 00:31:39.930
So there's often a kind of a
form of vibration, a very high

00:31:39.930 --> 00:31:41.850
frequency vibration
in the camera.

00:31:41.850 --> 00:31:46.030
And I don't know, is your
rolling shutter algorithm able

00:31:46.030 --> 00:31:48.380
to deal with something
like that?

00:31:48.380 --> 00:31:51.620
Or maybe detect a certain
frequency of vibration to try

00:31:51.620 --> 00:31:55.040
to more accurately get rid of
the rolling shutter effect?

00:31:55.040 --> 00:31:57.930
MATTHIAS GRUNDMANN: So our
rolling shutter algorithm

00:31:57.930 --> 00:31:59.570
detects rolling shutter.

00:31:59.570 --> 00:32:04.170
Now the question is, of course,
how crazy you see

00:32:04.170 --> 00:32:05.680
distortion.

00:32:05.680 --> 00:32:07.810
Because we do it automatically,
we calibrated

00:32:07.810 --> 00:32:09.650
it for the most common
use cases.

00:32:09.650 --> 00:32:12.590
So we can work on vibrating
[INAUDIBLE]

00:32:12.590 --> 00:32:16.430
from helicopters a little
bit, from driving cars.

00:32:16.430 --> 00:32:20.090
But if it gets too crazy, if
simply the camera motion just

00:32:20.090 --> 00:32:23.045
becomes too large during the
capturing process, it might

00:32:23.045 --> 00:32:24.080
not always work.

00:32:24.080 --> 00:32:27.840
AUDIENCE: Yeah, well I wonder
if it's also like the blades

00:32:27.840 --> 00:32:31.070
of a small quadcopter
they might be

00:32:31.070 --> 00:32:35.340
like 80 Hertz or something.

00:32:35.340 --> 00:32:38.900
So maybe a higher frequency
range then you're used to

00:32:38.900 --> 00:32:43.110
maybe detecting automatically
as that.

00:32:43.110 --> 00:32:46.570
And you might not be detecting
how to actually get rid of the

00:32:46.570 --> 00:32:48.400
rolling shutter in that case.

00:32:48.400 --> 00:32:48.650
MATTHIAS GRUNDMANN: Right.

00:32:48.650 --> 00:32:52.650
For those specialized cases,
we might not always do a

00:32:52.650 --> 00:32:56.130
perfect job because we strive
basically for this one click

00:32:56.130 --> 00:32:59.330
solution, with the absence
of any sliders.

00:32:59.330 --> 00:33:02.150
And so that might not be the
best use case for that.

00:33:02.150 --> 00:33:02.296
AUDIENCE: OK.

00:33:02.296 --> 00:33:02.640
Thanks.

00:33:02.640 --> 00:33:03.720
VIVEK KWATRA: Just to
add to that, it's a

00:33:03.720 --> 00:33:04.400
calibration free approach.

00:33:04.400 --> 00:33:06.350
So if we're doing it on YouTube

00:33:06.350 --> 00:33:08.530
after it has been uploaded.

00:33:08.530 --> 00:33:12.750
So we don't necessarily know
always which camera is used to

00:33:12.750 --> 00:33:13.350
compute that.

00:33:13.350 --> 00:33:16.460
So we need to know, or we need
to compute this information

00:33:16.460 --> 00:33:18.370
just based on the pixels.

00:33:18.370 --> 00:33:20.520
So we do as best as we can, but
we can always strive to

00:33:20.520 --> 00:33:23.130
improve it.

00:33:23.130 --> 00:33:24.240
AUDIENCE: Hi.

00:33:24.240 --> 00:33:28.020
So as you talk, you're using the
software measure to detect

00:33:28.020 --> 00:33:31.100
the motion of the film
or the camera, right?

00:33:31.100 --> 00:33:34.600
So is there any possibility in
the future that you can upload

00:33:34.600 --> 00:33:39.780
your motion vector with a video
to the YouTube so that

00:33:39.780 --> 00:33:43.968
you can just better stabilize
the video?

00:33:43.968 --> 00:33:46.260
MATTHIAS GRUNDMANN: John?

00:33:46.260 --> 00:33:49.210
JOHN GREGG: It's a good idea.

00:33:49.210 --> 00:33:51.050
I think it's something
that we think about.

00:33:51.050 --> 00:33:55.690
But right now it's too
complex, I guess.

00:33:55.690 --> 00:33:57.990
And we want to have a general
purpose solution that works

00:33:57.990 --> 00:33:59.870
even when we don't have
that information.

00:33:59.870 --> 00:34:01.490
So having the extra information

00:34:01.490 --> 00:34:03.262
would probably help.

00:34:03.262 --> 00:34:05.690
It's just a matter of working
it into the system.

00:34:05.690 --> 00:34:06.340
AUDIENCE: Right.

00:34:06.340 --> 00:34:08.110
And another question.

00:34:08.110 --> 00:34:13.199
So you upload the 1080p video,
and after the cropping, the

00:34:13.199 --> 00:34:14.400
video becomes smaller.

00:34:14.400 --> 00:34:18.620
But on the YouTube,
so we still are

00:34:18.620 --> 00:34:22.139
watching the 1080p video.

00:34:22.139 --> 00:34:24.250
So the quality drops
dramatically.

00:34:24.250 --> 00:34:30.580
So why are we still watching
in the 1080p definition?

00:34:30.580 --> 00:34:34.560
Because it's not the 1080p
definition anymore.

00:34:34.560 --> 00:34:34.830
JOHN GREGG: Right.

00:34:34.830 --> 00:34:36.699
We do scale the video
back up to the

00:34:36.699 --> 00:34:39.850
original size after cropping.

00:34:39.850 --> 00:34:41.540
So it appears to be the
same resolution.

00:34:41.540 --> 00:34:41.989
Although, you're right.

00:34:41.989 --> 00:34:46.630
There's a bit of a loss
of actual image data.

00:34:46.630 --> 00:34:49.300
VIVEK KWATRA: We do do some
sharpening on the video after

00:34:49.300 --> 00:34:50.090
scaling it.

00:34:50.090 --> 00:34:52.192
But yes, you do lose resolution
because you're

00:34:52.192 --> 00:34:53.440
cropping it.

00:34:53.440 --> 00:34:55.404
AUDIENCE: So that leads
into what I was

00:34:55.404 --> 00:34:57.050
going to ask about--

00:34:57.050 --> 00:35:00.680
effect this has on compression
quality because presumably,

00:35:00.680 --> 00:35:03.310
then the motion estimation that
the codec is doing is

00:35:03.310 --> 00:35:05.453
much simpler because you've
moved it into a more

00:35:05.453 --> 00:35:06.800
[INAUDIBLE] domain.

00:35:06.800 --> 00:35:09.122
And out with the domain where
the codec tends to fall over

00:35:09.122 --> 00:35:11.500
when you aren't doing
that to it.

00:35:11.500 --> 00:35:12.790
Did you notice that?

00:35:12.790 --> 00:35:18.680
The difference between the codec
performance is improved

00:35:18.680 --> 00:35:21.360
before and after this?

00:35:21.360 --> 00:35:23.880
I'm just interested if
you measured that.

00:35:23.880 --> 00:35:24.600
MATTHIAS GRUNDMANN: So,
I think, in principle,

00:35:24.600 --> 00:35:28.250
definitely having less shake in
the video should give you

00:35:28.250 --> 00:35:33.630
better compression performance
with lower bit rate.

00:35:33.630 --> 00:35:35.850
It would be interesting if you
would have actually the raw

00:35:35.850 --> 00:35:37.360
video available.

00:35:37.360 --> 00:35:39.890
We already have the encoded,
compressed video.

00:35:39.890 --> 00:35:41.840
So it might not be really
a benefit for us.

00:35:41.840 --> 00:35:44.090
AUDIENCE: Depends on what
it's shot with.

00:35:44.090 --> 00:35:45.920
If I uploaded an uncompressed
video.

00:35:45.920 --> 00:35:48.140
But yeah, most people already
give compressed.

00:35:48.140 --> 00:35:48.790
MATTHIAS GRUNDMANN: Right.

00:35:48.790 --> 00:35:50.290
So there might be some
benefit to it.

00:35:50.290 --> 00:35:52.730
AUDIENCE: So that leads me to
sort of another couple of

00:35:52.730 --> 00:35:56.200
questions, which is those videos
have motion vectors in.

00:35:56.200 --> 00:35:57.540
But they're probably really
bad because they've been

00:35:57.540 --> 00:35:58.720
estimated by a camera.

00:35:58.720 --> 00:36:01.240
So presumably you ignore those
and just look at pixels.

00:36:01.240 --> 00:36:04.070
But do you look at--

00:36:04.070 --> 00:36:09.780
once you've done your coplanar
recomposition of the thing,

00:36:09.780 --> 00:36:12.610
you could potentially
reconstruct better pixels

00:36:12.610 --> 00:36:16.910
across the motion from the fact
there are multiple shots

00:36:16.910 --> 00:36:18.260
of the same piece.

00:36:18.260 --> 00:36:22.260
So if there's some bit that's
been squished into low

00:36:22.260 --> 00:36:25.190
frequency because of the DCTs,
you could actually construct

00:36:25.190 --> 00:36:26.260
better pixels from a frame
going off this.

00:36:26.260 --> 00:36:28.350
I'm assuming you haven't
looked at that.

00:36:28.350 --> 00:36:29.610
But is that something you've
considered looking at?

00:36:32.240 --> 00:36:35.820
VIVEK KWATRA: That's
a good suggestion.

00:36:35.820 --> 00:36:37.790
We haven't necessarily looked
into that because we were just

00:36:37.790 --> 00:36:39.700
focused on the stabilization.

00:36:39.700 --> 00:36:43.610
That's sort of an additional
enhancement you could do.

00:36:43.610 --> 00:36:47.170
You could think of that as sort
of super resolution or--

00:36:47.170 --> 00:36:51.340
AUDIENCE: It's sort of like
HDR, but for sharpness.

00:36:51.340 --> 00:36:52.670
VIVEK KWATRA: And definitely
that's a good suggestion,

00:36:52.670 --> 00:36:54.730
something that can definitely
enhance a video.

00:36:54.730 --> 00:36:55.830
We'll have to think about.

00:36:55.830 --> 00:36:58.266
AUDIENCE: And that takes me to
sort of the third iteration of

00:36:58.266 --> 00:37:01.620
this thought, which is grumbling
about codecs.

00:37:01.620 --> 00:37:04.630
The codecs all have this stupid,
sort of dimensional

00:37:04.630 --> 00:37:07.790
squares moving around in space
models, whereas you're

00:37:07.790 --> 00:37:12.060
constructing a much more fluid
six degrees of freedom model

00:37:12.060 --> 00:37:15.140
for how the thing is moving,
which implies you construct a

00:37:15.140 --> 00:37:19.050
different kind of codec that
plays better with the GPU

00:37:19.050 --> 00:37:21.200
where you say OK, if we actually
understand how the

00:37:21.200 --> 00:37:23.860
camera's moving, we understand
what would be good triangles

00:37:23.860 --> 00:37:25.730
and textures, we could feed
something through to that.

00:37:25.730 --> 00:37:29.060
And people are starting to do
research on codecs that are

00:37:29.060 --> 00:37:33.130
written entirely in JavaScript
and WebGL to take

00:37:33.130 --> 00:37:34.050
advantage of that.

00:37:34.050 --> 00:37:36.780
I think this stuff will be
great to feed into that

00:37:36.780 --> 00:37:39.955
because if you start from a game
or something where you've

00:37:39.955 --> 00:37:42.350
already got the [? GL ?]
surfaces straightforward.

00:37:42.350 --> 00:37:45.030
But you seem to be doing a
fairly good job of saying, OK,

00:37:45.030 --> 00:37:45.960
this should be textured.

00:37:45.960 --> 00:37:48.810
And then we could decide where
the tri-meshes go depending on

00:37:48.810 --> 00:37:50.290
how coherent they are.

00:37:50.290 --> 00:37:51.740
This is the beginning
of a really

00:37:51.740 --> 00:37:54.290
interesting new kind of codec.

00:37:54.290 --> 00:37:54.765
MATTHIAS GRUNDMANN: Thank you.

00:37:54.765 --> 00:37:56.132
Yeah.

00:37:56.132 --> 00:37:56.613
VIVEK KWATRA: [INAUDIBLE]

00:37:56.613 --> 00:37:58.060
Thanks.

00:37:58.060 --> 00:38:00.200
AUDIENCE: So kind of
two questions.

00:38:00.200 --> 00:38:05.870
When you're reconstructing the
new smoothed camera path,

00:38:05.870 --> 00:38:12.150
there seems to be a loss of
parts where you have chosen to

00:38:12.150 --> 00:38:15.330
reconstruct it so it looks
like a professional

00:38:15.330 --> 00:38:20.650
photographer or so it follows
a particular, as you say, to

00:38:20.650 --> 00:38:23.310
keep a still image of
particular parts.

00:38:23.310 --> 00:38:28.460
So I was wondering how you
optimize within all of those

00:38:28.460 --> 00:38:33.370
constraints because it seems
like quite a big optimization

00:38:33.370 --> 00:38:35.460
problem to be doing
in real time.

00:38:35.460 --> 00:38:37.180
MATTHIAS GRUNDMANN: So we
haven't talked really about

00:38:37.180 --> 00:38:37.670
the details.

00:38:37.670 --> 00:38:43.000
But if you're familiar with
solving systems, usually

00:38:43.000 --> 00:38:45.120
people use something like
a least-square solver.

00:38:45.120 --> 00:38:48.180
This boils down to
a L1 solver.

00:38:48.180 --> 00:38:50.180
We have a little bit of the math
details, well actually

00:38:50.180 --> 00:38:52.990
all of the math details, up on
the Google research block and

00:38:52.990 --> 00:38:54.150
wrote a paper about it.

00:38:54.150 --> 00:38:56.880
So if you're really interested
on how that constraint

00:38:56.880 --> 00:38:59.200
solution works, how you set up
the equations, and how you

00:38:59.200 --> 00:39:01.880
find the solution, you're
more than welcome to

00:39:01.880 --> 00:39:03.150
check out that paper.

00:39:03.150 --> 00:39:06.100
AUDIENCE: And the other question
was is there any Open

00:39:06.100 --> 00:39:10.260
Source code for any parts of
this apart from the stuff

00:39:10.260 --> 00:39:14.650
that's commonly done like--

00:39:14.650 --> 00:39:15.850
MATTHIAS GRUNDMANN: It's
not Open Source.

00:39:15.850 --> 00:39:18.790
But it's this new API.

00:39:18.790 --> 00:39:22.050
And we encourage you to use that
so you can leverage all

00:39:22.050 --> 00:39:26.660
through this whole distributed
pipeline that we set up to do

00:39:26.660 --> 00:39:29.940
this in a highly scalable
and performant way.

00:39:29.940 --> 00:39:31.980
Thank you.

00:39:31.980 --> 00:39:32.290
AUDIENCE: Hey.

00:39:32.290 --> 00:39:33.050
Really cool talk.

00:39:33.050 --> 00:39:35.600
I was just curious it sounded
like you do linear segments

00:39:35.600 --> 00:39:37.800
with parabolic transitions
between them.

00:39:37.800 --> 00:39:41.220
Have you uploaded like real
Hollywood videos just to see

00:39:41.220 --> 00:39:43.690
what real cinema photographers
do as far as their curves?

00:39:43.690 --> 00:39:45.900
Or do different cinematographers
have slightly

00:39:45.900 --> 00:39:48.060
different curves where you could
apply it in the style of

00:39:48.060 --> 00:39:49.680
this person or that person?

00:39:49.680 --> 00:39:51.670
Have you done any of that sort
of analysis even just

00:39:51.670 --> 00:39:52.220
internally?

00:39:52.220 --> 00:39:53.990
MATTHIAS GRUNDMANN: That's
a great suggestion.

00:39:53.990 --> 00:39:57.535
Basically, I'd like to stress a
point, what we're doing here

00:39:57.535 --> 00:39:59.890
is we're trying to mimic
certain moves

00:39:59.890 --> 00:40:01.380
cinematographers do.

00:40:01.380 --> 00:40:03.090
And so these are really
just a constant,

00:40:03.090 --> 00:40:04.800
linear parabolic arcs.

00:40:04.800 --> 00:40:07.230
Cinematographers in many
settings, there's a very

00:40:07.230 --> 00:40:08.620
artistic note to it.

00:40:08.620 --> 00:40:11.170
So it's a good suggestion.

00:40:11.170 --> 00:40:13.900
But I think the space of camera
motions would be much

00:40:13.900 --> 00:40:14.870
more complex.

00:40:14.870 --> 00:40:17.310
And so we're not doing
exactly what a

00:40:17.310 --> 00:40:18.590
cinematographer would do.

00:40:18.590 --> 00:40:21.270
We're just mimicking these
certain moves here.

00:40:21.270 --> 00:40:21.870
AUDIENCE: Cool stuff.

00:40:21.870 --> 00:40:22.750
Thanks.

00:40:22.750 --> 00:40:25.395
VIVEK KWATRA: Thank you.

00:40:25.395 --> 00:40:27.462
MATTHIAS GRUNDMANN: Any
more questions?

00:40:27.462 --> 00:40:28.712
AUDIENCE: [INAUDIBLE].

00:40:33.260 --> 00:40:36.780
Following up on that last one,
you talked about dolly

00:40:36.780 --> 00:40:38.660
tracking and tripods.

00:40:38.660 --> 00:40:40.690
But there is a whole bunch
of other motion things.

00:40:40.690 --> 00:40:42.180
There's steadicam, there's
Louma cranes,

00:40:42.180 --> 00:40:43.600
and things like that.

00:40:43.600 --> 00:40:45.070
And they all have different
characteristics.

00:40:45.070 --> 00:40:47.070
So you can probably extend
the model of it there.

00:40:47.070 --> 00:40:49.770
The other fun thing would be to
say, if you've got a movie

00:40:49.770 --> 00:40:51.040
that's using this for effect--

00:40:51.040 --> 00:40:52.470
if you put "The Blair Witch
Project" through this, you

00:40:52.470 --> 00:40:54.110
make it a very different
movie.

00:40:54.110 --> 00:40:55.360
MATTHIAS GRUNDMANN: Correct.

00:40:57.130 --> 00:40:58.380
Thank you.

00:41:01.730 --> 00:41:02.010
JOHN GREGG: All right.

00:41:02.010 --> 00:41:02.910
Thanks everyone for coming.

00:41:02.910 --> 00:41:03.100
VIVEK KWATRA: Thank
you very much.

00:41:03.100 --> 00:41:04.350
MATTHIAS GRUNDMANN: Thank
you for coming.

