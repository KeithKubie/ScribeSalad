WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:02.719
Caching refers to storing the result of an operation so

00:00:02.719 --> 00:00:07.390
that future request return faster. Basically, if you do something once

00:00:07.390 --> 00:00:09.570
you know whether it's a database query or rendering some

00:00:09.570 --> 00:00:13.320
HTML or you know, anything that might be slow. You store

00:00:13.320 --> 00:00:15.070
the results so you don't have to do the computation

00:00:15.070 --> 00:00:18.430
a second time instead you can reference the previous result. So,

00:00:18.430 --> 00:00:21.450
when do we cache? We cache things when the underlying

00:00:21.450 --> 00:00:26.410
computation is slow, when the underlying computation will run multiple times.

00:00:26.410 --> 00:00:29.870
When the output of said computation is the same for

00:00:29.870 --> 00:00:32.009
a particular input, so that we know you know, we don't

00:00:32.009 --> 00:00:33.760
have to recompute it every time, because it's going to be the

00:00:33.760 --> 00:00:38.270
same every time; the output of this computation. And another good

00:00:38.270 --> 00:00:40.940
reason you know, for, for when we cache, when you are

00:00:40.940 --> 00:00:45.560
hosting provider charges for DB access, which applies to you right

00:00:45.560 --> 00:00:48.750
now. Google APP engine, gives you a fixed number of reads

00:00:48.750 --> 00:00:51.640
and writes to the data store in a particular day and

00:00:51.640 --> 00:00:53.970
if you go over that, you have to pay for it. Even

00:00:53.970 --> 00:00:57.050
if your app doesn't get a whole lot of traffic Caching request so

00:00:57.050 --> 00:00:59.860
they don't have to hit the database over and over is a

00:00:59.860 --> 00:01:03.040
fine way to save some money. And that will be an example we

00:01:03.040 --> 00:01:06.600
start with shortly. So, whenever you have a situation where you have

00:01:06.600 --> 00:01:07.880
the slow computation that you're running

00:01:07.880 --> 00:01:09.820
multiple times, with the same output over

00:01:09.820 --> 00:01:13.840
and over, you should cache it. You should store that result somewhere

00:01:13.840 --> 00:01:16.830
else. So that you don't have to run a computation over and over.

00:01:16.830 --> 00:01:19.570
So let's, let's talk about how that algorithm looks. Let's say

00:01:19.570 --> 00:01:22.830
we have a function called db_read(), and this reads from the database.

00:01:22.830 --> 00:01:25.970
And it's slow, you know, let's say it takes 100 ms to

00:01:25.970 --> 00:01:30.510
run this. This query which is slow for a database query but

00:01:30.510 --> 00:01:34.110
not unheard of. And, and you're serving thousands of requests, you know.

00:01:34.110 --> 00:01:36.570
If every request that comes in to, to your website has to

00:01:36.570 --> 00:01:39.400
hit db-read and that takes 100 milliseconds, that means you can only

00:01:39.400 --> 00:01:41.890
do ten requests a second or you start, you know, you start

00:01:41.890 --> 00:01:44.130
doing multiple requests at the same time and your database starts to get

00:01:44.130 --> 00:01:47.520
pummeled because it's trying to do this complicated query. All at the same time

00:01:47.520 --> 00:01:51.380
and, and this 100 milliseconds maybe turns in to 200 or 300 milliseconds,

00:01:51.380 --> 00:01:53.940
or 500 milliseconds, who knows, you know. When your database is under a load

00:01:53.940 --> 00:01:57.090
it starts to really get angry at you. So, if we wanted to

00:01:57.090 --> 00:01:59.320
cached this db read, let's talk about

00:01:59.320 --> 00:02:01.080
what this algorithm would look like. Prefer

00:02:01.080 --> 00:02:03.740
it a kind of write in, in sitor code here, we will have

00:02:03.740 --> 00:02:07.430
something that looks like this. If the request from making is in the cache,

00:02:07.430 --> 00:02:10.008
return the cache version of that request, and in this case,

00:02:10.008 --> 00:02:13.300
I'm pretending cache is, is like a dictionary and the request

00:02:13.300 --> 00:02:15.890
that we're making is the key into this dictionary. And that's

00:02:15.890 --> 00:02:18.740
generally the structure of the cache, the cache is basically a large,

00:02:18.740 --> 00:02:22.420
like a large hash table a large mapping of, of keys

00:02:22.420 --> 00:02:25.230
to values. Now you know all about hash tables a hash table

00:02:25.230 --> 00:02:27.680
works perfectly well for this. So, if a request is in

00:02:27.680 --> 00:02:33.450
the cache. Returned Cache value of that request, Else start the value

00:02:33.450 --> 00:02:35.980
of this DB Read in a variable, put that variable

00:02:35.980 --> 00:02:40.110
in the cache for future look ups. And then return that

00:02:40.110 --> 00:02:43.320
variable. So basically, instead of calling DB Read on every

00:02:43.320 --> 00:02:45.440
request, the first thing we do is check to see if

00:02:45.440 --> 00:02:48.120
that request is in our Cache And if it is,

00:02:48.120 --> 00:02:50.940
we return the cached value. This is called a cache hit.

00:02:50.940 --> 00:02:55.200
And only if this request isn't in our cache do we

00:02:55.200 --> 00:02:59.640
actually return our query. And this is called a cache miss.

00:02:59.640 --> 00:03:01.680
And what we do on a cache miss is we actually do

00:03:01.680 --> 00:03:06.420
operation, and store the result of the operation in our cache, and

00:03:06.420 --> 00:03:09.110
then return that result. So future requests will just bounce off the

00:03:09.110 --> 00:03:12.390
cache. Hash. Now if you're using a hash table, depending on the

00:03:12.390 --> 00:03:14.820
size of that hash table. We're going to probably do a lot better

00:03:14.820 --> 00:03:18.250
than 100 milliseconds, we're probably going to be talking about less than 1

00:03:18.250 --> 00:03:21.490
millisecond. Which would be you know, quite a big speed improvement. Now

00:03:21.490 --> 00:03:24.670
of course this hash table is huge and you're caching lots of things.

00:03:24.670 --> 00:03:28.220
You know, hash table have their own Performance characteristics that you'll

00:03:28.220 --> 00:03:30.430
have to take into account. But you know, you can get

00:03:30.430 --> 00:03:33.610
substantial improvements just by taking the slow pices of your code

00:03:33.610 --> 00:03:36.860
and wrapping this simple algorithm around it, which is the focus of

00:03:36.860 --> 00:03:41.030
our next quiz. What I'd like you to do is implement

00:03:41.030 --> 00:03:43.930
that caching algorithm here in Python. So, what I've given you

00:03:43.930 --> 00:03:47.620
is a function called Complex Computation. And this takes two numbers

00:03:47.620 --> 00:03:49.770
and it adds them up. But it's going to take half a second

00:03:49.770 --> 00:03:53.460
to do so. The time dot sleep function causes Python

00:03:53.460 --> 00:03:56.910
to just sleep or wait for however much time you want.

00:03:56.910 --> 00:03:58.680
In this case, I have it sleep for half a

00:03:58.680 --> 00:04:00.860
second. So, what I want you to do is use a

00:04:00.860 --> 00:04:03.830
dictionary as a cache. And it's defined right here as,

00:04:03.830 --> 00:04:07.860
called cache. I want you to make this function cache computation.

00:04:07.860 --> 00:04:11.460
Use this cache to store the results of calling complex

00:04:11.460 --> 00:04:14.960
computation on different inputs. So if we pass in the same

00:04:14.960 --> 00:04:20.589
inputs a and b twice, I want the second running of this function to use the

00:04:20.589 --> 00:04:22.720
cache. The first one, we'll do the actual

00:04:22.720 --> 00:04:26.440
computation. And we'll be grading this by running picking

00:04:26.440 --> 00:04:29.460
different values of a and b, seeing how long the first one takes to run and then

00:04:29.460 --> 00:04:30.690
seeing how long the second one takes to

00:04:30.690 --> 00:04:32.740
run. And the second one should run substantially faster.

