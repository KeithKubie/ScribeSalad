WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:03.790
Hello and welcome to Crash Course: Navigating
Digital Information.

00:00:03.790 --> 00:00:08.550
My name is John Green, and you may know me
from my various channels on YouTube, all caps

00:00:08.550 --> 00:00:14.320
tweets about Liverpool Football Club, Q&amp;As
about books on my website, or elsewhere on

00:00:14.320 --> 00:00:15.320
the internet.

00:00:15.320 --> 00:00:17.789
I spend a /lot/ of time online.

00:00:17.789 --> 00:00:20.480
In fact, in some ways, I live here.

00:00:20.480 --> 00:00:25.829
The average American spends 24 hours per week
online, but one in four U.S. adults say that

00:00:25.829 --> 00:00:28.859
they are online almost constantly.

00:00:28.859 --> 00:00:29.859
And I am among them.

00:00:29.859 --> 00:00:33.910
I love the Internet--it contains so much helpful
information; it connects us to each other;

00:00:33.910 --> 00:00:37.680
it allows more people to have a voice in public
conversations.

00:00:37.680 --> 00:00:42.480
But of course, the Internet is also littered
with misleading, sensationalized, and downright

00:00:42.480 --> 00:00:43.480
false information.

00:00:43.480 --> 00:00:44.480
So, OK.

00:00:44.480 --> 00:00:45.550
I only know two jokes.

00:00:45.550 --> 00:00:49.171
I’ll tell the other one at the end of the
series, but here’s the first one, which

00:00:49.171 --> 00:00:52.020
was made famous by the American writer David
Foster Wallace:

00:00:52.020 --> 00:00:57.140
Two young fish are swimming along one day
when an older fish swims past and says, “‘Morning,

00:00:57.140 --> 00:00:58.140
kids.

00:00:58.140 --> 00:00:59.140
How’s the water?’

00:00:59.140 --> 00:01:03.130
The young fish just look at each other for
a second and then swim on for a while, and

00:01:03.130 --> 00:01:06.010
then one says to the other, ‘What the heck
is water?’”

00:01:06.010 --> 00:01:09.450
Now I am not the wise old fish of this enterprise.

00:01:09.450 --> 00:01:13.110
I am as susceptible to misleading information
as anyone.

00:01:13.110 --> 00:01:17.909
I tend to focus on information that reinforces
my pre-existing worldview, and to passively

00:01:17.909 --> 00:01:23.649
ingest all kinds of media while scrolling
and swiping endlessly through my feeds.

00:01:23.649 --> 00:01:28.399
But I also think we ought to be suspicious
of anyone who claims to be the wise old fish

00:01:28.399 --> 00:01:32.130
with some special understanding of what we’re
swimming in.

00:01:32.130 --> 00:01:36.890
Believing that you’re immune to the seductions
of false and misleading information is, if

00:01:36.890 --> 00:01:41.630
anything, a symptom of being influenced by
false and misleading information.

00:01:41.630 --> 00:01:46.249
I tell this joke for two reasons: First, because
I need you to call me out if I start acting

00:01:46.249 --> 00:01:51.670
like the wise old fish, and second, to point
out that much of what we’re swimming in

00:01:51.670 --> 00:01:56.689
is new and strange--and we’re still figuring
it out together.

00:01:56.689 --> 00:02:01.340
So, for this series, Crash Course has teamed
up with MediaWise, a project out of the Poynter

00:02:01.340 --> 00:02:04.329
Institute that was created with support from
Google.

00:02:04.329 --> 00:02:07.380
The Poynter Institute is a non-profit journalism
school.

00:02:07.380 --> 00:02:13.140
The goal of MediaWise is to teach students
how to assess the accuracy of information

00:02:13.140 --> 00:02:14.600
they encounter online.

00:02:14.600 --> 00:02:18.470
The MediaWise curriculum was developed by
the Stanford History Education Group based

00:02:18.470 --> 00:02:22.530
on civic online reasoning research that they
began in 2015.

00:02:22.530 --> 00:02:27.730
Other MediaWise project partners include the
Local Media Association and the National Association

00:02:27.730 --> 00:02:29.450
for Media Literacy Education.

00:02:29.450 --> 00:02:33.510
I’m saying all that, and I’ll say it again,
because I think it’s important to understand

00:02:33.510 --> 00:02:37.640
where this information about information came
from.

00:02:37.640 --> 00:02:41.360
Over the next ten episodes, we’re going
to dive deeply into the feed and share some

00:02:41.360 --> 00:02:46.360
tools that are proven to work when it comes
to evaluating the quality and accuracy of

00:02:46.360 --> 00:02:47.480
information.

00:02:47.480 --> 00:02:52.980
We may not figure out exactly what water is,
but we’re going to try to learn to improve

00:02:52.980 --> 00:02:53.980
our swimming.

00:02:53.980 --> 00:02:55.630
Stan, have we rolled the intro yet?

00:02:55.630 --> 00:02:57.850
We’re MULTIPLE minutes into the video.

00:02:57.850 --> 00:02:58.850
Roll the intro!

00:02:58.850 --> 00:03:09.120
INTRO
When you want to see what your friends are

00:03:09.120 --> 00:03:13.330
up to, you might head to Snapchat, WhatsApp,
Instagram or maybe /Fin/stagram.

00:03:13.330 --> 00:03:17.090
I don’t get that joke but young people in
the office said that it is funny.

00:03:17.090 --> 00:03:20.990
And then when you want the news, you may wait
to be startled by a push alert from a news

00:03:20.990 --> 00:03:23.910
app, or you might go to twitter, or snapchat,
or reddit.

00:03:23.910 --> 00:03:29.201
And when you need to settle a feud over how
to pronounce g-i-f, or possibly gee-i-f, you

00:03:29.201 --> 00:03:30.740
just use a search engine.

00:03:30.740 --> 00:03:35.730
These habits all feel quite natural to me,
but in fact they are part of a huge shift

00:03:35.730 --> 00:03:40.020
in how humans find, and produce, and share
information.

00:03:40.020 --> 00:03:45.680
Just a short time ago, the production of information
was controlled by a much smaller group of

00:03:45.680 --> 00:03:46.680
people.

00:03:46.680 --> 00:03:50.190
Instead of Googling movie times, you had to
buy a newspaper or call the movie theater

00:03:50.190 --> 00:03:53.110
and risk talking to an actual human being.

00:03:53.110 --> 00:03:57.740
To write a research paper, you had to hunker
down in the library, not for the outlets and

00:03:57.740 --> 00:04:01.370
the free Wifi but for the access to Encyclopedias
and books.

00:04:01.370 --> 00:04:04.880
Now I should note that there’s a lot of
information that’s not available online,

00:04:04.880 --> 00:04:07.650
and that is available at your library.

00:04:07.650 --> 00:04:11.220
Libraries continue to be incredibly valuable
resources.

00:04:11.220 --> 00:04:16.340
But these days, anyone can hop online and
produce information via their personal website,

00:04:16.340 --> 00:04:18.430
social media, or YouTube channel.

00:04:18.430 --> 00:04:20.310
Well, actually, no.

00:04:20.310 --> 00:04:25.430
Access to digital devices and high-speed Internet
is still a real barrier to entry for many

00:04:25.430 --> 00:04:28.780
people, which means unequal access to information.

00:04:28.780 --> 00:04:34.340
It also means that while it can feel like
everyone is participating in facebook or instagram,

00:04:34.340 --> 00:04:38.090
in fact billions of people are not part of
those conversations.

00:04:38.090 --> 00:04:44.800
Still, the barrier for creating and retrieving
information is much lower than it was a generation

00:04:44.800 --> 00:04:45.800
ago.

00:04:45.800 --> 00:04:49.630
Like, when I was a kid, if you wanted to share
an opinion with the public, you wrote a letter

00:04:49.630 --> 00:04:52.800
to the newspaper and hoped they would publish
it.

00:04:52.800 --> 00:04:57.390
There was no other way for a stranger to hear
your story or your perspective.

00:04:57.390 --> 00:05:01.150
Furthermore, as you already know from the
three DMs you’ve answered since you started

00:05:01.150 --> 00:05:03.950
this video, the internet changed how we communicate.

00:05:03.950 --> 00:05:06.590
We can talk across time and space.

00:05:06.590 --> 00:05:11.460
We can connect across geographical and political
boundaries, we can create organizations and

00:05:11.460 --> 00:05:16.700
communities, find people with similar interests,
or we can lift people up when they feel alone.

00:05:16.700 --> 00:05:21.290
But, when information flows this freely, dangers
are inevitable.

00:05:21.290 --> 00:05:25.460
Misinformation -- unintentionally incorrect
information -- and disinformation -- information

00:05:25.460 --> 00:05:28.740
that’s wrong on purpose -- spread quickly
online.

00:05:28.740 --> 00:05:30.360
As do hate speech and propaganda.

00:05:30.360 --> 00:05:36.690
Plus, we can easily create online worlds where
we only see information we already agree with,

00:05:36.690 --> 00:05:38.670
or that lines up with our point of view.

00:05:38.670 --> 00:05:43.100
For instance, if I only followed people on
Twitter who were Team Blake, I would have

00:05:43.100 --> 00:05:45.669
been pretty blindsided when Garrett won The
Bachelorette.

00:05:45.669 --> 00:05:49.760
The same could be said for, say, actual elections.

00:05:49.760 --> 00:05:54.830
And because we use information for all kinds
of decisions, misinformation and disinformation

00:05:54.830 --> 00:05:57.040
are powerful.

00:05:57.040 --> 00:06:02.669
This is true for small everyday decisions--restaurant
reviews affect where we eat--and for much

00:06:02.669 --> 00:06:07.050
larger issues, like choosing a college to
attend or a place to work..

00:06:07.050 --> 00:06:12.180
The quality of our information directly shapes
the quality of our decisions.

00:06:12.180 --> 00:06:18.180
And the quality of our decisions, of course,
shapes the quality of our shared experience

00:06:18.180 --> 00:06:21.290
as humans
So, when we talk about [air quotes] “bad”

00:06:21.290 --> 00:06:25.380
or questionable information, that includes
fake news.

00:06:25.380 --> 00:06:28.389
The kind of news reporting that is /totally/
false.

00:06:28.389 --> 00:06:32.820
Which is a huge problem, especially on social
media and during breaking news events.

00:06:32.820 --> 00:06:36.590
And it’s a problem across all political
ideologies and perspectives.

00:06:36.590 --> 00:06:39.500
But we’re not just talking about fake news.

00:06:39.500 --> 00:06:43.570
We’re also talking about information that
isn’t credible because the author of that

00:06:43.570 --> 00:06:45.870
content isn’t an authority on the topic.

00:06:45.870 --> 00:06:51.880
Take a blog of serious-sounding fitness tips
from someone who loves gym selfies but isn’t

00:06:51.880 --> 00:06:53.760
qualified to give professional health advice.

00:06:53.760 --> 00:06:57.669
We’re also talking about information that
comes from writers or organizations that have

00:06:57.669 --> 00:07:00.240
something to lose from the whole truth.

00:07:00.240 --> 00:07:06.340
Like a company that sells toasters creating
BestToasters.com to publish lists of the “best”

00:07:06.340 --> 00:07:09.820
toasters, with their brand at the top of every
list.

00:07:09.820 --> 00:07:14.669
Or friends who conveniently find videos that
supposedly [air quotes] “prove” gif is

00:07:14.669 --> 00:07:18.300
pronounced gif when you know that gif is pronounced
gif.

00:07:18.300 --> 00:07:21.220
But the thing is, quality of information lies
on a spectrum.

00:07:21.220 --> 00:07:25.360
It’s not a duality, good information and
bad information.

00:07:25.360 --> 00:07:31.169
It is our job to evaluate the information
that we receive, find out where it falls on

00:07:31.169 --> 00:07:34.600
that spectrum, and decide how to use it going
forward.

00:07:34.600 --> 00:07:40.050
But as a species, we are not particularly
good at judging the quality of information

00:07:40.050 --> 00:07:41.100
on the internet.

00:07:41.100 --> 00:07:43.190
In fact, we’ve always been bad at it.

00:07:43.190 --> 00:07:48.760
In 2002, a study with over 2,000 participants[1]
reported that a website’s /design/ was the

00:07:48.760 --> 00:07:53.070
most frequently mentioned factor in judging
a website’s credibility.

00:07:53.070 --> 00:07:58.330
When asked to choose which of two sites was
more credible, 46% of participants used the

00:07:58.330 --> 00:08:01.419
look of the website in their evaluations.

00:08:01.419 --> 00:08:06.139
Adults and young people alike still typically
evaluate information based on factors unrelated

00:08:06.139 --> 00:08:11.870
to its content: how it looks, whether they’ve
used it before or who referred them to it.

00:08:11.870 --> 00:08:17.130
In 2016, our friends at the Stanford History
Education Group released a study of over 7,000

00:08:17.130 --> 00:08:19.699
middle school, high school, and college students.

00:08:19.699 --> 00:08:23.979
When asked to evaluate online information,
they based their evaluations on a site’s

00:08:23.979 --> 00:08:25.080
look and feel.

00:08:25.080 --> 00:08:31.080
They focused on things that a website creator
could easily change, like the URL or the About

00:08:31.080 --> 00:08:32.080
page.

00:08:32.080 --> 00:08:34.780
Spoiler alert: that technique doesn’t work
well.

00:08:34.780 --> 00:08:40.149
One of the things that participants had to
do was judge minimumwage.com, a site about

00:08:40.149 --> 00:08:42.659
-- you guessed it -- the minimum wage.

00:08:42.659 --> 00:08:47.470
It claimed to bust myths behind the minimum
wage, listing ways that raising it would hurt

00:08:47.470 --> 00:08:48.540
the economy.

00:08:48.540 --> 00:08:53.220
Many students never discovered that that site
was by a public relations firm working for

00:08:53.220 --> 00:08:56.420
a group that wants to keep minimum wages low.

00:08:56.420 --> 00:09:01.020
The firm represents industries that stand
to benefit from paying employees less.

00:09:01.020 --> 00:09:05.850
In other words, the creator of this website
has something to lose by telling both sides

00:09:05.850 --> 00:09:07.640
of the minimum wage debate.

00:09:07.640 --> 00:09:10.060
So we can’t fully trust them to do so.

00:09:10.060 --> 00:09:11.960
Let’s go to the Thought Bubble.

00:09:11.960 --> 00:09:16.060
During the study, some students also felt
the presence of certain types of content on

00:09:16.060 --> 00:09:18.210
a website meant that it was more reliable.

00:09:18.210 --> 00:09:21.600
Like, when students found something they thought
was evidence on a page --

00:09:21.600 --> 00:09:26.910
a statistic or an anecdote, perhaps --
they assumed that meant the entire page was

00:09:26.910 --> 00:09:28.220
more reliable.

00:09:28.220 --> 00:09:32.130
And they often didn’t check the sources,
because, you know, it’s the Internet.

00:09:32.130 --> 00:09:33.200
People never check sources.

00:09:33.200 --> 00:09:37.440
For example, participants also looked at an
article that was actually an advertisement

00:09:37.440 --> 00:09:38.980
for Shell Oil[2].

00:09:38.980 --> 00:09:44.800
70% of high school students rated it as more
reliable than a traditional news story.

00:09:44.800 --> 00:09:45.960
Why?

00:09:45.960 --> 00:09:48.080
Because of this pie chart at the top.

00:09:48.080 --> 00:09:52.380
Statistics and infographics are often easy
and effective ways to communicate facts and

00:09:52.380 --> 00:09:53.380
evidence.

00:09:53.380 --> 00:09:55.350
But that doesn’t mean all charts are trustworthy.

00:09:55.350 --> 00:09:56.990
Like, here’s another chart.

00:09:56.990 --> 00:10:00.800
It says that, 96% of the time, the sky is
green.

00:10:00.800 --> 00:10:06.390
The /existence/ of this chart is no more proof
of its validity than, say, a spooky noise

00:10:06.390 --> 00:10:08.580
is proof that your house is haunted.

00:10:08.580 --> 00:10:11.140
But back to the Stanford History Education
Group study.

00:10:11.140 --> 00:10:16.830
Over 80% of middle school students didn’t
correctly identify that this was an ad, either,

00:10:16.830 --> 00:10:20.370
even though it was labeled “Sponsored Content.”

00:10:20.370 --> 00:10:25.240
Sponsored content means a company paid the
publication for a space on its site, hoping

00:10:25.240 --> 00:10:28.880
to advertise with a post that /looks/ like
a news article.

00:10:28.880 --> 00:10:33.370
And as you may know, sponsored content shapes
a lot of discourse on YouTube.

00:10:33.370 --> 00:10:37.910
And it’s effective advertising, because
many of us can’t help but believe that what

00:10:37.910 --> 00:10:41.690
looks like a news article must in fact be
one.

00:10:41.690 --> 00:10:42.800
Thanks, Thought Bubble.

00:10:42.800 --> 00:10:46.050
You might argue that the students in that
study are still learning.

00:10:46.050 --> 00:10:49.950
They’ll probably be better at it when they
get older.

00:10:49.950 --> 00:10:55.140
Well, the Stanford History Education Group
also tested historians with PhDs, first year

00:10:55.140 --> 00:11:00.120
college students from a pretty fancy university,
and professional fact checkers from major

00:11:00.120 --> 00:11:01.860
news organizations.

00:11:01.860 --> 00:11:05.839
Fact checkers are the people who go through
each bit of copy in a news story to make sure

00:11:05.839 --> 00:11:07.860
that all the facts are accurate.

00:11:07.860 --> 00:11:10.410
There are far too few of them in this world.

00:11:10.410 --> 00:11:16.320
But anyway, how effectively would you guess
these three groups evaluated information quality?

00:11:16.320 --> 00:11:21.500
Although both the professors and the students
have achieved academic success and are smart,

00:11:21.500 --> 00:11:25.170
thoughtful people, they also didn’t do well
with the experiment.

00:11:25.170 --> 00:11:29.940
When evaluating online sources, they also
focused on superficial things like the sites’

00:11:29.940 --> 00:11:34.190
layout, how much content the site had, and
whether it linked to other sites.

00:11:34.190 --> 00:11:39.390
They focused largely on appearance and the
/presence/ of things like evidence and links,

00:11:39.390 --> 00:11:42.110
not their content or their value.

00:11:42.110 --> 00:11:45.950
And those strategies might have worked in
the early days of the internet, but things

00:11:45.950 --> 00:11:52.560
are much more complicated, and there are many
misleading or false stories cite sources that

00:11:52.560 --> 00:11:57.810
either don’t say what they’re purported
to say, or are themselves also false.

00:11:57.810 --> 00:11:59.480
It’s misinformation all the way down.

00:11:59.480 --> 00:12:02.860
So, who /did/ sort out the misinformation
from the good info?

00:12:02.860 --> 00:12:03.900
The fact-checkers!

00:12:03.900 --> 00:12:07.940
I mean, that is literally their jobs, but
it’s nice to know they were good at it.

00:12:07.940 --> 00:12:13.060
The fact-checkers did well because they employed
a variety of carefully honed skills to decipher

00:12:13.060 --> 00:12:14.730
fact from fiction.

00:12:14.730 --> 00:12:19.820
And we are going to learn those skills together
from the fact-checkers in the next episode.

00:12:19.820 --> 00:12:22.870
Also the one after that, and the one after
that and the one after that.

00:12:22.870 --> 00:12:23.870
We’re going to fact checker school!

00:12:23.870 --> 00:12:28.390
In the meantime, if you’re interested in
learning more about MediaWise and fact-checking,

00:12:28.390 --> 00:12:31.050
you can visit @mediawisetips on Instagram.

00:12:31.050 --> 00:12:33.760
Thanks for swimming with me.

00:12:33.760 --> 00:12:34.820
I’ll see you next time.

00:12:34.820 --> 00:12:37.640
For this series, Crash Course has teamed up
with MediaWise, a project out of the Poynter

00:12:37.640 --> 00:12:39.470
Institute that was created with support from
Google.

00:12:39.470 --> 00:12:41.110
The Poynter Institute is a non-profit journalism
school.

00:12:41.110 --> 00:12:44.350
The goal of MediaWise is to teach students
how to assess the accuracy of information

00:12:44.350 --> 00:12:45.990
they encounter online.

00:12:45.990 --> 00:12:52.550
The MediaWise curriculum was developed by
the Stanford History Education Group based

00:12:52.550 --> 00:12:58.019
on civic online reasoning research that they
began in 2015.

00:12:58.019 --> 00:13:05.120
If you’re interested in learning more about
MediaWise and fact-checking, you can visit

00:13:05.120 --> 00:13:06.760
@mediawisetips on Instagram.

00:13:06.760 --> 00:13:08.399
________________
[1] https://dejanseo.com.au/media/pdf/credibility-online.pdf

00:13:08.399 --> 00:13:09.490
[2] https://sheg.stanford.edu/civic-online-reasoning/comparing-articles

