WEBVTT
Kind: captions
Language: en

00:00:00.450 --> 00:00:04.080
So let's look at the system
that is not even unusual,

00:00:04.080 --> 00:00:07.560
that combines all of these
three forms of parallelism.

00:00:07.560 --> 00:00:12.650
So we can have a dual socket motherboard
that has two chips with four cores on

00:00:12.650 --> 00:00:17.160
each chip, and each core can
simultaneously run two threads,

00:00:17.160 --> 00:00:19.260
using simultaneous multi-threading.

00:00:19.260 --> 00:00:23.690
So as far as the programmer is concerned
and as far as the operating system is

00:00:23.690 --> 00:00:29.560
concerned, what we really have
is two times four times two.

00:00:29.560 --> 00:00:33.120
Which means that 16 threads,
or for that matter,

00:00:33.120 --> 00:00:37.010
16 different single-threaded
programs can run simultaneously.

00:00:37.010 --> 00:00:41.460
And a relatively simple operating
system would just treat these

00:00:41.460 --> 00:00:44.900
as 16 largely equivalent cores.

00:00:44.900 --> 00:00:47.570
This can be a big problem.

00:00:47.570 --> 00:00:51.920
Because let's say that we actually have
three threads, and the operating system

00:00:51.920 --> 00:00:57.850
not knowing any better, just maps them
to the first three threads that it has.

00:00:57.850 --> 00:01:01.700
But it turns out that these two
are really threads on the same

00:01:01.700 --> 00:01:03.840
core that compete with each other for

00:01:03.840 --> 00:01:07.150
issue slots and other things
in an out of order processor.

00:01:07.150 --> 00:01:11.270
And then,
really the first half of these threads,

00:01:11.270 --> 00:01:14.245
eight of them,
are really on the same chip.

00:01:14.245 --> 00:01:19.015
So we're using only half of the overall
cache capacity that the system has.

00:01:19.015 --> 00:01:23.255
Pretty much, we have a very large cache
in the other chip that we are not using.

00:01:23.255 --> 00:01:28.012
So, a much smarter policy for
using three threads would be

00:01:28.012 --> 00:01:31.982
to put them on different
chips if we can and

00:01:31.982 --> 00:01:36.832
definitely on different cores if we can,
so that they don't compete.

00:01:36.832 --> 00:01:40.126
So the idea would be that
you would first run threads

00:01:40.126 --> 00:01:41.906
such that they're
distributed among the chips,

00:01:41.906 --> 00:01:45.996
so that you maximize the cache
capacity that you're benefiting from.

00:01:45.996 --> 00:01:50.816
Then we also want to make sure that
the first map a thread to each core.

00:01:50.816 --> 00:01:53.926
And only then do we want to actually map

00:01:53.926 --> 00:01:56.920
threads to the second
thread in each core.

00:01:56.920 --> 00:01:58.810
So that if there are fewer threads,

00:01:58.810 --> 00:02:01.330
they don't need to share
the resources of the same core.

00:02:01.330 --> 00:02:03.110
Each gets its own core.

00:02:03.110 --> 00:02:07.100
And that requires the operating system
to actually know what's going on.

00:02:07.100 --> 00:02:10.889
So most of the well known operating
systems like Windows, and Linux, and

00:02:10.889 --> 00:02:14.320
so on, will actually be
able to figure this out.

00:02:14.320 --> 00:02:18.970
But that means that as we have this
fancy hardware that has pluralism

00:02:18.970 --> 00:02:21.210
at different levels of granularity,

00:02:21.210 --> 00:02:24.590
we also have to make our
operating systems aware of that.

00:02:24.590 --> 00:02:27.380
So it's not just expose

00:02:27.380 --> 00:02:30.760
more thread contexts that
the operating system can use.

00:02:30.760 --> 00:02:34.250
It actually matters how you
use this thread context.

