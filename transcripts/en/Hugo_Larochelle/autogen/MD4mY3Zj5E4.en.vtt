WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:03.649 align:start position:0%
 
in<00:00:00.840><c> this</c><00:00:01.560><c> video</c><00:00:01.800><c> we'll</c><00:00:02.070><c> discuss</c><00:00:02.939><c> and</c><00:00:03.149><c> contrast</c>

00:00:03.649 --> 00:00:03.659 align:start position:0%
in this video we'll discuss and contrast
 

00:00:03.659 --> 00:00:06.070 align:start position:0%
in this video we'll discuss and contrast
two<00:00:04.020><c> different</c><00:00:04.440><c> types</c><00:00:04.740><c> of</c><00:00:05.069><c> learning</c>

00:00:06.070 --> 00:00:06.080 align:start position:0%
two different types of learning
 

00:00:06.080 --> 00:00:10.629 align:start position:0%
two different types of learning
discriminative<00:00:07.080><c> and</c><00:00:07.379><c> generative</c><00:00:08.130><c> learning</c>

00:00:10.629 --> 00:00:10.639 align:start position:0%
 
 

00:00:10.639 --> 00:00:15.140 align:start position:0%
 
so<00:00:11.900><c> we'll</c><00:00:12.900><c> say</c><00:00:13.349><c> that</c><00:00:13.559><c> a</c><00:00:13.740><c> learning</c><00:00:14.670><c> algorithm</c>

00:00:15.140 --> 00:00:15.150 align:start position:0%
so we'll say that a learning algorithm
 

00:00:15.150 --> 00:00:17.570 align:start position:0%
so we'll say that a learning algorithm
corresponds<00:00:16.109><c> to</c><00:00:16.170><c> a</c><00:00:16.619><c> discriminative</c><00:00:17.490><c> learning</c>

00:00:17.570 --> 00:00:17.580 align:start position:0%
corresponds to a discriminative learning
 

00:00:17.580 --> 00:00:20.660 align:start position:0%
corresponds to a discriminative learning
algorithm<00:00:18.390><c> if</c><00:00:18.600><c> it's</c><00:00:19.199><c> trying</c><00:00:19.470><c> to</c><00:00:19.680><c> optimize</c><00:00:20.310><c> a</c>

00:00:20.660 --> 00:00:20.670 align:start position:0%
algorithm if it's trying to optimize a
 

00:00:20.670 --> 00:00:23.269 align:start position:0%
algorithm if it's trying to optimize a
conditional<00:00:21.570><c> likelihood</c><00:00:22.020><c> that</c><00:00:22.380><c> is</c><00:00:22.680><c> if</c><00:00:23.010><c> it's</c>

00:00:23.269 --> 00:00:23.279 align:start position:0%
conditional likelihood that is if it's
 

00:00:23.279 --> 00:00:25.939 align:start position:0%
conditional likelihood that is if it's
trying<00:00:23.640><c> to</c><00:00:24.199><c> optimize</c><00:00:25.199><c> the</c><00:00:25.410><c> last</c><00:00:25.710><c> function</c>

00:00:25.939 --> 00:00:25.949 align:start position:0%
trying to optimize the last function
 

00:00:25.949 --> 00:00:29.599 align:start position:0%
trying to optimize the last function
which<00:00:26.310><c> looks</c><00:00:26.580><c> at</c><00:00:27.590><c> minus</c><00:00:28.590><c> the</c><00:00:28.740><c> log</c><00:00:28.980><c> of</c><00:00:29.340><c> the</c>

00:00:29.599 --> 00:00:29.609 align:start position:0%
which looks at minus the log of the
 

00:00:29.609 --> 00:00:32.359 align:start position:0%
which looks at minus the log of the
probability<00:00:29.849><c> of</c><00:00:30.330><c> the</c><00:00:30.539><c> true</c><00:00:30.720><c> target</c><00:00:31.199><c> given</c><00:00:31.859><c> X</c>

00:00:32.359 --> 00:00:32.369 align:start position:0%
probability of the true target given X
 

00:00:32.369 --> 00:00:34.280 align:start position:0%
probability of the true target given X
so<00:00:33.059><c> for</c><00:00:33.180><c> instance</c><00:00:33.540><c> conditional</c><00:00:34.170><c> random</c>

00:00:34.280 --> 00:00:34.290 align:start position:0%
so for instance conditional random
 

00:00:34.290 --> 00:00:36.440 align:start position:0%
so for instance conditional random
fields<00:00:34.860><c> are</c><00:00:35.010><c> usually</c><00:00:35.670><c> trained</c><00:00:36.120><c> in</c><00:00:36.360><c> a</c>

00:00:36.440 --> 00:00:36.450 align:start position:0%
fields are usually trained in a
 

00:00:36.450 --> 00:00:38.330 align:start position:0%
fields are usually trained in a
conditional<00:00:36.989><c> way</c><00:00:37.170><c> and</c><00:00:37.380><c> actually</c><00:00:38.219><c> always</c>

00:00:38.330 --> 00:00:38.340 align:start position:0%
conditional way and actually always
 

00:00:38.340 --> 00:00:40.400 align:start position:0%
conditional way and actually always
train<00:00:38.730><c> conditionally</c><00:00:39.719><c> because</c><00:00:40.110><c> a</c>

00:00:40.400 --> 00:00:40.410 align:start position:0%
train conditionally because a
 

00:00:40.410 --> 00:00:42.740 align:start position:0%
train conditionally because a
conditional<00:00:41.219><c> random</c><00:00:41.309><c> field</c><00:00:41.670><c> only</c><00:00:41.820><c> defines</c><00:00:42.450><c> a</c>

00:00:42.740 --> 00:00:42.750 align:start position:0%
conditional random field only defines a
 

00:00:42.750 --> 00:00:44.830 align:start position:0%
conditional random field only defines a
conditional<00:00:43.379><c> distribution</c><00:00:43.649><c> it</c><00:00:44.219><c> actually</c>

00:00:44.830 --> 00:00:44.840 align:start position:0%
conditional distribution it actually
 

00:00:44.840 --> 00:00:47.560 align:start position:0%
conditional distribution it actually
doesn't<00:00:45.840><c> really</c><00:00:46.200><c> look</c><00:00:46.440><c> at</c><00:00:46.590><c> defining</c><00:00:46.980><c> a</c>

00:00:47.560 --> 00:00:47.570 align:start position:0%
doesn't really look at defining a
 

00:00:47.570 --> 00:00:50.630 align:start position:0%
doesn't really look at defining a
distribution<00:00:48.570><c> just</c><00:00:48.600><c> over</c><00:00:49.410><c> X</c><00:00:50.070><c> or</c><00:00:50.309><c> junk</c>

00:00:50.630 --> 00:00:50.640 align:start position:0%
distribution just over X or junk
 

00:00:50.640 --> 00:00:55.130 align:start position:0%
distribution just over X or junk
distribution<00:00:51.239><c> over</c><00:00:51.360><c> Y</c><00:00:51.989><c> and</c><00:00:52.320><c> X</c><00:00:54.140><c> another</c>

00:00:55.130 --> 00:00:55.140 align:start position:0%
distribution over Y and X another
 

00:00:55.140 --> 00:00:58.010 align:start position:0%
distribution over Y and X another
alternative<00:00:55.710><c> actually</c><00:00:56.280><c> would</c><00:00:56.760><c> be</c><00:00:56.789><c> to</c><00:00:57.570><c> do</c>

00:00:58.010 --> 00:00:58.020 align:start position:0%
alternative actually would be to do
 

00:00:58.020 --> 00:01:00.470 align:start position:0%
alternative actually would be to do
generative<00:00:58.859><c> learning</c><00:00:59.039><c> that</c><00:00:59.850><c> is</c><00:01:00.030><c> to</c><00:01:00.300><c> optimize</c>

00:01:00.470 --> 00:01:00.480 align:start position:0%
generative learning that is to optimize
 

00:01:00.480 --> 00:01:03.439 align:start position:0%
generative learning that is to optimize
the<00:01:01.170><c> joint</c><00:01:01.559><c> log</c><00:01:02.070><c> likelihood</c><00:01:02.640><c> so</c><00:01:03.270><c> in</c><00:01:03.359><c> other</c>

00:01:03.439 --> 00:01:03.449 align:start position:0%
the joint log likelihood so in other
 

00:01:03.449 --> 00:01:05.690 align:start position:0%
the joint log likelihood so in other
words<00:01:03.690><c> optimize</c><00:01:04.559><c> minus</c><00:01:04.979><c> the</c><00:01:05.100><c> log</c><00:01:05.280><c> of</c><00:01:05.489><c> the</c>

00:01:05.690 --> 00:01:05.700 align:start position:0%
words optimize minus the log of the
 

00:01:05.700 --> 00:01:08.870 align:start position:0%
words optimize minus the log of the
joint<00:01:06.000><c> probability</c><00:01:06.180><c> of</c><00:01:07.049><c> observing</c><00:01:07.650><c> y</c><00:01:08.040><c> and</c><00:01:08.369><c> X</c>

00:01:08.870 --> 00:01:08.880 align:start position:0%
joint probability of observing y and X
 

00:01:08.880 --> 00:01:11.120 align:start position:0%
joint probability of observing y and X
as<00:01:09.150><c> opposed</c><00:01:09.689><c> to</c><00:01:09.840><c> the</c><00:01:10.100><c> probability</c><00:01:11.100><c> of</c>

00:01:11.120 --> 00:01:11.130 align:start position:0%
as opposed to the probability of
 

00:01:11.130 --> 00:01:14.920 align:start position:0%
as opposed to the probability of
observing<00:01:11.490><c> Y</c><00:01:12.000><c> given</c><00:01:12.780><c> that</c><00:01:13.229><c> I'm</c><00:01:13.350><c> observing</c><00:01:13.560><c> X</c>

00:01:14.920 --> 00:01:14.930 align:start position:0%
observing Y given that I'm observing X
 

00:01:14.930 --> 00:01:18.590 align:start position:0%
observing Y given that I'm observing X
so<00:01:15.930><c> for</c><00:01:16.080><c> instance</c><00:01:16.470><c> hmms</c><00:01:17.280><c> are</c><00:01:17.850><c> usually</c><00:01:18.299><c> trained</c>

00:01:18.590 --> 00:01:18.600 align:start position:0%
so for instance hmms are usually trained
 

00:01:18.600 --> 00:01:20.570 align:start position:0%
so for instance hmms are usually trained
generatively<00:01:19.110><c> so</c><00:01:19.409><c> if</c><00:01:19.530><c> you</c><00:01:19.619><c> know</c><00:01:19.770><c> about</c><00:01:19.950><c> hmms</c>

00:01:20.570 --> 00:01:20.580 align:start position:0%
generatively so if you know about hmms
 

00:01:20.580 --> 00:01:22.730 align:start position:0%
generatively so if you know about hmms
what<00:01:20.820><c> you've</c><00:01:21.000><c> probably</c><00:01:21.299><c> seen</c><00:01:21.689><c> is</c><00:01:21.990><c> the</c>

00:01:22.730 --> 00:01:22.740 align:start position:0%
what you've probably seen is the
 

00:01:22.740 --> 00:01:24.020 align:start position:0%
what you've probably seen is the
learning<00:01:23.040><c> algorithm</c><00:01:23.400><c> for</c><00:01:23.430><c> training</c><00:01:23.580><c> them</c>

00:01:24.020 --> 00:01:24.030 align:start position:0%
learning algorithm for training them
 

00:01:24.030 --> 00:01:26.929 align:start position:0%
learning algorithm for training them
generatively<00:01:24.830><c> though</c><00:01:25.830><c> we</c><00:01:26.040><c> could</c><00:01:26.250><c> also</c><00:01:26.460><c> train</c>

00:01:26.929 --> 00:01:26.939 align:start position:0%
generatively though we could also train
 

00:01:26.939 --> 00:01:29.420 align:start position:0%
generatively though we could also train
it<00:01:27.090><c> as</c><00:01:27.270><c> the</c><00:01:27.450><c> in</c><00:01:27.600><c> this</c><00:01:27.780><c> way</c><00:01:27.990><c> because</c><00:01:28.350><c> if</c><00:01:28.650><c> I</c><00:01:28.950><c> give</c>

00:01:29.420 --> 00:01:29.430 align:start position:0%
it as the in this way because if I give
 

00:01:29.430 --> 00:01:31.340 align:start position:0%
it as the in this way because if I give
you<00:01:29.549><c> a</c><00:01:29.579><c> joint</c><00:01:29.880><c> distribution</c><00:01:30.180><c> over</c><00:01:30.540><c> y</c><00:01:30.810><c> and</c><00:01:30.990><c> X</c><00:01:31.140><c> I</c>

00:01:31.340 --> 00:01:31.350 align:start position:0%
you a joint distribution over y and X I
 

00:01:31.350 --> 00:01:34.969 align:start position:0%
you a joint distribution over y and X I
can<00:01:31.650><c> then</c><00:01:32.720><c> do</c><00:01:33.720><c> the</c><00:01:33.869><c> inference</c><00:01:34.229><c> of</c><00:01:34.350><c> what</c><00:01:34.560><c> is</c><00:01:34.740><c> P</c>

00:01:34.969 --> 00:01:34.979 align:start position:0%
can then do the inference of what is P
 

00:01:34.979 --> 00:01:36.620 align:start position:0%
can then do the inference of what is P
of<00:01:35.070><c> Y</c><00:01:35.189><c> given</c><00:01:35.280><c> X</c><00:01:35.729><c> and</c><00:01:35.880><c> then</c><00:01:35.970><c> I</c><00:01:36.060><c> could</c><00:01:36.329><c> try</c><00:01:36.570><c> to</c>

00:01:36.620 --> 00:01:36.630 align:start position:0%
of Y given X and then I could try to
 

00:01:36.630 --> 00:01:40.700 align:start position:0%
of Y given X and then I could try to
train<00:01:37.350><c> it</c><00:01:37.579><c> discriminative</c><00:01:38.579><c> ly</c><00:01:38.759><c> but</c><00:01:39.710><c> but</c>

00:01:40.700 --> 00:01:40.710 align:start position:0%
train it discriminative ly but but
 

00:01:40.710 --> 00:01:43.280 align:start position:0%
train it discriminative ly but but
initially<00:01:41.549><c> hmm</c><00:01:41.970><c> have</c><00:01:42.150><c> mostly</c><00:01:42.540><c> been</c><00:01:42.630><c> developed</c>

00:01:43.280 --> 00:01:43.290 align:start position:0%
initially hmm have mostly been developed
 

00:01:43.290 --> 00:01:45.080 align:start position:0%
initially hmm have mostly been developed
and<00:01:43.649><c> proposed</c><00:01:44.310><c> in</c><00:01:44.460><c> the</c><00:01:44.549><c> context</c><00:01:44.909><c> of</c>

00:01:45.080 --> 00:01:45.090 align:start position:0%
and proposed in the context of
 

00:01:45.090 --> 00:01:48.950 align:start position:0%
and proposed in the context of
generative<00:01:45.509><c> training</c><00:01:46.110><c> and</c><00:01:47.240><c> so</c><00:01:48.240><c> let's</c><00:01:48.600><c> exploit</c>

00:01:48.950 --> 00:01:48.960 align:start position:0%
generative training and so let's exploit
 

00:01:48.960 --> 00:01:50.990 align:start position:0%
generative training and so let's exploit
that<00:01:49.259><c> formula</c><00:01:50.220><c> a</c><00:01:50.250><c> little</c><00:01:50.310><c> bit</c><00:01:50.579><c> so</c><00:01:50.850><c> we</c><00:01:50.970><c> have</c>

00:01:50.990 --> 00:01:51.000 align:start position:0%
that formula a little bit so we have
 

00:01:51.000 --> 00:01:53.870 align:start position:0%
that formula a little bit so we have
that<00:01:51.270><c> the</c><00:01:51.420><c> joint</c><00:01:51.689><c> distribution</c><00:01:52.020><c> it</c><00:01:52.790><c> can</c><00:01:53.790><c> be</c>

00:01:53.870 --> 00:01:53.880 align:start position:0%
that the joint distribution it can be
 

00:01:53.880 --> 00:01:55.850 align:start position:0%
that the joint distribution it can be
written<00:01:54.060><c> down</c><00:01:54.299><c> as</c><00:01:54.570><c> the</c><00:01:54.780><c> product</c><00:01:55.200><c> of</c><00:01:55.320><c> the</c>

00:01:55.850 --> 00:01:55.860 align:start position:0%
written down as the product of the
 

00:01:55.860 --> 00:01:59.350 align:start position:0%
written down as the product of the
conditional<00:01:56.640><c> P</c><00:01:56.850><c> of</c><00:01:56.939><c> Y</c><00:01:57.060><c> given</c><00:01:57.090><c> X</c><00:01:57.689><c> times</c><00:01:58.110><c> the</c>

00:01:59.350 --> 00:01:59.360 align:start position:0%
conditional P of Y given X times the
 

00:01:59.360 --> 00:02:02.810 align:start position:0%
conditional P of Y given X times the
marginal<00:02:00.360><c> P</c><00:02:00.659><c> of</c><00:02:00.840><c> X</c><00:02:01.229><c> and</c><00:02:01.560><c> because</c><00:02:02.070><c> the</c><00:02:02.369><c> log</c><00:02:02.579><c> of</c><00:02:02.729><c> a</c>

00:02:02.810 --> 00:02:02.820 align:start position:0%
marginal P of X and because the log of a
 

00:02:02.820 --> 00:02:05.990 align:start position:0%
marginal P of X and because the log of a
sum<00:02:03.090><c> is</c><00:02:03.329><c> the</c><00:02:03.360><c> sum</c><00:02:03.509><c> of</c><00:02:03.719><c> logs</c><00:02:04.049><c> then</c><00:02:04.770><c> this</c><00:02:05.670><c> is</c><00:02:05.820><c> also</c>

00:02:05.990 --> 00:02:06.000 align:start position:0%
sum is the sum of logs then this is also
 

00:02:06.000 --> 00:02:08.389 align:start position:0%
sum is the sum of logs then this is also
equal<00:02:06.360><c> to</c><00:02:06.540><c> minus</c><00:02:06.869><c> the</c><00:02:06.990><c> log</c><00:02:07.200><c> of</c><00:02:07.439><c> P</c><00:02:07.710><c> of</c><00:02:07.740><c> Y</c><00:02:07.890><c> given</c><00:02:07.920><c> X</c>

00:02:08.389 --> 00:02:08.399 align:start position:0%
equal to minus the log of P of Y given X
 

00:02:08.399 --> 00:02:11.510 align:start position:0%
equal to minus the log of P of Y given X
minus<00:02:09.209><c> the</c><00:02:09.539><c> log</c><00:02:09.750><c> of</c><00:02:10.020><c> P</c><00:02:10.289><c> of</c><00:02:10.319><c> X</c><00:02:10.470><c> so</c><00:02:11.190><c> we</c><00:02:11.280><c> see</c><00:02:11.400><c> that</c>

00:02:11.510 --> 00:02:11.520 align:start position:0%
minus the log of P of X so we see that
 

00:02:11.520 --> 00:02:13.180 align:start position:0%
minus the log of P of X so we see that
the<00:02:11.670><c> difference</c><00:02:12.060><c> is</c><00:02:12.209><c> this</c><00:02:12.390><c> term</c><00:02:12.690><c> here</c>

00:02:13.180 --> 00:02:13.190 align:start position:0%
the difference is this term here
 

00:02:13.190 --> 00:02:16.720 align:start position:0%
the difference is this term here
so<00:02:13.280><c> we</c><00:02:13.400><c> have</c><00:02:13.580><c> this</c><00:02:14.300><c> here</c><00:02:14.840><c> and</c><00:02:15.050><c> this</c><00:02:15.590><c> here</c><00:02:15.730><c> but</c>

00:02:16.720 --> 00:02:16.730 align:start position:0%
so we have this here and this here but
 

00:02:16.730 --> 00:02:21.070 align:start position:0%
so we have this here and this here but
we<00:02:16.850><c> have</c><00:02:17.000><c> this</c><00:02:17.240><c> term</c><00:02:17.660><c> that</c><00:02:18.470><c> is</c><00:02:19.630><c> added</c><00:02:20.630><c> when</c>

00:02:21.070 --> 00:02:21.080 align:start position:0%
we have this term that is added when
 

00:02:21.080 --> 00:02:24.240 align:start position:0%
we have this term that is added when
we're<00:02:21.260><c> performing</c><00:02:21.680><c> genitive</c><00:02:22.520><c> learning</c><00:02:22.880><c> and</c>

00:02:24.240 --> 00:02:24.250 align:start position:0%
we're performing genitive learning and
 

00:02:24.250 --> 00:02:26.650 align:start position:0%
we're performing genitive learning and
so<00:02:25.250><c> what</c><00:02:25.400><c> we</c><00:02:25.550><c> were</c><00:02:25.640><c> thinking</c><00:02:25.820><c> about</c><00:02:26.090><c> this</c><00:02:26.420><c> is</c>

00:02:26.650 --> 00:02:26.660 align:start position:0%
so what we were thinking about this is
 

00:02:26.660 --> 00:02:29.050 align:start position:0%
so what we were thinking about this is
that<00:02:26.900><c> perhaps</c><00:02:27.320><c> this</c><00:02:27.770><c> term</c><00:02:28.010><c> is</c><00:02:28.190><c> kind</c><00:02:28.550><c> of</c><00:02:28.670><c> acting</c>

00:02:29.050 --> 00:02:29.060 align:start position:0%
that perhaps this term is kind of acting
 

00:02:29.060 --> 00:02:31.750 align:start position:0%
that perhaps this term is kind of acting
like<00:02:29.090><c> a</c><00:02:29.360><c> regularizer</c><00:02:29.960><c> that</c><00:02:30.770><c> is</c><00:02:30.920><c> it's</c><00:02:31.160><c> we're</c>

00:02:31.750 --> 00:02:31.760 align:start position:0%
like a regularizer that is it's we're
 

00:02:31.760 --> 00:02:36.100 align:start position:0%
like a regularizer that is it's we're
adding<00:02:32.240><c> another</c><00:02:32.600><c> term</c><00:02:33.200><c> which</c><00:02:34.210><c> is</c><00:02:35.210><c> does</c><00:02:35.960><c> not</c>

00:02:36.100 --> 00:02:36.110 align:start position:0%
adding another term which is does not
 

00:02:36.110 --> 00:02:38.530 align:start position:0%
adding another term which is does not
involve<00:02:36.470><c> Y</c><00:02:36.920><c> so</c><00:02:37.400><c> it's</c><00:02:37.640><c> not</c><00:02:37.910><c> a</c><00:02:38.270><c> term</c><00:02:38.510><c> that</c>

00:02:38.530 --> 00:02:38.540 align:start position:0%
involve Y so it's not a term that
 

00:02:38.540 --> 00:02:40.840 align:start position:0%
involve Y so it's not a term that
encourages<00:02:39.350><c> the</c><00:02:39.620><c> model</c><00:02:39.980><c> to</c><00:02:40.400><c> assign</c><00:02:40.640><c> high</c>

00:02:40.840 --> 00:02:40.850 align:start position:0%
encourages the model to assign high
 

00:02:40.850 --> 00:02:43.120 align:start position:0%
encourages the model to assign high
probability<00:02:41.510><c> to</c><00:02:41.630><c> the</c><00:02:41.660><c> true</c><00:02:41.990><c> target</c><00:02:42.410><c> given</c><00:02:42.740><c> X</c>

00:02:43.120 --> 00:02:43.130 align:start position:0%
probability to the true target given X
 

00:02:43.130 --> 00:02:45.340 align:start position:0%
probability to the true target given X
it's<00:02:43.730><c> just</c><00:02:43.820><c> a</c><00:02:44.000><c> model</c><00:02:44.300><c> that</c><00:02:44.330><c> requires</c><00:02:44.990><c> to</c><00:02:45.200><c> do</c>

00:02:45.340 --> 00:02:45.350 align:start position:0%
it's just a model that requires to do
 

00:02:45.350 --> 00:02:47.380 align:start position:0%
it's just a model that requires to do
something<00:02:45.860><c> else</c><00:02:46.070><c> it's</c><00:02:46.340><c> gonna</c><00:02:46.550><c> favor</c><00:02:46.850><c> models</c>

00:02:47.380 --> 00:02:47.390 align:start position:0%
something else it's gonna favor models
 

00:02:47.390 --> 00:02:50.860 align:start position:0%
something else it's gonna favor models
that<00:02:47.630><c> also</c><00:02:48.020><c> explain</c><00:02:48.500><c> well</c><00:02:48.800><c> the</c><00:02:49.610><c> marginal</c><00:02:50.570><c> so</c><00:02:50.810><c> I</c>

00:02:50.860 --> 00:02:50.870 align:start position:0%
that also explain well the marginal so I
 

00:02:50.870 --> 00:02:53.140 align:start position:0%
that also explain well the marginal so I
assign<00:02:51.470><c> high</c><00:02:51.650><c> probability</c><00:02:52.400><c> to</c><00:02:52.670><c> observe</c><00:02:52.970><c> any</c>

00:02:53.140 --> 00:02:53.150 align:start position:0%
assign high probability to observe any
 

00:02:53.150 --> 00:02:56.170 align:start position:0%
assign high probability to observe any
true<00:02:53.540><c> data</c><00:02:53.810><c> so</c><00:02:54.590><c> the</c><00:02:54.710><c> data</c><00:02:54.740><c> just</c><00:02:55.700><c> the</c><00:02:55.790><c> inputs</c>

00:02:56.170 --> 00:02:56.180 align:start position:0%
true data so the data just the inputs
 

00:02:56.180 --> 00:02:59.080 align:start position:0%
true data so the data just the inputs
that<00:02:56.270><c> we</c><00:02:56.510><c> see</c><00:02:56.750><c> from</c><00:02:56.960><c> the</c><00:02:57.320><c> training</c><00:02:57.590><c> set</c><00:02:57.740><c> and</c><00:02:58.190><c> so</c>

00:02:59.080 --> 00:02:59.090 align:start position:0%
that we see from the training set and so
 

00:02:59.090 --> 00:03:01.390 align:start position:0%
that we see from the training set and so
for<00:02:59.270><c> that</c><00:02:59.360><c> reason</c><00:02:59.420><c> a</c><00:02:59.990><c> good</c><00:03:00.620><c> intuition</c><00:03:00.860><c> is</c><00:03:01.250><c> to</c>

00:03:01.390 --> 00:03:01.400 align:start position:0%
for that reason a good intuition is to
 

00:03:01.400 --> 00:03:03.700 align:start position:0%
for that reason a good intuition is to
think<00:03:01.670><c> that</c><00:03:01.880><c> this</c><00:03:02.480><c> kind</c><00:03:02.720><c> of</c><00:03:02.750><c> learning</c><00:03:03.230><c> will</c>

00:03:03.700 --> 00:03:03.710 align:start position:0%
think that this kind of learning will
 

00:03:03.710 --> 00:03:06.130 align:start position:0%
think that this kind of learning will
tend<00:03:03.980><c> to</c><00:03:04.070><c> fit</c><00:03:04.430><c> the</c><00:03:04.670><c> data</c><00:03:04.820><c> better</c><00:03:05.360><c> while</c>

00:03:06.130 --> 00:03:06.140 align:start position:0%
tend to fit the data better while
 

00:03:06.140 --> 00:03:07.660 align:start position:0%
tend to fit the data better while
genitive<00:03:06.680><c> learning</c><00:03:07.040><c> will</c><00:03:07.190><c> be</c><00:03:07.340><c> more</c>

00:03:07.660 --> 00:03:07.670 align:start position:0%
genitive learning will be more
 

00:03:07.670 --> 00:03:12.570 align:start position:0%
genitive learning will be more
regularized<00:03:08.150><c> because</c><00:03:08.780><c> of</c><00:03:08.900><c> this</c><00:03:09.080><c> term</c><00:03:09.320><c> here</c>

00:03:12.570 --> 00:03:12.580 align:start position:0%
 
 

00:03:12.580 --> 00:03:16.960 align:start position:0%
 
actually<00:03:13.580><c> we</c><00:03:13.700><c> can</c><00:03:13.880><c> show</c><00:03:14.240><c> that</c><00:03:15.520><c> there</c><00:03:16.520><c> are</c><00:03:16.760><c> two</c>

00:03:16.960 --> 00:03:16.970 align:start position:0%
actually we can show that there are two
 

00:03:16.970 --> 00:03:19.390 align:start position:0%
actually we can show that there are two
scenarios<00:03:17.470><c> that</c><00:03:18.470><c> we</c><00:03:18.560><c> can</c><00:03:18.709><c> observe</c><00:03:19.040><c> in</c><00:03:19.220><c> terms</c>

00:03:19.390 --> 00:03:19.400 align:start position:0%
scenarios that we can observe in terms
 

00:03:19.400 --> 00:03:21.310 align:start position:0%
scenarios that we can observe in terms
of<00:03:19.640><c> how</c><00:03:19.850><c> generative</c><00:03:20.450><c> versus</c><00:03:20.870><c> this</c><00:03:21.020><c> kind</c><00:03:21.230><c> of</c>

00:03:21.310 --> 00:03:21.320 align:start position:0%
of how generative versus this kind of
 

00:03:21.320 --> 00:03:24.580 align:start position:0%
of how generative versus this kind of
learning<00:03:21.770><c> will</c><00:03:21.950><c> compare</c><00:03:22.640><c> ibly</c><00:03:23.590><c> comparatively</c>

00:03:24.580 --> 00:03:24.590 align:start position:0%
learning will compare ibly comparatively
 

00:03:24.590 --> 00:03:29.410 align:start position:0%
learning will compare ibly comparatively
come<00:03:25.390><c> compare</c><00:03:26.390><c> so</c><00:03:27.320><c> if</c><00:03:27.800><c> a</c><00:03:28.220><c> model</c><00:03:28.880><c> is</c><00:03:29.030><c> well</c>

00:03:29.410 --> 00:03:29.420 align:start position:0%
come compare so if a model is well
 

00:03:29.420 --> 00:03:32.440 align:start position:0%
come compare so if a model is well
specified<00:03:30.140><c> so</c><00:03:30.709><c> that</c><00:03:30.920><c> means</c><00:03:31.190><c> that</c><00:03:31.459><c> the</c><00:03:31.970><c> data</c><00:03:32.239><c> in</c>

00:03:32.440 --> 00:03:32.450 align:start position:0%
specified so that means that the data in
 

00:03:32.450 --> 00:03:36.220 align:start position:0%
specified so that means that the data in
our<00:03:32.630><c> training</c><00:03:33.020><c> set</c><00:03:33.290><c> is</c><00:03:33.500><c> that</c><00:03:34.040><c> is</c><00:03:34.810><c> actually</c><00:03:35.810><c> was</c>

00:03:36.220 --> 00:03:36.230 align:start position:0%
our training set is that is actually was
 

00:03:36.230 --> 00:03:39.160 align:start position:0%
our training set is that is actually was
actually<00:03:36.530><c> generated</c><00:03:37.010><c> from</c><00:03:37.220><c> a</c><00:03:37.640><c> model</c><00:03:38.360><c> from</c><00:03:38.959><c> the</c>

00:03:39.160 --> 00:03:39.170 align:start position:0%
actually generated from a model from the
 

00:03:39.170 --> 00:03:40.780 align:start position:0%
actually generated from a model from the
same<00:03:39.380><c> class</c><00:03:39.620><c> as</c><00:03:39.830><c> our</c><00:03:39.950><c> model</c><00:03:40.310><c> so</c><00:03:40.489><c> there's</c><00:03:40.700><c> a</c>

00:03:40.780 --> 00:03:40.790 align:start position:0%
same class as our model so there's a
 

00:03:40.790 --> 00:03:42.670 align:start position:0%
same class as our model so there's a
setting<00:03:41.150><c> of</c><00:03:41.209><c> our</c><00:03:41.330><c> parameters</c><00:03:41.900><c> for</c><00:03:42.170><c> our</c><00:03:42.260><c> model</c>

00:03:42.670 --> 00:03:42.680 align:start position:0%
setting of our parameters for our model
 

00:03:42.680 --> 00:03:44.830 align:start position:0%
setting of our parameters for our model
that<00:03:43.070><c> corresponds</c><00:03:43.670><c> exactly</c><00:03:43.760><c> to</c><00:03:44.330><c> the</c><00:03:44.660><c> true</c>

00:03:44.830 --> 00:03:44.840 align:start position:0%
that corresponds exactly to the true
 

00:03:44.840 --> 00:03:47.229 align:start position:0%
that corresponds exactly to the true
model<00:03:45.110><c> that</c><00:03:45.260><c> generated</c><00:03:45.709><c> the</c><00:03:45.800><c> data</c><00:03:46.000><c> so</c><00:03:47.000><c> if</c><00:03:47.120><c> the</c>

00:03:47.229 --> 00:03:47.239 align:start position:0%
model that generated the data so if the
 

00:03:47.239 --> 00:03:50.350 align:start position:0%
model that generated the data so if the
model<00:03:47.750><c> is</c><00:03:47.780><c> well</c><00:03:48.050><c> specified</c><00:03:48.680><c> then</c><00:03:49.489><c> we</c><00:03:50.090><c> can</c><00:03:50.239><c> show</c>

00:03:50.350 --> 00:03:50.360 align:start position:0%
model is well specified then we can show
 

00:03:50.360 --> 00:03:52.090 align:start position:0%
model is well specified then we can show
a<00:03:50.390><c> genitive</c><00:03:50.900><c> learning</c><00:03:51.320><c> essentially</c><00:03:51.860><c> always</c>

00:03:52.090 --> 00:03:52.100 align:start position:0%
a genitive learning essentially always
 

00:03:52.100 --> 00:03:54.790 align:start position:0%
a genitive learning essentially always
better<00:03:52.489><c> that</c><00:03:52.760><c> is</c><00:03:53.300><c> for</c><00:03:53.600><c> any</c><00:03:53.810><c> size</c><00:03:53.989><c> of</c><00:03:54.470><c> training</c>

00:03:54.790 --> 00:03:54.800 align:start position:0%
better that is for any size of training
 

00:03:54.800 --> 00:03:57.040 align:start position:0%
better that is for any size of training
set<00:03:55.040><c> that</c><00:03:55.519><c> we</c><00:03:55.610><c> use</c><00:03:55.850><c> there's</c><00:03:56.450><c> always</c><00:03:56.660><c> going</c><00:03:56.959><c> to</c>

00:03:57.040 --> 00:03:57.050 align:start position:0%
set that we use there's always going to
 

00:03:57.050 --> 00:03:59.800 align:start position:0%
set that we use there's always going to
be<00:03:57.170><c> a</c><00:03:57.320><c> gap</c><00:03:57.680><c> between</c><00:03:58.370><c> what</c><00:03:59.330><c> generative</c>

00:03:59.800 --> 00:03:59.810 align:start position:0%
be a gap between what generative
 

00:03:59.810 --> 00:04:02.860 align:start position:0%
be a gap between what generative
learning<00:04:00.519><c> gets</c><00:04:01.519><c> in</c><00:04:01.730><c> terms</c><00:04:01.880><c> of</c><00:04:02.150><c> generalization</c>

00:04:02.860 --> 00:04:02.870 align:start position:0%
learning gets in terms of generalization
 

00:04:02.870 --> 00:04:04.990 align:start position:0%
learning gets in terms of generalization
performance<00:04:03.380><c> compared</c><00:04:03.890><c> to</c><00:04:04.070><c> discriminative</c>

00:04:04.990 --> 00:04:05.000 align:start position:0%
performance compared to discriminative
 

00:04:05.000 --> 00:04:06.850 align:start position:0%
performance compared to discriminative
training<00:04:05.180><c> so</c><00:04:05.660><c> genitive</c><00:04:06.050><c> training</c><00:04:06.380><c> is</c><00:04:06.530><c> it's</c>

00:04:06.850 --> 00:04:06.860 align:start position:0%
training so genitive training is it's
 

00:04:06.860 --> 00:04:09.550 align:start position:0%
training so genitive training is it's
going<00:04:07.010><c> to</c><00:04:07.070><c> perform</c><00:04:07.340><c> better</c><00:04:07.430><c> they'll</c><00:04:08.560><c> they</c>

00:04:09.550 --> 00:04:09.560 align:start position:0%
going to perform better they'll they
 

00:04:09.560 --> 00:04:11.580 align:start position:0%
going to perform better they'll they
should<00:04:09.739><c> both</c><00:04:09.890><c> eventually</c><00:04:10.370><c> converge</c><00:04:11.000><c> to</c><00:04:11.269><c> the</c>

00:04:11.580 --> 00:04:11.590 align:start position:0%
should both eventually converge to the
 

00:04:11.590 --> 00:04:14.310 align:start position:0%
should both eventually converge to the
two<00:04:12.590><c> essentially</c><00:04:13.190><c> an</c><00:04:13.370><c> error</c><00:04:13.670><c> zero</c><00:04:14.000><c> so</c><00:04:14.209><c> a</c>

00:04:14.310 --> 00:04:14.320 align:start position:0%
two essentially an error zero so a
 

00:04:14.320 --> 00:04:17.020 align:start position:0%
two essentially an error zero so a
perfect<00:04:15.320><c> performance</c><00:04:16.010><c> but</c><00:04:16.519><c> genitive</c>

00:04:17.020 --> 00:04:17.030 align:start position:0%
perfect performance but genitive
 

00:04:17.030 --> 00:04:19.330 align:start position:0%
perfect performance but genitive
learning<00:04:17.450><c> is</c><00:04:17.709><c> going</c><00:04:18.709><c> to</c><00:04:18.830><c> get</c><00:04:18.950><c> there</c><00:04:19.130><c> much</c>

00:04:19.330 --> 00:04:19.340 align:start position:0%
learning is going to get there much
 

00:04:19.340 --> 00:04:25.180 align:start position:0%
learning is going to get there much
faster<00:04:22.120><c> however</c><00:04:23.120><c> if</c><00:04:23.419><c> the</c><00:04:23.600><c> model</c><00:04:23.960><c> is</c><00:04:24.169><c> not</c><00:04:24.530><c> well</c>

00:04:25.180 --> 00:04:25.190 align:start position:0%
faster however if the model is not well
 

00:04:25.190 --> 00:04:26.650 align:start position:0%
faster however if the model is not well
specified<00:04:25.820><c> which</c><00:04:26.450><c> is</c>

00:04:26.650 --> 00:04:26.660 align:start position:0%
specified which is
 

00:04:26.660 --> 00:04:28.510 align:start position:0%
specified which is
most<00:04:27.020><c> of</c><00:04:27.170><c> the</c><00:04:27.260><c> time</c><00:04:27.440><c> so</c><00:04:27.740><c> if</c><00:04:27.890><c> data</c><00:04:28.310><c> was</c>

00:04:28.510 --> 00:04:28.520 align:start position:0%
most of the time so if data was
 

00:04:28.520 --> 00:04:30.850 align:start position:0%
most of the time so if data was
generated<00:04:28.970><c> by</c><00:04:29.000><c> some</c><00:04:29.720><c> experts</c><00:04:29.990><c> that</c><00:04:30.350><c> labeled</c>

00:04:30.850 --> 00:04:30.860 align:start position:0%
generated by some experts that labeled
 

00:04:30.860 --> 00:04:33.520 align:start position:0%
generated by some experts that labeled
some<00:04:31.280><c> data</c><00:04:31.510><c> then</c><00:04:32.510><c> this</c><00:04:32.660><c> is</c><00:04:32.810><c> a</c><00:04:32.840><c> process</c><00:04:33.350><c> that</c>

00:04:33.520 --> 00:04:33.530 align:start position:0%
some data then this is a process that
 

00:04:33.530 --> 00:04:36.610 align:start position:0%
some data then this is a process that
that<00:04:34.190><c> is</c><00:04:34.370><c> almost</c><00:04:34.520><c> most</c><00:04:34.910><c> almost</c><00:04:35.750><c> certainly</c>

00:04:36.610 --> 00:04:36.620 align:start position:0%
that is almost most almost certainly
 

00:04:36.620 --> 00:04:39.280 align:start position:0%
that is almost most almost certainly
more<00:04:37.250><c> complicated</c><00:04:37.940><c> than</c><00:04:38.240><c> the</c><00:04:38.690><c> model</c><00:04:39.080><c> we've</c>

00:04:39.280 --> 00:04:39.290 align:start position:0%
more complicated than the model we've
 

00:04:39.290 --> 00:04:42.610 align:start position:0%
more complicated than the model we've
written<00:04:39.710><c> down</c><00:04:39.980><c> in</c><00:04:40.220><c> math</c><00:04:40.630><c> so</c><00:04:41.630><c> so</c><00:04:42.080><c> really</c><00:04:42.470><c> this</c>

00:04:42.610 --> 00:04:42.620 align:start position:0%
written down in math so so really this
 

00:04:42.620 --> 00:04:44.980 align:start position:0%
written down in math so so really this
is<00:04:42.680><c> essentially</c><00:04:43.370><c> for</c><00:04:44.120><c> all</c><00:04:44.150><c> the</c><00:04:44.420><c> interesting</c>

00:04:44.980 --> 00:04:44.990 align:start position:0%
is essentially for all the interesting
 

00:04:44.990 --> 00:04:49.210 align:start position:0%
is essentially for all the interesting
problem<00:04:45.670><c> the</c><00:04:46.670><c> model</c><00:04:47.300><c> will</c><00:04:47.480><c> tend</c><00:04:47.900><c> to</c><00:04:47.930><c> be</c><00:04:48.220><c> will</c>

00:04:49.210 --> 00:04:49.220 align:start position:0%
problem the model will tend to be will
 

00:04:49.220 --> 00:04:53.320 align:start position:0%
problem the model will tend to be will
not<00:04:49.400><c> be</c><00:04:49.580><c> well</c><00:04:49.790><c> specified</c><00:04:50.530><c> then</c><00:04:51.760><c> the</c><00:04:52.760><c> picture</c>

00:04:53.320 --> 00:04:53.330 align:start position:0%
not be well specified then the picture
 

00:04:53.330 --> 00:04:56.740 align:start position:0%
not be well specified then the picture
is<00:04:53.540><c> not</c><00:04:53.780><c> as</c><00:04:53.930><c> clear</c><00:04:54.230><c> so</c><00:04:54.740><c> what</c><00:04:55.670><c> we'll</c><00:04:55.880><c> see</c><00:04:56.300><c> is</c><00:04:56.690><c> a</c>

00:04:56.740 --> 00:04:56.750 align:start position:0%
is not as clear so what we'll see is a
 

00:04:56.750 --> 00:04:58.750 align:start position:0%
is not as clear so what we'll see is a
picture<00:04:57.350><c> that</c><00:04:57.530><c> is</c><00:04:57.560><c> consistent</c><00:04:58.430><c> with</c><00:04:58.490><c> the</c><00:04:58.730><c> view</c>

00:04:58.750 --> 00:04:58.760 align:start position:0%
picture that is consistent with the view
 

00:04:58.760 --> 00:05:00.910 align:start position:0%
picture that is consistent with the view
that<00:04:59.000><c> genitive</c><00:04:59.660><c> learning</c><00:05:00.020><c> is</c><00:05:00.170><c> just</c><00:05:00.200><c> more</c>

00:05:00.910 --> 00:05:00.920 align:start position:0%
that genitive learning is just more
 

00:05:00.920 --> 00:05:03.490 align:start position:0%
that genitive learning is just more
corresponds<00:05:01.640><c> to</c><00:05:01.700><c> more</c><00:05:01.940><c> regularization</c><00:05:02.500><c> so</c>

00:05:03.490 --> 00:05:03.500 align:start position:0%
corresponds to more regularization so
 

00:05:03.500 --> 00:05:07.780 align:start position:0%
corresponds to more regularization so
the<00:05:03.680><c> training</c><00:05:04.010><c> set</c><00:05:04.280><c> is</c><00:05:04.550><c> small</c><00:05:05.510><c> then</c><00:05:06.500><c> we</c><00:05:07.400><c> should</c>

00:05:07.780 --> 00:05:07.790 align:start position:0%
the training set is small then we should
 

00:05:07.790 --> 00:05:09.670 align:start position:0%
the training set is small then we should
observe<00:05:07.970><c> that</c><00:05:08.450><c> genitive</c><00:05:08.930><c> learning</c><00:05:09.230><c> will</c><00:05:09.410><c> get</c>

00:05:09.670 --> 00:05:09.680 align:start position:0%
observe that genitive learning will get
 

00:05:09.680 --> 00:05:12.790 align:start position:0%
observe that genitive learning will get
a<00:05:09.950><c> better</c><00:05:10.670><c> performance</c><00:05:11.380><c> in</c><00:05:12.380><c> terms</c><00:05:12.620><c> of</c>

00:05:12.790 --> 00:05:12.800 align:start position:0%
a better performance in terms of
 

00:05:12.800 --> 00:05:15.400 align:start position:0%
a better performance in terms of
generalization<00:05:13.640><c> but</c><00:05:14.360><c> as</c><00:05:14.480><c> we</c><00:05:14.630><c> increase</c><00:05:14.990><c> the</c>

00:05:15.400 --> 00:05:15.410 align:start position:0%
generalization but as we increase the
 

00:05:15.410 --> 00:05:17.620 align:start position:0%
generalization but as we increase the
size<00:05:15.770><c> of</c><00:05:15.890><c> our</c><00:05:16.070><c> training</c><00:05:16.430><c> set</c><00:05:16.670><c> eventually</c><00:05:16.970><c> we</c>

00:05:17.620 --> 00:05:17.630 align:start position:0%
size of our training set eventually we
 

00:05:17.630 --> 00:05:19.660 align:start position:0%
size of our training set eventually we
should<00:05:17.840><c> reach</c><00:05:18.020><c> a</c><00:05:18.200><c> point</c><00:05:18.440><c> where</c><00:05:18.860><c> this</c><00:05:19.190><c> creative</c>

00:05:19.660 --> 00:05:19.670 align:start position:0%
should reach a point where this creative
 

00:05:19.670 --> 00:05:21.160 align:start position:0%
should reach a point where this creative
learning<00:05:19.910><c> will</c><00:05:20.150><c> catch</c><00:05:20.390><c> up</c><00:05:20.630><c> with</c><00:05:20.660><c> genitive</c>

00:05:21.160 --> 00:05:21.170 align:start position:0%
learning will catch up with genitive
 

00:05:21.170 --> 00:05:23.860 align:start position:0%
learning will catch up with genitive
learning<00:05:21.530><c> and</c><00:05:21.680><c> will</c><00:05:22.670><c> start</c><00:05:22.970><c> being</c><00:05:23.210><c> actually</c>

00:05:23.860 --> 00:05:23.870 align:start position:0%
learning and will start being actually
 

00:05:23.870 --> 00:05:25.690 align:start position:0%
learning and will start being actually
better<00:05:24.140><c> in</c><00:05:24.320><c> terms</c><00:05:24.470><c> of</c><00:05:24.700><c> generalization</c>

00:05:25.690 --> 00:05:25.700 align:start position:0%
better in terms of generalization
 

00:05:25.700 --> 00:05:27.490 align:start position:0%
better in terms of generalization
performance<00:05:26.180><c> to</c><00:05:26.270><c> get</c><00:05:26.390><c> lower</c><00:05:26.660><c> generalization</c>

00:05:27.490 --> 00:05:27.500 align:start position:0%
performance to get lower generalization
 

00:05:27.500 --> 00:05:33.250 align:start position:0%
performance to get lower generalization
error<00:05:28.570><c> than</c><00:05:29.570><c> a</c><00:05:29.840><c> generative</c><00:05:30.200><c> learning</c><00:05:31.390><c> and</c><00:05:32.390><c> in</c>

00:05:33.250 --> 00:05:33.260 align:start position:0%
error than a generative learning and in
 

00:05:33.260 --> 00:05:36.520 align:start position:0%
error than a generative learning and in
fact<00:05:33.680><c> more</c><00:05:34.220><c> specifically</c><00:05:34.960><c> what</c><00:05:35.960><c> we</c><00:05:36.140><c> get</c><00:05:36.350><c> is</c>

00:05:36.520 --> 00:05:36.530 align:start position:0%
fact more specifically what we get is
 

00:05:36.530 --> 00:05:39.430 align:start position:0%
fact more specifically what we get is
that<00:05:36.560><c> discredit</c><00:05:37.520><c> of</c><00:05:37.640><c> learning</c><00:05:38.090><c> will</c><00:05:38.570><c> converge</c>

00:05:39.430 --> 00:05:39.440 align:start position:0%
that discredit of learning will converge
 

00:05:39.440 --> 00:05:43.810 align:start position:0%
that discredit of learning will converge
to<00:05:39.740><c> a</c><00:05:40.070><c> smaller</c><00:05:41.230><c> asymptotic</c><00:05:42.230><c> error</c><00:05:42.820><c> asymptotic</c>

00:05:43.810 --> 00:05:43.820 align:start position:0%
to a smaller asymptotic error asymptotic
 

00:05:43.820 --> 00:05:45.550 align:start position:0%
to a smaller asymptotic error asymptotic
error<00:05:43.970><c> being</c><00:05:44.180><c> the</c><00:05:44.450><c> error</c><00:05:44.660><c> your</c><00:05:45.169><c> model</c><00:05:45.440><c> would</c>

00:05:45.550 --> 00:05:45.560 align:start position:0%
error being the error your model would
 

00:05:45.560 --> 00:05:47.080 align:start position:0%
error being the error your model would
get<00:05:45.740><c> if</c><00:05:45.919><c> you</c><00:05:45.950><c> had</c><00:05:46.070><c> infinite</c><00:05:46.580><c> amount</c><00:05:47.030><c> of</c>

00:05:47.080 --> 00:05:47.090 align:start position:0%
get if you had infinite amount of
 

00:05:47.090 --> 00:05:49.990 align:start position:0%
get if you had infinite amount of
training<00:05:47.300><c> data</c><00:05:47.450><c> so</c><00:05:48.140><c> we'll</c><00:05:48.380><c> it</c><00:05:49.160><c> has</c><00:05:49.400><c> a</c><00:05:49.430><c> small</c>

00:05:49.990 --> 00:05:50.000 align:start position:0%
training data so we'll it has a small
 

00:05:50.000 --> 00:05:52.090 align:start position:0%
training data so we'll it has a small
asymptotic<00:05:50.660><c> error</c><00:05:50.840><c> then</c><00:05:51.470><c> generative</c>

00:05:52.090 --> 00:05:52.100 align:start position:0%
asymptotic error then generative
 

00:05:52.100 --> 00:05:54.400 align:start position:0%
asymptotic error then generative
learning<00:05:52.280><c> which</c><00:05:52.760><c> won't</c><00:05:53.060><c> be</c><00:05:53.210><c> able</c><00:05:53.360><c> to</c><00:05:53.780><c> do</c><00:05:54.260><c> as</c>

00:05:54.400 --> 00:05:54.410 align:start position:0%
learning which won't be able to do as
 

00:05:54.410 --> 00:05:56.980 align:start position:0%
learning which won't be able to do as
well<00:05:54.440><c> even</c><00:05:54.950><c> with</c><00:05:55.340><c> an</c><00:05:55.580><c> infinite</c><00:05:56.540><c> amount</c><00:05:56.660><c> of</c>

00:05:56.980 --> 00:05:56.990 align:start position:0%
well even with an infinite amount of
 

00:05:56.990 --> 00:06:00.670 align:start position:0%
well even with an infinite amount of
training<00:05:57.260><c> data</c><00:05:57.610><c> ok</c><00:05:58.610><c> so</c><00:05:58.669><c> again</c><00:05:58.850><c> here</c><00:05:59.330><c> a</c><00:05:59.720><c> nice</c>

00:06:00.670 --> 00:06:00.680 align:start position:0%
training data ok so again here a nice
 

00:06:00.680 --> 00:06:03.790 align:start position:0%
training data ok so again here a nice
way<00:06:00.919><c> of</c><00:06:00.950><c> so</c><00:06:01.850><c> a</c><00:06:01.910><c> simpler</c><00:06:02.360><c> way</c><00:06:02.900><c> of</c><00:06:02.930><c> interpreting</c>

00:06:03.790 --> 00:06:03.800 align:start position:0%
way of so a simpler way of interpreting
 

00:06:03.800 --> 00:06:05.200 align:start position:0%
way of so a simpler way of interpreting
this<00:06:03.919><c> is</c><00:06:04.100><c> that</c><00:06:04.250><c> genitive</c><00:06:04.700><c> learning</c><00:06:05.000><c> means</c>

00:06:05.200 --> 00:06:05.210 align:start position:0%
this is that genitive learning means
 

00:06:05.210 --> 00:06:07.030 align:start position:0%
this is that genitive learning means
more<00:06:05.510><c> regularization</c><00:06:05.870><c> so</c><00:06:06.680><c> if</c><00:06:06.800><c> there's</c><00:06:06.980><c> a</c>

00:06:07.030 --> 00:06:07.040 align:start position:0%
more regularization so if there's a
 

00:06:07.040 --> 00:06:09.430 align:start position:0%
more regularization so if there's a
small<00:06:07.400><c> amount</c><00:06:07.910><c> of</c><00:06:08.030><c> training</c><00:06:08.240><c> data</c><00:06:08.440><c> genitive</c>

00:06:09.430 --> 00:06:09.440 align:start position:0%
small amount of training data genitive
 

00:06:09.440 --> 00:06:12.610 align:start position:0%
small amount of training data genitive
learning<00:06:09.820><c> will</c><00:06:10.820><c> probably</c><00:06:11.180><c> do</c><00:06:11.300><c> better</c><00:06:11.450><c> but</c><00:06:12.290><c> if</c>

00:06:12.610 --> 00:06:12.620 align:start position:0%
learning will probably do better but if
 

00:06:12.620 --> 00:06:14.710 align:start position:0%
learning will probably do better but if
I<00:06:12.950><c> have</c><00:06:13.250><c> quite</c><00:06:13.490><c> a</c><00:06:13.520><c> bit</c><00:06:13.730><c> of</c><00:06:13.850><c> training</c><00:06:14.150><c> data</c><00:06:14.330><c> then</c>

00:06:14.710 --> 00:06:14.720 align:start position:0%
I have quite a bit of training data then
 

00:06:14.720 --> 00:06:16.720 align:start position:0%
I have quite a bit of training data then
now<00:06:15.050><c> we</c><00:06:15.110><c> can</c><00:06:15.470><c> expect</c><00:06:15.800><c> this</c><00:06:15.890><c> punative</c><00:06:16.250><c> learning</c>

00:06:16.720 --> 00:06:16.730 align:start position:0%
now we can expect this punative learning
 

00:06:16.730 --> 00:06:19.900 align:start position:0%
now we can expect this punative learning
to<00:06:16.880><c> eventually</c><00:06:17.330><c> catch</c><00:06:17.510><c> up</c><00:06:17.540><c> and</c><00:06:17.930><c> do</c><00:06:18.350><c> better</c><00:06:18.910><c> so</c>

00:06:19.900 --> 00:06:19.910 align:start position:0%
to eventually catch up and do better so
 

00:06:19.910 --> 00:06:21.190 align:start position:0%
to eventually catch up and do better so
that's<00:06:20.090><c> actually</c><00:06:20.390><c> a</c><00:06:20.570><c> good</c><00:06:20.750><c> thing</c><00:06:20.810><c> to</c><00:06:21.169><c> know</c>

00:06:21.190 --> 00:06:21.200 align:start position:0%
that's actually a good thing to know
 

00:06:21.200 --> 00:06:23.650 align:start position:0%
that's actually a good thing to know
about<00:06:21.590><c> if</c><00:06:22.070><c> you're</c><00:06:22.580><c> tackling</c><00:06:22.970><c> a</c><00:06:23.000><c> problem</c><00:06:23.450><c> for</c>

00:06:23.650 --> 00:06:23.660 align:start position:0%
about if you're tackling a problem for
 

00:06:23.660 --> 00:06:25.570 align:start position:0%
about if you're tackling a problem for
which<00:06:23.840><c> you</c><00:06:24.350><c> either</c><00:06:24.410><c> have</c><00:06:24.680><c> a</c><00:06:24.710><c> lot</c><00:06:24.950><c> of</c><00:06:25.040><c> data</c><00:06:25.190><c> or</c>

00:06:25.570 --> 00:06:25.580 align:start position:0%
which you either have a lot of data or
 

00:06:25.580 --> 00:06:28.540 align:start position:0%
which you either have a lot of data or
not<00:06:26.030><c> a</c><00:06:26.090><c> lot</c><00:06:26.300><c> of</c><00:06:26.450><c> data</c><00:06:26.600><c> so</c><00:06:26.810><c> you</c><00:06:26.960><c> know</c><00:06:27.200><c> which</c><00:06:27.830><c> kind</c>

00:06:28.540 --> 00:06:28.550 align:start position:0%
not a lot of data so you know which kind
 

00:06:28.550 --> 00:06:31.750 align:start position:0%
not a lot of data so you know which kind
of<00:06:28.700><c> learning</c><00:06:28.910><c> you</c><00:06:29.150><c> should</c><00:06:29.180><c> prefer</c><00:06:30.080><c> and</c><00:06:30.760><c> for</c>

00:06:31.750 --> 00:06:31.760 align:start position:0%
of learning you should prefer and for
 

00:06:31.760 --> 00:06:34.150 align:start position:0%
of learning you should prefer and for
more<00:06:31.910><c> theoretical</c><00:06:32.810><c> details</c><00:06:33.200><c> on</c><00:06:33.410><c> this</c><00:06:33.560><c> invite</c>

00:06:34.150 --> 00:06:34.160 align:start position:0%
more theoretical details on this invite
 

00:06:34.160 --> 00:06:36.250 align:start position:0%
more theoretical details on this invite
you<00:06:34.280><c> to</c><00:06:34.400><c> consult</c><00:06:34.729><c> this</c><00:06:35.030><c> paper</c><00:06:35.270><c> on</c><00:06:35.600><c> this</c><00:06:36.020><c> random</c>

00:06:36.250 --> 00:06:36.260 align:start position:0%
you to consult this paper on this random
 

00:06:36.260 --> 00:06:39.909 align:start position:0%
you to consult this paper on this random
versus<00:06:36.830><c> genitive</c><00:06:37.550><c> classifiers</c><00:06:38.150><c> so</c><00:06:38.710><c> this</c><00:06:39.710><c> is</c><00:06:39.890><c> a</c>

00:06:39.909 --> 00:06:39.919 align:start position:0%
versus genitive classifiers so this is a
 

00:06:39.919 --> 00:06:40.360 align:start position:0%
versus genitive classifiers so this is a
paper

00:06:40.360 --> 00:06:40.370 align:start position:0%
paper
 

00:06:40.370 --> 00:06:44.410 align:start position:0%
paper
enjoying<00:06:40.910><c> and</c><00:06:41.120><c> michael</c><00:06:41.389><c> jordan</c><00:06:41.570><c> 2001</c>

