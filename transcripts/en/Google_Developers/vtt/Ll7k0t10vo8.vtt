WEBVTT
Kind: captions
Language: en

00:00:00.390 --> 00:00:02.300
FRED SAUER: What's the best
strategy to respond to

00:00:02.300 --> 00:00:03.840
requests that probably
take more than

00:00:03.840 --> 00:00:07.550
60 seconds to process?

00:00:07.550 --> 00:00:08.133
MANDY WAITE: Was that part
of the question?

00:00:08.133 --> 00:00:09.920
So make it back in process.

00:00:09.920 --> 00:00:11.080
It's a process to request.

00:00:11.080 --> 00:00:13.470
That's the best thing to do.

00:00:13.470 --> 00:00:17.530
You can do these things out of
bound almost from the actual

00:00:17.530 --> 00:00:18.220
request itself.

00:00:18.220 --> 00:00:20.390
So if the user makes a request,
you need to actually

00:00:20.390 --> 00:00:22.962
service that request within 60
seconds otherwise you'll hit a

00:00:22.962 --> 00:00:25.463
deadline exceeded exception
in both for

00:00:25.463 --> 00:00:27.310
Java and Python runtimes.

00:00:27.310 --> 00:00:32.460
That's a request timeout that we
have that's always in place

00:00:32.460 --> 00:00:35.710
for what we call frontend
instances currently.

00:00:35.710 --> 00:00:37.800
There's no such limitation
on backend instances.

00:00:37.800 --> 00:00:40.860
So what Fred said about moving
to the server model, if you

00:00:40.860 --> 00:00:43.490
choose to use a standard
instance that's not using

00:00:43.490 --> 00:00:45.700
autoscale, those things
won't apply.

00:00:45.700 --> 00:00:49.010
It won't automatically hit
its request timeout.

00:00:49.010 --> 00:00:52.110
So the best thing to do is if
you need to do heavy lifting,

00:00:52.110 --> 00:00:57.780
then when working to answer a
user request, you should find

00:00:57.780 --> 00:00:59.660
a way to do that asynchronously
out of bound

00:00:59.660 --> 00:01:01.840
from actually responding
to the user.

00:01:01.840 --> 00:01:05.800
So long-running task, let's say
the user makes a request

00:01:05.800 --> 00:01:09.665
or is always generating 100
emails to different people.

00:01:09.665 --> 00:01:12.312
What you need to do is return
the request back, which bumps

00:01:12.312 --> 00:01:14.870
out the user pretty quickly.

00:01:14.870 --> 00:01:18.465
And offline do them in the
background of the email-- the

00:01:18.465 --> 00:01:21.540
email processing using
a backend instance.

00:01:21.540 --> 00:01:23.130
It doesn't need to be
a backend instance.

00:01:23.130 --> 00:01:24.975
You can push it off to task
queues and then you can start

00:01:24.975 --> 00:01:28.580
using things like Compute Engine
and such like too.

00:01:28.580 --> 00:01:30.220
Compute Engine has the
ability to do pull

00:01:30.220 --> 00:01:31.510
requests using task queues.

00:01:31.510 --> 00:01:35.730
So you can use Compute Engine
instances to service those

00:01:35.730 --> 00:01:36.630
requests as well.

00:01:36.630 --> 00:01:38.730
But yeah, basically take it
away from the frontend

00:01:38.730 --> 00:01:41.405
instances and push it into the
background somewhere using the

00:01:41.405 --> 00:01:42.980
backend process or
Compute Engine.

00:01:42.980 --> 00:01:47.040
FRED SAUER: Yep, task queue is
definitely the way to go.

00:01:47.040 --> 00:01:50.480
The pull queues you mentioned
are great for working with

00:01:50.480 --> 00:01:54.290
external systems like doing
off App Engine work, like

00:01:54.290 --> 00:01:58.410
Compute Engine, but you could
really do it on a server that

00:01:58.410 --> 00:02:01.010
you have sitting on a rack in
your office if you have some

00:02:01.010 --> 00:02:03.460
special processing that
you need to do.

00:02:03.460 --> 00:02:06.510
And then push queues are a great
way of enqueuing work

00:02:06.510 --> 00:02:07.560
asynchronously.

00:02:07.560 --> 00:02:13.120
And those requests come back to
your application as if it

00:02:13.120 --> 00:02:15.710
were traffic, but it's
internal traffic.

00:02:15.710 --> 00:02:17.930
So App Engine will scale up and
down if you create more

00:02:17.930 --> 00:02:22.210
requests and then you have a 10
minute deadline instead of

00:02:22.210 --> 00:02:24.970
a 60 second, so you can easily
make those long-running URL

00:02:24.970 --> 00:02:27.000
Fetch calls or do more
complex processing.

