WEBVTT
Kind: captions
Language: en

00:00:12.760 --> 00:00:14.616
It's 1996

00:00:14.640 --> 00:00:16.656
in Uvira in eastern Congo.

00:00:16.680 --> 00:00:18.016
This is Bukeni.

00:00:18.040 --> 00:00:20.736
Militia commanders walk into his village,

00:00:20.760 --> 00:00:22.536
knock on his neighbors' doors

00:00:22.560 --> 00:00:25.720
and whisk their children away
to training camps.

00:00:26.320 --> 00:00:30.576
Bukeni borrows a video camera
from a local wedding photographer,

00:00:30.600 --> 00:00:32.376
he disguises as a journalist

00:00:32.400 --> 00:00:35.960
and he walks into the camps
to negotiate the release of the children.

00:00:36.560 --> 00:00:40.520
He filmed footage of the children
being trained as soldiers.

00:00:40.568 --> 00:00:43.158
[Soldiers don't worry!]

00:00:43.202 --> 00:00:44.680
[You'll wear uniforms!]

00:00:45.220 --> 00:00:46.890
[You'll have free cars!]

00:00:46.920 --> 00:00:47.660
[Free beans!]

00:00:47.680 --> 00:00:51.216
Many of these children
are under 15 years old,

00:00:51.240 --> 00:00:53.210
and that is a war crime.

00:00:53.270 --> 00:00:54.410
[Free!]

00:00:55.280 --> 00:00:59.040
But you don't have to go to eastern Congo
to find human rights abuses.

00:00:59.760 --> 00:01:03.536
In America, a country
with a rapidly aging population,

00:01:03.560 --> 00:01:07.936
experts estimate
that one in 10 people over 60

00:01:07.960 --> 00:01:09.960
will experience abuse.

00:01:10.640 --> 00:01:12.976
It's a hidden epidemic,

00:01:13.000 --> 00:01:15.776
and most of that abuse
actually happens at the hands

00:01:15.800 --> 00:01:17.880
of close caretakers or family.

00:01:19.200 --> 00:01:20.536
This is Vicky.

00:01:20.560 --> 00:01:25.016
Vicky put an iron gate on her bedroom door

00:01:25.040 --> 00:01:28.136
and she became a prisoner,
in fact, in her own house,

00:01:28.160 --> 00:01:32.520
out of fear for her nephew
who had taken over her home as a drug den.

00:01:33.760 --> 00:01:35.056
And this is Mary.

00:01:35.080 --> 00:01:38.216
Mary picked up a video camera
for the first time in her life

00:01:38.240 --> 00:01:40.176
when she was 65 years old,

00:01:40.200 --> 00:01:44.616
and she asked Vicky
and 99 other older people

00:01:44.640 --> 00:01:48.240
who had experienced abuse
to tell their stories on camera.

00:01:50.160 --> 00:01:52.016
And I am Dutch,

00:01:52.040 --> 00:01:55.016
so in the Netherlands
we are obsessed with the truth.

00:01:55.040 --> 00:01:57.496
Now, when you are a child,
that's a great thing,

00:01:57.520 --> 00:02:00.136
because you can basically
get away with anything,

00:02:00.160 --> 00:02:03.456
like "Yes, Mama,
it was me who smoked the cigars."

00:02:03.480 --> 00:02:05.120
(Laughter)

00:02:05.920 --> 00:02:09.896
But I think this is why
I have dedicated my life

00:02:09.920 --> 00:02:14.176
to promoting citizen video
to expose human rights violations,

00:02:14.200 --> 00:02:18.520
because I believe in the power of video
to create undeniable truths.

00:02:19.400 --> 00:02:21.096
And my organization, WITNESS,

00:02:21.120 --> 00:02:23.856
helped use the Congolese videos

00:02:23.880 --> 00:02:30.360
to help convict and send a notorious
warlord called Thomas Lubanga to jail.

00:02:31.440 --> 00:02:33.896
And the videos that Mary shot,

00:02:33.920 --> 00:02:36.896
we trained Mary and many other
elder justice advocates,

00:02:36.920 --> 00:02:39.736
to make sure that
the stories of elder abuse

00:02:39.760 --> 00:02:41.376
reached lawmakers,

00:02:41.400 --> 00:02:45.256
and those stories
helped convince lawmakers

00:02:45.280 --> 00:02:48.440
to pass landmark legislation
to protect older Americans.

00:02:50.280 --> 00:02:52.216
So I wonder,

00:02:52.240 --> 00:02:56.896
billions of us now have this powerful tool
right at our fingertips.

00:02:56.920 --> 00:02:58.416
It's a camera.

00:02:58.440 --> 00:03:03.256
So why are all of us not a more
powerful army of civic witnesses,

00:03:03.280 --> 00:03:05.336
like Mary and Bukeni?

00:03:05.360 --> 00:03:08.216
Why is it that so much more video

00:03:08.240 --> 00:03:11.760
is not leading to more rights
and more justice?

00:03:13.000 --> 00:03:17.536
And I think it is because
being an eyewitness is hard.

00:03:17.560 --> 00:03:20.016
Your story will get denied,

00:03:20.040 --> 00:03:22.896
your video will get lost
in a sea of images,

00:03:22.920 --> 00:03:26.600
your story will not be trusted,
and you will be targeted.

00:03:27.920 --> 00:03:29.920
So how do we help witnesses?

00:03:31.560 --> 00:03:33.256
In Oaxaca, in Mexico,

00:03:33.280 --> 00:03:35.856
the teachers' movement organized a protest

00:03:35.880 --> 00:03:39.400
after the president pushed down
very undemocratic reforms.

00:03:40.160 --> 00:03:43.960
The federal police came down in buses
and started shooting at the protesters.

00:03:44.640 --> 00:03:48.256
At least seven people died
and many, many more were wounded.

00:03:48.280 --> 00:03:51.656
Images started circulating
of the shootings,

00:03:51.680 --> 00:03:54.096
and the Mexican government
did what it always does.

00:03:54.120 --> 00:03:55.536
It issued a formal statement,

00:03:55.560 --> 00:03:58.936
and the statement basically
accused the independent media

00:03:58.960 --> 00:04:01.016
of creating fake news.

00:04:01.040 --> 00:04:02.816
It said, "We were not there,

00:04:02.840 --> 00:04:05.576
that was not us doing the shooting,

00:04:05.600 --> 00:04:06.960
this did not happen."

00:04:08.760 --> 00:04:11.976
But we had just trained
activists in Mexico

00:04:12.000 --> 00:04:15.776
to use metadata strategically
with their images.

00:04:15.800 --> 00:04:19.536
Now, metadata is the kind of information
that your camera captures

00:04:19.560 --> 00:04:22.576
that shows the date, the location,

00:04:22.600 --> 00:04:24.336
the temperature, the weather.

00:04:24.360 --> 00:04:27.776
It can even show the very unique way
you hold your camera

00:04:27.800 --> 00:04:29.536
when you capture something.

00:04:29.560 --> 00:04:31.656
So the images started recirculating,

00:04:31.680 --> 00:04:34.776
and this time with the very verifying,

00:04:34.800 --> 00:04:36.880
validating information on top of them.

00:04:37.960 --> 00:04:40.680
And the federal government
had to retract their statement.

00:04:41.520 --> 00:04:45.096
Now, justice for the people for Oaxaca

00:04:45.120 --> 00:04:46.536
is still far off,

00:04:46.560 --> 00:04:50.040
but their stories, their truths,
can no longer be denied.

00:04:51.240 --> 00:04:53.016
So we started thinking:

00:04:53.040 --> 00:04:54.736
What if you had "Proof Mode?"

00:04:54.760 --> 00:04:56.896
What if everybody had
a camera in their hands

00:04:56.920 --> 00:05:00.416
and all the platforms
had that kind of validating ability.

00:05:00.440 --> 00:05:01.696
So we developed --

00:05:01.720 --> 00:05:06.176
together with amazing Android developers
called the Guardian Project,

00:05:06.200 --> 00:05:09.496
we developed something called
a technology that's called Proof Mode,

00:05:09.520 --> 00:05:12.696
that marries those metadata
together with your image,

00:05:12.720 --> 00:05:15.440
and it validates
and it verifies your video.

00:05:16.520 --> 00:05:20.536
Now, imagine there is a deluge of images

00:05:20.560 --> 00:05:22.960
coming from the world's camera phones.

00:05:23.640 --> 00:05:27.640
Imagine if that information
could be trusted just a little bit more,

00:05:28.520 --> 00:05:30.856
what the potential
would be for journalists,

00:05:30.880 --> 00:05:32.696
for human rights investigators,

00:05:32.720 --> 00:05:34.160
for human rights lawyers.

00:05:35.440 --> 00:05:39.016
So we started sharing Proof Mode
with our partners in Brazil

00:05:39.040 --> 00:05:42.320
who are an amazing media collective
called Coletivo Papo Reto.

00:05:44.280 --> 00:05:47.120
Brazil is a tough place for human rights.

00:05:47.680 --> 00:05:51.640
The Brazilian police
kills thousands of people every year.

00:05:52.400 --> 00:05:54.720
The only time that
there's an investigation,

00:05:55.920 --> 00:05:57.120
guess when?

00:05:57.440 --> 00:05:58.640
When there's video.

00:06:00.240 --> 00:06:03.680
Seventeen-year-old Eduardo
was killed in broad daylight

00:06:04.640 --> 00:06:06.216
by the Rio police,

00:06:06.240 --> 00:06:08.520
and look what happens after they kill him.

00:06:10.320 --> 00:06:12.320
They put a gun in the dead boy's hand,

00:06:12.880 --> 00:06:14.600
they shoot the gun twice --

00:06:15.840 --> 00:06:17.040
(Shot)

00:06:17.600 --> 00:06:21.720
to fabricate their story of self-defense.

00:06:22.440 --> 00:06:25.896
The woman who filmed this
was a very, very courageous eyewitness,

00:06:25.920 --> 00:06:29.296
and she had to go into hiding
after she posted her video

00:06:29.320 --> 00:06:30.600
for fear of her life.

00:06:31.240 --> 00:06:34.696
But people are filming,
and they're not going to stop filming,

00:06:34.720 --> 00:06:37.736
so we're now working together
with media collectives

00:06:37.760 --> 00:06:40.256
so the residents on their WhatsApp

00:06:40.280 --> 00:06:43.016
frequently get guidance and tips,

00:06:43.040 --> 00:06:44.776
how to film safely,

00:06:44.800 --> 00:06:47.736
how to upload the video
that you shoot safely,

00:06:47.760 --> 00:06:51.560
how to capture a scene
so that it can actually count as evidence.

00:06:52.360 --> 00:06:54.456
And here is an inspiration

00:06:54.480 --> 00:06:57.320
from a group called MÃ­dia Ninja in Brazil.

00:06:58.480 --> 00:07:02.320
The man on left is a heavily armed
military policeman.

00:07:04.000 --> 00:07:05.496
He walks up to a protester --

00:07:05.520 --> 00:07:08.736
when you protest in Brazil,
you can be arrested or worse --

00:07:08.760 --> 00:07:11.336
and he says to the protester, "Watch me,

00:07:11.360 --> 00:07:13.880
I am going to search you right now."

00:07:15.080 --> 00:07:18.400
And the protester
is a live-streaming activist --

00:07:18.840 --> 00:07:20.296
he wears a little camera --

00:07:20.320 --> 00:07:24.256
and he says to the military policeman,
he says, "I am watching you,

00:07:24.280 --> 00:07:27.360
and there are 5,000 people
watching you with me."

00:07:28.400 --> 00:07:30.856
Now, the tables are turned.

00:07:30.880 --> 00:07:34.160
The distant witnesses,
the watching audience, they matter.

00:07:35.240 --> 00:07:36.896
So we started thinking,

00:07:36.920 --> 00:07:39.496
what if you could tap into that power,

00:07:39.520 --> 00:07:41.696
the power of distant witnesses?

00:07:41.720 --> 00:07:44.456
What if you could pull in
their expertise, their leverage,

00:07:44.480 --> 00:07:46.616
their solidarity, their skills

00:07:46.640 --> 00:07:49.680
when a frontline community
needs them to be there?

00:07:50.960 --> 00:07:56.296
And we started developing
a project that's called Mobilize Us,

00:07:56.320 --> 00:07:59.536
because many of us, I would assume,

00:07:59.560 --> 00:08:01.216
want to help

00:08:01.240 --> 00:08:03.856
and lend our skills and our expertise,

00:08:03.880 --> 00:08:06.736
but we are often not there
when a frontline community

00:08:06.760 --> 00:08:09.520
or a single individual faces an abuse.

00:08:10.760 --> 00:08:14.416
And it could be as simple
as this little app that we created

00:08:14.440 --> 00:08:17.496
that just shows the perpetrator
on the other side of the phone

00:08:17.520 --> 00:08:19.840
how many people are watching him.

00:08:20.880 --> 00:08:25.216
But now, imagine that you could put
a layer of computer task routing

00:08:25.240 --> 00:08:26.656
on top of that.

00:08:26.680 --> 00:08:30.720
Imagine that you're a community
facing an immigration raid,

00:08:31.520 --> 00:08:35.256
and at that very moment,
at that right moment, via livestream,

00:08:35.280 --> 00:08:37.760
you could pull in
a hundred legal observers.

00:08:38.400 --> 00:08:40.320
How would that change the situation?

00:08:41.320 --> 00:08:45.015
So we started piloting this
with our partner communities in Brazil.

00:08:45.039 --> 00:08:47.176
This is a woman called Camilla,

00:08:47.200 --> 00:08:51.000
and she was able -- she's the leader
in a favela called Favela Skol --

00:08:51.919 --> 00:08:56.056
she was able to pull in distant witnesses

00:08:56.080 --> 00:08:58.136
via livestream

00:08:58.160 --> 00:08:59.896
to help translation,

00:08:59.920 --> 00:09:01.536
to help distribution,

00:09:01.560 --> 00:09:04.336
to help amplify her story

00:09:04.360 --> 00:09:07.056
after her community was forcibly evicted

00:09:07.080 --> 00:09:10.960
to make room for a very glossy
Olympic event last summer.

00:09:12.920 --> 00:09:14.960
So we're talking about good witnessing,

00:09:15.920 --> 00:09:19.096
but what happens
if the perpetrators are filming?

00:09:19.120 --> 00:09:22.480
What happens if a bystander films
and doesn't do anything?

00:09:23.680 --> 00:09:25.896
This is the story of Chrissy.

00:09:25.920 --> 00:09:28.256
Chrissy is a transgender woman

00:09:28.280 --> 00:09:30.896
who walked into a McDonald's in Maryland

00:09:30.920 --> 00:09:32.360
to use the women's bathroom.

00:09:32.960 --> 00:09:38.376
Two teens viciously beat her
for using that woman's bathroom,

00:09:38.400 --> 00:09:41.520
and the McDonald's employee
filmed this on his mobile phone.

00:09:42.760 --> 00:09:44.200
And he posted his video,

00:09:44.920 --> 00:09:46.616
and it has garnered

00:09:46.640 --> 00:09:50.480
thousands of racist
and transphobic comments.

00:09:52.920 --> 00:09:55.800
So we started a project
that's called Capturing Hate.

00:09:56.840 --> 00:10:00.776
We took a very, very small sample
of eyewitness videos

00:10:00.800 --> 00:10:06.176
that showed abuse against transgender
and gender-nonconforming people.

00:10:06.200 --> 00:10:10.200
We searched two words,
"tranny fight" and "stud fight."

00:10:11.240 --> 00:10:16.296
And those 329 videos were watched
and are still being watched

00:10:16.320 --> 00:10:18.616
as we sit here in this theater,

00:10:18.640 --> 00:10:22.176
a stunning almost 90 million times,

00:10:22.200 --> 00:10:25.416
and there are hundreds of thousands
of comments with these videos,

00:10:25.440 --> 00:10:28.320
egging on to more violence and more hate.

00:10:30.240 --> 00:10:32.656
So we started developing a methodology

00:10:32.680 --> 00:10:36.976
that took all that
unquantified visual evidence

00:10:37.000 --> 00:10:41.416
and turned it into data,
turning video into data,

00:10:41.440 --> 00:10:42.696
and with that tool,

00:10:42.720 --> 00:10:47.136
LGBT organizations are now using that data

00:10:47.160 --> 00:10:48.720
to fight for rights.

00:10:49.400 --> 00:10:52.616
And we take that data
and we take it back to Silicon Valley,

00:10:52.640 --> 00:10:54.136
and we say to them:

00:10:54.160 --> 00:10:55.760
"How is it possible

00:10:56.600 --> 00:11:00.576
that these videos are still out there

00:11:00.600 --> 00:11:02.496
in a climate of hate

00:11:02.520 --> 00:11:04.376
egging on more hate,

00:11:04.400 --> 00:11:06.416
summoning more violence,

00:11:06.440 --> 00:11:08.856
when you have policies that actually say

00:11:08.880 --> 00:11:12.096
you do not allow this kind of content? --

00:11:12.120 --> 00:11:14.640
urging them to change their policies.

00:11:16.480 --> 00:11:19.136
So I have hope.

00:11:19.160 --> 00:11:23.560
I have hope that we can turn more video
into more rights and more justice.

00:11:24.360 --> 00:11:29.640
Ten billion video views
on Snapchat,

00:11:30.760 --> 00:11:32.296
per day.

00:11:32.320 --> 00:11:35.616
So what if we could turn
that Snapchat generation

00:11:35.640 --> 00:11:38.856
into effective and safe civic witnesses?

00:11:38.880 --> 00:11:42.520
What if they could become
the Bukenis of this new generation?

00:11:44.920 --> 00:11:48.936
In India, women have already
started using Snapchat filters

00:11:48.960 --> 00:11:52.840
to protect their identity when they
speak out about domestic violence.

00:11:52.860 --> 00:11:55.800
[They tortured me at home
and never let me go out.]

00:11:55.840 --> 00:11:59.416
The truth is, the real truth, the truth
that doesn't fit into any TED Talk,

00:11:59.440 --> 00:12:02.296
is fighting human rights abuse is hard.

00:12:02.320 --> 00:12:05.376
There are no easy solutions
for human rights abuse.

00:12:05.400 --> 00:12:08.136
And there's not a single
piece of technology

00:12:08.160 --> 00:12:10.040
that can ever stop the perpetrators.

00:12:11.400 --> 00:12:12.840
But for the survivors,

00:12:13.920 --> 00:12:15.536
for the victims,

00:12:15.560 --> 00:12:17.360
for the marginalized communities,

00:12:18.160 --> 00:12:22.616
their stories, their truths, matter.

00:12:22.640 --> 00:12:25.456
And that is where justice begins.

00:12:25.480 --> 00:12:26.696
Thank you.

00:12:26.720 --> 00:12:29.640
(Applause)

