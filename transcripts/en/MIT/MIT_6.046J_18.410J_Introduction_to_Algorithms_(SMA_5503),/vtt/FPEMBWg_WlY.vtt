WEBVTT
Kind: captions
Language: en

00:00:07.000 --> 00:00:12.431
-- valuable experience.
OK, today we're going to start

00:00:12.431 --> 00:00:18.477
talking about a particular class
of algorithms called greedy

00:00:18.477 --> 00:00:22.780
algorithms.
But we're going to do it in the

00:00:22.780 --> 00:00:27.597
context of graphs.
So, I want to review a little

00:00:27.597 --> 00:00:32.208
bit about graphs,
which mostly you can find in

00:00:32.208 --> 00:00:39.798
the textbook in appendix B.
And so, if you haven't reviewed

00:00:39.798 --> 00:00:45.801
in appendix B recently,
please sit down and review

00:00:45.801 --> 00:00:50.334
appendix B.
It will pay off especially

00:00:50.334 --> 00:00:55.725
during our take-home quiz.
So, just reminder,

00:00:55.725 --> 00:01:01.850
a digraph, what's a digraph?
What's that short for?

00:01:01.850 --> 00:01:04.056
Directed graph,
OK?

00:01:04.056 --> 00:01:07.731
Directed graph,
G equals (V,E),

00:01:07.731 --> 00:01:13.000
OK, has a set,
V, of vertices.

00:01:13.000 --> 00:01:17.365
And, I always get people
telling me that I have one

00:01:17.365 --> 00:01:20.507
vertice.
The singular is not vertice;

00:01:20.507 --> 00:01:21.904
it is vertex,
OK?

00:01:21.904 --> 00:01:25.920
The plural is vertices.
The singular is vertex.

00:01:25.920 --> 00:01:29.150
It's one of those weird English
words.

00:01:29.150 --> 00:01:33.428
It's probably originally like
French or something,

00:01:33.428 --> 00:01:37.207
right?
I don't know.

00:01:37.207 --> 00:01:47.566
OK, anyway, and we have a set,
E, which is a subset of V cross

00:01:47.566 --> 00:01:52.830
V of edges.
So that's a digraph.

00:01:52.830 --> 00:02:02.000
And undirected graph,
E contains unordered pairs.

00:02:12.000 --> 00:02:15.654
OK, and, sorry?
It's Latin, OK,

00:02:15.654 --> 00:02:21.137
so it's probably pretty old,
then, in English.

00:02:21.137 --> 00:02:28.203
I guess the vertex would be a
little bit of a giveaway that

00:02:28.203 --> 00:02:34.659
maybe it wasn't French.
It started to be used in 1570,

00:02:34.659 --> 00:02:39.313
OK.
OK, good, OK,

00:02:39.313 --> 00:02:52.058
so the number of edges is,
whether it's directed or

00:02:52.058 --> 00:03:02.000
undirected, is O of what?
V^2, good.

00:03:02.000 --> 00:03:05.600
OK, and one of the conventions
that will have when we're

00:03:05.600 --> 00:03:09.331
dealing, once we get into
graphs, we deal a lot with sets.

00:03:09.331 --> 00:03:13.128
We generally drop the vertical
bar notation within O's just

00:03:13.128 --> 00:03:16.139
because it's applied.
It just makes it messier.

00:03:16.139 --> 00:03:18.823
So, once again,
another abuse of notation.

00:03:18.823 --> 00:03:22.751
It really should be order the
size of V^2, but it just messes

00:03:22.751 --> 00:03:25.762
up, I mean, it's just more stuff
to write down.

00:03:25.762 --> 00:03:29.625
And, you're multiplying these
things, and all those vertical

00:03:29.625 --> 00:03:33.268
bars.
Since they don't even have a

00:03:33.268 --> 00:03:36.508
sense to the vertical bar,
it gets messy.

00:03:36.508 --> 00:03:40.720
So, we just drop the vertical
bars there when it's in

00:03:40.720 --> 00:03:44.770
asymptotic notation.
So, E is order V^2 when it's a

00:03:44.770 --> 00:03:48.335
set of pairs,
because if it's a set of pairs,

00:03:48.335 --> 00:03:52.952
it's at most n choose two,
which is where it's at most n^2

00:03:52.952 --> 00:03:56.192
over 2, here it could be,
at most, sorry,

00:03:56.192 --> 00:04:00.000
V^2 over 2, here it's at most
V^2.

00:04:00.000 --> 00:04:07.563
And then, another property that
sometimes comes up is if the G

00:04:07.563 --> 00:04:11.903
is connected,
we have another bound,

00:04:11.903 --> 00:04:18.971
implies that the size of E is
at least the size of V minus

00:04:18.971 --> 00:04:22.567
one.
OK, so if it's connected,

00:04:22.567 --> 00:04:31.000
meaning, what does it mean to
have a graph that's connected?

00:04:31.000 --> 00:04:37.089
Yeah, there's a path from any
vertex to any other vertex in

00:04:37.089 --> 00:04:40.870
the graph.
That's what it means to be

00:04:40.870 --> 00:04:44.230
connected.
So if that's the case,

00:04:44.230 --> 00:04:50.110
that a number of edges is at
least the number of vertices

00:04:50.110 --> 00:04:53.995
minus one, OK?
And so, what that says,

00:04:53.995 --> 00:05:00.399
so one of the things we'll get
into, a fact that I just wanted

00:05:00.399 --> 00:05:04.074
to remind you,
is that in that case,

00:05:04.074 --> 00:05:09.324
if I look at log E,
OK, log of the number of edges,

00:05:09.324 --> 00:05:14.067
that is O of log V.
And by this,

00:05:14.067 --> 00:05:18.338
is omega of log V.
So, it's equal to theta of log

00:05:18.338 --> 00:05:21.275
V.
OK, so basically the number of,

00:05:21.275 --> 00:05:25.991
in the case of a connected
graph, the number of edges,

00:05:25.991 --> 00:05:30.529
and the number of vertices are
polynomially related.

00:05:30.529 --> 00:05:36.558
So, their logs are comparable.
OK, so that's helpful just to

00:05:36.558 --> 00:05:41.588
know because sometimes I just
get questions later on where

00:05:41.588 --> 00:05:45.735
people will say,
oh, you showed it was log E but

00:05:45.735 --> 00:05:51.029
you didn't show it was log V.
And I could point out that it's

00:05:51.029 --> 00:05:55.000
the same thing.
OK, so there's various ways of

00:05:55.000 --> 00:05:59.764
representing graphs in
computers, and I'm just going to

00:05:59.764 --> 00:06:04.000
cover a couple of the important
ones.

00:06:04.000 --> 00:06:11.137
There's actually more.
We'll see some more.

00:06:11.137 --> 00:06:20.823
So, the simplest one is what's
called an adjacency matrix.

00:06:20.823 --> 00:06:30.000
An adjacency matrix of the
graph, G, equals (V,E),

00:06:30.000 --> 00:06:40.360
where, for simplicity,
I'll let V be the set of

00:06:40.360 --> 00:06:52.072
integers from one up to n,
OK, is the n by n matrix A

00:06:52.072 --> 00:07:04.909
given by the ij-th at the entry
is simply one if the edge,

00:07:04.909 --> 00:07:20.000
ij, is in the edge set and zero
if ij is not in the edge set.

00:07:20.000 --> 00:07:22.948
OK, so it's simply the matrix
where you say,

00:07:22.948 --> 00:07:25.759
the ij entry is one if it's in
the matrix.

00:07:25.759 --> 00:07:27.542
So, this is,
in some sense,

00:07:27.542 --> 00:07:32.000
giving you the predicate for,
is there an edge from i to j?

00:07:32.000 --> 00:07:35.716
OK, remember,
predicate is Boolean formula

00:07:35.716 --> 00:07:39.703
that is either zero or one,
and in this case,

00:07:39.703 --> 00:07:45.323
you're saying it's one if there
is an edge from i to j and zero

00:07:45.323 --> 00:07:48.676
otherwise.
OK, sometimes you have edge

00:07:48.676 --> 00:07:52.845
weighted graphs,
and then sometimes what people

00:07:52.845 --> 00:07:56.380
will do is replace this by edge
weights.

00:07:56.380 --> 00:08:02.000
OK, it will be the weight of
the edge from i to j.

00:08:02.000 --> 00:08:12.982
So, let's just do an example of
that just to make sure that our

00:08:12.982 --> 00:08:22.371
intuition corresponds to our
mathematical definitions.

00:08:22.371 --> 00:08:33.000
So, here's an example graph.
Let's say that's our graph.

00:08:33.000 --> 00:08:37.073
So let's just draw the
adjacency the matrix.

00:08:37.073 --> 00:08:42.000
OK, so what this says:
is there's an edge from one to

00:08:42.000 --> 00:08:44.368
one?
And the answer is no.

00:08:44.368 --> 00:08:47.399
Is there an edge from one to
two?

00:08:47.399 --> 00:08:50.431
Yes.
Is there an edge from one to

00:08:50.431 --> 00:08:51.852
three here?
Yep.

00:08:51.852 --> 00:08:54.884
Is there an edge for one to
four?

00:08:54.884 --> 00:08:58.105
No.
Is there an edge from two until

00:08:58.105 --> 00:09:00.410
one?
No.

00:09:00.410 --> 00:09:02.327
Two to two?
No.

00:09:02.327 --> 00:09:04.655
Two to three?
Yes.

00:09:04.655 --> 00:09:06.709
Two to four?
No.

00:09:06.709 --> 00:09:13.829
No edges going out of three.
Edge from four to three,

00:09:13.829 --> 00:09:19.991
and that's it.
That's the adjacency matrix for

00:09:19.991 --> 00:09:23.414
this particular graph,
OK?

00:09:23.414 --> 00:09:33.000
And so, I can represent a graph
as this adjacency matrix.

00:09:33.000 --> 00:09:43.327
OK, when I represent it in this
way, how much storage do I need?

00:09:43.327 --> 00:09:52.508
OK, n^2 or V^2 because the size
is the same thing for V^2

00:09:52.508 --> 00:10:03.000
storage, OK, and that's what we
call a dense representation.

00:10:03.000 --> 00:10:06.321
OK, it works well when the
graph is dense.

00:10:06.321 --> 00:10:11.181
So, the graph is dense if the
number of edges is close to all

00:10:11.181 --> 00:10:14.826
of the edges possible.
OK, then this is a good

00:10:14.826 --> 00:10:18.391
representation.
But for many types of graphs,

00:10:18.391 --> 00:10:23.170
the number of edges is much
less than the possible number of

00:10:23.170 --> 00:10:26.977
edges, in which case we say the
graph is sparse.

00:10:26.977 --> 00:10:32.000
Can somebody give me an example
of a sparse graph?

00:10:32.000 --> 00:10:35.519
A class of graphs:
so, I want a class of graphs

00:10:35.519 --> 00:10:38.733
that as n grows,
the number of edges in the

00:10:38.733 --> 00:10:42.712
graph doesn't grow as the
square, but grows rather as

00:10:42.712 --> 00:10:45.543
something much smaller.
A linked list,

00:10:45.543 --> 00:10:48.604
so, a chain,
OK, if you look at it from a

00:10:48.604 --> 00:10:52.277
graph theoretically,
is a perfectly good example:

00:10:52.277 --> 00:10:56.026
only n edges in the chain for a
chain of length n.

00:10:56.026 --> 00:10:59.163
So therefore,
the number of edges would be

00:10:59.163 --> 00:11:02.969
order V.
And in particular,

00:11:02.969 --> 00:11:07.018
you'd only have one edge per
row here.

00:11:07.018 --> 00:11:10.739
What other graphs are sparse?
Yeah?

00:11:10.739 --> 00:11:16.320
Good, a planar graph,
a graph that can be drawn in a

00:11:16.320 --> 00:11:21.245
plane turns out that if it has V
vertices has,

00:11:21.245 --> 00:11:25.184
and V is at least three,
then it has,

00:11:25.184 --> 00:11:30.000
at most, three V minus six
edges.

00:11:30.000 --> 00:11:34.393
So, it turns out that's order V
edges again.

00:11:34.393 --> 00:11:38.479
What's another example of a
common graph?

00:11:38.479 --> 00:11:42.975
Yeah, binary tree,
or even actually any tree,

00:11:42.975 --> 00:11:49.105
you know, what's called a free
tree if you read the appendix,

00:11:49.105 --> 00:11:54.417
OK, a tree that just is a
connected graph that has no

00:11:54.417 --> 00:12:00.445
cycles, OK, is another example.
What's an example of a graph

00:12:00.445 --> 00:12:04.343
that's dense?
A complete graph,

00:12:04.343 --> 00:12:07.582
OK: it's all ones,
OK, or if you have edge

00:12:07.582 --> 00:12:11.533
weights, it would be a
completely filled in matrix.

00:12:11.533 --> 00:12:14.298
OK, good.
So, this is good for dense

00:12:14.298 --> 00:12:17.854
representation.
But sometimes you want to have

00:12:17.854 --> 00:12:22.674
a sparse representation so we
don't have to spend V^2 space to

00:12:22.674 --> 00:12:26.703
deal with all of the,
where most of it's going to be

00:12:26.703 --> 00:12:28.995
zeroes.
OK, it's sort of like,

00:12:28.995 --> 00:12:33.261
if we know why it's zero,
why bother representing it as

00:12:33.261 --> 00:12:40.625
zero?
So, one such representation is

00:12:40.625 --> 00:12:46.625
an adjacency list
representation.

00:12:46.625 --> 00:12:56.750
Actually, adjacency list of a
given vertex is the list,

00:12:56.750 --> 00:13:08.000
which we denote by Adj of V,
of vertices adjacent to V.

00:13:08.000 --> 00:13:12.847
OK, just in terms by their
terminology, vertices are

00:13:12.847 --> 00:13:17.028
adjacent, but edges are incident
on vertices.

00:13:17.028 --> 00:13:22.446
OK, so the incidence is a
relation between a vertex and an

00:13:22.446 --> 00:13:25.392
edge.
An adjacency is a relation

00:13:25.392 --> 00:13:31.000
between two vertices.
OK, that's just the language.

00:13:31.000 --> 00:13:36.221
Why they use to different
terms, I don't know,

00:13:36.221 --> 00:13:40.979
but that's what they do.
So, in the graph,

00:13:40.979 --> 00:13:45.737
for example,
the adjacency list for vertex

00:13:45.737 --> 00:13:52.583
one is just the list or the set
of two three because one has

00:13:52.583 --> 00:13:57.573
going out of one are edges to
two and three.

00:13:57.573 --> 00:14:02.911
The adjacency list for two is
just three, four,

00:14:02.911 --> 00:14:07.225
three.
It's the empty set,

00:14:07.225 --> 00:14:10.153
and for four,
it is three.

00:14:10.153 --> 00:14:13.900
OK, so that's the
representation.

00:14:13.900 --> 00:14:21.045
Now, if we want to figure out
how much storage is required for

00:14:21.045 --> 00:14:26.783
this representation,
OK, we need to understand how

00:14:26.783 --> 00:14:35.777
long the adjacency list is.
So, what is the length of an

00:14:35.777 --> 00:14:40.725
adjacency list of a vertex,
V?

00:14:40.725 --> 00:14:48.402
What name do we give to that?
It's the degree.

00:14:48.402 --> 00:14:57.786
So, in an undirected graph,
we call it the degree of the

00:14:57.786 --> 00:15:02.222
vertex.
This is undirected.

00:15:02.222 --> 00:15:07.000
OK, about here,
OK.

00:15:07.000 --> 00:15:12.122
So that's an undirected case.
In the directed case,

00:15:12.122 --> 00:15:18.065
OK, actually I guess the way we
should do this is say this.

00:15:18.065 --> 00:15:22.676
If the degree,
we call it the out degree for a

00:15:22.676 --> 00:15:25.545
digraph.
OK, so in a digraph,

00:15:25.545 --> 00:15:32.000
we have an out degree and an in
degree for each vertex.

00:15:32.000 --> 00:15:36.658
So here, the in degree is
three.

00:15:36.658 --> 00:15:41.316
Here, the out degree is two,
OK?

00:15:41.316 --> 00:15:50.331
So, one of the important lemma
that comes up is what's called

00:15:50.331 --> 00:15:56.792
the handshaking lemma.
OK, it's one of these

00:15:56.792 --> 00:16:01.000
mathematical lemmas.

00:16:11.000 --> 00:16:16.100
And so, it comes from a story.
Go to a dinner party,

00:16:16.100 --> 00:16:21.500
and everybody at the dinner
party shakes other people's

00:16:21.500 --> 00:16:24.600
hands.
Some people may not shake

00:16:24.600 --> 00:16:29.000
anybody's hand.
Some people may shake several

00:16:29.000 --> 00:16:32.899
people's hands.
Nobody shakes hands with

00:16:32.899 --> 00:16:37.341
themselves.
And at some point during the

00:16:37.341 --> 00:16:41.020
dinner party,
the host goes around and counts

00:16:41.020 --> 00:16:45.033
up how many, the sum,
of the number of hands that

00:16:45.033 --> 00:16:48.210
each person has shaken.
OK, so he says,

00:16:48.210 --> 00:16:52.056
how many did you shake?
How many did you shake?

00:16:52.056 --> 00:16:55.317
How many did you shake?
He adds them up,

00:16:55.317 --> 00:17:00.000
OK, and that number is
guaranteed to be even.

00:17:00.000 --> 00:17:03.190
OK, that's the handshaking
lemma.

00:17:03.190 --> 00:17:08.773
Or, stated a little bit more
precisely, if I take for any

00:17:08.773 --> 00:17:13.858
graph the degree of the vertex,
and sum them all up,

00:17:13.858 --> 00:17:20.138
that's how many hands everybody
shook, OK, that's actually equal

00:17:20.138 --> 00:17:23.628
to always twice the number of
edges.

00:17:23.628 --> 00:17:26.818
So, why is that going to be
true?

00:17:26.818 --> 00:17:33.000
Why is that going to be twice
the number of edges?

00:17:33.000 --> 00:17:33.936
Yeah?
Yeah.

00:17:33.936 --> 00:17:39.369
Every time you put in an edge,
you add one to the degree of

00:17:39.369 --> 00:17:44.146
each person on each end.
So, it's just two different

00:17:44.146 --> 00:17:48.267
ways of counting up the same
number of edges.

00:17:48.267 --> 00:17:52.388
OK, I can go around,
and if you imagine that,

00:17:52.388 --> 00:17:56.696
that every time I count the
degree of the node,

00:17:56.696 --> 00:18:01.099
I put a mark on every edge.
Then, when I'm done,

00:18:01.099 --> 00:18:07.000
every edge has two marks on it,
one for each end.

00:18:07.000 --> 00:18:17.545
OK: a pretty simple theorem.
So, what that says is that for

00:18:17.545 --> 00:18:26.454
undirected graphs,
that implies that the adjacency

00:18:26.454 --> 00:18:35.000
list representation,
uses how much storage?

00:18:35.000 --> 00:18:39.183
OK, at most,
2E, so order E because that's

00:18:39.183 --> 00:18:42.959
not all.
Yeah, so you have to have the

00:18:42.959 --> 00:18:47.959
number of vertices plus order
the number of edges,

00:18:47.959 --> 00:18:53.979
OK, whether it's directed or
undirected because I may have a

00:18:53.979 --> 00:18:59.693
graph, say it has a whole bunch
of vertices and no edges,

00:18:59.693 --> 00:19:05.000
that's still going to cost me
order V, OK?

00:19:05.000 --> 00:19:09.305
So, it uses theta of V plus E
storage.

00:19:09.305 --> 00:19:15.007
And, it's basically the same
thing asymptotically.

00:19:15.007 --> 00:19:22.105
In fact, it's easier to see in
some sense for digraphs because

00:19:22.105 --> 00:19:27.109
for digraphs,
what I do is I just add up the

00:19:27.109 --> 00:19:33.625
out degrees, and that equal to
E, OK, if I add up the out

00:19:33.625 --> 00:19:39.123
degrees as equally.
In fact, this is kind of like

00:19:39.123 --> 00:19:41.612
it amortized analysis,
if you will,

00:19:41.612 --> 00:19:45.640
a book keeping analysis,
that if I'm adding up the total

00:19:45.640 --> 00:19:48.422
number of edges,
one way of doing it is

00:19:48.422 --> 00:19:50.838
accounting for a vertex by
vertex.

00:19:50.838 --> 00:19:54.353
OK, so for each vertex,
I basically can take each

00:19:54.353 --> 00:19:58.234
degree, and basically each
vertex, look at the degree,

00:19:58.234 --> 00:20:02.481
and that allocating of account
per edge, and then ending up

00:20:02.481 --> 00:20:06.947
with twice the number of edges,
that's exactly accounting type

00:20:06.947 --> 00:20:12.000
of analysis that we might do for
amortized analysis.

00:20:12.000 --> 00:20:17.014
OK, so we'll see that.
So, this is a sparse

00:20:17.014 --> 00:20:22.268
representation,
and it's often better than an

00:20:22.268 --> 00:20:25.731
adjacency matrix.
For example,

00:20:25.731 --> 00:20:32.179
you can imagine if the World
Wide Web were done with an

00:20:32.179 --> 00:20:37.313
adjacency matrix as opposed to,
essentially,

00:20:37.313 --> 00:20:44.000
with an adjacency list type of
representation.

00:20:44.000 --> 00:20:47.296
Every link on the World Wide
Web, I had to say,

00:20:47.296 --> 00:20:50.092
here are the ones that I'm
connected to,

00:20:50.092 --> 00:20:53.389
and here are all the ones I'm
not connected to.

00:20:53.389 --> 00:20:57.546
OK, that list of things you're
not connected to for a given

00:20:57.546 --> 00:20:59.911
page would be pretty
dramatically,

00:20:59.911 --> 00:21:03.064
show you that there is an
advantage to sparse

00:21:03.064 --> 00:21:06.901
representation.
On the other hand,

00:21:06.901 --> 00:21:13.450
one of the nice things about an
adjacency matrix representation

00:21:13.450 --> 00:21:19.154
is that each edge can be
represented with a single bit,

00:21:19.154 --> 00:21:24.542
whereas typical when I'm
representing things with an

00:21:24.542 --> 00:21:30.563
adjacency list representation,
how many bits am I going to

00:21:30.563 --> 00:21:35.000
need to represent each
adjacency?

00:21:35.000 --> 00:21:39.379
You'll need order log of V to
be able to name each different

00:21:39.379 --> 00:21:41.977
vertex.
OK, the log of the number is

00:21:41.977 --> 00:21:46.579
the number of bits that I need.
So, there are places where this

00:21:46.579 --> 00:21:50.068
is actually a far more efficient
representation.

00:21:50.068 --> 00:21:53.408
In particular,
if you have a very dense graph,

00:21:53.408 --> 00:21:56.896
OK, this may be a better way of
representing it.

00:21:56.896 --> 00:22:01.350
OK, the other thing I want you
to get, and we're going to see

00:22:01.350 --> 00:22:05.729
more of this in particular next
week, is that a matrix and a

00:22:05.729 --> 00:22:11.000
graph, there are two ways of
looking at the same thing.

00:22:11.000 --> 00:22:14.055
OK, and in fact,
there's a lot of graph theory

00:22:14.055 --> 00:22:17.993
that when you do things like
multiply the adjacency matrix,

00:22:17.993 --> 00:22:20.506
OK, and so forth.
So, there's a lot of

00:22:20.506 --> 00:22:24.580
commonality between graphs and
matrices, a lot of mathematics

00:22:24.580 --> 00:22:28.043
that if it applies for one,
it applies to the other.

00:22:28.043 --> 00:22:31.641
Do you have a question,
or just holding your finger in

00:22:31.641 --> 00:22:33.635
the air?
OK, good.

00:22:33.635 --> 00:22:37.874
OK, so that's all just review.
Now I want to get onto today's

00:22:37.874 --> 00:22:40.275
lecture.
OK, so any questions about

00:22:40.275 --> 00:22:42.607
graphs?
So, this is a good time to

00:22:42.607 --> 00:22:45.573
review appendix B.
there are a lot of great

00:22:45.573 --> 00:22:48.258
properties in there,
and in particular,

00:22:48.258 --> 00:22:52.496
there is a theorem that we're
going to cover today that we're

00:22:52.496 --> 00:22:56.381
going to talk about today,
which is properties of trees.

00:22:56.381 --> 00:23:00.761
Trees are very special kinds of
graphs, so I really want you to

00:23:00.761 --> 00:23:05.000
go and look to see what the
properties are.

00:23:05.000 --> 00:23:08.469
There is, I think,
something like six different

00:23:08.469 --> 00:23:11.788
definitions of trees that are
all equivalent,

00:23:11.788 --> 00:23:16.163
OK, and so, I think a very good
idea to go through and read

00:23:16.163 --> 00:23:20.009
through that theorem.
We're not going to prove it in

00:23:20.009 --> 00:23:23.630
class, but really,
provides a very good basis for

00:23:23.630 --> 00:23:27.175
the thinking that we're going to
be doing today.

00:23:27.175 --> 00:23:30.192
And we'll see more of that in
the future.

00:23:30.192 --> 00:23:33.058
OK, so today,
we're going to talk about

00:23:33.058 --> 00:23:38.434
minimum spanning trees.
OK, this is one of the world's

00:23:38.434 --> 00:23:42.328
most important algorithms.
OK, it is important in

00:23:42.328 --> 00:23:46.223
distributed systems.
It's one of the first things

00:23:46.223 --> 00:23:50.442
that almost any distributed
system tries to find is a

00:23:50.442 --> 00:23:55.230
minimum spanning tree of the
nodes that happened to be alive

00:23:55.230 --> 00:23:56.528
at any point,
OK?

00:23:56.528 --> 00:24:01.153
And one of the people who
developed an algorithm for this,

00:24:01.153 --> 00:24:04.723
we'll talk about this a little
bit later, OK,

00:24:04.723 --> 00:24:09.673
it was the basis of the billing
system for AT&amp;T for many years

00:24:09.673 --> 00:24:16.918
while it was a monopoly.
OK, so very important kind of

00:24:16.918 --> 00:24:21.108
thing.
It's got a huge number of

00:24:21.108 --> 00:24:25.702
applications.
So the problem is the

00:24:25.702 --> 00:24:31.243
following.
You have a connected undirected

00:24:31.243 --> 00:24:35.042
graph,
G equals (V,E),

00:24:35.042 --> 00:24:42.804
with an edge weight function,
w, which maps the edges into

00:24:42.804 --> 00:24:50.157
weights that are real numbers.
And for today's lecture,

00:24:50.157 --> 00:24:56.012
we're going to make an
important assumption,

00:24:56.012 --> 00:25:02.276
OK, for simplicity.
The book does not make this

00:25:02.276 --> 00:25:08.844
assumption.
And so, I encourage you to look

00:25:08.844 --> 00:25:16.534
at the alternative presentation
or, because what they do in the

00:25:16.534 --> 00:25:22.488
book is much more general,
but for simplicity and

00:25:22.488 --> 00:25:29.062
intuition, I'm going to make
this a little bit easier.

00:25:29.062 --> 00:25:37.000
We're going to assume that all
edge weights are distinct.

00:25:37.000 --> 00:25:39.306
OK, all edge weights are
distinct.

00:25:39.306 --> 00:25:42.940
So what does that mean?
What does that mean that this

00:25:42.940 --> 00:25:46.016
function, w, what property does
the function,

00:25:46.016 --> 00:25:48.811
w, have if all edge weights are
distinct?

00:25:48.811 --> 00:25:51.118
Who remembers their discreet
math?

00:25:51.118 --> 00:25:53.564
It's injective.
OK, it's one to one.

00:25:53.564 --> 00:25:56.639
OK, it's not one to one and
onto necessarily.

00:25:56.639 --> 00:26:00.833
In fact, it would be kind of
hard to do that because that's a

00:26:00.833 --> 00:26:05.408
pretty big set.
OK, but it's one to one.

00:26:05.408 --> 00:26:09.923
It's injective.
OK, so that's what we're going

00:26:09.923 --> 00:26:14.137
to assume for simplicity.
OK, and the book,

00:26:14.137 --> 00:26:19.454
they don't assume that.
It just means that the way you

00:26:19.454 --> 00:26:24.471
have to state things is just a
little more precise.

00:26:24.471 --> 00:26:28.183
It has to be more technically
precise.

00:26:28.183 --> 00:26:33.000
So, that's the input.
The output is--

00:26:33.000 --> 00:26:44.686
The output is a spanning tree,
T, and by spanning tree,

00:26:44.686 --> 00:26:52.477
we mean it connects all the
vertices.

00:26:52.477 --> 00:27:02.000
OK, and it's got to have
minimum weight.

00:27:02.000 --> 00:27:08.192
OK, so we can write the weight
of the tree is going to be,

00:27:08.192 --> 00:27:14.601
by that, we meet the sum over
all edges that are in the tree

00:27:14.601 --> 00:27:18.621
of the weight of the individual
edges.

00:27:18.621 --> 00:27:24.813
OK, so here I'(V,E) done a
little bit of abusive notation,

00:27:24.813 --> 00:27:31.331
which is that what I should be
writing is w of the edge (u,v)

00:27:31.331 --> 00:27:37.632
because this is a mapping from
edges, which would give me a

00:27:37.632 --> 00:27:42.171
double parentheses.
And, you know,

00:27:42.171 --> 00:27:45.266
as you know,
I love to abuse notation.

00:27:45.266 --> 00:27:48.948
So, I'm going to drop that
extra parentheses,

00:27:48.948 --> 00:27:54.051
because we understand that it's
really the weight of the edge,

00:27:54.051 --> 00:27:57.231
OK, not the weight of the
ordered pair.

00:27:57.231 --> 00:28:02.000
So, that's just a little
notational convenience.

00:28:02.000 --> 00:28:05.464
OK, so one of the things,
when we do the take-home exam,

00:28:05.464 --> 00:28:09.370
notational convenience can make
the difference between having a

00:28:09.370 --> 00:28:12.645
horrible time writing up a
problem, and an easy time.

00:28:12.645 --> 00:28:16.299
So, it's worth thinking about
what kinds of notation you'll

00:28:16.299 --> 00:28:19.637
use in writing up solutions to
problems, and so forth.

00:28:19.637 --> 00:28:22.787
OK, and just in general,
a technical communication,

00:28:22.787 --> 00:28:25.622
you adopt good notation people
understand you.

00:28:25.622 --> 00:28:29.086
You adopt a poor notation:
nobody pays attention to what

00:28:29.086 --> 00:28:34.000
you're doing because they don't
understand what you're saying.

00:28:34.000 --> 00:28:38.000
OK, so let's do an example.

00:28:45.000 --> 00:28:52.428
OK, so here's a graph.
I think for this,

00:28:52.428 --> 00:29:02.904
somebody asked once if I was
inspired by biochemistry or

00:29:02.904 --> 00:29:09.000
something, OK,
but I wasn't.

00:29:09.000 --> 00:29:11.857
I was just writing these things
down, OK?

00:29:11.857 --> 00:29:15.142
So, here's a graph.
And let's give us some edge

00:29:15.142 --> 00:29:16.000
weights.

00:29:31.000 --> 00:29:34.638
OK, so there are some edge
weights.

00:29:34.638 --> 00:29:39.668
And now, what we want is we
want to find a tree.

00:29:39.668 --> 00:29:45.876
So a connected acyclic graph
such that every vertex is part

00:29:45.876 --> 00:29:49.729
of the tree.
But it's got to have the

00:29:49.729 --> 00:29:55.508
minimum weight possible.
OK, so can somebody suggest to

00:29:55.508 --> 00:30:03.000
me some edges that have to be in
this minimum spanning tree?

00:30:03.000 --> 00:30:05.167
Yeah, so nine,
good.

00:30:05.167 --> 00:30:09.273
Nine has to be in there
because, why?

00:30:09.273 --> 00:30:14.520
It's the only one connecting it
to this vertex,

00:30:14.520 --> 00:30:16.346
OK?
And likewise,

00:30:16.346 --> 00:30:22.049
15 has to be in there.
So those both have to be in.

00:30:22.049 --> 00:30:26.726
What other edges have to be in?
Which one?

00:30:26.726 --> 00:30:33.000
14 has to be it.
Why does 14 have to be in?

00:30:33.000 --> 00:30:40.662
Well, one of 14 and three has
to be in there.

00:30:40.662 --> 00:30:50.067
I want the minimum weight.
The one that has the overall

00:30:50.067 --> 00:30:57.730
smallest weight.
So, can somebody argue to me

00:30:57.730 --> 00:31:04.448
that three has to be in there?
Yeah?

00:31:04.448 --> 00:31:09.292
That's the minimum of two,
which means that if I had a,

00:31:09.292 --> 00:31:14.764
if you add something you said
was a minimum spanning tree that

00:31:14.764 --> 00:31:19.338
didn't include three,
right, and so therefore it had

00:31:19.338 --> 00:31:23.196
to include 14,
then I could just delete this

00:31:23.196 --> 00:31:28.757
edge, 14, and put in edge three.
And, I have something of lower

00:31:28.757 --> 00:31:34.081
weight, right?
So, three has to be in there.

00:31:34.081 --> 00:31:37.906
What other edges have to be in
there?

00:31:37.906 --> 00:31:43.325
Do a little puzzle logic.
Six and five have to be in

00:31:43.325 --> 00:31:46.618
there.
Why do they have to be in

00:31:46.618 --> 00:31:48.000
there?

00:32:02.000 --> 00:32:05.200
Yeah, well, I mean,
it could be connected through

00:32:05.200 --> 00:32:08.400
this or something.
It doesn't necessarily have to

00:32:08.400 --> 00:32:11.000
go this way.
Six definitely has to be in

00:32:11.000 --> 00:32:14.066
there for the same reason that
three had to be,

00:32:14.066 --> 00:32:16.400
right?
Because we got two choices to

00:32:16.400 --> 00:32:19.466
connect up this guy.
And so, if everything were

00:32:19.466 --> 00:32:22.799
connected but it weren't,
12, I mean, and 12 was in

00:32:22.799 --> 00:32:24.200
there.
I could always,

00:32:24.200 --> 00:32:27.266
then, say, well,
let's connect them up this way

00:32:27.266 --> 00:32:31.769
instead.
OK, so definitely that's in

00:32:31.769 --> 00:32:35.358
there.
I still don't have everything

00:32:35.358 --> 00:32:37.000
connected up.

00:32:50.000 --> 00:33:03.428
What else has to be in there
for minimum spanning tree?

00:33:03.428 --> 00:33:11.634
Seven, five,
and eight, why seven,

00:33:11.634 --> 00:33:22.825
five, and eight?
OK, so can we argue those one

00:33:22.825 --> 00:33:32.026
at a time?
Why does five have to be in

00:33:32.026 --> 00:33:37.000
there?
Yeah?

00:33:37.000 --> 00:33:41.518
OK, so we have four connected
components because we have this

00:33:41.518 --> 00:33:43.852
one, this one,
we actually have,

00:33:43.852 --> 00:33:46.337
yeah, this one here,
and this one,

00:33:46.337 --> 00:33:49.048
good.
We need at least three edges to

00:33:49.048 --> 00:33:53.716
connect them because each edge
is going to reduce the connected

00:33:53.716 --> 00:33:57.105
components by one.
OK, so we need three edges,

00:33:57.105 --> 00:33:59.891
and those are the three
cheapest ones.

00:33:59.891 --> 00:34:04.334
And they work.
That works, right?

00:34:04.334 --> 00:34:11.209
Any other edges are going to be
bigger, so that works.

00:34:11.209 --> 00:34:15.489
Good.
OK, and so, now do we have a

00:34:15.489 --> 00:34:19.121
spanning tree?
Everything is,

00:34:19.121 --> 00:34:24.698
we have one big connected graph
here, right?

00:34:24.698 --> 00:34:31.054
Is that what I got?
Hey, that's the same as what I

00:34:31.054 --> 00:34:35.148
got.
Life is predictable.

00:34:35.148 --> 00:34:41.487
OK, so, so everybody had the
idea of what a minimum spanning

00:34:41.487 --> 00:34:44.280
tree is, then,
out of this,

00:34:44.280 --> 00:34:49.975
OK, what's going on there?
So, let's first of all make

00:34:49.975 --> 00:34:53.735
some observations about this
puzzle.

00:34:53.735 --> 00:34:59.322
And what I want to do is remind
you about the optimal

00:34:59.322 --> 00:35:06.090
substructure property because it
turns out minimum spanning tree

00:35:06.090 --> 00:35:12.000
has a great optimal substructure
property.

00:35:12.000 --> 00:35:17.989
OK, so the setup is going to
be, we're going to have some

00:35:17.989 --> 00:35:22.053
minimum spanning tree.
Let's call it T.

00:35:22.053 --> 00:35:27.828
And, I'm going to show that
with the other edges in the

00:35:27.828 --> 00:35:32.000
graph, are not going to be
shown.

00:35:32.000 --> 00:35:37.000
OK, so here's a graph.

00:35:54.000 --> 00:35:58.239
OK, so here's a graph.
It looks like the one I have my

00:35:58.239 --> 00:36:01.834
piece of paper here.
OK, so the idea is,

00:36:01.834 --> 00:36:05.118
this is some minimum spanning
tree.

00:36:05.118 --> 00:36:09.367
Now, we want to look at a
property of optimal

00:36:09.367 --> 00:36:13.327
substructure.
And the way I'm going to get

00:36:13.327 --> 00:36:17.769
that, is, I'm going to remove
some edge, (u,v),

00:36:17.769 --> 00:36:22.887
move an arbitrary edge,
(u,v), in the minimum spanning

00:36:22.887 --> 00:36:26.267
tree.
So, let's call this u and this

00:36:26.267 --> 00:36:29.068
V.
And so, we're removing this

00:36:29.068 --> 00:36:33.755
edge.
OK, so when I remove an edge in

00:36:33.755 --> 00:36:36.599
a tree, what happens to the
tree?

00:36:36.599 --> 00:36:39.622
What's left?
I have two trees left,

00:36:39.622 --> 00:36:41.844
OK?
I have two trees left.

00:36:41.844 --> 00:36:45.844
Now, proving that,
that's basically one of the

00:36:45.844 --> 00:36:50.733
properties in that appendix,
and the properties of trees

00:36:50.733 --> 00:36:55.355
that I want you to read,
OK, because you can actually

00:36:55.355 --> 00:37:00.511
prove that kind of thing rather
than it just being obvious,

00:37:00.511 --> 00:37:05.950
which is, OK?
OK, so we remove that.

00:37:05.950 --> 00:37:11.314
Then, T is partitioned into two
subtrees.

00:37:11.314 --> 00:37:15.605
And, we'll call them T_1 and
T_2.

00:37:15.605 --> 00:37:22.310
So, here's one subtree,
and here's another subtree.

00:37:22.310 --> 00:37:29.417
We'(V,E) partitioned it.
No matter what edge I picked,

00:37:29.417 --> 00:37:38.000
there would be two subtrees
that it's partitioned into.

00:37:38.000 --> 00:37:40.841
Even if the sub tree is a
trivial subtree,

00:37:40.841 --> 00:37:43.821
for example,
it just has a single node in it

00:37:43.821 --> 00:37:45.000
and no edges.

00:37:58.000 --> 00:38:11.970
So, the theorem that we'll
prove demonstrates a property of

00:38:11.970 --> 00:38:24.255
optimal substructure.
T_1 is a minimum spanning tree

00:38:24.255 --> 00:38:31.000
for the graph,
G_1, E_1,

00:38:31.000 --> 00:38:43.612
a subgraph of G induced by the
vertices in T_1.

00:38:43.612 --> 00:38:55.403
OK, that is,
V_1 is just the vertices in T_1

00:38:55.403 --> 00:39:09.171
is what it means to be induced.
OK, so V_1 is the vertices in

00:39:09.171 --> 00:39:12.623
T_1.
So, in this picture,

00:39:12.623 --> 00:39:16.938
I didn't label it.
This is T_1.

00:39:16.938 --> 00:39:20.965
This is T_2.
In this picture,

00:39:20.965 --> 00:39:27.438
these are the vertices of T_1.
So, that's V_1,

00:39:27.438 --> 00:39:32.328
OK?
And, E_1 is the set of pairs of

00:39:32.328 --> 00:39:39.232
vertices, x and y,
that are the edges that are in

00:39:39.232 --> 00:39:47.000
E_1 such that both x and y
belong to V_1.

00:39:47.000 --> 00:39:49.985
OK, so I haven't shown the
edges of G here.

00:39:49.985 --> 00:39:52.971
But basically,
if an edge went from here to

00:39:52.971 --> 00:39:57.236
here, that would be in the E_1.
If it went from here to here,

00:39:57.236 --> 00:40:00.080
it would not.
And if it went from here to

00:40:00.080 --> 00:40:04.255
here, it would not.
OK, so the vertices,

00:40:04.255 --> 00:40:10.684
the subgraph induced by the
vertices of T_1 are just those

00:40:10.684 --> 00:40:17.000
that connect up things in T_1,
and similarly for T_2.

00:40:27.000 --> 00:40:33.461
So, the theorem says that if I
look at just the edges within

00:40:33.461 --> 00:40:38.390
the graph here,
G_1, those that are induced by

00:40:38.390 --> 00:40:41.785
these vertices,
T_1 is, in fact,

00:40:41.785 --> 00:40:46.276
a minimum spanning tree for
that subgraph.

00:40:46.276 --> 00:40:51.971
That's what the theorem says.
OK, if I look over here

00:40:51.971 --> 00:40:58.542
conversely, or correspondingly,
if I look at the set of edges

00:40:58.542 --> 00:41:05.223
that are induced by this set of
vertices, the vertices in T_2,

00:41:05.223 --> 00:41:13.000
in fact, T_2 is a minimum
spanning tree on that subgraph.

00:41:13.000 --> 00:41:17.679
OK, OK, we can even do it over
here.

00:41:17.679 --> 00:41:21.556
If I took a look,
for example,

00:41:21.556 --> 00:41:27.705
at these, let's see,
let's say we cut out five,

00:41:27.705 --> 00:41:35.058
and if I cut out edge five,
that T_1 would be these four

00:41:35.058 --> 00:41:40.146
vertices here.
And, the point is that if I

00:41:40.146 --> 00:41:44.836
look at the subgraph induced on
that, that these edges here.

00:41:44.836 --> 00:41:48.573
In fact, the six,
eight, and three are all edges

00:41:48.573 --> 00:41:52.071
in a minimum spanning tree for
that subgraph.

00:41:52.071 --> 00:41:54.853
OK, so that's what the theorem
says.

00:41:54.853 --> 00:41:57.000
So let's prove it.

00:42:09.000 --> 00:42:19.783
OK, and so what technique are
we going to use to prove it?

00:42:19.783 --> 00:42:28.297
OK, we learned this technique
last time: hint,

00:42:28.297 --> 00:42:33.592
hint.
It's something you do it in

00:42:33.592 --> 00:42:39.447
your text editor all the time:
cut and paste,

00:42:39.447 --> 00:42:45.834
good, cut and paste.
OK, so the weight of T I can

00:42:45.834 --> 00:42:51.556
express as the weight of the
edge I removed,

00:42:51.556 --> 00:42:57.677
plus the weight of T_1,
plus the weight of T_2.

00:42:57.677 --> 00:43:07.412
OK, so that's the total weight.
So, the argument is pretty

00:43:07.412 --> 00:43:13.351
simple.
Suppose that there were some

00:43:13.351 --> 00:43:20.478
T_1 prime that was better than
T_1 for G_1.

00:43:20.478 --> 00:43:31.000
Suppose I had some better way
of forming a spanning tree.

00:43:31.000 --> 00:43:42.984
OK, then I would make up a T
prime, which just contained the

00:43:42.984 --> 00:43:48.468
edges, (u,v),
and T_1 prime,

00:43:48.468 --> 00:43:53.953
union T_2.
So, I would take,

00:43:53.953 --> 00:44:05.328
if I had a better spanning
tree, a spanning tree of lower

00:44:05.328 --> 00:44:12.452
weight for T_1.
And I call that T_1 prime.

00:44:12.452 --> 00:44:17.547
I just substitute that and make
up a spanning tree that

00:44:17.547 --> 00:44:22.358
consisted of my edge,
(u,v), whatever works well for

00:44:22.358 --> 00:44:26.037
T_1 prime and whatever works
well for T.

00:44:26.037 --> 00:44:30.000
And, that would be a spanning
tree.

00:44:30.000 --> 00:44:36.103
And it would be better than T
itself was for G,

00:44:36.103 --> 00:44:44.330
OK, because the weight of these
is just as the weight for this,

00:44:44.330 --> 00:44:50.300
I now just get to use the
weight of T_1 prime,

00:44:50.300 --> 00:44:54.812
and that's less.
And so, therefore,

00:44:54.812 --> 00:45:02.375
the assumption that T was a
minimum spanning tree would be

00:45:02.375 --> 00:45:11.000
violated if I could find a
better one for the subpiece.

00:45:11.000 --> 00:45:16.023
So, we have this nice property
of optimal substructure.

00:45:16.023 --> 00:45:20.023
OK, I have subproblems that
exhibit optimal,

00:45:20.023 --> 00:45:25.325
if I have a globally optimal
solution to the whole problem

00:45:25.325 --> 00:45:31.000
within it, I can find optimal
solutions to subproblems.

00:45:31.000 --> 00:45:36.400
So, now the question is,
that's one hallmark.

00:45:36.400 --> 00:45:41.554
That's one hallmark of dynamic
programming.

00:45:41.554 --> 00:45:45.727
What about overlapping
subproblems?

00:45:45.727 --> 00:45:51.250
Do I have that property?
Do I have overlapping

00:45:51.250 --> 00:45:58.000
subproblems over here for this
type of problem?

00:46:19.000 --> 00:46:20.623
So, imagine,
for example,

00:46:20.623 --> 00:46:22.855
that I'm removing different
edges.

00:46:22.855 --> 00:46:26.845
I look at the space of taking a
given edge, and removing it.

00:46:26.845 --> 00:46:30.565
It partitions it into two
pieces, and now I have another

00:46:30.565 --> 00:46:32.053
piece.
And I remove it,

00:46:32.053 --> 00:46:35.153
etc.
Am I going to end up getting a

00:46:35.153 --> 00:46:38.454
bunch of subproblems that are
similar in there?

00:46:38.454 --> 00:46:41.181
Yeah, I am.
OK, if I take out this one,

00:46:41.181 --> 00:46:43.693
then I take out,
say, this one here,

00:46:43.693 --> 00:46:46.923
and then I'll have another tree
here and here.

00:46:46.923 --> 00:46:51.157
OK, that would be the same as
if I had originally taken this

00:46:51.157 --> 00:46:53.454
out, and then taken that one
out.

00:46:53.454 --> 00:46:57.186
If I look at simple ordering of
taking out the edges,

00:46:57.186 --> 00:47:00.918
I'm going to end up with a
whole bunch of overlapping

00:47:00.918 --> 00:47:04.598
subproblems.
Yeah, OK.

00:47:04.598 --> 00:47:14.013
So then, what does that suggest
we use as an approach?

00:47:14.013 --> 00:47:18.453
Dynamic programming,
good.

00:47:18.453 --> 00:47:26.625
What a surprise!
Yes, OK, you could use dynamic

00:47:26.625 --> 00:47:33.949
programming.
But it turns out that minimum

00:47:33.949 --> 00:47:41.167
spanning tree exhibits an even
more powerful property.

00:47:41.167 --> 00:47:48.929
OK, so we'(V,E) got all the
clues for dynamic programming,

00:47:48.929 --> 00:47:57.237
but it turns out that there's
an even bigger clue that's going

00:47:57.237 --> 00:48:05.000
to help us to use an even more
powerful technique.

00:48:05.000 --> 00:48:11.074
And that, we call,
the hallmark for greedy

00:48:11.074 --> 00:48:13.000
algorithms.

00:48:32.000 --> 00:48:41.423
And that is,
we have a thing called the

00:48:41.423 --> 00:48:53.327
greedy choice property,
which says that a locally

00:48:53.327 --> 00:49:03.000
optimal choice is globally
optimal.

00:49:03.000 --> 00:49:05.846
And, of course,
as all these hallmarks is the

00:49:05.846 --> 00:49:09.792
kind of thing you want to box,
OK, because these are the clues

00:49:09.792 --> 00:49:12.315
that you're going to be able to
do that.

00:49:12.315 --> 00:49:15.873
So, we have this property that
we call the greedy choice

00:49:15.873 --> 00:49:18.266
property.
I'm going to show you how it

00:49:18.266 --> 00:49:21.177
works in this case.
And when you have a greedy

00:49:21.177 --> 00:49:24.024
choice property,
it turns out you can do even

00:49:24.024 --> 00:49:29.136
better that dynamic programming.
OK, so when you see the two

00:49:29.136 --> 00:49:33.568
dynamic programming properties,
there is a clue that says

00:49:33.568 --> 00:49:36.892
dynamic programming,
yes, but also it says,

00:49:36.892 --> 00:49:41.719
let me see whether it also has
this greedy property because if

00:49:41.719 --> 00:49:46.309
it does, you're going to come up
with something that's even

00:49:46.309 --> 00:49:49.079
better than dynamic programming,
OK?

00:49:49.079 --> 00:49:53.431
So, if you just have the two,
you can usually do dynamic

00:49:53.431 --> 00:49:56.834
programming, but if you have
this third one,

00:49:56.834 --> 00:50:00.000
it's like, whoa!
Jackpot!

00:50:00.000 --> 00:50:04.321
OK, so here's the theorem we'll
prove to illustrate this idea.

00:50:04.321 --> 00:50:08.076
Once again, these are not,
all these hallmarks are not

00:50:08.076 --> 00:50:09.989
things.
They are heuristics.

00:50:09.989 --> 00:50:14.027
I can't give you an algorithm
to say, here's where dynamic

00:50:14.027 --> 00:50:16.861
programming works,
or here's where greedy

00:50:16.861 --> 00:50:20.190
algorithms work.
But I can sort of indicate when

00:50:20.190 --> 00:50:23.166
they work, the kind of structure
they have.

00:50:23.166 --> 00:50:32.133
OK, so here's the theorem.
So let's let T be the MST of

00:50:32.133 --> 00:50:40.895
our graph.
And, let's let A be any subset

00:50:40.895 --> 00:50:49.000
of V, so, some subset of
vertices.

00:50:49.000 --> 00:51:04.608
And now, let's suppose that
edge, (u,v), is the least weight

00:51:04.608 --> 00:51:17.835
edge connecting our set A to A
complement, that is,

00:51:17.835 --> 00:51:27.359
V minus A.
Then the theorem says that

00:51:27.359 --> 00:51:39.000
(u,v) is in the minimum spanning
tree.

00:51:39.000 --> 00:51:43.477
So let's just take a look at
our graph over here and see if

00:51:43.477 --> 00:51:45.408
that's, in fact,
the case.

00:51:45.408 --> 00:51:49.036
OK, so let's take,
so one thing I could do for A

00:51:49.036 --> 00:51:53.514
is just take a singleton node.
So, I take a singleton node,

00:51:53.514 --> 00:51:56.680
let's say this guy here,
that can be my A,

00:51:56.680 --> 00:52:00.000
and everything else is V minus
A.

00:52:00.000 --> 00:52:04.235
And I look at the least weight
edge connecting this to

00:52:04.235 --> 00:52:07.910
everything else.
Well, there are only two edges

00:52:07.910 --> 00:52:10.627
that connect it to everything
else.

00:52:10.627 --> 00:52:15.262
And the theorem says that the
lighter one is in the minimum

00:52:15.262 --> 00:52:17.260
spanning tree.
Hey, I win.

00:52:17.260 --> 00:52:21.095
OK, if you take a look,
every vertex that I pick,

00:52:21.095 --> 00:52:25.730
the latest edge coming out of
that vertex is in the minimum

00:52:25.730 --> 00:52:29.086
spanning tree.
OK, the lightest weight edge

00:52:29.086 --> 00:52:35.000
coming out, but that's not all
the edges that are in here.

00:52:35.000 --> 00:52:39.318
OK, or let's just imagine,
let's take a look at these

00:52:39.318 --> 00:52:43.305
three vertices connected to this
set of vertices.

00:52:43.305 --> 00:52:46.129
I have three edges is going
across.

00:52:46.129 --> 00:52:50.780
The least weight one is five.
That's the minimum spanning

00:52:50.780 --> 00:52:53.355
tree.
Or, I can cut it this way.

00:52:53.355 --> 00:52:57.840
OK, the ones above one,
the edges going down are seven,

00:52:57.840 --> 00:53:02.079
eight, and 14.
Seven is the least weight.

00:53:02.079 --> 00:53:04.719
It's in the minimum spanning
tree.

00:53:04.719 --> 00:53:08.880
So, no matter how I choose,
I could make this one in,

00:53:08.880 --> 00:53:10.880
this one out,
this one in,

00:53:10.880 --> 00:53:12.880
this one out,
this one in,

00:53:12.880 --> 00:53:14.880
this one out,
this one in,

00:53:14.880 --> 00:53:18.079
this one out,
take a look at what all the

00:53:18.079 --> 00:53:21.039
edges are.
Which ever one to the least

00:53:21.039 --> 00:53:24.320
weight: it's in the minimum
spanning tree.

00:53:24.320 --> 00:53:28.239
So, in some sense,
that's a local property because

00:53:28.239 --> 00:53:34.000
I don't have to look at what the
rest of the tree is.

00:53:34.000 --> 00:53:38.473
I'm just looking at some small
set of vertices if I wish,

00:53:38.473 --> 00:53:42.227
and I say, well,
if I wanted to connect that set

00:53:42.227 --> 00:53:46.621
of vertices to the rest of the
world, what would I pick?

00:53:46.621 --> 00:53:50.855
I'd pick the cheapest one.
That's the greedy approach.

00:53:50.855 --> 00:53:53.011
It turns out,
that wins, OK,

00:53:53.011 --> 00:53:57.724
that picking that thing that's
locally good for that subset,

00:53:57.724 --> 00:54:04.568
A, OK, is also globally good.
OK, it optimizes the overall

00:54:04.568 --> 00:54:09.411
function.
That's what the theorem says,

00:54:09.411 --> 00:54:13.490
OK?
So, let's prove this theorem.

00:54:13.490 --> 00:54:20.372
Any questions about this?
OK, let's prove this theorem.

00:54:20.372 --> 00:54:27.892
So, we have (u,v) is the least
weight edge connecting A to D

00:54:27.892 --> 00:54:32.352
minus A.
So, let's suppose that this

00:54:32.352 --> 00:54:40.000
edge, (u,v), is not in the
minimum spanning tree.

00:54:40.000 --> 00:54:45.961
OK, let's suppose that somehow
there is a minimum spanning tree

00:54:45.961 --> 00:54:50.096
that doesn't include this least
weight edge.

00:54:50.096 --> 00:54:55.576
OK, so what technique you think
will use to prove to get a

00:54:55.576 --> 00:54:58.750
contradiction here?
Cut and paste,

00:54:58.750 --> 00:55:04.254
good.
Yeah, we're going to cut paste.

00:55:04.254 --> 00:55:08.647
OK, we're going to cut and
paste.

00:55:08.647 --> 00:55:14.000
So here, I did an example.
OK, so --

00:55:40.000 --> 00:55:42.051
OK, and so I'm going to use the
notation.

00:55:42.051 --> 00:55:44.000
I'm going to color some of
these in.

00:56:05.000 --> 00:56:10.037
OK, and so my notation here is
this is an element of A,

00:56:10.037 --> 00:56:14.235
and color it in.
It's an element of V minus A.

00:56:14.235 --> 00:56:18.152
OK, so if it's not colored it,
that's an A.

00:56:18.152 --> 00:56:21.138
This is my minimum spanning
tree.

00:56:21.138 --> 00:56:27.014
Once again, I'm not showing the
overall edges of all the graphs,

00:56:27.014 --> 00:56:30.000
but they're there,
OK?

00:56:30.000 --> 00:56:33.807
So, my edge,
(u,v), which is not my minimum

00:56:33.807 --> 00:56:38.158
spanning tree I say,
let's say is this edge here.

00:56:38.158 --> 00:56:42.600
It's an edge from u,
u as in A, v as in V minus A.

00:56:42.600 --> 00:56:48.039
OK, so everybody see the setup?
So, I want to prove that this

00:56:48.039 --> 00:56:52.572
edge should have been in the
minimum spanning tree,

00:56:52.572 --> 00:56:58.011
OK, that the contention that
this is a minimum spanning tree,

00:56:58.011 --> 00:57:02.000
and does include (u,v) is
wrong.

00:57:02.000 --> 00:57:05.322
So, what I want to do,
that, is I have a tree here,

00:57:05.322 --> 00:57:08.645
T, and I have two vertices,
u and v, and in a tree,

00:57:08.645 --> 00:57:12.300
between any two vertices there
is a unique, simple path:

00:57:12.300 --> 00:57:16.155
simple path meaning it doesn't
go back and forth and repeat

00:57:16.155 --> 00:57:18.746
edges or vertices.
OK, there's a unique,

00:57:18.746 --> 00:57:23.000
simple path from u to v.
So, let's consider that path.

00:57:42.000 --> 00:57:46.896
OK, and the way that I know
that that path exists is because

00:57:46.896 --> 00:57:51.377
I'(V,E) read appendix B of the
textbook, section B.5.1,

00:57:51.377 --> 00:57:56.107
OK, which has this nice theorem
about properties of trees.

00:57:56.107 --> 00:58:00.340
OK, so that's how I know that
there exists a unique,

00:58:00.340 --> 00:58:05.333
simple path.
OK, so now we're going to do is

00:58:05.333 --> 00:58:09.741
take a look at that path.
So in this case,

00:58:09.741 --> 00:58:13.505
it goes from here,
to here, to here,

00:58:13.505 --> 00:58:16.516
to here.
And along that path,

00:58:16.516 --> 00:58:22.967
there must be a point where I
connect from a vertex in A to a

00:58:22.967 --> 00:58:25.548
vertex in V minus A.
Why?

00:58:25.548 --> 00:58:32.000
Well, because this is in A.
This is in V minus A.

00:58:32.000 --> 00:58:42.471
So, along the path somewhere,
there must be a transition.

00:58:42.471 --> 00:58:52.195
OK, they are not all in A,
OK, because in particular,

00:58:52.195 --> 00:58:58.739
V isn't.
OK, so we're going to do is

00:58:58.739 --> 00:59:09.585
swap (u,v) with the first edge
on this path that connects a

00:59:09.585 --> 00:59:18.000
vertex in A to a vertex in V
minus A.

00:59:18.000 --> 00:59:20.880
So in this case,
it's this edge here.

00:59:20.880 --> 00:59:24.639
I go from A to V minus A.
In general, I might be

00:59:24.639 --> 00:59:28.960
alternating many times,
OK, and I just picked the first

00:59:28.960 --> 00:59:32.480
one that I encounter.
OK, that this guy here.

00:59:32.480 --> 00:59:36.000
And what I do is I put this
edge in.

00:59:36.000 --> 00:59:38.266
OK, so then,
what happens?

00:59:38.266 --> 00:59:42.164
Well, the edge,
(u,v), is the lightest thing

00:59:42.164 --> 00:59:46.787
connecting something in A to
something in V minus A.

00:59:46.787 --> 00:59:49.325
So that means,
in particular,

00:59:49.325 --> 00:59:53.405
it's lighter than this edge,
has lower weight.

00:59:53.405 --> 00:59:57.756
So, by swapping this,
I'(V,E) created a tree with

00:59:57.756 --> 01:00:02.198
lower overall weight,
contradicting the assumption

01:00:02.198 --> 01:00:08.000
that this other thing was a
minimum spanning tree.

01:00:08.000 --> 01:00:14.219
OK: so, a lower weight spanning
tree than T results,

01:00:14.219 --> 01:00:18.000
and that's a contradiction --

01:00:25.000 --> 01:00:33.010
-- than T results.
And that's a contradiction,

01:00:33.010 --> 01:00:36.570
OK?
How are we doing?

01:00:36.570 --> 01:00:44.225
Everybody with me?
OK, now we get to do some

01:00:44.225 --> 01:00:46.895
algorithms.
Yea!

01:00:46.895 --> 01:00:55.439
So, we are going to do an
algorithm called Prim's

01:00:55.439 --> 01:01:01.853
algorithm.
Prim eventually became a very

01:01:01.853 --> 01:01:07.069
high-up at AT&amp;T because he
invented this algorithm for

01:01:07.069 --> 01:01:12.187
minimum spanning trees,
and it was used in all of the

01:01:12.187 --> 01:01:15.730
billing code for AT&amp;T for many
years.

01:01:15.730 --> 01:01:21.438
He was very high up at Bell
Labs back in the heyday of Bell

01:01:21.438 --> 01:01:24.784
Laboratories.
OK, so it just shows,

01:01:24.784 --> 01:01:30.000
all you have to do is invent an
algorithm.

01:01:30.000 --> 01:01:36.702
You too can be a president of a
corporate monopoly.

01:01:36.702 --> 01:01:43.807
Of course, the government can
do things to monopolies,

01:01:43.807 --> 01:01:49.438
but anyway, if that's your
mission in life,

01:01:49.438 --> 01:01:55.202
invent an algorithm.
OK, so here's the idea.

01:01:55.202 --> 01:02:03.648
What we're going to do is we're
going to maintain V minus A as a

01:02:03.648 --> 01:02:11.923
priority queue.
We'll call it Q.

01:02:11.923 --> 01:02:26.076
And each vertex,
we're going to key each vertex

01:02:26.076 --> 01:02:39.923
in Q with the weight of the
least weight edge,

01:02:39.923 --> 01:02:53.280
connecting it to a vertex in A.
So here's the code.

01:02:53.280 --> 01:03:00.000
So, we're going to start out
with Q being all vertices.

01:03:00.000 --> 01:03:03.873
So, we start out with A being,
if you will,

01:03:03.873 --> 01:03:07.930
the empty set.
OK, and what we're going to do

01:03:07.930 --> 01:03:13.095
it is the least weight edge,
therefore, for everything in

01:03:13.095 --> 01:03:18.536
the priority queue is basically
going to be infinity because

01:03:18.536 --> 01:03:23.700
none of them have any edges.
The least weight edge to the

01:03:23.700 --> 01:03:29.325
empty set is going to be empty.
And then, we're going to start

01:03:29.325 --> 01:03:33.958
out with one guy.
We'll call him S,

01:03:33.958 --> 01:03:39.489
which will set to zero for some
arbitrary S in V.

01:03:39.489 --> 01:03:45.135
And then, the main part of the
algorithm kicks in.

01:03:45.135 --> 01:03:51.703
So that's our initialization.
OK, when we do the analysis,

01:03:51.703 --> 01:03:58.271
I'm going to write some stuff
on the left hand side of the

01:03:58.271 --> 01:04:04.406
board.
So if you're taking notes,

01:04:04.406 --> 01:04:14.406
you may want to also leave a
little bit of space on the left

01:04:14.406 --> 01:04:22.711
hand side of your notes.
So, while Q is not empty,

01:04:22.711 --> 01:04:30.000
we get the smallest element out
of it.

01:04:41.000 --> 01:04:43.000
And then we do some stuff.

01:05:19.000 --> 01:05:21.970
That's it.
And the only thing I should

01:05:21.970 --> 01:05:25.503
mention here is,
OK, so let's just see what's

01:05:25.503 --> 01:05:28.875
going on here.
And then we'll run it on the

01:05:28.875 --> 01:05:32.256
example.
OK, so what we do is we take

01:05:32.256 --> 01:05:36.609
out the smallest element out of
the queue at each step.

01:05:36.609 --> 01:05:40.156
And then for each step in the
adjacency list,

01:05:40.156 --> 01:05:43.783
in other words,
everything for which I have an

01:05:43.783 --> 01:05:46.846
edge going from v to u,
we take a look,

01:05:46.846 --> 01:05:51.440
and if v is still in our set V
minus A, so things we'(V,E)

01:05:51.440 --> 01:05:54.261
taken out are going to be part
of A.

01:05:54.261 --> 01:05:57.163
OK, every time we take
something out,

01:05:57.163 --> 01:06:02.000
that's going to be a new A that
we construct.

01:06:02.000 --> 01:06:04.258
At every step,
we want to find,

01:06:04.258 --> 01:06:08.400
what's the cheapest edge
connecting that A to everything

01:06:08.400 --> 01:06:11.035
else?
We basically are going to take

01:06:11.035 --> 01:06:15.025
whatever that cheapest thing is,
OK, add that edge in,

01:06:15.025 --> 01:06:19.242
and now bring that into A and
find the next cheapest one.

01:06:19.242 --> 01:06:22.103
And we just keep repeating the
process.

01:06:22.103 --> 01:06:25.567
OK, we'll do it on the example.
And what we do,

01:06:25.567 --> 01:06:28.955
is every time we bring it in,
I keep track of,

01:06:28.955 --> 01:06:34.000
what was the vertex responsible
for bringing me in.

01:06:34.000 --> 01:06:43.947
And what I claim is that at the
end, if I look at the set of

01:06:43.947 --> 01:06:52.209
these pairs that I'(V,E) made
here, V and pi of V,

01:06:52.209 --> 01:06:58.279
that forms the minimum spanning
tree.

01:06:58.279 --> 01:07:05.441
So let's just do this.
And, what's that?

01:07:05.441 --> 01:07:12.191
We're all set up.
So let's get rid of these guys

01:07:12.191 --> 01:07:20.234
here because we are going to
recompute them from scratch.

01:07:20.234 --> 01:07:30.000
OK, so you may want to copy the
graph over again in your notes.

01:07:30.000 --> 01:07:34.840
I was going to do it,
but it turned out,

01:07:34.840 --> 01:07:40.797
this is exactly the board is
going to erase this.

01:07:40.797 --> 01:07:47.127
OK, well let me just modify it.
OK, so we start out.

01:07:47.127 --> 01:07:54.574
We make everything be infinity.
OK, so that's where I'm going

01:07:54.574 --> 01:08:01.028
to keep the key value.
OK, and then what I'm going to

01:08:01.028 --> 01:08:07.952
do is find one vertex.
And I'm going to call him S.

01:08:07.952 --> 01:08:11.749
And I'm going to do this vertex
here.

01:08:11.749 --> 01:08:15.018
We'll call that S.
So basically,

01:08:15.018 --> 01:08:19.447
I now make him be zero.
And now, what I do,

01:08:19.447 --> 01:08:23.454
is I execute extract min.
So basically,

01:08:23.454 --> 01:08:28.199
what I'll do is I'll just shade
him like this,

01:08:28.199 --> 01:08:34.000
indicating that he has now
joined the set A.

01:08:34.000 --> 01:08:40.931
So, this is going to be A.
And this is element of V minus

01:08:40.931 --> 01:08:44.644
A.
OK, so then what we do is we

01:08:44.644 --> 01:08:47.986
take a look.
We extract him,

01:08:47.986 --> 01:08:53.433
and then for each edge in the
adjacency list,

01:08:53.433 --> 01:08:59.003
OK, so for each vertex in the
adjacency lists,

01:08:59.003 --> 01:09:05.315
that these guys here,
OK, we're going to look to see

01:09:05.315 --> 01:09:12.000
if it's still in Q,
that is, in V minus A.

01:09:12.000 --> 01:09:16.795
And if so, and its key value is
less than what the value is at

01:09:16.795 --> 01:09:20.254
the edge, there,
we're going to replace it by

01:09:20.254 --> 01:09:22.770
the edge value.
So, in this case,

01:09:22.770 --> 01:09:25.600
we're going to replace this by
seven.

01:09:25.600 --> 01:09:30.317
We're going to replace this by
15, and we're going to replace

01:09:30.317 --> 01:09:33.855
this by ten, OK,
because what we're interested

01:09:33.855 --> 01:09:39.608
in is, what is the cheapest?
Now, notice that everything in

01:09:39.608 --> 01:09:43.782
V minus A, that is,
what's in the priority queue,

01:09:43.782 --> 01:09:48.217
everything in there,
OK, now has its cheapest way of

01:09:48.217 --> 01:09:53.086
connecting it to the things that
I'(V,E) already removed,

01:09:53.086 --> 01:09:57.173
the things that are in A.
OK, and so now I just,

01:09:57.173 --> 01:10:01.608
OK, when I actually do that
update, there's actually

01:10:01.608 --> 01:10:07.000
something implicit going on in
this priority queue.

01:10:07.000 --> 01:10:10.636
And that is that I have to do a
decreased key.

01:10:10.636 --> 01:10:14.111
So, there's an implicit
decrease of the key.

01:10:14.111 --> 01:10:19.121
So, decreased key is a priority
queue operation that lowers the

01:10:19.121 --> 01:10:22.191
value of the key in the priority
queue.

01:10:22.191 --> 01:10:26.878
And so, that's implicitly going
on when I look at what data

01:10:26.878 --> 01:10:31.646
structure I'm going to use to
implement that priority queue.

01:10:31.646 --> 01:10:36.171
OK, so common data structures
for implementing a priority

01:10:36.171 --> 01:10:41.376
queue are a min heap.
OK, so I have to make sure that

01:10:41.376 --> 01:10:43.905
I'm actually doing this
operation.

01:10:43.905 --> 01:10:47.355
I can't just change it and not
affect my heap.

01:10:47.355 --> 01:10:51.111
So, there is an implicit
operation going on there.

01:10:51.111 --> 01:10:54.407
OK, now I repeat.
I find the cheapest thing,

01:10:54.407 --> 01:10:58.547
oh, and I also have to set,
now, a pointer from each of

01:10:58.547 --> 01:11:02.931
these guys back to u.
So here, this guy sets a

01:11:02.931 --> 01:11:07.114
pointer going this way.
This guy sets a pointer going

01:11:07.114 --> 01:11:11.298
this way, and this guy sets a
pointer going this way.

01:11:11.298 --> 01:11:16.206
That's my pi thing that's going
to keep track of who caused me

01:11:16.206 --> 01:11:20.873
to set my value to what it is.
So now, we go in and we find

01:11:20.873 --> 01:11:22.885
the cheapest thing,
again.

01:11:22.885 --> 01:11:25.620
And we're going to do it fast,
too.

01:11:25.620 --> 01:11:32.361
OK, this is a fast algorithm.
OK, so now we're going to go do

01:11:32.361 --> 01:11:36.481
this again.
So now, what's the cheapest

01:11:36.481 --> 01:11:39.843
thing to extract?
This guy here,

01:11:39.843 --> 01:11:42.987
right?
So, we'll take him out,

01:11:42.987 --> 01:11:47.542
OK, and now we update all of
his neighbors.

01:11:47.542 --> 01:11:51.771
So this guy gets five.
This guy gets 12.

01:11:51.771 --> 01:11:56.542
This guy gets nine.
This guy we don't update.

01:11:56.542 --> 01:12:02.722
We don't update him because
he's no longer in the priority

01:12:02.722 --> 01:12:07.464
queue.
And all of these guys now,

01:12:07.464 --> 01:12:12.297
we make point to where they're
supposed to point to.

01:12:12.297 --> 01:12:17.983
And, we're done with that step.
Now we find the cheapest one.

01:12:17.983 --> 01:12:22.437
What's the cheapest one now?
The five over here.

01:12:22.437 --> 01:12:24.807
Good.
So, we take him out.

01:12:24.807 --> 01:12:30.019
OK, we update the neighbors.
Here, yep, that goes to six

01:12:30.019 --> 01:12:34.000
now.
And, we have that pointer.

01:12:34.000 --> 01:12:39.684
And, this guy we don't do,
because he's not in there.

01:12:39.684 --> 01:12:44.604
This guy becomes 14,
and this guy here becomes

01:12:44.604 --> 01:12:47.774
eight.
So, we update that guy,

01:12:47.774 --> 01:12:52.803
make him be eight.
Did I do this the right way?

01:12:52.803 --> 01:12:57.395
Yeah, because pi is a function
of this guy.

01:12:57.395 --> 01:13:00.675
So basically,
this thing, then,

01:13:00.675 --> 01:13:04.938
disappears.
Yeah, did I have another one

01:13:04.938 --> 01:13:09.258
that I missed?
12, yes, good,

01:13:09.258 --> 01:13:12.584
it's removed,
OK, because pi is just a

01:13:12.584 --> 01:13:14.741
function.
And now I'm OK.

01:13:14.741 --> 01:13:18.516
OK, so now what do I do?
OK, so now my set,

01:13:18.516 --> 01:13:23.191
A, consists of these three
things, and now I want the

01:13:23.191 --> 01:13:26.786
cheapest edge.
I know it's in the minimum

01:13:26.786 --> 01:13:30.561
spanning tree.
So let me just greedily pick

01:13:30.561 --> 01:13:34.554
it.
OK, so what's the cheapest

01:13:34.554 --> 01:13:37.108
thing now?
This guy appear?

01:13:37.108 --> 01:13:39.466
Yeah, six.
So we take it.

01:13:39.466 --> 01:13:44.771
We go to update these things,
and nothing matters here.

01:13:44.771 --> 01:13:50.175
OK, nothing changes because
these guys are already in A.

01:13:50.175 --> 01:13:54.203
OK, so now the cheapest one is
eight here.

01:13:54.203 --> 01:13:56.856
Good.
So, we take eight out.

01:13:56.856 --> 01:14:01.656
OK, we update this.
Nothing to be done.

01:14:01.656 --> 01:14:04.970
This: nothing to be done.
This: oh, no,

01:14:04.970 --> 01:14:09.242
this one, instead of 14 we can
make this be three.

01:14:09.242 --> 01:14:14.212
So, we get rid of that pointer
and make it point that way.

01:14:14.212 --> 01:14:16.915
Now three is the cheapest
thing.

01:14:16.915 --> 01:14:21.100
So, we take it out,
and of course there's nothing

01:14:21.100 --> 01:14:24.239
to be done over there.
And now, last,

01:14:24.239 --> 01:14:26.506
I take nine.
And it's done.

01:14:26.506 --> 01:14:32.000
And 15: it's done.
And the algorithm terminates.

01:14:32.000 --> 01:14:36.972
OK, and as I look at,
now, all the edges that I

01:14:36.972 --> 01:14:43.135
picked, those are exactly all
the edges that we had at the

01:14:43.135 --> 01:14:48.000
beginning.
OK, let's do an analysis here.

01:14:58.000 --> 01:15:06.316
OK, so let's see,
this part here costs me order

01:15:06.316 --> 01:15:11.197
V, right?
OK, and this part,

01:15:11.197 --> 01:15:16.983
let's see what we are doing
here.

01:15:16.983 --> 01:15:27.107
Well, we're going to go through
this loop how many times?

01:15:27.107 --> 01:15:32.711
V times.
It's V elements we put into the

01:15:32.711 --> 01:15:35.860
queue.
We are not inserting anything.

01:15:35.860 --> 01:15:39.795
We're just taking them out.
This goes V times,

01:15:39.795 --> 01:15:43.819
OK, and we do a certain number
of extract Mins.

01:15:43.819 --> 01:15:47.492
So, we're going to do order V
extract Mins.

01:15:47.492 --> 01:15:52.915
And then we go to the adjacency
list, and we have some constant

01:15:52.915 --> 01:15:55.801
things.
But we have these implicit

01:15:55.801 --> 01:16:00.000
decreased keys for this stuff
here.

01:16:00.000 --> 01:16:07.412
That's this thing here.
OK, and so how many implicit

01:16:07.412 --> 01:16:14.389
decreased keys do we have?
That's going to be the

01:16:14.389 --> 01:16:18.459
expensive thing.
OK, we have,

01:16:18.459 --> 01:16:25.000
in this case,
the degree of u of those.

01:16:25.000 --> 01:16:31.309
OK, so overall,
how many implicit decreased

01:16:31.309 --> 01:16:38.218
keys do we have?
Well, we have V times through.

01:16:38.218 --> 01:16:43.025
How big could the degree of u
be?

01:16:43.025 --> 01:16:48.433
OK, it could be as big as V,
order V.

01:16:48.433 --> 01:16:56.995
So, that's V^2 decreased use.
But we can do a better bound

01:16:56.995 --> 01:17:04.189
than that.
How many do we really have?

01:17:04.189 --> 01:17:11.948
Yeah, at most order E,
OK, because what am I doing?

01:17:11.948 --> 01:17:19.086
I'm summing up the degrees of
all the vertices.

01:17:19.086 --> 01:17:27.000
That's how many times I
actually execute that.

01:17:27.000 --> 01:17:34.322
So, I have order E,
implicit decreased keys.

01:17:34.322 --> 01:17:44.028
So the time overall is order V
times time for whatever the

01:17:44.028 --> 01:17:53.224
extract Min is plus E times the
time for decreased key.

01:17:53.224 --> 01:18:02.931
So now, let's look at data
structures, and we can evaluate

01:18:02.931 --> 01:18:14.000
for different data structures
what this formula gives us.

01:18:14.000 --> 01:18:21.492
So, we have different ways of
implementing a data structure.

01:18:21.492 --> 01:18:28.222
We have the cost of extract
Min, and of decreased key,

01:18:28.222 --> 01:18:32.636
and total.
So, the simplest way of

01:18:32.636 --> 01:18:38.369
implementing a data structure is
an unsorted array.

01:18:38.369 --> 01:18:44.904
If I have an unsorted array,
how much time does it take me

01:18:44.904 --> 01:18:51.668
to extract the minimum element?
If I have an unsorted array?

01:18:51.668 --> 01:18:58.433
Right, order V in this case
because it's an array of size V.

01:18:58.433 --> 01:19:06.000
And, to do a decreased key,
OK, I can do it in order one.

01:19:06.000 --> 01:19:14.245
So, the total is V^2,
good, order V^2 algorithm.

01:19:14.245 --> 01:19:22.666
Or, as people suggested,
how about a binary heap?

01:19:22.666 --> 01:19:33.017
OK, to do an extract Min in a
binary heap will cost me what?

01:19:33.017 --> 01:19:38.905
O of log V.
Decreased key will cost me,

01:19:38.905 --> 01:19:44.932
yeah, it turns out you can do
that in order log V because

01:19:44.932 --> 01:19:49.668
basically you just have to
shuffle the value,

01:19:49.668 --> 01:19:54.295
actually shuffle it up towards
the root, OK?

01:19:54.295 --> 01:19:58.708
Or at log V.
And, the total cost therefore

01:19:58.708 --> 01:20:01.717
is?
E log V, good.

01:20:01.717 --> 01:20:06.869
Which of these is better?
It depends, good.

01:20:06.869 --> 01:20:12.758
When is one better,
and when is the other better?

01:20:12.758 --> 01:20:18.401
Yeah, if it's a dense graph,
E is close to V^2,

01:20:18.401 --> 01:20:24.167
the array is better.
But if it's a sparse graph,

01:20:24.167 --> 01:20:33.000
and E is much smaller than V^2,
then the binary heap is better.

01:20:33.000 --> 01:20:37.824
So that motivated the invention
of a data structure,

01:20:37.824 --> 01:20:43.216
OK, called a Fibonacci Heap.
So, Fibonacci Heap is covered

01:20:43.216 --> 01:20:47.851
in Chapter 20 of CLRS.
We're not going to hold you

01:20:47.851 --> 01:20:53.148
responsible for the content,
but it's an interesting data

01:20:53.148 --> 01:20:57.878
structure because it's an
amortized data structure.

01:20:57.878 --> 01:21:01.851
And it turns out that it is
data structure,

01:21:01.851 --> 01:21:08.000
you can do extract Min in order
log V amortized time.

01:21:08.000 --> 01:21:12.747
And remarkably,
you can do decreased key in

01:21:12.747 --> 01:21:17.834
order one amortized.
So, when I plug those in,

01:21:17.834 --> 01:21:21.000
what do I get over here?

01:21:34.000 --> 01:21:42.088
What's that going to be?
Plug that it here.

01:21:42.088 --> 01:21:52.296
It's going to be V times log V
plus E: E plus V log V.

01:21:52.296 --> 01:22:00.000
These are amortized,
so what's this?

01:22:00.000 --> 01:22:02.317
Trick question.
It's worst-case.

01:22:02.317 --> 01:22:05.979
It's not amortized over here.
These are amortized,

01:22:05.979 --> 01:22:08.745
but that's the beauty of
amortization.

01:22:08.745 --> 01:22:13.006
I can say it's going to be
worst case: E plus V log V over

01:22:13.006 --> 01:22:17.715
here, because when I add up the
amortized cost of my operations,

01:22:17.715 --> 01:22:20.480
it's an upper bound on the true
costs.

01:22:20.480 --> 01:22:24.292
OK, so that's why I say,
one of the beauties of this

01:22:24.292 --> 01:22:27.058
amortized analysis,
and in particular,

01:22:27.058 --> 01:22:31.692
being able to assign different
costs to different operations is

01:22:31.692 --> 01:22:37.000
I can just add them up and I get
my worst-case costs.

01:22:37.000 --> 01:22:40.565
So this is already V log V.
There are a couple other

01:22:40.565 --> 01:22:43.012
algorithms just before I let you
go.

01:22:43.012 --> 01:22:47.066
Kruskal's Algorithm in the book
uses another amortized data

01:22:47.066 --> 01:22:50.282
structure called a disjoint set
data structure,

01:22:50.282 --> 01:22:53.498
which also runs in E log V,
that is, this time:

01:22:53.498 --> 01:22:56.574
runs in this time,
the same as using a binary

01:22:56.574 --> 01:23:00.000
heap.
So, I'll refer you to the book.

01:23:00.000 --> 01:23:04.935
The best algorithm to date with
this problem is done by our own

01:23:04.935 --> 01:23:09.233
David Karger on the faculty here
with one of our former

01:23:09.233 --> 01:23:12.975
graduates, Phil Kline,
who is now a professor at

01:23:12.975 --> 01:23:17.353
Brown, and Robert Tarjan,
who is sort of like the master

01:23:17.353 --> 01:23:22.368
of all data structures who was a
professor at Princeton in 1993.

01:23:22.368 --> 01:23:26.189
OK, it's a randomized
algorithm, and it gives you

01:23:26.189 --> 01:23:32.000
order V plus E expected time.
OK, so that's the best to date.

01:23:32.000 --> 01:23:36.300
It's still open as to whether
there is a deterministic,

01:23:36.300 --> 01:23:40.679
there is worst-case bound,
whether there is a worst-case

01:23:40.679 --> 01:23:45.059
bound that is linear time.
OK, but there is a randomized

01:23:45.059 --> 01:23:47.369
to linear time,
and otherwise,

01:23:47.369 --> 01:23:51.509
this is essentially the best
bound without additional

01:23:51.509 --> 01:23:54.058
assumptions.
OK, very cool stuff.

01:23:54.058 --> 01:23:58.676
Next, we're going to see a lot
of these ideas of greedy and

01:23:58.676 --> 01:24:00.809
dynamic programming in practice.

