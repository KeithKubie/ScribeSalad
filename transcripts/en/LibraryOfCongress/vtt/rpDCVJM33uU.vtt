WEBVTT
Kind: captions
Language: en

00:00:00.730 --> 00:00:04.510
&gt;&gt; From the Library of
Congress in Washington, DC.

00:00:04.510 --> 00:00:19.210
[ Silence ]

00:00:19.210 --> 00:00:20.810
&gt;&gt; Bergis Jules: Thank
you for having me.

00:00:20.810 --> 00:00:23.730
It's right after lunch;
people are all energized.

00:00:23.730 --> 00:00:26.120
And now I'm going to depress
you with all my concerns

00:00:26.120 --> 00:00:29.200
about collecting social media data.

00:00:29.200 --> 00:00:31.900
I'm actually really
excited that, you know,

00:00:31.900 --> 00:00:34.850
this session is part
of the program today.

00:00:34.850 --> 00:00:39.930
Because you know, we don't do
enough thinking around, you know,

00:00:39.930 --> 00:00:43.590
the effects of doing this stuff
and how to protect people,

00:00:43.590 --> 00:00:47.340
so I'm really glad to see that
this panel is part of the program.

00:00:47.340 --> 00:00:49.720
And I'm glad to be part of it.

00:00:49.720 --> 00:00:54.510
So where is the -- okay.

00:00:54.510 --> 00:01:02.670
Alright, so at a basic level,
Documenting the Now is a project

00:01:02.670 --> 00:01:06.150 position:56%
to build free and open source tools
that are easy to use for collecting,

00:01:06.150 --> 00:01:09.000 position:56%
analyzing, and sharing twitter data.

00:01:09.000 --> 00:01:13.920 position:56%
It's a collaborative project between
UC-Riverside, the Maryland Institute

00:01:13.920 --> 00:01:17.260
for Technology and the Humanities
at the University of Maryland,

00:01:17.260 --> 00:01:20.790
and Washington University
in St. Louis.

00:01:20.790 --> 00:01:25.560
The DocNow team, our development
team, has been hard at work

00:01:25.560 --> 00:01:27.930
over the past ten months, you know,

00:01:27.930 --> 00:01:29.560
really trying to build
something great

00:01:29.560 --> 00:01:31.090
that everyone will be able to use.

00:01:31.090 --> 00:01:33.640
And I'm really excited
for what's to come.

00:01:33.640 --> 00:01:38.590
But today I'm going to focus less
on the technical part of our work.

00:01:38.590 --> 00:01:41.950
What's been really exciting --
what's been the most exciting part

00:01:41.950 --> 00:01:46.140
of the project, in my opinion,
is how much people from all kinds

00:01:46.140 --> 00:01:49.040
of backgrounds have engaged
with some of the ideas

00:01:49.040 --> 00:01:50.340
that we've been addressing.

00:01:50.340 --> 00:01:52.700
And I think those ideas
can help us address some

00:01:52.700 --> 00:01:56.970
of the more serious implications
for building collections of data,

00:01:56.970 --> 00:02:00.510
especially as they relate
to social media data.

00:02:00.510 --> 00:02:06.040
[ Silence ]

00:02:06.040 --> 00:02:10.220
So because our work was inspired
by the activism and protest

00:02:10.220 --> 00:02:13.670
that followed the police killing
of Michael Brown in Ferguson,

00:02:13.670 --> 00:02:16.870
Missouri in 2014, I
think from the beginning

00:02:16.870 --> 00:02:20.950
of the project we felt we
had a responsibility, really,

00:02:20.950 --> 00:02:26.140
not to forget that there are in
fact people behind all this data.

00:02:26.140 --> 00:02:30.520
That's why DocNow has such a focus
on ethics, of collecting this type

00:02:30.520 --> 00:02:33.130
of content for long-term
preservation.

00:02:33.130 --> 00:02:37.280
We're really interested
in how our building

00:02:37.280 --> 00:02:40.430
of these collections might
affect people's lives.

00:02:40.430 --> 00:02:44.170
It's also why we're being really
transparent with our work,

00:02:44.170 --> 00:02:48.540
while at the same time trying to
help build a community of people

00:02:48.540 --> 00:02:51.400
who also value these ideas.

00:02:51.400 --> 00:02:54.310
So really, you know,
at the higher level,

00:02:54.310 --> 00:02:58.090
DocNow is about a couple
of things, in my mind.

00:02:58.090 --> 00:02:59.810
It's about valuing
people enough to care

00:02:59.810 --> 00:03:02.340
about how we collect
and store their data.

00:03:02.340 --> 00:03:06.160
And it's about helping to build a
community of archives professionals

00:03:06.160 --> 00:03:09.160
and other folks committed to
engaging with content owners

00:03:09.160 --> 00:03:13.420
and creators in equitable and safe
ways as we collect their data.

00:03:13.420 --> 00:03:15.970
These two things are priorities

00:03:15.970 --> 00:03:18.760
above our technical
work on the project.

00:03:18.760 --> 00:03:21.820
And a lot of credit really
has to go to Ed Summers

00:03:21.820 --> 00:03:24.420
for the project being
framed this way.

00:03:24.420 --> 00:03:26.430
Ed has been my partner in crime

00:03:26.430 --> 00:03:29.160
over the past couple
years doing this work.

00:03:29.160 --> 00:03:33.510
And he's also a principal
investigator on the DocNow Project.

00:03:33.510 --> 00:03:38.040
[ Silence ]

00:03:38.040 --> 00:03:42.580
So we all agree that there's an
immense value in social media data,

00:03:42.580 --> 00:03:46.720
especially as it relates to our
work in archives in libraries.

00:03:46.720 --> 00:03:49.460
I'm primarily interested in
collecting that type of data,

00:03:49.460 --> 00:03:53.140 position:56%
especially twitter, because I think
it presents tremendous opportunities

00:03:53.140 --> 00:03:55.560
to document some aspects --

00:03:55.560 --> 00:03:59.450
some aspects of African-American
history and culture.

00:03:59.450 --> 00:04:02.470
For example, this is a Pew --

00:04:02.470 --> 00:04:05.970
a graph from the Pew
research that talked

00:04:05.970 --> 00:04:10.580
about how young African-Americans
are among the highest users

00:04:10.580 --> 00:04:13.490
of twitter especially, right?

00:04:13.490 --> 00:04:16.920 position:56%
So a large number of
African-Americans have round a space

00:04:16.920 --> 00:04:19.110
where they feel free
to share and engage

00:04:19.110 --> 00:04:20.410
in issues that matter to them.

00:04:20.410 --> 00:04:23.090
And especially considering
how little information we hold

00:04:23.090 --> 00:04:26.540
in our traditional collections
about African-Americans.

00:04:26.540 --> 00:04:29.000
You know, I think this is a good
opportunity to at least learn

00:04:29.000 --> 00:04:32.510
about some of those issues, if
not collect data about them.

00:04:32.510 --> 00:04:38.700
[ Silence ]

00:04:38.700 --> 00:04:44.400
So we've also seen the value that
platforms such as twitter have had

00:04:44.400 --> 00:04:45.820
in amplifying voices, right?

00:04:45.820 --> 00:04:48.580
In the current movement
for black lives,

00:04:48.580 --> 00:04:52.050
we've seen it in Arrow Spring, and
several other social justice events

00:04:52.050 --> 00:04:54.860
that have played out on line.

00:04:54.860 --> 00:04:59.940
This is a screen shot from the
brilliant work of Deen Freelon,

00:04:59.940 --> 00:05:03.710
Meredith Clark, and
Charlton McIlwain, Ferguson,

00:05:03.710 --> 00:05:07.620
Black Lives Matter, and the online
struggle for offline justice.

00:05:07.620 --> 00:05:10.510
I highly suggest you check
it out if you get a chance;

00:05:10.510 --> 00:05:15.490
it's a 90-something-page report
about the impact that twitter

00:05:15.490 --> 00:05:20.080
and other social media had on
spreading the message in Ferguson.

00:05:20.080 --> 00:05:22.140
So all of this is good.

00:05:22.140 --> 00:05:24.740
But we should also acknowledge
the significant responsibility

00:05:24.740 --> 00:05:27.770
and embrace the challenges that
come with collecting, preserving,

00:05:27.770 --> 00:05:29.480
and making that kind
of data accessible.

00:05:29.480 --> 00:05:32.190
And we should be prepared
to do this work in ways

00:05:32.190 --> 00:05:35.710
that don't compromise people's
safety, disregards their rights

00:05:35.710 --> 00:05:39.330
as content owners and creators,
or presents their data in ways

00:05:39.330 --> 00:05:42.060
that distorts people's
original intent.

00:05:47.570 --> 00:05:50.530
Because we know we're not
the only ones interested

00:05:50.530 --> 00:05:54.200
in collecting this
kind of data, right?

00:05:54.200 --> 00:05:59.660
So this is a screen
shot of an email from --

00:05:59.660 --> 00:06:02.930
the ACLU-California last
week published a report

00:06:02.930 --> 00:06:07.600
about the growing use of
social media collection tools

00:06:07.600 --> 00:06:11.380
by law enforcement, especially
local law enforcement.

00:06:11.380 --> 00:06:14.060 position:56%
And, you know, they were able to get
their hands on a lot of documents

00:06:14.060 --> 00:06:18.210
for this, and this is a screen
shot from an email that a company,

00:06:18.210 --> 00:06:21.470
Geofeedia, which is really
popular in this space right now,

00:06:21.470 --> 00:06:26.030
is sending out to its
clients about Ferguson.

00:06:26.030 --> 00:06:29.160
It's saying, you know, hey,
we have a lot of good stuff

00:06:29.160 --> 00:06:32.510
on Ferguson protestors here,
click here to view the collection.

00:06:32.510 --> 00:06:37.110
[ Silence ]

00:06:37.110 --> 00:06:40.720 position:56%
And, you know, here I think the ACLU
articulates really well, you know,

00:06:40.720 --> 00:06:44.580
the danger to people of color
and other minority groups

00:06:44.580 --> 00:06:47.530
when police start using
these kinds of tools, right?

00:06:47.530 --> 00:06:50.910
And for those in the back,
I'll go ahead and read this.

00:06:50.910 --> 00:06:55.140
"The racist implications of social
media surveillance technology are

00:06:55.140 --> 00:06:56.490
not surprising.

00:06:56.490 --> 00:06:59.580
We know that when law
enforcement gets to conceal the use

00:06:59.580 --> 00:07:02.700
of surveillance technology, they
also get to conceal its misuse.

00:07:02.700 --> 00:07:05.280
Discriminatory policing
that targets communities

00:07:05.280 --> 00:07:08.000
of color is unacceptable
and secretive.

00:07:08.000 --> 00:07:11.640
Sophisticated surveillance
technologies supersize the impact

00:07:11.640 --> 00:07:14.730
of racial profiling
and abuse, right?

00:07:14.730 --> 00:07:21.760
So there are some real issues
we have to consider here.

00:07:21.760 --> 00:07:25.470
How will our collections of
social media data be different

00:07:25.470 --> 00:07:29.250
than those built by law enforcement
or private security firms?

00:07:29.250 --> 00:07:34.820
I think that's a question
we all need to think about.

00:07:34.820 --> 00:07:36.660
Here's an image of two
prominent activists

00:07:36.660 --> 00:07:39.330
who became well known during
the Ferguson protests.

00:07:39.330 --> 00:07:43.560 position:56%
Here they're being labeled as threat
actors by a private security firm.

00:07:43.560 --> 00:07:49.780
This is DeRay McKesson on
the left, and Johnetta Elzie.

00:07:49.780 --> 00:07:58.670
I think this is in relation to the
Baltimore uprising when they found

00:07:58.670 --> 00:08:02.450
out that this company
especially, Zerofox was doing a lot

00:08:02.450 --> 00:08:06.550
of data collection for
local law enforcement.

00:08:07.690 --> 00:08:10.140
So it's a scary situation.

00:08:10.140 --> 00:08:14.520 position:56%
Because these companies are
increasingly interested in this data

00:08:14.520 --> 00:08:17.700
as a way to punish people
for being active citizens.

00:08:17.700 --> 00:08:21.430 position:56%
When Ed Summers -- and I'm
dropping Ed's name a lot here today.

00:08:21.430 --> 00:08:23.990
You're going to owe
me a beer after this.

00:08:23.990 --> 00:08:26.810
When Ed Summers first
published a blog post

00:08:26.810 --> 00:08:31.300
about the Ferguson twitter data set
we collected during the first month

00:08:31.300 --> 00:08:34.960
of that event, a private security
firm was one of the first groups

00:08:34.960 --> 00:08:38.830
to reach out to him asking if they
could access that data, right?

00:08:38.830 --> 00:08:42.860
It's a real concern for people
in our profession to be aware of.

00:08:42.860 --> 00:08:44.520
So for example, how do we make sure

00:08:44.520 --> 00:08:47.900
that the massive twitter data
archive being built right

00:08:47.900 --> 00:08:50.640
at the Library of Congress
doesn't become a tool

00:08:50.640 --> 00:08:54.630
that these groups can use against
already marginalized people, right?

00:08:54.630 --> 00:08:58.840
Whose only request is that
the police stop killing them.

00:08:58.840 --> 00:09:02.770 position:56%
So how will the Library respond to
requests from private security firms

00:09:02.770 --> 00:09:04.960
and law enforcement for that data?

00:09:04.960 --> 00:09:08.400
Part of the answer is that
we have to engage directly

00:09:08.400 --> 00:09:13.300
with people generating social media
data to understand how our work

00:09:13.300 --> 00:09:16.320
in collecting this type of
data might affect their lives.

00:09:16.320 --> 00:09:19.430
I think that will be an
important way for us to come

00:09:19.430 --> 00:09:20.950
up with some policies

00:09:20.950 --> 00:09:26.760
around offering public access
to some of this content.

00:09:26.760 --> 00:09:29.130
It's a difficult task,
but I think it's possible.

00:09:29.130 --> 00:09:34.180 position:56%
And, you know, it's especially tough
because of the number of people

00:09:34.180 --> 00:09:37.510
who can engage with an issue
on a social media platform

00:09:37.510 --> 00:09:38.810
at any given time, right?

00:09:38.810 --> 00:09:40.110
That number can be daunting.

00:09:40.110 --> 00:09:43.540
I'm not sure how large the
LC twitter data set is now,

00:09:43.540 --> 00:09:45.370
but I'm sure it's significant.

00:09:45.370 --> 00:09:47.450
And just in the past couple weeks,

00:09:47.450 --> 00:09:51.000
Ed has collected almost
two million tweets related

00:09:51.000 --> 00:09:54.250
to the police killings of
Keith Scott in Charlotte,

00:09:54.250 --> 00:09:56.480
and Terence Crutcher in Tulsa.

00:09:56.480 --> 00:10:00.210
So it's a big job, but
I think it's possible.

00:10:00.210 --> 00:10:03.470
There are ways to engage if
we're willing to drop some

00:10:03.470 --> 00:10:05.830
of our traditional models
of building collections

00:10:05.830 --> 00:10:09.620
that prioritize our ideas about
professionalism and the myth

00:10:09.620 --> 00:10:12.510
of neutrality over the wishes
of people and communities.

00:10:12.510 --> 00:10:20.240
[ Silence ]

00:10:20.240 --> 00:10:24.780
So last month the DocNow Project
hosted our first advisory board

00:10:24.780 --> 00:10:26.400
meeting in St. Louis.

00:10:26.400 --> 00:10:28.060
And this was an opportunity

00:10:28.060 --> 00:10:30.370
to get our awesome
advisory board members --

00:10:30.370 --> 00:10:34.780
I'm sure some of these names or
these faces are familiar to you --

00:10:34.780 --> 00:10:37.650
to get together for
a deep dive into many

00:10:37.650 --> 00:10:41.030
of the issues we've been raising
around social media, web archiving,

00:10:41.030 --> 00:10:44.040
ethics, and technology
over the past year.

00:10:44.040 --> 00:10:48.610
And, you know, this was a really --

00:10:48.610 --> 00:10:54.740
we had six really great
panels of insightful

00:10:54.740 --> 00:10:56.360
and challenging discussions.

00:10:56.360 --> 00:10:59.860
And I really hope you'll
check them out on our website,

00:10:59.860 --> 00:11:02.400
DocNow.io when you get a chance.

00:11:02.400 --> 00:11:04.210
Because I don't think
this type of --

00:11:04.210 --> 00:11:08.130
this group of people really have
been brought together before

00:11:08.130 --> 00:11:12.810
in the context of sort of archiving
digital media or web archives.

00:11:12.810 --> 00:11:15.160
So definitely check it
out if you get a chance,

00:11:15.160 --> 00:11:18.540
it's in the meetings
page on our website.

00:11:18.540 --> 00:11:21.760
But I want to focus on
just one of those panels

00:11:21.760 --> 00:11:24.750
for the last few minutes, because
I think it's a great example

00:11:24.750 --> 00:11:28.690
of the type of community work
we're going to need to engage

00:11:28.690 --> 00:11:32.060
in in the future if we want to
continue building these types

00:11:32.060 --> 00:11:34.960
of data sets as archives.

00:11:34.960 --> 00:11:39.560
The panel was made up of
four activists from Ferguson

00:11:39.560 --> 00:11:42.560
who were some of the many
organizers in Ferguson

00:11:42.560 --> 00:11:43.930
after Michael Brown's killing.

00:11:43.930 --> 00:11:48.580
It included Alexis
Templeton, Rasheen Aldridge,

00:11:48.580 --> 00:11:50.520
Kayla Reed, and Reuben Riggs.

00:11:50.520 --> 00:11:53.830 position:56%
And it was really expertly
moderated by Dr. Jonathan Fenderson,

00:11:53.830 --> 00:11:56.400
who is a faculty member
at Washington University.

00:11:56.400 --> 00:12:01.300
And I was really thankful for
the activists for joining us.

00:12:01.300 --> 00:12:02.990
Because, you know these are people

00:12:02.990 --> 00:12:05.350
who have nine-to-fives;
they're students.

00:12:05.350 --> 00:12:08.060
And they took time out of
their day to be with us

00:12:08.060 --> 00:12:10.210
for a good chunk of the day.

00:12:10.210 --> 00:12:11.900
And so we really appreciated that.

00:12:11.900 --> 00:12:15.840 position:56%
And, you know, they really added a
richness and a realness to the event

00:12:15.840 --> 00:12:19.840 position:56%
that we wouldn't have had otherwise.

00:12:19.840 --> 00:12:23.510
You know, and they talked about
their lives before Ferguson,

00:12:23.510 --> 00:12:26.130 position:56%
they talked about their lives during
Ferguson, and their lives now.

00:12:26.130 --> 00:12:29.950 position:56%
And there were some really difficult
conversations that happened

00:12:29.950 --> 00:12:32.590
on that panel; it's about
an hour and a half long,

00:12:32.590 --> 00:12:34.010
our longest panel of the day.

00:12:34.010 --> 00:12:39.110
And, you know, I think that
there's some real good stuff

00:12:39.110 --> 00:12:40.410
in there, so check it out.

00:12:40.410 --> 00:12:45.590 position:56%
I'm seeing my five minutes cue here,
so I'll go ahead and stop here.

00:12:45.590 --> 00:12:50.800
But I want to share a short
clip from that panel with you;

00:12:50.800 --> 00:12:56.610
it's about six minutes long, so
-- and I'll just leave it open

00:12:56.610 --> 00:13:00.130
and then we can get into
a conversation that way.

00:13:00.130 --> 00:13:03.510
So let's see if this will
work; it worked during testing.

00:13:03.510 --> 00:13:08.080
[ Silence ]

00:13:08.080 --> 00:13:10.690
So you all are in a roomful of
people who are really interested

00:13:10.690 --> 00:13:14.870
in documenting the now, right?

00:13:14.870 --> 00:13:18.130
To try to be able to
capture what's happening,

00:13:18.130 --> 00:13:22.000
particularly with social
movements as it's happening, right?

00:13:22.000 --> 00:13:26.640
And so one of the things that's
really interesting is that --

00:13:26.640 --> 00:13:29.530
sorry, you're going to
hear from Alexis first.

00:13:29.530 --> 00:13:32.050
And Kayla second.

00:13:32.050 --> 00:13:34.950
This is a story that
you all helped create,

00:13:34.950 --> 00:13:37.660
helped make into a global story.

00:13:37.660 --> 00:13:39.250 position:56%
But at the same time it's a story --

00:13:39.250 --> 00:13:44.120
and in many ways attempted to
control via twitter, right?

00:13:44.120 --> 00:13:47.630
But at the same time it's a
story that's become so big

00:13:47.630 --> 00:13:50.930
that it's also beyond any
of your control, right?

00:13:50.930 --> 00:13:53.930
And so one of the questions I
really wanted to get at was,

00:13:53.930 --> 00:13:56.510
how do you all want the
movement to be remembered?

00:13:56.510 --> 00:14:00.110 position:56%
And what are some of the things that
you would like people doing research

00:14:00.110 --> 00:14:03.100
around your lives, your work?

00:14:03.100 --> 00:14:07.890
What are some of the things you
want them to be conscious of?

00:14:07.890 --> 00:14:10.190
You can't stop them, right?

00:14:10.190 --> 00:14:12.290
But what are some of the things
you would want them to keep in mind

00:14:12.290 --> 00:14:14.340
as they're doing that work?

00:14:14.340 --> 00:14:16.370
&gt;&gt; Can I go first?

00:14:16.370 --> 00:14:17.670
&gt;&gt; Yes.

00:14:17.670 --> 00:14:18.970
&gt;&gt; [Inaudible], alright, cool.

00:14:18.970 --> 00:14:24.630
So like, really iffy about -- I
guess I'm more so just talking

00:14:24.630 --> 00:14:27.260 position:56%
to like the black folks in the room.

00:14:27.260 --> 00:14:33.700
When documenting the movement, like
internally, like, don't wash out,

00:14:33.700 --> 00:14:36.280
like, the internal politics of it.

00:14:36.280 --> 00:14:40.200
And like the argument, like,
don't wash that stuff out.

00:14:40.200 --> 00:14:43.020
Don't wash away the homophobia,
don't wash away the sexism,

00:14:43.020 --> 00:14:45.590
like don't wash away the misogyny,

00:14:45.590 --> 00:14:47.800
like don't wash away
those front line stories

00:14:47.800 --> 00:14:50.150
about what was happening
to people like internally,

00:14:50.150 --> 00:14:53.000 position:56%
and how people felt unsafe like with
people they were fighting next to,

00:14:53.000 --> 00:14:54.930
like don't leave that out.

00:14:54.930 --> 00:15:00.380
Because we have, in all our
movements and it leaves people

00:15:00.380 --> 00:15:03.290
so scorned and so hurt
and so bitter.

00:15:03.290 --> 00:15:05.360
Which is why a lot of the
arguments happen online.

00:15:05.360 --> 00:15:08.020
Which is why like, you know,
they don't really bother me.

00:15:08.020 --> 00:15:10.150
Because it also humanizes
our movement.

00:15:10.150 --> 00:15:12.050
And I don't think we've
got that with a lot of --

00:15:12.050 --> 00:15:15.330 position:56%
I don't think we've gotten that with
any black movement that we've had.

00:15:15.330 --> 00:15:16.630
They've never been humanized.

00:15:16.630 --> 00:15:19.010
They always felt they had to be
perfect when fighting the system,

00:15:19.010 --> 00:15:21.000
and we just fucking aren't, right?

00:15:21.000 --> 00:15:24.830
We just aren't; we're depressed.

00:15:24.830 --> 00:15:27.230
We like to drink and
smoke to cope, like.

00:15:27.230 --> 00:15:31.340
We curse, like we have kids, we
have jobs, like we're married, not,

00:15:31.340 --> 00:15:33.550
like we're scorned, like whatever.

00:15:33.550 --> 00:15:34.980
Like we're human, you know?

00:15:34.980 --> 00:15:37.250
And like I don't want
people to forget that.

00:15:37.250 --> 00:15:40.190
Like actually humanize
the people out there.

00:15:40.190 --> 00:15:43.390
These everyday people, because
they're literally like just

00:15:43.390 --> 00:15:45.700
like you all in this room.

00:15:45.700 --> 00:15:51.890
And like we can't -- we just
can't wash them out of the story.

00:15:51.890 --> 00:15:55.010
&gt;&gt; Bergis Jules: Real quick,
I saw the five-minute sign,

00:15:55.010 --> 00:15:56.310
so we've got to wrap it tight.

00:15:56.310 --> 00:15:59.470
&gt;&gt; Yes, so for me,
that's really important.

00:15:59.470 --> 00:16:03.930
And the other thing I would add to
that, the other thing I would add

00:16:03.930 --> 00:16:07.790
to that is just the idea of
what Reuben was hinting to,

00:16:07.790 --> 00:16:11.840
that social media at first was
this super democratized space,

00:16:11.840 --> 00:16:14.710 position:56%
but it somewhat perpetuates elitism.

00:16:14.710 --> 00:16:20.630
That for those of us who have
a -- like I have like $15,000,

00:16:20.630 --> 00:16:23.560
Alexis has whatever, it changes.

00:16:23.560 --> 00:16:24.880
But it's a lot.

00:16:24.880 --> 00:16:29.380
And so people, some like
mistakenly put your value

00:16:29.380 --> 00:16:31.750
at how many people
choose to follow you.

00:16:31.750 --> 00:16:34.350
And leadership isn't based on how
many followers you have online,

00:16:34.350 --> 00:16:36.480
leadership is based on how
many people you're invested

00:16:36.480 --> 00:16:38.350
in in developing on the ground.

00:16:38.350 --> 00:16:41.120
And so some of my -- the most
important things that I feel

00:16:41.120 --> 00:16:43.320
like I accomplished
in the last few years,

00:16:43.320 --> 00:16:45.970
maybe weren't told on
social media, right?

00:16:45.970 --> 00:16:49.210
Because they didn't need
to be told on social media.

00:16:49.210 --> 00:16:52.160
And my development into
self and our relationships,

00:16:52.160 --> 00:16:54.330
like those stories aren't
told on social media.

00:16:54.330 --> 00:16:57.660
And so just being conscious of
the fact that for every face

00:16:57.660 --> 00:17:00.680
that you see that has been
lifted up, that we are standing

00:17:00.680 --> 00:17:03.150
on the shoulders of
hundreds of giants

00:17:03.150 --> 00:17:05.080
that we'll never even see again.

00:17:05.080 --> 00:17:08.370 position:56%
And Ferguson wasn't because the four
of us just came together in a huddle

00:17:08.370 --> 00:17:09.900
and said we're going to
fight for black liberation.

00:17:09.900 --> 00:17:12.590
It's because thousands of
people in St. Louis said, yo,

00:17:12.590 --> 00:17:15.590
this is messed up; and I'm
not going to let this stand.

00:17:15.590 --> 00:17:18.020
And we see those people
every time we go to Target,

00:17:18.020 --> 00:17:20.810
hopefully when you
don't go to Walmart.

00:17:20.810 --> 00:17:25.230
When you go into your local fast
food spot, you see those people

00:17:25.230 --> 00:17:30.620
who for a moment say, I'm going
to give all of myself to a space,

00:17:30.620 --> 00:17:32.180
and then go back to life.

00:17:32.180 --> 00:17:36.970
And so we've been ethically
blessed; like we worked for it,

00:17:36.970 --> 00:17:41.340
but also part of it is just this
crazy equation that happened

00:17:41.340 --> 00:17:43.090
that put us in an elevated space.

00:17:43.090 --> 00:17:47.200
And so our job in that elevated
space is to always fight for those

00:17:47.200 --> 00:17:49.360
who aren't in those spaces
and represent them well.

00:17:49.360 --> 00:17:51.540
And I think we really try to
do that, but that's your job,

00:17:51.540 --> 00:17:53.710
it's to tell those stories,
to find those people.

00:17:53.710 --> 00:17:56.240
And if you can't find those
people, at least create space

00:17:56.240 --> 00:17:59.600
for that narrative to be
built that like for the rest

00:17:59.600 --> 00:18:01.510
of my life I'll owe
people I'll never know.

00:18:01.510 --> 00:18:04.520
And I take that shit
so seriously, you know?

00:18:04.520 --> 00:18:07.900
Like in every space I represent,
it's like my mom and my grandma are

00:18:07.900 --> 00:18:11.650 position:56%
like behind some window I can't see;
that's the way I need to behave.

00:18:11.650 --> 00:18:14.450
Because people literally
sacrifice their lives

00:18:14.450 --> 00:18:17.050
and comfort for one person.

00:18:17.050 --> 00:18:20.420
And we have somewhat
benefited from it, right?

00:18:20.420 --> 00:18:22.330
And somewhat been super
traumatized by it.

00:18:22.330 --> 00:18:25.740
But -- and in the benefit
has come more trauma.

00:18:25.740 --> 00:18:29.270
But like accept that and
like tell our whole selves.

00:18:29.270 --> 00:18:31.910
And so I made this
commitment in therapy --

00:18:31.910 --> 00:18:34.010
because I didn't go to
therapy before Ferguson.

00:18:34.010 --> 00:18:36.170
But I made this commitment
that said like I will love --

00:18:36.170 --> 00:18:39.960
I commit to my community and
myself to love us in our entirety.

00:18:39.960 --> 00:18:42.640
And that's the non-romantic story;

00:18:42.640 --> 00:18:44.640
that's the "we were hungry,
we didn't have food."

00:18:44.640 --> 00:18:46.440
That's the subway lady
giving us a sandwich

00:18:46.440 --> 00:18:47.740
when we didn't have no money.

00:18:47.740 --> 00:18:50.990
That's then her getting cancer and
putting up a GoFundMe and reaching

00:18:50.990 --> 00:18:53.070
out to Ferguson activists
who have become --

00:18:53.070 --> 00:18:55.700
have platforms now to say,
you all, I have cancer.

00:18:55.700 --> 00:18:57.790
When she would come out every
single night and ask us,

00:18:57.790 --> 00:19:01.020
did we need to use the restroom
again before the subway closed?

00:19:01.020 --> 00:19:03.270
That's a story that a
lot of people don't know,

00:19:03.270 --> 00:19:05.930
but was so important
to just how we sustain.

00:19:05.930 --> 00:19:10.580 position:56%
That that kind of community existed.

00:19:11.840 --> 00:19:14.580
&gt;&gt; Bergis Jules: Alright.

00:19:14.580 --> 00:19:22.270
Okay, where is -- alright,
so that's all I have.

00:19:22.270 --> 00:19:25.510
And look forward to the discussion.

00:19:25.510 --> 00:19:51.670
[ Applause ]

00:19:51.670 --> 00:19:53.470
&gt;&gt; Nicole Saylor: Oh, hello.

00:19:53.470 --> 00:19:57.220
It's an extremely tough act
to follow; thanks for that.

00:19:57.220 --> 00:20:05.710 position:56%
I want to thank NDI, Kate for this
wonderful opportunity to participate

00:20:05.710 --> 00:20:07.900
in such a terrific event.

00:20:07.900 --> 00:20:18.090
So my talk is a rehash of a
paper that we put together

00:20:18.090 --> 00:20:20.760
for the upcoming IPRES conference.

00:20:20.760 --> 00:20:24.300
And so it's less about the ethical
considerations of this work,

00:20:24.300 --> 00:20:28.600
and more about the
technical side of the work.

00:20:28.600 --> 00:20:33.220
But I'm certainly happy to
talk about ethics in the Q&amp;A.

00:20:33.220 --> 00:20:36.650
So I'd like to give a shout out to
the co-authors, and I invite them

00:20:36.650 --> 00:20:40.530
to chime in to correct and
expand as needed; I welcome that.

00:20:40.530 --> 00:20:44.220
I also want to shout out to
Julia Kim and Melissa Lindberg

00:20:44.220 --> 00:20:46.760
in the American Folklife Center,
who are the ones in receipt

00:20:46.760 --> 00:20:49.920
of these big piles of ones
and zeros, and they push them

00:20:49.920 --> 00:20:51.970 position:56%
through our system for preservation.

00:20:51.970 --> 00:20:54.310
And we couldn't do it without them.

00:20:54.310 --> 00:20:57.690
I also want to take a
minute at a forum like this

00:20:57.690 --> 00:21:01.970
to acknowledge the AFC
Director, Betsy Peterson,

00:21:01.970 --> 00:21:06.150 position:56%
and other senior leaders in
Library Services and in Web Services

00:21:06.150 --> 00:21:10.110
for sort of recognizing the
importance of these projects

00:21:10.110 --> 00:21:13.000
and creating conditions where
this kind of experimentation

00:21:13.000 --> 00:21:15.310
and innovation can exist.

00:21:15.310 --> 00:21:17.380
So today I'll be talking

00:21:17.380 --> 00:21:20.800
about a collaboration among
my library colleagues to pull

00:21:20.800 --> 00:21:23.660
down web content for
preservation and access

00:21:23.660 --> 00:21:27.180
that moves us beyond classic
web archiving methods.

00:21:27.180 --> 00:21:32.020
And I'll focus on two community
collecting projects, one to solicit

00:21:32.020 --> 00:21:35.880
and harvest community-generated
photos off of Flickr.

00:21:35.880 --> 00:21:38.870
And then another is to gather
oral narratives generated

00:21:38.870 --> 00:21:41.840
through a relatively new
story core mobile application.

00:21:41.840 --> 00:21:45.810
So both projects involve
a public call to action,

00:21:45.810 --> 00:21:50.030
and they prompt public engagement
in building library collections.

00:21:50.030 --> 00:21:52.490 position:56%
They leverage our partnerships or --

00:21:52.490 --> 00:21:56.950
by leveraging or partnering with
third party software platforms,

00:21:56.950 --> 00:22:01.380
these efforts allow us to focus on
preservation and long-term access

00:22:01.380 --> 00:22:03.520
of records while still
supporting immediate

00:22:03.520 --> 00:22:06.340
and dynamic engagement
with communities.

00:22:06.340 --> 00:22:14.770
Kate got into it a little bit,
but just a brief background

00:22:14.770 --> 00:22:16.290
on the American Folklife Center.

00:22:16.290 --> 00:22:20.100
We are a large ethnographic
archive with more

00:22:20.100 --> 00:22:22.900
than five million items
-- closer to six.

00:22:22.900 --> 00:22:27.350 position:56%
And these collections include
extensive audio-visual documentation

00:22:27.350 --> 00:22:30.830
of traditional arts, cultural
expressions, oral histories.

00:22:30.830 --> 00:22:34.330
And they offer researchers
access to songs, stories,

00:22:34.330 --> 00:22:39.720
and other creative expressions of
people from diverse communities.

00:22:39.720 --> 00:22:44.340
And as mentioned they range from
wax cylinders created in 1890

00:22:44.340 --> 00:22:46.140
that we talked about
yesterday at the conference

00:22:46.140 --> 00:22:47.760
in the other building,

00:22:47.760 --> 00:22:52.140
to the born-digital StoryCorps
collection, among many others.

00:22:52.140 --> 00:22:55.010
And we have pretty
much every technology,

00:22:55.010 --> 00:22:58.560
AV technology in between
represented in our collection.

00:22:59.830 --> 00:23:02.200
I'll mention too that
we're perhaps best known

00:23:02.200 --> 00:23:04.680
for our collection
of field recordings.

00:23:04.680 --> 00:23:07.640
These performances of
songs, instrumental music

00:23:07.640 --> 00:23:09.750
by little-known grassroots
musicians.

00:23:09.750 --> 00:23:15.550 position:56%
But also by famous musicians such as
Elizabeth Cotten and Molly Jackson,

00:23:15.550 --> 00:23:18.130
Woody Guthrie, Lead
Belly, Jelly Roll Morton,

00:23:18.130 --> 00:23:20.390
Burl Ives, Johnny Cash, and so on.

00:23:20.390 --> 00:23:23.290
Some of whom did very
famous performances right

00:23:23.290 --> 00:23:28.770
on this very stage that
are in our archives.

00:23:28.770 --> 00:23:32.890 position:56%
Alright, so moving ahead -- maybe --

00:23:34.260 --> 00:23:36.370
The American Folklife
Center was created

00:23:36.370 --> 00:23:39.090
in 1976 by an act of Congress.

00:23:39.090 --> 00:23:42.100
And we have a wide
ranging mandate to preserve

00:23:42.100 --> 00:23:44.480
and to present folk life.

00:23:44.480 --> 00:23:48.060
And so I'm showing you just
a snippet of the verbiage

00:23:48.060 --> 00:23:53.650
from the legislation, which
defines what folk life is,

00:23:53.650 --> 00:23:58.170
and sort of sets our tone
for collecting scope,

00:23:58.170 --> 00:24:02.740
which I would say is broad if
not wildly ambitious to try

00:24:02.740 --> 00:24:05.290
to get all of this documented.

00:24:05.290 --> 00:24:11.700
So I want to point out that the
digital collecting initiatives

00:24:11.700 --> 00:24:14.760
that I'm going to talk about
are part of a long history

00:24:14.760 --> 00:24:18.330
of the archives of
soliciting public collaboration

00:24:18.330 --> 00:24:21.020
in documenting the cultural record.

00:24:21.020 --> 00:24:23.950 position:56%
Even with the founding of the
archives, Robert Winslow Gordon went

00:24:23.950 --> 00:24:28.370
out and recorded singers to
document American folk song.

00:24:28.370 --> 00:24:32.590
Of course, Alan Lomax,
right after Pearl Harbor --

00:24:32.590 --> 00:24:37.160 position:56%
who was then the assistant in charge
of the archive, sent a telegram

00:24:37.160 --> 00:24:40.190
to field workers in various
locations throughout the United

00:24:40.190 --> 00:24:43.490
States telling them to please
do man-on-the-street interviews

00:24:43.490 --> 00:24:47.440
to get people's reactions
to what had happened.

00:24:47.440 --> 00:24:49.930
We have since built on that
tradition, with doing the same

00:24:49.930 --> 00:24:52.850
for 9/11, for sermons and orations

00:24:52.850 --> 00:24:55.850
that were commemorating
the inauguration

00:24:55.850 --> 00:25:00.510
of the first African-American
President, and so on.

00:25:00.510 --> 00:25:05.040
[ Silence ]

00:25:05.040 --> 00:25:09.250
So of course with the proliferation
of smart phones, tablets,

00:25:09.250 --> 00:25:11.500
and wireless internet connections,

00:25:11.500 --> 00:25:14.280
networked communication
is increasingly

00:25:14.280 --> 00:25:16.660
where the cultural record
is being documented.

00:25:16.660 --> 00:25:20.210
And so AFC staff have
long recognized this need

00:25:20.210 --> 00:25:25.320
to preserve folk expression on the
web, and until how have not had

00:25:25.320 --> 00:25:26.620
but paper tools to do them.

00:25:26.620 --> 00:25:30.160
So you'll see, we have a
very respectable collection

00:25:30.160 --> 00:25:35.960
of scam emails that are
in boxes, printed out.

00:25:35.960 --> 00:25:42.080
But anyway, we've since evolved
and in June 2014 we worked

00:25:42.080 --> 00:25:45.810
with Abby Gratke's team in
the web archiving program

00:25:45.810 --> 00:25:48.650 position:56%
to create a web cultures collection.

00:25:48.650 --> 00:25:52.880
And we co-curate this with
scholars who study digital culture.

00:25:52.880 --> 00:25:55.550
And we're capturing a set of sites

00:25:55.550 --> 00:25:59.040
that document the digital
vernaculars.

00:25:59.040 --> 00:26:04.190
And so we're up to about 49 sites
ranging from "know your meme" --

00:26:04.190 --> 00:26:08.570
there's a pepper spray everything
meme, that's one on that site.

00:26:08.570 --> 00:26:12.920
And to creepypasta.com; and
feel free to google that later.

00:26:12.920 --> 00:26:22.750
Alright, so our -- just briefly
-- yes, I love that one so much.

00:26:22.750 --> 00:26:29.450
Anyway, so we're looking at
sites that document, you know,

00:26:29.450 --> 00:26:34.220
communities that are engaging
with each other, DIY communities,

00:26:34.220 --> 00:26:39.720
SPAN communities, people talking
about urban legends and lore.

00:26:39.720 --> 00:26:43.100
Again, these are just extensions
of the kinds of documentation

00:26:43.100 --> 00:26:44.400
that we have in the analog.

00:26:44.400 --> 00:26:51.480
Alright, so by way of background,

00:26:51.480 --> 00:26:55.590
the Library of Congress has been
collecting web archives since 2000,

00:26:55.590 --> 00:26:58.230
and has a well-established
practice for acquiring

00:26:58.230 --> 00:27:00.530
and processing the collections.

00:27:00.530 --> 00:27:04.770
Most website collections are
harvested via a crawler tool,

00:27:04.770 --> 00:27:06.070
Heritrix.

00:27:06.070 --> 00:27:08.830
And they are saved into
a format called WARC.

00:27:08.830 --> 00:27:14.380 position:56%
The crawler works from a list of
known seeds that are starting URL's.

00:27:14.380 --> 00:27:19.790
And then it -- you're
doing a great job --

00:27:19.790 --> 00:27:24.120
and it crawls to a specific depth

00:27:24.120 --> 00:27:28.420
from each one following
internal links on websites.

00:27:28.420 --> 00:27:30.910
There's no verification
against the original source;

00:27:30.910 --> 00:27:32.950 position:56%
that's not possible in this context.

00:27:32.950 --> 00:27:35.840
But the results are
subjectively reviewed.

00:27:35.840 --> 00:27:37.860
And these methods are appropriate

00:27:37.860 --> 00:27:40.480
for collecting documentation
of everyday life.

00:27:40.480 --> 00:27:43.520
But they're different and
distinctive from the kinds

00:27:43.520 --> 00:27:46.780 position:56%
of abilities that were offered in
these two projects I'm going to talk

00:27:46.780 --> 00:27:50.910
about in ten minutes or less.

00:27:50.910 --> 00:27:53.830
Okay.

00:27:53.830 --> 00:27:57.900
We first started working
with library developers

00:27:57.900 --> 00:28:05.220
to collect user submitted
photographs via Flickr

00:28:05.220 --> 00:28:08.420
that document Halloween, Day
of the Dead, and the other sort

00:28:08.420 --> 00:28:09.720
of constellation of holidays

00:28:09.720 --> 00:28:12.670
that surround late
October, early November.

00:28:12.670 --> 00:28:18.160 position:56%
So participants were asked to post
photos to Flickr with that hash tag;

00:28:18.160 --> 00:28:20.970
we did it again last year.

00:28:20.970 --> 00:28:25.370
And then have a creative comments
license accompanying them.

00:28:25.370 --> 00:28:30.010
We've since expanded that; this is
our 40th anniversary of the center.

00:28:30.010 --> 00:28:33.520
And so we've asked people
to document their traditions

00:28:33.520 --> 00:28:34.820 position:56%
and do the same thing, so at the end

00:28:34.820 --> 00:28:37.580
of the calendar year we'll be
working again with developers

00:28:37.580 --> 00:28:41.190
to pull that content
into our archives.

00:28:41.190 --> 00:28:44.930
So the Flickr harvesting projects,

00:28:44.930 --> 00:28:47.690
like the StoryCorps project I'm
going to talk about in a minute,

00:28:47.690 --> 00:28:49.850
you know, have these
contours that are well suited

00:28:49.850 --> 00:28:53.610
for a different approach to
acquiring and processing.

00:28:53.610 --> 00:28:57.560
There's no external links in
the data, no easy list of seeds

00:28:57.560 --> 00:28:59.990
that link to the collections
externally.

00:28:59.990 --> 00:29:01.410
And most of the data was created --

00:29:01.410 --> 00:29:06.860
well, in the case of
StoryCorps, in an app.

00:29:06.860 --> 00:29:09.570 position:56%
And so the data sets, they also need

00:29:09.570 --> 00:29:12.890
to be treated differently
in terms of access.

00:29:12.890 --> 00:29:15.350
But in the case of StoryCorps --

00:29:15.350 --> 00:29:19.090
well, and Flickr, access is being
handled by these third parties.

00:29:19.090 --> 00:29:23.540
So that lets us off
the hook for now.

00:29:25.410 --> 00:29:30.380
Okay, so anyway, at the Library we
seen to have settled into a rhythm

00:29:30.380 --> 00:29:34.620
where we treat born-digital
data sets and web harvesting

00:29:34.620 --> 00:29:37.480
as two dependent but
related practices.

00:29:37.480 --> 00:29:42.590 position:56%
Data sets are generally collected in
time or tag-bound chunks by querying

00:29:42.590 --> 00:29:45.800
and external API, they're
downloaded onto LC storage

00:29:45.800 --> 00:29:48.990
in baguette structure,
and then continue

00:29:48.990 --> 00:29:51.090
through the useral workflow.

00:29:51.090 --> 00:29:53.010
Depending on whether they're
slated for preservation

00:29:53.010 --> 00:29:56.040
or online access, or both.

00:29:56.040 --> 00:30:03.450
Okay, so let me just move quickly
into the StoryCorps example.

00:30:03.450 --> 00:30:06.650
So this venture is an extension

00:30:06.650 --> 00:30:09.860
of a longstanding relationship
we've had with StoryCorps.

00:30:09.860 --> 00:30:12.260
StoryCorps started in 2003;

00:30:12.260 --> 00:30:17.470
they're now among the largest oral
narrative projects of their kind.

00:30:17.470 --> 00:30:20.450
And interviews have been
collected at mobile booths

00:30:20.450 --> 00:30:24.280
and permanent story booths
located in New York, Chicago,

00:30:24.280 --> 00:30:26.130
San Francisco, and Atlanta.

00:30:26.130 --> 00:30:29.670
The traditional interview is two
people who know each other talking

00:30:29.670 --> 00:30:31.770
with a facilitator for
about 40 minutes in a booth.

00:30:31.770 --> 00:30:36.190
And then each recording is
preserved at the Library

00:30:36.190 --> 00:30:38.640
of Congress American
Folklife Center.

00:30:38.640 --> 00:30:42.620
And then these -- snippets
of this stuff gets broadcast

00:30:42.620 --> 00:30:45.150
on National Public
Radio's morning edition.

00:30:45.150 --> 00:30:49.610
And so since the inception of the
project in 2003, the signature,

00:30:49.610 --> 00:30:54.270
what we're calling, you know,
face-to-face StoryCorps is --

00:30:54.270 --> 00:30:58.020
they've garnered more
than 67,000 interviews.

00:30:58.020 --> 00:31:03.210
And so then in 2015, founder
Dave Isay won the TED prize;

00:31:03.210 --> 00:31:04.520
which when you win the TED prize,

00:31:04.520 --> 00:31:08.180
you get a million dollars,
which is great.

00:31:08.180 --> 00:31:11.720
So Dave wanted to create an app

00:31:11.720 --> 00:31:14.090
to take StoryCorps
global; and so he did.

00:31:14.090 --> 00:31:17.020
And so we were like,
whoa, okay, let's do this.

00:31:17.020 --> 00:31:23.360
So we worked with StoryCorps
developers

00:31:23.360 --> 00:31:26.590
to put something together.

00:31:26.590 --> 00:31:29.230
And that's what I'll talk about.

00:31:29.230 --> 00:31:32.290
So as StoryCorps developers
were designing their app,

00:31:32.290 --> 00:31:34.600
they worked with the software
developers here at the Library

00:31:34.600 --> 00:31:38.050
to identify, design, and
construct this transfer mechanism.

00:31:38.050 --> 00:31:41.370
The team agreed that an API
would benefit both parties;

00:31:41.370 --> 00:31:44.010
the Library could receive or fetch.

00:31:44.010 --> 00:31:48.480
Oh boy, five -- and then
it would allow StoryCorps

00:31:48.480 --> 00:31:50.480
to expose their collection
for harvesting instead

00:31:50.480 --> 00:31:54.800
of spending staff time prepping
it and pushing it out to us.

00:31:54.800 --> 00:31:59.240
So one of the main requirements for
the API was the need for fixities.

00:31:59.240 --> 00:32:02.560
While StoryCorps developers
considered their content fluid,

00:32:02.560 --> 00:32:08.000 position:56%
Library developers were adamant that
we need things to be fixed, right?

00:32:08.000 --> 00:32:11.200
And so explaining this to an
external partner was beneficial,

00:32:11.200 --> 00:32:14.730 position:56%
of course, because it's a
technical facet of the library world

00:32:14.730 --> 00:32:19.940 position:56%
that exposes archival
preservation practices more broadly.

00:32:19.940 --> 00:32:22.210
This was where my cool
graphic was going to go

00:32:22.210 --> 00:32:25.220
to explain that, but
I couldn't do it.

00:32:25.220 --> 00:32:27.910
Anyway, so each interview
package consists

00:32:27.910 --> 00:32:31.260
of metadata files, JSON format.

00:32:31.260 --> 00:32:33.500
And there's an optional
upload of a photo,

00:32:33.500 --> 00:32:36.910
a selfie with your
interview partner in JPEG.

00:32:36.910 --> 00:32:39.160
And then an MP3 audio file.

00:32:39.160 --> 00:32:42.960
And those are discrete
packets that are served up.

00:32:42.960 --> 00:32:46.780
And StoryCorps was happy to
add the checksum feature,

00:32:46.780 --> 00:32:49.110
which is like a digital
fingerprint of sorts,

00:32:49.110 --> 00:32:52.400
against which later comparisons
can be made for errors.

00:32:52.400 --> 00:32:58.050
And so the MP3 was
hosted at SoundCloud.

00:32:58.050 --> 00:33:00.940
And StoryCorps wasn't sure
if SoundCloud would be cool

00:33:00.940 --> 00:33:02.910
with adding that; but they
were, after a little bit

00:33:02.910 --> 00:33:06.740 position:56%
of back-and-forth, happy to do that
for us so that made it a lot better.

00:33:06.740 --> 00:33:09.580
So then decisions had to
be made like, you know,

00:33:09.580 --> 00:33:12.910
what about the associated metadata?

00:33:12.910 --> 00:33:14.210
Do we care about likes?

00:33:14.210 --> 00:33:17.930
Do we care about descriptive tags?

00:33:17.930 --> 00:33:23.210
You know, we decided likes
were too fluid, and a snapshot

00:33:23.210 --> 00:33:26.410
at an arbitrary point in time
seemed a little bit meaningless.

00:33:26.410 --> 00:33:29.230
But we certainly thought tags
were incredibly important

00:33:29.230 --> 00:33:33.090
across metadata, rocking and all.

00:33:33.090 --> 00:33:38.440
So anyway, once developers were
happy with the general design

00:33:38.440 --> 00:33:41.820
of the transfer mechanism, then
both parties began to iterate.

00:33:41.820 --> 00:33:49.640
And StoryCorps on the API side, and
the Library on the fetching side.

00:33:49.640 --> 00:33:53.800
And I will blow through
a few technical details.

00:33:53.800 --> 00:33:56.560
Anyway, there were two
-- so in doing this work,

00:33:56.560 --> 00:34:00.180
just to jump to the two big classes
of errors that we were trying

00:34:00.180 --> 00:34:03.730
to protect against
were one, a single file

00:34:03.730 --> 00:34:08.440
or a tape gets destroyed, in which
case the checksum will reveal this.

00:34:08.440 --> 00:34:12.310
And then the second class of
error would be losing access

00:34:12.310 --> 00:34:15.890 position:56%
to a collection through correlated
errors, which is a class of mistakes

00:34:15.890 --> 00:34:20.350
where somebody follows a bad
practice or relied upon bad code;

00:34:20.350 --> 00:34:24.590
in that case an inventory can help
identify those kinds of things.

00:34:24.590 --> 00:34:28.570
And then they can make a copy.

00:34:28.570 --> 00:34:33.050
Okay, so this is how the
development is going.

00:34:33.050 --> 00:34:36.250
You -- the -- I'll just move ahead.

00:34:36.250 --> 00:34:41.360
Alright, well, so in
closing, you know,

00:34:41.360 --> 00:34:45.300
these projects have enabled
AFC to engage a broad public

00:34:45.300 --> 00:34:48.530
to collaboratively build its
collections as it's always done.

00:34:48.530 --> 00:34:53.250
And we're able to do so in
an automated way and in a way

00:34:53.250 --> 00:34:57.650
that bakes in sound preservation
practices, which we love.

00:34:57.650 --> 00:35:01.340
And if there's time to
play a 1-1/2 minute clip?

00:35:01.340 --> 00:35:07.740 position:56%
Okay. I'd like to close with this
clip from a StoryCorps.me interview.

00:35:07.740 --> 00:35:11.190
And I want to say that, you know,
this is a tremendous corpus,

00:35:11.190 --> 00:35:13.370 position:56%
a research corpus, these interviews.

00:35:13.370 --> 00:35:16.530
And they do get dinged sometimes
for being overtly sentimental,

00:35:16.530 --> 00:35:18.200
the stuff you hear on Friday.

00:35:18.200 --> 00:35:22.560
And this is no exception, so enjoy.

00:35:22.560 --> 00:35:25.510
But I'll leave you with this.

00:35:25.510 --> 00:35:35.250
[ Silence ]

00:35:35.250 --> 00:35:37.080
&gt;&gt; Well, this last question
basically just says,

00:35:37.080 --> 00:35:40.170
take time to tell your interview
partner what they mean to you.

00:35:40.170 --> 00:35:42.500 position:56%
And so I'm going to say that to you.

00:35:42.500 --> 00:35:45.740
I absolutely adore you.

00:35:45.740 --> 00:35:56.220
You're easily the best thing
that's ever happened to me

00:35:56.220 --> 00:35:57.590
in any way, shape, or form.

00:35:57.590 --> 00:36:01.910
While, like you said earlier,
there's so many things

00:36:01.910 --> 00:36:08.140
that we may still be unsure about
with our future, I can at least say

00:36:08.140 --> 00:36:10.890
that I know I want you in it.

00:36:10.890 --> 00:36:15.200
So, in the home that
we've built together,

00:36:15.200 --> 00:36:26.360 position:56%
in the life that we've made together
with each other, and in the family

00:36:26.360 --> 00:36:33.220
that we've started with our little
furry prince here, Asia, Colleen,

00:36:33.220 --> 00:36:37.540
Annette, Adcock, will you do me the
great honor, and will you marry me?

00:36:37.540 --> 00:36:40.210
&gt;&gt; Yes. Of course, I will, stupid.

00:36:40.210 --> 00:36:41.510
[Laughter].

00:36:41.510 --> 00:36:44.480
&gt;&gt; What better way than to talk
about all the wonderful things

00:36:44.480 --> 00:36:46.290
that we've done in our life so far.

00:36:46.290 --> 00:36:49.230
And then just think
about the great things,

00:36:49.230 --> 00:36:52.380
what's going to happen
in the future.

00:36:52.380 --> 00:36:53.820
&gt;&gt; Oh, gosh, you're so amazing.

00:36:53.820 --> 00:36:58.150
&gt;&gt; And I don't know if you --
I didn't tell you this yet,

00:36:58.150 --> 00:37:03.190
but this could also be saved in
the Library of Congress's archives.

00:37:03.190 --> 00:37:08.060
Forever. So that everyone
can listen to this.

00:37:08.060 --> 00:37:09.360
&gt;&gt; So happy.

00:37:09.360 --> 00:37:10.660
&gt;&gt; I love you so much.

00:37:10.660 --> 00:37:11.960
&gt;&gt; I love you too.

00:37:11.960 --> 00:37:17.220
&gt;&gt; This has been my
interview/surprise proposal

00:37:17.220 --> 00:37:22.790
to my wonderful girlfriend,
and now fiancee, Asia.

00:37:22.790 --> 00:37:25.840
I'm Rory T. Miller, now the
happiest man in the world.

00:37:25.840 --> 00:37:27.430
&gt;&gt; Thank you.

00:37:27.430 --> 00:37:29.230
&gt;&gt; Nicole Saylor: Thank you.

00:37:29.230 --> 00:37:47.040
[ Applause ]

00:37:47.040 --> 00:37:49.520 position:56%
&gt;&gt;Maciej Ceglowski: I have never had
a simultaneous translator before.

00:37:49.520 --> 00:37:54.060
So let me begin by saying to all
of you: pumpernickel, flapjack,

00:37:54.060 --> 00:37:58.300
chandelier, riboflavin, hockey
puck, calzone, moose antlers.

00:37:58.300 --> 00:38:00.910
I owe you a drink.

00:38:00.910 --> 00:38:03.160
My name is Maciej Ceglowski.

00:38:03.160 --> 00:38:06.570
I run a little web archive
for about 20,000 people.

00:38:06.570 --> 00:38:09.270
So to be invited to the Library
of Congress is like being a kid

00:38:09.270 --> 00:38:12.720
who glued some fins to a
cardboard tube and was invited

00:38:12.720 --> 00:38:14.900
to tell NASA about
rocket propulsion.

00:38:14.900 --> 00:38:17.400
Like every speaker
has correctly said,

00:38:17.400 --> 00:38:19.530
it is a signal honor to be here.

00:38:19.530 --> 00:38:23.330
It feels especially strange to
me because I'm used to talking

00:38:23.330 --> 00:38:27.530
about the U.S. Government
as a big, scary adversary.

00:38:27.530 --> 00:38:30.860
But here I am in a Government
institution that, despite the fact

00:38:30.860 --> 00:38:33.250
that we all went through a
metal detector to sit here,

00:38:33.250 --> 00:38:37.320
champions not just freedom but
the fundamental right to privacy,

00:38:37.320 --> 00:38:39.780
and the dignity that that entails.

00:38:39.780 --> 00:38:42.870
During the panic that followed
September 11th, Carla Hayden,

00:38:42.870 --> 00:38:45.360
who was then Head of the
American Library Association,

00:38:45.360 --> 00:38:48.460
took a principled stand against
provisions in the Patriot Act

00:38:48.460 --> 00:38:52.650
that required libraries to divulge
what their patrons were reading.

00:38:52.650 --> 00:38:53.950 position:56%
She did this in the face of ridicule

00:38:53.950 --> 00:38:56.350
from the Attorney General
and the Administration.

00:38:56.350 --> 00:38:58.440
And of course now she is
the Librarian of Congress;

00:38:58.440 --> 00:39:00.180
so what a wonderful institution.

00:39:00.180 --> 00:39:03.840
So it's particularly sad -- feel
free to applaud about that --

00:39:03.840 --> 00:39:05.760
that [Applause] --
yes, what a woman!

00:39:05.760 --> 00:39:12.030
So for me it is depressing to think
that those provisions that seemed

00:39:12.030 --> 00:39:15.720
so threatening and un-American look
almost quaint now when compared

00:39:15.720 --> 00:39:17.020
to what we have done

00:39:17.020 --> 00:39:18.360
in the commercial internet
to destroy privacy.

00:39:18.360 --> 00:39:23.030
You know, libraries have a
commitment to protect information

00:39:23.030 --> 00:39:24.450
about what their patrons
are reading.

00:39:24.450 --> 00:39:26.200
But Amazon knows every
book that you've read,

00:39:26.200 --> 00:39:28.940
if it's electronic they
know it down to the page.

00:39:28.940 --> 00:39:31.170
Google has your correspondence,
your web history.

00:39:31.170 --> 00:39:34.030
Your phone company knows where you
are and where you've been based

00:39:34.030 --> 00:39:36.420
on a device you voluntarily
carry with you.

00:39:36.420 --> 00:39:39.300
We all know the depressing litany.

00:39:39.300 --> 00:39:43.560
And in some ways the commercial
internet is the opposite

00:39:43.560 --> 00:39:44.900
of a library.

00:39:44.900 --> 00:39:46.770
You know, the libraries
exist to inform.

00:39:46.770 --> 00:39:48.380
The commercial internet
is there to extract

00:39:48.380 --> 00:39:50.400
as much information as possible.

00:39:50.400 --> 00:39:53.720
There's no ulterior motives in
a library that I know about.

00:39:53.720 --> 00:39:57.520
But when you're online, there's an
ulterior motive behind every link;

00:39:57.520 --> 00:39:59.690
every click is there so
that you share something

00:39:59.690 --> 00:40:04.210
or click something else, or stay on
the page, pay attention to an app.

00:40:04.210 --> 00:40:06.250
But these un-librarians

00:40:06.250 --> 00:40:09.140
that I unfortunately represent
have made enormous advances

00:40:09.140 --> 00:40:10.530
in technology.

00:40:10.530 --> 00:40:13.930
And I'm here today to talk to
you about machine learning.

00:40:13.930 --> 00:40:16.500
I want you to hear it
from me rather than out

00:40:16.500 --> 00:40:18.700
on the street or from your friends.

00:40:18.700 --> 00:40:23.030
Because I've come to think that
these machine learning techniques

00:40:23.030 --> 00:40:27.700
that are amazing are kind
of like a deep fat fryer.

00:40:27.700 --> 00:40:30.910
If you have never deep fried
something in your life,

00:40:30.910 --> 00:40:33.730
it's life-changing; you
taste it, it's amazing.

00:40:33.730 --> 00:40:37.290
And then you start to think,
this would work with anything.

00:40:37.290 --> 00:40:42.490
And you're kind of right; it does.

00:40:42.490 --> 00:40:44.860 position:56%
Like in my college days I had
friends who worked at the snack bar,

00:40:44.860 --> 00:40:46.870
and they conducted lots of
research along these lines.

00:40:46.870 --> 00:40:50.540
They would deep fry cheese,
candy, pens, name tags.

00:40:50.540 --> 00:40:52.330
And it all came out
tasting pretty good.

00:40:52.330 --> 00:40:55.990 position:56%
And then as you know, if you subsist
on it like you do in college,

00:40:55.990 --> 00:40:59.840
it kind of gives you a
little bit of a hangover.

00:40:59.840 --> 00:41:04.410
In our case the deep fryer is this
tool box of statistical techniques.

00:41:04.410 --> 00:41:05.740
The names keep changing.

00:41:05.740 --> 00:41:08.520
It used to be unsupervised
learning; now it's called big data

00:41:08.520 --> 00:41:10.750
or deep learning, AI,
machine learning.

00:41:10.750 --> 00:41:12.210
Next year there's going
to be a new buzz word.

00:41:12.210 --> 00:41:14.240
But the core ideas don't change.

00:41:14.240 --> 00:41:15.640 position:56%
You feed your computer lots of data,

00:41:15.640 --> 00:41:18.290
and it learns how to
recognize structure.

00:41:18.290 --> 00:41:21.740
Now, in any deep frying situation
you want to ask yourself,

00:41:21.740 --> 00:41:23.820
what is the stuff being fried in?

00:41:23.820 --> 00:41:28.890
In Poland in the '70s, where I'm
from, there was a crafty person

00:41:28.890 --> 00:41:31.460
who bought a high pressured
deep fryer from Italy,

00:41:31.460 --> 00:41:34.430
and they brought it to a
resort town in the mountains.

00:41:34.430 --> 00:41:35.760
They called it the
frytkopollo [Assumed].

00:41:35.760 --> 00:41:37.790
And people would stand
in line for blocks;

00:41:37.790 --> 00:41:40.110
you had to bring your own chicken
because this was under Communism.

00:41:40.110 --> 00:41:41.410 position:56%
But if you brought your own chicken,

00:41:41.410 --> 00:41:43.610
in three minutes it would be high
pressure deep friend and returned

00:41:43.610 --> 00:41:47.070
to you as the most delicious, hot,
tasty thing you had ever eaten.

00:41:47.070 --> 00:41:49.900
And this was a huge fad until
the Health Department came

00:41:49.900 --> 00:41:51.200
and closed it down.

00:41:51.200 --> 00:41:52.500
At which point it was revealed

00:41:52.500 --> 00:41:54.530
that the frytkopollo machine
had never been cleaned.

00:41:54.530 --> 00:41:57.580
And what the stuff inside
it was basically black tar,

00:41:57.580 --> 00:41:59.950
and that's where the flavor
secret of the frytkopollo.

00:41:59.950 --> 00:42:04.410
So what is your data
getting fried in, right?

00:42:04.410 --> 00:42:06.900
These algorithms train
on very large collections

00:42:06.900 --> 00:42:08.540
that you don't know anything about.

00:42:08.540 --> 00:42:11.380
And sites like Google operate on
scales hundreds of times bigger

00:42:11.380 --> 00:42:13.730
than what we're familiar
with in the humanities.

00:42:13.730 --> 00:42:17.680
For this reason, I've
referred to machine learning

00:42:17.680 --> 00:42:19.850
as money laundering for bias.

00:42:19.850 --> 00:42:21.340
Because you can smuggle in a lot

00:42:21.340 --> 00:42:23.800
of preconceptions based
on how you train.

00:42:23.800 --> 00:42:28.070
So for example, if you go to
Google Translate and you plug

00:42:28.070 --> 00:42:30.970
in an Arabic article about
something horrible in Syria,

00:42:30.970 --> 00:42:33.670
or an opinion piece on terrorism,
you get something in English

00:42:33.670 --> 00:42:36.130
that looks like it's
written by a native speaker.

00:42:36.130 --> 00:42:40.330
But if you put in Arabic a kid's
letter home from camp, say,

00:42:40.330 --> 00:42:42.700
or a passage from a novel,
it looks like it was written

00:42:42.700 --> 00:42:44.300
by the Frankenstein monster.

00:42:44.300 --> 00:42:46.940
The algorithm just can't
handle it and doesn't know.

00:42:46.940 --> 00:42:49.190
And it's not because the
algorithm's obsessed with war

00:42:49.190 --> 00:42:52.900
and things military, that's just
what it was trained on to do.

00:42:52.900 --> 00:42:56.400
I'm sure other languages
have other idiosyncrasies.

00:42:56.400 --> 00:42:57.930 position:56%
It's not always a problem; some uses

00:42:57.930 --> 00:42:59.970
of machine learning are
benign and wonderful.

00:42:59.970 --> 00:43:01.680
If you do optical character
recognition,

00:43:01.680 --> 00:43:04.510
you benefit from a
lot of these advances.

00:43:04.510 --> 00:43:06.750
But others are problematic.

00:43:06.750 --> 00:43:09.300
I would be very wary of
using sentiment analysis,

00:43:09.300 --> 00:43:11.140
for example, on any collection.

00:43:11.140 --> 00:43:14.720
Or anything to do with social
networks without careful thought

00:43:14.720 --> 00:43:16.940
as to where it had trained.

00:43:16.940 --> 00:43:19.250
I find it helpful to think
of algorithms as a dim-witted

00:43:19.250 --> 00:43:23.280
but extremely industrious graduate
student who you don't fully trust.

00:43:23.280 --> 00:43:26.720
So if you want a concordance or
an index or you want them to go

00:43:26.720 --> 00:43:28.350
through ten million
photos and tell you

00:43:28.350 --> 00:43:31.030
where there are horses,
then that's perfect.

00:43:31.030 --> 00:43:33.530
But if you want them to draw
conclusions on gender based

00:43:33.530 --> 00:43:36.610
on word use patterns, or if you
want to do social network analysis

00:43:36.610 --> 00:43:39.870
on census data, then you
want some adult supervision

00:43:39.870 --> 00:43:41.930
in the room when they're active.

00:43:41.930 --> 00:43:44.800
But besides these issues of bias,

00:43:44.800 --> 00:43:47.180
it's really the opportunity
cost that irks me.

00:43:47.180 --> 00:43:49.900
This love affair with computational
techniques removes a lot

00:43:49.900 --> 00:43:52.000
of the potential for
surprise that comes

00:43:52.000 --> 00:43:54.020
when you deal with actual people.

00:43:54.020 --> 00:43:55.820
Because if you go searching
for patterns in your data,

00:43:55.820 --> 00:43:57.350
you're going to find
patterns in your data.

00:43:57.350 --> 00:43:59.360
You know, woo-hoo, right?

00:43:59.360 --> 00:44:02.460
What gets lost in that
data is what's fresh

00:44:02.460 --> 00:44:04.490
and really interesting
and different.

00:44:04.490 --> 00:44:06.480
And we've seen entire
fields disappear

00:44:06.480 --> 00:44:08.110
down the numerical rabbit hole.

00:44:08.110 --> 00:44:10.450
Economics came first, Sociology

00:44:10.450 --> 00:44:12.780
and Political Science are
still trying to get out.

00:44:12.780 --> 00:44:14.450
Bioinformatics is down
there somewhere

00:44:14.450 --> 00:44:16.170
and has not been heard
from in a while.

00:44:16.170 --> 00:44:21.350
In my eyes, the excitement is not
in the computational possibilities.

00:44:21.350 --> 00:44:23.680
The computers are a tool, and
they eliminate some drudgery

00:44:23.680 --> 00:44:24.980
and it's fun.

00:44:24.980 --> 00:44:26.330
And deep fry some things;
it's tasty.

00:44:26.330 --> 00:44:29.340
But the real excitement
is in human potential.

00:44:29.340 --> 00:44:31.330
Because for the first time
we can make things available

00:44:31.330 --> 00:44:32.700
to anyone on the planet.

00:44:32.700 --> 00:44:37.050 position:56%
And I don't think we've internalized
the enormity of that stat.

00:44:37.050 --> 00:44:41.160
Now, as you all know, just throwing
the data online is not the answer.

00:44:41.160 --> 00:44:44.390
When I was a -- I'm laughing

00:44:44.390 --> 00:44:46.690
because the Andrew Mellon
Foundation once hired me

00:44:46.690 --> 00:44:49.520
as a program officer;
that was crazy of them.

00:44:49.520 --> 00:44:52.250
But when I was a program
officer at the Mellon Foundation,

00:44:52.250 --> 00:44:54.370 position:56%
I remember working with early JSTOR.

00:44:54.370 --> 00:44:59.240
And finding out that 50% of
JSTOR records had never appeared

00:44:59.240 --> 00:45:00.720
in a search results page.

00:45:00.720 --> 00:45:02.980
So not only had no one read
them, no one had even seen them;

00:45:02.980 --> 00:45:04.880
they might as well not
have been digitized.

00:45:04.880 --> 00:45:08.920
Part of that was because of
extremely restrictive agreements

00:45:08.920 --> 00:45:10.220
with publishers.

00:45:10.220 --> 00:45:12.020
But part of it was a
failure of imagination.

00:45:12.020 --> 00:45:14.980
Here you have every journal article
under the sun, and no attempt

00:45:14.980 --> 00:45:17.410
to connect it to people
outside of the academy.

00:45:17.410 --> 00:45:22.560
For the same reason, we completely
flubbed Wikipedia at Mellon.

00:45:22.560 --> 00:45:24.740
Nobody could imagine that
the effort would succeed.

00:45:24.740 --> 00:45:28.590
I remember my boss went as far as
exploring whether to print a copy

00:45:28.590 --> 00:45:34.250
of it and have it published that
way, but that's where we stalled.

00:45:34.250 --> 00:45:38.480
And then later, after leaving
Mellon, I saw librarians fail

00:45:38.480 --> 00:45:41.090
to engage with some vibrant
communities at Flickr

00:45:41.090 --> 00:45:42.390
and Delicious in early days.

00:45:42.390 --> 00:45:47.360
Services that they
later grew to love.

00:45:47.360 --> 00:45:51.420
Basically because of a lack of
trust and openness to an experiment

00:45:51.420 --> 00:45:53.540
around unstructured tagging.

00:45:53.540 --> 00:45:58.520
When we talk about data, a lot
of our language is extractive.

00:45:58.520 --> 00:46:02.580
You talk about data flows,
data mining, data crunching;

00:46:02.580 --> 00:46:06.280 position:56%
it's like a rocky substance that you
have to smash to get the jewels out.

00:46:06.280 --> 00:46:08.550
I like that.

00:46:08.550 --> 00:46:10.260
But in cultivating communities,

00:46:10.260 --> 00:46:12.390
I prefer to think of
a gardening metaphor.

00:46:12.390 --> 00:46:15.520
You need the right conditions,
a propitious climate,

00:46:15.520 --> 00:46:18.230
and a judicious sprinkling
of bullshit.

00:46:18.230 --> 00:46:21.360
But it also requires some
patience and weeding and tending.

00:46:21.360 --> 00:46:25.190
And the ability to accept that you
don't know exactly what is going

00:46:25.190 --> 00:46:26.490
to grow.

00:46:26.490 --> 00:46:27.790
If we take seriously the idea

00:46:27.790 --> 00:46:30.340
that digitizing collections
makes them more accessible,

00:46:30.340 --> 00:46:33.470
then we have to accept that the
kinds of people and activities

00:46:33.470 --> 00:46:36.260
that those collections attract
are going to seem odd to us.

00:46:36.260 --> 00:46:38.260
We have to give up that control.

00:46:38.260 --> 00:46:39.680
It should make perfect sense,

00:46:39.680 --> 00:46:42.160
because human cultures
are famously diverse.

00:46:42.160 --> 00:46:45.450
It's normal that there's different
kinds of music and food and dance;

00:46:45.450 --> 00:46:47.020
we enjoy these differences.

00:46:47.020 --> 00:46:49.430
Unless you're a Silicon Valley
nerd, you delight in the fact

00:46:49.430 --> 00:46:51.340
that there are hundreds of
different kinds of cuisine rather

00:46:51.340 --> 00:46:54.560
than a single beige slurry that
gives you all your nutrition.

00:46:54.560 --> 00:46:57.770
But when we go online,
our horizons narrow.

00:46:57.770 --> 00:46:59.250
We expect that domain experts

00:46:59.250 --> 00:47:02.070
and programmers can meet
everyone's needs anywhere.

00:47:02.070 --> 00:47:04.010
We think it's normal to
build a social network

00:47:04.010 --> 00:47:06.170
for seven billion people.

00:47:06.170 --> 00:47:08.680
I call this the Mormon
bartender problem.

00:47:08.680 --> 00:47:10.310
When you try to make things

00:47:10.310 --> 00:47:14.200
for people while lacking the
visceral experience of their lives,

00:47:14.200 --> 00:47:16.850
imagining that you can just
think your way through it.

00:47:16.850 --> 00:47:19.320
I'll give you an example
from my own website.

00:47:19.320 --> 00:47:21.290
I run the Very Vanilla
Bookmark Archive,

00:47:21.290 --> 00:47:23.610
where people save URL's for later.

00:47:23.610 --> 00:47:26.560
So it's a search engine
for scholars, journalists.

00:47:26.560 --> 00:47:29.030
I even have a priest who
researches his sermons

00:47:29.030 --> 00:47:30.810
on it, which I'm happy about.

00:47:30.810 --> 00:47:32.140
But one of the biggest
groups of users

00:47:32.140 --> 00:47:34.640
on my site are writers
of FanFiction.

00:47:34.640 --> 00:47:37.230
I'll explain what FanFiction
is because you're all going

00:47:37.230 --> 00:47:38.530
to pretend you don't know --

00:47:38.530 --> 00:47:41.650
even though I know all the
librarians here are avid writers

00:47:41.650 --> 00:47:42.950
of it.

00:47:42.950 --> 00:47:45.090
So this is a vibrant subculture
of people who write stories,

00:47:45.090 --> 00:47:48.860
often highly erotic, that are set
in various fictional universes.

00:47:48.860 --> 00:47:51.000
If you always thought that
there were sparks between Holmes

00:47:51.000 --> 00:47:53.480
and Watson, this is
the subculture for you,

00:47:53.480 --> 00:47:55.690
and I encourage you
to come explore it.

00:47:55.690 --> 00:47:58.740
So FanFic authors came to my
site, adopted the tagging system,

00:47:58.740 --> 00:48:01.230
and to them it's a search
engine and publication tool,

00:48:01.230 --> 00:48:04.350
it's not an archive at all in
the sense that I intended it.

00:48:04.350 --> 00:48:06.350
And they do a lot of
additional technical work

00:48:06.350 --> 00:48:08.270
to make it suit their needs.

00:48:08.270 --> 00:48:11.010
For me, it was like watching bees
arrive in your garden and set

00:48:11.010 --> 00:48:13.840
up a hive and, you know,
make honeycombs and honey.

00:48:13.840 --> 00:48:16.150
You just observe and wonder
and hope you don't get stung.

00:48:16.150 --> 00:48:20.180
It was really a wonderful
experience.

00:48:20.180 --> 00:48:21.480
But it made me think,
the internet has

00:48:21.480 --> 00:48:24.190
to get a lot, lot weirder
than it is.

00:48:24.190 --> 00:48:25.680
People out there are also tired

00:48:25.680 --> 00:48:28.860
of this deep-fried data
flavor, and they want substance.

00:48:28.860 --> 00:48:32.630
They do interesting things, but
you have to trust them first.

00:48:32.630 --> 00:48:35.340
In an institutional setting,
this can be frightening.

00:48:35.340 --> 00:48:38.260
It takes courage to ask for a
grant to bring a collection online

00:48:38.260 --> 00:48:40.230
when you have no measurable
outcomes other than the hope

00:48:40.230 --> 00:48:42.250
that it will attract
something interesting.

00:48:42.250 --> 00:48:45.070
It takes even more courage
to award such a grant.

00:48:45.070 --> 00:48:48.160 position:56%
It takes courage for a young faculty
member to devote time and energy

00:48:48.160 --> 00:48:52.290
into projects that someone
might use to make a cat video.

00:48:52.290 --> 00:48:54.770
I realize that that is not,
you know, the royal road

00:48:54.770 --> 00:48:56.450
to tenure in most institutions.

00:48:56.450 --> 00:49:00.180
And it takes courage to commit
to maintaining those collections

00:49:00.180 --> 00:49:02.990
for a long time, and
for staying engaged

00:49:02.990 --> 00:49:04.420
with the people who use them.

00:49:04.420 --> 00:49:08.050
But the search for intelligent
life on the internet means you have

00:49:08.050 --> 00:49:09.350
to put away some preconceptions

00:49:09.350 --> 00:49:10.980
about who your communities
of use are.

00:49:10.980 --> 00:49:14.030
Now, I thought the FanFic authors

00:49:14.030 --> 00:49:17.070
on my site were just pursuing
a harmless quirky hobby.

00:49:17.070 --> 00:49:21.280
What I didn't realize is that
online the frivolous blends easily

00:49:21.280 --> 00:49:23.270
with the serious.

00:49:23.270 --> 00:49:25.310
FanFic authors tend to be women.

00:49:25.310 --> 00:49:29.880
Britta Gustafson has call Fandom
a secret seminar on feminism.

00:49:29.880 --> 00:49:32.720
Young Fans use stories to
explore issues of gender identity,

00:49:32.720 --> 00:49:35.610
and in some cases they
use Fandom to discover

00:49:35.610 --> 00:49:37.850 position:56%
that there's something called
gender identity that they're allowed

00:49:37.850 --> 00:49:40.300
to have and think about
and question.

00:49:40.300 --> 00:49:43.160
And they do it through the medium
of something they genuinely enjoy.

00:49:43.160 --> 00:49:46.980
They learn to deconstruct plot
elements in writing in a way

00:49:46.980 --> 00:49:49.890
that would make a Russian
structuralist critic blush.

00:49:49.890 --> 00:49:52.040
They coach each other
in writing better;

00:49:52.040 --> 00:49:54.300 position:56%
they coach each other in technology.

00:49:54.300 --> 00:49:58.670
Because serious people enjoy
frivolous things and they mix

00:49:58.670 --> 00:50:01.480
and mingle with young people at
the same time, it becomes a sort

00:50:01.480 --> 00:50:05.230
of secret educational system
that works in surprising ways.

00:50:05.230 --> 00:50:08.040
My friend, Sasha Judd, who in
an upcoming talk will describe

00:50:08.040 --> 00:50:11.170
something similar with fans of
the boy band, One Direction.

00:50:11.170 --> 00:50:14.290
The band has an obsessive
following, again of young women.

00:50:14.290 --> 00:50:16.670
And in chronicling the lives
of these beloved band members,

00:50:16.670 --> 00:50:18.730
they reach heights of
technical achievement

00:50:18.730 --> 00:50:20.480
that media companies can't get to.

00:50:20.480 --> 00:50:24.450
They are de facto professional
archivists, developers,

00:50:24.450 --> 00:50:26.860
video editors, and journalists.

00:50:26.860 --> 00:50:28.300
But they don't think
of themselves that way.

00:50:28.300 --> 00:50:31.590
And to "real technologists,"

00:50:31.590 --> 00:50:34.590
these interests aren't
serious, so they don't matter.

00:50:34.590 --> 00:50:37.720
So these women would never
dream of applying to jobs

00:50:37.720 --> 00:50:39.450
that they're already
effectively doing.

00:50:39.450 --> 00:50:42.370
I think of this as like a dark
matter of talented, motivated,

00:50:42.370 --> 00:50:44.590
and interested people online
who just aren't connected.

00:50:44.590 --> 00:50:48.790
And I'm convinced our time is much
better spent trying to reach them

00:50:48.790 --> 00:50:53.470
and engage them than playing
with the same algorithmic toys.

00:50:53.470 --> 00:50:58.120
I've talked a bit about
bringing collections online

00:50:58.120 --> 00:50:59.700
and making them accessible.

00:50:59.700 --> 00:51:01.540
There's also the question of how
to deal with the flood of stuff

00:51:01.540 --> 00:51:04.320
that is already on the
internet and coming from it.

00:51:04.320 --> 00:51:07.330
One approach is to go to people
who have control of the data,

00:51:07.330 --> 00:51:10.650
the big companies, and
partner with them to study it.

00:51:10.650 --> 00:51:12.370
I think that this is awkward,
though, because the very thing

00:51:12.370 --> 00:51:15.160
that the Librarian of Congress
objected to in the Patriot Act,

00:51:15.160 --> 00:51:18.260
this intrusive constant
surveillance, is the bread

00:51:18.260 --> 00:51:20.680
and butter of online services.

00:51:20.680 --> 00:51:23.140
Much of the valuable
information is collected in ways

00:51:23.140 --> 00:51:25.720
that would never pass
ethical standards in academia,

00:51:25.720 --> 00:51:29.460
in ways that even the NSA would
be constrained by law from using.

00:51:29.460 --> 00:51:31.750
But the data is there.

00:51:31.750 --> 00:51:33.730
There are no laws that
constrict us --

00:51:33.730 --> 00:51:36.190
constrain us from collecting
it however we want.

00:51:36.190 --> 00:51:39.300
And I know that you can hear
that data calling to you.

00:51:39.300 --> 00:51:41.380
It's saying, study me.

00:51:41.380 --> 00:51:42.790
Preserve me.

00:51:42.790 --> 00:51:44.090
These fly-by-night companies,

00:51:44.090 --> 00:51:47.590
they're going to lose
me, analyze me.

00:51:47.590 --> 00:51:51.970 position:56%
You can try to add layers of ethical
paint to this conundrum and say

00:51:51.970 --> 00:51:53.410
that you're really helping.

00:51:53.410 --> 00:51:56.400
But I worry about legitimizing
a culture

00:51:56.400 --> 00:51:58.300 position:56%
of universal surveillance like this.

00:51:58.300 --> 00:52:00.680
I'm very uneasy when I see
social scientists working

00:52:00.680 --> 00:52:02.810
with Facebook, for example.

00:52:02.810 --> 00:52:04.110
You know, people are pragmatic.

00:52:04.110 --> 00:52:06.680
In the absence of meaningful
privacy protections, their approach

00:52:06.680 --> 00:52:09.490
to privacy has become
click okay and pray.

00:52:09.490 --> 00:52:12.390
Every once in a while there's a
big hack that shakes everybody up.

00:52:12.390 --> 00:52:15.790
But since we have yet to see
a really big tragic misuse

00:52:15.790 --> 00:52:19.930
of personal information, we're just
kind of hoping it doesn't happen.

00:52:19.930 --> 00:52:22.850
But remember, we live in a time
when this spiritual successor

00:52:22.850 --> 00:52:27.170
to fascism is on the ascendant
in a lot of Western democracies.

00:52:27.170 --> 00:52:31.040 position:56%
Having large unregulated collections
of private information harvested

00:52:31.040 --> 00:52:34.460
from people -- often without their
knowledge -- is just dangerous.

00:52:34.460 --> 00:52:36.910
Don't legitimize it.

00:52:36.910 --> 00:52:40.270
People face social pressures
to abandon their privacy.

00:52:40.270 --> 00:52:43.190
Being on social media has become
an expected part of getting a job

00:52:43.190 --> 00:52:44.490
or an apartment in places.

00:52:44.490 --> 00:52:47.560
Now the border patrol wants to
look at your social media data.

00:52:47.560 --> 00:52:49.210
So when you work with
online behemoths,

00:52:49.210 --> 00:52:52.470
realize that the behavioral
information is not consensual,

00:52:52.470 --> 00:52:54.210
and there can't be
consent to this kind

00:52:54.210 --> 00:52:56.880
of mass surveillance;
it's an illusion.

00:52:58.850 --> 00:53:02.440
I want to talk momentarily
about my bread and butter,

00:53:02.440 --> 00:53:05.000
which is actually collecting
websites.

00:53:05.000 --> 00:53:07.790
I hope you'll forgive me for being
technical in this part of the talk,

00:53:07.790 --> 00:53:12.540 position:56%
but the average web page right now
is a giant pile of steaming garbage.

00:53:12.540 --> 00:53:16.810
I don't mean the content, but
I mean the way it's structured

00:53:16.810 --> 00:53:18.110
and fits together.

00:53:18.110 --> 00:53:21.720
So everything is a Frankenstein
monster of dependencies

00:53:21.720 --> 00:53:24.700
and Java scripts and things
pulled in at display time.

00:53:24.700 --> 00:53:26.690
And what does it mean
to archive this?

00:53:26.690 --> 00:53:28.170
These steaming piles of garbage?

00:53:28.170 --> 00:53:30.420
You can save the rendered
image in the browser,

00:53:30.420 --> 00:53:32.830
but then you forego all the
dynamic behaviors it might have.

00:53:32.830 --> 00:53:36.280
You know, is a dynamic out
on a page just an annoyance?

00:53:36.280 --> 00:53:39.740
Or is it a valuable
window on life in 2016?

00:53:39.740 --> 00:53:42.120
And if it is, then which of the
ads are we supposed archive?

00:53:42.120 --> 00:53:44.010 position:56%
And, you know, how do we pull it in?

00:53:44.010 --> 00:53:47.270
And who should it be targeted to?

00:53:47.270 --> 00:53:53.040
You know, you end up in a situation
where you have to build a simulator

00:53:53.040 --> 00:53:55.490
of the entire computing
environment of today.

00:53:55.490 --> 00:53:57.830 position:56%
And I don't think future generations
will forgive us for doing that;

00:53:57.830 --> 00:54:00.600
it's bad enough to
live through it now.

00:54:00.600 --> 00:54:03.370
Game developers have already
wrestled through this program.

00:54:03.370 --> 00:54:06.280
They have stuff that we can
learn from, because they've tried

00:54:06.280 --> 00:54:09.130
to emulate video games
including classic ones that turn

00:54:09.130 --> 00:54:11.980
out to be surprisingly hard; they
were implemented in hardware.

00:54:11.980 --> 00:54:14.140
But the reason these game
developers are able to do it is

00:54:14.140 --> 00:54:16.490
because they're also passionate
about playing those games

00:54:16.490 --> 00:54:19.320
and continuing to have them and
teaching them to their kids.

00:54:19.320 --> 00:54:24.130
So once again communities pop
up as kind of a life saver.

00:54:24.130 --> 00:54:26.030
One problem that an
institution like the Library

00:54:26.030 --> 00:54:28.460
of Congress faces is you
can't just kind of, you know,

00:54:28.460 --> 00:54:30.130
roll up your sleeves and
go in there willy-nilly

00:54:30.130 --> 00:54:31.750
and say we'll archive
however we can,

00:54:31.750 --> 00:54:34.180
because what you do would
be considered normative.

00:54:34.180 --> 00:54:35.570
And then everybody
will follow the lead.

00:54:35.570 --> 00:54:37.390
So I understand it's
a dicey problem.

00:54:37.390 --> 00:54:39.590
But communities can help us.

00:54:39.590 --> 00:54:42.480
An example from LiveJournal
might help.

00:54:42.480 --> 00:54:45.760
So LiveJournal is an early blog
site that was very popular.

00:54:45.760 --> 00:54:47.060
One of the features it had was

00:54:47.060 --> 00:54:50.190
for every post you could have
a little thumbnail-type image.

00:54:50.190 --> 00:54:54.910
And what began happening is, people
would use those images as a sort

00:54:54.910 --> 00:54:57.110
of gloss on the post;
they would kind of riff

00:54:57.110 --> 00:54:59.750
against what they had written
with their choice of thumbnails.

00:54:59.750 --> 00:55:02.430
So some people would have hundreds
or thousands of these images.

00:55:02.430 --> 00:55:06.800
And it became a sort of art for how
to do commentary the silent way.

00:55:06.800 --> 00:55:10.950
LiveJournal, totally unaware of
this, imposed a limit of 16 images,

00:55:10.950 --> 00:55:12.870
and it was a retroactive limit.

00:55:12.870 --> 00:55:14.960
So they destroyed a lot of
the value in their archive

00:55:14.960 --> 00:55:18.700
without even knowing that
they had done anything.

00:55:18.700 --> 00:55:20.330
It's easy to say that,
well, you know,

00:55:20.330 --> 00:55:22.360
you talk to your users,
you find out about this.

00:55:22.360 --> 00:55:24.730
But I think a lot of stuff
falls in between the cracks

00:55:24.730 --> 00:55:26.370
when people use multiple sites.

00:55:26.370 --> 00:55:27.960
People's online presence
is complicated;

00:55:27.960 --> 00:55:30.140
it's not limited to
one or two places.

00:55:30.140 --> 00:55:33.630
So the only way to know how to
preserve is to talk to them.

00:55:33.630 --> 00:55:35.750
The problem isn't that
we can't store the stuff;

00:55:35.750 --> 00:55:37.050
we have more than enough storage.

00:55:37.050 --> 00:55:39.780 position:56%
It's just that we can't recreate
these environments in a faithful way

00:55:39.780 --> 00:55:43.350
without bringing in all of the
operating systems and browsers

00:55:43.350 --> 00:55:46.510
and ad networks that exist now,
which is an impossible task.

00:55:46.510 --> 00:55:50.150
[ Silence ]

00:55:50.150 --> 00:55:53.220
Focusing on communities, like I
said, means relinquishing control.

00:55:53.220 --> 00:55:54.520
It's scary.

00:55:54.520 --> 00:55:56.750
But there are some key
steps we can follow.

00:55:56.750 --> 00:56:00.690
So making materials available in
open formats, without restrictions,

00:56:00.690 --> 00:56:04.540
with a serious commitment to having
a URL be a permanent promise goes a

00:56:04.540 --> 00:56:05.840
long way.

00:56:05.840 --> 00:56:11.140 position:56%
Publishing texts as text, API's like
we've seen and talked about today,

00:56:11.140 --> 00:56:12.730
which I find very encouraging.

00:56:12.730 --> 00:56:18.130 position:56%
And a commitment to fair use that
the copyright office has also shown,

00:56:18.130 --> 00:56:21.810
so that people can freely create
and stitch this stuff together

00:56:21.810 --> 00:56:25.710
without fear of automated
robot emails from lawyers.

00:56:25.710 --> 00:56:32.890
I want to give my wistful
closing, closing memory of the --

00:56:32.890 --> 00:56:34.410
a place I never thought
I'd be wistful about,

00:56:34.410 --> 00:56:36.460
the Glenview Public Library.

00:56:36.460 --> 00:56:38.930 position:56%
I grew up in the suburbs of Chicago,

00:56:38.930 --> 00:56:42.070
and it was a suburban
library like any other.

00:56:42.070 --> 00:56:44.580
But like a lot of nerdy
kids of my generation,

00:56:44.580 --> 00:56:47.240
I spent half of my adolescence
there or at home reading books

00:56:47.240 --> 00:56:48.730
that I checked out from there.

00:56:48.730 --> 00:56:51.960
It was my window on the
world before the internet.

00:56:51.960 --> 00:56:55.300
And I never reflected why this
unremarkable suburban library

00:56:55.300 --> 00:56:58.590
existed, or who funded it, or
where its values came from,

00:56:58.590 --> 00:57:00.140
or how long it would be around.

00:57:00.140 --> 00:57:03.160 position:56%
It was just a part of the
landscape to me, like Lake Michigan.

00:57:03.160 --> 00:57:06.370
But it taught me that like everyone
else I had a right to learn.

00:57:06.370 --> 00:57:07.780
And that I was welcome.

00:57:07.780 --> 00:57:09.320
That I could ask questions.

00:57:09.320 --> 00:57:11.250
That I could learn how to
find my way to the answers.

00:57:11.250 --> 00:57:15.380
And it taught me the importance
of being quiet in public spaces.

00:57:15.380 --> 00:57:18.420
For the generation that's
growing up today, the internet is

00:57:18.420 --> 00:57:20.040
that window on the world.

00:57:20.040 --> 00:57:22.770
And to them it just exists;
they take it for granted.

00:57:22.770 --> 00:57:25.120
And it's only us who have seen
it take shape and are aware

00:57:25.120 --> 00:57:29.020 position:56%
of all the ways it could be
different, and how contingent it is,

00:57:29.020 --> 00:57:31.950
that need to worry about it.

00:57:31.950 --> 00:57:33.800 position:56%
The coming years are going to decide

00:57:33.800 --> 00:57:36.740
to what extent the internet
is a medium for consumption,

00:57:36.740 --> 00:57:40.020
to what extent it's going to lift
people up, and how much it's going

00:57:40.020 --> 00:57:42.820
to be a tool of social control.

00:57:42.820 --> 00:57:46.040
As it exists today, the internet
is kind of a shopping mall.

00:57:46.040 --> 00:57:49.010
There are two big anchor stores
-- there's Facebook and Google.

00:57:49.010 --> 00:57:51.340
And of course there's an
Apple store in the middle.

00:57:51.340 --> 00:57:55.250
There's a food court
with a couple of punks,

00:57:55.250 --> 00:57:59.280
and lots of surveillance cameras
everywhere watching everything

00:57:59.280 --> 00:58:00.580
that happens.

00:58:00.580 --> 00:58:02.290
And outside in the parking
lot there's the bookmobile,

00:58:02.290 --> 00:58:03.730
which is you guys.

00:58:03.730 --> 00:58:06.870
There just to add a veneer
of classiness to the place.

00:58:06.870 --> 00:58:09.710
This isn't my dream of the web.

00:58:09.710 --> 00:58:12.820
My dream of the web is for
it to feel like the big city.

00:58:12.820 --> 00:58:16.060
It's a place where you rub elbows
with people who are not like you.

00:58:16.060 --> 00:58:19.080
Some place that's a little
bit scary, a little chaotic,

00:58:19.080 --> 00:58:22.980
full of everything you can imagine,
and many things that you can't.

00:58:22.980 --> 00:58:25.390
And a place where there's
room for chain stores,

00:58:25.390 --> 00:58:26.690
for entertainment complexes.

00:58:26.690 --> 00:58:28.350
But also for people
to be themselves,

00:58:28.350 --> 00:58:32.430
for people to create their own
spaces, to learn from one another.

00:58:32.430 --> 00:58:35.670
And of course room
for big, beautiful,

00:58:35.670 --> 00:58:38.400
huge, tremendous libraries.

00:58:38.400 --> 00:58:40.200
Thank you very much.

00:58:40.200 --> 00:58:43.100
[ Applause ]

00:58:43.100 --> 00:58:46.730
&gt;&gt; This has been a presentation
of the Library of Congress.

00:58:46.730 --> 00:58:49.100
Visit us at loc.gov.

