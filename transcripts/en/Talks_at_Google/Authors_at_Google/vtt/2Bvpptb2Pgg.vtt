WEBVTT
Kind: captions
Language: en

00:00:08.600 --> 00:00:10.690
MALE SPEAKER: Hello, everyone.

00:00:10.690 --> 00:00:12.470
Welcome to Talks at Google.

00:00:12.470 --> 00:00:15.930
I'm delighted to host
Professor David Gelernter today

00:00:15.930 --> 00:00:17.690
at Google for a talk
on his latest book,

00:00:17.690 --> 00:00:21.610
"The Tides of Mind-- Uncovering
the Spectrum of Consciousness."

00:00:21.610 --> 00:00:23.150
David Hillel
Gelernter is a writer

00:00:23.150 --> 00:00:26.490
and a professor of computer
science at Yale University.

00:00:26.490 --> 00:00:29.120
He's a former national fellow
at the American Enterprise

00:00:29.120 --> 00:00:32.450
Institute and a senior fellow
in Jewish thought at the Shalem

00:00:32.450 --> 00:00:36.580
center and sat on the National
Endowments of the Arts.

00:00:36.580 --> 00:00:38.316
He publishes
widely, and his work

00:00:38.316 --> 00:00:40.940
has appeared in the "Wall Street
Journal," the "New York Post,"

00:00:40.940 --> 00:00:45.730
the "LA Times," the "Weekly
Standard," and elsewhere.

00:00:45.730 --> 00:00:47.620
He is known for his
contributions to parallel

00:00:47.620 --> 00:00:51.060
computation and for books
on topics including computed

00:00:51.060 --> 00:00:54.540
worlds, mirror worlds, and
what he sees as the destructive

00:00:54.540 --> 00:00:57.330
influence of liberal
academia on American society,

00:00:57.330 --> 00:01:00.710
expressed in his book
"America-Lite00 How Imperial

00:01:00.710 --> 00:01:04.152
Academia Dismantled
Our Culture."

00:01:04.152 --> 00:01:08.230
In 1993, he was sent a
mail bomb by Ted Kaczynski,

00:01:08.230 --> 00:01:11.010
the Unabomber, which
he miraculously

00:01:11.010 --> 00:01:12.470
and thankfully survived.

00:01:12.470 --> 00:01:14.370
His latest book,
"The Tides of Mind,"

00:01:14.370 --> 00:01:17.080
is a fascinating look at the
spectrum of consciousness--

00:01:17.080 --> 00:01:19.630
dreams, memory, and creativity.

00:01:19.630 --> 00:01:21.570
I'm looking forward
to hearing him

00:01:21.570 --> 00:01:23.539
speak for approximately
35 minutes,

00:01:23.539 --> 00:01:25.330
and then we'll open
the floor to questions.

00:01:25.330 --> 00:01:27.160
And I'm eager to
hear your questions

00:01:27.160 --> 00:01:29.071
on for Professor Gelertner.

00:01:29.071 --> 00:01:33.960
[APPLAUSE]

00:01:33.960 --> 00:01:37.260
DAVID GELERNTER: I have to
apologize to Jason and to you

00:01:37.260 --> 00:01:41.980
for that antique biography,
which I think I haven't updated

00:01:41.980 --> 00:01:47.596
in 1,000 years.

00:01:47.596 --> 00:01:50.484
I'm going to have to-- I don't
know where it is, exactly,

00:01:50.484 --> 00:01:52.650
because-- I can't update
it because I can't find it.

00:01:52.650 --> 00:01:58.760
Anyway, it's very
nice to be here.

00:01:58.760 --> 00:02:00.390
It's a pleasure to be here.

00:02:00.390 --> 00:02:03.740
It's been a while since
I've been in Cambridge,

00:02:03.740 --> 00:02:06.090
and it's always nice to be here.

00:02:08.754 --> 00:02:12.590
I've talked about this work
before, the work discussed

00:02:12.590 --> 00:02:16.440
in this particular
book, once or twice.

00:02:16.440 --> 00:02:19.650
I do have a decent
talk on the topic.

00:02:19.650 --> 00:02:24.250
But last night, I decided
to rewrite the whole thing.

00:02:24.250 --> 00:02:24.910
Not last night.

00:02:24.910 --> 00:02:25.826
The night before last.

00:02:25.826 --> 00:02:27.780
Last night, we were
already in Boston.

00:02:30.770 --> 00:02:34.680
My wife notified me that
this was a bad idea.

00:02:34.680 --> 00:02:37.310
But some people are
ridiculously stubborn.

00:02:37.310 --> 00:02:39.570
There's nothing I
can do with her.

00:02:39.570 --> 00:02:41.170
So here's the new
talk, and I have

00:02:41.170 --> 00:02:45.610
to apologize for its being
not completely debugged.

00:02:45.610 --> 00:02:48.850
But I'll give it
my very best shot.

00:02:48.850 --> 00:02:51.800
And if I get jammed or stuck
in a loop or something,

00:02:51.800 --> 00:02:56.490
just give me a shove.

00:02:56.490 --> 00:03:01.010
AI, artificial intelligence,
is a strange field,

00:03:01.010 --> 00:03:03.320
very strange-- full of
brilliant achievements,

00:03:03.320 --> 00:03:07.190
of course, world class thinkers,
and fundamentally wrong,

00:03:07.190 --> 00:03:11.296
it seems to me, on
an important point.

00:03:11.296 --> 00:03:13.470
AI's achievements
are well-known.

00:03:13.470 --> 00:03:16.330
I think its big mistake
is less well-known,

00:03:16.330 --> 00:03:18.542
so I'll focus on that.

00:03:18.542 --> 00:03:23.900
But not in the usual, negative
way, certainly not entirely.

00:03:23.900 --> 00:03:27.576
For me, this big mistake
is an opportunity,

00:03:27.576 --> 00:03:33.610
a fascinating entryway into a
lot of interesting and useful

00:03:33.610 --> 00:03:35.300
ideas.

00:03:35.300 --> 00:03:38.130
I'd like to discuss some obvious
and important hints that I

00:03:38.130 --> 00:03:43.880
think we missed and
we should act on,

00:03:43.880 --> 00:03:46.470
and some missed opportunities.

00:03:46.470 --> 00:03:50.102
The big mistake I'm referring
to is obviously not universal.

00:03:50.102 --> 00:03:51.560
There are a million
different views

00:03:51.560 --> 00:03:57.350
in the field, all sorts of
views on basic questions,

00:03:57.350 --> 00:03:59.790
in this field and in the
adjacent fields, of course,

00:03:59.790 --> 00:04:01.440
we mix with all the time.

00:04:01.440 --> 00:04:05.652
But there is a reason the basic
mistake attracts my attention.

00:04:05.652 --> 00:04:08.750
And that's because
of the many classes,

00:04:08.750 --> 00:04:13.430
courses at Yale and at
colleges across the country--

00:04:13.430 --> 00:04:15.470
and I'm tempted to
say across the world--

00:04:15.470 --> 00:04:21.432
in which this view is stated
as simple, settled truth.

00:04:21.432 --> 00:04:23.960
In science today,
we're just starting

00:04:23.960 --> 00:04:26.630
to develop the nasty
idea that there's

00:04:26.630 --> 00:04:29.730
only one legitimate side
to contested issues,

00:04:29.730 --> 00:04:33.122
and anyone who
disagrees must be crazy.

00:04:33.122 --> 00:04:35.960
The ones who suffer the most,
of course, are the students.

00:04:35.960 --> 00:04:40.620
They tend to believe us
till they learn better.

00:04:40.620 --> 00:04:44.310
AI's achievements are important,
and we all know all about them.

00:04:44.310 --> 00:04:49.790
Some company called
Google-- [INAUDIBLE]

00:04:49.790 --> 00:04:51.980
might have heard of
these guys-- built

00:04:51.980 --> 00:04:54.510
a program that just
beat the world's go

00:04:54.510 --> 00:04:56.416
champion a few weeks ago.

00:04:56.416 --> 00:04:58.690
Of course, go
resembles chess, is

00:04:58.690 --> 00:05:01.520
said to be deeper and
even harder and more

00:05:01.520 --> 00:05:03.560
complicated to play.

00:05:03.560 --> 00:05:07.715
And significantly, it's
resisted AI researchers longer.

00:05:07.715 --> 00:05:10.580
I saw on the news
yesterday, the day

00:05:10.580 --> 00:05:12.270
before yesterday
that the defeated go

00:05:12.270 --> 00:05:17.320
champion is demanding a rematch,
probably get beat again.

00:05:17.320 --> 00:05:22.770
But in any case, mastering go
fits well into AI's ambitions.

00:05:22.770 --> 00:05:25.070
Ultimately, AI is
set on creating

00:05:25.070 --> 00:05:28.200
an actual human intelligence,
humanlike intelligence,

00:05:28.200 --> 00:05:30.320
a humanlike mind.

00:05:30.320 --> 00:05:32.260
And that will, of
course, lead inevitably

00:05:32.260 --> 00:05:36.230
to superhuman minds and
super-superhuman minds

00:05:36.230 --> 00:05:40.316
with gigantic IQ's and gigantic
intellectual capacities,

00:05:40.316 --> 00:05:41.690
an issue that I
don't think we've

00:05:41.690 --> 00:05:44.080
thought about sufficiently.

00:05:44.080 --> 00:05:46.590
In any case, AI
continues to prove

00:05:46.590 --> 00:05:49.705
itself an ever more
powerful set of techniques

00:05:49.705 --> 00:05:52.650
for building the world's most
sophisticated applications.

00:05:52.650 --> 00:05:56.490
It's clear that AI and
state-of-the-art programming

00:05:56.490 --> 00:06:00.070
will increasingly grow together
and become a single field.

00:06:00.070 --> 00:06:02.550
But I'd like to look
at this basic mistake,

00:06:02.550 --> 00:06:08.145
alleged mistake I mentioned,
mainstream AI's mistake,

00:06:08.145 --> 00:06:14.270
according to me-- confusing
a sonnet with a grapefruit,

00:06:14.270 --> 00:06:18.930
so to speak, confusing a pure
idea or abstraction on the one

00:06:18.930 --> 00:06:22.210
hand with a physical
object on the other.

00:06:22.210 --> 00:06:24.590
It's attractive to
think of the mind

00:06:24.590 --> 00:06:28.350
as a mere well-structured
idea, independent of the way

00:06:28.350 --> 00:06:32.590
it happens to be realized in the
human brain, capable of being

00:06:32.590 --> 00:06:34.710
realized in
arbitrarily many ways,

00:06:34.710 --> 00:06:36.920
as we've heard so
many people say

00:06:36.920 --> 00:06:39.690
and seen so many people
write, including, not

00:06:39.690 --> 00:06:42.745
incidentally, by software
on a digital computer.

00:06:42.745 --> 00:06:45.730
But we have no basis for
arguing that this is true,

00:06:45.730 --> 00:06:48.710
that the mind is independent
of its realization.

00:06:48.710 --> 00:06:51.080
We'd merely like it to be true.

00:06:51.080 --> 00:06:54.990
There is only one known way
to get a humanlike mind,

00:06:54.990 --> 00:06:57.260
and that's to
start with a human.

00:06:57.260 --> 00:06:59.175
Of course, there
might be other ways,

00:06:59.175 --> 00:07:02.731
but we haven't found any yet,
and we have no logical reason

00:07:02.731 --> 00:07:03.980
to believe that there are any.

00:07:03.980 --> 00:07:06.120
It's an empirical question.

00:07:06.120 --> 00:07:07.590
Maybe yes, maybe no.

00:07:07.590 --> 00:07:10.310
All we can do is wait and see.

00:07:10.310 --> 00:07:14.240
At any rate, the mind is
not a structured idea.

00:07:14.240 --> 00:07:16.490
It's a grapefruit
and not a sonnet.

00:07:16.490 --> 00:07:19.540
It's a physical thing-- or,
more precisely, one aspect

00:07:19.540 --> 00:07:21.600
of a physical thing.

00:07:21.600 --> 00:07:24.520
Human mind, one aspect
of the human brain,

00:07:24.520 --> 00:07:28.050
or, again more precisely,
one aspect of the human

00:07:28.050 --> 00:07:32.790
being-- the human body,
the brain included.

00:07:32.790 --> 00:07:37.940
The fact that the mind is one
aspect of a physical-- in fact,

00:07:37.940 --> 00:07:41.510
an organic, living
thing-- makes it

00:07:41.510 --> 00:07:46.830
natural to see what too many
AI researchers have ignored--

00:07:46.830 --> 00:07:50.840
the organic, body-centered
side of the mind

00:07:50.840 --> 00:07:52.940
or aspect of the mind.

00:07:52.940 --> 00:07:57.740
This physical
quasi-organic view makes

00:07:57.740 --> 00:08:00.420
it natural to see the
mind as a tidal object

00:08:00.420 --> 00:08:03.050
that changes over the
course of everyday,

00:08:03.050 --> 00:08:06.700
changes as gently and
naturally as a flower opening

00:08:06.700 --> 00:08:10.280
its petals in sunlight
and closing in darkness.

00:08:10.280 --> 00:08:14.310
But the mind's changes
are more complicated

00:08:14.310 --> 00:08:19.380
than that, although, I will
argue, no less obvious.

00:08:19.380 --> 00:08:24.200
A pendulum that doesn't
move doesn't convey

00:08:24.200 --> 00:08:26.960
the reality of pendulums.

00:08:26.960 --> 00:08:30.410
If your view of a pendulum
is as an unmoving object,

00:08:30.410 --> 00:08:32.596
you're missing
something important.

00:08:32.596 --> 00:08:38.175
And constant and gradual change
is basic to the mind, too.

00:08:38.175 --> 00:08:41.490
If we don't see
it-- if we don't see

00:08:41.490 --> 00:08:45.340
the gentle swing of the
pendulum or the tidal motions

00:08:45.340 --> 00:08:48.830
of the mind-- we're
looking at a stopped clock,

00:08:48.830 --> 00:08:50.330
taking it for a real clock.

00:08:50.330 --> 00:08:52.960
We're missing
something important.

00:08:52.960 --> 00:08:56.630
I'll argue that we can't
understand the mind properly

00:08:56.630 --> 00:08:58.440
unless we see it as
a changing thing that

00:08:58.440 --> 00:09:01.470
follows a predictable
course over the day.

00:09:01.470 --> 00:09:03.680
But AI doesn't generally
take this view,

00:09:03.680 --> 00:09:06.520
and neither do the fields
adjacent-- psychology,

00:09:06.520 --> 00:09:10.300
neurobiology,
philosophy of mind.

00:09:10.300 --> 00:09:11.900
Before I look at
that changing mind,

00:09:11.900 --> 00:09:14.320
just a final glance
at the sonnet

00:09:14.320 --> 00:09:18.370
versus grapefruit debate
and this alleged mistake.

00:09:18.370 --> 00:09:25.000
Some people-- a minority,
but a formidable one--

00:09:25.000 --> 00:09:26.120
agree with my view.

00:09:26.120 --> 00:09:28.922
Or rather, I agree
with their view.

00:09:28.922 --> 00:09:31.450
Said in effect, the same
thing about the mind being

00:09:31.450 --> 00:09:34.070
a physical object
[INAUDIBLE], Thomas Nagel

00:09:34.070 --> 00:09:36.670
being the most prominent among
them, although their goals are

00:09:36.670 --> 00:09:38.520
different from mine.

00:09:38.520 --> 00:09:42.470
But notice that if I think of
the mind as an idea instead

00:09:42.470 --> 00:09:47.410
of a physical object, it's easy
and natural to make the mistake

00:09:47.410 --> 00:09:50.100
of seeing the mind as static.

00:09:50.100 --> 00:09:54.860
After all, an idea doesn't
change unless we change it.

00:09:54.860 --> 00:09:58.510
A sonnet or a
theorem in geometry

00:09:58.510 --> 00:10:07.270
or Beethoven's first symphony
is an unchanging, static reality

00:10:07.270 --> 00:10:09.360
in ordinary conditions.

00:10:09.360 --> 00:10:11.190
If I think of the
mind as an idea

00:10:11.190 --> 00:10:14.290
or an abstraction instead
of an organic object,

00:10:14.290 --> 00:10:16.090
it's also natural to
think that the mind is

00:10:16.090 --> 00:10:22.273
a rationality engine, an
informal reasoning machine.

00:10:22.273 --> 00:10:25.590
Many scientists-- I would
argue most scientists

00:10:25.590 --> 00:10:27.970
and philosophers-- who
work on this question

00:10:27.970 --> 00:10:30.855
identify human thought
with rationality,

00:10:30.855 --> 00:10:33.830
with reasoning or
informal logic.

00:10:33.830 --> 00:10:36.870
This approach leaves out
a lot of important things.

00:10:36.870 --> 00:10:41.310
In fact, it leaves out almost
all of human psychology.

00:10:41.310 --> 00:10:47.320
Some mistakes associated with
the mind as abstraction idea

00:10:47.320 --> 00:10:52.880
are mistakes any child can
see, which is not a good sign.

00:10:52.880 --> 00:10:56.967
The press has been full
of declarations recently--

00:10:56.967 --> 00:10:58.550
I don't know why
recently, especially.

00:10:58.550 --> 00:11:02.960
But just the weekend
before last, I

00:11:02.960 --> 00:11:06.770
saw this again-- declarations
of billionaires and futurists

00:11:06.770 --> 00:11:13.490
and just ad hoc loudmouths who
tell us they plan to, quote,

00:11:13.490 --> 00:11:16.240
"upload their minds in
digital form to the internet,

00:11:16.240 --> 00:11:19.130
and thereby make
themselves immortal."

00:11:19.130 --> 00:11:21.230
Two weeks ago or
whenever it was,

00:11:21.230 --> 00:11:23.990
quite recently, there
was a Russian businessman

00:11:23.990 --> 00:11:29.340
or wealthy businessman who
was making a statement.

00:11:29.340 --> 00:11:31.960
This plan will not work.

00:11:31.960 --> 00:11:34.760
It might work metaphorically,
but the enthusiasts never

00:11:34.760 --> 00:11:36.990
seem to be speaking
metaphorically.

00:11:36.990 --> 00:11:40.410
Thomas Jefferson made
himself immortal, of course,

00:11:40.410 --> 00:11:42.330
by writing the Declaration
of Independence

00:11:42.330 --> 00:11:48.660
and doing a bunch of
other fascinating things.

00:11:48.660 --> 00:11:52.430
But nonetheless,
he's still dead.

00:11:52.430 --> 00:11:55.550
Abstractions of
Jefferson, summaries

00:11:55.550 --> 00:11:59.160
of some aspect of his mind
or some aspect of his work,

00:11:59.160 --> 00:12:02.580
can be immortal-- abstracts
of his physical appearance.

00:12:02.580 --> 00:12:03.270
We have statues.

00:12:03.270 --> 00:12:04.020
We have paintings.

00:12:04.020 --> 00:12:06.350
We have engravings--
that can last forever.

00:12:06.350 --> 00:12:07.340
They can be immortal.

00:12:07.340 --> 00:12:10.385
But Jefferson himself
was a human being,

00:12:10.385 --> 00:12:13.510
a particular physical object
that no longer exists.

00:12:13.510 --> 00:12:16.480
Jefferson's mind,
being one aspect

00:12:16.480 --> 00:12:18.660
of this no longer
extant physical object,

00:12:18.660 --> 00:12:20.470
no longer exists, either.

00:12:20.470 --> 00:12:24.530
No matter how fervently
AI mainstream researchers

00:12:24.530 --> 00:12:28.100
insist that the mind is an
abstraction, nonetheless,

00:12:28.100 --> 00:12:31.770
when a human being
dies, he no longer cares

00:12:31.770 --> 00:12:34.220
about how many
abstractions of his mind

00:12:34.220 --> 00:12:38.580
are kicking around the internet,
no longer cares about anything.

00:12:38.580 --> 00:12:40.450
You can tell him he's
immortal, but he's not

00:12:40.450 --> 00:12:42.680
going to be interested.

00:12:42.680 --> 00:12:45.000
There are strong
positive advantages

00:12:45.000 --> 00:12:48.780
to be got, on the other hand,
from seeing the mind as one

00:12:48.780 --> 00:12:51.850
aspect of a physical thing.

00:12:51.850 --> 00:12:54.530
The mind is a tidal
object, I want to argue,

00:12:54.530 --> 00:12:57.776
with its own natural rhythms.

00:12:57.776 --> 00:13:01.470
If we miss those rhythms, we're
missing its basic character.

00:13:01.470 --> 00:13:04.650
Everyone understands that waking
on the one hand and asleep

00:13:04.650 --> 00:13:07.920
and dreaming on the other
are two very different states

00:13:07.920 --> 00:13:11.130
of mind, two different mental
states, or two different states

00:13:11.130 --> 00:13:12.380
of consciousness.

00:13:12.380 --> 00:13:16.300
But the system has more
than just these two states.

00:13:16.300 --> 00:13:20.085
The mind moves continually along
a spectrum of different states,

00:13:20.085 --> 00:13:22.130
where the waking,
energetic mind is

00:13:22.130 --> 00:13:24.720
near the top of the spectrum,
and the sleeping and dreaming

00:13:24.720 --> 00:13:26.915
mind is near the bottom.

00:13:26.915 --> 00:13:29.110
It seems to me that
we need to understand

00:13:29.110 --> 00:13:31.220
how the top and the
bottom differ exactly

00:13:31.220 --> 00:13:33.560
and what happens in between.

00:13:33.560 --> 00:13:36.780
Consider dreaming, to go
straight towards the bottom.

00:13:36.780 --> 00:13:39.690
We experience dreams, but
we don't think about them

00:13:39.690 --> 00:13:41.860
much as they unfold.

00:13:41.860 --> 00:13:45.660
This simple statement
includes a lot of information.

00:13:45.660 --> 00:13:49.610
We experience dreams
emotionally, of course.

00:13:49.610 --> 00:13:52.126
We feel them as they happen.

00:13:52.126 --> 00:13:54.860
Sometimes, their emotional
color lingers after we've

00:13:54.860 --> 00:13:56.370
forgotten all the rest.

00:13:56.370 --> 00:14:01.670
Often, they leave us vaguely
uneasy, vague dysphoria

00:14:01.670 --> 00:14:03.840
an emotion often
associated with dreams.

00:14:03.840 --> 00:14:06.730
But they can also cause
elation or terror.

00:14:06.730 --> 00:14:10.360
The most powerful emotions
we know occur in dreams.

00:14:10.360 --> 00:14:13.060
On the other hand, we don't
think about them much.

00:14:13.060 --> 00:14:14.070
We experience them.

00:14:14.070 --> 00:14:16.435
We don't think about
them much as they unfold.

00:14:16.435 --> 00:14:18.840
All sorts of improbabilities
and absurdities

00:14:18.840 --> 00:14:21.996
happen in dreams, of
course, and we don't mind.

00:14:21.996 --> 00:14:25.770
Thinking about and experience--
thinking about on the one hand,

00:14:25.770 --> 00:14:28.300
experience on the
other-- are good ways

00:14:28.300 --> 00:14:32.020
to identify the endpoints of
this spectrum of consciousness,

00:14:32.020 --> 00:14:34.230
the spectrum of
conscious states.

00:14:34.230 --> 00:14:37.420
The spectrum's top
edge is thinking about,

00:14:37.420 --> 00:14:40.840
pondering the morning
news or the daffodils

00:14:40.840 --> 00:14:45.240
outside your window or the
future of American Colleges.

00:14:45.240 --> 00:14:48.520
These are intentional states,
in philosophical terms.

00:14:48.520 --> 00:14:51.800
They refer to something
outside themselves.

00:14:51.800 --> 00:14:55.040
They refer to the news or
the daffodils or whatever,

00:14:55.040 --> 00:14:57.210
the colleges.

00:14:57.210 --> 00:15:00.780
The opposite pole, the
bottom of the spectrum,

00:15:00.780 --> 00:15:05.710
is pure experience, meaning
sensation or emotion.

00:15:05.710 --> 00:15:10.005
Feeling is a word
that well captures

00:15:10.005 --> 00:15:12.730
this idea of experience.

00:15:12.730 --> 00:15:16.040
It's a combination of several
philosophical entities.

00:15:16.040 --> 00:15:21.900
Pure being or feeling, sensation
or emotion, is about nothing.

00:15:21.900 --> 00:15:27.055
A chill or warmth, seeing
violet, or smelling cut grass,

00:15:27.055 --> 00:15:31.110
uneasiness or thirst or
unhappiness or euphoria

00:15:31.110 --> 00:15:33.240
must each have a cause.

00:15:33.240 --> 00:15:36.780
But they're not about
anything, anymore

00:15:36.780 --> 00:15:39.440
than the pleasant
coolness of your forearm

00:15:39.440 --> 00:15:42.280
is about the spring breeze.

00:15:42.280 --> 00:15:44.260
When the mind moves
over the course of a day

00:15:44.260 --> 00:15:46.825
from a state of thinking
about-- up spectrum--

00:15:46.825 --> 00:15:49.720
to a state of being or
experience-- down spectrum--

00:15:49.720 --> 00:15:51.500
it's moving from one
kind of mental state

00:15:51.500 --> 00:15:53.960
to a very different
kind, or mental apples

00:15:53.960 --> 00:15:55.940
to mental oranges.

00:15:55.940 --> 00:15:59.120
We rarely reach the absolute
top or the absolute bottom

00:15:59.120 --> 00:15:59.840
of the spectrum.

00:15:59.840 --> 00:16:02.330
But we move from near the
top to near the bottom.

00:16:02.330 --> 00:16:05.200
Dreaming itself is
not pure experience

00:16:05.200 --> 00:16:08.520
but is a state of consciousness
in which experience tends

00:16:08.520 --> 00:16:11.210
to dominate thinking about.

00:16:11.210 --> 00:16:13.920
Again, we experience dreams, but
we don't think about them much.

00:16:13.920 --> 00:16:17.740
If dreams were pure being,
we'd witness the dream--

00:16:17.740 --> 00:16:19.910
see and hear it--
but not take it

00:16:19.910 --> 00:16:23.380
in because we wouldn't be
thinking about it at all.

00:16:23.380 --> 00:16:25.250
We'd simply
experience the events

00:16:25.250 --> 00:16:28.630
as they unfold without
thinking about them.

00:16:28.630 --> 00:16:31.985
A sufficiently dramatic
roller coaster ride

00:16:31.985 --> 00:16:36.510
might scare you into an actual
state of pure experience,

00:16:36.510 --> 00:16:38.060
where you're not
thinking at all.

00:16:38.060 --> 00:16:40.950
You're only having
an experience.

00:16:40.950 --> 00:16:44.780
Dreams can be close to this
roller coaster state of mind--

00:16:44.780 --> 00:16:48.120
not in the up and down sense,
but in the strong emotions

00:16:48.120 --> 00:16:49.420
sense.

00:16:49.420 --> 00:16:53.810
One symptom of that state
afterwards, evidence for what

00:16:53.810 --> 00:16:58.200
happened, is poor memory, such
as our poor memory for dreams.

00:16:58.200 --> 00:17:01.340
Having experienced something,
we have to think about it

00:17:01.340 --> 00:17:04.310
in order to fix the
short-term memory,

00:17:04.310 --> 00:17:06.790
in order to fix the fleeting
impression in such a way

00:17:06.790 --> 00:17:08.990
that it can survive
over the longer term.

00:17:08.990 --> 00:17:13.930
If we're not thinking about
much, we won't remember much.

00:17:13.930 --> 00:17:17.680
And that's the case for dreaming
and for significant parts

00:17:17.680 --> 00:17:19.900
of the lower spectrum.

00:17:19.900 --> 00:17:22.880
We can only reproduce
the spectrum in software

00:17:22.880 --> 00:17:25.260
if we can reproduce the
endpoints, to start.

00:17:25.260 --> 00:17:29.116
Thinking about, I believe, can
be simulated on a computer,

00:17:29.116 --> 00:17:30.740
and there's been a
lot of work on that.

00:17:30.740 --> 00:17:33.260
But no computer can
ever feel anything,

00:17:33.260 --> 00:17:35.100
will ever feel anything.

00:17:35.100 --> 00:17:37.446
Feeling is uncomputable.

00:17:37.446 --> 00:17:40.590
Feeling and consciousness can
only happen, as far as we know,

00:17:40.590 --> 00:17:44.350
to organic, Earth-type
animals, and can't ever

00:17:44.350 --> 00:17:46.630
be produced-- no matter
what, no matter where we go

00:17:46.630 --> 00:17:49.250
and what we find--
can't ever be produced

00:17:49.250 --> 00:17:51.650
by mere software on a computer.

00:17:51.650 --> 00:17:53.996
But that doesn't limit AI.

00:17:53.996 --> 00:17:56.420
Software, of course,
could simulate feeling.

00:17:56.420 --> 00:17:58.935
A robot could tell
you it's depressed

00:17:58.935 --> 00:18:01.340
and act depressed,
although it feels nothing.

00:18:01.340 --> 00:18:05.270
AI in principle could
build a simulated mind

00:18:05.270 --> 00:18:08.055
that reproduced all the
nuances of human thought

00:18:08.055 --> 00:18:11.490
and dealt with the world in
a thoroughly humanlike way

00:18:11.490 --> 00:18:12.880
despite being unconscious.

00:18:12.880 --> 00:18:16.322
After all, your best
friend might be a zombie.

00:18:16.322 --> 00:18:17.847
Or they might all be zombies.

00:18:17.847 --> 00:18:18.680
And would it matter?

00:18:18.680 --> 00:18:21.780
Of course, but only to him.

00:18:21.780 --> 00:18:24.830
When we say that
we feel some way,

00:18:24.830 --> 00:18:28.396
we're saying that our minds
are part of a physical system

00:18:28.396 --> 00:18:32.650
and register the state of that
system in the form of feelings.

00:18:32.650 --> 00:18:35.785
Consciousness is a property
of a certain kind of object,

00:18:35.785 --> 00:18:38.732
just as bounciness
is or rustiness.

00:18:38.732 --> 00:18:42.290
You can't download software to
make your smartphone conscious

00:18:42.290 --> 00:18:45.315
any more than you can download
software to make it bounce

00:18:45.315 --> 00:18:49.365
or to make it rust or to
make it smell like roses.

00:18:49.365 --> 00:18:52.410
Those attributes are the
result of physical processes

00:18:52.410 --> 00:18:54.070
in a certain type of object.

00:18:54.070 --> 00:18:57.700
Why don't we say the
same of thinking about?

00:18:57.700 --> 00:19:00.320
I'm saying that the bottom of
the spectrum we experienced

00:19:00.320 --> 00:19:02.850
will not exist on a computer.

00:19:02.850 --> 00:19:04.760
We could make that
claim in principle

00:19:04.760 --> 00:19:09.295
about thinking about, also,
about intentional thought.

00:19:12.011 --> 00:19:15.140
It's a deep topic, and
could go on at length.

00:19:15.140 --> 00:19:19.720
But we might say just in
passing that the substance

00:19:19.720 --> 00:19:22.120
of our thoughts, what
we're thinking about,

00:19:22.120 --> 00:19:25.160
can, on the whole, be
described, in English,

00:19:25.160 --> 00:19:28.380
some other language,
or maybe a language

00:19:28.380 --> 00:19:30.830
in the sense in which
mathematics is a language

00:19:30.830 --> 00:19:32.430
or music or drawing.

00:19:32.430 --> 00:19:35.070
You know, you have language
in a very broad and metaphoric

00:19:35.070 --> 00:19:35.840
sense.

00:19:35.840 --> 00:19:38.390
The substance of our
thoughts can be abstracted.

00:19:38.390 --> 00:19:40.160
It can be captured
and communicated,

00:19:40.160 --> 00:19:43.680
can therefore, perhaps,
be accurately reproduced

00:19:43.680 --> 00:19:46.250
outside the human body,
can live and exist

00:19:46.250 --> 00:19:49.570
outside the body-- in
vitro, so to speak.

00:19:49.570 --> 00:19:54.060
Language is our tool of
abstraction separating

00:19:54.060 --> 00:19:56.230
the message from the medium
because language allows

00:19:56.230 --> 00:19:58.110
us to separate the
substance of thinking

00:19:58.110 --> 00:20:00.300
from the medium
in which we think.

00:20:00.300 --> 00:20:03.360
Seems reasonable the thinking
might be accomplished

00:20:03.360 --> 00:20:06.040
by using some different medium.

00:20:06.040 --> 00:20:08.030
And thinking about
doesn't depend

00:20:08.030 --> 00:20:10.780
on the particular platform,
the particular medium.

00:20:10.780 --> 00:20:14.120
But feeling can't be
abstracted in this sense.

00:20:14.120 --> 00:20:18.060
Feelings can't be
described in language.

00:20:18.060 --> 00:20:22.740
Happy or thirsty or
angry feel a certain way,

00:20:22.740 --> 00:20:25.450
but we can't put that
feeling into words.

00:20:25.450 --> 00:20:29.560
We tend to communicate emotion
not by language, but by using

00:20:29.560 --> 00:20:32.550
our bodies, by tone
of voice, gestures,

00:20:32.550 --> 00:20:34.940
our way of holding
ourselves and speaking

00:20:34.940 --> 00:20:37.880
and so forth, the goal being
to allow the other person

00:20:37.880 --> 00:20:40.000
to recognize which
of his own emotions

00:20:40.000 --> 00:20:44.086
corresponds to what
we're describing.

00:20:44.086 --> 00:20:47.040
And we can do that by
showing him physical gestures

00:20:47.040 --> 00:20:49.880
that he associates with
particular feelings of his own.

00:20:49.880 --> 00:20:54.060
The sound of middle C
or the look of sky blue

00:20:54.060 --> 00:20:56.210
or the feeling of
happiness are famously

00:20:56.210 --> 00:20:58.220
impossible to describe.

00:20:58.220 --> 00:21:00.980
Basic feelings are primitives
of mind experience.

00:21:00.980 --> 00:21:03.310
We can't abstract them
from the medium of feeling,

00:21:03.310 --> 00:21:04.740
from the body itself.

00:21:04.740 --> 00:21:07.480
And we have no good
reason to believe

00:21:07.480 --> 00:21:10.600
that they occur in
any other medium

00:21:10.600 --> 00:21:14.580
than the ordinary,
organic animal body.

00:21:14.580 --> 00:21:18.880
Returning to the spectrum,
no artificial mind

00:21:18.880 --> 00:21:23.426
will ever be humanlike unless
it imitates not just feeling

00:21:23.426 --> 00:21:25.440
on the one hand and
thinking about on the other,

00:21:25.440 --> 00:21:27.080
but the entire spectrum.

00:21:27.080 --> 00:21:31.195
Consider how your mind changes
as you slide down spectrum.

00:21:34.432 --> 00:21:38.290
The human mind is a whole
range of shades, not just

00:21:38.290 --> 00:21:39.980
rationality.

00:21:39.980 --> 00:21:41.950
We begin with something
like rationality,

00:21:41.950 --> 00:21:46.070
and gently and gradually
mix feeling or experience

00:21:46.070 --> 00:21:49.270
into it, creating a
whole range of shades.

00:21:49.270 --> 00:21:51.920
The range is infinite,
but the formula

00:21:51.920 --> 00:21:55.459
for creating this
infinity is simple.

00:21:55.459 --> 00:21:57.875
At the start of the day, we
tend to be mentally energetic.

00:21:57.875 --> 00:22:00.320
We tend to be near
the spectrum's top.

00:22:00.320 --> 00:22:04.220
At the day's other end, we're at
the other end of the spectrum.

00:22:04.220 --> 00:22:08.250
When we grow sleepy,
we're down spectrum

00:22:08.250 --> 00:22:09.990
and moving steadily lower.

00:22:09.990 --> 00:22:14.040
During the day, we generally go
through two main oscillations--

00:22:14.040 --> 00:22:17.415
drifting downwards towards
a temporary low point.

00:22:17.415 --> 00:22:19.730
This is often in the
middle or late afternoon.

00:22:19.730 --> 00:22:22.280
Then drifting higher
for a few hours,

00:22:22.280 --> 00:22:25.260
and finally downward
again, straight into sleep.

00:22:25.260 --> 00:22:27.720
Obviously, everyone
has his own pattern,

00:22:27.720 --> 00:22:31.080
but our general course over
a day, our general course,

00:22:31.080 --> 00:22:33.080
is from up spectrum to down.

00:22:33.080 --> 00:22:36.505
Software could imitate this
spectrum and will have to,

00:22:36.505 --> 00:22:39.170
to achieve humanlike thought.

00:22:39.170 --> 00:22:42.810
Many mental changes-- changes in
the quality of consciousness--

00:22:42.810 --> 00:22:46.960
are associated with this
movement across the spectrum.

00:22:46.960 --> 00:22:50.350
When we dream, our
focus is almost entirely

00:22:50.350 --> 00:22:52.960
on the inner world, the
inner world of the mind.

00:22:52.960 --> 00:22:55.800
When we're wide awake
and mentally energetic,

00:22:55.800 --> 00:23:01.240
we focus mainly outside,
on objective reality.

00:23:01.240 --> 00:23:04.330
If attention focuses on
the outer world at the top

00:23:04.330 --> 00:23:06.880
and on the inner world or
the inner mind at the bottom,

00:23:06.880 --> 00:23:09.610
we assume there must be
intermediate states in which it

00:23:09.610 --> 00:23:12.340
focuses partly outside
and partly inside.

00:23:12.340 --> 00:23:14.750
And, of course, we find
all sorts of such states,

00:23:14.750 --> 00:23:17.590
as when we are
daydreaming, for example,

00:23:17.590 --> 00:23:21.510
or occupied with whatever
our minds have cooked up

00:23:21.510 --> 00:23:23.970
and need to be roused
by people around us

00:23:23.970 --> 00:23:25.875
if they want our attention.

00:23:25.875 --> 00:23:28.810
But, of course, it's somewhat
easier to rouse a daydreamer

00:23:28.810 --> 00:23:32.890
and less dramatic for
the person himself than

00:23:32.890 --> 00:23:34.475
to rouse a sleeper.

00:23:34.475 --> 00:23:37.340
At the spectrum's top,
we concentrate readily,

00:23:37.340 --> 00:23:41.190
and memory, a crucial element
in the picture-- memory

00:23:41.190 --> 00:23:43.570
is docile at the
top of the spectrum.

00:23:43.570 --> 00:23:45.920
And it supplies facts
and figures and methods

00:23:45.920 --> 00:23:49.080
without distracting us
with fascinating anecdotes

00:23:49.080 --> 00:23:50.630
and recollections.

00:23:50.630 --> 00:23:53.475
Emotion tends to lie low.

00:23:53.475 --> 00:23:55.410
It's never completely absent.

00:23:55.410 --> 00:23:57.270
Emotion is never
completely absent.

00:23:57.270 --> 00:23:59.390
We need it to introduce
value into the world,

00:23:59.390 --> 00:24:02.930
to allow us to choose among
different mental directions.

00:24:02.930 --> 00:24:06.705
But up spectrum, emotion is
also docile, under control.

00:24:06.705 --> 00:24:09.900
It doesn't tend to overwhelm us.

00:24:09.900 --> 00:24:12.820
Early mornings are rarely
the time for histrionics

00:24:12.820 --> 00:24:14.170
and emotional scenes.

00:24:14.170 --> 00:24:16.350
Those come later.

00:24:16.350 --> 00:24:19.820
As we move down spectrum,
we lose concentration

00:24:19.820 --> 00:24:21.740
and reasoning power.

00:24:21.740 --> 00:24:24.620
We come gradually to
rely more on remembering

00:24:24.620 --> 00:24:28.000
than on reasoning-- on
the wisdom of experience,

00:24:28.000 --> 00:24:29.830
you might call it,
to solve problems,

00:24:29.830 --> 00:24:32.440
to react to the world.

00:24:32.440 --> 00:24:35.590
Lower still on the spectrum,
the mind starts to wander.

00:24:35.590 --> 00:24:37.100
We daydream.

00:24:37.100 --> 00:24:40.100
Our memories and fantasies
and ideas generally

00:24:40.100 --> 00:24:43.010
are growing vivid and
distracting as the mind's focus

00:24:43.010 --> 00:24:46.510
moves from outside to inside.

00:24:46.510 --> 00:24:48.970
Eventually, we grow sleepy.

00:24:48.970 --> 00:24:51.183
We find ourselves
free associating.

00:24:51.183 --> 00:24:53.530
Memory now controls
the mental agenda.

00:24:53.530 --> 00:24:54.640
It's no longer docile.

00:24:54.640 --> 00:24:56.130
It's no longer under control.

00:24:56.130 --> 00:24:59.710
And we pass through this strange
state of sleep onset thought,

00:24:59.710 --> 00:25:03.100
or sleep onset mentation, on
the way to sleep and dreaming,

00:25:03.100 --> 00:25:05.230
where sleep onset
thought is usually

00:25:05.230 --> 00:25:10.000
a series of vivid static
memories or ideas, sometimes--

00:25:10.000 --> 00:25:14.360
often-- hallucinatory,
like dreams themselves.

00:25:14.360 --> 00:25:18.080
Emotion grows more prominent
as we move downward.

00:25:18.080 --> 00:25:21.240
Daydreams and fantasies
often move us emotionally.

00:25:21.240 --> 00:25:24.020
Dry, emotionless
daydreams are rare.

00:25:24.020 --> 00:25:27.350
And we take it for granted
that we feel our dreams,

00:25:27.350 --> 00:25:29.840
often as mere
worrisome uneasiness,

00:25:29.840 --> 00:25:32.490
but sometimes acutely.

00:25:32.490 --> 00:25:36.670
Up-spectrum thought uses memory
like a faithful, colorless

00:25:36.670 --> 00:25:37.260
assistant.

00:25:37.260 --> 00:25:39.610
Down spectrum,
memory increasingly

00:25:39.610 --> 00:25:41.500
goes off on its own.

00:25:41.500 --> 00:25:43.910
The flow of
information from memory

00:25:43.910 --> 00:25:49.046
gradually supplants the
flow from outer reality

00:25:49.046 --> 00:25:53.750
as we sink into ourselves like
a flame sinking into a candle.

00:25:53.750 --> 00:25:56.750
The spectrum suggests
that dreaming

00:25:56.750 --> 00:26:00.590
is no strange intrusion
into ordinary thought.

00:26:00.590 --> 00:26:02.360
It is the natural
outcome of descending

00:26:02.360 --> 00:26:04.520
the spectrum, like
rolling down the runway

00:26:04.520 --> 00:26:07.750
is the natural
conclusion of landing

00:26:07.750 --> 00:26:11.790
an airplane, landing
in an airplane.

00:26:11.790 --> 00:26:15.040
Because our focus shifts
gradually from outside the self

00:26:15.040 --> 00:26:18.730
to inside, it's natural
that when we reach dreaming,

00:26:18.730 --> 00:26:22.280
it should be wholly
inside, or almost wholly.

00:26:22.280 --> 00:26:24.990
Because the role
of memory shifts

00:26:24.990 --> 00:26:28.602
from a well-behaved conveyor
of facts and figures

00:26:28.602 --> 00:26:32.350
to a supplier of increasingly
vivid and attention-demanding

00:26:32.350 --> 00:26:35.930
recollections and
ideas, it's natural

00:26:35.930 --> 00:26:37.860
that in dreams,
memory should be so

00:26:37.860 --> 00:26:39.830
vivid they seem like reality.

00:26:39.830 --> 00:26:42.075
After all, the
memories are becoming

00:26:42.075 --> 00:26:44.700
more and more colorful, more and
more attention-demanding, more

00:26:44.700 --> 00:26:48.676
and more vivid as we
drift down spectrum.

00:26:48.676 --> 00:26:50.610
And it's natural
that in the end,

00:26:50.610 --> 00:26:53.876
we find ourselves hallucinating.

00:26:53.876 --> 00:26:57.230
Hallucinations are the
most vivid, after all,

00:26:57.230 --> 00:26:59.690
of memories or ideas.

00:26:59.690 --> 00:27:04.830
Recalling an apple tree in
the fall with brilliant maple

00:27:04.830 --> 00:27:06.850
leaves all over and
apples hanging on the tree

00:27:06.850 --> 00:27:07.960
can be a vivid memory.

00:27:07.960 --> 00:27:11.350
But hallucinating that same
tree is even more vivid.

00:27:11.350 --> 00:27:15.020
So dreaming seems like the
natural endpoint of the process

00:27:15.020 --> 00:27:17.860
of descending the spectrum.

00:27:17.860 --> 00:27:20.290
We need to understand
this whole transition

00:27:20.290 --> 00:27:21.460
to understand the mind.

00:27:21.460 --> 00:27:23.710
And obviously, there's a lot
more to be said about it.

00:27:23.710 --> 00:27:27.770
But does AI need to
reproduce it all finally

00:27:27.770 --> 00:27:31.900
to achieve humanlike
intelligence?

00:27:31.900 --> 00:27:34.840
I will argue, or
have argued, that it

00:27:34.840 --> 00:27:36.560
needs to reproduce
every bit of it,

00:27:36.560 --> 00:27:38.540
the entire spectrum,
top to bottom.

00:27:38.540 --> 00:27:41.660
One important down-spectrum
activity, for example,

00:27:41.660 --> 00:27:43.500
is creativity.

00:27:43.500 --> 00:27:46.290
Reporters of personal
experience tend

00:27:46.290 --> 00:27:49.770
to suggest that creativity
happens when they are not

00:27:49.770 --> 00:27:53.240
thinking hard about a problem,
when they're thinking about it

00:27:53.240 --> 00:27:56.090
in the back of one's mind
is a phrase we often see,

00:27:56.090 --> 00:27:58.650
when mental focus is diffuse.

00:27:58.650 --> 00:28:01.070
In other words, when
they're down spectrum.

00:28:01.070 --> 00:28:05.240
Creativity often centers on
inventing new analogies, which

00:28:05.240 --> 00:28:07.400
allow us to see an old
problem in the light

00:28:07.400 --> 00:28:09.020
of a new comparison.

00:28:09.020 --> 00:28:11.100
But where does the
analogy itself come from

00:28:11.100 --> 00:28:12.950
is the interesting question.

00:28:12.950 --> 00:28:15.140
[INAUDIBLE] for example,
compares the flight

00:28:15.140 --> 00:28:17.370
of a small bird
across the evening sky

00:28:17.370 --> 00:28:24.070
to a crack in a smooth porcelain
cup, a very evocative line.

00:28:24.070 --> 00:28:26.070
But how did he
come up with that?

00:28:26.070 --> 00:28:30.040
Certainly not the first thing
you think of in this context.

00:28:30.040 --> 00:28:31.460
How did he invent the analogy?

00:28:31.460 --> 00:28:34.660
Possibly by using the fact that
these very different things

00:28:34.660 --> 00:28:36.930
made him feel the same way.

00:28:36.930 --> 00:28:40.880
Emotion is a hugely powerful
and personal encoding

00:28:40.880 --> 00:28:43.690
and summarizing
function that can sum up

00:28:43.690 --> 00:28:48.136
a whole complex scene in
just one subtle feeling.

00:28:48.136 --> 00:28:50.040
Using that feeling
as an index value,

00:28:50.040 --> 00:28:53.750
we can search out among huge
collections of candidates

00:28:53.750 --> 00:28:58.590
the odd candidate with a deep
resemblance to the thing we

00:28:58.590 --> 00:29:00.345
have in mind at the moment.

00:29:00.345 --> 00:29:03.920
I think that understanding
emotion as an encoding

00:29:03.920 --> 00:29:06.860
and simulating function is
one of the most important

00:29:06.860 --> 00:29:11.180
unsolved problems-- in fact,
ignored problems-- in AI

00:29:11.180 --> 00:29:15.410
today, ignored problems and
missed opportunities in AI

00:29:15.410 --> 00:29:18.610
today-- I would say
in computing today.

00:29:18.610 --> 00:29:24.230
In conclusion, once AI has
decided to notice and accept

00:29:24.230 --> 00:29:29.345
this, spectrum this basic
fact about the mind--

00:29:29.345 --> 00:29:33.280
namely that the pendulum
swings, that mind

00:29:33.280 --> 00:29:38.140
is one aspect of an organic,
living, changing, physical

00:29:38.140 --> 00:29:43.210
thing-- we'll be able to
reproduce it in software.

00:29:43.210 --> 00:29:46.100
We could be working on that
right now, this afternoon

00:29:46.100 --> 00:29:48.176
and this morning.

00:29:48.176 --> 00:29:52.700
The path from the spectrum to
genuine artificial intelligence

00:29:52.700 --> 00:29:53.780
is no short hop.

00:29:53.780 --> 00:29:56.750
It's more like a
flight to the moon.

00:29:56.750 --> 00:30:00.530
But once we had, in the
past, rocket engines, radios,

00:30:00.530 --> 00:30:02.980
computers, and a bunch of
other technologies in hand,

00:30:02.980 --> 00:30:04.860
the moon flight--
although it took

00:30:04.860 --> 00:30:08.910
genius and daring and tremendous
effort and labor-- was

00:30:08.910 --> 00:30:10.670
inevitable.

00:30:10.670 --> 00:30:13.260
The spectrum is just one
among the technologies

00:30:13.260 --> 00:30:16.650
that's necessary to make
true artificial intelligence.

00:30:16.650 --> 00:30:19.490
But it's one that
has been missing.

00:30:19.490 --> 00:30:21.510
Of course, once
we've got true AI,

00:30:21.510 --> 00:30:24.950
we've got the most dangerous
technology mankind will ever

00:30:24.950 --> 00:30:26.780
have developed.

00:30:26.780 --> 00:30:30.040
The sooner we start thinking
about that, the better.

00:30:30.040 --> 00:30:34.310
But for now, one problem at
a time, and I'll stop there.

00:30:34.310 --> 00:30:35.845
Thank you.

00:30:35.845 --> 00:30:39.741
[APPLAUSE]

00:30:42.180 --> 00:30:43.040
Are there questions?

00:30:43.040 --> 00:30:43.623
AUDIENCE: Yes.

00:30:43.623 --> 00:30:48.730
It seems like your-- the
difference between human

00:30:48.730 --> 00:30:51.830
and humanlike is not
something you seem

00:30:51.830 --> 00:30:54.330
to be caring too much about.

00:30:54.330 --> 00:30:56.660
And one of the things
that you do care about

00:30:56.660 --> 00:31:01.200
is having a physical
representation, and essentially

00:31:01.200 --> 00:31:06.610
the ability to feel, to
experience, the world.

00:31:06.610 --> 00:31:08.540
When you started the
talk, you started

00:31:08.540 --> 00:31:11.120
with talking about,
like, AlphaGo

00:31:11.120 --> 00:31:16.490
as a form of the mental
model of AI as it exists now.

00:31:16.490 --> 00:31:18.600
If the mental model
or the example

00:31:18.600 --> 00:31:21.510
was instead the
self-driving car,

00:31:21.510 --> 00:31:24.520
then it has a physical
manifestation.

00:31:24.520 --> 00:31:28.580
It is all about
experiencing the world.

00:31:28.580 --> 00:31:33.560
The key of its intelligence
is seeing every little dog

00:31:33.560 --> 00:31:36.580
or pedestrian or anything
that's happening in the world.

00:31:36.580 --> 00:31:39.170
And you could even
abstractly say

00:31:39.170 --> 00:31:45.870
that it has a state of its
mind that you could call pain

00:31:45.870 --> 00:31:47.611
when it intersects with a bus.

00:31:47.611 --> 00:31:48.110
You know?

00:31:48.110 --> 00:31:53.280
So isn't that the right
model to compare against?

00:31:53.280 --> 00:31:54.290
How is that different?

00:31:54.290 --> 00:31:57.590
And obviously, it's
not a human mind.

00:31:57.590 --> 00:32:04.042
But what is the bar for
starting to be more humanlike?

00:32:04.042 --> 00:32:05.750
DAVID GELERNTER: It's
an important issue.

00:32:05.750 --> 00:32:09.100
And AI loves to say
things like this.

00:32:09.100 --> 00:32:11.290
You could call it pain.

00:32:11.290 --> 00:32:15.560
You could also call it
whimsical nostalgia.

00:32:15.560 --> 00:32:17.668
You'd have no

00:32:17.668 --> 00:32:19.810
reason to do either one.

00:32:19.810 --> 00:32:22.860
But this is the crucial
issue between what's human

00:32:22.860 --> 00:32:25.470
and what's humanlike--
what's humanlike is

00:32:25.470 --> 00:32:26.640
purely an objective issue.

00:32:26.640 --> 00:32:29.880
What's human is a
subjective one, also.

00:32:29.880 --> 00:32:32.030
What's human has to do
with the state of mind

00:32:32.030 --> 00:32:33.470
that we experience.

00:32:33.470 --> 00:32:35.190
I don't have any
reason whatsoever

00:32:35.190 --> 00:32:38.800
to think that a self-driving
car has any experiences.

00:32:38.800 --> 00:32:40.790
Of course, it has sensory input.

00:32:40.790 --> 00:32:44.850
I have no reason to think that a
self-driving car sees anything.

00:32:44.850 --> 00:32:48.530
Of course it has sensory input,
and it deals algorithmically

00:32:48.530 --> 00:32:52.150
and using a variety of
techniques and heuristics

00:32:52.150 --> 00:32:53.370
from this input.

00:32:53.370 --> 00:32:58.110
But we know that we human
beings, when we see red,

00:32:58.110 --> 00:33:00.950
have a different experience
from when we see blue.

00:33:00.950 --> 00:33:02.950
In fact, we have an
idiom "seeing red."

00:33:02.950 --> 00:33:04.812
colors matter a lot.

00:33:04.812 --> 00:33:06.770
They matter more to some
people than to others.

00:33:06.770 --> 00:33:08.560
But we have experiences.

00:33:08.560 --> 00:33:12.360
It's not just a matter of noting
that the frequency of the light

00:33:12.360 --> 00:33:14.030
associated with
this painted wall

00:33:14.030 --> 00:33:16.170
is probably X as opposed
to the rug, which

00:33:16.170 --> 00:33:17.830
is Y. It feels different.

00:33:17.830 --> 00:33:18.920
We have favorite colors.

00:33:18.920 --> 00:33:22.930
When pain happens, we don't
say to ourselves, well,

00:33:22.930 --> 00:33:26.210
I could call that pain.

00:33:26.210 --> 00:33:28.980
We're in no doubt.

00:33:28.980 --> 00:33:31.680
It's a kind of experience.

00:33:31.680 --> 00:33:33.470
It's a character of experience.

00:33:33.470 --> 00:33:37.630
It's a particular,
qualitative experience.

00:33:37.630 --> 00:33:41.275
Philosophy of mind uses the word
qualia, of course, to describe,

00:33:41.275 --> 00:33:45.330
although in a rather confused
way, to describe feeling.

00:33:45.330 --> 00:33:51.290
So it is-- driverless cars
are major achievements of AI

00:33:51.290 --> 00:33:57.935
and are technically exciting
in many ways, in some ways.

00:33:57.935 --> 00:34:00.880
But they don't move
the ball a millimeter

00:34:00.880 --> 00:34:05.400
in terms of humanness as
opposed to humanlikeness.

00:34:05.400 --> 00:34:07.490
Is it useful to have
humanlike things?

00:34:07.490 --> 00:34:08.771
Absolutely.

00:34:08.771 --> 00:34:11.070
It's the only thing
AI can aspire to.

00:34:11.070 --> 00:34:14.580
It will never achieve
an inner world.

00:34:14.580 --> 00:34:17.330
It will never build a
subjective inner world using

00:34:17.330 --> 00:34:19.780
digital computers and software.

00:34:19.780 --> 00:34:21.469
But does that matter?

00:34:21.469 --> 00:34:23.159
Only to the car itself.

00:34:23.159 --> 00:34:25.610
And that's not the issue.

00:34:25.610 --> 00:34:31.550
So I completely agree that
we have sophisticated ways

00:34:31.550 --> 00:34:36.650
for dealing not only with formal
theorems of the sort whose

00:34:36.650 --> 00:34:38.949
proof got AI going.

00:34:38.949 --> 00:34:41.030
But you're dealing
with data of all sorts

00:34:41.030 --> 00:34:42.710
and dealing with
enormous databases

00:34:42.710 --> 00:34:45.989
and dealing with sensory
input and dealing with motion

00:34:45.989 --> 00:34:47.850
and dealing with
all sorts of things.

00:34:47.850 --> 00:34:51.870
We're making an enormous
amount of progress.

00:34:51.870 --> 00:34:54.460
We're lacking something
crucial, which

00:34:54.460 --> 00:34:57.030
is the big picture, the
way these things-- the way

00:34:57.030 --> 00:34:59.440
the intentional states relate
to the emotional states

00:34:59.440 --> 00:35:01.120
or the feeling states.

00:35:01.120 --> 00:35:04.320
We're lacking a clear view of
creativity and how it works.

00:35:04.320 --> 00:35:09.480
But it's not fair to say "and
we are lacking inner experience"

00:35:09.480 --> 00:35:12.110
because inner
experience is neither

00:35:12.110 --> 00:35:17.510
a necessity nor a possibility,
whereas objective performance

00:35:17.510 --> 00:35:21.010
is achievable and important.

00:35:21.010 --> 00:35:23.436
AUDIENCE: So your
idea of the spectrum

00:35:23.436 --> 00:35:25.530
reminds me of sort
of current writing

00:35:25.530 --> 00:35:28.390
and behavioral
economics, psychologists

00:35:28.390 --> 00:35:31.810
like Daniel Kahneman, "Thinking
Fast and Slow," getting away

00:35:31.810 --> 00:35:35.850
from the classic, purely
rational homo economicus

00:35:35.850 --> 00:35:38.170
trying to describe people
behaving and thinking

00:35:38.170 --> 00:35:39.320
as they really do.

00:35:39.320 --> 00:35:42.499
How would you relate
your work to that?

00:35:42.499 --> 00:35:44.540
DAVID GELERNTER: I think
the work is fascinating,

00:35:44.540 --> 00:35:49.810
and there is-- it used to be
said, as a matter of course,

00:35:49.810 --> 00:35:53.132
that there are
overlaps between AI

00:35:53.132 --> 00:35:56.700
and psychology,
cognitive psychology.

00:35:56.700 --> 00:35:59.000
In the past, it seemed to
me that cognitive psychology

00:35:59.000 --> 00:36:03.240
had been axiomatically
fixed on foundations

00:36:03.240 --> 00:36:05.140
that were not useful.

00:36:05.140 --> 00:36:07.900
The first thing that I read in
cognitive psychology textbooks

00:36:07.900 --> 00:36:11.580
and heard from cognitive
psychology teachers

00:36:11.580 --> 00:36:14.330
was the ground analogy,
that the mind relates

00:36:14.330 --> 00:36:17.340
to the brain the way software
relates to a computer, which

00:36:17.340 --> 00:36:20.550
is not only false but is
tremendously destructive,

00:36:20.550 --> 00:36:23.710
it seems to me, to our
thought in this field.

00:36:23.710 --> 00:36:25.420
Psychology in recent
years seems to me

00:36:25.420 --> 00:36:28.580
to be doing a lot of things that
are much more interesting, that

00:36:28.580 --> 00:36:32.950
are much truer, that are
much truer to human reality.

00:36:32.950 --> 00:36:35.120
The more intercourse
there is between AI

00:36:35.120 --> 00:36:39.550
and modern psychology--
and also the reawakening

00:36:39.550 --> 00:36:43.110
of depth psychology within
clinical psychiatry,

00:36:43.110 --> 00:36:48.750
where it had been dead and
crushed out like a Freudian

00:36:48.750 --> 00:36:50.705
cigarette butt for
more than a generation

00:36:50.705 --> 00:36:53.750
and seems to be
gradually reawakening.

00:36:53.750 --> 00:36:55.110
I think that's a wonderful sign.

00:36:55.110 --> 00:37:01.390
And we're entering,
finally-- we are re-entering

00:37:01.390 --> 00:37:04.340
an age of psychology of
the individual as opposed

00:37:04.340 --> 00:37:05.330
to the template.

00:37:05.330 --> 00:37:06.896
And that can only be good.

00:37:10.046 --> 00:37:11.420
AUDIENCE: You said
a couple times

00:37:11.420 --> 00:37:16.110
that it's not possible
for a computer system

00:37:16.110 --> 00:37:19.150
to have an inner life
and that kind of thing.

00:37:19.150 --> 00:37:24.290
How can you state that is-- I
hope I'm characterizing this

00:37:24.290 --> 00:37:27.730
correctly-- but state that
it's basically impossible when

00:37:27.730 --> 00:37:31.310
this is really all
about information.

00:37:31.310 --> 00:37:34.490
For example, if you simulate
creativity or problem-solving,

00:37:34.490 --> 00:37:38.550
you will have, I think, if
you're simulating it correctly,

00:37:38.550 --> 00:37:41.500
real ideas and
real solutions that

00:37:41.500 --> 00:37:46.800
come out of it, even if
simulating a computer enjoying

00:37:46.800 --> 00:37:50.294
the scent of a flower would
not be really enjoying

00:37:50.294 --> 00:37:51.210
the scent of a flower.

00:37:51.210 --> 00:37:53.585
Like, those seem like those
are kind of different things.

00:37:53.585 --> 00:37:56.610
And it seems like you
could have an inner life

00:37:56.610 --> 00:38:00.894
or an inner world, even
if you do not directly

00:38:00.894 --> 00:38:03.040
experience the physical world.

00:38:03.040 --> 00:38:04.860
DAVID GELERNTER:
Well, it depends,

00:38:04.860 --> 00:38:06.860
of course, what you
mean by an inner world.

00:38:06.860 --> 00:38:11.075
And the definition is up to you.

00:38:11.075 --> 00:38:14.830
If by inner world you
merely mean capacity

00:38:14.830 --> 00:38:18.770
to deal with input that we would
describe as sensory input--

00:38:18.770 --> 00:38:20.820
about the environment,
about the temperature,

00:38:20.820 --> 00:38:23.420
about the breeze, about
things like that-- then you

00:38:23.420 --> 00:38:24.330
have an inner world.

00:38:24.330 --> 00:38:28.415
That's a definition most
people would reject, though.

00:38:28.415 --> 00:38:30.040
AUDIENCE: Oh, I'm
thinking specifically

00:38:30.040 --> 00:38:32.540
about the-- for example,
the example you gave earlier

00:38:32.540 --> 00:38:37.740
about creativity and thinking
of an analogy for something

00:38:37.740 --> 00:38:39.920
and having it be in
the back of your mind.

00:38:39.920 --> 00:38:41.744
And you think of
something when you're not

00:38:41.744 --> 00:38:42.660
trying to think of it.

00:38:42.660 --> 00:38:45.880
Like, why couldn't a computer
do that if it's all just

00:38:45.880 --> 00:38:47.330
information?

00:38:47.330 --> 00:38:49.890
DAVID GELERNTER: I think a
computer absolutely could do it

00:38:49.890 --> 00:38:51.110
and should do it.

00:38:51.110 --> 00:38:55.081
I think a computer could
simulate the entire spectrum.

00:38:55.081 --> 00:38:59.240
I wrote years ago--
one of the things that

00:38:59.240 --> 00:39:01.860
was kicking around the
net-- that true AI won't

00:39:01.860 --> 00:39:04.260
be achieved until we have
computers that hallucinate.

00:39:04.260 --> 00:39:07.140
And I think this is achievable.

00:39:07.140 --> 00:39:10.730
The entire spectrum can exist
in the sense of performance.

00:39:10.730 --> 00:39:13.030
And I think it's very
important that it does exist.

00:39:13.030 --> 00:39:16.630
If I care about
AI, I care about AI

00:39:16.630 --> 00:39:22.870
being able to think creatively
as well as logically.

00:39:22.870 --> 00:39:25.240
To do that, I want it to
be able to-- creativity's

00:39:25.240 --> 00:39:26.240
not just a single thing.

00:39:26.240 --> 00:39:29.240
But one important thing is
this creation of new analogies.

00:39:29.240 --> 00:39:31.210
There are many ways to
create new analogies.

00:39:31.210 --> 00:39:35.780
But one important method
within that variety of methods

00:39:35.780 --> 00:39:37.430
is an emotional one.

00:39:37.430 --> 00:39:42.730
Now, if I'm [INAUDIBLE]
and I pull out of my memory

00:39:42.730 --> 00:39:44.350
the idea of a
cracked teacup when

00:39:44.350 --> 00:39:46.880
I'm looking up
and seeing a bird,

00:39:46.880 --> 00:39:49.470
I'm probably having an
emotional experience.

00:39:49.470 --> 00:39:50.650
That is, I feel something.

00:39:50.650 --> 00:39:53.230
It made me feel a certain way.

00:39:53.230 --> 00:39:55.840
I can't describe it in words
because feelings in general

00:39:55.840 --> 00:39:57.190
are indescribable.

00:39:57.190 --> 00:39:59.540
But I might say some
sort of warm, slight,

00:39:59.540 --> 00:40:03.280
tingling with a reminiscence
of a brown room in somewhere

00:40:03.280 --> 00:40:03.780
or other.

00:40:03.780 --> 00:40:05.170
I can't really describe it.

00:40:05.170 --> 00:40:07.220
But I have a feeling.

00:40:07.220 --> 00:40:10.910
Now, nonetheless, I could make
a computer do the same thing

00:40:10.910 --> 00:40:13.080
while feeling nothing.

00:40:13.080 --> 00:40:16.260
There is no reason why a
computer can't simulate

00:40:16.260 --> 00:40:21.170
the entire spectrum and
all the nuances of emotion,

00:40:21.170 --> 00:40:25.380
just as it's easy to do a
thought experiment in which we

00:40:25.380 --> 00:40:26.610
live in a zombie world.

00:40:26.610 --> 00:40:29.750
And none of us has in our
life, and we're all faking it.

00:40:29.750 --> 00:40:32.210
Or half of us are.

00:40:32.210 --> 00:40:36.380
It's a thought experiment which
has convinced many people,

00:40:36.380 --> 00:40:38.230
and is convincing, I think.

00:40:38.230 --> 00:40:42.460
And so yes, a computer can
simulate this whole spectrum.

00:40:42.460 --> 00:40:45.140
And the importance of
the spectrum in computing

00:40:45.140 --> 00:40:47.232
is that it can and should.

00:40:47.232 --> 00:40:49.200
We should be able
to build a computer

00:40:49.200 --> 00:40:51.740
that can jog up and
down the spectrum, that

00:40:51.740 --> 00:40:56.480
can move adaptively to
different points in the spectrum

00:40:56.480 --> 00:40:59.630
and that also drifts lower
so that it encounters

00:40:59.630 --> 00:41:01.760
the same environment and
these same set of problems

00:41:01.760 --> 00:41:05.520
from different standpoints as
it moves down the spectrum.

00:41:05.520 --> 00:41:07.900
It's not a goal of
this research to say,

00:41:07.900 --> 00:41:11.690
here's how you create a
computer with an inner life,

00:41:11.690 --> 00:41:15.050
or, on the other hand, to say,
my goal is to prove to you that

00:41:15.050 --> 00:41:16.840
you cannot do that.

00:41:16.840 --> 00:41:18.970
I take it as proved
by other people.

00:41:18.970 --> 00:41:20.850
Of course, it's
still under debate.

00:41:20.850 --> 00:41:23.180
It's not as if there's
only one side to it.

00:41:23.180 --> 00:41:27.780
But from my point of view, it's
proved that a digital computer

00:41:27.780 --> 00:41:30.665
will never feel anything.

00:41:30.665 --> 00:41:32.940
But taking that for
granted, we can still build

00:41:32.940 --> 00:41:35.410
enormously sophisticated AI.

00:41:35.410 --> 00:41:39.680
We can achieve a true artificial
intelligence, a true humanlike

00:41:39.680 --> 00:41:41.510
intelligence.

00:41:41.510 --> 00:41:44.290
But we can't unless
we see the spectrum

00:41:44.290 --> 00:41:48.654
and reproduce it, among a lot
of other things, of course.

00:41:48.654 --> 00:41:50.570
But one of the things
we need is the spectrum.

00:41:54.071 --> 00:41:54.835
AUDIENCE: Hi.

00:41:54.835 --> 00:41:59.910
My question is, why do we
need to distinguish feelings

00:41:59.910 --> 00:42:04.520
from other things
that you experience?

00:42:04.520 --> 00:42:07.100
Let me give a bit of
background why I'm asking this.

00:42:07.100 --> 00:42:11.540
In my simplistic
engineering view,

00:42:11.540 --> 00:42:15.130
feelings must be the
result of experience,

00:42:15.130 --> 00:42:20.460
biology, a current situation,
current state of my body,

00:42:20.460 --> 00:42:23.090
my machine.

00:42:23.090 --> 00:42:25.470
And with that, a
feeling is basically

00:42:25.470 --> 00:42:27.310
the result of all
those different things

00:42:27.310 --> 00:42:33.250
at any point in time, in
my personal understanding.

00:42:33.250 --> 00:42:36.760
So I'm wondering, if that's
not completely crazy,

00:42:36.760 --> 00:42:40.740
why could a computer
not also say, oh, OK.

00:42:40.740 --> 00:42:43.580
With all the things that I
currently experience and know

00:42:43.580 --> 00:42:45.410
and maybe-- I
don't know-- power,

00:42:45.410 --> 00:42:47.030
input is great or
it's not great,

00:42:47.030 --> 00:42:50.650
or whatever it is, I'm feeling
good, or I'm feeling sad,

00:42:50.650 --> 00:42:55.411
or whatever you could feel.

00:42:55.411 --> 00:42:56.536
DAVID GELERNTER: Excuse me.

00:42:56.536 --> 00:42:57.202
AUDIENCE: Sorry.

00:42:57.202 --> 00:43:00.580
So just to repeat, why do we
need to distinguish feelings

00:43:00.580 --> 00:43:01.890
from other things?

00:43:05.080 --> 00:43:07.430
DAVID GELERNTER: It certainly
is not completely crazy.

00:43:07.430 --> 00:43:10.470
In fact, it's a natural
reaction, I think,

00:43:10.470 --> 00:43:12.700
of nearly anybody and
everybody involved

00:43:12.700 --> 00:43:17.360
in the sciences or medicine
or engineering at first.

00:43:17.360 --> 00:43:20.590
And this was the
philosophical viewpoint

00:43:20.590 --> 00:43:22.900
associated with
materialism, when

00:43:22.900 --> 00:43:25.660
we look at the philosophy
of mind, roughly

00:43:25.660 --> 00:43:28.400
speaking, midcentury,
mid-20th century, middle

00:43:28.400 --> 00:43:29.920
of the last century.

00:43:29.920 --> 00:43:35.350
And the reason why materialism
died and was replaced

00:43:35.350 --> 00:43:38.010
by functionalism,
which is still pretty

00:43:38.010 --> 00:43:41.470
much the current philosophical
wisdom on philosophy of mind--

00:43:41.470 --> 00:43:43.730
the work of Hilary Putnam
and [INAUDIBLE] and others

00:43:43.730 --> 00:43:47.850
is because so many
people on second thought,

00:43:47.850 --> 00:43:51.210
when the physiologists
had said, you

00:43:51.210 --> 00:43:53.760
want to know what nostalgia it?

00:43:53.760 --> 00:44:01.602
It's these neurons firing in
the dopaminergic neo striatal

00:44:01.602 --> 00:44:05.260
cortex while these neurons are
suppressed in the something

00:44:05.260 --> 00:44:06.270
something something.

00:44:06.270 --> 00:44:10.220
And the potential here is
this, and the potential there

00:44:10.220 --> 00:44:11.465
is that.

00:44:11.465 --> 00:44:14.730
And on second thought,
people would say, all right.

00:44:14.730 --> 00:44:15.230
Fine.

00:44:15.230 --> 00:44:18.640
You're telling me what causes
my feeling of nostalgia.

00:44:18.640 --> 00:44:20.870
But where is the feeling itself?

00:44:20.870 --> 00:44:23.000
Where is the feeling
of nostalgia?

00:44:23.000 --> 00:44:26.240
If you're saying that there
is an equivalence in identity

00:44:26.240 --> 00:44:32.480
between a certain voltage or
between certain set of neuron

00:44:32.480 --> 00:44:36.830
activities and feelings,
I'll tell you you're wrong.

00:44:36.830 --> 00:44:39.700
You're comparing
apples and oranges.

00:44:39.700 --> 00:44:42.720
You're making the
original category error

00:44:42.720 --> 00:44:45.390
because a feeling
is not a voltage.

00:44:45.390 --> 00:44:46.890
A feeling has nothing
to-- a feeling

00:44:46.890 --> 00:44:49.060
is not a matter of neurons
or a particular chemical

00:44:49.060 --> 00:44:50.030
environment.

00:44:50.030 --> 00:44:54.630
We know a feeling
when we experience it.

00:44:54.630 --> 00:44:56.660
This is something that
human beings have managed

00:44:56.660 --> 00:44:58.880
to agree among themselves.

00:44:58.880 --> 00:45:00.630
This is the nature
of an inner life,

00:45:00.630 --> 00:45:04.950
the nature of a subjective
reaction, as opposed--

00:45:04.950 --> 00:45:10.130
there are a million reasons to
feel itchy because something

00:45:10.130 --> 00:45:13.770
touches your skin or there's
some pollen suffusing

00:45:13.770 --> 00:45:17.600
the atmosphere or
because of some entirely

00:45:17.600 --> 00:45:20.500
physiological event.

00:45:20.500 --> 00:45:22.270
But none of them is itchiness.

00:45:22.270 --> 00:45:25.070
Itchiness is an
experience, is a feeling.

00:45:25.070 --> 00:45:28.650
Now, in the final analysis,
this really is an assertion.

00:45:28.650 --> 00:45:33.940
It's an assertion more than a
logical, provable proposition.

00:45:33.940 --> 00:45:36.570
It's an assertion with
which functionalism started.

00:45:36.570 --> 00:45:39.440
And functionalism succeeded
as a philosophical approach

00:45:39.440 --> 00:45:45.310
because people have
proven unwilling to accept

00:45:45.310 --> 00:45:48.424
the identity theory,
so-called, or the materialism.

00:45:48.424 --> 00:45:50.090
I mean, there are
certainly materialists

00:45:50.090 --> 00:45:51.000
in the broader sense.

00:45:51.000 --> 00:45:53.080
But the philosophically
materialist

00:45:53.080 --> 00:45:57.480
view that a feeling
just was certain kind

00:45:57.480 --> 00:45:58.570
of neural activity.

00:45:58.570 --> 00:46:03.610
The neural activity seems to
leave something critical out,

00:46:03.610 --> 00:46:07.500
namely the feeling itself,
the qualitative feeling.

00:46:07.500 --> 00:46:10.614
So to conclude, there's not
a proof that you're wrong.

00:46:10.614 --> 00:46:12.530
And certainly, what
you're saying isn't crazy.

00:46:12.530 --> 00:46:14.760
Again, as I say, it's
a natural reaction.

00:46:17.446 --> 00:46:20.360
But it tends to
have been rejected

00:46:20.360 --> 00:46:24.820
by those who insist that
they can clearly distinguish

00:46:24.820 --> 00:46:28.970
a feeling on the one hand
from physiological events

00:46:28.970 --> 00:46:29.930
on the other.

00:46:29.930 --> 00:46:33.570
They're just different
kinds of event.

00:46:33.570 --> 00:46:34.195
AUDIENCE: OK.

00:46:34.195 --> 00:46:36.486
I got to believe this now.

00:46:36.486 --> 00:46:38.170
I don't agree, but I believe it.

00:46:38.170 --> 00:46:40.320
DAVID GELERNTER: Fair enough.

00:46:40.320 --> 00:46:44.620
AUDIENCE: So I'm tempted to
play a 60-second version of 20

00:46:44.620 --> 00:46:45.620
questions.

00:46:45.620 --> 00:46:49.290
Does a chimpanzee or an
orangutan really feel?

00:46:49.290 --> 00:46:52.666
Or are they a zombie in
your way of thinking?

00:46:56.372 --> 00:46:58.080
DAVID GELERNTER: I
don't have the vaguest

00:46:58.080 --> 00:47:00.060
idea in the absolute sense.

00:47:00.060 --> 00:47:04.410
But I would be astonished
if they didn't feel simply

00:47:04.410 --> 00:47:08.930
because the idea of relevant
similarity, which is introduced

00:47:08.930 --> 00:47:11.940
by philosophers of
mind in, I don't know,

00:47:11.940 --> 00:47:15.720
the '70s and the '80s-- although
is discussed by Wittgenstein

00:47:15.720 --> 00:47:20.790
the 1940s-- says, on what
basis do we attribute feelings

00:47:20.790 --> 00:47:23.310
to other creatures?

00:47:23.310 --> 00:47:25.035
And the answer is
very straightforward.

00:47:25.035 --> 00:47:26.660
We attribute feeling
to other creatures

00:47:26.660 --> 00:47:28.993
and so forth that remind us
of ourselves insofar as they

00:47:28.993 --> 00:47:30.290
seem humanlike.

00:47:30.290 --> 00:47:32.820
That's the psychological
approach that humans take.

00:47:32.820 --> 00:47:34.860
I take it, being a human being.

00:47:34.860 --> 00:47:38.370
And insofar as a chimpanzee
and orangutan seems

00:47:38.370 --> 00:47:41.360
very humanlike-- has a
face and arms and legs

00:47:41.360 --> 00:47:44.520
and so forth-- I
would be astonished

00:47:44.520 --> 00:47:46.590
if they didn't have feelings.

00:47:46.590 --> 00:47:49.293
We have a wonderful
macaw at home,

00:47:49.293 --> 00:47:52.540
who is less humanlike, in
a sense, than an orangutan,

00:47:52.540 --> 00:47:53.863
but much brighter.

00:47:53.863 --> 00:47:57.094
And why am I sure
he has feelings?

00:47:57.094 --> 00:47:58.760
Because of the way
he expresses himself,

00:47:58.760 --> 00:48:01.780
the articulate way he moves
around and moves his head

00:48:01.780 --> 00:48:04.180
and talks, to a limited extent.

00:48:04.180 --> 00:48:06.700
So this is just a
guess, obviously.

00:48:06.700 --> 00:48:14.880
We can't-- I could be a
legitimate non-solipsist

00:48:14.880 --> 00:48:17.516
and deny that animals
have feelings.

00:48:17.516 --> 00:48:19.077
But I think they do.

00:48:19.077 --> 00:48:20.160
AUDIENCE: So I understand.

00:48:20.160 --> 00:48:22.480
I wasn't trying to go to
the solipsism direction.

00:48:22.480 --> 00:48:25.310
I'm assuming that
you've got the charity

00:48:25.310 --> 00:48:26.920
to attribute us
the same feelings

00:48:26.920 --> 00:48:28.420
because you have
feelings, and we're

00:48:28.420 --> 00:48:30.003
similar enough that
you probably think

00:48:30.003 --> 00:48:31.412
that we have feelings, too.

00:48:31.412 --> 00:48:32.620
And I was just wondering if--

00:48:32.620 --> 00:48:35.076
DAVID GELERNTER: I don't
think it's charity, but--

00:48:35.076 --> 00:48:37.480
AUDIENCE: In the
Greician form, right?

00:48:37.480 --> 00:48:41.870
I'm just saying, if I look at
an orangutan or a chimpanzee,

00:48:41.870 --> 00:48:44.520
to me, they are
so close to human

00:48:44.520 --> 00:48:47.130
that the distinction
would-- I'd have

00:48:47.130 --> 00:48:49.490
to really work very hard
to try to draw a principle

00:48:49.490 --> 00:48:50.080
distinction.

00:48:50.080 --> 00:48:52.950
But I then do wonder
about the inductive case.

00:48:52.950 --> 00:48:55.400
Because then when you
go from the chimpanzee,

00:48:55.400 --> 00:48:58.820
just go down the animal kingdom,
and where do you draw the line?

00:48:58.820 --> 00:49:00.760
And on what principle
do you draw the line?

00:49:00.760 --> 00:49:02.341
Where do they stop
having feelings?

00:49:02.341 --> 00:49:04.090
Or do they have feelings
all the way down?

00:49:06.794 --> 00:49:09.460
DAVID GELERNTER: Are you really,
are you serious that you find--

00:49:09.460 --> 00:49:11.010
AUDIENCE: Yes, I am
absolutely serious.

00:49:11.010 --> 00:49:11.370
DAVID GELERNTER: --it
hard to draw the line?

00:49:11.370 --> 00:49:13.550
AUDIENCE: I have
seen chimpanzees.

00:49:13.550 --> 00:49:16.500
And to me, they are
scarily close to humans

00:49:16.500 --> 00:49:18.130
in a lot of ways.

00:49:18.130 --> 00:49:19.760
And I take them very seriously.

00:49:19.760 --> 00:49:21.260
DAVID GELERNTER:
Absolutely, they're

00:49:21.260 --> 00:49:23.070
close to humans
in a lot of ways.

00:49:23.070 --> 00:49:25.800
And there are a lot of reasons
to take them seriously.

00:49:25.800 --> 00:49:26.560
They can't talk.

00:49:26.560 --> 00:49:28.110
They have no language.

00:49:28.110 --> 00:49:28.870
It seems to me--

00:49:28.870 --> 00:49:29.610
AUDIENCE: So is
it just that they

00:49:29.610 --> 00:49:30.770
can't express their feelings?

00:49:30.770 --> 00:49:31.970
So I'm trying to understand.

00:49:31.970 --> 00:49:33.560
You're defining
certain predicates.

00:49:33.560 --> 00:49:35.060
You're saying this
one has feelings.

00:49:35.060 --> 00:49:35.420
DAVID GELERNTER: Right.

00:49:35.420 --> 00:49:36.020
AUDIENCE: That thing doesn't.

00:49:36.020 --> 00:49:36.390
It's a zombie.

00:49:36.390 --> 00:49:38.540
It looks like it's feeling
clever, but it doesn't really.

00:49:38.540 --> 00:49:40.670
I'm trying to just understand
the predicate better.

00:49:40.670 --> 00:49:42.230
How do you draw the
line between-- what's

00:49:42.230 --> 00:49:43.386
the characteristics of
something that has feelings?

00:49:43.386 --> 00:49:45.427
DAVID GELERNTER: Between
a zombie on the one hand

00:49:45.427 --> 00:49:49.024
and a chimpanzee on the
other, is that the question?

00:49:49.024 --> 00:49:51.440
AUDIENCE: No, I'm trying to
understand in the biological--

00:49:51.440 --> 00:49:52.830
DAVID GELERNTER: I
look at the zombie.

00:49:52.830 --> 00:49:54.755
The zombie is a completely
humanlike robot.

00:49:54.755 --> 00:49:57.430
You know, my first guess,
does he have feelings?

00:49:57.430 --> 00:49:59.050
Of course he does.

00:49:59.050 --> 00:50:01.270
I have no reason
to question whether

00:50:01.270 --> 00:50:04.262
any other human-- evidently
human being-- has feelings.

00:50:04.262 --> 00:50:06.220
Of course I'm going to
believe he has feelings.

00:50:06.220 --> 00:50:07.580
He may be my best friend.

00:50:07.580 --> 00:50:10.710
I may spend 25 years
discussing my deepest problems

00:50:10.710 --> 00:50:12.860
and feelings with him.

00:50:12.860 --> 00:50:15.780
I only learn that he
has no feelings when

00:50:15.780 --> 00:50:18.000
he says, by the way,
let me open my head

00:50:18.000 --> 00:50:20.110
and show you what's inside.

00:50:20.110 --> 00:50:21.330
And he says, you see?

00:50:21.330 --> 00:50:22.780
I'm software.

00:50:22.780 --> 00:50:26.090
I've got a computer here, and
I'm executing instructions.

00:50:26.090 --> 00:50:28.420
And then I can say, well, OK.

00:50:28.420 --> 00:50:32.160
I revert to the work of
other philosophers, which

00:50:32.160 --> 00:50:36.600
has convinced me that
executing instructions

00:50:36.600 --> 00:50:40.510
in the digital computer is never
sufficient to produce feelings.

00:50:40.510 --> 00:50:43.700
So it's a conclusion
that I draw logically,

00:50:43.700 --> 00:50:45.120
not on the basis of behavior.

00:50:45.120 --> 00:50:49.065
Behavior all points-- physical
manifestations all point

00:50:49.065 --> 00:50:49.860
in the other way.

00:50:49.860 --> 00:50:50.440
AUDIENCE: I'm just
asking logically.

00:50:50.440 --> 00:50:52.856
DAVID GELERNTER: And exactly
the same with the chimpanzee.

00:50:52.856 --> 00:50:57.690
Everything that the
chimpanzee does makes me say,

00:50:57.690 --> 00:50:59.270
this guy must have feelings.

00:50:59.270 --> 00:51:00.494
Of course he has feelings.

00:51:00.494 --> 00:51:01.160
Is he conscious?

00:51:01.160 --> 00:51:02.361
Of course he's conscious.

00:51:02.361 --> 00:51:03.860
Now, if there were
some way that you

00:51:03.860 --> 00:51:06.575
could prove to me
that that was false,

00:51:06.575 --> 00:51:08.740
then I'd accept it, if
it were a valid proof.

00:51:08.740 --> 00:51:11.310
But I certainly-- but
I can't even concede

00:51:11.310 --> 00:51:12.930
what such a proof would be.

00:51:12.930 --> 00:51:16.264
And in the lack of such a proof,
I'm going to say, of course.

00:51:16.264 --> 00:51:17.930
Of course these
creatures have feelings.

00:51:17.930 --> 00:51:19.630
Of course they're conscious.

00:51:19.630 --> 00:51:22.300
And I'm also going to agree
with those philosophers who

00:51:22.300 --> 00:51:26.555
say as resemblance tails
off, my willingness

00:51:26.555 --> 00:51:28.837
to believe that these
other creatures are

00:51:28.837 --> 00:51:31.420
conscious in the sense that I
am or have feelings in the sense

00:51:31.420 --> 00:51:35.700
that I am-- I'm more convinced
that a chimpanzee does

00:51:35.700 --> 00:51:38.340
than a rabbit does, more
convinced that a rabbit does

00:51:38.340 --> 00:51:41.250
than a turtle does, more
convinced that a turtle does

00:51:41.250 --> 00:51:42.950
than a worm does.

00:51:42.950 --> 00:51:45.400
This isn't an absolute
black and white thing.

00:51:45.400 --> 00:51:48.170
This is tailing off of
probabilities, in my view,

00:51:48.170 --> 00:51:50.740
of the world, and of
guesses about things

00:51:50.740 --> 00:51:52.390
that I can never know.

00:51:52.390 --> 00:51:54.960
AUDIENCE: So last question--
assume, go somewhere down

00:51:54.960 --> 00:51:55.710
in that hierarchy.

00:51:55.710 --> 00:51:57.670
And assume at some
point, decades from now,

00:51:57.670 --> 00:52:00.020
neuroscience actually
works, and we actually

00:52:00.020 --> 00:52:01.360
solve some small creature.

00:52:01.360 --> 00:52:03.350
That is, we can
predict it accurately.

00:52:03.350 --> 00:52:06.250
We understand how to grow it
from one cell, all of that,

00:52:06.250 --> 00:52:08.800
maybe a worm or something.

00:52:08.800 --> 00:52:11.880
Would that be troublesome
if you were previously

00:52:11.880 --> 00:52:14.160
attributing feelings
to it, and then we

00:52:14.160 --> 00:52:15.500
solved the neuroscience?

00:52:15.500 --> 00:52:16.962
Would you then say, I was wrong?

00:52:16.962 --> 00:52:18.420
Or would there be
something that we

00:52:18.420 --> 00:52:20.586
could solve the neuroscience
of that you would still

00:52:20.586 --> 00:52:23.990
admit into the things
that can have feelings?

00:52:23.990 --> 00:52:26.390
DAVID GELERNTER: The more
we learn, the better.

00:52:26.390 --> 00:52:31.390
And there's no reason to
think that the physiology

00:52:31.390 --> 00:52:34.526
of subjective life
is unsolvable.

00:52:34.526 --> 00:52:36.942
I have no reason to think that
it's an unsolvable problem.

00:52:36.942 --> 00:52:38.210
AUDIENCE: OK.

00:52:38.210 --> 00:52:40.584
DAVID GELERNTER: I just don't
think it's been solved yet.

00:52:40.584 --> 00:52:42.395
And I don't know how
it will be solved.

00:52:42.395 --> 00:52:43.820
AUDIENCE: Hi.

00:52:43.820 --> 00:52:45.650
Kind of similar to
the last question,

00:52:45.650 --> 00:52:48.780
but I'm curious what you think
about the thought experiment

00:52:48.780 --> 00:52:52.180
where with sufficiently
advanced technology,

00:52:52.180 --> 00:52:54.870
we take a live human,
who we probably agree

00:52:54.870 --> 00:52:56.190
is conscious and has feelings.

00:52:56.190 --> 00:52:59.650
And one by one, we would replace
the neurons in their brain

00:52:59.650 --> 00:53:02.980
with computers which
perfectly simulate

00:53:02.980 --> 00:53:04.620
the behavior of the neurons.

00:53:04.620 --> 00:53:08.470
And this can take as long--
over a long period as you want.

00:53:08.470 --> 00:53:10.230
And so bit by bit,
the human brain

00:53:10.230 --> 00:53:13.460
becomes a digital computer.

00:53:13.460 --> 00:53:16.950
Do you think at some point,
that brain becomes a zombie?

00:53:16.950 --> 00:53:18.115
Or what's happening there?

00:53:18.115 --> 00:53:19.490
DAVID GELERNTER:
Yes, absolutely.

00:53:19.490 --> 00:53:23.314
This is a thought experiment
associated with [INAUDIBLE].

00:53:23.314 --> 00:53:25.230
I didn't hear the first
part of what you said,

00:53:25.230 --> 00:53:27.714
and maybe that's exactly
what you did say.

00:53:27.714 --> 00:53:31.920
[INAUDIBLE] has been
quoted, sort of,

00:53:31.920 --> 00:53:35.620
as authoritative by a
lot of people, Hofstadter

00:53:35.620 --> 00:53:37.960
and many others.

00:53:37.960 --> 00:53:40.616
I think it's completely
unconvincing.

00:53:40.616 --> 00:53:42.910
As a thought experiment,
first of all,

00:53:42.910 --> 00:53:45.760
you tell me you bring somebody
in and gradually replace

00:53:45.760 --> 00:53:47.950
all his neurons with
electronic circuits.

00:53:47.950 --> 00:53:51.380
And then at the end
of the procedure,

00:53:51.380 --> 00:53:53.095
you say, how are you feeling?

00:53:53.095 --> 00:53:55.390
You have a conversation
with him the whole time,

00:53:55.390 --> 00:53:57.010
so you keep track
of what's going on.

00:53:57.010 --> 00:54:00.095
And when it's all over,
you say, how are things?

00:54:00.095 --> 00:54:03.080
And he says, I feel
exactly the same as before.

00:54:03.080 --> 00:54:04.580
This raises a
fundamental question

00:54:04.580 --> 00:54:07.465
about thought experiments,
which-- what is illegitimate

00:54:07.465 --> 00:54:08.465
in a thought experiment?

00:54:08.465 --> 00:54:11.140
You know, when I do
this thought experiment,

00:54:11.140 --> 00:54:13.945
the subject is
guaranteed to die.

00:54:13.945 --> 00:54:17.770
It makes absolutely no sense
to say that I'm gradually

00:54:17.770 --> 00:54:19.900
pulling out the
organic components,

00:54:19.900 --> 00:54:23.700
pulling out the chemical
environment in which I work,

00:54:23.700 --> 00:54:26.560
the physiochemical
environment, replacing them

00:54:26.560 --> 00:54:28.900
by electronic parts,
and asserting that it

00:54:28.900 --> 00:54:30.860
will make no difference.

00:54:30.860 --> 00:54:32.410
Granted, we do
thought experiments

00:54:32.410 --> 00:54:37.959
in order to explore
possibilities

00:54:37.959 --> 00:54:39.750
that are difficult to
achieve in real life.

00:54:39.750 --> 00:54:41.790
But nonetheless, not
every thought experiment

00:54:41.790 --> 00:54:42.796
is admissible.

00:54:42.796 --> 00:54:44.420
If I say I've done
a thought experiment

00:54:44.420 --> 00:54:46.450
in which I'm standing
on the top of the hill

00:54:46.450 --> 00:54:48.360
wearing gigantic bat wings.

00:54:48.360 --> 00:54:51.860
And I jump off the cliff,
and I can see myself soaring

00:54:51.860 --> 00:54:55.610
from Cambridge to Boston.

00:54:55.610 --> 00:54:58.070
I can say, well, that's a
good thought experiment.

00:54:58.070 --> 00:54:59.820
But unfortunately,
I can't accept it.

00:54:59.820 --> 00:55:01.730
It doesn't hold up logically.

00:55:01.730 --> 00:55:04.140
And that is the
way the [INAUDIBLE]

00:55:04.140 --> 00:55:05.760
thought experiment strikes me.

00:55:05.760 --> 00:55:10.240
But I think what would happen
is as you replace neurons

00:55:10.240 --> 00:55:13.790
of your unfortunate
graduate student's brain

00:55:13.790 --> 00:55:17.450
or whoever you've chosen
to test this out on,

00:55:17.450 --> 00:55:20.570
what's going to happen is he's
going to lose consciousness.

00:55:20.570 --> 00:55:23.050
And then he's going to
start feeling very strange.

00:55:23.050 --> 00:55:24.600
I mean, I can't say exactly.

00:55:24.600 --> 00:55:26.072
But something is
going to happen.

00:55:26.072 --> 00:55:27.780
He's not just going
to sit there chatting

00:55:27.780 --> 00:55:31.240
about baseball with you as
his brain is dug out piece

00:55:31.240 --> 00:55:31.740
by piece.

00:55:31.740 --> 00:55:33.330
I can't accept that.

00:55:33.330 --> 00:55:35.950
So yeah, would he
become a zombie?

00:55:35.950 --> 00:55:37.600
He would become dead.

00:55:37.600 --> 00:55:41.300
If you really were able to
maintain the organic framework

00:55:41.300 --> 00:55:44.750
while having replaced the
organic brain with a computer

00:55:44.750 --> 00:55:47.230
in this incremental way--
if you were able to do that,

00:55:47.230 --> 00:55:48.260
yeah, a zombie.

00:55:48.260 --> 00:55:50.533
But certainly not
more than a zombie.

00:55:53.650 --> 00:55:54.490
AUDIENCE: Hi.

00:55:54.490 --> 00:55:56.030
Thanks for the great talk.

00:55:56.030 --> 00:55:57.745
It was very interesting.

00:55:57.745 --> 00:56:00.070
In your talk, you
seemed to be focusing

00:56:00.070 --> 00:56:02.392
on feelings and emotions.

00:56:02.392 --> 00:56:04.170
And a couple times,
you actually mentioned

00:56:04.170 --> 00:56:06.104
the problem of qualia.

00:56:06.104 --> 00:56:08.470
Once you said that
you don't believe

00:56:08.470 --> 00:56:11.300
that executing the set of
instructions in a computer

00:56:11.300 --> 00:56:13.620
will reproduce the feeling.

00:56:13.620 --> 00:56:16.020
By that, you probably meant
reproduce the inner world,

00:56:16.020 --> 00:56:17.890
the actual feeling.

00:56:17.890 --> 00:56:19.210
Now, why stop there?

00:56:19.210 --> 00:56:22.630
I think the same can
be applied to thinking.

00:56:22.630 --> 00:56:26.060
Do you think that executing
a set of instructions

00:56:26.060 --> 00:56:29.580
in a computer will actually
produce the actual thinking?

00:56:29.580 --> 00:56:32.010
What I'm trying to say is
that the qualia applied

00:56:32.010 --> 00:56:36.147
to the thought, to thinking.

00:56:36.147 --> 00:56:37.730
DAVID GELERNTER:
It's a good question.

00:56:37.730 --> 00:56:43.180
And absolutely, qualia
are always present.

00:56:43.180 --> 00:56:48.780
I think it would be
virtually impossible to make

00:56:48.780 --> 00:56:54.550
yourself think without being
aware of any qualia at all.

00:56:54.550 --> 00:56:58.310
And of course, we know, in
fact, that to steer your mind,

00:56:58.310 --> 00:56:59.800
you use impulses.

00:56:59.800 --> 00:57:00.966
You use emotions.

00:57:00.966 --> 00:57:03.340
You say, this direction is
more attractive or it's easier

00:57:03.340 --> 00:57:04.700
or it's more beautiful.

00:57:04.700 --> 00:57:06.210
This problem is more pressing.

00:57:06.210 --> 00:57:06.920
I'll go this way.

00:57:06.920 --> 00:57:08.320
This is more dangerous.

00:57:08.320 --> 00:57:08.910
It scares me.

00:57:08.910 --> 00:57:11.190
So I'll solve this problem
and ignore that one.

00:57:11.190 --> 00:57:15.740
So emotions are
there as guide posts,

00:57:15.740 --> 00:57:20.900
just as I'm proving a theorem in
my maximum mathematician mode,

00:57:20.900 --> 00:57:25.770
I need memory constantly to
fetch methods and results

00:57:25.770 --> 00:57:27.664
and remember what I
did five minutes ago.

00:57:27.664 --> 00:57:29.080
It's not as if
memory isn't there.

00:57:29.080 --> 00:57:33.530
But memory and emotions
don't play the vivid role--

00:57:33.530 --> 00:57:36.330
they don't play the controlling,
vivid role that they

00:57:36.330 --> 00:57:40.130
do when you're falling asleep,
much less when you are asleep.

00:57:40.130 --> 00:57:43.420
So it's not that they
don't exist up spectrum.

00:57:43.420 --> 00:57:45.360
And by the same token,
when you're dreaming,

00:57:45.360 --> 00:57:48.160
it's not the case that
you aren't thinking at all

00:57:48.160 --> 00:57:50.460
and you can remember nothing.

00:57:50.460 --> 00:57:52.670
Sometimes, you can
remember nothing.

00:57:52.670 --> 00:57:56.200
But it's not unusual to remember
some fragments of dreams.

00:57:56.200 --> 00:57:59.070
It's not unusual to
think about what's

00:57:59.070 --> 00:58:00.280
happening to some extent.

00:58:00.280 --> 00:58:04.890
But we clearly
don't think about it

00:58:04.890 --> 00:58:06.350
in the same skeptical,
critical way

00:58:06.350 --> 00:58:08.183
we would think when we
were paying attention

00:58:08.183 --> 00:58:12.050
and when our focus was
concentrated rather

00:58:12.050 --> 00:58:14.450
than diffuse, towards the
bottom of the spectrum.

00:58:14.450 --> 00:58:17.520
So yeah, I never want
to say there are qualia.

00:58:17.520 --> 00:58:20.830
But I do want to say that qualia
play a far more important role

00:58:20.830 --> 00:58:23.450
as incrementally,
gradually, they

00:58:23.450 --> 00:58:27.760
come on strong and stronger
as we move down the spectrum.

00:58:27.760 --> 00:58:33.020
AUDIENCE: So why does organic
matter produce consciousness?

00:58:33.020 --> 00:58:38.400
If zombies were possible-- I
mean, I think ants are zombies.

00:58:38.400 --> 00:58:43.740
And ant colonies are quite
evolutionarily successful.

00:58:43.740 --> 00:58:47.530
Why would nature not
perfectly happily create

00:58:47.530 --> 00:58:49.890
little troupes of
chimpanzees that are not

00:58:49.890 --> 00:58:53.190
conscious but nevertheless
express emotion to one

00:58:53.190 --> 00:58:56.220
another for the social
function of making

00:58:56.220 --> 00:58:59.694
the troupe of chimpanzees happy,
or-- well, not literally happy.

00:58:59.694 --> 00:59:00.360
They're zombies.

00:59:00.360 --> 00:59:02.401
But making them more
successful gathering bananas

00:59:02.401 --> 00:59:04.890
or whatever happens there.

00:59:04.890 --> 00:59:07.310
I mean, I think you're
committing yourself

00:59:07.310 --> 00:59:12.400
to a one-step-above science
thinking here by saying,

00:59:12.400 --> 00:59:16.040
OK, we have the natural
world that creatures evolve,

00:59:16.040 --> 00:59:19.360
and they produce life, and
they live and do things.

00:59:19.360 --> 00:59:21.370
But why not just stop at ants?

00:59:21.370 --> 00:59:24.670
If there was-- there has
to be that extra thing.

00:59:24.670 --> 00:59:27.580
And if it's not produced
purely from nature,

00:59:27.580 --> 00:59:30.790
purely from physics, then
what is producing it?

00:59:30.790 --> 00:59:32.680
Why is it there?

00:59:32.680 --> 00:59:35.510
DAVID GELERNTER: I apologize
for creating the impression

00:59:35.510 --> 00:59:37.270
that feelings are not
produced by physics.

00:59:37.270 --> 00:59:39.590
I don't claim that at all.

00:59:39.590 --> 00:59:42.550
I'm taking a strictly
materialist view of this.

00:59:42.550 --> 00:59:45.560
But there's a big
difference between saying,

00:59:45.560 --> 00:59:47.540
certainly, this is
a natural phenomena,

00:59:47.540 --> 00:59:52.380
and physics is all there is,
at least in this discussion.

00:59:52.380 --> 00:59:54.980
There's a big difference
between saying that and saying,

00:59:54.980 --> 00:59:57.200
I can explain to you
exactly how it works.

00:59:57.200 --> 01:00:00.100
We have to recognize the
existence of unsolved problems.

01:00:00.100 --> 01:00:02.890
As far as I'm concerned,
subjective feelings

01:00:02.890 --> 01:00:06.160
are created and
explicable by physics.

01:00:06.160 --> 01:00:07.610
But we don't know how.

01:00:07.610 --> 01:00:11.770
And as far as you're saying, why
didn't evolution stop, I mean,

01:00:11.770 --> 01:00:14.930
this is a very,
very good question.

01:00:14.930 --> 01:00:18.885
It's a deep question, not
for me but for Darwin.

01:00:18.885 --> 01:00:21.560
That is, if you
believe philosophers--

01:00:21.560 --> 01:00:24.110
who are not quite
unanimous but are nearly

01:00:24.110 --> 01:00:25.760
unanimous in
philosophy of mind--

01:00:25.760 --> 01:00:29.140
that consciousness
accomplishes nothing,

01:00:29.140 --> 01:00:35.120
that-- I argue in the book
that one could believe

01:00:35.120 --> 01:00:37.420
that consciousness itself
plays a certain role

01:00:37.420 --> 01:00:40.230
in analogy-forming, in
memory, because of what you

01:00:40.230 --> 01:00:41.900
might call resonance effects.

01:00:41.900 --> 01:00:43.360
It's just speculation.

01:00:43.360 --> 01:00:47.530
Certainly the mainstream
view is that consciousness

01:00:47.530 --> 01:00:50.990
does absolutely nothing
for you whatsoever.

01:00:50.990 --> 01:00:52.674
And then the question
is, why should

01:00:52.674 --> 01:00:54.340
the mechanism of
consciousness, whatever

01:00:54.340 --> 01:00:56.520
it is-- it's some sort
of physical mechanism.

01:00:56.520 --> 01:00:57.420
It isn't magic.

01:00:57.420 --> 01:01:01.532
It isn't divine intervention,
as far as I'm concerned.

01:01:01.532 --> 01:01:03.460
Why should it have evolved?

01:01:03.460 --> 01:01:07.250
And the answer is, I don't know.

01:01:07.250 --> 01:01:09.700
The answer is, that's a very
good question for Darwin.

01:01:09.700 --> 01:01:14.612
And the hypothesis that
Darwinian evolution

01:01:14.612 --> 01:01:22.230
is a perfect, proven
whole, it's just not true.

01:01:22.230 --> 01:01:26.325
If you talk to evolutionary
and developmental biologists,

01:01:26.325 --> 01:01:28.670
you'll find all
sorts of them who

01:01:28.670 --> 01:01:35.065
will give you all sorts
of profound unhappinesses

01:01:35.065 --> 01:01:37.180
they have with Darwin,
particularly about

01:01:37.180 --> 01:01:39.220
the formation and
evolution of body plans,

01:01:39.220 --> 01:01:42.600
the organization of creatures,
the HOX genes, so-called,

01:01:42.600 --> 01:01:45.330
in a larger sense, as well as,
of course, the older questions

01:01:45.330 --> 01:01:47.180
about the fossil records.

01:01:47.180 --> 01:01:52.979
That's a good example of an
area in which we don't know.

01:01:52.979 --> 01:01:55.020
Darwin certainly has a
better theory than anybody

01:01:55.020 --> 01:01:56.980
else right now.

01:01:56.980 --> 01:01:58.960
But that doesn't mean
we know he's right.

01:01:58.960 --> 01:02:00.360
We don't know he's right.

01:02:00.360 --> 01:02:05.520
And consciousness is a difficult
problem for standard Darwinism

01:02:05.520 --> 01:02:06.730
and neo-Darwinism.

01:02:06.730 --> 01:02:07.440
Good question.

01:02:07.440 --> 01:02:10.457
I don't know how
it's going to end up.

01:02:10.457 --> 01:02:11.540
AUDIENCE: Quick follow-up.

01:02:11.540 --> 01:02:12.500
It'll be really short.

01:02:12.500 --> 01:02:15.876
I mean, I think zombies
are preposterous,

01:02:15.876 --> 01:02:20.270
that you could have this
whole thing that-- but I also

01:02:20.270 --> 01:02:23.560
think a disembodied intelligence
running in a data center that's

01:02:23.560 --> 01:02:27.470
fully emotionally aware
is preposterous, also.

01:02:27.470 --> 01:02:29.610
Like, I think my viewpoint's
in between yours.

01:02:29.610 --> 01:02:32.680
But I just find
it very difficult

01:02:32.680 --> 01:02:36.600
to accept zombies and the
idea that we have something

01:02:36.600 --> 01:02:38.790
that's indistinguishable
from consciousness

01:02:38.790 --> 01:02:39.860
but not conscious.

01:02:39.860 --> 01:02:42.260
I mean, ants act like ants.

01:02:42.260 --> 01:02:43.930
DAVID GELERNTER:
Well, the reason

01:02:43.930 --> 01:02:46.350
I disagree-- people
tend to disagree

01:02:46.350 --> 01:02:49.265
sort of on experiential,
empirical grounds.

01:02:49.265 --> 01:02:52.260
20 years ago, when I first
started working on this,

01:02:52.260 --> 01:02:56.130
I built a program with
an adjustable focus knob.

01:02:56.130 --> 01:02:58.480
And the idea is that when
you turn the dial down,

01:02:58.480 --> 01:03:00.470
it would move down the spectrum.

01:03:00.470 --> 01:03:03.460
It would start to, instead
of logically chaining

01:03:03.460 --> 01:03:06.000
its pseudo-memories
together, it would

01:03:06.000 --> 01:03:08.720
start doing something more
like free associating.

01:03:08.720 --> 01:03:11.530
And eventually, when you had the
dial turned all the way down,

01:03:11.530 --> 01:03:15.110
it would wander off and pay
no attention to you at all.

01:03:15.110 --> 01:03:18.650
Now, this did absolutely
nothing of any value.

01:03:18.650 --> 01:03:20.415
It was an interesting demo.

01:03:20.415 --> 01:03:24.300
It showed me how much I didn't
know about my own theory.

01:03:24.300 --> 01:03:27.135
Now that I figured out things
that were not clear to me then,

01:03:27.135 --> 01:03:29.030
I'd like to go back
to the software

01:03:29.030 --> 01:03:30.500
and continue from there.

01:03:30.500 --> 01:03:33.720
And I don't see any
reason why I shouldn't

01:03:33.720 --> 01:03:36.320
be able to build a
highly-accurate simulation

01:03:36.320 --> 01:03:38.670
of the spectrum.

01:03:38.670 --> 01:03:40.719
But by the same token,
I don't see any reason

01:03:40.719 --> 01:03:42.260
to believe that that
simulation would

01:03:42.260 --> 01:03:44.290
have consciousness or feelings.

01:03:44.290 --> 01:03:48.017
So it's an open point.

01:03:48.017 --> 01:03:48.850
AUDIENCE: Thank you.

01:03:48.850 --> 01:03:49.505
DAVID GELERNTER: Thank you.

01:03:49.505 --> 01:03:50.395
MALE SPEAKER: Thank
you very much.

01:03:50.395 --> 01:03:50.840
[APPLAUSE]

01:03:50.840 --> 01:03:51.965
DAVID GELERNTER: Thank you.

01:03:51.965 --> 01:03:54.770
[APPLAUSE]

