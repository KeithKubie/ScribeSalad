WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.000
So you may have noticed a bit of redundancy

00:00:02.000 --> 00:00:05.000
in our handling of "quoted strings".

00:00:05.000 --> 00:00:09.000
We return the entire matched text,

00:00:09.000 --> 00:00:11.000
which includes these double quotes at the end.

00:00:11.000 --> 00:00:14.000
But, in some sense, they're not as much part of the meaning,

00:00:14.000 --> 00:00:18.000
as they are beginning and ending markers to tell us when the string starts.

00:00:18.000 --> 00:00:20.000
This is our default token value,

00:00:20.000 --> 00:00:24.000
but we might want to take a small pair of scissors to this string,

00:00:24.000 --> 00:00:28.000
and snip off the quotes at the beginning--and at the end.

00:00:28.000 --> 00:00:31.000
Here we have an example of a token definition

00:00:31.000 --> 00:00:34.000
that does just that.

00:00:34.000 --> 00:00:37.000
After matching the right kind of string,

00:00:37.000 --> 00:00:39.000
we take the token value--

00:00:39.000 --> 00:00:41.000
the entire thing--

00:00:41.000 --> 00:00:44.000
and we're going to use substring selection,

00:00:44.000 --> 00:00:46.000
starting at character 1--

00:00:46.000 --> 00:00:48.000
this is going to be character 1--

00:00:48.000 --> 00:00:50.000
and going up to, but not including,

00:00:50.000 --> 00:00:52.000
character negative 1.

00:00:52.000 --> 00:00:55.000
Now if you haven't seen this trick before in Python this might surprise you a bit,

00:00:55.000 --> 00:00:58.000
but you can count back from the end of the string,

00:00:58.000 --> 00:01:00.000
using negative numbers.

00:01:00.000 --> 00:01:04.000
So this is actually the negative first character.

00:01:04.000 --> 00:01:06.000
And remember that substring inclusion

00:01:06.000 --> 00:01:12.000
starts at 1 and goes up to, but not including, the negative 1.

00:01:12.000 --> 00:01:15.000
So this is going to get everything from the "q"

00:01:15.000 --> 00:01:17.000
over to the "s" in strings--

00:01:17.000 --> 00:01:20.000
or in other words, have exactly the effect that we wanted.

00:01:20.000 --> 00:01:22.000
Cute little trick, huh?

00:01:22.000 --> 00:01:25.000
So now I'm going to show you how to make

00:01:25.000 --> 00:01:27.000
a lexical analyzer--which, recall--

00:01:27.000 --> 00:01:31.000
is just a bunch of token definitions put together.

00:01:31.000 --> 00:01:33.000
I'm going to write it out in Python

00:01:33.000 --> 00:01:35.000
and we'll follow along.

00:01:35.000 --> 00:01:38.000
This top line--the import statement--is a lot like Import RE.

00:01:38.000 --> 00:01:43.000
It's telling Python where to find our lexical analyzer software

00:01:43.000 --> 00:01:46.000
or libraries that we're going to build upon.

00:01:46.000 --> 00:01:50.000
Just like regular expressions were called RE to save space,

00:01:50.000 --> 00:01:55.000
a lexical analyzer is just called "lex"--to save space.

00:01:55.000 --> 00:01:59.000
And now I'm going to give a list of all of the tokens that I care about.

00:01:59.000 --> 00:02:03.000
Here, I'm just going to be concerned with the 6 that we've previously spoken about:

00:02:03.000 --> 00:02:08.000
the Left Angle bracket; the Left Angle bracket, followed by a slash; the Right Angle bracket--

00:02:08.000 --> 00:02:11.000
these 3 make tags--

00:02:11.000 --> 00:02:15.000
an Equal sign, Strings that are surrounded by quotes,

00:02:15.000 --> 00:02:17.000
and every other word.

00:02:17.000 --> 00:02:19.000
I'm also going to use a little shortcut.

00:02:19.000 --> 00:02:22.000
Before, we used a Whitespace token,

00:02:22.000 --> 00:02:27.000
but if you like, you can write the word t_ignore instead

00:02:27.000 --> 00:02:32.000
and, implicitly, we'll ignore everything matching this regular expression.

00:02:32.000 --> 00:02:34.000
Here's my first token definition rule.

00:02:34.000 --> 00:02:36.000
It's for LANGLESLASH.

00:02:36.000 --> 00:02:39.000
Here's the regular expression that it matches.

00:02:39.000 --> 00:02:41.000
We return the text, unchanged.

00:02:41.000 --> 00:02:43.000
Here's another rule for the Left Angle bracket,

00:02:43.000 --> 00:02:47.000
the regular expression that it matches--and we return the text, unchanged.

00:02:47.000 --> 00:02:50.000
And you'll note that I have the LANGELSLASH rule ahead--

00:02:50.000 --> 00:02:52.000
before it--in the file.

00:02:52.000 --> 00:02:55.000
And that's because I want this one to win, on ties.

00:02:55.000 --> 00:02:58.000
If I see a Left Angle, followed by a slash,

00:02:58.000 --> 00:03:00.000
I want it to be the LANGLESLASH (token)--

00:03:00.000 --> 00:03:04.000
and not the Left Angle, followed by--say--a WORD(token).

00:03:04.000 --> 00:03:06.000
More on that in just a bit; I'll test that out and show it to you.

00:03:06.000 --> 00:03:09.000
Here's our rule for the Right Angle bracket.

00:03:09.000 --> 00:03:12.000
Here's our rule for the Equal sign token.

00:03:12.000 --> 00:03:14.000
Note that while these are long--

00:03:14.000 --> 00:03:17.000
they take up a bit of space--they're not actually particularly complicated.

00:03:17.000 --> 00:03:20.000
This has mostly been listing 5 regular expressions.

00:03:20.000 --> 00:03:22.000
Here's one now.

00:03:22.000 --> 00:03:25.000
This one is a little bit more complicated--here's are rule for STRING(token)s.

00:03:25.000 --> 00:03:28.000
Here's our regular expression that matches it.

00:03:28.000 --> 00:03:31.000
And there I am, dropping off--shaving off--

00:03:31.000 --> 00:03:33.000
the surrounding double quotes,

00:03:33.000 --> 00:03:35.000
just as you've seen before.

00:03:35.000 --> 00:03:39.000
Finally, there's our definition for the WORD(token).

00:03:39.000 --> 00:03:41.000
And now what we want to do is use

00:03:41.000 --> 00:03:44.000
these regular expressions, together--these token definitions--

00:03:44.000 --> 00:03:46.000
to break up a Web page.

00:03:46.000 --> 00:03:51.000
So here, I'll make a variable that holds the text of a hypothetical Web page.

00:03:51.000 --> 00:03:53.000
"This is my webpage!"

00:03:53.000 --> 00:03:57.000
Let's make it more exciting; Ho, ho--this is at least 10 percent more exciting!

00:03:57.000 --> 00:04:01.000
This function call tells our lexical analysis library

00:04:01.000 --> 00:04:05.000
that we want to use all of the token definitions above

00:04:05.000 --> 00:04:09.000
to make a lexical analyzer, and break up strings.

00:04:09.000 --> 00:04:12.000
This function call tells it which string to break up.

00:04:12.000 --> 00:04:14.000
I want to break up this Web page:

00:04:14.000 --> 00:04:16.000
"This is my webpage!"

00:04:16.000 --> 00:04:19.000
Now, recall that the output of a lexical analyzer

00:04:19.000 --> 00:04:21.000
is a list of tokens.

00:04:21.000 --> 00:04:24.000
I want to print out every element of that list.

00:04:24.000 --> 00:04:28.000
This call, .token, returns the next token that's available.

00:04:28.000 --> 00:04:31.000
If there are not more tokens,

00:04:31.000 --> 00:04:33.000
then we're going to break out of this loop.

00:04:33.000 --> 00:04:35.000
Otherwise, we print out the token.

00:04:35.000 --> 00:04:38.000
Well, let's go see what sort of output we get.

00:04:38.000 --> 00:04:41.000
The odds of me having written this, making no mistakes

00:04:41.000 --> 00:04:45.000
the first time, from scratch, are about zero.

00:04:45.000 --> 00:04:47.000
Let's go see what happens.

00:04:47.000 --> 00:04:51.000
Oh! I actually don't really believe it!

00:04:51.000 --> 00:04:54.000
We can see the output here at the bottom:

00:04:54.000 --> 00:04:57.000
LexToken (WORD, ' T ',' h ', ' i ', ' s '

00:04:57.000 --> 00:05:00.000
but it's not quite the output I was expecting.

00:05:00.000 --> 00:05:03.000
Oh, here's the mistake that I made--

00:05:03.000 --> 00:05:08.000
right now, I only have one character in t_WORD

00:05:08.000 --> 00:05:10.000
and if you look down here, instead of seeing

00:05:10.000 --> 00:05:12.000
the word, "This"--for "This is my webpage!"--

00:05:12.000 --> 00:05:15.000
I have each letter spelled out separately.

00:05:15.000 --> 00:05:17.000
Let me fix that.

00:05:17.000 --> 00:05:21.000
And now we get more of the output that we were expecting.

00:05:21.000 --> 00:05:24.000
Our first token is ' This ';

00:05:24.000 --> 00:05:26.000
our next token is a word, ' is '.

00:05:26.000 --> 00:05:28.000
Then we saw the Left Angle bracket,

00:05:28.000 --> 00:05:31.000
a word, ' b '--for bold,

00:05:31.000 --> 00:05:33.000
the Right Angle bracket; a word, ' my ';

00:05:33.000 --> 00:05:35.000
the LANGLESLASH,

00:05:35.000 --> 00:05:37.000
and then the word, ' webpage '.

