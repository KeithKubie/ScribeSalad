WEBVTT
Kind: captions
Language: en

00:00:00.780 --> 00:00:04.700
&gt;&gt; From the Library of
Congress in Washington, D.C.

00:00:23.090 --> 00:00:25.670
&gt;&gt; Steve Antosca: Going
to give a presentation

00:00:25.670 --> 00:00:32.620
about percussion composition that
I created with my two colleagues,

00:00:32.620 --> 00:00:33.920
William Brent and Ross Karre.

00:00:34.790 --> 00:00:38.230
And before we get started I want to
thank all the folks at the Library

00:00:38.230 --> 00:00:40.760
of Congress for inviting us here.

00:00:40.760 --> 00:00:44.660
And it's a great honor for
us to give this presentation.

00:00:45.690 --> 00:00:51.940
And we have a lot to cover so I'm
just going to jump right into it.

00:00:51.940 --> 00:00:55.430
This is a breakdown of what
we're going to do this afternoon.

00:00:55.430 --> 00:00:56.730
I'm going to talk about some

00:00:56.730 --> 00:01:01.450
of the compositional elements
behind creating Habitat,

00:01:01.450 --> 00:01:04.000
and some of the history behind it.

00:01:04.870 --> 00:01:07.200
William Brent is going to
talk about the technology

00:01:07.200 --> 00:01:08.660
that he created for the piece.

00:01:08.660 --> 00:01:13.380
And Ross is going to talk
about video aspects of it.

00:01:13.380 --> 00:01:15.980
Then we're going to
take a brief break

00:01:15.980 --> 00:01:19.000
for about five minutes while we
get set up for the performance.

00:01:20.250 --> 00:01:24.000
And Ross and William are then
going to perform three movements

00:01:24.000 --> 00:01:28.790
from Habitat, the opening, which
is what you see in the center here,

00:01:28.790 --> 00:01:33.390 position:56%
and then third movement called
household, which is on the far side,

00:01:33.390 --> 00:01:36.000
and then triangles,
which is in the front.

00:01:37.520 --> 00:01:44.270
So this piece, Habitat, was
written for the 35th anniversary

00:01:44.270 --> 00:01:49.070 position:56%
of the east building of the National
Gallery Art and was also part

00:01:49.070 --> 00:01:52.160
of the 65th Annual Music Festival.

00:01:52.160 --> 00:02:00.270
And this came about because
I had created a concert

00:02:00.270 --> 00:02:06.980 position:56%
for the 70th anniversary of the west
building of the National Gallery,

00:02:06.980 --> 00:02:11.550
and the gallery asked me
to compose a new piece

00:02:11.550 --> 00:02:14.000
for the 35th anniversary
of the east building.

00:02:15.310 --> 00:02:21.960
And knowing the space very
well I immediately thought

00:02:21.960 --> 00:02:26.070
about a piece I had
conceived of around 2005

00:02:26.070 --> 00:02:29.270
that involved a percussionist
wandering through a kind

00:02:29.270 --> 00:02:32.860
of spiral galaxy of
percussion instruments.

00:02:32.860 --> 00:02:35.870
And as he moved through
these instruments more

00:02:35.870 --> 00:02:38.890
and more technology
was added to the piece

00:02:38.890 --> 00:02:42.620 position:56%
to add certain levels of complexity.

00:02:42.620 --> 00:02:45.700
And the piece kind of laid
dormant for several years,

00:02:45.700 --> 00:02:49.500
but when I was invited to create
this piece for the east building,

00:02:49.500 --> 00:02:53.000
to create a piece, I
immediately thought of Habitat.

00:02:54.180 --> 00:03:01.880
And William and Ross and I sat down
for about 2 1/2 years and mapped

00:03:01.880 --> 00:03:06.870
out all the parts of it,
and thought out strategy

00:03:06.870 --> 00:03:09.160
of how to create the piece.

00:03:09.160 --> 00:03:10.920
And as I said, I'm going
to tell you a little bit

00:03:10.920 --> 00:03:14.880
about the composition
components of it.

00:03:14.880 --> 00:03:18.460
I'm going to talk specifically
about four parts,

00:03:18.460 --> 00:03:23.830
what I refer to as transformations,
the architecture and the space,

00:03:23.830 --> 00:03:26.940
the percussionist's
path, and finally,

00:03:26.940 --> 00:03:29.000
score design, structure and time.

00:03:30.650 --> 00:03:34.770
And these were the four
elements of the composition

00:03:34.770 --> 00:03:39.070
that I decided were critical
to make to realize this piece,

00:03:39.070 --> 00:03:44.850 position:56%
to make it into what I was thinking.

00:03:44.850 --> 00:03:47.400
So first of all, transformation.

00:03:47.400 --> 00:03:53.100
I was thinking about three
elements that were important

00:03:53.100 --> 00:03:56.020
to make the concept of
transformation happen.

00:03:56.020 --> 00:04:00.500
First of all, thinking of music
as a -- as an abstract language.

00:04:01.060 --> 00:04:08.340
It's unique in that it
can create abstract images

00:04:08.340 --> 00:04:10.220
for the listening audience.

00:04:10.220 --> 00:04:15.920
Then the second is the
transformational power of music.

00:04:15.920 --> 00:04:21.940
And the third is music as sound
composed across a time canvas.

00:04:21.940 --> 00:04:23.970
And I'll talk more
about the third one

00:04:23.970 --> 00:04:26.910 position:56%
in detail toward the end of my talk.

00:04:26.910 --> 00:04:32.180
So, first of all, music as a
singular abstract language.

00:04:32.180 --> 00:04:35.000
I've always been fascinated by
the abstractedness of music.

00:04:35.630 --> 00:04:38.330
You can make it whatever you want

00:04:38.330 --> 00:04:45.320
and different people perceive
what you create differently.

00:04:45.320 --> 00:04:48.810 position:56%
And music not like words and speech.

00:04:48.810 --> 00:04:55.010
You need to be able to comprehend
what someone is saying in order

00:04:55.010 --> 00:04:57.060
to have a conversation with them.

00:04:57.060 --> 00:05:00.280
As an example, if you were having
a conversation with someone --

00:05:00.280 --> 00:05:03.060 position:56%
if someone is speaking to you in a
foreign language and you don't speak

00:05:03.060 --> 00:05:06.000 position:56%
that language, you can't
comprehend what they're telling you.

00:05:06.730 --> 00:05:11.450
Whereas with music, you --
in order to understand it

00:05:11.450 --> 00:05:14.670
at a very high level you
generally are trained in some way

00:05:14.670 --> 00:05:18.840
as a musician, but that might
not affect your enjoyment

00:05:18.840 --> 00:05:20.140
or appreciation of music.

00:05:20.140 --> 00:05:24.050
You don't have to be trained
as a musician to understand it

00:05:24.050 --> 00:05:26.960
or enjoy it or get
pleasure out of it.

00:05:26.960 --> 00:05:30.910
So because of its abstract
nature you can do a lot of things

00:05:30.910 --> 00:05:34.310
with music that can be
appreciated hopefully

00:05:34.310 --> 00:05:36.000
by a wider range of people.

00:05:38.300 --> 00:05:44.720
And, for me, the -- all art has to
be transformational in some way.

00:05:44.720 --> 00:05:48.350 position:56%
That's the real power behind art and
the -- and the power behind music.

00:05:48.350 --> 00:05:53.510
And what I was attempting
to do with Habitat is

00:05:53.510 --> 00:05:59.190 position:56%
to use the performance base to blend
acoustic sounds of instrument --

00:05:59.190 --> 00:06:02.910
of the percussion instruments,
technology, and the architecture

00:06:02.910 --> 00:06:06.660
of the space to create a
transformational affect.

00:06:07.390 --> 00:06:10.030
And I've wanted to do this
not just for the person --

00:06:10.030 --> 00:06:13.920
the audience listening, but
for the percussionists as well.

00:06:13.920 --> 00:06:16.270
So in Habitat the performer goes

00:06:16.270 --> 00:06:20.540
through this transformational
journey, which I'll describe

00:06:20.540 --> 00:06:22.800
in a little bit, but it also is one

00:06:22.800 --> 00:06:27.330
that hopefully the
audience enjoys as well.

00:06:29.120 --> 00:06:35.240
And this element of music composed
across a time canvas is one

00:06:35.240 --> 00:06:38.050
that is very important to me.

00:06:38.050 --> 00:06:43.250
I -- all of my music is very
deliberately mapped out,

00:06:43.250 --> 00:06:49.220
and I'll show you some examples
later, and it is very specific

00:06:49.220 --> 00:06:58.160
in terms of the timings
and how its performed,

00:06:58.160 --> 00:07:01.420
even when there are
aleatoric sections

00:07:01.420 --> 00:07:06.780
of it there are boundary conditions
that the performer has to adhere

00:07:06.780 --> 00:07:10.860
to in order to play that part.

00:07:10.860 --> 00:07:15.940
So after I thought about all
of these transformative forces

00:07:15.940 --> 00:07:17.840
for Habitat, I came up with this --

00:07:17.840 --> 00:07:21.000
what I refer to as the Habitat
transformation algorithm.

00:07:21.730 --> 00:07:29.110
And it consisted of three parts,
the composer, the percussionist,

00:07:29.110 --> 00:07:32.330
the computer musician,
and architecture.

00:07:32.330 --> 00:07:37.410
So each of these characters
has a unique role to play.

00:07:37.410 --> 00:07:41.930
The composer creates the source
material, or the seed idea.

00:07:41.930 --> 00:07:46.280
And essentially the composer
puts all of this on paper

00:07:46.280 --> 00:07:51.670
and designs the entire piece, but
it's the percussionist in this case

00:07:51.670 --> 00:07:54.730
who makes the piece come alive.

00:07:54.730 --> 00:07:59.900
The percussionist realizes
these black smudges

00:07:59.900 --> 00:08:03.790
on these dots on a piece of paper.

00:08:03.790 --> 00:08:09.000
So it's critical for the
percussionist to be able to sort

00:08:09.000 --> 00:08:16.330
of own the piece and give life to
what the composer puts on paper.

00:08:17.100 --> 00:08:23.280
In the case of Habitat and all
other computer music, it --

00:08:23.280 --> 00:08:26.650
the role of a computer
musician is --

00:08:26.650 --> 00:08:30.720
opens up a new threshold
where new sounds are created,

00:08:30.720 --> 00:08:34.220
and ideas that the composer has

00:08:34.220 --> 00:08:41.560
and that the percussionist
performs are taken to a new level.

00:08:41.560 --> 00:08:51.340
And the -- with Habitat the
percussionist acts as a trigger

00:08:51.340 --> 00:08:54.820
for some of these sounds,
and the computer musician,

00:08:54.820 --> 00:08:59.900
in this case William Brent,
modifies the incoming sounds

00:08:59.900 --> 00:09:03.000
and also generates some
new sounds for the piece.

00:09:03.370 --> 00:09:06.510
And all of this happens
within the context

00:09:06.510 --> 00:09:09.050
of the architecture of a space.

00:09:09.050 --> 00:09:12.350
And in the east building

00:09:12.350 --> 00:09:16.720
of the National Gallery
there is voluminous space.

00:09:16.720 --> 00:09:23.000
It's really an extraordinary
place to perform a piece of music.

00:09:23.940 --> 00:09:31.010
And I have some pictures that
I'll show you later of layout.

00:09:31.010 --> 00:09:34.360
And our challenge was to put
all of these pieces together

00:09:34.360 --> 00:09:41.640
and make them coherent
inside a monstrously huge

00:09:41.640 --> 00:09:44.280
architectural space.

00:09:44.280 --> 00:09:48.750
So that leads me to this
part, architecture and spaces.

00:09:48.750 --> 00:09:52.130
This is the east building of the --

00:09:52.130 --> 00:09:56.130
the east building atrium of
the National Gallery of Art.

00:09:56.130 --> 00:09:58.850
And if you -- if you've
never been there,

00:09:58.850 --> 00:10:01.660
it's really an extraordinary
place to visit.

00:10:02.040 --> 00:10:04.860
And it's a fabulous place for art.

00:10:04.860 --> 00:10:09.070
And we were very privileged
to be able to present --

00:10:09.070 --> 00:10:16.840
to premier Habitat in this
beautiful space and to be allowed

00:10:16.840 --> 00:10:21.750
to explore the sonic
possibilities in the atrium.

00:10:22.760 --> 00:10:29.180
So knowing that we were going to
present Habitat in the atrium,

00:10:29.180 --> 00:10:33.050
I felt what needed to
happen is that we needed

00:10:33.050 --> 00:10:35.610
to create a sonic ecosystem.

00:10:35.610 --> 00:10:46.800 position:56%
And I developed a set of
parameters that we needed to explore

00:10:46.800 --> 00:10:50.550
to make this happen, and the first
was thinking about the architecture

00:10:50.550 --> 00:10:53.950
of the space as a kind
of inverted sculpture.

00:10:53.950 --> 00:11:02.380
And when we presented Habitat
we had multiple workstations,

00:11:02.380 --> 00:11:05.640
performance stations
as you see here.

00:11:05.640 --> 00:11:09.140
And these work beautifully
in the atrium.

00:11:09.140 --> 00:11:11.660
They look like pieces of artwork,

00:11:11.660 --> 00:11:15.550
sculptures that were
inside the atrium.

00:11:15.550 --> 00:11:22.020
So we also -- I have done a number
of performances inside the atrium.

00:11:22.020 --> 00:11:28.810
And I was -- I spent a lot of time
before the performance of Habitat,

00:11:28.810 --> 00:11:32.170
and before composing it,
listening to the space,

00:11:32.170 --> 00:11:35.730
walking around the space,
actually bringing speakers

00:11:35.730 --> 00:11:40.630
into various places and corners
of the space and projecting sound

00:11:40.630 --> 00:11:43.090
to find out what it sounded

00:11:43.090 --> 00:11:49.400
like in all the various spaces
and areas of the atrium.

00:11:49.400 --> 00:11:54.630
And I also recognize that there
would be two kinds of participants

00:11:54.630 --> 00:11:57.770
in this, the creators,
that is William, Ross,

00:11:57.770 --> 00:11:59.980
and I in this case,
and the audience.

00:11:59.980 --> 00:12:06.360
And what we needed to do was
to shape a unifying experience

00:12:06.360 --> 00:12:13.300
through our creativity and connect
with the audience and have them go

00:12:13.300 --> 00:12:15.800
on this journey with
the percussionist.

00:12:15.800 --> 00:12:20.210
So this is just a kind of shopping
list of things that I was thinking

00:12:20.210 --> 00:12:25.170 position:56%
about for the creative side of this.

00:12:25.170 --> 00:12:29.280
I won't go through this list, but
you can take a quick look at them.

00:12:29.280 --> 00:12:33.080
And they're very ordinary
things, like being concerned

00:12:33.080 --> 00:12:36.750
about speaker placement, the
movement of the performer

00:12:36.750 --> 00:12:40.120
through the space, but also the
more important one was auditory

00:12:40.120 --> 00:12:41.420
spatial awareness.

00:12:41.420 --> 00:12:46.570
That is, the three of us spent time
in the space thinking about how

00:12:46.570 --> 00:12:51.470
to set things up and what would
work best for the performance.

00:12:51.470 --> 00:12:54.820
Also, the final one,
vertical and horizontal

00:12:54.820 --> 00:12:57.490
and surround sound
was very important.

00:12:57.490 --> 00:13:02.650
We weren't thinking of this in
terms of a traditional performance

00:13:02.650 --> 00:13:06.430
in a space like this where sound
is projected right at the audience,

00:13:06.430 --> 00:13:10.010
but rather we wanted to
surround the audience with sound.

00:13:10.010 --> 00:13:12.850
We wanted sound to be
able to move vertically

00:13:12.850 --> 00:13:15.490
as well as move at the audience.

00:13:15.490 --> 00:13:23.070
And the audience's role was
obviously a lot more static.

00:13:23.070 --> 00:13:28.670
We wanted to have the audience
respond to the performance,

00:13:28.670 --> 00:13:31.050
and in some performances I've done

00:13:31.050 --> 00:13:34.770
in the atrium we've actually
asked the audience to move

00:13:34.770 --> 00:13:39.620
around to listen to the performance
from different perspectives.

00:13:39.620 --> 00:13:44.080
And so the audience is --
inhabits the sound space.

00:13:44.080 --> 00:13:47.940
And that was one very
important goal for us.

00:13:47.940 --> 00:13:51.120
We wanted the audience
to feel like they were

00:13:51.120 --> 00:13:55.940
within this massive instrument
that we were creating.

00:13:55.940 --> 00:14:04.000
And so I recognize that
the best way to do this was

00:14:04.000 --> 00:14:08.280
to have a solo performer,
not to write a piece

00:14:08.280 --> 00:14:11.760
for multiple performers because I
wanted the focus of the audience,

00:14:11.760 --> 00:14:14.320
the listener, to be on
one performer's journey

00:14:14.320 --> 00:14:17.720
so that they always knew that
sound was either being triggered

00:14:17.720 --> 00:14:20.700
in some way or created
by the percussionist,

00:14:20.700 --> 00:14:26.830
or by some processing that's
being done to that performer.

00:14:26.830 --> 00:14:32.900
So there were -- it's not
perception that who was --

00:14:32.900 --> 00:14:37.370
who was responsible for creating
the sound and the performance

00:14:37.370 --> 00:14:42.010
so they could focus
on one performer.

00:14:42.010 --> 00:14:44.820
And this idea led me to something

00:14:44.820 --> 00:14:51.390
that I call the multiplicity
of effects.

00:14:51.390 --> 00:14:56.770
And I'm very interested in blending
all of these sounds together.

00:14:56.770 --> 00:14:58.350
When you think about
any performance,

00:14:58.350 --> 00:15:00.550
just a regular acoustic
instrument performance,

00:15:00.550 --> 00:15:03.550
what you're really hearing
is the acoustic instrument

00:15:03.550 --> 00:15:07.580
and that instrument in the
space it's being performed in.

00:15:07.580 --> 00:15:09.790
And if you think about
performances that you've heard

00:15:09.790 --> 00:15:14.960 position:56%
in difference venues, the instrument
can sound very different depending

00:15:14.960 --> 00:15:18.190
on the shape and the design,
the architecture of that space.

00:15:18.190 --> 00:15:25.180
So what we were attempting to do
is blending the acoustic instrument

00:15:25.180 --> 00:15:27.650
through traditional
performance techniques.

00:15:27.650 --> 00:15:31.170
You'll Ross play these instruments
in very traditional ways.

00:15:31.170 --> 00:15:34.190
You'll also see him play
them in nontraditional ways,

00:15:34.190 --> 00:15:37.200
what we refer to as extended
performance techniques.

00:15:37.200 --> 00:15:38.920
Then there's also computer
processing,

00:15:38.920 --> 00:15:43.440
which will be very obvious to.

00:15:43.440 --> 00:15:47.810
And then the effect, the impact
of the architecture of this space.

00:15:47.810 --> 00:15:53.060
So this is what I refer to as
the multiplicity of effects.

00:15:53.060 --> 00:15:58.720
Then finally, computer music
technology, these are the things

00:15:58.720 --> 00:16:00.710
that the three of discussed
and wanted

00:16:00.710 --> 00:16:03.830
to create, and William realized.

00:16:03.830 --> 00:16:08.720
So we were able to set up a
multi-channel computer system

00:16:08.720 --> 00:16:13.090
and it's all controlled
through William's computer.

00:16:13.090 --> 00:16:16.750
There's also real-time computer
processing that's happening

00:16:16.750 --> 00:16:22.120
and percussion samples that are
modified and advanced by William

00:16:22.120 --> 00:16:24.120
and played during the piece.

00:16:24.120 --> 00:16:27.440
And then, as you will hear during
the performance part of this,

00:16:27.440 --> 00:16:33.990
there's spatialization control
through the computer, but also,

00:16:33.990 --> 00:16:37.340
you won't see this today, but in
the performance in the atrium,

00:16:37.340 --> 00:16:41.930
as Ross performed the piece
and moved around the hall,

00:16:41.930 --> 00:16:47.150
the sound sources were coming
from different directions.

00:16:48.280 --> 00:16:51.150
So that leads me to the next part,

00:16:51.150 --> 00:16:55.100
which is the percussionist's
path through the atrium.

00:16:55.100 --> 00:17:01.100
So once again, this is the
atrium of the east building.

00:17:01.100 --> 00:17:06.480
And after I decided I was going to
write Habitat I spent a lot of time

00:17:06.480 --> 00:17:10.540
in the space wandering around
all the areas that you see here.

00:17:10.540 --> 00:17:16.020
And I created this
diagram to create --

00:17:16.020 --> 00:17:21.290
to map out what I thought
of as a spiral galaxy,

00:17:21.290 --> 00:17:23.570
where you see down in
numbers one and seven,

00:17:23.570 --> 00:17:25.820
this is the starting
and the ending point.

00:17:25.820 --> 00:17:30.170
And Ross moves from there to number
two and three, and the number four,

00:17:30.170 --> 00:17:36.140
five, and then six is the bridge
up at the top of the atrium.

00:17:36.140 --> 00:17:39.090
And then he moves over to
the left side of the screen

00:17:39.090 --> 00:17:42.470
and there's actually a hidden
elevator back there, which he takes

00:17:42.470 --> 00:17:46.550
down to the floor to
finish the piece.

00:17:46.550 --> 00:17:49.630
So I've got some images of
-- before I get to those.

00:17:49.630 --> 00:17:53.110
These are the seven
movements of Habitat.

00:17:53.110 --> 00:17:55.740
And then after -- between
six and seven you can see

00:17:55.740 --> 00:17:58.680
that there's a little prepared
piano interlude, and I'll explain

00:17:58.680 --> 00:18:00.340
that in a -- in a moment.

00:18:00.340 --> 00:18:07.910 position:56%
We're going to perform sections one,
three, and six in a little while.

00:18:07.910 --> 00:18:12.360
So this is what the opening
and closing section look

00:18:12.360 --> 00:18:15.620
like on the floor of the atrium.

00:18:15.620 --> 00:18:18.550
So Ross started out
from this position.

00:18:18.550 --> 00:18:21.890
And you can see these
beautiful images he projected.

00:18:21.890 --> 00:18:26.300
There are three projectors, one
under the bridge on the left side,

00:18:26.300 --> 00:18:28.510
and then one on the far wall,
and one on the near wall.

00:18:28.510 --> 00:18:30.860
And if you look at the far right

00:18:30.860 --> 00:18:35.680
of that image you can see the
third station, the flower pots.

00:18:35.680 --> 00:18:36.980
So this is the opening.

00:18:36.980 --> 00:18:41.380
You then move a piano that was
used as a percussion instrument,

00:18:41.380 --> 00:18:42.690
treated as a percussion instrument.

00:18:42.690 --> 00:18:45.800
He's playing the inside
of it in this section.

00:18:45.800 --> 00:18:52.290
Then this is a Harry Bertoia
sculpture that was in the atrium

00:18:52.290 --> 00:18:53.950
at the time of the performance.

00:18:53.950 --> 00:18:58.990
And we received permission from
the National Gallery to allow Ross

00:18:58.990 --> 00:19:02.530
to play it, and you can see he's
wearing white gloves and he has

00:19:02.530 --> 00:19:04.530
to run his hands across these rods.

00:19:04.530 --> 00:19:07.120
These are, I think,
17 foot long rods

00:19:07.120 --> 00:19:09.150
and they made absolutely
gorgeous sound.

00:19:09.150 --> 00:19:13.610
And so when he was moving from
the second station, the piano,

00:19:13.610 --> 00:19:16.920
to the third station, which
is the household station,

00:19:16.920 --> 00:19:22.450
he walked passed this and
just moved it with his hands,

00:19:22.450 --> 00:19:27.370
and it actually rang and
played for several minutes.

00:19:27.370 --> 00:19:32.400
And then this is the stairway up to
the third station, the flower pots.

00:19:32.400 --> 00:19:35.630
Here's a close up of
Ross playing those.

00:19:35.630 --> 00:19:41.430
And that's one of the sections
he's going to play in a little bit.

00:19:41.430 --> 00:19:45.670
Then he moved on to sound modules.

00:19:45.670 --> 00:19:49.950
And it -- the flower pot section he
plays in a very traditional manner,

00:19:49.950 --> 00:19:52.430
but he's playing unusual
percussion instruments.

00:19:52.430 --> 00:19:54.270
And in this section, sound modules,

00:19:54.270 --> 00:19:56.700
he's playing traditional
percussion instrument

00:19:56.700 --> 00:19:59.080
but he's triggering them
in a very unusual way.

00:19:59.080 --> 00:20:01.950
You see in his left
hand he has a microphone

00:20:01.950 --> 00:20:06.690
and he's playing something
called proximity,

00:20:06.690 --> 00:20:09.560
moving the microphone
closer and further away

00:20:09.560 --> 00:20:13.630
as he activates all
of these instruments.

00:20:13.630 --> 00:20:19.540
Then he moves up to the triangles
at the highest point in the atrium.

00:20:20.940 --> 00:20:24.430
Here's a close up of that.

00:20:24.430 --> 00:20:30.290
And so we had this issue of Ross
having to walk across the bridge

00:20:30.290 --> 00:20:33.830
and get in the elevator
to come down to the floor,

00:20:33.830 --> 00:20:37.600
and that took about a minute or so.

00:20:37.600 --> 00:20:40.860
So there was a -- I wrote a
short prepared piano part,

00:20:40.860 --> 00:20:43.810
and the piano sort of
snuck out from the audience

00:20:43.810 --> 00:20:45.650
and played this part
while he was walking

00:20:45.650 --> 00:20:47.470
across the bridge and coming down.

00:20:47.470 --> 00:20:51.310
And you can -- this is the
image of a short moment

00:20:51.310 --> 00:20:54.400
where the two of them
played together.

00:20:54.400 --> 00:20:58.440
And then he plays the
closing section here.

00:20:58.440 --> 00:21:04.570
So this is a map showing
all the different stages

00:21:04.570 --> 00:21:07.510
that he moved through, from
the floor up to the stairs

00:21:07.510 --> 00:21:09.900
to the mezzanine, and
up to the bridge,

00:21:09.900 --> 00:21:14.090
and then back down to the
floor again for the closing.

00:21:14.090 --> 00:21:18.910
So knowing that the piece was
going to be mapped out like that,

00:21:18.910 --> 00:21:21.650
I began work on the score design.

00:21:21.650 --> 00:21:25.270
And for me, the two
most important elements

00:21:25.270 --> 00:21:30.420
in creating a score
are structure and time.

00:21:30.420 --> 00:21:35.990
And structure is important to
me because it creates a set

00:21:35.990 --> 00:21:39.420
of boundary condition that allow me

00:21:39.420 --> 00:21:41.210
to feel comfortable
writing the piece

00:21:41.210 --> 00:21:45.030
and knowing exactly how long
the piece is going to be

00:21:45.030 --> 00:21:47.080
and what all the performance
elements are going

00:21:47.080 --> 00:21:48.380
to be in the piece.

00:21:48.380 --> 00:21:51.320
So I actually create very
tightly controlled structures.

00:21:51.320 --> 00:21:55.290
I will show you some examples of
the opening section in a moment.

00:21:55.290 --> 00:21:58.970
The other element that's
important to me is time,

00:21:58.970 --> 00:22:06.190
and being very tightly
controlling of the time element.

00:22:06.190 --> 00:22:12.290
And these are two of my favorite
sayings about the time element.

00:22:12.290 --> 00:22:15.930
Time if the canvas on which you
consider music to be presented.

00:22:15.930 --> 00:22:18.880
And this one, by the same
composer, Elliott Carter,

00:22:18.880 --> 00:22:21.710
the really interesting thing
about music is the time of it,

00:22:21.710 --> 00:22:23.170
the way it all goes along.

00:22:23.170 --> 00:22:26.130
And I feel exactly the
same way about these.

00:22:26.130 --> 00:22:31.810
These are really -- time is
the most important matter

00:22:31.810 --> 00:22:34.390
to control in a composition.

00:22:34.390 --> 00:22:39.380
So one of the things that I
created was a map that shows,

00:22:39.380 --> 00:22:43.270
if you look across the top you can
see these seven galaxies that I --

00:22:43.270 --> 00:22:48.410 position:56%
as I refer to them, and each of them
have different sets of instruments

00:22:48.410 --> 00:22:50.610
and they show dynamic progressions

00:22:50.610 --> 00:22:52.680
and all the various
other progressions

00:22:52.680 --> 00:22:54.740
that are happening in
the -- in the piece.

00:22:54.740 --> 00:23:00.160 position:56%
This is a close up of the first
half of the -- of the -- of the map.

00:23:00.160 --> 00:23:04.720
And here's the second
half, and I want to point

00:23:04.720 --> 00:23:07.890
out at the bottom this quote
from William, that when earlier

00:23:07.890 --> 00:23:11.260
on in our discussions about
creating Habitat this was --

00:23:11.260 --> 00:23:16.100
this was what William stated as
his intention for the electronics

00:23:16.100 --> 00:23:17.870
and the computer part of it.

00:23:17.870 --> 00:23:22.340
And I think we really
succeeded in creating that.

00:23:22.340 --> 00:23:26.780
So I have all of these
-- I have a map of the --

00:23:26.780 --> 00:23:29.500
of the venue of the space.

00:23:29.500 --> 00:23:31.770
I have a kind of time
map of how I'm going

00:23:31.770 --> 00:23:34.490
to move percussionists
through the space.

00:23:34.490 --> 00:23:41.270
And then I start to work
in very specific units,

00:23:41.270 --> 00:23:43.400
something that I call --
refer to as sonic units,

00:23:43.400 --> 00:23:46.780
and start breaking the piece
up into manageable units.

00:23:46.780 --> 00:23:49.680
And across the time at the
top you can see the timeline

00:23:49.680 --> 00:23:50.980
through the piece.

00:23:50.980 --> 00:23:53.910
And I don't -- when I say
timeline I don't mean minutes or,

00:23:53.910 --> 00:23:58.050
I'm talking about seconds that
I'm going to be working on.

00:23:58.050 --> 00:24:04.380
Then I made a list of them in
the center of it and trying --

00:24:04.380 --> 00:24:08.410
I'm trying to order them
here in the lower half of it.

00:24:08.410 --> 00:24:13.030
And so from this not very
detailed timeline I start

00:24:13.030 --> 00:24:16.800 position:56%
to build more detail into the piece.

00:24:16.800 --> 00:24:20.230
Start to work on dynamic
levels and what's going

00:24:20.230 --> 00:24:23.360
to happen with the computer parts.

00:24:23.360 --> 00:24:29.290
And then across the top here you
can see there are tonal centers

00:24:29.290 --> 00:24:33.010
that I'm working on, that I'm
figuring out, and what's going

00:24:33.010 --> 00:24:39.290
to happen in these various states
for the computer and the performer.

00:24:39.290 --> 00:24:44.220
And this is another
breakdown of the opening.

00:24:44.220 --> 00:24:46.800
And there's a lot to absorb here.

00:24:46.800 --> 00:24:54.530
You couldn't possibly absorb all
of this, but I want to show you

00:24:54.530 --> 00:24:57.530
that I'm breaking this down into
more and more detail and start

00:24:57.530 --> 00:25:02.940
to figure out specifics
about each section and neater

00:25:02.940 --> 00:25:06.870
and important factors like that.

00:25:06.870 --> 00:25:09.720
And eventually I put
all of this together

00:25:09.720 --> 00:25:13.740
into a very specific
timeline that looks like this.

00:25:13.740 --> 00:25:16.910
So this is -- this is a
timeline of the opening section,

00:25:16.910 --> 00:25:18.350
which is about 10 minutes,

00:25:18.350 --> 00:25:23.280
and it maps almost every event
that's supposed to happen

00:25:23.280 --> 00:25:27.480
and breaks everything down
into very precise segments.

00:25:27.480 --> 00:25:30.070
When the computer is supposed to
happen, when Ross is switching

00:25:30.070 --> 00:25:32.610
from instrument to instrument.

00:25:32.610 --> 00:25:36.220
And so it's a very,
very specific breakdown

00:25:36.220 --> 00:25:39.140
of how the first movement
is going to go.

00:25:39.140 --> 00:25:42.670
And this actually does
eventually turn into music.

00:25:42.670 --> 00:25:47.520 position:56%
And this is the -- this is the score
for the -- for the opening section.

00:25:47.520 --> 00:25:53.540
And each of the movements has
a quote associated with it.

00:25:53.540 --> 00:25:57.680
And this one is from Steve Schick's
book, The Percussionist's Art.

00:25:57.680 --> 00:26:02.840
So all of these -- all the sections
that you're seeing through here,

00:26:02.840 --> 00:26:07.830
the meter changes and instrument
changes and the phrasing changes,

00:26:07.830 --> 00:26:10.970
are all mapped out in
the section before.

00:26:14.320 --> 00:26:18.780
So this is still the -- this is the
second page of the opening section.

00:26:27.270 --> 00:26:30.500
And Ross is going to play
this for us in a little bit.

00:26:30.500 --> 00:26:33.670
So I think that we were
very, very successful

00:26:33.670 --> 00:26:37.080
in accomplishing what
we set out to do.

00:26:37.080 --> 00:26:41.440
And this is a review that
Stephen Brookes wrote

00:26:41.440 --> 00:26:44.730
in the Washington Post I
think a day or so after the --

00:26:44.730 --> 00:26:46.900
a day or so after the performance.

00:26:46.900 --> 00:26:52.240
And one of the things he points
out at the end is that it seemed

00:26:52.240 --> 00:26:56.180
as if Ross is playing and
the atrium itself is a

00:26:56.180 --> 00:26:57.550
gigantic meta-instrument.

00:26:57.550 --> 00:27:01.440
And that was really my
goal, to make it feel

00:27:01.440 --> 00:27:07.260
like the audience was inside this
sonic environment that we created

00:27:07.260 --> 00:27:09.910
through the percussion,
through the movement,

00:27:09.910 --> 00:27:12.210
and through the technology.

00:27:17.390 --> 00:27:22.920
And so, again, Ross is going
to perform these three sections

00:27:22.920 --> 00:27:25.800
from the piece in a little bit.

00:27:25.800 --> 00:27:30.800
So now William is going
to give a little talk

00:27:30.800 --> 00:27:34.840
about some of the technology stuff.

00:27:34.840 --> 00:27:38.570
And I want to thank
both William and Ross

00:27:38.570 --> 00:27:44.200
for all the work they've done
today in making this happen.

00:27:44.200 --> 00:27:47.650
And for me, one of the
most important things

00:27:47.650 --> 00:27:50.730
about contemporary
composition is collaboration.

00:27:50.730 --> 00:27:54.800
It's really what makes very
difficult music happen.

00:27:54.800 --> 00:27:56.640
It's what allows it to be realized.

00:27:56.640 --> 00:28:01.270
And I'm very fortunate to have two
enormously talented collaborators

00:28:01.270 --> 00:28:02.570
in Habitat.

00:28:02.570 --> 00:28:04.400
And this really was a joint effort.

00:28:04.400 --> 00:28:09.510
So William is now going
to talk about this.

00:28:09.510 --> 00:28:17.500
[ Applause ]

00:28:22.070 --> 00:28:24.280
&gt;&gt; William Brent: Hi,
I'm William Brent.

00:28:24.280 --> 00:28:28.840
And I'm going to pick up right
here and just talk a little

00:28:28.840 --> 00:28:32.710
about the technology,
design, and management of how

00:28:32.710 --> 00:28:34.000
to control all these
different elements.

00:28:34.920 --> 00:28:37.070
As you can tell from some of
the pictures Steve was showing,

00:28:37.070 --> 00:28:42.540
there's a lot -- there are a
lot of instruments out there,

00:28:42.540 --> 00:28:46.970
but there are a lot of microphones,
projectors, other computers

00:28:46.970 --> 00:28:48.270
that are networked together.

00:28:48.270 --> 00:28:49.570
So there's a lot to cover there.

00:28:49.570 --> 00:28:50.870
So I'll show you a stage plot,
a vocal piece in a second.

00:28:51.060 --> 00:28:59.250
And then I want to get into
the process of how to design

00:28:59.250 --> 00:29:04.040
and manage something this
big, because there are

00:29:04.040 --> 00:29:05.640 position:56%
so many changing elements constantly

00:29:05.640 --> 00:29:08.890
that you can't possibly
do it all manually.

00:29:08.890 --> 00:29:11.680
You really need computer power
and processing to be able

00:29:11.680 --> 00:29:13.200
to pull this kind of stuff
off in live performance.

00:29:13.200 --> 00:29:14.500
And also, I want to
say a little about how

00:29:14.500 --> 00:29:15.800
that impacts the performer.

00:29:16.540 --> 00:29:19.880
And then I want to show you
the programming environment

00:29:19.880 --> 00:29:22.770
that the piece was realized
in, which is called Pd,

00:29:22.770 --> 00:29:24.260
which is short for Pure Data.

00:29:24.260 --> 00:29:29.890 position:56%
And it's basically just a graphical
programming language that's specific

00:29:29.890 --> 00:29:33.370
for manipulating media,
and especially audio.

00:29:33.370 --> 00:29:35.520
But you can -- you can
technically make anything.

00:29:35.520 --> 00:29:39.260
It's a computer language
just like [inaudible].

00:29:39.260 --> 00:29:42.050
And so there we'll look
at audio analysis stuff.

00:29:42.050 --> 00:29:45.910
I kind of gathered meaningful
information off the microphones

00:29:45.910 --> 00:29:50.520 position:56%
about what the performer is doing,
different kinds of musical processes

00:29:50.520 --> 00:29:54.270
that the computer can do in
response to the performer,

00:29:54.270 --> 00:29:57.890
some sound synthesis techniques

00:29:57.890 --> 00:30:00.000
that we're using, and
also transformation.

00:30:00.570 --> 00:30:04.000
So those are kind of like the
effects, like a wah-wah pedal

00:30:04.000 --> 00:30:08.830
on a guitar or a fuzz distortion,
that sort of thing, but different.

00:30:08.830 --> 00:30:12.100
So this is the overview.

00:30:12.100 --> 00:30:17.150 position:56%
I don't know how clearly you can
see it, but these different stations

00:30:17.150 --> 00:30:18.810
that Steve was showing you

00:30:18.810 --> 00:30:22.550
in the actual images are
kind of mapped out here.

00:30:22.550 --> 00:30:25.890
You can see that there are
four mics on the opening

00:30:25.890 --> 00:30:27.750
and closing section here.

00:30:27.750 --> 00:30:31.000
That's what we've got set up
here, a couple on the piano.

00:30:32.480 --> 00:30:36.020
There was a lavalier mic
for the household thing,

00:30:36.020 --> 00:30:41.780
one on the modules thing that
Ross was moving his left hand

00:30:41.780 --> 00:30:45.090
to capture those sounds, and
more on the triangles up here.

00:30:45.090 --> 00:30:49.380 position:56%
So all that has been fed into this
central audio computer that's taking

00:30:49.380 --> 00:30:54.480
in all these channels of audio and
transforming them and then coming

00:30:54.480 --> 00:30:57.600
up with the transform
result that's spatialized

00:30:57.600 --> 00:30:59.660
over these eight speakers
here surrounding the space.

00:31:00.260 --> 00:31:06.210
So we can really clearly make
the sensation of sounds moving

00:31:06.210 --> 00:31:08.750
in specific directions,
sounds, you know,

00:31:08.750 --> 00:31:10.790
happening in certain locations,

00:31:10.790 --> 00:31:14.160
and sometimes just
having random processes

00:31:14.160 --> 00:31:17.460
for controlling the spatialization
so that it's always kind of roaming

00:31:17.460 --> 00:31:19.400
around and never settling.

00:31:19.400 --> 00:31:25.400
The other main computer down
here is the video computer

00:31:25.400 --> 00:31:28.250
that Ross' projection
design is run from.

00:31:28.250 --> 00:31:30.610
So he created these videos.

00:31:30.610 --> 00:31:33.440
He's going to say more
about that a little later.

00:31:33.440 --> 00:31:36.270
And it's really important
though that the audio

00:31:36.270 --> 00:31:38.630
and video computer are on
the same network together

00:31:38.630 --> 00:31:41.000
so that we can send
information back and forth.

00:31:42.040 --> 00:31:43.780
So whatever happens based on the --

00:31:43.780 --> 00:31:47.490
what's coming in off the microphone
is going to affect the video,

00:31:47.490 --> 00:31:49.380
things like changing the
brightness of the video

00:31:49.380 --> 00:31:53.610
and how loud he's playing, or where
a note attack starts a new video

00:31:53.610 --> 00:31:56.080
pops up, stuff like that.

00:31:56.080 --> 00:31:58.700
So those are all connected
on a network switch as well

00:31:58.700 --> 00:32:04.520
as two other computers for motion
capture to track Ross' gestures

00:32:04.520 --> 00:32:08.830
as he plays, which can
also affect processing.

00:32:08.830 --> 00:32:13.670
So a lot of -- a lot of elements,
and it is all controlled,

00:32:13.670 --> 00:32:16.000
this is the terrifying
part, with one spacebar.

00:32:17.340 --> 00:32:21.440
There are faders, of course,
too, for fine grain control,

00:32:21.440 --> 00:32:23.250
but mostly that's automated.

00:32:23.250 --> 00:32:26.300
If you take a peak later at
the equipment set up over here,

00:32:26.300 --> 00:32:29.970
it's pretty minimal and it's just
some faders that are automated

00:32:29.970 --> 00:32:32.610
as I move through these
pre-composed queues

00:32:32.610 --> 00:32:35.400
that we worked hard
to get just right.

00:32:35.400 --> 00:32:42.580
That's -- so that's where
I'll pick up to continue,

00:32:42.580 --> 00:32:47.090
is what it's like to be able to
do this stuff in real time and how

00:32:47.090 --> 00:32:50.080
that compares with the
way it used to be done.

00:32:50.080 --> 00:32:56.020
There are some classic pieces from
the 1960's by Karlheinz Stockhausen

00:32:56.020 --> 00:32:59.530
that involve electronic sounds
and acoustic instruments,

00:32:59.530 --> 00:33:02.000
and they're played at the
same time in a performance.

00:33:02.780 --> 00:33:05.540
But the big difference
between these two pieces here,

00:33:05.540 --> 00:33:09.340
Kontakta has a fixed take part.

00:33:09.340 --> 00:33:11.810
So its electronic sound
is recorded on tape

00:33:11.810 --> 00:33:13.620
and you just hit play and you go.

00:33:13.620 --> 00:33:19.770
And the performer memorizes all of
these wild sounds and knows exactly

00:33:19.770 --> 00:33:24.380
where he or she is and plays their
part tightly, synchronized with it.

00:33:24.380 --> 00:33:27.310
And the result is really
fantastic because you get --

00:33:27.310 --> 00:33:32.000
you get these perfect moments
of these worlds coming together.

00:33:32.000 --> 00:33:37.500
But the one drawback is, there's no
ability or leeway for the performer

00:33:37.500 --> 00:33:41.000
to be able to be expressive with
things like phrasing and tempo.

00:33:41.720 --> 00:33:44.580
They can't -- if they
want to rush a section

00:33:44.580 --> 00:33:46.580
because they're just
feeling it in the moment,

00:33:46.580 --> 00:33:52.000
they can't because they'll be out
of sync with this fixed take part.

00:33:52.000 --> 00:33:57.100
One of the early solutions to that
was another piece by Stockhausen,

00:33:57.100 --> 00:34:02.160
Mikrophonie I, that involves
exploring a giant tam-tam

00:34:02.160 --> 00:34:07.770
with microphones but also has an
electronic instrument performer

00:34:07.770 --> 00:34:09.820
that is controlling filters,

00:34:09.820 --> 00:34:13.200
just a couple basic [inaudible]
filters, but in real time.

00:34:13.200 --> 00:34:15.550 position:56%
So that's another part in the score,

00:34:15.550 --> 00:34:19.510
is how to move these
filters in real time.

00:34:19.510 --> 00:34:24.000 position:56%
So that works out great because they
can never get out of sync, right?

00:34:25.040 --> 00:34:28.350
If the -- if the percussionist's
tam-tam performers go faster

00:34:28.350 --> 00:34:31.070
or slower, the filtered
performer can slow down, too,

00:34:31.070 --> 00:34:34.410
and it's just like any
other music situation.

00:34:34.410 --> 00:34:39.540
So the problem is when you have
more than one person can do.

00:34:39.540 --> 00:34:42.150
If you have instead of
two or three effects,

00:34:42.150 --> 00:34:44.180
what if you have 200 effects,

00:34:44.180 --> 00:34:46.590
and what if they change
much more quickly

00:34:46.590 --> 00:34:49.540
than any person could
actually keep up with?

00:34:49.540 --> 00:34:53.520
And that idea was explored
really effectively,

00:34:53.520 --> 00:34:57.160
and still is being explored,
at [inaudible] in Paris

00:34:57.160 --> 00:35:02.630
and some early pioneers there were
Phillippe Manoury, a composer,

00:35:02.630 --> 00:35:06.710
and Miller Puckette, who's
the author of [inaudible],

00:35:06.710 --> 00:35:09.660
these programming environments
for this kind of thing.

00:35:10.040 --> 00:35:13.700
And they worked together to
develop a score following system

00:35:13.700 --> 00:35:17.780
where the microphones analyze
what the performer is doing

00:35:17.780 --> 00:35:19.890 position:56%
to see what pitches they're playing.

00:35:19.890 --> 00:35:22.600
The computer knows the pitches
they're supposed to play,

00:35:22.600 --> 00:35:25.750
so if they more or less play their
part right the computer knows

00:35:25.750 --> 00:35:29.750
where they are in the piece and can
make very specific things happen,

00:35:29.750 --> 00:35:32.340
tightly synchronize with them.

00:35:32.340 --> 00:35:34.350
And I've run -- these
pieces are amazing.

00:35:34.350 --> 00:35:37.540
And I've run the electronics for
them myself, but I can tell you,

00:35:37.540 --> 00:35:41.770
it's never perfect because
pitch tracking is not --

00:35:41.770 --> 00:35:44.000
it depends on the instrument.

00:35:44.370 --> 00:35:46.810
With percussion it's
especially bad actually.

00:35:46.810 --> 00:35:49.810
And so there are problems with
it and you always end up having

00:35:49.810 --> 00:35:53.630
to nudge the computer part along
and you're always terrified

00:35:53.630 --> 00:35:57.060
that it's going to, you know,
jump forward five queues

00:35:57.060 --> 00:35:58.440
and everything will be out of sync.

00:35:58.440 --> 00:36:01.730
So what we've sort of settled

00:36:01.730 --> 00:36:05.660
in on is just something
that's kind of semi-automatic.

00:36:05.660 --> 00:36:10.420
Instead of an automated computer
part that just fully tries

00:36:10.420 --> 00:36:14.520
to follow along with the
performer, we're having me,

00:36:14.520 --> 00:36:19.700
or any computer musician, advance
the score along with the spacebar,

00:36:19.700 --> 00:36:21.530
if you do a few other
minor adjustments,

00:36:21.530 --> 00:36:23.100
something that's manageable

00:36:23.100 --> 00:36:26.280
so that things can't
get too far out of sync.

00:36:26.280 --> 00:36:29.440
And try -- we try to keep
the inner activity level high

00:36:29.440 --> 00:36:34.190 position:56%
by still using all that information,
the pitch and the loudness

00:36:34.190 --> 00:36:38.170
and [inaudible] to actually
trigger events and processes

00:36:38.170 --> 00:36:41.660
so that the whole result still
feels really interactive.

00:36:42.350 --> 00:36:45.100
And actually I like that
graph that's [inaudible].

00:36:45.100 --> 00:36:47.660
They're showing the feedback
loop between the performer

00:36:47.660 --> 00:36:51.460
and the computer musician,
because obviously what Ross,

00:36:51.460 --> 00:36:54.570
the percussionist is doing
affects what I do, and vice versa,

00:36:54.570 --> 00:36:58.330
what I put back out into the space
is going to affect his playing,

00:36:58.330 --> 00:37:03.060
just like you'd hope any kind of
chamber music situation would be.

00:37:03.060 --> 00:37:06.740
So the next couple slides are
just to give you a little glimpse

00:37:06.740 --> 00:37:12.000
into Pd, Pure Data, the programming
environment, which Pd does nothing.

00:37:12.890 --> 00:37:17.340
You make everything in Pd
from basic elements basically.

00:37:17.340 --> 00:37:24.350
It gives you basic tools like
math, multipliers and dividers,

00:37:24.350 --> 00:37:28.090
and you can manage controlled data
for all the logic side of things,

00:37:28.090 --> 00:37:31.120
and audio processing for
the audio side of things.

00:37:31.120 --> 00:37:33.630
You can design, you know, effects.

00:37:33.630 --> 00:37:35.570
So instead of -- if
some of you have worked

00:37:35.570 --> 00:37:39.950
with digital audio workstations
where you have plugins,

00:37:39.950 --> 00:37:42.930
someone made this plugin
or effect and you pop it in

00:37:42.930 --> 00:37:45.120
and you can use it,
but you can't really --

00:37:45.120 --> 00:37:47.000
there's a limit to how
much control you can have.

00:37:47.730 --> 00:37:53.710 position:56%
So the idea with Pd is to be able to
make anything you want from scratch.

00:37:53.710 --> 00:37:58.490
So this is a screenshot from
the control panel for Habitat,

00:37:58.490 --> 00:38:03.160 position:56%
and you can see the different little
-- these are called sub-patches.

00:38:03.160 --> 00:38:05.070
The main thing is called a patch.

00:38:05.070 --> 00:38:08.930
And if you click into any one of
these you get one layer deeper

00:38:08.930 --> 00:38:12.120
and you can go as deep as you like.

00:38:12.120 --> 00:38:16.810
In here the processing module
has all of the effects.

00:38:16.810 --> 00:38:20.660
And this DSB thing has
spatialization routines.

00:38:21.960 --> 00:38:26.650
This involves network communication
to the other computers, you know,

00:38:26.650 --> 00:38:30.220
by basic volume, all the -- all
the basic stuff you'd expect,

00:38:30.220 --> 00:38:36.670 position:56%
as well as controls for [inaudible],
which are all the specific queues

00:38:36.670 --> 00:38:39.180
that happen through the
course of the piece.

00:38:39.180 --> 00:38:41.330
This is just to show
you, kind of exploding

00:38:41.330 --> 00:38:45.090
that other view, a
few layers into there.

00:38:45.090 --> 00:38:47.120
So I'm not going to
show too much of Pd.

00:38:47.120 --> 00:38:51.000
I'll show you a couple live
demonstrations in just a minute.

00:38:51.890 --> 00:38:59.190 position:56%
But basically you're interconnecting
a bunch of different basic objects

00:38:59.190 --> 00:39:03.930
and programming your
whole system yourself.

00:39:03.930 --> 00:39:09.550
These are little screenshots
from a couple --

00:39:09.550 --> 00:39:13.910
this looks like a couple lines
from the opening section.

00:39:13.910 --> 00:39:17.440
So on the left and right
are two different queues.

00:39:17.440 --> 00:39:20.620
You can see like right
here I'm turning up the --

00:39:20.620 --> 00:39:24.970
or turning down the time
stretch gain, on effects gain.

00:39:24.970 --> 00:39:28.660
I preloaded a sample that
I want to be able to play.

00:39:29.100 --> 00:39:33.780
I'm sending out a video queue
to Ross' computer for a change

00:39:33.780 --> 00:39:36.820
in the video that's supposed
to happen right on that queue.

00:39:36.820 --> 00:39:38.990
You can send spatialization
commands.

00:39:38.990 --> 00:39:42.190
This is all just -- you can make up
your own language for how to talk

00:39:42.190 --> 00:39:48.190
to your system and reduce it
into these basic commands,

00:39:48.190 --> 00:39:52.620 position:56%
which is nice because if you need to
make changes before a performance,

00:39:52.620 --> 00:39:55.220
or you change your
mind, instead of having

00:39:55.220 --> 00:39:59.000
to remember anything you just
go in like we did just today.

00:39:59.700 --> 00:40:03.490
We wanted the release time on
some of these sine wave generators

00:40:03.490 --> 00:40:07.760
to be longer, so I changed these
[inaudible] a couple hours ago

00:40:07.760 --> 00:40:09.100
and we just made them longer.

00:40:09.100 --> 00:40:11.860
So now those sine waves
are going to last longer.

00:40:11.860 --> 00:40:15.660 position:56%
And it's all really compact language
and it's actually manageable.

00:40:15.660 --> 00:40:20.400
And that means every button press
when these commands are executed,

00:40:20.400 --> 00:40:23.870
it could be 10 commands,
it could 100 commands,

00:40:23.870 --> 00:40:26.400
but it's all instantaneous.

00:40:27.460 --> 00:40:33.220
I'll quickly say a couple
things about audio analysis.

00:40:33.220 --> 00:40:35.420
The big things that
we're taking advantage

00:40:35.420 --> 00:40:39.400
of here are spectral
analysis, or foray analysis,

00:40:39.400 --> 00:40:41.260
to get the spectrum of a sound.

00:40:41.260 --> 00:40:45.700
And that can be done continuously
in little chunks of audio

00:40:45.700 --> 00:40:47.160
as it's coming in off
the microphone.

00:40:47.160 --> 00:40:51.550
So you can just take spectrum
snapshots and you can use

00:40:51.550 --> 00:40:56.180
that information to capture things
like attacks, the spectral envelope

00:40:56.180 --> 00:40:59.080
of the sound or how
bright it sounds.

00:40:59.080 --> 00:41:00.980
You can also get volume.

00:41:00.980 --> 00:41:03.500
You can get pitch off
of this spectrum.

00:41:03.500 --> 00:41:07.780
And I wanted to show that
sort of in context here.

00:41:07.780 --> 00:41:15.640
So this is a Pd patch here
that I made just to show this.

00:41:15.640 --> 00:41:18.270
So this is me -- there's
the analysis

00:41:18.270 --> 00:41:20.200
of me talking right now, right?

00:41:20.200 --> 00:41:22.910
And you can see really
clearly, first of all,

00:41:22.910 --> 00:41:25.340
this thing if we go
into the patch here.

00:41:25.340 --> 00:41:30.160
I'm using a bunch of weird objects,
but this one gives you a text

00:41:30.160 --> 00:41:32.340
that tells you when
there's been a sudden change

00:41:32.340 --> 00:41:33.980
in the spectrum of a sound.

00:41:33.980 --> 00:41:37.930
So if I snap my fingers
[snapping sounds], right,

00:41:37.930 --> 00:41:43.660
it'll react really quickly.

00:41:44.040 --> 00:41:46.970
And if I can make a bang, if
I can make an event happen,

00:41:46.970 --> 00:41:51.930
I can make that button flash, then
I can do anything at that instant.

00:41:51.930 --> 00:41:56.070
And it -- with the right settings
you can make it seem like as soon

00:41:56.070 --> 00:41:59.350
as there's a note attack
the computer does something

00:41:59.350 --> 00:42:01.780
at exactly the same
time, or close enough

00:42:01.780 --> 00:42:03.700
to exactly the same time
that it feels together.

00:42:03.700 --> 00:42:05.550
So that's one thing.

00:42:05.550 --> 00:42:07.220
The spectrum itself, you can see

00:42:07.220 --> 00:42:12.320
from me whistling right now maybe
[whistling], you can see energy

00:42:13.720 --> 00:42:15.660 position:56%
and different bands of the spectrum.

00:42:16.320 --> 00:42:19.370
And when I'm talking you can
see harmonics of my voice

00:42:19.370 --> 00:42:25.250
which could tell you
the pitch of the sound.

00:42:25.250 --> 00:42:26.550
This is the pitch over
here [singing].

00:42:26.550 --> 00:42:28.250
Right, it's graphing out pitch.

00:42:28.250 --> 00:42:30.480
So all of this can be
done really cheaply.

00:42:30.480 --> 00:42:32.080
It doesn't take much
processing power.

00:42:32.080 --> 00:42:44.570
Okay. I think the next bit was just
to show you a couple of processes

00:42:44.570 --> 00:42:47.760
that depend on that kind of
analysis in order to work.

00:42:47.760 --> 00:42:52.240
So these are -- these aren't
effects processing the raw sound

00:42:52.240 --> 00:42:56.560
of the instruments,
they're generated material

00:42:56.560 --> 00:43:01.920
that the computer comes up with
independently, but it's triggered,

00:43:01.920 --> 00:43:03.220
or at least controlled
by the percussionist.

00:43:03.880 --> 00:43:06.720
So one of the ideas that
we talked about was this --

00:43:06.720 --> 00:43:10.060
we call it a gesture trigger,
and the idea there was

00:43:10.060 --> 00:43:15.800 position:56%
to get any short phrase out of the
entire composition, which we encoded

00:43:15.800 --> 00:43:19.250
in a certain way that
the computer can read it

00:43:19.250 --> 00:43:21.050
and just grab a little phrase here,

00:43:21.050 --> 00:43:25.430
a little phrase there any time
the percussionist hits a note

00:43:25.430 --> 00:43:28.070
at certain -- at certain moments.

00:43:28.070 --> 00:43:31.320
And that could be played back
using any samples we want.

00:43:31.320 --> 00:43:34.960
So if we want to play that little
phrase using a vibraphone sound

00:43:34.960 --> 00:43:40.520
or a [inaudible] sound or metal
instrument sound, we can do that.

00:43:40.520 --> 00:43:43.330
And another one was the -- that
I want to show is the mobile.

00:43:44.230 --> 00:43:45.900
And that was -- that happens
right at the end of the opening.

00:43:45.900 --> 00:43:48.990
We're going to do it today.

00:43:48.990 --> 00:43:51.740
And basically as the
performer goes through

00:43:51.740 --> 00:43:54.440
and plays these specific
sounds at the end,

00:43:54.440 --> 00:43:56.960
each one of those is
captured live by the --

00:43:56.960 --> 00:44:02.000 position:56%
by the computer and then just looped
at a different spot in the hall.

00:44:02.370 --> 00:44:06.050
So it makes this collage of
spatialized sounds that sort

00:44:06.050 --> 00:44:09.370
of accumulate as he
plays the material.

00:44:09.370 --> 00:44:13.620
And we use that as transitional
material between the opening

00:44:13.620 --> 00:44:17.990
and the piano section, which is the
next instrument he has to walk to.

00:44:17.990 --> 00:44:22.530
So I'll just quickly show
little examples of those.

00:44:22.530 --> 00:44:26.910
This is the gesture trig example.

00:44:28.510 --> 00:45:11.050
[ Music ]

00:45:11.050 --> 00:45:14.670
So there -- I think the
significant thing there is

00:45:14.670 --> 00:45:18.130
that it's not just a computer
depending on the performer

00:45:18.130 --> 00:45:19.970
and microphones to
generate something.

00:45:19.970 --> 00:45:24.960
It can sort of hold its
own once he gets enough

00:45:24.960 --> 00:45:27.800
of those little fragments
going and they play back.

00:45:27.800 --> 00:45:31.040
It feels like it's got its own
momentum and then that can start

00:45:31.040 --> 00:45:34.810
to create more of a push and
pull between the performer --

00:45:34.810 --> 00:45:37.250 position:56%
the live performer and the computer.

00:45:37.250 --> 00:45:43.120
So that's sort of -- kind of
like a little additional player.

00:45:43.120 --> 00:45:48.250
And this is the mobile that we're
going to hear in a moment anyway,

00:45:48.250 --> 00:45:51.100
but I just want to draw
your attention to it

00:45:51.100 --> 00:45:55.650 position:56%
so that you understand how it's
being created when we play it later.

00:45:55.650 --> 00:45:58.860
So you'll hear him play
these discrete events,

00:45:58.860 --> 00:46:03.470
and let 30 seconds go by,
you'll kind of hear them echoing

00:46:03.470 --> 00:46:08.510
and still remaining and
recirculating the space.

00:46:08.510 --> 00:47:14.070
[ Music ]

00:47:14.070 --> 00:47:15.550
Okay, I'll cut that off there.

00:47:15.550 --> 00:47:20.390
So at the beginning there
were other processes going

00:47:20.390 --> 00:47:24.100
on to [inaudible] decomposition
effect,

00:47:24.100 --> 00:47:28.650
which I think will be the
last thing I show here.

00:47:28.650 --> 00:47:31.710
But over all that's the challenge,

00:47:31.710 --> 00:47:37.490
is to be able to make these
different layers of process happen,

00:47:37.490 --> 00:47:40.120
not letting anything become
static and just sit there

00:47:40.120 --> 00:47:42.610
for too longer that
it becomes boring.

00:47:43.800 --> 00:47:45.160
That's the goal.

00:47:45.160 --> 00:47:50.020
So I'll finish just by
showing you one more.

00:47:51.630 --> 00:47:56.570
If any of you have studied physics
or foray analysis or anything

00:47:56.570 --> 00:47:58.780
like that, or a lot
of musicians that get

00:47:58.780 --> 00:48:03.950
into this have had some experience
with foray analysis and FFT's,

00:48:03.950 --> 00:48:06.970
you could sort of appreciate
it what's going on here,

00:48:06.970 --> 00:48:11.760
which is that any sound, I'm going
to use a recording of Ross playing

00:48:11.760 --> 00:48:15.420
that we captured in a rehearsal,
but any sound coming in live

00:48:15.420 --> 00:48:20.970
or recorded can be analyzed broken
down into its basic components

00:48:20.970 --> 00:48:26.420
as sine waves because all sounds
are just a big sum of sine waves.

00:48:26.420 --> 00:48:28.960
Even the sound of me
talking right now,

00:48:28.960 --> 00:48:31.750
just really quickly
changing sums of sine waves.

00:48:31.750 --> 00:48:35.380
If you have enough of them you
can perfectly resynthesize it.

00:48:35.380 --> 00:48:41.290
So the idea here is to analyze
that using the analysis object,

00:48:41.290 --> 00:48:46.310
which is called the Sigmund,
which is supposed to be a joke,

00:48:46.310 --> 00:48:48.970
after Sigmund Freud for analysis.

00:48:48.970 --> 00:48:57.240
And Sigmund creates -- it gives
you all of the frequencies, phases,

00:48:57.240 --> 00:49:02.060
amplitudes of the main sine waves
and the sound you're analyzing.

00:49:02.060 --> 00:49:04.350
You can tell it any
details you want.

00:49:04.350 --> 00:49:08.730
Like right here I said I want to
know the 18 most important peaks,

00:49:08.730 --> 00:49:10.670
most important sine components.

00:49:10.670 --> 00:49:14.640
The highest I want to go is about
15,000 hertz, which is higher

00:49:14.640 --> 00:49:17.640
than I can really hear anyway,
so I don't care that much,

00:49:17.640 --> 00:49:19.800
and then some analysis specs.

00:49:19.800 --> 00:49:22.620
And then all that information
is being sent

00:49:22.620 --> 00:49:25.470
to a bunch of sine wave generators.

00:49:25.470 --> 00:49:28.130
This is -- these are just
a bunch of sine waves.

00:49:28.130 --> 00:49:34.340 position:56%
In the end it's this, an oscillator,
just something that puts out numbers

00:49:34.340 --> 00:49:36.360
that go like that, right?

00:49:36.360 --> 00:49:39.780
But you can control the frequency
and the phase and the amplitude.

00:49:39.780 --> 00:49:43.550
So this has about 90 oscillators.

00:49:43.550 --> 00:49:44.850
Here's the real sound first.

00:49:44.850 --> 00:49:47.510
I'll turn this up.

00:49:47.510 --> 00:49:59.040
[ Music ]

00:49:59.040 --> 00:50:03.430
And I'll mute that and
I'm going to start it over

00:50:03.430 --> 00:50:06.970
and we'll hear the
synthesized version of it.

00:50:08.510 --> 00:50:20.040
[ Music ]

00:50:20.040 --> 00:50:26.610
You can kind of hear like little
[inaudible] weird sounds [music],

00:50:26.610 --> 00:50:27.910
right?

00:50:27.910 --> 00:50:31.260
Especially broadband sounds
like that tam-tam at the end.

00:50:31.260 --> 00:50:35.640
But for a lot of sounds,
especially sounds that just ring

00:50:35.640 --> 00:50:38.270
out like a vibraphone bar, it
can sound really realistic.

00:50:38.270 --> 00:50:42.090
And for the triangles here that
we're going to work with later,

00:50:42.090 --> 00:50:44.530
you can analyze that and
get all that information

00:50:44.530 --> 00:50:46.510
and resynthesize it
really accurately

00:50:46.510 --> 00:50:50.280
and make it sound pretty realistic.

00:50:50.280 --> 00:50:54.320
But the point is not to synthesize
it perfectly but to get that level

00:50:54.320 --> 00:50:58.460
of control and then do
something unusual with it.

00:50:58.460 --> 00:51:03.190
So one of the effects
you'll hear a lot is this --

00:51:03.190 --> 00:51:06.120
it's a set of commands to these
sine oscillators telling them

00:51:06.120 --> 00:51:11.050
to start playing the right pitch
but then, you know, [inaudible]

00:51:11.050 --> 00:51:12.870
and bend the pitch in weird ways

00:51:12.870 --> 00:51:15.750
that just make the sound
sound like it's melting.

00:51:15.750 --> 00:51:18.490
So if I play that same sample

00:51:18.490 --> 00:51:26.890
with the different setting here we
can listen to that result [music].

00:51:26.890 --> 00:51:30.510
And I'll mix in the original, too.

00:51:30.510 --> 00:51:57.050
[ Music ]

00:51:57.050 --> 00:52:01.090
Okay. We're going to hear a lot
more of that in the performance,

00:52:01.090 --> 00:52:03.770
so I might just stop there.

00:52:03.770 --> 00:52:08.520
But all of these things in a
nutshell just add another layer

00:52:08.520 --> 00:52:13.150
of expressivity and
compositional intention,

00:52:13.150 --> 00:52:16.870
and it's been great working
with Steve on this, and Ross,

00:52:16.870 --> 00:52:20.520
because they're both -- all
of us have our foot in all

00:52:20.520 --> 00:52:23.700
of these worlds, composition
technology and performance.

00:52:23.700 --> 00:52:27.160
And so we really, I think, are
able to work together nicely

00:52:27.160 --> 00:52:31.130
and communicate well to do this
kind of collaborative effort.

00:52:31.130 --> 00:52:37.120
Okay, well I'm going to let Ross
say a little bit video here.

00:52:37.120 --> 00:52:38.420
Thank you.

00:52:38.920 --> 00:52:47.160
[ Applause ]

00:52:48.200 --> 00:52:49.500
&gt;&gt; Ross Karre: Thanks, William.

00:52:49.500 --> 00:52:53.200
And thanks to Steve and also
the entire staff of the Library

00:52:53.200 --> 00:52:54.500
of Congress for hosting this.

00:52:54.500 --> 00:52:57.720
It feels nice to bring
the Habitat back to D.C.

00:52:57.720 --> 00:52:59.520
In many ways it was born here.

00:52:59.520 --> 00:53:03.060
It was created for the National
Gallery space, as Steve describe.

00:53:03.060 --> 00:53:05.400
And we've had other performances

00:53:05.400 --> 00:53:08.070
at the American University
Katzen Gallery.

00:53:08.070 --> 00:53:09.920
And so I feel like this is --

00:53:09.920 --> 00:53:11.840
this is the home, the
origin of this piece.

00:53:11.840 --> 00:53:15.390
It's really nice to be back here.

00:53:15.390 --> 00:53:20.760
And my main role in this project is
as a percussionist, but I also --

00:53:20.760 --> 00:53:26.030
from the very beginning we started
to design what is now a common term

00:53:26.030 --> 00:53:28.820
in theatrical and dance
productions and sometimes in music,

00:53:28.820 --> 00:53:30.570
it's called projection design.

00:53:30.570 --> 00:53:33.850
A subcategory of that is
called projection mapping.

00:53:33.850 --> 00:53:38.730
And the basic idea was to bring
the sort of innards of this Habitat

00:53:38.730 --> 00:53:42.480
that Steve created to
a much larger scale.

00:53:42.480 --> 00:53:47.590
So the smallest, most micro-grain,
granular sort of element of the --

00:53:47.590 --> 00:53:52.110 position:56%
of the materials that go into making
these sounds, the piano strings,

00:53:52.110 --> 00:53:56.420 position:56%
the metals, the vibraphone bars, the
wood, all of the sort of textures

00:53:56.420 --> 00:54:02.210
that comprise that sonic world,
we want to represent that visually

00:54:02.210 --> 00:54:06.940
to allow kind of a microscopic
view into the sound world.

00:54:06.940 --> 00:54:10.600
And what allows that is
instead of what we have here,

00:54:10.600 --> 00:54:13.570
which is basically a very
presentational version

00:54:13.570 --> 00:54:18.360
of projection, which is someone
talking and projected imagery,

00:54:18.360 --> 00:54:24.020
we can -- we can design images that
integrate into the space itself.

00:54:24.020 --> 00:54:25.320
We won't be doing that today,

00:54:25.320 --> 00:54:27.890
but in the previous performances
we've had that opportunity.

00:54:27.890 --> 00:54:30.560
And I want to show you a little
bit about what that field is,

00:54:30.560 --> 00:54:34.050
not just for Habitat
but for the whole world

00:54:34.050 --> 00:54:35.850
of theater and dance and music.

00:54:35.850 --> 00:54:37.590
But what is projection design?

00:54:37.590 --> 00:54:40.270
I think if you -- if
you -- we look at --

00:54:40.270 --> 00:54:45.670
historically projection design
starts probably in the '60s

00:54:45.670 --> 00:54:50.150 position:56%
for what I call integrated media, or
intermedia, which was a term coined

00:54:50.150 --> 00:54:53.440
by one of the Fluxus'
members, Dick Higgins.

00:54:53.440 --> 00:54:57.180
And a writer around that time, one
of my mentors and collaborators,

00:54:57.180 --> 00:54:59.980
Roger Reynolds, created
a piece in 1968.

00:54:59.980 --> 00:55:04.490
It was my first experience
working with integrated media.

00:55:04.490 --> 00:55:09.330
And what that means is essentially
what Habitat tried to do and does,

00:55:09.330 --> 00:55:11.850
which is to take various
media components

00:55:11.850 --> 00:55:16.740
and decide how they will each
serve one conceptual goal, focus.

00:55:16.740 --> 00:55:21.710
In the case of this piece by Roger
Reynolds, the media were many.

00:55:21.710 --> 00:55:24.190
There was a Butoh dancer.

00:55:24.190 --> 00:55:27.320
Text by Samuel Beckett,
35 millimeter slides,

00:55:27.320 --> 00:55:31.660
16 millimeter film projection,
quadraphonic electronic sounds,

00:55:31.660 --> 00:55:34.980
percussion, harmonium,
piano, and flute.

00:55:34.980 --> 00:55:37.950 position:56%
And so for 1968 this was a lot of --

00:55:37.950 --> 00:55:41.420
a lot of cables and a lot of
analog equipment to wrangle.

00:55:41.420 --> 00:55:47.080
And my experience with the piece
was to bring it to the world

00:55:47.080 --> 00:55:49.830
of the digital and make
it a digital piece.

00:55:49.830 --> 00:55:53.520
It was through researching
this piece that I started

00:55:53.520 --> 00:55:55.830
to understand the process
of integrating media.

00:55:55.830 --> 00:55:58.530
And one of the most
interesting parts of that process

00:55:58.530 --> 00:56:03.310 position:56%
to me is this diagramming phase that
Steve and William both talked about.

00:56:03.310 --> 00:56:09.530
So even in 1968 these sort
of diagrams start to crop up,

00:56:09.530 --> 00:56:12.210
and so that you see that
composers are really starting

00:56:12.210 --> 00:56:16.430
to consider space as one
of the parameters that's

00:56:16.430 --> 00:56:17.730
as important as anything else.

00:56:17.730 --> 00:56:19.510
It's as important as the
melody and the harmony

00:56:19.510 --> 00:56:21.480
and the -- and the volumes.

00:56:21.480 --> 00:56:26.790
And so this is an example of a 1968
version of a kind of stage plan

00:56:26.790 --> 00:56:29.610
with the 16 millimeter
projector at the bottom

00:56:29.610 --> 00:56:32.620
and the two slide projectors in
the middle and these two screens

00:56:32.620 --> 00:56:35.350
that are represented by those
lines, and then the piano,

00:56:35.350 --> 00:56:36.920
percussion, up in the upper left.

00:56:36.920 --> 00:56:41.200
And then what happens over
the course of the history

00:56:41.200 --> 00:56:42.960
of integrated media, of intermedia,

00:56:42.960 --> 00:56:45.310
is we have a much more
sophisticated way

00:56:45.310 --> 00:56:48.560
of managing these forces
in the diagram stage.

00:56:48.560 --> 00:56:51.090
And for me it's one of the most
fun parts, is the creative part

00:56:51.090 --> 00:56:55.750
of thinking about how screens can
be set up, what they'll be made,

00:56:55.750 --> 00:56:57.920
where they'll be, whether
we're projecting on the walls

00:56:57.920 --> 00:57:01.570
or base drum heads, or
whatever, it's a really fun,

00:57:01.570 --> 00:57:03.210
creative part of the process.

00:57:03.210 --> 00:57:06.360
So where this usually starts for
me, and it's the same for Habitat,

00:57:06.360 --> 00:57:07.780
it's the same for all
the pieces I worked on,

00:57:07.780 --> 00:57:12.030
is in a simple 3D rendering
software.

00:57:12.030 --> 00:57:14.340
Sometimes I use this
software called SketchUp,

00:57:14.340 --> 00:57:18.870
which is a little Google
offshoot, to create rudimentary,

00:57:18.870 --> 00:57:24.590
three-dimensional abstract
representations, I guess, of --

00:57:24.590 --> 00:57:27.710
geometric representations of
what the stage could look like.

00:57:27.710 --> 00:57:31.700
And so not knowing what
all of these shapes mean,

00:57:31.700 --> 00:57:36.480
it doesn't have much meaning
to someone outside the project,

00:57:36.480 --> 00:57:41.210
but this was a design
for a three screen system

00:57:41.210 --> 00:57:42.950
for James Dylan's piece.

00:57:42.950 --> 00:57:45.520
James is known as a
Scottish composer

00:57:45.520 --> 00:57:48.440
who writes really long
and complex pieces.

00:57:48.440 --> 00:57:50.780
And during the sort of
premier of this piece we had

00:57:50.780 --> 00:57:52.480
to come up with this design.

00:57:52.480 --> 00:57:57.530 position:56%
And it was realized in this form
you can see the three screens angled

00:57:57.530 --> 00:57:59.540
in the lower left and upper right,

00:57:59.540 --> 00:58:04.050
and in the middle screen
there's a base drum projecting --

00:58:04.050 --> 00:58:05.350
protruding through it.

00:58:05.350 --> 00:58:06.650
You can see the concept here

00:58:06.650 --> 00:58:09.160
and then this is the
realization of the concept.

00:58:09.160 --> 00:58:13.470
So the integration of those screens
is fundamental to the piece itself.

00:58:13.470 --> 00:58:17.170
And it defines the piece's overall
environment and characteristics

00:58:17.170 --> 00:58:23.980 position:56%
and really sets it apart from a very
traditional sort of binary of actor,

00:58:23.980 --> 00:58:25.870
singer, dancer, and screen.

00:58:25.870 --> 00:58:29.420
Instead, it puts the
actor, the performer,

00:58:29.420 --> 00:58:32.260
in the projected installation.

00:58:32.260 --> 00:58:36.590
And so I've tried to do this with
nearly every piece I've created,

00:58:36.590 --> 00:58:38.900
and Habitat is no exception.

00:58:38.900 --> 00:58:40.830
In another version of the piece,

00:58:40.830 --> 00:58:45.920
we often find ourselves requiring
a sort of site specificity,

00:58:45.920 --> 00:58:51.360
which you've probably heard in the
sort of description of public art,

00:58:51.360 --> 00:58:56.850
of site specific art, and some
spaces don't accommodate the same

00:58:56.850 --> 00:58:58.150
installation twice.

00:58:58.150 --> 00:59:00.200
And so I often end up
reinventing this integration

00:59:00.200 --> 00:59:01.570
of media for each new space.

00:59:01.570 --> 00:59:03.870
This is another version
of the same piece

00:59:03.870 --> 00:59:06.160
with the same musical
instruments and the same sounds,

00:59:06.160 --> 00:59:10.900
but a completely different
projection design that was more apt

00:59:10.900 --> 00:59:14.730
to function correctly
in the space of this --

00:59:14.730 --> 00:59:18.140
of this theater in the
Netherlands called the Bim House.

00:59:18.140 --> 00:59:23.430 position:56%
And the idea here was that the black
screen behind the circular base drum

00:59:23.430 --> 00:59:25.790
screen in the middle
is actually looking

00:59:25.790 --> 00:59:30.200
out over the harbor
and river in Amsterdam.

00:59:30.200 --> 00:59:33.720
And so these sort of sail
screens become a nice foreground

00:59:33.720 --> 00:59:35.020
to that backdrop.

00:59:35.020 --> 00:59:38.800
So my main interest is in looking
at the space, and what the meaning

00:59:38.800 --> 00:59:40.100
of that space -- what that space is

00:59:40.100 --> 00:59:43.520
and integrating a screen
design that's complementary

00:59:43.520 --> 00:59:48.130
or that's contrasting in a way
that creates its own conversation,

00:59:48.130 --> 00:59:52.040 position:56%
that makes for some sort of level
of interpretation from the audience,

00:59:52.040 --> 00:59:55.200
in this case the motivation
was sails and ships,

00:59:55.200 --> 00:59:58.600
and in this case the
motivation was to create --

00:59:58.600 --> 01:00:02.850
to recreate the dry canal
beds of the Los Angeles River.

01:00:02.850 --> 01:00:07.290
And in the case of -- you see here,
this is sort of behind the scenes.

01:00:07.290 --> 01:00:12.340
This is the back view of the
sails in James Dylan's piece.

01:00:12.340 --> 01:00:14.860
Some other images from
that same thing.

01:00:14.860 --> 01:00:17.810 position:56%
One of the largest productions I
worked on also had its origins here,

01:00:17.810 --> 01:00:22.040
which is in the National
Symphony Orchestra's presentation

01:00:22.040 --> 01:00:26.110
of a new piece called George
Washington, by Roger Reynolds.

01:00:26.110 --> 01:00:29.640
And in this case we converted
the Kennedy Center space

01:00:29.640 --> 01:00:37.090
into a three screen, 36 panel
array of images that were scaled

01:00:37.090 --> 01:00:43.290 position:56%
to the space and were designed to be
evocative of the inside of the top

01:00:43.290 --> 01:00:45.700
of the Mount Vernon
mansion, Washington's mansion

01:00:45.700 --> 01:00:48.440
on the Mount Vernon estate,
which is built of these panels

01:00:48.440 --> 01:00:51.350
of windows in an octagonal cupola.

01:00:51.350 --> 01:00:55.220
So we wanted to expand that cupola
and basically take the interior

01:00:55.220 --> 01:00:57.340
of that and put that onto the stage

01:00:57.340 --> 01:01:02.480
of the National Symphony's Kennedy
Center stage, which I'm sure some

01:01:02.480 --> 01:01:05.410
of you -- some of you
here have seen.

01:01:05.410 --> 01:01:10.310
And that sort of scale relationship
and the bringing of the orchestra

01:01:10.310 --> 01:01:13.670
to that landscape of the Mount
Vernon estate was our way

01:01:13.670 --> 01:01:16.650
of integrating the
concept and media.

01:01:16.650 --> 01:01:18.570
That's my main -- my
main goal in all of this.

01:01:18.570 --> 01:01:24.900
A couple other images from that
performance at the Kennedy Center.

01:01:24.900 --> 01:01:27.440
And the newest project
I'm working on is trying

01:01:27.440 --> 01:01:28.760
to do the opposite in scale.

01:01:28.760 --> 01:01:31.510
Instead of big projections,
we're scaling everything

01:01:31.510 --> 01:01:33.930
down to two by two foot boxes.

01:01:33.930 --> 01:01:36.560
This is the initial
sketch up version

01:01:36.560 --> 01:01:39.800
of the -- of the 3D rendering.

01:01:39.800 --> 01:01:42.890
And here is an early
performance from March

01:01:42.890 --> 01:01:46.660
of the string quartet sort
of situated in these --

01:01:46.660 --> 01:01:49.610
this constellation
of two-sided boxes.

01:01:49.610 --> 01:01:53.300
And the projections are mapped
precisely onto these surfaces.

01:01:53.300 --> 01:01:56.980
And this is the part where
the actors come on stage

01:01:56.980 --> 01:01:59.600
and they are situated
also among these boxes.

01:01:59.600 --> 01:02:02.720
And the whole -- the whole
concept of this piece is based

01:02:02.720 --> 01:02:07.040
on the history of flight from
sort of cave paintings of birds

01:02:07.040 --> 01:02:10.050
to the entire history of
human aspiration to fly.

01:02:10.050 --> 01:02:13.960
And so the images come
from that history.

01:02:13.960 --> 01:02:16.220
They tell that story.

01:02:16.220 --> 01:02:21.520
But the purpose of the boxes is
to create a vocation of box kites,

01:02:21.520 --> 01:02:24.620
which is one of the original
ways of putting something in --

01:02:24.620 --> 01:02:28.910
aloft in the air and it's
also the original conception

01:02:28.910 --> 01:02:31.350
of the biplane wing from
the Wright brothers.

01:02:31.350 --> 01:02:34.620
So that's the motivation
behind these boxes.

01:02:34.620 --> 01:02:38.450
And over the course of the piece
that motivation gets revealed.

01:02:38.450 --> 01:02:41.550
I like that idea that the
concept can be somewhat ambiguous,

01:02:41.550 --> 01:02:44.380
can seem like abstracted cubes
at the beginning of the piece,

01:02:44.380 --> 01:02:47.840 position:56%
only to reveal as -- to reveal later
that it's supposed to be a wing.

01:02:47.840 --> 01:02:52.650
And for Habitat, as you've
seen many images already,

01:02:52.650 --> 01:02:58.150
the goal there again was to scale
up and to immerse the audience

01:02:58.150 --> 01:03:00.940 position:56%
in this world of microscopic imagery

01:03:00.940 --> 01:03:03.140
from the materials of
the percussion setup.

01:03:03.140 --> 01:03:06.830
And so for that process it
meant mapping huge projections

01:03:06.830 --> 01:03:12.510
onto these facets of the stairwells
that lead to the lower level

01:03:12.510 --> 01:03:15.720
and the upper mezzanine and the top
of the escalator of the east wing

01:03:15.720 --> 01:03:18.840
of the National Gallery and
controlling them precisely

01:03:18.840 --> 01:03:23.050
with the -- with the softwares
that William just described.

01:03:23.050 --> 01:03:29.030
So the scale there isn't so much
about making my percussion playing

01:03:29.030 --> 01:03:32.600
in the body somehow related to the
-- to the scale of the screens,

01:03:32.600 --> 01:03:35.700
but instead you create a
wall of imagery that is --

01:03:35.700 --> 01:03:40.310
that is all sort of
surrounding and encompassing.

01:03:40.310 --> 01:03:43.650 position:56%
For the -- for another performance
in the Katzen Gallery we didn't have

01:03:43.650 --> 01:03:45.630
that luxury of creating such scale.

01:03:45.630 --> 01:03:48.190
So for that we actually
went the opposite direction.

01:03:48.190 --> 01:03:52.390
We created object-like projections
onto the smaller surfaces

01:03:52.390 --> 01:03:54.550
of the -- of the -- of the setups.

01:03:54.550 --> 01:03:57.550
So this is one of the setups.

01:03:57.550 --> 01:04:02.080
You can see off to stage left
over here with the flowerpots,

01:04:02.080 --> 01:04:05.280
and below there's this wooden
cube, and it's difficult to see

01:04:05.280 --> 01:04:08.100
on this projection but there
are images precisely mapped

01:04:08.100 --> 01:04:12.060
onto those facets of
that white gallery cube.

01:04:12.060 --> 01:04:14.750
And similar, this was a
test setup of making sure

01:04:14.750 --> 01:04:18.320
that the images would map onto
these other white gallery cubes

01:04:18.320 --> 01:04:23.010
that served not only as percussion
instruments, like cajons,

01:04:23.010 --> 01:04:27.100
but they also served as
something that's similar

01:04:27.100 --> 01:04:29.430
and familiar to a gallery space.

01:04:29.430 --> 01:04:35.140
So as not to impose a completely
foreign sculptural identity

01:04:35.140 --> 01:04:38.170
onto the piece, we used
existing common resources

01:04:38.170 --> 01:04:39.880
within the gallery itself.

01:04:39.880 --> 01:04:42.870
And so that's the -- that's
where the piece has been.

01:04:42.870 --> 01:04:46.250
It's transformed from this huge,
immersive piece that was all

01:04:46.250 --> 01:04:50.450
about architecture and space,
to this object-oriented,

01:04:50.450 --> 01:04:54.610
very focused version in the Katzen
Gallery at the American University,

01:04:54.610 --> 01:04:58.900
and here today presenting a version
just for the three movements of --

01:04:58.900 --> 01:05:02.300 position:56%
with the live percussion playing
processed through electronic sounds,

01:05:02.300 --> 01:05:07.430
without the video projections,
just to offer another version

01:05:07.430 --> 01:05:10.790 position:56%
of the piece, because every space
warrants a different interpretation.

01:05:10.790 --> 01:05:14.170
And I consider space to be the
fourth collaborator of our quartet,

01:05:14.170 --> 01:05:17.720
and that it has just
as big an impact

01:05:17.720 --> 01:05:20.520
on the way we configure
this piece and interpret it

01:05:20.520 --> 01:05:23.620
as any other consideration.

01:05:23.620 --> 01:05:28.150
And so I think with that we
can move on to the second part

01:05:28.150 --> 01:05:30.410
of the presentation, which
is a performance of three

01:05:30.410 --> 01:05:32.510
of the movements of Habitat.

01:05:32.510 --> 01:05:35.500
[ Applause ]

01:05:49.510 --> 01:23:48.500
[ Music ]

01:23:55.510 --> 01:24:17.500
[ Applause ]

01:24:19.200 --> 01:24:22.860
&gt;&gt; This has been a presentation
of the Library of Congress.

01:24:22.860 --> 01:24:24.970
Visit us at loc.gov.

