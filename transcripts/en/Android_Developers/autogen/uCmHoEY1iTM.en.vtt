WEBVTT
Kind: captions
Language: en

00:00:01.550 --> 00:00:03.649
let's be honest you're an awesome

00:00:03.649 --> 00:00:03.659
let's be honest you're an awesome
 

00:00:03.659 --> 00:00:05.809
let's be honest you're an awesome
engineer with an awesome app and you are

00:00:05.809 --> 00:00:05.819
engineer with an awesome app and you are
 

00:00:05.819 --> 00:00:07.909
engineer with an awesome app and you are
using threading to the max sadly though

00:00:07.909 --> 00:00:07.919
using threading to the max sadly though
 

00:00:07.919 --> 00:00:09.620
using threading to the max sadly though
managing all those individual threads

00:00:09.620 --> 00:00:09.630
managing all those individual threads
 

00:00:09.630 --> 00:00:10.970
managing all those individual threads
and assigning work between them is

00:00:10.970 --> 00:00:10.980
and assigning work between them is
 

00:00:10.980 --> 00:00:13.100
and assigning work between them is
causing you to lose your hair my name is

00:00:13.100 --> 00:00:13.110
causing you to lose your hair my name is
 

00:00:13.110 --> 00:00:15.289
causing you to lose your hair my name is
Colt McAnlis and please don't join the

00:00:15.289 --> 00:00:15.299
Colt McAnlis and please don't join the
 

00:00:15.299 --> 00:00:17.480
Colt McAnlis and please don't join the
bald Club instead use the thread pools

00:00:17.480 --> 00:00:17.490
bald Club instead use the thread pools
 

00:00:17.490 --> 00:00:19.099
bald Club instead use the thread pools
class which is an ideal primitive for

00:00:19.099 --> 00:00:19.109
class which is an ideal primitive for
 

00:00:19.109 --> 00:00:20.990
class which is an ideal primitive for
breaking up lots of work into little

00:00:20.990 --> 00:00:21.000
breaking up lots of work into little
 

00:00:21.000 --> 00:00:22.790
breaking up lots of work into little
buckets see historically it was

00:00:22.790 --> 00:00:22.800
buckets see historically it was
 

00:00:22.800 --> 00:00:24.290
buckets see historically it was
commonplace that applications would use

00:00:24.290 --> 00:00:24.300
commonplace that applications would use
 

00:00:24.300 --> 00:00:27.349
commonplace that applications would use
a dedicated thread model that is one

00:00:27.349 --> 00:00:27.359
a dedicated thread model that is one
 

00:00:27.359 --> 00:00:28.700
a dedicated thread model that is one
thread that only deals with database

00:00:28.700 --> 00:00:28.710
thread that only deals with database
 

00:00:28.710 --> 00:00:30.050
thread that only deals with database
rights while a separate thread only

00:00:30.050 --> 00:00:30.060
rights while a separate thread only
 

00:00:30.060 --> 00:00:31.429
rights while a separate thread only
handles streaming of music and a third

00:00:31.429 --> 00:00:31.439
handles streaming of music and a third
 

00:00:31.439 --> 00:00:33.950
handles streaming of music and a third
one only handles networking these setups

00:00:33.950 --> 00:00:33.960
one only handles networking these setups
 

00:00:33.960 --> 00:00:36.020
one only handles networking these setups
are okay because the amount of work per

00:00:36.020 --> 00:00:36.030
are okay because the amount of work per
 

00:00:36.030 --> 00:00:38.030
are okay because the amount of work per
thread isn't that large and it's okay to

00:00:38.030 --> 00:00:38.040
thread isn't that large and it's okay to
 

00:00:38.040 --> 00:00:40.250
thread isn't that large and it's okay to
handle this work in sequential order but

00:00:40.250 --> 00:00:40.260
handle this work in sequential order but
 

00:00:40.260 --> 00:00:42.200
handle this work in sequential order but
there reaches a point where this model

00:00:42.200 --> 00:00:42.210
there reaches a point where this model
 

00:00:42.210 --> 00:00:43.700
there reaches a point where this model
starts to fall over say for example

00:00:43.700 --> 00:00:43.710
starts to fall over say for example
 

00:00:43.710 --> 00:00:46.310
starts to fall over say for example
you've got 40 bitmaps to decode and each

00:00:46.310 --> 00:00:46.320
you've got 40 bitmaps to decode and each
 

00:00:46.320 --> 00:00:48.799
you've got 40 bitmaps to decode and each
decode takes like four milliseconds or

00:00:48.799 --> 00:00:48.809
decode takes like four milliseconds or
 

00:00:48.809 --> 00:00:50.330
decode takes like four milliseconds or
something and putting all of this work

00:00:50.330 --> 00:00:50.340
something and putting all of this work
 

00:00:50.340 --> 00:00:52.700
something and putting all of this work
on a single dedicated thread is a bad

00:00:52.700 --> 00:00:52.710
on a single dedicated thread is a bad
 

00:00:52.710 --> 00:00:54.920
on a single dedicated thread is a bad
idea since it'll take 80 milliseconds

00:00:54.920 --> 00:00:54.930
idea since it'll take 80 milliseconds
 

00:00:54.930 --> 00:00:56.479
idea since it'll take 80 milliseconds
total to get all that work done in a

00:00:56.479 --> 00:00:56.489
total to get all that work done in a
 

00:00:56.489 --> 00:00:58.670
total to get all that work done in a
sequential fashion on the other hand if

00:00:58.670 --> 00:00:58.680
sequential fashion on the other hand if
 

00:00:58.680 --> 00:01:00.470
sequential fashion on the other hand if
you created 10 threads and let each one

00:01:00.470 --> 00:01:00.480
you created 10 threads and let each one
 

00:01:00.480 --> 00:01:02.420
you created 10 threads and let each one
decode four bitmaps then you'd end up

00:01:02.420 --> 00:01:02.430
decode four bitmaps then you'd end up
 

00:01:02.430 --> 00:01:04.969
decode four bitmaps then you'd end up
only taking 16 milliseconds total but

00:01:04.969 --> 00:01:04.979
only taking 16 milliseconds total but
 

00:01:04.979 --> 00:01:06.140
only taking 16 milliseconds total but
then of course you run into the problem

00:01:06.140 --> 00:01:06.150
then of course you run into the problem
 

00:01:06.150 --> 00:01:08.240
then of course you run into the problem
of how to properly pass the workaround

00:01:08.240 --> 00:01:08.250
of how to properly pass the workaround
 

00:01:08.250 --> 00:01:09.890
of how to properly pass the workaround
between those threads schedule that work

00:01:09.890 --> 00:01:09.900
between those threads schedule that work
 

00:01:09.900 --> 00:01:11.469
between those threads schedule that work
and then managing of those threads and

00:01:11.469 --> 00:01:11.479
and then managing of those threads and
 

00:01:11.479 --> 00:01:13.460
and then managing of those threads and
before you start stressing out about

00:01:13.460 --> 00:01:13.470
before you start stressing out about
 

00:01:13.470 --> 00:01:15.830
before you start stressing out about
writing all that code don't worry this

00:01:15.830 --> 00:01:15.840
writing all that code don't worry this
 

00:01:15.840 --> 00:01:18.590
writing all that code don't worry this
is exactly what thread pool executors

00:01:18.590 --> 00:01:18.600
is exactly what thread pool executors
 

00:01:18.600 --> 00:01:20.899
is exactly what thread pool executors
primitive is for basically this class

00:01:20.899 --> 00:01:20.909
primitive is for basically this class
 

00:01:20.909 --> 00:01:22.399
primitive is for basically this class
will just let you spin up a number of

00:01:22.399 --> 00:01:22.409
will just let you spin up a number of
 

00:01:22.409 --> 00:01:24.469
will just let you spin up a number of
threads and toss blocks of work to

00:01:24.469 --> 00:01:24.479
threads and toss blocks of work to
 

00:01:24.479 --> 00:01:26.539
threads and toss blocks of work to
execute on it thread pool executor

00:01:26.539 --> 00:01:26.549
execute on it thread pool executor
 

00:01:26.549 --> 00:01:28.070
execute on it thread pool executor
handles all of the heavy lifting of

00:01:28.070 --> 00:01:28.080
handles all of the heavy lifting of
 

00:01:28.080 --> 00:01:30.200
handles all of the heavy lifting of
spinning up the threads load balancing

00:01:30.200 --> 00:01:30.210
spinning up the threads load balancing
 

00:01:30.210 --> 00:01:31.789
spinning up the threads load balancing
work across those threads and even

00:01:31.789 --> 00:01:31.799
work across those threads and even
 

00:01:31.799 --> 00:01:33.469
work across those threads and even
killing those threads when they have

00:01:33.469 --> 00:01:33.479
killing those threads when they have
 

00:01:33.479 --> 00:01:35.480
killing those threads when they have
been idle for a while basically it

00:01:35.480 --> 00:01:35.490
been idle for a while basically it
 

00:01:35.490 --> 00:01:37.039
been idle for a while basically it
handles all the heavy lifting of super

00:01:37.039 --> 00:01:37.049
handles all the heavy lifting of super
 

00:01:37.049 --> 00:01:39.020
handles all the heavy lifting of super
parallel processing on your behalf all

00:01:39.020 --> 00:01:39.030
parallel processing on your behalf all
 

00:01:39.030 --> 00:01:40.850
parallel processing on your behalf all
you have to do is split up the work but

00:01:40.850 --> 00:01:40.860
you have to do is split up the work but
 

00:01:40.860 --> 00:01:43.190
you have to do is split up the work but
there's a small caveat here how many

00:01:43.190 --> 00:01:43.200
there's a small caveat here how many
 

00:01:43.200 --> 00:01:45.440
there's a small caveat here how many
threads should your thread pool have I

00:01:45.440 --> 00:01:45.450
threads should your thread pool have I
 

00:01:45.450 --> 00:01:47.149
threads should your thread pool have I
mean technically speaking you have the

00:01:47.149 --> 00:01:47.159
mean technically speaking you have the
 

00:01:47.159 --> 00:01:48.469
mean technically speaking you have the
ability to create as many threads as you

00:01:48.469 --> 00:01:48.479
ability to create as many threads as you
 

00:01:48.479 --> 00:01:51.889
ability to create as many threads as you
want but that's not ideal see CPUs can

00:01:51.889 --> 00:01:51.899
want but that's not ideal see CPUs can
 

00:01:51.899 --> 00:01:53.630
want but that's not ideal see CPUs can
only execute a certain number of threads

00:01:53.630 --> 00:01:53.640
only execute a certain number of threads
 

00:01:53.640 --> 00:01:55.789
only execute a certain number of threads
in parallel once you get above that

00:01:55.789 --> 00:01:55.799
in parallel once you get above that
 

00:01:55.799 --> 00:01:57.560
in parallel once you get above that
number then the CPU has to start

00:01:57.560 --> 00:01:57.570
number then the CPU has to start
 

00:01:57.570 --> 00:01:59.420
number then the CPU has to start
deciding which threads get the next free

00:01:59.420 --> 00:01:59.430
deciding which threads get the next free
 

00:01:59.430 --> 00:02:01.580
deciding which threads get the next free
block of processor time based on how

00:02:01.580 --> 00:02:01.590
block of processor time based on how
 

00:02:01.590 --> 00:02:03.920
block of processor time based on how
important they are which means that if

00:02:03.920 --> 00:02:03.930
important they are which means that if
 

00:02:03.930 --> 00:02:05.899
important they are which means that if
you keep eventually adding threads

00:02:05.899 --> 00:02:05.909
you keep eventually adding threads
 

00:02:05.909 --> 00:02:08.389
you keep eventually adding threads
you'll hit a break-even point where your

00:02:08.389 --> 00:02:08.399
you'll hit a break-even point where your
 

00:02:08.399 --> 00:02:10.160
you'll hit a break-even point where your
computation isn't getting any faster

00:02:10.160 --> 00:02:10.170
computation isn't getting any faster
 

00:02:10.170 --> 00:02:11.990
computation isn't getting any faster
even though the number of threads that

00:02:11.990 --> 00:02:12.000
even though the number of threads that
 

00:02:12.000 --> 00:02:12.730
even though the number of threads that
you have

00:02:12.730 --> 00:02:12.740
you have
 

00:02:12.740 --> 00:02:14.890
you have
has increased significantly and it's

00:02:14.890 --> 00:02:14.900
has increased significantly and it's
 

00:02:14.900 --> 00:02:16.090
has increased significantly and it's
also important to note that each of

00:02:16.090 --> 00:02:16.100
also important to note that each of
 

00:02:16.100 --> 00:02:19.000
also important to note that each of
these threads aren't free each thread

00:02:19.000 --> 00:02:19.010
these threads aren't free each thread
 

00:02:19.010 --> 00:02:21.190
these threads aren't free each thread
cost you about 64k of memory and minimum

00:02:21.190 --> 00:02:21.200
cost you about 64k of memory and minimum
 

00:02:21.200 --> 00:02:23.050
cost you about 64k of memory and minimum
and that adds up quickly especially in

00:02:23.050 --> 00:02:23.060
and that adds up quickly especially in
 

00:02:23.060 --> 00:02:24.760
and that adds up quickly especially in
situations where the call stacks can

00:02:24.760 --> 00:02:24.770
situations where the call stacks can
 

00:02:24.770 --> 00:02:27.370
situations where the call stacks can
start growing pretty large as such your

00:02:27.370 --> 00:02:27.380
start growing pretty large as such your
 

00:02:27.380 --> 00:02:28.810
start growing pretty large as such your
app needs to find a sweet spot between

00:02:28.810 --> 00:02:28.820
app needs to find a sweet spot between
 

00:02:28.820 --> 00:02:30.580
app needs to find a sweet spot between
the number of cores and the point of

00:02:30.580 --> 00:02:30.590
the number of cores and the point of
 

00:02:30.590 --> 00:02:32.560
the number of cores and the point of
diminishing return with the number of

00:02:32.560 --> 00:02:32.570
diminishing return with the number of
 

00:02:32.570 --> 00:02:34.870
diminishing return with the number of
threads thankfully once again the thread

00:02:34.870 --> 00:02:34.880
threads thankfully once again the thread
 

00:02:34.880 --> 00:02:37.120
threads thankfully once again the thread
pool executors class has got you covered

00:02:37.120 --> 00:02:37.130
pool executors class has got you covered
 

00:02:37.130 --> 00:02:39.190
pool executors class has got you covered
when creating your thread pool you can

00:02:39.190 --> 00:02:39.200
when creating your thread pool you can
 

00:02:39.200 --> 00:02:41.080
when creating your thread pool you can
specify the number of initial threads

00:02:41.080 --> 00:02:41.090
specify the number of initial threads
 

00:02:41.090 --> 00:02:43.660
specify the number of initial threads
and the number of maximum threads as the

00:02:43.660 --> 00:02:43.670
and the number of maximum threads as the
 

00:02:43.670 --> 00:02:45.220
and the number of maximum threads as the
workload in the thread pool changes

00:02:45.220 --> 00:02:45.230
workload in the thread pool changes
 

00:02:45.230 --> 00:02:47.080
workload in the thread pool changes
it'll scale the number of alive threads

00:02:47.080 --> 00:02:47.090
it'll scale the number of alive threads
 

00:02:47.090 --> 00:02:49.750
it'll scale the number of alive threads
to match oh and a quick note the value

00:02:49.750 --> 00:02:49.760
to match oh and a quick note the value
 

00:02:49.760 --> 00:02:51.790
to match oh and a quick note the value
returned from get available processors

00:02:51.790 --> 00:02:51.800
returned from get available processors
 

00:02:51.800 --> 00:02:53.770
returned from get available processors
may not reflect the number of physical

00:02:53.770 --> 00:02:53.780
may not reflect the number of physical
 

00:02:53.780 --> 00:02:56.050
may not reflect the number of physical
cores in the device see some devices

00:02:56.050 --> 00:02:56.060
cores in the device see some devices
 

00:02:56.060 --> 00:02:58.270
cores in the device see some devices
have CPUs that will deactivate one or

00:02:58.270 --> 00:02:58.280
have CPUs that will deactivate one or
 

00:02:58.280 --> 00:03:00.340
have CPUs that will deactivate one or
more cores depending on the system load

00:03:00.340 --> 00:03:00.350
more cores depending on the system load
 

00:03:00.350 --> 00:03:01.990
more cores depending on the system load
to save battery so if your device has

00:03:01.990 --> 00:03:02.000
to save battery so if your device has
 

00:03:02.000 --> 00:03:04.480
to save battery so if your device has
two CPUs but one of them is asleep this

00:03:04.480 --> 00:03:04.490
two CPUs but one of them is asleep this
 

00:03:04.490 --> 00:03:06.760
two CPUs but one of them is asleep this
value could return one and of course

00:03:06.760 --> 00:03:06.770
value could return one and of course
 

00:03:06.770 --> 00:03:08.470
value could return one and of course
thread pools won't solve all of your

00:03:08.470 --> 00:03:08.480
thread pools won't solve all of your
 

00:03:08.480 --> 00:03:10.330
thread pools won't solve all of your
threading problems as mentioned earlier

00:03:10.330 --> 00:03:10.340
threading problems as mentioned earlier
 

00:03:10.340 --> 00:03:12.010
threading problems as mentioned earlier
unless you're dealing with lots and lots

00:03:12.010 --> 00:03:12.020
unless you're dealing with lots and lots
 

00:03:12.020 --> 00:03:13.750
unless you're dealing with lots and lots
of work packets all the time this

00:03:13.750 --> 00:03:13.760
of work packets all the time this
 

00:03:13.760 --> 00:03:16.090
of work packets all the time this
thing's kind of overkill it's best use

00:03:16.090 --> 00:03:16.100
thing's kind of overkill it's best use
 

00:03:16.100 --> 00:03:17.830
thing's kind of overkill it's best use
things like handler threads or async

00:03:17.830 --> 00:03:17.840
things like handler threads or async
 

00:03:17.840 --> 00:03:20.200
things like handler threads or async
task loader for specific types of work

00:03:20.200 --> 00:03:20.210
task loader for specific types of work
 

00:03:20.210 --> 00:03:22.300
task loader for specific types of work
blocks and only throw the massive

00:03:22.300 --> 00:03:22.310
blocks and only throw the massive
 

00:03:22.310 --> 00:03:24.220
blocks and only throw the massive
computing problems at the thread pool

00:03:24.220 --> 00:03:24.230
computing problems at the thread pool
 

00:03:24.230 --> 00:03:26.560
computing problems at the thread pool
and for you power users out there

00:03:26.560 --> 00:03:26.570
and for you power users out there
 

00:03:26.570 --> 00:03:28.930
and for you power users out there
remember that renderscript might be a

00:03:28.930 --> 00:03:28.940
remember that renderscript might be a
 

00:03:28.940 --> 00:03:30.310
remember that renderscript might be a
better alternative to large-scale

00:03:30.310 --> 00:03:30.320
better alternative to large-scale
 

00:03:30.320 --> 00:03:32.230
better alternative to large-scale
parallel work on android devices but

00:03:32.230 --> 00:03:32.240
parallel work on android devices but
 

00:03:32.240 --> 00:03:35.050
parallel work on android devices but
that's a whole separate set of videos

00:03:35.050 --> 00:03:35.060
that's a whole separate set of videos
 

00:03:35.060 --> 00:03:36.880
that's a whole separate set of videos
that we haven't gotten into yet and

00:03:36.880 --> 00:03:36.890
that we haven't gotten into yet and
 

00:03:36.890 --> 00:03:38.620
that we haven't gotten into yet and
don't forget that systrace is an

00:03:38.620 --> 00:03:38.630
don't forget that systrace is an
 

00:03:38.630 --> 00:03:40.480
don't forget that systrace is an
amazingly powerful tool that lets you

00:03:40.480 --> 00:03:40.490
amazingly powerful tool that lets you
 

00:03:40.490 --> 00:03:42.250
amazingly powerful tool that lets you
visualize how work is flowing through

00:03:42.250 --> 00:03:42.260
visualize how work is flowing through
 

00:03:42.260 --> 00:03:44.050
visualize how work is flowing through
the threads in your application it's a

00:03:44.050 --> 00:03:44.060
the threads in your application it's a
 

00:03:44.060 --> 00:03:45.970
the threads in your application it's a
great way to validate that things are

00:03:45.970 --> 00:03:45.980
great way to validate that things are
 

00:03:45.980 --> 00:03:48.400
great way to validate that things are
working as intended and also see all the

00:03:48.400 --> 00:03:48.410
working as intended and also see all the
 

00:03:48.410 --> 00:03:50.020
working as intended and also see all the
other crazy threads that are being

00:03:50.020 --> 00:03:50.030
other crazy threads that are being
 

00:03:50.030 --> 00:03:52.720
other crazy threads that are being
worked on by other parts of your app and

00:03:52.720 --> 00:03:52.730
worked on by other parts of your app and
 

00:03:52.730 --> 00:03:54.280
worked on by other parts of your app and
that's the trick with performance isn't

00:03:54.280 --> 00:03:54.290
that's the trick with performance isn't
 

00:03:54.290 --> 00:03:56.140
that's the trick with performance isn't
it I mean you can make assumptions but

00:03:56.140 --> 00:03:56.150
it I mean you can make assumptions but
 

00:03:56.150 --> 00:03:57.520
it I mean you can make assumptions but
things don't always work the way you

00:03:57.520 --> 00:03:57.530
things don't always work the way you
 

00:03:57.530 --> 00:03:59.380
things don't always work the way you
think which is why you need to check out

00:03:59.380 --> 00:03:59.390
think which is why you need to check out
 

00:03:59.390 --> 00:04:00.340
think which is why you need to check out
the rest of the Android performance

00:04:00.340 --> 00:04:00.350
the rest of the Android performance
 

00:04:00.350 --> 00:04:02.140
the rest of the Android performance
patterns videos and don't forget to join

00:04:02.140 --> 00:04:02.150
patterns videos and don't forget to join
 

00:04:02.150 --> 00:04:04.540
patterns videos and don't forget to join
our Google+ community to ask a lot of

00:04:04.540 --> 00:04:04.550
our Google+ community to ask a lot of
 

00:04:04.550 --> 00:04:07.300
our Google+ community to ask a lot of
hard threading questions as well so keep

00:04:07.300 --> 00:04:07.310
hard threading questions as well so keep
 

00:04:07.310 --> 00:04:09.160
hard threading questions as well so keep
calm profile your code and always

00:04:09.160 --> 00:04:09.170
calm profile your code and always
 

00:04:09.170 --> 00:04:12.400
calm profile your code and always
remember perf matters

