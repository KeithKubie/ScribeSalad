WEBVTT
Kind: captions
Language: en

00:00:00.300 --> 00:00:03.750
In other words, if you increase
the size of your outputs,

00:00:03.750 --> 00:00:07.060
your classifier becomes very
confident about its predictions.

00:00:07.060 --> 00:00:09.440
But if you reduce
the size of your outputs,

00:00:09.440 --> 00:00:11.810
your classifier becomes very unsure.

00:00:11.810 --> 00:00:13.390
Keep this in mind for later.

00:00:13.390 --> 00:00:17.410
We'll want our classifier to not be
too sure of itself in the beginning.

00:00:17.410 --> 00:00:21.480
And then over time,
it will gain confidence as it learns.

00:00:21.480 --> 00:00:25.350
Next, we need a way to represent
our labels mathematically.

00:00:25.350 --> 00:00:28.750
We just said, let's have the
probabilities for the correct class be

00:00:28.750 --> 00:00:33.410
close to 1, and the probability for
all the others be close to 0.

00:00:33.410 --> 00:00:35.400
We can write exactly with that.

00:00:35.400 --> 00:00:37.920
Each label will be
represented by a vector

00:00:37.920 --> 00:00:40.460
that is as long as there are classes and

00:00:40.460 --> 00:00:45.780
it has the value 1.0 for the correct
class and 0 every where else.

00:00:45.780 --> 00:00:47.710
This is often called one-hot encoding.

