WEBVTT
Kind: captions
Language: en

00:00:00.160 --> 00:00:02.940
Do you ever get into an argument where you know you're right

00:00:02.940 --> 00:00:05.880
And yet even with your eloquent explanation and

00:00:05.880 --> 00:00:08.720
All of the facts on your side, you just can't get through

00:00:08.745 --> 00:00:11.275
Is there a strategic way to successfully

00:00:11.275 --> 00:00:14.275
Convince somebody and change their opinion ?

00:00:14.275 --> 00:00:17.355
The first and most disappointing thing that you have to come to terms with is this

00:00:17.355 --> 00:00:20.335
Facts don't convince people. Especially if they already have an opinion

00:00:20.415 --> 00:00:23.345
We all like to THINK that

00:00:23.345 --> 00:00:26.445
Information or indisputable study would convince US in an argument

00:00:26.445 --> 00:00:32.685
But study after study shows that when certain facts don't conform to our beliefs,

00:00:32.685 --> 00:00:35.725
Our brains are happy to disregard or simply rationalize them away

00:00:35.725 --> 00:00:40.000
In one study, scientists ask people if they believe in man-made climate change

00:00:40.000 --> 00:00:44.400
And then categorize them as believers or deniers

00:00:44.415 --> 00:00:47.375
They then told some that scientist have reevaluated the data and concluded that

00:00:47.375 --> 00:00:50.325
Predictions of the future were much worse than before

00:00:50.325 --> 00:00:56.400
While some others were told the situation wasn't nearly as bad as once thought

00:00:56.405 --> 00:00:59.285
But these facts have some interesting results on their beliefs.

00:00:59.285 --> 00:01:02.135
People who didn't believe in climate change and were told that things would be much worse

00:01:02.135 --> 00:01:05.605
Completely ignored this fact and their opinions were unchanged

00:01:05.785 --> 00:01:08.735
But if they were told that things weren't nearly as bad

00:01:08.775 --> 00:01:11.695
Their beliefs moved much farther in that direction

00:01:11.695 --> 00:01:14.745
And the same thing happened to those who believed strongly in climate change

00:01:14.745 --> 00:01:17.775
When told that things are now predicted to be worse

00:01:17.775 --> 00:01:21.075
They shifted their opinions more strongly in that direction

00:01:21.075 --> 00:01:25.000
Whereas those told it wouldn't be so bad didn't change their opinions at all

00:01:25.000 --> 00:01:27.105
The facts only caused people to polarize

00:01:27.105 --> 00:01:33.200
It turns out that once formed, people's impressions and opinions are extremely perseverant

00:01:33.275 --> 00:01:35.645
And cognitive scientists say

00:01:35.645 --> 00:01:38.705
Much of this is actually linked to our abilities as a human to cooperate

00:01:38.705 --> 00:01:41.445
A skill that no other animals have

00:01:41.445 --> 00:01:45.680
To the degree that humans do from hunting and gathering to agriculture and modern computers

00:01:46.040 --> 00:01:50.740
Our cooperation allows us to rely on one and another's expertise instead of knowing everything

00:01:50.800 --> 00:01:55.560
As a result we can hardly tell where our own understanding ends and another begin

00:01:55.660 --> 00:01:59.860
Ultimately strong beliefs don't actually come from deep understandings

00:01:59.880 --> 00:02:03.040
This is known as the "Illusion of Explanatory Depth"

00:02:03.280 --> 00:02:06.680
If I asked you to rate your understanding of something like a toilet

00:02:06.680 --> 00:02:09.740
Zippers or computers chances are

00:02:09.740 --> 00:02:12.380
You believe you know way more than you actually do

00:02:12.520 --> 00:02:17.160
Go on and try to explain step by step how a toilet or a zipper functions in detail.

00:02:17.380 --> 00:02:21.835
Sometimes this simple act can expose how baseless our and others opinion is

00:02:21.840 --> 00:02:26.260
In one study, when participants were asked to rate their of public policies

00:02:26.260 --> 00:02:30.820
Like healthcare and then later asked to explain in as much detail as possible

00:02:30.820 --> 00:02:33.680
The impact of implementing those policies

00:02:33.680 --> 00:02:36.300
They would quickly turn down the intensity of their beliefs

00:02:36.300 --> 00:02:38.900
Having been exposed to their own ignorance

00:02:38.900 --> 00:02:42.740
How else can we overcome these tendencies and convince people in an argument?

00:02:42.860 --> 00:02:45.500
It turns out that we need to focus on the common motive

00:02:45.500 --> 00:02:48.660
As per by Tali Sharot(?) a cognitive neural scientist

00:02:48.660 --> 00:02:52.115
That is focus on the motives and things that you can agree on

00:02:52.115 --> 00:02:55.085
One study looking at parent afraid to vaccine their children

00:02:55.085 --> 00:02:56.520
Because the fear of autism

00:02:56.520 --> 00:02:59.040
Found that they simply told them the facts

00:02:59.040 --> 00:03:03.060
That the science shows there is no link between the two they wouldn't listen

00:03:03.060 --> 00:03:06.500
But when they focus on the common goal of protecting their children

00:03:06.505 --> 00:03:09.305
And explained what vaccines are meant to prevent

00:03:09.305 --> 00:03:12.080
Things like measles, mumps, polio, tetanus and

00:03:12.080 --> 00:03:15.780
How those diseases impact children who get them without even mentioning autism

00:03:15.780 --> 00:03:19.020
They were more likely to have their kids vaccinated after

00:03:19.020 --> 00:03:23.780
Finally humans are known to have something called an in-group and out-group bias

00:03:23.780 --> 00:03:27.980
We tend to be of outsiders or people who we see as different from us

00:03:28.200 --> 00:03:31.360
This can come in the form of race, religion, physical traits, gender

00:03:31.360 --> 00:03:36.580
But also in the form of ideas. So people who don't share your ideas

00:03:36.580 --> 00:03:39.875
Are part of your out-group. Studies have been done to show that

00:03:39.880 --> 00:03:44.080
If you can find a way to relate to people and have them see you in a different light

00:03:44.080 --> 00:03:48.140
To see you as a part of their in-group, they're much more likely to listen to you

00:03:48.140 --> 00:03:50.620
Than if they think you're nothing like them

00:03:50.620 --> 00:03:54.455
Find the group that you're both part of and use that as a point of personal connection

00:03:54.460 --> 00:04:00.100
Now if you ever wanna challenge your own opinions or become more aware to those opinions contrary to those to your own

00:04:00.100 --> 00:04:02.280
Then you should definitely check out vubble

00:04:02.280 --> 00:04:05.740
A really awesome new company that I love which uses machine learning to

00:04:05.740 --> 00:04:08.800
Send you stuff you'll like but with a twist that also sending stuff

00:04:08.800 --> 00:04:11.240
That will nudge you outside of your filter bubble

00:04:11.240 --> 00:04:16.180
It's a cool tool that'll analyzes you and your interests, your questions, pictures and videos

00:04:16.180 --> 00:04:17.780
And then helps you flex your mental muscles

00:04:17.780 --> 00:04:20.320
With some stuff that wouldn't normally be in your feed

00:04:20.320 --> 00:04:24.300
It's a really nice way to expose yourself to a broader view of the world online

00:04:24.300 --> 00:04:25.660
And it's completely free!

00:04:25.660 --> 00:04:28.980
You can check out the chat bar on facebook by clicking the link below

00:04:28.980 --> 00:04:31.920
And then click in the get started button to launch the chat bar

00:04:31.920 --> 00:04:34.260
Help mind your feed and feed your mind

00:04:34.260 --> 00:04:37.220
And subscribe for more weekly science videos every Thursday :)

