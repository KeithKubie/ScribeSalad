WEBVTT
Kind: captions
Language: en

00:00:03.120 --> 00:00:06.380
Hi, I’m Adriene Hill, and welcome back to
Crash Course Statistics.

00:00:06.390 --> 00:00:10.500
You may have seen an ad before this video,
or maybe there’s one on the twitter feed

00:00:10.500 --> 00:00:11.740
you’re scrolling through right now.

00:00:11.740 --> 00:00:14.660
Those ads are great examples of how “Big
Data” is used.

00:00:14.670 --> 00:00:19.020
They’re often chosen just for you based
on the sites you’ve been to, your sex, approximate

00:00:19.020 --> 00:00:21.660
age, where you live and a bunch of other variables.

00:00:21.660 --> 00:00:28.340
That data is part of HUGE--GIGANTICALLY HUGE--amount of data about you and everyone else.

00:00:28.340 --> 00:00:32.680
Almost everytime you click, or don’t click
an ad, that data gets stored somewhere.

00:00:32.680 --> 00:00:37.100
Everytime you watch a YouTube video like this
one, YouTube keeps a record of it.

00:00:37.100 --> 00:00:41.320
Even some toothbrushes and water bottles collect
data on your everyday habits.

00:00:41.320 --> 00:00:45.980
Data sets include the clicks of everyone who
has ever been on Amazon every like and comment

00:00:45.980 --> 00:00:50.579
on every instagram picture every purchase
you make with a credit card every show you

00:00:50.579 --> 00:00:53.120
stream on Netflix and how long you watch.

00:00:53.120 --> 00:00:58.149
With 7.5 billion people on the planet, lots
of data is created every second.

00:00:58.149 --> 00:01:01.609
I mean pretty much just by existing, you’re
creating data.

00:01:01.609 --> 00:01:03.860
So much data that we call it…”Big Data.”

00:01:03.860 --> 00:01:13.140
INTRO

00:01:13.150 --> 00:01:16.740
In the days before smartphones, laptops, and
personal computers, data was hard to come

00:01:16.759 --> 00:01:17.759
by.

00:01:17.759 --> 00:01:20.799
It took a lot of time and effort to record
measurements, and store them.

00:01:20.799 --> 00:01:26.350
Often, data from the United States Census--which
takes place every 10 years--would take almost

00:01:26.350 --> 00:01:28.710
10 years to collect and put together.

00:01:28.710 --> 00:01:32.460
Computers have helped shorten the time it
takes to collect, summarize, and store data

00:01:32.460 --> 00:01:38.090
but as our power to collect and analyze data
increases we just make more and more of it.

00:01:38.090 --> 00:01:42.860
The term “Big Data,” in the way we use
it today, is usually credited to John Mashey.

00:01:42.860 --> 00:01:48.140
In the 1990s, he used the term to describe
data that is so big and complex, that commonly

00:01:48.140 --> 00:01:52.860
used tools to work with data, everything from collecting to interpreting, just can’t handle it.

00:01:52.860 --> 00:01:57.240
Your phone records your location, the apps
you use--and how long you use them--and all

00:01:57.240 --> 00:02:00.619
those apps that you use are each collecting
their own data on you.

00:02:00.619 --> 00:02:05.210
That’s why StubHub won’t stop pinging
me about Taylor Swift concert tickets.

00:02:05.210 --> 00:02:06.210
They KNOW me.

00:02:06.210 --> 00:02:09.760
The Coca Cola Company collects data from tons
of places, including those soft drink machines

00:02:09.760 --> 00:02:12.190
that let you add a variety of additional flavors
to your regular soda of choice.

00:02:12.190 --> 00:02:13.950
That’s the reason we now have Cherry Sprite!

00:02:13.950 --> 00:02:18.209
Enough people were choosing that combination
and Coke had the data to prove it, so they

00:02:18.209 --> 00:02:19.209
put it in cans.

00:02:19.209 --> 00:02:23.629
We’ve created an interconnected world that’s
sometimes referred to as the “Internet of

00:02:23.629 --> 00:02:24.629
Things”.

00:02:24.629 --> 00:02:28.330
Consider the network of “smart” devices
that collect data and can potentially communicate

00:02:28.330 --> 00:02:33.230
with each other everything from your refrigerator
to your car to your watch to your lights.

00:02:33.230 --> 00:02:38.820
Scientists have even rigged some SPINACH plants
to be able to wirelessly send emails about

00:02:38.820 --> 00:02:39.970
their surroundings.

00:02:39.970 --> 00:02:42.360
Even when you visit a ski resort, they’re
collecting data.

00:02:42.360 --> 00:02:47.050
They may give you a scannable RFID pass, allowing
automated ski lift access.

00:02:47.050 --> 00:02:51.379
Plus, the resort employees will know where
you are while you ski.

00:02:51.379 --> 00:02:54.580
And an app will give you all kinds of stats,
like how many days you’ve skied and your

00:02:54.580 --> 00:02:55.780
vertical distance.

00:02:55.780 --> 00:03:00.430
The whole point of Big Data is that there’s
too much of it to wrap our heads around.

00:03:00.430 --> 00:03:03.659
So let’s take one tiny aspect of it: Facebook
likes.

00:03:03.659 --> 00:03:05.709
For years, those likes seemed pretty useless.

00:03:05.709 --> 00:03:08.720
I don’t care if you like The Godfather or
Starbucks or Beyoncé.

00:03:08.720 --> 00:03:09.950
Everybody likes those things.

00:03:09.950 --> 00:03:13.269
But, that information is more revealing than
you might think.

00:03:13.269 --> 00:03:18.590
In 2013, the Proceedings of the National Academy
of Sciences published a study out of the Psychometrics

00:03:18.590 --> 00:03:20.709
Centre at Cambridge University.

00:03:20.709 --> 00:03:27.019
The participants were around 58,500 Facebook
users who took a personality survey on the

00:03:27.019 --> 00:03:28.079
researchers’ app.

00:03:28.079 --> 00:03:32.049
Then, they requested permission to view the
users’ “likes.”

00:03:32.049 --> 00:03:37.129
They found, “Individual traits and attributes
can be predicted to a high degree of accuracy

00:03:37.129 --> 00:03:39.540
based on records of users’ Likes.”

00:03:39.540 --> 00:03:43.189
So liking “Thunderstorms,” “Science,”
and “Curly Fries” were signs that someone

00:03:43.189 --> 00:03:45.129
was highly intelligent.

00:03:45.129 --> 00:03:50.170
Liking “Wu-Tang Clan,” “Shaq,” and
“Being Confused After Waking Up From Naps”

00:03:50.170 --> 00:03:52.890
pointed towards someone being a heterosexual
man.

00:03:52.890 --> 00:03:57.120
A person’s interest in Hello Kitty led to
a surprisingly detailed prediction.

00:03:57.120 --> 00:04:01.769
The paper claimed, “Users who liked the
‘Hello Kitty’ brand tended to be high

00:04:01.769 --> 00:04:08.190
on Openness and low on ‘Conscientiousness,’
‘Agreeableness,’ and ‘Emotional Stability.’

00:04:08.190 --> 00:04:13.040
They were also more likely to have Democratic
political views and to be of African-American

00:04:13.040 --> 00:04:17.300
origin, predominantly Christian, and slightly
below average age.”

00:04:17.300 --> 00:04:21.320
This is a tiny piece of the puzzle that can
give you a sense of Big Data in action.

00:04:21.320 --> 00:04:27.180
If a little bit of information about a person
can actually reveal a lot, then multiply that

00:04:27.180 --> 00:04:30.610
by the tons of other data they’re producing
each day.

00:04:30.610 --> 00:04:32.080
Then, that data gets used.

00:04:32.080 --> 00:04:35.460
Facebook itself sorts people into categories,
like political views.

00:04:35.460 --> 00:04:41.170
In 2016, the New York Times reported, “Even
if you do not like any candidates’ pages,

00:04:41.170 --> 00:04:46.080
if most of the people who like the same pages
that you do -- such as Ben and Jerry’s ice

00:04:46.080 --> 00:04:51.320
cream -- identify as liberal, then Facebook
might classify you as one, too.”

00:04:51.320 --> 00:04:52.840
(That’s just for the U.S., by the way.

00:04:52.840 --> 00:04:56.170
We don’t know what they’re gathering about
people’s views in other countries.)

00:04:56.170 --> 00:05:00.880
Categories like this allow advertisers on
Facebook to select very specific criteria

00:05:00.880 --> 00:05:04.700
and send ads to the exact groups of people
that they want to see them.

00:05:04.700 --> 00:05:10.540
For example, a Bloomberg analysis of 2016
U.S. presidential campaign finances noted

00:05:10.540 --> 00:05:16.600
that the Trump campaign chose particular groups
of Hillary Clinton supporters to see anti-Clinton

00:05:16.600 --> 00:05:19.560
ads on social media, trying to make them less
likely to vote.

00:05:19.560 --> 00:05:24.500
Between May and July of 2018, the Planned
Parenthood Federation of America was second

00:05:24.500 --> 00:05:30.340
to The Trump Make America Great Again Committee
in Facebook political ad spending in the U.S..

00:05:30.340 --> 00:05:34.690
A Planned Parenthood spokesperson told the
New York Times, “Running ads on Facebook

00:05:34.690 --> 00:05:41.500
is a targeted and cost-effective way to reach
both our 2.4 million patients and 12 million

00:05:41.500 --> 00:05:42.160
supporters.”

00:05:42.160 --> 00:05:46.380
They use location targeting, so they can be
specific about their resources in a given

00:05:46.380 --> 00:05:47.380
area.

00:05:47.380 --> 00:05:51.670
The spokesperson also noted that they run
negative political advertisements about the

00:05:51.670 --> 00:05:53.220
Trump-Pence administration.

00:05:53.220 --> 00:05:55.580
And the political implications go beyond that.

00:05:55.590 --> 00:06:00.460
Another researcher at Cambridge University,
Aleksandr Kogan, used a similar method and

00:06:00.460 --> 00:06:03.680
quiz app to that study I mentioned earlier.

00:06:03.680 --> 00:06:09.100
That helped the political consulting film
Cambridge Analytica get data on up to 87 million

00:06:09.100 --> 00:06:10.100
Facebook users.

00:06:10.100 --> 00:06:13.850
There’s a good chance that Big Data has
positively impacted your life.

00:06:13.850 --> 00:06:17.330
Perhaps you saved some money on your grocery
bill by using coupons that were tailored to

00:06:17.330 --> 00:06:18.880
your shopping habits.

00:06:18.880 --> 00:06:22.040
Or you got to buy that Cherry Sprite in a
can.

00:06:22.040 --> 00:06:26.890
Big Data is used to personalize medicine,
to predict which baseball players a team should

00:06:26.890 --> 00:06:28.770
recruit, and to create driverless cars.

00:06:28.770 --> 00:06:31.740
You’re also using Big Data every time you
use Google Maps.

00:06:31.740 --> 00:06:35.730
If you have your location enabled on your
phone, information about your location and

00:06:35.730 --> 00:06:38.880
speed is constantly being sent back to Google.

00:06:38.880 --> 00:06:41.930
That information alone isn’t super useful
to anyone.

00:06:41.930 --> 00:06:45.630
BUT, countless people around you are also
using Google Maps.

00:06:45.630 --> 00:06:49.630
So, Google has a TON of data about where people
are and how fast they’re moving.

00:06:49.630 --> 00:06:52.560
Because they’ve been doing this for a while,
they also know what traffic SHOULD look like

00:06:52.560 --> 00:06:55.890
based on things like the day of the week,
what time it is, even holidays.

00:06:55.890 --> 00:07:00.410
So, with all their data, they can then tell
you whether there’s a lot of traffic on

00:07:00.410 --> 00:07:01.590
a particular road.

00:07:01.590 --> 00:07:06.210
In 2013, Google acquired the app Waze, which
gave them even MORE data to work with.

00:07:06.210 --> 00:07:09.830
Waze users tell the app when they see traffic
and accidents.

00:07:09.830 --> 00:07:12.390
So your Google Maps app uses that, too.

00:07:12.390 --> 00:07:17.570
It also keeps track of your personal history,
which is how it can prepare you for your specific

00:07:17.570 --> 00:07:18.570
morning commute.

00:07:18.570 --> 00:07:23.570
The system City Brain, which was implemented
in Hangzhou, China starting in 2016, takes

00:07:23.570 --> 00:07:25.810
this concept one step further.

00:07:25.810 --> 00:07:28.870
The goal of City Brain is to minimize traffic
in the city.

00:07:28.870 --> 00:07:33.130
And like Google Maps, it’s also run by a
company: a huge retailer called Alibaba.

00:07:33.130 --> 00:07:36.930
The difference is: they have the help of local
government as well.

00:07:36.930 --> 00:07:40.030
So, the City Brain A-I system gets data in
ways similar to Google Maps.

00:07:40.030 --> 00:07:44.150
But, they also have access to information
from the transportation bureau and city surveillance

00:07:44.150 --> 00:07:45.150
cameras.

00:07:45.150 --> 00:07:50.560
Alibaba claimed they were able to increase
traffic speed by 15% in an area where they

00:07:50.560 --> 00:07:53.960
had been given the power to control over 100
intersections.

00:07:54.000 --> 00:07:55.380
And it’s a two way street.

00:07:55.380 --> 00:07:56.360
(Pause for ungodly amounts of laugher.)

00:07:56.360 --> 00:08:02.080
The city also uses their access to this information
to see where accidents have occurred, to get

00:08:02.080 --> 00:08:07.540
directions for emergency vehicles, and to
determine areas that need infrastructure changes.

00:08:07.540 --> 00:08:12.150
In 2018, it was announced that City Brain
was being implemented in a second city: Kuala

00:08:12.150 --> 00:08:13.230
Lumpur, Malaysia.

00:08:13.230 --> 00:08:17.200
Of course, I don’t expect you to be unquestionably
psyched about all of this.

00:08:17.200 --> 00:08:18.080
I’m not.

00:08:18.080 --> 00:08:21.260
Not everyone wants private companies to know
where they are.

00:08:21.260 --> 00:08:24.980
And we’re going to talk about privacy concerns
in depth next week.

00:08:24.980 --> 00:08:28.800
But let’s move onto another use of Big Data
in the Thought Bubble.

00:08:28.810 --> 00:08:32.020
Netflix uses “Big Data” to improve your
entertainment experience.

00:08:32.020 --> 00:08:37.050
To give recommendations, Netflix’s algorithm
learns from an endless stream of data on clicks,

00:08:37.050 --> 00:08:39.700
watch time, if you like movies starring Matt
Damon.

00:08:39.700 --> 00:08:43.580
It might learn that people who watch Queer
Eye, are more likely to enjoy The Great British

00:08:43.580 --> 00:08:48.670
Bake Off, and that people who binge watch
tend to like shows with more Seasons available.

00:08:48.670 --> 00:08:54.920
It’s also why you might get weirdly specific
category recommendations like “Lovable Losers”

00:08:54.920 --> 00:08:56.790
and “TV Shows about Friendship.”

00:08:56.790 --> 00:08:58.449
But Netflix doesn’t stop there.

00:08:58.449 --> 00:09:02.170
Big Data also influences the image you’ll
see for a show or movie.

00:09:02.170 --> 00:09:06.570
For example, here are some of the images you
might be shown for the Netflix show, Stranger

00:09:06.570 --> 00:09:07.629
Things.

00:09:07.629 --> 00:09:11.890
Netflix uses all the data at its disposal
to decide which image you’ll see.

00:09:11.890 --> 00:09:16.610
Since the Title and Image are your first exposure
to the content, choosing a picture that’s

00:09:16.610 --> 00:09:19.310
attractive to you can affect your decision
to watch it.

00:09:19.310 --> 00:09:22.220
Take, for example, the movie Good Will Hunting.

00:09:22.220 --> 00:09:27.810
This post from the Netflix Tech Blog shows
how your past viewing habits can influence

00:09:27.810 --> 00:09:28.839
which image you get5.

00:09:28.839 --> 00:09:33.000
If you’re an avid romance watcher, you might
be more drawn to a picture of Matt Damon and

00:09:33.000 --> 00:09:34.120
Minnie Driver kissing.

00:09:34.120 --> 00:09:38.060
But, if you watch a bunch of comedies, Robin
Williams might be enough to convince you to

00:09:38.060 --> 00:09:39.060
watch.

00:09:39.060 --> 00:09:43.009
You wouldn’t have known he was in the movie
if you had been shown the other image, and

00:09:43.009 --> 00:09:46.850
you may never what Ben Affleck’s Boston
accent sounds like.

00:09:46.850 --> 00:09:47.850
Just kidding.

00:09:47.850 --> 00:09:49.029
He does it in every movie..you’d know.

00:09:49.029 --> 00:09:54.180
Using the HUGE amount of data at its disposal
allows Netflix to make YOUR viewing experience

00:09:54.180 --> 00:09:55.180
better.

00:09:55.180 --> 00:09:56.180
How do you like them apples.

00:09:56.180 --> 00:09:57.600
Thanks, Thought Bubble.

00:09:57.600 --> 00:10:00.509
And Big Data can do much more than convince
us to watch a movie.

00:10:00.509 --> 00:10:05.829
We could be able to better personalize medicines
by sequencing a patient’s genome, and predicting

00:10:05.829 --> 00:10:08.230
which medicine will have the fewest side effects.

00:10:08.230 --> 00:10:12.550
Or which treatment is least likely to interact
with an existing heart condition.

00:10:12.550 --> 00:10:13.620
Big Data is here to stay.

00:10:13.620 --> 00:10:17.300
It lets us do things like use machines to
recognize the faces of criminals based on

00:10:17.300 --> 00:10:21.990
security footage, or make sure that Amazon
Warehouses are stocked so that you can get

00:10:21.990 --> 00:10:24.670
a video game for your niece in time for her
birthday.

00:10:24.670 --> 00:10:26.779
And you’re creating it right this second.

00:10:26.779 --> 00:10:30.769
YouTube knows you made it to the end of the
video or at least nearly the end.

00:10:30.769 --> 00:10:34.930
But the complexity and sheer amount of data
that’s being collected can present some

00:10:34.930 --> 00:10:35.930
problems.

00:10:35.930 --> 00:10:40.450
In the next episode, we’ll talk about a
few different ways we can overcome or at least

00:10:40.450 --> 00:10:42.060
manage some of them.

00:10:42.080 --> 00:10:44.300
Thanks for watching, I’ll see you next time.

