WEBVTT
Kind: captions
Language: en

00:00:05.796 --> 00:00:08.060
DOMINIC PREUSS: Good
afternoon, everyone.

00:00:08.060 --> 00:00:10.150
My name is Dominic
Preuss, and I'm

00:00:10.150 --> 00:00:12.430
very excited to be here
at Google I/O. So welcome

00:00:12.430 --> 00:00:15.850
to everyone who made it this far
in the conference and everyone

00:00:15.850 --> 00:00:17.350
that's on the Livestream.

00:00:17.350 --> 00:00:21.087
First of all, you made it to the
last session of the last day.

00:00:21.087 --> 00:00:23.170
So round of applause to
everyone who's still here.

00:00:23.170 --> 00:00:27.570
[APPLAUSE]

00:00:27.570 --> 00:00:29.990
We're very excited to
talk about Cloud Spanner.

00:00:33.750 --> 00:00:37.600
Before we get started, I want
to set your expectations.

00:00:37.600 --> 00:00:39.792
So before we do the
session, I want to tell you

00:00:39.792 --> 00:00:40.750
what we're going to do.

00:00:40.750 --> 00:00:42.833
And if there are other
sessions you want to go to,

00:00:42.833 --> 00:00:45.680
I won't be offended, but I want
you to know what to expect.

00:00:45.680 --> 00:00:48.400
So in this session, we're going
to talk about a brief history

00:00:48.400 --> 00:00:50.317
of Spanner at Google.

00:00:50.317 --> 00:00:52.150
I'm going to give you
an explanation of what

00:00:52.150 --> 00:00:54.370
Cloud Spanner is, and
then we'll do a demo.

00:00:54.370 --> 00:00:56.620
And hopefully we'll have a
few minutes left at the end

00:00:56.620 --> 00:00:58.070
to do some question and answer.

00:01:01.020 --> 00:01:04.920
So why did we build
Cloud Spanner?

00:01:04.920 --> 00:01:07.380
So you have to go back to 2005.

00:01:07.380 --> 00:01:10.050
Every dollar that Google made
in its advertising system

00:01:10.050 --> 00:01:13.560
called AdWords was built
on the back of a manually

00:01:13.560 --> 00:01:16.200
sharded MySQL cluster.

00:01:16.200 --> 00:01:18.780
We were sharding
by customer IDs,

00:01:18.780 --> 00:01:20.900
and we had to move a customer.

00:01:20.900 --> 00:01:22.650
They had outgrown the
shard, and we needed

00:01:22.650 --> 00:01:24.300
to move them to another shard.

00:01:24.300 --> 00:01:28.110
That last re-shard took
multiple years to complete.

00:01:28.110 --> 00:01:31.500
And when we did that, we decided
we had to have a better way.

00:01:31.500 --> 00:01:34.920
How many people in the room have
either a manually sharded MySQL

00:01:34.920 --> 00:01:37.447
or a manually sharded
Postgres implementation?

00:01:37.447 --> 00:01:39.030
All right, so those
of you in the room

00:01:39.030 --> 00:01:41.760
know the pain that we felt.
So it was at that point

00:01:41.760 --> 00:01:46.080
that we decided we need
to do something different.

00:01:46.080 --> 00:01:48.080
So what were Google's needs?

00:01:48.080 --> 00:01:51.470
We needed a horizontally
scaling database

00:01:51.470 --> 00:01:54.470
that we could give our most
mission critical data to.

00:01:54.470 --> 00:01:57.570
So we needed ACID transactions
with global consistency.

00:01:57.570 --> 00:02:00.830
AdWords was already a global
product at that point,

00:02:00.830 --> 00:02:02.780
and we needed no downtime.

00:02:02.780 --> 00:02:04.850
Every minute that
we were down cost us

00:02:04.850 --> 00:02:06.650
millions of dollars of revenue.

00:02:06.650 --> 00:02:08.479
So how were we going
to solve this problem?

00:02:12.360 --> 00:02:14.050
So the answer was Spanner.

00:02:14.050 --> 00:02:16.570
So what is Cloud Spanner?

00:02:16.570 --> 00:02:19.000
We're going to start by taking
you through a quick video

00:02:19.000 --> 00:02:20.830
as an overview of
what the product is.

00:02:35.354 --> 00:02:36.020
[VIDEO PLAYBACK]

00:02:36.020 --> 00:02:38.770
- We demand a lot
of our databases,

00:02:38.770 --> 00:02:41.590
and our databases
demand a lot of us.

00:02:41.590 --> 00:02:45.130
They're fragile, expensive,
and tough to maintain.

00:02:45.130 --> 00:02:47.560
When things break, it can be
hard to put the pieces back

00:02:47.560 --> 00:02:49.870
together at the speed
of your business,

00:02:49.870 --> 00:02:52.790
and you often lose
data in the process.

00:02:52.790 --> 00:02:55.540
We've all come to expect the
distributed databases can't

00:02:55.540 --> 00:02:58.540
be globally consistent
and scalable.

00:02:58.540 --> 00:03:00.970
But what if you didn't
have to make tradeoffs?

00:03:00.970 --> 00:03:03.550
What if you could have a
fully managed database service

00:03:03.550 --> 00:03:05.740
that's consistent,
scales horizontally

00:03:05.740 --> 00:03:08.770
across data centers,
and speaks SQL?

00:03:08.770 --> 00:03:12.940
This is Cloud Spanner, a mission
critical relational database

00:03:12.940 --> 00:03:15.310
service built from the
ground up and battle

00:03:15.310 --> 00:03:17.650
tested at Google for
strong consistency

00:03:17.650 --> 00:03:20.740
and high availability
at global scale.

00:03:20.740 --> 00:03:22.780
At Google, we use
Spanner for services

00:03:22.780 --> 00:03:25.720
that billions of people
access every day.

00:03:25.720 --> 00:03:27.760
It's the only cloud
service designed

00:03:27.760 --> 00:03:29.860
to be a massively
distributed relational

00:03:29.860 --> 00:03:34.330
database with transactions
and SQL semantics.

00:03:34.330 --> 00:03:36.160
And we're talking massive.

00:03:36.160 --> 00:03:39.340
Spanner can scale up to millions
of machines across hundreds

00:03:39.340 --> 00:03:42.430
of data centers and trillions
of database rows stretched

00:03:42.430 --> 00:03:45.430
across the globe while
behaving like it's all in one

00:03:45.430 --> 00:03:48.270
place, where you want it.

00:03:48.270 --> 00:03:51.550
We built Cloud Spanner to
be fully managed and secure.

00:03:51.550 --> 00:03:53.950
Automatic sharding and
synchronous replication

00:03:53.950 --> 00:03:57.250
with low latency and schema
updates without downtime

00:03:57.250 --> 00:04:00.790
means your data is highly
available and reliable.

00:04:00.790 --> 00:04:03.880
Instead of endless provisioning
and worrying about maintenance,

00:04:03.880 --> 00:04:07.120
you can focus on
growing your business.

00:04:07.120 --> 00:04:09.010
No matter your
needs, you don't have

00:04:09.010 --> 00:04:11.270
to hit a wall with
your database service.

00:04:11.270 --> 00:04:14.090
Get started with Cloud
Spanner, and build what's next.

00:04:14.090 --> 00:04:23.750
[END PLAYBACK]

00:04:23.750 --> 00:04:27.430
DOMINIC PREUSS: So Cloud
Spanner is the externalization

00:04:27.430 --> 00:04:30.820
of that technology that we
started building in 2005.

00:04:30.820 --> 00:04:33.280
So in 2005 we started
building Spanner.

00:04:33.280 --> 00:04:37.590
It went into production to
power the AdWord system in 2007.

00:04:37.590 --> 00:04:40.000
And over the last
nine-plus years,

00:04:40.000 --> 00:04:42.520
many of Google's mission
critical applications

00:04:42.520 --> 00:04:44.650
run on Spanner.

00:04:44.650 --> 00:04:47.980
Cloud Spanner is the Google
Cloud Platform service

00:04:47.980 --> 00:04:51.820
that we have exposed to give
outside developers access

00:04:51.820 --> 00:04:53.260
to the same powerful
tools that we

00:04:53.260 --> 00:04:56.780
have inside of Google for their
mission critical applications.

00:04:56.780 --> 00:05:00.340
So Cloud Spanner is a fully
managed database service

00:05:00.340 --> 00:05:02.030
with global scale.

00:05:02.030 --> 00:05:05.770
So what this means is you come
in, you create an instance,

00:05:05.770 --> 00:05:08.590
you put data in the system,
and that's all you worry about.

00:05:08.590 --> 00:05:12.420
We do backups, we do
upgrades, security patches,

00:05:12.420 --> 00:05:17.830
and making sure that your data
is always protected and secure.

00:05:17.830 --> 00:05:20.510
The second thing was it's
a traditional relational

00:05:20.510 --> 00:05:21.010
database.

00:05:21.010 --> 00:05:23.020
So it gives you
relational semantics,

00:05:23.020 --> 00:05:26.290
so you have rows and
tables and schemas,

00:05:26.290 --> 00:05:28.330
as well as the
transactional capabilities.

00:05:28.330 --> 00:05:30.750
You have ACID transactions
across as many rows

00:05:30.750 --> 00:05:31.730
as you want.

00:05:31.730 --> 00:05:33.400
You can update
hundreds or millions

00:05:33.400 --> 00:05:36.370
of rows in a single transaction,
and you get to use SQL.

00:05:36.370 --> 00:05:39.550
So we do all of our
SQL definition in SQL,

00:05:39.550 --> 00:05:41.800
and we do all of
our queries in SQL.

00:05:41.800 --> 00:05:44.830
It's ANSI 2011 SQL
extensions, so it's

00:05:44.830 --> 00:05:46.330
been built to be
as compatible as it

00:05:46.330 --> 00:05:48.205
can be with your existing
relational database

00:05:48.205 --> 00:05:50.286
technologies.

00:05:50.286 --> 00:05:51.910
We do automatic
synchronous replication

00:05:51.910 --> 00:05:54.185
within and across
regions for availability.

00:05:54.185 --> 00:05:55.810
So one of the things
that is inherently

00:05:55.810 --> 00:05:57.640
different about
Google Cloud Platform

00:05:57.640 --> 00:06:00.520
versus other public clouds is
that we work off the assumption

00:06:00.520 --> 00:06:02.830
that we have to be
multi-regional to reach

00:06:02.830 --> 00:06:05.930
the level of availability
necessary to run our business.

00:06:05.930 --> 00:06:08.890
So Google Cloud Storage is
inherently multi-regional,

00:06:08.890 --> 00:06:10.870
Cloud Datastore
is multi-regional,

00:06:10.870 --> 00:06:14.814
and Cloud Spanner is designed
to run multi-regional.

00:06:14.814 --> 00:06:16.730
It's also been battle
tested inside of Google.

00:06:16.730 --> 00:06:19.630
So we say here five years
for things like AdWords

00:06:19.630 --> 00:06:22.359
in the Google PlayStore, but
it's been now over nine years

00:06:22.359 --> 00:06:24.400
that we've been building
applications and running

00:06:24.400 --> 00:06:26.800
all of Google's mission critical
applications on Spanner.

00:06:32.860 --> 00:06:34.270
So the question is, so what?

00:06:34.270 --> 00:06:35.770
You've said a bunch
of words, you've

00:06:35.770 --> 00:06:37.960
said a bunch of database terms.

00:06:37.960 --> 00:06:39.560
What does that actually mean?

00:06:39.560 --> 00:06:41.350
So what Cloud Spanner
allows you to do

00:06:41.350 --> 00:06:46.090
is have the horizontal
scalability of a NoSQL Solution

00:06:46.090 --> 00:06:49.270
with the relational and
transactional characteristics

00:06:49.270 --> 00:06:51.080
of a relational database.

00:06:51.080 --> 00:06:54.520
So what this means is, when
you come across a problem--

00:06:54.520 --> 00:06:58.570
a business problem that requires
a solution, you have an answer.

00:06:58.570 --> 00:07:00.070
We see this pattern
time and time

00:07:00.070 --> 00:07:02.620
again with both our large
enterprise customers

00:07:02.620 --> 00:07:05.230
and our cloud native
companies where

00:07:05.230 --> 00:07:07.330
they build a project
or a solution

00:07:07.330 --> 00:07:11.420
or a technology on top of
the database that they know.

00:07:11.420 --> 00:07:14.080
It might be MySQL, it might
be Postgres, SQL Server,

00:07:14.080 --> 00:07:15.790
or whatever it happens to be.

00:07:15.790 --> 00:07:18.430
And then if that project
becomes very successful,

00:07:18.430 --> 00:07:21.347
if it gets popular and they
have scalability issues.

00:07:21.347 --> 00:07:22.930
So now they have to
worry about things

00:07:22.930 --> 00:07:25.930
like read replicas to
scale reads and continue

00:07:25.930 --> 00:07:27.720
to scale out their solution.

00:07:27.720 --> 00:07:31.370
And at some point they basically
outgrow that technology.

00:07:31.370 --> 00:07:34.570
So if you've outgrown your
relational database technology,

00:07:34.570 --> 00:07:37.570
your one immutable requirement
is horizontal scalability.

00:07:37.570 --> 00:07:40.630
So then this takes you into
things like Cassandra and MySQL

00:07:40.630 --> 00:07:43.120
and those eventually consistent
technologies that give you

00:07:43.120 --> 00:07:44.860
the horizontal
scalability, but then you

00:07:44.860 --> 00:07:47.350
have to re-architect your
application to understand

00:07:47.350 --> 00:07:49.360
those consistency requirements.

00:07:49.360 --> 00:07:52.510
Cloud Spanner allows you to
scale out your application

00:07:52.510 --> 00:07:55.810
without compromises around
transactional semantics

00:07:55.810 --> 00:07:58.947
or your relational structures.

00:07:58.947 --> 00:08:01.030
So if you compare this to
a traditional relational

00:08:01.030 --> 00:08:07.270
database, Cloud SQL has schemas,
SQL, strong consistency.

00:08:07.270 --> 00:08:09.880
We don't have failover because
we don't do master-slave.

00:08:09.880 --> 00:08:13.390
We use a custom paxos consensus
algorithm and two-face

00:08:13.390 --> 00:08:16.150
commits so that we
don't have master-slave.

00:08:16.150 --> 00:08:19.410
We have consistent versions of
the data in all the replicas,

00:08:19.410 --> 00:08:21.160
so we can serve your
data out of whichever

00:08:21.160 --> 00:08:24.160
replica is most expedient.

00:08:24.160 --> 00:08:27.400
Instead of vertical scaling
by creating bigger VMs where

00:08:27.400 --> 00:08:29.320
you're limited to the
largest VM that you

00:08:29.320 --> 00:08:31.050
can get from a public
cloud provider,

00:08:31.050 --> 00:08:33.177
we scale horizontally.

00:08:33.177 --> 00:08:35.260
And then also replication--
it's not configurable.

00:08:35.260 --> 00:08:37.480
It's something you
get automatically.

00:08:37.480 --> 00:08:40.210
Now, how does this compare
to your NoSQL Solutions?

00:08:40.210 --> 00:08:43.809
So NoSQL Solutions,
no schemas, limited

00:08:43.809 --> 00:08:46.392
SQL or NoSQL,
eventual consistency,

00:08:46.392 --> 00:08:48.100
you can get high
availability because you

00:08:48.100 --> 00:08:49.641
have a distributed
system because you

00:08:49.641 --> 00:08:50.830
can scale horizontally.

00:08:50.830 --> 00:08:52.810
But you still have to
worry about configuring

00:08:52.810 --> 00:08:54.420
your replication.

00:08:54.420 --> 00:08:56.830
So Spanner allows you to
have the best of both worlds

00:08:56.830 --> 00:08:57.750
in a single solution.

00:09:02.776 --> 00:09:04.400
One of the biggest
questions that I get

00:09:04.400 --> 00:09:08.234
is you've had Spanner
internally for nine years.

00:09:08.234 --> 00:09:10.400
Why was it so hard to bring
it to the outside world?

00:09:10.400 --> 00:09:12.830
We worked on it for years,
and it was in early access

00:09:12.830 --> 00:09:13.950
for over a year.

00:09:13.950 --> 00:09:15.350
And it's because
we really wanted

00:09:15.350 --> 00:09:19.880
to package Spanner in such a
way that it was open standards

00:09:19.880 --> 00:09:22.580
and it met our enterprise
customers where they are.

00:09:22.580 --> 00:09:25.070
Google is tremendously
committed to the idea

00:09:25.070 --> 00:09:26.360
being the open cloud.

00:09:26.360 --> 00:09:28.310
So we wanted to adopt
any open standards

00:09:28.310 --> 00:09:30.020
that we could to
really make sure

00:09:30.020 --> 00:09:33.180
that it was as easy as possible
to adopt this technology.

00:09:33.180 --> 00:09:36.470
So we used standard SQL, which
is ANSI 2011 with extensions.

00:09:36.470 --> 00:09:39.170
We do extensions for things
like interleaved tables

00:09:39.170 --> 00:09:42.070
and some of the things that
are specific to Spanner.

00:09:42.070 --> 00:09:44.390
For our enterprise
customers, out of the box

00:09:44.390 --> 00:09:48.050
you get encryption at
rest, you get audit logging

00:09:48.050 --> 00:09:50.750
so you can know who's making
changes to your database,

00:09:50.750 --> 00:09:53.180
and integration with Google
Cloud Platform's identity

00:09:53.180 --> 00:09:54.480
and access management.

00:09:54.480 --> 00:09:57.654
So you get rule-based access
patterns to all of your data.

00:09:57.654 --> 00:09:59.570
So if you're a large
enterprise company that's

00:09:59.570 --> 00:10:02.240
trying to move your mission
critical data on to Google

00:10:02.240 --> 00:10:03.920
Cloud Platform
and Cloud Spanner,

00:10:03.920 --> 00:10:06.410
these are things that you need
to know that you've achieved

00:10:06.410 --> 00:10:09.650
the solution that you need.

00:10:09.650 --> 00:10:11.510
We've also got open
source client libraries

00:10:11.510 --> 00:10:13.280
for all the popular languages.

00:10:13.280 --> 00:10:16.130
We talk a lot about being a
developer from the platform,

00:10:16.130 --> 00:10:19.490
and for us that means really
strong documentation and really

00:10:19.490 --> 00:10:20.900
great client libraries.

00:10:20.900 --> 00:10:25.850
So we launched our beta with
Java, Python, Go, and Node.

00:10:25.850 --> 00:10:27.980
And just today we
launched our PHP clients,

00:10:27.980 --> 00:10:32.900
and we've got Ruby and C#
client libraries coming shortly.

00:10:32.900 --> 00:10:35.810
The last thing we did was
we've developed a JDBC driver.

00:10:35.810 --> 00:10:38.690
So we have a read only
JDBC driver specifically

00:10:38.690 --> 00:10:40.220
for our partner ecosystem.

00:10:40.220 --> 00:10:44.150
So partners are tremendously
important to Google's success

00:10:44.150 --> 00:10:45.650
for the Google Cloud Platform.

00:10:45.650 --> 00:10:47.480
So by providing
this JDBC driver,

00:10:47.480 --> 00:10:50.060
we made as easy as possible
for both our partners,

00:10:50.060 --> 00:10:53.540
like Tableau and Looker and
MicroStrategy, the BI tools,

00:10:53.540 --> 00:10:55.370
as well as customers
to integrate it

00:10:55.370 --> 00:10:56.520
into their workloads.

00:10:56.520 --> 00:10:58.340
So we provide this
read-only JDBC driver

00:10:58.340 --> 00:11:01.190
to make it easy as possible to
get the data out of the system.

00:11:05.330 --> 00:11:07.250
During the early
access program and now

00:11:07.250 --> 00:11:09.410
from beta to general
availability,

00:11:09.410 --> 00:11:12.602
we've seen a lot of traction
on specific types of workloads,

00:11:12.602 --> 00:11:14.810
and these workloads are
actually very similar to what

00:11:14.810 --> 00:11:16.070
we've seen inside Google.

00:11:16.070 --> 00:11:17.780
So the first one
is transactional.

00:11:17.780 --> 00:11:20.600
If you have a heavily
transactional workload where

00:11:20.600 --> 00:11:22.820
you need global
consistency, Cloud Spanner

00:11:22.820 --> 00:11:24.240
is an ideal solution.

00:11:24.240 --> 00:11:26.900
So examples of this
are financial services.

00:11:26.900 --> 00:11:28.370
If you're moving
around money, you

00:11:28.370 --> 00:11:30.380
need to have consistent data.

00:11:30.380 --> 00:11:34.220
If you are doing inventory
management or supply chain

00:11:34.220 --> 00:11:37.350
applications, you can't sell
more inventory than you have.

00:11:37.350 --> 00:11:40.580
So it's important that you
have a strongly consistent data

00:11:40.580 --> 00:11:43.400
store to store your inventory.

00:11:43.400 --> 00:11:45.590
Another good example
of this is Adtech.

00:11:45.590 --> 00:11:47.660
So Adtech, money,
budgets, you're

00:11:47.660 --> 00:11:49.580
serving ads against
the budget, you

00:11:49.580 --> 00:11:51.664
can't spend more than the
budget of the customer.

00:11:51.664 --> 00:11:54.080
So it's very important that
you have a consistent database

00:11:54.080 --> 00:11:56.860
for those types of systems.

00:11:56.860 --> 00:12:00.130
The next one is scale out,
and so the type of customer

00:12:00.130 --> 00:12:01.270
that we actually--

00:12:01.270 --> 00:12:04.390
is the easiest to
understand Cloud Spanner

00:12:04.390 --> 00:12:07.300
are those that have these
manually sharded MySQL

00:12:07.300 --> 00:12:08.830
and Postgres databases.

00:12:08.830 --> 00:12:11.080
If your database has gotten
large enough that you

00:12:11.080 --> 00:12:13.030
are manually sharding
your database,

00:12:13.030 --> 00:12:15.550
either at the application
layer, using some sort

00:12:15.550 --> 00:12:18.730
of sharding technology,
then you understand the need

00:12:18.730 --> 00:12:21.640
for having a horizontally
scalable database.

00:12:21.640 --> 00:12:23.500
The fact that you can
pick a single database

00:12:23.500 --> 00:12:26.380
and never have to worry
about outgrowing it up

00:12:26.380 --> 00:12:28.144
to petabytes of
data is something

00:12:28.144 --> 00:12:29.560
that's very
reassuring when you're

00:12:29.560 --> 00:12:31.730
choosing an architectural
solution to build

00:12:31.730 --> 00:12:34.360
your applications on.

00:12:34.360 --> 00:12:36.400
The third one is
global data plane.

00:12:36.400 --> 00:12:39.440
So an interesting fact is
that Google Cloud Platforms--

00:12:39.440 --> 00:12:42.480
all of its control planes
are based on Spanner.

00:12:42.480 --> 00:12:46.900
And so if you have to have a
consistent view of your systems

00:12:46.900 --> 00:12:49.330
for control plane or
things like user accounts,

00:12:49.330 --> 00:12:53.230
we see this as a really common
use case for Cloud Spanner.

00:12:53.230 --> 00:12:55.510
If your customers happen
to be globally distributed,

00:12:55.510 --> 00:12:57.280
let's say that you're
a US company that

00:12:57.280 --> 00:13:00.730
has a lot of customers in Japan
or a European company that

00:13:00.730 --> 00:13:02.520
has a lot of
customers in the US,

00:13:02.520 --> 00:13:04.720
then having a
globally distributed

00:13:04.720 --> 00:13:08.650
single source of truth system
for things like user accounts

00:13:08.650 --> 00:13:12.149
and metadata on your
system is very valuable.

00:13:12.149 --> 00:13:14.440
The last one is consolidation,
and this is actually one

00:13:14.440 --> 00:13:16.030
that I'm most excited about.

00:13:16.030 --> 00:13:19.150
As a former CTO of a company,
we had multiple solutions.

00:13:19.150 --> 00:13:22.730
We had a Postgres database
for our customer data.

00:13:22.730 --> 00:13:26.410
We had a Mongo database
for our logging data,

00:13:26.410 --> 00:13:30.015
and we had a analytics solution
for all of our logging data.

00:13:30.015 --> 00:13:31.640
And so what's great
about Cloud Spanner

00:13:31.640 --> 00:13:33.514
is it allows you to
consolidate all your data

00:13:33.514 --> 00:13:34.870
stores into a single one.

00:13:34.870 --> 00:13:37.120
So if you had a Postgres
cluster for your user data

00:13:37.120 --> 00:13:39.580
and a Cassandra cluster for
all of your logging data,

00:13:39.580 --> 00:13:42.330
you can now bring those
into a single, scalable data

00:13:42.330 --> 00:13:44.740
source that is globally
consistent with a single source

00:13:44.740 --> 00:13:47.020
of truth to run
your applications.

00:13:47.020 --> 00:13:49.600
And this really starts to
give you much greater velocity

00:13:49.600 --> 00:13:51.010
from a developer perspective.

00:13:51.010 --> 00:13:53.510
You don't have to worry
about e-tailing the data

00:13:53.510 --> 00:13:55.829
or trying to do joins
across disparate data sets.

00:13:55.829 --> 00:13:57.745
You have a single source
for all of your data.

00:13:57.745 --> 00:14:00.540
So you can do real time,
consistent queries on the data.

00:14:05.440 --> 00:14:07.230
So how does Spanner work?

00:14:07.230 --> 00:14:11.400
So the atomic unit for Cloud
Spanner is an instance.

00:14:11.400 --> 00:14:13.650
So when you create a
Cloud Spanner instance,

00:14:13.650 --> 00:14:15.690
you're selecting two things--

00:14:15.690 --> 00:14:18.780
a instance configuration,
which is effectively

00:14:18.780 --> 00:14:21.330
the replication typology
of the database,

00:14:21.330 --> 00:14:23.700
and the number of nodes.

00:14:23.700 --> 00:14:25.830
The nodes are the compute
units by which you

00:14:25.830 --> 00:14:28.890
can do work on the database.

00:14:28.890 --> 00:14:32.564
So once I have that data,
I have created my instance.

00:14:32.564 --> 00:14:34.980
If you're creating a regional
instance which we have today

00:14:34.980 --> 00:14:37.354
and we'll have multi-regional
instances rolling out later

00:14:37.354 --> 00:14:37.980
this year--

00:14:37.980 --> 00:14:39.521
for a regional
instance, you're going

00:14:39.521 --> 00:14:41.930
to have three replicas
in three different zones

00:14:41.930 --> 00:14:43.890
in a single region.

00:14:43.890 --> 00:14:46.440
And then when you create
a database inside of that

00:14:46.440 --> 00:14:49.020
instance-- so your database
is your logical separation

00:14:49.020 --> 00:14:50.070
of your data--

00:14:50.070 --> 00:14:52.140
all of that data is
going to be available

00:14:52.140 --> 00:14:56.070
and copied and replicated across
all of your various replicas.

00:14:56.070 --> 00:15:00.030
So what this does is gives
you a fault tolerant,

00:15:00.030 --> 00:15:02.400
highly available system
that has your data separated

00:15:02.400 --> 00:15:03.540
across multiple zones.

00:15:06.660 --> 00:15:10.470
So what happens is when a
update comes into the system,

00:15:10.470 --> 00:15:14.040
you don't address
a single replica.

00:15:14.040 --> 00:15:15.720
You don't address a cluster.

00:15:15.720 --> 00:15:17.790
You just address your instance.

00:15:17.790 --> 00:15:20.700
So whether or not you're doing
a write from a virtual machine

00:15:20.700 --> 00:15:23.230
in Europe or the United
States, you just say,

00:15:23.230 --> 00:15:25.920
hey, Cloud Spanner,
here's some data.

00:15:25.920 --> 00:15:28.020
We will automatically
route that data

00:15:28.020 --> 00:15:31.820
to the nearest replica that
can serve your request.

00:15:31.820 --> 00:15:34.590
It'll come into one
of the replicas.

00:15:34.590 --> 00:15:37.770
The commit will be figured
out using our paxos algorithm

00:15:37.770 --> 00:15:39.840
and our two-faced
commits, and then we'll

00:15:39.840 --> 00:15:44.010
get consensus from the other
replicas to write that data.

00:15:44.010 --> 00:15:46.320
All of that is completely
transparent to you.

00:15:46.320 --> 00:15:48.930
And when you're writing
data to Cloud Spanner,

00:15:48.930 --> 00:15:51.540
it looks just like a
single node database.

00:15:51.540 --> 00:15:53.040
There's nothing
about the behavior

00:15:53.040 --> 00:15:55.623
that you will see that will look
any different than if you are

00:15:55.623 --> 00:15:57.570
addressing an
individual, single node

00:15:57.570 --> 00:16:00.150
database like MySQL or Postgres.

00:16:00.150 --> 00:16:02.784
In terms of what this
does in terms of latency

00:16:02.784 --> 00:16:04.200
is when you're
doing reads, you're

00:16:04.200 --> 00:16:06.390
talking about single
millisecond reads,

00:16:06.390 --> 00:16:09.300
and you're talking about
sub 15 millisecond writes.

00:16:09.300 --> 00:16:11.040
So depending on the
shape of your data

00:16:11.040 --> 00:16:13.202
and how fast you're writing
data and reading data,

00:16:13.202 --> 00:16:15.660
you're going to see very similar
performance that you would

00:16:15.660 --> 00:16:17.214
see out of a single
node machine,

00:16:17.214 --> 00:16:18.630
but you're getting
the distributed

00:16:18.630 --> 00:16:19.630
nature of Cloud Spanner.

00:16:25.230 --> 00:16:26.730
Well, how does
Spanner achieve this?

00:16:26.730 --> 00:16:28.410
There has to be some tradeoffs.

00:16:28.410 --> 00:16:30.326
So one of the things
that's really interesting

00:16:30.326 --> 00:16:31.960
is how we actually
structure the data.

00:16:31.960 --> 00:16:34.920
So if you are using a
traditional database--

00:16:34.920 --> 00:16:36.690
traditional relational
database, your data

00:16:36.690 --> 00:16:37.814
is going to look like this.

00:16:37.814 --> 00:16:40.290
You're going to have a
single table, in this case,

00:16:40.290 --> 00:16:42.100
for example, a singer ID.

00:16:42.100 --> 00:16:44.820
We've got ID 1, 2,
3, and then we're

00:16:44.820 --> 00:16:46.680
going to have an
album table that's

00:16:46.680 --> 00:16:50.010
going to have its
own ID, so album ID.

00:16:50.010 --> 00:16:52.230
And you might have a
foreign key constraint here,

00:16:52.230 --> 00:16:54.030
but you basically have
two disparate tables

00:16:54.030 --> 00:16:56.990
and you're doing joins.

00:16:56.990 --> 00:17:00.620
Spanner, to be
performant and to support

00:17:00.620 --> 00:17:03.380
the relational semantics
in a distributed system,

00:17:03.380 --> 00:17:05.780
has the idea of
interleave tables.

00:17:05.780 --> 00:17:09.200
So the way that
Spanner does this is we

00:17:09.200 --> 00:17:13.099
allow you to tell us what
is the physical relationship

00:17:13.099 --> 00:17:14.430
of your data.

00:17:14.430 --> 00:17:15.980
An interleaved
table is effectively

00:17:15.980 --> 00:17:21.140
a child table that allows you to
create a connection of the data

00:17:21.140 --> 00:17:23.020
so that we can
group it together.

00:17:23.020 --> 00:17:28.010
You're telling Spanner that
this data, which is albums,

00:17:28.010 --> 00:17:30.227
is closely related to singer.

00:17:30.227 --> 00:17:32.060
So what that allows us
to do is to make sure

00:17:32.060 --> 00:17:36.140
that we keep that data close,
and we can quickly serve data

00:17:36.140 --> 00:17:39.360
that is within a single parent.

00:17:39.360 --> 00:17:41.420
So in this case, Beatles.

00:17:41.420 --> 00:17:43.940
This also is how we implement
foreign key constraints.

00:17:43.940 --> 00:17:46.670
So if you want to do things
like cascade on delete,

00:17:46.670 --> 00:17:48.260
then you basically have--

00:17:48.260 --> 00:17:51.140
all the child table has all
the same keys as the primary,

00:17:51.140 --> 00:17:53.870
as its parent, and then you
can say cascade on delete.

00:17:53.870 --> 00:17:56.930
So when I delete a
child row, then--

00:17:56.930 --> 00:17:58.730
or a parent row, you
can cascade on delete

00:17:58.730 --> 00:18:00.920
to make sure that you
maintain that integrity.

00:18:00.920 --> 00:18:02.840
We don't do foreign
key constraints

00:18:02.840 --> 00:18:05.975
across these top level tables,
which we call root tables,

00:18:05.975 --> 00:18:08.000
because then that would
affect our performance.

00:18:08.000 --> 00:18:10.130
So by creating this
interleaved table,

00:18:10.130 --> 00:18:13.292
we're able to give the
performance that you need,

00:18:13.292 --> 00:18:15.500
but structuring the data in
a slightly different way.

00:18:18.770 --> 00:18:21.390
So what does that look like
when I build my schemas?

00:18:21.390 --> 00:18:23.630
So this is how you do DDL.

00:18:23.630 --> 00:18:26.390
So when you define
your schemas, so you

00:18:26.390 --> 00:18:31.520
can say create table singers
with singer ID and singer name,

00:18:31.520 --> 00:18:33.920
and the primary
key is singer ID.

00:18:33.920 --> 00:18:38.400
So we use primary keys
that are actual data.

00:18:38.400 --> 00:18:42.510
So we encourage you to create
enough separation in keys

00:18:42.510 --> 00:18:46.480
as to use actual data from your
system as the primary keys.

00:18:48.639 --> 00:18:50.180
So now if we wanted
to create a child

00:18:50.180 --> 00:18:53.690
table or an interleave table, we
would say create table albums.

00:18:53.690 --> 00:18:58.220
You can see that it has singer
ID as a key-- as a property

00:18:58.220 --> 00:19:01.070
because we need to have all of
the same ones as the parent.

00:19:01.070 --> 00:19:03.660
We've added album
ID as a separate ID,

00:19:03.660 --> 00:19:05.150
and we've added album name.

00:19:05.150 --> 00:19:07.910
So we said the primary keys need
to be singer ID and album ID,

00:19:07.910 --> 00:19:10.310
and again, this is so
that we can interleave

00:19:10.310 --> 00:19:13.580
the data together, and then
we say interleave and singers.

00:19:13.580 --> 00:19:17.970
So what this means is
whenever you create a child

00:19:17.970 --> 00:19:20.540
row of the parent
table, that data

00:19:20.540 --> 00:19:24.410
will be physically located on
the same nodes in Cloud Spanner

00:19:24.410 --> 00:19:27.740
so that we can quickly do
queries across that data.

00:19:27.740 --> 00:19:31.130
Some people like to think of
this as a pre-computed join.

00:19:31.130 --> 00:19:34.790
So it allows you to basically--
by laying the data on data--

00:19:34.790 --> 00:19:39.120
laying the data out on disk and
in the relational semantics,

00:19:39.120 --> 00:19:42.440
it allows us to do these
pre-computed joins.

00:19:42.440 --> 00:19:45.000
The other thing it allows us to
do is no downtime migrations.

00:19:45.000 --> 00:19:47.630
So if you wanted to do,
say, alter table singers

00:19:47.630 --> 00:19:51.980
and add column age, that
is a no downtime migration.

00:19:51.980 --> 00:19:53.340
So we don't lock the database.

00:19:53.340 --> 00:19:54.920
We don't lock the tables.

00:19:54.920 --> 00:19:58.580
Spanner does cell level
pessimistic locking,

00:19:58.580 --> 00:20:01.920
and so you can do
online schema migrations

00:20:01.920 --> 00:20:03.480
without bringing
down your system.

00:20:03.480 --> 00:20:05.521
These are all things that
we had to develop to be

00:20:05.521 --> 00:20:07.316
able to run Google's business.

00:20:07.316 --> 00:20:09.440
It's our mission critical
applications at the scale

00:20:09.440 --> 00:20:10.481
and speed that we needed.

00:20:15.990 --> 00:20:18.120
So what does this
look like in code?

00:20:18.120 --> 00:20:20.030
So I talked a little
bit about the importance

00:20:20.030 --> 00:20:21.169
of documentation.

00:20:21.169 --> 00:20:23.210
I'll also talk about the
importance of our client

00:20:23.210 --> 00:20:23.900
libraries.

00:20:23.900 --> 00:20:26.358
I'm a Python guy, so we're
going to go through the Python--

00:20:26.358 --> 00:20:27.890
the Python experience.

00:20:27.890 --> 00:20:30.620
But we spent a lot of time
with our Google Cloud client

00:20:30.620 --> 00:20:33.500
libraries to make sure that it's
as easy as possible to get up

00:20:33.500 --> 00:20:34.410
and running.

00:20:34.410 --> 00:20:37.010
So for Python-- by the
way, how many Python people

00:20:37.010 --> 00:20:38.210
are in the room?

00:20:38.210 --> 00:20:39.290
Fantastic.

00:20:39.290 --> 00:20:41.750
You're my people.

00:20:41.750 --> 00:20:44.450
First thing I'm going
to do is import Spanner

00:20:44.450 --> 00:20:45.590
from google.cloud.

00:20:45.590 --> 00:20:50.990
So I've imported the package
necessary to get access.

00:20:50.990 --> 00:20:53.330
I'm going to
instantiate a client.

00:20:53.330 --> 00:20:56.020
So a client is a
pool of connections.

00:20:56.020 --> 00:20:58.522
So you create a single
client for your application,

00:20:58.522 --> 00:21:00.480
and then the client
libraries in the background

00:21:00.480 --> 00:21:03.170
do all the connection pooling
to optimize your network

00:21:03.170 --> 00:21:05.342
traffic back and forth.

00:21:05.342 --> 00:21:07.550
I'm then going to say, grab
a handle to my instance--

00:21:07.550 --> 00:21:10.370
so my instance ID is a string.

00:21:10.370 --> 00:21:14.210
I'll pass that to the
client, say grab my instance.

00:21:14.210 --> 00:21:16.130
And now I need to
handle the database.

00:21:16.130 --> 00:21:18.920
So you could have many
databases per instance.

00:21:18.920 --> 00:21:21.620
Again, this is a logical
separation of data.

00:21:21.620 --> 00:21:24.710
I'm going to say my database
ID is my database ID,

00:21:24.710 --> 00:21:26.970
and then I'm to grab the
handles on my database.

00:21:26.970 --> 00:21:28.910
And now I can start
to run queries.

00:21:28.910 --> 00:21:32.100
So in seven lines of
code I'm able to start

00:21:32.100 --> 00:21:34.100
executing queries, and
then I can start printing

00:21:34.100 --> 00:21:34.683
out that data.

00:21:39.660 --> 00:21:43.830
As a quick high-level,
how does Cloud Spanner

00:21:43.830 --> 00:21:45.730
fit into the overall portfolio?

00:21:45.730 --> 00:21:48.390
So if you look at our portfolio
of products going from right

00:21:48.390 --> 00:21:52.250
to left, we start with
a in-memory data source

00:21:52.250 --> 00:21:55.170
that we provide, Memcache
as part of App Engine.

00:21:55.170 --> 00:21:57.840
This is obviously very good
for Web and mobile apps

00:21:57.840 --> 00:22:00.210
and for caches.

00:22:00.210 --> 00:22:03.580
Cloud SQL is our managed
relational database service.

00:22:03.580 --> 00:22:06.520
So today it supports
MySQL and Postgres.

00:22:06.520 --> 00:22:08.520
We are very excited to
announce Postgres support

00:22:08.520 --> 00:22:12.840
at Cloud Next in March.

00:22:12.840 --> 00:22:15.330
Skipping over Cloud
Spanner, Cloud Datastore--

00:22:15.330 --> 00:22:18.270
Cloud Datastore is our document
database for mobile and web

00:22:18.270 --> 00:22:19.380
applications.

00:22:19.380 --> 00:22:23.490
This is what powers things
like Snapchat, Pokemon Go,

00:22:23.490 --> 00:22:26.230
and other large
gaming applications.

00:22:26.230 --> 00:22:29.020
Cloud Bigtable is our
analytics database.

00:22:29.020 --> 00:22:32.330
So this is for high
throughput, low latency write.

00:22:32.330 --> 00:22:34.590
So if you need single
millisecond reads and writes

00:22:34.590 --> 00:22:38.880
of very large amounts
of data, Cloud Bigtable

00:22:38.880 --> 00:22:40.410
is what allows you to do that.

00:22:40.410 --> 00:22:43.740
It's fantastic for
time series data,

00:22:43.740 --> 00:22:46.860
for monitoring data
or anything that you

00:22:46.860 --> 00:22:49.560
need to do those very
heavy writes and then do

00:22:49.560 --> 00:22:52.110
really fast tables scans.

00:22:52.110 --> 00:22:54.090
Cloud Storage, which
is our object store,

00:22:54.090 --> 00:22:55.860
I'd like to keep it
in here because we're

00:22:55.860 --> 00:22:57.693
seeing more and more
people that are writing

00:22:57.693 --> 00:22:59.790
their data into GCS
or into Google Cloud

00:22:59.790 --> 00:23:04.380
Storage as its data store in
things like Avro and Parquet

00:23:04.380 --> 00:23:06.870
and JSON files and
log files, and then

00:23:06.870 --> 00:23:10.296
running federated queries from
BigQuery across that data.

00:23:10.296 --> 00:23:11.670
So we see a number
of people that

00:23:11.670 --> 00:23:14.430
are starting to use it
as a column data store

00:23:14.430 --> 00:23:19.680
by putting those files directly
into a object store bucket.

00:23:19.680 --> 00:23:23.040
And last one is BigQuery, which
is our cloud native warehouse.

00:23:23.040 --> 00:23:25.140
So this is a
federated query engine

00:23:25.140 --> 00:23:29.010
that allows you to search across
the data in BigQuery, Google

00:23:29.010 --> 00:23:31.530
Cloud Storage, Google
Drive, and we recently

00:23:31.530 --> 00:23:34.500
announced the ability to query
data in Cloud Bigtable as well.

00:23:34.500 --> 00:23:37.950
Fed allows you to do joins
across data in multiple data

00:23:37.950 --> 00:23:42.540
sources and doing it all from
a single interface using SQL.

00:23:42.540 --> 00:23:44.910
So you come back
to Cloud Spanner.

00:23:44.910 --> 00:23:46.050
What is it good for?

00:23:46.050 --> 00:23:48.115
So if you are using--

00:23:48.115 --> 00:23:49.740
if you have an
application that doesn't

00:23:49.740 --> 00:23:52.350
have one of three requirements,
then normally using

00:23:52.350 --> 00:23:54.720
MySQL and Postgres is great.

00:23:54.720 --> 00:23:56.164
Great ecosystem, lots of tools.

00:23:56.164 --> 00:23:58.080
But there are three
things that will drive you

00:23:58.080 --> 00:23:59.550
to Cloud Spanner.

00:23:59.550 --> 00:24:01.680
If you need super
high availability,

00:24:01.680 --> 00:24:03.702
so you either need four
nines of availability

00:24:03.702 --> 00:24:05.910
for a regional instance or
five nines of availability

00:24:05.910 --> 00:24:08.981
for multi-regional, then Cloud
Spanner is a solution for you.

00:24:08.981 --> 00:24:10.980
You don't have to worry
about scheduled downtime

00:24:10.980 --> 00:24:12.240
because there isn't any.

00:24:12.240 --> 00:24:14.700
We aren't doing-- when
we do binary upgrades,

00:24:14.700 --> 00:24:15.570
you don't see it.

00:24:15.570 --> 00:24:16.890
It happens online.

00:24:16.890 --> 00:24:19.280
It doesn't have any
impact to customers.

00:24:19.280 --> 00:24:22.560
Five nines of availability
is 20-some seconds a month

00:24:22.560 --> 00:24:23.475
of downtime.

00:24:23.475 --> 00:24:26.100
And so it allows you to run your
mission critical applications.

00:24:26.100 --> 00:24:28.530
So number one is super
high availability.

00:24:28.530 --> 00:24:30.690
Number two is if you
need more writes than you

00:24:30.690 --> 00:24:32.130
can put through a single node.

00:24:32.130 --> 00:24:33.990
So if you're doing
lots and lots of writes

00:24:33.990 --> 00:24:36.630
on your MySQL or
Postgres database,

00:24:36.630 --> 00:24:39.000
you can shard the reads
by creating read replicas

00:24:39.000 --> 00:24:41.174
and pushing your read
traffic to read replicas.

00:24:41.174 --> 00:24:42.840
But if you're doing
more writes than you

00:24:42.840 --> 00:24:44.550
can put through
a single VM, then

00:24:44.550 --> 00:24:47.340
you can only scale
vertically to as large

00:24:47.340 --> 00:24:49.456
as the biggest VM
as on that platform.

00:24:49.456 --> 00:24:51.330
So Cloud Spanner allows
you to go beyond that

00:24:51.330 --> 00:24:56.010
by doing as many writes as you
want by just adding more nodes.

00:24:56.010 --> 00:24:57.220
The last one is data.

00:24:57.220 --> 00:24:59.340
So if you have more data
than you can reasonably

00:24:59.340 --> 00:25:01.710
put into a relational
database-- and that's

00:25:01.710 --> 00:25:03.570
somewhere around
three terabytes--

00:25:03.570 --> 00:25:06.510
and you need to be able to
scale up to tens or hundreds

00:25:06.510 --> 00:25:08.460
or even petabytes of
data, Cloud Spanner

00:25:08.460 --> 00:25:10.770
allows you to scale
beyond the storage

00:25:10.770 --> 00:25:14.310
requirements of a traditional
relational database.

00:25:14.310 --> 00:25:17.880
So that's where people get
moved from Cloud Spanner into--

00:25:17.880 --> 00:25:19.720
or from Cloud SQL
into Cloud Spanner

00:25:19.720 --> 00:25:21.720
is when you have one of
those three requirements

00:25:21.720 --> 00:25:23.594
that can't be met by a
traditional relational

00:25:23.594 --> 00:25:26.200
database.

00:25:26.200 --> 00:25:28.647
One note-- when I did
the slide last week,

00:25:28.647 --> 00:25:29.980
Cloud Spanner was still in beta.

00:25:29.980 --> 00:25:32.950
We actually went to general
availability on Tuesday.

00:25:32.950 --> 00:25:35.130
So it is now generally
available for everyone.

00:25:35.130 --> 00:25:36.130
It is no longer beta.

00:25:41.409 --> 00:25:43.200
You just talked about
a bunch of databases.

00:25:43.200 --> 00:25:44.399
Which one do I use when?

00:25:44.399 --> 00:25:46.440
So this is something that
I put together recently

00:25:46.440 --> 00:25:48.898
that I always like to show in
any database talk is how do I

00:25:48.898 --> 00:25:50.310
choose which solution to use.

00:25:50.310 --> 00:25:53.530
So we'll start at the top
and work our way down.

00:25:53.530 --> 00:25:55.980
So first, is your data
structured, yes or no?

00:25:55.980 --> 00:25:57.630
So if the answer
is no, then you're

00:25:57.630 --> 00:26:01.790
going to end up over in one of
our unstructured object stores.

00:26:01.790 --> 00:26:04.310
So if you need mobile
SDKs, then you're

00:26:04.310 --> 00:26:06.570
going to use Firebase Storage.

00:26:06.570 --> 00:26:08.312
So for those of
you who don't know,

00:26:08.312 --> 00:26:10.020
as you've gotten
through this conference,

00:26:10.020 --> 00:26:12.800
Firebase is our mobile
developer platform,

00:26:12.800 --> 00:26:15.810
and it's the primary way that
developers-- mobile developers

00:26:15.810 --> 00:26:18.062
access Google Cloud
Platform services.

00:26:18.062 --> 00:26:20.520
So if you need a mobile SDK,
you'll go to Firebase Storage.

00:26:20.520 --> 00:26:23.010
If you don't, then you'll
go to Cloud Storage.

00:26:23.010 --> 00:26:24.850
All of the data ends
up in the same place,

00:26:24.850 --> 00:26:28.320
but it's just two different
developer experiences.

00:26:28.320 --> 00:26:30.300
If your data is
structured, then are you

00:26:30.300 --> 00:26:31.667
doing an analytics workload?

00:26:31.667 --> 00:26:33.250
If you're doing an
analytics workload,

00:26:33.250 --> 00:26:35.280
then you're going end up
over on the right side,

00:26:35.280 --> 00:26:36.863
and then your question
is going to be,

00:26:36.863 --> 00:26:39.925
do you need lots and lots of
updates or super low latency?

00:26:39.925 --> 00:26:42.300
So if the answer is yes, you'll
end up in Cloud Bigtable.

00:26:42.300 --> 00:26:45.145
So we recently did an experiment
with a large financial services

00:26:45.145 --> 00:26:47.520
company where we're doing
millions and millions of writes

00:26:47.520 --> 00:26:49.830
a second into Cloud
Bigtable and we're

00:26:49.830 --> 00:26:52.710
talking about sub ten
millisecond reads and writes.

00:26:52.710 --> 00:26:54.450
That's Cloud Bigtable.

00:26:54.450 --> 00:26:55.890
If you don't need
lots of updates

00:26:55.890 --> 00:26:58.098
and you're looking at more
of an append-only workload

00:26:58.098 --> 00:26:59.970
or a traditional data
warehouse, then you're

00:26:59.970 --> 00:27:01.380
going to end up over in
BigQuery where you're

00:27:01.380 --> 00:27:03.120
talking about single
second queries

00:27:03.120 --> 00:27:08.180
for doing massive aggregations
over lots and lots of data.

00:27:08.180 --> 00:27:09.920
If your data isn't
analytics, then you're

00:27:09.920 --> 00:27:11.378
going to end up in
the middle here.

00:27:11.378 --> 00:27:13.976
And then the question is,
is your data relational?

00:27:13.976 --> 00:27:16.100
Without getting into a
whole religious conversation

00:27:16.100 --> 00:27:19.010
about SQL versus NoSQL,
the real question

00:27:19.010 --> 00:27:20.225
is, is your data relational?

00:27:20.225 --> 00:27:22.850
Do you have lots of references,
and are you doing lots of joins

00:27:22.850 --> 00:27:24.830
across multiple tables?

00:27:24.830 --> 00:27:27.020
Then this will drive you
into one of two solutions.

00:27:27.020 --> 00:27:29.600
So if your data
is not relational,

00:27:29.600 --> 00:27:31.910
then the question again is,
do you need mobile SDKs?

00:27:31.910 --> 00:27:32.870
If the answer is
no, you're going

00:27:32.870 --> 00:27:34.340
to end up in Cloud
Datastore, which

00:27:34.340 --> 00:27:37.070
is our scalable document
database for Web

00:27:37.070 --> 00:27:38.540
and mobile applications.

00:27:38.540 --> 00:27:40.680
If you do want
mobile applications,

00:27:40.680 --> 00:27:43.100
you want the native mobile
SDKs, and you're going up

00:27:43.100 --> 00:27:46.365
in Firebase real time database.

00:27:46.365 --> 00:27:47.990
If your data is
relational, then you're

00:27:47.990 --> 00:27:51.932
going to be over on the
left side of our slide.

00:27:51.932 --> 00:27:53.390
And so then the
question is, do you

00:27:53.390 --> 00:27:54.920
need horizontal scalability?

00:27:54.920 --> 00:27:58.067
If you don't, then
generally MySQL and Postgres

00:27:58.067 --> 00:27:59.900
are going to provide
you a great experience.

00:27:59.900 --> 00:28:04.122
They've got a much more robust
ecosystem, open source tools,

00:28:04.122 --> 00:28:06.080
lots of support for you
getting up and running,

00:28:06.080 --> 00:28:08.450
and takes away some of
the complexity of doing

00:28:08.450 --> 00:28:09.877
the work that you need to do.

00:28:09.877 --> 00:28:11.960
But if you do have one of
those three needs, which

00:28:11.960 --> 00:28:14.420
is super high
availability, more writes

00:28:14.420 --> 00:28:16.759
than you can put through
a single VM, or more data

00:28:16.759 --> 00:28:18.800
than you can fit in a
single relational database,

00:28:18.800 --> 00:28:20.675
then you're going to
end up in Cloud Spanner.

00:28:25.800 --> 00:28:27.800
I talked a little bit
before about how important

00:28:27.800 --> 00:28:32.570
it was for Google Cloud
Platform and Cloud Spanner

00:28:32.570 --> 00:28:34.670
to have a robust
partner ecosystem.

00:28:34.670 --> 00:28:37.230
So we spent a lot of time
during the early access program

00:28:37.230 --> 00:28:39.530
and since launch in
engaging with our partners

00:28:39.530 --> 00:28:43.250
to make sure that whatever tool
you happen to be using today,

00:28:43.250 --> 00:28:45.260
you can continue to
use with Cloud Spanner.

00:28:45.260 --> 00:28:46.926
So I'm very excited
that we have support

00:28:46.926 --> 00:28:50.550
from companies like Xplenty,
Looker, MicroStrategy,

00:28:50.550 --> 00:28:53.060
and we're going to continue
to see integrations roll out

00:28:53.060 --> 00:28:55.970
the rest of the year from
Informatica, Tableau,

00:28:55.970 --> 00:28:57.770
and all of our various partners.

00:28:57.770 --> 00:28:59.729
And so if you happen to
be an Alooma user today

00:28:59.729 --> 00:29:02.019
and you want to be able to
migrate your data into Cloud

00:29:02.019 --> 00:29:03.650
Spanner, we're
making sure that we

00:29:03.650 --> 00:29:05.300
have those integrations in
place for those partners

00:29:05.300 --> 00:29:07.830
so that you can use the tools
that you're used to using,

00:29:07.830 --> 00:29:10.280
and Cloud Spanner will just
fit right into your existing

00:29:10.280 --> 00:29:11.278
architecture.

00:29:16.520 --> 00:29:17.990
So now we're going to do a demo.

00:29:17.990 --> 00:29:22.160
So before you switch
over to the machine,

00:29:22.160 --> 00:29:23.900
any good talk has a demo.

00:29:23.900 --> 00:29:26.450
Go ahead and switch, yeah.

00:29:26.450 --> 00:29:29.780
Great, so I'm in the
Google Cloud Console,

00:29:29.780 --> 00:29:34.010
and when you log in, we provide
you a bunch of graphical tools

00:29:34.010 --> 00:29:35.750
to help you understand.

00:29:35.750 --> 00:29:38.180
So we're in the next Spanner.

00:29:38.180 --> 00:29:41.510
So if you saw any of the Spanner
talks, you've seen the demo.

00:29:41.510 --> 00:29:43.640
It's been running
over in the pavilion.

00:29:43.640 --> 00:29:47.960
This is a globally replicated
Cloud Spanner instance.

00:29:47.960 --> 00:29:51.080
So what this means is we have
data in the United States,

00:29:51.080 --> 00:29:52.260
Europe, and Asia.

00:29:52.260 --> 00:29:54.890
So Iowa, Oklahoma,
Belgium, and Taiwan.

00:29:54.890 --> 00:29:57.080
We've got 50 nodes of capacity.

00:29:57.080 --> 00:30:03.000
And so what this means is
we can do about 500,000

00:30:03.000 --> 00:30:06.180
reads a second and about
100,000 writes a second.

00:30:06.180 --> 00:30:10.700
So you get about 10,000 reads
and 2,000 writes per node.

00:30:10.700 --> 00:30:13.670
You can see CP realization
and the type of data.

00:30:13.670 --> 00:30:17.109
We've got about 17 terabytes
of data that we're running.

00:30:17.109 --> 00:30:18.650
We provide you some
monitoring tools,

00:30:18.650 --> 00:30:23.287
so you can see what we've been
doing over the last seven days.

00:30:23.287 --> 00:30:25.370
Going back, you can see
we were loading some data,

00:30:25.370 --> 00:30:27.680
running a bunch of demos.

00:30:27.680 --> 00:30:29.540
You can see the
operational work-through.

00:30:29.540 --> 00:30:31.415
You can see how much
data we've been writing,

00:30:31.415 --> 00:30:33.440
and you can see that
we've been scaling up

00:30:33.440 --> 00:30:35.860
to about 18 terabytes of data.

00:30:35.860 --> 00:30:39.204
So we provide all these
tools as part of the product.

00:30:39.204 --> 00:30:41.370
If we want to then go ahead
and look at a database--

00:30:41.370 --> 00:30:45.932
so again, multiple databases
inside of a instance,

00:30:45.932 --> 00:30:47.390
you can see here
all of our tables.

00:30:47.390 --> 00:30:48.930
So we can look at
the account table.

00:30:48.930 --> 00:30:49.846
We can see the schema.

00:30:49.846 --> 00:30:51.440
We can see indexes.

00:30:51.440 --> 00:30:53.315
So under event, we can
see we've got indexes.

00:30:57.069 --> 00:30:58.610
If I want to preview
the data, I can.

00:30:58.610 --> 00:31:01.890
So we're going to look
at the venue info table.

00:31:04.802 --> 00:31:06.510
And if we want to
preview it, we can look

00:31:06.510 --> 00:31:09.120
and say, OK, these are the
venue IDs, venue names,

00:31:09.120 --> 00:31:10.770
and country codes.

00:31:10.770 --> 00:31:13.440
If I want to introspect
my data and take a look,

00:31:13.440 --> 00:31:15.001
I can go ahead
and write a query.

00:31:15.001 --> 00:31:16.500
I'm going to cheat
and cut and paste

00:31:16.500 --> 00:31:18.874
because I'm a terrible typer
when people are watching me.

00:31:21.570 --> 00:31:22.895
It's the end of the Conference.

00:31:22.895 --> 00:31:24.270
I really want to
be on the beach.

00:31:24.270 --> 00:31:27.630
So let's look for any venues
that have beach in the title.

00:31:27.630 --> 00:31:30.840
We run the query,
43 milliseconds

00:31:30.840 --> 00:31:33.900
to query across 18
terabytes of data

00:31:33.900 --> 00:31:36.610
in three continents in
five different regions.

00:31:36.610 --> 00:31:38.640
And as one of my
colleagues likes to say,

00:31:38.640 --> 00:31:40.410
what's so remarkable
about this query

00:31:40.410 --> 00:31:42.420
is how unremarkable it is.

00:31:42.420 --> 00:31:45.840
Select venue ID, venue name,
country code from venue

00:31:45.840 --> 00:31:48.660
where venue name contains beach.

00:31:48.660 --> 00:31:52.290
This is standard ANSI 2011 SQL.

00:31:52.290 --> 00:31:55.390
There's nothing special
about this at all.

00:31:55.390 --> 00:31:57.390
If I want to see how would
that query look like,

00:31:57.390 --> 00:31:58.710
we provide a query explain.

00:31:58.710 --> 00:32:01.030
So you can look at the
data and say, OK, we

00:32:01.030 --> 00:32:03.270
did a distributed union.

00:32:03.270 --> 00:32:05.860
We get down to the end, we
see, oh, there's a table scan.

00:32:05.860 --> 00:32:07.002
That's probably bad.

00:32:07.002 --> 00:32:09.210
I should probably add an
index for this type of query

00:32:09.210 --> 00:32:12.460
and add a secondary index to
make these queries even faster.

00:32:12.460 --> 00:32:14.130
So we can get that
43 milliseconds down

00:32:14.130 --> 00:32:16.403
to 10 milliseconds.

00:32:19.720 --> 00:32:21.950
Talked a little bit about
the developer experience.

00:32:21.950 --> 00:32:25.240
So again, I'm a
Python developer.

00:32:30.040 --> 00:32:31.330
So I'm in Cloud Shell.

00:32:31.330 --> 00:32:32.260
So for those of
you who don't know,

00:32:32.260 --> 00:32:34.630
if you click this little
button up here in the corner,

00:32:34.630 --> 00:32:38.040
that actually spins up
a VM in your project

00:32:38.040 --> 00:32:42.070
and instantiates a SSH
session into the VM, which

00:32:42.070 --> 00:32:44.110
allows you to basically
have command line

00:32:44.110 --> 00:32:45.700
access to all of your VMs.

00:32:45.700 --> 00:32:48.765
So if I'm getting
ready to run this,

00:32:48.765 --> 00:32:50.640
the first thing I'm
going to do is say, OK, I

00:32:50.640 --> 00:32:51.910
need the client library.

00:32:51.910 --> 00:32:54.070
So I apologize for using pseudo.

00:32:54.070 --> 00:32:55.790
It's bad hygiene,
but this is a demo.

00:32:58.440 --> 00:33:01.559
Google Cloud Spanner.

00:33:01.559 --> 00:33:03.100
So I'm going to
check and make sure I

00:33:03.100 --> 00:33:04.330
have all my dependencies.

00:33:04.330 --> 00:33:05.724
Great, I've got them installed.

00:33:05.724 --> 00:33:07.390
Let's go ahead and
start a command line,

00:33:07.390 --> 00:33:09.040
interactive command line.

00:33:11.650 --> 00:33:13.870
Great, so going back
and doing that code

00:33:13.870 --> 00:33:15.910
that we did before, first
thing I'm going to do

00:33:15.910 --> 00:33:17.094
is grab my import.

00:33:17.094 --> 00:33:18.385
I'm going to import my package.

00:33:21.370 --> 00:33:24.377
I'm going to grab my client.

00:33:24.377 --> 00:33:25.460
So this client is created.

00:33:25.460 --> 00:33:27.550
It's using credentials
based on the fact that I've

00:33:27.550 --> 00:33:29.450
done G Cloud, so it
knows where to find

00:33:29.450 --> 00:33:32.720
the credentials in my JSON
file with my credentials.

00:33:32.720 --> 00:33:35.600
Great, I've got a
client, and I need

00:33:35.600 --> 00:33:37.104
to grab a handle to my instance.

00:33:37.104 --> 00:33:37.770
Got an instance.

00:33:41.170 --> 00:33:42.957
Need a database.

00:33:42.957 --> 00:33:44.290
Give me a handle on my database.

00:33:44.290 --> 00:33:47.545
Obviously we could do this
all in one line of code.

00:33:47.545 --> 00:33:48.920
And now I'm going
to run a query.

00:33:53.680 --> 00:33:58.000
Great, so, again, what I've
done is I've selected venues.

00:33:58.000 --> 00:34:00.550
We just did a talk in
Cloud Next in Tel Aviv.

00:34:00.550 --> 00:34:02.950
So I wanted all the venues
that are in Jerusalem.

00:34:02.950 --> 00:34:05.080
I can then print this
out and just say,

00:34:05.080 --> 00:34:12.437
for row in results print row.

00:34:12.437 --> 00:34:13.520
And these are the results.

00:34:13.520 --> 00:34:16.219
So seven lines of
code, I've run a query

00:34:16.219 --> 00:34:19.220
over 18 terabytes of data,
returned them and printed them

00:34:19.220 --> 00:34:20.323
out to the command line.

00:34:20.323 --> 00:34:22.489
That's all it takes to get
started on Cloud Spanner.

00:34:22.489 --> 00:34:23.989
And we spent a
lot of time really

00:34:23.989 --> 00:34:26.090
optimizing this to
make sure that it feels

00:34:26.090 --> 00:34:28.460
idiomatic for Python and
idiomatic for all the client

00:34:28.460 --> 00:34:29.750
libraries.

00:34:29.750 --> 00:34:32.910
So it's very clean to use.

00:34:32.910 --> 00:34:34.909
The last thing I'll show
you is that we actually

00:34:34.909 --> 00:34:37.922
export all of our
data into Stackdriver.

00:34:37.922 --> 00:34:39.380
So for those of
you who don't know,

00:34:39.380 --> 00:34:42.900
Stackdriver is our multi
cloud monitoring system.

00:34:42.900 --> 00:34:44.420
It provides logging
and monitoring.

00:34:44.420 --> 00:34:45.590
You push metrics.

00:34:45.590 --> 00:34:47.480
So we've pushed all
of these metrics

00:34:47.480 --> 00:34:50.600
into Stackdriver, which allows
you to build custom dashboard.

00:34:50.600 --> 00:34:52.750
So this is our
ticker sales demo.

00:34:52.750 --> 00:34:55.150
So we can see Spanner
utilization over time,

00:34:55.150 --> 00:34:56.690
throughput to the database.

00:34:56.690 --> 00:34:58.876
Let's do a week.

00:34:58.876 --> 00:35:00.500
We can see the number
of nodes we have,

00:35:00.500 --> 00:35:02.235
the size of the demo database.

00:35:02.235 --> 00:35:03.860
And because the data
is in Stackdriver,

00:35:03.860 --> 00:35:06.734
you can set up custom alerts.

00:35:06.734 --> 00:35:08.900
So custom alerting policies
that can either send you

00:35:08.900 --> 00:35:11.781
emails, text messages,
integration with things

00:35:11.781 --> 00:35:13.530
like pager duty,
whatever it happens to be

00:35:13.530 --> 00:35:14.690
for your monitoring system.

00:35:14.690 --> 00:35:16.731
Because all the data is
available in Stackdriver,

00:35:16.731 --> 00:35:18.530
you can set up
whatever type of custom

00:35:18.530 --> 00:35:21.140
alerting and monitoring
you want to do.

00:35:21.140 --> 00:35:22.906
So Cloud Spanner really
from the beginning

00:35:22.906 --> 00:35:25.280
was integrated with all the
various parts of Google Cloud

00:35:25.280 --> 00:35:28.300
Platform to make it as easy and
seamless for people to get up

00:35:28.300 --> 00:35:28.800
and running.

00:35:28.800 --> 00:35:30.590
And so these are
just some examples,

00:35:30.590 --> 00:35:32.330
along with things like
identity and access management

00:35:32.330 --> 00:35:34.640
and the way that we do our
auto logging, so that all of it

00:35:34.640 --> 00:35:35.723
just works out of the box.

00:35:35.723 --> 00:35:37.882
[MUSIC PLAYING]

