WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:02.430
If you have ever looked
for your car keys,

00:00:02.430 --> 00:00:04.220
or been lost in an
unfamiliar place,

00:00:04.220 --> 00:00:06.320
you know how
incredibly useful it

00:00:06.320 --> 00:00:09.060
is to understand and
remember your surroundings.

00:00:09.060 --> 00:00:11.910
Project Tango is adding this
capability to mobile devices,

00:00:11.910 --> 00:00:14.790
so they can track their motion,
recognize faces, and scan

00:00:14.790 --> 00:00:17.110
the surroundings in 3D.

00:00:17.110 --> 00:00:19.230
Its ability to
recognize spaces means

00:00:19.230 --> 00:00:23.570
it can determine its exact
position, find your car keys,

00:00:23.570 --> 00:00:26.910
and remember where you put
your virtual pet monster.

00:00:26.910 --> 00:00:29.900
In this episode, we will talk
about area learning concepts

00:00:29.900 --> 00:00:33.180
and how to get started with
Project Tango Explorer.

00:00:33.180 --> 00:00:35.880
Project Tango combines
visual and inertial data

00:00:35.880 --> 00:00:38.000
to give mobile devices
an understanding

00:00:38.000 --> 00:00:40.040
of position and orientation.

00:00:40.040 --> 00:00:42.040
It gets the visual
data from its cameras,

00:00:42.040 --> 00:00:44.630
and the inertial data from
its built-in acceleration

00:00:44.630 --> 00:00:47.150
and rotation sensors.

00:00:47.150 --> 00:00:50.150
This is combined into motion
tracking data, which provides

00:00:50.150 --> 00:00:52.520
the device relative motion.

00:00:52.520 --> 00:00:55.630
Area Learning extends this
data to remember areas

00:00:55.630 --> 00:00:58.750
and to estimate the device
position within them.

00:00:58.750 --> 00:01:00.460
You can use this for
multiple purposes,

00:01:00.460 --> 00:01:02.770
such as precise
indoor navigation,

00:01:02.770 --> 00:01:04.989
placing virtual objects
in the physical world,

00:01:04.989 --> 00:01:09.470
or to share a virtual
world with other users.

00:01:09.470 --> 00:01:11.240
To use area learning,
you must first

00:01:11.240 --> 00:01:13.980
learn an area so the system
will be able to recognize

00:01:13.980 --> 00:01:15.550
the area later.

00:01:15.550 --> 00:01:18.710
The combination of
learning and localization

00:01:18.710 --> 00:01:20.840
is similar to what humans do.

00:01:20.840 --> 00:01:22.590
When you enter a new
building, you quickly

00:01:22.590 --> 00:01:24.210
get a picture of
its layout, and you

00:01:24.210 --> 00:01:28.810
can use this memory to find
your way around at a later time.

00:01:28.810 --> 00:01:30.680
Project Tango saves
the learned memories

00:01:30.680 --> 00:01:33.810
into an area description
file, or ADF.

00:01:33.810 --> 00:01:36.970
This file contains descriptions
of visual landmarks

00:01:36.970 --> 00:01:40.340
that the system uses when
looking for known places.

00:01:40.340 --> 00:01:43.940
An ADF enables the device
to estimate its position

00:01:43.940 --> 00:01:47.000
through a process we
call localization.

00:01:47.000 --> 00:01:48.880
Another important
aspect of area learning

00:01:48.880 --> 00:01:52.390
is that the device can
refine its position estimate

00:01:52.390 --> 00:01:55.100
relative to the area it is in.

00:01:55.100 --> 00:01:57.900
This is great if you want
to fixate a virtual world

00:01:57.900 --> 00:01:59.300
in the physical world.

00:01:59.300 --> 00:02:02.940
For example, if you want to put
an elephant in the living room

00:02:02.940 --> 00:02:06.610
and have it stay there,
without area learning

00:02:06.610 --> 00:02:08.900
the system can only
estimate its position

00:02:08.900 --> 00:02:12.700
based on small increments
in the motion of the device.

00:02:12.700 --> 00:02:15.060
This method introduces
inaccuracies,

00:02:15.060 --> 00:02:18.160
as it requires incredibly
precise sensors

00:02:18.160 --> 00:02:20.730
to be able to track
motion like this.

00:02:20.730 --> 00:02:23.080
Just imagine you had
to count your steps

00:02:23.080 --> 00:02:25.760
and turns to be able
to know where you are.

00:02:25.760 --> 00:02:28.080
It's error prone.

00:02:28.080 --> 00:02:31.050
Area learning sidesteps
this whole issue

00:02:31.050 --> 00:02:33.300
by storing visual
references that it can

00:02:33.300 --> 00:02:35.860
use to calculate its position.

00:02:35.860 --> 00:02:38.350
In other words, the
ADF is the frame

00:02:38.350 --> 00:02:41.570
of reference in area learning.

00:02:41.570 --> 00:02:43.420
To make area
description files, you

00:02:43.420 --> 00:02:45.640
can either implement area
learning in your own app,

00:02:45.640 --> 00:02:48.900
or use a developer tool
like Project Tango Explorer

00:02:48.900 --> 00:02:50.910
to learn an area.

00:02:50.910 --> 00:02:53.440
But first you need to know
that area descriptions are not

00:02:53.440 --> 00:02:54.970
created equal.

00:02:54.970 --> 00:02:57.800
It's possible to learn an
area with different levels

00:02:57.800 --> 00:03:00.850
of quality depending on how much
of the area you have learned.

00:03:00.850 --> 00:03:03.830
For instance, it's going to make
a big difference if you only

00:03:03.830 --> 00:03:08.060
take a picture from one
perspective versus taking

00:03:08.060 --> 00:03:10.972
pictures of all the
perspectives of a room.

00:03:10.972 --> 00:03:12.880
The more coverage
you have, the easier

00:03:12.880 --> 00:03:16.000
it will be for the device to
recall it has been in the area

00:03:16.000 --> 00:03:18.020
before.

00:03:18.020 --> 00:03:21.340
It is important to note that the
success of area learning also

00:03:21.340 --> 00:03:23.190
depends on visual
characteristics

00:03:23.190 --> 00:03:24.990
of the environment.

00:03:24.990 --> 00:03:28.740
An ideal environment has
distinguishing visual features,

00:03:28.740 --> 00:03:33.340
mostly stationary objects, and
does not change much over time.

00:03:33.340 --> 00:03:35.210
Environments that
are visually bland,

00:03:35.210 --> 00:03:37.470
such as long,
undecorated hallways,

00:03:37.470 --> 00:03:39.780
or places with a
lot of moving people

00:03:39.780 --> 00:03:42.840
can be harder for the
system to remember.

00:03:42.840 --> 00:03:45.530
Light also changes
the way things look.

00:03:45.530 --> 00:03:48.979
So if the lighting conditions
vary a lot in the area,

00:03:48.979 --> 00:03:50.520
you may need to have
a couple of ADFs

00:03:50.520 --> 00:03:54.280
for the brightest and
darkest time of day.

00:03:54.280 --> 00:03:58.310
Project Tango allows you
to learn and load an ADF.

00:03:58.310 --> 00:04:01.810
The ADF will be stored
in the flash memory,

00:04:01.810 --> 00:04:04.490
and can be used in other
apps to find the position

00:04:04.490 --> 00:04:06.020
and orientation.

00:04:06.020 --> 00:04:08.050
You can download Explorer
from the Play Store,

00:04:08.050 --> 00:04:12.210
but let's go through how
it works in practice.

00:04:12.210 --> 00:04:14.600
In the default mode,
click the learn button

00:04:14.600 --> 00:04:16.600
to create a new
ADF, and walk around

00:04:16.600 --> 00:04:18.959
in the area in one direction.

00:04:18.959 --> 00:04:21.410
Remember, the system
benefits from having

00:04:21.410 --> 00:04:24.320
seen more of the space, so
once done walking around,

00:04:24.320 --> 00:04:26.582
walk back in the
opposite direction.

00:04:26.582 --> 00:04:28.540
This increases the coverage
and makes it easier

00:04:28.540 --> 00:04:30.670
to use the ADF later.

00:04:30.670 --> 00:04:33.910
In the end, we save
the ADF to a file.

00:04:33.910 --> 00:04:37.480
It then takes three steps
to localize in the area.

00:04:37.480 --> 00:04:40.650
First, be in an area
that has been learned

00:04:40.650 --> 00:04:42.890
and for which there is an ADF.

00:04:42.890 --> 00:04:46.140
Second, load the
ADF for the area.

00:04:46.140 --> 00:04:52.530
And third, move the device to
compare the ADF to the area.

00:04:52.530 --> 00:04:54.960
Once the system has
recognized the area,

00:04:54.960 --> 00:04:58.040
you will be receiving real-time
updates on the position

00:04:58.040 --> 00:05:00.310
and orientation of the device.

00:05:00.310 --> 00:05:02.330
You will only see a blue
trace in the beginning,

00:05:02.330 --> 00:05:05.040
and until the system
figures out where it is.

00:05:05.040 --> 00:05:07.210
This is the relative
motion tracking trace,

00:05:07.210 --> 00:05:09.590
which you can learn more
about in the Introduction

00:05:09.590 --> 00:05:12.200
to Motion Tracking video.

00:05:12.200 --> 00:05:16.920
As soon as the system recognizes
the area using the ADF,

00:05:16.920 --> 00:05:19.260
a green trace will appear.

00:05:19.260 --> 00:05:20.770
This is the position
of the device

00:05:20.770 --> 00:05:22.450
in the area you have learned.

00:05:22.450 --> 00:05:25.400
The system now uses the learned
data to correct the device

00:05:25.400 --> 00:05:29.100
position within this area.

00:05:29.100 --> 00:05:32.210
Area learning adds the
ability to visually recognize

00:05:32.210 --> 00:05:37.110
known areas, and locate
the device within them.

00:05:37.110 --> 00:05:39.670
Whether you want to have
a monster under your bed,

00:05:39.670 --> 00:05:41.930
or have an elephant
in your living room,

00:05:41.930 --> 00:05:44.830
area learning will
allow you to do that.

00:05:44.830 --> 00:05:48.550
Visit our Google+ community,
and join us on our journey.

00:05:48.550 --> 00:05:51.585
We're excited to see what you
will build with Project Tango.

00:05:51.585 --> 00:05:54.500
[MUSIC PLAYING]

