WEBVTT
Kind: captions
Language: en

00:00:00.170 --> 00:00:03.060
All right, so you might ask,
get ready Megan,

00:00:03.060 --> 00:00:05.390
you might ask what does this
have to do with vision?

00:00:05.390 --> 00:00:07.320
&gt;&gt; What does this have
to do with vision?

00:00:07.320 --> 00:00:11.390
&gt;&gt; Well you might have some video
of something happening such as

00:00:11.390 --> 00:00:15.900
a person moving their hands around to
wave, or point, or control something.

00:00:15.900 --> 00:00:19.440
And you'd like to be able to say,
you know, which gesture is this?

00:00:19.440 --> 00:00:22.210
Or you know, what action are they doing?

00:00:22.210 --> 00:00:24.630
And the stuff I'm going to talk about
today is sort of some of this time

00:00:24.630 --> 00:00:26.790
series work,
in particular Markov models,

00:00:26.790 --> 00:00:31.430
apply to the decoding of
visual kinds of information.

00:00:31.430 --> 00:00:34.350
So the real question is,
how do we model these problem?

00:00:34.350 --> 00:00:37.750
How do we, you know, how are we going to
build, I showed you these time series.

00:00:37.750 --> 00:00:39.660
Well, we need a model of these.

00:00:39.660 --> 00:00:42.510
And in particular, we're going to
have to give it a bunch of them to

00:00:42.510 --> 00:00:44.350
be able to construct that model.

00:00:44.350 --> 00:00:47.080
So it's basically going to be
an inference or a learning problem.

00:00:47.080 --> 00:00:48.750
The learning is, learning the model and

00:00:48.750 --> 00:00:51.280
the inferences while
given a set of models,

00:00:51.280 --> 00:00:55.160
which one do I think is most likely to
have generated the data that I'm seeing?

