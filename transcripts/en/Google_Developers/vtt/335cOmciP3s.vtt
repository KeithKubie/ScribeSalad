WEBVTT
Kind: captions
Language: en

00:00:11.672 --> 00:00:12.880
FRED SAUER: Welcome everyone.

00:00:12.880 --> 00:00:14.710
It's great to have you
here at the end of the day.

00:00:14.710 --> 00:00:16.129
Thank you for sticking around.

00:00:16.129 --> 00:00:19.830
We've seen some pretty
exciting announcements today.

00:00:19.830 --> 00:00:22.290
I want to welcome
back to the stage

00:00:22.290 --> 00:00:25.980
Urs Holzle, who is,
as you already know,

00:00:25.980 --> 00:00:28.540
the senior VP in charge of
technical infrastructure

00:00:28.540 --> 00:00:32.009
at Google responsible for
building all the data centers.

00:00:32.009 --> 00:00:35.960
I also want to welcome
Jeff Dean on stage.

00:00:35.960 --> 00:00:39.350
Many of you know Jeff, and if
you don't, you probably should.

00:00:39.350 --> 00:00:42.410
He is a senior Google
fellow and has had his hands

00:00:42.410 --> 00:00:45.390
in every piece of major
infrastructure at Google,

00:00:45.390 --> 00:00:46.830
and he's built
many of the systems

00:00:46.830 --> 00:00:50.040
that you know and have heard
about that have inspired

00:00:50.040 --> 00:00:53.690
many open source projects
such as MapReduce, BigTable,

00:00:53.690 --> 00:00:54.550
Spanner.

00:00:54.550 --> 00:00:57.850
He's worked on web search, the
ad serving system, basically

00:00:57.850 --> 00:01:01.260
all the important
bits at Google.

00:01:01.260 --> 00:01:05.400
So Urs, if I can
start with you, maybe

00:01:05.400 --> 00:01:08.740
ask you a couple questions that
are on top of developers minds

00:01:08.740 --> 00:01:09.500
today.

00:01:09.500 --> 00:01:12.040
We've heard a lot
about the commitment

00:01:12.040 --> 00:01:15.700
to Cloud and
everything that Google

00:01:15.700 --> 00:01:18.590
is putting behind the
Google Cloud Platform.

00:01:18.590 --> 00:01:20.090
Could you maybe
tell us a little bit

00:01:20.090 --> 00:01:23.530
about why Cloud is important to
Google, why Cloud is important

00:01:23.530 --> 00:01:24.520
you.

00:01:24.520 --> 00:01:25.650
URS HOLZLE: Sure.

00:01:25.650 --> 00:01:27.620
So it's really two
things coming together.

00:01:27.620 --> 00:01:33.100
One is that we always like
to think about the long term.

00:01:33.100 --> 00:01:36.320
If you think about it
in a 10 year time frame,

00:01:36.320 --> 00:01:40.680
there isn't really any
chance that 10 years from now

00:01:40.680 --> 00:01:45.560
the public Cloud isn't a
major, major part of the world.

00:01:45.560 --> 00:01:47.590
Today, everyone talks about it.

00:01:47.590 --> 00:01:50.470
But the reality is that
you all who are using Cloud

00:01:50.470 --> 00:01:56.680
are part of the vast minority
of developers and IT folks

00:01:56.680 --> 00:01:58.480
who actually are doing it.

00:01:58.480 --> 00:02:01.320
But if you think 10 years
out, there's just no question

00:02:01.320 --> 00:02:06.790
that a reasonable fraction of
the world's server side cycles

00:02:06.790 --> 00:02:08.539
are going to be in
the public Cloud.

00:02:08.539 --> 00:02:12.750
And that's going to be an
interesting business for us,

00:02:12.750 --> 00:02:16.610
for others too, and so if
you look at just the numbers

00:02:16.610 --> 00:02:20.540
it's easily bigger than the
advertising business is for us.

00:02:20.540 --> 00:02:23.970
So that's the business
opportunity side.

00:02:23.970 --> 00:02:27.010
Then the second part is
the technical opportunity.

00:02:27.010 --> 00:02:30.690
We've been living at Google
in the Cloud for 15 years

00:02:30.690 --> 00:02:31.480
basically.

00:02:31.480 --> 00:02:36.062
For 13 of these 15 years our
Cloud was just for our own use.

00:02:36.062 --> 00:02:38.270
But we've learned a lot,
and many of the things we've

00:02:38.270 --> 00:02:43.100
learned apply directly
to the public Cloud.

00:02:43.100 --> 00:02:48.050
And you mention Jeff, we
came up with MapReduce,

00:02:48.050 --> 00:02:50.590
and that's now turned
into a very common thing

00:02:50.590 --> 00:02:51.839
that everyone uses.

00:02:51.839 --> 00:02:53.630
It's just that we had
the problems earlier,

00:02:53.630 --> 00:02:56.360
and that's why we came
across there early.

00:02:56.360 --> 00:02:58.240
So there's a big
opportunity for us

00:02:58.240 --> 00:03:00.990
to actually take that
technical leadership

00:03:00.990 --> 00:03:03.000
and really turn it
into product leadership

00:03:03.000 --> 00:03:07.056
on the external side,
just not the internal one.

00:03:07.056 --> 00:03:07.680
FRED SAUER: OK.

00:03:10.420 --> 00:03:14.880
Yesterday there was an article
in "Wired Magazine" where

00:03:14.880 --> 00:03:20.100
you were quite prominently
featured, and in that article

00:03:20.100 --> 00:03:22.090
there was a memo
that was described

00:03:22.090 --> 00:03:25.349
that you wrote to folks
in your organization,

00:03:25.349 --> 00:03:26.890
to the technical
infrastructure team,

00:03:26.890 --> 00:03:31.430
but also to the rest of
Google, and you set a call

00:03:31.430 --> 00:03:33.430
to change the
direction in motion.

00:03:33.430 --> 00:03:35.190
Could you talk about
what you wrote,

00:03:35.190 --> 00:03:39.140
and what was the reason
for sending this memo?

00:03:39.140 --> 00:03:41.850
URS HOLZLE: Sure.

00:03:41.850 --> 00:03:45.660
Engineers get to write code,
and managers get to write memos.

00:03:45.660 --> 00:03:50.170
So we compete on equal footing.

00:03:50.170 --> 00:03:51.550
[LAUGHTER]

00:03:51.550 --> 00:03:54.669
JEFF DEAN: How many lines of
memos have you done this year?

00:03:54.669 --> 00:03:55.710
URS HOLZLE: That's right.

00:03:55.710 --> 00:03:59.790
My memo's are very concise, and
I write them in [INAUDIBLE].

00:03:59.790 --> 00:04:02.260
[LAUGHTER]

00:04:02.260 --> 00:04:05.710
I write them in Google
Docs, of course.

00:04:05.710 --> 00:04:07.230
We're really going
through a change.

00:04:07.230 --> 00:04:09.800
So we started,
about two years ago,

00:04:09.800 --> 00:04:12.490
to redo our internal
infrastructure

00:04:12.490 --> 00:04:14.590
because in the 15 years
that we'd been doing it

00:04:14.590 --> 00:04:17.060
we learned a lot and we
went through a big push

00:04:17.060 --> 00:04:18.510
to simplify things.

00:04:18.510 --> 00:04:20.670
We accumulated a lot
of stuff because we

00:04:20.670 --> 00:04:21.880
tried a lot of things.

00:04:21.880 --> 00:04:23.380
Some of them worked
and some of them

00:04:23.380 --> 00:04:25.060
didn't, and now we
think we actually

00:04:25.060 --> 00:04:26.800
know pretty well how to do that.

00:04:26.800 --> 00:04:29.450
We're using this
infrastructure to power Cloud,

00:04:29.450 --> 00:04:32.390
and we want those
two to be the same.

00:04:32.390 --> 00:04:35.460
Previously, the last two years,
was really the preparation

00:04:35.460 --> 00:04:37.150
for that, laying the groundwork.

00:04:37.150 --> 00:04:41.900
And now that the platform
Compute Engine is actually

00:04:41.900 --> 00:04:45.030
live, no longer
beta, now it's time

00:04:45.030 --> 00:04:49.350
to really move many more of
our infrastructure systems

00:04:49.350 --> 00:04:50.820
onto the external platforms.

00:04:50.820 --> 00:04:55.670
So the new world
memo that I wrote

00:04:55.670 --> 00:04:58.690
was really about
taking this year

00:04:58.690 --> 00:05:02.050
and making this the number
one priority for everyone,

00:05:02.050 --> 00:05:04.270
and have a majority
of the organization

00:05:04.270 --> 00:05:08.059
work on the external product
rather than the internal one.

00:05:08.059 --> 00:05:09.600
And one of the
reasons we can do that

00:05:09.600 --> 00:05:13.370
is because our internal one is
actually in pretty good shape.

00:05:13.370 --> 00:05:18.880
So not working quite as much on
it is not going to hurt anyone.

00:05:18.880 --> 00:05:20.940
So this year we're really
spending the majority

00:05:20.940 --> 00:05:25.190
of our effort in externalizing
the many things that we haven't

00:05:25.190 --> 00:05:27.660
externalized yet, because
the platform now is ready.

00:05:27.660 --> 00:05:30.870
And so adding people will
actually make things go faster

00:05:30.870 --> 00:05:31.910
rather than slower.

00:05:31.910 --> 00:05:33.530
FRED SAUER: So it's a
pretty significant shift.

00:05:33.530 --> 00:05:34.738
URS HOLZLE: Yeah, definitely.

00:05:34.738 --> 00:05:35.880
FRED SAUER: Hence the memo.

00:05:35.880 --> 00:05:36.588
URS HOLZLE: Yeah.

00:05:36.588 --> 00:05:37.950
Yes.

00:05:37.950 --> 00:05:41.380
FRED SAUER: So, App Engine,
in less than two weeks time,

00:05:41.380 --> 00:05:43.550
turns six.

00:05:43.550 --> 00:05:45.600
So Google has been
working on the Cloud

00:05:45.600 --> 00:05:47.760
platform for quite some time.

00:05:47.760 --> 00:05:50.750
But it seems that,
not only seems,

00:05:50.750 --> 00:05:54.600
but there is actual
accelerated lunches

00:05:54.600 --> 00:05:58.170
that have been happening in the
last 12 months, and of course

00:05:58.170 --> 00:05:59.470
with today's event.

00:05:59.470 --> 00:06:03.450
Was delivering and creating
the Google Cloud Platform

00:06:03.450 --> 00:06:05.940
always the plan for
you from day one,

00:06:05.940 --> 00:06:09.780
or is this something that
has evolved over time?

00:06:09.780 --> 00:06:16.890
URS HOLZLE: So I
think the dichotomy

00:06:16.890 --> 00:06:19.810
between infrastructure
as a service and platform

00:06:19.810 --> 00:06:22.717
as a service is really
a false dichotomy.

00:06:22.717 --> 00:06:25.300
It's really much more of a grey
scale, and you saw that today.

00:06:25.300 --> 00:06:28.810
We want to make it a grey scale
where you can be all the way

00:06:28.810 --> 00:06:31.440
over here where we make all the
choices for you and your life

00:06:31.440 --> 00:06:34.660
is really, really easy, or over
here where you can make all

00:06:34.660 --> 00:06:36.380
the choices and
your life is really,

00:06:36.380 --> 00:06:38.300
really flexible but maybe you
have to do a little bit more

00:06:38.300 --> 00:06:38.900
work.

00:06:38.900 --> 00:06:40.483
And there aren't
just these two points

00:06:40.483 --> 00:06:43.270
but there's is basically
anything in between.

00:06:43.270 --> 00:06:47.770
So I think what we realized was
that even though people were

00:06:47.770 --> 00:06:49.944
extremely successful
on App Engine,

00:06:49.944 --> 00:06:52.360
you heard Snapchat today, but
there's many other examples.

00:06:52.360 --> 00:06:55.410
People really love App Engine
because they can walk away

00:06:55.410 --> 00:06:57.920
from an application
after they deployed it.

00:06:57.920 --> 00:07:00.160
Really the way we say, you're
only maintenance action

00:07:00.160 --> 00:07:02.810
for years is to renew
your credit card.

00:07:02.810 --> 00:07:04.470
That's really all
you have to do.

00:07:04.470 --> 00:07:06.440
And there's incredible
value in that.

00:07:06.440 --> 00:07:10.310
But even the biggest users
of App Engine said, hey look,

00:07:10.310 --> 00:07:12.410
I have this other piece
on here and it's not

00:07:12.410 --> 00:07:15.160
realistic to rewrite it, or
I don't want to rewrite it,

00:07:15.160 --> 00:07:17.300
or it's actually
great as it is, and I

00:07:17.300 --> 00:07:18.950
need be able to just run it.

00:07:18.950 --> 00:07:21.850
And for that you need VMs so
they can wrap them around.

00:07:21.850 --> 00:07:24.100
And our goal really
is to say, look,

00:07:24.100 --> 00:07:27.010
pick the parts
that you like most,

00:07:27.010 --> 00:07:30.300
implement the components
the way you see fit,

00:07:30.300 --> 00:07:33.340
and then fit things
together into a low effort,

00:07:33.340 --> 00:07:36.420
high performance, easy
to maintain system.

00:07:36.420 --> 00:07:40.220
So it's really not an either/or.

00:07:40.220 --> 00:07:41.060
So that's that.

00:07:41.060 --> 00:07:42.570
We set out, certainly,
with a vision

00:07:42.570 --> 00:07:45.760
of having something that's very
high level, very easy to use,

00:07:45.760 --> 00:07:49.870
and very low touch once
you're done, very productive.

00:07:49.870 --> 00:07:52.350
Actually, if you
ask me to bet, I

00:07:52.350 --> 00:07:54.200
would say, 10 years
from now, that

00:07:54.200 --> 00:07:57.520
is going to be the main way of
how you actually use a Cloud.

00:07:57.520 --> 00:08:02.820
Because if you can fit into
that pattern, it's so useful,

00:08:02.820 --> 00:08:08.250
it's so low cost because you
don't have to touch anything,

00:08:08.250 --> 00:08:09.950
that that's really a big win.

00:08:09.950 --> 00:08:13.050
But you've got to cover
the entire spectrum,

00:08:13.050 --> 00:08:16.100
and there's a lot between
now one and 10 years from now

00:08:16.100 --> 00:08:17.790
that's going to change.

00:08:17.790 --> 00:08:20.860
It's an iffy bet
even for me to make.

00:08:20.860 --> 00:08:22.690
FRED SAUER: OK.

00:08:22.690 --> 00:08:27.280
So when you run and manage the
world's largest data centers

00:08:27.280 --> 00:08:29.820
and you're hosting
millions of applications

00:08:29.820 --> 00:08:33.700
and that application
data, security

00:08:33.700 --> 00:08:36.070
has to be just at
the top of your mind.

00:08:38.690 --> 00:08:42.620
Why should developers trust
their data to the cloud?

00:08:45.390 --> 00:08:47.240
URS HOLZLE: So I think
there's two answers.

00:08:47.240 --> 00:08:52.280
One is we're probably going to
do a better job than you would

00:08:52.280 --> 00:08:55.050
do yourself, because
security is hard

00:08:55.050 --> 00:08:59.640
and there's always all
kinds of ways to screw up

00:08:59.640 --> 00:09:01.440
and we have a great team.

00:09:01.440 --> 00:09:03.240
The second one is
that there used

00:09:03.240 --> 00:09:10.110
to be this conception that
IT needs security, that's

00:09:10.110 --> 00:09:12.790
where your standards
are high, and consumers,

00:09:12.790 --> 00:09:15.380
they will deal with
something that's insecure.

00:09:15.380 --> 00:09:16.850
But that's not really true.

00:09:16.850 --> 00:09:19.620
With consumers having moved
much more of their personal data

00:09:19.620 --> 00:09:23.970
into the Cloud, they set
the very high standards,

00:09:23.970 --> 00:09:25.760
they have very
high expectations.

00:09:25.760 --> 00:09:28.890
So for us, as a
consumer Cloud provider,

00:09:28.890 --> 00:09:32.390
a security incident would
be extremely expensive.

00:09:32.390 --> 00:09:37.120
So we're actually spending
hundreds of people on security,

00:09:37.120 --> 00:09:38.910
we have a very
good security team,

00:09:38.910 --> 00:09:43.380
to really try and make
that extremely unlikely.

00:09:43.380 --> 00:09:46.280
And even on the
consumer side you

00:09:46.280 --> 00:09:49.220
have security features
like one time passwords

00:09:49.220 --> 00:09:54.180
that are ahead of many
enterprise products today.

00:09:54.180 --> 00:09:59.430
Or our HTTPS for years now
has used elliptic curve

00:09:59.430 --> 00:10:01.910
cryptography, which
makes it much, much more

00:10:01.910 --> 00:10:04.940
secure against intruders.

00:10:04.940 --> 00:10:07.710
Even if you get the
master key at some point,

00:10:07.710 --> 00:10:10.920
you still cannot decrypt
recorded sessions.

00:10:10.920 --> 00:10:12.690
So we've worked
really hard on that,

00:10:12.690 --> 00:10:14.872
and I think if you look
at this as a developer do

00:10:14.872 --> 00:10:16.330
you want to take
advantage of that,

00:10:16.330 --> 00:10:18.660
or do you want to
try your own luck?

00:10:18.660 --> 00:10:21.560
I think you're going to be
better off doing it this way.

00:10:21.560 --> 00:10:25.240
In the Cloud we have the extra
advantage that if you wish,

00:10:25.240 --> 00:10:27.650
you can go encrypt your
data with your own key

00:10:27.650 --> 00:10:29.660
where not even we
have access to it.

00:10:29.660 --> 00:10:31.170
So you get the
infrastructure that's

00:10:31.170 --> 00:10:34.720
already very secure against
the common mistakes,

00:10:34.720 --> 00:10:37.640
and then on top of that you
have your own extra layer

00:10:37.640 --> 00:10:39.549
of security under control.

00:10:39.549 --> 00:10:41.090
So that's really a
pretty good place,

00:10:41.090 --> 00:10:44.150
versus hosting yourself
is really, I think,

00:10:44.150 --> 00:10:45.207
a bad proposition.

00:10:45.207 --> 00:10:47.790
FRED SAUER: So you could get the
best of both worlds that way.

00:10:47.790 --> 00:10:48.390
URS HOLZLE: Exactly.

00:10:48.390 --> 00:10:49.427
You can layer on top.

00:10:49.427 --> 00:10:50.760
You can bring your own security.

00:10:50.760 --> 00:10:55.310
But you really benefit
from all the work

00:10:55.310 --> 00:10:56.430
that we've already done.

00:10:56.430 --> 00:10:58.990
In the long term people
ask what about security

00:10:58.990 --> 00:11:01.970
in the Cloud,
compliance in the Cloud?

00:11:01.970 --> 00:11:07.060
That's just as much of the
success as technical features.

00:11:07.060 --> 00:11:10.910
So if the Cloud really is 10
years from now a major factor

00:11:10.910 --> 00:11:15.230
in everything IT,
then very clearly it

00:11:15.230 --> 00:11:18.480
needs to be the best security
place, and the best compliance

00:11:18.480 --> 00:11:22.300
place, just as it is the best
technical place and the best

00:11:22.300 --> 00:11:23.182
economical place.

00:11:23.182 --> 00:11:24.640
These things need
to come together.

00:11:24.640 --> 00:11:29.500
You can't really leave them out.

00:11:29.500 --> 00:11:31.590
So almost by
definition our security

00:11:31.590 --> 00:11:34.410
will be very good,
because it has to be.

00:11:34.410 --> 00:11:35.810
FRED SAUER: OK.

00:11:35.810 --> 00:11:40.670
So I'd like to move in a little
bit to innovation at scale.

00:11:40.670 --> 00:11:42.630
And Jeff, since
we have you here,

00:11:42.630 --> 00:11:45.820
you've been involved in all the
large scale distributed systems

00:11:45.820 --> 00:11:47.850
at Google.

00:11:47.850 --> 00:11:51.230
I wonder if you could share
some of the challenges you've

00:11:51.230 --> 00:11:54.790
witnessed, and had to deal with,
and program around that really

00:11:54.790 --> 00:11:57.682
only happen at that
very large scale.

00:11:57.682 --> 00:11:59.140
Things that you
wouldn't see if you

00:11:59.140 --> 00:12:02.030
have an isle of servers
in a data center,

00:12:02.030 --> 00:12:04.220
but something you
see when you have

00:12:04.220 --> 00:12:06.640
data centers full of
computers, warehouse scale

00:12:06.640 --> 00:12:10.870
machines, many data
centers across the world,

00:12:10.870 --> 00:12:14.040
50 years of running
software on there.

00:12:14.040 --> 00:12:15.040
JEFF DEAN: Battle scars.

00:12:15.040 --> 00:12:16.180
FRED SAUER: Yeah.

00:12:16.180 --> 00:12:17.570
Show us your battle scars.

00:12:17.570 --> 00:12:19.380
JEFF DEAN: I think
there's a lot of lessons

00:12:19.380 --> 00:12:21.010
we've learned over time.

00:12:21.010 --> 00:12:22.680
From the very early
days of Google

00:12:22.680 --> 00:12:26.250
we had hardware that was
very consumer oriented

00:12:26.250 --> 00:12:29.300
hardware, didn't have a lot
of reliability features built

00:12:29.300 --> 00:12:31.760
into the hardware that you
might, like ECC memory,

00:12:31.760 --> 00:12:34.280
or even parody for
our earliest machines.

00:12:34.280 --> 00:12:37.262
So if you sort a terabyte of
memory, a terabyte of data,

00:12:37.262 --> 00:12:38.720
with a machine
that's on parody, it

00:12:38.720 --> 00:12:42.320
ends up mostly sorted,
and sorted again.

00:12:42.320 --> 00:12:44.870
It's mostly sorted
some other way.

00:12:44.870 --> 00:12:46.760
So I think from
those early days,

00:12:46.760 --> 00:12:50.660
to work around that, we built a
software check summing library

00:12:50.660 --> 00:12:55.480
that is in constant use in old
pieces of our infrastructure,

00:12:55.480 --> 00:12:58.430
just to make things more
robust for that very low level

00:12:58.430 --> 00:12:59.370
hardware.

00:12:59.370 --> 00:13:03.730
Modern machines have ECC errors,
but sometimes switch buffers

00:13:03.730 --> 00:13:06.850
don't necessarily have
ECC so you get corruption,

00:13:06.850 --> 00:13:08.822
even in never transit.

00:13:08.822 --> 00:13:10.280
So these kinds of
things are really

00:13:10.280 --> 00:13:13.640
good for protecting
against that.

00:13:13.640 --> 00:13:16.680
I think when you're pushing
the boundaries of scale,

00:13:16.680 --> 00:13:20.930
like you're running systems that
are 1,000s or perhaps 10,000s

00:13:20.930 --> 00:13:24.770
of machines, you see failure
modes that are really rare

00:13:24.770 --> 00:13:27.566
but are very perplexing
and annoying that you

00:13:27.566 --> 00:13:29.815
wouldn't necessarily see if
you're running 100 machine

00:13:29.815 --> 00:13:31.450
systems.

00:13:31.450 --> 00:13:35.320
A good example is if a
whole rack switch goes bad.

00:13:35.320 --> 00:13:37.710
That's a pretty rare event,
but all of a sudden you

00:13:37.710 --> 00:13:43.030
lose 40 machines, or 80
machines off your network.

00:13:43.030 --> 00:13:46.510
But even more nasty
than that is a switch

00:13:46.510 --> 00:13:49.730
that is kind of working.

00:13:49.730 --> 00:13:51.994
So it drops half the
packets coming through it.

00:13:51.994 --> 00:13:53.410
URS HOLZLE: Only
in one direction.

00:13:53.410 --> 00:13:54.076
JEFF DEAN: Yeah.

00:13:54.076 --> 00:13:56.140
Or only in one direction.

00:13:56.140 --> 00:14:01.320
That's actually tricky because
things like health checking

00:14:01.320 --> 00:14:05.030
and so on, that are designed
to see if something's alive,

00:14:05.030 --> 00:14:06.310
actually work.

00:14:06.310 --> 00:14:07.000
It is alive.

00:14:07.000 --> 00:14:09.000
It's just incredibly slow
and you can't actually

00:14:09.000 --> 00:14:10.220
communicate effectively
with other machines.

00:14:10.220 --> 00:14:12.080
So these are the
kinds of problems

00:14:12.080 --> 00:14:14.380
that you see running at scale.

00:14:14.380 --> 00:14:16.520
One of the things
that has happened

00:14:16.520 --> 00:14:18.680
is you recognize these
sorts of problems,

00:14:18.680 --> 00:14:22.830
and then you build
infrastructure to, in software,

00:14:22.830 --> 00:14:25.820
deal with these kinds of
failures automatically.

00:14:25.820 --> 00:14:29.140
So some of the things that
we built into MapReduce

00:14:29.140 --> 00:14:32.530
are designed to be robust to
not just a particular kind

00:14:32.530 --> 00:14:34.790
of failure, but lots
of kinds of failures.

00:14:34.790 --> 00:14:38.880
Even ones we can't imagine
right now because the software

00:14:38.880 --> 00:14:42.780
techniques are just effective at
dealing with when things aren't

00:14:42.780 --> 00:14:44.790
working right, no
matter how exactly they

00:14:44.790 --> 00:14:46.430
aren't working right.

00:14:46.430 --> 00:14:47.640
FRED SAUER: OK.

00:14:47.640 --> 00:14:50.910
So Urs, you co-authored a book.

00:14:50.910 --> 00:14:53.740
It's called "Data
Center as a Computer.

00:14:53.740 --> 00:14:57.730
An Introduction to the Design
of Warehouse-Scale Machines."

00:14:57.730 --> 00:15:00.625
In there you talk about
this software tolerance.

00:15:03.730 --> 00:15:08.930
If we get the point where we can
design some of our own hardware

00:15:08.930 --> 00:15:13.260
and build better
switches, tell us

00:15:13.260 --> 00:15:15.130
why we can't just
build better hardware

00:15:15.130 --> 00:15:17.940
so Jeff doesn't have
to work so hard.

00:15:17.940 --> 00:15:21.450
URS HOLZLE: We can and
we do, but Jeff still

00:15:21.450 --> 00:15:22.620
has to work hard.

00:15:22.620 --> 00:15:25.230
[LAUGHTER]

00:15:25.230 --> 00:15:27.920
The problem is that
scale, in the end,

00:15:27.920 --> 00:15:32.210
gets you even if
you try to avoid it.

00:15:32.210 --> 00:15:38.550
Even if you had an incredibly
good piece of hardware,

00:15:38.550 --> 00:15:40.770
there's no manufacturer
in the world that

00:15:40.770 --> 00:15:43.190
can make 100,000
of them and have

00:15:43.190 --> 00:15:47.740
them work three years
without things failing.

00:15:47.740 --> 00:15:50.970
So once you accept that
you will have failure

00:15:50.970 --> 00:15:56.180
as part of the every day,
then whether something fails

00:15:56.180 --> 00:16:00.170
three times more often or not
is actually not your problem.

00:16:00.170 --> 00:16:02.310
The problem is that
there are failures

00:16:02.310 --> 00:16:06.730
that you have to recognize,
and isolate, and automatically

00:16:06.730 --> 00:16:08.270
deal with.

00:16:08.270 --> 00:16:13.130
I think we came to peace
with that a long time ago.

00:16:13.130 --> 00:16:17.900
Because you really realize, OK,
even if I could do it better

00:16:17.900 --> 00:16:20.930
by a factor of 10, and I don't
see any vendor who does it

00:16:20.930 --> 00:16:23.910
better by a factor of
10, but even if I did it,

00:16:23.910 --> 00:16:26.060
basically my software
effort is still the same

00:16:26.060 --> 00:16:28.220
because failures
would still happen.

00:16:28.220 --> 00:16:30.872
And to some extent the
more frequent failures

00:16:30.872 --> 00:16:32.330
are the ones that
you handle really

00:16:32.330 --> 00:16:34.650
well because those are
the really well tested

00:16:34.650 --> 00:16:35.710
kinds of things.

00:16:35.710 --> 00:16:38.050
So to some extent,
there really is not

00:16:38.050 --> 00:16:40.630
an advantage in
making them more rare.

00:16:40.630 --> 00:16:42.440
So generally we pick
the right point,

00:16:42.440 --> 00:16:46.430
so today we do have ECC memory
because memory errors actually

00:16:46.430 --> 00:16:50.800
are, in today's
lithography, are even more

00:16:50.800 --> 00:16:52.230
common than they used to be.

00:16:52.230 --> 00:16:53.700
So we absolutely
want to have it.

00:16:53.700 --> 00:16:56.700
But still, do we actually have
memory errors that even ECC two

00:16:56.700 --> 00:17:00.070
bit ECC correction,
does not detect?

00:17:00.070 --> 00:17:01.020
The answer is yes.

00:17:01.020 --> 00:17:02.228
At scale you're going to see.

00:17:02.228 --> 00:17:04.109
I haven't done the
computation recently,

00:17:04.109 --> 00:17:07.319
but I'm sure we see it at least
every week, probably every day,

00:17:07.319 --> 00:17:10.050
just based on the amount
of RAM that we do have.

00:17:10.050 --> 00:17:10.869
JEFF DEAN: It's coordinated
with the solar flares.

00:17:10.869 --> 00:17:12.079
URS HOLZLE: Exactly right.

00:17:12.079 --> 00:17:15.650
Alpha ray, Alpha particles,
and so on and so on.

00:17:15.650 --> 00:17:18.670
You have to go deal with it,
and have enough resilience

00:17:18.670 --> 00:17:22.760
so that you can
actually still move on.

00:17:22.760 --> 00:17:25.940
FRED SAUER: So the way I
read this and summarize

00:17:25.940 --> 00:17:28.790
it is being on the Cloud
platform insulates me

00:17:28.790 --> 00:17:30.600
from solar flares.

00:17:30.600 --> 00:17:31.850
JEFF DEAN: Among other things.

00:17:31.850 --> 00:17:32.550
FRED SAUER: Among other things.

00:17:32.550 --> 00:17:33.380
URS HOLZLE: Hopefully yes.

00:17:33.380 --> 00:17:33.900
Yes.

00:17:33.900 --> 00:17:35.270
Hopefully yes.

00:17:35.270 --> 00:17:39.490
We really hope that we can
expose some of these things

00:17:39.490 --> 00:17:42.340
that we learned as tools
that make it easier for all

00:17:42.340 --> 00:17:44.590
of you to build applications,
and not actually have

00:17:44.590 --> 00:17:48.350
to understand how to deal with
failure because as long as you

00:17:48.350 --> 00:17:51.270
follow these simple
rules, you will be fine.

00:17:51.270 --> 00:17:53.390
That's the ideal situation.

00:17:53.390 --> 00:17:56.860
Today we have realized
that in App Engine,

00:17:56.860 --> 00:17:58.560
and on the VM side
to a smaller extent,

00:17:58.560 --> 00:18:00.460
we've realized it
with the VM migration

00:18:00.460 --> 00:18:02.960
where we're able to move you
away from something that we see

00:18:02.960 --> 00:18:05.840
coming, and you don't know
that this even happened,

00:18:05.840 --> 00:18:09.720
but we can do a lot
more in that area.

00:18:09.720 --> 00:18:10.690
FRED SAUER: OK.

00:18:10.690 --> 00:18:14.760
So Jeff, when you were
building the first iterations

00:18:14.760 --> 00:18:21.650
of these distributed systems
14 and 1/2 years ago,

00:18:21.650 --> 00:18:24.740
did you realize when you were
trying to make the engineering

00:18:24.740 --> 00:18:29.340
trade offs in dealing
with failures,

00:18:29.340 --> 00:18:33.780
providing availability for
systems, and consistency,

00:18:33.780 --> 00:18:37.220
did you realize at the time that
it was essentially those three

00:18:37.220 --> 00:18:39.955
components, the cap theorem,
consistency, availability,

00:18:39.955 --> 00:18:43.540
and partitioning,
that we're really

00:18:43.540 --> 00:18:45.627
underlying the
engineering decisions?

00:18:45.627 --> 00:18:47.210
URS HOLZLE: Just to
interrupt, I think

00:18:47.210 --> 00:18:49.810
it's called Brewer's theorem.

00:18:49.810 --> 00:18:51.620
At least that's how
I like to call it.

00:18:51.620 --> 00:18:52.370
JEFF DEAN: Really?

00:18:52.370 --> 00:18:53.530
I always call it
the cap theorem.

00:18:53.530 --> 00:18:54.650
URS HOLZLE: No, its
Brewer's theorem.

00:18:54.650 --> 00:18:55.670
ERIC BREWER: I think
I know this one.

00:18:55.670 --> 00:18:56.015
URS HOLZLE: I think
you're thinking

00:18:56.015 --> 00:18:57.589
too much about cats I think.

00:18:57.589 --> 00:18:58.380
JEFF DEAN: No, cap.

00:18:58.380 --> 00:19:00.000
ERIC BREWER: I think
I know this one.

00:19:00.000 --> 00:19:00.320
JEFF DEAN: All right.

00:19:00.320 --> 00:19:01.260
ERIC BREWER: May I join you?

00:19:01.260 --> 00:19:01.510
JEFF DEAN: Yeah.

00:19:01.510 --> 00:19:02.010
Please.

00:19:02.010 --> 00:19:04.729
URS HOLZLE: Everyone
please welcome Eric Brewer.

00:19:04.729 --> 00:19:08.110
[APPLAUSE]

00:19:08.110 --> 00:19:10.592
JEFF DEAN: What a surprise.

00:19:10.592 --> 00:19:12.050
ERIC BREWER: Good
to see you again.

00:19:12.050 --> 00:19:14.000
FRED SAUER: Eric, thank
you for joining us.

00:19:14.000 --> 00:19:14.760
ERIC BREWER: My pleasure.

00:19:14.760 --> 00:19:16.590
FRED SAUER: So you noticed that
we had the three person couch,

00:19:16.590 --> 00:19:18.580
so obviously we
needed a third guest.

00:19:18.580 --> 00:19:19.960
ERIC BREWER: Saw that coming.

00:19:19.960 --> 00:19:22.670
FRED SAUER: So if
you don't know Eric,

00:19:22.670 --> 00:19:25.160
he devised the cap theorem,
or Brewer's theorem,

00:19:25.160 --> 00:19:27.430
we'll let him answer that
question in a moment.

00:19:27.430 --> 00:19:31.255
He's a professor at UC
Berkeley of computer science.

00:19:31.255 --> 00:19:34.310
A pioneer really in building
large scale systems,

00:19:34.310 --> 00:19:38.910
built the first really useful
cluster for web infrastructure.

00:19:38.910 --> 00:19:42.310
And can you tell
us, do you prefer

00:19:42.310 --> 00:19:44.640
cap theorem or Brewer's theorem.

00:19:44.640 --> 00:19:46.900
ERIC BREWER: Actually
I prefer cap theorem

00:19:46.900 --> 00:19:48.504
because it sounds
bad coming from me

00:19:48.504 --> 00:19:49.670
to call it Brewer's theorem.

00:19:49.670 --> 00:19:50.120
URS HOLZLE: OK.

00:19:50.120 --> 00:19:51.025
ERIC BREWER: You can call
it whatever you like,

00:19:51.025 --> 00:19:52.790
but I'm always going
to call it cap theorem.

00:19:52.790 --> 00:19:54.280
URS HOLZLE: I'll cal
it Brewer's theorem.

00:19:54.280 --> 00:19:55.542
ERIC BREWER: That's all right.

00:19:55.542 --> 00:19:57.805
I don't mind.

00:19:57.805 --> 00:19:59.180
FRED SAUER: Can
you maybe tell us

00:19:59.180 --> 00:20:01.620
a little bit about cap theorem?

00:20:01.620 --> 00:20:04.880
I think sometimes it's
explained incorrectly as a two

00:20:04.880 --> 00:20:06.820
our of three choice.

00:20:06.820 --> 00:20:08.535
ERIC BREWER: Well,
I think in 2000,

00:20:08.535 --> 00:20:11.410
or really when I first
thought about it, it was 1998,

00:20:11.410 --> 00:20:13.790
it was a two out of
three choice in the sense

00:20:13.790 --> 00:20:17.150
that we were in an era where
everyone wanted ACID properties

00:20:17.150 --> 00:20:19.120
and wanted us to
build, literally,

00:20:19.120 --> 00:20:22.115
cross national systems
that had both availability

00:20:22.115 --> 00:20:24.080
and consistency.

00:20:24.080 --> 00:20:27.210
I realized that we weren't
going to be able to do it,

00:20:27.210 --> 00:20:29.040
but also that we were
regularly choosing

00:20:29.040 --> 00:20:31.894
availability over consistency.

00:20:31.894 --> 00:20:34.060
People didn't accept that
that was the choice that I

00:20:34.060 --> 00:20:35.476
had to make, so
they were actually

00:20:35.476 --> 00:20:39.180
very reticent to say
that's an OK choice.

00:20:39.180 --> 00:20:42.200
So cap theorem, in some
sense, was to give everyone,

00:20:42.200 --> 00:20:46.150
myself included, permission
to choose availability.

00:20:46.150 --> 00:20:47.560
And now that's what happened.

00:20:47.560 --> 00:20:49.880
People like Jeff chose
availability for BigTable,

00:20:49.880 --> 00:20:52.001
and many others have as well.

00:20:52.001 --> 00:20:53.500
I think it's because
the internet is

00:20:53.500 --> 00:20:57.539
the first time we've
had a 24 by 7 service,

00:20:57.539 --> 00:21:00.080
except maybe the phone system
which isn't really data system,

00:21:00.080 --> 00:21:02.370
it's a communications
system, where you actually

00:21:02.370 --> 00:21:05.669
had both data and availability
that you wanted to get.

00:21:05.669 --> 00:21:07.960
So we had to start making
some difficult choices, which

00:21:07.960 --> 00:21:10.630
we still make actually.

00:21:10.630 --> 00:21:12.590
FRED SAUER: So in
addition to cap theorem,

00:21:12.590 --> 00:21:17.600
you've also looked at the
origins of a SQL and NoSQL

00:21:17.600 --> 00:21:18.570
databases.

00:21:18.570 --> 00:21:22.070
And on the Cloud platform you
can get a Managed SQL service,

00:21:22.070 --> 00:21:25.490
managed NoSQL service, but
you can also run your own.

00:21:25.490 --> 00:21:28.230
If you do VMs you
can spin up Cassandra

00:21:28.230 --> 00:21:32.600
and you have your own flavor
of a large NoSQL system.

00:21:32.600 --> 00:21:35.830
How should developers think
about those trade offs

00:21:35.830 --> 00:21:39.650
and how they select
one over the other?

00:21:39.650 --> 00:21:41.400
ERIC BREWER: I actually
try not to choose.

00:21:41.400 --> 00:21:43.800
I just told you,
you have to choose.

00:21:43.800 --> 00:21:46.107
You only have to
choose if you are

00:21:46.107 --> 00:21:47.690
going to have our
partitions, and only

00:21:47.690 --> 00:21:49.960
during the small amount of
time where you have partitions.

00:21:49.960 --> 00:21:51.501
The rest of the time
you can actually

00:21:51.501 --> 00:21:52.774
mix them much more gracefully.

00:21:52.774 --> 00:21:54.440
I would say we've
already built systems,

00:21:54.440 --> 00:21:56.330
and certainly talked
about some, like Spanner

00:21:56.330 --> 00:21:58.769
that Jeff worked on,
where you can set it

00:21:58.769 --> 00:22:01.060
in a more consistent setting
or more of an availability

00:22:01.060 --> 00:22:02.685
setting, and you can
make those choices

00:22:02.685 --> 00:22:04.317
on a relatively fine grain.

00:22:04.317 --> 00:22:06.150
If you know you want
partitions, like you're

00:22:06.150 --> 00:22:09.820
doing mobile phones or
disconnected operations

00:22:09.820 --> 00:22:12.747
and you really are going to
have truly concurrent operations

00:22:12.747 --> 00:22:14.580
on both sides of
partitions, then you really

00:22:14.580 --> 00:22:17.022
have to plan around that and
think about your merging.

00:22:17.022 --> 00:22:19.480
Otherwise, I think you can be
a bit more graceful about it.

00:22:19.480 --> 00:22:22.050
At least that's
the modern answer.

00:22:22.050 --> 00:22:24.599
FRED SAUER: So you can have
all three legs of the stool,

00:22:24.599 --> 00:22:26.557
but just not all at the
same time all the time.

00:22:26.557 --> 00:22:28.432
ERIC BREWER: You have
to play with them a bit

00:22:28.432 --> 00:22:29.856
more gracefully.

00:22:29.856 --> 00:22:30.480
FRED SAUER: OK.

00:22:30.480 --> 00:22:34.910
So Jeff, if you've been
building many generations

00:22:34.910 --> 00:22:39.396
of these storage
systems, maybe you

00:22:39.396 --> 00:22:41.360
can talk about the
problems you were working

00:22:41.360 --> 00:22:46.440
on when you developed
BigTable and MapReduce.

00:22:46.440 --> 00:22:50.310
What were the fundamental
big data problems?

00:22:50.310 --> 00:22:53.660
JEFF DEAN: So
MapReduce originated

00:22:53.660 --> 00:22:55.260
when my colleague
Sanjay Ghemawat

00:22:55.260 --> 00:22:59.290
and I were working on
rewriting the core indexing

00:22:59.290 --> 00:23:04.220
system for web search at Google.

00:23:04.220 --> 00:23:07.160
The pipeline, at that
time, goes from a bunch

00:23:07.160 --> 00:23:09.800
of raw pages on disk that
our crawler has collected,

00:23:09.800 --> 00:23:11.340
sitting in a bunch of files.

00:23:11.340 --> 00:23:12.910
And you have a
bunch of stages that

00:23:12.910 --> 00:23:15.110
are trying to transform
it and do things

00:23:15.110 --> 00:23:17.990
like find duplicates and choose
which one of the duplicates

00:23:17.990 --> 00:23:20.080
you want to because
it has a prettier URL,

00:23:20.080 --> 00:23:24.040
compute page rank,
decide which pages

00:23:24.040 --> 00:23:26.824
we're going to put in the index,
what languages they're all in.

00:23:26.824 --> 00:23:28.240
So there's all
these little phases

00:23:28.240 --> 00:23:30.990
that, conceptually, are
doing pretty simple things.

00:23:30.990 --> 00:23:33.120
But the code had gotten
really complicated

00:23:33.120 --> 00:23:37.920
because in each of those phases,
we rolled our own parallelism

00:23:37.920 --> 00:23:39.232
for the that phase.

00:23:39.232 --> 00:23:40.940
We'd say, well, this
one runs pretty fast

00:23:40.940 --> 00:23:43.340
so we need to use a
couple hundred machines.

00:23:43.340 --> 00:23:46.510
This one's slow so 1,000
machines would be better.

00:23:46.510 --> 00:23:48.080
Each one of them
had its own check

00:23:48.080 --> 00:23:49.814
pointing mechanism
and recovery mechanism

00:23:49.814 --> 00:23:51.105
for that to deal with failures.

00:23:51.105 --> 00:23:53.188
Because when you're running
on that many machines,

00:23:53.188 --> 00:23:55.445
you have failures.

00:23:55.445 --> 00:23:58.320
And so what got lost in
there was actually the fact

00:23:58.320 --> 00:24:00.210
that all these operations
were relatively

00:24:00.210 --> 00:24:01.990
simple and
straightforward, and they

00:24:01.990 --> 00:24:05.460
were obscured by all
this nasty support code.

00:24:05.460 --> 00:24:08.780
So Sanjay started squinting
at each of the phases looking

00:24:08.780 --> 00:24:12.110
for abstractions that
we felt could represent

00:24:12.110 --> 00:24:15.340
all the simple computation
we were trying to do in a way

00:24:15.340 --> 00:24:17.800
that we could then hide all
the complexity of dealing

00:24:17.800 --> 00:24:20.360
with failures, and
automatically parallelizing

00:24:20.360 --> 00:24:22.800
across an appropriate
number of machines,

00:24:22.800 --> 00:24:26.790
and dealing with slow
machines in a library.

00:24:26.790 --> 00:24:28.530
So MapReduce is what
we came up with.

00:24:28.530 --> 00:24:31.162
We both have
backgrounds in looking

00:24:31.162 --> 00:24:32.620
at different
programming languages,

00:24:32.620 --> 00:24:34.360
and the functional
programming paradigm

00:24:34.360 --> 00:24:35.640
is a pretty useful one.

00:24:35.640 --> 00:24:40.530
So MapReduce builds, at
least loosely, on that.

00:24:40.530 --> 00:24:44.740
So we realized that all the
phases in the indexing system

00:24:44.740 --> 00:24:48.320
could be represented
in this abstraction,

00:24:48.320 --> 00:24:51.570
and then we could work hard on
making that one library perform

00:24:51.570 --> 00:24:52.930
really well.

00:24:52.930 --> 00:24:56.470
So that's the
origin of MapReduce.

00:24:56.470 --> 00:24:59.490
The origin of BigTable is
similar in that we wanted

00:24:59.490 --> 00:25:01.277
to have an incrementally
updating system

00:25:01.277 --> 00:25:02.610
for all of our indexing systems.

00:25:02.610 --> 00:25:06.090
We wanted to have a row of data
for every page we know about

00:25:06.090 --> 00:25:07.590
and then have
different columns that

00:25:07.590 --> 00:25:08.950
are being
asynchronously updated.

00:25:08.950 --> 00:25:11.241
So the crawler would go off
and fetch contents and then

00:25:11.241 --> 00:25:14.980
write the actual current
contents into one of the cells,

00:25:14.980 --> 00:25:16.730
and then there would
be other asynchronous

00:25:16.730 --> 00:25:19.131
processes updating things
like what language we thing

00:25:19.131 --> 00:25:21.010
that page is, all the
different phases we use

00:25:21.010 --> 00:25:24.270
to run in a pipeline would
now run asynchronously,

00:25:24.270 --> 00:25:26.810
then we'd always have the
current state of this page

00:25:26.810 --> 00:25:28.500
by just looking at that route.

00:25:28.500 --> 00:25:31.899
We needed to scale that out to
a very large number of machines

00:25:31.899 --> 00:25:33.440
to be able to deal
with all the pages

00:25:33.440 --> 00:25:35.015
that we wanted to represent.

00:25:35.015 --> 00:25:35.640
FRED SAUER: OK.

00:25:35.640 --> 00:25:40.750
And then how did that
lead then to Spanner?

00:25:40.750 --> 00:25:42.710
What subsequent
problems were you

00:25:42.710 --> 00:25:44.750
solving that BigTable
didn't address?

00:25:44.750 --> 00:25:47.320
JEFF DEAN: So the first
version of BigTable

00:25:47.320 --> 00:25:49.710
essentially ran
within one cluster,

00:25:49.710 --> 00:25:51.270
within a single data center.

00:25:51.270 --> 00:25:54.380
And then over time
we added some support

00:25:54.380 --> 00:25:59.290
for eventual consistency to
have more interactive services

00:25:59.290 --> 00:26:02.490
where you wanted to keep a bunch
of geographically distributed

00:26:02.490 --> 00:26:05.480
versions of the data in sync.

00:26:05.480 --> 00:26:08.730
But that was
somewhat unsatisfying

00:26:08.730 --> 00:26:12.360
because you actually want all of
the things that you mentioned.

00:26:12.360 --> 00:26:15.560
You want consistency
and availability.

00:26:15.560 --> 00:26:17.520
it's actually a
pain for developers

00:26:17.520 --> 00:26:20.900
to deal with having 12
BigTable replicas of their data

00:26:20.900 --> 00:26:22.250
scattered around the world.

00:26:22.250 --> 00:26:26.020
So what's Spanner solves
that BigTable didn't really

00:26:26.020 --> 00:26:29.320
do is the problem of
geographic distribution of data

00:26:29.320 --> 00:26:33.750
across wide areas,
potentially, and also

00:26:33.750 --> 00:26:37.130
some flexibility in
allowing users to say,

00:26:37.130 --> 00:26:40.257
well this particular data I want
to keep two copies in Europe

00:26:40.257 --> 00:26:41.840
and three in the US
and I don't really

00:26:41.840 --> 00:26:45.404
care where I keep them, that's
just roughly where I want them.

00:26:45.404 --> 00:26:47.070
That gives the
underlying system freedom

00:26:47.070 --> 00:26:52.382
to move data around in response
to changing patterns of demand,

00:26:52.382 --> 00:26:56.390
and load, and disk availability
in our European data centers.

00:26:56.390 --> 00:26:59.660
And also, Spanner allows
users of the system

00:26:59.660 --> 00:27:03.660
to select the appropriate
consistency trade offs.

00:27:03.660 --> 00:27:06.670
For some operations you want
a strongly consistent view

00:27:06.670 --> 00:27:09.030
and you may pay for
it in availability.

00:27:09.030 --> 00:27:11.490
Other ones, if I
marketing an email message

00:27:11.490 --> 00:27:14.575
read or something, it's probably
fine to have an inconsistent

00:27:14.575 --> 00:27:16.112
view of that data.

00:27:16.112 --> 00:27:17.570
What's the worst
that could happen.

00:27:17.570 --> 00:27:20.400
So I think allowing
users to pick that trade

00:27:20.400 --> 00:27:22.520
off appropriately for
the different pieces

00:27:22.520 --> 00:27:25.930
of their application is one
important thing Spanner allows

00:27:25.930 --> 00:27:27.405
you to do.

00:27:27.405 --> 00:27:28.030
FRED SAUER: OK.

00:27:28.030 --> 00:27:31.292
So Eric, you joined Google
about two and 1/2 years ago?

00:27:31.292 --> 00:27:32.000
ERIC BREWER: Yes.

00:27:32.000 --> 00:27:35.370
FRED SAUER: And you're currently
on sabbatical from UC Berkeley,

00:27:35.370 --> 00:27:39.240
and you've had a chance
to look at innovation

00:27:39.240 --> 00:27:41.640
in the academic setting,
the commercial setting,

00:27:41.640 --> 00:27:44.890
and you've seen it
firsthand inside of Google.

00:27:44.890 --> 00:27:48.240
How would you compare the
way innovation happens?

00:27:48.240 --> 00:27:50.340
Is the pace different?

00:27:50.340 --> 00:27:52.940
What does it feel like
to be inside of Google

00:27:52.940 --> 00:27:54.294
and how does it compare?

00:27:54.294 --> 00:27:56.460
ERIC BREWER: Well when I
started in this area, which

00:27:56.460 --> 00:28:00.330
is almost 20 years ago, we had
a cluster of four machines,

00:28:00.330 --> 00:28:02.400
you could put it on a
disk, and that was actually

00:28:02.400 --> 00:28:04.736
enough to make progress
on cluster computing.

00:28:04.736 --> 00:28:06.110
You could actually
solve problems

00:28:06.110 --> 00:28:08.760
that were new with
four machines.

00:28:08.760 --> 00:28:13.710
And now we're at the
state where you really

00:28:13.710 --> 00:28:17.380
need many, many, many, many,
many more machines than that.

00:28:17.380 --> 00:28:19.670
So I feel like
Google is the place

00:28:19.670 --> 00:28:22.660
to be to have the problems
that I want to solve.

00:28:22.660 --> 00:28:25.540
They just aren't anywhere
else because of the scale,

00:28:25.540 --> 00:28:27.400
and because really of the goals.

00:28:27.400 --> 00:28:29.920
It's an ambitious
place to be and I

00:28:29.920 --> 00:28:31.657
think I get a lot
of challenge out

00:28:31.657 --> 00:28:32.823
of that and great enjoyment.

00:28:37.069 --> 00:28:38.485
FRED SAUER: Is the
pace different?

00:28:38.485 --> 00:28:41.730
Of Innovation, is
it faster at Google?

00:28:41.730 --> 00:28:42.480
ERIC BREWER: Yeah.

00:28:42.480 --> 00:28:44.230
I mean, it's faster
in several dimensions.

00:28:44.230 --> 00:28:48.250
It's faster because you
have vastly more people.

00:28:48.250 --> 00:28:52.370
It's also faster because
there is an urgency.

00:28:52.370 --> 00:28:59.482
There's not much urgency
to Cloud computing in 1995.

00:28:59.482 --> 00:29:01.210
I remember we went
from 10 machines

00:29:01.210 --> 00:29:03.000
100, that was a big deal.

00:29:03.000 --> 00:29:03.750
Like woo.

00:29:03.750 --> 00:29:05.860
100 machines.

00:29:05.860 --> 00:29:07.630
JEFF DEAN: It's a factor of 10.

00:29:07.630 --> 00:29:08.380
ERIC BREWER: Yeah.

00:29:08.380 --> 00:29:12.080
It was a factor of 10 and things
broke, and we had to fix stuff.

00:29:12.080 --> 00:29:15.450
But it's definitely not the
breadth of stuff going on,

00:29:15.450 --> 00:29:19.860
and also not really
the same ambition.

00:29:19.860 --> 00:29:23.080
The time is more ambitious now,
and that's great for everybody.

00:29:23.080 --> 00:29:28.110
FRED SAUER: So it's the harder
problems bigger scale really

00:29:28.110 --> 00:29:29.060
that drives this.

00:29:29.060 --> 00:29:30.060
ERIC BREWER: Absolutely.

00:29:30.060 --> 00:29:32.005
URS HOLZLE: And actually
Fred, if I can add.

00:29:32.005 --> 00:29:33.750
Having been in
academia myself, I

00:29:33.750 --> 00:29:35.515
think one of the big
differences really,

00:29:35.515 --> 00:29:38.460
that today I think
academia struggles with,

00:29:38.460 --> 00:29:42.660
is that you may have the ideas,
but you don't have a good way

00:29:42.660 --> 00:29:44.250
to test them.

00:29:44.250 --> 00:29:46.680
And not just because you
lack the infrastructure,

00:29:46.680 --> 00:29:49.930
but you also need real
world applications

00:29:49.930 --> 00:29:51.780
to actually your thesis--

00:29:51.780 --> 00:29:53.600
ERIC BREWER: You
need users and data.

00:29:53.600 --> 00:29:55.880
URS HOLZLE: --whether
it really works.

00:29:55.880 --> 00:29:58.790
One of the great
things at Google

00:29:58.790 --> 00:30:03.050
is we're in a pretty good
place already because we've

00:30:03.050 --> 00:30:05.050
been working on it for
10 years, so the standard

00:30:05.050 --> 00:30:06.360
is relatively high.

00:30:06.360 --> 00:30:09.350
We have great people and we
have great problems to solve,

00:30:09.350 --> 00:30:15.780
and together that really
get's an acceleration factor.

00:30:15.780 --> 00:30:18.230
My favorite quote
from the last half

00:30:18.230 --> 00:30:21.410
year or so-- for those of
you, just a short digression

00:30:21.410 --> 00:30:22.540
into networking.

00:30:22.540 --> 00:30:23.800
Van Jacobson, maybe you know.

00:30:23.800 --> 00:30:26.210
If you know TCP, you
know Van Jacobson.

00:30:26.210 --> 00:30:29.430
He's at Google, he joined
us last spring or so.

00:30:29.430 --> 00:30:31.670
I talked to him in the
summer and he said, you know,

00:30:31.670 --> 00:30:34.470
I didn't expect it, but
in the last four months

00:30:34.470 --> 00:30:38.160
I've gotten more done than I
have in the past five years.

00:30:38.160 --> 00:30:41.060
And I said why.

00:30:41.060 --> 00:30:45.990
And the answer was, I can
actually test an idea,

00:30:45.990 --> 00:30:49.820
and I can test it very quickly,
and then the next day I

00:30:49.820 --> 00:30:52.450
know I was wrong, but
I have a better idea.

00:30:52.450 --> 00:30:53.365
So I can actually--

00:30:53.365 --> 00:30:54.820
[LAUGHTER]

00:30:54.820 --> 00:30:58.650
And before this took me
years to get to that point.

00:30:58.650 --> 00:31:01.890
And that's one of the
big opportunities I have.

00:31:01.890 --> 00:31:06.870
That's why I said before,
10 years from now we're not

00:31:06.870 --> 00:31:08.210
going to live in the same world.

00:31:08.210 --> 00:31:10.010
Things will profoundly
change because we

00:31:10.010 --> 00:31:13.050
can discover along the way
the things that we do right,

00:31:13.050 --> 00:31:16.450
and the things we do wrong, and
then think of better ways to,

00:31:16.450 --> 00:31:19.030
or more innovative
ways to do them wrong.

00:31:19.030 --> 00:31:21.900
But over time we get
them less and less wrong.

00:31:25.319 --> 00:31:27.360
FRED SAUER: Talking about
that pace of innovation

00:31:27.360 --> 00:31:28.390
in the future.

00:31:28.390 --> 00:31:32.530
I see Jeff, you wore
your Google Brain shirt.

00:31:32.530 --> 00:31:34.550
JEFF DEAN: My cerebellum
is folded though.

00:31:34.550 --> 00:31:35.120
ERIC BREWER: It's
supposed to be folded.

00:31:35.120 --> 00:31:36.745
FRED SAUER: I wanted
to ask about that.

00:31:36.745 --> 00:31:40.950
You wrote a blog post,
I think it was 2012,

00:31:40.950 --> 00:31:46.630
and you described what I'll just
call a very large cat detector.

00:31:46.630 --> 00:31:48.040
But there's a lot
more behind it.

00:31:48.040 --> 00:31:51.650
I wonder if you could talk a
little bit about the project,

00:31:51.650 --> 00:31:54.390
what you did in 2012,
and then maybe we

00:31:54.390 --> 00:31:56.640
can talk a little bit about
what's happened since then

00:31:56.640 --> 00:31:59.874
and what the benefits to other
Google products have been.

00:31:59.874 --> 00:32:00.540
JEFF DEAN: Sure.

00:32:00.540 --> 00:32:04.914
The last couple years I've
been working on-- I've

00:32:04.914 --> 00:32:06.580
switched gears a
little and have started

00:32:06.580 --> 00:32:09.090
to look into very large scale
machine learning systems.

00:32:09.090 --> 00:32:12.900
And in particular, systems
for framing very large neural

00:32:12.900 --> 00:32:16.020
nets and then using them
for a variety of problems.

00:32:16.020 --> 00:32:18.654
This project started because
Andrew Ng is a Stanford faculty

00:32:18.654 --> 00:32:22.620
member with expertise in this
field of machine learning

00:32:22.620 --> 00:32:25.170
and was spending a couple
days a week at Google,

00:32:25.170 --> 00:32:27.390
and he and I bumped into
each other in a kitchen.

00:32:27.390 --> 00:32:29.510
And he said, oh
yeah, I'm thinking

00:32:29.510 --> 00:32:32.725
of figuring out how to use
neural nets for things.

00:32:32.725 --> 00:32:34.266
And I said, oh, that
sounds like fun.

00:32:34.266 --> 00:32:35.820
I'd actually done
a undergrad thesis

00:32:35.820 --> 00:32:39.069
on parallel training of
[INAUDIBLE], a very long time

00:32:39.069 --> 00:32:39.610
ago actually.

00:32:44.900 --> 00:32:49.350
So he said, at small scales,
these kinds of approaches

00:32:49.350 --> 00:32:52.380
were showing pretty promising
results in perceptual tasks.

00:32:52.380 --> 00:32:55.900
Things like computer vision
and speech recognition.

00:32:55.900 --> 00:32:57.410
So I said, wow.

00:32:57.410 --> 00:32:59.430
That sounds like if we
just made them bigger,

00:32:59.430 --> 00:33:02.020
they'd get even better.

00:33:02.020 --> 00:33:03.479
So he and I and a
few other people

00:33:03.479 --> 00:33:05.270
started a form a little
project around this

00:33:05.270 --> 00:33:09.440
of how are we able-- can
we build systems that

00:33:09.440 --> 00:33:13.320
allow us to train very large
neural networks to accomplish

00:33:13.320 --> 00:33:15.270
interesting things.

00:33:15.270 --> 00:33:19.950
So one of the first experiments
we did was what's called

00:33:19.950 --> 00:33:22.960
unsupervised learning, where
you don't have the desired

00:33:22.960 --> 00:33:25.870
output of the model, you
just have a bunch of raw data

00:33:25.870 --> 00:33:28.100
and you want the
model to capture

00:33:28.100 --> 00:33:31.240
regularities and interesting
patterns that it observes.

00:33:31.240 --> 00:33:33.694
So the we did was
we took 10 million

00:33:33.694 --> 00:33:36.110
YouTube videos, one of the
benefits of having lots of data

00:33:36.110 --> 00:33:39.690
lying around, and we took one
frame from each one of them,

00:33:39.690 --> 00:33:42.690
so it's a random
sampling of video frames,

00:33:42.690 --> 00:33:46.480
and we put it through a model
where we essentially just tried

00:33:46.480 --> 00:33:49.290
to learn representations that
were good at reconstructing

00:33:49.290 --> 00:33:51.660
what the individual images were.

00:33:54.530 --> 00:33:57.760
The training was
done on 16,000 cores,

00:33:57.760 --> 00:33:59.560
and that's one of the
benefits of having

00:33:59.560 --> 00:34:02.010
these large scale
cloud platforms.

00:34:02.010 --> 00:34:05.390
That we can do those experiments
and get results more quickly.

00:34:05.390 --> 00:34:08.989
So getting back to Van's
point of being able to get

00:34:08.989 --> 00:34:11.800
results on your
experiment to figure out

00:34:11.800 --> 00:34:13.840
what the next thing is
that you want to do.

00:34:13.840 --> 00:34:17.489
Being able to run that on
16,000 cores instead of 1,000

00:34:17.489 --> 00:34:20.260
is not necessarily as efficient
as doing it on 1,000 in terms

00:34:20.260 --> 00:34:24.360
of actual dollars, but it
lets us get our results

00:34:24.360 --> 00:34:28.170
more quickly so
we're more effect.

00:34:28.170 --> 00:34:31.110
Anyway, we trained this model
in a completely unsupervised

00:34:31.110 --> 00:34:33.757
manner, and then
we looked around

00:34:33.757 --> 00:34:35.840
at what the highest layers
in this model-- so it's

00:34:35.840 --> 00:34:39.230
like a deep, 10
layer neural net.

00:34:39.230 --> 00:34:42.000
At the lowest layer,
the neurons learned

00:34:42.000 --> 00:34:44.350
to be responsive to very
primitive things like edges

00:34:44.350 --> 00:34:45.909
at different orientations.

00:34:45.909 --> 00:34:47.649
And then as you
go up, the neurons

00:34:47.649 --> 00:34:48.899
get a little more complicated.

00:34:48.899 --> 00:34:51.959
So they'll learn corners
or things like that.

00:34:51.959 --> 00:34:53.500
As you get a little
further up you'll

00:34:53.500 --> 00:34:57.290
get pieces of chair legs
and things like that.

00:34:57.290 --> 00:35:00.160
So we looked at the top layer,
at the very top of this model,

00:35:00.160 --> 00:35:05.299
there are 60,000 neurons, and
then we had a test data set.

00:35:05.299 --> 00:35:07.340
It's YouTube, so we said,
there's got to be cats.

00:35:07.340 --> 00:35:11.440
So we took a test data set that
was half cats and half not,

00:35:11.440 --> 00:35:13.720
and we knew those,
and we looked around

00:35:13.720 --> 00:35:16.610
for a neuron that was most
sensitive to whether or not

00:35:16.610 --> 00:35:18.030
the image contained a cat.

00:35:18.030 --> 00:35:20.292
And if you can just skip ahead.

00:35:20.292 --> 00:35:22.040
So we looked, and
we found a neuron

00:35:22.040 --> 00:35:24.360
that was actually
pretty responsive.

00:35:24.360 --> 00:35:27.750
These were the images that
caused that particular neuron

00:35:27.750 --> 00:35:29.730
to get the most excited.

00:35:29.730 --> 00:35:31.320
And you see they're mostly cats.

00:35:31.320 --> 00:35:33.630
There's one Starbucks mug
there, but mostly cats.

00:35:37.370 --> 00:35:40.576
If you can see this, this is
actually the representation

00:35:40.576 --> 00:35:42.200
of the optimal
stimulus, the thing that

00:35:42.200 --> 00:35:45.480
would cause that neuron
to get the most excited.

00:35:45.480 --> 00:35:48.100
That's actually a cat.

00:35:48.100 --> 00:35:49.760
It's pretty cool.

00:35:49.760 --> 00:35:50.960
We call it average cat.

00:35:54.184 --> 00:35:55.600
ERIC BREWER: It
was the house cat.

00:35:55.600 --> 00:35:57.475
JEFF DEAN: By just
training on a lot of data,

00:35:57.475 --> 00:36:00.270
this model has essentially
invented the concept of a cat

00:36:00.270 --> 00:36:03.030
without ever being
told what a cat is.

00:36:03.030 --> 00:36:05.015
I think that's a pretty
fundamental thing.

00:36:05.015 --> 00:36:06.390
We looked around
at other neurons

00:36:06.390 --> 00:36:09.930
and found one that was receptive
to faces, and backs of people,

00:36:09.930 --> 00:36:12.850
and concepts that you
would expect these models

00:36:12.850 --> 00:36:15.090
represent from just looking
at a whole bunch images.

00:36:15.090 --> 00:36:16.840
FRED SAUER: I think
we have another slide.

00:36:16.840 --> 00:36:18.880
Let's look at this
next one here.

00:36:18.880 --> 00:36:19.580
JEFF DEAN: Yeah.

00:36:19.580 --> 00:36:21.750
Then we shifted gears
a bit and realized

00:36:21.750 --> 00:36:25.780
that, although this unsupervised
learning was incredibly cool,

00:36:25.780 --> 00:36:27.490
there's actually
more applied uses you

00:36:27.490 --> 00:36:29.679
can make if you have a
large, supervised data set.

00:36:29.679 --> 00:36:32.220
So you have a bunch of images
and you have a bunch of labels,

00:36:32.220 --> 00:36:34.390
so an image of a cheetah
and the label is cheetah,

00:36:34.390 --> 00:36:36.550
and a garbage truck,
garbage truck.

00:36:36.550 --> 00:36:38.810
If you can directly train
on that objective, where

00:36:38.810 --> 00:36:41.430
you want to give it an image
and then have it tell you

00:36:41.430 --> 00:36:45.132
what it is, supervised training
is actually pretty effective.

00:36:45.132 --> 00:36:47.590
Again, once we've done a little
bit of supervised training,

00:36:47.590 --> 00:36:49.850
we then looked at what
are the optimal stimuli

00:36:49.850 --> 00:36:54.190
for a few of the neurons at
the top layer of this model,

00:36:54.190 --> 00:36:58.970
and you see that some of them
are pretty good at succinctly

00:36:58.970 --> 00:37:02.570
finding things that we would,
as humans, know what they are.

00:37:02.570 --> 00:37:04.990
Like yellow flowers,
or wine bottles,

00:37:04.990 --> 00:37:08.430
or balsamic vinegar,
or pizza at the bottom.

00:37:08.430 --> 00:37:13.260
Some are a little more abstract,
they aren't a single succinct

00:37:13.260 --> 00:37:15.940
category, but they are things
like very textured, spotty

00:37:15.940 --> 00:37:17.970
objects.

00:37:17.970 --> 00:37:20.290
I think that's an
indication of what's

00:37:20.290 --> 00:37:21.777
going on in these models.

00:37:21.777 --> 00:37:22.485
It's interesting.

00:37:25.130 --> 00:37:29.100
FRED SAUER: So 16,000 cores,
probably 1,000 machines or so.

00:37:29.100 --> 00:37:31.550
JEFF DEAN: Yep.

00:37:31.550 --> 00:37:33.040
FRED SAUER: To detect a cat.

00:37:33.040 --> 00:37:35.990
So how many cores would
we need to represent

00:37:35.990 --> 00:37:38.600
the brain of a cat.

00:37:38.600 --> 00:37:42.716
JEFF DEAN: Well, I think those
kinds of comparisons are hard.

00:37:42.716 --> 00:37:44.090
I think have a
pretty good handle

00:37:44.090 --> 00:37:49.060
on how to do training
for categorization tasks,

00:37:49.060 --> 00:37:51.870
but the brain of a cat
is much more complex

00:37:51.870 --> 00:37:56.874
and has a lot of mechanisms that
we don't understand quite as

00:37:56.874 --> 00:37:58.540
well from a machine
learning standpoint,

00:37:58.540 --> 00:38:01.070
how to do feedback and control.

00:38:01.070 --> 00:38:02.849
But from a perceptual
view point,

00:38:02.849 --> 00:38:04.390
I think we're getting
a handle on how

00:38:04.390 --> 00:38:08.580
to train interesting systems
to do perceptual tasks pretty

00:38:08.580 --> 00:38:09.292
well.

00:38:09.292 --> 00:38:09.650
FRED SAUER: OK.

00:38:09.650 --> 00:38:11.358
JEFF DEAN: We actually
have a fair number

00:38:11.358 --> 00:38:13.170
of those perceptual
tasks at Google.

00:38:13.170 --> 00:38:15.930
Some of them are very general
things like this general object

00:38:15.930 --> 00:38:17.880
recognition, and some
are more fine grain.

00:38:17.880 --> 00:38:21.360
So the street view team, if you
can click to the next thing,

00:38:21.360 --> 00:38:25.100
wanted to be able to find text
in arbitrary street scenes.

00:38:25.100 --> 00:38:26.540
So with a little
bit of label data

00:38:26.540 --> 00:38:28.340
we had some people
draw bounding boxes

00:38:28.340 --> 00:38:30.495
around text in some scenes.

00:38:30.495 --> 00:38:33.220
You can actually see that this
model does a pretty good job

00:38:33.220 --> 00:38:36.740
of finding text in these scenes,
which is the precursor to them

00:38:36.740 --> 00:38:40.167
doing OCR of the world.

00:38:40.167 --> 00:38:42.750
I have one more example there,
it's just another street scene.

00:38:42.750 --> 00:38:44.370
But it's a pretty
challenging problem

00:38:44.370 --> 00:38:46.661
because you see there's all
kinds of things like logos,

00:38:46.661 --> 00:38:49.310
and different font
sizes, different fonts,

00:38:49.310 --> 00:38:50.750
different colors.

00:38:50.750 --> 00:38:53.540
But this model is actually able
to do this very effectively,

00:38:53.540 --> 00:38:55.580
and is doing it from raw pixels.

00:38:55.580 --> 00:38:57.210
You just feed in
raw images and it

00:38:57.210 --> 00:38:59.400
is able to give
you this nice heat

00:38:59.400 --> 00:39:01.400
map of where this text might be.

00:39:01.400 --> 00:39:04.120
We have other models that find
street signs or other kinds

00:39:04.120 --> 00:39:05.960
of interesting things
in these instances.

00:39:08.900 --> 00:39:11.670
FRED SAUER: Have there been
benefits to other Google

00:39:11.670 --> 00:39:13.670
projects from Google Brain?

00:39:13.670 --> 00:39:15.260
You mentioned voice recognition.

00:39:15.260 --> 00:39:16.624
Is that being used?

00:39:16.624 --> 00:39:17.290
JEFF DEAN: Yeah.

00:39:17.290 --> 00:39:19.840
So we've been
working with a whole,

00:39:19.840 --> 00:39:22.470
growing array of
different teams.

00:39:22.470 --> 00:39:26.740
We've had some very initial
close collaborations

00:39:26.740 --> 00:39:27.690
with different teams.

00:39:27.690 --> 00:39:29.270
So the speech team
was definitely

00:39:29.270 --> 00:39:32.590
one of those early clients
we worked closely with,

00:39:32.590 --> 00:39:36.700
to use our distributed training
system for problems they had.

00:39:36.700 --> 00:39:39.840
In particular, they
wanted to build and train

00:39:39.840 --> 00:39:42.430
very effective acoustic
models for speech recognition.

00:39:42.430 --> 00:39:44.580
So that's the first part
of speech recognition

00:39:44.580 --> 00:39:48.830
where you go from a
quarter second of raw wave

00:39:48.830 --> 00:39:52.730
forms of speech, to predicting
what is the sound being uttered

00:39:52.730 --> 00:39:53.980
in the middle 10 milliseconds.

00:39:53.980 --> 00:39:57.850
Is it a "buh" or a "fl" or
a "ss," that kind of thing.

00:39:57.850 --> 00:40:00.390
And then you stitch it
together with a language model

00:40:00.390 --> 00:40:03.776
to actually figure out
what the utterance is.

00:40:03.776 --> 00:40:05.400
Working with them we
were able to train

00:40:05.400 --> 00:40:08.210
a pretty big acoustic model
that was actually much more

00:40:08.210 --> 00:40:09.950
effective than the
previous kind of model

00:40:09.950 --> 00:40:11.290
they were using for this.

00:40:11.290 --> 00:40:13.400
And the word error rate
for English recognition

00:40:13.400 --> 00:40:14.340
dropped by 30%.

00:40:14.340 --> 00:40:15.220
FRED SAUER: Wow.

00:40:15.220 --> 00:40:17.132
JEFF DEAN: Which is
a really huge drop.

00:40:17.132 --> 00:40:18.465
ERIC BREWER: Unprecedented drop.

00:40:18.465 --> 00:40:19.715
JEFF DEAN: This is unheard of.

00:40:19.715 --> 00:40:20.420
Yeah.

00:40:20.420 --> 00:40:24.650
And a 30% drop goes
from not quite usable

00:40:24.650 --> 00:40:27.850
to actually quite usable
for a variety of tasks.

00:40:27.850 --> 00:40:29.470
We're continuing
to push on making

00:40:29.470 --> 00:40:31.825
the models bigger and better.

00:40:31.825 --> 00:40:33.200
Then a whole bunch
of other teams

00:40:33.200 --> 00:40:36.765
came to us after
they saw that success

00:40:36.765 --> 00:40:39.450
on speech and on some
of the image tasks.

00:40:39.450 --> 00:40:43.168
Now we have about 30 or 40
teams within Google applying

00:40:43.168 --> 00:40:45.168
these models to all kinds
of different problems.

00:40:47.914 --> 00:40:49.330
FRED SAUER: So the
neural networks

00:40:49.330 --> 00:40:52.630
that you've been working
with, the basic form thereof

00:40:52.630 --> 00:40:55.330
that they've been around
since the '80s, why is it

00:40:55.330 --> 00:40:59.150
that we're making progress now?

00:40:59.150 --> 00:41:00.150
JEFF DEAN: A few things.

00:41:00.150 --> 00:41:04.500
One is, as you said,
the basic ideas

00:41:04.500 --> 00:41:07.210
have been around
for about 20 years.

00:41:07.210 --> 00:41:09.740
20 years ago, there wasn't
enough computational power

00:41:09.740 --> 00:41:14.560
to train very large, and in
particular, very deep networks.

00:41:14.560 --> 00:41:17.230
So people were playing
around with neural nets that

00:41:17.230 --> 00:41:19.870
had maybe two or three
layers of abstraction

00:41:19.870 --> 00:41:23.130
in them, and on fairly
small data sets.

00:41:23.130 --> 00:41:24.940
So I think the big
difference is we now

00:41:24.940 --> 00:41:29.810
have enough computational
power, and big enough data sets,

00:41:29.810 --> 00:41:32.909
to really train
very large models

00:41:32.909 --> 00:41:35.200
and have enough computational
power that we can do that

00:41:35.200 --> 00:41:36.820
in a reasonable amount of time.

00:41:36.820 --> 00:41:41.100
We have what we call a patience
threshold of four or five days

00:41:41.100 --> 00:41:42.990
we're willing to wait
for a model train

00:41:42.990 --> 00:41:46.390
completely from scratch, and
maybe a day if we're really

00:41:46.390 --> 00:41:48.890
experimenting quickly.

00:41:48.890 --> 00:41:51.046
The reason we use lots
and lots of machines

00:41:51.046 --> 00:41:53.420
is because we want to train
the biggest model we possibly

00:41:53.420 --> 00:41:55.023
can in that patience threshold.

00:41:55.023 --> 00:41:55.790
FRED SAUER: OK.

00:41:55.790 --> 00:41:58.415
JEFF DEAN: And if we're able to
train a bigger model because we

00:41:58.415 --> 00:42:00.840
can parallelize things better,
or use machines, that's

00:42:00.840 --> 00:42:04.060
just gravy because we can then
train more effective models

00:42:04.060 --> 00:42:07.060
on larger data sets and so on.

00:42:07.060 --> 00:42:08.720
FRED SAUER: I'd
like to step it back

00:42:08.720 --> 00:42:11.630
into the data center world.

00:42:11.630 --> 00:42:16.490
So we've just talked about this
neural network, 16,000 cores.

00:42:16.490 --> 00:42:22.970
, That in Google scale is
probably a small scale system.

00:42:22.970 --> 00:42:27.150
When we talk to lower
level storage systems,

00:42:27.150 --> 00:42:28.720
they're much larger.

00:42:28.720 --> 00:42:32.185
How does your technical
infrastructure

00:42:32.185 --> 00:42:35.230
team deliver the network so
that all these machines can talk

00:42:35.230 --> 00:42:39.992
together, both globally
and within the data center?

00:42:39.992 --> 00:42:40.700
URS HOLZLE: Yeah.

00:42:40.700 --> 00:42:42.920
It's definitely an
interesting problem.

00:42:42.920 --> 00:42:45.330
And one of the nice
things is that it's

00:42:45.330 --> 00:42:47.370
kind of like having a child.

00:42:47.370 --> 00:42:51.470
It doesn't come with a
manual, but fortunately they

00:42:51.470 --> 00:42:53.230
grow up slowly so
you have some time

00:42:53.230 --> 00:42:54.780
to catch up with their demands.

00:42:54.780 --> 00:42:57.530
And that's been us with
networking, or compute,

00:42:57.530 --> 00:42:58.660
or storage.

00:42:58.660 --> 00:43:02.070
If we had the
problem from day one,

00:43:02.070 --> 00:43:04.640
then we would have been
pretty overwhelmed.

00:43:04.640 --> 00:43:07.170
So networking is
actually something

00:43:07.170 --> 00:43:10.470
that's become very important
in the last 10 or so years,

00:43:10.470 --> 00:43:12.450
and we've started
to do a lot of work

00:43:12.450 --> 00:43:15.700
because we got to the place,
just like with compute

00:43:15.700 --> 00:43:19.642
or with software systems, we
couldn't buy what we needed.

00:43:19.642 --> 00:43:20.850
There wasn't really a vendor.

00:43:20.850 --> 00:43:23.450
So it wasn't a question
of should we build or buy

00:43:23.450 --> 00:43:27.520
because which one is cheaper,
but really there is nothing out

00:43:27.520 --> 00:43:31.240
there that you can buy so you
have to actually build it.

00:43:31.240 --> 00:43:37.010
So one of the biggest
leaps we made recently,

00:43:37.010 --> 00:43:40.580
is to convert our-- Actually,
let me back up for one second.

00:43:40.580 --> 00:43:42.830
So we started building
networks obviously,

00:43:42.830 --> 00:43:47.000
both inside the cluster and
between all the data centers.

00:43:47.000 --> 00:43:50.930
So we've been owning Dark Fiber
and lighting our own optics

00:43:50.930 --> 00:43:53.370
et cetera for a long time
because at that scale you need

00:43:53.370 --> 00:43:56.230
to do that, both for
capacity and price reasons.

00:43:56.230 --> 00:43:58.900
But one of the biggest
steps that we made recently

00:43:58.900 --> 00:44:02.310
was to convert much of
our external backbone,

00:44:02.310 --> 00:44:04.800
so this is the
backbone that connects

00:44:04.800 --> 00:44:08.450
the different data
centers together, to run,

00:44:08.450 --> 00:44:16.820
not on traditional networking
protocols like BGP, and OSPF,

00:44:16.820 --> 00:44:20.180
and LSPs, and all
these things, MPLS,

00:44:20.180 --> 00:44:25.480
but on OpenFlow,
which is actually

00:44:25.480 --> 00:44:32.490
a very cluster-ish idea of
how to control networking

00:44:32.490 --> 00:44:36.790
where it basically takes
the same idea from cluster

00:44:36.790 --> 00:44:39.390
computing where you say, gee,
the individual nodes shouldn't

00:44:39.390 --> 00:44:40.950
really make decisions.

00:44:40.950 --> 00:44:43.340
Let's have a manager,
the nodes are dumb,

00:44:43.340 --> 00:44:48.230
they basically just a pool of
nodes, we tell them what to do.

00:44:48.230 --> 00:44:50.040
Rather than them
trying to communicate

00:44:50.040 --> 00:44:51.475
and figuring out what to do.

00:44:51.475 --> 00:44:53.680
So in networking, once
you have a certain scale,

00:44:53.680 --> 00:44:56.320
you actually want the elements,
the routers, the switches,

00:44:56.320 --> 00:44:58.650
to be relatively dumb
because they don't really

00:44:58.650 --> 00:45:01.330
understand what's
going worldwide.

00:45:01.330 --> 00:45:05.230
And OpenFlow, or software
defined networking in general,

00:45:05.230 --> 00:45:09.090
really brings that world much
closer to the software world.

00:45:09.090 --> 00:45:12.490
So now we have a
global network that we

00:45:12.490 --> 00:45:16.340
can control much better,
and at a much higher level,

00:45:16.340 --> 00:45:18.250
more at the application
level if you

00:45:18.250 --> 00:45:20.520
want more than at
the network level.

00:45:20.520 --> 00:45:23.950
So we can worry about,
hey, here's two Gmail cells

00:45:23.950 --> 00:45:25.730
that are talking to
each other, and not

00:45:25.730 --> 00:45:32.000
about here's port 1234 and some
QS class, and some IP ranges,

00:45:32.000 --> 00:45:33.910
and things that
are just brittle.

00:45:33.910 --> 00:45:38.750
So that has helped us a lot
in really pushing the envelope

00:45:38.750 --> 00:45:42.550
in terms of how fast we can grow
and how well we can control it.

00:45:42.550 --> 00:45:44.800
One of the biggest
advantages, and that's really

00:45:44.800 --> 00:45:48.790
what we've seen since the
'90s on the cluster side,

00:45:48.790 --> 00:45:53.220
is that once you move something
to be more software controlled,

00:45:53.220 --> 00:45:54.710
you can simulate it.

00:45:54.710 --> 00:45:57.390
And simulation means you
can do better testing.

00:45:57.390 --> 00:46:00.430
So one of the big reasons
why we're actually

00:46:00.430 --> 00:46:04.290
able to switch our
global backbone

00:46:04.290 --> 00:46:11.140
from traditional to a completely
new stack in about 15 months

00:46:11.140 --> 00:46:16.980
was that we couldn't
do that testing it

00:46:16.980 --> 00:46:18.660
on the real hardware
in the real world.

00:46:18.660 --> 00:46:19.840
That would be pretty risky.

00:46:19.840 --> 00:46:24.080
But we were able to build our
global network in software

00:46:24.080 --> 00:46:25.980
as an emulation,
so we could play

00:46:25.980 --> 00:46:27.750
through all kinds of
disaster scenarios.

00:46:27.750 --> 00:46:29.460
What happens if this
thing goes down?

00:46:29.460 --> 00:46:31.570
What if this thing
goes partially down?

00:46:31.570 --> 00:46:34.500
What if you lose this line?

00:46:34.500 --> 00:46:36.910
Does the software react
correctly et cetera?

00:46:36.910 --> 00:46:39.370
So if you can do the
software testing,

00:46:39.370 --> 00:46:43.290
really the whole unit
and integration testing,

00:46:43.290 --> 00:46:44.790
then you have much
higher confidence

00:46:44.790 --> 00:46:47.950
that when you actually try
it out, it will really work.

00:46:47.950 --> 00:46:50.010
And if it doesn't
work, you explain it

00:46:50.010 --> 00:46:51.290
in a much better way.

00:46:51.290 --> 00:46:54.410
Once you've figured it out, you
can add it to a regression test

00:46:54.410 --> 00:46:56.114
sweep and it won't happen again.

00:46:56.114 --> 00:46:58.280
We won't break it again
with a new software release.

00:46:58.280 --> 00:47:01.410
So in networking, I would say
that, really in the last 10

00:47:01.410 --> 00:47:03.410
years, has probably
been the biggest change.

00:47:03.410 --> 00:47:07.890
That now networks are becoming
much more Cloud friendly

00:47:07.890 --> 00:47:09.340
if you want, or
cluster friendly,

00:47:09.340 --> 00:47:12.400
because we can start to program
just like we could program

00:47:12.400 --> 00:47:16.200
the nodes in a data center
or the storage elements.

00:47:16.200 --> 00:47:18.070
And you can take
the big picture,

00:47:18.070 --> 00:47:21.200
how you want to orchestrate
things, and automatically

00:47:21.200 --> 00:47:24.250
translate it down into what the
network elements need to do.

00:47:24.250 --> 00:47:26.560
And your operator doesn't
need to do that anymore.

00:47:26.560 --> 00:47:28.980
That really is a huge change.

00:47:28.980 --> 00:47:31.340
We're still discovering
new opportunities

00:47:31.340 --> 00:47:34.620
of how that really percolates
through the entire stack.

00:47:34.620 --> 00:47:37.422
And you say, over here,
I used to do it this way

00:47:37.422 --> 00:47:38.880
but now there isn't
really a reason

00:47:38.880 --> 00:47:40.665
to do it this way
because now I can do it

00:47:40.665 --> 00:47:42.770
the easy way because
the network actually

00:47:42.770 --> 00:47:46.500
understands what I want to do.

00:47:46.500 --> 00:47:47.430
FRED SAUER: OK.

00:47:47.430 --> 00:47:51.630
We've a lot of
innovation and research.

00:47:51.630 --> 00:47:55.230
Jeff, I wonder if you could
talk about Google's philosophy

00:47:55.230 --> 00:47:56.990
between research
and engineering?

00:47:56.990 --> 00:47:59.880
How does Google make the
trade offs between two?

00:47:59.880 --> 00:48:04.221
How do you decide
which team you work on?

00:48:04.221 --> 00:48:05.720
JEFF DEAN: I think
one of the things

00:48:05.720 --> 00:48:07.570
that I really like
about Google is

00:48:07.570 --> 00:48:12.670
that we have this very
continuous, not hard boundary

00:48:12.670 --> 00:48:14.250
between research
and engineering.

00:48:14.250 --> 00:48:18.510
So I'm in engineering but I
work on longer term problems

00:48:18.510 --> 00:48:21.800
sometimes, and work on shorter
term things some of the time.

00:48:21.800 --> 00:48:25.530
Really you're not a
researcher or an engineer,

00:48:25.530 --> 00:48:27.950
you're working on
problems that fall

00:48:27.950 --> 00:48:30.290
on different parts
of this continuum.

00:48:30.290 --> 00:48:32.960
The same person might move
back and forth on this

00:48:32.960 --> 00:48:35.350
as they work on some
very long term thing

00:48:35.350 --> 00:48:39.330
and then gradually get it
closer to being ready to deploy

00:48:39.330 --> 00:48:41.980
to real users or whatever, then
you become a little bit more

00:48:41.980 --> 00:48:43.060
of an engineer hat.

00:48:43.060 --> 00:48:45.860
I think that's a
really valuable thing.

00:48:45.860 --> 00:48:49.200
So on our team we
have a bunch of people

00:48:49.200 --> 00:48:51.200
who are a little bit
more on the research

00:48:51.200 --> 00:48:53.080
end of the spectrum, a bunch
of people who are a little bit

00:48:53.080 --> 00:48:54.913
more on the engineering
end of the spectrum,

00:48:54.913 --> 00:48:57.240
and collectively
we can do things

00:48:57.240 --> 00:48:59.712
with complimentary skill sets.

00:48:59.712 --> 00:49:02.170
So there's a bunch of people
with a lot of machine learning

00:49:02.170 --> 00:49:05.490
expertise on the current
team I'm working on,

00:49:05.490 --> 00:49:08.260
and a bunch of people with
large scale distributive systems

00:49:08.260 --> 00:49:08.760
things.

00:49:08.760 --> 00:49:10.940
Collectively we're doing
things that none of us

00:49:10.940 --> 00:49:12.481
could do individually
because we just

00:49:12.481 --> 00:49:15.840
don't have the whole set
of skills in one person.

00:49:15.840 --> 00:49:16.942
I think that's really fun.

00:49:16.942 --> 00:49:18.400
Because you learn
a lot about that.

00:49:18.400 --> 00:49:20.860
You learn about
what are the trade

00:49:20.860 --> 00:49:24.480
offs of doing machine
learning algorithms at scale.

00:49:24.480 --> 00:49:26.220
I think that's a
really valuable thing

00:49:26.220 --> 00:49:28.450
to keep working on
interesting problems

00:49:28.450 --> 00:49:30.540
and learning a lot as you work.

00:49:30.540 --> 00:49:34.900
URS HOLZLE: And We've done that
very deliberately actually.

00:49:34.900 --> 00:49:37.940
You see that today in Cloud,
but you saw that in search

00:49:37.940 --> 00:49:39.620
10 years ago.

00:49:39.620 --> 00:49:43.550
When you have a problem
that is so early stage,

00:49:43.550 --> 00:49:45.100
and you can see the
ramp that really

00:49:45.100 --> 00:49:46.870
is going to change by
orders of magnitude,

00:49:46.870 --> 00:49:50.420
you can't incrementally engineer
the product to a better state.

00:49:50.420 --> 00:49:52.552
I mean yes, you do that,
of course you have to,

00:49:52.552 --> 00:49:54.760
but at the same time you
really have to fundamentally

00:49:54.760 --> 00:49:57.060
rethink things all
the time in order

00:49:57.060 --> 00:50:04.280
to have a chance of actually
keeping up, and hopefully even

00:50:04.280 --> 00:50:07.070
getting ahead
versus the problem.

00:50:07.070 --> 00:50:10.795
So research versus
engineer, it's almost not

00:50:10.795 --> 00:50:14.120
sensible to ask the question
how are they different.

00:50:14.120 --> 00:50:17.160
They're really different
facets of the same thing.

00:50:17.160 --> 00:50:18.654
If you don't really
tightly coupled

00:50:18.654 --> 00:50:20.320
that, you're going
to have research that

00:50:20.320 --> 00:50:23.120
is no longer
grounded in reality,

00:50:23.120 --> 00:50:26.230
or you're going to have people
that are too much grounded

00:50:26.230 --> 00:50:29.495
in reality who are just making
today's problem better, rather

00:50:29.495 --> 00:50:32.120
than recognizing that tomorrow's
problem is actually very, very

00:50:32.120 --> 00:50:34.590
different, and
requires something new,

00:50:34.590 --> 00:50:37.500
that is a departure from
what has served you well

00:50:37.500 --> 00:50:38.490
in the past.

00:50:38.490 --> 00:50:40.540
So we're trying to really
blend that all the time

00:50:40.540 --> 00:50:43.440
and give people some
freedom to do crazy things.

00:50:43.440 --> 00:50:46.730
Because what looks crazy
today might actually

00:50:46.730 --> 00:50:50.282
look obvious tomorrow, so
you have to balance that.

00:50:50.282 --> 00:50:52.615
ERIC BREWER: Actually a good
example that came up today,

00:50:52.615 --> 00:50:56.250
which is the demo that was
given this morning about doing

00:50:56.250 --> 00:50:58.280
live migration of
a video player,

00:50:58.280 --> 00:51:01.250
it's a demo I gave
internally about a year ago.

00:51:01.250 --> 00:51:05.320
That idea was in academia in
2003, but to get it right,

00:51:05.320 --> 00:51:08.491
and Google took a while, and to
convince people with something

00:51:08.491 --> 00:51:09.990
we want to bet on,
this is how we're

00:51:09.990 --> 00:51:11.810
going to run our
clusters, it actually

00:51:11.810 --> 00:51:15.090
takes internal consensus, ans
solving the whole problem,

00:51:15.090 --> 00:51:17.970
which you don't solve in
academia, it's a big problem,

00:51:17.970 --> 00:51:19.689
it has to work
for all the cases.

00:51:19.689 --> 00:51:21.980
Then you actually then get
people to take that actually

00:51:21.980 --> 00:51:23.355
to product, which
is [INAUDIBLE].

00:51:26.520 --> 00:51:28.730
FRED SAUER: So you talked
about building systems.

00:51:28.730 --> 00:51:32.565
When you built the
InktoMi search engine,

00:51:32.565 --> 00:51:36.840
you had to get your own gear
and get your own cage in a data

00:51:36.840 --> 00:51:37.340
center.

00:51:37.340 --> 00:51:38.990
You even shared
one next to Google.

00:51:38.990 --> 00:51:40.281
ERIC BREWER: We were neighbors.

00:51:40.281 --> 00:51:42.642
URS HOLZLE: I visited that cage.

00:51:42.642 --> 00:51:44.100
ERIC BREWER: They
sent heat my way.

00:51:44.100 --> 00:51:44.808
URS HOLZLE: Yeah.

00:51:44.808 --> 00:51:46.870
Yours looked much
cleaner than ours.

00:51:46.870 --> 00:51:47.970
[LAUGHTER]

00:51:47.970 --> 00:51:49.310
ERIC BREWER: But for the
record, modern Google cluster

00:51:49.310 --> 00:51:50.520
look more like InktoMi clusters.

00:51:50.520 --> 00:51:51.395
JEFF DEAN: It's true.

00:51:51.395 --> 00:51:52.020
It's true.

00:51:52.020 --> 00:51:56.920
We no longer bungee cord
our racks to the pipes.

00:51:56.920 --> 00:51:59.245
FRED SAUER: That's
more than 10 years ago.

00:51:59.245 --> 00:52:01.660
ERIC BREWER: Yes.

00:52:01.660 --> 00:52:04.980
FRED SAUER: If you were
doing it over again today,

00:52:04.980 --> 00:52:08.212
would you build InktoMi on
the Google Cloud platform?

00:52:08.212 --> 00:52:08.920
ERIC BREWER: Yes.

00:52:08.920 --> 00:52:11.045
I think that part is the
easy part of the question.

00:52:11.045 --> 00:52:13.910
Which is any start-up
shouldn't be investing

00:52:13.910 --> 00:52:15.770
in their own infrastructure.

00:52:15.770 --> 00:52:18.462
It's not the core
[INAUDIBLE], it's

00:52:18.462 --> 00:52:20.170
not fundamentally to
what you want to do.

00:52:20.170 --> 00:52:22.628
I think the harder question,
which I think you can uniquely

00:52:22.628 --> 00:52:26.960
answer now, is when
InktoMi got to a size

00:52:26.960 --> 00:52:30.320
where it could afford to
build it's own data center

00:52:30.320 --> 00:52:33.080
and have it's own machine,
should it or should it not?

00:52:33.080 --> 00:52:34.782
That's the harder question.

00:52:34.782 --> 00:52:36.240
Before today, the
answer would have

00:52:36.240 --> 00:52:39.610
been InktoMi should have because
there would be significant cost

00:52:39.610 --> 00:52:41.000
savings to do so.

00:52:41.000 --> 00:52:44.240
But if Google is wiling to
provide virtual hardware

00:52:44.240 --> 00:52:47.430
on the same Moore's Law cost
curve as the real hardware,

00:52:47.430 --> 00:52:48.910
then there's no
reason to switch.

00:52:48.910 --> 00:52:51.160
And that's actually comforting
because it's a big pain

00:52:51.160 --> 00:52:52.744
to switch.

00:52:52.744 --> 00:52:54.620
That's new actually, new today.

00:53:00.652 --> 00:53:01.360
FRED SAUER: Jeff.

00:53:01.360 --> 00:53:03.380
Maybe not quite
a final question,

00:53:03.380 --> 00:53:06.610
but what problems are
you working on today?

00:53:06.610 --> 00:53:08.840
Is it still Google Brain?

00:53:08.840 --> 00:53:10.530
Is it an extension thereof?

00:53:10.530 --> 00:53:13.220
What are the future
problems that you're

00:53:13.220 --> 00:53:14.670
trying to solve now?

00:53:14.670 --> 00:53:16.180
JEFF DEAN: I think
one of the things

00:53:16.180 --> 00:53:20.190
that these neural nets
are able to do, is they're

00:53:20.190 --> 00:53:22.350
able to take very
raw forms of data

00:53:22.350 --> 00:53:26.360
and then automatically build
interesting, high level

00:53:26.360 --> 00:53:30.090
abstractions of that
data and give you things

00:53:30.090 --> 00:53:32.464
that you could learn from
that data automatically.

00:53:32.464 --> 00:53:34.630
So unlike a lot of other
machine learning techniques

00:53:34.630 --> 00:53:36.610
where you hand engineer
features you think

00:53:36.610 --> 00:53:39.540
are predictive of something
you ultimately care about,

00:53:39.540 --> 00:53:44.000
these systems can build
that automatic combination

00:53:44.000 --> 00:53:45.860
of interesting
features and discover

00:53:45.860 --> 00:53:48.400
what is actually interesting
is automatically.

00:53:52.700 --> 00:53:55.930
How can we package that up
and make that easier to use

00:53:55.930 --> 00:53:58.730
has been a question we've been
wrestling with within our group

00:53:58.730 --> 00:54:01.240
as more teams within
Google try to use

00:54:01.240 --> 00:54:04.215
this for their own problems.

00:54:04.215 --> 00:54:06.780
We're making some
progress on that I think.

00:54:06.780 --> 00:54:08.600
FRED SAUER: Eric,
What problems are

00:54:08.600 --> 00:54:11.610
you trying to solve
right now for Google.

00:54:11.610 --> 00:54:14.455
ERIC BREWER: That's
the funny thing.

00:54:14.455 --> 00:54:16.240
I can't talk about it.

00:54:16.240 --> 00:54:17.670
I've been here
two and 1/2 years,

00:54:17.670 --> 00:54:20.830
and Urs mentioned before
that we, about two years ago,

00:54:20.830 --> 00:54:24.250
started making transitions
to what we want to build,

00:54:24.250 --> 00:54:27.170
a joint infrastructure for
internal use and external use.

00:54:27.170 --> 00:54:29.630
That's what I've been
working on for two years.

00:54:29.630 --> 00:54:33.800
You can see glimpses of
it, but frankly, the best

00:54:33.800 --> 00:54:34.945
is still to come.

00:54:34.945 --> 00:54:35.570
FRED SAUER: OK.

00:54:38.260 --> 00:54:40.314
Urs, maybe final
thoughts for today?

00:54:40.314 --> 00:54:41.730
URS HOLZLE: I think
Eric is trying

00:54:41.730 --> 00:54:44.975
to say we're solving problems
that you don't know you have.

00:54:44.975 --> 00:54:47.710
[LAUGHTER]

00:54:47.710 --> 00:54:50.640
No, but actually I
think Eric's pointing

00:54:50.640 --> 00:54:52.480
to something that's
pretty profound.

00:54:55.340 --> 00:54:57.370
Clearly where we are
today is very cool,

00:54:57.370 --> 00:54:59.610
and if you had asked me
10 years ago could we

00:54:59.610 --> 00:55:02.970
ever get to this kind of scale
and have it work this way

00:55:02.970 --> 00:55:09.350
and have it be available to
really everyone at this scale

00:55:09.350 --> 00:55:12.180
I would've said no,
it's probably unlikely.

00:55:12.180 --> 00:55:15.290
So to some extent really, it's
incredibly cool where we are.

00:55:15.290 --> 00:55:19.110
It's amazing when I look at
a picture like this, the fact

00:55:19.110 --> 00:55:22.420
that we can stamp these out,
and they work this well,

00:55:22.420 --> 00:55:28.270
and they're cost effective,
I'm sometimes surprised myself.

00:55:28.270 --> 00:55:30.060
But in the grand
scheme of things,

00:55:30.060 --> 00:55:32.390
I think we shouldn't
kid ourselves

00:55:32.390 --> 00:55:33.980
about having solved the problem.

00:55:33.980 --> 00:55:36.170
We haven't solved
the problem at all.

00:55:36.170 --> 00:55:40.430
In fact, were 2% in or so.

00:55:40.430 --> 00:55:43.980
So I think the most
amazing part to me

00:55:43.980 --> 00:55:47.340
is that I'm really
confident that if we look

00:55:47.340 --> 00:55:50.560
back 10, or even
five years from now,

00:55:50.560 --> 00:55:54.000
to where we are today, and the
things that we're proud of,

00:55:54.000 --> 00:55:57.100
whether that's recognizing
cats or handling petabytes,

00:55:57.100 --> 00:56:02.970
or something like that, we're
going to really be embarrassed

00:56:02.970 --> 00:56:04.630
because it's so lame.

00:56:04.630 --> 00:56:06.810
And five years, or
10 years from now,

00:56:06.810 --> 00:56:08.610
it really will be
obvious how lame

00:56:08.610 --> 00:56:11.740
it was even though it
seems amazing today

00:56:11.740 --> 00:56:15.150
because we're so
early in the cycle.

00:56:15.150 --> 00:56:18.770
We're just having,
literally in the last five

00:56:18.770 --> 00:56:24.160
years, the different elements
coming together, actually

00:56:24.160 --> 00:56:29.006
solving the whole availability,
partitioning, consistency.

00:56:29.006 --> 00:56:31.130
In Spanner for example,
it's a much better solution

00:56:31.130 --> 00:56:32.640
than we had earlier.

00:56:32.640 --> 00:56:35.010
MapReduce, we're not actually
using MapReduce anymore

00:56:35.010 --> 00:56:35.692
for new code.

00:56:35.692 --> 00:56:37.900
We have a new thing that's
called Flume that actually

00:56:37.900 --> 00:56:40.620
is an even more elegant way
of expressing these things.

00:56:40.620 --> 00:56:43.030
But just in the last
five years, we've

00:56:43.030 --> 00:56:45.920
had the hardware and
software pieces come together

00:56:45.920 --> 00:56:48.490
that are a good starting
point where you can go off

00:56:48.490 --> 00:56:53.140
into a Google Brain within a
pretty short amount of time.

00:56:53.140 --> 00:56:58.430
But if you take that
ability, then the innovation

00:56:58.430 --> 00:57:01.040
that happens everywhere
is based on that.

00:57:01.040 --> 00:57:03.320
I think we will really
see an acceleration,

00:57:03.320 --> 00:57:07.970
or an accelerated pace, of
discovery and innovation

00:57:07.970 --> 00:57:10.190
over the next five, 10 years.

00:57:10.190 --> 00:57:13.980
We all underestimate
how fast that will be.

00:57:13.980 --> 00:57:20.280
We realize that five years ago
we didn't have smart phones

00:57:20.280 --> 00:57:20.790
or whatever.

00:57:20.790 --> 00:57:23.020
But five years from
now, the smart phones

00:57:23.020 --> 00:57:26.680
are just going to be faster and
cheaper than they are today.

00:57:26.680 --> 00:57:27.367
No they're not.

00:57:27.367 --> 00:57:29.450
They're actually going to
be profoundly different.

00:57:29.450 --> 00:57:33.670
As profoundly different
as five years ago

00:57:33.670 --> 00:57:37.600
the T-mobile G1 was
compared to the Nexus 5.

00:57:37.600 --> 00:57:39.700
These are not the same thing.

00:57:39.700 --> 00:57:43.080
So the same thing is going
to be true for cloud.

00:57:43.080 --> 00:57:45.490
So when we sit here
five years from now,

00:57:45.490 --> 00:57:47.460
or 10 years from
now, I think we'll

00:57:47.460 --> 00:57:51.260
have some pained smiles
if you show us videos

00:57:51.260 --> 00:57:54.470
of this conversation today,
or of keynote this morning,

00:57:54.470 --> 00:57:59.160
and say, yeah, I guess given
the time this was cool,

00:57:59.160 --> 00:58:03.060
but today really, that's
what we were proud of?

00:58:03.060 --> 00:58:05.910
So to me, that's actually
the most exciting part

00:58:05.910 --> 00:58:07.000
about all of this.

00:58:07.000 --> 00:58:09.070
We really are just
at the beginning.

00:58:09.070 --> 00:58:11.680
Only 1% of the world
is in the cloud.

00:58:11.680 --> 00:58:15.840
I think the only 1% of the
Cloud's problems are solved.

00:58:15.840 --> 00:58:17.880
But I think 5, 10
years from now we're

00:58:17.880 --> 00:58:21.120
going to be well into the double
digits on both of these sides,

00:58:21.120 --> 00:58:23.500
and it's going to be a
very exciting time, for me

00:58:23.500 --> 00:58:26.050
as a computer scientist,
and I think for everyone

00:58:26.050 --> 00:58:28.520
as a developer to
be part of this.

00:58:28.520 --> 00:58:34.000
This could easily be the
time where decades from now

00:58:34.000 --> 00:58:36.740
you tell your grandchildren
or whatever, yeah, I remember.

00:58:36.740 --> 00:58:40.030
This was a time when
we went from Stone Age

00:58:40.030 --> 00:58:46.740
to pretty modern in computing,
in software systems,

00:58:46.740 --> 00:58:48.750
and I was there.

00:58:48.750 --> 00:58:50.680
Now realize how
important that was.

00:58:50.680 --> 00:58:52.530
So I hope that five
years from now you all

00:58:52.530 --> 00:58:54.680
agree with me on that.

00:58:54.680 --> 00:58:57.490
But I really think we're at the
beginning of something pretty

00:58:57.490 --> 00:59:00.740
big and something I'm more
excited about than I've

00:59:00.740 --> 00:59:02.140
been in a long time.

00:59:02.140 --> 00:59:02.890
FRED SAUER: Great.

00:59:02.890 --> 00:59:05.270
Thank you for that.

