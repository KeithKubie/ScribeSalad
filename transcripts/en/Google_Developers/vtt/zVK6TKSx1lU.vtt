WEBVTT
Kind: captions
Language: en

00:00:00.447 --> 00:00:02.280
So let's say you've got
some awesome Android

00:00:02.280 --> 00:00:04.506
game with hundreds of
thousands of downloads.

00:00:04.506 --> 00:00:06.880
But it seems like you can't
break that million-user mark.

00:00:06.880 --> 00:00:07.380
The reason?

00:00:07.380 --> 00:00:10.030
Users are unhappy with
your game's performance.

00:00:10.030 --> 00:00:11.970
You see, users notice
bad performance

00:00:11.970 --> 00:00:13.660
before any other
feature in your game--

00:00:13.660 --> 00:00:16.144
before your item stats;
or your UI interfaces;

00:00:16.144 --> 00:00:18.060
or how, on level three,
one of your characters

00:00:18.060 --> 00:00:19.610
is actually speaking Klingon.

00:00:19.610 --> 00:00:20.400
And guess what?

00:00:20.400 --> 00:00:22.770
Users unhappy with
performance give bad reviews

00:00:22.770 --> 00:00:25.249
at a higher percentage than
any other problem in your game.

00:00:25.249 --> 00:00:27.040
So you want to break
the million-user mark?

00:00:27.040 --> 00:00:29.780
You're going to have to fix
the perf problems in your game.

00:00:29.780 --> 00:00:31.240
And for modern
Android games, that

00:00:31.240 --> 00:00:33.823
starts with understanding that
there exists a delicate dance--

00:00:33.823 --> 00:00:36.920
a tango, if you will-- of
interaction between the CPU

00:00:36.920 --> 00:00:38.760
and GPU in your
game that can have

00:00:38.760 --> 00:00:40.830
a drastic impact on
your performance.

00:00:40.830 --> 00:00:43.040
And the dance works a
little something like this.

00:00:43.040 --> 00:00:46.200
Modern graphics APIs don't
allow the CPU to talk directly

00:00:46.200 --> 00:00:47.480
to the GPU hardware.

00:00:47.480 --> 00:00:49.250
Instead, it uses an
intermediate process

00:00:49.250 --> 00:00:51.190
known as a graphics
driver to handle

00:00:51.190 --> 00:00:52.670
communication between the two.

00:00:52.670 --> 00:00:54.410
Drawing calls from
the CPU are cached

00:00:54.410 --> 00:00:56.007
by the driver in
a message queue.

00:00:56.007 --> 00:00:57.840
And when the GPU hardware
is ready for work,

00:00:57.840 --> 00:01:00.131
it will start consuming
commands from the same resource

00:01:00.131 --> 00:01:01.766
and begin executing on them.

00:01:01.766 --> 00:01:04.099
The existence of the message
queue process in the driver

00:01:04.099 --> 00:01:06.062
means the CPU can
be pushing messages

00:01:06.062 --> 00:01:07.520
into the driver at
a different rate

00:01:07.520 --> 00:01:09.410
than the GPU is reading from it.

00:01:09.410 --> 00:01:12.350
And as such, your GPU can
be consuming, processing,

00:01:12.350 --> 00:01:14.500
and drawing data that's
around one to two frames

00:01:14.500 --> 00:01:15.800
behind the CPU.

00:01:15.800 --> 00:01:17.650
Now, while alarming,
don't worry.

00:01:17.650 --> 00:01:20.070
This is actually really
typical of modern hardware

00:01:20.070 --> 00:01:21.040
architectures.

00:01:21.040 --> 00:01:22.450
But with this in
mind, understand

00:01:22.450 --> 00:01:24.283
that hitting 60 frames
a second in your game

00:01:24.283 --> 00:01:27.040
requires both your CPU
frame and your GPU frame

00:01:27.040 --> 00:01:29.655
to both complete their work
in around 16 milliseconds.

00:01:29.655 --> 00:01:32.030
When either of these two
systems starts to go out of sync

00:01:32.030 --> 00:01:33.571
and take longer than
that, bad things

00:01:33.571 --> 00:01:34.990
happen to your frame rate.

00:01:34.990 --> 00:01:37.190
For example, what if
your GPU has more work

00:01:37.190 --> 00:01:38.420
to do then your CPU?

00:01:38.420 --> 00:01:40.890
This means that your CPU is
going to be submitting frames

00:01:40.890 --> 00:01:42.515
into the driver at
a faster frequency

00:01:42.515 --> 00:01:44.714
than the GPU is actually
going to be consuming them.

00:01:44.714 --> 00:01:46.880
Eventually, the driver queue
is going to get filled.

00:01:46.880 --> 00:01:49.640
And any time the CPU wants
to submit a driver call,

00:01:49.640 --> 00:01:51.409
it'll have to block,
wait for the GPU

00:01:51.409 --> 00:01:52.825
to clear up some
commands in order

00:01:52.825 --> 00:01:55.850
to free up space, at which
point the CPU can then carry on

00:01:55.850 --> 00:01:57.500
and submit its new commands.

00:01:57.500 --> 00:01:59.520
On the other hand,
if you're CPU-bound,

00:01:59.520 --> 00:02:02.030
then you're inserting bubbles
into your GPU pipeline.

00:02:02.030 --> 00:02:03.810
Every time the CPU
submits a frame,

00:02:03.810 --> 00:02:05.965
the GPU will consume it
immediately, process it,

00:02:05.965 --> 00:02:07.923
and sit around waiting
for the next frame where

00:02:07.923 --> 00:02:08.892
it can do work again.

00:02:08.892 --> 00:02:10.350
The straightforward
way to fix this

00:02:10.350 --> 00:02:12.950
is to simply do less
work on the CPU.

00:02:12.950 --> 00:02:14.980
But in this case, it may
be that the GPU simply

00:02:14.980 --> 00:02:17.313
doesn't have enough work to
do and the correct action is

00:02:17.313 --> 00:02:19.460
actually to give it
more work in order

00:02:19.460 --> 00:02:21.404
to fully maximize
the GPU throughput.

00:02:21.404 --> 00:02:22.820
There's a great
opportunity to put

00:02:22.820 --> 00:02:25.956
like 200 extra zombies on the
screen for your designers.

00:02:25.956 --> 00:02:28.330
You can get a general estimate
of where your problem lies

00:02:28.330 --> 00:02:30.890
by taking a good look at your
CPU frame time for a couple

00:02:30.890 --> 00:02:32.160
seconds of simulation.

00:02:32.160 --> 00:02:35.520
For example, if your CPU frame
time is around 16 milliseconds,

00:02:35.520 --> 00:02:37.190
then your game is
running pretty well.

00:02:37.190 --> 00:02:38.773
Now, while your goal
is to keep things

00:02:38.773 --> 00:02:41.700
under the 16-millisecond mark,
some frames, your CPU load

00:02:41.700 --> 00:02:45.090
changes and you expect
slight variances in the time.

00:02:45.090 --> 00:02:47.440
If, however, your frame time
starts to spike suddenly

00:02:47.440 --> 00:02:49.930
and your CPU computation load
hasn't changed-- you know,

00:02:49.930 --> 00:02:52.020
you haven't put 200
zombies on the screen--

00:02:52.020 --> 00:02:54.690
then there's a high probability
that this is due to the GPU

00:02:54.690 --> 00:02:56.800
getting backed up,
forcing your CPU

00:02:56.800 --> 00:02:58.340
time to stall in the driver.

00:02:58.340 --> 00:03:00.850
These tall spikes are actually
pretty telling since they're

00:03:00.850 --> 00:03:02.970
around 11 to 15
milliseconds of time, which

00:03:02.970 --> 00:03:06.180
would be exactly how long the
GPU would need to flush a frame

00:03:06.180 --> 00:03:07.080
or so.

00:03:07.080 --> 00:03:09.174
In order to figure out
what the culprit really is,

00:03:09.174 --> 00:03:10.840
it's time to sit down
and get proficient

00:03:10.840 --> 00:03:12.710
with mobile profiling tools.

00:03:12.710 --> 00:03:14.820
Some of the nuances
of the GPU performance

00:03:14.820 --> 00:03:17.000
require dedicated
tools to discover.

00:03:17.000 --> 00:03:19.770
But thankfully, each
Android chip manufacturer

00:03:19.770 --> 00:03:22.110
provides a great suite
of tools to give you

00:03:22.110 --> 00:03:23.700
more information
on how to optimize

00:03:23.700 --> 00:03:25.920
your game for their hardware.

00:03:25.920 --> 00:03:28.950
Understanding and optimizing the
dance between the CPU and GPU

00:03:28.950 --> 00:03:31.860
is the first step in maximizing
your game's performance, which,

00:03:31.860 --> 00:03:33.990
of course, results in
happier users, which

00:03:33.990 --> 00:03:36.030
could result in
better transactions.

00:03:36.030 --> 00:03:37.850
And that's the
whole point, right?

00:03:37.850 --> 00:03:40.060
So keep calm, profile
your code, and as always,

00:03:40.060 --> 00:03:42.450
remember perf matters.

