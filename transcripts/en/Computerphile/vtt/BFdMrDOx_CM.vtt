WEBVTT
Kind: captions
Language: en-GB

00:00:00.000 --> 00:00:02.760
Let's start talking about convolutional neural networks again

00:00:02.760 --> 00:00:05.540
A few people have been asking what does the convolutional layers look like

00:00:06.140 --> 00:00:12.720
So you know, what transformations are happening on these input images, that mean we can do something interesting in terms of machine learning.

00:00:13.060 --> 00:00:18.820
So, what I've done is that I've trained a pretty basic network to do digit recognition.

00:00:18.820 --> 00:00:24.600
And so we can see what the convolutions are doing, what the intermediate layers look like and then hopefully what the classification is at the end,

00:00:24.600 --> 00:00:25.940
so people can get a good idea.

00:00:28.600 --> 00:00:39.700
Let's start talking about MNIST, so MNIST is a dataset that has been around for a few years and was produced by Yann Lecun who is, I think, currently at Facebook

00:00:39.920 --> 00:00:42.560
and he's big in deep-learning

00:00:43.060 --> 00:00:45.800
and loads of good papers

00:00:45.800 --> 00:00:55.220
And one of its early efforts into convolutional networks was LeNet, is all what we call it,

00:00:55.480 --> 00:01:00.760
which was a sort of five layerish small convolutional neural network aimed doing this MNIST dataset

00:01:00.760 --> 00:01:06.180
and it basically said, look, this convolutional neural network is going to be really good on digit recognition,

00:01:06.180 --> 00:01:10.120
the current state of the art is all the machine learning techniques, and now we're even better than that.

00:01:10.700 --> 00:01:16.340
So what I've done is that I tweaked the LeNet model a bit to make it a little bit more interesting,

00:01:16.580 --> 00:01:22.640
and the I've basically printed out all the intermediate layers so we can see them on a few digits, so that you can see how it works

00:01:22.860 --> 00:01:24.540
So this is numbers when i say digits

00:01:24.540 --> 00:01:33.680
That's right, just the digits 0 to 9.
In fact, it's small, 28 pixels x 28 pixels images of any hand written digit 0 to 9.

00:01:33.860 --> 00:01:40.980
And there's about I think 90,000, or so, of them in the dataset, so there is about 10,000 to the testing and about 80,000 for trying it.

00:01:41.140 --> 00:01:49.540
The normal LeNet network is I think a convolutional layer, followed by a pooling
-- so that's the spatial downsampling layer --

00:01:49.540 --> 00:01:53.040
followed by another convolution, followed by another spatial downsampling, and all these kind of things.

00:01:53.040 --> 00:01:58.480
Now, the thing about spatial downsampling is it's useful in some situations but it's not very interesting to look at,

00:01:58.480 --> 00:02:01.420
because we're then looking at images which are very very small.

00:02:01.460 --> 00:02:05.500
So what I've done is that I've done away with that and I'm just putting lots more convolutional layers

00:02:05.500 --> 00:02:15.980
So my network is -- I think if I refer back to my... 1, 2, 3, 4, 5, 6... -- is 6 convolutional layers, apparently, according to my piece of paper.

00:02:16.520 --> 00:02:20.680
And then two fully connected artificial neural network layers at the end.

00:02:20.740 --> 00:02:27.280
So I'm gonna write these down, so we've got 1, 2, 3, 4, 5, 6 convolutional layers

00:02:27.280 --> 00:02:33.760
all of which have 5 by 5 kernels so this isn't the standard network, this is just one that I came over myself.

00:02:33.760 --> 00:02:41.140
On this digit recognition task, any reasonable network will probably do a pretty good job, you know, if you thought a little bit about it.

00:02:41.140 --> 00:02:48.140
Because it's just not, you know, digit recognition is not quite as hard as character recognition which in turn is not as hard as other problems and so on

00:02:48.140 --> 00:02:51.000
Is that just purely because there are less digits than there are characters ?

00:02:51.000 --> 00:02:53.700
Yeah, there is less, there is basically less variations between images.

00:02:53.700 --> 00:03:00.180
If you're, if you're taking lots of pictures of cats, and lot's of pictures of dogs, there is gonna to be more variation over the images and more pixels to deal with,

00:03:00.180 --> 00:03:06.320
than there is in a 28 by 28 picture that may have a 9 in it or it may have a slightly differently shaped 9, you know.

00:03:06.840 --> 00:03:13.660
And then I've got my fully connected layer so I'm gonna say FC1. I'm gonna got a fully connected layer here FC2.

00:03:13.820 --> 00:03:18.780
FC1 has an output size of 500, according to my piece of paper, I've forgotten already

00:03:19.060 --> 00:03:23.040
and FC2 has an output size of 10 which is the digits.

00:03:23.180 --> 00:03:26.360
Now if you think back to our last video on convolutional networks,

00:03:26.460 --> 00:03:32.100
after we've done all of convolutions, we have some fully connected layers which actually perform the classification.

00:03:32.280 --> 00:03:38.080
And the last fully connected layer is this case is going to be however long we have of different classes,

00:03:38.340 --> 00:03:41.940
so we have 10 classes 0 to all the way to 9, so 10 outputs,

00:03:41.980 --> 00:03:51.680
when output number 2 lights up or produces a high value, that means that digit 1, which is slightly confusing cause 0 indexed, but digit 1 has been recognized.

00:03:52.120 --> 00:03:53.260
Okay

00:03:53.820 --> 00:04:00.060
So I won't going to too much details about what effect each of these will have on the input image

00:04:00.060 --> 00:04:03.820
but you can imagine that if if you got a 28 by 28 image input

00:04:04.200 --> 00:04:11.200
then this first convolutional layout which is 5 by 5 is going to reduce the width of that and the height of that image by 4

00:04:11.200 --> 00:04:15.140
because you know it's not gonna go to the edges , we're not doing any padding

00:04:15.140 --> 00:04:22.680
So you gonna then have a 24 by 24 image
and the next layer will take it down to 20 by 20
and the next layer will take it down further than that.

00:04:22.680 --> 00:04:27.520
So let's talk about how many different kernels there are in each of these layers,

00:04:27.520 --> 00:04:33.160
So the first layers, I got 20 different kernels per layer, and then if I refer back to my model file

00:04:33.160 --> 00:04:33.900
Is that the code for?

00:04:33.900 --> 00:04:40.180
It's actually a text document in Caffe
-- because this is the log have been using to do this --
which basically explains...

00:04:40.180 --> 00:04:47.180
this way you detail what size of kernel, how many kernels, how many layers you have, which one connects to each other ones and so on. Okay.

00:04:47.540 --> 00:04:52.800
This is also slightly different to the stock MNIST model file, but it's, you know, similar stuff, okay

00:04:52.800 --> 00:04:55.740
So, for example if we pick a layer at random, could you see this layer here ?

00:04:55.800 --> 00:04:59.100
so we've got 20 outputs, kernel size of 5, a stride of 1,

00:04:59.100 --> 00:05:03.100
and then this tells you how you're going to ramdomize your weight when your begin training.

00:05:03.960 --> 00:05:08.120
So we just described all of these things to the network and it goes off and does most of the work for us.

00:05:08.120 --> 00:05:10.780
So my first 2 layers have 20 kernels,

00:05:10.780 --> 00:05:19.080
then, because I decided this was a good idea, I increase this number to 50 kernels, and 50 kernels... And I have 4 with 50 kernels.

00:05:19.080 --> 00:05:27.920
You could imagine that your input image to begin with is 28 by 28, and it's 1 deep, because we have a grayscale image.

00:05:27.980 --> 00:05:29.940
These are grayscale digits we're looking at here.

00:05:29.940 --> 00:05:34.580
After the first 5 by 5 convolution this image is gonna shrink to 24 by 24

00:05:34.580 --> 00:05:38.960
but because there's 20 different kernels, all producing their own image output,

00:05:38.960 --> 00:05:47.580
it's going to be 24 by 24 by 20, and so on, okay

00:05:47.880 --> 00:05:50.820
I won't draw the whole thing out because we've done that in the last video.

00:05:50.940 --> 00:05:56.660
but these convolutions here, because I'm not using any padding will slowly decrease the size of the image

00:05:56.660 --> 00:06:06.880
and when we get to this point here at the first fully connected layer, the image should be 4 by 4 by 50 deep, which is 800 different values.

00:06:06.980 --> 00:06:12.220
Now often we would go round that to 1x1 but that is not really necessary in this case, cause there is not too much data.

00:06:12.280 --> 00:06:19.480
So this first fully connected layer is 500 neurons long,
all of which connect to all the possible 800 values

00:06:19.480 --> 00:06:22.020
and then the final 10 comes from these 500.

00:06:22.920 --> 00:06:26.880
So let's look at some pictures and then maybe it will be more clear, okay,

00:06:26.880 --> 00:06:32.220
It's not a very complicated network, modern networks gets much bigger than this but this shows you the kind of things that they're doing

00:06:32.220 --> 00:06:37.620
So I've printed out some examples of the kinds of things that these networks will do

00:06:37.620 --> 00:06:40.080
So let's just use number "2" as an example

00:06:40.080 --> 00:06:43.200
This is a picture of a "2" !
It's very exciting for people watching

00:06:43.200 --> 00:06:51.480
It's a 28 by 28 picture of a "2", which has been normalized so that the background is basically black and the foreground is white, okay

00:06:51.480 --> 00:07:01.840
You get slightly better results if you normalize because if they pressed lightly with their pen and maybe not have done a very firm to then maybe you sort of increase the contrast a little bit

00:07:01.880 --> 00:07:05.080
So we first gonna do a 5 by 5  convolution over this

00:07:05.080 --> 00:07:12.000
we're gonna 20 of those, so unsurprisingly if we move this away, we gonna see a number of kernel convolutions

00:07:12.040 --> 00:07:19.040
These are performing low-level image processing tasks, just like the kind of Sobel edge detectors that I talked about in previous videos

00:07:19.040 --> 00:07:25.800
So this one for example is a kind of diagonal gradient you can see that the edges that are going diagonally are quite highlighted

00:07:25.800 --> 00:07:32.420
and there's different orientations, so this one is horizontal, and there's a vertical one over here, and so on

00:07:32.580 --> 00:07:38.520
We can't do a lot of interesting things with this image after this one set of convolutions, but we're getting there

00:07:38.520 --> 00:07:42.100
So this one is starting to be transformed,
 some of them are noisier than others

00:07:42.100 --> 00:07:46.800
That's partly due to my, you know, not having trained it very long, and partly because maybe that's useful

00:07:46.880 --> 00:07:50.300
So, we're gonna do another set of convolutions on all of these inputs

00:07:50.640 --> 00:07:53.360
So these are now gonna be convolutions of convolutions.

00:07:53.460 --> 00:07:59.360
They start getting a little bit smoother because we're shrinking our image down and we're slowly starting to find higher level features.

00:07:59.360 --> 00:08:03.200
So now you can see that the loop in the top of the "2" has been highlighted here

00:08:03.200 --> 00:08:08.020
and this one is highlighted only the horizontal bit on the top of the bottom of the 2 if that kind of makes sense.

00:08:08.020 --> 00:08:10.660
So different areas of the image are now starting to be highlighted

00:08:10.660 --> 00:08:12.420
we're bringing in different information

00:08:12.420 --> 00:08:16.920
and as we keep going, you can see we're going even further, so we've increased the number of features

00:08:17.060 --> 00:08:23.660
and you can kind of see maybe there used to be a "2" there, but we've extracted away the actual "2" now and we're looking just to features.

00:08:23.660 --> 00:08:29.700
So there's lot of diagonals here which have been highlighted, and they are highlighted in very specific nuances,

00:08:29.720 --> 00:08:32.180
because some of them are looking for some things and some of them are looking for other things.

00:08:32.180 --> 00:08:35.940
Just by looking at these pictures, it's hard to know what exactly each of these is looking for,

00:08:35.940 --> 00:08:39.960
because they would be looking for something different if you had a different number in there.

00:08:39.960 --> 00:08:45.580
We keep going, they get smaller and smaller, and they get more and more abstract, so you're still seeing the tip of a "2" here,

00:08:45.800 --> 00:08:54.300
and this is the image which is highlighted, things that the computer thinks are useful to learn to tell us about what it is to be a "2", which is kind of weird concept.

00:08:55.160 --> 00:09:01.560
And we keep going and the image continue to just get smaller and smaller until we get to our final 4 by 4 images

00:09:01.560 --> 00:09:04.920
Now I'll put a comparison of two different digits on these in a minute

00:09:04.920 --> 00:09:09.760
but you can see that obviously we're getting very general shapes now. There's no concept of a "2" anymore,

00:09:09.760 --> 00:09:13.680
this has been completely extracted away into which of these are lit up and where,

00:09:13.680 --> 00:09:21.140
and we connect that to a first fully connected layer which I've tried to print out but it's kind of odd, which is just a bunch of activations spread out over these 500,

00:09:21.360 --> 00:09:28.580
not all of them are activated as you can see, the white ones are very strong activations, the grey ones are in the middle, and the black ones are very low activations.

00:09:28.580 --> 00:09:30.780
So you can see that, you know, these 2 are good.

00:09:31.000 --> 00:09:36.300
So in some sense it's learned that when there is a 2 in this image, these 2 have been lighted up, and so is this one, and so on.

00:09:36.300 --> 00:09:39.920
Basically I've said, here is a picture of a "2", I'd like you to output the number "2",

00:09:40.020 --> 00:09:42.740
And it said, well okay, if I make these like this, then that would work.

00:09:42.740 --> 00:09:45.180
So it's just following a mathematical process.

00:09:45.180 --> 00:09:48.300
So even for different original "2"s, would those two..?

00:09:48.300 --> 00:09:50.400
They would be, yeah, they would be subtly different..

00:09:50.520 --> 00:09:53.760
I mean, if you got a really well trained algorithm, they would start to look very similar

00:09:53.760 --> 00:10:00.300
But there's a lot of nuances here, and there's only 10 classes, so there's gonna be more information in here in some way than you need.

00:10:00.580 --> 00:10:06.980
And then at the end, this will be possibly easier to understand, these are our final 10 outputs.

00:10:06.980 --> 00:10:10.520
These 2 are not real, I just, they're just left-in by mistake when they were printed.

00:10:10.520 --> 00:10:17.740
So you can see 0, 1, 2, the white one, the one that lit up is number 2, okay, so this is essentially correctly identified the "2".

00:10:17.860 --> 00:10:25.940
Now obviously, in my program, I would read this value out and do something useful with it, I wouldn't just print it as a block, but you get the idea. Okay.

00:10:25.940 --> 00:10:29.280
Lets have a look at "2" versus let's say some other number.

00:10:29.280 --> 00:10:32.860
"4" is kind of like 2, in a sense that is has some sort of horizontal bits in it.

00:10:32.860 --> 00:10:37.200
I should have asked to any digits, so really "4" is nothing like a "2", I'm talking nonsense.

00:10:37.200 --> 00:10:41.880
The first layer looks much like the one from the "2", because it would do,

00:10:41.880 --> 00:10:45.460
because we've only done only one set of convolutions and they all do much the same thing.

00:10:45.460 --> 00:10:50.820
So you can see that for example in this one here, you've got mostly these kind of corners here that are highlighted

00:10:50.820 --> 00:10:52.140
and that's true of the 4 as well

00:10:52.140 --> 00:10:54.460
As we've sort of progress it and I'll skip a few layers,

00:10:54.460 --> 00:10:56.440
Let's see if I can get the matching layer for the "4".

00:10:56.440 --> 00:11:00.080
You can see that some elements are the same, and some are different.

00:11:00.200 --> 00:11:05.200
So this one here, this new one here, is darker, but it's got a white region, that isn't in this "2",

00:11:05.320 --> 00:11:08.840
so this one this is starting to pick up differences between these two images now,

00:11:08.840 --> 00:11:12.280
And, you know, if you start doing this for a while you could see there are some other differences.

00:11:12.280 --> 00:11:18.420
Again, I'm showing you this because it's interesting to see what a convolutional neural network does,

00:11:18.700 --> 00:11:23.900
but its very difficult to look at this and go
"oh of course, this is finding where the corners of the '4' here" and so on

00:11:23.900 --> 00:11:26.560
You have to study it for quite a long time to work out what that is.

00:11:26.560 --> 00:11:33.120
There are people doing these sort of things, but to be honest most people would just go "oh, that's nice and it's works and that's what important".

00:11:33.120 --> 00:11:37.900
So we've progressed a bit further, so this is the last convolutional output before the fully connected layers.

00:11:37.900 --> 00:11:41.060
Now you can see that actually there are some quite big differences.

00:11:41.060 --> 00:11:46.580
So this one, for example, is bright in the top left and dark in the top right, for the "4",

00:11:46.800 --> 00:11:50.740
where as it's dark in the top left and bright in the bottom right for the "2".

00:11:50.740 --> 00:11:56.600
At this point we've now extracted away anything that said exactly what the image looked like, and now we are just looking at features.

00:11:56.820 --> 00:12:00.480
So these are basically things that the computer finds useful, and now they are completly different.

00:12:00.480 --> 00:12:05.240
And as we we now look at the fully connected layers, completely different neurons have been activated.

00:12:05.240 --> 00:12:09.880
These two are now dark and there are some black ones in this "4" that aren't in this one, and so on.

00:12:09.940 --> 00:12:15.400
So what it's done is that it's transformed the image using the convolutional layers into something

00:12:15.400 --> 00:12:19.580
that when it gets into the fully connected layers looks different to the computer, and that's really useful.

00:12:19.700 --> 00:12:24.800
And then finally unsurprisingly, number "4" has lit up. So it's successfully worked.

00:12:24.820 --> 00:12:26.960
And that's basically what it's look like,

00:12:26.960 --> 00:12:31.920
Now obviously if you have a much deeper convolutional network, with many more classes,

00:12:32.020 --> 00:12:36.400
this is gonna be doing lot's more hierarchical, complex operations.

00:12:36.660 --> 00:12:39.240
But this is basically the gist of work a convolutional network would do.

00:12:39.480 --> 00:12:41.300
And how long did it take for you to do that?

00:12:41.420 --> 00:12:50.240
Oh, well, building the model took a few minutes and then to train it was a few hours because I added a few convolutional layers.

00:12:50.460 --> 00:12:58.400
It takes, you know, 40 minutes to train the most if you're doing standard small networks, which still is not 88% accurate on these digits.

00:12:58.400 --> 00:13:01.600
And how much harder is it to do, for, say, letters

00:13:01.840 --> 00:13:08.180
It's a bit harder, because you've got 26 classes, instead of, or maybe for capitals as well you've got even more classes.

00:13:08.560 --> 00:13:15.700
But on the other hand, if you're providing images like this, which are very controlled, it's not very difficult.

00:13:16.020 --> 00:13:24.080
If you're producing any possible "a", then it's gonna be more challenging, but still convolutional networks can do these tasks quite easily.

00:13:24.300 --> 00:13:30.360
You just have to increase the number of convolutions, increase the number of kernels you have per layer, just to increase the amount that it can do.

00:13:30.600 --> 00:13:34.440
And then you just leave it to train a little bit longer and it seems to work.

00:13:34.700 --> 00:13:44.800
It seems to me that all these things that we see on websites these days where it says "are you a human, click this box", are kind of the thing of the past, nowadays?

00:13:44.920 --> 00:13:52.220
Captchas, yeah, so in some sense the old captchas style that we had where you'd see like 5 or 6 letters

00:13:52.400 --> 00:13:57.480
that you'd have to type them in, they are defeated by convolutional neural networks.

00:13:57.600 --> 00:14:01.440
If someone has bothered to train a convolutional network to defeat that task

00:14:01.440 --> 00:14:07.380
one important thing to remember is that I have trained this network on a very specific set of digits

00:14:07.560 --> 00:14:12.720
If I give it some kind of captcha with digits in, particularly if there is more than one digit per image,

00:14:12.980 --> 00:14:17.740
it's not gonna to understand, because I've been giving him 28 by 28 images with just 1 digit in.

00:14:17.880 --> 00:14:23.720
So to get to work on a specific captcha system, you're gonna have to train it on that specific captcha system

00:14:23.720 --> 00:14:28.080
Now, one of the nice things that captcha systems do,
from the point of view of trying to crack them,

00:14:28.240 --> 00:14:33.680
is generate a lot of images so you just download their API and you can just generate dataset after dataset.

00:14:33.960 --> 00:14:38.620
So in some sense, image based captchas are starting to look a bit weak.

00:14:39.040 --> 00:14:45.320
On the other hand, as a researcher where I'm not really heavily interested in breaking captchas, I think it's probably serves quite a useful purpose,

00:14:45.780 --> 00:14:51.900
so, you know, maybe a spammer is trying to do this, so you start to look into more complex captcha systems

00:14:52.100 --> 00:14:56.920
so for example Google reCAPTCHA which won't necessarily provide you numbers will ask you

00:14:57.020 --> 00:15:01.260
"can you see all the biscuits in this image, and you'll see a 9 by 9 grid of biscuits

00:15:01.480 --> 00:15:06.940
and then it's slightly more complicated for a bot to interact with this HTML

00:15:06.940 --> 00:15:11.180
and it's a slightly more complicated problem, particularly if you don't know it's going to ask until it does.

00:15:12.540 --> 00:15:16.480
So I guess the idea ot it is to keep changing your captcha system

00:15:16.620 --> 00:15:23.420
with enough frequency that if anyone had trained the network to solve it, it then become redundant and they can't solve the next one.

00:15:27.860 --> 00:15:30.680
The problem is that if I obtain a cookie of you which is supposed to be secure,

00:15:30.820 --> 00:15:38.480
then I can send that to, let's say, Amazon, or to a shop and say "I'm Shawn, please, what's in the shoping basket "

00:15:38.480 --> 00:15:41.239
what's his address, what's his credit card details.

