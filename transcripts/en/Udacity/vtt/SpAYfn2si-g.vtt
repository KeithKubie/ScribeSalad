WEBVTT
Kind: captions
Language: en

00:00:00.090 --> 00:00:02.810
So in this section on advanced
algorithmic analysis,

00:00:02.810 --> 00:00:03.730
what have we learned?

00:00:03.730 --> 00:00:06.397
&gt;&gt; Well we learned a bunch of stuff.

00:00:06.397 --> 00:00:10.900
It's a compact and dense lesson.

00:00:10.900 --> 00:00:11.850
I think that's pretty good.

00:00:11.850 --> 00:00:13.270
&gt;&gt; Oh that was a math joke, wasn't it?

00:00:13.270 --> 00:00:14.880
&gt;&gt; Yes it was a math joke.

00:00:14.880 --> 00:00:17.375
Well the first thing we learned
is that you like alliteration.

00:00:17.375 --> 00:00:19.840
&gt;&gt; [LAUGH]
&gt;&gt; This whole section was

00:00:19.840 --> 00:00:21.790
advanced algorithmic analysis.

00:00:21.790 --> 00:00:22.764
&gt;&gt; Okay.
&gt;&gt; Mm-hm.

00:00:22.764 --> 00:00:26.240
And in particular we talked about
three things, all ending in I.

00:00:26.240 --> 00:00:28.580
VI, LI and PI.

00:00:28.580 --> 00:00:31.200
&gt;&gt; [LAUGH] Yeah there's
a problem with LI though.

00:00:31.200 --> 00:00:32.780
&gt;&gt; Yeah that it's not really a thing.

00:00:32.780 --> 00:00:35.290
&gt;&gt; Yeah, it's LP in your programming.

00:00:35.290 --> 00:00:37.730
&gt;&gt; But then it wouldn't end in an I.

00:00:37.730 --> 00:00:39.550
&gt;&gt; I agree with that, but
at least it ends with P and

00:00:39.550 --> 00:00:40.830
the other one starts with P.

00:00:40.830 --> 00:00:42.190
There is some over lap.

00:00:42.190 --> 00:00:43.690
All of these things
overlap with each other.

00:00:43.690 --> 00:00:47.620
&gt;&gt; If you call it VLP for
very linear programming.

00:00:47.620 --> 00:00:48.920
&gt;&gt; No, It's just linear programming.

00:00:48.920 --> 00:00:50.680
Let's just go with that.

00:00:50.680 --> 00:00:52.510
&gt;&gt; Okay.
Very linear is still linear.

00:00:52.510 --> 00:00:53.930
In any case, all right.

00:00:53.930 --> 00:00:54.720
So what did we learn?

00:00:54.720 --> 00:00:57.260
We learned a little bit
about each of those things.

00:00:57.260 --> 00:01:01.270
So in particular for
value iteration, we learned that it

00:01:01.270 --> 00:01:06.370
converges to optimal in a finite number
of steps, or it gets bound towards that.

00:01:06.370 --> 00:01:07.780
&gt;&gt; Okay.
Can we be more precise there?

00:01:07.780 --> 00:01:10.230
The value function doesn't converge
in a finite number of steps.

00:01:10.230 --> 00:01:11.430
&gt;&gt; But the policy does.

00:01:11.430 --> 00:01:12.960
&gt;&gt; The greedy policy does, yeah.

00:01:12.960 --> 00:01:14.410
&gt;&gt; Right.
But really, that's what we want.

00:01:14.410 --> 00:01:15.090
&gt;&gt; Yeah.

00:01:15.090 --> 00:01:16.490
I agree with that.

00:01:16.490 --> 00:01:17.740
&gt;&gt; Sure.
But that's a good point.

00:01:17.740 --> 00:01:21.270
It's not that the value function
itself has to, because otherwise

00:01:21.270 --> 00:01:23.860
we go all the way back to 'em' and
have that conversation again.

00:01:23.860 --> 00:01:27.960
But that the policy itself
will stop changing.

00:01:27.960 --> 00:01:31.960
The greedy policy will stop changing
at some point and in finite time.

00:01:31.960 --> 00:01:32.690
&gt;&gt; Right.

00:01:32.690 --> 00:01:34.230
And it will be optimal at that point.

00:01:34.230 --> 00:01:37.750
Yeah, and so the value function itself
doesn't necessarily converge, but

00:01:37.750 --> 00:01:40.960
it's going to get boundedly
close to the solution.

00:01:40.960 --> 00:01:45.620
So that is to say,
if we want to be epsilon close to

00:01:45.620 --> 00:01:50.520
the solution to the Belmont equation,
we can define how many iterations of

00:01:50.520 --> 00:01:54.630
value iteration we would need to
accomplish that degree of approximation.

00:01:54.630 --> 00:01:56.120
&gt;&gt; Right.
And that's fine.

00:01:56.120 --> 00:01:57.700
Because in the end that's interesting,

00:01:57.700 --> 00:02:00.830
but what's really interesting is that
we get a policy that we can act on.

00:02:00.830 --> 00:02:02.130
&gt;&gt; Because we want to maximize reward.

00:02:02.130 --> 00:02:03.260
That's just what we are about.

00:02:03.260 --> 00:02:04.458
&gt;&gt; That's what we are all about, really.

00:02:04.458 --> 00:02:07.500
So let's see.
Then we talked about linear programming,

00:02:07.500 --> 00:02:11.970
which is another way to
think about solving MVPs.

00:02:11.970 --> 00:02:16.500
What I remember most about it
is you actually define the dual.

00:02:16.500 --> 00:02:17.000
&gt;&gt; Okay.

00:02:17.000 --> 00:02:21.960
&gt;&gt; That was really cool because it
allowed us to solve the problem and

00:02:21.960 --> 00:02:24.970
like so many things that we do,
it was a call back to our first class.

00:02:24.970 --> 00:02:27.637
And now I actually understand how
support vector machines work.

00:02:27.637 --> 00:02:30.300
&gt;&gt; [LAUGH] Okay.

00:02:30.300 --> 00:02:33.600
I think you did that lecture, so
I was hoping you understood it already.

00:02:33.600 --> 00:02:34.717
&gt;&gt; Well,
there was just a point where you say,

00:02:34.717 --> 00:02:37.940
well or could you solve the dual,
and then I rapidly wave my hands and

00:02:37.940 --> 00:02:39.740
said don't worry about it,
it's a dual, it's a thing.

00:02:39.740 --> 00:02:41.420
&gt;&gt; Okay.
&gt;&gt; But now we talked about the dual, so

00:02:41.420 --> 00:02:42.170
I think that that's good.

00:02:42.170 --> 00:02:45.640
&gt;&gt; I feel like the concept of dual
is somehow relevant to superheroes.

00:02:45.640 --> 00:02:46.280
&gt;&gt; You think so?

00:02:46.280 --> 00:02:46.830
&gt;&gt; I don't know.

00:02:46.830 --> 00:02:50.820
You know way more about comic books
than I do, but isn't there like every

00:02:50.820 --> 00:02:56.130
superhero has a dual,
like anti-Batman or the dark Spiderman?

00:02:56.130 --> 00:02:56.670
&gt;&gt; Venom?

00:02:56.670 --> 00:03:01.550
So you're saying that primal and
duals are like nemesis.

00:03:03.160 --> 00:03:05.510
&gt;&gt; Yeah, or
mirror images of each other in some way.

00:03:05.510 --> 00:03:09.440
&gt;&gt; So the flow,
the sort of policy flow idea,

00:03:09.440 --> 00:03:13.540
is like the nemesis of the value idea,
or the mirror image of it.

00:03:13.540 --> 00:03:14.140
&gt;&gt; Yeah, sure.

00:03:14.140 --> 00:03:14.740
&gt;&gt; Let's go with that.

00:03:14.740 --> 00:03:17.440
I was thinking more of a hip-hop
analogy, but I think that's pretty good.

00:03:17.440 --> 00:03:19.040
&gt;&gt; Oh, flow is a hip-hop thing.

00:03:19.040 --> 00:03:19.970
&gt;&gt; It's a hip-hop thing.

00:03:19.970 --> 00:03:21.430
&gt;&gt; And values.

00:03:21.430 --> 00:03:23.010
People in hip hop have values.

00:03:23.010 --> 00:03:25.310
&gt;&gt; That's right, so
it just follows in one step.

00:03:25.310 --> 00:03:26.660
Okay, speaking in one step.

00:03:26.660 --> 00:03:29.890
So, then there's policy iteration,
which I thought was kind of cool.

00:03:30.980 --> 00:03:32.940
We got a chance to prove
a bunch of things about it.

00:03:32.940 --> 00:03:34.860
And I think the first thing
we talked about there or

00:03:34.860 --> 00:03:38.410
somewhere in that mix was domination,
which turned out to be really cool.

00:03:38.410 --> 00:03:41.220
&gt;&gt; Yeah and that comes up actually
in all of the algorithms.

00:03:41.220 --> 00:03:42.650
Value iteration has some of that.

00:03:42.650 --> 00:03:44.650
Linear programming has some of that.

00:03:44.650 --> 00:03:46.030
And policy iteration.

00:03:46.030 --> 00:03:48.970
The proof of policy iteration
depends significantly on that.

00:03:48.970 --> 00:03:50.925
&gt;&gt; Right.
Speaking of things the proof of policy

00:03:50.925 --> 00:03:55.800
iteration depends on, we also talked
about value non deprovement, or

00:03:55.800 --> 00:03:59.090
value improvement as I believe is
the non-technical term for it.

00:03:59.090 --> 00:04:02.880
&gt;&gt; That's right and we argued that we'd
actually get strict value improvement

00:04:02.880 --> 00:04:05.320
any time that we didn't have
a policy that was already optimal.

00:04:05.320 --> 00:04:09.970
If it was already optimal then a step of
policy iteration resulted in value non

00:04:09.970 --> 00:04:14.700
deprovement which is just our broken
way of saying it doesn't get worse.

00:04:14.700 --> 00:04:16.690
It might not get better,
but it doesn't get worse.

00:04:16.690 --> 00:04:17.894
&gt;&gt; Yeah.
It's like a monotonically

00:04:17.894 --> 00:04:19.700
non-decreasing function.

00:04:19.700 --> 00:04:20.870
But the other thing is,

00:04:20.870 --> 00:04:23.550
we had a discussion that I think
is actually pretty important,

00:04:23.550 --> 00:04:27.260
that when we talk about things like
domination, you writing them down for

00:04:27.260 --> 00:04:30.890
good notational reasons, talking
about an entire value function, but

00:04:30.890 --> 00:04:35.380
really this is about things have to
also be true on a state by state basis.

00:04:35.380 --> 00:04:37.160
&gt;&gt; That's right.
&gt;&gt; Because if that weren't true,

00:04:37.160 --> 00:04:40.690
then in principle, you could cycle, and
then you get stuck in local optimum.

00:04:40.690 --> 00:04:42.900
But here,
we don't get stuck in local optimum,

00:04:44.190 --> 00:04:47.250
because things also dominate
on a state by state basis.

00:04:47.250 --> 00:04:49.340
&gt;&gt; Cool.
&gt;&gt; Kind of neat.

00:04:49.340 --> 00:04:50.960
We also talked about monotonicity.

00:04:50.960 --> 00:04:52.830
&gt;&gt; And
that you can contract it from kissing.

00:04:52.830 --> 00:04:53.620
&gt;&gt; Yeah.

00:04:53.620 --> 00:04:54.780
Oh, you said contract.

00:04:54.780 --> 00:04:55.980
Very well done, Mike.

00:04:55.980 --> 00:04:57.260
&gt;&gt; Oh, yeah.

00:04:57.260 --> 00:04:58.716
That was pun intentional.

00:04:58.716 --> 00:05:00.066
Sorry.
&gt;&gt; Pun intentional.

00:05:00.066 --> 00:05:04.060
[LAUGH] Okay and really when you
put all these things together.

00:05:04.060 --> 00:05:08.285
I think the real thing we learned in
this lesson is that proofs do not suck.

00:05:08.285 --> 00:05:12.120
&gt;&gt; [LAUGH] So that's great.

00:05:12.120 --> 00:05:16.880
Because if I recall we started our last
class with a little discussion about how

00:05:16.880 --> 00:05:19.560
I don't mind proofs as much as you do.

00:05:19.560 --> 00:05:20.622
&gt;&gt; That's right.
Speaking of proof you

00:05:20.622 --> 00:05:22.100
forgot the s on proofs.

00:05:22.100 --> 00:05:25.620
&gt;&gt; See, I did a proof of your proof.

00:05:25.620 --> 00:05:26.990
That was pretty good.

00:05:26.990 --> 00:05:27.840
&gt;&gt; You proof read it?

00:05:27.840 --> 00:05:28.570
&gt;&gt; Yes.

00:05:28.570 --> 00:05:29.530
Yes.

00:05:29.530 --> 00:05:31.430
&gt;&gt; Nice.
&gt;&gt; I feel like we have converged.

00:05:31.430 --> 00:05:34.570
&gt;&gt; [LAUGH] And
that's what this was all about.

00:05:34.570 --> 00:05:36.150
&gt;&gt; That's what this is all about.

00:05:36.150 --> 00:05:38.730
&gt;&gt; Yeah, there's something
very satisfying about getting

00:05:38.730 --> 00:05:39.800
to the convergence point.

00:05:39.800 --> 00:05:40.530
&gt;&gt; Very nice.
Very nice.

00:05:40.530 --> 00:05:41.122
Okay well,

00:05:41.122 --> 00:05:44.775
I think that's everything that I was
capable of learning in one lesson.

00:05:44.775 --> 00:05:49.200
&gt;&gt; [LAUGH] Yeah, all right, well so next
time we'll start in with something else.

00:05:49.200 --> 00:05:52.380
I think we're going to talk about how
we can modify reward functions and

00:05:52.380 --> 00:05:53.680
get different things out of them.

00:05:53.680 --> 00:05:54.860
&gt;&gt; Oh yeah, that's my favorite.

00:05:54.860 --> 00:05:55.990
Excellent.
Well, then I will see you then.

