WEBVTT
Kind: captions
Language: en

00:00:03.100 --> 00:00:06.020
Hi, I’m Adriene Hill, and welcome back to
Crash Course Statistics.

00:00:06.029 --> 00:00:08.059
It’s great to have a lot of choices.

00:00:08.059 --> 00:00:12.590
But sometimes we limit our choices in order to do something productive or meaningful.

00:00:12.590 --> 00:00:17.000
Like being on a team project that needs a
writer, director, host, camera person, and

00:00:17.000 --> 00:00:18.200
boom mic holder.

00:00:18.200 --> 00:00:23.480
If we have 5 different people who can be on that team, after assigning 4 of them positions...the

00:00:23.480 --> 00:00:26.550
last person doesn’t have any freedom to
choose theirs.

00:00:26.550 --> 00:00:28.430
It has effectively been assigned.

00:00:28.430 --> 00:00:32.430
If she’s willing to give up the freedom
to have a choice of positions and take on

00:00:32.430 --> 00:00:37.803
the great feat of upper body strength that
is holding a boom mic, then they have a team

00:00:37.803 --> 00:00:39.190
that can complete their project.

00:00:39.190 --> 00:00:41.170
This can happen in statistics, too.

00:00:41.170 --> 00:00:46.010
Occasionally we have to give up some freedom--degrees of freedom--in order to do something useful

00:00:46.010 --> 00:00:46.960
with our data.

00:00:46.960 --> 00:00:52.100
Degrees of freedom are the number of independent pieces of information we have and Degrees

00:00:52.100 --> 00:00:55.399
of freedom are an important part of many of the models that we use.

00:00:55.400 --> 00:01:00.220
In fact, we’ve also been leaving out another
important component of the t-test: effect size.

00:01:00.220 --> 00:01:04.940
Knowing what degrees-of-freedom and effect-size are and why they matter will help give our

00:01:04.940 --> 00:01:06.800
t-tests better context.

00:01:06.800 --> 00:01:16.120
INTRO

00:01:16.120 --> 00:01:19.890
In the last few episodes we’ve covered the
general formula for test statistics.

00:01:19.890 --> 00:01:24.710
And we’ve gotten pretty good at calculating
t-statistics for all sorts of situations:

00:01:24.710 --> 00:01:29.490
means, proportions, one sample, two sample, paired, unpaired but every time we’ve needed

00:01:29.490 --> 00:01:32.700
a p-value, we’ve let the computer do the
work.

00:01:32.700 --> 00:01:34.219
Which is what we’ll continue to do.

00:01:34.220 --> 00:01:39.520
But it’s important to know that we’re
not using the same t-distribution every single time.

00:01:39.520 --> 00:01:44.720
As we’ve previously discussed, the t-distribution is like the z-distribution, but it has fatter

00:01:44.720 --> 00:01:50.170
tails, meaning that extreme t-values tend
to be slightly more likely.

00:01:50.170 --> 00:01:55.709
And that’s because we don’t know the population standard deviation when we calculate a t-statistic,

00:01:55.709 --> 00:01:59.080
so we estimate it using the sample standard deviation.

00:01:59.080 --> 00:02:05.120
This little bit of uncertainty means that
we don’t have a perfect normal--or z--distribution.

00:02:05.130 --> 00:02:07.220
Instead we have our fat tailed friend.

00:02:07.229 --> 00:02:11.810
But with bigger sample sizes, we’re better
able to estimate population parameters like

00:02:11.810 --> 00:02:18.200
the mean and standard deviation, so our t-distribution changes its shape to reflect that.

00:02:18.200 --> 00:02:23.320
As n--our sample size--gets bigger, we’re
less and less uncertain about our estimate,

00:02:23.320 --> 00:02:27.130
and the t-distribution will get closer and
closer to z.

00:02:27.130 --> 00:02:31.300
More information usually means we have a more accurate estimate.

00:02:31.300 --> 00:02:34.360
Degrees of freedom can help us measure that accuracy.

00:02:34.360 --> 00:02:39.110
We choose our t-distribution based on the
number of degrees of freedom that we have.

00:02:39.110 --> 00:02:43.230
Degrees of freedom are the number of pieces of independent information in our data.

00:02:43.230 --> 00:02:44.970
Let’s go to the thought bubble.

00:02:44.970 --> 00:02:48.360
After dinner with 2 friends, you all pull
out your credit cards to split the bill.

00:02:48.360 --> 00:02:53.750
Your friend Carmen, who’s a bit of math
savant, and a bit of a showoff, notices that if you took your credit

00:02:53.750 --> 00:02:59.160
card numbers as a single 16 digit number,
the mean of your three credit card numbers

00:02:59.170 --> 00:03:05.830
is 4551-9681-7590-9146.

00:03:05.830 --> 00:03:09.660
She said this really loudly and you’re a
little nervous that an identity thief might

00:03:09.660 --> 00:03:15.460
have been lurking nearby and overheard Carmen make her very public declaration.

00:03:15.460 --> 00:03:16.970
But there’s nothing to worry about!

00:03:16.970 --> 00:03:20.100
Even though a potential thief has the mean
of your credit card numbers, they won’t

00:03:20.100 --> 00:03:24.110
be able to figure out what any of your individual numbers are.

00:03:24.110 --> 00:03:27.710
In other words, there’s a lot of “freedom”
around what those numbers could be.

00:03:27.710 --> 00:03:31.210
And actually, you’d even be okay if the
thief found out Carmen‘s credit card number.

00:03:31.210 --> 00:03:35.860
At that point, they could figure out the sum
or mean of your and your other friend Eli‘s

00:03:35.860 --> 00:03:39.950
cards, but they still couldn’t tell what
your exact number was.

00:03:39.950 --> 00:03:43.740
There’s still freedom for your credit card
number to take on different values.

00:03:43.740 --> 00:03:44.970
It could be any of these:

00:03:44.970 --> 00:03:50.500
BUT as soon as someone knows the mean of all three cards, Carmen’s number, and Eli ’s

00:03:50.500 --> 00:03:53.530
number, they’ll know exactly what your credit card number is.

00:03:53.530 --> 00:03:56.069
It’s no longer “free” to take on different
values.

00:03:56.069 --> 00:03:57.820
If Carmen’s number is this:

00:03:57.820 --> 00:03:59.370
And Eli’s number is this:

00:03:59.370 --> 00:04:04.660
Then knowing the mean allows anyone to figure out that your number must be this:

00:04:04.660 --> 00:04:08.150
So you should probably make sure that Eli
keeps his number underwraps.

00:04:08.150 --> 00:04:09.150
Just to be safe.

00:04:09.150 --> 00:04:10.150
Thanks Thought bubble.

00:04:10.150 --> 00:04:14.780
In that example, the three credit card numbers already existed before we started doing any math.

00:04:14.780 --> 00:04:18.040
And they are three independent pieces of information.

00:04:18.040 --> 00:04:22.120
Eli’s credit card number has no effect on
your credit card number, which has no effect

00:04:22.129 --> 00:04:23.520
on Carmen’s, and so on.

00:04:23.520 --> 00:04:28.680
But, as soon as Carmen calculated the mean, she used up one of those independent pieces

00:04:28.680 --> 00:04:30.419
of information.

00:04:30.419 --> 00:04:35.330
Once the thief knows the mean, they only need TWO pieces of independent information.

00:04:35.330 --> 00:04:37.580
(that is n-1 pieces).

00:04:37.580 --> 00:04:41.639
In this case, once they know any two of the
credit card numbers--and the mean--they know

00:04:41.639 --> 00:04:42.639
all three.

00:04:42.639 --> 00:04:45.830
So when they learn Carmen’s number and Eli’s number -- SUDDENLY those numbers can

00:04:45.830 --> 00:04:47.180
reveal yours.

00:04:47.180 --> 00:04:50.229
The thief can figure out your exact credit
card number.

00:04:50.229 --> 00:04:53.180
Since it’s no longer independent of the
others.

00:04:53.180 --> 00:04:57.379
To bring it back to our t-tests... when we
calculate a mean, we’re using up one degree

00:04:57.379 --> 00:05:01.090
of freedom--or one piece of independent information.

00:05:01.090 --> 00:05:05.689
The amount of information that we originally have depends on our sample size--n--which

00:05:05.689 --> 00:05:09.719
is why you’ll often see it in the formulas
to calculate degrees of freedom.

00:05:09.719 --> 00:05:13.330
The more data you have, the more independent information that you have.

00:05:13.330 --> 00:05:17.819
But every time you make a calculation like
a mean, you’re using up one piece of independent

00:05:17.819 --> 00:05:18.819
information.

00:05:18.819 --> 00:05:24.341
So, for example, we have data from 100 randomly sampled square miles of avocado orchard, and

00:05:24.341 --> 00:05:30.719
we’ve painstakingly counted the number of
bees spotted in each sampled square mile over

00:05:30.719 --> 00:05:31.870
the course of a week.

00:05:31.870 --> 00:05:33.809
The bee population is declining!

00:05:33.809 --> 00:05:36.999
We need to be sure avocados are getting pollinated!

00:05:36.999 --> 00:05:41.840
The owner of one avocado orchard says that she usually sees 15,000 bees per square mile.

00:05:41.840 --> 00:05:47.139
So, you set out to analyze your data to see
whether you think the bee population has changed.

00:05:47.139 --> 00:05:52.140
You have 100 pieces of independent data--one measure from each square mile--so, when you

00:05:52.140 --> 00:05:58.129
calculate the mean number of bees from all 100 square miles, you’re using up 1 degree

00:05:58.129 --> 00:05:59.129
of freedom.

00:05:59.129 --> 00:06:04.919
Now that we know the mean number of bees is 16,838, you only need 99 of the bee counts

00:06:04.919 --> 00:06:12.099
to figure out what the count for the 100th
square mile would bee.

00:06:12.099 --> 00:06:17.181
With a quick one sample t-test, we get our
p-value from a t-distribution with 99 degrees

00:06:17.181 --> 00:06:18.309
of freedom (the black line).

00:06:18.309 --> 00:06:23.110
If we had less data, say 6 data points, we’d
only have 5 degrees of freedom which will

00:06:23.110 --> 00:06:27.719
give us a slightly different t-distribution
with fatter tails (the blue line), and therefore

00:06:27.719 --> 00:06:28.800
a different p-value.

00:06:28.800 --> 00:06:34.550
Our p-value of 0.001 tells us that we reject
the null that the mean number of bees per

00:06:34.550 --> 00:06:37.009
square mile is 15,000.

00:06:37.009 --> 00:06:41.259
And we couldn’t find that p-value without
knowing our degrees of freedom, because as

00:06:41.259 --> 00:06:47.460
we mentioned in a previous episode, t-distributions get more and more like a normal distribution

00:06:47.460 --> 00:06:52.550
as we get more and more independent information...aka degrees of freedom.

00:06:52.550 --> 00:06:57.229
In fact, it looks like the number of bees
may be higher than it was previously.

00:06:57.229 --> 00:06:58.409
Go bees!

00:06:58.409 --> 00:07:05.569
One thing to note, though: the 1,838 bee increase is statistically significant, but that just

00:07:05.569 --> 00:07:11.050
means that if the true bee count per square
mile was 15,000 then it’s unlikely that

00:07:11.050 --> 00:07:14.909
we’d get a sample mean of 16,838.

00:07:14.909 --> 00:07:19.789
But it doesn’t mean that this difference
is practically significant, or all that useful.

00:07:19.789 --> 00:07:27.349
An increase of 1,838 bees isn’t really that
big compared to the standard deviation, 5,420.

00:07:27.349 --> 00:07:34.319
If on average, we expect bee counts to vary
5,420 bees from the mean, then a change of

00:07:34.319 --> 00:07:37.919
1,838 may not be that important to us.

00:07:37.919 --> 00:07:41.990
For example, say that we treated half the
orchard with a bee pheromone...which bees

00:07:41.990 --> 00:07:44.160
love...and is thought to encourage them to
come back.

00:07:44.160 --> 00:07:48.349
Our statistical test on the difference between a group of bees exposed to the pheromone and

00:07:48.349 --> 00:07:53.789
a group not exposed revealed that there was a statistically significant difference of

00:07:53.789 --> 00:07:59.430
3,297 bees per square mile between the pheromone and non pheromone groups.

00:07:59.430 --> 00:08:05.659
But we still need to ask whether a difference of 3,297 bees is useful to the orchard owner?

00:08:05.659 --> 00:08:06.949
Those pheromones are pricey.

00:08:06.949 --> 00:08:09.369
And she wants to make sure that they’re
worth it.

00:08:09.369 --> 00:08:16.869
That 3,297 bee per square mile difference
is an increase of about 0.6 standard deviations.

00:08:16.869 --> 00:08:21.529
Remember that almost ALL of the data is within 2 standard deviations of the mean.

00:08:21.529 --> 00:08:25.520
So a difference of a little more than half
a standard deviation is a big deal..Maybe

00:08:25.520 --> 00:08:27.159
those pheromones are worth it.

00:08:27.159 --> 00:08:30.059
Sometimes statistical significance doesn't
give us the whole picture.

00:08:30.059 --> 00:08:33.300
You probably already use this kind of reasoning in your real life.

00:08:33.300 --> 00:08:36.930
Like when you're scrolling through your Instagram feed and see a former Bachelor contestant

00:08:36.930 --> 00:08:38.289
promoting a hair vitamin.

00:08:38.289 --> 00:08:42.650
A little Googling tells you that yes, this
vitamin does cause a statistically significant

00:08:42.650 --> 00:08:46.220
increase in hair growth, but only a few nanometers.

00:08:46.220 --> 00:08:50.980
Your hair normally grows about 12.7 millimeters a month plus or minus a millimeter.

00:08:50.980 --> 00:08:55.440
So, this vitamin has what we call a small
effect size.

00:08:55.440 --> 00:09:00.190
Effect size tells us how big the effect we
observed was, compared to random variation.

00:09:00.190 --> 00:09:04.930
It’s really important to pair our p-values
with effect sizes, because sometimes, we can

00:09:04.930 --> 00:09:09.990
get statistically significant effects, but
effect sizes that are so small, they don’t

00:09:09.990 --> 00:09:10.990
really matter to us.

00:09:10.990 --> 00:09:14.060
Let’s look at an educational supplement
called WOWZERBRAIN!.

00:09:14.060 --> 00:09:16.780
The creators of WOWZERBRAIN! do an experiment.

00:09:16.780 --> 00:09:22.010
They bring 90 kids into their center and randomly assign half of them to get the WOWZERBRAIN!

00:09:22.010 --> 00:09:25.940
supplemental materials, and the other half
as a control group.

00:09:25.940 --> 00:09:29.810
The control reads age appropriate books for the same amount of time that it takes to go

00:09:29.810 --> 00:09:32.140
through a WOWZERBRAIN! lesson.

00:09:32.140 --> 00:09:36.070
Once the data is collected, the WOWZERBRAIN! creators take a look at their data and find

00:09:36.070 --> 00:09:41.500
out that the kids who took part in the WOWZERBRAIN! intervention had a mean reading score improvement

00:09:41.500 --> 00:09:48.620
of about 1.329 points and the control group improved an average of 1.265 points.

00:09:48.620 --> 00:09:52.790
The first things the WOWZERBRAIN! researchers do is perform a two sample t-test, and find

00:09:52.790 --> 00:09:55.700
a t-value of -0.21.

00:09:55.700 --> 00:10:01.840
And a p-value 0.8 -- calculated using a t-distribution with 88 degrees of freedom.

00:10:01.840 --> 00:10:04.010
So they weren’t able to reject the null.

00:10:04.010 --> 00:10:11.080
Their effect size - substituted into our equation is only about 0.044, which is pretty small.

00:10:11.080 --> 00:10:15.240
That means that the kids that got WOWZERBRAIN! materials only had scores that were higher

00:10:15.240 --> 00:10:20.790
by about 1/23rd of the amount we expect students to vary just by chance.

00:10:20.790 --> 00:10:24.770
But despite the null result of their t-test,
the WOWZERBRAIN! creators look at the raw

00:10:24.770 --> 00:10:30.190
numbers and see that the kids who got WOWZERBRAIN! did score numerically higher, even though

00:10:30.190 --> 00:10:32.220
it wasn’t statistically significant.

00:10:32.220 --> 00:10:36.230
So they, like many researchers and scientists, think to themselves that maybe the reason

00:10:36.230 --> 00:10:41.861
that the t-test wasn’t significant was because they ran an underpowered experiment... with

00:10:41.861 --> 00:10:42.920
too small of a sample size.

00:10:42.920 --> 00:10:47.880
Since standard error is scaled by the square root of n then--all things equal--the larger

00:10:47.880 --> 00:10:53.300
our sample size, the smaller our standard
error and the larger our t-statistic will be.

00:10:53.300 --> 00:10:58.640
So, the researchers wonder whether they could detect an effect if they tested 10,000 children.

00:10:58.640 --> 00:11:07.200
And sure enough, with 10,000 kids, they got
a t-value of -2.218, with a p-value of 0.02886.

00:11:07.200 --> 00:11:10.510
Which is small enough to reject the null hypothesis!

00:11:10.510 --> 00:11:14.910
But notice that their effect size is still
the same...about 0.044.

00:11:14.910 --> 00:11:20.450
So the intensive WOWZERBRAIN! intervention, still only helped improve average reading

00:11:20.450 --> 00:11:22.480
scores by 0.064 points.

00:11:22.480 --> 00:11:25.380
P-values, as you can see, aren’t everything.

00:11:25.380 --> 00:11:29.680
They should always be looked at in the context of other measures, like effect sizes.

00:11:29.680 --> 00:11:34.160
P-values tell us whether it’s likely something happened by chance alone.

00:11:34.160 --> 00:11:38.630
Effect sizes help us figure out whether observed effects are practically significant to us.

00:11:38.630 --> 00:11:42.940
In this case, though the WOWZERBRAIN! creators achieved statistical significance, for many

00:11:42.940 --> 00:11:46.430
people they may have failed to achieve practical significance.

00:11:46.430 --> 00:11:50.980
Parents are unlikely to pay for a year round
educational program that only improves test

00:11:50.980 --> 00:11:53.780
scores by 0.064 points.

00:11:53.780 --> 00:11:57.420
We talk a lot about p-values, and that’s
because lots of people use them to do really

00:11:57.420 --> 00:11:58.420
important things.

00:11:58.420 --> 00:12:00.320
But they can’t stand alone.

00:12:00.320 --> 00:12:03.931
P-values are PART of the whole picture and
should be paired with other information, like

00:12:03.931 --> 00:12:04.931
an effect size.

00:12:04.931 --> 00:12:08.440
It’s like trying to buy an apartment based
on cost per square foot alone.

00:12:08.440 --> 00:12:12.910
Sure, maybe you find something for 75 cents per square foot….but it turns out it’s

00:12:12.910 --> 00:12:16.500
right next to the city dump...so maybe you’ll
pass on that one…

00:12:16.500 --> 00:12:21.780
And we need degrees of freedom to understand why smaller differences between means can

00:12:21.780 --> 00:12:24.960
be significant if you have a larger sample
size.

00:12:24.960 --> 00:12:28.280
The more information you have, the more accurate your estimates are.

00:12:28.280 --> 00:12:32.020
It’s why we might not bat an eye at the
fact that two people from two different countries

00:12:32.020 --> 00:12:37.200
have a height difference of 1 foot, but very
surprised if those two countries had an average

00:12:37.200 --> 00:12:39.180
height difference of 1 foot.

00:12:39.180 --> 00:12:42.900
And that’s about 0.3 meters for you people
using the metric system.

00:12:42.900 --> 00:12:49.480
Having more accurate information changes the threshold for what’s surprising or significant to us.

00:12:49.480 --> 00:12:51.320
Thanks for watching. I'll see you next time.

