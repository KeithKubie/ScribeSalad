WEBVTT
Kind: captions
Language: en

00:00:01.190 --> 00:00:04.340
MATT STEPHENSON: Good afternoon
and welcome.

00:00:04.340 --> 00:00:05.870
My name is Matt Stevenson.

00:00:05.870 --> 00:00:08.090
I'm a software engineer.

00:00:08.090 --> 00:00:12.190
I work on the Java runtime
for Google App Engine.

00:00:12.190 --> 00:00:14.730
Today I'd like to talk about
something that's been very

00:00:14.730 --> 00:00:18.150
important with what I work on
and what I've worked on in the

00:00:18.150 --> 00:00:20.520
past, which is how to build
applications that autoscale

00:00:20.520 --> 00:00:22.190
very well in Java.

00:00:25.180 --> 00:00:28.890
Autoscaling is an incredibly
important piece of Google's

00:00:28.890 --> 00:00:30.120
internal infrastructure.

00:00:30.120 --> 00:00:35.080
It allows us to efficiently
utilize the resources that we

00:00:35.080 --> 00:00:36.370
currently have internally.

00:00:40.520 --> 00:00:43.260
An autoscaling environment is
an environment with the

00:00:43.260 --> 00:00:46.500
capability to expand
and reduce capacity

00:00:46.500 --> 00:00:49.600
based on user demands.

00:00:49.600 --> 00:00:50.300
This is done by

00:00:50.300 --> 00:00:53.770
overprovisioning machines, typically.

00:00:53.770 --> 00:00:56.440
And for us it's really great,
because we get to have really

00:00:56.440 --> 00:00:58.700
effective utilization
of our resources.

00:00:58.700 --> 00:01:01.270
For some of you that
might be important.

00:01:01.270 --> 00:01:05.120
But for many of you,
that may not be the

00:01:05.120 --> 00:01:05.920
most important thing.

00:01:05.920 --> 00:01:06.620
You may have only one

00:01:06.620 --> 00:01:08.250
application that you're running.

00:01:08.250 --> 00:01:10.760
It may not make sense to
overprovision and have

00:01:10.760 --> 00:01:16.040
different applications consume
your resource pool over time.

00:01:16.040 --> 00:01:17.740
So I'll give you
a little story.

00:01:20.550 --> 00:01:22.380
A while back, I used
to work for a large

00:01:22.380 --> 00:01:24.950
online internet retailer.

00:01:24.950 --> 00:01:28.990
And I was on call.

00:01:28.990 --> 00:01:31.150
And it was a holiday week.

00:01:31.150 --> 00:01:36.840
And it was a little bit rough,
as it usually was.

00:01:36.840 --> 00:01:42.300
But they sold a lot of this
new device that year--

00:01:42.300 --> 00:01:44.850
a whole lot of this
new device.

00:01:44.850 --> 00:01:48.820
And I ended up getting paged.

00:01:48.820 --> 00:01:52.470
This device had a large group of
services that supported it,

00:01:52.470 --> 00:01:57.830
running behind, running inside
of our infrastructure.

00:01:57.830 --> 00:02:01.470
And those services were
scaled pretty well.

00:02:01.470 --> 00:02:04.020
That's what the team thought.

00:02:04.020 --> 00:02:06.010
But they had a big concern.

00:02:06.010 --> 00:02:07.450
And I was paged--

00:02:07.450 --> 00:02:09.660
kind of in a scramble to get
resources and be able to

00:02:09.660 --> 00:02:12.880
deploy their service to many,
many instances in a very short

00:02:12.880 --> 00:02:14.420
period of time--

00:02:14.420 --> 00:02:17.580
because they had sold a lot of
these devices, but not a lot

00:02:17.580 --> 00:02:20.880
of them had been
turned on yet.

00:02:20.880 --> 00:02:24.080
And the reason for this was that
many of them we're still

00:02:24.080 --> 00:02:25.680
on the packaging.

00:02:25.680 --> 00:02:31.130
And so over the next few days
at specific times, they were

00:02:31.130 --> 00:02:33.470
expecting these services
to get hit really,

00:02:33.470 --> 00:02:36.560
really, really hard.

00:02:36.560 --> 00:02:41.410
So in that sense, autoscaling
would have been a magical

00:02:41.410 --> 00:02:42.220
thing for us.

00:02:42.220 --> 00:02:43.230
I would not have been paged.

00:02:43.230 --> 00:02:46.200
It would not have been so much
use of engineering resources

00:02:46.200 --> 00:02:50.290
and so much of a scramble to
try and find additional

00:02:50.290 --> 00:02:57.120
computational resources
to support

00:02:57.120 --> 00:03:02.560
this influx of requests.

00:03:02.560 --> 00:03:05.840
So what does this
mean about Java?

00:03:05.840 --> 00:03:07.700
How does Java play into this?

00:03:07.700 --> 00:03:11.270
Java has an interesting
evolution.

00:03:11.270 --> 00:03:14.060
We started off really small
and simple with applets.

00:03:14.060 --> 00:03:16.570
Those consumed a very small
amount of memory.

00:03:16.570 --> 00:03:19.270
And the JVM was optimized
for that.

00:03:19.270 --> 00:03:23.190
And then we went from there and
grew into a much larger

00:03:23.190 --> 00:03:26.370
vendor-specific enterprise-
Java

00:03:26.370 --> 00:03:28.650
Enterprise Edition servers.

00:03:28.650 --> 00:03:31.140
And JVM was optimized
to fully consume

00:03:31.140 --> 00:03:32.030
these pieces of hardware.

00:03:32.030 --> 00:03:35.750
It was optimized for
CPU and memory.

00:03:35.750 --> 00:03:37.610
And that evolution continued.

00:03:37.610 --> 00:03:40.700
But at the same time, we started
having this really

00:03:40.700 --> 00:03:42.210
popular thing called
the internet.

00:03:42.210 --> 00:03:44.960
And so really the only thing
that people were building with

00:03:44.960 --> 00:03:48.240
Java Enterprise Edition were
web application resources.

00:03:48.240 --> 00:03:49.740
And so we started to have
containers that were

00:03:49.740 --> 00:03:50.950
optimized for that--

00:03:50.950 --> 00:03:54.610
things like JBoss and Spring
Application Server.

00:03:54.610 --> 00:04:02.280
And all of that kind of evolved
to build out to fully

00:04:02.280 --> 00:04:04.530
consume compute resources
again.

00:04:04.530 --> 00:04:06.380
But in that case, it was more
commodity hardware.

00:04:06.380 --> 00:04:09.750
It wasn't the big
application-specific mass of

00:04:09.750 --> 00:04:12.880
machines you were purchasing
from these vendors.

00:04:12.880 --> 00:04:16.500
And again, the JVM was optimized
for memory and CPU

00:04:16.500 --> 00:04:17.940
utilization.

00:04:17.940 --> 00:04:22.110
But now we're kind of in a new
generation of Java runtimes

00:04:22.110 --> 00:04:27.190
and Java VMs, or usage of the
VM, where you're seeing very

00:04:27.190 --> 00:04:28.820
small containers--

00:04:28.820 --> 00:04:31.100
things like Jetty--

00:04:31.100 --> 00:04:35.230
just running very small
frameworks, like Drop Wizard

00:04:35.230 --> 00:04:39.630
and things like App Engine
coming around.

00:04:39.630 --> 00:04:42.860
Along with that, now you're
seeing a lot of Java

00:04:42.860 --> 00:04:45.570
development in another platform
that's about the same

00:04:45.570 --> 00:04:48.670
size, if even larger than what
you usually have in an

00:04:48.670 --> 00:04:51.590
overprovisioned infrastructure
as a service or

00:04:51.590 --> 00:04:53.680
platform as a service.

00:04:53.680 --> 00:04:58.580
Because like your mobile phones
today are massively

00:04:58.580 --> 00:05:03.250
more powerful than say a Google
Compute Engine micro

00:05:03.250 --> 00:05:08.420
instance or an App Engine F1,
or even an F2 instance.

00:05:08.420 --> 00:05:11.070
And again, Spring and
JBoss and such are

00:05:11.070 --> 00:05:12.770
still very widely used.

00:05:12.770 --> 00:05:15.580
And they are very,
very effective on

00:05:15.580 --> 00:05:18.830
larger pieces of hardware.

00:05:18.830 --> 00:05:20.550
So what does this mean
for App Engine?

00:05:23.250 --> 00:05:25.760
App Engine has a Java runtime.

00:05:25.760 --> 00:05:30.320
We can automatically scale
to meet your needs.

00:05:30.320 --> 00:05:34.020
And it works pretty well
for the average user.

00:05:34.020 --> 00:05:36.330
You're not really going
to see much limitation

00:05:36.330 --> 00:05:39.310
when it comes to that.

00:05:39.310 --> 00:05:42.035
So let me give you a quick demo
of what that looks like.

00:05:45.190 --> 00:05:49.900
I'm just using a pretty simple
tool here called jMeter.

00:05:49.900 --> 00:05:53.490
And if you haven't messed with
it yet, then you probably

00:05:53.490 --> 00:05:55.110
should take a look.

00:05:55.110 --> 00:05:58.620
All I'm going to do here is
hit my App Engine instance

00:05:58.620 --> 00:06:01.860
that's running, with about 1,000
concurrent users, 100

00:06:01.860 --> 00:06:03.040
times over.

00:06:03.040 --> 00:06:06.040
So let's just do that
real quick.

00:06:06.040 --> 00:06:08.460
So as you can see, I'm pounding
it pretty hard.

00:06:13.310 --> 00:06:16.710
And let's go take a look
at App Engine here.

00:06:16.710 --> 00:06:21.400
And we can take a look at how
many instances I have running.

00:06:21.400 --> 00:06:25.700
I'm hitting the normal version
of my application.

00:06:25.700 --> 00:06:29.160
So I've got a good deal of
instances running here.

00:06:29.160 --> 00:06:31.270
And these are all pretty
healthy instances.

00:06:31.270 --> 00:06:34.910
They're all responding
pretty well.

00:06:34.910 --> 00:06:39.330
So let's take a look at what
this looks like in a graph.

00:06:39.330 --> 00:06:43.240
And as we can see, we had some
loading requests that hit.

00:06:43.240 --> 00:06:46.120
We were thankfully you
know, subsecond.

00:06:46.120 --> 00:06:49.700
And everything seems to respond
just perfectly fine.

00:06:58.390 --> 00:07:03.000
So what are some problems when
it comes to trying to build a

00:07:03.000 --> 00:07:06.420
JAVA application that runs on
top of an overprovisioned

00:07:06.420 --> 00:07:10.070
environment or a platform as a
service that utilizes very

00:07:10.070 --> 00:07:13.640
light resources so that you can
do very cost effective and

00:07:13.640 --> 00:07:15.070
very powerful autoscaling?

00:07:18.820 --> 00:07:21.550
Large deployments can
be very complicated.

00:07:21.550 --> 00:07:25.570
And in that I mean, deployments
that have a very

00:07:25.570 --> 00:07:30.430
large amount of resources
allocated to them--

00:07:30.430 --> 00:07:32.830
things that where you have
a very complex dependency

00:07:32.830 --> 00:07:34.330
structures--

00:07:34.330 --> 00:07:38.690
automatically instantiating
classes can be overly complex,

00:07:38.690 --> 00:07:42.760
and can be very difficult for a
platform as a service to be

00:07:42.760 --> 00:07:46.340
able to keep up with.

00:07:46.340 --> 00:07:50.540
Code generation can be very
problematic because in many

00:07:50.540 --> 00:07:55.160
times, you're going be spinning
up and spinning down

00:07:55.160 --> 00:07:56.650
instances very quickly.

00:07:56.650 --> 00:08:00.420
So runtime generation of code
can be very, very, very

00:08:00.420 --> 00:08:05.810
difficult for the runtime
to keep up with--

00:08:05.810 --> 00:08:07.770
as well as if you have
Security Managers

00:08:07.770 --> 00:08:08.730
and things like that.

00:08:08.730 --> 00:08:12.280
Managing shared state can be a
big problem, and persisting

00:08:12.280 --> 00:08:14.250
configuration both can
be [? moral ?]

00:08:14.250 --> 00:08:18.970
problems, not really specific to
the Java world, but more in

00:08:18.970 --> 00:08:26.660
general when it comes to just
having that many cross

00:08:26.660 --> 00:08:30.870
connecting, that much crosstalk,
with the individual

00:08:30.870 --> 00:08:33.620
instances coming up.

00:08:33.620 --> 00:08:35.220
So large deployments--

00:08:35.220 --> 00:08:39.600
this as an example of just some
Maven that I've seen in

00:08:39.600 --> 00:08:43.250
applications that I've had
to take a look at.

00:08:43.250 --> 00:08:45.270
And these kind of dependencies,
whenever you

00:08:45.270 --> 00:08:47.730
have really complex dependency
structures and you end up with

00:08:47.730 --> 00:08:51.290
a lot of artifacts, it can be
very, very difficult to track

00:08:51.290 --> 00:08:54.600
down what's going on.

00:08:54.600 --> 00:08:57.750
This is kind of actually what
I prefer in terms of Maven

00:08:57.750 --> 00:08:58.400
dependencies--

00:08:58.400 --> 00:09:02.990
something really lightweight,
using just Guice with Jersey

00:09:02.990 --> 00:09:04.140
and Jackson.

00:09:04.140 --> 00:09:06.250
This is more like for if you're
building in like a

00:09:06.250 --> 00:09:08.560
RESTful web service--

00:09:08.560 --> 00:09:10.830
if you're building it from
scratch, not necessarily using

00:09:10.830 --> 00:09:12.780
cloud end points.

00:09:12.780 --> 00:09:16.320
Let me show you real quick
what it looks like--

00:09:16.320 --> 00:09:18.440
what I'm talking about
in terms of what's

00:09:18.440 --> 00:09:21.870
going on here in Maven.

00:09:21.870 --> 00:09:27.650
So I've got an application
that's got a pretty complex

00:09:27.650 --> 00:09:28.560
dependency structure.

00:09:28.560 --> 00:09:31.520
And I can kind of see that
because all of a sudden, I'm

00:09:31.520 --> 00:09:35.050
kind of just downloading the
entire world to try and get

00:09:35.050 --> 00:09:38.260
this application built.

00:09:38.260 --> 00:09:42.110
Now if I really want to make
sure, if I really want to take

00:09:42.110 --> 00:09:43.430
a look at everything and see--

00:09:43.430 --> 00:09:46.510
I'm sorry, that's a
little bit small--

00:09:46.510 --> 00:09:48.840
if I want to see what's going
on really in my dependencies

00:09:48.840 --> 00:09:51.125
in Maven, that's actually
really easy.

00:09:57.150 --> 00:10:02.290
A Maven dependency plug-in can
give me a really good idea.

00:10:02.290 --> 00:10:05.150
And there's a whole lot of IDE
integrations that make this a

00:10:05.150 --> 00:10:06.300
lot prettier.

00:10:06.300 --> 00:10:10.400
But as you can see, this
is relatively complex.

00:10:10.400 --> 00:10:13.040
If I wanted to try and make this
a lot simpler, I'm pretty

00:10:13.040 --> 00:10:14.290
sure I could.

00:10:18.440 --> 00:10:19.690
So let's take a look here.

00:10:25.240 --> 00:10:29.480
So along with that, the other
problem that I see a lot is

00:10:29.480 --> 00:10:32.470
automatically instantiating
classes.

00:10:32.470 --> 00:10:34.510
This is kind of a problem
because it can get a little

00:10:34.510 --> 00:10:36.110
bit of control.

00:10:36.110 --> 00:10:38.420
And if you're using frameworks
to do a whole lot of work for

00:10:38.420 --> 00:10:42.930
you to instantiate and destroy
classes, and manage the life

00:10:42.930 --> 00:10:46.200
cycle of those objects, you're
going to have a lot of

00:10:46.200 --> 00:10:49.510
problems refactoring later on to
try and make sure that you

00:10:49.510 --> 00:10:52.610
are not accidentally creating
objects and such.

00:10:52.610 --> 00:10:54.910
And one of the things that
always gets me about this is

00:10:54.910 --> 00:10:58.300
is that "New" is a really
fast operation in Java.

00:10:58.300 --> 00:11:00.720
So this is kind of an example of
something that I see a lot

00:11:00.720 --> 00:11:02.440
of people doing, where
you have a--

00:11:07.270 --> 00:11:08.770
my goodness, OK.

00:11:08.770 --> 00:11:12.850
This is a problem that I see a
lot of people have with Spring

00:11:12.850 --> 00:11:13.470
applications.

00:11:13.470 --> 00:11:16.760
This is an example of using
an annotation to try and

00:11:16.760 --> 00:11:20.110
automatically instantiate
a class.

00:11:20.110 --> 00:11:22.690
So what this is is, you have a
class that's annotated with a

00:11:22.690 --> 00:11:26.300
specific annotation, and then in
Spring you can define, you

00:11:26.300 --> 00:11:29.852
can say, scan the entire class
path to try and find any of

00:11:29.852 --> 00:11:33.170
these classes that I might
want to instantiate.

00:11:33.170 --> 00:11:35.500
The way that Spring does this,
and the way that a lot of

00:11:35.500 --> 00:11:39.410
other frameworks does this, is
it they take all of these JARs

00:11:39.410 --> 00:11:40.790
that you have on your
class path.

00:11:40.790 --> 00:11:43.600
So again, if you have a lot of
JARs, if you have a really

00:11:43.600 --> 00:11:47.550
large deployment, this can
be even more of an issue.

00:11:47.550 --> 00:11:49.850
It'll take all of these
different JARs.

00:11:49.850 --> 00:11:52.740
It'll, in this case in Spring,
you can specify a

00:11:52.740 --> 00:11:54.070
package to filter on.

00:11:54.070 --> 00:11:56.530
In some other examples, you
might find that you can

00:11:56.530 --> 00:12:00.670
specify regexes on the
class name and such.

00:12:00.670 --> 00:12:02.960
But it's got to go and look at
the table of contents of every

00:12:02.960 --> 00:12:07.880
single JAR file, if it hasn't
already, try and figure out

00:12:07.880 --> 00:12:11.530
which class definitions it might
want to go see if they

00:12:11.530 --> 00:12:13.590
have annotations on.

00:12:13.590 --> 00:12:16.420
And in order to get that, to
determine if there's an

00:12:16.420 --> 00:12:18.540
annotation on any of those
classes, it's going to read

00:12:18.540 --> 00:12:20.970
all of those class
definitions in.

00:12:20.970 --> 00:12:24.270
It's probably going to use ASM
or something like that to

00:12:24.270 --> 00:12:26.920
locate the actual annotation
itself.

00:12:26.920 --> 00:12:30.800
So you're not only reading in
the byte code, you're parsing

00:12:30.800 --> 00:12:31.980
the byte code.

00:12:31.980 --> 00:12:33.520
You're processing it.

00:12:33.520 --> 00:12:36.260
And then finally, you're making
a decision of whether

00:12:36.260 --> 00:12:39.330
or not to instantiate
the class.

00:12:39.330 --> 00:12:40.990
So this can be really,
really problematic.

00:12:40.990 --> 00:12:43.650
And to be perfectly honest if
you only have a few classes,

00:12:43.650 --> 00:12:47.600
it can be this easy just to have
the class instantiated by

00:12:47.600 --> 00:12:49.390
your framework.

00:12:49.390 --> 00:12:53.810
And I could do even less code
than this and just write "new

00:12:53.810 --> 00:12:57.150
simple movie listing."

00:12:57.150 --> 00:13:00.710
So what's it look like when App
Engine app is doing a lot

00:13:00.710 --> 00:13:02.290
of this automatic class
instantiating?

00:13:07.530 --> 00:13:08.815
Let's take a look here.

00:13:11.840 --> 00:13:12.210
OK.

00:13:12.210 --> 00:13:14.710
So again, this is jMeter,
really great--

00:13:14.710 --> 00:13:18.996
Apache jMeter, sorry-- a
really great program.

00:13:18.996 --> 00:13:22.640
Let me make sure I've got this
all set up correctly.

00:13:22.640 --> 00:13:25.500
What I'm looking at is, I can
define an HDP request

00:13:25.500 --> 00:13:26.780
underneath thread group.

00:13:26.780 --> 00:13:29.520
A thread group is where I define
how many concurrent

00:13:29.520 --> 00:13:32.580
users and how often they're
hitting this service.

00:13:32.580 --> 00:13:34.990
So let's give this a go.

00:13:34.990 --> 00:13:38.880
Let me make sure I don't
have any results here.

00:13:38.880 --> 00:13:42.470
So now I'm kind of beating
up the service again.

00:13:42.470 --> 00:13:44.610
We can actually take a look and
see how many instances I

00:13:44.610 --> 00:13:45.860
have a running.

00:13:49.240 --> 00:13:52.230
And here I have a few
less instances.

00:13:52.230 --> 00:13:54.410
Well, we haven't ramped
up all the way yet,

00:13:54.410 --> 00:13:55.946
so let's see here.

00:13:55.946 --> 00:13:56.960
There we go.

00:13:56.960 --> 00:13:58.811
We're starting to get there.

00:13:58.811 --> 00:14:01.212
And we can actually
take a look.

00:14:01.212 --> 00:14:05.850
We should be able to graph
these at this point.

00:14:05.850 --> 00:14:08.730
And so we're kind of now at
about 20 seconds to actually

00:14:08.730 --> 00:14:10.880
get our first few requests in.

00:14:10.880 --> 00:14:12.770
So this is what it looks like
whenever you have an

00:14:12.770 --> 00:14:17.200
application that you're doing
a whole lot of work to avoid

00:14:17.200 --> 00:14:20.510
writing a lot of code
that could pretty

00:14:20.510 --> 00:14:21.760
easily just be written.

00:14:27.610 --> 00:14:28.860
OK.

00:14:35.360 --> 00:14:37.670
Code generation--

00:14:37.670 --> 00:14:40.850
this is my code.

00:14:40.850 --> 00:14:44.010
I wrote this a long time ago.

00:14:44.010 --> 00:14:48.380
And every now and then, I use
something like this as an

00:14:48.380 --> 00:14:49.250
interview question.

00:14:49.250 --> 00:14:54.530
So if you can spot the most
terrible mistake I made in

00:14:54.530 --> 00:14:57.040
this, grab me.

00:14:57.040 --> 00:14:59.730
I've got office hours
and stuff later.

00:14:59.730 --> 00:15:01.640
I'd love to chat about how
terrible this code is with

00:15:01.640 --> 00:15:04.570
anyone who wants to tell
me how bad it is.

00:15:04.570 --> 00:15:06.710
The reason this code is terrible
in the context of

00:15:06.710 --> 00:15:09.260
what I'm telling you today
though is, what this is, this

00:15:09.260 --> 00:15:10.750
is an aspect.

00:15:10.750 --> 00:15:12.900
It's designed--

00:15:12.900 --> 00:15:16.610
it's an around advice aspect
for Spring Aspect-Oriented

00:15:16.610 --> 00:15:18.030
Programming--

00:15:18.030 --> 00:15:20.210
the Spring AOP support.

00:15:20.210 --> 00:15:22.120
And what it does,
is it actually

00:15:22.120 --> 00:15:24.520
creates a little class.

00:15:24.520 --> 00:15:25.680
It creates a little
bit of byte code

00:15:25.680 --> 00:15:28.710
that wraps your class.

00:15:28.710 --> 00:15:31.050
And whenever an exception
is thrown, it logs that

00:15:31.050 --> 00:15:36.280
exception, and re-throws it,
which is kind of weird.

00:15:36.280 --> 00:15:37.570
But if you look--

00:15:40.580 --> 00:15:42.720
I don't know what
that is doing.

00:15:42.720 --> 00:15:43.520
OK.

00:15:43.520 --> 00:15:44.250
[INAUDIBLE].

00:15:44.250 --> 00:15:46.260
Good.

00:15:46.260 --> 00:15:49.620
If you take a look at this "at
around" here, this is called a

00:15:49.620 --> 00:15:51.630
Point Cut in Aspect-Oriented
Programming.

00:15:51.630 --> 00:15:53.400
And this Point Cut in particular
is going to be

00:15:53.400 --> 00:15:55.770
hitting every single
public method.

00:15:55.770 --> 00:15:58.190
So that means that for every
single public method in my

00:15:58.190 --> 00:16:02.730
entire application, I'm going to
generate some code, and put

00:16:02.730 --> 00:16:04.560
that in the way.

00:16:04.560 --> 00:16:08.130
So there's a whole lot of
frameworks that just relaxed

00:16:08.130 --> 00:16:09.236
to doing this.

00:16:09.236 --> 00:16:11.100
This is something that you
should probably avoid when

00:16:11.100 --> 00:16:12.760
ever you're building
new applications.

00:16:12.760 --> 00:16:16.780
But a lot of frameworks do
run-time generation of code.

00:16:16.780 --> 00:16:20.290
If you're working in something
and you can't really get rid

00:16:20.290 --> 00:16:22.500
of a lot of this Aspect-Oriented
Programming,

00:16:22.500 --> 00:16:23.440
even though it's--

00:16:23.440 --> 00:16:25.590
I don't like it.

00:16:25.590 --> 00:16:29.400
You could definitely do things
like use compile time

00:16:29.400 --> 00:16:32.580
generation of the aspects,
generation of the code.

00:16:32.580 --> 00:16:35.770
And you can also do with
aspectJ, I believe you can do

00:16:35.770 --> 00:16:38.700
compile, like build
compile-time

00:16:38.700 --> 00:16:41.050
class byte code weaving.

00:16:41.050 --> 00:16:42.210
That's what I was looking for.

00:16:42.210 --> 00:16:42.570
All right.

00:16:42.570 --> 00:16:45.940
So what does it look like when
we have an application that

00:16:45.940 --> 00:16:47.190
does a lot of this?

00:16:51.190 --> 00:16:54.370
So I've got another jMeter
demo all spun up

00:16:54.370 --> 00:16:56.280
and ready to go.

00:16:56.280 --> 00:16:57.530
Let's make sure that--

00:16:59.710 --> 00:17:01.450
see yep, that's right.

00:17:01.450 --> 00:17:02.190
That's all right.

00:17:02.190 --> 00:17:03.970
OK.

00:17:03.970 --> 00:17:06.800
Let's give it a shot.

00:17:06.800 --> 00:17:08.450
So we can actually go and
take a look again

00:17:08.450 --> 00:17:09.859
and see what's happening.

00:17:09.859 --> 00:17:12.480
Now the interesting thing about
doing a lot of class

00:17:12.480 --> 00:17:15.940
generation is that you're
actually going to end up using

00:17:15.940 --> 00:17:20.160
a lot of permanent generation
space in the VM to track all

00:17:20.160 --> 00:17:22.059
of the generated classes.

00:17:22.059 --> 00:17:24.750
And that's another thing that's
really problematic,

00:17:24.750 --> 00:17:27.730
because it's really
hard to tune a VM.

00:17:27.730 --> 00:17:30.930
And if you're on a platform as
a service, do you really want

00:17:30.930 --> 00:17:33.770
to like have to really specify a
lot of tuning parameters for

00:17:33.770 --> 00:17:35.630
your specific VMs?

00:17:35.630 --> 00:17:38.430
It can be really, really,
really troublesome.

00:17:38.430 --> 00:17:40.700
As you can see, we're spinning
up a lot of instances

00:17:40.700 --> 00:17:42.920
to deal with this.

00:17:42.920 --> 00:17:47.460
So let's take a look at what
this looks like in a graph.

00:17:47.460 --> 00:17:49.190
Yeah, that doesn't
look too clean.

00:17:49.190 --> 00:17:50.590
We're up at 22 seconds.

00:17:50.590 --> 00:17:53.410
And now you're kind of seeing
this really bizarre behavior

00:17:53.410 --> 00:17:54.670
where we didn't have
that before.

00:17:54.670 --> 00:17:56.530
You see this kind of
arc like this.

00:17:56.530 --> 00:18:01.780
And a lot of that is you're
going to end up spinning up

00:18:01.780 --> 00:18:05.280
more instances over time to
try and handle that versus

00:18:05.280 --> 00:18:08.100
like being able to really
blow through it.

00:18:08.100 --> 00:18:10.210
And I don't really have data
points on this graph.

00:18:10.210 --> 00:18:10.960
It's unfortunate.

00:18:10.960 --> 00:18:13.110
OK.

00:18:13.110 --> 00:18:14.300
Cool.

00:18:14.300 --> 00:18:15.665
So that's kind of what
that looks like.

00:18:15.665 --> 00:18:18.110
And as a result, that's
something you should probably

00:18:18.110 --> 00:18:20.170
avoid doing in your
application.

00:18:20.170 --> 00:18:23.670
It's not something that's
specific to App Engine even.

00:18:23.670 --> 00:18:25.740
Because you're going to end up
with this kind of problem if

00:18:25.740 --> 00:18:32.680
you're using anything, if you're
going to end up having

00:18:32.680 --> 00:18:34.170
a lot of untuned JVMs.

00:18:36.870 --> 00:18:41.550
So the next few are JAVA
specific, because they are

00:18:41.550 --> 00:18:44.900
things that typically
JAVA applications

00:18:44.900 --> 00:18:46.620
have done in the past.

00:18:46.620 --> 00:18:49.800
Managing shared state--

00:18:49.800 --> 00:18:56.310
it's kind of not the best idea
to do a whole lot of cross

00:18:56.310 --> 00:18:58.640
talk between your application
instances as they're starting

00:18:58.640 --> 00:19:00.530
up, if you're starting up a ton
of application instances

00:19:00.530 --> 00:19:01.930
at the same time.

00:19:01.930 --> 00:19:03.560
And so in this case, we're kind
of just grabbing some

00:19:03.560 --> 00:19:07.960
information out of our
persistence mechanism, doing

00:19:07.960 --> 00:19:11.300
on each request from a user.

00:19:11.300 --> 00:19:15.410
And this can be really
problematic because you're

00:19:15.410 --> 00:19:17.620
going to end up autoscaling
in a very brief

00:19:17.620 --> 00:19:19.320
period of time, generally.

00:19:19.320 --> 00:19:23.860
So all of these requests are
going to hit some service to

00:19:23.860 --> 00:19:26.470
try and pull in all
this context.

00:19:26.470 --> 00:19:29.250
So you have to be very careful
not to try and do too many.

00:19:29.250 --> 00:19:33.330
You can end up doing too many
requests on start up in these

00:19:33.330 --> 00:19:34.910
types of applications.

00:19:34.910 --> 00:19:37.940
And caching can kind of help,
but it's not going to be the

00:19:37.940 --> 00:19:39.190
most effective.

00:19:41.850 --> 00:19:44.020
Another problem that goes
along the same vein is

00:19:44.020 --> 00:19:47.120
persisting configuration.

00:19:47.120 --> 00:19:48.350
In the last several
years, I've kind

00:19:48.350 --> 00:19:49.250
of shifted my opinion.

00:19:49.250 --> 00:19:53.010
I used to be really behind
having your configuration

00:19:53.010 --> 00:19:57.660
persisted in your data store
or in your database.

00:19:57.660 --> 00:20:01.410
The problem with this is that
again, when you have a whole

00:20:01.410 --> 00:20:03.470
bunch of instances of your
application start up at the

00:20:03.470 --> 00:20:07.410
same time, they'll just pound
that back-end resource.

00:20:07.410 --> 00:20:11.160
This was a big problem back
when I worked at unnamed,

00:20:11.160 --> 00:20:12.410
large internet retailer.

00:20:14.890 --> 00:20:20.130
And so it's what I've come to
do, is actually just work on

00:20:20.130 --> 00:20:24.970
trying to build that
configuration into a my source

00:20:24.970 --> 00:20:27.700
code, into the source itself.

00:20:27.700 --> 00:20:29.890
Build and deploy that
configuration along with my

00:20:29.890 --> 00:20:31.120
application.

00:20:31.120 --> 00:20:35.510
And maybe just keep a few keys
available so I can switch in

00:20:35.510 --> 00:20:37.060
and out a few of those
properties.

00:20:37.060 --> 00:20:40.880
Like say, I want to use the
development, my development

00:20:40.880 --> 00:20:41.600
configuration.

00:20:41.600 --> 00:20:43.640
I want to use my QA
configuration or

00:20:43.640 --> 00:20:45.370
something like that.

00:20:45.370 --> 00:20:48.420
And what you're seeing in this
code here is just kind of

00:20:48.420 --> 00:20:50.860
something that where you're
generating some kind of shared

00:20:50.860 --> 00:20:53.730
secret on the first request and
start trying to persist it

00:20:53.730 --> 00:20:55.000
and re-get it.

00:20:55.000 --> 00:20:57.180
Well, let's see what happens
whenever we have an

00:20:57.180 --> 00:20:59.670
application that does something
like this--

00:20:59.670 --> 00:21:02.350
see how this plays out.

00:21:07.290 --> 00:21:08.540
So jMeter again.

00:21:10.860 --> 00:21:13.460
We're going to spin up a bunch
instances again to see if we

00:21:13.460 --> 00:21:15.230
can handle all this load.

00:21:19.080 --> 00:21:24.520
And this is our App Engine
dashboard here with all the

00:21:24.520 --> 00:21:27.450
instances that are running.

00:21:27.450 --> 00:21:29.790
As you see here, we've got
a good deal of instances.

00:21:29.790 --> 00:21:33.660
We're spinning up way more.

00:21:33.660 --> 00:21:39.000
And when we take a look at this
graph, we'll see that

00:21:39.000 --> 00:21:45.030
we're doing OK in general, but
that we're still not handling

00:21:45.030 --> 00:21:48.940
user requests very quickly
for a little while.

00:21:48.940 --> 00:21:53.740
We're still not nearly like
what we have here.

00:21:53.740 --> 00:21:57.330
And unfortunately, since I'm
using the App Engine data

00:21:57.330 --> 00:22:01.130
store as what I'm persisting all
of my stuff with it, it's

00:22:01.130 --> 00:22:02.990
actually kind of fast and
pretty performant.

00:22:02.990 --> 00:22:04.540
So is Memcache.

00:22:04.540 --> 00:22:08.140
I'm sorry it's not quite as
crazy of a graph, but I could

00:22:08.140 --> 00:22:10.030
definitely try a
little harder.

00:22:10.030 --> 00:22:12.180
And as you can see also, I'm
spinning up tons and tons of

00:22:12.180 --> 00:22:13.660
instances to handle this--

00:22:13.660 --> 00:22:15.205
way more than my
other examples.

00:22:23.980 --> 00:22:25.590
OK.

00:22:25.590 --> 00:22:28.230
So what are some tools I've been
using and that I use to

00:22:28.230 --> 00:22:30.560
try and work on, like
work through these

00:22:30.560 --> 00:22:33.060
types of issues myself?

00:22:33.060 --> 00:22:35.010
I of course like to
use my build tool.

00:22:35.010 --> 00:22:36.770
And I think that it's incredibly
important to have a

00:22:36.770 --> 00:22:42.800
build tool that will manage
all of the relationships

00:22:42.800 --> 00:22:44.470
between the dependencies
in your application--

00:22:44.470 --> 00:22:48.200
something that you can easily
analyze your entire dependency

00:22:48.200 --> 00:22:51.090
closure and make sure you're not
bringing in a lot of stuff

00:22:51.090 --> 00:22:53.390
you don't need.

00:22:53.390 --> 00:22:56.420
Another thing that's really
useful is actually Proguard.

00:22:56.420 --> 00:22:58.910
And it's something that I've
been working on trying to get

00:22:58.910 --> 00:23:02.450
a little bit more of a paper
written up that would help

00:23:02.450 --> 00:23:04.540
developers use that
in App Engine.

00:23:04.540 --> 00:23:08.140
But it can really help you
reduce the amount of classes

00:23:08.140 --> 00:23:09.340
you're deploying--

00:23:09.340 --> 00:23:12.350
deploy only what you need.

00:23:12.350 --> 00:23:15.500
And in those cases, you actually
have really good

00:23:15.500 --> 00:23:19.810
cache locality when it comes
to the network file system

00:23:19.810 --> 00:23:24.370
that's going to be providing
your application to your

00:23:24.370 --> 00:23:27.680
individual application
instances.

00:23:27.680 --> 00:23:30.700
So that can help a whole lot.

00:23:30.700 --> 00:23:33.200
And then of course, I was using
Apache jMeter a lot in

00:23:33.200 --> 00:23:35.450
all the demos.

00:23:35.450 --> 00:23:37.450
Of course load testing-- people
are always concerned

00:23:37.450 --> 00:23:42.710
about that, but to be honest--

00:23:42.710 --> 00:23:44.310
well this is kind of
a crazy number.

00:23:44.310 --> 00:23:45.030
I'm sorry.

00:23:45.030 --> 00:23:46.870
I was going to reduce this.

00:23:46.870 --> 00:23:51.750
But it's cost me about $9.41
to run this demo.

00:23:51.750 --> 00:23:53.860
I don't know how
many times now.

00:23:53.860 --> 00:23:55.400
It's not that expensive
to just do

00:23:55.400 --> 00:23:58.655
some simple load tests.

00:23:58.655 --> 00:24:00.750
Let's see.

00:24:00.750 --> 00:24:05.510
AppStats is also a really
great tool.

00:24:05.510 --> 00:24:08.190
It's really useful for a
profiling all of your back-end

00:24:08.190 --> 00:24:12.380
RPC calls and making sure that
everything is smooth from that

00:24:12.380 --> 00:24:13.630
perspective.

00:24:17.610 --> 00:24:19.890
So go forth and scale.

00:24:19.890 --> 00:24:21.870
Build applications
that scale well.

00:24:21.870 --> 00:24:25.510
Build applications that
are very simple.

00:24:25.510 --> 00:24:29.210
Things that you have
very strong static

00:24:29.210 --> 00:24:32.630
analysis tools for.

00:24:32.630 --> 00:24:35.160
And have fun.

00:24:35.160 --> 00:24:40.110
My office hours are tomorrow
10:15 to 11 AM over at the

00:24:40.110 --> 00:24:42.530
Cloud Sandbox.

00:24:42.530 --> 00:24:46.470
And feel free to
come hit us up.

00:24:46.470 --> 00:24:47.720
Are there any questions?

00:24:50.080 --> 00:24:52.700
Please.

00:24:52.700 --> 00:24:53.240
Yes.

00:24:53.240 --> 00:24:56.150
AUDIENCE: So, a lot of
the [INAUDIBLE].

00:24:56.150 --> 00:24:58.580
FEMALE SPEAKER: Can he go to
the microphone, please.

00:24:58.580 --> 00:24:59.040
MATT STEPHENSON: Yeah.

00:24:59.040 --> 00:25:00.290
There's a microphone.

00:25:02.270 --> 00:25:03.220
Do you want to use
a microphone?

00:25:03.220 --> 00:25:04.890
Yeah.

00:25:04.890 --> 00:25:05.930
Or you can repeat what
you're saying if you

00:25:05.930 --> 00:25:06.636
don't want to use it.

00:25:06.636 --> 00:25:06.990
Fine.

00:25:06.990 --> 00:25:08.490
AUDIENCE: A lot of things you're
doing is trying to

00:25:08.490 --> 00:25:10.090
simplify the application
so that the

00:25:10.090 --> 00:25:11.330
footprint is smaller, right?

00:25:11.330 --> 00:25:11.980
This is--

00:25:11.980 --> 00:25:12.190
MATT STEPHENSON: Yes.

00:25:12.190 --> 00:25:14.760
AUDIENCE: But the other hand,
a lot of framework is trying

00:25:14.760 --> 00:25:16.820
to simplify workflow to
make things simple.

00:25:16.820 --> 00:25:20.220
Where do you reach the balance
between writing everything in

00:25:20.220 --> 00:25:23.130
your code versus making it
simple and tuning it?

00:25:23.130 --> 00:25:25.390
And would you do that
first when you're

00:25:25.390 --> 00:25:26.920
starting off a new app?

00:25:26.920 --> 00:25:28.920
MATT STEPHENSON: That's
an interesting point.

00:25:28.920 --> 00:25:31.260
I think that there's a really
good balance there.

00:25:31.260 --> 00:25:34.400
And the really good balance is
usually, I actually can use

00:25:34.400 --> 00:25:35.550
testing a lot--

00:25:35.550 --> 00:25:37.490
testing my application, testing
assumptions of my

00:25:37.490 --> 00:25:38.050
application--

00:25:38.050 --> 00:25:39.870
to try and strike
that boundary.

00:25:39.870 --> 00:25:43.270
Because if I want to really
test my application--

00:25:43.270 --> 00:25:45.410
and the frameworks that are
associated with my application

00:25:45.410 --> 00:25:46.670
are a part of that--

00:25:46.670 --> 00:25:48.580
I do need to test some
assumptions about those

00:25:48.580 --> 00:25:49.350
frameworks.

00:25:49.350 --> 00:25:52.220
I can't just go on those
frameworks on face value.

00:25:52.220 --> 00:25:55.810
So when it comes to trying
to leverage frameworks to

00:25:55.810 --> 00:25:58.320
simplify the amount of code
you're writing and your code

00:25:58.320 --> 00:26:01.550
flow, it means that you're going
to end up writing a lot

00:26:01.550 --> 00:26:06.710
of tests to make it so that you
can be able to understand

00:26:06.710 --> 00:26:09.750
what's going on under the covers
with those frameworks.

00:26:09.750 --> 00:26:13.530
So at a certain point, you can
kind of strike a boundary of

00:26:13.530 --> 00:26:17.380
like saying, look, if I
introduce this framework, I

00:26:17.380 --> 00:26:20.120
have to think about also all the
tests that I need to write

00:26:20.120 --> 00:26:23.200
to need to make sure I
understand all the assumptions

00:26:23.200 --> 00:26:26.460
that I'm bringing into my
dependency closure.

00:26:26.460 --> 00:26:29.700
From that, that kind of helps me
understand if a framework's

00:26:29.700 --> 00:26:31.210
going to be valuable or not.

00:26:31.210 --> 00:26:34.030
And I mean, I have to play with
it a bit, usually myself,

00:26:34.030 --> 00:26:36.510
to make sure that it's what
I really want to use.

00:26:36.510 --> 00:26:39.340
Was that good?

00:26:39.340 --> 00:26:40.750
AUDIENCE: Hi.

00:26:40.750 --> 00:26:44.580
So let's say that you finally
convinced your employer that

00:26:44.580 --> 00:26:48.450
dependency management tools
are a good thing.

00:26:48.450 --> 00:26:49.380
MATT STEPHENSON:
That is great.

00:26:49.380 --> 00:26:52.730
AUDIENCE: And then they turn to
you and say, OK, we don't

00:26:52.730 --> 00:26:54.250
want an instinctual answer.

00:26:54.250 --> 00:26:55.530
We don't want your
gut reaction.

00:26:55.530 --> 00:26:58.360
What we want to do is, we want
you to go and actually assess

00:26:58.360 --> 00:27:01.100
them and report back to us
what you can about the

00:27:01.100 --> 00:27:02.100
different tools.

00:27:02.100 --> 00:27:04.690
We really want to make an
objective as opposed to an

00:27:04.690 --> 00:27:06.680
emotional decision here.

00:27:06.680 --> 00:27:09.250
Do you have any advice
for me on how to move

00:27:09.250 --> 00:27:12.620
forward doing that?

00:27:12.620 --> 00:27:15.200
MATT STEPHENSON: So I guess my
objective stance on that is

00:27:15.200 --> 00:27:19.730
to, if I want to objectively
evaluate different build tools

00:27:19.730 --> 00:27:22.960
and different dependency
management tools, it's best if

00:27:22.960 --> 00:27:25.980
everything's kind of working
together really well.

00:27:25.980 --> 00:27:29.910
So having something that's
very mature is useful.

00:27:29.910 --> 00:27:33.050
But my personal preference
has ended up being

00:27:33.050 --> 00:27:34.000
Maven for right now.

00:27:34.000 --> 00:27:38.110
Like, I like Gradle, but Maven
ends up, everything kind of

00:27:38.110 --> 00:27:39.785
works together, as long
as I keep it simple.

00:27:39.785 --> 00:27:40.040
You know.

00:27:40.040 --> 00:27:45.820
So I think that having a full
build toolset that works

00:27:45.820 --> 00:27:48.320
together really well is
really important.

00:27:48.320 --> 00:27:49.660
Testing that out.

00:27:49.660 --> 00:27:51.635
And then being able to--

00:27:51.635 --> 00:27:53.610
Oh, the other thing that's
really great is IDE

00:27:53.610 --> 00:27:56.490
integrations, so which is like
one of the big reasons why we

00:27:56.490 --> 00:27:58.950
got behind Maven on the App
Engine chain was because then,

00:27:58.950 --> 00:28:01.140
all of a sudden, IntelliJ
is a lot nicer and

00:28:01.140 --> 00:28:02.130
everything's lot nicer.

00:28:02.130 --> 00:28:03.660
NetBeans is a lot nice.

00:28:03.660 --> 00:28:08.060
So I would say IDE integrations
and having a tool

00:28:08.060 --> 00:28:11.590
set that's complete and whole,
in and of itself.

00:28:11.590 --> 00:28:12.150
AUDIENCE: Thank you.

00:28:12.150 --> 00:28:12.690
MATT STEPHENSON: Is a good?

00:28:12.690 --> 00:28:13.170
AUDIENCE: Yeah.

00:28:13.170 --> 00:28:16.050
Thank you.

00:28:16.050 --> 00:28:16.260
AUDIENCE: Hi.

00:28:16.260 --> 00:28:18.980
We use Spring MVC quite a
bit in our applications.

00:28:18.980 --> 00:28:21.360
And you give the example of
doing the single bean

00:28:21.360 --> 00:28:22.140
instantiations.

00:28:22.140 --> 00:28:24.570
Can you give any other tips
for optimizing Spring MVC

00:28:24.570 --> 00:28:26.430
applications on App Engine?

00:28:26.430 --> 00:28:26.830
MATT STEPHENSON: Yeah.

00:28:26.830 --> 00:28:31.020
So if you're doing, so Spring
MVC is really big on the

00:28:31.020 --> 00:28:32.960
automatic instantiation
of classes.

00:28:32.960 --> 00:28:36.900
And there's potentially a lot of
AOP that you can get mixed

00:28:36.900 --> 00:28:39.280
in there if you're using some
of the security features in

00:28:39.280 --> 00:28:41.970
Spring, I believe.

00:28:41.970 --> 00:28:44.920
And so those two, you kind of
have to be careful with what

00:28:44.920 --> 00:28:46.410
all you're--

00:28:46.410 --> 00:28:48.770
whenever you're using Spring AOP
in there-- what all you're

00:28:48.770 --> 00:28:50.290
going to be surrounding
with Advice.

00:28:53.030 --> 00:28:58.240
And then I would also say
that trying to use lazy

00:28:58.240 --> 00:29:02.910
initialization wherever
you can for beans.

00:29:02.910 --> 00:29:05.100
Lazy initialization is a really
careful one though.

00:29:05.100 --> 00:29:07.330
Because whenever you use lazy
initialization, you're going

00:29:07.330 --> 00:29:09.640
to be creating a lot of extra
classes in the middle there.

00:29:12.640 --> 00:29:13.510
Yeah.

00:29:13.510 --> 00:29:17.050
And the reason to do lazy
loading is to try and amortize

00:29:17.050 --> 00:29:20.930
all that cost of starting up
your application over time.

00:29:20.930 --> 00:29:21.220
AUDIENCE: Great.

00:29:21.220 --> 00:29:21.930
Thank you very much

00:29:21.930 --> 00:29:24.450
MATT STEPHENSON: Sure.

00:29:24.450 --> 00:29:25.710
AUDIENCE: Hey there.

00:29:25.710 --> 00:29:26.690
Two part question.

00:29:26.690 --> 00:29:29.910
Do you feel like--

00:29:29.910 --> 00:29:31.340
you had a lot of good
anti-patterns.

00:29:31.340 --> 00:29:34.130
And reducing the amount of
libraries and dependency seems

00:29:34.130 --> 00:29:35.020
like a good idea.

00:29:35.020 --> 00:29:36.770
Do you feel like there's a
correlation between more

00:29:36.770 --> 00:29:40.390
realistic applications and
more larger uses of more

00:29:40.390 --> 00:29:41.640
libraries--

00:29:45.020 --> 00:29:48.050
as opposed to like a load driver
that you were showing?

00:29:48.050 --> 00:29:49.300
MATT STEPHENSON: Yeah.

00:29:52.470 --> 00:29:52.890
Yeah.

00:29:52.890 --> 00:29:55.830
I would say that for
applications that are built

00:29:55.830 --> 00:29:58.850
where you have a single
instantiated app--

00:29:58.850 --> 00:30:01.460
like a single version, a
single piece of that

00:30:01.460 --> 00:30:03.940
application is instantiated
at a time--

00:30:03.940 --> 00:30:07.690
so if I'm building a very large
application, I generally

00:30:07.690 --> 00:30:09.940
build a lot of different smaller
services that I'm

00:30:09.940 --> 00:30:11.710
going to run behind
that application.

00:30:11.710 --> 00:30:12.540
AUDIENCE: Exactly.

00:30:12.540 --> 00:30:14.460
MATT STEPHENSON: And with those
services, each one of

00:30:14.460 --> 00:30:16.950
those I'm pretty careful to make
sure that the dependency

00:30:16.950 --> 00:30:18.810
closure is very minimal.

00:30:18.810 --> 00:30:22.960
And so in a lot of cases, I can
reduce how much overhead I

00:30:22.960 --> 00:30:26.990
have in my application
just by constraining,

00:30:26.990 --> 00:30:28.230
like splitting services.

00:30:28.230 --> 00:30:32.600
In a way, it's really nice to
have your services split out,

00:30:32.600 --> 00:30:33.300
very logically.

00:30:33.300 --> 00:30:36.280
But sometimes, if you split out
services just to be able

00:30:36.280 --> 00:30:38.490
to keep the dependency
closure constrained--

00:30:38.490 --> 00:30:39.150
AUDIENCE: I get it.

00:30:39.150 --> 00:30:41.590
MATT STEPHENSON: --you can
really gain a lot of value.

00:30:41.590 --> 00:30:42.325
AUDIENCE: Decompose
for scalability.

00:30:42.325 --> 00:30:43.030
Yeah.

00:30:43.030 --> 00:30:43.420
MATT STEPHENSON: Yeah.

00:30:43.420 --> 00:30:44.100
AUDIENCE: OK.

00:30:44.100 --> 00:30:46.670
And then I heard a couple
of other people

00:30:46.670 --> 00:30:47.810
remark on this too.

00:30:47.810 --> 00:30:49.610
Obviously frameworks are here
to stay and there's a lot of

00:30:49.610 --> 00:30:51.160
value in them.

00:30:51.160 --> 00:30:55.490
What are you guys doing to make
frameworks work better on

00:30:55.490 --> 00:30:57.050
App Engine as opposed to
saying, hey you have to

00:30:57.050 --> 00:30:58.200
choose, right?

00:30:58.200 --> 00:31:01.220
Put your configuration in your
code where it's hard to manage

00:31:01.220 --> 00:31:02.630
over time or-- you
know what I mean?

00:31:02.630 --> 00:31:03.190
Stuff like that.

00:31:03.190 --> 00:31:05.600
Like, what are you guys doing
to make it work better?

00:31:05.600 --> 00:31:09.090
MATT STEPHENSON: So one thing
in particular is for Spring

00:31:09.090 --> 00:31:11.890
MVC, if you're using the Context
Component Scan, I was

00:31:11.890 --> 00:31:15.370
just like talking to Jurgen
over at, now I guess

00:31:15.370 --> 00:31:18.220
Pivotal, who is--

00:31:18.220 --> 00:31:18.350
AUDIENCE: Disclaimer.

00:31:18.350 --> 00:31:19.490
I work for Pivotal.

00:31:19.490 --> 00:31:21.430
MATT STEPHENSON: You
work for Pivotal.

00:31:21.430 --> 00:31:23.060
You weren't on the phone
with me, were you?

00:31:23.060 --> 00:31:23.820
AUDIENCE: Maybe I was.

00:31:23.820 --> 00:31:25.340
MATT STEPHENSON: OK.

00:31:25.340 --> 00:31:27.850
So we were talking about--

00:31:27.850 --> 00:31:32.340
and I owe him a pull request to
try and help get some JAR

00:31:32.340 --> 00:31:36.460
indexing in, kind of like
what JBoss does.

00:31:36.460 --> 00:31:37.140
So they do.

00:31:37.140 --> 00:31:39.480
They have like a project called
jandex that indexes all

00:31:39.480 --> 00:31:42.800
these classes and indexes
the annotations on them.

00:31:42.800 --> 00:31:46.890
And then they can actually call
back into that and create

00:31:46.890 --> 00:31:49.800
classes that way, so you're not
going and spinning through

00:31:49.800 --> 00:31:54.320
tons and tons of JAR files
whenever you're trying to find

00:31:54.320 --> 00:31:56.800
classes that might have
a specific annotation.

00:31:56.800 --> 00:32:00.210
So that's one thing that I've
been working with framework

00:32:00.210 --> 00:32:01.120
providers to do.

00:32:01.120 --> 00:32:05.650
And then the other thing is just
basically fixing bugs.

00:32:05.650 --> 00:32:08.030
I'll go on there sometimes just
send pull requests to fix

00:32:08.030 --> 00:32:10.650
bugs for things that I
see here and there.

00:32:10.650 --> 00:32:10.890
AUDIENCE: Cool.

00:32:10.890 --> 00:32:11.160
Thanks.

00:32:11.160 --> 00:32:12.830
We're excited to work
with you too.

00:32:12.830 --> 00:32:14.530
MATT STEPHENSON: Cool.

00:32:14.530 --> 00:32:17.980
AUDIENCE: It seems a lot of the
discussion that you had is

00:32:17.980 --> 00:32:20.010
around optimizing
start-up times.

00:32:20.010 --> 00:32:20.200
MATT STEPHENSON: Yes.

00:32:20.200 --> 00:32:21.820
AUDIENCE: And that is especially
important when you

00:32:21.820 --> 00:32:24.550
have a lot of smaller
instances.

00:32:24.550 --> 00:32:24.930
MATT STEPHENSON: Yes.

00:32:24.930 --> 00:32:27.910
AUDIENCE: Does App Engine, or
will it ever support more

00:32:27.910 --> 00:32:33.350
coarse-grained scaling, such
that you have fewer instances

00:32:33.350 --> 00:32:36.215
and therefore less of this
kind of problem?

00:32:36.215 --> 00:32:38.530
MATT STEPHENSON: So are you
asking about having larger

00:32:38.530 --> 00:32:39.750
instance types, or?

00:32:39.750 --> 00:32:40.380
AUDIENCE: Yeah.

00:32:40.380 --> 00:32:40.730
MATT STEPHENSON: OK.

00:32:40.730 --> 00:32:43.656
So we have F1, F2, F4.

00:32:43.656 --> 00:32:47.090
F4s are pretty big for
front-end instances.

00:32:47.090 --> 00:32:50.760
And we also back-end
instances.

00:32:50.760 --> 00:32:56.090
And I think probably if you come
to the office hours, or

00:32:56.090 --> 00:32:58.490
if you actually cover to the
cloud booth later, I can point

00:32:58.490 --> 00:33:03.110
you to the guy-- or I can make
sure I find his office hours--

00:33:03.110 --> 00:33:06.100
who is working, Troy, who is
working on the servers

00:33:06.100 --> 00:33:09.460
project, which would be like
really along the lines of what

00:33:09.460 --> 00:33:11.190
you're thinking about,
I think.

00:33:11.190 --> 00:33:14.850
Which allows you to have much
heavier weight machines.

00:33:14.850 --> 00:33:18.540
AUDIENCE: But that's something
that the developer would have

00:33:18.540 --> 00:33:22.425
to look at specifically and say,
we can't make this start

00:33:22.425 --> 00:33:23.780
up any faster.

00:33:23.780 --> 00:33:24.040
MATT STEPHENSON: Yeah.

00:33:24.040 --> 00:33:25.050
AUDIENCE: We're going to have
to go with a different

00:33:25.050 --> 00:33:26.170
instance size.

00:33:26.170 --> 00:33:26.530
MATT STEPHENSON: Yeah.

00:33:26.530 --> 00:33:27.330
AUDIENCE: There's really no--

00:33:27.330 --> 00:33:27.800
MATT STEPHENSON: Yeah.

00:33:27.800 --> 00:33:28.600
AUDIENCE: OK

00:33:28.600 --> 00:33:30.140
MATT STEPHENSON: There's a
couple of other projects going

00:33:30.140 --> 00:33:33.770
on now, like CapeDwarf is an
open source alternative to App

00:33:33.770 --> 00:33:36.160
Engine that's capable
of running

00:33:36.160 --> 00:33:38.940
on some larger instances.

00:33:38.940 --> 00:33:41.330
AUDIENCE: How do you handle
applications with very large

00:33:41.330 --> 00:33:44.360
memory footprint in the App
Engine world, like where they

00:33:44.360 --> 00:33:46.900
would like to load a lot of
static content in memory like

00:33:46.900 --> 00:33:48.310
10 gig, 20 gig?

00:33:48.310 --> 00:33:52.160
Do you find issues with the
garbage collection?

00:33:52.160 --> 00:33:53.040
MATT STEPHENSON: Yes.

00:33:53.040 --> 00:33:56.210
Very large applications--

00:33:56.210 --> 00:33:58.660
first of all, if you have too
large of a memory footprint,

00:33:58.660 --> 00:34:00.840
it just won't start,
because we do very

00:34:00.840 --> 00:34:02.590
small instance sizes.

00:34:02.590 --> 00:34:03.580
AUDIENCE: So is there a limit?

00:34:03.580 --> 00:34:06.750
Like, what is the maximum you
can go in App Engine?

00:34:06.750 --> 00:34:08.179
MATT STEPHENSON: There is.

00:34:08.179 --> 00:34:09.330
I would have to pull
it all up.

00:34:09.330 --> 00:34:11.400
I believe for F1s, it's like,
it's pretty small.

00:34:11.400 --> 00:34:12.949
It's 128 megs.

00:34:12.949 --> 00:34:15.480
Like, we have really
small instances.

00:34:15.480 --> 00:34:17.219
And then we get up to
I believe one or

00:34:17.219 --> 00:34:18.760
two gigs on an instance?

00:34:18.760 --> 00:34:20.210
Maybe it's half a gig.

00:34:20.210 --> 00:34:21.659
I would have to go look it up.

00:34:21.659 --> 00:34:23.159
I don't remember off
the top of my head,

00:34:23.159 --> 00:34:27.260
but it's pretty small.

00:34:27.260 --> 00:34:30.489
So running a lot, consuming a
lot of memory on an individual

00:34:30.489 --> 00:34:33.520
instance can be problematic
from that regard.

00:34:33.520 --> 00:34:35.889
It also can take a little while
to get the instance up

00:34:35.889 --> 00:34:39.120
and running because it's
just going to be--

00:34:39.120 --> 00:34:41.460
you're going to be continuously
trying to

00:34:41.460 --> 00:34:43.670
allocate memory inside
of the instance.

00:34:43.670 --> 00:34:46.699
And if you're in a really,
really overprovisioned

00:34:46.699 --> 00:34:49.270
environment, you
could end up--

00:34:49.270 --> 00:34:51.850
even outside of App Engine, if
you're using something like

00:34:51.850 --> 00:34:54.179
OpenStack Tiny Instances and
trying to autoscale with

00:34:54.179 --> 00:34:55.139
something like that--

00:34:55.139 --> 00:34:59.180
then you can end up with, if
you're oversubscribed for

00:34:59.180 --> 00:35:02.790
memory on the machine, then you
can end up actually like

00:35:02.790 --> 00:35:06.890
the virtualization software
actually starts swapping out

00:35:06.890 --> 00:35:07.970
some of that memory.

00:35:07.970 --> 00:35:11.340
So you end up with a lot of
problems if you're consuming

00:35:11.340 --> 00:35:12.310
tons and tons of memory.

00:35:12.310 --> 00:35:14.040
AUDIENCE: But if you have
applications which are like

00:35:14.040 --> 00:35:16.750
loading a lot of content, and
they require like eight or 10

00:35:16.750 --> 00:35:20.010
gigs, how do you guys handle the
garbage collection part?

00:35:20.010 --> 00:35:23.990
You continuously try to optimize
the JVM parameters?

00:35:23.990 --> 00:35:24.940
Are you trying to--

00:35:24.940 --> 00:35:25.740
MATT STEPHENSON: Yeah.

00:35:25.740 --> 00:35:25.960
Yeah.

00:35:25.960 --> 00:35:28.118
We're always looking at them and
trying to optimize them.

00:35:28.118 --> 00:35:29.402
AUDIENCE: OK.

00:35:29.402 --> 00:35:32.700
And is the JVM used in the App
Engine is the same from the

00:35:32.700 --> 00:35:38.110
Oracle like HotSpot one, or is
it a different flavor of it?

00:35:42.350 --> 00:35:44.740
MATT STEPHENSON: I don't know if
I should say on camera too

00:35:44.740 --> 00:35:49.190
much about that, but
it's pretty close.

00:35:49.190 --> 00:35:50.330
You wouldn't notice
the difference.

00:35:50.330 --> 00:35:50.828
AUDIENCE: OK.

00:35:50.828 --> 00:35:52.078
Thank you.

00:35:54.820 --> 00:35:55.120
AUDIENCE: Hey.

00:35:55.120 --> 00:35:56.170
How's it going?

00:35:56.170 --> 00:35:59.100
I'm not on App Engine now, but
I'm considering about using

00:35:59.100 --> 00:35:59.630
App Engine.

00:35:59.630 --> 00:36:02.030
And one of the questions I have
is actually about being

00:36:02.030 --> 00:36:04.140
able to profile, right?

00:36:04.140 --> 00:36:05.200
MATT STEPHENSON: Yeah.

00:36:05.200 --> 00:36:06.030
AUDIENCE: I'm assuming
you don't get to

00:36:06.030 --> 00:36:07.590
profile in the box.

00:36:07.590 --> 00:36:10.240
How do you guys manage being
able to use some sort of

00:36:10.240 --> 00:36:12.620
profiling tool or what do you
guys suggest to profiling your

00:36:12.620 --> 00:36:15.100
application that at least
replicates some sort of

00:36:15.100 --> 00:36:17.920
environment on the cloud?

00:36:17.920 --> 00:36:21.580
MATT STEPHENSON: So I've been
trying to look at building

00:36:21.580 --> 00:36:23.040
better profiling tools
for developers.

00:36:26.540 --> 00:36:29.710
There's some stuff that we have
helped people with in the

00:36:29.710 --> 00:36:32.070
past along those lines--

00:36:32.070 --> 00:36:35.050
larger customers.

00:36:35.050 --> 00:36:38.500
It's very difficult to make
something like that really

00:36:38.500 --> 00:36:40.060
work well, where it's not
interfering with your

00:36:40.060 --> 00:36:41.310
application.

00:36:43.050 --> 00:36:46.940
But AppStats is really great for
profiling all of your out

00:36:46.940 --> 00:36:48.400
of the VM calls.

00:36:48.400 --> 00:36:51.650
So all of your calls to like
going to getting things from

00:36:51.650 --> 00:36:55.560
the data store, things like
that, AppStats is really

00:36:55.560 --> 00:36:56.240
effective for.

00:36:56.240 --> 00:36:58.450
AUDIENCE: Does AppStats provide,
for instance you were

00:36:58.450 --> 00:37:02.470
talking about on start up--

00:37:02.470 --> 00:37:04.690
class creation and things that
happen on start up-- does

00:37:04.690 --> 00:37:07.520
AppStats provide insights
into that, or?

00:37:07.520 --> 00:37:07.810
MATT STEPHENSON: No.

00:37:07.810 --> 00:37:08.950
AUDIENCE: Mind you,
I apologise.

00:37:08.950 --> 00:37:11.390
I'm not so familiar
with App Engine.

00:37:11.390 --> 00:37:12.230
MATT STEPHENSON: No, not yet.

00:37:12.230 --> 00:37:14.620
But like I said, not yet.

00:37:14.620 --> 00:37:16.790
I was actually going
to try and hack

00:37:16.790 --> 00:37:18.430
that in at some point.

00:37:18.430 --> 00:37:19.970
That was one of the things,
that's one thing that I'm

00:37:19.970 --> 00:37:23.800
looking at, is how to get a lot
more of those statistics

00:37:23.800 --> 00:37:28.240
out there in a way that it's
going to just be information

00:37:28.240 --> 00:37:29.860
that's pertinent to you.

00:37:29.860 --> 00:37:33.700
Because right now, if I try kind
of shoving those types of

00:37:33.700 --> 00:37:37.200
metrics in, I have to be a
little bit delicate not to

00:37:37.200 --> 00:37:39.430
mung up what we're doing with
what you're doing in your

00:37:39.430 --> 00:37:40.310
application.

00:37:40.310 --> 00:37:42.130
AUDIENCE: Right, Yeah, it's
extremely important I think

00:37:42.130 --> 00:37:47.040
for like super large scale usage
to be able to dive into

00:37:47.040 --> 00:37:48.970
your application and see what's
happening, so if you

00:37:48.970 --> 00:37:50.510
get around to ha hacking
into it--

00:37:50.510 --> 00:37:50.740
MATT STEPHENSON: Yeah.

00:37:50.740 --> 00:37:51.610
AUDIENCE: --it will
be very useful.

00:37:51.610 --> 00:37:52.070
Thank you.

00:37:52.070 --> 00:37:53.320
MATT STEPHENSON: Thank you.

00:37:57.575 --> 00:37:59.870
AUDIENCE: Could you talk about
how whether you use Omega

00:37:59.870 --> 00:38:01.800
behind App Engine?

00:38:01.800 --> 00:38:02.980
MATT STEPHENSON: I couldn't
hear you too well.

00:38:02.980 --> 00:38:05.355
AUDIENCE: Can you talk about
whether you use Omega behind

00:38:05.355 --> 00:38:06.160
the App Engine?

00:38:06.160 --> 00:38:06.960
MATT STEPHENSON: Omega?

00:38:06.960 --> 00:38:07.760
AUDIENCE: Yeah.

00:38:07.760 --> 00:38:09.490
MATT STEPHENSON: I'm not
familiar with it.

00:38:09.490 --> 00:38:10.930
AUDIENCE: That's
the [INAUDIBLE]

00:38:10.930 --> 00:38:11.990
scaling system.

00:38:11.990 --> 00:38:13.870
You have people on that.

00:38:13.870 --> 00:38:17.620
Google research has
people on that.

00:38:17.620 --> 00:38:18.740
MATT STEPHENSON: I'm having
a hard time hearing.

00:38:18.740 --> 00:38:23.200
AUDIENCE: It's like the Mesos
thing you developed.

00:38:23.200 --> 00:38:23.910
MATT STEPHENSON: Oh.

00:38:23.910 --> 00:38:25.710
AUDIENCE: Yeah.

00:38:25.710 --> 00:38:26.530
MATT STEPHENSON: Yeah.

00:38:26.530 --> 00:38:29.020
To my knowledge, no, we don't.

00:38:29.020 --> 00:38:30.270
AUDIENCE: OK.

00:38:37.060 --> 00:38:38.810
AUDIENCE: I got here a little
late, so I'm sorry if this

00:38:38.810 --> 00:38:40.000
question's been answered.

00:38:40.000 --> 00:38:43.130
But I've had the opposite
problem, where I have really,

00:38:43.130 --> 00:38:45.400
really small request servlets.

00:38:45.400 --> 00:38:48.510
And I think there's a limit in
App Engine that you can only

00:38:48.510 --> 00:38:50.270
have like 10 concurrent
requests

00:38:50.270 --> 00:38:52.720
handled by one instance.

00:38:52.720 --> 00:38:55.810
Is there any plan to
increase that?

00:38:55.810 --> 00:38:58.960
I think it was some legacy
thing with memory issues.

00:38:58.960 --> 00:39:00.480
Like, what's your reasoning
behind it?

00:39:00.480 --> 00:39:01.970
Is there a story around this?

00:39:04.900 --> 00:39:06.590
MATT STEPHENSON: Those types of
limitations have been with

00:39:06.590 --> 00:39:07.720
it for a long time--

00:39:07.720 --> 00:39:09.490
been with App Engine
for a long time.

00:39:09.490 --> 00:39:11.590
And a lot of them do need
to be reevaluated.

00:39:11.590 --> 00:39:20.420
So I would say, yeah, I'm happy
to take a look and see

00:39:20.420 --> 00:39:22.060
what we can do about that.

00:39:22.060 --> 00:39:25.430
That's a good suggestion.

00:39:25.430 --> 00:39:28.080
You can hit me up on
Stack Overflow.

00:39:28.080 --> 00:39:31.430
You can hit me up on the App
Engine IRC channel and

00:39:31.430 --> 00:39:32.360
Freenode too.

00:39:32.360 --> 00:39:32.730
AUDIENCE: Cool.

00:39:32.730 --> 00:39:35.290
MATT STEPHENSON: And, yeah,
let's chat about doing that.

00:39:35.290 --> 00:39:35.800
AUDIENCE: [INAUDIBLE]

00:39:35.800 --> 00:39:36.210
Thank you.

00:39:36.210 --> 00:39:37.460
MATT STEPHENSON: I like that.

00:39:41.790 --> 00:39:43.340
AUDIENCE: Does this [INAUDIBLE]
problem with

00:39:43.340 --> 00:39:46.360
Guice, when you use Guice
with App Engine?

00:39:46.360 --> 00:39:48.520
MATT STEPHENSON: Oh, Guice.

00:39:48.520 --> 00:39:49.920
I like using Guice a lot.

00:39:49.920 --> 00:39:52.340
There is a couple things in
Guice that are kind of weird

00:39:52.340 --> 00:39:55.030
that I avoid.

00:39:55.030 --> 00:39:59.070
The circular proxies in Guice
create a lot of problems with

00:39:59.070 --> 00:40:03.080
creating extra classes
to deal with--

00:40:03.080 --> 00:40:07.950
you haven't had both classes
fully initialize yet.

00:40:07.950 --> 00:40:10.570
And circular proxy is
just kind of weird.

00:40:10.570 --> 00:40:15.540
And then I try to avoid
automatic injection, but

00:40:15.540 --> 00:40:18.240
that's more of just a personal
preference, I think.

00:40:18.240 --> 00:40:22.910
The thing that can kind of go
sideways with App Engine and

00:40:22.910 --> 00:40:25.380
Guice is if you have a whole lot
of modules, whole lot of

00:40:25.380 --> 00:40:27.500
separate modules are all being
composed together.

00:40:31.420 --> 00:40:32.690
I'm kind of cold on
this question.

00:40:32.690 --> 00:40:35.890
I haven't looked at this in
about two months now.

00:40:35.890 --> 00:40:38.210
So I'm trying to get my context
back, but I believe

00:40:38.210 --> 00:40:41.790
there's a validation step that
Guice goes through that does

00:40:41.790 --> 00:40:45.050
end up doing a good deal
of introspection of the

00:40:45.050 --> 00:40:50.340
application's class path that
can be problematic like that.

00:40:50.340 --> 00:40:50.895
Is that good?

00:40:50.895 --> 00:40:52.312
AUDIENCE: Yeah.

00:40:52.312 --> 00:40:53.820
I don't know how much
more time I have.

00:40:57.060 --> 00:41:00.010
Any more questions?

00:41:00.010 --> 00:41:00.470
Cool.

00:41:00.470 --> 00:41:01.970
Well, I'm here all week.

00:41:01.970 --> 00:41:02.740
I'll be--

00:41:02.740 --> 00:41:06.300
me and Ludov will both
be at office

00:41:06.300 --> 00:41:07.850
hours tomorrow at 10:15.

00:41:07.850 --> 00:41:09.810
That's kind of the official
time to come find us.

00:41:09.810 --> 00:41:12.240
But I'm going to be running
around the conference a little

00:41:12.240 --> 00:41:15.600
bit, but mostly over
at the cloud desk.

00:41:15.600 --> 00:41:18.100
I'll also be helping out
with the Atlas--

00:41:18.100 --> 00:41:22.310
the, sorry, cloud data
store code lab at

00:41:22.310 --> 00:41:25.100
the end of the week.

00:41:25.100 --> 00:41:26.350
And so, that should
be pretty fun.

