WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.451
[MUSIC PLAYING]

00:00:08.080 --> 00:00:09.830
MICHAEL WOLF: It's
great to be here today,

00:00:09.830 --> 00:00:14.480
and it's a tremendous honor to
get to chat with Jimmy Wales.

00:00:14.480 --> 00:00:16.430
So Jimmy, why don't you come on.

00:00:16.430 --> 00:00:19.980
So first of all, everybody
knows Jimmy Wales.

00:00:19.980 --> 00:00:22.485
[APPLAUSE]

00:00:22.485 --> 00:00:28.670
If you go to Wikipedia, you'll
notice that a drawing of him

00:00:28.670 --> 00:00:32.280
or a picture of him appears
asking you to give money.

00:00:32.280 --> 00:00:35.120
So if you're one of the
hundreds of millions

00:00:35.120 --> 00:00:39.705
of people who go to Wikipedia
practically every day,

00:00:39.705 --> 00:00:40.580
you'll know his face.

00:00:40.580 --> 00:00:41.310
This is him.

00:00:41.310 --> 00:00:42.560
It's not like Colonel Sanders.

00:00:42.560 --> 00:00:45.110
He actually exists.

00:00:45.110 --> 00:00:47.630
So just by a little
bit of background, so

00:00:47.630 --> 00:00:52.010
Jimmy started Wikipedia in 2001.

00:00:52.010 --> 00:00:56.480
He launched Wikia in 2004,
which is much more focused

00:00:56.480 --> 00:01:01.730
on entertainment and games, and
is one of the top 20 websites

00:01:01.730 --> 00:01:03.140
worldwide.

00:01:03.140 --> 00:01:06.980
And in 2015, he started
the Wikipedia Foundation.

00:01:06.980 --> 00:01:09.980
And most recently, this
year he started something

00:01:09.980 --> 00:01:14.150
called WikiTribune with the
goal to fight fake news.

00:01:14.150 --> 00:01:19.700
And you described it as news by
the people and for the people.

00:01:19.700 --> 00:01:22.340
And the first time that
professional journalists

00:01:22.340 --> 00:01:25.110
and citizen journalists
will work side by side.

00:01:25.110 --> 00:01:27.200
So let's go back.

00:01:27.200 --> 00:01:29.540
Let's, like, rewind back
to when you started.

00:01:29.540 --> 00:01:32.270
You've described
the initial group

00:01:32.270 --> 00:01:35.270
that helped you start
Wikipedia as a--

00:01:35.270 --> 00:01:40.320
I'm quoting here-- "ragtag
band of volunteers."

00:01:40.320 --> 00:01:42.330
If you can remember
back to then,

00:01:42.330 --> 00:01:45.540
what was it like to start
something that has become

00:01:45.540 --> 00:01:47.497
such a worldwide phenomenon?

00:01:47.497 --> 00:01:49.663
JIMMY WALES: Yeah, well, I
mean, this was, you know,

00:01:49.663 --> 00:01:52.070
in the very, very
early days of Wikipedia

00:01:52.070 --> 00:01:54.930
we were just a really
small group of people.

00:01:54.930 --> 00:01:57.560
And you know,
before Wikipedia, I

00:01:57.560 --> 00:02:00.330
had a project called Newpedia,
which was the same goal,

00:02:00.330 --> 00:02:02.910
to have a free
encyclopedia for everyone.

00:02:02.910 --> 00:02:05.220
But I didn't really
understand online communities.

00:02:05.220 --> 00:02:08.160
I didn't have any idea
about the concept of a wiki.

00:02:08.160 --> 00:02:12.360
And so we organized a
very top down system

00:02:12.360 --> 00:02:15.610
with seven stages of review
to get anything published.

00:02:15.610 --> 00:02:16.835
And that was a failure.

00:02:16.835 --> 00:02:18.330
It was a failure
mainly because it

00:02:18.330 --> 00:02:22.890
was really intimidating for
anybody to get involved.

00:02:22.890 --> 00:02:28.470
And over the course
of a year, we

00:02:28.470 --> 00:02:31.430
had created about
two dozen entries.

00:02:31.430 --> 00:02:34.380
I had joked, I still
keep them by my bed

00:02:34.380 --> 00:02:35.550
and read them every night.

00:02:35.550 --> 00:02:37.050
I will get my money's
worth someday.

00:02:37.050 --> 00:02:38.700
MICHAEL WOLF: What were
some of the two dozen?

00:02:38.700 --> 00:02:40.574
JIMMY WALES: What were
some of the two dozen?

00:02:40.574 --> 00:02:42.870
They were just very eclectic.

00:02:42.870 --> 00:02:45.000
But I mean, there were
so few, and they were

00:02:45.000 --> 00:02:47.460
very academic and so forth.

00:02:47.460 --> 00:02:48.960
And then you know,
really realized

00:02:48.960 --> 00:02:50.400
that that wasn't working.

00:02:50.400 --> 00:02:53.370
And I decided to pivot--
although nobody called it pivot

00:02:53.370 --> 00:02:54.479
back then, but--

00:02:54.479 --> 00:02:56.520
MICHAEL WOLF: Nobody should
call it that anymore.

00:02:56.520 --> 00:02:57.644
JIMMY WALES: Yeah, exactly.

00:02:57.644 --> 00:03:00.650
I'm about done with that word.

00:03:00.650 --> 00:03:02.700
And launched the wiki.

00:03:02.700 --> 00:03:06.445
And in two weeks, we had as
much work done as we had in--

00:03:06.445 --> 00:03:08.070
well, it was actually
nearly two years.

00:03:08.070 --> 00:03:11.160
So that was the very beginning.

00:03:11.160 --> 00:03:13.950
And the truth is, in the
very early days, I mean,

00:03:13.950 --> 00:03:17.040
the software was in
no kind of state.

00:03:17.040 --> 00:03:21.750
I had downloaded a UseModWiki,
which was a Perl script.

00:03:21.750 --> 00:03:24.210
Very simple wiki package.

00:03:24.210 --> 00:03:27.566
It was so simple, in fact,
that there were no passwords.

00:03:27.566 --> 00:03:30.190
So you could create a username,
but you didn't have a password.

00:03:30.190 --> 00:03:33.300
So anybody could pretend to
be anybody, which clearly

00:03:33.300 --> 00:03:35.700
doesn't scale very well.

00:03:35.700 --> 00:03:37.200
So one of the first
things I did was

00:03:37.200 --> 00:03:42.530
sort of write a password, sort
of ability to have a password.

00:03:42.530 --> 00:03:48.105
And but still, what was great
about wikis is the word wiki,

00:03:48.105 --> 00:03:50.984
it comes from a Hawaiian word,
wiki wiki, meaning quick.

00:03:50.984 --> 00:03:53.400
Quick collaboration, like
people are able to just turn in.

00:03:53.400 --> 00:03:56.904
Because although we had been
going for about two years

00:03:56.904 --> 00:03:58.320
and hadn't gotten
much done, there

00:03:58.320 --> 00:04:00.653
were a lot of people who were
super interested and super

00:04:00.653 --> 00:04:04.860
excited about this concept of a
free encyclopedia for everyone.

00:04:04.860 --> 00:04:07.950
And so we were able to
pretty quickly move forward.

00:04:07.950 --> 00:04:09.930
But we were able to do it.

00:04:09.930 --> 00:04:11.630
I mean, there was no, like--

00:04:11.630 --> 00:04:15.434
again, people didn't say minimal
viable product back then.

00:04:15.434 --> 00:04:17.100
It was just like this
crappy Perl script

00:04:17.100 --> 00:04:19.890
and we were just sort of doing
stuff on a day-to-day basis

00:04:19.890 --> 00:04:21.029
to try to make it better.

00:04:21.029 --> 00:04:23.820
MICHAEL WOLF: When you
take apart Wikipedia

00:04:23.820 --> 00:04:27.030
as you really founded
and invented it,

00:04:27.030 --> 00:04:28.930
there's a couple
of unique things.

00:04:28.930 --> 00:04:33.810
One of them is that
practically anybody can post.

00:04:33.810 --> 00:04:37.050
One of the others
that isn't so apparent

00:04:37.050 --> 00:04:42.240
is this massive community of
people who, totally unpaid,

00:04:42.240 --> 00:04:46.500
in a lot of cases,
totally anonymous,

00:04:46.500 --> 00:04:52.580
who edit and make sure that
every entry fits to, really,

00:04:52.580 --> 00:04:54.264
to Wikipedia's standards.

00:04:54.264 --> 00:04:55.680
JIMMY WALES: Yeah,
I mean, I think

00:04:55.680 --> 00:04:57.450
there's a few elements
of that that are really

00:04:57.450 --> 00:04:58.449
important to understand.

00:04:58.449 --> 00:05:02.520
So first of all, you
know, the word community,

00:05:02.520 --> 00:05:04.645
online community,
is much abused.

00:05:04.645 --> 00:05:06.270
And oftentimes what
people mean by that

00:05:06.270 --> 00:05:07.760
is just the general public.

00:05:07.760 --> 00:05:09.510
But for me, when I use
the word community,

00:05:09.510 --> 00:05:11.580
it's people who actually
know each other,

00:05:11.580 --> 00:05:13.270
and they're discussing
and debating,

00:05:13.270 --> 00:05:15.540
they're actually
making decisions.

00:05:15.540 --> 00:05:18.870
And so if your mental model
of how Wikipedia works

00:05:18.870 --> 00:05:21.512
is 100 million people
adding one sentence each

00:05:21.512 --> 00:05:23.220
and it magically
becomes an encyclopedia,

00:05:23.220 --> 00:05:24.630
that isn't the case.

00:05:24.630 --> 00:05:27.000
It's really a core
group of volunteers

00:05:27.000 --> 00:05:30.360
who enforce the rules, who
decide what the rules are,

00:05:30.360 --> 00:05:33.510
who put into place
organized procedures

00:05:33.510 --> 00:05:37.090
and processes to monitor
things, to update things.

00:05:37.090 --> 00:05:41.140
Just as one example is the
concept of a WikiProject.

00:05:41.140 --> 00:05:42.840
So one of my
favorite WikiProject

00:05:42.840 --> 00:05:44.881
is WikiProject Bridges.

00:05:44.881 --> 00:05:46.380
So this is a group
of people who are

00:05:46.380 --> 00:05:49.470
really interested in bridges,
the architecture, the history.

00:05:49.470 --> 00:05:51.095
And they go through
all of Wikipedia

00:05:51.095 --> 00:05:53.470
and they find all the articles
having to do with bridges.

00:05:53.470 --> 00:05:55.380
MICHAEL WOLF: These are experts?

00:05:55.380 --> 00:05:57.122
Interested amateurs?

00:05:57.122 --> 00:05:58.330
JIMMY WALES: A mix, actually.

00:05:58.330 --> 00:06:00.750
So one of the guys
who I met who is

00:06:00.750 --> 00:06:03.020
one of the leaders of
the WikiProject Bridges

00:06:03.020 --> 00:06:05.070
is an architect.

00:06:05.070 --> 00:06:06.410
But many of the people aren't.

00:06:06.410 --> 00:06:08.700
They're just
interested hobbyists.

00:06:08.700 --> 00:06:10.710
And so they go through
all these articles,

00:06:10.710 --> 00:06:12.995
and they come up with
checklists of, OK,

00:06:12.995 --> 00:06:14.860
what does a good bridge
article look like?

00:06:14.860 --> 00:06:16.409
What does it need
to have included?

00:06:16.409 --> 00:06:17.950
Which ones don't
have those elements,

00:06:17.950 --> 00:06:19.665
and can we research
and find that?

00:06:19.665 --> 00:06:21.060
And so there's a lot
of that kind of work

00:06:21.060 --> 00:06:22.435
that goes on
beneath the surface.

00:06:22.435 --> 00:06:24.000
And it really is
small groups who

00:06:24.000 --> 00:06:25.666
know each other who
say, OK, well, we're

00:06:25.666 --> 00:06:27.510
going to take on this
particular topic.

00:06:27.510 --> 00:06:30.270
Another fantastic one,
particularly strong

00:06:30.270 --> 00:06:33.150
in English Wikipedia is
WikiProject Medicine.

00:06:33.150 --> 00:06:36.960
And they are quite
fearsome in their demands

00:06:36.960 --> 00:06:39.930
that the rules be followed
because the medical topics are,

00:06:39.930 --> 00:06:41.190
you know, people rely on it.

00:06:41.190 --> 00:06:43.800
It's really important that the--

00:06:43.800 --> 00:06:46.200
are very, very
careful about things

00:06:46.200 --> 00:06:48.430
that could mislead the
public and so forth.

00:06:48.430 --> 00:06:50.679
So yeah.

00:06:50.679 --> 00:06:52.470
MICHAEL WOLF: And why
do people contribute?

00:06:52.470 --> 00:06:54.610
Is it-- you talked
about a community

00:06:54.610 --> 00:06:56.370
of people that know each other.

00:06:56.370 --> 00:06:59.010
Is it a dedication to it?

00:06:59.010 --> 00:07:02.130
Is it prestige among the
other people that they

00:07:02.130 --> 00:07:03.240
know in this community?

00:07:03.240 --> 00:07:05.590
JIMMY WALES: So it's
a couple of things.

00:07:05.590 --> 00:07:07.710
So first of all, the vision--

00:07:07.710 --> 00:07:10.050
a free encyclopedia
for every single person

00:07:10.050 --> 00:07:13.470
on the planet in their own
language-- is exciting.

00:07:13.470 --> 00:07:15.870
People think that's
worth spending time on.

00:07:15.870 --> 00:07:18.630
So you know, if you're
someone, you know,

00:07:18.630 --> 00:07:22.530
you could spend the weekend
playing Grand Theft Auto,

00:07:22.530 --> 00:07:25.200
and then late Sunday
night you realize

00:07:25.200 --> 00:07:27.150
you've just wasted
two days of your life

00:07:27.150 --> 00:07:28.590
that you'll never
get back and you

00:07:28.590 --> 00:07:29.400
haven't improved the world--

00:07:29.400 --> 00:07:31.050
MICHAEL WOLF: It's
very productive.

00:07:31.050 --> 00:07:32.820
JIMMY WALES: Or you
can work on Wikipedia

00:07:32.820 --> 00:07:35.359
and whatever may come of
it, you come away thinking,

00:07:35.359 --> 00:07:36.150
hey, you know what?

00:07:36.150 --> 00:07:39.480
The world's a little bit better
now than it was when I started.

00:07:39.480 --> 00:07:42.106
So that grand
vision is important.

00:07:42.106 --> 00:07:43.230
But also, it has to be fun.

00:07:43.230 --> 00:07:45.030
People have to find
it interesting.

00:07:45.030 --> 00:07:48.074
You have to meet other nice,
interesting people who are,

00:07:48.074 --> 00:07:50.490
you know, you're learning
things and you're meeting people

00:07:50.490 --> 00:07:53.130
and you're having
quality debates, which

00:07:53.130 --> 00:07:54.860
is hard to come by
on the internet.

00:07:54.860 --> 00:07:59.010
There's plenty of places to
have sort of raging flame wars.

00:07:59.010 --> 00:08:00.990
But to actually have an
interesting discussion

00:08:00.990 --> 00:08:03.390
or debate around the
quality of sourcing

00:08:03.390 --> 00:08:06.940
around some particular
topic, people enjoy that.

00:08:06.940 --> 00:08:08.730
And so it's got to
be both of those.

00:08:08.730 --> 00:08:10.789
It's got to be that
we feel like we're

00:08:10.789 --> 00:08:13.080
doing something productive
and we also are enjoying it.

00:08:13.080 --> 00:08:14.538
And so yeah, it
does have something

00:08:14.538 --> 00:08:16.320
to do with, not prestige.

00:08:16.320 --> 00:08:20.604
So if you want to become
a well-known famous person

00:08:20.604 --> 00:08:22.020
on the internet,
I would recommend

00:08:22.020 --> 00:08:23.670
being a blogger or
something like that.

00:08:23.670 --> 00:08:27.870
You know, spend your
time on social media.

00:08:27.870 --> 00:08:30.540
But so within the
Wikipedia community though,

00:08:30.540 --> 00:08:32.640
we aren't particularly
anonymous with each other.

00:08:32.640 --> 00:08:34.140
People do know each
other and people

00:08:34.140 --> 00:08:35.350
have respect and people--

00:08:35.350 --> 00:08:36.220
MICHAEL WOLF: But they
know each other virtually,

00:08:36.220 --> 00:08:38.490
or do they actually know
each other in person?

00:08:38.490 --> 00:08:41.768
JIMMY WALES: Mostly
virtually, but it depends.

00:08:41.768 --> 00:08:43.809
Actually, that depends
very much on the language.

00:08:43.809 --> 00:08:47.520
So if you think
about, for example,

00:08:47.520 --> 00:08:51.660
Lithuanian Wikipedia, virtually
everyone who speaks Lithuanian

00:08:51.660 --> 00:08:53.805
lives within a train
ride of each other.

00:08:53.805 --> 00:08:56.430
And so they tend to have meetups
and they get together for beer

00:08:56.430 --> 00:08:58.470
and they actually know
each other pretty well.

00:08:58.470 --> 00:09:00.320
Other languages, like
English, of course,

00:09:00.320 --> 00:09:01.630
is spread all around the world.

00:09:01.630 --> 00:09:03.210
And so oftentimes, people
talk to each other.

00:09:03.210 --> 00:09:04.126
But people do meet up.

00:09:04.126 --> 00:09:05.310
They meet up locally.

00:09:05.310 --> 00:09:06.680
They meet up all over the world.

00:09:06.680 --> 00:09:09.547
We have our conferences
and things like that.

00:09:09.547 --> 00:09:11.380
MICHAEL WOLF: Of course,
one of the topics--

00:09:11.380 --> 00:09:16.020
and putting aside the last
election board on the topics

00:09:16.020 --> 00:09:17.070
overall--

00:09:17.070 --> 00:09:20.160
is verifying information.

00:09:20.160 --> 00:09:26.190
And everybody's aware of some
of the famous Wikipedia hacks.

00:09:26.190 --> 00:09:29.790
So for example, I used
to run MTV Networks,

00:09:29.790 --> 00:09:31.650
and one of our companies
is Nickelodeon.

00:09:31.650 --> 00:09:36.540
And there was the Wikipedia page
for both Eminem and SpongeBob

00:09:36.540 --> 00:09:38.950
said that Eminem was
the voice of SpongeBob.

00:09:38.950 --> 00:09:41.490
Now I can assure you,
that was not the case.

00:09:41.490 --> 00:09:44.850
Or Stephen Colbert
from Comedy Central

00:09:44.850 --> 00:09:49.560
convinced his audience to change
Wikipedia to say that elephants

00:09:49.560 --> 00:09:51.260
were not endangered.

00:09:51.260 --> 00:09:56.970
What needs to happen to
ensure that these entries,

00:09:56.970 --> 00:09:59.580
whether it's about
popular culture

00:09:59.580 --> 00:10:02.130
or about medicine or
about architecture,

00:10:02.130 --> 00:10:06.120
what happens to make sure
that they are verified?

00:10:06.120 --> 00:10:09.300
JIMMY WALES: Yeah, so just
as an example, so they--

00:10:09.300 --> 00:10:12.570
when Colbert made
this joke on the air,

00:10:12.570 --> 00:10:15.950
literally within 30 seconds
of him saying the joke,

00:10:15.950 --> 00:10:18.750
the page was locked because
the Wikipedians actually

00:10:18.750 --> 00:10:19.680
watch Colbert, too.

00:10:19.680 --> 00:10:23.310
So the admins just went in and
locked the page immediately.

00:10:23.310 --> 00:10:25.770
And vandalism-- and then we
had to cope with it for, like,

00:10:25.770 --> 00:10:28.020
three weeks as people
kept trying to put it in.

00:10:28.020 --> 00:10:30.960
But we just kept
the page locked.

00:10:30.960 --> 00:10:32.502
I didn't have time--

00:10:32.502 --> 00:10:33.710
you mentioned the Eminem one.

00:10:33.710 --> 00:10:34.890
I had not heard that one.

00:10:34.890 --> 00:10:37.790
I'm guessing that probably
only lasted in Wikipedia

00:10:37.790 --> 00:10:40.440
for, again, a few minutes.

00:10:40.440 --> 00:10:41.410
I think I know why.

00:10:41.410 --> 00:10:43.380
There's actually--
I saw it on YouTube.

00:10:43.380 --> 00:10:51.020
There's a SpongeBob and "Lose
Yourself" mash-up on YouTube.

00:10:51.020 --> 00:10:52.470
Has like, 4 million views.

00:10:52.470 --> 00:10:54.330
So that's probably
where it came from.

00:10:54.330 --> 00:10:55.980
That probably became
a meme and then

00:10:55.980 --> 00:10:58.950
people thought it was
funny to have that.

00:10:58.950 --> 00:11:01.950
So-- and that sort of
thing, it does happen.

00:11:01.950 --> 00:11:05.026
Usually it's very,
very short term.

00:11:05.026 --> 00:11:06.400
And you know,
sometimes it isn't.

00:11:06.400 --> 00:11:09.480
Sometimes you can have
vandalism in Wikipedia

00:11:09.480 --> 00:11:11.420
that lasts much longer
than we would like.

00:11:11.420 --> 00:11:14.130
So it isn't perfect.

00:11:14.130 --> 00:11:17.022
But the way it works,
we have to have--

00:11:17.022 --> 00:11:18.730
again, if you have
the model of Wikipedia

00:11:18.730 --> 00:11:22.080
as 100 million people, all
randomly putting stuff in,

00:11:22.080 --> 00:11:25.540
it would just be-- that's all
it would be is just nonsense.

00:11:25.540 --> 00:11:30.540
But we have a whole bunch of
different policies, procedures.

00:11:30.540 --> 00:11:32.256
People become admins.

00:11:32.256 --> 00:11:33.630
They're elected
by the community.

00:11:33.630 --> 00:11:36.930
And then they have the
ability-- and admins are not

00:11:36.930 --> 00:11:38.864
like in most sites.

00:11:38.864 --> 00:11:40.780
So, if you're on YouTube,
and you do something

00:11:40.780 --> 00:11:44.072
against the rules of YouTube,
and your video gets taken down,

00:11:44.072 --> 00:11:45.530
and you're locked
out, you actually

00:11:45.530 --> 00:11:47.480
have no idea who did that.

00:11:47.480 --> 00:11:51.650
Somebody mysterious, deep
in Google somewhere, did it.

00:11:51.650 --> 00:11:54.440
Whereas in our
community, the admins

00:11:54.440 --> 00:11:56.270
are all members of the public.

00:11:56.270 --> 00:11:57.260
They're all volunteers.

00:11:57.260 --> 00:12:00.410
And they monitor each other,
and there's always debates

00:12:00.410 --> 00:12:02.060
about is this a
valid block, why did

00:12:02.060 --> 00:12:04.550
you block this person,
et cetera, et cetera.

00:12:04.550 --> 00:12:07.520
So they're more like police.

00:12:07.520 --> 00:12:09.440
They're not judge,
jury, and executioner.

00:12:09.440 --> 00:12:12.300
They have certain abilities to
block people or block pages,

00:12:12.300 --> 00:12:13.550
but they have to justify that.

00:12:13.550 --> 00:12:15.841
And there are ways that those
decisions can be reviewed

00:12:15.841 --> 00:12:17.310
and overturned and so forth.

00:12:17.310 --> 00:12:21.380
So it's like managing a good
municipal government, really.

00:12:21.380 --> 00:12:25.790
MICHAEL WOLF: So we have 100
million users of Wikipedia

00:12:25.790 --> 00:12:27.140
is how many people--

00:12:27.140 --> 00:12:28.910
I mean, this number
we want to know.

00:12:28.910 --> 00:12:31.410
How many people are
actually editing today?

00:12:31.410 --> 00:12:35.660
JIMMY WALES: Yes, so if you take
a look at the numbers, the best

00:12:35.660 --> 00:12:40.290
number we have right now for
the number of unique devices

00:12:40.290 --> 00:12:44.310
that access Wikipedia in a
month is about 1.4 billion.

00:12:44.310 --> 00:12:45.520
So that's a lot of people.

00:12:45.520 --> 00:12:48.680
It's not 1.4 billion people,
because probably most people

00:12:48.680 --> 00:12:50.840
in this room, for
example access Wikipedia

00:12:50.840 --> 00:12:54.870
in a month on at least
two or three devices.

00:12:54.870 --> 00:12:56.607
But it's a huge audience.

00:12:56.607 --> 00:12:58.940
And then just to give the
numbers for English Wikipedia,

00:12:58.940 --> 00:13:03.680
there's probably about
70,000 to 80,000 people

00:13:03.680 --> 00:13:06.190
who make at least
five edits in a month,

00:13:06.190 --> 00:13:08.720
and there's about
3,000 people who make

00:13:08.720 --> 00:13:10.670
at least 100 edits in a month.

00:13:10.670 --> 00:13:13.310
So it's that 3,000 who are the
really active community, who

00:13:13.310 --> 00:13:14.685
really oversee
and manage things.

00:13:14.685 --> 00:13:16.143
And then there's
lots of people who

00:13:16.143 --> 00:13:18.900
just add one thing, which then
is reviewed by the community

00:13:18.900 --> 00:13:19.610
and so forth.

00:13:19.610 --> 00:13:21.068
MICHAEL WOLF: Pretty
extraordinary.

00:13:21.068 --> 00:13:25.220
Those 3,000 people
who really make,

00:13:25.220 --> 00:13:27.920
really change the world
for the rest of us.

00:13:27.920 --> 00:13:29.090
You've talked a lot about--

00:13:29.090 --> 00:13:29.630
JIMMY WALES: You
know, it's funny.

00:13:29.630 --> 00:13:32.210
I was-- a few years
back, it just struck me.

00:13:32.210 --> 00:13:33.210
I was at--

00:13:33.210 --> 00:13:34.910
Wikimania is our
annual conference.

00:13:34.910 --> 00:13:38.420
And I, at a dinner, I just,
with my tray, I went and sat.

00:13:38.420 --> 00:13:39.170
And I was, oh, OK.

00:13:39.170 --> 00:13:39.670
Look.

00:13:39.670 --> 00:13:41.720
Here's the English
Arbitration Committee.

00:13:41.720 --> 00:13:45.287
So this is like the Supreme
Court of the English Wikipedia.

00:13:45.287 --> 00:13:47.370
And we're having dinner
and discussing this, that,

00:13:47.370 --> 00:13:48.245
and the other policy.

00:13:48.245 --> 00:13:50.914
And I left the
table, and I thought,

00:13:50.914 --> 00:13:52.580
I get to meet a lot
of important people,

00:13:52.580 --> 00:13:56.570
but this is probably some of the
most powerful people in media

00:13:56.570 --> 00:13:58.670
in the world, is the English
Wikipedia Arbitration

00:13:58.670 --> 00:13:59.170
Committee.

00:13:59.170 --> 00:14:01.580
I mean, they make
really big decisions,

00:14:01.580 --> 00:14:02.975
and they're a bunch of geeks.

00:14:02.975 --> 00:14:03.766
Which is fantastic.

00:14:03.766 --> 00:14:06.670
MICHAEL WOLF: And nobody outside
their community knows them?

00:14:06.670 --> 00:14:07.670
JIMMY WALES: Not really.

00:14:07.670 --> 00:14:08.169
No.

00:14:08.169 --> 00:14:11.180
I mean, occasionally
you'll get a news article

00:14:11.180 --> 00:14:16.010
about somebody who's had
the most number of edits

00:14:16.010 --> 00:14:17.010
and that sort of thing.

00:14:17.010 --> 00:14:18.320
And oftentimes the people who--

00:14:18.320 --> 00:14:19.945
if you've had the
most number of edits,

00:14:19.945 --> 00:14:21.740
oftentimes, they're
running a bot.

00:14:21.740 --> 00:14:24.110
That's how you get a very
high edit count, is do spell

00:14:24.110 --> 00:14:25.610
checking or something like that.

00:14:25.610 --> 00:14:27.470
Not always.

00:14:27.470 --> 00:14:29.810
And they're generally
known in the community,

00:14:29.810 --> 00:14:31.837
but they aren't
always necessarily

00:14:31.837 --> 00:14:34.170
the most influential or
powerful within their community.

00:14:34.170 --> 00:14:36.003
They're just really
busy, is the main thing.

00:14:36.003 --> 00:14:37.040
So in general, no.

00:14:37.040 --> 00:14:38.030
Nobody really
knows who they are.

00:14:38.030 --> 00:14:38.613
I mean, we do.

00:14:38.613 --> 00:14:40.760
But.

00:14:40.760 --> 00:14:44.000
MICHAEL WOLF: But you've also
talked a lot about AI machine

00:14:44.000 --> 00:14:45.020
learning.

00:14:45.020 --> 00:14:50.030
What role will that play
in verifying information

00:14:50.030 --> 00:14:51.239
in the future?

00:14:51.239 --> 00:14:53.030
JIMMY WALES: So, I
mean, what's interesting

00:14:53.030 --> 00:14:55.340
about this is sometimes
people will ask it this way.

00:14:55.340 --> 00:14:57.901
When do you think AI will
be able to write Wikipedia

00:14:57.901 --> 00:14:58.400
articles?

00:14:58.400 --> 00:15:00.740
And I say, it's
a very long time.

00:15:00.740 --> 00:15:04.180
Or anyway, it's one of the
highest human activities,

00:15:04.180 --> 00:15:07.580
is to write a good Wikipedia
entry, is really quite a--

00:15:07.580 --> 00:15:10.000
I mean, once we're there,
we're at full general AI.

00:15:10.000 --> 00:15:12.710
It's the singularity, and let's
just hope they're nice to us.

00:15:15.380 --> 00:15:17.590
But before that,
I do think there

00:15:17.590 --> 00:15:19.100
are some interesting things.

00:15:19.100 --> 00:15:24.071
We have a partnership
with Jigsaw, where we--

00:15:24.071 --> 00:15:26.619
it's AI looking at edits
and machine-learning.

00:15:26.619 --> 00:15:28.160
I actually know very
little about it,

00:15:28.160 --> 00:15:30.590
except it's really cool.

00:15:30.590 --> 00:15:32.250
So on Wikipedia, if
you're logged in,

00:15:32.250 --> 00:15:33.958
you can go to Recent
Changes, and now you

00:15:33.958 --> 00:15:35.750
can filter the Recent
Changes, and you

00:15:35.750 --> 00:15:36.950
can save whatever filter.

00:15:36.950 --> 00:15:38.900
And there's different
things you can select.

00:15:38.900 --> 00:15:39.929
So what I do--

00:15:39.929 --> 00:15:41.720
this is with my favorite
way of filtering--

00:15:41.720 --> 00:15:46.310
I want to see edits that
are very likely bad,

00:15:46.310 --> 00:15:49.550
that are likely in good
faith, by new users.

00:15:49.550 --> 00:15:51.530
So this is somebody
new to the site.

00:15:51.530 --> 00:15:53.660
They've made an edit
which is probably bad,

00:15:53.660 --> 00:15:55.820
but it was probably
made in good faith.

00:15:55.820 --> 00:15:58.550
And it actually is pretty
good at finding those.

00:15:58.550 --> 00:16:00.469
And what you do
then, the reason I

00:16:00.469 --> 00:16:02.635
pick those is that's the
kind of people I go say hi.

00:16:02.635 --> 00:16:03.500
Like, hi, thanks.

00:16:03.500 --> 00:16:05.300
It looks like you're
trying to do this.

00:16:05.300 --> 00:16:06.470
Let's-- you know.

00:16:06.470 --> 00:16:08.490
And that's kind of amazing.

00:16:08.490 --> 00:16:09.560
So being able to--

00:16:09.560 --> 00:16:12.770
I think what is interesting
here is the idea of AI

00:16:12.770 --> 00:16:15.020
basically just raising the hand.

00:16:15.020 --> 00:16:17.509
Raising the flag for a
human to review something.

00:16:17.509 --> 00:16:18.800
Because it often gets it wrong.

00:16:18.800 --> 00:16:21.167
You wouldn't really want AI
policing this sort of thing.

00:16:21.167 --> 00:16:22.750
MICHAEL WOLF: So
it's assisted review.

00:16:22.750 --> 00:16:24.350
JIMMY WALES: It's
assisted review.

00:16:24.350 --> 00:16:27.020
And I think that's
very useful to--

00:16:27.020 --> 00:16:29.390
and I think this is an
area we will pursue more

00:16:29.390 --> 00:16:30.140
in various ways.

00:16:30.140 --> 00:16:33.410
And AI is a very broad
term, but the idea

00:16:33.410 --> 00:16:37.730
of using much more algorithmic
approaches to bring things

00:16:37.730 --> 00:16:40.700
to the attention of people that
you're probably interested in.

00:16:40.700 --> 00:16:44.160
So just as an
example, to interest

00:16:44.160 --> 00:16:47.520
new editors, what we could do
is notice what you're reading.

00:16:47.520 --> 00:16:50.350
And so if we see, OK, every day
you're reading about World War

00:16:50.350 --> 00:16:53.100
II, and we have over here
an article that we have

00:16:53.100 --> 00:16:55.697
algorithmic signals is not
very good, we could say,

00:16:55.697 --> 00:16:57.780
hey, you've been reading
a lot about World War II.

00:16:57.780 --> 00:16:59.152
Would you like to help out?

00:16:59.152 --> 00:17:00.860
Here's an article that
needs improvement.

00:17:00.860 --> 00:17:01.830
MICHAEL WOLF: More
recruitment potential.

00:17:01.830 --> 00:17:03.570
JIMMY WALES: Yeah, exactly.

00:17:03.570 --> 00:17:06.923
Or if you're editing in an area,
then we can say, oh, here's

00:17:06.923 --> 00:17:08.339
some similar things
that you might

00:17:08.339 --> 00:17:11.050
want to edit that need help,
and that sort of thing.

00:17:11.050 --> 00:17:14.273
And we've been very, very human
about all that sort of thing.

00:17:14.273 --> 00:17:16.064
We don't have much in
the way of algorithms

00:17:16.064 --> 00:17:17.339
to look at that sort of thing.

00:17:17.339 --> 00:17:20.520
But I think there's huge
opportunities there.

00:17:20.520 --> 00:17:23.609
And the great thing about
assisted review or prompting

00:17:23.609 --> 00:17:26.099
people, is it doesn't have to
be perfect to be a lot better

00:17:26.099 --> 00:17:27.869
than nothing.

00:17:27.869 --> 00:17:30.570
If Wikipedia starts
suggesting things

00:17:30.570 --> 00:17:34.427
to me that I should edit, and I
think half of them are useless,

00:17:34.427 --> 00:17:36.510
and half of them are
actually kind of interesting,

00:17:36.510 --> 00:17:38.350
that's better than
suggesting zero to me.

00:17:38.350 --> 00:17:38.910
So.

00:17:38.910 --> 00:17:42.170
MICHAEL WOLF: How does the
community feel about AI?

00:17:42.170 --> 00:17:44.660
Do they feel that they should
put some standard around it?

00:17:44.660 --> 00:17:45.910
JIMMY WALES: Yeah, yeah, yeah.

00:17:45.910 --> 00:17:51.660
They're very protective of
their turf, in a certain way.

00:17:51.660 --> 00:17:53.070
But they're also very--

00:17:53.070 --> 00:17:55.490
these are quite geeky people.

00:17:55.490 --> 00:17:57.270
They're interested
in technology.

00:17:57.270 --> 00:18:00.150
They're open to saying,
yeah, there's a lot of stuff

00:18:00.150 --> 00:18:03.360
that humans aren't very good at
that machines-- very tedious,

00:18:03.360 --> 00:18:04.110
boring stuff.

00:18:04.110 --> 00:18:05.850
If we can get machines
to do that stuff

00:18:05.850 --> 00:18:07.811
and raise it to our
attention, then our work

00:18:07.811 --> 00:18:08.560
is more effective.

00:18:08.560 --> 00:18:10.340
Because as I said
in the beginning,

00:18:10.340 --> 00:18:12.380
one of the reasons
people want to edit

00:18:12.380 --> 00:18:15.330
Wikipedia is at the end of
an hour editing Wikipedia,

00:18:15.330 --> 00:18:17.832
if you feel like you
did something useful,

00:18:17.832 --> 00:18:18.540
that's important.

00:18:18.540 --> 00:18:21.600
And so if I go to Wikipedia,
and I pick some obscure article

00:18:21.600 --> 00:18:23.365
and try to improve a
couple of sentences,

00:18:23.365 --> 00:18:25.740
I'm never quite sure, is
anybody even going to read that?

00:18:25.740 --> 00:18:26.500
Or whatever.

00:18:26.500 --> 00:18:28.890
But if you show me, oh,
here's a popular article

00:18:28.890 --> 00:18:30.570
that is in poor state, OK.

00:18:30.570 --> 00:18:32.160
I will have an
impact if I do that.

00:18:32.160 --> 00:18:35.177
So I think people like
that sort of idea.

00:18:35.177 --> 00:18:36.510
MICHAEL WOLF: Let's shift gears.

00:18:36.510 --> 00:18:38.070
Let's talk about education.

00:18:38.070 --> 00:18:39.880
So I have a personal experience.

00:18:39.880 --> 00:18:44.310
I have two 18-year-olds,
a boy and a girl.

00:18:44.310 --> 00:18:49.650
And they've gone through school,
and one is already in college.

00:18:49.650 --> 00:18:52.440
And their entire time through
school, their teachers

00:18:52.440 --> 00:18:55.440
have said, Wikipedia
is not a source.

00:18:55.440 --> 00:18:56.645
You can't use Wikipedia.

00:18:56.645 --> 00:18:58.990
You have to go-- and by
the way, the first place

00:18:58.990 --> 00:19:01.480
that they go for
anything is Wikipedia,

00:19:01.480 --> 00:19:03.070
but it's never disclosed.

00:19:03.070 --> 00:19:04.430
JIMMY WALES: Yeah.

00:19:04.430 --> 00:19:07.230
It's like, you can tell kids,
don't listen to rock and roll

00:19:07.230 --> 00:19:10.020
music, but.

00:19:10.020 --> 00:19:11.120
We're well past that.

00:19:11.120 --> 00:19:11.300
[INAUDIBLE]

00:19:11.300 --> 00:19:11.466
MICHAEL WOLF: Right.

00:19:11.466 --> 00:19:12.840
No, it's actually
more important.

00:19:12.840 --> 00:19:15.690
It's what you protect
your parents from doing.

00:19:15.690 --> 00:19:18.510
And it's your responsibility.

00:19:18.510 --> 00:19:20.770
But coming back to what's--

00:19:20.770 --> 00:19:25.020
what is it that Wikipedia
and other organizations

00:19:25.020 --> 00:19:29.170
that are around information,
what's their responsibility,

00:19:29.170 --> 00:19:31.080
and what's the opportunity?

00:19:31.080 --> 00:19:35.130
JIMMY WALES: So for us, I mean,
we feel a very heavy burden.

00:19:35.130 --> 00:19:37.320
If we think about--

00:19:37.320 --> 00:19:39.730
well, 18-year-olds, right?

00:19:39.730 --> 00:19:42.320
So Wikipedia is
now 16 years old.

00:19:42.320 --> 00:19:45.010
So from the time they
were learning to read,

00:19:45.010 --> 00:19:46.030
Wikipedia had existed.

00:19:46.030 --> 00:19:48.709
And certainly in
the last five years,

00:19:48.709 --> 00:19:50.500
five to 10 years, when
they were old enough

00:19:50.500 --> 00:19:52.824
to start doing homework
and looking online

00:19:52.824 --> 00:19:54.740
or following their own
intellectual interests,

00:19:54.740 --> 00:19:57.305
whatever that might be,
they go to Wikipedia.

00:19:57.305 --> 00:19:59.680
And so it's just part of the
infrastructure of the world,

00:19:59.680 --> 00:20:01.000
as far as they're
concerned, which

00:20:01.000 --> 00:20:02.583
means we have a
responsibility to make

00:20:02.583 --> 00:20:05.080
it as good as we possibly can.

00:20:05.080 --> 00:20:07.780
And when I say we, I include
everyone in this room.

00:20:07.780 --> 00:20:11.320
I mean this is a--
it's a public resource.

00:20:11.320 --> 00:20:15.880
And it's important to
know, we don't consider

00:20:15.880 --> 00:20:18.230
it to be a goal for
Wikipedia that we

00:20:18.230 --> 00:20:23.550
be a citable source for
18-year-olds entering college

00:20:23.550 --> 00:20:26.350
any more than when
I was at university,

00:20:26.350 --> 00:20:28.629
if I cited
Britannica, that would

00:20:28.629 --> 00:20:29.920
have been considered ludicrous.

00:20:29.920 --> 00:20:32.452
That's something--
an encyclopedia,

00:20:32.452 --> 00:20:34.910
that's not the role it should
play in the research process.

00:20:34.910 --> 00:20:37.310
An encyclopedia is the starting
point, not the ending point.

00:20:37.310 --> 00:20:38.740
Particularly at
the college level,

00:20:38.740 --> 00:20:41.800
it's like, hey, if all you're
going to do is read Wikipedia

00:20:41.800 --> 00:20:44.094
and write a paper, I mean,
come on, this is ridiculous.

00:20:44.094 --> 00:20:45.760
Read Wikipedia to get
oriented, but then

00:20:45.760 --> 00:20:47.260
go to the original
sources and start

00:20:47.260 --> 00:20:49.270
doing more interesting
intellectual work.

00:20:49.270 --> 00:20:52.750
Now, of course, if a
13-year-old writes something

00:20:52.750 --> 00:20:54.860
and adds a footnote
and cites Wikipedia,

00:20:54.860 --> 00:20:56.350
I'm like, hey, progress.

00:20:56.350 --> 00:20:57.896
At least they've
written something,

00:20:57.896 --> 00:20:59.020
and they put in a footnote.

00:20:59.020 --> 00:21:00.919
That's OK at a certain age.

00:21:00.919 --> 00:21:02.710
But later on, I don't
think that-- it's not

00:21:02.710 --> 00:21:04.420
something we aspire to.

00:21:04.420 --> 00:21:06.610
MICHAEL WOLF: And do
you think Wikipedia

00:21:06.610 --> 00:21:09.940
or other organizations
with Wikipedia have

00:21:09.940 --> 00:21:11.640
more of a role in education?

00:21:11.640 --> 00:21:14.570
I mean, education's
a huge challenge.

00:21:14.570 --> 00:21:16.870
And not every kid
in this country

00:21:16.870 --> 00:21:19.000
is going to get
to go to college.

00:21:19.000 --> 00:21:22.000
What can Wikipedia and
other organizations

00:21:22.000 --> 00:21:24.539
do to solve our
education problem?

00:21:24.539 --> 00:21:27.080
JIMMY WALES: Well, I think one
of the things that's going on,

00:21:27.080 --> 00:21:30.290
if you look at the trends
in formal education,

00:21:30.290 --> 00:21:34.840
so what percentage of people
are going to college, that

00:21:34.840 --> 00:21:36.730
moves around a very
little bit, but it's

00:21:36.730 --> 00:21:39.776
pretty stable, and nothing
dramatic is happening there.

00:21:39.776 --> 00:21:41.650
A few more people are
going to college, a few

00:21:41.650 --> 00:21:43.780
less in certain places,
in certain things.

00:21:43.780 --> 00:21:47.030
But in general, that's a
pretty well understood area.

00:21:47.030 --> 00:21:49.640
But what is completely
changed in the last 10,

00:21:49.640 --> 00:21:53.170
15 years is the amount
of informal learning

00:21:53.170 --> 00:21:54.340
that people do.

00:21:54.340 --> 00:21:56.504
That if you hear--

00:21:56.504 --> 00:21:57.670
MICHAEL WOLF: Self-directed?

00:21:57.670 --> 00:21:59.050
JIMMY WALES: Self-directed.

00:21:59.050 --> 00:22:00.420
Even just ordinary things.

00:22:00.420 --> 00:22:03.262
So if you hear,
oh, I don't know.

00:22:03.262 --> 00:22:04.720
Blah, blah, blah,
there's something

00:22:04.720 --> 00:22:05.920
going on called Bitcoin.

00:22:05.920 --> 00:22:08.140
I don't really
know what that is.

00:22:08.140 --> 00:22:10.935
If it was 25 years ago,
you would go, I don't know.

00:22:10.935 --> 00:22:12.310
I read this article
in the paper.

00:22:12.310 --> 00:22:13.240
I don't really get it.

00:22:13.240 --> 00:22:14.469
Now people dig deep.

00:22:14.469 --> 00:22:15.760
And we see this in our traffic.

00:22:15.760 --> 00:22:16.920
People can dig deep.

00:22:16.920 --> 00:22:19.120
All the information is there.

00:22:19.120 --> 00:22:21.090
And that's really important.

00:22:21.090 --> 00:22:23.380
And it doesn't result in
more degrees and so forth,

00:22:23.380 --> 00:22:25.289
but people can
learn about anything

00:22:25.289 --> 00:22:26.830
they want to learn
about very easily,

00:22:26.830 --> 00:22:29.150
and that is a huge
impact on education.

00:22:29.150 --> 00:22:32.030
I do think there's a
lot to think about.

00:22:32.030 --> 00:22:34.120
So for us, one of
the biggest things

00:22:34.120 --> 00:22:36.700
that we are interested
in is the growth

00:22:36.700 --> 00:22:39.430
of Wikipedia in the languages
of the developing world.

00:22:39.430 --> 00:22:40.900
Because of course,
there are places

00:22:40.900 --> 00:22:43.540
in the world where people
have very limited access

00:22:43.540 --> 00:22:45.310
to information.

00:22:45.310 --> 00:22:48.070
So the way I think
about this is if you're

00:22:48.070 --> 00:22:49.900
an English speaker,
one of the things

00:22:49.900 --> 00:22:52.030
Wikipedia is the
solution to is just

00:22:52.030 --> 00:22:57.200
narrowing down a place to go
to find basic information.

00:22:57.200 --> 00:22:59.620
So if I type Queen
Victoria into Google,

00:22:59.620 --> 00:23:02.069
I'm going to get, I don't
know, millions of pages.

00:23:02.069 --> 00:23:04.110
The number one is probably
going to be Wikipedia,

00:23:04.110 --> 00:23:05.526
and that's probably
what I wanted.

00:23:05.526 --> 00:23:08.320
I just wanted to get the
basic story of Queen Victoria,

00:23:08.320 --> 00:23:09.640
her life and times, da, da, da.

00:23:09.640 --> 00:23:10.737
It's all there.

00:23:10.737 --> 00:23:12.820
And this is because we
have a glut of information.

00:23:12.820 --> 00:23:19.930
But if you're speaking
an obscure language

00:23:19.930 --> 00:23:23.740
with only a million speakers
in Africa, in your language,

00:23:23.740 --> 00:23:25.030
there's going to be--

00:23:25.030 --> 00:23:26.740
the role of Wikipedia
is, hey, it's

00:23:26.740 --> 00:23:29.890
the only source I have
for Queen Victoria.

00:23:29.890 --> 00:23:32.010
It's the only place I can
go for that information.

00:23:32.010 --> 00:23:33.226
And not yet, in many cases.

00:23:33.226 --> 00:23:34.600
We're just really
getting started

00:23:34.600 --> 00:23:35.771
in a lot of those languages.

00:23:35.771 --> 00:23:37.270
So there's a lot
of work left to do.

00:23:37.270 --> 00:23:40.030
But it's interesting how that
impact will be different.

00:23:40.030 --> 00:23:42.187
Because instead of
saying, oh, we've

00:23:42.187 --> 00:23:43.270
got a glut of information.

00:23:43.270 --> 00:23:44.790
Let's summarize it in
an encyclopedia article.

00:23:44.790 --> 00:23:46.460
It's like, we have
no information,

00:23:46.460 --> 00:23:51.350
so let's share it with
people in this way.

00:23:51.350 --> 00:23:54.910
MICHAEL WOLF: The nature of how
people interact with the web

00:23:54.910 --> 00:23:56.980
is changing dramatically.

00:23:56.980 --> 00:24:00.890
And so everyone's aware
of the voice interface,

00:24:00.890 --> 00:24:05.700
but the reality is the digital
assistant, whether it's

00:24:05.700 --> 00:24:12.640
Alexa or Google Assist
or OK Google, or Siri,

00:24:12.640 --> 00:24:14.350
these are one of the
ways in which people

00:24:14.350 --> 00:24:16.140
will access information.

00:24:16.140 --> 00:24:20.170
How will Wikipedia adapt
to those new interfaces?

00:24:20.170 --> 00:24:21.990
JIMMY WALES: So it
is very interesting.

00:24:21.990 --> 00:24:26.710
I mean, we are an important part
of those interfaces already.

00:24:26.710 --> 00:24:31.392
If you ask Alexa a
question, 99% of the time,

00:24:31.392 --> 00:24:33.100
she's just going to
read Wikipedia to you

00:24:33.100 --> 00:24:35.680
or get a fact from Wikipedia.

00:24:35.680 --> 00:24:38.750
Obviously Google relies a lot
on Wikipedia for the Knowledge

00:24:38.750 --> 00:24:40.260
Graph.

00:24:40.260 --> 00:24:42.470
I don't actually use
the Google Assistant

00:24:42.470 --> 00:24:43.740
because I have Alexa at home.

00:24:43.740 --> 00:24:45.050
I assume it's very similar.

00:24:45.050 --> 00:24:49.110
Although I heard that if you
ask Google a question, it says,

00:24:49.110 --> 00:24:51.290
according to
Wikipedia-- thank you--

00:24:51.290 --> 00:24:54.260
whereas Alexa just acts
like she knows everything,

00:24:54.260 --> 00:24:57.800
even though she's just
reading it out of Wikipedia.

00:24:57.800 --> 00:24:58.660
So there's that.

00:24:58.660 --> 00:25:00.455
I need to email Jeff
Bezos about that.

00:25:00.455 --> 00:25:02.630
But.

00:25:02.630 --> 00:25:04.220
But what's interesting for us--

00:25:04.220 --> 00:25:05.240
MICHAEL WOLF: And Siri
asked you the question.

00:25:05.240 --> 00:25:06.405
JIMMY WALES: [LAUGHS] Yeah.

00:25:06.405 --> 00:25:06.710
I don't know.

00:25:06.710 --> 00:25:08.751
I try-- Siri didn't
understand what I was saying.

00:25:08.751 --> 00:25:11.570
So you know.

00:25:11.570 --> 00:25:17.510
So in any event, basically,
what's interesting to us

00:25:17.510 --> 00:25:19.070
about that is--

00:25:19.070 --> 00:25:22.040
and one of the areas that we
do slightly worry about it,

00:25:22.040 --> 00:25:24.080
but we don't have
firm evidence yet--

00:25:24.080 --> 00:25:25.610
one of the worries we have is--

00:25:25.610 --> 00:25:26.720
and we're not a business.

00:25:26.720 --> 00:25:27.407
We're a charity.

00:25:27.407 --> 00:25:29.240
So we don't think much
about business model,

00:25:29.240 --> 00:25:31.130
and we've never been
very good at thinking

00:25:31.130 --> 00:25:33.140
about business model.

00:25:33.140 --> 00:25:34.827
We just are a
group of people who

00:25:34.827 --> 00:25:36.410
are enjoying making
this encyclopedia,

00:25:36.410 --> 00:25:38.300
and we're really happy
that everybody likes it.

00:25:38.300 --> 00:25:40.383
But realistically, we do
have to think about that.

00:25:40.383 --> 00:25:44.270
So right now, the way
Wikipedia gets money to survive

00:25:44.270 --> 00:25:47.180
is you come to the website,
and there's a little banner.

00:25:47.180 --> 00:25:49.379
Very rarely, but
once a year you see--

00:25:49.379 --> 00:25:51.920
MICHAEL WOLF: Your photo does
very well in terms of getting--

00:25:51.920 --> 00:25:53.336
JIMMY WALES: It--
yeah, we haven't

00:25:53.336 --> 00:25:54.590
been using it in recent years.

00:25:54.590 --> 00:25:55.215
I'm very happy.

00:25:55.215 --> 00:25:57.980
We found this ugly yellow banner
that no one on Madison Avenue

00:25:57.980 --> 00:26:00.320
would think would work,
but it works beautifully.

00:26:00.320 --> 00:26:01.940
And actually, we are--

00:26:01.940 --> 00:26:05.090
more and more, our fundraising
is through the email campaign.

00:26:05.090 --> 00:26:07.280
Because our donors
are very loyal.

00:26:07.280 --> 00:26:09.140
And if you donate
to Wikipedia, a year

00:26:09.140 --> 00:26:12.860
later, you get a message from
me, which I may or may not

00:26:12.860 --> 00:26:16.120
have actually written, that
says, hey, it's been a year.

00:26:16.120 --> 00:26:17.090
Time to cough up again.

00:26:17.090 --> 00:26:21.180
And it gets a really
good response.

00:26:21.180 --> 00:26:22.540
And so that's the good news.

00:26:22.540 --> 00:26:23.540
What we worry about is--

00:26:23.540 --> 00:26:27.920
I call it the "how old
is Tom Cruise" problem.

00:26:27.920 --> 00:26:30.710
So five years ago,
10 years ago, if you

00:26:30.710 --> 00:26:33.480
typed, "how old is Tom
Cruise" into Google,

00:26:33.480 --> 00:26:35.014
the first link was Wikipedia.

00:26:35.014 --> 00:26:37.430
And you go there, and you find
out how old was Tom Cruise.

00:26:37.430 --> 00:26:39.805
Now the first link is still
Wikipedia, but up above that,

00:26:39.805 --> 00:26:42.604
it tells you how old Tom Cruise
is, because Google understands

00:26:42.604 --> 00:26:43.520
the world much better.

00:26:43.520 --> 00:26:45.180
Google read Wikipedia,
for one thing.

00:26:45.180 --> 00:26:47.200
And so we think, OK.

00:26:47.200 --> 00:26:49.242
But does that mean we're
not seeing that traffic,

00:26:49.242 --> 00:26:50.949
and does that mean
we're not going to get

00:26:50.949 --> 00:26:52.190
the donations from people?

00:26:52.190 --> 00:26:54.660
So far, we don't have
any evidence of that.

00:26:54.660 --> 00:26:57.247
And in fact, because the
Knowledge Graph does link

00:26:57.247 --> 00:26:57.830
to Wikipedia--

00:26:57.830 --> 00:26:59.580
I mean, we see a lot
of traffic from that.

00:26:59.580 --> 00:27:00.680
So it hasn't yet hurt us.

00:27:00.680 --> 00:27:03.710
But when we think then
about a voice assistant,

00:27:03.710 --> 00:27:07.499
if people are just
saying, who is Tom Cruise?

00:27:07.499 --> 00:27:09.290
And you get three
sentences from Wikipedia,

00:27:09.290 --> 00:27:10.310
and people don't know
where it's from--

00:27:10.310 --> 00:27:11.640
MICHAEL WOLF: So you're
concerned about attribution.

00:27:11.640 --> 00:27:12.910
JIMMY WALES: Concerned
about attribution.

00:27:12.910 --> 00:27:14.316
But even if there
is attribution,

00:27:14.316 --> 00:27:15.440
are people going to donate?

00:27:15.440 --> 00:27:16.400
We don't know.

00:27:16.400 --> 00:27:17.300
So far, so good.

00:27:17.300 --> 00:27:18.300
But that is one thing.

00:27:18.300 --> 00:27:23.964
And our view is, again,
the fundamental--

00:27:23.964 --> 00:27:25.380
the vision statement
for Wikipedia

00:27:25.380 --> 00:27:28.220
is, imagine a world in
which every single person

00:27:28.220 --> 00:27:30.890
on the planet is given
free access to the sum

00:27:30.890 --> 00:27:31.880
of all human knowledge.

00:27:31.880 --> 00:27:32.980
That's what we're doing.

00:27:32.980 --> 00:27:36.020
And so in that front,
and the community's view

00:27:36.020 --> 00:27:38.240
on this sort of thing, is
it's fucking fantastic.

00:27:38.240 --> 00:27:39.272
Like, amazing.

00:27:39.272 --> 00:27:41.480
Wikipedia is part of the
infrastructure of the world.

00:27:41.480 --> 00:27:43.280
All these new technologies
are coming out.

00:27:43.280 --> 00:27:45.830
The knowledge that we've
carefully stewarded and written

00:27:45.830 --> 00:27:46.985
is now helping people--

00:27:50.310 --> 00:27:52.140
When did Fred
Astaire die, right?

00:27:52.140 --> 00:27:54.390
You have this thought in
your kitchen for two seconds,

00:27:54.390 --> 00:27:57.262
and you ask Alexa, and she
tells you, amazing, right?

00:27:57.262 --> 00:27:58.720
We don't need to
get paid for that.

00:27:58.720 --> 00:28:00.530
That's what we're a charity for.

00:28:00.530 --> 00:28:02.686
We want everybody to
have access to knowledge.

00:28:02.686 --> 00:28:04.310
But there is a little
bit of a question

00:28:04.310 --> 00:28:08.870
about, OK, how does our business
model work if in 20 years,

00:28:08.870 --> 00:28:11.030
as technology changes,
we don't want to let

00:28:11.030 --> 00:28:13.270
Wikipedia get left behind?

00:28:13.270 --> 00:28:16.300
But so far, we're doing
great financially.

00:28:16.300 --> 00:28:20.240
So we always run it in
a very conservative way.

00:28:20.240 --> 00:28:21.440
We ask for money.

00:28:21.440 --> 00:28:24.320
Sometimes we're getting
criticism from, I think,

00:28:24.320 --> 00:28:27.110
rather stupid press outlets,
who say, why is Wikipedia

00:28:27.110 --> 00:28:27.860
begging for money?

00:28:27.860 --> 00:28:30.470
They have $100
million in the bank.

00:28:30.470 --> 00:28:34.380
And it's like, well, our annual
budget is about $70 million,

00:28:34.380 --> 00:28:35.970
so we have about
18 months reserve.

00:28:35.970 --> 00:28:38.480
That's considered to be a
healthy level of reserves

00:28:38.480 --> 00:28:39.620
for a nonprofit.

00:28:39.620 --> 00:28:42.260
We're not apologetic about that.

00:28:42.260 --> 00:28:44.110
But every year, we've been--

00:28:44.110 --> 00:28:46.966
last year-- well,
thanks to the president,

00:28:46.966 --> 00:28:48.590
who is not necessarily
a big fan of us,

00:28:48.590 --> 00:28:50.210
but who has motivated
people to care

00:28:50.210 --> 00:28:55.760
about knowledge, in a
roundabout way, from the day

00:28:55.760 --> 00:28:57.830
after the election, we
saw a massive increase

00:28:57.830 --> 00:29:02.360
in donations, which was
very heartwarming to see.

00:29:02.360 --> 00:29:04.120
Because you know.

00:29:04.120 --> 00:29:06.380
And we'll get on to
fake news in a bit

00:29:06.380 --> 00:29:08.710
when we're talking
about WikiTribune.

00:29:08.710 --> 00:29:14.215
But we've decided we're also
raising an endowment fund.

00:29:14.215 --> 00:29:16.340
Because we do think of
ourselves not so much as a--

00:29:16.340 --> 00:29:17.689
I mean, we're not a dot.com.

00:29:17.689 --> 00:29:18.730
We're not a tech startup.

00:29:18.730 --> 00:29:21.440
We're a charity
sharing knowledge,

00:29:21.440 --> 00:29:23.070
and we try to think
in the long run.

00:29:23.070 --> 00:29:24.890
And so one of the
things we say is, look,

00:29:24.890 --> 00:29:28.649
while we're not in desperate
financial situation,

00:29:28.649 --> 00:29:30.690
we should be thinking
about the long-term future.

00:29:30.690 --> 00:29:31.760
So we've now got--

00:29:31.760 --> 00:29:35.450
we're raising $100
million endowment fund.

00:29:35.450 --> 00:29:39.041
And I think we've got pledges
for about $17 million so far.

00:29:39.041 --> 00:29:41.040
And it's really the first
time that we've really

00:29:41.040 --> 00:29:43.770
tried to have more of
a major donor campaign.

00:29:43.770 --> 00:29:46.350
Because the vast majority
of the money for Wikipedia

00:29:46.350 --> 00:29:47.550
comes from those--

00:29:47.550 --> 00:29:49.350
you see the banner,
and you give $20.

00:29:49.350 --> 00:29:52.040
And that's the vast
majority of the money.

00:29:52.040 --> 00:29:54.540
And we've never been really
good at doing major donor stuff,

00:29:54.540 --> 00:29:57.200
but we think this is
an interesting product,

00:29:57.200 --> 00:29:59.310
you might call it,
for a major donor

00:29:59.310 --> 00:30:01.620
to say, don't just
fund our annual budget,

00:30:01.620 --> 00:30:02.670
think about the future.

00:30:02.670 --> 00:30:04.530
We want Wikipedia and
the idea of Wikipedia

00:30:04.530 --> 00:30:06.040
to be safe in the long run.

00:30:06.040 --> 00:30:08.730
So we want to have this fund
for any future emergencies

00:30:08.730 --> 00:30:09.940
or any future opportunities.

00:30:09.940 --> 00:30:11.610
And we've done it
all the right way.

00:30:11.610 --> 00:30:12.990
We've got a separate
board, so there's

00:30:12.990 --> 00:30:14.864
another layer of
governance, so it's not just

00:30:14.864 --> 00:30:17.870
a big bank account for
some future profligate CEO

00:30:17.870 --> 00:30:18.590
and so forth.

00:30:18.590 --> 00:30:20.170
So, so far, so good.

00:30:20.170 --> 00:30:22.420
MICHAEL WOLF: I'm going to
ask everybody for questions

00:30:22.420 --> 00:30:24.940
a little later, so please
start thinking about them.

00:30:24.940 --> 00:30:28.790
But in the meantime, I'd like
to welcome Orit Kopel, who's

00:30:28.790 --> 00:30:31.392
your co-founder of WikiTribune.

00:30:31.392 --> 00:30:32.100
JIMMY WALES: Yes.

00:30:32.100 --> 00:30:32.700
Fantastic.

00:30:32.700 --> 00:30:33.680
MICHAEL WOLF: Orit,
you're somewhere?

00:30:33.680 --> 00:30:35.138
JIMMY WALES: Orit,
there she comes.

00:30:35.138 --> 00:30:37.520
[APPLAUSE]

00:30:41.370 --> 00:30:42.464
ORIT KOPEL: Hi.

00:30:42.464 --> 00:30:43.380
MICHAEL WOLF: Welcome.

00:30:43.380 --> 00:30:44.296
ORIT KOPEL: Thank you.

00:30:44.296 --> 00:30:46.774
MICHAEL WOLF: So what should
we know about WikiTribune?

00:30:46.774 --> 00:30:48.190
JIMMY WALES: Do
you want to start?

00:30:48.190 --> 00:30:50.820
I have to let her start, because
I'm terrible about just--

00:30:50.820 --> 00:30:52.810
I can just sit here and talk.

00:30:52.810 --> 00:30:56.300
ORIT KOPEL: Well, how many of
you have heard of WikiTribune?

00:30:56.300 --> 00:30:57.130
Oh, that's great.

00:30:57.130 --> 00:30:57.630
OK.

00:30:57.630 --> 00:30:59.880
It's Google here, so.

00:30:59.880 --> 00:31:02.700
It's a new, inventive
news platform

00:31:02.700 --> 00:31:04.380
which involves
journalism in a way that

00:31:04.380 --> 00:31:07.530
has never been done before
by bringing together

00:31:07.530 --> 00:31:10.320
a Wiki-based community
of volunteers

00:31:10.320 --> 00:31:12.870
and hired professional
journalists in an effort

00:31:12.870 --> 00:31:15.710
to create a
collaborative news space.

00:31:15.710 --> 00:31:19.170
A high-quality, open platform
which is generally community

00:31:19.170 --> 00:31:22.500
controlled and have the backbone
of professional journalists.

00:31:22.500 --> 00:31:26.490
And so we practically attend
the community of volunteers

00:31:26.490 --> 00:31:28.860
and the hired
journalists as equals.

00:31:28.860 --> 00:31:32.460
And it is a Wiki-based
platform, so everyone can edit

00:31:32.460 --> 00:31:35.150
every article on our website.

00:31:35.150 --> 00:31:37.970
MICHAEL WOLF: So--
but how do you

00:31:37.970 --> 00:31:40.490
ensure freedom of expression?

00:31:40.490 --> 00:31:43.290
And this is not just-- this
isn't just journalists.

00:31:43.290 --> 00:31:47.360
These are individuals who are
today posting to social media.

00:31:47.360 --> 00:31:49.867
First of all, what do we
need to protect them from?

00:31:49.867 --> 00:31:51.200
And how do we ensure expression?

00:31:51.200 --> 00:31:52.640
JIMMY WALES: Yeah, one
thing I wanted to explain.

00:31:52.640 --> 00:31:55.460
Because there was a little
error in the introduction, so.

00:31:55.460 --> 00:31:59.236
In 2015, I didn't set up
the Wikipedia Foundation.

00:31:59.236 --> 00:32:01.610
The Wikipedia Foundation has
been around for a long time.

00:32:01.610 --> 00:32:05.960
In 2015, I set up the
Jimmy Wales Foundation

00:32:05.960 --> 00:32:10.550
for Freedom of Expression, which
is a nonprofit based in the UK.

00:32:10.550 --> 00:32:12.750
What we do is we fight for--

00:32:12.750 --> 00:32:14.270
mainly for social media users.

00:32:14.270 --> 00:32:16.610
So people who aren't covered.

00:32:16.610 --> 00:32:18.860
So Reporters Without
Borders does a fantastic job

00:32:18.860 --> 00:32:22.190
of working to highlight cases
of journalists being arrested,

00:32:22.190 --> 00:32:25.261
but a lot of times, ordinary
people who say something

00:32:25.261 --> 00:32:27.260
and get themselves arrested,
a political speech,

00:32:27.260 --> 00:32:28.770
get a bit ignored.

00:32:28.770 --> 00:32:31.190
And so we try to campaign for
those people, and so forth.

00:32:31.190 --> 00:32:35.150
And Orit is the CEO of the
Jimmy Wales Foundation.

00:32:35.150 --> 00:32:38.630
And that's a separate piece
of work from WikiTribune,

00:32:38.630 --> 00:32:39.795
which is a new project.

00:32:39.795 --> 00:32:42.800
Jim Wales Foundation,
what happened there,

00:32:42.800 --> 00:32:47.450
I went to Dubai to
give a speech, as I do.

00:32:47.450 --> 00:32:50.780
And when I landed, they
said, oh, congratulations.

00:32:50.780 --> 00:32:52.760
The leader of Dubai
has decided to give you

00:32:52.760 --> 00:32:56.330
a half a million dollars
as the Knowledge Award.

00:32:56.330 --> 00:32:57.970
And I was like, OK.

00:32:57.970 --> 00:32:58.490
Fine.

00:32:58.490 --> 00:32:59.406
That sounds all right.

00:32:59.406 --> 00:33:01.790
But then I went back to
my room, and I was like,

00:33:01.790 --> 00:33:06.080
you know, I'm super critical
of Dubai on human rights

00:33:06.080 --> 00:33:09.360
issues, freedom of
expression, and so forth.

00:33:09.360 --> 00:33:13.700
So I can't in good conscience
take this money and buy a boat.

00:33:13.700 --> 00:33:15.410
And so that was when I said, OK.

00:33:15.410 --> 00:33:18.260
I'm going to take the money,
which is from a bad source,

00:33:18.260 --> 00:33:19.242
in my opinion.

00:33:19.242 --> 00:33:20.700
I don't want to
give it back to him

00:33:20.700 --> 00:33:24.799
so he can hire more
people to beat bloggers.

00:33:24.799 --> 00:33:27.090
Instead I'll use it to fight
for freedom of expression.

00:33:27.090 --> 00:33:29.540
So that's when we started
working together on that.

00:33:29.540 --> 00:33:31.160
And so that's been great fun.

00:33:31.160 --> 00:33:31.868
MICHAEL WOLF: OK.

00:33:31.868 --> 00:33:33.370
So then explain
WikiTribune, please.

00:33:33.370 --> 00:33:34.328
JIMMY WALES: All right.

00:33:34.328 --> 00:33:36.170
So WikiTribune.

00:33:36.170 --> 00:33:39.360
So WikiTribune, we
just started this year.

00:33:39.360 --> 00:33:42.740
Orit gave the basic concept of
it, a little of the history.

00:33:42.740 --> 00:33:47.870
We decided to launch using
a crowdfunding campaign.

00:33:47.870 --> 00:33:49.640
And I really am a big
fan of crowdfunding.

00:33:49.640 --> 00:33:54.500
As an entrepreneur
starting something new,

00:33:54.500 --> 00:33:56.979
I could have easily gone and
raised money in Silicon Valley

00:33:56.979 --> 00:33:59.270
to do it, but I don't know
if the public is interested.

00:33:59.270 --> 00:34:00.690
Do they want this?

00:34:00.690 --> 00:34:04.120
And so saying to people, hey,
will you sign up to contribute?

00:34:04.120 --> 00:34:08.030
And the business model
is we asked people

00:34:08.030 --> 00:34:10.100
to become monthly supporters.

00:34:10.100 --> 00:34:12.080
We have no paywall
and no advertising.

00:34:12.080 --> 00:34:14.917
So a series of bad business
decisions, but it's

00:34:14.917 --> 00:34:16.250
how I've built my career so far.

00:34:18.760 --> 00:34:19.510
But I didn't know.

00:34:19.510 --> 00:34:20.949
I'm like, will that even work?

00:34:20.949 --> 00:34:22.032
Will people be interested?

00:34:22.032 --> 00:34:23.480
So we did a
crowdfunding campaign.

00:34:23.480 --> 00:34:25.188
Not on Kickstarter or
anywhere like that,

00:34:25.188 --> 00:34:26.840
we just did it independently.

00:34:26.840 --> 00:34:27.679
And we got a great--

00:34:27.679 --> 00:34:28.250
you know, I said, look.

00:34:28.250 --> 00:34:30.600
I need enough money to hire
10 journalists and some tech

00:34:30.600 --> 00:34:31.100
people.

00:34:31.100 --> 00:34:32.840
And so we managed to do that.

00:34:32.840 --> 00:34:36.320
We also got a lovely
grant from Google.

00:34:36.320 --> 00:34:39.020
Google Digital News
Initiative, in Europe,

00:34:39.020 --> 00:34:41.570
to develop the software.

00:34:41.570 --> 00:34:43.820
We're taking WordPress
as a platform

00:34:43.820 --> 00:34:45.000
and turning it into a wiki.

00:34:45.000 --> 00:34:48.206
And as it turns out, WordPress
doesn't want to be a wiki.

00:34:48.206 --> 00:34:49.580
So there's a lot
of beating on it

00:34:49.580 --> 00:34:55.500
to make that more
useful in that regard.

00:34:55.500 --> 00:35:00.740
And we went into closed
beta for a while,

00:35:00.740 --> 00:35:03.375
and then now, just two
weeks ago, we've opened--

00:35:03.375 --> 00:35:05.750
you can go and sign up, and
you can start editing things.

00:35:05.750 --> 00:35:08.660
And we've got now 13
journalists hired--

00:35:08.660 --> 00:35:12.337
some of them are part-time,
but 10 full-time equivalents--

00:35:12.337 --> 00:35:14.920
around the world, but mostly in
London, which is where I live.

00:35:14.920 --> 00:35:16.380
And that's where we are today.

00:35:16.380 --> 00:35:17.630
And we are publishing stories.

00:35:17.630 --> 00:35:19.338
So go to WikiTribune,
and you can see it.

00:35:19.338 --> 00:35:21.710
MICHAEL WOLF: So what
is-- just for this group

00:35:21.710 --> 00:35:26.090
to understand-- what is the
problem that WikiTribune solves

00:35:26.090 --> 00:35:29.720
versus what
Wikipedia does today?

00:35:29.720 --> 00:35:30.470
JIMMY WALES: Yeah.

00:35:30.470 --> 00:35:34.160
So Wikipedia is not news.

00:35:34.160 --> 00:35:36.170
There's a page on Wikipedia
that says, not news.

00:35:36.170 --> 00:35:36.800
We're not news.

00:35:36.800 --> 00:35:38.550
Now, of course,
Wikipedia, quite famously,

00:35:38.550 --> 00:35:41.510
does update very quickly
when news events happen,

00:35:41.510 --> 00:35:44.300
but it doesn't cover every
single thing as it's happening.

00:35:44.300 --> 00:35:48.110
And also at Wikipedia, one
of the fundamental rules

00:35:48.110 --> 00:35:50.090
is no original research.

00:35:50.090 --> 00:35:51.890
And so everything
in Wikipedia should

00:35:51.890 --> 00:35:54.440
have been published in a
high-quality, third-party

00:35:54.440 --> 00:35:55.489
source.

00:35:55.489 --> 00:35:57.530
But to do journalism--
journalism, by definition,

00:35:57.530 --> 00:35:58.742
is original research.

00:35:58.742 --> 00:36:00.200
It's actually going
out and getting

00:36:00.200 --> 00:36:02.330
new stories, new information.

00:36:02.330 --> 00:36:06.800
What I'm hopeful for, and
the concept behind this

00:36:06.800 --> 00:36:10.280
is to say, look, if we can
find a way for a community

00:36:10.280 --> 00:36:12.830
to usefully and
productively help out

00:36:12.830 --> 00:36:14.750
with the process
of journalism, it

00:36:14.750 --> 00:36:16.695
lowers the costs significantly.

00:36:16.695 --> 00:36:18.320
And by lowering the
cost significantly,

00:36:18.320 --> 00:36:20.611
that means of the money we
get from readers, more of it

00:36:20.611 --> 00:36:22.900
can be spent on journalists.

00:36:22.900 --> 00:36:25.400
If I was on the board of "The
Guardian"-- and "The Guardian"

00:36:25.400 --> 00:36:27.412
has lots and lots
of journalists.

00:36:27.412 --> 00:36:28.370
It's a fantastic paper.

00:36:28.370 --> 00:36:30.203
But they've got a lot
of people doing things

00:36:30.203 --> 00:36:32.330
inside "The Guardian"
that I know people

00:36:32.330 --> 00:36:33.750
would enjoy doing themselves.

00:36:33.750 --> 00:36:36.030
There's no reason to pay
staff to do something

00:36:36.030 --> 00:36:39.430
that people would enjoy doing
if they're invited to do it.

00:36:39.430 --> 00:36:42.120
And one of those
things, for example,

00:36:42.120 --> 00:36:45.900
is policing for
neutrality, which

00:36:45.900 --> 00:36:49.170
is something that most
newspapers these days are

00:36:49.170 --> 00:36:50.850
very, very bad at.

00:36:50.850 --> 00:36:53.500
MICHAEL WOLF: So explain to--
what do you mean by neutrality?

00:36:53.500 --> 00:36:55.150
JIMMY WALES: Neutrality.

00:36:55.150 --> 00:36:59.070
Well, you're familiar
with it from Wikipedia.

00:36:59.070 --> 00:37:02.910
Wikipedia tries very
hard to be quite neutral

00:37:02.910 --> 00:37:05.010
and succeeds, for the most part.

00:37:05.010 --> 00:37:10.350
And most media outlets
these days don't even try.

00:37:10.350 --> 00:37:11.300
I mean, a few do.

00:37:11.300 --> 00:37:14.490
Good quality papers
still try to be neutral.

00:37:14.490 --> 00:37:18.480
I don't think-- if we think
of neutrality, I mean,

00:37:18.480 --> 00:37:20.730
we've been criticized
on the neutrality front

00:37:20.730 --> 00:37:23.580
from both the right and the
left at WikiTribune already.

00:37:23.580 --> 00:37:28.920
So Breitbart had a really nasty
article about WikiTribune.

00:37:28.920 --> 00:37:30.220
And I was like, right.

00:37:30.220 --> 00:37:31.980
MICHAEL WOLF: Not living to
their standard of neutrality.

00:37:31.980 --> 00:37:33.150
JIMMY WALES: Not living
to Breitbart's standard

00:37:33.150 --> 00:37:33.480
of neutrality.

00:37:33.480 --> 00:37:35.354
No, it was basically
saying we were obviously

00:37:35.354 --> 00:37:37.105
a bunch of lefties, and so on.

00:37:37.105 --> 00:37:39.480
And then we had a left-wing
journalist saying, obviously,

00:37:39.480 --> 00:37:42.000
there's no such thing as truth.

00:37:42.000 --> 00:37:44.370
So I'm exaggerating.

00:37:44.370 --> 00:37:47.242
But basically,
everybody-- the simple way

00:37:47.242 --> 00:37:49.440
to understand it
philosophically is everybody

00:37:49.440 --> 00:37:51.011
knows what bias looks like.

00:37:51.011 --> 00:37:51.510
You know?

00:37:51.510 --> 00:37:53.120
If we mention Breitbart
and neutrality

00:37:53.120 --> 00:37:55.320
in the same sentence,
we all chuckle,

00:37:55.320 --> 00:37:57.750
because we know they don't
even try to be neutral.

00:37:57.750 --> 00:38:00.410
Same with the "Daily
Mail," for example.

00:38:00.410 --> 00:38:02.160
And frankly, the same
with "The Guardian."

00:38:02.160 --> 00:38:03.690
I love "The Guardian,"
but they're not

00:38:03.690 --> 00:38:04.523
a neutral newspaper.

00:38:04.523 --> 00:38:08.250
They come from a particular
liberal position.

00:38:08.250 --> 00:38:10.230
And the idea is to
say, look, actually,

00:38:10.230 --> 00:38:12.360
you should try to
just report the facts

00:38:12.360 --> 00:38:13.710
in a very neutral manner.

00:38:13.710 --> 00:38:15.330
And it's important
to really try.

00:38:15.330 --> 00:38:16.607
Will you get there perfectly?

00:38:16.607 --> 00:38:17.190
Of course not.

00:38:17.190 --> 00:38:18.260
Not every time.

00:38:18.260 --> 00:38:21.780
But one of the ways that you
can get there is if you do

00:38:21.780 --> 00:38:24.000
have a healthy
community, who aren't

00:38:24.000 --> 00:38:26.580
just people screaming at each
other, who are saying, yeah.

00:38:26.580 --> 00:38:28.350
Actually, we've
got some diversity

00:38:28.350 --> 00:38:31.920
in the community to make sure
that we're not just focusing

00:38:31.920 --> 00:38:33.330
on one side of the issue.

00:38:33.330 --> 00:38:34.980
We're actually
taking into account

00:38:34.980 --> 00:38:37.950
the best arguments of the other
side, et cetera, et cetera.

00:38:37.950 --> 00:38:39.991
MICHAEL WOLF: So please
get your questions ready.

00:38:39.991 --> 00:38:42.240
I have one more question
for Jimmy and Orit,

00:38:42.240 --> 00:38:44.930
and then we'll open it up.

00:38:44.930 --> 00:38:49.740
So there are 3,000 people
in the Wikipedia world

00:38:49.740 --> 00:38:51.450
who are probably
the most important,

00:38:51.450 --> 00:38:53.279
and they're important
for everybody.

00:38:53.279 --> 00:38:55.320
There's also a-- and
they're known to each other.

00:38:55.320 --> 00:38:57.810
There's also a set of
people in the world who

00:38:57.810 --> 00:39:00.222
are maybe equally
or more important,

00:39:00.222 --> 00:39:01.680
and those are the
people who create

00:39:01.680 --> 00:39:03.630
the algorithm for Google.

00:39:03.630 --> 00:39:05.700
What should Google
take away from what

00:39:05.700 --> 00:39:08.670
you've been able to
accomplish and the way

00:39:08.670 --> 00:39:12.076
you see the world going forward
in terms of information?

00:39:12.076 --> 00:39:13.325
JIMMY WALES: Oh, I don't know.

00:39:13.325 --> 00:39:15.900
[LAUGHS] I mean, I--

00:39:15.900 --> 00:39:18.240
that's a really-- it's
a really tough problem.

00:39:18.240 --> 00:39:23.780
I mean, so one of the
things that I think--

00:39:23.780 --> 00:39:24.535
I don't know.

00:39:24.535 --> 00:39:25.160
I have no idea.

00:39:25.160 --> 00:39:26.451
That's a really tough question.

00:39:26.451 --> 00:39:30.240
I'll just comment
somewhere near that.

00:39:30.240 --> 00:39:32.960
So I was part of a
group that Google

00:39:32.960 --> 00:39:36.950
asked to help and be
advising about the "Right

00:39:36.950 --> 00:39:38.390
to Be Forgotten"
in Europe, which

00:39:38.390 --> 00:39:40.570
was a huge deal in Europe.

00:39:40.570 --> 00:39:43.100
This is Orit and I
were working together.

00:39:43.100 --> 00:39:46.940
She was helping me write
stuff for Google and so forth.

00:39:46.940 --> 00:39:52.410
And the issue there is that in
Europe, the state of the law

00:39:52.410 --> 00:39:55.520
is really, it's a disaster
for freedom of expression.

00:39:55.520 --> 00:39:58.112
It's really not appropriate.

00:39:58.112 --> 00:39:59.570
And the problem is
the law that has

00:39:59.570 --> 00:40:03.170
been applied by the courts is
actually older than Google.

00:40:03.170 --> 00:40:05.390
The particular case
that went through

00:40:05.390 --> 00:40:11.690
was a lawyer in Spain had had
some sort of a tax problem,

00:40:11.690 --> 00:40:13.850
and his house had
been taken from him

00:40:13.850 --> 00:40:15.350
and had to be auctioned.

00:40:15.350 --> 00:40:17.270
And he-- and this was
covered in the papers.

00:40:17.270 --> 00:40:19.160
It was actually
an official notice

00:40:19.160 --> 00:40:20.990
from the courts that
was in the papers.

00:40:20.990 --> 00:40:22.910
It's still published
in that paper,

00:40:22.910 --> 00:40:25.700
but Google is not
allowed to link to it,

00:40:25.700 --> 00:40:29.156
on the grounds that it's out
of date, irrelevant, et cetera.

00:40:29.156 --> 00:40:30.530
Now, to me, that's
not irrelevant

00:40:30.530 --> 00:40:34.310
at all if my lawyer has had his
house taken for tax reasons.

00:40:34.310 --> 00:40:36.610
That's probably
important for me to know.

00:40:36.610 --> 00:40:37.730
But so there you have it.

00:40:37.730 --> 00:40:40.400
So it's really a bad thing.

00:40:40.400 --> 00:40:42.170
But there are other
cases where you can

00:40:42.170 --> 00:40:43.880
be a little more sympathetic.

00:40:46.670 --> 00:40:49.700
Revenge porn, things
like that, where

00:40:49.700 --> 00:40:52.730
if Google is linking to
it, that's problematic.

00:40:52.730 --> 00:40:57.020
My belief is that any demand
to take down content or a link

00:40:57.020 --> 00:40:59.750
to content should
go through a judge.

00:40:59.750 --> 00:41:02.210
It shouldn't be--
the way it is now,

00:41:02.210 --> 00:41:06.110
Google is mandated to be
judge, jury, and executioner

00:41:06.110 --> 00:41:06.810
on these things.

00:41:06.810 --> 00:41:07.760
And there's not--
for publishers,

00:41:07.760 --> 00:41:09.770
there's not a really
clear right of appeal.

00:41:09.770 --> 00:41:12.020
And Google shouldn't
have that responsibility.

00:41:12.020 --> 00:41:13.610
Google, I think,
takes it seriously

00:41:13.610 --> 00:41:16.580
to try to do the right thing,
but it's just not the--

00:41:16.580 --> 00:41:18.980
public policy-wise, it's
not the right answer.

00:41:18.980 --> 00:41:22.490
But one of the things I
said to Eric Schmidt, when

00:41:22.490 --> 00:41:24.460
we were going around
doing this, is I said--

00:41:24.460 --> 00:41:25.640
we were doing hearings
around Europe.

00:41:25.640 --> 00:41:27.056
Hearings from all
kinds of experts

00:41:27.056 --> 00:41:28.360
on all sides of the issue.

00:41:28.360 --> 00:41:31.190
I said, I wish we were doing
these hearings two years ago,

00:41:31.190 --> 00:41:33.880
before it became a
legal court issue.

00:41:33.880 --> 00:41:36.830
Because I actually think this
is a search quality issue that,

00:41:36.830 --> 00:41:38.870
for Google, you
don't really want

00:41:38.870 --> 00:41:40.895
to be linking to revenge porn.

00:41:40.895 --> 00:41:42.770
You really want to have
a well-understood and

00:41:42.770 --> 00:41:44.910
well-developed editorial policy.

00:41:44.910 --> 00:41:47.360
And of course,
Google traditionally

00:41:47.360 --> 00:41:51.290
has kind of been a
little reluctant to say,

00:41:51.290 --> 00:41:53.527
we choose to link to things
we think are quality.

00:41:53.527 --> 00:41:54.860
We're like "The New York Times."

00:41:54.860 --> 00:41:56.800
We have a right of
freedom of expression.

00:41:56.800 --> 00:42:00.110
Instead, Google has preferred
to go, mm, it's the algorithm.

00:42:00.110 --> 00:42:01.730
And I think that may have been--

00:42:01.730 --> 00:42:03.440
I'm not a lawyer,
so I don't know

00:42:03.440 --> 00:42:05.150
why that approach was taken.

00:42:05.150 --> 00:42:06.620
I think it may have
been a mistake.

00:42:06.620 --> 00:42:09.140
Because I do think, for a
lot of the kinds of things

00:42:09.140 --> 00:42:11.810
that Google is linking
to or shouldn't

00:42:11.810 --> 00:42:14.840
be linking to, rather than
having the law dictate it,

00:42:14.840 --> 00:42:17.180
most of the time, I
think Google should just

00:42:17.180 --> 00:42:19.144
make those decisions
to say, yeah,

00:42:19.144 --> 00:42:20.810
we're not going to
link to revenge porn.

00:42:20.810 --> 00:42:23.030
So if there's a revenge
porn link out there,

00:42:23.030 --> 00:42:24.660
and we're notified, we're
going to take that link down.

00:42:24.660 --> 00:42:25.560
Which I think they do now.

00:42:25.560 --> 00:42:26.105
But.

00:42:26.105 --> 00:42:26.938
MICHAEL WOLF: Great.

00:42:26.938 --> 00:42:30.710
Well, this is a good
transition to questions.

00:42:30.710 --> 00:42:35.960
If your questions-- there are
two microphones on either side,

00:42:35.960 --> 00:42:40.220
since we need this
to go on video.

00:42:40.220 --> 00:42:40.760
Questions.

00:42:40.760 --> 00:42:42.900
Does anybody have questions?

00:42:42.900 --> 00:42:43.400
Yes, please.

00:42:43.400 --> 00:42:43.950
AUDIENCE: Hi.

00:42:43.950 --> 00:42:45.658
I was wondering what
the relationship was

00:42:45.658 --> 00:42:47.520
between WikiTribune
and Wikipedia

00:42:47.520 --> 00:42:49.682
or what the intended
goal relationship is?

00:42:49.682 --> 00:42:50.390
JIMMY WALES: Yes.

00:42:50.390 --> 00:42:54.020
So WikiTribune is a
completely new organization,

00:42:54.020 --> 00:42:57.230
and there is no
relationship at all.

00:42:57.230 --> 00:43:00.230
I'm on the board of
both, but that's it.

00:43:00.230 --> 00:43:02.900
And the reason I did it
that way, one of the things

00:43:02.900 --> 00:43:06.620
that's fantastic about
the world of Wikipedia

00:43:06.620 --> 00:43:10.490
is that all decisions get made
through a very long process

00:43:10.490 --> 00:43:14.180
of community consultation
and deliberation,

00:43:14.180 --> 00:43:16.700
which means we're very
slow at making decisions,

00:43:16.700 --> 00:43:19.226
but we tend to make
very good decisions.

00:43:19.226 --> 00:43:21.350
This is a startup where
I'm going to have to change

00:43:21.350 --> 00:43:23.450
the website like 10
times quite radically,

00:43:23.450 --> 00:43:25.580
as we figure out what's
working, what isn't.

00:43:25.580 --> 00:43:27.440
And it wasn't really
possible to even launch

00:43:27.440 --> 00:43:28.622
something like this--

00:43:28.622 --> 00:43:30.830
it would be a massive, sort
of two-year consultation,

00:43:30.830 --> 00:43:33.060
and I wanted to
just move quickly.

00:43:33.060 --> 00:43:35.160
So that's why we're
doing it this way.

00:43:35.160 --> 00:43:37.677
MICHAEL WOLF: Other questions?

00:43:37.677 --> 00:43:38.510
AUDIENCE: Hi, Jimmy.

00:43:38.510 --> 00:43:42.390
Thanks very much for an
interesting conversation.

00:43:42.390 --> 00:43:44.650
You mentioned that
you live in London.

00:43:44.650 --> 00:43:47.420
I think the foundation
is based in the UK.

00:43:47.420 --> 00:43:51.030
The UK also has famously
restrictive and gruesome libel

00:43:51.030 --> 00:43:54.390
laws that massively restrict
freedom of expression.

00:43:54.390 --> 00:43:56.910
Is there any kind of risk
to the foundation for that?

00:43:56.910 --> 00:43:58.880
Or is there some kind
of irony in there?

00:43:58.880 --> 00:43:59.990
To base it right there?

00:43:59.990 --> 00:44:00.656
JIMMY WALES: OK.

00:44:00.656 --> 00:44:02.910
So the Jimmy Wales
Foundation is based

00:44:02.910 --> 00:44:05.240
in the UK, a completely
separate organization.

00:44:05.240 --> 00:44:06.570
We have too many organizations.

00:44:06.570 --> 00:44:08.844
WikiTribune is based in the UK.

00:44:08.844 --> 00:44:10.260
And then the
Wikimedia Foundation,

00:44:10.260 --> 00:44:13.340
which runs Wikipedia,
is in California.

00:44:13.340 --> 00:44:16.950
So on the libel law
front for WikiTribune,

00:44:16.950 --> 00:44:20.020
the law has changed
recently in the UK.

00:44:20.020 --> 00:44:22.860
It's become a lot better,
but it's still by no means

00:44:22.860 --> 00:44:28.530
as good as in the US.

00:44:28.530 --> 00:44:30.300
But I'm not that
worried about it

00:44:30.300 --> 00:44:33.840
because we want to be really
very high-quality, very

00:44:33.840 --> 00:44:36.040
neutral, very fact-based.

00:44:36.040 --> 00:44:39.750
Obviously, there's always a
risk of a lawsuit, of course.

00:44:39.750 --> 00:44:42.160
But if the "Daily
Mail" can survive

00:44:42.160 --> 00:44:43.660
without being sued
out of existence,

00:44:43.660 --> 00:44:44.868
I imagine we'll be all right.

00:44:47.970 --> 00:44:49.730
MICHAEL WOLF:
Right here, please.

00:44:49.730 --> 00:44:52.505
AUDIENCE: What's your
plans for scope and scale

00:44:52.505 --> 00:44:53.700
of the first year?

00:44:53.700 --> 00:44:56.010
How many stories
on an average day

00:44:56.010 --> 00:44:59.215
would you want to have
up on WikiTribune?

00:44:59.215 --> 00:45:01.092
JIMMY WALES: I
don't really know.

00:45:01.092 --> 00:45:01.800
We want to have--

00:45:01.800 --> 00:45:02.380
ORIT KOPEL: As much as possible.

00:45:02.380 --> 00:45:03.190
JIMMY WALES: As
much as possible,

00:45:03.190 --> 00:45:05.080
but without
compromising quality.

00:45:05.080 --> 00:45:07.210
So there are a lot of
interesting open questions.

00:45:07.210 --> 00:45:11.140
So right now, because
we've just launched,

00:45:11.140 --> 00:45:14.500
basically, what we say is that
the community and the staff

00:45:14.500 --> 00:45:16.930
are equals, but that
doesn't mean that everybody

00:45:16.930 --> 00:45:18.650
is the editor in chief.

00:45:18.650 --> 00:45:20.867
And so we do have editors
who approve things

00:45:20.867 --> 00:45:23.200
before they're published, and
they treat the journalists

00:45:23.200 --> 00:45:24.859
and the staff as
equal in that regard.

00:45:24.859 --> 00:45:26.650
So right now, we're
being a little bit slow

00:45:26.650 --> 00:45:28.316
about what we're
putting out, because we

00:45:28.316 --> 00:45:29.680
want it to be good quality.

00:45:29.680 --> 00:45:31.750
Part of that is I
wouldn't do it this way

00:45:31.750 --> 00:45:35.640
if I weren't a well-known
person already.

00:45:35.640 --> 00:45:38.490
But I know that a
lot of people who--

00:45:38.490 --> 00:45:40.150
at the "Daily
Mail," for example,

00:45:40.150 --> 00:45:42.910
are just waiting for us to
publish some error to just sort

00:45:42.910 --> 00:45:44.410
of take us down a notch.

00:45:44.410 --> 00:45:45.640
And we'd rather be--

00:45:45.640 --> 00:45:46.270
MICHAEL WOLF: You're
held to a high standard.

00:45:46.270 --> 00:45:46.960
JIMMY WALES: Held
to a high standard

00:45:46.960 --> 00:45:50.260
from day one, whereas Wikipedia
was not held to a high standard

00:45:50.260 --> 00:45:54.129
from day one, because nobody
knew what we were doing.

00:45:54.129 --> 00:45:54.670
Nobody cared.

00:45:54.670 --> 00:45:55.750
They were like, they're
a tiny little group

00:45:55.750 --> 00:45:58.102
of people in an obscure
corner of the internet.

00:45:58.102 --> 00:45:59.560
Eventually, though,
I think we want

00:45:59.560 --> 00:46:02.440
to open it up to have stories
published quite quickly.

00:46:02.440 --> 00:46:03.580
A lot of open-ended things.

00:46:03.580 --> 00:46:05.920
I'm happy to have
short, little stub

00:46:05.920 --> 00:46:08.710
articles that are just quick
updates rather than a fully

00:46:08.710 --> 00:46:10.060
composed piece.

00:46:10.060 --> 00:46:11.260
But to be determined.

00:46:11.260 --> 00:46:11.990
To be determined.

00:46:11.990 --> 00:46:13.240
MICHAEL WOLF: So we're going
to take another one here.

00:46:13.240 --> 00:46:14.180
We have two more here.

00:46:14.180 --> 00:46:15.040
I just want to
make sure everyone

00:46:15.040 --> 00:46:16.873
gets their questions
answered, because we're

00:46:16.873 --> 00:46:17.920
going to run out of time.

00:46:17.920 --> 00:46:18.550
AUDIENCE: Hey, Jimmy.

00:46:18.550 --> 00:46:20.779
I used to do some work on
the Wikipedia Signpost,

00:46:20.779 --> 00:46:22.570
and I was wondering to
what extent that may

00:46:22.570 --> 00:46:23.847
have influenced WikiTribune?

00:46:23.847 --> 00:46:26.180
The Wikipedia Signpost, for
those of you who don't know,

00:46:26.180 --> 00:46:28.570
is an on-Wikipedia
sort of newspaper

00:46:28.570 --> 00:46:30.640
that's been around
for at least a decade.

00:46:30.640 --> 00:46:33.324
Probably a decade and a half.

00:46:33.324 --> 00:46:34.740
JIMMY WALES: To
some extent, yeah.

00:46:34.740 --> 00:46:37.490
Because it's a--

00:46:37.490 --> 00:46:39.771
I mean, obviously,
I read the Signpost.

00:46:39.771 --> 00:46:41.270
And it sort of goes
into my thinking

00:46:41.270 --> 00:46:43.550
about what communities can do.

00:46:43.550 --> 00:46:47.180
And the Signpost,
generally it reports

00:46:47.180 --> 00:46:48.730
on internal goings-on
at Wikipedia,

00:46:48.730 --> 00:46:51.230
as well as things that would
be of interest to the community

00:46:51.230 --> 00:46:54.440
outside, and tries to be
neutral and fair and so on.

00:46:54.440 --> 00:46:56.810
And I think it's quite
good, but I can't

00:46:56.810 --> 00:46:58.550
say it directly inspired me.

00:46:58.550 --> 00:47:01.380
But obviously, it's
just a part of my world.

00:47:01.380 --> 00:47:02.145
Yeah.

00:47:02.145 --> 00:47:03.270
MICHAEL WOLF: Here, please.

00:47:03.270 --> 00:47:03.811
AUDIENCE: Hi.

00:47:03.811 --> 00:47:06.580
So I'd like to go back on
fact-checking on Wikipedia,

00:47:06.580 --> 00:47:08.200
if you could comment a bit more.

00:47:08.200 --> 00:47:11.440
What happens when
somebody edits obscure,

00:47:11.440 --> 00:47:14.840
difficult to check
facts, like for example,

00:47:14.840 --> 00:47:17.505
we have census data for
some small county in the US,

00:47:17.505 --> 00:47:21.500
let's say, which is not
easy to check, and maybe--

00:47:21.500 --> 00:47:23.050
does that trigger--

00:47:23.050 --> 00:47:25.630
signal an email
to the moderators,

00:47:25.630 --> 00:47:28.120
or do you have a
minimum amount of edits

00:47:28.120 --> 00:47:31.780
that need to be done before that
triggers an alert that perhaps

00:47:31.780 --> 00:47:34.840
somebody is making
significant changes?

00:47:34.840 --> 00:47:36.350
I'd specifically
like to understand

00:47:36.350 --> 00:47:40.135
how you check numbers, because
I use that in my project.

00:47:40.135 --> 00:47:41.560
JIMMY WALES: Yeah.

00:47:41.560 --> 00:47:43.930
So generally, there's
not much algorithmic

00:47:43.930 --> 00:47:46.840
signaling of people.

00:47:46.840 --> 00:47:48.789
So editors have a
watch list, and they

00:47:48.789 --> 00:47:50.830
can flag the things they
are interested to watch,

00:47:50.830 --> 00:47:53.260
and then they're notified
when something changes there.

00:47:53.260 --> 00:47:55.662
Normally what we would say is
we will ask for the source,

00:47:55.662 --> 00:47:57.370
so then you'd have to
link to the source.

00:47:57.370 --> 00:48:00.136
And it may be hard
to find the source,

00:48:00.136 --> 00:48:01.510
but once you've
found the source,

00:48:01.510 --> 00:48:03.640
and you've linked to it, it's
quite easy for other people

00:48:03.640 --> 00:48:05.306
to go and evaluate
it and say, oh, well,

00:48:05.306 --> 00:48:10.370
this is from the
government of this area.

00:48:10.370 --> 00:48:11.650
It was published at this date.

00:48:11.650 --> 00:48:13.984
It seems like legit information,
and that sort of thing.

00:48:13.984 --> 00:48:15.358
It's quite
old-fashioned, really.

00:48:15.358 --> 00:48:16.077
There's nothing--

00:48:16.077 --> 00:48:18.410
AUDIENCE: Sometimes these
sources aren't online, though.

00:48:18.410 --> 00:48:20.360
So like, I've seen census
data from the 1800s.

00:48:20.360 --> 00:48:21.360
JIMMY WALES: Yeah, yeah.

00:48:21.360 --> 00:48:23.800
So for sources
that aren't online,

00:48:23.800 --> 00:48:26.550
we consider that to be valid.

00:48:26.550 --> 00:48:27.640
There's no rule--

00:48:27.640 --> 00:48:29.080
I actually sometimes
get quoted--

00:48:29.080 --> 00:48:31.510
I find it incredibly annoying--

00:48:31.510 --> 00:48:34.570
I get quoted, and people love
to make these beautiful kind

00:48:34.570 --> 00:48:38.350
of placards with this quote,
saying, "if it isn't in Google,

00:48:38.350 --> 00:48:40.120
it doesn't exist."

00:48:40.120 --> 00:48:42.070
OK, those words came
out of my mouth only

00:48:42.070 --> 00:48:45.310
to make fun of that
view of the world.

00:48:45.310 --> 00:48:47.800
And so I'm like, that's
not really fair to quote me

00:48:47.800 --> 00:48:49.730
as saying that.

00:48:49.730 --> 00:48:57.270
So basically, there's
nothing special.

00:48:57.270 --> 00:48:58.920
Nothing I can really tell you.

00:48:58.920 --> 00:49:00.880
If you're a well-known
contributor,

00:49:00.880 --> 00:49:02.560
and you're known to be someone
who works in that area,

00:49:02.560 --> 00:49:04.060
and you're trusted
by the community,

00:49:04.060 --> 00:49:05.740
that would be
completely accepted.

00:49:05.740 --> 00:49:07.390
If the information
you're putting in

00:49:07.390 --> 00:49:11.110
seems in some way
surprising, so you're

00:49:11.110 --> 00:49:15.310
saying the population
of Miami, Florida

00:49:15.310 --> 00:49:18.740
was 43 million
people in 1870, we'd

00:49:18.740 --> 00:49:21.970
probably go, yeah, probably
not, and challenge it.

00:49:21.970 --> 00:49:24.214
And then in between, I think
we would tend to trust.

00:49:24.214 --> 00:49:25.630
If it's obscure,
like, what motive

00:49:25.630 --> 00:49:28.360
would you have for making
up population numbers?

00:49:28.360 --> 00:49:30.790
That's a question that would
go through people's minds.

00:49:30.790 --> 00:49:35.260
And the source, there will
be people in Wikipedia

00:49:35.260 --> 00:49:39.100
who their hobby is population
figures in the 1800s.

00:49:39.100 --> 00:49:41.800
And they will have some idea
as to whether it corroborates

00:49:41.800 --> 00:49:43.840
with the general da, da, da.

00:49:43.840 --> 00:49:46.270
Nothing magical about it.

00:49:46.270 --> 00:49:48.100
It's just trying to do
the best job we can.

00:49:48.100 --> 00:49:49.100
MICHAEL WOLF: I'm sorry.

00:49:49.100 --> 00:49:51.794
I want to just get through
the rest of the questions.

00:49:51.794 --> 00:49:52.460
Please go ahead.

00:49:52.460 --> 00:49:53.212
JIMMY WALES: They're trying
to throw a question to you.

00:49:53.212 --> 00:49:55.720
AUDIENCE: So this relates to
the previous question on scope.

00:49:55.720 --> 00:49:58.053
But a significant way in which
news sources express bias

00:49:58.053 --> 00:50:00.970
is not only the tone
of the articles,

00:50:00.970 --> 00:50:02.822
but also which stories
they choose to cover

00:50:02.822 --> 00:50:04.780
and what prominence they
choose to assign them.

00:50:04.780 --> 00:50:06.280
So is there any way
that WikiTribune

00:50:06.280 --> 00:50:08.290
plans to address this issue?

00:50:08.290 --> 00:50:09.790
JIMMY WALES: I
think this is where

00:50:09.790 --> 00:50:14.350
having a healthy and diverse
community is very helpful.

00:50:14.350 --> 00:50:17.530
Because community members can
start stories about anything

00:50:17.530 --> 00:50:18.560
they want.

00:50:18.560 --> 00:50:22.706
And so the problem of a small
team of an editorial board

00:50:22.706 --> 00:50:24.580
who have a certain
perspective on the world--

00:50:24.580 --> 00:50:26.580
even if they're trying
to be neutral, obviously.

00:50:26.580 --> 00:50:30.594
One of the facts about
bias is oftentimes,

00:50:30.594 --> 00:50:32.260
we are biased in ways
that we don't even

00:50:32.260 --> 00:50:36.250
notice because that's
what bias is, right?

00:50:36.250 --> 00:50:38.326
And so having a diverse
community who says,

00:50:38.326 --> 00:50:39.700
hey, we need to
write about this,

00:50:39.700 --> 00:50:41.074
this is an important
story that's

00:50:41.074 --> 00:50:43.480
not being covered
elsewhere, and they

00:50:43.480 --> 00:50:45.810
can rally volunteers to
do that, then they should.

00:50:45.810 --> 00:50:48.310
And I think we have to be
very introspective, always,

00:50:48.310 --> 00:50:51.850
about our internal
staff processes to say,

00:50:51.850 --> 00:50:54.330
are we just choosing stories--

00:50:54.330 --> 00:50:57.250
you know, like in today's
political environment,

00:50:57.250 --> 00:51:01.240
you might only choose stories
about Donald Trump and Russia

00:51:01.240 --> 00:51:04.450
and not choose stories about
Hillary and her emails.

00:51:04.450 --> 00:51:06.200
That's just one simple example.

00:51:06.200 --> 00:51:08.050
To say, no, you've always got
to challenge yourself and say,

00:51:08.050 --> 00:51:08.320
right.

00:51:08.320 --> 00:51:09.580
We need to make sure
we're looking at things.

00:51:09.580 --> 00:51:10.940
Because actually, one of the--

00:51:10.940 --> 00:51:13.150
I have a whole little
rant about Fox News.

00:51:13.150 --> 00:51:17.280
And I haven't lived in
the US in a long time.

00:51:17.280 --> 00:51:18.710
For eight years.

00:51:18.710 --> 00:51:21.100
And even before that, I wasn't
a big watcher of Fox News,

00:51:21.100 --> 00:51:22.683
because I don't watch
much television.

00:51:22.683 --> 00:51:25.420
But one of the things I think a
lot of people missed when they

00:51:25.420 --> 00:51:27.610
thought Fox News was
incredibly biased,

00:51:27.610 --> 00:51:29.460
which of course, it
is in certain ways,

00:51:29.460 --> 00:51:32.080
is most of the shows people
talked about are opinion shows.

00:51:32.080 --> 00:51:34.620
It's Bill O'Reilly pontificating
and having guests in.

00:51:34.620 --> 00:51:37.570
But their straight news
segments were actually

00:51:37.570 --> 00:51:41.140
quite high quality, but
they often covered stories

00:51:41.140 --> 00:51:43.630
that people in the
Heartland cared about,

00:51:43.630 --> 00:51:45.490
that people in New
York and California

00:51:45.490 --> 00:51:46.956
weren't that interested in.

00:51:46.956 --> 00:51:49.330
And that was one of the reasons
they became very popular.

00:51:49.330 --> 00:51:51.580
They would cover
a story that just

00:51:51.580 --> 00:51:54.760
seemed like, you know, whatever
factory workers out of work

00:51:54.760 --> 00:51:55.705
somewhere.

00:51:55.705 --> 00:51:57.350
Maybe "The New York
Times" covers it,

00:51:57.350 --> 00:51:59.360
but they were really
in there, in a way.

00:51:59.360 --> 00:52:01.026
And I think that's
important because one

00:52:01.026 --> 00:52:04.540
of the reasons I think we've
had this huge drop in trust

00:52:04.540 --> 00:52:07.480
in the media is a lot of
people read quality media,

00:52:07.480 --> 00:52:08.550
and they're like, this--

00:52:08.550 --> 00:52:09.091
I don't know.

00:52:09.091 --> 00:52:10.684
This has nothing
to do with my life.

00:52:10.684 --> 00:52:11.850
Nobody's really covering it.

00:52:11.850 --> 00:52:14.560
And when we look at the
incredible devastation that's

00:52:14.560 --> 00:52:18.520
happened to local
newspapers everywhere,

00:52:18.520 --> 00:52:22.060
you can actually see why people
feel like, hey, journalism

00:52:22.060 --> 00:52:23.380
doesn't care about me.

00:52:23.380 --> 00:52:25.690
They're basically-- all
they do is rant about Trump.

00:52:25.690 --> 00:52:29.310
Nobody is concerned
about our problems here.

00:52:29.310 --> 00:52:30.340
So.

00:52:30.340 --> 00:52:33.050
MICHAEL WOLF: We have like
two speed-dating questions.

00:52:33.050 --> 00:52:34.664
So let's take the
two questions here.

00:52:34.664 --> 00:52:36.330
And if we can, we'll
just take one more.

00:52:36.330 --> 00:52:38.317
I'm really concerned about time.

00:52:38.317 --> 00:52:39.400
They're starting to like--

00:52:39.400 --> 00:52:40.970
AUDIENCE: Can you let
your partner speak on--

00:52:40.970 --> 00:52:41.900
JIMMY WALES: I would love to.

00:52:41.900 --> 00:52:42.399
Yes.

00:52:42.399 --> 00:52:45.171
Every question, they say,
Jimmy, da, da, da, da.

00:52:45.171 --> 00:52:46.420
Let's ask Orit some questions.

00:52:46.420 --> 00:52:47.000
MICHAEL WOLF: OK, Orit.

00:52:47.000 --> 00:52:47.890
JIMMY WALES: Thank you.

00:52:47.890 --> 00:52:48.723
AUDIENCE: Thank you.

00:52:48.723 --> 00:52:50.960
This question is for
Orit, explicitly.

00:52:50.960 --> 00:52:53.750
It seems to me, part of
the success of Wikipedia

00:52:53.750 --> 00:52:55.580
is the quality of the community.

00:52:55.580 --> 00:52:59.420
How at WikiTribune are you going
about building the community

00:52:59.420 --> 00:53:02.220
and making sure it is a
productive environment?

00:53:02.220 --> 00:53:04.260
Thank you.

00:53:04.260 --> 00:53:06.980
ORIT KOPEL: So first of all,
we're welcoming everyone,

00:53:06.980 --> 00:53:09.530
and we're welcoming all of you.

00:53:09.530 --> 00:53:12.140
We are lucky to
have Jimmy to have

00:53:12.140 --> 00:53:15.140
the experience of building
an online community

00:53:15.140 --> 00:53:16.890
of contributors.

00:53:16.890 --> 00:53:19.700
So we are also aware of
all the possible problems

00:53:19.700 --> 00:53:21.650
that might occur.

00:53:21.650 --> 00:53:27.080
We don't want to be UK-based
or US-based or Euro--

00:53:27.080 --> 00:53:29.750
just West-centric.

00:53:29.750 --> 00:53:32.660
That's why we plan to launch in
as many languages as possible

00:53:32.660 --> 00:53:36.910
and in as many regions as
possible, to start dissolving--

00:53:36.910 --> 00:53:41.150
the all focus on--

00:53:41.150 --> 00:53:43.490
and you were talking
about Trump and Hillary.

00:53:43.490 --> 00:53:46.460
There are so many more stories
around the world happening.

00:53:46.460 --> 00:53:50.880
You have terror attacks in Egypt
and so on, that people do talk,

00:53:50.880 --> 00:53:52.150
but maybe not enough.

00:53:52.150 --> 00:53:54.530
Maybe a lot of
corruptions in different,

00:53:54.530 --> 00:53:56.590
you know, in Colombia
and different countries,

00:53:56.590 --> 00:53:59.010
that I don't think
they get enough focus.

00:53:59.010 --> 00:54:02.880
That's why personally-- I have
the background of human rights

00:54:02.880 --> 00:54:06.750
law, so personally, I'm
very interested in having

00:54:06.750 --> 00:54:11.670
a very diverse community
from different backgrounds,

00:54:11.670 --> 00:54:14.460
for gender-wise.

00:54:14.460 --> 00:54:19.470
I know that Wikipedia has some
problem with not enough women

00:54:19.470 --> 00:54:21.850
editing the entries.

00:54:21.850 --> 00:54:24.540
So we are very aware
of the problems that

00:54:24.540 --> 00:54:27.060
were or still
exist in Wikipedia,

00:54:27.060 --> 00:54:29.310
and we're trying to
avoid them or solve them

00:54:29.310 --> 00:54:30.900
before they happen.

00:54:30.900 --> 00:54:34.410
And so it is a
challenge, of course.

00:54:34.410 --> 00:54:36.480
I don't have all
the answers yet.

00:54:36.480 --> 00:54:40.620
But we can adopt some of the
solutions that were already

00:54:40.620 --> 00:54:44.690
found in Wikipedia, and
maybe we will find new ones.

00:54:44.690 --> 00:54:47.240
Diversity, I think
it's very important

00:54:47.240 --> 00:54:50.120
for the neutrality part
that Jimmy spoke about,

00:54:50.120 --> 00:54:56.360
but for many more things
that are important for a very

00:54:56.360 --> 00:55:00.650
successful news site that's
going to attend all issues

00:55:00.650 --> 00:55:03.270
and relate to as many
people as possible.

00:55:03.270 --> 00:55:04.580
We want to change journalism.

00:55:04.580 --> 00:55:08.194
We don't want to replicate
what already exists.

00:55:08.194 --> 00:55:09.610
MICHAEL WOLF: So
we are going to--

00:55:09.610 --> 00:55:11.012
I know I'm running overtime.

00:55:11.012 --> 00:55:12.470
They're going to
get the hook soon.

00:55:12.470 --> 00:55:14.900
But I want to make sure we
get [INAUDIBLE] questions.

00:55:14.900 --> 00:55:16.460
Amazing duck sweater.

00:55:16.460 --> 00:55:17.900
Please go ahead.

00:55:17.900 --> 00:55:20.840
AUDIENCE: So I guess bringing
it back to a Wikipedia question.

00:55:20.840 --> 00:55:22.850
You've mentioned how
important the community is,

00:55:22.850 --> 00:55:26.000
and you kind of just mentioned
some of the maybe biases

00:55:26.000 --> 00:55:28.175
or differences about that.

00:55:28.175 --> 00:55:30.560
A specific question
I had is, do you

00:55:30.560 --> 00:55:32.270
think that the community
of contributors

00:55:32.270 --> 00:55:34.820
is going to be aging
over time with Wikipedia,

00:55:34.820 --> 00:55:38.951
or are you seeing a lot of
newer, younger people come in?

00:55:38.951 --> 00:55:41.200
Comment, I guess, if you
have any insight into other--

00:55:41.200 --> 00:55:42.470
any kind of diversity there.

00:55:42.470 --> 00:55:43.520
JIMMY WALES: Yeah.

00:55:43.520 --> 00:55:47.090
In terms of Wikipedia, the--

00:55:47.090 --> 00:55:50.060
it's a concern, but it's
not an overwhelming concern.

00:55:50.060 --> 00:55:51.380
So we do see--

00:55:51.380 --> 00:55:55.700
we've got a very large
cohort of very active, very

00:55:55.700 --> 00:55:58.826
powerful users who've been
around for a long time,

00:55:58.826 --> 00:56:00.200
but we also have
new contributors

00:56:00.200 --> 00:56:02.360
who come in all the time.

00:56:02.360 --> 00:56:04.310
We don't have good
data on the aging.

00:56:04.310 --> 00:56:09.290
My feeling is that the Wikipedia
community has been aging--

00:56:09.290 --> 00:56:11.060
sort of the average
age has been going up

00:56:11.060 --> 00:56:14.790
about a quarter of a year every
year, or something like that.

00:56:14.790 --> 00:56:16.805
So we are aging, but
it's not like we're

00:56:16.805 --> 00:56:19.650
all-- we're not going
up by one year per year.

00:56:19.650 --> 00:56:22.220
So there is that.

00:56:22.220 --> 00:56:24.710
And yeah.

00:56:24.710 --> 00:56:26.396
MICHAEL WOLF: Final
question, please.

00:56:26.396 --> 00:56:27.020
AUDIENCE: Yeah.

00:56:27.020 --> 00:56:30.050
So my question is
just around fake news.

00:56:30.050 --> 00:56:32.236
And a large part of
the fake news problem

00:56:32.236 --> 00:56:33.610
is that people
are just consuming

00:56:33.610 --> 00:56:34.730
news in an echo chamber.

00:56:34.730 --> 00:56:37.217
So I'm just curious
about how WikiTribune

00:56:37.217 --> 00:56:39.050
plans to tackle that,
and any other thoughts

00:56:39.050 --> 00:56:40.276
you have around that.

00:56:40.276 --> 00:56:42.150
ORIT KOPEL: I think I
just talked about that.

00:56:42.150 --> 00:56:46.380
That we are going to
attend more communities.

00:56:46.380 --> 00:56:49.200
And also going to local
communities as well.

00:56:49.200 --> 00:56:50.750
We're searching
for a lot of models

00:56:50.750 --> 00:56:55.160
to get as many diverse people
and communities and backgrounds

00:56:55.160 --> 00:56:56.030
involved.

00:56:56.030 --> 00:56:56.780
JIMMY WALES: Yeah.

00:56:56.780 --> 00:56:59.210
I think one of the
key elements here

00:56:59.210 --> 00:57:02.120
and one of the reasons
we're launching with no ads

00:57:02.120 --> 00:57:06.397
is the advertising model
drives a certain sameness

00:57:06.397 --> 00:57:07.730
to the stories that are covered.

00:57:07.730 --> 00:57:09.524
If you're chasing
clicks, you need

00:57:09.524 --> 00:57:10.940
to have a headline
about something

00:57:10.940 --> 00:57:13.670
that people are already
excited about and know about,

00:57:13.670 --> 00:57:15.680
so you're going to
get a lot more clicks.

00:57:15.680 --> 00:57:17.140
Our business model,
what I need, I

00:57:17.140 --> 00:57:20.270
need you to read to the bottom
of a piece and say, wow.

00:57:20.270 --> 00:57:22.160
I didn't see that anywhere else.

00:57:22.160 --> 00:57:25.130
I understand the world
better than I did before.

00:57:25.130 --> 00:57:26.510
This deserves to exist.

00:57:26.510 --> 00:57:27.900
I should chip in.

00:57:27.900 --> 00:57:30.770
I should pay for this.

00:57:30.770 --> 00:57:34.220
Versus if I were ad-driven, I
just need you to come and look.

00:57:34.220 --> 00:57:35.990
And that means it
doesn't drive you

00:57:35.990 --> 00:57:38.880
in the direction of trying to
wow people with like, oh wow,

00:57:38.880 --> 00:57:41.300
I didn't know about that,
and how did I miss that?

00:57:41.300 --> 00:57:42.240
This is something new.

00:57:42.240 --> 00:57:44.360
So I think that's a
part of the answer,

00:57:44.360 --> 00:57:47.480
is to set up the business model
so that the organization's

00:57:47.480 --> 00:57:50.090
internal focus is on
something different from what

00:57:50.090 --> 00:57:51.140
everybody else is doing.

00:57:51.140 --> 00:57:53.790
MICHAEL WOLF: So this has
been a great conversation.

00:57:53.790 --> 00:57:56.300
We could go on for a long time.

00:57:56.300 --> 00:58:00.560
And I'm sure the folks at
Google really appreciate it.

00:58:00.560 --> 00:58:01.220
Thank you both.

00:58:01.220 --> 00:58:01.520
JIMMY WALES: Yeah.

00:58:01.520 --> 00:58:02.395
Thanks for having us.

00:58:02.395 --> 00:58:04.870
[APPLAUSE]

