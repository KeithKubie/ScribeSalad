WEBVTT
Kind: captions
Language: en

00:00:05.060 --> 00:00:06.550
CORY DOCTOROW: Charlie and I
wrote this book, "The Rapture

00:00:06.550 --> 00:00:09.320
of the Nerds." We started
writing it about seven years

00:00:09.320 --> 00:00:11.550
ago as a kind of experiment.

00:00:11.550 --> 00:00:16.920
Charlie and I had corresponded
and he said, would you like to

00:00:16.920 --> 00:00:18.380
collaborate on something?

00:00:18.380 --> 00:00:22.260
So he sent me a chunk of the
manuscript, the first 500 or

00:00:22.260 --> 00:00:25.500
1,000 words of a story called
"Jury Service." And I read

00:00:25.500 --> 00:00:27.290
them and they were quite
gonzo, I mean,

00:00:27.290 --> 00:00:28.310
really, really gonzo.

00:00:28.310 --> 00:00:30.720
And I thought, all right,
challenge accepted.

00:00:30.720 --> 00:00:33.900
So I wrote the most gonzo sort
of follow-on 500 or 1,000

00:00:33.900 --> 00:00:36.200
words that I could think of
and sent them back to him.

00:00:36.200 --> 00:00:38.100
And then he did the same.

00:00:38.100 --> 00:00:40.410
And back and forth we went and
ended up writing this thing

00:00:40.410 --> 00:00:44.160
that's very silly
and very fun.

00:00:44.160 --> 00:00:47.750
And it was much loved, so much
so that there was a lot of

00:00:47.750 --> 00:00:49.740
demand for a sequel, so we wrote
another story called

00:00:49.740 --> 00:00:50.790
"Appeals Court."

00:00:50.790 --> 00:00:54.680
And those two seemed like they
were unfinished, and Tor asked

00:00:54.680 --> 00:00:58.230
us if we would finish them and
do a write-through and turn it

00:00:58.230 --> 00:00:59.140
into one book.

00:00:59.140 --> 00:01:02.470
So we wrote this third piece,
which is called "Parole

00:01:02.470 --> 00:01:04.400
Board." And that's the new chunk
that we're going to read

00:01:04.400 --> 00:01:06.050
from a little later today.

00:01:06.050 --> 00:01:09.500
And the whole thing with a
thoroughgoing edit became

00:01:09.500 --> 00:01:11.270
"Rapture of the Nerds,"
the book but you can

00:01:11.270 --> 00:01:13.490
pick up back there.

00:01:13.490 --> 00:01:15.520
And I'm going to just say a few
words about kind of the

00:01:15.520 --> 00:01:18.110
thematic nature of the book,
and then Charlie will say a

00:01:18.110 --> 00:01:18.970
few words as well.

00:01:18.970 --> 00:01:20.810
And then we'll each do
a brief reading.

00:01:20.810 --> 00:01:23.120
The title "Rapture of the Nerds"
comes from another

00:01:23.120 --> 00:01:25.090
writer, Ken McLeod--

00:01:25.090 --> 00:01:28.870
Scottish, Trotskyist, science
fiction writer of some great

00:01:28.870 --> 00:01:30.380
merit and thoughtfulness.

00:01:30.380 --> 00:01:33.980
And Ken was one of the first
people to notice that the

00:01:33.980 --> 00:01:39.030
Singularity bears a market
similarity to the notion of

00:01:39.030 --> 00:01:42.100
the Rapture and the "Left
Behind" novels, and this idea

00:01:42.100 --> 00:01:44.440
that there will come a time
when people who possess a

00:01:44.440 --> 00:01:47.620
specific virtue will disappear
from the Earth, leaving only

00:01:47.620 --> 00:01:49.110
the virtuous behind.

00:01:49.110 --> 00:01:53.460
Only instead of people who have
faithfully adhered to

00:01:53.460 --> 00:01:57.750
Bronze Age doctrine going away
to heaven, this would be

00:01:57.750 --> 00:02:02.930
techies and nerds and skeptics
and math people who would be

00:02:02.930 --> 00:02:05.080
comfortable with having their
brains stuck in computers and

00:02:05.080 --> 00:02:09.280
being disassembled here on Earth
and uploaded to a cloud.

00:02:09.280 --> 00:02:12.590
So that's the notion of the
book, is to try and sort of

00:02:12.590 --> 00:02:16.360
explore an inverse of being left
behind, a "Left Behind"

00:02:16.360 --> 00:02:18.070
where the people left behind
are the people who are

00:02:18.070 --> 00:02:20.900
skeptical about uploading.

00:02:20.900 --> 00:02:24.050
And it's something that I like
to think of as the progressive

00:02:24.050 --> 00:02:24.830
apocalypse.

00:02:24.830 --> 00:02:28.140
So before the Enlightenment,
we had this idea of

00:02:28.140 --> 00:02:30.930
lapsarianism, the idea that
things were getting worse and

00:02:30.930 --> 00:02:34.200
worse every year, that we were
kicked out of the Garden and

00:02:34.200 --> 00:02:36.250
every year that went by,
we fell further and

00:02:36.250 --> 00:02:37.730
further from grace.

00:02:37.730 --> 00:02:41.150
And it's kind of easy to
understand how lapsarianism

00:02:41.150 --> 00:02:43.890
would seem like an a natural,
incredible idea.

00:02:43.890 --> 00:02:47.450
After all, by the time you hit
sort of the last 10% of your

00:02:47.450 --> 00:02:50.700
natural lifespan, it seems
pretty apparent that things

00:02:50.700 --> 00:02:51.330
are getting worse.

00:02:51.330 --> 00:02:53.220
After all, didn't everything
used to taste better?

00:02:53.220 --> 00:02:54.840
And didn't everything used
to smell better?

00:02:54.840 --> 00:02:57.830
Weren't the people of your
preferred gender prettier?

00:02:57.830 --> 00:02:59.290
Didn't you hurt less?

00:02:59.290 --> 00:03:02.170
I mean, clearly the world is
a worse place than it was.

00:03:02.170 --> 00:03:04.430
And I think even the human
imagination balks

00:03:04.430 --> 00:03:05.970
at unbounded systems.

00:03:05.970 --> 00:03:07.990
We think, well, if things are
going to get worse and worse,

00:03:07.990 --> 00:03:10.440
eventually they'll reach a point
of, as Spinal Tap would

00:03:10.440 --> 00:03:13.580
have put it, "none more worse."
And that "none more

00:03:13.580 --> 00:03:14.900
worse" is the Apocalypse,
right?

00:03:14.900 --> 00:03:18.470
When things can't get any more
worse, you have a break.

00:03:18.470 --> 00:03:19.970
Everything comes to
a crashing halt.

00:03:19.970 --> 00:03:22.140
Now along comes the
Enlightenment and the idea

00:03:22.140 --> 00:03:25.360
that things are just going to
get better, that we will stand

00:03:25.360 --> 00:03:28.130
on the shoulders of giants, and
then people stand on our

00:03:28.130 --> 00:03:30.710
shoulders, and then they'll
stand on theirs, and so on,

00:03:30.710 --> 00:03:33.340
all the way up to the
contemporary notion of Moore's

00:03:33.340 --> 00:03:35.630
law and the idea that things are
getting better and better.

00:03:35.630 --> 00:03:39.570
And again, we confront this
unbounded system and we go,

00:03:39.570 --> 00:03:42.120
well, there must come a time
when things can get none more

00:03:42.120 --> 00:03:45.290
better, when the balloon has
inflated so much that it

00:03:45.290 --> 00:03:47.710
bursts and we reach a
break with history.

00:03:47.710 --> 00:03:50.410
We cease to be humans
as we understand it.

00:03:50.410 --> 00:03:53.060
And that's the other theme that
we explore in this book,

00:03:53.060 --> 00:03:57.700
this idea that the Singularity
is in many ways attractive not

00:03:57.700 --> 00:04:00.380
because it's credible, but
because our brain likes the

00:04:00.380 --> 00:04:02.630
idea of a bounding
condition on this

00:04:02.630 --> 00:04:04.710
otherwise unbounded system.

00:04:04.710 --> 00:04:06.980
So that's the book, and I'm
going to let Charlie talk

00:04:06.980 --> 00:04:08.950
about it a bit first and
then do some reading.

00:04:08.950 --> 00:04:10.660
And then I'll come back and do
some reading, and then we'll

00:04:10.660 --> 00:04:11.910
take your questions.

00:04:15.980 --> 00:04:19.430
CHARLES STROSS: Well,
so, the Singularity.

00:04:19.430 --> 00:04:20.610
It's an interesting term.

00:04:20.610 --> 00:04:23.880
It really got introduced in
the science fiction field

00:04:23.880 --> 00:04:28.090
around 1992 by Vernor Vinge, who
you've probably heard of

00:04:28.090 --> 00:04:29.370
and may well have read.

00:04:29.370 --> 00:04:32.800
Science fiction writer, Hugo
Nebula winner, also a

00:04:32.800 --> 00:04:36.260
now-retired professor
of computer science.

00:04:36.260 --> 00:04:38.290
Vernor's version of a
singularity was a lot more

00:04:38.290 --> 00:04:41.720
constrained and, dare I say it,
grounded than the version

00:04:41.720 --> 00:04:44.320
that's become common
currency among

00:04:44.320 --> 00:04:46.410
transhumanists these days.

00:04:46.410 --> 00:04:49.850
Vernor's resolution was
essentially a hypothesis about

00:04:49.850 --> 00:04:52.830
artificial intelligence,
that if we can build a

00:04:52.830 --> 00:04:56.570
human-equivalent AI, then it
should, in principle, be

00:04:56.570 --> 00:04:59.200
possible to make it think faster
than a regular human

00:04:59.200 --> 00:05:01.460
being just by throwing more
computing resources at it,

00:05:01.460 --> 00:05:03.430
assuming it's not
bottlenecked--

00:05:03.430 --> 00:05:05.950
which it has the brain as
a thoroughly parallel

00:05:05.950 --> 00:05:06.530
architecture.

00:05:06.530 --> 00:05:09.840
There's no reason to suppose
it would be.

00:05:09.840 --> 00:05:15.930
He also speculated further
that if there are

00:05:15.930 --> 00:05:19.060
fundamentally more powerful
modes of cognition than human

00:05:19.060 --> 00:05:25.540
consciousness, if there are
forms of intelligence that are

00:05:25.540 --> 00:05:29.150
as much more powerful than our
thinking as we are than, say,

00:05:29.150 --> 00:05:33.780
a frog, then once you have
really, really, really fast

00:05:33.780 --> 00:05:38.160
human-equivalent AIs, they will
make a breakthrough to a

00:05:38.160 --> 00:05:40.950
strongly transhuman form of
intelligence, if such a

00:05:40.950 --> 00:05:42.800
breakthrough is possible
at all.

00:05:42.800 --> 00:05:45.700
And at that point, the brakes
are off and we are not setting

00:05:45.700 --> 00:05:48.850
the agenda for the universe
we inhabit.

00:05:48.850 --> 00:05:51.920
This was Vernor's original
context for singularity.

00:05:51.920 --> 00:05:54.850
And he wrote some novels about
it, starting from, I think,

00:05:54.850 --> 00:05:59.780
the late 1980s with "Marooned in
Realtime" and "Subsequent."

00:05:59.780 --> 00:06:04.130
But it wasn't long before this
cross-fertilized with some

00:06:04.130 --> 00:06:06.940
interesting, in subcultures
relating to each other via the

00:06:06.940 --> 00:06:09.740
internet-- the early
transhumanists, the

00:06:09.740 --> 00:06:10.720
Extropians.

00:06:10.720 --> 00:06:12.700
I don't know if anyone here was
on the Extropians mailing

00:06:12.700 --> 00:06:14.460
list in the late '80s,
early '90s.

00:06:14.460 --> 00:06:17.805
I see some recognition.

00:06:17.805 --> 00:06:21.700
And like a giant Katamari of
weird ideas, it began sort of

00:06:21.700 --> 00:06:25.310
accreting baggage as
it rolled downhill.

00:06:25.310 --> 00:06:27.550
Among the bits of baggage
it acquired--

00:06:27.550 --> 00:06:31.050
well, molecular nanotechnology
and magic nanite pixie dust

00:06:31.050 --> 00:06:33.090
probably need no further
explanation.

00:06:33.090 --> 00:06:38.280
But mind uploading, the idea
that we can dissect bits of

00:06:38.280 --> 00:06:41.260
our brains, analyze the signal
processing therein, and

00:06:41.260 --> 00:06:44.810
ultimately port whatever
representation we have of a

00:06:44.810 --> 00:06:47.810
human mind to run on
different hardware.

00:06:47.810 --> 00:06:49.770
And of course, once we are
running in a computer, there's

00:06:49.770 --> 00:06:54.560
no reason we can't make our sim
very pleasant to live in.

00:06:54.560 --> 00:06:56.370
It's AI Heaven time.

00:06:56.370 --> 00:06:59.090
And hey, we're all going to
flying up into the computers,

00:06:59.090 --> 00:07:02.710
live in the Google Cloud
for that matter.

00:07:02.710 --> 00:07:04.700
I'm not sure that's such a
good idea, but I digress.

00:07:04.700 --> 00:07:06.300
[LAUGHTER]

00:07:06.300 --> 00:07:08.150
CHARLES STROSS: And this sort
of began accreting all sorts

00:07:08.150 --> 00:07:11.980
of theological baggage.

00:07:11.980 --> 00:07:14.610
It got to the point where I
found myself being sort of

00:07:14.610 --> 00:07:19.020
pinned into corners at SF
conventions by people with no

00:07:19.020 --> 00:07:21.480
context of personal space who
wanted to know how long it

00:07:21.480 --> 00:07:24.150
would be before they could
abandon the meat puppet.

00:07:24.150 --> 00:07:26.830
[LAUGHTER]

00:07:26.830 --> 00:07:29.310
CHARLES STROSS: Now this
struck me as slightly

00:07:29.310 --> 00:07:30.990
disturbing.

00:07:30.990 --> 00:07:33.410
And when one goes looking for
parallels, it doesn't take

00:07:33.410 --> 00:07:35.140
long to find them.

00:07:35.140 --> 00:07:40.070
From around 950 AD onwards,
Western Europe was sort of hit

00:07:40.070 --> 00:07:44.410
by wave after wave of cults,
if you like, where the

00:07:44.410 --> 00:07:46.730
peasants would sort of abandon
their farms, abandon their

00:07:46.730 --> 00:07:49.820
clothes, trash the joint and
go and form free-love

00:07:49.820 --> 00:07:53.550
communes, marauding around
Europe, because they knew

00:07:53.550 --> 00:07:55.910
Jesus was going to come and
spirit them away to heaven

00:07:55.910 --> 00:07:57.910
within the next few weeks.

00:07:57.910 --> 00:08:01.390
And this sort of kept up for
about 50 to 100 years,

00:08:01.390 --> 00:08:03.400
periodically being put
down by [INAUDIBLE]

00:08:03.400 --> 00:08:06.550
by the nobility, with the
enthusiastic backing of the

00:08:06.550 --> 00:08:10.980
Church, who disapproved
of this kind of thing.

00:08:10.980 --> 00:08:14.040
But it has had echoes
ever since.

00:08:14.040 --> 00:08:17.630
Christian eschatology came up
with the Revelation of St.

00:08:17.630 --> 00:08:20.960
John around the second century,
and ever since then,

00:08:20.960 --> 00:08:27.440
as Cory noted, there has been
the apocalyptic trend embedded

00:08:27.440 --> 00:08:29.580
very deeply in our culture.

00:08:29.580 --> 00:08:32.169
If we fast forward to the 18th
century and the Scottish

00:08:32.169 --> 00:08:34.720
Enlightenment, we have
a changeover--

00:08:34.720 --> 00:08:36.950
to some extent a reaction
against a very dire,

00:08:36.950 --> 00:08:41.175
fundamentalist, Presbyterian
theology of the theocracy that

00:08:41.175 --> 00:08:42.929
ran Scotland for a couple
of centuries until

00:08:42.929 --> 00:08:45.190
the early 18th century--

00:08:45.190 --> 00:08:48.220
resulting in a new more
optimistic vision of the world

00:08:48.220 --> 00:08:51.050
whereby things can get better
and better all the time and we

00:08:51.050 --> 00:08:52.850
can improve ourselves.

00:08:52.850 --> 00:08:55.990
But it's still the same
apocalyptic imagery and urge.

00:08:58.730 --> 00:09:00.650
And "The Rapture of the Nerds"
was, to some extent, an

00:09:00.650 --> 00:09:03.740
attempt to grapple with the
theological and aesthetic

00:09:03.740 --> 00:09:06.940
underpinnings of
Singularitarianism.

00:09:06.940 --> 00:09:09.920
More recently, if you want to
find the missing link to the

00:09:09.920 --> 00:09:13.150
Extropians and the
transhumanists, you really

00:09:13.150 --> 00:09:15.540
need to look at the 1920s
Russian movement

00:09:15.540 --> 00:09:17.270
known as the Cosmists.

00:09:17.270 --> 00:09:19.610
If you think sort of 1920s
Russian revolutionary

00:09:19.610 --> 00:09:21.360
Communist Extropians--

00:09:21.360 --> 00:09:24.110
most of them would be American
libertarians these days--

00:09:24.110 --> 00:09:25.990
that's where you find them.

00:09:25.990 --> 00:09:31.050
They got their scheme from a
theologian, Nikolai Fedorov,

00:09:31.050 --> 00:09:33.160
late 19th-century
Russian Orthodox

00:09:33.160 --> 00:09:35.020
theologian and teacher.

00:09:35.020 --> 00:09:37.970
He taught Konstantin
Tsiolkovsky, the father of

00:09:37.970 --> 00:09:40.470
rocketry among other things.

00:09:40.470 --> 00:09:46.390
And the Fedorov came up with
an almost barking teleology

00:09:46.390 --> 00:09:49.440
framed in terms of Christian
thought.

00:09:49.440 --> 00:09:53.790
First of all, given that we have
a theological impetus to

00:09:53.790 --> 00:09:56.420
improve ourselves towards
perfection, to converge with

00:09:56.420 --> 00:10:01.140
godliness, Fedorov concluded
that a necessary step on this

00:10:01.140 --> 00:10:03.160
was the complete unification
of humanity and the

00:10:03.160 --> 00:10:04.670
abolition of war.

00:10:04.670 --> 00:10:05.390
How do you do this?

00:10:05.390 --> 00:10:08.100
Well, you find them something
more important to wage on--

00:10:08.100 --> 00:10:10.780
like, say, death.

00:10:10.780 --> 00:10:14.230
So Fedorov came up with this
proposal that we should work

00:10:14.230 --> 00:10:18.990
on human immortality, expansion
into space, giving

00:10:18.990 --> 00:10:21.260
human beings the ability to
photosynthesize and move

00:10:21.260 --> 00:10:23.360
between worlds.

00:10:23.360 --> 00:10:27.440
We're talking 1890s here,
I should add.

00:10:27.440 --> 00:10:30.560
And this, however, was not
where the buck stopped.

00:10:30.560 --> 00:10:33.830
Because let us suppose we've
inherited the entire cosmos,

00:10:33.830 --> 00:10:36.460
we're de facto omnipotent
and immortal.

00:10:36.460 --> 00:10:38.970
It is an insult to our existence
that there are still

00:10:38.970 --> 00:10:41.560
human beings moldering in the
grave, that we must therefore

00:10:41.560 --> 00:10:45.420
then seek to resurrect every
human being who had ever

00:10:45.420 --> 00:10:48.980
lived, and moreover, every human
being on every timeline

00:10:48.980 --> 00:10:52.610
that could have given rise
to the present day.

00:10:52.610 --> 00:10:54.610
Now if you put that in your pipe
and smoke it, it's some

00:10:54.610 --> 00:10:56.410
pretty heady stuff.

00:10:56.410 --> 00:10:58.560
And as I said, this stuff--

00:10:58.560 --> 00:11:00.740
1920s Leninists?

00:11:00.740 --> 00:11:05.430
1890s Russian Orthodox Christian
theologians?

00:11:05.430 --> 00:11:09.250
2010 Raymond Kurzweil?

00:11:09.250 --> 00:11:14.595
It has what the police in the
UK refer to as "form." You

00:11:14.595 --> 00:11:17.230
know, it's come up on
their radar before.

00:11:17.230 --> 00:11:17.952
Shall I start?

00:11:17.952 --> 00:11:18.354
CORY DOCTOROW: Yeah.

00:11:18.354 --> 00:11:18.756
You're reading.

00:11:18.756 --> 00:11:21.350
CHARLES STROSS: And so I'd like
to read a chunk to you

00:11:21.350 --> 00:11:25.630
today, if I can get this machine
to recognize me,

00:11:25.630 --> 00:11:27.750
explaining how Huw
finds himself--

00:11:27.750 --> 00:11:30.320
Huw, our protagonist, finds
herself, I should add.

00:11:30.320 --> 00:11:33.680
Huw started out male and ends
up female and it gets

00:11:33.680 --> 00:11:35.150
complicated thereafter.

00:11:35.150 --> 00:11:36.410
[LAUGHTER]

00:11:36.410 --> 00:11:40.270
CHARLES STROSS: How Huw ends up
in the digital afterlife.

00:11:40.270 --> 00:11:43.100
And I should add, Huw is a
curmudgeonly Welsh Green who

00:11:43.100 --> 00:11:45.660
runs a pottery and trusts no
technology more complex than

00:11:45.660 --> 00:11:48.150
his bicycle.

00:11:48.150 --> 00:11:48.550
CORY DOCTOROW: Her.

00:11:48.550 --> 00:11:49.870
CHARLES STROSS: Her,
by this point.

00:11:49.870 --> 00:11:50.250
[LAUGHTER]

00:11:50.250 --> 00:11:51.010
CHARLES STROSS: No, the--

00:11:51.010 --> 00:11:52.910
I thought the bike
had been crushed.

00:11:52.910 --> 00:11:53.730
Anyway.

00:11:53.730 --> 00:11:54.073
CORY DOCTOROW: Continuity.

00:11:54.073 --> 00:11:54.416
CHARLES STROSS: Continuity.

00:11:54.416 --> 00:11:55.430
[LAUGHTER]

00:11:55.430 --> 00:11:55.830
CHARLES STROSS: Huw--

00:11:55.830 --> 00:11:56.290
CORY DOCTOROW: It's
a new bike.

00:11:56.290 --> 00:11:56.560
CHARLES STROSS: Yeah.

00:11:56.560 --> 00:11:57.690
It's a new bike.

00:11:57.690 --> 00:12:01.032
Huw is holding her right hand
under the cold-water tap and

00:12:01.032 --> 00:12:03.470
swearing when there's another
knock at the door.

00:12:03.470 --> 00:12:05.890
"Who is it?" she calls
down the hall.

00:12:05.890 --> 00:12:09.790
"It's the Singularity," a
booming voice replies.

00:12:09.790 --> 00:12:11.130
"What do you want?"

00:12:11.130 --> 00:12:13.260
"Everything is different now!"

00:12:13.260 --> 00:12:15.220
"I don't want any."

00:12:15.220 --> 00:12:19.100
"If I could just have a moment
of your time?" It takes a lot

00:12:19.100 --> 00:12:21.820
of skill to make a stentorian
voicebox emit a credible

00:12:21.820 --> 00:12:24.260
wheedle, but the bell ringer
at the door has clearly

00:12:24.260 --> 00:12:27.050
practiced it to a fine art.

00:12:27.050 --> 00:12:29.460
Huw turns the faucet back up and
puts her fingers into the

00:12:29.460 --> 00:12:30.920
cold stream.

00:12:30.920 --> 00:12:33.360
There are vicious little burns,
red welts that her

00:12:33.360 --> 00:12:35.390
honest, baseline human
cells will take

00:12:35.390 --> 00:12:37.400
weeks to properly heal.

00:12:37.400 --> 00:12:40.000
Of course, you could just ride
over to the McNanite's and get

00:12:40.000 --> 00:12:42.840
some salve that'd make them
vanish before her eyes, but

00:12:42.840 --> 00:12:45.660
Huw's endured much worse and she
still got enough stubborn

00:12:45.660 --> 00:12:49.360
stockpiled to last her
a couple of eons.

00:12:49.360 --> 00:12:51.610
There's another thud
at the door.

00:12:51.610 --> 00:12:52.630
Thud.

00:12:52.630 --> 00:12:53.660
Thud.

00:12:53.660 --> 00:12:54.670
Thudthudthud.

00:12:54.670 --> 00:12:58.160
Then a transhuman tattoo of
thuds in rising frequency,

00:12:58.160 --> 00:13:01.190
individual thuds blurring into a
composite buzz that gets the

00:13:01.190 --> 00:13:04.210
bones of the old house
rattling in sympathy,

00:13:04.210 --> 00:13:06.835
shivering down little hisses
of plaster dust from the

00:13:06.835 --> 00:13:09.500
joints in the ceiling.

00:13:09.500 --> 00:13:12.370
Huw uses her good hand to wrench
the faucet off, then

00:13:12.370 --> 00:13:15.040
wraps a tea towel around her
throbbing, dripping fingers

00:13:15.040 --> 00:13:17.670
and walks to the door, gritting
her teeth with every

00:13:17.670 --> 00:13:20.840
step as she forces herself
not to run.

00:13:20.840 --> 00:13:23.480
It feels like the house might
rattle down around her ears

00:13:23.480 --> 00:13:26.910
any second, but she won't give
the infinity-botherer outside

00:13:26.910 --> 00:13:29.410
the satisfaction.

00:13:29.410 --> 00:13:32.300
She opens the door with the
same measured calm.

00:13:32.300 --> 00:13:34.280
Let one of these fundies know
you're on edge, and he'll try

00:13:34.280 --> 00:13:36.490
to grab the psychological
advantage and work it until

00:13:36.490 --> 00:13:38.100
you agree to his balls.

00:13:38.100 --> 00:13:38.530
Sorry.

00:13:38.530 --> 00:13:38.990
Pitch.

00:13:38.990 --> 00:13:40.730
Freudian slip there.

00:13:40.730 --> 00:13:41.420
[LAUGHTER]

00:13:41.420 --> 00:13:46.178
"I said," Huw says, "I
don't want any."

00:13:46.178 --> 00:13:48.730
"I'm afraid I rather must
insist," says the

00:13:48.730 --> 00:13:52.750
infinity-botherer through his
augmented, celestial voicebox.

00:13:52.750 --> 00:13:54.940
The first of that voice makes
Huw take an involuntary

00:13:54.940 --> 00:13:58.460
wincing step backwards, like
a blast from an air horn.

00:13:58.460 --> 00:14:02.390
"Huw, this is mandatory,
not optional.

00:14:02.390 --> 00:14:05.140
This is mandatory,
not optional.

00:14:05.140 --> 00:14:08.100
The words send Huw whirling back
through time, back to her

00:14:08.100 --> 00:14:11.090
boyhood, and a million
repetitions and variations on

00:14:11.090 --> 00:14:12.250
this phrase from his--

00:14:12.250 --> 00:14:16.320
"Mum?" she asks, jaw dropping as
she stares up at the giant

00:14:16.320 --> 00:14:18.540
borg on the doorstep.

00:14:18.540 --> 00:14:21.980
It's at least three meters high,
silvery and fluid, thin

00:14:21.980 --> 00:14:24.380
as a schwa, all ashimmer
with otherworldly

00:14:24.380 --> 00:14:26.340
transcendent wossname.

00:14:26.340 --> 00:14:28.680
It's neither beautiful nor
handsome, though it's

00:14:28.680 --> 00:14:32.120
intensely aesthetically pleasing
in a way that demands

00:14:32.120 --> 00:14:35.070
some sort of genderless
superlative that no human

00:14:35.070 --> 00:14:37.410
language has ever managed.

00:14:37.410 --> 00:14:39.080
Huw hates it instantly--

00:14:39.080 --> 00:14:41.970
especially since she suspects at
the loa riding it might be

00:14:41.970 --> 00:14:46.120
descended from one of
his awful parents.

00:14:46.120 --> 00:14:48.030
"Yes, dear," the Singularity
booms.

00:14:48.030 --> 00:14:49.100
"I like the regendering.

00:14:49.100 --> 00:14:50.465
It really suits you.

00:14:50.465 --> 00:14:52.660
Your father would send his best,
by the way, if he was

00:14:52.660 --> 00:14:56.400
still hanging around
the solar system."

00:14:56.400 --> 00:14:59.200
Huw last saw her parents
at their disembodiment.

00:14:59.200 --> 00:15:01.660
They'd already had avatars
running around in the cloud

00:15:01.660 --> 00:15:04.930
for years, dipping into
meatspace every now and again

00:15:04.930 --> 00:15:06.560
for a resynch with
their slowcode

00:15:06.560 --> 00:15:09.380
bioinstances dirtside.

00:15:09.380 --> 00:15:12.070
When they were finally
deconstituted into a fine

00:15:12.070 --> 00:15:15.320
powder of component molecules,
it'd been a technicality

00:15:15.320 --> 00:15:19.300
really, a final flourish in
their transhumanunification.

00:15:19.300 --> 00:15:22.860
But the finality of it, zero out
their bodies, had marked a

00:15:22.860 --> 00:15:24.140
break for Huw.

00:15:24.140 --> 00:15:27.180
Mum and Dad were now
technically dead.

00:15:27.180 --> 00:15:28.670
They were technically
alive, too, but that

00:15:28.670 --> 00:15:30.650
was beside the point.

00:15:30.650 --> 00:15:34.855
Until Mum donned a golem
and came to talk.

00:15:34.855 --> 00:15:37.770
"Mum, I don't talk to dead
people," Huw says.

00:15:37.770 --> 00:15:41.660
"Go away." She deliberately does
not slam the door, but

00:15:41.660 --> 00:15:44.850
closes it, and turns the latch,
and heads back to the

00:15:44.850 --> 00:15:48.300
sink, deliberately ignoring the
fragments of cloud wearing

00:15:48.300 --> 00:15:50.730
her mum's memories.

00:15:50.730 --> 00:15:53.640
She manages to go three steps
before the door splinters and

00:15:53.640 --> 00:15:56.520
tears loose of its hinges,
thudding to the painstakingly

00:15:56.520 --> 00:15:59.120
restored tile floor in the
front hall with a merry

00:15:59.120 --> 00:16:02.000
tinkling of shattered
antique glass.

00:16:02.000 --> 00:16:04.550
"Love, I know you're not best
pleased to see me, but you've

00:16:04.550 --> 00:16:08.170
been summoned, and
that's that."

00:16:08.170 --> 00:16:12.490
The spirit of adolescence
descends on Huw in a red mist.

00:16:12.490 --> 00:16:14.960
Her mum has always been able to
reduce her to a screeching

00:16:14.960 --> 00:16:16.910
teakettle of resentment.

00:16:16.910 --> 00:16:18.250
"Get out my house, mum!

00:16:18.250 --> 00:16:20.910
I hate you!"

00:16:20.910 --> 00:16:24.050
Her mum's avatar grabs Huw in a
vicious hug that feels like

00:16:24.050 --> 00:16:28.430
foam rubber paddings wrapped
around titanium armatures.

00:16:28.430 --> 00:16:29.840
"Poor thing," it says.

00:16:29.840 --> 00:16:31.380
I know it's been hard for you.

00:16:31.380 --> 00:16:34.580
We did our best, you know, but
well, we were only human.

00:16:34.580 --> 00:16:37.390
Now, come along, sweetie."

00:16:37.390 --> 00:16:40.510
It's Tripoli all over again, but
this time the golem whose

00:16:40.510 --> 00:16:43.690
grasp she can't escape emits
a steady stream of basso

00:16:43.690 --> 00:16:47.350
profundo validations of Huw's
many gifts and talents and how

00:16:47.350 --> 00:16:51.260
proud her parents are of all
she's achieved and suchlike.

00:16:51.260 --> 00:16:54.000
Huy tries to signal a
beedlemote, but her mum's got

00:16:54.000 --> 00:16:56.190
some kind of diplomatic
semaphore that makes all the

00:16:56.190 --> 00:16:59.080
enforcementware give
it free passage.

00:16:59.080 --> 00:17:02.130
Mum's bot stops at every traffic
signal, and several

00:17:02.130 --> 00:17:04.960
times, Huw tries to get
passersby by to help her, with

00:17:04.960 --> 00:17:06.920
lines like, "I'm being kidnapped
by the bloody

00:17:06.920 --> 00:17:08.839
Singularity!"

00:17:08.839 --> 00:17:12.280
Unfortunately, nobody seems
interested in lending a hand.

00:17:12.280 --> 00:17:15.560
And even if they did, Mum goes
about 200 kilometers per hour

00:17:15.560 --> 00:17:18.900
between traffic lights, her gait
so fast that every time

00:17:18.900 --> 00:17:22.339
Huw opens her mouth to screen,
it fills with wind and her

00:17:22.339 --> 00:17:24.970
cheeks wibble and wobble while
she tries to breathe past the

00:17:24.970 --> 00:17:27.760
air battering at her windpipe.

00:17:27.760 --> 00:17:30.718
Then they've arrived.

00:17:30.718 --> 00:17:35.030
The alien consulate is midfab,
its hairy fractal edges

00:17:35.030 --> 00:17:37.380
radiating heat as nanites
grab matter out of the

00:17:37.380 --> 00:17:39.400
sky to add to it.

00:17:39.400 --> 00:17:42.500
The actual walls are only waist
high, though the spindly

00:17:42.500 --> 00:17:45.630
plumbing, mains, and network
infrastructure are already in

00:17:45.630 --> 00:17:49.370
place and teeter skyward like
a disembodied nervous system

00:17:49.370 --> 00:17:53.220
filled with dye for an
anatomical illustration.

00:17:53.220 --> 00:17:56.250
The consul is an infinitely
hot and dense dot of

00:17:56.250 --> 00:17:59.080
eyeball-warping fuzz in the
exact center of what will be

00:17:59.080 --> 00:18:00.940
the ground floor.

00:18:00.940 --> 00:18:03.820
Well, it's not exactly infinite,
but it does seem to

00:18:03.820 --> 00:18:07.060
bend the light around it, and it
certainly radiates too much

00:18:07.060 --> 00:18:08.880
heat to approach closely.

00:18:08.880 --> 00:18:11.330
"Thank you for coming,"
it says.

00:18:11.330 --> 00:18:12.630
"You brought your invitation, I

00:18:12.630 --> 00:18:14.750
hope?" "Fuck you!

00:18:14.750 --> 00:18:17.050
No!" Huw screams.

00:18:17.050 --> 00:18:19.280
She's gathering breath for
another outburst, but Mum

00:18:19.280 --> 00:18:20.370
shakes her--

00:18:20.370 --> 00:18:23.490
gently by golem standards, but
hard enough to rattle the

00:18:23.490 --> 00:18:25.185
teeth in her jaws.

00:18:25.185 --> 00:18:28.620
"Bad idea, darling." A palpable
cone of silence

00:18:28.620 --> 00:18:31.730
descends around Huw's ears as
Mum confides, "When I said it

00:18:31.730 --> 00:18:33.840
was mandatory, I was serious.

00:18:33.840 --> 00:18:37.300
If you don't comply, it'll
delete everyone."

00:18:37.300 --> 00:18:38.660
"Fuuuu--" Huw pauses.

00:18:38.660 --> 00:18:42.440
"Delete?" She realizes that
everything outside the cone of

00:18:42.440 --> 00:18:46.340
silence has stopped, stuck in a
bizarre meatspace cognate of

00:18:46.340 --> 00:18:47.630
bullet time--

00:18:47.630 --> 00:18:50.555
that's hanging on the wing in
midair, leaves frozen in

00:18:50.555 --> 00:18:52.962
midfall, that sort of thing.

00:18:52.962 --> 00:18:53.830
"Yes, dear.

00:18:53.830 --> 00:18:55.450
I'm not exaggerating.

00:18:55.450 --> 00:18:58.950
It's come to pass a visit from
the Next Level, and faster,

00:18:58.950 --> 00:19:02.610
smarter thinkers than you or I
are crapping themselves." Huw

00:19:02.610 --> 00:19:03.670
is rattled.

00:19:03.670 --> 00:19:05.730
Mum always had an accurate
appreciation of her own

00:19:05.730 --> 00:19:08.340
abilities, and as a Fields
Medal winner, she wasn't

00:19:08.340 --> 00:19:11.080
inclined to hide them
under a bushel.

00:19:11.080 --> 00:19:12.910
"But it's playing by the
rules, apparentl.

00:19:12.910 --> 00:19:15.910
There's got to be a
Public Inquiry.

00:19:15.910 --> 00:19:18.170
Which means statements by
witnesses and friends of the

00:19:18.170 --> 00:19:19.800
court and so on and so forth--

00:19:19.800 --> 00:19:23.760
all very tiresome, I'm sure,
but it seems your name came

00:19:23.760 --> 00:19:26.640
out of the hat first.

00:19:26.640 --> 00:19:31.280
So I'm afraid you're back on
jury duty, like it or not.

00:19:31.280 --> 00:19:35.356
If it's any consolation, I'll
try to make this painless."

00:19:35.356 --> 00:19:38.345
The birds and the bees resume
their respective chirping and

00:19:38.345 --> 00:19:41.410
buzzing as the cone of silence
collapses on Huw like an icy

00:19:41.410 --> 00:19:43.810
waterfall of fear.

00:19:43.810 --> 00:19:47.590
"Shitbiscuits!" she screams as
Mum gently wraps a band of

00:19:47.590 --> 00:19:49.970
silvery-shimmering
nanomanipulators around Huw's

00:19:49.970 --> 00:19:54.530
head and saws off the
top of her skull.

00:19:54.530 --> 00:19:56.100
Over to Cory.

00:19:56.100 --> 00:19:59.360
[APPLAUSE]

00:19:59.360 --> 00:20:04.310
CORY DOCTOROW: So as you've just
heard, Huw is forcibly

00:20:04.310 --> 00:20:05.860
transcended.

00:20:05.860 --> 00:20:08.470
And later on in the story, the
section I'm going to read,

00:20:08.470 --> 00:20:13.830
she's finally been taken off to
the galactic civilization's

00:20:13.830 --> 00:20:17.750
holding pen for expert
witnesses, which is a giant,

00:20:17.750 --> 00:20:21.120
tasteless replica of the Burj
Khalifa made out of the bones

00:20:21.120 --> 00:20:25.060
of the moons of Jupiter, which
have been co-opted as a

00:20:25.060 --> 00:20:28.590
temporary computronium
outpost.

00:20:28.590 --> 00:20:32.780
It's so tasteless that the
doorman is a giant gorilla.

00:20:32.780 --> 00:20:35.170
"I hope you enjoy the facilities
here," says the

00:20:35.170 --> 00:20:36.680
gorilla, with a wink.

00:20:36.680 --> 00:20:39.060
"Nothing but the best for
our expert witnesses--

00:20:39.060 --> 00:20:42.830
we have hot and cold running
everything."

00:20:42.830 --> 00:20:47.960
It's a far cry from jury duty
accommodation in the crappy

00:20:47.960 --> 00:20:50.850
backpacker's hostel
in dusty Tripoli.

00:20:50.850 --> 00:20:54.940
Huw dials her time right up
(sinfully extravagant) and

00:20:54.940 --> 00:20:58.130
orders the whirlpool-equipped
hot tub with champagne to

00:20:58.130 --> 00:21:00.030
appear in the bathroom.

00:21:00.030 --> 00:21:03.640
Then she climbs in to marinate
for subjective hours (a

00:21:03.640 --> 00:21:08.020
handful of seconds in everyone
else's timeframe) and to

00:21:08.020 --> 00:21:11.390
unkink for the first
time in ages.

00:21:11.390 --> 00:21:13.500
After all, it's not as though
she's consuming

00:21:13.500 --> 00:21:15.170
real resources here.

00:21:15.170 --> 00:21:19.380
And she needs to relax, needs
to recenter her emotions the

00:21:19.380 --> 00:21:23.420
natural way, and do some
serious plotting.

00:21:23.420 --> 00:21:27.750
Of course, the sim is
far too realistic.

00:21:27.750 --> 00:21:30.850
A virtual champagne bath should
somehow manage to keep

00:21:30.850 --> 00:21:33.560
the champagne
drinking-temperature cold

00:21:33.560 --> 00:21:36.180
while still feeling
warm to the touch.

00:21:36.180 --> 00:21:39.410
And it shouldn't be sticky
and hot and flat.

00:21:39.410 --> 00:21:41.500
It should feel like champagne
does when

00:21:41.500 --> 00:21:42.630
it hits your tongue--

00:21:42.630 --> 00:21:44.730
icy, bubbly, and fizzy.

00:21:44.730 --> 00:21:48.770
And when Huw's non-bladder feels
uncomfortably full and

00:21:48.770 --> 00:21:52.210
relaxed in the hot liquid and
she lets loose a surreptitious

00:21:52.210 --> 00:21:56.720
stream, it should be magicked
away, not instantly blended in

00:21:56.720 --> 00:21:59.420
with the vintage Veuve Clicquot
to make an instant

00:21:59.420 --> 00:22:01.250
tub's worth of piss mimosa.

00:22:01.250 --> 00:22:03.300
[LAUGHTER]

00:22:03.300 --> 00:22:06.840
This is what comes of having too
much compute-time at one's

00:22:06.840 --> 00:22:09.620
disposal, Huw seethes.

00:22:09.620 --> 00:22:13.190
In constraint, there is
discipline, the need to choose

00:22:13.190 --> 00:22:16.270
how much reality you're going
to import and model.

00:22:16.270 --> 00:22:19.690
Sitting on an Io's worth of
computronium has freed the

00:22:19.690 --> 00:22:20.900
Galactic Authority--

00:22:20.900 --> 00:22:24.060
and isn't that an imaginative
corker of a name?--

00:22:24.060 --> 00:22:26.110
from having to choose.

00:22:26.110 --> 00:22:29.070
And with her own self simulated
as hot and wide as

00:22:29.070 --> 00:22:32.530
she can be bothered with, she
can feel every unpleasant

00:22:32.530 --> 00:22:37.230
sensation, each individual
sticky bubble, each droplet

00:22:37.230 --> 00:22:40.800
clinging to her body as she hops
out of the tub and into a

00:22:40.800 --> 00:22:44.660
six-jet steam-shower for a
top-to-bottom rinse, and then

00:22:44.660 --> 00:22:45.800
grabs a towel--

00:22:45.800 --> 00:22:49.610
every fiber slightly stiff and
plasticky, as if fresh out of

00:22:49.610 --> 00:22:51.760
the wrapper and never
properly laundered

00:22:51.760 --> 00:22:53.870
to relax the fibers--

00:22:53.870 --> 00:22:55.480
and she dries off.

00:22:55.480 --> 00:22:58.630
She discovers that she is
hyperaware, hyperalert,

00:22:58.630 --> 00:23:01.830
feeling every grain of not-dust
in the not-air

00:23:01.830 --> 00:23:05.260
individually as it collides
with her not-skin.

00:23:05.260 --> 00:23:07.310
Oh, enough, she wants
to shout.

00:23:07.310 --> 00:23:11.460
What is the point of
all this rubbish?

00:23:11.460 --> 00:23:15.710
This is the thing that Huw has
never wanted to admit.

00:23:15.710 --> 00:23:18.600
Her primary beef against the
Singularity has never been

00:23:18.600 --> 00:23:20.120
existential--

00:23:20.120 --> 00:23:21.820
it's aesthetic.

00:23:21.820 --> 00:23:25.090
The power to be a being of pure
thought, the unlimited,

00:23:25.090 --> 00:23:28.820
unconstrained world of
imagination, and we build a

00:23:28.820 --> 00:23:33.540
world of animated gifs, stupid
sight gags, lame van-art

00:23:33.540 --> 00:23:37.500
avatars, brain-dead "playful"
environments, and brain-dead

00:23:37.500 --> 00:23:41.130
flame wars augmented by animated
emoticons that allow

00:23:41.130 --> 00:23:44.390
participants to express their
hackneyed ad hominems,

00:23:44.390 --> 00:23:47.830
concern-trollery, and violations
of Godwin's law

00:23:47.830 --> 00:23:49.890
through the media of
cartoon animals and

00:23:49.890 --> 00:23:54.130
oversized animated genitals.

00:23:54.130 --> 00:23:58.160
Whether or not sim-Huw is really
Huw, whether or not

00:23:58.160 --> 00:24:02.120
uploading is a kind of death,
whether or not posthumanity is

00:24:02.120 --> 00:24:06.060
immortal or just kidding itself,
the single inviolable

00:24:06.060 --> 00:24:07.630
fact remains.

00:24:07.630 --> 00:24:10.610
Humans simspace is no more
tasteful than the

00:24:10.610 --> 00:24:14.700
architectural train wreck
that the Galactic

00:24:14.700 --> 00:24:16.590
Authority has erected.

00:24:16.590 --> 00:24:19.650
The people who live in it have
all the aesthetic sense of a

00:24:19.650 --> 00:24:21.410
senile jackdaw.

00:24:21.410 --> 00:24:23.330
Huw is prepared to accept--
for the sake

00:24:23.330 --> 00:24:24.490
of argument, mind--

00:24:24.490 --> 00:24:28.320
that uploading leaves your soul
intact, but she is never

00:24:28.320 --> 00:24:31.230
going to give one nanometer
on the question of whether

00:24:31.230 --> 00:24:34.630
uploading leaves your
taste intact.

00:24:34.630 --> 00:24:38.150
If the Turing test measure an
AI's capacity to conduct

00:24:38.150 --> 00:24:42.230
itself with a sense of real
style, all of simspace would

00:24:42.230 --> 00:24:44.650
be revealed for a
machine-sham.

00:24:44.650 --> 00:24:47.380
Give humanity a truly unlimited
field, and it would

00:24:47.380 --> 00:24:50.850
fill it with Happy Meal toys and
holographic, sport-star,

00:24:50.850 --> 00:24:54.840
collectible trading
card game art.

00:24:54.840 --> 00:24:57.600
There's a whole gang of dirtside
refuseniks to make

00:24:57.600 --> 00:25:00.260
this their primary objective
to transcendence.

00:25:00.260 --> 00:25:03.860
They're severe Bauhause
cosplayers, so immaculately

00:25:03.860 --> 00:25:05.910
and plainly turned out that
they look more like

00:25:05.910 --> 00:25:07.920
illustrations than humans.

00:25:07.920 --> 00:25:10.310
Huw's never felt any
affinity for them--

00:25:10.310 --> 00:25:14.040
too cringeworthy, to like a
Southern belle who comes down

00:25:14.040 --> 00:25:17.420
with the vapors at the sight of
a fish knife laying where

00:25:17.420 --> 00:25:19.870
the dessert fork
is meant to go.

00:25:19.870 --> 00:25:23.640
It's always felt unserious to
object to a major debate over

00:25:23.640 --> 00:25:27.380
human evolution with an
argument about style.

00:25:27.380 --> 00:25:30.960
But Huw appreciates their point,
and has spent his and

00:25:30.960 --> 00:25:35.460
then her entire life complaining
instead about the

00:25:35.460 --> 00:25:38.820
ineffable and undefinable
humanness that is lost when

00:25:38.820 --> 00:25:40.830
someone departs for the cloud.

00:25:40.830 --> 00:25:44.060
She's turned her back on her
parents, refused to take their

00:25:44.060 --> 00:25:47.110
calls from beyond the grave,
she's shut herself up in her

00:25:47.110 --> 00:25:50.440
pottery with only the barest
vestige of a social life,

00:25:50.440 --> 00:25:54.490
remade herself as someone who is
both a defender of humanity

00:25:54.490 --> 00:25:56.240
and a misanthrope.

00:25:56.240 --> 00:25:59.490
All the while, she's
insisted--

00:25:59.490 --> 00:26:02.650
mostly to herself, because, as
she now sees with glittering

00:26:02.650 --> 00:26:05.100
clarity, no one else
gave a shit--

00:26:05.100 --> 00:26:08.130
that the source of her concerns
all along has been

00:26:08.130 --> 00:26:09.990
metaphysical.

00:26:09.990 --> 00:26:13.720
The reality that stares her in
the face now, as she reclines

00:26:13.720 --> 00:26:17.330
on the impeccably rendered
20-million-count non-Egyptian

00:26:17.330 --> 00:26:21.410
noncotton nonsheets, is that
it's always been a perfectly

00:26:21.410 --> 00:26:25.100
normal, absolutely subjective,
totally meaningless dispute

00:26:25.100 --> 00:26:27.160
about color schemes.

00:26:27.160 --> 00:26:31.910
And now she's got existential
angst.

00:26:31.910 --> 00:26:36.030
The Burj Khalifa's in-room TV
gets an infinity of channels,

00:26:36.030 --> 00:26:38.020
evidently cross-wired
from the cable feed

00:26:38.020 --> 00:26:39.430
for Hilbert's hotel.

00:26:39.430 --> 00:26:40.300
It uses some--

00:26:40.300 --> 00:26:41.580
[LAUGHTER]

00:26:41.580 --> 00:26:44.450
It uses some evolutionary
computing system to generate

00:26:44.450 --> 00:26:46.850
new programs on the fly,
every time you press

00:26:46.850 --> 00:26:48.310
the channel-up button.

00:26:48.310 --> 00:26:51.500
This isn't nearly as banal as
Huw imagined it might be when

00:26:51.500 --> 00:26:54.110
she read about it on the
triangular-folded cardboard

00:26:54.110 --> 00:26:56.910
standup that materialized in her
hand when she reached for

00:26:56.910 --> 00:26:58.250
the remote.

00:26:58.250 --> 00:26:59.170
That's because--

00:26:59.170 --> 00:27:00.770
as the card explained--

00:27:00.770 --> 00:27:03.900
the Burj has enough computation
to model captive

00:27:03.900 --> 00:27:07.290
versions of Huw at extremely
high speed, and to tailor the

00:27:07.290 --> 00:27:09.680
programming by sharpening
its teeth against those

00:27:09.680 --> 00:27:12.430
instances-in-a-bottle so that
every press of the button

00:27:12.430 --> 00:27:15.510
brings up eye-catching,
attention-snaring material.

00:27:15.510 --> 00:27:17.640
It's mostly soft-core
pornography

00:27:17.640 --> 00:27:18.840
that involves pottery.

00:27:18.840 --> 00:27:21.350
[LAUGHTER]

00:27:21.350 --> 00:27:24.150
Huw would like nothing better
than to relax with the

00:27:24.150 --> 00:27:27.200
goggle-box and let her mind
be lovingly swaddled in

00:27:27.200 --> 00:27:31.150
intellectual flannel, but her
mind isn't having any of it.

00:27:31.150 --> 00:27:34.680
The more broadly parallel she
runs, the more meta-cognition

00:27:34.680 --> 00:27:38.590
she finds herself mired in, so
that even as she lies abed,

00:27:38.590 --> 00:27:41.350
propped up on a hill of pillows
the size of a Celtic

00:27:41.350 --> 00:27:46.590
burial mound, her thoughts are
doing something like this.

00:27:46.590 --> 00:27:46.730
Oh.

00:27:46.730 --> 00:27:47.710
That's interesting.

00:27:47.710 --> 00:27:50.752
Never thought of doing that
sort of thing with glaze.

00:27:50.752 --> 00:27:52.330
Oh, too interesting.

00:27:52.330 --> 00:27:54.410
If you ask me, it's not
natural, that kind of

00:27:54.410 --> 00:27:55.100
interesting.

00:27:55.100 --> 00:27:57.950
They've got to be simulating
gigaHuws to come up with that

00:27:57.950 --> 00:28:00.400
sort of realtime optimization.

00:28:00.400 --> 00:28:03.350
There'll be hordes of Huw
instances being subjected to

00:28:03.350 --> 00:28:06.480
much-less-interesting versions
of this program and winking

00:28:06.480 --> 00:28:09.160
out of existence as soon
as they get bored.

00:28:09.160 --> 00:28:12.950
Hell, I could be one of those
instances, my life dangling by

00:28:12.950 --> 00:28:15.430
a frayed thread of attention.

00:28:15.430 --> 00:28:18.560
Every time I press the
channel-up button, I execute

00:28:18.560 --> 00:28:19.470
thousands--

00:28:19.470 --> 00:28:20.760
millions?

00:28:20.760 --> 00:28:21.720
billions?--

00:28:21.720 --> 00:28:23.440
of copies of myself.

00:28:23.440 --> 00:28:25.630
Why don't I care more
about them?

00:28:25.630 --> 00:28:29.160
It's insane and profligate
cruelty but here's me blithely

00:28:29.160 --> 00:28:31.270
pressing the channel-up
button.

00:28:31.270 --> 00:28:33.180
Whoa, that's interesting--

00:28:33.180 --> 00:28:35.810
she looks awfully like Bonnie,
but with a bum that's a little

00:28:35.810 --> 00:28:38.470
bit more like that girl
I fancied in college.

00:28:38.470 --> 00:28:41.490
I could die at any instant, just
by losing attention and

00:28:41.490 --> 00:28:43.320
pressing channel-up.

00:28:43.320 --> 00:28:45.390
That's wild, I never noticed
how those muscles--

00:28:45.390 --> 00:28:47.480
the quadrati lumborum?--

00:28:47.480 --> 00:28:50.120
spring out when someone's at
the wheel, that bloke's got

00:28:50.120 --> 00:28:52.040
QL's for days.

00:28:52.040 --> 00:28:54.800
If I were really aesthetically
opposed to this sort of thing,

00:28:54.800 --> 00:28:57.410
I'd be vomming in my mouth with
rage at the thought of

00:28:57.410 --> 00:29:00.450
all those virtual people
springing into existence and

00:29:00.450 --> 00:29:01.920
being snuffed out.

00:29:01.920 --> 00:29:03.350
But I'm not, am I?

00:29:03.350 --> 00:29:08.170
Hypocrite, liar, poseur, mincing
aesthete, that's me.

00:29:08.170 --> 00:29:10.120
So long as it's interesting
and stylish,

00:29:10.120 --> 00:29:12.280
I'll forgive anything.

00:29:12.280 --> 00:29:13.930
I've got as much existential

00:29:13.930 --> 00:29:17.160
introspection as a Mario sprite.

00:29:17.160 --> 00:29:20.230
Enough, already, she tells
herself, and cools herself

00:29:20.230 --> 00:29:24.150
down to a single thread, then
throws that down, hunting for

00:29:24.150 --> 00:29:28.040
the sweet spot at the junction
of stupidity and calm.

00:29:28.040 --> 00:29:31.956
Then finding it, she settles
down and watches TV for one

00:29:31.956 --> 00:29:35.560
hundred subjective years,
slaughtering invisible hordes

00:29:35.560 --> 00:29:38.640
of herself without a moment's
further thought.

00:29:38.640 --> 00:29:41.190
Satori.

00:29:41.190 --> 00:29:42.618
So that's the reading.

00:29:42.618 --> 00:29:49.420
[APPLAUSE]

00:29:49.420 --> 00:29:51.100
we're on there is
a power button.

00:29:51.100 --> 00:29:52.860
Or is that controlled
of a console?

00:29:52.860 --> 00:29:56.440
So we're now free to take
your questions.

00:29:56.440 --> 00:29:58.450
We can share the mic
if we can't figure

00:29:58.450 --> 00:29:58.960
out how to get one.

00:29:58.960 --> 00:30:00.660
How many science fiction writers
does it take to turn

00:30:00.660 --> 00:30:01.570
on a wireless mic?

00:30:01.570 --> 00:30:03.850
All of them, apparently.

00:30:03.850 --> 00:30:05.170
So are there any questions?

00:30:05.170 --> 00:30:05.900
Yeah.

00:30:05.900 --> 00:30:08.200
AUDIENCE: Would I be correct
in guessing that you wrote

00:30:08.200 --> 00:30:10.970
sections primarily
by yourselves?

00:30:10.970 --> 00:30:11.620
CORY DOCTOROW: Uh, no.

00:30:11.620 --> 00:30:12.990
CHARLES STROSS: I
don't think so.

00:30:12.990 --> 00:30:13.500
CORY DOCTOROW: No.

00:30:13.500 --> 00:30:16.090
They really-- there's a lot of
thought of interwriting in

00:30:16.090 --> 00:30:17.100
both of those passages.

00:30:17.100 --> 00:30:20.010
They're really interwritten,
those two, particularly.

00:30:20.010 --> 00:30:22.600
Those are among the passages
where, when I read them, I'm

00:30:22.600 --> 00:30:24.730
like, that looks like my tick
and that looks like Charlies

00:30:24.730 --> 00:30:26.460
tick and who the fuck
wrote that?

00:30:26.460 --> 00:30:26.765
[LAUGHTER]

00:30:26.765 --> 00:30:27.390
CHARLES STROSS: Yeah.

00:30:27.390 --> 00:30:30.060
We were swapping over about
every 500 to 1,000 words, and

00:30:30.060 --> 00:30:32.700
both of the passages we read are
well over 1,000 words, so.

00:30:32.700 --> 00:30:34.430
CORY DOCTOROW: And we did
lots of re-editing of

00:30:34.430 --> 00:30:36.400
each other's stuff.

00:30:36.400 --> 00:30:38.830
So there are some interesting
offcuts lying around in our

00:30:38.830 --> 00:30:41.980
hard drives, too.

00:30:41.980 --> 00:30:43.656
Other questions?

00:30:43.656 --> 00:30:46.170
We actually could figure out who
wrote those, because I at

00:30:46.170 --> 00:30:48.390
least did version control
with them.

00:30:48.390 --> 00:30:50.260
I--

00:30:50.260 --> 00:30:52.780
a friend of mine wrote me some
Python scripts that are in

00:30:52.780 --> 00:30:56.220
GitHub called flashbake, and
every 15 minutes, they grab

00:30:56.220 --> 00:30:59.190
all my working files and then
they check them into a local

00:30:59.190 --> 00:31:01.120
Git repo with the--

00:31:01.120 --> 00:31:04.030
it figures out what time zone
I'm in from my IP address,

00:31:04.030 --> 00:31:07.510
where I am from my IP address,
the last three songs I

00:31:07.510 --> 00:31:11.335
listened to, the last three
headlines I posted on Boing

00:31:11.335 --> 00:31:13.820
Boing," and then and logs it.

00:31:13.820 --> 00:31:16.810
And I figure, you know, in like
10 years, it'll be kind

00:31:16.810 --> 00:31:18.370
of interesting to go back
and look over it.

00:31:18.370 --> 00:31:20.890
I've also been thinking that I
could probably do something

00:31:20.890 --> 00:31:23.310
more interesting these days,
like take a picture every 15

00:31:23.310 --> 00:31:23.940
minutes and--

00:31:23.940 --> 00:31:24.540
CHARLES STROSS: Blood
pressure.

00:31:24.540 --> 00:31:26.550
CORY DOCTOROW: Blood pressure
from the picture.

00:31:26.550 --> 00:31:31.320
Skin galvanometry, skin response
from the touch pad.

00:31:31.320 --> 00:31:32.410
And probably more.

00:31:32.410 --> 00:31:34.370
I mean, I'm sure, like,
eventually the mic will be

00:31:34.370 --> 00:31:35.930
sensitive enough to grab
things like heart

00:31:35.930 --> 00:31:37.390
rate and so on, too.

00:31:37.390 --> 00:31:38.530
AUDIENCE: Is that
Thomas Gideon?

00:31:38.530 --> 00:31:40.340
CORY DOCTOROW: That's
Thomas Gideon, yeah.

00:31:40.340 --> 00:31:42.105
He's a good guy.

00:31:42.105 --> 00:31:43.020
You know him?

00:31:43.020 --> 00:31:45.730
He has a great podcast called
"The Command Line." And he

00:31:45.730 --> 00:31:47.070
works for New America
Foundation now.

00:31:47.070 --> 00:31:49.100
He's one of the
internet-in-a-box guys.

00:31:49.100 --> 00:31:50.220
CHARLES STROSS: I like
living dangerously.

00:31:50.220 --> 00:31:52.490
I just basically left
my backups to Time

00:31:52.490 --> 00:31:54.210
Machine on the laptop.

00:31:54.210 --> 00:31:57.150
Having said that, we worked on
this as just a markdown file

00:31:57.150 --> 00:32:00.690
bounced back and forth in email,
and as long as the

00:32:00.690 --> 00:32:02.750
email folders are thoroughly
backed up, I've got different

00:32:02.750 --> 00:32:04.295
snapshots all the way through.

00:32:04.295 --> 00:32:04.630
CORY DOCTOROW: Yeah.

00:32:04.630 --> 00:32:07.120
I mean, this all started with
the Merril Collection in

00:32:07.120 --> 00:32:10.020
Toronto, which is the largest
public science fiction

00:32:10.020 --> 00:32:12.450
reference library in the world,
started by Judy Merril,

00:32:12.450 --> 00:32:15.540
who was kind of my mentor
when I was younger.

00:32:15.540 --> 00:32:17.100
They logged my papers for me.

00:32:17.100 --> 00:32:18.910
Because when I started selling
novels, I was moving

00:32:18.910 --> 00:32:20.340
continents like every
18 months.

00:32:20.340 --> 00:32:23.550
And especially back then, every
novel you sold involved

00:32:23.550 --> 00:32:26.060
three lumps of paper at
least about this big.

00:32:26.060 --> 00:32:27.620
There was the initial
manuscript, and then the

00:32:27.620 --> 00:32:29.710
marked-up manuscript, and then
the typed script, and so on.

00:32:29.710 --> 00:32:31.020
And there was no way I
could manage them.

00:32:31.020 --> 00:32:33.020
And so they just keep my papers
for me, and one day,

00:32:33.020 --> 00:32:35.320
the head librarian, Lorna
Toolis, said, you know, it's

00:32:35.320 --> 00:32:38.110
such a pity, because in the
old days, we used to get

00:32:38.110 --> 00:32:40.700
multiple distinct drafts
from our writers.

00:32:40.700 --> 00:32:42.750
And this was obviously very
interesting to scholars in

00:32:42.750 --> 00:32:43.860
subsequent years.

00:32:43.860 --> 00:32:47.640
And now there's just kind of
the rolling text file that

00:32:47.640 --> 00:32:49.370
then gets turned into a book.

00:32:49.370 --> 00:32:51.440
If only there were some way
to keep track of the

00:32:51.440 --> 00:32:52.725
changes to a text file.

00:32:52.725 --> 00:32:53.460
[LAUGHTER]

00:32:53.460 --> 00:32:54.780
CORY DOCTOROW: And I was like,
you know, this is the

00:32:54.780 --> 00:32:57.370
canonical solved
problem, right?

00:32:57.370 --> 00:33:00.548
So that's where it
all started.

00:33:00.548 --> 00:33:01.570
Are there other questions?

00:33:01.570 --> 00:33:02.630
Yeah?

00:33:02.630 --> 00:33:03.880
AUDIENCE: [INAUDIBLE]

00:33:07.820 --> 00:33:10.180
CHARLES STROSS: We will talk
about it at the end of this

00:33:10.180 --> 00:33:12.250
talk, if we haven't strangled
each other first.

00:33:12.250 --> 00:33:13.940
CORY DOCTOROW: Yeah, I mean,
everything is possible.

00:33:13.940 --> 00:33:16.360
We might upload and fork new
instances to work on books

00:33:16.360 --> 00:33:17.100
together or something.

00:33:17.100 --> 00:33:17.730
CHARLES STROSS: Yeah.

00:33:17.730 --> 00:33:18.240
CORY DOCTOROW: It's possible.

00:33:18.240 --> 00:33:21.710
We both have a lot of stuff
on the go at the moment.

00:33:21.710 --> 00:33:24.030
And we are-- we're both
contributing to a project,

00:33:24.030 --> 00:33:26.010
although we're not collaborating
directly on it.

00:33:26.010 --> 00:33:28.180
Neal Stephenson is working on
this thing, "Hieroglyphics,"

00:33:28.180 --> 00:33:29.600
with Arizona State.

00:33:29.600 --> 00:33:33.590
It's science fiction stories
built on real science,

00:33:33.590 --> 00:33:37.020
credible, sort of plausible
science.

00:33:37.020 --> 00:33:39.770
I'm working on a story about
Burners who create a

00:33:39.770 --> 00:33:43.590
playa-dust printer that is so
successful, they drop it on

00:33:43.590 --> 00:33:45.880
the Playa at Fourth of Juplaya
celebration at the start of

00:33:45.880 --> 00:33:48.480
the summer, and by Labor Day
weekend, it's printed out

00:33:48.480 --> 00:33:49.320
their yurt.

00:33:49.320 --> 00:33:52.340
And they live in it for Burning
Man, and then they

00:33:52.340 --> 00:33:54.630
chop it up into pieces
and pack it out.

00:33:54.630 --> 00:33:56.860
And they're so happy with it
that they decide to build one

00:33:56.860 --> 00:33:58.490
that does luna rigala.

00:33:58.490 --> 00:34:01.420
And they use a private
space-exploration vehicle to

00:34:01.420 --> 00:34:03.910
drop one on the moon, and
they spend a generation

00:34:03.910 --> 00:34:07.590
reprogramming its firmware by
bouncing hand signals off the

00:34:07.590 --> 00:34:11.000
moon and building a lunar
habitat that their

00:34:11.000 --> 00:34:12.280
grandchildren can move into.

00:34:12.280 --> 00:34:13.929
And Charlie, what story
are you working on?

00:34:13.929 --> 00:34:15.810
CHARLES STROSS: Well, I was
meant to be working on the

00:34:15.810 --> 00:34:17.383
third of a trilogy beginning
with "Halting

00:34:17.383 --> 00:34:18.620
State" and "Rule 34"--

00:34:18.620 --> 00:34:20.900
this being the political
one titled "The Lambda

00:34:20.900 --> 00:34:23.389
Functionary." But it's going to
take me about two years to

00:34:23.389 --> 00:34:25.830
write as it's sort of
set 15 years out.

00:34:25.830 --> 00:34:28.600
And trying to do near-future
SF like that is really hard

00:34:28.600 --> 00:34:30.660
these days, thanks to
people like you.

00:34:30.660 --> 00:34:32.110
[LAUGHTER]

00:34:32.110 --> 00:34:35.150
So I'm negotiating with my agent
to hand in a different--

00:34:35.150 --> 00:34:37.440
the fifth "Laundry"
novel instead.

00:34:37.440 --> 00:34:39.250
CORY DOCTOROW: But what are
you working on for Neal?

00:34:39.250 --> 00:34:41.360
For the "Hieroglyph" thing?

00:34:41.360 --> 00:34:43.190
CHARLES STROSS: I haven't even
confirmed I'm on that yet.

00:34:43.190 --> 00:34:48.330
I want to be, but I'm juggling
too many balls right now.

00:34:48.330 --> 00:34:49.176
CORY DOCTOROW: Seth.

00:34:49.176 --> 00:34:53.299
AUDIENCE: So did guys have
many parts of this?

00:34:53.299 --> 00:34:57.593
Like when you're collaborating
on a shared work like this,

00:34:57.593 --> 00:34:59.543
are there parts of it that
you had to give up?

00:35:02.580 --> 00:35:04.160
CORY DOCTOROW: Maybe not that we
wish we could've kept, but

00:35:04.160 --> 00:35:05.990
there's definitely big chunks
that got off-cut.

00:35:05.990 --> 00:35:08.190
CHARLES STROSS: Yeah, a lot of
arguing over whether something

00:35:08.190 --> 00:35:10.010
belonged in it and
then rewriting.

00:35:10.010 --> 00:35:11.340
CORY DOCTOROW: Yeah.

00:35:11.340 --> 00:35:15.740
There's nothing that I like more
and overmuch, but there's

00:35:15.740 --> 00:35:17.340
plenty of stuff on cutting-room
floor.

00:35:17.340 --> 00:35:18.350
CHARLES STROSS: I mean, think of
it as a kind of half-assed

00:35:18.350 --> 00:35:22.500
version of pair programming if
you emailing source files back

00:35:22.500 --> 00:35:25.970
and forth to each other and
working 400 miles apart rather

00:35:25.970 --> 00:35:27.380
than the same room.

00:35:27.380 --> 00:35:28.380
CORY DOCTOROW: Yeah.

00:35:28.380 --> 00:35:33.520
You know, I just read an early
edition of the new David Byrne

00:35:33.520 --> 00:35:36.660
book, "How Music Works." It's an
amazing book, and there's a

00:35:36.660 --> 00:35:39.230
section in it on how we
collaborated with Eno on

00:35:39.230 --> 00:35:41.230
"Everything That Happens Will
Happen Today," the album they

00:35:41.230 --> 00:35:43.090
did a couple of years ago.

00:35:43.090 --> 00:35:45.440
And Eno had actually written
all the melodies.

00:35:45.440 --> 00:35:47.680
And so he just-- they were sort
of sitting on his hard

00:35:47.680 --> 00:35:49.700
drive, and so he fired
them off to Byrne.

00:35:49.700 --> 00:35:51.370
And then Byrne figured
out the words.

00:35:51.370 --> 00:35:53.340
And he was like, I could go
back and ask for, like,

00:35:53.340 --> 00:35:55.990
melodic changes, but there's
kind of a hassle to that, so

00:35:55.990 --> 00:35:58.110
I'm just going to work with
this as a constraint.

00:35:58.110 --> 00:36:00.190
It's a pretty interesting
passage in a

00:36:00.190 --> 00:36:01.220
very, very good book.

00:36:01.220 --> 00:36:02.590
I heartily recommend it.

00:36:02.590 --> 00:36:04.270
It'll be out in about a week.

00:36:04.270 --> 00:36:06.670
I've got a review queued up on
Boing Boing that may remind

00:36:06.670 --> 00:36:08.410
you, if you read Boing Boing.

00:36:08.410 --> 00:36:09.826
Scott, you had a question.

00:36:09.826 --> 00:36:11.076
AUDIENCE: [INAUDIBLE]?

00:36:22.780 --> 00:36:25.270
CORY DOCTOROW: I mean, I think
it would have been bad form to

00:36:25.270 --> 00:36:26.830
do too much in one go.

00:36:26.830 --> 00:36:27.670
CHARLES STROSS: Yeah, but the
main thing was to keep

00:36:27.670 --> 00:36:29.520
momentum going so we
had to turn it

00:36:29.520 --> 00:36:30.990
around within 48 hours.

00:36:30.990 --> 00:36:35.090
And you know, 500 to 1,000 is
a reasonable day's polished

00:36:35.090 --> 00:36:36.280
output, especially when
you're trying to do

00:36:36.280 --> 00:36:37.490
something high concept.

00:36:37.490 --> 00:36:38.980
CORY DOCTOROW: And when you're
rewriting the stuff that came

00:36:38.980 --> 00:36:41.150
before, so you're taking a pass
through the piece that

00:36:41.150 --> 00:36:41.540
came before.

00:36:41.540 --> 00:36:43.410
CHARLES STROSS: I think the
longest chunk I mailed to Cory

00:36:43.410 --> 00:36:46.310
at one point was about 2,500
words, at a time when you were

00:36:46.310 --> 00:36:49.510
traveling and not able to work
on it for a couple of days.

00:36:49.510 --> 00:36:49.840
CORY DOCTOROW: Yeah.

00:36:49.840 --> 00:36:52.510
And you know, that's about how
I did it, I did that novella

00:36:52.510 --> 00:36:55.600
with Ben Rosenbaum, "True
Names," and that's about how

00:36:55.600 --> 00:36:56.720
we did that too.

00:36:56.720 --> 00:36:58.090
Although Ben--

00:36:58.090 --> 00:37:00.150
Ben likes to talk a lot about
what you're writing.

00:37:00.150 --> 00:37:02.490
He used to send me long, like,
so here's what I'm thinking.

00:37:02.490 --> 00:37:05.060
I don't know if you've ever met
Ben, or heard him talk.

00:37:05.060 --> 00:37:05.820
It comes through.

00:37:05.820 --> 00:37:06.980
It's like-- (FRANTICALLY) So
here's what I'm thinking.

00:37:06.980 --> 00:37:07.530
There's this thing.

00:37:07.530 --> 00:37:08.300
And there's another thing.

00:37:08.300 --> 00:37:08.880
And this other thing.

00:37:08.880 --> 00:37:09.310
And this other thing.

00:37:09.310 --> 00:37:10.310
And I'd be, like, yeah, Ben?

00:37:10.310 --> 00:37:11.210
Can we just write it?

00:37:11.210 --> 00:37:12.040
I know, I know.

00:37:12.040 --> 00:37:12.420
I know.

00:37:12.420 --> 00:37:15.070
And he was like, I overthinking
it again.

00:37:15.070 --> 00:37:17.930
We were a little more compatible
in that regard.

00:37:17.930 --> 00:37:18.840
There was less--

00:37:18.840 --> 00:37:22.035
less foreplay, more of
the important stuff.

00:37:22.035 --> 00:37:23.460
[LAUGHTER]

00:37:23.460 --> 00:37:24.500
CHARLES STROSS: I didn't
know you cared.

00:37:24.500 --> 00:37:25.110
CORY DOCTOROW: Yeah.

00:37:25.110 --> 00:37:27.996
[LAUGHTER]

00:37:27.996 --> 00:37:29.246
AUDIENCE: [INAUDIBLE]?

00:37:39.402 --> 00:37:40.670
CORY DOCTOROW: Would
Google Docs be more

00:37:40.670 --> 00:37:43.170
beneficial of less?

00:37:43.170 --> 00:37:44.570
CHARLES STROSS: This probably
isn't the right venue to

00:37:44.570 --> 00:37:46.990
confess that I hate, loathe,
and fear cloud computing

00:37:46.990 --> 00:37:48.260
systems but don't
actually have an

00:37:48.260 --> 00:37:50.330
in-my-pocket fall-back.

00:37:50.330 --> 00:37:53.050
The trouble of Google Docs for
this sort of thing, first,

00:37:53.050 --> 00:37:56.010
you'd be working on one long
continual scrolling text.

00:37:56.010 --> 00:37:58.370
And by the time you're up to
about 90,000 words, Google

00:37:58.370 --> 00:38:01.830
Docs is not terribly happy.

00:38:01.830 --> 00:38:05.373
The other aspect is it requires
you to be online with

00:38:05.373 --> 00:38:06.450
a good internet connection.

00:38:06.450 --> 00:38:08.840
And if you're traveling or you
live somewhere where the

00:38:08.840 --> 00:38:12.540
internet is up or down, that's
not so good either.

00:38:12.540 --> 00:38:14.990
CORY DOCTOROW: And in
particular, if those moments

00:38:14.990 --> 00:38:17.180
in which there's no network are
the moments that you're

00:38:17.180 --> 00:38:19.470
like, oh, wow, there's nothing
else that I can be doing right

00:38:19.470 --> 00:38:21.980
now, no high-priority items
that I can take care of

00:38:21.980 --> 00:38:23.860
because I've got network
access, now's the

00:38:23.860 --> 00:38:26.020
moment I can write.

00:38:26.020 --> 00:38:28.790
Then Google Docs is no
good to you at all.

00:38:28.790 --> 00:38:30.340
I've got the sequel to "Little
Brother" coming out in

00:38:30.340 --> 00:38:32.700
February, and I wrote big chunks
of that, I write that

00:38:32.700 --> 00:38:35.950
like 2,000 words a day, and
I did it while touring.

00:38:35.950 --> 00:38:37.770
And a lot of it while
touring Germany.

00:38:37.770 --> 00:38:40.310
So the German tour is
really interesting.

00:38:40.310 --> 00:38:43.710
I was touring a young adult
book, so I would go to schools

00:38:43.710 --> 00:38:44.620
with my translator.

00:38:44.620 --> 00:38:46.460
My translator would read for
half an hour, and then I'd

00:38:46.460 --> 00:38:47.775
read for half an hour,
because, you

00:38:47.775 --> 00:38:48.600
know, they're Europeans.

00:38:48.600 --> 00:38:50.050
They speak better English
than I do.

00:38:50.050 --> 00:38:54.030
And while my translator was
reading in German, I would

00:38:54.030 --> 00:38:56.990
have half an hour to sit there
on stage and write.

00:38:56.990 --> 00:39:01.170
And if I'd needed network
access, I would've been hosed.

00:39:01.170 --> 00:39:02.530
I never would have finished
that book.

00:39:05.470 --> 00:39:09.046
AUDIENCE: First of all, I loved
the reference to "I was

00:39:09.046 --> 00:39:10.870
an infinitely hot
and dense dot."

00:39:10.870 --> 00:39:11.140
CORY DOCTOROW: Yeah.

00:39:11.140 --> 00:39:11.740
Mark Leyner.

00:39:11.740 --> 00:39:12.206
AUDIENCE: Yeah.

00:39:12.206 --> 00:39:14.846
That was really my introduction,
in a lot of

00:39:14.846 --> 00:39:18.270
ways, to [INAUDIBLE].

00:39:18.270 --> 00:39:23.198
But the other thing I was going
to ask is I was actually

00:39:23.198 --> 00:39:27.086
introduced to your writing
by Paul Krugman's blogs.

00:39:27.086 --> 00:39:28.960
And I was just wondering
if you--

00:39:28.960 --> 00:39:31.672
he's never mentioned meeting
you, that I've read, but I was

00:39:31.672 --> 00:39:32.480
just wondering--

00:39:32.480 --> 00:39:34.260
CHARLES STROSS: Oh,
yeah, we have met.

00:39:34.260 --> 00:39:37.000
It was at the World Science
Fiction Convention about three

00:39:37.000 --> 00:39:39.410
years ago in Montreal, where
they sort of arranged to put

00:39:39.410 --> 00:39:40.260
us on stage.

00:39:40.260 --> 00:39:42.630
And it's the second most
terrifying thing I've ever

00:39:42.630 --> 00:39:46.050
done on stage, is go up on stage
in front of 1,000 people

00:39:46.050 --> 00:39:49.140
and cameras with Paul
Krugman and try not

00:39:49.140 --> 00:39:52.320
to look like a fool.

00:39:52.320 --> 00:39:53.090
CORY DOCTOROW: It's on YouTube.

00:39:53.090 --> 00:39:53.450
[LAUGHTER]

00:39:53.450 --> 00:39:54.500
CHARLES STROSS: Note,
I say the second

00:39:54.500 --> 00:39:55.600
most terrifying thing.

00:39:55.600 --> 00:39:56.780
[LAUGHTER]

00:39:56.780 --> 00:39:59.830
CHARLES STROSS: To give you
something but exceeds that for

00:39:59.830 --> 00:40:03.220
sheer blind terror was a event
about 15 years ago, when I

00:40:03.220 --> 00:40:06.310
went on stage while a guy who
was into medieval longsword

00:40:06.310 --> 00:40:08.680
reenactment demonstrated
killing strokes with a

00:40:08.680 --> 00:40:10.420
broadsword, using
me as a model.

00:40:10.420 --> 00:40:11.640
[LAUGHTER]

00:40:11.640 --> 00:40:13.580
CHARLES STROSS: And what I knew
and the audience didn't

00:40:13.580 --> 00:40:16.460
know was that this guy had
macular degeneration and was

00:40:16.460 --> 00:40:17.440
registered blind.

00:40:17.440 --> 00:40:19.533
He only had 2% of his
visual field left.

00:40:19.533 --> 00:40:21.630
[LAUGHTER]

00:40:21.630 --> 00:40:23.380
CORY DOCTOROW: Wow.

00:40:23.380 --> 00:40:24.730
CHARLES STROSS: Going up with
Paul Krugman was sort of the

00:40:24.730 --> 00:40:25.590
intellectual equivalent.

00:40:25.590 --> 00:40:28.070
[LAUGHTER]

00:40:28.070 --> 00:40:29.440
CORY DOCTOROW: Are you
think Paul's blind?

00:40:29.440 --> 00:40:30.890
CHARLES STROSS: No, I'm saying
he's the equivalent of the

00:40:30.890 --> 00:40:32.500
sort of blind sensei.

00:40:32.500 --> 00:40:34.380
CORY DOCTOROW: Oh
right, I see.

00:40:34.380 --> 00:40:35.450
CHARLES STROSS: Doing something
that should be

00:40:35.450 --> 00:40:36.400
impossible.

00:40:36.400 --> 00:40:38.323
CORY DOCTOROW: In the back.

00:40:38.323 --> 00:40:40.960
AUDIENCE: First of all, thank
you both for your blogs and

00:40:40.960 --> 00:40:42.210
[INAUDIBLE].

00:40:48.830 --> 00:40:51.548
But I wanted to ask you
both [INAUDIBLE].

00:40:55.480 --> 00:41:00.172
Ray Kurzweil, the debate I've
heard about him is whether he

00:41:00.172 --> 00:41:02.362
is scientifically grounded with
a very strong speculative

00:41:02.362 --> 00:41:05.874
component, or basically
speculative fiction marketing

00:41:05.874 --> 00:41:08.450
itself as scientifically
grounded.

00:41:08.450 --> 00:41:11.530
I've heard the science
perspective on that, but if

00:41:11.530 --> 00:41:13.320
two authors in speculative
[INAUDIBLE].

00:41:13.320 --> 00:41:15.634
I'm curious what sort of
perspective you have

00:41:15.634 --> 00:41:19.071
[INAUDIBLE], especially in the
context of this novel.

00:41:19.071 --> 00:41:22.470
CHARLES STROSS: Um, I just got a
real strong sense of deja vu

00:41:22.470 --> 00:41:25.560
when I read some of his books,
because I'd seen the stuff 10

00:41:25.560 --> 00:41:28.690
years earlier on the Extropians
mailing list.

00:41:28.690 --> 00:41:30.110
I should say no more.

00:41:30.110 --> 00:41:34.510
CORY DOCTOROW: Well, I mean, I
interviewed Ray for "Asimov's

00:41:34.510 --> 00:41:36.080
Science Fiction Magazine."
It's online.

00:41:36.080 --> 00:41:39.670
And you know, the summary of
kind of where I netted out

00:41:39.670 --> 00:41:45.560
with this is that there's an
underlying question that Ray

00:41:45.560 --> 00:41:49.130
treats as kind of one on which
there is broad consensus, that

00:41:49.130 --> 00:41:51.460
in fact we don't have any broad
consensus on, and that's

00:41:51.460 --> 00:41:52.640
the locus of identity.

00:41:52.640 --> 00:41:54.390
Not the locus of consciousness,
but the locus

00:41:54.390 --> 00:41:55.330
of identity.

00:41:55.330 --> 00:41:59.720
So imagine that you uploaded
a copy of yourself.

00:41:59.720 --> 00:42:01.750
And you wanted to, like--

00:42:01.750 --> 00:42:02.360
what's the command?

00:42:02.360 --> 00:42:05.420
Tar -t, or whatever, to
verify the archive?

00:42:05.420 --> 00:42:07.150
You wanted to verify your
archive, right?

00:42:07.150 --> 00:42:09.630
So one way to do that is you
could do a Turing test.

00:42:09.630 --> 00:42:12.030
So two Chinese rooms--

00:42:12.030 --> 00:42:14.700
you're in one, the uploaded
you is in the other, and

00:42:14.700 --> 00:42:15.515
someone gives you stimulus.

00:42:15.515 --> 00:42:19.660
They ask you questions, and if
the questions line up, you

00:42:19.660 --> 00:42:22.340
know, the answers line up, the
same identical response to

00:42:22.340 --> 00:42:25.570
stimulus, we'd say, OK,
it's the same person.

00:42:25.570 --> 00:42:28.260
But there's a problem with that,
which is that if I took

00:42:28.260 --> 00:42:32.490
you five years ago and stuck
you in a room and then took

00:42:32.490 --> 00:42:35.440
you today, you wouldn't
give the same answers.

00:42:35.440 --> 00:42:39.540
So there's a kind of
reductionist story, there's a

00:42:39.540 --> 00:42:42.350
kind of Socratic dialogue that
takes place in the Singularity

00:42:42.350 --> 00:42:46.380
literature, in which you have
someone who's a skeptic and

00:42:46.380 --> 00:42:48.630
someone who's a guru
or a believer.

00:42:48.630 --> 00:42:51.370
And the skeptic says, if you
upload me into a computer, I

00:42:51.370 --> 00:42:52.520
will no longer be me.

00:42:52.520 --> 00:42:54.940
And the guru leads them through
this dialogue where

00:42:54.940 --> 00:42:57.580
they say, well, what if I
replaced one of your legs with

00:42:57.580 --> 00:42:59.560
a robot leg, would
you still be you?

00:42:59.560 --> 00:43:01.590
And the person says, why, of
course I'd still be me.

00:43:01.590 --> 00:43:03.540
And what if we moved it one
inch higher, right?

00:43:03.540 --> 00:43:05.540
And you just keep going till
you get to the brain stem.

00:43:05.540 --> 00:43:07.770
And then you go, well, at what
point do you cease to be you?

00:43:07.770 --> 00:43:09.240
Or you can do it in the other
direction, right?

00:43:09.240 --> 00:43:11.930
Your pupil is the end of your
optic nerve, so you can see--

00:43:11.930 --> 00:43:13.870
just like your teeth are the
end of your skeleton.

00:43:13.870 --> 00:43:14.050
Right?

00:43:14.050 --> 00:43:16.600
So if I took that part of your
brain right there that we can

00:43:16.600 --> 00:43:18.420
all see and I replaced that
with a microchip--

00:43:18.420 --> 00:43:22.920
as there's already CCDs that
people hook up to optic nerves

00:43:22.920 --> 00:43:25.820
and experiment in a medical
context-- are you still you?

00:43:25.820 --> 00:43:27.450
Part of your brain
is now a machine.

00:43:27.450 --> 00:43:30.030
And you just go millimeter by
millimeter back, again, until

00:43:30.030 --> 00:43:31.610
you reach the brain stem, and
you say, at what point do you

00:43:31.610 --> 00:43:32.700
cease to be you?

00:43:32.700 --> 00:43:35.070
And that sounds plausible.

00:43:35.070 --> 00:43:36.570
It's a nice word game to play.

00:43:36.570 --> 00:43:39.580
But actually, if you were a
concert pianist and I cut your

00:43:39.580 --> 00:43:41.330
hands off and replace them
with robot hands,

00:43:41.330 --> 00:43:42.680
you wouldn't be you.

00:43:42.680 --> 00:43:42.830
Right?

00:43:42.830 --> 00:43:46.540
If I put you prior to this gross
insult to your anatomy

00:43:46.540 --> 00:43:50.370
and you afterwards in Chinese
rooms and ask you questions,

00:43:50.370 --> 00:43:51.630
you wouldn't be you.

00:43:51.630 --> 00:43:55.610
And I've come to think that
although we exist in a

00:43:55.610 --> 00:44:00.270
continuum of identity, from
moment to moment the answers,

00:44:00.270 --> 00:44:02.040
the difference between the
answers that we would give in

00:44:02.040 --> 00:44:05.580
the Chinese room experiment are
near enough to identical

00:44:05.580 --> 00:44:09.840
as makes no never-mind, that
across certain distances or

00:44:09.840 --> 00:44:12.480
across certain singularities,
across certain punctuated

00:44:12.480 --> 00:44:14.190
events, those answers change.

00:44:14.190 --> 00:44:18.120
In the same way that all of the
stages between Latin and

00:44:18.120 --> 00:44:20.160
French are mutually
intelligible, but Latin and

00:44:20.160 --> 00:44:21.910
French are not mutually
intelligible.

00:44:21.910 --> 00:44:25.050
Or all of the intermediate
stages between speciation in

00:44:25.050 --> 00:44:28.990
two finches are mutually
compatible, but once you're

00:44:28.990 --> 00:44:31.400
fully speciated, by definition,
you're no longer

00:44:31.400 --> 00:44:32.360
compatible.

00:44:32.360 --> 00:44:38.070
And that because we can't agree
on who I am and who you

00:44:38.070 --> 00:44:40.560
are and where the locus of
identity is-- because we've

00:44:40.560 --> 00:44:41.710
never had to answer
the question.

00:44:41.710 --> 00:44:44.130
Because we've never had a
meaningful way to say, well,

00:44:44.130 --> 00:44:47.000
here's two of you, which
one is the real one?

00:44:47.000 --> 00:44:49.560
That because we can't do that,
that there's this enormous

00:44:49.560 --> 00:44:54.180
question that we elide when
we talk about uploading.

00:44:54.180 --> 00:44:56.980
This is an important question
in the Kurzweilian sense.

00:44:56.980 --> 00:44:58.710
Maybe not in the
Vingean sense.

00:44:58.710 --> 00:45:01.260
"Are you still you once you're
in the computer?" is a

00:45:01.260 --> 00:45:03.850
question that matters
a lot to you.

00:45:03.850 --> 00:45:04.090
Right?

00:45:04.090 --> 00:45:06.740
It may not matter a lot to the
Singularity, but it matters an

00:45:06.740 --> 00:45:08.050
awful lot to you.

00:45:08.050 --> 00:45:12.010
And if we can't even agree on
what "you" means, then I think

00:45:12.010 --> 00:45:14.080
we have a hard time answering
that question.

00:45:14.080 --> 00:45:20.370
And I think that little cheap
Socratic dialogue is a trick

00:45:20.370 --> 00:45:23.920
that is used to misdirect us,
deliberately or otherwise,

00:45:23.920 --> 00:45:25.430
from a pretty important
existential

00:45:25.430 --> 00:45:27.330
problem that's new.

00:45:27.330 --> 00:45:29.830
Or at least new in the
sense that it may be

00:45:29.830 --> 00:45:32.340
non-hypothetical in
the near future.

00:45:32.340 --> 00:45:35.120
And that newness is something
that we have yet to come to

00:45:35.120 --> 00:45:35.930
grips with.

00:45:35.930 --> 00:45:38.040
CORY DOCTOROW: On the other
hand, I will add that it is an

00:45:38.040 --> 00:45:40.240
interestingly constrained
question, because it is one

00:45:40.240 --> 00:45:42.940
that is subject to empirical
experimentation.

00:45:42.940 --> 00:45:43.330
CORY DOCTOROW: Mmhm.

00:45:43.330 --> 00:45:45.400
Sure.

00:45:45.400 --> 00:45:46.760
CHARLES STROSS: Although I
wouldn't recommend starting

00:45:46.760 --> 00:45:48.410
with human volunteers.

00:45:48.410 --> 00:45:51.960
Take something like lobsters.

00:45:51.960 --> 00:45:52.860
CORY DOCTOROW: Charlie
has written

00:45:52.860 --> 00:45:54.060
about uploaded lobsters.

00:45:54.060 --> 00:45:55.190
Yeah?

00:45:55.190 --> 00:45:59.790
AUDIENCE: So this thing about
uploading yourself,

00:45:59.790 --> 00:46:01.740
and is it still you?

00:46:01.740 --> 00:46:08.130
We can have a much smaller
version of the argument.

00:46:08.130 --> 00:46:10.470
People who change their
hairstyle and say, oh, this is

00:46:10.470 --> 00:46:12.030
the new me.

00:46:12.030 --> 00:46:15.670
Just that very statement, that
by changing your hairstyle,

00:46:15.670 --> 00:46:18.285
you become a new you, should
really give us the answer of

00:46:18.285 --> 00:46:21.110
what happens when you
upload yourself.

00:46:21.110 --> 00:46:22.960
CORY DOCTOROW: Well, you could
change nothing, and someone

00:46:22.960 --> 00:46:25.430
could fly an airplane into a
building in your hometown, and

00:46:25.430 --> 00:46:27.450
you would still-- and you would
probably be a different

00:46:27.450 --> 00:46:28.780
person, too, right?

00:46:28.780 --> 00:46:31.780
CHARLES STROSS: Let me ask a
different variant on it.

00:46:31.780 --> 00:46:33.110
Here's a tablet.

00:46:33.110 --> 00:46:34.510
Is this tablet part of me?

00:46:34.510 --> 00:46:36.020
Obviously not.

00:46:36.020 --> 00:46:42.140
OK, take into account the
combination of programs,

00:46:42.140 --> 00:46:45.960
configuration, and data loaded
onto it, including chunks

00:46:45.960 --> 00:46:48.350
which definitely came out of my
mind which are part of my

00:46:48.350 --> 00:46:49.740
extended phenotype.

00:46:49.740 --> 00:46:51.070
Is it part of me?

00:46:51.070 --> 00:46:56.010
This is the argument on, are
tools part of identity?

00:46:56.010 --> 00:46:57.210
We relate to them as if they're

00:46:57.210 --> 00:46:59.880
extensions of our body.

00:46:59.880 --> 00:47:01.390
Or are they separate?

00:47:01.390 --> 00:47:03.850
It's sort of reverse of
the amputation and

00:47:03.850 --> 00:47:05.750
artificial leg question.

00:47:05.750 --> 00:47:05.910
CORY DOCTOROW: Mmhm.

00:47:05.910 --> 00:47:06.320
Sure.

00:47:06.320 --> 00:47:09.060
I mean, if you've got 100 times
more non-human cells in

00:47:09.060 --> 00:47:11.190
your body, symbiotes, than
you have human cells--

00:47:11.190 --> 00:47:11.980
which you do--

00:47:11.980 --> 00:47:14.100
and if you remove them, you
would die-- which you would--

00:47:14.100 --> 00:47:16.000
then who are you?

00:47:16.000 --> 00:47:18.230
Are you a colony organism
that just thinks that

00:47:18.230 --> 00:47:19.440
it's a single entity?

00:47:19.440 --> 00:47:27.350
Or are you a ship on which
many passengers, that are

00:47:27.350 --> 00:47:30.640
nevertheless somehow under
your volitional control,

00:47:30.640 --> 00:47:31.530
hitch a ride on?

00:47:31.530 --> 00:47:34.250
I mean, I think that these are
really important, weird

00:47:34.250 --> 00:47:35.490
questions that we haven't
quite answered.

00:47:35.490 --> 00:47:35.980
CHARLES STROSS: Oh.

00:47:35.980 --> 00:47:36.580
Another version.

00:47:36.580 --> 00:47:38.150
Life-logging.

00:47:38.150 --> 00:47:40.380
I assume everybody's more or
less familiar with the idea of

00:47:40.380 --> 00:47:41.230
life-logging.

00:47:41.230 --> 00:47:46.020
You carry video cameras, mics,
GPS, other data recorders

00:47:46.020 --> 00:47:47.400
around with you-- blood
pressure monitors--

00:47:47.400 --> 00:47:48.660
CORY DOCTOROW: Compromised
mobile phones.

00:47:48.660 --> 00:47:49.100
CHARLES STROSS: Yep.

00:47:49.100 --> 00:47:51.230
Internal biological monitors.

00:47:51.230 --> 00:47:52.510
You record everything.

00:47:52.510 --> 00:47:55.140
You tag everything.

00:47:55.140 --> 00:47:58.200
We have reasonable
speech-to-text.

00:47:58.200 --> 00:48:03.530
We have reasonable recognition
of objects in the real world.

00:48:03.530 --> 00:48:05.740
I mean, you guys here have been
part of a company that's

00:48:05.740 --> 00:48:07.155
developed a lot of that stuff.

00:48:07.155 --> 00:48:07.530
OK.

00:48:07.530 --> 00:48:10.870
Imagine everything around me is
logged and tagged for the

00:48:10.870 --> 00:48:12.160
whole of my life.

00:48:12.160 --> 00:48:14.430
But you can then ask it
questions, such as, who was

00:48:14.430 --> 00:48:17.390
having lunch with in such and
such a city on Tuesday

00:48:17.390 --> 00:48:20.060
the 2nd last year?

00:48:20.060 --> 00:48:21.560
And get answers back.

00:48:21.560 --> 00:48:26.370
If you then couple that with
an avatar generated from

00:48:26.370 --> 00:48:32.600
recordings of me, and some sort
of model that has via a

00:48:32.600 --> 00:48:34.650
genetic algorithm been evolved
to try and give the same

00:48:34.650 --> 00:48:38.420
responses as me, you then
have a artificial

00:48:38.420 --> 00:48:39.700
representative of me.

00:48:39.700 --> 00:48:40.430
An avatar.

00:48:40.430 --> 00:48:42.890
Now suppose somebody
shoots me.

00:48:42.890 --> 00:48:44.410
Is the avatar part of me?

00:48:44.410 --> 00:48:46.220
Is it me?

00:48:46.220 --> 00:48:47.520
One argument is no.

00:48:47.520 --> 00:48:50.280
Another argument is well,
it's a component of

00:48:50.280 --> 00:48:52.190
your extended identity.

00:48:52.190 --> 00:48:53.230
It's what's left over.

00:48:53.230 --> 00:48:54.900
CORY DOCTOROW: In the same way
that all the stuff in your

00:48:54.900 --> 00:48:55.990
hard drive is, too.

00:48:55.990 --> 00:48:58.250
Or this was a big question
when AOL did

00:48:58.250 --> 00:48:59.660
that search term dump.

00:48:59.660 --> 00:49:02.850
Your search queries
are an enormously

00:49:02.850 --> 00:49:04.720
personal part of you.

00:49:04.720 --> 00:49:05.780
I just--

00:49:05.780 --> 00:49:07.850
I don't know if anyone any of
you saw, if you read Boing

00:49:07.850 --> 00:49:11.270
Boing, I wrote it an obit for a
good friend of mine in June.

00:49:11.270 --> 00:49:14.130
He was a hacker, free software
guy who was my age.

00:49:14.130 --> 00:49:15.820
Died in his sleep totally
randomly.

00:49:15.820 --> 00:49:18.510
He was a vegetarian who did
yoga and rode a bicycle

00:49:18.510 --> 00:49:19.910
everywhere but had a cerebral
hemorrhage.

00:49:19.910 --> 00:49:23.420
It was like, you just multiply
all the blood vessels in your

00:49:23.420 --> 00:49:25.275
body by the number of heartbeats
you have and divide

00:49:25.275 --> 00:49:27.660
it by the failure rate, and at
a certain point, some of you

00:49:27.660 --> 00:49:29.210
will have brain hemorrhages.

00:49:29.210 --> 00:49:32.040
So his family, not very
technical, didn't know what to

00:49:32.040 --> 00:49:33.210
do with his computer.

00:49:33.210 --> 00:49:38.020
It was on when he died, logged
in to his [INAUDIBLE] machine.

00:49:38.020 --> 00:49:40.600
And they were just going to turn
it off and stick it in a

00:49:40.600 --> 00:49:42.150
box until they could
figure it out.

00:49:42.150 --> 00:49:44.480
And I was like, you know, if you
do that, you'll lose it.

00:49:44.480 --> 00:49:46.200
The platters will seize up.

00:49:46.200 --> 00:49:48.240
The computer-- you'll get
burgled and it'll get stolen.

00:49:48.240 --> 00:49:49.220
It'll get shorted out.

00:49:49.220 --> 00:49:50.250
It'll get wet.

00:49:50.250 --> 00:49:51.310
And this is him, right?

00:49:51.310 --> 00:49:54.070
This is everything, all the
software he's written,

00:49:54.070 --> 00:49:57.180
everything he's done since he
was about 14 years old, copied

00:49:57.180 --> 00:49:58.140
over and over and over.

00:49:58.140 --> 00:50:00.840
And I went with a hard
drive over to

00:50:00.840 --> 00:50:02.210
the commune he founded--

00:50:02.210 --> 00:50:04.680
he lived in a kind of anarchist
commune in Toronto--

00:50:04.680 --> 00:50:10.450
and copied off terabyte of his
data, which was mostly nested

00:50:10.450 --> 00:50:14.370
backups of his old data, which
like many of us, he hadn't

00:50:14.370 --> 00:50:16.950
really thought this through, and
didn't really plan on what

00:50:16.950 --> 00:50:19.570
people would do with his
data after he was dead.

00:50:19.570 --> 00:50:24.250
But yes, by the time I watched
our sync copy the 10 millionth

00:50:24.250 --> 00:50:28.670
copy of Python, I was like, I
probably should have de-duped

00:50:28.670 --> 00:50:29.910
this before I started.

00:50:29.910 --> 00:50:33.340
But in any event, I stuck it
on S3 and paid for 10 years

00:50:33.340 --> 00:50:35.540
storage so they could figure out
what to do it in 10 years.

00:50:35.540 --> 00:50:37.710
But this really was
part of him.

00:50:37.710 --> 00:50:40.430
And I think we haven't come
to grips at all with

00:50:40.430 --> 00:50:41.290
what to do with that.

00:50:41.290 --> 00:50:45.950
And I think we're already kind
of symbolically starting to

00:50:45.950 --> 00:50:48.530
deal with what to do with
backups of people, because

00:50:48.530 --> 00:50:50.220
there's an enormous amount
of personal information.

00:50:50.220 --> 00:50:52.130
Charlie, you were saying
the other day that--

00:50:52.130 --> 00:50:52.850
what was the year?

00:50:52.850 --> 00:50:54.020
2050?

00:50:54.020 --> 00:50:55.510
CHARLES STROSS: Around--
yeah, some estimates.

00:50:55.510 --> 00:50:59.880
Around 2050, whatever social
networks are still running, we

00:50:59.880 --> 00:51:03.920
can expect internet adoption to
have penetrated the entire

00:51:03.920 --> 00:51:06.610
population of Earth who are
functionally literate, and

00:51:06.610 --> 00:51:09.900
even some who aren't, around
2050, which is the flip-over

00:51:09.900 --> 00:51:12.180
point at which more people
on the internet will

00:51:12.180 --> 00:51:14.880
be dead than alive.

00:51:14.880 --> 00:51:17.410
Because by then, the internet
will have been around for, in

00:51:17.410 --> 00:51:21.470
one form or another, about 80
years and will have hit

00:51:21.470 --> 00:51:23.110
serious take-off 50
years earlier.

00:51:23.110 --> 00:51:25.170
A lot of people will have been
on there and will have died.

00:51:25.170 --> 00:51:29.290
I mean, I would like to think
I'll be alive in 2050, but I'm

00:51:29.290 --> 00:51:32.030
not optimistic, because
I would be 86.

00:51:32.030 --> 00:51:33.430
CORY DOCTOROW: If any of you
want to quit your job and do a

00:51:33.430 --> 00:51:35.400
start-up, I've got
a great idea.

00:51:35.400 --> 00:51:36.110
Not that I'm going to start--

00:51:36.110 --> 00:51:37.835
I'm going to write about it for
"The Guardian" this week

00:51:37.835 --> 00:51:38.650
because I owe them a column.

00:51:38.650 --> 00:51:43.120
But basically the idea is that
you just deploy an army of biz

00:51:43.120 --> 00:51:46.350
dev people in, like, sailcloth
blue suits and khakis to go

00:51:46.350 --> 00:51:49.260
around and do deals with all
the major social networks--

00:51:49.260 --> 00:51:51.130
Facebook and Google
and so on--

00:51:51.130 --> 00:51:54.380
to authenticate that someone
is dead and that there is

00:51:54.380 --> 00:51:57.310
someone who is empowered
to receive their login

00:51:57.310 --> 00:51:58.240
credentials.

00:51:58.240 --> 00:52:00.950
And then you sell it to
funeral directors.

00:52:00.950 --> 00:52:02.910
And so you come and you're,
like, oh, I'm grieving, I

00:52:02.910 --> 00:52:03.550
don't know what to do.

00:52:03.550 --> 00:52:05.480
And as they're trying to upsell
you on a giant, tacky

00:52:05.480 --> 00:52:10.100
aluminum coffin, they're also
saying, by the way, we have a

00:52:10.100 --> 00:52:11.130
service that we work with.

00:52:11.130 --> 00:52:14.140
They're very good, and they will
make sure that your loved

00:52:14.140 --> 00:52:16.810
one's Facebook, Gmail, and so
on, all those credentials, are

00:52:16.810 --> 00:52:18.660
turned over to you so
you can manage them.

00:52:18.660 --> 00:52:20.350
We deal with all the
CAs and so on.

00:52:20.350 --> 00:52:21.750
It's a single point
of contact.

00:52:21.750 --> 00:52:24.280
And they'll just turn over the
credentials to you on a

00:52:24.280 --> 00:52:25.590
certified basis.

00:52:25.590 --> 00:52:29.260
I think it would be
a big business.

00:52:29.260 --> 00:52:30.470
AUDIENCE: [INAUDIBLE].

00:52:30.470 --> 00:52:31.846
CORY DOCTOROW: Really?

00:52:31.846 --> 00:52:33.760
AUDIENCE: I've seen
[INAUDIBLE].

00:52:33.760 --> 00:52:34.480
CORY DOCTOROW: With--?

00:52:34.480 --> 00:52:35.440
AUDIENCE: I don't
remember where.

00:52:35.440 --> 00:52:37.430
CORY DOCTOROW: There are ones
that will set up a memorial to

00:52:37.430 --> 00:52:41.740
export your Facebook, but
there's no one, as far as I

00:52:41.740 --> 00:52:42.920
know, who will ease--

00:52:42.920 --> 00:52:44.528
AUDIENCE: [INAUDIBLE].

00:52:44.528 --> 00:52:46.560
CORY DOCTOROW: Yeah, but there's
no one who can do the

00:52:46.560 --> 00:52:47.820
authentication credentials.

00:52:47.820 --> 00:52:48.860
That's the hard part, right?

00:52:48.860 --> 00:52:53.740
It's to like, convince Yahoo or
Google or Facebook to hand

00:52:53.740 --> 00:52:55.740
over auth credentials
to someone.

00:52:55.740 --> 00:52:58.555
And that's the part that's like
logistically intensive

00:52:58.555 --> 00:53:00.810
and relationship-intensive.

00:53:00.810 --> 00:53:02.690
Yeah, there are tons of
companies that'll do an online

00:53:02.690 --> 00:53:04.230
memorial, where you can
export the Facebook

00:53:04.230 --> 00:53:05.090
data and get it in.

00:53:05.090 --> 00:53:07.580
But you need to have the login
credentials to do it.

00:53:07.580 --> 00:53:10.140
So unless you know how to log
into that person's account,

00:53:10.140 --> 00:53:11.390
then you're hosed.

00:53:14.200 --> 00:53:15.450
AUDIENCE: [INAUDIBLE].

00:53:22.810 --> 00:53:23.750
CORY DOCTOROW: For not dying.

00:53:23.750 --> 00:53:24.573
Yeah.

00:53:24.573 --> 00:53:26.465
[LAUGHTER]

00:53:26.465 --> 00:53:28.357
CORY DOCTOROW: Yeah.

00:53:28.357 --> 00:53:31.195
Yeah, Sam?

00:53:31.195 --> 00:53:34.252
AUDIENCE: So I've always noticed
that in singularity

00:53:34.252 --> 00:53:37.890
and sort of uploader culture,
it's never mentioned who

00:53:37.890 --> 00:53:40.786
administers the systems
that run it.

00:53:40.786 --> 00:53:42.094
[LAUGHTER]

00:53:42.094 --> 00:53:44.574
AUDIENCE: You want to get a
Singularity [INAUDIBLE] now?

00:53:44.574 --> 00:53:47.044
[LAUGHTER]

00:53:47.044 --> 00:53:48.526
AUDIENCE: I am [INAUDIBLE],
yeah.

00:53:48.526 --> 00:53:52.610
I think, if we're the people
who are probably more

00:53:52.610 --> 00:53:54.640
interested in uploading,
but who are we gonna

00:53:54.640 --> 00:53:55.690
trust to run us?

00:53:55.690 --> 00:53:56.310
AUDIENCE: Google.

00:53:56.310 --> 00:53:58.120
CHARLES STROSS: Actually,
there's one novel I can think

00:53:58.120 --> 00:53:59.700
of where the novelist
in question tackled

00:53:59.700 --> 00:54:01.170
that question head-on--

00:54:01.170 --> 00:54:05.010
Iain M. Banks in "Surface
Detail." And you probably

00:54:05.010 --> 00:54:05.860
won't like the answer.

00:54:05.860 --> 00:54:07.340
[LAUGHTER]

00:54:07.340 --> 00:54:08.950
CORY DOCTOROW: You know, we
kind of tackle it in this.

00:54:08.950 --> 00:54:12.200
I mean, for one thing, we have
a whole group of people who

00:54:12.200 --> 00:54:15.760
are uploaded and kind
of LARP bureaucracy.

00:54:15.760 --> 00:54:19.070
They feel like you need a
bureaucracy, and so they go to

00:54:19.070 --> 00:54:20.120
work and they do boring work.

00:54:20.120 --> 00:54:21.860
Even though it's all automated,
they feel like

00:54:21.860 --> 00:54:22.610
someone needs to do it.

00:54:22.610 --> 00:54:25.040
They're called the
World Gov LARP.

00:54:25.040 --> 00:54:27.050
CHARLES STROSS: And the clothing
for their LARP is

00:54:27.050 --> 00:54:27.880
really boring.

00:54:27.880 --> 00:54:28.720
CORY DOCTOROW: Yeah.

00:54:28.720 --> 00:54:29.330
Yeah.

00:54:29.330 --> 00:54:33.640
And we do actually, we do have
some self-governed systems

00:54:33.640 --> 00:54:35.860
that run Capabilities
environment.

00:54:35.860 --> 00:54:39.790
So there's a Capabilities bar
where you can't get into a

00:54:39.790 --> 00:54:41.920
fight unless the other person
allows you to fight with them,

00:54:41.920 --> 00:54:43.770
and then you have a contract
that allows you to fight.

00:54:43.770 --> 00:54:46.150
And there's things like, you
could be diffed back if you

00:54:46.150 --> 00:54:47.750
violate the contract and so on.

00:54:47.750 --> 00:54:48.650
It's--

00:54:48.650 --> 00:54:52.030
it's a pretty fun bar.

00:54:52.030 --> 00:54:54.670
AUDIENCE: "Permutation City,"
I think, has a pretty

00:54:54.670 --> 00:54:57.040
interesting take on it,
that essentially it

00:54:57.040 --> 00:54:59.318
doesn't require hardware.

00:54:59.318 --> 00:55:03.947
But that also has some really
good tips about what it would

00:55:03.947 --> 00:55:05.270
be like to be [INAUDIBLE].

00:55:05.270 --> 00:55:06.270
CORY DOCTOROW: Yeah.

00:55:06.270 --> 00:55:08.340
CHARLES STROSS: But bear in
mind, Greg Egan has sort of

00:55:08.340 --> 00:55:12.050
recanted fairly valiantly
against the approach to AI via

00:55:12.050 --> 00:55:15.050
genetic algorithms he was
pitching in that novel.

00:55:15.050 --> 00:55:16.180
Doesn't like it anymore.

00:55:16.180 --> 00:55:17.590
Has ethical qualms.

00:55:17.590 --> 00:55:18.190
Over--

00:55:18.190 --> 00:55:18.610
CORY DOCTOROW: I'm sorry.

00:55:18.610 --> 00:55:19.890
PRESENTER: That's all
we have time for.

00:55:19.890 --> 00:55:20.330
I'm sorry.

00:55:20.330 --> 00:55:22.120
CORY DOCTOROW: Oh, we did have
someone who hadn't asked a

00:55:22.120 --> 00:55:23.365
question at all.

00:55:23.365 --> 00:55:24.550
PRESENTER: Uh, oh, OK.

00:55:24.550 --> 00:55:25.452
CORY DOCTOROW: Just
one quick one?

00:55:25.452 --> 00:55:26.868
[LAUGHTER]

00:55:26.868 --> 00:55:29.480
AUDIENCE: Uh, so the worlds you
write about and the worlds

00:55:29.480 --> 00:55:32.840
you live in are a little bit
different, today, at least.

00:55:32.840 --> 00:55:34.276
How do you stay creative?

00:55:34.276 --> 00:55:35.925
How do you generate
these ideas?

00:55:35.925 --> 00:55:36.740
Do you have a process?

00:55:36.740 --> 00:55:38.670
CORY DOCTOROW: There's a post
office box in Schenectady.

00:55:38.670 --> 00:55:40.380
You send a self-addressed
stamped envelope and they send

00:55:40.380 --> 00:55:41.580
you back science
fiction ideas.

00:55:41.580 --> 00:55:42.490
[LAUGHTER]

00:55:42.490 --> 00:55:42.880
CHARLES STROSS: There's--

00:55:42.880 --> 00:55:45.320
actually, in my case, there's
a little closet in the

00:55:45.320 --> 00:55:47.560
basement of the MIT Media Lab,
and I have to report there for

00:55:47.560 --> 00:55:48.850
reprogramming every two years.

00:55:48.850 --> 00:55:49.110
[LAUGHTER]

00:55:49.110 --> 00:55:50.490
CORY DOCTOROW: That's the one
Aaron Swartz got busted for

00:55:50.490 --> 00:55:51.470
sneaking into.

00:55:51.470 --> 00:55:52.065
No.

00:55:52.065 --> 00:55:53.190
It's the 21st century.

00:55:53.190 --> 00:55:55.110
If you can't come up with cool
science fiction ideas before

00:55:55.110 --> 00:55:56.860
breakfast, you're not paying
attention, you know?

00:55:56.860 --> 00:55:58.660
[LAUGHTER]

00:55:58.660 --> 00:56:04.797
[APPLAUSE]

