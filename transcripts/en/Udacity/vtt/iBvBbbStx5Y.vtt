WEBVTT
Kind: captions
Language: en

00:00:00.350 --> 00:00:02.040
&gt;&gt; So, we've got a whole bunch of trees we have

00:00:02.040 --> 00:00:04.100
to look at, Michael. And were going to have to come up with

00:00:04.100 --> 00:00:07.590
some clever way to look through them. And this get's us

00:00:07.590 --> 00:00:10.110
back, something that we've talked about before, which is the notion of

00:00:10.110 --> 00:00:16.370
bias. And in particular, the notion of inductive bias. Now, just

00:00:16.370 --> 00:00:18.875
as a quick refresher, I'm want to remind you that there is

00:00:18.875 --> 00:00:21.560
two kind of biases we worrying about when we think about algorithms

00:00:21.560 --> 00:00:25.660
that are searching through space. One is what's called a restriction bias.

00:00:27.040 --> 00:00:28.420
The other is called preference bias.

00:00:31.600 --> 00:00:34.430
So a restriction bias is nothing more than

00:00:34.430 --> 00:00:37.610
the hypothesis set that you actually care about. So

00:00:37.610 --> 00:00:39.190
in this case, with the decision trees, the

00:00:39.190 --> 00:00:43.146
hypothesis set is all possible decision trees. Okay? That

00:00:43.146 --> 00:00:46.701
means we're not considering, y equals 2x plus

00:00:46.701 --> 00:00:50.715
3. We're not considering quadratic equations. We're not considering

00:00:50.715 --> 00:00:54.050
non-boolean functions of a certain type. We're only considering

00:00:54.050 --> 00:00:56.420
decision trees, and all that they can represent. And

00:00:56.420 --> 00:00:59.130
nothing else. Okay? So that's already a restriction bias

00:00:59.130 --> 00:01:02.000
and it's important. Because, instead of looking at the infinite

00:01:02.000 --> 00:01:05.860
number uncountably infinite number of functions that are out there,

00:01:05.860 --> 00:01:08.120
that we might consider. We're only going to consider those

00:01:08.120 --> 00:01:10.920
that can be represented by a decision tree over

00:01:10.920 --> 00:01:13.440
in, you know, all the cases we've given so far

00:01:13.440 --> 00:01:17.080
discreet variable. But a preference bias is something that's just

00:01:17.080 --> 00:01:21.580
as important. And it tells us what source of hypotheses

00:01:21.580 --> 00:01:27.590
from this hypothesis set we prefer,

00:01:27.590 --> 00:01:32.924
and that is really at the heart of inductive bias. So Michael,

00:01:32.924 --> 00:01:38.044
given that, what would you say is the inductive

00:01:38.044 --> 00:01:42.960
bias of the ID3 algorithm? That is, given a whole

00:01:42.960 --> 00:01:48.590
bunch of decision trees, which decision trees would ID3 prefer,

00:01:48.590 --> 00:01:49.080
over others?

00:01:49.080 --> 00:01:54.500
&gt;&gt; So, it definitely tries, since it's, since it's making

00:01:54.500 --> 00:01:59.780
it's decisions top down. It's going to be more likely to produce a tree that has

00:01:59.780 --> 00:02:03.530
basically good splits near the top than a tree that has bad splits

00:02:03.530 --> 00:02:06.820
at the top. Even if the two trees can represent the same function.

00:02:06.820 --> 00:02:08.000
&gt;&gt; Good point.

00:02:10.199 --> 00:02:12.420
So good splits near the top.

00:02:15.580 --> 00:02:16.850
Alright. And you said something very important

00:02:16.850 --> 00:02:19.420
there Michael. Given two decision trees that

00:02:19.420 --> 00:02:23.620
are both correct. They both represent the,

00:02:23.620 --> 00:02:25.500
the function that we might care about.

00:02:25.500 --> 00:02:30.330
It would prefer the one that had the better split near the top. Okay,

00:02:30.330 --> 00:02:34.740
so any other preferences? Any other inductive bias on the, on the ID3 algorithm.

00:02:34.740 --> 00:02:38.090
&gt;&gt; It prefers ones that model the data

00:02:38.090 --> 00:02:40.680
better to ones that model the data worse.

00:02:40.680 --> 00:02:44.120
&gt;&gt; Right. So this is one that people often forget: it prefers

00:02:44.120 --> 00:02:49.420
correct ones to incorrect ones. So, given a tree that has very

00:02:49.420 --> 00:02:52.710
good splits at the top but produces the wrong answer. It will

00:02:52.710 --> 00:02:55.330
not take that one over one that doesn't have as good splits at

00:02:55.330 --> 00:02:57.820
the top, but does give you the correct answer. So that's really,

00:02:57.820 --> 00:03:00.100
those are really the two main things that are the inductive bias

00:03:00.100 --> 00:03:03.630
for ID3. Although, when you put those two together, in particular when

00:03:03.630 --> 00:03:05.730
you look at the first one, there's sort of a third one that

00:03:05.730 --> 00:03:09.460
comes out as well, which is ID3 algorithm tends to

00:03:09.460 --> 00:03:14.280
prefer shorter trees to longer trees. Now, that preference for shorter

00:03:14.280 --> 00:03:18.460
trees actually comes naturally from the fact that you're doing

00:03:18.460 --> 00:03:21.390
good splits at the top. Because you're going to take trees

00:03:21.390 --> 00:03:24.220
that actually separate the data well by labels, you're going to

00:03:24.220 --> 00:03:26.820
tend to come to the answer faster than you would if

00:03:26.820 --> 00:03:28.380
you didn't do that. So, if you go back to

00:03:28.380 --> 00:03:31.060
the example where we went before, where one of the attributes

00:03:31.060 --> 00:03:34.660
doesn't split the data at all, that is not something that ID3 would

00:03:34.660 --> 00:03:39.100
go for, and it would in fact create a longer and unnecessarily longer tree.

00:03:39.100 --> 00:03:42.440
So it tends to prefer shorter trees over longer trees. So long as

00:03:42.440 --> 00:03:45.350
they're correct and they give you good splits near the top of the tree.

