WEBVTT
Kind: captions
Language: en

00:00:06.169 --> 00:00:08.210
MARLA: I'm an engineer at
the Cultural Institute.

00:00:08.210 --> 00:00:10.830
And you should have been on a
tour of the Cultural Institute

00:00:10.830 --> 00:00:13.160
earlier today, so you
probably know a bit about it.

00:00:13.160 --> 00:00:16.250
But basically, we are
a team of engineers

00:00:16.250 --> 00:00:19.460
whose mission is to
democratize access to culture.

00:00:19.460 --> 00:00:22.520
And one of the ways we do
that is by helping museums

00:00:22.520 --> 00:00:24.660
digitize their collections.

00:00:24.660 --> 00:00:27.230
So that's why we built
the Art Camera, which

00:00:27.230 --> 00:00:29.580
is this thing right here.

00:00:29.580 --> 00:00:32.659
And it's a camera to
digitize paintings

00:00:32.659 --> 00:00:34.540
in very high resolution.

00:00:34.540 --> 00:00:37.610
And also, efficiently
at low cost.

00:00:37.610 --> 00:00:40.650
So it works by
taking automatically

00:00:40.650 --> 00:00:44.290
hundreds of very zoomed
in pictures of an artwork.

00:00:44.290 --> 00:00:46.550
And then, we stitch all
these pictures together

00:00:46.550 --> 00:00:49.125
to make a single very
high resolution image.

00:00:52.620 --> 00:00:54.940
We call these images gigapixels,
because they typically

00:00:54.940 --> 00:00:56.490
contain a few billion pixels.

00:00:56.490 --> 00:00:57.660
So that's one example.

00:00:57.660 --> 00:00:59.160
That's one of the
first paintings we

00:00:59.160 --> 00:01:00.590
digitized with the Art Camera.

00:01:00.590 --> 00:01:02.910
It's by a street artist,
called [INAUDIBLE].

00:01:02.910 --> 00:01:07.880
And if you zoom in, here
is the kind of resolution

00:01:07.880 --> 00:01:08.770
that we can get.

00:01:08.770 --> 00:01:11.650
So here, you can see
details that you would not

00:01:11.650 --> 00:01:13.250
be able to see with
your naked eye.

00:01:13.250 --> 00:01:15.990
So we actually get better
than eye resolution.

00:01:15.990 --> 00:01:21.380
And if you were to display this
at 100 pixels per inch, which

00:01:21.380 --> 00:01:26.130
is a typical display resolution,
then it would be about 10

00:01:26.130 --> 00:01:28.930
by 15 meters.

00:01:28.930 --> 00:01:32.480
So that's the kind of thing we
can get with the Art Camera.

00:01:32.480 --> 00:01:35.780
And now, let me tell
you a bit about what

00:01:35.780 --> 00:01:38.520
it's like for me
working on this project.

00:01:38.520 --> 00:01:41.089
So I joined this project
about 10 months ago.

00:01:41.089 --> 00:01:42.630
And when I first
joined, it was a bit

00:01:42.630 --> 00:01:43.990
like the first time I saw this.

00:01:43.990 --> 00:01:46.630
I was like, what is this?

00:01:46.630 --> 00:01:51.810
It's a big project with
lots of moving parts.

00:01:51.810 --> 00:01:53.720
There's three main components.

00:01:53.720 --> 00:01:56.810
The first component is the
camera itself, the hardware.

00:01:56.810 --> 00:02:01.270
So the actual DSLR camera
is an off the shelf Canon

00:02:01.270 --> 00:02:03.620
camera with a custom enclosure.

00:02:03.620 --> 00:02:05.880
And there's also
inside a custom circuit

00:02:05.880 --> 00:02:09.419
board with custom firmware.

00:02:09.419 --> 00:02:11.867
Then, the camera is
controlled by software

00:02:11.867 --> 00:02:12.700
running on a laptop.

00:02:12.700 --> 00:02:14.100
That's connected to USB.

00:02:14.100 --> 00:02:17.780
So on the laptop, there's
eight different servers

00:02:17.780 --> 00:02:21.040
running to control the
camera and also web

00:02:21.040 --> 00:02:23.790
UI for the operator.

00:02:23.790 --> 00:02:26.940
And the third part is
the stitching pipeline.

00:02:26.940 --> 00:02:31.350
So the software actually pieces
all the pictures together

00:02:31.350 --> 00:02:32.510
to create a single image.

00:02:32.510 --> 00:02:33.968
And that doesn't
run on the laptop.

00:02:33.968 --> 00:02:36.590
That runs in Google
data centers.

00:02:36.590 --> 00:02:40.042
And the pipeline
looks like this.

00:02:40.042 --> 00:02:42.510
So I was like, what?

00:02:42.510 --> 00:02:46.805
And all of this is written
using some C, lots of C++.

00:02:46.805 --> 00:02:48.230
Quite a lot of Python.

00:02:48.230 --> 00:02:49.440
There's a bit of Java.

00:02:49.440 --> 00:02:50.980
There's HTML and JavaScript.

00:02:50.980 --> 00:02:52.760
And CSS of course.

00:02:52.760 --> 00:02:55.200
So it's lots of moving pieces.

00:02:55.200 --> 00:02:58.040
And what's also fun
about this project

00:02:58.040 --> 00:03:01.320
is that we're just two software
engineers working on it.

00:03:01.320 --> 00:03:06.690
So that means we all get
to work on everything.

00:03:06.690 --> 00:03:11.720
Also, my colleague joined
the project 12 months ago

00:03:11.720 --> 00:03:13.180
and I joined 10 months ago.

00:03:13.180 --> 00:03:15.580
And it's just been
the two of us since.

00:03:15.580 --> 00:03:20.360
And that means that
we don't have anybody

00:03:20.360 --> 00:03:23.697
to ask questions to when we
don't know how things work.

00:03:23.697 --> 00:03:24.780
Or why they work that way.

00:03:24.780 --> 00:03:26.700
Or is there really a
good reason for that?

00:03:26.700 --> 00:03:28.530
Because sometimes there isn't.

00:03:28.530 --> 00:03:30.990
And so, it's always a
bit of a detective story

00:03:30.990 --> 00:03:35.490
when we try to
investigate issues.

00:03:35.490 --> 00:03:39.060
Another fun part of the project
is working with hardware.

00:03:39.060 --> 00:03:41.070
So that's me working
with hardware.

00:03:50.145 --> 00:03:52.020
One of the things when
you work with hardware

00:03:52.020 --> 00:03:57.295
is that you can't just write
unit tests for your software.

00:03:57.295 --> 00:03:58.670
At some point,
you really do have

00:03:58.670 --> 00:04:01.020
to test with the actual camera
by plugging these things

00:04:01.020 --> 00:04:02.690
physically.

00:04:02.690 --> 00:04:06.310
We do have unit tests and
integration tests that

00:04:06.310 --> 00:04:08.920
use a fake software camera.

00:04:08.920 --> 00:04:12.630
But recently for
instance, I wrote a bug

00:04:12.630 --> 00:04:14.210
and that went into production.

00:04:14.210 --> 00:04:17.162
And we didn't notice,
because the bug was only

00:04:17.162 --> 00:04:19.370
happening in the real camera
and not in the fake one.

00:04:19.370 --> 00:04:20.800
Because we discovered
that there was

00:04:20.800 --> 00:04:22.883
a difference between the
fake camera the real one.

00:04:22.883 --> 00:04:24.790
And we were not aware
of that difference.

00:04:24.790 --> 00:04:25.750
So these things happen.

00:04:25.750 --> 00:04:27.833
That's why you have to
test with a camera and even

00:04:27.833 --> 00:04:31.086
with several cameras and
different situations.

00:04:31.086 --> 00:04:32.460
Another fun part
with hardware is

00:04:32.460 --> 00:04:36.260
that these cameras get sent
all over the world to museums.

00:04:36.260 --> 00:04:40.420
And sometimes things
get wrong at the museum.

00:04:40.420 --> 00:04:43.090
And then, we have to
try and de-bug remotely.

00:04:43.090 --> 00:04:47.460
So recently, I had to
SSH into an Art Camera

00:04:47.460 --> 00:04:51.410
laptop in Columbia to try
and help with a capture that

00:04:51.410 --> 00:04:52.160
wasn't going well.

00:04:52.160 --> 00:04:53.535
And the connection
kept dropping,

00:04:53.535 --> 00:04:57.500
so that was lots of fun.

00:04:57.500 --> 00:05:01.160
But now, I understand
this project a bit better.

00:05:01.160 --> 00:05:06.170
So I can run you through
how a capture happens,

00:05:06.170 --> 00:05:09.700
how we get to this gigapixel.

00:05:09.700 --> 00:05:12.560
So this is the basic flow.

00:05:12.560 --> 00:05:14.560
First, we ship the
camera to the museum.

00:05:14.560 --> 00:05:17.320
Then, we set it up
for each painting.

00:05:17.320 --> 00:05:18.570
Then, we capture the painting.

00:05:18.570 --> 00:05:20.600
We upload the data to
Google Data Centers,

00:05:20.600 --> 00:05:21.800
where we stitch everything.

00:05:21.800 --> 00:05:24.720
And then, we are ready
to publish it on the web.

00:05:27.670 --> 00:05:30.370
Each step in a bit more detail.

00:05:30.370 --> 00:05:33.110
So first, we center the
camera on the painting.

00:05:33.110 --> 00:05:37.290
And at this step, we also decide
what distance to put the camera

00:05:37.290 --> 00:05:38.920
from the painting.

00:05:38.920 --> 00:05:41.430
There's a trade-off.

00:05:41.430 --> 00:05:43.890
The closer the camera is to
the artwork, the more pixels

00:05:43.890 --> 00:05:44.140
we get.

00:05:44.140 --> 00:05:45.056
The better resolution.

00:05:45.056 --> 00:05:47.100
But also the more time it
takes, because it means

00:05:47.100 --> 00:05:48.850
we need to take more pictures.

00:05:48.850 --> 00:05:51.122
And you should be
able to see here.

00:05:51.122 --> 00:05:53.080
To help with the distance,
we have a sonar here

00:05:53.080 --> 00:05:54.871
that tells us the
distance to the painting.

00:05:58.180 --> 00:06:00.634
The second step is
capturing the color checker.

00:06:00.634 --> 00:06:02.050
So that's a really
important step.

00:06:02.050 --> 00:06:04.466
The color checker is this
object that you see on the left.

00:06:04.466 --> 00:06:07.260
It's a piece of plastic
with patches of color

00:06:07.260 --> 00:06:10.310
that have very precise
predefined colors.

00:06:10.310 --> 00:06:12.280
And taking a picture
of this object

00:06:12.280 --> 00:06:15.560
allows us to record what
the lighting in the room

00:06:15.560 --> 00:06:18.460
was like when we
captured the painting.

00:06:18.460 --> 00:06:20.540
So that's really
important, because when

00:06:20.540 --> 00:06:22.960
you take a picture
with a camera,

00:06:22.960 --> 00:06:26.090
the RGB values of the pixels
depend not on the object

00:06:26.090 --> 00:06:28.390
that you photographed,
but also on the lighting.

00:06:28.390 --> 00:06:30.770
And so, taking a picture of
this and recording lighting

00:06:30.770 --> 00:06:34.690
allows us afterwards to
apply a correction algorithm

00:06:34.690 --> 00:06:37.430
to the colors of
the picture to make

00:06:37.430 --> 00:06:41.240
it look like all the
artworks were captured

00:06:41.240 --> 00:06:42.790
under the same
lighting conditions,

00:06:42.790 --> 00:06:46.770
even though that's
not necessarily true.

00:06:46.770 --> 00:06:48.603
Third step is the
actual capture.

00:06:51.480 --> 00:06:55.760
So the camera stays fixed, but
it can rotate left and right

00:06:55.760 --> 00:06:57.630
and up and down with this.

00:06:57.630 --> 00:07:00.460
Which is called a gimbal and
there's two [? buttons. ?]

00:07:00.460 --> 00:07:02.710
And so, it
automatically takes as I

00:07:02.710 --> 00:07:04.012
said, hundreds of pictures.

00:07:04.012 --> 00:07:05.470
This shows you the
pictures that we

00:07:05.470 --> 00:07:09.500
would take for an artwork that's
about one meter wide at two

00:07:09.500 --> 00:07:10.750
meters distance.

00:07:10.750 --> 00:07:13.250
So that's roughly 1000 pictures.

00:07:13.250 --> 00:07:15.130
And it would take about an hour.

00:07:18.280 --> 00:07:20.534
Once we have all this
data, we upload it.

00:07:20.534 --> 00:07:22.450
And then, we put it in
the stitching pipeline.

00:07:22.450 --> 00:07:24.408
So I showed the diagram
of the program earlier.

00:07:24.408 --> 00:07:26.210
It's kind of complicated.

00:07:26.210 --> 00:07:30.250
But the basic idea
is that we first look

00:07:30.250 --> 00:07:31.810
for features in all the images.

00:07:31.810 --> 00:07:36.190
So features are points of
interest on the images, things

00:07:36.190 --> 00:07:39.490
that we can describe,
like edges or corners.

00:07:39.490 --> 00:07:42.320
And they're represented
by squares on this slide.

00:07:42.320 --> 00:07:44.130
And then, we try
to match features

00:07:44.130 --> 00:07:45.430
between neighboring images.

00:07:45.430 --> 00:07:47.060
So if you find this
corner in an image

00:07:47.060 --> 00:07:49.410
and we find the same corner
in another image, we say OK.

00:07:49.410 --> 00:07:50.880
That's probably the same point.

00:07:50.880 --> 00:07:53.070
And then, after we matched
all of these features,

00:07:53.070 --> 00:07:55.930
we can find the best
alignment for the images.

00:07:55.930 --> 00:07:58.410
And then, we can blend
them smoothly together,

00:07:58.410 --> 00:08:02.650
so that you don't see the
separation between the images.

00:08:02.650 --> 00:08:06.890
So after this step, we
have one single big image.

00:08:06.890 --> 00:08:09.440
Which, for instance for the
painting I showed earlier,

00:08:09.440 --> 00:08:11.560
is about 500 megabytes.

00:08:11.560 --> 00:08:14.590
So at this point,
there's still a step

00:08:14.590 --> 00:08:15.940
needed to put it on the web.

00:08:15.940 --> 00:08:20.720
Because we don't want users to
have to download 500 megabytes

00:08:20.720 --> 00:08:23.170
just to see one painting.

00:08:23.170 --> 00:08:28.370
So what we do is that
we slice it up in tiles.

00:08:28.370 --> 00:08:35.870
So we cut it into square tiles
that are 512 pixels by 512.

00:08:35.870 --> 00:08:38.340
And we also made smaller
versions of the painting

00:08:38.340 --> 00:08:39.690
with fewer tiles.

00:08:39.690 --> 00:08:43.570
Until at the top of the pyramid,
you only have a single tile.

00:08:43.570 --> 00:08:45.980
A thumbnail of the image.

00:08:45.980 --> 00:08:48.900
And so, that way when the user
navigates the image-- like pans

00:08:48.900 --> 00:08:50.960
around and zooms
in, we only need

00:08:50.960 --> 00:08:53.360
to load the ties that
are needed to show

00:08:53.360 --> 00:08:55.645
the part of the painting
that the user is looking at,

00:08:55.645 --> 00:08:59.570
at the current zoom level.

00:08:59.570 --> 00:09:02.860
So that's how capture works.

00:09:02.860 --> 00:09:07.835
So now, I'm going to tell you
a bit about specific change

00:09:07.835 --> 00:09:08.710
I've been working on.

00:09:08.710 --> 00:09:12.990
So that you know what
I'm actually working on.

00:09:12.990 --> 00:09:18.000
And that change is the
quest for sharp pixels.

00:09:18.000 --> 00:09:21.899
Trying to get the
sharpest pictures we can.

00:09:21.899 --> 00:09:24.440
As I explained, we take hundreds
of pictures of the painting.

00:09:24.440 --> 00:09:26.000
And most of the
time, they're sharp.

00:09:26.000 --> 00:09:28.400
But also, sometimes
we notice that we

00:09:28.400 --> 00:09:32.674
have some that are blurry,
which is obviously bad.

00:09:32.674 --> 00:09:34.840
Because we're not getting
the best quality we could.

00:09:34.840 --> 00:09:37.420
And also then, when we
stitch them together,

00:09:37.420 --> 00:09:39.742
you can see the separation
between the sharp picture

00:09:39.742 --> 00:09:40.700
and the blurry picture.

00:09:40.700 --> 00:09:42.300
So that doesn't look very good.

00:09:42.300 --> 00:09:44.560
And sometimes we
actually fail to stitch.

00:09:44.560 --> 00:09:47.660
Because when we try to match
the features between the images,

00:09:47.660 --> 00:09:50.110
the images don't look like
each other because one is sharp

00:09:50.110 --> 00:09:51.800
and one is blurry.

00:09:51.800 --> 00:09:55.470
So the idea was to try and
detect automatically when

00:09:55.470 --> 00:09:58.640
we took a blurry picture,
so that we can immediately

00:09:58.640 --> 00:10:00.970
take another one.

00:10:00.970 --> 00:10:06.510
And trying to evaluate
the sharpness of a picture

00:10:06.510 --> 00:10:08.002
is quite a common problem.

00:10:08.002 --> 00:10:09.960
There's actually lots of
research papers on it.

00:10:09.960 --> 00:10:13.220
So I read a bunch
of papers and I also

00:10:13.220 --> 00:10:15.054
looked around other
Google projects

00:10:15.054 --> 00:10:17.470
to see what they were doing,
because I'm not the first one

00:10:17.470 --> 00:10:20.150
to try and determine if
an image is blurry or not.

00:10:20.150 --> 00:10:23.187
And I got all the data set
of some of our sharp pictures

00:10:23.187 --> 00:10:24.520
and some of our blurry pictures.

00:10:24.520 --> 00:10:27.070
And I tried these
algorithms on it.

00:10:27.070 --> 00:10:31.950
And actually none of them
worked very well on my data sets

00:10:31.950 --> 00:10:33.650
and there are several reasons.

00:10:33.650 --> 00:10:37.700
One reason is I think most of
these algorithms work better

00:10:37.700 --> 00:10:40.210
on out of focus blur.

00:10:40.210 --> 00:10:43.890
So basically there are two
reasons why you can get blur.

00:10:43.890 --> 00:10:45.880
One is because your
object is out of focus,

00:10:45.880 --> 00:10:48.310
so your camera is
focused in front

00:10:48.310 --> 00:10:50.140
or in the back of your object.

00:10:50.140 --> 00:10:52.290
And the other is
the motion blur,

00:10:52.290 --> 00:10:54.670
because you moved
the camera while you

00:10:54.670 --> 00:10:56.240
were taking the picture.

00:10:56.240 --> 00:10:59.800
And actually, it seems that
most of the blur we get

00:10:59.800 --> 00:11:01.647
is from motion blur.

00:11:01.647 --> 00:11:02.980
I mean the camera is not moving.

00:11:02.980 --> 00:11:04.460
But actually, we're
taking pictures

00:11:04.460 --> 00:11:08.930
that are so zoomed in that even
the tiniest shake of the camera

00:11:08.930 --> 00:11:09.600
causes blur.

00:11:13.640 --> 00:11:18.220
That's the kind of blur
that's a bit harder to detect.

00:11:18.220 --> 00:11:21.090
And another thing that makes
it a bit more complicated

00:11:21.090 --> 00:11:25.520
is the fact that we have some
pictures that look like this.

00:11:25.520 --> 00:11:28.391
So when we are
capturing a drawing

00:11:28.391 --> 00:11:30.890
and there's like the drawing
in the middle and on the sides,

00:11:30.890 --> 00:11:34.390
it's just paper, we have
pictures that look like paper.

00:11:34.390 --> 00:11:35.950
And most algorithms
will say, oh.

00:11:35.950 --> 00:11:36.930
That's pretty blurry.

00:11:36.930 --> 00:11:40.930
But actually, it's a sharp
picture of a piece of paper.

00:11:40.930 --> 00:11:44.051
And even for me when I
was getting my data set

00:11:44.051 --> 00:11:46.300
and trying to find sharp
pictures and blurry pictures,

00:11:46.300 --> 00:11:48.924
sometimes it was hard for me to
tell if they were sharp or not.

00:11:48.924 --> 00:11:50.630
So if it's hard for
me, you can tell

00:11:50.630 --> 00:11:53.640
it's going to be tricky
for an algorithm.

00:11:53.640 --> 00:11:56.417
So at that point, I
was a bit disappointed

00:11:56.417 --> 00:11:57.250
that it didn't work.

00:11:57.250 --> 00:11:59.570
And then, my colleagues
came to my rescue

00:11:59.570 --> 00:12:01.837
and give me a
million suggestions.

00:12:01.837 --> 00:12:03.795
There were more possibilities
than combinations

00:12:03.795 --> 00:12:04.860
on my Rubik's cube.

00:12:04.860 --> 00:12:06.140
And I was like, ah!

00:12:06.140 --> 00:12:08.954
I can't test all of this.

00:12:08.954 --> 00:12:10.370
I mean I could
spend months trying

00:12:10.370 --> 00:12:12.495
to-- I'm sure this is a
problem that can be solved.

00:12:12.495 --> 00:12:14.300
I could spend months
trying to solve it.

00:12:14.300 --> 00:12:17.300
But actually, at that point, I
thought that a better approach

00:12:17.300 --> 00:12:21.220
would be to try and
prevent the shaking

00:12:21.220 --> 00:12:24.547
or the blur from happening
in the first place.

00:12:24.547 --> 00:12:26.130
So why are we getting
blurry pictures?

00:12:26.130 --> 00:12:28.190
I said it's because of shaking.

00:12:28.190 --> 00:12:29.870
So how do you get
rid of shaking?

00:12:29.870 --> 00:12:31.995
Typically, a photographer
would tell you, well, you

00:12:31.995 --> 00:12:32.620
use a tripod.

00:12:32.620 --> 00:12:36.160
So we already have a
very sturdy tripod.

00:12:36.160 --> 00:12:38.370
It's very big and heavy.

00:12:38.370 --> 00:12:41.120
But the fact that we take
pictures that are so zoomed in

00:12:41.120 --> 00:12:44.419
means when it's shaking a tiny
bit-- and you can't even see.

00:12:44.419 --> 00:12:46.460
Like I look at it and I'm
like, it's not shaking.

00:12:46.460 --> 00:12:47.750
But actually, it is.

00:12:47.750 --> 00:12:50.610
When you look at the camera
view, it is shaking a bit.

00:12:50.610 --> 00:12:52.480
And so we are getting
blurry pictures,

00:12:52.480 --> 00:12:55.650
despite this very heavy
industrial tripod.

00:12:55.650 --> 00:13:01.150
So what we can do is try
and use an accelerometer

00:13:01.150 --> 00:13:04.020
to detect when the
camera is moving.

00:13:04.020 --> 00:13:06.500
And we actually already
have an accelerometer

00:13:06.500 --> 00:13:08.990
on the camera that
was already there.

00:13:08.990 --> 00:13:12.120
On that custom board
that I mentioned.

00:13:12.120 --> 00:13:15.140
And we have an algorithm that's
supposed to detect shaking

00:13:15.140 --> 00:13:17.700
and prevent taking
pictures when it's shaking.

00:13:17.700 --> 00:13:22.120
So if we already have this, why
am I getting blurry pictures?

00:13:22.120 --> 00:13:25.560
That was the question
I asked myself.

00:13:25.560 --> 00:13:27.510
Obviously, the shaking
detection algorithm

00:13:27.510 --> 00:13:30.460
was not working very well,
because we got blurry pictures

00:13:30.460 --> 00:13:31.730
even though it said it's fine.

00:13:31.730 --> 00:13:34.690
And also, sometimes when we
were in museums, the shaking

00:13:34.690 --> 00:13:38.050
the detection was saying
all the time, oh my god.

00:13:38.050 --> 00:13:39.742
It's shaking, I can't
take a picture--

00:13:39.742 --> 00:13:41.200
even though everything
seemed fine.

00:13:41.200 --> 00:13:44.080
And when I had to SSH in
Columbia-- that story I

00:13:44.080 --> 00:13:47.424
mentioned earlier-- that was
because of a shaking problem.

00:13:47.424 --> 00:13:49.340
It kept saying it was
shaking, so the operator

00:13:49.340 --> 00:13:53.000
could not capture, even
though everything seemed fine.

00:13:53.000 --> 00:13:56.653
So I didn't know anything
about accelerometers

00:13:56.653 --> 00:13:58.440
or signal processing
or anything.

00:13:58.440 --> 00:14:00.760
And as I said, there
was nobody on the team

00:14:00.760 --> 00:14:02.250
who knew anything about this.

00:14:02.250 --> 00:14:05.225
So I dug up the schematics
of the power board

00:14:05.225 --> 00:14:08.250
and the data sheet
of the accelerometer.

00:14:08.250 --> 00:14:11.320
And I spent hours trying
to understand what

00:14:11.320 --> 00:14:14.090
the firmware was trying to do.

00:14:14.090 --> 00:14:18.230
And then, finally I wrote some
tools to record some data.

00:14:18.230 --> 00:14:20.910
So on the left, I recorded
the camera images,

00:14:20.910 --> 00:14:24.640
so that I could see visually if
it looked like it was shaking.

00:14:24.640 --> 00:14:27.870
And on the right, you have
the accelerometer data.

00:14:27.870 --> 00:14:31.010
So there's three lines
for x, y, and z-axes.

00:14:31.010 --> 00:14:34.410
And so, after looking at
this data, what I realized

00:14:34.410 --> 00:14:37.620
is that probably we were
giving too much importance

00:14:37.620 --> 00:14:41.440
to high frequencies and not
enough to low frequencies.

00:14:41.440 --> 00:14:43.960
And so, I try and
modified the algorithm

00:14:43.960 --> 00:14:47.250
to have a low pass
filter to remove

00:14:47.250 --> 00:14:49.550
the very high frequencies,
which are just noise.

00:14:49.550 --> 00:14:51.490
Which are not
actually causing blur.

00:14:51.490 --> 00:14:55.420
So that we can detect
the lower frequencies,

00:14:55.420 --> 00:14:57.585
which actually cause blur.

00:14:57.585 --> 00:14:59.994
So that's not really
the end of the story,

00:14:59.994 --> 00:15:01.410
because I'm still
working on this.

00:15:01.410 --> 00:15:03.034
I haven't deployed
the new version yet,

00:15:03.034 --> 00:15:05.620
because that's the fun
thing we have where I said,

00:15:05.620 --> 00:15:07.470
you have to test it a lot.

00:15:07.470 --> 00:15:09.990
I have to test it on
different cameras,

00:15:09.990 --> 00:15:13.320
because maybe they vibrate
at different frequencies

00:15:13.320 --> 00:15:16.020
and in different conditions.

00:15:16.020 --> 00:15:18.390
Maybe here at my
desk, it's fine.

00:15:18.390 --> 00:15:20.130
Maybe in Columbia it's not fine.

00:15:20.130 --> 00:15:21.760
Maybe I won't go
test it in Columbia.

00:15:21.760 --> 00:15:25.280
But it needs a lot more testing.

00:15:25.280 --> 00:15:30.760
So to summarize working
on this project,

00:15:30.760 --> 00:15:31.830
it's fun and challenging.

00:15:31.830 --> 00:15:33.860
And sometimes it's
also frustrating.

00:15:33.860 --> 00:15:37.110
But at the same time,
it's very rewarding

00:15:37.110 --> 00:15:39.380
because at the end of
all this hard work,

00:15:39.380 --> 00:15:44.990
we have several
thousand pictures

00:15:44.990 --> 00:15:46.910
for very high resolution
pictures of paintings

00:15:46.910 --> 00:15:47.790
that we've captured.

00:15:47.790 --> 00:15:50.500
And that we have
available on the web

00:15:50.500 --> 00:15:51.930
at google.com/CulturalInstitute.

00:15:51.930 --> 00:15:54.180
So you can go check
them out over there.

00:15:54.180 --> 00:15:58.450
And sometimes you also get
very nice messages from users,

00:15:58.450 --> 00:16:02.010
so that's really gratifying.

00:16:02.010 --> 00:16:06.960
And that really makes
it worth the effort.

00:16:06.960 --> 00:16:08.260
Thank you.

00:16:08.260 --> 00:16:09.102
Questions?

00:16:09.102 --> 00:16:11.070
[APPLAUSE]

00:16:17.261 --> 00:16:17.760
Questions?

00:16:26.420 --> 00:16:27.069
AUDIENCE: Hi.

00:16:27.069 --> 00:16:27.610
MARLA: Hello.

00:16:27.610 --> 00:16:29.360
AUDIENCE: Hello.

00:16:29.360 --> 00:16:32.480
I saw that there is,
it's a camera inside,

00:16:32.480 --> 00:16:34.840
so I guess it has a brand.

00:16:37.480 --> 00:16:44.260
Did you happen to work with
the brand of this camera?

00:16:44.260 --> 00:16:49.020
I mean all these algorithms
to improve this camera?

00:16:49.020 --> 00:16:54.524
Or with the company
that built this camera?

00:16:54.524 --> 00:16:57.170
MARLA: The actual DSLR
camera that's inside

00:16:57.170 --> 00:16:58.690
is an off the shelf camera.

00:16:58.690 --> 00:17:01.150
So it's a normal camera
that you can buy.

00:17:01.150 --> 00:17:02.150
It's a Canon camera.

00:17:02.150 --> 00:17:05.064
It's a 7D Mark II if you know
anything about photography.

00:17:05.064 --> 00:17:06.730
I didn't know anything
about photography

00:17:06.730 --> 00:17:08.450
before joining this
project by the way.

00:17:08.450 --> 00:17:09.460
I learned some stuff.

00:17:09.460 --> 00:17:11.275
Now, I know some stuff.

00:17:11.275 --> 00:17:14.460
We also have a professional
photographer that helps us.

00:17:14.460 --> 00:17:16.020
And that goes to
museums sometime.

00:17:16.020 --> 00:17:18.561
So that also helps.

00:17:18.561 --> 00:17:19.060
But, yeah.

00:17:19.060 --> 00:17:21.280
It's a normal camera.

00:17:21.280 --> 00:17:24.339
And I think this model is
working pretty well for us

00:17:24.339 --> 00:17:25.150
right now.

00:17:25.150 --> 00:17:28.300
I'm not sure if that was
exactly your question.

00:17:28.300 --> 00:17:31.570
AUDIENCE: Basically,
did you think about

00:17:31.570 --> 00:17:37.160
to work with the camera
company that built this Canon?

00:17:37.160 --> 00:17:38.230
Or with Canon?

00:17:38.230 --> 00:17:39.530
I don't know.

00:17:39.530 --> 00:17:42.630
Because I guess they
have more experience

00:17:42.630 --> 00:17:44.190
about building cameras.

00:17:46.430 --> 00:17:46.930
MARLA: Yeah.

00:17:46.930 --> 00:17:49.480
I guess that's a good question.

00:17:49.480 --> 00:17:54.310
So I think we're happy
with the camera itself.

00:17:54.310 --> 00:17:58.080
And like the value
we're adding is not--

00:17:58.080 --> 00:18:00.170
the way we're getting very
high resolution images

00:18:00.170 --> 00:18:02.170
is not by having the
best camera in the world

00:18:02.170 --> 00:18:03.753
that has the most
pixels in the world.

00:18:03.753 --> 00:18:05.790
It's by just having
a normal camera

00:18:05.790 --> 00:18:07.740
and taking lots of pictures.

00:18:07.740 --> 00:18:09.459
And then, stitching
them all together.

00:18:09.459 --> 00:18:12.000
And we also wanted it to be a
normal camera, because we don't

00:18:12.000 --> 00:18:13.970
want this to be too expensive.

00:18:13.970 --> 00:18:18.154
We want it to be low
cost and efficient.

00:18:18.154 --> 00:18:18.695
AUDIENCE: OK.

00:18:23.300 --> 00:18:25.950
MARLA: Is there
another question?

00:18:25.950 --> 00:18:29.005
Over here.

00:18:29.005 --> 00:18:29.546
AUDIENCE: Hi.

00:18:29.546 --> 00:18:30.230
MARLA: Hi.

00:18:30.230 --> 00:18:31.688
AUDIENCE: So what
is your technique

00:18:31.688 --> 00:18:34.800
to stitch correctly the
different images that you're

00:18:34.800 --> 00:18:37.470
taking?

00:18:37.470 --> 00:18:43.020
MARLA: So I tried to explain
that quickly at one point.

00:18:43.020 --> 00:18:45.179
So we know where we
took the images, right?

00:18:45.179 --> 00:18:47.220
Because we know where the
camera was pointing at.

00:18:47.220 --> 00:18:49.511
And you would think we could
just use that information.

00:18:49.511 --> 00:18:51.870
But actually, it's
not precise enough.

00:18:51.870 --> 00:18:56.740
So the way we do it
is actually looking

00:18:56.740 --> 00:18:59.770
at the pixels of the images.

00:18:59.770 --> 00:19:01.840
So we take images
that overlap a little.

00:19:01.840 --> 00:19:05.800
So each area is
on several images

00:19:05.800 --> 00:19:09.170
and then we check
for these overlaps.

00:19:09.170 --> 00:19:14.310
And we figure out what's the
best alignment for the images

00:19:14.310 --> 00:19:18.540
and how best to stitch them.

00:19:18.540 --> 00:19:20.007
I hope that makes
it a bit clearer.

00:19:20.007 --> 00:19:21.340
I'm not sure if that's the case.

00:19:25.970 --> 00:19:29.080
AUDIENCE: So can you tell us
how many pictures on average

00:19:29.080 --> 00:19:31.890
do you take for each artwork?

00:19:31.890 --> 00:19:35.610
And do you have a paper
explaining the algorithm

00:19:35.610 --> 00:19:37.960
of the stitching part?

00:19:42.580 --> 00:19:44.640
MARLA: I don't know
the average number.

00:19:44.640 --> 00:19:52.380
It's probably on average
between 500 and 1,000.

00:19:52.380 --> 00:19:55.750
We don't have a paper or
anything explaining it.

00:19:55.750 --> 00:20:00.700
If you guys want to learn more
about it, you can email me.

00:20:00.700 --> 00:20:03.270
My address is Marla, my
first name, @google.com.

00:20:05.810 --> 00:20:07.560
Because I don't really
have time right now

00:20:07.560 --> 00:20:08.934
to explain everything in detail.

00:20:08.934 --> 00:20:10.475
Also, I don't know
the most about it.

00:20:10.475 --> 00:20:11.933
The one who knows
the most about it

00:20:11.933 --> 00:20:16.230
is my colleague, the other
engineer who works on it.

00:20:16.230 --> 00:20:18.947
But really, it's a bunch
of existing techniques

00:20:18.947 --> 00:20:20.030
like looking for features.

00:20:20.030 --> 00:20:22.960
There are algorithms that
exist to look for features.

00:20:22.960 --> 00:20:25.300
Matching features
is just features

00:20:25.300 --> 00:20:26.550
that are described by vectors.

00:20:26.550 --> 00:20:29.085
We just look for the Euclidean
distance of the vectors

00:20:29.085 --> 00:20:29.960
and things like that.

00:20:32.380 --> 00:20:32.880
No.

00:20:32.880 --> 00:20:34.130
We don't use machine learning.

00:20:34.130 --> 00:20:36.335
Not that I know, but maybe.

00:20:39.390 --> 00:20:40.842
I think I might have time.

00:20:40.842 --> 00:20:42.050
AUDIENCE: The final question.

00:20:42.050 --> 00:20:42.730
MARLA: Sure.

00:20:42.730 --> 00:20:44.771
AUDIENCE: Did you finish
that Rubik's cube as you

00:20:44.771 --> 00:20:47.070
were standing up on stage?

00:20:47.070 --> 00:20:47.970
[CHUCKLING]

00:20:47.970 --> 00:20:50.720
[APPLAUSE]

