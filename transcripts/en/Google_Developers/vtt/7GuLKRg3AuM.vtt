WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.750
ALEX GOUAILLARD: Well, thanks
to the organizer for having me

00:00:02.750 --> 00:00:03.890
here.

00:00:03.890 --> 00:00:05.610
I'm going to talk
to you a little bit

00:00:05.610 --> 00:00:06.880
about the infrastructure part.

00:00:06.880 --> 00:00:09.160
I'm Alex, the CTO of Temasys.

00:00:09.160 --> 00:00:12.020
We're providing a few
services that I'm not

00:00:12.020 --> 00:00:14.140
going to speak about today.

00:00:14.140 --> 00:00:19.060
I'm just going to take you
guys through the painful path

00:00:19.060 --> 00:00:22.360
we followed last year trying
to build up a first scalable

00:00:22.360 --> 00:00:24.060
infrastructure.

00:00:24.060 --> 00:00:27.410
So this is what I'm
going to speak about.

00:00:27.410 --> 00:00:29.930
Most of the people start
from the reference code.

00:00:29.930 --> 00:00:31.540
So I'm going to start
from there, too.

00:00:31.540 --> 00:00:34.810
And there is a lot of reason
why you should do that.

00:00:34.810 --> 00:00:37.280
Now, the reference code
is good for one use case,

00:00:37.280 --> 00:00:39.060
but might not be
good for others.

00:00:39.060 --> 00:00:41.860
So I'm going to put
disclaimer on that

00:00:41.860 --> 00:00:44.300
and show how you
can do it better

00:00:44.300 --> 00:00:46.190
and address the first
real pain, which

00:00:46.190 --> 00:00:47.815
is going to be scalability.

00:00:47.815 --> 00:00:49.690
There's a lot of things
on the infrastructure

00:00:49.690 --> 00:00:52.890
of a good WebRTC solution
that are going to be left out

00:00:52.890 --> 00:00:55.530
of this presentation because
it's only 20 minutes.

00:00:55.530 --> 00:00:57.390
But I'm still going
to provide the list

00:00:57.390 --> 00:00:59.540
at the end of the
point you might want

00:00:59.540 --> 00:01:02.140
to look at before you
go into architecturing

00:01:02.140 --> 00:01:04.170
such a solution for yourself.

00:01:04.170 --> 00:01:06.790
All right, so the
reference code.

00:01:06.790 --> 00:01:08.650
WebRTC is an API.

00:01:08.650 --> 00:01:11.210
So APIs are difficult
to demonstrate.

00:01:11.210 --> 00:01:13.050
There is a reference
implementation

00:01:13.050 --> 00:01:17.620
at webrtc.org where a lot of
companies, including Mozilla,

00:01:17.620 --> 00:01:19.680
Google, MIPS, Intel.

00:01:19.680 --> 00:01:22.460
Vonage contributed too.

00:01:22.460 --> 00:01:26.450
It has the existing pure
connection, all the APIs.

00:01:26.450 --> 00:01:28.540
It has an iOS version.

00:01:28.540 --> 00:01:31.840
It has an Android version
with all the wrapping,

00:01:31.840 --> 00:01:33.790
so if you want to start
somewhere start there.

00:01:33.790 --> 00:01:34.950
It's working.

00:01:34.950 --> 00:01:43.210
And to be able to
play with it, there

00:01:43.210 --> 00:01:47.650
is also a reference application
for you to use that.

00:01:47.650 --> 00:01:51.384
As [? Sari ?] told you
before, WebRTC is just an API.

00:01:51.384 --> 00:01:53.050
If you want a solution,
you need to make

00:01:53.050 --> 00:01:54.700
a choice for the signaling.

00:01:54.700 --> 00:01:56.040
You need to make a few choices.

00:01:56.040 --> 00:01:57.720
You need to provide
a few servers.

00:01:57.720 --> 00:02:00.860
And that's exactly
what appRTC does.

00:02:00.860 --> 00:02:05.510
So this is the
drawing of appRTC.

00:02:05.510 --> 00:02:09.130
You have a STUN server
provided by Google, by Mozilla,

00:02:09.130 --> 00:02:12.810
depending on which browser
you connect to the website.

00:02:12.810 --> 00:02:15.430
There is a separate web server
for the TURN management,

00:02:15.430 --> 00:02:18.470
for the load balancing,
and geographically loading

00:02:18.470 --> 00:02:19.590
for TURN.

00:02:19.590 --> 00:02:22.550
There's a TURN
cluster, actually.

00:02:22.550 --> 00:02:25.920
Then you have the web server
and the signaling server.

00:02:25.920 --> 00:02:28.450
The advantage of the
appRTC is that it's

00:02:28.450 --> 00:02:30.110
hosted by Google App Engine.

00:02:30.110 --> 00:02:31.720
So it's very scalable.

00:02:31.720 --> 00:02:33.770
You don't have to think
about how many instances.

00:02:33.770 --> 00:02:35.900
They're already
taking care of that.

00:02:35.900 --> 00:02:37.967
You don't think about
replicating the database

00:02:37.967 --> 00:02:38.800
or things like that.

00:02:38.800 --> 00:02:40.350
It's done for you.

00:02:40.350 --> 00:02:44.460
So there is a few problems
about the reliability, though.

00:02:44.460 --> 00:02:47.030
And that's mainly on
the signaling server.

00:02:47.030 --> 00:02:51.070
So appRTC is here to implement
a very simple case which

00:02:51.070 --> 00:02:52.800
is a one-to-one communication.

00:02:52.800 --> 00:02:55.800
And within that scope, it
does the job very well.

00:02:55.800 --> 00:02:58.227
And if you find a mistake
and you want to report a bug,

00:02:58.227 --> 00:03:00.060
the first thing you're
going to be asked for

00:03:00.060 --> 00:03:02.970
is to try to replicate
it with appRTC.

00:03:02.970 --> 00:03:05.450
That's where the
maintenance job is done.

00:03:05.450 --> 00:03:07.620
Now, one of the
problems, though,

00:03:07.620 --> 00:03:11.350
is that the signaling server is
actually not a single signaling

00:03:11.350 --> 00:03:16.250
server but it's leveraging what
is called the GAE Channel API.

00:03:16.250 --> 00:03:18.980
And that is sometimes a
little bit problematic.

00:03:18.980 --> 00:03:21.630
The access to the
database induce delays.

00:03:21.630 --> 00:03:24.596
And up to our experiments.

00:03:24.596 --> 00:03:27.290
The GAE Channel API
is sometimes not

00:03:27.290 --> 00:03:30.130
reliable-- and more
than sometimes.

00:03:30.130 --> 00:03:32.080
So if you're going to
multiparty for example,

00:03:32.080 --> 00:03:34.663
the first thing people want to
do is to go from the one to one

00:03:34.663 --> 00:03:35.860
to the multiparty.

00:03:35.860 --> 00:03:40.410
And suddenly, there's a lot of
things that go unpredictable.

00:03:40.410 --> 00:03:42.310
So this is a little
drawing of what

00:03:42.310 --> 00:03:46.270
is happening behind the scene
just for a handshake, right?

00:03:46.270 --> 00:03:52.090
So you have the caller and the
callee for a one-to-one call.

00:03:52.090 --> 00:03:55.140
OK, the addLocalString,
createOffer,

00:03:55.140 --> 00:03:58.620
setLocal-- that's the
API you have in WebRTC.

00:03:58.620 --> 00:04:00.620
And in the middle, you
have a signaling server

00:04:00.620 --> 00:04:02.650
exchanging a few signals, right?

00:04:02.650 --> 00:04:06.280
That is very, very order
and timing sensitive.

00:04:06.280 --> 00:04:09.850
So if you start adding delays
on one part or the other,

00:04:09.850 --> 00:04:12.000
and you don't do that
exactly in order,

00:04:12.000 --> 00:04:16.540
exactly like that, things
just don't go through, right?

00:04:16.540 --> 00:04:18.990
The reference code, you
can make it reliable,

00:04:18.990 --> 00:04:22.440
adding delays, adding
database here and there.

00:04:22.440 --> 00:04:24.020
This is what is done in appRTC.

00:04:24.020 --> 00:04:27.930
You have a cache for the message
waiting if a message arrives

00:04:27.930 --> 00:04:29.410
out of order and
things like that.

00:04:29.410 --> 00:04:32.180
But then the handshake is
stretched up to 10 seconds.

00:04:32.180 --> 00:04:36.490
So we had a multiparty scalable
solution based on that one

00:04:36.490 --> 00:04:39.300
point, but waiting 10
second for things to happen

00:04:39.300 --> 00:04:41.100
is just not acceptable.

00:04:41.100 --> 00:04:43.900
So let's go for a
little bit better.

00:04:43.900 --> 00:04:46.460
As was mentioned
before, a lot of people

00:04:46.460 --> 00:04:49.050
just drop that signaling
and go for something

00:04:49.050 --> 00:04:50.840
that is Node.js based.

00:04:50.840 --> 00:04:53.320
It's much more reliable.

00:04:53.320 --> 00:04:54.450
It's much faster.

00:04:54.450 --> 00:04:57.200
So you can achieve
handshake under one second

00:04:57.200 --> 00:05:00.390
without a lot of effort
with almost all the SDK API

00:05:00.390 --> 00:05:01.290
out there.

00:05:01.290 --> 00:05:05.060
There's a huge ecosystem
of plug-ins and modules

00:05:05.060 --> 00:05:07.290
and stuff you can put
on your node to actually

00:05:07.290 --> 00:05:09.840
add very nice
feature very easily.

00:05:09.840 --> 00:05:12.800
Now, the problem is you
lose the scalability

00:05:12.800 --> 00:05:15.890
you had from Google App Engine,
and you lose the maintenance

00:05:15.890 --> 00:05:16.770
as well.

00:05:16.770 --> 00:05:20.272
So you can put the maintenance
on an API SDK vendor,

00:05:20.272 --> 00:05:21.480
if that's the route you want.

00:05:21.480 --> 00:05:22.938
But if you do it
yourself, you will

00:05:22.938 --> 00:05:24.990
have to be very careful
about the level of test

00:05:24.990 --> 00:05:27.240
and the security
you want to provide

00:05:27.240 --> 00:05:28.870
with your infrastructure.

00:05:28.870 --> 00:05:29.900
So let's address that.

00:05:29.900 --> 00:05:32.510
What's the scalability
problem, really?

00:05:32.510 --> 00:05:34.630
Most of the people
reviewed Node.js

00:05:34.630 --> 00:05:37.750
and would go for a public
cloud, like let's say Amazon Web

00:05:37.750 --> 00:05:41.990
Services, if only because
they're everywhere

00:05:41.990 --> 00:05:42.690
in the world.

00:05:42.690 --> 00:05:46.130
And if you want to address Asia,
as we're based in Singapore

00:05:46.130 --> 00:05:49.030
and that's the fastest
growing market,

00:05:49.030 --> 00:05:50.960
Amazon Web Services
is the only one

00:05:50.960 --> 00:05:54.405
that will have 10 data
centers all across Asia.

00:05:54.405 --> 00:05:57.260
Now, the problem with Amazon
Web Services, for example,

00:05:57.260 --> 00:06:02.120
is they don't give you a
commitment on bandwidth.

00:06:02.120 --> 00:06:04.670
They're going to tell you
low usage, medium usage,

00:06:04.670 --> 00:06:06.060
or high usage.

00:06:06.060 --> 00:06:08.500
So you start going there, and
you start doing benchmark,

00:06:08.500 --> 00:06:10.050
and then you
realize very quickly

00:06:10.050 --> 00:06:12.050
that there are unwritten rules.

00:06:12.050 --> 00:06:14.620
The biggest and the
newest instances

00:06:14.620 --> 00:06:17.750
will have preferential
access to the bandwidth.

00:06:17.750 --> 00:06:20.790
And the big instances will
have their own network adapter,

00:06:20.790 --> 00:06:26.440
so you can actually have
replicable bandwidth, right?

00:06:26.440 --> 00:06:28.430
Otherwise, on the small
instances, one day

00:06:28.430 --> 00:06:30.940
you have 50 gigabytes,
the day after you have 10.

00:06:30.940 --> 00:06:33.120
You have the noisy
neighbor effect.

00:06:33.120 --> 00:06:37.520
So you will so for the big
instances and the newest one.

00:06:37.520 --> 00:06:42.590
The second problem is you
don't have Amazon Web Services

00:06:42.590 --> 00:06:45.670
socket intensive
instances, right?

00:06:45.670 --> 00:06:47.510
So they have CPU intensive.

00:06:47.510 --> 00:06:48.996
They have memory intensive.

00:06:48.996 --> 00:06:50.870
They don't tell you
anything about bandwidth.

00:06:50.870 --> 00:06:52.040
What about socket intensive?

00:06:52.040 --> 00:06:54.140
A signaling server
is something that

00:06:54.140 --> 00:06:56.297
will have a lot of
sockets open-- and closed,

00:06:56.297 --> 00:06:58.630
open and closed-- and they
don't have really an instance

00:06:58.630 --> 00:07:01.140
that fit to that.

00:07:01.140 --> 00:07:04.640
Most people will use
Socket.io for the transport

00:07:04.640 --> 00:07:06.880
because it will provide
you web socket, which

00:07:06.880 --> 00:07:09.370
is the best solution out
there when it's available

00:07:09.370 --> 00:07:13.170
and implement or fall back
to XHR and other solutions

00:07:13.170 --> 00:07:14.110
when it's not, right?

00:07:14.110 --> 00:07:16.780
So it's completely transparent,
and it's fantastic.

00:07:16.780 --> 00:07:19.330
The problem is it
doesn't scale across CPU.

00:07:19.330 --> 00:07:23.360
So if you go for one of those
big instances like the 8XL

00:07:23.360 --> 00:07:25.700
and you have 32
CPU, well, you're

00:07:25.700 --> 00:07:27.110
going to use only one CPU.

00:07:27.110 --> 00:07:28.710
So you get the
bandwidth, but you're

00:07:28.710 --> 00:07:34.020
wasting most of your CPU power.

00:07:34.020 --> 00:07:35.760
Horizontal scalability
is a problem.

00:07:35.760 --> 00:07:37.560
Everybody that play
video games know that.

00:07:37.560 --> 00:07:39.896
You have to connect to the
same server as your friend

00:07:39.896 --> 00:07:41.520
if you want to play
with them, so there

00:07:41.520 --> 00:07:43.120
is a limit that is per server.

00:07:43.120 --> 00:07:47.020
What do you do when you want to
have people that are chatting

00:07:47.020 --> 00:07:50.610
in the same room but spread
across different servers

00:07:50.610 --> 00:07:51.590
on your infrastructure?

00:07:51.590 --> 00:07:53.790
That's horizontal scalability.

00:07:53.790 --> 00:07:55.950
And finally, Node
fails often, so you

00:07:55.950 --> 00:07:57.990
need to find a way
to address that

00:07:57.990 --> 00:08:00.120
and to handle the
downtime when you want

00:08:00.120 --> 00:08:02.210
to upgrade your back
end, for example.

00:08:02.210 --> 00:08:03.860
So let's go into that.

00:08:03.860 --> 00:08:08.302
Socket.io look 0.9
scales using a store.

00:08:08.302 --> 00:08:09.760
So for example, we
use Redis, and I

00:08:09.760 --> 00:08:14.060
think that that's the best
way to achieve a low latency.

00:08:14.060 --> 00:08:17.140
But the problem is the store
replicates the data object,

00:08:17.140 --> 00:08:19.650
so then all the
instances of nodes

00:08:19.650 --> 00:08:22.920
using that store will
try to do the same thing.

00:08:22.920 --> 00:08:25.050
So you're not CPU scaling.

00:08:25.050 --> 00:08:28.270
You just replicate the load on
every single one of your core.

00:08:28.270 --> 00:08:30.590
So you do several
times the same thing.

00:08:30.590 --> 00:08:35.309
So Socket.io 1.x specifically
addresses that problem.

00:08:35.309 --> 00:08:36.799
It change the way
the store works.

00:08:36.799 --> 00:08:39.580
It's going to use the same
store as an event bus.

00:08:39.580 --> 00:08:43.230
So each instance run
independently of each other,

00:08:43.230 --> 00:08:45.892
and it's only handling the
clients connected to them.

00:08:45.892 --> 00:08:49.920
That being said, they still
only send to all the events,

00:08:49.920 --> 00:08:53.110
so two clients can be
connected to separate instances

00:08:53.110 --> 00:08:56.460
and still speak to each other
through the signaling server.

00:08:56.460 --> 00:09:02.700
So it's Socket.io 1.0 solved the
horizontal scalability and CPU

00:09:02.700 --> 00:09:06.716
scalability problem if you
have a Node.js problem.

00:09:09.670 --> 00:09:11.390
The horizontal
scalability can even

00:09:11.390 --> 00:09:13.810
be improved by using the
business, as you heard.

00:09:13.810 --> 00:09:16.670
We use proxy load, but
everybody that has a website

00:09:16.670 --> 00:09:18.170
and has a load is using that.

00:09:18.170 --> 00:09:20.250
So just to mention,
you can also improve

00:09:20.250 --> 00:09:25.260
by just putting a NGINX or
HA high-availability reverse

00:09:25.260 --> 00:09:28.230
proxy in front of everything.

00:09:28.230 --> 00:09:29.660
Node zombification.

00:09:29.660 --> 00:09:32.650
So the problem with Node is
it's failing quite often.

00:09:32.650 --> 00:09:34.480
And you have to
be careful and be

00:09:34.480 --> 00:09:37.790
able to detect not only when
it fails to bring it back,

00:09:37.790 --> 00:09:40.130
but also sometimes when you
have a new version that you

00:09:40.130 --> 00:09:42.500
want to deploy in
your infrastructure,

00:09:42.500 --> 00:09:46.270
you don't want to take the
infrastructure down and cut

00:09:46.270 --> 00:09:48.550
existing conversation,
for example,

00:09:48.550 --> 00:09:50.030
time for the deployment.

00:09:50.030 --> 00:09:53.990
So there are a few Node
modules that are good for that.

00:09:53.990 --> 00:09:56.910
There is a Node Cluster
API, which is nice.

00:09:56.910 --> 00:09:58.270
There is forever.

00:09:58.270 --> 00:10:00.620
Not forever, but
actually going to monitor

00:10:00.620 --> 00:10:03.890
every instance of Node
running and bring them

00:10:03.890 --> 00:10:06.797
back up if they fail or
terminate by themselves.

00:10:06.797 --> 00:10:08.380
But there is a new
one which is called

00:10:08.380 --> 00:10:10.840
PM2, which is even
better than that.

00:10:10.840 --> 00:10:15.180
It does keep alive clustering
and load balancing at the OS

00:10:15.180 --> 00:10:18.600
level, not at the instance
level-- log aggregation,

00:10:18.600 --> 00:10:21.380
terminal monitoring,
and a lot of other magic

00:10:21.380 --> 00:10:23.940
that's going to make your
life much, much, much easier.

00:10:26.850 --> 00:10:29.260
So there are other
things to consider

00:10:29.260 --> 00:10:31.580
when you think about a
WebRTC infrastructure,

00:10:31.580 --> 00:10:35.180
even though the scalability is
really, really the pain point.

00:10:35.180 --> 00:10:38.410
Scalability for the signaling
server like I presented to you

00:10:38.410 --> 00:10:40.430
is one way to approach
it, but you're not

00:10:40.430 --> 00:10:43.895
going to scale a media
server-- an MCU-- the same way.

00:10:43.895 --> 00:10:45.770
Because it's going to
be bandwidth intensive,

00:10:45.770 --> 00:10:47.890
because it's going
to be CPU intensive,

00:10:47.890 --> 00:10:50.540
so every single piece
of your infrastructure

00:10:50.540 --> 00:10:52.910
will have to have a
different way of addressing

00:10:52.910 --> 00:10:54.700
the scalability
issue and you still

00:10:54.700 --> 00:10:58.890
need to keep the entire
infrastructure coherent, right?

00:10:58.890 --> 00:11:02.750
So that's where the
difficulty resides.

00:11:02.750 --> 00:11:05.000
You want to be careful
about session management,

00:11:05.000 --> 00:11:07.440
authentication, usage
payments, but there

00:11:07.440 --> 00:11:09.670
are a lot of usual
solutions that

00:11:09.670 --> 00:11:13.185
exist for that in the
ecosystem that you can take out

00:11:13.185 --> 00:11:14.560
of the shells,
and you don't need

00:11:14.560 --> 00:11:17.620
to make different for WebRTC.

00:11:17.620 --> 00:11:21.230
Now if you really, really want
to go into the difficult part,

00:11:21.230 --> 00:11:26.250
TURN server can be
difficult to load balance.

00:11:26.250 --> 00:11:30.600
When you use appRTC, it's
done a very smart way behind

00:11:30.600 --> 00:11:34.100
to put the secret
outside the website,

00:11:34.100 --> 00:11:36.580
have security and load
balancing at the same time you

00:11:36.580 --> 00:11:37.690
don't see it.

00:11:37.690 --> 00:11:39.401
And the source code
for that has not

00:11:39.401 --> 00:11:41.650
been made available, so be
careful for when you go out

00:11:41.650 --> 00:11:42.970
of appRTC.

00:11:42.970 --> 00:11:44.690
You will have to replicate that.

00:11:44.690 --> 00:11:46.271
And MCUs are really
the things that

00:11:46.271 --> 00:11:48.020
are going to make a
difference if you want

00:11:48.020 --> 00:11:50.710
to have more people
in a given conference,

00:11:50.710 --> 00:11:54.300
and they don't
scale the same way.

00:11:54.300 --> 00:11:54.800
There it is.

00:12:00.543 --> 00:12:05.980
[APPLAUSE]

00:12:05.980 --> 00:12:07.911
I don't know if
we have time left.

00:12:07.911 --> 00:12:09.660
But apparently, there
is nobody behind me,

00:12:09.660 --> 00:12:11.850
so if anybody has
questions, they're welcome.

00:12:20.051 --> 00:12:20.550
Questions?

00:12:23.780 --> 00:12:27.900
Is the middleware to handle
TURN server load balancing

00:12:27.900 --> 00:12:29.314
going to be made available?

00:12:29.314 --> 00:12:31.230
JUSTIN UBERTI: Yeah, it
actually is available.

00:12:31.230 --> 00:12:32.858
ALEX GOUAILLARD: The COE TURN?

00:12:32.858 --> 00:12:35.348
JUSTIN UBERTI: Yeah, the
Compute Engine on Demand.

00:12:35.348 --> 00:12:37.838
And I think that's
actually been open sourced.

00:12:37.838 --> 00:12:39.581
I'll talk about that
more a little later

00:12:39.581 --> 00:12:40.328
because I want to address--

00:12:40.328 --> 00:12:41.161
[INTERPOSING VOICES]

00:12:53.430 --> 00:12:56.926
ALEX GOUAILLARD: So Justin
Uberti, tech lead for Google.

00:12:56.926 --> 00:12:59.352
JUSTIN UBERTI: A [INAUDIBLE]
walks into a bar--

00:12:59.352 --> 00:13:02.330
[LAUGHTER]

00:13:02.330 --> 00:13:05.720
Just responding to
the-- we have a thing

00:13:05.720 --> 00:13:08.490
called-- it's Compute Engine
on Demand, which actually

00:13:08.490 --> 00:13:11.770
is like a service that runs
on App Engine that spools up

00:13:11.770 --> 00:13:15.510
TURN servers running on
Compute Engine on demand.

00:13:15.510 --> 00:13:17.330
And we have that code.

00:13:17.330 --> 00:13:19.390
It's actually open sourced.

00:13:19.390 --> 00:13:22.540
I'll go find a link to
it so that the things

00:13:22.540 --> 00:13:25.710
that-- the secret sauce
that Alex is referring to,

00:13:25.710 --> 00:13:30.560
we can make it unsecret.

00:13:30.560 --> 00:13:35.760
Alex also mentioned some
issues with the actual Channel

00:13:35.760 --> 00:13:38.030
API and message delivery.

00:13:38.030 --> 00:13:41.920
This has been a recurring
nightmare for us as well.

00:13:41.920 --> 00:13:44.320
This stuff is all getting
gutted, burned with fire,

00:13:44.320 --> 00:13:47.090
and rewritten so that it
is going to be actually

00:13:47.090 --> 00:13:50.060
appropriately industrial
strength based on Memecache,

00:13:50.060 --> 00:13:51.620
and we hope to have that soon.

00:13:51.620 --> 00:13:53.660
I'll talk more about that later.

00:13:53.660 --> 00:13:55.010
ALEX GOUAILLARD: All right.

00:13:55.010 --> 00:13:58.270
And GAE API for mobile, so I
don't have to put a webview

00:13:58.270 --> 00:14:00.247
with a hack on [INAUDIBLE]
to be able to--

00:14:00.247 --> 00:14:02.580
AUDIENCE: We'll have the
chance to ask questions, later.

00:14:02.580 --> 00:14:04.380
ALEX GOUAILLARD:
OK, fair enough.

