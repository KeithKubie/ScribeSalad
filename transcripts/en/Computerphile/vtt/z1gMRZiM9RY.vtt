WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.709
AI has become quite prevalent

00:00:01.709 --> 00:00:04.170
these days. I mean we see mobile apps

00:00:04.170 --> 00:00:05.970
telling you to point your phone at your

00:00:05.970 --> 00:00:07.799
kind of code, got a magazine or something

00:00:07.800 --> 00:00:09.591
like that.

00:00:11.000 --> 00:00:12.200
All these solutions are

00:00:12.210 --> 00:00:14.340
basically using computer vision and your

00:00:14.340 --> 00:00:16.440
phone camera. All they're really doing is

00:00:16.440 --> 00:00:20.939
recognizing a picture, so ideally a 2D

00:00:20.939 --> 00:00:22.769
image, but they can extrapolate from that.

00:00:22.769 --> 00:00:24.420
Once they recognize the image they can

00:00:24.420 --> 00:00:26.039
get its position in space and its

00:00:26.039 --> 00:00:28.619
orientation and then just tie virtual

00:00:28.619 --> 00:00:30.510
content to it. Right? Now the problem with that is,

00:00:30.510 --> 00:00:32.820
it looks pretty impressive, but

00:00:32.820 --> 00:00:34.350
they don't actually ,these systems,

00:00:34.350 --> 00:00:37.079
understand the environment around them.

00:00:37.079 --> 00:00:39.450
It doesn't know that this is a card, it

00:00:39.450 --> 00:00:41.280
doesn't know that I'm holding it in my hand

00:00:41.280 --> 00:00:43.050
or anything like that. So it might put my

00:00:43.050 --> 00:00:45.149
hand in front of it. If it can still see

00:00:45.149 --> 00:00:46.680
part of the card or anything like that,

00:00:46.680 --> 00:00:48.840
it will keep drawing the content above

00:00:48.840 --> 00:00:51.329
my hand and the illusion is very easy

00:00:51.329 --> 00:00:53.820
to break with these things. That's because we, you know, the

00:00:53.820 --> 00:00:56.070
same as the depth problem but we see in computer

00:00:56.070 --> 00:00:58.710
graphics before. Exactly yes, and also

00:00:58.710 --> 00:01:00.872
it limits the kinds of things you can do.

00:01:00.872 --> 00:01:02.520
If all it really understands is

00:01:02.520 --> 00:01:03.989
ok I've seen this thing I know my

00:01:03.989 --> 00:01:07.799
position in space. It quickly limits the...

00:01:07.799 --> 00:01:09.240
the things you can do with physics

00:01:09.240 --> 00:01:11.280
or moving about you're tired of looking at

00:01:11.280 --> 00:01:13.409
that mark and maybe moving a little bit

00:01:13.409 --> 00:01:15.210
off it with optical flow as we discuss

00:01:15.210 --> 00:01:16.740
another time. The thing is that there are

00:01:16.740 --> 00:01:18.540
ready solutions that are trying to deal with this.

00:01:18.540 --> 00:01:21.150
For example there is the Google Tango

00:01:21.150 --> 00:01:22.950
project. which, what they did was this

00:01:22.950 --> 00:01:24.869
group, they looked at the kinect and said

00:01:24.869 --> 00:01:27.540
okay what does the kinect do? It has a

00:01:27.540 --> 00:01:29.130
depth camera it reads the environment

00:01:29.130 --> 00:01:29.579
around it.

00:01:29.579 --> 00:01:31.950
Well, it was designed to read, eh.. to look at

00:01:31.950 --> 00:01:33.689
humans and register what they're doing.

00:01:33.689 --> 00:01:35.430
But it turned out it was pretty good at 3D

00:01:35.430 --> 00:01:37.680
scanning stuff. So they said, alright let's

00:01:37.680 --> 00:01:38.939
strap one of those to back of a

00:01:38.939 --> 00:01:41.340
tablet and they came up with this.

00:01:41.340 --> 00:01:42.990
This is the original Google Tango

00:01:42.990 --> 00:01:45.479
development device. It has on the back of

00:01:45.479 --> 00:01:48.000
it, a laser sensor depth cameras and

00:01:48.000 --> 00:01:49.680
what have you. I believe it's billed as the

00:01:49.680 --> 00:01:53.399
spatially aware tablet. So, it has a very

00:01:53.399 --> 00:01:55.710
good understanding of where it is, its

00:01:55.710 --> 00:01:57.930
orientation, what it's looking at and

00:01:57.930 --> 00:02:01.380
the motion. So what this does is it creates

00:02:01.380 --> 00:02:05.490
a point cloud in pretty much well real time, of

00:02:05.490 --> 00:02:06.840
the environment around it.

00:02:06.840 --> 00:02:09.390
Unlike the previous AI that is

00:02:09.390 --> 00:02:11.190
where we started reading that original

00:02:11.190 --> 00:02:12.810
point where with understanding of the

00:02:12.810 --> 00:02:13.700
environment and

00:02:13.700 --> 00:02:15.379
understanding of the motion of  the tablet, we can

00:02:15.379 --> 00:02:18.500
start tying virtual content to things we

00:02:18.500 --> 00:02:20.930
couldn't before. So, I can put a mesh on

00:02:20.930 --> 00:02:23.239
this floor and it will stay there or I

00:02:23.239 --> 00:02:25.069
can put a piece of sound on the corner

00:02:25.069 --> 00:02:27.080
of this cabinet and whenever I come

00:02:27.080 --> 00:02:30.800
close i'll get to hear the sound. But this is

00:02:30.800 --> 00:02:33.349
now an old device under with about 3-4

00:02:33.349 --> 00:02:35.870
years old and it was only developer

00:02:35.870 --> 00:02:37.940
device. There is actually the first

00:02:37.940 --> 00:02:41.930
commercial device the Lenovo fab2pro

00:02:41.930 --> 00:02:45.049
I believe. It is now looking like a proper

00:02:45.049 --> 00:02:46.880
commercial device horrible case

00:02:46.880 --> 00:02:49.819
notwithstanding and just like the

00:02:49.819 --> 00:02:51.590
developer device it does have an array

00:02:51.590 --> 00:02:52.940
of sensors over here.

00:02:52.940 --> 00:02:54.709
So what can this do let's have a look.

00:02:54.709 --> 00:02:57.620
It is probably my favorite example although

00:02:57.620 --> 00:02:58.849
it's not very exciting.

00:02:58.849 --> 00:03:01.130
We have this plane that is reading the

00:03:01.130 --> 00:03:03.739
environment pretty well and telling me

00:03:03.739 --> 00:03:06.349
what play i'm looking at the green mill

00:03:06.349 --> 00:03:08.090
dog yeah so the green little dot is

00:03:08.090 --> 00:03:10.370
basically the edge detection and this

00:03:10.370 --> 00:03:13.310
playing over here is aligning itself to

00:03:13.310 --> 00:03:14.870
the real world so in this case the table

00:03:14.870 --> 00:03:17.000
there's a lot of whites are playing a

00:03:17.000 --> 00:03:18.560
surface basically that is aligning

00:03:18.560 --> 00:03:19.819
itself to the real world

00:03:19.819 --> 00:03:22.069
I can see that only the edges line up

00:03:22.069 --> 00:03:24.200
with the table and the area near the

00:03:24.200 --> 00:03:26.510
wall ovens and as we go over the floor

00:03:26.510 --> 00:03:29.060
seats of its turnaround and lining it up

00:03:29.060 --> 00:03:30.410
to any surface

00:03:30.410 --> 00:03:33.319
ok yeah so that's all very well but what

00:03:33.319 --> 00:03:35.000
does it actually mean well it means that

00:03:35.000 --> 00:03:38.810
i can go and understand the real world

00:03:38.810 --> 00:03:39.709
so there we go

00:03:39.709 --> 00:03:42.109
ok let's measure the size of the door

00:03:42.109 --> 00:03:49.040
you're drawing a line

00:03:49.040 --> 00:03:51.769
yeah i'm basically using a measuring

00:03:51.769 --> 00:03:56.540
tape and there we have it so there are

00:03:56.540 --> 00:03:58.220
essentially two market on this you can

00:03:58.220 --> 00:04:00.200
see how with an understanding of the

00:04:00.200 --> 00:04:02.299
space around it can actually start

00:04:02.299 --> 00:04:05.060
measuring as well so we could go around

00:04:05.060 --> 00:04:07.370
this room taking measurements and end up

00:04:07.370 --> 00:04:09.139
with an architectural floor pan

00:04:09.139 --> 00:04:12.380
I mean that is one of the use cases you

00:04:12.380 --> 00:04:15.139
know they felt safe agents real estate

00:04:15.139 --> 00:04:18.079
yeah it has it already though we've been

00:04:18.079 --> 00:04:20.660
using it to create basic floor plans and

00:04:20.660 --> 00:04:22.340
3d model that they'll just checking the

00:04:22.340 --> 00:04:24.050
website with a better understanding of

00:04:24.050 --> 00:04:27.020
what is what the environment Uranus

00:04:27.020 --> 00:04:29.300
populated with and how the cameras

00:04:29.300 --> 00:04:31.129
moving about you can start doing way

00:04:31.129 --> 00:04:32.419
more interesting things such as

00:04:32.419 --> 00:04:35.330
populating the environment around you

00:04:35.330 --> 00:04:36.889
with your own virtual content or

00:04:36.889 --> 00:04:38.449
whatever you might want to see so this

00:04:38.449 --> 00:04:41.569
is the Augmented camera application and

00:04:41.569 --> 00:04:43.280
what is a normal camera application but

00:04:43.280 --> 00:04:45.620
again with that whole understanding of

00:04:45.620 --> 00:04:46.970
the environment things we can start

00:04:46.970 --> 00:04:49.759
putting virtual content inside it so in

00:04:49.759 --> 00:04:52.340
this case we can put a cat where would

00:04:52.340 --> 00:04:53.780
you normally have a cat

00:04:53.780 --> 00:04:57.440
let's see here oh oh there it is

00:04:57.440 --> 00:05:00.949
reflected on the floor there and we have

00:05:00.949 --> 00:05:02.690
a cat that is standing on the floor

00:05:02.690 --> 00:05:05.150
playing on the floor with thing of the

00:05:05.150 --> 00:05:06.860
devices and understanding of what floor

00:05:06.860 --> 00:05:11.419
is and I guess we can also use a laser

00:05:11.419 --> 00:05:15.530
pointer or where we cannot all of that

00:05:15.530 --> 00:05:17.780
is that it should when it sees it up

00:05:17.780 --> 00:05:22.849
there definitely not acting like him cat

00:05:22.849 --> 00:05:28.610
I know to be honest but down the fish so

00:05:28.610 --> 00:05:30.440
that's fine it's recognized the floor

00:05:30.440 --> 00:05:31.729
and we have a cat playing on the floor

00:05:31.729 --> 00:05:33.979
but maybe we can get it up onto another

00:05:33.979 --> 00:05:35.870
surface that is recognized like say the

00:05:35.870 --> 00:05:38.210
table and gets the difference between

00:05:38.210 --> 00:05:40.940
the floor down there and the top of the

00:05:40.940 --> 00:05:42.680
table but and it's jumped off the table

00:05:42.680 --> 00:05:45.590
with a traditional AR application that

00:05:45.590 --> 00:05:48.110
was just using a marker to do that it

00:05:48.110 --> 00:05:49.159
would have an understanding of that it

00:05:49.159 --> 00:05:50.750
would just be doing everything in

00:05:50.750 --> 00:05:52.219
relation to that market whether we had

00:05:52.219 --> 00:05:53.389
on the floor in the table

00:05:53.389 --> 00:05:55.909
it wouldn't matter this now is were

00:05:55.909 --> 00:05:57.889
actually having lied i went to

00:05:57.889 --> 00:05:59.900
intelligence content in this case

00:05:59.900 --> 00:06:03.380
populating space are real space the

00:06:03.380 --> 00:06:04.940
objects that we use every day you can

00:06:04.940 --> 00:06:07.190
see how this could end up being

00:06:07.190 --> 00:06:08.659
something a bit more exciting in fact we

00:06:08.659 --> 00:06:10.819
do have something to show for that one

00:06:10.819 --> 00:06:14.719
of these so this is the max of holland

00:06:14.719 --> 00:06:17.150
same principle that strapped to your

00:06:17.150 --> 00:06:17.930
face

00:06:17.930 --> 00:06:22.550
so as you can see in has again it's

00:06:22.550 --> 00:06:25.550
pretty much a connect all across the top

00:06:25.550 --> 00:06:27.710
over here right this is the proper

00:06:27.710 --> 00:06:29.419
heads-up display on say something

00:06:29.419 --> 00:06:32.060
earlier endeavors like the google glass

00:06:32.060 --> 00:06:33.949
which is simply just the screen off to

00:06:33.949 --> 00:06:37.130
the side which didn't cover your normal

00:06:37.130 --> 00:06:39.750
vision with ottoman content but this is

00:06:39.750 --> 00:06:42.860
yeah I see the real deal

00:06:44.070 --> 00:06:46.740
this is the wall I don't want to make

00:06:46.740 --> 00:06:49.770
that claim by upset start from a lot of

00:06:49.770 --> 00:06:51.510
the stuff I've tried this is probably

00:06:51.510 --> 00:06:54.600
the one that gets it does in fact i can

00:06:54.600 --> 00:06:57.650
show you a bit more than

