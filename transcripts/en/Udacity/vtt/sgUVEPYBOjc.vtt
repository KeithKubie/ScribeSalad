WEBVTT
Kind: captions
Language: en

00:00:00.210 --> 00:00:02.930
We are now entering the modeling phase.

00:00:02.930 --> 00:00:06.170
Let's switch back to the iPython Notebook.

00:00:06.170 --> 00:00:11.780
To recall briefly we had chosen person 1 as B and person 2 as F.

00:00:11.780 --> 00:00:16.260
And we are going to classify them according to their location patterns.

00:00:16.260 --> 00:00:21.060
We did a final sanity check to ensure that the features chosen actually seem to

00:00:21.060 --> 00:00:22.790
have discriminating power.

00:00:22.790 --> 00:00:25.700
At this point let's run this piece of code.

00:00:25.700 --> 00:00:30.720
What it does is, it fills an array named classification_events with

00:00:30.720 --> 00:00:34.460
the events of person B and person F.

00:00:34.460 --> 00:00:39.630
We are now going to split the data in a training set and a test set.

00:00:39.630 --> 00:00:45.420
In this case we are going to use 60% of the data on training, and 40% on test.

00:00:45.420 --> 00:00:49.700
Let's go ahead and do that first.

00:00:49.700 --> 00:00:54.870
At this point, we have split the data into training and test sets.

00:00:54.870 --> 00:00:57.840
We are using a large portion of the data for

00:00:57.840 --> 00:01:04.040
testing, as we will be illustrating several validation matrix on the test data.

00:01:04.040 --> 00:01:05.810
Just as a sanity check.

00:01:05.810 --> 00:01:10.390
We want to plot our features within our training data.

00:01:10.390 --> 00:01:14.520
Once you have run the above code, you should get histograms for

00:01:14.520 --> 00:01:19.770
the distribution of different distances at a certain time for each person.

00:01:19.770 --> 00:01:24.180
Remember we wanted to make three different classifiers.

00:01:24.180 --> 00:01:27.340
To do so we have now split our data set.

00:01:27.340 --> 00:01:29.840
Into the training and the test set.

00:01:29.840 --> 00:01:31.690
We also asked a quick question.

00:01:31.690 --> 00:01:35.640
Are the features different enough in the training data set?

00:01:35.640 --> 00:01:40.720
We validated that again by looking at the histogram of the different features.

00:01:40.720 --> 00:01:45.560
So now we are ready to run the three classification models.

00:01:45.560 --> 00:01:48.030
Let's get back to the iPython notebook again.

00:01:49.050 --> 00:01:53.570
In this part of the code, we are setting up the three models for

00:01:53.570 --> 00:01:55.370
our classification problems.

00:01:55.370 --> 00:01:59.220
We are using the sklearns logistic

00:01:59.220 --> 00:02:04.170
regression support vector classifier and the random forest classifier.

00:02:04.170 --> 00:02:08.820
This method here simply returns the model that we want to train.

00:02:08.820 --> 00:02:10.979
So now let's run this code.

00:02:10.979 --> 00:02:16.350
After you're done with defining the three models, let's simply build the models.

00:02:16.350 --> 00:02:20.540
It's as simple as this one line of code.

00:02:20.540 --> 00:02:21.910
Let's run it.

00:02:21.910 --> 00:02:23.410
And there you have it.

00:02:23.410 --> 00:02:26.470
We have the models built.

00:02:26.470 --> 00:02:31.250
In the following videos we will use some of Sklearn's built in

00:02:31.250 --> 00:02:35.870
model alidation metrics to give us the performance of these models.

00:02:35.870 --> 00:02:40.020
Before that, let us define some of the quantities we might want to

00:02:40.020 --> 00:02:44.100
look at,when evaluating the performance of classifiers

