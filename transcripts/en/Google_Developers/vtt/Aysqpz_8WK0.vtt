WEBVTT
Kind: captions
Language: en

00:00:01.510 --> 00:00:02.750
TOBY SMITH: Hi, everybody.

00:00:02.750 --> 00:00:04.890
Welcome to Taming Your
Cloud Applications

00:00:04.890 --> 00:00:06.270
with Intelligent Monitoring.

00:00:06.270 --> 00:00:09.720
We're glad you
could make it today.

00:00:09.720 --> 00:00:10.560
My name's Toby.

00:00:10.560 --> 00:00:12.850
I'm an engineering
lead here at Google.

00:00:12.850 --> 00:00:15.652
I work on cloud logging,
monitoring, and alerting

00:00:15.652 --> 00:00:16.860
DAN BELCHER: Hello, everyone.

00:00:16.860 --> 00:00:17.740
I'm Dan Belcher.

00:00:17.740 --> 00:00:20.660
I'm a product manager
on the same team.

00:00:20.660 --> 00:00:22.820
I'm what they call a
noogler because I started

00:00:22.820 --> 00:00:24.970
at the company just
last month, when

00:00:24.970 --> 00:00:27.020
a company that I had
co-founded, called

00:00:27.020 --> 00:00:28.844
Stackdriver became
part of Google.

00:00:28.844 --> 00:00:30.760
TOBY SMITH: Super happy
to have you here, Dan.

00:00:30.760 --> 00:00:32.924
DAN BELCHER: Thanks, Toby.

00:00:32.924 --> 00:00:33.840
TOBY SMITH: All right.

00:00:33.840 --> 00:00:36.430
So if you've ever developed
any sort of application

00:00:36.430 --> 00:00:38.830
and you've had any
user base whatsoever,

00:00:38.830 --> 00:00:42.140
there's probably a time
when you've had this moment.

00:00:42.140 --> 00:00:44.640
That awful sort of,
oh crap, feeling

00:00:44.640 --> 00:00:47.090
that accompanies
that recognition

00:00:47.090 --> 00:00:48.970
that your users figured
out an awful problem

00:00:48.970 --> 00:00:50.050
with your application.

00:00:50.050 --> 00:00:53.532
And you had no idea
it was going on.

00:00:53.532 --> 00:00:54.240
You're not alone.

00:00:54.240 --> 00:00:56.490
Pretty much everyone
who develops anything

00:00:56.490 --> 00:00:58.602
has been in this boat
at one point or another.

00:00:58.602 --> 00:01:00.310
But sure it sure
doesn't make it any fun.

00:01:03.260 --> 00:01:06.390
When it happens, you're kind
of pulling your hair out.

00:01:06.390 --> 00:01:11.230
And as you can tell, I must have
been in these situations a lot.

00:01:11.230 --> 00:01:13.217
Because you already
have a full-time job,

00:01:13.217 --> 00:01:15.300
you're just trying to
develop the world's greatest

00:01:15.300 --> 00:01:16.350
application.

00:01:16.350 --> 00:01:18.255
And now suddenly you
have two or three jobs.

00:01:18.255 --> 00:01:20.380
You're still trying to
develop the world's greatest

00:01:20.380 --> 00:01:21.620
application.

00:01:21.620 --> 00:01:23.570
But now you're trying
to fix that critical bug

00:01:23.570 --> 00:01:26.750
that your users were so
helpful in helping you find.

00:01:26.750 --> 00:01:28.280
Thank you, users.

00:01:28.280 --> 00:01:32.220
And if it's just you and another
person, like maybe me and Dan,

00:01:32.220 --> 00:01:34.950
well you might be on the
hook for sending email

00:01:34.950 --> 00:01:37.660
and apologies,
writing blog posts,

00:01:37.660 --> 00:01:41.040
maybe even calling up customers
and saying, hey, we're on it.

00:01:41.040 --> 00:01:41.660
We have this.

00:01:41.660 --> 00:01:42.909
We're going to fix it for you.

00:01:42.909 --> 00:01:44.454
You totally don't
need to go look

00:01:44.454 --> 00:01:46.245
at the world's second
greatest application.

00:01:49.840 --> 00:01:51.280
Why does this happen?

00:01:51.280 --> 00:01:53.960
It doesn't need to,
especially in the cloud.

00:01:53.960 --> 00:01:57.210
We have all sorts of information
about how applications behave

00:01:57.210 --> 00:02:00.020
that can help save you
from this sort of thing.

00:02:00.020 --> 00:02:02.547
That sounds nice, but
it's not always that easy.

00:02:02.547 --> 00:02:04.380
So first of all, just
a quick show of hands.

00:02:04.380 --> 00:02:06.530
How many of you here
are completely new

00:02:06.530 --> 00:02:10.250
to cloud development,
have never done it before?

00:02:10.250 --> 00:02:10.820
All right.

00:02:10.820 --> 00:02:12.070
There's only a handful of you.

00:02:12.070 --> 00:02:13.140
That's fantastic.

00:02:13.140 --> 00:02:16.580
And we welcome you to
the cloud sometime soon.

00:02:16.580 --> 00:02:18.960
But if you are coming from
a more traditional sort

00:02:18.960 --> 00:02:21.380
of application
development environment,

00:02:21.380 --> 00:02:24.055
you might be used to a world
where you write your code.

00:02:24.055 --> 00:02:25.680
You test the hell
out of it because you

00:02:25.680 --> 00:02:27.346
want to make sure
you're giving the best

00:02:27.346 --> 00:02:29.320
product to the customer
that you possibly can.

00:02:29.320 --> 00:02:30.300
But at some point,
you just kind of

00:02:30.300 --> 00:02:31.460
have to throw it over the wall.

00:02:31.460 --> 00:02:33.220
You have to package it
up and ship it out there.

00:02:33.220 --> 00:02:34.000
Someone buys it.

00:02:34.000 --> 00:02:35.930
They install it on
a computer that you

00:02:35.930 --> 00:02:39.380
have absolutely no
visibility into.

00:02:39.380 --> 00:02:41.550
When that happens,
you're just left

00:02:41.550 --> 00:02:44.147
wondering how your application's
behaving in the wild.

00:02:44.147 --> 00:02:46.230
And if that's the environment
that you're used to,

00:02:46.230 --> 00:02:47.840
you might not have
any expectation

00:02:47.840 --> 00:02:49.510
that there is more
to be learned,

00:02:49.510 --> 00:02:51.580
that there is logging and
monitoring information

00:02:51.580 --> 00:02:53.410
about your live
running applications

00:02:53.410 --> 00:02:55.490
that you could have.

00:02:55.490 --> 00:02:57.160
So I guess the
rest of you are all

00:02:57.160 --> 00:02:59.910
die hard cloud developers who
have been around the block

00:02:59.910 --> 00:03:02.090
for a few years.

00:03:02.090 --> 00:03:04.150
You folks might have
a different sort

00:03:04.150 --> 00:03:06.940
of perspective on what's
available out there.

00:03:06.940 --> 00:03:08.860
There's a lot of
really great vendors

00:03:08.860 --> 00:03:11.170
doing fantastic
things in the logging,

00:03:11.170 --> 00:03:13.610
monitoring, and alerting spaces.

00:03:13.610 --> 00:03:16.120
But you have to go
out and find them.

00:03:16.120 --> 00:03:18.150
You have to do some research.

00:03:18.150 --> 00:03:19.880
You have to understand
what's available.

00:03:19.880 --> 00:03:21.930
You have to pick and
choose from this a la carte

00:03:21.930 --> 00:03:24.220
sort of offering,
instead of just

00:03:24.220 --> 00:03:25.910
being able to rely
on your platform

00:03:25.910 --> 00:03:28.990
to provide a single pane of
glass to the core functionality

00:03:28.990 --> 00:03:30.915
that your application needs.

00:03:30.915 --> 00:03:32.587
Wouldn't it be nice
if something just

00:03:32.587 --> 00:03:33.795
gave you that out of the box?

00:03:36.570 --> 00:03:37.500
We agree.

00:03:37.500 --> 00:03:39.630
We think that it should
be easier than this.

00:03:39.630 --> 00:03:41.630
And so that's why we're
so excited to be talking

00:03:41.630 --> 00:03:44.150
to you about Google
Cloud Monitoring today.

00:03:44.150 --> 00:03:46.100
With Google Cloud
Monitoring you don't even

00:03:46.100 --> 00:03:47.300
need to know it exists.

00:03:47.300 --> 00:03:49.008
If you're just getting
started and you're

00:03:49.008 --> 00:03:51.150
coming from a more
traditional background,

00:03:51.150 --> 00:03:53.799
you might not even think,
oh, I need to set up logging.

00:03:53.799 --> 00:03:55.590
Oh, I need to set up
monitoring because I'm

00:03:55.590 --> 00:03:56.940
going to care about it later.

00:03:56.940 --> 00:03:58.160
We do that for you.

00:03:58.160 --> 00:04:01.190
So when you do care about
it, the data's there for you.

00:04:01.190 --> 00:04:02.780
But we're also able
to grow with you.

00:04:02.780 --> 00:04:04.350
If you're more
sophisticated and you've

00:04:04.350 --> 00:04:06.308
been looking at other
vendors, and maybe you're

00:04:06.308 --> 00:04:08.329
even using some
of them today, we

00:04:08.329 --> 00:04:10.120
can give you some of
the core functionality

00:04:10.120 --> 00:04:12.620
that you need without ever
leaving the Google Cloud

00:04:12.620 --> 00:04:13.691
Platform sandbox.

00:04:13.691 --> 00:04:15.940
You get all the information
about how your application

00:04:15.940 --> 00:04:17.564
is behaving in one place.

00:04:21.019 --> 00:04:22.690
That's why I'm super
excited that Dan's

00:04:22.690 --> 00:04:24.290
up here on stage with me.

00:04:24.290 --> 00:04:26.710
He and his team with
Stackdriver developed

00:04:26.710 --> 00:04:29.680
a world class cloud
monitoring application.

00:04:29.680 --> 00:04:32.080
And now they're bringing
their real world experience,

00:04:32.080 --> 00:04:35.840
their domain expertise, and
most of all a fantastic product

00:04:35.840 --> 00:04:37.550
to Google Cloud Monitoring.

00:04:37.550 --> 00:04:39.370
They really form
the pillar of what

00:04:39.370 --> 00:04:41.420
we're going to be
talking about today.

00:04:41.420 --> 00:04:44.590
And with Stackdriver and
with Google Cloud Platform

00:04:44.590 --> 00:04:46.500
you can go from knowing
absolutely nothing

00:04:46.500 --> 00:04:49.130
about logging and
monitoring to setting up

00:04:49.130 --> 00:04:52.760
sophisticated dashboards
and alerts in no time.

00:04:52.760 --> 00:04:54.430
Dan's going to talk
a little bit more

00:04:54.430 --> 00:04:56.630
about the types of
data we get together

00:04:56.630 --> 00:04:59.930
and give to you to help you
understand your applications.

00:04:59.930 --> 00:05:01.200
DAN BELCHER: Thank you, Toby.

00:05:01.200 --> 00:05:03.330
so this is all about visibility.

00:05:03.330 --> 00:05:05.840
And so what we set out to
do is give you visibility

00:05:05.840 --> 00:05:11.370
into your entire application
stack running on the platform.

00:05:11.370 --> 00:05:14.740
And just a quick overview,
in terms of how it works.

00:05:14.740 --> 00:05:17.970
So we think of the application
stack in three layers.

00:05:17.970 --> 00:05:20.480
The first layer of the
application stack at the base

00:05:20.480 --> 00:05:22.250
is the cloud platform itself.

00:05:22.250 --> 00:05:24.890
If you're using App Engine, if
you're using Compute Engine,

00:05:24.890 --> 00:05:28.800
Cloud SQL, Cloud
Pub, and so forth.

00:05:28.800 --> 00:05:31.480
And so that's the bottom
layer in the stack.

00:05:31.480 --> 00:05:33.230
On top of that you
have the systems layer.

00:05:33.230 --> 00:05:33.730
Right.

00:05:33.730 --> 00:05:35.480
So these are
typically VMs running

00:05:35.480 --> 00:05:37.990
in Google Compute,
where historically it's

00:05:37.990 --> 00:05:40.660
been difficult to get really
good information in terms

00:05:40.660 --> 00:05:42.940
of the performance
of VMs themselves.

00:05:42.940 --> 00:05:44.500
And whether it's
Windows or Linux,

00:05:44.500 --> 00:05:47.230
we support a variety
of operating system.

00:05:47.230 --> 00:05:51.450
And we have an agent that we
use to integrate with the VMs.

00:05:51.450 --> 00:05:54.130
And then on top of that you
have your application stack.

00:05:54.130 --> 00:05:56.100
For the many of you who
have been developing

00:05:56.100 --> 00:05:58.000
in the cloud for
some time, you're

00:05:58.000 --> 00:06:00.190
probably using one or
more of these components,

00:06:00.190 --> 00:06:04.125
whether it's Redis or Nginx
or Apache or Cassandra

00:06:04.125 --> 00:06:06.220
or Elasticsearch, and so forth.

00:06:06.220 --> 00:06:09.080
And we use the agent
framework to integrate

00:06:09.080 --> 00:06:11.950
with those services natively.

00:06:11.950 --> 00:06:15.670
So we are able to monitor
those services as well.

00:06:15.670 --> 00:06:17.330
And when we think
about giving you

00:06:17.330 --> 00:06:19.080
visibility, what that
really comes down to

00:06:19.080 --> 00:06:22.710
is log data, metric
data, and metadata.

00:06:22.710 --> 00:06:25.530
So we're capturing all
this data from all three

00:06:25.530 --> 00:06:26.680
layers of the application.

00:06:26.680 --> 00:06:29.660
We're storing it in
massively scalable databases.

00:06:29.660 --> 00:06:32.980
And then we're making
it useful for you.

00:06:32.980 --> 00:06:34.730
And so that starts
with visualization.

00:06:34.730 --> 00:06:38.080
We'll talk a lot about really
rich charting and dashboard

00:06:38.080 --> 00:06:39.640
capabilities here.

00:06:39.640 --> 00:06:42.400
But beyond visualization, if
you're looking at a chart,

00:06:42.400 --> 00:06:44.750
usually you're trying
to analyze the data.

00:06:44.750 --> 00:06:47.010
And so what we've
done is built tools

00:06:47.010 --> 00:06:51.330
into the platform to analyze
the data on your behalf.

00:06:51.330 --> 00:06:54.060
So that's the analysis
capabilities in the product.

00:06:54.060 --> 00:06:56.710
And then finally,
it doesn't really

00:06:56.710 --> 00:06:59.580
help anybody if the
platform discovers an issue

00:06:59.580 --> 00:07:00.950
and you don't know about it.

00:07:00.950 --> 00:07:03.860
And so there's a really
flexible notification framework

00:07:03.860 --> 00:07:05.490
to let you know
when issues occur,

00:07:05.490 --> 00:07:07.990
whether you're at lunch
with your teammates

00:07:07.990 --> 00:07:12.340
or, unfortunately, asleep
at 3 o'clock in the morning.

00:07:12.340 --> 00:07:14.360
So that's how the
system works as a whole.

00:07:14.360 --> 00:07:17.340
We think a lot about the
one or two developers

00:07:17.340 --> 00:07:21.300
working from a home office or
a garage and the experience

00:07:21.300 --> 00:07:23.037
for them getting started.

00:07:23.037 --> 00:07:25.120
And so to illustrate that,
we'll talk a little bit

00:07:25.120 --> 00:07:27.240
about the Walkshare application.

00:07:27.240 --> 00:07:29.100
So this is an
example application

00:07:29.100 --> 00:07:30.930
that you might build some day.

00:07:30.930 --> 00:07:33.720
If you didn't catch
the I/O keynote,

00:07:33.720 --> 00:07:35.920
the Walkshare application
is a simple app

00:07:35.920 --> 00:07:39.037
they basically tracks your
walk around San Francisco,

00:07:39.037 --> 00:07:40.620
for example, and
makes it easy for you

00:07:40.620 --> 00:07:42.840
to share that with friends.

00:07:42.840 --> 00:07:45.830
The Walkshare application
has three App Engine modules,

00:07:45.830 --> 00:07:48.280
and it uses a number
of Google services.

00:07:48.280 --> 00:07:51.600
And what we'll focus on here
is the front end interface that

00:07:51.600 --> 00:07:54.550
connects to a Leaderboard
module on App Engine,

00:07:54.550 --> 00:07:57.540
and then that module itself
connecting to a set of Redis

00:07:57.540 --> 00:08:01.110
nodes, a cluster of Redis
nodes on Google Compute Engine.

00:08:01.110 --> 00:08:02.790
And so we'll use
this as an example

00:08:02.790 --> 00:08:07.230
of how you can get going with
cloud logging and monitoring.

00:08:07.230 --> 00:08:09.636
So in terms of this
App Engine module,

00:08:09.636 --> 00:08:11.260
the Leaderboard
Module, the first thing

00:08:11.260 --> 00:08:13.250
that you might want
to ask yourself is,

00:08:13.250 --> 00:08:15.630
is it up and running
and available to users?

00:08:15.630 --> 00:08:18.760
And we'll show you how you can
configure endpoint or uptime

00:08:18.760 --> 00:08:22.100
checks to notify you when
it goes down completely

00:08:22.100 --> 00:08:24.930
or when it's
inaccessible to users.

00:08:24.930 --> 00:08:28.770
Then we'll talk about default
dashboard, so dashboards

00:08:28.770 --> 00:08:31.500
and charts that give you
insight into the performance

00:08:31.500 --> 00:08:33.120
of that module.

00:08:33.120 --> 00:08:37.419
We'll talk about how you can use
log data to get to root cause

00:08:37.419 --> 00:08:41.440
and also how you can create
very, very simple alerting

00:08:41.440 --> 00:08:44.781
policies to notify you when
issues occur in the future.

00:08:44.781 --> 00:08:46.060
OK.

00:08:46.060 --> 00:08:48.460
So we'll start with
getting started

00:08:48.460 --> 00:08:51.989
monitoring that module
that's running on App Engine.

00:08:51.989 --> 00:08:53.530
The first thing that
we'll want to do

00:08:53.530 --> 00:08:56.910
is configure an endpoint
check so that we

00:08:56.910 --> 00:09:01.460
know if the Leaderboard is
no longer available at all.

00:09:01.460 --> 00:09:04.900
And so Toby's going to go
to services and endpoints.

00:09:04.900 --> 00:09:07.320
And he'll configure
a check to basically

00:09:07.320 --> 00:09:11.270
connect to a specific
host name every minute

00:09:11.270 --> 00:09:12.850
to poll it every minute.

00:09:12.850 --> 00:09:15.620
And what this is basically
doing is instructing

00:09:15.620 --> 00:09:19.090
our infrastructure of probes
deployed around the world

00:09:19.090 --> 00:09:20.910
to connect to that
host every minute

00:09:20.910 --> 00:09:23.670
and confirm availability.

00:09:23.670 --> 00:09:25.800
So we'll specify a
protocol and a path

00:09:25.800 --> 00:09:27.920
and say that we want it
to happen every minute.

00:09:27.920 --> 00:09:30.224
And Toby will test the
endpoint to be sure

00:09:30.224 --> 00:09:31.140
that we're connecting.

00:09:31.140 --> 00:09:32.494
TOBY SMITH: Huzzah!

00:09:32.494 --> 00:09:34.410
DAN BELCHER: So we had
a successful connection

00:09:34.410 --> 00:09:34.960
in the test.

00:09:34.960 --> 00:09:36.124
And we would save this.

00:09:36.124 --> 00:09:37.290
And now it's up and running.

00:09:37.290 --> 00:09:39.199
That will just keep running.

00:09:39.199 --> 00:09:41.240
And you can see that we
have an existing endpoint

00:09:41.240 --> 00:09:42.590
check in place.

00:09:42.590 --> 00:09:44.750
And for each of
our five regions,

00:09:44.750 --> 00:09:47.770
we are actually
healthy right now.

00:09:47.770 --> 00:09:49.960
So this means that we've
gotten a 200 response

00:09:49.960 --> 00:09:51.660
from each of the regions.

00:09:51.660 --> 00:09:53.610
And we're good to go
from that perspective.

00:09:53.610 --> 00:09:55.435
So we're up and running.

00:09:55.435 --> 00:09:57.560
Next, we'd want to see if
there are any performance

00:09:57.560 --> 00:10:00.610
issues related to the
App Engine module.

00:10:00.610 --> 00:10:03.860
So we'll go to our
App Engine dashboard.

00:10:03.860 --> 00:10:08.190
And this gives us an overview
of the performance for this App

00:10:08.190 --> 00:10:10.166
Engine project.

00:10:10.166 --> 00:10:12.290
And so on the left, you'll
see that the format here

00:10:12.290 --> 00:10:13.990
is of kind of an
operational dashboard.

00:10:13.990 --> 00:10:17.830
So we have key configuration
information on the left

00:10:17.830 --> 00:10:20.460
and then key metrics
on the right.

00:10:20.460 --> 00:10:22.530
And if we scroll down,
looking at the metrics,

00:10:22.530 --> 00:10:27.350
we can see latency, network
I/O, response codes,

00:10:27.350 --> 00:10:28.260
response styles.

00:10:28.260 --> 00:10:30.010
And actually, Toby,
response codes,

00:10:30.010 --> 00:10:32.051
it looks like we have
something interesting here.

00:10:32.051 --> 00:10:33.470
TOBY SMITH: Hold the phone, Dan.

00:10:33.470 --> 00:10:34.220
DAN BELCHER: Yeah.

00:10:34.220 --> 00:10:38.620
So we have what looks like
a spike in 500 errors that

00:10:38.620 --> 00:10:40.500
happened at some point
over the last hour.

00:10:40.500 --> 00:10:44.150
So first I might want to
zoom into that time period.

00:10:44.150 --> 00:10:46.240
So we can just click and
zoom right in the chart.

00:10:46.240 --> 00:10:48.530
And that'll zoom
all of our charts

00:10:48.530 --> 00:10:50.670
into that time period
for the module.

00:10:50.670 --> 00:10:53.080
And so we can see if there
are any correlating issues.

00:10:53.080 --> 00:10:55.940
It looks like there was a
slight increase in latency,

00:10:55.940 --> 00:10:59.570
a little bit more
network load, and again

00:10:59.570 --> 00:11:01.980
this spike in 500 errors.

00:11:01.980 --> 00:11:03.470
So what we don't
know now is which

00:11:03.470 --> 00:11:05.370
module is emitting the errors.

00:11:05.370 --> 00:11:07.990
So we'll click on
the modules tab,

00:11:07.990 --> 00:11:12.970
and we'll see the same
metrics broken out by modules.

00:11:12.970 --> 00:11:15.740
So we can scroll down
to the 500 errors

00:11:15.740 --> 00:11:19.640
and then highlight over the
ones where we see the spike

00:11:19.640 --> 00:11:22.060
and discover that
this is our Redis.

00:11:22.060 --> 00:11:22.560
Module.

00:11:22.560 --> 00:11:23.930
That's the Leaderboard module.

00:11:23.930 --> 00:11:25.763
DAN BELCHER (WHISPERING):
It's always Redis.

00:11:25.763 --> 00:11:27.830
[LAUGHTER]

00:11:27.830 --> 00:11:30.050
DAN BELCHER: It's
not always Redis.

00:11:30.050 --> 00:11:32.150
So this is the
Leaderboard module.

00:11:32.150 --> 00:11:33.650
It looks like there's
an issue here.

00:11:33.650 --> 00:11:35.360
And now we want to try
to get to root cause.

00:11:35.360 --> 00:11:35.859
Right.

00:11:35.859 --> 00:11:37.820
Why are we seeing this
increase in errors?

00:11:37.820 --> 00:11:40.680
And one great way to do that
is to take a look at the logs.

00:11:40.680 --> 00:11:43.450
So we'll go back to
our developers console.

00:11:43.450 --> 00:11:44.846
We'll click on logs.

00:11:44.846 --> 00:11:46.720
And then you'll see that
we bring all the log

00:11:46.720 --> 00:11:50.880
data from our App Engine
projects into a single place.

00:11:50.880 --> 00:11:57.110
And we can filter the module
to only that Redis module.

00:11:57.110 --> 00:12:00.932
And sure enough, we see that
the errors are abundant.

00:12:00.932 --> 00:12:02.390
And Toby, what do
we see if we look

00:12:02.390 --> 00:12:03.922
at the details on this one?

00:12:03.922 --> 00:12:05.220
TOBY SMITH: That we're sad.

00:12:05.220 --> 00:12:06.416
DAN BELCHER: That we're sad.

00:12:06.416 --> 00:12:08.790
TOBY SMITH: Well, it looks
like an invalid password, Dan.

00:12:08.790 --> 00:12:09.748
DAN BELCHER: All right.

00:12:09.748 --> 00:12:11.970
Well, the good news
is we found the issue.

00:12:11.970 --> 00:12:14.670
And also it's a
pretty quick fix.

00:12:14.670 --> 00:12:18.060
What this means is
probably the Redis module

00:12:18.060 --> 00:12:21.289
is having trouble connecting
to the Redis cluster.

00:12:21.289 --> 00:12:22.830
We're using the
wrong password there.

00:12:22.830 --> 00:12:24.770
So maybe one of the teammates
here in the audience

00:12:24.770 --> 00:12:25.311
could fix it.

00:12:25.311 --> 00:12:26.770
But maybe, Toby,
why don't we turn

00:12:26.770 --> 00:12:29.425
on live streaming for
the logs to confirm

00:12:29.425 --> 00:12:32.160
that it's still
happening right now?

00:12:32.160 --> 00:12:36.050
And indeed, it looks like it is.

00:12:36.050 --> 00:12:36.730
All right.

00:12:36.730 --> 00:12:39.580
So that's how you can use
the logs from App Engine

00:12:39.580 --> 00:12:42.560
to get to root
cause on an issue.

00:12:42.560 --> 00:12:45.390
Now finally, the good news
is that we found the issue.

00:12:45.390 --> 00:12:48.510
We happened to be looking
at a dashboard at the time.

00:12:48.510 --> 00:12:50.860
I don't know who here likes
to spend all day staring

00:12:50.860 --> 00:12:54.110
at dashboards, besides Toby
and I. So what you'd want to do

00:12:54.110 --> 00:12:56.310
is configure an alerting
policy so that you're

00:12:56.310 --> 00:12:59.070
notified if the issue
occurs in the future.

00:12:59.070 --> 00:13:02.350
So we'll go, and we'll
create a learning policy.

00:13:02.350 --> 00:13:06.150
And we'll specify that
we'd like to be alerted

00:13:06.150 --> 00:13:11.060
when 500 errors increase
for that specific module.

00:13:11.060 --> 00:13:14.404
So we'll select the module.

00:13:14.404 --> 00:13:15.820
And then on the
next screen, we'll

00:13:15.820 --> 00:13:19.520
say that we want it
to alert on 500 errors

00:13:19.520 --> 00:13:22.280
when they go above
say 10 per second

00:13:22.280 --> 00:13:24.964
for more than five minutes.

00:13:24.964 --> 00:13:26.380
And one good thing
that we do here

00:13:26.380 --> 00:13:29.060
is give you a
preview of the metric

00:13:29.060 --> 00:13:31.150
or a historical
overview of the metric

00:13:31.150 --> 00:13:33.130
and how frequently
it would have fired

00:13:33.130 --> 00:13:35.714
if you set it at that level.

00:13:35.714 --> 00:13:36.660
OK.

00:13:36.660 --> 00:13:38.980
So I've saved that condition.

00:13:38.980 --> 00:13:40.804
And now I can configure
a notification.

00:13:40.804 --> 00:13:42.220
So this is to say
whether you want

00:13:42.220 --> 00:13:45.230
it to email you or send
an SMS, and so forth.

00:13:45.230 --> 00:13:47.992
And so here we'll say
we'll generate an email.

00:13:47.992 --> 00:13:50.450
And because maybe we're just
getting started, and it's Toby

00:13:50.450 --> 00:13:54.440
and I in our garage, we'll
send an email to both of us

00:13:54.440 --> 00:13:56.751
when we see these 500s.

00:13:56.751 --> 00:13:57.250
OK.

00:13:57.250 --> 00:13:59.666
So that's how you can create
a simple alerting policy that

00:13:59.666 --> 00:14:02.848
notifies you when there's
an issue in App Engine.

00:14:02.848 --> 00:14:03.760
OK.

00:14:03.760 --> 00:14:08.036
So we've demonstrated how you
can configure an endpoint check

00:14:08.036 --> 00:14:10.410
that will notify you if there's
an issue if it goes down,

00:14:10.410 --> 00:14:11.730
if the front end goes down.

00:14:11.730 --> 00:14:13.660
We've demonstrated
how you can get access

00:14:13.660 --> 00:14:16.010
to rich metrics for App Engine.

00:14:16.010 --> 00:14:17.910
That'd be a very
similar experience

00:14:17.910 --> 00:14:20.910
if you were looking at the other
Google Cloud Platform services.

00:14:20.910 --> 00:14:22.660
And then how you can
dig into the log data

00:14:22.660 --> 00:14:24.076
to get to root
cause, and finally,

00:14:24.076 --> 00:14:26.500
how you can now configure
alerts to notify you

00:14:26.500 --> 00:14:28.094
when issues occur.

00:14:28.094 --> 00:14:29.080
OK.

00:14:29.080 --> 00:14:30.430
So that's getting started.

00:14:30.430 --> 00:14:34.510
Now, if we were very fortunate
and our project worked out,

00:14:34.510 --> 00:14:36.930
things would get
serious after a while,

00:14:36.930 --> 00:14:39.950
as we have more customers
and a more complex system,

00:14:39.950 --> 00:14:41.430
and a larger team.

00:14:41.430 --> 00:14:43.630
TOBY SMITH: We're totally
getting serious, Dan.

00:14:43.630 --> 00:14:44.130
So right.

00:14:44.130 --> 00:14:45.310
When you're first
getting started,

00:14:45.310 --> 00:14:46.870
you just want things
to get out of your way.

00:14:46.870 --> 00:14:48.120
As you're starting
to get serious,

00:14:48.120 --> 00:14:50.310
you want more sophistication
from your monitoring

00:14:50.310 --> 00:14:51.599
and logging platform.

00:14:51.599 --> 00:14:53.140
And we're here to
help you with that.

00:14:53.140 --> 00:14:55.644
But what do we mean when
we say we transition

00:14:55.644 --> 00:14:57.310
from getting started
to getting serious?

00:14:57.310 --> 00:14:58.851
I mean, we have a
couple cute slides.

00:14:58.851 --> 00:15:02.245
But what are we
really talking about?

00:15:02.245 --> 00:15:04.120
So when you're getting
started, typically you

00:15:04.120 --> 00:15:05.512
develop on machines.

00:15:05.512 --> 00:15:07.220
You might only have
three or four of them

00:15:07.220 --> 00:15:08.534
in your whole fleet.

00:15:08.534 --> 00:15:10.200
You probably care
very deeply about each

00:15:10.200 --> 00:15:11.116
and every one of them.

00:15:11.116 --> 00:15:14.294
They're all special flowers, and
they probably all have names.

00:15:14.294 --> 00:15:16.460
You probably have one that's
running your front end.

00:15:16.460 --> 00:15:18.200
You probably have one that's
running your back end.

00:15:18.200 --> 00:15:20.160
There's probably a couple that
are running your data store

00:15:20.160 --> 00:15:21.570
or something like that.

00:15:21.570 --> 00:15:24.870
When one of those goes down,
it means something catastrophic

00:15:24.870 --> 00:15:27.570
for your application.

00:15:27.570 --> 00:15:30.580
As you start getting serious,
that becomes less true.

00:15:30.580 --> 00:15:33.280
You start thinking less
about individual machines

00:15:33.280 --> 00:15:35.080
and more about clusters.

00:15:35.080 --> 00:15:36.960
You start understanding
a little bit less

00:15:36.960 --> 00:15:38.995
about the entirety
of your architecture.

00:15:38.995 --> 00:15:40.370
And you start to
understand, well

00:15:40.370 --> 00:15:42.330
I basically know how this
thing works over here,

00:15:42.330 --> 00:15:43.490
but there's other
folks who are working

00:15:43.490 --> 00:15:45.448
on that who know a lot
more about it than I do.

00:15:48.304 --> 00:15:50.470
When something's broken
when you're getting started,

00:15:50.470 --> 00:15:52.553
again, you just have these
three or four machines.

00:15:52.553 --> 00:15:53.870
It's a big deal.

00:15:53.870 --> 00:15:56.470
If that front end goes down,
your entire site is gone.

00:15:56.470 --> 00:15:59.980
If the back end goes down, all
of your fantastic data is gone,

00:15:59.980 --> 00:16:04.220
and you can't show anything
interesting to users.

00:16:04.220 --> 00:16:07.490
When you're getting serious,
well you think about things

00:16:07.490 --> 00:16:10.190
because, for the most part,
when things get large enough,

00:16:10.190 --> 00:16:11.940
something's always broken.

00:16:11.940 --> 00:16:13.970
So really the question
you want to answer is,

00:16:13.970 --> 00:16:16.420
is it something I care about?

00:16:16.420 --> 00:16:18.120
So if you have those
same three or four

00:16:18.120 --> 00:16:20.029
machines that you used
to use for everything

00:16:20.029 --> 00:16:21.445
when you were
getting started, you

00:16:21.445 --> 00:16:23.944
might have re-purposed them
into a Redis cluster a long time

00:16:23.944 --> 00:16:24.830
ago.

00:16:24.830 --> 00:16:27.816
And now, if all four of those go
down, you just might not care.

00:16:27.816 --> 00:16:29.690
That's something you
get to on Monday morning

00:16:29.690 --> 00:16:31.410
while you're having your coffee.

00:16:31.410 --> 00:16:33.972
But on the other hand, if
you're experiencing 500 errors

00:16:33.972 --> 00:16:35.430
that you're throwing
to your users,

00:16:35.430 --> 00:16:36.690
you always care about those.

00:16:36.690 --> 00:16:38.315
That is something
that you want to have

00:16:38.315 --> 00:16:40.215
to wake up in the
middle of the night for.

00:16:40.215 --> 00:16:42.090
So you need to understand
what the difference

00:16:42.090 --> 00:16:43.798
between these different
types of failures

00:16:43.798 --> 00:16:46.359
is when you're getting serious.

00:16:46.359 --> 00:16:48.900
When you're getting started,
the development team's just you.

00:16:48.900 --> 00:16:50.820
Like I said, you have
everything in your head.

00:16:50.820 --> 00:16:51.960
You know the entire system.

00:16:51.960 --> 00:16:53.396
This is your baby.

00:16:53.396 --> 00:16:54.890
As you start
getting serious, you

00:16:54.890 --> 00:16:57.830
might have a team of
10, 20, 30, 40 people.

00:16:57.830 --> 00:17:00.790
Your grasp on the particulars
of what's going on

00:17:00.790 --> 00:17:02.580
is starting to
slip a little bit.

00:17:02.580 --> 00:17:04.206
You still talk a good
game in meetings,

00:17:04.206 --> 00:17:05.871
but really you don't
know exactly what's

00:17:05.871 --> 00:17:06.829
going on all the time.

00:17:09.380 --> 00:17:11.040
So Dan's going to
talk now about what

00:17:11.040 --> 00:17:13.079
it means when you
start getting serious

00:17:13.079 --> 00:17:16.317
and how we can help you still
understand your application.

00:17:16.317 --> 00:17:17.400
DAN BELCHER: Thanks, Toby.

00:17:17.400 --> 00:17:20.319
And so the Walkshare
application is actually

00:17:20.319 --> 00:17:22.369
an app that's on the
verge of a serious app.

00:17:22.369 --> 00:17:22.869
Right.

00:17:22.869 --> 00:17:25.730
Because with this
red Redis cluster,

00:17:25.730 --> 00:17:28.960
things start to look more
like a distributed system,

00:17:28.960 --> 00:17:31.530
and so some of these patterns
that Toby talked about

00:17:31.530 --> 00:17:32.445
are going to emerge.

00:17:32.445 --> 00:17:33.280
Right.

00:17:33.280 --> 00:17:36.760
With a cluster, we'll talk
about how you can get visibility

00:17:36.760 --> 00:17:39.480
into that cluster
that's running on GCE

00:17:39.480 --> 00:17:42.840
and get the right
metrics out of it.

00:17:42.840 --> 00:17:45.220
We'll talk about how now
that you have a distributed

00:17:45.220 --> 00:17:46.950
system that's
fairly complex, you

00:17:46.950 --> 00:17:49.372
may want to create a
view that's all your own,

00:17:49.372 --> 00:17:51.580
and how you can take
information from different parts

00:17:51.580 --> 00:17:54.740
of the platform and
create custom dashboards.

00:17:54.740 --> 00:17:57.070
We'll talk about how you
can get log data, access

00:17:57.070 --> 00:17:59.940
to log data for VMs that are
running on Google Compute

00:17:59.940 --> 00:18:00.990
Engine.

00:18:00.990 --> 00:18:04.040
And then finally, how you
can create alerting policies

00:18:04.040 --> 00:18:05.401
that are cluster aware.

00:18:05.401 --> 00:18:05.900
Right.

00:18:05.900 --> 00:18:09.560
This is a really important part
of managing distributed systems

00:18:09.560 --> 00:18:11.870
in the cloud.

00:18:11.870 --> 00:18:14.100
And so we'll show
you how things look

00:18:14.100 --> 00:18:16.320
when your kind of
getting serious.

00:18:16.320 --> 00:18:17.960
In this case, we'll
start with the home

00:18:17.960 --> 00:18:19.579
page for Cloud Monitoring.

00:18:19.579 --> 00:18:21.120
One thing you'll
see on the left here

00:18:21.120 --> 00:18:24.820
is that we've identified
a couple groups of nodes.

00:18:24.820 --> 00:18:25.320
Right.

00:18:25.320 --> 00:18:28.950
The first is this Redis cluster
that we were talking about.

00:18:28.950 --> 00:18:31.440
And so we've
discovered these groups

00:18:31.440 --> 00:18:34.660
by analyzing some
metadata around the VMs.

00:18:34.660 --> 00:18:36.900
In this case, we saw that
there was a pattern where

00:18:36.900 --> 00:18:40.800
you had a lot of machines that
the name started with Redis.

00:18:40.800 --> 00:18:41.300
All right.

00:18:41.300 --> 00:18:42.930
And you can define
your own groups.

00:18:42.930 --> 00:18:45.270
The great thing here is
that they're filters.

00:18:45.270 --> 00:18:46.280
They're dynamic.

00:18:46.280 --> 00:18:48.560
So if I add a new
Redis node, the machine

00:18:48.560 --> 00:18:51.020
will automatically be
added into the group.

00:18:51.020 --> 00:18:51.880
And you can do this.

00:18:51.880 --> 00:18:56.060
You can define groups based on
accounts or regions or tags.

00:18:56.060 --> 00:18:58.360
There are lots of different
ways that you can do this.

00:18:58.360 --> 00:18:58.860
OK.

00:18:58.860 --> 00:19:00.860
So this notion of a
group is really important

00:19:00.860 --> 00:19:02.970
as you scale up.

00:19:02.970 --> 00:19:04.680
And now we'll want
to get visibility

00:19:04.680 --> 00:19:06.877
into that group of Redis nodes.

00:19:06.877 --> 00:19:08.460
And so we'll go, and
we'll take a look

00:19:08.460 --> 00:19:11.820
at our dashboard
for the Redis nodes.

00:19:11.820 --> 00:19:13.860
Here you see the same
operational dashboard,

00:19:13.860 --> 00:19:17.360
where on the left we have the
configuration of the service,

00:19:17.360 --> 00:19:19.580
and on the right we
have key metrics.

00:19:19.580 --> 00:19:22.420
Now, out of the box with no
configuration, what you'll have

00:19:22.420 --> 00:19:25.160
is visibility into
CPU, as well as

00:19:25.160 --> 00:19:28.640
network and storage
I/O for the VMs.

00:19:28.640 --> 00:19:31.020
But if you deploy
the agent, you'll

00:19:31.020 --> 00:19:34.480
have access to much more
detailed system level metrics.

00:19:34.480 --> 00:19:38.070
So this would include
CPU Steal, memory,

00:19:38.070 --> 00:19:41.250
how full each of the
disks attached to the VM

00:19:41.250 --> 00:19:45.480
are, and then also information
on specific processes running

00:19:45.480 --> 00:19:46.976
on the machine.

00:19:46.976 --> 00:19:48.284
OK.

00:19:48.284 --> 00:19:49.700
So this is the
visibility that you

00:19:49.700 --> 00:19:52.890
get into kind of the
core system stats.

00:19:52.890 --> 00:19:55.680
But also with a simple
configuration file

00:19:55.680 --> 00:19:57.600
you can tell the
agent to monitor

00:19:57.600 --> 00:20:00.050
Redis on those machines.

00:20:00.050 --> 00:20:02.540
And once you put that
file on the machines,

00:20:02.540 --> 00:20:05.690
then the agent will
know to pull Redis stats

00:20:05.690 --> 00:20:07.590
and send them to our service.

00:20:07.590 --> 00:20:08.580
And then you're done.

00:20:08.580 --> 00:20:11.460
What will happen is the
Redis statistics will show up

00:20:11.460 --> 00:20:13.025
on the dashboard automatically.

00:20:13.025 --> 00:20:14.650
We'll know that
they're Redis machines.

00:20:14.650 --> 00:20:17.300
You don't have to do any other
configuration to get visibility

00:20:17.300 --> 00:20:18.680
into the Redis status.

00:20:18.680 --> 00:20:21.920
In here, you see, we'll have
Redis connections and memory

00:20:21.920 --> 00:20:24.510
and expired keys, and so forth.

00:20:24.510 --> 00:20:26.410
And these metrics are
also now available

00:20:26.410 --> 00:20:28.330
throughout the system.

00:20:28.330 --> 00:20:28.950
OK.

00:20:28.950 --> 00:20:31.990
Now, if we saw an issue as we
had with the App Engine module,

00:20:31.990 --> 00:20:34.890
we could dive in and
take a look at the logs.

00:20:34.890 --> 00:20:36.990
But before we do that,
let's take a quick look

00:20:36.990 --> 00:20:40.020
at how we would create a
custom dashboard that gives us

00:20:40.020 --> 00:20:43.340
visibility into different
parts of our app.

00:20:43.340 --> 00:20:46.490
So first, you see we have
our custom dashboard.

00:20:46.490 --> 00:20:50.330
I've added a couple charts to
this dashboard as defaults.

00:20:50.330 --> 00:20:54.220
The first, on the left you see
an overview of production CPU

00:20:54.220 --> 00:20:56.190
across a larger cluster.

00:20:56.190 --> 00:20:56.990
All right.

00:20:56.990 --> 00:20:58.780
Now, if you've managed
large environments

00:20:58.780 --> 00:21:01.110
you know they can be a little
bit difficult sometimes

00:21:01.110 --> 00:21:02.900
when you have too
much data on a chart.

00:21:02.900 --> 00:21:04.840
Anyone have that experience?

00:21:04.840 --> 00:21:05.370
Yeah, yeah.

00:21:05.370 --> 00:21:06.890
I guess a bunch of you.

00:21:06.890 --> 00:21:09.000
One great thing here is
we can go to full screen

00:21:09.000 --> 00:21:13.700
mode for that chart
to get a broader view.

00:21:13.700 --> 00:21:17.140
And then it looks like there's
some interesting activity here.

00:21:17.140 --> 00:21:19.320
So what I'll do is we'll
go into x-ray mode.

00:21:19.320 --> 00:21:19.820
All right.

00:21:19.820 --> 00:21:22.540
And x-ray mode is a
way, especially when

00:21:22.540 --> 00:21:25.760
you have a lot of time
series on a chart, a way that

00:21:25.760 --> 00:21:28.884
makes it easier for you see
for you to see the trends.

00:21:28.884 --> 00:21:30.800
So you can see here we
have a set of machines,

00:21:30.800 --> 00:21:33.049
it looks like in the cluster,
that are hovering around

00:21:33.049 --> 00:21:34.800
40% CPU utilization.

00:21:34.800 --> 00:21:36.690
We also have this
band of machines

00:21:36.690 --> 00:21:38.610
that are hovering
right around 60.

00:21:38.610 --> 00:21:41.420
And then there's some
noise right up at the top.

00:21:41.420 --> 00:21:45.830
So what I'd like to do is sort
by volatility in the legend

00:21:45.830 --> 00:21:48.404
to see what the most
volatile machines are.

00:21:48.404 --> 00:21:49.820
And in fact, it
looks like there's

00:21:49.820 --> 00:21:52.540
one machine that's
alerting API that's

00:21:52.540 --> 00:21:54.290
much more volatile
than the others.

00:21:54.290 --> 00:21:57.210
So this might be a
case where we want to--

00:21:57.210 --> 00:21:59.600
Often we want to terminate
the node and start a new one,

00:21:59.600 --> 00:22:01.960
but in this case, we may
want to dive into the logs

00:22:01.960 --> 00:22:04.400
to see what's going
on with that node.

00:22:04.400 --> 00:22:05.810
OK.

00:22:05.810 --> 00:22:09.680
So again, we can go back
to our cloud console

00:22:09.680 --> 00:22:11.300
and access the logs.

00:22:11.300 --> 00:22:13.580
And now for the first
time, we have rich access

00:22:13.580 --> 00:22:18.029
to the logs for the
machines running on GCE.

00:22:18.029 --> 00:22:19.570
And the great thing
here is you don't

00:22:19.570 --> 00:22:22.570
have to SSH into the machines
to get access to the data.

00:22:22.570 --> 00:22:24.610
All of the log data
from all of the machines

00:22:24.610 --> 00:22:25.545
come into one place.

00:22:25.545 --> 00:22:26.160
All right.

00:22:26.160 --> 00:22:29.984
And it's easily sortable and
filterable, and so forth.

00:22:29.984 --> 00:22:30.760
OK.

00:22:30.760 --> 00:22:34.120
So this is how you would
go into the log data

00:22:34.120 --> 00:22:36.730
for machines that
live on GCE to help

00:22:36.730 --> 00:22:40.460
diagnose issues in this cluster.

00:22:40.460 --> 00:22:42.380
OK.

00:22:42.380 --> 00:22:44.280
And then finally,
in this case, we

00:22:44.280 --> 00:22:47.480
can also look at the
live updating logs.

00:22:47.480 --> 00:22:50.110
Finally and probably most
importantly, alerting.

00:22:50.110 --> 00:22:50.610
Right.

00:22:50.610 --> 00:22:52.000
So this is a cluster.

00:22:52.000 --> 00:22:52.730
It's dynamic.

00:22:52.730 --> 00:22:55.080
We're adding, removing,
and recycling machines

00:22:55.080 --> 00:22:56.154
all the time.

00:22:56.154 --> 00:22:58.320
And so what I want to do
is create alerting policies

00:22:58.320 --> 00:22:59.821
at the cluster level.

00:22:59.821 --> 00:23:00.320
All right.

00:23:00.320 --> 00:23:02.860
And because we have this group
capability we can do that.

00:23:02.860 --> 00:23:05.170
So we'll specify
here that we want

00:23:05.170 --> 00:23:08.820
to create a policy to tell
us if more than a third

00:23:08.820 --> 00:23:12.110
of the machines in the cluster
are, let's say, over-utilized.

00:23:12.110 --> 00:23:15.640
So CPU is over 50%.

00:23:15.640 --> 00:23:16.560
OK?

00:23:16.560 --> 00:23:20.290
So this will only trigger
if more than a third

00:23:20.290 --> 00:23:24.845
of the machines in the cluster
are over 50% CPU utilization.

00:23:24.845 --> 00:23:26.970
And this doesn't matter if
you add 10 more machines

00:23:26.970 --> 00:23:27.595
to the cluster.

00:23:27.595 --> 00:23:29.530
It will automatically
incorporate those

00:23:29.530 --> 00:23:32.330
into the algorithm.

00:23:32.330 --> 00:23:34.550
Here again, we see a preview.

00:23:34.550 --> 00:23:37.170
We can now add a
second condition.

00:23:37.170 --> 00:23:39.260
So because I'm thinking
about the cluster,

00:23:39.260 --> 00:23:42.250
I might want to think about the
health of the cluster overall.

00:23:42.250 --> 00:23:44.060
So I'll aggregate the metrics.

00:23:44.060 --> 00:23:47.430
I could do, say, the average
CPU across all the nodes

00:23:47.430 --> 00:23:49.000
in the cluster.

00:23:49.000 --> 00:23:51.310
And so we'll select our metric.

00:23:51.310 --> 00:23:54.590
We'll specify the Redis cluster.

00:23:54.590 --> 00:23:56.800
We'll choose CPU.

00:23:56.800 --> 00:23:58.530
And then we'll
say, if the average

00:23:58.530 --> 00:24:00.430
is over 40% percent
across the cluster.

00:24:00.430 --> 00:24:02.266
Maybe this is a case
where it's telling us

00:24:02.266 --> 00:24:03.390
we need some more capacity.

00:24:06.130 --> 00:24:07.980
And we could have
just as easily done it

00:24:07.980 --> 00:24:10.380
based on the standard deviation
of the 95th percentile

00:24:10.380 --> 00:24:14.720
or fifth percentile
or otherwise.

00:24:14.720 --> 00:24:17.620
Now also, given that
we have two conditions,

00:24:17.620 --> 00:24:19.600
we didn't just create
two alerting policies.

00:24:19.600 --> 00:24:23.480
We created two conditions
for the same policy.

00:24:23.480 --> 00:24:26.510
And that's important
because we may not

00:24:26.510 --> 00:24:29.620
want the alert to fire
unless both of the conditions

00:24:29.620 --> 00:24:31.100
are true.

00:24:31.100 --> 00:24:34.890
So you can imagine that you have
a metric for your App Engine

00:24:34.890 --> 00:24:36.610
module connecting to Redis.

00:24:36.610 --> 00:24:39.220
And you might want to look
at two different metrics

00:24:39.220 --> 00:24:41.192
as conditions and then
only fire the alert

00:24:41.192 --> 00:24:42.650
if both of the
conditions are true.

00:24:45.180 --> 00:24:47.560
Here we have a larger team.

00:24:47.560 --> 00:24:50.120
As Toby showed, we're
a successful crew.

00:24:50.120 --> 00:24:51.500
We have 40 engineers.

00:24:51.500 --> 00:24:53.810
And maybe this is a
serious enough issue

00:24:53.810 --> 00:24:56.110
that I want to email everyone.

00:24:56.110 --> 00:24:58.130
And so right in the
notification framework

00:24:58.130 --> 00:25:00.910
you can say that you'd like
everyone to be notified.

00:25:00.910 --> 00:25:05.021
But as Toby said, not
everyone knows exactly what's

00:25:05.021 --> 00:25:06.770
going on in every
component of the system.

00:25:06.770 --> 00:25:11.040
So we can also add read me
information to the policy,

00:25:11.040 --> 00:25:14.000
so to say, if this
occurs, maybe you

00:25:14.000 --> 00:25:15.967
want to try these three steps.

00:25:15.967 --> 00:25:16.467
All right.

00:25:20.450 --> 00:25:23.300
So that's how you can
create an alerting policy

00:25:23.300 --> 00:25:25.464
in a more sophisticated
environment.

00:25:25.464 --> 00:25:26.880
And you'll see
that there are lots

00:25:26.880 --> 00:25:31.890
of options in terms of making
it really effective to alert

00:25:31.890 --> 00:25:34.510
at the cluster level right
in the distributed systems

00:25:34.510 --> 00:25:35.992
environment.

00:25:35.992 --> 00:25:37.240
OK.

00:25:37.240 --> 00:25:39.460
So this is how the
monitoring systems

00:25:39.460 --> 00:25:43.810
can scale when you get
to a larger environment.

00:25:43.810 --> 00:25:48.310
Finally, what Toby will talk
about is some of the lessons

00:25:48.310 --> 00:25:49.160
that we've learned.

00:25:49.160 --> 00:25:52.870
One of them is take advantage
of some of the integrations

00:25:52.870 --> 00:25:54.640
that are built
into the platform.

00:25:54.640 --> 00:25:56.640
So as you get
larger, it might be

00:25:56.640 --> 00:26:00.012
fine to get an email alert when
things happen getting started.

00:26:00.012 --> 00:26:01.470
But as you get
larger, you may have

00:26:01.470 --> 00:26:03.450
a team that hangs
out in chat rooms

00:26:03.450 --> 00:26:05.240
because you're spread
around the country.

00:26:05.240 --> 00:26:08.660
And so you may want that to
trigger into a chat room,

00:26:08.660 --> 00:26:12.280
in this case Campfire or
HipChat or whatever you use.

00:26:12.280 --> 00:26:15.810
You may also have an operations
team and on-call rotations.

00:26:15.810 --> 00:26:18.960
So if you use PagerDuty,
there's native integration

00:26:18.960 --> 00:26:22.220
with PagerDuty so that we can
escalate issues directly there.

00:26:25.124 --> 00:26:26.040
TOBY SMITH: All right.

00:26:26.040 --> 00:26:28.530
Thank you, Dan.

00:26:28.530 --> 00:26:30.810
As Dan said, we
know we've given you

00:26:30.810 --> 00:26:33.060
kind of a whirlwind
tour of Google Cloud

00:26:33.060 --> 00:26:34.130
Monitoring at this point.

00:26:34.130 --> 00:26:35.440
And we really don't
expect you to remember

00:26:35.440 --> 00:26:38.106
everything that we showed or all
the fiddly little menus that we

00:26:38.106 --> 00:26:38.940
went through.

00:26:38.940 --> 00:26:40.910
But if you remember
nothing else,

00:26:40.910 --> 00:26:43.530
just take away a few things, and
when you do start using this,

00:26:43.530 --> 00:26:46.750
you can be successful with it
and really make the most of it.

00:26:46.750 --> 00:26:49.130
First of all, we talked
a bit about groups.

00:26:49.130 --> 00:26:51.675
But groups become vital
as your team grows.

00:26:51.675 --> 00:26:53.050
When you're just
getting started,

00:26:53.050 --> 00:26:55.190
you might not care all
that much about groups.

00:26:55.190 --> 00:26:58.550
But once you start getting
even 10, 15 machines,

00:26:58.550 --> 00:27:00.390
this starts to
become invaluable.

00:27:00.390 --> 00:27:03.150
You don't need to keep track of
which individual machines are

00:27:03.150 --> 00:27:04.680
associated with
Redis, which ones

00:27:04.680 --> 00:27:06.820
are associated with Cassandra.

00:27:06.820 --> 00:27:08.840
As these things
grow and contract,

00:27:08.840 --> 00:27:11.270
your alerting roles and
your monitoring dashboards

00:27:11.270 --> 00:27:14.150
grow and contract too take
advantage of these things.

00:27:14.150 --> 00:27:16.320
Plus it's just a
great way to navigate

00:27:16.320 --> 00:27:18.350
the complexity of a
sophisticated system.

00:27:20.970 --> 00:27:23.070
Second, go nuts.

00:27:23.070 --> 00:27:24.130
Be your own person.

00:27:24.130 --> 00:27:26.090
We provide a lot
of personalization

00:27:26.090 --> 00:27:28.390
with the dashboards.

00:27:28.390 --> 00:27:31.030
We have reasonable
suggestions for things

00:27:31.030 --> 00:27:34.680
like App Engine and Compute
Engine, Cassandra and Redis.

00:27:34.680 --> 00:27:36.410
But that's just
our guess for what

00:27:36.410 --> 00:27:38.160
these dashboards
should look like.

00:27:38.160 --> 00:27:39.640
If you disagree, go change it.

00:27:39.640 --> 00:27:40.890
Add the metrics that you want.

00:27:40.890 --> 00:27:42.600
Add the screens that you want.

00:27:42.600 --> 00:27:45.190
You can bring in any
information, any data.

00:27:45.190 --> 00:27:47.830
You can have any number
of these graphs on screen.

00:27:47.830 --> 00:27:50.330
You can even do things like
drag them around and change

00:27:50.330 --> 00:27:52.010
this color scheme if you want.

00:27:52.010 --> 00:27:53.330
This is your system.

00:27:53.330 --> 00:27:56.310
Make it your own.

00:27:56.310 --> 00:27:58.290
And finally, we've talked
a lot about alerting.

00:27:58.290 --> 00:28:00.310
But we really can't
emphasize enough both

00:28:00.310 --> 00:28:03.630
how powerful and potentially
useless and dangerous

00:28:03.630 --> 00:28:06.206
alerting can be if you
don't use it right.

00:28:06.206 --> 00:28:07.830
So be thoughtful when
you're setting up

00:28:07.830 --> 00:28:09.480
your alerting conditions.

00:28:09.480 --> 00:28:12.560
Understand the questions that
you actually want to answer,

00:28:12.560 --> 00:28:14.050
and go from there.

00:28:14.050 --> 00:28:18.040
If you're alerting on, say, one
Cassandra latency problem that

00:28:18.040 --> 00:28:20.102
lasts one minute, and
you're waking someone up

00:28:20.102 --> 00:28:22.560
at 3:00 in the morning, your
team is not going to be happy.

00:28:22.560 --> 00:28:24.210
By the time they wake
up, the problem's

00:28:24.210 --> 00:28:25.710
probably resolved itself.

00:28:25.710 --> 00:28:27.760
Even if it hasn't, the
rest of the cluster's

00:28:27.760 --> 00:28:30.490
probably behaving normally.

00:28:30.490 --> 00:28:33.410
Dan showed a few examples of
the sophisticated sort of rules

00:28:33.410 --> 00:28:36.600
that you can apply to do
the things that you actually

00:28:36.600 --> 00:28:38.270
want to accomplish
with your system.

00:28:38.270 --> 00:28:39.305
So think about those.

00:28:39.305 --> 00:28:40.680
Set the alerts up
so that they're

00:28:40.680 --> 00:28:43.750
meaningful for your team,
and revisit them occasionally

00:28:43.750 --> 00:28:44.390
as well.

00:28:44.390 --> 00:28:46.230
The things that are
useful now might not

00:28:46.230 --> 00:28:47.646
be the same things
that are useful

00:28:47.646 --> 00:28:52.380
three months from now when
you've again doubled in size.

00:28:52.380 --> 00:28:53.020
And that's it.

00:28:53.020 --> 00:28:54.630
Thanks so much for coming
and listening to us

00:28:54.630 --> 00:28:56.220
talk about Google
Cloud Monitoring.

00:28:56.220 --> 00:28:57.640
We're super excited about it.

00:28:57.640 --> 00:28:58.970
And we hope you are too.

00:28:58.970 --> 00:29:01.220
DAN BELCHER: And we're really
excited that you decided

00:29:01.220 --> 00:29:05.060
to spend an hour on your
Thursday afternoon with us.

00:29:05.060 --> 00:29:09.590
We're also excited because today
we started the Trusted Tester

00:29:09.590 --> 00:29:11.670
Program for Google
Cloud Monitoring.

00:29:11.670 --> 00:29:14.820
And that means that if you're
a current Google Cloud Platform

00:29:14.820 --> 00:29:18.350
customer, if you log into
your developer console,

00:29:18.350 --> 00:29:21.880
you'll see a new link on the
left for dashboards and alerts.

00:29:21.880 --> 00:29:24.300
If you click on that link,
you can request access

00:29:24.300 --> 00:29:27.730
to the Trusted Tester Program.

00:29:27.730 --> 00:29:28.240
Oh, yeah.

00:29:28.240 --> 00:29:30.440
We can show you exactly
how that happens.

00:29:30.440 --> 00:29:32.170
So you'll see
dashboards and alerts.

00:29:32.170 --> 00:29:32.962
TOBY SMITH: Ba bum.

00:29:32.962 --> 00:29:34.586
DAN BELCHER: If you
click there, you'll

00:29:34.586 --> 00:29:35.920
see a button to request access.

00:29:35.920 --> 00:29:38.590
Unfortunately, we can't grant
everyone access right away.

00:29:38.590 --> 00:29:41.380
But certainly, we'll do
it as quickly as we can.

00:29:41.380 --> 00:29:45.810
And then secondly, if you're
not a current cloud platform

00:29:45.810 --> 00:29:47.440
customer, it's also good day.

00:29:47.440 --> 00:29:52.490
And that's because you
can claim a $500 credit

00:29:52.490 --> 00:29:56.089
to get started on the platform.

00:29:56.089 --> 00:29:58.130
And at this point, thank
you very much, everyone.

00:29:58.130 --> 00:30:00.460
We'd welcome any questions
or feedback that you have.

00:30:00.460 --> 00:30:05.494
We'll just ask you to use the
mics here in the center aisle.

00:30:05.494 --> 00:30:12.580
[APPLAUSE]

00:30:12.580 --> 00:30:13.715
Any questions?

00:30:13.715 --> 00:30:15.449
TOBY SMITH: Sure.

00:30:15.449 --> 00:30:16.990
DAN BELCHER: Right
here in the front.

00:30:16.990 --> 00:30:17.951
AUDIENCE: Hi, guys.

00:30:17.951 --> 00:30:18.450
Thanks.

00:30:18.450 --> 00:30:19.780
Great talk.

00:30:19.780 --> 00:30:22.650
I was very impressed by
the metrics and alerting

00:30:22.650 --> 00:30:24.120
that was demonstrated.

00:30:24.120 --> 00:30:26.970
And I'm wondering
if there's a way

00:30:26.970 --> 00:30:31.310
to alert on a single metric
that is comparing itself

00:30:31.310 --> 00:30:33.780
to a different time.

00:30:33.780 --> 00:30:35.190
DAN BELCHER: Oh.

00:30:35.190 --> 00:30:36.100
Not yet.

00:30:36.100 --> 00:30:37.340
Not today.

00:30:37.340 --> 00:30:39.860
This is a request that
we've gotten in the past.

00:30:39.860 --> 00:30:42.190
Great, great feedback,
something that we'll

00:30:42.190 --> 00:30:45.300
take into consideration.

00:30:45.300 --> 00:30:46.070
AUDIENCE: Hi.

00:30:46.070 --> 00:30:49.100
I'd like to ask if it's
possible to create a custom

00:30:49.100 --> 00:30:53.080
metrics and custom notification.

00:30:53.080 --> 00:30:58.320
DAN BELCHER: So custom
metrics are not yet available.

00:30:58.320 --> 00:31:01.920
They are something that
we hear loud and clear are

00:31:01.920 --> 00:31:02.570
very important.

00:31:02.570 --> 00:31:06.700
In fact, it's been our
number one request so far.

00:31:06.700 --> 00:31:09.390
Custom notifications, what
you do have the ability to do

00:31:09.390 --> 00:31:13.330
is configure a webhook as
a notification endpoint.

00:31:13.330 --> 00:31:16.420
And so then you can just
specify the path of the webhook,

00:31:16.420 --> 00:31:18.587
and we'll send the data there.

00:31:18.587 --> 00:31:19.420
AUDIENCE: Thank you.

00:31:19.420 --> 00:31:20.378
DAN BELCHER: Thank you.

00:31:22.959 --> 00:31:23.870
AUDIENCE: Hello.

00:31:23.870 --> 00:31:25.570
Very impressing
tool I have to say.

00:31:25.570 --> 00:31:26.695
DAN BELCHER: Oh, thank you.

00:31:26.695 --> 00:31:28.810
AUDIENCE: As an
experienced user on GCE,

00:31:28.810 --> 00:31:32.372
my question is referring to
the extending of the agent.

00:31:32.372 --> 00:31:34.830
That's what the custom metrics
I guess you're referring to.

00:31:34.830 --> 00:31:35.650
Right?

00:31:35.650 --> 00:31:39.410
At the moment, it's
impossible to extend the agent

00:31:39.410 --> 00:31:42.270
from my own application?

00:31:42.270 --> 00:31:45.420
DAN BELCHER: Today,
it is not supported

00:31:45.420 --> 00:31:49.500
to add new plug-ins or
metrics to the agent.

00:31:49.500 --> 00:31:52.260
The agent is based on
[? Collectee. ?] It's a package

00:31:52.260 --> 00:31:54.890
of [? Collectee, ?] which is
a really popular open source

00:31:54.890 --> 00:31:56.590
agent framework.

00:31:56.590 --> 00:32:00.370
Today, we don't support custom
plug-ins to [? Collectee ?].

00:32:00.370 --> 00:32:02.500
But as I said, support
for custom data

00:32:02.500 --> 00:32:05.140
coming into the system is
really important for us.

00:32:05.140 --> 00:32:06.664
So we know that
it's an important.

00:32:06.664 --> 00:32:07.330
AUDIENCE: Right.

00:32:07.330 --> 00:32:09.371
And the second question
is, what is the mechanism

00:32:09.371 --> 00:32:12.670
to send my own logs to
the log infrastructure

00:32:12.670 --> 00:32:13.782
that you provide?

00:32:13.782 --> 00:32:15.240
TOBY SMITH: We have
a Fluentd agent

00:32:15.240 --> 00:32:17.440
that we're using
on GCE instances,

00:32:17.440 --> 00:32:20.070
that you'll be able to
configure to point to your logs.

00:32:20.070 --> 00:32:20.903
AUDIENCE: All right.

00:32:20.903 --> 00:32:23.350
And is there an endpoint that
I should send that up to?

00:32:23.350 --> 00:32:26.620
I should install the Fluentd
agent on the instance

00:32:26.620 --> 00:32:29.670
and send the logs to
wherever endpoint--

00:32:29.670 --> 00:32:32.360
TOBY SMITH: You can just specify
where the logs are stored.

00:32:32.360 --> 00:32:34.790
And we can configure the Fluentd
agent to find them there.

00:32:34.790 --> 00:32:35.240
AUDIENCE: All right.

00:32:35.240 --> 00:32:35.690
Cool.

00:32:35.690 --> 00:32:36.140
Thanks.

00:32:36.140 --> 00:32:36.931
DAN BELCHER: Great.

00:32:36.931 --> 00:32:39.000
Thanks for your questions.

00:32:39.000 --> 00:32:40.270
AUDIENCE: Two questions.

00:32:40.270 --> 00:32:41.825
Does this add extra cost?

00:32:41.825 --> 00:32:44.450
If I have a lot of logs flowing
in, am I paying for an instance

00:32:44.450 --> 00:32:47.500
to maintain those or
is that sort of free

00:32:47.500 --> 00:32:49.930
as part of the
rest of the system?

00:32:49.930 --> 00:32:52.020
DAN BELCHER: So the
capabilities that we

00:32:52.020 --> 00:32:54.950
showed you here today
are available to Trusted

00:32:54.950 --> 00:32:57.370
Testers at no charge.

00:32:57.370 --> 00:33:02.430
We don't have pricing
finalized for the service.

00:33:02.430 --> 00:33:04.880
But it's our intent
for native things,

00:33:04.880 --> 00:33:07.290
at a minimum, the
platform services,

00:33:07.290 --> 00:33:09.860
to not charge for the
core monitoring for those.

00:33:09.860 --> 00:33:10.546
OK.

00:33:10.546 --> 00:33:12.046
And then the logging,
is there any--

00:33:12.046 --> 00:33:13.420
TOBY SMITH: No,
there's no charge

00:33:13.420 --> 00:33:14.462
for monitoring right now.

00:33:14.462 --> 00:33:15.086
AUDIENCE: Cool.

00:33:15.086 --> 00:33:16.530
And does this
provide or will this

00:33:16.530 --> 00:33:18.405
provide more information
about the containers

00:33:18.405 --> 00:33:21.460
in the external sort of the
equivalent of a physical PC,

00:33:21.460 --> 00:33:25.600
or is this mostly just about the
operating system in the inside.

00:33:25.600 --> 00:33:26.380
DAN BELCHER: Oh.

00:33:26.380 --> 00:33:31.441
So could you restate
the question?

00:33:31.441 --> 00:33:33.190
AUDIENCE: So this
seemed to monitor things

00:33:33.190 --> 00:33:37.950
like my Linux and
my application.

00:33:37.950 --> 00:33:41.560
Are there statistics
also for the outside,

00:33:41.560 --> 00:33:44.404
the virtual PC, the
container, or what

00:33:44.404 --> 00:33:45.570
I'm running on in the cloud?

00:33:45.570 --> 00:33:46.528
DAN BELCHER: Oh the VM?

00:33:46.528 --> 00:33:49.470
Well, out of the box, so
before you deploy the agent,

00:33:49.470 --> 00:33:52.110
there are some metrics that
are available basically

00:33:52.110 --> 00:33:54.290
with the hypervisor
looking at activity

00:33:54.290 --> 00:33:55.910
between the
hypervisor and the VM.

00:33:55.910 --> 00:33:58.640
So that would be
kind of core CP usage

00:33:58.640 --> 00:34:03.082
and network and storage
I/O. But beyond that, no.

00:34:03.082 --> 00:34:03.790
I don't think so.

00:34:03.790 --> 00:34:04.963
Not really.

00:34:04.963 --> 00:34:05.504
AUDIENCE: OK.

00:34:05.504 --> 00:34:05.991
Cool.

00:34:05.991 --> 00:34:07.300
But those come from the
hypervisor then the core PU?

00:34:07.300 --> 00:34:08.050
DAN BELCHER: Yeah.

00:34:08.050 --> 00:34:08.722
That's right.

00:34:08.722 --> 00:34:09.222
Yeah.

00:34:09.222 --> 00:34:10.942
Great question.

00:34:10.942 --> 00:34:12.275
Any other questions or comments?

00:34:14.949 --> 00:34:15.449
All right.

00:34:15.449 --> 00:34:16.783
Well, thank you again, everyone.

00:34:16.783 --> 00:34:17.532
Thank you so much.

00:34:17.532 --> 00:34:18.282
Oh it looks like--

00:34:18.282 --> 00:34:20.615
Yeah, you could come up and
ask questions after as well.

00:34:20.615 --> 00:34:22.310
But it seems like we
have one more here.

00:34:22.310 --> 00:34:23.976
AUDIENCE: So maybe a
heretical question,

00:34:23.976 --> 00:34:27.090
but you started being an
amazing monitoring tool on AWS,

00:34:27.090 --> 00:34:29.170
now you were acquired by Google.

00:34:29.170 --> 00:34:35.300
Will you be able to do this for
both my AWS and my Google Cloud

00:34:35.300 --> 00:34:36.570
usage?

00:34:36.570 --> 00:34:41.320
DAN BELCHER: Well, we can't
really comment on future plans.

00:34:41.320 --> 00:34:43.909
We're going to let
our customers help

00:34:43.909 --> 00:34:46.800
to inform that decision
in the long run.

00:34:46.800 --> 00:34:48.790
So certainly, there
are existing customers

00:34:48.790 --> 00:34:50.719
using the Stackdriver product.

00:34:50.719 --> 00:34:54.830
We plan to continue to
support them in perpetuity.

00:34:54.830 --> 00:34:58.200
The support for AWS
and Google together

00:34:58.200 --> 00:35:00.350
and other cloud
platforms and Google

00:35:00.350 --> 00:35:03.640
together is something that
we're looking for our customers

00:35:03.640 --> 00:35:05.966
to help us decide.

00:35:05.966 --> 00:35:07.962
AUDIENCE: Thank you.

00:35:07.962 --> 00:35:08.920
DAN BELCHER: All right.

00:35:08.920 --> 00:35:10.530
Thank you, everyone,
for your time.

00:35:10.530 --> 00:35:11.571
TOBY SMITH: Thanks again.

00:35:11.571 --> 00:35:12.380
[APPLAUSE]

