WEBVTT
Kind: captions
Language: en

00:00:00.400 --> 00:00:03.130
Okay?
So last time we were talking about joint

00:00:03.130 --> 00:00:04.250
distributions.

00:00:04.250 --> 00:00:09.880
And just to kinda quickly remind everyone
I like the big theme right now is joint,

00:00:09.880 --> 00:00:11.830
conditional, and marginal distributions.

00:00:11.830 --> 00:00:16.380
And everyone needs to get comfortable
at how all those concepts relate.

00:00:16.380 --> 00:00:18.190
So there's three different
types of things.

00:00:18.190 --> 00:00:20.680
Joint, conditional, and marginal.

00:00:23.658 --> 00:00:27.660
And we were talking about joint and
marginal distributions last time.

00:00:27.660 --> 00:00:29.660
Not so
much about conditional distributions.

00:00:29.660 --> 00:00:34.080
But it's analagous to the stuff we've
already seen about conditioning.

00:00:34.080 --> 00:00:35.950
So those are the three key words.

00:00:35.950 --> 00:00:38.490
Joint, conditional, and
marginal distributions.

00:00:41.610 --> 00:00:47.180
So at this point in the course we pretty
much have all the tools we need for

00:00:47.180 --> 00:00:50.430
working with one random
variable at a time.

00:00:50.430 --> 00:00:54.540
But there's much much more that we need
to study about what happens when we have

00:00:54.540 --> 00:00:55.950
two random variables.

00:00:55.950 --> 00:00:59.610
Or a list, a sequence of random variables.

00:00:59.610 --> 00:01:01.705
Things like that.
A sum of a million random variables, and

00:01:01.705 --> 00:01:02.506
things like that.

00:01:02.506 --> 00:01:05.718
So we're gonna talk a lot about what
happens with lots of random variables at

00:01:05.718 --> 00:01:06.380
the same time.

00:01:06.380 --> 00:01:09.477
And that's why I keep emphasizing
that everything is accumulative here.

00:01:09.477 --> 00:01:12.941
Because if you have trouble
with one random variable and

00:01:12.941 --> 00:01:18.180
it's CDF then understanding two of them at
the same time is gonna be very difficult.

00:01:21.080 --> 00:01:22.550
So we always have a joint CDF.

00:01:24.060 --> 00:01:24.980
If there's two of them.

00:01:24.980 --> 00:01:31.160
I'll just write down what it looks like,
F(x,y).

00:01:31.160 --> 00:01:37.560
So joint CDF would be this,
for two random variables.

00:01:37.560 --> 00:01:40.920
But of course, if we had a million
random variables instead of two,

00:01:40.920 --> 00:01:41.990
I'm not gonna write this down.

00:01:41.990 --> 00:01:44.612
I could write x 1 through x a million.

00:01:44.612 --> 00:01:48.730
And then, x 1, less than or
equal, little x 1, and so on.

00:01:48.730 --> 00:01:49.930
And a million of them.

00:01:49.930 --> 00:01:52.790
So this extends to as many as you want.

00:01:52.790 --> 00:01:56.710
But it's just easier to write it down and
think about it for two of them.

00:01:56.710 --> 00:01:59.020
But it's more general than this.

00:01:59.020 --> 00:02:02.620
That's the joint CDF
that always makes sense.

00:02:02.620 --> 00:02:07.360
They can be discrete, continuous, mixtures
of discrete and continuous or anything.

00:02:07.360 --> 00:02:08.900
In the continuous case

00:02:10.590 --> 00:02:15.000
then we have a joint PDF which
I talked a little bit about.

00:02:15.000 --> 00:02:18.820
But I don't think I wrote down how to
get from the joint CDF to the joint PDF.

00:02:19.850 --> 00:02:21.460
So then we have a joint PDF.

00:02:25.634 --> 00:02:28.740
And if it's analogous to
the one-dimensional case.

00:02:30.880 --> 00:02:34.920
Where in the one- dimensional case we take
the derivative of the CDF to get the PDF.

00:02:34.920 --> 00:02:35.900
In this case,

00:02:35.900 --> 00:02:39.480
we take the derivative except that
it's a function of two variables.

00:02:39.480 --> 00:02:40.700
So, we're gonna take two
partial derivatives.

00:02:40.700 --> 00:02:45.871
And so I would write it as d squared

00:02:45.871 --> 00:02:51.245
of d squared, dx/dy F(x,y).

00:02:51.245 --> 00:02:56.992
Which looks complicated, especially if
you haven't seen partial derivatives.

00:02:56.992 --> 00:03:01.696
But even if you haven't ever
done partial derivatives before

00:03:01.696 --> 00:03:05.590
there's nothing really to
worry about with this.

00:03:05.590 --> 00:03:10.840
All it means is take the derivative,
this is a function of two variables.

00:03:10.840 --> 00:03:14.870
Take the derivative with respect to y,
treating x as a constant, right?

00:03:14.870 --> 00:03:16.740
So if you can do derivatives,

00:03:16.740 --> 00:03:20.210
which I'm assuming you can do,
you can pretend x is a constant.

00:03:20.210 --> 00:03:24.330
And then take the derivative with
respect to x, holding y as a constant.

00:03:24.330 --> 00:03:28.030
And there's a theorem in
multi-variable calculus that says that

00:03:28.030 --> 00:03:31.260
under some mild conditions, it doesn't
actually matter if you take the partial

00:03:31.260 --> 00:03:33.190
with respect to y then with respect to x.

00:03:33.190 --> 00:03:35.620
Or with respect to x and then with
respect to y, you'll get the same thing.

00:03:36.910 --> 00:03:40.110
So this is again analogous
to the one-dimensional case.

00:03:40.110 --> 00:03:44.220
And the joint PDF, this is not
a probability, that's a density.

00:03:44.220 --> 00:03:47.090
That's all we integrate to get a density.

00:03:47.090 --> 00:03:49.380
So integrate this.

00:03:49.380 --> 00:03:53.790
If we want to know what's
the probability that x,

00:03:53.790 --> 00:03:58.210
y is in some set A?

00:03:58.210 --> 00:04:03.780
Then that's just gonna be the integral
over that set A of the density.

00:04:09.462 --> 00:04:12.830
If you haven't done double intervals
before, again, it's no big deal.

00:04:12.830 --> 00:04:15.550
Just integrate with respect to x,
holding y constant, and

00:04:15.550 --> 00:04:17.200
then integrate it with respect to y.

00:04:17.200 --> 00:04:22.030
Basically, the only complicated thing is
figuring out the limits of integration.

00:04:22.030 --> 00:04:27.980
So I just wrote double interval over A,
cuz A could be any region in the plane.

00:04:27.980 --> 00:04:32.310
So if we had something like,
if A is this blob,

00:04:34.260 --> 00:04:37.010
that may be a hard
problem to this integral.

00:04:37.010 --> 00:04:39.240
What does it mean to
integrate over the blob?

00:04:39.240 --> 00:04:42.650
I mean, that turns into a nasty
multi-variable calculus problem.

00:04:42.650 --> 00:04:44.870
That's not something we care about for
this course.

00:04:44.870 --> 00:04:46.310
It's just a nasty calculus problem.

00:04:46.310 --> 00:04:47.990
It's not an interesting
probability problem.

00:04:49.730 --> 00:04:51.660
So the more interesting case for

00:04:51.660 --> 00:04:54.570
our purposes would be if it's,
let's call that A1.

00:04:54.570 --> 00:04:57.340
Down here's the A we actually want.

00:04:57.340 --> 00:05:01.980
If it's a rectangle, then this
double integral just means integrate

00:05:01.980 --> 00:05:04.140
x goes from here to here,
y goes from here to here.

00:05:04.140 --> 00:05:07.170
So it's just literally
the integral of the integral so

00:05:07.170 --> 00:05:09.000
it's no different from
doing two integrals.

00:05:09.000 --> 00:05:12.240
So you don't have to worry
too much about the blobs.

00:05:12.240 --> 00:05:15.590
There's only one case where we might
care about the blobs in this course.

00:05:15.590 --> 00:05:19.260
And that's when we have a uniform
distribution over some region.

00:05:19.260 --> 00:05:20.680
So I'll come back to this.

00:05:20.680 --> 00:05:25.000
So at the very end last time we were
talking about a distribution that's

00:05:25.000 --> 00:05:30.050
uniform over a square or
over a circle, that kinda thing.

00:05:30.050 --> 00:05:34.110
And in the uniform case, we can interpret
probability as proportional to area.

00:05:35.420 --> 00:05:37.880
So in the uniform case probability
is proportional to area.

00:05:37.880 --> 00:05:39.080
And then I could say well,

00:05:39.080 --> 00:05:42.230
I'm just going to do something
proportional to the area of the blob.

00:05:42.230 --> 00:05:44.330
And at least I can think
more geometrically.

00:05:47.100 --> 00:05:51.730
But anyway, conceptually it's analogous.

00:05:51.730 --> 00:05:56.680
The joint PDF is what we integrate
to get the probability of any

00:05:56.680 --> 00:05:59.690
of xy being in any particular set, right?

00:05:59.690 --> 00:06:02.870
In one dimension we'd say, what's
the probability of x is between -3 and

00:06:02.870 --> 00:06:03.570
5, right?

00:06:03.570 --> 00:06:05.210
We want an interval.

00:06:05.210 --> 00:06:07.650
And here we want the probability
that it's in some region.

00:06:09.060 --> 00:06:11.580
But the rectangular case
is gonna be the nicest one.

00:06:12.940 --> 00:06:15.980
So, those are joint distributions.

00:06:15.980 --> 00:06:18.990
And I talked a little bit last time
about how to get them marginal.

00:06:20.040 --> 00:06:22.121
And it's very straight forward.

00:06:22.121 --> 00:06:23.743
Marginal PDF of x.

00:06:23.743 --> 00:06:29.380
To get the marginal PDF of x,
we just integrate out the y.

00:06:30.460 --> 00:06:35.377
So we just integrate minus
infinity to infinity, f (xy) dy.

00:06:37.810 --> 00:06:43.130
Notice that by doing this, we'll get
something that's now a function of x.

00:06:43.130 --> 00:06:47.520
X is just treated as a constant
here we are integrating overall y

00:06:47.520 --> 00:06:50.890
this is no longer gonna depend on y
because you're integrating overall

00:06:50.890 --> 00:06:52.300
y becomes a dummy variable.

00:06:53.780 --> 00:06:58.410
Similarly you get the marginal
PDF of y by integrating dx.

00:07:00.190 --> 00:07:05.940
And this is just completely analogous
to doing a summing over the cases.

00:07:05.940 --> 00:07:09.550
It's just saying we want
x to be this little x.

00:07:09.550 --> 00:07:10.891
And y has to be something.

00:07:10.891 --> 00:07:12.629
So we just integrate
over all possibilities.

00:07:12.629 --> 00:07:15.480
So that's the marginal.

00:07:15.480 --> 00:07:17.520
So that's called marginalization.

00:07:17.520 --> 00:07:19.280
We marginalized out the y.

00:07:19.280 --> 00:07:20.920
Then we get the marginal of that.

00:07:20.920 --> 00:07:22.990
We integrate out the y,
we get the marginal of x.

00:07:22.990 --> 00:07:25.600
It's just terminology for
something very simple.

00:07:25.600 --> 00:07:26.460
Just integrate.

00:07:28.480 --> 00:07:30.860
If we did a double integral.

00:07:30.860 --> 00:07:35.370
So if we then took this thing and
integrate this dx, we should get 1.

00:07:35.370 --> 00:07:41.070
And what that says, one way to think of it
is to say if we let A be the entire plane,

00:07:41.070 --> 00:07:42.780
everything, we'd better get 1, right?

00:07:42.780 --> 00:07:45.600
Otherwise it wouldn't make any sense.

00:07:45.600 --> 00:07:49.690
The other way to think of it is this
is supposed to be the density of x,

00:07:49.690 --> 00:07:52.020
just viewed as x in its own.

00:07:52.020 --> 00:07:54.940
So if we integrate this dx,
we have to get 1,

00:07:54.940 --> 00:07:57.647
otherwise do not find
a valid marginal PDF.

00:07:57.647 --> 00:07:59.578
So that has to integrate to 1.

00:07:59.578 --> 00:08:06.090
May as well write that down just for
emphasis, the double integral equals 1.

00:08:06.090 --> 00:08:08.270
And it's always minus
infinity to infinity,

00:08:08.270 --> 00:08:12.570
minus infinity to infinity to start with.

00:08:12.570 --> 00:08:16.500
It might be that this is zero
outside of some region, and

00:08:16.500 --> 00:08:18.370
then we could restrict it further.

00:08:18.370 --> 00:08:21.343
But we could always write
it like this at first, and

00:08:21.343 --> 00:08:25.576
then we should be careful about where
is it zero or where is it non-zero.

00:08:25.576 --> 00:08:30.952
So that's gonna be our marginal,
let's do a conditional.

00:08:30.952 --> 00:08:36.030
Conditional distribution,
so we want conditional PDF.

00:08:36.030 --> 00:08:39.514
And this should be easy to understand and
remember,

00:08:39.514 --> 00:08:43.725
because it's analogous to
conditioning we've done before.

00:08:43.725 --> 00:08:48.541
So let's say we want
the conditional PDF of Y|X,

00:08:48.541 --> 00:08:52.105
well, we would just write that as f.

00:08:52.105 --> 00:08:55.582
Sometimes we'd put a subscript
of Y|X just for emphasis.

00:08:55.582 --> 00:08:57.716
And sometimes we may
leave out the subscript,

00:08:57.716 --> 00:08:59.530
just cuz it's clear from the context.

00:09:01.006 --> 00:09:05.760
Conditional PDF It's just,

00:09:05.760 --> 00:09:09.790
think of it as the PDF where we get
to pretend that we know what X is.

00:09:09.790 --> 00:09:12.270
We get to observe what x is, okay?

00:09:12.270 --> 00:09:13.330
Given that information,

00:09:13.330 --> 00:09:17.800
that we now know the value of x,
what is the appropriate PDF for y?

00:09:17.800 --> 00:09:24.940
Well, we could think of
that as being the joint

00:09:24.940 --> 00:09:31.710
density, divided by
the marginal density of x.

00:09:33.620 --> 00:09:37.718
What I just wrote down just
looks like the definition of

00:09:37.718 --> 00:09:40.492
conditional probability, right?

00:09:40.492 --> 00:09:43.914
The probability of this given this
is the probability of this and this,

00:09:43.914 --> 00:09:45.977
divided by the probability of this thing.

00:09:45.977 --> 00:09:49.966
Now x and y are representing numbers,
not events, okay?

00:09:49.966 --> 00:09:53.653
But it looks the same as the definition
of conditional probability, and

00:09:53.653 --> 00:09:57.227
you can derive this from the definition
of conditional probability.

00:09:57.227 --> 00:10:01.417
Where basically what you would do is say,

00:10:01.417 --> 00:10:05.616
our event is that y is either, take y = Y.

00:10:05.616 --> 00:10:10.310
Or if we are worried about probability
zero, say y is extremely close to Y.

00:10:10.310 --> 00:10:15.370
That is, we let capital Y be
in some tiny little interval

00:10:15.370 --> 00:10:21.040
around little y and find the conditional
probability of that, given the value of x.

00:10:21.040 --> 00:10:24.590
And it's completely analogous
to conditional probability.

00:10:24.590 --> 00:10:29.350
So this says that we can get
the conditional just by doing

00:10:29.350 --> 00:10:34.310
the joint distribution, joint density
divided by the marginal density.

00:10:34.310 --> 00:10:36.770
We could also do something
that looks like Bayes' rule.

00:10:38.150 --> 00:10:42.649
That is, what if we want
the conditional PDF of Y|X?

00:10:42.649 --> 00:10:45.513
Well, we want fX|Y(x|y) fY(y),

00:10:45.513 --> 00:10:50.074
I'm just writing down something
that looks like Bayes' rule,

00:10:56.570 --> 00:10:57.873
That looks like Bayes' rule, right?

00:10:57.873 --> 00:11:02.912
I swapped the x and the y, but
instead of probability I'm doing density,

00:11:02.912 --> 00:11:05.920
completely analogous to Bayes' rule.

00:11:05.920 --> 00:11:08.800
The proof is really, use Bayes' rule and

00:11:08.800 --> 00:11:13.660
then take a limit, and so
this should be easy to remember.

00:11:13.660 --> 00:11:18.234
And the numerator is the same, another
way to say this is that to get the joint

00:11:18.234 --> 00:11:23.547
density, we can take one of the marginals,
then times the other conditional, right?

00:11:23.547 --> 00:11:27.099
That's like, if we're pretending it's
probability rather than density.

00:11:27.099 --> 00:11:30.658
It's like the probability of this y value
times the probability of the x value,

00:11:30.658 --> 00:11:31.580
given that y value.

00:11:31.580 --> 00:11:36.409
So everything is analagous to
Bayes' rule in the discrete case.

00:11:37.660 --> 00:11:42.360
All right, so those are just
the basic concepts we need for that.

00:11:42.360 --> 00:11:48.140
And I should mention again
how to think of independence,

00:11:48.140 --> 00:11:50.440
so again, this is the continuous case.

00:11:50.440 --> 00:11:54.470
X and Y are independent if,

00:11:57.540 --> 00:12:01.420
well, the general definition
in terms of CDFs, but

00:12:01.420 --> 00:12:04.840
it's usually easier to work
with the PDF than the CDF.

00:12:04.840 --> 00:12:09.812
So usually, the best way to think
of it is independent means that

00:12:09.812 --> 00:12:13.420
the joint PDF is the product
of the marginal PDFs.

00:12:15.380 --> 00:12:18.089
And that has to hold for all x and y.

00:12:22.430 --> 00:12:27.510
It's not too hard to show that that's
equivalent to having the CDFs factor.

00:12:27.510 --> 00:12:29.880
Cuz basically, if the CDFs factor,

00:12:29.880 --> 00:12:34.730
you could take the derivative, this
derivative thing, and you'll get this.

00:12:34.730 --> 00:12:37.740
You could take this thing, and
integrate, and go back there, so

00:12:37.740 --> 00:12:39.010
it's basically equivalent.

00:12:39.010 --> 00:12:40.099
Intuitively, it should be equivalent.

00:12:42.230 --> 00:12:48.472
All right, so
let's come back to this uniform example.

00:12:48.472 --> 00:12:51.342
Because I wanted to write
what the conditional,

00:12:51.342 --> 00:12:54.702
we wrote down the joint PDF last time,
I'll remind you.

00:12:54.702 --> 00:13:02.545
That is, we have the distribution that was
uniform on a circle, or inside the disc.

00:13:02.545 --> 00:13:09.606
So uniform in the disc, which is x squared
+ y squared less than or equal to 1.

00:13:09.606 --> 00:13:13.390
We are picking a uniformly random point,
maybe there.

00:13:14.670 --> 00:13:22.121
Uniform means that probability of some
region is proportional to area, okay?

00:13:22.121 --> 00:13:27.077
So therefore, so one nice thing
when we have problems that involve

00:13:27.077 --> 00:13:30.979
a uniform distribution on
some region in the plane.

00:13:30.979 --> 00:13:33.283
We can actually think of
probability in terms of area, or

00:13:33.283 --> 00:13:34.820
at least it's proportional to area.

00:13:36.640 --> 00:13:41.748
So the joint PDF we did
last time Is just 1

00:13:41.748 --> 00:13:46.885
over pi, it's one over the area,
because that'll make it integrate to 1.

00:13:48.060 --> 00:13:53.775
Within the circle,
x squared + y squared less than or

00:13:53.775 --> 00:13:57.721
equal to 1, and 0 outside, okay?

00:13:57.721 --> 00:14:02.866
But just for practice,
let's get the marginal density of x and

00:14:02.866 --> 00:14:06.662
then the conditional density, x|y or y|x.

00:14:06.662 --> 00:14:13.768
So, and by the way, this may look like
they're independent because this doesn't,

00:14:13.768 --> 00:14:19.310
this looks like somehow it factors
as a constant times a constant.

00:14:19.310 --> 00:14:21.795
But x and
y are not independent here, right?

00:14:21.795 --> 00:14:27.131
Because it x is very close to 1,
then it's constraining the values of y,

00:14:27.131 --> 00:14:29.810
so they're definitely dependent.

00:14:29.810 --> 00:14:31.413
You have to be careful
about things like that.

00:14:31.413 --> 00:14:33.342
Cuz if you just only
look at the 1 over pi,

00:14:33.342 --> 00:14:35.285
it looks like they might be independent.

00:14:35.285 --> 00:14:39.430
But the key thing is that they
are constrained together to be, right?

00:14:39.430 --> 00:14:42.380
So this is saying that x and
y are actually closely related.

00:14:42.380 --> 00:14:45.066
But if you only look at this part and
ignore this part,

00:14:45.066 --> 00:14:47.105
you might think they're independent.

00:14:47.105 --> 00:14:51.512
All right, so let's get the marginal,

00:14:51.512 --> 00:14:56.703
fx(x), all we have to
do integrate out the y.

00:14:56.703 --> 00:15:01.494
So we're gonna integrate the joint PDF,
which is 1 over pi,

00:15:01.494 --> 00:15:07.690
as long as we're careful to,
we're gonna integrate this thing, dy.

00:15:07.690 --> 00:15:11.909
The only thing we have to be careful
about is the limits of integration.

00:15:11.909 --> 00:15:15.579
This is only valid when x squared +
y squared is less than or equal to 1.

00:15:15.579 --> 00:15:19.508
Which is the same thing as saying
that y squared is less than or

00:15:19.508 --> 00:15:21.136
equal to 1- x squared.

00:15:21.136 --> 00:15:25.027
And that tells us that y has to be
between minus square root of this and

00:15:25.027 --> 00:15:26.540
plus square root of this.

00:15:28.640 --> 00:15:33.933
So we're gonna integrate from
minus square root 1- x squared,

00:15:33.933 --> 00:15:37.080
to square root of 1- x squared.

00:15:37.080 --> 00:15:39.520
So the main mistake with
this kind of problem

00:15:39.520 --> 00:15:41.960
is messing up the limits
of integration somehow.

00:15:41.960 --> 00:15:44.880
We have to be very,
very careful with limits of integration.

00:15:44.880 --> 00:15:49.460
You're not actually ever gonna have to do
any difficult integral in this course.

00:15:49.460 --> 00:15:53.450
But sometimes, you have to think carefully
about the limits of integration, okay?

00:15:53.450 --> 00:15:56.930
So this is just saying,
these are the bounds on y for

00:15:56.930 --> 00:16:01.270
which I should have 1 over
pi rather than 0 here, okay?

00:16:01.270 --> 00:16:03.300
So if we get the limits
of integration wrong,

00:16:03.300 --> 00:16:04.342
then it's just Just completely wrong.

00:16:04.342 --> 00:16:07.745
All right, this is a very easy integral.

00:16:07.745 --> 00:16:13.520
This integral of a constant is just the
constant times the length of the interval.

00:16:13.520 --> 00:16:18.670
So that's just 2/pi square
root of 1- x squared.

00:16:18.670 --> 00:16:22.468
And that's valid for -1 less than or
= x less than or = 1.

00:16:25.355 --> 00:16:30.361
As a check,
we could integrate this thing, dx and,

00:16:33.733 --> 00:16:38.119
How do you actually integrate
the square root of one minus x squared?

00:16:38.119 --> 00:16:41.460
You would do a trick substitution.

00:16:41.460 --> 00:16:45.622
I'm not gonna do that integral right now,
but you could integrate this thing from

00:16:45.622 --> 00:16:48.960
minus one to one, use a trick
substitution as he just suggested.

00:16:48.960 --> 00:16:54.260
That's basically gonna reduce it back down
to the fact that it's based on a circle,

00:16:54.260 --> 00:16:55.930
and you'll get one.

00:16:55.930 --> 00:16:58.691
So that does integrate to one.

00:17:00.072 --> 00:17:05.424
So that's the marginal, notice that
this does not look like a uniform,

00:17:05.424 --> 00:17:11.142
so it's certainly false to say that
it's uniform between minus one and one.

00:17:11.142 --> 00:17:15.681
The point xy is uniform, but
the marginals are not uniform, right, and

00:17:15.681 --> 00:17:20.383
in fact you can see that this is largest
when x is 0 which kinda makes sense.

00:17:20.383 --> 00:17:22.973
Cuz if you imagine the random point here,

00:17:22.973 --> 00:17:26.821
then kind of near the center
seems like there's more space for

00:17:26.821 --> 00:17:31.267
stuff to happen and seems a little
less likely to be further out, okay?

00:17:31.267 --> 00:17:33.331
So let's get the conditional PDF now.

00:17:36.413 --> 00:17:40.742
All right so we can either do y given x or
x given y whichever we feel like.

00:17:40.742 --> 00:17:46.221
Notice that if you want the marginal
PDF of y, just changed the letter

00:17:46.221 --> 00:17:51.145
x to y here by symmetry no need
to repeat the same calculation.

00:17:53.587 --> 00:17:58.370
Okay, so let's do the PDF of y given x.

00:17:59.670 --> 00:18:07.055
So that's just gonna be be the joint
PDF divided by the marginal PDF of x.

00:18:07.055 --> 00:18:13.248
So it's just gonna be 1/pi/2/pi,

00:18:13.248 --> 00:18:17.624
square root 1- x squared.

00:18:17.624 --> 00:18:21.764
I just took the joint PDF
divided by the marginal PDF, and

00:18:21.764 --> 00:18:26.440
we have to be careful about
where is this non-zero.

00:18:26.440 --> 00:18:30.334
I'm thinking of y as fixed right now,
it's like we get to observe x and

00:18:30.334 --> 00:18:33.244
I wanna say well,
what are the possible values of y?

00:18:33.244 --> 00:18:37.021
Well, for each x,
we know that y has to be between,

00:18:40.082 --> 00:18:43.241
square root of 1- the same thing again.

00:18:43.241 --> 00:18:48.526
y has to be between root 1- x squared,

00:18:48.526 --> 00:18:51.577
okay, 0 otherwise.

00:18:53.652 --> 00:18:55.153
So the pi's cancel, and,

00:19:02.327 --> 00:19:03.952
That looks kind of ugly.

00:19:03.952 --> 00:19:08.086
What would be another way to say
what this conditional density is?

00:19:11.769 --> 00:19:12.824
You're treating x as a constant.

00:19:21.098 --> 00:19:23.292
What would you call this thing?

00:19:23.292 --> 00:19:27.923
Uniform, because notice this
only has a x here, there's no y.

00:19:27.923 --> 00:19:30.153
And general you would have a y here.

00:19:30.153 --> 00:19:32.630
There's no letter y on the right
side of this equation.

00:19:32.630 --> 00:19:37.912
So a nicer way to write
this would be to say that

00:19:37.912 --> 00:19:44.167
y given X is uniform between
(- root 1- X squared,

00:19:44.167 --> 00:19:52.385
root 1- x squared) because this is
just a constant for each fixed x.

00:19:52.385 --> 00:19:57.680
I wrote this with capital X
here to clarify this notation.

00:19:57.680 --> 00:20:00.130
When you see this thing
like y given capital X.

00:20:00.130 --> 00:20:01.230
What does that mean?

00:20:01.230 --> 00:20:06.129
Intuitively that means just pretend that
capital X, we know x is a random variable

00:20:06.129 --> 00:20:10.044
but pretend capital X is a known
constant cuz we got to observe it.

00:20:10.044 --> 00:20:18.729
But you can just think of this as
short hand for saying, Y given X = x.

00:20:18.729 --> 00:20:23.393
This kind of is a more direct way to write
it that is we get to observe that X = x.

00:20:23.393 --> 00:20:28.476
And we're saying that if we know that
then we have a uniform distribution,

00:20:28.476 --> 00:20:33.729
between (- square root of 1- x squared,
square root of 1- x squared).

00:20:35.793 --> 00:20:37.868
But its a little more cumbersome
to write it this way.

00:20:37.868 --> 00:20:40.943
So sometimes I'll write it
this way with capital x but

00:20:40.943 --> 00:20:43.480
just treat that as short hand for this.

00:20:43.480 --> 00:20:49.786
That just means given that we get to know
what x is, here's the distribution for y.

00:20:49.786 --> 00:20:52.194
So we're treating x as a constant here,
and

00:20:52.194 --> 00:20:56.570
here we're explicitly calling that
constant little x, it's just notation.

00:20:58.130 --> 00:21:04.850
So okay, so that says it's conditionally
uniform over some interval.

00:21:04.850 --> 00:21:06.237
Notice that that's
the appropriate interval.

00:21:06.237 --> 00:21:11.060
Cuz as soon as you specify what x is,
we know y has to be between here and here.

00:21:11.060 --> 00:21:11.856
This says it's uniform.

00:21:13.974 --> 00:21:17.015
So similarly you could do f of x given y.

00:21:18.801 --> 00:21:23.774
And you can see that
they're not independent,

00:21:23.774 --> 00:21:27.996
because well one way to see it, is, fx,

00:21:27.996 --> 00:21:35.716
y does not equal the product of
the marginal PDFs in general here, right?

00:21:35.716 --> 00:21:39.031
Take this thing and
then the same thing with y,

00:21:39.031 --> 00:21:42.350
you multiply them you do
not get the joint PDF.

00:21:44.420 --> 00:21:45.660
So they're not independent.

00:21:46.750 --> 00:21:52.446
Another way to say they're not independent
is that the conditional distribution

00:21:52.446 --> 00:21:57.496
of y given x is not the same thing as
the unconditional distribution of y.

00:21:57.496 --> 00:22:03.020
That is learning x gives us information,
okay?

00:22:03.020 --> 00:22:09.570
All right, so those are these basic
concepts, joint, conditional, marginal.

00:22:09.570 --> 00:22:15.580
I wanted to mention one more thing that's
analogous to the one-dimensional case.

00:22:15.580 --> 00:22:17.481
And that's what I call the 2D LOTUS.

00:22:20.567 --> 00:22:21.781
And it's completely analogous.

00:22:26.575 --> 00:22:31.065
So we wanna do LOTUS where we have
a function of more than one variable.

00:22:31.065 --> 00:22:36.730
So, let's let (x,y) have a joint PDF.

00:22:36.730 --> 00:22:38.750
I'll state it in the continuous case, but

00:22:38.750 --> 00:22:41.229
you could also do a discrete
2-D LOTUS if you want.

00:22:44.067 --> 00:22:50.725
So we have a joint PDF, f(x,y) okay,

00:22:50.725 --> 00:22:54.856
and then just let g be any function of xy.

00:22:58.026 --> 00:22:59.650
Let's say it's real valued.

00:23:00.930 --> 00:23:07.270
So this function g, takes two values
as input and outputs one value.

00:23:07.270 --> 00:23:12.196
For example it could just be x plus y, or
it could be x squared times sine of x,y,

00:23:12.196 --> 00:23:13.459
cubed or whatever.

00:23:13.459 --> 00:23:16.683
Just any function of x,y, okay?

00:23:16.683 --> 00:23:19.517
A real-valued function of x,y.

00:23:21.342 --> 00:23:22.882
And then we're gonna write down LOTUS.

00:23:25.597 --> 00:23:30.185
LOTUS tells us how to get
the expected value of g(X, Y), and

00:23:30.185 --> 00:23:34.506
it says, we do not need to try
to find the PDF of g(x, y),

00:23:34.506 --> 00:23:37.970
we can work directly in
terms of the joint PDF.

00:23:37.970 --> 00:23:41.306
And all we have to do is integrate,

00:23:43.498 --> 00:23:47.740
It's gonna be minus infinity to
infinity minus infinity to infinity.

00:23:47.740 --> 00:23:51.736
But possibly we can narrow
it down that range of

00:23:51.736 --> 00:23:55.741
I just change capital
X,Y to lowercase x,y.

00:23:55.741 --> 00:23:57.081
And then I use the joint PDF.

00:24:01.333 --> 00:24:04.220
Completely analogous.

00:24:07.000 --> 00:24:12.250
So let's do a couple of examples,
how is this fact useful?

00:24:13.440 --> 00:24:20.690
So here is an important fact that I
already needed this fact once and

00:24:20.690 --> 00:24:24.930
we didn't improve it yet, which was
like we were talking about the fact that

00:24:24.930 --> 00:24:30.670
the MGF of a sum of independent random
variables is the product of the MGFs.

00:24:30.670 --> 00:24:33.710
And at some point we need to say E
of something times something is E of

00:24:33.710 --> 00:24:35.630
something, E of the other thing.

00:24:35.630 --> 00:24:39.265
That's true when they're independent,
that's what we need to show right now.

00:24:41.698 --> 00:24:45.722
So the theorem is that if X and
Y are independent.

00:24:48.880 --> 00:24:54.953
Then E of XY equals E of X E of Y,
that's a very useful fact.

00:24:57.385 --> 00:25:02.500
Well, we'll come back to this fact
later when we talk about correlation,

00:25:02.500 --> 00:25:07.775
the way we would say this in words is
that independent implies uncorrelated,

00:25:07.775 --> 00:25:10.060
that's just foreshadowing.

00:25:10.060 --> 00:25:13.520
Later we'll talk more about what
exactly does correlation mean.

00:25:13.520 --> 00:25:18.020
But, when we define correlation,
in a later lecture,

00:25:18.020 --> 00:25:20.590
we'll see that that actually
says that they're uncorrelated.

00:25:20.590 --> 00:25:21.460
And so

00:25:21.460 --> 00:25:25.140
this independent implies uncorrelated,
is the way to say it in words.

00:25:27.860 --> 00:25:29.300
So let's prove this fact.

00:25:30.530 --> 00:25:32.840
And this is always true.

00:25:32.840 --> 00:25:35.670
It doesn't matter if they're continuous or
discrete or whatever.

00:25:35.670 --> 00:25:39.690
But so we don't have to invent a lot
of notations or do a lot of cases,

00:25:39.690 --> 00:25:42.670
let's just do a continuous case for
practice.

00:25:43.930 --> 00:25:52.190
So proof in the continuous case Well,
we're just gonna use the 2D LOTUS.

00:25:53.820 --> 00:25:59.390
That saves us a lot of effort, because
when you just see this thing E of X.

00:25:59.390 --> 00:26:03.270
X times Y is a random
variable in its own right.

00:26:03.270 --> 00:26:04.350
So the first time you see this,

00:26:04.350 --> 00:26:07.280
you might think I need to
study that random variable.

00:26:07.280 --> 00:26:08.305
That takes a lot of work.

00:26:08.305 --> 00:26:13.447
2D LOTUS just says that's the function
of XY I'm just gonna use LOTUS and

00:26:13.447 --> 00:26:14.438
then it's gonna be easy.

00:26:14.438 --> 00:26:20.780
So E of XY equals, how do we do this?

00:26:20.780 --> 00:26:28.038
Well, I'll just write down double
integral minus infinity to infinity,

00:26:28.038 --> 00:26:33.820
minus infinity to infinity
xy times the joint PDF.

00:26:33.820 --> 00:26:35.790
But since we assumed
that they're independent,

00:26:35.790 --> 00:26:39.450
the joint PDF is just the product
of the marginal PDFs.

00:26:41.310 --> 00:26:45.280
So independence means the joint
PDF just factors like that.

00:26:46.660 --> 00:26:51.800
And that's what makes this,
actually, easy to deal with.

00:26:51.800 --> 00:26:54.870
Because this function is
just separated out like,

00:26:54.870 --> 00:26:57.350
this is a function of X function of Y.

00:26:57.350 --> 00:26:58.930
Function of X, function of Y.

00:26:58.930 --> 00:26:59.430
Very nice.

00:27:01.850 --> 00:27:04.620
So, now, what do we actually do?

00:27:04.620 --> 00:27:07.129
Well, what this is to do is take this.

00:27:08.790 --> 00:27:11.390
I'll put parentheses here to
make it a little clearer what

00:27:11.390 --> 00:27:12.930
this double integral means.

00:27:12.930 --> 00:27:14.980
That's just the definition
of this double integral.

00:27:14.980 --> 00:27:19.820
It says do this integral, then to this
outer integral, so you work your way out.

00:27:21.710 --> 00:27:25.190
When you're doing this inner integral
you're treating Y as a constant, so

00:27:25.190 --> 00:27:28.360
this Y you're gonna stick it right there.

00:27:28.360 --> 00:27:31.560
And this fy of y also stick that there.

00:27:32.570 --> 00:27:33.520
Both of those come out.

00:27:34.765 --> 00:27:38.280
So that look a little messy,
let's rewrite that.

00:27:38.280 --> 00:27:44.201
All I did was to take out the y and
the marginal PDF of y.

00:27:44.201 --> 00:27:50.398
And what's left is the x and
the marginal PDF of x.

00:27:55.191 --> 00:27:57.770
So I just took them out.

00:27:57.770 --> 00:28:02.780
Now this whole thing here,
that's just a number.

00:28:04.050 --> 00:28:08.690
That just says we took this function and
we integrated it over x and

00:28:08.690 --> 00:28:09.420
we get a number.

00:28:09.420 --> 00:28:11.340
That's just a constant.

00:28:11.340 --> 00:28:16.950
And we know what constant that is,
that's E of X.

00:28:16.950 --> 00:28:17.870
That's just a number.

00:28:18.910 --> 00:28:22.950
So that constant you can pull
out of this entire integral.

00:28:22.950 --> 00:28:25.520
It's just a constant,
take it out of the integral.

00:28:25.520 --> 00:28:26.840
What's left?

00:28:26.840 --> 00:28:30.330
Integral of Y times the PDF of Y.

00:28:30.330 --> 00:28:32.100
That's just E of Y.

00:28:32.100 --> 00:28:38.991
So that's immediately just E of X E of Y.

00:28:38.991 --> 00:28:45.782
So basically this amounts
to E of X E of Y.

00:28:45.782 --> 00:28:49.731
All this amounts to doing is just taking
out things that you're treating as

00:28:49.731 --> 00:28:51.430
constant and then the factors.

00:28:52.540 --> 00:28:53.910
So that's a useful fact.

00:28:53.910 --> 00:28:58.030
And it would be a nightmare to try to
prove this without having LOTUS available.

00:28:58.030 --> 00:29:00.512
But with LOTUS then we can
do that pretty quickly.

00:29:03.451 --> 00:29:08.760
All right, there's another problem
I like to do with the 2D LOTUS.

00:29:08.760 --> 00:29:13.367
And that's like expected
distance between two points.

00:29:15.897 --> 00:29:20.420
So let's start with the uniform case.

00:29:20.420 --> 00:29:24.490
I talked about this on the strategic
practice too, you can look at that later.

00:29:24.490 --> 00:29:29.530
But I think this is a useful point for
everyone to see this now.

00:29:29.530 --> 00:29:34.060
So we have, so this is an example,
where we take two uniforms,

00:29:34.060 --> 00:29:38.730
let's let them be X and Y, B i.i.d.

00:29:38.730 --> 00:29:40.060
uniform 0, 1.

00:29:40.060 --> 00:29:46.844
And we wanna find expected
distance between them.

00:29:52.290 --> 00:29:56.893
So, this kind of problem comes a lot
in applications where you have two

00:29:56.893 --> 00:29:58.000
random points.

00:29:58.000 --> 00:30:00.720
And often you wanna know
how far apart they are.

00:30:00.720 --> 00:30:05.910
So, this is used for various applications.

00:30:05.910 --> 00:30:11.060
And so one approach would be,
try to study absolute value of X minus Y,

00:30:11.060 --> 00:30:16.420
find it's distribution and maybe for
some problems we need the distribution.

00:30:16.420 --> 00:30:19.500
But in this case,
they said I only want the mean, so,

00:30:19.500 --> 00:30:23.170
therefore LOTUS should suffice for that.

00:30:23.170 --> 00:30:29.595
So just write down LOTUS So

00:30:29.595 --> 00:30:32.600
it's a double integral, x minus y.

00:30:33.680 --> 00:30:38.006
And since they're i.i.d uniformed,
the PDF is just 1.

00:30:38.006 --> 00:30:39.230
The joint PDF is just 1.

00:30:39.230 --> 00:30:47.212
So you just have to integrate this thing,
dxdy from 0 to 1, 0 to 1.

00:30:47.212 --> 00:30:55.740
So, Then the only question I guess is
how do we integrate the absolute value?

00:30:55.740 --> 00:30:59.040
Well usually if you wanna
integrate an absolute value,

00:30:59.040 --> 00:31:03.370
the best strategy would be to
split the integral into pieces

00:31:03.370 --> 00:31:06.200
such that you can get rid
of the absolute value.

00:31:06.200 --> 00:31:12.180
So we could split this up as one
piece where x is greater than y.

00:31:12.180 --> 00:31:14.050
I'll write it this way.

00:31:14.050 --> 00:31:14.790
X greater than y.

00:31:14.790 --> 00:31:19.380
That is I'm integrating over
the set of all points in 0,

00:31:19.380 --> 00:31:23.590
1 where x is greater
than y of this function.

00:31:23.590 --> 00:31:27.370
Now if x is greater than y,
I can just drop the absolute value

00:31:28.820 --> 00:31:34.020
plus and now integrate over the piece
where x is less than or equal to y.

00:31:34.020 --> 00:31:38.880
And in that case,
it's y minus x not x minus y.

00:31:47.875 --> 00:31:51.181
Now if you think of
the symmetry of the problem,

00:31:51.181 --> 00:31:55.740
this problem is completely
symmetrical because of the i.i.d.

00:31:55.740 --> 00:32:00.250
And this is symmetrical function,
I could have changed this to y minus x.

00:32:00.250 --> 00:32:02.810
So, really there is no point
in doing two double integrals,

00:32:02.810 --> 00:32:05.141
let's just do one and
double integral, and double it.

00:32:05.141 --> 00:32:11.510
And then we have to do two integrals
instead of four, so that's much nicer.

00:32:11.510 --> 00:32:17.390
This is just gonna be 2 times
the first integral I wrote down.

00:32:17.390 --> 00:32:20.730
Okay, I am not gonna do a lot
of double integrals in class and

00:32:20.730 --> 00:32:25.010
you won't have to do many double
integral in general in this course.

00:32:25.010 --> 00:32:28.038
We will have to do a couple of them.

00:32:28.038 --> 00:32:30.610
So just for practice, let's do this.

00:32:30.610 --> 00:32:33.880
Basically, the only thing you could
mess up is the limits of integration.

00:32:33.880 --> 00:32:38.207
So let's carefully say, how do we get
the correct limits of integration here?

00:32:39.582 --> 00:32:42.061
The outer limits, I could've done dydx and

00:32:42.061 --> 00:32:45.220
then it'll be different
limits of integration.

00:32:45.220 --> 00:32:48.964
Okay, but I chose, for no particular
reason, to just write it as dxdy.

00:32:51.421 --> 00:32:56.570
So if we write dxdy,
the outer limits must refer to y.

00:32:56.570 --> 00:32:59.321
And we know y goes from 0 to 1.

00:32:59.321 --> 00:33:05.420
Okay, now the inner limits, so these
outer limits have to just be numbers.

00:33:05.420 --> 00:33:10.952
But as you move inward, the limits can
start depending on other variables,

00:33:10.952 --> 00:33:13.725
so these inner limits can depend on y.

00:33:13.725 --> 00:33:16.022
In fact, they have to depend on y.

00:33:16.022 --> 00:33:19.719
Okay, it would not work to go 0 to 1 here.

00:33:19.719 --> 00:33:21.833
We know x has to be between 0 and 1.

00:33:21.833 --> 00:33:25.609
But we also know that we're only
integrating over x greater than y, so

00:33:25.609 --> 00:33:27.620
x has to be greater than y.

00:33:27.620 --> 00:33:29.500
So we go from y to 1.

00:33:29.500 --> 00:33:31.920
Right, because x is bigger than y so
it has to start at y,

00:33:31.920 --> 00:33:33.660
so that's all we have to do.

00:33:33.660 --> 00:33:34.570
We do have to be careful.

00:33:34.570 --> 00:33:36.820
It's easy to mess up
the limits of integration.

00:33:36.820 --> 00:33:41.112
Now this just says do 2 easy integrals,
okay?

00:33:41.112 --> 00:33:46.347
So it's integral 0 to 1,
this inner integral,

00:33:48.875 --> 00:33:53.549
Inner integral, I integrate x- y dx so

00:33:53.549 --> 00:33:57.515
I'm treating y as a constant, so

00:33:57.515 --> 00:34:02.063
I would just do x squared over 2- yx.

00:34:03.320 --> 00:34:08.832
All right, I'm treating y as a constant
and then evaluate this from y to 1.

00:34:10.396 --> 00:34:15.099
Okay, and so then we just plug in 1 and
subtract, plug in y.

00:34:15.099 --> 00:34:17.440
And then it's just a very,
very easy integral.

00:34:17.440 --> 00:34:20.110
And I won't bore you with
all the algebra for that.

00:34:20.110 --> 00:34:24.050
You just plug in 1, plug in y, and
it's integrating a very easy integral.

00:34:24.050 --> 00:34:26.866
If you simplify that you get one-third.

00:34:29.722 --> 00:34:33.231
So the average distance between
two uniforms is one-third.

00:34:34.372 --> 00:34:39.640
Let's draw a little picture to see
whether that makes intuitive sense to us.

00:34:39.640 --> 00:34:43.883
So we have this interval 0 to 1, okay?

00:34:43.883 --> 00:34:48.585
And we're picking 2 uniformly
random points in this interval.

00:34:48.585 --> 00:34:55.312
Let's say there and
there, completely random.

00:34:55.312 --> 00:35:00.942
But notice that the distance between then
is one-third because that's one-third,

00:35:00.942 --> 00:35:03.883
two-thirds, the distance is one-third.

00:35:03.883 --> 00:35:06.326
That sort of looks like
your stereotypical,

00:35:06.326 --> 00:35:09.218
if you had to guess something
what would it look like,

00:35:09.218 --> 00:35:12.387
that might be what you would guess,
right, and it works.

00:35:17.646 --> 00:35:21.303
This actually, for me at least, this
actually makes the result one-third easy

00:35:21.303 --> 00:35:24.095
to remember,
even though that's not a proof, obviously.

00:35:24.095 --> 00:35:24.760
&gt;&gt; [LAUGH]
&gt;&gt; But

00:35:24.760 --> 00:35:28.376
that actually does suggest another
way to look at this problem.

00:35:30.550 --> 00:35:33.658
Which is,
I'm picking these two random points, and

00:35:33.658 --> 00:35:37.500
there's gonna be a point on the left and
a point on the right.

00:35:37.500 --> 00:35:41.880
So that suggests reinterpreting this
in terms of the max and the min.

00:35:41.880 --> 00:35:46.997
So another way to look
at this would be to let,

00:35:46.997 --> 00:35:50.643
let's say M = maximum of x,y.

00:35:51.781 --> 00:35:53.769
And you should think through for yourself.

00:35:53.769 --> 00:35:56.470
Why is the maximum random
variable as a random variable.

00:35:56.470 --> 00:35:58.840
That's just basic practice
with your random variables.

00:35:59.860 --> 00:36:03.150
L, this is something that always
annoys me is that the word maximum and

00:36:03.150 --> 00:36:06.940
the word minimum both start with m, so
it's hard to remember your notation.

00:36:06.940 --> 00:36:12.310
So I started using L for
the minimum because L stands for

00:36:12.310 --> 00:36:15.260
the least one or L stands for
the little one, but

00:36:15.260 --> 00:36:18.935
unfortunately, then I realized L
could also stand for the large one.

00:36:18.935 --> 00:36:21.141
&gt;&gt; [LAUGH]
&gt;&gt; It's just one annoying fact about

00:36:21.141 --> 00:36:21.728
English.

00:36:21.728 --> 00:36:25.113
&gt;&gt; [LAUGH]
&gt;&gt; Well, anyway,

00:36:25.113 --> 00:36:27.193
we'll let M be the max and L me the min.

00:36:28.260 --> 00:36:36.367
Here's a handy fact, X-Y absolute
value the same thing as M-L, right.

00:36:36.367 --> 00:36:39.278
Because you take the bigger
one minus the smaller one,

00:36:39.278 --> 00:36:43.740
that's the same thing as taking in the
absolute difference, same thing, right.

00:36:43.740 --> 00:36:45.250
That's how you do an absolute value,

00:36:45.250 --> 00:36:46.920
you just take the bigger
one minus the smaller one.

00:36:47.930 --> 00:36:52.939
So therefore,
what we've just shown is that E of

00:36:52.939 --> 00:36:58.566
M-L = one-third,
according to that calculation.

00:36:59.733 --> 00:37:08.133
So that says that E of
M-E of L = one-third.

00:37:08.133 --> 00:37:11.882
And on the other hand, sorry,
I should have written this up higher.

00:37:11.882 --> 00:37:15.670
I'm gonna go loop around to the top here.

00:37:15.670 --> 00:37:20.164
So the difference of
the expectations is one-third.

00:37:20.164 --> 00:37:22.640
Let's also look at the sum.

00:37:22.640 --> 00:37:28.428
If we look at E of M+L, Well,

00:37:28.428 --> 00:37:32.520
by linearity, that's E of M + E of L.

00:37:32.520 --> 00:37:38.234
But on the other hand,
what's M + L in terms of X and Y?

00:37:38.234 --> 00:37:41.840
It's just X + Y because if you add
the bigger number plus the smaller number,

00:37:41.840 --> 00:37:45.080
all you've done is add the two numbers,
right?

00:37:45.080 --> 00:37:51.330
M + L is the same thing as X + Y But

00:37:51.330 --> 00:37:55.233
by linearity,
E of X + Y is E of X + E of Y and

00:37:55.233 --> 00:38:02.530
both of those are one-half cuz they're
uniform 0 to 1, so this must = 1.

00:38:03.700 --> 00:38:07.870
We just showed that that is = 1.

00:38:07.870 --> 00:38:11.138
So from this,
we actually now have an expression for

00:38:11.138 --> 00:38:14.820
the sum of these two expectations and
the difference.

00:38:14.820 --> 00:38:18.290
So therefore, we can just solve that and
we get E of M and E of L.

00:38:19.573 --> 00:38:25.284
So, E of M = two-thirds, and E of L,
I have a system of two equations and

00:38:25.284 --> 00:38:28.940
two unknowns,
just solve that the usual way,

00:38:28.940 --> 00:38:32.443
add the two equations, that kind of thing.

00:38:32.443 --> 00:38:36.365
E of L = one-third,
just like in this picture.

00:38:36.365 --> 00:38:40.670
That's L, that's M, On average.

00:38:40.670 --> 00:38:42.053
So on average, it looks like that.

00:38:44.830 --> 00:38:48.049
So another approach to this
problem would have been,

00:38:48.049 --> 00:38:52.769
if I used this result to prove this
result, another approach would have been,

00:38:52.769 --> 00:38:55.786
let's directly study the max and
the min, okay.

00:38:55.786 --> 00:39:00.126
And you've seen examples like on
the strategic practice like very useful

00:39:00.126 --> 00:39:03.486
factors that the minimum of
independent exponentials is

00:39:03.486 --> 00:39:05.845
exponential with a larger rate.

00:39:05.845 --> 00:39:09.650
And we showed that on
the strategic practice problem.

00:39:09.650 --> 00:39:12.580
And on the new strategic practice,
there's something related with the min and

00:39:12.580 --> 00:39:13.410
the max.

00:39:13.410 --> 00:39:18.270
So another way to do this would have been
directly find the PDF of M, the PDF of L,

00:39:18.270 --> 00:39:20.510
and that would give us this result, right.

00:39:20.510 --> 00:39:22.282
So you could go in either direction.

00:39:23.967 --> 00:39:25.839
I actually don't like
doing double integrals,

00:39:25.839 --> 00:39:28.590
I'm not gonna do a lot of double
integrals, you won't have to do many.

00:39:28.590 --> 00:39:32.377
I felt I should do one for
practice with the 2D LOTUS.

00:39:33.460 --> 00:39:37.602
Okay, but in general,
I would rather think more in this way.

00:39:37.602 --> 00:39:43.030
Use linearity, use the CDFs, the things
like that and not do a lot of integrals.

00:39:44.212 --> 00:39:46.590
Okay, so those are continuous examples.

00:39:46.590 --> 00:39:52.273
I want to do one discrete example for
the rest of today.

00:39:52.273 --> 00:39:54.842
And then next time,
we'll also do some more discrete stuff and

00:39:54.842 --> 00:39:57.430
maybe some more continuous stuff too.

00:39:57.430 --> 00:40:00.470
This is one of my favorite
discrete problems.

00:40:02.622 --> 00:40:04.870
I call it the chicken and egg problem.

00:40:06.050 --> 00:40:10.860
Chicken-egg, We already had

00:40:10.860 --> 00:40:14.500
a homework problem about chickens and
eggs, and hatchings and so on.

00:40:14.500 --> 00:40:17.570
But it's not exactly the same
as this problem, it's related.

00:40:19.240 --> 00:40:21.280
So here's the problem.

00:40:21.280 --> 00:40:26.145
I'll state the problem, then we'll solve
the problem, and then we'll be done.

00:40:26.145 --> 00:40:29.090
&gt;&gt; [LAUGH]
&gt;&gt; Okay, here's the problem.

00:40:29.090 --> 00:40:35.620
There are some eggs, some of them hatch,
some of them don't hatch.

00:40:35.620 --> 00:40:36.810
The eggs are independent.

00:40:39.340 --> 00:40:41.610
Let's assume there are N eggs.

00:40:42.850 --> 00:40:47.920
The twist to this problem is that
the number of eggs is random,

00:40:47.920 --> 00:40:51.530
chicken doesn't always lay
exactly the same number of eggs.

00:40:51.530 --> 00:40:54.450
So let's assume that it's Poisson Lambda.

00:40:54.450 --> 00:41:00.990
That's the number of eggs,
now each one either hatches or

00:41:00.990 --> 00:41:06.160
fails to hatch, so
each hatches with probability p

00:41:10.190 --> 00:41:14.042
And independently, so you can think
of each egg as an independent

00:41:14.042 --> 00:41:16.920
Bernoulli p trial for
whether it hatches or not.

00:41:16.920 --> 00:41:20.850
Hatching is success.

00:41:20.850 --> 00:41:27.020
So independently, and
let X equal the number that hatch,

00:41:32.010 --> 00:41:38.475
So I would write that as
X given N is binomial Np.

00:41:38.475 --> 00:41:42.675
That's just a restatement
we already know this.

00:41:42.675 --> 00:41:48.005
As I explained this notation means
pretend that N is a known constant,

00:41:48.005 --> 00:41:51.315
actually N is Poisson, but pretend
that now we know the number of eggs.

00:41:51.315 --> 00:41:56.050
So we're treating N as a constant then
just binomial Np because I assumed

00:41:56.050 --> 00:41:57.240
independent Bernoulli trials.

00:41:57.240 --> 00:42:00.710
So still we know that.

00:42:00.710 --> 00:42:04.930
Okay, let's also let Y equal
to number that don't hatch.

00:42:09.230 --> 00:42:16.361
So we have an identity X plus Y equals N.

00:42:18.798 --> 00:42:21.306
All right, well,
that's not the end yet, but

00:42:21.306 --> 00:42:24.945
we derived the theorem that X plus
Y equals N, because the number that

00:42:24.945 --> 00:42:28.620
hatched plus the number that don't
hatch equals the number of eggs.

00:42:30.290 --> 00:42:33.320
Now the problem is to find the joint PMF.

00:42:33.320 --> 00:42:37.651
It's discrete so
I could find the joint PMF of X and Y.

00:42:43.240 --> 00:42:47.370
And in particular we'd like to know,
are they independent?

00:42:49.330 --> 00:42:58.200
And intuitively, they seem extremely
dependent because their sum must equal N.

00:42:58.200 --> 00:43:01.020
That's not a proof though because

00:43:01.020 --> 00:43:05.580
this proof that they're
conditionally dependent.

00:43:05.580 --> 00:43:08.250
That is if we know N they are dependent,
and

00:43:08.250 --> 00:43:10.470
intuitively they seem pretty dependent.

00:43:10.470 --> 00:43:12.816
That is if you have a lot of eggs
that hatch then there's not so

00:43:12.816 --> 00:43:13.971
many left that don't hatch.

00:43:13.971 --> 00:43:19.750
But we haven't yet proven whether they are
independent of not cuz this is equal N.

00:43:19.750 --> 00:43:22.400
So now let's find the joint PMF.

00:43:22.400 --> 00:43:28.307
So just by definition the joint PMF is
the probability that X equals something,

00:43:28.307 --> 00:43:32.260
lets say i, Y equals j,
could use little x little y.

00:43:32.260 --> 00:43:35.760
But I'm just using i and
j to remind us that they are integers.

00:43:37.760 --> 00:43:46.080
Now, to do that, somehow we have
to bring in this Poisson thing.

00:43:46.080 --> 00:43:47.200
So our strategy for

00:43:47.200 --> 00:43:51.890
solving this should be going back
to our early part of the course.

00:43:51.890 --> 00:43:54.640
You have a probability, if you don't
immediately know how to do it,

00:43:54.640 --> 00:43:56.940
try to find something to condition on.

00:43:56.940 --> 00:43:57.980
What do you condition on?

00:43:57.980 --> 00:43:59.270
What we wish that we knew.

00:44:00.370 --> 00:44:02.040
I wish I knew the number of eggs.

00:44:02.040 --> 00:44:04.480
Then it's an easy binomial problem.

00:44:04.480 --> 00:44:07.250
Conditional on the number of eggs,
just a binomial.

00:44:07.250 --> 00:44:08.830
So we're gonna condition on N.

00:44:08.830 --> 00:44:17.020
The law of total probability says we can
just write this as the sum of X equals i,

00:44:17.020 --> 00:44:22.210
Y equals j, given that N equals n
times the probability that N equals n.

00:44:23.750 --> 00:44:26.930
Summed over all n from zero to infinity.

00:44:26.930 --> 00:44:28.596
That's just the total probability.

00:44:28.596 --> 00:44:32.230
And probably N equals n,
we already know that from the Poisson.

00:44:33.610 --> 00:44:38.130
Well, okay, that looks a little scary like
we're gonna have to do an infinite sum.

00:44:39.400 --> 00:44:43.540
For similar problems I seen a lot of
students get stuck at this point.

00:44:43.540 --> 00:44:48.250
And my suggestion is if you ever find
yourself getting stuck at a point like

00:44:48.250 --> 00:44:52.280
this is to try some simple examples,
make up some numbers,

00:44:52.280 --> 00:44:56.280
do some special cases so
you think about it more concretely

00:44:56.280 --> 00:45:00.450
rather than being intimidated
by this infinite series.

00:45:00.450 --> 00:45:05.330
If you actually think about it concretely,
you'll notice something very, very simple.

00:45:05.330 --> 00:45:07.500
That is, if I said,
what is the probability of this,

00:45:07.500 --> 00:45:09.460
this is just kind of some scratch work.

00:45:09.460 --> 00:45:15.662
What's the probability that X equals 3,
Y equals 5, given N equals 10?

00:45:15.662 --> 00:45:17.610
What's that?

00:45:17.610 --> 00:45:22.410
0, because there's 10 eggs, 3 hatched,

00:45:22.410 --> 00:45:25.000
5 didn't hatch,
someone stole the other two eggs,

00:45:25.000 --> 00:45:28.600
I mean it doesn't make any sense,
that it's impossible, 0.

00:45:28.600 --> 00:45:34.340
What's the probability that X equals 3,
Y equals 5,

00:45:34.340 --> 00:45:37.965
given N equals 2?

00:45:37.965 --> 00:45:42.960
0, There's only two eggs and yet
you're claiming three hatched and

00:45:42.960 --> 00:45:45.120
five didn't hatch, that makes no sense.

00:45:45.120 --> 00:45:46.340
So as soon as you write down,

00:45:46.340 --> 00:45:49.790
I find writing down a few
simple numbers like that

00:45:49.790 --> 00:45:53.820
it becomes completely obvious that this
incident sums up actually only one term.

00:45:54.860 --> 00:45:59.700
The one term is the case when
in fact N equals i plus j.

00:45:59.700 --> 00:46:02.110
So we only have one term here.

00:46:02.110 --> 00:46:09.530
X equals i, Y equals j,
given N equals i plus j.

00:46:10.970 --> 00:46:13.240
Otherwise there's a mismatch.

00:46:13.240 --> 00:46:17.864
Times the probability
that N equals i plus j.

00:46:19.280 --> 00:46:23.450
And now we know everything we need
to know to just evaluate this.

00:46:25.400 --> 00:46:30.000
Notice there's now some redundancy,
because if I know there's i plus j

00:46:30.000 --> 00:46:33.370
eggs and i hatched,
I already know that j hatched.

00:46:33.370 --> 00:46:34.990
You didn't have to tell me that.

00:46:34.990 --> 00:46:38.400
Redundant information,
we just cross that out.

00:46:38.400 --> 00:46:43.130
Now X equals i given N equal,
that's just from the binomial.

00:46:43.130 --> 00:46:46.800
Cuz given the value of N we're treating
X as binomial so we're just gonna take

00:46:46.800 --> 00:46:51.450
something from the binomial PMF times
something from the Poisson PMF.

00:46:53.156 --> 00:46:57.530
And so let's see,

00:46:57.530 --> 00:47:01.560
that board is broken, so we can do this
here still, just have a little more space.

00:47:03.160 --> 00:47:07.580
So we want to find
the probability that X equals i,

00:47:07.580 --> 00:47:12.410
given N equals i plus j, times
the probability that N equals i plus j.

00:47:12.410 --> 00:47:16.300
Okay, this is just,

00:47:16.300 --> 00:47:19.029
this is an easy calculation now,
but let's see what the answer is.

00:47:21.190 --> 00:47:24.980
For the first term we
just use the binomial.

00:47:24.980 --> 00:47:28.340
So i plus j choose i.

00:47:28.340 --> 00:47:34.800
I'll write that as i plus j
over i factorial, j factorial.

00:47:34.800 --> 00:47:37.320
That's just i plus j choose i.

00:47:37.320 --> 00:47:44.160
Then, That's a factorial, thank you.

00:47:44.160 --> 00:47:47.200
So that's i plus j, thanks,
that's i plus j choose i.

00:47:47.200 --> 00:47:48.580
From the binomial.

00:47:48.580 --> 00:47:53.860
Times p to the i, times.

00:47:54.930 --> 00:47:56.660
Because we're assuming binomial Np.

00:47:56.660 --> 00:48:00.050
So p to the i, and q,
as usual, q is one minus p.

00:48:00.050 --> 00:48:04.024
So i successes, j failures,
q to the j, and

00:48:04.024 --> 00:48:08.643
then times the Poisson PMF,
e to the minus lambda,

00:48:08.643 --> 00:48:12.737
lambda to the i plus j
over i plus j factorial.

00:48:12.737 --> 00:48:17.235
Let's just simplify this quickly.

00:48:17.235 --> 00:48:25.190
i plus j factorials cancel, and let's try
to write this in a nicer looking form.

00:48:25.190 --> 00:48:28.220
Where we are going to try to split it up

00:48:28.220 --> 00:48:30.850
into a function of i
times a function of j.

00:48:31.960 --> 00:48:39.000
So we could write this as lambda to
the i plus j we can split that up so

00:48:39.000 --> 00:48:43.770
really we have lambda p to
the i over i factorial.

00:48:43.770 --> 00:48:49.240
And we have a lambda q to
the j over j factorial.

00:48:49.240 --> 00:48:53.310
And the only thing left that we have to
deal with, is this e to the minus lambda.

00:48:53.310 --> 00:48:54.988
But remember, that p plus q equals 1.

00:48:54.988 --> 00:49:00.500
So I can think of it as having a p
plus q sitting up in the exponent.

00:49:00.500 --> 00:49:02.801
So this is e to the minus, lambda p.

00:49:04.504 --> 00:49:07.190
And this e to the minus lambda q.

00:49:09.997 --> 00:49:14.840
So actually it factored, so actually
that shows that they are independent.

00:49:16.090 --> 00:49:20.010
That says that X and Y are independent.

00:49:21.360 --> 00:49:28.420
And X is also Poisson X is Poisson
lambda p, and Y is Poisson lambda q.

00:49:29.790 --> 00:49:34.150
Which sounds like impossible at
first how could they be independent?

00:49:34.150 --> 00:49:37.850
And if your intuition was that
they're not independent, you shouldn't

00:49:37.850 --> 00:49:42.770
feel bad about that because it turns out
that this is only true for the Poisson.

00:49:42.770 --> 00:49:45.870
So this is actually a very
special property of the Poisson.

00:49:45.870 --> 00:49:49.320
If you change Poisson to anything
else they will become dependent.

00:49:49.320 --> 00:49:52.910
It happens to be true for the Poisson,
we just proved that they're independent.

00:49:52.910 --> 00:49:55.681
That is you think well,
you have more eggs that hatched,

00:49:55.681 --> 00:49:59.030
there is less that didn't hatch, but
the number of eggs is random and

00:49:59.030 --> 00:50:03.060
that randomness exactly for the Poisson
exactly makes them independent.

00:50:03.060 --> 00:50:05.070
Well, let's just get
an example of a joint PMF.

00:50:05.070 --> 00:50:06.650
It's also a nice story.

00:50:06.650 --> 00:50:08.660
And have a good weekend.

