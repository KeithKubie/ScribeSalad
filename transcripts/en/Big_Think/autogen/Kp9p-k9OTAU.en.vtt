WEBVTT
Kind: captions
Language: en

00:00:00.359 --> 00:00:02.780
There is a pattern to the introduction of
technologies.

00:00:02.780 --> 00:00:06.590
&nbsp;When Gutenberg invented the press, some
of the earliest authors were frightened of

00:00:06.590 --> 00:00:09.760
having their words and thoughts set down and
permanently distributed widely.

00:00:09.760 --> 00:00:13.419
&nbsp;Jonathan Swift said that a book of verses
kept in a drawer shown only to friends was

00:00:13.419 --> 00:00:19.740
like a fine lass, but once printed as a book
it was like a common whore anyone could buy

00:00:19.740 --> 00:00:21.650
for two crown.&nbsp;

00:00:21.650 --> 00:00:27.390
Fast forward to the prior kind of moral panic
we’ve had about privacy came because of

00:00:27.390 --> 00:00:28.390
a technology.

00:00:28.390 --> 00:00:33.829
&nbsp;In the year 1890, the first major law review
article written by Louis Brandeis and Samuel

00:00:33.829 --> 00:00:40.070
Warren that tried to look for a legal basis
to a right to privacy in the United States

00:00:40.070 --> 00:00:46.230
was inspired by the invention of a technology,
the Kodak camera, and that caused some measure

00:00:46.230 --> 00:00:47.940
of moral panic and fear.

00:00:47.940 --> 00:00:52.430
&nbsp;The New York Times at the time had stories
about fiendish Kodakers lying in wait.

00:00:52.430 --> 00:00:55.440
&nbsp;A young Vanderbilt horsewhipped a Kodaker.

00:00:55.440 --> 00:00:59.739
&nbsp;President Teddy Roosevelt outlawed Kodaking
in Washington parks.

00:00:59.739 --> 00:01:01.030
&nbsp;
Now what happened?

00:01:01.030 --> 00:01:02.350
&nbsp;Well, we got used to cameras.

00:01:02.350 --> 00:01:06.370
&nbsp;In fact, we’re happy to pose in front
of them as I am right now.&nbsp;

00:01:06.370 --> 00:01:11.010
And what really went on there was that a new
technology caused a change that our norms

00:01:11.010 --> 00:01:15.240
weren’t ready for, and until such time as
we had new norms, we had new agreements about

00:01:15.240 --> 00:01:18.270
how we operated as a society around this,
we were unsettled.

00:01:18.270 --> 00:01:19.760
&nbsp;We were afraid what could go wrong.

00:01:19.760 --> 00:01:23.420
&nbsp;Well, that's what's happening with the internet
with a much bigger technology that it is.

00:01:23.420 --> 00:01:24.820
&nbsp;It’s causing new opportunities.

00:01:24.820 --> 00:01:25.820
&nbsp;It’s causing change.

00:01:25.820 --> 00:01:32.710
&nbsp;It also causes fear and disruption and sometimes
even a moral panic, which is what I think

00:01:32.710 --> 00:01:33.710
we’re going through now.

00:01:33.710 --> 00:01:34.710
&nbsp;
Privacy matters.

00:01:34.710 --> 00:01:35.710
&nbsp;Privacy is important.

00:01:35.710 --> 00:01:36.710
&nbsp;It needs protectors.

00:01:36.710 --> 00:01:37.710
&nbsp;I have a private life.

00:01:37.710 --> 00:01:41.909
&nbsp;All that is true, but we also have this
magnificent tool to publicness, the Internet,

00:01:41.909 --> 00:01:42.930
in all of our hands.

00:01:42.930 --> 00:01:47.060
&nbsp;We can find, form and act as publics now
in ways that we couldn’t before.

00:01:47.060 --> 00:01:48.990
&nbsp;That’s a magnificent ability.&nbsp;

00:01:48.990 --> 00:01:54.570
And my fear is that if governments come in
to regulate the 'Net we’ll lose some of

00:01:54.570 --> 00:01:55.570
that power.&nbsp;

00:01:55.570 --> 00:01:58.990
And some of them want us to lose that power
because they fear that power.

00:01:58.990 --> 00:02:04.370
So I think we have to beware of demonizing
technology--things like tracking cookies being

00:02:04.370 --> 00:02:08.369
bad for us or worried about technology first
off--because we’re walking into the hands

00:02:08.369 --> 00:02:13.550
of those who would limit the technology rather
than what we should do, what society has long

00:02:13.550 --> 00:02:16.020
done, is you regulate the behaviors.

00:02:16.020 --> 00:02:20.950
&nbsp;So you can use a telephone to do good things
and summon an ambulance; you can use it to

00:02:20.950 --> 00:02:22.870
do bad things and defraud people.

00:02:22.870 --> 00:02:24.200
&nbsp;The technology isn’t bad.

00:02:24.200 --> 00:02:25.980
&nbsp;It’s the behavior we regulate.

00:02:25.980 --> 00:02:31.670
&nbsp;Yet nowadays we’re seeing efforts by governments
to come in and regulate on the whole the Internet.&nbsp;

00:02:31.670 --> 00:02:38.370
So even Canada and Australia want to filter
all the content on the 'Net to get to pedophilia.

00:02:38.370 --> 00:02:42.989
&nbsp;Well, they create an ability and an architecture
that also Iran and China will use.

00:02:42.989 --> 00:02:44.470
&nbsp;We have to beware of that.&nbsp;

