WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:01.880
 
now for our first panel of the day we

00:00:01.880 --> 00:00:01.890
now for our first panel of the day we
 

00:00:01.890 --> 00:00:03.169
now for our first panel of the day we
thought we'd better define what we're

00:00:03.169 --> 00:00:03.179
thought we'd better define what we're
 

00:00:03.179 --> 00:00:05.360
thought we'd better define what we're
talking about so the topic of that panel

00:00:05.360 --> 00:00:05.370
talking about so the topic of that panel
 

00:00:05.370 --> 00:00:08.839
talking about so the topic of that panel
is what is intelligence not a small task

00:00:08.839 --> 00:00:08.849
is what is intelligence not a small task
 

00:00:08.849 --> 00:00:10.610
is what is intelligence not a small task
that you're enhancing secretary-general

00:00:10.610 --> 00:00:10.620
that you're enhancing secretary-general
 

00:00:10.620 --> 00:00:11.839
that you're enhancing secretary-general
of the Royal Swedish Academy of Sciences

00:00:11.839 --> 00:00:11.849
of the Royal Swedish Academy of Sciences
 

00:00:11.849 --> 00:00:14.900
of the Royal Swedish Academy of Sciences
has as moderator on his panel he has

00:00:14.900 --> 00:00:14.910
has as moderator on his panel he has
 

00:00:14.910 --> 00:00:16.490
has as moderator on his panel he has
Barbara gross of Harvard University

00:00:16.490 --> 00:00:16.500
Barbara gross of Harvard University
 

00:00:16.500 --> 00:00:18.859
Barbara gross of Harvard University
Helga Novotny who's professor emeritus

00:00:18.859 --> 00:00:18.869
Helga Novotny who's professor emeritus
 

00:00:18.869 --> 00:00:22.640
Helga Novotny who's professor emeritus
at 8a ha in Zurich edvard moser who is

00:00:22.640 --> 00:00:22.650
at 8a ha in Zurich edvard moser who is
 

00:00:22.650 --> 00:00:24.590
at 8a ha in Zurich edvard moser who is
one of the 2014 Nobel laureates in

00:00:24.590 --> 00:00:24.600
one of the 2014 Nobel laureates in
 

00:00:24.600 --> 00:00:26.599
one of the 2014 Nobel laureates in
medicine and Maggi Bowden from the

00:00:26.599 --> 00:00:26.609
medicine and Maggi Bowden from the
 

00:00:26.609 --> 00:00:29.029
medicine and Maggi Bowden from the
University of Sussex you're on the floor

00:00:29.029 --> 00:00:29.039
University of Sussex you're on the floor
 

00:00:29.039 --> 00:00:31.299
University of Sussex you're on the floor
is yours thank you Adam

00:00:31.299 --> 00:00:31.309
is yours thank you Adam
 

00:00:31.309 --> 00:00:35.030
is yours thank you Adam
good morning everyone so we heard some

00:00:35.030 --> 00:00:35.040
good morning everyone so we heard some
 

00:00:35.040 --> 00:00:38.900
good morning everyone so we heard some
very interesting talks and video

00:00:38.900 --> 00:00:38.910
very interesting talks and video
 

00:00:38.910 --> 00:00:41.780
very interesting talks and video
comments on intelligence but what is it

00:00:41.780 --> 00:00:41.790
comments on intelligence but what is it
 

00:00:41.790 --> 00:00:42.139
comments on intelligence but what is it
really

00:00:42.139 --> 00:00:42.149
really
 

00:00:42.149 --> 00:00:44.090
really
Margaret you've thought a lot about this

00:00:44.090 --> 00:00:44.100
Margaret you've thought a lot about this
 

00:00:44.100 --> 00:00:47.209
Margaret you've thought a lot about this
can you give us a helpful definition the

00:00:47.209 --> 00:00:47.219
can you give us a helpful definition the
 

00:00:47.219 --> 00:00:49.729
can you give us a helpful definition the
definition certainly a description

00:00:49.729 --> 00:00:49.739
definition certainly a description
 

00:00:49.739 --> 00:00:53.090
definition certainly a description
I think intelligence is being able to

00:00:53.090 --> 00:00:53.100
I think intelligence is being able to
 

00:00:53.100 --> 00:00:56.119
I think intelligence is being able to
move towards and in some cases achieve

00:00:56.119 --> 00:00:56.129
move towards and in some cases achieve
 

00:00:56.129 --> 00:00:58.970
move towards and in some cases achieve
your goals some of which conflict with

00:00:58.970 --> 00:00:58.980
your goals some of which conflict with
 

00:00:58.980 --> 00:00:59.569
your goals some of which conflict with
one another

00:00:59.569 --> 00:00:59.579
one another
 

00:00:59.579 --> 00:01:02.590
one another
in a complex and largely unpredictable

00:01:02.590 --> 00:01:02.600
in a complex and largely unpredictable
 

00:01:02.600 --> 00:01:05.960
in a complex and largely unpredictable
environment which certainly all the

00:01:05.960 --> 00:01:05.970
environment which certainly all the
 

00:01:05.970 --> 00:01:09.710
environment which certainly all the
higher animals can do and which at the

00:01:09.710 --> 00:01:09.720
higher animals can do and which at the
 

00:01:09.720 --> 00:01:12.770
higher animals can do and which at the
moment virtually well no artificial

00:01:12.770 --> 00:01:12.780
moment virtually well no artificial
 

00:01:12.780 --> 00:01:14.750
moment virtually well no artificial
intelligence can do not least because

00:01:14.750 --> 00:01:14.760
intelligence can do not least because
 

00:01:14.760 --> 00:01:17.450
intelligence can do not least because
the vast majority of AI systems at the

00:01:17.450 --> 00:01:17.460
the vast majority of AI systems at the
 

00:01:17.460 --> 00:01:20.420
the vast majority of AI systems at the
moment only have one goal they try and

00:01:20.420 --> 00:01:20.430
moment only have one goal they try and
 

00:01:20.430 --> 00:01:21.980
moment only have one goal they try and
do one thing and they do it very very

00:01:21.980 --> 00:01:21.990
do one thing and they do it very very
 

00:01:21.990 --> 00:01:25.280
do one thing and they do it very very
well very often but they don't negotiate

00:01:25.280 --> 00:01:25.290
well very often but they don't negotiate
 

00:01:25.290 --> 00:01:28.760
well very often but they don't negotiate
lots of mode of goals and motives and I

00:01:28.760 --> 00:01:28.770
lots of mode of goals and motives and I
 

00:01:28.770 --> 00:01:30.140
lots of mode of goals and motives and I
think that's what's involved in

00:01:30.140 --> 00:01:30.150
think that's what's involved in
 

00:01:30.150 --> 00:01:32.810
think that's what's involved in
intelligence thank you I think we can

00:01:32.810 --> 00:01:32.820
intelligence thank you I think we can
 

00:01:32.820 --> 00:01:35.300
intelligence thank you I think we can
come back to artificial intelligence in

00:01:35.300 --> 00:01:35.310
come back to artificial intelligence in
 

00:01:35.310 --> 00:01:40.219
come back to artificial intelligence in
a little while but let's hear first from

00:01:40.219 --> 00:01:40.229
a little while but let's hear first from
 

00:01:40.229 --> 00:01:42.980
a little while but let's hear first from
our the other panelists here do you

00:01:42.980 --> 00:01:42.990
our the other panelists here do you
 

00:01:42.990 --> 00:01:45.740
our the other panelists here do you
agree with this description would you

00:01:45.740 --> 00:01:45.750
agree with this description would you
 

00:01:45.750 --> 00:01:48.350
agree with this description would you
bear anyone be a volunteer to condense

00:01:48.350 --> 00:01:48.360
bear anyone be a volunteer to condense
 

00:01:48.360 --> 00:01:51.429
bear anyone be a volunteer to condense
it into a definition in a few words

00:01:51.429 --> 00:01:51.439
it into a definition in a few words
 

00:01:51.439 --> 00:01:55.370
it into a definition in a few words
Barbara I'm not going to define it

00:01:55.370 --> 00:01:55.380
Barbara I'm not going to define it
 

00:01:55.380 --> 00:01:58.249
Barbara I'm not going to define it
precisely but to start by quoting a

00:01:58.249 --> 00:01:58.259
precisely but to start by quoting a
 

00:01:58.259 --> 00:02:00.170
precisely but to start by quoting a
United States Supreme Court justice

00:02:00.170 --> 00:02:00.180
United States Supreme Court justice
 

00:02:00.180 --> 00:02:02.569
United States Supreme Court justice
asked to define something somewhat more

00:02:02.569 --> 00:02:02.579
asked to define something somewhat more
 

00:02:02.579 --> 00:02:05.450
asked to define something somewhat more
risque and he said I know it when I see

00:02:05.450 --> 00:02:05.460
risque and he said I know it when I see
 

00:02:05.460 --> 00:02:10.410
risque and he said I know it when I see
it

00:02:10.410 --> 00:02:10.420
 
 

00:02:10.420 --> 00:02:13.370
 
know it when they see it I think

00:02:13.370 --> 00:02:13.380
know it when they see it I think
 

00:02:13.380 --> 00:02:16.770
know it when they see it I think
Maggie's definition or non definition

00:02:16.770 --> 00:02:16.780
Maggie's definition or non definition
 

00:02:16.780 --> 00:02:19.440
Maggie's definition or non definition
description brings it brings up very

00:02:19.440 --> 00:02:19.450
description brings it brings up very
 

00:02:19.450 --> 00:02:22.199
description brings it brings up very
important points which is that it's it's

00:02:22.199 --> 00:02:22.209
important points which is that it's it's
 

00:02:22.209 --> 00:02:26.850
important points which is that it's it's
not a single capability but many

00:02:26.850 --> 00:02:26.860
not a single capability but many
 

00:02:26.860 --> 00:02:29.100
not a single capability but many
different capabilities in the ways in

00:02:29.100 --> 00:02:29.110
different capabilities in the ways in
 

00:02:29.110 --> 00:02:31.590
different capabilities in the ways in
which we understand the universe and the

00:02:31.590 --> 00:02:31.600
which we understand the universe and the
 

00:02:31.600 --> 00:02:33.240
which we understand the universe and the
word itself goes back to a latin word

00:02:33.240 --> 00:02:33.250
word itself goes back to a latin word
 

00:02:33.250 --> 00:02:35.880
word itself goes back to a latin word
which means understand but it's an

00:02:35.880 --> 00:02:35.890
which means understand but it's an
 

00:02:35.890 --> 00:02:41.880
which means understand but it's an
understanding of a complex sort maybe I

00:02:41.880 --> 00:02:41.890
understanding of a complex sort maybe I
 

00:02:41.890 --> 00:02:43.830
understanding of a complex sort maybe I
can just add that in my own field which

00:02:43.830 --> 00:02:43.840
can just add that in my own field which
 

00:02:43.840 --> 00:02:46.350
can just add that in my own field which
is psychology and neuroscience this

00:02:46.350 --> 00:02:46.360
is psychology and neuroscience this
 

00:02:46.360 --> 00:02:49.320
is psychology and neuroscience this
complex this concept is so complicated

00:02:49.320 --> 00:02:49.330
complex this concept is so complicated
 

00:02:49.330 --> 00:02:51.630
complex this concept is so complicated
so broad that we actually don't really

00:02:51.630 --> 00:02:51.640
so broad that we actually don't really
 

00:02:51.640 --> 00:02:53.759
so broad that we actually don't really
use it so in neuroscience no one really

00:02:53.759 --> 00:02:53.769
use it so in neuroscience no one really
 

00:02:53.769 --> 00:02:55.500
use it so in neuroscience no one really
talks about intelligence because it

00:02:55.500 --> 00:02:55.510
talks about intelligence because it
 

00:02:55.510 --> 00:02:59.309
talks about intelligence because it
covers so much that although we all feel

00:02:59.309 --> 00:02:59.319
covers so much that although we all feel
 

00:02:59.319 --> 00:03:01.620
covers so much that although we all feel
we know what is meant by this concept

00:03:01.620 --> 00:03:01.630
we know what is meant by this concept
 

00:03:01.630 --> 00:03:07.259
we know what is meant by this concept
it's it's too too diverse hope that you

00:03:07.259 --> 00:03:07.269
it's it's too too diverse hope that you
 

00:03:07.269 --> 00:03:09.180
it's it's too too diverse hope that you
would by now I mean I mean last year we

00:03:09.180 --> 00:03:09.190
would by now I mean I mean last year we
 

00:03:09.190 --> 00:03:10.680
would by now I mean I mean last year we
won the Nobel Prize for discovering the

00:03:10.680 --> 00:03:10.690
won the Nobel Prize for discovering the
 

00:03:10.690 --> 00:03:12.870
won the Nobel Prize for discovering the
Positioning System GPS of the brain I

00:03:12.870 --> 00:03:12.880
Positioning System GPS of the brain I
 

00:03:12.880 --> 00:03:14.849
Positioning System GPS of the brain I
thought you would announce the cells

00:03:14.849 --> 00:03:14.859
thought you would announce the cells
 

00:03:14.859 --> 00:03:16.770
thought you would announce the cells
that account for intelligence in the

00:03:16.770 --> 00:03:16.780
that account for intelligence in the
 

00:03:16.780 --> 00:03:21.470
that account for intelligence in the
brain it will take a while apparently

00:03:21.470 --> 00:03:21.480
brain it will take a while apparently
 

00:03:21.480 --> 00:03:23.970
brain it will take a while apparently
let me take you back a couple of

00:03:23.970 --> 00:03:23.980
let me take you back a couple of
 

00:03:23.980 --> 00:03:27.240
let me take you back a couple of
centuries to the Chinese philosopher Lao

00:03:27.240 --> 00:03:27.250
centuries to the Chinese philosopher Lao
 

00:03:27.250 --> 00:03:30.479
centuries to the Chinese philosopher Lao
si and he defined intelligence as the

00:03:30.479 --> 00:03:30.489
si and he defined intelligence as the
 

00:03:30.489 --> 00:03:33.840
si and he defined intelligence as the
ability to understand each other but he

00:03:33.840 --> 00:03:33.850
ability to understand each other but he
 

00:03:33.850 --> 00:03:38.280
ability to understand each other but he
added to understand oneself is wisdom I

00:03:38.280 --> 00:03:38.290
added to understand oneself is wisdom I
 

00:03:38.290 --> 00:03:41.130
added to understand oneself is wisdom I
think what he did not foresee could not

00:03:41.130 --> 00:03:41.140
think what he did not foresee could not
 

00:03:41.140 --> 00:03:44.610
think what he did not foresee could not
foresee is the enormous progress we have

00:03:44.610 --> 00:03:44.620
foresee is the enormous progress we have
 

00:03:44.620 --> 00:03:47.580
foresee is the enormous progress we have
made in understanding ourselves but not

00:03:47.580 --> 00:03:47.590
made in understanding ourselves but not
 

00:03:47.590 --> 00:03:50.069
made in understanding ourselves but not
so much in the philosophical sense but

00:03:50.069 --> 00:03:50.079
so much in the philosophical sense but
 

00:03:50.079 --> 00:03:52.349
so much in the philosophical sense but
in the sense that we have heard and seen

00:03:52.349 --> 00:03:52.359
in the sense that we have heard and seen
 

00:03:52.359 --> 00:03:55.860
in the sense that we have heard and seen
of I'm trying to understand how the

00:03:55.860 --> 00:03:55.870
of I'm trying to understand how the
 

00:03:55.870 --> 00:03:59.400
of I'm trying to understand how the
brain works how the mind works and what

00:03:59.400 --> 00:03:59.410
brain works how the mind works and what
 

00:03:59.410 --> 00:04:02.580
brain works how the mind works and what
is our challenge ahead is to take this

00:04:02.580 --> 00:04:02.590
is our challenge ahead is to take this
 

00:04:02.590 --> 00:04:05.520
is our challenge ahead is to take this
this one step further to turn it not

00:04:05.520 --> 00:04:05.530
this one step further to turn it not
 

00:04:05.530 --> 00:04:07.849
this one step further to turn it not
just into understanding but into wisdom

00:04:07.849 --> 00:04:07.859
just into understanding but into wisdom
 

00:04:07.859 --> 00:04:11.699
just into understanding but into wisdom
namely anticipating understanding better

00:04:11.699 --> 00:04:11.709
namely anticipating understanding better
 

00:04:11.709 --> 00:04:13.830
namely anticipating understanding better
the unintended consequences of what we

00:04:13.830 --> 00:04:13.840
the unintended consequences of what we
 

00:04:13.840 --> 00:04:18.870
the unintended consequences of what we
do we only better at that now then we

00:04:18.870 --> 00:04:18.880
do we only better at that now then we
 

00:04:18.880 --> 00:04:22.110
do we only better at that now then we
were say at Monte where this times when

00:04:22.110 --> 00:04:22.120
were say at Monte where this times when
 

00:04:22.120 --> 00:04:22.940
were say at Monte where this times when
that the new

00:04:22.940 --> 00:04:22.950
that the new
 

00:04:22.950 --> 00:04:24.260
that the new
take that we heard in the beginning was

00:04:24.260 --> 00:04:24.270
take that we heard in the beginning was
 

00:04:24.270 --> 00:04:27.140
take that we heard in the beginning was
written I think definitely but we also

00:04:27.140 --> 00:04:27.150
written I think definitely but we also
 

00:04:27.150 --> 00:04:30.020
written I think definitely but we also
see that the number of challenges is

00:04:30.020 --> 00:04:30.030
see that the number of challenges is
 

00:04:30.030 --> 00:04:32.510
see that the number of challenges is
mounting and this has to do with the

00:04:32.510 --> 00:04:32.520
mounting and this has to do with the
 

00:04:32.520 --> 00:04:34.910
mounting and this has to do with the
complexity of the modern world in which

00:04:34.910 --> 00:04:34.920
complexity of the modern world in which
 

00:04:34.920 --> 00:04:39.770
complexity of the modern world in which
we live our inability to foresee and

00:04:39.770 --> 00:04:39.780
we live our inability to foresee and
 

00:04:39.780 --> 00:04:43.250
we live our inability to foresee and
this is how complexity works the way how

00:04:43.250 --> 00:04:43.260
this is how complexity works the way how
 

00:04:43.260 --> 00:04:48.380
this is how complexity works the way how
parts interconnect and we do have better

00:04:48.380 --> 00:04:48.390
parts interconnect and we do have better
 

00:04:48.390 --> 00:04:51.470
parts interconnect and we do have better
ways of looking into this

00:04:51.470 --> 00:04:51.480
ways of looking into this
 

00:04:51.480 --> 00:04:53.930
ways of looking into this
interconnection simulation models etc

00:04:53.930 --> 00:04:53.940
interconnection simulation models etc
 

00:04:53.940 --> 00:04:57.500
interconnection simulation models etc
etc but there's still a long way to go

00:04:57.500 --> 00:04:57.510
etc but there's still a long way to go
 

00:04:57.510 --> 00:05:01.760
etc but there's still a long way to go
so yes we have made tremendous advances

00:05:01.760 --> 00:05:01.770
so yes we have made tremendous advances
 

00:05:01.770 --> 00:05:06.110
so yes we have made tremendous advances
but we also face no challenges and I

00:05:06.110 --> 00:05:06.120
but we also face no challenges and I
 

00:05:06.120 --> 00:05:08.990
but we also face no challenges and I
would add perhaps one dimension of

00:05:08.990 --> 00:05:09.000
would add perhaps one dimension of
 

00:05:09.000 --> 00:05:11.660
would add perhaps one dimension of
intelligence that I think we have to

00:05:11.660 --> 00:05:11.670
intelligence that I think we have to
 

00:05:11.670 --> 00:05:13.700
intelligence that I think we have to
come to grips with and that is social

00:05:13.700 --> 00:05:13.710
come to grips with and that is social
 

00:05:13.710 --> 00:05:16.370
come to grips with and that is social
intelligence and by social intelligence

00:05:16.370 --> 00:05:16.380
intelligence and by social intelligence
 

00:05:16.380 --> 00:05:20.000
intelligence and by social intelligence
I mean a better understanding of how the

00:05:20.000 --> 00:05:20.010
I mean a better understanding of how the
 

00:05:20.010 --> 00:05:23.090
I mean a better understanding of how the
social order works and when Lars

00:05:23.090 --> 00:05:23.100
social order works and when Lars
 

00:05:23.100 --> 00:05:25.700
social order works and when Lars
mentioned in the beginning of his talk

00:05:25.700 --> 00:05:25.710
mentioned in the beginning of his talk
 

00:05:25.710 --> 00:05:28.070
mentioned in the beginning of his talk
the world has changed has been

00:05:28.070 --> 00:05:28.080
the world has changed has been
 

00:05:28.080 --> 00:05:30.110
the world has changed has been
transformed in the last couple of months

00:05:30.110 --> 00:05:30.120
transformed in the last couple of months
 

00:05:30.120 --> 00:05:32.480
transformed in the last couple of months
for us living in Europe and in in the

00:05:32.480 --> 00:05:32.490
for us living in Europe and in in the
 

00:05:32.490 --> 00:05:35.000
for us living in Europe and in in the
world and I think we also have to start

00:05:35.000 --> 00:05:35.010
world and I think we also have to start
 

00:05:35.010 --> 00:05:37.970
world and I think we also have to start
thinking about how we can enhance social

00:05:37.970 --> 00:05:37.980
thinking about how we can enhance social
 

00:05:37.980 --> 00:05:38.960
thinking about how we can enhance social
intelligence

00:05:38.960 --> 00:05:38.970
intelligence
 

00:05:38.970 --> 00:05:42.040
intelligence
I worry sly slightly here because

00:05:42.040 --> 00:05:42.050
I worry sly slightly here because
 

00:05:42.050 --> 00:05:44.300
I worry sly slightly here because
intelligence now in these few minutes

00:05:44.300 --> 00:05:44.310
intelligence now in these few minutes
 

00:05:44.310 --> 00:05:46.700
intelligence now in these few minutes
has come to encompass essentially all of

00:05:46.700 --> 00:05:46.710
has come to encompass essentially all of
 

00:05:46.710 --> 00:05:50.120
has come to encompass essentially all of
human civilization and interactions

00:05:50.120 --> 00:05:50.130
human civilization and interactions
 

00:05:50.130 --> 00:05:54.560
human civilization and interactions
between humans a market can we somehow

00:05:54.560 --> 00:05:54.570
between humans a market can we somehow
 

00:05:54.570 --> 00:05:58.270
between humans a market can we somehow
divide it or reduce it to two specific

00:05:58.270 --> 00:05:58.280
divide it or reduce it to two specific
 

00:05:58.280 --> 00:06:02.090
divide it or reduce it to two specific
more more defined activities that

00:06:02.090 --> 00:06:02.100
more more defined activities that
 

00:06:02.100 --> 00:06:03.650
more more defined activities that
perhaps the advert could find the nerve

00:06:03.650 --> 00:06:03.660
perhaps the advert could find the nerve
 

00:06:03.660 --> 00:06:08.090
perhaps the advert could find the nerve
cells for in a few years time well you

00:06:08.090 --> 00:06:08.100
cells for in a few years time well you
 

00:06:08.100 --> 00:06:11.510
cells for in a few years time well you
can focus on this activity that sort of

00:06:11.510 --> 00:06:11.520
can focus on this activity that sort of
 

00:06:11.520 --> 00:06:13.790
can focus on this activity that sort of
problem this sort of problem for example

00:06:13.790 --> 00:06:13.800
problem this sort of problem for example
 

00:06:13.800 --> 00:06:16.240
problem this sort of problem for example
you can call them academic disciplines

00:06:16.240 --> 00:06:16.250
you can call them academic disciplines
 

00:06:16.250 --> 00:06:18.980
you can call them academic disciplines
but we all know that there are these

00:06:18.980 --> 00:06:18.990
but we all know that there are these
 

00:06:18.990 --> 00:06:21.320
but we all know that there are these
artificial Chinese walls between

00:06:21.320 --> 00:06:21.330
artificial Chinese walls between
 

00:06:21.330 --> 00:06:23.780
artificial Chinese walls between
academic disciplines so you start out as

00:06:23.780 --> 00:06:23.790
academic disciplines so you start out as
 

00:06:23.790 --> 00:06:27.080
academic disciplines so you start out as
an economist for example thinking you

00:06:27.080 --> 00:06:27.090
an economist for example thinking you
 

00:06:27.090 --> 00:06:29.090
an economist for example thinking you
only worry about those sorts of problems

00:06:29.090 --> 00:06:29.100
only worry about those sorts of problems
 

00:06:29.100 --> 00:06:31.220
only worry about those sorts of problems
but you find out actually you've got to

00:06:31.220 --> 00:06:31.230
but you find out actually you've got to
 

00:06:31.230 --> 00:06:32.780
but you find out actually you've got to
start thinking about perhaps

00:06:32.780 --> 00:06:32.790
start thinking about perhaps
 

00:06:32.790 --> 00:06:36.100
start thinking about perhaps
neuroscience perhaps

00:06:36.100 --> 00:06:36.110
neuroscience perhaps
 

00:06:36.110 --> 00:06:40.130
neuroscience perhaps
meteorology so yes you can try and focus

00:06:40.130 --> 00:06:40.140
meteorology so yes you can try and focus
 

00:06:40.140 --> 00:06:42.980
meteorology so yes you can try and focus
and it helps you to focus helps you to

00:06:42.980 --> 00:06:42.990
and it helps you to focus helps you to
 

00:06:42.990 --> 00:06:45.530
and it helps you to focus helps you to
ask and answer questions otherwise you

00:06:45.530 --> 00:06:45.540
ask and answer questions otherwise you
 

00:06:45.540 --> 00:06:49.670
ask and answer questions otherwise you
couldn't have done but you can't get rid

00:06:49.670 --> 00:06:49.680
couldn't have done but you can't get rid
 

00:06:49.680 --> 00:06:51.440
couldn't have done but you can't get rid
of the complexity the complexity is

00:06:51.440 --> 00:06:51.450
of the complexity the complexity is
 

00:06:51.450 --> 00:06:54.080
of the complexity the complexity is
always there and if you forget about it

00:06:54.080 --> 00:06:54.090
always there and if you forget about it
 

00:06:54.090 --> 00:06:59.470
always there and if you forget about it
eventually it'll come back and bite you

00:06:59.470 --> 00:06:59.480
 
 

00:06:59.480 --> 00:07:04.610
 
for Neuroscience Edward can neuroscience

00:07:04.610 --> 00:07:04.620
for Neuroscience Edward can neuroscience
 

00:07:04.620 --> 00:07:05.960
for Neuroscience Edward can neuroscience
contribute to this topic

00:07:05.960 --> 00:07:05.970
contribute to this topic
 

00:07:05.970 --> 00:07:09.710
contribute to this topic
consider it yeah I think I mean it's

00:07:09.710 --> 00:07:09.720
consider it yeah I think I mean it's
 

00:07:09.720 --> 00:07:11.510
consider it yeah I think I mean it's
really a revolution going on in

00:07:11.510 --> 00:07:11.520
really a revolution going on in
 

00:07:11.520 --> 00:07:14.590
really a revolution going on in
neuroscience today in the sense that

00:07:14.590 --> 00:07:14.600
neuroscience today in the sense that
 

00:07:14.600 --> 00:07:18.680
neuroscience today in the sense that
these most complex functions of the

00:07:18.680 --> 00:07:18.690
these most complex functions of the
 

00:07:18.690 --> 00:07:20.960
these most complex functions of the
brain are actually beginning to be

00:07:20.960 --> 00:07:20.970
brain are actually beginning to be
 

00:07:20.970 --> 00:07:23.120
brain are actually beginning to be
understood so I think we are learning

00:07:23.120 --> 00:07:23.130
understood so I think we are learning
 

00:07:23.130 --> 00:07:27.250
understood so I think we are learning
now how the brain or how the cortex is

00:07:27.250 --> 00:07:27.260
now how the brain or how the cortex is
 

00:07:27.260 --> 00:07:29.600
now how the brain or how the cortex is
actually computing what are the basic

00:07:29.600 --> 00:07:29.610
actually computing what are the basic
 

00:07:29.610 --> 00:07:31.850
actually computing what are the basic
algorithms and many of those may be

00:07:31.850 --> 00:07:31.860
algorithms and many of those may be
 

00:07:31.860 --> 00:07:34.040
algorithms and many of those may be
similar to all of these seemingly

00:07:34.040 --> 00:07:34.050
similar to all of these seemingly
 

00:07:34.050 --> 00:07:37.280
similar to all of these seemingly
diverse functions of the brain but I

00:07:37.280 --> 00:07:37.290
diverse functions of the brain but I
 

00:07:37.290 --> 00:07:40.030
diverse functions of the brain but I
think you're still just at the start and

00:07:40.030 --> 00:07:40.040
think you're still just at the start and
 

00:07:40.040 --> 00:07:44.330
think you're still just at the start and
it will take a while to figure out we'll

00:07:44.330 --> 00:07:44.340
it will take a while to figure out we'll
 

00:07:44.340 --> 00:07:46.970
it will take a while to figure out we'll
probably over the next year's get a lot

00:07:46.970 --> 00:07:46.980
probably over the next year's get a lot
 

00:07:46.980 --> 00:07:50.450
probably over the next year's get a lot
of data about from the brain but to put

00:07:50.450 --> 00:07:50.460
of data about from the brain but to put
 

00:07:50.460 --> 00:07:53.090
of data about from the brain but to put
it all together and to see what are the

00:07:53.090 --> 00:07:53.100
it all together and to see what are the
 

00:07:53.100 --> 00:07:56.030
it all together and to see what are the
really the principles by which the brain

00:07:56.030 --> 00:07:56.040
really the principles by which the brain
 

00:07:56.040 --> 00:07:58.610
really the principles by which the brain
work that is a much much slower process

00:07:58.610 --> 00:07:58.620
work that is a much much slower process
 

00:07:58.620 --> 00:08:01.310
work that is a much much slower process
but I definitely think it's going

00:08:01.310 --> 00:08:01.320
but I definitely think it's going
 

00:08:01.320 --> 00:08:04.280
but I definitely think it's going
forward and it's hard to predict what we

00:08:04.280 --> 00:08:04.290
forward and it's hard to predict what we
 

00:08:04.290 --> 00:08:08.210
forward and it's hard to predict what we
will know by 2050 for example how much

00:08:08.210 --> 00:08:08.220
will know by 2050 for example how much
 

00:08:08.220 --> 00:08:11.660
will know by 2050 for example how much
do you think is hardwired how much will

00:08:11.660 --> 00:08:11.670
do you think is hardwired how much will
 

00:08:11.670 --> 00:08:14.750
do you think is hardwired how much will
be specific cells and group of cells

00:08:14.750 --> 00:08:14.760
be specific cells and group of cells
 

00:08:14.760 --> 00:08:17.480
be specific cells and group of cells
that are there and stay in one place and

00:08:17.480 --> 00:08:17.490
that are there and stay in one place and
 

00:08:17.490 --> 00:08:19.280
that are there and stay in one place and
connect to each other like your grid

00:08:19.280 --> 00:08:19.290
connect to each other like your grid
 

00:08:19.290 --> 00:08:21.350
connect to each other like your grid
cells and play cells there's a lot that

00:08:21.350 --> 00:08:21.360
cells and play cells there's a lot that
 

00:08:21.360 --> 00:08:24.110
cells and play cells there's a lot that
is hardwired definitely but at the same

00:08:24.110 --> 00:08:24.120
is hardwired definitely but at the same
 

00:08:24.120 --> 00:08:26.540
is hardwired definitely but at the same
time what's so special about human

00:08:26.540 --> 00:08:26.550
time what's so special about human
 

00:08:26.550 --> 00:08:27.110
time what's so special about human
beings

00:08:27.110 --> 00:08:27.120
beings
 

00:08:27.120 --> 00:08:30.170
beings
compared to machines is that from the

00:08:30.170 --> 00:08:30.180
compared to machines is that from the
 

00:08:30.180 --> 00:08:32.150
compared to machines is that from the
very very beginning we interact with the

00:08:32.150 --> 00:08:32.160
very very beginning we interact with the
 

00:08:32.160 --> 00:08:34.880
very very beginning we interact with the
environment through lots of sensors

00:08:34.880 --> 00:08:34.890
environment through lots of sensors
 

00:08:34.890 --> 00:08:37.219
environment through lots of sensors
we're bombarded by information and this

00:08:37.219 --> 00:08:37.229
we're bombarded by information and this
 

00:08:37.229 --> 00:08:38.959
we're bombarded by information and this
is sort of put into the brain the brain

00:08:38.959 --> 00:08:38.969
is sort of put into the brain the brain
 

00:08:38.969 --> 00:08:41.150
is sort of put into the brain the brain
is rewired a little bit to adapt to this

00:08:41.150 --> 00:08:41.160
is rewired a little bit to adapt to this
 

00:08:41.160 --> 00:08:44.930
is rewired a little bit to adapt to this
and this goes on then for decades so I

00:08:44.930 --> 00:08:44.940
and this goes on then for decades so I
 

00:08:44.940 --> 00:08:47.870
and this goes on then for decades so I
mean the the answer is both

00:08:47.870 --> 00:08:47.880
mean the the answer is both
 

00:08:47.880 --> 00:08:48.950
mean the the answer is both
we are hardwired

00:08:48.950 --> 00:08:48.960
we are hardwired
 

00:08:48.960 --> 00:08:50.690
we are hardwired
there's a lot that is fixed but then

00:08:50.690 --> 00:08:50.700
there's a lot that is fixed but then
 

00:08:50.700 --> 00:08:52.730
there's a lot that is fixed but then
this is also adapted to functional

00:08:52.730 --> 00:08:52.740
this is also adapted to functional
 

00:08:52.740 --> 00:09:00.350
this is also adapted to functional
function optimally in the world so there

00:09:00.350 --> 00:09:00.360
function optimally in the world so there
 

00:09:00.360 --> 00:09:02.510
function optimally in the world so there
is some that's hardwired is some that's

00:09:02.510 --> 00:09:02.520
is some that's hardwired is some that's
 

00:09:02.520 --> 00:09:06.020
is some that's hardwired is some that's
learnt and by experience and repetition

00:09:06.020 --> 00:09:06.030
learnt and by experience and repetition
 

00:09:06.030 --> 00:09:12.920
learnt and by experience and repetition
and so forth can we construct a an

00:09:12.920 --> 00:09:12.930
and so forth can we construct a an
 

00:09:12.930 --> 00:09:14.810
and so forth can we construct a an
artificial intelligence system that will

00:09:14.810 --> 00:09:14.820
artificial intelligence system that will
 

00:09:14.820 --> 00:09:16.430
artificial intelligence system that will
function essentially as the human ones

00:09:16.430 --> 00:09:16.440
function essentially as the human ones
 

00:09:16.440 --> 00:09:18.910
function essentially as the human ones
Barbara was your thoughts about that

00:09:18.910 --> 00:09:18.920
Barbara was your thoughts about that
 

00:09:18.920 --> 00:09:21.410
Barbara was your thoughts about that
first I want to say that we don't need

00:09:21.410 --> 00:09:21.420
first I want to say that we don't need
 

00:09:21.420 --> 00:09:23.480
first I want to say that we don't need
to construct artificial intelligence

00:09:23.480 --> 00:09:23.490
to construct artificial intelligence
 

00:09:23.490 --> 00:09:26.390
to construct artificial intelligence
systems that replicate us there's quite

00:09:26.390 --> 00:09:26.400
systems that replicate us there's quite
 

00:09:26.400 --> 00:09:31.910
systems that replicate us there's quite
a good way of already replicating us it

00:09:31.910 --> 00:09:31.920
a good way of already replicating us it
 

00:09:31.920 --> 00:09:34.300
a good way of already replicating us it
works pretty well most of the time I

00:09:34.300 --> 00:09:34.310
works pretty well most of the time I
 

00:09:34.310 --> 00:09:37.340
works pretty well most of the time I
want to go back to the person who really

00:09:37.340 --> 00:09:37.350
want to go back to the person who really
 

00:09:37.350 --> 00:09:41.000
want to go back to the person who really
initiated AI Alan Turing who said that

00:09:41.000 --> 00:09:41.010
initiated AI Alan Turing who said that
 

00:09:41.010 --> 00:09:42.560
initiated AI Alan Turing who said that
the whole process of thinking was rather

00:09:42.560 --> 00:09:42.570
the whole process of thinking was rather
 

00:09:42.570 --> 00:09:43.340
the whole process of thinking was rather
mysterious

00:09:43.340 --> 00:09:43.350
mysterious
 

00:09:43.350 --> 00:09:45.980
mysterious
but by trying to understand it we would

00:09:45.980 --> 00:09:45.990
but by trying to understand it we would
 

00:09:45.990 --> 00:09:48.770
but by trying to understand it we would
learn a lot about how we think so

00:09:48.770 --> 00:09:48.780
learn a lot about how we think so
 

00:09:48.780 --> 00:09:50.990
learn a lot about how we think so
I think the the goals of artificial

00:09:50.990 --> 00:09:51.000
I think the the goals of artificial
 

00:09:51.000 --> 00:09:53.050
I think the the goals of artificial
intelligence are to understand

00:09:53.050 --> 00:09:53.060
intelligence are to understand
 

00:09:53.060 --> 00:09:55.700
intelligence are to understand
intelligent behavior and intelligence

00:09:55.700 --> 00:09:55.710
intelligent behavior and intelligence
 

00:09:55.710 --> 00:09:59.000
intelligent behavior and intelligence
and to embody it computationally but

00:09:59.000 --> 00:09:59.010
and to embody it computationally but
 

00:09:59.010 --> 00:10:00.830
and to embody it computationally but
that doesn't necessarily mean

00:10:00.830 --> 00:10:00.840
that doesn't necessarily mean
 

00:10:00.840 --> 00:10:03.620
that doesn't necessarily mean
replicating us I wanted also to pick up

00:10:03.620 --> 00:10:03.630
replicating us I wanted also to pick up
 

00:10:03.630 --> 00:10:07.700
replicating us I wanted also to pick up
on something that my co-panelists said

00:10:07.700 --> 00:10:07.710
on something that my co-panelists said
 

00:10:07.710 --> 00:10:10.940
on something that my co-panelists said
which is we now know from neural science

00:10:10.940 --> 00:10:10.950
which is we now know from neural science
 

00:10:10.950 --> 00:10:15.040
which is we now know from neural science
that the learning that humans do is

00:10:15.040 --> 00:10:15.050
that the learning that humans do is
 

00:10:15.050 --> 00:10:19.130
that the learning that humans do is
socially very very dependent on social

00:10:19.130 --> 00:10:19.140
socially very very dependent on social
 

00:10:19.140 --> 00:10:22.250
socially very very dependent on social
interaction and we see this in early

00:10:22.250 --> 00:10:22.260
interaction and we see this in early
 

00:10:22.260 --> 00:10:24.260
interaction and we see this in early
brain development I'm sure Edouard can

00:10:24.260 --> 00:10:24.270
brain development I'm sure Edouard can
 

00:10:24.270 --> 00:10:26.350
brain development I'm sure Edouard can
say more about this we see this in

00:10:26.350 --> 00:10:26.360
say more about this we see this in
 

00:10:26.360 --> 00:10:29.930
say more about this we see this in
learning of languages so that as we

00:10:29.930 --> 00:10:29.940
learning of languages so that as we
 

00:10:29.940 --> 00:10:32.240
learning of languages so that as we
build AI systems I think it's crucial

00:10:32.240 --> 00:10:32.250
build AI systems I think it's crucial
 

00:10:32.250 --> 00:10:36.080
build AI systems I think it's crucial
that we take into account the role of

00:10:36.080 --> 00:10:36.090
that we take into account the role of
 

00:10:36.090 --> 00:10:38.330
that we take into account the role of
social interaction even though we are

00:10:38.330 --> 00:10:38.340
social interaction even though we are
 

00:10:38.340 --> 00:10:39.950
social interaction even though we are
building a different species of

00:10:39.950 --> 00:10:39.960
building a different species of
 

00:10:39.960 --> 00:10:42.650
building a different species of
intelligent behavior so I think if I

00:10:42.650 --> 00:10:42.660
intelligent behavior so I think if I
 

00:10:42.660 --> 00:10:46.370
intelligent behavior so I think if I
have a concern about how we look forward

00:10:46.370 --> 00:10:46.380
have a concern about how we look forward
 

00:10:46.380 --> 00:10:48.590
have a concern about how we look forward
at intelligence it's that we not

00:10:48.590 --> 00:10:48.600
at intelligence it's that we not
 

00:10:48.600 --> 00:10:50.450
at intelligence it's that we not
overlook the social interaction which

00:10:50.450 --> 00:10:50.460
overlook the social interaction which
 

00:10:50.460 --> 00:10:57.170
overlook the social interaction which
really everybody has has brought up in a

00:10:57.170 --> 00:10:57.180
really everybody has has brought up in a
 

00:10:57.180 --> 00:10:59.960
really everybody has has brought up in a
sense we are stumbling into an

00:10:59.960 --> 00:10:59.970
sense we are stumbling into an
 

00:10:59.970 --> 00:11:02.840
sense we are stumbling into an
artificial future there will be a new

00:11:02.840 --> 00:11:02.850
artificial future there will be a new
 

00:11:02.850 --> 00:11:06.110
artificial future there will be a new
between the artifacts that we create

00:11:06.110 --> 00:11:06.120
between the artifacts that we create
 

00:11:06.120 --> 00:11:08.900
between the artifacts that we create
I being one of the most prominent ones

00:11:08.900 --> 00:11:08.910
I being one of the most prominent ones
 

00:11:08.910 --> 00:11:11.990
I being one of the most prominent ones
but the precise way of embedding this

00:11:11.990 --> 00:11:12.000
but the precise way of embedding this
 

00:11:12.000 --> 00:11:15.019
but the precise way of embedding this
into a social environment into the way

00:11:15.019 --> 00:11:15.029
into a social environment into the way
 

00:11:15.029 --> 00:11:19.009
into a social environment into the way
how our institutions function all this

00:11:19.009 --> 00:11:19.019
how our institutions function all this
 

00:11:19.019 --> 00:11:21.019
how our institutions function all this
is a kind of stumbling there is no

00:11:21.019 --> 00:11:21.029
is a kind of stumbling there is no
 

00:11:21.029 --> 00:11:23.329
is a kind of stumbling there is no
master plan out there there's a lot of

00:11:23.329 --> 00:11:23.339
master plan out there there's a lot of
 

00:11:23.339 --> 00:11:25.579
master plan out there there's a lot of
uncertainty on the way how we will get

00:11:25.579 --> 00:11:25.589
uncertainty on the way how we will get
 

00:11:25.589 --> 00:11:28.460
uncertainty on the way how we will get
there and I think it is this stumbling

00:11:28.460 --> 00:11:28.470
there and I think it is this stumbling
 

00:11:28.470 --> 00:11:31.069
there and I think it is this stumbling
into an artificial future that contains

00:11:31.069 --> 00:11:31.079
into an artificial future that contains
 

00:11:31.079 --> 00:11:33.860
into an artificial future that contains
an enormous potential but at the same

00:11:33.860 --> 00:11:33.870
an enormous potential but at the same
 

00:11:33.870 --> 00:11:36.290
an enormous potential but at the same
time we have to have the kind of

00:11:36.290 --> 00:11:36.300
time we have to have the kind of
 

00:11:36.300 --> 00:11:39.559
time we have to have the kind of
adaptability and the plasticity that we

00:11:39.559 --> 00:11:39.569
adaptability and the plasticity that we
 

00:11:39.569 --> 00:11:42.199
adaptability and the plasticity that we
have inherited but to translate it also

00:11:42.199 --> 00:11:42.209
have inherited but to translate it also
 

00:11:42.209 --> 00:11:45.199
have inherited but to translate it also
into is socially manageable forms so I

00:11:45.199 --> 00:11:45.209
into is socially manageable forms so I
 

00:11:45.209 --> 00:11:47.990
into is socially manageable forms so I
think that's exactly right and one of

00:11:47.990 --> 00:11:48.000
think that's exactly right and one of
 

00:11:48.000 --> 00:11:50.509
think that's exactly right and one of
the things we've learned in an area of

00:11:50.509 --> 00:11:50.519
the things we've learned in an area of
 

00:11:50.519 --> 00:11:51.740
the things we've learned in an area of
artificial intelligence called

00:11:51.740 --> 00:11:51.750
artificial intelligence called
 

00:11:51.750 --> 00:11:53.990
artificial intelligence called
multi-agent systems is that it's much

00:11:53.990 --> 00:11:54.000
multi-agent systems is that it's much
 

00:11:54.000 --> 00:11:56.240
multi-agent systems is that it's much
more difficult to build a system that

00:11:56.240 --> 00:11:56.250
more difficult to build a system that
 

00:11:56.250 --> 00:11:58.189
more difficult to build a system that
interacts with groups of people than it

00:11:58.189 --> 00:11:58.199
interacts with groups of people than it
 

00:11:58.199 --> 00:12:00.259
interacts with groups of people than it
is to build a system that just interacts

00:12:00.259 --> 00:12:00.269
is to build a system that just interacts
 

00:12:00.269 --> 00:12:03.470
is to build a system that just interacts
with groups of systems and I think going

00:12:03.470 --> 00:12:03.480
with groups of systems and I think going
 

00:12:03.480 --> 00:12:04.939
with groups of systems and I think going
forward it's going to be absolutely

00:12:04.939 --> 00:12:04.949
forward it's going to be absolutely
 

00:12:04.949 --> 00:12:07.550
forward it's going to be absolutely
crucial in the field and I would say

00:12:07.550 --> 00:12:07.560
crucial in the field and I would say
 

00:12:07.560 --> 00:12:10.460
crucial in the field and I would say
also in the neurosciences and in the

00:12:10.460 --> 00:12:10.470
also in the neurosciences and in the
 

00:12:10.470 --> 00:12:12.170
also in the neurosciences and in the
cognitive sciences writ large

00:12:12.170 --> 00:12:12.180
cognitive sciences writ large
 

00:12:12.180 --> 00:12:16.040
cognitive sciences writ large
not to focus on intelligence as in a

00:12:16.040 --> 00:12:16.050
not to focus on intelligence as in a
 

00:12:16.050 --> 00:12:19.910
not to focus on intelligence as in a
single mind but to look at the

00:12:19.910 --> 00:12:19.920
single mind but to look at the
 

00:12:19.920 --> 00:12:21.650
single mind but to look at the
intelligence of individuals in the

00:12:21.650 --> 00:12:21.660
intelligence of individuals in the
 

00:12:21.660 --> 00:12:24.439
intelligence of individuals in the
context of societies and communities and

00:12:24.439 --> 00:12:24.449
context of societies and communities and
 

00:12:24.449 --> 00:12:28.220
context of societies and communities and
of working together so I wanted to give

00:12:28.220 --> 00:12:28.230
of working together so I wanted to give
 

00:12:28.230 --> 00:12:30.019
of working together so I wanted to give
my answer to the eleven-year-old who

00:12:30.019 --> 00:12:30.029
my answer to the eleven-year-old who
 

00:12:30.029 --> 00:12:33.259
my answer to the eleven-year-old who
asked if a wonderful question of whether

00:12:33.259 --> 00:12:33.269
asked if a wonderful question of whether
 

00:12:33.269 --> 00:12:36.230
asked if a wonderful question of whether
AI was going to replace teachers and of

00:12:36.230 --> 00:12:36.240
AI was going to replace teachers and of
 

00:12:36.240 --> 00:12:38.269
AI was going to replace teachers and of
course I don't I can't predict the

00:12:38.269 --> 00:12:38.279
course I don't I can't predict the
 

00:12:38.279 --> 00:12:40.100
course I don't I can't predict the
future I can say that what we have

00:12:40.100 --> 00:12:40.110
future I can say that what we have
 

00:12:40.110 --> 00:12:42.920
future I can say that what we have
learned in the last decades about

00:12:42.920 --> 00:12:42.930
learned in the last decades about
 

00:12:42.930 --> 00:12:45.499
learned in the last decades about
artificial intelligences and teaching is

00:12:45.499 --> 00:12:45.509
artificial intelligences and teaching is
 

00:12:45.509 --> 00:12:48.920
artificial intelligences and teaching is
that it can complement teachers and

00:12:48.920 --> 00:12:48.930
that it can complement teachers and
 

00:12:48.930 --> 00:12:51.470
that it can complement teachers and
actually make for a better educational

00:12:51.470 --> 00:12:51.480
actually make for a better educational
 

00:12:51.480 --> 00:12:53.900
actually make for a better educational
system if you look at complementing and

00:12:53.900 --> 00:12:53.910
system if you look at complementing and
 

00:12:53.910 --> 00:12:55.639
system if you look at complementing and
working with people and with the

00:12:55.639 --> 00:12:55.649
working with people and with the
 

00:12:55.649 --> 00:12:57.079
working with people and with the
teachers and with the students rather

00:12:57.079 --> 00:12:57.089
teachers and with the students rather
 

00:12:57.089 --> 00:12:59.929
teachers and with the students rather
than thinking about replacing them so I

00:12:59.929 --> 00:12:59.939
than thinking about replacing them so I
 

00:12:59.939 --> 00:13:02.240
than thinking about replacing them so I
wanted to thank that student for his

00:13:02.240 --> 00:13:02.250
wanted to thank that student for his
 

00:13:02.250 --> 00:13:04.340
wanted to thank that student for his
question and we have a panel on the

00:13:04.340 --> 00:13:04.350
question and we have a panel on the
 

00:13:04.350 --> 00:13:07.309
question and we have a panel on the
future of learning discipline or it was

00:13:07.309 --> 00:13:07.319
future of learning discipline or it was
 

00:13:07.319 --> 00:13:10.560
future of learning discipline or it was
a related question we got from from

00:13:10.560 --> 00:13:10.570
a related question we got from from
 

00:13:10.570 --> 00:13:13.650
a related question we got from from
student in the audience I'm Rita

00:13:13.650 --> 00:13:13.660
student in the audience I'm Rita
 

00:13:13.660 --> 00:13:16.740
student in the audience I'm Rita
Krishnan I don't know if he's here and I

00:13:16.740 --> 00:13:16.750
Krishnan I don't know if he's here and I
 

00:13:16.750 --> 00:13:18.300
Krishnan I don't know if he's here and I
wouldn't say be able to see if your

00:13:18.300 --> 00:13:18.310
wouldn't say be able to see if your
 

00:13:18.310 --> 00:13:21.240
wouldn't say be able to see if your
raises his hand anyway the question is

00:13:21.240 --> 00:13:21.250
raises his hand anyway the question is
 

00:13:21.250 --> 00:13:24.030
raises his hand anyway the question is
is artificial intelligence an evolution

00:13:24.030 --> 00:13:24.040
is artificial intelligence an evolution
 

00:13:24.040 --> 00:13:28.290
is artificial intelligence an evolution
of intelligence itself that it brings up

00:13:28.290 --> 00:13:28.300
of intelligence itself that it brings up
 

00:13:28.300 --> 00:13:30.000
of intelligence itself that it brings up
of course the interaction between the

00:13:30.000 --> 00:13:30.010
of course the interaction between the
 

00:13:30.010 --> 00:13:33.090
of course the interaction between the
artificial and the biological and the

00:13:33.090 --> 00:13:33.100
artificial and the biological and the
 

00:13:33.100 --> 00:13:36.180
artificial and the biological and the
human that we touched upon any one would

00:13:36.180 --> 00:13:36.190
human that we touched upon any one would
 

00:13:36.190 --> 00:13:48.540
human that we touched upon any one would
water some thoughts on this hugely

00:13:48.540 --> 00:13:48.550
water some thoughts on this hugely
 

00:13:48.550 --> 00:13:51.120
water some thoughts on this hugely
important and exciting one with a hugely

00:13:51.120 --> 00:13:51.130
important and exciting one with a hugely
 

00:13:51.130 --> 00:13:55.860
important and exciting one with a hugely
exciting future to it yes whether it's

00:13:55.860 --> 00:13:55.870
exciting future to it yes whether it's
 

00:13:55.870 --> 00:13:58.080
exciting future to it yes whether it's
any more of an evolution of human

00:13:58.080 --> 00:13:58.090
any more of an evolution of human
 

00:13:58.090 --> 00:14:02.160
any more of an evolution of human
intelligence then you know Newton's laws

00:14:02.160 --> 00:14:02.170
intelligence then you know Newton's laws
 

00:14:02.170 --> 00:14:06.270
intelligence then you know Newton's laws
Darwin's theory whatever I don't know it

00:14:06.270 --> 00:14:06.280
Darwin's theory whatever I don't know it
 

00:14:06.280 --> 00:14:08.100
Darwin's theory whatever I don't know it
said there's another an example and as I

00:14:08.100 --> 00:14:08.110
said there's another an example and as I
 

00:14:08.110 --> 00:14:10.290
said there's another an example and as I
say a hugely interesting and exciting

00:14:10.290 --> 00:14:10.300
say a hugely interesting and exciting
 

00:14:10.300 --> 00:14:15.240
say a hugely interesting and exciting
one it seems from from what you all say

00:14:15.240 --> 00:14:15.250
one it seems from from what you all say
 

00:14:15.250 --> 00:14:19.080
one it seems from from what you all say
that human intelligence is still in the

00:14:19.080 --> 00:14:19.090
that human intelligence is still in the
 

00:14:19.090 --> 00:14:22.650
that human intelligence is still in the
driver's seat so to say but I wonder if

00:14:22.650 --> 00:14:22.660
driver's seat so to say but I wonder if
 

00:14:22.660 --> 00:14:24.900
driver's seat so to say but I wonder if
if the interaction between us and

00:14:24.900 --> 00:14:24.910
if the interaction between us and
 

00:14:24.910 --> 00:14:28.760
if the interaction between us and
artificial systems how that will affect

00:14:28.760 --> 00:14:28.770
artificial systems how that will affect
 

00:14:28.770 --> 00:14:31.530
artificial systems how that will affect
us how what impact it will have for

00:14:31.530 --> 00:14:31.540
us how what impact it will have for
 

00:14:31.540 --> 00:14:35.190
us how what impact it will have for
instance now that we have gps's in our

00:14:35.190 --> 00:14:35.200
instance now that we have gps's in our
 

00:14:35.200 --> 00:14:38.310
instance now that we have gps's in our
cell phones wherever it is will your

00:14:38.310 --> 00:14:38.320
cell phones wherever it is will your
 

00:14:38.320 --> 00:14:40.980
cell phones wherever it is will your
system atrophy to service that the Lord

00:14:40.980 --> 00:14:40.990
system atrophy to service that the Lord
 

00:14:40.990 --> 00:14:42.900
system atrophy to service that the Lord
what will happen to the great cells in

00:14:42.900 --> 00:14:42.910
what will happen to the great cells in
 

00:14:42.910 --> 00:14:45.660
what will happen to the great cells in
the future are you worried well of

00:14:45.660 --> 00:14:45.670
the future are you worried well of
 

00:14:45.670 --> 00:14:48.930
the future are you worried well of
course this affects us because we we

00:14:48.930 --> 00:14:48.940
course this affects us because we we
 

00:14:48.940 --> 00:14:50.460
course this affects us because we we
navigate in different ways but I think

00:14:50.460 --> 00:14:50.470
navigate in different ways but I think
 

00:14:50.470 --> 00:14:53.550
navigate in different ways but I think
what's so special about humans and human

00:14:53.550 --> 00:14:53.560
what's so special about humans and human
 

00:14:53.560 --> 00:14:55.620
what's so special about humans and human
intelligence if you use that word is

00:14:55.620 --> 00:14:55.630
intelligence if you use that word is
 

00:14:55.630 --> 00:14:57.600
intelligence if you use that word is
that you must can adapt to almost

00:14:57.600 --> 00:14:57.610
that you must can adapt to almost
 

00:14:57.610 --> 00:14:59.700
that you must can adapt to almost
anything that's the success that's why

00:14:59.700 --> 00:14:59.710
anything that's the success that's why
 

00:14:59.710 --> 00:15:02.550
anything that's the success that's why
there are so many of us everywhere and I

00:15:02.550 --> 00:15:02.560
there are so many of us everywhere and I
 

00:15:02.560 --> 00:15:06.840
there are so many of us everywhere and I
think just like any challenges that are

00:15:06.840 --> 00:15:06.850
think just like any challenges that are
 

00:15:06.850 --> 00:15:08.520
think just like any challenges that are
happened before in evolution humans were

00:15:08.520 --> 00:15:08.530
happened before in evolution humans were
 

00:15:08.530 --> 00:15:10.560
happened before in evolution humans were
led up to this to a level by other forms

00:15:10.560 --> 00:15:10.570
led up to this to a level by other forms
 

00:15:10.570 --> 00:15:12.170
led up to this to a level by other forms
of interaction

00:15:12.170 --> 00:15:12.180
of interaction
 

00:15:12.180 --> 00:15:16.920
of interaction
perhaps but of course for navigation as

00:15:16.920 --> 00:15:16.930
perhaps but of course for navigation as
 

00:15:16.930 --> 00:15:19.620
perhaps but of course for navigation as
such we'll always there's always an a

00:15:19.620 --> 00:15:19.630
such we'll always there's always an a
 

00:15:19.630 --> 00:15:22.710
such we'll always there's always an a
component of training and experience

00:15:22.710 --> 00:15:22.720
component of training and experience
 

00:15:22.720 --> 00:15:26.129
component of training and experience
and if you use then a GPS instead of our

00:15:26.129 --> 00:15:26.139
and if you use then a GPS instead of our
 

00:15:26.139 --> 00:15:28.079
and if you use then a GPS instead of our
own brain of course we navigate at least

00:15:28.079 --> 00:15:28.089
own brain of course we navigate at least
 

00:15:28.089 --> 00:15:32.369
own brain of course we navigate at least
in a different way but III think I don't

00:15:32.369 --> 00:15:32.379
in a different way but III think I don't
 

00:15:32.379 --> 00:15:34.290
in a different way but III think I don't
see it as a threat it will just change

00:15:34.290 --> 00:15:34.300
see it as a threat it will just change
 

00:15:34.300 --> 00:15:36.210
see it as a threat it will just change
in a different way in the same way that

00:15:36.210 --> 00:15:36.220
in a different way in the same way that
 

00:15:36.220 --> 00:15:39.509
in a different way in the same way that
mobile phones over just 10 20 years so

00:15:39.509 --> 00:15:39.519
mobile phones over just 10 20 years so
 

00:15:39.519 --> 00:15:41.369
mobile phones over just 10 20 years so
completely changed our lives how we

00:15:41.369 --> 00:15:41.379
completely changed our lives how we
 

00:15:41.379 --> 00:15:44.759
completely changed our lives how we
handle information but I mean people

00:15:44.759 --> 00:15:44.769
handle information but I mean people
 

00:15:44.769 --> 00:15:47.040
handle information but I mean people
learn in a different way people treat

00:15:47.040 --> 00:15:47.050
learn in a different way people treat
 

00:15:47.050 --> 00:15:49.050
learn in a different way people treat
information access information in a

00:15:49.050 --> 00:15:49.060
information access information in a
 

00:15:49.060 --> 00:15:54.179
information access information in a
different way I would say it's an

00:15:54.179 --> 00:15:54.189
different way I would say it's an
 

00:15:54.189 --> 00:15:56.999
different way I would say it's an
example of cultural evolution and

00:15:56.999 --> 00:15:57.009
example of cultural evolution and
 

00:15:57.009 --> 00:15:59.059
example of cultural evolution and
cultural evolution is much faster than

00:15:59.059 --> 00:15:59.069
cultural evolution is much faster than
 

00:15:59.069 --> 00:16:02.670
cultural evolution is much faster than
biological evolution but we also see new

00:16:02.670 --> 00:16:02.680
biological evolution but we also see new
 

00:16:02.680 --> 00:16:05.639
biological evolution but we also see new
and interesting intersections between

00:16:05.639 --> 00:16:05.649
and interesting intersections between
 

00:16:05.649 --> 00:16:09.210
and interesting intersections between
cultural evolution what we do and what

00:16:09.210 --> 00:16:09.220
cultural evolution what we do and what
 

00:16:09.220 --> 00:16:11.340
cultural evolution what we do and what
biological evolution has equipped us to

00:16:11.340 --> 00:16:11.350
biological evolution has equipped us to
 

00:16:11.350 --> 00:16:13.980
biological evolution has equipped us to
be able to move on we have so many more

00:16:13.980 --> 00:16:13.990
be able to move on we have so many more
 

00:16:13.990 --> 00:16:17.550
be able to move on we have so many more
social interactions now then 200 years

00:16:17.550 --> 00:16:17.560
social interactions now then 200 years
 

00:16:17.560 --> 00:16:20.179
social interactions now then 200 years
ago say ovide we're in touch with

00:16:20.179 --> 00:16:20.189
ago say ovide we're in touch with
 

00:16:20.189 --> 00:16:23.249
ago say ovide we're in touch with
millions of people around the planet and

00:16:23.249 --> 00:16:23.259
millions of people around the planet and
 

00:16:23.259 --> 00:16:26.069
millions of people around the planet and
each one of us with at least thousands

00:16:26.069 --> 00:16:26.079
each one of us with at least thousands
 

00:16:26.079 --> 00:16:28.470
each one of us with at least thousands
probably through digital media and and

00:16:28.470 --> 00:16:28.480
probably through digital media and and
 

00:16:28.480 --> 00:16:31.199
probably through digital media and and
in many different ways whereas my great

00:16:31.199 --> 00:16:31.209
in many different ways whereas my great
 

00:16:31.209 --> 00:16:33.299
in many different ways whereas my great
great grandparents probably saw the

00:16:33.299 --> 00:16:33.309
great grandparents probably saw the
 

00:16:33.309 --> 00:16:35.670
great grandparents probably saw the
other people on their neighbor forms and

00:16:35.670 --> 00:16:35.680
other people on their neighbor forms and
 

00:16:35.680 --> 00:16:38.220
other people on their neighbor forms and
that was it is that gonna change the way

00:16:38.220 --> 00:16:38.230
that was it is that gonna change the way
 

00:16:38.230 --> 00:16:40.530
that was it is that gonna change the way
our brains function and this is gonna

00:16:40.530 --> 00:16:40.540
our brains function and this is gonna
 

00:16:40.540 --> 00:16:44.309
our brains function and this is gonna
change the way our brains look the way

00:16:44.309 --> 00:16:44.319
change the way our brains look the way
 

00:16:44.319 --> 00:16:47.100
change the way our brains look the way
they're hardwired so I think as Edouard

00:16:47.100 --> 00:16:47.110
they're hardwired so I think as Edouard
 

00:16:47.110 --> 00:16:49.949
they're hardwired so I think as Edouard
was suggesting our brains are very

00:16:49.949 --> 00:16:49.959
was suggesting our brains are very
 

00:16:49.959 --> 00:16:54.689
was suggesting our brains are very
plastic and and we adapt and we adapt so

00:16:54.689 --> 00:16:54.699
plastic and and we adapt and we adapt so
 

00:16:54.699 --> 00:16:57.509
plastic and and we adapt and we adapt so
culturally also and I think we're seeing

00:16:57.509 --> 00:16:57.519
culturally also and I think we're seeing
 

00:16:57.519 --> 00:17:00.540
culturally also and I think we're seeing
that you ask the question of what

00:17:00.540 --> 00:17:00.550
that you ask the question of what
 

00:17:00.550 --> 00:17:02.579
that you ask the question of what
artificial intelligence to replace our

00:17:02.579 --> 00:17:02.589
artificial intelligence to replace our
 

00:17:02.589 --> 00:17:04.799
artificial intelligence to replace our
cognitive abilities I think they will

00:17:04.799 --> 00:17:04.809
cognitive abilities I think they will
 

00:17:04.809 --> 00:17:08.970
cognitive abilities I think they will
certainly change what we need to make

00:17:08.970 --> 00:17:08.980
certainly change what we need to make
 

00:17:08.980 --> 00:17:11.279
certainly change what we need to make
sure of and and we actually can control

00:17:11.279 --> 00:17:11.289
sure of and and we actually can control
 

00:17:11.289 --> 00:17:13.949
sure of and and we actually can control
this in some way through design is that

00:17:13.949 --> 00:17:13.959
this in some way through design is that
 

00:17:13.959 --> 00:17:16.919
this in some way through design is that
they make us smarter not dumber but they

00:17:16.919 --> 00:17:16.929
they make us smarter not dumber but they
 

00:17:16.929 --> 00:17:19.470
they make us smarter not dumber but they
really truly complement us and so I

00:17:19.470 --> 00:17:19.480
really truly complement us and so I
 

00:17:19.480 --> 00:17:22.770
really truly complement us and so I
actually I like the GPS example because

00:17:22.770 --> 00:17:22.780
actually I like the GPS example because
 

00:17:22.780 --> 00:17:24.809
actually I like the GPS example because
I'm a hiker and you know if you're out

00:17:24.809 --> 00:17:24.819
I'm a hiker and you know if you're out
 

00:17:24.819 --> 00:17:27.079
I'm a hiker and you know if you're out
of GPS range you better know how to

00:17:27.079 --> 00:17:27.089
of GPS range you better know how to
 

00:17:27.089 --> 00:17:30.120
of GPS range you better know how to
locate yourself without the GPS system

00:17:30.120 --> 00:17:30.130
locate yourself without the GPS system
 

00:17:30.130 --> 00:17:32.370
locate yourself without the GPS system
and I'm not sure about Europe but we

00:17:32.370 --> 00:17:32.380
and I'm not sure about Europe but we
 

00:17:32.380 --> 00:17:33.930
and I'm not sure about Europe but we
have these stories in the United States

00:17:33.930 --> 00:17:33.940
have these stories in the United States
 

00:17:33.940 --> 00:17:35.170
have these stories in the United States
of people who get in great

00:17:35.170 --> 00:17:35.180
of people who get in great
 

00:17:35.180 --> 00:17:37.300
of people who get in great
trouble because they think that their

00:17:37.300 --> 00:17:37.310
trouble because they think that their
 

00:17:37.310 --> 00:17:39.250
trouble because they think that their
phone will show them how to go when

00:17:39.250 --> 00:17:39.260
phone will show them how to go when
 

00:17:39.260 --> 00:17:40.510
phone will show them how to go when
they're up in the mountains and it

00:17:40.510 --> 00:17:40.520
they're up in the mountains and it
 

00:17:40.520 --> 00:17:43.360
they're up in the mountains and it
doesn't always work so I it's an example

00:17:43.360 --> 00:17:43.370
doesn't always work so I it's an example
 

00:17:43.370 --> 00:17:46.270
doesn't always work so I it's an example
of where you want not to think about

00:17:46.270 --> 00:17:46.280
of where you want not to think about
 

00:17:46.280 --> 00:17:49.000
of where you want not to think about
replacement but complementarity and I

00:17:49.000 --> 00:17:49.010
replacement but complementarity and I
 

00:17:49.010 --> 00:17:51.400
replacement but complementarity and I
would say to everyone who is a consumer

00:17:51.400 --> 00:17:51.410
would say to everyone who is a consumer
 

00:17:51.410 --> 00:17:54.520
would say to everyone who is a consumer
of these devices that you can ask that

00:17:54.520 --> 00:17:54.530
of these devices that you can ask that
 

00:17:54.530 --> 00:17:56.530
of these devices that you can ask that
they make you smarter and not less

00:17:56.530 --> 00:17:56.540
they make you smarter and not less
 

00:17:56.540 --> 00:18:00.810
they make you smarter and not less
intelligent so that's a wonderful

00:18:00.810 --> 00:18:00.820
intelligent so that's a wonderful
 

00:18:00.820 --> 00:18:05.260
intelligent so that's a wonderful
message too at which to conclude here

00:18:05.260 --> 00:18:05.270
message too at which to conclude here
 

00:18:05.270 --> 00:18:08.320
message too at which to conclude here
that after all mankind is getting

00:18:08.320 --> 00:18:08.330
that after all mankind is getting
 

00:18:08.330 --> 00:18:11.530
that after all mankind is getting
smarter perhaps in small steps but it's

00:18:11.530 --> 00:18:11.540
smarter perhaps in small steps but it's
 

00:18:11.540 --> 00:18:13.030
smarter perhaps in small steps but it's
moving in the right direction we just

00:18:13.030 --> 00:18:13.040
moving in the right direction we just
 

00:18:13.040 --> 00:18:16.030
moving in the right direction we just
have to hope that we're moving fast

00:18:16.030 --> 00:18:16.040
have to hope that we're moving fast
 

00:18:16.040 --> 00:18:18.310
have to hope that we're moving fast
enough to handle all the problems that

00:18:18.310 --> 00:18:18.320
enough to handle all the problems that
 

00:18:18.320 --> 00:18:20.640
enough to handle all the problems that
not against invention in the beginning

00:18:20.640 --> 00:18:20.650
not against invention in the beginning
 

00:18:20.650 --> 00:18:23.710
not against invention in the beginning
but I take it that there is a optimistic

00:18:23.710 --> 00:18:23.720
but I take it that there is a optimistic
 

00:18:23.720 --> 00:18:25.870
but I take it that there is a optimistic
message from the panel here and with

00:18:25.870 --> 00:18:25.880
message from the panel here and with
 

00:18:25.880 --> 00:18:28.510
message from the panel here and with
that I thank you so much for discussing

00:18:28.510 --> 00:18:28.520
that I thank you so much for discussing
 

00:18:28.520 --> 00:18:31.750
that I thank you so much for discussing
this difficult topic with us and I think

00:18:31.750 --> 00:18:31.760
this difficult topic with us and I think
 

00:18:31.760 --> 00:18:34.630
this difficult topic with us and I think
we all understood at least how complex

00:18:34.630 --> 00:18:34.640
we all understood at least how complex
 

00:18:34.640 --> 00:18:37.000
we all understood at least how complex
the topic is and how hard to define it

00:18:37.000 --> 00:18:37.010
the topic is and how hard to define it
 

00:18:37.010 --> 00:18:38.500
the topic is and how hard to define it
is but there is hope for the future

00:18:38.500 --> 00:18:38.510
is but there is hope for the future
 

00:18:38.510 --> 00:18:41.500
is but there is hope for the future
thank you very much

