WEBVTT
Kind: captions
Language: en

00:00:01.872 --> 00:00:03.280
KEVIN FIVES: All right.

00:00:03.280 --> 00:00:05.510
First of all, thank you
all so much for being here.

00:00:05.510 --> 00:00:06.290
My name is Kevin.

00:00:06.290 --> 00:00:07.750
And today, Montana
and I are going

00:00:07.750 --> 00:00:11.260
to talk to you about
machine learning.

00:00:11.260 --> 00:00:13.721
Now, this may not
be the first time

00:00:13.721 --> 00:00:15.470
that you've heard
someone from Google talk

00:00:15.470 --> 00:00:17.080
about machine learning.

00:00:17.080 --> 00:00:19.120
We talk about it a lot.

00:00:19.120 --> 00:00:21.430
In fact, our CEO, Sundar,
has gone as far as

00:00:21.430 --> 00:00:24.160
to say that we will move
from a mobile first world

00:00:24.160 --> 00:00:26.690
to an AI first world.

00:00:26.690 --> 00:00:28.570
But when we talk to
developers, the question

00:00:28.570 --> 00:00:30.940
that we get most
often is how to think

00:00:30.940 --> 00:00:33.730
about machine learning within
the context of their business.

00:00:33.730 --> 00:00:36.070
Sure, they've
heard about AlphaGo

00:00:36.070 --> 00:00:37.690
or they've used Google Photos.

00:00:37.690 --> 00:00:39.850
But what about practical
ways they can start

00:00:39.850 --> 00:00:41.860
with machine learning today?

00:00:41.860 --> 00:00:44.276
Now, we have a diverse
audience here today.

00:00:44.276 --> 00:00:46.900
There's a mix of businesspeople
and product managers, designers

00:00:46.900 --> 00:00:47.829
and developers.

00:00:47.829 --> 00:00:49.870
Some of you might be
experts in machine learning.

00:00:49.870 --> 00:00:51.244
Others maybe have
heard the term.

00:00:51.244 --> 00:00:52.990
But you're not quite
sure where to start

00:00:52.990 --> 00:00:54.310
or what all the fuss is about.

00:00:54.310 --> 00:00:56.310
So we're going break
the talk into two parts.

00:00:56.310 --> 00:00:57.961
Mine will be pretty short.

00:00:57.961 --> 00:01:00.460
I'm going to give sort of the
high-level, practical overview

00:01:00.460 --> 00:01:02.876
of machine learning to make
sure that everyone has context

00:01:02.876 --> 00:01:04.090
for Montana's section.

00:01:04.090 --> 00:01:06.300
Montana will then
share how Instacart

00:01:06.300 --> 00:01:08.890
uses machine learning and
the real-world problems

00:01:08.890 --> 00:01:11.015
that they're solving using ML.

00:01:11.015 --> 00:01:11.890
So let's get started.

00:01:14.850 --> 00:01:20.270
So the first question is, why
using machine learning at all?

00:01:20.270 --> 00:01:22.796
And to answer this, I'd like
to give a very simple example.

00:01:22.796 --> 00:01:24.170
What if I was to
ask you to write

00:01:24.170 --> 00:01:26.240
a program that
tells the difference

00:01:26.240 --> 00:01:28.330
between an apple and an orange?

00:01:31.840 --> 00:01:33.710
You might start by
writing manual rules.

00:01:33.710 --> 00:01:36.880
For example, maybe you'd count
the number of orange pixels

00:01:36.880 --> 00:01:38.980
in an image versus the
number of green pixels

00:01:38.980 --> 00:01:40.540
and compare the ratio.

00:01:40.540 --> 00:01:43.150
And that might work
for these two images.

00:01:43.150 --> 00:01:44.950
But the problem with
writing manual rules

00:01:44.950 --> 00:01:46.870
is that it doesn't scale.

00:01:46.870 --> 00:01:49.570
And for every rule
that you come up with,

00:01:49.570 --> 00:01:52.750
I can find an example
that breaks that rule.

00:01:52.750 --> 00:01:55.420
For instance, what if I
gave you an image that

00:01:55.420 --> 00:02:01.250
was in black and white, or what
if instead of a green apple,

00:02:01.250 --> 00:02:04.450
I gave you an image
of a red apple?

00:02:04.450 --> 00:02:06.040
Accounting for all
of these exceptions

00:02:06.040 --> 00:02:07.540
and writing all of
these rules would

00:02:07.540 --> 00:02:09.897
require lots and lots of code.

00:02:09.897 --> 00:02:11.980
And if I gave you a similar
problem in the future,

00:02:11.980 --> 00:02:14.680
like tell me the difference
between a raspberry

00:02:14.680 --> 00:02:17.950
and a strawberry, you'd
need to start all over.

00:02:17.950 --> 00:02:21.490
Clearly, there has
to be a better way.

00:02:21.490 --> 00:02:23.800
Rather than relying
on manual rules,

00:02:23.800 --> 00:02:25.780
machine learning
learns from examples.

00:02:25.780 --> 00:02:29.350
And the general way that a
machine learning model works is

00:02:29.350 --> 00:02:32.096
you take a set of inputs-- in
this case, labelled images.

00:02:32.096 --> 00:02:33.970
You feed them into a
machine learning model--

00:02:33.970 --> 00:02:36.820
in this case, a
convolutional neural network.

00:02:36.820 --> 00:02:38.440
And the model makes predictions.

00:02:38.440 --> 00:02:41.260
And if the predictions are
incorrect, what happens

00:02:41.260 --> 00:02:43.270
is it actually slightly
adjusts the model

00:02:43.270 --> 00:02:44.416
to make it more accurate.

00:02:44.416 --> 00:02:45.790
Generally, the
more data that you

00:02:45.790 --> 00:02:47.956
put into a machine learning
model, the more accurate

00:02:47.956 --> 00:02:48.940
it will be.

00:02:48.940 --> 00:02:50.980
What this allows
you to do is then

00:02:50.980 --> 00:02:53.990
you can take a new set of
data that's totally unlabeled,

00:02:53.990 --> 00:02:55.730
feed it into a machine
learning model,

00:02:55.730 --> 00:02:57.146
and the model will
tell you either

00:02:57.146 --> 00:03:01.240
that this is an
orange or an apple.

00:03:01.240 --> 00:03:04.090
Now, I'm simplifying
a little bit here.

00:03:04.090 --> 00:03:06.730
Montana, please don't kill me.

00:03:06.730 --> 00:03:09.235
But, in general, when you think
of the workflow for machine

00:03:09.235 --> 00:03:11.860
learning, there are really three
steps that you need to follow.

00:03:11.860 --> 00:03:13.782
The first is to collect data.

00:03:13.782 --> 00:03:14.740
So what does data mean?

00:03:14.740 --> 00:03:16.600
Data comes in different forms.

00:03:16.600 --> 00:03:18.490
Data can be images or audio.

00:03:18.490 --> 00:03:22.300
It can be numbers in a
database or a spreadsheet.

00:03:22.300 --> 00:03:25.460
It can be structured, or
it can be unstructured.

00:03:25.460 --> 00:03:29.050
The data collection
step specifically--

00:03:29.050 --> 00:03:32.484
by that, I mean quantity of
data, quality of data, maybe

00:03:32.484 --> 00:03:34.650
which features you choose
to include in your model--

00:03:34.650 --> 00:03:36.641
is often the most
challenging step to getting

00:03:36.641 --> 00:03:37.890
started with machine learning.

00:03:37.890 --> 00:03:40.030
When we talk to developers,
this is the biggest obstacle

00:03:40.030 --> 00:03:41.190
that they have to overcome.

00:03:41.190 --> 00:03:43.523
And Montana's going to talk
about this a little bit more

00:03:43.523 --> 00:03:44.450
in a minute.

00:03:44.450 --> 00:03:46.717
The second step is you
need to choose your model.

00:03:46.717 --> 00:03:48.300
Models come in
different flavors, too.

00:03:48.300 --> 00:03:50.758
There are deep learning models
and shallow learning models.

00:03:50.758 --> 00:03:53.410
There are pre-built
models, or models

00:03:53.410 --> 00:03:55.079
that you can build on your own.

00:03:55.079 --> 00:03:57.370
There are models that need
labelled data and those that

00:03:57.370 --> 00:03:59.650
don't.

00:03:59.650 --> 00:04:01.309
This is often a
step that I think

00:04:01.309 --> 00:04:03.100
developers that are
new to machine learning

00:04:03.100 --> 00:04:04.330
are most intimidated by.

00:04:04.330 --> 00:04:07.180
But the truth is for most
common machine learning tasks,

00:04:07.180 --> 00:04:09.820
there are open source
models that you can use.

00:04:09.820 --> 00:04:12.216
So when you choose a model,
what should you think about?

00:04:12.216 --> 00:04:14.590
The first thing is, what
problem are you trying to solve?

00:04:14.590 --> 00:04:17.390
There are different ML models
for different problems.

00:04:17.390 --> 00:04:20.176
The second is, what data do
you have at your disposal?

00:04:20.176 --> 00:04:22.300
And then the third is, what
other considerations do

00:04:22.300 --> 00:04:22.600
you have?

00:04:22.600 --> 00:04:24.479
For example, are there
latency requirements

00:04:24.479 --> 00:04:26.770
where you might need to use
on device machine learning,

00:04:26.770 --> 00:04:29.320
or are there compute
restrictions?

00:04:29.320 --> 00:04:30.990
The last step is to
predict and tune.

00:04:30.990 --> 00:04:33.812
Now, tuning really depends on
your level of sophistication.

00:04:33.812 --> 00:04:35.770
If you're new to machine
learning, like I said,

00:04:35.770 --> 00:04:37.811
there are plenty of models
you can use that don't

00:04:37.811 --> 00:04:39.466
require any tuning at all.

00:04:39.466 --> 00:04:40.840
But if you're more
sophisticated,

00:04:40.840 --> 00:04:42.673
there are things you
can do to tweak a model

00:04:42.673 --> 00:04:44.860
and make it more accurate.

00:04:44.860 --> 00:04:46.780
So that's great.

00:04:46.780 --> 00:04:48.220
What about real-world use cases?

00:04:48.220 --> 00:04:50.800
What problems can machine
learning actually solve?

00:04:50.800 --> 00:04:53.410
So I put together
some use cases that I

00:04:53.410 --> 00:04:56.200
think are broadly applicable
to folks in this room.

00:04:56.200 --> 00:04:58.469
This is not a
comprehensive list.

00:04:58.469 --> 00:05:00.010
The beauty of machine
learning really

00:05:00.010 --> 00:05:03.509
is that it can solve many, many
different types of problems.

00:05:03.509 --> 00:05:05.800
I should also caveat this by
saying that in some cases,

00:05:05.800 --> 00:05:08.570
you can solve some of these
problems in multiple ways.

00:05:08.570 --> 00:05:11.295
But one framework
that you can use

00:05:11.295 --> 00:05:12.670
when thinking
about what problems

00:05:12.670 --> 00:05:14.980
you can solve for
your specific business

00:05:14.980 --> 00:05:17.020
is to start with what
kind of data's available.

00:05:17.020 --> 00:05:18.711
If you have high-quality,
labelled data,

00:05:18.711 --> 00:05:20.710
you can do something
called supervised learning.

00:05:20.710 --> 00:05:22.780
And supervised learning
kind of has two buckets.

00:05:22.780 --> 00:05:24.610
The first is classification--

00:05:24.610 --> 00:05:26.750
identify an image.

00:05:26.750 --> 00:05:28.480
The second is regression--

00:05:28.480 --> 00:05:30.100
for the game
developers in the room,

00:05:30.100 --> 00:05:33.310
maybe forecasting
LTV or predicting

00:05:33.310 --> 00:05:36.970
the likelihood that a given
transaction is fraudulent.

00:05:36.970 --> 00:05:40.480
Even if you don't have
high-quality, labelled data,

00:05:40.480 --> 00:05:43.300
you can still conduct what
we call unsupervised learning

00:05:43.300 --> 00:05:44.110
tasks.

00:05:44.110 --> 00:05:47.920
This is essentially where
the model will infer patterns

00:05:47.920 --> 00:05:49.460
or commonalities in data.

00:05:49.460 --> 00:05:51.460
And you can use clustering
or association models

00:05:51.460 --> 00:05:54.100
to do things like
segment your customers

00:05:54.100 --> 00:05:56.920
or determine which product
you want to cross-sell

00:05:56.920 --> 00:05:59.007
at the time of purchase.

00:05:59.007 --> 00:06:01.090
So I'm not going to spend
too much more time here.

00:06:01.090 --> 00:06:02.673
Montana has some
really great examples

00:06:02.673 --> 00:06:05.140
that he's going to
share in about a minute.

00:06:05.140 --> 00:06:07.777
And it's easy to get started.

00:06:07.777 --> 00:06:10.360
Like I said, there are plenty
of pre-trained and off-the-shelf

00:06:10.360 --> 00:06:12.776
models you can use using the
Google Cloud Machine Learning

00:06:12.776 --> 00:06:14.800
API, things like vision,
speech, translation,

00:06:14.800 --> 00:06:16.060
and natural language.

00:06:16.060 --> 00:06:18.880
I'd also encourage everyone
to check out TensorFlow.

00:06:18.880 --> 00:06:21.940
TensorFlow is the
best-in-class and most popular

00:06:21.940 --> 00:06:24.310
open source machine
learning library.

00:06:24.310 --> 00:06:26.320
It's the same code
that we use internally

00:06:26.320 --> 00:06:29.110
for most of our projects
internally at Google.

00:06:29.110 --> 00:06:31.102
Finally, since this
a mobile audience,

00:06:31.102 --> 00:06:32.560
I wanted to let
you know that we're

00:06:32.560 --> 00:06:35.060
making mobile-specific
investments as well.

00:06:35.060 --> 00:06:37.300
So three quick plugs--

00:06:37.300 --> 00:06:39.430
the first is that
with MR1, which

00:06:39.430 --> 00:06:42.550
is coming later this year, we'll
be announcing the Neural Nets

00:06:42.550 --> 00:06:45.680
API, which enables hardware
acceleration on the device.

00:06:45.680 --> 00:06:47.680
The second is TensorFlow
Lite, something

00:06:47.680 --> 00:06:49.540
that we announced at
Google I/O this year,

00:06:49.540 --> 00:06:51.831
we're also hoping to launch
before the end of the year.

00:06:51.831 --> 00:06:54.660
TensorFlow Lite is
essentially TensorFlow

00:06:54.660 --> 00:06:56.860
that's optimized for
smartphone runtimes.

00:06:56.860 --> 00:06:59.290
And then third, we're working
on a set of top-level APIs

00:06:59.290 --> 00:07:02.500
that make common machine
learning tasks easier.

00:07:02.500 --> 00:07:05.290
I'd also like to say if anyone
is thinking about machine

00:07:05.290 --> 00:07:07.040
learning at all, we
have Brahim, who's

00:07:07.040 --> 00:07:09.401
our PM for machine
learning at Android,

00:07:09.401 --> 00:07:10.900
as well as a number
of our engineers

00:07:10.900 --> 00:07:12.430
that are going to be
in the classroom later.

00:07:12.430 --> 00:07:13.450
Please, please go find them.

00:07:13.450 --> 00:07:14.890
They'd love to hear
about what problems

00:07:14.890 --> 00:07:16.240
you're trying to
solve and answer

00:07:16.240 --> 00:07:17.406
any questions that you have.

00:07:20.260 --> 00:07:24.190
So with that, I'd like
to introduce Montana,

00:07:24.190 --> 00:07:25.990
who's going to talk
about how Instacart

00:07:25.990 --> 00:07:27.644
uses machine learning.

00:07:27.644 --> 00:07:30.983
[APPLAUSE]

00:07:34.800 --> 00:07:36.630
MONTANA LOW: Thanks, Kevin.

00:07:36.630 --> 00:07:38.240
So I'm always
impressed when somebody

00:07:38.240 --> 00:07:43.910
can summarize a very complex
topic in three easy steps.

00:07:43.910 --> 00:07:47.240
My artistic friend did one
better when I asked them,

00:07:47.240 --> 00:07:49.790
how do you draw an owl?

00:07:49.790 --> 00:07:51.410
Well, they said,
first, you start off

00:07:51.410 --> 00:07:53.360
with a circle and
another circle.

00:07:53.360 --> 00:07:55.460
And this is sort of
the head and the body.

00:07:55.460 --> 00:07:57.366
And then you just
draw the damn owl.

00:07:57.366 --> 00:07:59.696
[LAUGHTER]

00:07:59.696 --> 00:08:03.410
Well, I'm going to try and break
this down, those three steps,

00:08:03.410 --> 00:08:06.830
into quite a few more as we
go through several high-level

00:08:06.830 --> 00:08:09.690
overviews of when we
use supervised learning

00:08:09.690 --> 00:08:12.310
in Instacart, when we use
unsupervised learning.

00:08:12.310 --> 00:08:13.910
And at the end of
the talk, we'll

00:08:13.910 --> 00:08:17.510
go through a detailed
feature development use case.

00:08:17.510 --> 00:08:21.470
And we'll talk about how
we start and how we finish.

00:08:21.470 --> 00:08:25.040
To begin, I'd like to give you
some context of what Instacart

00:08:25.040 --> 00:08:28.520
is, how our business works,
so that you understand

00:08:28.520 --> 00:08:29.990
why we would use
machine learning

00:08:29.990 --> 00:08:32.150
to solve any problem we have.

00:08:32.150 --> 00:08:34.880
We deliver groceries from
the stores you love in

00:08:34.880 --> 00:08:38.120
as little as an hour.

00:08:38.120 --> 00:08:41.809
We connect personal
shoppers to our customers

00:08:41.809 --> 00:08:44.840
so that they can deliver the
service those customers expect

00:08:44.840 --> 00:08:46.440
in real time.

00:08:46.440 --> 00:08:48.950
We also partner with
hundreds of retailers

00:08:48.950 --> 00:08:52.040
around the country so that we
can shop out of their stores.

00:08:52.040 --> 00:08:53.750
We can provide discount prices.

00:08:53.750 --> 00:08:56.300
That way, we have
deep integrations

00:08:56.300 --> 00:09:00.920
with their product catalogs
we host on our website.

00:09:00.920 --> 00:09:03.680
And the fourth party
in this marketplace

00:09:03.680 --> 00:09:05.810
are the actual
product manufacturers.

00:09:05.810 --> 00:09:08.750
We partner with them to give our
customers discounts, coupons,

00:09:08.750 --> 00:09:11.300
and other incentives
on the website.

00:09:11.300 --> 00:09:16.070
So at the heart of this is a ton
of data passing back and forth

00:09:16.070 --> 00:09:17.510
between a lot of parties.

00:09:17.510 --> 00:09:19.130
And what really
drives this engine

00:09:19.130 --> 00:09:21.170
in terms of growth
and efficiency

00:09:21.170 --> 00:09:22.730
are deep machine
learning models.

00:09:25.572 --> 00:09:27.780
I'm going to walk you through
the customer experience

00:09:27.780 --> 00:09:29.260
to begin.

00:09:29.260 --> 00:09:32.670
When they get to the
app, they choose a store.

00:09:32.670 --> 00:09:34.770
They shop for their groceries.

00:09:34.770 --> 00:09:36.717
They go ahead and
check out in the app.

00:09:36.717 --> 00:09:38.550
We have all their payment
information saved.

00:09:38.550 --> 00:09:41.310
So it's real easy.

00:09:41.310 --> 00:09:44.430
They select a delivery time
that's convenient for them.

00:09:44.430 --> 00:09:47.130
And after that, we've
got it in the bag.

00:09:47.130 --> 00:09:49.800
I promise that's the
only pun in this talk--

00:09:49.800 --> 00:09:51.480
[LAUGHTER]

00:09:51.480 --> 00:09:53.850
--I think.

00:09:53.850 --> 00:09:56.660
On the other side of the
transaction, there's a shopper.

00:09:56.660 --> 00:10:00.100
The shopper lets us know when
they're available to do work.

00:10:00.100 --> 00:10:03.040
They'll acknowledge an
order as it comes in.

00:10:03.040 --> 00:10:07.250
They'll go pick all of the
groceries for that customer.

00:10:07.250 --> 00:10:10.480
We make sure that they scan
every item for accuracy.

00:10:10.480 --> 00:10:12.730
This is actually a step
that improves their speed

00:10:12.730 --> 00:10:15.960
because it's easier for your
phone to tell you yes or no

00:10:15.960 --> 00:10:19.670
when you're trying to
decide 2%, 1%, light, whole.

00:10:19.670 --> 00:10:22.270
All the labels look the same.

00:10:22.270 --> 00:10:25.230
So this is a nice improvement.

00:10:25.230 --> 00:10:27.120
And then the shopper
actually delivers it

00:10:27.120 --> 00:10:29.790
to the customer's address.

00:10:29.790 --> 00:10:32.580
We don't discriminate
between cats and dogs.

00:10:32.580 --> 00:10:36.630
We're an equal pet service.

00:10:36.630 --> 00:10:39.570
But I'd like to show you an
example of one of our teams

00:10:39.570 --> 00:10:42.660
that uses machine learning
pretty extensively.

00:10:42.660 --> 00:10:44.700
It's our search
and discovery team,

00:10:44.700 --> 00:10:49.530
which powers our storefront
that all of our customers use.

00:10:49.530 --> 00:10:52.620
If you think about search when
you're dealing with a product

00:10:52.620 --> 00:10:56.250
catalog, very minor
changes in search terms

00:10:56.250 --> 00:10:58.590
should have a completely
different results page.

00:10:58.590 --> 00:11:00.390
What you see on a
milk results page

00:11:00.390 --> 00:11:02.370
should be completely different
than a chocolate milk results

00:11:02.370 --> 00:11:04.828
page and should be complete
different than a milk chocolate

00:11:04.828 --> 00:11:06.240
results page.

00:11:06.240 --> 00:11:09.790
That's hard if you're
just using text.

00:11:09.790 --> 00:11:11.910
So one reason we
use machine learning

00:11:11.910 --> 00:11:17.010
is to extract more meaning and
provide more relevant results.

00:11:20.430 --> 00:11:23.010
The beginning of any
machine learning problem

00:11:23.010 --> 00:11:27.150
is to break down all of your
input into specific features,

00:11:27.150 --> 00:11:30.390
in this case, the features
of all of our product.

00:11:30.390 --> 00:11:31.950
Is it USDA?

00:11:31.950 --> 00:11:33.180
Is it organic?

00:11:33.180 --> 00:11:34.730
What's the fat content?

00:11:34.730 --> 00:11:36.470
What's the size
of the container?

00:11:36.470 --> 00:11:38.010
What's the color of the image?

00:11:38.010 --> 00:11:40.600
All of these become
features of products.

00:11:40.600 --> 00:11:43.830
And so we don't really think
of products as an ID or a name.

00:11:43.830 --> 00:11:47.040
But they're a huge collection
of potentially dozens

00:11:47.040 --> 00:11:49.710
or more of these features.

00:11:49.710 --> 00:11:52.020
And the important thing
about all of these features

00:11:52.020 --> 00:11:54.960
is that they can be
quantified numerically.

00:11:54.960 --> 00:11:58.200
For color, we can assign
red, green, blue numbers.

00:11:58.200 --> 00:12:01.080
Machine learning models
only work with numbers.

00:12:01.080 --> 00:12:05.100
Fundamentally, they're
arithmetic all the way down.

00:12:05.100 --> 00:12:09.480
So if we can quantify milk
in a series of features,

00:12:09.480 --> 00:12:12.810
they're embedded as
numbers in our models.

00:12:12.810 --> 00:12:16.610
Then we can actually apply
really advanced mathematics

00:12:16.610 --> 00:12:18.270
to get better search results.

00:12:21.640 --> 00:12:24.790
So the way that we actually
translate a search ranking

00:12:24.790 --> 00:12:27.610
problem into a supervised
machine learning problem

00:12:27.610 --> 00:12:32.290
is we use the signal of
when a user adds a search

00:12:32.290 --> 00:12:34.000
result to their cart.

00:12:34.000 --> 00:12:37.000
If they actually decide to buy
something that we show them

00:12:37.000 --> 00:12:39.640
when they search for
milk, that's a supervisor

00:12:39.640 --> 00:12:41.694
saying, this is the
correct search result.

00:12:41.694 --> 00:12:43.360
There's also an
implicit negative signal

00:12:43.360 --> 00:12:45.760
there of everything else
we show them on the page

00:12:45.760 --> 00:12:49.160
isn't quite as milky to them.

00:12:49.160 --> 00:12:52.960
So doing this with
libraries like TensorFlow

00:12:52.960 --> 00:12:57.400
that Kevin pointed out, we can
really improve the situation.

00:12:57.400 --> 00:13:01.150
And what's even cooler is that
as we launch new retailers

00:13:01.150 --> 00:13:03.640
and add hundreds of new
products to our catalog

00:13:03.640 --> 00:13:06.550
every single day,
we can identify

00:13:06.550 --> 00:13:09.070
what new products
will also be highly

00:13:09.070 --> 00:13:12.100
ranked search results
immediately because we look

00:13:12.100 --> 00:13:14.200
at these products in
terms of their features,

00:13:14.200 --> 00:13:17.020
not in terms of any
individual products history.

00:13:17.020 --> 00:13:19.780
So the fact that this
product has similar features

00:13:19.780 --> 00:13:22.360
to other things that have
ranked highly for milk

00:13:22.360 --> 00:13:24.760
means this product should
probably rank highly for milk

00:13:24.760 --> 00:13:25.280
as well.

00:13:31.850 --> 00:13:34.340
Once you've built one
machine learning model

00:13:34.340 --> 00:13:36.520
and you've got your
data in a good shape,

00:13:36.520 --> 00:13:39.800
then you can start to think
about all of the other signals

00:13:39.800 --> 00:13:40.570
you have.

00:13:40.570 --> 00:13:42.430
One of the super
powers of deep learning

00:13:42.430 --> 00:13:44.000
is called transfer learning.

00:13:44.000 --> 00:13:47.470
You can take the understanding
that one model has developed--

00:13:47.470 --> 00:13:49.540
in this case, our
search results model.

00:13:49.540 --> 00:13:54.310
It understands that these
particular features are closely

00:13:54.310 --> 00:13:57.650
related to the term
"milk," or in this case,

00:13:57.650 --> 00:13:59.920
these two sets of
features, the ones that

00:13:59.920 --> 00:14:02.470
represent Coca-Cola and
Pepsi, are closely related

00:14:02.470 --> 00:14:04.570
to the term "cola."

00:14:04.570 --> 00:14:07.700
In terms of their features,
they're very similar.

00:14:07.700 --> 00:14:12.740
We could subtract them and
get 0 in mathematical sense.

00:14:12.740 --> 00:14:15.400
But what we see when we
have Coca-Cola and Pepsi

00:14:15.400 --> 00:14:16.990
is that people
almost never add them

00:14:16.990 --> 00:14:19.070
to the cart at the same time.

00:14:19.070 --> 00:14:22.900
So this is another signal that
even though these two products

00:14:22.900 --> 00:14:24.760
have incredibly
similar features,

00:14:24.760 --> 00:14:26.980
they're never added to
the cart at the same time,

00:14:26.980 --> 00:14:28.300
making them competitive.

00:14:28.300 --> 00:14:29.950
So now we can
start merchandising

00:14:29.950 --> 00:14:30.970
all of our website.

00:14:30.970 --> 00:14:32.470
And when people are
looking at Coke,

00:14:32.470 --> 00:14:34.480
they should also see
Pepsi when people

00:14:34.480 --> 00:14:40.270
are looking at all of these
different types of items

00:14:40.270 --> 00:14:41.530
that are similar.

00:14:41.530 --> 00:14:46.810
We can take another signal, very
similar, but it's the opposite.

00:14:46.810 --> 00:14:48.580
In this case, peanut
butter and jelly

00:14:48.580 --> 00:14:51.260
are often added to the
cart at the same time.

00:14:51.260 --> 00:14:53.740
But they have very
dissimilar features.

00:14:53.740 --> 00:14:56.770
So using this
knowledge we have now

00:14:56.770 --> 00:15:00.850
about what features are
similar and how they work,

00:15:00.850 --> 00:15:02.710
we can recommend products.

00:15:02.710 --> 00:15:04.840
After we see you add
peanut butter to your cart,

00:15:04.840 --> 00:15:06.490
then we can, say,
hey you probably

00:15:06.490 --> 00:15:07.804
are forgetting the jelly.

00:15:07.804 --> 00:15:09.220
And that's a
different application

00:15:09.220 --> 00:15:12.490
than organizing our
storefront in the beginning.

00:15:12.490 --> 00:15:17.380
All of this requires that we
collect the data from the user,

00:15:17.380 --> 00:15:19.360
acting as a supervisor
for our machine

00:15:19.360 --> 00:15:22.580
learning algorithms that are
continuously running and taking

00:15:22.580 --> 00:15:23.720
in new data over time.

00:15:27.336 --> 00:15:28.710
I'd like to move
on to an example

00:15:28.710 --> 00:15:30.840
of unsupervised learning
that Kevin mentioned.

00:15:30.840 --> 00:15:32.640
It's called clustering.

00:15:32.640 --> 00:15:34.410
In this case, we
don't necessarily

00:15:34.410 --> 00:15:35.560
start with the answers.

00:15:35.560 --> 00:15:38.100
We don't have somebody
training our algorithm

00:15:38.100 --> 00:15:39.780
with the correct answer.

00:15:39.780 --> 00:15:41.100
We start with questions.

00:15:41.100 --> 00:15:44.340
We want to know more about who
our users are, what they want,

00:15:44.340 --> 00:15:45.840
what motivates them.

00:15:45.840 --> 00:15:48.210
Some people in the past
would use demographic data

00:15:48.210 --> 00:15:50.130
to understand their user base.

00:15:50.130 --> 00:15:52.870
But that's sort of
irrelevant in many cases.

00:15:52.870 --> 00:15:55.890
It doesn't really matter how
old you are or what sex you are

00:15:55.890 --> 00:15:57.630
or what age you are
when you're talking

00:15:57.630 --> 00:16:01.830
about behavior-driven
development.

00:16:01.830 --> 00:16:05.640
What we want to do is we want to
actually segment our users not

00:16:05.640 --> 00:16:08.160
by these superficial
qualities, but instead

00:16:08.160 --> 00:16:13.790
by how they actually use the
app and derive value from it.

00:16:13.790 --> 00:16:15.720
It starts just the same way.

00:16:15.720 --> 00:16:18.180
We break our users down
into a set of features.

00:16:18.180 --> 00:16:20.730
It might be what platform are
they visiting the site on,

00:16:20.730 --> 00:16:23.040
what time of day do
they come to the site.

00:16:23.040 --> 00:16:26.150
A funny one is aol.com
email addresses

00:16:26.150 --> 00:16:29.760
are significantly different
than gmail.com email addresses.

00:16:29.760 --> 00:16:31.740
Those users tend to
engage with the site

00:16:31.740 --> 00:16:34.690
differently at different
times of the day.

00:16:34.690 --> 00:16:38.220
And so even at sign-up time,
we know a lot about a user

00:16:38.220 --> 00:16:41.310
and how they're going to behave.

00:16:41.310 --> 00:16:45.030
We can use an unsupervised
learning model

00:16:45.030 --> 00:16:47.100
to begin to cluster these users.

00:16:47.100 --> 00:16:49.200
And so it will actually
begin to pull out

00:16:49.200 --> 00:16:51.780
groups of these people.

00:16:51.780 --> 00:16:53.807
In this case, I've
asked for three groups

00:16:53.807 --> 00:16:55.890
from the-- and that's the
only parameter I specify

00:16:55.890 --> 00:16:59.110
for the model because I want
to maybe make a small, medium,

00:16:59.110 --> 00:17:00.840
and a large version
of my product.

00:17:00.840 --> 00:17:03.000
And I want to decide
what should those three

00:17:03.000 --> 00:17:05.339
versions of my product be.

00:17:05.339 --> 00:17:07.440
In this case, we've
got group one, which

00:17:07.440 --> 00:17:10.829
are green people, group two,
which are orange people,

00:17:10.829 --> 00:17:13.890
and group three,
which are blue people.

00:17:13.890 --> 00:17:16.770
To begin with, the
unsupervised model

00:17:16.770 --> 00:17:18.599
has just told me
that blue people

00:17:18.599 --> 00:17:19.890
are very much like blue people.

00:17:19.890 --> 00:17:21.599
Orange people are very
much like orange people.

00:17:21.599 --> 00:17:23.880
And green people are very
much like green people.

00:17:23.880 --> 00:17:26.540
But that doesn't really
help me too much.

00:17:26.540 --> 00:17:28.980
What I need to then do
is do some deep analysis

00:17:28.980 --> 00:17:31.830
on the green people
versus the orange people

00:17:31.830 --> 00:17:36.120
versus the blue people versus
our normal overall global user

00:17:36.120 --> 00:17:37.700
base.

00:17:37.700 --> 00:17:39.450
And what I might find
is that green people

00:17:39.450 --> 00:17:41.370
tend for organic food.

00:17:41.370 --> 00:17:44.490
Orange people tend
to prefer spicy food.

00:17:44.490 --> 00:17:49.620
And blue people really love
ice cream late at night

00:17:49.620 --> 00:17:50.470
with a frozen pizza.

00:17:53.410 --> 00:17:56.140
So that's one way that we
can use machine learning

00:17:56.140 --> 00:17:58.210
to plan how we're
going to build products

00:17:58.210 --> 00:18:04.210
that people are going to engage
with, even before we launch.

00:18:04.210 --> 00:18:06.790
I'd like to go through
a detailed analysis

00:18:06.790 --> 00:18:10.360
on what our product
development looks like.

00:18:10.360 --> 00:18:12.850
This is a case for
picking groceries.

00:18:12.850 --> 00:18:14.760
We do a lot of
picking groceries.

00:18:14.760 --> 00:18:18.940
It's where a huge
portion of time goes.

00:18:18.940 --> 00:18:23.050
We have this enormous catalog
that shoppers are handed

00:18:23.050 --> 00:18:25.300
in a single shopping list.

00:18:25.300 --> 00:18:28.720
They go out to all
these different stores

00:18:28.720 --> 00:18:31.160
that they may never
have been to before.

00:18:31.160 --> 00:18:34.900
And eventually, they
will complete the order.

00:18:34.900 --> 00:18:38.840
If we can save 10 seconds, 20
seconds per order, at scale,

00:18:38.840 --> 00:18:41.650
this becomes hugely
valuable to the company.

00:18:41.650 --> 00:18:44.602
So we've looked at lots of
ways to improve their speed.

00:18:44.602 --> 00:18:46.060
I've mentioned the
bar code scanner

00:18:46.060 --> 00:18:48.670
was one incidental metric.

00:18:48.670 --> 00:18:50.830
But when we do these
things at scale,

00:18:50.830 --> 00:18:54.280
it becomes very
difficult. We have

00:18:54.280 --> 00:18:57.130
hundreds of different
retailers that we partner with,

00:18:57.130 --> 00:19:00.220
millions of products,
thousands of stores.

00:19:00.220 --> 00:19:03.820
Actually organizing the data on
how every single store is laid

00:19:03.820 --> 00:19:07.120
out is incredibly challenging.

00:19:07.120 --> 00:19:10.930
So we go to our CEO after
he says, speed up picking.

00:19:10.930 --> 00:19:12.640
I said, well, if
we could just be

00:19:12.640 --> 00:19:14.414
like some of our
competitors, why don't we

00:19:14.414 --> 00:19:15.580
just build their warehouses?

00:19:15.580 --> 00:19:16.720
And then we'll know
where everything is.

00:19:16.720 --> 00:19:18.210
And we can have robots do this.

00:19:18.210 --> 00:19:19.730
And it'll be super fast.

00:19:19.730 --> 00:19:21.490
Apoorva said no.

00:19:21.490 --> 00:19:23.170
That's not our business model.

00:19:23.170 --> 00:19:24.430
We don't build warehouses.

00:19:24.430 --> 00:19:26.860
We shop out of
stores people like.

00:19:26.860 --> 00:19:28.240
So we said, OK.

00:19:28.240 --> 00:19:32.830
Well, maybe we can get more data
about each individual store.

00:19:32.830 --> 00:19:35.790
And maybe we can sort the
shopping lists that way.

00:19:35.790 --> 00:19:37.630
And we can speed
up shopping time.

00:19:37.630 --> 00:19:40.510
So we do a little weekend
hackathon project.

00:19:40.510 --> 00:19:43.330
And it's a little
Rails app that lets

00:19:43.330 --> 00:19:49.270
us take where baby accessories
are and put them on an aisle

00:19:49.270 --> 00:19:50.470
number in the store.

00:19:50.470 --> 00:19:53.070
And then some shift
lead in a store

00:19:53.070 --> 00:19:55.690
can drag and drop
all of our categories

00:19:55.690 --> 00:19:58.840
in order, like they say
aisle 15 comes after aisle 14

00:19:58.840 --> 00:20:00.280
after aisle 13.

00:20:00.280 --> 00:20:03.186
And then when we ship a
shopping list this way,

00:20:03.186 --> 00:20:04.810
we can put things in
the order that has

00:20:04.810 --> 00:20:06.070
been specified at that store.

00:20:09.990 --> 00:20:13.080
This is our baseline
control, where we started.

00:20:13.080 --> 00:20:15.640
If you notice, it goes
up into the right,

00:20:15.640 --> 00:20:17.130
which is generally good.

00:20:17.130 --> 00:20:19.740
In this case, what
that means is as we

00:20:19.740 --> 00:20:24.090
add more items to the order,
the individual time per item

00:20:24.090 --> 00:20:25.410
goes down.

00:20:25.410 --> 00:20:27.642
So it's an improvement--
that if you're

00:20:27.642 --> 00:20:29.100
shopping for 10
items in the store,

00:20:29.100 --> 00:20:30.740
you have to walk
around the whole store

00:20:30.740 --> 00:20:32.040
to only get 10 items.

00:20:32.040 --> 00:20:33.990
If you're shopping for
50 items in a store,

00:20:33.990 --> 00:20:36.310
you walk around the whole
store still only one time.

00:20:36.310 --> 00:20:37.840
But now you've got 50 items.

00:20:37.840 --> 00:20:40.140
So we've known for a
long time that this

00:20:40.140 --> 00:20:41.334
is a key to our business.

00:20:41.334 --> 00:20:42.750
What we haven't
known is if we can

00:20:42.750 --> 00:20:45.000
change the shape of this curve.

00:20:45.000 --> 00:20:47.250
When we launched
that experiment,

00:20:47.250 --> 00:20:49.920
we actually showed that
there's a significant slope

00:20:49.920 --> 00:20:51.320
improvement.

00:20:51.320 --> 00:20:54.390
We're very excited.

00:20:54.390 --> 00:20:57.806
Unfortunately, this
is too expensive.

00:20:57.806 --> 00:21:00.060
Our CEO says this
works in one store.

00:21:00.060 --> 00:21:00.930
That's great.

00:21:00.930 --> 00:21:03.180
But next week, when they
move everything around again,

00:21:03.180 --> 00:21:05.500
we're going to have to
go do this over again.

00:21:05.500 --> 00:21:08.400
And by the way, we're
growing insanely fast.

00:21:08.400 --> 00:21:13.050
So I can't see us sparing
the labor hours to do this.

00:21:13.050 --> 00:21:15.331
So we say, OK, fine, Apoorva.

00:21:15.331 --> 00:21:17.080
Maybe there's something
smarter we can do.

00:21:17.080 --> 00:21:18.990
We have phones with GPS on them.

00:21:18.990 --> 00:21:21.840
Shoppers are in these
stores eight hours a day.

00:21:21.840 --> 00:21:24.310
They're picking
hundreds of times a day.

00:21:24.310 --> 00:21:28.085
Maybe we can actually sort
of map implicitly using GPS.

00:21:28.085 --> 00:21:30.210
We know the time they pick
the item because they're

00:21:30.210 --> 00:21:31.710
scanning the bar code.

00:21:31.710 --> 00:21:35.490
We know relatively where they
are in this store with GPS.

00:21:35.490 --> 00:21:38.730
If we see enough picks on
that product, over time,

00:21:38.730 --> 00:21:40.550
we can start to map
the whole store.

00:21:40.550 --> 00:21:44.670
And we can start to build up
a detailed analysis of where

00:21:44.670 --> 00:21:48.180
the baby diapers
are in this store.

00:21:48.180 --> 00:21:50.940
Once we have a map like
this, for any given order,

00:21:50.940 --> 00:21:52.680
we can plot the dots on the map.

00:21:52.680 --> 00:21:55.470
We can solve the traveling
salesman problem.

00:21:55.470 --> 00:21:57.890
We can actually solve
it for small orders.

00:21:57.890 --> 00:22:02.100
We use heuristic approximations
for large orders.

00:22:02.100 --> 00:22:07.710
And the results for that were
exciting, but disappointing

00:22:07.710 --> 00:22:10.620
because we actually saw
significant improvement

00:22:10.620 --> 00:22:11.340
over baseline.

00:22:11.340 --> 00:22:13.320
And now we're not paying
anybody to do this.

00:22:13.320 --> 00:22:15.850
Now this is implicit data
that we get for free.

00:22:15.850 --> 00:22:17.700
It's just an algorithm running.

00:22:17.700 --> 00:22:20.100
But we know that it's not
really as good as what

00:22:20.100 --> 00:22:21.610
the humans were able to do.

00:22:21.610 --> 00:22:23.460
There's some deficiencies
in this algorithm

00:22:23.460 --> 00:22:25.140
that-- it doesn't
know where walls are.

00:22:25.140 --> 00:22:29.400
So it might ask you to
walk through an aisle.

00:22:29.400 --> 00:22:34.510
And so we weren't quite
ready to stop there.

00:22:34.510 --> 00:22:36.720
We started looking
around for, is there

00:22:36.720 --> 00:22:39.495
tech that will give us more
accurate mapping information?

00:22:39.495 --> 00:22:41.610
We're really
excited about things

00:22:41.610 --> 00:22:43.600
like Google Tango coming out.

00:22:43.600 --> 00:22:47.490
A lot of this AR is
going to be big for us.

00:22:47.490 --> 00:22:49.740
It's going to really change
the way we do things.

00:22:49.740 --> 00:22:52.110
But it's not really
ubiquitous yet.

00:22:52.110 --> 00:22:54.240
So we can't expect
all of our shoppers

00:22:54.240 --> 00:22:59.520
to go buy brand new
devices to shop with us.

00:22:59.520 --> 00:23:04.470
Once we've exhausted all of
the options, what do we do?

00:23:04.470 --> 00:23:06.565
We smear some machine
learning on the problem

00:23:06.565 --> 00:23:07.440
and see what happens.

00:23:10.330 --> 00:23:12.210
So in any machine
learning problem,

00:23:12.210 --> 00:23:14.070
you need a formal
problem statement.

00:23:14.070 --> 00:23:16.920
We like to do our problem
statements in emoji.

00:23:16.920 --> 00:23:19.770
In this case, you
have 10 products

00:23:19.770 --> 00:23:23.130
of some corn to coffee.

00:23:23.130 --> 00:23:25.200
And the goal of this
machine learning algorithm

00:23:25.200 --> 00:23:30.540
is to put those products
in the correct sequence

00:23:30.540 --> 00:23:34.440
so that then we can
predict the sequence.

00:23:34.440 --> 00:23:39.210
For a specific instance
stated mathematically,

00:23:39.210 --> 00:23:41.220
the probability
that the next item

00:23:41.220 --> 00:23:45.540
is going to be the cookie given
that the last item is bread,

00:23:45.540 --> 00:23:47.190
and your candidates
are the items that

00:23:47.190 --> 00:23:51.572
remain to be shopped,
is the function

00:23:51.572 --> 00:23:54.030
that we're trying to learn with
the machine learning model.

00:23:57.340 --> 00:24:00.100
We use a TensorFlow
architecture to build

00:24:00.100 --> 00:24:02.259
this machine learning model.

00:24:02.259 --> 00:24:04.300
In this case, you can see
that our model actually

00:24:04.300 --> 00:24:06.400
takes features from
several different things.

00:24:06.400 --> 00:24:09.112
It considers what the features
of the shopper that's shopping

00:24:09.112 --> 00:24:11.320
is, how experienced are
they, how long have they been

00:24:11.320 --> 00:24:14.900
on shift, how many refunds they
typically do during an order,

00:24:14.900 --> 00:24:17.260
how quickly do they
typically shop an order.

00:24:17.260 --> 00:24:19.060
It looks at the
warehouse location

00:24:19.060 --> 00:24:21.280
that they're at
so that it can say

00:24:21.280 --> 00:24:24.280
how big is this place, how
confusingly is it laid out,

00:24:24.280 --> 00:24:26.530
do they typically have
things that are out of stock

00:24:26.530 --> 00:24:28.060
that they haven't told us about.

00:24:28.060 --> 00:24:30.550
It looks at the previous
item that they just picked,

00:24:30.550 --> 00:24:32.810
which in this case is bread.

00:24:32.810 --> 00:24:37.030
And it looks at the next
item that they might pick.

00:24:37.030 --> 00:24:39.490
One really important thing
that I touched on earlier

00:24:39.490 --> 00:24:41.320
is this notion of embeddings.

00:24:41.320 --> 00:24:43.840
When you have
features for a product

00:24:43.840 --> 00:24:46.870
that are numerically
represented, the model--

00:24:46.870 --> 00:24:51.550
as it's incrementally updated,
it embeds that set of features

00:24:51.550 --> 00:24:52.930
into itself.

00:24:52.930 --> 00:24:54.820
And so, in this
case, we actually

00:24:54.820 --> 00:24:56.350
have two products
that are coming

00:24:56.350 --> 00:24:57.820
into this model as features.

00:24:57.820 --> 00:24:59.990
TensorFlow lets us
share that embedding.

00:24:59.990 --> 00:25:03.220
So the model only has to learn
about products one time, which

00:25:03.220 --> 00:25:04.852
doubles the efficiency.

00:25:07.950 --> 00:25:10.020
The goal of this model
is to actually make

00:25:10.020 --> 00:25:14.400
a prediction of whether
the chocolate bar will

00:25:14.400 --> 00:25:17.490
be the next item picked
given that bread was

00:25:17.490 --> 00:25:20.610
the previous item picked
there at this retailer

00:25:20.610 --> 00:25:23.370
with this shopper.

00:25:23.370 --> 00:25:26.950
With enough examples, we can
actually train this model

00:25:26.950 --> 00:25:28.170
and learn this function.

00:25:30.890 --> 00:25:33.570
We're going to call this thing,
this model that we've just

00:25:33.570 --> 00:25:36.060
trained, the score generator.

00:25:36.060 --> 00:25:38.580
And we're going to set it
up-- the top right-hand corner

00:25:38.580 --> 00:25:41.100
for now--

00:25:41.100 --> 00:25:43.320
and go a little
bit deeper in how

00:25:43.320 --> 00:25:48.090
we use this score generator
to actually sequence an order.

00:25:48.090 --> 00:25:52.140
We generate a score
for every product

00:25:52.140 --> 00:25:53.730
given the input features.

00:25:53.730 --> 00:25:56.370
And then we do that for
every remaining product

00:25:56.370 --> 00:25:59.827
inside the availability set.

00:25:59.827 --> 00:26:01.410
You can see that
it's going to predict

00:26:01.410 --> 00:26:04.350
several different scores.

00:26:04.350 --> 00:26:06.720
Some things are very
probable to be picked next.

00:26:06.720 --> 00:26:10.050
Some things are less
probable to be picked next.

00:26:10.050 --> 00:26:12.060
We take the most
likely one of that.

00:26:12.060 --> 00:26:16.470
Softmax is a fancy
mathematical term for that.

00:26:16.470 --> 00:26:17.890
We get a prediction.

00:26:17.890 --> 00:26:19.540
And we actually
use cross-entropy,

00:26:19.540 --> 00:26:23.100
which is a way to teach the
model that these answers are

00:26:23.100 --> 00:26:26.130
constrained to the available
ones you're looking at now.

00:26:26.130 --> 00:26:29.130
There are millions of other
products in our catalog.

00:26:29.130 --> 00:26:31.470
I don't know if you're
familiar with "Silicon Valley,"

00:26:31.470 --> 00:26:32.950
if anybody watches that.

00:26:32.950 --> 00:26:36.900
The hot dog/no hot dog
machine learning classifier--

00:26:36.900 --> 00:26:39.000
he couldn't actually
make it universal.

00:26:39.000 --> 00:26:40.860
He couldn't train it
so that it can actually

00:26:40.860 --> 00:26:42.640
do more than one thing.

00:26:42.640 --> 00:26:46.080
Our classifier actually
can consider all things

00:26:46.080 --> 00:26:48.030
because it's a single
model that represents

00:26:48.030 --> 00:26:51.060
all stores, all
products, confined

00:26:51.060 --> 00:26:54.630
to the very small list of
available products remaining

00:26:54.630 --> 00:26:55.860
in your shopping list.

00:26:55.860 --> 00:26:58.740
That's the
cross-entropy function--

00:26:58.740 --> 00:27:01.230
gives us that
little extra nudge.

00:27:04.550 --> 00:27:08.720
And so given that model, we can
now actually make predictions

00:27:08.720 --> 00:27:12.110
every step of the way that corn
will be the most likely item

00:27:12.110 --> 00:27:13.370
picked first.

00:27:13.370 --> 00:27:14.870
Given that they've
just picked corn,

00:27:14.870 --> 00:27:16.910
what will be the next
item that they pick?

00:27:16.910 --> 00:27:18.950
With all the rest
of these, we repeat

00:27:18.950 --> 00:27:23.120
that until we've actually
exhausted the entire list

00:27:23.120 --> 00:27:24.560
of available products.

00:27:24.560 --> 00:27:27.560
And then we can show
that to the shoppers.

00:27:27.560 --> 00:27:30.080
So the question is, this
sounds really complicated,

00:27:30.080 --> 00:27:32.880
does it actually work?

00:27:32.880 --> 00:27:36.800
And the answer is smashingly.

00:27:36.800 --> 00:27:40.490
We're very, very excited
with the results here.

00:27:40.490 --> 00:27:44.390
To give you an idea, if there
are 125 million households

00:27:44.390 --> 00:27:49.850
in the US, if 5% of them
do business on Instacart,

00:27:49.850 --> 00:27:52.670
they typically shop for
groceries about once a week.

00:27:52.670 --> 00:27:55.090
If we can save about
a minute a week,

00:27:55.090 --> 00:27:59.930
then that's 618 years of labor
that we save every single week

00:27:59.930 --> 00:28:01.010
with a model like this.

00:28:03.590 --> 00:28:05.810
Once we have a model in
production like this,

00:28:05.810 --> 00:28:08.000
it's really easy to tweak
it to add more features

00:28:08.000 --> 00:28:10.130
to see which ones
make sense, which ones

00:28:10.130 --> 00:28:13.910
are harming the
model's performance,

00:28:13.910 --> 00:28:16.400
to add extra hidden layers.

00:28:16.400 --> 00:28:19.430
We went through about seven
iterations on this one.

00:28:19.430 --> 00:28:21.770
And we actually doubled
the performance of it

00:28:21.770 --> 00:28:23.300
compared to the baseline.

00:28:23.300 --> 00:28:27.890
So we're at over a millennia
saved per week now,

00:28:27.890 --> 00:28:31.248
which we're very happy about.

00:28:31.248 --> 00:28:33.080
[LAUGHTER]

00:28:33.080 --> 00:28:34.760
So that's all I've got.

00:28:34.760 --> 00:28:36.950
I'm going to turn it
back over to Kevin,

00:28:36.950 --> 00:28:39.140
who should be able to
give us some closing

00:28:39.140 --> 00:28:41.140
notes before lunch.

