WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.402
[MUSICAL INTRO]

00:00:05.137 --> 00:00:07.470
LOUIS HYMAN: Thank you so
much for having me here today.

00:00:07.470 --> 00:00:09.950
And thank you, Rachel,
Professor, Dr. Rachel,

00:00:09.950 --> 00:00:12.610
Professor Hyman.

00:00:12.610 --> 00:00:16.580
And as a professor, I'm here to
remind you of lessons that you

00:00:16.580 --> 00:00:19.310
may have learned long ago.

00:00:19.310 --> 00:00:21.800
When we learn about the
Industrial Revolution

00:00:21.800 --> 00:00:26.040
in school, we hear a lot about
factories, and steam engines,

00:00:26.040 --> 00:00:30.740
and maybe if you had a really
particularly terrible teacher,

00:00:30.740 --> 00:00:32.270
the power loom.

00:00:32.270 --> 00:00:35.510
And we are taught that this
technological innovation

00:00:35.510 --> 00:00:40.460
drives social change,
explains how the world works,

00:00:40.460 --> 00:00:44.780
and has made it possible to
work in the way that we do.

00:00:44.780 --> 00:00:47.540
Now likewise, when we talk
about today's economy,

00:00:47.540 --> 00:00:52.150
we focus on smartphones,
artificial intelligence, apps.

00:00:52.150 --> 00:00:54.980
And here too, the inexorable
march of technology

00:00:54.980 --> 00:00:57.590
is thought to be
responsible for disrupting

00:00:57.590 --> 00:01:00.740
traditional work, for
phasing out the employee who

00:01:00.740 --> 00:01:03.440
works for a regular
wage or a salary,

00:01:03.440 --> 00:01:06.710
and phasing in independent
contractors, consultants,

00:01:06.710 --> 00:01:08.480
temps, and freelancers--

00:01:08.480 --> 00:01:11.330
of course, none of
whom are at Google--

00:01:11.330 --> 00:01:14.250
the so-called gig economy.

00:01:14.250 --> 00:01:16.050
But this narrative is wrong.

00:01:16.050 --> 00:01:17.620
This narrative is wrong.

00:01:17.620 --> 00:01:20.840
The history of labor shows that
technology does not usually

00:01:20.840 --> 00:01:22.820
drive social change.

00:01:22.820 --> 00:01:27.620
On the contrary, social
change is driven by decisions

00:01:27.620 --> 00:01:31.400
about reorganizing people
that reorganize our work.

00:01:31.400 --> 00:01:34.940
Only later does technology
swoop in, accelerate,

00:01:34.940 --> 00:01:38.040
and consolidate those changes.

00:01:38.040 --> 00:01:42.290
This insight that it's not
just technological determinism,

00:01:42.290 --> 00:01:45.680
that it's not just
market determinism is

00:01:45.680 --> 00:01:48.770
crucial for anyone who
wants to understand

00:01:48.770 --> 00:01:51.980
the insecurity and other
shortcomings of the gig

00:01:51.980 --> 00:01:56.160
economy, and more broadly,
our economy today.

00:01:56.160 --> 00:01:58.220
Ford reminds us
that, far from being

00:01:58.220 --> 00:02:02.960
the unavoidable consequence of
progress, the nature of work

00:02:02.960 --> 00:02:07.040
is part of our social
fabric that progress,

00:02:07.040 --> 00:02:11.720
technological or otherwise,
does not require insecurity.

00:02:11.720 --> 00:02:13.520
Consider the
Industrial Revolution.

00:02:13.520 --> 00:02:17.220
Well, before it took
place in the 19th century,

00:02:17.220 --> 00:02:19.490
another revolution
in work took place

00:02:19.490 --> 00:02:23.510
in the 18th century, which
historians call the Industrious

00:02:23.510 --> 00:02:24.740
Revolution.

00:02:24.740 --> 00:02:27.290
Before this revolution,
people worked where they

00:02:27.290 --> 00:02:30.590
lived, on a farm, or in a shop.

00:02:30.590 --> 00:02:33.650
The manufacturing of
textiles, for instance,

00:02:33.650 --> 00:02:35.990
relied on networks of
independent farmers

00:02:35.990 --> 00:02:38.690
who spun and wove cloth.

00:02:38.690 --> 00:02:40.160
They worked on their own.

00:02:40.160 --> 00:02:42.150
They were not employees.

00:02:42.150 --> 00:02:45.860
In the Industrious
Revolution, manufacturers

00:02:45.860 --> 00:02:49.250
gathered workers under one
roof where the work could

00:02:49.250 --> 00:02:52.460
be divided and supervised.

00:02:52.460 --> 00:02:57.470
For the first time on a large
scale, home life and work life

00:02:57.470 --> 00:02:59.150
were separated.

00:02:59.150 --> 00:03:04.820
And so this was a precondition
for the Industrial Revolution.

00:03:04.820 --> 00:03:08.390
While factory technology would
consolidate this development,

00:03:08.390 --> 00:03:10.370
the creation of
factory technology

00:03:10.370 --> 00:03:17.270
was only possible because people
were already in the factories.

00:03:17.270 --> 00:03:20.510
Solving for this
world, a power loom

00:03:20.510 --> 00:03:24.890
would have no purpose if people
still worked in their houses.

00:03:24.890 --> 00:03:29.120
And the story continues today
in what I call, in the book,

00:03:29.120 --> 00:03:31.640
the Second Industrious
Revolution,

00:03:31.640 --> 00:03:34.450
today's digital
revolution in the world,

00:03:34.450 --> 00:03:39.200
in the economy that has come
into being since the 1970s.

00:03:39.200 --> 00:03:43.190
It's often described as
a second Machine Age.

00:03:43.190 --> 00:03:47.540
But it's more like a second
Industrious Revolution that's

00:03:47.540 --> 00:03:50.480
been underway for at least
40 years, encompassing

00:03:50.480 --> 00:03:55.040
the collapse, since the 1970s,
of the relatively secure work

00:03:55.040 --> 00:03:56.930
of the post-war period.

00:03:56.930 --> 00:03:59.310
This is the
post-industrialization.

00:03:59.310 --> 00:04:02.840
This is the rise of
the service economy.

00:04:02.840 --> 00:04:04.640
And over these
four decades, we've

00:04:04.640 --> 00:04:08.780
seen an increase in the use
of day laborers, office temps,

00:04:08.780 --> 00:04:14.000
management consultants, contract
assemblers, adjunct professors,

00:04:14.000 --> 00:04:18.860
Blackwater mercenaries, and
every other kind of person

00:04:18.860 --> 00:04:23.100
filing IRS form 1099.

00:04:23.100 --> 00:04:25.290
These jobs span
the income ranks.

00:04:25.290 --> 00:04:28.200
But what they share in common
is what all work increasingly

00:04:28.200 --> 00:04:32.140
seems to have in common
since the 1970s--

00:04:32.140 --> 00:04:33.940
insecurity.

00:04:33.940 --> 00:04:36.630
This is possible because
of the way in which work

00:04:36.630 --> 00:04:38.730
has become to be organized.

00:04:38.730 --> 00:04:42.930
Workers are no longer as closely
bound to employers for good

00:04:42.930 --> 00:04:44.130
and for bad.

00:04:44.130 --> 00:04:46.680
And all the tech
of the gig economy,

00:04:46.680 --> 00:04:52.020
all the apps of your smartphone
is the result of that.

00:04:52.020 --> 00:04:53.790
For some, the rise
of the gig economy

00:04:53.790 --> 00:04:57.510
represents liberation from the
stifling bureaucratic world

00:04:57.510 --> 00:04:58.980
of corporate America.

00:04:58.980 --> 00:05:02.520
High-paid consultants, well-paid
independent contractors--

00:05:02.520 --> 00:05:06.960
it is a return to the autonomy
and independence of an economy

00:05:06.960 --> 00:05:09.610
before wage labor--

00:05:09.610 --> 00:05:13.270
no desk, no boss,
every consultant

00:05:13.270 --> 00:05:16.110
his or her own master.

00:05:16.110 --> 00:05:19.810
Yet for the majority of
workers, this so-called freedom

00:05:19.810 --> 00:05:22.960
of the gig economy is just
the freedom to be afraid.

00:05:22.960 --> 00:05:26.890
It is a severing of obligations
between firms and employers.

00:05:26.890 --> 00:05:29.930
[INAUDIBLE] is the
collapse of protections

00:05:29.930 --> 00:05:32.080
the people of the United
States, and our laws,

00:05:32.080 --> 00:05:36.790
and our customs once
fought hard to enshrine.

00:05:36.790 --> 00:05:38.320
Internet technologies
have certainly

00:05:38.320 --> 00:05:41.950
intensified this development,
even though most freelancers

00:05:41.950 --> 00:05:43.750
remain offline.

00:05:43.750 --> 00:05:46.630
But services like Uber and
online freelance markets

00:05:46.630 --> 00:05:49.030
like TaskRabbit or
Upwork were created

00:05:49.030 --> 00:05:53.470
to take advantage of an
already independent workforce.

00:05:53.470 --> 00:05:55.130
They are not creating it.

00:05:55.130 --> 00:05:58.330
The technology is solving
the business and consumer

00:05:58.330 --> 00:06:02.500
problems of an already
insecure world of work.

00:06:02.500 --> 00:06:06.070
Uber is the symptom,
not the cause.

00:06:06.070 --> 00:06:11.890
Uber is the waste product
of the service economy.

00:06:11.890 --> 00:06:15.300
So today I would like to talk
about just one small part

00:06:15.300 --> 00:06:19.740
of this book, which tells the
story of how Americans created

00:06:19.740 --> 00:06:22.830
security in the years coming
out of the Great Depression

00:06:22.830 --> 00:06:27.290
and World War II
and then suddenly,

00:06:27.290 --> 00:06:31.010
unexpectedly dismantled it.

00:06:31.010 --> 00:06:34.220
This larger history is
about how the corporation

00:06:34.220 --> 00:06:37.310
and the workplace have
changed since the 1930s.

00:06:37.310 --> 00:06:38.900
It is a story of
who counts and who

00:06:38.900 --> 00:06:42.740
doesn't count, who is
included and who is excluded,

00:06:42.740 --> 00:06:47.240
how workplace stability,
how a secure job stopped

00:06:47.240 --> 00:06:50.750
being something to be
celebrated and instead

00:06:50.750 --> 00:06:55.520
became a problem to be
solved by consultants.

00:06:55.520 --> 00:06:57.710
The story I'm
telling today is part

00:06:57.710 --> 00:06:59.960
of the story of
Silicon Valley, which

00:06:59.960 --> 00:07:03.030
I explore in depth in the book.

00:07:03.030 --> 00:07:05.690
This story here is
about temp workers,

00:07:05.690 --> 00:07:08.900
and undocumented migrants,
and legal migrants

00:07:08.900 --> 00:07:10.790
at the very bottom
of the Silicon Valley

00:07:10.790 --> 00:07:14.090
world, the world that's often
not discussed when we read

00:07:14.090 --> 00:07:18.310
those biographies of
Steve Jobs, or the Woz,

00:07:18.310 --> 00:07:21.890
or all of these other so-called
leaders of Silicon Valley.

00:07:21.890 --> 00:07:24.110
So today I'd like to tell
you a different story

00:07:24.110 --> 00:07:29.020
of a place with which you're
probably already familiar.

00:07:29.020 --> 00:07:31.270
So just as the
agricultural economy

00:07:31.270 --> 00:07:34.690
was born between two
great rivers, the Tigris

00:07:34.690 --> 00:07:37.630
and Euphrates, so is
the digital economy

00:07:37.630 --> 00:07:43.240
born between two great
highways, 101 and 280--

00:07:43.240 --> 00:07:46.200
or if you're from Southern
California, the 111

00:07:46.200 --> 00:07:47.740
and the 280.

00:07:47.740 --> 00:07:50.830
So connecting San
Jose to San Francisco,

00:07:50.830 --> 00:07:53.560
these highways define the
eastern and western borders

00:07:53.560 --> 00:07:57.610
of Silicon Valley, which
had, until the 1950s, mostly

00:07:57.610 --> 00:07:59.140
been fruit trees.

00:07:59.140 --> 00:08:02.770
In the 1960s, as the
electronics industry grew,

00:08:02.770 --> 00:08:04.870
these trees were
cut down to make way

00:08:04.870 --> 00:08:07.400
for factories and offices.

00:08:07.400 --> 00:08:10.870
Now today's Silicon Valley
is mostly known for its apps.

00:08:10.870 --> 00:08:14.410
But in the '70s and '80s, it was
still a place where products--

00:08:14.410 --> 00:08:16.900
first transistors,
and then whole chips--

00:08:16.900 --> 00:08:17.830
were made.

00:08:17.830 --> 00:08:21.760
And by the 1980s, electronics
was the largest manufacturing

00:08:21.760 --> 00:08:24.070
industry in the United States.

00:08:24.070 --> 00:08:27.040
It was what economists call the
leading sector, the place that

00:08:27.040 --> 00:08:30.340
was driving change,
driving profits.

00:08:30.340 --> 00:08:35.799
And Silicon Valley's factories
left Detroit's far behind.

00:08:35.799 --> 00:08:41.049
The 1980s-- Detroit
falters, San Jose thrives.

00:08:41.049 --> 00:08:42.820
Japan might have
made better cars,

00:08:42.820 --> 00:08:45.710
but we made better computers.

00:08:45.710 --> 00:08:48.850
And if American manufacturing
was to be successful,

00:08:48.850 --> 00:08:51.880
if America still had
a claim on the future,

00:08:51.880 --> 00:08:55.540
if America was still seen
as a leader in progress,

00:08:55.540 --> 00:08:58.120
it was in Silicon Valley.

00:08:58.120 --> 00:09:01.060
The electronics industry
validated new ways

00:09:01.060 --> 00:09:03.850
to think about
capitalism since it,

00:09:03.850 --> 00:09:07.150
unlike any previous
leading sector, depended

00:09:07.150 --> 00:09:10.750
on short-term,
flexible workforces,

00:09:10.750 --> 00:09:13.450
depended on venture
capital, depended

00:09:13.450 --> 00:09:16.510
on new lean ways
of manufacturing,

00:09:16.510 --> 00:09:18.820
new kinds of supply
chains, new kinds

00:09:18.820 --> 00:09:24.520
of subcontracted workforces in
a way that Detroit never had.

00:09:24.520 --> 00:09:27.040
Unions were nowhere to be found.

00:09:27.040 --> 00:09:29.530
And the sporadic
organizing campaigns

00:09:29.530 --> 00:09:33.310
of the '60s, '70s,
and '80s all failed.

00:09:33.310 --> 00:09:37.840
Silicon Valley became the
laboratory and the blueprint

00:09:37.840 --> 00:09:42.100
for a lean American capitalism.

00:09:42.100 --> 00:09:45.820
Apple never produced the good
life for its line workers

00:09:45.820 --> 00:09:47.950
like General Motors did.

00:09:47.950 --> 00:09:50.200
And the story of flexibility
in Silicon Valley

00:09:50.200 --> 00:09:53.080
is not just the insecurity
of the workers in the bottom,

00:09:53.080 --> 00:09:55.810
but of course, the
success of workers

00:09:55.810 --> 00:09:58.240
at the top, of the
venture capitalists that

00:09:58.240 --> 00:10:01.810
moved from startup to startup,
of software engineers who

00:10:01.810 --> 00:10:05.410
hopped from project to project,
of consultants designing

00:10:05.410 --> 00:10:08.170
strategies and
organizational structures

00:10:08.170 --> 00:10:11.590
to maximize profits
and flexibility.

00:10:11.590 --> 00:10:15.870
And that's a story that
we're more familiar with.

00:10:15.870 --> 00:10:18.140
But underneath that
world were layers

00:10:18.140 --> 00:10:21.860
of formal and informal
workers, of migrants.

00:10:21.860 --> 00:10:24.830
These migrants worked in
large assembly factories,

00:10:24.830 --> 00:10:28.700
small Quonset huts, and
even in their own kitchens,

00:10:28.700 --> 00:10:31.160
making the electronics
that made those venture

00:10:31.160 --> 00:10:32.692
capitalists wealthy.

00:10:32.692 --> 00:10:34.400
And even though they
are usually left out

00:10:34.400 --> 00:10:40.110
of the story of Silicon Valley,
they are essential to its rise.

00:10:40.110 --> 00:10:42.360
From top to bottom,
Silicon Valley

00:10:42.360 --> 00:10:45.750
defines a new universal
model of business,

00:10:45.750 --> 00:10:49.850
even as its own industry,
electronics, and then software,

00:10:49.850 --> 00:10:51.390
were unique.

00:10:51.390 --> 00:10:54.380
And it's interesting what's
hidden by the stories we tell

00:10:54.380 --> 00:10:56.180
as well as the graphs.

00:10:56.180 --> 00:10:59.060
This is a graph that
everybody here knows.

00:10:59.060 --> 00:11:01.970
It's a graph of
Moore's law, which

00:11:01.970 --> 00:11:04.220
becomes, with the
rise of electronics,

00:11:04.220 --> 00:11:07.310
the new time signature
of capitalism.

00:11:07.310 --> 00:11:09.410
Twice as many
transistors crammed

00:11:09.410 --> 00:11:11.570
on chips every 18 months--

00:11:11.570 --> 00:11:12.110
look at it.

00:11:12.110 --> 00:11:13.130
It's so smooth.

00:11:13.130 --> 00:11:16.460
It's so logarithmic.

00:11:16.460 --> 00:11:21.000
This pace of miniaturization
is astounding.

00:11:21.000 --> 00:11:22.910
It also has other consequences.

00:11:22.910 --> 00:11:25.910
It's impossible for
firms to earn much money

00:11:25.910 --> 00:11:29.690
before they have to move on
to the next kind of chip.

00:11:29.690 --> 00:11:33.230
And this punishing
cycle made electronics

00:11:33.230 --> 00:11:35.300
a very different
kind of industry

00:11:35.300 --> 00:11:37.940
than in, for
instance, aerospace,

00:11:37.940 --> 00:11:39.560
where the same
machines could be used

00:11:39.560 --> 00:11:43.370
for year after year on
the same kinds of bodies,

00:11:43.370 --> 00:11:45.440
or even in cars.

00:11:45.440 --> 00:11:49.640
So work couldn't be as
mechanized as in an earlier

00:11:49.640 --> 00:11:50.660
economy.

00:11:50.660 --> 00:11:53.390
It had to be more flexible.

00:11:53.390 --> 00:11:56.350
And this flexibility
depended on people,

00:11:56.350 --> 00:12:00.390
especially cheap people,
especially disposable workers.

00:12:00.390 --> 00:12:03.980
And so the flexibility of
this production of Moore's law

00:12:03.980 --> 00:12:06.690
just was not from
engineering wizardry

00:12:06.690 --> 00:12:10.720
as much as it was from workers.

00:12:10.720 --> 00:12:13.920
So as we-- this is one part
of one chapter in the book.

00:12:13.920 --> 00:12:15.630
And the first part
of the chapter

00:12:15.630 --> 00:12:19.080
is about that world of
consultants and business

00:12:19.080 --> 00:12:21.510
leaders, the story
of Steve Jobs,

00:12:21.510 --> 00:12:25.860
the story of McKinsey
remaking Silicon Valley.

00:12:25.860 --> 00:12:29.850
It's a story that you can
see in this slide here,

00:12:29.850 --> 00:12:33.090
the story of the corporation
from top to bottom,

00:12:33.090 --> 00:12:36.750
of consultants, and temps,
and subcontracted workers,

00:12:36.750 --> 00:12:38.400
undocumented workers.

00:12:38.400 --> 00:12:42.570
But today I want to talk about
the people at the very bottom

00:12:42.570 --> 00:12:46.290
as this new kind of
leading sector emerges.

00:12:46.290 --> 00:12:48.510
And if we think about
the word "temp"--

00:12:48.510 --> 00:12:51.930
and this book is going to annoy
lots of social scientists.

00:12:51.930 --> 00:12:55.040
Because they're like, oh, that
just means office workers.

00:12:55.040 --> 00:12:57.510
Like, well, yeah,
but really, it's

00:12:57.510 --> 00:13:00.430
a more expansive
category of flexibility.

00:13:00.430 --> 00:13:02.970
And this kind of
woman is probably

00:13:02.970 --> 00:13:06.390
the woman you imagine coming
out of the post-war who

00:13:06.390 --> 00:13:09.900
may work as an office
temp, a white woman,

00:13:09.900 --> 00:13:12.200
slender and beautiful.

00:13:12.200 --> 00:13:14.190
She's really a housewife,
but really, she

00:13:14.190 --> 00:13:16.044
goes, sometimes, to work.

00:13:16.044 --> 00:13:17.460
This is certainly
the story that's

00:13:17.460 --> 00:13:20.400
told by people like
Elmer Winter who

00:13:20.400 --> 00:13:25.030
started Manpower Incorporated,
that this is all discretionary.

00:13:25.030 --> 00:13:29.680
This kind of work is a choice
for middle-class white women.

00:13:29.680 --> 00:13:31.170
But this is not
the kind of woman

00:13:31.170 --> 00:13:33.390
I want you to think
about as we are

00:13:33.390 --> 00:13:37.050
exploring this hidden
history of Silicon Valley.

00:13:37.050 --> 00:13:39.660
I want you to think
of faces like this.

00:13:39.660 --> 00:13:43.260
I want you to think of
hands like this, women

00:13:43.260 --> 00:13:46.560
who need to work, and of
course, the many people

00:13:46.560 --> 00:13:49.320
whose faces we don't have
pictures of, who remained

00:13:49.320 --> 00:13:54.870
undocumented even as their work
made Silicon Valley possible.

00:13:54.870 --> 00:13:59.100
Every year after 1965,
the INS apprehended

00:13:59.100 --> 00:14:02.910
more, what they called, illegal
aliens in industry and service

00:14:02.910 --> 00:14:04.450
than in agriculture.

00:14:04.450 --> 00:14:06.840
In fact, these
undocumented workers

00:14:06.840 --> 00:14:09.760
were foundational to the
rise of Silicon Valley.

00:14:09.760 --> 00:14:14.220
Now this is perhaps ironic
that workers matter so much

00:14:14.220 --> 00:14:15.300
in Silicon Valley.

00:14:15.300 --> 00:14:17.970
Because of course, if
we imagine a place that

00:14:17.970 --> 00:14:22.920
would be automated, that would
be this future kind of world,

00:14:22.920 --> 00:14:25.410
it would be electronics.

00:14:25.410 --> 00:14:28.080
Apple, for instance-- and I can
say this because I'm at Google,

00:14:28.080 --> 00:14:32.021
not Apple, which I understand
you guys are all excited

00:14:32.021 --> 00:14:32.520
about--

00:14:32.520 --> 00:14:37.710
Apple, that iconic Silicon
Valley firm, bragged, in 1984,

00:14:37.710 --> 00:14:40.410
that the factory for its
new computer, something

00:14:40.410 --> 00:14:44.730
called the Macintosh,
would be the most automated

00:14:44.730 --> 00:14:45.700
in the world.

00:14:45.700 --> 00:14:47.820
And everywhere, they
celebrated this,

00:14:47.820 --> 00:14:50.250
a machine that builds machines.

00:14:50.250 --> 00:14:51.580
It's amazing.

00:14:51.580 --> 00:14:53.250
It's highly automated.

00:14:53.250 --> 00:14:54.965
It's the future.

00:14:54.965 --> 00:14:56.130
It's robots.

00:14:56.130 --> 00:15:00.120
It's everything we imagined
about the world to come.

00:15:00.120 --> 00:15:03.180
And yet Apple's factory,
like all other electronics

00:15:03.180 --> 00:15:07.390
factories, was
shockingly old-fashioned.

00:15:07.390 --> 00:15:11.570
It had some robots
on the line there.

00:15:11.570 --> 00:15:13.900
But to understand the
electronics industry

00:15:13.900 --> 00:15:17.300
is very, very simple.

00:15:17.300 --> 00:15:21.490
Every time someone says "robot,"
simply picture, instead,

00:15:21.490 --> 00:15:24.900
a migrant woman of color.

00:15:24.900 --> 00:15:27.210
Instead of self-aware
robots, workers--

00:15:27.210 --> 00:15:29.430
nearly all women and
mostly immigrant--

00:15:29.430 --> 00:15:32.220
hunched over tables
with magnifying glasses

00:15:32.220 --> 00:15:33.890
assembling parts.

00:15:33.890 --> 00:15:37.220
In the entire world, in
1986, only two industries

00:15:37.220 --> 00:15:41.160
accounted, according to that
left-wing propaganda instrument

00:15:41.160 --> 00:15:46.780
"McKinsey Quarterly," for 80%
of installed robots in aerospace

00:15:46.780 --> 00:15:48.030
and automaking.

00:15:48.030 --> 00:15:50.250
And these workplaces of--

00:15:50.250 --> 00:15:53.400
these are all pictures of
the first Macintosh plants.

00:15:53.400 --> 00:15:55.680
These workplaces were
organized in accordance

00:15:55.680 --> 00:15:59.130
with new lean
manufacturing principles.

00:15:59.130 --> 00:16:02.010
Historians often talk
about the NUMMI factory,

00:16:02.010 --> 00:16:05.340
that collaboration between
General Motors and Toyota,

00:16:05.340 --> 00:16:09.180
where today, of course,
Tesla has its own factory.

00:16:09.180 --> 00:16:12.060
That was across the street
from the first Macintosh

00:16:12.060 --> 00:16:14.980
plant in Fremont, California.

00:16:14.980 --> 00:16:18.330
They were both of the same
moment, the same ideas

00:16:18.330 --> 00:16:21.330
of flexible production,
of pushing things out

00:16:21.330 --> 00:16:22.830
into the supply chain.

00:16:22.830 --> 00:16:25.430
But of course, with
auto manufacturing,

00:16:25.430 --> 00:16:28.310
that supply chain
was very visible.

00:16:28.310 --> 00:16:31.520
The supply chains of these
places were instead--

00:16:31.520 --> 00:16:34.920
these electronics
firms were more hidden.

00:16:34.920 --> 00:16:36.410
Instead of robots,
Silicon Valley

00:16:36.410 --> 00:16:39.110
relied upon a
transient workforce.

00:16:39.110 --> 00:16:41.810
If they were white and
native-born, they were temps.

00:16:41.810 --> 00:16:43.940
If they weren't, then
they were the laborers

00:16:43.940 --> 00:16:47.150
who worked by the
day or by the piece.

00:16:47.150 --> 00:16:50.120
Tech firms outsourced
labor to temp agencies,

00:16:50.120 --> 00:16:55.400
subcontracted sweatshops and
overseas factories eventually.

00:16:55.400 --> 00:16:58.050
So let's tell the story of this.

00:16:58.050 --> 00:17:00.680
Let's tell the story
of John Senko, who,

00:17:00.680 --> 00:17:05.599
in 1984, was an 18-year veteran
of the INS, the forerunner

00:17:05.599 --> 00:17:07.040
of today's ICE.

00:17:07.040 --> 00:17:09.710
And it opens its first
office in San Jose

00:17:09.710 --> 00:17:11.630
and begins to oversee
the immigration

00:17:11.630 --> 00:17:13.339
issues in Silicon Valley.

00:17:13.339 --> 00:17:16.040
The INS believed
that as much as 25%

00:17:16.040 --> 00:17:19.880
of the Silicon Valley
workforce, about 200,000 people,

00:17:19.880 --> 00:17:21.349
was undocumented.

00:17:21.349 --> 00:17:26.060
Sanko's task was simple,
and yet impossible--

00:17:26.060 --> 00:17:29.720
eliminate illegal labor
in Silicon Valley.

00:17:29.720 --> 00:17:31.910
The office had only
four investigators

00:17:31.910 --> 00:17:34.190
and was chronically
under-resourced.

00:17:34.190 --> 00:17:37.550
Senko said, quote, "It's
difficult to make people

00:17:37.550 --> 00:17:41.780
realize, because the nature of
the industry, illegal aliens

00:17:41.780 --> 00:17:43.100
are working here.

00:17:43.100 --> 00:17:45.290
It's hard because
high technology

00:17:45.290 --> 00:17:47.080
is sophisticated industry.

00:17:47.080 --> 00:17:50.030
And it was easy to believe
that no part of the production

00:17:50.030 --> 00:17:53.000
was unskilled."

00:17:53.000 --> 00:17:56.641
Behind graphs of this
world, the people

00:17:56.641 --> 00:17:58.640
were-- there were people
who were not officially

00:17:58.640 --> 00:18:00.860
part of that workforce.

00:18:00.860 --> 00:18:03.260
Behind graphs of
growth were workers

00:18:03.260 --> 00:18:05.210
like a woman named Fermina--

00:18:05.210 --> 00:18:06.790
whose name actually
wasn't Fermina.

00:18:06.790 --> 00:18:10.580
It's a fake name I
used in the book--

00:18:10.580 --> 00:18:13.040
whose names aren't as
actually well-known

00:18:13.040 --> 00:18:16.860
as IBM PC or Apple II.

00:18:16.860 --> 00:18:20.690
In 1982, Fermina had worked
at an electronics assembly

00:18:20.690 --> 00:18:24.620
plant in Tijuana where she
had earned $0.65 an hour,

00:18:24.620 --> 00:18:27.170
quote, "soldering gold
filaments to nodes

00:18:27.170 --> 00:18:29.330
neatly marked on
printed circuits"

00:18:29.330 --> 00:18:31.040
for about three years.

00:18:31.040 --> 00:18:33.920
She peered, hour after hour,
through her microscope,

00:18:33.920 --> 00:18:35.790
bonding semiconductors.

00:18:35.790 --> 00:18:38.060
Then the peso
destabilized, and Fermina

00:18:38.060 --> 00:18:41.900
crossed the border to stay with
relatives and look for work.

00:18:41.900 --> 00:18:44.180
Looking in the newspaper,
she called a number

00:18:44.180 --> 00:18:46.200
where she could even
inquire about jobs

00:18:46.200 --> 00:18:47.780
she had once left behind.

00:18:47.780 --> 00:18:49.470
She could even do it in Spanish.

00:18:49.470 --> 00:18:52.550
She felt very welcomed
in her new country.

00:18:52.550 --> 00:18:55.700
And she found her own job
bonding semiconductors.

00:18:55.700 --> 00:18:58.730
But this time, it was in an
assembly plant that made parts

00:18:58.730 --> 00:19:00.350
for personal computers.

00:19:00.350 --> 00:19:04.490
Instead of $0.65 an
hour, she now got $5.

00:19:04.490 --> 00:19:06.650
In the plant,
hundreds of Mexicans

00:19:06.650 --> 00:19:08.780
worked alongside
Fermina, many of them

00:19:08.780 --> 00:19:11.030
undocumented just like her.

00:19:11.030 --> 00:19:13.230
For Fermina, it was
a great-paying job.

00:19:13.230 --> 00:19:16.310
And for the firm, it was
a great-paying, very cheap

00:19:16.310 --> 00:19:17.570
employee.

00:19:17.570 --> 00:19:21.950
For Fermina and people like
her, it enabled great profits.

00:19:21.950 --> 00:19:26.240
In 1983, this factory was
the fourth-largest supplier

00:19:26.240 --> 00:19:28.860
of personal computers
in the United States

00:19:28.860 --> 00:19:35.240
with sales of $75 million
and profits of $13 million.

00:19:35.240 --> 00:19:36.350
So that sounds good.

00:19:36.350 --> 00:19:38.910
It seems like a
win-win situation.

00:19:38.910 --> 00:19:43.710
But you see, her life was,
in fact, quite insecure.

00:19:43.710 --> 00:19:47.970
Because when the INS raid came
through in November of 1984,

00:19:47.970 --> 00:19:51.390
Fermina hid in a supply
closet, terrified.

00:19:51.390 --> 00:19:52.740
Fermina escaped.

00:19:52.740 --> 00:19:55.920
But 50 of her coworkers,
nearly all Mexican women,

00:19:55.920 --> 00:19:58.400
were put in vans
for deportation.

00:19:58.400 --> 00:20:01.030
Quote, "I came to this
country to work hard,

00:20:01.030 --> 00:20:05.180
but now I live torn
between duty and shame."

00:20:05.180 --> 00:20:07.110
Fermina was not alone.

00:20:07.110 --> 00:20:09.800
Other high-profile INS raids
found firms that employed,

00:20:09.800 --> 00:20:13.370
on average, about half of their
assembly workforces illegally.

00:20:13.370 --> 00:20:17.810
Scholars estimate that about
100,000 Hispanic women, largely

00:20:17.810 --> 00:20:20.000
undocumented, worked
in electronics

00:20:20.000 --> 00:20:22.950
just in Southern California.

00:20:22.950 --> 00:20:27.720
At the other end, consider the
life of the temp Dennis Hayes.

00:20:27.720 --> 00:20:31.180
A world-- just recently, the
Ampex sign was taken down.

00:20:31.180 --> 00:20:33.030
And I, for one,
was very surprised

00:20:33.030 --> 00:20:35.700
to not hear this history
told about the history

00:20:35.700 --> 00:20:38.520
of that iconic
Silicon Valley firm.

00:20:38.520 --> 00:20:40.110
But in the story
of Dennis Hayes,

00:20:40.110 --> 00:20:42.330
we can see the story
of the interconnection

00:20:42.330 --> 00:20:45.880
between the white
native-born workforce

00:20:45.880 --> 00:20:49.230
and this other hidden
world of subcontracting.

00:20:49.230 --> 00:20:53.190
Dennis Hayes had dropped out of
his PhD program in sociology.

00:20:53.190 --> 00:20:57.660
And he came to California
to start temping in 1980.

00:20:57.660 --> 00:20:59.790
And he may have
hating temping, but he

00:20:59.790 --> 00:21:03.870
noticed that he didn't have
the worst job in the valley.

00:21:03.870 --> 00:21:06.690
Hayes noticed that
this futuristic economy

00:21:06.690 --> 00:21:09.870
rested on a very old idea--

00:21:09.870 --> 00:21:12.450
give the dirty,
dangerous work to people

00:21:12.450 --> 00:21:14.430
who had no alternative.

00:21:14.430 --> 00:21:17.400
Hayes temped at
Ampex, which was then

00:21:17.400 --> 00:21:19.650
a leading audio
electronics firm.

00:21:19.650 --> 00:21:22.380
And he worked on the floor
of the assembly room,

00:21:22.380 --> 00:21:24.210
but he didn't put
anything together.

00:21:24.210 --> 00:21:27.090
In that room was, like
most assembly rooms

00:21:27.090 --> 00:21:31.620
in Silicon Valley, nearly all
women, mostly women of color.

00:21:31.620 --> 00:21:34.350
And they put the
parts together there

00:21:34.350 --> 00:21:38.670
with tools that were ancient,
much older than transistors,

00:21:38.670 --> 00:21:43.830
much older than screwdrivers,
even older than the axe.

00:21:43.830 --> 00:21:46.320
They used their fingernails.

00:21:46.320 --> 00:21:48.060
These women would
grow two or three

00:21:48.060 --> 00:21:50.580
strategically long
fingernails on each hand

00:21:50.580 --> 00:21:54.090
so they could move the
components onto the circuit

00:21:54.090 --> 00:21:56.270
boards.

00:21:56.270 --> 00:21:58.860
Ampex was not unique.

00:21:58.860 --> 00:22:02.720
This all came through this
world of work dependant

00:22:02.720 --> 00:22:06.170
on fingernails and
not automation.

00:22:06.170 --> 00:22:10.640
Now what did Dennis Hayes do
there if he did not actually

00:22:10.640 --> 00:22:12.660
put things together?

00:22:12.660 --> 00:22:16.760
Well, his job was to deliver
and pick up components

00:22:16.760 --> 00:22:20.450
from subcontractors,
the metal shops.

00:22:20.450 --> 00:22:24.812
High-end audio was made possible
by low-end subcontracting.

00:22:24.812 --> 00:22:26.270
And in this regard,
it was not just

00:22:26.270 --> 00:22:29.660
about finding cheap worker, or
cheap suppliers, or vendors,

00:22:29.660 --> 00:22:33.040
but subcontracting
out toxic work

00:22:33.040 --> 00:22:37.520
to places and people that were
not part of OSHA regulations.

00:22:37.520 --> 00:22:39.650
So Hayes would drive
to a "dirt floor"

00:22:39.650 --> 00:22:43.550
Quonset hut in Santa Clara,
inside of which were "Hispanic"

00:22:43.550 --> 00:22:45.440
workers in rubber boot--
when I go like this,

00:22:45.440 --> 00:22:47.565
it means I'm quoting,
because I'm a historian, OK--

00:22:47.565 --> 00:22:49.310
and "rubber boots,
gloves, and apron"

00:22:49.310 --> 00:22:50.725
and without respiratory masks.

00:22:53.380 --> 00:22:56.410
The front and back doors of
these Quonset huts were open.

00:22:56.410 --> 00:22:59.170
Some passively turning
fans were in the ceiling.

00:22:59.170 --> 00:23:01.540
But otherwise, there
was no ventilation.

00:23:01.540 --> 00:23:03.790
The workers moved
around quickly,

00:23:03.790 --> 00:23:08.890
stoking fires beneath
vats of chemicals-- fires,

00:23:08.890 --> 00:23:12.760
vats, boiling chemicals
climbing up and down

00:23:12.760 --> 00:23:16.870
the jerry-built platforms
which gave access to the vats.

00:23:16.870 --> 00:23:18.340
Some of the vats boiled.

00:23:18.340 --> 00:23:21.550
Others, untouched by the
fires, yielded the smoke

00:23:21.550 --> 00:23:23.300
of the chemical reaction.

00:23:23.300 --> 00:23:26.950
He was there to drop off
chassis panels, nuts, and screws

00:23:26.950 --> 00:23:28.900
made in Ampex's factory.

00:23:28.900 --> 00:23:32.830
And these subcontracted workers
dipped the unfinished alloys

00:23:32.830 --> 00:23:34.300
in their vats.

00:23:34.300 --> 00:23:37.090
Hayes was only there
for minutes at a time,

00:23:37.090 --> 00:23:39.670
but he wrote that the
foul, metallic odors,

00:23:39.670 --> 00:23:42.070
"made me want to
hold my breath."

00:23:42.070 --> 00:23:43.960
Hayes never spoke to
the workers there,

00:23:43.960 --> 00:23:46.600
only to the boss, who
spoke to him in English

00:23:46.600 --> 00:23:49.950
while commanding the
workers in Spanish.

00:23:49.950 --> 00:23:54.040
So the point of this
system of production

00:23:54.040 --> 00:23:58.480
was not just to find cheaper,
but to avoid legal action.

00:23:58.480 --> 00:24:01.210
This is tort-liable
work outsourced

00:24:01.210 --> 00:24:05.170
to a network of employees
to act as intermediaries.

00:24:05.170 --> 00:24:08.860
No official employee of
Ampex delivered or picked up

00:24:08.860 --> 00:24:10.990
the panels, nuts, and screws.

00:24:10.990 --> 00:24:13.360
So no official employee
of Ampex could ever

00:24:13.360 --> 00:24:16.120
really know the
conditions under which

00:24:16.120 --> 00:24:18.290
this chemistry took place.

00:24:18.290 --> 00:24:19.930
If there was a legal
problem with one

00:24:19.930 --> 00:24:22.060
of these vat-filled
Quonset huts,

00:24:22.060 --> 00:24:24.730
it would have been easy
to disappear into just

00:24:24.730 --> 00:24:27.590
another anonymous Quonset hut.

00:24:27.590 --> 00:24:29.920
And so the clean rooms
of high technology

00:24:29.920 --> 00:24:33.850
are built atop a foundation of
very dirty, very toxic Quonset

00:24:33.850 --> 00:24:35.290
huts.

00:24:35.290 --> 00:24:37.390
And of course, today,
Santa Clara County

00:24:37.390 --> 00:24:41.616
has more EPA Superfund
sites than any other county

00:24:41.616 --> 00:24:42.490
in the United States.

00:24:46.430 --> 00:24:49.490
At the very bottom of
this system of electronics

00:24:49.490 --> 00:24:53.540
manufacture was not the small
factory or the Quonset hut,

00:24:53.540 --> 00:24:55.220
but kitchens.

00:24:55.220 --> 00:24:59.390
Investigators found that
somewhere between 10% and 30%

00:24:59.390 --> 00:25:02.960
of electronics firms
subcontracted to what they

00:25:02.960 --> 00:25:05.420
called, quote, "homeworkers."

00:25:05.420 --> 00:25:08.900
Like garment workers taking
in sewing in the 1880s,

00:25:08.900 --> 00:25:11.300
electronics workers
could assemble parts

00:25:11.300 --> 00:25:12.590
in their kitchens--

00:25:12.590 --> 00:25:14.660
a mother and her
children gathered

00:25:14.660 --> 00:25:17.510
around a kitchen table,
assembling components

00:25:17.510 --> 00:25:19.680
for $0.07 apiece.

00:25:19.680 --> 00:25:22.240
These little shops put
together the boards

00:25:22.240 --> 00:25:24.730
that went to the big companies.

00:25:24.730 --> 00:25:28.550
A California Labor inspector
turned a blind eye, saying,

00:25:28.550 --> 00:25:31.670
quote, "A Mexican or
Vietnamese can take home

00:25:31.670 --> 00:25:34.630
1,000 coils for
wiring one evening,

00:25:34.630 --> 00:25:38.240
and put every close neighbor
and family member to work,

00:25:38.240 --> 00:25:41.390
and return, the next
day, to the plant.

00:25:41.390 --> 00:25:44.840
It's not even worth our
time trying to wipe it out.

00:25:44.840 --> 00:25:47.660
When there are people
eager to work for pennies,

00:25:47.660 --> 00:25:52.940
you can expect that kind of
thing to happen," end quote.

00:25:52.940 --> 00:25:57.620
It was their fault for being
"eager" to work for pennies.

00:26:00.370 --> 00:26:03.490
While the image of the
Silicon Valley was futuristic,

00:26:03.490 --> 00:26:07.640
its methods were more that
of 19th century tenements.

00:26:07.640 --> 00:26:11.080
These homeworkers offered
firms a cheap labor force.

00:26:11.080 --> 00:26:14.740
But the real appeal was,
of course, flexibility.

00:26:14.740 --> 00:26:17.320
Chip processing fluctuated.

00:26:17.320 --> 00:26:20.510
Like cars, computer demand
varied through the year,

00:26:20.510 --> 00:26:21.820
both for consumers--

00:26:21.820 --> 00:26:25.440
holidays, the new school year--

00:26:25.440 --> 00:26:27.620
and for changes in
technology-- ah,

00:26:27.620 --> 00:26:32.210
the new cycle of chips, the
tick-tock, as we call it today.

00:26:32.210 --> 00:26:34.990
And as demand went up
and down, these firms

00:26:34.990 --> 00:26:37.330
had no obligation to
their homeworkers.

00:26:37.330 --> 00:26:39.640
So these kitchens
and Quonset huts

00:26:39.640 --> 00:26:42.290
would open and close as needed.

00:26:42.290 --> 00:26:44.710
Now the exact number,
how many firms,

00:26:44.710 --> 00:26:47.800
how many chips is hard
to point down exactly,

00:26:47.800 --> 00:26:50.980
because itself was a subterfuge.

00:26:50.980 --> 00:26:52.970
Behind the big,
expensive plants were

00:26:52.970 --> 00:26:55.610
vast networks of other workers.

00:26:55.610 --> 00:26:59.230
Tellingly, more firms in
the early 1980s at least,

00:26:59.230 --> 00:27:01.900
in various business
surveys subcontracted

00:27:01.900 --> 00:27:04.440
to exactly these
kinds of homeworkers

00:27:04.440 --> 00:27:07.600
than offshore plants.

00:27:07.600 --> 00:27:12.831
Anyhow, what did the
INS do about this?

00:27:12.831 --> 00:27:16.440
This is-- as you imagine,
there's not many pictures.

00:27:16.440 --> 00:27:19.860
But this is a picture of a
binder, Volume 8, entitled

00:27:19.860 --> 00:27:22.849
"Illegal Aliens,"
from the INS library

00:27:22.849 --> 00:27:25.140
just to give you a sense of
what that world looks like.

00:27:27.720 --> 00:27:30.300
The INS encouraged
the large companies

00:27:30.300 --> 00:27:33.870
to cooperate by offering them
lenience for giving up their,

00:27:33.870 --> 00:27:35.790
quote, "illegal aliens."

00:27:35.790 --> 00:27:38.700
At Circuit Assembly
Corporation in San Jose,

00:27:38.700 --> 00:27:42.870
the INS asked for names of its
non-citizen, non-documented

00:27:42.870 --> 00:27:44.160
employees.

00:27:44.160 --> 00:27:47.430
Of the 250 names, the
company thought that, quote,

00:27:47.430 --> 00:27:50.940
"20 or 30 of them could
be using forged papers."

00:27:50.940 --> 00:27:57.270
The actual number was
187, 187 out of 250.

00:27:57.270 --> 00:27:59.370
And the company,
because it cooperated,

00:27:59.370 --> 00:28:02.100
received no penalties, no
sanctions, and according

00:28:02.100 --> 00:28:06.510
to Senko, simply replaced
those 187 with other workers

00:28:06.510 --> 00:28:10.600
while those workers were,
themselves, deported.

00:28:10.600 --> 00:28:15.220
When Senko came to
San Jose in 1984,

00:28:15.220 --> 00:28:17.950
he raided not just
workplaces, but neighborhoods.

00:28:17.950 --> 00:28:21.130
In Menlo Park,
just near Stanford,

00:28:21.130 --> 00:28:25.150
INS agents blocked the streets,
removing Hispanic males

00:28:25.150 --> 00:28:27.250
from cars and from
homes, checking them

00:28:27.250 --> 00:28:29.110
for proof of citizenship.

00:28:29.110 --> 00:28:33.310
In Santa Cruz, the INS went door
to door checking citizenship.

00:28:33.310 --> 00:28:35.560
Senko and the INS
agents believed

00:28:35.560 --> 00:28:38.960
they did not need warrants
to name names ahead of time.

00:28:38.960 --> 00:28:41.530
Now of course, local
governments pushed back.

00:28:41.530 --> 00:28:43.450
The San Jose
government push back

00:28:43.450 --> 00:28:45.820
against the INS in
the name of defending,

00:28:45.820 --> 00:28:49.210
quote, "Chicano citizens"
against harassment,

00:28:49.210 --> 00:28:51.610
passing a resolution
against this, quote,

00:28:51.610 --> 00:28:55.150
"unwarranted disruption of
the business community."

00:28:55.150 --> 00:28:59.860
In December 1985, San Francisco
declares itself a sanctuary

00:28:59.860 --> 00:29:02.920
city and directs its
police and officials not

00:29:02.920 --> 00:29:07.030
to assist the INS in finding
law-abiding but undocumented

00:29:07.030 --> 00:29:08.950
migrants.

00:29:08.950 --> 00:29:10.450
So what happens then?

00:29:10.450 --> 00:29:11.920
Does all this end?

00:29:11.920 --> 00:29:12.940
No.

00:29:12.940 --> 00:29:15.730
The INS enforcement
becomes more selective,

00:29:15.730 --> 00:29:18.730
which actually enables
Silicon Valley corporations

00:29:18.730 --> 00:29:23.590
to have even more power over
their undocumented workforce.

00:29:23.590 --> 00:29:26.500
Businesses could selectively
check Green Cards

00:29:26.500 --> 00:29:28.600
against an INS database.

00:29:28.600 --> 00:29:31.900
If workers began to
organize or push back

00:29:31.900 --> 00:29:35.830
in any way against their
bosses, they could be deported.

00:29:35.830 --> 00:29:37.990
The spokesperson for the
International Association

00:29:37.990 --> 00:29:40.030
of Machinists explained
that when everyone

00:29:40.030 --> 00:29:42.850
tried to organize, the
company threatened to have

00:29:42.850 --> 00:29:45.570
anyone in the union deported.

00:29:45.570 --> 00:29:47.460
What about John Senko?

00:29:47.460 --> 00:29:49.950
Let's not forget
about his travails,

00:29:49.950 --> 00:29:54.300
his troubles as an INS
agent here in San Jose.

00:29:54.300 --> 00:29:59.440
Well, for him, it was the
worst three years of his life.

00:29:59.440 --> 00:30:01.830
He came to believe if he
was actually successful

00:30:01.830 --> 00:30:05.370
in deporting undocumented
workers from Silicon Valley,

00:30:05.370 --> 00:30:07.200
we'd have a "revolution."

00:30:07.200 --> 00:30:09.930
He preferred, he said,
businesses to cooperate rather

00:30:09.930 --> 00:30:11.310
than to have them raided.

00:30:11.310 --> 00:30:13.380
But that missed the point.

00:30:13.380 --> 00:30:17.730
The low cost of the undocumented
as well as their willingness,

00:30:17.730 --> 00:30:24.780
their need to work in illegal
conditions, in toxic situations

00:30:24.780 --> 00:30:29.040
made them too valuable, too
necessary to the Silicon Valley

00:30:29.040 --> 00:30:31.620
economy.

00:30:31.620 --> 00:30:35.640
This economy, former INS
head told a newspaper

00:30:35.640 --> 00:30:39.240
around that time, was built
on the assumption or reality

00:30:39.240 --> 00:30:42.990
of a heavy influx
of illegal labor.

00:30:42.990 --> 00:30:46.030
This former head of the
INS was not just referring

00:30:46.030 --> 00:30:49.000
to the electronics industry,
but the entire economy

00:30:49.000 --> 00:30:50.680
of the American West.

00:30:50.680 --> 00:30:52.720
This new American
economy that was

00:30:52.720 --> 00:30:55.870
looked to by the rest of
America as the future,

00:30:55.870 --> 00:30:59.830
as the most influential,
as the most successful

00:30:59.830 --> 00:31:04.210
was an economy that was built
on the backs of people who

00:31:04.210 --> 00:31:08.190
had few rights, built on
the backs of those excluded,

00:31:08.190 --> 00:31:10.990
built on the backs of those
who were so hard-pressed,

00:31:10.990 --> 00:31:14.095
they put their children to
work in their own kitchens.

00:31:17.540 --> 00:31:20.430
By the end of the 1980s,
these kinds of operations

00:31:20.430 --> 00:31:23.630
left the Bay Area, leaving
behind the people who

00:31:23.630 --> 00:31:27.060
had made this new accumulation
of wealth possible,

00:31:27.060 --> 00:31:30.260
and of course, the country's
largest Superfund sites.

00:31:30.260 --> 00:31:31.760
This is a picture
of two people that

00:31:31.760 --> 00:31:35.330
replaced-- that trained their
own replacements in Singapore

00:31:35.330 --> 00:31:38.060
before Apple moved overseas.

00:31:38.060 --> 00:31:39.200
Look how happy they are.

00:31:39.200 --> 00:31:40.600
They're so proud.

00:31:40.600 --> 00:31:43.900
Now why am I telling
you this story?

00:31:43.900 --> 00:31:47.170
I'm telling you a story of the
1980s, which, at this point,

00:31:47.170 --> 00:31:48.920
is a long time ago.

00:31:48.920 --> 00:31:50.590
And I'm not telling
you the story

00:31:50.590 --> 00:31:53.470
of the people who are above
this, the world of consultants,

00:31:53.470 --> 00:31:56.590
and temps, and all those
independent contractors.

00:31:56.590 --> 00:32:00.880
These people are important
too, to this story.

00:32:00.880 --> 00:32:04.090
But I'm telling you this
story today, this history

00:32:04.090 --> 00:32:08.630
because it's similar to how we
are talking about the future

00:32:08.630 --> 00:32:10.420
now.

00:32:10.420 --> 00:32:14.560
Just as Apple talked about
a world of automation

00:32:14.560 --> 00:32:18.090
and delivered a world
of exploitation,

00:32:18.090 --> 00:32:21.850
so too we hear the
same kind of language

00:32:21.850 --> 00:32:24.550
obscuring a certain
kind of reality today.

00:32:24.550 --> 00:32:26.920
The language of
robots and AI still

00:32:26.920 --> 00:32:29.650
do this cultural
and linguistic work

00:32:29.650 --> 00:32:32.660
of erasing the
present-day workforce,

00:32:32.660 --> 00:32:35.480
both visible and invisible.

00:32:35.480 --> 00:32:37.990
These workers are transitionary.

00:32:37.990 --> 00:32:40.570
These workers are disposable.

00:32:40.570 --> 00:32:43.600
The low-paid contingent
workers of Silicon Valley

00:32:43.600 --> 00:32:48.480
do not count, because some day
they will be replaced by an AI,

00:32:48.480 --> 00:32:50.430
or so we hear.

00:32:50.430 --> 00:32:53.700
It's not a coincidence that
these transitional workers

00:32:53.700 --> 00:32:56.160
look nothing like
the engineers that

00:32:56.160 --> 00:32:58.260
are the face of Silicon Valley.

00:32:58.260 --> 00:33:00.570
The plight of Uber
drivers doesn't really

00:33:00.570 --> 00:33:03.169
matter as its CEO tells us.

00:33:03.169 --> 00:33:04.710
And I'm pretty sure
mispronouncing it

00:33:04.710 --> 00:33:06.270
when I call him Travis Colonic.

00:33:10.130 --> 00:33:13.790
Because of source, someday,
narrow machine-learning AI

00:33:13.790 --> 00:33:15.020
will take it over.

00:33:15.020 --> 00:33:18.200
These people are a transition
to a better world to come,

00:33:18.200 --> 00:33:21.280
and it doesn't matter
how they suffer.

00:33:21.280 --> 00:33:24.560
But yet somehow this
future never comes to them.

00:33:24.560 --> 00:33:27.850
This ever-receding future
seems to legitimate

00:33:27.850 --> 00:33:33.050
a very real, very unequal,
seemingly unending present.

00:33:33.050 --> 00:33:35.817
So as we think about
the future, as we-- oh,

00:33:35.817 --> 00:33:37.360
there we are, the rotten apple.

00:33:37.360 --> 00:33:39.070
As we think about
the future, we have

00:33:39.070 --> 00:33:42.640
to ask, again and again,
the same question--

00:33:42.640 --> 00:33:43.900
who counts?

00:33:43.900 --> 00:33:48.280
Who deserves, if not guaranteed
work, at least secure lives?

00:33:48.280 --> 00:33:49.780
Who matters?

00:33:49.780 --> 00:33:52.510
We must, as we think
about this, also not

00:33:52.510 --> 00:33:56.590
forget that even for those
post-war white men, those men

00:33:56.590 --> 00:33:59.620
who got pensions and
defined benefits,

00:33:59.620 --> 00:34:04.130
men who had the good paychecks,
working on the assembly line,

00:34:04.130 --> 00:34:07.430
or in a mine, or even in
an office, in a factory

00:34:07.430 --> 00:34:10.040
was dehumanizing,
sometimes backbreaking,

00:34:10.040 --> 00:34:13.010
but most often,
soul-breaking work.

00:34:13.010 --> 00:34:15.889
Whatever the wages and
benefits, humans should not

00:34:15.889 --> 00:34:19.139
do the work of robots.

00:34:19.139 --> 00:34:22.040
So it's not simply that we
should give up on automation,

00:34:22.040 --> 00:34:25.130
we should give up on
robotics, we should give up

00:34:25.130 --> 00:34:27.170
on the future,
but that we should

00:34:27.170 --> 00:34:30.469
think about the future
cognizantly of how

00:34:30.469 --> 00:34:34.790
the past has used the
future to erase the present.

00:34:34.790 --> 00:34:37.850
We can't turn back the clock
to a world that was never

00:34:37.850 --> 00:34:40.730
as great as we imagined
it was, to an America

00:34:40.730 --> 00:34:45.080
that was never as wonderful
as we often hear it was.

00:34:45.080 --> 00:34:48.350
But progress does not
require insecurity.

00:34:48.350 --> 00:34:50.060
Just as the post-war
period managed

00:34:50.060 --> 00:34:53.420
to make industrialization
benefit some industrial workers

00:34:53.420 --> 00:34:56.600
to give some people
this level of security,

00:34:56.600 --> 00:35:00.770
we need to create new norms,
institutions, and policies

00:35:00.770 --> 00:35:05.660
to make digitization
benefit everyone today.

00:35:05.660 --> 00:35:08.630
It's important, as we make
choices going into this world,

00:35:08.630 --> 00:35:11.090
whether conservative or
liberal, that this world

00:35:11.090 --> 00:35:14.132
of independent work, this
world of automation is coming

00:35:14.132 --> 00:35:16.590
and that we need to remember
that we have choices about how

00:35:16.590 --> 00:35:19.250
it will play out, that
the distribution of wealth

00:35:19.250 --> 00:35:23.030
and productivity is not
just an economic reality,

00:35:23.030 --> 00:35:25.100
but a political choice.

00:35:25.100 --> 00:35:27.170
So just as the
industrial economy

00:35:27.170 --> 00:35:31.070
offered inequality and
growth for 100 years

00:35:31.070 --> 00:35:33.950
before it produced the,
quote, "good life," so,

00:35:33.950 --> 00:35:35.900
too, will the digital economy.

00:35:35.900 --> 00:35:39.140
And we need to understand that
this flexible workforce can,

00:35:39.140 --> 00:35:41.030
depending on the
choices that we make,

00:35:41.030 --> 00:35:44.780
be the liberation from wage
work that Americans have

00:35:44.780 --> 00:35:49.610
so long yearn for,
or to be immiserated,

00:35:49.610 --> 00:35:54.030
to be damned to insecure
life in an unequal society.

00:35:54.030 --> 00:35:56.540
And as we choose
this world before us,

00:35:56.540 --> 00:35:59.150
we should not make the
mistakes of the past,

00:35:59.150 --> 00:36:01.640
creating a more
inclusive capitalism that

00:36:01.640 --> 00:36:05.230
accounts for everybody.

00:36:05.230 --> 00:36:07.270
Insecurity is not
the inevitable cost,

00:36:07.270 --> 00:36:11.620
nor does progress require
treating people like machines.

00:36:11.620 --> 00:36:13.480
Only by understanding
that fact can

00:36:13.480 --> 00:36:17.890
we make capitalism work
for us, not work us over.

00:36:17.890 --> 00:36:18.912
Thank you so much.

00:36:18.912 --> 00:36:19.870
Happy to be here today.

00:36:19.870 --> 00:36:23.202
[APPLAUSE]

00:36:28.270 --> 00:36:28.770
Yeah.

00:36:28.770 --> 00:36:31.170
AUDIENCE: So it sounds like
one of the primary reasons

00:36:31.170 --> 00:36:34.290
that undocumented workers
were able to be exploited

00:36:34.290 --> 00:36:37.140
was because they
were undocumented.

00:36:37.140 --> 00:36:40.410
How do you feel
about open borders?

00:36:40.410 --> 00:36:42.869
LOUIS HYMAN: Yeah, I'm
actually very much--

00:36:42.869 --> 00:36:44.410
so in the book, I
take account of all

00:36:44.410 --> 00:36:45.400
these different approaches.

00:36:45.400 --> 00:36:47.108
So one of the approaches
people often say

00:36:47.108 --> 00:36:50.430
is, well, we should
have sanctions, right,

00:36:50.430 --> 00:36:51.330
against employers.

00:36:51.330 --> 00:36:53.490
If you hire someone
who's undocumented,

00:36:53.490 --> 00:36:55.270
we should sanction the employer.

00:36:55.270 --> 00:36:58.050
And in fact, in 1970,
the state of California,

00:36:58.050 --> 00:37:02.010
under Governor Ronald
Reagan, a former movie actor,

00:37:02.010 --> 00:37:04.140
passes a law to do this.

00:37:04.140 --> 00:37:08.940
And in fact, that following
month after it was passed,

00:37:08.940 --> 00:37:13.560
the department responsible for
it lost 79 out of 80 employees,

00:37:13.560 --> 00:37:16.380
leaving one person to enforce
the law in the whole state.

00:37:16.380 --> 00:37:18.580
That law was actually
never enforced ever.

00:37:18.580 --> 00:37:21.780
And again and again, there
is an appeal to this idea

00:37:21.780 --> 00:37:23.970
that we can simply
solve this problem

00:37:23.970 --> 00:37:25.830
of excluding and
exploiting people

00:37:25.830 --> 00:37:28.560
by sanctioning employers.

00:37:28.560 --> 00:37:30.000
And it's never happened ever.

00:37:30.000 --> 00:37:32.640
There's too much pressure
on the other hand

00:37:32.640 --> 00:37:34.120
for large corporations.

00:37:34.120 --> 00:37:37.660
So I think we do need
to have open borders.

00:37:37.660 --> 00:37:38.730
We need to make sure--

00:37:38.730 --> 00:37:41.370
at least we need to make
sure that people who are here

00:37:41.370 --> 00:37:44.640
are protected under the same
kinds of laws and rights

00:37:44.640 --> 00:37:49.940
as people who are
citizens of this country.

00:37:49.940 --> 00:37:51.769
Did I bum everybody out?

00:37:51.769 --> 00:37:53.060
AUDIENCE: So I have a question.

00:37:53.060 --> 00:37:53.390
LOUIS HYMAN: Yeah.

00:37:53.390 --> 00:37:55.790
AUDIENCE: So if robots are
going to make everything, what

00:37:55.790 --> 00:37:59.110
about basic income for
everybody else so that if I

00:37:59.110 --> 00:38:02.250
own the robot, I'll send it
to work, and I can relax.

00:38:02.250 --> 00:38:03.000
LOUIS HYMAN: Sure.

00:38:03.000 --> 00:38:05.750
This is often like, what
about the basic income?

00:38:05.750 --> 00:38:08.210
So in the future, people
will be worthless.

00:38:08.210 --> 00:38:10.490
In the future, all
that will matter

00:38:10.490 --> 00:38:14.390
will be programmers, and other
technologists, and engineers.

00:38:14.390 --> 00:38:17.060
And I talk about, this is
often something I hear.

00:38:17.060 --> 00:38:18.960
Like, oh, I'm the only
one that's worthwhile.

00:38:18.960 --> 00:38:23.215
Well, I think that there
are actually lots of things

00:38:23.215 --> 00:38:25.340
that people do that are
worthwhile besides computer

00:38:25.340 --> 00:38:27.050
programming.

00:38:27.050 --> 00:38:28.874
And I think as we
look to the future--

00:38:28.874 --> 00:38:30.290
as I think, actually,
you guys all

00:38:30.290 --> 00:38:33.180
agree, as we look
to the future--

00:38:33.180 --> 00:38:36.380
we should be thinking about
how we can use technology

00:38:36.380 --> 00:38:40.410
to liberate us, do work
that is more human.

00:38:40.410 --> 00:38:42.530
And just as mechanical
thresher meant

00:38:42.530 --> 00:38:46.010
that we didn't have to all
go in and reap the harvest,

00:38:46.010 --> 00:38:48.380
we can use automation
to liberate us

00:38:48.380 --> 00:38:49.866
from tedium, from paperwork.

00:38:49.866 --> 00:38:51.740
And this is something
we have to take account

00:38:51.740 --> 00:38:57.380
of as we think about the future,
how work can become more human.

00:38:57.380 --> 00:39:01.586
We can become caring, and
curious, and creative together.

00:39:01.586 --> 00:39:02.960
And the basic
income is certainly

00:39:02.960 --> 00:39:04.336
one approach to do this.

00:39:04.336 --> 00:39:05.960
It's certainly a very
liberal approach.

00:39:05.960 --> 00:39:08.450
It's approach that
has a lot of appeal.

00:39:08.450 --> 00:39:11.060
But it also is in contrast to
a lot of the political values

00:39:11.060 --> 00:39:12.200
that Americans have.

00:39:12.200 --> 00:39:14.630
So another approach, a
more conservative approach,

00:39:14.630 --> 00:39:16.460
would simply be,
do something that

00:39:16.460 --> 00:39:20.150
is modeled on the 401(k), where,
as you move from job to job,

00:39:20.150 --> 00:39:24.350
you are able to take your
retirement, and health care,

00:39:24.350 --> 00:39:26.090
and other kinds of
benefits with you.

00:39:26.090 --> 00:39:29.750
I think what's important here is
not the specific policy that we

00:39:29.750 --> 00:39:32.990
use to address this new
independent workforce, or even

00:39:32.990 --> 00:39:34.610
automation.

00:39:34.610 --> 00:39:37.310
It's that we need to
make sure that we're not

00:39:37.310 --> 00:39:39.590
just nostalgic for
the past and try

00:39:39.590 --> 00:39:42.860
to return to this old
world, whether you're

00:39:42.860 --> 00:39:45.140
a Republican or a Democrat.

00:39:45.140 --> 00:39:49.340
I also think that as we think
about solutions to this,

00:39:49.340 --> 00:39:54.350
we need to acknowledge that
the automation has never

00:39:54.350 --> 00:39:56.670
fully replaced the
need for people,

00:39:56.670 --> 00:40:00.180
and that people will
always be of value.

00:40:00.180 --> 00:40:05.270
AUDIENCE: One sense I got from
this talk was that automation--

00:40:05.270 --> 00:40:08.760
you said Apple kept claiming
that they were going to do

00:40:08.760 --> 00:40:11.310
fully automated factories.

00:40:11.310 --> 00:40:15.960
But it seems like that will not
happen, that the temp work will

00:40:15.960 --> 00:40:21.480
just change hands, in this
case, from Silicon Valley

00:40:21.480 --> 00:40:24.510
to Singapore, and
then from Singapore

00:40:24.510 --> 00:40:27.900
maybe to somewhere else.

00:40:27.900 --> 00:40:30.600
Is that a conclusion
that you have come to?

00:40:30.600 --> 00:40:33.210
Or do you think that
we will eventually

00:40:33.210 --> 00:40:39.219
reach a point that automation
does actually happen?

00:40:39.219 --> 00:40:41.010
LOUIS HYMAN: Well,
automation has certainly

00:40:41.010 --> 00:40:44.724
already happened in the sense of
increasing productivity, right?

00:40:44.724 --> 00:40:46.890
I mean, if you think about
things like agriculture--

00:40:46.890 --> 00:40:48.560
the best analog is not--

00:40:48.560 --> 00:40:50.880
in the AI world of
tomorrow, is not--

00:40:50.880 --> 00:40:52.590
industry, it's agriculture.

00:40:52.590 --> 00:40:54.870
So that less than
2% of the workforce

00:40:54.870 --> 00:40:58.770
now feeds all the rest of us.

00:40:58.770 --> 00:41:01.410
And those people are able
to do other kinds of things.

00:41:01.410 --> 00:41:02.970
The thing I think--

00:41:02.970 --> 00:41:07.410
the rhetorical value--
the rhetorical consequent

00:41:07.410 --> 00:41:10.530
of automation and
robotics is imagining

00:41:10.530 --> 00:41:13.620
a future in which the
present is erased, right,

00:41:13.620 --> 00:41:15.450
and that some
people are left out

00:41:15.450 --> 00:41:19.040
of this new economy, or
the contemporary economy,

00:41:19.040 --> 00:41:20.280
and treated badly.

00:41:20.280 --> 00:41:23.430
And that's the kind
of thing that I'm

00:41:23.430 --> 00:41:25.680
trying to push back against,
I think, in this history.

00:41:25.680 --> 00:41:27.450
AUDIENCE: Yeah,
and it just seems

00:41:27.450 --> 00:41:33.080
like when one source,
when one person to erase

00:41:33.080 --> 00:41:36.170
has been erased, they'll
just move onto the next one

00:41:36.170 --> 00:41:37.250
is what I mean.

00:41:37.250 --> 00:41:38.120
LOUIS HYMAN: Yeah,
it's a problem--

00:41:38.120 --> 00:41:38.750
AUDIENCE: It just
seems like it's

00:41:38.750 --> 00:41:41.270
going to keep going that
way, that we're never

00:41:41.270 --> 00:41:46.490
going to actually get
that perfect automation.

00:41:46.490 --> 00:41:48.126
We'll just find another group.

00:41:48.126 --> 00:41:50.000
LOUIS HYMAN: Well, that
would be unfortunate.

00:41:50.000 --> 00:41:52.880
I'd like to think that we'd
be able to make progress

00:41:52.880 --> 00:41:55.280
in not just playing
whack-a-mole where we're

00:41:55.280 --> 00:41:58.460
the moles that get whacked
all around the world because

00:41:58.460 --> 00:41:59.565
of automation.

00:41:59.565 --> 00:42:01.700
I do think automation--

00:42:01.700 --> 00:42:04.580
there's a lot of ways
in which narrow AI has

00:42:04.580 --> 00:42:06.740
a lot of opportunities
here, as I'm sure all of you

00:42:06.740 --> 00:42:10.000
can talk to me more about
than I can talk to you about.

00:42:10.000 --> 00:42:12.140
And machine learning
is exciting.

00:42:12.140 --> 00:42:15.470
But I do think it's going
to be relatively constrained

00:42:15.470 --> 00:42:17.425
and not take over
every aspect of life.

00:42:17.425 --> 00:42:18.800
AUDIENCE: Of course
I don't think

00:42:18.800 --> 00:42:22.040
it's going to take over
every aspect right now.

00:42:22.040 --> 00:42:24.890
I'm just probably
badly extrapolating

00:42:24.890 --> 00:42:28.944
from the story shown
in this talk so far.

00:42:28.944 --> 00:42:31.110
LOUIS HYMAN: Well, I think
that's also a good point.

00:42:31.110 --> 00:42:33.080
So the question
is, fundamentally,

00:42:33.080 --> 00:42:34.536
can things get better?

00:42:34.536 --> 00:42:35.660
Is that what you're saying?

00:42:35.660 --> 00:42:37.201
And I think one of
the things that we

00:42:37.201 --> 00:42:39.020
can learn from the
history of capitalism

00:42:39.020 --> 00:42:40.560
is that it can be
more inclusive.

00:42:40.560 --> 00:42:43.280
I think things in our
economy is more inclusive

00:42:43.280 --> 00:42:45.090
than it was 40 years ago.

00:42:45.090 --> 00:42:48.050
It's certainly more inclusive
than it was 400 years ago.

00:42:48.050 --> 00:42:50.570
And we can change the
foundations of capitalism

00:42:50.570 --> 00:42:51.240
as we want.

00:42:51.240 --> 00:42:56.600
So in 1850, 55% of
the GDP of America

00:42:56.600 --> 00:43:00.290
was based on enslaved people
or the products they produced.

00:43:00.290 --> 00:43:04.070
And yet 10, 15 years-- and
15 years later, it's not.

00:43:04.070 --> 00:43:06.110
And so we can remoor
the foundation.

00:43:06.110 --> 00:43:08.510
For me, this is a
tremendous opportunity

00:43:08.510 --> 00:43:11.240
to think about, well, how
do we remake capitalism

00:43:11.240 --> 00:43:14.000
so that it works for
more people, you know?

00:43:14.000 --> 00:43:17.450
And I think that's something
we need to consider as we--

00:43:17.450 --> 00:43:20.060
whether we want automation
to make a few people rich,

00:43:20.060 --> 00:43:22.510
or whether we want it to just--

00:43:22.510 --> 00:43:24.089
or to liberate the rest of us.

00:43:24.089 --> 00:43:25.880
AUDIENCE: Yeah, and I
guess my point is not

00:43:25.880 --> 00:43:27.590
that things don't get better.

00:43:27.590 --> 00:43:29.840
It's more, how
long can we keep--

00:43:29.840 --> 00:43:32.270
can this game keep
being played for?

00:43:32.270 --> 00:43:35.060
Because so far,
at least for now,

00:43:35.060 --> 00:43:36.660
it seems like that's
what we're doing.

00:43:36.660 --> 00:43:38.620
We're just going to
keep playing this game.

00:43:38.620 --> 00:43:39.440
LOUIS HYMAN: Well, I
think we have a choice

00:43:39.440 --> 00:43:40.500
about playing the game.

00:43:40.500 --> 00:43:41.930
And I think that's a
great point though.

00:43:41.930 --> 00:43:42.804
That's a great point.

00:43:42.804 --> 00:43:46.430
AUDIENCE: So you mentioned that
automation cannot completely

00:43:46.430 --> 00:43:47.750
replace people.

00:43:47.750 --> 00:43:50.180
So I'm curious to hear your
perspective about a scenario

00:43:50.180 --> 00:43:53.200
where automation does
replace people entirely,

00:43:53.200 --> 00:43:55.320
let's say if you
have machines that

00:43:55.320 --> 00:43:58.220
are as smart, and
as intelligent,

00:43:58.220 --> 00:43:59.330
and creative as humans.

00:43:59.330 --> 00:44:00.080
LOUIS HYMAN: Yeah.

00:44:00.080 --> 00:44:01.121
AUDIENCE: At that point--

00:44:01.121 --> 00:44:03.409
I mean, from your perspective,
what do you think?

00:44:03.409 --> 00:44:04.700
LOUIS HYMAN: What would happen?

00:44:04.700 --> 00:44:05.670
So in that scenario?

00:44:05.670 --> 00:44:09.410
AUDIENCE: How would that
change society as we know it?

00:44:09.410 --> 00:44:10.910
LOUIS HYMAN: Well,
I mean, I think

00:44:10.910 --> 00:44:13.370
people are valuable not just
because they're smart, right?

00:44:13.370 --> 00:44:15.170
So people are valuable
insofar as they

00:44:15.170 --> 00:44:17.120
can care for one
another, insofar

00:44:17.120 --> 00:44:19.760
as they can create
for one another.

00:44:19.760 --> 00:44:21.740
So if you're just
talking about a future

00:44:21.740 --> 00:44:25.460
where you're like a "Westworld"
general AI scenario where

00:44:25.460 --> 00:44:27.280
the robots are as smart as us--

00:44:27.280 --> 00:44:28.520
AUDIENCE: Yeah, so imagine--

00:44:28.520 --> 00:44:28.895
LOUIS HYMAN: "Terminator?"

00:44:28.895 --> 00:44:30.920
AUDIENCE: --an AI
scenario, I which may not

00:44:30.920 --> 00:44:33.440
be that close as we think.

00:44:33.440 --> 00:44:36.390
But let's say, if that happens,
from your perspective--

00:44:36.390 --> 00:44:37.520
I'm just curious.

00:44:37.520 --> 00:44:40.380
LOUIS HYMAN: Yeah, no,
I mean, I would be--

00:44:40.380 --> 00:44:42.500
it would fall-- like
most science fiction,

00:44:42.500 --> 00:44:45.740
it would fall into
the 100% dystopian

00:44:45.740 --> 00:44:49.830
and scary or 100% utopian
and kind of boring, right?

00:44:49.830 --> 00:44:52.170
We would just sit around just
eating ice cream all day,

00:44:52.170 --> 00:44:55.070
which is boring but
kind of wonderful.

00:44:55.070 --> 00:44:56.660
My suspicion is it's
going to be more

00:44:56.660 --> 00:44:59.720
like the mechanical thresher
in that technologies

00:44:59.720 --> 00:45:01.370
will accelerate productivity.

00:45:01.370 --> 00:45:03.590
They will displace
segments of the workforce.

00:45:03.590 --> 00:45:05.690
And we'll have to
figure out what to do

00:45:05.690 --> 00:45:06.920
with the rest of the people.

00:45:06.920 --> 00:45:09.740
So coming out of this
agricultural revolution,

00:45:09.740 --> 00:45:12.980
we had to really tool up the
way we educated our people.

00:45:12.980 --> 00:45:15.380
So this is the moment when
people become literate,

00:45:15.380 --> 00:45:18.380
when they begin to go to
school in the 1920s and '30s.

00:45:18.380 --> 00:45:21.200
And that kind of
industrial education

00:45:21.200 --> 00:45:22.850
worked well for
an industrial age.

00:45:22.850 --> 00:45:25.050
And we found other
uses for them.

00:45:25.050 --> 00:45:27.530
So I think the
trick is, nowadays,

00:45:27.530 --> 00:45:30.530
our educational system is
not built to teach people

00:45:30.530 --> 00:45:32.060
how to learn how to learn.

00:45:32.060 --> 00:45:34.010
It's built to
teach them to obey.

00:45:34.010 --> 00:45:35.960
And we need to have an
educational system that

00:45:35.960 --> 00:45:40.400
does encourage curiosity and
creativity for the new kind

00:45:40.400 --> 00:45:41.210
of economy to come.

00:45:41.210 --> 00:45:45.170
If this happens, I don't think
history will matter at all.

00:45:45.170 --> 00:45:48.680
Because that kind of
world of general AI

00:45:48.680 --> 00:45:51.110
will be just something
that I probably imagine

00:45:51.110 --> 00:45:54.560
you or I can't
fully think about.

00:45:54.560 --> 00:45:55.370
Yeah.

00:45:55.370 --> 00:45:57.380
AUDIENCE: Yeah, so I know
the focus of your talk

00:45:57.380 --> 00:45:59.810
was primarily on
the past and how

00:45:59.810 --> 00:46:01.550
we should use it to
frame the way that we

00:46:01.550 --> 00:46:04.480
think about the present and
how we want to mold the future.

00:46:04.480 --> 00:46:06.830
It was more focused on
generalities rather than

00:46:06.830 --> 00:46:08.087
specific public policy.

00:46:08.087 --> 00:46:09.920
You mentioned corporate
sanctions as an idea

00:46:09.920 --> 00:46:11.180
that we shouldn't try.

00:46:11.180 --> 00:46:13.010
But surely there must
be public policies

00:46:13.010 --> 00:46:15.350
that you think we should be
advocating for, you know,

00:46:15.350 --> 00:46:17.810
either internally, as
members of a corporation,

00:46:17.810 --> 00:46:19.820
or as citizens
who vote, in order

00:46:19.820 --> 00:46:22.580
to shape the future that
would be more pleasant.

00:46:22.580 --> 00:46:24.120
What are some of those policies?

00:46:24.120 --> 00:46:24.830
LOUIS HYMAN: Some
of those policies

00:46:24.830 --> 00:46:26.204
are laid in this
delightful book,

00:46:26.204 --> 00:46:28.640
available for sale in
the back of the room.

00:46:28.640 --> 00:46:29.360
AUDIENCE: I've
already bought mine.

00:46:29.360 --> 00:46:30.734
Everyone else
should do the same.

00:46:30.734 --> 00:46:33.210
LOUIS HYMAN: They make wonderful
doorstops, or kindling,

00:46:33.210 --> 00:46:35.040
depending on your proclivities.

00:46:35.040 --> 00:46:40.080
So I think that there are lots
of policies that one could go.

00:46:40.080 --> 00:46:42.270
In the book, I lay out
both very conservative ones

00:46:42.270 --> 00:46:45.660
so you can talk about it
with your Republican friends.

00:46:45.660 --> 00:46:47.940
You can also talk about it
with your liberal friends.

00:46:47.940 --> 00:46:51.510
I think what's important
is that we choose to make--

00:46:51.510 --> 00:46:54.510
to recognize what's
happening, that this is--

00:46:54.510 --> 00:46:57.720
that half of people
under 34 are working

00:46:57.720 --> 00:47:00.420
in this freelance economy,
right, in this gig economy,

00:47:00.420 --> 00:47:04.920
in this temp economy, and
that this reality is not

00:47:04.920 --> 00:47:06.070
being talked about, right?

00:47:06.070 --> 00:47:08.250
We are treating
it as, this is not

00:47:08.250 --> 00:47:10.110
"real work" this
is not "real job."

00:47:10.110 --> 00:47:12.210
Well, this is where
people are, right?

00:47:12.210 --> 00:47:15.540
And I think that this
book is trying to put

00:47:15.540 --> 00:47:17.220
that in a longer perspective.

00:47:17.220 --> 00:47:21.000
So people talk about it as
if it's Uber, and the apps,

00:47:21.000 --> 00:47:22.540
and the phones, and
stuff like that.

00:47:22.540 --> 00:47:25.150
Well, this has been
going on for a long time.

00:47:25.150 --> 00:47:26.970
And we need to
understand that it's

00:47:26.970 --> 00:47:30.570
choices we're making about
big corporations, how

00:47:30.570 --> 00:47:33.330
they treat the people
who work for them

00:47:33.330 --> 00:47:34.440
in a temporary fashion.

00:47:34.440 --> 00:47:38.100
Large tech firms often
have numbers of contractors

00:47:38.100 --> 00:47:40.770
and other kinds
of subcontractors.

00:47:40.770 --> 00:47:43.230
What is the relationship
between them and the, quote,

00:47:43.230 --> 00:47:45.615
"real employees?"

00:47:45.615 --> 00:47:50.230
How do we even value companies
like that if we look at them?

00:47:50.230 --> 00:47:52.740
You know, one of the reasons
we value a company so much is

00:47:52.740 --> 00:47:54.810
how low their headcount is.

00:47:54.810 --> 00:47:56.424
The fewer employees, the better.

00:47:56.424 --> 00:47:57.840
So how do we think
about valuation

00:47:57.840 --> 00:48:00.880
if they want to embed not
just money, but our values?

00:48:00.880 --> 00:48:02.657
So this is an
important question.

00:48:02.657 --> 00:48:04.740
AUDIENCE: So there's no
one specific public policy

00:48:04.740 --> 00:48:05.850
you want to get
up on your soapbox

00:48:05.850 --> 00:48:07.260
and advocate for more
than a [INAUDIBLE]??

00:48:07.260 --> 00:48:08.350
LOUIS HYMAN: There's
no silver bullet.

00:48:08.350 --> 00:48:10.110
There's no, like,
let's get basic income,

00:48:10.110 --> 00:48:11.880
and then everything will be OK.

00:48:11.880 --> 00:48:14.490
Or let's put employer
sanctions in place,

00:48:14.490 --> 00:48:16.560
and then everything
will be OK, right?

00:48:16.560 --> 00:48:19.660
If there were a simple answer,
we already would have done it.

00:48:19.660 --> 00:48:21.690
And I think what
we need to do is

00:48:21.690 --> 00:48:24.300
have a larger, more
expansive conversation that

00:48:24.300 --> 00:48:29.230
talks about the big question
of how do we create security

00:48:29.230 --> 00:48:32.160
in a world where work
is more insecure.

00:48:32.160 --> 00:48:34.980
And maybe we decouple, in
many different possible ways,

00:48:34.980 --> 00:48:38.970
depending on our
political consensus, how

00:48:38.970 --> 00:48:42.150
that security may no longer
relate to the job, right,

00:48:42.150 --> 00:48:43.360
and split those things apart.

00:48:43.360 --> 00:48:45.210
So one of the things I
think a lot about is,

00:48:45.210 --> 00:48:48.360
how is the job like
marriage, right?

00:48:48.360 --> 00:48:50.070
How is work like
marriage, right?

00:48:50.070 --> 00:48:53.790
Very few people these days
are getting married, right?

00:48:53.790 --> 00:48:56.190
And yet we're still trying
to rebuild our social system,

00:48:56.190 --> 00:48:59.040
or our social norms, addressing
this problem of, what happens

00:48:59.040 --> 00:49:01.002
to children coming out of--

00:49:01.002 --> 00:49:02.710
they're are born out
of marriages, right?

00:49:02.710 --> 00:49:05.190
And this is the norm now.

00:49:05.190 --> 00:49:06.264
That's happening.

00:49:06.264 --> 00:49:07.430
We have to acknowledge that.

00:49:07.430 --> 00:49:09.720
I mean, we don't-- we want
those kids to grow up well.

00:49:09.720 --> 00:49:11.387
We want this to be
the world that we--

00:49:11.387 --> 00:49:12.720
that people are treated well in.

00:49:12.720 --> 00:49:14.640
Similarly for work, the norm--

00:49:14.640 --> 00:49:20.520
a few very privileged people
are allowed to have secure jobs.

00:49:20.520 --> 00:49:22.470
Like, I have a lot of security.

00:49:22.470 --> 00:49:24.510
I'm a tenured professor
at a school, right?

00:49:24.510 --> 00:49:26.400
So I am part of this old world.

00:49:26.400 --> 00:49:29.400
70% of professors are
adjuncts, you know?

00:49:29.400 --> 00:49:31.680
They make $2,000
to $3,000 a course.

00:49:31.680 --> 00:49:33.720
Their lives are immiserating.

00:49:33.720 --> 00:49:37.470
And it's important that people
like me say that's not OK.

00:49:37.470 --> 00:49:39.802
Or how do we take this
kind of flexibility

00:49:39.802 --> 00:49:41.010
and create security for them?

00:49:41.010 --> 00:49:44.070
And similarly, for those who
are in positions where they have

00:49:44.070 --> 00:49:47.310
security in their lives to
speak for these other people

00:49:47.310 --> 00:49:48.770
that don't have
as much security--

00:49:48.770 --> 00:49:50.970
and I think that's
just being humane.

00:49:50.970 --> 00:49:52.220
It was a good question though.

00:49:52.220 --> 00:49:52.970
Thank you so much.

00:49:52.970 --> 00:49:54.080
AUDIENCE: Thank you.

00:49:54.080 --> 00:49:56.250
AUDIENCE: My question is
a little bit off-topic.

00:49:56.250 --> 00:50:00.080
But you mentioned that post-war,
with traditional industries,

00:50:00.080 --> 00:50:02.210
the workers would have unions.

00:50:02.210 --> 00:50:06.200
But for us, software
engineers, I

00:50:06.200 --> 00:50:09.040
don't think we have a union
or any kind of those things.

00:50:09.040 --> 00:50:12.140
Do think, because of the nature
of the job, it's not necessary?

00:50:12.140 --> 00:50:14.602
Or it is just a problem
that we just ignore?

00:50:14.602 --> 00:50:16.310
LOUIS HYMAN: Do you
want to have a union?

00:50:16.310 --> 00:50:17.518
AUDIENCE: Software engineers?

00:50:17.518 --> 00:50:18.965
LOUIS HYMAN: Yeah.

00:50:18.965 --> 00:50:20.030
AUDIENCE: I don't know.

00:50:20.030 --> 00:50:21.414
That's why I'm asking.

00:50:21.414 --> 00:50:23.330
LOUIS HYMAN: Yeah, I
mean, I think it depends.

00:50:23.330 --> 00:50:25.089
You need a union if
you feel like you--

00:50:25.089 --> 00:50:26.630
I mean, for me,
generally, it's like,

00:50:26.630 --> 00:50:29.720
you need a union if you feel
like you don't have agency

00:50:29.720 --> 00:50:33.050
in how you control your own
work process and your own life,

00:50:33.050 --> 00:50:35.571
and you feel like
you're being mistreated.

00:50:35.571 --> 00:50:37.820
I suspect you feel like
you're worked a lot at Google,

00:50:37.820 --> 00:50:40.041
but you're not
mistreated exactly.

00:50:40.041 --> 00:50:42.290
You know, I think that's
very different than if you're

00:50:42.290 --> 00:50:46.587
in a dead-end job where the
boss kind of dictates to you,

00:50:46.587 --> 00:50:48.170
and you feel like
you have no control.

00:50:48.170 --> 00:50:51.314
Historically, that's only--
so I would worry less about--

00:50:51.314 --> 00:50:53.230
I don't worry as much
about software engineers

00:50:53.230 --> 00:50:55.370
unless I know them and
they're friends of mine,

00:50:55.370 --> 00:50:57.330
that I work with them
on a personal level.

00:50:57.330 --> 00:51:01.490
But as a class of workers,
I'm not as worried about them

00:51:01.490 --> 00:51:04.370
as I am about janitors,
or GrubHub delivery

00:51:04.370 --> 00:51:06.342
people, or retail workers.

00:51:06.342 --> 00:51:08.800
You know, in the coming years--
the gentleman, earlier, was

00:51:08.800 --> 00:51:10.411
asking about automation.

00:51:10.411 --> 00:51:11.910
I kind of don't
believe in the world

00:51:11.910 --> 00:51:14.220
of general AI, and "Westworld,"
and stuff like that.

00:51:14.220 --> 00:51:16.520
But I do think retail workers
will all lose their jobs

00:51:16.520 --> 00:51:18.119
in the next 15 years.

00:51:18.119 --> 00:51:19.910
This is where most
people work, and they're

00:51:19.910 --> 00:51:21.456
going to lose their employment.

00:51:21.456 --> 00:51:24.080
Now software engineers, you guys
have a lot to worry about too,

00:51:24.080 --> 00:51:24.579
right?

00:51:24.579 --> 00:51:26.270
I mean there's a lot
of contract work.

00:51:26.270 --> 00:51:29.450
You know, at Google, you're
kind of at the Cornell,

00:51:29.450 --> 00:51:36.569
or the Harvard, or whatever,
or Dartmouth of software,

00:51:36.569 --> 00:51:37.610
so you're not as worried.

00:51:37.610 --> 00:51:40.040
But a lot of people in
software engineering

00:51:40.040 --> 00:51:43.426
have very tenuous, precarious
jobs as software engineers.

00:51:43.426 --> 00:51:45.050
And there's a lot of
things coming down

00:51:45.050 --> 00:51:47.300
the pipeline that seem like
it could automate software

00:51:47.300 --> 00:51:48.560
engineering as well.

00:51:48.560 --> 00:51:51.470
But I think the trick is
that software engineering,

00:51:51.470 --> 00:51:53.342
as you guys literally all--

00:51:53.342 --> 00:51:55.300
every single one of you
knows better than I do,

00:51:55.300 --> 00:51:58.010
is not just coding, but
being creative, right,

00:51:58.010 --> 00:52:00.122
thinking analytically
about algorithms.

00:52:00.122 --> 00:52:01.580
And I don't think
a computer can do

00:52:01.580 --> 00:52:03.650
that as well as a human being.

00:52:03.650 --> 00:52:06.470
AUDIENCE: Well, I'm not
mostly worried about myself.

00:52:06.470 --> 00:52:10.430
As you mentioned, there's a
lot of, like, contract coders,

00:52:10.430 --> 00:52:15.530
or freelancers, which,
in general, are not

00:52:15.530 --> 00:52:21.154
protected by any kind of
unions or laws, anything.

00:52:21.154 --> 00:52:23.570
LOUIS HYMAN: When people are
highly skilled and in demand,

00:52:23.570 --> 00:52:25.670
they don't need
unions as much, right?

00:52:25.670 --> 00:52:29.150
So I think that
programmers, as long

00:52:29.150 --> 00:52:31.196
as they are part of-- they
deliver lots of value,

00:52:31.196 --> 00:52:32.570
they're high-skilled,
they're not

00:52:32.570 --> 00:52:34.452
totally interchangeable--
despite what

00:52:34.452 --> 00:52:36.410
I read in Quora, I don't
think that programmers

00:52:36.410 --> 00:52:37.970
are interchangeable.

00:52:37.970 --> 00:52:40.700
And I think that there's
a lot of opportunity

00:52:40.700 --> 00:52:43.850
for people to work
remotely and be anywhere.

00:52:43.850 --> 00:52:47.420
One of the exciting things
about this economy is that--

00:52:47.420 --> 00:52:50.550
in the book, I write how
what's different about today

00:52:50.550 --> 00:52:51.774
is not AI.

00:52:51.774 --> 00:52:54.240
AI, narrow AI, is just
another way in which

00:52:54.240 --> 00:52:56.200
tools become more productive.

00:52:56.200 --> 00:52:58.620
What's different is we may no
longer need the corporation

00:52:58.620 --> 00:53:01.845
to access those tools,
that you can sell globally,

00:53:01.845 --> 00:53:04.590
you can work globally,
you can consume globally.

00:53:04.590 --> 00:53:07.680
And that the corporation
might no longer

00:53:07.680 --> 00:53:13.630
be necessary in capitalism
is a shocking transformation.

00:53:13.630 --> 00:53:17.190
So I think that that's what you
guys should be thinking about.

00:53:17.190 --> 00:53:22.290
How do we work in flexible teams
assembling production together?

00:53:22.290 --> 00:53:24.310
And so do you need a union?

00:53:24.310 --> 00:53:26.290
I think that's only
for you to decide.

00:53:26.290 --> 00:53:28.410
But I think unions are
really necessary when

00:53:28.410 --> 00:53:31.350
people don't have power unless
they work together Thank you.

00:53:31.350 --> 00:53:34.700
[APPLAUSE]

