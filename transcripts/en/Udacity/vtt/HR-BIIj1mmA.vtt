WEBVTT
Kind: captions
Language: en

00:00:00.100 --> 00:00:03.530
What we have just done here, is a very powerful idea in learning.

00:00:03.530 --> 00:00:08.420
Convergence is important. Because without convergence, a learning agent could

00:00:08.420 --> 00:00:13.660
zig zag forever in a large learning space. We want to ensure that the learning

00:00:13.660 --> 00:00:18.130
agent converges to some concept characterization, and that remains stable.

00:00:18.130 --> 00:00:22.210
This method guarantees convergence, as long as there is a sufficiently large

00:00:22.210 --> 00:00:27.050
number of examples. We needed five examples in this particular illustration, for

00:00:27.050 --> 00:00:31.290
the convergence to occur. This convergence would have occurred, irrespective of

00:00:31.290 --> 00:00:35.650
the order of the examples, as long as the five examples were there. Note that we

00:00:35.650 --> 00:00:39.360
did not use background knowledge like we did in incremental concept learning.

00:00:39.360 --> 00:00:43.180
Note also that we did not assume that the teacher was forwarding the examples in

00:00:43.180 --> 00:00:47.580
the right order. This is the benefit of version space learning. There is

00:00:47.580 --> 00:00:52.120
another feature to note. In incremental concept learning, we wanted each example

00:00:52.120 --> 00:00:56.460
different from the current concept characterization in exactly one feature, so

00:00:56.460 --> 00:01:00.970
that the learning agent could focus its attention. However inversion spaces,

00:01:00.970 --> 00:01:04.209
you can notice that each successful example, the first one,

00:01:04.209 --> 00:01:07.660
the previous one and many features, just look at the first two examples.

00:01:07.660 --> 00:01:11.466
They differ in many features in the name of the restaurant, in the meal,

00:01:11.466 --> 00:01:14.630
in the cost. Here is the algorithm for the version space technique.

00:01:14.630 --> 00:01:17.570
We'll go through it very quickly, because we've already illustrated it in

00:01:17.570 --> 00:01:23.900
detail. If the new example is positive, generalize all specific models included.

00:01:23.900 --> 00:01:26.960
Prune away the general models that cannot include the positive example.

00:01:28.250 --> 00:01:32.370
If the example is negative, specialize all the general models to include it.

00:01:32.370 --> 00:01:35.950
Prune away the specific models that cannot include the negative example.

00:01:35.950 --> 00:01:39.840
Prune away any models subsumed by the other models. Know that in this

00:01:39.840 --> 00:01:43.710
specific implementation of version space technique that we just illustrated,

00:01:43.710 --> 00:01:47.310
there is a single pathway coming from the most specialize concert model.

00:01:47.310 --> 00:01:53.390
And therefore there is no need to prune away specific models. In general,

00:01:53.390 --> 00:01:55.440
there could be multiple generalizations coming for

00:01:55.440 --> 00:01:57.770
the most specialized models, and this might be needed.

