WEBVTT
Kind: captions
Language: en

00:00:00.200 --> 00:00:02.730
BRIAN DORSEY: This is importing
large data sets into

00:00:02.730 --> 00:00:04.920
Google Cloud Storage.

00:00:04.920 --> 00:00:07.240
You're in the right room, and
thank you for coming or

00:00:07.240 --> 00:00:08.720
watching on video.

00:00:08.720 --> 00:00:10.960
My name is Brian Dorsey, and
I'm a developer programs

00:00:10.960 --> 00:00:15.306
engineer in developer relations
on Google Cloud.

00:00:15.306 --> 00:00:16.290
DAVE BARTH: I'm Dave Barth.

00:00:16.290 --> 00:00:21.160
I'm a product manager on
Google Cloud Storage.

00:00:21.160 --> 00:00:23.300
BRIAN DORSEY: And let's
get started.

00:00:23.300 --> 00:00:26.010
So very quickly we're going to
go through a tiny bit of

00:00:26.010 --> 00:00:27.380
background.

00:00:27.380 --> 00:00:30.910
We're going to run through
progressively larger size and

00:00:30.910 --> 00:00:32.350
scale imports.

00:00:32.350 --> 00:00:35.030
And then, talk a little bit
about how to post process your

00:00:35.030 --> 00:00:38.720
data, and how to integrate it
with your application, and

00:00:38.720 --> 00:00:43.820
some tips and tricks for all
scales of data imports, a

00:00:43.820 --> 00:00:46.510
special announcement, and
then, your questions.

00:00:46.510 --> 00:00:49.580
So let's get started.

00:00:49.580 --> 00:00:53.620
I expect that being this is an
importing talk, many of you

00:00:53.620 --> 00:00:56.040
are already familiar with Google
Cloud Storage, but I'm

00:00:56.040 --> 00:00:59.670
just going to run through a
few things quickly to make

00:00:59.670 --> 00:01:01.610
sure we're all coming
from the same place.

00:01:01.610 --> 00:01:06.660
This is a whole lot of words,
but to summarize, Google Cloud

00:01:06.660 --> 00:01:08.120
Storage has a ton of features.

00:01:08.120 --> 00:01:11.860
It is basically a container for
your data that lives in

00:01:11.860 --> 00:01:15.800
Google infrastructure and
communicates on the

00:01:15.800 --> 00:01:17.780
internet via HTTP.

00:01:17.780 --> 00:01:20.300
And we have a bunch of features
to make that HTTP

00:01:20.300 --> 00:01:24.770
communication very efficient
and easy to use, but that's

00:01:24.770 --> 00:01:26.360
the main part of it.

00:01:26.360 --> 00:01:31.200
It's also a project that is
under very active development.

00:01:31.200 --> 00:01:33.040
Just in the last year, we've
released a whole bunch of

00:01:33.040 --> 00:01:35.210
features on the bottom there,
which could be an entire talk

00:01:35.210 --> 00:01:37.710
in and of itself, but that's
not this talk.

00:01:37.710 --> 00:01:40.650
We're talking about
importing data.

00:01:40.650 --> 00:01:43.580
But I wanted to take a quick
moment and reflect on the

00:01:43.580 --> 00:01:47.560
awesome that is Google
Cloud Storage.

00:01:47.560 --> 00:01:50.360
I think all of you have used
applications and most of you

00:01:50.360 --> 00:01:52.770
have probably built applications
that store their

00:01:52.770 --> 00:01:54.270
data in files.

00:01:54.270 --> 00:01:54.870
Right?

00:01:54.870 --> 00:01:55.770
And that works out
pretty well.

00:01:55.770 --> 00:01:56.820
It's easy to get started.

00:01:56.820 --> 00:01:59.770
And at some point, you need
another disk and then, another

00:01:59.770 --> 00:02:01.120
disk and another disk.

00:02:01.120 --> 00:02:03.120
And at some point, you need
another machine because you

00:02:03.120 --> 00:02:05.710
filled that machine up, and you
start adding more machines

00:02:05.710 --> 00:02:06.970
and a little complexity
here and there.

00:02:06.970 --> 00:02:10.169
And then, you decide you need
the data somewhere else or

00:02:10.169 --> 00:02:12.640
maybe you need another copy
of it for redundancy.

00:02:12.640 --> 00:02:16.190
So that adds some complexity,
and it just keeps going.

00:02:16.190 --> 00:02:20.870
So at some point, you end up
with this gnarly knot of

00:02:20.870 --> 00:02:24.300
interconnected pieces on your
architectural diagram.

00:02:24.300 --> 00:02:29.810
And you're probably familiar
with the steps to get you from

00:02:29.810 --> 00:02:31.235
one place to the other.

00:02:31.235 --> 00:02:33.910
You've done it enough times as
you hit those levels, you know

00:02:33.910 --> 00:02:35.150
how to address that.

00:02:35.150 --> 00:02:38.810
But each time you do that,
that's an interruption from

00:02:38.810 --> 00:02:42.770
taking you away from building
features for your users.

00:02:42.770 --> 00:02:48.380
And we really think of Google
Cloud Storage as a way to

00:02:48.380 --> 00:02:53.480
trade that knot for a hosted
service from Google.

00:02:53.480 --> 00:02:57.300
And with a little bit of work
integrating the APIs on your

00:02:57.300 --> 00:02:59.900
part, you get to take advantage
of the scale of the

00:02:59.900 --> 00:03:04.450
Google Cloud Platform and all
of the redundancy speed that

00:03:04.450 --> 00:03:07.530
we provide through the system.

00:03:07.530 --> 00:03:11.410
It is a solution where you're
not going to have to worry

00:03:11.410 --> 00:03:12.710
about the scale.

00:03:12.710 --> 00:03:17.470
We have developers who have
literally billions of objects

00:03:17.470 --> 00:03:20.720
in a single bucket and
developers with multiple

00:03:20.720 --> 00:03:23.850
petabytes of data in a bucket.

00:03:23.850 --> 00:03:27.670
We're ready to take your data
and run with it and help you

00:03:27.670 --> 00:03:30.780
make your applications
amazing.

00:03:30.780 --> 00:03:33.600
And it's also very close to the
rest of the Google Cloud

00:03:33.600 --> 00:03:36.710
Platform, so it becomes a great
gateway to all the other

00:03:36.710 --> 00:03:40.510
work you might want to do in
BigQuery, Compute Engine, App

00:03:40.510 --> 00:03:41.510
Engine, and the like.

00:03:41.510 --> 00:03:42.920
We make that very easy.

00:03:42.920 --> 00:03:48.090
So let's move on to
smaller imports.

00:03:48.090 --> 00:03:51.970
These are things on the few
gigabyte scale or tens or

00:03:51.970 --> 00:03:53.400
hundreds of files.

00:03:53.400 --> 00:03:58.700
And in some ways, it's an excuse
to talk about gsutil.

00:03:58.700 --> 00:04:00.330
So just a quick question.

00:04:00.330 --> 00:04:04.120
How many people in the room
have heard of gsutil?

00:04:04.120 --> 00:04:06.590
And how many people have
actually used it?

00:04:06.590 --> 00:04:07.010
OK.

00:04:07.010 --> 00:04:09.120
Awesome.

00:04:09.120 --> 00:04:13.670
So quick demo just to give
you a sense of gsutil.

00:04:13.670 --> 00:04:16.579
I've got a directory here that's
living, actually, on a

00:04:16.579 --> 00:04:19.519
Compute Engine instance because
I want a pixel.

00:04:19.519 --> 00:04:23.270
And I've got some files here
that I would like to copy up

00:04:23.270 --> 00:04:24.840
into Google Cloud Storage.

00:04:24.840 --> 00:04:32.500
So I can say, gsutil cp data
star to GS some bucket name,

00:04:32.500 --> 00:04:38.480
and we're going to use I/O demo
as the bucket name, and

00:04:38.480 --> 00:04:39.810
it copies one file.

00:04:39.810 --> 00:04:41.410
But I actually meant to
copy all of these.

00:04:41.410 --> 00:04:44.900
And one of the things I'd like
to highlight here is gsutil

00:04:44.900 --> 00:04:46.530
tries very hard to
help you out.

00:04:46.530 --> 00:04:48.110
And it says, oh, did you
actually mean to do a

00:04:48.110 --> 00:04:50.610
recursive copy there?

00:04:50.610 --> 00:04:54.800
Perhaps you wanted the dash
capital R. And in fact, I did.

00:04:54.800 --> 00:04:57.840
So let's go ahead and do that.

00:04:57.840 --> 00:05:01.440
And then, we've now copied all
of that data up into Google

00:05:01.440 --> 00:05:05.380
Cloud Storage, and it's
available from anywhere.

00:05:05.380 --> 00:05:08.120
Cloud Storage also fairly
uniquely offers

00:05:08.120 --> 00:05:09.940
read-after-write consistency.

00:05:09.940 --> 00:05:14.680
So as soon as you get the OK
back, they're available to the

00:05:14.680 --> 00:05:15.510
whole world.

00:05:15.510 --> 00:05:18.630
Exactly that version.

00:05:18.630 --> 00:05:24.290
Quickly, we can go ahead and run
an LS command on this same

00:05:24.290 --> 00:05:28.030
bucket, and we should see
a different result here.

00:05:28.030 --> 00:05:28.840
Look at that.

00:05:28.840 --> 00:05:30.700
We've got some data up there.

00:05:30.700 --> 00:05:34.070
Another way to look at the same
data is in the Google

00:05:34.070 --> 00:05:36.220
Cloud Counsel.

00:05:36.220 --> 00:05:39.980
This is our new UI for
the various Google

00:05:39.980 --> 00:05:42.240
Cloud Platform APIs.

00:05:42.240 --> 00:05:45.200
And the Cloud Storage version
of this was, in fact, just

00:05:45.200 --> 00:05:47.260
released last week.

00:05:47.260 --> 00:05:49.320
So I encourage you to
take a look at that.

00:05:49.320 --> 00:05:53.170
If we come down here and switch
back and forth between

00:05:53.170 --> 00:05:55.890
the buckets, we can see
the same thing there.

00:05:55.890 --> 00:05:59.240
So you can go ahead and work
through the web UI as well.

00:06:02.330 --> 00:06:05.380
So in a way, this talk is going
to be a little bit of a

00:06:05.380 --> 00:06:06.630
love song four gsutil.

00:06:09.820 --> 00:06:11.500
Here's how you get it.

00:06:11.500 --> 00:06:14.300
The tried and true way is go
ahead and download a zip or

00:06:14.300 --> 00:06:17.950
tarball and extract that out,
and you're good to go.

00:06:17.950 --> 00:06:21.130
We've also just started a
developer preview of the

00:06:21.130 --> 00:06:25.500
Google Cloud SDK, and that is
a collection of tools for

00:06:25.500 --> 00:06:29.880
Cloud Storage, Compute Engine,
BigQuery, App Engine, all

00:06:29.880 --> 00:06:32.910
bundled together in one download
and install with

00:06:32.910 --> 00:06:33.590
consistent auth.

00:06:33.590 --> 00:06:35.190
So you do the authorization
once, and it works

00:06:35.190 --> 00:06:38.420
across all the tools.

00:06:38.420 --> 00:06:41.030
We've also, for Python
programmers, gsutil

00:06:41.030 --> 00:06:43.130
is written in Python.

00:06:43.130 --> 00:06:47.230
It's open source up on GitHub,
and it is mostly based at the

00:06:47.230 --> 00:06:49.890
lower levels on top of
the boto library for

00:06:49.890 --> 00:06:51.710
communicating.

00:06:51.710 --> 00:06:53.940
And if you're a Python developer
or you're working in

00:06:53.940 --> 00:06:55.790
a Python stack, it might
make sense to

00:06:55.790 --> 00:06:57.360
you to use pip install.

00:06:57.360 --> 00:06:58.810
And we've got an experimental
release where you

00:06:58.810 --> 00:07:01.860
can do that as well.

00:07:01.860 --> 00:07:05.670
One of the key things gsutil
provides is a conceptual path

00:07:05.670 --> 00:07:07.010
abstraction.

00:07:07.010 --> 00:07:10.630
The Cloud Storage itself
is a flat name

00:07:10.630 --> 00:07:12.050
space within a bucket.

00:07:12.050 --> 00:07:13.830
So you can have as many
names as you want,

00:07:13.830 --> 00:07:14.790
but it's a flat space.

00:07:14.790 --> 00:07:18.030
It is not actually aware
of hierarchy.

00:07:18.030 --> 00:07:20.680
But gsutil goes and tries to
give you a sense of hierarchy

00:07:20.680 --> 00:07:22.750
because you're usually going
back and forth between file

00:07:22.750 --> 00:07:26.050
systems and the cloud, and it
just makes it easier to say I

00:07:26.050 --> 00:07:28.770
want to copy a subdirectory
here, and that sort of thing.

00:07:28.770 --> 00:07:32.570
So it tries very hard to give
you commands that look like

00:07:32.570 --> 00:07:36.340
the regular Unix commands you're
used to with a couple

00:07:36.340 --> 00:07:39.150
exceptions around buckets
and the like.

00:07:39.150 --> 00:07:41.850
It also provides complete
feature

00:07:41.850 --> 00:07:43.890
support for the product.

00:07:43.890 --> 00:07:46.520
So Google Cloud Storage
has many features

00:07:46.520 --> 00:07:47.660
that are very useful.

00:07:47.660 --> 00:07:49.900
For example, hosting
static websites

00:07:49.900 --> 00:07:52.050
directly from Cloud Storage.

00:07:52.050 --> 00:07:57.830
And you can configure those
features through extensions.

00:07:57.830 --> 00:07:59.080
Gsutil provides those.

00:08:01.760 --> 00:08:05.480
And for smaller data sets, we
can go ahead and just do a

00:08:05.480 --> 00:08:07.530
straight cp, and
that's plenty.

00:08:07.530 --> 00:08:09.100
It works out great.

00:08:09.100 --> 00:08:11.800
Here's some example command
lines of going back and forth

00:08:11.800 --> 00:08:16.810
between text files and Google
Cloud Storage, back down.

00:08:16.810 --> 00:08:19.690
It also, since it's based on the
boto library, it inherits

00:08:19.690 --> 00:08:21.850
the ability to talk
to Amazon S3.

00:08:21.850 --> 00:08:24.930
So you can use gsutil to
talk to S3 if you're

00:08:24.930 --> 00:08:26.750
already using S3.

00:08:26.750 --> 00:08:32.490
And you can also copy back and
forth between S3 and Google

00:08:32.490 --> 00:08:34.789
Cloud Storage.

00:08:34.789 --> 00:08:36.705
Those copies do go through
the machine that

00:08:36.705 --> 00:08:38.230
you run gsutil on.

00:08:38.230 --> 00:08:39.919
So be aware that.

00:08:39.919 --> 00:08:47.150
And also, just as a thought to
put in your head, gsutil is

00:08:47.150 --> 00:08:53.580
essentially a reference to how
to make good applications.

00:08:53.580 --> 00:08:54.740
Talk to Google Cloud Storage.

00:08:54.740 --> 00:08:58.240
It's a reference implementation
of efficiently

00:08:58.240 --> 00:09:00.630
communicating with
Cloud Storage.

00:09:00.630 --> 00:09:04.680
And if you just go ahead and
do a straight gsutil cp,

00:09:04.680 --> 00:09:07.210
what's the first limit you're
going to run into?

00:09:07.210 --> 00:09:12.500
And I predict it will
be network latency.

00:09:12.500 --> 00:09:15.640
By default, gsutil does
one thing at a time.

00:09:15.640 --> 00:09:18.430
So if you've got 100 files or
1,000 files, no matter what

00:09:18.430 --> 00:09:20.370
size they are, it does
a round trip.

00:09:20.370 --> 00:09:24.040
Or in some cases, a couple back
and forth to the service,

00:09:24.040 --> 00:09:26.280
and all of those run
sequentially.

00:09:26.280 --> 00:09:31.360
So you can end up taking a
lot of time to do that.

00:09:31.360 --> 00:09:33.140
So what do we do about that?

00:09:33.140 --> 00:09:35.250
Let's do some larger imports.

00:09:35.250 --> 00:09:38.900
This is things in the tens of
gigabytes, perhaps the tens of

00:09:38.900 --> 00:09:45.170
terabytes, very large numbers
of files in the hundreds of

00:09:45.170 --> 00:09:50.570
thousands, in that
sort of range.

00:09:50.570 --> 00:09:53.760
We just add this dash m and
it's all good, right?

00:09:53.760 --> 00:09:54.110
That's easy.

00:09:54.110 --> 00:09:56.460
We're done.

00:09:56.460 --> 00:09:59.180
So the dash m stands for
multi-processing and

00:09:59.180 --> 00:10:03.300
multi-threading, and gsutil
actually uses both at the same

00:10:03.300 --> 00:10:05.210
time to maximize overall
throughput.

00:10:08.700 --> 00:10:14.020
And since it's I/O, if you end
up needing to, you can dive in

00:10:14.020 --> 00:10:17.330
to the dot boto configuration
file, and there's various

00:10:17.330 --> 00:10:20.280
things to control gsutil
operation in there.

00:10:20.280 --> 00:10:23.010
But related to this, you could
actually tweak the number of

00:10:23.010 --> 00:10:26.450
processes and threads
if you need to.

00:10:26.450 --> 00:10:29.096
Most the time, it does a very
good job of defaults.

00:10:32.210 --> 00:10:34.370
So that was kind of like, look,
I just hand wave, and

00:10:34.370 --> 00:10:36.830
it's all fast, right?

00:10:36.830 --> 00:10:39.050
So what kind of limitations
are you going to run into

00:10:39.050 --> 00:10:42.590
after adding the
magical dash m?

00:10:42.590 --> 00:10:44.920
You're going to run into network
bandwidth this time is

00:10:44.920 --> 00:10:45.970
probably the case.

00:10:45.970 --> 00:10:49.570
So Google Cloud Storage is
hosted on Google networks,

00:10:49.570 --> 00:10:53.750
Google infrastructure, and
Google Storage technology.

00:10:53.750 --> 00:10:56.230
So you're running over the same
networks that we use to

00:10:56.230 --> 00:11:00.440
host YouTube, and Gmail, and
all of the things they may

00:11:00.440 --> 00:11:02.530
have talked about in other
sessions where internet

00:11:02.530 --> 00:11:06.170
requests go quickly from most
users ISPs directly onto

00:11:06.170 --> 00:11:07.410
Google backbone.

00:11:07.410 --> 00:11:09.650
And that communicates on the
Google internal network.

00:11:09.650 --> 00:11:11.940
You get all of those
advantages.

00:11:11.940 --> 00:11:15.900
One side effect of that is just
gsutil dash m can often

00:11:15.900 --> 00:11:17.390
completely saturate your upload

00:11:17.390 --> 00:11:20.550
bandwidth all by itself.

00:11:20.550 --> 00:11:25.470
So in many cases, you can go
with the absolute fastest that

00:11:25.470 --> 00:11:27.340
your internet connection
can sustain.

00:11:29.990 --> 00:11:34.380
Many of you, however, have very
fast networks, and you

00:11:34.380 --> 00:11:39.030
may first run into disk I/0
as your bottleneck.

00:11:39.030 --> 00:11:43.910
So if you're copying everything
from one drive, and

00:11:43.910 --> 00:11:45.700
you copy a whole bunch of
different files, you get a

00:11:45.700 --> 00:11:47.030
bunch of random seeks.

00:11:47.030 --> 00:11:48.840
And things can end up slowing
down that way.

00:11:48.840 --> 00:11:51.740
So you can end up wanting to
use multiple machines to

00:11:51.740 --> 00:11:52.990
speed things up.

00:11:52.990 --> 00:11:55.660
And then, once you get enough
files, there ends up being

00:11:55.660 --> 00:12:00.850
coordination and complexity
challenges just in terms of

00:12:00.850 --> 00:12:03.030
keeping track of which files
need to be copied, which ones

00:12:03.030 --> 00:12:06.170
to copy next, perhaps, how to
figure out which machines to

00:12:06.170 --> 00:12:08.490
copy them from, and that
sort of thing.

00:12:08.490 --> 00:12:12.520
So there's one other
situation that I

00:12:12.520 --> 00:12:14.180
wanted to call out here.

00:12:14.180 --> 00:12:18.180
So the way dash m makes things
faster is by doing more things

00:12:18.180 --> 00:12:19.060
at the same time.

00:12:19.060 --> 00:12:20.800
So it's running multiple
copies.

00:12:20.800 --> 00:12:23.650
But what if you really have a
single large file that you're

00:12:23.650 --> 00:12:26.310
trying to speed up?

00:12:26.310 --> 00:12:28.420
Can't use dash m, right?

00:12:28.420 --> 00:12:31.090
Or can we?

00:12:31.090 --> 00:12:33.480
So what you can do is you can
actually split your file into

00:12:33.480 --> 00:12:38.260
multiple pieces and upload
those in parallel and ask

00:12:38.260 --> 00:12:39.890
Google Cloud Storage
to reassemble them

00:12:39.890 --> 00:12:41.530
back into one object.

00:12:41.530 --> 00:12:44.250
And this uses the compose
feature that was released a

00:12:44.250 --> 00:12:46.810
few months ago.

00:12:46.810 --> 00:12:50.260
And it works very, very well,
and especially in situations

00:12:50.260 --> 00:12:53.230
where your data naturally comes
from multiple sources.

00:12:53.230 --> 00:12:57.320
For example, the output of
MapReduce jobs or some sort of

00:12:57.320 --> 00:12:59.780
logging and you actually want
to combine them all into one

00:12:59.780 --> 00:13:03.230
logical object in the end, it
can be very convenient to

00:13:03.230 --> 00:13:05.240
upload them all separately
and combine them

00:13:05.240 --> 00:13:07.230
actually in the cloud.

00:13:07.230 --> 00:13:10.710
One limitation I'd like to
mention there, is the compose

00:13:10.710 --> 00:13:13.940
is currently limited
to 32 pieces.

00:13:13.940 --> 00:13:17.650
So you can take 32 objects and
combine them into one.

00:13:20.450 --> 00:13:22.105
So now, we get into
enormous imports.

00:13:24.980 --> 00:13:26.082
Really?

00:13:26.082 --> 00:13:29.250
Is it that easy?

00:13:29.250 --> 00:13:32.710
And we just had a customer go
through this process with

00:13:32.710 --> 00:13:35.066
great success, and I'd like to
hand this over to Dave to talk

00:13:35.066 --> 00:13:36.430
about that.

00:13:36.430 --> 00:13:37.680
DAVE BARTH: Thank you.

00:13:39.330 --> 00:13:42.100
So I'd like to walk you through
a recent example of a

00:13:42.100 --> 00:13:45.470
customer that needed to move 5,
over 5 petabytes, actually,

00:13:45.470 --> 00:13:47.310
into Google Cloud Storage.

00:13:47.310 --> 00:13:50.560
And before I dive into that,
sometimes we throw these big

00:13:50.560 --> 00:13:51.280
numbers around.

00:13:51.280 --> 00:13:53.430
I'd just like to recognize that
5 petabytes is actually a

00:13:53.430 --> 00:13:54.410
lot of data.

00:13:54.410 --> 00:13:59.400
You could burn 5 petabytes of
data to just over 100,000

00:13:59.400 --> 00:14:03.460
Blu-ray DVDs or you can stick
that on your TV and watch 100

00:14:03.460 --> 00:14:08.090
years of high definition video
if you were so inclined.

00:14:08.090 --> 00:14:11.290
So this is actually a pretty
significant migration that

00:14:11.290 --> 00:14:13.050
this customer went through.

00:14:13.050 --> 00:14:16.900
And this is the architecture
of the system that was put

00:14:16.900 --> 00:14:19.240
together for that migration.

00:14:19.240 --> 00:14:21.060
It obviously is a little
bit more complicated

00:14:21.060 --> 00:14:22.480
than gsutil dash m.

00:14:22.480 --> 00:14:26.470
But I want to point out that the
actual work that's being

00:14:26.470 --> 00:14:30.010
done, the migration work, or the
red boxes in this diagram,

00:14:30.010 --> 00:14:33.780
that really is gsutil dash
m running across in this

00:14:33.780 --> 00:14:36.680
instance multiple Compute
Engine machines.

00:14:36.680 --> 00:14:37.920
So what's the rest of it?

00:14:37.920 --> 00:14:40.890
Well, the rest of it is that
coordination complexity that

00:14:40.890 --> 00:14:43.560
Brian mentioned that you're
going to end up having to deal

00:14:43.560 --> 00:14:46.090
with if you do really
large migrations.

00:14:46.090 --> 00:14:48.360
In this case, there's
two parts to it.

00:14:48.360 --> 00:14:51.010
So breaking it down, there's
basically coordinating the

00:14:51.010 --> 00:14:53.730
migration in order to set up the
objects that are going to

00:14:53.730 --> 00:14:56.930
get copied by these Compute
Engine instances, doing the

00:14:56.930 --> 00:14:59.160
copying, and then validating
and cleaning

00:14:59.160 --> 00:15:00.870
up after the copying.

00:15:00.870 --> 00:15:04.360
For the coordination, that was
done with an App Engine app.

00:15:04.360 --> 00:15:05.850
Oh, I should've mentioned.

00:15:05.850 --> 00:15:08.070
I forgot to mention that this
customer is actually moving

00:15:08.070 --> 00:15:11.440
his data from Amazon S3 over
to Google Cloud Storage.

00:15:11.440 --> 00:15:14.880
So they had requirements to.

00:15:14.880 --> 00:15:17.870
Of course, they wanted to move
it as quickly as possible.

00:15:17.870 --> 00:15:22.240
They also wanted to do a live
migration and delete the

00:15:22.240 --> 00:15:24.970
objects off of S3 as they were
being copied over to Cloud

00:15:24.970 --> 00:15:29.640
Storage so that they didn't
end up double paying for 5

00:15:29.640 --> 00:15:32.650
petabytes of data right
up to the very end.

00:15:32.650 --> 00:15:34.960
And so the first thing that they
did in order to queue up

00:15:34.960 --> 00:15:36.830
which objects needed to be
copied and coordinate the

00:15:36.830 --> 00:15:40.050
transfer was, there's an App
Engine app that basically just

00:15:40.050 --> 00:15:42.760
listed all the objects that
needed to be transferred out

00:15:42.760 --> 00:15:45.760
of the customer's S3 bucket.

00:15:45.760 --> 00:15:48.070
So they just get a list of
object names, and they would

00:15:48.070 --> 00:15:51.220
queue those up into an App
Engine task queue, which is

00:15:51.220 --> 00:15:53.750
just a standard component that
any App Engine developer can

00:15:53.750 --> 00:15:55.170
make use of.

00:15:55.170 --> 00:15:57.390
So there's all these object's
names that are sitting in the

00:15:57.390 --> 00:15:59.950
task queues, and that's
basically all the

00:15:59.950 --> 00:16:02.040
coordination, all the prep, that
was required before the

00:16:02.040 --> 00:16:03.860
copying began.

00:16:03.860 --> 00:16:06.950
The copying itself is basically
firing up a bunch of

00:16:06.950 --> 00:16:08.700
Compute Engine instances.

00:16:08.700 --> 00:16:12.820
Each Compute Instance would pull
a handful of objects off

00:16:12.820 --> 00:16:17.040
of the task queue, and then
use gsutil dash m to copy

00:16:17.040 --> 00:16:19.760
those over to Cloud Storage.

00:16:19.760 --> 00:16:23.850
I think there are at peak
about 160 Compute Engine

00:16:23.850 --> 00:16:27.830
instances running in parallel
at any given time.

00:16:27.830 --> 00:16:30.800
And that basically handled
the copying aspect of it.

00:16:30.800 --> 00:16:32.360
Now, the post processing
validation.

00:16:32.360 --> 00:16:35.340
So what was done in this
particular case was, every

00:16:35.340 --> 00:16:40.560
time an object completed its
copying, a note was made into

00:16:40.560 --> 00:16:43.310
what's noted here as the
migration bucket, which is

00:16:43.310 --> 00:16:45.770
just a separate Google Cloud
Storage bucket that

00:16:45.770 --> 00:16:48.000
essentially held a series
of flat files.

00:16:48.000 --> 00:16:49.840
With each Compute Engine
instance, every time we'd

00:16:49.840 --> 00:16:53.210
finished copying something,
we'd just append a note

00:16:53.210 --> 00:16:55.350
saying, this object was copied,
and this was the hash

00:16:55.350 --> 00:16:58.670
code that was returned from
Google Cloud Storage.

00:16:58.670 --> 00:17:01.040
And that enabled the customer's
systems then to go

00:17:01.040 --> 00:17:03.590
back and read through that list
of objects that was in

00:17:03.590 --> 00:17:06.660
the migration bucket, check that
the hash code matched to

00:17:06.660 --> 00:17:09.530
make sure there wasn't any
corruption during the copying,

00:17:09.530 --> 00:17:15.440
update the index in their client
system so that the end

00:17:15.440 --> 00:17:17.839
user computer knew that if it
wanted that object it now

00:17:17.839 --> 00:17:19.890
could find it over on Google
Cloud Storage instead of on

00:17:19.890 --> 00:17:23.400
Amazon S3, and then go and
delete the object from S3.

00:17:26.480 --> 00:17:29.600
So overall, everybody was really
pleased with how the

00:17:29.600 --> 00:17:31.500
migration went.

00:17:31.500 --> 00:17:34.260
I forgot to mention, it was
about four billion objects.

00:17:34.260 --> 00:17:38.260
It was significantly over 5
petabytes of data, but there

00:17:38.260 --> 00:17:41.370
was a period of set up
and testing of the

00:17:41.370 --> 00:17:42.720
system I just described.

00:17:42.720 --> 00:17:46.330
And then, once it got humming,
the bulk of the data, about 5

00:17:46.330 --> 00:17:47.820
petabytes, was moved
in five weeks.

00:17:47.820 --> 00:17:49.840
So it was about an average of
12 gigabytes per second

00:17:49.840 --> 00:17:52.560
throughput, and it regularly
peaked above 20

00:17:52.560 --> 00:17:54.700
gigabytes per second.

00:17:54.700 --> 00:17:57.860
And perhaps most important,
there wasn't any down time in

00:17:57.860 --> 00:18:00.190
the client application.

00:18:00.190 --> 00:18:02.940
And so this addressed a lot
of the limits that Brian

00:18:02.940 --> 00:18:04.400
mentioned before.

00:18:04.400 --> 00:18:07.670
Network bandwidth, of course,
wasn't really a problem by

00:18:07.670 --> 00:18:13.120
virtue of the data being moved
from S3 over to Cloud Storage.

00:18:13.120 --> 00:18:16.940
Google has quite sufficient
peering, network

00:18:16.940 --> 00:18:18.510
peering, with Amazon.

00:18:18.510 --> 00:18:19.550
So that wasn't an issue.

00:18:19.550 --> 00:18:22.640
In this particular case, disk
I/O also wasn't an issue,

00:18:22.640 --> 00:18:25.280
because we were moving from
another cloud provider that

00:18:25.280 --> 00:18:26.640
had a lot of scale.

00:18:26.640 --> 00:18:30.690
It also helped, we didn't really
worry about it much in

00:18:30.690 --> 00:18:33.620
any case, because the customer's
objects, their

00:18:33.620 --> 00:18:35.340
object names were all
hashes themselves.

00:18:35.340 --> 00:18:38.900
So it was really, really easy
to partition the data.

00:18:38.900 --> 00:18:41.360
Speaking of partitioning, if
you're moving from an on

00:18:41.360 --> 00:18:44.200
premise system then, that's
where coordination can come in

00:18:44.200 --> 00:18:44.660
really handy.

00:18:44.660 --> 00:18:48.540
You know how your data is
stored, and you can, during

00:18:48.540 --> 00:18:50.300
the coordination step, basically
make sure that you

00:18:50.300 --> 00:18:52.990
partition it and shard it up
so that each Compute Engine

00:18:52.990 --> 00:18:56.400
instance that's handling or
whatever instance is handling

00:18:56.400 --> 00:19:00.260
the copy in parallel, is working
on different bits of

00:19:00.260 --> 00:19:03.700
data at a time so no particular
disk gets too hot.

00:19:03.700 --> 00:19:05.940
And the coordination and
complexity was handled, of

00:19:05.940 --> 00:19:08.470
course, by building up some
of these components on the

00:19:08.470 --> 00:19:11.250
coordination side to the App
Engine instance in order to

00:19:11.250 --> 00:19:14.030
queue objects to be copied.

00:19:14.030 --> 00:19:18.160
And then, this post processing
step where the client

00:19:18.160 --> 00:19:21.370
application was updated to know
where to find the object,

00:19:21.370 --> 00:19:24.060
post processing is going to be
something that's going to tend

00:19:24.060 --> 00:19:27.180
to be pretty client specific,
use case specific.

00:19:27.180 --> 00:19:29.110
But also really, really
important.

00:19:29.110 --> 00:19:32.180
So Brian's going to talk a
little bit more about that.

00:19:32.180 --> 00:19:32.590
BRIAN DORSEY: Thanks a lot.

00:19:32.590 --> 00:19:34.340
Thanks Dave.

00:19:34.340 --> 00:19:35.150
OK.

00:19:35.150 --> 00:19:37.710
So now, you've got all this
data in your Google Cloud

00:19:37.710 --> 00:19:38.850
Storage buckets.

00:19:38.850 --> 00:19:41.920
And presumably, you guys have
written some amazing

00:19:41.920 --> 00:19:44.480
applications that delight
your users.

00:19:44.480 --> 00:19:49.340
So we want to allow you to
easily make Cloud Storage the

00:19:49.340 --> 00:19:51.910
processes there become part
of your application.

00:19:51.910 --> 00:19:55.270
So if you need to transcode the
data after upload, if you

00:19:55.270 --> 00:19:58.550
need to make thumbnails, if you
apply your special sauce,

00:19:58.550 --> 00:20:01.910
you can do that easily
and very quickly.

00:20:01.910 --> 00:20:07.800
So this is a big wall of detail,
JSON details here.

00:20:07.800 --> 00:20:11.400
But essentially, we offer a
feature called notifications,

00:20:11.400 --> 00:20:14.480
and you enable notifications
on the bucket level.

00:20:14.480 --> 00:20:18.990
And once you've enabled it,
every single change that is

00:20:18.990 --> 00:20:22.770
made to that bucket, every new
upload, every over write,

00:20:22.770 --> 00:20:27.060
every delete, every metadata
change, turns into, in

00:20:27.060 --> 00:20:28.560
addition to actually saving
the data and making the

00:20:28.560 --> 00:20:33.880
change, turns into an HTTP post
to any URL you choose.

00:20:33.880 --> 00:20:37.060
So what you get is details about
the change that just

00:20:37.060 --> 00:20:39.680
happened over HTTP
to your app.

00:20:39.680 --> 00:20:40.830
So that can be an
App Engine app.

00:20:40.830 --> 00:20:45.090
It can be an app that you host
anywhere, and very soon after

00:20:45.090 --> 00:20:47.710
the actual change happens,
you'll find out about it.

00:20:47.710 --> 00:20:50.535
So there's no need to write a
bunch of polling logic, and

00:20:50.535 --> 00:20:51.080
that sort of thing.

00:20:51.080 --> 00:20:53.100
It can become more tightly
integrated with your

00:20:53.100 --> 00:20:56.470
application workflow.

00:20:56.470 --> 00:20:58.720
And this kind of
handler doesn't

00:20:58.720 --> 00:21:01.250
need to be very complex.

00:21:01.250 --> 00:21:07.320
You can accept the post, do a
little dispatch on what type

00:21:07.320 --> 00:21:11.360
of event it is, and then pull
out the information you care

00:21:11.360 --> 00:21:13.510
about, buckets, names,
what have you.

00:21:13.510 --> 00:21:14.870
And then, do whatever
you need to do.

00:21:14.870 --> 00:21:17.310
So at this point, you could
put it in a database.

00:21:17.310 --> 00:21:20.320
You could put it in a queuing
system, anything that you

00:21:20.320 --> 00:21:21.620
could imagine.

00:21:21.620 --> 00:21:25.030
Once it's in a database or a
queue, as app developers, the

00:21:25.030 --> 00:21:26.390
sky's the limit, right?

00:21:26.390 --> 00:21:28.230
You can go from there and
do anything you need.

00:21:28.230 --> 00:21:31.400
So it's a quick and easy way
to get tight integration

00:21:31.400 --> 00:21:34.860
between Cloud Storage and the
rest of your application, make

00:21:34.860 --> 00:21:37.460
it feel more seamless.

00:21:37.460 --> 00:21:42.980
There's another situation that
can arise where you need to do

00:21:42.980 --> 00:21:44.220
bulk changes.

00:21:44.220 --> 00:21:47.960
So part of the way that Cloud
storage, Google Cloud Storage,

00:21:47.960 --> 00:21:52.260
achieves scalability is access
control is to find it at an

00:21:52.260 --> 00:21:53.930
individual object level.

00:21:53.930 --> 00:21:56.640
So every single object
has access control.

00:21:56.640 --> 00:21:59.200
So the rights of who's allowed
to read, who's allowed to

00:21:59.200 --> 00:22:01.760
write it, change it,
that sort of thing.

00:22:01.760 --> 00:22:05.310
And if you change your mind
about how that should be

00:22:05.310 --> 00:22:09.190
later, you may need to
do a bulk update

00:22:09.190 --> 00:22:10.810
against all of the objects.

00:22:10.810 --> 00:22:15.690
As an aside, we recommend that
you use groups for often

00:22:15.690 --> 00:22:17.160
changing group membership.

00:22:17.160 --> 00:22:18.850
So you can do that independently
of this.

00:22:18.850 --> 00:22:22.260
But if you make a large scale
change to your access control,

00:22:22.260 --> 00:22:24.930
you may run into some challenges
because you

00:22:24.930 --> 00:22:28.250
actually need to do a request
response cycle per object.

00:22:28.250 --> 00:22:32.210
Or perhaps, if you're doing a
large migration or conversion

00:22:32.210 --> 00:22:34.700
of some sort, you might have a
staging bucket that you might

00:22:34.700 --> 00:22:37.170
need to clear out that
has a lot of objects.

00:22:37.170 --> 00:22:39.100
And one approach
that you can--

00:22:39.100 --> 00:22:41.710
in most cases, I recommend going
ahead and just using

00:22:41.710 --> 00:22:47.460
gsutil dash m rm for remove or
we have a command CH ACL for

00:22:47.460 --> 00:22:51.190
changing ACLs, and that
will cover you in the

00:22:51.190 --> 00:22:52.520
vast majority of cases.

00:22:52.520 --> 00:22:54.910
But if you start to get into
half a million, a million,

00:22:54.910 --> 00:22:59.000
couple million objects, here's
something to look at.

00:22:59.000 --> 00:23:03.270
The new JSON API, Google Cloud
Storage JSON API, supports

00:23:03.270 --> 00:23:04.840
batching of requests.

00:23:04.840 --> 00:23:07.940
So what would normally have
been a round trip actually

00:23:07.940 --> 00:23:10.790
becomes one round trip, split
apart on the other end, and

00:23:10.790 --> 00:23:13.430
then you get all the responses
back in a batch as well.

00:23:13.430 --> 00:23:18.130
So you can make batches of 1,000
or more requests and

00:23:18.130 --> 00:23:21.010
responses in one network call.

00:23:21.010 --> 00:23:24.550
And those all get sent
off to Cloud Storage.

00:23:24.550 --> 00:23:26.620
This is just kind of a rough
idea of what that looks like

00:23:26.620 --> 00:23:31.090
on the wire, but logically it
groups the requests, multiple

00:23:31.090 --> 00:23:33.170
requests into one.

00:23:33.170 --> 00:23:35.340
In terms of how you would
actually write this code in

00:23:35.340 --> 00:23:39.640
Python, it's relatively
straightforward.

00:23:39.640 --> 00:23:42.270
So we've got some set
up stuff here.

00:23:42.270 --> 00:23:44.690
We're doing credentials at the
top, and that sort of thing.

00:23:44.690 --> 00:23:47.550
But the meat of it is, we've got
a list of things that we

00:23:47.550 --> 00:23:51.370
want to apply a change to and
we iterate through them and

00:23:51.370 --> 00:23:53.340
call this function, I'm going
to show on the next slide,

00:23:53.340 --> 00:23:55.600
called batch remove.

00:23:55.600 --> 00:23:57.970
And I'll have a URL to these
slides at the very end of the

00:23:57.970 --> 00:24:01.200
deck, so all this
will be there.

00:24:01.200 --> 00:24:05.310
And so we call batch remove
with our objects.

00:24:05.310 --> 00:24:10.640
And batch remove, if we take a
look right here in the center,

00:24:10.640 --> 00:24:15.020
this is a normal Python Client
Library call that we're just

00:24:15.020 --> 00:24:17.830
wrapping in this batch system.

00:24:17.830 --> 00:24:21.510
So we just add each of those
calls to the batch and then at

00:24:21.510 --> 00:24:24.090
the end, execute the batch.

00:24:24.090 --> 00:24:26.500
So it's pretty straightforward
to convert code that you

00:24:26.500 --> 00:24:29.350
already have that is doing
it one at a time

00:24:29.350 --> 00:24:30.790
into a batch call.

00:24:30.790 --> 00:24:33.070
And that's what this would
end up looking like.

00:24:33.070 --> 00:24:36.380
I know this is a few chunks, so
we've got an example up on

00:24:36.380 --> 00:24:40.570
GitHub, a full example, of
using this technique.

00:24:40.570 --> 00:24:42.620
And that's there.

00:24:42.620 --> 00:24:46.030
And then, I'd like to go into
some tips and techniques that

00:24:46.030 --> 00:24:49.340
work across any scale
data you've got.

00:24:49.340 --> 00:24:50.660
So you've got a little bit of
data, you've got a lot of

00:24:50.660 --> 00:24:53.110
data, a whole bunch of
different scenarios.

00:24:53.110 --> 00:24:57.980
First off, I really highly
recommend taking a look at the

00:24:57.980 --> 00:24:59.950
gsutil help.

00:24:59.950 --> 00:25:05.650
So just as you'd expect, gsutil
help and many of you

00:25:05.650 --> 00:25:09.210
are familiar with command line
applications and how obscure

00:25:09.210 --> 00:25:13.670
their help can be and this,
that, the other, gsutil has--

00:25:13.670 --> 00:25:16.120
let's go ahead and
do less here--

00:25:16.120 --> 00:25:17.990
complete help--

00:25:17.990 --> 00:25:19.240
or not--

00:25:23.130 --> 00:25:29.230
complete help for all of the
regular commands, and it also

00:25:29.230 --> 00:25:34.410
has at the end these special
topics like access control

00:25:34.410 --> 00:25:38.800
lists or credentials or, my
favorite I think, is Prod.

00:25:38.800 --> 00:25:40.920
If you are going to write
one of these, go

00:25:40.920 --> 00:25:41.620
ahead and read this.

00:25:41.620 --> 00:25:44.390
Each of these is like a little
essay in and of itself on best

00:25:44.390 --> 00:25:45.910
practices for using
Google Cloud

00:25:45.910 --> 00:25:48.400
Storage as part of gsutil.

00:25:48.400 --> 00:25:51.450
So you can learn a lot about
the product and the best

00:25:51.450 --> 00:25:54.970
practices by working
with gsutil help.

00:25:54.970 --> 00:25:58.180
Highly recommend it.

00:25:58.180 --> 00:26:03.810
Also, Dave mentioned it a bit
in passing, but one simple

00:26:03.810 --> 00:26:07.140
technique you can use to address
the complexity for

00:26:07.140 --> 00:26:12.070
medium sized workloads is to
split your work up by prefix.

00:26:12.070 --> 00:26:17.440
And what that means is your
object names, you could have

00:26:17.440 --> 00:26:20.020
them start with a certain
character.

00:26:20.020 --> 00:26:24.190
Or if they already start with
certain alphabetic letters,

00:26:24.190 --> 00:26:25.680
you can use that to
your advantage.

00:26:25.680 --> 00:26:28.710
So for example, in this example,
the files you were

00:26:28.710 --> 00:26:31.350
going to upload are already
MD5 hashes.

00:26:31.350 --> 00:26:33.810
You have a natural, just by
starting at the first

00:26:33.810 --> 00:26:37.460
character, you have a natural
split into 16 even groups.

00:26:37.460 --> 00:26:40.450
And if you needed to 256 even
groups for some reason, you

00:26:40.450 --> 00:26:42.930
could use the first two
characters and split them out

00:26:42.930 --> 00:26:45.550
and run them separately.

00:26:45.550 --> 00:26:47.470
Another way to think about
this is inverting it.

00:26:47.470 --> 00:26:50.145
When you're designing your
workflow, if you're know

00:26:50.145 --> 00:26:52.590
you're going to want to access
these objects by date, for

00:26:52.590 --> 00:26:55.330
example, put the dates
up at the beginning

00:26:55.330 --> 00:26:56.710
of the object names.

00:26:56.710 --> 00:26:59.500
That makes it very easy to
separate them out and work

00:26:59.500 --> 00:27:01.510
with them individually later.

00:27:01.510 --> 00:27:03.910
And that way, you can get all of
the log files from the same

00:27:03.910 --> 00:27:06.830
day and things like that.

00:27:06.830 --> 00:27:10.280
Another thing that can come
up is this happens at

00:27:10.280 --> 00:27:11.040
both ends the scale.

00:27:11.040 --> 00:27:14.320
If you've got a set of objects
that you're manually trying to

00:27:14.320 --> 00:27:18.400
work with and you want to do
operations or check them or

00:27:18.400 --> 00:27:25.600
copy them over and over, or if
you want to have an external

00:27:25.600 --> 00:27:29.240
program create the list of
things to work on, you can use

00:27:29.240 --> 00:27:33.810
this dash uppercase
I flag for copy.

00:27:33.810 --> 00:27:38.270
And in this case, I'm
using a text file in

00:27:38.270 --> 00:27:41.100
and piping into gsutil.

00:27:41.100 --> 00:27:43.770
But the actual source program
can be any program you write

00:27:43.770 --> 00:27:48.000
or xargs or what have you
on the Unix side.

00:27:48.000 --> 00:27:50.300
So you could work from a static
file or a dynamically

00:27:50.300 --> 00:27:52.860
generated list of files and pipe
them directly through it

00:27:52.860 --> 00:27:56.540
and still let gsutil do the
copying work for you.

00:27:56.540 --> 00:27:58.670
So that can be pretty
powerful.

00:27:58.670 --> 00:28:02.900
Another thing to remember is the
data is actually copying

00:28:02.900 --> 00:28:04.610
through gsutil.

00:28:04.610 --> 00:28:09.100
so you want to run the gsutil
app itself close, in a network

00:28:09.100 --> 00:28:13.580
sense, to one end of
the connection.

00:28:13.580 --> 00:28:17.390
So in the example Dave talked
about, the connection was

00:28:17.390 --> 00:28:20.760
actually on Compute Engine so
that's in the Google Cloud so

00:28:20.760 --> 00:28:22.800
that's very close to
Cloud Storage.

00:28:22.800 --> 00:28:28.450
Or you may need to actually run
it on premise at your data

00:28:28.450 --> 00:28:31.810
center, and that
may make sense.

00:28:31.810 --> 00:28:39.830
So that actually only works if
you've got enough bandwidth.

00:28:39.830 --> 00:28:41.460
We hinted at that.

00:28:41.460 --> 00:28:44.500
So I'd like to hand
it off to Dave.

00:28:44.500 --> 00:28:45.210
DAVE BARTH: Right
it only works if

00:28:45.210 --> 00:28:46.320
you have enough bandwidth.

00:28:46.320 --> 00:28:50.120
And we started with network
constrained, and you never get

00:28:50.120 --> 00:28:51.450
rid of that.

00:28:51.450 --> 00:28:54.030
If you have a poor internet
connection between your data

00:28:54.030 --> 00:28:56.310
and Google, you're going to have
a bad time moving that

00:28:56.310 --> 00:28:58.820
data to Google.

00:28:58.820 --> 00:29:00.040
We're really happy, today,
to announce a

00:29:00.040 --> 00:29:01.130
work around for that.

00:29:01.130 --> 00:29:04.490
And that is, offline disk
import, which basically works

00:29:04.490 --> 00:29:05.800
around the internet.

00:29:05.800 --> 00:29:09.330
And that involves basically
writing your data to a disk

00:29:09.330 --> 00:29:10.840
and shipping it to
us in Google to

00:29:10.840 --> 00:29:12.010
upload from our network.

00:29:12.010 --> 00:29:14.510
We don't necessarily recommend a
manila envelope, although, I

00:29:14.510 --> 00:29:16.730
guess it might work
just as well.

00:29:16.730 --> 00:29:19.330
The process is pretty
straightforward.

00:29:19.330 --> 00:29:21.070
Format a SATA disk with encfs.

00:29:21.070 --> 00:29:22.010
This encrypts the data.

00:29:22.010 --> 00:29:24.980
So make sure that if it gets
lost, or protects it,

00:29:24.980 --> 00:29:27.860
basically, during deranged
shipment.

00:29:27.860 --> 00:29:29.170
Copy your data to the disk.

00:29:29.170 --> 00:29:30.460
Mail it to Google.

00:29:30.460 --> 00:29:33.370
We'll upload it to a Google
Cloud Storage bucket that's

00:29:33.370 --> 00:29:35.010
owned by the customer.

00:29:35.010 --> 00:29:36.190
We don't touch the
data at all.

00:29:36.190 --> 00:29:39.550
We just upload it and make use
of Google's fast network, and

00:29:39.550 --> 00:29:41.800
then ship the disk back.

00:29:41.800 --> 00:29:45.070
We're launching this feature
in limited preview today.

00:29:45.070 --> 00:29:49.430
Meaning that, you can sign up
at the link there to let us

00:29:49.430 --> 00:29:51.070
know you're interested
in making use of it.

00:29:51.070 --> 00:29:58.660
And we'll take applicants as
we can to scale it up.

00:29:58.660 --> 00:30:02.000
Right now, it's only available
for customers that are located

00:30:02.000 --> 00:30:03.010
in the United States.

00:30:03.010 --> 00:30:05.530
If you're an international
customer, please do fill out

00:30:05.530 --> 00:30:08.100
the interest form anyway and let
us know, because we will

00:30:08.100 --> 00:30:11.010
be definitely expanding this
internationally in coming

00:30:11.010 --> 00:30:14.130
months, and that may help us
prioritize a little bit.

00:30:14.130 --> 00:30:18.450
And the prices is a
flat $80 per disk.

00:30:18.450 --> 00:30:22.440
We don't charge any other fees
and that beyond the usual

00:30:22.440 --> 00:30:24.510
storage fees that are associated
with any kind of

00:30:24.510 --> 00:30:25.760
Google Cloud Storage usage.

00:30:29.384 --> 00:30:30.370
BRIAN DORSEY: OK.

00:30:30.370 --> 00:30:31.820
Thank you very much.

00:30:31.820 --> 00:30:37.880
And I wanted to highlight a few
of the things that have

00:30:37.880 --> 00:30:40.030
happened in the last year.

00:30:40.030 --> 00:30:41.300
Several of these I've talked
about in the talk and a few of

00:30:41.300 --> 00:30:43.580
them I haven't.

00:30:43.580 --> 00:30:46.160
You can also enable versioning
on any bucket.

00:30:46.160 --> 00:30:49.620
So as things change, you keep
the old versions around.

00:30:49.620 --> 00:30:52.470
We announced Durable Reduced
Availability storage for

00:30:52.470 --> 00:30:55.310
situations where backup, in
particular, where you're

00:30:55.310 --> 00:30:56.310
willing to trade
a little bit of

00:30:56.310 --> 00:30:59.390
availability for a lower price.

00:30:59.390 --> 00:31:02.860
And we lowered prices by
30% in the last year.

00:31:02.860 --> 00:31:06.990
And also throughout the talk,
if you were paying careful

00:31:06.990 --> 00:31:09.375
attention, I did actually
reference several things that

00:31:09.375 --> 00:31:10.640
have been announced recently.

00:31:10.640 --> 00:31:12.970
So the Cloud Console
is one of them.

00:31:12.970 --> 00:31:15.150
It was actually just
released last week.

00:31:15.150 --> 00:31:18.870
We also talked about the Compose
Command which allows

00:31:18.870 --> 00:31:21.940
you to combine multiple
objects in the cloud.

00:31:21.940 --> 00:31:23.560
Notifications, which I
mentioned in the post

00:31:23.560 --> 00:31:24.580
processing.

00:31:24.580 --> 00:31:28.900
Our new JSON API that's been out
for many months but just

00:31:28.900 --> 00:31:33.200
went through a significant
revision and improvement and

00:31:33.200 --> 00:31:38.700
went to, the correct
term is, preview.

00:31:38.700 --> 00:31:42.990
And that is now available, and
our intent is to make that a

00:31:42.990 --> 00:31:46.540
generally available feature.

00:31:46.540 --> 00:31:49.400
And so we highly recommend
you take a look at that.

00:31:49.400 --> 00:31:52.150
It's very good, and offline
disk import.

00:31:52.150 --> 00:31:59.690
So to wrap up a little bit,
we've talked about many tools

00:31:59.690 --> 00:32:02.580
and techniques to help you
get your data into

00:32:02.580 --> 00:32:03.780
Google Cloud Storage.

00:32:03.780 --> 00:32:10.800
And Google Cloud Storage is a
very reliable, efficient,

00:32:10.800 --> 00:32:14.310
fast, place to store
your data.

00:32:14.310 --> 00:32:16.330
And we look forward to seeing
the applications that all of

00:32:16.330 --> 00:32:20.510
you build on top of Google
Cloud Storage.

00:32:20.510 --> 00:32:23.390
We'd like to move into Q&amp;A. And
as we do that, I'd like to

00:32:23.390 --> 00:32:25.870
invite two other folks up to
the stage from the Google

00:32:25.870 --> 00:32:28.760
Cloud Storage team.

00:32:28.760 --> 00:32:29.880
We have--

00:32:29.880 --> 00:32:30.680
Yup.

00:32:30.680 --> 00:32:30.720
Yup.

00:32:30.720 --> 00:32:31.350
Bring them up here.

00:32:31.350 --> 00:32:33.370
And go ahead and line up
at the mics if you have

00:32:33.370 --> 00:32:34.620
questions for us.

00:32:41.100 --> 00:32:42.350
I'll let you guys introduce
yourself.

00:32:45.110 --> 00:32:45.260
Hi.

00:32:45.260 --> 00:32:52.100
I'm Lamia Youseff, and I'm the
BM on the Google Import Desk.

00:32:52.100 --> 00:32:52.320
Hi.

00:32:52.320 --> 00:32:53.880
I'm Bill [? Agos, ?]

00:32:53.880 --> 00:32:57.640
and I'm the tech lead for
the Cloud Storage.

00:32:57.640 --> 00:32:58.500
BRIAN DORSEY: OK.

00:32:58.500 --> 00:33:01.230
First question.

00:33:01.230 --> 00:33:04.130
AUDIENCE: With regards to
small and medium sized

00:33:04.130 --> 00:33:07.100
uploads, is there a reason why
I would not want to use the

00:33:07.100 --> 00:33:11.036
dash m If I want to get that
smaller amount in a

00:33:11.036 --> 00:33:14.970
multi-thread fashion aside
from the limitations or

00:33:14.970 --> 00:33:17.230
problems that were mentioned
with the large data

00:33:17.230 --> 00:33:18.070
structures?

00:33:18.070 --> 00:33:18.280
BRIAN DORSEY: No.

00:33:18.280 --> 00:33:22.010
In most cases, you can use dash
m in almost any scenario.

00:33:22.010 --> 00:33:22.770
So yeah.

00:33:22.770 --> 00:33:24.050
Go ahead and use dash m.

00:33:27.590 --> 00:33:28.660
AUDIENCE: Hi.

00:33:28.660 --> 00:33:31.970
I work in the industrial
electronics sector, and we see

00:33:31.970 --> 00:33:35.690
a lot of times people trying to
pull information from PLCs

00:33:35.690 --> 00:33:37.770
or different types of servers so
that they can put into the

00:33:37.770 --> 00:33:39.170
cloud for redundancy.

00:33:39.170 --> 00:33:43.640
Do you see this edition of the
offline import being helpful

00:33:43.640 --> 00:33:46.010
in that instance where they're
going to be trying to take

00:33:46.010 --> 00:33:48.510
previous data and put into the
cloud so they can still have

00:33:48.510 --> 00:33:50.795
that redundancy for previous
instances?

00:33:54.500 --> 00:33:56.860
LAMIA YOUSEFF: I would say
definitely yes, since it's

00:33:56.860 --> 00:33:59.800
going to be much faster to get
the data into the cloud.

00:33:59.800 --> 00:34:03.270
However, if it's already online
and the size of the

00:34:03.270 --> 00:34:06.680
data is not very large, then
maybe the online version is

00:34:06.680 --> 00:34:07.830
going to be much faster.

00:34:07.830 --> 00:34:10.090
So it depends on the
size of the data.

00:34:10.090 --> 00:34:12.780
BRIAN DORSEY: It really comes
down to the amount of data you

00:34:12.780 --> 00:34:16.920
have, and the bandwidth of your
network connection, and

00:34:16.920 --> 00:34:20.000
how long you have before you
need the data online.

00:34:20.000 --> 00:34:24.070
So if those don't work, Disk
Import becomes a great choice.

00:34:24.070 --> 00:34:24.739
AUDIENCE: Hi.

00:34:24.739 --> 00:34:29.310
Do you have any suggestions for
best practices on getting

00:34:29.310 --> 00:34:34.719
data and logs out of App Engine
into the Cloud Storage?

00:34:34.719 --> 00:34:37.639
BRIAN DORSEY: So I think for
that the very best thing to do

00:34:37.639 --> 00:34:41.570
is to recommend visiting
the Cloud Sandbox.

00:34:41.570 --> 00:34:44.100
We'll have some more App
Engine experts there.

00:34:44.100 --> 00:34:47.639
But I will just hint that
there are some tools for

00:34:47.639 --> 00:34:52.360
getting exports of the App
Engine Data Store directly

00:34:52.360 --> 00:34:54.840
into Cloud Storage, and you can
also use all the regular

00:34:54.840 --> 00:34:56.880
Cloud Storage APIs directly
from App Engine code.

00:35:00.650 --> 00:35:03.166
AUDIENCE: Is there any way to
do streaming uploads or to

00:35:03.166 --> 00:35:04.760
append a file without resorting
to combine?

00:35:08.220 --> 00:35:10.470
I'm sorry, streaming
uploads doing what?

00:35:10.470 --> 00:35:12.855
AUDIENCE: Streaming uploads or
appending some files that are

00:35:12.855 --> 00:35:13.260
already uploaded.

00:35:13.260 --> 00:35:13.650
BILL: Yes.

00:35:13.650 --> 00:35:17.010
So you can't do an append right
now, forever and ever.

00:35:17.010 --> 00:35:19.390
But what you can do is you can
use the object composition up

00:35:19.390 --> 00:35:20.070
to a limit.

00:35:20.070 --> 00:35:21.960
So if, for example, you're doing
logs and you want to

00:35:21.960 --> 00:35:24.500
snapshot logs on an hourly
basis, you could

00:35:24.500 --> 00:35:27.610
do that up to 32.

00:35:27.610 --> 00:35:31.080
But other than that, the append
support, just general

00:35:31.080 --> 00:35:33.510
append, it's not supported.

00:35:33.510 --> 00:35:39.850
BRIAN DORSEY: And one work
around for that, resumable

00:35:39.850 --> 00:35:44.730
uploads for a limited time
frame, you can actually leave

00:35:44.730 --> 00:35:48.550
a resumable upload open, and
you can keep trickling the

00:35:48.550 --> 00:35:49.845
upload up to the service.

00:35:53.030 --> 00:35:57.300
But the objects only become
available once it's completed.

00:35:57.300 --> 00:35:59.820
So if you need to use the data
in between, you have to use

00:35:59.820 --> 00:36:00.870
composition.

00:36:00.870 --> 00:36:02.390
AUDIENCE: How long
can that take?

00:36:02.390 --> 00:36:05.600
What's the maximum time.

00:36:05.600 --> 00:36:06.850
BRIAN DORSEY: About a week.

00:36:08.760 --> 00:36:11.180
Try to keep it under a week.

00:36:11.180 --> 00:36:14.710
AUDIENCE: Can say anything about
compression built-in

00:36:14.710 --> 00:36:16.070
support with gsutil?

00:36:20.180 --> 00:36:24.560
BILL:I don't think it does any
support encryption by default.

00:36:24.560 --> 00:36:27.560
Encryption, I mean, compression
by default.

00:36:27.560 --> 00:36:30.230
But you certainly go ahead
and gzip data.

00:36:30.230 --> 00:36:32.070
Gzip it before you upload it.

00:36:42.480 --> 00:36:43.740
AUDIENCE: Hi.

00:36:43.740 --> 00:36:44.550
My name is Jeremy.

00:36:44.550 --> 00:36:45.760
I work for Edit Share.

00:36:45.760 --> 00:36:49.770
It's a company that does high
speed local storage for video

00:36:49.770 --> 00:36:50.470
production.

00:36:50.470 --> 00:36:51.970
BRIAN DORSEY: Oh, great.

00:36:51.970 --> 00:36:55.690
AUDIENCE: And we've considered
using Cloud services for some

00:36:55.690 --> 00:37:00.240
of our customers, and even for
some of these customers who

00:37:00.240 --> 00:37:03.300
are willing to just mail in a
disk and upload it to the

00:37:03.300 --> 00:37:07.200
Cloud, one key feature, which
they require, is being able

00:37:07.200 --> 00:37:11.990
to, essentially, get at parts
of that data quickly.

00:37:11.990 --> 00:37:17.090
So how exactly would I do the
equivalent of a seek using and

00:37:17.090 --> 00:37:18.730
just copying that
part of a file?

00:37:18.730 --> 00:37:21.310
BILL: You can basically
use range gets.

00:37:21.310 --> 00:37:25.260
So you can basically say, give
me the byte ranges that you

00:37:25.260 --> 00:37:27.500
want out of the full object.

00:37:27.500 --> 00:37:28.530
AUDIENCE: And is that something
I could do in

00:37:28.530 --> 00:37:30.640
parallel for lots of objects.

00:37:30.640 --> 00:37:31.690
BRIAN DORSEY: Absolutely.

00:37:31.690 --> 00:37:33.020
HTTP range header.

00:37:37.750 --> 00:37:41.400
And there's no more people up
there with questions, but

00:37:41.400 --> 00:37:44.370
we'll just say that we will also
be at the Cloud Sandbox

00:37:44.370 --> 00:37:46.890
with Google Cloud Storage
specific office

00:37:46.890 --> 00:37:49.750
hours tomorrow afternoon.

00:37:49.750 --> 00:37:54.240
Maybe check the schedule for the
exact time, and thank you

00:37:54.240 --> 00:37:56.140
all very, very much
for coming.

00:37:56.140 --> 00:37:57.390
BILL: Thank you.

