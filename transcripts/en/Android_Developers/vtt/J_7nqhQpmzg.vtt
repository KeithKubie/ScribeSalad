WEBVTT
Kind: captions
Language: en

00:00:07.567 --> 00:00:09.400
NAZMUL IDRIS: Welcome
to this episode of UXD

00:00:09.400 --> 00:00:11.740
where we will talk about
what user research is,

00:00:11.740 --> 00:00:14.360
and how you can use it to make
better products that users

00:00:14.360 --> 00:00:15.650
will actually want to use.

00:00:15.650 --> 00:00:17.960
I'm your host, Nazmul
Idris-- developer, advocate,

00:00:17.960 --> 00:00:19.440
passionate about
design and mobile.

00:00:19.440 --> 00:00:21.887
And I have a very special
guest with me today.

00:00:21.887 --> 00:00:23.470
RICHARD FULCHER: Hi,
I'm Rich Fulcher.

00:00:23.470 --> 00:00:26.245
I'm a designer and manager
on the Android team.

00:00:26.245 --> 00:00:27.870
NAZMUL IDRIS: Thank
you for being here.

00:00:27.870 --> 00:00:28.820
RICHARD FULCHER: Thanks.

00:00:28.820 --> 00:00:30.210
NAZMUL IDRIS: So, Rich, from
your personal experience

00:00:30.210 --> 00:00:32.860
as a designer, why is user
research important to building

00:00:32.860 --> 00:00:33.744
great products?

00:00:33.744 --> 00:00:35.160
RICHARD FULCHER:
Well, I've always

00:00:35.160 --> 00:00:40.260
been able to benefit from user
research throughout my career.

00:00:40.260 --> 00:00:43.210
I feel that it just helps bring
me closer to the people who

00:00:43.210 --> 00:00:46.660
are actually going to use the
products that I, and my teams,

00:00:46.660 --> 00:00:48.810
helped to design and build.

00:00:48.810 --> 00:00:51.480
And that's been true for me
at a big company like Google,

00:00:51.480 --> 00:00:53.840
where we have a
large research staff.

00:00:53.840 --> 00:00:57.440
It's also been true for a much,
much, much smaller companies

00:00:57.440 --> 00:00:58.930
that I've been a
part of as well.

00:01:01.670 --> 00:01:04.594
Thinking back to my very
earliest days as a designer,

00:01:04.594 --> 00:01:09.660
and my first class in was called
Human Computer Interaction,

00:01:09.660 --> 00:01:12.490
back in the day.

00:01:12.490 --> 00:01:15.560
That very first class,
we talked about that this

00:01:15.560 --> 00:01:21.330
is the study of users, in a
context, making use of tools,

00:01:21.330 --> 00:01:24.270
to perform tasks, to
achieve their goals.

00:01:24.270 --> 00:01:29.510
So those five important things--
users, context, tools, task,

00:01:29.510 --> 00:01:34.370
goals-- are really what
research helps us speak to.

00:01:34.370 --> 00:01:37.450
As a designer, I have
a lot of responsibility

00:01:37.450 --> 00:01:39.060
in defining the tool.

00:01:39.060 --> 00:01:40.700
What does your
program look like?

00:01:40.700 --> 00:01:42.010
How does it work?

00:01:42.010 --> 00:01:45.790
And I get a little bit of
influence over the task.

00:01:45.790 --> 00:01:47.990
What are the steps
that I put you through?

00:01:47.990 --> 00:01:52.140
Or how is it divided out
into different pieces?

00:01:52.140 --> 00:01:55.180
Research tells me a lot
about those other three

00:01:55.180 --> 00:01:56.870
areas as well.

00:01:56.870 --> 00:02:00.420
So it tells me about the
users, a little bit more

00:02:00.420 --> 00:02:01.360
about who they are.

00:02:01.360 --> 00:02:04.620
It tells me about the context
that they use these products

00:02:04.620 --> 00:02:05.720
in.

00:02:05.720 --> 00:02:09.289
And that's both environments
and just state of mind.

00:02:09.289 --> 00:02:12.020
A lot of different factors
come into play there.

00:02:12.020 --> 00:02:14.800
And, importantly, it tells
me about their goals.

00:02:14.800 --> 00:02:17.070
Not just, get this
thing done, but why

00:02:17.070 --> 00:02:18.570
do they want to get
that thing done?

00:02:18.570 --> 00:02:21.560
What are they trying to
achieve in their lives, is

00:02:21.560 --> 00:02:25.026
the reason for this product.

00:02:25.026 --> 00:02:26.400
RICHARD FULCHER:
So, Nazmul, what

00:02:26.400 --> 00:02:29.470
do you think of when you
hear the term user research?

00:02:29.470 --> 00:02:30.990
What's the picture in your head?

00:02:30.990 --> 00:02:33.490
NAZMUL IDRIS: I think
about a lab in an office.

00:02:33.490 --> 00:02:36.870
I think about being part
of a usability study,

00:02:36.870 --> 00:02:38.480
where other people
watch me actually

00:02:38.480 --> 00:02:40.350
use a product that's
already been built,

00:02:40.350 --> 00:02:42.630
to see whether it makes
sense to me or not.

00:02:42.630 --> 00:02:43.345
Is that right?

00:02:43.345 --> 00:02:45.845
RICHARD FULCHER: It sounds like
you're describing that scene

00:02:45.845 --> 00:02:49.510
in "Ghostbusters" where Dr.
Venkman has the students come

00:02:49.510 --> 00:02:52.205
into his lab in the University,
and does an ESP test,

00:02:52.205 --> 00:02:55.170
and electroshocks a few of them.

00:02:55.170 --> 00:02:57.410
But that is basically right.

00:02:57.410 --> 00:02:58.580
That's one form of testing.

00:02:58.580 --> 00:03:01.010
That's what we would
call usability testing,

00:03:01.010 --> 00:03:03.011
or in-lab usability studies.

00:03:03.011 --> 00:03:04.260
And that's a very common type.

00:03:04.260 --> 00:03:06.010
And it's probably the
one that most people

00:03:06.010 --> 00:03:08.510
think of as research
when we think

00:03:08.510 --> 00:03:12.210
of that in a canonical form.

00:03:12.210 --> 00:03:15.570
Those focus on tools and tasks
that we just talked about.

00:03:15.570 --> 00:03:17.860
So there's a tool there.

00:03:17.860 --> 00:03:22.430
We're asking, can the user use
this tool to complete the task?

00:03:22.430 --> 00:03:25.310
We give the user the task
when they step into the lab,

00:03:25.310 --> 00:03:28.811
and we just see, well, did
they do it successfully?

00:03:28.811 --> 00:03:30.810
If they did, how long did
it take them to do it?

00:03:30.810 --> 00:03:33.120
So time on task and
test completion.

00:03:33.120 --> 00:03:36.210
But there's a lot more that we
can do in research than just

00:03:36.210 --> 00:03:37.790
that.

00:03:37.790 --> 00:03:40.450
It's not just testing
that's really important

00:03:40.450 --> 00:03:43.180
to remind people about.

00:03:43.180 --> 00:03:46.450
The broader goal is bigger
than just validating,

00:03:46.450 --> 00:03:48.400
is this product working or not?

00:03:48.400 --> 00:03:50.170
What you want to
get out of research

00:03:50.170 --> 00:03:53.994
is a richer understanding
about all of your users.

00:03:53.994 --> 00:03:55.660
You want to understand
their perceptions

00:03:55.660 --> 00:03:57.240
and their expectations.

00:03:57.240 --> 00:03:59.910
You want to get
insight about them

00:03:59.910 --> 00:04:02.340
that you can apply, not
just for this one thing

00:04:02.340 --> 00:04:04.730
that you're testing
right here now,

00:04:04.730 --> 00:04:07.120
but that you can apply to all
the future things you might

00:04:07.120 --> 00:04:08.306
build for users.

00:04:08.306 --> 00:04:10.320
I mean, the next
version of the product,

00:04:10.320 --> 00:04:13.617
or a new product that relates
to that same audience.

00:04:13.617 --> 00:04:15.200
NAZMUL IDRIS: So,
now, that's starting

00:04:15.200 --> 00:04:16.991
to sound a little bit
like market research.

00:04:16.991 --> 00:04:17.751
Is that right?

00:04:17.751 --> 00:04:19.459
RICHARD FULCHER: It's
definitely related.

00:04:19.459 --> 00:04:22.830
There's definitely some overlap
between those disciplines.

00:04:22.830 --> 00:04:29.110
Certainly at how they conduct--
set up experiments, or do

00:04:29.110 --> 00:04:30.940
data analysis--
there's certainly

00:04:30.940 --> 00:04:32.080
common elements there.

00:04:32.080 --> 00:04:34.860
I think, about research,
market research

00:04:34.860 --> 00:04:38.910
can focus on demographic
or marketing data.

00:04:38.910 --> 00:04:42.380
And that's a little bit more
divorced from tasking goals,

00:04:42.380 --> 00:04:46.490
but can still speak
to user in context.

00:04:46.490 --> 00:04:49.800
It may be things like purchasing
behavior that tie into that.

00:04:49.800 --> 00:04:52.140
But user research, I think,
is a little bit more focused

00:04:52.140 --> 00:04:55.400
on users' day to day behavior.

00:04:55.400 --> 00:04:56.400
What does the user want?

00:04:56.400 --> 00:04:57.500
What do they need?

00:04:57.500 --> 00:04:59.405
What are those big
capital G goals

00:04:59.405 --> 00:05:01.970
that we talked about earlier?

00:05:01.970 --> 00:05:04.812
How did the different
contexts affect their ability

00:05:04.812 --> 00:05:05.520
to use a product?

00:05:08.070 --> 00:05:12.100
If I've got a phone, and I'm
just using it two-handed,

00:05:12.100 --> 00:05:16.230
that's a different context than
if I have a latte in one hand,

00:05:16.230 --> 00:05:18.040
and I'm one-handing
the phone, and I'm also

00:05:18.040 --> 00:05:19.532
running to catch a bus.

00:05:19.532 --> 00:05:20.740
It might be the same product.

00:05:20.740 --> 00:05:22.406
It might be the same
tasks-- same tools,

00:05:22.406 --> 00:05:23.730
same tasks, same goals even.

00:05:23.730 --> 00:05:24.970
But the context is
going to make that

00:05:24.970 --> 00:05:26.750
a very different
experience for the user.

00:05:26.750 --> 00:05:27.666
NAZMUL IDRIS: Exactly.

00:05:27.666 --> 00:05:30.390
In fact, we have an episode
dedicated just to context.

00:05:30.390 --> 00:05:30.850
RICHARD FULCHER: Oh, perfect.

00:05:30.850 --> 00:05:31.540
NAZMUL IDRIS: And it's
going to air soon.

00:05:31.540 --> 00:05:32.500
RICHARD FULCHER: Great.

00:05:32.500 --> 00:05:33.291
NAZMUL IDRIS: Cool.

00:05:33.291 --> 00:05:35.400
So now, those seem like
really big questions.

00:05:35.400 --> 00:05:37.921
So how do you even ask
users those questions?

00:05:37.921 --> 00:05:39.670
RICHARD FULCHER: Those
are huge questions.

00:05:39.670 --> 00:05:41.878
And you're not going to be
able to answer all of them

00:05:41.878 --> 00:05:44.862
in an in-lab study, just
with usability testing.

00:05:44.862 --> 00:05:46.320
NAZMUL IDRIS: And
that makes sense.

00:05:46.320 --> 00:05:49.590
So is this where the expertise
of user researchers come in?

00:05:49.590 --> 00:05:51.910
RICHARD FULCHER:
Yeah, absolutely.

00:05:51.910 --> 00:05:54.430
On the surface, what a
researcher does sometimes

00:05:54.430 --> 00:05:55.570
seems simple.

00:05:55.570 --> 00:05:57.410
It's just asking
people questions.

00:05:57.410 --> 00:05:58.270
NAZMUL IDRIS: Well,
I can do that.

00:05:58.270 --> 00:05:59.060
RICHARD FULCHER:
Everybody can do that.

00:05:59.060 --> 00:06:00.060
We can all be journalists.

00:06:00.060 --> 00:06:00.740
It's all simple.

00:06:00.740 --> 00:06:00.850
NAZMUL IDRIS: Right.

00:06:00.850 --> 00:06:01.560
Of course.

00:06:01.560 --> 00:06:02.230
RICHARD FULCHER:
It's the same thing

00:06:02.230 --> 00:06:04.330
that designers grapple
with sometimes.

00:06:04.330 --> 00:06:05.835
Oh, so you draw pictures.

00:06:05.835 --> 00:06:07.210
Well everybody
can draw pictures.

00:06:07.210 --> 00:06:08.750
NAZMUL IDRIS: I scribble
and I'm a designer.

00:06:08.750 --> 00:06:09.666
RICHARD FULCHER: Yeah.

00:06:09.666 --> 00:06:11.640
I think, in both
cases, that just

00:06:11.640 --> 00:06:14.460
belies the rich
set of skills that

00:06:14.460 --> 00:06:17.550
an experienced practitioner
can bring to bear.

00:06:17.550 --> 00:06:19.840
And for researchers,
they are particularly

00:06:19.840 --> 00:06:22.530
expert at figuring
out how to get answers

00:06:22.530 --> 00:06:25.000
to difficult questions.

00:06:25.000 --> 00:06:28.280
So interviewing-- just flat-out
asking somebody a question--

00:06:28.280 --> 00:06:31.100
is one technique
that they'll use.

00:06:31.100 --> 00:06:32.910
But it is really
just one of many.

00:06:32.910 --> 00:06:35.940
A lot of the techniques
rely on conservation,

00:06:35.940 --> 00:06:38.320
as opposed to
direct questioning.

00:06:38.320 --> 00:06:44.250
So that it may be going to a
user's home, into a workplace.

00:06:44.250 --> 00:06:46.810
It may be bringing
them into a lab,

00:06:46.810 --> 00:06:49.750
but not directly prompting
them to do certain things,

00:06:49.750 --> 00:06:51.567
and just seeing how they behave.

00:06:51.567 --> 00:06:54.150
NAZMUL IDRIS: It's like watching
them in their native habitat.

00:06:54.150 --> 00:06:55.191
RICHARD FULCHER: Exactly.

00:06:55.191 --> 00:06:56.780
There is an
anthropological aspect

00:06:56.780 --> 00:06:58.970
to this that is part
of the discipline.

00:07:01.560 --> 00:07:05.980
And researchers compliment that
with a whole bunch of skills.

00:07:05.980 --> 00:07:08.690
One is in just
experimental design.

00:07:08.690 --> 00:07:12.550
How do I set up a study to find
the answer to this question?

00:07:12.550 --> 00:07:14.590
How do I pick which
participants I

00:07:14.590 --> 00:07:16.790
should be bringing
in to answer this?

00:07:16.790 --> 00:07:21.800
How do I mitigate the bias based
on this artificial situation

00:07:21.800 --> 00:07:23.120
I'm putting them in?

00:07:23.120 --> 00:07:25.420
Or based on which
users I select.

00:07:25.420 --> 00:07:28.060
How do I analyze the
data and collect it?

00:07:28.060 --> 00:07:30.694
And then once I've gotten
those findings together,

00:07:30.694 --> 00:07:32.610
how do I actually bring
those back to my team,

00:07:32.610 --> 00:07:34.300
to my designers,
to my engineers,

00:07:34.300 --> 00:07:37.265
and really convince them of the
importance of these findings.

00:07:37.265 --> 00:07:38.640
And those are all
critical skills

00:07:38.640 --> 00:07:41.330
that a really good
researcher can bring to bear.

00:07:41.330 --> 00:07:41.820
NAZMUL IDRIS: That makes sense.

00:07:41.820 --> 00:07:43.340
Sounds like researchers
are awesome,

00:07:43.340 --> 00:07:46.790
and they should be an
integral part of every team.

00:07:46.790 --> 00:07:48.320
RICHARD FULCHER: Definitely.

00:07:48.320 --> 00:07:51.220
Throughout my career, which is
[INTENTIONALLY MUMBLES] years

00:07:51.220 --> 00:07:58.250
back, I've been most
proud of products

00:07:58.250 --> 00:08:01.290
that I've shipped where
design and research have

00:08:01.290 --> 00:08:03.880
had a really strong
collaboration.

00:08:03.880 --> 00:08:06.520
One just makes the other better.

00:08:06.520 --> 00:08:10.820
When you have a designer who
really gets research and is

00:08:10.820 --> 00:08:13.040
an active participant
in that process,

00:08:13.040 --> 00:08:16.057
whether they're helping
to set up the experiment

00:08:16.057 --> 00:08:18.390
or they're taking notes, or
capturing video, or building

00:08:18.390 --> 00:08:21.390
a prototype, they
just get more and more

00:08:21.390 --> 00:08:24.060
of that immediate information
by being involved, instead of

00:08:24.060 --> 00:08:26.510
just waiting for the
findings of the report.

00:08:26.510 --> 00:08:28.350
And seeing things
firsthand is always

00:08:28.350 --> 00:08:31.059
more powerful than just reading
about it after the fact.

00:08:31.059 --> 00:08:32.350
NAZMUL IDRIS: That makes sense.

00:08:32.350 --> 00:08:33.883
It puts a human context to it.

00:08:33.883 --> 00:08:34.799
RICHARD FULCHER: Yeah.

00:08:34.799 --> 00:08:37.215
And it's definitely the kind
of thing that, as a designer,

00:08:37.215 --> 00:08:41.770
I will be working on something,
and I will think back

00:08:41.770 --> 00:08:43.774
to a very particular
experience I had of that.

00:08:43.774 --> 00:08:46.370
Oh, I remember when
this user came in,

00:08:46.370 --> 00:08:48.680
and they did this thing
that surprised me.

00:08:48.680 --> 00:08:51.730
And I definitely
dropped on that.

00:08:51.730 --> 00:08:54.480
Likewise, a really
great researcher

00:08:54.480 --> 00:08:56.930
will have a good understanding
of the design process.

00:08:56.930 --> 00:09:00.074
And they'll be really expert
at thinking about, well,

00:09:00.074 --> 00:09:01.490
if this is the
process, I know how

00:09:01.490 --> 00:09:03.810
to plug in here or here or here.

00:09:03.810 --> 00:09:06.360
And I know for each of those
opportunities what method

00:09:06.360 --> 00:09:08.180
is the right one
that I should employ.

00:09:08.180 --> 00:09:09.380
NAZMUL IDRIS: Cool.

00:09:09.380 --> 00:09:11.660
So now, speaking of plugging
into the process, what

00:09:11.660 --> 00:09:13.451
other ways have you
seen research conducted

00:09:13.451 --> 00:09:15.834
at different parts of the
product development life cycle?

00:09:15.834 --> 00:09:16.750
RICHARD FULCHER: Yeah.

00:09:16.750 --> 00:09:20.670
So this probably is a topic
that deserves it's own episode.

00:09:20.670 --> 00:09:22.240
But at a really
high level, I think,

00:09:22.240 --> 00:09:25.790
when you're starting
out on a project,

00:09:25.790 --> 00:09:28.000
you want to go out
and observe users

00:09:28.000 --> 00:09:31.192
in their natural environment.

00:09:31.192 --> 00:09:33.150
The kind of things that
you're looking for here

00:09:33.150 --> 00:09:36.010
are to challenge the assumptions
that you may already have.

00:09:36.010 --> 00:09:37.720
So you may think users
do this one thing.

00:09:37.720 --> 00:09:40.304
But by observing them you
see, OK, they do do that.

00:09:40.304 --> 00:09:41.720
But they also do
this other thing.

00:09:41.720 --> 00:09:43.761
Or they do this thing in
a slightly different way

00:09:43.761 --> 00:09:46.260
than I thought they would.

00:09:46.260 --> 00:09:49.002
So those little
surprising insights

00:09:49.002 --> 00:09:49.960
can be really valuable.

00:09:49.960 --> 00:09:52.168
And they may even shift the
direction of your product

00:09:52.168 --> 00:09:54.280
as you see those.

00:09:54.280 --> 00:09:57.450
You can also just learn
about what already exists.

00:09:57.450 --> 00:10:00.040
So you could look at other
studies that you've done,

00:10:00.040 --> 00:10:02.880
or that are published in
the academic literature,

00:10:02.880 --> 00:10:05.150
and things like that.

00:10:05.150 --> 00:10:08.010
You're asking this question,
what's already been done?

00:10:08.010 --> 00:10:09.990
But, really, the
second order question

00:10:09.990 --> 00:10:14.040
is, well, how did that work
out when people did that?

00:10:14.040 --> 00:10:17.270
So a little bit of that is
competitive evaluation--

00:10:17.270 --> 00:10:18.609
looking at other applications.

00:10:18.609 --> 00:10:19.900
NAZMUL IDRIS: That makes sense.

00:10:19.900 --> 00:10:22.780
So is this like testing
a competitor's product

00:10:22.780 --> 00:10:24.445
before actually
building your own?

00:10:24.445 --> 00:10:25.361
RICHARD FULCHER: Yeah.

00:10:25.361 --> 00:10:27.870
And I think a lot of
us do that already.

00:10:27.870 --> 00:10:29.870
People that are really
involved with technology,

00:10:29.870 --> 00:10:31.960
we just to do this
casually as a user.

00:10:31.960 --> 00:10:34.070
I mean, we use lots
of different products.

00:10:34.070 --> 00:10:35.850
And there's a lot of
input coming to us

00:10:35.850 --> 00:10:37.770
from just our day
to day behavior.

00:10:37.770 --> 00:10:39.580
And when we're
thinking about an area,

00:10:39.580 --> 00:10:43.240
sometimes it's because we've
used something similar,

00:10:43.240 --> 00:10:45.754
or maybe we've used something
that isn't satisfying for us.

00:10:45.754 --> 00:10:47.420
And we know we think
we can do something

00:10:47.420 --> 00:10:50.380
interesting or
different in that space.

00:10:50.380 --> 00:10:53.812
This is just taking that natural
instinct to go and learn,

00:10:53.812 --> 00:10:55.520
and making it a little
bit more rigorous.

00:10:55.520 --> 00:10:56.811
NAZMUL IDRIS: That makes sense.

00:10:56.811 --> 00:10:58.370
So now, after you've
gotten started,

00:10:58.370 --> 00:11:00.760
and you've chosen a
direction, and are actively

00:11:00.760 --> 00:11:02.940
doing development,
how does research

00:11:02.940 --> 00:11:04.632
come into play at that point?

00:11:04.632 --> 00:11:06.590
RICHARD FULCHER: Well,
I think research is best

00:11:06.590 --> 00:11:09.470
served when it's just
as iterative as the rest

00:11:09.470 --> 00:11:10.970
of your development process.

00:11:10.970 --> 00:11:14.900
So as early as you
can, you should

00:11:14.900 --> 00:11:18.840
get users to play with some
version of your product.

00:11:18.840 --> 00:11:21.920
And that could be a
working prototype.

00:11:21.920 --> 00:11:23.819
It could be just a
bunch of screenshots

00:11:23.819 --> 00:11:25.360
that have maybe been
linked together.

00:11:25.360 --> 00:11:27.860
It could just be
pieces of paper.

00:11:27.860 --> 00:11:30.090
I've definitely done all
of these forms of testing,

00:11:30.090 --> 00:11:33.580
where, for the paper, you get
to play the computer and shuffle

00:11:33.580 --> 00:11:36.090
around the different screens
and things like that.

00:11:36.090 --> 00:11:39.090
You're just trying to learn,
what's clicking for the user.

00:11:39.090 --> 00:11:43.080
What isn't clicking that I
can come back to and iterate,

00:11:43.080 --> 00:11:45.720
iterate, iterate.

00:11:45.720 --> 00:11:49.436
This is a mantra you'll hear
probably a lot on this show.

00:11:49.436 --> 00:11:51.310
Make mistakes early so
you can get over them,

00:11:51.310 --> 00:11:54.470
and make things better
in the next one.

00:11:54.470 --> 00:11:56.930
You can also just use this
to address any questions that

00:11:56.930 --> 00:12:02.310
come up during the course
of building the product out.

00:12:02.310 --> 00:12:04.380
There's almost always
some kind of technique

00:12:04.380 --> 00:12:06.450
that you can use to help
answer that question,

00:12:06.450 --> 00:12:09.380
even if it can't
answer it fully.

00:12:09.380 --> 00:12:11.929
If you're being forced to make
a compromise on the product--

00:12:11.929 --> 00:12:12.720
NAZMUL IDRIS: Yeah.

00:12:12.720 --> 00:12:13.320
That never happens.

00:12:13.320 --> 00:12:14.390
RICHARD FULCHER: Never.

00:12:14.390 --> 00:12:14.630
NAZMUL IDRIS: Yeah.

00:12:14.630 --> 00:12:16.088
I've never heard
of that, actually.

00:12:16.088 --> 00:12:17.950
RICHARD FULCHER: Nope.

00:12:17.950 --> 00:12:21.060
Being able to draw upon
research to help you resolve

00:12:21.060 --> 00:12:23.860
how to best make that
set of trade-offs

00:12:23.860 --> 00:12:26.154
is something that can
be really helpful.

00:12:26.154 --> 00:12:26.945
NAZMUL IDRIS: Yeah.

00:12:26.945 --> 00:12:28.230
No, that's true.

00:12:28.230 --> 00:12:30.772
So now, as you get closer to
the end of this development life

00:12:30.772 --> 00:12:32.646
cycle, and you're about
to release a product,

00:12:32.646 --> 00:12:34.460
how does research
come into play here?

00:12:34.460 --> 00:12:36.844
I mean, is this where
usability testing comes in?

00:12:36.844 --> 00:12:37.760
RICHARD FULCHER: Yeah.

00:12:37.760 --> 00:12:39.980
It's definitely the
most typical time

00:12:39.980 --> 00:12:41.730
that you'll see in-lab testing.

00:12:41.730 --> 00:12:45.180
So you get the
working product there.

00:12:45.180 --> 00:12:46.960
The kind of things
you're doing, I think,

00:12:46.960 --> 00:12:50.770
best serving at that point are
you're catching final bugs.

00:12:50.770 --> 00:12:52.830
You're trying to
identify, am I really

00:12:52.830 --> 00:12:55.330
ready to launch this thing?

00:12:55.330 --> 00:12:58.100
And, in particular, I think it
identifies the types of bugs

00:12:58.100 --> 00:13:01.200
that maybe your
own team has just

00:13:01.200 --> 00:13:03.850
habituated itself
to and overcome.

00:13:03.850 --> 00:13:06.084
And so it might be
problems with the first use

00:13:06.084 --> 00:13:07.500
experience for
somebody who hasn't

00:13:07.500 --> 00:13:09.570
been using every
version of the product

00:13:09.570 --> 00:13:10.520
you've worked on for
the last three months.

00:13:10.520 --> 00:13:10.700
NAZMUL IDRIS: Right.

00:13:10.700 --> 00:13:11.405
Because you're
biased, obviously.

00:13:11.405 --> 00:13:12.571
RICHARD FULCHER: Absolutely.

00:13:12.571 --> 00:13:16.760
You carry a ton of bias,
just from your experience.

00:13:16.760 --> 00:13:19.785
But you should be kept
really apprehensive

00:13:19.785 --> 00:13:21.570
if this is the first
part of research

00:13:21.570 --> 00:13:23.030
that you're doing at this point.

00:13:23.030 --> 00:13:26.190
Changes that you make here
are really expensive in terms

00:13:26.190 --> 00:13:29.296
of time, of resource, of
possibly delaying your launch.

00:13:29.296 --> 00:13:31.420
NAZMUL IDRIS: That's why
iterating is so important.

00:13:31.420 --> 00:13:32.190
RICHARD FULCHER: That's
why it's important.

00:13:32.190 --> 00:13:34.430
And this is-- don't
just wait till the end,

00:13:34.430 --> 00:13:36.480
and don't just do
validation testing.

00:13:36.480 --> 00:13:41.220
Understand your users much,
much earlier whenever you can.

00:13:41.220 --> 00:13:43.430
And then when you're
at the end-- of course,

00:13:43.430 --> 00:13:46.400
launching isn't
really the end-- once

00:13:46.400 --> 00:13:48.750
you get the product
launch, you can

00:13:48.750 --> 00:13:52.330
observe how live users use
the product in the wild.

00:13:54.931 --> 00:13:57.430
Not just, how does somebody use
it two minutes after they've

00:13:57.430 --> 00:13:59.940
been introduced, but two
days later, two weeks,

00:13:59.940 --> 00:14:00.940
two months later.

00:14:00.940 --> 00:14:03.330
And how does that change.

00:14:03.330 --> 00:14:04.080
What do they need?

00:14:04.080 --> 00:14:04.960
What do they want?

00:14:04.960 --> 00:14:06.130
What don't they use?

00:14:06.130 --> 00:14:07.520
So you can look at logs.

00:14:07.520 --> 00:14:10.770
You can look at comments
on the Play Store.

00:14:10.770 --> 00:14:12.840
You can start at this
point thinking about,

00:14:12.840 --> 00:14:14.680
well, what's that
next release like?

00:14:14.680 --> 00:14:17.405
What's really, really critical
that I need to have in there

00:14:17.405 --> 00:14:20.200
because it's still
missing this for users.

00:14:20.200 --> 00:14:23.070
What did I think was going to
be a big thing that I was going

00:14:23.070 --> 00:14:26.526
to do more work on, but now it's
just not important to users.

00:14:26.526 --> 00:14:27.900
So maybe I'd pull
back from that.

00:14:27.900 --> 00:14:28.540
NAZMUL IDRIS: Exactly.

00:14:28.540 --> 00:14:28.690
Yeah.

00:14:28.690 --> 00:14:30.125
I know because it's not
like your application is

00:14:30.125 --> 00:14:30.800
ever finished.

00:14:30.800 --> 00:14:32.270
Just because you've
launched a current version

00:14:32.270 --> 00:14:33.890
doesn't mean you're
going to not do upgrades

00:14:33.890 --> 00:14:36.265
and doesn't mean there's not
going to be another version.

00:14:36.265 --> 00:14:37.400
So it never really ends.

00:14:37.400 --> 00:14:37.880
RICHARD FULCHER: No.

00:14:37.880 --> 00:14:39.047
No, your work is never done.

00:14:39.047 --> 00:14:41.046
NAZMUL IDRIS: If you do
it right, it never ends.

00:14:41.046 --> 00:14:42.330
RICHARD FULCHER: That's right.

00:14:42.330 --> 00:14:43.720
That's the positive
way to think about it.

00:14:43.720 --> 00:14:44.636
NAZMUL IDRIS: Exactly.

00:14:44.636 --> 00:14:47.350
So what are some things
that designers in particular

00:14:47.350 --> 00:14:49.320
are looking to get
out of user research?

00:14:49.320 --> 00:14:50.460
RICHARD FULCHER: Yeah.

00:14:50.460 --> 00:14:52.080
I mean, for me it's
always just great

00:14:52.080 --> 00:14:55.790
to hear users talk in
their own language,

00:14:55.790 --> 00:14:59.260
and just pay attention to
the particular vocabulary

00:14:59.260 --> 00:15:02.990
that a user makes use of when
going through your product.

00:15:02.990 --> 00:15:05.050
Or even separate
from your product,

00:15:05.050 --> 00:15:08.550
when just doing their
task without it.

00:15:08.550 --> 00:15:10.170
You can take that
language, and you

00:15:10.170 --> 00:15:12.230
can borrow it, and
include it into the UI.

00:15:12.230 --> 00:15:14.130
So that might be how
you label an action,

00:15:14.130 --> 00:15:17.890
or what you choose
to depict as an icon.

00:15:17.890 --> 00:15:18.880
Or things like that.

00:15:18.880 --> 00:15:20.610
It just reduces the
need for the user

00:15:20.610 --> 00:15:23.939
to translate between their
world and your world.

00:15:23.939 --> 00:15:24.730
NAZMUL IDRIS: Yeah.

00:15:24.730 --> 00:15:27.650
It reduces the cognitive load,
and it makes it more intuitive.

00:15:27.650 --> 00:15:28.525
RICHARD FULCHER: Yes.

00:15:28.525 --> 00:15:31.040
And I think that's a lot of
what intuitive, to a user,

00:15:31.040 --> 00:15:32.892
means is it's familiar to me.

00:15:32.892 --> 00:15:34.350
Either because it's
in the language

00:15:34.350 --> 00:15:37.140
I understand, or it's doing
things that I expect it to do,

00:15:37.140 --> 00:15:38.410
based on other context.

00:15:38.410 --> 00:15:42.260
I think that's what
intuition is for users.

00:15:42.260 --> 00:15:45.280
An example might be, if the
users might use the word,

00:15:45.280 --> 00:15:48.130
settings, you might want to
use the word, preference,

00:15:48.130 --> 00:15:52.090
because you think it's
more correct in some form.

00:15:52.090 --> 00:15:54.430
But if that's not the
language the user uses,

00:15:54.430 --> 00:15:57.460
they have to do the translation
work to come to your product.

00:15:57.460 --> 00:15:59.220
You can, instead,
do the design work

00:15:59.220 --> 00:16:01.595
to bring the product closer
to what the user understands,

00:16:01.595 --> 00:16:04.860
and just spare them that effort.

00:16:04.860 --> 00:16:07.470
And the last thing
about language

00:16:07.470 --> 00:16:09.230
is it can also be
a bit of a doorway

00:16:09.230 --> 00:16:13.720
into understanding the
users thought process.

00:16:13.720 --> 00:16:18.280
So if you talk to a designer for
more than two or three minutes,

00:16:18.280 --> 00:16:20.894
you're going to hear the
phrase, mental model.

00:16:20.894 --> 00:16:21.394
And there.

00:16:21.394 --> 00:16:22.019
I've got it in.

00:16:22.019 --> 00:16:23.810
So I earned my badge.

00:16:26.410 --> 00:16:27.880
We'd love to talk about that.

00:16:27.880 --> 00:16:33.150
All that really means is how
the user understands a process

00:16:33.150 --> 00:16:35.810
to work in the world.

00:16:35.810 --> 00:16:41.290
And I've seen users
construct both vastly simpler

00:16:41.290 --> 00:16:43.100
mental models than
the real model,

00:16:43.100 --> 00:16:47.930
and much, much, much more
complicated things as well.

00:16:47.930 --> 00:16:51.810
So one example is
for a mobile device.

00:16:51.810 --> 00:16:53.240
Battery usage.

00:16:53.240 --> 00:16:57.370
I see users in
research who engage

00:16:57.370 --> 00:17:01.410
in all kinds of bizarre,
ritualistic behaviors

00:17:01.410 --> 00:17:03.320
because they have a
mental model that says,

00:17:03.320 --> 00:17:05.819
if I do these things, I will
get more battery or life.

00:17:05.819 --> 00:17:09.347
So they swipe away
recent applications

00:17:09.347 --> 00:17:10.305
that they're not using.

00:17:10.305 --> 00:17:10.700
Or they--

00:17:10.700 --> 00:17:11.700
NAZMUL IDRIS: I do that.

00:17:11.700 --> 00:17:13.380
RICHARD FULCHER: You
do-- well, there.

00:17:13.380 --> 00:17:15.020
Now I've taught you something.

00:17:15.020 --> 00:17:18.030
It's all even.

00:17:18.030 --> 00:17:20.300
Or they put the device
in airplane mode.

00:17:20.300 --> 00:17:23.270
And, of course, as
they're doing all of this,

00:17:23.270 --> 00:17:25.859
they're driving the screen
at the highest brightness

00:17:25.859 --> 00:17:27.660
and keeping the display active.

00:17:27.660 --> 00:17:30.640
And, actually, possibly being
contrary to their goals.

00:17:30.640 --> 00:17:34.252
Because the mental model
doesn't match the real model.

00:17:34.252 --> 00:17:37.386
And when there is
that mismatch, I

00:17:37.386 --> 00:17:39.260
get very excited as a
designer because that's

00:17:39.260 --> 00:17:40.120
a huge opportunity.

00:17:40.120 --> 00:17:40.610
NAZMUL IDRIS: No.

00:17:40.610 --> 00:17:41.280
That makes sense.

00:17:41.280 --> 00:17:43.780
RICHARD FULCHER: Once I see,
oh, the user doesn't understand

00:17:43.780 --> 00:17:45.402
this, but if they
could understand it,

00:17:45.402 --> 00:17:46.610
they would be more effective.

00:17:46.610 --> 00:17:49.512
Or their battery would last
longer, or things like that.

00:17:49.512 --> 00:17:51.720
So those points of difference
are really interesting.

00:17:51.720 --> 00:17:51.760
NAZMUL IDRIS: No.

00:17:51.760 --> 00:17:53.426
Definitely another
example of this point

00:17:53.426 --> 00:17:55.400
is the refresh
button, where folks

00:17:55.400 --> 00:17:58.159
that are not familiar
with, basically,

00:17:58.159 --> 00:17:59.950
data being pushed
directly into the device,

00:17:59.950 --> 00:18:01.950
might think that, oh,
there's no refresh button.

00:18:01.950 --> 00:18:04.000
So the data that
they're seeing is stale.

00:18:04.000 --> 00:18:06.130
But, actually, it's being
updated in real time.

00:18:06.130 --> 00:18:08.270
And they just don't have
an awareness of that.

00:18:08.270 --> 00:18:12.510
And then that can actually be
contrary to their perception

00:18:12.510 --> 00:18:14.320
and expectation
from the software.

00:18:14.320 --> 00:18:16.367
It feels like, oh,
it's not performing

00:18:16.367 --> 00:18:18.950
as well as it should because it
doesn't have a refresh button.

00:18:18.950 --> 00:18:20.533
But, in reality, it
is performing well

00:18:20.533 --> 00:18:22.434
because it doesn't
have a refresh button.

00:18:22.434 --> 00:18:23.350
RICHARD FULCHER: Yeah.

00:18:23.350 --> 00:18:26.350
We try to be really
careful as designers

00:18:26.350 --> 00:18:30.030
not to create the opportunity
for false rituals.

00:18:30.030 --> 00:18:32.290
Like by removing a
refresh button that

00:18:32.290 --> 00:18:35.350
doesn't do anything, I'm
hopefully moving a user

00:18:35.350 --> 00:18:38.100
away from just doing
things to no benefit,

00:18:38.100 --> 00:18:39.860
or to no end result.

00:18:39.860 --> 00:18:42.830
And, ideally, I'm
freeing up space

00:18:42.830 --> 00:18:45.710
to take a meaningless
action away, and put

00:18:45.710 --> 00:18:47.216
a meaningful action
in its place.

00:18:47.216 --> 00:18:48.590
Because I only
have so much space

00:18:48.590 --> 00:18:49.600
to put all of these
actions anyway.

00:18:49.600 --> 00:18:52.430
And the more actions I put, the
less emphasis any one of them

00:18:52.430 --> 00:18:53.400
gets.

00:18:53.400 --> 00:18:54.660
So, yes.

00:18:54.660 --> 00:18:57.389
This is very much what
I do on a daily basis.

00:18:57.389 --> 00:18:58.680
NAZMUL IDRIS: That's fantastic.

00:18:58.680 --> 00:19:02.855
So how does user research
help other folks in a team?

00:19:02.855 --> 00:19:05.230
Because we've talked about
the benefits to the designers.

00:19:05.230 --> 00:19:07.610
What about benefits to
PMs-- product managers--

00:19:07.610 --> 00:19:08.962
and also engineers?

00:19:08.962 --> 00:19:10.420
RICHARD FULCHER:
I think everything

00:19:10.420 --> 00:19:14.540
you do to better understand
your users can help.

00:19:14.540 --> 00:19:17.290
And I'm saying help.

00:19:17.290 --> 00:19:20.230
That's not the same as,
make your job easier.

00:19:20.230 --> 00:19:22.870
Because sometimes it's very easy
to make an ignorant decision

00:19:22.870 --> 00:19:25.850
without knowledge of your users.

00:19:25.850 --> 00:19:30.640
Research often will reveal that
there's a lot more variability

00:19:30.640 --> 00:19:33.570
in your audience than
you probably had in mind.

00:19:33.570 --> 00:19:36.340
And that can complicate some
of your decision making.

00:19:36.340 --> 00:19:39.710
NAZMUL IDRIS: So this is kind
of like how user research allows

00:19:39.710 --> 00:19:42.300
us to-- it's like
we get to create

00:19:42.300 --> 00:19:44.880
our own mental models
off actual users.

00:19:44.880 --> 00:19:48.650
And our mental models
might be overly simplistic,

00:19:48.650 --> 00:19:51.327
and not actually match the
reality of our actual users.

00:19:51.327 --> 00:19:52.910
RICHARD FULCHER:
That's exactly right.

00:19:52.910 --> 00:19:54.830
I mean, the mental
model we may have

00:19:54.830 --> 00:19:57.650
may be just loaded
with our own biases.

00:19:57.650 --> 00:20:00.770
In a lot of ways, that mental
model of who the user is

00:20:00.770 --> 00:20:02.980
could just be, well, they're me.

00:20:02.980 --> 00:20:04.960
Because I know that person best.

00:20:04.960 --> 00:20:07.345
And I want to use this product.

00:20:07.345 --> 00:20:08.430
So I'm obviously the user.

00:20:08.430 --> 00:20:11.610
NAZMUL IDRIS: Everyone
is just like me.

00:20:11.610 --> 00:20:14.560
RICHARD FULCHER:
That's not true at all.

00:20:14.560 --> 00:20:17.500
So by doing research,
you can help

00:20:17.500 --> 00:20:20.130
release yourself, and
release the rest of the team

00:20:20.130 --> 00:20:22.050
from those types of
biases, and getting away

00:20:22.050 --> 00:20:24.850
from that monolithic
model of, the user is me.

00:20:27.590 --> 00:20:31.970
This is also helpful
in making some

00:20:31.970 --> 00:20:33.400
of the debates
about the decision

00:20:33.400 --> 00:20:37.760
and those compromises
less confrontational.

00:20:37.760 --> 00:20:39.710
Because you're not talking
about, I want this,

00:20:39.710 --> 00:20:40.750
and you want that.

00:20:40.750 --> 00:20:43.449
It's, our users are
telling us this.

00:20:43.449 --> 00:20:45.240
NAZMUL IDRIS: We're
advocates for the user.

00:20:45.240 --> 00:20:46.120
They're the stakeholders.

00:20:46.120 --> 00:20:46.760
Not us.

00:20:46.760 --> 00:20:47.240
RICHARD FULCHER:
And that doesn't

00:20:47.240 --> 00:20:48.470
mean the answer is obvious.

00:20:48.470 --> 00:20:53.010
But at least we can
engage in an honest debate

00:20:53.010 --> 00:20:55.450
about the right way
to try to satisfy

00:20:55.450 --> 00:20:57.922
a goal that we agree on.

00:20:57.922 --> 00:20:59.380
And when you have
research, you can

00:20:59.380 --> 00:21:00.713
talk about what you've observed.

00:21:00.713 --> 00:21:03.620
You can think back to that user,
and tell that little anecdote

00:21:03.620 --> 00:21:06.997
about, well, that might be true
for you, but I saw this user.

00:21:06.997 --> 00:21:08.830
And they did this thing,
which surprised me.

00:21:08.830 --> 00:21:11.700
But they did it.

00:21:11.700 --> 00:21:16.260
There was a trick I learned
from a colleague long ago,

00:21:16.260 --> 00:21:19.840
which is to be very
conscientious about that bias

00:21:19.840 --> 00:21:22.406
by just repeating the
word, I, when you're

00:21:22.406 --> 00:21:23.780
speaking about
your own opinions.

00:21:23.780 --> 00:21:26.930
So if I say, well,
I-I-I think the product

00:21:26.930 --> 00:21:27.980
should work this way.

00:21:27.980 --> 00:21:29.940
Just saying it three
times, it makes it clear

00:21:29.940 --> 00:21:31.610
that-- which is
important, especially

00:21:31.610 --> 00:21:33.770
for a designer--
that's me talking.

00:21:33.770 --> 00:21:35.840
Not me speaking on
behalf of the users.

00:21:35.840 --> 00:21:36.080
NAZMUL IDRIS: Definitely.

00:21:36.080 --> 00:21:37.550
You're signaling
to your colleagues

00:21:37.550 --> 00:21:39.710
that this is your
own personal opinion.

00:21:39.710 --> 00:21:42.340
So they can treat it
with whatever bias--

00:21:42.340 --> 00:21:44.310
I mean, look at it
with bias that's built

00:21:44.310 --> 00:21:45.384
into that statement.

00:21:45.384 --> 00:21:46.300
RICHARD FULCHER: Yeah.

00:21:46.300 --> 00:21:47.550
And I think it's
helpful for others,

00:21:47.550 --> 00:21:49.050
but it's also just
helpful for me.

00:21:49.050 --> 00:21:51.760
Because that ritual
that I have of doing,

00:21:51.760 --> 00:21:55.780
I-I-I, is there to remind me
that this is what I'm thinking,

00:21:55.780 --> 00:21:58.542
not what others have
shown me from research.

00:21:58.542 --> 00:21:59.250
NAZMUL IDRIS: No.

00:21:59.250 --> 00:22:00.461
That makes sense.

00:22:00.461 --> 00:22:02.460
So that's all the time
we have for this episode.

00:22:02.460 --> 00:22:02.950
RICHARD FULCHER: Ah.

00:22:02.950 --> 00:22:03.825
NAZMUL IDRIS: I know.

00:22:03.825 --> 00:22:05.750
Thank you so much
for being here, Rich.

00:22:05.750 --> 00:22:08.460
We will do many more episodes
on the topic of user research

00:22:08.460 --> 00:22:09.230
very soon.

00:22:09.230 --> 00:22:09.860
RICHARD FULCHER: Great.

00:22:09.860 --> 00:22:10.984
Well, thanks for having me.

00:22:10.984 --> 00:22:12.040
It's been a pleasure.

00:22:12.040 --> 00:22:13.081
NAZMUL IDRIS: Absolutely.

00:22:13.081 --> 00:22:15.490
And if you haven't already,
please be sure to join our UX

00:22:15.490 --> 00:22:16.365
community on Google+.

00:22:16.365 --> 00:22:18.810
It's a place where you can
continue this discussion.

00:22:18.810 --> 00:22:22.360
And you can meet others who
are just as passionate about UX

00:22:22.360 --> 00:22:23.470
as you are.

00:22:23.470 --> 00:22:25.710
Thank you very much,
and have a great day.

00:22:25.710 --> 00:22:27.150
Goodbye.

