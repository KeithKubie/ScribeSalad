WEBVTT
Kind: captions
Language: en

00:00:00.370 --> 00:00:04.620
[Music]

00:00:04.620 --> 00:00:04.630
[Music]
 

00:00:04.630 --> 00:00:06.580
[Music]
first of all there's a whole question

00:00:06.580 --> 00:00:06.590
first of all there's a whole question
 

00:00:06.590 --> 00:00:09.669
first of all there's a whole question
about what what why is it that we in the

00:00:09.669 --> 00:00:09.679
about what what why is it that we in the
 

00:00:09.679 --> 00:00:11.400
about what what why is it that we in the
first place assume that we have

00:00:11.400 --> 00:00:11.410
first place assume that we have
 

00:00:11.410 --> 00:00:14.499
first place assume that we have
obligations towards robots so we think

00:00:14.499 --> 00:00:14.509
obligations towards robots so we think
 

00:00:14.509 --> 00:00:16.840
obligations towards robots so we think
that if something is intelligent then

00:00:16.840 --> 00:00:16.850
that if something is intelligent then
 

00:00:16.850 --> 00:00:19.120
that if something is intelligent then
that's that's their special source

00:00:19.120 --> 00:00:19.130
that's that's their special source
 

00:00:19.130 --> 00:00:20.560
that's that's their special source
that's that's why we have moral

00:00:20.560 --> 00:00:20.570
that's that's why we have moral
 

00:00:20.570 --> 00:00:22.780
that's that's why we have moral
obligations right and and why do we

00:00:22.780 --> 00:00:22.790
obligations right and and why do we
 

00:00:22.790 --> 00:00:25.120
obligations right and and why do we
think that because most of our moral

00:00:25.120 --> 00:00:25.130
think that because most of our moral
 

00:00:25.130 --> 00:00:27.640
think that because most of our moral
obligations the most important thing to

00:00:27.640 --> 00:00:27.650
obligations the most important thing to
 

00:00:27.650 --> 00:00:29.620
obligations the most important thing to
us is each other we're trying you know

00:00:29.620 --> 00:00:29.630
us is each other we're trying you know
 

00:00:29.630 --> 00:00:31.840
us is each other we're trying you know
so basically morality and ethics are the

00:00:31.840 --> 00:00:31.850
so basically morality and ethics are the
 

00:00:31.850 --> 00:00:33.639
so basically morality and ethics are the
way that we maintain human society

00:00:33.639 --> 00:00:33.649
way that we maintain human society
 

00:00:33.649 --> 00:00:35.650
way that we maintain human society
including by doing things like keeping

00:00:35.650 --> 00:00:35.660
including by doing things like keeping
 

00:00:35.660 --> 00:00:37.810
including by doing things like keeping
the environment okay you know making it

00:00:37.810 --> 00:00:37.820
the environment okay you know making it
 

00:00:37.820 --> 00:00:41.560
the environment okay you know making it
so we can live all right so one of the

00:00:41.560 --> 00:00:41.570
so we can live all right so one of the
 

00:00:41.570 --> 00:00:43.960
so we can live all right so one of the
ways we characterize ourselves is as

00:00:43.960 --> 00:00:43.970
ways we characterize ourselves is as
 

00:00:43.970 --> 00:00:46.780
ways we characterize ourselves is as
intelligent and so when we then see

00:00:46.780 --> 00:00:46.790
intelligent and so when we then see
 

00:00:46.790 --> 00:00:48.100
intelligent and so when we then see
something else and say oh it's more

00:00:48.100 --> 00:00:48.110
something else and say oh it's more
 

00:00:48.110 --> 00:00:49.600
something else and say oh it's more
intelligent well then maybe it needs

00:00:49.600 --> 00:00:49.610
intelligent well then maybe it needs
 

00:00:49.610 --> 00:00:52.540
intelligent well then maybe it needs
even more protection alright so that we

00:00:52.540 --> 00:00:52.550
even more protection alright so that we
 

00:00:52.550 --> 00:00:54.760
even more protection alright so that we
in AI we call that kind of reasoning

00:00:54.760 --> 00:00:54.770
in AI we call that kind of reasoning
 

00:00:54.770 --> 00:00:56.530
in AI we call that kind of reasoning
heuristic reasoning it's a good guess

00:00:56.530 --> 00:00:56.540
heuristic reasoning it's a good guess
 

00:00:56.540 --> 00:00:59.160
heuristic reasoning it's a good guess
it'll probably get you pretty far right

00:00:59.160 --> 00:00:59.170
it'll probably get you pretty far right
 

00:00:59.170 --> 00:01:02.080
it'll probably get you pretty far right
but it isn't necessarily true I mean

00:01:02.080 --> 00:01:02.090
but it isn't necessarily true I mean
 

00:01:02.090 --> 00:01:04.689
but it isn't necessarily true I mean
again how you define the term

00:01:04.689 --> 00:01:04.699
again how you define the term
 

00:01:04.699 --> 00:01:08.020
again how you define the term
intelligent will vary if you mean by

00:01:08.020 --> 00:01:08.030
intelligent will vary if you mean by
 

00:01:08.030 --> 00:01:11.440
intelligent will vary if you mean by
intelligent a moral agent you know

00:01:11.440 --> 00:01:11.450
intelligent a moral agent you know
 

00:01:11.450 --> 00:01:13.120
intelligent a moral agent you know
something that that's responsible for

00:01:13.120 --> 00:01:13.130
something that that's responsible for
 

00:01:13.130 --> 00:01:14.320
something that that's responsible for
its actions well then of course

00:01:14.320 --> 00:01:14.330
its actions well then of course
 

00:01:14.330 --> 00:01:16.810
its actions well then of course
intelligence implies moral agency when

00:01:16.810 --> 00:01:16.820
intelligence implies moral agency when
 

00:01:16.820 --> 00:01:18.280
intelligence implies moral agency when
will we know for sure that we need to

00:01:18.280 --> 00:01:18.290
will we know for sure that we need to
 

00:01:18.290 --> 00:01:21.520
will we know for sure that we need to
worry about robots well there's there's

00:01:21.520 --> 00:01:21.530
worry about robots well there's there's
 

00:01:21.530 --> 00:01:24.300
worry about robots well there's there's
all hotness questions there but

00:01:24.300 --> 00:01:24.310
all hotness questions there but
 

00:01:24.310 --> 00:01:26.350
all hotness questions there but
consciousness is another one of those

00:01:26.350 --> 00:01:26.360
consciousness is another one of those
 

00:01:26.360 --> 00:01:29.620
consciousness is another one of those
words the word I like to use is moral

00:01:29.620 --> 00:01:29.630
words the word I like to use is moral
 

00:01:29.630 --> 00:01:32.080
words the word I like to use is moral
patient it's a it's a tactical term that

00:01:32.080 --> 00:01:32.090
patient it's a it's a tactical term that
 

00:01:32.090 --> 00:01:34.060
patient it's a it's a tactical term that
the philosophers came up with and it

00:01:34.060 --> 00:01:34.070
the philosophers came up with and it
 

00:01:34.070 --> 00:01:36.370
the philosophers came up with and it
means exactly something that we are

00:01:36.370 --> 00:01:36.380
means exactly something that we are
 

00:01:36.380 --> 00:01:38.710
means exactly something that we are
obliged to take care of so now we can

00:01:38.710 --> 00:01:38.720
obliged to take care of so now we can
 

00:01:38.720 --> 00:01:40.870
obliged to take care of so now we can
have this conversation if you just mean

00:01:40.870 --> 00:01:40.880
have this conversation if you just mean
 

00:01:40.880 --> 00:01:43.780
have this conversation if you just mean
conscious means moral patient then then

00:01:43.780 --> 00:01:43.790
conscious means moral patient then then
 

00:01:43.790 --> 00:01:46.060
conscious means moral patient then then
it's no great assumption disabled then

00:01:46.060 --> 00:01:46.070
it's no great assumption disabled then
 

00:01:46.070 --> 00:01:48.490
it's no great assumption disabled then
if it's conscious then then we need to

00:01:48.490 --> 00:01:48.500
if it's conscious then then we need to
 

00:01:48.500 --> 00:01:50.380
if it's conscious then then we need to
be you know we need to take care of it

00:01:50.380 --> 00:01:50.390
be you know we need to take care of it
 

00:01:50.390 --> 00:01:54.240
be you know we need to take care of it
but it's a way more cool if you can say

00:01:54.240 --> 00:01:54.250
but it's a way more cool if you can say
 

00:01:54.250 --> 00:01:58.300
but it's a way more cool if you can say
does consciousness necessitate moral

00:01:58.300 --> 00:01:58.310
does consciousness necessitate moral
 

00:01:58.310 --> 00:02:00.580
does consciousness necessitate moral
patientsí right and then we can sit down

00:02:00.580 --> 00:02:00.590
patientsí right and then we can sit down
 

00:02:00.590 --> 00:02:02.020
patientsí right and then we can sit down
and say well it depends what you mean by

00:02:02.020 --> 00:02:02.030
and say well it depends what you mean by
 

00:02:02.030 --> 00:02:03.819
and say well it depends what you mean by
consciousness right people use

00:02:03.819 --> 00:02:03.829
consciousness right people use
 

00:02:03.829 --> 00:02:05.260
consciousness right people use
consciousness to mean a lot of different

00:02:05.260 --> 00:02:05.270
consciousness to mean a lot of different
 

00:02:05.270 --> 00:02:08.020
consciousness to mean a lot of different
things so one of the things that we did

00:02:08.020 --> 00:02:08.030
things so one of the things that we did
 

00:02:08.030 --> 00:02:10.210
things so one of the things that we did
last year which was pretty cool the

00:02:10.210 --> 00:02:10.220
last year which was pretty cool the
 

00:02:10.220 --> 00:02:12.550
last year which was pretty cool the
headlines because we were replicating

00:02:12.550 --> 00:02:12.560
headlines because we were replicating
 

00:02:12.560 --> 00:02:15.680
headlines because we were replicating
some psychology stuff about

00:02:15.680 --> 00:02:15.690
some psychology stuff about
 

00:02:15.690 --> 00:02:18.240
some psychology stuff about
implicit bias actually the best one is

00:02:18.240 --> 00:02:18.250
implicit bias actually the best one is
 

00:02:18.250 --> 00:02:20.790
implicit bias actually the best one is
something like scientists show that AI

00:02:20.790 --> 00:02:20.800
something like scientists show that AI
 

00:02:20.800 --> 00:02:23.570
something like scientists show that AI
is sexist and racist and it's our fault

00:02:23.570 --> 00:02:23.580
is sexist and racist and it's our fault
 

00:02:23.580 --> 00:02:25.710
is sexist and racist and it's our fault
which is that's pretty accurate because

00:02:25.710 --> 00:02:25.720
which is that's pretty accurate because
 

00:02:25.720 --> 00:02:28.320
which is that's pretty accurate because
it really is about picking things up

00:02:28.320 --> 00:02:28.330
it really is about picking things up
 

00:02:28.330 --> 00:02:31.920
it really is about picking things up
from our society anyway the point was so

00:02:31.920 --> 00:02:31.930
from our society anyway the point was so
 

00:02:31.930 --> 00:02:34.590
from our society anyway the point was so
here is an AI system that is so

00:02:34.590 --> 00:02:34.600
here is an AI system that is so
 

00:02:34.600 --> 00:02:36.420
here is an AI system that is so
human-like that it's picked up by our

00:02:36.420 --> 00:02:36.430
human-like that it's picked up by our
 

00:02:36.430 --> 00:02:38.970
human-like that it's picked up by our
prejudices and whatever and it's just

00:02:38.970 --> 00:02:38.980
prejudices and whatever and it's just
 

00:02:38.980 --> 00:02:41.670
prejudices and whatever and it's just
vectors it's not an ape it's not going

00:02:41.670 --> 00:02:41.680
vectors it's not an ape it's not going
 

00:02:41.680 --> 00:02:42.840
vectors it's not an ape it's not going
to take over the world it's not going to

00:02:42.840 --> 00:02:42.850
to take over the world it's not going to
 

00:02:42.850 --> 00:02:44.610
to take over the world it's not going to
do anything it's just a representations

00:02:44.610 --> 00:02:44.620
do anything it's just a representations
 

00:02:44.620 --> 00:02:48.449
do anything it's just a representations
like a photograph right and and so I the

00:02:48.449 --> 00:02:48.459
like a photograph right and and so I the
 

00:02:48.459 --> 00:02:51.810
like a photograph right and and so I the
the art we can't trust our intuitions

00:02:51.810 --> 00:02:51.820
the art we can't trust our intuitions
 

00:02:51.820 --> 00:02:56.090
the art we can't trust our intuitions
about these things we give things rights

00:02:56.090 --> 00:02:56.100
about these things we give things rights
 

00:02:56.100 --> 00:02:58.890
about these things we give things rights
because that's the best way we can find

00:02:58.890 --> 00:02:58.900
because that's the best way we can find
 

00:02:58.900 --> 00:03:01.650
because that's the best way we can find
to handle very complicated situations

00:03:01.650 --> 00:03:01.660
to handle very complicated situations
 

00:03:01.660 --> 00:03:03.390
to handle very complicated situations
and the things that we give rights are

00:03:03.390 --> 00:03:03.400
and the things that we give rights are
 

00:03:03.400 --> 00:03:05.729
and the things that we give rights are
basically people I mean some people

00:03:05.729 --> 00:03:05.739
basically people I mean some people
 

00:03:05.739 --> 00:03:09.810
basically people I mean some people
argue about animals but technically and

00:03:09.810 --> 00:03:09.820
argue about animals but technically and
 

00:03:09.820 --> 00:03:11.250
argue about animals but technically and
again this depends on who's technical

00:03:11.250 --> 00:03:11.260
again this depends on who's technical
 

00:03:11.260 --> 00:03:12.600
again this depends on who's technical
definition you use but technically

00:03:12.600 --> 00:03:12.610
definition you use but technically
 

00:03:12.610 --> 00:03:15.030
definition you use but technically
rights are usually things that come with

00:03:15.030 --> 00:03:15.040
rights are usually things that come with
 

00:03:15.040 --> 00:03:18.120
rights are usually things that come with
responsibilities and that you can defend

00:03:18.120 --> 00:03:18.130
responsibilities and that you can defend
 

00:03:18.130 --> 00:03:20.880
responsibilities and that you can defend
in a court of law so so normally we talk

00:03:20.880 --> 00:03:20.890
in a court of law so so normally we talk
 

00:03:20.890 --> 00:03:23.250
in a court of law so so normally we talk
about animal welfare and we talk about

00:03:23.250 --> 00:03:23.260
about animal welfare and we talk about
 

00:03:23.260 --> 00:03:29.759
about animal welfare and we talk about
human rights but the with with

00:03:29.759 --> 00:03:29.769
human rights but the with with
 

00:03:29.769 --> 00:03:31.350
human rights but the with with
artificial intelligence you can even

00:03:31.350 --> 00:03:31.360
artificial intelligence you can even
 

00:03:31.360 --> 00:03:33.630
artificial intelligence you can even
imagine itself knowing its rights and

00:03:33.630 --> 00:03:33.640
imagine itself knowing its rights and
 

00:03:33.640 --> 00:03:35.850
imagine itself knowing its rights and
defending itself in the court of law but

00:03:35.850 --> 00:03:35.860
defending itself in the court of law but
 

00:03:35.860 --> 00:03:38.400
defending itself in the court of law but
the question is why would we need to

00:03:38.400 --> 00:03:38.410
the question is why would we need to
 

00:03:38.410 --> 00:03:40.620
the question is why would we need to
protect the artificial intelligence with

00:03:40.620 --> 00:03:40.630
protect the artificial intelligence with
 

00:03:40.630 --> 00:03:42.930
protect the artificial intelligence with
rights why is that the best way to

00:03:42.930 --> 00:03:42.940
rights why is that the best way to
 

00:03:42.940 --> 00:03:45.509
rights why is that the best way to
protect it so with humans it's because

00:03:45.509 --> 00:03:45.519
protect it so with humans it's because
 

00:03:45.519 --> 00:03:47.610
protect it so with humans it's because
we're fragile it's because there's only

00:03:47.610 --> 00:03:47.620
we're fragile it's because there's only
 

00:03:47.620 --> 00:03:50.070
we're fragile it's because there's only
one of us and I actually think this is

00:03:50.070 --> 00:03:50.080
one of us and I actually think this is
 

00:03:50.080 --> 00:03:52.830
one of us and I actually think this is
horribly reductionist but I actually

00:03:52.830 --> 00:03:52.840
horribly reductionist but I actually
 

00:03:52.840 --> 00:03:54.509
horribly reductionist but I actually
think it's just the best way that we

00:03:54.509 --> 00:03:54.519
think it's just the best way that we
 

00:03:54.519 --> 00:03:56.789
think it's just the best way that we
found to be able to cooperate it's sort

00:03:56.789 --> 00:03:56.799
found to be able to cooperate it's sort
 

00:03:56.799 --> 00:03:58.229
found to be able to cooperate it's sort
of an acknowledgment of the fact that

00:03:58.229 --> 00:03:58.239
of an acknowledgment of the fact that
 

00:03:58.239 --> 00:04:00.120
of an acknowledgment of the fact that
we're all basically the same thing the

00:04:00.120 --> 00:04:00.130
we're all basically the same thing the
 

00:04:00.130 --> 00:04:01.830
we're all basically the same thing the
same stuff and we had to come up with

00:04:01.830 --> 00:04:01.840
same stuff and we had to come up with
 

00:04:01.840 --> 00:04:04.199
same stuff and we had to come up with
some kind of the technical term again is

00:04:04.199 --> 00:04:04.209
some kind of the technical term again is
 

00:04:04.209 --> 00:04:06.420
some kind of the technical term again is
equilibrium we had to come up with some

00:04:06.420 --> 00:04:06.430
equilibrium we had to come up with some
 

00:04:06.430 --> 00:04:08.789
equilibrium we had to come up with some
way to share the planet and we haven't

00:04:08.789 --> 00:04:08.799
way to share the planet and we haven't
 

00:04:08.799 --> 00:04:10.650
way to share the planet and we haven't
managed to do it completely fairly like

00:04:10.650 --> 00:04:10.660
managed to do it completely fairly like
 

00:04:10.660 --> 00:04:12.150
managed to do it completely fairly like
everybody gets the same amount of space

00:04:12.150 --> 00:04:12.160
everybody gets the same amount of space
 

00:04:12.160 --> 00:04:14.550
everybody gets the same amount of space
but actually we all want to be

00:04:14.550 --> 00:04:14.560
but actually we all want to be
 

00:04:14.560 --> 00:04:17.069
but actually we all want to be
recognized for our achievements so even

00:04:17.069 --> 00:04:17.079
recognized for our achievements so even
 

00:04:17.079 --> 00:04:19.140
recognized for our achievements so even
completely fair isn't completely fair if

00:04:19.140 --> 00:04:19.150
completely fair isn't completely fair if
 

00:04:19.150 --> 00:04:22.620
completely fair isn't completely fair if
that makes sense so and I don't mean to

00:04:22.620 --> 00:04:22.630
that makes sense so and I don't mean to
 

00:04:22.630 --> 00:04:24.839
that makes sense so and I don't mean to
be facetious there it really is true

00:04:24.839 --> 00:04:24.849
be facetious there it really is true
 

00:04:24.849 --> 00:04:28.110
be facetious there it really is true
that that you can't make all the things

00:04:28.110 --> 00:04:28.120
that that you can't make all the things
 

00:04:28.120 --> 00:04:29.429
that that you can't make all the things
you would like out of fairness

00:04:29.429 --> 00:04:29.439
you would like out of fairness
 

00:04:29.439 --> 00:04:32.969
you would like out of fairness
be true at once right that that's just

00:04:32.969 --> 00:04:32.979
be true at once right that that's just
 

00:04:32.979 --> 00:04:35.159
be true at once right that that's just
it's a fact about the world it's a fact

00:04:35.159 --> 00:04:35.169
it's a fact about the world it's a fact
 

00:04:35.169 --> 00:04:37.459
it's a fact about the world it's a fact
about the way we define fairness so

00:04:37.459 --> 00:04:37.469
about the way we define fairness so
 

00:04:37.469 --> 00:04:40.529
about the way we define fairness so
given how hard it is to be fair why

00:04:40.529 --> 00:04:40.539
given how hard it is to be fair why
 

00:04:40.539 --> 00:04:43.709
given how hard it is to be fair why
should we build AI that needs us

00:04:43.709 --> 00:04:43.719
should we build AI that needs us
 

00:04:43.719 --> 00:04:46.859
should we build AI that needs us
to be fair to it so what I'm trying to

00:04:46.859 --> 00:04:46.869
to be fair to it so what I'm trying to
 

00:04:46.869 --> 00:04:48.659
to be fair to it so what I'm trying to
do is just make the problem simpler and

00:04:48.659 --> 00:04:48.669
do is just make the problem simpler and
 

00:04:48.669 --> 00:04:52.079
do is just make the problem simpler and
focus us on the thing that we can't help

00:04:52.079 --> 00:04:52.089
focus us on the thing that we can't help
 

00:04:52.089 --> 00:04:54.209
focus us on the thing that we can't help
which is the human condition and I'm

00:04:54.209 --> 00:04:54.219
which is the human condition and I'm
 

00:04:54.219 --> 00:04:59.040
which is the human condition and I'm
recommending that if you if you if you

00:04:59.040 --> 00:04:59.050
recommending that if you if you if you
 

00:04:59.050 --> 00:05:01.109
recommending that if you if you if you
specify something if you say okay this

00:05:01.109 --> 00:05:01.119
specify something if you say okay this
 

00:05:01.119 --> 00:05:05.189
specify something if you say okay this
is when you really need rights in this

00:05:05.189 --> 00:05:05.199
is when you really need rights in this
 

00:05:05.199 --> 00:05:07.589
is when you really need rights in this
context okay once we establish that

00:05:07.589 --> 00:05:07.599
context okay once we establish that
 

00:05:07.599 --> 00:05:11.339
context okay once we establish that
don't build that okay yeah a lot of

00:05:11.339 --> 00:05:11.349
don't build that okay yeah a lot of
 

00:05:11.349 --> 00:05:13.259
don't build that okay yeah a lot of
people that this rubs them the wrong way

00:05:13.259 --> 00:05:13.269
people that this rubs them the wrong way
 

00:05:13.269 --> 00:05:15.299
people that this rubs them the wrong way
like it's because they fought you know

00:05:15.299 --> 00:05:15.309
like it's because they fought you know
 

00:05:15.309 --> 00:05:17.549
like it's because they fought you know
Blade Runner or or AI the movie or

00:05:17.549 --> 00:05:17.559
Blade Runner or or AI the movie or
 

00:05:17.559 --> 00:05:20.189
Blade Runner or or AI the movie or
something like this in a lot of these

00:05:20.189 --> 00:05:20.199
something like this in a lot of these
 

00:05:20.199 --> 00:05:22.379
something like this in a lot of these
movies we're not really talking about AI

00:05:22.379 --> 00:05:22.389
movies we're not really talking about AI
 

00:05:22.389 --> 00:05:23.879
movies we're not really talking about AI
we're not talking about something

00:05:23.879 --> 00:05:23.889
we're not talking about something
 

00:05:23.889 --> 00:05:27.059
we're not talking about something
designed from the ground up right we're

00:05:27.059 --> 00:05:27.069
designed from the ground up right we're
 

00:05:27.069 --> 00:05:29.209
designed from the ground up right we're
talking basically about clones and

00:05:29.209 --> 00:05:29.219
talking basically about clones and
 

00:05:29.219 --> 00:05:31.529
talking basically about clones and
clones they're a different situation if

00:05:31.529 --> 00:05:31.539
clones they're a different situation if
 

00:05:31.539 --> 00:05:34.139
clones they're a different situation if
you have something that's exactly like a

00:05:34.139 --> 00:05:34.149
you have something that's exactly like a
 

00:05:34.149 --> 00:05:36.809
you have something that's exactly like a
person however it was made then okay

00:05:36.809 --> 00:05:36.819
person however it was made then okay
 

00:05:36.819 --> 00:05:38.790
person however it was made then okay
then it's exactly like a person it needs

00:05:38.790 --> 00:05:38.800
then it's exactly like a person it needs
 

00:05:38.800 --> 00:05:40.949
then it's exactly like a person it needs
that kind of protection but even

00:05:40.949 --> 00:05:40.959
that kind of protection but even
 

00:05:40.959 --> 00:05:43.079
that kind of protection but even
biological clones even if you just want

00:05:43.079 --> 00:05:43.089
biological clones even if you just want
 

00:05:43.089 --> 00:05:45.359
biological clones even if you just want
to clone yourself at least in the

00:05:45.359 --> 00:05:45.369
to clone yourself at least in the
 

00:05:45.369 --> 00:05:46.619
to clone yourself at least in the
European Union that's illegal

00:05:46.619 --> 00:05:46.629
European Union that's illegal
 

00:05:46.629 --> 00:05:48.749
European Union that's illegal
right I I'm not sure about in America I

00:05:48.749 --> 00:05:48.759
right I I'm not sure about in America I
 

00:05:48.759 --> 00:05:51.629
right I I'm not sure about in America I
think it's illegal in America too but

00:05:51.629 --> 00:05:51.639
think it's illegal in America too but
 

00:05:51.639 --> 00:05:53.699
think it's illegal in America too but
people think it's unethical to create

00:05:53.699 --> 00:05:53.709
people think it's unethical to create
 

00:05:53.709 --> 00:05:56.399
people think it's unethical to create
human clones partly because they don't

00:05:56.399 --> 00:05:56.409
human clones partly because they don't
 

00:05:56.409 --> 00:05:58.919
human clones partly because they don't
want to burden someone with a knowledge

00:05:58.919 --> 00:05:58.929
want to burden someone with a knowledge
 

00:05:58.929 --> 00:06:00.540
want to burden someone with a knowledge
that they're supposed to be someone else

00:06:00.540 --> 00:06:00.550
that they're supposed to be someone else
 

00:06:00.550 --> 00:06:02.669
that they're supposed to be someone else
right that there was some other person

00:06:02.669 --> 00:06:02.679
right that there was some other person
 

00:06:02.679 --> 00:06:05.059
right that there was some other person
that chose them to be that person I

00:06:05.059 --> 00:06:05.069
that chose them to be that person I
 

00:06:05.069 --> 00:06:07.169
that chose them to be that person I
don't know if we'll be able to stick to

00:06:07.169 --> 00:06:07.179
don't know if we'll be able to stick to
 

00:06:07.179 --> 00:06:09.359
don't know if we'll be able to stick to
that but I would say that the that AI

00:06:09.359 --> 00:06:09.369
that but I would say that the that AI
 

00:06:09.369 --> 00:06:11.339
that but I would say that the that AI
clones fall into the same category if

00:06:11.339 --> 00:06:11.349
clones fall into the same category if
 

00:06:11.349 --> 00:06:12.659
clones fall into the same category if
you were really going to make something

00:06:12.659 --> 00:06:12.669
you were really going to make something
 

00:06:12.669 --> 00:06:14.850
you were really going to make something
and then say hey congratulations you're

00:06:14.850 --> 00:06:14.860
and then say hey congratulations you're
 

00:06:14.860 --> 00:06:16.439
and then say hey congratulations you're
me and you have to do what I say you

00:06:16.439 --> 00:06:16.449
me and you have to do what I say you
 

00:06:16.449 --> 00:06:18.089
me and you have to do what I say you
know I wouldn't want it myself to tell

00:06:18.089 --> 00:06:18.099
know I wouldn't want it myself to tell
 

00:06:18.099 --> 00:06:20.549
know I wouldn't want it myself to tell
me that what to do if that makes sense

00:06:20.549 --> 00:06:20.559
me that what to do if that makes sense
 

00:06:20.559 --> 00:06:22.409
me that what to do if that makes sense
up there were two of me right I think

00:06:22.409 --> 00:06:22.419
up there were two of me right I think
 

00:06:22.419 --> 00:06:23.969
up there were two of me right I think
we'd like to be able to both be equals

00:06:23.969 --> 00:06:23.979
we'd like to be able to both be equals
 

00:06:23.979 --> 00:06:26.369
we'd like to be able to both be equals
if they're you know and and so you don't

00:06:26.369 --> 00:06:26.379
if they're you know and and so you don't
 

00:06:26.379 --> 00:06:28.619
if they're you know and and so you don't
want to have an artifact is something

00:06:28.619 --> 00:06:28.629
want to have an artifact is something
 

00:06:28.629 --> 00:06:30.299
want to have an artifact is something
deliberately built in that you're going

00:06:30.299 --> 00:06:30.309
deliberately built in that you're going
 

00:06:30.309 --> 00:06:32.969
deliberately built in that you're going
to own if you have something that's sort

00:06:32.969 --> 00:06:32.979
to own if you have something that's sort
 

00:06:32.979 --> 00:06:36.029
to own if you have something that's sort
of a humanoid servant that you own then

00:06:36.029 --> 00:06:36.039
of a humanoid servant that you own then
 

00:06:36.039 --> 00:06:39.480
of a humanoid servant that you own then
the word for that is slave and so that I

00:06:39.480 --> 00:06:39.490
the word for that is slave and so that I
 

00:06:39.490 --> 00:06:41.819
the word for that is slave and so that I
was trying to establish that look we are

00:06:41.819 --> 00:06:41.829
was trying to establish that look we are
 

00:06:41.829 --> 00:06:43.499
was trying to establish that look we are
going to own anything we've

00:06:43.499 --> 00:06:43.509
going to own anything we've
 

00:06:43.509 --> 00:06:45.689
going to own anything we've
and so therefore it would be run to make

00:06:45.689 --> 00:06:45.699
and so therefore it would be run to make
 

00:06:45.699 --> 00:06:47.010
and so therefore it would be run to make
it a person because we've already

00:06:47.010 --> 00:06:47.020
it a person because we've already
 

00:06:47.020 --> 00:06:48.930
it a person because we've already
established that slavery of people is

00:06:48.930 --> 00:06:48.940
established that slavery of people is
 

00:06:48.940 --> 00:06:51.779
established that slavery of people is
wrong and bad and illegal right and so

00:06:51.779 --> 00:06:51.789
wrong and bad and illegal right and so
 

00:06:51.789 --> 00:06:53.219
wrong and bad and illegal right and so
it never occurred to me that people

00:06:53.219 --> 00:06:53.229
it never occurred to me that people
 

00:06:53.229 --> 00:06:55.140
it never occurred to me that people
would take that to mean that other

00:06:55.140 --> 00:06:55.150
would take that to mean that other
 

00:06:55.150 --> 00:06:56.640
would take that to mean that other
all--that's will be people that we just

00:06:56.640 --> 00:06:56.650
all--that's will be people that we just
 

00:06:56.650 --> 00:06:58.650
all--that's will be people that we just
treat really badly it's like no that's

00:06:58.650 --> 00:06:58.660
treat really badly it's like no that's
 

00:06:58.660 --> 00:07:01.170
treat really badly it's like no that's
exactly the opposite I already mentioned

00:07:01.170 --> 00:07:01.180
exactly the opposite I already mentioned
 

00:07:01.180 --> 00:07:03.029
exactly the opposite I already mentioned
that if somebody did manage to clone

00:07:03.029 --> 00:07:03.039
that if somebody did manage to clone
 

00:07:03.039 --> 00:07:04.589
that if somebody did manage to clone
people somehow which I don't believe

00:07:04.589 --> 00:07:04.599
people somehow which I don't believe
 

00:07:04.599 --> 00:07:06.089
people somehow which I don't believe
this is ever going to work but people do

00:07:06.089 --> 00:07:06.099
this is ever going to work but people do
 

00:07:06.099 --> 00:07:07.350
this is ever going to work but people do
talk about it they caught and they

00:07:07.350 --> 00:07:07.360
talk about it they caught and they
 

00:07:07.360 --> 00:07:08.969
talk about it they caught and they
people spend tens of millions of dollars

00:07:08.969 --> 00:07:08.979
people spend tens of millions of dollars
 

00:07:08.979 --> 00:07:13.860
people spend tens of millions of dollars
on it whole brain uploading so I don't

00:07:13.860 --> 00:07:13.870
on it whole brain uploading so I don't
 

00:07:13.870 --> 00:07:15.300
on it whole brain uploading so I don't
believe it's possible I don't think it's

00:07:15.300 --> 00:07:15.310
believe it's possible I don't think it's
 

00:07:15.310 --> 00:07:18.900
believe it's possible I don't think it's
actually computationally tractable but

00:07:18.900 --> 00:07:18.910
actually computationally tractable but
 

00:07:18.910 --> 00:07:21.870
actually computationally tractable but
but if it were to happen then yeah I

00:07:21.870 --> 00:07:21.880
but if it were to happen then yeah I
 

00:07:21.880 --> 00:07:23.430
but if it were to happen then yeah I
would be there saying yes this is a

00:07:23.430 --> 00:07:23.440
would be there saying yes this is a
 

00:07:23.440 --> 00:07:26.310
would be there saying yes this is a
person right but how can we stop that

00:07:26.310 --> 00:07:26.320
person right but how can we stop that
 

00:07:26.320 --> 00:07:28.080
person right but how can we stop that
the same way we stopped human cloning

00:07:28.080 --> 00:07:28.090
the same way we stopped human cloning
 

00:07:28.090 --> 00:07:30.060
the same way we stopped human cloning
which is just to say don't do that and

00:07:30.060 --> 00:07:30.070
which is just to say don't do that and
 

00:07:30.070 --> 00:07:33.240
which is just to say don't do that and
in particular with AI my point is it

00:07:33.240 --> 00:07:33.250
in particular with AI my point is it
 

00:07:33.250 --> 00:07:35.490
in particular with AI my point is it
shouldn't be a commercial product so if

00:07:35.490 --> 00:07:35.500
shouldn't be a commercial product so if
 

00:07:35.500 --> 00:07:38.219
shouldn't be a commercial product so if
somebody does this in their basement or

00:07:38.219 --> 00:07:38.229
somebody does this in their basement or
 

00:07:38.229 --> 00:07:39.390
somebody does this in their basement or
something well then we have a few

00:07:39.390 --> 00:07:39.400
something well then we have a few
 

00:07:39.400 --> 00:07:41.490
something well then we have a few
exceptions but it's I'm much more

00:07:41.490 --> 00:07:41.500
exceptions but it's I'm much more
 

00:07:41.500 --> 00:07:43.620
exceptions but it's I'm much more
concerned about people mass producing

00:07:43.620 --> 00:07:43.630
concerned about people mass producing
 

00:07:43.630 --> 00:07:45.850
concerned about people mass producing
such things

00:07:45.850 --> 00:07:45.860
such things
 

00:07:45.860 --> 00:07:49.110
such things
[Music]

