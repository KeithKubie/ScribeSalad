WEBVTT
Kind: captions
Language: en

00:00:06.950 --> 00:00:08.750
- What I would like
to talk about today

00:00:08.750 --> 00:00:11.850
is about my research, which
is not so diverse in the end.

00:00:11.850 --> 00:00:13.250
It's all about computing.

00:00:13.250 --> 00:00:15.410
It's just that computing
has applications

00:00:15.410 --> 00:00:17.860
in many different fields.

00:00:17.860 --> 00:00:20.840
And I would like to discuss
three elements that you

00:00:20.840 --> 00:00:22.800
will see repeatedly today.

00:00:22.800 --> 00:00:24.680
One is about laws.

00:00:24.680 --> 00:00:27.970
Not necessarily the law of
the land, but physical laws.

00:00:27.970 --> 00:00:30.140
It's going to have
to do with data,

00:00:30.140 --> 00:00:33.320
and there's going
to be about humans.

00:00:33.320 --> 00:00:36.110
The dots that you
see here is what

00:00:36.110 --> 00:00:38.690
we have been doing over
the centuries in science,

00:00:38.690 --> 00:00:42.470
connecting our driving physical
laws by human intuition,

00:00:42.470 --> 00:00:45.290
by observation, by
interaction with data.

00:00:45.290 --> 00:00:47.600
And then you would think that
has happened in the last,

00:00:47.600 --> 00:00:51.800
let's say, 60, 70, or
even perhaps 100 years

00:00:51.800 --> 00:00:52.790
these computers.

00:00:52.790 --> 00:00:54.500
And these computers
are generating

00:00:54.500 --> 00:00:57.170
new paths that connect
all of these players,

00:00:57.170 --> 00:01:00.590
and I would like to discuss in
particular these connections

00:01:00.590 --> 00:01:02.810
between physical
laws and computers;

00:01:02.810 --> 00:01:07.130
between daytime computers
and in particular humans

00:01:07.130 --> 00:01:08.660
and computers.

00:01:08.660 --> 00:01:11.480
And I would like to
discuss if there is--

00:01:11.480 --> 00:01:13.790
if computing is or
can be structured

00:01:13.790 --> 00:01:16.470
for the benefit of mankind.

00:01:16.470 --> 00:01:19.040
Now computers and computing.

00:01:19.040 --> 00:01:22.330
You can say that the modern era
starts with people, like John

00:01:22.330 --> 00:01:25.460
[INAUDIBLE] and
Robert Oppenheimer,

00:01:25.460 --> 00:01:27.530
and perhaps with the
Manhattan Project.

00:01:27.530 --> 00:01:30.880
And the Manhattan Project
is infamous for this.

00:01:34.331 --> 00:01:35.317
[VIDEO PLAYBACK]

00:01:35.317 --> 00:01:37.782
[EXPLOSION]

00:01:40.247 --> 00:01:41.726
- There it goes.

00:01:41.726 --> 00:01:45.820
The fourth atomic bomb have
been successfully detonated.

00:01:45.820 --> 00:01:49.510
- So computers, or computing,
can trace its beginning back

00:01:49.510 --> 00:01:50.710
to the Manhattan Project.

00:01:50.710 --> 00:01:53.980
And as you can see, people have
been dealing with computers,

00:01:53.980 --> 00:01:56.640
or they have been concerned
with computers, early on.

00:01:56.640 --> 00:01:57.306
[VIDEO PLAYBACK]

00:01:57.306 --> 00:01:58.050
- Good evening.

00:01:58.050 --> 00:02:00.529
I'm David Wayne, and
as all of you are,

00:02:00.529 --> 00:02:02.320
I'm concerned with the
world in which we're

00:02:02.320 --> 00:02:05.620
going to live tomorrow.

00:02:05.620 --> 00:02:09.770
A world in which a new
machine, the digital computer,

00:02:09.770 --> 00:02:11.320
may be of even
greater importance

00:02:11.320 --> 00:02:13.570
than the atomic bomb.

00:02:13.570 --> 00:02:16.870
- So indeed, computers
have been part of my life.

00:02:16.870 --> 00:02:18.610
I have a longer
relationship with them

00:02:18.610 --> 00:02:23.530
than I have with my wife, for
example, starting back in 1981.

00:02:23.530 --> 00:02:25.900
And you can see that this
picture goes all the way

00:02:25.900 --> 00:02:27.760
to 1997.

00:02:27.760 --> 00:02:30.880
And I stopped in 1997,
because after that I was not

00:02:30.880 --> 00:02:32.170
programming or doing things.

00:02:32.170 --> 00:02:35.440
I became a professor, and
then I had students of mine

00:02:35.440 --> 00:02:38.290
that actually began programming
and doing great things,

00:02:38.290 --> 00:02:40.780
and doing great things
in some of the biggest

00:02:40.780 --> 00:02:43.330
supercomputers of the world.

00:02:43.330 --> 00:02:45.700
What is important
to see over this 36

00:02:45.700 --> 00:02:51.730
years is that, going from 1981
to 2017, the speed of computers

00:02:51.730 --> 00:02:55.180
has increased by a factor
of about 20 million.

00:02:55.180 --> 00:02:58.330
So you can take any technology--
imagine you take a car,

00:02:58.330 --> 00:03:01.270
and a car that runs
with 60 miles an hour

00:03:01.270 --> 00:03:04.170
after in the span
of about 36 years

00:03:04.170 --> 00:03:06.740
is able to run 20 million times.

00:03:06.740 --> 00:03:08.830
So this is a
tremendous technology,

00:03:08.830 --> 00:03:11.110
and I would like to show
you some of the achievements

00:03:11.110 --> 00:03:14.320
that we have been
doing with it today.

00:03:14.320 --> 00:03:16.840
So the people in
general they started

00:03:16.840 --> 00:03:19.540
becoming aware of computers
when computers actually

00:03:19.540 --> 00:03:22.960
started beating people in
what would be one of the signs

00:03:22.960 --> 00:03:25.600
of human intelligence,
and this being chess.

00:03:25.600 --> 00:03:28.450
And then people became very much
aware of the power of computers

00:03:28.450 --> 00:03:31.000
when the Deep Blue
beat Kasparov.

00:03:31.000 --> 00:03:33.580
Or perhaps, very few people
are aware that Deep Blue

00:03:33.580 --> 00:03:36.220
beat Kasparov because of a bug.

00:03:36.220 --> 00:03:38.620
In fact at some
point, what happened

00:03:38.620 --> 00:03:41.530
is that it picked actually
the best move, which

00:03:41.530 --> 00:03:43.720
is a medium term
best move, but then

00:03:43.720 --> 00:03:45.630
because of the bug
and the algorithm,

00:03:45.630 --> 00:03:47.860
it picked this medium term move.

00:03:47.860 --> 00:03:50.800
And it takes another move,
which was actually random.

00:03:50.800 --> 00:03:52.780
And then when Kasparov's
saw that he said,

00:03:52.780 --> 00:03:54.280
that this thing is impossible.

00:03:54.280 --> 00:03:56.740
Only human could be
doing such a thing,

00:03:56.740 --> 00:04:00.310
like sacrificing a short term
advantage for something that

00:04:00.310 --> 00:04:02.920
is happening later.

00:04:02.920 --> 00:04:05.450
Now today, computers
have improved.

00:04:05.450 --> 00:04:08.080
We can beat actually
humans in other things

00:04:08.080 --> 00:04:09.820
that are even more
sophisticated,

00:04:09.820 --> 00:04:12.970
like the computer game
of Go, and more recently,

00:04:12.970 --> 00:04:18.550
a few-- a couple of months ago,
even between humans on poker.

00:04:18.550 --> 00:04:20.459
And it's not that they
are good at games.

00:04:20.459 --> 00:04:23.710
They are also good at replacing
testing for atomic bombs.

00:04:23.710 --> 00:04:26.080
And what we can do
today, we can actually

00:04:26.080 --> 00:04:28.780
do simulations that are
replacing the experiments

00:04:28.780 --> 00:04:31.390
and testing of atomic
bombs, precisely

00:04:31.390 --> 00:04:35.260
because we have developed
such computing capabilities.

00:04:35.260 --> 00:04:37.420
Now another game
changing technology

00:04:37.420 --> 00:04:39.490
that we are facing
today is data.

00:04:39.490 --> 00:04:43.420
So today there is about
five billion devices,

00:04:43.420 --> 00:04:47.660
or about 1 billion people who
have access to these devices.

00:04:47.660 --> 00:04:50.350
So it's important to distinguish
that these devices are

00:04:50.350 --> 00:04:53.770
producing data they're
not necessarily computing,

00:04:53.770 --> 00:04:57.550
but there is nothing that to
escape all these kinds of data

00:04:57.550 --> 00:04:58.770
that are coming together.

00:04:58.770 --> 00:05:02.680
And I would like to argue that
computers, humans, computing,

00:05:02.680 --> 00:05:05.710
and data are converging
today, and it's

00:05:05.710 --> 00:05:09.360
a wonderful opportunity
that is presented to us.

00:05:09.360 --> 00:05:11.880
So a little bit about
what we do with computers,

00:05:11.880 --> 00:05:13.380
or what I call computing.

00:05:13.380 --> 00:05:14.940
So what is computing?

00:05:14.940 --> 00:05:17.210
It's about information
processing,

00:05:17.210 --> 00:05:20.340
and it's about what can be
computed and how to compute it.

00:05:20.340 --> 00:05:22.950
It's not only about
computers, but it's also

00:05:22.950 --> 00:05:25.920
about posing the right
question about creating

00:05:25.920 --> 00:05:28.920
mathematical models,
about making algorithms,

00:05:28.920 --> 00:05:32.520
creating software, being
aware of a particular computer

00:05:32.520 --> 00:05:37.080
architecture, performing a
simulation, analyzing the data,

00:05:37.080 --> 00:05:40.350
and eventually trying
to reach a decision.

00:05:40.350 --> 00:05:42.450
And in the end, of course,
you never stop there,

00:05:42.450 --> 00:05:45.840
but you keep looping and looping
and looping until you go back,

00:05:45.840 --> 00:05:47.130
and you change your question.

00:05:47.130 --> 00:05:50.590
And you try to get
better a decision.

00:05:50.590 --> 00:05:54.880
To give you an idea, let me give
you an example of from ecology.

00:05:54.880 --> 00:05:58.030
So this is foxes and
rabbits, and foxes

00:05:58.030 --> 00:06:00.220
are chasing of course rabbits.

00:06:00.220 --> 00:06:01.957
And there are some
bizarre biology

00:06:01.957 --> 00:06:03.790
that I'm going to be
telling you about, just

00:06:03.790 --> 00:06:05.224
to make the thing simpler.

00:06:05.224 --> 00:06:06.390
We're going to have rabbits.

00:06:06.390 --> 00:06:08.830
They're going to be eating
grass, and immediately giving

00:06:08.830 --> 00:06:09.430
birth.

00:06:09.430 --> 00:06:12.727
And they're going to be dying
when they are eaten by foxes.

00:06:12.727 --> 00:06:14.560
We're going to have
foxes that eat raw meat,

00:06:14.560 --> 00:06:16.330
and they give
birth, but they also

00:06:16.330 --> 00:06:18.940
die, perhaps out of old age.

00:06:18.940 --> 00:06:20.620
And I will introduce grass.

00:06:20.620 --> 00:06:22.200
Grass grows by rain.

00:06:22.200 --> 00:06:27.040
It dies by rabbits, and it can
also die because of pollution.

00:06:27.040 --> 00:06:29.170
So this is something
that maybe someone

00:06:29.170 --> 00:06:30.490
is interested to understand.

00:06:30.490 --> 00:06:33.320
What happens when you don't have
just there a Fox and a rabbit,

00:06:33.320 --> 00:06:35.260
but when you have many of them.

00:06:35.260 --> 00:06:37.600
So you write down an
equation, and you write down

00:06:37.600 --> 00:06:40.540
an equation that tells you
how the population of rabbits

00:06:40.540 --> 00:06:41.890
is changing with time.

00:06:41.890 --> 00:06:44.560
This is this dr dt.

00:06:44.560 --> 00:06:46.750
And then it tells you
how the number of foxes

00:06:46.750 --> 00:06:48.429
is changing with time.

00:06:48.429 --> 00:06:50.470
And then you write an
equation that tells you how

00:06:50.470 --> 00:06:53.320
grass is changing with time.

00:06:53.320 --> 00:06:54.070
Now this is great.

00:06:54.070 --> 00:06:55.111
What do you do with that?

00:06:55.111 --> 00:06:56.360
Well, you take the equations.

00:06:56.360 --> 00:06:59.860
You do numerical algorithms,
and you create software.

00:06:59.860 --> 00:07:03.760
And today we are blessed to have
amazing capabilities of just

00:07:03.760 --> 00:07:09.070
writing one line that is able to
integrate all these equations,

00:07:09.070 --> 00:07:12.330
without even needing to develop
numerical algorithms, studies

00:07:12.330 --> 00:07:14.600
stability, etc.

00:07:14.600 --> 00:07:17.770
And then after you do that,
then you perform a simulation.

00:07:17.770 --> 00:07:20.080
So here's a parameter that
I want you to pay attention.

00:07:20.080 --> 00:07:23.110
This is a parameter
that says that if grass

00:07:23.110 --> 00:07:26.410
is dying due to pollution,
it depends on the parameter

00:07:26.410 --> 00:07:27.130
epsilon.

00:07:27.130 --> 00:07:30.040
So if we set this
parameter epsilon to zero,

00:07:30.040 --> 00:07:32.920
it means that the grass is not
dying because of pollution.

00:07:32.920 --> 00:07:36.950
So we fix some other parameters
for rabbits and foxes.

00:07:36.950 --> 00:07:38.890
And this thing is
performing, and you

00:07:38.890 --> 00:07:41.230
see how the numbers
are changing over time.

00:07:41.230 --> 00:07:44.920
You see this predator
prey architecture.

00:07:44.920 --> 00:07:46.690
Now if you change
it, and you say,

00:07:46.690 --> 00:07:48.280
well, let's have
some of the grass

00:07:48.280 --> 00:07:51.940
die because of pollution, then
the dynamics are changing.

00:07:51.940 --> 00:07:53.770
And you see that
indeed in the beginning

00:07:53.770 --> 00:07:55.750
you have that
rabbits are growing,

00:07:55.750 --> 00:07:58.420
and then the foxes are chasing
them and they're growing.

00:07:58.420 --> 00:08:02.290
But then there's less rabbits,
and then there is less foxes.

00:08:02.290 --> 00:08:06.160
But it's interesting to observe,
that as the grass eventually

00:08:06.160 --> 00:08:08.310
is going to be
starting to die, you're

00:08:08.310 --> 00:08:13.600
going to see that there is less
and less foxes, first of all.

00:08:13.600 --> 00:08:17.530
And then less and less rabbits
that will be happening.

00:08:17.530 --> 00:08:21.700
So this is some of the things
that we do in computing.

00:08:21.700 --> 00:08:24.400
Of course today, we don't do
it only for three differential

00:08:24.400 --> 00:08:27.010
equations, but we can
do it for trillions

00:08:27.010 --> 00:08:28.920
of differential equations,
which I will also

00:08:28.920 --> 00:08:30.620
show you in a second.

00:08:30.620 --> 00:08:31.820
So why do we compute?

00:08:31.820 --> 00:08:33.730
What does it give us?

00:08:33.730 --> 00:08:37.419
Well, it can complement
theory in experiments.

00:08:37.419 --> 00:08:40.179
And there's a lot of things that
we can do with theory that we

00:08:40.179 --> 00:08:43.330
cannot do with computing, and
there's a lot of things that we

00:08:43.330 --> 00:08:45.790
can do with experiments that
we cannot do with theory

00:08:45.790 --> 00:08:47.080
or computing.

00:08:47.080 --> 00:08:50.860
But I think the three together
is a very potent combination.

00:08:50.860 --> 00:08:52.570
We can test hypotheses.

00:08:52.570 --> 00:08:55.440
There is a lot of activity
happening today about geo

00:08:55.440 --> 00:08:58.300
engineering, and there is
a lot of crazy things being

00:08:58.300 --> 00:09:01.910
proposed about how we can
interact with the environment.

00:09:01.910 --> 00:09:06.110
Perhaps we can test such
things in the computer first.

00:09:06.110 --> 00:09:07.090
We also have data.

00:09:07.090 --> 00:09:10.120
We can process and
we can analyze data.

00:09:10.120 --> 00:09:14.950
We can optimize and design, and
we can also, as I said earlier,

00:09:14.950 --> 00:09:15.580
decide.

00:09:15.580 --> 00:09:17.890
So it's omnipresent,
and it's omnipresent

00:09:17.890 --> 00:09:20.540
in every field of science.

00:09:20.540 --> 00:09:24.230
So in the end, in my opinion,
what do we do with computing

00:09:24.230 --> 00:09:27.110
it's about acquiring
and creating knowledge,

00:09:27.110 --> 00:09:29.380
and it's about
trying to predict.

00:09:29.380 --> 00:09:33.420
And I would like to elaborate a
little bit more on this topic.

00:09:33.420 --> 00:09:34.460
So what is knowledge?

00:09:34.460 --> 00:09:37.730
Knowledge, perhaps you
can start to classify it

00:09:37.730 --> 00:09:39.330
in different ways.

00:09:39.330 --> 00:09:43.080
One of the segments of knowledge
is how do you do something,

00:09:43.080 --> 00:09:46.350
and what do you know
about something.

00:09:46.350 --> 00:09:48.500
And you can say
that this how can

00:09:48.500 --> 00:09:50.760
be classified as classical
knowledge, and the

00:09:50.760 --> 00:09:53.750
what can be classified
as empirical knowledge.

00:09:53.750 --> 00:09:56.180
And if we go back
to the Greeks, we

00:09:56.180 --> 00:09:59.060
can call that the
episteme, and the techne.

00:09:59.060 --> 00:10:04.100
And the techne is what became
later artificiale became art.

00:10:04.100 --> 00:10:07.940
And then our episteme usually
leads to principles and laws,

00:10:07.940 --> 00:10:12.020
where techne usually is involved
with heuristics and structures.

00:10:12.020 --> 00:10:15.470
And in the end heuristics and
development or structures,

00:10:15.470 --> 00:10:17.870
this is the job of engineers.

00:10:17.870 --> 00:10:20.000
And the development
of principles and laws

00:10:20.000 --> 00:10:23.534
have been traditionally
the job of scientists.

00:10:23.534 --> 00:10:25.700
What has been happening,
in my opinion, in knowledge

00:10:25.700 --> 00:10:29.240
is that they have been creating
silos that have been created,

00:10:29.240 --> 00:10:30.920
and often the two
things they will not

00:10:30.920 --> 00:10:32.630
be talking to each other.

00:10:32.630 --> 00:10:35.270
And where I compute there,
consider that computing

00:10:35.270 --> 00:10:38.800
is enabling is that give
us a common language,

00:10:38.800 --> 00:10:41.510
and give us a fantastic
bridge to go between these two

00:10:41.510 --> 00:10:43.310
different types of knowledge.

00:10:43.310 --> 00:10:46.100
And I would like to
demonstrate that.

00:10:46.100 --> 00:10:48.120
So let's look at
classical knowledge.

00:10:48.120 --> 00:10:51.190
Here is Leonardo da Vinci
"Old "Man and Vortices".

00:10:51.190 --> 00:10:52.930
You're looking at
the flow; you are

00:10:52.930 --> 00:10:55.000
looking at the flow
around the plate here.

00:10:55.000 --> 00:10:56.880
And you can think about that.

00:10:56.880 --> 00:11:01.220
But then there came Newton,
and he put down these equations

00:11:01.220 --> 00:11:03.370
of how the flow is happening.

00:11:03.370 --> 00:11:05.560
These are the famous
Navier-Stokes equations,

00:11:05.560 --> 00:11:07.870
I'll be showing you
again and again.

00:11:07.870 --> 00:11:09.460
And what is the classical thing?

00:11:09.460 --> 00:11:11.950
The classical thing with
equations and principles

00:11:11.950 --> 00:11:14.110
is that you can make
precise predictions,

00:11:14.110 --> 00:11:16.540
and you can provide
explanations.

00:11:16.540 --> 00:11:20.740
At the same time, you can do
that by a few rather expensive,

00:11:20.740 --> 00:11:23.670
in terms of menu terms
data and observations.

00:11:23.670 --> 00:11:25.780
And at the same time
what you have developed

00:11:25.780 --> 00:11:28.960
may not be useful
for applications.

00:11:28.960 --> 00:11:32.590
And what is happening today
is that these capabilities are

00:11:32.590 --> 00:11:35.680
greatly enhanced by computing.

00:11:35.680 --> 00:11:38.980
An example, very often
maybe you look up in the sky

00:11:38.980 --> 00:11:40.480
and you see this contrail.

00:11:40.480 --> 00:11:43.450
This is the condensation
of air that gives you

00:11:43.450 --> 00:11:45.850
actually markers of vorticity.

00:11:45.850 --> 00:11:49.380
Vorticity is what
makes airplanes fly.

00:11:49.380 --> 00:11:51.970
And this is experiments
that can be done,

00:11:51.970 --> 00:11:55.960
and people are looking at how
these vortices behind aircraft

00:11:55.960 --> 00:11:58.130
are being destroyed.

00:11:58.130 --> 00:12:00.580
So you can do experiments,
and this is more or less

00:12:00.580 --> 00:12:02.830
the knowledge that he
acquired from experiments.

00:12:02.830 --> 00:12:05.710
But if you perform
a simulation then

00:12:05.710 --> 00:12:09.610
it is possible to get
inside these contrails,

00:12:09.610 --> 00:12:11.440
and look at the
muscles of the flow,

00:12:11.440 --> 00:12:13.390
look at what creates
the vorticity,

00:12:13.390 --> 00:12:16.180
looks at what creates
all these instabilities.

00:12:16.180 --> 00:12:18.370
And how very precise
and very detailed

00:12:18.370 --> 00:12:22.240
information about instabilities,
and about how you can interfere

00:12:22.240 --> 00:12:25.750
with the flow in order to
be able to learn about it

00:12:25.750 --> 00:12:30.820
and eventually to control
and to manipulate it.

00:12:30.820 --> 00:12:33.340
So yes, we can do
all these things,

00:12:33.340 --> 00:12:36.250
but there is a lot of things
that we are challenged with.

00:12:36.250 --> 00:12:38.230
And one of the
challenges that we have--

00:12:38.230 --> 00:12:41.710
I told you that computers
are 20 million faster.

00:12:41.710 --> 00:12:45.430
This does not mean that the
way we compute is 20 million

00:12:45.430 --> 00:12:46.450
faster.

00:12:46.450 --> 00:12:49.510
On the contrary, there is a
big challenge in computing,

00:12:49.510 --> 00:12:51.730
and the people who are
dealing with computing,

00:12:51.730 --> 00:12:55.330
that this software is not
catching up with hardware.

00:12:55.330 --> 00:12:57.670
In fact, one can
say that this is

00:12:57.670 --> 00:12:59.740
one of the biggest
gaps of computing,

00:12:59.740 --> 00:13:02.680
and we are failing
Moore's law in practice.

00:13:02.680 --> 00:13:06.700
And about 90% of the software
is using less than 10%

00:13:06.700 --> 00:13:09.700
of the hardware, and this
is an optimistic view.

00:13:09.700 --> 00:13:11.180
Now what does this mean?

00:13:11.180 --> 00:13:13.900
This means that this is an
inherent problem that you have

00:13:13.900 --> 00:13:17.140
in energy, given how
many computers you have,

00:13:17.140 --> 00:13:19.840
and how much does it cost
to create the computers.

00:13:19.840 --> 00:13:22.060
So we make these
expensive machines,

00:13:22.060 --> 00:13:23.800
but then we are
under using them.

00:13:23.800 --> 00:13:27.160
And another thing, that
is actually data tell us,

00:13:27.160 --> 00:13:30.630
is that, for example, CO2
emissions from Germany

00:13:30.630 --> 00:13:33.940
are higher because of
information and communication

00:13:33.940 --> 00:13:37.750
technologies, cooling of
supercomputing centers,

00:13:37.750 --> 00:13:41.620
than the pollution that is
generated by air traffic.

00:13:41.620 --> 00:13:43.900
So one of the
challenges of computing

00:13:43.900 --> 00:13:48.100
is how to actually create
mathematics and software that

00:13:48.100 --> 00:13:52.600
can actually use the computers
in the most effective way.

00:13:52.600 --> 00:13:54.540
So we try to do that.

00:13:54.540 --> 00:13:56.620
And the way we did
that is by trying

00:13:56.620 --> 00:13:58.690
to solve an actual problem.

00:13:58.690 --> 00:14:03.550
We decided to write, perhaps,
the fastest or the best code

00:14:03.550 --> 00:14:06.190
that ever was, dying
computational fluid dynamics,

00:14:06.190 --> 00:14:08.920
and to try instead
of using 10% to see

00:14:08.920 --> 00:14:11.020
how high we can get on that.

00:14:11.020 --> 00:14:13.150
The problem we
decided to study is

00:14:13.150 --> 00:14:16.120
something that is called
cloud cavitation collapse.

00:14:16.120 --> 00:14:19.420
The idea is that when
you get to boil water,

00:14:19.420 --> 00:14:24.190
by increasing the temperature
of the water you get bubbles.

00:14:24.190 --> 00:14:25.900
There is one more
way to get bubbles,

00:14:25.900 --> 00:14:28.907
and that is by decreasing
the pressure of the water.

00:14:28.907 --> 00:14:31.240
You decrease the pressure of
the water when the water is

00:14:31.240 --> 00:14:32.900
get going very fast.

00:14:32.900 --> 00:14:36.190
So that's how the bubbles are
generated over the airfoil,

00:14:36.190 --> 00:14:38.110
and when these bubbles
collapsed together

00:14:38.110 --> 00:14:40.570
they generate huge pressures.

00:14:40.570 --> 00:14:43.240
And these huge pressures, they
can actually be little bubbles,

00:14:43.240 --> 00:14:45.010
they can destroy propellers.

00:14:45.010 --> 00:14:47.650
And at the same time,
people are using them

00:14:47.650 --> 00:14:51.160
in order to destroy tissue that
exists between blood vessels

00:14:51.160 --> 00:14:53.500
and tumors, and
actually use them

00:14:53.500 --> 00:14:57.040
in order to destroy this tissue,
so that when drugs are coming

00:14:57.040 --> 00:14:58.960
out of the blood vessels
they can actually

00:14:58.960 --> 00:15:01.780
arrive on to the tumor.

00:15:01.780 --> 00:15:04.010
So they're doing
that by putting--

00:15:04.010 --> 00:15:06.940
here they have injected bubbles
together with the drugs,

00:15:06.940 --> 00:15:11.050
and then by doing ultrasound
they're cavitating--

00:15:11.050 --> 00:15:13.630
the bubbles are
collapsing destroying

00:15:13.630 --> 00:15:17.120
the tissue, the same way that
are destroying propellers.

00:15:17.120 --> 00:15:20.140
Now what people have
done in the past

00:15:20.140 --> 00:15:22.300
is that you understand
that by the destruction

00:15:22.300 --> 00:15:26.950
power of this process it's very
difficult to do experiments.

00:15:26.950 --> 00:15:28.810
And by the complexity
of this process

00:15:28.810 --> 00:15:30.610
it's very difficult
to do theory.

00:15:30.610 --> 00:15:32.860
In fact, the only
theory that exists

00:15:32.860 --> 00:15:35.680
is what happens to one bubble.

00:15:35.680 --> 00:15:41.470
Now what we do is we take the
equations, and I can tell you

00:15:41.470 --> 00:15:42.810
these are continuous equations.

00:15:42.810 --> 00:15:44.470
You have to discretized them.

00:15:44.470 --> 00:15:46.270
You put them into the
computer, and I'll

00:15:46.270 --> 00:15:49.750
tell you in how many points we
discretized them, in a second.

00:15:49.750 --> 00:15:52.330
I want to show you the
complexity of this,

00:15:52.330 --> 00:15:54.700
and this is one of the
largest simulations.

00:15:54.700 --> 00:15:56.830
Actually, is the
largest simulation

00:15:56.830 --> 00:15:59.170
ever made in consideration
of fluid dynamics.

00:15:59.170 --> 00:16:01.930
This is the problem of cloud
gravitational collapse.

00:16:01.930 --> 00:16:03.760
You see a part of this bubbles.

00:16:03.760 --> 00:16:06.940
You see the yellow, which is
the pressure that is happening.

00:16:06.940 --> 00:16:10.030
At the center of the movie that
you see lasts a few seconds.

00:16:10.030 --> 00:16:13.300
In practice, it lasts
less than a microsecond,

00:16:13.300 --> 00:16:14.280
this whole process.

00:16:14.280 --> 00:16:16.180
So that's what computers can do.

00:16:16.180 --> 00:16:18.730
They can go down to
less than a microsecond,

00:16:18.730 --> 00:16:22.330
and less than millimeters,
and be able to give you

00:16:22.330 --> 00:16:23.950
these processes.

00:16:23.950 --> 00:16:25.900
So we do these
simulations, but we do them

00:16:25.900 --> 00:16:27.100
in order to understand.

00:16:27.100 --> 00:16:29.080
And we understand
that nobody in a way

00:16:29.080 --> 00:16:31.930
that nobody ever seen before,
and that, actually, I'm

00:16:31.930 --> 00:16:34.240
happy to show you this
for the first time.

00:16:34.240 --> 00:16:37.260
We actually find that when the
bubbles started collapsing,

00:16:37.260 --> 00:16:39.240
what happens is
that there is fluid

00:16:39.240 --> 00:16:41.010
that is coming
inside the bubbles.

00:16:41.010 --> 00:16:45.150
It is being accelerated by
the stretching of the bubbles,

00:16:45.150 --> 00:16:48.150
and so we know now that
cavitation collapse

00:16:48.150 --> 00:16:52.860
can be derived as
interactions of micro jets.

00:16:52.860 --> 00:16:57.870
So I told you that we set out
to do the fastest code ever,

00:16:57.870 --> 00:17:00.240
and this is the
fastest code ever

00:17:00.240 --> 00:17:02.040
in computational fluid dynamics.

00:17:02.040 --> 00:17:05.890
And it goes to say, about the
international collaboration,

00:17:05.890 --> 00:17:09.690
that, coming from Switzerland,
we were able to get access

00:17:09.690 --> 00:17:11.180
to the Lawrence Livermore--

00:17:11.180 --> 00:17:13.650
Lawrence Berkeley and
Lawrence Livermore,

00:17:13.650 --> 00:17:15.839
in this particular
case, national lab.

00:17:15.839 --> 00:17:18.480
They gave us access
to 1.6 million codes.

00:17:18.480 --> 00:17:21.329
We were able to run
our simulations there,

00:17:21.329 --> 00:17:25.200
and what has been an
amazing achievement for us

00:17:25.200 --> 00:17:27.270
there is something
called the America's Cup.

00:17:27.270 --> 00:17:28.750
As you know, for yacht racing.

00:17:28.750 --> 00:17:30.810
There's the golden
bell award, that

00:17:30.810 --> 00:17:34.080
is also being something
that is done in computers.

00:17:34.080 --> 00:17:37.230
So we were fortunate, again,
thanks to collaboration

00:17:37.230 --> 00:17:40.230
with our colleagues between
Switzerland and the US,

00:17:40.230 --> 00:17:42.960
to be able to demonstrate
of doing simulations

00:17:42.960 --> 00:17:45.810
using trillions of
computational points.

00:17:45.810 --> 00:17:48.300
Today we can reach
100,000 bubbles,

00:17:48.300 --> 00:17:50.850
and we can actually
compress data

00:17:50.850 --> 00:17:55.530
by a factor of 100, which is
also an important achievement.

00:17:55.530 --> 00:17:57.900
Just to give you an idea
of what has happened,

00:17:57.900 --> 00:18:00.270
when we ran our code, we
took our code actually

00:18:00.270 --> 00:18:02.880
and we ran it on the
machines in Germany.

00:18:02.880 --> 00:18:05.400
And then machines in Germany
they will tell us we cannot run

00:18:05.400 --> 00:18:06.030
your code.

00:18:06.030 --> 00:18:09.360
And then we will tell them why
can't you don't run our code,

00:18:09.360 --> 00:18:11.066
and then this is
what they told us.

00:18:11.066 --> 00:18:12.690
You know when you
start to run, instead

00:18:12.690 --> 00:18:17.190
of 10% of 70% of the machine,
the machine started to shake,

00:18:17.190 --> 00:18:20.160
and they had to physically
go and screw down

00:18:20.160 --> 00:18:23.700
the cooling units so that
they could run our code.

00:18:23.700 --> 00:18:27.650
So this is actually counts much
more than the previous numbers

00:18:27.650 --> 00:18:29.730
that you have seen,
but all these things

00:18:29.730 --> 00:18:30.600
have been resolved.

00:18:30.600 --> 00:18:33.210
But this is actually
real engineering

00:18:33.210 --> 00:18:36.120
in order to be
able to run a code.

00:18:36.120 --> 00:18:38.850
I want to show you one more
landmark simulations that

00:18:38.850 --> 00:18:41.520
was done thanks to my students.

00:18:41.520 --> 00:18:44.010
This is another problem, that
I will tell you in a second.

00:18:44.010 --> 00:18:45.740
This is a microfluidics device.

00:18:45.740 --> 00:18:49.140
This is a copy in the computer
of microfluidics device that

00:18:49.140 --> 00:18:54.450
has been designed by
[INAUDIBLE] here at Harvard--

00:18:54.450 --> 00:18:57.270
at Harvard, at the MGH.

00:18:57.270 --> 00:18:59.250
And what is the problem?

00:18:59.250 --> 00:19:02.640
We're looking into
cancer, and 90% of cancer

00:19:02.640 --> 00:19:04.830
is attributed to metastasis.

00:19:04.830 --> 00:19:08.100
When tumors are growing, they
are emitting growth factors.

00:19:08.100 --> 00:19:09.600
These growth
factors are actually

00:19:09.600 --> 00:19:11.910
cheating the blood
vessels to grow,

00:19:11.910 --> 00:19:13.770
and when the blood
vessels are growing,

00:19:13.770 --> 00:19:15.300
they arrive to the tumor.

00:19:15.300 --> 00:19:18.180
And the tumor finds their way
to escape through the blood

00:19:18.180 --> 00:19:19.360
vessels.

00:19:19.360 --> 00:19:23.730
So we want to find out if the
blood is contained in tumors.

00:19:23.730 --> 00:19:25.860
So the processing
that people have to do

00:19:25.860 --> 00:19:29.540
is you have to find one
circulating tumor cell in one

00:19:29.540 --> 00:19:31.660
billion red blood cells.

00:19:31.660 --> 00:19:33.270
So there is an
ingenious device, that

00:19:33.270 --> 00:19:36.240
was developed by the group
of [INAUDIBLE] whereby

00:19:36.240 --> 00:19:38.640
taking advantage of
some fluid dynamics

00:19:38.640 --> 00:19:42.750
processes, they're able through
empirical ways, actually,

00:19:42.750 --> 00:19:46.710
to distinguish cells
by size by taking

00:19:46.710 --> 00:19:51.240
them to go in different
parts of their domain.

00:19:51.240 --> 00:19:53.220
And what we have
achieved, actually,

00:19:53.220 --> 00:19:58.110
is to be able to go down, and to
simulate every red blood cells

00:19:58.110 --> 00:20:01.830
up to 0.2 milliliters of blood.

00:20:01.830 --> 00:20:05.550
In this particular case, you are
visualizing 200,000 red blood

00:20:05.550 --> 00:20:08.070
cells in the same
microfluidics device.

00:20:08.070 --> 00:20:10.920
It's a millimeter long
microfluidics device,

00:20:10.920 --> 00:20:13.390
to appreciate the
size of the domain.

00:20:13.390 --> 00:20:15.240
So we can repeat
the same experiment

00:20:15.240 --> 00:20:18.360
that the group of [INAUDIBLE]
does, and we can actually

00:20:18.360 --> 00:20:21.970
try to do optimization
of that different panels

00:20:21.970 --> 00:20:25.620
of the different geometries
that you see here.

00:20:25.620 --> 00:20:27.247
So we put down the
red blood cells.

00:20:27.247 --> 00:20:28.830
And then, as you
will see in a second,

00:20:28.830 --> 00:20:33.630
we create a model of a
circulating tumor cell.

00:20:33.630 --> 00:20:38.460
And what we do is we take
it and we implanted there,

00:20:38.460 --> 00:20:41.520
and then we try to see if
by continuously flowing

00:20:41.520 --> 00:20:43.680
these things we are able
to separate red blood

00:20:43.680 --> 00:20:47.100
cells from tumor cells.

00:20:47.100 --> 00:20:49.170
This is a homage to
the fantastic voyage,

00:20:49.170 --> 00:20:52.350
for those of you that are old
enough to have seen this movie.

00:20:52.350 --> 00:20:55.590
It's quite a lot of effort
to be able to do that.

00:20:55.590 --> 00:21:00.060
But to cut a long story short,
you start particles there,

00:21:00.060 --> 00:21:03.870
time zero, and indeed,
after about the same time

00:21:03.870 --> 00:21:06.140
that it will take in an
experimental facility,

00:21:06.140 --> 00:21:09.450
of course it takes
much longer to compute.

00:21:09.450 --> 00:21:14.400
We are able to separate tumor
cells from red blood cells.

00:21:14.400 --> 00:21:16.700
So this is the classical
way, I call it,

00:21:16.700 --> 00:21:18.950
of knowledge, where we're
setting up physical laws,

00:21:18.950 --> 00:21:22.640
and we're using the computer
in order to advance it.

00:21:22.640 --> 00:21:26.200
My original training has
been on empirical knowledge.

00:21:26.200 --> 00:21:29.210
It has been about using
dependencies from data,

00:21:29.210 --> 00:21:32.110
or using experience
and [? CID ?] design.

00:21:32.110 --> 00:21:33.800
There has not been
a lot of science

00:21:33.800 --> 00:21:37.100
in designing [? CIDs. ?] There
has not been a lot of science

00:21:37.100 --> 00:21:38.820
in designing the
first airplanes.

00:21:38.820 --> 00:21:42.380
You are imitating what other
shipbuilders have done.

00:21:42.380 --> 00:21:44.720
You're using here rustic
rules left and right,

00:21:44.720 --> 00:21:46.700
but somehow there is a
lot of the things that

00:21:46.700 --> 00:21:49.310
are flying today and
swimming that are

00:21:49.310 --> 00:21:51.440
based on this approach.

00:21:51.440 --> 00:21:55.590
So the empirical way is about
statistical predictions,

00:21:55.590 --> 00:21:56.360
at best.

00:21:56.360 --> 00:21:59.600
It's not about the precision
that physical laws have.

00:21:59.600 --> 00:22:01.970
So it is expensive,
because it requires

00:22:01.970 --> 00:22:05.030
that you have a lot of data
and a lot of observations

00:22:05.030 --> 00:22:06.880
in order to do statistics.

00:22:06.880 --> 00:22:09.460
And it realize that this
data on observations

00:22:09.460 --> 00:22:13.010
have to come in a certain
way in inexpensively.

00:22:13.010 --> 00:22:16.820
And of course this inexpensively
is changing today about

00:22:16.820 --> 00:22:18.230
from computers.

00:22:18.230 --> 00:22:20.690
And the last thing is
that empirical knowledge

00:22:20.690 --> 00:22:24.920
has a practical utility, but has
a practical utility for a given

00:22:24.920 --> 00:22:25.580
application.

00:22:25.580 --> 00:22:27.980
When you do a training
as a naval architect,

00:22:27.980 --> 00:22:30.980
you cannot go and
become a cell biologist.

00:22:30.980 --> 00:22:34.930
You cannot go and even become
in aeronautics engineer.

00:22:34.930 --> 00:22:38.660
And so this empirical
knowledge is very useful,

00:22:38.660 --> 00:22:40.280
but it's very limited.

00:22:40.280 --> 00:22:42.860
At the same time, this
is changing today,

00:22:42.860 --> 00:22:44.180
because of computing.

00:22:44.180 --> 00:22:47.960
And if you decide to focus
on computational aspects

00:22:47.960 --> 00:22:50.750
of empirical knowledge,
you are returning back

00:22:50.750 --> 00:22:52.880
to similar problems
that you encounter

00:22:52.880 --> 00:22:54.380
in classical knowledge.

00:22:54.380 --> 00:22:56.120
And for me, this
has been the pathway

00:22:56.120 --> 00:22:59.150
to go from naval
architecture to cell biology,

00:22:59.150 --> 00:23:02.370
by finding common
computational problems.

00:23:02.370 --> 00:23:03.830
So I would like to show you--

00:23:03.830 --> 00:23:05.600
well, these are
examples, actually,

00:23:05.600 --> 00:23:07.280
of empirical knowledge.

00:23:07.280 --> 00:23:10.370
This is about machine
learning algorithm, which

00:23:10.370 --> 00:23:13.480
I call empirical knowledge,
and I will argue later

00:23:13.480 --> 00:23:16.550
of looking at the images
being better than humans,

00:23:16.550 --> 00:23:20.300
looking at text being
better than lawyers,

00:23:20.300 --> 00:23:23.900
and using the power of computers
in order to derive things.

00:23:23.900 --> 00:23:26.930
Of course, when you have
a code that does not,

00:23:26.930 --> 00:23:31.220
it's not the same code that
does that in terms of machinery,

00:23:31.220 --> 00:23:34.280
but both of them they say are
the aspect of being empirical

00:23:34.280 --> 00:23:36.050
in the way they proceed.

00:23:36.050 --> 00:23:38.210
We also follow
that, and I was very

00:23:38.210 --> 00:23:41.480
happy to meet here actually
Manuel Dominguez Rodrigo

00:23:41.480 --> 00:23:42.530
through--

00:23:42.530 --> 00:23:44.730
Manuel is the husband
of Mary Pendergrast.

00:23:44.730 --> 00:23:48.210
He's also a fellow,
and we work together.

00:23:48.210 --> 00:23:50.630
And over lunch he
asked, can we use

00:23:50.630 --> 00:23:53.360
some of the machine learning
things you do in order

00:23:53.360 --> 00:23:57.290
to distinguish marks made
by weapons versus marks

00:23:57.290 --> 00:23:59.600
made by trampling over bones.

00:23:59.600 --> 00:24:00.650
So we did that.

00:24:00.650 --> 00:24:02.810
There has been a
wonderful collaboration.

00:24:02.810 --> 00:24:05.840
And we're basically
trying to answer when

00:24:05.840 --> 00:24:07.460
did the humans start to hunt?

00:24:07.460 --> 00:24:09.890
So by distinguishing
what is a cut mark

00:24:09.890 --> 00:24:12.440
and what is a trampling mark,
through machine learning

00:24:12.440 --> 00:24:13.490
we're trying to answer.

00:24:13.490 --> 00:24:17.450
I think this is a very
important question.

00:24:17.450 --> 00:24:20.000
Let me give you a more
elaborate example of how

00:24:20.000 --> 00:24:21.710
you can use data,
and to give you

00:24:21.710 --> 00:24:24.140
a Warning as to what
machine learning can do,

00:24:24.140 --> 00:24:26.550
by looking at trajectories.

00:24:26.550 --> 00:24:29.180
So here is trajectories
of viruses.

00:24:29.180 --> 00:24:33.470
And we have done classification
using support vector machines,

00:24:33.470 --> 00:24:35.420
where by looking
at characteristics

00:24:35.420 --> 00:24:37.070
of the particular
trajectories we

00:24:37.070 --> 00:24:41.600
can distinguish what is the
thing that the virus is doing.

00:24:41.600 --> 00:24:44.180
And we are very much
interested in places

00:24:44.180 --> 00:24:46.730
that are marked in red,
because these are the times

00:24:46.730 --> 00:24:50.330
that viruses are going
on straight segments.

00:24:50.330 --> 00:24:52.760
Now the knowledge about
viruses, and how do they

00:24:52.760 --> 00:24:55.350
move around inside the
cell is very limited.

00:24:55.350 --> 00:24:58.340
We know that they attach
themselves to microtubules,

00:24:58.340 --> 00:25:00.890
but microscopy is not
good enough to tell us

00:25:00.890 --> 00:25:03.290
how many attachments they have.

00:25:03.290 --> 00:25:05.516
And then we resort to movies.

00:25:05.516 --> 00:25:10.390
This is done by a company called
BioVisions, here at Harvard.

00:25:10.390 --> 00:25:13.590
These are microtubules,
they're inside the cell.

00:25:13.590 --> 00:25:15.927
And then we get here
a vesicle, and there

00:25:15.927 --> 00:25:18.662
are proteins that are moving
on these microtubules.

00:25:18.662 --> 00:25:21.027
The viruses are recruiting them.

00:25:21.027 --> 00:25:25.010
And these proteins are bringing
them either to the center

00:25:25.010 --> 00:25:28.978
or to the outside of the cell.

00:25:28.978 --> 00:25:33.630
I was interacting on that with a
guy called Ari Helenius at ETH.

00:25:33.630 --> 00:25:37.410
And we actually wanted to
examine different hypotheses

00:25:37.410 --> 00:25:39.950
by looking at trajectory data.

00:25:39.950 --> 00:25:41.900
Looking at whether
kinesin and dyein,

00:25:41.900 --> 00:25:43.860
the blue and green are together.

00:25:43.860 --> 00:25:46.200
Whether you have only
one of the two, or there

00:25:46.200 --> 00:25:49.110
is another secret
molecule that is acting.

00:25:49.110 --> 00:25:51.450
The way we did that is we
took that trajectories.

00:25:51.450 --> 00:25:54.600
We analyzed them, and we looked
up straight trajectories,

00:25:54.600 --> 00:25:58.110
because that's when we
thought that the virus exists

00:25:58.110 --> 00:26:02.640
on the surface of microtubules,
and is doing a directed motion.

00:26:02.640 --> 00:26:05.700
And we specify the model,
it's a stochastic model.

00:26:05.700 --> 00:26:08.130
It contains six equations here.

00:26:08.130 --> 00:26:10.480
And there six equations
tell you, for example,

00:26:10.480 --> 00:26:13.260
that you have dyein not
tossed and dyein moves.

00:26:13.260 --> 00:26:15.690
You have kinesin tops
and kinesin in moves.

00:26:15.690 --> 00:26:17.850
They move in
opposite directions.

00:26:17.850 --> 00:26:21.180
You have that they unbind, and
you have them that they bind.

00:26:21.180 --> 00:26:23.270
And now the whole thing
here is-- yes, you're

00:26:23.270 --> 00:26:24.540
right, this model.

00:26:24.540 --> 00:26:28.350
But you say, I do not know
what are the rates under which

00:26:28.350 --> 00:26:30.540
these equations are operating.

00:26:30.540 --> 00:26:32.790
So you have to do some
reverse engineering,

00:26:32.790 --> 00:26:35.970
and use that data in
order to find these rates,

00:26:35.970 --> 00:26:38.790
because you cannot really
do first principles.

00:26:38.790 --> 00:26:42.640
So we do that, and we specify
probability distribution

00:26:42.640 --> 00:26:46.380
of the velocities that we get
from the data and the distances

00:26:46.380 --> 00:26:47.970
that the viruses are doing.

00:26:47.970 --> 00:26:51.420
We're doing some
expensive optimizations,

00:26:51.420 --> 00:26:53.070
in the sense that
it takes millions

00:26:53.070 --> 00:26:57.390
of function evaluations
to do such optimizations.

00:26:57.390 --> 00:26:59.160
And the net result
is that we are

00:26:59.160 --> 00:27:02.220
able to find out what
are all these rates,

00:27:02.220 --> 00:27:04.590
or when the experiments
and the simulations

00:27:04.590 --> 00:27:07.650
are agreeing in terms of their
probability distributions.

00:27:07.650 --> 00:27:10.860
We know what are
these different rates,

00:27:10.860 --> 00:27:12.810
and then we can
specify that it has

00:27:12.810 --> 00:27:15.420
been a stochastic tug of war.

00:27:15.420 --> 00:27:18.240
But we can do even more
besides these things.

00:27:18.240 --> 00:27:20.790
We can actually find out
by playing a little bit

00:27:20.790 --> 00:27:23.300
with our model where
these proteins are

00:27:23.300 --> 00:27:24.810
attaching themselves.

00:27:24.810 --> 00:27:27.060
So by optimizing
our model further,

00:27:27.060 --> 00:27:28.890
we find that we
can predict better

00:27:28.890 --> 00:27:32.460
the data when the binding
sites are 10 and 15.

00:27:32.460 --> 00:27:35.810
Now when the viruses
are inside the cytosol,

00:27:35.810 --> 00:27:38.480
there is three
proteins where these

00:27:38.480 --> 00:27:40.516
that are existing
on their cupsid,

00:27:40.516 --> 00:27:42.390
and these three proteins
are the places where

00:27:42.390 --> 00:27:45.220
the kinesin and the
dynein can attach itself.

00:27:45.220 --> 00:27:47.220
So now, if you
take a microtubule,

00:27:47.220 --> 00:27:50.490
and you project it over
one of the sides over here,

00:27:50.490 --> 00:27:52.470
then you find out
that the amount

00:27:52.470 --> 00:27:57.010
of places that you can attach
yourself are between 10 and 15,

00:27:57.010 --> 00:27:57.510
indeed.

00:27:57.510 --> 00:28:01.050
And this has to do with
this hexon-hexon interfaces,

00:28:01.050 --> 00:28:02.640
not with this p 9.

00:28:02.640 --> 00:28:05.580
So we did that, and then
the biologists in our group

00:28:05.580 --> 00:28:08.940
they destroyed p 9,
and then after that, we

00:28:08.940 --> 00:28:10.290
put again the viruses.

00:28:10.290 --> 00:28:14.380
And the viruses were able
to move inside the cells.

00:28:14.380 --> 00:28:16.720
So this is a prediction
by a computer model,

00:28:16.720 --> 00:28:19.410
as to what part of
the virus you destroy.

00:28:19.410 --> 00:28:21.780
And what we find is we
published this paper,

00:28:21.780 --> 00:28:24.180
and actually a week
later another paper

00:28:24.180 --> 00:28:27.150
came out from a completely
experimental group that they

00:28:27.150 --> 00:28:30.270
actually have reached the
same conclusion by doing

00:28:30.270 --> 00:28:33.690
experiments and playing
with the different factors.

00:28:33.690 --> 00:28:36.060
They identified
that viral capsids--

00:28:36.060 --> 00:28:39.990
actually, the hexon
sub units is the place

00:28:39.990 --> 00:28:42.390
where kinesin and dynein
are attaching themselves,

00:28:42.390 --> 00:28:44.580
and they're moving the viruses.

00:28:44.580 --> 00:28:47.340
So you can imagine that when
Google, or other places,

00:28:47.340 --> 00:28:49.980
have access to
your trajectories,

00:28:49.980 --> 00:28:51.480
they can process trajectories.

00:28:51.480 --> 00:28:53.940
And a lot of information
can be inferred.

00:28:53.940 --> 00:28:55.620
I will not be
surprised if people

00:28:55.620 --> 00:29:00.000
know what I have inside my
refrigerator by looking at what

00:29:00.000 --> 00:29:02.670
is my particular trajectory.

00:29:02.670 --> 00:29:05.530
Now I will come back to that.

00:29:05.530 --> 00:29:08.340
So this inference is
actually, again, this

00:29:08.340 --> 00:29:11.100
is a very powerful
process, and you

00:29:11.100 --> 00:29:14.650
can take data from trajectories
and look at structure.

00:29:14.650 --> 00:29:18.510
So this is, again, a comparison
of the two knowledges,

00:29:18.510 --> 00:29:21.110
and as I mentioned
earlier, I consider

00:29:21.110 --> 00:29:23.520
that now computing
is coming together,

00:29:23.520 --> 00:29:25.410
and is putting it together.

00:29:25.410 --> 00:29:27.750
We can actually use
first principles,

00:29:27.750 --> 00:29:30.210
and do statistical
type of calculations,

00:29:30.210 --> 00:29:33.210
because we can afford to
do many of these things.

00:29:33.210 --> 00:29:35.820
We can actually take
this possibility

00:29:35.820 --> 00:29:37.740
that the principles
are not useful,

00:29:37.740 --> 00:29:40.830
and combine them with
data and actually create

00:29:40.830 --> 00:29:44.730
new practical utilities
for given applications.

00:29:44.730 --> 00:29:46.320
But there's two
more things that we

00:29:46.320 --> 00:29:48.600
can do that we could
not do before, I think,

00:29:48.600 --> 00:29:50.640
and this is thanks to computers.

00:29:50.640 --> 00:29:53.520
One is to, for the first
time, understand that

00:29:53.520 --> 00:29:56.070
Newton and all these people
that they put forward

00:29:56.070 --> 00:29:58.960
the equations
there is a problem.

00:29:58.960 --> 00:30:01.320
And the problem is that
there are imperfections

00:30:01.320 --> 00:30:03.810
in the ways people
derive equations,

00:30:03.810 --> 00:30:05.290
and there are uncertainties.

00:30:05.290 --> 00:30:07.780
This is the first thing that
I would like to tell you.

00:30:07.780 --> 00:30:10.410
And the second thing
is that heuristics,

00:30:10.410 --> 00:30:12.360
the same way that
first principles can

00:30:12.360 --> 00:30:15.060
give you guidance for
causation, heuristics,

00:30:15.060 --> 00:30:17.010
when combined with
first principles,

00:30:17.010 --> 00:30:19.290
can actually lead to causation.

00:30:19.290 --> 00:30:22.380
And again, both of them are
thanks to the capabilities

00:30:22.380 --> 00:30:24.100
of computers.

00:30:24.100 --> 00:30:26.740
So what is about the
imperfections and uncertainty?

00:30:26.740 --> 00:30:29.850
So I gave you a model
that I made earlier,

00:30:29.850 --> 00:30:32.950
but the model was about
foxes and rabbits.

00:30:32.950 --> 00:30:38.100
And then at some point, I
created a mathematical model

00:30:38.100 --> 00:30:40.070
about foxes and rabbits.

00:30:40.070 --> 00:30:42.870
Then I made the
computational model.

00:30:42.870 --> 00:30:45.390
I could have compared
with experimenters,

00:30:45.390 --> 00:30:49.170
as I have done in my other
simulations, but everywhere--

00:30:49.170 --> 00:30:52.080
everywhere when experiments
and mathematical models

00:30:52.080 --> 00:30:54.720
are being compared-- when
computational and mathematical

00:30:54.720 --> 00:30:58.200
models are being compared
everywhere there are errors.

00:30:58.200 --> 00:30:59.670
There are errors in modeling.

00:30:59.670 --> 00:31:01.540
Maybe they are terms I forgot.

00:31:01.540 --> 00:31:04.710
There are error in experiments,
and errors in my models.

00:31:04.710 --> 00:31:06.300
There is discretization errors.

00:31:06.300 --> 00:31:08.640
You write down an equation,
but you corrupt it when

00:31:08.640 --> 00:31:10.710
you put it inside the computer.

00:31:10.710 --> 00:31:12.930
So out of all these
imperfections,

00:31:12.930 --> 00:31:14.730
you have to acknowledge
imperfections

00:31:14.730 --> 00:31:17.670
if you are to be able
to arrive to knowledge,

00:31:17.670 --> 00:31:21.360
and to be able to quantify
imperfections and uncertainties

00:31:21.360 --> 00:31:23.380
in your predictions.

00:31:23.380 --> 00:31:26.250
So this process of
uncertainty quantification

00:31:26.250 --> 00:31:29.530
and mathematical models
has been very important.

00:31:29.530 --> 00:31:30.789
And here is an example--

00:31:30.789 --> 00:31:31.455
[VIDEO PLAYBACK]

00:31:31.455 --> 00:31:33.930
- Tom Menino is
defending his decision

00:31:33.930 --> 00:31:37.230
not to close the schools there
today, despite a snowstorm.

00:31:37.230 --> 00:31:40.050
He says he got
conflicting forecasts.

00:31:40.050 --> 00:31:42.330
And when severe weather
is approaching--

00:31:42.330 --> 00:31:44.850
when you hear us talk
about the European models,

00:31:44.850 --> 00:31:48.210
we don't mean anyone who wears
fancy clothes walking down

00:31:48.210 --> 00:31:49.080
a runway.

00:31:49.080 --> 00:31:51.780
Those multicolored spaghetti
lines on the weather

00:31:51.780 --> 00:31:54.180
maps when big storms
are approaching,

00:31:54.180 --> 00:31:57.030
those are all computer
models, predictions.

00:31:57.030 --> 00:32:00.600
Some are from our government
forecasters, but increasingly

00:32:00.600 --> 00:32:02.910
the European computer--

00:32:02.910 --> 00:32:05.670
- So this is the
big success story

00:32:05.670 --> 00:32:10.470
of the European computer models
was on the Sunday storm, where

00:32:10.470 --> 00:32:10.970
they had--

00:32:10.970 --> 00:32:11.150
[VIDEO PLAYBACK]

00:32:11.150 --> 00:32:12.830
- The question is,
do we need the push

00:32:12.830 --> 00:32:15.630
broom, or the great
big shovel out here?

00:32:15.630 --> 00:32:17.190
We really don't need either.

00:32:17.190 --> 00:32:18.720
- Weather Channel's
Jim Cantore--

00:32:18.720 --> 00:32:21.210
- So what does this--
what are all this--

00:32:21.210 --> 00:32:24.980
what this thing says,
basically, is that--

00:32:24.980 --> 00:32:28.200
that depending on the model
you get, you have parameters.

00:32:28.200 --> 00:32:30.780
You may get a different
forecast from one model.

00:32:30.780 --> 00:32:33.420
You may get a different
forecast from the other model.

00:32:33.420 --> 00:32:35.850
And I should tell you that
the European medium weather

00:32:35.850 --> 00:32:39.160
forecast model also
fails in other cases.

00:32:39.160 --> 00:32:42.270
So whenever you hear an
answer from a computation,

00:32:42.270 --> 00:32:44.250
the same way that
in the past we would

00:32:44.250 --> 00:32:47.280
go through experimentalists,
and ask them for error bars,

00:32:47.280 --> 00:32:50.580
you should go now to
modalists and ask them also,

00:32:50.580 --> 00:32:54.600
like people like myself, and
ask us also for error bars.

00:32:54.600 --> 00:32:56.850
So these error bars
are becoming important.

00:32:56.850 --> 00:32:59.352
For another, I'll give you
another example about that.

00:32:59.352 --> 00:33:00.810
You look at the
experiments, people

00:33:00.810 --> 00:33:03.990
study how much water is
flowing in carbon nanotubes.

00:33:03.990 --> 00:33:07.560
The dimensions you see across
there is two nanometers.

00:33:07.560 --> 00:33:10.590
And then people are studying
how fast you can push water,

00:33:10.590 --> 00:33:12.720
and you can push that
orders of magnitude

00:33:12.720 --> 00:33:16.640
faster than if this
was a much larger pipe,

00:33:16.640 --> 00:33:19.290
due to specularities
of the molecular level.

00:33:19.290 --> 00:33:21.360
But what I want you to
observe is that these

00:33:21.360 --> 00:33:22.770
are order of magnitude.

00:33:22.770 --> 00:33:25.410
And you can see even
for the same length

00:33:25.410 --> 00:33:27.570
that you have two
or three orders

00:33:27.570 --> 00:33:30.480
of magnitude differences on
their results from experiments.

00:33:30.480 --> 00:33:33.360
Or one experimentalists
will run this experiment,

00:33:33.360 --> 00:33:36.520
and we get the factor of 1,000
different than the other.

00:33:36.520 --> 00:33:38.850
Both of them will
publish their papers,

00:33:38.850 --> 00:33:40.890
but the question is
why does it happen?

00:33:40.890 --> 00:33:45.880
And the same error bars
actually appear in simulations.

00:33:45.880 --> 00:33:49.000
So in simulations-- we
do molecular simulations.

00:33:49.000 --> 00:33:51.700
We have parameters, because
of the models we use.

00:33:51.700 --> 00:33:54.820
The parameters we choose
the way we do the computing.

00:33:54.820 --> 00:33:57.070
And then we use
measurements to calibrate.

00:33:57.070 --> 00:33:58.780
So depending how
we calibrate, we

00:33:58.780 --> 00:34:01.060
can get also different models.

00:34:01.060 --> 00:34:03.310
And depending on what kind
of computing resources

00:34:03.310 --> 00:34:06.000
we can run, for example,
that weather model

00:34:06.000 --> 00:34:09.250
at the size of one kilometer
resolution or 100 meters--

00:34:09.250 --> 00:34:13.550
100 kilometers resolution, and
that makes a big difference.

00:34:13.550 --> 00:34:17.170
So we go back to a theory,
that came back about the 1700s,

00:34:17.170 --> 00:34:19.780
and this is by Bayes.

00:34:19.780 --> 00:34:22.730
And the idea is that you
have to use theories,

00:34:22.730 --> 00:34:24.699
but the theories
have to be charged

00:34:24.699 --> 00:34:27.969
in terms of probabilities
in light of the evidence.

00:34:27.969 --> 00:34:31.199
This is Bayes formula,
and if you replace a here,

00:34:31.199 --> 00:34:34.540
what is the probability of
a certain hypothesis given

00:34:34.540 --> 00:34:35.530
the data?

00:34:35.530 --> 00:34:38.409
You have to do that by looking
at this thing over here, which

00:34:38.409 --> 00:34:40.480
is the likelihood
or the evidence.

00:34:40.480 --> 00:34:42.500
What prior information
that you have?

00:34:42.500 --> 00:34:44.500
And then you create
the posterior.

00:34:44.500 --> 00:34:46.870
So once you calibrate it,
and you have this probability

00:34:46.870 --> 00:34:49.900
distribution, then you can
go and predict something.

00:34:49.900 --> 00:34:53.110
But you predict only
with probabilities.

00:34:53.110 --> 00:34:55.409
So instead of giving
you a value for epsilon

00:34:55.409 --> 00:34:58.930
that they gave earlier
to be 0 or 0.2, now

00:34:58.930 --> 00:35:00.790
I would give a
probability distribution,

00:35:00.790 --> 00:35:03.800
because this probabliity
distribution came from data.

00:35:03.800 --> 00:35:05.800
So when I predict
how fast the water is

00:35:05.800 --> 00:35:07.660
going inside the
carbon nanotubes,

00:35:07.660 --> 00:35:12.550
I give again a probability
distribution about my results.

00:35:12.550 --> 00:35:14.470
Now where are the
computers in there?

00:35:14.470 --> 00:35:16.330
Well, the computers
are in there,

00:35:16.330 --> 00:35:18.400
because to do this
probability distributions,

00:35:18.400 --> 00:35:21.040
you have to do high
dimensional integrals.

00:35:21.040 --> 00:35:24.040
For every parameter, you
account for an integral

00:35:24.040 --> 00:35:25.030
for one dimension.

00:35:25.030 --> 00:35:28.270
This is a highly dimensional
problem, without computers.

00:35:28.270 --> 00:35:31.030
The theory of Bayes has
been there for 400 years.

00:35:31.030 --> 00:35:33.820
It's only now that we
are able to access it,

00:35:33.820 --> 00:35:37.660
and we are able to do wonderful
things, in my opinion, with it.

00:35:37.660 --> 00:35:40.670
Last one, heuristics
and causality.

00:35:40.670 --> 00:35:44.410
This is about an algorithm
that you all know.

00:35:44.410 --> 00:35:46.660
And this is the algorithm,
by Charles Darwin.

00:35:46.660 --> 00:35:48.190
It's about evolution.

00:35:48.190 --> 00:35:51.820
And we use this algorithm
in order to do design.

00:35:51.820 --> 00:35:54.490
Instead of having genes,
we consider the parameters

00:35:54.490 --> 00:35:56.320
of an engineering system.

00:35:56.320 --> 00:35:59.200
And then by evolving
this engineering system

00:35:59.200 --> 00:36:01.330
in a probabilistic
fashion, the parameters

00:36:01.330 --> 00:36:03.130
in a probabilistic
fashion, we're

00:36:03.130 --> 00:36:07.000
able to do reverse engineering
in the most powerful way.

00:36:07.000 --> 00:36:10.690
In mathematical terms, you can
put evolution in that sense.

00:36:10.690 --> 00:36:14.170
I will not go into the
details, today at least,

00:36:14.170 --> 00:36:16.180
but I want to show you
some examples of what

00:36:16.180 --> 00:36:17.860
is it that we do.

00:36:17.860 --> 00:36:20.260
You can use that actually
to compute behavior,

00:36:20.260 --> 00:36:23.360
by reverse engineering,
again, data.

00:36:23.360 --> 00:36:26.470
So one of the data
that we look at--

00:36:26.470 --> 00:36:30.550
this is a little fish, and
he's been chased by a big fish.

00:36:30.550 --> 00:36:33.340
And the little fish is
escaping constantly.

00:36:33.340 --> 00:36:36.910
So people have been fascinated
by the way the little fish are

00:36:36.910 --> 00:36:39.190
escaping in the water.

00:36:39.190 --> 00:36:42.910
So actually, if you want to see
it a little bit more up close

00:36:42.910 --> 00:36:45.100
and personal, is
what these guys do

00:36:45.100 --> 00:36:47.980
is they sense the water when
the mouth of the predator

00:36:47.980 --> 00:36:48.610
is coming.

00:36:48.610 --> 00:36:50.620
And then they're able to escape.

00:36:50.620 --> 00:36:53.260
But they way they escape
is very, very peculiar,

00:36:53.260 --> 00:36:56.020
and it's encoded in
their nervous system.

00:36:56.020 --> 00:36:58.090
What they do is when
they're disturbed,

00:36:58.090 --> 00:37:00.890
they're doing something
that is called a C-start,

00:37:00.890 --> 00:37:03.640
and the C-start is this
bending of the body

00:37:03.640 --> 00:37:06.340
so that it looks
like a C. And then

00:37:06.340 --> 00:37:08.890
you can see how fast it is
that the camera is actually

00:37:08.890 --> 00:37:11.740
losing it from the frame here.

00:37:11.740 --> 00:37:14.920
People have done experiments,
but you can do experiments.

00:37:14.920 --> 00:37:16.630
You can visualize
the flow, you still

00:37:16.630 --> 00:37:18.940
don't know if this is optimal.

00:37:18.940 --> 00:37:21.730
But if you formulate it in the
computer as an optimization

00:37:21.730 --> 00:37:25.100
problem, you can find
out if nature is optimal.

00:37:25.100 --> 00:37:27.130
So what you do is you specify--

00:37:27.130 --> 00:37:29.680
you take the animal, and
you take the geometry.

00:37:29.680 --> 00:37:31.870
And you specify some parameters.

00:37:31.870 --> 00:37:34.270
You specify a cost
function, and then you

00:37:34.270 --> 00:37:38.260
give it degrees of freedom to
discover different motions.

00:37:38.260 --> 00:37:40.570
So you do that, and you
start with the motion

00:37:40.570 --> 00:37:41.780
that these fish like.

00:37:41.780 --> 00:37:46.410
And in this particular medium
or flow viscosity, if you like,

00:37:46.410 --> 00:37:47.950
it doesn't go very far.

00:37:47.950 --> 00:37:51.640
But it goes very far when
it's doing the C-start.

00:37:51.640 --> 00:37:54.640
So the C-start actually was an
outcome of the optimization.

00:37:54.640 --> 00:37:57.640
After 8,000 direct
numerical simulations,

00:37:57.640 --> 00:37:59.890
we were able to
discover that, and we

00:37:59.890 --> 00:38:01.720
were able to compare
with experiments.

00:38:01.720 --> 00:38:05.320
We find the center line
is the same deformation

00:38:05.320 --> 00:38:08.360
in the simulation and
in the experiment.

00:38:08.360 --> 00:38:10.390
But all this thing
is not explanation.

00:38:10.390 --> 00:38:13.270
The explanation comes
through a very nice idea

00:38:13.270 --> 00:38:15.550
of [? Vim Varis ?] who
is in the audience.

00:38:15.550 --> 00:38:16.690
So we look at this thing.

00:38:16.690 --> 00:38:17.860
This is vorticity.

00:38:17.860 --> 00:38:20.620
This is great, but what
[? Vim ?] and Mattia Gazzola

00:38:20.620 --> 00:38:24.790
did is they looked at what
this body of the fish is doing.

00:38:24.790 --> 00:38:27.670
This is a little animal,
so in order to push fluid,

00:38:27.670 --> 00:38:29.710
it has to use all its body.

00:38:29.710 --> 00:38:33.040
So what it does is it engulfs
us much fluid as possible,

00:38:33.040 --> 00:38:36.220
and then with a swing of the
tail is getting out of there.

00:38:36.220 --> 00:38:39.970
So using heuristics, using
these evolutions strategies,

00:38:39.970 --> 00:38:41.860
and using direct
numerical simulations,

00:38:41.860 --> 00:38:45.150
we have looked into
optimality in nature.

00:38:45.150 --> 00:38:48.700
And the last question that we
ask in science, if you'd like,

00:38:48.700 --> 00:38:50.855
is about fish schooling.

00:38:54.040 --> 00:38:57.040
So schooling is one of
these magnificent patterns

00:38:57.040 --> 00:38:58.840
that you see in nature.

00:38:58.840 --> 00:39:02.110
And you ask the
question, do these guys

00:39:02.110 --> 00:39:05.200
have a choice that they
school, or is it their fate

00:39:05.200 --> 00:39:07.280
that they are doing that?

00:39:07.280 --> 00:39:09.250
So we're trying to
understand that,

00:39:09.250 --> 00:39:11.750
and we started by doing
it in a more humble way we

00:39:11.750 --> 00:39:13.960
start with two fish.

00:39:13.960 --> 00:39:16.090
So this is filmed
with an iPhone.

00:39:16.090 --> 00:39:17.542
And so you look
at these two fish,

00:39:17.542 --> 00:39:19.000
and you look again
at what they do.

00:39:19.000 --> 00:39:22.070
And you try to understand what
is it that they are doing.

00:39:22.070 --> 00:39:24.130
But before you do that,
you have to find out

00:39:24.130 --> 00:39:26.950
if this is efficient
to swim behind someone,

00:39:26.950 --> 00:39:28.480
or what is it that you gain.

00:39:28.480 --> 00:39:31.620
But to do that, you have to put
two fish to stream together.

00:39:31.620 --> 00:39:34.490
And to put two fish to swim
together it's very difficult.

00:39:34.490 --> 00:39:37.540
First of all, because no
simulation capabilities existed

00:39:37.540 --> 00:39:39.730
to have two
self-propelled bodies,

00:39:39.730 --> 00:39:41.440
but we have resolved that.

00:39:41.440 --> 00:39:45.820
But what you see here is you put
two fish, one behind the other,

00:39:45.820 --> 00:39:47.800
and you give them
an initial motion.

00:39:47.800 --> 00:39:51.250
But then the second fish
is actually speeding up,

00:39:51.250 --> 00:39:53.530
and is catching up
with the first guy.

00:39:53.530 --> 00:39:55.280
So you say, aha,
that's what happens.

00:39:55.280 --> 00:39:58.360
But then you move the second
fish a little bit behind,

00:39:58.360 --> 00:40:00.100
and this optimization
does not work.

00:40:00.100 --> 00:40:02.650
We threw every optimization
technique we have.

00:40:02.650 --> 00:40:04.990
This is not an
optimization problem.

00:40:04.990 --> 00:40:06.290
This is something else.

00:40:06.290 --> 00:40:08.780
This is a reinforcement
learning problem.

00:40:08.780 --> 00:40:10.390
An reinforcement
learning problem

00:40:10.390 --> 00:40:12.610
is Pavlov's dog problem.

00:40:12.610 --> 00:40:15.010
The idea is that
you have an agent,

00:40:15.010 --> 00:40:17.890
and an agent is experienced
in the environment.

00:40:17.890 --> 00:40:21.820
Is acquiring information,
and the key thing is reward.

00:40:21.820 --> 00:40:24.690
And once you have
the reward, then you

00:40:24.690 --> 00:40:29.060
are able to find the optimal
policy by which you are moving.

00:40:29.060 --> 00:40:31.300
Now, Guido Novati,
is in the audience,

00:40:31.300 --> 00:40:33.380
has done a lot of
work about that.

00:40:33.380 --> 00:40:36.130
But just to give you an idea
about reinforcement learning,

00:40:36.130 --> 00:40:38.200
I use this example usually.

00:40:38.200 --> 00:40:40.790
It's about bugs
solving problems.

00:40:40.790 --> 00:40:43.570
So here's a bug, and
he has a problem.

00:40:43.570 --> 00:40:46.390
And the problem that he has
is what you see right here.

00:40:46.390 --> 00:40:48.010
So he has to solve it.

00:40:48.010 --> 00:40:49.360
So he tries very hard.

00:40:49.360 --> 00:40:51.900
This is a three minute movie
from the movie Microsmos.

00:40:51.900 --> 00:40:53.900
You're not going to see
all three minutes of it,

00:40:53.900 --> 00:40:55.790
it has been edited.

00:40:55.790 --> 00:40:59.270
So you see he tries,
it doesn't really work.

00:40:59.270 --> 00:41:01.180
And then what he's going
to do, in a second,

00:41:01.180 --> 00:41:03.235
he is going to be almost
solving the problem--

00:41:06.220 --> 00:41:07.570
but not quite.

00:41:07.570 --> 00:41:10.480
Then he gets the idea
of trying another way.

00:41:10.480 --> 00:41:11.920
He goes around.

00:41:11.920 --> 00:41:15.480
Well then he is going to
totally miss the point.

00:41:15.480 --> 00:41:16.320
[LAUGHING]

00:41:16.320 --> 00:41:18.670
But to cut the long
story short, this guy

00:41:18.670 --> 00:41:23.720
is actually successful, after a
real time of 3 and 1/2 minutes.

00:41:23.720 --> 00:41:26.530
And he is able to feel like
applauding after seeing

00:41:26.530 --> 00:41:27.580
this three minutes.

00:41:27.580 --> 00:41:28.630
[LAUGHING]

00:41:28.630 --> 00:41:32.140
So this is reinforcement
learning without the math.

00:41:32.140 --> 00:41:35.920
So what we do is we take
actually fish and simulations,

00:41:35.920 --> 00:41:38.350
and we have actions,
which is how we move.

00:41:38.350 --> 00:41:41.350
We put states, which is
to see the other fish.

00:41:41.350 --> 00:41:44.680
And we put the reward to find
out if you are efficient.

00:41:44.680 --> 00:41:47.840
And what we find, it's
actually the second fish

00:41:47.840 --> 00:41:50.410
has the option to not swim
behind the first fish,

00:41:50.410 --> 00:41:53.410
but because of reinforcement
learning, he finds out

00:41:53.410 --> 00:41:56.590
that there he can
actually go, and harness

00:41:56.590 --> 00:41:58.080
the wake of the
first time animal

00:41:58.080 --> 00:42:00.670
and increase its efficiency.

00:42:00.670 --> 00:42:04.010
This is more spectacular when
you see it in three dimensions.

00:42:04.010 --> 00:42:07.030
This is one of a kind simulation
again, and in my opinion

00:42:07.030 --> 00:42:10.150
it ranks up there with a
cavitation and the red blood

00:42:10.150 --> 00:42:12.100
cells, because the
first time that someone

00:42:12.100 --> 00:42:16.420
sees two self-propelled swimmers
that together actually have

00:42:16.420 --> 00:42:19.060
learned to follow its other.

00:42:19.060 --> 00:42:20.780
And this is an early learning.

00:42:20.780 --> 00:42:23.140
And this is a later
learning that you will see,

00:42:23.140 --> 00:42:26.140
that the second guy totally
in an automated fashion,

00:42:26.140 --> 00:42:28.720
has learned to avoid
the vortices that

00:42:28.720 --> 00:42:33.550
will disturb it from the first
guy, and goes in between.

00:42:33.550 --> 00:42:35.500
So through
Navier-Stokes equations,

00:42:35.500 --> 00:42:37.720
and for the first time,
Navier-Stokes equations

00:42:37.720 --> 00:42:40.620
and deep reinforcement
learning, we do that.

00:42:40.620 --> 00:42:42.880
And actually, what we
are very much interested

00:42:42.880 --> 00:42:46.180
is to revisit some experimental
results that people argue

00:42:46.180 --> 00:42:48.310
that fish stay behind
stones, and they

00:42:48.310 --> 00:42:53.300
are exploiting vortices to
reduce their muscle activity.

00:42:53.300 --> 00:42:55.900
So we're moving into
things like cyber fish.

00:42:55.900 --> 00:42:59.140
This is how I fell asleep
by reading books to my kids.

00:42:59.140 --> 00:43:02.560
This is from a great
book called Flotsam,

00:43:02.560 --> 00:43:04.150
but I thought it
was magnificent,

00:43:04.150 --> 00:43:06.190
because these are
some of the ideas

00:43:06.190 --> 00:43:08.690
that we would like
to do, combining

00:43:08.690 --> 00:43:12.650
the cyber and the real.

00:43:12.650 --> 00:43:15.580
So cyber and the he
has a long history.

00:43:15.580 --> 00:43:19.390
So this is now we're going
about computers humans and data.

00:43:19.390 --> 00:43:22.510
And there are things that
talk about my machina sapians,

00:43:22.510 --> 00:43:25.900
and how the humans and
the computers and the data

00:43:25.900 --> 00:43:28.120
are coming together.

00:43:28.120 --> 00:43:29.626
So here's David Wayne.

00:43:29.626 --> 00:43:30.292
[VIDEO PLAYBACK]

00:43:30.292 --> 00:43:32.600
- Even the scientists
argue that.

00:43:32.600 --> 00:43:36.300
I don't believe that we can
say yet that machines do think.

00:43:36.300 --> 00:43:38.720
I have a basic question,
which I always ask,

00:43:38.720 --> 00:43:41.696
and that is are these
producing anything really new.

00:43:41.696 --> 00:43:46.360
Until I see a machine
producing genuinely new things,

00:43:46.360 --> 00:43:49.334
I will not agree
that machines think.

00:43:49.334 --> 00:43:50.000
[VIDEO PLAYBACK]

00:43:50.000 --> 00:43:52.490
- I confidently expect,
that within a matter of 10

00:43:52.490 --> 00:43:54.410
or 15 years,
something will emerge

00:43:54.410 --> 00:43:57.390
from the laboratories which
is not too far from the robot

00:43:57.390 --> 00:43:59.280
or science fiction thing.

00:43:59.280 --> 00:44:02.010
- This is Claude Shannon, of
Shannon Information Theory.

00:44:02.010 --> 00:44:04.590
And this is, again, a
movie from the MIT archives

00:44:04.590 --> 00:44:07.260
that I found from the 1960s.

00:44:07.260 --> 00:44:09.960
And this is perhaps
how humans think.

00:44:09.960 --> 00:44:11.550
This is the fixation
of The Thinker,

00:44:11.550 --> 00:44:15.170
one of my favorite paintings
by Georgia de Chirico.

00:44:15.170 --> 00:44:19.920
And talking about people that
have looked into machines,

00:44:19.920 --> 00:44:22.920
a lot of the things
happened back in the 80s.

00:44:22.920 --> 00:44:26.130
And if you are very fast
and you read all this,

00:44:26.130 --> 00:44:28.740
you will find people like
Stephen Wolfram in there,

00:44:28.740 --> 00:44:32.100
and you will look at all
the cellular automata

00:44:32.100 --> 00:44:35.290
was one of the early ideas
of putting machines together.

00:44:35.290 --> 00:44:37.370
You will find,
actually down here,

00:44:37.370 --> 00:44:41.100
the connection machine that
I had the honor to compute.

00:44:41.100 --> 00:44:43.260
And you will find
also one more person,

00:44:43.260 --> 00:44:47.160
which is Gerard Vichelac, which
is the husband of Judy, that

00:44:47.160 --> 00:44:50.190
actually happened to be
one of the pioneers working

00:44:50.190 --> 00:44:53.580
in this interface between
machines and intelligence.

00:44:53.580 --> 00:44:55.410
And actually at
that time, people

00:44:55.410 --> 00:44:57.720
were thinking how to
combine the two in order

00:44:57.720 --> 00:45:00.300
to create computers.

00:45:00.300 --> 00:45:03.430
Moving forward,
today this interface

00:45:03.430 --> 00:45:06.120
of machines and humans has
taken another dimension.

00:45:06.120 --> 00:45:09.510
We're talking about
society, but we are actually

00:45:09.510 --> 00:45:14.490
coming to the level of talking
about the digital society.

00:45:14.490 --> 00:45:16.080
And now machine
learning can also

00:45:16.080 --> 00:45:17.524
be used for the digital society.

00:45:17.524 --> 00:45:18.190
[VIDEO PLAYBACK]

00:45:18.190 --> 00:45:20.700
- --machine learning and
artificial intelligence making

00:45:20.700 --> 00:45:23.010
Facebook different for people.

00:45:23.010 --> 00:45:24.810
How has it changed
Facebook, the platform?

00:45:24.810 --> 00:45:25.140
[VIDEO PLAYBACK]

00:45:25.140 --> 00:45:27.390
- Yeah, I think, you know,
AI machinery learning

00:45:27.390 --> 00:45:29.870
is really a key tool
that will help people

00:45:29.870 --> 00:45:32.107
manage just the tremendous
amount of information you

00:45:32.107 --> 00:45:32.690
see everyday.

00:45:32.690 --> 00:45:35.310
You know, every single
time you log into Facebook,

00:45:35.310 --> 00:45:38.529
there are hundreds or
possibly thousands of things

00:45:38.529 --> 00:45:39.570
your friends have shared.

00:45:39.570 --> 00:45:40.365
We can show you.

00:45:40.365 --> 00:45:43.800
And our job is to try to
find absolute things that

00:45:43.800 --> 00:45:45.180
are the best and
most interesting

00:45:45.180 --> 00:45:47.640
to you, the thing you
want to see and share.

00:45:47.640 --> 00:45:50.320
- So information is growing.

00:45:50.320 --> 00:45:53.520
And this is a picture of
me trying to cast an Uber,

00:45:53.520 --> 00:45:56.400
and, of course, this is the
picture that I get from Uber.

00:45:56.400 --> 00:45:59.190
And you know the recent stories
about what pictures Uber might

00:45:59.190 --> 00:46:00.780
be presenting you.

00:46:00.780 --> 00:46:03.270
So my information,
which is actually

00:46:03.270 --> 00:46:06.720
I consider it to be my
product and to be considered

00:46:06.720 --> 00:46:10.410
I consider it also to be my
property, is being shared.

00:46:10.410 --> 00:46:13.050
At the same time, I don't
receive the same information

00:46:13.050 --> 00:46:13.560
from Uber.

00:46:13.560 --> 00:46:16.110
For example, I don't know
how many people are waiting.

00:46:16.110 --> 00:46:19.680
So perhaps I can hitch a
ride with someone else.

00:46:19.680 --> 00:46:22.110
So the story of
the information is

00:46:22.110 --> 00:46:25.410
that this symmetry of
information that we produce,

00:46:25.410 --> 00:46:27.780
and information that
people have access,

00:46:27.780 --> 00:46:30.420
is becoming more and
more symmetrical.

00:46:30.420 --> 00:46:33.150
And this leads to inequality.

00:46:33.150 --> 00:46:37.020
And I would like to use here
a quote by Larry Lessig, who

00:46:37.020 --> 00:46:40.020
is a professor of Law at
Harvard, talking about,

00:46:40.020 --> 00:46:43.620
"A culture without property, or
in which creators can get paid,

00:46:43.620 --> 00:46:46.190
is anarchy, not freedom".

00:46:46.190 --> 00:46:48.960
And I would lead people to
make their own comments,

00:46:48.960 --> 00:46:51.960
but there is a lot of agitation
that is happening today,

00:46:51.960 --> 00:46:54.270
because of all these
technologies, all these machine

00:46:54.270 --> 00:46:57.000
learning, that they told
you it's a wonderful tool

00:46:57.000 --> 00:46:58.500
to do discovery.

00:46:58.500 --> 00:47:00.570
At the same time,
this possibility

00:47:00.570 --> 00:47:03.900
of accessing human
data raises the level

00:47:03.900 --> 00:47:06.450
of actually questioning
whether democracy

00:47:06.450 --> 00:47:11.030
will survive big data and
artificial intelligence.

00:47:11.030 --> 00:47:12.990
And there are other
voices who are actually

00:47:12.990 --> 00:47:17.530
questioning what is the
effect of computing in people.

00:47:17.530 --> 00:47:19.470
So there is this professor
from the University

00:47:19.470 --> 00:47:23.130
of Michigan, Kentaro Toyama,
who actually showed--

00:47:23.130 --> 00:47:27.480
this is the US poverty rate, and
he looks at digital technology.

00:47:27.480 --> 00:47:29.700
And then you would
have expected that when

00:47:29.700 --> 00:47:33.030
the internet appeared, that
poverty would stay and stay

00:47:33.030 --> 00:47:35.340
down, or when Google
appeared, something

00:47:35.340 --> 00:47:36.750
will happen to poverty.

00:47:36.750 --> 00:47:39.480
But poverty doesn't
change, and it's actually

00:47:39.480 --> 00:47:41.910
it's indifferent to
all these developments

00:47:41.910 --> 00:47:43.944
on digital technology.

00:47:43.944 --> 00:47:45.360
You would think
that this would be

00:47:45.360 --> 00:47:48.690
a change in the charitable
giving in the United States.

00:47:48.690 --> 00:47:53.520
Digital technology does
not change that either.

00:47:53.520 --> 00:47:56.430
At the same time, what
digital technology is doing

00:47:56.430 --> 00:48:00.270
is increasing the productivity
of people, but at the same time

00:48:00.270 --> 00:48:04.290
the compensation of people is
not increasing proportional

00:48:04.290 --> 00:48:07.790
to their productivity.

00:48:07.790 --> 00:48:10.200
To put it on the other
side at the same time,

00:48:10.200 --> 00:48:13.650
we go back, and thanks to
UPS and thanks to Facebook

00:48:13.650 --> 00:48:16.740
and thanks to all these
technologies, people

00:48:16.740 --> 00:48:19.200
in very remote areas--

00:48:19.200 --> 00:48:22.020
this is an example,
from people from ETH,

00:48:22.020 --> 00:48:25.770
that they are actually going and
through a phone they actually

00:48:25.770 --> 00:48:32.100
can examine children in
remote areas in South America.

00:48:32.100 --> 00:48:35.610
You can actually use the Google
Street View images in order

00:48:35.610 --> 00:48:38.490
to identify information
about poverty,

00:48:38.490 --> 00:48:41.370
and perhaps one can do
something about that.

00:48:41.370 --> 00:48:44.490
So all I'm saying is
that we live in times

00:48:44.490 --> 00:48:46.440
that perhaps at
some point we have

00:48:46.440 --> 00:48:49.640
to choose in which way we want
to push these technologies.

00:48:49.640 --> 00:48:53.130
So I argue that this
is a critical time.

00:48:53.130 --> 00:48:56.410
And at the same time, something
that I have experienced

00:48:56.410 --> 00:48:58.110
that last time that
I've been here,

00:48:58.110 --> 00:49:02.280
you start to realize that
also the mind, the human mind,

00:49:02.280 --> 00:49:04.260
needs assistance.

00:49:04.260 --> 00:49:05.730
We believe in untruths.

00:49:05.730 --> 00:49:07.350
We cannot distinguish things.

00:49:07.350 --> 00:49:09.840
We need some assistance
in order to face

00:49:09.840 --> 00:49:12.040
this onslaught of information.

00:49:12.040 --> 00:49:15.210
So we have to put
computers in good use.

00:49:15.210 --> 00:49:16.860
And I told you
about Moore's Law.

00:49:16.860 --> 00:49:18.600
Here's where Moore's
Law is going,

00:49:18.600 --> 00:49:20.430
and here's the brain is going.

00:49:20.430 --> 00:49:23.220
So when you are able to
harness all the spectrum,

00:49:23.220 --> 00:49:25.950
I think there is
great potential.

00:49:25.950 --> 00:49:29.660
Another way that I see it
is computing as thinking,

00:49:29.660 --> 00:49:31.860
and there is this great
book by Daniel Kahneman

00:49:31.860 --> 00:49:33.570
about fast and slow.

00:49:33.570 --> 00:49:35.340
And I concede there--

00:49:35.340 --> 00:49:38.310
actually I conceded that the
classical to be the slow,

00:49:38.310 --> 00:49:39.990
and I concede
there the empirical

00:49:39.990 --> 00:49:42.220
to be the fast way of thinking.

00:49:42.220 --> 00:49:44.880
And I think its possible
to combine the two,

00:49:44.880 --> 00:49:48.660
and to come up with ideas
similar to the fast and slow

00:49:48.660 --> 00:49:50.370
questions that we
have, provided you

00:49:50.370 --> 00:49:54.150
know when to use what between
these two ways of approaching

00:49:54.150 --> 00:49:57.870
knowledge, and when to
combine the two together.

00:49:57.870 --> 00:49:59.610
Here is a suggestion that comes.

00:49:59.610 --> 00:50:01.690
Here's a suggestion
about our scientists

00:50:01.690 --> 00:50:05.550
that came from an interview or
a visit of Alex Pete at Caltech.

00:50:05.550 --> 00:50:08.670
I get this magazine as
an alumni from there.

00:50:08.670 --> 00:50:11.940
What he says is that forget
about doing hypotheses

00:50:11.940 --> 00:50:12.990
as humans.

00:50:12.990 --> 00:50:15.990
Get as much data as
possible, and without too

00:50:15.990 --> 00:50:18.930
much of a theory became
to analyze the data.

00:50:18.930 --> 00:50:21.330
And the idea is
that there is would

00:50:21.330 --> 00:50:24.750
be some reinforcement learning
in there, and it will say,

00:50:24.750 --> 00:50:27.030
you have a particular
hypothesis.

00:50:27.030 --> 00:50:29.460
And then the machine
will look at the data,

00:50:29.460 --> 00:50:33.720
and then you will find that
your hypothesis may not be true.

00:50:33.720 --> 00:50:36.360
If you want my personal
opinion, I actually

00:50:36.360 --> 00:50:39.900
find this to be a great and
a very interesting idea,

00:50:39.900 --> 00:50:43.650
if it's used at the right
and appropriate way,

00:50:43.650 --> 00:50:46.170
because in a sense, very often
when I advise my students,

00:50:46.170 --> 00:50:49.650
I also do perhaps what their
machine could be doing better

00:50:49.650 --> 00:50:50.990
than me.

00:50:50.990 --> 00:50:54.520
The same time, computers and
suggestions are dangerous.

00:50:54.520 --> 00:50:58.720
And thanks to Ratliff again, I
was exposed to Mark Lombardi.

00:50:58.720 --> 00:51:01.060
And after being exposed
to Mark Lombardia,

00:51:01.060 --> 00:51:04.160
I was exposed by my fellows
here to give the board.

00:51:04.160 --> 00:51:06.800
And actually, I
found the statement,

00:51:06.800 --> 00:51:10.790
by the board that was done
back in 1964, where it's

00:51:10.790 --> 00:51:13.070
talking about there
is all aspects

00:51:13.070 --> 00:51:14.660
of technological development.

00:51:14.660 --> 00:51:16.880
It focuses on communications.

00:51:16.880 --> 00:51:19.460
And he says that
isolation of individuals,

00:51:19.460 --> 00:51:21.380
as well as control
of these individuals

00:51:21.380 --> 00:51:23.750
by means of
suggestions broadcast

00:51:23.750 --> 00:51:24.860
by all sorts of leaders.

00:51:24.860 --> 00:51:27.387
So we have to take
suggestions, but we

00:51:27.387 --> 00:51:28.970
have to think about
these suggestions.

00:51:28.970 --> 00:51:31.940
And we have to create the
knowledge by which we process

00:51:31.940 --> 00:51:35.090
this particular suggestions.

00:51:35.090 --> 00:51:40.190
Which brings us to one or two
before the last about this idea

00:51:40.190 --> 00:51:42.634
of computers, and about AI.

00:51:42.634 --> 00:51:46.280
AI, I consider it to be a
core technology in many fields

00:51:46.280 --> 00:51:47.210
today.

00:51:47.210 --> 00:51:51.890
AI has tremendous power
that goes beyond humans.

00:51:51.890 --> 00:51:54.290
And the same way
computing compliments

00:51:54.290 --> 00:51:57.140
theory and
experiments, I think AI

00:51:57.140 --> 00:52:01.660
can complement the classical way
that we are doing our thinking.

00:52:01.660 --> 00:52:04.280
At the same time, we
have to be able to create

00:52:04.280 --> 00:52:08.150
new ways of interfacing
with machines and computers.

00:52:08.150 --> 00:52:11.720
We have to be able to ask the
computer, why did you do that?

00:52:11.720 --> 00:52:12.860
When do you succeed?

00:52:12.860 --> 00:52:14.056
When do you fail?

00:52:14.056 --> 00:52:15.680
You should be able
to ask the computer,

00:52:15.680 --> 00:52:18.080
can I trust you in
what you gave me?

00:52:18.080 --> 00:52:20.880
Can you explain what
you just produced?

00:52:20.880 --> 00:52:22.970
It was a great effort--
this slide adopted

00:52:22.970 --> 00:52:24.990
from David Gunning, from DARPA.

00:52:24.990 --> 00:52:26.750
It is a great effort
that's happening now,

00:52:26.750 --> 00:52:30.320
about explainable AI to
understand, to trust,

00:52:30.320 --> 00:52:33.590
and to manage AI.

00:52:33.590 --> 00:52:36.740
In closing, I think
I'd like to offer

00:52:36.740 --> 00:52:39.030
a definition for computing.

00:52:39.030 --> 00:52:42.110
Computing is knowledge that
helps discover, predict,

00:52:42.110 --> 00:52:43.820
and explain structure.

00:52:43.820 --> 00:52:46.880
It's something that helps
you to join boundaries.

00:52:46.880 --> 00:52:49.670
To go from fish schooling
to nanoparticles

00:52:49.670 --> 00:52:51.320
for cancer therapy.

00:52:51.320 --> 00:52:53.690
And actually I think
there is a musical way

00:52:53.690 --> 00:52:55.860
to understand this
interdisciplinary.

00:52:55.860 --> 00:52:57.020
[VIOLIN MUSIC]

00:52:57.020 --> 00:52:58.670
And this is this.

00:53:03.090 --> 00:53:06.460
This is from a group
called Lambarena,

00:53:06.460 --> 00:53:10.750
and it's a combinational music
from Bach and from Africa.

00:53:10.750 --> 00:53:13.240
It's about listening
to the violin of Bach,

00:53:13.240 --> 00:53:16.330
it's about listening
to the drums of Africa,

00:53:16.330 --> 00:53:19.330
and finding the way of
putting the two together

00:53:19.330 --> 00:53:23.620
in perfect harmony in order to
be able to create great music.

00:53:23.620 --> 00:53:28.150
This is where I think we have
the opportunity to go today.

00:53:28.150 --> 00:53:30.400
So computing is knowledge.

00:53:30.400 --> 00:53:32.650
I would like to
put the signs up,

00:53:32.650 --> 00:53:35.260
and say the most important
thing is the last one

00:53:35.260 --> 00:53:37.040
it's about education.

00:53:37.040 --> 00:53:39.420
We have to change a lot of
things in the education.

00:53:39.420 --> 00:53:42.310
Of how do we teach
people about computers?

00:53:42.310 --> 00:53:44.530
How do we teach about
software making?

00:53:44.530 --> 00:53:46.990
How do we teach
about data handling?

00:53:46.990 --> 00:53:51.400
So it's a lot about education,
education, education.

00:53:51.400 --> 00:53:54.430
And I think we should take into
account these different modes

00:53:54.430 --> 00:53:59.030
of thinking, and the way we try
to teach people of the future.

00:53:59.030 --> 00:54:01.540
And I like to tell you that
I think with the powers

00:54:01.540 --> 00:54:03.370
that we have today,
I think we've never

00:54:03.370 --> 00:54:05.590
been in a better position.

00:54:05.590 --> 00:54:08.380
Having something that
is 20 millions faster

00:54:08.380 --> 00:54:10.120
than it was 36 years ago.

00:54:10.120 --> 00:54:12.280
If we put it to
good use, I think

00:54:12.280 --> 00:54:15.880
we can address a lot of the
problems that exist today,

00:54:15.880 --> 00:54:19.810
and I think a lot of people are
using computers and computing

00:54:19.810 --> 00:54:22.610
to do just that.

00:54:22.610 --> 00:54:24.370
So I'd like to thank
you, and I would

00:54:24.370 --> 00:54:27.010
like to thank also
myself all my students

00:54:27.010 --> 00:54:29.740
and post stocks that
are listed up there.

00:54:29.740 --> 00:54:32.440
The ones that are
underlined have actually

00:54:32.440 --> 00:54:34.570
had an association with Harvard.

00:54:34.570 --> 00:54:36.890
Three of them are in the room.

00:54:36.890 --> 00:54:39.130
I'll be happy to
take any questions.

00:54:39.130 --> 00:54:42.180
[APPLAUSE]

