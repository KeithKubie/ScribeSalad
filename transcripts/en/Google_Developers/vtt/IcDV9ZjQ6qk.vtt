WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.350
[MUSIC PLAYING]

00:00:06.297 --> 00:00:08.130
LAURENCE MORONEY: Today
I'm in the Big Apple

00:00:08.130 --> 00:00:09.720
meeting with Josh
Gordon from Google

00:00:09.720 --> 00:00:11.360
to talk about machine
learning, where

00:00:11.360 --> 00:00:14.310
we will dig into how it
works, why it's important,

00:00:14.310 --> 00:00:17.437
and where you can
learn all about it.

00:00:17.437 --> 00:00:19.520
Welcome to Coffee with a
Googler in New York City.

00:00:19.520 --> 00:00:21.400
I'm Laurence Moroney,
and I'm here today

00:00:21.400 --> 00:00:23.500
speaking with Joshua Gordon.

00:00:23.500 --> 00:00:25.180
Now, it's something
that a lot of people

00:00:25.180 --> 00:00:27.179
don't really understand
what machine learning is

00:00:27.179 --> 00:00:28.114
in a concrete manner.

00:00:28.114 --> 00:00:29.530
JOSHUA GORDON: So
machine learning

00:00:29.530 --> 00:00:31.500
is all about learning
from examples

00:00:31.500 --> 00:00:32.969
rather than writing
manual rules.

00:00:32.969 --> 00:00:34.010
LAURENCE MORONEY: Got it.

00:00:34.010 --> 00:00:35.510
JOSHUA GORDON: So the
short way of saying

00:00:35.510 --> 00:00:38.230
that is regular programming is
you write a lot of manual rules

00:00:38.230 --> 00:00:39.170
to solve a problem.

00:00:39.170 --> 00:00:41.210
In machine learning,
you let the algorithm

00:00:41.210 --> 00:00:42.269
find those rules for you.

00:00:42.269 --> 00:00:43.310
LAURENCE MORONEY: Got it.

00:00:43.310 --> 00:00:43.970
JOSHUA GORDON: From examples.

00:00:43.970 --> 00:00:45.200
LAURENCE MORONEY:
So pattern matching.

00:00:45.200 --> 00:00:47.520
It might be visual, or it
might be other patterns

00:00:47.520 --> 00:00:48.060
that are hidden in data.

00:00:48.060 --> 00:00:48.740
JOSHUA GORDON: Absolutely.

00:00:48.740 --> 00:00:51.406
And so the input to machine-- so
the beauty of machine learning,

00:00:51.406 --> 00:00:54.170
and the real secret sauce,
is that an algorithm that

00:00:54.170 --> 00:00:57.760
learns patterns from
data can solve thousands

00:00:57.760 --> 00:00:58.850
of different problems.

00:00:58.850 --> 00:01:01.266
And the reason is if I write
a Python program to recognize

00:01:01.266 --> 00:01:03.509
digits, my program is hard
coded to work with digits.

00:01:03.509 --> 00:01:04.550
LAURENCE MORONEY: Got it.

00:01:04.550 --> 00:01:07.050
JOSHUA GORDON: But if I write
an algorithm to learn patterns

00:01:07.050 --> 00:01:09.520
from data, I can use that
for speech recognition, image

00:01:09.520 --> 00:01:11.470
recognition, medicine.

00:01:11.470 --> 00:01:14.010
Basically, anything that
you can start with examples,

00:01:14.010 --> 00:01:17.880
just tell apart A and B, my
same algorithm that I wrote just

00:01:17.880 --> 00:01:20.380
once can tackle
all these problems.

00:01:20.380 --> 00:01:23.050
And that's a really special and
actually fairly profound thing.

00:01:23.050 --> 00:01:24.010
LAURENCE MORONEY: Absolutely.

00:01:24.010 --> 00:01:26.093
Now, one of the things in
your classes that you're

00:01:26.093 --> 00:01:28.500
talking about that you're
starting with language.

00:01:28.500 --> 00:01:30.260
You're starting with
Java and Python,

00:01:30.260 --> 00:01:30.810
I think it was, that you said?

00:01:30.810 --> 00:01:31.590
JOSHUA GORDON: Yes, absolutely.

00:01:31.590 --> 00:01:32.590
LAURENCE MORONEY:
So how's the class

00:01:32.590 --> 00:01:33.700
going to be
structured for people

00:01:33.700 --> 00:01:35.330
who want to be these data
scientists of the future?

00:01:35.330 --> 00:01:35.910
JOSHUA GORDON: Absolutely.

00:01:35.910 --> 00:01:37.950
So first of all, there
are zero prerequisites.

00:01:37.950 --> 00:01:38.380
Well, that's not true.

00:01:38.380 --> 00:01:39.090
There's one prerequisite.

00:01:39.090 --> 00:01:39.780
LAURENCE MORONEY: My favorite.

00:01:39.780 --> 00:01:40.210
Oh, OK.

00:01:40.210 --> 00:01:41.376
Well, what's the one prereq?

00:01:41.376 --> 00:01:44.500
JOSHUA GORDON: Basic programming
ability in Java or Python.

00:01:44.500 --> 00:01:48.230
And by basic, I mean you can run
scripts and you can tweak them.

00:01:48.230 --> 00:01:49.770
That's it.

00:01:49.770 --> 00:01:51.440
A little bit of
high school math.

00:01:51.440 --> 00:01:54.450
And that means like basic
algebra, basic geometry.

00:01:54.450 --> 00:01:56.470
When I say basic geometry,
to be totally honest,

00:01:56.470 --> 00:01:58.447
if you asked me, like,
what sine and cosine,

00:01:58.447 --> 00:01:59.530
I would have to Google it.

00:01:59.530 --> 00:02:01.510
I don't remember, honestly.

00:02:01.510 --> 00:02:04.419
So just basic familiarity,
and that's it.

00:02:04.419 --> 00:02:06.460
And we're going to teach
the class in three ways.

00:02:06.460 --> 00:02:09.030
We're going to teach it
totally from the ground up.

00:02:09.030 --> 00:02:12.206
So one problem I had with some
of the academic classes I took

00:02:12.206 --> 00:02:14.080
is that they'll talk
about a fancy algorithm,

00:02:14.080 --> 00:02:16.149
like neural
networks, but they'll

00:02:16.149 --> 00:02:17.440
talk about it in terms of math.

00:02:17.440 --> 00:02:20.120
And so at the end of the class,
I don't know how to build that.

00:02:20.120 --> 00:02:21.107
I can't really do it.

00:02:21.107 --> 00:02:22.440
We're doing it in a reverse way.

00:02:22.440 --> 00:02:24.440
We're building it step
by step, and we're

00:02:24.440 --> 00:02:27.744
explaining only the math that's
really necessary as we go.

00:02:27.744 --> 00:02:30.160
And instead of equations, we're
going use visual examples.

00:02:30.160 --> 00:02:30.730
LAURENCE MORONEY: Perfect.

00:02:30.730 --> 00:02:32.188
JOSHUA GORDON: So
an equation could

00:02:32.188 --> 00:02:34.060
be like if you talk
about gradient descent,

00:02:34.060 --> 00:02:36.260
gradient descent
basically means finding

00:02:36.260 --> 00:02:37.884
the minimum of a function.

00:02:37.884 --> 00:02:40.550
So if I just say that, like as a
developer, I'm like, all right,

00:02:40.550 --> 00:02:41.160
what does that mean?

00:02:41.160 --> 00:02:42.535
So you can think
of any equation,

00:02:42.535 --> 00:02:45.550
like x cubed plus y squared
plus whatever equals 7.

00:02:45.550 --> 00:02:47.250
There's some value of x and y.

00:02:47.250 --> 00:02:48.660
LAURENCE MORONEY: That's going
to be the bottom of that curve,

00:02:48.660 --> 00:02:48.920
right?

00:02:48.920 --> 00:02:49.270
JOSHUA GORDON: Or not equals 7.

00:02:49.270 --> 00:02:50.020
Equals some value.

00:02:50.020 --> 00:02:50.660
Right.

00:02:50.660 --> 00:02:52.720
Anyway, you can find
the bottom of that curve

00:02:52.720 --> 00:02:54.070
literally by thinking as a bowl.

00:02:54.070 --> 00:02:56.270
You can drop a piece
of fruit in a bowl

00:02:56.270 --> 00:02:57.715
and it will roll to the bottom.

00:02:57.715 --> 00:02:59.340
And gradient descent
just means finding

00:02:59.340 --> 00:03:00.960
where this function is 0.

00:03:00.960 --> 00:03:03.010
And you can actually
describe that really simply

00:03:03.010 --> 00:03:05.280
in only like 10 or
12 lines of Python,

00:03:05.280 --> 00:03:07.585
actually, instead of
five slides of equations.

00:03:07.585 --> 00:03:09.210
LAURENCE MORONEY:
And I think it's also

00:03:09.210 --> 00:03:11.300
important to understand
why you need to find

00:03:11.300 --> 00:03:12.300
the bottom of the curve.

00:03:12.300 --> 00:03:13.340
JOSHUA GORDON: Absolutely.

00:03:13.340 --> 00:03:14.920
LAURENCE MORONEY: And just
focus on that example.

00:03:14.920 --> 00:03:15.330
JOSHUA GORDON: Absolutely.

00:03:15.330 --> 00:03:17.420
So that's difficult
to describe concisely.

00:03:17.420 --> 00:03:19.077
LAURENCE MORONEY: Right.

00:03:19.077 --> 00:03:20.660
JOSHUA GORDON: So
in machine learning,

00:03:20.660 --> 00:03:22.350
let's say you're
writing an algorithm.

00:03:22.350 --> 00:03:26.240
Let's say it's to distinguish
apples from oranges.

00:03:26.240 --> 00:03:29.200
You always want to know, how
accurate is my algorithm?

00:03:29.200 --> 00:03:31.090
Like, I can solve that
problem in one line.

00:03:31.090 --> 00:03:34.020
I can just say,
return math.random.

00:03:34.020 --> 00:03:35.390
So one line, math.random.

00:03:35.390 --> 00:03:37.390
LAURENCE MORONEY: That
would be the perfect one.

00:03:37.390 --> 00:03:39.084
JOSHUA GORDON: My
accuracy is crap.

00:03:39.084 --> 00:03:40.000
LAURENCE MORONEY: 50%.

00:03:40.000 --> 00:03:40.874
JOSHUA GORDON: Right.

00:03:40.874 --> 00:03:42.160
Yeah, it's 50%.

00:03:42.160 --> 00:03:43.190
LAURENCE MORONEY: Between
an apple and an orange.

00:03:43.190 --> 00:03:44.630
JOSHUA GORDON: It's a one liner.

00:03:44.630 --> 00:03:47.186
But really, we want
to get-- another way

00:03:47.186 --> 00:03:48.810
of describing accuracy
is you can think

00:03:48.810 --> 00:03:50.690
about it n terms of error.

00:03:50.690 --> 00:03:53.120
High accuracy means low error.

00:03:53.120 --> 00:03:57.550
And you can have an equation
that describes your error.

00:03:57.550 --> 00:03:59.570
And the minimum of
that equation is

00:03:59.570 --> 00:04:01.741
going to give you
the highest accuracy.

00:04:01.741 --> 00:04:03.740
So you can write your
machine learning algorithm

00:04:03.740 --> 00:04:06.299
to try and minimize the equation
that describes the error.

00:04:06.299 --> 00:04:07.340
LAURENCE MORONEY: Got it.

00:04:07.340 --> 00:04:09.120
JOSHUA GORDON: And we'll
make that super concrete

00:04:09.120 --> 00:04:11.320
in the class, but that's
where minimization comes in

00:04:11.320 --> 00:04:12.670
and that's where gradient
descent comes in.

00:04:12.670 --> 00:04:13.320
LAURENCE MORONEY:
So one of the things

00:04:13.320 --> 00:04:14.736
you're saying in
the class, you're

00:04:14.736 --> 00:04:16.486
teaching just a pure
Java, Python version.

00:04:16.486 --> 00:04:18.111
But there's also a
version where you're

00:04:18.111 --> 00:04:19.490
bringing in
preexisting libraries

00:04:19.490 --> 00:04:20.720
that have come from academia.

00:04:20.720 --> 00:04:20.985
JOSHUA GORDON: Absolutely.

00:04:20.985 --> 00:04:22.260
LAURENCE MORONEY: That will
solve a lot of this for you,

00:04:22.260 --> 00:04:22.700
right?

00:04:22.700 --> 00:04:23.230
JOSHUA GORDON: Absolutely.

00:04:23.230 --> 00:04:24.563
So I want to do a couple things.

00:04:24.563 --> 00:04:27.010
One is I want to
provide the TLDR.

00:04:27.010 --> 00:04:29.720
So honestly, as a
developer, I like to get up

00:04:29.720 --> 00:04:31.090
and running really fast.

00:04:31.090 --> 00:04:34.632
So we're also going to use
open source libraries from just

00:04:34.632 --> 00:04:35.590
different universities.

00:04:35.590 --> 00:04:37.990
There's one in New Zealand
that I really love.

00:04:37.990 --> 00:04:40.510
We're going to you how to build,
basically first, everything

00:04:40.510 --> 00:04:42.384
from the ground up step
by step from scratch.

00:04:42.384 --> 00:04:45.730
And the reason we do that is
because it keeps us honest.

00:04:45.730 --> 00:04:48.250
If you build every
single piece, you

00:04:48.250 --> 00:04:50.560
have some understanding
of every single piece.

00:04:50.560 --> 00:04:52.140
LAURENCE MORONEY: And if
you're relying on somebody else

00:04:52.140 --> 00:04:54.330
having done the work, you don't
fully get to understand it

00:04:54.330 --> 00:04:54.490
yourself.

00:04:54.490 --> 00:04:55.500
JOSHUA GORDON: Exactly.

00:04:55.500 --> 00:04:57.750
Now, another thing is using
the open source libraries,

00:04:57.750 --> 00:05:00.330
honestly, you can solve
probably 80% or 90%

00:05:00.330 --> 00:05:03.390
of the machine learning problems
you would as a data scientist.

00:05:03.390 --> 00:05:04.510
LAURENCE MORONEY: Nice.

00:05:04.510 --> 00:05:06.801
JOSHUA GORDON: Now, when you
get to the really gigantic

00:05:06.801 --> 00:05:09.472
problems, then really it
makes sense to use the cloud.

00:05:09.472 --> 00:05:11.180
So we're also going
to teach how to solve

00:05:11.180 --> 00:05:12.470
problems using Google APIs.

00:05:12.470 --> 00:05:14.530
But that's at the
very end of the class,

00:05:14.530 --> 00:05:16.345
and it's totally optional.

00:05:16.345 --> 00:05:17.520
LAURENCE MORONEY: This
is all on YouTube, right?

00:05:17.520 --> 00:05:18.770
JOSHUA GORDON: All on YouTube.

00:05:18.770 --> 00:05:21.500
There might be some ads on
it, but that's literally it.

00:05:21.500 --> 00:05:22.230
We think it's going
to be awesome.

00:05:22.230 --> 00:05:23.410
LAURENCE MORONEY: Like
source code and stuff

00:05:23.410 --> 00:05:23.930
that you've done?

00:05:23.930 --> 00:05:25.800
JOSHUA GORDON: The source
code will be on GitHub.

00:05:25.800 --> 00:05:26.570
LAURENCE MORONEY:
It's all on GitHub.

00:05:26.570 --> 00:05:26.710
Perfect.

00:05:26.710 --> 00:05:27.070
JOSHUA GORDON: It
will all be on GitHub.

00:05:27.070 --> 00:05:28.020
And the reason I
was hesitating is

00:05:28.020 --> 00:05:29.644
I'm writing all this
as we're speaking,

00:05:29.644 --> 00:05:30.820
so I'm totally exhausted.

00:05:30.820 --> 00:05:32.700
But yes, it's totally,
100% out there.

00:05:32.700 --> 00:05:35.390
LAURENCE MORONEY: Well, you're
still looking energetic to me.

00:05:35.390 --> 00:05:38.386
JOSHUA GORDON: I've had a
lot of coffee with a Googler.

00:05:38.386 --> 00:05:39.400
Good for you.

00:05:39.400 --> 00:05:40.775
LAURENCE MORONEY:
Well, I for one

00:05:40.775 --> 00:05:42.483
am really looking
forward to this course.

00:05:42.483 --> 00:05:45.710
I'm looking forward to learning
what you have to teach.

00:05:45.710 --> 00:05:47.270
I've had the same
kind of struggles

00:05:47.270 --> 00:05:50.096
as you in trying to understand
the math behind this

00:05:50.096 --> 00:05:51.470
and why I'm doing
the math, which

00:05:51.470 --> 00:05:53.360
is why I had those
pointed questions earlier.

00:05:53.360 --> 00:05:54.140
JOSHUA GORDON: Absolutely.

00:05:54.140 --> 00:05:54.830
LAURENCE MORONEY:
So thanks, Josh.

00:05:54.830 --> 00:05:56.030
That was a whole lot of fun.

00:05:56.030 --> 00:05:57.814
And I've learned so
much about machine

00:05:57.814 --> 00:05:59.730
learning just from these
few minutes with you,

00:05:59.730 --> 00:06:01.410
so I'm really looking
forward to your class.

00:06:01.410 --> 00:06:01.970
JOSHUA GORDON: Thanks so much.

00:06:01.970 --> 00:06:03.550
LAURENCE MORONEY: If you've
enjoyed this episode of Coffee

00:06:03.550 --> 00:06:05.420
with a Googler and if you
want to learn machine learning

00:06:05.420 --> 00:06:07.694
for yourself, if you have
any questions for Joshua,

00:06:07.694 --> 00:06:09.110
or if you've any
questions for me,

00:06:09.110 --> 00:06:10.819
please leave them in
the comments below.

00:06:10.819 --> 00:06:12.610
And tune into the Google
Developers channel

00:06:12.610 --> 00:06:14.380
for more great videos,
including episodes

00:06:14.380 --> 00:06:15.530
of Coffee with a Googler.

00:06:15.530 --> 00:06:16.606
Thank you.

00:06:16.606 --> 00:06:17.522
[MUSIC PLAYING]

00:06:17.522 --> 00:06:19.730
JOSHUA GORDON: You really
can learn machine learning,

00:06:19.730 --> 00:06:21.950
and it's faster and
easier than you think.

00:06:21.950 --> 00:06:25.540
We've gone through a ton of
classes, textbooks, and blog

00:06:25.540 --> 00:06:29.120
posts to bring you the clearest
and most concise explanations

00:06:29.120 --> 00:06:30.460
of the hard concepts.

00:06:30.460 --> 00:06:32.025
We really think you're going
to be able to learn it and have

00:06:32.025 --> 00:06:33.290
some fun on the way.

00:06:33.290 --> 00:06:35.410
Click here to get started.

