WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.735
[MUSIC PLAYING]

00:00:02.735 --> 00:00:03.860
JOSH GORDON: Hey, everyone.

00:00:03.860 --> 00:00:04.800
My name's Josh Gordon.

00:00:04.800 --> 00:00:06.770
I'm here with the Developer
Show at the TensorFlow Developer

00:00:06.770 --> 00:00:08.390
Summit, and Daniel
Smilkov, who is

00:00:08.390 --> 00:00:10.499
one of the authors
of TensorFlow.js.

00:00:10.499 --> 00:00:12.540
And it's one of my favorite
launches of the year.

00:00:12.540 --> 00:00:14.910
So Daniel, thank you so
much for joining us today.

00:00:14.910 --> 00:00:15.993
DANIEL SMILKOV: Thank you.

00:00:15.993 --> 00:00:17.660
I'm really glad
you liked the talk.

00:00:17.660 --> 00:00:21.650
So TensorFlow.js is a JavaScript
library for machine learning

00:00:21.650 --> 00:00:24.590
that can run entirely
in the browser.

00:00:24.590 --> 00:00:28.190
And you can both use
your model for reference

00:00:28.190 --> 00:00:30.690
or do training in the browser.

00:00:30.690 --> 00:00:32.990
So you could take an
existing model in Python--

00:00:32.990 --> 00:00:34.700
there are a lot of
models out there

00:00:34.700 --> 00:00:36.140
that people have written--

00:00:36.140 --> 00:00:39.830
and you can use one of our
tools to automatically convert

00:00:39.830 --> 00:00:42.710
that model and import
it in the browser.

00:00:42.710 --> 00:00:48.440
And then it can build creative
applications and visual apps

00:00:48.440 --> 00:00:49.250
around that.

00:00:49.250 --> 00:00:51.680
The way TensorFlow.js
started was

00:00:51.680 --> 00:00:54.050
from a different library
called deeplearn.js

00:00:54.050 --> 00:00:55.740
that we initially released.

00:00:55.740 --> 00:00:58.700
And deeplearn.js had
a lower level API

00:00:58.700 --> 00:01:01.670
that only had lean algebra ops.

00:01:01.670 --> 00:01:05.360
With the launch today,
deeplearn.js joining TensorFlow

00:01:05.360 --> 00:01:10.040
family, we're adding a new
layer of high level ops that

00:01:10.040 --> 00:01:12.740
is aligned with DF
layers and Keras

00:01:12.740 --> 00:01:15.470
so people can just use
high-level building

00:01:15.470 --> 00:01:17.630
blocks and best
practices to build

00:01:17.630 --> 00:01:21.630
RNNs or convolutional
neural networks.

00:01:21.630 --> 00:01:23.630
JOSH GORDON: So for
instance, if I'm a developer

00:01:23.630 --> 00:01:25.430
and I've implemented
a model already

00:01:25.430 --> 00:01:27.920
on my desktop in
Keras or TensorFlow,

00:01:27.920 --> 00:01:29.997
or a combination of both,
then I can export it?

00:01:29.997 --> 00:01:30.830
DANIEL SMILKOV: Yes.

00:01:30.830 --> 00:01:34.370
You can do any TensorFlow
SaveModel or Keras model.

00:01:34.370 --> 00:01:36.580
You can use our Pit package.

00:01:36.580 --> 00:01:38.990
We just released the
TensorFlow.js Pit package

00:01:38.990 --> 00:01:39.920
in Python.

00:01:39.920 --> 00:01:42.410
Run that script
pointing to the artifact

00:01:42.410 --> 00:01:43.790
where your model is saved.

00:01:43.790 --> 00:01:45.950
And it will produce a
different set of files

00:01:45.950 --> 00:01:47.921
that you can then
use in the browser.

00:01:47.921 --> 00:01:50.420
JOSH GORDON: And one thing I
really like about TensorFlow.js

00:01:50.420 --> 00:01:52.640
is you have an
outstanding examples

00:01:52.640 --> 00:01:55.970
directory that demonstrates how
to accomplish things like this.

00:01:55.970 --> 00:01:58.370
DANIEL SMILKOV: That's one
very cool part about the web,

00:01:58.370 --> 00:02:01.910
is that people can easily
fork these examples,

00:02:01.910 --> 00:02:05.390
launch them in the browser,
modify them, upload them

00:02:05.390 --> 00:02:08.852
in their own servers, and
share it with everyone.

00:02:08.852 --> 00:02:10.310
JOSH GORDON: OK,
so now, let's talk

00:02:10.310 --> 00:02:12.600
about some of your
great live demos.

00:02:12.600 --> 00:02:16.160
There's the Teachable Machine,
the Emoji Scavenger Hunt,

00:02:16.160 --> 00:02:17.330
and Pac-Man.

00:02:17.330 --> 00:02:19.250
DANIEL SMILKOV: All
very cool demos.

00:02:19.250 --> 00:02:22.040
Teachable Machine is one
of our earliest demos.

00:02:22.040 --> 00:02:26.640
It was a collaboration with
Google Creative Lab folks.

00:02:26.640 --> 00:02:28.910
It runs a neural
network in the browser.

00:02:28.910 --> 00:02:31.670
And then you can train
it with your webcam

00:02:31.670 --> 00:02:34.700
and associate it with
one of the four actions.

00:02:34.700 --> 00:02:35.952
And people love it.

00:02:35.952 --> 00:02:37.910
JOSH GORDON: So I actually
like that so much, I

00:02:37.910 --> 00:02:39.230
taught a course last
semester, and had

00:02:39.230 --> 00:02:40.610
all my students
build a Teachable

00:02:40.610 --> 00:02:42.740
Machine as their final project.

00:02:42.740 --> 00:02:43.920
They loved it, too.

00:02:43.920 --> 00:02:44.870
DANIEL SMILKOV: I'm
very glad to hear that.

00:02:44.870 --> 00:02:45.619
JOSH GORDON: Yeah.

00:02:45.619 --> 00:02:48.149
OK, so the Emoji Scavenger
Hunt and Pac-Man.

00:02:48.149 --> 00:02:49.940
DANIEL SMILKOV: Yes,
so the Emoji Scavenger

00:02:49.940 --> 00:02:53.360
Hunt is another game that our
friends at Google Brand Studio

00:02:53.360 --> 00:02:58.230
built. This one actually
uses our latest tools.

00:02:58.230 --> 00:03:02.930
So it uses the TensorFlow
[? Reports ?] tutorial,

00:03:02.930 --> 00:03:05.380
takes a pre-trained mobile net.

00:03:05.380 --> 00:03:10.400
Then they are retraining it to
identify 400 different objects

00:03:10.400 --> 00:03:12.170
that you can have in your home.

00:03:12.170 --> 00:03:14.680
Then they're using our
Automatic Converter tool

00:03:14.680 --> 00:03:16.040
to port it in the browser.

00:03:16.040 --> 00:03:17.810
And they turn it into a game.

00:03:17.810 --> 00:03:20.450
The goal of the game is you
can run it on the phone,

00:03:20.450 --> 00:03:21.890
uses the webcam.

00:03:21.890 --> 00:03:23.960
And you point it to an object.

00:03:23.960 --> 00:03:25.490
It gives you an emoji.

00:03:25.490 --> 00:03:27.800
And you have to find the
real object in real life,

00:03:27.800 --> 00:03:30.620
point it, and make the
model predict correctly

00:03:30.620 --> 00:03:31.787
before the time runs out.

00:03:31.787 --> 00:03:33.620
And I just want to point
out that everything

00:03:33.620 --> 00:03:35.630
runs in the browser.

00:03:35.630 --> 00:03:37.959
No data is being
sent to any server.

00:03:37.959 --> 00:03:40.250
JOSH GORDON: So this is
valuable for privacy-preserving

00:03:40.250 --> 00:03:41.150
applications, as well.

00:03:41.150 --> 00:03:41.670
DANIEL SMILKOV: Yes.

00:03:41.670 --> 00:03:42.650
JOSH GORDON: But let me
make a quick comment.

00:03:42.650 --> 00:03:44.540
So when I think
of web browser, I

00:03:44.540 --> 00:03:46.197
think of opening
Chrome on my laptop.

00:03:46.197 --> 00:03:48.530
But I just realized, from
what you're saying, of course,

00:03:48.530 --> 00:03:50.480
I can develop a
TensorFlow.js app

00:03:50.480 --> 00:03:52.885
and also open it from
a mobile browser.

00:03:52.885 --> 00:03:55.460
So you have a last awesome
demo, which is Pac-Man.

00:03:55.460 --> 00:03:56.690
So tell me about Pac-Man.

00:03:56.690 --> 00:03:59.840
DANIEL SMILKOV: So Pac-Man
is a demo that kind of

00:03:59.840 --> 00:04:05.930
joins the '80s game and the
machine learning technologies

00:04:05.930 --> 00:04:08.120
from 2018 together.

00:04:08.120 --> 00:04:11.690
And it shows you how you
can take a pre-trained model

00:04:11.690 --> 00:04:16.230
and retrain it with your own
private data in the browser.

00:04:16.230 --> 00:04:20.990
So what we do is, I use my face
to turn it into a controller

00:04:20.990 --> 00:04:24.710
and teach a neural network to
recognize my different poses as

00:04:24.710 --> 00:04:26.160
left, right, up, or down.

00:04:26.160 --> 00:04:27.260
And then I play Pac-Man.

00:04:27.260 --> 00:04:29.200
JOSH GORDON: So you can control
Pac-Man by moving your face.

00:04:29.200 --> 00:04:29.460
DANIEL SMILKOV: Yeah.

00:04:29.460 --> 00:04:29.720
JOSH GORDON: That's really cool.

00:04:29.720 --> 00:04:32.011
DANIEL SMILKOV: So even though
it looks like, you know,

00:04:32.011 --> 00:04:35.570
just a game, it actually
has huge implications

00:04:35.570 --> 00:04:37.040
for accessibility.

00:04:37.040 --> 00:04:39.560
Think of someone building
a Chrome extension

00:04:39.560 --> 00:04:41.240
that can then
recognize these actions

00:04:41.240 --> 00:04:43.164
and allow people
to browse the web.

00:04:43.164 --> 00:04:44.580
JOSH GORDON: That's
a great point,

00:04:44.580 --> 00:04:46.740
so for paralyzed patients
and stuff like that.

00:04:46.740 --> 00:04:47.960
OK, so this is awesome.

00:04:47.960 --> 00:04:50.180
To wrap it up, where is the
best place for developers

00:04:50.180 --> 00:04:51.055
to go to get started?

00:04:51.055 --> 00:04:52.880
DANIEL SMILKOV: Go
to js.tensorflow.org.

00:04:52.880 --> 00:04:55.760
We have a beautiful website
with a lot of examples.

00:04:55.760 --> 00:04:59.630
Each example you can
easily fork, modify, share.

00:04:59.630 --> 00:05:01.250
And also, we have tutorials.

00:05:01.250 --> 00:05:02.266
Feel free to dive in.

00:05:02.266 --> 00:05:03.140
JOSH GORDON: Awesome.

00:05:03.140 --> 00:05:04.494
So Daniel, thanks so much.

00:05:04.494 --> 00:05:06.660
For the Developer Show at
the TensorFlow Dev Summit,

00:05:06.660 --> 00:05:07.340
I'm Josh Gordon.

00:05:07.340 --> 00:05:09.850
Thanks again, and I'll
see you next time.

