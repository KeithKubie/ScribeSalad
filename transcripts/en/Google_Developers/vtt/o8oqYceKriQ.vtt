WEBVTT
Kind: captions
Language: en

00:00:03.967 --> 00:00:06.300
MODERATOR: We've got some
burning questions right there.

00:00:06.300 --> 00:00:07.888
Let's do it.

00:00:07.888 --> 00:00:09.340
AUDIENCE: Hello.

00:00:09.340 --> 00:00:12.130
So next Tuesday
there is going to be

00:00:12.130 --> 00:00:15.690
a hearing between the Justice
Department and the EFF on

00:00:15.690 --> 00:00:19.310
whether or not
courts can request

00:00:19.310 --> 00:00:22.430
user data from companies.

00:00:22.430 --> 00:00:26.170
That in response has
created a lot of talk

00:00:26.170 --> 00:00:28.310
about client side
crypto, and there's

00:00:28.310 --> 00:00:35.080
a working group in the
HTML5 about web crypto API.

00:00:35.080 --> 00:00:38.850
I was wondering if you guys
had any sort of opinions

00:00:38.850 --> 00:00:41.040
on web crypto API
and whether or not

00:00:41.040 --> 00:00:44.520
that was a viable response
to that kind of attack.

00:00:44.520 --> 00:00:46.885
I know that ProtonMail
just released their beta

00:00:46.885 --> 00:00:50.510
a week and a half ago.

00:00:50.510 --> 00:00:54.440
And I was wondering, since
that is so slow currently

00:00:54.440 --> 00:00:57.980
because it's JavaScript
crypto, whether or not

00:00:57.980 --> 00:01:00.270
web crypto API would
contribute to that at all?

00:01:07.900 --> 00:01:11.230
EDUARDO VELA NAVA: So I think
web crypto is super useful.

00:01:11.230 --> 00:01:13.740
Generally speaking,
it has problems

00:01:13.740 --> 00:01:16.120
in the sense that it's
a native crypto library,

00:01:16.120 --> 00:01:17.790
so it's likely that
people that want

00:01:17.790 --> 00:01:19.660
to implement their
own crypto are

00:01:19.660 --> 00:01:21.500
going to fail at doing that.

00:01:21.500 --> 00:01:24.140
But if they use of crypto
system that is well known,

00:01:24.140 --> 00:01:26.256
it is most likely that
it's going to be safe.

00:01:26.256 --> 00:01:27.880
I'm not sure if I
answered the question

00:01:27.880 --> 00:01:31.790
because it seemed like it was
whether web crypto was cool.

00:01:31.790 --> 00:01:32.290
I like it.

00:01:39.634 --> 00:01:40.550
AUDIENCE: My question.

00:01:40.550 --> 00:01:41.508
My name is [INAUDIBLE].

00:01:41.508 --> 00:01:42.790
My question is more general.

00:01:42.790 --> 00:01:46.090
It's related to the whole
philosophy we learned today

00:01:46.090 --> 00:01:50.210
about how important security
is, and to submit security

00:01:50.210 --> 00:01:53.180
vulnerabilities,
and report the bugs.

00:01:53.180 --> 00:01:55.150
I'm wondering, Google
has this program

00:01:55.150 --> 00:01:57.950
where they offer rewards.

00:01:57.950 --> 00:02:03.110
What about if in the application
there exists a vulnerability

00:02:03.110 --> 00:02:05.665
and it's happening
from Google, possibly

00:02:05.665 --> 00:02:08.210
it's happening for other
large corporations.

00:02:08.210 --> 00:02:11.690
Maybe some of those
who don't have a bounty

00:02:11.690 --> 00:02:16.650
program, how can we, as
good citizens I guess,

00:02:16.650 --> 00:02:21.732
report something and
not go to jail for that.

00:02:21.732 --> 00:02:25.297
[LAUGHTER]

00:02:25.297 --> 00:02:26.880
TIM WILLIS: So to
answer your question

00:02:26.880 --> 00:02:30.640
about can you submit
bugs to other programs.

00:02:30.640 --> 00:02:31.600
Yes you can.

00:02:31.600 --> 00:02:33.200
There are actually
programs which

00:02:33.200 --> 00:02:35.790
are set up, like the
Internet Bug Bounty, which

00:02:35.790 --> 00:02:39.740
is a program which allows you
to submit bugs in products that

00:02:39.740 --> 00:02:42.220
might not have a
vulnerability reward program.

00:02:42.220 --> 00:02:44.990
And they will actually sponsor
some of those payments as well.

00:02:44.990 --> 00:02:47.120
So it's possible for
you to submit a bug

00:02:47.120 --> 00:02:49.850
through a program like
that, and then you'll

00:02:49.850 --> 00:02:53.190
also receive a payment for that.

00:02:53.190 --> 00:02:56.261
That being said though,
with the wider issue,

00:02:56.261 --> 00:02:58.010
I think that with the
vulnerability reward

00:02:58.010 --> 00:02:59.904
program that we run,
and the different types

00:02:59.904 --> 00:03:01.570
of vulnerability
reward programs we run,

00:03:01.570 --> 00:03:05.050
you'll probably see that we
will continue to invest in that.

00:03:05.050 --> 00:03:08.800
And we'll probably end up
looking at some more client

00:03:08.800 --> 00:03:11.900
side applications
in the near future.

00:03:11.900 --> 00:03:14.550
AUDIENCE: So if some company
doesn't have a reward system,

00:03:14.550 --> 00:03:16.504
you can-- some other website?

00:03:16.504 --> 00:03:17.920
Where do you go
for that you said?

00:03:17.920 --> 00:03:19.378
TIM WILLIS: So one
example of that.

00:03:19.378 --> 00:03:23.150
There are companies which will
conglomerate bug reporting

00:03:23.150 --> 00:03:25.860
for you and take care
of the relationship

00:03:25.860 --> 00:03:28.614
between the company
and the disclosure

00:03:28.614 --> 00:03:30.030
and keep you at
an arm's distance.

00:03:30.030 --> 00:03:32.660
One example of that is
the Internet Bug Bounty.

00:03:32.660 --> 00:03:34.244
There are other examples.

00:03:34.244 --> 00:03:36.410
I think Bug Crowd is another
one that comes to mind.

00:03:36.410 --> 00:03:39.380
But you can always--
usually security at

00:03:39.380 --> 00:03:42.470
for the big companies is
a good place to start.

00:03:42.470 --> 00:03:45.979
And if you present yourself
in the right light,

00:03:45.979 --> 00:03:48.270
I can't imagine you're going
to run into many problems.

00:03:48.270 --> 00:03:49.960
AUDIENCE: And can you
just blog about it

00:03:49.960 --> 00:03:52.100
if you find something
on your own?

00:03:52.100 --> 00:03:54.300
TIM WILLIS: Well that's
a personal decision.

00:03:54.300 --> 00:03:57.527
There's the debate between
full disclosure, coordinated

00:03:57.527 --> 00:03:59.360
disclosure, responsible
disclosure, whatever

00:03:59.360 --> 00:04:00.810
you want to call it.

00:04:00.810 --> 00:04:04.180
It's really up to you how you
want to handle that situation.

00:04:04.180 --> 00:04:05.960
That being said,
there usually are

00:04:05.960 --> 00:04:08.630
avenues that companies
will be willing to accept

00:04:08.630 --> 00:04:10.800
those type of bugs.

00:04:10.800 --> 00:04:12.564
AUDIENCE: Thanks.

00:04:12.564 --> 00:04:14.980
MODERATOR: Yeah, on company
just got funded for $9 million

00:04:14.980 --> 00:04:18.790
to help solve that
problem at TechCrunch.

00:04:18.790 --> 00:04:22.070
What do you see as fundamental
computing security problems?

00:04:22.070 --> 00:04:24.410
We have the whole arms
race back and forth.

00:04:24.410 --> 00:04:29.280
What are some things that
are fundamentally technology,

00:04:29.280 --> 00:04:33.840
structure, approaches,
even language syntax,

00:04:33.840 --> 00:04:37.270
or architecture in clouds, there
are problems that fundamentally

00:04:37.270 --> 00:04:39.380
are bigger than what
one company can fix

00:04:39.380 --> 00:04:40.890
that people should
be looking at?

00:04:40.890 --> 00:04:42.520
Like OpenStack's
doing and other stuff.

00:04:49.110 --> 00:04:51.420
TIM WILLIS: They were just
a lot of scary words to me.

00:04:51.420 --> 00:04:53.620
[LAUGHTER]

00:04:53.620 --> 00:04:56.290
To be honest, I think,
at the moment at Google,

00:04:56.290 --> 00:04:58.500
we're focusing on the
products that we build

00:04:58.500 --> 00:05:01.260
and how we can do that, unless
someone else has comments

00:05:01.260 --> 00:05:03.690
specifically on the wider
issue, I'll hand it to Joel.

00:05:07.650 --> 00:05:10.460
JOEL WEINBERGER: I think
fundamentally we'll

00:05:10.460 --> 00:05:12.660
always have bad
guys who are trying

00:05:12.660 --> 00:05:14.670
to break whatever we build.

00:05:14.670 --> 00:05:17.290
So in some sense, it'll
always be an arms race.

00:05:17.290 --> 00:05:18.830
But that doesn't
mean we're losing.

00:05:18.830 --> 00:05:21.184
And in fact, from
my perspective,

00:05:21.184 --> 00:05:23.350
we've done a pretty good
job over the last 10 years.

00:05:23.350 --> 00:05:27.480
If you compare web security and
tools available to us from 10,

00:05:27.480 --> 00:05:31.030
15 years ago, it's just
a world of difference.

00:05:31.030 --> 00:05:34.090
Even if you compare web
application security more

00:05:34.090 --> 00:05:38.460
generally to traditional
application security

00:05:38.460 --> 00:05:42.000
and OS level security, we've
done some pretty amazing things

00:05:42.000 --> 00:05:44.270
with the fact that
one website can't

00:05:44.270 --> 00:05:45.380
mess with another website.

00:05:45.380 --> 00:05:48.440
That's a pretty big
fundamental win.

00:05:48.440 --> 00:05:50.630
So I do think there will
always be an arms race.

00:05:50.630 --> 00:05:52.916
I'm not sure we can
really avoid that.

00:05:52.916 --> 00:05:54.790
Maybe there's somebody
who's got a great idea

00:05:54.790 --> 00:05:55.706
about how to fix that.

00:05:55.706 --> 00:05:58.240
But I think there are
leaps and bounds we take.

00:05:58.240 --> 00:06:00.640
And I actually think we're
doing a pretty good job in web

00:06:00.640 --> 00:06:02.460
security.

00:06:02.460 --> 00:06:03.835
MODERATOR: Why is
it that when we

00:06:03.835 --> 00:06:07.490
used to have secure computing in
projects and other frameworks,

00:06:07.490 --> 00:06:10.740
the actual break ins
we have now cascade

00:06:10.740 --> 00:06:12.090
because it's so [INAUDIBLE].

00:06:12.090 --> 00:06:14.190
We don't have tools to
keep that from happening

00:06:14.190 --> 00:06:15.670
with layered security.

00:06:15.670 --> 00:06:19.640
We have hits that are now 200
million users, or open all off,

00:06:19.640 --> 00:06:21.250
or SSL.

00:06:21.250 --> 00:06:24.450
These are things where the tools
we all use now affect everybody

00:06:24.450 --> 00:06:27.079
in one hit, like
Heartbleed hits everybody.

00:06:27.079 --> 00:06:28.745
That didn't used to
happen as much, even

00:06:28.745 --> 00:06:31.200
though the tools were
easy to build with.

00:06:31.200 --> 00:06:32.707
JOEL WEINBERGER:
Is that-- I'm not--

00:06:32.707 --> 00:06:34.170
AUDIENCE: Is that
a statement of a--

00:06:34.170 --> 00:06:35.320
AUDIENCE: That's a statement
and question though,

00:06:35.320 --> 00:06:36.820
because actually
it's getting harder

00:06:36.820 --> 00:06:39.832
secure larger surface areas.

00:06:39.832 --> 00:06:40.790
JOEL WEINBERGER: Maybe.

00:06:40.790 --> 00:06:43.990
I mean a Windows bug was
always pretty darn bad

00:06:43.990 --> 00:06:46.930
when it affected
95% of everybody.

00:06:46.930 --> 00:06:49.710
Worms in the early
2000s instantaneously

00:06:49.710 --> 00:06:51.289
affected most of the world.

00:06:51.289 --> 00:06:53.330
So I'm not actually sure
that's a true statement.

00:06:53.330 --> 00:06:54.760
There are certainly problems.

00:06:54.760 --> 00:06:56.769
Those are all valid issues.

00:06:56.769 --> 00:06:58.310
And I think it's an
open question how

00:06:58.310 --> 00:06:59.476
we're going to address that.

00:06:59.476 --> 00:07:00.874
I think it's a great question.

00:07:00.874 --> 00:07:02.790
EDUARDO VELA NAVA: So
just to mention on that.

00:07:02.790 --> 00:07:04.990
One thing that might
be worth mentioning

00:07:04.990 --> 00:07:09.030
is that the way the
DNS works in general

00:07:09.030 --> 00:07:11.640
is that they try to
diversify as much

00:07:11.640 --> 00:07:15.306
as possible implementations on
operating systems and so on.

00:07:15.306 --> 00:07:17.180
So if there is a
vulnerability in one system,

00:07:17.180 --> 00:07:19.650
it doesn't bring down
the whole internet,

00:07:19.650 --> 00:07:23.700
and maybe keeping up on
that idea might be worth,

00:07:23.700 --> 00:07:27.624
but they have other problems
that aren't related anyway.

00:07:30.530 --> 00:07:32.915
AUDIENCE: OK, so this is
mainly based toward Eduardo

00:07:32.915 --> 00:07:35.035
and you're talk.

00:07:38.650 --> 00:07:41.270
My question to you or how do
you think this should be solved

00:07:41.270 --> 00:07:44.670
is when you put the
responsibility to security

00:07:44.670 --> 00:07:48.180
to somebody else-- in your case
it's you, or you at Google,

00:07:48.180 --> 00:07:51.390
or whoever of some company,
or some other developer

00:07:51.390 --> 00:07:53.320
submitting patches.

00:07:53.320 --> 00:07:57.260
If you put it all out
of your own control,

00:07:57.260 --> 00:08:00.460
what stops those other
patches or a bad patch

00:08:00.460 --> 00:08:02.460
to be put into a large system?

00:08:02.460 --> 00:08:06.439
For example, a very recent
famous example is, let's say,

00:08:06.439 --> 00:08:07.230
the Heartbleed bug.

00:08:07.230 --> 00:08:10.830
Everybody's relying on
this SSL or everybody's

00:08:10.830 --> 00:08:13.960
relying on one specific source.

00:08:13.960 --> 00:08:18.540
What securities or safeguards
do you have against, let's say,

00:08:18.540 --> 00:08:20.455
a company who doesn't--
oh let's patch it.

00:08:20.455 --> 00:08:22.380
It looks like it
works, and it fixes,

00:08:22.380 --> 00:08:25.110
but it's actually
and evil patch.

00:08:25.110 --> 00:08:26.960
And the company
mistakenly accepts that

00:08:26.960 --> 00:08:28.790
and now puts
everybody in danger.

00:08:28.790 --> 00:08:31.940
What safeguards do
you foresee that will

00:08:31.940 --> 00:08:33.206
prevent those kind of things?

00:08:33.206 --> 00:08:35.539
EDUARDO VELA NAVA: So it's
pretty similar to what I just

00:08:35.539 --> 00:08:38.150
mentioned right now, but one
of the reasons that we're not

00:08:38.150 --> 00:08:40.150
just sponsoring one
framework, for example,

00:08:40.150 --> 00:08:43.140
is because we want to
make sure that this

00:08:43.140 --> 00:08:44.560
is-- that people have options.

00:08:44.560 --> 00:08:47.370
So for example, in one case, if
there were several framers that

00:08:47.370 --> 00:08:51.260
have roughly the same
qualities or values

00:08:51.260 --> 00:08:53.360
and people can choose
and compete within them,

00:08:53.360 --> 00:08:56.030
like you can choose
which one we want to use,

00:08:56.030 --> 00:08:59.622
then you're most likely--
if there are two,

00:08:59.622 --> 00:09:01.330
then half of the
internet will be broken.

00:09:01.330 --> 00:09:03.746
If there are 20, then 1/20 of
the internet will be broken.

00:09:03.746 --> 00:09:05.860
And that's a problem
with all support.

00:09:05.860 --> 00:09:07.550
Like if there is a
common component,

00:09:07.550 --> 00:09:10.721
if anyone trusts it and it's
going to affect lot of people.

00:09:10.721 --> 00:09:13.220
One other thing that I mentioned
at the end, which might not

00:09:13.220 --> 00:09:15.180
affect-- might not makes
sense for open SSL,

00:09:15.180 --> 00:09:17.096
for example, as you
mentioned with Heartbleed,

00:09:17.096 --> 00:09:19.470
but it makes sense for
other common components,

00:09:19.470 --> 00:09:22.800
like FFMPG or things like
that, which is sandboxing.

00:09:22.800 --> 00:09:26.120
So if you sandbox
things that have

00:09:26.120 --> 00:09:28.830
very specific set of
constraints that only need

00:09:28.830 --> 00:09:30.850
to do a specific
subset of [INAUDIBLE],

00:09:30.850 --> 00:09:32.450
then we're now
witnessing that system,

00:09:32.450 --> 00:09:34.590
I don't think is going to
have as big of an impact

00:09:34.590 --> 00:09:36.920
as it would have otherwise.

00:09:36.920 --> 00:09:40.500
AUDIENCE: And then just the
one point to query on that.

00:09:40.500 --> 00:09:43.050
The sandbox itself,
would that be

00:09:43.050 --> 00:09:46.070
in any way vulnerable to, say,
somebody bugging the sandbox

00:09:46.070 --> 00:09:48.290
or making it not sandbox.

00:09:48.290 --> 00:09:49.860
Is that possible?

00:09:49.860 --> 00:09:53.230
EDUARDO VELA NAVA: That will
be a feature of the operating

00:09:53.230 --> 00:09:54.490
system or of the platform.

00:09:54.490 --> 00:09:59.070
So for example, in BSD you
have just [INAUDIBLE] jails.

00:09:59.070 --> 00:10:02.240
Or like in Linux, you
will have the seccomp

00:10:02.240 --> 00:10:04.984
or whatever sandbox.

00:10:04.984 --> 00:10:05.900
Windows has their own.

00:10:05.900 --> 00:10:07.040
Mac OS has their own.

00:10:07.040 --> 00:10:09.920
In the web frame where
we have appropriately

00:10:09.920 --> 00:10:12.350
named iframe
sandboxes and CSP that

00:10:12.350 --> 00:10:14.440
can be somewhat useful
sandboxing as well.

00:10:14.440 --> 00:10:16.740
So it's a feature
of the framework.

00:10:16.740 --> 00:10:19.666
The [INAUDIBLE] is broken, then
the internet is broken as well.

00:10:19.666 --> 00:10:21.540
But then you have several
browsers hopefully.

00:10:25.350 --> 00:10:27.950
As long as there is no
complete diversification,

00:10:27.950 --> 00:10:30.152
there will always be some
sort of one thing that

00:10:30.152 --> 00:10:31.110
can break the internet.

00:10:31.110 --> 00:10:32.680
Open is always a great example.

00:10:32.680 --> 00:10:34.900
But there is also
NSS, for example.

00:10:34.900 --> 00:10:37.640
And many people didn't
break because they

00:10:37.640 --> 00:10:39.720
didn't used OpenSSL
they used NSS.

00:10:39.720 --> 00:10:41.881
And that doesn't mean that
NSS is not vulnerable.

00:10:41.881 --> 00:10:43.880
Maybe NSS is vulnerable
to even something worse,

00:10:43.880 --> 00:10:48.050
but then people on OpenSSL
will not be vulnerable.

00:10:48.050 --> 00:10:50.386
That's a problem with
common components.

00:10:50.386 --> 00:10:51.760
PARISA TABRIZ: I
just want to say

00:10:51.760 --> 00:10:54.860
one thing is one of the
fundamental security design

00:10:54.860 --> 00:10:56.610
principles is defense
in depth, right?

00:10:56.610 --> 00:11:00.870
So at any point, if you're
a software is dependent--

00:11:00.870 --> 00:11:03.290
the total security is
dependent on one bug, then

00:11:03.290 --> 00:11:05.206
that is something
to worry about.

00:11:05.206 --> 00:11:07.330
And that's why you want
multiple layers of defense.

00:11:07.330 --> 00:11:09.480
As developers, we
rely on abstraction.

00:11:09.480 --> 00:11:12.790
You will not be able
to understand firsthand

00:11:12.790 --> 00:11:15.010
every single layer of
the software you're

00:11:15.010 --> 00:11:17.570
trying to build, otherwise you
just can't get anything done.

00:11:17.570 --> 00:11:19.520
So you're right.

00:11:19.520 --> 00:11:21.930
When you are abstracting, are
dependent on somebody else

00:11:21.930 --> 00:11:26.420
to actually supply code and
behave as you expect it to.

00:11:26.420 --> 00:11:29.260
There is some risk in that
there may be a but there.

00:11:29.260 --> 00:11:31.630
If not today, then
in the future,

00:11:31.630 --> 00:11:34.160
which is why it's so important
to architecture software

00:11:34.160 --> 00:11:40.277
such that you you're
just reliant on one bug.

00:11:40.277 --> 00:11:41.360
AUDIENCE: Thank very much.

00:11:45.080 --> 00:11:46.700
AUDIENCE: Hi, thanks
for doing this.

00:11:46.700 --> 00:11:48.130
Question about testing.

00:11:48.130 --> 00:11:50.390
Are there any
automated ways to test

00:11:50.390 --> 00:11:52.520
for something that's
very common like CSRF?

00:11:52.520 --> 00:11:56.050
If 75% of what you're
seeing is CSRF out there,

00:11:56.050 --> 00:11:58.300
are there any frameworks
or third party services

00:11:58.300 --> 00:11:59.010
that you can use?

00:11:59.010 --> 00:12:00.720
And if not, are
there any challenges

00:12:00.720 --> 00:12:01.990
to developing such a service?

00:12:06.020 --> 00:12:09.235
EDUARDO VELA NAVA: So
for CSRF in a specific,

00:12:09.235 --> 00:12:12.050
I think it mostly depends--
if you're using-- well

00:12:12.050 --> 00:12:15.400
this is HTML5, so
in this case, you

00:12:15.400 --> 00:12:18.660
might use the traditional
model of just having a form

00:12:18.660 --> 00:12:20.994
and then the form submitting
things automatically,

00:12:20.994 --> 00:12:23.410
which means that traditional
scanners-- there are scanners

00:12:23.410 --> 00:12:25.890
that find CSRF, but
they might not find them

00:12:25.890 --> 00:12:31.280
on very client side
rich applications.

00:12:31.280 --> 00:12:33.272
I think, at the end of
the day in this case,

00:12:33.272 --> 00:12:35.730
you need to either depend on
the framework to do it safely,

00:12:35.730 --> 00:12:38.290
or if you want to
really do it by testing,

00:12:38.290 --> 00:12:42.090
then you need to either
do something specifically

00:12:42.090 --> 00:12:44.670
to your framework or use a tool.

00:12:44.670 --> 00:12:46.160
There is one tool
called Ratproxy,

00:12:46.160 --> 00:12:49.190
for example, that one of
my colleagues released,

00:12:49.190 --> 00:12:53.050
which analyzes
requests passively.

00:12:53.050 --> 00:12:56.020
So you create as a proxy,
and then it makes requests,

00:12:56.020 --> 00:12:57.890
and then it analyzes requests.

00:12:57.890 --> 00:13:00.150
And then in some cases,
it repeats requests

00:13:00.150 --> 00:13:02.980
that it thinks are state
changing without the CSRF token

00:13:02.980 --> 00:13:04.150
in my find box.

00:13:04.150 --> 00:13:08.250
But it's not fool
proof, of course.

00:13:08.250 --> 00:13:10.760
With testing you mostly are
trying to find these bugs,

00:13:10.760 --> 00:13:14.522
but you're not sure that
they're not going to happen.

00:13:14.522 --> 00:13:15.105
That may help.

00:13:18.335 --> 00:13:18.835
Anyone else?

00:13:22.409 --> 00:13:22.950
AUDIENCE: Hi.

00:13:22.950 --> 00:13:26.650
Thank you for this
nice presentation.

00:13:26.650 --> 00:13:33.110
My question is if HTTP is
very vulnerable protocol,

00:13:33.110 --> 00:13:36.410
why not get rid of
it, or disallow it?

00:13:38.920 --> 00:13:40.867
JOEL WEINBERGER: Oh,
you're my best friend.

00:13:40.867 --> 00:13:41.950
Oh, you're my best friend.

00:13:41.950 --> 00:13:43.270
I would love to do that.

00:13:43.270 --> 00:13:49.880
No, I mean the answer
is, as a security guy,

00:13:49.880 --> 00:13:52.560
my goal is not to
break the world, right?

00:13:52.560 --> 00:13:54.430
As much as I'd
like to sometimes,

00:13:54.430 --> 00:13:58.210
it's really important that
the world keep working.

00:13:58.210 --> 00:14:02.410
And while it would be great
to live in a world in which we

00:14:02.410 --> 00:14:08.330
only have HTTPS, that's a
world we're working towards.

00:14:08.330 --> 00:14:10.870
There are things
we do to encourage

00:14:10.870 --> 00:14:12.880
people to go to HTTPS.

00:14:12.880 --> 00:14:15.414
We have these green locks,
which look really nice

00:14:15.414 --> 00:14:17.080
and are really pretty,
and they actually

00:14:17.080 --> 00:14:18.329
make your website look better.

00:14:18.329 --> 00:14:19.680
And that's great.

00:14:19.680 --> 00:14:22.170
And there's a reason we do that.

00:14:22.170 --> 00:14:24.790
And we want you users to
know that they're secure.

00:14:24.790 --> 00:14:28.880
And when they're not over HTTPS,
we want them to not have that

00:14:28.880 --> 00:14:31.950
feeling of security,
because they shouldn't.

00:14:31.950 --> 00:14:36.390
But if any of the
browsers, for example,

00:14:36.390 --> 00:14:40.320
were to just take
away HTTP, nobody

00:14:40.320 --> 00:14:42.790
would use that web browser, or
at least a very small number

00:14:42.790 --> 00:14:45.170
would.

00:14:45.170 --> 00:14:47.381
Well, no because the
users would know.

00:14:47.381 --> 00:14:49.130
And users would know
because they wouldn't

00:14:49.130 --> 00:14:52.950
be able to get to The New
York Times, for example.

00:14:52.950 --> 00:14:54.860
Just as a random example.

00:14:54.860 --> 00:14:58.020
So our job as
software engineers who

00:14:58.020 --> 00:15:00.130
focus on security, or
as security engineers,

00:15:00.130 --> 00:15:02.640
is to make the
world a place where

00:15:02.640 --> 00:15:05.980
HTTPS is a place you want
to be as web developers,

00:15:05.980 --> 00:15:07.756
where you want to be as users.

00:15:07.756 --> 00:15:09.380
And if we're not
doing that, then we've

00:15:09.380 --> 00:15:10.482
done something wrong.

00:15:10.482 --> 00:15:12.190
So we're trying really
hard to get there,

00:15:12.190 --> 00:15:13.500
and we're trying
harder and harder.

00:15:13.500 --> 00:15:14.760
And we're trying to
move towards that.

00:15:14.760 --> 00:15:16.259
But it's not something
we could just

00:15:16.259 --> 00:15:19.710
jump into tomorrow
as much I'd like to.

00:15:19.710 --> 00:15:21.810
Although there are
ways you can do that.

00:15:21.810 --> 00:15:24.210
You can get extensions
for Firefox or Chrome

00:15:24.210 --> 00:15:29.090
which won't let you
visit non HTTPS pages.

00:15:29.090 --> 00:15:31.125
I do recommend that.

00:15:31.125 --> 00:15:31.750
AUDIENCE: Yeah.

00:15:31.750 --> 00:15:39.460
But one more comment is for non
developer or technology expert,

00:15:39.460 --> 00:15:43.250
they even distinguish
between HTTP and HTTPS.

00:15:43.250 --> 00:15:49.830
And one of my clients asked
me, Google+ send me email that

00:15:49.830 --> 00:15:51.365
my account hacked.

00:15:51.365 --> 00:15:55.580
Because I ask her what
type of password you have.

00:15:55.580 --> 00:15:58.985
She said let me in.

00:15:58.985 --> 00:16:00.606
So I told her no.

00:16:00.606 --> 00:16:01.980
That's not the
password you want.

00:16:01.980 --> 00:16:06.410
You want to have capital letter,
and one-- at least one capital

00:16:06.410 --> 00:16:10.790
letter, one digit, and
one special character,

00:16:10.790 --> 00:16:15.182
and at least eight,
blah, blah, blah.

00:16:15.182 --> 00:16:16.640
JOEL WEINBERGER:
I'm going to focus

00:16:16.640 --> 00:16:20.506
on the HTTPS and
users not knowing

00:16:20.506 --> 00:16:21.880
what that is, and
so on so forth.

00:16:21.880 --> 00:16:23.460
That's a totally valid point.

00:16:23.460 --> 00:16:25.470
And moreover I would make
a stronger statement,

00:16:25.470 --> 00:16:27.550
which is we don't
even necessarily want

00:16:27.550 --> 00:16:29.457
users to know what HTTPS is.

00:16:29.457 --> 00:16:31.290
We want them to know
secure versus insecure,

00:16:31.290 --> 00:16:34.370
but we don't want to
know what is HTTP even.

00:16:37.128 --> 00:16:39.930
AUDIENCE: They don't even care
about secure and not secure.

00:16:39.930 --> 00:16:42.862
JOEL WEINBERGER: So the--

00:16:42.862 --> 00:16:44.225
AUDIENCE: I'm sorry.

00:16:44.225 --> 00:16:46.350
JOEL WEINBERGER: The claim
is that users don't even

00:16:46.350 --> 00:16:49.392
know secure from insecure,
and that's possible too.

00:16:49.392 --> 00:16:50.350
So there's two answers.

00:16:50.350 --> 00:16:55.510
One is that we actually do
find differences depending on,

00:16:55.510 --> 00:16:57.830
for example, the user
interfaces that we have.

00:16:57.830 --> 00:17:01.160
We do find differences in how
users interact with web pages.

00:17:01.160 --> 00:17:04.869
So one answer is that, as a
browser vendor in particular,

00:17:04.869 --> 00:17:07.880
we try to find ways of
expressing or encouraging

00:17:07.880 --> 00:17:12.170
users to use more secure web
applications through our user

00:17:12.170 --> 00:17:13.400
interface design.

00:17:13.400 --> 00:17:15.150
The other answer is,
through same tools,

00:17:15.150 --> 00:17:18.050
we also want to encourage web
developers to choose HTTPS,

00:17:18.050 --> 00:17:20.579
because that's
ultimately how we're

00:17:20.579 --> 00:17:22.130
going to solve this problem.

00:17:22.130 --> 00:17:25.609
And so we try to come up
with ways of making sure

00:17:25.609 --> 00:17:28.917
that our developers have HTTPS
is the better option for them.

00:17:28.917 --> 00:17:30.750
And that's something
they'll want to choose.

00:17:30.750 --> 00:17:32.450
And to make it easier.

00:17:32.450 --> 00:17:34.230
Part of that's outreach.

00:17:34.230 --> 00:17:36.180
Not a coincidence
we're all here tonight

00:17:36.180 --> 00:17:38.330
trying to discuss these issues.

00:17:38.330 --> 00:17:41.670
But others is sort of
implementation as well.

00:17:41.670 --> 00:17:45.210
But the really short answer
is it's really, really tough.

00:17:45.210 --> 00:17:47.130
It's really hard to
make this happen.

00:17:47.130 --> 00:17:48.170
But we're trying.

00:17:48.170 --> 00:17:50.320
AUDIENCE: Thank you.

00:17:50.320 --> 00:17:52.140
JOEL WEINBERGER: And
you guys can all help.

00:17:52.140 --> 00:17:53.764
Make your website
secure, first of all.

00:17:53.764 --> 00:17:57.080
And tell all your friends,
and so on and so forth.

00:17:57.080 --> 00:17:58.372
MODERATOR: Final two questions.

00:17:58.372 --> 00:18:00.788
EDUARDO VELA NAVA: Just one
more thing on that last thing.

00:18:00.788 --> 00:18:02.420
There are some
features of HTML5 that

00:18:02.420 --> 00:18:04.520
are being released
only for HTTPS sites.

00:18:04.520 --> 00:18:08.610
So that also works
as a carrot to help.

00:18:08.610 --> 00:18:10.690
AUDIENCE: What about HTTP 2.0.

00:18:10.690 --> 00:18:12.020
It's already here.

00:18:12.020 --> 00:18:15.710
Does is it supporting
any security related?

00:18:15.710 --> 00:18:17.820
Has any security related fixes?

00:18:17.820 --> 00:18:18.930
Or I don't know.

00:18:18.930 --> 00:18:22.100
EDUARDO VELA NAVA:
So I'm actually not

00:18:22.100 --> 00:18:26.830
sure who ended up on top.

00:18:26.830 --> 00:18:30.000
But SPDY for example, Chrome
only supports SPDY over SSL,

00:18:30.000 --> 00:18:34.600
even though it could support
it over non encrypted channels.

00:18:34.600 --> 00:18:36.030
And that was it's
similar, right?

00:18:36.030 --> 00:18:37.180
Just like carrot.

00:18:37.180 --> 00:18:39.959
But I think SPDY is
possible to run without SSL.

00:18:39.959 --> 00:18:41.500
It's just Chrome
doesn't implement it

00:18:41.500 --> 00:18:47.150
that way, for security
and blah, blah, blah.

00:18:47.150 --> 00:18:48.860
And the betas still being had.

00:18:48.860 --> 00:18:52.170
But that is the
current implementation

00:18:52.170 --> 00:18:54.030
and how it has been implemented.

00:18:54.030 --> 00:18:56.830
AUDIENCE: My main question
was, it's more philosophical.

00:18:56.830 --> 00:19:00.200
Like today I learned
a lot about security,

00:19:00.200 --> 00:19:02.050
and I kind of underestimated it.

00:19:02.050 --> 00:19:04.077
And I know a lot
of companies do.

00:19:04.077 --> 00:19:05.910
They don't have a
dedicated security person,

00:19:05.910 --> 00:19:08.710
until something bad happens.

00:19:08.710 --> 00:19:11.500
Who should be the one
who should be an expert

00:19:11.500 --> 00:19:16.570
or know how to write correctly,
or write better code,

00:19:16.570 --> 00:19:18.926
that has security
checks and balances.

00:19:18.926 --> 00:19:19.925
Should it be developers?

00:19:19.925 --> 00:19:23.350
Or should it fall
under QA who should

00:19:23.350 --> 00:19:25.707
be testing for these
kind of attacks?

00:19:25.707 --> 00:19:28.040
EDUARDO VELA NAVA: So I think
it should be the framework

00:19:28.040 --> 00:19:30.760
developer,s and you should just
choose the right frameworks.

00:19:30.760 --> 00:19:35.190
But if you want to go the way
of teaching all the developers,

00:19:35.190 --> 00:19:37.970
the it should be all the
developers, and all QA testers,

00:19:37.970 --> 00:19:42.105
and all the everyone, because
all of them are humans.

00:19:42.105 --> 00:19:43.730
PARISA TABRIZ: I can
just say one thing

00:19:43.730 --> 00:19:47.270
for at Google it is the
responsibility of everybody

00:19:47.270 --> 00:19:50.470
who's working on a product
to care about the security

00:19:50.470 --> 00:19:53.850
just as similar as to
care about the usability

00:19:53.850 --> 00:19:57.350
and, in general, the
quality of the product.

00:19:57.350 --> 00:20:00.230
Security is just one aspect of
the quality of the software.

00:20:00.230 --> 00:20:01.900
And I don't think
you can actually

00:20:01.900 --> 00:20:05.200
delegate the responsibility
to any single job role.

00:20:05.200 --> 00:20:07.590
So all software engineers
are responsible for security.

00:20:07.590 --> 00:20:08.850
All product managers.

00:20:08.850 --> 00:20:10.530
All program managers.

00:20:10.530 --> 00:20:12.752
We have people that
work PR and legal,

00:20:12.752 --> 00:20:14.460
and they need to care
about security too.

00:20:14.460 --> 00:20:16.090
So I really don't
think it's something

00:20:16.090 --> 00:20:18.510
that you can delegate
to one person,

00:20:18.510 --> 00:20:23.720
because it's quality of
software that everybody

00:20:23.720 --> 00:20:24.960
needs to care about.

00:20:24.960 --> 00:20:29.290
And that's how we
make it scale and work

00:20:29.290 --> 00:20:33.880
across lots of software
in a really big company.

00:20:33.880 --> 00:20:36.710
AUDIENCE: Last
question for Eduardo.

00:20:36.710 --> 00:20:40.350
You said ask me in the
question, why was I sorry about?

00:20:40.350 --> 00:20:42.370
What is that?

00:20:42.370 --> 00:20:44.520
EDUARDO VELA NAVA: Because
I used Prezi, and Prezi

00:20:44.520 --> 00:20:47.710
is in a Flash application,
and I used it in HTML5.

00:20:47.710 --> 00:20:51.290
[LAUGHTER]

00:20:51.290 --> 00:20:52.580
That's why I said sorry.

00:20:52.580 --> 00:20:53.680
AUDIENCE: OK.

00:20:53.680 --> 00:20:54.780
Last question.

00:20:54.780 --> 00:20:57.600
On June 5, there
is a project called

00:20:57.600 --> 00:21:01.360
Reset the Net that is
asking web developers to do

00:21:01.360 --> 00:21:03.487
one thing to improve
web security.

00:21:03.487 --> 00:21:05.570
I was wondering if I could
get an answer from each

00:21:05.570 --> 00:21:08.540
of the panel on--
obviously your answer

00:21:08.540 --> 00:21:12.710
is HTTPS-- what are the
other three panelists

00:21:12.710 --> 00:21:14.480
opinions on what is
the one thing that you

00:21:14.480 --> 00:21:16.280
could do to improve
web security.

00:21:16.280 --> 00:21:19.960
And part of this
movement is to, whenever

00:21:19.960 --> 00:21:23.120
you do that thing on
June 5, write about it.

00:21:23.120 --> 00:21:25.480
Publish it, tweet
it, do anything

00:21:25.480 --> 00:21:28.022
you can to talk
about web security.

00:21:28.022 --> 00:21:30.480
JOEL WEINBERGER: I'm pretty
sad you didn't give me a chance

00:21:30.480 --> 00:21:32.790
to answer that, but
yeah, HTTPS, yes.

00:21:35.224 --> 00:21:37.390
EDUARDO VELA NAVA: I talked
about framework security

00:21:37.390 --> 00:21:38.265
and blah, blah, blah.

00:21:38.265 --> 00:21:41.190
So just make a patch,
or send an email

00:21:41.190 --> 00:21:43.320
to your favorite
framework and tell them

00:21:43.320 --> 00:21:44.840
about what you want them to do.

00:21:44.840 --> 00:21:47.210
Or do it yourself after
talking with them.

00:21:50.400 --> 00:21:53.350
PARISA TABRIZ: So I'm
also an SSL evangelist.

00:21:53.350 --> 00:21:56.380
But since you're already
going to do these things--

00:21:56.380 --> 00:21:57.590
you have to got last--

00:21:57.590 --> 00:21:58.620
[LAUGHTER]

00:21:58.620 --> 00:22:01.850
I guess mine would
be, if you're going

00:22:01.850 --> 00:22:04.940
to use existing
frameworks, or components,

00:22:04.940 --> 00:22:07.160
or whatever, make
sure they're updated.

00:22:07.160 --> 00:22:09.330
A lot of the times
vulnerabilities

00:22:09.330 --> 00:22:12.730
are disclosed, so people
know about the bugs

00:22:12.730 --> 00:22:14.660
and how to exploit
them, but you actually

00:22:14.660 --> 00:22:17.000
don't get the fixes unless
you update your software.

00:22:17.000 --> 00:22:19.090
So use SSL.

00:22:19.090 --> 00:22:20.129
Use existing frameworks.

00:22:20.129 --> 00:22:21.420
And make sure it's all updated.

00:22:24.001 --> 00:22:25.000
TIM WILLIS: Don't worry.

00:22:25.000 --> 00:22:25.750
I'm used to going last.

00:22:25.750 --> 00:22:26.708
My last name is WIllis.

00:22:26.708 --> 00:22:29.491
So I was always
last, until the kids

00:22:29.491 --> 00:22:31.240
whose last name started
with A complained.

00:22:31.240 --> 00:22:32.100
And they're like, all right.

00:22:32.100 --> 00:22:33.600
For this really
annoying task, we'll

00:22:33.600 --> 00:22:35.290
go reverse alphabetical order.

00:22:35.290 --> 00:22:37.220
Willis you're up.

00:22:37.220 --> 00:22:39.830
For me it would be, if you
can't sell them on HTTPS

00:22:39.830 --> 00:22:41.600
and you can't sell
them on the frameworks,

00:22:41.600 --> 00:22:43.590
send them the XSS Wargame.

00:22:43.590 --> 00:22:44.810
Please, please.

00:22:44.810 --> 00:22:46.936
XSS is a huge problem.

00:22:46.936 --> 00:22:49.227
And the one thing I would do
is, if you can't sell them

00:22:49.227 --> 00:22:51.530
on the frameworks and you
can't sell them on HTTPS,

00:22:51.530 --> 00:22:53.630
please use the links
we provided tonight

00:22:53.630 --> 00:22:56.060
and get them educated
and interested in XSS.

00:22:56.060 --> 00:22:57.910
Because if we could
squash that, we

00:22:57.910 --> 00:23:00.542
would be in an amazing position.

00:23:00.542 --> 00:23:01.458
AUDIENCE: [INAUDIBLE].

00:23:06.130 --> 00:23:07.870
MODERATOR: Just go for it.

00:23:07.870 --> 00:23:08.800
That's always fine.

00:23:08.800 --> 00:23:09.400
Thank you.

00:23:09.400 --> 00:23:10.770
AUDIENCE: Spread the word.

00:23:10.770 --> 00:23:12.070
MODERATOR: Spread the word.

00:23:12.070 --> 00:23:13.329
All right.

00:23:13.329 --> 00:23:15.120
Big round of applause
for all the speakers.

00:23:15.120 --> 00:23:19.760
[APPLAUSE]

00:23:19.760 --> 00:23:23.152
We are going to
have the raffle now,

00:23:23.152 --> 00:23:25.110
and we're going to sign
off on the live stream.

00:23:25.110 --> 00:23:27.360
Everyone, hundreds of
people on the live stream,

00:23:27.360 --> 00:23:29.300
thanks for joining us.

00:23:29.300 --> 00:23:32.470
We are going to go through
the raffle tickets.

00:23:32.470 --> 00:23:33.430
Actually first off--

00:23:33.430 --> 00:23:38.880
[MUSIC PLAYING]

