WEBVTT
Kind: captions
Language: en-GB

00:00:10.900 --> 00:00:13.510
I think probably
everything I say tonight I

00:00:13.510 --> 00:00:16.510
have said in several
versions to the students

00:00:16.510 --> 00:00:19.930
at New College of the
Humanities in the last few years

00:00:19.930 --> 00:00:21.660
when I've given lectures.

00:00:21.660 --> 00:00:24.260
They've very much
helped me write

00:00:24.260 --> 00:00:26.820
the book that's now emerged.

00:00:26.820 --> 00:00:30.950
And I was thinking, just
as you were introducing me,

00:00:30.950 --> 00:00:35.960
of a science teacher I
had when I was 16 or so,

00:00:35.960 --> 00:00:38.640
who said a wonderful
thing-- a physics teacher.

00:00:38.640 --> 00:00:45.320
He said science done right
is one of the humanities.

00:00:45.320 --> 00:00:48.140
And I thought, oh,
what a great idea.

00:00:48.140 --> 00:00:53.330
And I sort of kept that
in my mind all along.

00:00:53.330 --> 00:00:58.040
And when Anthony at New College
of the Humanities asked me--

00:00:58.040 --> 00:01:00.360
and, of course,
I'm a philosopher--

00:01:00.360 --> 00:01:05.030
to do my thing, I knew
that I was encouraged

00:01:05.030 --> 00:01:10.040
to talk about the science
that I was interested in,

00:01:10.040 --> 00:01:11.990
the scientific
ideas, which I think

00:01:11.990 --> 00:01:14.750
are also important
philosophical ideas.

00:01:14.750 --> 00:01:17.670
And that's what I'm going
to talk about tonight.

00:01:17.670 --> 00:01:20.010
So thank you all for coming.

00:01:20.010 --> 00:01:24.380
If some of you have seen my
Royal Institution talk of about

00:01:24.380 --> 00:01:27.080
two years ago, you will
recognise a few slides.

00:01:27.080 --> 00:01:34.340
This is a later development
of my thinking and pretty much

00:01:34.340 --> 00:01:38.270
lines up with what's
in my new book, called

00:01:38.270 --> 00:01:40.809
From Bacteria to Bach and Back.

00:01:45.800 --> 00:01:47.510
Here's a sort of punchline.

00:01:47.510 --> 00:01:49.780
Should be fairly obvious.

00:01:49.780 --> 00:01:54.830
We are the first intelligent
designers in the tree of life.

00:01:54.830 --> 00:01:58.920
Now, this is my favourite
diagram of the tree of life.

00:01:58.920 --> 00:02:05.210
And if you see, this is
the present all along here.

00:02:05.210 --> 00:02:07.400
This is the origin of life.

00:02:07.400 --> 00:02:09.120
So time goes out here.

00:02:09.120 --> 00:02:10.830
And here are the
earliest life forms,

00:02:10.830 --> 00:02:12.730
the bacteria in the Archean.

00:02:12.730 --> 00:02:15.200
And here's this
great, great moment,

00:02:15.200 --> 00:02:20.660
the eukaryotic revolution, which
led to this wonderful fanning

00:02:20.660 --> 00:02:23.300
out of basically all
the living things you

00:02:23.300 --> 00:02:25.710
can see with your naked eye.

00:02:25.710 --> 00:02:31.670
And that little Y there, well,
that's about six million years.

00:02:31.670 --> 00:02:35.240
And that's how long
we've been separated

00:02:35.240 --> 00:02:38.030
from our common ancestor
with the chimpanzee.

00:02:38.030 --> 00:02:42.440
So human beings have
only been on the scene

00:02:42.440 --> 00:02:45.590
for just a tiny little
bit of this diagram.

00:02:45.590 --> 00:02:48.290
And I'm claiming that--

00:02:48.290 --> 00:02:49.520
is there intelligent design?

00:02:49.520 --> 00:02:51.680
Yes.

00:02:51.680 --> 00:02:55.110
Intelligent designers in
this room by the dozens.

00:02:55.110 --> 00:02:57.990
And our scientists and artists
are intelligent designers.

00:02:57.990 --> 00:03:02.630
So the problem then that
I'm facing in this book is,

00:03:02.630 --> 00:03:06.800
how did intelligent
designers evolve?

00:03:06.800 --> 00:03:09.190
If natural selection is
not intelligent design,

00:03:09.190 --> 00:03:15.500
and it isn't, how did small I,
small D intelligent designers

00:03:15.500 --> 00:03:16.754
evolve?

00:03:16.754 --> 00:03:18.170
And some people
have real trouble,

00:03:18.170 --> 00:03:20.300
including somebody who's going
to be here, I understand,

00:03:20.300 --> 00:03:21.140
in the next month.

00:03:21.140 --> 00:03:24.080
And that's Roger
Penrose, who says

00:03:24.080 --> 00:03:28.220
"I am a strong believer in the
power of natural selection.

00:03:28.220 --> 00:03:33.440
But I do not see how
natural selection in itself

00:03:33.440 --> 00:03:35.720
can evolve algorithms
which could

00:03:35.720 --> 00:03:38.300
have the kind of
conscious judgements

00:03:38.300 --> 00:03:40.220
of the validity of
other algorithms

00:03:40.220 --> 00:03:42.140
that we seem to have."

00:03:42.140 --> 00:03:44.000
He goes on, "to my
way of thinking,

00:03:44.000 --> 00:03:47.300
there is still something
mysterious about evolution

00:03:47.300 --> 00:03:52.070
and its apparent groping
towards some future purpose.

00:03:52.070 --> 00:03:55.370
Things at least seem to organise
themselves somewhat better

00:03:55.370 --> 00:03:59.360
than they ought to, just on the
basis of blind chance evolution

00:03:59.360 --> 00:04:01.070
and natural selection."

00:04:01.070 --> 00:04:04.100
Now, that's a bit
of Darwin doubting

00:04:04.100 --> 00:04:07.790
by one of the most
eminent scientists around.

00:04:07.790 --> 00:04:10.100
And he's far from alone.

00:04:10.100 --> 00:04:12.230
There are a lot of--

00:04:12.230 --> 00:04:15.560
I like the way he puts
it too, because he's

00:04:15.560 --> 00:04:20.660
a great believer in our natural
selection, but it bothers him,

00:04:20.660 --> 00:04:23.630
and his nagging
thought that there's

00:04:23.630 --> 00:04:26.305
got to be something that
doesn't quite add up.

00:04:26.305 --> 00:04:27.680
And I'm going to
try to point out

00:04:27.680 --> 00:04:29.900
what it is and then show
you how to get yourself out

00:04:29.900 --> 00:04:32.180
of that puzzle.

00:04:32.180 --> 00:04:34.580
And here's the way it could go.

00:04:34.580 --> 00:04:38.540
How could a slow,
mindless process

00:04:38.540 --> 00:04:42.020
build a thing that
could build a thing

00:04:42.020 --> 00:04:44.900
that a slow mindless process
couldn't build on its own?

00:04:47.540 --> 00:04:51.490
There does seem to be
something faintly miraculous

00:04:51.490 --> 00:04:55.460
or pulling yourself up by
your own bootstraps there.

00:04:55.460 --> 00:05:00.900
And my book is an attempt
to answer that question.

00:05:00.900 --> 00:05:05.160
Well, of course,
you know the answer.

00:05:05.160 --> 00:05:08.540
First, you evolve Alan Turing.

00:05:08.540 --> 00:05:12.090
And then, he intelligently
designs a computer.

00:05:12.090 --> 00:05:14.870
And we're home.

00:05:14.870 --> 00:05:18.950
But how do we get
an Alan Turing?

00:05:18.950 --> 00:05:21.800
How do we evolve an Alan Turing?

00:05:21.800 --> 00:05:25.220
Well, the answer, of course,
is natural selection.

00:05:25.220 --> 00:05:29.930
But this is the main
point of my book in a way,

00:05:29.930 --> 00:05:32.900
not just natural
selection of genes.

00:05:32.900 --> 00:05:35.390
We have to also talk
about cultural evolution

00:05:35.390 --> 00:05:37.670
and the natural
selection of memes,

00:05:37.670 --> 00:05:40.700
Richard Dawkins' idea
of cultural units

00:05:40.700 --> 00:05:43.220
that replicate differentially.

00:05:43.220 --> 00:05:47.600
And the ones that replicate
best are fitter, survive,

00:05:47.600 --> 00:05:50.180
and make more, and
that human culture

00:05:50.180 --> 00:05:54.410
is the medium, the
source, and ultimately

00:05:54.410 --> 00:06:00.470
the power that makes somebody
like Alan Turing possible.

00:06:00.470 --> 00:06:04.130
Well, this idea
suggests a question,

00:06:04.130 --> 00:06:08.450
the question in my title.

00:06:08.450 --> 00:06:10.010
So are brains computers?

00:06:10.010 --> 00:06:12.690
I say, if brains are computers,
then who writes the software?

00:06:12.690 --> 00:06:15.380
Well, let's pause and look
at whether our brains are

00:06:15.380 --> 00:06:17.120
computers at all.

00:06:17.120 --> 00:06:20.060
And some people think not.

00:06:20.060 --> 00:06:22.760
Some insist that they aren't.

00:06:22.760 --> 00:06:24.890
They're scientists,
such as Roger Penrose,

00:06:24.890 --> 00:06:28.760
very clear about that in his
book, The Emperor's New Mind.

00:06:28.760 --> 00:06:32.670
Gerry Edelman, the
late Nobel laureate--

00:06:32.670 --> 00:06:38.690
I was a little puzzled by
Jerry's insistence that brains

00:06:38.690 --> 00:06:45.620
were not computers, while he
modelled brains on computers

00:06:45.620 --> 00:06:48.650
and used his models
to demonstrate

00:06:48.650 --> 00:06:53.030
why a computer couldn't do
that sort of thing, which

00:06:53.030 --> 00:06:56.390
was a problem that Gerry had.

00:06:56.390 --> 00:07:00.170
But there's also Jaak
Panksepp, some of you may know,

00:07:00.170 --> 00:07:03.530
an eminent neuroscientist
whose main area of interest

00:07:03.530 --> 00:07:06.640
is emotion.

00:07:06.640 --> 00:07:10.330
But there's philosophers
as well, of course.

00:07:10.330 --> 00:07:13.100
John Searle comes
to mind, famously.

00:07:13.100 --> 00:07:16.180
And your own Raymond Tallis.

00:07:16.180 --> 00:07:18.610
And I'm not going to say any
more about either one of them

00:07:18.610 --> 00:07:19.110
tonight.

00:07:19.110 --> 00:07:22.220
I had my say elsewhere.

00:07:22.220 --> 00:07:27.140
Because I want to talk about
computer phobia and, in fact,

00:07:27.140 --> 00:07:29.810
two different varieties
of computer phobia,

00:07:29.810 --> 00:07:32.360
which is my perhaps
somewhat rude term

00:07:32.360 --> 00:07:36.380
for those who really don't like
the idea that our brains are

00:07:36.380 --> 00:07:39.620
computers at all.

00:07:39.620 --> 00:07:42.360
If brains aren't
computers, what are they?

00:07:42.360 --> 00:07:43.970
Well, they're not pumps.

00:07:43.970 --> 00:07:45.800
They're not factories.

00:07:45.800 --> 00:07:48.470
They're not purifiers.

00:07:48.470 --> 00:07:52.040
The task of brains is
to take information

00:07:52.040 --> 00:07:54.125
in and yield control.

00:07:56.930 --> 00:07:59.000
Of course, they're computers.

00:07:59.000 --> 00:08:00.520
That's what a computer is.

00:08:00.520 --> 00:08:04.680
It uses information
to control something.

00:08:04.680 --> 00:08:09.650
This is not the kind of computer
that the people are imagining.

00:08:09.650 --> 00:08:13.030
So I wanted to help you imagine
a different kind of computer,

00:08:13.030 --> 00:08:17.590
an organic if you like or
an evolved computer, which

00:08:17.590 --> 00:08:21.100
is what I think we
have between our ears.

00:08:21.100 --> 00:08:23.380
So the mis-imagination
of computers

00:08:23.380 --> 00:08:25.060
is something that
needs a diagnosis.

00:08:25.060 --> 00:08:26.830
And I'm going to
try to provide it.

00:08:26.830 --> 00:08:29.860
And I'm going to make
a new suggestion.

00:08:29.860 --> 00:08:32.409
Well, it's a newish
suggestion, because others

00:08:32.409 --> 00:08:33.880
have made it before.

00:08:33.880 --> 00:08:36.130
But I want to remind you
that there have been a number

00:08:36.130 --> 00:08:38.860
of attempts to say, well, brains
are sort of like computers,

00:08:38.860 --> 00:08:41.620
but they aren't--

00:08:41.620 --> 00:08:43.929
well, you know, they're
not made of silicon.

00:08:43.929 --> 00:08:45.700
They're made of protein.

00:08:45.700 --> 00:08:50.237
That's not what I
think is important.

00:08:50.237 --> 00:08:51.070
They're not digital.

00:08:51.070 --> 00:08:53.440
They're analogue.

00:08:53.440 --> 00:08:55.390
That's slightly true,
but I don't think

00:08:55.390 --> 00:08:57.899
that's the important point.

00:08:57.899 --> 00:08:58.690
They're not serial.

00:08:58.690 --> 00:09:00.520
They're parallel.

00:09:00.520 --> 00:09:05.410
True, but that's not
what I want to focus on.

00:09:05.410 --> 00:09:10.830
I want to focus on
something else entirely,

00:09:10.830 --> 00:09:15.140
the difference between
cooperative and competitive

00:09:15.140 --> 00:09:16.130
computers--

00:09:16.130 --> 00:09:18.980
I mean, computers that
are made of cooperative

00:09:18.980 --> 00:09:21.680
versus competitive parts.

00:09:21.680 --> 00:09:23.840
So the default image
that most of us

00:09:23.840 --> 00:09:26.150
have of computation
and certainly, say,

00:09:26.150 --> 00:09:30.260
that Roger Penrose has is
that it's ultra efficient.

00:09:30.260 --> 00:09:33.350
There's no waste motion,
no cross-purposes.

00:09:33.350 --> 00:09:36.590
And there's redundancy
only for safety.

00:09:36.590 --> 00:09:42.290
It's hierarchically organised,
where routines call subroutines

00:09:42.290 --> 00:09:45.320
and the sub-routines answer.

00:09:45.320 --> 00:09:48.380
It's all like a
well-oiled corporation

00:09:48.380 --> 00:09:52.760
with chains of command
and control all the way

00:09:52.760 --> 00:09:54.390
up and down.

00:09:54.390 --> 00:09:57.470
And there is also
controlled prioritisation.

00:09:57.470 --> 00:10:00.290
That is, there are, as it were,
built-in traffic cops that

00:10:00.290 --> 00:10:02.660
decide what happens next.

00:10:02.660 --> 00:10:05.270
You don't have any
fighting over that.

00:10:05.270 --> 00:10:09.110
And there is competition
in the brain--

00:10:09.110 --> 00:10:10.130
I mean, in computers.

00:10:10.130 --> 00:10:13.230
But it's, as it were,
friendly opponent processes.

00:10:13.230 --> 00:10:16.280
There's sort of tugs of war
that are carefully set up

00:10:16.280 --> 00:10:21.020
in order to resolve some issue
in a tug of war sort of way.

00:10:21.020 --> 00:10:23.690
But it's not, as it
were, deadly competition.

00:10:23.690 --> 00:10:28.280
It's just for the sake of
finding a midpoint, usually,

00:10:28.280 --> 00:10:31.260
something like that.

00:10:31.260 --> 00:10:35.160
The computer scientist
Eric Baum has a nice name

00:10:35.160 --> 00:10:36.750
for this kind of architecture.

00:10:36.750 --> 00:10:42.210
He calls it the Politburo
architecture or Politburo

00:10:42.210 --> 00:10:44.430
control, like the
old Soviet Union.

00:10:47.080 --> 00:10:51.160
I want to compare that with
what one of my postdocs

00:10:51.160 --> 00:10:54.230
once called brain wars.

00:10:54.230 --> 00:10:58.200
In brain wars, we have real,
not notional competition.

00:10:58.200 --> 00:11:02.170
It's even, in some cases,
a matter of life or death.

00:11:02.170 --> 00:11:06.120
You have micro agents
with their own agendas--

00:11:06.120 --> 00:11:10.570
neurons, astrocytes, glia cells.

00:11:10.570 --> 00:11:14.350
But neurons are the ones
I'll concentrate on.

00:11:14.350 --> 00:11:18.580
Tecumseh Fitch, a friend
of mine and colleague,

00:11:18.580 --> 00:11:20.800
in the paper called
"Nano-Intentionality"

00:11:20.800 --> 00:11:23.440
in Biology and Philosophy
a few years ago,

00:11:23.440 --> 00:11:28.330
spells out the idea pretty
clearly that individual neurons

00:11:28.330 --> 00:11:29.410
are agents.

00:11:29.410 --> 00:11:31.690
And they're semi-autonomous.

00:11:31.690 --> 00:11:33.906
And they do have agendas.

00:11:33.906 --> 00:11:35.530
And that's very
different from what you

00:11:35.530 --> 00:11:39.980
have in your digital computer.

00:11:39.980 --> 00:11:46.750
So I want you to compare Marx,
to each according to his needs,

00:11:46.750 --> 00:11:51.760
from each according
to his talents.

00:11:51.760 --> 00:11:54.640
Compare that with
dog-eat-dog, free-for-all,

00:11:54.640 --> 00:11:57.730
laissez-faire
capitalism, where there's

00:11:57.730 --> 00:11:59.470
no central or higher control.

00:12:03.160 --> 00:12:06.850
Cooperation does happen,
but it's not a precondition.

00:12:06.850 --> 00:12:09.071
It's an intermittent
achievement.

00:12:11.720 --> 00:12:13.300
OK?

00:12:13.300 --> 00:12:16.180
Now, having presented
this stark contrast,

00:12:16.180 --> 00:12:22.360
I do need to do a preemptive
noting of the irony, what

00:12:22.360 --> 00:12:23.890
I'm not saying.

00:12:23.890 --> 00:12:26.740
You might think,
uh oh, Dennett has

00:12:26.740 --> 00:12:32.620
fallen in with the likes of
Ayn Rand and Milton Friedman

00:12:32.620 --> 00:12:34.120
and laissez-faire capitalism.

00:12:34.120 --> 00:12:36.970
No, no, no.

00:12:36.970 --> 00:12:39.910
I'm not a fan of that
view of the economy.

00:12:39.910 --> 00:12:47.630
But, still, centrally
planned economies don't work,

00:12:47.630 --> 00:12:53.420
and neither do centrally
controlled, top-down brains.

00:12:53.420 --> 00:12:56.510
Neither do centrally
controlled hierarchically

00:12:56.510 --> 00:12:59.600
organised top-down brains.

00:12:59.600 --> 00:13:02.180
Even the best
cognitive architectures

00:13:02.180 --> 00:13:05.090
that have been developed
so far in cognitive science

00:13:05.090 --> 00:13:09.950
have tended to be too
disciplined, too neat, too

00:13:09.950 --> 00:13:13.370
not have the sort of
unruly competition

00:13:13.370 --> 00:13:19.070
that I think now is essential
in an actual organic brain,

00:13:19.070 --> 00:13:20.600
especially the human brain.

00:13:20.600 --> 00:13:22.580
They're too bureaucratic,
you might say.

00:13:27.000 --> 00:13:29.620
They have millions of
identical elements,

00:13:29.620 --> 00:13:31.800
which is also important.

00:13:31.800 --> 00:13:35.880
I didn't really appreciate
this until very recently,

00:13:35.880 --> 00:13:38.160
when I was talking
with my good friend Rod

00:13:38.160 --> 00:13:42.240
Brooks, a roboticist, an
extraordinary roboticist

00:13:42.240 --> 00:13:46.860
with whom I worked for some
years on the Cog Project.

00:13:46.860 --> 00:13:49.680
But we've had these models
of the brain ever since

00:13:49.680 --> 00:13:52.980
the McCulloch-Pitts neurons,
which is one of the great

00:13:52.980 --> 00:13:56.041
oversimplifications of all
times that came along--

00:13:56.041 --> 00:13:57.540
I can't remember
the year right now,

00:13:57.540 --> 00:14:00.510
but it was in the
'50s, I think, which

00:14:00.510 --> 00:14:07.350
had these very simple elements,
logical neurons, which

00:14:07.350 --> 00:14:10.680
emitted a single
branching output

00:14:10.680 --> 00:14:14.280
and had bunches of
inputs that could either

00:14:14.280 --> 00:14:20.130
have positive or negative
inhibitory or excitatory

00:14:20.130 --> 00:14:23.190
attachments or stimuli inputs.

00:14:23.190 --> 00:14:25.020
And then, they
summed the results,

00:14:25.020 --> 00:14:26.970
and they either
fired or they didn't.

00:14:26.970 --> 00:14:29.790
That was a brilliant
simplification.

00:14:29.790 --> 00:14:36.240
And they're wonderful
little thinking tools.

00:14:36.240 --> 00:14:38.970
But brains aren't like that.

00:14:38.970 --> 00:14:40.780
This is mis-imagination.

00:14:40.780 --> 00:14:42.420
And when we think
about computers,

00:14:42.420 --> 00:14:44.790
we tend to imagine the
algorithms with which we

00:14:44.790 --> 00:14:46.770
are somewhat
familiar, things you

00:14:46.770 --> 00:14:49.950
know like Word and Photoshop
and Google Desktop, which

00:14:49.950 --> 00:14:53.400
are all brilliantly
designed from the top down

00:14:53.400 --> 00:14:55.450
with hierarchical control.

00:14:55.450 --> 00:14:58.290
And if we compare those with
brains, just intuitively,

00:14:58.290 --> 00:15:00.570
you think, nah.

00:15:00.570 --> 00:15:02.790
Brains just aren't like that.

00:15:02.790 --> 00:15:03.990
And you're right.

00:15:03.990 --> 00:15:05.130
They aren't.

00:15:05.130 --> 00:15:07.302
But that doesn't mean
they're not computers.

00:15:07.302 --> 00:15:08.760
It just means they
aren't computers

00:15:08.760 --> 00:15:13.830
with Politburo control and
top-down designed software.

00:15:13.830 --> 00:15:16.830
They're not cold,
orderly, ultra efficient,

00:15:16.830 --> 00:15:22.010
and authoritarian
machines, composed

00:15:22.010 --> 00:15:26.390
of units that are
mindless little machines.

00:15:26.390 --> 00:15:31.266
So I want to compare
those models with, oh,

00:15:31.266 --> 00:15:32.390
how about the stock market.

00:15:35.590 --> 00:15:39.070
Is the stock market a computer?

00:15:39.070 --> 00:15:43.030
Is stock trading a
computational phenomenon?

00:15:43.030 --> 00:15:44.350
Yeah.

00:15:44.350 --> 00:15:44.920
It is.

00:15:44.920 --> 00:15:46.810
And in fact, in a
way, the proof of that

00:15:46.810 --> 00:15:51.850
is that those traders are being
replaced by machines right now.

00:15:51.850 --> 00:15:55.710
And more and more stock
trading is done entirely

00:15:55.710 --> 00:15:58.330
in the digital world.

00:15:58.330 --> 00:16:01.510
And so whatever they were
doing all those years

00:16:01.510 --> 00:16:03.340
was something that
could be easily done

00:16:03.340 --> 00:16:07.720
by machines, because
machines are doing it now.

00:16:07.720 --> 00:16:10.120
But now, let's look at neurons.

00:16:10.120 --> 00:16:13.660
For once, I'm going to ask
you to look at a neuron.

00:16:13.660 --> 00:16:16.020
Let's see if this is running.

00:16:16.020 --> 00:16:17.380
Yes.

00:16:17.380 --> 00:16:21.890
This is a little
looped bit of a film.

00:16:24.680 --> 00:16:27.530
These are neurons in a dish.

00:16:27.530 --> 00:16:31.070
And you see they're putting out
their little dendritic graspers

00:16:31.070 --> 00:16:32.210
and looking around.

00:16:32.210 --> 00:16:34.070
Here's another one.

00:16:34.070 --> 00:16:35.611
Is it going to make
that connection?

00:16:35.611 --> 00:16:36.110
No.

00:16:36.110 --> 00:16:36.610
Yes.

00:16:36.610 --> 00:16:38.990
No.

00:16:38.990 --> 00:16:41.090
So I want you to
replace the image

00:16:41.090 --> 00:16:47.000
you have of a McCulloch-Pitts
neuron with these squiggly

00:16:47.000 --> 00:16:52.550
little agents by the billions,
gathered in your brain

00:16:52.550 --> 00:16:56.540
and faced with the task of
keeping life and limb together

00:16:56.540 --> 00:16:57.140
for you.

00:16:59.760 --> 00:17:01.460
Now, one thing that
you get immediately

00:17:01.460 --> 00:17:03.430
when you start
thinking of neurons

00:17:03.430 --> 00:17:08.119
in this more agent-like way
is you get a good account

00:17:08.119 --> 00:17:10.490
of brain plasticity.

00:17:10.490 --> 00:17:13.339
As you no doubt know, if
a little bit of your brain

00:17:13.339 --> 00:17:17.329
is damaged, very often, not
always, but in many conditions,

00:17:17.329 --> 00:17:20.000
the neighbouring parts of
the brain that are spared

00:17:20.000 --> 00:17:24.349
can take over the work that was
being done by that part that's

00:17:24.349 --> 00:17:26.690
now died or gone missing.

00:17:26.690 --> 00:17:31.110
And some of the degrees of
versatility of brain tissue,

00:17:31.110 --> 00:17:35.350
especially cortical
tissue, is just stunning.

00:17:35.350 --> 00:17:39.140
And experiments show, for
instance, the famous Merzenich

00:17:39.140 --> 00:17:43.640
experiments, where he
mapped the brain areas that

00:17:43.640 --> 00:17:47.220
were involved in the
digits of a monkey

00:17:47.220 --> 00:17:50.540
and then sutured the
fingers together,

00:17:50.540 --> 00:17:54.590
so that the monkey
just had three digits,

00:17:54.590 --> 00:17:57.680
and after a week or
so, went in and looked

00:17:57.680 --> 00:18:00.410
at the areas that
were responsible

00:18:00.410 --> 00:18:02.720
and saw that there
was a reorganisation

00:18:02.720 --> 00:18:05.210
of the [? cortex. ?] It
wasn't as much work to do.

00:18:05.210 --> 00:18:08.330
And so the neurons
were recruited

00:18:08.330 --> 00:18:12.894
to do jobs for other purposes.

00:18:12.894 --> 00:18:14.810
And the way to think
about this, I've decided,

00:18:14.810 --> 00:18:18.530
is these are neurons
hungry for work.

00:18:18.530 --> 00:18:21.560
And they've got to stay alive.

00:18:21.560 --> 00:18:23.540
You may remember
a wonderful line

00:18:23.540 --> 00:18:31.680
from Francois Jacobs, who once
said the dream of every cell

00:18:31.680 --> 00:18:36.450
is to become two
cells, which is good,

00:18:36.450 --> 00:18:41.190
true at first approximation,
but not true of neurons.

00:18:41.190 --> 00:18:46.040
Pretty much, they're like mules.

00:18:46.040 --> 00:18:48.810
They are the offspring
cells, but they're not

00:18:48.810 --> 00:18:51.630
going to have any
offspring of their own.

00:18:51.630 --> 00:18:55.065
So their dream is
just to stay alive.

00:18:55.065 --> 00:18:56.190
But they got to stay alive.

00:18:56.190 --> 00:18:58.080
They got to fight
for their energy.

00:18:58.080 --> 00:19:00.330
And the only way to
fight for their energy

00:19:00.330 --> 00:19:05.400
is to find useful work
that they can get paid for.

00:19:05.400 --> 00:19:10.980
And so that's the kind
of energetic economy

00:19:10.980 --> 00:19:16.290
that I think we have to
replace the Politburo model,

00:19:16.290 --> 00:19:21.360
where all of this is taken
care of in a bureaucratic way.

00:19:21.360 --> 00:19:26.130
Obviously, obviously, when
a bit of brain tissue dies,

00:19:26.130 --> 00:19:30.330
there's no central personnel
director who reassigns

00:19:30.330 --> 00:19:33.300
the neurons in
the neighbourhood.

00:19:33.300 --> 00:19:37.140
That has to be figured out
in some sort of bottom-up way

00:19:37.140 --> 00:19:44.190
by the neurons, not by some
boss neuron or commissar

00:19:44.190 --> 00:19:48.310
in some part of the brain.

00:19:48.310 --> 00:19:49.770
So there's no
central administrator

00:19:49.770 --> 00:19:52.340
doing the reassignment at all.

00:19:52.340 --> 00:19:58.260
But-- moreover, no two
neurons are exactly alike.

00:19:58.260 --> 00:20:01.710
And this is the point that
I got from Rod Brooks, which

00:20:01.710 --> 00:20:03.510
I mentioned earlier.

00:20:03.510 --> 00:20:07.665
Rod is an unusual man with
many talents and many projects.

00:20:07.665 --> 00:20:09.299
And one of his--

00:20:09.299 --> 00:20:10.840
I don't know if he's
finished it yet.

00:20:10.840 --> 00:20:13.950
I have spoken to him about this
for it's a couple of years,

00:20:13.950 --> 00:20:15.480
I guess.

00:20:15.480 --> 00:20:18.240
He was going to make what
I'm going to call a steampunk

00:20:18.240 --> 00:20:23.610
computer, a pre-electronic
computer, no chips, not

00:20:23.610 --> 00:20:25.290
even any vacuum tubes.

00:20:25.290 --> 00:20:29.220
He was going to make a computer
out of relays and solenoids

00:20:29.220 --> 00:20:31.440
and the sorts of
electrical switching

00:20:31.440 --> 00:20:34.230
that you had before you had
the electronic age at all, just

00:20:34.230 --> 00:20:37.160
to see if he could do it.

00:20:37.160 --> 00:20:39.192
And of course, you can
make a computer out

00:20:39.192 --> 00:20:41.150
of just about anything
if you're clever enough.

00:20:41.150 --> 00:20:45.450
And so he set out to
make an actual computer.

00:20:45.450 --> 00:20:50.630
He loves to solder and put wires
between things and so forth.

00:20:50.630 --> 00:20:54.860
And he had a big room,
not quite as big as this.

00:20:54.860 --> 00:20:57.210
But this is where he's
building the computer.

00:20:57.210 --> 00:20:59.030
And of course, the
computer he was building

00:20:59.030 --> 00:21:04.220
would have way, way less
than 1% of the power

00:21:04.220 --> 00:21:08.570
and speed of your cell phone.

00:21:08.570 --> 00:21:13.670
But it was an energy hog,
a giant electrical, not

00:21:13.670 --> 00:21:16.550
electronic computer.

00:21:16.550 --> 00:21:19.040
And I was talking with him
about the challenges of this.

00:21:19.040 --> 00:21:22.340
He said, you know, the
hardest part of all

00:21:22.340 --> 00:21:28.100
was getting all the flip-flops
exactly alike, simply

00:21:28.100 --> 00:21:32.870
making them so exactly
similar that you

00:21:32.870 --> 00:21:36.410
could get reliable
computation out of them.

00:21:36.410 --> 00:21:38.540
The timing has to be precise.

00:21:38.540 --> 00:21:40.550
And the response
has to be precise.

00:21:40.550 --> 00:21:47.120
And that was a major challenge
for him as the builder of this.

00:21:47.120 --> 00:21:49.820
And he said, we've been
taking for granted one

00:21:49.820 --> 00:21:52.760
of the features of
the digital age, which

00:21:52.760 --> 00:21:56.210
is that the manufacture,
the manufacturing

00:21:56.210 --> 00:22:01.790
processes of chips
are just stunningly

00:22:01.790 --> 00:22:04.980
high quality and regular.

00:22:04.980 --> 00:22:08.420
You can have a bubble
memory with billions

00:22:08.420 --> 00:22:13.640
of just test about exactly
identical to the atom

00:22:13.640 --> 00:22:17.840
little memory units,
or flip-flops.

00:22:17.840 --> 00:22:22.940
And without that,
the architecture

00:22:22.940 --> 00:22:27.140
that you build on top
of them wouldn't work.

00:22:27.140 --> 00:22:29.000
And we don't have
that between our ears.

00:22:29.000 --> 00:22:30.620
We just don't.

00:22:30.620 --> 00:22:34.640
So we have to rethink the
idea of computer architecture

00:22:34.640 --> 00:22:38.840
to make an architecture
out of these

00:22:38.840 --> 00:22:46.150
different, unruly, clueless,
little, multi-armed, blind

00:22:46.150 --> 00:22:46.650
cells.

00:22:56.850 --> 00:23:02.010
So a brain is not
made of units at all,

00:23:02.010 --> 00:23:07.200
in those properties like what
you've got on your cell phone.

00:23:07.200 --> 00:23:09.600
So now, I'm going to
show an image I've

00:23:09.600 --> 00:23:12.960
shown often before,
because it so vividly makes

00:23:12.960 --> 00:23:14.130
the point I want to make.

00:23:17.080 --> 00:23:22.110
On the left, you see a termite
castle, an Australian termite

00:23:22.110 --> 00:23:24.270
castle.

00:23:24.270 --> 00:23:26.520
On the right, you
see, of course,

00:23:26.520 --> 00:23:31.830
Antoni Gaudi's famous church
in Barcelona, Sagrada Familia.

00:23:31.830 --> 00:23:34.480
They look stunningly alike.

00:23:34.480 --> 00:23:35.820
And that's even no accident.

00:23:38.430 --> 00:23:42.210
Even the interiors and
the structural members

00:23:42.210 --> 00:23:44.880
have some striking similarities.

00:23:44.880 --> 00:23:50.490
So here we have two artefacts,
both made by living things.

00:23:50.490 --> 00:23:54.260
The one on the left
is made by termites.

00:23:54.260 --> 00:23:58.800
The one on the right was
designed and built by Gaudi.

00:23:58.800 --> 00:24:01.970
So here's a puzzle.

00:24:01.970 --> 00:24:05.090
On the left, we have
bottom-up design.

00:24:05.090 --> 00:24:06.860
On the right, we
have top-down design.

00:24:06.860 --> 00:24:09.500
And I mean that just
about literally.

00:24:09.500 --> 00:24:11.210
There's no boss termite.

00:24:11.210 --> 00:24:12.800
There's no architect termite.

00:24:12.800 --> 00:24:14.620
There's no blueprints.

00:24:14.620 --> 00:24:19.400
There's no second in command
and echelons of command.

00:24:19.400 --> 00:24:22.400
The termites are just doing
their individual thing.

00:24:22.400 --> 00:24:24.950
And they don't know what
they're doing or why,

00:24:24.950 --> 00:24:27.140
but they're doing it.

00:24:27.140 --> 00:24:31.190
And the result is that
amazing structure.

00:24:31.190 --> 00:24:35.180
That's bottom-up design
and construction.

00:24:35.180 --> 00:24:41.960
Gaudi, on the other hand, was
a charismatic, megalomaniac,

00:24:41.960 --> 00:24:46.520
creative genius with
blueprints, manifestos.

00:24:46.520 --> 00:24:48.680
He had it all worked out
in advance in his head.

00:24:48.680 --> 00:24:51.650
And he lorded it over
his second in command,

00:24:51.650 --> 00:24:54.980
who lorded it over
the lieutenants, who

00:24:54.980 --> 00:24:57.140
lorded it over the sergeants.

00:24:57.140 --> 00:24:59.030
And down it went
to the people who

00:24:59.030 --> 00:25:03.870
actually put the bricks together
or cut the stone and so forth.

00:25:03.870 --> 00:25:08.150
So we have a stark
contrast, two different ways

00:25:08.150 --> 00:25:10.070
of designing and building.

00:25:10.070 --> 00:25:12.922
One is bottom-up.

00:25:12.922 --> 00:25:15.130
I'm going to say, that's a
Darwinian way of building.

00:25:15.130 --> 00:25:23.810
It's done by a lot of competent
but uncomprehending processes.

00:25:23.810 --> 00:25:28.970
On the right, we have top-down,
intelligent design by Gaudi,

00:25:28.970 --> 00:25:32.007
which is where it's mind first.

00:25:32.007 --> 00:25:33.090
You come up with the idea.

00:25:33.090 --> 00:25:34.730
You prove it's a good idea.

00:25:34.730 --> 00:25:36.560
And off you go.

00:25:36.560 --> 00:25:39.470
Of course, my other favourite
example of something that was

00:25:39.470 --> 00:25:43.220
top-down design is
Turing's first computer.

00:25:43.220 --> 00:25:45.230
He had the proof of concept.

00:25:45.230 --> 00:25:48.580
Before they paid anything
to build the chassis

00:25:48.580 --> 00:25:51.200
or put in the tubes, they
knew it was going to work,

00:25:51.200 --> 00:25:53.160
because he proved it
was going to work.

00:25:53.160 --> 00:25:55.610
And he knew exactly how it
was going to be put together.

00:25:55.610 --> 00:25:58.520
They changed some things
along the way, of course.

00:25:58.520 --> 00:26:02.410
So we have a stark
contrast here.

00:26:02.410 --> 00:26:05.230
Now, here's the puzzle.

00:26:05.230 --> 00:26:07.210
A termite colony
might contain, I

00:26:07.210 --> 00:26:11.745
am told, up to 70 million
clueless termites.

00:26:15.490 --> 00:26:19.990
Latest count is that your
brain contains about 86 billion

00:26:19.990 --> 00:26:21.910
even more clueless neurons.

00:26:24.500 --> 00:26:28.270
Now, here's the puzzle.

00:26:28.270 --> 00:26:33.790
How do you get a Gaudi-type mind
out of a termite colony brain?

00:26:33.790 --> 00:26:38.560
What you have between your ears
is 86 billion semi-autonomous,

00:26:38.560 --> 00:26:40.690
clueless neurons.

00:26:40.690 --> 00:26:44.680
Not a one of them knows
who you are or cares.

00:26:44.680 --> 00:26:48.550
Somehow, that has
to be organised

00:26:48.550 --> 00:26:54.959
into something that can do what
Gaudi did or what Turing did.

00:26:54.959 --> 00:26:56.500
Well, when I was
thinking about this,

00:26:56.500 --> 00:26:59.830
I was reminded first of all of
another great triumph of about

00:26:59.830 --> 00:27:01.420
the same time as Turing.

00:27:01.420 --> 00:27:04.570
And that's the
great K-25 building

00:27:04.570 --> 00:27:07.330
at Oak Ridge in Tennessee,
built in record time

00:27:07.330 --> 00:27:10.360
during World War II, part
of the Manhattan Project.

00:27:10.360 --> 00:27:14.890
This is where they did the
gaseous diffusion of uranium

00:27:14.890 --> 00:27:22.342
to make the weapons-grade
uranium for the atomic bomb.

00:27:22.342 --> 00:27:23.800
When it was built,
it was, I think,

00:27:23.800 --> 00:27:27.110
the largest building
in the world.

00:27:27.110 --> 00:27:31.720
And over 12,000 workers
in round-the-clock shifts

00:27:31.720 --> 00:27:33.220
worked there.

00:27:33.220 --> 00:27:36.710
And they didn't know
what they were doing.

00:27:36.710 --> 00:27:39.890
They were clueless about
what they were doing.

00:27:39.890 --> 00:27:43.310
They were trained to push
buttons and turn dials and look

00:27:43.310 --> 00:27:44.450
at dials.

00:27:44.450 --> 00:27:49.350
And they had no idea
what they were doing.

00:27:49.350 --> 00:27:51.650
After the bomb was
dropped and they learned,

00:27:51.650 --> 00:27:52.650
they were flabbergasted.

00:27:52.650 --> 00:27:54.420
They didn't know they were--

00:27:54.420 --> 00:27:58.320
they had no idea what
they were making there.

00:27:58.320 --> 00:28:01.720
But now, think about it.

00:28:01.720 --> 00:28:05.790
First of all, it is
possible to organise

00:28:05.790 --> 00:28:09.390
armies of clueless operators
to perform some highly

00:28:09.390 --> 00:28:11.130
sophisticated control task.

00:28:11.130 --> 00:28:13.050
Witness Oak Ridge.

00:28:16.770 --> 00:28:19.800
But who or what
does the organising?

00:28:19.800 --> 00:28:22.140
And the answer in
the case of Oak Ridge

00:28:22.140 --> 00:28:24.480
is that it was
top-down, intelligently

00:28:24.480 --> 00:28:29.130
designed by a brilliant team
of physicists, engineers,

00:28:29.130 --> 00:28:32.935
and a brilliant leader named
Leslie Groves, General Leslie

00:28:32.935 --> 00:28:33.435
Groves.

00:28:37.410 --> 00:28:40.350
So it's like Gaudi's church.

00:28:40.350 --> 00:28:42.840
And it's like Turing's computer.

00:28:42.840 --> 00:28:47.000
And it's like all good
old-fashioned AI programmes.

00:28:47.000 --> 00:28:54.030
GOFAI was introduced by the
philosopher John Haugeland

00:28:54.030 --> 00:28:57.240
some years ago.

00:28:57.240 --> 00:28:58.630
And it stuck.

00:28:58.630 --> 00:29:02.130
People in AI have
adopted his sort

00:29:02.130 --> 00:29:05.760
of deliberately snide term,
"good old-fashioned AI."

00:29:05.760 --> 00:29:10.410
It's the kind of AI that led to
the AI winter that is now over.

00:29:10.410 --> 00:29:13.110
And we're now in
a new AI spring,

00:29:13.110 --> 00:29:20.640
with all of the new bottom-up
computer processes that

00:29:20.640 --> 00:29:23.910
are dazzling everybody today.

00:29:29.360 --> 00:29:33.710
So good old-fashioned AI was
top-down, not bottom-up design.

00:29:33.710 --> 00:29:36.887
This is a cartoon that
I made some years ago,

00:29:36.887 --> 00:29:37.970
the walking encyclopaedia.

00:29:37.970 --> 00:29:41.330
It was supposed to give you
an idea of what was involved.

00:29:41.330 --> 00:29:44.720
This is the sort of
phony flow graph.

00:29:44.720 --> 00:29:48.230
But we have a belief
box or belief fixation

00:29:48.230 --> 00:29:50.690
box, and the planning
committee, and the action,

00:29:50.690 --> 00:29:52.520
and the language
acquisition device

00:29:52.520 --> 00:29:54.170
that Chomsky made famous.

00:29:54.170 --> 00:29:55.430
And here's the lexicon.

00:29:55.430 --> 00:29:58.550
Here's where the logic
is, perceptual analysis.

00:29:58.550 --> 00:30:01.550
And you've got all these
departments interacting,

00:30:01.550 --> 00:30:03.070
sending memos back and forth.

00:30:03.070 --> 00:30:05.820
It's very, very bureaucratic
and very well organised,

00:30:05.820 --> 00:30:07.220
very efficient,
and very brittle.

00:30:07.220 --> 00:30:08.120
And it doesn't work.

00:30:10.940 --> 00:30:12.680
And I say it doesn't
work because we

00:30:12.680 --> 00:30:16.580
tried for several decades,
very, very smart people,

00:30:16.580 --> 00:30:20.220
and more or less proved
that it didn't work.

00:30:20.220 --> 00:30:26.260
So when we look at Oak Ridge,
we see it was top-down design,

00:30:26.260 --> 00:30:28.480
and it did work.

00:30:28.480 --> 00:30:32.300
But who knew what at Oak Ridge?

00:30:32.300 --> 00:30:33.440
I tried to find out.

00:30:33.440 --> 00:30:34.910
And as near as I
can tell, there's

00:30:34.910 --> 00:30:37.140
still not much publicly
available information.

00:30:37.140 --> 00:30:41.540
It's still clouded in security.

00:30:41.540 --> 00:30:44.600
But General Leslie Groves knew.

00:30:44.600 --> 00:30:47.690
And so did his
immediate staff and many

00:30:47.690 --> 00:30:51.380
of those who reported to
them, and the head engineers

00:30:51.380 --> 00:30:53.930
who designed the plant.

00:30:53.930 --> 00:30:58.400
But probably the architects
that designed the building, just

00:30:58.400 --> 00:31:00.620
the outer shell, had no
idea what the building

00:31:00.620 --> 00:31:03.672
was going to have inside it.

00:31:03.672 --> 00:31:08.499
It had a waterproof roof
and very strong supports

00:31:08.499 --> 00:31:09.290
for various things.

00:31:09.290 --> 00:31:12.080
But they didn't know
what was going in.

00:31:12.080 --> 00:31:14.330
So I think there's a
sort of diminishing

00:31:14.330 --> 00:31:17.030
level of comprehension
all the way down.

00:31:17.030 --> 00:31:20.030
But for most of the people
that work there every day, not

00:31:20.030 --> 00:31:23.040
a clue what they were doing.

00:31:23.040 --> 00:31:24.540
And so we have to
face what we might

00:31:24.540 --> 00:31:30.280
call the I can't see the woods
for the trees phenomenon.

00:31:30.280 --> 00:31:33.740
There were levels of
granularity or insularity,

00:31:33.740 --> 00:31:37.790
people who knew a little bit,
but only a few people who

00:31:37.790 --> 00:31:39.980
pretty well knew
the whole thing.

00:31:39.980 --> 00:31:44.060
The bird's eye view was
had by General Leslie

00:31:44.060 --> 00:31:46.110
Groves and a few others.

00:31:46.110 --> 00:31:47.510
And we can compare
that to, as it

00:31:47.510 --> 00:31:50.630
were, the termites' view,
which is most of the work force

00:31:50.630 --> 00:31:53.680
there had.

00:31:53.680 --> 00:31:56.520
And the interesting thing is
that in the termite colony,

00:31:56.520 --> 00:32:02.740
no termite or junta of top
termites sees the woods at all.

00:32:02.740 --> 00:32:04.640
They just see the trees
they're working on.

00:32:07.990 --> 00:32:09.460
And of course,
one effect of that

00:32:09.460 --> 00:32:14.020
is that redesign
is achingly slow.

00:32:14.020 --> 00:32:18.250
Takes evolutionary time
to get the termites

00:32:18.250 --> 00:32:23.278
to do something else, because
there's nobody there that can--

00:32:23.278 --> 00:32:26.130
to take a term from
good old-fashioned AI,

00:32:26.130 --> 00:32:28.180
there's nobody there
who can do the blame

00:32:28.180 --> 00:32:29.829
assignment and the
credit assignment

00:32:29.829 --> 00:32:32.120
that you need to figure out
why the thing doesn't work.

00:32:32.120 --> 00:32:36.871
They can't reverse engineer
their own engineer system,

00:32:36.871 --> 00:32:37.870
which is what we can do.

00:32:41.680 --> 00:32:44.910
Another effect is
with no boss, there's

00:32:44.910 --> 00:32:47.740
no issue of what the
boss has access to,

00:32:47.740 --> 00:32:50.970
to use a term from philosophy.

00:32:50.970 --> 00:32:54.287
So there's no reason to
posit access consciousness

00:32:54.287 --> 00:32:54.870
to the colony.

00:32:58.617 --> 00:33:00.200
In other words, it's
not like anything

00:33:00.200 --> 00:33:02.780
to be a termite colony.

00:33:02.780 --> 00:33:05.155
Maybe like something
to be a termite.

00:33:05.155 --> 00:33:06.530
But I think you'd
probably agree.

00:33:06.530 --> 00:33:09.560
It's not like anything
to be a termite colony,

00:33:09.560 --> 00:33:15.070
because there's no organisation
that gives access of any kind,

00:33:15.070 --> 00:33:18.130
bird's eye view or otherwise,
to what's going on below.

00:33:18.130 --> 00:33:20.290
Doesn't have to be.

00:33:20.290 --> 00:33:21.900
So I can't prove that.

00:33:21.900 --> 00:33:26.660
I think it's a highly
probable proposition.

00:33:26.660 --> 00:33:28.121
And if you doubt
it, you might want

00:33:28.121 --> 00:33:29.870
to consider questions
like what is it like

00:33:29.870 --> 00:33:33.320
to be the Seattle Seahawks?

00:33:33.320 --> 00:33:36.590
Not individual players on
the team, but the team.

00:33:36.590 --> 00:33:38.910
Probably you'd say, no,
it's not like anything.

00:33:38.910 --> 00:33:40.290
It's a bunch of individuals.

00:33:40.290 --> 00:33:43.970
They may be very well organised,
but it's not like anything

00:33:43.970 --> 00:33:45.640
to be the team.

00:33:45.640 --> 00:33:49.835
And it's not like anything
to be a termite colony, which

00:33:49.835 --> 00:33:51.710
would seem to lead to
the conclusion it's not

00:33:51.710 --> 00:33:54.950
like anything to have a
brain or to be a brain.

00:33:54.950 --> 00:33:56.450
What is it like to
be a human brain

00:33:56.450 --> 00:33:58.220
would seem to give
the same answer.

00:33:58.220 --> 00:34:01.740
But then, it sure seems
to be like something.

00:34:01.740 --> 00:34:03.350
It's an important
and obvious fact.

00:34:03.350 --> 00:34:05.930
There's no General Leslie
Groves in your brain.

00:34:09.090 --> 00:34:10.350
And yet there seems to be.

00:34:13.429 --> 00:34:17.330
Certainly, it seems to be
like something to be you

00:34:17.330 --> 00:34:22.989
and that you that it seems to
be like something is in charge.

00:34:22.989 --> 00:34:26.560
So now, we have the question,
how can we explain that there

00:34:26.560 --> 00:34:31.060
seems to be a General
Leslie Groves in your brain,

00:34:31.060 --> 00:34:34.420
when there isn't?

00:34:34.420 --> 00:34:37.830
This is the view
that is often called,

00:34:37.830 --> 00:34:40.399
or today often
called, illusionism,

00:34:40.399 --> 00:34:42.250
that the whole idea
that consciousness

00:34:42.250 --> 00:34:44.620
is a sort of useful illusion.

00:34:44.620 --> 00:34:51.730
And I see by reviews today in
the New Statesman, an otherwise

00:34:51.730 --> 00:34:54.030
very, very friendly
and positive review,

00:34:54.030 --> 00:34:56.770
but the reviewer
just thinks this idea

00:34:56.770 --> 00:34:59.240
that consciousness is
some kind of illusion,

00:34:59.240 --> 00:35:01.370
it's just hopeless.

00:35:01.370 --> 00:35:03.040
Well, I beg to differ.

00:35:03.040 --> 00:35:04.540
But that's a long
story, and I'm not

00:35:04.540 --> 00:35:07.240
going to be able to spend
a whole lot of time on it.

00:35:07.240 --> 00:35:09.700
I've given you a hint about
what the answer might be.

00:35:12.850 --> 00:35:15.260
So if we compare the
organisation of Oak Ridge

00:35:15.260 --> 00:35:18.480
to the organisation
of the mind, brain,

00:35:18.480 --> 00:35:21.910
and we compare it and GOFAI,
one of the things we see in this

00:35:21.910 --> 00:35:25.030
diagram, we see you
have all these parts.

00:35:25.030 --> 00:35:27.920
I can't leave it up there
while I ask my questions.

00:35:27.920 --> 00:35:33.430
Does the LAD know its job is
acquiring a natural language?

00:35:33.430 --> 00:35:35.590
No.

00:35:35.590 --> 00:35:39.070
Does the belief box
understand its role

00:35:39.070 --> 00:35:40.900
in informing the
other departments?

00:35:40.900 --> 00:35:42.820
No.

00:35:42.820 --> 00:35:48.250
Only the AI designers know
the functions of the parts.

00:35:48.250 --> 00:35:53.170
The intelligent designers
off on the side.

00:35:53.170 --> 00:35:56.240
GOFAI is a top-down
intelligent design.

00:35:59.080 --> 00:36:05.550
Now, this is not the
threadbare criticism

00:36:05.550 --> 00:36:09.910
that everything
these AI systems know

00:36:09.910 --> 00:36:12.270
is what the creators
installed in them.

00:36:12.270 --> 00:36:13.500
No.

00:36:13.500 --> 00:36:15.420
Garbage in, garbage out.

00:36:15.420 --> 00:36:18.540
Nothing in the programme that
isn't known by the programme

00:36:18.540 --> 00:36:19.110
creators.

00:36:19.110 --> 00:36:20.460
That's just not true.

00:36:20.460 --> 00:36:23.520
Even of those systems
it wasn't true.

00:36:23.520 --> 00:36:25.950
Many of those systems go
way beyond their creators

00:36:25.950 --> 00:36:28.110
in what they know.

00:36:28.110 --> 00:36:30.960
This is a point that the
design of the architecture that

00:36:30.960 --> 00:36:35.210
supports this knowledge
is top-down design.

00:36:35.210 --> 00:36:38.570
It's hierarchical and efficient.

00:36:38.570 --> 00:36:45.160
So actually that's just the
first kind of computer phobia

00:36:45.160 --> 00:36:51.970
that I wanted to try to alert
you to and suggest a runaround.

00:36:51.970 --> 00:36:53.920
Yes, our brains are
computers, but they're

00:36:53.920 --> 00:36:57.666
more like termite colonies
than like your laptop.

00:36:57.666 --> 00:36:58.540
And that's all right.

00:36:58.540 --> 00:37:03.810
They can still be
computers, because

00:37:03.810 --> 00:37:05.550
competitive
architectures are still

00:37:05.550 --> 00:37:07.260
computational architectures.

00:37:10.140 --> 00:37:12.270
The next source
of computer phobia

00:37:12.270 --> 00:37:15.810
is, but the mind isn't software.

00:37:15.810 --> 00:37:19.260
And I have to admit that
even some of my best friends

00:37:19.260 --> 00:37:22.980
think I'm nuts on this score,
among them Steve Pinker

00:37:22.980 --> 00:37:25.200
and Paul Churchland.

00:37:25.200 --> 00:37:27.790
But they haven't convinced me.

00:37:27.790 --> 00:37:34.950
And I'm going to defend the idea
that, in fact, our minds are

00:37:34.950 --> 00:37:40.440
software running on that
termite colony brain.

00:37:40.440 --> 00:37:43.059
And it's the software
that distinguishes us

00:37:43.059 --> 00:37:43.850
from other animals.

00:37:46.960 --> 00:37:50.020
First of all, let's get rid
of some obsolete objections.

00:37:50.020 --> 00:37:52.600
Where are the floppy discs?

00:37:52.600 --> 00:37:55.450
The brain doesn't have
RAM, and the CPU software

00:37:55.450 --> 00:37:57.520
consists of bit strings.

00:37:57.520 --> 00:38:01.450
Software is hardware specific
at the level of compiled code.

00:38:01.450 --> 00:38:02.950
Yeah, yeah, yeah, yeah.

00:38:02.950 --> 00:38:05.789
That's not what
I'm talking about.

00:38:05.789 --> 00:38:07.747
I'm talking about something
a little different.

00:38:11.860 --> 00:38:17.090
I'm talking about something
more like Java applets.

00:38:17.090 --> 00:38:18.592
What's a Java applet?

00:38:18.592 --> 00:38:19.550
You use them every day.

00:38:19.550 --> 00:38:22.770
You don't know it probably.

00:38:22.770 --> 00:38:25.370
They're apps.

00:38:25.370 --> 00:38:26.450
Or they're like apps.

00:38:26.450 --> 00:38:30.020
They run on your hardware.

00:38:30.020 --> 00:38:34.100
And they can be written
by a software designer who

00:38:34.100 --> 00:38:36.700
doesn't need to know what
kind of hardware you have,

00:38:36.700 --> 00:38:41.270
whether you're running it on
a cell phone, or on a Mac,

00:38:41.270 --> 00:38:45.750
or on an IBM computer, or a
Linux computer, on Windows,

00:38:45.750 --> 00:38:47.975
or Mountain Lion.

00:38:47.975 --> 00:38:48.725
It doesn't matter.

00:38:51.230 --> 00:38:55.470
It'll run, as they
say, on all platforms.

00:38:55.470 --> 00:38:58.640
That's not strictly true,
but on all that matter.

00:38:58.640 --> 00:39:01.030
It runs on lots of different--

00:39:01.030 --> 00:39:05.300
Java is a computer programming
language it runs on.

00:39:05.300 --> 00:39:08.720
You don't have to specify what
the underlying hardware is.

00:39:08.720 --> 00:39:11.460
Java takes care of that for you.

00:39:11.460 --> 00:39:13.760
So one who writes Java
applets has no need

00:39:13.760 --> 00:39:18.650
to know the fine
details of the hardware,

00:39:18.650 --> 00:39:23.270
because installed on your
hardware is something

00:39:23.270 --> 00:39:27.140
called the JVM, the
Java Virtual Machine.

00:39:27.140 --> 00:39:28.650
Now, that's software.

00:39:28.650 --> 00:39:30.800
But it's software
that is specifically

00:39:30.800 --> 00:39:34.040
designed to fit on the
hardware in question.

00:39:34.040 --> 00:39:36.770
And it protects that
hardware from malicious use,

00:39:36.770 --> 00:39:37.800
among other things.

00:39:37.800 --> 00:39:41.480
But it also permits Java
applets to be downloaded off

00:39:41.480 --> 00:39:47.068
the internet, for instance,
and run on your computer.

00:39:47.068 --> 00:39:52.570
Now, I want to draw
your attention.

00:39:52.570 --> 00:39:56.920
So the Java virtual machine has
to be installed before the Java

00:39:56.920 --> 00:39:59.600
applet will run.

00:39:59.600 --> 00:40:03.730
In fact, the Java virtual
machine on your cell phone

00:40:03.730 --> 00:40:09.880
or on your laptop has probably
been updated several times

00:40:09.880 --> 00:40:13.630
in the last week without
you even knowing it.

00:40:13.630 --> 00:40:15.220
You've gone online
to get something,

00:40:15.220 --> 00:40:19.750
and you need a new
version of Java VM.

00:40:19.750 --> 00:40:21.782
And so it's
automatically downloaded

00:40:21.782 --> 00:40:22.990
from whatever site you're on.

00:40:22.990 --> 00:40:26.310
And it takes care
of the problem.

00:40:26.310 --> 00:40:29.740
How many of you had a message
come on your screen say,

00:40:29.740 --> 00:40:35.830
will you accept a Java update?

00:40:35.830 --> 00:40:38.890
Some people set their machines
to make sure that they always

00:40:38.890 --> 00:40:40.240
know when that's happening.

00:40:40.240 --> 00:40:42.820
But in general, you don't know.

00:40:42.820 --> 00:40:44.860
So now, I want to draw
attention to this.

00:40:44.860 --> 00:40:48.490
One who writes Java
applets has no need

00:40:48.490 --> 00:40:56.010
to know the fine
details of the hardware.

00:40:56.010 --> 00:40:59.180
Now, what's the
importance of that?

00:40:59.180 --> 00:41:01.820
What am I doing right now?

00:41:01.820 --> 00:41:04.960
I'm talking to you all.

00:41:04.960 --> 00:41:07.630
Each of you has installed
a version of the EVM

00:41:07.630 --> 00:41:10.270
on your neck-top.

00:41:10.270 --> 00:41:13.180
That's the English
virtual machine.

00:41:13.180 --> 00:41:15.730
I don't have to know the
details of the hardware

00:41:15.730 --> 00:41:17.510
between your ears.

00:41:17.510 --> 00:41:19.870
I can count on the fact
that you have the EVM,

00:41:19.870 --> 00:41:22.810
and so you can run
the code that I'm

00:41:22.810 --> 00:41:24.350
downloading to you as we speak.

00:41:24.350 --> 00:41:26.290
Now, that's, of course,
an oversimplification.

00:41:26.290 --> 00:41:29.570
But the main idea is the
one that I want to stress,

00:41:29.570 --> 00:41:34.840
is that the beauty
of having language

00:41:34.840 --> 00:41:39.670
is it permits us to share
ways of doing things

00:41:39.670 --> 00:41:42.790
that we wouldn't otherwise
be able to share,

00:41:42.790 --> 00:41:44.650
because we can tell
each other about them.

00:41:44.650 --> 00:41:47.530
Of course, you can also
show people without telling.

00:41:47.530 --> 00:41:50.980
But the capacity to
talk is really important

00:41:50.980 --> 00:41:54.820
to make a culture cumulative.

00:41:54.820 --> 00:41:57.100
These are thinking tools.

00:41:57.100 --> 00:42:00.280
Words are a good example
of thinking tools.

00:42:00.280 --> 00:42:03.760
Each word is its own little
tool, a way of doing something,

00:42:03.760 --> 00:42:06.120
a way of referring to something,
remembering something,

00:42:06.120 --> 00:42:10.830
labelling something, et cetera,
and a way of pronouncing

00:42:10.830 --> 00:42:11.920
something.

00:42:11.920 --> 00:42:16.060
And I love the line from
Goethe, "when ideas fail,

00:42:16.060 --> 00:42:19.910
words come in very handy."

00:42:19.910 --> 00:42:22.810
That's important to
remember, that sometimes you

00:42:22.810 --> 00:42:25.420
can use a word to great
effect without really having

00:42:25.420 --> 00:42:27.700
much of an idea what it means.

00:42:27.700 --> 00:42:31.010
And sometimes, that's
actually useful.

00:42:31.010 --> 00:42:35.380
Other thinking tools are
numbers, diagrams, maps,

00:42:35.380 --> 00:42:39.460
methods, and intuition pumps.

00:42:39.460 --> 00:42:44.944
My last book was a collection
of more than 70 thinking tools,

00:42:44.944 --> 00:42:46.860
most of them were what
I call intuition pumps.

00:42:46.860 --> 00:42:49.130
They're a little fancier
than an individual word.

00:42:49.130 --> 00:42:52.360
They're a way of thinking
about something, which

00:42:52.360 --> 00:42:56.570
is worth adding to your kit.

00:42:56.570 --> 00:43:00.080
Notice, by the way, that
what I've just done right now

00:43:00.080 --> 00:43:03.589
is I've downloaded an
app to your neck-top.

00:43:03.589 --> 00:43:05.130
If you didn't have
it before, you now

00:43:05.130 --> 00:43:10.650
have the idea of words
and other cultural items

00:43:10.650 --> 00:43:12.840
being like apps
that are downloaded

00:43:12.840 --> 00:43:15.570
to your neck-tops, where they
can give you new competences

00:43:15.570 --> 00:43:18.850
that you didn't have
before, in exactly the way

00:43:18.850 --> 00:43:22.410
your cell phone or your laptop
can pick up new competences

00:43:22.410 --> 00:43:24.870
by downloading software.

00:43:24.870 --> 00:43:29.520
I think it's actually a very
significant and deep parallel.

00:43:29.520 --> 00:43:31.260
There's lots of reasons.

00:43:31.260 --> 00:43:37.390
There's lots of disanalogies
worth enumerating

00:43:37.390 --> 00:43:39.360
and considering.

00:43:39.360 --> 00:43:40.945
Any rate, I've
given you the app.

00:43:40.945 --> 00:43:41.820
You're stuck with it.

00:43:45.090 --> 00:43:46.770
And it's what makes
possible what I've

00:43:46.770 --> 00:43:50.700
called the MacCready Explosion.

00:43:50.700 --> 00:43:55.200
You remember the eukaryotic
revolution led pretty soon

00:43:55.200 --> 00:43:57.300
to what's known as the
Cambrian Explosion, which

00:43:57.300 --> 00:44:01.740
was a incredible diversity
of life that grew out

00:44:01.740 --> 00:44:09.120
of the rise of the eukaryotic
cell, which itself arose when

00:44:09.120 --> 00:44:13.260
two prokaryotic cells
bumped into each other

00:44:13.260 --> 00:44:16.290
and decided neither
one ate the other

00:44:16.290 --> 00:44:18.790
or disassembled the other.

00:44:18.790 --> 00:44:22.830
In fact, they joined forces and
became a more powerful thing.

00:44:22.830 --> 00:44:25.290
That was the first great
technology transfer

00:44:25.290 --> 00:44:26.940
in the history of evolution.

00:44:26.940 --> 00:44:29.850
The second was much more recent.

00:44:29.850 --> 00:44:31.740
It was when our
brains began to be

00:44:31.740 --> 00:44:37.140
invaded by memes, another
great technology transfer.

00:44:37.140 --> 00:44:40.740
You didn't have to invent
the wheel yourself.

00:44:40.740 --> 00:44:42.224
You got that for free.

00:44:42.224 --> 00:44:43.140
It was in the culture.

00:44:43.140 --> 00:44:46.530
You didn't have to invent
calculus or cost benefit

00:44:46.530 --> 00:44:49.500
analysis or French or English.

00:44:49.500 --> 00:44:51.180
You didn't have to
invent any of those.

00:44:51.180 --> 00:44:54.790
The software was already
available and almost free.

00:44:54.790 --> 00:44:59.230
All you have to do, download
it to your neck-top.

00:44:59.230 --> 00:45:03.750
So MacCready, the late, great
Paul MacCready calculates--

00:45:03.750 --> 00:45:09.840
calculated, died recently--
that if you go back 10,000 years

00:45:09.840 --> 00:45:13.320
to the dawn of
agriculture, and you

00:45:13.320 --> 00:45:16.260
put all the human beings,
plus all their pets,

00:45:16.260 --> 00:45:19.800
plus their livestock on
one side of the scale,

00:45:19.800 --> 00:45:22.050
and you put all
the other animals,

00:45:22.050 --> 00:45:26.550
terrestrial vertebrates on
the other side of the scale,

00:45:26.550 --> 00:45:33.720
10,000 years ago, the percentage
by mass of the humans,

00:45:33.720 --> 00:45:37.650
plus their domesticated
animals, he

00:45:37.650 --> 00:45:43.510
calculated at a fraction of 1%.

00:45:43.510 --> 00:45:45.760
So what is it today?

00:45:45.760 --> 00:45:47.820
Some of you have heard
me talk about this.

00:45:47.820 --> 00:45:50.500
Anybody hazard a guess?

00:45:50.500 --> 00:45:51.400
Is it 10%?

00:45:51.400 --> 00:45:53.470
20%?

00:45:53.470 --> 00:45:54.410
60%?

00:45:54.410 --> 00:45:56.450
80%?

00:45:56.450 --> 00:45:59.120
98%.

00:45:59.120 --> 00:46:04.040
We have swamped the
planet with our cattle

00:46:04.040 --> 00:46:07.130
and our other domesticated
animals and ourselves.

00:46:07.130 --> 00:46:12.200
This is one of the most vivid
and fast biological phenomena

00:46:12.200 --> 00:46:15.140
that's ever occurred in the
history of life on the planet.

00:46:15.140 --> 00:46:17.630
And it's taken only
10,000 years, which

00:46:17.630 --> 00:46:20.150
is just a eye blink of time.

00:46:24.330 --> 00:46:27.610
This is what MacCready
says about this.

00:46:27.610 --> 00:46:31.790
"Over billions of years,
on a unique sphere,

00:46:31.790 --> 00:46:40.130
chance has painted a
thin covering of life--

00:46:40.130 --> 00:46:45.470
complex, improbable,
wonderful, and fragile.

00:46:45.470 --> 00:46:52.080
Suddenly we humans have grown
in population, technology,

00:46:52.080 --> 00:46:55.320
and intelligence to a
position of terrible power.

00:46:55.320 --> 00:46:58.580
We now wield the paintbrush."

00:46:58.580 --> 00:47:02.300
Now, all this happened way
too fast to be due to genes.

00:47:02.300 --> 00:47:06.020
There have just not been enough
generations in the last 10,000

00:47:06.020 --> 00:47:11.270
years for there to be really
major revolutions in our genes.

00:47:11.270 --> 00:47:14.630
If you could time machine a
person from 10,000 years ago

00:47:14.630 --> 00:47:19.610
to today, they might have
some disease vulnerabilities

00:47:19.610 --> 00:47:20.540
that we don't have.

00:47:20.540 --> 00:47:23.622
But otherwise,
they'd do just fine.

00:47:23.622 --> 00:47:25.610
Give him a shave and a
haircut dress them up,

00:47:25.610 --> 00:47:28.994
and they'd pass for one of us.

00:47:28.994 --> 00:47:31.160
But I'll give you another
example, which some of you

00:47:31.160 --> 00:47:34.310
may know about, some of you
may not-- the Flynn effect.

00:47:34.310 --> 00:47:36.380
The Flynn effect
is perfectly real.

00:47:36.380 --> 00:47:42.260
And IQ is up just
in the last century.

00:47:42.260 --> 00:47:46.100
The average in 1932 would be 80.

00:47:46.100 --> 00:47:53.051
That is to say, IQ is on a
scale, so 100 is average.

00:47:53.051 --> 00:47:54.800
If you're above 100,
you're above average.

00:47:54.800 --> 00:47:57.570
If you're below 100,
you're below average.

00:47:57.570 --> 00:48:02.180
But if you give the very
same tests that people--

00:48:02.180 --> 00:48:06.150
where the average
was 100 just in 1932,

00:48:06.150 --> 00:48:09.320
you give the very same
test to people today,

00:48:09.320 --> 00:48:14.240
the people who scored 100
then would score 80 now.

00:48:14.240 --> 00:48:17.930
This is a robust, clear effect.

00:48:17.930 --> 00:48:20.090
We're getting smarter.

00:48:20.090 --> 00:48:21.260
And it's not due to genes.

00:48:21.260 --> 00:48:23.597
It cannot be due to genes.

00:48:23.597 --> 00:48:25.430
There hasn't been
anywhere near enough time.

00:48:31.375 --> 00:48:32.125
So what's changed?

00:48:36.710 --> 00:48:41.020
The short answer, you
can't do much carpentry

00:48:41.020 --> 00:48:43.510
with your bare hands.

00:48:43.510 --> 00:48:46.540
And you can't do much
thinking with your bare brain.

00:48:46.540 --> 00:48:48.270
That was something
that my friend Bo

00:48:48.270 --> 00:48:49.510
Dahlbom said a few years ago.

00:48:49.510 --> 00:48:51.190
I thought, boy, that nails it.

00:48:51.190 --> 00:48:53.530
You can't do much carpentry
with your bare hands.

00:48:53.530 --> 00:48:56.770
You can't do much thinking
with your bare brain.

00:48:56.770 --> 00:48:59.680
A termite colony
is a bare brain.

00:48:59.680 --> 00:49:07.500
Gaudi had a well-equipped
brain, full of thinking tools.

00:49:07.500 --> 00:49:10.470
And where did he get his tools?

00:49:10.470 --> 00:49:15.690
Well, here's the wrong answer,
coming from Freeman Dyson.

00:49:15.690 --> 00:49:19.530
"Technology is a gift of God.

00:49:19.530 --> 00:49:21.450
After the gift of
life, it is perhaps

00:49:21.450 --> 00:49:23.680
the greatest of God's gifts.

00:49:23.680 --> 00:49:26.610
It is the mother of
civilizations, of arts,

00:49:26.610 --> 00:49:29.220
and of sciences."

00:49:29.220 --> 00:49:33.360
Everything but the first
sentence I heartily endorse.

00:49:33.360 --> 00:49:35.250
But come on, Freeman.

00:49:35.250 --> 00:49:39.630
Technology is not a gift of God.

00:49:39.630 --> 00:49:43.040
So the long answer is
that cultural evolution

00:49:43.040 --> 00:49:45.420
designed thinking
tools that impose

00:49:45.420 --> 00:49:48.000
novel structures on our brains.

00:49:48.000 --> 00:49:50.520
These are evolved
virtual machines.

00:49:50.520 --> 00:49:52.170
Virtual machines are
machines made out

00:49:52.170 --> 00:49:58.170
of information, ways of doing
things on your neck-top.

00:49:58.170 --> 00:50:00.140
And this leads to a
chicken and egg puzzle.

00:50:04.220 --> 00:50:07.220
Did evolved mind
tools make us smarter?

00:50:07.220 --> 00:50:12.200
Or did we evolve to become
smart enough to make mind tools?

00:50:12.200 --> 00:50:14.400
And as usual with
chicken and egg problems,

00:50:14.400 --> 00:50:15.215
the answer is yes.

00:50:20.810 --> 00:50:25.700
The effect, though, of human
culture, which started slow

00:50:25.700 --> 00:50:30.830
and then sped up greatly, is
that human cultural evolution

00:50:30.830 --> 00:50:32.960
has itself evolved.

00:50:32.960 --> 00:50:37.270
And I owe the next slide
to my friend, Matt Ridley.

00:50:37.270 --> 00:50:39.350
it's his slide, which I do love.

00:50:43.490 --> 00:50:48.870
On the left, you see
an actual hand axe.

00:50:48.870 --> 00:50:57.030
Our ancestors made these without
any apparent change in design

00:50:57.030 --> 00:51:01.470
for a million years.

00:51:01.470 --> 00:51:04.190
On the right is a mouse.

00:51:07.540 --> 00:51:11.440
It was designed by
Douglas Engelbart.

00:51:11.440 --> 00:51:13.150
And it's on the
verge of extinction

00:51:13.150 --> 00:51:15.875
after only a few decades in use.

00:51:19.260 --> 00:51:24.970
That's a nice measure of the
speed of cultural evolution.

00:51:24.970 --> 00:51:29.220
So if we think of our minds
as software, if we think

00:51:29.220 --> 00:51:32.700
of words as virtual machines--

00:51:32.700 --> 00:51:33.810
well, why not?

00:51:33.810 --> 00:51:37.290
Well, what is a word made of?

00:51:37.290 --> 00:51:38.790
Sounds?

00:51:38.790 --> 00:51:40.420
Ink?

00:51:40.420 --> 00:51:42.180
No, no, no, no.

00:51:42.180 --> 00:51:44.970
Words are more
abstract than that.

00:51:44.970 --> 00:51:47.910
My colleague Ray Jackendoff
in his wonderful book,

00:51:47.910 --> 00:51:52.710
Foundations of Language, says
that words are semi-autonomous

00:51:52.710 --> 00:51:55.890
informational structures--

00:51:55.890 --> 00:51:59.580
sounds like software to me--

00:51:59.580 --> 00:52:03.540
with multiple roles
to play in cognition.

00:52:03.540 --> 00:52:05.790
That's what a word is.

00:52:05.790 --> 00:52:09.120
And just the way you can copy
software and move it around

00:52:09.120 --> 00:52:14.160
to other platforms, so you
can do the same with words.

00:52:14.160 --> 00:52:16.770
Think of the diversity of words.

00:52:16.770 --> 00:52:19.290
Tens of thousands of words
in many different languages--

00:52:19.290 --> 00:52:22.140
where did they all come from?

00:52:22.140 --> 00:52:26.790
In thousands of languages, could
they have a common ancestor?

00:52:26.790 --> 00:52:27.630
Yeah, they could.

00:52:30.430 --> 00:52:32.860
In fact, there's
interesting attempts

00:52:32.860 --> 00:52:35.320
to trace back, trace
back, trace back

00:52:35.320 --> 00:52:38.470
to find a common ancestor of
even the most diverse languages

00:52:38.470 --> 00:52:39.730
on the planet.

00:52:39.730 --> 00:52:41.380
This is all controversial.

00:52:41.380 --> 00:52:43.900
And of course, there's
no written records there,

00:52:43.900 --> 00:52:45.790
so it has to be
very conjectural.

00:52:45.790 --> 00:52:49.530
But at least we can trace
back a lot of the languages

00:52:49.530 --> 00:52:55.380
a very long way and
know that they evolved,

00:52:55.380 --> 00:52:58.090
that the words in them
evolved from those languages

00:52:58.090 --> 00:53:01.930
and often jumped
to other languages.

00:53:01.930 --> 00:53:05.094
Did those words have
intelligent designers?

00:53:05.094 --> 00:53:07.460
No.

00:53:07.460 --> 00:53:10.660
Words are brilliantly designed.

00:53:10.660 --> 00:53:16.660
They're great, infectious,
replicable, complex

00:53:16.660 --> 00:53:19.710
informational structures.

00:53:19.710 --> 00:53:24.730
But they're designed by
natural selection, not

00:53:24.730 --> 00:53:29.470
genetic natural selection, but
cultural natural selection.

00:53:29.470 --> 00:53:32.260
You don't get your
words with your genes.

00:53:32.260 --> 00:53:37.690
You move a baby born to
Chinese parents to London,

00:53:37.690 --> 00:53:43.900
and that baby is going to
learn English, not Chinese.

00:53:43.900 --> 00:53:45.670
Words have evolved.

00:53:45.670 --> 00:53:50.600
Darwin himself noted
that in a famous passage.

00:53:50.600 --> 00:53:54.020
He saw a striking resemblance
between the lineages

00:53:54.020 --> 00:53:57.050
of words and languages
and the theme

00:53:57.050 --> 00:54:01.100
that he was developing
in The Origin of Species.

00:54:01.100 --> 00:54:04.340
So we have phylogenetic
trees like the tree of life.

00:54:04.340 --> 00:54:06.290
And we have glossogenetic
trees, which

00:54:06.290 --> 00:54:09.940
show the evolution
of languages--

00:54:09.940 --> 00:54:12.830
the Romance language coming
from Latin, for instance.

00:54:12.830 --> 00:54:15.200
I don't need to
show those to you.

00:54:15.200 --> 00:54:16.760
So now, then, what is a meme?

00:54:19.550 --> 00:54:22.520
The other day I went and
looked on the online Collins

00:54:22.520 --> 00:54:27.410
dictionary and got
a rude awakening.

00:54:27.410 --> 00:54:33.440
"A meme is something such as
a video, picture, or phrase

00:54:33.440 --> 00:54:37.360
that a lot of people sent to
each other on the internet."

00:54:39.920 --> 00:54:45.890
Goes on, "short for mimeme,
both coined by R Dawkins, 1941,

00:54:45.890 --> 00:54:47.040
British biologist?"

00:54:52.730 --> 00:54:55.860
Not the best source
of information.

00:54:55.860 --> 00:54:58.460
But indeed, the word was
coined by Richard Dawkins,

00:54:58.460 --> 00:55:04.350
the author of The Selfish
Gene, in his book in 1976.

00:55:04.350 --> 00:55:06.720
And one thing that's clear
is that the meme meme

00:55:06.720 --> 00:55:07.475
has gone viral.

00:55:10.310 --> 00:55:16.010
Just a few days ago, on the
television show Jeopardy,

00:55:16.010 --> 00:55:19.700
an America quiz show,
the very same quiz show

00:55:19.700 --> 00:55:26.360
in which IBM's Watson beat
the human best contestants

00:55:26.360 --> 00:55:29.660
of all times handily--

00:55:29.660 --> 00:55:33.740
on Jeopardy, the term is used
without mention of Dawkins

00:55:33.740 --> 00:55:36.380
and without definition
for the contestants.

00:55:36.380 --> 00:55:38.660
So they had a whole
board of questions

00:55:38.660 --> 00:55:40.274
about different kinds of memes.

00:55:40.274 --> 00:55:41.690
I'm not going to
give you a chance

00:55:41.690 --> 00:55:45.080
to look at all those categories.

00:55:45.080 --> 00:55:46.970
And nobody said
boo about the fact

00:55:46.970 --> 00:55:52.100
that here the categories
were all memes.

00:55:52.100 --> 00:55:56.086
Is this what Dawkins meant when
he coined the term in 1976?

00:55:56.086 --> 00:55:58.610
Uh, no.

00:55:58.610 --> 00:55:59.510
Not at all.

00:55:59.510 --> 00:56:03.590
But I want to compare it
to another scientific term,

00:56:03.590 --> 00:56:05.780
the Big Bang.

00:56:05.780 --> 00:56:10.100
I went online to check
the Big Bang, which,

00:56:10.100 --> 00:56:15.560
of course, was coined by Fred
Hoyle a few years earlier,

00:56:15.560 --> 00:56:17.190
astronomer.

00:56:17.190 --> 00:56:19.940
And what I found was
that the first few pages

00:56:19.940 --> 00:56:23.510
of Google on Big Bang Theory
were about the television

00:56:23.510 --> 00:56:25.700
sitcom.

00:56:25.700 --> 00:56:28.160
Had to go to third page
before I got anything

00:56:28.160 --> 00:56:33.840
about Fred Hoyle and the
origins of the universe.

00:56:33.840 --> 00:56:40.826
So "the Big Bang" still
means what Hoyle meant.

00:56:40.826 --> 00:56:42.200
The question is
does "meme" still

00:56:42.200 --> 00:56:46.230
mean what Dawkins meant
when he coined the term?

00:56:46.230 --> 00:56:51.230
Well, let's look at Dawkins
version very quickly.

00:56:51.230 --> 00:56:53.330
He says, "I think that
a new kind of replicator

00:56:53.330 --> 00:56:56.280
has recently emerged
on this very planet.

00:56:56.280 --> 00:56:57.690
It is staring us in the face.

00:56:57.690 --> 00:57:01.220
It is still in its infancy,
still drifting clumsily

00:57:01.220 --> 00:57:03.440
in its primaeval soup.

00:57:03.440 --> 00:57:06.200
But already it's achieving
evolutionary change

00:57:06.200 --> 00:57:10.100
at a rate which leaves the
old gene panting far behind.

00:57:10.100 --> 00:57:12.290
The raw soup is the
soup of human culture."

00:57:15.040 --> 00:57:17.020
Well, now, what
do internet memes

00:57:17.020 --> 00:57:20.650
have to do with evolution
by natural selection?

00:57:20.650 --> 00:57:22.780
So has Dawkins'
term been hijacked?

00:57:25.630 --> 00:57:29.994
Has this meaning of
meme gone extinct?

00:57:29.994 --> 00:57:31.660
Many, especially those
in the humanities

00:57:31.660 --> 00:57:35.960
who hate the the idea of memes,
fervently hope so, I think.

00:57:35.960 --> 00:57:40.180
And they think this was
a suitably, fittingly

00:57:40.180 --> 00:57:45.270
unrespectable demise
of an abhorrent idea.

00:57:45.270 --> 00:57:46.472
Well, really?

00:57:46.472 --> 00:57:47.430
What's so bad about it?

00:57:47.430 --> 00:57:51.000
What's not to like in
the idea of a meme?

00:57:51.000 --> 00:57:52.590
To see why so many
are opposed to it,

00:57:52.590 --> 00:57:57.510
we must look at the key features
of Dawkins' concept of memes.

00:57:57.510 --> 00:57:59.580
Memes are replicators
like genes.

00:57:59.580 --> 00:58:02.820
Culture evolves by a process
of blind, purposeless,

00:58:02.820 --> 00:58:08.280
foresightless natural selection,
not by intelligent design.

00:58:08.280 --> 00:58:11.030
And differential
replication or reproduction

00:58:11.030 --> 00:58:14.020
is the key, not human genius.

00:58:14.020 --> 00:58:15.270
That's what people don't like.

00:58:15.270 --> 00:58:18.510
They don't like the idea
that human culture is not

00:58:18.510 --> 00:58:22.650
to be due to the authorship of
human geniuses over the age.

00:58:22.650 --> 00:58:25.860
That's one of the things
they don't like about it.

00:58:25.860 --> 00:58:28.110
Well, you see, internet
memes have authors.

00:58:28.110 --> 00:58:31.510
They are intelligently
designed, some of them,

00:58:31.510 --> 00:58:34.320
by self-styled meme smiths.

00:58:34.320 --> 00:58:36.270
There are even
competitions to see who

00:58:36.270 --> 00:58:39.660
can design the most viral meme.

00:58:39.660 --> 00:58:43.560
This is intelligent design
run riot on the internet.

00:58:46.300 --> 00:58:49.270
Are these not such profound
differences from Dawkins' memes

00:58:49.270 --> 00:58:52.030
that they must count as a
different type or species

00:58:52.030 --> 00:58:52.990
altogether?

00:58:52.990 --> 00:58:54.670
No.

00:58:54.670 --> 00:58:57.710
And the key is in
the word "species."

00:58:57.710 --> 00:59:00.560
Let me explain.

00:59:00.560 --> 00:59:02.960
Are dinosaurs extinct?

00:59:02.960 --> 00:59:03.800
How many say so?

00:59:08.370 --> 00:59:11.530
No, they're not
extinct, in one sense.

00:59:11.530 --> 00:59:13.490
Birds are direct
descendants of dinosaurs.

00:59:13.490 --> 00:59:18.760
There's probably a few
hundred dinosaur descendants

00:59:18.760 --> 00:59:23.660
within 100 yards of where
we're sitting right now.

00:59:23.660 --> 00:59:25.700
They're not much
like the originals.

00:59:25.700 --> 00:59:28.370
But they are direct
descendants of the dinosaurs.

00:59:28.370 --> 00:59:33.050
That's well-established
biological fact.

00:59:33.050 --> 00:59:34.940
And it was a gradual
process, which,

00:59:34.940 --> 00:59:38.780
of course, is very important.

00:59:38.780 --> 00:59:43.640
Very gradual change
we can believe in.

00:59:43.640 --> 00:59:46.040
Well, now, the question
is, is culture different?

00:59:46.040 --> 00:59:48.680
Did culture evolve by
Darwinian processes?

00:59:48.680 --> 00:59:51.550
Or did it arrive by
some sort of Big Bang,

00:59:51.550 --> 00:59:54.800
the way Freeman Dyson suggested?

00:59:54.800 --> 00:59:57.140
And we want to put in
yet another gradualism.

00:59:57.140 --> 00:59:59.750
Cultural evolution
happened gradually.

00:59:59.750 --> 01:00:02.660
The first memes were
adopted unwittingly

01:00:02.660 --> 01:00:06.080
by hominids that didn't know
what they were doing or why.

01:00:06.080 --> 01:00:09.590
They were more like
termites, in this regard.

01:00:09.590 --> 01:00:12.950
Reflectiveness about
memes came much later.

01:00:12.950 --> 01:00:15.080
And what's happened is
the de-Darwinization

01:00:15.080 --> 01:00:16.340
of cultural evolution.

01:00:16.340 --> 01:00:21.560
It started very Darwinian, very,
very much like termite design.

01:00:21.560 --> 01:00:24.470
And it's become ever
more intelligent,

01:00:24.470 --> 01:00:29.330
as human culture has provided
ever greater bounties of tools

01:00:29.330 --> 01:00:32.030
for the intelligent designers
to put in their heads

01:00:32.030 --> 01:00:35.930
and then use to think
of intelligent designs.

01:00:35.930 --> 01:00:36.980
So memes.

01:00:36.980 --> 01:00:40.370
Dawkins' list included tunes,
ideas, catchphrases, clothes,

01:00:40.370 --> 01:00:45.100
fashions, ways of making
pots or building arches.

01:00:45.100 --> 01:00:49.600
So memes are ways
of doing things.

01:00:49.600 --> 01:00:53.860
The difference between memes
and instincts is simple.

01:00:53.860 --> 01:00:57.760
Instincts are ways that are
passed through the germ line,

01:00:57.760 --> 01:00:59.580
through the genes.

01:00:59.580 --> 01:01:03.000
Memes are ways that are passed
otherwise, perceptually,

01:01:03.000 --> 01:01:03.500
socially.

01:01:09.364 --> 01:01:11.030
At this point, I know
some people think,

01:01:11.030 --> 01:01:13.170
do memes even exist?

01:01:13.170 --> 01:01:15.370
I've encountered this often.

01:01:15.370 --> 01:01:18.000
Somebody will say, I don't
know if memes even exist.

01:01:18.000 --> 01:01:20.100
Prove to me that memes exist.

01:01:20.100 --> 01:01:23.880
They seem like flights
of fancy, just metaphors.

01:01:23.880 --> 01:01:25.890
Well, now, I want to
consider-- how many of you

01:01:25.890 --> 01:01:29.790
would accept this statement?

01:01:29.790 --> 01:01:32.440
Hands up those who agree.

01:01:32.440 --> 01:01:35.065
I don't see any hands going up.

01:01:35.065 --> 01:01:35.940
Well, what are words?

01:01:41.089 --> 01:01:42.880
Dogs are a kind of
mammal or a kind of pet.

01:01:42.880 --> 01:01:44.350
Words are a kind of what?

01:01:44.350 --> 01:01:46.330
Sound, sign, symbol?

01:01:46.330 --> 01:01:49.090
What they are is a kind of meme.

01:01:49.090 --> 01:01:50.000
What kind?

01:01:50.000 --> 01:01:52.890
The kind that can be pronounced.

01:01:52.890 --> 01:01:56.840
That's what distinguishes
them from all other memes.

01:01:56.840 --> 01:01:59.160
So they're items of
culture that spread

01:01:59.160 --> 01:02:01.560
by being reproduced,
differentially reproduced,

01:02:01.560 --> 01:02:04.020
sometimes with
changes or mutations.

01:02:04.020 --> 01:02:08.220
They form lineages, differential
replication, and extinction.

01:02:08.220 --> 01:02:13.200
Memes evolve just as animals
and plants and viruses do.

01:02:13.200 --> 01:02:15.480
Viruses aren't
alive, but they sure

01:02:15.480 --> 01:02:18.780
do evolve by natural selection.

01:02:18.780 --> 01:02:20.550
So you don't have to
be alive to evolve

01:02:20.550 --> 01:02:22.674
by natural selection, which
is a pretty good thing,

01:02:22.674 --> 01:02:24.930
because words aren't alive.

01:02:24.930 --> 01:02:27.145
But they evolved by
natural selection.

01:02:30.710 --> 01:02:33.980
Memes are not alive.

01:02:33.980 --> 01:02:35.630
They are subject to
natural selection.

01:02:35.630 --> 01:02:38.770
I have a phrase for
what viruses are.

01:02:38.770 --> 01:02:42.900
They're nucleic
acid with attitude.

01:02:42.900 --> 01:02:44.600
That means something
about their shape

01:02:44.600 --> 01:02:46.760
gives them the
power, the competence

01:02:46.760 --> 01:02:51.430
to provoke their own replication
when they get inside a cell.

01:02:51.430 --> 01:02:56.480
Memes are virtual machines,
software with attitude.

01:02:56.480 --> 01:02:59.502
They provoke their own
replication in various ways,

01:02:59.502 --> 01:03:00.335
for various reasons.

01:03:03.840 --> 01:03:07.512
They compete for transmission
and also for local influence.

01:03:07.512 --> 01:03:08.470
What are memes made of?

01:03:08.470 --> 01:03:09.642
They're made of information.

01:03:09.642 --> 01:03:11.100
I'm going to speed
up a little bit.

01:03:11.100 --> 01:03:12.805
I want to get to a punchline.

01:03:15.660 --> 01:03:17.740
People think genes
are made of DNA.

01:03:17.740 --> 01:03:19.110
No, no, no.

01:03:19.110 --> 01:03:25.260
Genes are the information
that are carried by DNA codes.

01:03:25.260 --> 01:03:28.640
Poems aren't made of ink.

01:03:28.640 --> 01:03:30.970
Right?

01:03:30.970 --> 01:03:34.390
You can send a poem to
somebody with some ink,

01:03:34.390 --> 01:03:38.530
but poems are not made of ink.

01:03:38.530 --> 01:03:40.990
And genes are not made
of DNA, although that's

01:03:40.990 --> 01:03:44.180
their normal vehicle
of expression,

01:03:44.180 --> 01:03:46.660
but not the only one.

01:03:46.660 --> 01:03:52.150
When you get your
genome coded, when

01:03:52.150 --> 01:03:54.670
you get your genome
sequenced, you

01:03:54.670 --> 01:03:58.580
get a list of A, C,
G, and T, so forth.

01:03:58.580 --> 01:04:00.840
Those are your genes
in a different medium.

01:04:04.300 --> 01:04:05.910
So words are the
best memes that we

01:04:05.910 --> 01:04:10.060
have that make good examples,
because they're countable.

01:04:10.060 --> 01:04:11.310
They have clear lineages.

01:04:11.310 --> 01:04:13.470
They mutate in meaning
and in pronunciation

01:04:13.470 --> 01:04:14.670
and grammatical role.

01:04:14.670 --> 01:04:18.180
And they compete
for space in brains,

01:04:18.180 --> 01:04:21.030
the way bacteria and viruses
compete for space in bodies.

01:04:24.320 --> 01:04:25.970
Well, if words are
the best memes,

01:04:25.970 --> 01:04:27.260
why didn't Dawkins say so?

01:04:27.260 --> 01:04:30.050
Well, in fact, he did say this.

01:04:30.050 --> 01:04:33.170
"The survival or preservation
of certain featured words

01:04:33.170 --> 01:04:38.070
in the struggle for existence
is natural selection."

01:04:38.070 --> 01:04:46.020
And that's Darwin sort of
prophesying Dawkins on memes.

01:04:46.020 --> 01:04:50.800
So words are brilliantly
designed, but not by us.

01:04:50.800 --> 01:04:54.820
Phonemes, one of
natural selection's most

01:04:54.820 --> 01:04:57.090
brilliant inventions--

01:04:57.090 --> 01:05:00.950
I'm going to pass over
this very swiftly.

01:05:00.950 --> 01:05:02.780
I think I've run out of time.

01:05:02.780 --> 01:05:05.020
But first of all,
I want you to ask,

01:05:05.020 --> 01:05:07.910
what counts for
replication in words?

01:05:07.910 --> 01:05:09.850
Is it physical similarity?

01:05:09.850 --> 01:05:12.640
Or is it something else?

01:05:12.640 --> 01:05:13.840
Is it physical resemblance?

01:05:13.840 --> 01:05:16.081
Well, let's look.

01:05:16.081 --> 01:05:23.170
Cat, cat, cat, cat, cat,
cat, cat, cat, cat, cat, cat.

01:05:23.170 --> 01:05:25.540
How similar were
those physical things?

01:05:25.540 --> 01:05:28.020
Not very.

01:05:28.020 --> 01:05:31.620
But they were all tokens
of the type "cat."

01:05:31.620 --> 01:05:34.860
And you recognise
them easily as such.

01:05:34.860 --> 01:05:38.660
That's because
they're digitised.

01:05:38.660 --> 01:05:43.420
They are orally
digitised as phonemes

01:05:43.420 --> 01:05:47.410
and orthographically digitised
as letters of the alphabet.

01:05:47.410 --> 01:05:51.220
And this is what makes
high fidelity transmission

01:05:51.220 --> 01:05:53.530
and replication in
culture possible,

01:05:53.530 --> 01:05:57.670
in the same way that the
four letter code of DNA

01:05:57.670 --> 01:06:00.460
permits the high fidelity
replication of living

01:06:00.460 --> 01:06:01.190
organisms.

01:06:09.050 --> 01:06:12.640
So if words are virtual
machines, who designed them?

01:06:12.640 --> 01:06:15.996
Evolution, cultural evolution.

01:06:15.996 --> 01:06:17.120
And how are they installed?

01:06:17.120 --> 01:06:20.440
They're installed by repetition.

01:06:20.440 --> 01:06:22.550
I'm going to go
over that quickly.

01:06:22.550 --> 01:06:24.350
Go in more detail in my book.

01:06:30.840 --> 01:06:32.370
How did cultural
evolution start?

01:06:32.370 --> 01:06:35.430
Well, we started with the
genetic information highway

01:06:35.430 --> 01:06:38.220
that is used by all lifeforms.

01:06:38.220 --> 01:06:40.470
And then, a second
information highway

01:06:40.470 --> 01:06:42.930
evolved by natural selection.

01:06:42.930 --> 01:06:45.390
And that was social learning.

01:06:45.390 --> 01:06:48.682
And when you have species
where the children hang around

01:06:48.682 --> 01:06:50.640
with their parents,
because they're dependent--

01:06:50.640 --> 01:06:53.400
they're altricial,
rather than precocial.

01:06:53.400 --> 01:06:56.280
Precocial species, they sort
of hit the ground running.

01:06:56.280 --> 01:06:58.140
If they need parental
care, then they're

01:06:58.140 --> 01:07:00.630
going to be hanging
around their parents.

01:07:00.630 --> 01:07:03.390
This gives opportunities
for information transfer

01:07:03.390 --> 01:07:06.750
that would not
otherwise be there.

01:07:06.750 --> 01:07:09.450
And social learning
is also abetted

01:07:09.450 --> 01:07:13.630
by other adaptations, some of
which are quite easy to see.

01:07:13.630 --> 01:07:16.270
Well, there's prolonged
infancy, which I just mentioned.

01:07:16.270 --> 01:07:17.940
And then, there's
imprinting on parents,

01:07:17.940 --> 01:07:24.670
which is also seen in
geese and ducks and birds,

01:07:24.670 --> 01:07:29.850
as Tinbergen and
Lorenz famously shown.

01:07:29.850 --> 01:07:36.100
But now, I want to show you
our nearest living relative.

01:07:36.100 --> 01:07:39.720
And I want to
compare her to her.

01:07:39.720 --> 01:07:43.630
What's the most
striking difference?

01:07:43.630 --> 01:07:45.515
The sclera, the
whites of the eyes.

01:07:48.510 --> 01:07:52.470
Why do we have the whites
of our eyes when our nearest

01:07:52.470 --> 01:07:56.960
neighbours and the
orangutans don't?

01:07:56.960 --> 01:08:02.350
Because it enhances the
capacity for gaze monitoring,

01:08:02.350 --> 01:08:06.050
for seeing where
mum's looking, which

01:08:06.050 --> 01:08:09.620
enhances the capacity for
shared attention, which

01:08:09.620 --> 01:08:12.950
is, by general agreement
now, among people working

01:08:12.950 --> 01:08:14.840
on learning and
cultural evolution,

01:08:14.840 --> 01:08:18.680
is a key feature of
transmission of information

01:08:18.680 --> 01:08:20.210
from parents to children.

01:08:20.210 --> 01:08:23.390
But once you got parent-children
information passing,

01:08:23.390 --> 01:08:27.740
then that's a highway that can
be parasitised, just the way

01:08:27.740 --> 01:08:32.450
the internet, which was
designed for transmitting

01:08:32.450 --> 01:08:35.479
classified information
about military projects,

01:08:35.479 --> 01:08:39.740
has been parasitised by
internet memes, pornography,

01:08:39.740 --> 01:08:43.850
all the rest of the things
that we use the internet for.

01:08:43.850 --> 01:08:46.460
So a second information
highway, once it's in place,

01:08:46.460 --> 01:08:49.630
it can be invaded in what
Boyd and Richerson, who

01:08:49.630 --> 01:08:52.700
are the leading theorists,
call oblique transmission.

01:08:52.700 --> 01:08:56.779
And they call these things
that are obliquely transmitted

01:08:56.779 --> 01:09:00.680
rogue cultural variants.

01:09:00.680 --> 01:09:06.229
Another word for rogue
cultural variants is memes.

01:09:06.229 --> 01:09:10.460
They choose not to use the word
"meme" for various reasons.

01:09:10.460 --> 01:09:13.430
But that's what they are.

01:09:13.430 --> 01:09:16.490
Other theories of culture
need memes just as much

01:09:16.490 --> 01:09:20.510
as Dawkins' and mine, even if
they don't call them memes.

01:09:20.510 --> 01:09:23.120
They call them traditions
or methods or ideas or ways

01:09:23.120 --> 01:09:26.609
or non-genetically transmitted
adaptations and so forth.

01:09:26.609 --> 01:09:31.080
But they're all memes.

01:09:31.080 --> 01:09:33.520
Memes take advantage of the
information highways built

01:09:33.520 --> 01:09:37.750
by evolution for many species
and enhance in our species

01:09:37.750 --> 01:09:39.970
and our species only.

01:09:39.970 --> 01:09:44.260
Francis Crick once propounded
Orgel's second rule.

01:09:44.260 --> 01:09:47.996
Evolution is cleverer
than you are.

01:09:47.996 --> 01:09:49.870
Obviously, he doesn't
mean intelligent design

01:09:49.870 --> 01:09:52.930
with a capital I, D. He means
that evolution, a completely

01:09:52.930 --> 01:09:55.500
mindless, purposeless
process, nevertheless

01:09:55.500 --> 01:10:00.190
can generate designs
of cunning virtuosity

01:10:00.190 --> 01:10:04.120
and brilliant efficiency that
is hard for human engineers,

01:10:04.120 --> 01:10:06.310
human intelligent
designers to match.

01:10:08.950 --> 01:10:11.860
Well, intelligent
design now exists.

01:10:11.860 --> 01:10:16.900
We have people like,
oh, Bach and Turing

01:10:16.900 --> 01:10:21.400
and Gaudi, wonderful examples
of intelligent designers.

01:10:21.400 --> 01:10:24.580
And intelligent design is
becoming ever more intelligent,

01:10:24.580 --> 01:10:27.760
thanks to all the new
thinking tools that we're

01:10:27.760 --> 01:10:29.440
creating all the time.

01:10:29.440 --> 01:10:33.110
And this has some
surprising implications.

01:10:33.110 --> 01:10:36.340
So finally, I just want
to finish off this topic.

01:10:36.340 --> 01:10:38.200
So is this a
reductio ad absurdum?

01:10:38.200 --> 01:10:41.100
Internet memes, is this an
embarrassment to Dawkins?

01:10:41.100 --> 01:10:44.080
Is it a reductio ad absurdum
of his concept of memes?

01:10:44.080 --> 01:10:45.400
I don't think so.

01:10:45.400 --> 01:10:48.070
An intelligently designed meme
is a contradiction in terms?

01:10:48.070 --> 01:10:49.390
No.

01:10:49.390 --> 01:10:52.300
Or so what?

01:10:52.300 --> 01:10:54.910
Here's another
contradiction in terms.

01:10:54.910 --> 01:10:57.600
A splittable atom.

01:10:57.600 --> 01:11:02.020
After all, the word "atom"
originally means unspittable.

01:11:02.020 --> 01:11:04.420
We learned that you
can split an atom.

01:11:04.420 --> 01:11:06.440
We didn't change the term.

01:11:06.440 --> 01:11:10.330
And we learned that you can
intelligently design a meme.

01:11:10.330 --> 01:11:15.970
And they belong to the same
class, if not the same species,

01:11:15.970 --> 01:11:17.540
as the original memes.

01:11:17.540 --> 01:11:23.695
They're just evolved under
different evolutionary regimes.

01:11:26.540 --> 01:11:28.730
So internet memes are
actually prime examples

01:11:28.730 --> 01:11:29.810
of Dawkins' memes.

01:11:29.810 --> 01:11:32.360
They replicate because they
can, not because they're

01:11:32.360 --> 01:11:36.430
necessarily good for us, not
because they're good for us.

01:11:36.430 --> 01:11:42.050
And they have fitness
independent of ours.

01:11:42.050 --> 01:11:44.330
They spread so fast.

01:11:44.330 --> 01:11:46.610
Tell me if there's
anybody in this room who

01:11:46.610 --> 01:11:50.510
thinks that internet
memes are an enhancement

01:11:50.510 --> 01:11:52.790
to the genetic fitness of
the people that make them?

01:11:56.662 --> 01:11:59.270
You have another
thing coming if you

01:11:59.270 --> 01:12:01.460
think that's likely to be true.

01:12:01.460 --> 01:12:04.790
They're cultural junk,
not cultural treasure.

01:12:04.790 --> 01:12:06.930
Neither their authors nor
their vectors-- that is,

01:12:06.930 --> 01:12:08.480
those who spread them--

01:12:08.480 --> 01:12:12.832
need to understand why they are
doing what they're doing, just

01:12:12.832 --> 01:12:13.915
like spreading cold germs.

01:12:16.820 --> 01:12:20.160
One of my favourite examples
is the Polynesian canoe.

01:12:20.160 --> 01:12:23.120
In an article by
Rogers and Ehrlich,

01:12:23.120 --> 01:12:25.740
they quote a French philosopher.

01:12:25.740 --> 01:12:28.010
He was not writing
about Polynesian canoes,

01:12:28.010 --> 01:12:31.310
but, in fact, about
French fishing boats.

01:12:31.310 --> 01:12:33.520
And he says, "every boat is
copied from another boat.

01:12:33.520 --> 01:12:37.040
Let's reason as follows
in the manner of Darwin.

01:12:37.040 --> 01:12:40.370
It is clear that a
very badly made boat

01:12:40.370 --> 01:12:42.920
will end up on the bottom
after one or two voyages

01:12:42.920 --> 01:12:44.990
and thus never be copied.

01:12:44.990 --> 01:12:47.060
One could then say,
with complete rigour,

01:12:47.060 --> 01:12:51.670
that it is the sea herself
who fashions the boats,

01:12:51.670 --> 01:12:55.980
choosing those which function
and destroying the others."

01:12:55.980 --> 01:12:58.050
If it comes back, copy it.

01:12:58.050 --> 01:13:01.260
That's natural selection.

01:13:01.260 --> 01:13:03.870
The copiers don't have
to understand why it's

01:13:03.870 --> 01:13:05.520
a better boat than the others.

01:13:05.520 --> 01:13:10.690
They simply trust the
fact it came back.

01:13:10.690 --> 01:13:12.970
Don't fix what ain't broke.

01:13:12.970 --> 01:13:16.040
Copy it.

01:13:16.040 --> 01:13:17.960
So when we usually
think of culture,

01:13:17.960 --> 01:13:21.640
we think about the grand,
highest levels of culture,

01:13:21.640 --> 01:13:27.340
where we have the high culture--
opera and great art in museums

01:13:27.340 --> 01:13:31.000
and so forth, which we
spend good money to maintain

01:13:31.000 --> 01:13:31.720
and preserve.

01:13:31.720 --> 01:13:35.030
And we very carefully bequeath
it to the next generation,

01:13:35.030 --> 01:13:36.252
and so forth.

01:13:36.252 --> 01:13:37.960
But in addition to
all that great stuff--

01:13:37.960 --> 01:13:40.330
and that includes all the
science too, of course--

01:13:40.330 --> 01:13:42.160
there's all the junk.

01:13:42.160 --> 01:13:44.560
And it's just as much
a part of human culture

01:13:44.560 --> 01:13:46.050
as the high culture is.

01:13:46.050 --> 01:13:47.710
And we want to have
a perspective which

01:13:47.710 --> 01:13:54.280
treats all of the culture
in the same diagram,

01:13:54.280 --> 01:13:55.660
in the same picture.

01:13:55.660 --> 01:13:57.340
And that's what we can do.

01:13:57.340 --> 01:14:00.340
Memes have their own fitness.

01:14:00.340 --> 01:14:02.770
And the memes-eye view
provides a general perspective

01:14:02.770 --> 01:14:06.880
on cultural evolution,
not just on the treasures,

01:14:06.880 --> 01:14:09.340
and not just the things
noticed or valued,

01:14:09.340 --> 01:14:13.000
not just the actual inventions.

01:14:13.000 --> 01:14:15.070
We comprehend less
than we think.

01:14:15.070 --> 01:14:20.350
And that's one of the features
that I develop in the book.

01:14:20.350 --> 01:14:24.040
We don't need to comprehend
many of the things in culture

01:14:24.040 --> 01:14:25.990
that we benefit
from, in the same way

01:14:25.990 --> 01:14:30.374
that a butterfly with
eye spots on its wings

01:14:30.374 --> 01:14:32.290
doesn't need to understand
that this is really

01:14:32.290 --> 01:14:34.230
good at scaring away the birds.

01:14:34.230 --> 01:14:39.580
It benefits from having the
spots and opening up its wings.

01:14:39.580 --> 01:14:42.520
It doesn't have to understand
it to be the beneficiary.

01:14:42.520 --> 01:14:44.770
And similarly, we don't
have to understand

01:14:44.770 --> 01:14:50.650
many of our cultural traditions
that we endorse, spread, keep.

01:14:50.650 --> 01:14:52.340
They may be very good for us.

01:14:52.340 --> 01:14:54.760
But we don't have
to understand it.

01:14:54.760 --> 01:14:57.910
So we're living in the
age of intelligent design.

01:14:57.910 --> 01:15:00.250
It has become ever
more top-down.

01:15:00.250 --> 01:15:02.800
And we even have things
like GM food and people

01:15:02.800 --> 01:15:04.690
like Craig Venter.

01:15:04.690 --> 01:15:08.890
But now, we're entering the
age of post-intelligent design.

01:15:11.550 --> 01:15:13.950
In many fields,
intelligent designers

01:15:13.950 --> 01:15:17.042
are exploiting the truth
of Orgel's second rule.

01:15:17.042 --> 01:15:19.560
Evolution is cleverer
than you are.

01:15:19.560 --> 01:15:21.690
We have genetic algorithms
and deep learning

01:15:21.690 --> 01:15:24.110
and evolutionary architecture
and nanotechnology

01:15:24.110 --> 01:15:25.380
of various sorts.

01:15:25.380 --> 01:15:28.890
And all of these are
Darwin-esque, evolution-like,

01:15:28.890 --> 01:15:32.130
bottom-up, mindless,
competent processes

01:15:32.130 --> 01:15:35.580
that sift through
enormous amounts of data

01:15:35.580 --> 01:15:37.080
and come up with new ideas.

01:15:39.970 --> 01:15:42.790
So now, let's recall
my earlier question.

01:15:42.790 --> 01:15:45.160
How could a slow,
mindless process

01:15:45.160 --> 01:15:46.930
build a thing that
could build a thing

01:15:46.930 --> 01:15:51.410
that a slow mindless process
couldn't build on its own?

01:15:51.410 --> 01:15:52.660
We've come full circle.

01:15:52.660 --> 01:15:54.535
Thank you very much
for your attention.

01:15:54.535 --> 01:15:56.960
[APPLAUSE]

01:16:03.270 --> 01:16:05.370
Is it actually true
that nobody really

01:16:05.370 --> 01:16:06.870
wants to talk about
that in science,

01:16:06.870 --> 01:16:09.090
because it's not a
third-person phenomenon,

01:16:09.090 --> 01:16:11.450
or am I missing something?

01:16:11.450 --> 01:16:14.310
Why is there never talk about
the most important thing

01:16:14.310 --> 01:16:17.150
in human biology,
in brain science?

