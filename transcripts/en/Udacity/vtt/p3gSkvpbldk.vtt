WEBVTT
Kind: captions
Language: en

00:00:00.025 --> 00:00:04.844
Well, one of the most direct effects of this universality finding was, it

00:00:04.844 --> 00:00:12.390
really opened up research on emotion in the face, and emotion more generally.

00:00:12.390 --> 00:00:15.888
Because for much of the 20th century, people had not studied emotion because it

00:00:15.888 --> 00:00:19.188
was considered something inherently subjective.

00:00:19.188 --> 00:00:19.619
&gt;&gt; Right.

00:00:19.619 --> 00:00:22.667
&gt;&gt; That you could not measure. And is, and if you think about what's been going on

00:00:22.667 --> 00:00:26.850
in psychology during this time, behaviorism, everything has to be observable.

00:00:26.850 --> 00:00:31.437
How could you study something as private as an, as an emotion? This finding on

00:00:31.437 --> 00:00:35.272
the face, suddenly suggested, which earlier research and psychology had not

00:00:35.272 --> 00:00:39.225
suggested, that there was reliable information about emotion in an observable

00:00:39.225 --> 00:00:45.460
immortality/g, in the face. So, it became clear that we could study emotions

00:00:45.460 --> 00:00:47.632
from the outside not just.

00:00:47.632 --> 00:00:48.185
&gt;&gt; Right.

00:00:48.185 --> 00:00:52.353
&gt;&gt; From the inside. And in order to kind of, potentatiate this work, make it more

00:00:52.353 --> 00:00:56.433
likely, Eckman and Freezen developed a measurement tool to enable the objective

00:00:56.433 --> 00:01:03.095
studying of facial feature from the outside. They developed. The Facial Action

00:01:03.095 --> 00:01:09.274
Coding System, the acronym for that is FACS, or FACS. Which is an elaborate,

00:01:09.274 --> 00:01:13.837
detailed observational system. Observational meaning it relies on human

00:01:13.837 --> 00:01:19.860
observation, to code all observable facial movement. Without saying, what it

00:01:19.860 --> 00:01:24.666
is, so it's purely descriptive. And that really opened up an enormous amount of

00:01:24.666 --> 00:01:28.552
opportunity in emotion research to set emotional behavior objectively to do it

00:01:28.552 --> 00:01:33.562
without drawing people's attention to it. You know, because you could video

00:01:33.562 --> 00:01:36.075
record and then code the behavior later.

00:01:36.075 --> 00:01:39.854
&gt;&gt; Each emotional expression has a unique pattern of facial.

00:01:39.854 --> 00:01:43.330
&gt;&gt; Right, but it's important to understand that facts is not just for emotion.

00:01:43.330 --> 00:01:47.670
Facts is for describing facial movement. You can see which actions occur

00:01:47.670 --> 00:01:51.994
together to describe any expression on the face. So, I'm going to give another

00:01:51.994 --> 00:01:56.642
little demonstration right now. Let me back up. FACS, describes all facial

00:01:56.642 --> 00:02:02.814
muscle actions in terms of arbitrary action units. So it separates all facial

00:02:02.814 --> 00:02:07.035
behavior in terms of what each muscle does. So if I lift the inner corner of

00:02:07.035 --> 00:02:12.128
the eyebrow. That's one action. Each action has an arbitrary numeric code. So

00:02:12.128 --> 00:02:19.400
this is action unit one. This is two. This is four. This is five. This is six.

00:02:19.400 --> 00:02:22.564
I could go through the whole face. There are 44 different action units to

00:02:22.564 --> 00:02:26.640
describe. The individual components of facial action, and then you can, see

00:02:26.640 --> 00:02:31.650
whatever the face does and describe it in terms of these components. So, if I

00:02:31.650 --> 00:02:39.684
take one of the, emotion expressions that I modeled earlier, like anger. This

00:02:39.684 --> 00:02:44.087
has the brow lower, which is actually unit four. Lifting the upper eyelid is

00:02:44.087 --> 00:02:49.295
action unit five, tightening the lower eyelid is seven, pressing the lips

00:02:49.295 --> 00:02:54.251
together and pushing the chin up is 17 and 24 so we have a 4, 5, 7,17 and 24,

00:02:54.251 --> 00:03:00.612
so you can describe any facial action.

00:03:00.612 --> 00:03:00.964
&gt;&gt; Right.

00:03:00.964 --> 00:03:05.122
&gt;&gt; And one of the interesting applications of the facial action code in system has

00:03:05.122 --> 00:03:10.527
been in computer animation. In fact its become the gold standard in on the

00:03:10.527 --> 00:03:14.929
visual effects industry for developing virtual beings, virtual actors you know

00:03:14.929 --> 00:03:18.525
it was used in Avatar, it was used in, in Harry Porter was used in, in any

00:03:18.525 --> 00:03:23.895
animated creature they use the action units.

00:03:23.895 --> 00:03:24.015
&gt;&gt; Yeah.

00:03:24.015 --> 00:03:26.074
&gt;&gt; As the basis for animating our faces.

00:03:26.074 --> 00:03:29.194
&gt;&gt; So, in fact, yeah, that leads to my next question, which is can you tell us

00:03:29.194 --> 00:03:32.678
something about how you've applied FACS or Facial Action Coding Systems in your

00:03:32.678 --> 00:03:34.745
own work?

00:03:34.745 --> 00:03:38.573
&gt;&gt; It's been really interesting because my original intent was to study emotion,

00:03:38.573 --> 00:03:43.405
and that's why I got into studying the face. So, I've applied FACS to my own

00:03:43.405 --> 00:03:47.053
research on emotion where I've looked at things like the role of anger and

00:03:47.053 --> 00:03:52.361
heart disease but that was my dissertation research. I've also looked at the

00:03:52.361 --> 00:03:55.497
relationship between facial expression and people's reports of emotional

00:03:55.497 --> 00:04:00.705
experience. And how emotions change as a function of more recently meditation

00:04:00.705 --> 00:04:07.000
training. So that's in my research but as a result of becoming expert in facts.

00:04:07.000 --> 00:04:09.624
I've learned that a lot of people are interested in this measurement tool for

00:04:09.624 --> 00:04:13.562
other reasons. So I've trained animators. Like people who do visual effects

00:04:13.562 --> 00:04:18.425
animation. I worked on the television show "Lie to Me" which was on from 2009

00:04:18.425 --> 00:04:26.286
to 2011 on FOX. And this was a drama based on, Really, Paul Eckman's career. So

00:04:26.286 --> 00:04:30.738
that the lead character in that, was a deception detection expert. And the

00:04:30.738 --> 00:04:34.515
field of deception detection depends a lot on facial movement detection. So I

00:04:34.515 --> 00:04:37.980
was a scientifical consultant on that show, reading scripts, coaching the

00:04:37.980 --> 00:04:41.900
actors, etcetera. So it's really run the gamut it from basic research to

00:04:41.900 --> 00:04:46.913
something really applied, like in the entertainment industry. And, sort of a, a

00:04:46.913 --> 00:04:50.477
continuous thing throughout all of those is, is facts, the facial measurement

00:04:50.477 --> 00:04:54.749
and, and the kinds of people I've trained in that, in that.

00:04:54.749 --> 00:04:55.351
&gt;&gt; Right.

00:04:55.351 --> 00:04:55.557
&gt;&gt; Yeah.

00:04:55.557 --> 00:04:55.789
&gt;&gt; Great.

00:04:55.789 --> 00:04:59.199
&gt;&gt; Well thank you, I hope you've enjoyed this, and also see how psychology can

00:04:59.199 --> 00:05:04.204
applied in a lot of different areas and ways that you may not have expected.

