WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:01.910 align:start position:0%
 
in<00:00:00.359><c> a</c><00:00:00.480><c> previous</c><00:00:00.870><c> video</c><00:00:00.989><c> you</c><00:00:01.230><c> saw</c><00:00:01.410><c> how</c><00:00:01.650><c> to</c>

00:00:01.910 --> 00:00:01.920 align:start position:0%
in a previous video you saw how to
 

00:00:01.920 --> 00:00:03.770 align:start position:0%
in a previous video you saw how to
compute<00:00:02.460><c> derivatives</c><00:00:02.610><c> and</c><00:00:03.330><c> implement</c>

00:00:03.770 --> 00:00:03.780 align:start position:0%
compute derivatives and implement
 

00:00:03.780 --> 00:00:05.869 align:start position:0%
compute derivatives and implement
gradient<00:00:03.929><c> descent</c><00:00:04.440><c> with</c><00:00:04.950><c> respect</c><00:00:05.310><c> to</c><00:00:05.490><c> just</c>

00:00:05.869 --> 00:00:05.879 align:start position:0%
gradient descent with respect to just
 

00:00:05.879 --> 00:00:07.550 align:start position:0%
gradient descent with respect to just
one<00:00:06.150><c> training</c><00:00:06.420><c> example</c><00:00:06.600><c> for</c><00:00:07.259><c> Lich's</c>

00:00:07.550 --> 00:00:07.560 align:start position:0%
one training example for Lich's
 

00:00:07.560 --> 00:00:09.950 align:start position:0%
one training example for Lich's
regression<00:00:08.010><c> now</c><00:00:08.639><c> we</c><00:00:08.700><c> want</c><00:00:09.120><c> to</c><00:00:09.210><c> do</c><00:00:09.330><c> it</c><00:00:09.480><c> for</c><00:00:09.719><c> M</c>

00:00:09.950 --> 00:00:09.960 align:start position:0%
regression now we want to do it for M
 

00:00:09.960 --> 00:00:12.470 align:start position:0%
regression now we want to do it for M
training<00:00:10.530><c> examples</c><00:00:10.650><c> to</c><00:00:11.610><c> get</c><00:00:11.730><c> started</c><00:00:12.210><c> let's</c>

00:00:12.470 --> 00:00:12.480 align:start position:0%
training examples to get started let's
 

00:00:12.480 --> 00:00:14.419 align:start position:0%
training examples to get started let's
remind<00:00:12.929><c> ourselves</c><00:00:13.139><c> of</c><00:00:13.559><c> the</c><00:00:13.710><c> definition</c><00:00:14.280><c> of</c>

00:00:14.419 --> 00:00:14.429 align:start position:0%
remind ourselves of the definition of
 

00:00:14.429 --> 00:00:17.480 align:start position:0%
remind ourselves of the definition of
the<00:00:14.610><c> cost</c><00:00:14.820><c> function</c><00:00:15.000><c> J</c><00:00:15.379><c> cost</c><00:00:16.379><c> function</c><00:00:16.890><c> WP</c>

00:00:17.480 --> 00:00:17.490 align:start position:0%
the cost function J cost function WP
 

00:00:17.490 --> 00:00:19.550 align:start position:0%
the cost function J cost function WP
which<00:00:17.730><c> you</c><00:00:17.820><c> care</c><00:00:18.060><c> about</c><00:00:18.270><c> is</c><00:00:18.539><c> this</c><00:00:19.080><c> average</c>

00:00:19.550 --> 00:00:19.560 align:start position:0%
which you care about is this average
 

00:00:19.560 --> 00:00:21.650 align:start position:0%
which you care about is this average
right<00:00:19.830><c> 1</c><00:00:20.070><c> over</c><00:00:20.279><c> m</c><00:00:20.460><c> sum</c><00:00:20.970><c> from</c><00:00:21.119><c> I</c><00:00:21.270><c> equals</c><00:00:21.570><c> 1</c>

00:00:21.650 --> 00:00:21.660 align:start position:0%
right 1 over m sum from I equals 1
 

00:00:21.660 --> 00:00:24.920 align:start position:0%
right 1 over m sum from I equals 1
through<00:00:21.990><c> m</c><00:00:22.170><c> you</c><00:00:22.760><c> know</c><00:00:23.760><c> the</c><00:00:23.970><c> loss</c><00:00:24.240><c> when</c><00:00:24.779><c> your</c>

00:00:24.920 --> 00:00:24.930 align:start position:0%
through m you know the loss when your
 

00:00:24.930 --> 00:00:28.040 align:start position:0%
through m you know the loss when your
algorithm<00:00:25.380><c> output</c><00:00:25.890><c> a</c><00:00:26.070><c> I</c><00:00:26.279><c> on</c><00:00:26.820><c> the</c><00:00:27.269><c> example</c><00:00:27.810><c> why</c>

00:00:28.040 --> 00:00:28.050 align:start position:0%
algorithm output a I on the example why
 

00:00:28.050 --> 00:00:33.260 align:start position:0%
algorithm output a I on the example why
we're<00:00:28.949><c> you</c><00:00:29.550><c> know</c><00:00:29.670><c> AI</c><00:00:29.910><c> is</c><00:00:30.449><c> D</c><00:00:31.730><c> prediction</c><00:00:32.730><c> on</c><00:00:32.969><c> the</c>

00:00:33.260 --> 00:00:33.270 align:start position:0%
we're you know AI is D prediction on the
 

00:00:33.270 --> 00:00:35.750 align:start position:0%
we're you know AI is D prediction on the
I've<00:00:33.540><c> trained</c><00:00:33.809><c> example</c><00:00:34.410><c> which</c><00:00:35.160><c> is</c><00:00:35.309><c> Sigma</c><00:00:35.730><c> of</c>

00:00:35.750 --> 00:00:35.760 align:start position:0%
I've trained example which is Sigma of
 

00:00:35.760 --> 00:00:39.770 align:start position:0%
I've trained example which is Sigma of
Zi<00:00:36.149><c> which</c><00:00:36.780><c> is</c><00:00:36.899><c> equal</c><00:00:37.290><c> to</c><00:00:37.610><c> Sigma</c><00:00:38.610><c> of</c><00:00:38.780><c> W</c>

00:00:39.770 --> 00:00:39.780 align:start position:0%
Zi which is equal to Sigma of W
 

00:00:39.780 --> 00:00:46.279 align:start position:0%
Zi which is equal to Sigma of W
transpose<00:00:40.020><c> X</c><00:00:40.649><c> plus</c><00:00:41.809><c> B</c><00:00:43.640><c> ok</c><00:00:44.640><c> so</c><00:00:45.450><c> what</c><00:00:45.660><c> we</c><00:00:45.780><c> show</c><00:00:45.989><c> in</c>

00:00:46.279 --> 00:00:46.289 align:start position:0%
transpose X plus B ok so what we show in
 

00:00:46.289 --> 00:00:48.529 align:start position:0%
transpose X plus B ok so what we show in
the<00:00:46.829><c> previous</c><00:00:47.280><c> line</c><00:00:47.460><c> is</c><00:00:47.760><c> for</c><00:00:48.059><c> any</c><00:00:48.210><c> single</c>

00:00:48.529 --> 00:00:48.539 align:start position:0%
the previous line is for any single
 

00:00:48.539 --> 00:00:51.439 align:start position:0%
the previous line is for any single
training<00:00:49.050><c> example</c><00:00:49.140><c> how</c><00:00:50.070><c> to</c><00:00:50.100><c> compute</c><00:00:50.670><c> you</c><00:00:51.390><c> know</c>

00:00:51.439 --> 00:00:51.449 align:start position:0%
training example how to compute you know
 

00:00:51.449 --> 00:00:55.639 align:start position:0%
training example how to compute you know
the<00:00:51.600><c> derivatives</c><00:00:53.120><c> when</c><00:00:54.120><c> you</c><00:00:54.719><c> have</c><00:00:54.930><c> just</c><00:00:55.260><c> one</c>

00:00:55.639 --> 00:00:55.649 align:start position:0%
the derivatives when you have just one
 

00:00:55.649 --> 00:00:56.840 align:start position:0%
the derivatives when you have just one
training<00:00:55.949><c> example</c>

00:00:56.840 --> 00:00:56.850 align:start position:0%
training example
 

00:00:56.850 --> 00:01:02.810 align:start position:0%
training example
great<00:00:57.120><c> so</c><00:00:57.920><c> dw1</c><00:00:59.129><c> d</c><00:00:59.370><c> w2</c><00:00:59.760><c> and</c><00:01:00.210><c> d</c><00:01:00.629><c> be</c><00:01:01.550><c> with</c><00:01:02.550><c> now</c><00:01:02.760><c> the</c>

00:01:02.810 --> 00:01:02.820 align:start position:0%
great so dw1 d w2 and d be with now the
 

00:01:02.820 --> 00:01:04.960 align:start position:0%
great so dw1 d w2 and d be with now the
superscript<00:01:03.690><c> I</c><00:01:03.840><c> to</c><00:01:03.870><c> denote</c><00:01:04.409><c> the</c>

00:01:04.960 --> 00:01:04.970 align:start position:0%
superscript I to denote the
 

00:01:04.970 --> 00:01:07.250 align:start position:0%
superscript I to denote the
corresponding<00:01:05.970><c> values</c><00:01:06.360><c> you</c><00:01:06.510><c> get</c><00:01:06.720><c> if</c><00:01:06.930><c> you</c><00:01:07.110><c> were</c>

00:01:07.250 --> 00:01:07.260 align:start position:0%
corresponding values you get if you were
 

00:01:07.260 --> 00:01:08.929 align:start position:0%
corresponding values you get if you were
doing<00:01:07.530><c> what</c><00:01:07.860><c> we</c><00:01:07.979><c> did</c><00:01:08.130><c> on</c><00:01:08.280><c> the</c><00:01:08.400><c> previous</c><00:01:08.430><c> slide</c>

00:01:08.929 --> 00:01:08.939 align:start position:0%
doing what we did on the previous slide
 

00:01:08.939 --> 00:01:12.070 align:start position:0%
doing what we did on the previous slide
but<00:01:09.240><c> just</c><00:01:09.270><c> using</c><00:01:09.750><c> the</c><00:01:10.590><c> one</c><00:01:10.830><c> training</c><00:01:11.070><c> example</c>

00:01:12.070 --> 00:01:12.080 align:start position:0%
but just using the one training example
 

00:01:12.080 --> 00:01:16.219 align:start position:0%
but just using the one training example
X<00:01:13.080><c> I</c><00:01:13.320><c> Y</c><00:01:13.770><c> I</c><00:01:13.799><c> those</c><00:01:14.520><c> use</c><00:01:14.790><c> me</c><00:01:14.939><c> missing</c><00:01:15.330><c> on</c><00:01:15.450><c> I</c><00:01:15.630><c> there</c>

00:01:16.219 --> 00:01:16.229 align:start position:0%
X I Y I those use me missing on I there
 

00:01:16.229 --> 00:01:19.340 align:start position:0%
X I Y I those use me missing on I there
as<00:01:16.320><c> well</c><00:01:16.560><c> so</c><00:01:17.189><c> now</c><00:01:17.850><c> you</c><00:01:17.909><c> notice</c><00:01:18.420><c> the</c><00:01:18.750><c> overall</c>

00:01:19.340 --> 00:01:19.350 align:start position:0%
as well so now you notice the overall
 

00:01:19.350 --> 00:01:21.649 align:start position:0%
as well so now you notice the overall
cost<00:01:19.619><c> function</c><00:01:19.710><c> the</c><00:01:20.220><c> sum</c><00:01:20.790><c> was</c><00:01:21.270><c> really</c><00:01:21.540><c> the</c>

00:01:21.649 --> 00:01:21.659 align:start position:0%
cost function the sum was really the
 

00:01:21.659 --> 00:01:23.990 align:start position:0%
cost function the sum was really the
average<00:01:21.810><c> gives</c><00:01:22.290><c> a</c><00:01:22.380><c> 1</c><00:01:22.560><c> over</c><00:01:22.799><c> m</c><00:01:22.890><c> term</c><00:01:23.130><c> of</c><00:01:23.340><c> the</c>

00:01:23.990 --> 00:01:24.000 align:start position:0%
average gives a 1 over m term of the
 

00:01:24.000 --> 00:01:27.620 align:start position:0%
average gives a 1 over m term of the
individual<00:01:24.720><c> losses</c><00:01:25.280><c> so</c><00:01:26.280><c> it</c><00:01:26.850><c> turns</c><00:01:27.119><c> out</c><00:01:27.360><c> that</c>

00:01:27.620 --> 00:01:27.630 align:start position:0%
individual losses so it turns out that
 

00:01:27.630 --> 00:01:31.789 align:start position:0%
individual losses so it turns out that
the<00:01:27.810><c> derivative</c><00:01:28.400><c> respect</c><00:01:29.400><c> to</c><00:01:29.549><c> say</c><00:01:29.700><c> w1</c><00:01:30.299><c> of</c><00:01:30.799><c> the</c>

00:01:31.789 --> 00:01:31.799 align:start position:0%
the derivative respect to say w1 of the
 

00:01:31.799 --> 00:01:34.880 align:start position:0%
the derivative respect to say w1 of the
overall<00:01:32.340><c> cost</c><00:01:32.640><c> function</c><00:01:32.729><c> is</c><00:01:33.390><c> also</c><00:01:34.290><c> going</c><00:01:34.770><c> to</c>

00:01:34.880 --> 00:01:34.890 align:start position:0%
overall cost function is also going to
 

00:01:34.890 --> 00:01:40.910 align:start position:0%
overall cost function is also going to
be<00:01:35.100><c> the</c><00:01:35.610><c> average</c><00:01:36.119><c> of</c><00:01:38.659><c> derivatives</c><00:01:39.829><c> respect</c><00:01:40.829><c> to</c>

00:01:40.910 --> 00:01:40.920 align:start position:0%
be the average of derivatives respect to
 

00:01:40.920 --> 00:01:45.319 align:start position:0%
be the average of derivatives respect to
w1<00:01:41.390><c> of</c><00:01:42.390><c> the</c><00:01:42.630><c> individual</c><00:01:43.280><c> loss</c><00:01:44.280><c> terms</c><00:01:44.640><c> but</c>

00:01:45.319 --> 00:01:45.329 align:start position:0%
w1 of the individual loss terms but
 

00:01:45.329 --> 00:01:47.450 align:start position:0%
w1 of the individual loss terms but
previously<00:01:45.990><c> we</c><00:01:46.200><c> have</c><00:01:46.380><c> already</c><00:01:46.530><c> shown</c><00:01:46.799><c> how</c><00:01:47.430><c> to</c>

00:01:47.450 --> 00:01:47.460 align:start position:0%
previously we have already shown how to
 

00:01:47.460 --> 00:01:52.999 align:start position:0%
previously we have already shown how to
compute<00:01:48.060><c> this</c><00:01:48.270><c> term</c><00:01:48.329><c> as</c><00:01:48.840><c> say</c><00:01:49.470><c> d</c><00:01:50.210><c> w1</c><00:01:51.210><c> I</c><00:01:52.009><c> right</c>

00:01:52.999 --> 00:01:53.009 align:start position:0%
compute this term as say d w1 I right
 

00:01:53.009 --> 00:01:55.340 align:start position:0%
compute this term as say d w1 I right
which<00:01:53.250><c> we</c><00:01:53.460><c> you</c><00:01:54.149><c> know</c><00:01:54.270><c> on</c><00:01:54.479><c> the</c><00:01:54.689><c> previous</c><00:01:55.110><c> slide</c>

00:01:55.340 --> 00:01:55.350 align:start position:0%
which we you know on the previous slide
 

00:01:55.350 --> 00:01:57.319 align:start position:0%
which we you know on the previous slide
show<00:01:55.649><c> how</c><00:01:55.860><c> the</c><00:01:55.920><c> computers</c><00:01:56.460><c> on</c><00:01:56.880><c> a</c><00:01:56.939><c> single</c>

00:01:57.319 --> 00:01:57.329 align:start position:0%
show how the computers on a single
 

00:01:57.329 --> 00:01:59.480 align:start position:0%
show how the computers on a single
training<00:01:57.570><c> example</c><00:01:57.689><c> so</c><00:01:58.530><c> what</c><00:01:58.920><c> you</c><00:01:59.040><c> need</c><00:01:59.189><c> to</c><00:01:59.340><c> do</c>

00:01:59.480 --> 00:01:59.490 align:start position:0%
training example so what you need to do
 

00:01:59.490 --> 00:02:01.969 align:start position:0%
training example so what you need to do
is<00:01:59.700><c> really</c><00:01:59.909><c> compute</c><00:02:00.479><c> these</c><00:02:00.780><c> um</c><00:02:01.049><c> derivatives</c>

00:02:01.969 --> 00:02:01.979 align:start position:0%
is really compute these um derivatives
 

00:02:01.979 --> 00:02:04.069 align:start position:0%
is really compute these um derivatives
as<00:02:02.250><c> we</c><00:02:02.549><c> showed</c><00:02:02.850><c> on</c><00:02:03.149><c> the</c><00:02:03.180><c> previous</c><00:02:03.420><c> training</c>

00:02:04.069 --> 00:02:04.079 align:start position:0%
as we showed on the previous training
 

00:02:04.079 --> 00:02:06.770 align:start position:0%
as we showed on the previous training
example<00:02:04.530><c> and</c><00:02:04.649><c> average</c><00:02:05.430><c> them</c><00:02:05.700><c> and</c><00:02:05.969><c> this</c><00:02:06.600><c> will</c>

00:02:06.770 --> 00:02:06.780 align:start position:0%
example and average them and this will
 

00:02:06.780 --> 00:02:09.529 align:start position:0%
example and average them and this will
give<00:02:07.020><c> you</c><00:02:07.170><c> the</c><00:02:07.380><c> overall</c><00:02:08.000><c> gradient</c><00:02:09.000><c> that</c><00:02:09.330><c> you</c>

00:02:09.529 --> 00:02:09.539 align:start position:0%
give you the overall gradient that you
 

00:02:09.539 --> 00:02:11.960 align:start position:0%
give you the overall gradient that you
can<00:02:09.690><c> use</c><00:02:09.959><c> to</c><00:02:10.440><c> implement</c><00:02:10.679><c> gradient</c><00:02:11.160><c> descent</c>

00:02:11.960 --> 00:02:11.970 align:start position:0%
can use to implement gradient descent
 

00:02:11.970 --> 00:02:14.660 align:start position:0%
can use to implement gradient descent
so<00:02:12.240><c> I</c><00:02:12.510><c> know</c><00:02:12.570><c> there</c><00:02:12.840><c> was</c><00:02:12.900><c> a</c><00:02:12.960><c> lot</c><00:02:13.200><c> of</c><00:02:13.230><c> details</c><00:02:13.770><c> but</c>

00:02:14.660 --> 00:02:14.670 align:start position:0%
so I know there was a lot of details but
 

00:02:14.670 --> 00:02:16.460 align:start position:0%
so I know there was a lot of details but
let's<00:02:14.880><c> take</c><00:02:15.240><c> all</c><00:02:15.390><c> of</c><00:02:15.420><c> this</c><00:02:15.690><c> up</c><00:02:15.870><c> and</c><00:02:15.900><c> wrap</c><00:02:16.290><c> this</c>

00:02:16.460 --> 00:02:16.470 align:start position:0%
let's take all of this up and wrap this
 

00:02:16.470 --> 00:02:19.340 align:start position:0%
let's take all of this up and wrap this
up<00:02:16.530><c> into</c><00:02:16.920><c> a</c><00:02:17.100><c> concrete</c><00:02:17.790><c> algorithms</c><00:02:18.660><c> and</c><00:02:19.020><c> what</c>

00:02:19.340 --> 00:02:19.350 align:start position:0%
up into a concrete algorithms and what
 

00:02:19.350 --> 00:02:21.050 align:start position:0%
up into a concrete algorithms and what
you<00:02:19.500><c> should</c><00:02:19.710><c> implement</c><00:02:19.950><c> together</c><00:02:20.670><c> to</c><00:02:20.940><c> see</c>

00:02:21.050 --> 00:02:21.060 align:start position:0%
you should implement together to see
 

00:02:21.060 --> 00:02:23.000 align:start position:0%
you should implement together to see
regression<00:02:21.600><c> with</c><00:02:21.750><c> gradient</c><00:02:21.780><c> descent</c><00:02:22.200><c> working</c>

00:02:23.000 --> 00:02:23.010 align:start position:0%
regression with gradient descent working
 

00:02:23.010 --> 00:02:26.360 align:start position:0%
regression with gradient descent working
so<00:02:24.000><c> here's</c><00:02:24.720><c> what</c><00:02:24.990><c> you</c><00:02:25.230><c> can</c><00:02:25.440><c> do</c><00:02:25.710><c> let's</c>

00:02:26.360 --> 00:02:26.370 align:start position:0%
so here's what you can do let's
 

00:02:26.370 --> 00:02:33.920 align:start position:0%
so here's what you can do let's
initialize<00:02:26.850><c> J</c><00:02:27.570><c> equals</c><00:02:28.020><c> 0</c><00:02:28.820><c> DW</c><00:02:29.820><c> 1</c><00:02:30.210><c> equals</c><00:02:30.570><c> 0</c><00:02:31.250><c> DW</c><00:02:32.930><c> 2</c>

00:02:33.920 --> 00:02:33.930 align:start position:0%
initialize J equals 0 DW 1 equals 0 DW 2
 

00:02:33.930 --> 00:02:39.200 align:start position:0%
initialize J equals 0 DW 1 equals 0 DW 2
equals<00:02:34.440><c> 0</c><00:02:35.450><c> DB</c><00:02:36.800><c> equals</c><00:02:37.800><c> 0</c><00:02:38.130><c> and</c><00:02:38.910><c> what</c><00:02:39.090><c> we're</c>

00:02:39.200 --> 00:02:39.210 align:start position:0%
equals 0 DB equals 0 and what we're
 

00:02:39.210 --> 00:02:41.440 align:start position:0%
equals 0 DB equals 0 and what we're
going<00:02:39.360><c> to</c><00:02:39.420><c> do</c><00:02:39.630><c> is</c><00:02:39.930><c> use</c><00:02:40.140><c> a</c><00:02:40.170><c> for</c><00:02:40.590><c> loop</c><00:02:40.770><c> over</c><00:02:41.340><c> the</c>

00:02:41.440 --> 00:02:41.450 align:start position:0%
going to do is use a for loop over the
 

00:02:41.450 --> 00:02:44.900 align:start position:0%
going to do is use a for loop over the
training<00:02:42.450><c> set</c><00:02:42.780><c> and</c><00:02:43.220><c> compute</c><00:02:44.220><c> the</c><00:02:44.340><c> derivatives</c>

00:02:44.900 --> 00:02:44.910 align:start position:0%
training set and compute the derivatives
 

00:02:44.910 --> 00:02:46.070 align:start position:0%
training set and compute the derivatives
with<00:02:45.060><c> respect</c><00:02:45.090><c> to</c><00:02:45.450><c> each</c><00:02:45.690><c> training</c><00:02:45.960><c> example</c>

00:02:46.070 --> 00:02:46.080 align:start position:0%
with respect to each training example
 

00:02:46.080 --> 00:02:48.500 align:start position:0%
with respect to each training example
and<00:02:46.680><c> then</c><00:02:47.190><c> add</c><00:02:47.370><c> them</c><00:02:47.580><c> up</c><00:02:47.700><c> all</c><00:02:48.060><c> right</c><00:02:48.180><c> so</c><00:02:48.210><c> here's</c>

00:02:48.500 --> 00:02:48.510 align:start position:0%
and then add them up all right so here's
 

00:02:48.510 --> 00:02:50.900 align:start position:0%
and then add them up all right so here's
we<00:02:48.630><c> do</c><00:02:48.810><c> for</c><00:02:49.020><c> I</c><00:02:49.050><c> equals</c><00:02:49.500><c> 1</c><00:02:49.680><c> through</c><00:02:49.890><c> m</c><00:02:50.070><c> so</c><00:02:50.550><c> M</c><00:02:50.730><c> is</c>

00:02:50.900 --> 00:02:50.910 align:start position:0%
we do for I equals 1 through m so M is
 

00:02:50.910 --> 00:02:52.400 align:start position:0%
we do for I equals 1 through m so M is
the<00:02:51.150><c> number</c><00:02:51.210><c> of</c><00:02:51.510><c> training</c><00:02:51.750><c> examples</c><00:02:51.780><c> we</c>

00:02:52.400 --> 00:02:52.410 align:start position:0%
the number of training examples we
 

00:02:52.410 --> 00:02:55.940 align:start position:0%
the number of training examples we
compute<00:02:52.860><c> Z</c><00:02:53.100><c> I</c><00:02:53.130><c> equals</c><00:02:53.850><c> W</c><00:02:54.390><c> transpose</c><00:02:54.930><c> X</c><00:02:55.170><c> I</c><00:02:55.470><c> plus</c>

00:02:55.940 --> 00:02:55.950 align:start position:0%
compute Z I equals W transpose X I plus
 

00:02:55.950 --> 00:02:59.600 align:start position:0%
compute Z I equals W transpose X I plus
B<00:02:56.190><c> the</c><00:02:57.120><c> prediction</c><00:02:57.630><c> AI</c><00:02:57.870><c> is</c><00:02:58.350><c> equal</c><00:02:58.740><c> to</c><00:02:58.920><c> Sigma</c><00:02:59.430><c> of</c>

00:02:59.600 --> 00:02:59.610 align:start position:0%
B the prediction AI is equal to Sigma of
 

00:02:59.610 --> 00:03:02.750 align:start position:0%
B the prediction AI is equal to Sigma of
zi<00:03:00.360><c> and</c><00:03:00.810><c> then</c><00:03:01.170><c> you</c><00:03:01.500><c> know</c><00:03:01.620><c> let's</c><00:03:01.890><c> let's</c><00:03:02.310><c> add</c><00:03:02.490><c> up</c>

00:03:02.750 --> 00:03:02.760 align:start position:0%
zi and then you know let's let's add up
 

00:03:02.760 --> 00:03:09.140 align:start position:0%
zi and then you know let's let's add up
j<00:03:03.060><c> j</c><00:03:04.020><c> plus</c><00:03:04.440><c> equals</c><00:03:04.980><c> y</c><00:03:05.550><c> i</c><00:03:05.580><c> log</c><00:03:06.480><c> a</c><00:03:06.780><c> i</c><00:03:07.160><c> plus</c><00:03:08.160><c> 1</c><00:03:08.460><c> minus</c>

00:03:09.140 --> 00:03:09.150 align:start position:0%
j j plus equals y i log a i plus 1 minus
 

00:03:09.150 --> 00:03:12.380 align:start position:0%
j j plus equals y i log a i plus 1 minus
y<00:03:09.330><c> i</c><00:03:09.360><c> log</c><00:03:10.200><c> 1</c><00:03:10.740><c> minus</c><00:03:10.770><c> AI</c><00:03:11.310><c> and</c><00:03:11.760><c> then</c><00:03:11.940><c> this</c><00:03:12.090><c> put</c><00:03:12.360><c> a</c>

00:03:12.380 --> 00:03:12.390 align:start position:0%
y i log 1 minus AI and then this put a
 

00:03:12.390 --> 00:03:14.030 align:start position:0%
y i log 1 minus AI and then this put a
negative<00:03:12.840><c> sign</c><00:03:13.260><c> in</c><00:03:13.320><c> front</c><00:03:13.530><c> of</c><00:03:13.800><c> the</c><00:03:13.890><c> whole</c>

00:03:14.030 --> 00:03:14.040 align:start position:0%
negative sign in front of the whole
 

00:03:14.040 --> 00:03:16.010 align:start position:0%
negative sign in front of the whole
thing<00:03:14.220><c> and</c><00:03:14.430><c> then</c><00:03:14.670><c> as</c><00:03:14.790><c> we</c><00:03:14.940><c> saw</c><00:03:15.120><c> earlier</c><00:03:15.150><c> we</c><00:03:15.810><c> have</c>

00:03:16.010 --> 00:03:16.020 align:start position:0%
thing and then as we saw earlier we have
 

00:03:16.020 --> 00:03:20.600 align:start position:0%
thing and then as we saw earlier we have
d<00:03:16.320><c> zi</c><00:03:16.709><c> or</c><00:03:17.370><c> it</c><00:03:17.459><c> is</c><00:03:17.640><c> equal</c><00:03:18.120><c> to</c><00:03:18.420><c> AI</c><00:03:18.830><c> minus</c><00:03:19.830><c> y</c><00:03:20.070><c> i</c><00:03:20.100><c> and</c>

00:03:20.600 --> 00:03:20.610 align:start position:0%
d zi or it is equal to AI minus y i and
 

00:03:20.610 --> 00:03:28.520 align:start position:0%
d zi or it is equal to AI minus y i and
DW<00:03:21.510><c> gets</c><00:03:21.900><c> plus</c><00:03:22.200><c> equals</c><00:03:22.650><c> x1</c><00:03:23.580><c> i</c><00:03:24.230><c> d</c><00:03:25.230><c> zi</c><00:03:25.530><c> d</c><00:03:26.370><c> w2</c><00:03:27.530><c> plus</c>

00:03:28.520 --> 00:03:28.530 align:start position:0%
DW gets plus equals x1 i d zi d w2 plus
 

00:03:28.530 --> 00:03:33.199 align:start position:0%
DW gets plus equals x1 i d zi d w2 plus
equals<00:03:29.040><c> x</c><00:03:29.489><c> i2</c><00:03:30.440><c> d</c><00:03:31.440><c> zi</c><00:03:31.650><c> o</c><00:03:32.100><c> and</c><00:03:32.730><c> i'm</c><00:03:32.880><c> doing</c><00:03:33.060><c> this</c>

00:03:33.199 --> 00:03:33.209 align:start position:0%
equals x i2 d zi o and i'm doing this
 

00:03:33.209 --> 00:03:35.300 align:start position:0%
equals x i2 d zi o and i'm doing this
calculation<00:03:33.450><c> assuming</c><00:03:34.260><c> that</c><00:03:34.650><c> you</c><00:03:35.010><c> have</c><00:03:35.130><c> just</c>

00:03:35.300 --> 00:03:35.310 align:start position:0%
calculation assuming that you have just
 

00:03:35.310 --> 00:03:37.430 align:start position:0%
calculation assuming that you have just
feet<00:03:35.580><c> two</c><00:03:36.090><c> features</c><00:03:36.540><c> so</c><00:03:36.720><c> that</c><00:03:36.750><c> n</c><00:03:36.989><c> is</c><00:03:37.170><c> equal</c><00:03:37.410><c> to</c>

00:03:37.430 --> 00:03:37.440 align:start position:0%
feet two features so that n is equal to
 

00:03:37.440 --> 00:03:39.949 align:start position:0%
feet two features so that n is equal to
2<00:03:37.709><c> otherwise</c><00:03:38.250><c> you</c><00:03:38.580><c> do</c><00:03:38.790><c> this</c><00:03:38.970><c> for</c><00:03:39.150><c> DW</c><00:03:39.570><c> 1</c><00:03:39.750><c> DW</c>

00:03:39.949 --> 00:03:39.959 align:start position:0%
2 otherwise you do this for DW 1 DW
 

00:03:39.959 --> 00:03:42.949 align:start position:0%
2 otherwise you do this for DW 1 DW
tunity<00:03:40.500><c> number</c><00:03:40.860><c> 3</c><00:03:41.100><c> and</c><00:03:41.250><c> so</c><00:03:41.370><c> on</c><00:03:41.550><c> and</c><00:03:41.820><c> then</c><00:03:41.940><c> g</c><00:03:42.180><c> p+</c>

00:03:42.949 --> 00:03:42.959 align:start position:0%
tunity number 3 and so on and then g p+
 

00:03:42.959 --> 00:03:44.660 align:start position:0%
tunity number 3 and so on and then g p+
equals<00:03:43.470><c> d</c><00:03:43.950><c> zi</c>

00:03:44.660 --> 00:03:44.670 align:start position:0%
equals d zi
 

00:03:44.670 --> 00:03:47.120 align:start position:0%
equals d zi
and<00:03:45.360><c> i</c><00:03:45.510><c> guess</c><00:03:45.690><c> that's</c><00:03:45.870><c> the</c><00:03:46.170><c> end</c><00:03:46.320><c> of</c><00:03:46.769><c> the</c><00:03:46.890><c> for</c>

00:03:47.120 --> 00:03:47.130 align:start position:0%
and i guess that's the end of the for
 

00:03:47.130 --> 00:03:48.740 align:start position:0%
and i guess that's the end of the for
loop<00:03:47.310><c> and</c><00:03:47.400><c> then</c><00:03:47.580><c> finally</c><00:03:48.030><c> having</c><00:03:48.420><c> done</c><00:03:48.600><c> this</c>

00:03:48.740 --> 00:03:48.750 align:start position:0%
loop and then finally having done this
 

00:03:48.750 --> 00:03:51.170 align:start position:0%
loop and then finally having done this
for<00:03:48.810><c> all</c><00:03:49.170><c> M</c><00:03:49.380><c> training</c><00:03:49.860><c> examples</c><00:03:50.150><c> you</c><00:03:51.150><c> will</c>

00:03:51.170 --> 00:03:51.180 align:start position:0%
for all M training examples you will
 

00:03:51.180 --> 00:03:54.380 align:start position:0%
for all M training examples you will
still<00:03:51.690><c> need</c><00:03:51.870><c> to</c><00:03:51.930><c> divide</c><00:03:52.709><c> by</c><00:03:53.100><c> M</c><00:03:53.340><c> because</c><00:03:54.209><c> we're</c>

00:03:54.380 --> 00:03:54.390 align:start position:0%
still need to divide by M because we're
 

00:03:54.390 --> 00:03:58.660 align:start position:0%
still need to divide by M because we're
computing<00:03:54.959><c> averages</c><00:03:55.170><c> so</c><00:03:55.890><c> d</c><00:03:56.160><c> w1</c><00:03:56.700><c> if</c><00:03:57.420><c> I</c><00:03:57.570><c> equals</c><00:03:57.870><c> m</c>

00:03:58.660 --> 00:03:58.670 align:start position:0%
computing averages so d w1 if I equals m
 

00:03:58.670 --> 00:04:03.650 align:start position:0%
computing averages so d w1 if I equals m
DW<00:03:59.670><c> to</c><00:04:00.030><c> 2</c><00:04:00.239><c> Phi</c><00:04:00.390><c> cos</c><00:04:00.660><c> M</c><00:04:01.100><c> DB</c><00:04:02.100><c> devising</c><00:04:02.850><c> cost</c><00:04:03.030><c> M</c><00:04:03.239><c> in</c>

00:04:03.650 --> 00:04:03.660 align:start position:0%
DW to 2 Phi cos M DB devising cost M in
 

00:04:03.660 --> 00:04:06.560 align:start position:0%
DW to 2 Phi cos M DB devising cost M in
all<00:04:03.870><c> the</c><00:04:03.989><c> computer</c><00:04:04.350><c> bridges</c><00:04:04.769><c> and</c><00:04:04.980><c> so</c><00:04:05.760><c> with</c><00:04:06.360><c> all</c>

00:04:06.560 --> 00:04:06.570 align:start position:0%
all the computer bridges and so with all
 

00:04:06.570 --> 00:04:08.330 align:start position:0%
all the computer bridges and so with all
of<00:04:06.930><c> these</c><00:04:07.050><c> calculations</c><00:04:07.350><c> you've</c><00:04:08.130><c> just</c>

00:04:08.330 --> 00:04:08.340 align:start position:0%
of these calculations you've just
 

00:04:08.340 --> 00:04:10.280 align:start position:0%
of these calculations you've just
computed<00:04:08.910><c> the</c><00:04:09.120><c> derivative</c><00:04:09.150><c> of</c><00:04:09.989><c> the</c><00:04:10.140><c> cost</c>

00:04:10.280 --> 00:04:10.290 align:start position:0%
computed the derivative of the cost
 

00:04:10.290 --> 00:04:12.199 align:start position:0%
computed the derivative of the cost
function<00:04:10.440><c> J</c><00:04:10.769><c> with</c><00:04:11.220><c> respect</c><00:04:11.250><c> to</c><00:04:11.820><c> e</c><00:04:11.850><c> 3</c>

00:04:12.199 --> 00:04:12.209 align:start position:0%
function J with respect to e 3
 

00:04:12.209 --> 00:04:16.159 align:start position:0%
function J with respect to e 3
parameters<00:04:12.450><c> w1</c><00:04:13.410><c> w2</c><00:04:14.280><c> and</c><00:04:14.610><c> be</c><00:04:15.180><c> just</c><00:04:15.930><c> a</c><00:04:15.989><c> couple</c>

00:04:16.159 --> 00:04:16.169 align:start position:0%
parameters w1 w2 and be just a couple
 

00:04:16.169 --> 00:04:18.460 align:start position:0%
parameters w1 w2 and be just a couple
details<00:04:16.440><c> of</c><00:04:16.769><c> what</c><00:04:16.950><c> we're</c><00:04:17.040><c> doing</c><00:04:17.340><c> we're</c><00:04:18.060><c> using</c>

00:04:18.460 --> 00:04:18.470 align:start position:0%
details of what we're doing we're using
 

00:04:18.470 --> 00:04:24.310 align:start position:0%
details of what we're doing we're using
DW<00:04:19.470><c> 1</c><00:04:19.739><c> +</c><00:04:20.039><c> DW</c><00:04:20.729><c> 2</c><00:04:21.060><c> and</c><00:04:21.210><c> DP</c><00:04:21.600><c> 2</c><00:04:22.410><c> as</c><00:04:22.729><c> accumulators</c>

00:04:24.310 --> 00:04:24.320 align:start position:0%
DW 1 + DW 2 and DP 2 as accumulators
 

00:04:24.320 --> 00:04:26.680 align:start position:0%
DW 1 + DW 2 and DP 2 as accumulators
so<00:04:24.560><c> that</c><00:04:24.740><c> after</c><00:04:25.040><c> this</c><00:04:25.190><c> computation</c><00:04:25.970><c> you</c><00:04:26.540><c> know</c>

00:04:26.680 --> 00:04:26.690 align:start position:0%
so that after this computation you know
 

00:04:26.690 --> 00:04:30.790 align:start position:0%
so that after this computation you know
DW<00:04:27.290><c> 1</c><00:04:27.500><c> is</c><00:04:27.800><c> equal</c><00:04:28.190><c> to</c><00:04:28.460><c> D</c><00:04:29.110><c> derivative</c><00:04:30.110><c> of</c><00:04:30.470><c> your</c>

00:04:30.790 --> 00:04:30.800 align:start position:0%
DW 1 is equal to D derivative of your
 

00:04:30.800 --> 00:04:33.160 align:start position:0%
DW 1 is equal to D derivative of your
overall<00:04:31.160><c> cost</c><00:04:31.520><c> function</c><00:04:31.610><c> with</c><00:04:32.330><c> respect</c><00:04:32.660><c> to</c><00:04:32.720><c> W</c>

00:04:33.160 --> 00:04:33.170 align:start position:0%
overall cost function with respect to W
 

00:04:33.170 --> 00:04:36.340 align:start position:0%
overall cost function with respect to W
1<00:04:33.350><c> and</c><00:04:33.560><c> similarly</c><00:04:34.100><c> for</c><00:04:34.490><c> DW</c><00:04:34.940><c> 2</c><00:04:35.120><c> and</c><00:04:35.390><c> DB</c><00:04:35.960><c> so</c>

00:04:36.340 --> 00:04:36.350 align:start position:0%
1 and similarly for DW 2 and DB so
 

00:04:36.350 --> 00:04:38.890 align:start position:0%
1 and similarly for DW 2 and DB so
notice<00:04:36.710><c> that</c><00:04:36.740><c> DW</c><00:04:37.400><c> 1</c><00:04:37.520><c> +</c><00:04:37.670><c> DW</c><00:04:37.880><c> to</c><00:04:38.210><c> do</c><00:04:38.450><c> not</c><00:04:38.660><c> have</c><00:04:38.870><c> a</c>

00:04:38.890 --> 00:04:38.900 align:start position:0%
notice that DW 1 + DW to do not have a
 

00:04:38.900 --> 00:04:40.840 align:start position:0%
notice that DW 1 + DW to do not have a
superscript<00:04:39.530><c> I</c><00:04:39.770><c> because</c><00:04:40.130><c> we're</c><00:04:40.400><c> using</c><00:04:40.610><c> them</c>

00:04:40.840 --> 00:04:40.850 align:start position:0%
superscript I because we're using them
 

00:04:40.850 --> 00:04:42.940 align:start position:0%
superscript I because we're using them
in<00:04:41.030><c> this</c><00:04:41.150><c> code</c><00:04:41.390><c> as</c><00:04:41.540><c> accumulators</c><00:04:42.320><c> to</c><00:04:42.470><c> sum</c><00:04:42.680><c> over</c>

00:04:42.940 --> 00:04:42.950 align:start position:0%
in this code as accumulators to sum over
 

00:04:42.950 --> 00:04:44.680 align:start position:0%
in this code as accumulators to sum over
the<00:04:43.070><c> entire</c><00:04:43.400><c> training</c><00:04:43.850><c> set</c><00:04:44.150><c> whereas</c><00:04:44.540><c> in</c>

00:04:44.680 --> 00:04:44.690 align:start position:0%
the entire training set whereas in
 

00:04:44.690 --> 00:04:48.490 align:start position:0%
the entire training set whereas in
contrast<00:04:44.840><c> DZ</c><00:04:45.710><c> I</c><00:04:45.740><c> here</c><00:04:46.340><c> this</c><00:04:46.820><c> was</c><00:04:47.000><c> d</c><00:04:47.810><c> Z</c><00:04:48.080><c> with</c>

00:04:48.490 --> 00:04:48.500 align:start position:0%
contrast DZ I here this was d Z with
 

00:04:48.500 --> 00:04:50.680 align:start position:0%
contrast DZ I here this was d Z with
respect<00:04:48.890><c> to</c><00:04:48.980><c> just</c><00:04:49.520><c> once</c><00:04:49.790><c> single</c><00:04:50.390><c> training</c>

00:04:50.680 --> 00:04:50.690 align:start position:0%
respect to just once single training
 

00:04:50.690 --> 00:04:52.090 align:start position:0%
respect to just once single training
example<00:04:50.840><c> so</c><00:04:51.290><c> that's</c><00:04:51.500><c> why</c><00:04:51.680><c> that</c><00:04:51.710><c> had</c><00:04:52.070><c> a</c>

00:04:52.090 --> 00:04:52.100 align:start position:0%
example so that's why that had a
 

00:04:52.100 --> 00:04:53.980 align:start position:0%
example so that's why that had a
superscript<00:04:52.670><c> I</c><00:04:52.850><c> to</c><00:04:52.940><c> refer</c><00:04:53.480><c> to</c><00:04:53.510><c> the</c><00:04:53.810><c> one</c>

00:04:53.980 --> 00:04:53.990 align:start position:0%
superscript I to refer to the one
 

00:04:53.990 --> 00:04:56.350 align:start position:0%
superscript I to refer to the one
training<00:04:54.260><c> example</c><00:04:54.410><c> either</c><00:04:55.250><c> that's</c><00:04:55.760><c> computed</c>

00:04:56.350 --> 00:04:56.360 align:start position:0%
training example either that's computed
 

00:04:56.360 --> 00:04:58.660 align:start position:0%
training example either that's computed
on<00:04:56.450><c> and</c><00:04:56.630><c> so</c><00:04:56.960><c> having</c><00:04:57.650><c> finished</c><00:04:58.100><c> all</c><00:04:58.400><c> these</c>

00:04:58.660 --> 00:04:58.670 align:start position:0%
on and so having finished all these
 

00:04:58.670 --> 00:05:01.180 align:start position:0%
on and so having finished all these
calculations<00:04:59.000><c> to</c><00:04:59.870><c> implement</c><00:05:00.380><c> one</c><00:05:00.680><c> step</c><00:05:00.980><c> of</c>

00:05:01.180 --> 00:05:01.190 align:start position:0%
calculations to implement one step of
 

00:05:01.190 --> 00:05:03.970 align:start position:0%
calculations to implement one step of
gradient<00:05:01.220><c> descent</c><00:05:01.580><c> you</c><00:05:02.180><c> implement</c><00:05:02.750><c> W</c><00:05:03.290><c> 1</c><00:05:03.500><c> gets</c>

00:05:03.970 --> 00:05:03.980 align:start position:0%
gradient descent you implement W 1 gets
 

00:05:03.980 --> 00:05:06.400 align:start position:0%
gradient descent you implement W 1 gets
updated<00:05:04.400><c> as</c><00:05:04.670><c> W</c><00:05:05.060><c> 1</c><00:05:05.090><c> minus</c><00:05:05.720><c> a</c><00:05:05.840><c> learning</c><00:05:06.200><c> rate</c>

00:05:06.400 --> 00:05:06.410 align:start position:0%
updated as W 1 minus a learning rate
 

00:05:06.410 --> 00:05:10.720 align:start position:0%
updated as W 1 minus a learning rate
times<00:05:06.590><c> D</c><00:05:07.100><c> W</c><00:05:07.820><c> 1</c><00:05:08.090><c> W</c><00:05:08.450><c> 2</c><00:05:08.660><c> kids</c><00:05:09.200><c> up</c><00:05:09.350><c> patients</c><00:05:09.770><c> W</c><00:05:10.040><c> 2</c><00:05:10.250><c> -</c>

00:05:10.720 --> 00:05:10.730 align:start position:0%
times D W 1 W 2 kids up patients W 2 -
 

00:05:10.730 --> 00:05:13.750 align:start position:0%
times D W 1 W 2 kids up patients W 2 -
learning<00:05:11.060><c> rate</c><00:05:11.180><c> times</c><00:05:11.210><c> DW</c><00:05:11.750><c> 2</c><00:05:12.260><c> and</c><00:05:12.500><c> B</c><00:05:12.980><c> gets</c>

00:05:13.750 --> 00:05:13.760 align:start position:0%
learning rate times DW 2 and B gets
 

00:05:13.760 --> 00:05:17.230 align:start position:0%
learning rate times DW 2 and B gets
updated<00:05:14.120><c> as</c><00:05:14.330><c> B</c><00:05:14.540><c> -</c><00:05:15.110><c> learning</c><00:05:15.950><c> rate</c><00:05:16.130><c> times</c><00:05:16.430><c> G</c><00:05:17.000><c> B</c>

00:05:17.230 --> 00:05:17.240 align:start position:0%
updated as B - learning rate times G B
 

00:05:17.240 --> 00:05:21.010 align:start position:0%
updated as B - learning rate times G B
where<00:05:17.590><c> DW</c><00:05:18.590><c> 1</c><00:05:18.740><c> DW</c><00:05:18.950><c> +</c><00:05:19.550><c> DB</c><00:05:19.730><c> where</c><00:05:20.180><c> you</c><00:05:20.720><c> know</c><00:05:20.810><c> as</c>

00:05:21.010 --> 00:05:21.020 align:start position:0%
where DW 1 DW + DB where you know as
 

00:05:21.020 --> 00:05:23.770 align:start position:0%
where DW 1 DW + DB where you know as
computed<00:05:21.740><c> and</c><00:05:22.520><c> finally</c><00:05:23.000><c> J</c><00:05:23.240><c> here</c><00:05:23.540><c> would</c><00:05:23.750><c> also</c>

00:05:23.770 --> 00:05:23.780 align:start position:0%
computed and finally J here would also
 

00:05:23.780 --> 00:05:27.010 align:start position:0%
computed and finally J here would also
be<00:05:24.320><c> a</c><00:05:24.700><c> correct</c><00:05:25.700><c> value</c><00:05:25.940><c> for</c><00:05:26.450><c> your</c><00:05:26.570><c> cost</c>

00:05:27.010 --> 00:05:27.020 align:start position:0%
be a correct value for your cost
 

00:05:27.020 --> 00:05:28.600 align:start position:0%
be a correct value for your cost
function<00:05:27.230><c> so</c><00:05:27.710><c> everything</c><00:05:28.250><c> on</c><00:05:28.340><c> this</c><00:05:28.490><c> slide</c>

00:05:28.600 --> 00:05:28.610 align:start position:0%
function so everything on this slide
 

00:05:28.610 --> 00:05:31.030 align:start position:0%
function so everything on this slide
implements<00:05:29.360><c> just</c><00:05:29.630><c> one</c><00:05:30.020><c> single</c><00:05:30.530><c> step</c><00:05:30.740><c> of</c>

00:05:31.030 --> 00:05:31.040 align:start position:0%
implements just one single step of
 

00:05:31.040 --> 00:05:33.100 align:start position:0%
implements just one single step of
gradient<00:05:31.280><c> descent</c><00:05:31.550><c> and</c><00:05:32.030><c> so</c><00:05:32.090><c> you</c><00:05:32.660><c> have</c><00:05:32.930><c> to</c>

00:05:33.100 --> 00:05:33.110 align:start position:0%
gradient descent and so you have to
 

00:05:33.110 --> 00:05:35.740 align:start position:0%
gradient descent and so you have to
repeat<00:05:33.890><c> everything</c><00:05:34.220><c> on</c><00:05:34.430><c> this</c><00:05:34.580><c> slide</c><00:05:34.940><c> multiple</c>

00:05:35.740 --> 00:05:35.750 align:start position:0%
repeat everything on this slide multiple
 

00:05:35.750 --> 00:05:37.720 align:start position:0%
repeat everything on this slide multiple
times<00:05:35.960><c> in</c><00:05:36.290><c> order</c><00:05:36.440><c> to</c><00:05:36.620><c> take</c><00:05:36.920><c> multiple</c><00:05:37.340><c> steps</c><00:05:37.580><c> of</c>

00:05:37.720 --> 00:05:37.730 align:start position:0%
times in order to take multiple steps of
 

00:05:37.730 --> 00:05:40.510 align:start position:0%
times in order to take multiple steps of
gradient<00:05:37.850><c> descent</c><00:05:38.170><c> in</c><00:05:39.170><c> case</c><00:05:39.410><c> these</c><00:05:39.950><c> details</c>

00:05:40.510 --> 00:05:40.520 align:start position:0%
gradient descent in case these details
 

00:05:40.520 --> 00:05:42.970 align:start position:0%
gradient descent in case these details
seem<00:05:40.790><c> too</c><00:05:41.000><c> complicated</c><00:05:41.530><c> again</c><00:05:42.530><c> don't</c><00:05:42.890><c> worry</c>

00:05:42.970 --> 00:05:42.980 align:start position:0%
seem too complicated again don't worry
 

00:05:42.980 --> 00:05:45.160 align:start position:0%
seem too complicated again don't worry
too<00:05:43.220><c> much</c><00:05:43.250><c> about</c><00:05:43.370><c> it</c><00:05:43.610><c> for</c><00:05:43.880><c> now</c><00:05:43.910><c> hopefully</c><00:05:44.840><c> all</c>

00:05:45.160 --> 00:05:45.170 align:start position:0%
too much about it for now hopefully all
 

00:05:45.170 --> 00:05:47.470 align:start position:0%
too much about it for now hopefully all
this<00:05:45.350><c> would</c><00:05:45.530><c> be</c><00:05:45.650><c> clearer</c><00:05:45.980><c> when</c><00:05:46.790><c> you</c><00:05:47.060><c> go</c><00:05:47.360><c> and</c>

00:05:47.470 --> 00:05:47.480 align:start position:0%
this would be clearer when you go and
 

00:05:47.480 --> 00:05:49.570 align:start position:0%
this would be clearer when you go and
implement<00:05:47.720><c> as</c><00:05:48.110><c> in</c><00:05:48.350><c> G</c><00:05:48.650><c> programming</c><00:05:49.130><c> assignment</c>

00:05:49.570 --> 00:05:49.580 align:start position:0%
implement as in G programming assignment
 

00:05:49.580 --> 00:05:51.750 align:start position:0%
implement as in G programming assignment
but<00:05:50.030><c> it</c><00:05:50.150><c> turns</c><00:05:50.360><c> out</c><00:05:50.570><c> there</c><00:05:50.900><c> are</c><00:05:50.930><c> two</c>

00:05:51.750 --> 00:05:51.760 align:start position:0%
but it turns out there are two
 

00:05:51.760 --> 00:05:55.420 align:start position:0%
but it turns out there are two
weaknesses<00:05:52.760><c> with</c><00:05:53.660><c> the</c><00:05:54.170><c> calculation</c><00:05:55.070><c> as</c><00:05:55.340><c> well</c>

00:05:55.420 --> 00:05:55.430 align:start position:0%
weaknesses with the calculation as well
 

00:05:55.430 --> 00:05:58.420 align:start position:0%
weaknesses with the calculation as well
as<00:05:56.060><c> we've</c><00:05:56.660><c> implemented</c><00:05:57.140><c> it</c><00:05:57.440><c> here</c><00:05:57.740><c> which</c><00:05:58.220><c> is</c>

00:05:58.420 --> 00:05:58.430 align:start position:0%
as we've implemented it here which is
 

00:05:58.430 --> 00:06:00.670 align:start position:0%
as we've implemented it here which is
that<00:05:58.640><c> to</c><00:05:59.240><c> implement</c><00:05:59.570><c> logistic</c><00:06:00.200><c> regression</c>

00:06:00.670 --> 00:06:00.680 align:start position:0%
that to implement logistic regression
 

00:06:00.680 --> 00:06:03.040 align:start position:0%
that to implement logistic regression
this<00:06:00.830><c> way</c><00:06:01.040><c> you</c><00:06:01.100><c> need</c><00:06:01.430><c> to</c><00:06:01.610><c> write</c><00:06:02.210><c> to</c><00:06:02.240><c> for</c><00:06:02.780><c> loops</c>

00:06:03.040 --> 00:06:03.050 align:start position:0%
this way you need to write to for loops
 

00:06:03.050 --> 00:06:04.990 align:start position:0%
this way you need to write to for loops
the<00:06:03.320><c> first</c><00:06:03.590><c> for</c><00:06:03.800><c> loop</c><00:06:04.010><c> is</c><00:06:04.160><c> this</c><00:06:04.310><c> for</c><00:06:04.520><c> loop</c><00:06:04.670><c> over</c>

00:06:04.990 --> 00:06:05.000 align:start position:0%
the first for loop is this for loop over
 

00:06:05.000 --> 00:06:07.210 align:start position:0%
the first for loop is this for loop over
the<00:06:05.030><c> M</c><00:06:05.240><c> training</c><00:06:05.510><c> examples</c><00:06:05.600><c> and</c><00:06:06.200><c> the</c><00:06:06.830><c> second</c>

00:06:07.210 --> 00:06:07.220 align:start position:0%
the M training examples and the second
 

00:06:07.220 --> 00:06:09.370 align:start position:0%
the M training examples and the second
for<00:06:07.400><c> loop</c><00:06:07.430><c> is</c><00:06:07.760><c> a</c><00:06:07.790><c> for</c><00:06:08.060><c> loop</c><00:06:08.240><c> over</c><00:06:08.750><c> all</c><00:06:08.930><c> the</c>

00:06:09.370 --> 00:06:09.380 align:start position:0%
for loop is a for loop over all the
 

00:06:09.380 --> 00:06:12.010 align:start position:0%
for loop is a for loop over all the
features<00:06:09.770><c> over</c><00:06:10.730><c> here</c><00:06:11.000><c> right</c><00:06:11.480><c> so</c><00:06:11.690><c> in</c><00:06:11.900><c> this</c>

00:06:12.010 --> 00:06:12.020 align:start position:0%
features over here right so in this
 

00:06:12.020 --> 00:06:14.110 align:start position:0%
features over here right so in this
example<00:06:12.170><c> we</c><00:06:12.680><c> just</c><00:06:12.710><c> had</c><00:06:12.920><c> two</c><00:06:13.160><c> features</c><00:06:13.640><c> so</c><00:06:13.910><c> n</c>

00:06:14.110 --> 00:06:14.120 align:start position:0%
example we just had two features so n
 

00:06:14.120 --> 00:06:17.350 align:start position:0%
example we just had two features so n
it's<00:06:14.330><c> equal</c><00:06:14.750><c> to</c><00:06:14.900><c> 2</c><00:06:15.110><c> and</c><00:06:15.470><c> x</c><00:06:15.980><c> equals</c><00:06:16.310><c> 2</c><00:06:16.370><c> but</c><00:06:16.850><c> if</c>

00:06:17.350 --> 00:06:17.360 align:start position:0%
it's equal to 2 and x equals 2 but if
 

00:06:17.360 --> 00:06:18.580 align:start position:0%
it's equal to 2 and x equals 2 but if
you<00:06:17.450><c> have</c><00:06:17.540><c> more</c><00:06:17.720><c> features</c><00:06:17.900><c> you</c><00:06:18.140><c> end</c><00:06:18.440><c> up</c>

00:06:18.580 --> 00:06:18.590 align:start position:0%
you have more features you end up
 

00:06:18.590 --> 00:06:21.640 align:start position:0%
you have more features you end up
writing<00:06:18.860><c> yo</c><00:06:19.160><c> DW</c><00:06:19.760><c> 1</c><00:06:19.880><c> DW</c><00:06:20.090><c> 2</c><00:06:20.600><c> and</c><00:06:20.840><c> here</c><00:06:21.290><c> similar</c>

00:06:21.640 --> 00:06:21.650 align:start position:0%
writing yo DW 1 DW 2 and here similar
 

00:06:21.650 --> 00:06:24.430 align:start position:0%
writing yo DW 1 DW 2 and here similar
computations<00:06:22.220><c> for</c><00:06:22.400><c> DW</c><00:06:22.850><c> 3</c><00:06:23.120><c> and</c><00:06:23.420><c> so</c><00:06:23.930><c> on</c><00:06:23.960><c> down</c><00:06:24.380><c> to</c>

00:06:24.430 --> 00:06:24.440 align:start position:0%
computations for DW 3 and so on down to
 

00:06:24.440 --> 00:06:26.860 align:start position:0%
computations for DW 3 and so on down to
DW<00:06:25.100><c> n</c><00:06:25.280><c> so</c><00:06:25.490><c> it</c><00:06:25.550><c> seems</c><00:06:25.730><c> like</c><00:06:25.880><c> you</c><00:06:26.000><c> need</c><00:06:26.150><c> to</c><00:06:26.210><c> have</c><00:06:26.510><c> a</c>

00:06:26.860 --> 00:06:26.870 align:start position:0%
DW n so it seems like you need to have a
 

00:06:26.870 --> 00:06:30.400 align:start position:0%
DW n so it seems like you need to have a
for<00:06:27.230><c> loop</c><00:06:27.260><c> over</c><00:06:27.680><c> the</c><00:06:28.480><c> features</c><00:06:29.480><c> over</c><00:06:29.840><c> our</c><00:06:30.020><c> n</c>

00:06:30.400 --> 00:06:30.410 align:start position:0%
for loop over the features over our n
 

00:06:30.410 --> 00:06:33.010 align:start position:0%
for loop over the features over our n
features<00:06:30.740><c> when</c><00:06:31.640><c> you're</c><00:06:31.880><c> implementing</c><00:06:32.419><c> deep</c>

00:06:33.010 --> 00:06:33.020 align:start position:0%
features when you're implementing deep
 

00:06:33.020 --> 00:06:35.590 align:start position:0%
features when you're implementing deep
learning<00:06:33.230><c> algorithms</c><00:06:34.010><c> you</c><00:06:34.610><c> find</c><00:06:34.940><c> that</c><00:06:35.180><c> having</c>

00:06:35.590 --> 00:06:35.600 align:start position:0%
learning algorithms you find that having
 

00:06:35.600 --> 00:06:36.460 align:start position:0%
learning algorithms you find that having
explicit

00:06:36.460 --> 00:06:36.470 align:start position:0%
explicit
 

00:06:36.470 --> 00:06:38.440 align:start position:0%
explicit
for<00:06:36.590><c> loops</c><00:06:36.830><c> in</c><00:06:37.010><c> your</c><00:06:37.130><c> code</c><00:06:37.400><c> makes</c><00:06:38.150><c> your</c>

00:06:38.440 --> 00:06:38.450 align:start position:0%
for loops in your code makes your
 

00:06:38.450 --> 00:06:41.860 align:start position:0%
for loops in your code makes your
algorithm<00:06:39.230><c> run</c><00:06:39.650><c> less</c><00:06:40.160><c> efficiency</c><00:06:40.730><c> and</c><00:06:41.150><c> so</c><00:06:41.570><c> in</c>

00:06:41.860 --> 00:06:41.870 align:start position:0%
algorithm run less efficiency and so in
 

00:06:41.870 --> 00:06:44.140 align:start position:0%
algorithm run less efficiency and so in
the<00:06:42.050><c> deep</c><00:06:42.290><c> learning</c><00:06:42.470><c> error</c><00:06:42.890><c> would</c><00:06:43.580><c> move</c><00:06:43.880><c> to</c>

00:06:44.140 --> 00:06:44.150 align:start position:0%
the deep learning error would move to
 

00:06:44.150 --> 00:06:46.660 align:start position:0%
the deep learning error would move to
bigger<00:06:44.390><c> and</c><00:06:44.540><c> bigger</c><00:06:44.840><c> data</c><00:06:45.530><c> sets</c><00:06:45.890><c> and</c><00:06:46.160><c> so</c><00:06:46.430><c> being</c>

00:06:46.660 --> 00:06:46.670 align:start position:0%
bigger and bigger data sets and so being
 

00:06:46.670 --> 00:06:48.670 align:start position:0%
bigger and bigger data sets and so being
able<00:06:46.790><c> to</c><00:06:47.000><c> implement</c><00:06:47.390><c> your</c><00:06:48.140><c> algorithms</c>

00:06:48.670 --> 00:06:48.680 align:start position:0%
able to implement your algorithms
 

00:06:48.680 --> 00:06:50.830 align:start position:0%
able to implement your algorithms
without<00:06:49.070><c> using</c><00:06:49.460><c> explicit</c><00:06:50.120><c> for</c><00:06:50.390><c> loops</c><00:06:50.630><c> is</c>

00:06:50.830 --> 00:06:50.840 align:start position:0%
without using explicit for loops is
 

00:06:50.840 --> 00:06:52.840 align:start position:0%
without using explicit for loops is
really<00:06:51.620><c> important</c><00:06:52.100><c> and</c><00:06:52.310><c> will</c><00:06:52.460><c> help</c><00:06:52.490><c> you</c><00:06:52.820><c> to</c>

00:06:52.840 --> 00:06:52.850 align:start position:0%
really important and will help you to
 

00:06:52.850 --> 00:06:55.150 align:start position:0%
really important and will help you to
scale<00:06:53.240><c> to</c><00:06:53.300><c> much</c><00:06:53.690><c> bigger</c><00:06:53.900><c> data</c><00:06:54.140><c> sets</c><00:06:54.530><c> so</c><00:06:55.100><c> it</c>

00:06:55.150 --> 00:06:55.160 align:start position:0%
scale to much bigger data sets so it
 

00:06:55.160 --> 00:06:56.740 align:start position:0%
scale to much bigger data sets so it
turns<00:06:55.370><c> out</c><00:06:55.610><c> that</c><00:06:55.940><c> there</c><00:06:56.330><c> are</c><00:06:56.360><c> set</c><00:06:56.630><c> of</c>

00:06:56.740 --> 00:06:56.750 align:start position:0%
turns out that there are set of
 

00:06:56.750 --> 00:06:58.150 align:start position:0%
turns out that there are set of
techniques<00:06:57.050><c> called</c><00:06:57.500><c> vectorization</c>

00:06:58.150 --> 00:06:58.160 align:start position:0%
techniques called vectorization
 

00:06:58.160 --> 00:07:01.180 align:start position:0%
techniques called vectorization
techniques<00:06:58.910><c> that</c><00:06:59.510><c> allow</c><00:06:59.810><c> you</c><00:06:59.870><c> to</c><00:07:00.140><c> get</c><00:07:00.860><c> rid</c><00:07:01.070><c> of</c>

00:07:01.180 --> 00:07:01.190 align:start position:0%
techniques that allow you to get rid of
 

00:07:01.190 --> 00:07:03.550 align:start position:0%
techniques that allow you to get rid of
these<00:07:01.400><c> explicit</c><00:07:01.910><c> full</c><00:07:02.390><c> loops</c><00:07:02.660><c> in</c><00:07:02.840><c> your</c><00:07:02.960><c> code</c><00:07:03.230><c> I</c>

00:07:03.550 --> 00:07:03.560 align:start position:0%
these explicit full loops in your code I
 

00:07:03.560 --> 00:07:06.190 align:start position:0%
these explicit full loops in your code I
think<00:07:04.190><c> in</c><00:07:04.400><c> the</c><00:07:04.640><c> pre</c><00:07:05.060><c> deep</c><00:07:05.510><c> learning</c><00:07:05.720><c> era</c>

00:07:06.190 --> 00:07:06.200 align:start position:0%
think in the pre deep learning era
 

00:07:06.200 --> 00:07:08.220 align:start position:0%
think in the pre deep learning era
that's<00:07:06.740><c> before</c><00:07:07.220><c> the</c><00:07:07.340><c> rise</c><00:07:07.520><c> of</c><00:07:07.550><c> deep</c><00:07:07.850><c> learning</c>

00:07:08.220 --> 00:07:08.230 align:start position:0%
that's before the rise of deep learning
 

00:07:08.230 --> 00:07:11.260 align:start position:0%
that's before the rise of deep learning
vectorization<00:07:09.230><c> was</c><00:07:09.860><c> a</c><00:07:09.890><c> nice</c><00:07:10.310><c> to</c><00:07:10.550><c> have</c><00:07:10.760><c> you</c>

00:07:11.260 --> 00:07:11.270 align:start position:0%
vectorization was a nice to have you
 

00:07:11.270 --> 00:07:13.180 align:start position:0%
vectorization was a nice to have you
could<00:07:11.450><c> sometimes</c><00:07:11.750><c> do</c><00:07:12.200><c> it</c><00:07:12.350><c> to</c><00:07:12.500><c> speed</c><00:07:12.740><c> Agricole</c>

00:07:13.180 --> 00:07:13.190 align:start position:0%
could sometimes do it to speed Agricole
 

00:07:13.190 --> 00:07:15.610 align:start position:0%
could sometimes do it to speed Agricole
and<00:07:13.580><c> sometimes</c><00:07:14.090><c> not</c><00:07:14.300><c> but</c><00:07:15.110><c> in</c><00:07:15.290><c> the</c><00:07:15.410><c> deep</c>

00:07:15.610 --> 00:07:15.620 align:start position:0%
and sometimes not but in the deep
 

00:07:15.620 --> 00:07:17.770 align:start position:0%
and sometimes not but in the deep
learning<00:07:15.830><c> era</c><00:07:16.220><c> vectorization</c><00:07:16.910><c> that</c><00:07:17.600><c> is</c>

00:07:17.770 --> 00:07:17.780 align:start position:0%
learning era vectorization that is
 

00:07:17.780 --> 00:07:20.050 align:start position:0%
learning era vectorization that is
getting<00:07:18.170><c> rid</c><00:07:18.320><c> of</c><00:07:18.440><c> for</c><00:07:18.680><c> loops</c><00:07:18.950><c> like</c><00:07:19.550><c> this</c><00:07:19.790><c> and</c>

00:07:20.050 --> 00:07:20.060 align:start position:0%
getting rid of for loops like this and
 

00:07:20.060 --> 00:07:22.720 align:start position:0%
getting rid of for loops like this and
like<00:07:20.210><c> this</c><00:07:20.480><c> has</c><00:07:21.320><c> become</c><00:07:21.770><c> really</c><00:07:22.070><c> important</c>

00:07:22.720 --> 00:07:22.730 align:start position:0%
like this has become really important
 

00:07:22.730 --> 00:07:25.060 align:start position:0%
like this has become really important
because<00:07:23.180><c> we're</c><00:07:23.600><c> more</c><00:07:23.780><c> and</c><00:07:23.930><c> more</c><00:07:24.110><c> training</c><00:07:24.710><c> on</c>

00:07:25.060 --> 00:07:25.070 align:start position:0%
because we're more and more training on
 

00:07:25.070 --> 00:07:27.010 align:start position:0%
because we're more and more training on
very<00:07:25.370><c> large</c><00:07:25.580><c> datasets</c><00:07:26.030><c> and</c><00:07:26.510><c> so</c><00:07:26.630><c> you</c><00:07:26.690><c> really</c>

00:07:27.010 --> 00:07:27.020 align:start position:0%
very large datasets and so you really
 

00:07:27.020 --> 00:07:29.260 align:start position:0%
very large datasets and so you really
need<00:07:27.230><c> your</c><00:07:27.440><c> code</c><00:07:27.620><c> to</c><00:07:27.830><c> be</c><00:07:27.950><c> very</c><00:07:28.190><c> efficient</c><00:07:28.700><c> so</c>

00:07:29.260 --> 00:07:29.270 align:start position:0%
need your code to be very efficient so
 

00:07:29.270 --> 00:07:31.230 align:start position:0%
need your code to be very efficient so
in<00:07:29.510><c> the</c><00:07:29.630><c> next</c><00:07:29.900><c> few</c><00:07:30.080><c> videos</c><00:07:30.230><c> we'll</c><00:07:30.800><c> talk</c><00:07:30.980><c> about</c>

00:07:31.230 --> 00:07:31.240 align:start position:0%
in the next few videos we'll talk about
 

00:07:31.240 --> 00:07:34.270 align:start position:0%
in the next few videos we'll talk about
vectorization<00:07:32.240><c> and</c><00:07:32.870><c> how</c><00:07:33.380><c> to</c><00:07:33.440><c> implement</c><00:07:34.070><c> all</c>

00:07:34.270 --> 00:07:34.280 align:start position:0%
vectorization and how to implement all
 

00:07:34.280 --> 00:07:37.330 align:start position:0%
vectorization and how to implement all
this<00:07:34.550><c> without</c><00:07:35.390><c> using</c><00:07:35.930><c> even</c><00:07:36.440><c> a</c><00:07:36.680><c> single</c><00:07:36.950><c> full</c>

00:07:37.330 --> 00:07:37.340 align:start position:0%
this without using even a single full
 

00:07:37.340 --> 00:07:40.930 align:start position:0%
this without using even a single full
loop<00:07:38.470><c> so</c><00:07:39.470><c> of</c><00:07:39.620><c> this</c><00:07:39.800><c> I</c><00:07:39.830><c> hope</c><00:07:40.250><c> you</c><00:07:40.400><c> have</c><00:07:40.580><c> a</c><00:07:40.610><c> sense</c>

00:07:40.930 --> 00:07:40.940 align:start position:0%
loop so of this I hope you have a sense
 

00:07:40.940 --> 00:07:42.580 align:start position:0%
loop so of this I hope you have a sense
of<00:07:41.120><c> how</c><00:07:41.300><c> to</c><00:07:41.360><c> implement</c><00:07:41.960><c> the</c><00:07:42.260><c> gistic</c>

00:07:42.580 --> 00:07:42.590 align:start position:0%
of how to implement the gistic
 

00:07:42.590 --> 00:07:43.990 align:start position:0%
of how to implement the gistic
regression<00:07:43.130><c> or</c><00:07:43.280><c> gradient</c><00:07:43.490><c> descent</c><00:07:43.910><c> for</c>

00:07:43.990 --> 00:07:44.000 align:start position:0%
regression or gradient descent for
 

00:07:44.000 --> 00:07:46.120 align:start position:0%
regression or gradient descent for
logistic<00:07:44.360><c> regression</c><00:07:44.800><c> things</c><00:07:45.800><c> will</c><00:07:45.980><c> be</c>

00:07:46.120 --> 00:07:46.130 align:start position:0%
logistic regression things will be
 

00:07:46.130 --> 00:07:47.409 align:start position:0%
logistic regression things will be
clearer<00:07:46.400><c> when</c><00:07:46.640><c> you</c><00:07:46.760><c> implement</c><00:07:47.030><c> the</c><00:07:47.300><c> program</c>

00:07:47.409 --> 00:07:47.419 align:start position:0%
clearer when you implement the program
 

00:07:47.419 --> 00:07:50.080 align:start position:0%
clearer when you implement the program
exercise<00:07:47.990><c> but</c><00:07:48.830><c> before</c><00:07:49.220><c> actually</c><00:07:49.730><c> doing</c><00:07:50.000><c> the</c>

00:07:50.080 --> 00:07:50.090 align:start position:0%
exercise but before actually doing the
 

00:07:50.090 --> 00:07:51.850 align:start position:0%
exercise but before actually doing the
program<00:07:50.330><c> exercise</c><00:07:50.750><c> let's</c><00:07:51.350><c> first</c><00:07:51.590><c> talk</c><00:07:51.800><c> about</c>

00:07:51.850 --> 00:07:51.860 align:start position:0%
program exercise let's first talk about
 

00:07:51.860 --> 00:07:54.070 align:start position:0%
program exercise let's first talk about
vectorization<00:07:52.669><c> so</c><00:07:53.330><c> that</c><00:07:53.540><c> you</c><00:07:53.660><c> can</c><00:07:53.810><c> implement</c>

00:07:54.070 --> 00:07:54.080 align:start position:0%
vectorization so that you can implement
 

00:07:54.080 --> 00:07:56.440 align:start position:0%
vectorization so that you can implement
this<00:07:54.350><c> whole</c><00:07:54.560><c> thing</c><00:07:54.970><c> implement</c><00:07:55.970><c> in</c><00:07:56.120><c> single</c>

00:07:56.440 --> 00:07:56.450 align:start position:0%
this whole thing implement in single
 

00:07:56.450 --> 00:07:58.180 align:start position:0%
this whole thing implement in single
iteration<00:07:56.960><c> of</c><00:07:57.020><c> gradient</c><00:07:57.080><c> descent</c><00:07:57.470><c> without</c>

00:07:58.180 --> 00:07:58.190 align:start position:0%
iteration of gradient descent without
 

00:07:58.190 --> 00:08:01.540 align:start position:0%
iteration of gradient descent without
using<00:07:58.790><c> any</c><00:07:59.030><c> full</c><00:07:59.330><c> news</c>

