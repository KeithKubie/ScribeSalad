WEBVTT
Kind: captions
Language: en

00:00:03.040 --> 00:00:06.540
Hi, I’m Adriene Hill, and Welcome back to
Crash Course, Statistics.

00:00:06.549 --> 00:00:12.019
In the last episode we talked about Null Hypothesis Significance testing and p-values and how

00:00:12.019 --> 00:00:15.360
these two things help us make decisions about things we care about.

00:00:15.360 --> 00:00:19.580
Like whether babies who drink non-dairy milk are more likely to have allergies, or whether

00:00:19.580 --> 00:00:24.610
the number of hours you spend watching home makeover shows tends to increase with age.

00:00:24.610 --> 00:00:28.360
We don’t always come up with the right answer, even if it seemed reasonable.

00:00:28.360 --> 00:00:30.960
We want to limit our errors as much as possible.

00:00:30.960 --> 00:00:34.540
Today we’ll talk about when and why we might get it wrong.

00:00:34.540 --> 00:00:43.800
INTRO

00:00:43.810 --> 00:00:47.860
In the last episode we briefly touched on
“rejecting” the null hypothesis.

00:00:47.860 --> 00:00:52.680
P-values tell us how “rare” or “extreme”
our sample data would be if it really did

00:00:52.680 --> 00:00:54.640
come from the null distribution.

00:00:54.640 --> 00:00:58.680
Null means nothing so null hypotheses tend to say that there’s no effect, or nothing’s

00:00:58.680 --> 00:00:59.680
going on.

00:00:59.680 --> 00:01:04.610
For example, for whether babies who drink
non-dairy milk are more likely to have allergies,

00:01:04.610 --> 00:01:09.450
the null hypothesis (or H0) would be that
there is no difference in proportion of babies

00:01:09.450 --> 00:01:14.060
with allergies between babies who drink non-dairy milk, and those who do not.

00:01:14.060 --> 00:01:19.270
In the case of home makeover shows, the null hypothesis might be that there’s no relationship.

00:01:19.270 --> 00:01:24.229
So the regression slope--or coefficient--between number of home makeover shows watched and

00:01:24.229 --> 00:01:26.060
age would be 0:

00:01:26.060 --> 00:01:29.950
By looking at this slope, we can see it’s
not exactly flat, but we don’t know whether

00:01:29.950 --> 00:01:33.850
this slope is due to a real relationship,
or just random variation.

00:01:33.850 --> 00:01:38.179
When we get low p-values, we “reject”
the null hypothesis because we’ve decided

00:01:38.179 --> 00:01:42.829
that our data would be pretty rare if the
null was true since the probability of getting

00:01:42.829 --> 00:01:47.409
data as or more extreme than ours is below
our alpha level.

00:01:47.409 --> 00:01:48.810
That’s option 1.

00:01:48.810 --> 00:01:54.209
Option 2 is that our p-value is not lower
than our pre-selected cutoff which means that

00:01:54.209 --> 00:01:56.600
we “fail to reject” the null hypothesis.

00:01:56.600 --> 00:02:01.060
So, we’ve narrowed it down to two decisions: we can either reject, or fail to reject the null.

00:02:01.060 --> 00:02:03.680
The null can either be true, or not true.

00:02:03.680 --> 00:02:10.259
This means that there are four possible situations: either you correctly reject the null, mistakenly

00:02:10.260 --> 00:02:15.140
reject the null, correctly fail to reject
the null, or mistakenly fail to reject the null.

00:02:15.140 --> 00:02:19.300
In two of these situations we make the correct decisions, and in the other two, we’d have

00:02:19.310 --> 00:02:20.300
made an error.

00:02:20.300 --> 00:02:25.140
The first error is called a Type I error,
which is rejecting the null, even if it’s true.

00:02:25.140 --> 00:02:28.420
It can therefore only happen if the null is
true.

00:02:28.420 --> 00:02:33.420
Say we’ve decided that our alpha level is
0.05, so we’ll reject the null if our p-value

00:02:33.420 --> 00:02:39.189
is smaller than 0.05, which means that our
sample is in the 5% most extreme values we

00:02:39.189 --> 00:02:42.469
can expect to get if the null hypothesis were true.

00:02:42.469 --> 00:02:47.689
So, if the null is true, 5% of the time, we’ll
still reject it mistakenly, just because we

00:02:47.689 --> 00:02:50.269
happened to get a rare value.

00:02:50.269 --> 00:02:54.920
The red shaded region represents all the values from the null distribution that would cause

00:02:54.920 --> 00:02:58.269
us to decide to “reject” the null, even
if it was true.

00:02:58.269 --> 00:03:03.879
Since our type 1 error rate is equal to alpha,
we get to choose exactly how often we are

00:03:03.879 --> 00:03:07.709
willing to make Type 1 errors when we choose our alpha.

00:03:07.709 --> 00:03:11.959
We control our Type I errors by explicitly
deciding how often we’ll make them.

00:03:11.959 --> 00:03:16.349
We could also make an error by failing to
reject the null hypothesis when it actually is false.

00:03:17.720 --> 00:03:22.939
In order for the null hypothesis to be false,
some other, alternative, hypothesis must be true.

00:03:23.939 --> 00:03:28.099
We mentioned in the last episode that we don’t actually know any specifics about which hypothesis

00:03:28.099 --> 00:03:31.150
is correct when we “reject the null”,
it could be anything.

00:03:31.150 --> 00:03:36.909
But we can estimate which distribution might be correct, we’ll show it outlined in gray,

00:03:36.909 --> 00:03:40.709
this helps us to compare two distributions
instead of just looking at one.

00:03:40.709 --> 00:03:45.010
We estimate the alternative distribution based on the mean and standard deviation of our

00:03:45.010 --> 00:03:46.459
experimental group.

00:03:46.459 --> 00:03:51.950
The sample mean is our best guess at what he effect size is, so we often use that if

00:03:51.950 --> 00:03:55.790
we’re estimating the alternative after we’ve
collected our data.

00:03:55.790 --> 00:03:59.819
But sometimes we want to estimate it before we collect data, in which case we use the

00:03:59.819 --> 00:04:02.480
sample estimates from other, related studies.

00:04:02.480 --> 00:04:05.900
We’re assuming the Alternative (Ha) distribution looks like this.

00:04:05.900 --> 00:04:10.670
Our cutoff line is still in the same place;
it marks the cutoffs that tell us where the

00:04:10.670 --> 00:04:13.160
5% most extreme values are.

00:04:13.160 --> 00:04:17.590
Any value we get that is to the right of the
line causes us to “reject the null” and

00:04:17.590 --> 00:04:21.959
any value to the left of the line causes us
to “fail to reject the null”.

00:04:21.959 --> 00:04:27.160
The cutoff value doesn’t change depending
on whether H0 or HA is true.

00:04:27.160 --> 00:04:32.720
So, if the alternative is true, we still might
fail to reject the null if we happen to get

00:04:32.720 --> 00:04:35.060
a value that is to the left of the cutoff.

00:04:35.060 --> 00:04:40.280
The blue shaded region shows you the values where we’ll make this Type II error.

00:04:40.280 --> 00:04:46.360
Just like the rate of Type I errors is equal
to alpha, the rate of type II errors is equal to Beta.

00:04:46.360 --> 00:04:49.800
Since we’re only estimating what the alternative distribution looks like, we can’t know what

00:04:49.860 --> 00:04:55.320
Beta is for sure, but again we can estimate
it by using our cutoff (alpha) and our best

00:04:55.330 --> 00:05:00.400
estimates of the shape and position of our
alternative distribution to find the approximate

00:05:00.400 --> 00:05:01.830
area of the shaded region.

00:05:01.830 --> 00:05:05.100
There’s often a trade off between Type I
and Type II errors.

00:05:05.100 --> 00:05:10.560
Type I errors are essentially False positives:
we think we’ve detected an effect, but there isn't one.

00:05:10.560 --> 00:05:16.500
And Type II errors are False negatives: there was an effect, we just didn’t see it.

00:05:16.500 --> 00:05:20.600
And while both of these mean we were wrong, there’s a lot of times where we may prefer

00:05:20.600 --> 00:05:23.110
one type of error over the other.

00:05:23.110 --> 00:05:24.110
Take smoke alarms.

00:05:24.110 --> 00:05:27.920
While the sound of the smoke alarm going off is annoying, there’s not a lot of cost to

00:05:27.920 --> 00:05:31.140
having a false positive--or type I error.

00:05:31.140 --> 00:05:34.130
All you have to do is press a button to reset
it.

00:05:34.130 --> 00:05:40.080
There is however a huge risk if your smoke
alarm does not go off when there really is a fire.

00:05:40.080 --> 00:05:45.800
For this reason, fire alarms tend to favor
having type I errors over type II errors.

00:05:45.800 --> 00:05:49.940
Which is why sometimes particularly long,
hot showers can cause them to go off.

00:05:49.940 --> 00:05:51.170
Better safe than sorry.

00:05:51.170 --> 00:05:54.020
But yeah, turning off an alarm when you’re
naked and wet.

00:05:54.020 --> 00:05:55.020
Not fun.

00:05:55.020 --> 00:05:59.060
Think about someone in your life who is constantly worried, they operate on the assumption that

00:05:59.060 --> 00:06:03.490
Type I errors--thinking there’ll be an issue
when there won’t be--are preferable to Type

00:06:03.490 --> 00:06:07.710
II errors--not preparing for a problem when
there really could be one.

00:06:07.710 --> 00:06:12.420
You can see on this graph that if we assume our null distribution is here, and the alternative

00:06:12.420 --> 00:06:17.570
is here, then moving the cutoff threshold
to the right will cause us--all other things

00:06:17.570 --> 00:06:20.260
being equal--to have fewer type I errors.

00:06:20.260 --> 00:06:25.950
But we’ll have more type II errors since
less of the null distribution is in the “reject”

00:06:25.950 --> 00:06:30.560
region, and more of the alternative distribution is in the “fail to reject region”.

00:06:30.560 --> 00:06:33.930
And the opposite happens if we move our cutoff threshold to the left.

00:06:33.930 --> 00:06:38.550
We’ll have more False positives since more
of the null is in the “reject” region,

00:06:38.550 --> 00:06:43.411
but fewer False Negatives because less of
the alternative distribution is in the “fail

00:06:43.411 --> 00:06:44.730
to reject” region.

00:06:44.730 --> 00:06:47.720
If the error types hard to keep straight,
think of the Boy who cried wolf.

00:06:47.720 --> 00:06:50.890
In that story the villagers first made a type
I error (thinking there was a wolf when there

00:06:50.890 --> 00:06:55.110
really wasn’t), but by the end--and to the
detriment of the little boy--they made a type

00:06:55.110 --> 00:06:59.080
II error: thinking there WASN’T a wolf when
there really.

00:06:59.080 --> 00:07:02.940
Sometimes we do make the right decision and there are two ways to be right: either the

00:07:02.940 --> 00:07:08.100
null hypothesis is true and we fail to reject
it, or the null hypothesis is false and we

00:07:08.100 --> 00:07:09.260
do reject it.

00:07:09.260 --> 00:07:13.040
If the null is true, you’ll reject it 1
- alpha of the time.

00:07:13.040 --> 00:07:18.470
When alpha is 0.05 that means that when the null is true, we’ll correctly fail to reject

00:07:18.470 --> 00:07:21.810
0.95 or 95% of the time.

00:07:21.810 --> 00:07:27.800
If the null is false and the alternative is
true, we’ll correctly reject the null 1-Beta

00:07:27.800 --> 00:07:28.880
of the time.

00:07:28.880 --> 00:07:34.220
If Beta--the proportion of times we will fail
to reject the null even though it’s false--is

00:07:34.220 --> 00:07:39.210
10%, then we’ll correctly reject the null
90% of the time.

00:07:39.210 --> 00:07:43.260
This proportion (1-Beta) is called our statistical power.

00:07:43.260 --> 00:07:47.550
As the name suggests, statistical power is
really important and something that we want.

00:07:47.550 --> 00:07:49.680
I mean, it’s a power.

00:07:49.680 --> 00:07:51.140
I want powers!

00:07:51.140 --> 00:07:54.870
Statistical power tells us our chance of detecting an effect if there is one.

00:07:54.870 --> 00:07:59.290
Imagine we design a study to look at whether fish oil makes cat’s hair shinier and it

00:07:59.290 --> 00:08:01.860
has 80% statistical power.

00:08:01.860 --> 00:08:06.670
That means we know that if there really is
an effect of a certain type of fish oil and

00:08:06.670 --> 00:08:11.710
if we ran the same experiment multiple times with different samples of cats, the data from

00:08:11.710 --> 00:08:17.300
80% of the experiments will lead us to make the correct decision and reject the null hypothesis

00:08:17.300 --> 00:08:19.640
that fish oil has no effect.

00:08:19.640 --> 00:08:23.500
This is important because the whole reason that we do experiments is to see whether there’s

00:08:23.500 --> 00:08:24.500
an effect.

00:08:24.500 --> 00:08:28.980
We don’t just test whether fish oil makes
cat’s hair shiner just for fun, we want

00:08:28.980 --> 00:08:30.300
shinier cats!

00:08:30.300 --> 00:08:34.200
Statistical power tells us about our ability
to detect these effects if they exist.

00:08:34.210 --> 00:08:38.140
It would be a waste of time and money to run an experiment on whether people who play video

00:08:38.140 --> 00:08:43.310
games have quicker reaction times than those who don’t if we only have an estimated 20%

00:08:43.310 --> 00:08:47.960
power, because that means that even if there gameplay effects reaction time, we often wouldn’t

00:08:47.960 --> 00:08:49.040
be able to tell.

00:08:49.040 --> 00:08:51.780
Experiments cost money, so if you’re going
to go through the process of growing cells

00:08:51.780 --> 00:08:56.440
in a petri dish, or of giving cats fish oil
you want to be relatively confident you’ll

00:08:56.440 --> 00:08:58.800
be able to detect an effect if there is one.

00:08:58.800 --> 00:09:03.350
Visually we see that statistical power is
affected by how much the null and alternative

00:09:03.350 --> 00:09:05.990
hypothesis distributions overlap.

00:09:05.990 --> 00:09:10.681
The more they overlap, the less statistical
power we’ll have, because less of the alternative

00:09:10.681 --> 00:09:13.650
distribution will be to the right of the cutoff.

00:09:13.650 --> 00:09:17.100
There are two main ways to get the two distributions to overlap less.

00:09:17.100 --> 00:09:19.820
Either you can move them further apart, or
you can make them skinnier.

00:09:19.820 --> 00:09:25.190
The distance between the mean of the two distributions represents something called “effect size”.

00:09:25.190 --> 00:09:29.110
If we’re looking at the difference between
two groups--like level of neuroticism between

00:09:29.110 --> 00:09:35.600
cat people and dog people--effect size tells
us how big the difference in neuroticism is

00:09:35.600 --> 00:09:37.590
between the two groups.

00:09:37.590 --> 00:09:42.040
If effect size is large, the groups are further
away from each other, if it’s small, they’re

00:09:42.040 --> 00:09:43.330
pretty close.

00:09:43.330 --> 00:09:46.990
If two things are really different from each
other, it’s easier to tell them apart.

00:09:46.990 --> 00:09:50.820
Say we’re researching whether the amount
of time people spend in the sun leads to more freckles.

00:09:50.820 --> 00:09:54.920
If one group that spent 10 minutes in the
sun led to an average of 5 new freckles over

00:09:54.920 --> 00:09:59.270
the body, it’d be a lot harder to tell than
if 10 minutes in the sun led to an average

00:09:59.270 --> 00:10:01.140
of 500 new freckles.

00:10:01.140 --> 00:10:04.740
Unfortunately, effect size is largely out
of our control.

00:10:04.740 --> 00:10:08.740
Researchers can't magically change the efficacy of a drug, or the difference in heart rate

00:10:08.750 --> 00:10:12.150
between people who do kickboxing and people who do Crossfit.

00:10:12.150 --> 00:10:15.490
We can also make our distributions overlap
less by making them skinnier.

00:10:15.490 --> 00:10:19.850
And remember, the null and alternative distributions are just sampling distributions.

00:10:19.850 --> 00:10:24.300
We’ve seen that as you increase the size
of your samples, the distribution of sample

00:10:24.300 --> 00:10:26.140
means gets thinner.

00:10:26.140 --> 00:10:31.880
And all other things being the same, they
overlap less and we have more power to detect an effect.

00:10:31.940 --> 00:10:36.340
This shrinking represents the fact that in
general, the more data we have, the more information

00:10:36.340 --> 00:10:37.340
we have.

00:10:37.350 --> 00:10:39.160
Thankfully we can change sample size.

00:10:39.160 --> 00:10:43.270
It might be a pain to sample more people,
feed more cats more fish oil, or measure more

00:10:43.270 --> 00:10:47.690
ocean temperatures, but at least it’s within
our control, unlike effect size.

00:10:47.690 --> 00:10:49.760
And that’s just what researchers do.

00:10:49.760 --> 00:10:53.000
We already mentioned that if we’re going
to take the time to run an experiment or do

00:10:53.000 --> 00:10:58.590
a study... we want to make sure it has sufficient power to detect any effects out there, and

00:10:58.590 --> 00:11:03.430
since almost everything else is out of our
control, scientists will increase their sample

00:11:03.430 --> 00:11:07.590
size to get sufficient statistical power to
detect these effects.

00:11:07.590 --> 00:11:13.370
Across many fields it’s considered sufficient to have 80% statistical power or more, and

00:11:13.370 --> 00:11:18.010
often when researchers are designing studies, they’ll decide how many subjects they need

00:11:18.010 --> 00:11:21.000
based on estimates of effect size and power.

00:11:21.000 --> 00:11:25.650
So now you’re playing with power…and in
the next few episodes we’ll talk a lot more

00:11:25.650 --> 00:11:31.220
about exactly when and how you can use p-values, and also some completely different methods

00:11:31.220 --> 00:11:32.800
for testing ideas.

00:11:32.800 --> 00:11:35.960
Thanks for watching, I’ll see 
you next time.

