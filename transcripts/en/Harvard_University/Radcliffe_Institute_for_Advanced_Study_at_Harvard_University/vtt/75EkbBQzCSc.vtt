WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.784
[MUSIC PLAYING]

00:00:03.784 --> 00:00:05.200
- Well, first I
just want to start

00:00:05.200 --> 00:00:07.990
the second half of our program
by thanking the audience.

00:00:07.990 --> 00:00:10.670
So you've been wonderful so
far, asking great questions.

00:00:10.670 --> 00:00:12.280
And it's always a
sign of a good event

00:00:12.280 --> 00:00:14.920
when you can't get people
back in to sit down,

00:00:14.920 --> 00:00:17.040
because you're too busy
talking to each other.

00:00:17.040 --> 00:00:20.911
But so now we do get to hear a
couple more of presentations,

00:00:20.911 --> 00:00:22.660
and then we'll have
this panel discussion,

00:00:22.660 --> 00:00:25.515
and then we'll have even more
amazing snacks at the end

00:00:25.515 --> 00:00:26.515
where you can continue--

00:00:26.515 --> 00:00:27.160
[LAUGHTER]

00:00:27.160 --> 00:00:30.070
--the conversations
that you began.

00:00:30.070 --> 00:00:32.321
And I should just tell
you that, again, please

00:00:32.321 --> 00:00:33.820
think of the questions
that you want

00:00:33.820 --> 00:00:36.232
to ask each individual
speaker, but then keep in mind

00:00:36.232 --> 00:00:37.690
the ones that you
didn't get to ask

00:00:37.690 --> 00:00:39.340
or that apply to
more than one speaker

00:00:39.340 --> 00:00:42.490
for joint discussion at the end.

00:00:42.490 --> 00:00:44.910
And so again, before
I continue, I'll

00:00:44.910 --> 00:00:48.760
just explain that these two
talks by Ben Shneiderman who's

00:00:48.760 --> 00:00:51.310
our special guest from
the University of Maryland

00:00:51.310 --> 00:00:52.490
next week--

00:00:52.490 --> 00:00:55.690
the first one will be a very
large venue in Science Center

00:00:55.690 --> 00:01:00.460
D, but you're still requested
to register if you want to come.

00:01:00.460 --> 00:01:02.692
And that one is about
algorithmic accountability.

00:01:02.692 --> 00:01:04.900
So the reason I mention this
now is because you heard

00:01:04.900 --> 00:01:07.900
the question to Nathan at
the end, which I'm sure

00:01:07.900 --> 00:01:10.930
will come up again in the
discussion, essentially about

00:01:10.930 --> 00:01:13.000
what do we do about
the fact that we have

00:01:13.000 --> 00:01:16.810
these algorithms that either we
don't know what they're doing

00:01:16.810 --> 00:01:19.840
or they're being applied
for sometimes less

00:01:19.840 --> 00:01:22.120
than completely
honorable reasons--

00:01:22.120 --> 00:01:25.390
not by Nathan or
legendary entertainment.

00:01:25.390 --> 00:01:28.450
But we can talk about
Mr. Zuckerberg later.

00:01:28.450 --> 00:01:31.690
Anyway, speaking of Harvard
alums or almost Harvard alums,

00:01:31.690 --> 00:01:35.110
I lied to you when I said
that the next speaker wouldn't

00:01:35.110 --> 00:01:36.520
be a Harvard alum.

00:01:36.520 --> 00:01:39.730
She does not have a Harvard PhD,
like the previous two speakers,

00:01:39.730 --> 00:01:42.940
but she does have, I believe,
an undergraduate degree

00:01:42.940 --> 00:01:44.736
from Harvard University.

00:01:44.736 --> 00:01:46.360
Renee, do you have
any Harvard degrees?

00:01:46.360 --> 00:01:46.860
- I have not been to Harvard.

00:01:46.860 --> 00:01:47.360
- OK.

00:01:47.360 --> 00:01:49.619
Unless we suddenly confer
an honorary degree on Renee,

00:01:49.619 --> 00:01:50.410
we're going to be--

00:01:50.410 --> 00:01:50.710
- I'm fine.

00:01:50.710 --> 00:01:51.590
- --we're going to be good.

00:01:51.590 --> 00:01:52.660
You want an honorary degree?

00:01:52.660 --> 00:01:53.260
- [INAUDIBLE].

00:01:53.260 --> 00:01:55.780
- OK, wait about 30 years
and then we'll give you one.

00:01:55.780 --> 00:01:56.620
OK?

00:01:56.620 --> 00:02:01.270
So anyway, but her master's
degree is not from Harvard,

00:02:01.270 --> 00:02:02.590
it's from Johns Hopkins.

00:02:02.590 --> 00:02:06.730
This is Saki Takahashi who I'm
talking about, in epidemiology,

00:02:06.730 --> 00:02:09.820
and her undergraduate
degree was in applied math.

00:02:09.820 --> 00:02:12.130
And currently, she's
a graduate student

00:02:12.130 --> 00:02:16.480
at Princeton University, which
I hear is a pretty good school.

00:02:16.480 --> 00:02:17.160
It's OK.

00:02:17.160 --> 00:02:18.430
[LAUGHS]

00:02:18.430 --> 00:02:20.890
And we learned about her
work from our colleagues

00:02:20.890 --> 00:02:26.350
in epidemiology here, and also
from the leader of her lab--

00:02:26.350 --> 00:02:27.640
whose name is Jess Metcalf--

00:02:27.640 --> 00:02:29.950
who some of you might
remember as a speaker

00:02:29.950 --> 00:02:33.130
in the wonderful Contagion event
that my Codirector of Science

00:02:33.130 --> 00:02:36.370
here, Janet Rich-Edwards,
organized back in the fall.

00:02:36.370 --> 00:02:38.650
And what Jess was talking
about was essentially

00:02:38.650 --> 00:02:42.340
the use of data on difficult
problems in epidemiology,

00:02:42.340 --> 00:02:46.420
but in this era of the
availability of lots

00:02:46.420 --> 00:02:48.520
of large online datasets.

00:02:48.520 --> 00:02:50.860
And one aspect of that
that particularly interests

00:02:50.860 --> 00:02:54.880
me-- that I'm really eager to
hear about today from Saki--

00:02:54.880 --> 00:02:57.910
is looking at
spatial distributions

00:02:57.910 --> 00:03:01.790
and temporal
distributions and bringing

00:03:01.790 --> 00:03:04.990
the tools of other
fields of science

00:03:04.990 --> 00:03:08.050
and other fields of
statistics to epidemiology

00:03:08.050 --> 00:03:10.810
in ways that either they
weren't there before

00:03:10.810 --> 00:03:12.860
or were not possible before.

00:03:12.860 --> 00:03:14.720
And I'm being purposely vague.

00:03:14.720 --> 00:03:17.620
She's going to show you now--

00:03:17.620 --> 00:03:21.620
that means as soon as I put
the microphone back together.

00:03:21.620 --> 00:03:24.236
So let's welcome
Saki, and I can't

00:03:24.236 --> 00:03:25.360
wait to hear what she says.

00:03:25.360 --> 00:03:30.260
[APPLAUSE]

00:03:30.260 --> 00:03:31.310
- Great.

00:03:31.310 --> 00:03:32.480
Thank you so much.

00:03:32.480 --> 00:03:35.750
Thanks to the organizers of
this event for inviting me here.

00:03:35.750 --> 00:03:38.600
So today, I'm going to tell
you about some of the work

00:03:38.600 --> 00:03:40.850
that we've been doing on
combining different data

00:03:40.850 --> 00:03:44.810
sources to generate fine
scale maps of susceptibility

00:03:44.810 --> 00:03:47.480
to vaccine preventable
infectious diseases.

00:03:47.480 --> 00:03:49.520
And this work is
really exciting to me

00:03:49.520 --> 00:03:52.040
because it was driven by real
time public health policy

00:03:52.040 --> 00:03:53.180
questions.

00:03:53.180 --> 00:03:55.970
And it's especially exciting
to be here because I actually

00:03:55.970 --> 00:03:58.580
first got involved in
epidemiology and public health

00:03:58.580 --> 00:04:01.522
as an undergrad, I had a mentor
in the biostats department

00:04:01.522 --> 00:04:03.980
at the School of Public Health,
who introduced me to people

00:04:03.980 --> 00:04:05.870
in the epidemiology department.

00:04:05.870 --> 00:04:07.740
And needless to
say, I got hooked.

00:04:07.740 --> 00:04:10.280
And I've been doing infectious
disease epidemiology

00:04:10.280 --> 00:04:12.200
since then.

00:04:12.200 --> 00:04:14.990
So I know that you guys
have hosted previous events

00:04:14.990 --> 00:04:18.680
on epidemiology, so perhaps
you've come across this map

00:04:18.680 --> 00:04:19.700
before.

00:04:19.700 --> 00:04:21.290
For those of you
who haven't, this

00:04:21.290 --> 00:04:23.750
is a map of cholera
cases in London

00:04:23.750 --> 00:04:26.870
that was made by
John Snow in 1854.

00:04:26.870 --> 00:04:30.240
And he traced the source of
the large cholera outbreak--

00:04:30.240 --> 00:04:34.400
and cases are shown as
these black rectangles--

00:04:34.400 --> 00:04:37.850
to the famous Broad
Street Pump shown in red.

00:04:37.850 --> 00:04:40.430
Jon Snow is known as
one of the founders

00:04:40.430 --> 00:04:42.500
of the field of epidemiology.

00:04:42.500 --> 00:04:44.360
But I'm going to
argue that he was also

00:04:44.360 --> 00:04:46.250
a founder of spatial
epidemiology.

00:04:46.250 --> 00:04:49.570
And my talk will be on
spatial epidemiology.

00:04:49.570 --> 00:04:52.390
So one infectious
disease that I,

00:04:52.390 --> 00:04:54.910
and a lot of people in my
field, think about often

00:04:54.910 --> 00:04:57.590
is measles, which
as you may know,

00:04:57.590 --> 00:05:00.640
is one of the most transmissible
and potentially deadly

00:05:00.640 --> 00:05:02.380
infectious diseases.

00:05:02.380 --> 00:05:06.550
It has a R0, or basic
reproductive number,

00:05:06.550 --> 00:05:08.020
of 10 to 20.

00:05:08.020 --> 00:05:12.160
And R0 is the expected number
of secondary cases caused

00:05:12.160 --> 00:05:14.740
by one infectious
individual in a completely

00:05:14.740 --> 00:05:16.210
susceptible population.

00:05:16.210 --> 00:05:18.790
And so basically, R0
is a metric of how

00:05:18.790 --> 00:05:21.100
transmissible an infection is.

00:05:21.100 --> 00:05:23.120
And so let's compare
that to the out of,

00:05:23.120 --> 00:05:26.400
let's say seasonal influenza,
which is around two.

00:05:26.400 --> 00:05:30.010
But R0 for measles of
10 to 20 is quite high.

00:05:30.010 --> 00:05:32.710
And measles is a leading
cause of death in children

00:05:32.710 --> 00:05:34.240
under five years of age.

00:05:34.240 --> 00:05:38.820
And measles still kills almost
90,000 people each year.

00:05:38.820 --> 00:05:41.430
And so here's a toy
schematic to give you

00:05:41.430 --> 00:05:45.180
an idea of how transmissible
an infection with an R0 of 10

00:05:45.180 --> 00:05:46.290
really is.

00:05:46.290 --> 00:05:49.950
So individuals who are
susceptible to a disease here

00:05:49.950 --> 00:05:51.240
are shown in green.

00:05:51.240 --> 00:05:53.970
And infected and
infectious individuals,

00:05:53.970 --> 00:05:57.790
or the infected and infectious
individual is shown in orange.

00:05:57.790 --> 00:05:59.880
And now let's say we have
a completely susceptible

00:05:59.880 --> 00:06:01.860
population, so everyone's green.

00:06:01.860 --> 00:06:03.870
And then we introduce
a single person

00:06:03.870 --> 00:06:09.180
who has infection with a
disease with an R0 of 10.

00:06:09.180 --> 00:06:11.820
On average, that
one infected person

00:06:11.820 --> 00:06:15.840
will cause 10 new infections.

00:06:15.840 --> 00:06:19.670
So in addition to R0, a key
concept in infectious disease

00:06:19.670 --> 00:06:21.920
epidemiology is herd immunity.

00:06:21.920 --> 00:06:25.070
And herd immunity is
the indirect protection

00:06:25.070 --> 00:06:26.870
against an infectious
disease that

00:06:26.870 --> 00:06:29.180
occurs when a sufficient
proportion of the population

00:06:29.180 --> 00:06:31.850
is immune, or in other
words vaccinated.

00:06:31.850 --> 00:06:36.050
And Herd immunity is related to
R0 in quite a simple way, which

00:06:36.050 --> 00:06:38.210
is that from
epidemiological theory,

00:06:38.210 --> 00:06:40.340
we know that the proportion
of the population that

00:06:40.340 --> 00:06:42.920
must be vaccinated in
order to actually achieve

00:06:42.920 --> 00:06:45.500
herd immunity--

00:06:45.500 --> 00:06:47.360
or what we call p of c--

00:06:47.360 --> 00:06:50.460
is calculated as
1 minus 1 over R0.

00:06:50.460 --> 00:06:53.930
And so this means from
a pragmatic standpoint,

00:06:53.930 --> 00:06:56.030
the higher the R0
is, the greater

00:06:56.030 --> 00:06:59.030
the proportion of the population
that needs to be vaccinated.

00:06:59.030 --> 00:07:03.810
And so for measles, which I said
earlier has an R0 of 10 to 20,

00:07:03.810 --> 00:07:07.190
this means that roughly 90
to 95% of the population

00:07:07.190 --> 00:07:09.890
actually needs to be vaccinated
in order to eliminate

00:07:09.890 --> 00:07:12.190
the disease.

00:07:12.190 --> 00:07:13.920
So now here's that
same schematic

00:07:13.920 --> 00:07:18.120
again showing a measles-like
infection with an R0 of 10,

00:07:18.120 --> 00:07:21.480
except this time we vaccinate
91% of the population.

00:07:21.480 --> 00:07:24.390
So there are 11 people in our
population, and 10 out of 11

00:07:24.390 --> 00:07:25.770
are vaccinated--

00:07:25.770 --> 00:07:28.050
vaccinated individuals
are shown in blue.

00:07:28.050 --> 00:07:31.450
And let's assume that vaccine
is perfectly immunizing.

00:07:31.450 --> 00:07:34.080
And again, we introduce
a single infected person

00:07:34.080 --> 00:07:36.620
into that population.

00:07:36.620 --> 00:07:40.519
This time the infected person
won't cause any new infections,

00:07:40.519 --> 00:07:42.560
because a sufficient
proportion of the population

00:07:42.560 --> 00:07:45.460
is vaccinated, and so
they won't get infected.

00:07:45.460 --> 00:07:47.620
In addition, the one
person shown in green

00:07:47.620 --> 00:07:51.647
here who wasn't
vaccinated, will also not

00:07:51.647 --> 00:07:53.230
get infected because
they're protected

00:07:53.230 --> 00:07:58.180
by this concept of herd immunity
that I introduced earlier.

00:07:58.180 --> 00:08:01.450
So measles vaccination is one
of the most cost-effective

00:08:01.450 --> 00:08:03.110
public health interventions.

00:08:03.110 --> 00:08:05.260
And this is because
measles, the disease,

00:08:05.260 --> 00:08:09.280
has both a potentially high
case fatality ratio of up to 20%

00:08:09.280 --> 00:08:12.670
in some situations, as well
as a safe, effective, and

00:08:12.670 --> 00:08:14.320
inexpensive vaccine.

00:08:14.320 --> 00:08:16.840
And so this figure here
is showing the number

00:08:16.840 --> 00:08:20.140
of reported global measles
cases, in blue bars,

00:08:20.140 --> 00:08:22.770
from 1980 to 2016.

00:08:22.770 --> 00:08:25.550
And the corresponding
yearly vaccination coverage

00:08:25.550 --> 00:08:28.820
during this time period
in blue and red dots.

00:08:28.820 --> 00:08:31.450
And you can see that the gains
in vaccination coverage that

00:08:31.450 --> 00:08:33.669
have been made
over recent decades

00:08:33.669 --> 00:08:38.240
have led to a large reduction
in measles cases globally.

00:08:38.240 --> 00:08:43.179
And so as a result of this
all WHO regions and countries

00:08:43.179 --> 00:08:45.850
currently target elimination
of measles, the disease,

00:08:45.850 --> 00:08:48.710
by the year 2020.

00:08:48.710 --> 00:08:52.720
However, continued measles virus
circulation in many countries

00:08:52.720 --> 00:08:55.360
makes this goal seem
particularly elusive.

00:08:55.360 --> 00:08:57.460
And as I said earlier,
measles is still

00:08:57.460 --> 00:09:00.170
one of the leading killers
of children globally.

00:09:00.170 --> 00:09:02.110
And so to get a more
clear picture of what

00:09:02.110 --> 00:09:05.290
vaccination coverage estimates
in that previous slide that I

00:09:05.290 --> 00:09:07.150
showed actually
represent, this is

00:09:07.150 --> 00:09:10.870
a map showing reported measles
vaccination coverage in 2016

00:09:10.870 --> 00:09:12.170
by country.

00:09:12.170 --> 00:09:14.290
And you can see that
across countries, there's

00:09:14.290 --> 00:09:17.340
quite a bit of spatial
heterogeneity in coverage.

00:09:17.340 --> 00:09:19.570
In countries where coverage
is particularly low,

00:09:19.570 --> 00:09:21.910
which is-- so below
the 80% threshold

00:09:21.910 --> 00:09:25.221
is shown in light and dark red.

00:09:25.221 --> 00:09:25.720
So yeah.

00:09:25.720 --> 00:09:27.760
So there's quite a bit
of spatial heterogeneity.

00:09:27.760 --> 00:09:29.860
And countries in
Sub-Saharan Africa

00:09:29.860 --> 00:09:32.380
have some of the lowest
vaccination coverage levels.

00:09:32.380 --> 00:09:34.120
And this is also
where the majority

00:09:34.120 --> 00:09:37.560
of the world's remaining
measles cases are found.

00:09:37.560 --> 00:09:40.180
So what I'd like to try
to convince you in my talk

00:09:40.180 --> 00:09:43.500
is that it's important to think
at an even more local level.

00:09:43.500 --> 00:09:45.150
And since a country
level estimate--

00:09:45.150 --> 00:09:49.360
so any of these single
polygons-- is still an average,

00:09:49.360 --> 00:09:52.430
a country can have
high overall coverage,

00:09:52.430 --> 00:09:54.390
but also have pockets
of low coverage,

00:09:54.390 --> 00:09:57.030
and that could sustain
a measles outbreak.

00:09:57.030 --> 00:09:59.260
So I'm going to tell you
a little bit about how

00:09:59.260 --> 00:10:01.930
measles vaccination
is actually delivered

00:10:01.930 --> 00:10:05.770
with a focus on Sub-Saharan
African countries.

00:10:05.770 --> 00:10:09.060
So there's two ways in which
measles vaccine is delivered.

00:10:09.060 --> 00:10:12.670
First, by routine immunization
at health centers.

00:10:12.670 --> 00:10:14.640
And this targets young
children at nine months

00:10:14.640 --> 00:10:17.220
of age for their first
dose of measles containing

00:10:17.220 --> 00:10:20.016
vaccine, which we call MCV-1.

00:10:20.016 --> 00:10:23.332
Secondly, countries
conduct catch-up campaigns,

00:10:23.332 --> 00:10:25.290
and they're known as
Supplementary Immunization

00:10:25.290 --> 00:10:28.080
Activities, or SIAs.

00:10:28.080 --> 00:10:30.300
And the purpose
of an SIA campaign

00:10:30.300 --> 00:10:33.120
is to boost population
level immunity.

00:10:33.120 --> 00:10:36.360
And they do that by targeting
a wider age range of children,

00:10:36.360 --> 00:10:38.280
compared to routine
immunization.

00:10:38.280 --> 00:10:42.390
So SIAs will sometimes target
kids up to five years age,

00:10:42.390 --> 00:10:45.360
but even possibly older--
even up to 15 years of age

00:10:45.360 --> 00:10:46.740
in some scenarios.

00:10:46.740 --> 00:10:49.170
And so what SIAs, or
these catch-up campaigns,

00:10:49.170 --> 00:10:52.020
do is they both provide
a first dose of vaccine

00:10:52.020 --> 00:10:54.540
to kids who were missed
by routine immunization,

00:10:54.540 --> 00:10:56.010
but they also
provide a second dose

00:10:56.010 --> 00:10:58.500
to those who are already
vaccinated by routine programs.

00:10:58.500 --> 00:11:01.020
And in many countries,
we have kids getting

00:11:01.020 --> 00:11:03.340
two doses of measles vaccine.

00:11:03.340 --> 00:11:05.970
And these campaigns
can be conducted

00:11:05.970 --> 00:11:07.830
across an entire
country, or they

00:11:07.830 --> 00:11:10.230
can target a specific
geographic area,

00:11:10.230 --> 00:11:13.441
and they're conducted
every two to five years.

00:11:13.441 --> 00:11:17.580
So this equation for p of c
that I mentioned earlier--

00:11:17.580 --> 00:11:20.750
which represents the proportion
of the population that

00:11:20.750 --> 00:11:22.940
needs to be vaccinated--

00:11:22.940 --> 00:11:26.360
this equation assumes that
susceptible individuals

00:11:26.360 --> 00:11:29.070
are evenly distributed
throughout the population.

00:11:29.070 --> 00:11:32.120
And so this doesn't account for
any heterogen-- heterogeneity

00:11:32.120 --> 00:11:33.440
across space.

00:11:33.440 --> 00:11:36.770
And in reality, the spatial
clustering of unvaccinated

00:11:36.770 --> 00:11:39.260
people-- and unvaccinated
people being susceptible people,

00:11:39.260 --> 00:11:40.010
right--

00:11:40.010 --> 00:11:43.245
makes it even more difficult to
actually achieve herd immunity.

00:11:43.245 --> 00:11:44.870
And let's compare
that to the situation

00:11:44.870 --> 00:11:47.960
where the same number
of people are randomly

00:11:47.960 --> 00:11:49.940
distributed across space.

00:11:49.940 --> 00:11:53.480
And so along those same lines,
estimating vaccination coverage

00:11:53.480 --> 00:11:56.520
by taking the average
across large spatial areas

00:11:56.520 --> 00:11:59.090
can miss zones of
vulnerability that are small,

00:11:59.090 --> 00:12:01.580
or those that don't follow
administrative or political

00:12:01.580 --> 00:12:02.840
boundaries.

00:12:02.840 --> 00:12:06.740
And this has been increasingly
recognized among public health

00:12:06.740 --> 00:12:10.550
policymakers, and is
reflected by a shift

00:12:10.550 --> 00:12:13.190
from simply setting
country level targets

00:12:13.190 --> 00:12:15.830
to focus on ensuring
uniformly high vaccination

00:12:15.830 --> 00:12:17.580
levels across a country.

00:12:17.580 --> 00:12:20.270
And so in 2010, the
World Health Assembly

00:12:20.270 --> 00:12:23.630
set a goal to achieve 90%
measles of vaccination

00:12:23.630 --> 00:12:26.810
by country, as well as
at least 80% coverage

00:12:26.810 --> 00:12:30.260
in every district
within a country.

00:12:30.260 --> 00:12:33.410
And so in response to this
shifting focus towards more

00:12:33.410 --> 00:12:36.080
detailed geographic
information and equity,

00:12:36.080 --> 00:12:38.420
we've been setting up an
analytical pipeline that

00:12:38.420 --> 00:12:41.480
combines data with models
that incorporate the two

00:12:41.480 --> 00:12:44.330
mechanisms of vaccine
delivery, towards the goal

00:12:44.330 --> 00:12:46.490
of understanding measles
vaccination coverage

00:12:46.490 --> 00:12:49.660
at the sub-national level.

00:12:49.660 --> 00:12:53.020
So the primary data that we
use are demographic and health

00:12:53.020 --> 00:12:55.450
surveys, or DHS.

00:12:55.450 --> 00:12:58.870
These are large
cross-sectional, geolocated and

00:12:58.870 --> 00:13:01.720
nationally-representative
household surveys.

00:13:01.720 --> 00:13:03.460
They are a rich and
publicly available

00:13:03.460 --> 00:13:06.010
source of information on
demographic and health

00:13:06.010 --> 00:13:08.080
indicators, including
vaccination,

00:13:08.080 --> 00:13:10.930
and they're conducted
across over 90 countries.

00:13:10.930 --> 00:13:14.140
And they're usually done every
few years in each country,

00:13:14.140 --> 00:13:15.910
and they ask
hundreds of questions

00:13:15.910 --> 00:13:18.040
using a standardized framework.

00:13:18.040 --> 00:13:19.900
And so every survey
has information

00:13:19.900 --> 00:13:22.810
on thousands of participants.

00:13:22.810 --> 00:13:25.270
In particular, a DHS
survey has information

00:13:25.270 --> 00:13:28.510
on each interviewed woman's
child who are five years of age

00:13:28.510 --> 00:13:30.640
or younger at the
time of the survey.

00:13:30.640 --> 00:13:32.741
And it includes relevant
dates, their date

00:13:32.741 --> 00:13:35.170
of birth, their date of
survey, and from that we

00:13:35.170 --> 00:13:37.216
can calculate children's age.

00:13:37.216 --> 00:13:38.590
And then there's
also information

00:13:38.590 --> 00:13:40.600
on their measles
vaccination status, which

00:13:40.600 --> 00:13:42.730
we're really interested in.

00:13:42.730 --> 00:13:44.980
For some children,
we have information

00:13:44.980 --> 00:13:47.980
on their date of vaccination
from their vaccine cards,

00:13:47.980 --> 00:13:50.590
but for others we only know
that they were vaccinated

00:13:50.590 --> 00:13:52.810
based on their mother's recall.

00:13:52.810 --> 00:13:56.200
Lastly, we have data
on their GPS locations

00:13:56.200 --> 00:13:58.570
at the level of
household cluster.

00:13:58.570 --> 00:14:00.610
And what cluster
here means is it's

00:14:00.610 --> 00:14:02.320
an aggregate of households.

00:14:02.320 --> 00:14:06.580
And there are 300 or more of
these clusters per survey.

00:14:06.580 --> 00:14:10.870
So on the right here is the
data from the DHS survey

00:14:10.870 --> 00:14:14.185
that was conducted in
Madagascar in 2008-2009.

00:14:14.185 --> 00:14:16.060
And that's the most
recently available survey

00:14:16.060 --> 00:14:17.290
from that country.

00:14:17.290 --> 00:14:19.120
And there were over
10,000 children

00:14:19.120 --> 00:14:20.580
included in this survey.

00:14:20.580 --> 00:14:24.820
And each point on this map
corresponds to a GPS cluster.

00:14:24.820 --> 00:14:27.400
And the color of the point
reflects the proportion

00:14:27.400 --> 00:14:30.460
of children who are
vaccinated against measles.

00:14:30.460 --> 00:14:33.340
And then the size of the point
corresponds to the total number

00:14:33.340 --> 00:14:35.890
of children in that cluster.

00:14:35.890 --> 00:14:39.880
And so the information that goes
into the DHS vaccination data

00:14:39.880 --> 00:14:42.740
comes from individual vaccine
cards, such as this one.

00:14:42.740 --> 00:14:44.984
And you can see
here for this child

00:14:44.984 --> 00:14:46.900
you can see their date
of birth and their date

00:14:46.900 --> 00:14:48.610
of measles vaccination.

00:14:48.610 --> 00:14:51.040
And if you do the math, they
got their measles vaccination

00:14:51.040 --> 00:14:52.498
at around nine
months of age, which

00:14:52.498 --> 00:14:55.690
is the recommended age,
at least in this context.

00:14:55.690 --> 00:14:58.090
And this is what the
country level vaccination

00:14:58.090 --> 00:15:01.450
data in that Madagascar DHS
survey actually looks like.

00:15:01.450 --> 00:15:04.390
And so this histogram is
showing children's age receiving

00:15:04.390 --> 00:15:06.934
measles vaccination, if we
know it-- and that's in months.

00:15:06.934 --> 00:15:08.350
And this is
information that comes

00:15:08.350 --> 00:15:10.900
from vaccine cards like the
one that I just showed you.

00:15:10.900 --> 00:15:12.940
And you can see that for
a majority of children

00:15:12.940 --> 00:15:15.520
for whom we know when
they were vaccinated,

00:15:15.520 --> 00:15:17.210
they got it at
around nine months.

00:15:17.210 --> 00:15:21.500
But there is some [INAUDIBLE]
distribution around that.

00:15:21.500 --> 00:15:23.230
And this histogram
is a different way

00:15:23.230 --> 00:15:26.810
to look at the data, which is
children's measles vaccination

00:15:26.810 --> 00:15:29.470
dates that we got from
the DHS survey, also

00:15:29.470 --> 00:15:31.360
from the Madagascar survey.

00:15:31.360 --> 00:15:35.470
And this is binned into month
and year of vaccination.

00:15:35.470 --> 00:15:38.140
And the months with a
turquoise or pink bar

00:15:38.140 --> 00:15:40.440
contained a measles
vaccination campaign.

00:15:40.440 --> 00:15:43.030
And in Madagascar, they
actually do two campaigns a year

00:15:43.030 --> 00:15:45.610
to try to catch up kids.

00:15:45.610 --> 00:15:50.320
And so you can see that months
associated with the campaign

00:15:50.320 --> 00:15:54.100
have higher vaccination
dates on cards.

00:15:54.100 --> 00:15:56.380
So this is kind of the
signature that these campaigns

00:15:56.380 --> 00:15:57.980
are doing something.

00:15:57.980 --> 00:16:01.150
And so for each child in the
DHS survey, what we do is we

00:16:01.150 --> 00:16:03.470
take information on
their vaccination status,

00:16:03.470 --> 00:16:05.400
their age at the survey,
and then their age

00:16:05.400 --> 00:16:07.110
at the vaccination
if we know it.

00:16:07.110 --> 00:16:09.700
And then we fit it all into
a likelihood-based model,

00:16:09.700 --> 00:16:11.500
and then we estimate
parameters that

00:16:11.500 --> 00:16:14.980
describe the probability of
any child being vaccinated

00:16:14.980 --> 00:16:16.590
given their location.

00:16:16.590 --> 00:16:19.450
And so we've been developing
the statistical methods

00:16:19.450 --> 00:16:22.540
that we think are widely
applicable to countries

00:16:22.540 --> 00:16:25.540
that has DHS surveys.

00:16:25.540 --> 00:16:27.760
And so as we were
working on these methods,

00:16:27.760 --> 00:16:31.320
the West African Ebola
epidemic was under way.

00:16:31.320 --> 00:16:33.610
And so in addition to the
considerable morbidity

00:16:33.610 --> 00:16:36.310
and mortality is a
direct effect of Ebola,

00:16:36.310 --> 00:16:38.710
the epidemic also
disrupted the normal means

00:16:38.710 --> 00:16:41.500
by which routine health care was
delivered in these countries.

00:16:41.500 --> 00:16:44.080
And this is because Ebola shut
down the health infrastructure

00:16:44.080 --> 00:16:45.850
in the affected countries.

00:16:45.850 --> 00:16:49.090
And so disruptions in
routine health care

00:16:49.090 --> 00:16:52.630
lead to a reduction
in vaccination rates.

00:16:52.630 --> 00:16:56.330
And that leads to a reduction
in increasing population level

00:16:56.330 --> 00:16:58.930
susceptibility to
measles, especially

00:16:58.930 --> 00:17:02.210
in the young age cohort.

00:17:02.210 --> 00:17:05.440
And that can lead down to a
breakdown of herd immunity.

00:17:05.440 --> 00:17:07.660
And so Guinea, Sierra
Leone, and Liberia

00:17:07.660 --> 00:17:10.180
had all been concerned about
growing measles susceptibility

00:17:10.180 --> 00:17:11.980
in their countries,
and had planned

00:17:11.980 --> 00:17:14.720
to conduct these catch-up
campaigns in the future.

00:17:14.720 --> 00:17:17.140
And so our program manager
at the Gates Foundation

00:17:17.140 --> 00:17:20.170
told us that given the shut
downs of health services

00:17:20.170 --> 00:17:23.307
due to Ebola, measles
outbreaks are inevitable,

00:17:23.307 --> 00:17:25.390
and it would be good to
have some sort of risk map

00:17:25.390 --> 00:17:28.877
to show and to guide
a preemptive response.

00:17:28.877 --> 00:17:30.460
And so for us, this
was an opportunity

00:17:30.460 --> 00:17:31.959
to apply the methods
that we've been

00:17:31.959 --> 00:17:35.320
developing to analyze the
geolocated DHS vaccination

00:17:35.320 --> 00:17:36.190
data.

00:17:36.190 --> 00:17:39.380
And what we did was we pulled
the most recently available DHS

00:17:39.380 --> 00:17:42.970
survey from affected countries
and surrounding countries,

00:17:42.970 --> 00:17:46.450
and we pulled information on
their most recent SIA campaigns

00:17:46.450 --> 00:17:47.920
that they've done.

00:17:47.920 --> 00:17:51.100
And our aim here was
to map and quantify

00:17:51.100 --> 00:17:54.250
how Ebola related health
care disruptions increased

00:17:54.250 --> 00:17:55.990
the risk of a measles
outbreak, and that

00:17:55.990 --> 00:17:58.330
could create a potential
second public health

00:17:58.330 --> 00:18:01.050
crisis following Ebola.

00:18:01.050 --> 00:18:04.140
And so we've observed that
measles epidemics frequently

00:18:04.140 --> 00:18:06.270
follow humanitarian disasters.

00:18:06.270 --> 00:18:08.610
For instance, a
survey of households

00:18:08.610 --> 00:18:12.360
that were displaced due to
the Ethiopian famine in 2000,

00:18:12.360 --> 00:18:13.800
found measles to
be a contributing

00:18:13.800 --> 00:18:16.740
cause in 35 deaths.

00:18:16.740 --> 00:18:18.870
Measles epidemics also
followed disruptions

00:18:18.870 --> 00:18:22.200
in the health system due
to natural disasters.

00:18:22.200 --> 00:18:24.540
And the current political
conflict in Syria

00:18:24.540 --> 00:18:26.910
has also led to large
numbers of measles cases

00:18:26.910 --> 00:18:30.474
due to the collapse
of the health system.

00:18:30.474 --> 00:18:32.390
So now I'm going to take
you through the steps

00:18:32.390 --> 00:18:34.550
of our analysis
pipeline, and how

00:18:34.550 --> 00:18:36.860
we applied it to
understand how Ebola

00:18:36.860 --> 00:18:41.020
related health care disruptions
increased the risk of measles.

00:18:41.020 --> 00:18:45.780
So first, we obtained the
geolocated DHS vaccination data

00:18:45.780 --> 00:18:48.720
that I've been describing
from these countries

00:18:48.720 --> 00:18:50.580
at the epicenter
of the outbreak,

00:18:50.580 --> 00:18:53.140
as well as the
adjacent countries.

00:18:53.140 --> 00:18:55.890
And then estimated the
relevant vaccination parameters

00:18:55.890 --> 00:18:58.500
from our model at the
DHS cluster locations,

00:18:58.500 --> 00:19:00.270
and we incorporated
the two mechanisms

00:19:00.270 --> 00:19:02.340
of vaccination, both
routine health care

00:19:02.340 --> 00:19:05.410
services and these campaigns.

00:19:05.410 --> 00:19:07.590
Inevitably, we don't
have to DHS data

00:19:07.590 --> 00:19:09.030
from every single
point in space,

00:19:09.030 --> 00:19:10.410
which is what we would like.

00:19:10.410 --> 00:19:13.260
But what we do is we take our
estimated parameter values

00:19:13.260 --> 00:19:15.660
at the locations for
which we do have data,

00:19:15.660 --> 00:19:18.180
and then we interpolate,
or we assign,

00:19:18.180 --> 00:19:20.782
their values to locations
that are unsampled.

00:19:20.782 --> 00:19:22.740
And we assume that
neighboring locations should

00:19:22.740 --> 00:19:24.370
have similar parameter values.

00:19:24.370 --> 00:19:26.820
And so this, you
might have heard of,

00:19:26.820 --> 00:19:29.560
is essentially the
first law of geography,

00:19:29.560 --> 00:19:31.890
which is that everything is
related to everything else,

00:19:31.890 --> 00:19:35.160
but near things are more
related than far things.

00:19:35.160 --> 00:19:38.880
And so this map is showing
the baseline probability

00:19:38.880 --> 00:19:42.360
of receiving routine
vaccination by two years of age.

00:19:42.360 --> 00:19:45.780
And these are at five kilometer
by five kilometer grid cells.

00:19:45.780 --> 00:19:48.030
And so we see that
there's low vaccination

00:19:48.030 --> 00:19:50.280
coverage in Guinea
and Liberia overall,

00:19:50.280 --> 00:19:52.140
compared to Sierra Leone.

00:19:52.140 --> 00:19:54.630
But there is considerable
within country heterogeneity

00:19:54.630 --> 00:19:57.980
and vaccination
coverage, as well.

00:19:57.980 --> 00:20:01.580
So we use the DHS data to
estimate the baseline--

00:20:01.580 --> 00:20:04.520
or pre-Ebola
vaccination estimates--

00:20:04.520 --> 00:20:06.620
and then we applied
this framework

00:20:06.620 --> 00:20:09.710
to look at the effects of
a reduction in vaccination

00:20:09.710 --> 00:20:12.240
due to Ebola.

00:20:12.240 --> 00:20:15.720
So reports during
the Ebola outbreak

00:20:15.720 --> 00:20:18.660
were indicating that at least
half of health care centers

00:20:18.660 --> 00:20:21.570
were closed, and that
those that remained open

00:20:21.570 --> 00:20:23.284
were receiving fewer patients.

00:20:23.284 --> 00:20:25.200
And so what we did was
we looked at the effect

00:20:25.200 --> 00:20:29.140
of a 75% reduction in
routine vaccination rates,

00:20:29.140 --> 00:20:31.440
and this is based on the
best available information

00:20:31.440 --> 00:20:33.730
we had at the time.

00:20:33.730 --> 00:20:36.840
And so we used those
reduced vaccination rates

00:20:36.840 --> 00:20:39.580
to estimate post-Ebola
vaccination coverage.

00:20:39.580 --> 00:20:43.422
And so what we did was we
took our DHS survey estimates,

00:20:43.422 --> 00:20:44.880
and then we combined
them with data

00:20:44.880 --> 00:20:46.720
from the World Pop Project.

00:20:46.720 --> 00:20:49.080
And they have high
resolution, age structured,

00:20:49.080 --> 00:20:52.170
population size, and
birth rate information.

00:20:52.170 --> 00:20:55.590
And those are based on satellite
data on human settlements.

00:20:55.590 --> 00:20:57.270
And so on these
maps, lighter colors

00:20:57.270 --> 00:20:59.890
indicate higher
population density.

00:20:59.890 --> 00:21:03.000
And so now that we have this
additional demographic data,

00:21:03.000 --> 00:21:05.290
we take our proportions of
vaccinated children, which

00:21:05.290 --> 00:21:09.090
is from there at each
location, and then we

00:21:09.090 --> 00:21:12.330
can generate the expected
number of unvaccinated kids

00:21:12.330 --> 00:21:14.420
at a given age.

00:21:14.420 --> 00:21:17.640
So the last step was to
project the population forward

00:21:17.640 --> 00:21:20.490
in time using the
spatial birthrate data,

00:21:20.490 --> 00:21:23.550
and under different scenarios
in which routine vaccination is

00:21:23.550 --> 00:21:26.286
disrupted for six to 18 months.

00:21:26.286 --> 00:21:27.660
And so what we
did was we mapped,

00:21:27.660 --> 00:21:29.130
and then we counted
up the number

00:21:29.130 --> 00:21:32.130
of children who were
unvaccinated against measles

00:21:32.130 --> 00:21:34.590
under five years of
age in the region,

00:21:34.590 --> 00:21:38.490
under this assumption of a 75%
reduction in vaccination rates.

00:21:38.490 --> 00:21:41.700
And then what we found was that
with every month of health care

00:21:41.700 --> 00:21:44.730
disruption, an additional
19,000 children

00:21:44.730 --> 00:21:48.270
are unvaccinated against measles
in the three focal countries.

00:21:48.270 --> 00:21:53.010
And so you can see on this map
here that susceptible children

00:21:53.010 --> 00:21:55.080
reside in these
contiguous clusters that

00:21:55.080 --> 00:21:58.800
cross national borders.

00:21:58.800 --> 00:22:01.610
So to summarize this work
we know that the Ebola

00:22:01.610 --> 00:22:03.500
outbreak led to a
significant disruption

00:22:03.500 --> 00:22:06.290
in health care services, and
a corresponding reduction

00:22:06.290 --> 00:22:09.320
in routine childhood
vaccinations-- including

00:22:09.320 --> 00:22:10.700
those against measles.

00:22:10.700 --> 00:22:12.800
And then based on our
synthesis of DHS survey

00:22:12.800 --> 00:22:15.950
data with high resolution
demographic information,

00:22:15.950 --> 00:22:17.840
there would be these
large connected clusters

00:22:17.840 --> 00:22:19.880
of unvaccinated children.

00:22:19.880 --> 00:22:21.650
Some of the caveats
of this work are

00:22:21.650 --> 00:22:24.560
that the exact numbers
of susceptibles

00:22:24.560 --> 00:22:27.560
depends on the values of the
reduction in vaccination.

00:22:27.560 --> 00:22:29.810
And that could vary
spatially, based on factors

00:22:29.810 --> 00:22:32.030
like local Ebola incidents.

00:22:32.030 --> 00:22:34.500
But regardless of
the exact numbers,

00:22:34.500 --> 00:22:36.440
there is a clear path
to avoiding outbreaks

00:22:36.440 --> 00:22:39.020
of childhood vaccine
preventable disease, which

00:22:39.020 --> 00:22:42.470
would be to conduct a
multi-country vaccination

00:22:42.470 --> 00:22:46.340
campaign aimed at age groups
that were unprotected.

00:22:46.340 --> 00:22:48.230
And a robust campaign
could virtually

00:22:48.230 --> 00:22:51.490
eliminate the risk of
measles in the region.

00:22:51.490 --> 00:22:54.250
So we've heard secondhand
that this analysis, which

00:22:54.250 --> 00:22:56.980
we published during the last
year of the Ebola epidemic,

00:22:56.980 --> 00:22:59.600
was useful in motivating
a public health response.

00:22:59.600 --> 00:23:01.420
So in Liberia there
was an outbreak

00:23:01.420 --> 00:23:03.570
of measles in the
first half of 2015,

00:23:03.570 --> 00:23:06.760
and a follow up
national campaign--

00:23:06.760 --> 00:23:08.560
vaccination campaign
against measles,

00:23:08.560 --> 00:23:11.140
as well as polio, was
conducted that June.

00:23:11.140 --> 00:23:13.570
And so we've worked with
various organizations

00:23:13.570 --> 00:23:16.840
to do specific
follow up analyzes.

00:23:16.840 --> 00:23:19.360
And then in the Lola
prefecture of Guinea,

00:23:19.360 --> 00:23:21.280
which is near the
Liberian border,

00:23:21.280 --> 00:23:23.530
there was also an outbreak
of post-Ebola measles

00:23:23.530 --> 00:23:25.540
in the first half of 2015.

00:23:25.540 --> 00:23:29.710
And there were over 700
suspected measles cases.

00:23:29.710 --> 00:23:32.470
And this was another example
of Ebola-associated disruption

00:23:32.470 --> 00:23:35.350
to the health care system
since an SIA campaign had

00:23:35.350 --> 00:23:37.730
been planned in Guinea
during the previous year,

00:23:37.730 --> 00:23:39.790
but it was interrupted
by the Ebola outbreak.

00:23:39.790 --> 00:23:42.730
And it actually never
got to Lola prefecture.

00:23:42.730 --> 00:23:44.470
And so Matt Graham,
who was a post-doc

00:23:44.470 --> 00:23:46.750
at Johns Hopkins at the
time, led some of our work

00:23:46.750 --> 00:23:49.300
in estimating susceptibility
to measles in Lola,

00:23:49.300 --> 00:23:52.330
and forecasting the course
of the measles epidemic.

00:23:52.330 --> 00:23:56.110
And this was done with the
European CDC and the WHO.

00:23:56.110 --> 00:23:58.670
And so to conclude,
measles vaccination

00:23:58.670 --> 00:24:00.350
is a best buy in public health.

00:24:00.350 --> 00:24:03.044
The DHS survey data are
an invaluable resource

00:24:03.044 --> 00:24:05.210
for understanding the spatial
distribution of health

00:24:05.210 --> 00:24:07.940
indicators, including
childhood vaccination.

00:24:07.940 --> 00:24:10.420
And I hope I've demonstrated
that this type of work that

00:24:10.420 --> 00:24:13.340
leverages various data sources
and applies spatial analysis

00:24:13.340 --> 00:24:15.830
techniques can reveal
useful insights

00:24:15.830 --> 00:24:18.585
for real-time public health
planning and advocacy.

00:24:18.585 --> 00:24:21.620
So with that, I'd like to thank
my mentors, my collaborators,

00:24:21.620 --> 00:24:22.580
and funding sources.

00:24:22.580 --> 00:24:24.412
And thank you very much.

00:24:24.412 --> 00:24:27.358
[APPLAUSE]

00:24:31.286 --> 00:24:33.620
- Thank you very much.

00:24:33.620 --> 00:24:36.170
We'll take just a few
questions now for [INAUDIBLE]

00:24:36.170 --> 00:24:38.455
and some more afterwards.

00:24:41.579 --> 00:24:42.454
- Oh, the microphone.

00:24:42.454 --> 00:24:43.882
You sound [INAUDIBLE].

00:24:46.740 --> 00:24:49.870
- So I was really interested
in the demographic data

00:24:49.870 --> 00:24:51.860
that you used from
the satellite images.

00:24:51.860 --> 00:24:57.190
How does one link just
population density

00:24:57.190 --> 00:24:58.781
to population
density of children?

00:24:58.781 --> 00:25:00.280
Or are you just
making a correlation

00:25:00.280 --> 00:25:03.117
that there's some average number
of kids per number of people?

00:25:03.117 --> 00:25:05.200
- Yeah, so these are
actually age-structured data.

00:25:05.200 --> 00:25:08.729
So they go in and estimate
at five-year intervals,

00:25:08.729 --> 00:25:10.520
like, the number of
zero to five-year-olds,

00:25:10.520 --> 00:25:13.260
five to 10-year-olds, 10
to 15-year-olds, by pixel.

00:25:13.260 --> 00:25:15.760
- You can-- sorry, you can tell
the number of five-year-olds

00:25:15.760 --> 00:25:17.300
from space.

00:25:17.300 --> 00:25:18.130
- Apparently.

00:25:18.130 --> 00:25:18.940
- Wow.

00:25:18.940 --> 00:25:19.510
- Yeah.

00:25:19.510 --> 00:25:22.920
Well, so it's based on
demographic projections

00:25:22.920 --> 00:25:24.970
by UNDP and whatnot,
and fertility rates

00:25:24.970 --> 00:25:26.770
and those things go
into the estimation.

00:25:26.770 --> 00:25:29.020
But yeah, it's pretty cool.

00:25:38.230 --> 00:25:41.980
- I had a clarification
question on the R0.

00:25:41.980 --> 00:25:45.130
And I'm kind of assuming
that, in the background

00:25:45.130 --> 00:25:48.640
there, there's some assumption
about kind of how many people

00:25:48.640 --> 00:25:52.780
the typical child interacts
with, that's in the background

00:25:52.780 --> 00:25:53.650
there somewhere.

00:25:53.650 --> 00:25:56.380
And I'm wondering if
you could also tell us

00:25:56.380 --> 00:25:58.540
a little bit about the
state of the art in regard

00:25:58.540 --> 00:26:02.590
to, say, the social graph
structure in the sense

00:26:02.590 --> 00:26:05.890
that there may be some super
connectors who interact

00:26:05.890 --> 00:26:08.590
with a lot more people,
and kind of what

00:26:08.590 --> 00:26:11.860
does your literature have
to say about that problem,

00:26:11.860 --> 00:26:14.470
and how should we be
thinking about it.

00:26:14.470 --> 00:26:15.160
- Yeah.

00:26:15.160 --> 00:26:17.540
So for your first
point about R0,

00:26:17.540 --> 00:26:20.560
so that's something that,
for the context of measles,

00:26:20.560 --> 00:26:23.140
transmission is driven by
kids at schools, usually.

00:26:23.140 --> 00:26:25.930
So there's some great
work showing that,

00:26:25.930 --> 00:26:27.220
during the school--

00:26:27.220 --> 00:26:30.381
like when school is in session,
measles, R0, is higher.

00:26:30.381 --> 00:26:32.505
And then during the summer
term or winter vacation,

00:26:32.505 --> 00:26:33.309
R0 goes down.

00:26:33.309 --> 00:26:35.350
And that's because kids
aren't mixing in schools.

00:26:35.350 --> 00:26:38.170
And so there's a
whole literature

00:26:38.170 --> 00:26:40.330
around the seasonality
of measles.

00:26:40.330 --> 00:26:44.970
And then in terms of
I guess mixing, yeah,

00:26:44.970 --> 00:26:47.360
so I think that
what this work does

00:26:47.360 --> 00:26:49.776
is it sets the baseline
level of susceptibility.

00:26:49.776 --> 00:26:52.150
But then when you're actually
thinking about transmission

00:26:52.150 --> 00:26:55.690
and epidemic dynamics, it
gets much more complex,

00:26:55.690 --> 00:26:57.490
because you have
these non-linearities

00:26:57.490 --> 00:26:59.090
between susceptibles
and infecteds.

00:26:59.090 --> 00:27:00.650
And you know, it's--

00:27:00.650 --> 00:27:03.700
yeah, so I guess
all I would say is

00:27:03.700 --> 00:27:05.590
that trying to
understand susceptibility

00:27:05.590 --> 00:27:10.510
is possibly a more
tractable question.

00:27:10.510 --> 00:27:12.310
I think that-- yeah,
so in other work,

00:27:12.310 --> 00:27:14.200
I also think about
like epidemic dynamics

00:27:14.200 --> 00:27:16.355
and how transmission plays
out in the population.

00:27:16.355 --> 00:27:17.980
And I think you have
to think much more

00:27:17.980 --> 00:27:23.710
about how kids contact, or
how people contact each other,

00:27:23.710 --> 00:27:26.690
not just by space,
but also by age.

00:27:26.690 --> 00:27:29.890
So there are these studies that
show that essentially mixing

00:27:29.890 --> 00:27:31.690
patterns between
age, like there's

00:27:31.690 --> 00:27:34.690
this diagonal where I'm
more likely to interact

00:27:34.690 --> 00:27:36.100
with people of my age.

00:27:36.100 --> 00:27:38.470
But then there's also these
interesting off-diagonal

00:27:38.470 --> 00:27:41.650
effects, where parents
and children interact.

00:27:41.650 --> 00:27:46.240
And so you there are some
strong mixing patterns

00:27:46.240 --> 00:27:48.130
between those age
cohorts, as well.

00:27:48.130 --> 00:27:49.905
So, yeah, it's a really.

00:27:49.905 --> 00:27:51.946
- I'm gonna take the
microphone to ask a followup

00:27:51.946 --> 00:27:54.550
question, which will be the
last question, which is just--

00:27:54.550 --> 00:27:57.430
so I'm very interested
in spatial epidemiology.

00:27:57.430 --> 00:28:03.550
And part of the problem is that
these R0 models, very basic

00:28:03.550 --> 00:28:06.432
models, just assume, you know,
who's infected, [INAUDIBLE]

00:28:06.432 --> 00:28:08.110
no spatial information
whatsoever.

00:28:08.110 --> 00:28:11.780
And so what you've done is
take smaller and smaller

00:28:11.780 --> 00:28:14.660
spatial cells, and then
model those very carefully,

00:28:14.660 --> 00:28:16.960
and then get a spatial
map of what's going on.

00:28:16.960 --> 00:28:19.085
And there's interactions
within those spatial cells

00:28:19.085 --> 00:28:21.980
of different kinds of people,
to answer David's question

00:28:21.980 --> 00:28:24.250
about transmission, but
is there in your modeling

00:28:24.250 --> 00:28:26.610
any interaction between
the cells themselves,

00:28:26.610 --> 00:28:28.750
and does that
spatial relationship

00:28:28.750 --> 00:28:31.491
of the individual dots--

00:28:31.491 --> 00:28:31.990
- Yeah.

00:28:31.990 --> 00:28:33.680
Right now, it's
completely static,

00:28:33.680 --> 00:28:35.920
but I think that
this could probably

00:28:35.920 --> 00:28:38.800
serve as the basis
for dynamic modeling.

00:28:38.800 --> 00:28:39.530
Absolutely.

00:28:39.530 --> 00:28:40.029
Yeah.

00:28:40.029 --> 00:28:43.510
But there's not-- yeah, we don't
have kids moving or interacting

00:28:43.510 --> 00:28:45.638
in these flat maps.

00:28:45.638 --> 00:28:50.440
- [INAUDIBLE] the answer to
all questions in this session.

00:28:50.440 --> 00:28:51.983
But anyway, thank you again.

00:28:51.983 --> 00:28:52.483
- Thanks.

00:28:52.483 --> 00:28:56.427
[APPLAUSE]

00:29:00.300 --> 00:29:05.120
- So now we will move to
the largest scale of today.

00:29:05.120 --> 00:29:07.430
We will move to the
entire universe.

00:29:07.430 --> 00:29:10.080
And I will read a sentence
which is actually true,

00:29:10.080 --> 00:29:13.190
which is that Renee
Hlozek's goal is

00:29:13.190 --> 00:29:15.740
to understand the structure
and amount of dark energy

00:29:15.740 --> 00:29:19.100
in the universe constraining
theoretical cosmological models

00:29:19.100 --> 00:29:20.880
with observations.

00:29:20.880 --> 00:29:23.326
So for those of you who
don't study astronomy,

00:29:23.326 --> 00:29:24.950
that means that she's
actually studying

00:29:24.950 --> 00:29:27.320
the fundamental mysteries
of the universe.

00:29:27.320 --> 00:29:32.135
And we don't understand
like 95% of the universe,

00:29:32.135 --> 00:29:32.760
optimistically.

00:29:32.760 --> 00:29:37.190
And part of what Renee does
and the kind of data science

00:29:37.190 --> 00:29:39.050
that she's going to
talk to you about today

00:29:39.050 --> 00:29:41.540
is something that
people in astronomy

00:29:41.540 --> 00:29:44.480
have come to appreciate
in the last decade or so.

00:29:44.480 --> 00:29:46.160
What used to happen
in astronomy is

00:29:46.160 --> 00:29:47.900
that people would
make observations,

00:29:47.900 --> 00:29:49.400
and then they would
try to back out

00:29:49.400 --> 00:29:51.560
what the physical
parameters that explained

00:29:51.560 --> 00:29:53.420
those observations are.

00:29:53.420 --> 00:29:55.337
Now, there's a lot of
what in statistics often

00:29:55.337 --> 00:29:57.336
would be called forward
modeling, where you say,

00:29:57.336 --> 00:29:59.150
OK, I think maybe I
understand the physics.

00:29:59.150 --> 00:30:00.770
If I make a
prediction, to go back

00:30:00.770 --> 00:30:03.940
to Nathan's world, about
what the universe would

00:30:03.940 --> 00:30:05.450
look like under
those assumptions,

00:30:05.450 --> 00:30:06.800
what would that look like?

00:30:06.800 --> 00:30:08.258
And that's what
Renee will probably

00:30:08.258 --> 00:30:11.090
call a model, or a cosmological
model, in her case,

00:30:11.090 --> 00:30:12.180
of the universe.

00:30:12.180 --> 00:30:14.000
And then the statistically
difficult stuff

00:30:14.000 --> 00:30:17.660
is to get enough data and
enough clever statistics

00:30:17.660 --> 00:30:20.030
to constrain the difference
between the models

00:30:20.030 --> 00:30:21.457
and the observations.

00:30:21.457 --> 00:30:23.040
And sometimes, people
even go so far--

00:30:23.040 --> 00:30:25.623
and I don't know whether that's
what she'll talk about today--

00:30:25.623 --> 00:30:27.370
but to make synthetic
observations,

00:30:27.370 --> 00:30:29.810
to take these models and
then make fake observations,

00:30:29.810 --> 00:30:31.700
as if you have real telescopes.

00:30:31.700 --> 00:30:33.830
And so part of what
distinguishes Renee's work

00:30:33.830 --> 00:30:35.360
is that she's
actually interested

00:30:35.360 --> 00:30:37.380
in those real telescopes,
even though she

00:30:37.380 --> 00:30:38.810
trained as a theorist.

00:30:38.810 --> 00:30:42.330
So I should explain that
she did not go to Harvard,

00:30:42.330 --> 00:30:45.650
but we let her
come today anyway.

00:30:45.650 --> 00:30:49.230
So Renee is originally
from South Africa.

00:30:49.230 --> 00:30:51.560
And she went both to the
University of Pretoria

00:30:51.560 --> 00:30:53.960
and the University of Cape Town.

00:30:53.960 --> 00:30:56.120
And then she went
to Oxford, where

00:30:56.120 --> 00:30:59.030
she got her DPhil in 2011.

00:30:59.030 --> 00:31:02.560
And I met Renee sometime
around then, I don't know,

00:31:02.560 --> 00:31:06.530
at a funky [INAUDIBLE] event at
Google, and before that once.

00:31:06.530 --> 00:31:09.290
But Renee has a lot of
extracurricular interests,

00:31:09.290 --> 00:31:10.880
not unlike Nathan.

00:31:10.880 --> 00:31:14.229
And she was, among other
things, a senior TED fellow,

00:31:14.229 --> 00:31:15.770
while she was all
these other things,

00:31:15.770 --> 00:31:18.740
including she was a post-doc
before her current assistant

00:31:18.740 --> 00:31:21.380
professorship at the
University of Toronto.

00:31:21.380 --> 00:31:23.450
But she's also at
the Dunlap Institute,

00:31:23.450 --> 00:31:24.660
which I should mention.

00:31:24.660 --> 00:31:28.610
But she was a post-doc at
Princeton of many flavors

00:31:28.610 --> 00:31:30.260
that involve the
name Lyman Spitzer,

00:31:30.260 --> 00:31:32.240
who is one of my great
heroes in astrophysics.

00:31:32.240 --> 00:31:34.460
And you can ask me why later.

00:31:34.460 --> 00:31:36.270
That's not important right now.

00:31:36.270 --> 00:31:37.910
What's important
is that Renee is

00:31:37.910 --> 00:31:41.540
going to tell us about the most
modern techniques in trying

00:31:41.540 --> 00:31:43.710
to understand the
mysteries of the universe.

00:31:43.710 --> 00:31:44.993
So, no big deal.

00:31:44.993 --> 00:31:48.374
[APPLAUSE]

00:31:50.094 --> 00:31:51.510
- Thank you so
much for having me.

00:31:51.510 --> 00:31:52.800
It's wonderful to be here.

00:31:52.800 --> 00:31:56.700
I'd like to state for the record
that I had my measles and mumps

00:31:56.700 --> 00:31:58.680
booster a couple of months ago.

00:31:58.680 --> 00:32:01.020
I'm definitely going to
see Pacific Rim uprising,

00:32:01.020 --> 00:32:03.420
and I promise to stop adding
extra noise to your tweets,

00:32:03.420 --> 00:32:05.670
because I often post that
I'm really glad to be alive,

00:32:05.670 --> 00:32:08.560
and I really like the
universe and space.

00:32:08.560 --> 00:32:11.490
So I'm going to stop
that now and only be

00:32:11.490 --> 00:32:14.447
mildly pleased by the universe.

00:32:14.447 --> 00:32:16.530
But I do have the best
job, and I'm probably going

00:32:16.530 --> 00:32:18.240
to tweet about that later.

00:32:18.240 --> 00:32:20.836
So, thank you so much.

00:32:20.836 --> 00:32:22.710
So I used to live in
New York City for a year

00:32:22.710 --> 00:32:26.550
while I was at Princeton,
and one of the reasons why

00:32:26.550 --> 00:32:29.460
I like bringing that up
when I talk about what I do

00:32:29.460 --> 00:32:32.130
is because, while
Hurricane Sandy gave us

00:32:32.130 --> 00:32:36.470
many terrible things, one thing
it did give us was darkness.

00:32:36.470 --> 00:32:38.385
And so I'm going to
take you back to Sandy.

00:32:38.385 --> 00:32:40.920
So this photo was
taken by Jared Levy

00:32:40.920 --> 00:32:44.220
through a darkened
lower Manhattan.

00:32:44.220 --> 00:32:46.914
And imagine that you were here.

00:32:46.914 --> 00:32:48.580
You can see there
were cars on the road,

00:32:48.580 --> 00:32:50.220
but there are no street lights.

00:32:50.220 --> 00:32:53.880
And you want to cross
the road and not die.

00:32:53.880 --> 00:32:54.800
So what do you do?

00:32:54.800 --> 00:32:56.940
You typically, if you've
grown up in a city,

00:32:56.940 --> 00:32:59.820
you look at the cars
approaching you,

00:32:59.820 --> 00:33:01.442
and if their head
lamps are bright,

00:33:01.442 --> 00:33:03.150
you realize they're
probably close to you

00:33:03.150 --> 00:33:05.070
and will kill you if
you cross the road.

00:33:05.070 --> 00:33:06.114
And so you don't.

00:33:06.114 --> 00:33:07.530
And if their head
lamps are faint,

00:33:07.530 --> 00:33:11.000
you realize they're probably far
away, and you cross the road.

00:33:11.000 --> 00:33:12.930
But did you ever ask
who told you to do that?

00:33:12.930 --> 00:33:15.366
Like, who taught you to do that?

00:33:15.366 --> 00:33:16.740
If anyone has
grown up in a city,

00:33:16.740 --> 00:33:18.360
you just learn how to
do that, because you

00:33:18.360 --> 00:33:20.526
understand that there's a
connection with brightness

00:33:20.526 --> 00:33:22.050
and distance.

00:33:22.050 --> 00:33:23.840
But it relies on a
fundamental assumption.

00:33:23.840 --> 00:33:25.830
It relies on the assumption
that the person who

00:33:25.830 --> 00:33:28.110
put the headlamps
in the car put them

00:33:28.110 --> 00:33:29.400
in with the same brightness.

00:33:29.400 --> 00:33:31.610
Otherwise, that whole
calculus you did in your head

00:33:31.610 --> 00:33:34.890
without thinking would fail, and
you'd cross the road and die.

00:33:34.890 --> 00:33:38.230
So we call these things
standard head lamps.

00:33:38.230 --> 00:33:40.605
Or if you're in cosmology and
you like to be a little bit

00:33:40.605 --> 00:33:42.210
archaic, you call
them standard candles,

00:33:42.210 --> 00:33:44.585
because that sounds cooler,
and candles were a thing back

00:33:44.585 --> 00:33:46.020
in the day.

00:33:46.020 --> 00:33:48.130
But we do this in
astronomy, too.

00:33:48.130 --> 00:33:50.880
We actually use
exploding stars that we

00:33:50.880 --> 00:33:54.120
think explode with roughly
the same brightness wherever

00:33:54.120 --> 00:33:55.710
they are in the
universe to tell us

00:33:55.710 --> 00:33:57.760
something about the distance.

00:33:57.760 --> 00:34:01.950
So for example, this is an
image of the Whirlpool Galaxy.

00:34:01.950 --> 00:34:05.266
And I'm going to tell you
there's an arrow there, which

00:34:05.266 --> 00:34:06.390
is going to guide your eye.

00:34:06.390 --> 00:34:08.610
But even without the
arrow, if I show you

00:34:08.610 --> 00:34:11.010
an image taken before
and after, you'll

00:34:11.010 --> 00:34:13.870
see that there's something
there that wasn't there before.

00:34:13.870 --> 00:34:16.237
This is an exploding
star, exactly

00:34:16.237 --> 00:34:18.320
similar to the kind that
Nathan was talking about,

00:34:18.320 --> 00:34:21.389
an exploding
supernova that shines

00:34:21.389 --> 00:34:24.030
very brightly in its galaxy.

00:34:24.030 --> 00:34:26.280
And so these objects
actually allow

00:34:26.280 --> 00:34:29.230
us to make a measurement of
distance in the universe.

00:34:29.230 --> 00:34:30.840
And I care about
that as a cosmologist

00:34:30.840 --> 00:34:33.805
because, if I understand
how big the universe is,

00:34:33.805 --> 00:34:36.179
that tells me something about
what the universe contains,

00:34:36.179 --> 00:34:37.910
and also how it
changes with time

00:34:37.910 --> 00:34:39.659
and how it evolves and
all of these really

00:34:39.659 --> 00:34:42.870
grandiose questions
that I want to answer.

00:34:42.870 --> 00:34:45.330
In order to measure
these kinds of objects,

00:34:45.330 --> 00:34:47.730
I need to build bigger
and bigger telescopes.

00:34:47.730 --> 00:34:52.139
And so this is the wonderfully
named Large Synoptic Survey

00:34:52.139 --> 00:34:56.310
Telescope, or LSST, or,
as I like to call it,

00:34:56.310 --> 00:34:58.380
the Careful What You
Wish For telescope.

00:34:58.380 --> 00:35:00.090
And I'll tell you
why in a second.

00:35:00.090 --> 00:35:03.374
This is being constructed
in northern Chile.

00:35:03.374 --> 00:35:05.040
I have a great movie
of the construction

00:35:05.040 --> 00:35:06.930
later, as Alyssa said,
but I didn't put it

00:35:06.930 --> 00:35:07.890
in the beginning of
the talk because I

00:35:07.890 --> 00:35:09.480
figured it was too dramatic.

00:35:09.480 --> 00:35:12.250
But we can get to the
dramatic parts in a bit.

00:35:12.250 --> 00:35:14.910
And LSST is really
incredible because it has

00:35:14.910 --> 00:35:17.730
incredibly amazing instruments.

00:35:17.730 --> 00:35:22.270
And it looks at a large part
of the sky at any given time.

00:35:22.270 --> 00:35:27.110
So it has a 3.5-degree diameter
in the size of what it looks

00:35:27.110 --> 00:35:27.610
at.

00:35:27.610 --> 00:35:29.026
So that's seven
times the diameter

00:35:29.026 --> 00:35:31.300
of the full moon in the sky.

00:35:31.300 --> 00:35:34.230
And if you were to point the
Hubble telescope, which we all

00:35:34.230 --> 00:35:37.020
know and love, to take
images of that same patch,

00:35:37.020 --> 00:35:40.560
you'd need 3,000 images of
Hubble to patch that whole sky.

00:35:40.560 --> 00:35:42.679
So it's really incredible.

00:35:42.679 --> 00:35:44.220
And the way that
you do this, the way

00:35:44.220 --> 00:35:47.340
you get a telescope like this
is you build a giant camera.

00:35:47.340 --> 00:35:52.044
So this is a
3.2-megapixel camera.

00:35:52.044 --> 00:35:54.210
And it's about the size of
the gentleman [? whose ?]

00:35:54.210 --> 00:35:56.280
[? head ?] has no
head is to scale.

00:35:56.280 --> 00:35:57.930
So the LSST camera
is about the size

00:35:57.930 --> 00:36:02.669
of a Volkswagen Beetle, which
again is a car from the past.

00:36:02.669 --> 00:36:04.210
But the incredible
thing is that LSST

00:36:04.210 --> 00:36:06.190
will scan the sky very rapidly.

00:36:06.190 --> 00:36:10.260
So it will scan the whole sky
about once every three days,

00:36:10.260 --> 00:36:12.660
which is something that
really isn't possible now

00:36:12.660 --> 00:36:14.910
with current telescopes
to that same depth

00:36:14.910 --> 00:36:16.920
and to that same precision.

00:36:16.920 --> 00:36:19.650
And that allows us to really see
the sky in a whole new light.

00:36:19.650 --> 00:36:23.360
So if we take a journey
back in time to pre-2000,

00:36:23.360 --> 00:36:27.244
if you digitize old plates,
old plates from telescopes,

00:36:27.244 --> 00:36:28.410
you get something like this.

00:36:28.410 --> 00:36:31.320
You can see the sky, and
it's really incredible.

00:36:31.320 --> 00:36:34.320
And I'm going to show you
what it looked like post that.

00:36:34.320 --> 00:36:36.060
So this is coming
out a little dark,

00:36:36.060 --> 00:36:39.210
but the Sloan Digital Sky
Survey was a small telescope

00:36:39.210 --> 00:36:42.100
that also scanned the
sky a lot, and really

00:36:42.100 --> 00:36:46.090
revolutionized astronomy when
it came about in the 2000s

00:36:46.090 --> 00:36:50.067
because, until then, it hadn't
been possible to really scan

00:36:50.067 --> 00:36:50.650
the whole sky.

00:36:50.650 --> 00:36:53.410
And so one of my old
advisors as an undergrad

00:36:53.410 --> 00:37:00.010
said that Sloan essentially did
his entire body's work of 20

00:37:00.010 --> 00:37:02.260
years in about three weeks.

00:37:02.260 --> 00:37:04.510
So it really
revolutionized things.

00:37:04.510 --> 00:37:07.810
But LSST-- this is a simulation
of what LSST will see--

00:37:07.810 --> 00:37:10.420
it will just be
incredibly deep, and show

00:37:10.420 --> 00:37:12.730
us really incredibly
large numbers of objects

00:37:12.730 --> 00:37:14.450
that we just
haven't seen before.

00:37:14.450 --> 00:37:16.783
So the projected estimates
are that we measure something

00:37:16.783 --> 00:37:18.280
like 40 billion
stars and galaxies.

00:37:18.280 --> 00:37:21.040
Those numbers start
to sound astronomical,

00:37:21.040 --> 00:37:24.770
for want of a better word.

00:37:24.770 --> 00:37:26.590
And what it'll
actually do is now

00:37:26.590 --> 00:37:30.220
we can start to see the
sky not only as static,

00:37:30.220 --> 00:37:32.770
but really as transient,
that there are objects that

00:37:32.770 --> 00:37:34.570
come in and out, as
Nathan introduced us

00:37:34.570 --> 00:37:37.790
to earlier, these objects
that brighten and then fade.

00:37:37.790 --> 00:37:40.030
And if you looked at the
sky-- this is a simulation

00:37:40.030 --> 00:37:42.696
of the kinds of objects that we,
or the kinds of explosions that

00:37:42.696 --> 00:37:45.040
we would expect
to see with LSST--

00:37:45.040 --> 00:37:48.160
you expect to see so
many of these supernovae

00:37:48.160 --> 00:37:51.400
of different kinds going off
in the sky at any time, which

00:37:51.400 --> 00:37:51.930
is great.

00:37:51.930 --> 00:37:58.480
So we're going to get vast
amounts of data from LSST.

00:37:58.480 --> 00:38:01.150
But you have to be
careful what you wish for.

00:38:01.150 --> 00:38:05.500
So I like analogies, because
I'm a professor of astronomy,

00:38:05.500 --> 00:38:08.470
and we have so many cool things
we can make analogies to.

00:38:08.470 --> 00:38:11.560
And so I like to say, imagine if
all the supernovae that we know

00:38:11.560 --> 00:38:13.510
of up to now, that
we have really

00:38:13.510 --> 00:38:17.290
studied very well with
smaller telescopes,

00:38:17.290 --> 00:38:20.271
let's just assume those
are all modeled by a fish.

00:38:20.271 --> 00:38:20.770
This fish.

00:38:20.770 --> 00:38:21.930
I can see it really well.

00:38:21.930 --> 00:38:25.290
I understand it's got some
cool, like, lip action going on.

00:38:25.290 --> 00:38:26.500
There's fins.

00:38:26.500 --> 00:38:29.620
I can look at its markings, and
I can understand it very well.

00:38:29.620 --> 00:38:31.750
And that's fantastically
useful if I want

00:38:31.750 --> 00:38:33.890
to understand this one fish.

00:38:33.890 --> 00:38:36.380
LSST is going to give us
something more like this.

00:38:36.380 --> 00:38:38.710
I'm going to get a lot of
data, but now I can't really

00:38:38.710 --> 00:38:40.664
tell how many types
of data there are,

00:38:40.664 --> 00:38:42.580
or how many different
kinds of fish there are.

00:38:42.580 --> 00:38:45.466
Actually, this comes from
a study on coral diversity.

00:38:45.466 --> 00:38:46.840
And I tried to--
it's really hard

00:38:46.840 --> 00:38:48.214
to find images of
schools of fish

00:38:48.214 --> 00:38:50.230
that are not just
one type of fish.

00:38:50.230 --> 00:38:52.980
But apparently, there are
148 different species of fish

00:38:52.980 --> 00:38:55.900
in this image, according to
the website that I shamelessly

00:38:55.900 --> 00:38:57.880
stole it from.

00:38:57.880 --> 00:38:59.890
And that's both a
fantastic challenge

00:38:59.890 --> 00:39:02.200
and it's incredibly
scary, because now

00:39:02.200 --> 00:39:05.690
we really need to know
about each different type.

00:39:05.690 --> 00:39:08.110
The reason why that's
important is the kinds of stars

00:39:08.110 --> 00:39:12.280
that I use to do cosmology with
that really are intrinsically

00:39:12.280 --> 00:39:14.240
bright everywhere
in the universe,

00:39:14.240 --> 00:39:18.280
those are a very specific subset
of these supernovae transients.

00:39:18.280 --> 00:39:20.600
They're called
type 1a supernovae.

00:39:20.600 --> 00:39:22.090
And they have this relationship.

00:39:22.090 --> 00:39:24.430
But other dying stars,
similar to the ones

00:39:24.430 --> 00:39:27.130
that Nathan studies,
they die when

00:39:27.130 --> 00:39:28.990
they are at the
end of their lives,

00:39:28.990 --> 00:39:31.120
and they die with
different various masses.

00:39:31.120 --> 00:39:33.880
And so we don't have
the same correlation

00:39:33.880 --> 00:39:36.910
with explosion and distance
that you would have.

00:39:36.910 --> 00:39:39.220
And so if I just use
all of these fish,

00:39:39.220 --> 00:39:40.990
assuming they're
of one type, I'll

00:39:40.990 --> 00:39:44.140
actually get a very different
answer than if I hand-pick out

00:39:44.140 --> 00:39:45.480
the ones that I want.

00:39:45.480 --> 00:39:48.670
But I can't hand-pick out so
many fish because I'd need them

00:39:48.670 --> 00:39:51.000
to look like this,
and I want to look--

00:39:51.000 --> 00:39:53.077
I know they will look like this.

00:39:53.077 --> 00:39:54.910
So the question is,
well, how do we classify

00:39:54.910 --> 00:39:56.017
astronomical transients?

00:39:56.017 --> 00:39:58.100
I'm going to highlight
some of the work by myself,

00:39:58.100 --> 00:40:00.980
but also lots of my colleagues
who are really exploding

00:40:00.980 --> 00:40:02.210
in interest in this field.

00:40:02.210 --> 00:40:03.569
And it's really fantastic.

00:40:03.569 --> 00:40:05.110
So again, this was
introduced before,

00:40:05.110 --> 00:40:07.587
but we do something typically
called a difference image.

00:40:07.587 --> 00:40:09.670
I take a photo of you
today, I take a photo of you

00:40:09.670 --> 00:40:13.090
tomorrow, I remove the average,
which is just how old you are,

00:40:13.090 --> 00:40:14.200
how tired you are.

00:40:14.200 --> 00:40:16.658
And then I probably see that
you were crying this afternoon

00:40:16.658 --> 00:40:18.040
or something like that.

00:40:18.040 --> 00:40:19.830
Probably don't cry at
the end of my talk.

00:40:19.830 --> 00:40:21.100
But we do this in space.

00:40:21.100 --> 00:40:23.540
And so we take a photo of a
galaxy today and tomorrow.

00:40:23.540 --> 00:40:25.784
And if we see a difference,
we know that there's

00:40:25.784 --> 00:40:26.950
some explosion has gone off.

00:40:26.950 --> 00:40:28.215
And you see this.

00:40:28.215 --> 00:40:30.340
What looks like just a
boring white dot is actually

00:40:30.340 --> 00:40:32.200
incredible because
it's showing us

00:40:32.200 --> 00:40:35.195
that there's a transient at
that position in the galaxy.

00:40:35.195 --> 00:40:37.570
This allows us to [? build-- ?]
because we have different

00:40:37.570 --> 00:40:40.810
filters on LSSTs, so we actually
measure the sky not just

00:40:40.810 --> 00:40:43.739
in optical light, but we
select very specific wavelength

00:40:43.739 --> 00:40:46.030
of light, and so we can
actually measure what does this

00:40:46.030 --> 00:40:47.860
transient look like
in different filters.

00:40:47.860 --> 00:40:50.910
And we give them very
original names, like R, G, I,

00:40:50.910 --> 00:40:53.080
and Z. And Y.

00:40:53.080 --> 00:40:55.210
And so you can see
that the brightness

00:40:55.210 --> 00:40:59.160
of the object in these filters
change as a function of time.

00:40:59.160 --> 00:41:01.450
And the way that
they change with time

00:41:01.450 --> 00:41:04.160
is, luckily, different
for Nathan's supernovae

00:41:04.160 --> 00:41:05.191
and my supernovae.

00:41:05.191 --> 00:41:06.940
Sorry, I'm throwing
you under the bus now.

00:41:06.940 --> 00:41:09.040
You did it to Alyssa, so.

00:41:09.040 --> 00:41:10.990
So one of the ways
you can distinguish

00:41:10.990 --> 00:41:13.080
these different
types of supernovae,

00:41:13.080 --> 00:41:14.500
or type of transients
in general,

00:41:14.500 --> 00:41:16.230
is to fit some kind of--

00:41:16.230 --> 00:41:17.590
to extract some features.

00:41:17.590 --> 00:41:19.240
So I know that
there's a light curve.

00:41:19.240 --> 00:41:20.800
Can I describe it in some way?

00:41:20.800 --> 00:41:23.770
Can I figure out what the
components of the light curve

00:41:23.770 --> 00:41:26.250
R, or can I fit
a template to it?

00:41:26.250 --> 00:41:28.000
And myself and
other colleagues do

00:41:28.000 --> 00:41:31.000
a lot of these kinds of
approaches, where you find out

00:41:31.000 --> 00:41:33.580
the number of features that
describe this light curve,

00:41:33.580 --> 00:41:36.670
and then you can train your
machine learning classifier

00:41:36.670 --> 00:41:39.740
on that using
various techniques.

00:41:39.740 --> 00:41:42.610
And these are great,
but it helps--

00:41:42.610 --> 00:41:45.250
the key in this area is really
to understand the clustering

00:41:45.250 --> 00:41:46.310
of these objects.

00:41:46.310 --> 00:41:49.150
So what types of supernovae
or what types of transients

00:41:49.150 --> 00:41:51.520
have the same
characteristics or features,

00:41:51.520 --> 00:41:53.840
and how do they
cluster together?

00:41:53.840 --> 00:41:55.100
Which is really important.

00:41:55.100 --> 00:41:57.100
And so some of my colleagues
spend a lot of time

00:41:57.100 --> 00:41:59.000
making graphs like this.

00:41:59.000 --> 00:42:01.710
So this is a T-distributed
stochastic neighborhood

00:42:01.710 --> 00:42:02.609
embedding.

00:42:02.609 --> 00:42:04.900
And the only thing you need
to take away from this plot

00:42:04.900 --> 00:42:07.660
is, if the areas are
overlapping in this space,

00:42:07.660 --> 00:42:09.430
you can't tell them
apart very well.

00:42:09.430 --> 00:42:12.970
What you want is actually, in
this particular dimensional

00:42:12.970 --> 00:42:16.960
representation, you want all the
little types or classifications

00:42:16.960 --> 00:42:18.130
to be separate.

00:42:18.130 --> 00:42:22.270
And one of the things we find
in astronomical supernova data

00:42:22.270 --> 00:42:25.360
is that actually we
have a lot of overlap.

00:42:25.360 --> 00:42:27.610
A lot of the things look a
little bit like each other.

00:42:27.610 --> 00:42:30.520
If I change the characteristics
of the supernova explosion,

00:42:30.520 --> 00:42:33.190
it could look a little like a
variable star, which is again

00:42:33.190 --> 00:42:35.356
very interesting, but not
telling me about cosmology

00:42:35.356 --> 00:42:36.290
necessarily.

00:42:36.290 --> 00:42:38.290
And so one way that
you can do that

00:42:38.290 --> 00:42:45.280
is to try and reintroduce some
sort of balancing to your data.

00:42:45.280 --> 00:42:48.400
One of the things that happens
is some kinds of objects

00:42:48.400 --> 00:42:51.100
are much more probable to occur
than other kinds of objects.

00:42:51.100 --> 00:42:53.950
And so when you look
at a set of data

00:42:53.950 --> 00:42:57.280
that you get from a telescope,
you get a whole lot of one kind

00:42:57.280 --> 00:42:58.690
and none of the other.

00:42:58.690 --> 00:43:00.920
If I want to then
train some classifying

00:43:00.920 --> 00:43:03.310
algorithm on that
training data, it's

00:43:03.310 --> 00:43:05.970
going to do very well at
classifying this kind of data

00:43:05.970 --> 00:43:08.144
and very badly at classifying
this kind of data.

00:43:08.144 --> 00:43:10.060
Just like if you've never
met a South African,

00:43:10.060 --> 00:43:11.980
it's hard to classify my accent.

00:43:11.980 --> 00:43:15.250
But the more South Africans
you meet, the better you get.

00:43:15.250 --> 00:43:17.860
And so the way that you
can do that is either bring

00:43:17.860 --> 00:43:21.430
more South Africans into the
room or kind of copying me.

00:43:21.430 --> 00:43:25.032
So make different copies of my
accent, change it subtly to try

00:43:25.032 --> 00:43:27.240
and make the balance in the
room a little bit better.

00:43:27.240 --> 00:43:30.130
And this is what some
of my colleagues do.

00:43:30.130 --> 00:43:32.080
Another thing that's
really interesting

00:43:32.080 --> 00:43:36.280
is to try and say, well, can I,
rather than removing features,

00:43:36.280 --> 00:43:38.874
can I turn a light
curve into an image

00:43:38.874 --> 00:43:40.540
and then apply a lot
of very interesting

00:43:40.540 --> 00:43:42.400
visual deep learning techniques?

00:43:42.400 --> 00:43:45.250
So this is again from
a colleague of mine

00:43:45.250 --> 00:43:50.380
who has done this, and is now
able to, instead of saying

00:43:50.380 --> 00:43:53.020
I think I know what features
are in this light curve,

00:43:53.020 --> 00:43:54.802
turn it into an image
and apply something

00:43:54.802 --> 00:43:56.260
like a convolutional
neural network

00:43:56.260 --> 00:43:58.000
to try and do this
classification.

00:43:58.000 --> 00:44:00.550
And it's shown that
they do pretty well.

00:44:00.550 --> 00:44:02.050
This is a little
side note because I

00:44:02.050 --> 00:44:03.250
asked a colleague
of mine in Toronto

00:44:03.250 --> 00:44:05.020
about the work he's doing
in machine learning,

00:44:05.020 --> 00:44:06.340
and he told me about
craters on the moon,

00:44:06.340 --> 00:44:07.839
and I just had to
share it with you.

00:44:07.839 --> 00:44:10.360
It's not related to
astronomy of exploding stars,

00:44:10.360 --> 00:44:12.830
but I thought it
was really cool.

00:44:12.830 --> 00:44:14.170
We see craters on the moon.

00:44:14.170 --> 00:44:16.529
Turns out, they're very
hard to find and identify.

00:44:16.529 --> 00:44:17.070
Did you know?

00:44:17.070 --> 00:44:19.060
I did not know that until
a couple of days ago.

00:44:19.060 --> 00:44:23.122
And so a colleague of mine
at the University of Toronto,

00:44:23.122 --> 00:44:25.330
there's a lot of data and
there are a lot of craters.

00:44:25.330 --> 00:44:27.670
And typically, grad
students go and circle them,

00:44:27.670 --> 00:44:29.850
and they see if they have them.

00:44:29.850 --> 00:44:31.830
But the little craters
are very numerous.

00:44:31.830 --> 00:44:33.970
And particularly, the
backside of the moon

00:44:33.970 --> 00:44:36.490
doesn't have a lot of
images taken of it.

00:44:36.490 --> 00:44:38.770
And so these
colleagues in Toronto

00:44:38.770 --> 00:44:42.250
actually developed, again, a
convolutional neural network

00:44:42.250 --> 00:44:44.140
to build up templates
of what they think

00:44:44.140 --> 00:44:45.516
the circles of the moon are.

00:44:45.516 --> 00:44:47.140
And then there's some
data that you can

00:44:47.140 --> 00:44:49.060
use to validate your results.

00:44:49.060 --> 00:44:53.410
And they can identify 92% of the
craters that exist in images.

00:44:53.410 --> 00:44:56.766
And they're having a great
time at the back of the moon.

00:44:56.766 --> 00:44:58.390
So this is really
cool work that I just

00:44:58.390 --> 00:44:59.431
wanted to have highlight.

00:44:59.431 --> 00:45:01.930
But that's a little diversion.

00:45:01.930 --> 00:45:04.930
One question that we
ask is, can we actually

00:45:04.930 --> 00:45:07.110
skip this difference
imaging completely?

00:45:07.110 --> 00:45:09.610
So the problem with taking an
image of me today and an image

00:45:09.610 --> 00:45:12.850
of me tomorrow and taking
the difference is, sometimes,

00:45:12.850 --> 00:45:15.610
something will happen to
the image that introduces

00:45:15.610 --> 00:45:18.400
an artifact that's not real.

00:45:18.400 --> 00:45:20.790
So I could-- if I'm not wearing
exactly the same outfit,

00:45:20.790 --> 00:45:23.206
something moves, you might
think that there's a transient,

00:45:23.206 --> 00:45:26.830
but actually it's just a
factor of the image processing.

00:45:26.830 --> 00:45:28.570
And that happens a
lot, particularly

00:45:28.570 --> 00:45:29.840
with things like cosmic rays.

00:45:29.840 --> 00:45:33.250
So these are things that come
not from a cosmological origin,

00:45:33.250 --> 00:45:35.170
but just more local
to the instrument.

00:45:35.170 --> 00:45:37.767
And that can really
influence your result.

00:45:37.767 --> 00:45:39.350
But some colleagues
of mine have said,

00:45:39.350 --> 00:45:43.300
well, listen, we can model
a galaxy plus a little star,

00:45:43.300 --> 00:45:46.240
and we can train
our neural networks

00:45:46.240 --> 00:45:48.700
to predict that and
then test it with data.

00:45:48.700 --> 00:45:51.280
And actually, they're
finding pretty great results,

00:45:51.280 --> 00:45:52.900
where they don't
need to just take

00:45:52.900 --> 00:45:56.260
differences between day
one and day two, which

00:45:56.260 --> 00:45:58.850
is really useful.

00:45:58.850 --> 00:46:00.390
So how do we get ready for LSST?

00:46:00.390 --> 00:46:03.640
So something that I've become
very involved with recently

00:46:03.640 --> 00:46:06.100
is trying to do better
at simulating what

00:46:06.100 --> 00:46:08.770
we think LSST will be like.

00:46:08.770 --> 00:46:10.570
People talk about
turning the faucet on

00:46:10.570 --> 00:46:12.010
and data just comes
streaming out.

00:46:12.010 --> 00:46:15.160
And the big problem with
LSST is that, even though we

00:46:15.160 --> 00:46:19.060
can write down what we
think the data rate will be,

00:46:19.060 --> 00:46:22.750
we've just never seen this many
objects because we've never

00:46:22.750 --> 00:46:24.640
had a telescope
that is good enough

00:46:24.640 --> 00:46:27.880
to look with such precision and
such accuracy and such repeated

00:46:27.880 --> 00:46:28.690
cadence.

00:46:28.690 --> 00:46:30.490
So it is going to
just be a data deluge.

00:46:30.490 --> 00:46:33.410
And you have to try and
prepare yourself for that.

00:46:33.410 --> 00:46:35.260
So as I said before,
we have a problem that,

00:46:35.260 --> 00:46:37.600
often, the data
that you train on

00:46:37.600 --> 00:46:39.860
isn't representative of
the data that you receive.

00:46:39.860 --> 00:46:41.860
And we know that that
will be the case with LSST

00:46:41.860 --> 00:46:44.810
because it's just looking
deeper than anything has before.

00:46:44.810 --> 00:46:47.200
So what we can try
to do is actually

00:46:47.200 --> 00:46:50.950
simulate data sets and collect
all the data to try and make

00:46:50.950 --> 00:46:52.810
something more representative.

00:46:52.810 --> 00:46:57.040
So this is just another
example of that,

00:46:57.040 --> 00:47:02.070
where the training data in black
were used on the testing data.

00:47:02.070 --> 00:47:04.842
And you can just see that those
two data sets are really not

00:47:04.842 --> 00:47:06.050
representative of each other.

00:47:06.050 --> 00:47:08.230
And so you really struggle,
your algorithms really

00:47:08.230 --> 00:47:10.150
struggle to predict
the rate if all you had

00:47:10.150 --> 00:47:12.340
was the black to train on.

00:47:12.340 --> 00:47:13.497
And so some of my work--

00:47:13.497 --> 00:47:15.580
some of the work that a
colleague of mine, Rafael,

00:47:15.580 --> 00:47:19.660
is doing in the audience is
actually collecting data from

00:47:19.660 --> 00:47:22.220
lots of different surveys within
a particular area of the sky

00:47:22.220 --> 00:47:24.700
that's been well-studied,
and also trying to say, well,

00:47:24.700 --> 00:47:25.390
so these--

00:47:25.390 --> 00:47:29.950
on the y-axis is different
types of variables, and trying

00:47:29.950 --> 00:47:32.110
to figure out, can
we oversample where

00:47:32.110 --> 00:47:34.390
we need to, can we build
complete light curves,

00:47:34.390 --> 00:47:36.320
can we actually build
a good data set,

00:47:36.320 --> 00:47:39.310
and that people can use to
classify on with existing data.

00:47:39.310 --> 00:47:43.480
And this partly inspired us
to do this from a simulation

00:47:43.480 --> 00:47:45.060
standpoint, as well.

00:47:45.060 --> 00:47:47.050
So with Rafael and
others, I'm actually

00:47:47.050 --> 00:47:50.440
leading a group of people around
the astronomical community

00:47:50.440 --> 00:47:52.191
who are bringing their
theoretical models.

00:47:52.191 --> 00:47:53.815
So they're actually
bringing the models

00:47:53.815 --> 00:47:55.330
that they've inferred from data.

00:47:55.330 --> 00:47:57.820
And now we're saying,
can we simulate the sky?

00:47:57.820 --> 00:47:59.920
Can I tell you I'm
going to make a sky that

00:47:59.920 --> 00:48:02.890
has supernovae, and type 1A
supernovae, and core collapse

00:48:02.890 --> 00:48:06.100
supernovae, and transients, and
variable stars, and asteroids,

00:48:06.100 --> 00:48:09.100
and throw them all together,
and then open it up

00:48:09.100 --> 00:48:12.310
to the machine learning
community in general,

00:48:12.310 --> 00:48:14.860
not just astronomers, to
say, we are going to give you

00:48:14.860 --> 00:48:17.290
an object of about-- sorry,
a data set of about a million

00:48:17.290 --> 00:48:19.720
objects as a function of time.

00:48:19.720 --> 00:48:22.630
Can you classify them, and
how well are you going to do?

00:48:22.630 --> 00:48:26.470
And what happens if we change
the cadence of how often LSST

00:48:26.470 --> 00:48:27.950
looks at the sky?

00:48:27.950 --> 00:48:30.730
So this is really
exciting work, and it's

00:48:30.730 --> 00:48:34.720
proving to be very interesting
and very complex as we try

00:48:34.720 --> 00:48:39.400
and piece apart the ways to
make the data rich and usable,

00:48:39.400 --> 00:48:41.350
and also to engage
people that are not

00:48:41.350 --> 00:48:43.690
just astronomers to try
and help us understand

00:48:43.690 --> 00:48:45.220
the incredible sky.

00:48:45.220 --> 00:48:48.174
I'm really lucky that I am
able to do this as my job.

00:48:48.174 --> 00:48:49.840
But looking up at the
sky shouldn't just

00:48:49.840 --> 00:48:53.170
be something I think that
is reserved for people who

00:48:53.170 --> 00:48:56.350
live in universities, because
trying to understand what

00:48:56.350 --> 00:48:57.850
goes bang in the
night is something

00:48:57.850 --> 00:48:59.110
that matters to all of us.

00:48:59.110 --> 00:48:59.925
Thanks.

00:48:59.925 --> 00:49:03.320
[APPLAUSE]

00:49:07.200 --> 00:49:10.595
- [INAUDIBLE].

00:49:10.595 --> 00:49:12.094
We'll show the other
beautiful movie

00:49:12.094 --> 00:49:13.456
at the end of the discussion.

00:49:13.456 --> 00:49:15.170
But anyway, we can
take questions now.

00:49:15.170 --> 00:49:15.930
Go ahead.

00:49:15.930 --> 00:49:18.130
- Nice talk.

00:49:18.130 --> 00:49:20.640
I have kind of a niggledy
piggledy question

00:49:20.640 --> 00:49:23.640
on the stochastic
clustering embedding chart.

00:49:23.640 --> 00:49:26.595
What's the rationale for not
including individual points?

00:49:30.770 --> 00:49:33.240
- So one of the things--

00:49:33.240 --> 00:49:37.240
I mean, you can try and do a
clustering over multiple axes.

00:49:37.240 --> 00:49:38.892
So in this sense,
what-- oh, you mean

00:49:38.892 --> 00:49:40.350
just the visual
representation, why

00:49:40.350 --> 00:49:42.687
we used a KDE to smooth it out?

00:49:42.687 --> 00:49:45.270
I think that's basically just
to make things look a little bit

00:49:45.270 --> 00:49:46.061
better as the plot.

00:49:46.061 --> 00:49:48.270
So one of my
bugbears, for everyone

00:49:48.270 --> 00:49:50.610
who's interested in data
science, typically the plots

00:49:50.610 --> 00:49:54.510
that we make are really ugly
because they're like plots

00:49:54.510 --> 00:49:57.369
in a t-SNE plot showing
some kind of clustering,

00:49:57.369 --> 00:49:59.160
but if you look at it,
it's not really show

00:49:59.160 --> 00:50:01.500
what you're supposed to
believe, or a rock curve

00:50:01.500 --> 00:50:04.290
that literally just looks
like every other rock curve.

00:50:04.290 --> 00:50:06.330
Sorry if anyone uses them a lot.

00:50:06.330 --> 00:50:10.630
So using the KDE was
a way, I think, for--

00:50:10.630 --> 00:50:13.000
particularly for my
colleague, Dr. [INAUDIBLE],,

00:50:13.000 --> 00:50:15.120
to actually make it
a little bit more

00:50:15.120 --> 00:50:18.714
tactile and show
some sort of 3D-ness,

00:50:18.714 --> 00:50:20.880
even though that's not
necessarily real, rather than

00:50:20.880 --> 00:50:21.720
just individual points.

00:50:21.720 --> 00:50:22.770
But the points are there.

00:50:22.770 --> 00:50:26.346
They're not sort of
hidden or anything.

00:50:26.346 --> 00:50:27.762
- Thank you.

00:50:27.762 --> 00:50:29.650
- One more question for
Renee, and then we'll

00:50:29.650 --> 00:50:31.066
bring everybody back together.

00:50:31.066 --> 00:50:32.482
So, go ahead.

00:50:32.482 --> 00:50:33.920
- A simple question.

00:50:33.920 --> 00:50:37.770
When the James Webb
eventually gets launched--

00:50:37.770 --> 00:50:39.540
when the James Webb
telescope eventually

00:50:39.540 --> 00:50:42.280
gets launched in two or three
years, something like that,

00:50:42.280 --> 00:50:43.870
is that going to--

00:50:43.870 --> 00:50:46.410
I mean, that's looking
at longer wavelengths.

00:50:46.410 --> 00:50:49.270
Is it going to produce
a lot of new information

00:50:49.270 --> 00:50:52.200
on these kind of events
that you're talking about?

00:50:52.200 --> 00:50:57.330
- So one of the interesting
things about longer wavelengths

00:50:57.330 --> 00:51:00.565
is that of course these
objects, supernovae,

00:51:00.565 --> 00:51:02.940
behave differently-- different
kinds of supernovae behave

00:51:02.940 --> 00:51:05.500
differently as a
function of wavelength.

00:51:05.500 --> 00:51:07.950
And so one of the cool
things about some supernovae

00:51:07.950 --> 00:51:09.420
is they have another bump.

00:51:09.420 --> 00:51:11.850
They rise again in brightness
in the infrared, which

00:51:11.850 --> 00:51:15.144
is very useful and
very interesting.

00:51:15.144 --> 00:51:18.032
James Webb will go
very deep and will

00:51:18.032 --> 00:51:19.740
be able to give us
incredible resolution.

00:51:19.740 --> 00:51:21.323
So this will definitely
supplement us.

00:51:21.323 --> 00:51:24.780
But in the supernova community,
because we're really looking,

00:51:24.780 --> 00:51:28.440
you know, wide areas of
the sky, it's actually

00:51:28.440 --> 00:51:31.740
one of our biggest problems
is finding other surveys

00:51:31.740 --> 00:51:35.290
that can really match the area
that we're going to survey.

00:51:35.290 --> 00:51:37.030
And as far as I know,
James Webb will not

00:51:37.030 --> 00:51:38.640
tell do a significantly
better job

00:51:38.640 --> 00:51:41.067
at actually overlapping
with us, although we're

00:51:41.067 --> 00:51:43.192
going to bring all the data
that we can to overlap.

00:51:43.192 --> 00:51:44.650
- But there is an
interesting point

00:51:44.650 --> 00:51:47.060
in our community in
general that there

00:51:47.060 --> 00:51:51.060
is this emphasis on both
very targeted, very narrow

00:51:51.060 --> 00:51:53.020
observations like James
Webb can do, and then

00:51:53.020 --> 00:51:54.730
these huge surveys.

00:51:54.730 --> 00:51:56.700
So a lot of times,
people think data science

00:51:56.700 --> 00:52:00.250
is about huge data sets, and
just only hugeness of it.

00:52:00.250 --> 00:52:02.039
But there's also
this kind of how

00:52:02.039 --> 00:52:04.080
do you optimally combine
different kinds of data,

00:52:04.080 --> 00:52:07.650
which I think goes across
all of our fields here.

00:52:07.650 --> 00:52:09.940
So why don't we sit down
and talk about that.

00:52:09.940 --> 00:52:12.204
But anyway, thank
you again, Renee.

00:52:12.204 --> 00:52:15.613
[APPLAUSE]

00:52:16.590 --> 00:52:19.070
So we're going to do this
for about 15 minutes.

00:52:19.070 --> 00:52:21.896
We'll have everybody come
sit in the front here.

00:52:21.896 --> 00:52:24.960
And then we'll have
our little party.

00:52:24.960 --> 00:52:26.490
Although this is
like a party here.

00:52:28.771 --> 00:52:30.229
So I have a couple
questions to get

00:52:30.229 --> 00:52:32.600
it started, which we'll
start with the one

00:52:32.600 --> 00:52:34.510
that I just almost ask.

00:52:34.510 --> 00:52:36.560
But then please, we'll
just go to the audience,

00:52:36.560 --> 00:52:39.134
because I can ask
the questions later.

00:52:39.134 --> 00:52:40.800
You don't have to
hear that conversation

00:52:40.800 --> 00:52:42.240
if you don't want to.

00:52:42.240 --> 00:52:44.180
So but this question
that I just asked

00:52:44.180 --> 00:52:47.930
about this challenge
of combining

00:52:47.930 --> 00:52:50.100
a lot of different,
diverse data sets,

00:52:50.100 --> 00:52:54.620
and a lot of different sizes
of data sets and types of data,

00:52:54.620 --> 00:52:57.570
and then I think that there's
this kind of public perception

00:52:57.570 --> 00:53:00.560
that the macho data
science, or good data

00:53:00.560 --> 00:53:04.460
science is just about the
gigantic, enormous data sets.

00:53:04.460 --> 00:53:06.320
And so you don't
all have to answer,

00:53:06.320 --> 00:53:09.530
but if anybody has thoughts
on that particular,

00:53:09.530 --> 00:53:11.930
you know, the perception
both within the data science

00:53:11.930 --> 00:53:14.840
community and in the broader
public, where they don't

00:53:14.840 --> 00:53:17.330
understand that diversity of
data, different kinds of data

00:53:17.330 --> 00:53:19.069
is so important.

00:53:19.069 --> 00:53:21.110
- I mean, one of the things
we're doing with LSST

00:53:21.110 --> 00:53:23.200
is actually figuring out--

00:53:23.200 --> 00:53:27.220
we know that LSST
only takes images,

00:53:27.220 --> 00:53:30.940
so it can't take a very
fine spectrum of energy

00:53:30.940 --> 00:53:33.070
as a function of
wavelength of the objects.

00:53:33.070 --> 00:53:35.410
And there's some benefits
to taking a kind of spectrum

00:53:35.410 --> 00:53:37.243
like that, where you
learn a lot of the very

00:53:37.243 --> 00:53:39.154
fine physics of the explosions.

00:53:39.154 --> 00:53:40.570
And so we are
trying to figure out

00:53:40.570 --> 00:53:45.491
what surveys can give that to
us, and how to design that.

00:53:45.491 --> 00:53:47.740
But I think one of the things
that is a real challenge

00:53:47.740 --> 00:53:49.410
is, if we throw a
huge bunch of data--

00:53:49.410 --> 00:53:52.097
kind of to the point of
inference versus prediction

00:53:52.097 --> 00:53:54.430
that Nathan brought up, if
we just throw a bunch of data

00:53:54.430 --> 00:53:56.620
at a machine learning
algorithm that we don't really

00:53:56.620 --> 00:53:59.244
understand, and we get an answer
that is predictive but doesn't

00:53:59.244 --> 00:54:01.079
tell us about the
physics, I'm much less

00:54:01.079 --> 00:54:02.620
interested in that,
because that just

00:54:02.620 --> 00:54:05.260
means I found a cool new
object that I don't understand.

00:54:05.260 --> 00:54:07.030
But I really want
to know, you know,

00:54:07.030 --> 00:54:09.196
is there something weird
in the explosion mechanism,

00:54:09.196 --> 00:54:12.350
or is the dark energy
changing with space or time?

00:54:12.350 --> 00:54:16.270
And so we need to do much more
targeted small surveys, as well

00:54:16.270 --> 00:54:18.418
as the big ones, I think.

00:54:18.418 --> 00:54:19.840
- I think so.

00:54:19.840 --> 00:54:22.120
- One of the ways that we
think about this [INAUDIBLE]

00:54:22.120 --> 00:54:24.220
and the way that we've
actually structured our group,

00:54:24.220 --> 00:54:25.720
our analytics division
here in Boston--

00:54:25.720 --> 00:54:27.303
and I think you see
this more and more

00:54:27.303 --> 00:54:29.920
in sort of data-oriented
groups and industry--

00:54:29.920 --> 00:54:32.720
is that we actually have
a separation in the teams

00:54:32.720 --> 00:54:35.350
and types of people we hire
for between the data science

00:54:35.350 --> 00:54:38.290
skill set that I sort spoke
about and represent here today

00:54:38.290 --> 00:54:40.980
and the software development
and data engineering skill

00:54:40.980 --> 00:54:41.976
set and perspective.

00:54:41.976 --> 00:54:44.350
And it's really useful for us
to have that specialization

00:54:44.350 --> 00:54:46.150
because it means
people with an interest

00:54:46.150 --> 00:54:49.090
like mine, who are really
interested in developing

00:54:49.090 --> 00:54:52.580
models and understanding
and modeling systems,

00:54:52.580 --> 00:54:54.279
can focus on that,
and we can benefit

00:54:54.279 --> 00:54:56.320
from the incredible skill
set that our colleagues

00:54:56.320 --> 00:54:58.736
on the software development
side and data engineering side

00:54:58.736 --> 00:55:01.385
have to be able to assemble and
wrangle and help us to combine

00:55:01.385 --> 00:55:02.260
together [INAUDIBLE].

00:55:02.260 --> 00:55:04.360
- I'm really glad that you
brought up the specialization

00:55:04.360 --> 00:55:06.790
because my most pressing
question-- is David still here?

00:55:06.790 --> 00:55:09.850
Yeah, David Parks, who's one
of the co-directors of the new

00:55:09.850 --> 00:55:12.294
Data Science
Institute at Harvard--

00:55:12.294 --> 00:55:13.960
Dave, wave, so people
will know and they

00:55:13.960 --> 00:55:15.732
can talk to you afterwards--

00:55:15.732 --> 00:55:17.440
David was present at
a conversation where

00:55:17.440 --> 00:55:20.080
I won't name the other people
involved because it's important

00:55:20.080 --> 00:55:22.507
not to, but the conversation
was about science

00:55:22.507 --> 00:55:25.090
and the future of science, and
whether or not knowing anything

00:55:25.090 --> 00:55:29.620
about actual science, like
principles in science, matters,

00:55:29.620 --> 00:55:33.250
or whether you could have
this version of science that

00:55:33.250 --> 00:55:35.200
was put forward on the
cover of Wired magazine

00:55:35.200 --> 00:55:38.110
a decade ago where people
were like "the end of theory."

00:55:38.110 --> 00:55:40.504
there was a big X on the
cover of the magazine.

00:55:40.504 --> 00:55:41.920
And the idea was
that, if you have

00:55:41.920 --> 00:55:43.930
enough statistics
and enough data,

00:55:43.930 --> 00:55:45.550
that you can just
infer everything,

00:55:45.550 --> 00:55:47.383
and that you don't have
to understand things

00:55:47.383 --> 00:55:48.732
like, I don't know, gravity.

00:55:48.732 --> 00:55:50.440
And so you can tell
from my tone of voice

00:55:50.440 --> 00:55:53.890
that I don't really subscribe
to this point of view,

00:55:53.890 --> 00:55:56.120
but on the other hand, you
noticed in Nathan's talk--

00:55:56.120 --> 00:55:57.310
and I want to ask the
other speakers, too,

00:55:57.310 --> 00:55:59.830
but in Nathan's talk, you
were talking about things that

00:55:59.830 --> 00:56:01.480
had very human terminology.

00:56:01.480 --> 00:56:05.260
You know, do they like
robots or, you know,

00:56:05.260 --> 00:56:08.540
do they go to the movies
after dinner or before dinner,

00:56:08.540 --> 00:56:12.649
and these human concepts of
dinner and robots and all that.

00:56:12.649 --> 00:56:15.190
For those of you who don't know
very much about data science,

00:56:15.190 --> 00:56:17.600
a lot of it is about
feature vectors.

00:56:17.600 --> 00:56:19.990
And so some of like
what Renee was just

00:56:19.990 --> 00:56:23.719
showing in these t-SNE
plots are very abstract.

00:56:23.719 --> 00:56:26.010
You know, they're not a
physical property of something,

00:56:26.010 --> 00:56:29.140
they're something that shows
up again, again repeatedly

00:56:29.140 --> 00:56:32.450
statistically, and not even
the experts know what they are.

00:56:32.450 --> 00:56:34.270
And so there's this
tension between, like,

00:56:34.270 --> 00:56:36.190
human interpretable
things that you

00:56:36.190 --> 00:56:38.440
can measure, like what you
were talking about, Nathan,

00:56:38.440 --> 00:56:39.580
and then not.

00:56:39.580 --> 00:56:43.090
And I'm just curious what,
in your various fields,

00:56:43.090 --> 00:56:43.870
you think about--

00:56:43.870 --> 00:56:45.250
I mean, you talked about
humans in the loop,

00:56:45.250 --> 00:56:47.374
but I'm talking about
something slightly different,

00:56:47.374 --> 00:56:49.870
which is like human
interpretable features,

00:56:49.870 --> 00:56:50.927
shall we call them.

00:56:50.927 --> 00:56:53.510
- Yeah, I think there really is
a sort of division in the data

00:56:53.510 --> 00:56:54.820
science community
between people who

00:56:54.820 --> 00:56:56.140
do have a scientific
background and are

00:56:56.140 --> 00:56:58.479
interested in learning from
data, interested in making--

00:56:58.479 --> 00:57:00.145
- That's maybe the
inference part, yeah.

00:57:00.145 --> 00:57:01.660
- --exactly right,
interested in inference,

00:57:01.660 --> 00:57:03.730
interested in being able to
learn from the comparisons

00:57:03.730 --> 00:57:05.813
between models of data,
to update our own theories

00:57:05.813 --> 00:57:08.062
and our cognitive model
for how a system works,

00:57:08.062 --> 00:57:10.520
and people who just are coming
from a different background.

00:57:10.520 --> 00:57:12.370
And as I sort of alluded
to, I think the model

00:57:12.370 --> 00:57:13.786
that we have at
our company, and I

00:57:13.786 --> 00:57:16.036
think a model that's really
successful in general,

00:57:16.036 --> 00:57:17.910
is to have both those
skill sets represented,

00:57:17.910 --> 00:57:19.300
and to allow the
interaction between them,

00:57:19.300 --> 00:57:21.803
to literally have those
individuals collaborate to get

00:57:21.803 --> 00:57:22.570
to the best possible outcome.

00:57:22.570 --> 00:57:24.440
- Yeah, because there are
these sort of warring factions.

00:57:24.440 --> 00:57:26.950
But I'll turn it into a more
specific question for Jen.

00:57:26.950 --> 00:57:30.487
So you were talking about
manipulation in China, right?

00:57:30.487 --> 00:57:32.320
But a lot of us-- most
of us, I think-- live

00:57:32.320 --> 00:57:35.020
in the United States, and
we wonder about those kinds

00:57:35.020 --> 00:57:36.940
of things in the United States.

00:57:36.940 --> 00:57:40.960
You know, Facebook
manipulating our lives, things

00:57:40.960 --> 00:57:45.910
like their emotional contagion
experiments and all of that.

00:57:45.910 --> 00:57:49.720
And so if you think
about that, some

00:57:49.720 --> 00:57:53.740
of the data scientists at places
like Facebook, which I'm sure

00:57:53.740 --> 00:57:55.810
comes to mind, especially
given where you live,

00:57:55.810 --> 00:58:01.930
very often, do and don't
care about the kind of--

00:58:01.930 --> 00:58:05.177
whether they understand what
the algorithms are telling them,

00:58:05.177 --> 00:58:06.760
and what that means
about real people,

00:58:06.760 --> 00:58:07.870
rather than just
what it tells them

00:58:07.870 --> 00:58:08.815
about improving the algorithm.

00:58:08.815 --> 00:58:10.810
And so what's your
opinion-- like, if you

00:58:10.810 --> 00:58:12.790
were going to apply
what you were doing,

00:58:12.790 --> 00:58:16.610
and you were going to try
to have a sort of social,

00:58:16.610 --> 00:58:18.380
emotional,
psychological, whatever,

00:58:18.380 --> 00:58:22.536
but in a kind of human
language way, what would

00:58:22.536 --> 00:58:24.660
you do that would change
anything about what you're

00:58:24.660 --> 00:58:26.010
doing, and what do you
think that has to do

00:58:26.010 --> 00:58:26.940
with what's going on in the US?

00:58:26.940 --> 00:58:28.357
That's like five
questions in one.

00:58:28.357 --> 00:58:29.523
- That's a lot of questions.

00:58:29.523 --> 00:58:30.390
- Pick any of them.

00:58:30.390 --> 00:58:33.032
- Actually, so picking
up on this point,

00:58:33.032 --> 00:58:34.740
I think from a social
science perspective

00:58:34.740 --> 00:58:37.639
there's a lot of
pushback against data

00:58:37.639 --> 00:58:39.930
science, computational social
science, machine learning

00:58:39.930 --> 00:58:42.450
because of the
focus on prediction

00:58:42.450 --> 00:58:43.770
versus the focus on inference.

00:58:43.770 --> 00:58:45.989
So as social scientists,
we want to do inference.

00:58:45.989 --> 00:58:47.280
We don't want to do prediction.

00:58:47.280 --> 00:58:48.795
- Which is the human
understanding side.

00:58:48.795 --> 00:58:49.140
- Exactly.

00:58:49.140 --> 00:58:49.640
- Right.

00:58:49.640 --> 00:58:52.020
- But computer scientists
and others, engineers,

00:58:52.020 --> 00:58:54.540
are coming in and
doing prediction

00:58:54.540 --> 00:58:57.810
on these human behaviors.

00:58:57.810 --> 00:59:02.190
And there's now-- so how can
those communities, instead

00:59:02.190 --> 00:59:04.005
of being at odds
with each other,

00:59:04.005 --> 00:59:05.850
kind of collaborate together.

00:59:05.850 --> 00:59:09.420
And I think where it happens,
at least in the areas I'm in,

00:59:09.420 --> 00:59:11.520
is in causal inference.

00:59:11.520 --> 00:59:14.600
So we want to know what causes
certain types of behavior

00:59:14.600 --> 00:59:16.500
at individual, societal levels.

00:59:16.500 --> 00:59:20.010
So are there ways of using more
of these predictive tools that

00:59:20.010 --> 00:59:22.071
do more individual-level
causal inference.

00:59:22.071 --> 00:59:22.570
- Yeah.

00:59:22.570 --> 00:59:23.140
And I'm also curious--

00:59:23.140 --> 00:59:25.140
I'll ask one last question
and I'll turn it over

00:59:25.140 --> 00:59:26.730
to the audience,
but just for Saki,

00:59:26.730 --> 00:59:31.230
I had the pleasure at one
point of meeting Ban Ki-moon

00:59:31.230 --> 00:59:35.700
during the Ebola epidemic,
and I was interested then

00:59:35.700 --> 00:59:37.240
in spatial epidemiology, too.

00:59:37.240 --> 00:59:41.700
And he told me that the reason
that apparently the predictions

00:59:41.700 --> 00:59:43.950
about the epidemic and the
spread of the epidemic were

00:59:43.950 --> 00:59:46.850
mostly too pessimistic-- at
least that's what he told me--

00:59:46.850 --> 00:59:49.860
and he said that the reason
was because the models

00:59:49.860 --> 00:59:53.250
of human behavior and how
well they would cooperate

00:59:53.250 --> 00:59:56.610
with health officials and
with instructives were wrong,

00:59:56.610 --> 00:59:59.070
and that people were more
cooperative than they

00:59:59.070 --> 00:59:59.920
should be.

00:59:59.920 --> 01:00:03.240
And so how much of that
kind of human factor stuff

01:00:03.240 --> 01:00:04.440
comes into what you do?

01:00:04.440 --> 01:00:06.280
And how good are we
at modeling that?

01:00:06.280 --> 01:00:06.780
- Yeah.

01:00:06.780 --> 01:00:09.000
So I guess in terms
of just simple

01:00:09.000 --> 01:00:10.890
epidemiological
mechanistic models,

01:00:10.890 --> 01:00:14.370
we don't usually incorporate
the human behavior element.

01:00:14.370 --> 01:00:16.170
But there are social
scientists and people

01:00:16.170 --> 01:00:19.620
that we work with who
incorporate rational behaviors

01:00:19.620 --> 01:00:21.130
into the epidemic process.

01:00:21.130 --> 01:00:23.190
So basically, if you see
a lot of other people

01:00:23.190 --> 01:00:25.530
who are infected, you're
more likely to, you know,

01:00:25.530 --> 01:00:28.260
stay away from them or
quarantine yourself.

01:00:28.260 --> 01:00:30.360
So there are-- and that's
kind of-- it's called

01:00:30.360 --> 01:00:31.530
a rational epidemic.

01:00:31.530 --> 01:00:34.380
And that's something that
I'm very interested in just

01:00:34.380 --> 01:00:38.190
because like, yeah, there's a
bunch of cool new data coming

01:00:38.190 --> 01:00:40.170
out from, like, social
media, people using,

01:00:40.170 --> 01:00:42.835
like, Twitter data to look
at how behaviors spread

01:00:42.835 --> 01:00:43.850
on a network, right?

01:00:43.850 --> 01:00:45.480
And so like,
specifically in my field,

01:00:45.480 --> 01:00:49.780
it's like vaccine refusal or
human behaviors about health.

01:00:49.780 --> 01:00:52.330
They also spread on a
network, just like diseases

01:00:52.330 --> 01:00:53.220
spread on a network.

01:00:53.220 --> 01:00:54.455
So yeah, there are--

01:00:54.455 --> 01:00:55.080
- Good to hear.

01:00:55.080 --> 01:00:56.520
- --a lot of links to the
social sciences, I think.

01:00:56.520 --> 01:00:57.020
- OK.

01:00:57.020 --> 01:00:58.650
Now I will fulfill my promise.

01:00:58.650 --> 01:00:59.685
Go ahead.

01:00:59.685 --> 01:01:01.560
- I actually also had
a question a little bit

01:01:01.560 --> 01:01:03.870
about the interpretability,
and probably

01:01:03.870 --> 01:01:05.640
mostly about the
inference domain,

01:01:05.640 --> 01:01:09.330
but so with the explosion
in data science,

01:01:09.330 --> 01:01:13.770
there's obviously a lot
more budding data scientists

01:01:13.770 --> 01:01:16.530
I think than there are
people willing to undergo

01:01:16.530 --> 01:01:19.730
like this strong quantitative
type of training,

01:01:19.730 --> 01:01:23.640
let's say a PhD in statistics
or a related field, right?

01:01:23.640 --> 01:01:30.360
So I was wondering if you guys
had any idea maybe for how to I

01:01:30.360 --> 01:01:33.715
guess mitigate any
potential deficit of people

01:01:33.715 --> 01:01:35.590
highly trained in these
quantitative methods?

01:01:35.590 --> 01:01:39.742
Because I feel that there
are sort of problems

01:01:39.742 --> 01:01:40.700
that it creates, right?

01:01:40.700 --> 01:01:42.540
On the one hand, you
have a lot of people

01:01:42.540 --> 01:01:44.850
who are super willing to
solve real-world problems

01:01:44.850 --> 01:01:46.920
with big data science, right?

01:01:46.920 --> 01:01:48.750
And you need to catch
them up to speed.

01:01:48.750 --> 01:01:51.750
But on the other hand, you don't
want to make any, you know,

01:01:51.750 --> 01:01:54.030
incorrect, haphazard inferences.

01:01:56.292 --> 01:01:58.500
- So the question is what
happens when people get too

01:01:58.500 --> 01:01:59.940
gung-ho about data science?

01:01:59.940 --> 01:02:00.730
- Exactly.

01:02:00.730 --> 01:02:01.230
- OK.

01:02:01.230 --> 01:02:03.360
- What do we do
to mitigate that?

01:02:03.360 --> 01:02:04.380
- OK.

01:02:04.380 --> 01:02:06.020
- Well, we definitely see
this from an employer side.

01:02:06.020 --> 01:02:07.380
So we'll sometimes go
to recruitment events

01:02:07.380 --> 01:02:09.750
for data scientists where
the recruiters far outnumber

01:02:09.750 --> 01:02:11.010
the candidates in the room.

01:02:11.010 --> 01:02:14.460
That's how much demand there is
for this skill set right now.

01:02:14.460 --> 01:02:15.990
And for me, the
solution to this is

01:02:15.990 --> 01:02:20.166
creating pathways for
young scientists and people

01:02:20.166 --> 01:02:21.540
early in their
careers in general

01:02:21.540 --> 01:02:23.699
to have exposure to
date science practices

01:02:23.699 --> 01:02:25.240
so that they can
learn whether or not

01:02:25.240 --> 01:02:26.270
it's a good fit
for them, something

01:02:26.270 --> 01:02:28.540
they're interested in,
and develop the skill set.

01:02:28.540 --> 01:02:31.509
So I think there's a couple ways
that I think about doing this.

01:02:31.509 --> 01:02:33.300
One I bet everyone in
this room is familiar

01:02:33.300 --> 01:02:35.767
with is the idea of having
open competitions online,

01:02:35.767 --> 01:02:37.350
like the ones that
Renee talked about,

01:02:37.350 --> 01:02:40.200
which I've seen just be a
gateway into data science

01:02:40.200 --> 01:02:42.810
for so many people, and I
think are incredibly valuable.

01:02:42.810 --> 01:02:44.550
From a more formal
perspective, I

01:02:44.550 --> 01:02:48.420
think part of the thing that
sort of academia needs to do

01:02:48.420 --> 01:02:50.850
is create pathways for
students to get experience

01:02:50.850 --> 01:02:53.724
practicing data science in an
applied setting in industry.

01:02:53.724 --> 01:02:55.140
And of course, in
a lot of fields,

01:02:55.140 --> 01:02:56.610
this is standard
practice already.

01:02:56.610 --> 01:02:58.280
In statistics and
engineering, it's

01:02:58.280 --> 01:03:00.330
very common, especially
for graduate students,

01:03:00.330 --> 01:03:01.380
to do internships.

01:03:01.380 --> 01:03:02.880
But in some other
fields-- actually,

01:03:02.880 --> 01:03:05.340
in astronomy and physics
and in other domains--

01:03:05.340 --> 01:03:08.500
that's very unusual, and
frankly often frowned upon.

01:03:08.500 --> 01:03:12.841
And I think that's actually
anti-productive for science

01:03:12.841 --> 01:03:14.590
as an enterprise to
develop this skill set

01:03:14.590 --> 01:03:16.089
and be able to take
advantage of it,

01:03:16.089 --> 01:03:18.655
and certainly for society
at large and for employers

01:03:18.655 --> 01:03:21.030
to have candidates who are
experienced and really skilled

01:03:21.030 --> 01:03:24.450
and know that they're
interested in that topic.

01:03:24.450 --> 01:03:28.290
- So this is, I think, a really
important thing to discuss,

01:03:28.290 --> 01:03:33.030
I think because, particularly
in astronomy, which is already

01:03:33.030 --> 01:03:37.080
open to large data, already
has people doing data science,

01:03:37.080 --> 01:03:42.605
potentially in another name,
but there is this perception

01:03:42.605 --> 01:03:44.480
that, first of all, if
you introduce students

01:03:44.480 --> 01:03:47.120
to data science in astronomy,
they will leave, right?

01:03:47.120 --> 01:03:49.590
So there's this fear like you
don't put your best students

01:03:49.590 --> 01:03:50.810
to work on anything
data science,

01:03:50.810 --> 01:03:51.770
because they will leave.

01:03:51.770 --> 01:03:53.950
- She meant leave astronomy,
not leave data science,

01:03:53.950 --> 01:03:54.658
just to be clear.

01:03:54.658 --> 01:03:57.535
- Yeah, sorry, leave
astronomy for data science.

01:03:57.535 --> 01:03:58.910
And sometimes, I
think colleagues

01:03:58.910 --> 01:04:01.016
can be scared of that.

01:04:01.016 --> 01:04:02.390
But then the other
bias sometimes

01:04:02.390 --> 01:04:05.840
that I hear from my
more senior colleagues

01:04:05.840 --> 01:04:08.000
is that, exactly to
what you alluded to,

01:04:08.000 --> 01:04:08.960
are we teaching them--

01:04:08.960 --> 01:04:10.626
I mean, someone said
to me once, are you

01:04:10.626 --> 01:04:11.900
doing physics or statistics?

01:04:11.900 --> 01:04:13.840
And I was like, both.

01:04:13.840 --> 01:04:17.150
But I think,
particularly in my field,

01:04:17.150 --> 01:04:20.510
we've always really needed to do
surveys in cosmology because we

01:04:20.510 --> 01:04:22.820
have to understand
things, you know,

01:04:22.820 --> 01:04:24.810
on a population level
of the universe,

01:04:24.810 --> 01:04:25.768
rather than individual.

01:04:25.768 --> 01:04:27.740
But some other
groups I think have--

01:04:27.740 --> 01:04:30.300
you could only study your
kind of object or your star

01:04:30.300 --> 01:04:31.610
or your region in the universe.

01:04:31.610 --> 01:04:33.700
And so there's a
paradigm shift that

01:04:33.700 --> 01:04:37.800
has to happen as people
realize that you can do both.

01:04:37.800 --> 01:04:41.390
You can get the answers that you
need astronomically and excite

01:04:41.390 --> 01:04:43.904
people, as you said,
with real-world problems.

01:04:43.904 --> 01:04:45.320
And then if they
leave, fantastic,

01:04:45.320 --> 01:04:47.450
and if they don't, fantastic.

01:04:47.450 --> 01:04:49.460
But often, I find myself
having discussions

01:04:49.460 --> 01:04:52.910
with colleagues about
sort of whether or not

01:04:52.910 --> 01:04:56.685
we should be allowing people
to call it science or astronomy

01:04:56.685 --> 01:04:59.060
if they're doing something
that is effectively statistics

01:04:59.060 --> 01:05:01.059
and data science and
computer engineering, which

01:05:01.059 --> 01:05:03.680
to me is just a moot point.

01:05:03.680 --> 01:05:05.160
- I think it's a non--

01:05:05.160 --> 01:05:07.560
it's a question that
hasn't been answered.

01:05:07.560 --> 01:05:09.410
In social sciences,
the expectation

01:05:09.410 --> 01:05:12.260
is that if you're wanting
a PhD in, let's say,

01:05:12.260 --> 01:05:16.370
political science, you
need a master's in CS

01:05:16.370 --> 01:05:20.070
or computer science
or statistics.

01:05:20.070 --> 01:05:22.025
That's increasingly the norm.

01:05:24.570 --> 01:05:27.510
Or you're spending many
years, or two or three

01:05:27.510 --> 01:05:29.160
years when you're a
PhD, just training

01:05:29.160 --> 01:05:30.301
on the technical skills.

01:05:30.301 --> 01:05:31.800
And then you don't
have that theory.

01:05:31.800 --> 01:05:34.800
So it's an issue
that is not resolved.

01:05:34.800 --> 01:05:38.300
Some have proposed can we
work just across disciplines,

01:05:38.300 --> 01:05:40.620
but that collaboration
is very difficult

01:05:40.620 --> 01:05:43.140
unless both
collaborators actually

01:05:43.140 --> 01:05:46.790
know something about where
the other is coming from.

01:05:46.790 --> 01:05:50.050
So I don't know that we have
an existing kind of answer

01:05:50.050 --> 01:05:55.050
to how exactly we change this in
academia in terms of training,

01:05:55.050 --> 01:05:57.270
given the time constraints.

01:05:57.270 --> 01:05:58.980
- And as the
student perspective,

01:05:58.980 --> 01:06:01.380
I think the internet
has made it really easy

01:06:01.380 --> 01:06:03.221
to try to learn new
skills in terms of like,

01:06:03.221 --> 01:06:05.220
you know, people putting
their code up on GitHub

01:06:05.220 --> 01:06:08.475
in a public way so we can just
go through and, like, you know,

01:06:08.475 --> 01:06:10.350
it's commented, and we
can see what they did.

01:06:10.350 --> 01:06:12.204
And I think that like,
yeah, the internet

01:06:12.204 --> 01:06:13.370
has really made it so that--

01:06:13.370 --> 01:06:14.190
- Yeah, I'm so glad.

01:06:14.190 --> 01:06:15.450
- --we can try to figure
it out on our own,

01:06:15.450 --> 01:06:17.700
we don't necessarily have
to take a course on it.

01:06:17.700 --> 01:06:20.360
Like, I don't-- at Princeton,
I don't think we, like--

01:06:20.360 --> 01:06:22.080
yeah, we don't take
courses in our PhD,

01:06:22.080 --> 01:06:23.860
but there aren't,
like, data science

01:06:23.860 --> 01:06:27.240
for biology courses yet.

01:06:27.240 --> 01:06:30.360
But I think that, yeah,
informally, like, online,

01:06:30.360 --> 01:06:33.030
we've been able to, like,
pick up a lot of that.

01:06:33.030 --> 01:06:34.817
- David, you have a question?

01:06:34.817 --> 01:06:36.400
- We need the
microphone [INAUDIBLE]..

01:06:36.400 --> 01:06:38.820
- It's right behind you.

01:06:38.820 --> 01:06:41.500
- So if I could just also
make a comment first,

01:06:41.500 --> 01:06:45.080
which is that we're launching
a new master's of data science

01:06:45.080 --> 01:06:46.320
here within the FAS.

01:06:46.320 --> 01:06:49.500
And kind of on this
note about, you know,

01:06:49.500 --> 01:06:53.460
the supply and demand,
we got 1,300 applications

01:06:53.460 --> 01:06:55.410
and we made 70 offers.

01:06:55.410 --> 01:06:59.310
So there's a huge number
of students out there

01:06:59.310 --> 01:07:02.940
in the world that are looking to
do a data science master's, and

01:07:02.940 --> 01:07:05.200
clearly programs like
Harvard are, you know,

01:07:05.200 --> 01:07:07.625
not going to be able
to supply all of that.

01:07:07.625 --> 01:07:09.750
So we do need to really
think carefully about this.

01:07:09.750 --> 01:07:13.500
And this is a very
integrated program.

01:07:13.500 --> 01:07:17.490
My question was, you
know, a lot of us

01:07:17.490 --> 01:07:20.550
are seeing this revolution
happening right now

01:07:20.550 --> 01:07:24.870
with the black box kind
of end-to-end models.

01:07:24.870 --> 01:07:27.520
A number of you mentioned
convolutional neural nets,

01:07:27.520 --> 01:07:31.320
but also many of you,
and especially Nathan,

01:07:31.320 --> 01:07:35.610
talked actually about
very detailed models

01:07:35.610 --> 01:07:38.700
that clearly have been
crafted extremely carefully

01:07:38.700 --> 01:07:43.890
by people with high
expertise in the domain.

01:07:43.890 --> 01:07:47.320
And I just wanted to invite
you to talk about that.

01:07:47.320 --> 01:07:51.360
I'm curious about, in
your case, you know,

01:07:51.360 --> 01:07:53.280
how many years of
effort have gone

01:07:53.280 --> 01:07:57.210
into getting your
team to the place

01:07:57.210 --> 01:08:01.110
where you're able to craft
those models that can really

01:08:01.110 --> 01:08:02.640
provide insight?

01:08:02.640 --> 01:08:05.370
And invite others on the panel
to talk to that, as well.

01:08:07.956 --> 01:08:10.230
- Yeah, maybe I can give
the first response, which

01:08:10.230 --> 01:08:13.710
is that I think it's
incredibly important for those

01:08:13.710 --> 01:08:16.439
on my team at Legendary to
build that domain expertise.

01:08:16.439 --> 01:08:18.420
If we really want
to be in a position

01:08:18.420 --> 01:08:20.754
to create a positive impact
for the rest of the company,

01:08:20.754 --> 01:08:23.294
and particularly to be able to
collaborate and really support

01:08:23.294 --> 01:08:25.180
effectively the creative
side of our company,

01:08:25.180 --> 01:08:26.279
it's our responsibility.

01:08:26.279 --> 01:08:28.804
It's incumbent on us to
build that domain expertise

01:08:28.804 --> 01:08:30.720
to be able to, again,
to interpret our models,

01:08:30.720 --> 01:08:33.819
to understand what consequences
the comparisons between model

01:08:33.819 --> 01:08:35.994
and data that we're making
have for decision-making

01:08:35.994 --> 01:08:38.410
in the company, and to be able
to communicate back to them

01:08:38.410 --> 01:08:43.109
in terms that are going to be
understandable and actionable,

01:08:43.109 --> 01:08:46.270
how our inferences should
change their decision-making.

01:08:46.270 --> 01:08:48.450
So that absolutely is a
challenge and a process

01:08:48.450 --> 01:08:52.140
that we've had to go through
over a period of about

01:08:52.140 --> 01:08:53.819
four years now to do that.

01:08:53.819 --> 01:08:55.660
And I think we're still
learning every day.

01:08:55.660 --> 01:08:57.660
And it's a fantastic
opportunity for those of us

01:08:57.660 --> 01:08:59.826
who are at Legendary to be
able to interact directly

01:08:59.826 --> 01:09:01.910
with incredibly skilled,
talented, and experienced

01:09:01.910 --> 01:09:04.326
creative people in our company,
for us to be able to build

01:09:04.326 --> 01:09:05.310
that domain expertise.

01:09:05.310 --> 01:09:07.290
And it's a pleasure to be able
to have that collaboration.

01:09:07.290 --> 01:09:09.290
- And we have some
[? lunch ?] [? and ?] coffee,

01:09:09.290 --> 01:09:12.359
but just to clarify for David,
is it right that you started

01:09:12.359 --> 01:09:14.760
that group at Legendary, and
that that four years is how

01:09:14.760 --> 01:09:16.439
long you've been doing this?

01:09:16.439 --> 01:09:18.060
- So I was one of the first
people to join the group.

01:09:18.060 --> 01:09:19.140
It was started by
Matt [INAUDIBLE],,

01:09:19.140 --> 01:09:20.609
who's our chief
analytics officer,

01:09:20.609 --> 01:09:22.091
who came from a sports domain.

01:09:22.091 --> 01:09:22.590
- OK.

01:09:22.590 --> 01:09:22.740
- [INAUDIBLE].

01:09:22.740 --> 01:09:25.449
- But then it was you and him,
and now it's how many people?

01:09:25.449 --> 01:09:27.990
- So now we have about 70 people
across our applied analytics

01:09:27.990 --> 01:09:28.810
division.

01:09:28.810 --> 01:09:29.520
- In four years?

01:09:29.520 --> 01:09:30.399
- Right.

01:09:30.399 --> 01:09:32.620
- There's your answer, David.

01:09:32.620 --> 01:09:35.370
OK, so what I'm
going to do now is

01:09:35.370 --> 01:09:38.120
I'm going to suggest that
we thank all the speakers.

01:09:38.120 --> 01:09:41.170
[APPLAUSE]

