WEBVTT
Kind: captions
Language: en

00:00:00.140 --> 00:00:01.930
Okay Michael so this wraps up all this

00:00:01.930 --> 00:00:04.950
Bayesian Learning stuff. What have we learned today?

00:00:04.950 --> 00:00:06.450
&gt;&gt; We did Bayes rule.

00:00:06.450 --> 00:00:09.740
&gt;&gt; We learned Bayes rule. We even learned how to derive Bayes rule.

00:00:09.740 --> 00:00:11.710
&gt;&gt; And it was super useful because it

00:00:11.710 --> 00:00:13.920
let's you swap, kind of, causes and effect.

00:00:13.920 --> 00:00:15.880
&gt;&gt; So I like the way you put that, Michael that

00:00:15.880 --> 00:00:19.310
we're swapping causes and effects. Sort of mathematically when we think about

00:00:19.310 --> 00:00:22.170
Bayes rule, what that really let's us do is. Instead of

00:00:22.170 --> 00:00:25.480
having to compute the probably of a hypothesis given the data We

00:00:25.480 --> 00:00:27.170
instead view to compute the probability of the

00:00:27.170 --> 00:00:30.130
data given the hypothesis, which is typically a

00:00:30.130 --> 00:00:35.660
much easier thing to do. And what makes it of course Bayes rule in general is

00:00:35.660 --> 00:00:38.150
that you weight that by the prior probability

00:00:38.150 --> 00:00:40.620
over the hypothesis. Which in fact is one

00:00:40.620 --> 00:00:42.580
of the important things that we learned which

00:00:42.580 --> 00:00:45.680
is that priors matter. So anything else we learned?

00:00:45.680 --> 00:00:51.500
&gt;&gt; Yep, we did the MAP hypothesis, Maximum a posteriori. Right.

00:00:51.500 --> 00:00:54.630
We learned about HMap, and we also learned about HML.

00:00:54.630 --> 00:00:59.560
&gt;&gt; ML, right. The maximum likelihood hypothesis. &gt; Right. And what's the

00:00:59.560 --> 00:01:01.220
maximum likelihood hypothesis? How's it relate

00:01:01.220 --> 00:01:03.510
to the maximum a posteriori hypothesis?

00:01:03.510 --> 00:01:06.970
&gt;&gt; It's the MAP that you get when the prior is uniform.

00:01:06.970 --> 00:01:08.970
&gt;&gt; Right. Alright. And we, oh, we

00:01:08.970 --> 00:01:12.510
connected up maximum a posteriori and least squares.

00:01:12.510 --> 00:01:16.530
&gt;&gt; Yeah, that was pretty, I really liked that. So, we basically der, we

00:01:16.530 --> 00:01:20.010
deroved. We derived a bunch of things we'd

00:01:20.010 --> 00:01:22.330
been doing before. And short of showed that

00:01:22.330 --> 00:01:23.760
there's actually a good argument for them. At

00:01:23.760 --> 00:01:26.020
least if you're Bayesian. There are good arguments for

00:01:26.020 --> 00:01:29.120
doing some doing sum of squares. There are good

00:01:29.120 --> 00:01:32.060
arguments for Occam's Razor. We'd actually be able

00:01:32.060 --> 00:01:34.110
to give real justification for doing them other

00:01:34.110 --> 00:01:35.790
than, well sure it makes us one of them.

00:01:35.790 --> 00:01:39.170
&gt;&gt; Right so that includes the minimum description length story.

00:01:39.170 --> 00:01:40.185
&gt;&gt; Mm-hm.

00:01:40.185 --> 00:01:41.320
&gt;&gt; And then finally,

00:01:41.320 --> 00:01:45.850
you told me that was all a lie, and you said that really what you want to do

00:01:45.850 --> 00:01:48.820
is this other kind of way of picking that

00:01:48.820 --> 00:01:51.830
actually factors in the probability of all the different hypotheses

00:01:51.830 --> 00:01:55.580
and having them essentially vote. Right. What we really

00:01:55.580 --> 00:01:59.690
care about, is classification. We're learning in the end and

00:01:59.690 --> 00:02:02.300
so we also learned about Bayes classifiers. So in

00:02:02.300 --> 00:02:07.180
fact, what we described before, which is voting of hypothesis.

00:02:07.180 --> 00:02:11.260
Turns out to be the Bayes optimal classifier. I

00:02:11.260 --> 00:02:14.360
didn't say that, but it is very important to note.

00:02:14.360 --> 00:02:16.060
In fact, what you should be noting there is

00:02:16.060 --> 00:02:18.040
not only is it the Bayes optimal classifier, it's the

00:02:18.040 --> 00:02:21.780
Bayes optimal classifier. And what that means is that

00:02:21.780 --> 00:02:26.400
on average you cannot do any better than basically doing

00:02:26.400 --> 00:02:29.550
a weighted vote of all the hypotheses according to

00:02:29.550 --> 00:02:32.210
the probability of the hypothesis given the data. You cannot

00:02:32.210 --> 00:02:33.940
do any better than this on average. So

00:02:33.940 --> 00:02:36.960
again, what Bayesian learning gives us and what Bayesian

00:02:36.960 --> 00:02:39.480
classification gives us is a way of talking

00:02:39.480 --> 00:02:43.240
about optimality and gold standards. What'd you think, Michael?

00:02:43.240 --> 00:02:44.450
&gt;&gt; That's really neat.

00:02:44.450 --> 00:02:45.990
&gt;&gt; I like it. I mean, I have to tell

00:02:45.990 --> 00:02:48.830
you, I really think that this stuff is kind of cool.

00:02:48.830 --> 00:02:51.140
It's always nice to be able to take things that actually

00:02:51.140 --> 00:02:55.080
work and explain them according to some framework, some underlying theory.

00:02:55.080 --> 00:02:57.390
&gt;&gt; I wonder though, it seems like

00:02:57.390 --> 00:03:02.280
all these Bayesian equations lead us to the question, of how we actually infere

00:03:02.280 --> 00:03:06.360
probabilities from various different quantities and observations.

00:03:06.360 --> 00:03:07.780
So is there a way to do that?

00:03:07.780 --> 00:03:13.330
&gt;&gt; So I think the answer is yes. And maybe you should

00:03:13.330 --> 00:03:15.140
go figure it out and then tell me about it next time.

00:03:15.140 --> 00:03:18.550
&gt;&gt; Okay. [LAUGH] All right, as you wish.

00:03:18.550 --> 00:03:19.950
&gt;&gt; As you wish.

00:03:19.950 --> 00:03:20.910
&gt;&gt; Stay tuned.

00:03:20.910 --> 00:03:22.470
&gt;&gt; Anyway, this has been a lot of fun, Michael.

00:03:22.470 --> 00:03:23.270
I will talk to you later.

00:03:23.270 --> 00:03:23.860
&gt;&gt; Thanks.

00:03:23.860 --> 00:03:24.590
&gt;&gt; Bye.

