WEBVTT
Kind: captions
Language: en

00:00:00.080 --> 00:00:04.070
To summarize, the performance results
for Flash show the following.

00:00:04.070 --> 00:00:08.980
When the data is in cache, the basic
SPED model performs much better than

00:00:08.980 --> 00:00:13.720
the AMPED Flash,
because it doesn't require the test for

00:00:13.720 --> 00:00:17.145
memory presence,
which was necessary in the AMPED Flash.

00:00:17.145 --> 00:00:21.387
Both SPED and the AMPED Flash
are better than the multi-threaded or

00:00:21.387 --> 00:00:25.755
multi-process models, because they don't
incur any of the synchronization or

00:00:25.755 --> 00:00:29.085
context switching overheads that
are necessary with these models.

00:00:29.085 --> 00:00:33.665
When the workload is disk-bound,
however, AMPED performs much better than

00:00:33.665 --> 00:00:38.970
the single-process event-driven model,
because the single process model blocks,

00:00:38.970 --> 00:00:41.450
since there's no support for
asynchronous I/O.

00:00:41.450 --> 00:00:45.250
AMPED Flash performs better than both
the multi-threaded and the multi-process

00:00:45.250 --> 00:00:50.390
model, because it has much more
memory efficient implementation,

00:00:50.390 --> 00:00:54.380
and it doesn't require the same level of
context switching as in these models.

00:00:55.410 --> 00:01:00.330
Again, only the number of concurrent
I/O bound requests result

00:01:00.330 --> 00:01:04.680
in concurrent processes or
concurrent threads in this model.

00:01:04.680 --> 00:01:10.080
The model is not necessarily suitable
for every single type of server process.

00:01:10.080 --> 00:01:13.310
There are certain challenges
with event-driven architecture.

00:01:13.310 --> 00:01:17.990
We said, some of these can come from the
fact that we need to take advantage of

00:01:17.990 --> 00:01:23.470
multiple cores and we need to be able to
route events to the appropriate core.

00:01:23.470 --> 00:01:26.350
In other cases,
perhaps the processing itself,

00:01:26.350 --> 00:01:30.060
is not as suitable for
this type of architecture.

00:01:30.060 --> 00:01:34.230
But if you look at some of the high
performance server implementations

00:01:34.230 --> 00:01:39.470
that are in use today, you will see
that a lot of them do in fact use

00:01:39.470 --> 00:01:43.470
a event-driven model,
combined with a synchronous I/O support.

