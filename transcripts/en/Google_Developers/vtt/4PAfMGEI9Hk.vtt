WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.353
[MUSIC PLAYING]

00:00:08.596 --> 00:00:10.970
NANDINI STOCKER: If you've
been hearing a lot about voice

00:00:10.970 --> 00:00:13.430
technology, artificial
intelligence, and how

00:00:13.430 --> 00:00:15.560
it's the next big
thing, but you're not

00:00:15.560 --> 00:00:18.410
quite sure what that means for
you, you're not the only one.

00:00:18.410 --> 00:00:19.850
Whether you're a
developer trying

00:00:19.850 --> 00:00:22.160
to create a
conversational interface,

00:00:22.160 --> 00:00:24.080
a business that wants
to know what this means

00:00:24.080 --> 00:00:27.590
for the future of commerce, or
just a human being wondering

00:00:27.590 --> 00:00:30.230
why in the world we need
more robots when we're

00:00:30.230 --> 00:00:32.970
trying so hard just to
connect to each other,

00:00:32.970 --> 00:00:34.445
you've come to the right place.

00:00:34.445 --> 00:00:35.180
Hey, Sachit.

00:00:35.180 --> 00:00:35.900
How's it going?

00:00:35.900 --> 00:00:36.610
SACHIT MISRA: Not too bad.

00:00:36.610 --> 00:00:36.920
How about you?

00:00:36.920 --> 00:00:37.870
NANDINI STOCKER: I'm
so glad you're here.

00:00:37.870 --> 00:00:38.660
SACHIT MISRA: Glad to be here.

00:00:38.660 --> 00:00:39.230
NANDINI STOCKER:
Seriously though.

00:00:39.230 --> 00:00:40.920
You've been doing this
for quite a while.

00:00:40.920 --> 00:00:41.860
SACHIT MISRA: It's
definitely different.

00:00:41.860 --> 00:00:43.160
And it's fairly new.

00:00:43.160 --> 00:00:44.420
NANDINI STOCKER: I'm Nandini.

00:00:44.420 --> 00:00:46.890
And welcome to this
new video series

00:00:46.890 --> 00:00:50.120
where we'll explore all
things related to voice tech

00:00:50.120 --> 00:00:52.640
and the rich elements
of human communication

00:00:52.640 --> 00:00:54.540
that will be the
key to its success.

00:00:54.540 --> 00:00:55.710
Hey, Google.

00:00:55.710 --> 00:00:57.500
Let's talk to Number Genie.

00:00:57.500 --> 00:00:59.709
NUMBER GENIE: I'm thinking
of a number from 0 to 100.

00:00:59.709 --> 00:01:01.583
NANDINI STOCKER: We're
looking for great apps

00:01:01.583 --> 00:01:02.960
out there to
highlight how you're

00:01:02.960 --> 00:01:05.840
using these elements to
create your own conversational

00:01:05.840 --> 00:01:06.722
experience.

00:01:06.722 --> 00:01:08.930
SACHIT MISRA: What you're
building is a conversation.

00:01:08.930 --> 00:01:10.460
NANDINI STOCKER: What was the
biggest challenge for you?

00:01:10.460 --> 00:01:13.350
SACHIT MISRA: You realize
you have so many options.

00:01:13.350 --> 00:01:15.780
NANDINI STOCKER: How do you
maintain that variability?

00:01:15.780 --> 00:01:16.970
SACHIT MISRA: So there's
a lot of opportunity

00:01:16.970 --> 00:01:18.950
here, actually, for the
developer to be clever.

00:01:18.950 --> 00:01:20.950
NANDINI STOCKER: Because
cats rule the internet.

00:01:20.950 --> 00:01:21.830
SACHIT MISRA: Right.

00:01:21.830 --> 00:01:23.121
NANDINI STOCKER: So let's talk.

00:01:23.121 --> 00:01:25.550
It's kind of where we're
starting today is hello, world.

00:01:25.550 --> 00:01:26.978
[MUSIC PLAYING]

00:01:26.978 --> 00:01:34.130
[APPLAUSE]

00:01:34.130 --> 00:01:35.610
NANDINI STOCKER: I'm Nandini.

00:01:35.610 --> 00:01:40.590
And I enable conversations
between humans,

00:01:40.590 --> 00:01:44.880
among businesses, and any
combination in between, some

00:01:44.880 --> 00:01:46.395
of which include some machines.

00:01:49.170 --> 00:01:52.480
Who's excited about
this series, developers?

00:01:52.480 --> 00:01:56.400
[APPLAUSE]

00:01:56.400 --> 00:01:58.865
We just launched this
as a teaser on YouTube.

00:01:58.865 --> 00:02:00.240
But it's coming,
and you're going

00:02:00.240 --> 00:02:02.970
to hear all about that today.

00:02:02.970 --> 00:02:05.700
But I want you to stop
and take a moment.

00:02:05.700 --> 00:02:07.770
Take a picture in
your mind right now

00:02:07.770 --> 00:02:10.590
of why voice is interesting.

00:02:10.590 --> 00:02:11.370
Why is it?

00:02:11.370 --> 00:02:13.830
I wonder what you're thinking.

00:02:13.830 --> 00:02:16.080
We're living in a
time when innovation

00:02:16.080 --> 00:02:20.850
is shifting our outlook
so rapidly of our future.

00:02:20.850 --> 00:02:22.860
In fact, it's so
rapid that it's worth

00:02:22.860 --> 00:02:26.370
taking that moment to stop and
think about where you are now

00:02:26.370 --> 00:02:30.240
and how different it could be in
a week's time, a month's time.

00:02:30.240 --> 00:02:31.860
And next year, I
guarantee you will

00:02:31.860 --> 00:02:34.560
be a different landscape, a
different ecosystem than we

00:02:34.560 --> 00:02:36.240
are today.

00:02:36.240 --> 00:02:39.030
You're part of that, by the way.

00:02:39.030 --> 00:02:40.770
So why is that?

00:02:40.770 --> 00:02:43.920
Enabling machines to
speak on our behalf,

00:02:43.920 --> 00:02:50.520
to speak to us out loud,
is so deep to our context

00:02:50.520 --> 00:02:54.280
as a culture and
as human beings.

00:02:54.280 --> 00:02:56.110
It makes us question
where we are.

00:02:56.110 --> 00:03:00.090
Makes us question where
we are with technology.

00:03:00.090 --> 00:03:03.570
It really is putting us at
the intersection of technology

00:03:03.570 --> 00:03:06.090
and the human condition.

00:03:06.090 --> 00:03:08.760
More than ever
before, we're actually

00:03:08.760 --> 00:03:14.040
confronting a reckoning between
science and culture right now.

00:03:14.040 --> 00:03:16.560
So I have a lot more to
say about that topic.

00:03:16.560 --> 00:03:19.350
But today is not
the forum for that.

00:03:19.350 --> 00:03:21.900
Today we're just
starting a conversation.

00:03:21.900 --> 00:03:26.160
And the hardest part about
any conversation is listening.

00:03:26.160 --> 00:03:29.190
So we want you to know,
developers, designers,

00:03:29.190 --> 00:03:31.920
businesses, we've heard you.

00:03:31.920 --> 00:03:35.310
We've seen the feedback
from I/O and conferences

00:03:35.310 --> 00:03:38.610
like this, that the most
valuable part of the experience

00:03:38.610 --> 00:03:42.120
is interacting with Googlers
and with other developers

00:03:42.120 --> 00:03:44.970
and people creating
experiences out there.

00:03:44.970 --> 00:03:46.770
So we decided to
create a different kind

00:03:46.770 --> 00:03:51.760
of content feedback loop for
you and with this series.

00:03:51.760 --> 00:03:54.319
So in our first few
episodes, for example,

00:03:54.319 --> 00:03:56.610
we're going to start by
helping you understand just how

00:03:56.610 --> 00:03:59.610
to get your arms around the
Zero-d interface and then

00:03:59.610 --> 00:04:04.080
how you supplement that with
other elements like visuals.

00:04:04.080 --> 00:04:06.810
We'll show you what palette
you have to work with,

00:04:06.810 --> 00:04:08.820
and how to create
your landscape,

00:04:08.820 --> 00:04:14.970
how to build your world for your
users in your own unique way.

00:04:14.970 --> 00:04:17.358
So in our first season,
we just wrapped filming.

00:04:17.358 --> 00:04:18.149
It's very exciting.

00:04:18.149 --> 00:04:21.029
We're going to have six
episodes we've already filmed.

00:04:21.029 --> 00:04:24.000
We're going to have things
like greetings and goodbyes.

00:04:24.000 --> 00:04:26.160
How do you start and
end a conversation?

00:04:26.160 --> 00:04:29.280
Including, how do
you do reengagement?

00:04:29.280 --> 00:04:31.500
How do you identify users?

00:04:31.500 --> 00:04:32.790
How do you authenticate them?

00:04:32.790 --> 00:04:36.030
And how do you
make money at this?

00:04:36.030 --> 00:04:38.550
Transactions are a
big part of this.

00:04:38.550 --> 00:04:40.740
We'll also show you how
to create custom voices

00:04:40.740 --> 00:04:44.730
to brand your experience.

00:04:44.730 --> 00:04:48.540
What does it take to create
character and persona?

00:04:48.540 --> 00:04:53.230
And also, what are sounds
involved in all this?

00:04:53.230 --> 00:04:54.750
There's audio
landscaping you can

00:04:54.750 --> 00:04:57.240
create that's an
entirely new world, that

00:04:57.240 --> 00:05:00.540
will be the gateway to
things like virtual reality

00:05:00.540 --> 00:05:02.890
technology.

00:05:02.890 --> 00:05:07.080
So from there, we'll explore
timely topics and deeper

00:05:07.080 --> 00:05:11.520
concepts and feature
and highlight examples

00:05:11.520 --> 00:05:13.440
from the ecosystem.

00:05:13.440 --> 00:05:15.450
We want to showcase
what good looks like,

00:05:15.450 --> 00:05:18.180
what are you guys creating out
there, and what kinds of people

00:05:18.180 --> 00:05:20.340
it takes to make this work.

00:05:23.100 --> 00:05:24.870
And then on each
episode, we'll always

00:05:24.870 --> 00:05:29.790
feature guests that will
help us dig a little deeper.

00:05:29.790 --> 00:05:32.340
And they will be people
from the community.

00:05:32.340 --> 00:05:35.010
Sometimes they'll be Googlers.

00:05:35.010 --> 00:05:36.390
And come on up, you guys.

00:05:36.390 --> 00:05:39.890
[MUSIC PLAYING]

00:05:41.890 --> 00:05:45.710
So we're going to do a
little live show today

00:05:45.710 --> 00:05:48.380
to talk a little bit about what
this means and hopefully get

00:05:48.380 --> 00:05:50.110
a little bit of insight.

00:05:50.110 --> 00:05:52.960
And we'll actually not
answer all your questions.

00:05:52.960 --> 00:05:56.830
But we have a few questions that
I've gathered from social media

00:05:56.830 --> 00:06:00.780
and just from our advocacy work
that we've done in this space.

00:06:00.780 --> 00:06:04.540
So to start out, I want
to introduce our panel.

00:06:04.540 --> 00:06:08.750
And I'm thrilled to have
this great set of panelists

00:06:08.750 --> 00:06:12.770
here that I personally selected.

00:06:12.770 --> 00:06:16.880
Because I feel like they're
most representative of where

00:06:16.880 --> 00:06:20.390
people who have come
at this and pivoted

00:06:20.390 --> 00:06:24.470
to this field from
other areas to give us

00:06:24.470 --> 00:06:26.960
some insight into their
journey of how they got here.

00:06:26.960 --> 00:06:29.870
Because I really think that
there are a lot of experts

00:06:29.870 --> 00:06:32.120
in the field, but
actually very few

00:06:32.120 --> 00:06:34.340
that are considered experts.

00:06:34.340 --> 00:06:37.910
But there's this tapped in
muscle that you don't even

00:06:37.910 --> 00:06:40.430
realize you have, that
you can design and build

00:06:40.430 --> 00:06:41.090
for this space.

00:06:41.090 --> 00:06:42.465
And that's what
I'm hoping you'll

00:06:42.465 --> 00:06:44.360
get out of this today
and the whole series.

00:06:44.360 --> 00:06:48.080
So we'll start by-- first
we have Marc Paulina,

00:06:48.080 --> 00:06:50.480
who together with Peter
Hodgson in the audience,

00:06:50.480 --> 00:06:53.690
they've created a new rapid
prototyping technique that

00:06:53.690 --> 00:06:54.590
involves--

00:06:54.590 --> 00:06:56.990
it's a methodology for
interaction design.

00:06:56.990 --> 00:07:00.020
And in fact, to give you
an idea how we're really

00:07:00.020 --> 00:07:04.520
taking the audience and building
the series with the audience

00:07:04.520 --> 00:07:07.340
and our users in mind
and our viewers in mind,

00:07:07.340 --> 00:07:09.830
we've built this panel
also directly from feedback

00:07:09.830 --> 00:07:10.440
from you guys.

00:07:10.440 --> 00:07:13.730
So, for example, Marc just
ran a sprint with Peter

00:07:13.730 --> 00:07:16.640
with a small group
across the street

00:07:16.640 --> 00:07:18.290
with this new methodology.

00:07:18.290 --> 00:07:20.490
But it has to be done
in a small scale.

00:07:20.490 --> 00:07:21.800
So we want to scale that big.

00:07:21.800 --> 00:07:24.091
So we're going to show it on
camera so that you can all

00:07:24.091 --> 00:07:25.100
learn from it.

00:07:25.100 --> 00:07:26.780
That's an example.

00:07:26.780 --> 00:07:31.550
Another is Kimberly Harvey, who
has pivoted with deep research

00:07:31.550 --> 00:07:33.260
experience.

00:07:33.260 --> 00:07:34.670
Recently pivoted to design.

00:07:34.670 --> 00:07:36.730
She'll tell you about that.

00:07:36.730 --> 00:07:39.110
But Kimberly on the
panel is a direct request

00:07:39.110 --> 00:07:41.650
from the GDE community.

00:07:41.650 --> 00:07:44.060
Yes, Shuli.

00:07:44.060 --> 00:07:47.330
Shuli from the Tel Aviv
area, a UX research expert

00:07:47.330 --> 00:07:50.780
in children's research,
asked about having

00:07:50.780 --> 00:07:53.090
more representative
from UX research.

00:07:53.090 --> 00:07:56.480
And Kimberley offers such a
great point of view for that.

00:07:56.480 --> 00:07:57.930
So she's here.

00:07:57.930 --> 00:08:00.170
And then finally, if you
don't already know him,

00:08:00.170 --> 00:08:02.870
Sachit, he has found
the decoder ring

00:08:02.870 --> 00:08:04.940
between design and engineering.

00:08:04.940 --> 00:08:09.200
And I can credit Sachit
as fully responsible-- him

00:08:09.200 --> 00:08:11.450
and his team--
for pulling me out

00:08:11.450 --> 00:08:14.051
of my shell of where I was
working and doing more advocacy

00:08:14.051 --> 00:08:14.550
work.

00:08:14.550 --> 00:08:15.830
So thank you.

00:08:15.830 --> 00:08:22.130
And also, another example is
the G+ community, I'd asked,

00:08:22.130 --> 00:08:24.090
what else do you want
to see in our videos?

00:08:24.090 --> 00:08:27.230
And the immediate answer was
authentication, transactions.

00:08:27.230 --> 00:08:28.250
How do we do those?

00:08:28.250 --> 00:08:30.830
And so we reached
out to David Wang,

00:08:30.830 --> 00:08:32.990
who's going to be on one
of our very first episodes

00:08:32.990 --> 00:08:36.080
talking about that, who is from
the Product Management team.

00:08:36.080 --> 00:08:38.780
So this team are all
advocates for you.

00:08:38.780 --> 00:08:41.330
And we're really excited
to dig into some questions.

00:08:41.330 --> 00:08:43.165
So welcome, everybody.

00:08:48.520 --> 00:08:51.100
So Sachit, let's start with you.

00:08:51.100 --> 00:08:51.700
Voice.

00:08:51.700 --> 00:08:53.369
What's all the noise about?

00:08:53.369 --> 00:08:54.160
SACHIT MISRA: Sure.

00:08:54.160 --> 00:08:56.150
First off, Nandini, thank you
for having me on the panel.

00:08:56.150 --> 00:08:57.649
And thanks to all
of you for coming.

00:08:57.649 --> 00:08:59.520
It's really exciting
actually to be here.

00:08:59.520 --> 00:09:01.270
Just Nandini gave me
a great introduction.

00:09:01.270 --> 00:09:02.350
But just to add to
it a little bit,

00:09:02.350 --> 00:09:04.016
I'm an engineer at
Google working mostly

00:09:04.016 --> 00:09:05.350
on developer tooling.

00:09:05.350 --> 00:09:09.220
And I was working on the Living
Room team before on Android TV

00:09:09.220 --> 00:09:09.962
and Cast.

00:09:09.962 --> 00:09:11.920
And Google Home became
part of the Living Room.

00:09:11.920 --> 00:09:14.980
So that's how I got sucked
into this, thank god.

00:09:14.980 --> 00:09:19.330
And so about a year
ago, Nandini and I

00:09:19.330 --> 00:09:22.510
were working on some
of the first samples.

00:09:22.510 --> 00:09:24.322
Which by the way, she helped.

00:09:24.322 --> 00:09:25.780
If you ever have
the chance to have

00:09:25.780 --> 00:09:27.010
her help with an
app you're building,

00:09:27.010 --> 00:09:29.197
she has an extraordinary
talent for both the design

00:09:29.197 --> 00:09:30.280
and the technical portion.

00:09:30.280 --> 00:09:30.430
She'll really help the--

00:09:30.430 --> 00:09:30.530
NANDINI STOCKER:
Please continue.

00:09:30.530 --> 00:09:32.657
SACHIT MISRA: --the
code you write.

00:09:32.657 --> 00:09:34.240
Seriously, she saved
me a lot of time.

00:09:34.240 --> 00:09:35.230
Trust me.

00:09:35.230 --> 00:09:39.280
In any case, to get back to your
question, Nandini, about what's

00:09:39.280 --> 00:09:40.480
all this noise about.

00:09:40.480 --> 00:09:44.020
I think that this noise
that we're hearing

00:09:44.020 --> 00:09:48.280
is the low, low hum
of the Sci-Fi promise,

00:09:48.280 --> 00:09:50.500
to take words
directly from Nandini.

00:09:50.500 --> 00:09:52.210
And what I mean
by that is we are

00:09:52.210 --> 00:09:55.000
at the very, very,
very early stages

00:09:55.000 --> 00:09:59.420
of the next mode of interaction
between us and machines.

00:09:59.420 --> 00:10:01.675
And this is something we've
dreamt about for decades.

00:10:01.675 --> 00:10:02.800
And it's finally happening.

00:10:02.800 --> 00:10:05.454
And so far, it's
still a little rough.

00:10:05.454 --> 00:10:07.870
A lot of these interactions
are still a little frustrating

00:10:07.870 --> 00:10:08.950
sometimes.

00:10:08.950 --> 00:10:11.740
But what's important
is to listen

00:10:11.740 --> 00:10:14.906
through the noise for the
signal of those magical moments

00:10:14.906 --> 00:10:16.030
that we have with machines.

00:10:16.030 --> 00:10:17.410
And it's happening today.

00:10:17.410 --> 00:10:19.750
And we're going to be
telling future generations

00:10:19.750 --> 00:10:22.120
about these days, years
from now, when it's

00:10:22.120 --> 00:10:24.642
working as they expect it to.

00:10:24.642 --> 00:10:25.600
NANDINI STOCKER: Great.

00:10:25.600 --> 00:10:27.400
Thanks, Sachit.

00:10:27.400 --> 00:10:29.950
So how about you, Kimberly?

00:10:29.950 --> 00:10:33.760
What's all the noise about?

00:10:33.760 --> 00:10:34.690
KIMBERLY HARVEY: God.

00:10:34.690 --> 00:10:38.560
So I guess noise, meaning
what's exciting about voice.

00:10:38.560 --> 00:10:40.840
For me, what is
exciting about it is

00:10:40.840 --> 00:10:43.890
I feel like we're getting closer
and closer to a direct thought

00:10:43.890 --> 00:10:44.560
download.

00:10:44.560 --> 00:10:47.350
I studied communication and
cross-cultural communication

00:10:47.350 --> 00:10:48.400
in grad school.

00:10:48.400 --> 00:10:52.360
And everyone knows humans have
a lot of different methods

00:10:52.360 --> 00:10:53.374
of communicating.

00:10:53.374 --> 00:10:55.040
Someone might be
watching this on video.

00:10:55.040 --> 00:10:56.530
I'm using gestures.

00:10:56.530 --> 00:10:58.300
I'm using words.

00:10:58.300 --> 00:11:00.860
We have systems of writings
all around the globe.

00:11:00.860 --> 00:11:05.710
But I feel like having humans
interact in a way that's

00:11:05.710 --> 00:11:06.640
been natural--

00:11:06.640 --> 00:11:08.440
that's been one of
the first skills

00:11:08.440 --> 00:11:10.960
that we learned as babies--

00:11:10.960 --> 00:11:13.480
can get rid of some of
the challenges we have--

00:11:13.480 --> 00:11:15.319
we're having--

00:11:15.319 --> 00:11:16.860
can get rid of some
of the challenges

00:11:16.860 --> 00:11:20.172
we have getting one thought from
one person's mind to another.

00:11:20.172 --> 00:11:21.130
NANDINI STOCKER: Great.

00:11:21.130 --> 00:11:24.130
And Marc, you've been a
designer for a long time.

00:11:24.130 --> 00:11:25.840
And you bring some
unique perspectives

00:11:25.840 --> 00:11:26.950
on interaction design.

00:11:26.950 --> 00:11:31.240
But you started in voice,
actually, but way before we

00:11:31.240 --> 00:11:33.112
had the Google Assistant.

00:11:33.112 --> 00:11:33.820
So how about you?

00:11:33.820 --> 00:11:35.170
What's all the noise about?

00:11:35.170 --> 00:11:35.961
MARC PAULINA: Yeah.

00:11:35.961 --> 00:11:38.600
I think it's a really
interesting time at the moment.

00:11:38.600 --> 00:11:43.060
So talking about like the
journey that we've had,

00:11:43.060 --> 00:11:45.700
I wasn't a voice
designer before I

00:11:45.700 --> 00:11:49.290
started working on voice actions
in the Google Search app.

00:11:49.290 --> 00:11:53.050
I was a interaction
designer working on mobile,

00:11:53.050 --> 00:11:55.360
working in automotive and TVs.

00:11:55.360 --> 00:12:00.250
But voice for me was
quite a stunning journey.

00:12:00.250 --> 00:12:02.320
It was so different
than what I was used to.

00:12:02.320 --> 00:12:07.000
So for me, it's been
really enlightening

00:12:07.000 --> 00:12:11.170
thinking about voice, and
conversation, and natural user

00:12:11.170 --> 00:12:11.770
interfaces.

00:12:11.770 --> 00:12:14.150
And how there's such an
emergence right now of all

00:12:14.150 --> 00:12:17.320
of these technologies, like
AI, Internet of Things,

00:12:17.320 --> 00:12:22.060
robotics, and so on, where
the technology is really

00:12:22.060 --> 00:12:25.510
trying to take the burden and
the friction away from people.

00:12:25.510 --> 00:12:28.720
And so we've got all of
this, these new natural user

00:12:28.720 --> 00:12:33.280
interfaces that set people's
expectations so much higher

00:12:33.280 --> 00:12:34.670
than we've had before.

00:12:34.670 --> 00:12:36.280
So as a designer,
it's been really

00:12:36.280 --> 00:12:41.560
exciting to try and create
these new design methodologies

00:12:41.560 --> 00:12:45.460
where we can understand
people a lot more

00:12:45.460 --> 00:12:48.155
and try and meet
users' expectations.

00:12:48.155 --> 00:12:50.530
As Sachit was saying, in the
future, it should just work.

00:12:50.530 --> 00:12:53.250
But right now, with the
technology how it is,

00:12:53.250 --> 00:12:55.540
there's a lot of really
interesting design problems.

00:12:55.540 --> 00:12:56.650
NANDINI STOCKER: Yeah.

00:12:56.650 --> 00:12:59.470
What we've been
seeing that there is

00:12:59.470 --> 00:13:00.820
some kind of forgiveness there.

00:13:00.820 --> 00:13:04.330
People are at this point
where they're like, OK,

00:13:04.330 --> 00:13:07.430
we get that it doesn't work
perfectly all the time.

00:13:07.430 --> 00:13:09.940
And it's great to see that
people are working on that.

00:13:09.940 --> 00:13:14.170
But it's like people get
the possibility finally,

00:13:14.170 --> 00:13:17.620
which is so exciting.

00:13:17.620 --> 00:13:18.870
Well, let's start.

00:13:18.870 --> 00:13:20.290
I have a few questions.

00:13:20.290 --> 00:13:22.750
I polled online.

00:13:22.750 --> 00:13:25.810
And then we have a few others
that we got from just asking

00:13:25.810 --> 00:13:27.190
around at the conference.

00:13:27.190 --> 00:13:29.590
We do user-centered research.

00:13:29.590 --> 00:13:32.990
Very not last minute at all.

00:13:32.990 --> 00:13:35.740
So this one comes from Twitter.

00:13:35.740 --> 00:13:38.170
Bob Stoltzberg.

00:13:38.170 --> 00:13:41.430
Is the Google
Assistant a Girl Scout?

00:13:41.430 --> 00:13:43.709
KIMBERLY HARVEY: I
can take this one.

00:13:43.709 --> 00:13:45.250
Well, the first
thing I would ask Bob

00:13:45.250 --> 00:13:47.970
is, why do you think
it's a Girl Scout?

00:13:47.970 --> 00:13:50.866
What is it that lends
itself to that stereotype

00:13:50.866 --> 00:13:51.990
that you have in your mind?

00:13:51.990 --> 00:13:53.770
That's just from a
research perspective.

00:13:53.770 --> 00:13:55.800
But to answer his
question, I would

00:13:55.800 --> 00:13:58.530
say that the Assistant
is not a Girl Scout.

00:13:58.530 --> 00:14:00.660
But it can facilitate
relationships

00:14:00.660 --> 00:14:03.330
with characters
like Girl Scouts.

00:14:03.330 --> 00:14:06.630
We have an entire team at
Google that just concerns itself

00:14:06.630 --> 00:14:07.920
with the personality.

00:14:07.920 --> 00:14:09.990
Make sure that the
interactions we're designing

00:14:09.990 --> 00:14:11.550
are on par with
that personality,

00:14:11.550 --> 00:14:15.450
make sure the wording is right,
and also shows different parts

00:14:15.450 --> 00:14:16.930
of the Assistant's character.

00:14:16.930 --> 00:14:18.180
NANDINI STOCKER: That's great.

00:14:18.180 --> 00:14:22.050
And Ryan Germick, who heads the
Doodle team and the Personality

00:14:22.050 --> 00:14:26.180
team, has a great analogy, that
you ask personality questions.

00:14:26.180 --> 00:14:28.170
You poke at things
and ask it things

00:14:28.170 --> 00:14:32.545
that you can know what to expect
an answer from or a little--

00:14:32.545 --> 00:14:34.420
like what color-- what's
your favorite color?

00:14:34.420 --> 00:14:35.370
Things like that.

00:14:35.370 --> 00:14:36.600
And it's like, when you--

00:14:36.600 --> 00:14:38.550
it's a way of
establishing trust.

00:14:38.550 --> 00:14:41.050
So when you establish trust
with your neighbor, for example,

00:14:41.050 --> 00:14:42.905
you might borrow a cup of sugar.

00:14:42.905 --> 00:14:44.700
Like Ryan says,
borrow a cup of sugar

00:14:44.700 --> 00:14:46.890
before you go and ask
for the lawn mower.

00:14:46.890 --> 00:14:50.610
So one of our episodes
features how to write.

00:14:50.610 --> 00:14:53.580
How do you write for personality
questions, that are just

00:14:53.580 --> 00:14:55.500
about the character
you're interacting

00:14:55.500 --> 00:14:59.130
with, as opposed to the
deeper back and forth

00:14:59.130 --> 00:15:01.110
interaction about whatever
that is the task you

00:15:01.110 --> 00:15:02.440
want to accomplish?

00:15:02.440 --> 00:15:05.430
So that's a great question.

00:15:05.430 --> 00:15:07.920
And then, so we'll switch
to a-- oh, a zinger

00:15:07.920 --> 00:15:09.780
from the developer community.

00:15:09.780 --> 00:15:12.500
This one via LinkedIn,
probably for Sachit.

00:15:12.500 --> 00:15:15.930
But maybe one of the
others can pipe in.

00:15:15.930 --> 00:15:18.360
So there's a common
sentiment among developers,

00:15:18.360 --> 00:15:21.180
who are leery of starting
projects found in newer

00:15:21.180 --> 00:15:24.220
services and tools,
as they've been burned

00:15:24.220 --> 00:15:27.360
numerous times in the
past by deprecation

00:15:27.360 --> 00:15:30.180
and abandonment of support.

00:15:30.180 --> 00:15:33.210
So given the inherent
community-based nature

00:15:33.210 --> 00:15:37.950
of conversation design, can
developers find assurances that

00:15:37.950 --> 00:15:41.460
Google recognizes this pillar
and won't be abandoning support

00:15:41.460 --> 00:15:46.280
for the Assistant SDK,
API.AI, the speech reco API,

00:15:46.280 --> 00:15:48.750
or other related projects to--

00:15:48.750 --> 00:15:51.000
this is amazing--
allow innovators

00:15:51.000 --> 00:15:55.260
to create new products and
even found businesses upon?

00:15:55.260 --> 00:15:57.240
Well, I will say one thing.

00:15:57.240 --> 00:16:00.340
If we were doing that,
none of us have any jobs.

00:16:00.340 --> 00:16:02.610
So we're here.

00:16:02.610 --> 00:16:04.020
So just to say that.

00:16:04.020 --> 00:16:06.139
But Sachit, from the
developer perspective,

00:16:06.139 --> 00:16:08.430
you guys work with the tools
and all the APIs and that.

00:16:08.430 --> 00:16:10.720
So what would you say to that?

00:16:10.720 --> 00:16:14.100
SACHIT MISRA: So first, I
would empathize with the person

00:16:14.100 --> 00:16:15.255
asking the question.

00:16:15.255 --> 00:16:17.380
NANDINI STOCKER: It was
Brandon Hunter, by the way,

00:16:17.380 --> 00:16:19.279
from LinkedIn who asked
amazing questions.

00:16:19.279 --> 00:16:20.070
Thank you, Brandon.

00:16:20.070 --> 00:16:21.420
SACHIT MISRA: Thanks, Brandon.

00:16:21.420 --> 00:16:22.680
So I've felt that burn before.

00:16:22.680 --> 00:16:26.760
So I certainly wouldn't want
to inflict that on anyone else.

00:16:26.760 --> 00:16:30.330
I would also say in
this space that I

00:16:30.330 --> 00:16:35.160
think a little bit extra
of an adventurous attitude

00:16:35.160 --> 00:16:38.250
is actually called for here from
the developers point of view.

00:16:38.250 --> 00:16:42.150
Because early investments now,
in terms of just picking up

00:16:42.150 --> 00:16:44.580
the knowledge around these
APIs and around even just

00:16:44.580 --> 00:16:45.540
the terminology.

00:16:45.540 --> 00:16:47.370
Just figuring out
what the design looks

00:16:47.370 --> 00:16:50.730
like for these types of things
will pay off exponentially

00:16:50.730 --> 00:16:51.930
in the future.

00:16:51.930 --> 00:16:54.480
But to directly
answer the question,

00:16:54.480 --> 00:16:57.690
in terms of Google's
investment in this space,

00:16:57.690 --> 00:16:59.640
I think it's very
clear, just even

00:16:59.640 --> 00:17:02.420
using the list of
services and APIs

00:17:02.420 --> 00:17:05.224
that the person asked
in the question.

00:17:05.224 --> 00:17:06.599
It's very clear
that we're trying

00:17:06.599 --> 00:17:09.489
to push an entire suite of
products on developers here.

00:17:09.489 --> 00:17:11.280
And I think that gives
evidence to the idea

00:17:11.280 --> 00:17:14.160
that Google's really trying to
push heavily into this space.

00:17:14.160 --> 00:17:16.140
And I can tell you from
personal experience

00:17:16.140 --> 00:17:18.780
that, I mean, just
internally, we are

00:17:18.780 --> 00:17:21.240
seeing this as the next step.

00:17:21.240 --> 00:17:24.490
And this also is shown
through the consumer side.

00:17:24.490 --> 00:17:28.590
So the Google Assistant, as
an entire company initiative,

00:17:28.590 --> 00:17:32.010
reflects the developer APIs and
services that we're releasing.

00:17:32.010 --> 00:17:34.110
So I think what's
clear, if you look

00:17:34.110 --> 00:17:37.410
at the scope of what Google
is actually putting out there,

00:17:37.410 --> 00:17:40.290
is that we see this really as
the next step for both users

00:17:40.290 --> 00:17:41.130
and developers.

00:17:41.130 --> 00:17:43.480
And we will be supporting
this moving forward.

00:17:43.480 --> 00:17:48.300
So I wouldn't worry too much
about the sort of platforms

00:17:48.300 --> 00:17:51.030
going away or these
services going away.

00:17:51.030 --> 00:17:53.430
Even if there are changes
and that kind of thing,

00:17:53.430 --> 00:17:58.710
clearly the platform as a
whole, the conversational push

00:17:58.710 --> 00:18:00.210
as a whole, isn't
going anywhere.

00:18:00.210 --> 00:18:01.712
And we're sticking to that.

00:18:01.712 --> 00:18:02.670
NANDINI STOCKER: Great.

00:18:02.670 --> 00:18:03.940
Thank you.

00:18:03.940 --> 00:18:06.660
OK, let's pivot to design.

00:18:06.660 --> 00:18:09.930
Marc, can you talk about
some of the design methods

00:18:09.930 --> 00:18:11.719
you've used for
voice interaction?

00:18:11.719 --> 00:18:12.510
MARC PAULINA: Sure.

00:18:12.510 --> 00:18:18.510
So, as I said, learning the
design process for voice,

00:18:18.510 --> 00:18:22.500
being new to the field
is quite a challenge.

00:18:22.500 --> 00:18:24.800
As I said, we can't use a
lot of the same assumptions

00:18:24.800 --> 00:18:26.675
and the same design
process and methodologies

00:18:26.675 --> 00:18:29.050
that we used for
other experiences.

00:18:29.050 --> 00:18:34.080
For example, designing apps,
websites, and so on, for voice.

00:18:34.080 --> 00:18:39.960
So it helps to keep
learning new methodologies.

00:18:39.960 --> 00:18:44.970
So I personally take a lot
from service design theory.

00:18:44.970 --> 00:18:46.620
One of the principles
of service design

00:18:46.620 --> 00:18:49.570
is that we democratize
the design process.

00:18:49.570 --> 00:18:52.560
So that means-- for me, it means
empowering the whole product

00:18:52.560 --> 00:18:56.220
team to be able to come up
with powerful experiences

00:18:56.220 --> 00:18:58.140
and come up with
user-centered designs.

00:18:58.140 --> 00:19:00.660
And so the way to
do that is, just

00:19:00.660 --> 00:19:05.830
as a designer, or a researcher,
or as anyone in the product

00:19:05.830 --> 00:19:09.570
team, just to be aware
of who the user is

00:19:09.570 --> 00:19:10.970
and what the user needs.

00:19:10.970 --> 00:19:14.380
And keep asking the question,
what's the motivation?

00:19:14.380 --> 00:19:15.390
What's their goal?

00:19:15.390 --> 00:19:18.420
Even what are their
anxieties and their fears?

00:19:18.420 --> 00:19:20.629
The more that you understand
about the user, the more

00:19:20.629 --> 00:19:22.420
user-centered your
designs are going to be.

00:19:22.420 --> 00:19:24.720
Like you said, people have
got much higher expectations

00:19:24.720 --> 00:19:27.330
of these natural use
interfaces than they have

00:19:27.330 --> 00:19:29.880
of other types of interface.

00:19:29.880 --> 00:19:32.580
And then the other
thing is best practices

00:19:32.580 --> 00:19:36.120
for conversation design.

00:19:36.120 --> 00:19:37.980
One principle we have
conversation design

00:19:37.980 --> 00:19:41.390
is that we focus a lot
on designing for failure,

00:19:41.390 --> 00:19:44.940
because with the technology
how it currently is, there can

00:19:44.940 --> 00:19:46.830
be a lot of misrecognitions.

00:19:46.830 --> 00:19:49.990
And also, just with language,
there's a lot of ambiguity.

00:19:49.990 --> 00:19:54.540
So we focus a lot-- the happy
path is fairly straightforward.

00:19:54.540 --> 00:19:58.584
But the unhappy path
can be quite complex.

00:19:58.584 --> 00:20:00.000
So we spend a lot
of time focusing

00:20:00.000 --> 00:20:01.860
on designing for failure.

00:20:01.860 --> 00:20:04.580
And then there's also
investment in prototyping.

00:20:04.580 --> 00:20:07.472
So that's another aspect
of user-centered design,

00:20:07.472 --> 00:20:09.930
is being able to validate what
you're designing with users.

00:20:09.930 --> 00:20:10.370
NANDINI STOCKER: Yep.

00:20:10.370 --> 00:20:12.730
Sachit, you have a term for
it instead of happy path.

00:20:12.730 --> 00:20:13.399
It's--

00:20:13.399 --> 00:20:14.190
SACHIT MISRA: Yeah.

00:20:14.190 --> 00:20:16.020
I have something I
call the happy tree.

00:20:16.020 --> 00:20:17.571
NANDINI STOCKER:
It's a happy tree.

00:20:17.571 --> 00:20:18.071
Yeah.

00:20:18.071 --> 00:20:21.170
There's a Bob Ross reference
in there somewhere.

00:20:21.170 --> 00:20:23.580
Happy little trees.

00:20:23.580 --> 00:20:24.190
OK.

00:20:24.190 --> 00:20:26.540
Well, and then, I mean,
you mentioned research.

00:20:26.540 --> 00:20:29.250
So Kimberly-- so
we can all talk.

00:20:29.250 --> 00:20:33.129
We can all speak, or gesture,
or we can all communicate.

00:20:33.129 --> 00:20:35.670
It's the interface we learned
first and the one we know best.

00:20:35.670 --> 00:20:39.810
So it's not like we need
any help understanding that.

00:20:39.810 --> 00:20:40.980
Finding a button.

00:20:40.980 --> 00:20:43.931
So why do we need UX research?

00:20:43.931 --> 00:20:46.775
KIMBERLY HARVEY: Why
don't we need UX research?

00:20:46.775 --> 00:20:48.150
Just because we
know how to speak

00:20:48.150 --> 00:20:50.820
doesn't mean we understand the
intention of what's going on.

00:20:50.820 --> 00:20:52.800
For example, backstage,
I was saying,

00:20:52.800 --> 00:20:57.450
let's say Marc was outside
in the center of the hall.

00:20:57.450 --> 00:20:58.830
And I was talking to someone.

00:20:58.830 --> 00:21:00.810
And I said, what
does Marc look like?

00:21:00.810 --> 00:21:03.189
They would describe Marc
in a certain way like,

00:21:03.189 --> 00:21:04.230
he's wearing white shoes.

00:21:04.230 --> 00:21:05.700
He's got a
multicolored shirt on.

00:21:05.700 --> 00:21:08.220
But if we were working
in an office, and Marc

00:21:08.220 --> 00:21:10.097
had been out with
the flu for a week.

00:21:10.097 --> 00:21:11.430
And this was his first day back.

00:21:11.430 --> 00:21:13.920
And I turned to my boss, and I
said, what does Marc look like?

00:21:13.920 --> 00:21:15.961
My boss might say, well,
he looks a little better

00:21:15.961 --> 00:21:16.950
than he did last week.

00:21:16.950 --> 00:21:20.430
Same question, completely
different answers

00:21:20.430 --> 00:21:22.170
based on the context.

00:21:22.170 --> 00:21:24.240
And a lot of times,
while we are sitting

00:21:24.240 --> 00:21:27.810
and we're developing, even
designing an experience,

00:21:27.810 --> 00:21:31.260
we really don't know, until
we actually see it in motion,

00:21:31.260 --> 00:21:33.420
whether we've ironed
out all of the kinks

00:21:33.420 --> 00:21:36.930
and whether there are
surprising behaviors that

00:21:36.930 --> 00:21:39.790
are emerging from the designs
that we didn't expect.

00:21:39.790 --> 00:21:41.220
So it's a great way to--

00:21:41.220 --> 00:21:44.610
it's almost like QAing
your human condition

00:21:44.610 --> 00:21:48.630
to make sure that you've
got everything covered.

00:21:48.630 --> 00:21:51.810
NANDINI STOCKER: So
Sachit, what about you?

00:21:51.810 --> 00:21:54.600
I mean, you--learning other
disciplines as you get

00:21:54.600 --> 00:21:55.140
into this.

00:21:55.140 --> 00:21:57.300
But just from a
developer perspective,

00:21:57.300 --> 00:22:01.050
getting just the ramp
up into this, what

00:22:01.050 --> 00:22:05.105
can a developer bring from
past platforms into this space?

00:22:05.105 --> 00:22:09.330
SACHIT MISRA: So I think the
great thing about our platform

00:22:09.330 --> 00:22:11.670
in particular is it's mostly
driven through the cloud

00:22:11.670 --> 00:22:12.780
and through the web.

00:22:12.780 --> 00:22:16.890
So what that means is for
developers who have already

00:22:16.890 --> 00:22:19.200
been developing on the
cloud, or like web apps,

00:22:19.200 --> 00:22:21.180
or even APIs they've been
building for mobile apps, that

00:22:21.180 --> 00:22:23.763
kind of thing, you'll be able
to bring all that experience in.

00:22:23.763 --> 00:22:27.090
And the tools that we provide,
like in particular API.AI,

00:22:27.090 --> 00:22:29.670
to abstract some of
the harder problems,

00:22:29.670 --> 00:22:32.280
like the natural language
understanding, those tools

00:22:32.280 --> 00:22:33.930
are fairly easy to
use for anybody.

00:22:33.930 --> 00:22:35.550
You don't need a computer
science degree really

00:22:35.550 --> 00:22:36.925
to understand that
kind of stuff.

00:22:36.925 --> 00:22:39.250
So first learning
that is fairly simple.

00:22:39.250 --> 00:22:40.746
There's a low barrier to entry.

00:22:40.746 --> 00:22:42.870
And then secondly, with
your existing cloud and web

00:22:42.870 --> 00:22:45.960
knowledge and just using
basically efficient coding

00:22:45.960 --> 00:22:49.159
practices around things
like string manipulation,

00:22:49.159 --> 00:22:50.700
those kind of things,
you can already

00:22:50.700 --> 00:22:52.916
build apps pretty
effectively on our platform.

00:22:52.916 --> 00:22:55.290
And one of the things I'm
actually really looking forward

00:22:55.290 --> 00:22:57.990
to hopefully, that I want
to see from the community,

00:22:57.990 --> 00:23:00.240
is more tooling and
frameworks that we

00:23:00.240 --> 00:23:03.565
have similar to front-end apps
on other platforms, like web

00:23:03.565 --> 00:23:04.440
apps and mobile apps.

00:23:04.440 --> 00:23:07.206
There's a lot out there if
you just want to build the UI.

00:23:07.206 --> 00:23:08.580
And so I'm really
looking forward

00:23:08.580 --> 00:23:11.340
to seeing how people
build frameworks

00:23:11.340 --> 00:23:13.823
for building conversational
UIs and voice UIs.

00:23:13.823 --> 00:23:15.614
I think that's going
to be really exciting.

00:23:15.614 --> 00:23:16.530
NANDINI STOCKER: Cool.

00:23:16.530 --> 00:23:17.250
Great.

00:23:17.250 --> 00:23:19.650
And then usually, once
you start building,

00:23:19.650 --> 00:23:21.120
you're early in the process.

00:23:21.120 --> 00:23:22.540
You want to start prototyping.

00:23:22.540 --> 00:23:25.090
So Marc, you have some really
unique perspective here.

00:23:25.090 --> 00:23:28.080
So do you have suggestions
for how to prototype

00:23:28.080 --> 00:23:29.550
in voice interaction design?

00:23:29.550 --> 00:23:31.870
MARC PAULINA: Yeah.

00:23:31.870 --> 00:23:33.630
When I think about
prototype, I'm

00:23:33.630 --> 00:23:36.750
looking at something that I
can use early in the design

00:23:36.750 --> 00:23:39.060
process, that I
can learn quickly,

00:23:39.060 --> 00:23:40.990
and I can iterate
really quickly.

00:23:40.990 --> 00:23:47.200
So I think it's really important
that we invest in prototyping,

00:23:47.200 --> 00:23:51.044
especially if we don't have
the years of experience working

00:23:51.044 --> 00:23:52.960
on voice use interfaces,
and that we're really

00:23:52.960 --> 00:23:54.430
learning on the go.

00:23:54.430 --> 00:23:56.500
So there's a few
methodologies that we've

00:23:56.500 --> 00:24:01.750
used with some success designing
conversational UIs at Google,

00:24:01.750 --> 00:24:04.830
such as Wizard of
Oz prototyping.

00:24:04.830 --> 00:24:06.850
So this is the idea
about Wizard of Oz,

00:24:06.850 --> 00:24:12.880
is that you remotely control the
device that the participant is

00:24:12.880 --> 00:24:16.120
using in a study environment.

00:24:16.120 --> 00:24:18.370
But they think that they're
speaking to the Assistant.

00:24:18.370 --> 00:24:19.530
But really, they're
speaking to me

00:24:19.530 --> 00:24:20.620
as the puppet master
pulling the strings--

00:24:20.620 --> 00:24:20.740
NANDINI STOCKER:
It's like, you--

00:24:20.740 --> 00:24:21.070
MARC PAULINA:
--behind the strings.

00:24:21.070 --> 00:24:22.486
NANDINI STOCKER:
--could literally

00:24:22.486 --> 00:24:23.770
create the whole scene.

00:24:23.770 --> 00:24:25.126
You could go behind the-- yeah.

00:24:25.126 --> 00:24:26.500
MARC PAULINA: You
could basically

00:24:26.500 --> 00:24:28.990
emulate what they would
believe is like the end user

00:24:28.990 --> 00:24:29.530
experience.

00:24:29.530 --> 00:24:30.992
But basically there's no AI.

00:24:30.992 --> 00:24:31.700
There's no cloud.

00:24:31.700 --> 00:24:33.190
It's just me on the other side.

00:24:33.190 --> 00:24:35.106
NANDINI STOCKER: Because
talking is as scrappy

00:24:35.106 --> 00:24:38.910
as it gets in terms
of role-playing.

00:24:38.910 --> 00:24:42.040
MARC PAULINA: And it's
incredibly-- conversation is--

00:24:42.040 --> 00:24:43.014
it can go anywhere.

00:24:43.014 --> 00:24:43.930
You never really know.

00:24:43.930 --> 00:24:46.000
There's no set path.

00:24:46.000 --> 00:24:47.770
And so to feel
natural, you need to be

00:24:47.770 --> 00:24:49.280
able to pivot in real time.

00:24:49.280 --> 00:24:52.840
So really, unless you had
the AI built for that,

00:24:52.840 --> 00:24:55.060
the only person who can
do that is a real person

00:24:55.060 --> 00:24:56.500
listening in real time.

00:24:56.500 --> 00:24:59.280
So Wizard of Oz is
really powerful.

00:24:59.280 --> 00:25:01.750
And it can be as
simple as having

00:25:01.750 --> 00:25:05.870
a Bluetooth speaker
and the audio files

00:25:05.870 --> 00:25:07.090
ready to go on your laptop.

00:25:07.090 --> 00:25:08.200
And you're just
basically playing

00:25:08.200 --> 00:25:09.783
them as you're
responding to the user.

00:25:09.783 --> 00:25:13.390
It takes a bit of practice,
but it's really good.

00:25:13.390 --> 00:25:15.910
And then the other
methodology that we use early

00:25:15.910 --> 00:25:20.390
in the design process is just
saying out loud role-playing.

00:25:20.390 --> 00:25:22.075
And in the Google
Design Sprints,

00:25:22.075 --> 00:25:25.810
when we're actually got
the whole product team

00:25:25.810 --> 00:25:27.610
designing their
conversations, we'll

00:25:27.610 --> 00:25:30.620
actually do
investigative rehearsal.

00:25:30.620 --> 00:25:35.260
Which is a methodology created
by Adam Lawrence of "This

00:25:35.260 --> 00:25:37.630
is Service Design Doing."

00:25:37.630 --> 00:25:40.990
And it's basically-- the
idea is that you rehearse

00:25:40.990 --> 00:25:42.790
the conversation in real time.

00:25:42.790 --> 00:25:44.860
And then you investigate
that conversation.

00:25:44.860 --> 00:25:46.740
And you ask questions about it.

00:25:46.740 --> 00:25:52.030
So it is the most scrappiest,
most lowest fidelity prototype

00:25:52.030 --> 00:25:55.180
you can imagine, but
incredibly powerful

00:25:55.180 --> 00:25:59.380
for the first draft
of the conversation

00:25:59.380 --> 00:26:04.720
before you invest in
any coded prototyping.

00:26:04.720 --> 00:26:06.940
SACHIT MISRA: It's funny
you mentioned that you--

00:26:06.940 --> 00:26:08.440
for the sprints you
were just talking about,

00:26:08.440 --> 00:26:10.023
that you have the
whole product there.

00:26:10.023 --> 00:26:12.340
Because basically what
you're facilitating

00:26:12.340 --> 00:26:15.460
is a conversation to
build a conversation.

00:26:15.460 --> 00:26:17.470
And it actually creates
better conversations

00:26:17.470 --> 00:26:18.670
in terms of the actual apps.

00:26:18.670 --> 00:26:19.170
Yeah?

00:26:19.170 --> 00:26:21.251
MARC PAULINA: Yeah.

00:26:21.251 --> 00:26:22.750
Having the whole
product team there,

00:26:22.750 --> 00:26:25.600
it democratizes, as I
said, the design process,

00:26:25.600 --> 00:26:29.620
that everyone shares the same
understanding of the problem.

00:26:29.620 --> 00:26:32.560
Everyone understands
the user requirements.

00:26:32.560 --> 00:26:37.000
Everyone understands their goals
and maybe the business goals

00:26:37.000 --> 00:26:38.410
as well.

00:26:38.410 --> 00:26:40.840
And everyone's thinking
through that at the same time

00:26:40.840 --> 00:26:42.460
and trying stuff out.

00:26:42.460 --> 00:26:46.109
So it really is like a
platform approach for design,

00:26:46.109 --> 00:26:47.150
which is pretty powerful.

00:26:47.150 --> 00:26:47.350
NANDINI STOCKER: Yeah.

00:26:47.350 --> 00:26:49.150
In fact, that's
probably a good place

00:26:49.150 --> 00:26:51.700
to close and just
wrap up, and is

00:26:51.700 --> 00:26:55.240
to get everyone
thinking about this.

00:26:55.240 --> 00:26:57.740
I've been doing this for a
really, really long time.

00:26:57.740 --> 00:27:02.560
So hopefully, if you feel
like we raised more questions

00:27:02.560 --> 00:27:06.610
in this panel than answers,
then good, because there's

00:27:06.610 --> 00:27:08.590
a lot to talk about.

00:27:08.590 --> 00:27:10.840
As I said at the
beginning, this is just

00:27:10.840 --> 00:27:13.150
the start of a conversation.

00:27:13.150 --> 00:27:14.900
It's like the inception
of conversations.

00:27:14.900 --> 00:27:16.040
There's so many different kinds.

00:27:16.040 --> 00:27:17.320
There's worldwide conversations.

00:27:17.320 --> 00:27:19.528
There's conversations between
one person and a group.

00:27:19.528 --> 00:27:22.330
There's two-person
conversations.

00:27:22.330 --> 00:27:23.610
This is just one of them.

00:27:23.610 --> 00:27:25.630
And it's a much larger one.

00:27:25.630 --> 00:27:31.030
So a conversation about
the future of technology,

00:27:31.030 --> 00:27:35.080
and where we are today, and
where we're going from here

00:27:35.080 --> 00:27:37.370
is going to take a
new kind of ecosystem.

00:27:37.370 --> 00:27:39.480
This is called the
conversation economy.

00:27:39.480 --> 00:27:40.480
You guys are part of it.

00:27:40.480 --> 00:27:45.160
And with your help, we need
to build this new ecosystem.

00:27:45.160 --> 00:27:48.190
We can actually, at this
point, take a quantum leap

00:27:48.190 --> 00:27:51.620
past this AI first world.

00:27:51.620 --> 00:27:53.860
In fact, words really matter.

00:27:53.860 --> 00:27:56.560
It's actually quite unfortunate
that we call it artificial

00:27:56.560 --> 00:28:00.280
at all, when we need things
like authentic and advanced

00:28:00.280 --> 00:28:02.570
intelligence more than ever.

00:28:02.570 --> 00:28:05.590
We're all starving to
amplify our own intelligence.

00:28:05.590 --> 00:28:11.660
So maybe amplified intelligence,
hashtag fix the glitch.

00:28:11.660 --> 00:28:14.260
So we can-- but with
all of your help,

00:28:14.260 --> 00:28:16.690
with the ecosystem of the
developer community on all

00:28:16.690 --> 00:28:18.520
platforms, on all devices--

00:28:18.520 --> 00:28:20.950
it doesn't matter--
users come first.

00:28:20.950 --> 00:28:25.540
And if we build a world using a
people first creative approach

00:28:25.540 --> 00:28:27.550
to building
solutions that people

00:28:27.550 --> 00:28:29.230
can use in their
daily lives, it's

00:28:29.230 --> 00:28:31.990
more than just talking and
getting answers anymore.

00:28:31.990 --> 00:28:32.864
People want insight.

00:28:32.864 --> 00:28:34.780
And they actually want
to be able to do things

00:28:34.780 --> 00:28:35.620
in their world.

00:28:35.620 --> 00:28:38.970
We want to find those micro
moments that are assistive.

00:28:38.970 --> 00:28:41.840
Well, there's another A-word.

00:28:41.840 --> 00:28:44.950
And we just need
the whole alphabet.

00:28:44.950 --> 00:28:48.370
And we need all
disciplines at the table.

00:28:48.370 --> 00:28:53.350
Diverse voices, diverse
approaches, diverse thinking.

00:28:53.350 --> 00:28:55.870
This is really a time
when, it's like I said,

00:28:55.870 --> 00:29:00.580
the intersection of science
and culture, human interaction,

00:29:00.580 --> 00:29:05.470
human solutions to a
global problem of like,

00:29:05.470 --> 00:29:06.770
we built these machines.

00:29:06.770 --> 00:29:09.340
Let's make them
work on our behalf

00:29:09.340 --> 00:29:11.950
to help us connect more
with each other in our world

00:29:11.950 --> 00:29:14.410
and the things we
want to get done.

00:29:14.410 --> 00:29:15.532
So personally, it's my--

00:29:15.532 --> 00:29:17.240
I mean, I've been
doing this a long time,

00:29:17.240 --> 00:29:18.448
working with this technology.

00:29:18.448 --> 00:29:23.290
But really, it's my personal
mission to give voice to others

00:29:23.290 --> 00:29:25.090
and to help create
a culture that we

00:29:25.090 --> 00:29:27.490
can build experiences
that illustrate

00:29:27.490 --> 00:29:30.100
a shared vision of our future.

00:29:30.100 --> 00:29:31.840
We need to
collectively recognize

00:29:31.840 --> 00:29:34.450
that good means
going beyond, don't

00:29:34.450 --> 00:29:38.290
be evil, or do what's right,
to actually create experiences

00:29:38.290 --> 00:29:41.722
that are to show how it's done.

00:29:41.722 --> 00:29:43.180
And so hopefully,
with this series,

00:29:43.180 --> 00:29:44.721
we want to show what
good looks like.

00:29:44.721 --> 00:29:47.260
We want partner experiences,
developer experience

00:29:47.260 --> 00:29:52.210
to showcase what you're
creating and for your users

00:29:52.210 --> 00:29:56.740
and for the common good
of users everywhere.

00:29:56.740 --> 00:30:02.680
So we want to give insight
to the kinds of people

00:30:02.680 --> 00:30:05.440
inside Google who are building
this and also changing

00:30:05.440 --> 00:30:08.950
the landscape of the
future of technology.

00:30:08.950 --> 00:30:12.400
And also, this is the power of
spoken language and discourse.

00:30:12.400 --> 00:30:16.150
What kinds of people does it
take out there in the ecosystem

00:30:16.150 --> 00:30:18.610
to change the landscape?

00:30:18.610 --> 00:30:20.260
It's a disruptive environment.

00:30:20.260 --> 00:30:22.070
It's a really,
really good thing.

00:30:22.070 --> 00:30:26.020
So we're all living our
legacies in real time.

00:30:26.020 --> 00:30:27.730
What are you going
to be known for?

00:30:27.730 --> 00:30:29.950
What kind of world are you
creating for your kids?

00:30:29.950 --> 00:30:33.144
Have that conversation with
yourself and with each other.

00:30:33.144 --> 00:30:35.060
And we're going to create
some amazing things.

00:30:35.060 --> 00:30:37.099
And I can't wait to
see what you create.

00:30:37.099 --> 00:30:38.390
And we will look forward to it.

00:30:38.390 --> 00:30:39.700
Thank you so much to our panel.

00:30:39.700 --> 00:30:41.530
And thank you to the
audience for being

00:30:41.530 --> 00:30:45.220
part of this exciting,
creative moment for us.

00:30:45.220 --> 00:30:46.930
Thank you.

00:30:46.930 --> 00:30:50.580
[MUSIC PLAYING]

