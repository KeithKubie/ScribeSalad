1
00:00:00,460 --> 00:00:00,971
In this video,

2
00:00:00,971 --> 00:00:04,420
we'll describe a very important
problem in natural language processing.

3
00:00:04,450 --> 00:00:05,940
The problem of language model.

4
00:00:09,430 --> 00:00:14,430
So a language model is a
probabilistic model that is signs,

5
00:00:15,940 --> 00:00:18,580
probabilities to any sequence of words.

6
00:00:18,850 --> 00:00:22,930
So it's a distribution essentially
on a sequences of words,

7
00:00:22,960 --> 00:00:25,000
on sentences and documents.

8
00:00:25,540 --> 00:00:29,010
And so the problem of language modeling
or the task of language modeling is to

9
00:00:29,011 --> 00:00:34,011
actually learn such a model that will
assign high probabilities to a well formed

10
00:00:35,071 --> 00:00:35,750
sentences.

11
00:00:35,750 --> 00:00:40,750
So sentences that are likely to be written
in some document or heard or and so

12
00:00:41,801 --> 00:00:43,540
on.
Um,

13
00:00:44,050 --> 00:00:48,490
this is a problem or task that is very
important. Natural language processing.

14
00:00:48,520 --> 00:00:53,520
A lot of systems actually incorporate
in language modeling component such as

15
00:00:54,041 --> 00:00:57,460
speech recognition systems and
machine translation systems.

16
00:00:57,790 --> 00:00:59,980
So find stance,
uh,

17
00:01:00,040 --> 00:01:05,040
if we add a sentence wanted to
translate in Beth [inaudible] and uh,

18
00:01:05,111 --> 00:01:09,190
we had assistant that's pretty good at
just translating each individual words.

19
00:01:09,191 --> 00:01:13,630
So in would be the Sim would know
that you would translate it to uh,

20
00:01:14,080 --> 00:01:15,310
which is here also.

21
00:01:15,310 --> 00:01:19,210
And Besson would be translated by person.

22
00:01:19,600 --> 00:01:23,560
And then I tell you, Shannon
would be considered by smart. Um,

23
00:01:24,160 --> 00:01:28,300
but imagine our system is also not so
good at determining the order of these

24
00:01:28,301 --> 00:01:32,110
words, then, uh, in, in the setting, uh,

25
00:01:32,140 --> 00:01:36,730
language model would be very useful in
distinguishes funds funds since whether

26
00:01:36,910 --> 00:01:41,910
we should prefer a person smart or a
smart person as a good translation of in

27
00:01:43,080 --> 00:01:47,440
fascinated Asia and particular if you
have a good language model than it would

28
00:01:47,441 --> 00:01:52,441
recognize that this has a
higher probability of being
a written by a person in

29
00:01:54,191 --> 00:01:56,740
English,
then a person smart.

30
00:01:57,550 --> 00:02:02,550
So in this case it would have been
able to reorder Besson and put it after

31
00:02:02,891 --> 00:02:07,510
antigen out in, in the actual
translation in English. So,

32
00:02:07,690 --> 00:02:11,910
um, there are many other types of
usage of uh, language modeling, uh,

33
00:02:11,911 --> 00:02:16,420
and language problems, uh, sorry, language
models. Uh, and so they are really,

34
00:02:16,421 --> 00:02:18,430
really important in natural
language processing.

35
00:02:21,290 --> 00:02:21,770
Okay.

36
00:02:21,770 --> 00:02:24,810
And the assumption that
one often makes when, uh,

37
00:02:24,900 --> 00:02:29,900
someone designs a language model is to
make the nef order Markov assumption.

38
00:02:31,470 --> 00:02:33,410
What this assumption,
uh,

39
00:02:33,450 --> 00:02:38,100
says is that if we have a distribution
of probability distribution over a

40
00:02:38,101 --> 00:02:41,970
sequence, then, uh, the, uh, uh,

41
00:02:42,000 --> 00:02:46,380
then we're assuming that we can write
it as the product of the probability of

42
00:02:46,500 --> 00:02:51,500
each element of the sequence given only
the n minus one previous elements in

43
00:02:52,501 --> 00:02:54,750
that sequence.
Or in our case we're modeling words.

44
00:02:54,870 --> 00:02:59,870
So we're assuming that the
word at position t is only
dependent on the n minus

45
00:03:00,521 --> 00:03:04,180
one previous words and does not
depend on the other words, uh,

46
00:03:04,210 --> 00:03:08,140
before that in the sequence of words
in this sentence or in the document.

47
00:03:09,520 --> 00:03:14,500
Um, so this is, uh,
restrictive, uh, assumption. Uh,

48
00:03:14,630 --> 00:03:18,430
it essentially never,
he holds it really holds I,

49
00:03:18,431 --> 00:03:23,330
except for perhaps very, very
large and values. And, um,

50
00:03:24,100 --> 00:03:26,560
and whenever I'm going
to talk about context,

51
00:03:26,740 --> 00:03:30,250
I'm going to talk about these
n minus one people's words.

52
00:03:30,280 --> 00:03:34,990
They're the words on which
were conditioning the
probability of observing the

53
00:03:35,020 --> 00:03:39,670
next word.
So,

54
00:03:39,671 --> 00:03:40,800
uh,
the,

55
00:03:40,801 --> 00:03:45,460
a model which or type of model that is
very frequently used in natural language

56
00:03:45,461 --> 00:03:48,650
processing is known as the engram model.
So first,

57
00:03:48,651 --> 00:03:53,020
let's describe what we mean by Anne Graham
and then drive is just a sequence of

58
00:03:53,110 --> 00:03:57,910
and words that, uh, usually we extract
from some training data from some,

59
00:03:57,990 --> 00:04:01,570
uh, uh, corpus of words. So for instance,

60
00:04:01,780 --> 00:04:06,090
it would just take that sentence
here as our corpus, our,

61
00:04:06,091 --> 00:04:09,250
our training data. Uh, then, uh,

62
00:04:09,340 --> 00:04:13,930
the unigrams that are
contained is what there is, is,

63
00:04:13,990 --> 00:04:16,030
which is right here.
There's a,

64
00:04:16,210 --> 00:04:20,170
there's a sequence and all of the
other individual words in that, uh,

65
00:04:20,230 --> 00:04:22,120
in that sentence,
uh,

66
00:04:22,121 --> 00:04:26,080
examples of backgrounds taken from
that sentence would be as, uh,

67
00:04:26,130 --> 00:04:29,260
because we have is
followed by, uh, here, uh,

68
00:04:29,261 --> 00:04:33,850
also a sequence because we have, uh,
followed by sequence here and so on.

69
00:04:34,360 --> 00:04:39,190
And then try grounds,
which corresponds to an equals three.

70
00:04:39,370 --> 00:04:42,430
And then Graham for any equals
three, uh, when an example is,

71
00:04:42,670 --> 00:04:47,560
is a sequence because we have is a
sequence here, uh, as sequence of,

72
00:04:47,890 --> 00:04:50,560
because we have a sequence
of here and so on.

73
00:04:51,190 --> 00:04:54,790
So that's what an then Graham is really
just a sequence of and words that is

74
00:04:54,940 --> 00:04:59,320
usually extract them from some,
from Beta, remove some ink.

75
00:05:00,190 --> 00:05:01,150
And so,
um,

76
00:05:01,270 --> 00:05:06,270
and then Graham model is going to estimate
the conditional probability that we

77
00:05:06,461 --> 00:05:11,461
need in our mark of model for assigning
the probability of a whole document or

78
00:05:11,831 --> 00:05:16,831
sentence a is going to estimate that
conditional probability based on counts of

79
00:05:16,930 --> 00:05:21,930
and grams that counts that are extracted
from some training corpus of training

80
00:05:22,451 --> 00:05:24,340
data.
Uh,

81
00:05:24,341 --> 00:05:28,300
so specifically if we had a set of words,

82
00:05:28,301 --> 00:05:32,470
the m minus one people's words or the
context and we're monitoring what's the

83
00:05:32,471 --> 00:05:35,920
probability of some given
word that is observed next.

84
00:05:36,280 --> 00:05:38,470
But what we do is that we would count.

85
00:05:38,471 --> 00:05:43,270
So imagine we have dysfunction count that
just contains the number of times that

86
00:05:43,510 --> 00:05:44,500
the context,

87
00:05:44,560 --> 00:05:49,560
so the word from position t minus one t
minus and minus one up to t a w WT minus

88
00:05:52,541 --> 00:05:53,374
one.

89
00:05:53,950 --> 00:05:58,820
So the number of times we've observed
this context followed this word wt.

90
00:05:59,520 --> 00:06:03,380
The probability conditional
probably as a modeled by, uh,

91
00:06:03,400 --> 00:06:07,130
estimated by this model is going
to be proportional to that count.

92
00:06:07,790 --> 00:06:11,900
And then we're going to normalize that
by the number of times we've seen this

93
00:06:11,901 --> 00:06:16,070
context followed by any word.
So by dividing this way,

94
00:06:16,250 --> 00:06:20,630
then we're guaranteed that this
estimate of the probability is about it.

95
00:06:20,631 --> 00:06:22,760
Probability it's going to sum to one.

96
00:06:25,730 --> 00:06:26,563
Yeah.

97
00:06:27,180 --> 00:06:32,180
No [inaudible] models have one particular
problem or challenge that I have to

98
00:06:32,941 --> 00:06:33,890
face.
Uh,

99
00:06:33,891 --> 00:06:38,891
and it's a problem data sparsity so if
you want a good model that's accurate,

100
00:06:39,420 --> 00:06:43,620
that that is close to reality,
a really what we want is,

101
00:06:43,680 --> 00:06:47,190
and to be as large as possible.
Otherwise,

102
00:06:47,250 --> 00:06:49,230
once it's for any equals one,

103
00:06:49,410 --> 00:06:53,220
then we actually assuming that all the
words are independent because then the n

104
00:06:53,221 --> 00:06:57,870
minus one previous words, that's one
minus one. That's the zero previous words.

105
00:06:58,020 --> 00:07:02,070
So we conditioning on no words
before, uh, any word for,

106
00:07:02,350 --> 00:07:03,420
uh,

107
00:07:03,450 --> 00:07:07,590
when we're modeling the probability
of each word in the sentence.

108
00:07:07,591 --> 00:07:10,280
So effectively we're considering
that all the words are independent,

109
00:07:10,310 --> 00:07:14,550
the seeds sequence, which is
of course a very crude, uh,

110
00:07:14,551 --> 00:07:17,760
assumption to make a,
if that any calls to them,

111
00:07:17,761 --> 00:07:20,280
we're just assuming that
if we know one word,

112
00:07:20,290 --> 00:07:23,990
then the distribution of
the next word is, uh, uh,

113
00:07:24,030 --> 00:07:28,800
not influenced by the third word before
or fourth word before then. So on.

114
00:07:29,760 --> 00:07:34,710
Uh, uh, so, uh, so that again is a very
crude approximation. So really we want,

115
00:07:34,711 --> 00:07:37,350
and to be as large as possible
to get a realistic model,

116
00:07:38,460 --> 00:07:40,170
Howard for large values of n,

117
00:07:40,171 --> 00:07:44,430
then it means that when we're estimating
these probabilities in this end grand

118
00:07:44,431 --> 00:07:49,390
model, uh, it's going to be
much more likely that for
some new data and some, uh,

119
00:07:49,470 --> 00:07:53,730
testing corporate for which we are
evaluating the probability of sentences,

120
00:07:54,090 --> 00:07:59,090
it's going to be much more likely that
we will have never seen the exact context

121
00:07:59,340 --> 00:08:04,110
for which we have to
condition for evaluating our
conditional probabilities in

122
00:08:04,111 --> 00:08:07,980
the uh, and grand model. And so, uh,

123
00:08:08,010 --> 00:08:11,550
there are ways of
alleviating this problem. Uh,

124
00:08:11,610 --> 00:08:16,560
essentially they're all variants of this
idea of smoothing the accounts that is,

125
00:08:16,620 --> 00:08:17,890
uh, when we're, for instance,

126
00:08:17,910 --> 00:08:22,910
estimating the probability of some
word given the three previous words.

127
00:08:23,100 --> 00:08:26,010
So we have, uh, uh, for gram here model.

128
00:08:26,390 --> 00:08:30,750
And then instead of just making that
proportional to the number of times we've

129
00:08:30,751 --> 00:08:35,310
seen w one followed by w
two w two and NW for a,

130
00:08:35,311 --> 00:08:36,420
and then normalizing,

131
00:08:36,421 --> 00:08:41,220
we actually have this
probability be proportional
to a combination of the counts

132
00:08:41,670 --> 00:08:46,670
of seeing w one up next
to w two w three and four.

133
00:08:46,980 --> 00:08:50,880
And then combined with the number of
times we've seen just w two followed by w

134
00:08:50,881 --> 00:08:54,690
three w four. And then combine
that also with w three and four.

135
00:08:54,691 --> 00:08:57,360
And then the number of
times we've seen w four.

136
00:08:58,140 --> 00:09:02,370
And so there's a whole literature on ways
of combining these different counts to

137
00:09:02,371 --> 00:09:06,840
get a, a model that doesn't ever
fit as much in generalizes better.

138
00:09:07,770 --> 00:09:11,220
Uh, but, uh, actually
as we'll see, uh, uh,

139
00:09:11,400 --> 00:09:15,150
this only partly solves the problem in
the sense that there's something better

140
00:09:15,151 --> 00:09:16,620
we can do a,

141
00:09:16,621 --> 00:09:20,210
and specifically we'll see a neural
network language model that they cannot

142
00:09:20,220 --> 00:09:21,300
perform this approach.

