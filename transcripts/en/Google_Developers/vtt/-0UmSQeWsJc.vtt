WEBVTT
Kind: captions
Language: en

00:00:01.167 --> 00:00:03.300
Sparks: Good afternoon.
My name's Dave Sparks.

00:00:03.300 --> 00:00:06.167
I'm on the Android team.

00:00:06.167 --> 00:00:09.801
And I'm the technical lead
for the multimedia framework.

00:00:09.801 --> 00:00:15.567
I've been working on Android
since October of 2007.

00:00:15.567 --> 00:00:18.334
But actually, technically,
I started before that,

00:00:18.334 --> 00:00:21.100
because I worked on the MIDI
engine that we're using.

00:00:21.100 --> 00:00:24.667
So I kind of have
a long, vested interest

00:00:24.667 --> 00:00:26.100
in the project.

00:00:26.100 --> 00:00:30.200
So today, we have kind of
an ambitious title,

00:00:30.200 --> 00:00:32.801
called "Mastering
the Media Framework."

00:00:32.801 --> 00:00:36.367
I think the reality is
that if you believe that--

00:00:36.367 --> 00:00:38.567
that we're going
to do that in an hour,

00:00:38.567 --> 00:00:40.734
it's probably pretty ambitious.

00:00:40.734 --> 00:00:42.868
And if you do believe that,

00:00:42.868 --> 00:00:45.200
I have a bridge
just north of here

00:00:45.200 --> 00:00:47.634
that you might be interested in.

00:00:47.634 --> 00:00:50.534
But I think we actually will
be able to cover

00:00:50.534 --> 00:00:52.434
a few kind of
interesting things.

00:00:52.434 --> 00:00:54.701
In thinking
about this topic,

00:00:54.701 --> 00:00:58.267
I wanted to cover stuff
that wasn't really available

00:00:58.267 --> 00:01:00.801
in the SDK,
so we're really going to del--

00:01:00.801 --> 00:01:04.501
delve into the lower parts
of the framework,

00:01:04.501 --> 00:01:06.334
the infrastructure
that basically

00:01:06.334 --> 00:01:07.534
everything's built on.

00:01:07.534 --> 00:01:11.167
Kind of explain
some of the design philosophy.

00:01:11.167 --> 00:01:13.434
So...

00:01:13.434 --> 00:01:15.100
Oh, I guess I should have
put that up first.

00:01:15.100 --> 00:01:17.100
Here we go.

00:01:17.100 --> 00:01:19.901
So on the agenda,

00:01:19.901 --> 00:01:22.868
in the cutesy fashion
of the thing,

00:01:22.868 --> 00:01:26.501
we're talking
about the architecture--

00:01:26.501 --> 00:01:28.501
Frank Lloyd Android.

00:01:28.501 --> 00:01:31.133
What's new
in our Cupcake release,

00:01:31.133 --> 00:01:33.734
which just came out recently.

00:01:33.734 --> 00:01:36.767
And those of you
who have the phone,

00:01:36.767 --> 00:01:39.234
you're running that
on your device today.

00:01:39.234 --> 00:01:41.667
And then a few common problems
that people run into

00:01:41.667 --> 00:01:44.934
when they're writing
applications for the framework.

00:01:44.934 --> 00:01:46.901
And then
there probably will be

00:01:46.901 --> 00:01:48.067
a little bit of time
left over at the end

00:01:48.067 --> 00:01:51.901
for anybody who has questions.

00:01:51.901 --> 00:01:53.200
So moving along,

00:01:53.200 --> 00:01:56.667
we'll start
with the architecture.

00:01:56.667 --> 00:02:00.067
So when we first started
designing the architecture,

00:02:00.067 --> 00:02:02.400
we had some goals in mind.

00:02:02.400 --> 00:02:05.033
One of the things
was to make development

00:02:05.033 --> 00:02:08.467
of applications that use media,
rich media applications,

00:02:08.467 --> 00:02:10.200
very easy to develop.

00:02:10.200 --> 00:02:13.000
And so that was one
of the key goals

00:02:13.000 --> 00:02:15.334
that we wanted to accomplish
in this.

00:02:15.334 --> 00:02:17.100
And I think you'll see it
as we look at the framework.

00:02:17.100 --> 00:02:19.434
It's really simple
to play audio,

00:02:19.434 --> 00:02:22.767
to display a video,
and things like that.

00:02:22.767 --> 00:02:25.434
One of the key things,
because this is

00:02:25.434 --> 00:02:27.968
a multi-tasking
operating system,

00:02:27.968 --> 00:02:30.968
is we have--
you could potentially have

00:02:30.968 --> 00:02:32.200
things happening
in the background.

00:02:32.200 --> 00:02:34.634
For example, you could have
a music player

00:02:34.634 --> 00:02:35.801
playing in the background.

00:02:35.801 --> 00:02:37.734
We need the ability
to share resources

00:02:37.734 --> 00:02:39.567
among all these applications,

00:02:39.567 --> 00:02:41.234
and so that's one
of the key things,

00:02:41.234 --> 00:02:42.634
was to design an architecture

00:02:42.634 --> 00:02:44.934
that could easily
share resources.

00:02:44.934 --> 00:02:47.434
And the other thing is,
you know,

00:02:47.434 --> 00:02:50.634
paramount in Android
is the security model.

00:02:50.634 --> 00:02:54.067
And if you've looked over
the security stuff--

00:02:54.067 --> 00:02:55.701
I'm not sure we had a talk today
on security.

00:02:55.701 --> 00:02:58.400
But security is really important
to us.

00:02:58.400 --> 00:03:01.734
And so we needed a way
to be able to sandbox

00:03:01.734 --> 00:03:03.033
parts of the application
that are--

00:03:03.033 --> 00:03:04.300
that are particularly
vulnerable,

00:03:04.300 --> 00:03:06.067
and I think you'll see
as we look at the--

00:03:06.067 --> 00:03:08.701
the framework,
that it's designed

00:03:08.701 --> 00:03:10.534
to isolate parts of the system

00:03:10.534 --> 00:03:14.133
that are particularly vulnerable
to hacking.

00:03:14.133 --> 00:03:15.934
And then, you know,
providing a way

00:03:15.934 --> 00:03:18.868
to add features in the future

00:03:18.868 --> 00:03:20.200
that are backwards compatible.

00:03:20.200 --> 00:03:24.234
So that's the--
the room for future growth.

00:03:24.234 --> 00:03:27.300
So here's kind of
a 30,000-foot view

00:03:27.300 --> 00:03:30.400
of the way
the media framework works.

00:03:30.400 --> 00:03:33.634
So on the left side,
you'll notice

00:03:33.634 --> 00:03:36.234
that there is the application.

00:03:36.234 --> 00:03:38.634
And the red line--
red dashed line there--

00:03:38.634 --> 00:03:41.400
is denoting
the process boundary.

00:03:41.400 --> 00:03:44.501
So applications run
in one process.

00:03:44.501 --> 00:03:46.133
And the media server
actually runs

00:03:46.133 --> 00:03:48.667
in its own process
that's actually booted up--

00:03:48.667 --> 00:03:50.601
brought up during boot time.

00:03:50.601 --> 00:03:53.701
And so the codecs

00:03:53.701 --> 00:03:57.400
and the file parsers
and the network stack

00:03:57.400 --> 00:03:59.033
and everything that has to do
with playing media

00:03:59.033 --> 00:04:01.834
is actually sitting
in a separate process.

00:04:01.834 --> 00:04:05.133
And then underneath that
are the hardware abstractions

00:04:05.133 --> 00:04:06.767
for the audio and video pass.

00:04:06.767 --> 00:04:09.868
So Surface Flingers are
an abstraction for video

00:04:09.868 --> 00:04:11.734
and graphics.

00:04:11.734 --> 00:04:16.734
And Audio Flinger's
the abstraction for audio.

00:04:16.734 --> 00:04:20.767
So looking at a typical
media function,

00:04:20.767 --> 00:04:22.467
there's a lot of stuff--

00:04:22.467 --> 00:04:24.934
because of this inner process
communication that's going on,

00:04:24.934 --> 00:04:25.968
there's a lot of things
that are involved

00:04:25.968 --> 00:04:28.133
in moving a call
down the stack.

00:04:28.133 --> 00:04:29.667
So I wanted to give you
an idea--

00:04:29.667 --> 00:04:31.434
for those of you who've looked
at the source code,

00:04:31.434 --> 00:04:35.267
it's sometimes hard to follow,
you know, how is a call--

00:04:35.267 --> 00:04:37.067
A question that comes up
quite frequently

00:04:37.067 --> 00:04:39.434
is how does a function call,
like, you know,

00:04:39.434 --> 00:04:40.501
prepare or make its way

00:04:40.501 --> 00:04:42.067
all the way down
to the framework

00:04:42.067 --> 00:04:44.133
and into the--
the media engine?

00:04:44.133 --> 00:04:46.467
So this is kind of
a top-level view

00:04:46.467 --> 00:04:48.434
of what a stack might look like.

00:04:48.434 --> 00:04:52.100
At the very top
is the Dalvik VM proxy.

00:04:52.100 --> 00:04:55.267
So that's the Java object
that you're actually talking to.

00:04:55.267 --> 00:04:57.100
So, for example,
for a media player,

00:04:57.100 --> 00:04:58.868
there's a media player object.

00:04:58.868 --> 00:05:00.968
If you look at
the media player definition,

00:05:00.968 --> 00:05:02.267
it's a pretty--
I mean,

00:05:02.267 --> 00:05:03.300
there's not a lot of code
in Java.

00:05:03.300 --> 00:05:04.601
It's pretty simple.

00:05:04.601 --> 00:05:07.968
And basically,
it's a proxy for--

00:05:07.968 --> 00:05:10.133
in this case, actually,
the native proxy,

00:05:10.133 --> 00:05:11.868
which it's underneath,
and then eventually,

00:05:11.868 --> 00:05:13.667
the actual implementation.

00:05:13.667 --> 00:05:16.734
So from that,
we go through JNI,

00:05:16.734 --> 00:05:18.834
which is
the Java Native Interface.

00:05:18.834 --> 00:05:21.100
And that is just
a little shim layer

00:05:21.100 --> 00:05:22.567
that's static bindings

00:05:22.567 --> 00:05:25.200
to an actual
MediaPlayer object.

00:05:25.200 --> 00:05:28.400
So when you create
a MediaPlayer in Java,

00:05:28.400 --> 00:05:30.801
what you're actually doing
is making a call

00:05:30.801 --> 00:05:32.534
through this JNI layer

00:05:32.534 --> 00:05:34.734
to instantiate a C++ object.

00:05:34.734 --> 00:05:37.400
That's actually
the MediaPlayer.

00:05:37.400 --> 00:05:40.968
And there's a reference to that
that's held in the Java object.

00:05:40.968 --> 00:05:42.467
And then some tricky stuff--

00:05:42.467 --> 00:05:45.501
weak references
to garbage collection

00:05:45.501 --> 00:05:47.534
and stuff like that,
which is a little bit too deep

00:05:47.534 --> 00:05:49.067
for the talk today.

00:05:49.067 --> 00:05:51.167
Like I said, you're not going
to master the framework today,

00:05:51.167 --> 00:05:53.501
but at least get an idea
of what's there.

00:05:53.501 --> 00:05:56.033
So in the native proxy,

00:05:56.033 --> 00:05:59.968
this is actually
a proxy object for the service.

00:05:59.968 --> 00:06:03.100
So there is a little bit of code
in the native code.

00:06:03.100 --> 00:06:05.434
You know, a little bit of logic
in the native code.

00:06:05.434 --> 00:06:07.434
But primarily,
most of the implementation

00:06:07.434 --> 00:06:10.067
is actually sitting down
in this media server process.

00:06:10.067 --> 00:06:13.033
So the native proxy is actually
the C++ object

00:06:13.033 --> 00:06:17.567
that talks through
this binder interface.

00:06:17.567 --> 00:06:19.634
The reason we have
a native proxy

00:06:19.634 --> 00:06:21.534
instead of going directly
through JNI

00:06:21.534 --> 00:06:23.834
is a lot of the other pieces
of the framework does.

00:06:23.834 --> 00:06:26.033
So we wanted to be able
to provide

00:06:26.033 --> 00:06:28.434
access to native applications
in the future

00:06:28.434 --> 00:06:30.501
to use MediaPlayer objects.

00:06:30.501 --> 00:06:32.868
So it makes it
relatively easy,

00:06:32.868 --> 00:06:34.901
because that's something
you'd probably want to do

00:06:34.901 --> 00:06:36.300
with games
and things like that

00:06:36.300 --> 00:06:40.734
that are kind of more natural
to write in native code.

00:06:40.734 --> 00:06:44.367
We wanted to provide
the ability to do that.

00:06:44.367 --> 00:06:46.567
So that's why the native proxy
sits there

00:06:46.567 --> 00:06:49.701
and then the Java layer
just sits on top of that.

00:06:49.701 --> 00:06:52.634
So the binder proxy
and the binder native piece--

00:06:52.634 --> 00:06:57.501
Binder is our abstraction
for inter-process communication.

00:06:57.501 --> 00:06:59.767
Binder, basically,
what it does,

00:06:59.767 --> 00:07:02.234
is it marshals objects across
this process boundary

00:07:02.234 --> 00:07:03.767
through a special kernel driver.

00:07:03.767 --> 00:07:06.801
And through that, we can
do things like move data,

00:07:06.801 --> 00:07:10.100
move file descriptors
that are duped across processes

00:07:10.100 --> 00:07:14.200
so that they can be accessed
by different processes.

00:07:14.200 --> 00:07:17.901
And we can also do something
which--we can share memory

00:07:17.901 --> 00:07:19.334
between processes.

00:07:19.334 --> 00:07:21.801
And this is a really efficient
way of moving data

00:07:21.801 --> 00:07:23.367
back and forth
between the application

00:07:23.367 --> 00:07:25.634
and the media server.

00:07:25.634 --> 00:07:27.767
And this is used extensively

00:07:27.767 --> 00:07:30.567
in Audio Flinger
and Surface Flinger.

00:07:30.567 --> 00:07:33.868
So the binder proxy is basically
the marshalling code

00:07:33.868 --> 00:07:35.701
on the applications side.

00:07:35.701 --> 00:07:40.000
And the binder native code
is the marshalling code

00:07:40.000 --> 00:07:42.901
for the server side
of the process.

00:07:42.901 --> 00:07:45.434
And if you're looking
at all the pieces

00:07:45.434 --> 00:07:47.267
of the framework--
they start with

00:07:47.267 --> 00:07:49.100
mediaplayer.java,
for example--

00:07:49.100 --> 00:07:51.834
there's an android_media...

00:07:51.834 --> 00:07:54.000
_mediaplayer.cpp,

00:07:54.000 --> 00:07:55.467
which is the JNI piece.

00:07:55.467 --> 00:07:57.801
There's a mediaplayer.cpp,

00:07:57.801 --> 00:08:00.567
which is
the native proxy object.

00:08:00.567 --> 00:08:03.801
Then there's an
imediaplayer.cpp,

00:08:03.801 --> 00:08:06.901
which is actually a--
a binder proxy

00:08:06.901 --> 00:08:10.601
and the binder native code
in one chunk.

00:08:10.601 --> 00:08:12.400
So you actually see
the marshalling code

00:08:12.400 --> 00:08:14.801
for both pieces
in that one file.

00:08:14.801 --> 00:08:18.934
And one is called
bpmediaplayer.cpp--

00:08:18.934 --> 00:08:21.467
or, sorry,
BP MediaPlayer object.

00:08:21.467 --> 00:08:23.901
And a BN MediaPlayer object.

00:08:23.901 --> 00:08:25.334
So when you're looking
at that code,

00:08:25.334 --> 00:08:27.834
you can see the piece
that's on the native side--

00:08:27.834 --> 00:08:31.100
the server side
and the proxy.

00:08:31.100 --> 00:08:34.767
And then the final piece
of the puzzle

00:08:34.767 --> 00:08:36.801
is the actual implementation
itself.

00:08:36.801 --> 00:08:39.801
So in the case
of the media server--

00:08:39.801 --> 00:08:42.267
sorry, the MediaPlayer--
there's a MediaPlayer service

00:08:42.267 --> 00:08:45.534
which instantiates
a MediaPlayer object

00:08:45.534 --> 00:08:49.434
in the service that's,
you know, proxied

00:08:49.434 --> 00:08:52.300
in the application by this
other MediaPlayer object.

00:08:52.300 --> 00:08:54.834
That's basically--
each one of the calls

00:08:54.834 --> 00:08:56.234
goes through this stack.

00:08:56.234 --> 00:09:00.834
Now, because the stack is,
you know, fairly lightweight

00:09:00.834 --> 00:09:03.601
in terms of we don't make
a lot of calls through it,

00:09:03.601 --> 00:09:05.467
we can afford a little bit
of overhead here.

00:09:05.467 --> 00:09:08.067
So there's a bit of code
that you go through

00:09:08.067 --> 00:09:10.934
to get to this place,
but once you've started playing,

00:09:10.934 --> 00:09:12.834
and you'll see this
later in the slides,

00:09:12.834 --> 00:09:14.801
you don't have to do
a lot of calls

00:09:14.801 --> 00:09:18.968
to maintain
the application playing.

00:09:18.968 --> 00:09:22.501
So this is actually kind of
a top-level diagram

00:09:22.501 --> 00:09:24.734
of what the media server
process looks like.

00:09:24.734 --> 00:09:26.868
So I've got this media player
service.

00:09:26.868 --> 00:09:30.968
And it can instantiate a number 
of different players.

00:09:30.968 --> 00:09:34.868
So on the left-hand side,
you'll see, bottom,

00:09:34.868 --> 00:09:36.634
we have OpenCORE, Vorbis,
and MIDI.

00:09:36.634 --> 00:09:40.667
And these are three different
media player types.

00:09:40.667 --> 00:09:45.701
So going from the simplest one,
which is the Vorbis player--

00:09:45.701 --> 00:09:48.534
Vorbis basically just plays
Ogg Vorbis files,

00:09:48.534 --> 00:09:50.834
which is a--
we'll get into the specifics

00:09:50.834 --> 00:09:53.901
of the codec, but it's
a psycho-acoustic codec

00:09:53.901 --> 00:09:55.267
that's open sourced.

00:09:55.267 --> 00:09:59.234
We use this for a lot
of our internal sounds,

00:09:59.234 --> 00:10:01.100
because it's very lightweight.

00:10:01.100 --> 00:10:02.934
It's pretty efficient.

00:10:02.934 --> 00:10:06.334
And so we use that
for our ringtones

00:10:06.334 --> 00:10:09.100
and for our application sounds.

00:10:09.100 --> 00:10:11.734
The MIDI player,
a little more complex.

00:10:11.734 --> 00:10:14.267
But basically, it's just
another instantiation

00:10:14.267 --> 00:10:15.434
of a media player.

00:10:15.434 --> 00:10:17.767
These all share
a common interface,

00:10:17.767 --> 00:10:21.067
so if you look at
the MediaPlayer.java interface,

00:10:21.067 --> 00:10:23.467
there's almost, you know,
one-for-one correspondence

00:10:23.467 --> 00:10:25.567
between what you see there
and what's actually happening

00:10:25.567 --> 00:10:27.634
in the players themselves.

00:10:27.634 --> 00:10:29.868
And then the final one
is OpenCORE.

00:10:29.868 --> 00:10:34.501
So anything that isn't
an Ogg file or a MIDI file

00:10:34.501 --> 00:10:37.167
is routed over
to OpenCORE.

00:10:37.167 --> 00:10:39.934
And OpenCORE is basically the--
the bulk of the framework.

00:10:39.934 --> 00:10:42.200
It consists of all
of the major codecs,

00:10:42.200 --> 00:10:45.667
like, you know,
MP3 and AAC and AMR

00:10:45.667 --> 00:10:50.734
and the video codecs,
H.263 and H.264 and AVC.

00:10:50.734 --> 00:10:54.434
So any file that's not
specifically one of those two

00:10:54.434 --> 00:10:56.467
ends up going to OpenCORE
to be played.

00:10:56.467 --> 00:10:58.734
Now, this provides
some extensibility.

00:10:58.734 --> 00:11:00.167
The media player service
is smart enough

00:11:00.167 --> 00:11:02.734
to sort of recognize
these file types.

00:11:02.734 --> 00:11:05.234
And we have a media scanner
that runs at boot time--

00:11:05.234 --> 00:11:06.634
that goes out,
looks at the files,

00:11:06.634 --> 00:11:08.367
figures out what they are.

00:11:08.367 --> 00:11:11.901
And so we can actually,
you know, replace or add

00:11:11.901 --> 00:11:14.534
new player types by just
instantiating

00:11:14.534 --> 00:11:16.000
a new type of player.

00:11:16.000 --> 00:11:19.801
In fact, there are
some projects out there

00:11:19.801 --> 00:11:22.701
where they've replaced OpenCORE
with GStreamer

00:11:22.701 --> 00:11:24.467
or other media frameworks.

00:11:24.467 --> 00:11:27.734
And we're talking
to some other--

00:11:27.734 --> 00:11:31.667
some different types
of player applications

00:11:31.667 --> 00:11:34.167
that might have new codecs
and new file types,

00:11:34.167 --> 00:11:35.467
and that's one way of doing it.

00:11:35.467 --> 00:11:36.968
The other way of doing it
is you--

00:11:36.968 --> 00:11:38.334
if you wanted
to add a new file type,

00:11:38.334 --> 00:11:42.734
you could actually implement it
inside of OpenCORE.

00:11:42.734 --> 00:11:45.167
And then on the right-hand side,

00:11:45.167 --> 00:11:48.200
we have
the media recorder service.

00:11:48.200 --> 00:11:52.434
Prior to--
in the 1.0, 1.1 releases,

00:11:52.434 --> 00:11:54.734
that was basically just
an audio record path.

00:11:54.734 --> 00:11:56.868
In Cupcake, we've added
video recording.

00:11:56.868 --> 00:11:59.601
So this is now integrated
with a camera service.

00:11:59.601 --> 00:12:03.734
And so the media recorder--
again, it's sort of a proxy.

00:12:03.734 --> 00:12:05.868
There's a proxy, um--

00:12:05.868 --> 00:12:08.267
it uses the same sort
of type of thing,

00:12:08.267 --> 00:12:10.334
where there's a media recorder--
media recorder object

00:12:10.334 --> 00:12:11.868
in the Java layer.

00:12:11.868 --> 00:12:15.133
And there's
a media recorder service

00:12:15.133 --> 00:12:18.200
that actually does
the recording.

00:12:18.200 --> 00:12:20.868
And for the actual
authoring engine,

00:12:20.868 --> 00:12:22.467
we're using OpenCORE.

00:12:22.467 --> 00:12:25.234
And it has the--
the encoder side.

00:12:25.234 --> 00:12:27.000
So we've talked about
the decoders,

00:12:27.000 --> 00:12:34.334
and the encoders would be
H.263, H.264, and also AVC.

00:12:34.334 --> 00:12:36.367
Sorry, and MPEG-4 SP.

00:12:36.367 --> 00:12:39.501
And then,
the audio codecs.

00:12:39.501 --> 00:12:42.300
So all those sit
inside of OpenCORE.

00:12:42.300 --> 00:12:45.501
And then the camera service
both operates

00:12:45.501 --> 00:12:47.000
in conjunction
with the media recorder

00:12:47.000 --> 00:12:49.501
and also independently
for still images.

00:12:49.501 --> 00:12:51.234
So if your application wants
to take a still image,

00:12:51.234 --> 00:12:53.434
you instantiate
a camera object,

00:12:53.434 --> 00:12:56.300
which again is just a proxy
for this camera service.

00:12:56.300 --> 00:12:59.501
The camera surface takes care
of handling preview for you,

00:12:59.501 --> 00:13:03.734
so again, we wanted to limit
the amount of traffic

00:13:03.734 --> 00:13:07.067
between the application
and the hardware.

00:13:07.067 --> 00:13:10.167
So this actually provides a way
for the preview frames

00:13:10.167 --> 00:13:11.934
to go directly out
to the display.

00:13:11.934 --> 00:13:14.634
Your application doesn't have
to worry about it,

00:13:14.634 --> 00:13:16.734
it just happens.

00:13:16.734 --> 00:13:18.868
And then in the case
where the media recorder

00:13:18.868 --> 00:13:21.667
is actually doing
video record,

00:13:21.667 --> 00:13:24.400
we take those frames
into the OpenCORE

00:13:24.400 --> 00:13:28.767
and it does the encoding there.

00:13:28.767 --> 00:13:33.634
So kind of looking at what
a media playback session

00:13:33.634 --> 00:13:35.200
would look like.

00:13:35.200 --> 00:13:39.868
The application provides
three main pieces of data.

00:13:39.868 --> 00:13:42.334
It's going to provide
the source URI.

00:13:42.334 --> 00:13:44.801
The "where is this file
coming from."

00:13:44.801 --> 00:13:47.434
It'll either come from
a local file that's on the--

00:13:47.434 --> 00:13:49.100
you know, on the SD card.

00:13:49.100 --> 00:13:51.133
It could come from a resource

00:13:51.133 --> 00:13:53.267
that's in the application,
the .apk,

00:13:53.267 --> 00:13:56.067
or it could come
from a network stream.

00:13:56.067 --> 00:13:58.968
And so the application provides
that information.

00:13:58.968 --> 00:14:02.167
It provides a surface
that basically,

00:14:02.167 --> 00:14:04.334
at the application level,
called a surface view.

00:14:04.334 --> 00:14:07.667
This, at the binder level,
is an ISurface interface,

00:14:07.667 --> 00:14:12.400
which is an abstraction
for the--the view that you see.

00:14:12.400 --> 00:14:14.534
And then it also provides
the audio types,

00:14:14.534 --> 00:14:18.934
so that the hardware knows
where to route the audio.

00:14:18.934 --> 00:14:22.434
So once those
have been established,

00:14:22.434 --> 00:14:24.567
the media server basically
takes care of everything

00:14:24.567 --> 00:14:25.968
from that point on.

00:14:25.968 --> 00:14:29.734
So you--once you have called
the prepare function

00:14:29.734 --> 00:14:31.133
and the start function,

00:14:31.133 --> 00:14:34.400
the frames--video frames,
audio frames, whatever, are--

00:14:34.400 --> 00:14:37.801
they're going to be decoded
inside the media server process.

00:14:37.801 --> 00:14:40.534
And they get output directly
to either Audio Flinger

00:14:40.534 --> 00:14:41.968
or Surface Flinger,
depending on whether

00:14:41.968 --> 00:14:43.868
it's an audio stream
or a video stream.

00:14:43.868 --> 00:14:46.901
And all the synchronization is
handled for you automatically.

00:14:46.901 --> 00:14:48.467
Again, it's a very low overhead.

00:14:48.467 --> 00:14:51.234
There's no data that's flowing
back up to the application

00:14:51.234 --> 00:14:54.400
at this point--it's all
happening inside the hardware.

00:14:54.400 --> 00:14:56.901
One other reason
for doing that

00:14:56.901 --> 00:14:59.434
we mentioned earlier
is that in the case--

00:14:59.434 --> 00:15:02.601
in many cases, for example
the G1 and the Sapphire,

00:15:02.601 --> 00:15:05.400
the device that you guys
got today--

00:15:05.400 --> 00:15:07.868
those devices actually have
hardware codecs.

00:15:07.868 --> 00:15:09.567
And so we're able
to take advantage

00:15:09.567 --> 00:15:12.767
of a DSP that's in the device
to accelerate.

00:15:12.767 --> 00:15:16.968
In the case of,
for example, H.264,

00:15:16.968 --> 00:15:19.734
we can accelerate
the decoded video in there

00:15:19.734 --> 00:15:22.801
and offload some of that
from the main processor.

00:15:22.801 --> 00:15:26.467
And that frees the processor
up to do other things,

00:15:26.467 --> 00:15:29.234
either, you know,
doing sync in the background,

00:15:29.234 --> 00:15:32.033
or just all sorts of things
that it might need--

00:15:32.033 --> 00:15:34.501
you might need
those cycles for.

00:15:34.501 --> 00:15:37.934
So again, that's--
all that is happening

00:15:37.934 --> 00:15:40.534
inside the media server process.

00:15:40.534 --> 00:15:43.534
We don't want to give
applications direct access

00:15:43.534 --> 00:15:45.100
to the hardware,
so it's another good reason

00:15:45.100 --> 00:15:50.701
for putting this inside
the media server process.

00:15:50.701 --> 00:15:52.334
So in the media recorder side,

00:15:52.334 --> 00:15:54.000
we have a similar sort of thing.

00:15:54.000 --> 00:15:55.667
It's a little more complex.

00:15:55.667 --> 00:16:00.033
The application
can either,

00:16:00.033 --> 00:16:02.033
in the case of--

00:16:02.033 --> 00:16:03.968
it can actually create
its own camera

00:16:03.968 --> 00:16:06.767
and then pass that
to the media server

00:16:06.767 --> 00:16:09.300
or it can let the media server
create a camera for it.

00:16:09.300 --> 00:16:11.901
And then the frames
from the camera go directly

00:16:11.901 --> 00:16:14.000
into the encoders.

00:16:14.000 --> 00:16:16.300
It again is going to provide
a surface for the preview,

00:16:16.300 --> 00:16:19.501
so as you're taking your video,
the preview frames are going

00:16:19.501 --> 00:16:21.534
directly to the--
to the display surface

00:16:21.534 --> 00:16:23.601
so you can see
what you're recording.

00:16:23.601 --> 00:16:25.834
And then you can select
an audio source.

00:16:25.834 --> 00:16:29.601
Right now that's just
the microphone input,

00:16:29.601 --> 00:16:32.033
but in the future,
it could be other sources.

00:16:32.033 --> 00:16:34.067
You know, potentially
you could be recording

00:16:34.067 --> 00:16:38.000
from, you know, TV or some--
some other hardware device

00:16:38.000 --> 00:16:40.701
that's on the device.

00:16:40.701 --> 00:16:42.868
And then--so once
you've established that,

00:16:42.868 --> 00:16:47.534
the camera service
will then start feeding frames

00:16:47.534 --> 00:16:50.300
through the camera service
up to the media server

00:16:50.300 --> 00:16:53.100
and then they're pushed out
to the Surface Flinger

00:16:53.100 --> 00:16:57.567
and they're also pushed out
into OpenCORE for encoding.

00:16:57.567 --> 00:17:02.067
And then there's
a file authoring piece

00:17:02.067 --> 00:17:04.534
that actually takes the frames
from audio and video,

00:17:04.534 --> 00:17:07.634
boxes them together,
and writes them out to a file.

00:17:11.400 --> 00:17:15.701
So, get into a little more
detail about the codecs.

00:17:15.701 --> 00:17:18.133
We have a number
of different--

00:17:18.133 --> 00:17:20.400
we have three different
video codecs.

00:17:20.400 --> 00:17:22.367
So one of the questions
that comes a lot--

00:17:22.367 --> 00:17:25.167
comes up a lot
from the forums

00:17:25.167 --> 00:17:27.467
is what kind of codecs
are available,

00:17:27.467 --> 00:17:30.467
what should they be used for,
and things like that.

00:17:30.467 --> 00:17:31.701
So just kind of a little bit
of history

00:17:31.701 --> 00:17:33.033
about the different codecs.

00:17:33.033 --> 00:17:35.868
So H.263 is a codec from--
I think it was--

00:17:35.868 --> 00:17:39.767
came out about 1996,
was when it was standardized.

00:17:39.767 --> 00:17:43.133
It was originally intended
for video conferencing,

00:17:43.133 --> 00:17:45.200
so it's really
low bit-rate stuff.

00:17:45.200 --> 00:17:48.200
You know, designed to go over
an ISDN line

00:17:48.200 --> 00:17:50.267
or something like that.

00:17:50.267 --> 00:17:54.067
So it's actually worked out
pretty well for mobile devices,

00:17:54.067 --> 00:17:56.767
and a lot of mobile devices
support H.263.

00:17:56.767 --> 00:17:59.400
The encoder is pretty simple.

00:17:59.400 --> 00:18:01.167
The decoder
is pretty simple.

00:18:01.167 --> 00:18:05.167
So it's a lightweight kind
of codec for an embedded device.

00:18:05.167 --> 00:18:07.701
It's part of the 3GPP standard.

00:18:07.701 --> 00:18:11.868
So it's adopted by a number
of different manufacturers.

00:18:11.868 --> 00:18:14.968
And it's actually used
by a number of existing

00:18:14.968 --> 00:18:18.033
video sites--
of websites--

00:18:18.033 --> 00:18:19.501
for their encode.

00:18:19.501 --> 00:18:22.300
For example, YouTube--
if you go to, like,

00:18:22.300 --> 00:18:23.901
the m.youtube.com,

00:18:23.901 --> 00:18:27.801
typically you'll end up
at an H.263 stream.

00:18:27.801 --> 00:18:33.934
Because it's supported
on most mobile devices.

00:18:33.934 --> 00:18:38.334
So MPEG-4 SP
was originally designed

00:18:38.334 --> 00:18:40.367
as a replacement
for MPEG-1 and MPEG-2.

00:18:40.367 --> 00:18:45.067
MPEG-1, MPEG-2--fairly early
standardized codecs.

00:18:45.067 --> 00:18:47.567
They wanted to do
something better.

00:18:47.567 --> 00:18:52.434
Again, it has a very simple
encoder model, similar to H.263.

00:18:52.434 --> 00:18:57.968
There's just single frame
references.

00:18:57.968 --> 00:19:00.634
And there's some question
about whether

00:19:00.634 --> 00:19:04.400
it's actually a better codec
or not than H.263,

00:19:04.400 --> 00:19:05.467
even though they're--

00:19:05.467 --> 00:19:07.801
they came out
very close together.

00:19:07.801 --> 00:19:11.868
It's missing
the deblocking filter, so--

00:19:11.868 --> 00:19:13.100
I didn't mention that before.

00:19:13.100 --> 00:19:15.133
H.263 has a deblocking filter.

00:19:15.133 --> 00:19:17.234
If you've ever looked
at video,

00:19:17.234 --> 00:19:21.567
it typically comes out
in, like, 8x8 pixel blocks.

00:19:21.567 --> 00:19:23.801
And you get kind of
a blockiness.

00:19:23.801 --> 00:19:28.033
So there's an in-loop
deblocking filter in H.263,

00:19:28.033 --> 00:19:30.501
which basically smooths
some of those edges out.

00:19:30.501 --> 00:19:34.167
The MPEG-4 SP,
in its basic profile,

00:19:34.167 --> 00:19:35.868
is missing that.

00:19:35.868 --> 00:19:38.100
So it--the quality of MPEG-4,

00:19:38.100 --> 00:19:40.234
some people don't think
it's quite as good,

00:19:40.234 --> 00:19:45.701
even though it came out
at roughly the same time.

00:19:45.701 --> 00:19:49.367
Then the final codec
we support

00:19:49.367 --> 00:19:51.133
is a fairly recent development.

00:19:51.133 --> 00:19:53.734
I think it's a 2003,
or something like that.

00:19:53.734 --> 00:19:56.167
The H.264 AVC codec came out.

00:19:56.167 --> 00:20:01.200
Compression's much better.

00:20:01.200 --> 00:20:03.033
It includes the ability

00:20:03.033 --> 00:20:04.400
to have
multiple reference frames,

00:20:04.400 --> 00:20:06.400
although
on our current platforms,

00:20:06.400 --> 00:20:08.868
we don't actually support that.

00:20:08.868 --> 00:20:12.634
But theoretically, you could get
better compression

00:20:12.634 --> 00:20:14.234
in the main--
what's called the main profile.

00:20:14.234 --> 00:20:16.467
We support base profile.

00:20:16.467 --> 00:20:20.501
It has this mandatory
in-loop deblocking filter

00:20:20.501 --> 00:20:21.734
that I mentioned before,

00:20:21.734 --> 00:20:25.734
which gets rid of the blockiness
in the frames.

00:20:25.734 --> 00:20:27.100
One of the really nice things

00:20:27.100 --> 00:20:29.067
is it has a number
of different profiles.

00:20:29.067 --> 00:20:31.801
And so different devices
support different levels

00:20:31.801 --> 00:20:33.834
of--of profiles.

00:20:33.834 --> 00:20:37.334
It specifies things like
frame sizes, bit rates,

00:20:37.334 --> 00:20:40.300
the--the types
of advanced features

00:20:40.300 --> 00:20:41.701
that it has to support.

00:20:41.701 --> 00:20:43.801
And there's a number
of optional features in there.

00:20:43.801 --> 00:20:45.300
And basically,
each of those levels

00:20:45.300 --> 00:20:49.367
and profiles defines
what's in those codecs.

00:20:49.367 --> 00:20:53.033
It's actually used in a pretty
wide range of things.

00:20:53.033 --> 00:20:57.133
Everything from digital cinema,
now, HDTV broadcasts,

00:20:57.133 --> 00:21:01.133
and we're starting to see it
on mobile devices like the G1.

00:21:01.133 --> 00:21:06.534
When you do a--if you're using
the device itself today,

00:21:06.534 --> 00:21:08.033
and you do a YouTube playback,

00:21:08.033 --> 00:21:09.868
you're actually--
on Wi-Fi,

00:21:09.868 --> 00:21:12.334
you're actually getting
a H.264 stream,

00:21:12.334 --> 00:21:15.834
which is why
it's so much better quality.

00:21:15.834 --> 00:21:19.367
On the downside, it's a lot
more complex than H.263

00:21:19.367 --> 00:21:23.234
because it has these
advanced features in it.

00:21:23.234 --> 00:21:26.033
So it takes a lot more CPU.

00:21:26.033 --> 00:21:29.467
And in the case of the G1,
for example,

00:21:29.467 --> 00:21:31.267
that particular hardware,

00:21:31.267 --> 00:21:33.367
some of the acceleration
happens in the DSP,

00:21:33.367 --> 00:21:35.400
but there's still some stuff
that has to go

00:21:35.400 --> 00:21:39.767
on the application processor.

00:21:39.767 --> 00:21:43.501
On the audio side,
MP3 is pretty--

00:21:43.501 --> 00:21:45.067
everybody's
pretty familiar with.

00:21:45.067 --> 00:21:48.234
It uses what's called
a psycho-acoustic model,

00:21:48.234 --> 00:21:51.067
which is why we get better
compression than a typical,

00:21:51.067 --> 00:21:54.167
you know, straight
compression algorithm.

00:21:54.167 --> 00:21:58.400
So psycho-acoustic means you
look for things in the--

00:21:58.400 --> 00:22:01.267
that are hidden
within the audio.

00:22:01.267 --> 00:22:02.434
There are certain sounds

00:22:02.434 --> 00:22:04.100
that are going to be masked
by other sounds.

00:22:04.100 --> 00:22:06.367
And so the psycho-acoustic model

00:22:06.367 --> 00:22:08.133
will try to pick out
those things,

00:22:08.133 --> 00:22:10.601
get rid of them,
and you get better--

00:22:10.601 --> 00:22:12.601
much better compression there.

00:22:12.601 --> 00:22:14.467
You get approximately
10:1 compression

00:22:14.467 --> 00:22:19.100
over a straight linear PCM
at 128kbits per second,

00:22:19.100 --> 00:22:23.067
which is pretty reasonable,
especially for a mobile device.

00:22:23.067 --> 00:22:26.534
And then if you want to,
you know, be a purist,

00:22:26.534 --> 00:22:30.734
most people figure
you get full sonic transparency

00:22:30.734 --> 00:22:33.133
at about 192kbits per second.

00:22:33.133 --> 00:22:36.601
So that's where most people
won't be able to hear

00:22:36.601 --> 00:22:37.868
the difference between
the original

00:22:37.868 --> 00:22:42.567
and the compressed version.

00:22:42.567 --> 00:22:46.033
For a more advanced codec,

00:22:46.033 --> 00:22:49.033
AAC came out
sometime after MP3.

00:22:49.033 --> 00:22:51.767
It's built on
the same basic principles,

00:22:51.767 --> 00:22:57.267
but it has
much better compression ratios.

00:22:57.267 --> 00:23:02.367
You get sonic transparency
at roughly 128kbits persecond.

00:23:02.367 --> 00:23:07.167
So, you know,
much, much better compression.

00:23:07.167 --> 00:23:11.467
And another mark
that people use

00:23:11.467 --> 00:23:13.601
is 128kbits per second--

00:23:13.601 --> 00:23:17.767
MP3 is roughly equivalent
to 96kbits per second AAC.

00:23:17.767 --> 00:23:20.834
We also find it's--
it's used, commonly used,

00:23:20.834 --> 00:23:22.133
in MPEG-4 streams.

00:23:22.133 --> 00:23:25.701
So if you have an MPEG-4
audio--video stream,

00:23:25.701 --> 00:23:30.067
you're likely to find
an AAC codec with it.

00:23:30.067 --> 00:23:33.501
In the case of our high-quality
YouTube streams,

00:23:33.501 --> 00:23:38.501
they're typically
a 96 kilohertz AAC format.

00:23:42.000 --> 00:23:44.734
And then finally, Ogg Vorbis,
which I'd mentioned earlier,

00:23:44.734 --> 00:23:46.400
we're using
for a lot of our sounds.

00:23:46.400 --> 00:23:48.534
Again, it's another
psycho-acoustic model.

00:23:48.534 --> 00:23:50.934
It's an open source codec,

00:23:50.934 --> 00:23:52.667
so it doesn't have
any patent,

00:23:52.667 --> 00:23:56.968
you know, issues
in terms of licensing--

00:23:56.968 --> 00:24:01.067
whereas any of the other codecs,
if you're selling a device,

00:24:01.067 --> 00:24:02.133
you need to go, you know,

00:24:02.133 --> 00:24:04.734
get the appropriate
patent licenses.

00:24:04.734 --> 00:24:07.133
Or I probably shouldn't
say that,

00:24:07.133 --> 00:24:08.200
because I'm not a lawyer,

00:24:08.200 --> 00:24:12.834
but you should probably
see your lawyer.

00:24:12.834 --> 00:24:15.734
From our perspective,
it's very low overhead.

00:24:15.734 --> 00:24:19.133
It doesn't bring in all
of the OpenCORE framework,

00:24:19.133 --> 00:24:21.334
'cause it's just
an audio codec.

00:24:21.334 --> 00:24:23.901
So it uses--
it's very lightweight

00:24:23.901 --> 00:24:26.167
in terms of the amount
of memory usage it uses

00:24:26.167 --> 00:24:27.601
and also the amount
of code space

00:24:27.601 --> 00:24:29.834
that it has to load in
in order to play a file.

00:24:29.834 --> 00:24:33.200
So that's why we use it
for things like ringtones

00:24:33.200 --> 00:24:35.434
and other things that need
fairly low latency

00:24:35.434 --> 00:24:38.267
and we know we're gonna
use it a lot.

00:24:38.267 --> 00:24:41.367
The other thing is that,
unlike MP3--

00:24:41.367 --> 00:24:46.868
MP3 doesn't have a native way
of specifying a seamless loop.

00:24:46.868 --> 00:24:49.801
For those of you
who aren't audio guy--

00:24:49.801 --> 00:24:52.367
audio experts, "seamless loop"
basically means

00:24:52.367 --> 00:24:55.868
you can play the whole thing
as one seamless,

00:24:55.868 --> 00:24:59.868
no clips, no pops loop
to play over and over again.

00:24:59.868 --> 00:25:02.300
A typical application for that
would be a ringtone,

00:25:02.300 --> 00:25:04.834
where you want it
to continue playing

00:25:04.834 --> 00:25:07.133
the same sound
over and over again

00:25:07.133 --> 00:25:09.534
without--without
the pops and clicks.

00:25:09.534 --> 00:25:12.534
MP3 doesn't have a way to
specify that accurately enough

00:25:12.534 --> 00:25:16.167
that you can actually do that
without having some sort of gap.

00:25:16.167 --> 00:25:20.033
There are people that have added
things in the ID3 tags

00:25:20.033 --> 00:25:21.434
to get around that,
but there isn't

00:25:21.434 --> 00:25:23.267
any standardized way to do it.

00:25:23.267 --> 00:25:26.334
Ogg does it--
actually, both Ogg and AAC

00:25:26.334 --> 00:25:29.934
have conventions for specifying
a seamless loop.

00:25:29.934 --> 00:25:31.868
So that's another reason
why we use Ogg

00:25:31.868 --> 00:25:34.100
is that we can get
that nice seamless loop.

00:25:34.100 --> 00:25:36.734
So if you're doing anything
in a game application

00:25:36.734 --> 00:25:39.734
where you want to get,
you know, some sort of--

00:25:39.734 --> 00:25:41.868
a typical thing would be like
an ambient sound

00:25:41.868 --> 00:25:43.601
that's playing over and over
in the background.

00:25:43.601 --> 00:25:47.501
You know, the factory sound
or, you know,

00:25:47.501 --> 00:25:49.300
some eerie swamp noises
or whatever.

00:25:49.300 --> 00:25:52.267
That's the way to do it
is to use the Ogg file.

00:25:52.267 --> 00:25:54.200
You'll get pretty good
compression.

00:25:54.200 --> 00:25:56.534
It's pretty low overhead
for decoding it.

00:25:56.534 --> 00:26:02.167
And you can get those loops
that won't click.

00:26:02.167 --> 00:26:05.567
And then finally,
the last codecs

00:26:05.567 --> 00:26:07.000
we're going to talk about
in terms of audio

00:26:07.000 --> 00:26:08.968
are the AMR codecs.

00:26:08.968 --> 00:26:12.501
AMR is a speech codec,

00:26:12.501 --> 00:26:15.267
so it doesn't get
the full bandwidth.

00:26:15.267 --> 00:26:19.968
If you ever try to encode one
with music on it,

00:26:19.968 --> 00:26:21.634
it will sound pretty crappy.

00:26:21.634 --> 00:26:24.501
That's because it--
it wants to kind of focus in

00:26:24.501 --> 00:26:26.267
on one central tone.

00:26:26.267 --> 00:26:28.634
That's how it gets
its high compression rate.

00:26:28.634 --> 00:26:31.634
But at the same time,
it throws away a lot of audio.

00:26:31.634 --> 00:26:34.767
So it's typically used
for video codecs.

00:26:34.767 --> 00:26:38.300
And in fact,
GSM basically is based

00:26:38.300 --> 00:26:41.367
on AMR-type codecs.

00:26:41.367 --> 00:26:44.234
It's--the input is,

00:26:44.234 --> 00:26:46.734
for the AMR narrow band,
is 8 kilohertz.

00:26:46.734 --> 00:26:49.734
So going back to Nyquist,
that basically means

00:26:49.734 --> 00:26:51.534
your highest frequency
you can represent

00:26:51.534 --> 00:26:54.434
is just shy of 4 kilohertz.

00:26:54.434 --> 00:26:57.934
And the output bit-rates
are, you know,

00:26:57.934 --> 00:27:03.434
anywhere from just under
5kbits per second up to 12.2.

00:27:03.434 --> 00:27:07.701
AMR wide band is a little bit
better quality.

00:27:07.701 --> 00:27:10.868
It's got a 16 kilohertz input,
and slightly higher bandwidths.

00:27:10.868 --> 00:27:14.267
But again,
it's a speech codec primarily,

00:27:14.267 --> 00:27:17.667
and so you're not going to get
great audio out of it.

00:27:17.667 --> 00:27:21.567
We do use these,
because in the package,

00:27:21.567 --> 00:27:25.100
the OpenCORE package,
the AMR narrow band codec

00:27:25.100 --> 00:27:26.701
is the only audio encoder--

00:27:26.701 --> 00:27:28.701
native audio encoder
we have in software.

00:27:28.701 --> 00:27:32.467
So if your hardware platform
doesn't have an encoder,

00:27:32.467 --> 00:27:35.133
that's kind of
the fallback codec.

00:27:35.133 --> 00:27:39.501
And in fact, if you use
the audio recorder application

00:27:39.501 --> 00:27:41.734
like MMS,
and attach an audio,

00:27:41.734 --> 00:27:43.467
this is the codec
you're going to get.

00:27:43.467 --> 00:27:45.133
If you do a video record
today,

00:27:45.133 --> 00:27:46.834
that's the codec
you're going to get.

00:27:46.834 --> 00:27:50.167
We're expecting that future
hardware platforms

00:27:50.167 --> 00:27:53.601
will provide, you know,
native encoders for AAC.

00:27:53.601 --> 00:27:55.968
It's a little too heavy
to do AAC

00:27:55.968 --> 00:27:57.501
on the application processor

00:27:57.501 --> 00:27:59.667
while you're doing video record
and everything else.

00:27:59.667 --> 00:28:01.834
So we really need
the acceleration

00:28:01.834 --> 00:28:03.534
in order to do it.

00:28:03.534 --> 00:28:08.167
AMR is specified
in 3GPP streams.

00:28:08.167 --> 00:28:13.501
So most phones
that will decode an H.263

00:28:13.501 --> 00:28:14.834
will also decode the AMR.

00:28:14.834 --> 00:28:16.634
So it's a fairly compatible
format.

00:28:16.634 --> 00:28:19.634
If you look at the--the other
phones that are out there

00:28:19.634 --> 00:28:21.501
that support, you know,
video playback,

00:28:21.501 --> 00:28:24.100
they typically
will support AMR as well.

00:28:27.567 --> 00:28:30.968
So we've talked about codecs.

00:28:30.968 --> 00:28:32.734
Both audio and video codecs.

00:28:32.734 --> 00:28:35.567
The other piece of it,
when you're doing a stream,

00:28:35.567 --> 00:28:38.434
is what's the container format?

00:28:38.434 --> 00:28:41.767
And so I'm going to talk
a little bit about that.

00:28:41.767 --> 00:28:45.834
So 3GPP is the stream
that's defined

00:28:45.834 --> 00:28:47.734
by the 3GPP organization.

00:28:47.734 --> 00:28:49.834
These are phones that support
that standard

00:28:49.834 --> 00:28:51.801
and are going to support
these types of files.

00:28:51.801 --> 00:28:55.501
3GPP is actually
an MPEG-4 file format.

00:28:55.501 --> 00:28:58.534
But it's--very, very
restricted set of--

00:28:58.534 --> 00:29:02.834
of things that
you can put into that file,

00:29:02.834 --> 00:29:05.534
designed for compatibility
with these embedded devices.

00:29:05.534 --> 00:29:09.701
So you really want to use
a H.263 video codec

00:29:09.701 --> 00:29:14.400
for--for broad compatibility
across a number of phones.

00:29:14.400 --> 00:29:17.467
You probably want to use
a low bit rate for the video,

00:29:17.467 --> 00:29:20.300
typically like 192kbits
per second.

00:29:20.300 --> 00:29:23.868
And you also want to use
the AMR narrow band codec.

00:29:27.400 --> 00:29:32.200
For MPEG-4 streams,
which we also support,

00:29:32.200 --> 00:29:34.000
they're typically
higher quality.

00:29:34.000 --> 00:29:36.067
They typically
are going to use

00:29:36.067 --> 00:29:43.534
either an H.264 or a higher--
bigger size H.263 format.

00:29:43.534 --> 00:29:45.801
Usually they use
an AAC codec.

00:29:45.801 --> 00:29:48.000
And then
on our particular devices,

00:29:48.000 --> 00:29:52.534
the G1 and the device
that you just received today--

00:29:52.534 --> 00:29:54.501
I'm not even sure
what we're calling it--

00:29:54.501 --> 00:29:55.868
I--

00:29:55.868 --> 00:30:00.200
is capable of
up to 500kbits per second

00:30:00.200 --> 00:30:02.100
on the video side

00:30:02.100 --> 00:30:04.234
and 96kbits per second.

00:30:04.234 --> 00:30:06.901
So a total of about
600kbits per second,

00:30:06.901 --> 00:30:08.868
sustained.

00:30:08.868 --> 00:30:10.834
If you do your encoding well,

00:30:10.834 --> 00:30:13.667
you're going to actually
get more than that out of it.

00:30:13.667 --> 00:30:15.334
We've actually been able
to do better

00:30:15.334 --> 00:30:17.501
than 1 megabit per second,
but you have to be--

00:30:17.501 --> 00:30:19.300
have a really good encoder.

00:30:19.300 --> 00:30:21.801
If it gets "burst-y,"
it will interfere

00:30:21.801 --> 00:30:24.801
with the performance
of the codec.

00:30:28.801 --> 00:30:32.234
So one question that comes up
a lot on the forums

00:30:32.234 --> 00:30:34.634
is what container
should I use

00:30:34.634 --> 00:30:38.634
if I'm either authoring
or if I'm doing video recording?

00:30:38.634 --> 00:30:41.334
So for authoring
for our Android device,

00:30:41.334 --> 00:30:43.067
if you want
the best quality--

00:30:43.067 --> 00:30:45.868
the most bang for your bits,
so to speak--

00:30:45.868 --> 00:30:48.200
you want to use
an MPEG-4 codec--

00:30:48.200 --> 00:30:53.267
er, container file
with an H.264 encoded stream.

00:30:53.267 --> 00:30:57.267
It needs to be,
for these devices today,

00:30:57.267 --> 00:31:01.634
a baseline profile roughly,
as I was saying before,

00:31:01.634 --> 00:31:06.067
at 500kbits per second HVGA
or smaller,

00:31:06.067 --> 00:31:09.501
and AAC codec
up to 96kbits per second.

00:31:09.501 --> 00:31:11.334
That will get you
a pretty high quality--

00:31:11.334 --> 00:31:12.968
that's basically
the screen resolution.

00:31:12.968 --> 00:31:19.200
So it looks really good on--
on the display.

00:31:19.200 --> 00:31:22.334
For other--

00:31:22.334 --> 00:31:25.634
you're going to create content
on an Android device,

00:31:25.634 --> 00:31:28.534
so you have a video record
application, for example.

00:31:28.534 --> 00:31:31.934
And you want to be able
to send that via MMS

00:31:31.934 --> 00:31:35.267
or some other email or whatever
to another phone,

00:31:35.267 --> 00:31:37.767
you probably want to stick
to a 3GPP format,

00:31:37.767 --> 00:31:41.200
because not all phones
will support an MPEG-4 stream,

00:31:41.200 --> 00:31:43.567
particularly
the advanced codecs.

00:31:43.567 --> 00:31:49.567
So in that case
we recommend...

00:31:49.567 --> 00:31:51.701
I'm getting
ahead of myself here.

00:31:51.701 --> 00:31:54.968
So in that case we recommend
using the QCIF format.

00:31:54.968 --> 00:31:59.200
That's 192kbits per second.

00:31:59.200 --> 00:32:02.267
Now, if you're
creating content

00:32:02.267 --> 00:32:04.467
on the Android device itself,

00:32:04.467 --> 00:32:06.868
intended for another
Android device,

00:32:06.868 --> 00:32:09.667
we have an H.263 encoder.

00:32:09.667 --> 00:32:12.501
We don't have an H.264 encoder,

00:32:12.501 --> 00:32:14.701
so you're restricted to H.263.

00:32:14.701 --> 00:32:16.501
And for the same reason
I've discussed before,

00:32:16.501 --> 00:32:17.901
we won't have an AAC encoder,

00:32:17.901 --> 00:32:20.267
so you're going to use
an AMR narrow band encoder,

00:32:20.267 --> 00:32:23.467
at least on the current range
of devices.

00:32:23.467 --> 00:32:25.801
So those are kind of
the critical things

00:32:25.801 --> 00:32:30.033
in terms of inter-operability
with other devices.

00:32:30.033 --> 00:32:32.501
And then the other thing is--
a question that comes up a lot

00:32:32.501 --> 00:32:35.834
is if I want to stream
to an Android device,

00:32:35.834 --> 00:32:38.000
what do I need to do
to make that work?

00:32:38.000 --> 00:32:41.934
The thing where most people
fail on that

00:32:41.934 --> 00:32:46.467
is the "moov" atom,
which is the index of frames

00:32:46.467 --> 00:32:49.100
that tells--basically tells
the organization of the file,

00:32:49.100 --> 00:32:54.234
needs to precede the data--
the movie data atom.

00:32:54.234 --> 00:32:59.534
And...the...

00:32:59.534 --> 00:33:01.934
Most applications
will not do that naturally.

00:33:01.934 --> 00:33:04.501
I mean, it's more--
it's easier for a programmer

00:33:04.501 --> 00:33:07.234
to write something that builds
that index afterwards.

00:33:07.234 --> 00:33:08.467
So you have--
you typically have

00:33:08.467 --> 00:33:11.534
to give it a specific--
you know,

00:33:11.534 --> 00:33:12.901
turn something on,

00:33:12.901 --> 00:33:14.267
depending on what
the application is,

00:33:14.267 --> 00:33:15.934
or if you're using FFmpeg,

00:33:15.934 --> 00:33:18.367
you have to give it
a command line option

00:33:18.367 --> 00:33:20.267
that tell it to--
to put that atom

00:33:20.267 --> 00:33:22.601
at the beginning
instead of the end.

00:33:26.868 --> 00:33:30.267
So...

00:33:30.267 --> 00:33:33.901
For--we just recently came out
with what we've been calling

00:33:33.901 --> 00:33:36.534
the Cupcake release,
or the 1.5 release.

00:33:36.534 --> 00:33:39.200
That's the release
that's on the phones

00:33:39.200 --> 00:33:41.067
you just received today.

00:33:41.067 --> 00:33:45.033
Some of the new features
we added in the media framework.

00:33:45.033 --> 00:33:47.968
We talked about
video recording before.

00:33:47.968 --> 00:33:52.367
We added
an AudioTrack interface

00:33:52.367 --> 00:33:54.868
and an AudioRecord interface
in Java,

00:33:54.868 --> 00:33:57.501
which allows direct access
to raw audio.

00:33:57.501 --> 00:34:00.133
And we added the JET
interactive MIDI engine.

00:34:00.133 --> 00:34:02.133
These are kind of the--
the highlights

00:34:02.133 --> 00:34:03.968
in the media framework area.

00:34:03.968 --> 00:34:08.434
So kind of digging
into the specifics here...

00:34:08.434 --> 00:34:11.467
AudioTrack--
we've had a lot of requests

00:34:11.467 --> 00:34:15.467
for getting
direct access to audio.

00:34:15.467 --> 00:34:18.300
And...so what AudioTrack does
is allow you

00:34:18.300 --> 00:34:21.367
to write a raw stream
from Java

00:34:21.367 --> 00:34:25.000
directly to the Audio Flinger
mixer engine.

00:34:25.000 --> 00:34:28.367
Audio Flinger
is a software mixer engine

00:34:28.367 --> 00:34:31.634
that abstracts the hardware
interface for you.

00:34:31.634 --> 00:34:35.100
So it could actually--
it could mix multiple streams

00:34:35.100 --> 00:34:37.734
from different applications.

00:34:37.734 --> 00:34:39.400
To give you an example,

00:34:39.400 --> 00:34:41.801
you could be listening
to an MP3 file

00:34:41.801 --> 00:34:43.367
while the phone rings.

00:34:43.367 --> 00:34:45.601
And the ringtone will play

00:34:45.601 --> 00:34:47.834
while the MP3 file
is still playing.

00:34:47.834 --> 00:34:51.267
Or a game could have
multiple sound effects

00:34:51.267 --> 00:34:52.767
that are all playing
at the same time.

00:34:52.767 --> 00:34:55.100
And the mixer engine takes care
of that automatically for you.

00:34:55.100 --> 00:34:57.534
You don't have to write
a special mixer engine.

00:34:57.534 --> 00:35:00.200
It's in--
built into the device.

00:35:00.200 --> 00:35:03.601
Potentially could be hardware
accelerated in the future.

00:35:03.601 --> 00:35:07.100
And it also allows you
to...

00:35:07.100 --> 00:35:09.100
It does sample rate conversion
for you.

00:35:09.100 --> 00:35:12.100
So you can mix multiple streams
at different sample rates.

00:35:12.100 --> 00:35:15.300
You can modify the pitch
and so on and so forth.

00:35:15.300 --> 00:35:19.100
So what AudioTrack does,
it gives you direct access

00:35:19.100 --> 00:35:20.367
to that mixer engine.

00:35:20.367 --> 00:35:24.367
So you can take
a raw Java stream,

00:35:24.367 --> 00:35:27.200
you know, 16-bit PCM samples,
for example,

00:35:27.200 --> 00:35:28.567
and you can--
you can send that out

00:35:28.567 --> 00:35:30.234
to the mixer engine.

00:35:30.234 --> 00:35:32.701
Have it do the sample rate
conversion for you.

00:35:32.701 --> 00:35:34.701
Do volume control for you.

00:35:34.701 --> 00:35:37.934
It does--
has anti-zipper volume filters

00:35:37.934 --> 00:35:40.934
so--if anybody's ever played
with audio before,

00:35:40.934 --> 00:35:43.701
if you change the volume,

00:35:43.701 --> 00:35:46.067
it changes the volume
in discrete steps

00:35:46.067 --> 00:35:49.601
so you don't get
the pops or clicks

00:35:49.601 --> 00:35:53.167
or what we typically refer to
as zipper noise.

00:35:53.167 --> 00:35:56.801
And that's all done
with...

00:35:56.801 --> 00:36:00.234
Either you can do writes
on a thread in Java,

00:36:00.234 --> 00:36:05.734
or you can use the callback
engine to fill the buffer.

00:36:05.734 --> 00:36:10.000
Similarly, AudioRecord gives you
direct access to the microphone.

00:36:10.000 --> 00:36:12.300
So in the same sort of way,

00:36:12.300 --> 00:36:14.167
you could pull up a stream
from the microphone.

00:36:14.167 --> 00:36:17.033
You specify the sample rate
you want it in.

00:36:17.033 --> 00:36:18.501
And, you know,
with the combination

00:36:18.501 --> 00:36:19.734
of the two of those,

00:36:19.734 --> 00:36:22.734
you can now take a stream
from the microphone,

00:36:22.734 --> 00:36:25.601
do some processing on it,
and now put it back out

00:36:25.601 --> 00:36:27.267
via the...

00:36:27.267 --> 00:36:31.567
the AudioTrack interface too,
that mixer engine.

00:36:31.567 --> 00:36:34.901
And that mixer engine will go
wherever audio is routed.

00:36:34.901 --> 00:36:37.100
So, for example,
a question that comes up

00:36:37.100 --> 00:36:39.801
a lot is, well, what if
they have a Bluetooth device?

00:36:39.801 --> 00:36:41.701
Well, that's actually
handled for you automatically.

00:36:41.701 --> 00:36:44.067
There's nothing you have to do
as an application programmer.

00:36:44.067 --> 00:36:50.000
If there's a Bluetooth device
paired that supports A2DP,

00:36:50.000 --> 00:36:51.601
then that audio
is going to go directly

00:36:51.601 --> 00:36:54.501
to the...to the A2DP headset.

00:36:54.501 --> 00:36:58.801
Your...whether it's a headset
or even your car or whatever.

00:36:58.801 --> 00:37:02.367
And then we've got
this call mack--

00:37:02.367 --> 00:37:05.000
callback mechanism
so you can actually

00:37:05.000 --> 00:37:07.267
just set up a buffer
and just keep--

00:37:07.267 --> 00:37:08.834
when you get a callback,
you fill it.

00:37:08.834 --> 00:37:10.701
You know, if you're doing
a ping-pong buffer,

00:37:10.701 --> 00:37:13.334
where you have half of it
being filled

00:37:13.334 --> 00:37:16.734
and the other half is actually
being output to the device.

00:37:16.734 --> 00:37:18.901
And there's also
a static buffer mode

00:37:18.901 --> 00:37:21.868
where you give it a--
for example,

00:37:21.868 --> 00:37:23.334
a sound effect
that you want to play

00:37:23.334 --> 00:37:25.234
and it only does a single copy.

00:37:25.234 --> 00:37:27.601
And then it just
automatically mixes it,

00:37:27.601 --> 00:37:29.033
so each time
you trigger the sound,

00:37:29.033 --> 00:37:30.734
it will mix it for you,

00:37:30.734 --> 00:37:33.634
and you don't have to do
additional memory copies.

00:37:33.634 --> 00:37:35.934
So those are kind of
the big highlights

00:37:35.934 --> 00:37:40.067
in terms of the--
the audio pieces of it.

00:37:40.067 --> 00:37:44.601
Then another new piece
that's actually been in there

00:37:44.601 --> 00:37:47.667
for a while, but we've finally
implemented the Java support,

00:37:47.667 --> 00:37:50.667
is the JET Interactive
MIDI Engine.

00:37:50.667 --> 00:37:53.667
So JET is--

00:37:53.667 --> 00:37:57.834
it's based upon
the EAS MIDI engine.

00:37:57.834 --> 00:38:01.367
And what it does is allow you
to pre-author some content

00:38:01.367 --> 00:38:04.133
that is very interactive.

00:38:04.133 --> 00:38:06.801
So what you do
is you,

00:38:06.801 --> 00:38:09.868
if you're an author,
you're going to create content

00:38:09.868 --> 00:38:12.667
in a--
your favorite authoring tool.

00:38:12.667 --> 00:38:14.501
Digital authoring
workstation tool.

00:38:14.501 --> 00:38:17.934
It has a VST plugin,
so that you can, you know,

00:38:17.934 --> 00:38:20.868
basically write your--
your game code--

00:38:20.868 --> 00:38:23.834
your--your audio
in the tool

00:38:23.834 --> 00:38:28.334
and hear it back played as it
would be played on the device.

00:38:28.334 --> 00:38:31.701
You can take and have
multiple tracks

00:38:31.701 --> 00:38:35.033
that are synchronized
and mute them and unmute them

00:38:35.033 --> 00:38:37.234
synchronous with the segment.

00:38:37.234 --> 00:38:40.300
So basically, your piece
is going to be divided up into

00:38:40.300 --> 00:38:42.033
a bunch of little segments.

00:38:42.033 --> 00:38:43.901
And just as an example,

00:38:43.901 --> 00:38:47.234
I might have an A section,
like the intro,

00:38:47.234 --> 00:38:49.701
and maybe I have a verse
and I have a chorus.

00:38:49.701 --> 00:38:52.400
And I can interactively
get those to place

00:38:52.400 --> 00:38:53.934
one after another.

00:38:53.934 --> 00:38:58.667
So, for example,
if I have a game that, um--

00:38:58.667 --> 00:39:02.267
it has kind of levels,
I might start with

00:39:02.267 --> 00:39:05.501
a certain background noise,
and perhaps, you know,

00:39:05.501 --> 00:39:06.801
my character's taking damage.

00:39:06.801 --> 00:39:09.300
So I bring in
some little element

00:39:09.300 --> 00:39:12.234
that heightens the tension
in the game

00:39:12.234 --> 00:39:13.801
and this
is all done seamlessly.

00:39:13.801 --> 00:39:17.901
And it's very small content,
because it's MIDI.

00:39:17.901 --> 00:39:19.834
And then you can actually have
little flourishes

00:39:19.834 --> 00:39:22.133
that play in synchronization
with it--

00:39:22.133 --> 00:39:23.434
with the music
that's going on.

00:39:23.434 --> 00:39:27.033
So some--for example,
let's say you, you know,

00:39:27.033 --> 00:39:29.133
you take out an enemy.

00:39:29.133 --> 00:39:31.901
There's a little trumpet sound
or whatever.

00:39:31.901 --> 00:39:33.400
A sound effect
that's synchronized

00:39:33.400 --> 00:39:36.734
with the rest of the--
the audio that's playing.

00:39:36.734 --> 00:39:40.434
Now all this is done under--
under program control.

00:39:40.434 --> 00:39:42.200
In addition to that,
you also have the ability

00:39:42.200 --> 00:39:44.767
to have callbacks
that are synchronized.

00:39:44.767 --> 00:39:47.901
So a good example would be
a &lt;i&gt;Guitar Hero&lt;/i&gt; type game

00:39:47.901 --> 00:39:51.234
where you have music
playing in the background.

00:39:51.234 --> 00:39:53.400
What you really want to do
is have the player

00:39:53.400 --> 00:39:56.701
do something in synchronization
with the rhythm of the sound.

00:39:56.701 --> 00:39:59.267
So you can get a callback
in your Java application

00:39:59.267 --> 00:40:01.734
that tells you when
a particular event occurred.

00:40:01.734 --> 00:40:05.634
So you could create
these tracks of--of events

00:40:05.634 --> 00:40:07.701
that you've been--
you know, measured--

00:40:07.701 --> 00:40:10.000
did they hit
before or after?

00:40:10.000 --> 00:40:12.267
And we actually have
a sample application

00:40:12.267 --> 00:40:14.567
in the SDK that shows you
how to do this.

00:40:14.567 --> 00:40:18.234
It's a--I think a, like,
two- or three-level game

00:40:18.234 --> 00:40:20.467
that with--
complete with graphics

00:40:20.467 --> 00:40:26.100
and sound and everything
to show you how to do it.

00:40:26.100 --> 00:40:28.400
The code--the code itself
is written in native code

00:40:28.400 --> 00:40:29.901
that's sitting on top
of the EAS engine,

00:40:29.901 --> 00:40:33.234
so again, in keeping
with our philosophy

00:40:33.234 --> 00:40:35.100
of trying to minimize the--

00:40:35.100 --> 00:40:37.300
the overhead
from the application,

00:40:37.300 --> 00:40:38.868
this is all happening
in background.

00:40:38.868 --> 00:40:41.100
You don't have to do anything
to keep it going

00:40:41.100 --> 00:40:44.100
other than
keep feeding it segments.

00:40:44.100 --> 00:40:45.934
So periodically,
you're going to wake up and say,

00:40:45.934 --> 00:40:48.968
"Oh, well, here's the next
segment of audio to play,"

00:40:48.968 --> 00:40:50.634
and then it will play
automatically

00:40:50.634 --> 00:40:53.968
for whatever the length
of that segment is.

00:40:53.968 --> 00:40:56.601
It's all open source.

00:40:56.601 --> 00:40:58.968
Not only is the--
the code itself open source,

00:40:58.968 --> 00:41:00.801
but the tools are open sourced,

00:41:00.801 --> 00:41:03.801
including the VST plugin.

00:41:03.801 --> 00:41:05.501
So if you are ambitious

00:41:05.501 --> 00:41:07.467
and you want to do something
interesting with it,

00:41:07.467 --> 00:41:10.968
it's all sitting out there
for you to play with.

00:41:10.968 --> 00:41:13.601
I think it's out there now.

00:41:13.601 --> 00:41:16.167
If not, it will be shortly.

00:41:16.167 --> 00:41:20.067
And so those are
the big highlights of the--

00:41:20.067 --> 00:41:25.934
the MIDI--
the MIDI engine.

00:41:25.934 --> 00:41:27.367
Oh, I forgot.
One more thing.

00:41:27.367 --> 00:41:30.601
The DLS support--
so one of the critiques

00:41:30.601 --> 00:41:32.934
of general MIDI,
or MIDI in general,

00:41:32.934 --> 00:41:34.334
is the quality
of the instruments.

00:41:34.334 --> 00:41:37.400
And admittedly, what we ship
with the device is pretty small.

00:41:37.400 --> 00:41:39.734
We try to keep
the code size down.

00:41:39.734 --> 00:41:42.701
But what the DLS support
does with JET

00:41:42.701 --> 00:41:45.667
is allow you
to load your own samples.

00:41:45.667 --> 00:41:48.567
So you can either
author them yourself

00:41:48.567 --> 00:41:50.133
or you can go
to a content provider

00:41:50.133 --> 00:41:51.868
and author these things.

00:41:51.868 --> 00:41:53.634
So if you want
a high-quality piano

00:41:53.634 --> 00:41:55.567
or you want, you know,
a particular drum set,

00:41:55.567 --> 00:41:58.100
you're going for a techno sound
or whatever,

00:41:58.100 --> 00:41:59.601
you can actually, you know,

00:41:59.601 --> 00:42:01.167
put these things
inside the game,

00:42:01.167 --> 00:42:02.334
use them as a resource,

00:42:02.334 --> 00:42:05.133
load them in and--
and your game will have

00:42:05.133 --> 00:42:06.834
a unique flavor
that you don't get

00:42:06.834 --> 00:42:08.467
from the general MIDI set.

00:42:13.267 --> 00:42:16.000
So...

00:42:16.000 --> 00:42:18.367
I wanted to talk about
a few common problems

00:42:18.367 --> 00:42:20.434
that people run into.

00:42:20.434 --> 00:42:21.801
Start with the first one here.

00:42:21.801 --> 00:42:24.267
This one I see a lot.

00:42:24.267 --> 00:42:27.701
And that is the behavior
of the application

00:42:27.701 --> 00:42:31.534
for the volume control is--
is inconsistent.

00:42:31.534 --> 00:42:34.701
So, volume control
on Android devices

00:42:34.701 --> 00:42:36.534
is an overloaded function.

00:42:36.534 --> 00:42:39.868
And as you can see
from here,

00:42:39.868 --> 00:42:42.868
if you're in a call,
what the volume control does

00:42:42.868 --> 00:42:44.434
is adjust the volume
that you're hearing

00:42:44.434 --> 00:42:46.067
from the other end
of the phone.

00:42:46.067 --> 00:42:48.834
If you're not in a call,
if it's ringing,

00:42:48.834 --> 00:42:52.634
pressing the volume button
mutes the--the ringer.

00:42:52.634 --> 00:42:53.868
Oh, panic.

00:42:53.868 --> 00:42:56.901
I'm in a, you know,
middle of a presentation

00:42:56.901 --> 00:42:58.567
and my phone goes off.

00:42:58.567 --> 00:43:00.934
So that's how you mute it.

00:43:00.934 --> 00:43:03.667
If we can detect
that a media track is active,

00:43:03.667 --> 00:43:07.400
then we'll adjust the volume
of whatever is playing.

00:43:07.400 --> 00:43:11.267
But otherwise,
it adjusts the ringtone volume.

00:43:11.267 --> 00:43:13.868
The issue here is that if your--
if your game is--

00:43:13.868 --> 00:43:17.367
or your application is just
sporadically making sounds,

00:43:17.367 --> 00:43:20.133
like, you know,
you just have little UI elements

00:43:20.133 --> 00:43:22.934
or you play a sound effect
periodically,

00:43:22.934 --> 00:43:26.067
you can only adjust the volume
of the application

00:43:26.067 --> 00:43:28.601
during that short period
that the sound is playing.

00:43:28.601 --> 00:43:30.200
It's because we don't
actually know

00:43:30.200 --> 00:43:33.667
that you're going to make sound
until that particular instant.

00:43:33.667 --> 00:43:36.968
So if you want
to make it work correctly,

00:43:36.968 --> 00:43:42.000
there's an--
there's an API you need to call.

00:43:42.000 --> 00:43:46.634
It's in--it's part
of the activity package.

00:43:46.634 --> 00:43:48.834
It's called
setVolumeControlStream.

00:43:48.834 --> 00:43:51.200
So you can see a little chunk
of code here.

00:43:51.200 --> 00:43:52.801
In your onCreate,

00:43:52.801 --> 00:43:55.968
you're going to call this
setVolumeControlStream

00:43:55.968 --> 00:43:59.300
and tell it what kind of stream
you're going to play.

00:43:59.300 --> 00:44:03.033
In the case of most applications
that are in the foreground,

00:44:03.033 --> 00:44:04.100
that are playing audio,

00:44:04.100 --> 00:44:05.734
you probably want
streamed music,

00:44:05.734 --> 00:44:08.334
which is kind of
our generic placeholder

00:44:08.334 --> 00:44:11.534
for, you know, audio
that's in the foreground.

00:44:11.534 --> 00:44:14.934
If your ringtone application,
for some--

00:44:14.934 --> 00:44:16.300
you know,
you're playing ringtones,

00:44:16.300 --> 00:44:18.200
and you would select
a different type.

00:44:18.200 --> 00:44:20.167
But this basically tells
the activity manager,

00:44:20.167 --> 00:44:22.100
when you press the audio button,

00:44:22.100 --> 00:44:27.634
if none of those...

00:44:27.634 --> 00:44:30.968
previous things are--
in other words,

00:44:30.968 --> 00:44:32.968
if we're not in call,
if it's not ringing,

00:44:32.968 --> 00:44:34.567
and if there's--
if--

00:44:34.567 --> 00:44:36.200
if none of these other things
are happening,

00:44:36.200 --> 00:44:38.934
then that's the default behavior
of the volume control.

00:44:38.934 --> 00:44:41.300
Without that,
you're probably going to get

00:44:41.300 --> 00:44:43.934
pretty inconsistent behavior
and frustrated users.

00:44:43.934 --> 00:44:46.501
That's probably
the number one problem

00:44:46.501 --> 00:44:48.968
I see with applications
in the marketplace today

00:44:48.968 --> 00:44:52.033
is they're not using that.

00:44:52.033 --> 00:44:55.601
Another common one I see
on the--in a--

00:44:55.601 --> 00:44:57.300
on the forums
is people saying,

00:44:57.300 --> 00:45:01.200
"How do I--how do I play
a file from my APK?

00:45:01.200 --> 00:45:03.133
"I just want to have
an audio file

00:45:03.133 --> 00:45:05.934
that I ship with the--
with the package,"

00:45:05.934 --> 00:45:07.667
and they get this wrong
for whatever reason.

00:45:07.667 --> 00:45:09.200
I think we have
some code out there

00:45:09.200 --> 00:45:11.667
from a long time ago
that looks like this.

00:45:11.667 --> 00:45:16.734
And so this doesn't work.

00:45:16.734 --> 00:45:19.567
This is the correct way
to do it.

00:45:19.567 --> 00:45:23.000
So there's this
AssetFileDescriptor.

00:45:23.000 --> 00:45:25.901
I talked a little bit earlier
about the binder object

00:45:25.901 --> 00:45:27.734
and how we pass things through,

00:45:27.734 --> 00:45:29.834
so we're going to pass
the file descriptor,

00:45:29.834 --> 00:45:33.200
which is a pointer
to your resource,

00:45:33.200 --> 00:45:37.267
through the binder
to the...

00:45:37.267 --> 00:45:39.067
I don't know
how that period got in there.

00:45:39.067 --> 00:45:40.434
It should be setDataSource.

00:45:40.434 --> 00:45:44.000
So it's setDataSource,
takes a FileDescriptor,

00:45:44.000 --> 00:45:45.467
StartOffset,
and a Length,

00:45:45.467 --> 00:45:48.634
and so what this will do is,
using a resource ID,

00:45:48.634 --> 00:45:51.167
it will find, you know,
open it,

00:45:51.167 --> 00:45:53.467
find the offset
where that raw--

00:45:53.467 --> 00:45:55.234
that resource starts.

00:45:55.234 --> 00:45:57.701
And it will, you know,
pass--

00:45:57.701 --> 00:46:01.567
set those values
so that we can tell

00:46:01.567 --> 00:46:03.234
the media player
where to find it,

00:46:03.234 --> 00:46:04.667
and the media player
will then play that

00:46:04.667 --> 00:46:07.601
from that offset
in the FileDescriptor.

00:46:14.067 --> 00:46:15.367
I had another thought there.

00:46:15.367 --> 00:46:17.200
Oh, yeah.
So--yeah.

00:46:17.200 --> 00:46:21.434
Raw resources, make sure
that when you put your file in,

00:46:21.434 --> 00:46:23.601
you're putting it in
as a raw resource,

00:46:23.601 --> 00:46:25.167
so it doesn't get compressed.

00:46:25.167 --> 00:46:28.300
We don't compress things
like MP3 files and so on.

00:46:28.300 --> 00:46:34.234
They have to be
in the raw directory.

00:46:34.234 --> 00:46:36.534
Another common one
I see on the forums

00:46:36.534 --> 00:46:39.267
is people running out
of MediaPlayers.

00:46:39.267 --> 00:46:41.133
And this is kind of
an absurd example,

00:46:41.133 --> 00:46:42.834
but, you know,
just to give you a point.

00:46:42.834 --> 00:46:44.534
There is a limited amount
of resources.

00:46:44.534 --> 00:46:45.834
This is an embedded device.

00:46:45.834 --> 00:46:48.567
A lot of people who are
moving over from the desktop

00:46:48.567 --> 00:46:50.200
don't realize that they're
working with something

00:46:50.200 --> 00:46:52.934
that's, you know,
equivalent to a desktop system

00:46:52.934 --> 00:46:55.033
from maybe ten years ago.

00:46:55.033 --> 00:46:57.601
So don't do this.

00:46:57.601 --> 00:47:01.200
If you're going to use
MediaPlayers,

00:47:01.200 --> 00:47:02.367
try to recycle them.

00:47:02.367 --> 00:47:06.734
So our solution is,
you know,

00:47:06.734 --> 00:47:09.434
there are resources
that are actually allocated

00:47:09.434 --> 00:47:10.901
when you create a MediaPlayer.

00:47:10.901 --> 00:47:14.067
It's allocating memory,
it may be loading codecs.

00:47:14.067 --> 00:47:16.367
It may--there may actually
be a hardware codec

00:47:16.367 --> 00:47:18.701
that's been instantiated
that you're preventing

00:47:18.701 --> 00:47:20.300
the rest of the system
from using.

00:47:20.300 --> 00:47:21.634
So whenever
you're done with them,

00:47:21.634 --> 00:47:24.100
make sure you release them.

00:47:24.100 --> 00:47:25.734
So you're going to call release,

00:47:25.734 --> 00:47:28.167
you set null
on the MediaPlayer object.

00:47:28.167 --> 00:47:32.300
Or you can call reset and set--
do a new setDataSource,

00:47:32.300 --> 00:47:35.567
which, you know, is basically
just recycling your MediaPlayer.

00:47:35.567 --> 00:47:39.000
And try to keep it to, you know,
two or three maximum.

00:47:39.000 --> 00:47:43.100
'Cause you are sharing with
other applications, hopefully.

00:47:43.100 --> 00:47:46.467
And so if you get a little piggy
with your MediaPlayer resources,

00:47:46.467 --> 00:47:49.934
somebody else can't get them.

00:47:49.934 --> 00:47:53.801
And also, if you go
into the background--

00:47:53.801 --> 00:47:55.234
so, and you're in--
on pause,

00:47:55.234 --> 00:47:58.367
you definitely want to release
all of your MediaPlayers

00:47:58.367 --> 00:48:03.367
so that other applications
can get access to them.

00:48:03.367 --> 00:48:05.734
Another big one
that happens a lot

00:48:05.734 --> 00:48:10.133
is the CPU...
"My CPU is saturated."

00:48:10.133 --> 00:48:12.601
And you look at the logs
and you see this.

00:48:12.601 --> 00:48:16.167
You know, CPU is--
is--

00:48:16.167 --> 00:48:17.934
can't remember
what the message is now.

00:48:17.934 --> 00:48:23.801
But it's pretty clear
that the CPU is unhappy.

00:48:23.801 --> 00:48:25.434
And this is kind of
the typical thing,

00:48:25.434 --> 00:48:26.767
is that you're trying to play
too many

00:48:26.767 --> 00:48:29.200
different compressed streams
at a time.

00:48:29.200 --> 00:48:32.868
Codecs take
a lot of CPU resources,

00:48:32.868 --> 00:48:35.567
especially ones that are running
on software.

00:48:35.567 --> 00:48:38.901
So, you know, a typical, say,
MP3 decode

00:48:38.901 --> 00:48:43.133
of a high-quality MP3
might take 20% of the CPU.

00:48:43.133 --> 00:48:44.601
You add up two or three
of those things,

00:48:44.601 --> 00:48:47.234
and you're talking about
some serious CPU resources.

00:48:47.234 --> 00:48:50.234
And then you wonder why your,
you know, frame rate

00:48:50.234 --> 00:48:52.000
on your game is pretty bad.

00:48:52.000 --> 00:48:54.033
Well, that's why.

00:48:54.033 --> 00:48:57.968
So we actually have
a solution for this problem.

00:48:57.968 --> 00:48:59.567
It's called SoundPool.

00:48:59.567 --> 00:49:03.400
Now, SoundPool had some problems
in the 1.0, 1.1 release.

00:49:03.400 --> 00:49:06.334
We fixed those problems
in Cupcake.

00:49:06.334 --> 00:49:08.534
It's actually pretty useful.

00:49:08.534 --> 00:49:12.067
So what it allows you to do
is take resources

00:49:12.067 --> 00:49:16.901
that are encoded in MP3 or AAC
or Ogg Vorbis,

00:49:16.901 --> 00:49:19.701
whatever
your preferred audio format is.

00:49:19.701 --> 00:49:22.267
It decodes them and loads them
into memory

00:49:22.267 --> 00:49:23.534
so they're ready to play,

00:49:23.534 --> 00:49:26.234
and then uses
the AudioTrack interface

00:49:26.234 --> 00:49:29.334
to play them out
through the mixer engine

00:49:29.334 --> 00:49:30.901
just like
we were talking about before.

00:49:30.901 --> 00:49:34.267
And so you can get
much lower overhead.

00:49:34.267 --> 00:49:37.934
You know, some are in the order
of about 5% per stream

00:49:37.934 --> 00:49:42.067
as compared to these, you know,
20% or 30%.

00:49:42.067 --> 00:49:44.167
Depending on what
the audio codec is.

00:49:44.167 --> 00:49:46.734
So it gives you
the same sort of flexibility.

00:49:46.734 --> 00:49:49.334
You can modify--in fact,
it actually gives you

00:49:49.334 --> 00:49:52.901
a little more flexibility,
because you can set the rates.

00:49:52.901 --> 00:49:55.334
It can--
will manage streams for you.

00:49:55.334 --> 00:49:57.100
So if you want to limit
the number of streams

00:49:57.100 --> 00:49:59.267
that are playing,
you tell it upfront,

00:49:59.267 --> 00:50:02.667
"I want," let's say,
"eight streams maximum."

00:50:02.667 --> 00:50:04.868
If you exceed that,
it will automatically,

00:50:04.868 --> 00:50:09.067
based on the priority, you know,
select the least priority,

00:50:09.067 --> 00:50:11.133
get rid of that one,
and start the new sound.

00:50:11.133 --> 00:50:14.667
So it's kind of managing
resources for you.

00:50:14.667 --> 00:50:18.200
And then you can do things
like pan in real time.

00:50:18.200 --> 00:50:20.234
You can change the pitch.

00:50:20.234 --> 00:50:21.667
So if you want to get
a Doppler effect

00:50:21.667 --> 00:50:24.334
or something like that,
this is the way to do it.

00:50:26.634 --> 00:50:29.033
So that's pretty much it.

00:50:29.033 --> 00:50:31.400
We have about ten minutes left
for questions,

00:50:31.400 --> 00:50:34.501
if anybody wants to go up
to a microphone.

00:50:34.501 --> 00:50:35.567
[applause]

00:50:35.567 --> 00:50:37.100
Thank you.

00:50:42.100 --> 00:50:44.000
man: Hi, thank you.
That was a great talk.

00:50:44.000 --> 00:50:47.734
Is setting the
streamed music,

00:50:47.734 --> 00:50:49.701
so you can respond
to the volume control--

00:50:49.701 --> 00:50:51.868
do you have to do that every
time you create a new activity,

00:50:51.868 --> 00:50:53.968
or is it sticky
for the life of the app?

00:50:53.968 --> 00:50:55.968
Sparks: It's sticky--

00:50:55.968 --> 00:50:59.501
you're going to call it
in your onCreate function.

00:50:59.501 --> 00:51:00.868
man: But in
every single activity?

00:51:00.868 --> 00:51:02.334
Sparks: Yeah, yeah.
man: Okay.

00:51:05.801 --> 00:51:09.501
man: Hi, my first question
is that currently,

00:51:09.501 --> 00:51:12.234
Android using the OpenCORE

00:51:12.234 --> 00:51:14.834
for the multimedia framework.

00:51:14.834 --> 00:51:18.434
And my question is that
does Google has any plan

00:51:18.434 --> 00:51:21.000
to support any other middleware,

00:51:21.000 --> 00:51:23.400
such as GStreamer
or anything else?

00:51:23.400 --> 00:51:25.367
Sparks: Not at this time.

00:51:25.367 --> 00:51:27.033
We don't have any plans
to support anything else.

00:51:27.033 --> 00:51:28.200
man: Okay.

00:51:28.200 --> 00:51:29.901
What's the strategy of Google

00:51:29.901 --> 00:51:31.634
for supporting other pioneers

00:51:31.634 --> 00:51:34.801
providing this
multimedia middleware?

00:51:34.801 --> 00:51:38.133
Sparks: Well, so,
because of the flexibility

00:51:38.133 --> 00:51:41.234
of the MediaPlayer service,
you could easily add

00:51:41.234 --> 00:51:45.267
another code--another media
framework engine in there

00:51:45.267 --> 00:51:46.634
and replace OpenCORE.

00:51:46.634 --> 00:51:47.767
man: Okay.

00:51:47.767 --> 00:51:50.167
So my second question
is that, um--

00:51:50.167 --> 00:51:51.234
[coughs]

00:51:51.234 --> 00:51:53.334
that currently--

00:51:53.334 --> 00:51:57.501
Google, you mentioned
implementing the MediaPlayer

00:51:57.501 --> 00:51:58.968
and the recording service.

00:51:58.968 --> 00:52:02.901
Is there any plan to support
the mobile TV and other,

00:52:02.901 --> 00:52:06.033
such as video conference,
in frameworks?

00:52:06.033 --> 00:52:09.133
Sparks: We're--we're looking
at video conferencing.

00:52:09.133 --> 00:52:12.133
Digital TV is probably
a little bit farther out.

00:52:12.133 --> 00:52:15.667
We kind of need a platform
to do the development on.

00:52:15.667 --> 00:52:17.868
So we'll be working
with partners.

00:52:17.868 --> 00:52:20.033
Basically, if there's
a partner that's interested

00:52:20.033 --> 00:52:22.901
in something that isn't there,

00:52:22.901 --> 00:52:25.200
we will--we can
work with you on it.

00:52:25.200 --> 00:52:27.968
man: Okay, thank you.

00:52:27.968 --> 00:52:31.934
man: Does the media framework
support RTSP control?

00:52:31.934 --> 00:52:33.501
Sparks: Yes.

00:52:33.501 --> 00:52:37.634
So RTSP support is not as good
as we'd like it to be.

00:52:37.634 --> 00:52:39.834
It's getting better
with every release.

00:52:39.834 --> 00:52:42.033
And we're expecting
to make some more strides

00:52:42.033 --> 00:52:43.601
in the next release
after this.

00:52:43.601 --> 00:52:44.767
But Cupcake is slightly better.

00:52:44.767 --> 00:52:47.601
man: And that's specified by...

00:52:47.601 --> 00:52:49.467
in the URL, by specifying
the RTSP?

00:52:49.467 --> 00:52:50.934
Sparks: Yeah. Right.
man: Okay.

00:52:50.934 --> 00:52:55.634
And you mentioned, like,
500 kilobits per second

00:52:55.634 --> 00:52:58.067
being the maximum, or--

00:52:58.067 --> 00:52:59.534
What if you tried
to play something

00:52:59.534 --> 00:53:00.834
that is larger than that?

00:53:00.834 --> 00:53:04.000
Sparks: Well, the codec
may fall behind.

00:53:04.000 --> 00:53:08.200
What will typically happen
is that you'll get a--

00:53:08.200 --> 00:53:11.834
if you're using our MovieView,
you'll get an error message

00:53:11.834 --> 00:53:13.501
that says that
it can't keep up.

00:53:13.501 --> 00:53:15.968
man: Mm-hmm. So it will try,
but it will--

00:53:15.968 --> 00:53:17.534
It might fall behind.
Sparks: Yeah.

00:53:17.534 --> 00:53:19.300
man: Thank you.

00:53:19.300 --> 00:53:21.734
man: My question is ask--

00:53:21.734 --> 00:53:24.701
how about--
how much flexibility we have

00:53:24.701 --> 00:53:26.467
to control the camera services?

00:53:26.467 --> 00:53:29.801
For example,
can I control the frame rate,

00:53:29.801 --> 00:53:33.834
and the color tunings,
and et cetera?

00:53:33.834 --> 00:53:36.334
Sparks: Yeah, some of that's
going to depend on the--

00:53:36.334 --> 00:53:38.234
on the device.

00:53:38.234 --> 00:53:40.100
We're still kind of struggling

00:53:40.100 --> 00:53:42.968
with some
of the device-specific things,

00:53:42.968 --> 00:53:44.334
but in the case of the camera,

00:53:44.334 --> 00:53:46.100
there's a setParameters
interface.

00:53:46.100 --> 00:53:49.033
And there's access,
depending on the device,

00:53:49.033 --> 00:53:51.033
to some of those parameters.

00:53:51.033 --> 00:53:53.267
The way you know that is,
you do a setParameter.

00:53:53.267 --> 00:53:55.901
Let's say you ask
for a certain frame rate.

00:53:55.901 --> 00:53:57.400
You--you do a getParameter.

00:53:57.400 --> 00:53:59.767
You find out if it accepted
your frame rate or not.

00:53:59.767 --> 00:54:01.200
Because there's a number
of parameters.

00:54:01.200 --> 00:54:04.567
man: Yeah, but also, in the--
for example, the low light.

00:54:04.567 --> 00:54:07.734
So you want--not only you want
to slow the frame rate,

00:54:07.734 --> 00:54:09.968
but also you want to increase
the integration time.

00:54:09.968 --> 00:54:11.067
Sparks: Right.

00:54:11.067 --> 00:54:13.234
man: So in the--
sometimes you want,

00:54:13.234 --> 00:54:14.334
even in the low light,

00:54:14.334 --> 00:54:16.167
but you want
to slow the frame rate.

00:54:16.167 --> 00:54:20.868
But you still want to keep
the normal integration time.

00:54:20.868 --> 00:54:24.133
So how you--do you have those
kind of flexibility to control?

00:54:24.133 --> 00:54:25.801
Sparks: Well,
so that's going to depend

00:54:25.801 --> 00:54:27.801
on whether the hardware
supports it or not.

00:54:27.801 --> 00:54:30.234
If the hardware supports it,
then there should be

00:54:30.234 --> 00:54:31.501
a parameter for that.

00:54:31.501 --> 00:54:33.567
One of the things
we've done is--

00:54:33.567 --> 00:54:36.100
for hardware dev--
manufacturers

00:54:36.100 --> 00:54:38.734
that have specific things
that they want to support,

00:54:38.734 --> 00:54:40.868
that aren't like, standard--

00:54:40.868 --> 00:54:44.767
they can add a prefix to their
parameter key value pairs.

00:54:44.767 --> 00:54:47.534
So that will, you know--
it's unique to that device.

00:54:47.534 --> 00:54:51.400
And we're certainly open
to manufacturers suggesting,

00:54:51.400 --> 00:54:53.667
you know, new--
new standard parameters.

00:54:53.667 --> 00:54:55.667
And we're starting to adopt
more of those.

00:54:55.667 --> 00:55:00.701
So, for example, like,
white balance is in there.

00:55:00.701 --> 00:55:03.133
Scene modes, things like that
are all part of it.

00:55:03.133 --> 00:55:05.634
man: Okay.
Sparks: Yeah.

00:55:05.634 --> 00:55:08.267
man: I was wondering
what kind of native code hooks

00:55:08.267 --> 00:55:10.133
the audio framework has?

00:55:10.133 --> 00:55:13.100
I'm working on an app
that basically would involve,

00:55:13.100 --> 00:55:15.534
like, actively doing
a fast Fourier transform,

00:55:15.534 --> 00:55:18.834
you know, on however many
samples you can get at a time.

00:55:18.834 --> 00:55:22.234
And so, it seems like
for now--

00:55:22.234 --> 00:55:24.234
or in the Java, for example,

00:55:24.234 --> 00:55:26.467
it's mostly built
toward recording audio and--

00:55:26.467 --> 00:55:27.968
and doing things with that.

00:55:27.968 --> 00:55:31.000
What sort of active control
do you have over the device?

00:55:31.000 --> 00:55:33.667
Sparks: So officially,
we don't support

00:55:33.667 --> 00:55:37.567
native API access
to audio yet.

00:55:37.567 --> 00:55:40.234
The reason for that is,

00:55:40.234 --> 00:55:42.501
we, you know--
any API we publish,

00:55:42.501 --> 00:55:44.067
we're going to have to live with
for a long whi--

00:55:44.067 --> 00:55:45.634
a long time.

00:55:45.634 --> 00:55:48.067
We're still playing
with APIs,

00:55:48.067 --> 00:55:50.467
trying to, you know, get--
make them better.

00:55:50.467 --> 00:55:51.734
And so the audio APIs

00:55:51.734 --> 00:55:53.534
have changed a little bit
in Cupcake.

00:55:53.534 --> 00:55:55.701
They're going to change again
in the next two releases.

00:55:55.701 --> 00:55:57.567
At that point,
we'll probably be ready

00:55:57.567 --> 00:56:00.000
to start providing
native access.

00:56:00.000 --> 00:56:01.834
What you can do,

00:56:01.834 --> 00:56:04.200
very shortly we'll have
a native SDK,

00:56:04.200 --> 00:56:07.534
which will give you access
to libc and libm.

00:56:07.534 --> 00:56:10.567
You can get access
to the audio

00:56:10.567 --> 00:56:14.667
from the Java--
official Java APIs,

00:56:14.667 --> 00:56:16.200
do your processing
in native code,

00:56:16.200 --> 00:56:18.634
and then feed it back,
and you'll be able to do that

00:56:18.634 --> 00:56:19.868
without having to do MEMcopies.

00:56:19.868 --> 00:56:21.300
man: And so basically,
that would just be

00:56:21.300 --> 00:56:23.634
accessing the buffer
that the audio writes to.

00:56:23.634 --> 00:56:26.501
And also, just a very tiny
question about the buffer.

00:56:26.501 --> 00:56:28.300
Does it--

00:56:28.300 --> 00:56:30.767
does it loop back
when you record the audio?

00:56:30.767 --> 00:56:34.133
Or is it--does it record in,
essentially, like, blocks?

00:56:34.133 --> 00:56:36.868
Do you record an entire buffer
once in a row,

00:56:36.868 --> 00:56:38.801
or does it sort of go back to
the start and then keep going?

00:56:38.801 --> 00:56:42.133
Sparks: You can either have it
cycle through a static buffer,

00:56:42.133 --> 00:56:45.067
or you can just pass in
new buffers each time,

00:56:45.067 --> 00:56:46.067
depending on how you want
to use it.

00:56:46.067 --> 00:56:47.534
man: Okay. Thanks.

00:56:49.934 --> 00:56:52.200
man: Let's say
you have a game

00:56:52.200 --> 00:56:56.367
where you want to generate
a sound instantly

00:56:56.367 --> 00:56:59.601
on a button press or a touch.

00:56:59.601 --> 00:57:01.601
Sparks: "Instantly"
is a relative term.

00:57:01.601 --> 00:57:03.334
man: As instantly
as you can get.

00:57:03.334 --> 00:57:05.868
Would you recommend,
then, the JET MIDI stuff,

00:57:05.868 --> 00:57:07.934
or an Ogg, or what?

00:57:07.934 --> 00:57:10.601
Sparks: You--you're probably
going to get best results

00:57:10.601 --> 00:57:11.868
with SoundPool,

00:57:11.868 --> 00:57:13.868
because SoundPool's
really aimed at that.

00:57:13.868 --> 00:57:15.801
What SoundPool
doesn't give you--

00:57:15.801 --> 00:57:17.133
and we don't have an API
for it,

00:57:17.133 --> 00:57:18.467
we get a lot of requests
for it,

00:57:18.467 --> 00:57:20.467
so, you know, it's on my list
of things to do--

00:57:20.467 --> 00:57:22.467
is synchronization.

00:57:22.467 --> 00:57:25.334
So if you're trying to do
a rhythm game

00:57:25.334 --> 00:57:28.934
where you--you want to be able
to have very precise control

00:57:28.934 --> 00:57:30.968
of--of, say, a drum track--

00:57:30.968 --> 00:57:33.100
you--there isn't a way
to do that today.

00:57:33.100 --> 00:57:34.367
But if you're just trying
to do--

00:57:34.367 --> 00:57:35.734
man: Like gunfire kind of thing.

00:57:35.734 --> 00:57:38.033
Sparks: Gunfire?
SoundPool is perfect for that.

00:57:38.033 --> 00:57:41.100
That's--that's what it was
intended for.

00:57:41.100 --> 00:57:44.367
man: Yeah, if I use
the audio mixer,

00:57:44.367 --> 00:57:46.434
can I control the volume

00:57:46.434 --> 00:57:48.234
of the different sources
differently?

00:57:48.234 --> 00:57:49.534
Sparks: Yes.
man: Okay.

00:57:49.534 --> 00:57:52.200
Sparks: So, SoundPool
has a volume control

00:57:52.200 --> 00:57:55.534
for each of
its channels that you--

00:57:55.534 --> 00:57:59.200
basically, when you trigger
a SoundPool sound,

00:57:59.200 --> 00:58:00.868
you get an ID back.

00:58:00.868 --> 00:58:02.934
And you can use that
to control that sound.

00:58:02.934 --> 00:58:04.567
If you're using
the AudioTrack interface,

00:58:04.567 --> 00:58:07.467
there's a volume control
interface on it.

00:58:07.467 --> 00:58:10.868
man: My question is,

00:58:10.868 --> 00:58:14.400
for the testing sites,
how--

00:58:14.400 --> 00:58:18.667
does Google have a plan
to release a certain application

00:58:18.667 --> 00:58:22.701
or testing program
to verify MediaPlayer

00:58:22.701 --> 00:58:24.434
and other media middleware
like this?

00:58:24.434 --> 00:58:25.567
Sparks: Right.

00:58:25.567 --> 00:58:28.367
man: 3D and everything else?

00:58:28.367 --> 00:58:31.701
Sparks:
So we haven't announced

00:58:31.701 --> 00:58:32.968
what we're doing there yet.

00:58:32.968 --> 00:58:34.434
I can't talk about it.

00:58:34.434 --> 00:58:37.100
But it's definitely something
we're thinking about.

00:58:37.100 --> 00:58:38.300
man: Okay.

00:58:38.300 --> 00:58:41.133
Another question is about
the concurrency

00:58:41.133 --> 00:58:43.801
there for the mobile devices.

00:58:43.801 --> 00:58:45.467
The resource is very limited.

00:58:45.467 --> 00:58:48.067
So for example,
the service you mentioned.

00:58:48.067 --> 00:58:52.868
The memory
is very limited.

00:58:52.868 --> 00:58:56.801
So how do we handle any--

00:58:56.801 --> 00:58:58.534
or maybe you have
any experience--

00:58:58.534 --> 00:59:00.801
handle the 3D surface

00:59:00.801 --> 00:59:03.501
and also the multimedia surface

00:59:03.501 --> 00:59:06.167
and put together
a raw atom surface

00:59:06.167 --> 00:59:07.868
or something like that?

00:59:07.868 --> 00:59:10.901
Sparks: So when you say "3D,"
you're talking about--

00:59:10.901 --> 00:59:14.400
man: Like OpenGL,
because you do the overlay

00:59:14.400 --> 00:59:15.901
and you use the overlay
and you--

00:59:15.901 --> 00:59:18.334
Sparks: Yeah, I'm--
I'm not that up on it.

00:59:18.334 --> 00:59:19.634
I'm not a graphics guy.

00:59:19.634 --> 00:59:21.200
I'm really an audio guy.

00:59:21.200 --> 00:59:23.901
But I actually manage the team
that does the 3D stuff.

00:59:23.901 --> 00:59:25.701
So I'm kind of familiar
with it.

00:59:25.701 --> 00:59:28.033
There's definitely
limited texture memory

00:59:28.033 --> 00:59:30.167
that's available--that's
probably the most critical thing

00:59:30.167 --> 00:59:32.701
that we're running into--
but obviously,

00:59:32.701 --> 00:59:34.000
you know, that--

00:59:34.000 --> 00:59:36.434
we're going to figure out
how to share that.

00:59:36.434 --> 00:59:39.300
And so--

00:59:39.300 --> 00:59:40.934
I don't have a good answer
for you,

00:59:40.934 --> 00:59:42.501
but we're aware of the problem.

00:59:42.501 --> 00:59:44.133
man: Okay.
Yeah.

00:59:44.133 --> 00:59:46.801
Just one more question
is do you have any plan

00:59:46.801 --> 00:59:49.000
to move OpenGL 2.0
for the Android?

00:59:49.000 --> 00:59:50.901
Sparks: Yes. If you--

00:59:50.901 --> 00:59:52.334
man: Do you have a time frame?

00:59:52.334 --> 00:59:53.734
Sparks: Yeah,
if you're following

00:59:53.734 --> 00:59:56.267
the master source tree
right now,

00:59:56.267 --> 00:59:58.734
you'll start to see changes
come out for--

00:59:58.734 --> 01:00:02.100
we're--we're marrying 2D
and 3D space.

01:00:02.100 --> 01:00:07.200
So the 2D framework will be
running as an OpenGL context,

01:00:07.200 --> 01:00:09.734
which will allow you, then,
to, you know--

01:00:09.734 --> 01:00:12.167
ES 2.0 context.

01:00:12.167 --> 01:00:14.667
So you'll be able to share
between the 3D app

01:00:14.667 --> 01:00:15.734
and the 2D app.

01:00:15.734 --> 01:00:17.067
Currently,
if you have a 3D app,

01:00:17.067 --> 01:00:18.667
it takes over the frame buffer

01:00:18.667 --> 01:00:20.200
and nothing else can run.

01:00:20.200 --> 01:00:21.868
You'll actually be able
to run 3D

01:00:21.868 --> 01:00:23.334
inside the 2D framework.

01:00:23.334 --> 01:00:24.901
man: Okay, thank you.

01:00:24.901 --> 01:00:26.667
man: I think this question
is sort of related.

01:00:26.667 --> 01:00:29.567
I was wondering how would you
take, like, the--

01:00:29.567 --> 01:00:31.100
the surface that you use
to play back video

01:00:31.100 --> 01:00:33.334
and use it as a texture,
like in OpenGL?

01:00:33.334 --> 01:00:35.033
Sparks: That's coming, yeah.

01:00:35.033 --> 01:00:37.968
Yeah, that--so you actually
would be able to map

01:00:37.968 --> 01:00:39.934
that texture onto a 3D--

01:00:39.934 --> 01:00:42.000
man: Is there any way
you can do that today

01:00:42.000 --> 01:00:43.167
with the current APIs?

01:00:43.167 --> 01:00:44.334
Sparks: Nope.

01:00:44.334 --> 01:00:45.901
Yeah, there's no access
to the--

01:00:45.901 --> 01:00:48.767
to the video after it leaves
the media server.

01:00:48.767 --> 01:00:50.033
man: And no time frame

01:00:50.033 --> 01:00:51.534
as far as
when there'll be

01:00:51.534 --> 01:00:53.567
some type of communication
as far as

01:00:53.567 --> 01:00:55.501
how to about doing that
in your applications?

01:00:55.501 --> 01:00:58.067
Sparks: Well, it's--
so it's in our--

01:00:58.067 --> 01:00:59.901
what we call
our Eclair release.

01:00:59.901 --> 01:01:01.601
So that's master today.

01:01:01.601 --> 01:01:04.534
man: Okay.
Okay, thank you.

01:01:04.534 --> 01:01:07.434
Sparks: I think--
are we out of time?

01:01:07.434 --> 01:01:08.834
woman: [indistinct]

01:01:08.834 --> 01:01:11.300
Sparks: Okay.

01:01:11.300 --> 01:01:13.734
woman: Hi, do you have
any performance metrics

01:01:13.734 --> 01:01:16.267
as to what are
the performance numbers

01:01:16.267 --> 01:01:21.701
with the certain playback
of audio and video to share,

01:01:21.701 --> 01:01:23.467
or any memory footprints
available

01:01:23.467 --> 01:01:25.000
that we can look up, maybe?

01:01:25.000 --> 01:01:26.434
Sparks: Not today.

01:01:26.434 --> 01:01:29.067
It's actually part of some
of the work we're doing

01:01:29.067 --> 01:01:31.133
that somebody was asking about
earlier.

01:01:31.133 --> 01:01:32.701
That I can't talk about yet.
But yeah.

01:01:32.701 --> 01:01:35.267
There's definitely some--
some plans to do metrics

01:01:35.267 --> 01:01:38.767
and to have baselines
that you can depend on.

01:01:38.767 --> 01:01:41.067
woman: And then the second
question that I have

01:01:41.067 --> 01:01:44.133
is that do you have
any additional formats

01:01:44.133 --> 01:01:47.067
that are lined up
or are in the roadmap?

01:01:47.067 --> 01:01:50.834
Like VC-1 and additional
audio formats?

01:01:50.834 --> 01:01:54.501
Sparks: No, not--
not officially, no.

01:01:54.501 --> 01:01:56.100
woman: Okay.

01:01:56.100 --> 01:01:59.200
woman: Hi, this is back
to the SoundPool question.

01:01:59.200 --> 01:02:02.467
Is it possible
to calculate latency

01:02:02.467 --> 01:02:03.868
or at least know, like,

01:02:03.868 --> 01:02:06.601
when the song actually went
to the sound card

01:02:06.601 --> 01:02:08.934
so I could at least know
when it actually did play--

01:02:08.934 --> 01:02:11.067
if there's any sort of callback
or anything?

01:02:11.067 --> 01:02:14.968
Sparks: So you can get
a playback complete callback

01:02:14.968 --> 01:02:20.767
that tells you
when it left the player engine.

01:02:20.767 --> 01:02:22.934
There's some additional latency
in the hardware

01:02:22.934 --> 01:02:26.367
that we...we don't have
complete visibility into,

01:02:26.367 --> 01:02:27.434
but it's reported back

01:02:27.434 --> 01:02:29.334
through the audio track
interface,

01:02:29.334 --> 01:02:31.767
theoretically,
if it's done correctly.

01:02:31.767 --> 01:02:35.234
So at
the MediaPlayer level, no.

01:02:35.234 --> 01:02:37.033
At the AudioTrack level, yes.

01:02:37.033 --> 01:02:38.501
If that's...makes any sense.

01:02:38.501 --> 01:02:40.033
woman: Okay, so I can at least
get that,

01:02:40.033 --> 01:02:42.200
even if I can't actually
calculate latency

01:02:42.200 --> 01:02:43.534
for every single call?

01:02:43.534 --> 01:02:44.601
Sparks: Right, right.

01:02:44.601 --> 01:02:46.000
woman: Okay. Thank you.

01:02:46.000 --> 01:02:47.501
Sparks: Uh-huh.

01:02:47.501 --> 01:02:49.367
man: Yeah, this is a question

01:02:49.367 --> 01:02:51.968
about the samples processing.

01:02:51.968 --> 01:02:55.234
You partially touched
upon that.

01:02:55.234 --> 01:02:57.300
But in your architecture
diagram,

01:02:57.300 --> 01:03:01.033
where do you think
the sound processing effect

01:03:01.033 --> 01:03:02.767
really has to be placed?

01:03:02.767 --> 01:03:05.100
For example, it could be
an equalizer

01:03:05.100 --> 01:03:08.400
or different kind
of audio post processing

01:03:08.400 --> 01:03:09.667
that needs to be done.

01:03:09.667 --> 01:03:13.667
Because in the current
Cupcake version, 1.5,

01:03:13.667 --> 01:03:16.200
I do not see a placeholder

01:03:16.200 --> 01:03:18.300
or any implementation
of that sort.

01:03:18.300 --> 01:03:21.167
Sparks: So one of the things
we're in the process of doing

01:03:21.167 --> 01:03:24.467
is we're--
we're looking at OpenAL--

01:03:24.467 --> 01:03:26.767
Have I got that right?
OpenAL ES?

01:03:26.767 --> 01:03:31.701
As the, um--possibly the--
an abstraction for that.

01:03:31.701 --> 01:03:33.534
But it definitely
is something you want to do

01:03:33.534 --> 01:03:36.801
on an application-by-application
basis.

01:03:36.801 --> 01:03:38.167
For example,
you don't want to have

01:03:38.167 --> 01:03:42.467
effects running on, you know,
a notification if...

01:03:42.467 --> 01:03:44.634
The--you--you wouldn't want
the application

01:03:44.634 --> 01:03:46.167
in the foreground
and forcing something

01:03:46.167 --> 01:03:48.801
on some other application
that's running in background.

01:03:48.801 --> 01:03:51.100
So that's kind of the direction
we're headed with that.

01:03:51.100 --> 01:03:53.534
man: What's the current
recommendation?

01:03:53.534 --> 01:03:56.067
How do you want the developers
to address?

01:03:56.067 --> 01:03:57.868
Sparks: Well, the--
since there isn't any way,

01:03:57.868 --> 01:03:59.901
there's no recommendation.

01:03:59.901 --> 01:04:01.701
I mean,
if you were doing native code,

01:04:01.701 --> 01:04:03.133
it's kind of up to you.

01:04:03.133 --> 01:04:06.767
But our recommendation would be
if you're, you know,

01:04:06.767 --> 01:04:08.534
doing some special version
of the code,

01:04:08.534 --> 01:04:10.434
you would probably want
to insert it

01:04:10.434 --> 01:04:12.634
at the application level
and not sitting

01:04:12.634 --> 01:04:14.300
at the bottom
of the Audio Flinger stack.

01:04:14.300 --> 01:04:16.100
man: Okay, thanks.

01:04:16.100 --> 01:04:19.634
woman: Is it better to get
the system service once

01:04:19.634 --> 01:04:22.400
and share it across activities
in an application,

01:04:22.400 --> 01:04:27.033
or let each activity
fetch the service?

01:04:27.033 --> 01:04:29.567
Sparks: I mean, there's
a certain amount of overhead,

01:04:29.567 --> 01:04:31.701
'cause it's a binder call
to do it.

01:04:31.701 --> 01:04:33.968
So if you know
you're going to use it,

01:04:33.968 --> 01:04:35.467
I would just keep it around.

01:04:35.467 --> 01:04:38.000
I mean, it's just a--
a Java object reference.

01:04:38.000 --> 01:04:41.734
So it's pretty cheap
to hold around.

01:04:41.734 --> 01:04:43.934
man: Is there any way
to listen to music

01:04:43.934 --> 01:04:46.334
on a mono Bluetooth?

01:04:46.334 --> 01:04:48.901
Sparks: Ah, on a SCO?

01:04:48.901 --> 01:04:50.868
Yeah, no.
[chuckles]

01:04:50.868 --> 01:04:53.167
The reason
we haven't done that

01:04:53.167 --> 01:04:56.033
is the audio quality
is really pretty poor.

01:04:56.033 --> 01:04:58.133
I mean, it's designed for--
for call audio.

01:04:58.133 --> 01:05:00.234
So the experience isn't going
to be very good.

01:05:00.234 --> 01:05:03.000
Theoretically, you know,
it's possible.

01:05:03.000 --> 01:05:06.067
We just don't think
it's a good idea.

01:05:06.067 --> 01:05:07.634
[chuckling]

01:05:07.634 --> 01:05:10.934
man: If you want to record
for a long period of time,

01:05:10.934 --> 01:05:12.400
you know, like a half-hour,

01:05:12.400 --> 01:05:14.400
can you frequency scale
the processor

01:05:14.400 --> 01:05:16.734
or put it to sleep, or...

01:05:16.734 --> 01:05:19.133
Sparks: It--well,
that happens automatically.

01:05:19.133 --> 01:05:23.133
I mean, it's--
it's actually going to sleep

01:05:23.133 --> 01:05:25.067
and waking up all the time.

01:05:25.067 --> 01:05:27.701
So it's just depending
on what's--

01:05:27.701 --> 01:05:30.000
man: But if you're doing, like,
a raw 8k sample rate,

01:05:30.000 --> 01:05:33.167
how big a buffer can you have,
and then will it sleep in--

01:05:33.167 --> 01:05:35.667
while that buffer's filling?

01:05:35.667 --> 01:05:38.100
Sparks: So the--the size
of those buffers

01:05:38.100 --> 01:05:40.300
is defined
in the media recorder service.

01:05:40.300 --> 01:05:42.567
And I think they're...

01:05:42.567 --> 01:05:46.734
I want to say they're like 2--
2k at...

01:05:46.734 --> 01:05:47.934
whatever the output rate is.

01:05:47.934 --> 01:05:49.200
So they're pretty good size.

01:05:49.200 --> 01:05:51.367
I mean, it's like
a half a second of audio.

01:05:51.367 --> 01:05:52.834
So the processor,
theoretically,

01:05:52.834 --> 01:05:55.200
would be asleep
for quite some time.

01:05:55.200 --> 01:05:56.868
man: So is that handled
by the codec,

01:05:56.868 --> 01:05:59.000
or is it handled by--
I mean, the DSP on a codec?

01:05:59.000 --> 01:06:00.067
Or is it handled by--

01:06:00.067 --> 01:06:01.534
Sparks: So the...
the process

01:06:01.534 --> 01:06:05.133
is going to wake up
when there's audio available.

01:06:05.133 --> 01:06:07.400
It's going to...

01:06:07.400 --> 01:06:11.133
you know, route it over
to the AMR encoder.

01:06:11.133 --> 01:06:12.767
It's going to do its thing.

01:06:12.767 --> 01:06:15.334
Spit out a bunch of bits
that'll go to the file composer

01:06:15.334 --> 01:06:16.667
to be written out.

01:06:16.667 --> 01:06:17.834
And then theoretically,

01:06:17.834 --> 01:06:18.934
it's gonna go back
to sleep again.

01:06:18.934 --> 01:06:20.200
man: No, I mean
on the recorder.

01:06:20.200 --> 01:06:22.901
If you're recording the audio.

01:06:22.901 --> 01:06:24.267
If you're off the microphone.

01:06:24.267 --> 01:06:25.834
Sparks: I'm sorry?

01:06:25.834 --> 01:06:27.901
man: If you're recording
raw audio off the microphone.

01:06:27.901 --> 01:06:29.234
Sparks: Yeah.

01:06:29.234 --> 01:06:31.701
Oh, oh, are you talking about
using the AudioTrack

01:06:31.701 --> 01:06:33.000
or AudioRecord interface?

01:06:33.000 --> 01:06:34.501
man: The AudioRecord interface.
ADPCM.

01:06:34.501 --> 01:06:36.000
Sparks: Yeah, that's...

01:06:36.000 --> 01:06:37.467
So it's pretty much
the same thing.

01:06:37.467 --> 01:06:39.834
I mean, if you define
your buffer size large enough,

01:06:39.834 --> 01:06:42.400
whatever that buffer size is,
that's the buffer size

01:06:42.400 --> 01:06:44.701
it's going to use
at the lower level.

01:06:44.701 --> 01:06:47.634
So it'll be asleep
for that amount of time.

01:06:47.634 --> 01:06:49.434
man: And the DSP will be
the one filling the buffer?

01:06:49.434 --> 01:06:51.501
Sparks: Yeah, yeah.
The DSP fills the buffer.

01:06:51.501 --> 01:06:53.400
man: All right, thanks.

01:06:53.400 --> 01:06:54.701
man: One last question.

01:06:54.701 --> 01:06:56.534
From a platform perspective,

01:06:56.534 --> 01:06:58.567
would you be able to state
a minimum requirement

01:06:58.567 --> 01:07:01.067
on OpenGL performance?

01:07:01.067 --> 01:07:03.067
Sparks: I'm not ready
to say that today.

01:07:03.067 --> 01:07:05.267
But...

01:07:05.267 --> 01:07:07.033
at some point we'll--

01:07:07.033 --> 01:07:08.467
we'll be able
to tell you about that.

01:07:08.467 --> 01:07:10.634
man: Okay, thanks.
Sparks: Uh-huh.

01:07:10.634 --> 01:07:12.701
Guess that's my time.
Thanks, everyone.

01:07:12.701 --> 01:07:15.634
[applause]

