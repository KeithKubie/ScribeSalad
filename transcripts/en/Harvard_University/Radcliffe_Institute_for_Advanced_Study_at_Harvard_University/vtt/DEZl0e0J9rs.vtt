WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.868
[MUSIC PLAYING]

00:00:03.830 --> 00:00:04.790
- Thank you, Meredith.

00:00:04.790 --> 00:00:07.160
And a big thank you to
everyone at the Radcliffe.

00:00:07.160 --> 00:00:09.440
As you can tell from
this lovely introduction,

00:00:09.440 --> 00:00:12.830
this has just been an enormously
supportive and wonderful place

00:00:12.830 --> 00:00:15.900
in which for me to start
this new research project.

00:00:15.900 --> 00:00:18.020
And I'm also really
happy to have this venue

00:00:18.020 --> 00:00:20.720
to share with you today
some of the results

00:00:20.720 --> 00:00:24.740
of this research, which I'll be
presenting for the first time.

00:00:24.740 --> 00:00:27.200
So what I'd like to
do is introduce you

00:00:27.200 --> 00:00:30.770
to the phenomenon known as
the "reproducibility crisis"

00:00:30.770 --> 00:00:34.500
via a thought experiment.

00:00:34.500 --> 00:00:36.360
Let's imagine that
we took a stack

00:00:36.360 --> 00:00:38.460
of recent scientific
journals, and we

00:00:38.460 --> 00:00:40.590
decided that we were
going to look through them

00:00:40.590 --> 00:00:44.960
for articles that may help
us develop new cancer drugs.

00:00:44.960 --> 00:00:46.770
Say we found an
article that showed

00:00:46.770 --> 00:00:49.500
that cancer cells with
a particular mutation

00:00:49.500 --> 00:00:52.920
were more sensitive
to a particular drug.

00:00:52.920 --> 00:00:54.810
And we look through
these journals, both some

00:00:54.810 --> 00:00:56.820
of the preeminent
scientific journals

00:00:56.820 --> 00:01:00.570
in the world, as well as some
maybe less well-known but still

00:01:00.570 --> 00:01:04.500
reputable journals, and we
came up with around 50 articles

00:01:04.500 --> 00:01:06.900
that we thought might help
us in developing new cancer

00:01:06.900 --> 00:01:08.790
treatments.

00:01:08.790 --> 00:01:11.100
Then we took those
articles, took them

00:01:11.100 --> 00:01:14.850
to a laboratory, a well-equipped
lab full of scientists

00:01:14.850 --> 00:01:17.700
with lots of experience in
doing this type of research,

00:01:17.700 --> 00:01:22.350
and said, just see if you can do
these experiments again and get

00:01:22.350 --> 00:01:25.200
the same result. When
you take that same cell

00:01:25.200 --> 00:01:27.600
with the same mutation and
you treat it with a drug,

00:01:27.600 --> 00:01:31.290
do you also find that they're
more sensitive, as was reported

00:01:31.290 --> 00:01:32.790
in the publication?

00:01:32.790 --> 00:01:34.890
So imagine the
scenario in your head.

00:01:34.890 --> 00:01:38.700
And I want you to pick
a percentage of articles

00:01:38.700 --> 00:01:42.000
that you think these scientists
can probably recreate.

00:01:42.000 --> 00:01:45.600
In this scenario, what
percentage of the findings

00:01:45.600 --> 00:01:47.662
do you think our
laboratory scientists would

00:01:47.662 --> 00:01:48.870
be able to redo on their own?

00:01:48.870 --> 00:01:51.240
And I encourage you to pick
an actual percentage here,

00:01:51.240 --> 00:01:54.450
just so you've got kind of
a baseline in your head.

00:01:54.450 --> 00:01:56.430
This is very close
to what happened

00:01:56.430 --> 00:01:59.310
in a real-life case, where
the pharmaceutical company

00:01:59.310 --> 00:02:04.350
Amgen in 2012 decided to
publish their own experience

00:02:04.350 --> 00:02:07.080
with trying to recreate results
from the published literature

00:02:07.080 --> 00:02:09.240
in their in-house laboratories.

00:02:09.240 --> 00:02:12.150
And in this publication,
here is the number

00:02:12.150 --> 00:02:14.070
that they reported of
the number of studies

00:02:14.070 --> 00:02:15.736
that they could
reproduce in their lab--

00:02:20.110 --> 00:02:24.580
11%, 6 out of 53
cases, that they chose.

00:02:24.580 --> 00:02:27.370
This article generated
a lot of attention

00:02:27.370 --> 00:02:29.534
in the biomedical
research world,

00:02:29.534 --> 00:02:31.450
particularly in the
leadership at the National

00:02:31.450 --> 00:02:32.920
Institutes of Health.

00:02:32.920 --> 00:02:34.810
And it became a
historical turning

00:02:34.810 --> 00:02:39.250
point in what's now known as the
reproducibility crisis, which

00:02:39.250 --> 00:02:41.860
is a transfield
phenomenon happening

00:02:41.860 --> 00:02:44.710
across scientific
disciplines, as we'll see,

00:02:44.710 --> 00:02:48.640
where researchers suddenly are
less confident that findings

00:02:48.640 --> 00:02:51.850
that they thought were stable
could actually hold true

00:02:51.850 --> 00:02:54.320
on closer examination.

00:02:54.320 --> 00:02:55.714
So this article
here was a moment

00:02:55.714 --> 00:02:57.880
when people really started
paying attention to this.

00:02:57.880 --> 00:03:01.300
It shows up high in the citation
lists of key articles coming

00:03:01.300 --> 00:03:03.280
from leaders at
the NIH when they

00:03:03.280 --> 00:03:05.800
decide to take action
and introduce policies

00:03:05.800 --> 00:03:09.380
on reproducibility and rigor
just a few years later.

00:03:09.380 --> 00:03:13.360
But one thing that's curious
about this phenomenon is that

00:03:13.360 --> 00:03:16.870
in this article and in another
article published by another

00:03:16.870 --> 00:03:20.500
pharmaceutical company-- in this
case, Bayer pharmaceuticals--

00:03:20.500 --> 00:03:23.650
what the researchers report is
the figure that they're showing

00:03:23.650 --> 00:03:27.360
us is, in fact,
common knowledge.

00:03:27.360 --> 00:03:28.440
Here's what they say.

00:03:28.440 --> 00:03:31.560
The first article from
Amgen pharmaceuticals--

00:03:31.560 --> 00:03:33.840
"on speaking with many
investigators in academia

00:03:33.840 --> 00:03:36.720
and industry, we found
widespread recognition

00:03:36.720 --> 00:03:38.760
of this issue."

00:03:38.760 --> 00:03:41.340
"Our findings are mirrored
by 'gut feelings' expressed

00:03:41.340 --> 00:03:44.100
in personal communications
with scientists from academia

00:03:44.100 --> 00:03:47.730
or other companies, as well
as published observations."

00:03:47.730 --> 00:03:51.359
That's the quote from a
similar article in Bayer.

00:03:51.359 --> 00:03:53.400
And these assertions here
are not just anecdotal.

00:03:53.400 --> 00:03:55.880
They're supported by
other kinds of data.

00:03:55.880 --> 00:03:59.010
If we take a look, for example,
at a recent survey conducted

00:03:59.010 --> 00:04:01.920
by Nature Publishing
Group in 2016,

00:04:01.920 --> 00:04:05.740
Nature asked 1,500 scientists
from across disciplines

00:04:05.740 --> 00:04:09.180
whether they'd had any personal
experience with failures

00:04:09.180 --> 00:04:12.690
to replicate, if they had
had a case in their own lab

00:04:12.690 --> 00:04:15.380
where they experienced
irreproducibility.

00:04:15.380 --> 00:04:18.180
And you can see here that
the majority of scientists--

00:04:18.180 --> 00:04:21.540
in some cases, the vast
majority of scientists--

00:04:21.540 --> 00:04:25.290
reported experiencing a failure
to replicate either someone

00:04:25.290 --> 00:04:28.712
else's result or even
their own result.

00:04:28.712 --> 00:04:31.170
So this is not just something
that pharmaceutical companies

00:04:31.170 --> 00:04:32.294
are telling us anecdotally.

00:04:32.294 --> 00:04:35.070
We also see in survey
data that scientists

00:04:35.070 --> 00:04:38.500
have widespread experience
with reproducibility--

00:04:38.500 --> 00:04:39.762
irreproducibility-- sorry.

00:04:39.762 --> 00:04:41.220
And just as a note
here, I'll pause

00:04:41.220 --> 00:04:42.719
to say that one of
the things that's

00:04:42.719 --> 00:04:44.820
quite unique about the
reproducibility crisis

00:04:44.820 --> 00:04:47.520
is that it's really
reaching across fields here.

00:04:47.520 --> 00:04:49.410
Chemistry is maybe
not the field where

00:04:49.410 --> 00:04:52.800
you would expect to see
widespread irreproducibility

00:04:52.800 --> 00:04:55.110
problems, and yet
it's high on the list.

00:04:55.110 --> 00:04:56.880
For the purposes of
my talk today, I'm

00:04:56.880 --> 00:05:00.150
going to be focusing on
preclinical research, which

00:05:00.150 --> 00:05:02.850
is research with animal
models or cell lines

00:05:02.850 --> 00:05:05.490
which is aimed, perhaps
indirectly or distantly,

00:05:05.490 --> 00:05:08.100
but aimed at affecting
human health.

00:05:08.100 --> 00:05:09.480
So that's the area
that I'm going

00:05:09.480 --> 00:05:12.720
to be looking at-- the type of
research that the NIH funds,

00:05:12.720 --> 00:05:16.350
which is largely things with
cell lines and animal models.

00:05:16.350 --> 00:05:19.170
So the take-home here is
it seems as though everyone

00:05:19.170 --> 00:05:21.540
has had experience
with irreproducibility,

00:05:21.540 --> 00:05:24.750
at least that's what the
survey data and Amgen says.

00:05:24.750 --> 00:05:28.380
And yet in this same
survey, Nature also

00:05:28.380 --> 00:05:33.390
asked researchers-- do they
feel like this is a crisis?

00:05:33.390 --> 00:05:36.082
Almost all of
respondents here said

00:05:36.082 --> 00:05:38.040
that they thought it was
some degree of crisis.

00:05:38.040 --> 00:05:40.890
And in fact, you can see that
about half of respondents

00:05:40.890 --> 00:05:44.860
feel as though it's a
very significant crisis.

00:05:44.860 --> 00:05:47.280
So the puzzle that I would
like to lay out for you today,

00:05:47.280 --> 00:05:50.370
and this is what most of my talk
is going to be responding to,

00:05:50.370 --> 00:05:53.010
is the following one--

00:05:53.010 --> 00:05:55.320
how can irreproducibility
be something

00:05:55.320 --> 00:05:58.680
that both everyone knows
about and an emerging

00:05:58.680 --> 00:06:01.980
crisis that suddenly hit us?

00:06:01.980 --> 00:06:06.060
Maybe, in other words, how could
irreproducibility be something

00:06:06.060 --> 00:06:10.100
that is hiding in plain sight?

00:06:10.100 --> 00:06:12.050
If you think this through,
it doesn't actually

00:06:12.050 --> 00:06:13.550
make a lot of sense
that it could be

00:06:13.550 --> 00:06:15.890
both of these things at once.

00:06:15.890 --> 00:06:18.470
In that thought experiment
that I asked you to do,

00:06:18.470 --> 00:06:21.200
my guess is, is that if you
had a number in your head

00:06:21.200 --> 00:06:24.560
that was close to 11%, when
I flashed the result up

00:06:24.560 --> 00:06:26.900
on the screen, it didn't
really pack that much

00:06:26.900 --> 00:06:28.070
of an emotional punch.

00:06:28.070 --> 00:06:30.630
And it seems like a true
statement about the world.

00:06:30.630 --> 00:06:33.620
And you might be tempted to make
an argument like well, yeah,

00:06:33.620 --> 00:06:35.630
most research on the
forefronts of our knowledge

00:06:35.630 --> 00:06:37.310
is going to be unstable.

00:06:37.310 --> 00:06:39.740
Science is a
low-yield enterprise,

00:06:39.740 --> 00:06:43.010
as John Ioannidis, one
of the headline figures

00:06:43.010 --> 00:06:45.014
in reproducibility, has said.

00:06:45.014 --> 00:06:47.180
But my guess is, is that
if you picked a number that

00:06:47.180 --> 00:06:51.955
was substantially higher than
11%, say, 50%, when I flashed

00:06:51.955 --> 00:06:54.080
that number up on the
screen, you have a completely

00:06:54.080 --> 00:06:56.240
different affective reaction.

00:06:56.240 --> 00:06:59.570
Then it feels more
like a crisis precisely

00:06:59.570 --> 00:07:03.720
because it doesn't align
with your expectations.

00:07:03.720 --> 00:07:05.529
So this is the core
of the puzzle here.

00:07:05.529 --> 00:07:07.070
How can this be
something that we all

00:07:07.070 --> 00:07:09.210
know about and have
experience with,

00:07:09.210 --> 00:07:12.890
and yet somehow this
particular paper feels

00:07:12.890 --> 00:07:14.810
like a revelation
where we realize

00:07:14.810 --> 00:07:17.315
something is wrong in science?

00:07:17.315 --> 00:07:19.440
In my talk for you today,
I'm going to address this

00:07:19.440 --> 00:07:21.052
from two different angles.

00:07:21.052 --> 00:07:23.010
First, I'm going to
approach this historically,

00:07:23.010 --> 00:07:24.990
putting the
reproducibility crisis

00:07:24.990 --> 00:07:28.470
into the context of a longer
history of clinical research

00:07:28.470 --> 00:07:31.497
reform, which is research
with human subjects.

00:07:31.497 --> 00:07:33.330
So the results that
we're talking about here

00:07:33.330 --> 00:07:34.980
in the reproducibility
crisis, again,

00:07:34.980 --> 00:07:37.470
are those with cell lines,
animal models taking

00:07:37.470 --> 00:07:39.420
place in experimental spaces.

00:07:39.420 --> 00:07:41.070
But by putting this
into conversation

00:07:41.070 --> 00:07:43.050
with clinical
research, we'll see

00:07:43.050 --> 00:07:45.900
both how it is that
reproducibility problems could

00:07:45.900 --> 00:07:48.651
be invisible and then
suddenly visible.

00:07:48.651 --> 00:07:51.150
And then in the second half of
my talk, what I'm going to do

00:07:51.150 --> 00:07:53.100
is combine this
historical research

00:07:53.100 --> 00:07:55.350
with some ethnographic
research to give us

00:07:55.350 --> 00:07:57.300
some purchase on
new ways that we

00:07:57.300 --> 00:08:00.330
might begin to think about
addressing irreproducibility

00:08:00.330 --> 00:08:01.380
today.

00:08:01.380 --> 00:08:03.750
In other words, the question
of-- what does this history

00:08:03.750 --> 00:08:05.700
mean for the many
people right now

00:08:05.700 --> 00:08:07.770
who are taking this
problem very seriously

00:08:07.770 --> 00:08:08.770
and working to solve it?

00:08:11.490 --> 00:08:14.010
So I will turn now to the
history of clinical research

00:08:14.010 --> 00:08:16.060
reform.

00:08:16.060 --> 00:08:17.510
If you read through
this history,

00:08:17.510 --> 00:08:18.700
one of the things
that you'll notice

00:08:18.700 --> 00:08:20.140
is that there are
a lot of moments

00:08:20.140 --> 00:08:22.330
in the history of
clinical research reform

00:08:22.330 --> 00:08:25.720
that bear a strong resemblance
to where we're at today.

00:08:25.720 --> 00:08:28.570
Take, for example, Harry
Marks' classic book called

00:08:28.570 --> 00:08:30.910
The Progress of Experiment.

00:08:30.910 --> 00:08:32.950
And he opens this
book with a situation

00:08:32.950 --> 00:08:35.830
that sounds very much like
where we're at right now

00:08:35.830 --> 00:08:37.929
in the 21st century.

00:08:37.929 --> 00:08:41.710
He says, "over the course of
research in the 19th century,

00:08:41.710 --> 00:08:43.840
researchers working
in a variety of fields

00:08:43.840 --> 00:08:45.820
noticed a common problem--

00:08:45.820 --> 00:08:48.250
individual observers,
putatively studying

00:08:48.250 --> 00:08:50.950
the same phenomenon
with similar techniques,

00:08:50.950 --> 00:08:54.160
gave divergent accounts of it."

00:08:54.160 --> 00:08:56.620
One of the examples that
he talks about in his book

00:08:56.620 --> 00:09:00.910
is an early 20th century remedy
introduced to help pneumonia.

00:09:00.910 --> 00:09:03.790
And this was one of these
tricky cases where doctors

00:09:03.790 --> 00:09:05.830
reported different effects.

00:09:05.830 --> 00:09:08.350
For some, the serum seemed
to work really well.

00:09:08.350 --> 00:09:11.640
In other cases, it didn't
seem to be effective at all.

00:09:11.640 --> 00:09:13.540
And it was difficult
to interpret

00:09:13.540 --> 00:09:16.660
exactly what this
irreproducibility situation

00:09:16.660 --> 00:09:17.620
meant.

00:09:17.620 --> 00:09:20.470
Was it because the doctors
who were using the serum

00:09:20.470 --> 00:09:23.260
were simply not accurately
diagnosing pneumonia

00:09:23.260 --> 00:09:25.720
and therefore using it
in the wrong patients?

00:09:25.720 --> 00:09:28.750
Or was it something about the
drug itself, the serum itself,

00:09:28.750 --> 00:09:31.000
that was not working well?

00:09:31.000 --> 00:09:32.860
And what Marks
argues in this book

00:09:32.860 --> 00:09:35.140
is it's exactly these
kinds of concerns

00:09:35.140 --> 00:09:38.320
that lead to the development
of the modern day

00:09:38.320 --> 00:09:41.710
system of randomized
controlled clinical trials.

00:09:41.710 --> 00:09:43.780
The way that we
now evaluate drugs

00:09:43.780 --> 00:09:46.720
for their effectiveness in
these large clinical trials

00:09:46.720 --> 00:09:50.170
is born, Marks argues, out
of this moment of concern

00:09:50.170 --> 00:09:52.950
about irreproducibility.

00:09:52.950 --> 00:09:54.420
There are lots of
other parallels

00:09:54.420 --> 00:09:57.060
in this book between the
kinds of problems happening

00:09:57.060 --> 00:09:59.850
in the clinical research world
throughout the 20th century

00:09:59.850 --> 00:10:02.400
and the types of
reforms proposed

00:10:02.400 --> 00:10:04.129
and what's going on today.

00:10:04.129 --> 00:10:05.670
But the story that
I want to tell you

00:10:05.670 --> 00:10:08.280
is not just one that's
about similarity.

00:10:08.280 --> 00:10:10.800
This is not one that's
just about history

00:10:10.800 --> 00:10:13.530
reproducing itself
or repeating itself.

00:10:13.530 --> 00:10:16.290
It is instead one about how
it is that clinical research

00:10:16.290 --> 00:10:20.730
reforms actively make invisible
problems going on in the lab

00:10:20.730 --> 00:10:22.620
and then suddenly reveal them.

00:10:22.620 --> 00:10:24.719
So there is a more
direct connection.

00:10:24.719 --> 00:10:26.760
What I'm going to do here
is I'm going to pick up

00:10:26.760 --> 00:10:28.260
where Marks leaves off.

00:10:28.260 --> 00:10:30.720
He ends this book
here in the 1990s.

00:10:30.720 --> 00:10:32.610
And I'm going to
start in the 1990s

00:10:32.610 --> 00:10:34.170
with a couple of
historical events

00:10:34.170 --> 00:10:36.420
that show us how we
get to this moment

00:10:36.420 --> 00:10:41.570
where we can have an aha
moment about irreproducibility.

00:10:41.570 --> 00:10:45.020
The first event that I want
to talk about in the 1990s is

00:10:45.020 --> 00:10:47.540
the rise of what's called
"evidence-based medicine"

00:10:47.540 --> 00:10:51.590
taking place here in the
late 1980s and early 1990s.

00:10:51.590 --> 00:10:53.270
And the evidence-based
medicine movement

00:10:53.270 --> 00:10:56.090
is born out of a
concern that doctors

00:10:56.090 --> 00:10:58.640
are making clinical
decisions, really,

00:10:58.640 --> 00:11:01.220
without respect to the
scientific evidence,

00:11:01.220 --> 00:11:03.500
either because that
evidence is hard for them

00:11:03.500 --> 00:11:06.710
to access because it's scattered
throughout the literature

00:11:06.710 --> 00:11:09.500
or because they're trusting
their clinical intuition more

00:11:09.500 --> 00:11:12.680
than they're trusting what's
out there in the science.

00:11:12.680 --> 00:11:15.410
And so evidence-based
medicine reformers, then,

00:11:15.410 --> 00:11:19.670
sought to try and collect,
evaluate the strength of,

00:11:19.670 --> 00:11:23.300
and then compile
scientific evidence for use

00:11:23.300 --> 00:11:25.460
by practitioners who are
out there in the clinic

00:11:25.460 --> 00:11:27.020
treating patients.

00:11:27.020 --> 00:11:30.320
One good example of an
organization founded in 1993

00:11:30.320 --> 00:11:32.240
that probably many of
you will have heard of

00:11:32.240 --> 00:11:34.820
is the Cochrane Collaboration,
now today just called

00:11:34.820 --> 00:11:36.760
the Cochrane, that
does exactly that.

00:11:36.760 --> 00:11:39.350
It gathers up evidence
for clinicians,

00:11:39.350 --> 00:11:41.829
tries to answer a meaningful
clinical question and say,

00:11:41.829 --> 00:11:43.370
here's what you
should do if you want

00:11:43.370 --> 00:11:46.790
to make your decision based
on the scientific evidence.

00:11:46.790 --> 00:11:49.490
Now it's important to note
here that in the early days

00:11:49.490 --> 00:11:51.470
of the evidence-based
medicine movement,

00:11:51.470 --> 00:11:54.260
this is a movement that's about
collecting science and giving

00:11:54.260 --> 00:11:55.580
it to researchers.

00:11:55.580 --> 00:11:59.850
It's not a movement which
is about critiquing science.

00:11:59.850 --> 00:12:03.180
And yet, the techniques
that evidence-based medicine

00:12:03.180 --> 00:12:06.660
researchers use to try
and compile this evidence

00:12:06.660 --> 00:12:11.430
ends up revealing systematic
flaws in clinical research.

00:12:11.430 --> 00:12:12.390
How does this happen?

00:12:12.390 --> 00:12:14.670
I'll give you an
example here using

00:12:14.670 --> 00:12:16.350
this cryptic little
graphic that's

00:12:16.350 --> 00:12:19.480
at the core of the
Cochrane's logo.

00:12:19.480 --> 00:12:22.050
What this is is it's
a stylized image

00:12:22.050 --> 00:12:24.450
of what's called a forest plot.

00:12:24.450 --> 00:12:27.090
And a forest plot
is a visualization

00:12:27.090 --> 00:12:29.250
of what happens when
you try and combine

00:12:29.250 --> 00:12:31.320
the information from
multiple studies

00:12:31.320 --> 00:12:33.247
or multiple clinical
trials together.

00:12:33.247 --> 00:12:34.830
So to walk you through
the information

00:12:34.830 --> 00:12:36.870
that we're getting
from this graphic here,

00:12:36.870 --> 00:12:41.220
each of these lines here
represents a different study.

00:12:41.220 --> 00:12:43.680
So say, for example,
we found in our review

00:12:43.680 --> 00:12:46.860
of clinical practices that
prostate cancer patients

00:12:46.860 --> 00:12:50.250
in one area of the United
States are eight times as

00:12:50.250 --> 00:12:54.030
likely to get their prostates
removed in early stage cancer

00:12:54.030 --> 00:12:56.220
as patients in another
area of the United States

00:12:56.220 --> 00:12:58.530
where physicians are
practicing differently.

00:12:58.530 --> 00:13:00.660
And we, the Cochrane,
say, OK, let's

00:13:00.660 --> 00:13:02.460
take a look at the
available evidence

00:13:02.460 --> 00:13:05.520
and decide whether or not
surgery actually helps

00:13:05.520 --> 00:13:07.770
early stage prostate patients.

00:13:07.770 --> 00:13:09.540
So we take all of
the clinical trials

00:13:09.540 --> 00:13:10.980
that have evaluated this.

00:13:10.980 --> 00:13:15.120
And each one of these gets
represented by this little box.

00:13:15.120 --> 00:13:17.970
The size of the box represents
the number of patients

00:13:17.970 --> 00:13:19.740
in each clinical trial.

00:13:19.740 --> 00:13:22.410
And it's spatialization
on this scale

00:13:22.410 --> 00:13:25.530
here represents whether the
outcome of the clinical trial

00:13:25.530 --> 00:13:29.310
show that the treatment
was effective or not.

00:13:29.310 --> 00:13:32.504
This middle line here
represents the equipoise point,

00:13:32.504 --> 00:13:34.170
the point at which
the treatment doesn't

00:13:34.170 --> 00:13:35.869
seem to do anything for people.

00:13:35.869 --> 00:13:37.660
So if your results are
right in the middle,

00:13:37.660 --> 00:13:40.260
it doesn't seem to matter
if you get surgery or not.

00:13:40.260 --> 00:13:41.910
If the boxes are
leaning this way,

00:13:41.910 --> 00:13:44.160
that means that
surgery did actually

00:13:44.160 --> 00:13:46.260
impact whatever our
outcome marker was,

00:13:46.260 --> 00:13:48.780
say, the number of years
that these prostate cancer

00:13:48.780 --> 00:13:49.940
patients lived.

00:13:49.940 --> 00:13:51.482
Now if it's leaning
the other way,

00:13:51.482 --> 00:13:53.940
then that says that actually
maybe the surgery harmed them.

00:13:53.940 --> 00:13:56.160
It might have actually
reduced their lifespan because

00:13:56.160 --> 00:13:58.540
of the complications of surgery.

00:13:58.540 --> 00:14:00.600
So what this thing is
here is a forest plot

00:14:00.600 --> 00:14:03.150
is it's a way of giving you all
of that information about all

00:14:03.150 --> 00:14:05.400
these clinical trials
in one graphic.

00:14:05.400 --> 00:14:07.500
And everything is summed
up by this diamond

00:14:07.500 --> 00:14:10.350
here at the bottom, which is the
statistical combination of all

00:14:10.350 --> 00:14:11.790
of those trials together.

00:14:11.790 --> 00:14:14.310
So if you want to know what
does the literature say,

00:14:14.310 --> 00:14:15.900
there's your diamond.

00:14:15.900 --> 00:14:19.050
But what I'd like you to notice
is that this very same graphic

00:14:19.050 --> 00:14:21.720
doesn't just give you
information about similarity.

00:14:21.720 --> 00:14:24.690
It also gives you
information about difference.

00:14:24.690 --> 00:14:28.591
By comparing all of the clinical
trials together in one graphic,

00:14:28.591 --> 00:14:30.090
now you can look
at this and you can

00:14:30.090 --> 00:14:34.620
start to ask questions like,
huh, this clinical trial has

00:14:34.620 --> 00:14:38.220
much more strongly positive
results than the rest.

00:14:38.220 --> 00:14:40.470
This one over here is
leaning a little bit

00:14:40.470 --> 00:14:43.230
towards the negative
effect side.

00:14:43.230 --> 00:14:45.120
And then you can
ask questions like,

00:14:45.120 --> 00:14:48.120
I wonder what accounts for the
differences in the outcomes

00:14:48.120 --> 00:14:50.520
between these clinical trials?

00:14:50.520 --> 00:14:54.150
For example, if I take a look
at all the clinical trials that

00:14:54.150 --> 00:14:57.270
have been funded by the
pharmaceutical industry,

00:14:57.270 --> 00:15:01.630
do I find that they're leaning
more in the positive direction?

00:15:01.630 --> 00:15:04.330
These are the kinds of
questions that researchers

00:15:04.330 --> 00:15:06.460
within the
evidence-based movement--

00:15:06.460 --> 00:15:09.890
evidence-based medicine
movement then begin to ask.

00:15:09.890 --> 00:15:12.910
And asking these questions and
producing the answers to them

00:15:12.910 --> 00:15:17.140
by the mid-2000s has started to
reveal some very serious flaws

00:15:17.140 --> 00:15:18.610
in the system of
clinical trials,

00:15:18.610 --> 00:15:21.970
particularly in
drug development.

00:15:21.970 --> 00:15:24.010
So for example,
one of the problems

00:15:24.010 --> 00:15:26.040
that this type of
research reveals

00:15:26.040 --> 00:15:29.970
is what's called publication
bias or selective publication.

00:15:29.970 --> 00:15:32.269
And the problem is as follows.

00:15:32.269 --> 00:15:33.810
Let's say you're a
doctor, and you're

00:15:33.810 --> 00:15:36.630
interested in prescribing
an antidepressant.

00:15:36.630 --> 00:15:38.490
So you go and take a
look at the literature

00:15:38.490 --> 00:15:41.490
to see what the clinical trials
say about the effectiveness

00:15:41.490 --> 00:15:43.170
of the antidepressant.

00:15:43.170 --> 00:15:45.690
And you look, and you see
what's been published.

00:15:45.690 --> 00:15:48.630
All the studies seem to
indicate that it's pretty good.

00:15:48.630 --> 00:15:50.400
So you go home
confident, thinking

00:15:50.400 --> 00:15:53.130
there is strong evidence for
my use of this antidepressant

00:15:53.130 --> 00:15:54.840
in a clinical setting.

00:15:54.840 --> 00:15:57.660
But now imagine for a moment
that all of the trials that

00:15:57.660 --> 00:16:00.660
showed negative results, where
the drug didn't help people

00:16:00.660 --> 00:16:02.520
or maybe it actually
harmed them,

00:16:02.520 --> 00:16:05.010
those ones just
haven't been published.

00:16:05.010 --> 00:16:07.470
They didn't make it into
the published literature.

00:16:07.470 --> 00:16:10.320
Or maybe they are just in
lower-tier journals, where

00:16:10.320 --> 00:16:12.620
you're less likely to look.

00:16:12.620 --> 00:16:14.340
And in the mid-2000s,
what we see

00:16:14.340 --> 00:16:16.440
is some revelations
here of some instances

00:16:16.440 --> 00:16:18.810
in which pharmaceutical
companies actively

00:16:18.810 --> 00:16:22.290
suppressed the publication
of clinical trials

00:16:22.290 --> 00:16:24.780
with negative results,
thereby creating

00:16:24.780 --> 00:16:28.320
a misleading impression of
the efficacy of those drugs

00:16:28.320 --> 00:16:30.232
in the published literature.

00:16:30.232 --> 00:16:32.190
So this New England
Journal of Medicine article

00:16:32.190 --> 00:16:34.950
tries to show you
systematically just that--

00:16:34.950 --> 00:16:37.050
how it is that the
effect size of this drug

00:16:37.050 --> 00:16:39.630
has been artificially
inflated by having

00:16:39.630 --> 00:16:41.910
those studies with positive
results placed in better

00:16:41.910 --> 00:16:44.880
journals and having the ones
that have negative results

00:16:44.880 --> 00:16:46.304
simply not appear at all.

00:16:46.304 --> 00:16:47.970
And for those of you
in the audience who

00:16:47.970 --> 00:16:50.659
might be psychologists or
historians of psychology,

00:16:50.659 --> 00:16:52.200
one of the names
that you'll probably

00:16:52.200 --> 00:16:53.880
recognize on this
author list here

00:16:53.880 --> 00:16:57.600
is Robert Rosenthal, one of
the founders of meta-analysis

00:16:57.600 --> 00:16:59.370
within the field of psychology.

00:16:59.370 --> 00:17:01.650
So you can see some
fairly direct connections

00:17:01.650 --> 00:17:04.260
here how it is that
meta-analysis is leading

00:17:04.260 --> 00:17:06.119
through into this new
research agenda which

00:17:06.119 --> 00:17:08.880
is about probing difference.

00:17:08.880 --> 00:17:11.010
These issues here are not
merely academic issues.

00:17:11.010 --> 00:17:13.109
They are issues that
get a lot of attention

00:17:13.109 --> 00:17:16.140
within the popular sphere and
within politics, particularly

00:17:16.140 --> 00:17:19.555
when Marcia Angell, who is
the former editor in chief

00:17:19.555 --> 00:17:21.180
of the New England
Journal of Medicine,

00:17:21.180 --> 00:17:22.740
where this article
was published,

00:17:22.740 --> 00:17:26.849
writes this really scathing
popular press book in 2004

00:17:26.849 --> 00:17:30.270
detailing all of the ways in
which she saw, in her position

00:17:30.270 --> 00:17:32.730
as editor in chief,
pharmaceutical companies

00:17:32.730 --> 00:17:35.430
manipulating data in these
ways in order to make

00:17:35.430 --> 00:17:36.960
their products look better.

00:17:36.960 --> 00:17:40.410
And this leads by the mid-2000s
to a bunch of reforms,

00:17:40.410 --> 00:17:44.430
such as legislation requiring
that pharmaceutical companies

00:17:44.430 --> 00:17:48.030
must register their trials in
a publicly available data base

00:17:48.030 --> 00:17:50.550
so that, in theory, you
could go out and look and see

00:17:50.550 --> 00:17:52.470
if there were trials
with negative results

00:17:52.470 --> 00:17:55.985
that were conducted but
then never published.

00:17:55.985 --> 00:17:57.360
So the pharmaceutical
industry is

00:17:57.360 --> 00:18:00.420
having a bad time in the first
decade here of the 21st century

00:18:00.420 --> 00:18:02.250
because of these
numerous scandals

00:18:02.250 --> 00:18:04.430
that have to do with
the conduct of research.

00:18:04.430 --> 00:18:07.290
And that's not the only problem
that the industry is facing.

00:18:07.290 --> 00:18:09.600
The second thing that's
going on in the '90s, maybe

00:18:09.600 --> 00:18:12.300
more visible in
the early 2000s, is

00:18:12.300 --> 00:18:16.690
declines in the productivity
of the pharmaceutical industry.

00:18:16.690 --> 00:18:19.110
So in this image
here, what you see

00:18:19.110 --> 00:18:24.030
is the number of new drugs
approved each year by the FDA

00:18:24.030 --> 00:18:27.630
plotted with R&amp;D, or Research
and Development, expenditure

00:18:27.630 --> 00:18:30.240
on the part of
pharmaceutical companies.

00:18:30.240 --> 00:18:32.220
Now commentators
such as Marcia Angell

00:18:32.220 --> 00:18:35.550
have been very critical
of this nice, neat curve

00:18:35.550 --> 00:18:38.040
here that you see on the R&amp;D
side, which they've argued

00:18:38.040 --> 00:18:39.810
is maybe kind of fictitious.

00:18:39.810 --> 00:18:42.120
But nonetheless, if we
just take a look here

00:18:42.120 --> 00:18:45.012
at the molecular entity
output, or the number of drugs

00:18:45.012 --> 00:18:46.470
being approved,
year over year, you

00:18:46.470 --> 00:18:48.420
can see that it's declining.

00:18:48.420 --> 00:18:51.180
Moreover, what you don't see
from this graph is that a lot

00:18:51.180 --> 00:18:53.640
of these drugs that are being
approved by the FDA at this

00:18:53.640 --> 00:18:57.220
time are what's
called "me-too drugs,"

00:18:57.220 --> 00:19:00.210
meaning they're very similar
to drugs that exist already

00:19:00.210 --> 00:19:01.170
on the market--

00:19:01.170 --> 00:19:04.400
say, yet another statin
to treat your cholesterol,

00:19:04.400 --> 00:19:07.226
when we've already got a bunch
of statins available to us.

00:19:07.226 --> 00:19:08.850
So the concern is,
is both we're seeing

00:19:08.850 --> 00:19:11.004
a decline in the number
of drugs approved,

00:19:11.004 --> 00:19:12.670
and the drugs that
are getting approved,

00:19:12.670 --> 00:19:14.070
they're not really
breakthroughs.

00:19:14.070 --> 00:19:17.340
They're kind of incremental
improvements on patient care,

00:19:17.340 --> 00:19:19.770
if they're really
improvements at all.

00:19:19.770 --> 00:19:22.560
So this is an issue that
is of great concern here,

00:19:22.560 --> 00:19:25.690
both to the pharmaceutical
industry, obviously,

00:19:25.690 --> 00:19:27.960
but also to entities
like the NIH that see it

00:19:27.960 --> 00:19:30.420
as their mission to try
and improve human health.

00:19:30.420 --> 00:19:33.090
And it seems like something
is going wrong here.

00:19:33.090 --> 00:19:36.030
The explanation that people
give for what's going wrong

00:19:36.030 --> 00:19:37.800
is the following.

00:19:37.800 --> 00:19:40.440
The argument in the
2000s is, is that we

00:19:40.440 --> 00:19:43.350
have a translational
research problem.

00:19:43.350 --> 00:19:46.350
We have good science
going on over here.

00:19:46.350 --> 00:19:49.230
We've got clinical development
partners over here.

00:19:49.230 --> 00:19:52.039
But we simply can't bridge
the gap between them.

00:19:52.039 --> 00:19:53.580
If you take a look
at this graph here

00:19:53.580 --> 00:19:55.800
in the context of the
other information presented

00:19:55.800 --> 00:19:57.690
in the original
article, what you'll see

00:19:57.690 --> 00:20:00.600
is that this graph is positioned
right next to this other one

00:20:00.600 --> 00:20:06.027
here, which shows NIH grants and
where the NIH grants are going.

00:20:06.027 --> 00:20:07.860
And the story, you can
see just from the way

00:20:07.860 --> 00:20:09.720
that this is plotted,
is that the NIH

00:20:09.720 --> 00:20:15.030
is giving all this money to
PhDs, not to MDs, or MDs-PHDs,

00:20:15.030 --> 00:20:17.060
and presumably,
the implication is,

00:20:17.060 --> 00:20:19.500
is that by giving money
to basic researchers,

00:20:19.500 --> 00:20:20.990
they're not really
well-positioned

00:20:20.990 --> 00:20:22.970
be able to carry
through the knowledge

00:20:22.970 --> 00:20:25.476
that they find into the clinic.

00:20:25.476 --> 00:20:28.100
Another way of illustrating this
is with this nice graphic that

00:20:28.100 --> 00:20:30.980
accompanies the article,
which plays on the term

00:20:30.980 --> 00:20:35.270
that the article uses called
"the valley of death."

00:20:35.270 --> 00:20:36.615
Nice, right?

00:20:36.615 --> 00:20:38.990
And the idea here is that
you've got your bench scientist

00:20:38.990 --> 00:20:42.020
over here represented with
test tubes and flasks.

00:20:42.020 --> 00:20:44.570
You've got your clinician
over here with a patient.

00:20:44.570 --> 00:20:48.680
And this terrible rickety bridge
is all that's connecting them.

00:20:48.680 --> 00:20:51.290
The argument here being is
that we produce knowledge

00:20:51.290 --> 00:20:52.850
that fails to
actually make it over,

00:20:52.850 --> 00:20:55.550
and good ideas die in
the valley of death.

00:20:55.550 --> 00:20:57.997
And this was an image
that was used ubiquitously

00:20:57.997 --> 00:21:00.080
when I was doing fieldwork
in the cancer community

00:21:00.080 --> 00:21:02.240
around 2010, 2011.

00:21:02.240 --> 00:21:04.790
This was the common
and accepted narrative

00:21:04.790 --> 00:21:06.380
for what was going wrong.

00:21:06.380 --> 00:21:07.430
What's going wrong?

00:21:07.430 --> 00:21:13.480
We're not moving our knowledge
from the bench to the bedside.

00:21:13.480 --> 00:21:15.280
And with this narrative
in mind, the NIH

00:21:15.280 --> 00:21:18.550
invested quite a bit of money in
the 2000s in that first decade

00:21:18.550 --> 00:21:21.700
of the 21st century trying to
develop translational research

00:21:21.700 --> 00:21:23.320
infrastructure,
trying to do things

00:21:23.320 --> 00:21:25.600
to solve what they thought
was the problem here--

00:21:25.600 --> 00:21:27.732
this problem.

00:21:27.732 --> 00:21:29.440
So now we're in a
position to return back

00:21:29.440 --> 00:21:33.040
where we started to this Amgen
article published in 2012

00:21:33.040 --> 00:21:35.020
and to see why it
is that somebody

00:21:35.020 --> 00:21:37.240
from the pharmaceutical
industry was positioned

00:21:37.240 --> 00:21:40.540
to write this thing and why
it is that the NIH took it

00:21:40.540 --> 00:21:44.740
very seriously when it was
published in the literature.

00:21:44.740 --> 00:21:46.957
In their article, Begley
and Ellis, the researchers

00:21:46.957 --> 00:21:48.790
here from Amgen--
actually, only one of them

00:21:48.790 --> 00:21:51.319
is from Amgen, but
that doesn't matter.

00:21:51.319 --> 00:21:53.110
What they're doing here
is there responding

00:21:53.110 --> 00:21:56.260
to a familiar problem about
this lack of productivity

00:21:56.260 --> 00:21:58.720
in the pharmaceutical
industry, but they're flipping

00:21:58.720 --> 00:21:59.860
the script a little bit.

00:21:59.860 --> 00:22:04.240
And they're positioning the
problem in a different place.

00:22:04.240 --> 00:22:07.120
They're saying the problem
is not translation,

00:22:07.120 --> 00:22:09.580
getting things from
bench to bedside.

00:22:09.580 --> 00:22:12.550
The problem is that
the science itself,

00:22:12.550 --> 00:22:16.090
that preclinical
research, it's not good.

00:22:16.090 --> 00:22:19.850
There are systemic
problems in that research.

00:22:19.850 --> 00:22:22.240
So it's a recognized
problem, but it's

00:22:22.240 --> 00:22:24.940
a different way of
formulating the problem,

00:22:24.940 --> 00:22:28.840
a way that most people had
not thought of it before.

00:22:28.840 --> 00:22:30.730
Moreover, the
pharmaceutical industry

00:22:30.730 --> 00:22:32.770
argued that it was in
a really good position

00:22:32.770 --> 00:22:36.310
to try and see these flaws
precisely because of all

00:22:36.310 --> 00:22:38.170
the scandals that
they had weathered

00:22:38.170 --> 00:22:42.166
in the previous decade about the
quality of their own research.

00:22:42.166 --> 00:22:43.540
So if the
pharmaceutical industry

00:22:43.540 --> 00:22:46.120
had been getting hit hard with
negative press about the way

00:22:46.120 --> 00:22:48.760
that it conducted
its experiments, when

00:22:48.760 --> 00:22:51.034
it was looking across
the hallway, so to speak,

00:22:51.034 --> 00:22:53.200
at the bench scientists and
seeing the way that they

00:22:53.200 --> 00:22:57.790
did their research, they said,
we see these same problems.

00:22:57.790 --> 00:23:00.430
So how is it that
irreproducibility in the lab

00:23:00.430 --> 00:23:02.650
could be both widely
experienced and sort

00:23:02.650 --> 00:23:04.390
of hiding in plain sight?

00:23:04.390 --> 00:23:06.670
Well, it was a problem
that everyone recognized,

00:23:06.670 --> 00:23:09.040
but it was a problem
that people assumed

00:23:09.040 --> 00:23:12.719
existed in a different place
of the so-called "pipeline."

00:23:12.719 --> 00:23:14.260
Everyone was thinking
the problem was

00:23:14.260 --> 00:23:17.680
with the quality of clinical
research, or translation,

00:23:17.680 --> 00:23:20.690
not with the quality of
basic research itself--

00:23:20.690 --> 00:23:24.842
so an accepted problem, but
a really new formulation.

00:23:24.842 --> 00:23:27.300
So now what I'm going to do
with this historical foundation

00:23:27.300 --> 00:23:30.390
in place is switch gears here
in the second half of the talk

00:23:30.390 --> 00:23:32.400
and focus more on
two lessons that we

00:23:32.400 --> 00:23:34.890
can learn from this history.

00:23:34.890 --> 00:23:37.410
And the first lesson that
I want to draw out of this

00:23:37.410 --> 00:23:40.800
is that I think we really
need better ways of talking

00:23:40.800 --> 00:23:46.630
about certainty or uncertainty
in scientific information.

00:23:46.630 --> 00:23:49.150
One of the things that happens
during the '90s with the rise

00:23:49.150 --> 00:23:51.130
of the evidence-based
medicine movement

00:23:51.130 --> 00:23:55.120
is we see the proliferation
of vocabularies and systems

00:23:55.120 --> 00:23:57.730
for trying to talk about
the relative strength

00:23:57.730 --> 00:23:59.650
of clinical evidence.

00:23:59.650 --> 00:24:01.300
For example,
probably many of you

00:24:01.300 --> 00:24:04.390
will have seen something
like this thing,

00:24:04.390 --> 00:24:08.470
the pyramid of evidence or the
levels of evidence pyramid.

00:24:08.470 --> 00:24:11.230
This particular one is taken
from an evidence-based medicine

00:24:11.230 --> 00:24:13.840
published in 2000,
but there are lots

00:24:13.840 --> 00:24:16.360
of variations that pop
up in places elsewhere

00:24:16.360 --> 00:24:19.100
with slight tweaks as to
what's included in it.

00:24:19.100 --> 00:24:21.910
But what this thing is,
really, is a motivation

00:24:21.910 --> 00:24:24.760
or a way of trying to
get clinicians thinking

00:24:24.760 --> 00:24:27.490
about the differential
strength of the evidence

00:24:27.490 --> 00:24:29.440
that they're basing
their opinions on--

00:24:29.440 --> 00:24:29.950
i.e.

00:24:29.950 --> 00:24:32.830
not all forms of evidence
are created equal

00:24:32.830 --> 00:24:34.720
or should be treated as equal.

00:24:34.720 --> 00:24:37.450
So this graphic is
trying to remind you--

00:24:37.450 --> 00:24:40.570
randomized clinical trials
are better evidence than,

00:24:40.570 --> 00:24:43.480
for example, an expert's
opinion who's saying,

00:24:43.480 --> 00:24:46.480
based on my years of clinical
experience, here's what I do.

00:24:46.480 --> 00:24:48.820
You should take that with
a bigger grain of salt

00:24:48.820 --> 00:24:50.854
than something that
comes from an RCT.

00:24:50.854 --> 00:24:52.270
So this is part
of the development

00:24:52.270 --> 00:24:56.350
of a vocabulary for how to
talk about degrees of certainty

00:24:56.350 --> 00:24:58.810
within the clinical information.

00:24:58.810 --> 00:25:01.580
A second example-- this
is a web page taken

00:25:01.580 --> 00:25:03.380
from the website UpToDate.

00:25:03.380 --> 00:25:05.540
The text here is not important.

00:25:05.540 --> 00:25:07.514
What I would like you
to notice, though,

00:25:07.514 --> 00:25:08.930
is these little
brackets that I've

00:25:08.930 --> 00:25:11.360
highlighted that contain
these cryptic codes grade

00:25:11.360 --> 00:25:13.850
1C, grade 1B.

00:25:13.850 --> 00:25:15.530
What this thing is
is it's another kind

00:25:15.530 --> 00:25:17.570
of evidence-based
medicine invention,

00:25:17.570 --> 00:25:19.610
again, founded in
the 1990s, which

00:25:19.610 --> 00:25:22.070
is a subscription-based
service where

00:25:22.070 --> 00:25:24.080
doctors who are
practicing in the clinic

00:25:24.080 --> 00:25:27.650
can go and quickly look up
the best available evidence

00:25:27.650 --> 00:25:29.460
on a particular topic.

00:25:29.460 --> 00:25:32.240
So if you want to know how to
treat a patient with leiomyoma,

00:25:32.240 --> 00:25:33.870
you can go and see--

00:25:33.870 --> 00:25:35.810
here's the evidence.

00:25:35.810 --> 00:25:37.430
What these things
in brackets, though,

00:25:37.430 --> 00:25:40.180
are when you click
through on them,

00:25:40.180 --> 00:25:42.620
they're little notes about
the strength of the evidence

00:25:42.620 --> 00:25:44.110
and-- importantly here--

00:25:44.110 --> 00:25:48.040
to which kinds of patients
the evidence applies,

00:25:48.040 --> 00:25:50.750
recognizing that not
all patients are similar

00:25:50.750 --> 00:25:53.000
and a clinical trial that
was done, say, in an older

00:25:53.000 --> 00:25:54.980
population may
not actually apply

00:25:54.980 --> 00:25:58.070
to your younger patient who's
sitting there in front of you.

00:25:58.070 --> 00:25:59.840
So with each of
these recommendations

00:25:59.840 --> 00:26:01.220
within this text--

00:26:01.220 --> 00:26:04.880
grade 2B, grade 1C, you can
click through, and you'll see--

00:26:04.880 --> 00:26:06.470
this is a weak recommendation.

00:26:06.470 --> 00:26:08.120
We see places where
you might want

00:26:08.120 --> 00:26:10.640
to go against this in
your clinical practice.

00:26:10.640 --> 00:26:13.140
Or this is a strong
recommendation.

00:26:13.140 --> 00:26:15.900
Most patients should
be treated in this way.

00:26:15.900 --> 00:26:18.080
So this is another example
of a kind of vocabulary

00:26:18.080 --> 00:26:20.770
that clinicians are developing
to try and say, all right,

00:26:20.770 --> 00:26:24.760
here's the relative
strength of the data.

00:26:24.760 --> 00:26:27.550
Now in contrast, compare that
to the preclinical world,

00:26:27.550 --> 00:26:30.460
where there are relatively few
or reasonably underdeveloped

00:26:30.460 --> 00:26:32.740
vocabularies for talking
about differential

00:26:32.740 --> 00:26:34.247
certainty in your data.

00:26:34.247 --> 00:26:35.830
This is one of the
things that I spent

00:26:35.830 --> 00:26:37.990
quite a lot of time
studying in my first book

00:26:37.990 --> 00:26:41.260
here, Model Behavior, where
I was in this laboratory

00:26:41.260 --> 00:26:43.390
with researchers who
were using mouse models

00:26:43.390 --> 00:26:45.130
of psychiatric disorders.

00:26:45.130 --> 00:26:47.560
And they themselves
saw, as Meredith said,

00:26:47.560 --> 00:26:50.380
all kinds of uncertainties
in their own research.

00:26:50.380 --> 00:26:52.851
And so I was interested in,
how did they communicate this,

00:26:52.851 --> 00:26:53.350
then?

00:26:53.350 --> 00:26:55.360
How did they let you
know that they're not

00:26:55.360 --> 00:26:58.570
entirely confident in
what they're doing?

00:26:58.570 --> 00:27:00.340
Take, for example,
this test, one which

00:27:00.340 --> 00:27:02.200
I spent a lot of time studying.

00:27:02.200 --> 00:27:04.690
It's called the
elevated plus maze.

00:27:04.690 --> 00:27:07.180
And it's a research
setup that researchers

00:27:07.180 --> 00:27:10.150
use both in basic
research and drug

00:27:10.150 --> 00:27:13.220
development to study anxiety.

00:27:13.220 --> 00:27:15.140
What you do is you
take your mouse,

00:27:15.140 --> 00:27:17.240
you put it at the
center of the maze,

00:27:17.240 --> 00:27:20.270
and then you measure how much
time it spends hanging out

00:27:20.270 --> 00:27:22.490
in these closed areas
of the maze that

00:27:22.490 --> 00:27:25.610
have the high protected
walls versus hanging out

00:27:25.610 --> 00:27:28.550
on these open platforms--

00:27:28.550 --> 00:27:30.590
very commonly used test.

00:27:30.590 --> 00:27:33.560
So how is it that researchers
signaled their uncertainty

00:27:33.560 --> 00:27:36.680
about what was going on here
and how much of a good test

00:27:36.680 --> 00:27:38.270
this actually was?

00:27:38.270 --> 00:27:42.950
They called it "a test of
anxiety-like behavior"--

00:27:42.950 --> 00:27:46.190
really rolls off
the tongue, right?

00:27:46.190 --> 00:27:48.080
I was really
curious when I first

00:27:48.080 --> 00:27:50.900
entered the lab to hear
people saying things like,

00:27:50.900 --> 00:27:53.360
well, in this test of
anxiety-like behavior

00:27:53.360 --> 00:27:55.670
or in this
depression-relevant phenotype.

00:27:55.670 --> 00:27:57.780
And they would say
that all the time,

00:27:57.780 --> 00:27:59.780
even when they were
talking amongst themselves.

00:27:59.780 --> 00:28:01.190
Why did they do this?

00:28:01.190 --> 00:28:03.920
This vocabulary mattered
to them because it inserted

00:28:03.920 --> 00:28:06.470
that little bit of uncertainty
that what they were studying

00:28:06.470 --> 00:28:08.810
was not anxiety.

00:28:08.810 --> 00:28:10.790
It was anxiety-like.

00:28:10.790 --> 00:28:15.060
It seemed like anxiety, but it
was not exactly the same thing.

00:28:15.060 --> 00:28:17.150
This vocabulary was one
that worked quite well

00:28:17.150 --> 00:28:19.400
within this particular
group of researchers

00:28:19.400 --> 00:28:21.110
who knew what they
were talking about,

00:28:21.110 --> 00:28:23.540
but you try and take
this vocabulary outside

00:28:23.540 --> 00:28:26.890
of the laboratory to communicate
uncertainty to someone,

00:28:26.890 --> 00:28:28.280
and it kind of falls apart.

00:28:28.280 --> 00:28:29.546
No one knows what you mean.

00:28:29.546 --> 00:28:30.920
It just sounds
like you're saying

00:28:30.920 --> 00:28:32.522
something overly complicated.

00:28:32.522 --> 00:28:33.980
And the journalist
will say to you,

00:28:33.980 --> 00:28:36.170
can we call it a
test for anxiety?

00:28:36.170 --> 00:28:38.480
And the scientist
will sort of shrink.

00:28:38.480 --> 00:28:41.540
In fact, one of the hallmarks
of the reproducibility crisis

00:28:41.540 --> 00:28:44.450
is the loss of the
one common vocabulary

00:28:44.450 --> 00:28:46.220
that bench scientists
and many others

00:28:46.220 --> 00:28:48.230
tend to use for
expressing degrees

00:28:48.230 --> 00:28:50.810
of certainty, which
is null hypothesis

00:28:50.810 --> 00:28:52.760
testing and p-values.

00:28:52.760 --> 00:28:54.350
These have recently
come under fire

00:28:54.350 --> 00:28:56.390
from very prominent
statisticians

00:28:56.390 --> 00:28:58.970
for being misused,
over-interpreted,

00:28:58.970 --> 00:29:02.960
under-interpreted, and generally
bad ways of communicating

00:29:02.960 --> 00:29:06.170
the degree of confidence that
we should have in findings.

00:29:06.170 --> 00:29:07.819
So the point that
I want to make here

00:29:07.819 --> 00:29:09.860
is that, really, the moment
that we're living in,

00:29:09.860 --> 00:29:13.310
we have a lack of a
vocabulary for dealing with

00:29:13.310 --> 00:29:16.690
or communicating uncertainty.

00:29:16.690 --> 00:29:18.142
What do we have instead?

00:29:18.142 --> 00:29:19.600
Well, in the popular
press, what we

00:29:19.600 --> 00:29:22.280
have is a lot of
conversation about truth.

00:29:22.280 --> 00:29:24.160
And truth is not
a great language

00:29:24.160 --> 00:29:27.610
for talking about shades of
gray because truth, generally

00:29:27.610 --> 00:29:29.740
speaking, seems binary.

00:29:29.740 --> 00:29:31.000
We have truth.

00:29:31.000 --> 00:29:32.440
We have falsity.

00:29:32.440 --> 00:29:35.710
We have truth or post-truth.

00:29:35.710 --> 00:29:38.620
We don't have
truthiness, exactly.

00:29:38.620 --> 00:29:40.690
And so when these
conversations are taking place

00:29:40.690 --> 00:29:43.780
in the popular press that
are focused on truth,

00:29:43.780 --> 00:29:46.330
the idea that the
truth is wearing off

00:29:46.330 --> 00:29:50.230
or that research is unreliable
gives you the sense of crisis.

00:29:50.230 --> 00:29:53.350
It gives you the sense that
something has gone wrong.

00:29:53.350 --> 00:29:55.360
There is no indication
here that maybe we just

00:29:55.360 --> 00:29:58.210
need to downgrade our
confidence in particular ways

00:29:58.210 --> 00:29:59.830
or particular situations.

00:29:59.830 --> 00:30:03.640
It seems like science
has just failed, broken.

00:30:03.640 --> 00:30:05.290
And you can see
from the images here

00:30:05.290 --> 00:30:08.980
of people falling through
space, like the whole thing--

00:30:08.980 --> 00:30:11.290
the rug has come out
from underneath of them.

00:30:11.290 --> 00:30:12.670
So truth and falsity--

00:30:12.670 --> 00:30:14.950
I think, a poor language
for talking about this.

00:30:14.950 --> 00:30:17.800
And yet, we do see
practitioners attaching

00:30:17.800 --> 00:30:20.130
onto this very same language.

00:30:20.130 --> 00:30:23.080
Here's a group of scientists
and librarians at University

00:30:23.080 --> 00:30:26.290
of Utah who are doing a lot of
organizing and infrastructure

00:30:26.290 --> 00:30:28.660
building around reproducibility.

00:30:28.660 --> 00:30:31.780
And what did they choose as
their social media campaign

00:30:31.780 --> 00:30:34.141
hashtag?

00:30:34.141 --> 00:30:37.740
#makeresearchtrue.

00:30:37.740 --> 00:30:40.620
You can tell what
they're going for here.

00:30:40.620 --> 00:30:44.940
And yet, the implication of
this is, well, what is it now?

00:30:44.940 --> 00:30:46.410
False?

00:30:46.410 --> 00:30:49.350
So it's not a good vocabulary
for trying to express

00:30:49.350 --> 00:30:50.732
degrees of certainty.

00:30:50.732 --> 00:30:52.440
And I think that this
is one of the traps

00:30:52.440 --> 00:30:55.530
that we find ourselves in here
with the reproducibility crisis

00:30:55.530 --> 00:30:57.840
in preclinical research,
in particular, is

00:30:57.840 --> 00:31:00.270
that that same infrastructure
for talking about shades

00:31:00.270 --> 00:31:02.520
of gray in terms
of our confidence,

00:31:02.520 --> 00:31:03.705
it doesn't really exist.

00:31:07.054 --> 00:31:09.220
The second lesson that I
think is to be learned here

00:31:09.220 --> 00:31:11.170
from thinking about the
reproducibility crisis

00:31:11.170 --> 00:31:13.810
in the context of
clinical research reform

00:31:13.810 --> 00:31:16.300
is that we need a
lot more attention

00:31:16.300 --> 00:31:21.610
to the dynamics of power
within research laboratories.

00:31:21.610 --> 00:31:24.310
Now if you put the
history of reproducibility

00:31:24.310 --> 00:31:26.470
in preclinical
research side by side

00:31:26.470 --> 00:31:28.180
with that of clinical
research, one

00:31:28.180 --> 00:31:29.950
of the things that you're
going to notice immediately--

00:31:29.950 --> 00:31:32.020
or that I notice-- is
that it's a lot harder

00:31:32.020 --> 00:31:34.480
to tell a good
story about what's

00:31:34.480 --> 00:31:37.180
going on in the labs
versus the story

00:31:37.180 --> 00:31:39.790
that I told you about the
pharmaceutical industry.

00:31:39.790 --> 00:31:42.010
And that's because the
pharmaceutical industry

00:31:42.010 --> 00:31:45.230
makes a really good
villain in the story.

00:31:45.230 --> 00:31:47.260
So if you want to
say things like we

00:31:47.260 --> 00:31:50.410
have a problem of
selective reporting here,

00:31:50.410 --> 00:31:52.480
you can tell an easy
story about that.

00:31:52.480 --> 00:31:54.970
You can say, well, that's
because the pharmaceutical

00:31:54.970 --> 00:31:58.240
industry really only cares
about making profits and selling

00:31:58.240 --> 00:31:59.170
its drugs.

00:31:59.170 --> 00:32:02.140
And that's the reason why
they're selectively reporting.

00:32:02.140 --> 00:32:04.300
Now if you turn that
around and think

00:32:04.300 --> 00:32:06.580
about the context
of the laboratory,

00:32:06.580 --> 00:32:08.350
here, it's a lot
more uncomfortable

00:32:08.350 --> 00:32:11.170
because its researchers
themselves calling out

00:32:11.170 --> 00:32:13.900
other researchers
on their practices

00:32:13.900 --> 00:32:16.090
and because it's
not entirely clear

00:32:16.090 --> 00:32:18.100
what the driving motivation is.

00:32:18.100 --> 00:32:20.650
So the problem of selective
reporting in the basic research

00:32:20.650 --> 00:32:21.520
world--

00:32:21.520 --> 00:32:25.300
is that because of pressure
to publish from funders,

00:32:25.300 --> 00:32:28.870
from your tenure committee,
from journals who

00:32:28.870 --> 00:32:30.580
want to publish novel results?

00:32:30.580 --> 00:32:31.650
Or is it internal?

00:32:31.650 --> 00:32:33.790
Is it your own biases?

00:32:33.790 --> 00:32:35.950
And what you can see
from this survey here

00:32:35.950 --> 00:32:38.710
is that in the various ways
of interpreting whether or not

00:32:38.710 --> 00:32:42.370
this is an external pressure or
something coming from within,

00:32:42.370 --> 00:32:46.630
people are tending to choose the
external pressure narrative--

00:32:46.630 --> 00:32:49.251
pressure to publish coming
from somewhere else.

00:32:49.251 --> 00:32:50.500
And this makes a lot of sense.

00:32:50.500 --> 00:32:52.390
And I have some deep sympathy
with the scientists that

00:32:52.390 --> 00:32:54.190
are trying to grapple
with this because

00:32:54.190 --> 00:32:56.470
in this particular case,
it's like the call's coming

00:32:56.470 --> 00:32:57.874
from inside the house.

00:32:57.874 --> 00:32:59.290
So it's a lot
harder to figure out

00:32:59.290 --> 00:33:01.330
how to talk about this thing.

00:33:01.330 --> 00:33:03.040
I want to pause here
at this point here

00:33:03.040 --> 00:33:05.140
and give a shout out to
my Radcliffe research

00:33:05.140 --> 00:33:07.360
fellows who are
this year mapping

00:33:07.360 --> 00:33:10.360
with me this discursive space
about the various problems

00:33:10.360 --> 00:33:13.910
that people identify and the
solutions that they point to.

00:33:13.910 --> 00:33:16.357
And unfortunately, we don't
have the data yet ready

00:33:16.357 --> 00:33:18.940
for prime time to show you, so
I'm relying on this survey data

00:33:18.940 --> 00:33:19.720
instead.

00:33:19.720 --> 00:33:22.312
But we're doing a lot more
work to comprehensively map

00:33:22.312 --> 00:33:23.770
the things that
people are pointing

00:33:23.770 --> 00:33:26.170
to as the sources of
problems and suggesting

00:33:26.170 --> 00:33:28.690
as potential solutions.

00:33:28.690 --> 00:33:33.220
So externalizing narratives
are kind of the fare of the day

00:33:33.220 --> 00:33:33.910
here.

00:33:33.910 --> 00:33:36.310
And yet we have a
large body of research

00:33:36.310 --> 00:33:39.340
that I've contributed to in
science and technology studies

00:33:39.340 --> 00:33:42.400
on what the internal dynamics
of the laboratory look

00:33:42.400 --> 00:33:44.320
like that we can draw
to think about some

00:33:44.320 --> 00:33:46.540
of the sources of the problems.

00:33:46.540 --> 00:33:49.150
For example, I'll
take here a classic

00:33:49.150 --> 00:33:50.440
of laboratory ethnography.

00:33:50.440 --> 00:33:52.560
This is one of the
first works where

00:33:52.560 --> 00:33:56.140
a sociologist, in this case,
decided to go inside the lab

00:33:56.140 --> 00:33:58.810
and study scientific
cultures as cultures

00:33:58.810 --> 00:34:00.400
in all of their richness.

00:34:00.400 --> 00:34:04.690
And conveniently for us, he
focused on reproducibility.

00:34:04.690 --> 00:34:07.330
One of Harry
Collins' key insights

00:34:07.330 --> 00:34:11.469
is that no two experiments
are ever the same.

00:34:11.469 --> 00:34:14.920
And so in trying to decide
what's similar enough

00:34:14.920 --> 00:34:17.380
to count as a
replication, that's

00:34:17.380 --> 00:34:21.070
the place in which a lot of
human judgment and human bias

00:34:21.070 --> 00:34:23.260
starts to creep in.

00:34:23.260 --> 00:34:27.489
For example, say you've
got two researchers here--

00:34:27.489 --> 00:34:30.520
in this case, myself and my
little sister on a family

00:34:30.520 --> 00:34:32.860
vacation looking fabulous.

00:34:32.860 --> 00:34:34.960
In many ways, we're
quite similar.

00:34:34.960 --> 00:34:36.520
We've got the same haircut.

00:34:36.520 --> 00:34:38.290
We've got the same
dresses and sandals.

00:34:38.290 --> 00:34:40.600
We were raised in
the same house.

00:34:40.600 --> 00:34:43.389
But in some significant
ways, we're also different.

00:34:43.389 --> 00:34:45.219
We don't share all
of our genetics.

00:34:45.219 --> 00:34:47.949
Perhaps we're working in labs
that have different equipment.

00:34:47.949 --> 00:34:50.260
Perhaps one of us is a
more skilled researcher

00:34:50.260 --> 00:34:51.380
than the other.

00:34:51.380 --> 00:34:55.090
So are we similar enough for
the purposes of comparison?

00:34:55.090 --> 00:34:57.640
Or are we different
in meaningful ways?

00:34:57.640 --> 00:35:00.610
That's a judgment where
often culture plays in

00:35:00.610 --> 00:35:03.040
because we tend to pay attention
to some kinds of things

00:35:03.040 --> 00:35:04.487
more than others.

00:35:04.487 --> 00:35:06.820
Now in the real-life case
that Harry Collins was talking

00:35:06.820 --> 00:35:09.670
about, he was looking at
early '80s experimentation

00:35:09.670 --> 00:35:11.620
around gravitational waves.

00:35:11.620 --> 00:35:14.080
And he was studying two
different laboratories,

00:35:14.080 --> 00:35:16.090
one of whom had
conducted an experiment

00:35:16.090 --> 00:35:17.740
and claimed to
have found evidence

00:35:17.740 --> 00:35:20.470
of gravitational waves,
and a second laboratory

00:35:20.470 --> 00:35:24.550
that conducted an experiment and
said they found no such thing.

00:35:24.550 --> 00:35:27.280
And what Collins does is he
looks at how the debate carries

00:35:27.280 --> 00:35:28.840
out and how it is
that scientists

00:35:28.840 --> 00:35:32.170
try to decide what's real,
in this case, and what's not.

00:35:32.170 --> 00:35:35.470
And he points out that this
second experiment, this failure

00:35:35.470 --> 00:35:38.350
to replicate, is very
unclear because it

00:35:38.350 --> 00:35:41.560
could be that they just didn't
find gravitational waves.

00:35:41.560 --> 00:35:44.404
It could be that the
experiment was also bad.

00:35:44.404 --> 00:35:45.820
Maybe their equipment
didn't work.

00:35:45.820 --> 00:35:48.470
Maybe they weren't as
competent experimenters.

00:35:48.470 --> 00:35:50.470
So it's not entirely
clear how to judge this.

00:35:50.470 --> 00:35:53.770
And this is why the debate
plays out for a long time.

00:35:53.770 --> 00:35:55.960
But importantly, the case
that Harry Collins here

00:35:55.960 --> 00:35:59.470
is talking about is one where
we have two high-status,

00:35:59.470 --> 00:36:03.640
well-funded labs who are trying
to debate whose results should

00:36:03.640 --> 00:36:05.410
be taken as credible.

00:36:05.410 --> 00:36:08.500
This is not the way that
irreproducibility presents

00:36:08.500 --> 00:36:10.277
itself most of the time.

00:36:10.277 --> 00:36:11.860
If you think about
biomedicine and who

00:36:11.860 --> 00:36:14.640
does most of the research
in the biomedical world,

00:36:14.640 --> 00:36:16.194
it's graduate students.

00:36:16.194 --> 00:36:17.860
And that power
differential is something

00:36:17.860 --> 00:36:19.780
that we really need to
take into account when

00:36:19.780 --> 00:36:23.710
thinking about how easy it is
to recognize irreproducibility.

00:36:23.710 --> 00:36:25.570
So what I'm going
to show you now here

00:36:25.570 --> 00:36:29.260
is a clip from a training
video produced by the NIH.

00:36:29.260 --> 00:36:31.990
And this clip is meant to be
shown to graduate students

00:36:31.990 --> 00:36:34.180
in the context of,
say, a lab meeting

00:36:34.180 --> 00:36:36.710
to talk about irreproducibility
in their own lab

00:36:36.710 --> 00:36:38.830
and how it is that they're
going to address it.

00:36:38.830 --> 00:36:41.140
And I think this video will
make pretty clear for you

00:36:41.140 --> 00:36:42.970
some of the issues of
power differentials

00:36:42.970 --> 00:36:44.202
that I've been talking about.

00:36:44.202 --> 00:36:45.160
So I'll play this clip.

00:36:45.160 --> 00:36:48.990
It's about two or
so minutes long.

00:36:48.990 --> 00:36:50.700
- I performed the
experiment exactly

00:36:50.700 --> 00:36:52.530
as Donna described
it in her protocol.

00:36:52.530 --> 00:36:56.910
And compared with her results,
mine just aren't matching up.

00:36:56.910 --> 00:36:59.452
I just can't get the results to
be statistically significant.

00:36:59.452 --> 00:37:01.951
- Well, something may be wrong
with the way you're doing it,

00:37:01.951 --> 00:37:02.970
then.

00:37:02.970 --> 00:37:03.872
- I guess.

00:37:03.872 --> 00:37:06.330
- This is the fourth protocol
that Donna perfected when she

00:37:06.330 --> 00:37:08.550
was postdocing here in the lab.

00:37:08.550 --> 00:37:10.470
I mean, this is a
good study design.

00:37:10.470 --> 00:37:13.210
I really don't get why you
can't reproduce it either.

00:37:13.210 --> 00:37:16.780
- I'm following everything to
the T exactly as described.

00:37:16.780 --> 00:37:19.570
It's just so weird
that it won't work.

00:37:19.570 --> 00:37:23.200
- Well, let me ask you this,
how many samples did you use?

00:37:23.200 --> 00:37:25.750
- I used eight mice per group.

00:37:25.750 --> 00:37:27.160
- Let's try this.

00:37:27.160 --> 00:37:29.500
Add two more mice to each group.

00:37:29.500 --> 00:37:32.350
Then try a different
statistical method.

00:37:32.350 --> 00:37:34.390
If I remember
correctly, I believe

00:37:34.390 --> 00:37:36.532
Donna performed a two-way ANOVA.

00:37:36.532 --> 00:37:38.740
See if changing those
parameters gets you the results

00:37:38.740 --> 00:37:39.700
we're looking for here.

00:37:39.700 --> 00:37:40.850
- That's a good idea.

00:37:40.850 --> 00:37:44.800
Remember, Robin, toss out
anything greater than 10.

00:37:44.800 --> 00:37:47.260
The normal range for living
cells is three to seven,

00:37:47.260 --> 00:37:50.055
so anything higher than that
is probably due to cell death.

00:37:50.055 --> 00:37:50.930
So keep that in mind.

00:37:50.930 --> 00:37:52.160
It could make a difference.

00:37:52.160 --> 00:37:52.837
- OK.

00:37:52.837 --> 00:37:53.420
Thanks, Jamal.

00:37:53.420 --> 00:37:55.300
- And let me know
how you do, OK?

00:37:55.300 --> 00:37:56.860
- Of course, Dr. Fielding.

00:37:56.860 --> 00:37:59.070
- Please, call me Harry.

00:37:59.070 --> 00:38:00.510
- Dr. Fielding.

00:38:00.510 --> 00:38:01.680
- Hey, she's new.

00:38:01.680 --> 00:38:02.710
You did the same thing.

00:38:02.710 --> 00:38:03.630
- No, I didn't.

00:38:03.630 --> 00:38:04.350
- Yes, you did.

00:38:04.350 --> 00:38:05.322
- Oh, come on.

00:38:10.668 --> 00:38:11.640
- Second scene.

00:38:15.060 --> 00:38:18.280
- So where are we here?

00:38:18.280 --> 00:38:21.070
- I did what you said, and I
added the two mice per group.

00:38:21.070 --> 00:38:24.820
And look, it's still not
statistically significant.

00:38:24.820 --> 00:38:27.370
These results are inconclusive,
and they don't match

00:38:27.370 --> 00:38:28.720
with Donna's results at all.

00:38:28.720 --> 00:38:30.490
- And you varied the
statistical test,

00:38:30.490 --> 00:38:32.000
ran a two-way ANOVA this time?

00:38:32.000 --> 00:38:33.160
- Yes.

00:38:33.160 --> 00:38:36.900
I mean, why is this happening?

00:38:36.900 --> 00:38:39.690
- Robin, I've been watching you
a little bit in the lab here.

00:38:39.690 --> 00:38:41.310
And I hate to say
this, but it seems

00:38:41.310 --> 00:38:44.290
like you're struggling a bit.

00:38:44.290 --> 00:38:45.401
- What?

00:38:45.401 --> 00:38:47.150
- Sometimes students
come in here and just

00:38:47.150 --> 00:38:49.770
can't hack it in grad school.

00:38:49.770 --> 00:38:54.930
- It's just embarrassing that
I can't repeat this test.

00:38:54.930 --> 00:38:55.770
- I'm worried, too.

00:38:55.770 --> 00:38:58.470
We do consistently
high-quality work here, Robin.

00:38:58.470 --> 00:39:00.720
We just can't afford to lower
our standards like this.

00:39:04.620 --> 00:39:05.850
- I'm sorry, Dr. Fielding.

00:39:14.910 --> 00:39:16.590
- So that's half of the video.

00:39:16.590 --> 00:39:21.630
In the second half, the PI
realizes the error of his ways,

00:39:21.630 --> 00:39:25.350
that his postdoc Robin has been
doing good science all along,

00:39:25.350 --> 00:39:28.180
does a mea culpa, and
everything is resolved.

00:39:28.180 --> 00:39:30.630
But I think that
you can probably

00:39:30.630 --> 00:39:33.090
imagine it's a pretty
reasonable hypothesis

00:39:33.090 --> 00:39:37.110
to assume that the story ends
in exactly this place in a lot

00:39:37.110 --> 00:39:39.930
of other moments in history.

00:39:39.930 --> 00:39:42.930
We can see here that there
are power dynamics at play,

00:39:42.930 --> 00:39:46.170
overlaid with race and
gender, that are really

00:39:46.170 --> 00:39:49.110
determining here
how we interpret

00:39:49.110 --> 00:39:52.170
the outcome of a
failure to replicate.

00:39:52.170 --> 00:39:54.840
This is a third way in which
irreproducibility could

00:39:54.840 --> 00:39:56.640
be hiding in plain sight--

00:39:56.640 --> 00:39:59.730
that we're seeing
irreproducibility and just

00:39:59.730 --> 00:40:02.850
misclassifying it as error
on the part of the people

00:40:02.850 --> 00:40:05.250
that are doing the research.

00:40:05.250 --> 00:40:08.040
This is something here that
we see a little bit coming up

00:40:08.040 --> 00:40:09.750
in reproducibility
conversations.

00:40:09.750 --> 00:40:12.840
Obviously, I've taken this
out of the NIH's own training

00:40:12.840 --> 00:40:13.560
guide.

00:40:13.560 --> 00:40:16.350
But it is not something that
is as visible as it really

00:40:16.350 --> 00:40:17.670
needs to be.

00:40:17.670 --> 00:40:20.400
For example, if we take a look
at the discussion guide that

00:40:20.400 --> 00:40:22.710
accompanies this video
that the NIH provides

00:40:22.710 --> 00:40:24.840
for you to talk
to your lab, they

00:40:24.840 --> 00:40:27.150
put their finger on
precisely the problem

00:40:27.150 --> 00:40:29.960
that Harry Collins identifies.

00:40:29.960 --> 00:40:33.660
How do you know what normal is
if you don't know the result?

00:40:33.660 --> 00:40:36.920
There is that interpretive
space where human judgment is,

00:40:36.920 --> 00:40:39.200
where you're saying, is
this a correct result,

00:40:39.200 --> 00:40:40.370
or is this an error?

00:40:40.370 --> 00:40:42.069
Is this a true finding--

00:40:42.069 --> 00:40:43.610
that there's nothing
there-- or is it

00:40:43.610 --> 00:40:45.200
simply that we didn't
try hard enough

00:40:45.200 --> 00:40:46.970
to set up this experiment?

00:40:46.970 --> 00:40:49.130
So they've got their
finger on the problem,

00:40:49.130 --> 00:40:50.750
but when it comes
to actually talking

00:40:50.750 --> 00:40:53.870
about the power dynamics that
would play into that judgment,

00:40:53.870 --> 00:40:55.647
here's where they
really back off.

00:40:55.647 --> 00:40:57.230
This is what the
question in the guide

00:40:57.230 --> 00:41:01.970
says with respect to Dr.
Fielding's treatment of Robin.

00:41:01.970 --> 00:41:05.330
Do you think Dr. Fielding
was too hard on Robin?

00:41:05.330 --> 00:41:07.730
Was there a more appropriate
and effective approach

00:41:07.730 --> 00:41:09.500
that he could have
taken when Robin was

00:41:09.500 --> 00:41:13.840
struggling to replicate
Donna's results?

00:41:13.840 --> 00:41:16.540
So really, what's
being ignored here

00:41:16.540 --> 00:41:19.900
is that the PI in this
case wasn't asking him

00:41:19.900 --> 00:41:23.440
this question about what
is normal and what's not.

00:41:23.440 --> 00:41:27.490
He believed that he knew already
what the correct result was--

00:41:27.490 --> 00:41:30.410
the one that his prior
postdoc had already published

00:41:30.410 --> 00:41:32.710
and that he had his name
on in the literature.

00:41:32.710 --> 00:41:35.620
And he believed instead that
what his graduate student was

00:41:35.620 --> 00:41:37.990
doing was simply error.

00:41:37.990 --> 00:41:39.850
And certainly, he
was likely to believe

00:41:39.850 --> 00:41:41.560
that because of
the power dynamics

00:41:41.560 --> 00:41:43.840
of having the people on
the frontlines of science

00:41:43.840 --> 00:41:46.090
being the most junior
people in the lab,

00:41:46.090 --> 00:41:48.550
combined with all of the
race and gender overtones

00:41:48.550 --> 00:41:50.852
that are very clear
in that video.

00:41:50.852 --> 00:41:52.810
This is something that
I think that we urgently

00:41:52.810 --> 00:41:56.620
need to address because of
the interpretive flexibility

00:41:56.620 --> 00:41:59.290
about the solutions that
people are posing to problems

00:41:59.290 --> 00:42:00.775
of irreproducibility.

00:42:00.775 --> 00:42:03.520
If you remember the chart
of solutions or problems

00:42:03.520 --> 00:42:06.190
that I showed you before,
here's its corresponding chart

00:42:06.190 --> 00:42:09.190
of solutions, again, from
this 2016 survey in Nature

00:42:09.190 --> 00:42:10.505
Publishing Group.

00:42:10.505 --> 00:42:12.880
And you'll see here that, in
fact, teaching and mentoring

00:42:12.880 --> 00:42:14.830
make a prominent appearance--

00:42:14.830 --> 00:42:18.640
better mentoring,
supervision, better teaching,

00:42:18.640 --> 00:42:23.550
more time for mentoring, more
incentives for reproduction--

00:42:23.550 --> 00:42:25.960
or incentives for
better practice, rather.

00:42:25.960 --> 00:42:29.770
So there's a lot of things that
are searching around this area

00:42:29.770 --> 00:42:31.660
to try and deal
with this problem,

00:42:31.660 --> 00:42:33.760
but it matters
crucially whether or not

00:42:33.760 --> 00:42:36.160
we think about the power
dynamics inside of labs

00:42:36.160 --> 00:42:37.480
when addressing them.

00:42:37.480 --> 00:42:40.180
If better mentoring
means finding ways

00:42:40.180 --> 00:42:41.980
to take seriously
information that's

00:42:41.980 --> 00:42:44.890
coming at us from the people
on the frontlines of science,

00:42:44.890 --> 00:42:45.520
then great.

00:42:45.520 --> 00:42:47.650
That's something that
sounds like it will help.

00:42:47.650 --> 00:42:51.190
But if better mentoring
instead means just continuing

00:42:51.190 --> 00:42:53.350
to assume that new
graduate students are

00:42:53.350 --> 00:42:55.480
likely to get it
wrong and we need

00:42:55.480 --> 00:42:59.020
to help them find ways to get
the results that we expect,

00:42:59.020 --> 00:43:02.906
that is not going to help
irreproducibility at all.

00:43:02.906 --> 00:43:04.780
So this is something
that I think we urgently

00:43:04.780 --> 00:43:07.990
need more attention to.

00:43:07.990 --> 00:43:10.780
So to sum it up,
despite the fact that I

00:43:10.780 --> 00:43:14.920
have ended in not a very
hopeful place, I would say,

00:43:14.920 --> 00:43:16.450
I'd like to emphasize
that I think

00:43:16.450 --> 00:43:18.700
that the overall
story that I'm telling

00:43:18.700 --> 00:43:21.980
is one that should
make us feel hopeful.

00:43:21.980 --> 00:43:24.280
We've spent a lot of
time over the years,

00:43:24.280 --> 00:43:27.250
rightly, looking at problems
in clinical research

00:43:27.250 --> 00:43:29.230
within the biomedical community.

00:43:29.230 --> 00:43:32.860
And we can see irreproducibility
in preclinical research

00:43:32.860 --> 00:43:35.770
not as a sudden, emergent
crisis, a thing that

00:43:35.770 --> 00:43:38.800
took us all by surprise and
shows that science is losing

00:43:38.800 --> 00:43:43.210
its truth, but as a continuation
of those reforms, an extension

00:43:43.210 --> 00:43:45.970
of the reforms that have
happened in the clinical trial

00:43:45.970 --> 00:43:48.490
world and continue to
happen and that are now

00:43:48.490 --> 00:43:49.960
playing out in the laboratory.

00:43:49.960 --> 00:43:52.870
We're identifying many
of the same problems.

00:43:52.870 --> 00:43:57.670
But this moment of reform
is undoubtedly trickier

00:43:57.670 --> 00:43:59.170
to deal with.

00:43:59.170 --> 00:44:01.600
For one, it's more
difficult for a community

00:44:01.600 --> 00:44:04.720
to look critically
at its own practices

00:44:04.720 --> 00:44:07.300
than it is to look at
a for-profit industry,

00:44:07.300 --> 00:44:09.250
like the pharmaceutical
industry,

00:44:09.250 --> 00:44:10.930
and point out the problems.

00:44:10.930 --> 00:44:12.620
That requires some
self-reflection,

00:44:12.620 --> 00:44:15.840
which is difficult to do.

00:44:15.840 --> 00:44:17.850
Taking these problems
seriously also require

00:44:17.850 --> 00:44:20.350
talking about the power
differentials within the lab,

00:44:20.350 --> 00:44:22.020
as I have emphasized here.

00:44:22.020 --> 00:44:24.960
And confronting that
requires confronting the idea

00:44:24.960 --> 00:44:27.900
that science is not
separate from society

00:44:27.900 --> 00:44:30.600
with all of its issues
and social biases.

00:44:30.600 --> 00:44:33.630
It reminds us that
science is done by humans

00:44:33.630 --> 00:44:36.600
and that we have to think about
science as an activity embedded

00:44:36.600 --> 00:44:40.390
in society in order to make
progress on these issues.

00:44:40.390 --> 00:44:43.440
And finally, think about how
to talk about scientific data

00:44:43.440 --> 00:44:47.940
in ways that don't rely on the
absolutist notion of truth,

00:44:47.940 --> 00:44:51.150
but instead emphasize
those shades of gray.

00:44:51.150 --> 00:44:52.860
That's something
that feels, again,

00:44:52.860 --> 00:44:55.530
deeply uncomfortable in this
particular historical moment

00:44:55.530 --> 00:44:57.960
that we find ourselves
in, where the idea

00:44:57.960 --> 00:45:02.550
of truth in post-truth politics
seems to be up for grabs.

00:45:02.550 --> 00:45:06.570
So it's not easy, but these are
issues that we can and should

00:45:06.570 --> 00:45:08.730
strive to make progress
on, even if they're not

00:45:08.730 --> 00:45:10.320
immediately fixable.

00:45:10.320 --> 00:45:12.150
And the kind of
research that I do

00:45:12.150 --> 00:45:14.040
is aimed at trying
to tell narratives

00:45:14.040 --> 00:45:17.640
about what's going on that will
help us more directly identify

00:45:17.640 --> 00:45:21.090
the problems so that we can
spend our efforts in the places

00:45:21.090 --> 00:45:22.950
that I think really matter.

00:45:22.950 --> 00:45:24.340
Thank you for your attention.

00:45:24.340 --> 00:45:26.540
I would love to hear your
thoughts on this material.

00:45:26.540 --> 00:45:29.590
[MUSIC PLAYING]

