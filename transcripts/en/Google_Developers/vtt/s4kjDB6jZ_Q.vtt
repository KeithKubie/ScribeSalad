WEBVTT
Kind: captions
Language: en

00:18:45.949 --> 00:18:47.949
Delivery Search-

00:18:50.697 --> 00:18:52.697
Friendly JavaScript -powered by 
Websites 

00:24:13.317 --> 00:24:16.164
       &gt;&gt; Welcome.  Thank you 
for joining.  Our session will 

00:24:16.165 --> 00:24:18.165
begin soon.

00:26:08.154 --> 00:26:10.154
       &gt;&gt; TOM GREENAWAY: Good 
morning, everyone.

00:26:13.443 --> 00:26:14.463
My name it Tom greenway, and I'm
a partner developer advocate 

00:26:14.464 --> 00:26:16.464
from Google 

00:26:17.535 --> 00:26:18.134
Sydney with a focus on 
progressiveibility of web 

00:26:18.135 --> 00:26:20.590
applications.  
       &gt;&gt; JOHN MUELLER: I'm John

00:26:22.835 --> 00:26:25.790
Mueller, an analyst from Zurich 
and Switzerland.  It's great to 

00:26:25.791 --> 00:26:27.831
see so many of you here, even at
this early hour.  

00:26:28.847 --> 00:26:31.527
&gt;&gt; TOM GREENAWAY: Now, as you 
can imagine, John and I have a 

00:26:31.528 --> 00:26:36.225
lot of experience the work web 
developers must do to ensure 

00:26:36.226 --> 00:26:38.257
websites are indexable, which is
another way of saying if a web 

00:26:41.095 --> 00:26:43.145
page can be found and understood
by search engines, but do search

00:26:43.146 --> 00:26:47.453
engines see all web pages 
exactly the same way, as some 

00:26:47.454 --> 00:26:49.499
pages are more complex than 
others?  And what about modern 

00:26:49.500 --> 00:26:52.350
JavaScript powered websites?  
Today we'll be taking a closer 

00:26:52.351 --> 00:26:56.429
look into what it takes for a 
modern JavaScript powered 

00:26:56.430 --> 00:27:00.142
website to be searched by search
scrollers and especially Google 

00:27:00.143 --> 00:27:02.143
Search.

00:27:03.435 --> 00:27:05.464
In this talk, we're announcing a
bunch of new talk, including a 

00:27:05.465 --> 00:27:10.179
new change to Google search 
policy and new approach for 

00:27:10.180 --> 00:27:12.440
rendering HTML to search 
crawlers and even a new Google 

00:27:12.441 --> 00:27:14.441
tool.

00:27:15.526 --> 00:27:16.949
It sounds lining a lot of stuff,
right?  That's because it is.  

00:27:16.950 --> 00:27:19.864
Let's get started.
       Now, a long time ago, 

00:27:19.865 --> 00:27:23.949
before I joined Google, I was 
building eCommerce sites, and I 

00:27:23.950 --> 00:27:26.592
personally felt there was a lot 
of mystery at times behind 

00:27:26.593 --> 00:27:30.678
Google Search, especially on the
topic of indexibility.  I would 

00:27:30.679 --> 00:27:33.178
wonder why do some of my pages 
appear in Google Search and some

00:27:33.179 --> 00:27:35.179
don't and what's the difference 
between them?  

00:27:36.432 --> 00:27:38.887
Will JavaScript be rendered 
correctly, will JavaScript 

00:27:38.888 --> 00:27:43.023
rendered content appear properly
and be indexed, and is lazy 

00:27:43.024 --> 00:27:45.271
loading an image safe to do?  
These are really critical 

00:27:45.272 --> 00:27:49.158
questions, and as developers 
ourselves, we understand the 

00:27:49.159 --> 00:27:53.656
frustration behind this mystery,
so today John and I are going to

00:27:53.657 --> 00:27:55.085
do something we very rarely do 
at Google, we're going to pull 

00:27:55.086 --> 00:27:59.378
back the curtain a little bit 
and reveal some new pieces of 

00:27:59.379 --> 00:28:01.228
information about how Google 
Search sees the web and indexes 

00:28:01.229 --> 00:28:05.504
it, and with this new knowledge 
and a few new tools, you'll have

00:28:05.505 --> 00:28:08.960
concrete steps you can take to 
ensure that JavaScript-powered 

00:28:08.961 --> 00:28:10.961
websites you're 

00:28:12.014 --> 00:28:14.014
building are visible to Google 
Search.

00:28:14.458 --> 00:28:16.492
Now, I want to remind you that 
this talk is about modern 

00:28:17.705 --> 00:28:18.925
JavaScript-powered websites, and
typically these websites will be

00:28:18.926 --> 00:28:21.792
powered by JavaScript framework,
such as 

00:28:25.687 --> 00:28:27.687
Angular, Polimer or react.  Who 
doesn't love a framework that's 

00:28:29.363 --> 00:28:30.997
easy to use and helps you build 
your sites faster and works 

00:28:30.998 --> 00:28:35.506
great for your users?  But it's 
important to recognize that some

00:28:35.507 --> 00:28:37.343
of these frameworks use a 
single-page app configuration 

00:28:37.344 --> 00:28:39.344
model, 

00:28:40.836 --> 00:28:42.856
meaning they use a single HTML 
file that pulls in a bunch of 

00:28:42.857 --> 00:28:45.123
JavaScript, and that can make 
stuff simpler, but if you don't 

00:28:47.369 --> 00:28:48.810
watch out, JavaScript-powered 
websites can be a problem for 

00:28:48.811 --> 00:28:50.811
search engines.

00:28:52.689 --> 00:28:55.943
Let's take a look at what a new 
Angular project looks like.  As 

00:28:55.944 --> 00:28:59.881
you can see the default project 
template is pretty basic.  It 

00:28:59.882 --> 00:29:02.139
shows you how to use Angular to 
render a header, and a few 

00:29:02.140 --> 00:29:04.997
links.  Nice and simple.  How 
could this possibly be a problem

00:29:06.612 --> 00:29:08.612
from an indexibility 
perspective?

00:29:09.692 --> 00:29:12.173
Let's take a peek behind the 
scenes at the HTML.  This is it.

00:29:13.432 --> 00:29:17.322
Take a good look.  When viewed 
in the browser, the default 

00:29:17.323 --> 00:29:18.941
browser context had text, 
imagery, and links, but you 

00:29:18.942 --> 00:29:23.051
wouldn't know this by looking at
this initial HTML that's been 

00:29:23.052 --> 00:29:25.908
delivered from the server.  The 
initial HTML that's been sent 

00:29:25.909 --> 00:29:29.007
down is completely devoid of any
content.  See here in the app 

00:29:29.008 --> 00:29:31.030
root?  That's all there is in 
the body of the 

00:29:34.222 --> 00:29:36.262
page except for some script 
tags, so some search engines 

00:29:36.263 --> 00:29:38.263
might assume that 

00:29:39.328 --> 00:29:42.215
there's actually nothing here to
index.  And to be clear clear, 

00:29:42.216 --> 00:29:46.913
angular isn't the only framework
that serves an empty response on

00:29:46.914 --> 00:29:49.559
its initial service side render.
Others have similar issues by 

00:29:49.560 --> 00:29:53.012
default.  What does this mean 
for the indexibility of our 

00:29:53.013 --> 00:29:55.013
websites from the perspective of
Google Search?  

00:29:56.511 --> 00:29:58.139
Well, to answer that question 
better, we'll take a little step

00:29:58.140 --> 00:30:00.173
back and talk about the web in 
general, why 

00:30:04.056 --> 00:30:07.733
search engines exist, and why 
search crawlers are necessary.  

00:30:07.734 --> 00:30:11.641
Perhaps a good question to start
with is how big is the web?  

00:30:11.642 --> 00:30:14.283
Well, we can tell you that we've
weave actually found over 10 

00:30:14.284 --> 00:30:17.752
trillion -- we've actually found
over 130 trillion documents on 

00:30:17.753 --> 00:30:21.628
the web.  In other words, it's 
really big, and the aim of all 

00:30:21.629 --> 00:30:23.488
search engines, including 
Google, is to provide a list of 

00:30:23.489 --> 00:30:25.489
relevant 

00:30:27.181 --> 00:30:29.181
search results based on a user's
search 

00:30:30.646 --> 00:30:32.906
queryy, and to make that search 
result fast and accurate, we 

00:30:32.907 --> 00:30:37.384
need an index, similar to the 
catalog of a gigantic library, 

00:30:37.385 --> 00:30:39.215
and given the size of the web, 
that's a really complex task.

00:30:39.216 --> 00:30:43.527
       So to build this index, 
to power our search engine, we 

00:30:43.528 --> 00:30:45.783
need another tool, a search 
crawler, and traditionally a 

00:30:47.447 --> 00:30:48.679
search crawler was basically 
just a computer and piece of 

00:30:48.680 --> 00:30:51.948
software that performed two key 
steps.  One, it aims to find a 

00:30:51.949 --> 00:30:53.998
piece of content to be crawled, 
and to do this, 

00:30:57.690 --> 00:31:00.129
the content must be retrievable 
by a URL, and once we have a 

00:31:00.130 --> 00:31:04.224
URL, we search through the HTML 
to index the page and find new 

00:31:04.225 --> 00:31:06.264
links to crawl as well, and 
thus, the cycle repeats.

00:31:08.294 --> 00:31:09.106
So let's look at that first 
step, the crawling, and break it

00:31:09.107 --> 00:31:13.594
down.  Oh, and yes, and as an 
Australian, I thought it was 

00:31:13.595 --> 00:31:16.878
imperative that I include some 
spiders in my talk.  This was 

00:31:16.879 --> 00:31:20.992
the cutest possible one I could 
find.  John, what do you think? 

00:31:20.993 --> 00:31:25.089
IsYou're not convinced?  I have 
a few more in the deck.  Maybe 

00:31:25.090 --> 00:31:27.090
you'll come around.  
       So to ensure crawling is 

00:31:28.367 --> 00:31:30.367
possible, there are key things 
to keep in mind.

00:31:34.099 --> 00:31:35.926
Firstly, we need URLs to be 
reachable, in there shouldn't be

00:31:35.927 --> 00:31:38.167
any issue once the crawler wants
to retrieve the web pages 

00:31:41.454 --> 00:31:43.489
and retrieve things to index 
them.  If there are multiple 

00:31:43.490 --> 00:31:47.783
documents that contain the same 
content, we need a way to 

00:31:47.784 --> 00:31:49.611
identify the original source, or
it could be interpreted as 

00:31:49.612 --> 00:31:51.651
duplicate content.  Finally, we 
want our web pages to have 

00:31:52.878 --> 00:31:55.524
clean, unique URLs.  This was 
pretty straightforward on the 

00:31:57.976 --> 00:32:00.482
web, but the first single page 
apps made things a bit more 

00:32:00.483 --> 00:32:02.522
complicated, so let's go over 
each of these concepts.

00:32:04.182 --> 00:32:06.182
First, for the reachibility of 

00:32:07.682 --> 00:32:09.311
URLs, this is simple a standard 
way to help search engines find 

00:32:09.312 --> 00:32:11.312
content that you're probably 
familiar with.

00:32:13.417 --> 00:32:15.417
You add a plain text file called
robot.

00:32:19.188 --> 00:32:21.188
text which specifies which URLs 
to use and which ones to ignore.

00:32:22.271 --> 00:32:24.739
This can spree vent JavaScript 
being crawled too, which could 

00:32:24.740 --> 00:32:26.808
affect your indexibility.  This 
example gives us a link to a 

00:32:26.809 --> 00:32:31.499
site map.  It helps crawlers by 
providing a recommended set of 

00:32:31.500 --> 00:32:35.241
URLs to crawl initially for a 
site, and to be clear, there's 

00:32:35.242 --> 00:32:36.253
no guarantee these URLs will get
crawled, they're just one of the

00:32:36.254 --> 00:32:38.254
signals 

00:32:40.122 --> 00:32:40.335
that search crawlers will 
consider .

00:32:40.336 --> 00:32:43.588
Okay.  But now let's talk about 
that duplicate content scenario 

00:32:43.589 --> 00:32:47.845
and how search crawlers deal 
with this situation.  Sometimes 

00:32:47.846 --> 00:32:50.113
websites want multiple pages to 
have the same content, right, 

00:32:50.114 --> 00:32:52.114
even if it's a different 
website.

00:32:55.025 --> 00:32:56.646
For example, bloggers will 
publish articles on their 

00:32:56.647 --> 00:32:58.647
website and cross-post 

00:32:59.737 --> 00:33:01.186
to services like media to 
increase the reach of their 

00:33:01.187 --> 00:33:05.145
content, and this is called 
content syndication.  It's 

00:33:05.146 --> 00:33:06.800
important for search crawlers to
understand which URL you prefer 

00:33:06.801 --> 00:33:08.801
to have 

00:33:12.296 --> 00:33:13.928
indexed, so they can order 
metadata search index, and it 

00:33:13.929 --> 00:33:17.662
allows the documents to 
communicate to crawlers where 

00:33:17.663 --> 00:33:19.663
the source for the content 
lives.

00:33:21.318 --> 00:33:23.318
We call that source document the
conocal document.

00:33:25.009 --> 00:33:27.009
And tra deductiblely $GS for the
web started out quite simple.

00:33:29.895 --> 00:33:31.311
A URL was to a server with HTML,
and Ajax came along and changed 

00:33:31.312 --> 00:33:35.387
everything.  Suddenly websites 
could execute JavaScript, which 

00:33:35.388 --> 00:33:39.090
could fetch new content from the
server without reloading the 

00:33:39.091 --> 00:33:42.754
browser page, but developers 
wanted a way to support back and

00:33:42.755 --> 00:33:43.979
forward browser navigation and 
history as well, so a trick was 

00:33:43.980 --> 00:33:48.450
invented which leveraged 
something called the fragment 

00:33:48.451 --> 00:33:50.919
identifier, and its purpose is 
for deep linking into the soft 

00:33:50.920 --> 00:33:52.920
content 

00:33:55.022 --> 00:33:58.077
of a page, like a subsection of 
an encyclopedia article.  

00:33:58.078 --> 00:33:59.721
Because it was supported by 
browsers for history and 

00:33:59.722 --> 00:34:01.577
navigation, this meant 
developers could trick the 

00:34:01.578 --> 00:34:04.043
browser into fetching new 
content dynamically without 

00:34:06.522 --> 00:34:07.754
reloading the browser page and 
yet support the history and 

00:34:07.755 --> 00:34:11.207
navigation we love about the 
web, but we realized using the 

00:34:11.208 --> 00:34:13.456
fragment identifier for two 
purposes, subsections on pages 

00:34:13.457 --> 00:34:17.356
and also deep linking into 
content, it wasn't very elegant,

00:34:17.357 --> 00:34:19.357
so we moved away from that, and 
instead, another approach was 

00:34:20.821 --> 00:34:22.821
proposed, to use the fragment 

00:34:23.939 --> 00:34:26.376
identifier, followed by an 
exclamation mark, which we 

00:34:26.377 --> 00:34:28.491
called the hash bang, and this 
way we could discern the 

00:34:28.492 --> 00:34:30.492
difference 

00:34:31.984 --> 00:34:34.028
between a traditional URL using 
the fragment identifier for the 

00:34:34.029 --> 00:34:36.029
subcontent on a page, vs.

00:34:37.727 --> 00:34:38.758
the fragmenter be used by 
JavaScript to use a deep link 

00:34:38.759 --> 00:34:40.759
into a panel.  This technique 
was recommended for a while.

00:34:44.904 --> 00:34:46.121
However, nowadays there is a 
modern day JavaScript API that 

00:34:46.122 --> 00:34:49.216
makes these old techniques 
unnecessary, and it's called the

00:34:49.217 --> 00:34:54.329
history API.  It's great because
it enables managing the history 

00:34:54.330 --> 00:34:56.330
state of the URL without 

00:34:57.587 --> 00:34:59.587
requiring reload of the browser,
all 

00:35:00.679 --> 00:35:03.962
through JavaScript, so we get 
the best of both worlds.  And I 

00:35:03.963 --> 00:35:06.239
can tell you from dwooling's 
perspective, we no longer index 

00:35:06.240 --> 00:35:09.928
that single hash work-around and
we discourage the use of the 

00:35:09.929 --> 00:35:11.929
hash bank 

00:35:13.352 --> 00:35:15.853
trick as well .
       Okay.  That's crawling 

00:35:15.854 --> 00:35:17.890
out of the way.  Let's move on 
to the indexing step.

00:35:19.934 --> 00:35:21.373
So web crawlers ideally want to 
be able to find all the content 

00:35:21.374 --> 00:35:25.668
on your website.  If the 
crawlers can't see some content,

00:35:25.669 --> 00:35:28.120
how are they going to index it? 
The core content of the page 

00:35:28.121 --> 00:35:31.978
includes all the text, imagery, 
video, and hidden elements, like

00:35:31.979 --> 00:35:34.427
structured metadata.  In other 
words, it's the HTML of the 

00:35:34.428 --> 00:35:37.897
page.  But don't forget about 
that content you dynamically 

00:35:37.898 --> 00:35:41.566
fetch either.  This could be 
worth indexing as well, such as 

00:35:41.567 --> 00:35:43.806
Facebook or discuss comments.  
Crawlers want to see this 

00:35:43.807 --> 00:35:46.462
embedded content too.
       And also this might seem 

00:35:46.463 --> 00:35:48.463
really obvious, but I want to 
emphasize that at 

00:35:51.533 --> 00:35:54.227
Google, we take HTTP codes 
pretty seriously, especially 404

00:35:54.228 --> 00:35:56.228
not found codes.

00:35:58.359 --> 00:36:00.395
If crawlers find a page that has
a 404 status code, they probably

00:36:00.396 --> 00:36:03.044
won't bother indexing it.  The 
lastly, a crawler wants to find 

00:36:04.459 --> 00:36:05.684
all the links on the page 
because these links allow the 

00:36:05.685 --> 00:36:08.533
crawler to crawl further.
       So now let's just talk a 

00:36:08.534 --> 00:36:11.797
bit about those links quickly, 
because they're some of the most

00:36:11.798 --> 00:36:14.455
important parts of the web.  How
do search crawlers like Google 

00:36:14.658 --> 00:36:19.134
find links?  Well, I can't speak
for all search crawlers, but I 

00:36:19.135 --> 00:36:21.768
can say that at Google, we only 
analyze one thing, anchor tags 

00:36:24.455 --> 00:36:27.365
with HREF attributes, and that's
it.  For example, this band here

00:36:27.366 --> 00:36:29.366
that I've just added, it won't 
get crawled because 

00:36:32.689 --> 00:36:34.689
it's not an anchor, and this 
additional 

00:36:36.154 --> 00:36:38.196
span I've added, it doesn't have
an HREF attribute.  But if you 

00:36:38.197 --> 00:36:39.417
are using JavaScript, such as 
with the history API that I 

00:36:39.418 --> 00:36:44.530
mentioned earlier, to navigate 
the page, purely on the client 

00:36:44.531 --> 00:36:46.619
and fetch view contact 
dynamically, you can do that so 

00:36:46.620 --> 00:36:51.365
long as you use the anchor tags 
with HREF attributes like in the

00:36:51.366 --> 00:36:54.872
last example because most search
crawlers, including Google, will

00:36:54.873 --> 00:36:57.345
not simulate navigation of a 
page to find links, only the 

00:36:57.346 --> 00:36:59.346
anchor 

00:37:01.416 --> 00:37:02.466
tags will be followed for 
linking.

00:37:02.467 --> 00:37:04.467
Oh, wait, is that really 
everything?

00:37:07.180 --> 00:37:09.259
In order to have sifted through 
the HTML to index the panel, we 

00:37:09.260 --> 00:37:13.182
needed to have the HTML in the 
first place.  In the early days,

00:37:13.183 --> 00:37:16.853
the server likely gave us all 
the HTML that was necessary, but

00:37:16.854 --> 00:37:18.681
today that's not the case.  
Let's insert a step between 

00:37:18.682 --> 00:37:21.957
crawling and indexing because we
need to recognize the search 

00:37:21.958 --> 00:37:26.250
crawlers themselves might need 
to take on this rendering task 

00:37:26.251 --> 00:37:27.910
as well, otherwise how will the 
search crawler understand the 

00:37:27.911 --> 00:37:32.181
modern JavaScript-powered 
websites we're building?  

00:37:32.182 --> 00:37:34.418
Because these sites are 
rendering their HTML in the 

00:37:34.419 --> 00:37:36.887
browser themselves using 
JavaScript and template 

00:37:38.762 --> 00:37:39.565
frameworks, just like the 
example I showed you earlier.

00:37:39.566 --> 00:37:43.040
       When I say rendering, I 
don't mean drawing pixels to the

00:37:43.041 --> 00:37:46.574
screen, I'm talking about the 
actual construction of the HTML 

00:37:46.575 --> 00:37:48.015
itself, and ultimately this is 
only can ever happen on either 

00:37:48.016 --> 00:37:52.077
the server or the client or a 
combination of the two could be 

00:37:52.078 --> 00:37:54.078
used, and we call that hybrid 
rendering.

00:37:55.541 --> 00:37:57.541
Now, if it's all prerendered on 

00:37:59.624 --> 00:38:01.624
the server, then a search engine
could 

00:38:02.669 --> 00:38:04.093
have that immediately, but if 
it's rerpdered on the client, 

00:38:04.094 --> 00:38:05.719
that's going to be trickier.  
That will be the challenge we'll

00:38:05.720 --> 00:38:08.808
be discussing today.
       One last term, you might 

00:38:08.809 --> 00:38:10.809
be 

00:38:12.086 --> 00:38:14.745
wondering what is Google's 
searcher called?  We call it 

00:38:14.746 --> 00:38:16.180
Googlebot, and we'll be 
referring to it a lot during 

00:38:16.181 --> 00:38:19.025
this talk.  I said that a search
crawler is basically a computer 

00:38:19.026 --> 00:38:21.905
with software running on it.  
Well, obviously, maybe in the 

00:38:21.906 --> 00:38:23.906
'90s 

00:38:25.008 --> 00:38:27.451
that was the case, but today due
to just the sheer size of the 

00:38:27.452 --> 00:38:30.939
web, Googlebot is comprised of 
thousands of machines running, 

00:38:30.940 --> 00:38:32.367
you know, all this distributed 
software that's constantly 

00:38:32.368 --> 00:38:35.653
crunching data to understand all
of this continuously expanding 

00:38:35.654 --> 00:38:37.888
information on the web.
       And to be honest, I think

00:38:37.889 --> 00:38:42.000
we sometimes take for granted 
just how incredible going Search

00:38:42.001 --> 00:38:46.096
really is.  For example, I 
recently learned with the 

00:38:46.097 --> 00:38:47.966
knowledge graph, which is a DB 
of all the information we have 

00:38:47.967 --> 00:38:50.803
on the web, it actually maps out
how more than one billion things

00:38:50.804 --> 00:38:52.804
in the real world are connected 
and over 70 billion facts 

00:38:53.047 --> 00:38:55.698
between them.  It's kind of 
amazing.

00:38:56.107 --> 00:39:00.192
Okay.  Well, now that we know 
the principles of a search 

00:39:00.193 --> 00:39:01.837
crawler, let's see how these 
three different key steps, 

00:39:01.838 --> 00:39:05.955
crawling, rendering, and 
indexing all connect, because 

00:39:05.956 --> 00:39:08.182
one crucial thing to understand 
is the cycle of how Googlebot 

00:39:08.183 --> 00:39:12.286
works or how it should ideally 
work.  As you can see, we want 

00:39:12.287 --> 00:39:16.762
these three steps to hand over 
to one another instantly, and as

00:39:16.763 --> 00:39:19.412
soon as the content is fully 
rendered, we want to index it to

00:39:21.482 --> 00:39:24.593
keep the Google Search index as 
fresh as possible.  This sounds 

00:39:24.594 --> 00:39:28.662
simple; right?  Well, it would 
be if all the content was 

00:39:28.663 --> 00:39:30.663
rendered on the server and 
complete 

00:39:32.350 --> 00:39:34.991
when we crawl it, but as you 
knowsh if a site uses 

00:39:34.992 --> 00:39:36.420
client-side rendering, that's 
not going to be the case, just 

00:39:36.421 --> 00:39:40.301
like the Angular sample I showed
you earlier.  What does 

00:39:40.302 --> 00:39:42.302
Googlebot do in this situation?

00:39:44.411 --> 00:39:47.090
Well, it includes its own 
renderer when it enables to run 

00:39:47.091 --> 00:39:50.553
to have pages with JavaScript, 
but rendering pages at the scale

00:39:50.554 --> 00:39:51.568
of the web, requires a lot of 
time and computational 

00:39:51.569 --> 00:39:53.569
resources.

00:39:55.029 --> 00:39:56.857
Make no mistake, this is a 
serious challenge for search 

00:39:56.858 --> 00:39:58.858
crawlers, Googlebot 

00:39:59.959 --> 00:40:02.044
included, so we come to the 
important truth about Google 

00:40:02.045 --> 00:40:05.298
Search we'd like to share today.
Currently the rendering of 

00:40:05.299 --> 00:40:09.377
JavaScript websites in Google 
Search is deferred until 

00:40:09.378 --> 00:40:10.403
Googlebot has the resources 
available to process that 

00:40:10.404 --> 00:40:12.865
content.
       Now, you might be 

00:40:12.866 --> 00:40:16.543
thinking, okay, well, what does 
that really mean?  Well, I'll 

00:40:16.544 --> 00:40:19.637
show you.  In reality, 
Googlebot's process looks a bit 

00:40:19.638 --> 00:40:21.638
different.

00:40:22.938 --> 00:40:25.199
We crawl a page, we fetch the 
server side rendered content and

00:40:25.200 --> 00:40:29.088
run some initial indexing on 
that document.  But rendering 

00:40:29.089 --> 00:40:31.089
the JavaScript-powered web pages
takes processing power and 

00:40:32.957 --> 00:40:34.582
memory, and while Googlebot is 
very powerful, it doesn't have 

00:40:34.583 --> 00:40:37.673
infinite resources.  So if the 
page has JavaScript in it, the 

00:40:37.674 --> 00:40:40.552
rendering is actually deferred 
until we have the resources 

00:40:40.553 --> 00:40:43.609
ready to render the client-side 
content and then we index the 

00:40:43.610 --> 00:40:46.461
content further.  So Googlebot 
might index a page before 

00:40:48.341 --> 00:40:50.772
rendering is complete rct and 
the final render can actually 

00:40:50.773 --> 00:40:53.028
arrive several days later.  And 
when that final render does 

00:40:55.668 --> 00:40:57.668
arrive, then we perform another 
wave of 

00:40:58.928 --> 00:41:01.406
offing on that client-side 
rendered content.  This means if

00:41:01.407 --> 00:41:04.302
your site is using a heavy 
amount of client-side JavaScript

00:41:05.759 --> 00:41:07.804
for rendering, you can be 
tripped up when your content is 

00:41:07.805 --> 00:41:09.632
being indexed due to the nature 
of this two-phase indexing 

00:41:09.633 --> 00:41:11.663
process.
       And so ultimately, what 

00:41:11.664 --> 00:41:16.786
I'm really trying to say is 
because Googlebot actually runs 

00:41:16.787 --> 00:41:19.415
two ways of indexing across 
content, it's possible some 

00:41:19.416 --> 00:41:21.416
details might be missed.

00:41:22.672 --> 00:41:24.108
For example, if your site is a 
progressive web application and 

00:41:24.109 --> 00:41:26.109
you've built it around the 
single-page app 

00:41:29.215 --> 00:41:31.215
model, it's likely all your 
unique URLs 

00:41:32.275 --> 00:41:34.127
share a base of template 
resources which are filled in 

00:41:34.128 --> 00:41:37.623
with contents, and if that's the
case, consider this.  Did the 

00:41:37.624 --> 00:41:39.624
initially service side 

00:41:43.401 --> 00:41:45.864
rendered of the page have the 
correct canonical tag rendered 

00:41:45.865 --> 00:41:47.865
in it, because our second wave 
of indexing doesn't 

00:41:51.560 --> 00:41:54.197
check for the Canon ishingts cal
tag at all.  If a user requested

00:41:54.198 --> 00:41:58.475
a URL that doesn't exist and you
attempt to use JavaScript to 

00:41:58.476 --> 00:41:59.308
send the user a 404 page, then 
we're actually going to miss 

00:41:59.309 --> 00:42:01.957
that too.
       Now, John and I -- John 

00:42:01.958 --> 00:42:05.231
will talk more about these 
issues later in the talk, but 

00:42:05.232 --> 00:42:07.232
the important thing to take away
right now is that these really 

00:42:10.470 --> 00:42:12.590
aren't minor issues , these are 
all issues that can affect 

00:42:16.059 --> 00:42:18.734
your ability, metadata, cal, 
HTTP codes.  As I mentioned, at 

00:42:18.735 --> 00:42:22.188
the beginning of the talk, these
are key to understand the 

00:42:22.189 --> 00:42:25.257
content on your web pages.
       However, just to be 

00:42:25.258 --> 00:42:27.754
clear, not all web pages on a 
website necessarily need to be 

00:42:27.755 --> 00:42:29.755
indexed.

00:42:32.836 --> 00:42:33.648
For example, actually on the 
Google I/O schedule website 

00:42:33.649 --> 00:42:35.898
there is a filtering interface 
for the sessions, 

00:42:39.151 --> 00:42:40.781
and we want search crawlers to 
find the individual session 

00:42:40.782 --> 00:42:42.814
pages, but we discovered the 
deep links weren't being 

00:42:47.499 --> 00:42:49.499
indexed because the cononical 
were rendered in the file.

00:42:53.601 --> 00:42:55.426
So we implemented a new template
and search side rendered 

00:42:55.427 --> 00:42:57.661
cononical tags to make sure 
they're properly indexed because

00:42:57.662 --> 00:43:00.365
we care about that context.  To 
ensure these documents were 

00:43:02.422 --> 00:43:04.422
crawlable, we added them to the 
site map as well.

00:43:05.291 --> 00:43:06.130
What about the single page app 
which allows for filtering 

00:43:06.131 --> 00:43:10.563
sessions?  That's more of a tool
than a piece of content, right, 

00:43:10.564 --> 00:43:13.635
therefore, it's not as important
to index the HTML on that page, 

00:43:13.636 --> 00:43:16.084
so ask yourself this.  Do the 
pages I care about from the 

00:43:18.337 --> 00:43:20.337
perspective of content and 
indexing use 

00:43:21.811 --> 00:43:23.477
client-side rind erring anyway ?
-- rendering anyway?  

00:43:23.478 --> 00:43:25.507
Okay.  So now you know, when 
building a 

00:43:28.812 --> 00:43:30.855
client-side rendered website you
must tread carefully.  As the 

00:43:30.856 --> 00:43:32.498
web and industry have gone 
bigger, so too have the teams 

00:43:32.499 --> 00:43:35.373
and companies become more 
complex.  We now work in a world

00:43:35.374 --> 00:43:38.422
where the people building 
websites aren't necessarily the 

00:43:38.423 --> 00:43:40.046
same people promoting or 
marketing those websites, and so

00:43:40.047 --> 00:43:44.350
this challenge is one that we're
all facing together as an 

00:43:44.351 --> 00:43:46.433
industry, both from Google's 
perspective and yours as 

00:43:48.278 --> 00:43:50.278
developers because after all, 
you want 

00:43:51.747 --> 00:43:53.747
your content index by search 
engines and so do we.

00:43:54.584 --> 00:43:56.832
Well, this seems like a good 
opportunity to change tracks, 

00:43:56.833 --> 00:43:59.924
so, John, do you want to take 
over and tell everyone about the

00:43:59.925 --> 00:44:03.633
Google Search policy changes and
some of the best practices they 

00:44:03.634 --> 00:44:05.634
can apply so we can meet this 
challenge together?  

00:44:05.867 --> 00:44:09.769
&gt;&gt; JOHN MUELLER: Sure.  Thanks, 
Tom.  That was a great summary 

00:44:09.770 --> 00:44:12.815
of how Search works.  So I still
don't know about those pictures 

00:44:12.816 --> 00:44:15.115
of spiders.  
       (Laughter) 

00:44:17.364 --> 00:44:18.589
Kind of scary, but Googlebot, in
reality, is actually quite 

00:44:18.590 --> 00:44:20.590
friendly.

00:44:22.716 --> 00:44:24.341
Anyway, as Tom mentioned, 
indexing of modern 

00:44:24.342 --> 00:44:27.184
JavaScript-powered websites is a
challenge.  It's a challenge 

00:44:27.185 --> 00:44:29.224
both for Google as a search 
engine and for you all as 

00:44:32.108 --> 00:44:34.773
developers of the modern way, 
and while development on our 

00:44:34.774 --> 00:44:38.041
side are still ongoing, we'd 
like to help you to tackle this 

00:44:38.042 --> 00:44:39.871
challenge in a more systematic 
way, so for that we'll look at 

00:44:39.872 --> 00:44:44.347
three things here, the policy 
change that we mentioned briefly

00:44:44.348 --> 00:44:46.796
before, some new tools that are 
available to help you diagnose 

00:44:48.654 --> 00:44:50.654
these issues a little bit 
better, and 

00:44:51.910 --> 00:44:54.358
lastly, a bunch of best 
practices to help you to make 

00:44:54.359 --> 00:44:56.822
better JavaScript-powered 
websites that also work well in 

00:44:56.823 --> 00:45:00.101
Search.
       So we've talked about 

00:45:00.102 --> 00:45:03.795
client-side rendering briefly 
and server-side rendering 

00:45:03.796 --> 00:45:07.862
already.  Client-side rendering 
is the traditional state where 

00:45:07.863 --> 00:45:11.324
JavaScript is processed on the 
client.  That would be the 

00:45:11.325 --> 00:45:13.325
user's browser, or on a search 
engine.

00:45:15.388 --> 00:45:17.014
For server-side rendering, the 
server, so your server, will 

00:45:17.015 --> 00:45:19.015
process the 

00:45:21.352 --> 00:45:23.352
JavaScript and serve mostly 
static HTML two-search engines.

00:45:24.813 --> 00:45:27.248
Also this also has speed 
advantages, so especially on 

00:45:27.249 --> 00:45:29.249
lower-end devices, on mobile 
devices, JavaScript can take a 

00:45:31.516 --> 00:45:33.516
bit of time to run, so this is a
good practice.

00:45:34.775 --> 00:45:36.775
For both of these, we index the 
state 

00:45:38.325 --> 00:45:40.150
as ultimately seen in the 
browser, so that's what we pick 

00:45:40.151 --> 00:45:42.595
up, and we try to render pages 
when we need to do that.

00:45:43.826 --> 00:45:45.644
There's a third type of 
rendering that we've talked 

00:45:45.645 --> 00:45:47.645
about in the past.

00:45:49.382 --> 00:45:51.466
It starts in the same way in 
that prerendered HTML is sent to

00:45:51.467 --> 00:45:56.139
the client, so you have the same
speed advantages there; however,

00:45:56.140 --> 00:45:58.814
on interaction or after the 
initial page load, the server 

00:45:58.815 --> 00:46:03.962
adds JavaScript on top of that, 
and as with server-side 

00:46:03.963 --> 00:46:05.963
rendering, our job as a search 
engine is pretty easy here.

00:46:09.555 --> 00:46:10.783
We just pick up the prerendered 
HTML content.  We call this 

00:46:10.784 --> 00:46:12.784
hybrid rendering.

00:46:14.116 --> 00:46:16.555
This is actually our long-term 
recommendation.  We think this 

00:46:16.556 --> 00:46:18.996
is probably where things will 
end up in the long run; however,

00:46:18.997 --> 00:46:24.088
in practice, implementing this 
can still be a bit tricky, and 

00:46:24.089 --> 00:46:26.089
most frameworks don't make this 
easy.

00:46:28.203 --> 00:46:29.651
A quick call out to Angular, 
since we featured them in the 

00:46:29.652 --> 00:46:35.550
beginning as an example of a 
page that was hard to pick up.  

00:46:35.551 --> 00:46:38.199
They have built a hybrid 
rendering mode with Angular 

00:46:38.200 --> 00:46:42.279
Universal that helps you to do 
this a little bit easier.  Over 

00:46:42.280 --> 00:46:43.697
time, I imagine more frameworks 
will have something similar to 

00:46:43.698 --> 00:46:47.781
make it easier for you to do 
this in practice; however, at 

00:46:47.782 --> 00:46:50.072
least at the moment, if your 
server isn't writ number 

00:46:50.073 --> 00:46:54.187
JavaScript, you're going to be 
dealing with kind of double 

00:46:54.188 --> 00:46:56.188
maintenance of controlling and 

00:46:57.673 --> 00:47:00.325
templating logic as well, so 
what's another option?  What's 

00:47:00.326 --> 00:47:02.167
another way that JavaScript 
sites could work well with 

00:47:02.168 --> 00:47:04.676
Search?  
       We have another option 

00:47:04.677 --> 00:47:07.114
that we'd like to introduce.  We
call it Dynamic Rendering.

00:47:12.020 --> 00:47:14.260
In a nutshell, dynamic rendering
is the principle of sending 

00:47:14.261 --> 00:47:16.312
normal client-side rendered 
content to users 

00:47:19.570 --> 00:47:21.631
and sending fully server-side 
rendered content to search 

00:47:21.632 --> 00:47:23.453
engines and to other crawlers 
that need it.  This is the 

00:47:23.454 --> 00:47:25.454
policy change that we 

00:47:28.408 --> 00:47:30.849
talked about before, so we call 
it dynamic because your site 

00:47:30.850 --> 00:47:32.889
dynamically detects whether or 
not the requester is 

00:47:36.346 --> 00:47:38.171
a search engine crawler, like 
Googlebot, and only then sends a

00:47:38.172 --> 00:47:41.928
server-side rendered content 
directly to the client.  You can

00:47:41.929 --> 00:47:43.588
include other web services here 
as well that can't deal with 

00:47:43.589 --> 00:47:45.589
rendering.  For example, maybe 
social media 

00:47:48.230 --> 00:47:51.984
services or chat services, 
anything that tries to extract 

00:47:51.985 --> 00:47:54.824
structured information to your 
pages, and for all other 

00:47:54.825 --> 00:47:57.270
requesters, so your normal 
users, you would serve your 

00:47:59.171 --> 00:48:01.409
normal hybrid or client-side 
rendered code.  This also gives 

00:48:01.410 --> 00:48:03.410
you the best of both 

00:48:05.887 --> 00:48:08.739
worlds and makes it easy for to 
you migrate to hybrid rendering 

00:48:08.740 --> 00:48:10.740
for your users over time as 
well.

00:48:12.600 --> 00:48:14.446
One thing to note, this is not a
requirement for JavaScript sites

00:48:14.447 --> 00:48:16.447
to be indexed.

00:48:17.493 --> 00:48:20.142
As you'll see later, Googlebot 
can render most pages already.  

00:48:20.143 --> 00:48:21.763
For dynamic rendering, our 
recommendation is to add a new 

00:48:21.764 --> 00:48:23.764
tool or 

00:48:25.235 --> 00:48:27.078
step in your server 
infrastructure to act as a 

00:48:27.079 --> 00:48:29.079
dynamic renderer.

00:48:30.331 --> 00:48:33.181
This reads your normal 
client-side content and sends a 

00:48:33.182 --> 00:48:35.182
prerendered version 

00:48:37.471 --> 00:48:39.307
to crawlers, so how might you 
implement that.  We have two 

00:48:39.308 --> 00:48:41.308
options here that help you to 
kind of get started.

00:48:45.840 --> 00:48:47.840
The first is Puppeteer, which is
a no 

00:48:49.125 --> 00:48:51.363
JavaScript library, which wraps 
Google Chrome underneath.  This 

00:48:51.364 --> 00:48:53.364
allows you to render pages on 

00:48:54.369 --> 00:48:56.450
your own.

00:48:59.724 --> 00:49:00.943
Another option is Rendertron, 
which renders on your side as 

00:49:00.944 --> 00:49:04.391
well.  Both are Open Source, so 
you could make your own version 

00:49:04.392 --> 00:49:06.434
or use something from a third 
party that does something 

00:49:06.842 --> 00:49:09.311
similar as well.  For more 
information on these, I'd 

00:49:12.419 --> 00:49:14.461
recommend checking the I/O 
session on Headless Chrome.  I 

00:49:14.462 --> 00:49:17.508
believe there's a recording 
about that already.

00:49:18.541 --> 00:49:20.797
Either way, keep in mind 
rendering can be pretty resource

00:49:22.250 --> 00:49:24.091
intensive, so we recommend doing
this out of band from your 

00:49:24.092 --> 00:49:26.124
normal web server and 
implementing caching as you need

00:49:26.125 --> 00:49:29.374
it.  
       So let's take a quick 

00:49:29.375 --> 00:49:31.375
look at what your server 
infrastructure might 

00:49:34.881 --> 00:49:36.902
look like with a dynamic 
renderer integrated.  Requests 

00:49:36.903 --> 00:49:40.161
from Googlebot come in on the 
side here.  They're sent to your

00:49:40.162 --> 00:49:42.162
normal server, and then, perhaps
through a reverse 

00:49:45.084 --> 00:49:47.925
proxy, they're sent to the 
dynamic renderer.  There it 

00:49:47.926 --> 00:49:49.959
requests and renders a complete 
final page and sends that back 

00:49:52.400 --> 00:49:54.445
to the search engines, so 
without needing to implement -- 

00:49:54.446 --> 00:49:57.323
maintain any new code, this 
setup could enable a website 

00:49:59.155 --> 00:50:01.823
that's designed only for 
client-side rendering to perform

00:50:01.824 --> 00:50:03.824
dynamic rendering 

00:50:04.903 --> 00:50:05.510
of the content to Googlebot and 
to other appropriate clients.

00:50:05.511 --> 00:50:08.626
       If you think about it, 
this kind of solves the problems

00:50:08.627 --> 00:50:12.907
that Tom mentioned before, and 
now we can be kind of confident 

00:50:12.908 --> 00:50:15.773
that the important content of 
our web pages is available to 

00:50:18.026 --> 00:50:20.890
Googlebot when it performs its 
initial wave of indexing.  So 

00:50:20.891 --> 00:50:22.891
how might you recognize 
Googlebot requests?  

00:50:23.590 --> 00:50:26.249
This is actually pretty easy.  
So the easiest way to do that is

00:50:26.250 --> 00:50:30.109
to find Googlebot in the user 
agent stream.  You can do 

00:50:30.110 --> 00:50:32.769
something similar for other 
services that you want to serve 

00:50:34.833 --> 00:50:36.048
prerendered content to, and for 
Googlebot as well as some 

00:50:36.049 --> 00:50:38.894
others, you can also do a 
reverse DNS lookup if you 

00:50:42.759 --> 00:50:43.977
want to be sure that you're 
serving it just to legitimate 

00:50:43.978 --> 00:50:46.017
clients.
       One thing to kind of 

00:50:46.018 --> 00:50:48.018
watch out 

00:50:49.532 --> 00:50:50.551
for here is that if you serve 
adapted content to smartphone 

00:50:50.552 --> 00:50:52.552
users vs.

00:50:53.830 --> 00:50:56.570
desktop users or you you 
redirect users to different URLs

00:50:56.571 --> 00:50:58.571
depending on the device that 
they use, you must make sure 

00:51:02.104 --> 00:51:04.104
that dynamic rendering returns 
device 

00:51:05.791 --> 00:51:08.025
rendered content; in other words
, mobile users when they go to 

00:51:08.026 --> 00:51:11.078
your page should see the mobile 
version, and the others should 

00:51:11.079 --> 00:51:13.729
see the desktop version.  If 
you're using responsive design, 

00:51:13.730 --> 00:51:17.814
if you're using the same HTML 
and using CSS to conditionally 

00:51:17.815 --> 00:51:20.290
change the way the content is 
shown to users,  this is one 

00:51:22.110 --> 00:51:23.787
thing you don't need to watch 
out for because the HTML is 

00:51:23.788 --> 00:51:27.683
exactly the same.
       What's not immediately 

00:51:27.684 --> 00:51:30.521
clear from the user agents is 
that Googlebot is 

00:51:33.606 --> 00:51:35.606
currently using a somewhat older
browser to render pages.

00:51:37.893 --> 00:51:40.151
It uses Chrome 41, which was 
released in 2015.  The most 

00:51:40.152 --> 00:51:42.189
visible implication for 
developers is that newer 

00:51:42.190 --> 00:51:47.081
JavaScript versions or coding 
conventions like arrow functions

00:51:47.082 --> 00:51:52.037
aren't supported by Googlebot, 
and with that, also any API that

00:51:52.038 --> 00:51:54.038
was added after Chrome 41 
currently isn't supported.

00:51:56.513 --> 00:51:58.541
You can check these on a site 
like Can I Use, and while you 

00:51:58.542 --> 00:52:01.436
could theoretically install an 
older version of Chrome, we 

00:52:02.865 --> 00:52:04.865
don't recommend doing that for 
obvious security reasons.

00:52:05.930 --> 00:52:07.962
Additionally, there's some APIs 
that Googlebot doesn't support 

00:52:07.963 --> 00:52:11.037
because they don't provide 
additional value for Search.  

00:52:11.038 --> 00:52:16.359
We'll check these out too.  Much
       All right.  So you might 

00:52:16.360 --> 00:52:18.594
be thinking this sounds like a 
lot of work, John.  I don't 

00:52:18.595 --> 00:52:20.595
know.  Do I really need to do 
this?

00:52:23.506 --> 00:52:26.346
So a lot of times Googlebot can 
render pages properly.  Why do I

00:52:26.347 --> 00:52:28.793
really have to watch out for 
this?  Well, there are a few 

00:52:28.794 --> 00:52:32.873
reasons to watch out for this.  
First is if your site is large 

00:52:32.874 --> 00:52:35.115
and rapidly changing.  For 
example, if you have a news 

00:52:37.348 --> 00:52:39.202
website that has a lot of new 
content that keeps coming out 

00:52:39.203 --> 00:52:41.203
regularly and 

00:52:42.884 --> 00:52:44.884
requires quick indexing, as Tom 
showed, 

00:52:46.325 --> 00:52:48.980
rendering is deferred from 
indexing, so if you have a large

00:52:48.981 --> 00:52:52.464
dynamic website, then kind of 
the new content might take a 

00:52:52.465 --> 00:52:55.525
while to be indexed otherwise.
       Secondly, if you rely on 

00:52:55.526 --> 00:52:57.526
modern JavaScript functionality,
for example, 

00:53:00.594 --> 00:53:02.594
if you have any libraries that 
can't be 

00:53:03.677 --> 00:53:05.341
transspiled back to ES5, then 
dynamic rendering can help you 

00:53:05.342 --> 00:53:07.987
there, and that said, we 
continue to recommend using 

00:53:10.432 --> 00:53:12.074
proper graceful degradation 
techniques so that even older 

00:53:12.075 --> 00:53:14.075
clients have access to your 
content.

00:53:16.153 --> 00:53:18.591
And finally, there's a third 
reason to also look into this, 

00:53:18.592 --> 00:53:20.592
in particular, if you're using 
social media 

00:53:23.115 --> 00:53:24.331
sites, if your site relies on 
sharing through social media or 

00:53:24.332 --> 00:53:26.332
through chat applications.

00:53:28.799 --> 00:53:30.644
If these services require access
to your page's content, then 

00:53:30.645 --> 00:53:32.645
dynamic 

00:53:33.689 --> 00:53:35.689
rendering can help you there too
.

00:53:36.123 --> 00:53:39.372
So when might you not use 
dynamic rendering?  I think the 

00:53:39.373 --> 00:53:41.373
main aspect here is balancing 
the time and effort needed to 

00:53:43.487 --> 00:53:45.711
implement and to run this with 
the games that are received, so 

00:53:45.712 --> 00:53:49.590
remember, implementation and 
maintenance of dynamic rendering

00:53:49.591 --> 00:53:53.853
can use a significant amount of 
server resources, and if you see

00:53:53.854 --> 00:53:56.494
Googlebot is able to index your 
pages properly, then if you're 

00:53:56.495 --> 00:53:58.495
not 

00:54:00.001 --> 00:54:01.419
making critical, high-frequency 
changes to your site, maybe you 

00:54:01.420 --> 00:54:03.420
don't actually need to implement
anything special.

00:54:06.115 --> 00:54:08.115
Most sites smud be able to let 

00:54:09.389 --> 00:54:11.858
Googlebot render their -- should
be able to let Googlebot render 

00:54:11.859 --> 00:54:14.302
your pages just fine.
       Like I mentioned, if 

00:54:14.303 --> 00:54:17.989
Googlebot can render your pages,
you probably don't need dynamic 

00:54:17.990 --> 00:54:20.059
rendering for your site.  Let's 
look at a few tools to help you 

00:54:21.089 --> 00:54:23.089
figure out what the situation 
is.

00:54:24.136 --> 00:54:26.781
When diagnosing rendering, we 
recommend doing so 

00:54:26.782 --> 00:54:29.634
incrementally, first checking 
the HTTP raw response and 

00:54:32.476 --> 00:54:34.362
checking the rendered version, 
either on mobile or mobile and 

00:54:34.363 --> 00:54:37.031
desktop, if you serve different 
content, for example.  Let's 

00:54:37.032 --> 00:54:39.060
take a quick look at these.

00:54:44.948 --> 00:54:46.948
So looking at the raw cononical 

00:54:50.309 --> 00:54:52.359
raw HTTP response, one is to 
gain access to Google Search 

00:54:52.360 --> 00:54:54.360
ConSol.

00:54:55.412 --> 00:54:56.049
To look at the features, you 
need to verify ownership of your

00:54:56.050 --> 00:55:02.179
website.  This is easy to do.  
There are a ways to do that.  I 

00:55:02.180 --> 00:55:04.180
would recommend you do that 
regardless of what you work on.

00:55:07.253 --> 00:55:10.121
Once you have it verified, you 
can use a tool called Fetch as 

00:55:10.122 --> 00:55:12.122
Google, and it 

00:55:13.166 --> 00:55:14.592
will show the HTTP response 
rendered by Googlebot, including

00:55:14.593 --> 00:55:17.430
the response code on top and the
HTML that was provided before 

00:55:17.431 --> 00:55:20.495
any rendering was done.  This is
a great way to double-check what

00:55:20.496 --> 00:55:21.923
is happening on your server, 
especially if you're using 

00:55:21.924 --> 00:55:24.772
dynamic rendering to serve 
different content to Googlebot.

00:55:26.441 --> 00:55:28.926
       Once you've checked the 
raw 

00:55:32.195 --> 00:55:34.234
response, I recommend checking 
how the pages actually render, 

00:55:34.235 --> 00:55:39.144
so the tool I use for this is 
the mobile-friendly test.  It's 

00:55:39.145 --> 00:55:41.145
a really fast way of checking 
Google's rendering of a page.

00:55:43.418 --> 00:55:45.464
As I mentioned, the name 
suggests that it's made for 

00:55:45.465 --> 00:55:48.130
mobile devices, so as you might 
know, over time our indexing 

00:55:48.131 --> 00:55:50.371
will be primarily focused on the
mobile version of a page.

00:55:53.864 --> 00:55:56.321
We call this mobile first 
indexing, so it's good to 

00:55:56.322 --> 00:55:58.192
already start focusing on the 
mobile version when you're 

00:55:58.193 --> 00:56:02.256
testing rendering.
       We recommend testing a 

00:56:02.257 --> 00:56:06.577
few pages of each kind of page 
within your website, so, for 

00:56:06.578 --> 00:56:08.578
example, if you have an 

00:56:10.054 --> 00:56:12.306
eCommerce site, check the Home 
Panel, some of the category 

00:56:12.307 --> 00:56:14.743
pages, and some -- Page, some of
the category pages, and some of 

00:56:14.744 --> 00:56:17.438
the details pages.  You don't 
have to check all the pages, 

00:56:19.508 --> 00:56:22.353
because a lot of times the 
template will be similar.  If 

00:56:22.354 --> 00:56:24.392
your pages render here, chances 
are high that Googlebot can 

00:56:24.393 --> 00:56:26.393
render your pages for Search as 
well.

00:56:27.855 --> 00:56:29.687
One thing that's kind of a down 
side here is you just see the 

00:56:29.688 --> 00:56:33.782
screenshot.  You don't see the 
rendered HTML here.  What's one 

00:56:33.783 --> 00:56:35.783
way to check the HTML?

00:56:37.243 --> 00:56:39.243
Well, new for I/O, I think we 
launched 

00:56:40.922 --> 00:56:42.148
this yesterday, we've added a 
way to review the HTML after 

00:56:42.149 --> 00:56:44.149
rendering.

00:56:45.433 --> 00:56:47.903
This is also in the 
mobile-friendly test.  It shows 

00:56:47.904 --> 00:56:50.151
you what was created after 
rendering with the mobile 

00:56:50.152 --> 00:56:54.676
Googlebot, includes all of the 
mark-up for links, for images, 

00:56:54.677 --> 00:56:56.510
for structure data, any 
invisible elements that might be

00:56:56.511 --> 00:57:00.200
on the page after rendering.
       So what do you do if the 

00:57:00.201 --> 00:57:03.031
page just doesn't render 
properly at all?

00:57:07.969 --> 00:57:08.976
We also just launched a way to 
get full information about 

00:57:08.977 --> 00:57:13.680
loading issues from a page as 
well.  On this part within the 

00:57:14.691 --> 00:57:16.939
mobile-friendly test, you can 
see all of the resources that 

00:57:16.940 --> 00:57:19.181
were blocked by Googlebot, so 
this could be JavaScript files 

00:57:19.182 --> 00:57:21.182
or API responses.

00:57:23.294 --> 00:57:24.722
A lot of times not everything 
needs to be crawled, kind of 

00:57:24.723 --> 00:57:26.723
like Tom mentioned.

00:57:27.794 --> 00:57:30.433
For example, also, if you have 
tracking pixels on a page, 

00:57:30.434 --> 00:57:34.704
Googlebot doesn't really need to
render those tracking pixels, 

00:57:34.705 --> 00:57:36.705
but if you use an API to pull in
content from somewhere else 

00:57:39.816 --> 00:57:41.648
and that API endpoint is blocked
by robot text, then obviously we

00:57:41.649 --> 00:57:45.307
can't pull in that content at 
all.  An aggregate list of all 

00:57:45.308 --> 00:57:47.308
of these 

00:57:49.013 --> 00:57:51.013
issues is also available in 
Search console.

00:57:52.311 --> 00:57:54.734
So when they fail in a browser, 
I check the developer console 

00:57:54.735 --> 00:57:56.735
for more information to see more
details on 

00:58:00.032 --> 00:58:02.486
exceptions, and new for I/O, one
of the most requested features 

00:58:02.487 --> 00:58:04.736
from people who make 
JavaScript-powered sites for 

00:58:04.737 --> 00:58:06.737
Search 

00:58:08.031 --> 00:58:08.435
is also showing the console rr 
log when Google tries to render 

00:58:08.436 --> 00:58:13.132
something.  This allows you to 
check for JavaScript issues, for

00:58:13.133 --> 00:58:15.133
example, if 

00:58:16.408 --> 00:58:18.236
you're using ES6 or have other 
issues with the JavaScript when 

00:58:18.237 --> 00:58:21.299
it tries to run.  This makes my 
life so much easier because I 

00:58:21.300 --> 00:58:23.348
don't have to help people with 
all of these detailed rendering 

00:58:23.349 --> 00:58:27.004
issues that much.
       Desktop is also a topic 

00:58:27.005 --> 00:58:32.743
that still comes up.  As you've 
seen in maybe some of the other 

00:58:32.744 --> 00:58:35.380
sessions, desktop isn't quite 
dead, so you can run all of 

00:58:35.381 --> 00:58:39.897
these diagnostics in the rich 
results test as well.  This tool

00:58:39.898 --> 00:58:41.898
shows the desktop version of 

00:58:43.307 --> 00:58:46.090
these pages .
       So now that we've seen 

00:58:46.091 --> 00:58:49.894
how to diagnose issues, what 
kind of issues have we run 

00:58:49.895 --> 00:58:53.374
across with modern 
JavaScript-powered science?  

00:58:53.375 --> 00:58:55.423
What patterns do you need to 
watch out for and handle well on

00:58:55.424 --> 00:58:57.424
your side?  

00:59:00.173 --> 00:59:01.589
So remember Tom mentioned at the
beginning of the talk something 

00:59:01.590 --> 00:59:05.492
about lazy loading images and 
being unsure if they're 

00:59:05.493 --> 00:59:10.240
indexable?  Well, it turns out 
they're only sometimes 

00:59:10.241 --> 00:59:12.443
indexable, so it was good to 
look at that.  Depending on how 

00:59:12.444 --> 00:59:16.959
lazy loading is implemented, 
Googlebot may be able to trigger

00:59:16.960 --> 00:59:20.449
it, and with that, may be able 
to pick up images for indexing. 

00:59:20.450 --> 00:59:22.450
For example, if the images are 
above 

00:59:23.717 --> 00:59:26.572
the fold and you're lazy loading
-- your lazy loading kind of 

00:59:26.573 --> 00:59:30.033
runs those images automatically,
Googlebot will probably see 

00:59:30.034 --> 00:59:32.261
that; however, if you want to be
sure that Googlebot is able to 

00:59:32.262 --> 00:59:34.527
pick up lazy loaded images, one 
way to do that 

00:59:38.400 --> 00:59:40.445
is to use a no script tag, so 
you can add a no script tag 

00:59:40.446 --> 00:59:43.320
around a normal image element, 
and we'll be able to pick that 

00:59:43.321 --> 00:59:45.557
up for image search directly.
       Another approach is to 

00:59:45.558 --> 00:59:49.419
use structured data on a page.  
When we see structured data that

00:59:51.069 --> 00:59:53.069
refers to an image, we can also 
pick that up for image search.

00:59:55.832 --> 00:59:58.707
As a side note for images, we 
don't index images that are 

00:59:58.708 --> 01:00:01.755
referenced only through CSS.  We
currently only index images that

01:00:03.625 --> 01:00:05.879
are kind of embedded with with 
the structured data mark-up or 

01:00:05.880 --> 01:00:10.771
with image tags .
       Apart from lazy-loaded 

01:00:10.772 --> 01:00:13.881
images, there are other types of
content that require some kind 

01:00:13.882 --> 01:00:15.882
of interaction to be loaded.

01:00:18.182 --> 01:00:20.642
What about tabs that load the 
content after you click on them 

01:00:20.643 --> 01:00:24.578
or if you have infinite scroll 
patterns on a site?  Googlebot 

01:00:24.579 --> 01:00:26.579
generally won't interact with a 
page, so it wouldn't be able to 

01:00:26.805 --> 01:00:28.805
see these.

01:00:30.328 --> 01:00:33.824
There are two ways that you can 
get this too Googlebot, though. 

01:00:33.825 --> 01:00:35.825
Either you can preload the 
content and 

01:00:36.876 --> 01:00:39.507
just use CSS to toggle 
visibility on and off.  That way

01:00:39.508 --> 01:00:43.416
Googlebot can see that content 
from the preloaded version.  Or 

01:00:43.417 --> 01:00:45.856
alternately, you can just use 
separate URLs and navigate the 

01:00:45.857 --> 01:00:48.742
user and Googlebot to those 
pages individually.

01:00:53.492 --> 01:00:55.300
Now, Googlebot is a patient bot,
but there are a lot of pages 

01:00:55.301 --> 01:00:59.418
that we have to crawl, so we 
have to be efficient and kind of

01:00:59.419 --> 01:01:01.419
go through pages fairly quickly.

01:01:02.719 --> 01:01:05.140
When pages are slow to load or 
render, Googlebot might miss 

01:01:05.141 --> 01:01:07.200
some of the rendered content, 
and since embedded 

01:01:10.252 --> 01:01:13.098
resources are aggressively 
cached for search, rendering 

01:01:13.099 --> 01:01:15.099
time outs are really hard to 
test for, so to limit these 

01:01:16.758 --> 01:01:18.758
problems, we recommend making 
performant 

01:01:22.436 --> 01:01:24.340
and efficient web pages, which 
you're hopefully already doing 

01:01:24.341 --> 01:01:27.241
for users anyway; right?  Limit 
the number of embedded resources

01:01:31.512 --> 01:01:34.561
and avoid artificial delays like
timed interstitials like here.  

01:01:34.562 --> 01:01:36.813
You can test pages with the 
usual set of tools and roughly 

01:01:36.814 --> 01:01:38.814
test rendering with a 
mobile-friendly testing tool.

01:01:41.837 --> 01:01:43.869
And while time-outs here are a 
little different for indexing, 

01:01:43.870 --> 01:01:45.913
in general, if the pages work in
the mobile-friendly test, 

01:01:45.914 --> 01:01:48.141
they'll work for search indexing
too .

01:01:49.994 --> 01:01:52.678
Additionally, Googlebot wants to
see the page as a new user would

01:01:52.679 --> 01:01:54.679
see it, 

01:01:55.742 --> 01:01:58.992
so we crawl and render pages in 
a stateless way.  Any API that 

01:01:58.993 --> 01:02:01.257
tries to store something locally
would not be supported, so if 

01:02:03.747 --> 01:02:05.747
you use any of these 
technologies, make 

01:02:07.030 --> 01:02:09.050
sure to use graceful degradation
techniques to allow anyone to 

01:02:09.051 --> 01:02:13.329
view your pages, even if these 
APIs are not supported .

01:02:14.957 --> 01:02:18.423
And that was it with regards to 
critical best practices.  Now 

01:02:18.424 --> 01:02:20.452
it's time to take a quick circle
back and see what we've seen.

01:02:21.878 --> 01:02:26.960
       So first, we recommend 
checking for proper 

01:02:26.961 --> 01:02:28.998
implementation of best practices
that we talked about, in 

01:02:32.664 --> 01:02:35.928
particular lazy-loaded images 
are really common.  Second, test

01:02:35.929 --> 01:02:38.811
a sample of your pages with the 
mobile-friendly test and use the

01:02:38.812 --> 01:02:40.667
other testing tools as well.  
Remember, you don't need to test

01:02:40.668 --> 01:02:44.542
all of your pages, just make 
sure that you have all of the 

01:02:44.543 --> 01:02:46.543
templates covered.

01:02:48.452 --> 01:02:50.124
And then finally, if pages are 
large and -- if sites are large 

01:02:50.125 --> 01:02:55.437
and quick-changing and you -- or
you can't reasonably fix 

01:02:55.438 --> 01:02:57.878
rendering across the site, then 
maybe consider using dynamic 

01:03:00.315 --> 01:03:01.944
rendering techniques to serve 
Googlebot and other crawlers a 

01:03:01.945 --> 01:03:03.945
prerendered version of your 
page.

01:03:04.585 --> 01:03:06.418
And finally, if you do decide to
use dynamic rendering, make sure

01:03:06.419 --> 01:03:08.462
to double-check the results 
there as well.

01:03:10.508 --> 01:03:12.744
One thing to keep in mind, 
indexing isn't the same as 

01:03:12.745 --> 01:03:14.745
ranking, but generally speaking,
pages do need to be 

01:03:17.453 --> 01:03:19.453
indexed before their content can
appear in Search at all.

01:03:20.936 --> 01:03:22.765
I don't know, Tom, do you think 
that covers about everything?  

01:03:22.766 --> 01:03:26.646
       &gt;&gt; TOM GREENAWAY: Well, 
it was a lot to take in, John.  

01:03:26.647 --> 01:03:28.653
That was some amazing content.  
But I guess one question I have,

01:03:28.654 --> 01:03:32.529
and I think maybe other people 
in the audience have this on 

01:03:32.530 --> 01:03:33.954
their mind as well, is, is it 
always going to be this way, 

01:03:33.955 --> 01:03:35.190
John?  
       &gt;&gt; JOHN MUELLER: That's a

01:03:35.191 --> 01:03:39.320
great question, Tomment I don't 
know.  Is -- I think -- Tom.  I 

01:03:39.321 --> 01:03:42.784
don't know.  I think things will
never stay the same.  As you 

01:03:42.785 --> 01:03:44.002
mentioned in the beginning, this
is challenge for us.  That's 

01:03:44.003 --> 01:03:48.918
important.  Within Google 
Search, we want our search 

01:03:48.919 --> 01:03:50.546
results to reflect the web as it
is regardless of the type of 

01:03:50.547 --> 01:03:55.233
website that's used, so our 
long-term version is that you, 

01:03:55.234 --> 01:03:57.234
the developers, shouldn't need 

01:03:59.735 --> 01:04:01.735
to worry as much about this for 
search crawlers.

01:04:03.061 --> 01:04:04.125
So circling back on the diagram 
that Tom showed in the beginning

01:04:04.126 --> 01:04:06.152
with deferred rendering, one 
change we want 

01:04:09.462 --> 01:04:11.061
to make is to move rendering 
closer to crawling and indexing.

01:04:11.062 --> 01:04:15.436
       Another change we want to
make is to make Googlebot use a 

01:04:15.437 --> 01:04:19.311
more modern version of Chrome 
over time.  Both of these will 

01:04:19.312 --> 01:04:21.545
take a bit of time.  I don't 
like making long-term 

01:04:25.426 --> 01:04:27.267
predictions, but I suspect it'll
be at least untilend of year 

01:04:27.268 --> 01:04:30.378
until this works a little bit.  
Similarly, we trust that 

01:04:30.379 --> 01:04:33.049
rendering will be more and more 
common across all kinds of web 

01:04:33.050 --> 01:04:35.286
services.
       So at that point, dynamic

01:04:37.937 --> 01:04:39.186
rendering is probably less 
critical for modern science; 

01:04:39.187 --> 01:04:41.239
however, the best practices that
we talked about, they'll 

01:04:43.279 --> 01:04:45.279
continue to be important here as
well.

01:04:47.909 --> 01:04:49.038
How does that sound, Tom?  
       &gt;&gt; TOM GREENAWAY: That 

01:04:49.039 --> 01:04:52.474
sounds really great.  I think 
that covers everything, and I 

01:04:54.497 --> 01:04:56.226
hope everyone in the room has 
learned some new approaches and 

01:04:56.227 --> 01:04:59.724
tools that are useful for making
your modern JavaScript-powered 

01:04:59.725 --> 01:05:02.998
websites work well in Google 
Search.  If you have any 

01:05:02.999 --> 01:05:05.660
questions, we'll be in the 
mobile web sandbox area together

01:05:08.309 --> 01:05:10.350
with the Search Console team, 
and alternatively you can reach 

01:05:10.351 --> 01:05:12.351
out to us 

01:05:13.403 --> 01:05:15.854
online be it through Twitter, 
our live office hours Hangouts 

01:05:15.855 --> 01:05:18.696
and in the webmaster help forum 
as well, so thanks, everyone, 

01:05:18.697 --> 01:05:19.515
for your time.  
       &gt;&gt; JOHN MUELLER: Thank 

01:05:19.516 --> 01:05:22.394
you.  
       (Applause) 

01:13:49.256 --> 01:13:51.256
RAW FILE

01:13:55.169 --> 01:13:57.395
GOOGLE I/O 2018
MOUNTAIN VIEW, CALIFORNIA

01:14:00.270 --> 01:14:02.270
MAY 10, 2018

01:14:03.526 --> 01:14:05.982
STAGE 2
9:30 AM

01:14:12.036 --> 01:14:14.036
THE FUTURE OF COMPUTING WITH

01:14:16.574 --> 01:14:18.574
: A CONVERSATION WITH JOHN 
HENNESSY

01:14:23.022 --> 01:14:23.922
T6813B
Services Provided By:

01:14:23.923 --> 01:14:26.056
Caption First, Inc.
P.O. Box 3066

01:14:23.923 --> 01:14:26.056
Monument, CO 80132
1 877 825 5234

01:14:23.923 --> 01:14:25.371
+001 719 481 9835
www.captionfirst.com

01:14:25.372 --> 01:14:27.705
***
This text, document, or file is 

01:14:25.372 --> 01:14:25.579
based on live transcription.  
Communication Access Realtime 

01:14:25.580 --> 01:14:29.713
Translation (CART), captioning, 
and/or live transcription are 

01:14:25.580 --> 01:14:28.580
provided in order to facilitate 
communication

01:14:25.580 --> 01:14:29.713
accessibility and may not be a 
totally verbatim record of the 

01:14:25.580 --> 01:14:29.313
proceedings.  This text, 
document, or file is not to be 

01:14:25.580 --> 01:14:29.713
distributed or used in any way 
that may violate copyright law.

01:14:25.580 --> 01:14:27.580
***

01:15:35.207 --> 01:15:37.207
GOOGLE I/O 2018

01:15:39.873 --> 01:15:42.343
MOUNTAIN VIEW, CALIFORNIA
MAY 10, 2018

01:15:44.788 --> 01:15:46.788
9:30 AM

01:15:47.853 --> 01:15:49.853
STAGE 2

01:15:53.596 --> 01:15:55.019
THE FUTURE OF COMPUTING: A 
CONVERSATION WITH JOHN HENNESSY

01:16:00.069 --> 01:16:02.069
T

01:16:04.575 --> 01:16:06.575
6813B

01:22:25.264 --> 01:22:27.264
&gt;&gt; What I find fascinating about

01:22:29.730 --> 01:22:31.978
technology and engineering is 
there's always something new 

01:22:31.979 --> 01:22:33.979
happening.  It's a field that 
goes out into the world.

01:22:36.854 --> 01:22:38.945
&gt;&gt; If you know computer 
temperature and technology 

01:22:38.946 --> 01:22:40.946
business, you know the name John
Hennessy.

01:22:44.075 --> 01:22:46.075
&gt;&gt; John Hennessy joined Stanford
University launching a life long

01:22:46.831 --> 01:22:48.368
commitment to technology and 
education.  He was instrumental 

01:22:48.369 --> 01:22:50.369
in the development 

01:22:51.945 --> 01:22:52.755
of a new technology known as 
reduced instruction set 

01:22:52.756 --> 01:22:54.392
computer, a game changer in 
computing that increased 

01:22:54.393 --> 01:22:57.923
performance while reducing 
costs.  He founded a start-up 

01:22:57.924 --> 01:22:59.924
and helped transfer risk to the 
commercial market.

01:23:05.006 --> 01:23:07.006
&gt;&gt; For me, entrepreneurship is 
about

01:23:09.119 --> 01:23:10.371
transforming things by taking 
new ideas, seeing them from 

01:23:10.372 --> 01:23:12.372
conference into practice.

01:23:13.701 --> 01:23:14.923
&gt;&gt; In 2000, he was named the 
tenth president of Stanford 

01:23:14.924 --> 01:23:17.606
University.
&gt;&gt; John Hennessy is a world 

01:23:17.607 --> 01:23:22.291
class scholar, on the boards of 
lots of very successful 

01:23:22.292 --> 01:23:24.292
ventures, and the recipient of 
numerous awards.

01:23:26.576 --> 01:23:28.403
&gt;&gt; I've sometimes had to put 
myself in situation that's had 

01:23:28.404 --> 01:23:32.893
some uncertainty about how they 
were going to evolve over time 

01:23:32.894 --> 01:23:34.310
but it's provided me with an 
opportunity to grow and learn 

01:23:34.311 --> 01:23:38.194
and experience new things, which
I think is one of life's great 

01:23:38.195 --> 01:23:41.043
rewards.
(applause)

01:23:47.617 --> 01:23:50.080
&gt;&gt; JOHN HENNESSY: Morning.  
Morning, everyone.

01:23:50.081 --> 01:23:52.081
(applause)

01:23:53.557 --> 01:23:55.998
Boy, I'm delighted to be here 
today, and have a chance to talk

01:23:55.999 --> 01:23:58.653
to you about what is one of the 
biggest challenges we've 

01:24:01.691 --> 01:24:04.350
faced in computing in 40 years, 
but also, a tremendous 

01:24:04.351 --> 01:24:07.423
opportunity to rethink how we 
build computers and how we move 

01:24:07.424 --> 01:24:11.541
forward.  You know, there's been
a lot of discussion about the 

01:24:11.542 --> 01:24:13.166
ending of Moore's Law.  The 
first thing to remember about 

01:24:13.167 --> 01:24:16.229
the ending of Moore's Law is 
something Gordon Moore said to 

01:24:16.230 --> 01:24:18.230
me.

01:24:19.482 --> 01:24:21.121
He said, all exponentials come 
to an end.  It's just a question

01:24:21.122 --> 01:24:23.122
of when, and 

01:24:26.365 --> 01:24:28.365
that's what's happening with 
Moore's Law

01:24:29.745 --> 01:24:32.181
.  If we look at, what does it 
really mean to say Moore's Law 

01:24:32.182 --> 01:24:35.672
is ending?  What does it mean?  
Well, look what's happening in 

01:24:35.673 --> 01:24:38.533
DRAMs, that's probably a good 
place to start because with all 

01:24:38.534 --> 01:24:42.192
depend on the incredible growth 
and memory capacity.  And if you

01:24:42.193 --> 01:24:44.193
look at what's happening in 

01:24:45.255 --> 01:24:47.281
DRAMs, for many years we were 
achieving increases of about 50 

01:24:47.282 --> 01:24:52.220
percent, in other words, going 
up slightly faster even than 

01:24:52.221 --> 01:24:53.855
Moore's Law, then we began a 
period of slow down and if you 

01:24:53.856 --> 01:24:58.152
look at what's happened in the 
last ten years, this technology 

01:24:58.153 --> 01:25:00.184
we were used to seeing boom, the
number of mega bits per chip, 

01:25:00.185 --> 01:25:04.660
more than doubling every two 
years is now going up at about 

01:25:04.661 --> 01:25:06.283
10 percent aee and is going to 
take about seven years to 

01:25:06.284 --> 01:25:09.141
double.
Now, DRAMs are particularly odd 

01:25:12.008 --> 01:25:14.008
technology because they used 
deep 

01:25:15.467 --> 01:25:16.687
trenched capacitors so they 
require a particular fabrication

01:25:16.688 --> 01:25:18.688
technology.  What's happening in
processors, though?

01:25:20.968 --> 01:25:22.785
If you look at the data in 
processors, you'll see a similar

01:25:22.786 --> 01:25:24.786
slow down.  Moore's Law is that 
red line going up 

01:25:28.697 --> 01:25:32.394
there on a nice log rhythmic 
plot.  Notice the blue line.  

01:25:32.395 --> 01:25:34.395
That's a particular Intel 
microprocessor at that date.

01:25:37.027 --> 01:25:39.027
It begins

01:25:40.611 --> 01:25:42.241
diverging, slowly at first, but 
look at the last ten years.  The

01:25:42.242 --> 01:25:46.900
gap has grown.  In fact, if you 
look at where we are in 2015, 

01:25:46.901 --> 01:25:48.901
2016, we're more than a factor 

01:25:51.101 --> 01:25:52.733
of ten off had we stayed on that
Moore's line curve.

01:25:52.734 --> 01:25:55.601
Now, the thing to remember is 
that it also, there's also a 

01:25:55.602 --> 01:25:57.602
cost factor in here.

01:26:00.952 --> 01:26:02.991
Fabs are getting a lot more 
expensive and the cost of chips 

01:26:02.992 --> 01:26:07.272
is actually not going down as 
fast so a result of that is that

01:26:07.273 --> 01:26:08.901
the cost for transistor is 
actually increasing at a worse 

01:26:08.902 --> 01:26:12.610
rate.  So, we're beginning to 
see the effects of that as we 

01:26:12.611 --> 01:26:14.611
think about archtecture.

01:26:17.855 --> 01:26:19.855
But, if the slowdown

01:26:21.980 --> 01:26:23.624
of Moore's Law, which you see 
all the press about, the big 

01:26:23.625 --> 01:26:28.104
issue is the end of what we call
Dennard's scaling.  So, Bob 

01:26:28.105 --> 01:26:30.105
Dennard, an IBM employee, the 

01:26:31.170 --> 01:26:32.809
guy who invested the one 
transistor DRAM and he made a 

01:26:32.810 --> 01:26:34.810
prediction many years ago that 
the energy, the power per square

01:26:37.548 --> 01:26:39.548
millimeter of silicone would 
stay 

01:26:40.816 --> 01:26:42.816
constant, would stay constant 
because 

01:26:47.750 --> 01:26:49.670
voltage levels would come down, 
capac itants would come down.  

01:26:49.671 --> 01:26:52.114
What does that mean?  If the 
energy stays constant and the 

01:26:54.968 --> 01:26:56.801
number of transistor increases 
exponentially then the energy 

01:26:56.802 --> 01:26:58.802
per 

01:27:00.100 --> 01:27:02.235
transistor is actually going 
down and in terms of energy 

01:27:02.236 --> 01:27:04.236
consumption and cheaper and 
cheaper to computes.

01:27:05.124 --> 01:27:06.140
Well, what happened with 
Dennard's scaling?  Look at that

01:27:06.141 --> 01:27:08.141
red line.

01:27:09.204 --> 01:27:11.204
The red line shows you 
technology 

01:27:12.659 --> 01:27:14.302
improving on a standard 
Dennard's law curve the the blue

01:27:14.303 --> 01:27:16.947
line is what's happening to 
power.  You've seen Microsoft's 

01:27:16.948 --> 01:27:22.009
processor now.  They slow their 
clock down, turn off cores, do 

01:27:22.010 --> 01:27:22.430
all kinds of things because 
otherwise they're going to burn 

01:27:22.431 --> 01:27:26.713
up.  I mean, I never thought 
we'd see the day where a 

01:27:26.714 --> 01:27:28.745
processor would actually slow 
itself down to prevent itself 

01:27:29.950 --> 01:27:31.635
overheating but we're there so 
what happens with Dennard's 

01:27:31.636 --> 01:27:33.636
scaling is the 

01:27:34.738 --> 01:27:36.738
last, it began to slow down 
starting 

01:27:38.992 --> 01:27:43.537
about 97, and then since 2007, 
it's essentially halted.  The 

01:27:43.538 --> 01:27:45.538
result is a big change.  All of 
a sudden, energy, power becomes 

01:27:46.237 --> 01:27:48.311
the key limiter.  Not the number
of transistors 

01:27:52.418 --> 01:27:54.418
available to designers, but the 
will 

01:27:55.469 --> 01:27:57.469
their power consumption becomes 
the key limiter.

01:27:58.714 --> 01:28:00.714
That requires you to think 
completely 

01:28:03.972 --> 01:28:05.972
dimply about archtecture, about 
how you

01:28:08.114 --> 01:28:10.114
design machines.

01:28:11.363 --> 01:28:13.994
It means inconsistency in how an
architecture computes is 

01:28:13.995 --> 01:28:16.017
penalized much more heavily than
it was in this earlier time.

01:28:17.260 --> 01:28:19.260
And of course, guess what.  All 
the devices we carry around, all

01:28:22.360 --> 01:28:23.787
the devices we use are running 
off batteries.  So, all of a 

01:28:23.788 --> 01:28:26.620
sudden, energy is a critical 
resource, right?  What's the 

01:28:26.621 --> 01:28:29.124
worst thing that happens?  Your 
cell phone runs out of power, 

01:28:30.542 --> 01:28:32.542
your smartphone runs out of 
power, that's a disaster, right?

01:28:33.605 --> 01:28:35.814
But you think about all the 
devices we walk around with.  

01:28:35.815 --> 01:28:37.815
They're hooked up to battery.

01:28:40.882 --> 01:28:43.401
Think about the era, the coming 
era of IoT where we're going to 

01:28:43.402 --> 01:28:47.877
have devices always on and 
permanently on which are 

01:28:47.878 --> 01:28:49.878
expected to last ten years on 

01:28:50.927 --> 01:28:53.169
a single battery by using energy
harvesting  techniques.  Energy 

01:28:53.170 --> 01:28:54.791
becomes the key resource in 
making those things work 

01:28:54.792 --> 01:28:57.057
efficiently.  And as we move 
more and more to always 

01:29:00.339 --> 01:29:01.551
on devices with things like 
Google Assistant you're going to

01:29:01.552 --> 01:29:04.616
want your device or at least the
CPU on all the time if not the 

01:29:04.617 --> 01:29:06.276
screen so we're going to have to
worry more and more about power.

01:29:06.277 --> 01:29:08.277
But the surprising thing that 
many 

01:29:12.541 --> 01:29:15.017
people are surprised by is that 
energy efficiency is a giant 

01:29:16.848 --> 01:29:18.875
issue in large Cloud 
configurations.  This shows you 

01:29:18.876 --> 01:29:22.165
what the typical capital cost 
would be like for a Google data 

01:29:22.166 --> 01:29:24.166
center.

01:29:25.849 --> 01:29:27.271
You'll notice that green slice 
there, those are the servers, 

01:29:27.272 --> 01:29:30.556
but look at the size of that red
slice.  That red slice is the 

01:29:30.557 --> 01:29:32.557
cost of the power plus cooling 
infrastructure.

01:29:37.864 --> 01:29:39.704
You're spending as much on power
and cooling as you're spending 

01:29:39.705 --> 01:29:41.705
on processors 

01:29:43.363 --> 01:29:44.815
so energy efficiency become 
becomes a really critical issue 

01:29:44.816 --> 01:29:48.530
as we go forward and the end of 
Dennard's scaling has meant 

01:29:48.531 --> 01:29:50.572
there's no more free lunch.  For
a lot of years, we had a free 

01:29:50.774 --> 01:29:54.423
lunch.  It was pretty easy to 
figure out how to make 

01:29:54.424 --> 01:29:56.482
computation more energy 
efficient.  Now, it's a lot 

01:29:56.483 --> 01:29:58.483
harder.

01:30:02.205 --> 01:30:04.205
And you can see the impact of 
this

01:30:07.760 --> 01:30:09.760
this just shows you 40 years of 

01:30:11.630 --> 01:30:14.081
processor performance, single 
and multicomponent.  So at the 

01:30:14.082 --> 01:30:17.341
beginning of the microprocessor 
era, we were seeing about 22 

01:30:17.342 --> 01:30:19.342
percent improvement per yearment
of 

01:30:20.822 --> 01:30:22.642
the creation of risk in the 
mid-1980s, a dramatic use of 

01:30:22.643 --> 01:30:24.643
instruction level parallels and 
pipelining, multiple issue.

01:30:29.431 --> 01:30:31.655
We saw this incredible period of
about 20 years where we got 

01:30:31.656 --> 01:30:33.723
roughly 50 percent performance 
improvement per year.  50 

01:30:33.724 --> 01:30:37.590
percent.  That was amazing.  
Then, the beginning of the end 

01:30:37.591 --> 01:30:40.221
of Dennard's scaling.  That 
cause ever caused everybody to 

01:30:41.042 --> 01:30:45.314
move to multicore.  What did 
multicore do?  Mulletsy core 

01:30:45.315 --> 01:30:47.315
shoved the efficiency problem 
from the hardware designer to 

01:30:51.579 --> 01:30:53.952
the software people.  Now the 
software people had to figure 

01:30:58.027 --> 01:31:00.027
out who to use those  multicore 
processors efficiently.

01:31:04.200 --> 01:31:06.439
But, Amdel's law came along, 
reared its ugly head.  I'll show

01:31:06.440 --> 01:31:09.932
you some data on that.  And now 
we're in this late stage period 

01:31:09.933 --> 01:31:12.178
where it looks like we're 
getting about 3 percent 

01:31:12.179 --> 01:31:14.220
performance improvement per 
year.  Doubling could take 20 

01:31:14.221 --> 01:31:17.737
years.  That's the end of the 
general purpose processor 

01:31:17.738 --> 01:31:19.738
performance as we know it, as 

01:31:23.192 --> 01:31:25.192
we're used to for so many years

01:31:28.556 --> 01:31:30.556
.  Why did this happen?

01:31:31.822 --> 01:31:33.822
Why did it grind to a halt so 
fast?

01:31:36.112 --> 01:31:38.270
Well, think about what's 
happening where we're building 

01:31:38.271 --> 01:31:41.614
these deep pipeline machines.  
Fifteen, 16, 17 stages.  Four 

01:31:41.615 --> 01:31:44.700
issues per clock.  That machine 
needs to have 60 instructions 

01:31:44.701 --> 01:31:47.770
that it's working on at once, 60
instructions.  How does it 

01:31:47.771 --> 01:31:49.771
possibly get 60 instructions?  
It uses speculation.

01:31:53.476 --> 01:31:55.476
It guesses about branches.

01:31:56.723 --> 01:31:58.365
It yanks instructions and tries 
to execute them.  But guess what

01:31:58.366 --> 01:32:02.826
happens?  Nobody can predict 
branches perfectly.  Every time 

01:32:02.827 --> 01:32:05.079
you predict a branch 
incorrectly, you have to undo 

01:32:05.080 --> 01:32:07.318
all the work associated with 
that misprediction.

01:32:10.574 --> 01:32:12.574
You've got to back it out, rue 
store the state of the machine.

01:32:15.863 --> 01:32:17.863
And if you look inside a typical
Intel 

01:32:19.529 --> 01:32:21.356
Core i7 today, on integer code, 
roughly 25 percent of the 

01:32:21.357 --> 01:32:23.357
instructions that get executed 
end up being thrown away.

01:32:24.429 --> 01:32:26.467
Guess what?  The energy still 
got burnt to execute 

01:32:30.926 --> 01:32:32.926
all these instructions

01:32:41.760 --> 01:32:43.598
.  And then I threw the results 
away and had to restore the 

01:32:43.599 --> 01:32:48.492
state of the machine.  A lot of 
wasted energy.  That's why we 

01:32:48.493 --> 01:32:50.493
saw the single core processor 
go.

01:32:53.175 --> 01:32:56.716
Amdahl's law, more than 30 years
ago, it's still true today.  

01:32:56.717 --> 01:32:59.152
Even if you take large data 
centers with heavily parallelled

01:32:59.153 --> 01:33:02.415
workloads, it's very hard to 
write a big complicated piece of

01:33:02.416 --> 01:33:05.070
software and not have small 
sections of it be sequential, 

01:33:05.071 --> 01:33:08.118
whether it's synchronization or 
coordination or something else.

01:33:08.323 --> 01:33:10.323
So, think about what happens.

01:33:12.593 --> 01:33:15.468
You get a 64-processor multicore
in the future.  Suppose 1 

01:33:15.469 --> 01:33:17.497
percent, just 1 percent of the 
code is sequential.

01:33:21.564 --> 01:33:24.207
Then that 64-processor multicore
only runs at the speed of a 

01:33:24.208 --> 01:33:26.208
40-processor core.  But, guess 
what?

01:33:30.802 --> 01:33:32.629
You paid all the energy for a 
64-processor core all the time 

01:33:32.630 --> 01:33:35.887
and you only got 40 processors 
out of that.  Slightly more than

01:33:35.888 --> 01:33:40.354
half.  That's the problem.  
We've got to break through this 

01:33:40.763 --> 01:33:42.817
efficiency barrier.  We've got 
to rethink how we design 

01:33:44.056 --> 01:33:46.287
machines.  So, what's left?

01:33:49.558 --> 01:33:51.990
Well, software centric 
approaches.  Can we make our 

01:33:51.991 --> 01:33:53.991
machines -- can we make our 
systems more efficient?

01:33:59.169 --> 01:34:00.569
It's great that we have these 
modern scripting languages, 

01:34:00.570 --> 01:34:03.869
they're interpreted, they 
encourage reuse.  They've really

01:34:03.870 --> 01:34:07.975
liberated programmers to get a 
lot more code written and create

01:34:07.976 --> 01:34:09.600
incredible functionality.  
They're efficient for 

01:34:09.601 --> 01:34:14.073
programmers.  They're very 
inefficient for execution and 

01:34:14.074 --> 01:34:15.904
I'll show you that in a second. 
And then there are hardware 

01:34:15.905 --> 01:34:20.362
centric approaches, what Dave 
Patterson and I call 

01:34:20.363 --> 01:34:22.814
domain-specific architectures.  
Namely, designing an 

01:34:22.815 --> 01:34:27.123
architecture which isn't fully 
general purpose but which does a

01:34:27.124 --> 01:34:30.003
set of domains, a set of 
applications really well.  Much 

01:34:30.004 --> 01:34:32.651
more efficiently.
So, let's take a look at what 

01:34:32.652 --> 01:34:34.652
the opportunity is.

01:34:38.719 --> 01:34:40.719
This is a chart that comes out 
of a

01:34:43.507 --> 01:34:45.949
paper by Charles Licensen and a 
group of colleagues at MIT 

01:34:45.950 --> 01:34:47.950
called, there's plenty of room 
at the talk.

01:34:50.474 --> 01:34:53.312
They take matrix multiply, they 
write it in python, they run it 

01:34:53.313 --> 01:34:55.313
on an 18-core Intel processor 
and then they proceed to 

01:34:55.762 --> 01:34:58.839
optimize it.  First, rewrite it 
in C.  That speeds it up 47 

01:34:58.840 --> 01:35:03.369
times.  Now, any compiler in the
world that can get a speed-up of

01:35:03.370 --> 01:35:08.055
47 would be really remarkable, 
even a speed-up of 20.  Then 

01:35:08.056 --> 01:35:10.292
they rewrite it with parallel 
loops.  They get almost a factor

01:35:10.293 --> 01:35:12.954
of nine out of that.  Then they 
rewrite it by doing memory 

01:35:13.566 --> 01:35:17.027
optimize conversation.  That 
gives them a factor of 20.  They

01:35:17.028 --> 01:35:20.743
block the matrix.  They allocate
it to the caches properly.  That

01:35:20.744 --> 01:35:23.590
gives them a factor of 20.  And 
then,  finally, they rewrite it 

01:35:26.880 --> 01:35:28.723
using Intel AVX instructions, 
using the vector instructions in

01:35:28.724 --> 01:35:33.621
the Intel core, right?  
Domain-specific instructions 

01:35:33.622 --> 01:35:36.318
that do vector operations 
efficiently, that gives them 

01:35:36.319 --> 01:35:38.977
another factor of ten.  The end 
result is that final version 

01:35:41.291 --> 01:35:43.291
runs 62,000 times faster than 
the initial version.

01:35:45.824 --> 01:35:47.842
Now, admittedly matrix multiply 
is an easy case small piece of 

01:35:47.843 --> 01:35:52.181
code but it shows the potential 
of rethinking how we write this 

01:35:52.182 --> 01:35:54.182
software and making it better.

01:35:57.669 --> 01:35:59.669
So what about

01:36:02.299 --> 01:36:04.729
these domain-specific 
architectures, really, what 

01:36:04.730 --> 01:36:06.730
we're going to try to do is 

01:36:08.866 --> 01:36:11.296
make a breakthrough in how we 
build the hardware and by 

01:36:11.297 --> 01:36:13.536
domain-specific we're referring 
to a class of processors which 

01:36:14.574 --> 01:36:16.574
do a range of  applications.

01:36:19.470 --> 01:36:21.470
They're not like, for example, 
the

01:36:22.823 --> 01:36:24.478
modem inside your cell phone.  
That's programmed once, never 

01:36:24.479 --> 01:36:29.968
does anything else.  But think 
of a set of processors which do 

01:36:29.969 --> 01:36:31.589
eye range of applications 
related to a particular 

01:36:31.590 --> 01:36:34.698
application.  They're useful in 
that domain.  They take 

01:36:34.699 --> 01:36:37.975
advantage of specific knowledge 
about that domain when they run 

01:36:37.976 --> 01:36:41.829
so they can run much more 
efficiently.  Obvious  examples,

01:36:41.830 --> 01:36:44.289
doing things for neural network 
processors.  Doing thing that's 

01:36:44.290 --> 01:36:47.357
focus on machine learning.  One 
example.  GPUs are another 

01:36:47.358 --> 01:36:49.358
example of this kind of 
thinking, right?

01:36:57.765 --> 01:36:58.981
They're programmable in the 
context of doing graphics 

01:36:58.982 --> 01:37:03.290
processing.  So any of you who 
have ever seen any of the books 

01:37:03.291 --> 01:37:05.532
that Dave Patterson and I wrote.
You know that you want 

01:37:05.533 --> 01:37:07.533
quantitative approaches and we 
like to analyze why 

01:37:11.638 --> 01:37:12.864
things work so the key about 
domain specific architecture is 

01:37:12.865 --> 01:37:16.112
there is no black magic here.  
Going to a more limited range of

01:37:16.928 --> 01:37:17.536
architectures doesn't 
automatically make things 

01:37:17.537 --> 01:37:19.803
faster.  We have to make some 
specific 

01:37:24.866 --> 01:37:26.866
architectural changes that win

01:37:33.693 --> 01:37:35.693
.  The first one is parallelism.

01:37:37.768 --> 01:37:38.983
We go from a multicore to a 
single multisystem data so 

01:37:38.984 --> 01:37:43.924
instead of having each one of my
cores fetch separate instruction

01:37:43.925 --> 01:37:45.925
streams, that separate set of 
caches, I've got one set of 

01:37:47.176 --> 01:37:49.206
instructions going to a whole 
set of functional units.  It's 

01:37:49.207 --> 01:37:53.334
much more efficient.  What do I 
give up?  I give up flexibility 

01:37:53.335 --> 01:37:55.573
when I do that.  I absolutely 
give up flexibility but 

01:38:00.612 --> 01:38:02.612
the efficiency gain is dramatic

01:38:14.943 --> 01:38:16.369
.  Something like VLW that uses 
a set of operations where the 

01:38:16.370 --> 01:38:20.502
compiler has decided that a set 
of operations can occur in 

01:38:20.503 --> 01:38:23.141
parallel so I shift work from 
runtime to compile time.  Again,

01:38:23.142 --> 01:38:24.767
it's less flexible but for 
applications when it works, it's

01:38:24.768 --> 01:38:26.768
much more efficient.

01:38:33.363 --> 01:38:35.384
I move away from caches.  So, 
caches are one of the great 

01:38:36.603 --> 01:38:38.228
interventions of computer 
science, one of the truly great 

01:38:38.229 --> 01:38:42.312
interventions.  The problem is 
with when there's low space, 

01:38:42.313 --> 01:38:45.818
caches don't work.  They 
actually slow programs down.  

01:38:45.819 --> 01:38:48.257
They slow them down.  So, we 
move away from that to user 

01:38:48.866 --> 01:38:53.560
control local memories.
What's the trade-off?  Now 

01:38:53.561 --> 01:38:56.200
somebody has to figure out how 
to map their applications in a a

01:38:57.020 --> 01:38:59.674
user-controlled memory 
structure.  Cache does it 

01:38:59.675 --> 01:39:01.693
automatically for you.  It's 
very general purpose but for 

01:39:02.911 --> 01:39:04.747
certain applications I can do a 
lot better by mapping those 

01:39:04.748 --> 01:39:06.748
things myself.

01:39:08.114 --> 01:39:08.922
And then finally, I focus on 
only the amount of accuracy I 

01:39:08.923 --> 01:39:10.923
need.

01:39:12.650 --> 01:39:14.650
I move from IEEE to the lower 

01:39:15.808 --> 01:39:17.808
precision floating point or from
32 and 

01:39:19.113 --> 01:39:21.354
64-bit integers to eight-bit and
16-bit integers.  If that's all 

01:39:21.355 --> 01:39:24.202
the accuracy I need, I can do 
eight eight-bit operations 

01:39:24.203 --> 01:39:26.203
notice 

01:39:28.061 --> 01:39:29.493
same amount of time I can do one
64-bit operation, so 

01:39:29.494 --> 01:39:33.765
considerably faster.  But, to go
along with that, I also need a 

01:39:33.766 --> 01:39:35.766
domain-specific language.

01:39:38.830 --> 01:39:40.830
I need a language that will

01:39:43.967 --> 01:39:45.967
match up to that specific 
hardware.  We're not going to be

01:39:45.968 --> 01:39:50.693
able to take code in pager and 
extract the kind of information 

01:39:50.694 --> 01:39:52.726
we need to map to a specific 
architecture.  We've got to 

01:39:52.727 --> 01:39:54.763
rethink how we program these 
machines and that's going to be 

01:39:55.576 --> 01:39:57.576
high level operations.

01:39:59.480 --> 01:40:01.480
It's going to be vector vector 

01:40:03.137 --> 01:40:04.563
multiplier or vector matrix 
multiplier or sparse matrix 

01:40:04.564 --> 01:40:06.564
organization so that I get that 
high level information that I 

01:40:07.406 --> 01:40:09.406
need and I can compile that down
into the architecture.

01:40:12.518 --> 01:40:14.518
The key in doing these 
domain-specific 

01:40:15.523 --> 01:40:17.523
languages will be

01:40:20.255 --> 01:40:22.114
to retain enough machine 
independence that I don't have 

01:40:22.115 --> 01:40:24.115
to recode things, that a 
compiler can come along, take a 

01:40:25.392 --> 01:40:26.418
domain-specific language, map it
to maybe one architecture 

01:40:26.419 --> 01:40:28.419
running in the 

01:40:30.088 --> 01:40:31.511
Cloud, maybe another 
architecture that's running on 

01:40:31.512 --> 01:40:33.512
my smartphone.  That's going to 
be the challenge.

01:40:37.433 --> 01:40:38.839
Ideas like TensorFlow and OpenGL
are a step in this direction, 

01:40:38.840 --> 01:40:41.073
but it's really new space.  
We're just beginning to 

01:40:41.074 --> 01:40:46.111
understand it and understand how
to design in this space

01:40:50.667 --> 01:40:52.496
.  You know, I built my first 
computer almost 50 years ago, 

01:40:52.497 --> 01:40:55.143
believe it or not.  I've seen a 
lot of revolutions in this 

01:40:57.986 --> 01:40:58.789
incredible IT industry since 
then.  The creation of the 

01:40:58.790 --> 01:41:00.790
internet.  The creation of the 
worldwide web.

01:41:03.937 --> 01:41:05.937
The manualic of the 
microprocessor, a 

01:41:06.957 --> 01:41:09.908
smartphone, personal computers. 
But the one I think that is 

01:41:09.909 --> 01:41:13.178
really going to change our lives
is the break through in machine 

01:41:13.179 --> 01:41:15.179
learning and artificial  
intelligence.

01:41:21.884 --> 01:41:25.617
This is a technology which 
people have worked on for 50 

01:41:21.884 --> 01:41:23.884
years and finally, 

01:41:25.944 --> 01:41:27.944
finally, we made the break 
through

01:41:33.457 --> 01:41:37.390
.  And the basis of that break 
through?  We needed about a 

01:41:33.457 --> 01:41:35.457
million more times than we 
thought we needed to get the 

01:41:36.348 --> 01:41:38.348
technology to work but we 
finally got to 

01:41:40.424 --> 01:41:42.424
the point where could apply that
kind of computer power.

01:41:43.691 --> 01:41:45.721
And the one thing that shows 
there's one thing growing just 

01:41:45.722 --> 01:41:48.565
as fast as Moore's Law, the 
number of papers being published

01:41:48.566 --> 01:41:52.826
in machine learning.
It is a revolution.  It's going 

01:41:52.827 --> 01:41:54.827
to change our world and I'm 

01:41:57.114 --> 01:41:59.129
sure some of you saw the duplex 
demo the other day.  In the 

01:41:59.130 --> 01:42:01.130
domain of making appointments, 

01:42:03.575 --> 01:42:05.575
it passes the

01:42:06.909 --> 01:42:09.198
Turing test in that domain which
is extraordinary.  It doesn't 

01:42:09.199 --> 01:42:11.199
pass it in general terms but it 
passes it in the domain and 

01:42:12.700 --> 01:42:15.149
that's really an indication of 
what's coming.

01:42:17.409 --> 01:42:19.409
So, how do you think about 
building a 

01:42:21.283 --> 01:42:23.937
domain-specific architecture to 
do deep neural networks.  This 

01:42:23.938 --> 01:42:26.175
is a big picture of what's 
inside a Tensor processing unit.

01:42:27.822 --> 01:42:30.532
The point I want to make is if 
you look at what uses up the 

01:42:30.533 --> 01:42:34.209
silicone area, notice it's not 
used for a lot of control.  It's

01:42:34.210 --> 01:42:36.210
not used for a lot of caching.  
It's used to do things that are 

01:42:37.060 --> 01:42:39.060
directly relevant to the 
computation.

01:42:42.582 --> 01:42:44.582
So, this processor do 256 by 
256.

01:42:49.525 --> 01:42:51.573
That is 64,000 multiply 
accumulates, eight-bit multiply 

01:42:51.574 --> 01:42:53.574
accumulates every single clock.

01:42:56.840 --> 01:42:58.840
Every single clock

01:43:01.963 --> 01:43:03.787
so really interesting things, 
enormous amount of  

01:43:03.788 --> 01:43:05.788
computational capability.

01:43:07.060 --> 01:43:09.060
You're not going to run general 
C code 

01:43:10.064 --> 01:43:12.064
on this

01:43:34.348 --> 01:43:35.985
.  So what we've plotted here is
performance per watt and you can

01:43:35.986 --> 01:43:37.986
see 

01:43:40.879 --> 01:43:42.560
that the first generation gets 
30 times per watt compared to a 

01:43:42.561 --> 01:43:44.801
general purpose processor.  It 
even does considerably better 

01:43:44.802 --> 01:43:46.802
than 

01:43:48.939 --> 01:43:50.156
a GPU largely by switching from 
floating point to lower density 

01:43:50.157 --> 01:43:53.619
energy, which is much faster.  
So, again, this notion of  

01:43:53.620 --> 01:43:55.620
tailoring the architecture to 
the specific domain 

01:43:59.124 --> 01:44:03.641
becomes really crucial.
So, this is a new era.  In some 

01:44:03.642 --> 01:44:06.278
sense, it's a return to the 
past.  In the early days of 

01:44:06.279 --> 01:44:08.279
computing, as 

01:44:09.553 --> 01:44:11.992
computers were just being 
developed, we often had teams of

01:44:11.993 --> 01:44:14.061
people working together.  We had
people who were early 

01:44:15.675 --> 01:44:17.119
applications experts working 
with people who were doing the 

01:44:17.120 --> 01:44:19.120
beginning of the software 
environment, building the first 

01:44:20.182 --> 01:44:22.227
compilers and the first software
environment and people doing the

01:44:25.695 --> 01:44:27.695
architecture

01:44:35.774 --> 01:44:36.572
and they're working as a 
vertical team.  That kind of 

01:44:36.573 --> 01:44:38.408
integration where we get a 
design team to go from 

01:44:38.409 --> 01:44:41.046
replication of some specific 
language to architecture and can

01:44:41.047 --> 01:44:42.473
think about how to rebuild 
machines in new ways to get 

01:44:42.474 --> 01:44:47.624
this.  It's an enormous 
opportunity and it's a new kind 

01:44:47.625 --> 01:44:49.625
of challenge for the industry 

01:44:50.837 --> 01:44:52.837
to go forward

01:44:59.684 --> 01:45:01.123
but I think there are enough 
interesting applications where 

01:45:01.124 --> 01:45:05.005
we can get incredible advantages
by tailoring our machine in new 

01:45:05.006 --> 01:45:07.870
ways and I think if we can do 
that maybe we'll free up some 

01:45:10.308 --> 01:45:12.760
time to worry about another 
problem, namely cybersecurity 

01:45:12.761 --> 01:45:16.702
and whether or not the hardware 
designers can finally help the 

01:45:16.703 --> 01:45:17.914
software designers to improve 
the security of our system, and 

01:45:17.915 --> 01:45:20.370
that would be a great problem to
focus on.  Thank you for your 

01:45:20.371 --> 01:45:22.371
attention and I'm happy to 
answer any questions you might 

01:45:22.407 --> 01:45:24.407
have
(applause)

01:45:25.877 --> 01:45:27.877
Thanks.

01:45:34.423 --> 01:45:39.334
Okay. Who's got a question?  You
can ask me anything.  I've done 

01:45:39.335 --> 01:45:41.335
this a lot.

01:45:52.674 --> 01:45:54.674
No questions?

01:45:57.172 --> 01:45:59.172
&gt;&gt; Hi.

01:46:02.328 --> 01:46:06.128
Can you talk about some of the 
advantages in quantum and 

01:46:02.328 --> 01:46:06.343
neomorphic computing?
&gt;&gt; JOHN HENNESSY: Yeah, so 

01:46:06.344 --> 01:46:09.465
quantum, that's a really good 
question.  My view is that we've

01:46:09.466 --> 01:46:13.981
got to build a bridge from where
we are today to post silicone.  

01:46:13.982 --> 01:46:15.017
The possibilities for post 
silicone, the two big, there are

01:46:15.018 --> 01:46:19.714
a couple.  I mean, there's 
organic, there's quantum, 

01:46:19.715 --> 01:46:21.957
there's carbon nano fiber, 
there's a few different 

01:46:21.958 --> 01:46:24.957
possibilities out there

01:46:56.400 --> 01:46:58.234
[N][F][N] the reason being, that
might take you a thousand 

01:46:58.235 --> 01:47:00.270
cubits.  Bit computational power
for things 

01:47:03.993 --> 01:47:06.841
that make sense, protein folder,
cryptography of 128 bit cubit is

01:47:09.288 --> 01:47:12.230
phenomenal so we could get an 
enormous jump forward there.  We

01:47:12.231 --> 01:47:14.280
need something post silicone.  
We need something post silicone.

01:47:17.132 --> 01:47:19.161
Maybe as Moore's Law slows down,
maybe another decade or so 

01:47:19.162 --> 01:47:21.201
before it comes to a real halt 
and we've got to get an 

01:47:22.211 --> 01:47:24.259
alternative technology out there
because I think there's lots of 

01:47:24.260 --> 01:47:27.550
creative software to be written 
that wants to run on faster 

01:47:27.551 --> 01:47:29.551
machines.

01:47:35.124 --> 01:47:39.420
&gt;&gt; At the end of your 
presentation, you briefly 

01:47:39.421 --> 01:47:42.270
mentioned how we could start 
using hardware to increase 

01:47:42.271 --> 01:47:44.108
security.  Would you mind 
elaborating?

01:47:44.109 --> 01:47:48.986
&gt;&gt; JOHN HENNESSY: Sure.  So 
here's my view of security.  

01:47:48.987 --> 01:47:51.238
Everybody knows about meltdown 
and specter.  The efficiency 

01:47:51.239 --> 01:47:53.239
thing to understand what 
happened is an attack that 

01:47:54.499 --> 01:47:56.499
basically undermined 
architecture in a 

01:47:58.729 --> 01:48:00.729
way that we

01:48:20.764 --> 01:48:21.782
.  I worked on that since the 
mid 1990s and we didn't even 

01:48:21.783 --> 01:48:26.450
know it.  Programs run, I don't 
fell telo how fast they run.  

01:48:26.451 --> 01:48:28.738
All I tell you is what the right
answer is.  Side channel attacks

01:48:28.739 --> 01:48:31.388
that use performance to leak 
information basically go around 

01:48:31.389 --> 01:48:33.389
our definition of architecture 
so we need to rethink about 

01:48:33.649 --> 01:48:35.649
architecture.

01:48:37.092 --> 01:48:38.321
You know, in the 1960s and 
1970s, there was a lot of 

01:48:38.322 --> 01:48:42.386
thought about how to do a better
job of protection.  Rings and 

01:48:42.387 --> 01:48:44.470
domains and capabilities.  They 
all got dropped and they got 

01:48:45.477 --> 01:48:47.316
dropped because two things.  
First of all, we became 

01:48:47.317 --> 01:48:51.192
convinced that people were going
to verify their software and it 

01:48:51.193 --> 01:48:53.193
was always going to be perfect.

01:48:54.857 --> 01:48:59.352
well the problem is the amount 
of software we write is far 

01:48:59.353 --> 01:49:01.353
bigger than the aments of 
software we verify, so that's 

01:49:02.199 --> 01:49:04.199
not going to help.

01:49:06.022 --> 01:49:08.022
[N][F][N]

01:49:12.470 --> 01:49:14.723
I think it's time for software 
accurate protects to think 

01:49:14.724 --> 01:49:16.724
about, how can they build 
systems to ensure the right 

01:49:16.945 --> 01:49:18.945
support?  How do we build those?

01:49:21.460 --> 01:49:22.912
How do we make sure they build 
systems effectively and how do 

01:49:22.913 --> 01:49:27.237
we work together to create a 
more secure environment and I 

01:49:27.238 --> 01:49:29.076
think it's going to mean 
thinking back on some of those 

01:49:29.077 --> 01:49:31.077
old ideas and bring them back in
some cases.

01:49:33.995 --> 01:49:35.839
&gt;&gt; After I took my processor 
architecture class which used 

01:49:35.840 --> 01:49:37.668
your book --
&gt;&gt; JOHN HENNESSY: I hope it 

01:49:37.669 --> 01:49:39.669
didn't hurt you.
(laughter)

01:49:39.701 --> 01:49:44.394
&gt;&gt; Hopefully not.  I had a real 
appreciation for the simplicity 

01:49:44.395 --> 01:49:46.395
of a risk system.

01:49:47.450 --> 01:49:48.672
It seems like we've gone towards
more complexity with 

01:49:48.673 --> 01:49:50.689
domain-specific languages and 
things.  Is that just because of

01:49:50.690 --> 01:49:53.399
performance or has your 
philosophy changes?  What do you

01:49:53.400 --> 01:49:54.403
think?
&gt;&gt; JOHN HENNESSY: No, I actually

01:49:54.404 --> 01:49:56.404
think 

01:49:58.833 --> 01:50:00.833
they're not necessarily

01:50:04.677 --> 01:50:07.383
more complicated.  They have a 
narrower range of applicability.

01:50:07.977 --> 01:50:10.833
But they're not more 
applicabilitied in the sense 

01:50:10.834 --> 01:50:18.003
that they're a better match for 
what the application is.  The 

01:50:18.004 --> 01:50:19.653
key thing is we weren't 
targeting people writing 

01:50:19.654 --> 01:50:21.703
assembly language anymore.  That
was the old way of doing things,

01:50:22.108 --> 01:50:27.245
right?  In the 1980s, the move 
was on.  Unix was the first 

01:50:27.246 --> 01:50:29.071
operating system ever written in
a high level language.  The 

01:50:29.072 --> 01:50:32.527
first ever.  The move was on 
from assembly language to high 

01:50:32.528 --> 01:50:34.780
level languages and what you 
needed to target was the 

01:50:34.781 --> 01:50:36.781
compiler output so it's the same
thing here.

01:50:39.462 --> 01:50:41.092
You're targeting the output of a
domain-specific language that 

01:50:41.093 --> 01:50:44.979
works well for a range of 
domains and you design the 

01:50:44.980 --> 01:50:47.645
architecture to match that  
environment.  Make it as simple 

01:50:47.646 --> 01:50:49.679
as possible, but no simpler.

01:50:53.402 --> 01:50:54.850
&gt;&gt; With the domain-specific 
architectures, do you have 

01:50:54.851 --> 01:50:56.851
examples of 

01:50:57.975 --> 01:50:59.975
what might be the most promising
areas 

01:51:01.652 --> 01:51:03.652
for future domain-specific 
architectures?

01:51:05.545 --> 01:51:07.793
&gt;&gt; JOHN HENNESSY: So I this I 
the most obvious ones are things

01:51:07.794 --> 01:51:12.272
related to machine learning, 
computations both training as 

01:51:12.273 --> 01:51:14.273
well as inference, so that's one
big field.

01:51:17.315 --> 01:51:19.315
Virtual reality

01:51:35.369 --> 01:51:37.369
, if we really want to construct
well 

01:51:40.403 --> 01:51:42.403
made augmented reality, it's a 
complex structure.

01:51:45.224 --> 01:51:48.690
They're going to give us a list 
on some of the most 

01:51:45.224 --> 01:51:46.192
computationally intensive 
problems.  We're still going to 

01:51:46.193 --> 01:51:48.193
have to advance and think about 
how to push forward 

01:51:51.098 --> 01:51:51.144
general purpose because the 
general purpose machines are 

01:51:51.145 --> 01:51:55.353
going to drive these domain 
specific machines.  The domain 

01:51:55.354 --> 01:51:55.493
specific machine will not do 
everything for us so we're going

01:51:55.494 --> 01:51:57.494
to have to figure out ways to go
forward on that front as well.

01:52:00.636 --> 01:52:03.683
&gt;&gt; How do you think about some 
emerging memory technology?  How

01:52:03.684 --> 01:52:04.698
will it impact the future of 
computer architecture?  Thank 

01:52:04.699 --> 01:52:05.721
you.
&gt;&gt; JOHN HENNESSY: That's a 

01:52:05.722 --> 01:52:07.722
really great question.

01:52:09.594 --> 01:52:11.433
So, as we get to the end of 
DRAMs, I think some of the more 

01:52:11.434 --> 01:52:14.299
innovative memory technologies 
are beginning to appear.

01:52:19.043 --> 01:52:20.466
So-called phase change 
technologies which had the 

01:52:20.467 --> 01:52:22.467
advantage that they can probably
scale better than DRAM, and 

01:52:24.782 --> 01:52:27.019
probably even better than flash 
technologies.  They have the 

01:52:27.020 --> 01:52:29.458
advantage that lifetimes are 
better, too, than flash.

01:52:34.005 --> 01:52:36.005
The problem with flash is it 
runs out.

01:52:37.890 --> 01:52:39.558
Some of these phase chain or mem
risk technologies have the 

01:52:39.559 --> 01:52:42.605
ability to scale longer and what
you'll get is probably not a 

01:52:42.606 --> 01:52:44.636
replacement for DRAM.  You'll 
probably get a replacement for 

01:52:46.932 --> 01:52:48.356
flash and a replacement for 
disks and I think that 

01:52:48.357 --> 01:52:50.357
technology is coming very fast, 
and it will change the way we 

01:52:53.481 --> 01:52:56.396
think about memory hierarchies 
and I/O hierarchy because you'll

01:52:56.397 --> 01:52:58.397
have a device that's not quite 
as fast as DRAM but a 

01:53:02.266 --> 01:53:03.953
lot faster than the other 
alternatives and that will 

01:53:03.954 --> 01:53:06.201
change the way we want to build 
machines.

01:53:09.859 --> 01:53:11.859
&gt;&gt; As a person, you think about 
education quite often.

01:53:14.708 --> 01:53:17.041
We all saw Zuckerberg having a 
conversation with 

01:53:22.086 --> 01:53:24.030
Congress, and I'm excited to see
children getting general 

01:53:24.031 --> 01:53:26.031
education around computing and 
coding which is 

01:53:28.443 --> 01:53:30.445
something that a lot of us 
didn't have the opportunity to 

01:53:30.446 --> 01:53:32.516
have.  Where do you see 
education, not only 

01:53:36.808 --> 01:53:38.808
for K12 grad, post-grad, et 
cetera, but 

01:53:39.894 --> 01:53:42.135
also existing people in 
policy-making decisions, et 

01:53:42.136 --> 01:53:43.964
cetera?
&gt;&gt; JOHN HENNESSY: Well, I think 

01:53:43.965 --> 01:53:49.047
first of all, education has 
become a life-long endeavor.  

01:53:49.048 --> 01:53:50.894
Nobody has one job for a 
lifetime anymore.  They change 

01:53:50.895 --> 01:53:54.365
what they're doing, and 
education becomes constant.  I 

01:53:54.366 --> 01:53:56.610
mean, you think about the stuff 
you learned as an undergrad and 

01:53:56.611 --> 01:54:00.116
you think about how far, how 
much technology has already 

01:54:00.117 --> 01:54:02.117
changed, right?  So we have to 
do more there.

01:54:04.840 --> 01:54:06.451
I think we also have to make 
more, technology, society needs 

01:54:06.452 --> 01:54:08.452
to be more technology-savvy.

01:54:12.576 --> 01:54:13.800
Computing is changing every 
single part of the world we live

01:54:13.801 --> 01:54:15.801
in.

01:54:18.414 --> 01:54:23.019
To not have some understanding I
think limits your ability to 

01:54:23.020 --> 01:54:25.085
lead an organization, to make 
decisions.  So we're going to 

01:54:25.086 --> 01:54:28.561
have to educate our young people
at beginning and we're going to 

01:54:28.562 --> 01:54:30.390
have to make an investment in 
education so that as people's 

01:54:30.391 --> 01:54:32.391
careers change over their 
lifetime they can go 

01:54:36.498 --> 01:54:38.498
back and engage in education

01:54:43.910 --> 01:54:45.128
.  Not necessarily going back to
college, but it's going to have 

01:54:45.129 --> 01:54:47.181
to be engaging, something that 
works well for people.

01:54:50.644 --> 01:54:52.477
&gt;&gt; Hi, from BBC, just wondered 
what your view was on the amount

01:54:52.478 --> 01:54:54.478
of energy being 

01:54:55.571 --> 01:54:57.808
used on bitcoin mining and other
crypts owe currencies and that 

01:54:57.809 --> 01:55:00.653
sort of thing.
&gt;&gt; JOHN HENNESSY: Yeah, sure.  I

01:55:00.654 --> 01:55:04.335
could build a special purpose 
architecture to mine.s.  That's 

01:55:04.336 --> 01:55:05.766
another obvious example of a 
domain specific architecture for

01:55:05.767 --> 01:55:07.767
sure.

01:55:09.986 --> 01:55:11.986
So,

01:55:14.312 --> 01:55:16.956
I'm a long term believer in 
cryptocurrency as an important 

01:55:16.957 --> 01:55:20.847
part of my space and what we're 
going to have to do is figure 

01:55:20.848 --> 01:55:22.848
out how to make it work, 

01:55:24.324 --> 01:55:26.607
how to make it work efficiently,
how to make it work seamlessly, 

01:55:26.608 --> 01:55:29.290
how to make it work 
inexpensively.  I think those 

01:55:29.291 --> 01:55:31.393
are all problems that can be 
conquered an I think you'll see 

01:55:31.394 --> 01:55:33.394
a 

01:55:35.263 --> 01:55:37.263
bunch of people that have both 
the 

01:55:38.265 --> 01:55:40.614
algorithmic heft and the ability
to rethink how we do that, and 

01:55:43.684 --> 01:55:45.306
really make cryptocurrencies go 
quite quick and then we can also

01:55:45.307 --> 01:55:49.192
build machines which accelerate 
that even further.  A 

01:55:49.193 --> 01:55:51.193
cryptocurrency transaction 
should be 

01:55:52.469 --> 01:55:54.584
faster than a cash transaction, 
and certainly no slower than a 

01:55:54.585 --> 01:55:56.900
credit card transaction.  We're 
not there yet, but we could get 

01:55:58.363 --> 01:55:59.402
there with enough work and I 
think that's where we ought to 

01:55:59.403 --> 01:56:01.403
be moving to.

01:56:04.261 --> 01:56:06.261
&gt;&gt; What do you think bets

01:56:13.065 --> 01:56:15.065
the future of operating system 
has to have.

01:56:15.940 --> 01:56:16.945
&gt;&gt; JOHN HENNESSY: So I think 
operating systems are really 

01:56:16.946 --> 01:56:19.815
crucial.  Way back when in the 
1980s we thought 

01:56:22.911 --> 01:56:24.911
we were going to solve all our 
operating 

01:56:26.806 --> 01:56:28.630
system problems by going to 
kernel based operating systems 

01:56:28.631 --> 01:56:30.631
and the kernel would be this 
really small thing that just did

01:56:31.679 --> 01:56:32.897
the core of protection and 
memory management and then 

01:56:32.898 --> 01:56:36.226
everything else around it would 
be protected, basically.  And 

01:56:36.227 --> 01:56:37.450
what happened was kernel started
out really small and then they 

01:56:37.451 --> 01:56:41.936
got bigger and then they got 
bigger and then they got bigger 

01:56:41.937 --> 01:56:43.996
and all of a sudden almost the 
entire operating system was 

01:56:47.248 --> 01:56:49.248
in the kernel, primarily to make
it performance-efficient.

01:56:52.943 --> 01:56:56.682
And the same thing happened with
hyper visors.  They started 

01:56:56.683 --> 01:56:59.768
really small in the beginning 
and got bigger.  We're going to 

01:56:59.769 --> 01:57:01.022
have to figure out how we 
structure complex operating 

01:57:01.023 --> 01:57:04.318
systems so they can deal with 
the protection issues, they can 

01:57:04.319 --> 01:57:07.194
deal with efficiency issues, 
they can work well.  We should 

01:57:07.195 --> 01:57:09.871
be building operating systems 
which, from the beginning, 

01:57:11.711 --> 01:57:13.741
realize that they're going to 
run on large numbers of 

01:57:13.742 --> 01:57:16.637
processors and organize them in 
such a way that they can do that

01:57:17.645 --> 01:57:19.896
efficiently because that's the 
future.  We're going to have to 

01:57:19.897 --> 01:57:21.897
rely on that.

01:57:25.028 --> 01:57:27.461
&gt;&gt; In your intro video you 
mentioned this chasm between 

01:57:27.462 --> 01:57:31.984
concept and practice and also in
your talk you've mentioned that 

01:57:31.985 --> 01:57:33.985
hardware is vital to the future 
of computing.

01:57:36.521 --> 01:57:38.767
Given that most investors are 
very hardware averse, especially

01:57:38.768 --> 01:57:42.431
this day in age, where do you 
expect that money to come from? 

01:57:42.432 --> 01:57:44.073
Is that something that will come
from governments or private 

01:57:44.074 --> 01:57:49.173
investing?  How are we going to 
fund the future of computing is 

01:57:49.174 --> 01:57:50.794
really what my question is?
&gt;&gt; JOHN HENNESSY: Yeah. it's a 

01:57:50.795 --> 01:57:53.479
good question.  I mean, I think 
the answer is both.

01:57:58.353 --> 01:57:59.977
You know, certainly Google is 
making large investments in a 

01:57:59.978 --> 01:58:03.434
lots of these technologies from 
quantum to other thing has.  I 

01:58:03.435 --> 01:58:05.684
think government remains a 
player.  So, government, you 

01:58:05.685 --> 01:58:07.685
look at how many of the 
innovations we're used to.

01:58:10.207 --> 01:58:12.207
The internet, risk, the rise of 
VLSI, 

01:58:13.217 --> 01:58:16.744
modern computerated design tools
of we all had funding basically 

01:58:16.745 --> 01:58:19.409
coming from the government at 
some point.  So I think the 

01:58:19.410 --> 01:58:23.733
government should still remain a
player in thinking about, what's

01:58:23.734 --> 01:58:25.975
the one area the government has 
probably funded longer than 

01:58:25.976 --> 01:58:27.976
anybody else?  Artificial 
intelligence.

01:58:31.662 --> 01:58:33.662
They funded it for 50 years

01:58:51.819 --> 01:58:53.445
.  So we're going to have to 
have that and we're going to 

01:58:53.446 --> 01:58:57.311
have to have industry as well.  
They compliment each other.  

01:58:57.312 --> 01:58:59.977
They do two different things but
they're complementary and if we 

01:58:59.978 --> 01:59:03.231
can get them to work well then 
we're going to have the best of 

01:59:03.232 --> 01:59:05.699
both worlds.
&gt;&gt; You talked a little bit about

01:59:05.700 --> 01:59:09.381
the difference between memory 
hierarchy and storage that is 

01:59:09.382 --> 01:59:12.226
coming up with these new memory 
technologies.  Have you seen any

01:59:12.227 --> 01:59:14.227
applications where 

01:59:17.122 --> 01:59:18.570
the compute and the storage get 
combined kind of more like the 

01:59:18.571 --> 01:59:21.009
brain?
&gt;&gt; JOHN HENNESSY: Yeah, I think 

01:59:23.049 --> 01:59:24.061
increasingly we'll see things 
manufacture towards that 

01:59:24.062 --> 01:59:26.062
direction where 

01:59:29.126 --> 01:59:31.096
you, the software takes care of 
the difference between what is 

01:59:31.097 --> 01:59:35.602
in storage, quote, unquote 
because it may actually be flash

01:59:35.603 --> 01:59:37.684
or some kind of next generation 
memory technology, and what's in

01:59:37.685 --> 01:59:39.943
DRAM.  What you need to tell me 
is, what's 

01:59:43.004 --> 01:59:45.469
volatile and when do I have to 
ensure that a particular 

01:59:45.470 --> 01:59:49.356
operation is committed to 
nonvolatile storage?  But, if 

01:59:49.357 --> 01:59:51.357
you know that, you know, we've 

01:59:52.458 --> 01:59:53.676
got log-based file systems, 
you've got other ideas which 

01:59:53.677 --> 01:59:55.677
move in the direction 

01:59:57.981 --> 01:59:59.981
of trying to take advantage of a
much, 

02:00:01.036 --> 02:00:03.503
greatly different memory 
hierarchy, greatly different 

02:00:03.504 --> 02:00:05.504
storage hierarchy than we're 
used to and we may want to 

02:00:06.003 --> 02:00:07.422
continue in that direction.  
Particularly when you begin to 

02:00:07.423 --> 02:00:09.506
think about, if you think about 
things like 

02:00:12.807 --> 02:00:14.843
networking or I/O, and they 
become major bottle necks in 

02:00:14.844 --> 02:00:16.844
applications, which they 

02:00:18.299 --> 02:00:20.942
often do, then rethinking how we
could do those efficiently and 

02:00:20.943 --> 02:00:24.223
optimize the hardware, but also 
the software because the minute 

02:00:24.224 --> 02:00:26.065
you stick an operating system 
transaction in there, you've 

02:00:26.066 --> 02:00:29.170
added a lot of weight to what it
costs to get to that storage 

02:00:29.171 --> 02:00:33.884
facility.  So, if we can make 
that work better and make it 

02:00:33.885 --> 02:00:35.885
more transparent without giving 
up protection, without giving up

02:00:37.202 --> 02:00:39.202
a guarantee that once something 
is 

02:00:40.441 --> 02:00:41.669
written to a certain storage 
unit, it's permanently recorded,

02:00:41.670 --> 02:00:46.224
then I think we could make much 
faster systems.

02:00:48.257 --> 02:00:50.696
&gt;&gt; So, do you see the 
implementation of a 

02:00:50.697 --> 02:00:52.697
domain-specific architecture 
being 

02:00:53.972 --> 02:00:55.972
implemented as heterotype or do 
you see 

02:00:57.025 --> 02:00:58.461
it off die, off chip type 
implementations or both?

02:00:58.462 --> 02:01:00.294
&gt;&gt; JOHN HENNESSY: I think both. 
I think it's a time of great 

02:01:00.295 --> 02:01:02.295
change.

02:01:04.199 --> 02:01:05.609
The rise of FPGAs, for example, 
give you the opportunity to 

02:01:05.610 --> 02:01:09.300
implement these machines, try 
them out.  Implement them in 

02:01:09.301 --> 02:01:11.301
FPGA before you're 

02:01:12.376 --> 02:01:14.376
committed to design a custom 
silicone 

02:01:15.631 --> 02:01:18.490
chip, put it in FPGA, unleash it
on the world, try it out, see 

02:01:18.491 --> 02:01:20.528
how it works, see how the 
applications map to it and then 

02:01:21.350 --> 02:01:22.381
perhaps decide whether or not 
you want to freeze the 

02:01:22.382 --> 02:01:26.691
architecture.  Or you may just 
want to build another next 

02:01:26.692 --> 02:01:28.348
generation FPGA so I think we'll
see lots of different 

02:01:28.349 --> 02:01:30.597
implementation approaches.
The one thing we have to do, you

02:01:30.598 --> 02:01:34.081
know, there was a big break 
through in how hard it was to 

02:01:34.082 --> 02:01:36.082
design chips that 

02:01:38.633 --> 02:01:42.480
occurred from about the mid-80s 
to about 1995 or 2000.  Things 

02:01:42.481 --> 02:01:44.547
have kind of ground to a halt 
since then of the we need a big 

02:01:44.548 --> 02:01:48.610
break through because we're 
going to need many more people 

02:01:48.611 --> 02:01:51.867
designing processors, targeting 
particular application domains. 

02:01:51.868 --> 02:01:54.161
And that's going to mean we need
to make it much easier and much 

02:01:54.162 --> 02:01:57.680
cheaper to design a processor.
&gt;&gt; I'm wondering as a deep 

02:01:57.681 --> 02:02:03.236
learning engineer, for private 
enterprise, what is my role in 

02:02:03.237 --> 02:02:05.280
pushing forward DSA.
&gt;&gt; JOHN HENNESSY: Yeah, well, I 

02:02:05.281 --> 02:02:10.205
think your role is vital because
we need people who really 

02:02:10.206 --> 02:02:14.636
understand the application space
and that's really critical.  And

02:02:14.637 --> 02:02:16.637
this is a change.

02:02:19.680 --> 02:02:21.989
I mean, if you think about how 
much architects and computer 

02:02:23.224 --> 02:02:24.439
designers had to think about the
applications, they haven't had 

02:02:24.440 --> 02:02:28.553
to think about them.  All of a 
sudden they're going to have to 

02:02:28.554 --> 02:02:30.381
develop a bunch of new friends 
that they can interact with and 

02:02:30.382 --> 02:02:34.085
colleagues they can work with to
really get the insights they 

02:02:34.086 --> 02:02:36.928
need in order to push forward 
the technology.  And that's 

02:02:36.929 --> 02:02:38.929
going to have -- that's going to
be a big change for us but I 

02:02:40.828 --> 02:02:42.828
think it's something that's 
absolutely 

02:02:44.085 --> 02:02:46.323
crucial and it's great for the 
industry too because all of a 

02:02:46.324 --> 02:02:50.214
sudden we get people who are 
application experts beginning to

02:02:50.215 --> 02:02:53.474
talk to people who are software 
architects, who talk to hardware

02:02:53.475 --> 02:02:55.475
people.  That's a terrific 
thing.

02:02:58.199 --> 02:03:00.430
&gt;&gt; You mentioned performance 
over domain specific languages 

02:03:00.431 --> 02:03:04.739
like python but they're also 
much harder to use, so do you 

02:03:04.740 --> 02:03:05.748
think software engineering 
talent can keep up in the 

02:03:05.749 --> 02:03:07.797
future?
&gt;&gt; JOHN HENNESSY: Yeah, I think 

02:03:07.798 --> 02:03:11.462
the challenge will be the gain 
we've gotten in software 

02:03:11.463 --> 02:03:13.943
productivity in the last 20, 30 
years is absolutely stunning.  

02:03:13.944 --> 02:03:15.944
It is absolute stunning.

02:03:17.028 --> 02:03:19.284
I mean a programmer now can 
probably write ten to 100 times 

02:03:19.285 --> 02:03:21.336
more code than they could 30 
years ago in terms of 

02:03:21.741 --> 02:03:24.428
functionality.  That's 
phenomenal.  We cannot give that

02:03:24.429 --> 02:03:27.892
up.  Because that's what's 
created all these incredible 

02:03:27.893 --> 02:03:30.398
applications we have.  What we 
need to do is figure out all 

02:03:33.874 --> 02:03:35.500
of a sudden we need a new 
generation of compiler people to

02:03:35.501 --> 02:03:39.199
think about how do we make those
run efficiently?  And by the 

02:03:39.200 --> 02:03:41.200
way, if the gap is a factor 

02:03:42.907 --> 02:03:44.339
of 25 between C and python, for 
example, if you get only half 

02:03:44.340 --> 02:03:49.457
that, that's a factor of 12 
times faster.  Any compiler 

02:03:49.458 --> 02:03:52.134
writer that can produce code 
that runs 12 times faster is a 

02:03:52.135 --> 02:03:54.984
hero in my book so we have to 
just think about new ways to 

02:03:54.985 --> 02:03:58.455
approach the problem and the 
opportunity is tremendous.

02:04:01.300 --> 02:04:03.300
&gt;&gt; Are there any opportunities 
still 

02:04:04.756 --> 02:04:06.756
left in X86 as far as like 
lifting the 

02:04:09.293 --> 02:04:11.728
complexity of DISA in the 
software and exposing more 

02:04:11.729 --> 02:04:12.948
microinfrastructure to the 
compiler?

02:04:12.949 --> 02:04:15.790
&gt;&gt; JOHN HENNESSY: It's tough.  I
mean, I think the Intel people 

02:04:15.791 --> 02:04:20.894
have spent more time 
implementing X86s than anybody 

02:04:20.895 --> 02:04:25.383
has ever spent implementing 
1ISA, one instruction set ever. 

02:04:25.384 --> 02:04:27.841
They've mined out almost all the
performance.  And in fact, if 

02:04:27.842 --> 02:04:29.842
you look at tweaks 

02:04:31.095 --> 02:04:33.095
that occur, for example, they do

02:04:34.179 --> 02:04:36.430
aggressive prefetching in the i7
but you look at what happens 

02:04:36.431 --> 02:04:38.431
with refreshing, 

02:04:41.681 --> 02:04:43.681
some programs actually slow down

02:04:51.673 --> 02:04:54.127
.  Now on balance, they get a 
limb bit of speed-up but they 

02:04:54.128 --> 02:04:58.459
get a little bit of slow down in
other applications.  The 

02:04:58.460 --> 02:05:00.903
balance, we don't get slow down 
on other things.  I see my 

02:05:00.904 --> 02:05:03.350
producer telling me it's the end
of session.  Thank you for your 

02:05:03.351 --> 02:05:04.398
great questions and for your 
attention

02:05:04.399 --> 02:05:06.399
(applause)

02:05:07.462 --> 02:05:08.271
(Session was concluded at 12:13 
PM CT)

02:05:08.272 --> 02:05:10.605
***
This text, document, or file is 

02:05:08.272 --> 02:05:12.272
based on live transcription.  
Communication Access Realtime 

02:05:08.272 --> 02:05:12.405
Translation (CART), captioning, 
and/or live transcription are 

02:05:08.272 --> 02:05:11.272
provided in order to facilitate 
communication

02:05:08.272 --> 02:05:12.405
accessibility and may not be a 
totally verbatim record of the 

02:05:08.272 --> 02:05:12.005
proceedings.  This text, 
document, or file is not to be 

02:05:08.272 --> 02:05:12.405
distributed or used in any way 
that may violate copyright law.

02:05:08.272 --> 02:05:11.129
***

02:05:20.761 --> 02:05:22.761
REALTIME CAPTIONING ON THIS 
SCREEN

02:10:57.560 --> 02:10:59.560
GOOGLE I/O 2018
MOUNTAIN VIEW, CALIFORNIA

02:11:01.206 --> 02:11:03.206
MAY 10, 2018
STAGE 2

02:11:05.918 --> 02:11:07.918
10:30 AM

02:11:09.815 --> 02:11:11.845
ANDROID JETPACK: SWEETENING COIN
DEVELOPMENT WITH ANDROID KTX

02:11:18.529 --> 02:11:20.529
T1260D

02:22:29.904 --> 02:22:31.904
(APPLAUSE)

02:22:33.978 --> 02:22:35.978
&gt;&gt; JAKE WHARTON: Hi, everyone.  
My name is Jake.

02:22:37.848 --> 02:22:39.848
I work on the Android team on 
Kotlin stuff.

02:22:41.159 --> 02:22:43.195
So, today, I'm going to be 
talking about Android KTX.  And 

02:22:43.196 --> 02:22:45.453
I'm not going to be talking 
about, I'm not going to be just 

02:22:45.454 --> 02:22:49.127
going over a bunch of the stuff 
that's in there.  I want to make

02:22:49.128 --> 02:22:52.198
it a little more interesting 
than that, so I'm going to start

02:22:52.199 --> 02:22:53.626
with a little bit of what 
happened last year at Google 

02:22:53.627 --> 02:22:55.627
I/O.  I was here last year, 
talking about 

02:22:59.141 --> 02:23:01.202
how you can write extensions 
extensions for Android types 

02:23:01.203 --> 02:23:03.551
such as this example where we 
have code that iterates over 

02:23:08.564 --> 02:23:10.564
the views inside of a view group

02:23:15.614 --> 02:23:17.846
.  You can pull that common code
out into an extension.  What 

02:23:17.847 --> 02:23:19.672
this extension does is enhance 
the type we don't control, the 

02:23:19.673 --> 02:23:22.969
view type.  We're allowed to 
essentially create a member 

02:23:22.970 --> 02:23:24.970
function that's not actually a 
member function.

02:23:26.871 --> 02:23:28.671
It actually turns into a static 
function in the bite code with 

02:23:28.672 --> 02:23:30.672
the functionality that we want 
to enhance.

02:23:34.574 --> 02:23:36.574
So, we can take our

02:23:42.182 --> 02:23:43.824
original code that had the 
explicit four group in it and 

02:23:43.825 --> 02:23:47.940
use the new member to create 
what we wanted to do.  It is 

02:23:47.941 --> 02:23:49.941
actually distinguished between a

02:23:51.865 --> 02:23:54.307
normal member function that it's
italicized.  If you use dark 

02:23:54.308 --> 02:23:58.581
yellow, that will actually be 
yellow but the intent is to feel

02:23:58.582 --> 02:24:00.582
semantically equivalent to a 
member.

02:24:01.228 --> 02:24:02.872
So, oftentimes, when you start 
talking about extension 

02:24:02.873 --> 02:24:04.873
functions, you think, 

02:24:06.535 --> 02:24:08.778
well, if this is so useful why 
don't we just put the function 

02:24:08.779 --> 02:24:12.676
directly on to view group.  Why 
doesn't view group just offer a 

02:24:12.677 --> 02:24:14.677
4H 

02:24:18.131 --> 02:24:20.131
index that takes in a lamb do

02:24:24.108 --> 02:24:26.108
-- lambda.

02:24:28.236 --> 02:24:32.010
Really by default, that eats up 
message and causes -- loading.  

02:24:32.011 --> 02:24:34.491
Kotlin, however, applies 
language functionality which 

02:24:34.492 --> 02:24:37.302
allows us to eliminate that 
lambda's allocation.  By marking

02:24:37.303 --> 02:24:38.955
its function in line, the body 
of the extension gets copied 

02:24:38.956 --> 02:24:42.612
into the call site and we have a
zero overhead extraction.

02:24:48.370 --> 02:24:50.411
Let's take a look at another 
example.  In API 23, we were 

02:24:50.412 --> 02:24:53.454
able to get a system service 
based on a class type, and in 

02:24:53.455 --> 02:24:55.455
27.

02:24:57.942 --> 02:25:00.022
1 of the support libraries, a 
context com pat version of this 

02:25:00.023 --> 02:25:02.023
was added that 

02:25:03.304 --> 02:25:05.758
allowed it to work on all API 
levels.  We can pull this into 

02:25:05.759 --> 02:25:07.759
an extension 

02:25:09.622 --> 02:25:11.052
that is also inline like the 
previous one but doesn't contain

02:25:11.053 --> 02:25:13.053
a lamb bough.

02:25:14.307 --> 02:25:15.536
What this one has that's 
different is something called 

02:25:15.537 --> 02:25:20.851
reF irk.  This is a compiler 
trick that forces the type of 

02:25:20.852 --> 02:25:22.852
information of the generic to be
known at compile time so that it

02:25:24.804 --> 02:25:26.804
can be made available at 
runtime.

02:25:30.046 --> 02:25:32.046
So, this is what allows us to 
take

02:25:39.923 --> 02:25:41.923
what we wore otherwise be 
classifying, 

02:25:44.449 --> 02:25:46.449
we can now pass that on so our 
calling 

02:25:47.694 --> 02:25:49.759
code can be used to pass the 
generic and because it's -- the 

02:25:49.760 --> 02:25:52.214
implementation to be able to 
class that Java.

02:25:55.504 --> 02:25:57.504
So, if we want to update the 
padding of 

02:25:59.993 --> 02:26:01.005
a view, just where we're only 
specifying two of the four 

02:26:01.006 --> 02:26:03.006
parameters.

02:26:04.308 --> 02:26:05.986
In this case, we want to update 
both the left and the right, we 

02:26:05.987 --> 02:26:10.692
have to pull out the existing 
padding from the top and the 

02:26:10.693 --> 02:26:12.693
bottom because Android requires 
you to specify all four.

02:26:14.139 --> 02:26:16.139
This is something that we can 
remedy, 

02:26:19.863 --> 02:26:21.863
again, using an extension 
function

02:26:23.197 --> 02:26:25.197
.  The key here is for each the 

02:26:26.881 --> 02:26:28.311
arguments on that function we 
can define, we're specifying 

02:26:28.312 --> 02:26:31.795
that default and that default 
will be used when value is not 

02:26:31.796 --> 02:26:33.844
provided for had a arguing.  So,
it allows us to take the calling

02:26:36.140 --> 02:26:38.140
code where we're specifying all 
four and 

02:26:39.990 --> 02:26:42.129
now specify them as just 2 but 
the problem here is that we've 

02:26:43.966 --> 02:26:46.002
eliminated two of the arguments,
but since we're only supplying 

02:26:46.003 --> 02:26:50.556
two, Kotlin takes that as 
meaning the first two, and the 

02:26:50.557 --> 02:26:53.212
latter two are the ones where 
the defaults are used.  This is 

02:26:53.213 --> 02:26:55.884
not what we intended.  We 
intended to do left and right, 

02:26:57.307 --> 02:26:59.307
which are the first and third.

02:27:00.987 --> 02:27:03.026
Another language feature comes 
to help here, which is named 

02:27:03.027 --> 02:27:05.027
arguments.  Name parameters, 
rather.

02:27:11.277 --> 02:27:13.300
By specifying the name of the 
parameter, we're able to tell 

02:27:13.301 --> 02:27:15.301
the compiler which of the

02:27:22.229 --> 02:27:25.187
the others two arguments we're 
specifying, and allowing it to 

02:27:25.188 --> 02:27:29.256
fill in the default for .  Okay.
Android APIs have a bunch of 

02:27:29.257 --> 02:27:31.257
composite types.

02:27:32.522 --> 02:27:35.521
These are things like point, 
rectangle,

02:27:40.063 --> 02:27:42.100
pear, even the location class.  
In this case, I'm calling an API

02:27:42.101 --> 02:27:46.160
which has a rectangle which is a
composite around the left right 

02:27:46.161 --> 02:27:49.655
top and bottom values of a 
rectangle.  And if you need to 

02:27:49.656 --> 02:27:54.138
do calculations based on the 
value inside of these composite 

02:27:54.139 --> 02:27:56.139
types, you have to pull them 

02:27:57.630 --> 02:27:59.630
out into individual values or 
variables.

02:28:01.122 --> 02:28:03.766
In order to do that calculation,
and then potentially, put them 

02:28:03.767 --> 02:28:05.767
all back together.

02:28:07.829 --> 02:28:12.092
So, with the help of the 
extension, we can avoid this.  

02:28:12.093 --> 02:28:14.779
This one is a little bit 
different.  We have a new key 

02:28:14.780 --> 02:28:17.041
word called an operator.  An 
operator means that Kotlin will 

02:28:20.528 --> 02:28:22.528
allow us to use a special call 
site site 

02:28:23.606 --> 02:28:24.015
syntax, and each operator 
function has a very specific 

02:28:24.016 --> 02:28:27.704
name.  A well-known name.  You 
can't just make up any names.

02:28:31.837 --> 02:28:33.670
And the name defines which call 
site syntax that you're 

02:28:33.671 --> 02:28:37.755
intending to create.  In this 
case, it's called component.  

02:28:37.756 --> 02:28:39.756
And component allows us to use a

02:28:41.224 --> 02:28:43.473
feature of Kotlin called 
restructuring so our original 

02:28:43.474 --> 02:28:45.474
code which had to 

02:28:46.731 --> 02:28:48.731
individually pull out the four 
different 

02:28:50.407 --> 02:28:52.407
components can now use this call
site 

02:28:53.697 --> 02:28:55.529
syntax where the rectangle is 
automatically syntaxed into four

02:28:55.530 --> 02:28:58.597
values and assigned to four 
variables with the names that we

02:28:58.598 --> 02:29:00.437
choose.
What's really nice about this is

02:29:00.438 --> 02:29:02.881
that if you don't care about 
ones later on, you can omit 

02:29:02.882 --> 02:29:06.538
them.  And if you don't care 
about ones in the middle, you 

02:29:06.539 --> 02:29:08.769
can specify them as underscore. 
And so, if we just need to pull 

02:29:08.770 --> 02:29:10.770
out 

02:29:15.346 --> 02:29:17.379
two of the values, we can do 
that very succinctly.

02:29:24.951 --> 02:29:27.816
An experienced Kotlin user might
know that -- well, can we go 

02:29:27.817 --> 02:29:29.817
back a slide?

02:29:43.645 --> 02:29:46.912
Okay. So this is a code that 
determines whether or not we can

02:29:46.913 --> 02:29:49.978
use the string digits.  Sets a 
digit using the character, and 

02:29:52.449 --> 02:29:54.449
then sets a value to default 
whenever it detects a nondigit.

02:29:58.568 --> 02:29:59.985
If you're an experienced Kotlin 
user you might know about the 

02:29:59.986 --> 02:30:01.986
all function 

02:30:03.268 --> 02:30:05.529
which exists on string which 
encapsulates the same looping, 

02:30:05.530 --> 02:30:11.285
allows you to specify predicate,
which in this case, is digit.  

02:30:11.286 --> 02:30:12.909
It's actually an inline function
so it desugars into the exact 

02:30:12.910 --> 02:30:14.910
same thing we would have wrote 
in the previous slide.

02:30:16.989 --> 02:30:18.418
But, what's interesting is that 
Android actually has a built-in 

02:30:18.419 --> 02:30:22.091
function for this and I suspect 
that a lot of people don't 

02:30:22.092 --> 02:30:24.963
actually know this exists.  And 
so, this is something that we 

02:30:24.964 --> 02:30:27.622
can actually take and turn into 
an extension 

02:30:32.327 --> 02:30:33.973
but you have to wonder, is this 
actually worth its weight in an 

02:30:33.974 --> 02:30:38.261
extension.  What value do we 
gain by turning this static 

02:30:38.262 --> 02:30:40.262
method that we can call into an 
extension.

02:30:41.922 --> 02:30:44.369
Well, for one, it changes the 
way that we invoke to feel a lot

02:30:44.370 --> 02:30:48.246
more natural and idiomatic in 
Kotlin, sure.  But, still, is 

02:30:48.247 --> 02:30:50.247
there really value that we 
extract from this?

02:30:53.191 --> 02:30:55.007
The biggest one that I think we 
gain from this is that when 

02:30:55.008 --> 02:30:59.940
you're in the IDE, you have your
string, and you're wanting to go

02:30:59.941 --> 02:31:02.937
and determine whether or not 
it's

02:31:10.013 --> 02:31:14.013
, you're wanting to make this 
query as to whether or not it 

02:31:10.013 --> 02:31:14.039
contains only digits, if you 
didn't know that status on text 

02:31:14.040 --> 02:31:16.864
was there, you probably would 
never find it.  When it's 

02:31:16.865 --> 02:31:18.742
extension, if you start typing 
in the IDE, it will actually 

02:31:18.743 --> 02:31:21.800
show this extension in auto 
complete where it's much more 

02:31:21.801 --> 02:31:23.801
discoverable than otherwise.

02:31:24.882 --> 02:31:26.882
So, you just press enter and you
get it.

02:31:27.750 --> 02:31:30.204
All right, so I covered a few 
extensions here.  I just wanted 

02:31:30.205 --> 02:31:34.733
to remind you a bit of the power
of these extensions.  The fact 

02:31:34.734 --> 02:31:36.734
that we're leveraging language 
features that exist only in 

02:31:38.843 --> 02:31:40.672
Kotlin, not in the Java 
language, and actually some of 

02:31:40.673 --> 02:31:42.906
these examples we're going to 
keep coming back to throughout 

02:31:47.445 --> 02:31:49.445
the rest of this talk

02:31:51.785 --> 02:31:53.785
so all of the extensions that I 
just 

02:31:56.277 --> 02:31:57.711
showed are part of the Android 
KTX file we announced in early 

02:31:57.712 --> 02:32:01.376
February.  There's been two 
releases since then, and as of 

02:32:01.377 --> 02:32:02.804
Tuesday, it's now part of 
Jetpack.  And versioned with 

02:32:02.805 --> 02:32:04.805
Jetpack.

02:32:07.445 --> 02:32:11.686
So, on Tuesday core KTX is now 
1.0 alpha one.  It's going to be

02:32:11.687 --> 02:32:13.687
versioned and 

02:32:16.614 --> 02:32:18.614
released with future Jetpack 
libraries 

02:32:21.351 --> 02:32:22.994
so we called this core KTX when 
we launched which is kind of a 

02:32:22.995 --> 02:32:26.666
weird name, it didn't make 
sense.  This is for extensions, 

02:32:26.667 --> 02:32:28.667
for types only in the framework.

02:32:30.544 --> 02:32:33.417
A lot of people suggested, can 
we add support library stuff and

02:32:33.418 --> 02:32:36.964
we were very adamant about 
saying no.  That should 

02:32:36.965 --> 02:32:39.844
hopefully make a lot more sense 
now but even this isn't exactly 

02:32:43.923 --> 02:32:48.598
true because core KTX initially 
depended on support compat.  

02:32:48.599 --> 02:32:51.597
Support compat is there to 
provide backwards

02:32:55.729 --> 02:32:57.729
compatibility of versions that 
are in the framework.

02:32:59.865 --> 02:33:02.306
That came from support compat so
now with the jet packs reframing

02:33:02.307 --> 02:33:05.182
and the Android X, support 
compat has become 

02:33:09.300 --> 02:33:11.362
core and now core KTX lines up 
with core.  We kind of knew what

02:33:11.363 --> 02:33:15.041
we were doing back when we 
started this and now it's only 

02:33:15.042 --> 02:33:17.076
starting to payoff.
Along with the other Jetpack 

02:33:17.077 --> 02:33:19.077
libraries, 

02:33:20.386 --> 02:33:24.070
there's actually a few new KTX 
libraries launching with it.  We

02:33:24.071 --> 02:33:26.316
have ones for fragment, 
collection, SQL 8, for the newer

02:33:26.317 --> 02:33:28.317
components, navigation and work 
runtime.

02:33:32.448 --> 02:33:34.919
I'm going to touch on how you 
can discover these a bit later 

02:33:34.920 --> 02:33:38.217
but I want to talk a bit about 
scoping about how you determine 

02:33:38.218 --> 02:33:40.218
whether or not something 

02:33:43.328 --> 02:33:45.328
should go into one of these 
libraries.

02:33:55.209 --> 02:33:56.431
All right so in core KTX, 0.3, 
we operated an extension that 

02:33:56.432 --> 02:34:01.168
looks like this.  If you look at
its signal, an operator, it 

02:34:01.169 --> 02:34:03.169
operates on color and the 

02:34:04.267 --> 02:34:07.237
name is plus so this allows us 
to use the

02:34:27.768 --> 02:34:30.439
.  If you look inside support 
compat, there is a color 

02:34:30.440 --> 02:34:34.310
utilities class and that color 
utilities class has a composite 

02:34:34.311 --> 02:34:36.142
colors that allows integer 
colors, allows a background and 

02:34:36.143 --> 02:34:39.231
turn them into a single  color. 
So, this is the first candidate 

02:34:39.232 --> 02:34:41.232
for placing the implementation 
of what that 

02:34:45.163 --> 02:34:46.391
extension function was into this
class so that everyone can use 

02:34:46.392 --> 02:34:48.392
it.

02:34:50.306 --> 02:34:51.321
So that it can be used to the 
Java language or the Kotlin 

02:34:51.322 --> 02:34:53.322
language.

02:34:55.234 --> 02:34:58.091
So, in core KTX 1.0, this 
actually has been rewritten to 

02:35:00.783 --> 02:35:02.783
just delegate to that color 
utils.

02:35:04.652 --> 02:35:06.076
So, the Java language users get 
that functionality but the 

02:35:06.077 --> 02:35:09.949
Kotlin users get the enhanced 
syntax.

02:35:11.575 --> 02:35:13.575
And if you look at the 
extensions that 

02:35:16.397 --> 02:35:18.555
we talked about so far, the 
bodies of them, the 

02:35:20.772 --> 02:35:24.043
implementation of these 
functions, they're all trivial. 

02:35:24.044 --> 02:35:26.044
They're exceedingly trivial and 
that's by design.

02:35:29.278 --> 02:35:31.278
And this gets me into

02:35:32.660 --> 02:35:34.660
covering some of the principles 
that we 

02:35:36.367 --> 02:35:38.603
defined defined that KTX 
extensions should have.  This 

02:35:38.604 --> 02:35:40.639
first one is that we want to 
adapt functionality that already

02:35:40.640 --> 02:35:46.210
exists, and if we want to add 
the new features, those should 

02:35:46.211 --> 02:35:48.494
be redirected upstream to a 
place where they're language 

02:35:48.495 --> 02:35:53.423
agnostic where both languages 
can take advantage of them.  

02:35:53.424 --> 02:35:55.424
Other examples of this was there
was 

02:35:58.131 --> 02:35:59.576
some HTML stuff and a path 
iterator that implemented core 

02:35:59.577 --> 02:36:01.577
KTX that has since moved 
upstream into core to be able to

02:36:04.238 --> 02:36:06.879
be used in both languages.  
Another thing that's common to 

02:36:06.880 --> 02:36:08.880
all 

02:36:11.120 --> 02:36:13.120
these extensions

02:36:16.739 --> 02:36:19.186
extensions is that they're 
inline.  The reason we do inline

02:36:19.187 --> 02:36:22.649
on the first one, the one at the
top, is that we want to avoid 

02:36:22.650 --> 02:36:26.730
the lambda allocation.  For the 
second one, because we're using 

02:36:26.731 --> 02:36:29.165
reFI generics, we're actually 
forced to use inline by the 

02:36:29.166 --> 02:36:31.616
compiler.  The third, the 
component ones and the 

02:36:35.952 --> 02:36:38.413
very bottom ones, are all inline
mostly because they're just 

02:36:38.414 --> 02:36:40.470
aliases to what you would 
otherwise write if the extension

02:36:41.685 --> 02:36:43.685
didn't exist.

02:36:46.393 --> 02:36:49.041
If we look at an example of 
something that's not inline in 

02:36:49.042 --> 02:36:51.042
core KTX, we have 

02:36:52.969 --> 02:36:54.969
this iterator extension to view 
group 

02:36:56.986 --> 02:36:58.986
which allows us to view

02:37:00.151 --> 02:37:03.219
Kotlin for in syntax to iterate 
the view and view group.  This 

02:37:03.220 --> 02:37:05.258
is not inline for a very 
specific reason and that is 

02:37:05.259 --> 02:37:07.259
because it defines, the 
implementation of this function 

02:37:07.691 --> 02:37:09.691
defines an anonymous class.

02:37:10.755 --> 02:37:12.399
If we were to inline this, that 
means that every time you use 

02:37:12.400 --> 02:37:17.111
it, an anonymous class would be 
defined at your call site so 

02:37:17.112 --> 02:37:19.112
this would increase your deck 
size, 

02:37:22.172 --> 02:37:24.172
method Copt and class loading

02:37:27.614 --> 02:37:29.446
.  We explicitly make this not 
inline because we want that 

02:37:29.447 --> 02:37:34.510
single implementation to be 
reused by all of the callers.  

02:37:34.511 --> 02:37:35.789
So, we default to an extension 
being inline unless there are 

02:37:35.790 --> 02:37:37.832
allocation reasons and I should 
note that this is 

02:37:42.399 --> 02:37:44.634
really only for KTX style 
extensions.  No normal Kotlin 

02:37:44.635 --> 02:37:47.074
code, this is not a good 
recommendation.  You don't want 

02:37:47.075 --> 02:37:49.512
to default to inline because it 
has the potential to lead to 

02:37:55.248 --> 02:37:57.720
actually having a negative 
effect on your code rather than 

02:37:57.721 --> 02:38:01.054
a positive one.
All right so earlier when we 

02:38:01.055 --> 02:38:04.922
showed this extension, I talked 
about how the inline modifier 

02:38:04.923 --> 02:38:07.376
coupled with the fact that 
there's a lambda allows this 

02:38:07.377 --> 02:38:09.377
extension 

02:38:10.449 --> 02:38:13.348
to be a zero overhead 
extraction.  In the reFIed case,

02:38:13.349 --> 02:38:18.265
we get the ability to have a 
more declarative version of the 

02:38:18.266 --> 02:38:20.266
look-up at call site without 
having 

02:38:22.332 --> 02:38:24.332
to specify the colon colon class
dot Java.

02:38:26.430 --> 02:38:28.430
For updating the padding, we get
to 

02:38:29.891 --> 02:38:31.555
use default values to not are to
specify each of the arguments 

02:38:31.556 --> 02:38:33.556
and name 

02:38:35.632 --> 02:38:37.058
parameters to specify which 
subset of arguments we want to 

02:38:37.059 --> 02:38:39.059
actually provide.

02:38:41.086 --> 02:38:44.387
For the destructuring case we 
get the fancy syntax that allows

02:38:44.388 --> 02:38:46.388
us to pull 

02:38:47.841 --> 02:38:52.126
apart the component variables 
out of a composite architect.  

02:38:52.127 --> 02:38:53.992
This is enabled by the fact that
we have operator  overloading in

02:38:53.993 --> 02:38:58.085
Kotlin.  We also talked about 
how we were able to add the plus

02:38:58.086 --> 02:39:00.086
for color.

02:39:07.085 --> 02:39:09.754
For this one, we're aliasing an 
extension to a static method to 

02:39:09.755 --> 02:39:13.040
help improve explorability for 
built in  helpers that you might

02:39:13.041 --> 02:39:15.706
otherwise not know exist.
And then for types that are 

02:39:16.772 --> 02:39:18.772
collection-like but not actually

02:39:20.444 --> 02:39:22.444
collections, we have the ability
to turn 

02:39:23.512 --> 02:39:25.512
them into pseudocollections 
where we can 

02:39:29.189 --> 02:39:31.189
use the afford answer eyewitness

02:39:34.951 --> 02:39:36.772
an cs of the language as if they
were actual collections so each 

02:39:36.773 --> 02:39:41.051
one of these has a very 
Kotlin-specific language that it

02:39:41.052 --> 02:39:43.052
uses and we want to make sure 
all of 

02:39:45.208 --> 02:39:46.624
these that we're defining 
leverage some use of the 

02:39:46.625 --> 02:39:48.625
language that doesn't otherwise 
exist for Java collars.

02:39:51.726 --> 02:39:53.774
We want to resist trying to fix 
an API just by creating 

02:39:53.775 --> 02:39:56.027
extensions for it but rather 
enhance it to become more 

02:39:58.101 --> 02:40:00.112
pleasant to use by leveraging 
these Kotlin-specific features.

02:40:05.266 --> 02:40:10.987
Okay. One of the suggestions we 
get quite frequently is to take 

02:40:10.988 --> 02:40:13.226
something like set on click 
listener and write an extension 

02:40:15.483 --> 02:40:17.523
which allows you to call it 
using something like click or on

02:40:17.524 --> 02:40:19.524
click.

02:40:25.780 --> 02:40:27.780
This allows the calling code 
instead 

02:40:29.033 --> 02:40:30.678
of having to call said unclick 
listener we get the shorter 

02:40:30.679 --> 02:40:32.987
version of click.  Are we 
leveraging a future language 

02:40:33.183 --> 02:40:37.269
here?  Well, we're leveraging 
extension functions but not 

02:40:37.270 --> 02:40:39.270
really, we're really just 
creating a shorter alias.

02:40:43.173 --> 02:40:45.837
What value are we creating from 
this type of extension or typing

02:40:45.838 --> 02:40:50.335
less characters but really it's 
auto completed anyway, but even 

02:40:50.336 --> 02:40:53.026
worse, what precedent will we be
setting here by adding this 

02:40:53.027 --> 02:40:57.892
extension.  Are we going to do 
this for every listener?  And 

02:40:57.893 --> 02:40:59.971
so, this is a great example of 
something we explicitly do not 

02:40:59.972 --> 02:41:01.972
want to 

02:41:03.596 --> 02:41:07.146
do in the KTX libraries.  If 
you're not familiar with the 

02:41:07.147 --> 02:41:09.147
term, 

02:41:10.250 --> 02:41:12.250
we call this code golf where you
have 

02:41:13.368 --> 02:41:15.404
the desire to create the 
shortest code possible.  This is

02:41:15.405 --> 02:41:17.037
something we do not want to do. 
We're not here to just make the 

02:41:17.038 --> 02:41:19.038
code shorter.

02:41:21.712 --> 02:41:26.231
Okay. There's another one that 
gets suggested every now and 

02:41:26.232 --> 02:41:28.232
then and that I've seen people 
using.

02:41:34.668 --> 02:41:36.979
With Android because of the 
different API levels we have to 

02:41:36.980 --> 02:41:41.259
support, you very frequently see
these checks around the STK.  So

02:41:41.260 --> 02:41:42.473
it can be tempting to pull this 
out into an extension where you 

02:41:42.474 --> 02:41:45.153
have a little bit more 
declarative version of this.

02:41:47.635 --> 02:41:49.635
We move the comparison into an 
extension 

02:41:51.096 --> 02:41:51.912
function, it's an inline 
function so we don't have the 

02:41:51.913 --> 02:41:53.913
overhead.

02:41:56.017 --> 02:41:58.035
The lambda is the last parameter
so we get the nice Kotlin call 

02:41:58.036 --> 02:42:00.036
site syntax and 

02:42:01.560 --> 02:42:03.560
it turns our if statement from 
this into this.

02:42:05.676 --> 02:42:09.768
Now, this by itself is not too 
terrible.  We're really not 

02:42:09.769 --> 02:42:11.769
leveraging any of the 

02:42:12.783 --> 02:42:16.534
language features again similar 
to the last one.  It's still 

02:42:16.535 --> 02:42:18.535
kind of an alias but at 

02:42:20.833 --> 02:42:23.110
least this one you can argue a 
little bit more for its merits. 

02:42:23.111 --> 02:42:25.111
But, there's a problem.  While 
these two statements are 

02:42:27.399 --> 02:42:28.817
equivalent, what happens when --
for one thing is that you can at

02:42:28.818 --> 02:42:33.327
least static import STK in and 
then they're a little bit closer

02:42:33.328 --> 02:42:37.055
so that's one reason why this is
less justified.  But, one thing 

02:42:37.056 --> 02:42:39.295
is that an if statement is a 
very primitive construct of a 

02:42:40.537 --> 02:42:42.537
programming language.

02:42:44.628 --> 02:42:47.068
And because an if statement is 
not just an if statement, 

02:42:47.069 --> 02:42:49.718
there's constructs like else.
So, what if your requirements 

02:42:49.719 --> 02:42:51.719
change such that you need to 
alter the behavior 

02:42:55.474 --> 02:42:57.515
on these two different versions?
Well, if you were using this 

02:42:57.516 --> 02:43:02.029
extension that you wrote in 
order to support this  case, you

02:43:02.030 --> 02:43:04.061
either have to change back to 
using an if statement, or you 

02:43:04.062 --> 02:43:06.062
have to 

02:43:07.357 --> 02:43:09.615
modify the function where maybe 
it takes two lambdas now, one 

02:43:09.616 --> 02:43:12.470
fortification where you're above
19.  One for the case where 

02:43:12.471 --> 02:43:14.471
you're not.

02:43:16.129 --> 02:43:18.158
Because we're not taking two 
lambdas in this function, we've 

02:43:18.159 --> 02:43:23.199
lost the special trailing lambda
syntax where we now have to pass

02:43:23.200 --> 02:43:25.200
them as arguments inside the 

02:43:27.211 --> 02:43:27.620
parentheses whereas before we 
didn't.  So, immediately, this 

02:43:27.621 --> 02:43:29.621
extension starts falling apart.

02:43:31.505 --> 02:43:34.013
If we introduce another 
conditional branch, maybe we 

02:43:34.014 --> 02:43:37.276
need to vary the behavior across
APIs in three different ways.  

02:43:37.277 --> 02:43:39.277
Well, there's really no way that
we 

02:43:42.520 --> 02:43:44.631
can make the extension do this. 
The other thing that is 

02:43:44.632 --> 02:43:47.878
different about this extension 
compared to the if statement is 

02:43:47.879 --> 02:43:49.722
that we're assuming the 
conditional that we want to 

02:43:49.723 --> 02:43:53.399
check is greater than or equal 
to, that the behavior we want to

02:43:53.400 --> 02:43:55.400
run in the lambda, 

02:43:57.118 --> 02:43:58.945
we only want to run on, you 
know, 19 plus.  Well, a lot of 

02:43:58.946 --> 02:44:00.946
times some of the if 

02:44:04.292 --> 02:44:06.744
statements, again, STK ints will
be less than or equal to so now 

02:44:06.745 --> 02:44:09.004
we need a second extension in 
order to support that use case.

02:44:12.282 --> 02:44:14.316
So this is another example of 
something that we're not looking

02:44:14.317 --> 02:44:16.964
to do.  We don't want to 
optimize for just a 

02:44:20.430 --> 02:44:22.430
single use case or a specific 
use case 

02:44:24.931 --> 02:44:26.973
where the extension only 
supports one way of doing 

02:44:26.974 --> 02:44:28.817
something and then when you need
to move to something more 

02:44:28.818 --> 02:44:31.894
complex, you have to revert to 
the original behavior.

02:44:36.140 --> 02:44:38.814
We want the extensions to allow 
you to express everything you 

02:44:38.815 --> 02:44:40.815
would need to 

02:44:42.470 --> 02:44:46.649
express if it didn't exist.  
Okay. So all the extensions 

02:44:46.650 --> 02:44:48.650
we've been 

02:44:50.571 --> 02:44:52.406
talking about thus far have been
ones that are in the core KTX 

02:44:52.407 --> 02:44:55.059
library.
I don't want to go through a ton

02:44:55.060 --> 02:44:58.974
of the extensions that are in 
these other libraries.  Again, 

02:44:58.975 --> 02:45:00.975
I'm going to show you how you 

02:45:03.224 --> 02:45:05.224
can discover them in a

02:45:06.987 --> 02:45:08.987
bit but I want to touch on one.

02:45:11.461 --> 02:45:13.461
So, for the fragment KTX, we 
have an 

02:45:14.467 --> 02:45:19.223
extension which encapsulates 
transactions.  We move the begin

02:45:19.224 --> 02:45:20.472
transaction and the commit 
function calls into an 

02:45:20.473 --> 02:45:22.473
extension.

02:45:26.830 --> 02:45:28.459
We use the fact that we can use 
an inline function and the 

02:45:28.460 --> 02:45:33.589
lambda again to turn this into a
zero overhead thing.  Our 

02:45:33.590 --> 02:45:35.216
calling code then becomes a 
little bit shorter where we now 

02:45:35.217 --> 02:45:38.072
use the transaction with a 
lambda body.

02:45:41.571 --> 02:45:43.220
So if you've used fragments, 
you'll know that commit is not 

02:45:43.221 --> 02:45:45.444
the only commit function.  
There's actually more than one.

02:45:50.792 --> 02:45:52.792
So we can model this by doing 

02:45:54.454 --> 02:45:56.285
something like allowing you to 
apply bullying as whether you 

02:45:56.286 --> 02:45:59.149
want to allow state loss or 
disallow state loss when you're 

02:45:59.150 --> 02:46:01.150
committing.

02:46:03.285 --> 02:46:05.113
This is really easy to 
accommodate.  But it sort of 

02:46:05.114 --> 02:46:07.950
goes against something I said 
earlier where you can update 

02:46:07.951 --> 02:46:11.416
your call sites to be able to 
use this, it sort of goes 

02:46:11.417 --> 02:46:13.245
against something I said 
earlier, though, wry talked 

02:46:13.246 --> 02:46:15.246
about 

02:46:16.285 --> 02:46:17.300
minimizing the impact of the 
implementation of these 

02:46:17.301 --> 02:46:19.830
extensions.  Since this is an 
inline function and 

02:46:23.209 --> 02:46:25.209
we've now put a conditional 
inside the 

02:46:27.285 --> 02:46:29.975
inline function, that 
conditional is being inlined 

02:46:29.976 --> 02:46:32.031
into all the call sites so all 
the call sites have to have this

02:46:33.866 --> 02:46:35.866
conditional inside of it, so is 
this 

02:46:38.571 --> 02:46:40.571
actually a bad thing

02:46:47.824 --> 02:46:49.824
.  You

02:46:50.864 --> 02:46:52.293
You don't really have to 
understand byte code.  There's 

02:46:52.294 --> 02:46:54.757
essentially three function 
calls.  The first one is 

02:46:54.758 --> 02:46:56.758
transaction w the second one is 
that place inside the 

02:46:59.591 --> 02:47:01.616
lambda and the third one is just
a call to commit allowing state 

02:47:01.617 --> 02:47:03.860
loss.  There's no if statement 
here.  There's no conditional.

02:47:09.385 --> 02:47:11.838
And that's because since this is
an inline function and since the

02:47:11.839 --> 02:47:13.839
argument 

02:47:14.865 --> 02:47:16.865
is a

02:47:24.650 --> 02:47:28.180
boolean, the compiler actually 
knows what time.  So since it 

02:47:28.181 --> 02:47:30.233
can be compiled and eliminates 
the branches that can never 

02:47:32.065 --> 02:47:34.065
possibly be executed so you 
actually get 

02:47:35.313 --> 02:47:36.117
in byte code what's equivalent 
to what you otherwise would have

02:47:36.118 --> 02:47:38.163
written.
There's actually more commit 

02:47:38.164 --> 02:47:42.716
functions.  There's one which 
will allow you to commit now and

02:47:42.717 --> 02:47:44.717
commit, so we can also 

02:47:45.785 --> 02:47:47.785
support that by adding an 
additional boolean.

02:47:50.695 --> 02:47:52.938
The same thing happens even 
though they're now nested, dead 

02:47:52.939 --> 02:47:54.939
code will make 

02:47:56.610 --> 02:48:00.099
it so there's only one call in 
the resulting byte code.  Okay. 

02:48:00.100 --> 02:48:02.532
As part of this effort of all 
these releases at I/O, one of 

02:48:02.533 --> 02:48:04.533
the things that 

02:48:07.599 --> 02:48:10.536
we've done is start creating a 
Kotlin-specific view of the 

02:48:10.537 --> 02:48:15.661
libraries that we publish and 
the Android framework itself.  

02:48:15.662 --> 02:48:17.662
So, if you see in that blue box 
there 

02:48:19.903 --> 02:48:21.903
when you visit the

02:48:28.728 --> 02:48:31.175
reference docs it will ask you 
if you want to review a 

02:48:31.176 --> 02:48:33.176
Kotlin-specific and 

02:48:34.627 --> 02:48:36.627
also if you scroll down to the 
page, at 

02:48:37.847 --> 02:48:39.847
the very bottom we have links to
them as well.

02:48:40.256 --> 02:48:42.087
And what these are are a Kotlin 
view of these libraries.  So 

02:48:42.088 --> 02:48:44.564
when you're browsing through, 
say, the fragment package, 

02:48:44.565 --> 02:48:46.797
you'll be able to see the 
extensions for fragment inside 

02:48:47.395 --> 02:48:50.047
the documentation.  That's no 
longer completely separate.

02:48:53.917 --> 02:48:56.355
One thing that's missing right 
now is we don't actually tell 

02:48:56.356 --> 02:48:59.696
you the Maven coordinates of the
artifact that these come from.  

02:48:59.697 --> 02:49:01.697
That's coming soon.

02:49:04.566 --> 02:49:06.566
And also the extensions

02:49:10.108 --> 02:49:11.745
in core KTX which extend the 
platforms sites don't actually 

02:49:11.746 --> 02:49:14.190
show up on the platform docs.  
But this is something we wanted 

02:49:14.191 --> 02:49:17.887
to get out to show you it's 
being worked on so hopefully 

02:49:17.888 --> 02:49:19.888
those two things will be coming 
soon.

02:49:22.847 --> 02:49:24.847
All right.  I want to touch on 
-- you know, I'm 

02:49:28.349 --> 02:49:30.175
here to talk about Android KTX 
but Kotlin extensions, there's 

02:49:30.176 --> 02:49:32.176
nothing Android specific about 
it.

02:49:34.294 --> 02:49:36.294
What we're doing is building 

02:49:37.378 --> 02:49:38.825
extensions it try and make these
libraries more Kotlin friendly 

02:49:38.826 --> 02:49:40.826
and that's something that any 
library can do 

02:49:44.325 --> 02:49:47.006
so I want to talk about the ways
that we think about how we can 

02:49:47.007 --> 02:49:49.007
make libraries 

02:49:50.679 --> 02:49:52.322
more Kotlin friendly that apply 
to both the Android libraries 

02:49:52.323 --> 02:49:55.609
but also apply to libraries you 
might be writing or you might be

02:49:55.610 --> 02:49:57.610
using.

02:49:58.682 --> 02:50:00.331
The first way it make a library 
really Kotlin friendly is just 

02:50:00.332 --> 02:50:03.831
rewrite the whole thing in 
Kotlin.  I mean, obviously this 

02:50:03.832 --> 02:50:06.277
isn't feasible for every library
but it's certainly an option for

02:50:06.278 --> 02:50:08.278
some.

02:50:12.134 --> 02:50:14.134
If it's a library that's private
to

02:50:15.877 --> 02:50:17.543
your app, it's in your 
repository or internal to your 

02:50:17.544 --> 02:50:20.002
company and you're already using
Kotlin, this is a viable option.

02:50:21.838 --> 02:50:23.889
Doesn't seem like something 
that's totally viable for, say, 

02:50:23.890 --> 02:50:27.771
the Android framework and I'm 
not quite sure we're at the 

02:50:27.772 --> 02:50:29.772
stage where an Android X library

02:50:32.774 --> 02:50:34.774
could do this

02:50:36.707 --> 02:50:39.607
maybe a future Android X library
could be written in Kotlin.  

02:50:39.608 --> 02:50:41.608
That seems like a strong 
possibility.

02:50:41.847 --> 02:50:43.847
What we've chosen to do with 
most of the 

02:50:45.973 --> 02:50:48.407
things that we publish is 
sibling artifacts.  So the main 

02:50:48.408 --> 02:50:51.319
library remains written using 
Java language and we ship Kotlin

02:50:54.033 --> 02:50:56.033
language features as a sibling 
artifact.

02:50:58.540 --> 02:51:00.390
What's great about this is you 
don't force the Kotlin standard 

02:51:00.391 --> 02:51:04.916
library on to your consumers 
unless they explicitly want it. 

02:51:04.917 --> 02:51:06.756
You can curate the extensions to
be exactly what's needed to 

02:51:06.757 --> 02:51:08.757
augment API 

02:51:11.238 --> 02:51:13.074
where you get the Kotlin 
specific features and what's 

02:51:13.075 --> 02:51:15.075
really nice about this is you 
don't have to control the 

02:51:16.563 --> 02:51:18.402
library that you're extending so
if you're just consuming a 

02:51:18.403 --> 02:51:20.403
library and you 

02:51:21.870 --> 02:51:22.674
want to make part of it more 
Kotlin friendly, you can do 

02:51:22.675 --> 02:51:26.737
that.  You can do that either in
your own app or you can publish 

02:51:26.738 --> 02:51:28.738
a set of extensions 

02:51:29.995 --> 02:51:31.995
for a library that someone else 
publishes.

02:51:38.401 --> 02:51:40.401
But, are these the only two 
options?

02:51:41.462 --> 02:51:43.312
I want to take a look at 
something that I think will lead

02:51:43.313 --> 02:51:45.313
into a third 

02:51:47.949 --> 02:51:49.949
somewhat hybrid option

02:51:54.724 --> 02:51:56.724
.  I'm going to go back to the 
simple 

02:51:57.994 --> 02:51:59.824
alias message where we've taken 
a Kotlin in the Java and turned 

02:51:59.825 --> 02:52:01.883
it into Kotlin language.  If we 
look at the implementation of 

02:52:03.715 --> 02:52:04.961
this class on the Java side, 
I've included the first line 

02:52:04.962 --> 02:52:07.415
because we can see that it 
immediately dereferences the 

02:52:11.133 --> 02:52:13.133
argument that we pass in.  As 
soon as we pass in a string, it 

02:52:14.197 --> 02:52:16.651
says, you know, what's the 
maximum number of characters 

02:52:16.652 --> 02:52:19.713
that I can iterate over in order
to determine whether or not 

02:52:19.714 --> 02:52:21.714
there are digits.

02:52:24.645 --> 02:52:26.674
And so, if you've been using 
Kotlin with Java APIs, you might

02:52:26.675 --> 02:52:28.675
know that this 

02:52:31.003 --> 02:52:32.641
means that the parameter is 
going to be exposed as what's 

02:52:32.642 --> 02:52:34.642
called a platform type.  It has 
unknown  nullability.

02:52:38.160 --> 02:52:40.160
But, from the implementation, we
know 

02:52:41.446 --> 02:52:43.269
right away that this method 
simply cannot accept null 

02:52:43.270 --> 02:52:45.270
values.

02:52:46.316 --> 02:52:48.316
And way that we would fix this 
is by 

02:52:49.591 --> 02:52:51.829
adding the non-null annotation. 
So what this annotation does is 

02:52:51.830 --> 02:52:53.830
it 

02:52:54.897 --> 02:52:56.897
informs the Kotlin compiler that
there's 

02:52:57.917 --> 02:52:59.917
a restriction

02:53:04.365 --> 02:53:06.398
, that there's special behavior 
it needs to take into account 

02:53:06.399 --> 02:53:09.842
where it needs to enforce that 
no one passes a potentially null

02:53:09.843 --> 02:53:12.305
value or null into this method. 
So, this is something, this is 

02:53:14.128 --> 02:53:16.577
enabling a language feature in 
Kotlin that simply doesn't exist

02:53:16.578 --> 02:53:18.578
in Java.

02:53:21.210 --> 02:53:23.210
Now, you can

02:53:28.177 --> 02:53:30.177
use tools that will allow this 

02:53:31.233 --> 02:53:33.519
enforcement to work for Java but
it's not intrinsic to the null 

02:53:33.520 --> 02:53:35.569
itself.  So if we can do 
something like that 

02:53:38.840 --> 02:53:41.277
for nullness, add this 
annotation to  nullness that it 

02:53:41.278 --> 02:53:43.720
needs to change its behavior 
when we invoke this method, can 

02:53:45.351 --> 02:53:47.788
we do this for something else?  
Say, I want to take this static 

02:53:47.789 --> 02:53:51.284
method where the first argument 
is really the receiver and can I

02:53:51.285 --> 02:53:53.486
say this is actually going to be
an extension function when 

02:53:55.563 --> 02:53:57.563
invoked from Kotlin?

02:54:00.783 --> 02:54:02.783
And what this allows us to do 

02:54:04.707 --> 02:54:06.707
potentially is eliminate the 
need to 

02:54:07.708 --> 02:54:09.707
have this explicitly defined 
extension at  all.  Right?  This

02:54:09.708 --> 02:54:10.919
extension only exists it change 
the calling convention to inform

02:54:10.920 --> 02:54:12.750
the compiler that we want to 
allow you to call it in a 

02:54:12.751 --> 02:54:14.751
different way.

02:54:20.042 --> 02:54:21.892
So now we're left with just 
this, the Kotlin compiler sees 

02:54:21.893 --> 02:54:23.893
the annotation just 

02:54:25.171 --> 02:54:27.218
like it saw the nonnull 
annotation, infers something 

02:54:27.219 --> 02:54:30.061
from it and allows you to call 
in a way that's more idiomatic 

02:54:30.921 --> 02:54:34.187
for that language.  In the byte 
code, we get what we otherwise 

02:54:34.188 --> 02:54:36.188
would have written, right?

02:54:37.444 --> 02:54:39.893
We get the call to the static 
method and the receiver becomes 

02:54:39.894 --> 02:54:41.894
the first 

02:54:42.896 --> 02:54:44.896
argument

02:54:48.857 --> 02:54:50.857
.  How about this example?  One 
thing you might have noticed is 

02:54:52.930 --> 02:54:55.416
this extension is named update 
padding, not set padding.  Now, 

02:54:55.417 --> 02:54:56.870
we can actually call this 
extension set padding, but the 

02:54:56.871 --> 02:54:59.720
problem is that it will only 
work for a subset of arguments. 

02:54:59.721 --> 02:55:01.721
So.  In this case, where we're 
just passing 

02:55:10.591 --> 02:55:10.639
left and right values, we could 
call that set padding and it 

02:55:10.640 --> 02:55:12.640
would work fine.

02:55:15.200 --> 02:55:15.247
But if we passed left right and 
then top bottom, we'd be 

02:55:15.248 --> 02:55:19.553
supplying four arguments and the
Kotlin compiler is going to see 

02:55:19.554 --> 02:55:21.554
that the real set padding also 
excepts four arguments and it's 

02:55:22.418 --> 02:55:24.418
going to prefer calling the real
one.

02:55:25.274 --> 02:55:27.274
And the real one doesn't have 
name 

02:55:28.344 --> 02:55:30.378
parameters so you're going to 
get a compilation error.  That's

02:55:30.379 --> 02:55:32.379
its reason we have to name this 
update padding.

02:55:38.984 --> 02:55:41.034
If we look at the real set 
padding, simple method that 

02:55:41.035 --> 02:55:43.035
takes four integers, 

02:55:44.305 --> 02:55:46.158
what if we could inform the 
Kotlin compiler that these 

02:55:46.159 --> 02:55:48.159
parameters have 

02:55:51.429 --> 02:55:53.429
names associated with them

02:55:54.551 --> 02:55:56.551
.  Now, it would be nice to 
infer this 

02:55:58.056 --> 02:56:00.309
just from the parameter, not the
set -- but I'll argue that for 

02:56:00.310 --> 02:56:03.170
one it's very nice being 
explicit about these names in 

02:56:03.778 --> 02:56:09.280
the annotation.  In Java 8 byte 
code, there actually is a way 

02:56:09.281 --> 02:56:12.148
for you to retain parameter 
names so the Kotlin compiler 

02:56:12.149 --> 02:56:15.237
could in theory use those but 
one problem is that then it 

02:56:15.238 --> 02:56:17.917
becomes an all or nothing thing.
You have to opt into this 

02:56:17.918 --> 02:56:19.918
behavior and 

02:56:21.411 --> 02:56:23.411
then suddenly every parameter 
name 

02:56:24.877 --> 02:56:26.714
across your library is set in 
stain whereas if it's 

02:56:26.715 --> 02:56:30.174
annotation, it's something you 
could incrementally migrate.  

02:56:30.175 --> 02:56:32.175
So, this has the potential to 
solve 

02:56:34.668 --> 02:56:36.668
the naming part where now we can
call 

02:56:37.680 --> 02:56:43.266
the real method from Kotlin and 
specify the four orders from any

02:56:43.267 --> 02:56:45.915
order we want based on what 
names we provide.  The default 

02:56:45.916 --> 02:56:51.044
value.  What if we could pass 
in, what if we could specify an 

02:56:51.045 --> 02:56:53.045
expression, a Kotlin 

02:56:57.128 --> 02:56:59.128
expression which allowed the 
compiler to

02:57:03.981 --> 02:57:05.981
.  This would change our 
original 

02:57:07.264 --> 02:57:08.917
extension calling convention 
from calling our extension to 

02:57:08.918 --> 02:57:13.425
actually just using the real 
method.  And then in the byte 

02:57:13.426 --> 02:57:15.426
code, we get the thing that we 
started with.

02:57:20.783 --> 02:57:22.837
The thing that our explicit 
extension would inline to but 

02:57:22.838 --> 02:57:24.838
now the extension doesn't have 
to exist.

02:57:28.369 --> 02:57:30.840
The metadata that we added in 
the form of annotations inform 

02:57:30.841 --> 02:57:33.899
the Kotlin compiler that we 
wanted to enhance our ability to

02:57:33.900 --> 02:57:35.900
call this function in a Kotlin 
specific way leveraging the 

02:57:36.557 --> 02:57:38.557
Kotlin features.

02:57:39.641 --> 02:57:41.641
And so we're able to do so.

02:57:45.806 --> 02:57:47.806
This is something, so Kotlin has
this 

02:57:50.036 --> 02:57:53.375
process which is called KEEP.  
Kotlin evolution and enhancement

02:57:53.584 --> 02:57:55.584
process.

02:57:57.463 --> 02:58:00.105
And just this morning, we 
proposed these annotations as 

02:58:00.106 --> 02:58:02.900
KEEP110.  So, this is something 
we're proposing 

02:58:05.962 --> 02:58:07.909
to add to the Kotlin compiler so
that it can understand these 

02:58:07.910 --> 02:58:12.023
annotations.  We have extension 
function and extension property,

02:58:12.024 --> 02:58:14.024
which are for static methods.

02:58:16.087 --> 02:58:18.087
Default value, which allows 
supplying 

02:58:19.181 --> 02:58:21.438
default values for our 
parameters, and then KT name, 

02:58:21.439 --> 02:58:27.429
which allows you to provide an 
alternate name for methods, 

02:58:27.430 --> 02:58:29.430
feels, or parameters.

02:58:30.685 --> 02:58:33.376
It's very important to note that
this is extremely early.  These 

02:58:33.377 --> 02:58:36.851
names might change.  The 
semantics might change.  This 

02:58:36.852 --> 02:58:38.852
may never actually be skepped 

02:58:40.907 --> 02:58:42.907
into the Kotlin compiler.

02:58:43.965 --> 02:58:45.587
We have been working with the 
jet brands team for quite a 

02:58:45.588 --> 02:58:49.873
while on this and some of this 
is already prototyped inside the

02:58:49.874 --> 02:58:51.874
Kotlin compiler.

02:58:52.950 --> 02:58:55.605
We really think this could be a 
way to enhance the framework for

02:58:55.606 --> 02:58:57.606
Kotlin callers 

02:59:00.574 --> 02:59:03.216
without actually having to go in
and rewrite the Android 

02:59:03.217 --> 02:59:05.865
framework for at least its API 
and Kotlin, which is really not 

02:59:05.866 --> 02:59:10.404
feasible.  And it's also 
important to note that while 

02:59:10.405 --> 02:59:12.653
this is an option assuming that 
it actually make it's into the 

02:59:12.654 --> 02:59:17.796
Kotlin compiler, it doesn't 
totally solve every problem that

02:59:17.797 --> 02:59:19.797
our existing extensions are 
solving.

02:59:24.122 --> 02:59:26.122
We determined these annotations 
that we 

02:59:28.201 --> 02:59:30.201
proposed in KEEP 110 through 
looking 

02:59:31.672 --> 02:59:32.076
through a bunch of open source 
libraries, looking through our 

02:59:32.077 --> 02:59:36.205
own libraries, and seeing what 
we thought would be the most 

02:59:36.206 --> 02:59:38.206
useful extensions.

02:59:39.464 --> 02:59:41.464
What would be the pattern of 
Java 

02:59:43.537 --> 02:59:44.752
methods with such that they 
would want to be turned into 

02:59:44.753 --> 02:59:46.753
extensions.

02:59:48.429 --> 02:59:51.289
And so, the latter two really 
are complementary.  The big 

02:59:51.290 --> 02:59:53.730
advantages of the annotations is
that you retain the single 

02:59:53.731 --> 02:59:55.731
source of truth.

02:59:57.856 --> 03:00:00.748
You don't have to really know 
Kotlin.  You don't have to add 

03:00:00.749 --> 03:00:02.749
Kotlin compiler to your build 
system.

03:00:05.254 --> 03:00:08.299
You don't have to publish 
sibling artifacts.  If you're a 

03:00:08.300 --> 03:00:10.382
pure Java library, you can add 
these annotations and just 

03:00:10.383 --> 03:00:15.911
enhance your API so that Kotlin 
callers get the more idiomatic 

03:00:15.912 --> 03:00:17.912
syntax.

03:00:21.634 --> 03:00:23.634
All right, so to sum up core KTX
is now 

03:00:25.289 --> 03:00:27.741
part of Android Jetpack, 
versions of Android Jetpack 

03:00:27.742 --> 03:00:29.742
released with Android Jetpack.

03:00:31.209 --> 03:00:33.275
There's a few new artifacts as 
you can see here on the screen, 

03:00:33.276 --> 03:00:35.308
there's definitely more coming. 
Notable ones that you think are 

03:00:37.580 --> 03:00:39.799
missing, are slices and V model.
I would not be surprised to see 

03:00:42.883 --> 03:00:44.883
artifacts for those in the 
coming months.

03:00:48.690 --> 03:00:50.931
Please check out the Kotlin 
version of the reference 

03:00:50.932 --> 03:00:53.577
document, yeah, the reference.  
You know, this is extremely 

03:00:53.578 --> 03:00:55.578
early.

03:01:01.076 --> 03:01:03.076
We're -- this requires changes 
in DAC

03:01:04.880 --> 03:01:06.539
doca and how we produce docs.  
It's something we want to get 

03:01:06.540 --> 03:01:08.540
out and 

03:01:09.949 --> 03:01:13.114
show you a preview.  This is 
definitely something being 

03:01:13.926 --> 03:01:15.926
actively worked on.

03:01:17.806 --> 03:01:19.879
There's a new component for 
Android KTX.  Because Core KTX 

03:01:19.880 --> 03:01:24.767
and all the KTX libraries are 
now part of Jetpack, the source 

03:01:24.768 --> 03:01:28.467
of truth has moved into the 
Android support repository.  

03:01:28.468 --> 03:01:30.468
We're going to be migrating the 
GitHub 

03:01:32.535 --> 03:01:35.393
issues on the GitHub project 
over to this bug tracker in the 

03:01:35.394 --> 03:01:37.394
coming weeks but 

03:01:40.509 --> 03:01:42.170
it's important to note that 
we're still gob accepting core 

03:01:42.171 --> 03:01:46.442
requests to the GitHub repo and 
syncing things back out to the 

03:01:46.443 --> 03:01:50.342
GitHub repo.  It's just that 
issues will no longer be the 

03:01:50.343 --> 03:01:51.560
source of truth on GitHub of the
it will be on the Android 

03:01:51.561 --> 03:01:53.561
tracker.

03:01:55.654 --> 03:01:57.686
The KEEP was proposed, I created
the poll request about an hour 

03:01:57.687 --> 03:02:00.741
ago.  Please go check that out. 
The document contains a lot more

03:02:02.776 --> 03:02:04.776
detail about examples.  And like
I said, the annotations that 

03:02:07.273 --> 03:02:09.750
were chosen were the ones that 
we think have the most impact 

03:02:09.751 --> 03:02:11.751
but at the bottom of the 
document you'll see that if 

03:02:12.794 --> 03:02:14.794
something like this gets 
accepted, 

03:02:16.046 --> 03:02:20.312
there's a potential for future 
enhancement of even more.  The 

03:02:20.313 --> 03:02:22.403
link to that should be this.  I 
made this link last night before

03:02:22.404 --> 03:02:24.404
I 

03:02:26.269 --> 03:02:28.099
submitted it so hopefully it's 
accurate.  And that's it.  Thank

03:02:28.100 --> 03:02:30.546
you.
(applause)

03:02:33.811 --> 03:02:35.238
(Session was concluded at 1:10 
PM CT)

03:02:35.239 --> 03:02:37.572
***
This text, document, or file is 

03:02:35.239 --> 03:02:39.239
based on live transcription.  
Communication Access Realtime 

03:02:35.239 --> 03:02:39.372
Translation (CART), captioning, 
and/or live transcription are 

03:02:35.239 --> 03:02:35.429
provided in order to facilitate 
communication

03:02:35.430 --> 03:02:39.563
accessibility and may not be a 
totally verbatim record of the 

03:02:35.430 --> 03:02:39.163
proceedings.  This text, 
document, or file is not to be 

03:02:35.430 --> 03:02:39.563
distributed or used in any way 
that may violate copyright law.

03:02:35.430 --> 03:02:37.874
***

03:02:45.213 --> 03:02:47.213
REALTIME CAPTIONING ON THIS 
SCREEN

03:08:59.600 --> 03:09:01.655
GOOGLE I/O 2018
MOUNTAIN VIEW, CALIFORNIA

03:09:02.876 --> 03:09:04.927
MAY 10, 2018
STAGE 2

03:09:08.844 --> 03:09:10.844
11:30 AM

03:09:12.702 --> 03:09:15.359
TENSORFLOW AND DEEP 
REINFORCEMENT LEARNING WITHOUT A

03:09:15.360 --> 03:09:17.360
PHD

03:09:20.024 --> 03:09:22.024
TAF466

03:22:19.811 --> 03:22:23.765
&gt;&gt; Hi, everyone.  Hello.  
Welcome to this TensorFlow 

03:22:23.766 --> 03:22:25.766
session about reinforcement 
learning.

03:22:28.088 --> 03:22:30.138
So, this is Yu-Han, I'm Martin, 
and today, we would like to 

03:22:30.139 --> 03:22:32.139
build a neural network with you.

03:22:36.664 --> 03:22:38.664
Do you know with neural 
networks?

03:22:39.110 --> 03:22:39.715
&gt;&gt; AUDIENCE: Yeah
&gt;&gt; MARTIN GORNER: Serious 

03:22:39.716 --> 03:22:41.716
question.

03:22:43.606 --> 03:22:45.846
If I said Softmax or cross 
entropy, raise your hand if you 

03:22:45.847 --> 03:22:49.745
know what that is.  Like half of
you.  Okay. Very quick primer.  

03:22:49.746 --> 03:22:51.746
This is a neural network.  Okay?

03:22:53.631 --> 03:22:54.640
Layers of neurons of those 
neurons, they always do the same

03:22:54.641 --> 03:22:57.917
thing.  They do a weighted sum 
of all of their inputs.

03:23:03.171 --> 03:23:05.171
And then, you can

03:23:10.749 --> 03:23:12.749
layer them in layers.

03:23:14.438 --> 03:23:16.438
The neurons in the first layer 
will be doing weighted sums.

03:23:18.785 --> 03:23:20.403
The neurons in the second layer 
will be doing sums from the 

03:23:20.404 --> 03:23:24.696
first layer and if you're 
building a classifier, let's say

03:23:24.697 --> 03:23:26.743
here you probably want to 
classify those little square 

03:23:26.744 --> 03:23:31.647
images into airplanes and 
nonairplanes, you will end up on

03:23:31.648 --> 03:23:33.648
a last layer which has as many 

03:23:34.743 --> 03:23:36.743
neurons as you have classes and 
if those 

03:23:37.748 --> 03:23:39.748
weights

03:23:45.553 --> 03:23:48.003
are configured correctly, we'll 
get to that, then one of those 

03:23:48.004 --> 03:23:50.004
will have a strong output.

03:23:51.885 --> 03:23:53.313
Tell you it's an airplane or the
other one will have a strong 

03:23:53.314 --> 03:23:55.314
output and tell you this is not 
an airplane.  Okay?

03:23:57.235 --> 03:23:58.876
There's one more thing, 
activation functions, so a 

03:23:58.877 --> 03:24:00.877
little bit more detail about 
what a neuron does.

03:24:03.031 --> 03:24:05.882
For those who like it, you have 
the full -- yep.  Right here.

03:24:08.969 --> 03:24:10.969
You havele full transfer 
function here 

03:24:12.851 --> 03:24:15.728
so you see it's a weighted sum 
plus something called the bias. 

03:24:15.729 --> 03:24:18.397
That's just an additional degree
of freedom and then you feed 

03:24:18.398 --> 03:24:20.398
this through 

03:24:21.500 --> 03:24:23.500
an activation.

03:24:24.567 --> 03:24:25.992
And so simplify for us here, 
only two activation functions 

03:24:25.993 --> 03:24:27.993
that count.

03:24:31.160 --> 03:24:33.597
So, for all the intermediate 
layers, the wide layers, that's 

03:24:33.598 --> 03:24:35.598
the simplest 

03:24:38.236 --> 03:24:40.236
function you can imagine

03:24:43.057 --> 03:24:46.110
.  We love it.  Everyone uses 
that.  Let's not go any further.

03:24:47.945 --> 03:24:50.804
On the last layer, though, if we
are building a classifier, 

03:24:50.805 --> 03:24:55.133
typically what you use is the 
Softmax activation function and 

03:24:55.134 --> 03:24:58.021
that is an exponential followed 
by a normalization.  So, here, I

03:24:58.022 --> 03:25:00.022
have different classifier 

03:25:03.280 --> 03:25:05.280
that classifies in ten classes

03:25:15.245 --> 03:25:17.299
.  You compute the norm of that 
ten vector elements and divide 

03:25:17.300 --> 03:25:19.948
everything by its norm.  The 
effect of that since exponential

03:25:22.190 --> 03:25:24.190
is very steeply increasing 
function is 

03:25:25.246 --> 03:25:27.312
that it will pull the winner 
apart.  I made a little 

03:25:27.313 --> 03:25:30.990
animation to show you like this.
This is after Softmax.  This is 

03:25:30.991 --> 03:25:32.991
before Softmax.

03:25:35.439 --> 03:25:37.439
So, you see

03:25:40.016 --> 03:25:41.441
much clearer which of those 
neurons is indicating the 

03:25:41.442 --> 03:25:43.490
winning class.  That's why it's 
called Softmax.

03:25:47.789 --> 03:25:50.037
It pulls the winner apart like a
max but it doesn't completely 

03:25:50.038 --> 03:25:52.299
destroy the animation, that's 
why it's the soft version of 

03:25:52.300 --> 03:25:54.300
max.
Okay.

03:25:57.710 --> 03:25:57.756
So just quick application to 
that we can build the stuff we 

03:25:57.757 --> 03:26:03.406
want to build.  So, now, coming 
out of our neural network, we 

03:26:03.407 --> 03:26:05.451
have let's say ten final neurons
producing values which have been

03:26:06.068 --> 03:26:07.897
normalized between zero and one.
We can say those values are 

03:26:07.898 --> 03:26:10.579
probabilities.  Okay?  The 
probability of this image being 

03:26:10.580 --> 03:26:12.580
in this class.

03:26:18.406 --> 03:26:19.634
How are we going to determine 
the weights in those weighted 

03:26:19.635 --> 03:26:21.635
sums?  Initially, it's all just,
you know, random.

03:26:24.778 --> 03:26:26.778
So, initially, our network 
doesn't do 

03:26:27.794 --> 03:26:29.794
anything

03:26:32.806 --> 03:26:36.900
actually so useful.  We do this 
through supervised learning so 

03:26:36.901 --> 03:26:38.795
you provide images which you 
have labeled beforehand, you 

03:26:38.796 --> 03:26:40.796
know what they are.

03:26:42.063 --> 03:26:43.487
And of those images, your 
network is going to output this 

03:26:43.488 --> 03:26:47.593
set of probabilities but you 
know what the correct answer is 

03:26:47.594 --> 03:26:50.885
because you are doing supervised
learning.  So, you will encode 

03:26:50.886 --> 03:26:54.801
your correct answer in a format 
that looks like what the network

03:26:54.802 --> 03:26:57.883
is producing.  It's the simplest
encoding you can think of.

03:27:02.173 --> 03:27:03.184
It's called one-hot encoding and
basically it's a bunch of zeros 

03:27:03.185 --> 03:27:05.832
with just 11 in the middle at 
the index of the class you want.

03:27:09.104 --> 03:27:11.132
So, here, to represent six, I 
have a vector of zeros with a 

03:27:11.133 --> 03:27:13.133
one in the six position.

03:27:14.662 --> 03:27:16.496
And now, those vectors look very
similar.  I can compute the 

03:27:16.497 --> 03:27:18.497
distance between.  Them.

03:27:20.366 --> 03:27:22.366
And the people who studied this 
in a 

03:27:23.445 --> 03:27:26.926
classifier, they tell us don't 
choose any distance.  Use the  

03:27:26.927 --> 03:27:30.456
cross-entropy distance.  Why?  I
don't know.  They are smarter 

03:27:30.457 --> 03:27:32.457
than me.  I just follow.

03:27:36.201 --> 03:27:38.201
And the cross-entropy distance 
is 

03:27:39.592 --> 03:27:41.807
computed like this so you 
multiply element by element, the

03:27:41.808 --> 03:27:46.290
elements of the vector, the 
known answer from the top by the

03:27:49.064 --> 03:27:53.749
logarythm.  You just sum that up
across the vector.  This is the 

03:27:53.750 --> 03:27:55.195
distance between what the 
network has predicted and the 

03:27:55.196 --> 03:27:58.690
correct answer.  That's what you
want if you want to train a 

03:27:58.691 --> 03:28:00.691
neural network.

03:28:01.780 --> 03:28:04.854
You get this, called an error 
function or loss function.  From

03:28:04.855 --> 03:28:06.285
there on, TensorFlow can take 
over and do the training for 

03:28:06.286 --> 03:28:08.541
you.  You just need an error 
function.

03:28:31.817 --> 03:28:33.647
--
And the error function that we 

03:28:33.648 --> 03:28:37.147
are going to use is the 
cross-entropy error function 

03:28:37.148 --> 03:28:39.172
that I have on the previous 
slide.  Okay?  All good on this?

03:28:40.594 --> 03:28:42.594
Bit of code.

03:28:44.709 --> 03:28:46.546
This is how you would write it 
in TensorFlow so there is a high

03:28:46.547 --> 03:28:48.599
level API in TensorFlow called 
layers where you 

03:28:52.285 --> 03:28:54.285
can instantiate an entire layer 
at once.

03:28:56.551 --> 03:28:58.551
You see

03:29:05.643 --> 03:29:08.507
I instantiate the first layer, 
has 200 neurons and is activated

03:29:08.508 --> 03:29:11.610
by the RELU here.  This also 
instantiates weights and biases 

03:29:11.611 --> 03:29:13.452
in the background.  You don't 
see that.  It's in the 

03:29:13.453 --> 03:29:15.453
background.

03:29:16.983 --> 03:29:18.205
I have a second layer here, 
which this one is just 20 

03:29:18.206 --> 03:29:22.904
neurons.  Again, early 
activation function, and this, I

03:29:22.905 --> 03:29:25.642
need to do this little final 
layer so it's a dense layer 

03:29:25.643 --> 03:29:29.736
again with two neurons, and even
if you don't see it on the 

03:29:29.737 --> 03:29:31.737
screen, it is activated by 

03:29:33.624 --> 03:29:36.289
Softmax, but you don't see it 
because I use its outputs in the

03:29:36.290 --> 03:29:40.558
cross-entropy function which has
Softmax build ten.  It is a 

03:29:40.559 --> 03:29:43.841
Softmax layer.  It's just that 
you don't see written Softmax in

03:29:43.842 --> 03:29:45.842
the code.

03:29:48.578 --> 03:29:50.578
Finally, this here is my error 

03:29:52.686 --> 03:29:54.686
function which is the distance 
between 

03:29:56.736 --> 03:29:58.803
the correct answer here, one-hot
encoded, and the output from my 

03:29:58.804 --> 03:30:01.047
neural network.  Once I have 
that, I can give it to 

03:30:03.488 --> 03:30:06.350
TensorFlow, pick an optimizer, 
ask it to optimize this loss and

03:30:06.351 --> 03:30:08.351
the magic will happen.  So, what
is this magic?

03:30:12.652 --> 03:30:14.508
TensorFlow will take this error 
function, differentiate it 

03:30:14.509 --> 03:30:16.509
relatively to 

03:30:18.568 --> 03:30:20.458
all the weights and all the 
biases, all the trainable 

03:30:20.459 --> 03:30:22.459
variables in the system, and 
that gives it something that is 

03:30:23.331 --> 03:30:26.202
mathematically called a 
gradient.  And by following this

03:30:26.203 --> 03:30:30.707
gradient, it can figure out how 
to adjust the weights and biases

03:30:30.708 --> 03:30:35.043
in the neural network in a way 
that makes this error smaller.  

03:30:35.044 --> 03:30:36.723
That makes the difference 
between what the network 

03:30:36.724 --> 03:30:40.174
predicts and what we know to be 
true smaller.  That's supervised

03:30:40.175 --> 03:30:42.175
learning.

03:30:48.159 --> 03:30:52.064
So that was the primer.  Now, 
what do we want to build?  

03:30:52.065 --> 03:30:54.065
Today, we would like with you to
build 

03:30:56.535 --> 03:30:58.535
a neural network that plays the 
game of pong.

03:31:03.927 --> 03:31:06.586
But just from the pixels of a 
game.  It's  notoriously 

03:31:06.587 --> 03:31:08.647
difficult to explain to a 
computer the rules of I game, 

03:31:08.648 --> 03:31:11.513
the strategy, all that.  So you 
want to do away with all of 

03:31:13.956 --> 03:31:15.436
that, give it the pixels and 
find some learning algorithm 

03:31:15.437 --> 03:31:17.673
where it will learn to play this
game.  And of course, that the 

03:31:17.674 --> 03:31:19.674
not the goal 

03:31:21.158 --> 03:31:23.396
in itself because figuring out 
how to program a paddle to win 

03:31:23.397 --> 03:31:25.641
pong is super easy.  You just 
always stay in front of the 

03:31:26.256 --> 03:31:28.522
ball, you know?  And you win all
the time.

03:31:32.201 --> 03:31:34.201
And actually, we will train 
again such 

03:31:37.107 --> 03:31:39.107
a computer controlled agent

03:31:41.887 --> 03:31:43.305
.  The goal here is to explore 
learning algorithms because this

03:31:43.306 --> 03:31:45.306
has applications, hopefully, way
beyond pong.

03:31:46.786 --> 03:31:49.059
So, this looks like a 
classifier.  We just learned how

03:31:49.060 --> 03:31:52.539
to build a classifierment of we 
have the pixels.  We will build 

03:31:52.540 --> 03:31:56.267
a neural network and it has 
three possible outcomes.  This 

03:31:56.268 --> 03:31:58.506
is a position in which you want 
to go up, stay still, or you 

03:31:58.507 --> 03:32:02.234
want to go down.  Okay. Let's 
try to do this by the book in a 

03:32:02.235 --> 03:32:04.235
classifier.

03:32:06.153 --> 03:32:08.153
So, we have a single 
intermediate 

03:32:09.212 --> 03:32:12.100
layer of neurons, activated with
the RELU, of course, and then a 

03:32:12.101 --> 03:32:14.961
last layer where there's three 
neurons activated by Softmax.

03:32:18.472 --> 03:32:20.472
We use the cross-entropy loss, 
so you have the function here.

03:32:24.209 --> 03:32:26.240
It's the distance between the 
probabilities that this policy 

03:32:26.241 --> 03:32:28.241
network, 

03:32:32.137 --> 03:32:34.137
it's called a policy network, 
predicts

03:32:37.756 --> 03:32:38.566
.  Probability of going up, 
going down, and the correct 

03:32:38.567 --> 03:32:41.640
move.  But, what is the correct 
move?  I don't know.  Do you 

03:32:41.641 --> 03:32:43.641
know?  Yu-Han?

03:32:46.772 --> 03:32:49.611
&gt;&gt; YU-HAN LIU: No, Martin, 
you're exactly right here.  

03:32:49.612 --> 03:32:51.456
Unlike in the supervised 
learning problem, we actually 

03:32:51.457 --> 03:32:54.711
don't know what's the correct 
move to play here.  However, the

03:32:54.712 --> 03:32:57.384
environment requires that we 
keep making moves of going up or

03:32:58.608 --> 03:33:01.267
staying still or moving down to 
progress again.  So what we're 

03:33:01.268 --> 03:33:03.268
going to do is sample 

03:33:04.579 --> 03:33:06.448
the move which means picking one
of the three possible moves of 

03:33:06.449 --> 03:33:11.137
moving the pedal up, staying 
still or going down randomly.  

03:33:11.138 --> 03:33:12.357
But not completely randomly, 
though, we're going to pick the 

03:33:12.358 --> 03:33:14.358
move based on the output of the 
network.

03:33:16.256 --> 03:33:18.256
So, for example, if the network 
says 

03:33:19.517 --> 03:33:21.788
the output probability of going 
up is 0.8 then we should plaque 

03:33:21.789 --> 03:33:25.858
it so that there's 80 percent 
chance we choose to move up as 

03:33:25.859 --> 03:33:29.348
our next move.
&gt;&gt; MARTIN GORNER: All right so. 

03:33:29.349 --> 03:33:31.012
Now we know how to play the 
game.  The policy network gives 

03:33:31.013 --> 03:33:34.703
us probabilities, we're all 
loaded dice and pick from that 

03:33:34.704 --> 03:33:36.704
and we know what next move to 
play.

03:33:39.798 --> 03:33:41.434
But initially, this network is 
initialized with random weights 

03:33:41.435 --> 03:33:43.435
so it will be playing random 
moves.

03:33:47.189 --> 03:33:50.049
How does that inform us about 
the correct move to play.  I 

03:33:50.050 --> 03:33:52.050
need to put the correct move in 
my formula.

03:33:52.486 --> 03:33:54.780
&gt;&gt; YU-HAN LIU: That's right.  
So, in this case, we really want

03:33:54.781 --> 03:33:59.713
the correct move to mean moves 
that will lead to winning.  We 

03:33:59.714 --> 03:34:01.555
don't know that until someone 
has scored a point, so that's 

03:34:01.556 --> 03:34:05.051
what we're going to do.  Only 
when someone either our panel or

03:34:06.914 --> 03:34:08.735
the other panel has scored a 
point do we know if we've played

03:34:08.736 --> 03:34:10.736
well or not.  So whenever 
somebody scores, we're 

03:34:14.235 --> 03:34:17.083
going to give ourselveses a 
reward.  If our pedal scores a 

03:34:17.084 --> 03:34:21.788
point we'll give ourselves a 
positive one reward point and if

03:34:21.789 --> 03:34:24.435
the opponent scores then we give
ourselves a negative one reward 

03:34:24.436 --> 03:34:27.531
point, then we're going to 
structure or losses slightly 

03:34:27.532 --> 03:34:29.532
different than before.

03:34:36.580 --> 03:34:38.210
Over here, you see some, a loss 
function very much like the 

03:34:38.211 --> 03:34:41.095
cross function we saw before.  
Now, in the middle here is the 

03:34:41.096 --> 03:34:44.339
main difference where instead of
the correct label in supervised 

03:34:44.340 --> 03:34:46.340
learning problem, 

03:34:48.422 --> 03:34:50.422
we're just going to put the 
sampled move in here.

03:34:51.692 --> 03:34:53.692
The move that we happen to play.

03:34:54.707 --> 03:34:56.707
And

03:34:58.103 --> 03:34:59.750
some of the moves might not be 
moves that will help us and 

03:34:59.751 --> 03:35:02.403
that's why every loss value is 
multiplied by the reward out 

03:35:02.404 --> 03:35:06.698
front.  This way moves that 
eventually lead to a winning 

03:35:06.699 --> 03:35:08.699
point will get encouraged and 

03:35:10.384 --> 03:35:11.602
moves that lead to a losing 
points will be discouraged over 

03:35:11.603 --> 03:35:13.669
time.
&gt;&gt; MARTIN GORNER: Okay. So you 

03:35:13.670 --> 03:35:15.670
do this for every move.  I can 
see how with this little 

03:35:17.348 --> 03:35:20.027
modification it could lead to 
some learning but putting back 

03:35:20.028 --> 03:35:24.754
my mathematician's hat on, I see
a big problem here.  You have 

03:35:24.755 --> 03:35:27.221
this sampled move.  That is a 
picking operation, the sampling 

03:35:27.222 --> 03:35:29.222
operation.

03:35:32.265 --> 03:35:34.265
You pick one out of three.

03:35:35.956 --> 03:35:40.960
That is not differentiable.  To 
apply the minimization and 

03:35:40.961 --> 03:35:42.961
gradient 

03:35:45.664 --> 03:35:47.664
and all that, the loss function 
must be differentiable.

03:35:47.713 --> 03:35:48.527
&gt;&gt; YU-HAN LIU: You're right, 
partner, asking the hard 

03:35:48.528 --> 03:35:53.463
question here.  The simple move 
here actually does depend on the

03:35:53.464 --> 03:35:55.281
model's weights and biases but 
the simple operation is not 

03:35:55.282 --> 03:35:59.577
differentiable.  So we're not 
going to differentiate that.  

03:35:59.578 --> 03:36:01.828
Instead, we're going to look at 
sampled moves as if they are 

03:36:01.829 --> 03:36:06.308
constant and then we play many 
games across many, many moves to

03:36:06.309 --> 03:36:08.999
get a lot of data, treating all 
of these sample moves as if 

03:36:13.228 --> 03:36:15.228
they're constant and only 
differentiating the 

03:36:15.791 --> 03:36:17.219
probabilities that are output by
the model in blue here on the 

03:36:17.220 --> 03:36:19.220
screen and those probabilities 
directly depend on 

03:36:21.730 --> 03:36:23.730
the models ways and biases, and 
we can differentiate those.

03:36:27.270 --> 03:36:29.270
With respect to the ways and 
biases 

03:36:31.547 --> 03:36:33.002
are respect to the gradient, 
looking at gradient techniques.

03:36:33.003 --> 03:36:36.277
&gt;&gt; MARTIN GORNER: Okay. So you 
kind of cheated.  The part that 

03:36:36.278 --> 03:36:40.143
is automatic just regarded as 
constant you're going to play 

03:36:40.144 --> 03:36:42.628
many games with the same neural 
network, accumulate those plate 

03:36:42.629 --> 03:36:45.884
moves, accumulate those rewards.
Whenever you know that you 

03:36:45.885 --> 03:36:51.253
scored a point, you accumulate 
those rewards and then you plug 

03:36:51.254 --> 03:36:53.488
that in and you only 
differentiate relative to the 

03:36:53.489 --> 03:36:56.748
predictive probabilities.  Yes, 
you're right.  That still gives 

03:36:56.749 --> 03:36:58.749
you a greatent that 

03:37:00.055 --> 03:37:02.055
depends on weights and biases so
we 

03:37:03.205 --> 03:37:05.205
should be able to do that.
Okay. I get it.  This is clever.

03:37:06.323 --> 03:37:07.739
So, this will actually train 
probably very slowly.  Here, we 

03:37:07.740 --> 03:37:09.740
want to show you the minimum 

03:37:10.829 --> 03:37:13.486
amount of stuff you need to do 
to get it to train.  But in the 

03:37:13.487 --> 03:37:15.723
minimal amount, there are still 
two little improvements that you

03:37:16.533 --> 03:37:18.533
always want to do.

03:37:19.794 --> 03:37:21.794
The first one is to discount the
rewards.

03:37:24.029 --> 03:37:26.029
So,

03:37:28.643 --> 03:37:30.684
probably if you lost a point, 
you did something wrong in the 

03:37:30.685 --> 03:37:32.685
three, five, 

03:37:34.015 --> 03:37:35.845
seven moves right before you 
lost that point and probably 

03:37:35.846 --> 03:37:39.708
before that you bounced the ball
correctly a couple of times.  

03:37:39.709 --> 03:37:41.709
And that was correct.

03:37:43.380 --> 03:37:45.380
You don't want to discourage 
that.

03:37:47.481 --> 03:37:49.324
So it's customary to discount 
the rewards backwards through 

03:37:49.325 --> 03:37:53.028
time with some factor so that 
the moves you play closest to 

03:37:53.029 --> 03:37:55.029
the scoring point are the ones 
that count the most.

03:37:57.122 --> 03:37:59.587
So, you see the, here we 
discounted them with a factor of

03:37:59.588 --> 03:38:01.588
one half, for instance.

03:38:05.151 --> 03:38:06.796
And then there is this 
normalization steps.  What is 

03:38:06.797 --> 03:38:08.797
that?

03:38:09.816 --> 03:38:13.912
&gt;&gt; YU-HAN LIU: That, that's very
interesting.  So, in experiments

03:38:13.913 --> 03:38:15.767
we noticed putting in the 
normalization really helps 

03:38:15.768 --> 03:38:19.252
training.  There are multiple 
ways to think about this.  The 

03:38:19.253 --> 03:38:20.675
way I like to think about this 
is in the context of playing the

03:38:20.676 --> 03:38:24.564
game.  You see, at the beginning
of the time the model only had 

03:38:24.565 --> 03:38:26.565
the randomized ways 

03:38:27.839 --> 03:38:29.273
and biases so it's going to mawk
random moves but most of the 

03:38:29.274 --> 03:38:32.803
time it's not going to make the 
right move.  Only once in a 

03:38:32.804 --> 03:38:36.460
while it's going to score a 
chance by accident.  Most of the

03:38:36.461 --> 03:38:38.461
time it's going to lose pointses
and we want to find a way to 

03:38:40.145 --> 03:38:42.424
naturally put more weight to the
very rare winning moves there so

03:38:42.425 --> 03:38:46.373
they can learn other corrective 
moves and performing this 

03:38:46.374 --> 03:38:48.606
normalizing and reward steps 
here naturally gives a very nice

03:38:50.456 --> 03:38:52.136
boost to the rare winning move 
so it does not get lost in a ton

03:38:52.137 --> 03:38:53.954
of losing moves.
&gt;&gt; MARTIN GORNER: Okay. So let's

03:38:53.955 --> 03:38:55.955
go.  Let's train this.

03:38:59.402 --> 03:39:01.886
We need to play the game and 
accumulate enough data to 

03:39:01.887 --> 03:39:05.139
compute this everything we need 
for this function here.  Okay?  

03:39:05.140 --> 03:39:07.140
So those are the sampled moves.

03:39:09.015 --> 03:39:10.031
We need the rewards and we also 
need those probabilities which 

03:39:10.032 --> 03:39:12.032
the network 

03:39:14.901 --> 03:39:17.450
can compute from us from the 
pixels so we are going to 

03:39:17.451 --> 03:39:19.451
collect the pixels during game 
play.

03:39:26.475 --> 03:39:28.475
That's how our collected data 
set looks like.

03:39:31.210 --> 03:39:31.271
You have one column with the 
move you actually played.  One 

03:39:31.272 --> 03:39:33.272
column where you would like to 
see 

03:39:34.484 --> 03:39:35.409
the probabilities predicted at 
that point but you are actually 

03:39:35.410 --> 03:39:37.410
going to store just the game 
board and run the 

03:39:38.672 --> 03:39:41.326
network to get the probabilities
and the last column with 

03:39:41.327 --> 03:39:43.785
rewards.
You see there is a plus one or 

03:39:43.786 --> 03:39:48.279
minus one reward on every move 
that scored a point and all the 

03:39:48.280 --> 03:39:50.280
other moves, you discount 

03:39:52.583 --> 03:39:54.583
that reward backwards in time 
with some exponential discount.

03:39:58.653 --> 03:40:00.653
And once you have this

03:40:02.211 --> 03:40:04.211
maybe you notice in the formula 
you 

03:40:05.494 --> 03:40:07.730
just multiply those three 
columns together and sum all of 

03:40:07.731 --> 03:40:09.731
that, that's how the loss 
computed.  Let's build it.

03:40:13.998 --> 03:40:15.998
You implemented this

03:40:18.407 --> 03:40:19.224
demo is can you walk us through 
the code?

03:40:19.225 --> 03:40:21.225
&gt;&gt; YU-HAN LIU: Let's do that.

03:40:23.128 --> 03:40:25.772
So up here, you see a few 
TensorFlow place holders.  You 

03:40:25.773 --> 03:40:27.192
should really think of them as 
functional arguments that are 

03:40:27.193 --> 03:40:29.193
required 

03:40:30.865 --> 03:40:32.865
to compute alpha values for 
model.

03:40:34.561 --> 03:40:36.217
So with three place holders for 
input, one for observation, 

03:40:36.218 --> 03:40:38.218
really this means the difference
between two consecutive 

03:40:41.381 --> 03:40:42.793
frames in an instance.
&gt;&gt; MARTIN GORNER: Yeah we didn't

03:40:42.794 --> 03:40:47.396
say that.  Just from the game of
pong you don't train from the 

03:40:47.397 --> 03:40:49.427
pixels because you don't see the
direction of the ball from the 

03:40:51.269 --> 03:40:52.701
pixels but you train from the 
Delta of two frames because 

03:40:52.702 --> 03:40:55.409
there you see the direction of 
the ball.  That's the only 

03:40:55.410 --> 03:40:58.271
wrinkle we're doing here 
specific to pong.  All the rest 

03:40:58.272 --> 03:41:00.145
is reinforcement learning that 
applies to many other problems.

03:41:00.146 --> 03:41:04.059
&gt;&gt; YU-HAN LIU: That's right and 
for the actions place holder, 

03:41:04.060 --> 03:41:07.122
it's just going to hold all the 
sampled move.  The moves that 

03:41:07.123 --> 03:41:09.780
the model happen to decide to 
play, and the rewards place 

03:41:12.095 --> 03:41:14.136
holder will collect all the 
discounted rewards.  Now, with 

03:41:14.137 --> 03:41:16.137
those as inputs ready to build 
the model, the network is really

03:41:19.048 --> 03:41:21.048
simple like the one Martin 
showed before.

03:41:22.994 --> 03:41:25.845
It has a single dense layer, a 
single dense hidden layer with 

03:41:25.846 --> 03:41:27.846
the activation 

03:41:29.558 --> 03:41:31.202
of the RELU function, 200 
neurons, followed by a Softmax 

03:41:31.203 --> 03:41:33.203
layer.

03:41:35.704 --> 03:41:36.908
You don't really see calling a 
Softmax function here and that's

03:41:36.909 --> 03:41:39.724
really because the next step, 
the sampling operation already 

03:41:39.725 --> 03:41:41.725
takes in values you get before 

03:41:43.226 --> 03:41:45.226
you close off max function and 
it can 

03:41:46.390 --> 03:41:48.211
perform multinomial sampling 
which just means you output a 

03:41:48.212 --> 03:41:50.212
random number of 

03:41:51.460 --> 03:41:53.510
zero, one, or two for the three 
classes we need output based on 

03:41:53.511 --> 03:41:57.837
the probabilities specifyied.
&gt;&gt; MARTIN GORNER: And this one 

03:41:57.838 --> 03:41:59.838
has the Softmax built in.

03:42:02.995 --> 03:42:04.015
So this is a Softmax layer, you 
don't see it on the code but it 

03:42:04.016 --> 03:42:06.016
is.

03:42:08.550 --> 03:42:10.187
Just a parenthesis for those not
familiar with TensorFlow, 

03:42:10.188 --> 03:42:12.188
TensorFlow builds a node or 
graph with operations 

03:42:14.915 --> 03:42:16.915
in the memory so that's why out 
of 

03:42:18.416 --> 03:42:21.082
multinomial we get an operation 
and then we will have an 

03:42:21.083 --> 03:42:23.083
additional step to run it and 
actually get those predictions 

03:42:24.364 --> 03:42:25.774
out and place holders are data 
you need to put in when you 

03:42:25.775 --> 03:42:28.419
actually run a note to be able 
to get a numerical result out.

03:42:28.420 --> 03:42:30.420
Okay.

03:42:32.857 --> 03:42:36.622
So we have everything we need to
play the game.  Still nothing to

03:42:36.623 --> 03:42:40.109
train.  So, let's do the 
training part.  For training, we

03:42:40.110 --> 03:42:42.110
need a loss function.

03:42:44.136 --> 03:42:46.136
So, our beloved

03:42:49.087 --> 03:42:51.087
cross entropy loss function 
computing 

03:42:53.122 --> 03:42:53.173
the distance between our 
actions, so the moves we 

03:42:53.174 --> 03:42:55.185
actually plate, and logics which
are from the previous screen, 

03:42:55.915 --> 03:42:57.915
that's what the network predicts
from the pixels.

03:43:04.114 --> 03:43:05.932
And then we modify it using the 
reinforcement learning paradigm,

03:43:05.933 --> 03:43:07.933
we 

03:43:11.187 --> 03:43:13.484
modify it by multiplying this 
per move loss by rewards, by the

03:43:13.485 --> 03:43:19.249
per move rewards.  And now with 
those rewards, moves, leading to

03:43:19.250 --> 03:43:21.250
a scoring point will be 
encouraged.

03:43:24.568 --> 03:43:27.833
Moves leading to a losing point 
will be discouraged.  So now we 

03:43:27.834 --> 03:43:29.834
have our error function, 
TensorFlow can take over.

03:43:30.995 --> 03:43:33.016
We pick one of the optimizers in
the library and simply ask this 

03:43:33.017 --> 03:43:35.017
optimizer to minimize our loss 
function which gives 

03:43:39.503 --> 03:43:41.503
us a training operation

03:43:46.553 --> 03:43:48.819
.  We will on the next slide run
this training operation feeding 

03:43:48.820 --> 03:43:53.184
in all the data we collected 
during game play, that is where 

03:43:53.185 --> 03:43:55.003
the gradient will be completed 
and that's the run that will 

03:43:55.004 --> 03:43:57.004
modify the weights and biases in
our policy network.

03:43:57.882 --> 03:44:00.536
So, let's play this game.  This 
is what you need to do to play 

03:44:02.758 --> 03:44:04.758
one game in 21 points.

03:44:12.684 --> 03:44:13.503
So the technical wrinkle is in 
TensorFlow if you want to 

03:44:13.504 --> 03:44:17.595
execute one of those operations 
you need a session, so we do a 

03:44:17.596 --> 03:44:19.596
session and we play the game.

03:44:21.478 --> 03:44:23.300
First we play the game stage, 
complete the Delta between two 

03:44:23.301 --> 03:44:26.409
frames.  Okay. That's technical.
And then run this sample 

03:44:26.410 --> 03:44:28.410
operation.  Remember, sample 
operation is what we 

03:44:32.484 --> 03:44:35.806
got from our picking multinomial
function.  So, that's what 

03:44:35.807 --> 03:44:37.807
decides the next move to play.

03:44:41.051 --> 03:44:43.051
Then we use

03:44:47.264 --> 03:44:49.264
a pong simulator here from open 
AI gem.

03:44:51.785 --> 03:44:53.819
We can use the mode it play, 
give us a reward if we score, 

03:44:53.820 --> 03:44:56.090
and give us information on 
whether this 21 game is 

03:44:56.293 --> 03:44:59.967
finishes.
That's all we need.  Now we 

03:44:59.968 --> 03:45:02.620
simply log that stuff.  We log 
the pixels, the move we played, 

03:45:03.867 --> 03:45:05.929
the reward if we got one.  So we
know how to play one game and we

03:45:08.574 --> 03:45:10.808
will play many of those games to
collect a large backlog of 

03:45:10.809 --> 03:45:14.068
moves, right?
&gt;&gt; YU-HAN LIU: That's right.  

03:45:14.069 --> 03:45:16.214
Playing DMs in reinforcement 
learning or in our experiment 

03:45:16.215 --> 03:45:19.496
really is a way of collecting 
data.  Now that we have 

03:45:19.497 --> 03:45:22.596
collected a lot of data, playing
one game, only ten games, why 

03:45:22.597 --> 03:45:27.298
not.  We can start processing 
rewards as we plan to.  We'll 

03:45:27.299 --> 03:45:29.557
discount the rewards so that a 
move stuff did not get any 

03:45:29.558 --> 03:45:33.857
reward during game play, now 
gets a discounted reward based 

03:45:33.858 --> 03:45:35.858
on whether or not they 
eventually 

03:45:37.165 --> 03:45:38.577
led to winning or losing points 
and how far they are from the 

03:45:38.578 --> 03:45:41.232
moves actually one or loss a 
point and then we normalize 

03:45:42.061 --> 03:45:44.107
rewards such as before.  Now 
we're ready.  We have all the 

03:45:44.108 --> 03:45:46.108
data in place.  We have 
observations, that's the 

03:45:47.179 --> 03:45:49.620
differences between game frames.
The actions that we have and the

03:45:51.485 --> 03:45:53.346
reward so that we know if those 
actions were good or bad, and 

03:45:53.347 --> 03:45:57.258
then we're ready to call the 
training op.  And training op is

03:45:57.259 --> 03:46:01.140
what we saw a couple slides 
before where we had optimized 

03:46:01.141 --> 03:46:02.967
already initialized and this 
going to do the heavy lifting 

03:46:02.968 --> 03:46:07.130
and compute the gradients for us
and modify the weights just 

03:46:07.131 --> 03:46:09.131
slightly.

03:46:10.802 --> 03:46:12.802
Suppose we play ten games, 
modify the 

03:46:16.356 --> 03:46:20.422
weight slightly, play more games
and get even more data.  And 

03:46:16.356 --> 03:46:18.356
repeat the process.  The 
expectation or the hope is that 

03:46:19.477 --> 03:46:20.483
the model will learn to play a 
little bit better all the time.

03:46:20.484 --> 03:46:24.989
&gt;&gt; MARTIN GORNER: I'm a bit 
skeptical.  Do you really think 

03:46:24.990 --> 03:46:27.021
this is going to work?
&gt;&gt; YU-HAN LIU: Well sometimes we

03:46:27.022 --> 03:46:29.545
see the model turn into player a
little bit worse so we'll see.

03:46:29.546 --> 03:46:31.546
&gt;&gt; MARTIN GORNER: Okay. Live 
demo?

03:46:32.229 --> 03:46:35.102
&gt;&gt; YU-HAN LIU: Live demo.
&gt;&gt; MARTIN GORNER: Let's go.  

03:46:35.103 --> 03:46:37.103
Let's run this game.

03:46:41.492 --> 03:46:43.492
So this is a live demo.

03:46:44.588 --> 03:46:48.460
I'm not completely sure that we 
are going to win but we'll see. 

03:46:48.461 --> 03:46:50.461
So, brown on this side is the 
computer controlled  paddle.

03:46:52.540 --> 03:46:53.952
Very simple algorithm, just 
stays in front of the ball at 

03:46:53.953 --> 03:46:55.953
all times.  There's only up with
way to win.

03:46:58.526 --> 03:47:00.970
Vertical velocity is limited so 
you have to hit the ball on the 

03:47:00.971 --> 03:47:05.733
very side of the paddle to send 
it at a very steep angle and 

03:47:05.734 --> 03:47:07.204
then you can overcome the 
vertical velocity of the 

03:47:07.205 --> 03:47:09.205
opponent.

03:47:12.264 --> 03:47:14.264
That's the open way to score

03:47:16.815 --> 03:47:18.243
.  On the right in green, we 
have our neural network 

03:47:18.244 --> 03:47:20.526
controlled agents and it's 
slightly behind now so we'll see

03:47:20.527 --> 03:47:24.804
if it wins.  And if you wanted, 
I want this side of the room to 

03:47:24.805 --> 03:47:28.269
cheer for brown and this side of
the room to cheer for AI.  Okay?

03:47:31.325 --> 03:47:33.325
It is very even right now.

03:47:37.202 --> 03:47:39.202
One -- yeah, go, go, go.

03:47:40.412 --> 03:47:42.250
(cheering)
&gt;&gt; MARTIN GORNER: AI is winning.

03:47:42.251 --> 03:47:46.570
AI is winning.  I'm happy 
because this is a live demo.  

03:47:46.571 --> 03:47:48.819
There is no guarantee that AI 
will actually win.  One thing 

03:47:48.820 --> 03:47:50.820
that is interesting here, 

03:47:52.535 --> 03:47:54.622
actually, is that  you, this is 
learning from just a pixels.

03:47:58.959 --> 03:48:01.190
So, initially, the AI had no 
idea of even what game is was 

03:48:01.191 --> 03:48:03.191
playing, what the rules were.

03:48:05.101 --> 03:48:07.342
It had even no idea which paddle
it was playing, okay?  And we 

03:48:07.343 --> 03:48:09.343
didn't have to explain that.

03:48:10.400 --> 03:48:13.251
We just gave the pixels and on 
scoring pointses we give a 

03:48:13.252 --> 03:48:16.377
positive or a negative reward 
and that's it.  From that it 

03:48:16.378 --> 03:48:20.758
learns.  And you see those 
emerging strategies.  Like what 

03:48:20.759 --> 03:48:22.759
I said, hitting the ball on 

03:48:25.077 --> 03:48:27.120
the side and sending it at a 
very steep angle is the only way

03:48:27.121 --> 03:48:30.600
of winning and it picked that 
up.  We never explained it.  

03:48:30.601 --> 03:48:34.658
It's just an emerging strategy. 
This is looking good.

03:48:35.682 --> 03:48:37.308
&gt;&gt; YU-HAN LIU: Pretty close.  
Yeah.

03:48:37.309 --> 03:48:38.767
&gt;&gt; MARTIN GORNER: It's looking 
good.  It's a bit close but 

03:48:38.768 --> 03:48:41.635
looking good.  You think we'll 
win?  Okay.

03:48:44.745 --> 03:48:46.176
Next point I want a loud cheer 
when AI wins because I hope this

03:48:46.177 --> 03:48:48.616
is going to work.
(groaning)

03:48:50.859 --> 03:48:52.289
(cheering)
&gt;&gt; MARTIN GORNER: Hey 20, one 

03:48:52.290 --> 03:48:55.563
more.  Yay, we won!
&gt;&gt; YU-HAN LIU: We've done it.

03:48:58.643 --> 03:48:59.913
&gt;&gt; MARTIN GORNER: Good job, 
Yu-Han.  This is fantastic.  All

03:48:59.914 --> 03:49:01.914
right.

03:49:04.743 --> 03:49:06.743
So, what was going on

03:49:19.382 --> 03:49:23.955
during game play?  Remember how 
the network was built?  Remember

03:49:23.956 --> 03:49:26.802
neurons first have a weight for 
every pixel and it's fairly easy

03:49:26.803 --> 03:49:29.867
to represent those weights on 
the board and see what those 

03:49:29.868 --> 03:49:31.868
neurons are seeing on the board.

03:49:34.105 --> 03:49:36.105
So,

03:49:39.763 --> 03:49:41.763
let's try to do that right here.

03:49:44.179 --> 03:49:46.959
We picked eight of those 200 
neurons and here we visualize 

03:49:48.367 --> 03:49:49.997
superimpose on the board the 
weights that have been trained 

03:49:49.998 --> 03:49:52.460
and the untrained eye doesn't 
see much here so maybe you can 

03:49:52.461 --> 03:49:54.461
analyze.
&gt;&gt; YU-HAN LIU: This is really 

03:49:54.911 --> 03:49:56.911
interesting, Martin.  We are 
looking at what the model sees 

03:49:59.614 --> 03:50:01.614
so rather what the model cares 
about 

03:50:02.759 --> 03:50:04.959
when it sees the game pixels we 
gave it.  You see one of the 

03:50:04.960 --> 03:50:06.960
neurons has learned pretty much 
nothing.

03:50:08.858 --> 03:50:10.902
It's still looking like white 
noise at the beginning.

03:50:12.937 --> 03:50:14.937
&gt;&gt; MARTIN GORNER: Bad pixel.  
Didn't listen.

03:50:15.778 --> 03:50:19.644
&gt;&gt; YU-HAN LIU: It doesn't 
contribute much to the game play

03:50:15.778 --> 03:50:20.139
but for the other neurons you 
see an interesting pattern.  We 

03:50:20.140 --> 03:50:22.791
see things the model seems to 
put a lot of weight on.  It 

03:50:22.792 --> 03:50:26.894
cares a lot about where the 
panel is, where it's moving.  It

03:50:26.895 --> 03:50:27.704
not cares about the triage 
equity rei across the game 

03:50:27.705 --> 03:50:31.219
board.  Quite interestingly it 
also cares about where its own 

03:50:31.220 --> 03:50:33.220
panel is on the right because 
like Martin pointed out 

03:50:35.701 --> 03:50:37.701
before, at the beginning of 
learning, 

03:50:38.966 --> 03:50:41.428
the model didn't even know which
panel is playing.  It has to 

03:50:41.429 --> 03:50:42.030
learn to remember, that's an 
important piece of information 

03:50:42.031 --> 03:50:46.541
to be able to play a game well. 
When you think about this this 

03:50:46.542 --> 03:50:50.053
is really consistent with how we
humans believe important 

03:50:50.054 --> 03:50:52.282
informations to be able to play 
the game well.

03:50:53.939 --> 03:50:55.939
&gt;&gt; MARTIN GORNER: So we wanted 
to show 

03:51:00.505 --> 03:51:01.727
this to you not to show our 
prowess at pong, although it 

03:51:01.728 --> 03:51:03.728
worked.  But mostly to explore 
training 

03:51:08.017 --> 03:51:10.017
algorithms and you see

03:51:11.371 --> 03:51:12.601
mostly in neural networks you do
supervised training and in 

03:51:12.602 --> 03:51:15.236
nature, sometimes when we teach 
people, it looks like supervised

03:51:15.237 --> 03:51:17.276
training.  Probably in class, 
the teacher says, 

03:51:20.771 --> 03:51:24.251
this is, you know, the Eiffel 
Tower and people say, Okay.  

03:51:24.252 --> 03:51:26.307
That's the Eiffel Tower and so 
on.  But if you think about a 

03:51:26.308 --> 03:51:28.308
kitten 

03:51:31.643 --> 03:51:33.290
jumping on a fur ball and 
missing it and jumping again 

03:51:33.291 --> 03:51:36.138
until it catches it, there is no
teacher there.  It has to figure

03:51:36.139 --> 03:51:38.139
out a sequence of 

03:51:39.211 --> 03:51:40.445
moves and gets a reward from 
catching the ball or not 

03:51:40.446 --> 03:51:44.340
catching it.  So it looks like 
in nature there are multiple 

03:51:44.341 --> 03:51:45.764
ways of training our own neural 
network and one of them is 

03:51:45.765 --> 03:51:49.498
probably quite close to this 
reinforcement learning way of 

03:51:49.499 --> 03:51:51.499
teaching.

03:51:54.628 --> 03:51:56.265
Yu-Han, you built this model.  
Is there some other thought that

03:51:56.266 --> 03:51:58.929
inspired you?
&gt;&gt; YU-HAN LIU: Yeah, I have a 

03:51:58.930 --> 03:52:00.930
sort of 

03:52:02.392 --> 03:52:05.448
technical insight, maybe, for 
you as a takeaway message.  In 

03:52:05.449 --> 03:52:07.449
running experiment, we see that 

03:52:09.122 --> 03:52:11.172
there are some stats which are 
not differentiable.  

03:52:11.173 --> 03:52:13.646
Particularly in this case 
sampling a move of the 

03:52:13.647 --> 03:52:15.253
probability output from the 
network and playing a game 

03:52:15.254 --> 03:52:17.891
getting the rewards back.  Yes, 
those factors really do depend 

03:52:17.892 --> 03:52:19.892
on 

03:52:22.592 --> 03:52:24.633
the model itself but in a 
nondifferentiable way so even 

03:52:24.634 --> 03:52:28.096
with tools like TensorFlow you 
wouldn't be able to build a loss

03:52:28.097 --> 03:52:31.157
function in gradient training 
but there are ways to get around

03:52:31.158 --> 03:52:33.194
it, and that's exactly the 
techniques we're showing today.

03:52:33.195 --> 03:52:36.927
&gt;&gt; MARTIN GORNER: So what you're
saying is that reinforcement 

03:52:36.928 --> 03:52:40.659
learning can solve many more 
problems than just pong and it's

03:52:40.660 --> 03:52:42.496
a way of getting around some 
nondifferential step that you 

03:52:42.497 --> 03:52:48.005
find in your problem.  That's 
great.  That's great.  So where 

03:52:48.006 --> 03:52:50.305
is this going?  We want to show 
you a couple of things 

03:52:54.213 --> 03:52:56.213
from the lab because this has 
had mostly 

03:52:57.332 --> 03:52:59.332
lab applications and then one 
last thing.

03:53:01.682 --> 03:53:02.899
What is  this?
&gt;&gt; YU-HAN LIU: This is very 

03:53:02.900 --> 03:53:04.900
interesting, everyone.

03:53:06.506 --> 03:53:09.201
What we're witnessing here is a 
human expert of pancake flipping

03:53:09.202 --> 03:53:11.202
trying to teach a robotic arm 
doing the same thing.

03:53:16.298 --> 03:53:18.298
And there's a model in the back,
those 

03:53:22.220 --> 03:53:25.148
output controls the joint 
movement.  The goal of this is 

03:53:25.149 --> 03:53:27.149
to flip the 

03:53:28.810 --> 03:53:30.897
pancake and the pancake.  Rather
implemented with sensors, so he 

03:53:33.791 --> 03:53:35.791
knows he's been flipped if it 
landed on 

03:53:37.248 --> 03:53:39.248
the floor or on the table or 
back in the frying pan.

03:53:39.703 --> 03:53:40.720
&gt;&gt; MARTIN GORNER: Doesn't seem 
to be working.

03:53:40.721 --> 03:53:42.764
&gt;&gt; YU-HAN LIU: It's trying.  In 
a common experiment --

03:53:44.234 --> 03:53:45.862
&gt;&gt; MARTIN GORNER: So what is the
reward here?

03:53:45.863 --> 03:53:47.939
&gt;&gt; YU-HAN LIU: The reward 
probably is if you flip a 

03:53:47.940 --> 03:53:49.980
pancake correctly then you get 
positive reward and otherwise 

03:53:50.593 --> 03:53:52.593
negative reward.

03:53:54.051 --> 03:53:55.500
Speaking of reward function, in 
another experiment, I was going 

03:53:55.501 --> 03:53:57.501
to say, the experimenters set 
the reward to be a 

03:54:00.472 --> 03:54:02.719
small amount of positive reward 
for any moment the pan kick a is

03:54:02.720 --> 03:54:04.720
not on the 

03:54:05.973 --> 03:54:07.973
floor and that machine, the way 
it 

03:54:09.026 --> 03:54:11.026
learned was to fling the pancake
as high 

03:54:13.102 --> 03:54:15.733
as possible to maximize pancake 
airborne time that way it can 

03:54:15.734 --> 03:54:19.477
maximize reward just because it 
takes a long time to land on the

03:54:19.478 --> 03:54:21.918
floor.
&gt;&gt; MARTIN GORNER: That's kind of

03:54:21.919 --> 03:54:25.602
funny but it's a nice 
illustration of the fact that 

03:54:25.603 --> 03:54:27.275
you can change the learned 
behavior by changing your loss 

03:54:27.276 --> 03:54:29.516
function.
&gt;&gt; YU-HAN LIU: Exactly.  The 

03:54:29.517 --> 03:54:31.517
model learns.  Now you have to 
learn.

03:54:31.598 --> 03:54:33.598
&gt;&gt; MARTIN GORNER: Oh, nice.  
Cool.

03:54:35.927 --> 03:54:37.548
We know how to play pong and 
flip pancakes.  That's 

03:54:37.549 --> 03:54:41.247
significant progress.  Deep mind
also published this video.  So, 

03:54:41.248 --> 03:54:43.248
they used reinforcement learning
and built those skeleton models.

03:54:46.954 --> 03:54:48.954
Here, the neural network is 
predicting 

03:54:50.622 --> 03:54:53.086
the power to send to the 
simulated muscles and joints of 

03:54:53.087 --> 03:54:55.402
these models and the reward is 
basically a positive 

03:55:00.220 --> 03:55:01.265
reward whenever you managed to 
move forward and a negative 

03:55:01.266 --> 03:55:06.285
reward when you even move 
backward or fall through a hole 

03:55:06.286 --> 03:55:08.286
or just chummable to the ground.
The rest is just reinforcement 

03:55:09.108 --> 03:55:11.543
learning as we have shown you 
today so all of these behaviors 

03:55:11.544 --> 03:55:13.544
are emerging behaviors.  Nobody 
taught those models.

03:55:16.271 --> 03:55:18.518
And look, you have some 
wonderful emerging behaviors.  

03:55:18.519 --> 03:55:23.229
It's coming in a couple of 
seconds.  Look at this jump.  

03:55:23.230 --> 03:55:25.268
After this, those are nice 
jumps, but there is a much nicer

03:55:25.269 --> 03:55:27.269
one in a second.

03:55:28.549 --> 03:55:30.592
You will see a jump.  An 
athletic jump with the model 

03:55:33.043 --> 03:55:35.043
swinging arms to get momentum 
then 

03:55:36.758 --> 03:55:38.758
lifting one leg, cushioning 
right here, look at this.

03:55:41.649 --> 03:55:44.335
This is a fantastic athletic 
jump.  It looks like from the 

03:55:44.336 --> 03:55:46.336
Olympics and 

03:55:47.656 --> 03:55:49.656
it's completely emerging 
behavior.

03:55:51.941 --> 03:55:56.278
What is it.
&gt;&gt; YU-HAN LIU: But Martin, if 

03:55:56.279 --> 03:56:00.374
this is optimal way of walking 
around, why do I not see people 

03:56:00.375 --> 03:56:02.268
doing this?
&gt;&gt; MARTIN GORNER: Well, there 

03:56:02.269 --> 03:56:04.946
are multiple ways of running.  
Probably the loss factor didn't 

03:56:04.947 --> 03:56:08.836
have any way of discouraging 
useless movements so again, by 

03:56:08.837 --> 03:56:12.802
modifying the loss function, you
get different behaviors.  And 

03:56:12.803 --> 03:56:14.631
actually one last one, not this 
one, this one is kind of funny, 

03:56:14.632 --> 03:56:16.632
still playing around.

03:56:18.904 --> 03:56:21.778
But, look, here, it's figured 
out how to run sideways of the 

03:56:21.779 --> 03:56:24.016
this is fantastic.  Yes, there 
are two ways of running and 

03:56:27.100 --> 03:56:28.575
it did figure out how to move 
sideways.

03:56:28.576 --> 03:56:30.576
This one you've probably seen.

03:56:33.671 --> 03:56:35.671
This is move 74 in game 4 of 
alpha go 

03:56:38.389 --> 03:56:40.389
versus Lisa Doll and that's the 
one move 

03:56:42.322 --> 03:56:44.187
that Lisadol played called the 
guard move.  He's world famous 

03:56:44.188 --> 03:56:49.479
for that.  He played one correct
move and managed to win one game

03:56:49.480 --> 03:56:54.425
against alpha go.  He lost four 
to one, which is fantastic.  And

03:56:54.426 --> 03:56:56.426
alpha go also uses reinforcement

03:56:57.930 --> 03:57:00.609
learning, not exactly in the 
same way.  Here it wasn't 

03:57:00.610 --> 03:57:02.849
entirely built out of 
reinforcement learning, okay?

03:57:05.919 --> 03:57:07.348
Because for turn-based games, 
the algorithm for winning is 

03:57:07.349 --> 03:57:09.349
actually quite easy.

03:57:14.291 --> 03:57:16.291
You just play all the moves to 
the end.

03:57:17.565 --> 03:57:18.592
The only problem is you can't 
compute them.  There are too 

03:57:18.593 --> 03:57:20.674
many of them.  So you use what's
called a value 

03:57:24.037 --> 03:57:26.301
function, you unroll on your 
couple of moves and use 

03:57:26.302 --> 03:57:28.805
something that looks at the 
board and tells you this is good

03:57:28.806 --> 03:57:30.806
for 

03:57:33.072 --> 03:57:34.698
white and good for black and 
that's what they built using 

03:57:34.699 --> 03:57:36.699
reinforcement learning.  And I 
find it interesting because it 

03:57:38.988 --> 03:57:42.051
kind of emulates the way we 
lines solve this problem.  This 

03:57:42.052 --> 03:57:43.884
is a -- humans solve this 
problem.  This is a very visual 

03:57:43.885 --> 03:57:45.885
game.  We have a very powerful 
core text when 

03:57:49.035 --> 03:57:51.682
we look at the board go as 
influence and see in this 

03:57:51.683 --> 03:57:53.964
region, black has a strong 
influence.  In this region, 

03:57:53.965 --> 03:57:57.888
white has a strong presence so 
we can kind of process this and 

03:57:57.889 --> 03:57:59.333
what they built is a value 
function that does kind of the 

03:57:59.334 --> 03:58:01.615
same thing and allows them to 
unroll the move to a much 

03:58:04.072 --> 03:58:05.538
shallower depth because after 
just a couple of moves their 

03:58:05.539 --> 03:58:07.539
value function built using 
reinforcement learning tells 

03:58:10.409 --> 03:58:12.409
them this is great for white or 
good for black.

03:58:16.357 --> 03:58:18.357
So these are results from the 
lab.

03:58:21.605 --> 03:58:23.605
Let's try to do something real

03:58:48.639 --> 03:58:50.639
real.

03:58:51.729 --> 03:58:53.970
Let's say we have build 
characters.  We structure it so 

03:58:53.971 --> 03:58:57.477
that those characters represent 
a neural network.  Yeah, a 

03:58:57.478 --> 03:59:00.738
neural network is sequence ever 
layers.  This is my first 

03:59:00.739 --> 03:59:02.739
syntax.

03:59:07.252 --> 03:59:09.252
Why not represents a neural 
network

03:59:13.800 --> 03:59:15.860
.  Let's say you have a entirely
network you care about, let's 

03:59:15.861 --> 03:59:18.345
say, spotting airplanes in 
pictures.  So, this will train 

03:59:18.346 --> 03:59:21.049
to give some accuracy.  What if 
now we take this accuracy and 

03:59:23.488 --> 03:59:25.488
make it a reward in a 
reinforcement 

03:59:27.743 --> 03:59:29.743
learning algorithm

03:59:42.572 --> 03:59:44.630
.  Let's say, we create a better
neural network, not just 

03:59:44.631 --> 03:59:46.631
changing the parameters, 
changing the shape of the 

03:59:47.521 --> 03:59:49.755
network that works better for 
our problem we care about.  We 

03:59:49.756 --> 03:59:51.824
get a neural network that is 
generating a neural network for 

03:59:51.825 --> 03:59:54.707
our specific problem.  It's 
called neural architecture 

03:59:54.708 --> 03:59:56.708
search and we actually published
a paper on 

04:00:00.488 --> 04:00:02.923
this, and I find this very nice 
application of a technology 

04:00:02.924 --> 04:00:09.236
designed initially to beat pong.
&gt;&gt; YU-HAN LIU: So Martin, you're

04:00:09.237 --> 04:00:12.959
saying we have entirely networks
that learn to build other neural

04:00:12.960 --> 04:00:14.960
networks.
&gt;&gt; MARTIN GORNER: Yeah.

04:00:15.005 --> 04:00:17.243
&gt;&gt; YU-HAN LIU: That's deep, man.
&gt;&gt; MARTIN GORNER: Yeah, so, 

04:00:17.244 --> 04:00:21.110
Yu-Han, to finish, you built 
this demo, so can you tell us a 

04:00:21.111 --> 04:00:22.169
word about the tools that you 
used?

04:00:22.170 --> 04:00:24.239
&gt;&gt; YU-HAN LIU: Yeah, definitely.
So we used TensorFlow for the 

04:00:24.240 --> 04:00:30.563
model itself.  And TensorFlow 
for tracking the metrics of 

04:00:30.564 --> 04:00:33.224
during the process training.  I 
really didn't want to run the 

04:00:35.267 --> 04:00:37.267
training on my laptop though I 
probably 

04:00:38.991 --> 04:00:39.793
could, so I used Cloud machine 
learning engine for the 

04:00:39.794 --> 04:00:42.031
training.  The model that was 
playing again for 

04:00:45.113 --> 04:00:47.348
the live demo took maybe one day
of training to accomplish that.

04:00:51.025 --> 04:00:54.291
&gt;&gt; MARTIN GORNER: So we have 
this job base with you and you 

04:00:54.292 --> 04:00:58.177
can launch 20 parameters and let
them run.  It's just 

04:00:58.178 --> 04:01:02.260
practicality, right?  It will 
tier down the whole cluster when

04:01:02.261 --> 04:01:04.511
every job is done and so on.
&gt;&gt; YU-HAN LIU: That's right.  

04:01:04.512 --> 04:01:06.512
Worry free.

04:01:08.594 --> 04:01:11.438
&gt;&gt; MARTIN GORNER: Yeah, I use 
engine ML for that.  There are 

04:01:11.439 --> 04:01:13.439
many tools for doing machine 

04:01:16.701 --> 04:01:19.285
learning on Cloud but one we 
just launched is ML engine.  

04:01:19.286 --> 04:01:21.361
That's one you do not program.  
You put in your data, it figures

04:01:21.362 --> 04:01:23.627
out the model for you and now 
you know how it works.

04:01:26.943 --> 04:01:31.328
Also, this uses lots of CPU, GPU
cycles.  Cloud CPUs are useful 

04:01:31.329 --> 04:01:34.177
when you're doing neural 
architecture search and they are

04:01:34.178 --> 04:01:38.522
available to you as well.  So, 
thank you.  That's all we wanted

04:01:38.523 --> 04:01:42.205
to show you today.  Please give 
us feedback.  We just released 

04:01:42.206 --> 04:01:44.255
this code to GitHub so you have 
the GitHub URL if you want 

04:01:49.308 --> 04:01:53.072
to train a pong agent yourself, 
go and do it.  You can take a 

04:01:53.073 --> 04:01:55.528
picture there.  If you want to, 
the URL is still on the screen.

04:01:59.735 --> 04:02:01.365
If you want to learn machine 
learning, I'm not going to say 

04:02:01.366 --> 04:02:03.366
it's easy, but I'm not going to 
say it's impossible either.

04:02:07.694 --> 04:02:09.694
We have this series relatively 
short 

04:02:15.767 --> 04:02:18.268
series of video and code samples
-- called code samples without a

04:02:18.269 --> 04:02:20.269
PhD that 

04:02:21.558 --> 04:02:23.558
is designed to give you the keys
to the machine learning kingdom.

04:02:23.817 --> 04:02:26.252
So you go through those videos. 
This talk is one of them and it 

04:02:26.253 --> 04:02:28.253
gives 

04:02:29.327 --> 04:02:31.177
you I vocabulary, all the 
concepts.  We are trying to 

04:02:31.178 --> 04:02:33.032
explain the concepts in a 
language that developers 

04:02:33.033 --> 04:02:36.131
understand because we are 
developers.  Thank you very much

04:02:39.149 --> 04:02:43.748
(applause)
(Session was concluded at 2:10 

04:02:43.749 --> 04:02:44.768
PM CT)
***

04:02:44.769 --> 04:02:48.902
This text, document, or file is 
based on live transcription.  

04:02:44.769 --> 04:02:48.902
Communication Access Realtime 
Translation (CART), captioning, 

04:02:44.769 --> 04:02:48.902
and/or live transcription are 
provided in order to facilitate 

04:02:44.769 --> 04:02:47.702
communication
accessibility and may not be a 

04:02:44.769 --> 04:02:48.502
totally verbatim record of the 
proceedings.  This text, 

04:02:44.769 --> 04:02:48.902
document, or file is not to be 
distributed or used in any way 

04:02:44.769 --> 04:02:47.035
that may violate copyright law.
***

04:02:52.488 --> 04:02:54.488
REALTIME CAPTIONING ON THIS 
SCREEN

04:06:43.403 --> 04:06:45.860
GOOGLE I/O 2018
MOUNTAIN VIEW, CALIFORNIA

04:06:47.889 --> 04:06:50.356
MAY 10, 2018
STAGE 2

04:06:52.601 --> 04:06:54.601
12:30 PM

04:06:57.091 --> 04:06:59.091
IMPROVE APP PERFORMANCE WITH 
ANDROID STUDIO PROFILERS

04:07:13.032 --> 04:07:15.032
TC069E

04:25:38.527 --> 04:25:40.527
it has is you can change the 
background.

04:25:41.552 --> 04:25:43.552
So

04:25:45.487 --> 04:25:46.932
if the internet connection is 
good enough, this is going to 

04:25:46.933 --> 04:25:49.979
start downloading.  So maybe 
just right now.  There you go.

04:25:49.980 --> 04:25:54.049
Can you dive into the network 
Profiler.  You surely have seen 

04:25:54.050 --> 04:25:56.503
these before and you can see all
the network requests that have 

04:25:56.504 --> 04:25:59.763
been done.  You can click on 
them and see the actual pay 

04:25:59.764 --> 04:26:03.670
load.  Something new that was 
added in 3.1 is the ability for 

04:26:03.671 --> 04:26:05.671
us to see what we send.

04:26:07.335 --> 04:26:09.370
Not just what we receive, but we
can see the pay load or the 

04:26:09.371 --> 04:26:12.641
custom headers that we use.  In 
this case, I have one custom 

04:26:12.642 --> 04:26:15.133
header that says, Google I/O.

04:26:18.392 --> 04:26:20.221
There is another new feature in 
3.1 for the network Profiler, 

04:26:20.222 --> 04:26:22.222
and that is the threads view.

04:26:28.557 --> 04:26:30.557
So, as you see here, we show you

04:26:31.750 --> 04:26:33.853
the requests in the timeline, 
but if you choose threads view, 

04:26:33.854 --> 04:26:35.854
what you can 

04:26:38.160 --> 04:26:39.583
see is on which thread, and let 
me close this so we have more 

04:26:39.584 --> 04:26:43.664
space.  There we go.  So you can
see each request on which thread

04:26:43.665 --> 04:26:45.665
it was made.

04:26:46.734 --> 04:26:48.734
And if we have more like this, 
I'm 

04:26:49.992 --> 04:26:51.992
using a standardized synchronous
task 

04:26:53.469 --> 04:26:55.469
which uses a default executor 
that will 

04:26:56.684 --> 04:27:00.438
run them sequentially and you 
can see them.  If they were 

04:27:00.439 --> 04:27:03.892
using a different thread, you 
can see that, too.  But if you 

04:27:03.893 --> 04:27:05.893
have a more complex threading 
with network requests, you can 

04:27:06.131 --> 04:27:08.131
use this to see what's going on.

04:27:09.200 --> 04:27:11.200
So, those are the two new 
features on 

04:27:12.461 --> 04:27:15.332
the Network Profiler that we've 
added in 3.1.  Now I'm going to 

04:27:15.333 --> 04:27:17.810
move to the Memory Profiler.  
Let me go to the live session.

04:27:23.516 --> 04:27:25.542
If you have seen this view 
before, we split up how much 

04:27:25.543 --> 04:27:27.543
money we are using but 

04:27:28.604 --> 04:27:30.604
we also show you the number of 
objects we have allocated.

04:27:33.509 --> 04:27:35.346
If you are profiling on an 
Android phone or newer, this is 

04:27:35.347 --> 04:27:37.576
super cool, we have a feature 
called live allocation tracking.

04:27:37.577 --> 04:27:41.244
Remember back in the day, it was
probably last year, when you had

04:27:41.245 --> 04:27:43.245
to do 

04:27:45.128 --> 04:27:47.164
allocation tracking, you had to 
click on a button to record 

04:27:47.165 --> 04:27:50.746
allocations and then you can see
them.  Well, if you wanted to 

04:27:50.747 --> 04:27:52.747
know what happened here, we can 
see that the 

04:27:58.554 --> 04:28:03.100
object lines going up as being 
garbage collected, going up.  

04:28:03.101 --> 04:28:04.537
Just select a range and we will 
have the information on every 

04:28:04.538 --> 04:28:06.776
single October that was  
allocated there, at which time 

04:28:10.234 --> 04:28:12.234
it was allocated, and where in 
your code it was allocated.

04:28:14.168 --> 04:28:17.804
And you can slide this window 
and see it thing changing.  So 

04:28:17.805 --> 04:28:18.626
if I slide it over a garbage 
collection period, you will see 

04:28:18.627 --> 04:28:22.918
which objects were deallocated.
Let me close this window.  There

04:28:22.919 --> 04:28:26.187
we go.  We can see that there 
was a lot of strings 

04:28:26.188 --> 04:28:28.643
deallocated.  So we can start 
actually having a look 

04:28:32.711 --> 04:28:34.711
at this app and ee how bad it is
written.

04:28:35.965 --> 04:28:37.824
For example, it if I select this
and I want to see what was 

04:28:37.825 --> 04:28:41.301
allocated, I can see there were 
a lot of strings allocated.  I 

04:28:41.302 --> 04:28:43.302
can click on any of those.  I 
can see where I allocated.

04:28:46.193 --> 04:28:48.226
And I allocated them inside a 
nondrawer.  This is not a good 

04:28:48.227 --> 04:28:50.668
idea if you have a custom view 
and you allocate a lot of 

04:28:55.185 --> 04:28:57.185
strings here but things will 
happen.

04:28:59.300 --> 04:29:02.349
And we'll see more about that, 
the CPU profiler.  This is more 

04:29:02.350 --> 04:29:04.350
to tell us signals about what my
app is doing wrong.

04:29:06.635 --> 04:29:08.635
Another new thing that we added 
in 3.

04:29:10.735 --> 04:29:13.388
2 is the ability to see JNI 
global references.  This is very

04:29:13.389 --> 04:29:15.389
important because a lot 

04:29:18.089 --> 04:29:19.715
of memory leaks occurred, 1YNS 
is created and we don't know 

04:29:19.716 --> 04:29:21.716
where we created it and we don't
know where it is.

04:29:25.423 --> 04:29:27.423
So when you select a range I 
have here 

04:29:29.081 --> 04:29:31.339
in my app every time I download 
an image I run a filter to 

04:29:31.340 --> 04:29:33.360
darken it so the font can be 
seen.  And I have a global 

04:29:33.361 --> 04:29:35.361
reference there and I hope I did
right, right?

04:29:40.348 --> 04:29:42.348
So, we have a special heap which
we 

04:29:45.038 --> 04:29:46.866
call the JNI heap that when you 
select it you can see all the 

04:29:46.867 --> 04:29:48.867
global references that exist in 
this time.

04:29:51.588 --> 04:29:52.808
In this case, I have the -- and 
I know I created one but it 

04:29:52.809 --> 04:29:54.809
should have been 

04:29:57.079 --> 04:29:59.079
gone so let me go live here and 
select a range.

04:30:02.226 --> 04:30:04.226
And here it is.

04:30:05.490 --> 04:30:09.983
This is my global, this is every
image that has been loaded.  I'm

04:30:09.984 --> 04:30:12.011
still holding a JNI global 
reference to it and I can 

04:30:12.012 --> 04:30:15.496
actually navigate to the C plus 
plus line of code.  When I 

04:30:15.497 --> 04:30:18.561
created that global reference, I
never let go.  So I hope this is

04:30:18.562 --> 04:30:20.608
useful to track down problems 
with global references in JNI.

04:30:25.704 --> 04:30:27.945
And one more thing.  You 
probably have been seeing all 

04:30:27.946 --> 04:30:32.412
the time on the left that we 
have a new panel called the 

04:30:32.413 --> 04:30:34.413
sessions panel.

04:30:35.671 --> 04:30:37.296
Well, now we allow you to see 
previous sessions that you have 

04:30:37.297 --> 04:30:39.297
been profiled so 

04:30:40.563 --> 04:30:43.281
you can navigate back and 
compare previous runs.  If 

04:30:43.282 --> 04:30:45.715
you're working on optimizing 
your app, see, what did I 

04:30:45.716 --> 04:30:49.388
change, you can go back and see 
previous sessions.  At the end 

04:30:49.389 --> 04:30:51.242
of the demo, hopefully, we can 
go back and see what we 

04:30:51.243 --> 04:30:53.491
optimized and what happened.  
But that opened the door for us 

04:30:53.492 --> 04:30:57.662
to do things like this.  Now we 
can import a file.  I'm going to

04:30:57.663 --> 04:30:59.663
import.

04:31:01.908 --> 04:31:03.908
And this

04:31:08.044 --> 04:31:10.904
heap dump is being imported 
directly and you can analyze the

04:31:10.905 --> 04:31:12.905
heap dump as you're using 
Profilers.

04:31:15.563 --> 04:31:17.187
You can trace the CPU and 
everything we can import we can 

04:31:17.188 --> 04:31:20.031
export, too.  So that's pretty 
handy, this is new in 3.2.  

04:31:20.032 --> 04:31:22.032
Cool.

04:31:24.307 --> 04:31:26.307
And this is what I wanted to 
show for memory.

04:31:27.998 --> 04:31:29.644
And now we're going to go to CPU
and spend most of the time 

04:31:29.645 --> 04:31:31.645
there.  Right.

04:31:33.918 --> 04:31:36.356
Right.  This is the live 
session.

04:31:42.464 --> 04:31:43.892
And I'm going to show you one 
feature that you have.  All 

04:31:43.893 --> 04:31:45.893
right.

04:31:52.063 --> 04:31:53.713
So one thing we wanted to add 
was the ability to profile from 

04:31:53.714 --> 04:31:58.400
the beginning.  If you use the 
profilers, you have to quickly 

04:31:58.401 --> 04:32:00.636
go to CPU Profiler and hit 
record so you can see what's 

04:32:00.637 --> 04:32:02.679
happening.  Well, in 3.

04:32:06.747 --> 04:32:08.363
2, what you can do is you go to 
the profiling tab, we have an 

04:32:08.364 --> 04:32:13.030
option that says start recording
a message trace on start-up.  So

04:32:13.031 --> 04:32:16.702
I have the stick, you can choose
the configuration you want.  In 

04:32:16.703 --> 04:32:18.553
this case, I'm going to use a 
sample Java configuration and 

04:32:18.554 --> 04:32:20.554
I'm going to rerun the app.

04:32:23.265 --> 04:32:25.265
Cool.

04:32:32.037 --> 04:32:34.037
Now, you can see that the app 
restarted.

04:32:36.298 --> 04:32:39.160
The profilers took me directly 
to the CPU Profiler and there 

04:32:39.161 --> 04:32:42.410
are already a capture in 
progress from the very beginning

04:32:42.411 --> 04:32:45.056
of the app so I'm going to stop 
it now and we're going to 

04:32:47.297 --> 04:32:50.155
investigate what happened there.
Take a few seconds to get the 

04:32:50.156 --> 04:32:52.156
data.  Cool.

04:32:56.083 --> 04:32:57.513
I don't know if you can see the 
resolution on the screen, but 

04:32:57.514 --> 04:32:59.514
let's have 

04:33:02.748 --> 04:33:06.256
a look and see that I'm going to
select the very beginning of the

04:33:06.257 --> 04:33:08.257
app.  In fact you can see that 
the capture 

04:33:12.912 --> 04:33:14.912
started even before or telemet 
rei.

04:33:17.444 --> 04:33:20.274
It started here but we started 
before, and we get the data.  If

04:33:20.275 --> 04:33:22.102
you keep zooming there you can 
see the first on create of my 

04:33:22.103 --> 04:33:24.103
main activity 

04:33:26.598 --> 04:33:28.620
and even before that, we can see
the load and the very, very 

04:33:28.621 --> 04:33:32.536
beginning of your app.  And with
this mechanism, you can profile 

04:33:32.537 --> 04:33:35.581
from the very beginning.  
Optimize the start-up time.  

04:33:35.582 --> 04:33:38.432
Cool.
But, let's have a look at this 

04:33:38.433 --> 04:33:40.433
capture 

04:33:41.481 --> 04:33:43.481
and see if those strings we saw 
before 

04:33:44.751 --> 04:33:46.751
are actually causing some 
problems.

04:33:49.427 --> 04:33:51.460
One of my favorite views in the 
CPU Profiler is the flame chart.

04:33:53.702 --> 04:33:55.114
The flame chart aggregates all 
the call steps that have the 

04:33:55.115 --> 04:33:58.990
same beginning.  So you can see 
it's basically the top down tree

04:33:58.991 --> 04:34:00.410
but in a visual way and you can 
see that one of the biggest 

04:34:00.411 --> 04:34:02.411
things 

04:34:04.084 --> 04:34:06.084
is my own draw.  Drawer.

04:34:07.953 --> 04:34:10.137
The way I wrote this app is on 
every frame I'm rendering 

04:34:10.138 --> 04:34:14.217
everything again of that's not a
good way of doing it but it's a 

04:34:14.218 --> 04:34:16.689
really good example for the 
Profilers.  So you can see that 

04:34:16.690 --> 04:34:18.690
I'm rendering and there is a lot
of things at the top that 

04:34:21.532 --> 04:34:23.389
have to do with string 
formatting and this could be the

04:34:23.390 --> 04:34:25.390
source of our string problem 
that we saw before.

04:34:32.975 --> 04:34:34.975
So your string is not doing 
well.

04:34:36.013 --> 04:34:38.074
One thing I always say about 
profilers is that we cannot 

04:34:38.075 --> 04:34:41.127
really tell you what's wrong in 
your app.  We can only tell you 

04:34:41.128 --> 04:34:45.188
what your app is doing and then 
it's up to you to say, oh, I 

04:34:45.189 --> 04:34:47.011
didn't expect this to happen.  
Because as you can see, my app 

04:34:47.012 --> 04:34:50.878
looks fine but under the hood, 
it's not.  So, let's say you 

04:34:50.879 --> 04:34:52.928
have a bug on a label that you 
put wrong and it's a different 

04:34:52.929 --> 04:34:58.074
position.  You're up, you see 
here.  I need to fix this.  But 

04:34:58.075 --> 04:35:00.508
if you have something like a 
performance issue wrong, you 

04:35:00.509 --> 04:35:03.576
won't see it until we talk about
battery later, and you will see 

04:35:03.577 --> 04:35:06.619
it in the field.  Right?  So we 
want our profilers to be another

04:35:11.073 --> 04:35:13.073
window to your app

04:35:14.380 --> 04:35:18.053
so that you can run your app 
while seeing the Profilers.  

04:35:18.054 --> 04:35:20.702
Something you did not expect 
start showing up like me doing a

04:35:20.703 --> 04:35:22.703
lot of string formatting.  Cool.

04:35:25.331 --> 04:35:27.331
So, let's go to the code.

04:35:31.518 --> 04:35:33.518
What I have -- can you see?  
Yeah.

04:35:37.833 --> 04:35:39.725
Cool, so I have my own drawer 
and I have a fucks called draw 

04:35:39.726 --> 04:35:42.992
time where I draw the time on my
app.  And I have another 

04:35:42.993 --> 04:35:45.852
function called draw time string
that uses

04:35:45.853 --> 04:35:51.576
blank string formatting to draw 
the time and that's probably not

04:35:51.577 --> 04:35:55.870
a good idea so as a coincidence 
I have another function that 

04:35:55.871 --> 04:35:57.292
draws the time without using 
strings and we're going to try 

04:35:57.293 --> 04:35:59.943
it.  Oh, before we do it, let me
show you one thing that we have 

04:35:59.944 --> 04:36:03.011
here.  So, how many of you are 
familiar with this line of code?

04:36:04.448 --> 04:36:06.448
Trace out begin section.  Raise 
your hands.  Cool.

04:36:12.352 --> 04:36:14.352
So, what this line does and

04:36:19.723 --> 04:36:21.723
together they will create a

04:36:25.487 --> 04:36:29.353
sis trace event.  I'm going to 
show you what happens if I take 

04:36:29.354 --> 04:36:32.819
a capture using the system trace
method.  Cool.  So this is 

04:36:32.820 --> 04:36:34.820
running sys trace under the 

04:36:35.869 --> 04:36:37.491
hood and you don't have to go to
the Python script anymore and 

04:36:37.492 --> 04:36:41.349
get it and then get it back on 
the HTML view.  We will, 

04:36:41.350 --> 04:36:45.824
instead, show it to you right 
here in our app.  In Android 

04:36:45.825 --> 04:36:47.825
Studio.  Okay.

04:36:51.344 --> 04:36:56.026
Remember what I mentioned about 
-- this is it.  Oopsie.  Let me 

04:36:56.027 --> 04:36:58.058
restart even later.  I will do 
it again.

04:37:02.933 --> 04:37:06.609
There we go.  Please, please, 
try this at home.  Find bugs.

04:37:09.666 --> 04:37:11.666
We will fix them and when we get
this 

04:37:12.953 --> 04:37:14.953
table, these issues will be all 
sorted out.  There we go.

04:37:20.086 --> 04:37:22.937
I'm going to go to CPU Profiler 
and use system trace.

04:37:28.458 --> 04:37:30.458
Second time's the charm.  Okay.

04:37:32.136 --> 04:37:33.978
So we have system trace here.  
Let me select and zoom into the 

04:37:33.979 --> 04:37:35.979
selection.  Cool.

04:37:39.671 --> 04:37:41.671
One thing that you notice here 
is that 

04:37:42.727 --> 04:37:44.959
first of all you have a new 
section here called the kernel 

04:37:44.960 --> 04:37:46.960
section where we show you all 
the CPUs.

04:37:49.035 --> 04:37:50.661
And if you pay close attention, 
we reran all the thread 

04:37:50.662 --> 04:37:53.101
information getting all the data
from sys trace.

04:37:56.135 --> 04:37:58.135
So, before, the string 
information, we 

04:38:00.366 --> 04:38:02.366
get sampling

04:38:06.137 --> 04:38:08.779
the profile system so it's not 
very accurate but as soon as we 

04:38:08.780 --> 04:38:10.780
take a sys 

04:38:11.786 --> 04:38:13.786
trace

04:38:14.985 --> 04:38:16.985
you can see more.

04:38:18.647 --> 04:38:20.647
More than that, we highlight 
above on 

04:38:22.306 --> 04:38:23.730
which CPU, so we can see all the
things kicking you out of the 

04:38:23.731 --> 04:38:25.731
CPU.

04:38:27.602 --> 04:38:29.859
There is a fundamental 
difference in the way we show 

04:38:29.860 --> 04:38:34.326
sys trace here.  Here, we focus 
on your app, so everything here 

04:38:34.327 --> 04:38:36.769
that is highlighted green, even 
the dark green is just your app.

04:38:38.805 --> 04:38:40.805
You can still go and see the 
other 

04:38:41.845 --> 04:38:43.888
events and see what is taking 
CPU or why you're being kicked 

04:38:43.889 --> 04:38:45.889
out, but we focus on your app.

04:38:49.169 --> 04:38:51.169
We show you the trace of your 
app so 

04:38:53.610 --> 04:38:56.519
you don't have to inform gate 
this gigantic list.

04:39:00.190 --> 04:39:02.799
So, for example, flame chart or 
top down view.  So, let me zoom 

04:39:02.800 --> 04:39:04.800
in the moment in time.  There we
can see our frames.

04:39:08.671 --> 04:39:12.075
So, I have here, let me zoom in 
more and choose actually my main

04:39:12.076 --> 04:39:14.076
thread.  There we go.

04:39:18.173 --> 04:39:20.173
So, we can see the frame and 
further 

04:39:22.800 --> 04:39:24.800
down we can see the

04:39:26.440 --> 04:39:30.690
on draw on my custom component. 
And we can see the draw time.  

04:39:30.691 --> 04:39:34.091
Remember the code.  Let me go 
back and show you in draw time 

04:39:34.092 --> 04:39:40.850
we have draw time around the 
section around my temp frame.  

04:39:40.851 --> 04:39:43.083
You can see I'm running it in 
three sections and we can 

04:39:43.084 --> 04:39:45.084
quickly see how long 

04:39:46.342 --> 04:39:47.361
each one of those it taken so 
I'm taking 38,000,002nds to run 

04:39:47.362 --> 04:39:49.362
the frame.

04:39:50.620 --> 04:39:53.466
If you want your app to run in 
60 seconds, you have to run it 

04:39:53.467 --> 04:39:56.313
on 17th frame, milliseconds.  
So, I'm way over that.

04:39:59.366 --> 04:40:01.366
In fact, one of my calls to draw
time 

04:40:02.417 --> 04:40:05.866
is taking 11 milliseconds.  So 
my app is not doing so well.  

04:40:05.867 --> 04:40:08.505
This is one of the things that I
was mentioning about, you look 

04:40:08.506 --> 04:40:13.207
at your app, but look at it 
through the profiler glass to 

04:40:13.208 --> 04:40:15.208
see if it's doing okay.

04:40:16.305 --> 04:40:21.386
Cool, now, let's optimize and 
take another sys trace capture. 

04:40:21.387 --> 04:40:23.387
I'm going to change 
implementation of 

04:40:24.401 --> 04:40:28.918
draw time.  Now instead of using
strings, I'm using my custom 

04:40:28.919 --> 04:40:33.194
formatting.  We'll run it again 
with these changes and run it 

04:40:33.195 --> 04:40:35.195
through sys trace and see how 
that affected my app.

04:40:40.361 --> 04:40:42.361
Cool.

04:40:43.565 --> 04:40:48.538
There is  There it is.  I'm 
going to go to CPU Profiler.  

04:40:48.539 --> 04:40:50.539
Just a few seconds should do 
because 

04:40:52.171 --> 04:40:55.053
there are a lot of frames that 
happen in there.  Cool.  We have

04:40:55.054 --> 04:40:58.518
it here.  Right.  Main thread 
selected.  Zoom into a specific 

04:40:58.519 --> 04:41:00.519
frame.

04:41:02.556 --> 04:41:07.084
We have the choreographer do 
frame in the framework and then 

04:41:07.085 --> 04:41:09.085
it goes down, and you cannot see
anymore the draw time functions 

04:41:10.567 --> 04:41:12.567
because they are tiny, tiny 
specs down there.

04:41:16.065 --> 04:41:18.065
Each one of them now taking

04:41:19.371 --> 04:41:21.371
71 microseconds and the on draw 
is 13 milliseconds now.  Woohoo.

04:41:22.623 --> 04:41:24.623
So, we did that.

04:41:27.645 --> 04:41:32.405
I'm still under 60 per second 
because my app is bad in other 

04:41:32.406 --> 04:41:35.203
places but at least we optimized
one part of it.  Cool, and 

04:41:35.204 --> 04:41:37.242
that's sys trace.  And let me 
mention again sessions, so 

04:41:41.966 --> 04:41:43.966
remember I said you can go back 
and compare.

04:41:46.867 --> 04:41:48.867
I have my previous sessions on 
the left.

04:41:50.120 --> 04:41:52.120
We can see the previous sys 
trace we did.

04:41:54.183 --> 04:41:56.844
Can select it, look, see how bad
my draw time is and go back to 

04:41:56.845 --> 04:41:58.845
the currently running session.

04:42:03.651 --> 04:42:05.675
Of course, if you right click, 
you can export or on the heap 

04:42:05.676 --> 04:42:08.306
dump you can export these things
right from the sessions panel.  

04:42:08.307 --> 04:42:11.781
Let me click this.
Right.  And that's our -- we 

04:42:11.782 --> 04:42:14.227
have 20 minutes.  And that's our
integration with sys trace.

04:42:19.303 --> 04:42:21.303
So, there's another way of 
capturing 

04:42:24.459 --> 04:42:26.459
CPU data that is through an API 
in the debugger.

04:42:30.132 --> 04:42:32.132
Let me go to the line of code.  
Here it is.

04:42:34.630 --> 04:42:37.284
So, I have my stopwatch.  And 
I'm going to change it so every 

04:42:39.518 --> 04:42:41.746
time I start my stopwatch, I'm 
going to run, start method 

04:42:41.747 --> 04:42:44.211
tracing and every time I stop 
it, I'm going to stop method 

04:42:44.410 --> 04:42:46.410
tracing.

04:42:49.254 --> 04:42:51.591
I need to import the debug and 
I'm going to rerun the app.

04:42:56.717 --> 04:42:59.150
Now, before this, once you run 
this API, you have to go on and 

04:42:59.151 --> 04:43:01.151
fetch this file 

04:43:03.230 --> 04:43:05.458
and open it in either any of 
your favorite Profilers that can

04:43:05.459 --> 04:43:10.768
open a trace file.  But right 
now if I'm the CPU Profiler and 

04:43:10.769 --> 04:43:12.769
I use my stopwatch, this is what
happens.

04:43:16.131 --> 04:43:17.801
So, now I'm taking a capture and
the Studio Profiler has detected

04:43:17.802 --> 04:43:19.802
that a 

04:43:22.267 --> 04:43:25.524
capture is being fetched and 
we're showing you theirs.  And 

04:43:25.525 --> 04:43:28.163
when I stop it, we pull it from 
the device and show it there so 

04:43:28.164 --> 04:43:32.433
if I start and stop, start and 
stop, all these captures that 

04:43:32.434 --> 04:43:34.674
are actually overriding each 
other we're pulling and 

04:43:38.156 --> 04:43:40.994
showing them on Studio so that's
super handy when you want 

04:43:40.995 --> 04:43:42.995
exactly a Profiler a moment in 
time.

04:43:44.077 --> 04:43:46.077
We can navigate to all of them 
and you 

04:43:48.527 --> 04:43:51.810
can see them here here in the 
sessions panel, too.  So it's 

04:43:51.811 --> 04:43:53.811
pretty cool.

04:43:55.493 --> 04:43:57.493
One more thing, we added in 
three to one.

04:43:59.762 --> 04:44:01.762
Another way of capturing CPU 
usage 

04:44:02.825 --> 04:44:04.825
using the C plus plus.

04:44:08.302 --> 04:44:10.302
Something called simple Perf, if
you 

04:44:12.201 --> 04:44:14.235
go to documentation on 
developers, you will find 

04:44:14.236 --> 04:44:16.468
documentation about simple perf.
We have it inside Android Studio

04:44:16.469 --> 04:44:18.469
and 

04:44:20.145 --> 04:44:21.371
it allows you to sample C plus 
plus code and your C plus plus 

04:44:21.372 --> 04:44:25.244
problem.  I'm not going to demo 
that because I don't have a lot 

04:44:25.245 --> 04:44:27.245
of C plus plus.

04:44:30.963 --> 04:44:33.219
Cool, so, that's CPU profiling 
and let me move to the energy 

04:44:33.220 --> 04:44:35.220
Profiler now.

04:44:37.091 --> 04:44:39.379
So, energy is tricky.  Energy is
tricky because there are two 

04:44:42.428 --> 04:44:44.675
main sources that use energy on 
your phone.  Well, the screen is

04:44:44.676 --> 04:44:49.372
obviously, I'm not even counting
the screen.  The screen is bad. 

04:44:49.373 --> 04:44:51.415
It uses a lot of energy but the 
user is using the game, so if 

04:44:51.416 --> 04:44:55.482
you're using a game, it's all 
the time using the screen.  But 

04:44:55.483 --> 04:44:57.346
the battery drain problems 
usually happen when we use CPU 

04:44:57.347 --> 04:45:01.435
or network when the user is not 
aware of this or maybe when we 

04:45:01.436 --> 04:45:03.436
as developers are not aware of 
this.

04:45:03.875 --> 04:45:05.875
So, let me go live.

04:45:08.136 --> 04:45:10.136
I'm using a fair amount of CPU 
on this 

04:45:13.249 --> 04:45:15.907
app and if I go into the energy 
Profiler, we classify this as 

04:45:15.908 --> 04:45:17.908
light use of energy.

04:45:20.587 --> 04:45:22.587
We will show you here things 
that, this is -- mobile.  Right?

04:45:24.655 --> 04:45:26.683
So we share the things that 
represent how much energy you 

04:45:26.684 --> 04:45:28.684
would be using on modern phone.

04:45:31.155 --> 04:45:32.720
I'm not profiling how much 
energy the emulator is using, 

04:45:32.721 --> 04:45:36.172
obviously, but this is for us to
see, okay.  I'm doing well or 

04:45:36.173 --> 04:45:38.652
I'm not doing well.  I'm going 
to show you something that shows

04:45:38.653 --> 04:45:40.653
up here.

04:45:42.130 --> 04:45:44.579
But obviously, the two big 
factors are CPU and network.  

04:45:44.580 --> 04:45:47.633
And it's not, you know, the 
obvious thing is Okay. Just 

04:45:47.634 --> 04:45:50.105
don't use CPU and network.  But 
how?  Right, or why am I using 

04:45:50.106 --> 04:45:52.758
that in the field?  And the 
problem is not actually when we 

04:45:52.759 --> 04:45:55.197
use it.  The problem is that we 
don't know we're using it.

04:45:59.069 --> 04:46:00.897
So, let's say I have a wake lock
that runs amok and we don't know

04:46:00.898 --> 04:46:03.169
where it is and that's using CPU
or I have an alarm 

04:46:06.421 --> 04:46:07.232
that I didn't set up correctly 
and that is walking my app and 

04:46:07.233 --> 04:46:09.233
I'm making network requests.

04:46:13.709 --> 04:46:16.037
So, it's not about the actual 
energy.  It's about all these 

04:46:16.038 --> 04:46:19.720
things that you could be doing 
incorrectly that could cause 

04:46:19.721 --> 04:46:21.753
battery drain in the long term 
and this is part of what I was 

04:46:21.754 --> 04:46:25.655
saying before that if you look 
at your app, if you look at my 

04:46:25.656 --> 04:46:27.656
app, seems to be running.  Seems
to be fine.

04:46:29.933 --> 04:46:31.566
If I were to push this app to 
the Play Store and you're 

04:46:31.567 --> 04:46:33.605
starting on your phone, this is 
going to be the most expensive 

04:46:36.867 --> 04:46:38.867
battery speaking clog you ever 
have on your phone.

04:46:40.306 --> 04:46:41.731
I'm going to drain your battery 
and I don't know it by looking 

04:46:41.732 --> 04:46:43.732
at this so by looking at the 
Profilers we can see that 

04:46:46.051 --> 04:46:48.209
constantly this is draining CPU 
and we can start investigating 

04:46:48.210 --> 04:46:50.210
why.

04:46:51.351 --> 04:46:53.479
Lied,like I said, the common 
mistakes are I 

04:46:57.340 --> 04:47:00.589
have a wake lock I don't release
or I have an alarm.  We want to 

04:47:00.590 --> 04:47:05.084
given you a window.  We want to 
show you if you have an a living

04:47:05.085 --> 04:47:06.305
room you didn't cancel or an 
alarm in the wrong place, we're 

04:47:06.306 --> 04:47:09.151
going to show you that.
So, let me show you this piece 

04:47:09.152 --> 04:47:11.152
of my app.  We have a timer.

04:47:13.832 --> 04:47:15.832
So, here, I can run, let's say, 
a 102nd timer.

04:47:18.126 --> 04:47:20.759
And you can see at the bottom of
the energy Profiler, there is a 

04:47:20.760 --> 04:47:25.893
yellow line that showed up.  
That's an alarm or a job, we 

04:47:25.894 --> 04:47:28.741
show you both there.  And you 
can see that when the timer 

04:47:30.700 --> 04:47:32.975
stopped, the alarm went away.  
And if I start the timer again, 

04:47:32.976 --> 04:47:36.636
again, I have the alarm.  And 
this, actually, when I was 

04:47:39.718 --> 04:47:41.140
developing this was useful for 
me to see, okay, am I doing it 

04:47:41.141 --> 04:47:47.253
right.  When I stop the timer, 
does my alarm go away?  When I 

04:47:47.254 --> 04:47:49.254
start again, do I call it back?

04:47:50.517 --> 04:47:52.345
So this allows you to see this. 
Please don't use alarms for a 

04:47:52.346 --> 04:47:54.346
timer and a clock.

04:47:56.022 --> 04:47:58.264
I also have a wake lock on my 
stopwatch.  Again, don't use 

04:47:58.265 --> 04:48:00.516
wake locks for a stopwatch.  And
you can see that when I start 

04:48:00.517 --> 04:48:04.168
it, I acquire a wake lock.  And 
when I stop it, I let it go.

04:48:07.429 --> 04:48:09.429
And I can see that it's working 
fine.

04:48:10.502 --> 04:48:12.529
If the alarm gets going, have a 
bug.  My app will look the same 

04:48:12.530 --> 04:48:16.809
and I will ship it and people 
will have problems but you can 

04:48:16.810 --> 04:48:19.459
see through this window whether 
it's fine or not.  And we also 

04:48:19.460 --> 04:48:23.731
track location.  So, if you are 
acquiring location like I'm 

04:48:23.732 --> 04:48:26.200
doing now, we have this purple 
line that shows you that your 

04:48:26.201 --> 04:48:28.235
current location, the emulator 
has a really 

04:48:32.708 --> 04:48:34.140
handy feature that you can 
actually tell it when to send 

04:48:34.141 --> 04:48:36.141
the location event.

04:48:39.248 --> 04:48:42.082
So, in our model, we show you 
that that is actually using 

04:48:42.083 --> 04:48:44.137
energy.  And again, you can see 
it in the 

04:48:47.592 --> 04:48:49.592
purple bar and if I stop it, 
there we go.

04:48:52.053 --> 04:48:54.053
The purple bar is gone.

04:48:57.344 --> 04:48:58.776
But more than that, I see used 
to our Profilers we can select a

04:48:58.777 --> 04:49:02.046
range.  And we can show you that
you had an alarm.  That you had 

04:49:02.047 --> 04:49:04.094
a location request.  If I move 
back, we can select the wake 

04:49:06.143 --> 04:49:08.143
lock and I'll do it in a second.

04:49:09.625 --> 04:49:11.625
More than that, I can show you 
where 

04:49:12.906 --> 04:49:14.906
the location is acquired, which 
kind of provider.

04:49:17.758 --> 04:49:21.469
I'm using a GBS Profiler.  They 
have a toggle location that 

04:49:22.694 --> 04:49:24.694
happens when I click the button.

04:49:26.369 --> 04:49:29.226
And if I click on the alarm, not
only I can see when I set it the

04:49:29.227 --> 04:49:33.291
first time, but when I reset it,
when I cancel it so you can see 

04:49:33.292 --> 04:49:35.587
all the places in the code that 
that was triggered so I can 

04:49:35.588 --> 04:49:37.588
debug problems when this is not 
happening correctly.

04:49:42.893 --> 04:49:45.963
Let me go back and show you the 
wake lock is right there.  I 

04:49:45.964 --> 04:49:47.603
select, you can see the wake 
lock.  And you can see every 

04:49:47.604 --> 04:49:49.604
time that I 

04:49:51.863 --> 04:49:53.324
started, I stopped the 
stopwatch, I was acquiring and 

04:49:53.325 --> 04:49:55.325
releasing the wake lock 

04:49:56.391 --> 04:49:58.657
and you can see all the calls.  
That's when that happened.  So, 

04:49:58.658 --> 04:50:00.243
this is the power for this.  
This is not to say, okay, you're

04:50:00.244 --> 04:50:02.244
using a lot of battery.

04:50:04.331 --> 04:50:06.331
Well, again, I want to use 
battery.  So, it's fine.

04:50:08.627 --> 04:50:10.252
The power of this is so that you
can see your app is doing what 

04:50:10.253 --> 04:50:15.990
you think it's doing.  If not, 
you should go and fix it.  So 

04:50:15.991 --> 04:50:22.071
cool.
That's Energy Profiler.  Let me 

04:50:22.072 --> 04:50:25.743
show you one more thing that I 
wanted to show you.  On the 

04:50:25.744 --> 04:50:27.744
left, we have the sessions 
panel.

04:50:31.680 --> 04:50:33.680
And let's go back in time.

04:50:37.208 --> 04:50:39.440
I can stop a current session 
like this.  And then you can 

04:50:39.441 --> 04:50:43.502
click on other sessions and we 
can start comparing all the 

04:50:43.503 --> 04:50:45.503
captures that we did back from 
when 

04:50:48.581 --> 04:50:50.581
I started to talk here.

04:50:51.636 --> 04:50:52.651
And this was the first time we 
run it and we keep all this 

04:50:52.652 --> 04:50:56.925
information until you restart 
Studio so you can compare runs. 

04:50:56.926 --> 04:50:58.963
And let me show you the last 
thing, and I want to close with 

04:50:58.964 --> 04:51:00.964
that.

04:51:02.004 --> 04:51:04.004
I'm going to close a few minutes
early.

04:51:05.087 --> 04:51:10.806
All right.  Like I said before, 
I'm rendering every frame.  I'm 

04:51:10.807 --> 04:51:12.225
doing something that I should 
not be doing, that is I'm 

04:51:12.226 --> 04:51:14.226
invalidating the view all the 
time and that is using a 

04:51:17.348 --> 04:51:19.590
lot of CPU so let's go back to 
my activity where I have the 

04:51:19.591 --> 04:51:22.234
code.  So, I have my model that 
I update 

04:51:25.305 --> 04:51:28.556
every frame and then I 
invalidate all the time.  My 

04:51:28.557 --> 04:51:31.206
model has the ability to know 
when it has changed so I'm only 

04:51:31.207 --> 04:51:34.070
going to invalidate the canvas 
whenever something has changed.

04:51:34.071 --> 04:51:36.308
And we're going to see the 
impact that 

04:51:39.986 --> 04:51:41.986
that has on energy CPU and so 
forth.

04:51:46.271 --> 04:51:48.747
Running the app again.  There we
go.

04:51:51.750 --> 04:51:52.959
You can see now that energy 
Profiler most of the time now is

04:51:52.960 --> 04:51:56.708
below light.  It was above 
medium before.  We can compare 

04:51:56.709 --> 04:51:58.709
with previous sessions.

04:52:01.944 --> 04:52:04.821
But, of course, when I have to 
render, we can see that the 

04:52:04.822 --> 04:52:08.516
energy usage starts going up.  
This is because I'm rerenderring

04:52:08.517 --> 04:52:12.588
my view every time.  And you can
see the effect here.  You can 

04:52:12.589 --> 04:52:14.589
see it on the memory Profiler, 

04:52:16.082 --> 04:52:18.082
too, if I go back to the memory 
Profiler.

04:52:18.529 --> 04:52:20.529
Remember that line that was 
going up, 

04:52:22.385 --> 04:52:24.385
up, up, about being garbage 
collected.  That is gone.

04:52:26.863 --> 04:52:28.507
I do have some objects that will
be claimed later like here but 

04:52:28.508 --> 04:52:30.745
it's not as it was before.  
Cool.

04:52:33.756 --> 04:52:36.886
And let me stop the demo and go 
back to the slides.

04:52:49.289 --> 04:52:52.990
All right.  We have a few 
minutes for questions if you 

04:52:52.991 --> 04:52:55.840
wanted to do live questions but 
I wanted to close with this and 

04:52:55.841 --> 04:52:59.338
say, again, our Profilers cannot
tell you exactly what you're 

04:52:59.339 --> 04:53:01.339
doing wrong.

04:53:02.990 --> 04:53:04.840
They can only show you what your
app is doing so use your 

04:53:04.841 --> 04:53:07.291
Profilers to look at your app 
and see if what you think the 

04:53:07.292 --> 04:53:10.350
app is doing is what it's 
actually doing.  Thank you very 

04:53:10.351 --> 04:53:12.351
much and I'm open for live 
questions

04:53:14.602 --> 04:53:16.602
(applause)

04:53:26.478 --> 04:53:31.756
&gt;&gt; Okay. So with the integration
of the system trace in the new 

04:53:31.757 --> 04:53:33.757
IDE, is there any 

04:53:36.236 --> 04:53:38.502
reason to use the old sys trace?
&gt;&gt; ESTEBAN DE LA CANAL: So far, 

04:53:38.503 --> 04:53:42.742
yes.  We are going to try to 
import everything that the other

04:53:42.743 --> 04:53:45.757
sys trace used to have but if 
you want to have an overview of 

04:53:45.758 --> 04:53:47.734
the system and see how your 
obligation is interactive with 

04:53:47.735 --> 04:53:49.996
other processes.  Yes.  But for 
most of the things, in fact, 

04:53:54.701 --> 04:53:57.539
if you have your own system 
events, can you use Android 

04:53:57.540 --> 04:53:59.540
Studio and you don't 

04:54:00.745 --> 04:54:03.429
have  to leave that ID.
&gt;&gt; Cool.  Thank you.

04:54:06.081 --> 04:54:08.081
&gt;&gt; My question is I mostly use 
system 

04:54:09.123 --> 04:54:11.123
trace in order to detect frame 
drops.

04:54:12.786 --> 04:54:14.786
Have you guys integrated a frame
drop 

04:54:16.452 --> 04:54:17.482
thing, frame drop detection into
Android Studio?

04:54:17.483 --> 04:54:18.909
&gt;&gt; ESTEBAN DE LA CANAL: Well, we
could show you how long each 

04:54:18.910 --> 04:54:20.910
frame is taking 

04:54:22.609 --> 04:54:24.279
to run, the information is there
in sys trace but it's really 

04:54:24.280 --> 04:54:26.280
difficult for us to know why, 
right?

04:54:28.960 --> 04:54:30.381
So even if you take a sys trace 
with Android Studio right now, 

04:54:30.382 --> 04:54:34.070
you will see the choreographer 
frame and you will see how long 

04:54:34.071 --> 04:54:36.104
it's taking so you can 
immediately see the pattern, 

04:54:36.105 --> 04:54:39.359
right, and you'll see your 
frames taking alonger so you'll 

04:54:39.360 --> 04:54:41.360
see when you drop frames.

04:54:42.403 --> 04:54:44.229
When we're working on custom UI 
to actually show you and 

04:54:44.230 --> 04:54:47.117
highlight frames that you have 
dropped.

04:54:49.559 --> 04:54:51.559
&gt;&gt; Hi.  I actually have two 
questions.

04:54:56.016 --> 04:54:58.016
So, the first one is,

04:55:00.994 --> 04:55:02.994
whether the number from the 
emulator is 

04:55:04.266 --> 04:55:05.687
reliable or not so when you're 
under CPU Profiler, whether the 

04:55:05.688 --> 04:55:07.741
time spent on costs are  
reliable.

04:55:12.609 --> 04:55:16.299
&gt;&gt; ESTEBAN DE LA CANAL: Well 
obviously the emulator will be 

04:55:16.300 --> 04:55:18.543
different from the device but it
can give you a relative 

04:55:19.970 --> 04:55:22.630
comparison with your other 
methods.  So, in fact, the 

04:55:22.631 --> 04:55:26.291
emulator is faster in many cases
than a device.  But 

04:55:26.292 --> 04:55:28.292
proportionately, things will 
take the same amount of time.

04:55:33.051 --> 04:55:34.888
So, if your draw is twice as low
after your optimization, you can

04:55:34.889 --> 04:55:38.759
expect the same pattern to be on
the device but if you want to 

04:55:38.760 --> 04:55:40.760
accurately profile the device 
you have to do it on the device 

04:55:41.210 --> 04:55:44.465
itself.
&gt;&gt; So my second question is you 

04:55:44.466 --> 04:55:46.466
didn't show the method course 
tap.

04:55:51.389 --> 04:55:53.389
So, can I get the number of 
cores for this method?

04:55:54.238 --> 04:55:56.712
&gt;&gt; ESTEBAN DE LA CANAL: Yes, one
of the capture methods is the 

04:55:56.713 --> 04:55:59.148
instrumentation capture.  That 
one will tell you exactly how 

04:56:02.151 --> 04:56:04.151
many times

04:56:05.257 --> 04:56:07.257
the method has been called in or
out.

04:56:09.130 --> 04:56:13.393
With sys trace, the method you 
care about.

04:56:13.806 --> 04:56:15.806
&gt;&gt; Thank you.
&gt;&gt; Hi, first of all, great talk.

04:56:15.838 --> 04:56:21.554
Great updates.  My question is, 
if I obtain a sys trace trace to

04:56:21.555 --> 04:56:23.379
other methods, can I open it up 
in the new Profiler?

04:56:23.380 --> 04:56:25.380
&gt;&gt; ESTEBAN DE LA CANAL: Yes.

04:56:27.447 --> 04:56:31.729
You can import it in the next 
version.  It will be in 3.2.  

04:56:31.730 --> 04:56:33.763
You can import a trace.  The 
main thing we're working on is 

04:56:35.386 --> 04:56:37.457
when you import it, it has other
processes.  They're all the same

04:56:37.458 --> 04:56:41.741
so we're working on choosing the
pretty processes that is for 

04:56:41.742 --> 04:56:44.576
your app so we can show you 
there or ask you if you want to 

04:56:44.577 --> 04:56:46.577
select which processes you care 
about.

04:56:46.821 --> 04:56:48.821
&gt;&gt; All right.  Excellent.  
Thanks.

04:56:50.889 --> 04:56:53.526
&gt;&gt; Hi, what is the compatibility
of these Profilers on different 

04:56:53.527 --> 04:56:57.408
devices and OS versions?
&gt;&gt; ESTEBAN DE LA CANAL: So, our 

04:57:00.453 --> 04:57:02.453
Profilers run on art only, so 
that rules 

04:57:06.768 --> 04:57:08.768
out kitkat and I believe it's 
from lolly 

04:57:10.650 --> 04:57:15.562
pop up, but we, all our features
are available on Android Oreo.  

04:57:15.563 --> 04:57:16.766
We degrade  gracefully back so 
the other platforms that don't 

04:57:16.767 --> 04:57:20.441
have the things that we use, you
suddenly, start, things 

04:57:20.442 --> 04:57:23.484
disappearing.  Like you don't 
have this line or that doesn't 

04:57:23.485 --> 04:57:25.913
show up because the platform 
doesn't have it.  So I would say

04:57:25.914 --> 04:57:29.159
the best platform to use is O.  
You will have Profilers going 

04:57:29.160 --> 04:57:31.160
back.

04:57:34.680 --> 04:57:36.680
But, Oreo is our target.

04:57:38.172 --> 04:57:40.172
&gt;&gt; Thanks.

04:57:42.227 --> 04:57:44.227
&gt;&gt; Hello, I see there's a Java 
Profiler, 

04:57:46.100 --> 04:57:48.348
there's a Navien Profiler.  Is 
there a Profiler to show the 

04:57:48.349 --> 04:57:50.349
Java 

04:57:51.603 --> 04:57:52.412
stacks and the native stacks in 
a single view?

04:57:52.413 --> 04:57:54.413
&gt;&gt; ESTEBAN DE LA CANAL: Not yet.

04:57:56.496 --> 04:57:58.496
But it's happening, so I think 
this is already out there.

04:58:03.619 --> 04:58:05.619
The newer versions of simple 
support 

04:58:08.133 --> 04:58:09.975
and as soon as we do that into 
import Studio and that works for

04:58:09.976 --> 04:58:13.452
us, then you'll be able to see. 
What I with like to see is the 

04:58:13.453 --> 04:58:15.453
hybrid 

04:58:16.705 --> 04:58:18.130
calls start going from Java, 
back to JNI, back to Java and 

04:58:18.131 --> 04:58:20.131
you can analyze all of that, so,
yes, it's going to happen.

04:58:20.364 --> 04:58:23.832
&gt;&gt; Cool.  Thank you.
&gt;&gt; Hi.  Great talk.

04:58:29.739 --> 04:58:31.739
When I analyze sys trace files, 
I 

04:58:34.842 --> 04:58:36.842
often see that main thread is 
slipping during the execution.

04:58:38.709 --> 04:58:40.938
So, there is a method call and 
there is a slip somewhere 

04:58:40.939 --> 04:58:42.939
inside, and that means that 
there is a problem.

04:58:46.588 --> 04:58:48.588
There is some

04:58:50.329 --> 04:58:54.002
synchronized meta or other lock 
that breaks the execution.  And 

04:58:54.003 --> 04:58:56.502
the question is, are you 
planning to do some automatic 

04:58:56.503 --> 04:58:58.503
analysis of these 

04:59:01.192 --> 04:59:03.653
to find out that shared 
preferences get in blocks the 

04:59:03.654 --> 04:59:06.905
execution?
&gt;&gt; ESTEBAN DE LA CANAL: Well, 

04:59:06.906 --> 04:59:12.198
this is back to what I was 
saying that we are not 

04:59:12.199 --> 04:59:13.420
opinionated in telling you when 
you did something, might not be 

04:59:13.421 --> 04:59:19.154
wrong.  So you're saying, there 
are slips.  Slips are okay.  You

04:59:19.155 --> 04:59:21.155
can have slops in your code and 
this can be part of your design.

04:59:23.239 --> 04:59:24.463
So, just the fact that a thread 
goes to sleep is not a bad 

04:59:24.464 --> 04:59:26.464
thing.

04:59:27.924 --> 04:59:30.171
But, if there is thread 
contention, you should be able 

04:59:30.172 --> 04:59:32.172
to see it while using the CPU 
Profiler as it is right now.

04:59:34.655 --> 04:59:36.655
So, you can see especially on 
sys 

04:59:38.307 --> 04:59:39.964
trace, you see if your thread is
waiting, is runnable, or is 

04:59:39.965 --> 04:59:41.990
running.  And those three 
differences are very important.

04:59:47.151 --> 04:59:49.186
If it is runnable, you're not in
sleep.  You're ready to run but 

04:59:49.187 --> 04:59:51.187
there are many 

04:59:52.865 --> 04:59:53.874
other threads using the CPUs 
that have more priority than 

04:59:53.875 --> 04:59:56.136
you, whatever, and you didn't 
run so you're not on the slip 

04:59:57.775 --> 04:59:59.775
but you didn't run so you need 
to look for that.

05:00:00.416 --> 05:00:02.437
And the other scenario is when 
your thread is sleeping then, 

05:00:02.438 --> 05:00:06.099
yes, it could be because you are
asleep or you are waiting on a 

05:00:06.100 --> 05:00:08.785
section or something else and if
you do have a deadlock then you 

05:00:10.008 --> 05:00:12.274
need to analyze it like that.  
You need to lock at which 

05:00:12.275 --> 05:00:16.137
threads are stopped and where in
your code and start feeling out 

05:00:16.138 --> 05:00:17.957
whether that's intentional or 
not.

05:00:17.958 --> 05:00:19.958
&gt;&gt; Yeah, but I just thought that
might 

05:00:22.655 --> 05:00:23.665
be a red flag or yellow flag --
&gt;&gt; ESTEBAN DE LA CANAL: Your 

05:00:23.666 --> 05:00:25.666
thread will 

05:00:26.942 --> 05:00:28.971
show up as waiting, so, if it is
in user space, it will show up 

05:00:28.972 --> 05:00:30.972
as waiting, and that's your 
flag.

05:00:31.201 --> 05:00:35.109
&gt;&gt; Thank you.
&gt;&gt; Hey.

05:00:36.103 --> 05:00:38.103
&gt;&gt; ESTEBAN DE LA CANAL: Hello.

05:00:40.789 --> 05:00:43.432
&gt;&gt; Is there a existing way to 
attach a debugger without 

05:00:43.433 --> 05:00:45.433
relaunching the app so 

05:00:48.948 --> 05:00:50.948
that we can debug points when 
you launch?

05:00:51.993 --> 05:00:55.867
&gt;&gt; ESTEBAN DE LA CANAL: Can you 
speak more in the microphone?  I

05:00:55.868 --> 05:00:58.325
can't hear you.
&gt;&gt; Okay. Is there a way you can 

05:00:58.326 --> 05:01:00.326
attach a 

05:01:02.826 --> 05:01:04.826
debugger so debugs when it 
launches.

05:01:05.868 --> 05:01:07.501
When you launch the app so we 
hit the debugger.

05:01:07.502 --> 05:01:10.563
&gt;&gt; ESTEBAN DE LA CANAL: Well, if
I understand your question, no. 

05:01:10.564 --> 05:01:12.564
Right now, the only way is to 
attach 

05:01:14.644 --> 05:01:17.485
the the Profilers on a 
debuggable app and attaching the

05:01:17.486 --> 05:01:19.486
debugger while at the 

05:01:21.164 --> 05:01:24.435
same time profiling do things 
that you don't want to do.  We 

05:01:24.436 --> 05:01:26.436
are planning on allowing you to 
run 

05:01:29.518 --> 05:01:31.365
the Profilers on a nondebuggable
app so there are no issues 

05:01:31.366 --> 05:01:33.366
because of the debuggable 
information in the app but we 

05:01:33.438 --> 05:01:36.308
don't have that yet.
&gt;&gt; Okay. Thanks.

05:01:37.141 --> 05:01:39.141
&gt;&gt; Hi.

05:01:40.603 --> 05:01:42.054
I wanted to know when you use 
the Profiler when you have the 

05:01:42.055 --> 05:01:47.327
more images in the app, is there
any way to see like I see the 

05:01:47.328 --> 05:01:49.328
bit maps, but is there any way 

05:01:51.199 --> 05:01:53.199
to see the preview of those  
images?

05:01:53.450 --> 05:01:55.450
&gt;&gt; ESTEBAN DE LA CANAL: Previews
what, sorry?

05:01:57.357 --> 05:01:58.372
&gt;&gt; Preview of the images, bit 
maps?

05:01:58.373 --> 05:02:00.604
&gt;&gt; ESTEBAN DE LA CANAL: Not at 
the moment, no.  But if you want

05:02:00.605 --> 05:02:05.286
to file a bug with the feature 
requests, we'll look at it.  And

05:02:05.287 --> 05:02:07.527
I'm going to hang around after 
this, and I'm going to be in the

05:02:07.528 --> 05:02:09.528
sandbox if you want to ask more 
questions.

05:02:12.424 --> 05:02:14.424
But, I'm going to be kicked out 
of the 

05:02:16.211 --> 05:02:18.477
stage in nine, eight, seven.  
Yeah, your question is fine.

05:02:18.904 --> 05:02:24.418
&gt;&gt; Okay. Is it possible to use 
the Profilers with an app that 

05:02:24.419 --> 05:02:26.419
isn't built with Android Studio?
&gt;&gt; ESTEBAN DE LA CANAL: Yes.

05:02:27.683 --> 05:02:29.683
&gt;&gt; Because some of the features 
stop working when we --

05:02:30.324 --> 05:02:32.324
&gt;&gt; ESTEBAN DE LA CANAL: If you 
are using 

05:02:33.338 --> 05:02:38.295
an Oreo phone and your app is 
debuggable you can build it with

05:02:38.296 --> 05:02:40.296
whatever you want.
&gt;&gt; Okay. Thank you.

05:02:40.542 --> 05:02:42.542
&gt;&gt; ESTEBAN DE LA CANAL: Thank 
you.

05:02:44.461 --> 05:02:46.092
(Session was concluded at 3:10 
PM CT)

05:02:46.093 --> 05:02:48.426
***
This text, document, or file is 

05:02:46.093 --> 05:02:50.093
based on live transcription.  
Communication Access Realtime 

05:02:46.093 --> 05:02:50.226
Translation (CART), captioning, 
and/or live transcription are 

05:02:46.093 --> 05:02:49.093
provided in order to facilitate 
communication

05:02:46.093 --> 05:02:50.226
accessibility and may not be a 
totally verbatim record of the 

05:02:46.093 --> 05:02:49.826
proceedings.  This text, 
document, or file is not to be 

05:02:46.093 --> 05:02:50.226
distributed or used in any way 
that may violate copyright law.

05:02:46.093 --> 05:02:48.093
***

05:02:53.796 --> 05:02:55.254
Realtime captioning on this 
screen

06:14:36.966 --> 06:14:39.824
GOOGLE I/O 2018
MOUNTAIN VIEW, CALIFORNIA

06:14:44.139 --> 06:14:46.139
MAY 10, 2018
STAGE 2

06:14:48.454 --> 06:14:50.454
2:30 PM

06:14:54.295 --> 06:14:56.295
MIGRATE YOUR EXISTING

06:14:59.082 --> 06:15:01.082
APP TO TARGET ANDROID OREO

06:15:04.781 --> 06:15:07.083
T30174

06:22:39.255 --> 06:22:41.255
&gt;&gt; All right.

06:22:42.699 --> 06:22:44.699
Welcome to

06:22:45.834 --> 06:22:49.498
migrating your app to Android O 
and beyond.  Hi.  I'm Fred 

06:22:49.499 --> 06:22:52.210
Chung, develop eradicate.
&gt;&gt; DAN GALPIN: Hi, I'm Dan 

06:22:52.211 --> 06:22:54.857
Galpin, develop eradicate.
&gt;&gt; ERIC KUXHAUSEN: Hi, I'm Eric.

06:22:56.281 --> 06:22:58.317
Not a develop eradicate.  I'm 
the lead software engineer 

06:23:00.352 --> 06:23:02.352
responsible for migrating the 
Google 

06:23:04.853 --> 06:23:06.264
Play Store app to target API 26.
Thank you for joining us on the 

06:23:06.265 --> 06:23:10.989
last day.  This is where they 
scheduled the most anticipated 

06:23:10.990 --> 06:23:12.990
sessions except for that 

06:23:14.039 --> 06:23:18.506
funny improve one that we don't 
record.  Sorry, home viewers.  

06:23:18.507 --> 06:23:20.507
So, you're here for what is 
really the 

06:23:23.196 --> 06:23:25.196
grand fin finale of Google I/O.

06:23:28.545 --> 06:23:30.603
&gt;&gt; Well, let the grand finale 
begin.  Why migrate?

06:23:34.473 --> 06:23:36.106
There are lots of reasons but 
foremost in your mind, 

06:23:36.107 --> 06:23:38.107
especially in your on 

06:23:39.822 --> 06:23:42.258
Google play, is that for new 
apps by the end of this year you

06:23:42.259 --> 06:23:44.259
must be target egg 

06:23:45.746 --> 06:23:48.214
at least API level 26 or Android
8.0.  Likewise, for app updates,

06:23:48.215 --> 06:23:53.365
they must also by targeting at 
least API level 26 by November 

06:23:53.366 --> 06:23:55.366
of 2018.

06:23:56.405 --> 06:23:58.034
That is if you wish to consider 
using app updates going forward.

06:23:58.035 --> 06:24:01.529
&gt;&gt; Now, every new Android 
version introduced changes that 

06:24:01.530 --> 06:24:03.530
bring 

06:24:06.181 --> 06:24:08.181
significant security and policy

06:24:11.776 --> 06:24:14.062
, and enhances overall.  Some of
these only have apps through 

06:24:17.725 --> 06:24:19.795
their target SDK management 
attribute, also then as target 

06:24:19.796 --> 06:24:22.264
API level.  In fact if you try 
to upload a SDK 

06:24:25.333 --> 06:24:26.964
with a target less than 26, 
you'll see a friendly reminder 

06:24:26.965 --> 06:24:29.008
like this.
&gt;&gt; And I'm here because we 

06:24:29.009 --> 06:24:33.626
wanted to keep updating the Play
Store app on Google Play after 

06:24:33.627 --> 06:24:35.269
the November deadline.
&gt;&gt; FRED CHUNG: So, let's go over

06:24:35.270 --> 06:24:37.270
some basics real quick, 
everyone.

06:24:40.975 --> 06:24:42.975
Minimum SDK is the lowest 
platform 

06:24:45.772 --> 06:24:47.805
version your app is willing to 
support.  It's ultimately tied 

06:24:47.806 --> 06:24:49.806
to multiple penetration of 
variation Android releases.

06:24:54.966 --> 06:24:56.908
&gt;&gt; The compile SDK is literally 
the SDK headers in stub library 

06:24:56.909 --> 06:25:00.166
that your project links to.
&gt;&gt; And the important one, of 

06:25:00.167 --> 06:25:02.610
course, is the one I'm talking 
about.  The target SDK version 

06:25:02.611 --> 06:25:04.611
is the 

06:25:08.345 --> 06:25:11.016
platform's way to ensure 
backwards compatibility.  It 

06:25:11.017 --> 06:25:13.257
means you only have certain 
behavior changes applied as 

06:25:13.258 --> 06:25:17.220
certain target SDK versions.
&gt;&gt; FRED CHUNG: So, technically, 

06:25:17.221 --> 06:25:19.221
this needs to be true.

06:25:21.262 --> 06:25:24.167
And this is typical and 
recommended case since you 

06:25:24.168 --> 06:25:26.818
probably care about 95 percent 
of users out there that are not 

06:25:31.781 --> 06:25:33.203
quite targeting the latest 
versions of Android just yet 

06:25:33.204 --> 06:25:35.204
although we are working to 
improve that.

06:25:36.154 --> 06:25:38.439
&gt;&gt; So if you don't change your 
target SDK to at least version 

06:25:38.440 --> 06:25:40.440
26, you might 

06:25:42.726 --> 06:25:44.732
not have to deal with things 
like runtime permissions, 

06:25:44.733 --> 06:25:50.380
AlarmManager changes, coming up 
with different ways to handle 

06:25:50.381 --> 06:25:52.249
broadcastreceiver actions and 
avoiding background services.

06:25:52.250 --> 06:25:56.947
&gt;&gt; But there's a good chance 
your app will waste network and 

06:25:56.948 --> 06:25:59.407
battery while making the device 
experience less fast and fluid.

06:26:04.676 --> 06:26:06.676
&gt;&gt; So, if you are migrating from
a

06:26:09.050 --> 06:26:11.050
preinversion, one of the biggest

06:26:12.332 --> 06:26:14.142
changes are about runtime 
permissions.  Really about user 

06:26:14.143 --> 06:26:16.143
privacy and trust 

06:26:18.240 --> 06:26:19.662
but also for apps to ask for 
sensitive permissions in 

06:26:19.663 --> 06:26:21.663
condition text and that's a good
thing for apps.

06:26:23.949 --> 06:26:25.794
You don't want someone to not 
install your apps just because 

06:26:25.795 --> 06:26:28.028
you are asking for permission 
for sensitive information 

06:26:32.486 --> 06:26:34.513
in one particular flow within 
your app.  So, first of all, not

06:26:34.514 --> 06:26:37.601
all permissions are runtime 
ones, just this simple, easy to 

06:26:37.602 --> 06:26:39.602
remember list.
&gt;&gt; But worry not, developers.

06:26:43.542 --> 06:26:45.994
You can think of these the way 
the user sees them in terms of 

06:26:45.995 --> 06:26:48.638
these broader categories and the
first question you should have 

06:26:48.639 --> 06:26:52.296
is whether the app really needs 
the permission at all.  After 

06:26:52.297 --> 06:26:54.751
all, removing the permission is 
easy.  Now, Eric, how did the 

06:26:54.752 --> 06:26:56.844
Play Store app handle this?
&gt;&gt; ERIC KUXHAUSEN: Well, it's 

06:26:56.845 --> 06:27:02.179
simple.  All you need to do is 
make sure their app is 

06:27:02.180 --> 06:27:04.180
pregranted the permissions on 
the systems image.

06:27:07.056 --> 06:27:08.479
&gt;&gt; FRED CHUNG: That's not very 
helpful, Eric.

06:27:08.480 --> 06:27:10.311
&gt;&gt; ERIC KUXHAUSEN: That being 
said, we try to use as few of 

06:27:10.312 --> 06:27:12.312
these as possible.

06:27:13.375 --> 06:27:15.644
And of course, just because your
app isn't yet targeting M, it 

06:27:15.645 --> 06:27:17.645
doesn't even 

06:27:19.761 --> 06:27:21.386
your users can't go and disable 
any permissions they want to 

06:27:21.387 --> 06:27:23.623
have.
&gt;&gt; FRED CHUNG: And there are 

06:27:23.624 --> 06:27:26.089
special permissions you need to 
redirect.

06:27:29.746 --> 06:27:32.017
For example, overlay windows or 
permissions like screen capture.

06:27:33.061 --> 06:27:37.325
&gt;&gt; ERIC KUXHAUSEN: Now, being 
the work of the UI, runtime 

06:27:37.326 --> 06:27:41.852
activity require fragment that 
is overridden the method.  This 

06:27:41.853 --> 06:27:43.853
means that your view layer like 
activities and fragments need to

06:27:44.705 --> 06:27:45.958
anticipate any permissions 
actually required by the other 

06:27:45.959 --> 06:27:50.022
layers.  All right, here's a 
great transition.  Let's talk 

06:27:50.023 --> 06:27:52.023
about alarms.

06:27:57.746 --> 06:27:59.746
Alarms and Android take two 
basic forms.

06:28:01.715 --> 06:28:03.715
They are literally alarms that 
allow 

06:28:04.768 --> 06:28:05.722
an app to wake itself up to 
deliver a notification of some 

06:28:05.723 --> 06:28:07.723
realtime event such 

06:28:08.724 --> 06:28:10.716
as waking you up or an upcoming 
appointment, or they are a way 

06:28:10.717 --> 06:28:12.722
of scheduling work to happen at 
some time in the future after 

06:28:12.723 --> 06:28:12.939
the app is closed.
And at the beginning of Android,

06:28:12.940 --> 06:28:14.940
this was a single API.

06:28:18.042 --> 06:28:19.888
But back in Kitkat, we made 
AlarmManager not exact unless it

06:28:19.889 --> 06:28:23.155
was explicitly requested which 
makes it better for scheduling 

06:28:23.156 --> 06:28:28.643
future work.  Now, if an app 
needs to notify the user at a 

06:28:28.644 --> 06:28:30.889
precise time, we added the 
method set exact, and here's 

06:28:30.890 --> 06:28:32.922
where we've implemented a method
in the support 

06:28:36.405 --> 06:28:38.405
library to call it on kitkat and
above.

06:28:38.848 --> 06:28:40.848
&gt;&gt; We don't use any exact alarms
in the Play Store app.

06:28:42.775 --> 06:28:44.601
The alarms we do use are inexact
which allows the system to batch

06:28:44.602 --> 06:28:46.629
them for better battery and 
system health.

06:28:50.239 --> 06:28:52.239
Now HMarshmallow added those 
which would 

06:28:56.035 --> 06:28:58.035
allow it to go -- so we added 
the method 

06:29:02.724 --> 06:29:04.746
allow while idle to allow the 
harm from doze and note that it 

06:29:04.747 --> 06:29:06.788
actually calls the previous 
support library method for said 

06:29:09.664 --> 06:29:11.930
exact on earlier platform 
versions.

06:29:13.566 --> 06:29:16.220
&gt;&gt; FRED CHUNG: So after all that
exposition, the take aways are 

06:29:16.221 --> 06:29:18.221
pretty simple.

06:29:21.330 --> 06:29:24.591
Consider moving work to DCM, a 
job via work manager.  Work 

06:29:24.592 --> 06:29:26.628
manager is the newest work 
scheduling thing that we launch 

06:29:26.629 --> 06:29:28.863
the.
&gt;&gt; ERICA JACKSON: Now, work 

06:29:28.864 --> 06:29:32.140
manager is a part of --
&gt;&gt; Now, work manager is a part 

06:29:32.141 --> 06:29:34.141
of Jetpack and chooses the best 
things to 

06:29:38.251 --> 06:29:40.080
run such as API version and app 
stay, and when it becomes stable

06:29:40.081 --> 06:29:43.751
it will be the recommended API 
forerunner tasks unless we come 

06:29:43.752 --> 06:29:45.752
up with something better before 
then.

06:29:46.246 --> 06:29:48.063
&gt;&gt; Play Store was able to see 
our background tasks regularly 

06:29:48.064 --> 06:29:50.064
reach 2 

06:29:54.263 --> 06:29:56.263
percent more users on kitkat 
with we 

06:29:57.737 --> 06:30:00.586
adopted Firebase -- this 
includes system and battery.  If

06:30:00.587 --> 06:30:02.587
you do have to use the alarms, 
use 

06:30:05.031 --> 06:30:06.727
the least exact ones you can
&gt;&gt; FRED CHUNG: Now, remember 

06:30:06.728 --> 06:30:08.728
that the 

06:30:10.254 --> 06:30:12.268
most exact alarms should only be
used every 15 minutes or so, so 

06:30:12.269 --> 06:30:14.269
you should only be using those 
judiciously.

06:30:15.271 --> 06:30:17.271
&gt;&gt; Oh, yeah.  Work manager.

06:30:18.525 --> 06:30:20.525
So, let's talk again about 
broadcast receivers.

06:30:20.976 --> 06:30:22.398
&gt;&gt; Should we talk about 
broadcast receivers?

06:30:22.399 --> 06:30:24.399
&gt;&gt; Yes.
&gt;&gt;

06:30:24.652 --> 06:30:26.079
&gt;&gt; FRED CHUNG: So, broadcast 
receivers, I think many of you 

06:30:26.080 --> 06:30:28.080
probably know that, 

06:30:29.342 --> 06:30:31.813
right, that's used by the 
platform to notify and launch 

06:30:31.814 --> 06:30:34.259
apps in response to system-wide 
events.  It's one of the reasons

06:30:34.260 --> 06:30:36.260
that Android has such a powerful
API service.

06:30:39.139 --> 06:30:42.604
&gt;&gt; Now, with great power, comes 
great responsibility.  And it, 

06:30:42.605 --> 06:30:44.449
in response to the way that 
these end points have been used,

06:30:44.450 --> 06:30:46.495
most of these can no longer 
launch your app.

06:30:49.961 --> 06:30:51.961
At least once you target O.

06:30:54.861 --> 06:30:57.313
&gt;&gt; Well, there are exceptions, 
of course.  It's Android, right?

06:30:59.551 --> 06:31:01.551
Many of these happen very rarely
such 

06:31:04.648 --> 06:31:06.077
as changes in locale or in some 
cases there are just no 

06:31:06.078 --> 06:31:08.078
alternatives yet to the 
broadcasts that need them.

06:31:12.422 --> 06:31:14.862
For example, like those USB 
accessory ones.  Let's check on 

06:31:14.863 --> 06:31:16.863
example of how to avoid using 
broadcasts.

06:31:20.780 --> 06:31:22.780
So, for a job, you can do so by 

06:31:24.036 --> 06:31:26.080
setting up the proper criteria 
and network service, and then 

06:31:26.081 --> 06:31:28.928
you have functionality that's 
comparable to listening to 

06:31:28.929 --> 06:31:32.423
network state change broadcasts.
And if you do have code like 

06:31:32.424 --> 06:31:34.424
this in 

06:31:35.910 --> 06:31:38.781
your manifest on older versions 
of Android, you can disable the 

06:31:38.782 --> 06:31:42.855
listener to the connectivity 
change and, you know, just leave

06:31:42.856 --> 06:31:44.856
it disabled and then what are 
you going to do?

06:31:46.520 --> 06:31:48.748
You can then enable the receiver
by setting the component enable 

06:31:48.749 --> 06:31:52.847
setting in the package manager.
&gt;&gt; Another exception is if you 

06:31:52.848 --> 06:31:57.344
need to perform any tasks after 
your package has been updated, 

06:31:57.345 --> 06:32:01.038
for example, rescheduling alarms
or updating your database.  You 

06:32:01.039 --> 06:32:03.039
can still register receiver in 

06:32:04.305 --> 06:32:06.763
your manifest for the action my 
package replaced which continues

06:32:06.764 --> 06:32:08.764
to work because 

06:32:09.814 --> 06:32:11.450
it's one of the explicit 
broadcasts targeted just to your

06:32:11.451 --> 06:32:15.155
app.  Now, if you really need it
did some work in every package 

06:32:15.156 --> 06:32:23.583
update and you probably don't 
because you can no longer be 

06:32:23.584 --> 06:32:26.015
launched by action pack replace 
events but we do have an API 

06:32:26.016 --> 06:32:28.053
called get change packages which
allows you to see what 

06:32:31.103 --> 06:32:33.798
packages have changed since the 
previous save sequence number.  

06:32:33.799 --> 06:32:36.648
Now, in life, running is usually
healthy, I probably should do 

06:32:36.649 --> 06:32:40.929
more but Android app wants to 
run as little as possible.  Lazy

06:32:40.930 --> 06:32:42.766
apps are actually better apps.  
I should make a manifest or 

06:32:42.767 --> 06:32:45.040
something.  Fred, what do you 
think we should actually --

06:32:46.881 --> 06:32:49.322
&gt;&gt; FRED CHUNG: Sounds good to 
me.  First of all, let's talk 

06:32:49.323 --> 06:32:54.485
about what it means to be in the
foreground because it's not 

06:32:54.486 --> 06:32:56.344
completely obvious, right?  
There are some typical cases 

06:32:56.345 --> 06:33:01.437
like when your app is visible to
users or when you're using 

06:33:01.438 --> 06:33:03.438
foreground service or if 

06:33:08.514 --> 06:33:10.514
your app is bound to a 
foreground app so

06:33:11.642 --> 06:33:12.446
your app is also in the 
foreground in these exceptional 

06:33:12.447 --> 06:33:15.608
cases.  Your app is in the 
background when you're not 

06:33:15.609 --> 06:33:17.609
visible such as when it's 

06:33:19.849 --> 06:33:23.659
running a standard service, 
broad service or broadcast 

06:33:23.660 --> 06:33:25.887
receiver.  And when you're on O 
plus, starting a 

06:33:28.947 --> 06:33:30.947
service when running in the 
background 

06:33:32.083 --> 06:33:33.701
will TensorFlow an exception 
called illegal stature exception

06:33:33.702 --> 06:33:36.187
which is not good.
&gt;&gt; Now you can start services 

06:33:36.188 --> 06:33:40.909
when your app is in the 
foreground and they'll continue 

06:33:40.910 --> 06:33:44.572
to run for about a member after 
your app is backgrounded.  This 

06:33:44.573 --> 06:33:46.005
is important because the system 
releases any wake when you have 

06:33:46.006 --> 06:33:50.321
no components such as activities
or services.  This applies to 

06:33:50.322 --> 06:33:52.322
all apps, not just apps 
targeting O.

06:33:52.759 --> 06:33:55.608
&gt;&gt; There are a few cases where 
your app is still allowed to run

06:33:55.609 --> 06:33:58.899
if it's foreground and start 
services.  For example, in 

06:33:58.900 --> 06:34:00.900
response to 

06:34:01.922 --> 06:34:07.271
notification action, a high 
priority is Cloud message or in 

06:34:07.272 --> 06:34:09.298
response to MMS or SMS delivery.
So, let's talk through some 

06:34:09.299 --> 06:34:12.548
solutions forerunner in the 
background without background 

06:34:12.549 --> 06:34:15.431
services.

06:34:18.935 --> 06:34:20.784
&gt;&gt; First of all, you use DCM 
fire job -- fork manager for 

06:34:20.785 --> 06:34:23.009
background tasks.  Now, there 
are many good reasons for this.

06:34:26.727 --> 06:34:27.743
It creates a consistent API 
surface across many Android 

06:34:27.744 --> 06:34:30.183
versions, for example.
&gt;&gt; Or if you don't care as much 

06:34:30.184 --> 06:34:34.894
about having your app behave 
consistently across platforms, 

06:34:34.895 --> 06:34:36.895
but want to move to O with the 
least amount of work required, 

06:34:41.042 --> 06:34:43.042
you can also use Java intent 
service

06:34:43.310 --> 06:34:45.310
&gt;&gt; But seriously, consider using
work manager.

06:34:46.976 --> 06:34:49.403
Leverage its constraints and 
make your life easier.

06:34:51.657 --> 06:34:52.682
&gt;&gt; So,le Google Play Store app 
didn't have the analyticsy of 

06:34:52.683 --> 06:34:54.720
using work manager because it 
didn't exist yet.

06:34:57.967 --> 06:34:59.199
That meant we had to use job 
scheduler and Firebase job 

06:34:59.200 --> 06:35:03.876
dispatcher.  Now the first thing
we learned is not o to use job 

06:35:03.877 --> 06:35:05.499
scheduler on Android L unless 
you really understand it and 

06:35:05.500 --> 06:35:10.210
have alarm watch dogs when it 
doesn't behave as expected.  

06:35:10.211 --> 06:35:12.211
Also, use workarounds.

06:35:15.940 --> 06:35:17.940
For example, on L and the first 

06:35:19.806 --> 06:35:21.107
release of M, job scheduler 
won't actually run your job 

06:35:21.108 --> 06:35:25.408
unless there are two jobs with 
the same constraints met.  You 

06:35:25.409 --> 06:35:27.225
can work around this by 
scheduling two jobs with 

06:35:27.226 --> 06:35:29.226
matching constraints.

06:35:31.506 --> 06:35:32.324
&gt;&gt; But seriously, like, work 
manager.

06:35:32.325 --> 06:35:34.325
&gt;&gt; Work manager.

06:35:36.614 --> 06:35:40.079
&gt;&gt; Things do get much better for
job scheduler on MR1 and above. 

06:35:40.080 --> 06:35:42.080
However, another quirk is that 
you 

06:35:43.161 --> 06:35:45.801
should avoid calling set minimum
latency to zero.  This could 

06:35:45.802 --> 06:35:49.280
interfere with the override 
deadline on some releases.  The 

06:35:49.281 --> 06:35:50.716
override deadline is a way of 
making sure your job runs with a

06:35:50.717 --> 06:35:52.767
fixed period of time even if the
constraints aren't met.

06:35:55.720 --> 06:35:57.720
&gt;&gt; Or you could just use work 
manager 

06:35:59.429 --> 06:36:01.446
which doesn't actually have 
override deadlines but what you 

06:36:01.447 --> 06:36:05.127
should do is schedule a second 
job as a watch dog to perform a 

06:36:05.128 --> 06:36:07.128
similar function.

06:36:09.981 --> 06:36:12.069
&gt;&gt; Here are a few things to 
consider when oozing job 

06:36:12.070 --> 06:36:14.070
scheduleer or work manager.

06:36:17.276 --> 06:36:17.877
Android tries to cover captive 
portals but it's an imperfect 

06:36:17.878 --> 06:36:23.037
art.  In addition, Android will 
occasionally wake up your app 

06:36:23.038 --> 06:36:25.687
right before network is 
available for your app.  All 

06:36:25.688 --> 06:36:27.688
this means is you need to have 
proper error handling to ensure 

06:36:28.348 --> 06:36:30.348
rescheduling of jobs.

06:36:31.417 --> 06:36:33.238
When play store added 
exponential backoff to our jobs 

06:36:33.239 --> 06:36:35.675
we saw 19 percent more 
successful background tasks.

06:36:37.922 --> 06:36:40.356
The key here, though, is let the
system do its work.  It's easy 

06:36:40.357 --> 06:36:42.190
to make the mistake of 
rescheduling with the same job 

06:36:42.191 --> 06:36:44.191
ID while 

06:36:45.289 --> 06:36:47.289
also using system backoffs.

06:36:48.562 --> 06:36:50.562
This can interfere or even reset
the backoff rate.

06:36:51.626 --> 06:36:53.482
&gt;&gt; DAN GALPIN: Or with 
WorkManager, actually, yeah, 

06:36:53.483 --> 06:36:55.483
don't do that either because it 
will have the same results.

06:37:01.740 --> 06:37:03.743
&gt;&gt; FRED CHUNG: So, for APIs that
require that you use pending 

06:37:03.744 --> 06:37:05.804
intents you can change the 
pending intent targets from 

06:37:07.829 --> 06:37:09.335
service to a broadcast receiver.
Now, if your task will execute 

06:37:09.336 --> 06:37:11.336
within 

06:37:15.841 --> 06:37:18.352
30 seconds, you can then call go
asynch and run the work within 

06:37:18.353 --> 06:37:20.353
your broadcast receiver with h 
by the way is 

06:37:23.455 --> 06:37:25.455
a super light weight getting 
things done.

06:37:28.697 --> 06:37:30.697
You aren't guaranteed to have

06:37:33.457 --> 06:37:34.883
network or wake locks so there 
are still many ways where you 

06:37:34.884 --> 06:37:36.712
should.
&gt;&gt; DAN GALPIN: Schedule a job 

06:37:36.713 --> 06:37:40.223
within your broadcast receiver 
using work manager.

06:37:45.090 --> 06:37:47.090
&gt;&gt; FRED CHUNG: So if you have 
externally 

06:37:50.654 --> 06:37:51.680
triggered time sensitive event 
that's require immediate 

06:37:51.681 --> 06:37:53.928
attention consider using 
Firebase Cloud messaging to 

06:37:53.929 --> 06:37:55.929
notify your app.

06:37:57.464 --> 06:37:59.464
FCM supports high and normal 
priority messages.

06:38:01.308 --> 06:38:03.320
High priority messages wake the 
device from doze which mean 

06:38:03.321 --> 06:38:06.813
that's a lot of them aren't good
for system health.  If the task 

06:38:06.814 --> 06:38:09.051
can run in less than ten 
seconds, you can execute it 

06:38:09.052 --> 06:38:13.326
right away.  Schedule a yob with
&gt;&gt; DAN GALPIN: Work manager.

06:38:18.279 --> 06:38:20.118
Ideal lie, these are user 
centric tasks that run for a 

06:38:20.119 --> 06:38:24.632
long time.  Examples are maps, 
navigation, fitness tracking, 

06:38:24.633 --> 06:38:27.073
playing music.
&gt;&gt; ERIC KUXHAUSEN: In play 

06:38:27.074 --> 06:38:31.362
store, we use a foreground 
service when we restore apps.  

06:38:31.363 --> 06:38:33.017
This is okay because it's long 
running work in response to user

06:38:33.018 --> 06:38:36.301
interaction.  But, it's not as 
fun as listening to music.

06:38:40.437 --> 06:38:42.270
&gt;&gt; FRED CHUNG: So the good news 
is that these other things are 

06:38:42.271 --> 06:38:44.271
already impacting your apps but 
perhaps you haven't 

06:38:48.153 --> 06:38:50.153
noticed yet

06:38:51.908 --> 06:38:54.581
.  So, in Android N, new photo 
broadcasts no longer happen, 

06:38:54.582 --> 06:38:58.853
right, but can be replaced by 
trigger content URIs for jobs --

06:38:58.854 --> 06:39:00.854
I mean works.

06:39:02.343 --> 06:39:04.588
So, it is what it looks like 
using the new work manager API.

06:39:07.421 --> 06:39:10.492
&gt;&gt; DAN GALPIN: Now if your app 
is running in the background on 

06:39:10.493 --> 06:39:14.181
an Android O plus device the 
location service computes a new 

06:39:14.182 --> 06:39:16.836
location for your app less often
even if your app requests more 

06:39:16.837 --> 06:39:20.906
frequent updates.  Even full 
Wi-Fi scans are only performed 

06:39:20.907 --> 06:39:22.964
for background apps a few times 
every hour so if you're called 

06:39:25.624 --> 06:39:26.848
more application the Wi-Fi 
manager will actually just 

06:39:26.849 --> 06:39:29.318
provide cache results.
Now, if you need to know when 

06:39:29.319 --> 06:39:31.319
the user 

06:39:32.624 --> 06:39:34.624
reaches a specific location, use
geo fencing.

06:39:35.909 --> 06:39:38.605
Now, there are only 100 
geofences that can be active so 

06:39:38.606 --> 06:39:40.606
if you need more sites 

06:39:42.913 --> 06:39:45.191
that than that you can actually 
use regional geofences to swap 

06:39:45.192 --> 06:39:47.553
in.
That being said, beacons are 

06:39:47.554 --> 06:39:52.091
awesome.  You can use the nearby
notifications API, and that's 

06:39:52.092 --> 06:39:54.092
important, particularly 

06:39:56.230 --> 06:39:58.230
if you're a certain prolific 
coffee vendor.

06:39:58.894 --> 06:40:00.726
&gt;&gt; ERIC KUXHAUSEN: You can also 
use the batch version of the 

06:40:00.727 --> 06:40:04.213
fuse location.  Specific face a 
maximum weight location that is 

06:40:04.214 --> 06:40:08.594
acceptable for your use case and
the system will attempt to batch

06:40:08.595 --> 06:40:11.445
location updates so that your 
app is woken up less frequently.

06:40:13.481 --> 06:40:15.481
This will optimize battery use.

06:40:17.581 --> 06:40:19.581
You can also use passive 
location that 

06:40:24.206 --> 06:40:25.441
enables your app to 
opportunisticallyically update 

06:40:25.442 --> 06:40:29.754
on other apps of keep in mind, 
though, that if your apps are 

06:40:29.755 --> 06:40:31.998
tied to anything such as network
throws, you should throttle 

06:40:32.805 --> 06:40:34.868
those as well.
&gt;&gt; FRED CHUNG: So through 

06:40:34.869 --> 06:40:38.181
batching and passive location, 
we can work with location 

06:40:38.182 --> 06:40:40.682
updates in a power efficient 
manner.  Next, let's go through 

06:40:40.683 --> 06:40:42.683
some related improvements in the
platform.

06:40:45.559 --> 06:40:47.559
So

06:40:49.354 --> 06:40:51.180
in the past several Android 
we've introduced a series of 

06:40:51.181 --> 06:40:54.449
battery optimization based on 
referring and restricting 

06:40:54.450 --> 06:40:56.292
background tasks.  You probably 
are familiar with some of these 

06:40:56.293 --> 06:40:58.293
already.

06:41:01.653 --> 06:41:03.312
For example, a device could 
enter doze when the device is 

06:41:03.313 --> 06:41:05.342
unplugged and when the device 
isn't being used for quite some 

06:41:05.343 --> 06:41:07.343
time.

06:41:08.795 --> 06:41:11.031
In doze, apps have to finish any
pending jobs in some periodic 

06:41:11.903 --> 06:41:14.581
maintenance windows.
&gt;&gt; DAN GALPIN: On N plus, doze 

06:41:14.582 --> 06:41:16.615
was extended for on the go use 
cases such as 

06:41:20.504 --> 06:41:22.504
when a device is sitting in the 
useer's pock.

06:41:24.378 --> 06:41:27.008
Now, app standby was introduced 
when where it imposes task 

06:41:27.009 --> 06:41:29.009
restrictions based upon app 
usage.

06:41:29.257 --> 06:41:30.308
&gt;&gt; ERIC KUXHAUSEN: And let me 
tell you about the brand new 

06:41:30.309 --> 06:41:32.309
stuff.

06:41:33.403 --> 06:41:34.824
In Android P, usage based 
restrictions are applied in a 

06:41:34.825 --> 06:41:38.897
more fine grained way.  You may 
have already learned about this 

06:41:38.898 --> 06:41:41.565
in the earlier I/O talk, don't 
let your app drain your users' 

06:41:41.566 --> 06:41:44.850
battery.  Apps will be added to 
one of the standby buckets based

06:41:44.851 --> 06:41:46.851
on usage.

06:41:49.617 --> 06:41:52.246
The system applies progressively
more restrictions on your app as

06:41:52.247 --> 06:41:54.247
it goes from the -- to the rare 
bucket.

06:41:58.505 --> 06:42:00.505
In addition, battery

06:42:01.830 --> 06:42:03.830
saver allows you to have 
additional battery life.

06:42:05.965 --> 06:42:07.965
This leads to some degradation 
in 

06:42:08.978 --> 06:42:10.978
functionality

06:42:12.484 --> 06:42:13.950
such as location requests not 
being available, however it 

06:42:13.951 --> 06:42:15.951
allows your battery to last a 
little bit longer.

06:42:16.802 --> 06:42:19.038
&gt;&gt; FRED CHUNG: So the features 
we gist discussed have additive 

06:42:19.039 --> 06:42:24.157
impacts on alarms, network 
access, and FCM messages so we 

06:42:24.158 --> 06:42:26.213
really strongly encourage 
everyone to thoroughly test 

06:42:26.214 --> 06:42:28.214
these scenarios 

06:42:29.281 --> 06:42:31.120
within your applications.
&gt;&gt; DAN GALPIN: And the good news

06:42:31.121 --> 06:42:34.827
is that there are tools for 
that.  For example, this adb 

06:42:34.828 --> 06:42:38.334
command forces the device into 
an idle state, making all apps 

06:42:38.335 --> 06:42:41.202
dose.
&gt;&gt; ERIC KUXHAUSEN: To test app 

06:42:41.203 --> 06:42:43.231
standby, first simulate unplug 
the device and 

06:42:46.724 --> 06:42:48.338
then use get and set demand to 
get the device in and out of 

06:42:48.339 --> 06:42:50.386
standby.
&gt;&gt; FRED CHUNG: For app standby 

06:42:50.387 --> 06:42:52.823
buckets you can get and set 
buckets for a given 

06:42:57.273 --> 06:43:00.443
package using simulate commands 
but remember to simulate 

06:43:00.444 --> 06:43:03.298
unplugging your device before 
testing.  There's also framework

06:43:03.299 --> 06:43:06.365
APIs available to do this.  
Finally, these are the commands 

06:43:06.366 --> 06:43:10.448
for testing battery saver.  One 
note is that if your app's UI 

06:43:10.449 --> 06:43:15.330
has a dark theme, you can 
consider enabling the dark theme

06:43:15.331 --> 06:43:17.331
when battery saver is 

06:43:19.419 --> 06:43:21.867
turned on to further conserve 
power on OLED devices.  Through 

06:43:21.868 --> 06:43:23.930
power manager, you can check 
with an API and listen to a 

06:43:23.931 --> 06:43:27.819
broadcast to do that.
&gt;&gt; DAN GALPIN: So there are lots

06:43:27.820 --> 06:43:32.133
of ways to make your apps do 
auto cool stuff in the 

06:43:32.134 --> 06:43:34.134
background without using 
foreground services.

06:43:35.637 --> 06:43:37.464
Leverage the new functionality 
in the WorkManager, use 

06:43:37.465 --> 06:43:41.131
efficient location strategies, 
use the new APIs and make sure 

06:43:41.132 --> 06:43:43.606
to tell us what doesn't meet 
your needs by submitting 

06:43:43.607 --> 06:43:45.607
feedback through the 

06:43:47.312 --> 06:43:48.958
issue tracker
&gt;&gt; FRED CHUNG: So right after 

06:43:48.959 --> 06:43:50.959
this talk 

06:43:53.453 --> 06:43:54.883
you'll probably be busy updating
your target SDKs which is all 

06:43:54.884 --> 06:43:58.345
good.  While you're at it we 
strongly encourage you to check 

06:43:58.346 --> 06:44:02.223
out some selective modern  
features on Android that are 

06:44:02.224 --> 06:44:04.224
relevant to your use cases.  So 
you have to have, for example, 

06:44:08.729 --> 06:44:11.332
notification channels to your 
app on O.  Otherwise, well, 

06:44:11.333 --> 06:44:14.659
notifications won't show which 
won't be good.  Plan your 

06:44:14.660 --> 06:44:17.119
channels carefully so that your 
users can selectively turn off 

06:44:17.933 --> 06:44:19.933
notifications that they don't 
want.

06:44:20.195 --> 06:44:22.260
&gt;&gt; DAN GALPIN: Back one slide, 
please, on devices where the 

06:44:22.261 --> 06:44:27.548
play store implemented support 
for notification channels, we 

06:44:27.549 --> 06:44:30.399
see a fewer percent for user 
disabling all of our 

06:44:30.400 --> 06:44:32.400
notifications.

06:44:33.674 --> 06:44:36.327
So if your app is using a 
translucent status bar, you can 

06:44:36.328 --> 06:44:38.328
use the inset APIs 

06:44:40.246 --> 06:44:42.093
to make sure your code doesn't 
assume status bar is a fixed 

06:44:42.094 --> 06:44:45.793
size.  If you're using the 
navigation drawer, this is tomb 

06:44:45.794 --> 06:44:49.062
very common.  If you target P, 
you can also do something 

06:44:49.063 --> 06:44:52.113
interesting in that area.  Now, 
public service announcement.  

06:44:52.114 --> 06:44:53.777
You don't have to put your 
system image on your only 

06:44:53.778 --> 06:44:57.029
device.  If you haven't used the
emulator in a while, it's pretty

06:44:57.030 --> 06:44:59.030
usement o.  Recently, we've 
added support for 

06:45:01.768 --> 06:45:03.818
super fast loading along with AI
sports.  On any device, you can 

06:45:03.819 --> 06:45:08.346
simulate display cutout through 
the developer options.  This 

06:45:08.347 --> 06:45:10.347
ends the public service 
announcement.

06:45:11.603 --> 06:45:13.603
&gt;&gt; FRED CHUNG: Great.

06:45:17.149 --> 06:45:19.149
So, long aspects ratio screens 
of it's 

06:45:22.383 --> 06:45:23.603
become a friend for OEM to be 
shipping device like these with 

06:45:23.604 --> 06:45:26.042
screens longer than the 16 by 
nine aspect ratio.

06:45:29.295 --> 06:45:31.143
Make sure your apps' immersive 
experiences fully take advantage

06:45:31.144 --> 06:45:33.144
of these capabilities, which is 
pretty usement o.

06:45:35.617 --> 06:45:37.617
As a last resort, the system 
still 

06:45:39.939 --> 06:45:41.769
provides you a way to declare 
your maximum supported aspect 

06:45:41.770 --> 06:45:44.043
ratio.
&gt;&gt; And seriously, do you really 

06:45:44.044 --> 06:45:46.044
want 

06:45:48.312 --> 06:45:50.312
letter boxes

06:45:51.873 --> 06:45:53.704
.
&gt;&gt; Now, consider taking 

06:45:53.705 --> 06:45:55.705
advantage for 

06:45:57.625 --> 06:45:59.625
use cases such as video, 
business 

06:46:01.090 --> 06:46:02.710
tracking or Pokemon Go.  
Multiple display also allows you

06:46:02.711 --> 06:46:04.711
to 

06:46:05.805 --> 06:46:07.241
launch an activity on a second 
display.  The only thing you 

06:46:07.242 --> 06:46:11.373
have to consider here is it has 
a second configuration which is 

06:46:11.374 --> 06:46:13.410
going to be different from the 
one on your app most likely so 

06:46:13.411 --> 06:46:17.087
be careful not to make 
assumptions about hardware 

06:46:17.088 --> 06:46:20.377
configuration.
&gt;&gt; And in conclusion, Android 

06:46:22.230 --> 06:46:24.230
development has evolved to mean 
using 

06:46:25.513 --> 06:46:27.803
the latest APIs, enable better 
battery life, smoother 

06:46:27.804 --> 06:46:29.869
multitasking, supporting the 
latest hardware and platform 

06:46:31.298 --> 06:46:33.770
features and taking advantage of
Jetpack to build a modern, 

06:46:33.771 --> 06:46:35.771
testable architecture.  Thank 
you

06:46:37.095 --> 06:46:40.563
(applause)
Actually, no, no, no.  There's 

06:46:40.564 --> 06:46:42.397
actually one more thing.  
Android is actually restricting 

06:46:42.398 --> 06:46:44.398
the 

06:46:46.282 --> 06:46:48.111
use of some non-SDK interfaces 
in developer preview one and you

06:46:48.112 --> 06:46:50.375
saw this because we actually 
warned you with like 

06:46:54.034 --> 06:46:56.073
toast and log entries if these 
methods were used but you'll 

06:46:56.074 --> 06:46:58.308
notice if you're testing against
DP2, some of these 

06:47:02.118 --> 06:47:04.118
methods will just

06:47:07.746 --> 06:47:11.611
cease to work.  To help you out 
in the future, we've actually 

06:47:11.612 --> 06:47:13.663
added a new VM policy for strict
mode that you can use to turn on

06:47:19.715 --> 06:47:19.729
and detect all non-SDK usage 
which is really important 

06:47:19.730 --> 06:47:23.759
because this non-SDK usage may 
be happening in your library so 

06:47:23.760 --> 06:47:27.893
this is a really great way to 
actually make sure that your app

06:47:23.760 --> 06:47:27.232
is going to be compatible going 
forward because we don't 

06:47:27.233 --> 06:47:29.233
guarantee the compatibility of 
any non-SDK API.

06:47:31.935 --> 06:47:33.935
And so, that really is it now.

06:47:35.871 --> 06:47:37.504
If you haven't been paying 
attention in the last 30 

06:47:37.505 --> 06:47:39.505
minutes, that's okay.  Because 
clearly my jokes need work.

06:47:42.400 --> 06:47:43.416
If you're an engineer, hopefully
much of the information shared 

06:47:43.417 --> 06:47:46.497
today was a review for you and 
we hope you found the tips 

06:47:46.498 --> 06:47:48.946
useful.
&gt;&gt; FRED CHUNG: So, if you're a 

06:47:48.947 --> 06:47:50.947
PM and 

06:47:53.070 --> 06:47:55.308
your ad is not quite targeting 
26 yet, it's not too late to 

06:47:55.309 --> 06:47:59.633
plan out, work with your teams 
to figure out how much work is 

06:47:59.634 --> 06:48:01.634
need and in fact we prepared a 
guide 

06:48:02.975 --> 06:48:04.215
on Android developer sites to 
help people understand based on 

06:48:04.216 --> 06:48:07.466
your current release the amount 
of work needed so that we can 

06:48:07.467 --> 06:48:08.277
collectively push the ecosystem 
forward.  Thank you very much

06:48:08.278 --> 06:48:12.248
(applause)
&gt;&gt; So, let us know what you 

06:48:12.249 --> 06:48:14.249
think.

06:48:16.327 --> 06:48:17.572
Now, if you don't ever want to 
see us present here at I/O 

06:48:17.573 --> 06:48:20.214
again, this is your chance to 
make sure this never happens 

06:48:20.215 --> 06:48:22.647
again.
&gt;&gt; So, just target straight to 

06:48:22.648 --> 06:48:25.718
P.
&gt;&gt; So, thank you very much.

06:48:26.118 --> 06:48:28.118
&gt;&gt; Thank you

06:48:29.132 --> 06:48:31.132
(applause)

06:48:34.542 --> 06:48:36.217
(Session was concluded at 4:56 
PM CT)

06:48:36.218 --> 06:48:38.551
***
This text, document, or file is 

06:48:36.218 --> 06:48:40.218
based on live transcription.  
Communication Access Realtime 

06:48:36.218 --> 06:48:40.351
Translation (CART), captioning, 
and/or live transcription are 

06:48:36.218 --> 06:48:39.218
provided in order to facilitate 
communication

06:48:36.218 --> 06:48:40.351
accessibility and may not be a 
totally verbatim record of the 

06:48:36.218 --> 06:48:39.951
proceedings.  This text, 
document, or file is not to be 

06:48:36.218 --> 06:48:40.351
distributed or used in any way 
that may violate copyright law.

06:48:36.218 --> 06:48:38.256
***

06:48:45.597 --> 06:48:47.863
REALTIME CAPTIONING ON THIS 
SCREEN

07:13:42.684 --> 07:13:44.684
GOOGLE I/O

07:13:50.924 --> 07:13:53.230
I/O 2018
MOUNTAIN VIEW, CALIFORNIA

07:13:55.265 --> 07:13:57.305
MAY 10, 2018
STAGE 2

07:13:59.605 --> 07:14:01.605
3:30 PM

07:14:05.949 --> 07:14:07.949
BUILD ENGAGING CONVERSATIONS FOR
GOOGLE ASSISTANT

07:14:11.315 --> 07:14:13.315
WITH DIALOGFLOW

07:14:19.047 --> 07:14:21.047
T519D2

07:22:30.416 --> 07:22:32.416
&gt;&gt; ALL RIGHT.  HEY, EVERYONE.

07:22:35.700 --> 07:22:38.142
MY MAIM IS Dan and this is Matt 
and we're both Googlers who work

07:22:38.143 --> 07:22:40.824
on a product called Dialogflow. 
So, I wanted to say first, thank

07:22:40.825 --> 07:22:42.825
you so much for coming.

07:22:44.685 --> 07:22:47.338
We've been having an amazing I/O
and we're super excited to share

07:22:47.339 --> 07:22:49.339
our talk with you.  You've 
probably heard a lot over the 

07:22:51.249 --> 07:22:53.081
last few days about how 
important the Google Assistant 

07:22:53.082 --> 07:22:55.119
is for our vision for how 
computers can help people get 

07:22:55.120 --> 07:22:59.587
things done.  The Assistant 
works across dozens of device 

07:22:59.588 --> 07:23:01.588
types and makes the most of the 
best features of each device.

07:23:05.722 --> 07:23:06.943
That could mean the quick 
at-a-glance display of the smart

07:23:06.944 --> 07:23:08.944
watch and it could 

07:23:10.029 --> 07:23:12.029
mean the benefits of no screen 
at all.

07:23:13.315 --> 07:23:15.165
The Assistant is now available 
on over 500 million devices so 

07:23:15.166 --> 07:23:18.053
that makes this a really 
important platform to build for.

07:23:20.913 --> 07:23:22.913
So, the system is really smart 
and 

07:23:23.953 --> 07:23:25.613
we've made it do some super cool
stuff but the real power of 

07:23:25.614 --> 07:23:27.614
platforms comes from their 
developers.

07:23:29.940 --> 07:23:31.583
So, how do we empower our 
developers to extend the 

07:23:31.584 --> 07:23:34.225
Assistant and do things we never
could have imagined?  This is 

07:23:34.226 --> 07:23:36.226
where Dialogflow comes in of 
we've taken what we learned from

07:23:37.083 --> 07:23:39.945
building amazing conversational 
experiences and we've built a 

07:23:39.946 --> 07:23:44.015
tool that allows any developer 
to do the same thing.  This 

07:23:44.016 --> 07:23:45.067
session, we're going to tell you
all about Dialogflow, we're 

07:23:45.068 --> 07:23:49.588
going to tell what you it does, 
where it fits, and we're going 

07:23:49.589 --> 07:23:52.027
to show you how to build a 
sophisticated action for the 

07:23:52.028 --> 07:23:54.028
Google Assistant in just a few 
minutes.

07:23:56.741 --> 07:23:58.766
We're also going to talk about a
few upgrades we've made based on

07:23:58.767 --> 07:24:00.767
feedback 

07:24:02.022 --> 07:24:04.251
we've had from our awesome 
community.  So, as you saw in 

07:24:04.252 --> 07:24:09.013
our developer keynote, we've had
really great momentum and growth

07:24:09.014 --> 07:24:12.256
this year.  We've had half a 
million developers use 

07:24:12.257 --> 07:24:13.680
Dialogflow, which is a 250 
percent increase since this time

07:24:13.681 --> 07:24:15.681
last year.

07:24:16.754 --> 07:24:18.783
Google's developers are 
obviously really excited to use 

07:24:18.784 --> 07:24:21.219
our ML tech in their work.  
We've also got brands all around

07:24:21.220 --> 07:24:24.063
the world using Dialogflow and 
they're building some really 

07:24:24.064 --> 07:24:26.064
amazing stuff.

07:24:29.525 --> 07:24:31.525
So if you want to see some case

07:24:32.725 --> 07:24:34.756
studies, you can check our 
website to see some partner 

07:24:34.757 --> 07:24:37.836
experiences using the website.
All right, let's get technical. 

07:24:37.837 --> 07:24:39.837
So, before we go further, let's 
go over some basics.

07:24:42.915 --> 07:24:44.337
An action is a third party 
experience for the system and 

07:24:44.338 --> 07:24:46.367
there are many ways a user can 
invoke your action.

07:24:50.450 --> 07:24:52.450
First, they can just ask the 
Assistant 

07:24:53.552 --> 07:24:55.552
for your action by name.

07:24:56.796 --> 07:24:59.029
Or maybe the Assistant might 
suggest your action based on its

07:24:59.030 --> 07:25:02.737
functionality.  Once invoked, 
the Assistant is going to hand 

07:25:02.738 --> 07:25:05.221
conversation control over to 
Dialogflow.  Dialogflow 

07:25:05.222 --> 07:25:07.222
understands conversational 
language, and it will hold a 

07:25:11.569 --> 07:25:12.180
conversation with your users 
based on a structure that you 

07:25:12.181 --> 07:25:16.249
define.  You can then connect 
this conversation with your 

07:25:16.250 --> 07:25:18.513
business logic to make things 
happen and generate replies.

07:25:21.796 --> 07:25:23.796
To define the conversation, 
you'll use Dialogflow's UI.

07:25:26.895 --> 07:25:28.895
And it's a web app that even 
nondeveloppers can use.

07:25:33.739 --> 07:25:37.656
There's no coding requirement 
for simple acts.  Under the 

07:25:37.657 --> 07:25:39.657
hood, this all uses machine 
learning and natural language 

07:25:42.531 --> 07:25:45.986
understanding tools but won't 
need a PhD to make use of then. 

07:25:45.987 --> 07:25:48.240
For more complex actions, 
connecting actions with your 

07:25:48.241 --> 07:25:51.106
code is super easy and you can 
even use our embedded Cloud 

07:25:52.322 --> 07:25:54.158
functions with Firebase editor. 
You just tell Dialogflow at 

07:25:54.159 --> 07:25:56.587
which point the conversation it 
should communication with your 

07:25:56.588 --> 07:25:59.461
code.
Dialogflow then makes an HTTP 

07:25:59.462 --> 07:26:01.462
request 

07:26:03.219 --> 07:26:05.219
with JSON describing what the 
user wants 

07:26:09.737 --> 07:26:09.849
and you can use this to 
construct a complex response or 

07:26:09.850 --> 07:26:12.740
to look something up and 
generally make stuff happen.  

07:26:12.741 --> 07:26:14.582
So, we want to show you how easy
it is to get started with 

07:26:14.583 --> 07:26:16.583
Dialogflow, and over the next 
few minutes, we're going to 

07:26:18.670 --> 07:26:22.568
build an action from scratch for
an imaginary local business.  

07:26:22.569 --> 07:26:27.031
Our business is going to be a 
bike repair shop.  Our action's 

07:26:27.032 --> 07:26:29.032
going to work like a helpful 
store clerk and it's going to 

07:26:32.338 --> 07:26:34.576
allow our bike repair shop's 
customers to check the shop's 

07:26:34.577 --> 07:26:36.828
opening hours and book an 
appointment to service their 

07:26:37.027 --> 07:26:39.481
bike.
So, here's what's going to 

07:26:39.482 --> 07:26:41.482
happen during the demo.  First, 
we're going to walk you through 

07:26:43.781 --> 07:26:46.034
how to respond to user queries 
with a powerful concept called 

07:26:46.035 --> 07:26:48.035
the intent.

07:26:49.562 --> 07:26:51.562
We're then going to show you how
to 

07:26:53.219 --> 07:26:55.219
extract detailed information 
from user's 

07:26:56.489 --> 07:26:59.284
queries like time and dates and 
we're going to demonstrate how 

07:26:59.285 --> 07:27:01.311
to connect your action to 
business logic that will store 

07:27:02.947 --> 07:27:05.590
appointments in a Google 
calendar.  Finally, we're going 

07:27:05.591 --> 07:27:07.414
to integrate our action with a 
Google Assistant and check it 

07:27:07.415 --> 07:27:11.705
out.  So, to get started, I'm 
going to hand it over to Matt 

07:27:11.706 --> 07:27:13.706
and he's going to demonstrate 
how the finished action is 

07:27:16.374 --> 07:27:18.374
going to work on his shiny new 
pixel book.

07:27:19.626 --> 07:27:21.673
&gt;&gt; MATT CARROLL: Thanks, Dan.  
Can we go ahead and switch to 

07:27:21.674 --> 07:27:24.932
the demo -- oh, there we go.  
So, before we get started 

07:27:24.933 --> 07:27:29.426
building, I'm just going to give
you guys a quick demo of what 

07:27:29.427 --> 07:27:31.427
we're going to build.  Right now
on the left hand side of the 

07:27:33.887 --> 07:27:35.887
screen we have thele Google 
Assistant up 

07:27:37.148 --> 07:27:39.148
on the pixel book and we'll say,
talk to 

07:27:40.962 --> 07:27:45.944
my bike shop to invoke to 
invocate our action.  Right now,

07:27:45.945 --> 07:27:48.176
Google Assistant to our action 
the bike shop.  Right now we're 

07:27:48.177 --> 07:27:51.277
going to set up an appointment 
and it's going to ask us what 

07:27:51.278 --> 07:27:54.773
day we want to come in.  So 
we're going to say next Friday. 

07:27:54.774 --> 07:27:58.280
And then it asks us what time, 
and we'll say 3:00 PM.  And 

07:27:58.281 --> 07:28:00.106
right now, we're, the Cloud 
function is actually adding an 

07:28:00.107 --> 07:28:03.358
event to our calendar you can 
see there and asking us what 

07:28:03.359 --> 07:28:07.422
kind of appointment.  So, I'm 
going to say tune-up.  And then 

07:28:07.423 --> 07:28:09.423
we can see our action is 

07:28:10.488 --> 07:28:12.488
confirmed the appointment and 
ended the conversation.

07:28:13.130 --> 07:28:15.401
So, now let's build it.  So, 
we're going to switch to our 

07:28:19.704 --> 07:28:21.948
Dialogflow here and log in.  So,
this is Dialogflow's console.

07:28:24.964 --> 07:28:27.214
On the left you'll see a panel 
where you have all the main 

07:28:27.215 --> 07:28:30.079
concepts that you need to lose 
to close the Dialogflow agent 

07:28:30.080 --> 07:28:31.707
and in the middle, we have the 
panel where you use all these 

07:28:31.708 --> 07:28:36.211
main concepts.  Right now, it's 
a list of intent and on the 

07:28:36.212 --> 07:28:38.874
right, we have a simulator where
you can try out your Dialogflow 

07:28:38.875 --> 07:28:44.405
agent as you're building it so 
let's go ahead and try it out.  

07:28:44.406 --> 07:28:48.474
We'll say hello.
So we can see that the default 

07:28:48.475 --> 07:28:52.542
welcome intent here was matched 
and if we look, open up the 

07:28:52.543 --> 07:28:54.977
default welcome intent, you can 
see that we had the response 

07:28:54.978 --> 07:28:59.447
high.  So, that's not quite what
we want to say since we have a 

07:28:59.448 --> 07:29:01.884
bike shop, so let's change that 
response up and say, welcome to 

07:29:01.885 --> 07:29:04.398
my bike shop.  How can I help?

07:29:13.575 --> 07:29:15.575
So, we'll try it again.

07:29:18.870 --> 07:29:21.524
So, now we're adding a training 
phrase here so that our high 

07:29:21.525 --> 07:29:23.525
query is understood and the 
agent is training and 

07:29:28.035 --> 07:29:29.473
using this high example as a 
training phrase for a machine 

07:29:29.474 --> 07:29:32.123
learning model that's running in
the background that 

07:29:38.200 --> 07:29:40.200
will identify incoming requests 
to this welcome intent.

07:29:42.219 --> 07:29:46.285
So, we'll try hi again, and now 
we can see that our response 

07:29:42.219 --> 07:29:45.752
correctly identified and we send
back the correct response.  So, 

07:29:45.753 --> 07:29:47.753
let's create our own intent now.

07:29:49.306 --> 07:29:51.155
So, we'll go to the navigation 
pin on the left where it says 

07:29:51.156 --> 07:29:53.618
intents and click this little 
plus sign so create our own 

07:29:53.824 --> 07:29:58.710
intent.  And we'll type in 
hours, so this will be our 

07:29:58.711 --> 07:30:00.530
intent that we're going to 
create for any intention the 

07:30:00.531 --> 07:30:05.034
user has to know the hours our 
bike is open.  So the first 

07:30:05.035 --> 07:30:09.008
thing we need to do is add 
training phrases.  These 

07:30:09.009 --> 07:30:10.028
training phrases are the basis 
for the machine learning model 

07:30:10.029 --> 07:30:14.718
so we need to think of things 
users might say when they want 

07:30:14.719 --> 07:30:19.213
to know the hours of our bike 
shop.  Do a few examples here.  

07:30:19.214 --> 07:30:21.214
How late can I come in?

07:30:22.899 --> 07:30:24.899
They might say, what are your 
hours directly?

07:30:25.978 --> 07:30:27.978
Or they might say, when do you 
open?

07:30:33.130 --> 07:30:35.167
So I'll go ahead and save that 
and then Dialogflow will start 

07:30:35.168 --> 07:30:38.845
this training process using 
these training phrases and all 

07:30:38.846 --> 07:30:40.909
that's happening.  We're going 
to add a response.

07:30:44.035 --> 07:30:46.035
So, down here with click add 
response 

07:30:47.722 --> 07:30:49.722
and then we'll say, we're open 
from 9:00 

07:30:54.226 --> 07:30:56.226
AM to 5:00 PM every week day.

07:30:59.228 --> 07:31:00.275
We'll click save and we'll try 
querying this out.

07:31:00.276 --> 07:31:02.276
All right, are you open now?

07:31:05.302 --> 07:31:07.302
So, now we can see the hours 
intent 

07:31:09.183 --> 07:31:11.661
was matched down here and send 
back the correct response, we're

07:31:11.662 --> 07:31:15.531
open from nine to five every 
day.  And now I just want to 

07:31:15.532 --> 07:31:19.594
take a moment and notice the 
query, are you open now isn't 

07:31:19.595 --> 07:31:21.432
really similar to any training 
phrases we have.  When do you 

07:31:21.433 --> 07:31:26.796
open?  What are your hours?  How
late do you come in?  So, this 

07:31:26.797 --> 07:31:29.036
is the power of Dialogflow.  If 
you can imagine trying to write 

07:31:29.037 --> 07:31:32.530
a regular expression to match 
every instance of these four 

07:31:32.531 --> 07:31:34.970
examples as well as thousands of
ways that someone could 

07:31:38.185 --> 07:31:39.835
ask, when is your store open, 
this is where Dialogflow becomes

07:31:39.836 --> 07:31:44.136
really powerful and allows your 
users to talk to you in a 

07:31:44.137 --> 07:31:46.137
natural conversational way.  So,
new let's take a closer look at 

07:31:46.374 --> 07:31:48.374
the response.

07:31:49.425 --> 07:31:52.255
It's a little bit generic so 
we're open from nine to five 

07:31:52.256 --> 07:31:54.256
every week day.

07:32:00.667 --> 07:32:02.667
We're not actually answer the 
question, are you open now?

07:32:05.536 --> 07:32:07.168
In a normal conversation, you 
might expect more contextual 

07:32:07.169 --> 07:32:09.169
information.  Oh, we're open 
until five today.

07:32:15.405 --> 07:32:17.440
So, for that, we need to know 
what the hour is and if that 

07:32:17.441 --> 07:32:22.355
falls within our open range.
So we need to use fulfillment.  

07:32:22.356 --> 07:32:24.356
Fulfillment is how you connect 
your 

07:32:25.357 --> 07:32:27.357
Dialogflow agent to code.

07:32:29.492 --> 07:32:31.110
In this case, we have an inline 
editor where I've already 

07:32:31.111 --> 07:32:35.174
written some code.  We can see 
the hours function.  We can 

07:32:35.175 --> 07:32:38.053
check if the store is currently 
open.  If it is, we give a 

07:32:38.054 --> 07:32:40.085
response that says we're open 
now and we will be open until 

07:32:40.086 --> 07:32:44.565
five.  If not, we tell them when
we're open next.  One more thing

07:32:44.566 --> 07:32:46.813
we need to do to connect this 
code to our Dialogflow agent.

07:32:50.704 --> 07:32:52.529
That's where we go to dialogue 
intent, scroll all the way down 

07:32:52.530 --> 07:32:56.798
to fulfillment and then enable 
this intent.  So, once we do 

07:32:56.799 --> 07:32:58.799
that, if we try our query again.
Are you open now?

07:33:02.767 --> 07:33:05.195
We can see right now, so right 
now, the hours and intent is 

07:33:05.196 --> 07:33:07.196
calling the web book and comes 
back with the correct 

07:33:11.675 --> 07:33:13.675
response of, we're open now

07:33:16.013 --> 07:33:18.042
and we close at 5:00 PM today.  
So that calculation was made and

07:33:18.043 --> 07:33:20.478
sent back the proper response.  
All right, so now let's try 

07:33:20.479 --> 07:33:24.562
something a little bit more 
complex.  We're going to create 

07:33:24.563 --> 07:33:27.656
an intent for making an 
appointment.  So, we'll call it 

07:33:27.657 --> 07:33:30.126
the make appointment intent.  
And for this intent, we'll need 

07:33:30.127 --> 07:33:34.438
a few more examples because 
there's many different ways that

07:33:34.439 --> 07:33:37.096
a user might say, I want it make
an appointment.  So we'll go 

07:33:37.097 --> 07:33:39.097
through those right now.

07:33:43.000 --> 07:33:45.000
I'd like to get a bike tune-up.

07:33:52.227 --> 07:33:54.227
I'd like to schedule an 
appointment next Thursday.

07:33:58.765 --> 07:34:00.765
Can I schedule service for noon?

07:34:06.948 --> 07:34:08.948
Can I set up an appointment for 
my bike 

07:34:09.965 --> 07:34:11.965
tomorrow at 2:00 PM?

07:34:16.801 --> 07:34:18.801
And the last one, I'd like to 
come in 

07:34:20.063 --> 07:34:22.063
at 9:00 AM on May 11th.

07:34:29.065 --> 07:34:31.065
So, now you can see we have a 
few 

07:34:33.182 --> 07:34:34.199
things going on here that are 
different from our previous 

07:34:34.200 --> 07:34:36.200
examples.

07:34:37.247 --> 07:34:40.107
So, Dialogflow has highlighted a
few of the entities that are 

07:34:40.108 --> 07:34:43.355
present in our users examples.  
So, entities and Dialogflow has 

07:34:44.989 --> 07:34:47.635
several entities built in so we 
can extract data from what users

07:34:47.636 --> 07:34:49.877
are saying and use it in this 
case to schedule a bike 

07:34:49.878 --> 07:34:55.233
appointment.  So, all of the red
highlighted items are times and 

07:34:55.234 --> 07:34:57.234
all of the yellow highlighted 
items are dates.

07:35:00.730 --> 07:35:02.730
So, if you scroll down

07:35:03.953 --> 07:35:05.953
, we can see that these are 
listed as 

07:35:08.389 --> 07:35:10.389
parameters so we have

07:35:11.717 --> 07:35:13.717
.  We want the time and date the
user 

07:35:15.378 --> 07:35:17.003
specified so that we can confirm
the right appointment time so 

07:35:17.004 --> 07:35:19.049
we'll go ahead and add a 
response here, and say great.

07:35:24.343 --> 07:35:26.343
I've set up your appointment the
dollar sign date.

07:35:28.217 --> 07:35:30.454
So, this takes the value from 
what the user says and then puts

07:35:30.455 --> 07:35:34.713
it in our response and then at 
dollar sign time, so this will 

07:35:34.714 --> 07:35:36.714
add the same thing for the time 
value.

07:35:39.552 --> 07:35:41.552
See you then.

07:35:43.821 --> 07:35:45.821
I'll go ahead and save that and 
then we'll try this out.

07:35:50.710 --> 07:35:53.019
So, I want an appointment 
tomorrow at 3:00 PM.

07:35:59.888 --> 07:36:01.888
So now you can see that

07:36:06.442 --> 07:36:08.442
the Dialogflow correctly maps an

07:36:12.592 --> 07:36:14.220
maps and it's easily parsable on
our website and correctly inputs

07:36:14.221 --> 07:36:16.850
those values back into our 
response.  So, to actually make 

07:36:16.851 --> 07:36:18.851
an appointment, we need a date 
and a  time.

07:36:21.530 --> 07:36:23.358
So, we need to make sure that 
the user provides both those 

07:36:23.359 --> 07:36:27.019
pieces of data so we're going to
go to the parameter table and 

07:36:27.020 --> 07:36:30.492
make both of these parameters 
required.  Now, when a parameter

07:36:30.493 --> 07:36:32.493
is required, we 

07:36:43.235 --> 07:36:47.501
can define a prompt so that if a
user doesn't require a date and 

07:36:43.235 --> 07:36:44.249
time, we can ask them for it.  
So in this case, we'll add a 

07:36:44.250 --> 07:36:46.250
prompt that says, what day do 
you want to come in?

07:36:56.169 --> 07:36:57.601
For our time we'll add a prompt 
that says, what time works for 

07:36:57.602 --> 07:37:01.112
you.  So, let's try that out.  
Say, I need an appointment.

07:37:06.018 --> 07:37:08.018
Oops.

07:37:10.287 --> 07:37:12.287
Let's try appointment.

07:37:14.581 --> 07:37:15.792
So, now that we've matched the 
make appointment intent, you can

07:37:15.793 --> 07:37:20.678
see that the response instead of
our response to find here, we 

07:37:20.679 --> 07:37:22.925
hit one of our prompts that 
says, what day do you want to 

07:37:22.926 --> 07:37:24.958
come in so we'll go ahead and 
answer that question, say, next 

07:37:24.959 --> 07:37:30.475
Friday.  And what time works for
you?  We'll say 11:00 AM.  And 

07:37:30.476 --> 07:37:32.304
now you can see that this has 
been filled in correctly by 

07:37:32.305 --> 07:37:34.305
Dialogflow and we 

07:37:35.774 --> 07:37:37.774
get the ultimate response back 
there.

07:37:38.430 --> 07:37:40.666
So, now that we've set up an 
appointment, we might want to 

07:37:40.667 --> 07:37:45.136
get some additional information 
from the user about the 

07:37:45.137 --> 07:37:46.566
appointment so we might want to 
know what kind of appointment 

07:37:46.567 --> 07:37:48.567
type.

07:37:51.538 --> 07:37:53.538
So we'll ask them a question and
say, 

07:37:54.807 --> 07:37:56.807
do you need a repair or just a 
tune-up.

07:37:58.685 --> 07:38:01.124
So now we need a way to capture 
the answer to this question.

07:38:04.382 --> 07:38:06.382
If they want a repair or a 
tune-up so 

07:38:07.637 --> 07:38:09.275
a dialogue flow already has 
these built-in entities for date

07:38:09.276 --> 07:38:13.366
and time but you can also create
your own entities so we'll go 

07:38:13.367 --> 07:38:16.206
ahead and do that now.  On the 
left panel again, you can see 

07:38:18.056 --> 07:38:19.266
the left hand button so we'll 
create an entity.  We'll call it

07:38:19.267 --> 07:38:21.267
appointment type.

07:38:22.339 --> 07:38:24.339
And then we'll add entries for 
our appointment type entity.

07:38:25.993 --> 07:38:26.601
So, in this case, we'll have a 
service option and a fix option.

07:38:26.602 --> 07:38:31.941
So, we'll enter in the first 
value, service.  And then we can

07:38:31.942 --> 07:38:36.294
also enter in synonym values for
each of these entities.  So, 

07:38:36.295 --> 07:38:38.126
someone might not actually say 
the word service but they might 

07:38:38.127 --> 07:38:40.577
say another word that means the 
same thing so we can 

07:38:43.834 --> 07:38:45.834
define synonyms that will map 
back to 

07:38:46.844 --> 07:38:50.197
this cannonnical value.  So 
instead of saying service, 

07:38:50.198 --> 07:38:54.655
someone might say overhaul.  
They might say maintenance.  

07:38:54.656 --> 07:38:57.516
They might say tune-up.  Or they
might say tune up with a space 

07:38:57.721 --> 07:38:59.960
in it.
For our other value, we have 

07:38:59.961 --> 07:39:03.639
fix.  Someone might say repair, 
mend.  They might say their bike

07:39:03.640 --> 07:39:08.152
is broken.  They might say they 
have a flat tire.  Or they might

07:39:08.153 --> 07:39:10.153
say, fixed.  So, we'll say that.

07:39:16.542 --> 07:39:18.542
So now that we have an 
appointment 

07:39:20.236 --> 07:39:22.479
entity, we need to create an 
intent to capture it.  In the 

07:39:22.480 --> 07:39:24.480
case of our intents we only 

07:39:26.478 --> 07:39:28.478
really need to capture this 
appointment 

07:39:29.482 --> 07:39:31.482
type entity

07:39:33.048 --> 07:39:35.282
after our intent has been 
matched.  So we want to make a 

07:39:35.283 --> 07:39:37.283
new intent.  To r that, 
something called follow-up 

07:39:37.312 --> 07:39:39.312
intent.

07:39:41.179 --> 07:39:42.406
So if we hover over add 
appointment, you can see 

07:39:42.407 --> 07:39:46.327
follow-up.  So we'll create a 
custom follow-up.  So this new 

07:39:46.328 --> 07:39:48.328
intent listed with that 

07:39:49.372 --> 07:39:51.372
arrow means this intent can only
be matched after the intent.

07:39:54.095 --> 07:39:56.140
So, for this, we just asked the 
user if they want a service or 

07:39:56.141 --> 07:40:01.236
if they want to fix their bike 
so we'll enter in some examples 

07:40:01.237 --> 07:40:03.237
of how users might answer that 
question.

07:40:04.517 --> 07:40:06.517
It might say I need a repair.

07:40:09.194 --> 07:40:11.194
Or they might say, can you 
service my bike?

07:40:14.080 --> 07:40:16.923
So now you can see as before 
with the built-in entities 

07:40:16.924 --> 07:40:18.924
Dialogflow was 

07:40:20.034 --> 07:40:22.065
directly identified for our 
custom entity that we just 

07:40:22.066 --> 07:40:25.319
created since we need to know 
this information, we're going to

07:40:25.320 --> 07:40:27.320
make it required and we'll add a
prompt for it as well.

07:40:30.434 --> 07:40:33.079
We can service or repair your 
bike.  Which one would you like?

07:40:35.528 --> 07:40:40.266
So, now for our response here, 
it would be nice to confirm our 

07:40:40.267 --> 07:40:43.336
actual appointment time and date
and after they've said what 

07:40:43.337 --> 07:40:45.337
appointment type they have, but 
if you'll see here in the 

07:40:47.260 --> 07:40:50.120
parameter table, we actually 
don't have the time or date here

07:40:50.121 --> 07:40:53.370
so how do we get this value.  
For that, we're going to need to

07:40:53.371 --> 07:40:55.371
dig a 

07:40:57.042 --> 07:40:59.509
little deeper into how follow-up
intents work.  So, follow-up 

07:40:59.510 --> 07:41:01.510
intents work through something 
called context.

07:41:04.999 --> 07:41:07.746
So, once we added this follow-up
intent, output was added to make

07:41:07.747 --> 07:41:09.747
appointment.

07:41:11.116 --> 07:41:14.778
There are two types of, output 
context and input context.  

07:41:14.779 --> 07:41:16.608
Output context attach a context 
to a session after the intent 

07:41:16.609 --> 07:41:18.609
has been 

07:41:20.106 --> 07:41:21.343
matched so in this case, after 
our make appointment attempt has

07:41:21.344 --> 07:41:23.379
been matched, the make 
appointment follow-up context 

07:41:25.406 --> 07:41:29.067
will be added to the session.
Next, let's take a look at our 

07:41:29.068 --> 07:41:31.736
follow-up intent.  For our 
follow-up intent, we have the 

07:41:33.992 --> 07:41:36.501
same value, make appointment 
follow-up context, except 

07:41:36.502 --> 07:41:40.376
instead of the output context 
it's in the input context.  So, 

07:41:40.377 --> 07:41:42.377
this makes the make appointment 

07:41:45.337 --> 07:41:46.971
custom or our follow-up intent 
only get matches once the make 

07:41:46.972 --> 07:41:51.266
appointment follow-up context is
attached to the session so in 

07:41:51.267 --> 07:41:53.267
our case, the only time that the
make appointment follow-up 

07:41:54.740 --> 07:41:55.558
context is attached to the 
session is attached to our 

07:41:55.559 --> 07:41:59.835
appointment.  So, this means 
that this make appointment 

07:41:59.836 --> 07:42:01.836
custom follow-up intent will 

07:42:03.292 --> 07:42:05.292
only be matched after our make 
appointment parent intent.

07:42:07.567 --> 07:42:09.567
In addition to controlling the 
flow in 

07:42:13.716 --> 07:42:15.716
how intents are matched, 
contexts also 

07:42:17.725 --> 07:42:19.725
store parameter value so we can 
use the 

07:42:20.774 --> 07:42:21.715
value to make appointment 
follow-up to reference time and 

07:42:21.716 --> 07:42:23.716
date that we previously gathered
in the make 

07:42:28.734 --> 07:42:30.734
appointment intent so we'll go 
ahead and do that now.

07:42:35.726 --> 07:42:36.715
We'll say, okay, we'll schedule 
a dollar sign appointment so 

07:42:36.716 --> 07:42:38.947
this is grabbing, fixing or 
servicing the bike just like 

07:42:38.948 --> 07:42:40.790
last time now we want to insert 
the date.  So we'll do pound, 

07:42:40.791 --> 07:42:44.240
make appointment, follow-up, do 
add date.  Then we'll add the 

07:42:44.241 --> 07:42:47.085
context value dot time.  So, 
this will grab our time and date

07:42:48.530 --> 07:42:53.215
value from the previous intent. 
We'll see you then.  All right.

07:42:58.555 --> 07:43:00.413
Now, instead of trying this out 
on Dialogflow simulator on the 

07:43:00.414 --> 07:43:02.414
right, why 

07:43:04.898 --> 07:43:08.775
don't we see what this looks 
like for Dialogflow assistant?  

07:43:08.776 --> 07:43:11.424
We'll see a tab called 
integrations.  This integrations

07:43:11.425 --> 07:43:13.425
page -- the Dialogflow has with 
other chat and voice providers.

07:43:18.130 --> 07:43:20.130
So you can use any of these to 
deploy your Dialogflow.

07:43:22.027 --> 07:43:24.027
For now we're going to start out
with the Google Assistant.

07:43:26.135 --> 07:43:27.147
You can see information about 
how Dialogflow works with Google

07:43:27.148 --> 07:43:29.148
Assistant but for now we're just
going to try it out.

07:43:33.234 --> 07:43:36.636
So, flipping tests is the 
actions on Google console.

07:43:39.933 --> 07:43:41.963
It's where you define all your 
information about your app like 

07:43:41.964 --> 07:43:43.964
con vocation.

07:43:45.428 --> 07:43:47.649
My test app is a special time 
just like you when you're trying

07:43:47.650 --> 07:43:51.710
to test but you can enter any 
names into your brand once you 

07:43:51.711 --> 07:43:54.574
get the actions console.  For 
now, we'll try talk to my test 

07:43:54.575 --> 07:43:57.832
app.
&gt;&gt; Okay. Here as the test 

07:43:57.833 --> 07:44:01.109
version of my test app.
&gt;&gt; Hi, welcome to my bike shop. 

07:44:01.110 --> 07:44:02.780
How can I help?
&gt;&gt; MATT CARROLL: So what's 

07:44:02.781 --> 07:44:04.781
happened now 

07:44:05.834 --> 07:44:08.483
is we've invocated our action 
and that sends the request to 

07:44:08.484 --> 07:44:12.357
Dialogflow which matches the 
welcome intent which sends back 

07:44:12.358 --> 07:44:16.415
the response we defined earlier.
So, let's try this out.  Can I 

07:44:16.416 --> 07:44:18.416
book an appointment for tomorrow
at noon?

07:44:19.898 --> 07:44:24.165
&gt;&gt; What time works for you?
&gt;&gt; MATT CARROLL: Noon.  There we

07:44:24.166 --> 07:44:26.819
go.
&gt;&gt; Great.  I've set up your 

07:44:26.820 --> 07:44:30.298
appointment for the 11th of May,
2018, at 12 hours, zero minutes 

07:44:30.299 --> 07:44:33.593
and zero seconds.  The do you 
need a repair or just a tune-up?

07:44:33.787 --> 07:44:37.468
&gt;&gt; MATT CARROLL: So now we see 
it's matched the make 

07:44:37.469 --> 07:44:40.114
appointment intent and now we're
going to try out our follow-up 

07:44:40.319 --> 07:44:45.445
intent.  So we'll say, I need a 
repair.

07:44:46.869 --> 07:44:48.869
&gt;&gt; Okay.

07:44:49.937 --> 07:44:52.780
We'll schedule a fix for the 
11th of May 2018, at 12 hours, 

07:44:52.781 --> 07:44:54.867
zero minutes and zero seconds, 
we'll see you then.

07:44:56.900 --> 07:44:59.370
&gt;&gt; MATT CARROLL: So now you can 
see that it correctly identified

07:44:59.371 --> 07:45:03.242
the repair word and mapped it to
the word fix so in our response,

07:45:03.243 --> 07:45:05.475
it says, okay, we'll schedule a 
word fix and also grabbed the 

07:45:05.476 --> 07:45:07.702
time and date from the context 
to surface that to the user as 

07:45:07.703 --> 07:45:10.143
well.  So, now that we've got an
action fully 

07:45:13.651 --> 07:45:14.657
working, I'm going to pass it 
back to Dan who's going to talk 

07:45:14.658 --> 07:45:18.362
about some of the new features 
we've built in Dialogflow over 

07:45:18.363 --> 07:45:20.802
the next year and some of the 
more features I didn't get to go

07:45:20.803 --> 07:45:22.452
over
(applause)

07:45:22.453 --> 07:45:24.453
&gt;&gt; DANIEL IMRIE-SITUNAYAKE: All 
right.

07:45:25.709 --> 07:45:27.544
You should take a bow.  So, 
yeah, I hope that we've shown 

07:45:27.545 --> 07:45:31.011
you how quickly you can build a 
really powerful Assistant action

07:45:31.012 --> 07:45:34.865
with Dialogflow.  If the few 
minutes we've built an engaging 

07:45:34.866 --> 07:45:38.123
conversational agent.  We 
connected it to our code.  And 

07:45:38.124 --> 07:45:40.124
we've been able to deploy and 
test it immediately.

07:45:41.580 --> 07:45:43.580
An the really crazy thing is 
that 

07:45:45.035 --> 07:45:47.299
after review, this action will 
be available on over 500 million

07:45:47.300 --> 07:45:49.300
devices with no install 
required.

07:45:51.367 --> 07:45:55.235
People just have to say the name
of your action.  So, 

07:45:55.236 --> 07:45:57.663
conversational experiences are a
pretty new idea, and building 

07:45:57.664 --> 07:45:59.664
your first agent can be hard 
because there's a 

07:46:04.214 --> 07:46:06.879
whole set of concepts that may 
be unfamiliar for you.  So we've

07:46:06.880 --> 07:46:08.494
built a lot of tools that will 
help make it easier to get 

07:46:08.495 --> 07:46:10.495
started.

07:46:12.165 --> 07:46:14.852
Of Dialogflow comes with 45 
prebuilt agents that you can use

07:46:14.853 --> 07:46:19.333
as a starting point when you're 
developing.  We've covered a 

07:46:19.334 --> 07:46:21.334
load of different real 

07:46:22.380 --> 07:46:25.035
world scenarios like alarms, 
built in tickets.  All you need 

07:46:25.036 --> 07:46:27.692
to do is import the intents and 
entity and customize them to 

07:46:28.927 --> 07:46:30.927
support and suit your action.

07:46:32.375 --> 07:46:34.375
In fact, every single Dialogflow
agent 

07:46:35.667 --> 07:46:38.098
comes equipped with over 50 
system entities.  These cover 

07:46:38.099 --> 07:46:40.099
common concepts, including 

07:46:43.131 --> 07:46:45.131
numbers, dates and times,

07:46:47.079 --> 07:46:49.117
amounts with units and 
geography.  Dialogflow can 

07:46:49.118 --> 07:46:51.558
extract values based on these 
with no additional work so you 

07:46:51.559 --> 07:46:56.400
can understand your customers 
and help them get things done 

07:46:56.401 --> 07:46:59.301
without a lot of overhead.  We 
also have a growing library of 

07:46:59.478 --> 07:47:00.905
sample agents that demonstrate 
how to use our features and 

07:47:00.906 --> 07:47:02.906
these are 

07:47:04.434 --> 07:47:06.434
referenced in our docs and on 
GitHub, 

07:47:09.335 --> 07:47:11.164
and for I/O this year E we've 
added a new feature where you 

07:47:11.165 --> 07:47:14.432
can open it with one click and 
try it out so this will deploy 

07:47:14.433 --> 07:47:16.871
the agent and fulfillment code 
so you can customize it and be 

07:47:16.872 --> 07:47:18.872
up and running straight away.

07:47:22.015 --> 07:47:24.269
Speaking of our docs, we've also
built in interactive Dialogflow 

07:47:24.270 --> 07:47:26.938
agents.  You can play with real 
world examples 

07:47:30.814 --> 07:47:32.814
to help you run with real world 
topics.

07:47:34.300 --> 07:47:36.386
We're regularly employing new 
world tutorials and we just 

07:47:36.387 --> 07:47:40.469
published another brief getting 
started video to our Dialogflow 

07:47:40.470 --> 07:47:44.127
YouTube.  Once you've learned 
the basics, we provide tools to 

07:47:44.128 --> 07:47:46.128
help you do really powerful 
stuff so Dialogflow will help 

07:47:47.181 --> 07:47:49.181
you extend your actions over 
time so you 

07:47:50.678 --> 07:47:52.678
can improve your customer 
experience and performance.

07:47:54.753 --> 07:47:56.797
For example, natural 
conversations branch in complex 

07:47:56.798 --> 07:47:58.798
and unpredictable ways.

07:47:59.890 --> 07:48:02.547
Things that are discussed 
earlier in a conversation can 

07:48:02.548 --> 07:48:04.548
have an impact later on.

07:48:05.607 --> 07:48:08.249
And in the past, conversational 
platforms require you to hard 

07:48:08.250 --> 07:48:10.250
code everything which is really 
brittle and 

07:48:12.731 --> 07:48:16.618
difficult to do anything to 
improve over time.  Fortunately,

07:48:16.619 --> 07:48:19.319
Dialogflow's context allows you 
to shape the flow of a 

07:48:22.409 --> 07:48:24.259
conversation without having to 
predict every possible twist and

07:48:24.260 --> 07:48:29.558
turn ahead of time.  This can 
help you get beyond the idea of 

07:48:29.559 --> 07:48:30.995
a menu-based phone conversation 
and create genuine conversation 

07:48:30.996 --> 07:48:32.996
between people and computers.

07:48:39.001 --> 07:48:40.419
Once your action is up and 
running, you'll have a ton of 

07:48:40.420 --> 07:48:45.733
log conversations and you can 
use the status to improve your 

07:48:45.734 --> 07:48:48.378
actions.  Our training  features
will show you 

07:48:51.429 --> 07:48:53.468
all of the past interactions.  
You can also create new intents 

07:48:53.469 --> 07:48:56.507
when customers ask for something
that you didn't handle.

07:49:01.777 --> 07:49:03.777
Every feature we add is guided 
by these three goals.  We

07:49:08.726 --> 07:49:10.769
want to create an excellent full
stack experience for our 

07:49:10.770 --> 07:49:12.770
developers.

07:49:14.744 --> 07:49:17.877
We want the best possible 
natural language and 

07:49:14.744 --> 07:49:14.836
understanding for machine 
learning and we want it to be 

07:49:14.837 --> 07:49:16.948
easy to integrate and scale 
across any conversational 

07:49:16.949 --> 07:49:21.840
platform.  We use developer 
feedback.  I want to show you 

07:49:21.841 --> 07:49:24.281
some of the features that we've 
added since last year's I/O.

07:49:27.340 --> 07:49:28.983
First, we've heard that you want
better insight into how 

07:49:28.984 --> 07:49:30.984
conversations are going so we've
included our history view and 

07:49:32.889 --> 07:49:35.761
made it much easier for 
developers to see how that agent

07:49:35.762 --> 07:49:37.762
is being used.

07:49:39.026 --> 07:49:40.657
Now you can filter on dates and 
platforms and you can search 

07:49:40.658 --> 07:49:42.658
through 

07:49:47.238 --> 07:49:49.241
logs to find particular 
interactions that are 

07:49:49.242 --> 07:49:51.242
noteworthy.

07:49:53.231 --> 07:49:57.097
This will help improve your 
debugging experience and help 

07:49:53.231 --> 07:49:55.231
you get to a better agent over 
time.

07:49:58.829 --> 07:50:02.495
We've also been working really 
hard to support all the 

07:49:58.829 --> 07:50:00.829
languages that your users speak 
and today we support 29 

07:50:02.814 --> 07:50:04.814
languages and nine locales.

07:50:05.986 --> 07:50:07.986
We recently added support for 

07:50:10.222 --> 07:50:13.646
languages including hindi, Thai 
and Indonesian.  We've also 

07:50:13.647 --> 07:50:15.647
added multiple agents so you can
build one agent that works for 

07:50:17.335 --> 07:50:19.335
all of your users across the 
world.

07:50:19.995 --> 07:50:21.995
Many of our customers have been 
asking 

07:50:23.272 --> 07:50:25.272
us for an enterprise solution so
this 

07:50:26.780 --> 07:50:30.032
year we introduced Dialogflow 
enterprise edition.  This brings

07:50:30.033 --> 07:50:32.033
Dialogflow to Google Cloud 

07:50:33.333 --> 07:50:34.977
which means you get enterprise 
grade compliance and customer 

07:50:34.978 --> 07:50:36.978
support on our Cloud services.

07:50:38.802 --> 07:50:40.802
So

07:50:42.309 --> 07:50:44.740
Ubisoft built their personal 
assistant, Sam, and Sam was able

07:50:44.741 --> 07:50:46.741
to understand 88 

07:50:47.836 --> 07:50:48.865
of players' requests in the 
first three months of their 

07:50:48.866 --> 07:50:50.866
beta.

07:50:52.775 --> 07:50:55.612
So, I hope you're feeling 
excited to get started dealing 

07:50:55.613 --> 07:50:57.613
with Dialogflow.

07:50:59.676 --> 07:51:01.123
There have been tons of really 
amazeing Assistant sessions at 

07:51:01.124 --> 07:51:06.097
this year's I/O.  You can fink 
find links on the recording 

07:51:06.098 --> 07:51:10.370
sites so you can enjoy them at 
your leisure.  You should also 

07:51:10.371 --> 07:51:14.060
make sure to check out our code 
apps which will guide you toward

07:51:14.061 --> 07:51:16.123
your first action.  Your 
feedback is crucial to us and we

07:51:17.770 --> 07:51:19.411
really hope you've enjoyed this 
session so we'd also love for 

07:51:19.412 --> 07:51:21.412
you to head over 

07:51:22.885 --> 07:51:25.535
to the I/O website.  It's super 
easy to get started with 

07:51:27.377 --> 07:51:28.998
Dialogflow and we've put 
together a page full of links 

07:51:28.999 --> 07:51:32.856
that can help you get up and 
running.  You'll also find links

07:51:32.857 --> 07:51:36.311
to our online communities where 
our whole team is hanging out 

07:51:36.312 --> 07:51:38.312
and we can help answer your 
questions.

07:51:42.662 --> 07:51:47.345
Also, don't be shy about 
tweeting our AoG Devs hashtag.  

07:51:47.346 --> 07:51:49.791
So we hope you've had a really 
amazing I/O and that you go on 

07:51:49.792 --> 07:51:51.792
and have a ton of 

07:51:53.061 --> 07:51:55.061
fun building actions with Google
with Dialogflow.

07:51:56.538 --> 07:51:58.538
Thank you very much

07:51:59.746 --> 07:52:01.746
(applause)

07:52:03.483 --> 07:52:04.913
(Session was concluded at 5:59 
PM CT)

07:52:04.914 --> 07:52:05.115
***
This text, document, or file is 

07:52:05.116 --> 07:52:09.116
based on live transcription.  
Communication Access Realtime 

07:52:05.116 --> 07:52:09.249
Translation (CART), captioning, 
and/or live transcription are 

07:52:05.116 --> 07:52:08.116
provided in order to facilitate 
communication

07:52:05.116 --> 07:52:09.249
accessibility and may not be a 
totally verbatim record of the 

07:52:05.116 --> 07:52:08.849
proceedings.  This text, 
document, or file is not to be 

07:52:05.116 --> 07:52:09.249
distributed or used in any way 
that may violate copyright law.

07:52:05.116 --> 07:52:07.351
***

