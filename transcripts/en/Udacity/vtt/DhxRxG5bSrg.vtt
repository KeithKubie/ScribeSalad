WEBVTT
Kind: captions
Language: en

00:00:00.210 --> 00:00:04.080
Before ending this lesson, I want
to talk about a couple of practical

00:00:04.080 --> 00:00:09.410
considerations of particle filters,
and the first one involves sampling.

00:00:09.410 --> 00:00:12.380
As you can imagine,
sampling is really important.

00:00:12.380 --> 00:00:13.140
Okay?

00:00:13.140 --> 00:00:15.060
Because I have this set of samples, and

00:00:15.060 --> 00:00:18.330
every step I have to generate
a new set of samples.

00:00:18.330 --> 00:00:19.440
So I have to re-sample it.

00:00:19.440 --> 00:00:24.370
I go, grab a sample, where the
probability of pulling out that sample,

00:00:24.370 --> 00:00:28.600
for its state x, is proportional
to the weight of that sample.

00:00:28.600 --> 00:00:32.210
And typically, I'm doing this a constant
amount of times, so n times, so

00:00:32.210 --> 00:00:35.500
I'm using 1,000 samples, 10,000, however
many samples, I'm doing that every time.

00:00:36.590 --> 00:00:40.440
We'll talk actually not today but next
time, that number can get kind of big if

00:00:40.440 --> 00:00:43.940
your state space gets large, so
being able to sample effectively or

00:00:43.940 --> 00:00:46.980
efficiently, or less often,
is kind of important.

00:00:46.980 --> 00:00:49.030
So I'll talk about
resampling a little bit.

00:00:49.030 --> 00:00:53.500
What we have here is a,
an outer ring, okay,

00:00:53.500 --> 00:00:58.090
where the idea is that the arc length of
that ring is proportional to the weight.

00:00:58.090 --> 00:01:03.190
Okay, so, you know, w1 is small, w2 is
bigger, w3 is huge, etc., whatever.

00:01:03.190 --> 00:01:05.160
And these are all the weights, right?

00:01:05.160 --> 00:01:08.620
So you can think of sampling as
the following, I just randomly pick

00:01:08.620 --> 00:01:13.830
a direction, and if I hit w3,
I'm going to take sample number three.

00:01:13.830 --> 00:01:15.590
So that'd be my first sample.

00:01:15.590 --> 00:01:16.860
All right, do it again!

00:01:16.860 --> 00:01:20.360
If I hit wn,
I pull out the nth sample, and

00:01:20.360 --> 00:01:23.759
basically I have to keep
doing that n times, right?

00:01:23.759 --> 00:01:26.845
So, it's kind of,
it's like a roulette wheel.

00:01:26.845 --> 00:01:31.665
I spin the roulette wheel n times, and
I have to figure out where I land, and

00:01:31.665 --> 00:01:33.835
that figuring out is
actually a binary search, so

00:01:33.835 --> 00:01:36.085
that's log n, but I do that n times.

00:01:36.085 --> 00:01:38.815
So it's an n log n operation.

00:01:38.815 --> 00:01:43.480
So that's kind of it's not awful,
but it doesn't

00:01:43.480 --> 00:01:48.320
scale linearly with the number of, of
samples you use, it goes up by n log n.

00:01:48.320 --> 00:01:51.790
It turns out there's a cute little
trick that you can use that is,

00:01:51.790 --> 00:01:55.280
instead of like a roulette wheel,
is more like a wagon wheel, and

00:01:55.280 --> 00:01:57.110
the way it works is this.

00:01:57.110 --> 00:01:59.650
So let's suppose I have n samples.

00:01:59.650 --> 00:02:04.408
I can make a set of spokes that
are 1 over n full rotation around.

00:02:04.408 --> 00:02:07.844
So here I've got 1, 2,
3, 4, 5, 6, 7, 8, right?

00:02:07.844 --> 00:02:09.526
So each one is an eighth of an arc.

00:02:09.526 --> 00:02:14.161
And what I can do is,
I can randomly put it down someplace,

00:02:14.161 --> 00:02:18.889
and if I've randomly done it,
then I can just read off, for

00:02:18.889 --> 00:02:22.504
each one of these spokes,
which w did it hit?

00:02:22.504 --> 00:02:25.640
Okay?
And in fact, the starting way, right,

00:02:25.640 --> 00:02:29.900
I can just start at some random one
here, and I see what w am I at, and

00:02:29.900 --> 00:02:32.830
I go to the next one and
I see, did I pass a boundary?

00:02:32.830 --> 00:02:35.990
If so, then I'm at the next w,
and likewise.

00:02:35.990 --> 00:02:40.780
So, what's nice about that is
that's done in constant n time.

00:02:40.780 --> 00:02:43.650
And it's sometimes called
stochastic universal sampling,

00:02:43.650 --> 00:02:45.320
systematic resampling.

00:02:45.320 --> 00:02:49.090
The nice thing about it is that
it's a linear time complexity.

00:02:49.090 --> 00:02:52.270
You know if you do 10,000 points,
it takes you so long.

00:02:52.270 --> 00:02:55.510
If you do 20,000 points, it takes
you just twice as long, all right?

00:02:55.510 --> 00:02:56.790
And it's very easy to implement.

00:02:56.790 --> 00:02:59.000
In fact so easy to implement,
let me show it to you.

