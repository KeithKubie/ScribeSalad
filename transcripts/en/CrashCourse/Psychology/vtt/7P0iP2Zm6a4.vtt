WEBVTT
Kind: captions
Language: en

00:00:00.110 --> 00:00:04.810
In February 1999, four New York City police
officers were on patrol in the Bronx when

00:00:04.810 --> 00:00:09.700
they saw a young black man standing on a stoop.
They thought he looked suspicious. When they

00:00:09.700 --> 00:00:14.570
pulled over, he retreated into the doorway
and began digging in his pocket. He kept digging

00:00:14.570 --> 00:00:18.930
as the police shouted at him to show his hands;
a few seconds later, the man, Amadou Diallo,

00:00:18.930 --> 00:00:24.560
a 23-year-old immigrant from Guinea, was
dead, hit by 19 of the 41 bullets that the

00:00:24.560 --> 00:00:29.960
police fired at him. What Diallo was reaching
for was his wallet. He was going for his ID

00:00:29.960 --> 00:00:32.340
as he stood on the steps of his own apartment
building.

00:00:32.340 --> 00:00:37.180
Diallo's story, and the officer's fatal pre-judgment
of him, is recounted in Malcolm Gladwell's

00:00:37.180 --> 00:00:40.970
2005 bestseller Blink. Gladwell, and
the social psychologists whose

00:00:40.970 --> 00:00:46.510
work he draws upon, explores Diallo's case
as an example of that grey area between deliberate

00:00:46.510 --> 00:00:51.060
violence and an accident, propagated by
non-conscious, or implicit biases.

00:00:51.060 --> 00:00:55.450
The officers did discriminate against Diallo,
but the prejudice they acted on may have been

00:00:55.450 --> 00:00:58.380
driven by something more subtle than simple
hatred.

00:00:58.380 --> 00:01:02.500
And that's an important thing to think about.
Yes, there are lots of overtly bigoted people

00:01:02.500 --> 00:01:06.860
and policies at work all over the world, but
what we're interested in today is the more

00:01:06.860 --> 00:01:11.590
insidious, non-conscious automatic bias, and
how it can affect our behavior.

00:01:11.590 --> 00:01:16.630
The fact is, our implicit biases affect the
way we relate to others in a very real way.

00:01:16.630 --> 00:01:21.660
Our race, gender, age, religion, or sexual
orientation can make the difference between

00:01:21.670 --> 00:01:26.170
whether we get a job or not, a fair paycheck,
or a good rental, or whether we get randomly

00:01:26.170 --> 00:01:29.100
pulled over or shot and killed for reaching
for a wallet.

00:01:29.100 --> 00:01:33.549
In the last two episodes, we've examined how
we think about and how we influence one another,

00:01:33.549 --> 00:01:36.770
but social psychology is also about how we
relate to one another.

00:01:36.770 --> 00:01:41.189
Like what factors might cause us to help another
person, or harm them, or fear them? What are

00:01:41.189 --> 00:01:44.990
the social, and cognitive, and emotional roots
of prejudice, racism, and sexism, and how

00:01:44.990 --> 00:01:48.200
do they shape our society? These are some
of the aspects of ourselves that are the hardest

00:01:48.200 --> 00:01:52.940
and most uncomfortable for us to explore,
which is why they're so important to understand.

00:02:02.720 --> 00:02:07.220
We've all been unfairly judged in our time,
and let's not pretend that we haven't done

00:02:07.229 --> 00:02:09.869
our fair share of uninformed judging too.

00:02:09.869 --> 00:02:12.769
Like it or not, prejudice is a common human
condition.

00:02:12.769 --> 00:02:17.840
Prejudice just means "prejudgment." It's an
unjustified, typically negative attitude toward

00:02:17.840 --> 00:02:20.910
an individual or group.
Prejudicial attitudes are often directed along

00:02:20.910 --> 00:02:25.900
the lines of gender, ethnic, socioeconomic
status, or culture, and by definition, prejudice

00:02:25.900 --> 00:02:31.420
is not the same thing as stereotyping or discrimination,
although the three phenomena are intimately related.

00:02:31.420 --> 00:02:36.480
People may distrust a female mechanic. That's
a prejudicial attitude, but it's rooted in

00:02:36.480 --> 00:02:40.430
a stereotype, or over-generalized belief about
a particular group.

00:02:40.430 --> 00:02:44.080
Although it's often discussed in a negative
way, stereotyping is really more of a general

00:02:44.080 --> 00:02:48.840
cognitive process that doesn't have to be
negative. It can even be accurate at times.

00:02:48.840 --> 00:02:54.080
Like, I have the stereotype that all crows
have wings, injuries and birth defects aside.

00:02:54.080 --> 00:02:55.730
And that happens to be true.

00:02:55.730 --> 00:03:00.010
But on the negative end, your prejudice against
female mechanics may be rooted in some inaccurate

00:03:00.010 --> 00:03:02.640
stereotype about women's skills with a socket
wrench.

00:03:02.640 --> 00:03:07.000
And when stereotypical beliefs combine with
prejudicial attitudes and emotions, like fear

00:03:07.000 --> 00:03:10.819
and hostility, they can drive the behavior
we call discrimination.

00:03:10.819 --> 00:03:16.209
So a prejudiced person won't necessarily act
on their attitude. Say you believe in the

00:03:16.209 --> 00:03:20.519
stereotype that overweight people are lazy.
You might then feel a prejudiced distaste

00:03:20.519 --> 00:03:22.450
when you see someone who appears overweight.

00:03:22.450 --> 00:03:26.110
But if you act on your prejudice, and, say,
refuse to hire them for a job or don't let

00:03:26.110 --> 00:03:30.019
them sit at your lunch counter, then you've
crossed over into discriminating against them.

00:03:30.019 --> 00:03:34.360
The former apartheid system of racial segregation
in South Africa, the Nazis' mass killing of

00:03:34.360 --> 00:03:38.230
Gypsies, Jewish people, and other groups,
and centuries of bloodshed between Protestants

00:03:38.230 --> 00:03:42.720
and Catholics, are all extreme examples of
violent prejudice and discrimination.

00:03:42.720 --> 00:03:48.159
The good news is that in many cultures, certain
forms of overt prejudice have waned over time.

00:03:48.159 --> 00:03:52.180
For example, in 1937 only 1/3 of Americans
said that they'd vote for a qualified woman to

00:03:52.180 --> 00:03:56.580
be president, while in 2007, that figure was
up to nearly 90 percent.

00:03:56.580 --> 00:03:59.160
But of course more subtle prejudices can still
linger.

00:03:59.160 --> 00:04:02.980
In the past, we've talked about dual-process
theories of thought, memories, and attitudes,

00:04:02.980 --> 00:04:08.379
and that while we're aware of our explicit
thoughts, or implicit cognition still operates

00:04:08.379 --> 00:04:12.900
under the radar, leaving us clueless about
its effect on our attitudes and behavior.

00:04:12.900 --> 00:04:18.349
In the same way, prejudice can be non-conscious
and automatic. And I mean it can be so non-conscious

00:04:18.349 --> 00:04:22.869
that even when people ask us point-blank about
our attitudes, we unwillingly or unknowingly

00:04:22.869 --> 00:04:24.659
don't always give them an honest answer.

00:04:24.659 --> 00:04:28.469
Do you think that men are better at science
the women? Or that Muslims are more violent

00:04:28.469 --> 00:04:31.199
than Christians? Or that overweight people
are unhealthy?

00:04:31.199 --> 00:04:36.099
Our tendency to unwittingly doctor our answers
to questions like these is why we have the

00:04:36.099 --> 00:04:40.999
implicit association test, or IAT. The test
was implemented in the late 1990s to try to

00:04:40.999 --> 00:04:47.559
gauge implicit attitudes, identities, beliefs, and biases
that people are unwilling or unable to report.

00:04:47.560 --> 00:04:51.839
You can take the IAT online and measure your
implicit attitudes in all kinds of topics,

00:04:51.839 --> 00:04:57.959
from race, religion, and gender to disability, weight, and
sexuality. It's basically a timed categorization task.

00:04:57.960 --> 00:05:02.020
For example, the age-related IAT looks at
implicit attitudes about older vs. younger

00:05:02.020 --> 00:05:07.009
people. In it, you might be shown a series
of faces, old and young, and objects, pleasant

00:05:07.009 --> 00:05:10.229
and unpleasant, like pretty flowers vs. a
pile of garbage.

00:05:10.229 --> 00:05:13.779
You're then asked to sort these pictures,
so you'd press the left key if you see a young

00:05:13.779 --> 00:05:17.930
face or a pleasant object, and press the right
key if you see an old face or an unpleasant

00:05:17.930 --> 00:05:22.330
object. That's the stereotypic condition.
Your keystrokes correspond to stereotypical

00:05:22.330 --> 00:05:27.149
pairs; in this case, associating good stuff
with youth and bad stuff with older age.

00:05:27.149 --> 00:05:31.439
Then the test asks you to do the same thing
in a counter-stereotypic condition, pressing

00:05:31.439 --> 00:05:35.399
the left key if you see a young face or an
unpleasant object and the right key if you

00:05:35.399 --> 00:05:37.509
see an old face or a pleasant object.

00:05:37.509 --> 00:05:41.869
The core of the test is your reaction time.
Are you faster at sorting when you're working

00:05:41.869 --> 00:05:45.819
with a stereotypical pairing than you are
with counter-stereotypical pairings? If that's

00:05:45.819 --> 00:05:49.619
the case, even though you may think you're
unprejudiced, you've got an implicit association

00:05:49.619 --> 00:05:53.999
between youth and goodness, which, as you
might guess, may have some implications about

00:05:53.999 --> 00:05:56.089
how you think and act toward older people.

00:05:56.089 --> 00:06:00.490
The test is widely used in research, and contrary
to what some critics think, it's surprisingly

00:06:00.490 --> 00:06:04.499
predictive of discriminatory behavior in all
kinds of experimental settings.

00:06:04.499 --> 00:06:09.080
So that's one way to measure subtle, implicit
prejudice. But obviously, overt prejudice

00:06:09.080 --> 00:06:13.589
is far from dead. That's why discrimination
studies are prominent in social psychology

00:06:13.589 --> 00:06:18.439
research, and they can also predict, sometimes
with scary accuracy, how discrimination might

00:06:18.439 --> 00:06:23.080
show up in broad social patterns, like wage
inequality and job opportunity gaps.

00:06:23.080 --> 00:06:27.999
For instance, the 2012 Yale study led by social
scientist Corinne Moss-Racusin demonstrated

00:06:27.999 --> 00:06:32.969
that science faculty across the country systematically
discriminated against female science students.

00:06:32.969 --> 00:06:37.069
In a double-blind study, a representative
sample of science faculty members were asked

00:06:37.069 --> 00:06:40.869
to hire a fictional student applicant for
a lab-manager job.

00:06:40.869 --> 00:06:45.339
When the applicant's name was Jennifer, instead
of John, they viewed her as less competent,

00:06:45.339 --> 00:06:49.659
were less likely to hire her, offered her less
money, and were less likely to mentor her.

00:06:49.659 --> 00:06:52.249
And this prejudice was even exhibited by women
faculty members.

00:06:52.249 --> 00:06:56.990
And that's an important point. People on both
sides of the stereotype tend to respond similarly,

00:06:56.990 --> 00:07:01.009
with the subjects of prejudice themselves
often holding the same stereotypical implicit

00:07:01.009 --> 00:07:04.089
attitudes or engaging in the same discriminatory
behavior.

00:07:04.089 --> 00:07:07.880
So when we say that stereotypes are pervasive,
we mean pervasive.

00:07:07.880 --> 00:07:11.839
Now it's all too easy to hold up examples
of how people are prejudiced, but the real

00:07:11.839 --> 00:07:14.289
root of the issue is why they are.

00:07:14.289 --> 00:07:15.779
Here are a few possibilities:

00:07:15.779 --> 00:07:20.240
For one, prejudices can come up as a way of
justifying social inequalities. This happens

00:07:20.240 --> 00:07:23.830
when people on both sides of the power and
wealth spectrum start believing that people

00:07:23.830 --> 00:07:29.570
get what they deserve, and they deserve what
they get. This is called the just-world phenomenon.

00:07:29.570 --> 00:07:34.280
Prejudices can also be driven by the "us vs.
them," or as social psychologists often call

00:07:34.289 --> 00:07:38.110
it, the ingroup-outgroup phenomenon. Whether
you're in a soccer stadium, or the political

00:07:38.110 --> 00:07:43.039
arena or school lunchroom, or, you know, in
the comments of this video, dividing the world

00:07:43.039 --> 00:07:46.999
into in-groups and out-groups definitely drives
prejudice and discrimination.

00:07:46.999 --> 00:07:51.239
But an in-group identity also gives its members
the benefits of communal solidarity and a

00:07:51.239 --> 00:07:56.110
sort of safety in numbers. This in-group bias,
or tendency to favor your own group at the

00:07:56.110 --> 00:08:00.800
expense of others, is powerful, even when
it's totally irrational. One common social

00:08:00.800 --> 00:08:04.899
psychology exercise on in-group favoritism
involves dividing a class into two arbitrary

00:08:04.899 --> 00:08:09.229
groups, say, those wearing sneakers and those
not wearing sneakers. Each person sits with

00:08:09.229 --> 00:08:13.459
his or her group and is told to list differences
between themselves and the opposing group.

00:08:13.459 --> 00:08:18.789
The lists usually start out pretty tame, but
become more strident as they grow longer. Eventually,

00:08:18.789 --> 00:08:22.599
you have sneaker-wearing kids saying that
they're just smarter than the people without

00:08:22.599 --> 00:08:26.219
sneakers. The kids who don't have sneakers
say that the other kids are trashy and low-class.

00:08:26.219 --> 00:08:30.399
Soon enough, each group has inflated itself
and derided the opposing group, even though

00:08:30.399 --> 00:08:33.719
the division between the two was essentially
meaningless to begin with.

00:08:33.719 --> 00:08:37.639
Little exercises like this illustrate the
power of any ingroup-outgroup distinction

00:08:37.639 --> 00:08:43.199
in creating conflict between groups, and that brings
us to the psychological nature of conflict itself.

00:08:43.199 --> 00:08:47.759
History is littered with examples of how the
us vs. them mentality has fueled violence

00:08:47.759 --> 00:08:51.569
in warfare, which is exactly what we'll be
talking about next time.

00:08:51.569 --> 00:08:55.660
Today, you learned about how prejudice, stereotyping,
and discrimination affect how we interact

00:08:55.660 --> 00:09:00.550
and relate to one another. You learned how
prejudice can often be non-conscious and automatic

00:09:00.550 --> 00:09:05.470
and how tools like the Implicit Association
Test help reveal and measure it. We also looked

00:09:05.470 --> 00:09:10.040
at the implications of the ingroup-outgroup
phenomenon, and how it can lead to strong

00:09:10.040 --> 00:09:13.360
in-group bias that often turns aggressive.

00:09:13.360 --> 00:09:17.320
This episode of Crash Course Psychology was
sponsored by Shane Barr, whose young adult

00:09:17.329 --> 00:09:21.019
sci-fi adventure book, Reset, is available
on Amazon.

00:09:21.019 --> 00:09:24.569
Thanks for watching, especially to all of our
Subbable subscribers who make Crash Course

00:09:24.569 --> 00:09:28.889
possible. To find out how you can become a
supporter or lead sponsor like Shane, just

00:09:28.889 --> 00:09:30.800
go to Subbable.com/CrashCourse.

00:09:30.800 --> 00:09:34.800
This episodes was written by Kathleen Yale,
edited by Blake de Pastino, and our consultant

00:09:34.800 --> 00:09:39.879
is Dr. Ranjit Bhagwat. Our director and editor
is Nicholas Jenkins, the script supervisor and sound

00:09:39.879 --> 00:09:43.199
designer is Michael Aranda, and the graphics
team is Thought Cafe.

