WEBVTT
Kind: captions
Language: en

00:00:00.434 --> 00:00:02.867
♪ (intro music) ♪

00:00:04.212 --> 00:00:06.233
So, welcome to this episode
of TensorFlow Meets,

00:00:06.233 --> 00:00:08.505
where I'm really delighted
to welcome Razial

00:00:08.505 --> 00:00:11.261
straight from his talk
at the TensorFlow Dev Summit.

00:00:11.261 --> 00:00:13.431
We spoke all about TensorFlow Lite.

00:00:13.431 --> 00:00:14.560
Welcome, Raziel.

00:00:14.560 --> 00:00:16.723
Can you tell us a little bit
about you and what you do?

00:00:16.723 --> 00:00:17.847
Thank you.

00:00:17.847 --> 00:00:20.911
I'm an Engineering Lead
at TensorFlow Lite.

00:00:20.911 --> 00:00:23.756
I'm particularly focused
on model optimization,

00:00:23.756 --> 00:00:28.036
which the goal is change
the models in certain ways

00:00:28.036 --> 00:00:32.205
that can be smaller and faster
to execute in edge devices.

00:00:32.205 --> 00:00:33.205
(Laurence) I see, okay.

00:00:33.205 --> 00:00:36.951
Now, I have to say,
I geek out about TensorFlow Lite.

00:00:36.951 --> 00:00:39.791
If I have a favorite thing
in TensorFlow, it's TF Lite.

00:00:39.791 --> 00:00:42.199
I just love doing it,
the demos are always great.

00:00:42.199 --> 00:00:43.855
When I do talks, it's usually about that.

00:00:43.855 --> 00:00:47.556
So, it's really fun to have you here
to learn a little bit more.

00:00:48.066 --> 00:00:50.542
Can you tell us what's going on
with TensorFlow Lite right now?

00:00:50.542 --> 00:00:52.419
Yeah, we are doing a lot of things.

00:00:53.089 --> 00:00:55.116
Like I said during the talk,

00:00:55.936 --> 00:00:58.713
we're really trying to make
as easy as possible

00:00:58.713 --> 00:01:01.114
to deploy machine learning on devices.

00:01:01.114 --> 00:01:02.838
And this is really important

00:01:03.608 --> 00:01:07.206
because machine learning
is moving from the server

00:01:07.206 --> 00:01:08.827
to these edge devices.

00:01:08.827 --> 00:01:11.587
And because of all
of these characteristics

00:01:11.587 --> 00:01:14.906
that you have on the Edge,
it is challenging,

00:01:14.906 --> 00:01:17.447
so we're trying
to make that very, very easy.

00:01:17.447 --> 00:01:20.929
Now, on the flip side, it also means
that you have access to a lot of data,

00:01:21.599 --> 00:01:24.642
it has a strong
privacy-preserving component.

00:01:24.642 --> 00:01:27.569
So, really, you can build products
that otherwise wouldn't be possible

00:01:27.569 --> 00:01:30.201
if you just rely on server-side execution.

00:01:30.201 --> 00:01:35.305
So, the way I see our work
is we're enabling the next generation

00:01:35.305 --> 00:01:37.803
of AI-based applications.

00:01:37.803 --> 00:01:40.239
Now, to the people who may be familiar
with TensorFlow Lite,

00:01:40.239 --> 00:01:43.302
they would think about it
as running on Android or iOS,

00:01:43.302 --> 00:01:46.147
but you're also extending now
into IoT devices.

00:01:46.147 --> 00:01:48.760
Yeah, we're extending to a lot of places.

00:01:50.010 --> 00:01:52.582
The Google Assistant
is one example of that

00:01:52.582 --> 00:01:56.001
where if you think the assistant
is running on Android,

00:01:56.001 --> 00:01:57.782
is running on Google Home devices,

00:01:57.782 --> 00:02:02.109
but it's also running
in many other types of wearables.

00:02:02.739 --> 00:02:05.050
They're really trying
to push the boundaries

00:02:05.050 --> 00:02:07.620
of where machine learning can execute.

00:02:07.620 --> 00:02:10.979
So, we're trying to engage with them

00:02:10.979 --> 00:02:13.588
and learn about those use cases,
and power those.

00:02:14.068 --> 00:02:18.036
We also have this new project
about micro-controllers.

00:02:18.816 --> 00:02:20.196
So, that's also very exciting

00:02:20.196 --> 00:02:22.970
because we're pushing now
more to IoT devices.

00:02:24.050 --> 00:02:27.303
Again, we're really trying to push
machine learning everywhere.

00:02:27.873 --> 00:02:31.512
So, one of my favorite scenarios
of using it on a mobile device

00:02:31.512 --> 00:02:33.841
was the Cassava-- if you've seen that.

00:02:33.841 --> 00:02:38.065
Where it's like these plants in Tanzania,
and you can diagnose them for disease

00:02:38.065 --> 00:02:39.926
by just waving your phone
over them like this.

00:02:39.926 --> 00:02:42.382
So, it's just a really exciting scenario.

00:02:42.382 --> 00:02:46.568
Do you see any other good, fun scenarios
around TensorFlow Lite

00:02:46.568 --> 00:02:48.805
or maybe even using it
in embedded systems?

00:02:48.805 --> 00:02:53.771
Yeah, like I said, one of the great things
of machine learning on the device

00:02:53.771 --> 00:02:57.361
is that you also do away
with the requirements of connectivity.

00:02:58.871 --> 00:03:01.472
This is very important
for many different countries--

00:03:01.472 --> 00:03:05.290
the connectivity, perhaps,
comes at a challenge or is costly,

00:03:05.290 --> 00:03:07.902
so we're trying to enable
all those things.

00:03:07.902 --> 00:03:09.160
And, at the same time,

00:03:09.160 --> 00:03:12.283
we're trying to support
more and more hardware

00:03:12.283 --> 00:03:18.032
so you can execute better and larger
and more complex models on these devices

00:03:18.032 --> 00:03:20.559
and do even more
exciting things with them.

00:03:20.559 --> 00:03:22.770
Like, one example is the Edge TPU,

00:03:23.250 --> 00:03:27.226
and that's something we're really excited
that we support it right now,

00:03:27.226 --> 00:03:31.132
and we're working with them
to make it even better and even faster.

00:03:32.382 --> 00:03:35.990
If you took a look at my presentation--

00:03:36.820 --> 00:03:39.921
we have this very nice slide of MobileNet.

00:03:39.921 --> 00:03:44.027
MobileNet is a very common
image recognition neural network,

00:03:44.357 --> 00:03:47.907
<i>and you can see the progress
from executing in floating point in CPU</i>

00:03:47.907 --> 00:03:52.868
<i>which is the baseline to be able
to execute in CPU [quantized],</i>

00:03:52.868 --> 00:03:55.183
<i>then with the GPU support that we have.</i>

00:03:55.183 --> 00:04:00.506
<i>The GPU was already seven times faster
than what you can get from a regular CPU.</i>

00:04:00.506 --> 00:04:02.873
<i>And if you look at the numbers
for the Edge TPU,</i>

00:04:02.873 --> 00:04:04.996
<i>they're like over 60 times faster.</i>

00:04:05.526 --> 00:04:11.764
And this is really important
because the quality of the model

00:04:12.384 --> 00:04:16.554
is very much directly related
to the size and the computation.

00:04:16.554 --> 00:04:21.084
So, by enabling larger models,
then we can also enable better quality

00:04:21.564 --> 00:04:23.363
- for the users.
- (Laurence) Excellent.

00:04:23.363 --> 00:04:26.446
One of the things you were mentioning
there about particularly complex models,

00:04:26.446 --> 00:04:28.348
like quantization and pruning.

00:04:28.348 --> 00:04:30.913
Now, it used to be that was part
of the conversion process

00:04:30.913 --> 00:04:33.850
when you're converting to TF Lite,
but now you can do it beforehand?

00:04:33.850 --> 00:04:37.288
Yes, we can do it before
and we can do it after.

00:04:37.288 --> 00:04:39.843
Each one has its pros and cons.

00:04:40.513 --> 00:04:45.442
The nice thing of beforehand
is that you can get even better quality.

00:04:45.442 --> 00:04:47.751
So, typically,
with all of these techniques,

00:04:48.931 --> 00:04:52.094
you have a model,
and you apply one of these techniques,

00:04:52.094 --> 00:04:54.861
and it might affect
your accuracy a little bit.

00:04:55.681 --> 00:05:01.382
So, by doing it at training time,
we're really trying to minimize that loss,

00:05:01.382 --> 00:05:03.311
and in many cases, there is none.

00:05:04.611 --> 00:05:08.877
Now, the nice thing is also
that being part of the TensorFlow,

00:05:08.877 --> 00:05:11.071
we have also Keras

00:05:11.071 --> 00:05:14.786
as this really nice abstraction
for neural network layers.

00:05:14.786 --> 00:05:17.119
So, we're building on top of Keras,

00:05:17.119 --> 00:05:21.103
and if you look at other APIs
that are coming very soon,

00:05:21.103 --> 00:05:23.370
it's extremely easy for anybody to just--

00:05:24.130 --> 00:05:26.308
if they have already a Keras model,

00:05:26.308 --> 00:05:29.742
it's very easy to apply
quantization and pruning.

00:05:30.472 --> 00:05:31.604
At the same time,

00:05:31.604 --> 00:05:36.034
we're making a huge effort
also on the post-training side

00:05:36.034 --> 00:05:41.156
to make it very easy for everybody
to also quantize a model, for example.

00:05:41.696 --> 00:05:45.283
And that's because some people
are not very familiar with training

00:05:45.283 --> 00:05:48.147
or the first thing they want to try

00:05:48.147 --> 00:05:50.703
is to just have a model
that they got somewhere

00:05:50.703 --> 00:05:52.332
and they want to quantize it.

00:05:52.332 --> 00:05:56.657
So, that's why we have this other path
of doing post-training quantization.

00:05:56.657 --> 00:05:58.521
So, we're very invested in doing both,

00:05:58.521 --> 00:06:02.334
like power users
and somebody that just wants to try it

00:06:02.334 --> 00:06:03.804
and see how things go.

00:06:03.804 --> 00:06:05.005
That makes perfect sense.

00:06:05.005 --> 00:06:08.380
So, if somebody is really inspired by this
and wants to give it a try,

00:06:08.380 --> 00:06:10.054
how would you recommend
they get started?

00:06:10.054 --> 00:06:11.741
Well, we have a lot of sites,

00:06:12.371 --> 00:06:16.170
a lot of examples
in the <i>tensorflow.org</i> site.

00:06:16.530 --> 00:06:20.742
We have right now
four completed applications

00:06:20.742 --> 00:06:22.711
that people can try.

00:06:22.711 --> 00:06:25.939
And we're trying to really build up
our model repository.

00:06:25.939 --> 00:06:29.250
And the goal is that
if there is somebody out there

00:06:29.250 --> 00:06:32.711
that perhaps doesn't have the experience
or doesn't want to invest right away

00:06:32.711 --> 00:06:36.140
but has a cool idea 
for a very interesting product,

00:06:36.140 --> 00:06:38.891
they can go to our repository,
see what is there,

00:06:38.891 --> 00:06:41.797
and maybe there is something already
that they can take advantage of.

00:06:41.797 --> 00:06:43.508
And maybe they can build
on that and expand

00:06:43.508 --> 00:06:45.484
and others can learn
from their experience.

00:06:45.484 --> 00:06:46.587
Yeah, exactly.

00:06:46.587 --> 00:06:52.454
I think it's all about
making friction-less adoption.

00:06:52.454 --> 00:06:55.015
Like, once you feel comfortable
doing something,

00:06:55.015 --> 00:06:57.777
then you can try more complex things,
and more complex things.

00:06:57.777 --> 00:06:59.084
So, thanks so much, Raziel.

00:06:59.084 --> 00:07:01.599
That was, as always,
informative and inspiring.

00:07:01.599 --> 00:07:03.136
- Thank you.
- So, thanks, everybody

00:07:03.136 --> 00:07:04.951
for watching this episode
of TensorFlow Meets.

00:07:04.951 --> 00:07:07.479
If you have any questions for me
or any questions for Raziel,

00:07:07.479 --> 00:07:09.270
please leave them in the comments below.

00:07:09.270 --> 00:07:12.294
And I'll also put a link to his talk
from the TensorFlow Developer Summit,

00:07:12.294 --> 00:07:14.258
so you can learn a lot more
about TensorFlow Lite.

00:07:14.258 --> 00:07:15.605
So, thank you so much.

00:07:15.612 --> 00:07:17.638
♪ (ending music) ♪

