WEBVTT
Kind: captions
Language: en

00:00:09.850 --> 00:00:12.330
DAVID KONERDING: Hello, and
welcome to Academics At Google

00:00:12.330 --> 00:00:13.230
talks.

00:00:13.230 --> 00:00:16.860
I'm really excited to
introduce Kai Kohlhoff today,

00:00:16.860 --> 00:00:19.550
with whom I've worked for
the past four years at Google

00:00:19.550 --> 00:00:21.540
on a project called Exacycle.

00:00:21.540 --> 00:00:23.300
Today, he's going
to announce and show

00:00:23.300 --> 00:00:25.700
some very exciting
results from using

00:00:25.700 --> 00:00:28.540
Exacycle for
simulating proteins.

00:00:28.540 --> 00:00:31.200
Now let me tell you a little
bit more about Exacycle

00:00:31.200 --> 00:00:32.530
and why it's important.

00:00:32.530 --> 00:00:35.350
Exacycle is a computing
platform at Google

00:00:35.350 --> 00:00:38.650
that uses our massive
data centers to carry out

00:00:38.650 --> 00:00:41.610
extraordinarily large
and complex simulations.

00:00:41.610 --> 00:00:44.500
This has been a problem in
science for a very long time

00:00:44.500 --> 00:00:46.440
where scientists were
not able to get access

00:00:46.440 --> 00:00:48.820
to really large amounts
of computing power.

00:00:48.820 --> 00:00:50.870
This has been changing
over the past few years,

00:00:50.870 --> 00:00:52.400
especially with the cloud.

00:00:52.400 --> 00:00:54.290
However, with the cloud,
there are a number

00:00:54.290 --> 00:00:56.390
of things that you
have to do to optimize

00:00:56.390 --> 00:00:58.600
your applications
to run very quickly.

00:00:58.600 --> 00:01:00.940
So we built an application
called Exacycle

00:01:00.940 --> 00:01:03.900
that enables
scientists to carry out

00:01:03.900 --> 00:01:07.280
millions of core simulations
that run for months or years

00:01:07.280 --> 00:01:07.930
at a time.

00:01:07.930 --> 00:01:10.290
And then also,
because we're Google,

00:01:10.290 --> 00:01:13.520
we need to be able to analyze
enormous amounts of data.

00:01:13.520 --> 00:01:15.950
And so along with
Exacycle, we created

00:01:15.950 --> 00:01:19.070
a technology called Flume, which
makes it really easy to process

00:01:19.070 --> 00:01:20.740
large amounts of data.

00:01:20.740 --> 00:01:23.120
So working with
Kai Kohlhoff, whom

00:01:23.120 --> 00:01:25.540
I met four years
ago at Stanford,

00:01:25.540 --> 00:01:28.710
we took the Exacycle
system and ran

00:01:28.710 --> 00:01:31.640
some very complicated
calculations on it.

00:01:31.640 --> 00:01:34.810
To give some background,
we do something

00:01:34.810 --> 00:01:37.070
called molecular dynamic
simulations, which

00:01:37.070 --> 00:01:41.530
are literally the application of
Newton's equations to proteins.

00:01:41.530 --> 00:01:43.430
And if you run these
kinds of simulations,

00:01:43.430 --> 00:01:46.880
you can often get insights
into how the systems work

00:01:46.880 --> 00:01:48.650
and behave in the real world.

00:01:48.650 --> 00:01:50.690
You can take those models
and that information

00:01:50.690 --> 00:01:53.910
and use it to improve industrial
products and pharmaceutical

00:01:53.910 --> 00:01:55.410
products like drugs.

00:01:55.410 --> 00:01:58.570
And so Kai will give
a lot of details

00:01:58.570 --> 00:02:00.435
about how the system works.

00:02:00.435 --> 00:02:01.810
What I'm going to
do is I'm going

00:02:01.810 --> 00:02:04.380
to give you a little bit
of an idea of how Exacycle

00:02:04.380 --> 00:02:06.470
itself works and
why it's important.

00:02:06.470 --> 00:02:08.610
So Google, in building
out its infrastructure

00:02:08.610 --> 00:02:10.470
to serve search
results for people,

00:02:10.470 --> 00:02:13.170
has to size its system
for peak capacity.

00:02:13.170 --> 00:02:14.750
However, in the
middle of the night,

00:02:14.750 --> 00:02:17.000
many of those systems when
people aren't searching

00:02:17.000 --> 00:02:18.450
have idle cycles.

00:02:18.450 --> 00:02:20.490
So we do is we
built a system that

00:02:20.490 --> 00:02:22.940
uses our idle cycles
to do computing.

00:02:22.940 --> 00:02:24.520
And we have a lot
of idle cycles,

00:02:24.520 --> 00:02:27.960
because at peak, we have
to serve a lot of users.

00:02:27.960 --> 00:02:30.430
So I took a system--
it was influenced

00:02:30.430 --> 00:02:32.710
by SETI@home Folding@home.

00:02:32.710 --> 00:02:36.050
We basically treat our
systems like massive farms

00:02:36.050 --> 00:02:39.220
of desktop computers
available for computing.

00:02:39.220 --> 00:02:42.050
This actually raises a number
of really challenging problems

00:02:42.050 --> 00:02:44.620
such as dealing
with data at scale

00:02:44.620 --> 00:02:47.090
and making sure that you
don't melt down data centers.

00:02:47.090 --> 00:02:48.960
So after a number
of years of work,

00:02:48.960 --> 00:02:51.490
Kai was able to run a
number of simulations.

00:02:51.490 --> 00:02:53.996
And he's assembled
the results here,

00:02:53.996 --> 00:02:55.370
and he's going to
be showing that

00:02:55.370 --> 00:02:58.160
in advance of a
publication coming out

00:02:58.160 --> 00:02:59.470
in "Nature Chemistry."

00:02:59.470 --> 00:03:02.780
So without further ado,
let me introduce Kai.

00:03:02.780 --> 00:03:05.610
I met Kai about
four years ago when

00:03:05.610 --> 00:03:08.720
he wanted to be a
bioinformatics intern in Google.

00:03:08.720 --> 00:03:12.020
However, he was a
post-doc, and post-docs

00:03:12.020 --> 00:03:13.320
can't be interns at Google.

00:03:13.320 --> 00:03:15.484
So instead, we hired him
as a visiting faculty

00:03:15.484 --> 00:03:16.900
and gave him the
resources that he

00:03:16.900 --> 00:03:18.890
needed to carry out his work.

00:03:18.890 --> 00:03:21.810
Kai has now become a
full-time researcher at Google

00:03:21.810 --> 00:03:24.275
and continues to work
on exciting problems.

00:03:24.275 --> 00:03:26.288
Dr. Kohlhoff, welcome.

00:03:26.288 --> 00:03:29.954
[APPLAUSE]

00:03:29.954 --> 00:03:32.120
KAI KOHLHOFF: Thank you,
Dave, for the introduction.

00:03:32.120 --> 00:03:33.911
Yes, so that was actually
quite surprising.

00:03:33.911 --> 00:03:37.940
I was hoping to spend three to
six months here-- just trying

00:03:37.940 --> 00:03:40.540
to get some bioinformatics
algorithms working

00:03:40.540 --> 00:03:42.060
with some of Google's
technologies.

00:03:42.060 --> 00:03:44.560
And then after I actually went
through the whole application

00:03:44.560 --> 00:03:48.430
process and was ready for host
matching, someone found out,

00:03:48.430 --> 00:03:49.739
well, you got a PhD.

00:03:49.739 --> 00:03:52.030
You're not going to be able
to come here or do anything

00:03:52.030 --> 00:03:54.890
because we're not taking
PhDs for the intern program.

00:03:54.890 --> 00:03:58.610
But luckily, they found a
different way of getting me in.

00:03:58.610 --> 00:04:01.760
And part of that is actually
a pretty interesting part

00:04:01.760 --> 00:04:03.880
of the story, which
really surprised me

00:04:03.880 --> 00:04:05.430
as well at the time.

00:04:05.430 --> 00:04:07.632
So just a little bit
further background--

00:04:07.632 --> 00:04:09.090
I was working as
a bioinformatician

00:04:09.090 --> 00:04:13.320
in the Bioengineering
department at Stanford.

00:04:13.320 --> 00:04:17.720
I was mainly focusing on protein
simulations-- so basically,

00:04:17.720 --> 00:04:21.320
physics-based simulations
of biological systems.

00:04:21.320 --> 00:04:24.770
And with more and more of the
life sciences being treated

00:04:24.770 --> 00:04:26.520
as information sciences,
there's this kind

00:04:26.520 --> 00:04:31.260
of natural interest for
many people and Google,

00:04:31.260 --> 00:04:33.930
for doing things at scale.

00:04:33.930 --> 00:04:35.560
And also, just the
curiosity of it,

00:04:35.560 --> 00:04:37.970
like how can things
work at this scale?

00:04:37.970 --> 00:04:40.096
How do you efficiently work?

00:04:40.096 --> 00:04:41.720
And it really came
as a surprise to me.

00:04:41.720 --> 00:04:44.960
I had an idea that
some people at Google

00:04:44.960 --> 00:04:47.370
might be interested
in biology or doing

00:04:47.370 --> 00:04:50.150
bioinformatics applications, but
that there was actually someone

00:04:50.150 --> 00:04:53.250
here working on
implementing a system that

00:04:53.250 --> 00:04:55.200
was at least in part
inspired by the kind

00:04:55.200 --> 00:04:58.450
of large-scale distributed
computing that we were doing

00:04:58.450 --> 00:05:01.360
at Stanford and the kind
of science applications

00:05:01.360 --> 00:05:02.660
we were working on.

00:05:02.660 --> 00:05:05.700
That really surprised me, and
that was a very nice surprise--

00:05:05.700 --> 00:05:09.240
being able to come here
and continue my work.

00:05:09.240 --> 00:05:11.260
So I was working on
a class of proteins

00:05:11.260 --> 00:05:13.290
called G-protein-coupled
receptors.

00:05:13.290 --> 00:05:15.480
They sit in the cell
membrane and act a little bit

00:05:15.480 --> 00:05:16.130
like a switch.

00:05:16.130 --> 00:05:18.740
So you can imagine that
they sense molecules

00:05:18.740 --> 00:05:21.390
from outside the cell, and
they switch on or off depending

00:05:21.390 --> 00:05:23.530
on what kind of
molecules they are.

00:05:23.530 --> 00:05:27.790
So for example, they
bind to epinephrine.

00:05:27.790 --> 00:05:29.600
Or they bind to caffeine.

00:05:29.600 --> 00:05:32.570
Or they bind to beta blockers.

00:05:32.570 --> 00:05:35.320
So what makes them
interesting also

00:05:35.320 --> 00:05:38.630
is that about half the
existing medication

00:05:38.630 --> 00:05:42.260
interacts with
G-protein-coupled receptors.

00:05:42.260 --> 00:05:45.160
So there's a big interest in
the pharmaceutical sciences

00:05:45.160 --> 00:05:48.000
in this class of proteins.

00:05:48.000 --> 00:05:49.170
So think about this.

00:05:49.170 --> 00:05:51.730
Someone like me right now
standing here in front of you

00:05:51.730 --> 00:05:55.630
and talking is probably
under a lot more stress

00:05:55.630 --> 00:05:57.060
than the rest of
you in the room.

00:05:57.060 --> 00:05:59.268
So you can imagine that I
have more epinephrine going

00:05:59.268 --> 00:06:00.090
through my body.

00:06:00.090 --> 00:06:03.540
And so you will actually
find a lot more active

00:06:03.540 --> 00:06:06.280
G-protein-coupled receptors
telling my heart to beat faster

00:06:06.280 --> 00:06:08.940
and telling my brain to
look out for predators.

00:06:08.940 --> 00:06:12.510
So the thing is that because
all these processes are taking

00:06:12.510 --> 00:06:15.480
place, you have to make sure
that any medication you send

00:06:15.480 --> 00:06:18.000
into the body doesn't
interact with too

00:06:18.000 --> 00:06:19.314
many of these receptors.

00:06:19.314 --> 00:06:20.730
And that's actually
very difficult

00:06:20.730 --> 00:06:23.271
because many of these receptors
are very similar in structure

00:06:23.271 --> 00:06:25.360
and bind to similar molecules.

00:06:25.360 --> 00:06:27.960
So for example, if you
take an Asthma medication,

00:06:27.960 --> 00:06:31.345
it will bind to one receptor
and it will relax your muscles.

00:06:31.345 --> 00:06:34.070
But at the same time, it will
bind to a very closely related

00:06:34.070 --> 00:06:37.440
second receptor, and it will
make your heart beat faster.

00:06:37.440 --> 00:06:39.690
So you have side-effects
that you want to avoid,

00:06:39.690 --> 00:06:42.106
so that's why we have to study
G-protein-coupled receptors

00:06:42.106 --> 00:06:45.260
in more detail and
understand how they work.

00:06:45.260 --> 00:06:46.429
So let's take a look at one.

00:06:46.429 --> 00:06:48.720
This is the system I've been
studying most of the time.

00:06:48.720 --> 00:06:51.680
This is [INAUDIBLE] receptor.

00:06:51.680 --> 00:06:53.817
And just for
comparison, you have

00:06:53.817 --> 00:06:55.400
something like this,
which is actually

00:06:55.400 --> 00:06:57.550
a relatively small protein.

00:06:57.550 --> 00:07:00.810
It's three amino acids,
just put together.

00:07:00.810 --> 00:07:05.260
Something like this has
about 340 amino acids.

00:07:05.260 --> 00:07:07.390
So it's a very different scale.

00:07:07.390 --> 00:07:09.750
But we can model
this on a computer.

00:07:09.750 --> 00:07:11.810
To get a system this
from a database,

00:07:11.810 --> 00:07:15.444
someone has taken the effort to
determine the structure using

00:07:15.444 --> 00:07:16.860
x-ray crystallography,
so you know

00:07:16.860 --> 00:07:18.694
pretty well where
all the atoms sit.

00:07:18.694 --> 00:07:19.860
And then we just model that.

00:07:19.860 --> 00:07:23.600
We take the 3D
coordinates, and then we

00:07:23.600 --> 00:07:26.570
add a patch of cell membrane,
because this receptor

00:07:26.570 --> 00:07:27.720
sits in the membrane.

00:07:27.720 --> 00:07:29.150
So if you want to
simulate it, you

00:07:29.150 --> 00:07:31.700
need to have the lipid
bilayer in there.

00:07:31.700 --> 00:07:34.404
The next step-- you
have to put in solvent,

00:07:34.404 --> 00:07:36.570
so it becomes closer and
closer to what you actually

00:07:36.570 --> 00:07:38.280
see in the cell.

00:07:38.280 --> 00:07:41.120
And then we add some
ions for good measure

00:07:41.120 --> 00:07:45.230
to make sure that the
electrostatics work correctly.

00:07:45.230 --> 00:07:47.340
And so now, you have
this protein in a box.

00:07:47.340 --> 00:07:51.570
And this is your simulation
system, ready to work.

00:07:51.570 --> 00:07:54.350
But to actually be able to
simulate this on the computer,

00:07:54.350 --> 00:07:56.720
you need to apply
the physics of it.

00:07:56.720 --> 00:07:58.630
So you need to describe
the system using

00:07:58.630 --> 00:07:59.784
a set of equations.

00:07:59.784 --> 00:08:01.950
And that's kind of what's
amazing about this system,

00:08:01.950 --> 00:08:06.250
because people have been able to
create a set of equations that

00:08:06.250 --> 00:08:08.560
describes all the
interactions between the atoms

00:08:08.560 --> 00:08:10.670
and approximate the behavior.

00:08:10.670 --> 00:08:13.560
And it fits on one
slide but still, it's

00:08:13.560 --> 00:08:16.560
extremely computationally
expansive.

00:08:16.560 --> 00:08:19.090
The one thing you see
here, the one equation,

00:08:19.090 --> 00:08:21.637
is Newton's Second
Law of Motion,

00:08:21.637 --> 00:08:23.720
and it's just saying if
you know the forces on all

00:08:23.720 --> 00:08:26.890
of the particles in the system
and if you know their masses,

00:08:26.890 --> 00:08:29.180
then we can calculate
the acceleration on them.

00:08:29.180 --> 00:08:32.080
And that's what we're using
when we drive our simulations.

00:08:32.080 --> 00:08:35.359
So here's an example--
an actual simulation one.

00:08:35.359 --> 00:08:37.150
You will now recognize
the different parts.

00:08:37.150 --> 00:08:38.025
You have the protein.

00:08:38.025 --> 00:08:39.299
You have some ions here.

00:08:39.299 --> 00:08:41.780
The solvent's not shown;
it would be too much.

00:08:41.780 --> 00:08:43.155
And you have the
liquid membrane.

00:08:43.155 --> 00:08:44.865
And so let's get this started.

00:08:50.530 --> 00:08:52.490
Oh, that's pretty bad.

00:08:52.490 --> 00:08:54.332
This is actually
what it would look

00:08:54.332 --> 00:08:56.370
like if you had
very low sampling

00:08:56.370 --> 00:09:00.120
and just save like
every couple of-- well,

00:09:00.120 --> 00:09:02.412
not really nanoseconds,
but just, let's say,

00:09:02.412 --> 00:09:03.872
every tenth frame.

00:09:03.872 --> 00:09:05.580
So really on my screen,
it's very liquid.

00:09:05.580 --> 00:09:05.680
It's very fluid.

00:09:05.680 --> 00:09:07.557
And you can see how
the membrane moves

00:09:07.557 --> 00:09:08.640
and how the protein moves.

00:09:08.640 --> 00:09:09.840
But I think you get
the impression--

00:09:09.840 --> 00:09:11.355
like how much it's
just moving there

00:09:11.355 --> 00:09:14.110
and how much is just happening
in a very short time span.

00:09:14.110 --> 00:09:17.150
Because, believe it or not,
this is three minute video

00:09:17.150 --> 00:09:19.890
and it's only 5 nanoseconds
of actual chemical time.

00:09:19.890 --> 00:09:21.880
So all of these
movements you see--

00:09:21.880 --> 00:09:23.366
they happen on a
nanosecond scale.

00:09:23.366 --> 00:09:25.490
And we have to simulate it
on the femtosecond scale

00:09:25.490 --> 00:09:27.483
to capture all these
tiny movements that

00:09:27.483 --> 00:09:28.470
are happening there.

00:09:28.470 --> 00:09:30.630
So you have that.

00:09:30.630 --> 00:09:33.065
You have to go from
the femtosecond scale

00:09:33.065 --> 00:09:34.805
to the nanosecond
scale, by just running

00:09:34.805 --> 00:09:36.350
the simulations for that long.

00:09:36.350 --> 00:09:38.390
At the same time, you
have all of these atoms.

00:09:38.390 --> 00:09:41.172
There's about 60,000
in this system.

00:09:41.172 --> 00:09:42.630
They all interacts
with one another

00:09:42.630 --> 00:09:44.660
through electrostatics
and van der Waals

00:09:44.660 --> 00:09:49.310
forces and long-range
forces-- which basically, it

00:09:49.310 --> 00:09:53.160
interferes with the
movement of all these atoms.

00:09:53.160 --> 00:10:01.230
OK, so creating this movie took
about 10 days on a single CPU.

00:10:01.230 --> 00:10:03.200
So there you have three
different time scales.

00:10:03.200 --> 00:10:04.616
But basically what
it tells you is

00:10:04.616 --> 00:10:07.470
that getting to the nanoseconds
takes days on a single CPU.

00:10:07.470 --> 00:10:09.303
And it doesn't actually
show your that much.

00:10:09.303 --> 00:10:11.750
In a nanosecond, what
you see is pretty much

00:10:11.750 --> 00:10:14.220
only that one of these
little side-chains

00:10:14.220 --> 00:10:18.219
here-- that may be in a flipped
position-- something like this.

00:10:18.219 --> 00:10:19.760
So that's not really
telling you that

00:10:19.760 --> 00:10:23.280
much about the activity of the
protein and what it can do.

00:10:23.280 --> 00:10:25.416
So we have to run for
even longer time scales.

00:10:25.416 --> 00:10:26.790
So what I want to
show this slide

00:10:26.790 --> 00:10:29.250
is basically just the difference
between the different time

00:10:29.250 --> 00:10:30.000
scales.

00:10:30.000 --> 00:10:32.440
So again, for nanoseconds,
you might see a flip

00:10:32.440 --> 00:10:34.297
in one of these
little side-chains.

00:10:34.297 --> 00:10:36.130
And that might actually
be relevant already,

00:10:36.130 --> 00:10:37.870
because it might mean
that some hydrogen

00:10:37.870 --> 00:10:39.550
bond result which is formed.

00:10:39.550 --> 00:10:42.050
And that might be the first
step of this protein doing

00:10:42.050 --> 00:10:42.550
something.

00:10:42.550 --> 00:10:43.940
So I told you it's
like a switch.

00:10:43.940 --> 00:10:46.000
So basically, you want
to see does it switch on,

00:10:46.000 --> 00:10:48.390
and how does it work.

00:10:48.390 --> 00:10:50.840
But the switch would be the
whole protein doing something

00:10:50.840 --> 00:10:52.040
not just one of the side-chains.

00:10:52.040 --> 00:10:53.520
So we're definitely
looking for that.

00:10:53.520 --> 00:10:54.590
We need to have that
kind of resolution.

00:10:54.590 --> 00:10:56.423
We need to understand
how everything happens

00:10:56.423 --> 00:10:59.500
step-by-step, but it's not
the most interesting part.

00:10:59.500 --> 00:11:02.700
If you go to
microsecond simulations,

00:11:02.700 --> 00:11:04.170
you're getting to
something where

00:11:04.170 --> 00:11:06.710
you can see ligand
binding to it.

00:11:06.710 --> 00:11:08.960
So it's a small molecule
coming from the outside, that

00:11:08.960 --> 00:11:11.376
will be the top outside of the
cell binding to the protein

00:11:11.376 --> 00:11:14.740
into the receptor,
and then it activates.

00:11:14.740 --> 00:11:17.342
So that happens on the
microsecond time scale.

00:11:17.342 --> 00:11:18.800
But microsecond's
already something

00:11:18.800 --> 00:11:20.580
where you need a lot
of processing power.

00:11:20.580 --> 00:11:23.750
You can do nanoseconds
on your own computer.

00:11:23.750 --> 00:11:26.590
But for microseconds, you're
actually already pushing

00:11:26.590 --> 00:11:30.681
the boundaries of what's
available to most people today.

00:11:30.681 --> 00:11:32.180
But we want to go
further than that.

00:11:32.180 --> 00:11:33.450
We want to really be there.

00:11:33.450 --> 00:11:37.110
You want to be somewhere in
the milliseconds time scale

00:11:37.110 --> 00:11:39.800
because that's when really
the bigger things happen.

00:11:39.800 --> 00:11:42.990
That's when the whole receptor
has time to change shape

00:11:42.990 --> 00:11:43.604
and activate.

00:11:43.604 --> 00:11:45.020
Because all we
want to see is what

00:11:45.020 --> 00:11:47.520
happens if something binds on
the extracellular side, what

00:11:47.520 --> 00:11:49.010
happens on the
intercellular side.

00:11:49.010 --> 00:11:50.840
Does it change shape as well?

00:11:50.840 --> 00:11:53.880
And how does bind other proteins
and what happens exactly?

00:11:53.880 --> 00:11:59.500
So to get there are,
basically, what's

00:11:59.500 --> 00:12:01.125
you have available
in academia nowadays

00:12:01.125 --> 00:12:02.499
is you have your
own workstation.

00:12:02.499 --> 00:12:04.030
You can run these
short simulations.

00:12:04.030 --> 00:12:05.540
You normally have
pooled resources,

00:12:05.540 --> 00:12:10.530
like a group cluster which
has a number of 100 cores,

00:12:10.530 --> 00:12:11.450
but it's shared.

00:12:11.450 --> 00:12:13.790
You have to compete with
other group members.

00:12:13.790 --> 00:12:16.980
And then you might have
departmental, university-wide,

00:12:16.980 --> 00:12:19.450
or national computer
centers, which give you

00:12:19.450 --> 00:12:22.060
maybe a few hundred
more CPU cores.

00:12:22.060 --> 00:12:24.560
But all of these have in common
that you have to share them,

00:12:24.560 --> 00:12:27.540
so it's pretty unlikely that
you get several thousand cores,

00:12:27.540 --> 00:12:33.240
which you might need for running
long-time scale simulations.

00:12:33.240 --> 00:12:36.470
So there needs to be
some other solution.

00:12:36.470 --> 00:12:38.580
But the way it was done
so far is that basically,

00:12:38.580 --> 00:12:41.760
you take this protein-in-a-box
and you subdivide it--

00:12:41.760 --> 00:12:44.650
just split it up according
to all three dimensions.

00:12:44.650 --> 00:12:47.210
And so if you have eight
cores, you just split it,

00:12:47.210 --> 00:12:50.060
and you give each core one part
of the protein to simulate.

00:12:50.060 --> 00:12:51.830
But then, you start
having problems

00:12:51.830 --> 00:12:55.976
because you have to transfer the
forces across these boundaries.

00:12:55.976 --> 00:12:57.350
So one of these
boxes has to know

00:12:57.350 --> 00:13:00.070
what happens in the other
box, because otherwise

00:13:00.070 --> 00:13:01.927
all your simulations
will go wrong.

00:13:01.927 --> 00:13:03.510
But that's what
people have been doing

00:13:03.510 --> 00:13:05.930
to speed up the processing.

00:13:05.930 --> 00:13:09.060
And you can keep doing that--
adding more and more cores

00:13:09.060 --> 00:13:11.220
and more and more subdivisions.

00:13:11.220 --> 00:13:14.080
But since these
individual parts are

00:13:14.080 --> 00:13:15.730
growing smaller and
smaller, you end up

00:13:15.730 --> 00:13:18.760
having very little to simulate
on each individual core.

00:13:18.760 --> 00:13:22.050
So you're spending more and more
time just transferring data.

00:13:22.050 --> 00:13:24.360
And so like in many
supercomputing applications,

00:13:24.360 --> 00:13:27.980
what you get is
imperfect scaling.

00:13:27.980 --> 00:13:29.910
What you want to have
is this ideal scaling

00:13:29.910 --> 00:13:31.750
where you double the
number of processors

00:13:31.750 --> 00:13:35.570
and you double the output,
basically-- the efficiency.

00:13:35.570 --> 00:13:38.100
But what you see here is--
what the reality of it is

00:13:38.100 --> 00:13:41.820
is that you just add the number
of cores, but you lose a lot.

00:13:41.820 --> 00:13:44.860
So after about 100 cores,
you're already down

00:13:44.860 --> 00:13:48.110
to 50% of the total efficiency
that you could have.

00:13:48.110 --> 00:13:50.280
And then it just
keeps flattening out.

00:13:50.280 --> 00:13:54.170
So even if you had thousands
of cores available,

00:13:54.170 --> 00:13:56.970
using this mechanism, it's
probably not very much

00:13:56.970 --> 00:13:59.820
faster than having 200 cores
or something like this.

00:13:59.820 --> 00:14:01.190
So this is not the way forward.

00:14:01.190 --> 00:14:02.690
Eventually what we
have to do is run

00:14:02.690 --> 00:14:05.460
several simulations in
parallel, and that way,

00:14:05.460 --> 00:14:08.647
recover some of the
lost efficiency.

00:14:08.647 --> 00:14:11.220
OK, so that's the other idea.

00:14:11.220 --> 00:14:13.590
You just have a lot of copies.

00:14:13.590 --> 00:14:16.620
And in the extreme case, you
just have one copy per core.

00:14:16.620 --> 00:14:19.110
And now, you actually
have perfect scaling

00:14:19.110 --> 00:14:21.200
because you just double
the number of cores,

00:14:21.200 --> 00:14:24.259
and you get twice
the throughput.

00:14:24.259 --> 00:14:26.550
It seems kind of silly to do
that because why would you

00:14:26.550 --> 00:14:29.250
simulate the same
system over and again?

00:14:29.250 --> 00:14:33.710
The difference is that you
introduce a random number,

00:14:33.710 --> 00:14:35.350
and you change the
starting condition

00:14:35.350 --> 00:14:39.520
so that each atom actually gets
a different velocity initially.

00:14:39.520 --> 00:14:41.830
And so that drives
the system basically

00:14:41.830 --> 00:14:44.020
into different directions
that evolve independently

00:14:44.020 --> 00:14:45.640
for each of these simulations.

00:14:45.640 --> 00:14:47.620
And so you spread it
out and use the sampling

00:14:47.620 --> 00:14:52.420
over the available phase
space for your proteins.

00:14:52.420 --> 00:14:54.865
And this is the idea
that has been followed

00:14:54.865 --> 00:14:56.990
for more than 10 years by
Vijay Pande and his group

00:14:56.990 --> 00:14:58.530
at Stanford.

00:14:58.530 --> 00:15:00.290
So they have basically
had this system,

00:15:00.290 --> 00:15:02.640
which is very similar
to SITI@home-- if you've

00:15:02.640 --> 00:15:04.810
heard about that--
where basically,

00:15:04.810 --> 00:15:06.810
people just download
a client program.

00:15:06.810 --> 00:15:09.945
And while their system is idle,
they just run the screen-saver

00:15:09.945 --> 00:15:15.992
and it computes work units
that it gets from Stanford.

00:15:15.992 --> 00:15:17.450
And it does it for
a number of days

00:15:17.450 --> 00:15:18.616
and then returns the result.

00:15:18.616 --> 00:15:21.890
And then Standford goes about
and analyzes the results.

00:15:21.890 --> 00:15:26.362
So there's something like
250,000 CPUs at any given time.

00:15:26.362 --> 00:15:27.820
There's a problem
with this though,

00:15:27.820 --> 00:15:29.420
because since these
are individuals,

00:15:29.420 --> 00:15:33.190
these are people like you and me
just using their home computer,

00:15:33.190 --> 00:15:35.359
they might decide to just
switch off their machine,

00:15:35.359 --> 00:15:37.150
and maybe never switch
it on again or maybe

00:15:37.150 --> 00:15:38.983
just not use the
screen-saver again anymore.

00:15:38.983 --> 00:15:43.277
So you have sent out your work
unit, and it never comes back.

00:15:43.277 --> 00:15:44.610
So you have to be aware of that.

00:15:44.610 --> 00:15:46.866
So sometimes it takes
awhile until you

00:15:46.866 --> 00:15:49.660
have sent out your work again
and have collected all of it.

00:15:52.180 --> 00:15:53.902
It's also a shared
resource, but we

00:15:53.902 --> 00:15:55.610
were able to actually
use this initially,

00:15:55.610 --> 00:15:56.830
when I was still at Stanford.

00:15:56.830 --> 00:16:03.296
And I did 10,000 simulations of
the protein that I showed you.

00:16:03.296 --> 00:16:04.670
And so that was
a good start just

00:16:04.670 --> 00:16:09.210
to show that the system was
actually stable and working.

00:16:09.210 --> 00:16:12.250
But now when I heard from
Dave what he was doing

00:16:12.250 --> 00:16:13.670
and what the scale
was, there was,

00:16:13.670 --> 00:16:15.295
of course, a very
different beast.

00:16:15.295 --> 00:16:17.150
Because Exacycle is
not just able to have

00:16:17.150 --> 00:16:21.060
hundreds of thousands of cores,
but in excess of a million

00:16:21.060 --> 00:16:23.570
cores working on your protein.

00:16:23.570 --> 00:16:26.870
So now you can have your
parallel simulations,

00:16:26.870 --> 00:16:29.950
and just have 10,000
jobs or 100,000 jobs

00:16:29.950 --> 00:16:31.540
running at the same time.

00:16:31.540 --> 00:16:33.771
It's a really good throughput.

00:16:33.771 --> 00:16:36.020
So it's basically an enormous
batch processing system.

00:16:36.020 --> 00:16:37.820
You just submit your work.

00:16:37.820 --> 00:16:40.030
You eventually get it back.

00:16:40.030 --> 00:16:42.810
Exacycle just goes out there
and finds the cycles for you.

00:16:42.810 --> 00:16:45.130
You don't have to
take care of that.

00:16:45.130 --> 00:16:48.050
And it was also part of
the grant program, which

00:16:48.050 --> 00:16:50.040
gave away one billion CPU hours.

00:16:50.040 --> 00:16:52.050
So that Google actually
showed that, you know,

00:16:52.050 --> 00:16:55.330
just take all this compute
power that we have and just do

00:16:55.330 --> 00:17:00.460
something good with it and
create some valuable science.

00:17:00.460 --> 00:17:03.824
So we had a chance to work on
about 100,000 cores for about

00:17:03.824 --> 00:17:06.240
half a year-- that's about the
years equivalent that we've

00:17:06.240 --> 00:17:07.300
got.

00:17:07.300 --> 00:17:10.970
So doing that, the
millions of CPU hours

00:17:10.970 --> 00:17:14.189
obviously gave us a lot of data.

00:17:14.189 --> 00:17:15.730
And that allowed us
to do something--

00:17:15.730 --> 00:17:17.390
what you see on the
right-hand side.

00:17:17.390 --> 00:17:19.310
So you start-- from the
starting confirmation.

00:17:19.310 --> 00:17:20.934
Let's say that's A.
Let's say that it's

00:17:20.934 --> 00:17:23.940
the off confirmation for
this switch that you have,

00:17:23.940 --> 00:17:25.394
and then you just
start sampling.

00:17:25.394 --> 00:17:26.732
You just spread out your work.

00:17:26.732 --> 00:17:28.940
And then after a while, you
just collect all the data

00:17:28.940 --> 00:17:29.860
and you look at it.

00:17:29.860 --> 00:17:33.550
And you see like, OK, so which
of my trajectories, which

00:17:33.550 --> 00:17:37.180
of my runs have actually
proceeded the furthest?

00:17:37.180 --> 00:17:39.420
And where did I do
all the sampling?

00:17:39.420 --> 00:17:42.115
The areas I've sampled
a lot-- I don't

00:17:42.115 --> 00:17:43.240
have to sample any further.

00:17:43.240 --> 00:17:44.840
So I'm just picking
some structures

00:17:44.840 --> 00:17:47.180
for the next simulation run.

00:17:47.180 --> 00:17:49.100
And I kind of keep
spreading out like this.

00:17:49.100 --> 00:17:53.210
And so eventually, I would get
to state B using this process.

00:17:53.210 --> 00:17:55.850
The other extreme is if we use
really specialized hardware

00:17:55.850 --> 00:17:57.980
like on the left-hand side
where you have the Anton

00:17:57.980 --> 00:18:00.190
supercomputer, which was
specifically built just

00:18:00.190 --> 00:18:02.760
to run molecular
dynamics simulations.

00:18:02.760 --> 00:18:04.260
But there you have
a number of cores

00:18:04.260 --> 00:18:05.890
that work on the same protein.

00:18:05.890 --> 00:18:07.848
And eventually, you have
a problem with scaling

00:18:07.848 --> 00:18:11.650
where you can't have smaller
and smaller subdivisions.

00:18:11.650 --> 00:18:14.300
But this is a way that you can
create a very long trajectory.

00:18:14.300 --> 00:18:17.670
And the advantage is that
once you get from state A

00:18:17.670 --> 00:18:20.850
to state B, you can go back and
replay this movie essentially

00:18:20.850 --> 00:18:22.502
and just see what happens.

00:18:22.502 --> 00:18:23.960
What are the dynamics
taking place?

00:18:23.960 --> 00:18:25.793
What are the structural
changes taking place

00:18:25.793 --> 00:18:29.190
to get the protein
from one to the other?

00:18:29.190 --> 00:18:30.920
OK, so that makes it easier.

00:18:30.920 --> 00:18:32.450
We have a lot of data now.

00:18:32.450 --> 00:18:34.520
And actually coming
to Google, suddenly I

00:18:34.520 --> 00:18:38.360
had like two orders of magnitude
more data to work with.

00:18:38.360 --> 00:18:39.750
So that's a bit of a challenge.

00:18:39.750 --> 00:18:41.640
So what you do with that?

00:18:41.640 --> 00:18:43.640
The answer is, of course,
go back to the cloud

00:18:43.640 --> 00:18:45.000
and do the analysis there.

00:18:45.000 --> 00:18:49.420
So we used something called
Markov state models that

00:18:49.420 --> 00:18:52.180
was also developed
at Standford mainly.

00:18:52.180 --> 00:18:54.565
And it basically takes all
these individual trajectories

00:18:54.565 --> 00:18:56.190
and it clusters
them together so you

00:18:56.190 --> 00:18:58.510
have a number of
different states.

00:18:58.510 --> 00:19:00.690
But because these small
trajectories actually

00:19:00.690 --> 00:19:03.960
sometimes migrate from
one state to another one,

00:19:03.960 --> 00:19:05.620
you have these
transitions as well.

00:19:05.620 --> 00:19:08.080
You get a probability
of how likely

00:19:08.080 --> 00:19:11.580
it is that a protein that starts
here goes to this other state,

00:19:11.580 --> 00:19:13.620
and then in comparison
to whatever other paths

00:19:13.620 --> 00:19:14.614
it can take.

00:19:14.614 --> 00:19:17.280
So like this example shows there
might be several different ways

00:19:17.280 --> 00:19:19.607
that you go from A to
B. And actually, you

00:19:19.607 --> 00:19:20.940
might go back sometimes as well.

00:19:20.940 --> 00:19:22.935
So actually, these arrows
should go both ways.

00:19:22.935 --> 00:19:25.060
But that tells us something
about what's happening.

00:19:25.060 --> 00:19:28.430
And in our case, analyzing
all the data that we had

00:19:28.430 --> 00:19:31.520
showed us that you have
a number of pathways

00:19:31.520 --> 00:19:33.760
that go from the inactive
state of the receptor

00:19:33.760 --> 00:19:35.890
to the active state.

00:19:35.890 --> 00:19:38.460
And that's actually something
that we didn't anticipate

00:19:38.460 --> 00:19:40.630
and something we weren't
sure we could actually see.

00:19:40.630 --> 00:19:42.505
So we basically just
let the simulations run,

00:19:42.505 --> 00:19:44.510
and we were just
letting ourselves

00:19:44.510 --> 00:19:45.700
be surprised by the outcome.

00:19:45.700 --> 00:19:47.880
There wasn't really
a clear plan how far

00:19:47.880 --> 00:19:50.140
we might be able
to get with this.

00:19:50.140 --> 00:19:52.013
But it was amazing
to see how far this

00:19:52.013 --> 00:19:56.950
lead us using all the
compute power that we had.

00:19:56.950 --> 00:19:59.150
OK, so now when you
have the pathways,

00:19:59.150 --> 00:20:01.310
here's one thing you
can do with that.

00:20:01.310 --> 00:20:03.580
So you know the protein
goes in different ways.

00:20:03.580 --> 00:20:07.670
Now you can see like, OK, what
happens with these molecules--

00:20:07.670 --> 00:20:09.290
the beta blockers
and things like that

00:20:09.290 --> 00:20:13.629
that bind to your receptor
that inactivate it.

00:20:13.629 --> 00:20:15.420
And so you have two
different examples here

00:20:15.420 --> 00:20:22.690
where basically you just do some
talking between the molecules

00:20:22.690 --> 00:20:25.590
shown here and the
big protein and just

00:20:25.590 --> 00:20:30.340
see along this pathway going
from the inactive state

00:20:30.340 --> 00:20:32.400
on the left to the active
state on the right--

00:20:32.400 --> 00:20:35.860
so basically the percentage of
progress along that trajectory.

00:20:35.860 --> 00:20:37.850
Where does this bind?

00:20:37.850 --> 00:20:41.170
And the interesting result
is that, for example,

00:20:41.170 --> 00:20:43.936
the one on the top, which
activates the protein,

00:20:43.936 --> 00:20:45.310
it doesn't bind
in the beginning.

00:20:45.310 --> 00:20:47.620
It doesn't bind in
the inactive state.

00:20:47.620 --> 00:20:51.290
You actually have to process
along the activation pathway

00:20:51.290 --> 00:20:53.834
for awhile before it
actually starts binding.

00:20:53.834 --> 00:20:55.500
So that's interesting
because if all you

00:20:55.500 --> 00:20:56.940
have is the inactive
state and you

00:20:56.940 --> 00:20:59.470
think you want to develop
a dark molecule for it,

00:20:59.470 --> 00:21:02.760
maybe the most efficient
dark molecule doesn't bind.

00:21:02.760 --> 00:21:04.870
Maybe because the protein
in it is fluctuating

00:21:04.870 --> 00:21:06.699
between inactive and
active to some degree,

00:21:06.699 --> 00:21:09.240
you need to have something that
just goes to the active state

00:21:09.240 --> 00:21:11.500
and then stabilizes it.

00:21:11.500 --> 00:21:14.000
And the other extreme
is the second example,

00:21:14.000 --> 00:21:16.440
which is actually
inactivating the receptor.

00:21:16.440 --> 00:21:18.814
And similarly, it mainly
binds to the inactive state

00:21:18.814 --> 00:21:20.230
and it's not really
on the protein

00:21:20.230 --> 00:21:25.780
the whole duration of a change
from active to inactive.

00:21:25.780 --> 00:21:27.190
So you can take
this into account

00:21:27.190 --> 00:21:29.677
when you start developing
dark molecules.

00:21:29.677 --> 00:21:31.510
And there's a lot more
information in there.

00:21:31.510 --> 00:21:32.410
We've actually
written this up, and I

00:21:32.410 --> 00:21:34.909
think there's more than 40 pages
in supplemental information

00:21:34.909 --> 00:21:37.340
in the paper that's
coming out, just

00:21:37.340 --> 00:21:40.690
doing this kind of analysis.

00:21:40.690 --> 00:21:43.980
OK, and just to summarize
the results-- so

00:21:43.980 --> 00:21:47.590
what we've shown really is that
you can use cloud computing

00:21:47.590 --> 00:21:49.590
to do these kind of simulations.

00:21:49.590 --> 00:21:52.330
And it's kind of the way
that you think about it.

00:21:52.330 --> 00:21:55.390
Basically, what people start
out with is they just learn,

00:21:55.390 --> 00:21:57.220
OK, we just throw more
and more CPUs at it

00:21:57.220 --> 00:21:59.320
and we just
subdivide it further.

00:21:59.320 --> 00:22:03.080
But people are not really
aware that some applications,

00:22:03.080 --> 00:22:05.610
if you find the right algorithms
and the right approach,

00:22:05.610 --> 00:22:09.164
you can actually go to the cloud
and be at least as efficient.

00:22:09.164 --> 00:22:11.580
And in our case, we actually
have created the largest data

00:22:11.580 --> 00:22:14.470
set for G-protein-coupled
receptors.

00:22:14.470 --> 00:22:17.090
And that was only possible
because of the last scale

00:22:17.090 --> 00:22:19.190
that Exacycle enabled us to use.

00:22:19.190 --> 00:22:21.030
This shows that
the cloud is there.

00:22:21.030 --> 00:22:23.440
The cloud is
something we can use

00:22:23.440 --> 00:22:25.744
as a useful tool that
allows us to scale.

00:22:25.744 --> 00:22:27.660
It allows us to have
capacity when we need it,

00:22:27.660 --> 00:22:29.826
and not have to wait for
the couple of hundred cores

00:22:29.826 --> 00:22:31.940
that I want to run for
the next three weeks just

00:22:31.940 --> 00:22:35.090
to see whether or not
my experiment works.

00:22:35.090 --> 00:22:37.260
The other advantage
is that I was actually

00:22:37.260 --> 00:22:40.370
given a lot of time at
Stanford to start researching

00:22:40.370 --> 00:22:42.220
G-protein-coupled
receptors, and that's

00:22:42.220 --> 00:22:44.640
something you might not
necessarily have at a company.

00:22:44.640 --> 00:22:47.780
So in this way, by just
working with scientists

00:22:47.780 --> 00:22:52.160
from university, you get kind
of the best of both worlds

00:22:52.160 --> 00:22:55.280
where you can do the fundamental
research at the university,

00:22:55.280 --> 00:22:57.400
but then take it to
scale and basically

00:22:57.400 --> 00:22:59.180
throw all this
compute power at it

00:22:59.180 --> 00:23:02.570
and get somewhere
very, very quickly.

00:23:02.570 --> 00:23:06.034
The third thing is that
hopefully, in the future,

00:23:06.034 --> 00:23:07.950
scientists don't really
have to bother so much

00:23:07.950 --> 00:23:09.320
with setting up their
own servers anymore

00:23:09.320 --> 00:23:11.970
and the technical aspects of it,
but just basically send it off

00:23:11.970 --> 00:23:13.803
to the cloud, someone
else takes care of it,

00:23:13.803 --> 00:23:16.850
and you just focus
on your science.

00:23:16.850 --> 00:23:19.270
It's surprising
that a lot of people

00:23:19.270 --> 00:23:22.660
don't really know that Google
is doing research in any field.

00:23:22.660 --> 00:23:25.320
I keep getting that feedback.

00:23:25.320 --> 00:23:28.302
But that Google is doing
something in biology

00:23:28.302 --> 00:23:30.010
is what really surprises
a lot of people.

00:23:30.010 --> 00:23:32.260
And I think this way, we can
also create the awareness

00:23:32.260 --> 00:23:34.330
that not only is Google
doing some research,

00:23:34.330 --> 00:23:37.220
you can also go as a
scientist and use Google

00:23:37.220 --> 00:23:38.910
for doing your research.

00:23:38.910 --> 00:23:41.055
And then hopefully, as a
big vision in the future,

00:23:41.055 --> 00:23:42.340
you have everything
in the cloud.

00:23:42.340 --> 00:23:43.310
You have the data in the cloud.

00:23:43.310 --> 00:23:44.780
You have the analysis
in the cloud.

00:23:44.780 --> 00:23:49.120
So you start having this
kind of continuous progress

00:23:49.120 --> 00:23:51.695
where people can go and
continue working their data

00:23:51.695 --> 00:23:53.890
and reproduce the results.

00:23:53.890 --> 00:23:57.860
And then they just do their
own analysis on top of it.

00:23:57.860 --> 00:24:00.200
And so basically, you
have shared resources.

00:24:00.200 --> 00:24:03.340
You don't have to have this
silo building that everyone

00:24:03.340 --> 00:24:05.150
does their own things
and doesn't share.

00:24:05.150 --> 00:24:07.066
But you can really
collaboratively go about it

00:24:07.066 --> 00:24:11.010
and have continuous
conversations

00:24:11.010 --> 00:24:13.392
about this research.

00:24:13.392 --> 00:24:14.850
And this is probably
the slide that

00:24:14.850 --> 00:24:18.480
makes me personally the proudest
because after almost five years

00:24:18.480 --> 00:24:21.870
of research, we have been able
to now get a paper accepted

00:24:21.870 --> 00:24:24.190
in "Nature Chemistry"
summarizing all the results,

00:24:24.190 --> 00:24:26.580
working on Exacycle
and the hard work done

00:24:26.580 --> 00:24:30.040
at Stanford with our
collaborators here.

00:24:30.040 --> 00:24:32.080
And so I'm actually showing
the different people

00:24:32.080 --> 00:24:34.580
involved at Google
and at Stanford.

00:24:34.580 --> 00:24:36.410
And the cover page
here that will

00:24:36.410 --> 00:24:39.190
be the cover page of the "Nature
Chemistry" issue in January

00:24:39.190 --> 00:24:42.410
coming out next week
and it was created

00:24:42.410 --> 00:24:47.971
by one of our colleagues in the
[INAUDIBLE] group, [INAUDIBLE].

00:24:47.971 --> 00:24:50.095
And so he helped us to
actually get us on the cover

00:24:50.095 --> 00:24:51.560
and be featured there as well.

00:24:51.560 --> 00:24:53.500
And so, yeah.

00:24:53.500 --> 00:24:56.690
So that actually
answered and just shows

00:24:56.690 --> 00:24:59.870
that we've had impact
with this program.

00:24:59.870 --> 00:25:00.624
OK, thanks a lot.

00:25:00.624 --> 00:25:02.540
Actually, I think David
wants to say something

00:25:02.540 --> 00:25:05.500
before we have questions.

00:25:05.500 --> 00:25:07.250
DAVID KONERDING: Thank
you very much, Kai.

00:25:07.250 --> 00:25:08.530
That was very exciting.

00:25:08.530 --> 00:25:11.020
It's really thrilling to
see after a number of years

00:25:11.020 --> 00:25:14.020
of hard work that the
science has paid off

00:25:14.020 --> 00:25:16.160
and that our ideas
are making it out

00:25:16.160 --> 00:25:19.786
into the academic community,
and we hope we have an impact.

00:25:19.786 --> 00:25:21.160
And further, what
I'd like to say

00:25:21.160 --> 00:25:24.120
is that Google has,
over the past few years,

00:25:24.120 --> 00:25:26.140
started to enter
the cloud business.

00:25:26.140 --> 00:25:29.760
And my feeling is, after seeing
this project work successfully,

00:25:29.760 --> 00:25:32.920
that I think our cloud
is ready for science.

00:25:32.920 --> 00:25:35.030
And I think as a
scientist, it's really

00:25:35.030 --> 00:25:38.240
in your interest to understand
how to use our systems

00:25:38.240 --> 00:25:39.680
and take advantage of them.

00:25:39.680 --> 00:25:42.161
Because in the future,
access to enormous amounts

00:25:42.161 --> 00:25:43.660
of computing power
are going to make

00:25:43.660 --> 00:25:45.990
the difference between
successful scientists

00:25:45.990 --> 00:25:47.280
and unsuccessful ones.

00:25:47.280 --> 00:25:50.570
So if you start looking at what
we're doing and read our papers

00:25:50.570 --> 00:25:53.180
and figure out the
techniques that we're using

00:25:53.180 --> 00:25:55.400
and look at open source
projects like Hadoop,

00:25:55.400 --> 00:25:58.482
you should start adopting
the idea that were promoting

00:25:58.482 --> 00:26:00.190
and that the Hadoop
people are promoting.

00:26:00.190 --> 00:26:01.770
There's a lot of
really great ideas

00:26:01.770 --> 00:26:04.010
there that help
scientists focus more

00:26:04.010 --> 00:26:06.092
on the interesting
questions they have.

00:26:06.092 --> 00:26:07.800
And that's really what
science is about--

00:26:07.800 --> 00:26:10.800
is attempting to answer
questions, less so

00:26:10.800 --> 00:26:12.990
the actual engineering
of how bytes move around

00:26:12.990 --> 00:26:13.740
between computers.

00:26:13.740 --> 00:26:18.073
[APPLAUSE]

