WEBVTT
Kind: captions
Language: en

00:00:00.140 --> 00:00:02.469
So what, what are the most important dos and don'ts

00:00:02.469 --> 00:00:05.900
to keep in mind in data science? I think I

00:00:05.900 --> 00:00:09.530
would mention two. One is a bit more, qualitative and

00:00:09.530 --> 00:00:12.750
one is a, a bit more, quantitative. So, on the

00:00:12.750 --> 00:00:15.250
qualitative side I, I would say the first thing is

00:00:15.250 --> 00:00:19.420
any problem you're looking at, it's always very valuable, I

00:00:19.420 --> 00:00:22.950
find, to start by thinking about. What sort of things

00:00:22.950 --> 00:00:25.780
do we know? What sort of expectations do we have?

00:00:25.780 --> 00:00:28.300
And what sort of qualitative things can we get from,

00:00:28.300 --> 00:00:31.310
an exploratory analysis of the data? So, as I mentioned,

00:00:31.310 --> 00:00:34.580
using things like k-means clustering and PCA are a good

00:00:34.580 --> 00:00:37.660
way to start to do some sort of dimentionality reduction.

00:00:37.660 --> 00:00:39.930
Some way of getting the data down to a point

00:00:39.930 --> 00:00:42.880
where you can. Look and get some qualitative insights. Understand

00:00:42.880 --> 00:00:46.610
the general structure of it. And quite often in, in

00:00:46.610 --> 00:00:50.680
certain topics that we work on, you have some intuition of,

00:00:50.680 --> 00:00:51.970
of what you'd expect things to look like.

00:00:51.970 --> 00:00:54.410
You can start to see patterns, emerging data that,

00:00:55.500 --> 00:00:58.780
you know, that makes sense. That, that. Either confirm

00:00:58.780 --> 00:01:02.710
or, or possibly go against other theories or ingrained

00:01:02.710 --> 00:01:05.540
beliefs that people have. so, so I think getting

00:01:05.540 --> 00:01:07.730
data down to that point is very important. The

00:01:07.730 --> 00:01:12.410
more quantitative suggestion I would have, has to do

00:01:12.410 --> 00:01:15.710
with trying to understand causal connections. So, this is

00:01:15.710 --> 00:01:18.460
a very common thing that comes up. In building predictive models you

00:01:18.460 --> 00:01:21.460
may have a number of features. That you put into a model to

00:01:21.460 --> 00:01:25.210
predict some outcome. And it's very, very important when doing that. So, often

00:01:25.210 --> 00:01:27.980
the question comes out not just being able to predict an outcome. But

00:01:27.980 --> 00:01:32.520
understanding which features are actually causing it. It's important to use a

00:01:32.520 --> 00:01:35.600
lot of caution around that. To never just sort of, dump a bunch

00:01:35.600 --> 00:01:38.630
of data into a model with lots of features, and then just naively

00:01:38.630 --> 00:01:40.870
look at the thins that have the strongest weights in your model and

00:01:40.870 --> 00:01:43.930
say, oh. Here's what's driving it. So, it's very important when you're

00:01:43.930 --> 00:01:46.140
asking those kinds of causal questions

00:01:46.140 --> 00:01:48.430
to proceed very carefully and, and rigorously.

