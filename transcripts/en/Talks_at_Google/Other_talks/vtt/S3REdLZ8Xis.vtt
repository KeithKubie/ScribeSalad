WEBVTT
Kind: captions
Language: en

00:00:01.251 --> 00:00:02.690
MALE SPEAKER: Thanks for
coming, everybody.

00:00:02.690 --> 00:00:05.490
Nicholas Nassim Taleb has
devoted his life to problems

00:00:05.490 --> 00:00:08.210
of uncertainty, probability,
and knowledge.

00:00:08.210 --> 00:00:10.860
He spent two decades as a
trader before becoming a

00:00:10.860 --> 00:00:14.070
philosophical essayist and
academic researcher.

00:00:14.070 --> 00:00:16.200
Although he now spends most of
the time either working in

00:00:16.200 --> 00:00:19.360
intense seclusion in his
study or as a flaneur--

00:00:19.360 --> 00:00:20.910
I love that word--

00:00:20.910 --> 00:00:23.880
meditating in cafes across the
planet, he is currently

00:00:23.880 --> 00:00:26.200
distinguished professor of risk
engineering at New York

00:00:26.200 --> 00:00:28.640
University's Polytechnic
Institute.

00:00:28.640 --> 00:00:30.260
His main subject matter
is decision

00:00:30.260 --> 00:00:32.369
making under opacity--

00:00:32.369 --> 00:00:35.210
that is, a map and a protocol
on how we should live in a

00:00:35.210 --> 00:00:37.730
world we don't understand.

00:00:37.730 --> 00:00:42.740
We'll be selling books after
the talk and Mr. Taleb will

00:00:42.740 --> 00:00:44.110
sign them for you.

00:00:44.110 --> 00:00:46.300
He is going to pause for
questions occasionally during

00:00:46.300 --> 00:00:49.136
the talk as well as after, but
please go to the mic if you

00:00:49.136 --> 00:00:51.890
want to ask a question.

00:00:51.890 --> 00:00:53.610
Please welcome Nicholas
Nassim Taleb.

00:00:59.955 --> 00:01:01.800
NASSIM NICHOLAS TALEB: Thank
you for inviting me.

00:01:01.800 --> 00:01:08.790
So this is actually the first
time I speak at a place

00:01:08.790 --> 00:01:11.310
knowing what it's about, because
I've watched your

00:01:11.310 --> 00:01:13.050
Google talks on YouTube.

00:01:16.890 --> 00:01:18.640
They're quite interesting
because they're long--

00:01:18.640 --> 00:01:21.230
no, they're one hour, which
means we have an hour and 10

00:01:21.230 --> 00:01:24.270
minutes, because there's
always a bonus that the

00:01:24.270 --> 00:01:26.930
speaker he likes to
give himself.

00:01:26.930 --> 00:01:28.180
So thanks for inviting me.

00:01:31.490 --> 00:01:37.130
An author should not give you
a substitute for his book.

00:01:37.130 --> 00:01:39.330
A book is a different
product--

00:01:39.330 --> 00:01:40.680
it's not a talk.

00:01:40.680 --> 00:01:42.390
So in other words, it's not
something that I can

00:01:42.390 --> 00:01:42.880
substitute.

00:01:42.880 --> 00:01:45.180
So what I'm going to
do is mostly--

00:01:45.180 --> 00:01:48.900
what I have here as slides is
things to scare you a little

00:01:48.900 --> 00:01:56.620
bit, just graphs of things
cannot be captured fully in a

00:01:56.620 --> 00:01:58.370
verbal conversation.

00:01:58.370 --> 00:02:02.210
And I'm going to show you graphs
of what is this idea of

00:02:02.210 --> 00:02:06.630
anti-fragile about.

00:02:06.630 --> 00:02:10.410
So I will speak for about, what,
20, 25, minutes, which

00:02:10.410 --> 00:02:14.650
means probably 30, and then
we're going to have a Q&amp;A. But

00:02:14.650 --> 00:02:18.290
if you're extremely angry with
what I have to say, do not

00:02:18.290 --> 00:02:19.680
hesitate and interrupt.

00:02:19.680 --> 00:02:22.070
Raise your hand.

00:02:22.070 --> 00:02:26.280
If you have severe
disagreements, disagreement is

00:02:26.280 --> 00:02:26.890
always very good.

00:02:26.890 --> 00:02:29.950
This is why these things should
be different from the

00:02:29.950 --> 00:02:33.000
book, because with a book, the
author rarely disagrees with

00:02:33.000 --> 00:02:34.370
himself, you see.

00:02:34.370 --> 00:02:35.860
Whereas here, you can have

00:02:35.860 --> 00:02:38.040
disagreements and they're welcome.

00:02:38.040 --> 00:02:39.290
OK, so we start.

00:02:41.640 --> 00:02:47.180
If you asked your mother or
cousins, someone who hasn't

00:02:47.180 --> 00:02:51.100
heard about this book, what's
the opposite of fragile, what

00:02:51.100 --> 00:02:53.736
do you think the answer
would be?

00:02:53.736 --> 00:02:54.680
AUDIENCE: Robust.

00:02:54.680 --> 00:02:55.230
NASSIM NICHOLAS TALEB: Robust.

00:02:55.230 --> 00:02:55.850
What else?

00:02:55.850 --> 00:02:57.458
AUDIENCE: Stout.

00:02:57.458 --> 00:03:01.150
NASSIM NICHOLAS TALEB: Stout,
durable, solid, adaptable,

00:03:01.150 --> 00:03:02.730
resilient, what else?

00:03:02.730 --> 00:03:08.430
OK, it's not, simply because
if you're sending--

00:03:08.430 --> 00:03:11.990
let's look at the exact
mathematical opposite.

00:03:11.990 --> 00:03:14.000
I don't know-- you guys
work for Google.

00:03:14.000 --> 00:03:17.560
What's the opposite
of negative here?

00:03:17.560 --> 00:03:18.150
Positive.

00:03:18.150 --> 00:03:18.980
It's not neutral.

00:03:18.980 --> 00:03:20.160
OK, very good.

00:03:20.160 --> 00:03:21.835
So what's the opposite
of convex?

00:03:21.835 --> 00:03:23.200
AUDIENCE: Concave.

00:03:23.200 --> 00:03:24.050
NASSIM NICHOLAS TALEB:
Concave.

00:03:24.050 --> 00:03:27.380
Actually, the negative of convex
is concave, you see.

00:03:27.380 --> 00:03:28.060
Very good.

00:03:28.060 --> 00:03:31.710
So the opposite of robust
cannot possibly be--

00:03:31.710 --> 00:03:36.220
the opposite of fragile cannot
possibly be robust.

00:03:36.220 --> 00:03:42.620
If I'm sending a package to
southwestern Siberia, and it's

00:03:42.620 --> 00:03:46.610
a wedding, and you're sending
a wedding gift--

00:03:46.610 --> 00:03:50.210
so we have champagne flutes.

00:03:50.210 --> 00:03:52.053
What do you write
on the package?

00:03:52.053 --> 00:03:53.040
AUDIENCE: Fragile.

00:03:53.040 --> 00:03:54.060
NASSIM NICHOLAS TALEB: Fragile
And underneath?

00:03:54.060 --> 00:03:56.790
Do we explain it to the
Russian inspector--

00:03:56.790 --> 00:03:58.770
what do you say?

00:03:58.770 --> 00:04:00.720
Handle with care.

00:04:00.720 --> 00:04:04.830
So what is the opposite
of handle with care?

00:04:04.830 --> 00:04:08.350
If you're going to send the
exact opposite package, what

00:04:08.350 --> 00:04:09.670
would you write on it?

00:04:09.670 --> 00:04:11.210
AUDIENCE: [INAUDIBLE].

00:04:11.210 --> 00:04:11.820
NASSIM NICHOLAS TALEB:
Exactly.

00:04:11.820 --> 00:04:13.580
Please mishandle.

00:04:13.580 --> 00:04:18.820
So something that is fragile,
if you map it properly

00:04:18.820 --> 00:04:21.130
mathematically, you'd realize
that the fragile is what does

00:04:21.130 --> 00:04:23.122
not like disorder.

00:04:23.122 --> 00:04:26.900
It doesn't want mishandling, it
doesn't want volatility, it

00:04:26.900 --> 00:04:28.980
wants peace and predictability.

00:04:28.980 --> 00:04:31.660
So the opposite of that would
be something that love

00:04:31.660 --> 00:04:33.770
volatility.

00:04:33.770 --> 00:04:36.660
What I'm saying may sound
interesting and new, but it's

00:04:36.660 --> 00:04:39.540
not to the option traders I
worked with, because I was an

00:04:39.540 --> 00:04:42.360
option trader for 20 years
before becoming whatever,

00:04:42.360 --> 00:04:44.620
calling myself all
these names.

00:04:44.620 --> 00:04:47.230
I was just a simple options
trader before, but my

00:04:47.230 --> 00:04:49.715
publishers now they
want to hide it.

00:04:49.715 --> 00:04:53.240
But the fact is option traders,
they understand the

00:04:53.240 --> 00:04:55.645
world and do it in two
different dimensions.

00:04:55.645 --> 00:05:00.170
There are things that don't
like volatility and things

00:05:00.170 --> 00:05:04.080
like volatility, and it's a
very, very extremely bipolar

00:05:04.080 --> 00:05:06.450
view of the world.

00:05:06.450 --> 00:05:08.360
You almost have nothing
in between.

00:05:08.360 --> 00:05:13.890
And effectively, all I did is
generalize this idea, to map

00:05:13.890 --> 00:05:17.700
it to things that option
traders-- because option

00:05:17.700 --> 00:05:22.480
traders, all they do is they
drink and they trade options,

00:05:22.480 --> 00:05:25.630
so they don't have exposure
outside of that narrow field.

00:05:25.630 --> 00:05:27.800
So all I'm doing is representing
them to take the

00:05:27.800 --> 00:05:29.530
idea outside.

00:05:29.530 --> 00:05:33.320
And we can do a lot of things,
because effectively, fragility

00:05:33.320 --> 00:05:36.350
is something I can measure and
anti-fragility is something I

00:05:36.350 --> 00:05:37.630
can measure.

00:05:37.630 --> 00:05:40.850
But risk, you can't
really measure--

00:05:40.850 --> 00:05:46.470
unless, of course, you're at
Harvard or Stanford or one of

00:05:46.470 --> 00:05:48.560
these places where they have
the illusion where they can

00:05:48.560 --> 00:05:49.410
measure risk.

00:05:49.410 --> 00:05:50.820
But in reality, we can't
measure risk.

00:05:50.820 --> 00:05:52.310
It's something in the future.

00:05:52.310 --> 00:05:54.610
I can measure fragility.

00:05:54.610 --> 00:05:56.370
And let's see how we
can generalize.

00:05:56.370 --> 00:06:00.030
The graph you have here shows
you very simply a fragile

00:06:00.030 --> 00:06:04.460
payoff where nothing happens
most of the time.

00:06:04.460 --> 00:06:06.310
I don't know, you don't have
porcelain cups here.

00:06:06.310 --> 00:06:08.120
Otherwise, we would have
had an experiment.

00:06:08.120 --> 00:06:10.290
But nothing happens
most of the time.

00:06:10.290 --> 00:06:12.090
But when something happens,
it's negative.

00:06:12.090 --> 00:06:13.330
You see?

00:06:13.330 --> 00:06:15.100
So this is a fragile,
and everything

00:06:15.100 --> 00:06:17.330
fragile has this property.

00:06:17.330 --> 00:06:21.470
To give you a hint, we can
generalize it to medicine

00:06:21.470 --> 00:06:25.820
where you take pills that give
you very small benefits.

00:06:25.820 --> 00:06:31.060
The benefits are small or
nonexistent, and the harm is

00:06:31.060 --> 00:06:35.600
large and rare and often not
seen in the past history of

00:06:35.600 --> 00:06:36.480
the product.

00:06:36.480 --> 00:06:38.400
That's a fragile.

00:06:38.400 --> 00:06:43.530
So I take a pill, it gives me
small benefits, and then 10

00:06:43.530 --> 00:06:46.280
years later, you realize that
it gave you cancer or some

00:06:46.280 --> 00:06:47.615
hidden disease that
nobody saw.

00:06:47.615 --> 00:06:50.780
It's the same payoff
for fragile.

00:06:50.780 --> 00:06:54.130
Visibly, the robust will
have this payoff--

00:06:54.130 --> 00:06:55.380
it doesn't care--

00:06:55.380 --> 00:07:02.470
and the anti-fragile will have
this payoff where harm is

00:07:02.470 --> 00:07:10.250
small and the big variations are
positive, are favorable.

00:07:10.250 --> 00:07:13.280
So this is sort of like the
idea or the general idea.

00:07:16.950 --> 00:07:22.030
Once you link fragility to
volatility, you can do a lot

00:07:22.030 --> 00:07:24.890
of things, and let me show
you exactly the link.

00:07:27.910 --> 00:07:32.460
I'm going to show you a graph
that sort of explains it in

00:07:32.460 --> 00:07:34.720
graphical terms.

00:07:34.720 --> 00:07:38.500
Everything fragile has to have
disproportionate harm--

00:07:38.500 --> 00:07:41.430
in other words, concave,
nonlinear.

00:07:41.430 --> 00:07:42.460
I'll show you what--

00:07:42.460 --> 00:07:44.210
we'll talk about concave
in a few minutes--

00:07:44.210 --> 00:07:49.280
nonlinear harm with respect
to an event size.

00:07:49.280 --> 00:07:50.270
Let me explain.

00:07:50.270 --> 00:07:52.930
I mean, you guys at Google and
particularly in this part of

00:07:52.930 --> 00:07:54.740
California, are pretty
special.

00:07:54.740 --> 00:07:57.170
But if you jump 10 meters--

00:07:57.170 --> 00:07:59.100
that's 33 feet--

00:07:59.100 --> 00:08:01.340
I guess people here in
Palo Alto, in this

00:08:01.340 --> 00:08:02.890
area, they die, no?

00:08:02.890 --> 00:08:03.630
Very good.

00:08:03.630 --> 00:08:03.930
No?

00:08:03.930 --> 00:08:05.460
They would die.

00:08:05.460 --> 00:08:10.510
Now if you jump 100 times 10
centimeters, you survive.

00:08:10.510 --> 00:08:11.760
No?

00:08:15.460 --> 00:08:20.490
It means your exposure is
not linear to harm.

00:08:20.490 --> 00:08:25.930
You're harmed a lot more jumping
10 feet than if you

00:08:25.930 --> 00:08:29.070
jump 10 times one foot.

00:08:29.070 --> 00:08:30.440
So we have acceleration
of harm.

00:08:30.440 --> 00:08:34.340
If I smash one of the Maseratis
you see in Palo Alto

00:08:34.340 --> 00:08:37.419
against a wall at 100 miles per
hour, I'm going to damage

00:08:37.419 --> 00:08:40.100
it a lot more than if I
smash it 100 times at

00:08:40.100 --> 00:08:40.900
one mile per hour.

00:08:40.900 --> 00:08:43.020
You agree?

00:08:43.020 --> 00:08:48.820
It means that there is this
proportionate harm coming, an

00:08:48.820 --> 00:08:49.900
acceleration of harm.

00:08:49.900 --> 00:08:54.010
It's a second order effect.

00:08:54.010 --> 00:08:56.460
Fragility isn't a second
order effect.

00:08:56.460 --> 00:09:03.080
And it has to be so, because
if harm were linear, I'd be

00:09:03.080 --> 00:09:06.470
harmed just walking
to the office.

00:09:06.470 --> 00:09:07.770
This is a central idea.

00:09:07.770 --> 00:09:11.560
Anything that has survived and
is in existence today is

00:09:11.560 --> 00:09:18.250
harmed a lot more by a 10%, say,
move in the market, 10

00:09:18.250 --> 00:09:21.970
meter jump or whatever it is,
than by a tenth of that and 10

00:09:21.970 --> 00:09:23.930
times the tenths of that.

00:09:23.930 --> 00:09:26.130
It means it has to be concave
to a source of stressor.

00:09:26.130 --> 00:09:28.880
In my book, I give the--

00:09:28.880 --> 00:09:33.340
because this talk is more
sophisticated than the book

00:09:33.340 --> 00:09:35.660
and the contents of the book.

00:09:35.660 --> 00:09:38.080
In the book, I have
to give a story.

00:09:38.080 --> 00:09:43.060
And it's in the Talmudic
literature that there is a

00:09:43.060 --> 00:09:47.130
king who had to punish his son,
and he had to crush him

00:09:47.130 --> 00:09:48.560
with a big stone.

00:09:48.560 --> 00:09:51.870
And given that he was both a
king and the father, he had

00:09:51.870 --> 00:09:54.960
the dilemma that was solved by a
local counselor who told him

00:09:54.960 --> 00:09:55.750
it was very simple.

00:09:55.750 --> 00:09:59.760
Crush the big stone in pebbles
and then throw pebbles at him

00:09:59.760 --> 00:10:00.720
That's the definition
of fragility.

00:10:00.720 --> 00:10:03.250
Anything that survived,
conditional on something

00:10:03.250 --> 00:10:06.435
having survived, has to be
harmed disproportionately.

00:10:06.435 --> 00:10:09.840
You see, the larger the stone,
the more the harm.

00:10:09.840 --> 00:10:14.520
With this, you can see why large
becomes vulnerable to

00:10:14.520 --> 00:10:18.855
shocks, because, for example, a
100 million pound project in

00:10:18.855 --> 00:10:22.060
the United Kingdom where we have
data had 30% more cost

00:10:22.060 --> 00:10:26.570
overruns than a five million
pound project.

00:10:26.570 --> 00:10:30.160
Now with this, not only do
we have a definition of

00:10:30.160 --> 00:10:33.330
fragility, but we have a robust
way to measure it.

00:10:33.330 --> 00:10:33.830
How?

00:10:33.830 --> 00:10:35.080
Simple.

00:10:36.800 --> 00:10:39.410
It's the acceleration that
allows me to detect the

00:10:39.410 --> 00:10:42.470
fragility, the acceleration
of harm.

00:10:42.470 --> 00:10:48.060
If I have a bad ruler, I
can't measure a child,

00:10:48.060 --> 00:10:48.780
the height of a child.

00:10:48.780 --> 00:10:49.700
Do you agree?

00:10:49.700 --> 00:10:50.880
It's very hard.

00:10:50.880 --> 00:10:56.100
But I can tell how fast he's
growing in percentage.

00:10:56.100 --> 00:10:56.830
Do you agree?

00:10:56.830 --> 00:10:58.320
So I don't have to have a great

00:10:58.320 --> 00:11:01.180
measuring tool for fragility.

00:11:01.180 --> 00:11:04.180
All I need is to detect the
second order of derivative,

00:11:04.180 --> 00:11:07.880
the acceleration, because
fragility is in acceleration.

00:11:07.880 --> 00:11:10.440
Now that I gave you the
difficult stuff, let me talk

00:11:10.440 --> 00:11:11.170
about my book.

00:11:11.170 --> 00:11:14.000
Everything we posit
on this idea that

00:11:14.000 --> 00:11:16.690
fragility is in the concave--

00:11:16.690 --> 00:11:20.570
and if I learned how
to work this.

00:11:20.570 --> 00:11:22.010
Hold on.

00:11:22.010 --> 00:11:24.520
This is a concave.

00:11:24.520 --> 00:11:28.870
The concave is fragile, and
you can see the benefits.

00:11:28.870 --> 00:11:32.340
And the concave is
anti-fragile.

00:11:32.340 --> 00:11:36.930
To give you an idea of why
the concave is fragile--

00:11:36.930 --> 00:11:38.820
if you have a piece of
information that your

00:11:38.820 --> 00:11:44.920
grandmother spent two days at
70 degrees Fahrenheit as the

00:11:44.920 --> 00:11:47.330
sole information, you would
assume that your grandmother's

00:11:47.330 --> 00:11:48.490
very happy, no?

00:11:48.490 --> 00:11:51.290
That's a perfect temperature
for grandmothers.

00:11:51.290 --> 00:11:56.740
But then the second order-- ah,
your grandmother spent the

00:11:56.740 --> 00:12:01.370
first day at zero degrees and
the second one at 140 degrees

00:12:01.370 --> 00:12:06.830
for an average 70 degrees, I
think you would be thinking

00:12:06.830 --> 00:12:08.950
about the inheritance and all
the things that come with a

00:12:08.950 --> 00:12:11.560
funeral, no?

00:12:11.560 --> 00:12:15.480
Is fragile what does not to like
a negative second order

00:12:15.480 --> 00:12:18.670
effect and is, therefore,
anti-fragile what likes

00:12:18.670 --> 00:12:22.750
variation and likes these
second order effects?

00:12:22.750 --> 00:12:24.760
Let me try to work this because
I'm a little confused

00:12:24.760 --> 00:12:29.750
about this, how to work
the computer.

00:12:29.750 --> 00:12:31.500
I figured out how to work it.

00:12:31.500 --> 00:12:32.900
So let's stop with the
graphs and let me

00:12:32.900 --> 00:12:34.740
talk about the book.

00:12:34.740 --> 00:12:37.690
Now you're confused enough
but intrigued.

00:12:37.690 --> 00:12:40.900
So let me talk about my book
after I showed you these

00:12:40.900 --> 00:12:43.610
technical definitions.

00:12:43.610 --> 00:12:45.680
This book--

00:12:45.680 --> 00:12:50.130
I realized that this property
of anti-fragility, once you

00:12:50.130 --> 00:12:51.580
had the definition of fragility
and then you have

00:12:51.580 --> 00:12:52.910
its opposite, was

00:12:52.910 --> 00:12:55.280
misunderstood in the discourse.

00:12:55.280 --> 00:12:59.300
Like, when governments want
stability, they shoot for

00:12:59.300 --> 00:13:03.390
perfect stability, but something
that is organic

00:13:03.390 --> 00:13:05.263
requires some amount
of volatility.

00:13:05.263 --> 00:13:07.770
It's the exact opposite
of the grandmother.

00:13:07.770 --> 00:13:09.380
There's a mathematical property
called Jensen's

00:13:09.380 --> 00:13:12.990
inequality that tells you that
often things gain on their

00:13:12.990 --> 00:13:13.980
variability.

00:13:13.980 --> 00:13:16.980
There are a huge amount of
phenomena like that.

00:13:16.980 --> 00:13:20.270
In other words, you do a lot
better, yourself, if you spend

00:13:20.270 --> 00:13:23.930
an hour at 50 degrees and an
hour at 80 degrees than if you

00:13:23.930 --> 00:13:27.780
spent two hours at 65 degrees,
for example.

00:13:27.780 --> 00:13:30.720
In Jensen's inequality,
anything convex--

00:13:30.720 --> 00:13:34.420
actually, this is a graph
of Jensen's inequality.

00:13:34.420 --> 00:13:36.370
OK, here it is.

00:13:36.370 --> 00:13:38.410
It's complicated, I told
you, so let me

00:13:38.410 --> 00:13:41.270
remove it very quickly.

00:13:41.270 --> 00:13:45.410
So there are things that
like variation.

00:13:45.410 --> 00:13:49.870
So you can classify in
three categories--

00:13:49.870 --> 00:13:54.150
the fragile is what does not
like volatility, randomness,

00:13:54.150 --> 00:13:57.080
variability, uncertainty,
stressors.

00:13:57.080 --> 00:13:58.830
The robust doesn't
really care, like

00:13:58.830 --> 00:14:00.350
the Brooklyn Bridge.

00:14:00.350 --> 00:14:03.640
And the anti-fragile requires
some amount of variability in

00:14:03.640 --> 00:14:04.820
all of these.

00:14:04.820 --> 00:14:09.140
The discourse missed completely
the notion of

00:14:09.140 --> 00:14:12.350
anti-fragile, so we try
to get stability.

00:14:12.350 --> 00:14:14.770
With government, for example,
they want to have no

00:14:14.770 --> 00:14:17.550
fluctuation and you saw
what Greenspan did.

00:14:17.550 --> 00:14:19.390
If you gave him the seasons, he
would have had the seasons

00:14:19.390 --> 00:14:23.080
at 67.8 degrees, the temperature
year round, like

00:14:23.080 --> 00:14:24.220
inside this office.

00:14:24.220 --> 00:14:27.580
It's what you maintain, I think,
inside the office.

00:14:27.580 --> 00:14:29.870
And of course, we would have
blown up the planet.

00:14:29.870 --> 00:14:31.770
I'm glad we only gave
him the economy--

00:14:31.770 --> 00:14:34.130
he only blew that up.

00:14:34.130 --> 00:14:38.230
But we do a lot of harm by
depriving something organic of

00:14:38.230 --> 00:14:39.810
a certain amount
of variability.

00:14:39.810 --> 00:14:42.660
Anything organic communicates
with its

00:14:42.660 --> 00:14:45.460
environment via stressors.

00:14:45.460 --> 00:14:51.040
So this is composed
of seven books.

00:14:51.040 --> 00:14:54.910
Book one, I talk about this
difference between a cat and a

00:14:54.910 --> 00:14:58.050
washing machine-- in other
words, between the organic

00:14:58.050 --> 00:14:59.720
that requires stressors.

00:14:59.720 --> 00:15:01.560
Do you guys have a
gym at Google?

00:15:01.560 --> 00:15:02.140
Well, there you go.

00:15:02.140 --> 00:15:04.320
So you put your body
under stress.

00:15:04.320 --> 00:15:06.000
But you don't realize there are
other things you need to

00:15:06.000 --> 00:15:07.650
put under stress as well.

00:15:07.650 --> 00:15:11.190
There are other stresses you
need to have just to enjoy

00:15:11.190 --> 00:15:13.390
life if you want to be alive.

00:15:13.390 --> 00:15:17.440
There's no liquid I know of
that tastes better than a

00:15:17.440 --> 00:15:20.320
glass of water after
spending some time

00:15:20.320 --> 00:15:22.680
in the Sahara Desert.

00:15:22.680 --> 00:15:24.920
So therefore, there's a chance
an inequality at work right

00:15:24.920 --> 00:15:26.170
there in your life.

00:15:29.660 --> 00:15:33.060
We realize here and there that
you need to stress the bones,

00:15:33.060 --> 00:15:36.870
but we don't really transfer
it to other areas of life.

00:15:36.870 --> 00:15:41.350
Like, we may not like to have
this architecture, modernistic

00:15:41.350 --> 00:15:43.470
architecture, smooth
architecture--

00:15:43.470 --> 00:15:45.730
it's not as pleasant,
it's not for us, as

00:15:45.730 --> 00:15:47.290
something richer, fractal.

00:15:47.290 --> 00:15:49.510
I'm looking out the window,
I have trees.

00:15:49.510 --> 00:15:52.750
It's a lot richer, and the
ancients actually liked that.

00:15:52.750 --> 00:15:54.740
I don't know if you've been
in the Gaudi Building in

00:15:54.740 --> 00:15:56.780
Barcelona, where you walk in.

00:15:56.780 --> 00:15:57.400
It's a cave.

00:15:57.400 --> 00:15:59.870
It's rich in details and I
feel more comfortable--

00:15:59.870 --> 00:16:03.330
visibly, my eye likes
variations, just like your

00:16:03.330 --> 00:16:07.230
body likes some term of
variation and some stressors.

00:16:07.230 --> 00:16:11.140
So that's book one where I talk
about that, and I talk

00:16:11.140 --> 00:16:13.200
about ethics.

00:16:13.200 --> 00:16:16.950
What happens is that people
understand that what doesn't

00:16:16.950 --> 00:16:19.550
kill me makes me stronger.

00:16:19.550 --> 00:16:22.440
They don't understand the real
logic of it, which is that

00:16:22.440 --> 00:16:25.860
what kills me makes
others stronger.

00:16:25.860 --> 00:16:30.070
That effect, a system that works
very well, is a system

00:16:30.070 --> 00:16:31.710
that has layers.

00:16:31.710 --> 00:16:34.430
Like the restaurant business
works very well because its

00:16:34.430 --> 00:16:38.630
components are fragile,
the entrepreneurs.

00:16:38.630 --> 00:16:40.330
Otherwise, we'd be
eating bad food.

00:16:40.330 --> 00:16:42.320
I mean, not that we're eating
great food all the time, but

00:16:42.320 --> 00:16:43.922
you understand the idea.

00:16:43.922 --> 00:16:47.850
You'd be eating like Russia
during the Soviet era.

00:16:47.850 --> 00:16:51.600
So there's some businesses
that thrive--

00:16:51.600 --> 00:16:54.770
like California, I'm here at the
epicenter of things that

00:16:54.770 --> 00:16:58.550
thrive because the failure
rate is converted into

00:16:58.550 --> 00:17:00.330
benefits for the system.

00:17:00.330 --> 00:17:05.109
So this is Darwinistic, except
that we can inject some ethics

00:17:05.109 --> 00:17:07.790
into it to avoid what
philosophers call the

00:17:07.790 --> 00:17:10.270
naturalistic fallacy, that
what is natural isn't

00:17:10.270 --> 00:17:11.930
necessarily great.

00:17:11.930 --> 00:17:14.530
So we can have--

00:17:14.530 --> 00:17:18.790
we should have entrepreneurs,
encourage more entrepreneurs

00:17:18.790 --> 00:17:21.290
in the economy, encourage
them to fail,

00:17:21.290 --> 00:17:22.329
and remove the stigma.

00:17:22.329 --> 00:17:25.859
This is the only place in the
world where there's no big

00:17:25.859 --> 00:17:27.235
stigma for failure, here
in California.

00:17:27.235 --> 00:17:29.020
We should have it more
generalized,

00:17:29.020 --> 00:17:30.500
because you need them.

00:17:30.500 --> 00:17:32.690
But also at the biological
level, when you starve

00:17:32.690 --> 00:17:35.060
yourself, you stress
some cells.

00:17:35.060 --> 00:17:41.650
And the reason we are healthy
is because there are fragile

00:17:41.650 --> 00:17:47.860
cells in us that break first
under stress, and therefore

00:17:47.860 --> 00:17:50.240
you have an improvement
within you.

00:17:50.240 --> 00:17:53.520
You always have the top layer
require the fragility of a

00:17:53.520 --> 00:17:55.000
lower layer.

00:17:55.000 --> 00:17:56.640
So that's book one.

00:17:56.640 --> 00:17:58.610
Book two--

00:17:58.610 --> 00:18:02.300
again, these books are separate
books that discuss

00:18:02.300 --> 00:18:04.140
different topics linked
to that original

00:18:04.140 --> 00:18:05.590
idea that I gave you.

00:18:05.590 --> 00:18:09.860
Book two is about modernity, how
suddenly you start having

00:18:09.860 --> 00:18:15.340
policies that try to control,
touristify the world, where

00:18:15.340 --> 00:18:18.240
you have a plan, you have
everything is smooth, no

00:18:18.240 --> 00:18:20.070
randomness in life.

00:18:20.070 --> 00:18:24.550
And I explained that, really,
we have a lot of people that

00:18:24.550 --> 00:18:27.010
have discovered over time that
you need randomness to

00:18:27.010 --> 00:18:28.650
stabilize a lot of systems.

00:18:28.650 --> 00:18:31.380
So the book discusses
a disease called

00:18:31.380 --> 00:18:34.430
interventionism, overstabilizing
systems, and

00:18:34.430 --> 00:18:38.060
some research on different
areas, about 50 of them, where

00:18:38.060 --> 00:18:40.710
in which there is a need
for randomness to

00:18:40.710 --> 00:18:42.190
stabilize the system.

00:18:42.190 --> 00:18:46.100
Like Maxwell's governor--

00:18:46.100 --> 00:18:49.300
it was discovered that if you
overstabilize a steam engine,

00:18:49.300 --> 00:18:51.090
it blows up.

00:18:51.090 --> 00:18:52.650
So we have that in the economy,
you have that in a

00:18:52.650 --> 00:18:53.480
lot of places.

00:18:53.480 --> 00:18:54.500
So that's my book two.

00:18:54.500 --> 00:18:56.800
And in it I discuss a certain
brand of person.

00:18:56.800 --> 00:19:01.500
I call them fragilista,
someone who denies the

00:19:01.500 --> 00:19:07.560
anti-fragility of things and
fracases by the denial.

00:19:07.560 --> 00:19:10.750
Later on, we'll talk about a
relative of the fragilista

00:19:10.750 --> 00:19:13.280
with the Soviet-Harvard approach
to things, from top

00:19:13.280 --> 00:19:15.050
down, not bottom up.

00:19:15.050 --> 00:19:15.880
So that's book two.

00:19:15.880 --> 00:19:21.730
Book three introduces a friend
of mine, Fat Tony.

00:19:21.730 --> 00:19:27.410
And Fat Tony doesn't like
predictions, and visibly, as

00:19:27.410 --> 00:19:30.480
name indicates, he
enjoys life.

00:19:30.480 --> 00:19:32.090
But he's a little coarse.

00:19:32.090 --> 00:19:33.710
And there's his friend Nero.

00:19:33.710 --> 00:19:35.860
He and Nero are always
fighting.

00:19:35.860 --> 00:19:39.580
But he taught Nero how
to smell fragility.

00:19:39.580 --> 00:19:40.960
Because you see these graphs?

00:19:40.960 --> 00:19:42.660
I had to use my brain to
understand fragility.

00:19:42.660 --> 00:19:44.630
Fat Tony can do it naturally.

00:19:44.630 --> 00:19:46.900
He can figure out the sucker--

00:19:46.900 --> 00:19:50.520
so, his idea of the world is
sucker versus non-sucker.

00:19:50.520 --> 00:19:53.240
And his point to that is any
system that's based on

00:19:53.240 --> 00:19:56.820
prediction is going
to blow up.

00:19:56.820 --> 00:19:58.970
So he finds those who
really are sensitive

00:19:58.970 --> 00:20:00.640
to prediction error--

00:20:00.640 --> 00:20:03.270
because, remember, the fragile
is very sensitive to

00:20:03.270 --> 00:20:04.800
prediction error.

00:20:04.800 --> 00:20:06.600
So then I continue.

00:20:06.600 --> 00:20:07.630
Book four--

00:20:07.630 --> 00:20:09.050
I don't know if I have
the book numbers

00:20:09.050 --> 00:20:10.750
right, but it's OK.

00:20:10.750 --> 00:20:14.580
I can change it, because I'm
the author, remember.

00:20:14.580 --> 00:20:24.010
Book four is about optionality
and the things I introduce

00:20:24.010 --> 00:20:28.200
link to convexity.

00:20:28.200 --> 00:20:29.410
I didn't want to scare
the readers--

00:20:29.410 --> 00:20:32.090
I didn't talk to them about
convexity right away.

00:20:32.090 --> 00:20:38.720
I tried to get through the back
door via this very simple

00:20:38.720 --> 00:20:40.610
representation.

00:20:40.610 --> 00:20:42.540
It's if you have an
asymmetric payoff.

00:20:42.540 --> 00:20:45.020
If you make more when you're
right than you lose when

00:20:45.020 --> 00:20:50.500
you're wrong, then you
are anti-fragile.

00:20:50.500 --> 00:20:53.590
And if you have more to lose
than to gain, you are fragile.

00:20:53.590 --> 00:20:55.430
The same applies to a coffee
cup, to anything--

00:20:55.430 --> 00:20:57.120
the china, anything.

00:20:57.120 --> 00:21:01.610
And of course, the volatility
will be the vector that would

00:21:01.610 --> 00:21:02.850
cause you to lose.

00:21:02.850 --> 00:21:08.500
So I introduced this, but so far
the book is not technical,

00:21:08.500 --> 00:21:11.920
so I introduced via Fat
Tony and Seneca.

00:21:11.920 --> 00:21:16.400
Seneca was also like Fat Tony
but much more intellectual.

00:21:16.400 --> 00:21:20.720
Seneca, the Roman philosopher,
who is precisely not Greek in

00:21:20.720 --> 00:21:22.450
the sense that he was practical
and he had a

00:21:22.450 --> 00:21:25.235
practical approach to
stoical philosophy.

00:21:25.235 --> 00:21:28.420
The guy was the wealthiest man
in the world, and he was

00:21:28.420 --> 00:21:31.460
obsessed with the fact that when
you're very wealthy, you

00:21:31.460 --> 00:21:34.120
have more lose than to
gain from wealth.

00:21:34.120 --> 00:21:37.680
So he trained himself every day
to wake up thinking he's

00:21:37.680 --> 00:21:40.770
poor and then rediscovered
wealth.

00:21:40.770 --> 00:21:43.840
Once in while, he
would mimic--

00:21:43.840 --> 00:21:49.630
he would have a shipwreck in
which he writes that he lives

00:21:49.630 --> 00:21:54.000
as if he were on a shipwreck
with only one or two slaves.

00:21:54.000 --> 00:21:56.110
You get it.

00:21:56.110 --> 00:21:58.360
But he was the wealthiest man in
the world writing about how

00:21:58.360 --> 00:21:59.390
to love poverty.

00:21:59.390 --> 00:22:02.470
You get the idea, but the
guy was good at it.

00:22:02.470 --> 00:22:06.350
He figured out that you have
to always be in a situation

00:22:06.350 --> 00:22:09.200
where you got more upside than
downside, and then you don't

00:22:09.200 --> 00:22:11.310
have to worry about
randomness.

00:22:11.310 --> 00:22:15.570
And in fact, the strangest thing
is not that he said it.

00:22:15.570 --> 00:22:17.330
I picked it up and
I was shocked.

00:22:17.330 --> 00:22:20.080
I said, this guy's talking
like normal people.

00:22:20.080 --> 00:22:24.440
What all academics, the view of
stoicism, is that they'd be

00:22:24.440 --> 00:22:25.930
like academics--

00:22:25.930 --> 00:22:28.860
boring, and like fashionable
stoicism,

00:22:28.860 --> 00:22:29.780
unmoved by the world.

00:22:29.780 --> 00:22:32.740
No, they're only unmoved
by bad events.

00:22:32.740 --> 00:22:33.950
That's central.

00:22:33.950 --> 00:22:38.040
So via Seneca, I introduced
that notion of asymmetry--

00:22:38.040 --> 00:22:41.640
always have more upside than
downside from random events,

00:22:41.640 --> 00:22:42.690
and then you're anti-fragile.

00:22:42.690 --> 00:22:45.740
So I go through Fat Tony and
Seneca to drill the point and

00:22:45.740 --> 00:22:47.890
it sort of works.

00:22:47.890 --> 00:22:52.450
Also, this book has titles and
subtitles, and there's no

00:22:52.450 --> 00:22:58.170
connection between the title,
the subtitle, and the text.

00:22:58.170 --> 00:22:59.350
Why?

00:22:59.350 --> 00:23:03.640
Because since I wrote my
first book, I sort of

00:23:03.640 --> 00:23:04.690
was afraid of reviewers.

00:23:04.690 --> 00:23:07.970
But then I said the best way to
have a book is to tick off

00:23:07.970 --> 00:23:09.990
reviewers from day one,
so that way I don't

00:23:09.990 --> 00:23:11.270
have to fear them.

00:23:11.270 --> 00:23:14.410
And reviewers, they want
to skim the book.

00:23:14.410 --> 00:23:17.344
I can't understand or figure
out what it is about them.

00:23:17.344 --> 00:23:21.560
Plus, I put a 600 page map--
actually, it's a Google text,

00:23:21.560 --> 00:23:21.910
by the way.

00:23:21.910 --> 00:23:24.150
You guys were housing
it for free.

00:23:24.150 --> 00:23:27.430
So far, it's 400 pages of math,
dense math, as backup

00:23:27.430 --> 00:23:28.845
for this, plus a technical
appendix.

00:23:33.050 --> 00:23:35.830
Just to tick off reviewers,
the ideas--

00:23:35.830 --> 00:23:38.690
I want people to go through
the reading experience.

00:23:38.690 --> 00:23:40.460
So they can't figure out by
then that I'm not talking

00:23:40.460 --> 00:23:42.060
about the whole thing, the
book, is about Jensen's

00:23:42.060 --> 00:23:45.690
inequality, things that love
randomness and how to

00:23:45.690 --> 00:23:46.830
benefit from it.

00:23:46.830 --> 00:23:49.460
Now I'm going to go to
California and talk to you

00:23:49.460 --> 00:23:53.080
guys about a phenomenon.

00:23:53.080 --> 00:23:55.230
I skipped the chapters because
here I have more Greek

00:23:55.230 --> 00:23:56.840
philosophers, more stories.

00:23:56.840 --> 00:23:58.980
Something very simple--

00:23:58.980 --> 00:24:01.890
I'm going to simulate
a process here--

00:24:01.890 --> 00:24:03.770
this is not in the book,
by the way, this

00:24:03.770 --> 00:24:06.870
is outside the book--

00:24:06.870 --> 00:24:08.860
where you have two
people competing.

00:24:08.860 --> 00:24:17.990
One person has knowledge and his
brother has convexity, has

00:24:17.990 --> 00:24:20.490
a convex payoff.

00:24:20.490 --> 00:24:22.610
And the difference between them
would be the difference

00:24:22.610 --> 00:24:27.790
between knowledge and a convex
payoff will be what I call the

00:24:27.790 --> 00:24:30.470
convexity bias.

00:24:30.470 --> 00:24:33.150
I simulated it and
look how big is.

00:24:33.150 --> 00:24:38.470
Well, visibly this explains
something that people so far

00:24:38.470 --> 00:24:39.980
couldn't understand.

00:24:39.980 --> 00:24:42.400
Trial and error has
errors in it.

00:24:42.400 --> 00:24:43.870
Do you agree?

00:24:43.870 --> 00:24:48.990
So in history books and history
of technology, people

00:24:48.990 --> 00:24:53.280
usually oppose trial and error
versus theoretical knowledge.

00:24:53.280 --> 00:24:55.130
But whenever we're able to work
with trial and error,

00:24:55.130 --> 00:24:57.750
they did not understand
it had to be convex.

00:24:57.750 --> 00:25:01.330
Trial and error relies on luck,
but luck can hurt you,

00:25:01.330 --> 00:25:04.520
so it was never modeled
as an option,

00:25:04.520 --> 00:25:05.600
technology as an option.

00:25:05.600 --> 00:25:07.490
If this model is an option-- and
I'm sure there are other

00:25:07.490 --> 00:25:10.810
questions, so I go over
this very quickly.

00:25:10.810 --> 00:25:14.570
If I were to model it as an
option, trial and error, then

00:25:14.570 --> 00:25:18.920
it would be something that
loves volatility--

00:25:18.920 --> 00:25:20.350
option loves volatility.

00:25:20.350 --> 00:25:23.270
And you can have policies
that come from it.

00:25:23.270 --> 00:25:26.770
My idea of flaneur
is very simple.

00:25:26.770 --> 00:25:29.770
I'd much rather have series of
options, like have a long

00:25:29.770 --> 00:25:33.130
highway with a lot of exits,
then be locked in into top

00:25:33.130 --> 00:25:35.700
down plan like a highway
with no exits--

00:25:35.700 --> 00:25:37.580
a destination and your
exit, that's it.

00:25:37.580 --> 00:25:41.082
So assuming you want to change
your mind, you're in trouble,

00:25:41.082 --> 00:25:44.120
particularly if you don't know
Russian and you're in Russia.

00:25:44.120 --> 00:25:46.950
That's how they build
their thing.

00:25:46.950 --> 00:25:48.920
So we have two approaches
to knowledge.

00:25:48.920 --> 00:25:51.660
One is top down and
one is bottom up.

00:25:51.660 --> 00:25:55.480
So here there are about 75 pages
that should upset a lot

00:25:55.480 --> 00:25:58.900
of academics because
you take--

00:25:58.900 --> 00:26:03.640
I took some evidence, which
includes my own field, which

00:26:03.640 --> 00:26:06.190
was to be derivatives, that a
lot of things that we think,

00:26:06.190 --> 00:26:09.280
that we believe come from top
down knowledge and theoretical

00:26:09.280 --> 00:26:13.380
knowledge effectively come from
tinkering, dressed up

00:26:13.380 --> 00:26:17.510
later as having been developed
by theoreticians, which

00:26:17.510 --> 00:26:20.100
includes these corners
up here.

00:26:20.100 --> 00:26:23.930
Euclid-- people say you have to
learn Euclidean geometry,

00:26:23.930 --> 00:26:26.520
and look at all these things
that were built after Euclid.

00:26:26.520 --> 00:26:29.640
For about 15, 16 centuries,
people were building things

00:26:29.640 --> 00:26:32.420
and never heard who
Euclid was.

00:26:32.420 --> 00:26:34.520
The Romans were extremely
heuristic--

00:26:34.520 --> 00:26:40.820
very, very, very experienced
based, and they did everything

00:26:40.820 --> 00:26:42.400
using this convex knowledge.

00:26:42.400 --> 00:26:43.680
How was it convex knowledge?

00:26:43.680 --> 00:26:45.830
It's exactly like cooking.

00:26:45.830 --> 00:26:47.420
You have very little to
lose by adding an

00:26:47.420 --> 00:26:49.960
ingredient and tasting.

00:26:49.960 --> 00:26:53.750
If it works, now you have
a better recipe.

00:26:53.750 --> 00:26:56.030
If it fails, you lost nothing.

00:26:56.030 --> 00:26:59.780
So things in knowledge, no
academic would want--

00:26:59.780 --> 00:27:03.100
I mean, I'm a professor in an
engineering department.

00:27:03.100 --> 00:27:04.870
No academic-- except engineers,
because they're

00:27:04.870 --> 00:27:06.320
nice people--

00:27:06.320 --> 00:27:09.860
would accept the notion that
knowledge can come

00:27:09.860 --> 00:27:12.420
from a bottom up.

00:27:12.420 --> 00:27:15.430
So we have evidence of
what I call lecturing

00:27:15.430 --> 00:27:16.420
birds how to fly.

00:27:16.420 --> 00:27:19.260
A lot of science comes
from technology.

00:27:19.260 --> 00:27:20.330
But look at a definition--

00:27:20.330 --> 00:27:23.560
google technology, science,
and it would explain that

00:27:23.560 --> 00:27:26.340
technology is application of
science to practical things,

00:27:26.340 --> 00:27:28.006
exactly opposite.

00:27:28.006 --> 00:27:30.810
Anyway, so this is my options
theory thing.

00:27:30.810 --> 00:27:32.900
I don't know if it upset many
of you, but typically it

00:27:32.900 --> 00:27:34.450
upsets academics.

00:27:34.450 --> 00:27:38.250
So then I go to the notion
of medicine.

00:27:38.250 --> 00:27:40.160
To get to it, I go to something

00:27:40.160 --> 00:27:41.830
called the via negativa--

00:27:41.830 --> 00:27:44.250
how to make something robust.

00:27:44.250 --> 00:27:47.140
To make something robust,
there are two things.

00:27:47.140 --> 00:27:48.240
Because of Jensen's inequality,

00:27:48.240 --> 00:27:50.075
it's better to run--

00:27:50.075 --> 00:27:54.950
better to walk and sprint
rather than just job.

00:27:54.950 --> 00:27:59.740
So you have strategies that
have variations in them.

00:27:59.740 --> 00:28:05.530
Bipolar strategies are vastly
better than mono strategies.

00:28:05.530 --> 00:28:09.460
And you see it, for example,
with portfolios.

00:28:09.460 --> 00:28:12.710
It's much better to put 80% of
your money risk free, if you

00:28:12.710 --> 00:28:16.000
can find something like that,
and 20% speculative, rather

00:28:16.000 --> 00:28:18.810
than the whole thing
medium risk.

00:28:18.810 --> 00:28:20.170
It's much more robust
that way.

00:28:20.170 --> 00:28:22.900
But you can see it in the
policy of every single

00:28:22.900 --> 00:28:26.670
monogamous species, which
includes humans, but we have

00:28:26.670 --> 00:28:27.850
data for birds.

00:28:27.850 --> 00:28:32.890
Monogamous birds, typically,
instead of the female opting

00:28:32.890 --> 00:28:39.420
for a good match, she picks the
accountant 90% of the time

00:28:39.420 --> 00:28:42.770
and the rock star to cheat with
10% of the time for a

00:28:42.770 --> 00:28:46.110
linear combination of having
someone in the middle.

00:28:46.110 --> 00:28:49.560
So the idea is you take the
loser, the stable accountant,

00:28:49.560 --> 00:28:50.150
and stuff like--

00:28:50.150 --> 00:28:53.660
not that accountants are losers,
but you see the kind.

00:28:53.660 --> 00:28:57.700
And then you take and then you
have the hotshot rock star on

00:28:57.700 --> 00:29:00.270
the occasion, so the linear
combination is better.

00:29:00.270 --> 00:29:03.380
This is explained in the book
why things that have

00:29:03.380 --> 00:29:04.790
variation--

00:29:04.790 --> 00:29:07.230
and I use the very same
equation with Jensen's

00:29:07.230 --> 00:29:11.510
inequality to show why it's
a lot more stable.

00:29:11.510 --> 00:29:14.110
Then medicine, of course.

00:29:14.110 --> 00:29:19.350
This is medicine where you
have visible gains from

00:29:19.350 --> 00:29:24.340
anything you ingest in medicine
and big losses,

00:29:24.340 --> 00:29:25.865
except there's convexity
in medicine.

00:29:30.050 --> 00:29:35.640
I study the problems of harm
done by the healer, whether in

00:29:35.640 --> 00:29:39.810
policy or something else,
in medical terms.

00:29:39.810 --> 00:29:41.380
It's called iatrogenics--

00:29:41.380 --> 00:29:45.230
harm given to you by someone
who's supposed to help you.

00:29:45.230 --> 00:29:48.840
And you can measure iatrogenics
probabilistically.

00:29:48.840 --> 00:29:50.420
I'm going to give you
an idea that I just

00:29:50.420 --> 00:29:52.260
put on the Web today.

00:29:52.260 --> 00:29:54.720
It's not exactly in the book,
but what we discovered from

00:29:54.720 --> 00:29:56.940
something about blood
pressure.

00:29:56.940 --> 00:30:02.020
So you have these big hidden
risks, but if you look at

00:30:02.020 --> 00:30:04.820
Mother Nature, Mother
Nature equipped us

00:30:04.820 --> 00:30:06.530
for a lot of natural--

00:30:06.530 --> 00:30:10.180
I mean, three billion years
is a lot of time, even for

00:30:10.180 --> 00:30:12.570
Google, so it's a lot of time.

00:30:12.570 --> 00:30:16.360
So Mother Nature was capable of
treating things that don't

00:30:16.360 --> 00:30:18.690
deviate from the normal.

00:30:18.690 --> 00:30:23.000
So we have never been able to
find anything you can put in

00:30:23.000 --> 00:30:26.930
your system that has turned
out to be 20 years later

00:30:26.930 --> 00:30:29.990
unconditionally good without
a hidden risk like this--

00:30:29.990 --> 00:30:32.210
steroids, tamoxifen,
all these.

00:30:32.210 --> 00:30:34.130
You see small little gains.

00:30:34.130 --> 00:30:36.970
But on the other hand, we should
analyze medicine using

00:30:36.970 --> 00:30:43.220
convexity terms, that if you are
very ill, you should have

00:30:43.220 --> 00:30:45.450
a lot more medicine and
much less medicine if

00:30:45.450 --> 00:30:47.170
you're not very ill.

00:30:47.170 --> 00:30:50.940
There's convexity of payoff
from medical treatment.

00:30:50.940 --> 00:30:53.840
But there is a problem, and let
me give you the problem.

00:30:53.840 --> 00:30:59.130
If you're mildly hypertensive
and they give you drugs, you

00:30:59.130 --> 00:31:06.140
have one chance in 53 of
benefiting from it, but now

00:31:06.140 --> 00:31:08.460
you have all these risks.

00:31:08.460 --> 00:31:13.060
If you're extremely
hypertensive, you have 90%,

00:31:13.060 --> 00:31:16.370
80% percent chance of benefiting
from the drug.

00:31:16.370 --> 00:31:18.680
So you have this risk, but you
have also a huge benefit,

00:31:18.680 --> 00:31:21.550
particularly when
you're very ill.

00:31:21.550 --> 00:31:24.840
The problem is as follows.

00:31:24.840 --> 00:31:27.650
People who are once sigma away
from the mean, which nature

00:31:27.650 --> 00:31:31.962
has treated, by the way, and
medicine doesn't help them

00:31:31.962 --> 00:31:36.460
much, are five times more
numerous than people four

00:31:36.460 --> 00:31:39.030
sigma aways from the mean.

00:31:39.030 --> 00:31:42.970
So if you're pharma,
what would you do?

00:31:42.970 --> 00:31:45.260
Who would you treat?

00:31:45.260 --> 00:31:48.360
You have five times more people
mildly ill than people

00:31:48.360 --> 00:31:49.570
who are ill.

00:31:49.570 --> 00:31:50.580
What would you do?

00:31:50.580 --> 00:31:52.930
You'd focus on the mildly ill.

00:31:52.930 --> 00:31:54.700
We'd focus on reclassifying
people as

00:31:54.700 --> 00:31:58.030
mildly ill to be treatable.

00:31:58.030 --> 00:32:00.553
And also, they don't die, so
they're repeat clients who are

00:32:00.553 --> 00:32:02.210
going to cash out
for a long time.

00:32:02.210 --> 00:32:04.130
So I use this argument
against pharma--

00:32:04.130 --> 00:32:10.400
via negativa is by removal of
something unnatural to us.

00:32:10.400 --> 00:32:13.440
You have no side effects, no
long term side effects.

00:32:13.440 --> 00:32:16.660
In a complex system, you need
something I call less is more,

00:32:16.660 --> 00:32:21.410
because adding something has
multiplicative side effects

00:32:21.410 --> 00:32:23.870
whereas removing something
unnatural-- like if I stop you

00:32:23.870 --> 00:32:26.080
from smoking or something like
that-- you have very, very

00:32:26.080 --> 00:32:28.590
small long term side effects.

00:32:28.590 --> 00:32:31.440
So these are the book so far.

00:32:31.440 --> 00:32:33.200
And book number--

00:32:33.200 --> 00:32:36.120
the last one, seven,
is on ethics.

00:32:36.120 --> 00:32:38.450
It's very simple.

00:32:38.450 --> 00:32:40.730
It's about a situation in which
one person makes the

00:32:40.730 --> 00:32:45.440
upside and someone else
makes a downside.

00:32:45.440 --> 00:32:47.360
You're looking at me like, what
he is he talking about?

00:32:47.360 --> 00:32:49.310
Well, have you heard
of the banks?

00:32:49.310 --> 00:32:50.760
Bankers make the upside.

00:32:50.760 --> 00:32:53.660
The rest of society
has a downside.

00:32:53.660 --> 00:32:56.510
So they're long volatility
at the expense of others.

00:32:56.510 --> 00:32:59.470
And of course, it's my most
emotional book and the one

00:32:59.470 --> 00:33:01.640
that made me the most enemies,
because I named names.

00:33:01.640 --> 00:33:05.560
I had this thing--

00:33:05.560 --> 00:33:07.910
when you see a fraud,
say fraud.

00:33:07.910 --> 00:33:09.840
Otherwise you're a fraud--

00:33:09.840 --> 00:33:13.190
so, commitment to ethics.

00:33:13.190 --> 00:33:19.160
And the whole book is about, of
course, never ask a doctor

00:33:19.160 --> 00:33:22.080
what you should do.

00:33:22.080 --> 00:33:24.320
You get a complete different
answer if you ask him what he

00:33:24.320 --> 00:33:26.790
would do if he were you.

00:33:26.790 --> 00:33:28.060
So here, I don't give advice.

00:33:28.060 --> 00:33:30.360
I just tell people what
I've done, what I do.

00:33:30.360 --> 00:33:31.890
Like when someone asked
me for a forecast, I

00:33:31.890 --> 00:33:32.625
don't believe in forecasts.

00:33:32.625 --> 00:33:34.510
I tell you this is
what I've done.

00:33:34.510 --> 00:33:35.820
This is what I have my portfolio
for the day.

00:33:35.820 --> 00:33:37.270
Go look at it, if I want.

00:33:37.270 --> 00:33:39.130
Otherwise, but no forecasts.

00:33:39.130 --> 00:33:43.100
The same thing is that
you should never harm

00:33:43.100 --> 00:33:45.200
others with a mistake.

00:33:45.200 --> 00:33:46.420
Why is this essential?

00:33:46.420 --> 00:33:48.750
At no time in history have we
had more people harm others

00:33:48.750 --> 00:33:51.250
without paying the price,
whether bureaucrats in

00:33:51.250 --> 00:33:51.920
Washington--

00:33:51.920 --> 00:33:54.790
they're not harmed, shamed
by spreadsheet--

00:33:54.790 --> 00:33:59.310
to economists giving us bogus
methods, and academics.

00:33:59.310 --> 00:34:01.730
I'm not harmed, I'm not the
one bearing the harm, so

00:34:01.730 --> 00:34:03.230
nothing improves
in that field.

00:34:03.230 --> 00:34:05.845
So like Steve Gill telling you,
oh, it's peer reviewed by

00:34:05.845 --> 00:34:06.940
a great journal.

00:34:06.940 --> 00:34:09.409
Nonsense-- all that's
nonsense.

00:34:09.409 --> 00:34:12.130
They're not harmed by the
mistakes or could keep going

00:34:12.130 --> 00:34:13.380
on with all this--

00:34:16.030 --> 00:34:17.100
can you curse here?--

00:34:17.100 --> 00:34:18.415
with all this bullshit.

00:34:18.415 --> 00:34:20.790
You can edit it out.

00:34:20.790 --> 00:34:21.110
I don't know.

00:34:21.110 --> 00:34:21.920
I did that at LSE--

00:34:21.920 --> 00:34:23.850
I used the F word at LSE--

00:34:23.850 --> 00:34:25.540
and then they told me,
well, you know what?

00:34:25.540 --> 00:34:27.340
We're going to keep it, but
it's extremely unusual.

00:34:27.340 --> 00:34:29.710
So I told them, OK.

00:34:29.710 --> 00:34:33.230
But anyway, during the Q&amp;A,
probably, I can relax more and

00:34:33.230 --> 00:34:34.130
[INAUDIBLE].

00:34:34.130 --> 00:34:37.260
So here I've introduced the
book, and add the book with

00:34:37.260 --> 00:34:39.100
the following.

00:34:39.100 --> 00:34:42.650
The only way you know you're
alive, you're not a machine,

00:34:42.650 --> 00:34:45.730
is if you like variability.

00:34:45.730 --> 00:34:46.409
That's it.

00:34:46.409 --> 00:34:49.290
So if you're anti-fragile,
that means you're alive.

00:34:49.290 --> 00:34:51.610
So thank you for listening to
me, and now let's start with

00:34:51.610 --> 00:34:52.840
Q&amp;A.

00:34:52.840 --> 00:35:00.060
[APPLAUSE]

00:35:00.060 --> 00:35:03.150
NASSIM NICHOLAS TALEB: I keep
the slides just in case

00:35:03.150 --> 00:35:05.610
someone asks me an emotional
question.

00:35:08.440 --> 00:35:08.930
Go ahead.

00:35:08.930 --> 00:35:09.530
AUDIENCE: Hi.

00:35:09.530 --> 00:35:10.270
Thanks for coming.

00:35:10.270 --> 00:35:11.380
It was great to hear
you speak.

00:35:11.380 --> 00:35:15.520
I was wondering if you could
elaborate on a related topic

00:35:15.520 --> 00:35:17.960
of fragility, which
is this whole

00:35:17.960 --> 00:35:20.515
question of a long peace?

00:35:20.515 --> 00:35:21.240
NASSIM NICHOLAS TALEB: OK.

00:35:21.240 --> 00:35:21.850
Very good.

00:35:21.850 --> 00:35:23.310
Excellent.

00:35:23.310 --> 00:35:30.400
What has happened over the
past 200 years and in the

00:35:30.400 --> 00:35:36.020
military is that you have
switched to tougher weapons,

00:35:36.020 --> 00:35:40.320
so we had longer periods of
peace punctuated with war.

00:35:40.320 --> 00:35:45.030
And if you stood in 1913 and 3/4
looking at recent history,

00:35:45.030 --> 00:35:46.300
you'd say, oh, it's
all quiet now.

00:35:46.300 --> 00:35:47.900
We don't have to worry.

00:35:47.900 --> 00:35:50.070
I'm sure you were really
surprised.

00:35:50.070 --> 00:35:53.590
So when we move into what
I call black swan prone

00:35:53.590 --> 00:35:56.910
variables, it takes much
longer to figure out

00:35:56.910 --> 00:35:57.650
what's going on.

00:35:57.650 --> 00:36:03.210
And we live in that world where
most of the big jumps

00:36:03.210 --> 00:36:05.290
come from a small number
of variables.

00:36:05.290 --> 00:36:08.020
You guys here prove it.

00:36:08.020 --> 00:36:10.740
If you look at how much of the
internet traffic is explained

00:36:10.740 --> 00:36:14.600
by Google, you had that
concentration.

00:36:14.600 --> 00:36:17.430
If you look in the book business
where you have 0.2%

00:36:17.430 --> 00:36:20.435
of the authors generate half the
income, if you realize you

00:36:20.435 --> 00:36:21.380
have that concentration--

00:36:21.380 --> 00:36:24.170
so the same applies
to wars, simply.

00:36:24.170 --> 00:36:27.610
With fat-tail processes you
cannot make an inference from

00:36:27.610 --> 00:36:30.400
just a small sample, and a lot
of people make the mistake of

00:36:30.400 --> 00:36:32.370
taking the last 50 years and
saying nothing happened the

00:36:32.370 --> 00:36:34.570
last 50 years, therefore,
let's not worry.

00:36:34.570 --> 00:36:36.460
No-- we have a lot of
potential danger.

00:36:36.460 --> 00:36:41.040
Plus, if it's a pinker book, the
pinker book is confused.

00:36:41.040 --> 00:36:43.190
But other than that--

00:36:43.190 --> 00:36:44.380
it's nice.

00:36:44.380 --> 00:36:48.770
Yeah, crime has dropped, but
you can't make statements

00:36:48.770 --> 00:36:53.830
about whether the risks
have changed.

00:36:53.830 --> 00:36:54.835
I've written about
it on the Web.

00:36:54.835 --> 00:36:54.990
I don't want to talk about it.

00:36:54.990 --> 00:36:56.142
I get emotional.

00:36:56.142 --> 00:36:57.970
Thanks.

00:36:57.970 --> 00:36:59.650
Next question.

00:36:59.650 --> 00:37:01.510
AUDIENCE: When you're describing
chapter one, I

00:37:01.510 --> 00:37:03.180
think it was, you said
that what doesn't

00:37:03.180 --> 00:37:04.620
kill me makes others--

00:37:04.620 --> 00:37:07.610
NASSIM NICHOLAS TALEB:
Book one, yeah.

00:37:07.610 --> 00:37:09.225
What kills me makes
others stronger.

00:37:09.225 --> 00:37:10.740
AUDIENCE: Right, what kills
me makes others stronger.

00:37:10.740 --> 00:37:13.890
But one of the takeaways I got
from your "Black Swan" book

00:37:13.890 --> 00:37:16.180
was that that's a fallacy,
that if you look at a

00:37:16.180 --> 00:37:18.150
population and you
stress it, and--

00:37:18.150 --> 00:37:18.815
NASSIM NICHOLAS TALEB:
That's excellent.

00:37:18.815 --> 00:37:20.730
AUDIENCE: --the weak ones die
out and you're left with the

00:37:20.730 --> 00:37:23.140
strong ones, but it's not really
true that the stress

00:37:23.140 --> 00:37:24.260
caused the strength.

00:37:24.260 --> 00:37:25.960
NASSIM NICHOLAS TALEB:
Exactly.

00:37:25.960 --> 00:37:28.170
It's the same point
I'm making.

00:37:28.170 --> 00:37:31.790
People think that what kills
me-- what didn't kill me makes

00:37:31.790 --> 00:37:34.130
me stronger, and I'm
saying it's wrong.

00:37:34.130 --> 00:37:38.670
It's typically because there is
a selection effect, not an

00:37:38.670 --> 00:37:39.260
improvement.

00:37:39.260 --> 00:37:41.650
Let me go through the history
of the mistakes made with

00:37:41.650 --> 00:37:43.080
anti-fragility.

00:37:43.080 --> 00:37:46.050
There's something in medicine
called hormesis.

00:37:46.050 --> 00:37:49.960
You give someone a drug, their
body overcompensates by

00:37:49.960 --> 00:37:52.560
getting stronger.

00:37:52.560 --> 00:37:55.880
A gentleman wrote something
on anti-fragility

00:37:55.880 --> 00:37:57.500
from a draft I had.

00:37:57.500 --> 00:38:01.310
He's a geneticist, and he
actually proved that what

00:38:01.310 --> 00:38:06.070
happens is that if a system gets
stronger, it's because

00:38:06.070 --> 00:38:09.920
some of the components
were destroyed.

00:38:09.920 --> 00:38:13.640
So when someone says
what killed me--

00:38:13.640 --> 00:38:16.190
what didn't kill me made me
stronger, it could often be

00:38:16.190 --> 00:38:19.170
that it killed the others who
were weaker, and therefore I

00:38:19.170 --> 00:38:21.490
have the illusion of getting
stronger, when in fact, it

00:38:21.490 --> 00:38:23.590
killed the others
who are weaker.

00:38:23.590 --> 00:38:24.650
That's the idea.

00:38:24.650 --> 00:38:27.240
It's a little subtle idea
which tells you that

00:38:27.240 --> 00:38:29.030
everything is by layers.

00:38:29.030 --> 00:38:32.000
I have cells, cells have protein
in them, and all that,

00:38:32.000 --> 00:38:36.610
and typically the weak needs to
always be destroyed for the

00:38:36.610 --> 00:38:38.140
system to improve.

00:38:38.140 --> 00:38:40.860
And this is how your body
improves, not because it

00:38:40.860 --> 00:38:42.600
overall improves under shock.

00:38:42.600 --> 00:38:43.660
It's because you are
killing things

00:38:43.660 --> 00:38:44.960
that are bad, typically.

00:38:44.960 --> 00:38:46.970
AUDIENCE: Thank you,
Professor Taleb.

00:38:46.970 --> 00:38:50.320
I think that your message about
our epistemic limitation

00:38:50.320 --> 00:38:51.320
is very important.

00:38:51.320 --> 00:38:55.880
And I had a question about
your view of libertarian

00:38:55.880 --> 00:38:58.810
movement, and how do you
think that your idea of

00:38:58.810 --> 00:39:02.500
anti-fragility fits into those
ideas of smaller government

00:39:02.500 --> 00:39:05.220
and more bottom up approach?

00:39:05.220 --> 00:39:06.130
NASSIM NICHOLAS TALEB:
That's excellent.

00:39:06.130 --> 00:39:08.460
So what I'm showing
here is actually--

00:39:08.460 --> 00:39:10.370
I don't know if it's a
libertarian view, but it's

00:39:10.370 --> 00:39:13.300
definitely a localist view in
favor city-states, a lot more

00:39:13.300 --> 00:39:16.070
robust, because of
the side effect.

00:39:16.070 --> 00:39:19.620
A small government works better,
not because it's small

00:39:19.620 --> 00:39:20.870
government, but because it's--

00:39:20.870 --> 00:39:22.860
you get the idea.

00:39:22.860 --> 00:39:24.560
Top down government
doesn't work.

00:39:24.560 --> 00:39:27.310
Now you can have probably a
dictatorship in a small

00:39:27.310 --> 00:39:29.530
village and it may work.

00:39:29.530 --> 00:39:35.700
So I cannot prove that it's
not private versus public.

00:39:35.700 --> 00:39:37.720
For me, it's large
versus small.

00:39:37.720 --> 00:39:42.120
Small has the ability to survive
and a large gets

00:39:42.120 --> 00:39:47.300
disproportionately weakened
by unexpected events.

00:39:47.300 --> 00:39:51.560
And thanks for linking it to
epistemic opacity, because

00:39:51.560 --> 00:39:55.390
this idea of fragility being
measurable solves the problem

00:39:55.390 --> 00:39:56.040
of opacity.

00:39:56.040 --> 00:39:59.180
I don't understand the
environment, but I can pretty

00:39:59.180 --> 00:40:01.542
much figure out I'm
fragile to it.

00:40:01.542 --> 00:40:02.474
Go ahead.

00:40:02.474 --> 00:40:04.975
AUDIENCE: So you said you didn't
believe in forecasts,

00:40:04.975 --> 00:40:07.310
so I won't ask you to
make a forecast.

00:40:07.310 --> 00:40:10.660
So what's in your portfolio?

00:40:10.660 --> 00:40:13.030
NASSIM NICHOLAS TALEB: I don't
want to answer the details of

00:40:13.030 --> 00:40:16.590
it because I'm talking about my
book and in a year it will

00:40:16.590 --> 00:40:20.170
change, so I can't
talk about that.

00:40:23.400 --> 00:40:25.650
I'll tell you that if I were
compelled to produce a

00:40:25.650 --> 00:40:29.310
forecast, but I don't
like to forecast.

00:40:29.310 --> 00:40:31.970
But anyway, the book tells
you what I do, so

00:40:31.970 --> 00:40:32.650
that's what I do.

00:40:32.650 --> 00:40:33.960
And it irritates the critics.

00:40:33.960 --> 00:40:35.790
Everything that irritates
books critics is

00:40:35.790 --> 00:40:37.040
wonderful for books.

00:40:39.330 --> 00:40:42.790
But again, consider this class
of phenomena that benefit from

00:40:42.790 --> 00:40:46.390
harm-- rumors love repression.

00:40:46.390 --> 00:40:50.370
Try to repress a rumor and
see what it will do.

00:40:50.370 --> 00:40:54.000
Go stand up and deny a rumor
and see when a politician

00:40:54.000 --> 00:40:56.310
says, we will not devalue.

00:40:56.310 --> 00:40:57.140
The rumor is wrong.

00:40:57.140 --> 00:40:59.100
You know what happens--
it's the best way

00:40:59.100 --> 00:41:00.550
for a rumor to spread.

00:41:00.550 --> 00:41:02.510
And same thing with books--

00:41:02.510 --> 00:41:04.090
try to ban them and
see what happens.

00:41:06.790 --> 00:41:10.240
There's some class
and I call it--

00:41:10.240 --> 00:41:11.320
what do I call it?--

00:41:11.320 --> 00:41:15.170
refractory love, where people
like in Proust where people

00:41:15.170 --> 00:41:16.580
have obsessive love.

00:41:16.580 --> 00:41:17.905
And the more you try
to repress it,

00:41:17.905 --> 00:41:19.140
the stronger it gets.

00:41:19.140 --> 00:41:22.390
A lot of things get stronger
under repression and belong to

00:41:22.390 --> 00:41:24.330
that class of anti-fragile
and it all can

00:41:24.330 --> 00:41:26.500
be mapped as convex.

00:41:26.500 --> 00:41:26.980
Yes?

00:41:26.980 --> 00:41:27.460
Go ahead.

00:41:27.460 --> 00:41:30.690
AUDIENCE: Some of the systems
that you mentioned, the

00:41:30.690 --> 00:41:31.280
difference of--

00:41:31.280 --> 00:41:34.690
I'm just trying to compare that
to the financial markets.

00:41:34.690 --> 00:41:37.770
If you have a period of
stability and all of sudden

00:41:37.770 --> 00:41:40.920
you get cancer, you usually
don't recover back yourself.

00:41:40.920 --> 00:41:43.420
Or if you have a fragile item,
it breaks down, it usually

00:41:43.420 --> 00:41:44.950
doesn't recover itself.

00:41:44.950 --> 00:41:46.820
But how would you compare that
to financial markets?

00:41:46.820 --> 00:41:49.771
It doesn't have an external
property that--

00:41:49.771 --> 00:41:50.490
NASSIM NICHOLAS TALEB: OK.

00:41:50.490 --> 00:41:52.570
Let me link this to the question
earlier, because now

00:41:52.570 --> 00:41:55.310
I remember that I didn't
give a full answer to

00:41:55.310 --> 00:41:56.690
the question earlier.

00:41:56.690 --> 00:42:00.060
A system that has a lot of
parts, independent, that break

00:42:00.060 --> 00:42:02.990
sequentially, is going
to improve.

00:42:02.990 --> 00:42:03.870
How?

00:42:03.870 --> 00:42:05.630
Take, for example,
transportation, or take

00:42:05.630 --> 00:42:07.210
engineering.

00:42:07.210 --> 00:42:10.990
Every bridge that collapses
makes every other bridge in

00:42:10.990 --> 00:42:12.740
the country safer.

00:42:12.740 --> 00:42:16.110
So the probability of a building
that collapses makes

00:42:16.110 --> 00:42:18.490
every building in the country,
or the probability of the next

00:42:18.490 --> 00:42:20.160
building collapsing smaller.

00:42:20.160 --> 00:42:23.120
Smaller or equal, but it
doesn't get worse.

00:42:23.120 --> 00:42:27.650
So when you have a system
composed of small units that

00:42:27.650 --> 00:42:32.450
break sequentially, fail without
contagion effects, the

00:42:32.450 --> 00:42:34.280
systems improves from failure.

00:42:34.280 --> 00:42:38.440
And, exactly as what kills me
makes others stronger, and

00:42:38.440 --> 00:42:41.390
that's a benign system or
a system that's actually

00:42:41.390 --> 00:42:42.080
anti-fragile.

00:42:42.080 --> 00:42:46.100
Now, take banking, take
large corporations.

00:42:46.100 --> 00:42:47.830
When one fails, the other--

00:42:47.830 --> 00:42:50.800
it increases the probability
of the other failing.

00:42:50.800 --> 00:42:53.370
Then the system doesn't
work well.

00:42:53.370 --> 00:42:57.490
That's one thing to answer him
and get into your point.

00:42:57.490 --> 00:42:59.740
He's asking me whether financial
markets, what

00:42:59.740 --> 00:43:01.310
benefits they have?

00:43:01.310 --> 00:43:03.140
Well, people think that they're
good at providing

00:43:03.140 --> 00:43:03.900
information.

00:43:03.900 --> 00:43:06.020
In fact, they're great at
masking information and that's

00:43:06.020 --> 00:43:07.270
why it works.

00:43:09.660 --> 00:43:10.520
It prevents panic.

00:43:10.520 --> 00:43:13.670
Say if someone is predictable
and comes home

00:43:13.670 --> 00:43:15.820
every day at 5:30.

00:43:15.820 --> 00:43:18.710
Boom, you can set your
watch, he walked in.

00:43:18.710 --> 00:43:20.390
And one day he's late?

00:43:20.390 --> 00:43:21.780
What would happen?

00:43:21.780 --> 00:43:24.500
Two minutes and everybody freaks
out, he's not here,

00:43:24.500 --> 00:43:28.050
where someone more random in
his arrival time would not

00:43:28.050 --> 00:43:29.310
cause a panic.

00:43:29.310 --> 00:43:31.480
Well, it's the same
thing with prices.

00:43:31.480 --> 00:43:33.050
That's one of the aspects.

00:43:33.050 --> 00:43:38.940
Another thing with prices is
that volatility prevents big

00:43:38.940 --> 00:43:42.380
collapses because it's
just like a forest.

00:43:42.380 --> 00:43:43.680
You have flammable materials.

00:43:43.680 --> 00:43:46.480
Steady, small forest fires
clean up that flammable

00:43:46.480 --> 00:43:48.570
material and don't let
it accumulate.

00:43:48.570 --> 00:43:51.200
But what happened with Greenspan
by stabilizing

00:43:51.200 --> 00:43:52.170
everything--

00:43:52.170 --> 00:43:54.540
no volatility or minimized
volatility, something they

00:43:54.540 --> 00:43:55.580
called The Great
Moderation that

00:43:55.580 --> 00:43:57.620
resembles the Great Peace--

00:43:57.620 --> 00:44:01.840
you had a lot of hidden risk in
the system, very explosive,

00:44:01.840 --> 00:44:02.820
ready to explode.

00:44:02.820 --> 00:44:05.530
In effect, we saw what
happened-- they blew up.

00:44:05.530 --> 00:44:08.110
So this is where financial
markets, by bringing

00:44:08.110 --> 00:44:11.812
volatility, clean up the
system periodically.

00:44:11.812 --> 00:44:12.764
That explained it.

00:44:12.764 --> 00:44:14.192
Thanks.

00:44:14.192 --> 00:44:15.660
AUDIENCE: Thanks a lot.

00:44:15.660 --> 00:44:19.090
The question I had was how does
your work reflect on how

00:44:19.090 --> 00:44:21.970
you think about conglomerates
and family businesses,

00:44:21.970 --> 00:44:24.010
especially in the developing
world where there seems to be

00:44:24.010 --> 00:44:26.930
a high concentration of
preservation and a model where

00:44:26.930 --> 00:44:28.300
they actually look
for stability

00:44:28.300 --> 00:44:30.485
versus choosing variation?

00:44:30.485 --> 00:44:32.180
NASSIM NICHOLAS TALEB: This
is a good question.

00:44:32.180 --> 00:44:33.690
I don't know much about--

00:44:33.690 --> 00:44:37.380
I looked at family data for
businesses, and effectively in

00:44:37.380 --> 00:44:41.100
what we call today the
OECD countries.

00:44:41.100 --> 00:44:44.760
They have stayed in power
because they have what I call

00:44:44.760 --> 00:44:47.490
skin in the game, among
other things

00:44:47.490 --> 00:44:51.970
and among other qualities.

00:44:51.970 --> 00:44:52.610
Now, conglomerates--

00:44:52.610 --> 00:44:55.000
I have no idea.

00:44:55.000 --> 00:44:58.780
I just like the conglomerate I
work for-- namely, the owner

00:44:58.780 --> 00:45:03.950
of Random House, Bertelsmann,
because they're not listed in

00:45:03.950 --> 00:45:05.200
the market.

00:45:07.270 --> 00:45:09.790
Although I like market
volatility, I don't like

00:45:09.790 --> 00:45:13.720
people to fit the company to
the security analysts that

00:45:13.720 --> 00:45:15.410
don't understand hidden risks.

00:45:15.410 --> 00:45:18.440
And the stock market tends to
push companies to hide risks,

00:45:18.440 --> 00:45:21.180
and it fails, because the
security analysts don't have

00:45:21.180 --> 00:45:24.884
the tool to analyse second
order effects.

00:45:24.884 --> 00:45:25.800
Go ahead.

00:45:25.800 --> 00:45:29.300
AUDIENCE: How much of the
anti-fragility phenomenon that

00:45:29.300 --> 00:45:33.740
you're talking about across
systems is really about

00:45:33.740 --> 00:45:36.220
evolutionary learning
in that the two

00:45:36.220 --> 00:45:38.920
curves, knowledge versus--

00:45:38.920 --> 00:45:40.860
I forget what the other one was
labeled, but it was the

00:45:40.860 --> 00:45:42.510
anti-fragile curve--

00:45:42.510 --> 00:45:46.365
is really about two different
forms of acquiring knowledge.

00:45:49.010 --> 00:45:51.800
One is for acquiring articulate
knowledge through

00:45:51.800 --> 00:45:55.120
articulate processes and the
other one is for acquiring

00:45:55.120 --> 00:45:58.450
inarticulate knowledge, the kind
of knowledge that Hayek

00:45:58.450 --> 00:46:02.260
talks about, where the system
learns without the human

00:46:02.260 --> 00:46:05.476
beings necessarily being aware
of what it learns.

00:46:05.476 --> 00:46:06.920
NASSIM NICHOLAS TALEB: That's
a good question.

00:46:06.920 --> 00:46:09.400
He's asking me how much of--
there are two types of

00:46:09.400 --> 00:46:14.880
knowledge, [INAUDIBLE],
knowledge top down, bottom up,

00:46:14.880 --> 00:46:18.830
heuristic knowledge versus what
we call propositional

00:46:18.830 --> 00:46:24.040
knowledge, or things that aren't
formalized, and so on.

00:46:24.040 --> 00:46:26.240
There's been a dichotomy through
history between these

00:46:26.240 --> 00:46:29.630
two [INAUDIBLE], a
lot of people.

00:46:29.630 --> 00:46:31.870
But the first person who
discovered it-- let me give

00:46:31.870 --> 00:46:34.480
you the background--
is Nietzsche.

00:46:34.480 --> 00:46:37.280
Nietzsche had [INAUDIBLE]

00:46:37.280 --> 00:46:40.410
between-- actually, even Seneca
discovered it, but we

00:46:40.410 --> 00:46:41.590
attribute it to Nietzsche.

00:46:41.590 --> 00:46:44.600
When he was 25, he wrote the
most beautiful book probably

00:46:44.600 --> 00:46:49.670
of the century, "The Birth of
Tragedy," by showing tension

00:46:49.670 --> 00:46:56.740
at humans between the rational
Apollonian and the deep, dark

00:46:56.740 --> 00:47:02.540
unexplainable force,
the Dionysian--

00:47:02.540 --> 00:47:05.710
depends if you're British or
American how you pronounce it,

00:47:05.710 --> 00:47:10.800
from Dionysus, the god of wine
and [INAUDIBLE] thing.

00:47:10.800 --> 00:47:11.385
And he actually--

00:47:11.385 --> 00:47:13.790
I think Nietzsche is the one
who used the word first,

00:47:13.790 --> 00:47:15.620
creative destruction.

00:47:15.620 --> 00:47:17.060
Nietzsche, not [INAUDIBLE].

00:47:17.060 --> 00:47:19.530
An economist cannot come up
with something that deep.

00:47:19.530 --> 00:47:23.600
So Nietzsche spoke about that,
and to continue, he went after

00:47:23.600 --> 00:47:29.120
Socrates for saying whatever
you cannot explain isn't

00:47:29.120 --> 00:47:30.740
necessarily stupid.

00:47:30.740 --> 00:47:33.280
And effectively in my
book, Fat Tony has

00:47:33.280 --> 00:47:35.470
a debate with Socrates.

00:47:35.470 --> 00:47:38.120
You can imagine a guy from
Brooklyn debating a Greek

00:47:38.120 --> 00:47:41.260
philosopher, and I'll let you
guess who's going to win the

00:47:41.260 --> 00:47:43.180
debate along these lines.

00:47:43.180 --> 00:47:45.520
So effectively I go along these
lines, except that what

00:47:45.520 --> 00:47:47.040
I've done is very simple.

00:47:47.040 --> 00:47:51.380
I don't have a theory in
here of anti-fragility.

00:47:51.380 --> 00:47:53.450
People can talk about complex
system, however they are.

00:47:53.450 --> 00:47:55.860
I have a descriptive
detection.

00:47:55.860 --> 00:47:59.910
This here, I proved very simply,
that I can detect

00:47:59.910 --> 00:48:02.950
fragility through a second
order derivative.

00:48:02.950 --> 00:48:05.900
So in a way what I have is more
like phenomenology, which

00:48:05.900 --> 00:48:10.380
is not at the level of a theory
but something lower--

00:48:10.380 --> 00:48:14.400
a way to map objects in order to
work with a world we don't

00:48:14.400 --> 00:48:14.880
understand.

00:48:14.880 --> 00:48:17.500
So in a way, I don't have a
theory how things come from,

00:48:17.500 --> 00:48:22.800
but I of integrated this
dichotomy you have between the

00:48:22.800 --> 00:48:25.960
bottom up, unexplainable, we
don't know how we do it.

00:48:25.960 --> 00:48:28.400
There was one thing I would like
to mention, since there's

00:48:28.400 --> 00:48:31.200
time for another question--
one important thing--

00:48:31.200 --> 00:48:35.440
that effectively the longer
we've been doing something

00:48:35.440 --> 00:48:40.270
that we don't understand, the
longer we will do it.

00:48:40.270 --> 00:48:44.750
In the book, I say time is the
only detector of fragility.

00:48:44.750 --> 00:48:45.860
Remember one thing--

00:48:45.860 --> 00:48:46.680
time is volatility.

00:48:46.680 --> 00:48:48.330
You agree?

00:48:48.330 --> 00:48:50.390
Time involved mathematically--

00:48:50.390 --> 00:48:51.300
they all are the same.

00:48:51.300 --> 00:48:53.940
Disorder, time, entropy,
volatility--

00:48:53.940 --> 00:48:56.990
approximately, I call them
siblings, brothers.

00:48:56.990 --> 00:48:59.750
They're not exactly the same,
but they're like fraternal

00:48:59.750 --> 00:49:00.460
twin brothers.

00:49:00.460 --> 00:49:01.490
OK

00:49:01.490 --> 00:49:06.060
So with time, what was fragile
eventually will break.

00:49:06.060 --> 00:49:07.450
So it's a very simple law.

00:49:07.450 --> 00:49:12.900
Whatever is not perishable,
namely an idea, will have a

00:49:12.900 --> 00:49:16.270
life expectancy that increases
with time, which is shocking

00:49:16.270 --> 00:49:21.710
for technologies, but let me
explain the rationale.

00:49:21.710 --> 00:49:24.800
If you see a human and he's 40
years old, you can safely say,

00:49:24.800 --> 00:49:29.160
not knowing his history, and
he's not ill, unconditionally,

00:49:29.160 --> 00:49:32.410
that he has an extra
50 years to go.

00:49:32.410 --> 00:49:33.340
You agree?

00:49:33.340 --> 00:49:35.300
That's mortality tables,
condition

00:49:35.300 --> 00:49:37.560
and mortality tables.

00:49:37.560 --> 00:49:40.190
He lives another year.

00:49:40.190 --> 00:49:42.110
You know that his life
expectancy has decreased by

00:49:42.110 --> 00:49:44.260
little less than a year.

00:49:44.260 --> 00:49:47.530
So his life expectancy decreases
every day he lives.

00:49:47.530 --> 00:49:50.520
If I look at a technology, how
old-- all of you need to know.

00:49:50.520 --> 00:49:50.820
How old?

00:49:50.820 --> 00:49:51.780
40 days.

00:49:51.780 --> 00:49:52.390
Technology--

00:49:52.390 --> 00:49:56.130
a book and idea [INAUDIBLE]
that are not perishable.

00:49:56.130 --> 00:49:58.770
Our genes, for example--

00:49:58.770 --> 00:50:00.680
not our bodies.

00:50:00.680 --> 00:50:01.960
How old, technology?

00:50:01.960 --> 00:50:02.600
40 years.

00:50:02.600 --> 00:50:05.850
Very good-- it has
40 years to go.

00:50:05.850 --> 00:50:08.420
Next year, 41 years--

00:50:08.420 --> 00:50:10.120
at least 41 years to go.

00:50:10.120 --> 00:50:12.860
So the life expectancy of
technology increases every

00:50:12.860 --> 00:50:15.830
day, an idea of everything,
believe it or not.

00:50:15.830 --> 00:50:20.060
So this is why we have bicycles
and they probably

00:50:20.060 --> 00:50:25.170
will live longer than the cars,
cars more than planes.

00:50:25.170 --> 00:50:28.290
And of course, now we know
that the regular plane's

00:50:28.290 --> 00:50:31.060
better than the supersonic
planes.

00:50:31.060 --> 00:50:33.270
And I'm talking about this
here in Silicon Valley.

00:50:33.270 --> 00:50:33.840
Why?

00:50:33.840 --> 00:50:35.475
Well, very simply because--

00:50:38.330 --> 00:50:39.870
and we don't understand why.

00:50:39.870 --> 00:50:41.140
We don't have to understand
anything.

00:50:41.140 --> 00:50:46.820
Time-- there's an intelligence
of time that's at work there.

00:50:46.820 --> 00:50:49.520
A book that had been in print
for 3,000 years--

00:50:49.520 --> 00:50:53.460
in print, or at least read
for 3,000 years--

00:50:53.460 --> 00:50:56.600
that you get in hotel rooms
still, will probably be read

00:50:56.600 --> 00:50:58.310
for 3,000 years.

00:50:58.310 --> 00:51:02.810
Regardless of what the latest
intellectual tell me about the

00:51:02.810 --> 00:51:04.040
rationality or not
rationality--

00:51:04.040 --> 00:51:05.070
I don't believe in
rationality.

00:51:05.070 --> 00:51:06.320
I believe in fragility.

00:51:09.270 --> 00:51:10.980
Things like that you could
apply to technology.

00:51:10.980 --> 00:51:13.740
You can say the red car, the
first red convertible car, was

00:51:13.740 --> 00:51:14.570
born when--

00:51:14.570 --> 00:51:16.200
38 and 1/2 years ago?

00:51:16.200 --> 00:51:18.650
That's 38 years ago,
approximately.

00:51:18.650 --> 00:51:21.900
But of course you'd be shocked
now if you see how much of

00:51:21.900 --> 00:51:25.250
what we have today resembles
ancient days.

00:51:25.250 --> 00:51:31.200
We still use watches, glasses,
3,000 years old, chairs,

00:51:31.200 --> 00:51:33.950
desks, silverware.

00:51:33.950 --> 00:51:36.520
We're trying to cook like
our ancients did.

00:51:36.520 --> 00:51:38.780
I have in the book a picture
of a kitchen

00:51:38.780 --> 00:51:41.970
from Pompeii in Italy.

00:51:41.970 --> 00:51:45.020
It's 2,000 years old and it's
no different from a good

00:51:45.020 --> 00:51:46.890
Italian restaurant's kitchen.

00:51:46.890 --> 00:51:48.900
So this is to tell you that
there are things we don't

00:51:48.900 --> 00:51:54.720
understand in the world, but we
can understand them via--

00:51:57.520 --> 00:51:59.560
there's no rational means to
understand why people use

00:51:59.560 --> 00:52:02.660
something like a technology, but
we can understand via just

00:52:02.660 --> 00:52:05.635
fragility, the concept of
fragility via time.

00:52:05.635 --> 00:52:07.350
AUDIENCE: So I'd like to ask--

00:52:07.350 --> 00:52:08.580
I suppose not, really.

00:52:08.580 --> 00:52:10.720
It's a separate question
more than a followup.

00:52:10.720 --> 00:52:16.210
But returning to the great
debate between Hayek and

00:52:16.210 --> 00:52:20.630
Keynes, especially with regard
to the Great Depression,

00:52:20.630 --> 00:52:21.730
oversimplifying--

00:52:21.730 --> 00:52:24.810
the way I view is that the
Austrians were saying that

00:52:24.810 --> 00:52:29.030
Hayek was saying, OK, you've
got this cascading failure.

00:52:29.030 --> 00:52:34.090
Let it fail, because systems
that fail under cascading

00:52:34.090 --> 00:52:36.230
failure need to be beaten
out of the system.

00:52:36.230 --> 00:52:37.580
It's the only way it's
going to learn.

00:52:41.000 --> 00:52:44.170
The basic Austrian point of view
was we're better off in

00:52:44.170 --> 00:52:47.270
the long run, which is the
long run that Keynes was

00:52:47.270 --> 00:52:49.715
responding to.

00:52:49.715 --> 00:52:50.660
NASSIM NICHOLAS TALEB:
This I agree.

00:52:50.660 --> 00:52:52.110
Because we're short on time,
so I'm going to answer you

00:52:52.110 --> 00:52:53.040
very quickly.

00:52:53.040 --> 00:52:55.410
He's comparing system--

00:52:55.410 --> 00:52:57.920
I think that it's quite
artificial to say Keynes

00:52:57.920 --> 00:52:58.820
versus Hayek.

00:52:58.820 --> 00:53:00.830
Keynes was not an idiot.

00:53:00.830 --> 00:53:05.080
He was a very smart human, and
he would think differently--

00:53:05.080 --> 00:53:07.630
vastly smaller than people who
write for New York Times and

00:53:07.630 --> 00:53:11.540
claim that Keynes
said something.

00:53:11.540 --> 00:53:14.590
And then also, of course, on
the risks of the system, I

00:53:14.590 --> 00:53:17.970
also have to say that the
problem is you can't suddenly

00:53:17.970 --> 00:53:20.060
stop doing things.

00:53:20.060 --> 00:53:24.660
If you look at medicine, the
rule is if you're slightly

00:53:24.660 --> 00:53:27.230
ill, let things take care of
yourself, because whatever

00:53:27.230 --> 00:53:29.490
medicine you're going to put
in probably will harm you

00:53:29.490 --> 00:53:31.610
probabilistically a lot
more than help you.

00:53:31.610 --> 00:53:34.180
But if you have cancer or
you're very ill, see 10

00:53:34.180 --> 00:53:36.016
doctors, not one, 10.

00:53:36.016 --> 00:53:37.100
You get the idea?

00:53:37.100 --> 00:53:41.230
So what happened was
interventionism, was statism

00:53:41.230 --> 00:53:42.810
intervention, overintervention.

00:53:42.810 --> 00:53:45.860
The state is never there, the
interventionist is never there

00:53:45.860 --> 00:53:48.700
when really needed because
of depleted resources.

00:53:48.700 --> 00:53:51.160
And this is what happened
to us, by the way.

00:53:51.160 --> 00:53:52.620
The money's gone, all right?

00:53:52.620 --> 00:53:54.570
So it's a different problem.

00:53:54.570 --> 00:53:59.200
I don't know if I can claim with
this thinking to be fully

00:53:59.200 --> 00:54:02.110
against state intervention,
but I would say the state

00:54:02.110 --> 00:54:02.890
needs to intervene.

00:54:02.890 --> 00:54:06.780
It's got to be extreme
circumstances and for a very

00:54:06.780 --> 00:54:11.760
temporary situation to just
avoid pain, starvation, and

00:54:11.760 --> 00:54:12.520
stuff like that.

00:54:12.520 --> 00:54:15.960
If I use the same linear
argument, reducing extreme

00:54:15.960 --> 00:54:18.080
unhappiness is different from
raising happiness--

00:54:18.080 --> 00:54:20.340
two different animals.

00:54:20.340 --> 00:54:23.530
We can take one more
question, I guess.

00:54:23.530 --> 00:54:24.490
We have one.

00:54:24.490 --> 00:54:27.350
We started at three, so
we have three minutes.

00:54:27.350 --> 00:54:29.391
That's what I owe you.

00:54:29.391 --> 00:54:34.010
AUDIENCE: When you talk about
finding fragility by talking

00:54:34.010 --> 00:54:35.630
in the second derivative?

00:54:35.630 --> 00:54:37.620
Can you give some more details,
like the second

00:54:37.620 --> 00:54:37.940
derivative?

00:54:37.940 --> 00:54:38.240
NASSIM NICHOLAS TALEB: Yes.

00:54:38.240 --> 00:54:39.370
It's very simple.

00:54:39.370 --> 00:54:45.050
You take a company, you
lower sales by 10%,

00:54:45.050 --> 00:54:46.460
they lose $100 million.

00:54:46.460 --> 00:54:51.120
You lower sales by an extra 10%,
they lose $500 million.

00:54:51.120 --> 00:54:52.830
Accelerating losses--

00:54:52.830 --> 00:54:55.530
it means they're going to be a
lot more harmed by an adverse

00:54:55.530 --> 00:54:56.990
event than a regular company.

00:54:56.990 --> 00:54:57.970
It's a very simple test.

00:54:57.970 --> 00:55:01.100
It's so simple that people
were ashamed of

00:55:01.100 --> 00:55:02.860
telling me I was right.

00:55:02.860 --> 00:55:06.430
You see, very simple--
acceleration.

00:55:06.430 --> 00:55:08.210
Take the stock market--

00:55:08.210 --> 00:55:09.485
take a portfolio.

00:55:09.485 --> 00:55:12.850
The market's down 5%,
I lose a million.

00:55:12.850 --> 00:55:16.460
The market is down 10%,
I lose $5 million.

00:55:16.460 --> 00:55:17.580
I'm fragile.

00:55:17.580 --> 00:55:18.780
It's that simple.

00:55:18.780 --> 00:55:20.540
It's the same argument when
you say that if the market

00:55:20.540 --> 00:55:23.640
goes up 10%, do I make
more that if the

00:55:23.640 --> 00:55:25.120
market went down 10%?

00:55:25.120 --> 00:55:26.580
I'm anti-fragile.

00:55:26.580 --> 00:55:28.740
It's the same thing with
a lot of situations.

00:55:28.740 --> 00:55:30.320
So that brings fragility--

00:55:30.320 --> 00:55:31.570
you can measure it that way.

00:55:31.570 --> 00:55:32.555
Size cause fragility.

00:55:32.555 --> 00:55:34.030
You can measure it that way.

00:55:34.030 --> 00:55:35.280
Thanks.

