WEBVTT

1
00:00:00.890 --> 00:00:01.581
In this video,

2
00:00:01.581 --> 00:00:06.160
we'll quickly look at an alternative to a conditional random fields for sequence

3
00:00:06.170 --> 00:00:09.490
classification,
no one that does the maximum entropy Markov

4
00:00:10.020 --> 00:00:10.853
<v 0>model.</v>

5
00:00:12.840 --> 00:00:16.930
<v 1>So we've mainly discussed conditional random fields.
They have one advantage,</v>

6
00:00:16.980 --> 00:00:21.600
which is that they are,
uh,
descriptively trained.
Uh,

7
00:00:21.630 --> 00:00:22.890
and as we've seen before,

8
00:00:22.891 --> 00:00:26.190
we should expect that for problem where we have a lot of data,
uh,

9
00:00:26.220 --> 00:00:30.690
that this is a better approach than training a model.
Generatively and,

10
00:00:30.691 --> 00:00:34.920
uh,
but we haven't really discussed whether there were other discriminative

11
00:00:34.950 --> 00:00:37.380
alternatives to the conditional random fields.

12
00:00:37.890 --> 00:00:40.500
So let's look at one in this video knowing that the,

13
00:00:40.530 --> 00:00:42.570
as the maximum entropy Markov model.

14
00:00:45.390 --> 00:00:45.740
<v 0>Okay.</v>

15
00:00:45.740 --> 00:00:50.740
<v 1>So the maximum entropy Markov model or m e m m is a different from the</v>

16
00:00:51.441 --> 00:00:54.830
conditioner and feel for a one main reason,

17
00:00:54.831 --> 00:00:58.450
which is that it is directed.
Uh,
so,
uh,

18
00:00:58.520 --> 00:01:03.110
we see here and illustration of the mem as a Bayesian network,

19
00:01:03.620 --> 00:01:07.400
which means that now we have random variables that aren't our nodes in the

20
00:01:07.401 --> 00:01:09.270
network.
And,
uh,

21
00:01:09.350 --> 00:01:14.330
the edges between the nodes are actually directed and the direction of the
edges,

22
00:01:14.420 --> 00:01:18.440
uh,
essentially the straight,
the generative story associated behind the model.

23
00:01:18.920 --> 00:01:19.311
So in,

24
00:01:19.311 --> 00:01:24.311
in and a m e m m d a way we assume that the data has been generated is that,

25
00:01:26.470 --> 00:01:28.580
uh,
given the whole sequence,

26
00:01:28.581 --> 00:01:33.470
so an emm emm does not define the way that the input sequence was,

27
00:01:33.800 --> 00:01:37.460
uh,
was,
uh,
was generated.

28
00:01:37.550 --> 00:01:41.090
So it's a conditional model that does not define a p of X.

29
00:01:42.200 --> 00:01:44.870
And a,
so given some input sequence,

30
00:01:44.900 --> 00:01:48.410
it assumes that the sequence of labels was generated from left to right.

31
00:01:48.410 --> 00:01:51.440
So the first sequence,
sorry,
the first label,

32
00:01:51.441 --> 00:01:55.610
why one was generated only from the information in x one and x two.

33
00:01:55.611 --> 00:01:56.444
So that's four a,

34
00:01:56.790 --> 00:02:01.160
a similar model then the CRF with the context window radius one.

35
00:02:01.580 --> 00:02:06.580
So why one was generated and then y two was generated from x one x two and x

36
00:02:06.891 --> 00:02:08.510
three and y one.

37
00:02:08.990 --> 00:02:13.990
So all of these guys were able to influence what value for the second label was

38
00:02:15.501 --> 00:02:19.100
generated.
Uh,
and then wide three was,

39
00:02:19.470 --> 00:02:21.160
uh,
then,
uh,

40
00:02:21.230 --> 00:02:25.220
generated and the value of y three was generated from,
again,

41
00:02:25.221 --> 00:02:30.221
y two x two x three and x four and so on until we reached the end of the

42
00:02:30.951 --> 00:02:31.784
sequence.

43
00:02:32.910 --> 00:02:33.300
<v 0>Yeah.</v>

44
00:02:33.300 --> 00:02:38.100
<v 1>So,
uh,
so it is a mark of,
in the sense that,
uh,
the,
uh,</v>

45
00:02:38.130 --> 00:02:42.810
distribution of one label here is a dependent also on the label,
uh,

46
00:02:42.870 --> 00:02:46.770
previously,
um,
and the,
uh,
transition.

47
00:02:46.771 --> 00:02:51.630
So it's a mark of model similarly to a hidden Markov model.
Uh,

48
00:02:51.660 --> 00:02:53.880
but the difference is that in the hidden Markov model,

49
00:02:54.060 --> 00:02:58.890
we would have arrows going down like this from the labels to,
uh,
the,

50
00:02:58.910 --> 00:03:03.610
uh,
input.
We're asked for a maximum entropy Markov model.

51
00:03:03.790 --> 00:03:05.830
The arrows are this way instead.

52
00:03:05.860 --> 00:03:10.120
So we don't actually define the distribution over the inputs and we just defined

53
00:03:10.121 --> 00:03:13.870
it conditional distribution over the labels.

54
00:03:13.900 --> 00:03:16.900
And the conditional story goes from,
you know,

55
00:03:16.901 --> 00:03:21.010
we assume that there was some generative process for the old inputs and then the

56
00:03:21.011 --> 00:03:23.410
sequence which generated instead of the other way around.

57
00:03:24.400 --> 00:03:28.330
And so more specifically,
the probability of a sequence of label,

58
00:03:28.331 --> 00:03:33.331
why given the sequence of input x is going to be this product of conditional

59
00:03:34.270 --> 00:03:38.080
probabilities over why k given the previous label,

60
00:03:38.081 --> 00:03:42.470
why k minus one and some information in X.
So,
uh,

61
00:03:42.580 --> 00:03:45.970
in the case here,
sometimes,
uh,
you know,
for why one,

62
00:03:46.020 --> 00:03:50.920
it was only x one and x two that,
uh,
influenced the probability of y one.

63
00:03:51.310 --> 00:03:54.320
But in general it could depend on the whole sequence or a,

64
00:03:54.380 --> 00:03:58.110
so I just use a general form here and,
uh,

65
00:03:58.340 --> 00:04:00.730
what will be used for the conditional distribution,

66
00:04:00.731 --> 00:04:05.090
the way they would be factored a would be through a,
uh,

67
00:04:05.140 --> 00:04:09.070
something very similar to either a logistic regression or a neural network.

68
00:04:09.370 --> 00:04:14.190
So you would essentially have a term that would depend similar to our,
uh,

69
00:04:14.320 --> 00:04:17.830
urinary luck factors that would depend on some information in the input.

70
00:04:18.280 --> 00:04:23.170
And then plus something similar to a pairwise factor where,
um,

71
00:04:23.260 --> 00:04:28.260
given the value at the previous step in the sequence came on as one,

72
00:04:29.470 --> 00:04:30.320
this,
uh,

73
00:04:30.340 --> 00:04:34.360
we could express a preference for what the value we think would be most likely

74
00:04:34.361 --> 00:04:37.510
at Viking.
And then we will normalize this.

75
00:04:37.570 --> 00:04:41.500
And now the normalization constant here would depend not just on x,

76
00:04:41.501 --> 00:04:44.860
but also on the value of Y K minus one.

77
00:04:44.980 --> 00:04:49.450
So the novelization constant here,
that would be the sum over the numerator,

78
00:04:49.870 --> 00:04:54.130
uh,
uh,
over all the potential values for just why king.

79
00:04:54.430 --> 00:04:58.240
So here we don't have a partition function over the where we have a summation

80
00:04:58.241 --> 00:04:59.590
over all sequences.

81
00:04:59.830 --> 00:05:04.830
We have only a sum over the value of the label for the current position for the,

82
00:05:05.270 --> 00:05:06.460
the given conditional.

83
00:05:09.430 --> 00:05:13.270
So this is a model that's not too complicated to train,
uh,

84
00:05:13.300 --> 00:05:18.130
but it has one problem which is known as the label bias problem.
So,

85
00:05:18.190 --> 00:05:19.023
uh,

86
00:05:19.210 --> 00:05:23.320
essentially intuitively when it means is that the observations that are far away

87
00:05:23.321 --> 00:05:27.760
in the sequence will not impact predictions that we would be making,
uh,

88
00:05:27.830 --> 00:05:30.460
early in the sequence.
And this could be,

89
00:05:30.470 --> 00:05:35.050
this can be illustrated in this example here where we actually have,

90
00:05:35.080 --> 00:05:39.250
and we can show that the marginal probability of the third label,

91
00:05:39.280 --> 00:05:43.210
given the whole sequence actually only depends,

92
00:05:43.240 --> 00:05:46.870
it can be reduced to the conditional probability of y three,

93
00:05:47.140 --> 00:05:51.220
given only the first four elements in the sequence.

94
00:05:51.460 --> 00:05:55.750
So I in particular,
because I have a context window that goes on the up to here,

95
00:05:56.560 --> 00:06:00.260
well then this,
um,
uh,

96
00:06:00.290 --> 00:06:04.940
this label here and this label here,
it can be marginalized out.
So,

97
00:06:05.720 --> 00:06:07.520
uh,
if I wanted,

98
00:06:07.521 --> 00:06:12.140
so I want to know what's the conditional probability of throwing some mink of y

99
00:06:12.170 --> 00:06:17.170
three given x one x two x three x four x five that to do this and we need to

100
00:06:18.591 --> 00:06:22.910
marginalize over these labels here and these labels here.

101
00:06:23.930 --> 00:06:26.030
Now if,
uh,
I can,

102
00:06:26.240 --> 00:06:30.620
if I marginalize those out that I can't really reduce anything because these

103
00:06:30.621 --> 00:06:34.890
depend on these,
then they will,
uh,
they will,
uh,

104
00:06:34.940 --> 00:06:39.470
have an impact on why three through,
why one?
However,

105
00:06:39.471 --> 00:06:41.870
from this,
because,
uh,

106
00:06:41.900 --> 00:06:44.570
the arrows is directed like this and like that,

107
00:06:45.230 --> 00:06:49.550
if I marginalize over why fi,
uh,
then,
uh,

108
00:06:49.610 --> 00:06:52.910
it's actually equivalent to just removing that note.

109
00:06:53.990 --> 00:06:54.710
Uh,

110
00:06:54.710 --> 00:06:59.710
and that's because if I write out the full expression for the probable the a of

111
00:07:00.861 --> 00:07:02.180
everything including Wifi,

112
00:07:03.010 --> 00:07:07.610
then this marginalizes into a conditional that only involves wifi.
And,
uh,

113
00:07:07.790 --> 00:07:12.570
this term actually needs to sum to one.
So I can just,
uh,
some,

114
00:07:12.571 --> 00:07:14.960
some it out,
uh,
some that turnout.

115
00:07:16.250 --> 00:07:19.670
And then if I do the same thing with why for a,

116
00:07:19.671 --> 00:07:23.510
so now I have is essentially I have a simpler graphical model that does not

117
00:07:23.511 --> 00:07:28.070
include Wifi and then they can also integrate out why four because now it's the

118
00:07:28.071 --> 00:07:33.071
last in my sort of hierarchy or random variable is the last one which doesn't

119
00:07:33.621 --> 00:07:36.980
have any descendants now.
And so I can also integrate it out,

120
00:07:37.280 --> 00:07:40.820
which means that this would yield a simpler graph,

121
00:07:42.470 --> 00:07:43.303
my bad.

122
00:07:43.550 --> 00:07:48.550
And so now we see that [inaudible] is not connected anymore to y three and a,

123
00:07:50.601 --> 00:07:55.601
so for that reason we have that y three given x is actually just a,

124
00:07:55.880 --> 00:08:00.260
sorry,
p of y three given this is just pure y three given x one,
two x four.

125
00:08:01.160 --> 00:08:04.610
So I'm going fairly quickly over this.
Uh,
um,

126
00:08:05.060 --> 00:08:09.560
those that are familiar with directed graphical model might see why this is not,

127
00:08:09.590 --> 00:08:13.700
you can look at a machine learning textbook on directed graphical models.

128
00:08:14.940 --> 00:08:16.330
Uh,
but that's,
you know,

129
00:08:16.450 --> 00:08:20.060
the main takeaway message here is that maximum entropy Markov models,

130
00:08:20.061 --> 00:08:23.840
while they might be easier to train,
and I'm just stating this,

131
00:08:23.841 --> 00:08:27.710
I haven't really described why,
but they're actually fairly simple to train.
Uh,

132
00:08:27.740 --> 00:08:28.730
they have a problem,

133
00:08:28.731 --> 00:08:33.530
which is that predictions in early positions in the sequence are actually not

134
00:08:33.531 --> 00:08:37.940
dependent on observations further away in the sequence.
And so they're not,

135
00:08:37.941 --> 00:08:38.511
in a sense,

136
00:08:38.511 --> 00:08:42.560
fully leveraging all of the information that might be helpful for predicting a

137
00:08:42.561 --> 00:08:43.940
label at a given position.

