WEBVTT
Kind: captions
Language: en

00:00:00.150 --> 00:00:03.130
Let's get back to the map of our models.

00:00:03.130 --> 00:00:09.260
We've so far built three different models and used several validation methods,

00:00:09.260 --> 00:00:14.510
including ROC curves, to choose the model that performs best.

00:00:14.510 --> 00:00:18.090
We could end our investigation here.

00:00:18.090 --> 00:00:20.460
However, we can ask a further question.

00:00:21.520 --> 00:00:25.860
Will changing the classes change the model?

00:00:25.860 --> 00:00:28.430
Let's investigate this a little bit further.

00:00:29.460 --> 00:00:32.369
To investigate this question a little bit further,

00:00:32.369 --> 00:00:37.540
we come back to our original point where we started building our models.

00:00:37.540 --> 00:00:39.660
To continue that investigation,

00:00:39.660 --> 00:00:44.600
we'll now build new classifiers by redefining the classes.

00:00:44.600 --> 00:00:50.030
Then we'll use different validation metrics and choose a new model.

00:00:50.030 --> 00:00:53.830
At this point, we have our entire map of our model-building and

00:00:53.830 --> 00:00:55.520
validation process.

00:00:55.520 --> 00:01:00.340
Let's investigate this end a little bit more to see what metrics we

00:01:00.340 --> 00:01:04.819
can use to validate models with our new classes.

00:01:04.819 --> 00:01:08.350
We're back to the precision, recall and F-Score video 28.

00:01:08.350 --> 00:01:13.940
The sensitivity and specificity of a classifier are symmetric

00:01:13.940 --> 00:01:19.160
measurements in the sense that the changes in false positives or

00:01:19.160 --> 00:01:25.080
false negatives do not affect the sensitivity or specificity respectively.

00:01:25.080 --> 00:01:30.100
Thus in our example we had two instances of classes, B and F.

00:01:30.100 --> 00:01:33.380
And we decided, thus in our example,

00:01:33.380 --> 00:01:38.388
we had two classes B and F and we classified between those two.

00:01:38.388 --> 00:01:42.120
Now we re-ask the question to see if we

00:01:42.120 --> 00:01:46.280
can choose between two classes that are asymmetric.

00:01:46.280 --> 00:01:50.520
In our new problem, we have slightly redefined the problem.

00:01:50.520 --> 00:01:55.640
We want to ask if something belongs to Class G or not Class G.

00:01:55.640 --> 00:01:58.680
This is a one versus all classifier.

00:01:58.680 --> 00:02:04.035
We're going to look at some metrics called precision, recall and

00:02:04.035 --> 00:02:08.490
F-score, that helps us in validating classification problems and

00:02:08.490 --> 00:02:11.950
models based on these kinds of classifiers.

00:02:11.950 --> 00:02:17.000
The difference being, the instances for Class G are a lot less

00:02:17.000 --> 00:02:22.270
than the instances for not Class G in the data.

00:02:22.270 --> 00:02:24.850
Let's get back to our Python notebook and

00:02:24.850 --> 00:02:27.100
see how we can build these models first.

00:02:30.500 --> 00:02:36.350
In this piece of code, we are starting to classify person1 vs all.

00:02:36.350 --> 00:02:38.955
We call that ova_person, or

00:02:38.955 --> 00:02:44.520
One Versus All person, and we choose G as that class.

00:02:44.520 --> 00:02:51.790
We now divide up the events such that we have G and not g as the two classes.

00:02:51.790 --> 00:02:54.270
Let's run this piece of code first.

00:02:54.270 --> 00:03:00.110
In the previous piece of code, we have setup the one versus all data.

00:03:00.110 --> 00:03:05.690
Let's look at what the y values are between then this is 220 to 230.

00:03:05.690 --> 00:03:06.910
Run this piece of code now.

00:03:08.550 --> 00:03:16.140
You see the ten values are Fs and Gs, with the last four values being G.

00:03:16.140 --> 00:03:20.810
Now let's see how this looks when we have the one versus all.

00:03:21.880 --> 00:03:25.805
Let's see how this looks for the one versus all data.

00:03:25.805 --> 00:03:27.830
Run this line of code.

00:03:27.830 --> 00:03:33.370
Notice, all the labels that are not G are labelled as false.

00:03:33.370 --> 00:03:38.270
All the labels that are G are labelled as true.

00:03:38.270 --> 00:03:43.220
Running the next line of code gives you the total number of false and

00:03:43.220 --> 00:03:47.630
true in each of the training and the test samples.

00:03:47.630 --> 00:03:50.825
We are now ready to build our models.

00:03:50.825 --> 00:03:55.360
Run this line of code that initializes the models and

00:03:55.360 --> 00:04:01.230
trains with x_train and y_train with the one verses all model.

00:04:01.230 --> 00:04:04.530
Now that we have built our one verses all models,

00:04:04.530 --> 00:04:10.780
let's try to print our accuracy, or score, for each of these models.

00:04:10.780 --> 00:04:16.250
Running this line gives us the accuracy for each of the LogisticRegression,

00:04:16.250 --> 00:04:19.704
RandomForest, and Support Vector Classifier models.

00:04:19.704 --> 00:04:26.400
Note, this time the classes are quite different than what we had before.

00:04:26.400 --> 00:04:31.030
Now we will define a few more metrics that are useful for

00:04:31.030 --> 00:04:35.270
selecting between these kind of classification models.

00:04:35.270 --> 00:04:40.050
We are now going to look at the definitions of precision, recall and

00:04:40.050 --> 00:04:44.990
f score and come back and calculate these for the model we just built.

