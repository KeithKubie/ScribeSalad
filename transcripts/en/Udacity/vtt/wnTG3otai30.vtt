WEBVTT
Kind: captions
Language: en

00:00:00.430 --> 00:00:02.670
The question is why map reduce is

00:00:02.670 --> 00:00:05.600
a programming framework for big data applications.

00:00:05.600 --> 00:00:09.310
It turns out that several processing steps

00:00:09.310 --> 00:00:12.907
in giant-scale services are expressible as map

00:00:12.907 --> 00:00:15.790
reduce. For example, let's say that you're

00:00:15.790 --> 00:00:19.610
looking for seat availability for selected dates

00:00:19.610 --> 00:00:22.780
to selected destinations on different airlines. That

00:00:22.780 --> 00:00:25.940
can be expressed as a map reduce computation.

00:00:25.940 --> 00:00:29.090
Let's say you want to access frequency of

00:00:29.090 --> 00:00:32.460
the URLs on the website that you've designed.

00:00:32.460 --> 00:00:34.340
That can be quoted up as a map

00:00:34.340 --> 00:00:37.900
reduce application. Let's say you want to create. Word

00:00:37.900 --> 00:00:42.380
indexes to facilitate document searches on the web.

00:00:42.380 --> 00:00:44.070
That can be coded up as a map

00:00:44.070 --> 00:00:47.210
reduce application. Or let's say that you want

00:00:47.210 --> 00:00:51.650
to do ranking of pages. When a user is

00:00:51.650 --> 00:00:54.300
doing a search, how to present present the

00:00:54.300 --> 00:00:58.090
search results May depend on the popularity of pages

00:00:58.090 --> 00:00:59.660
and that is what is often referred to as

00:00:59.660 --> 00:01:02.650
page ranking. So if page ranking has to be

00:01:02.650 --> 00:01:05.550
done for all the documents that is another

00:01:05.550 --> 00:01:07.980
application that can be [UNKNOWN] up as a map-reduce

00:01:07.980 --> 00:01:12.370
application. The list goes on. All such examples that

00:01:12.370 --> 00:01:16.770
are mentioned share some common property. They're embarrassingly parallel,

00:01:16.770 --> 00:01:19.890
and they're common in giant-scale services. And all

00:01:19.890 --> 00:01:22.400
of them tend to work on big data

00:01:22.400 --> 00:01:26.030
sets. Therefore there is plenty of opportunity for

00:01:26.030 --> 00:01:30.040
taking advantage of the computation resources that are

00:01:30.040 --> 00:01:33.520
available in a data center. And all such

00:01:33.520 --> 00:01:37.220
applications need domain expertise in terms of what

00:01:37.220 --> 00:01:39.850
to do with the data. Which is expressible

00:01:39.850 --> 00:01:42.600
as a map function and a reduce function, and

00:01:42.600 --> 00:01:45.120
this is the only thing that is required

00:01:45.120 --> 00:01:47.580
of the domain expert to provide to the programming

00:01:47.580 --> 00:01:50.760
system, because that is domain expertise that lives

00:01:50.760 --> 00:01:54.380
with the app developer. So here is another example

00:01:54.380 --> 00:01:57.110
of how an application may be structured as

00:01:57.110 --> 00:02:00.380
a map_reduce application. And in this case, I'm showing

00:02:00.380 --> 00:02:03.990
you a page ranking application that is, I'm

00:02:03.990 --> 00:02:07.960
interested in knowing what is the popularity of different

00:02:07.960 --> 00:02:14.130
URLs that occur in a document corpus. So the keyspace that is input to this

00:02:14.130 --> 00:02:19.300
application is a set of URLs. And the key value pair that is coming into each

00:02:19.300 --> 00:02:26.080
of the mapper is a source URL and the contents of that web page that corresponds

00:02:26.080 --> 00:02:29.020
to this particular URL. So what this mapper

00:02:29.020 --> 00:02:33.000
is doing is, in the given page defined

00:02:33.000 --> 00:02:38.780
by this URL the contents of which is the input to this mapper it is looking for

00:02:38.780 --> 00:02:44.350
different targets. Maybe it is looking for a particular URL target one, another

00:02:44.350 --> 00:02:50.390
URL target two, and so on, target N, and that's what each of these mappers are

00:02:50.390 --> 00:02:58.450
doing. So the keyspace that is output from the mapper is unique target names.

00:02:58.450 --> 00:03:00.400
So the keyspace that is output from the

00:03:00.400 --> 00:03:06.000
mapper is unique, target URLs and, the value

00:03:06.000 --> 00:03:11.840
is the URL in which it was actually phoned. So the corpus of input URLs it is

00:03:11.840 --> 00:03:14.490
taking, and saying well, in this particular URL

00:03:14.490 --> 00:03:16.530
I phoned this target. If it did. It

00:03:16.530 --> 00:03:19.770
is emitting that this target was found in

00:03:19.770 --> 00:03:24.150
a particular URL. And this reducer is going to get

00:03:24.150 --> 00:03:26.680
all the hits for a particular target that

00:03:26.680 --> 00:03:30.720
was found in the input corpus of URLs. So

00:03:30.720 --> 00:03:33.730
all the mappers they're going to send their results to

00:03:33.730 --> 00:03:37.390
this reducer if they found in the input -

00:03:37.390 --> 00:03:40.620
Surl the target, target 1, if they did,

00:03:40.620 --> 00:03:42.830
they are going to send their results to this

00:03:42.830 --> 00:03:46.790
reducer. Similarly if they found target n, each of

00:03:46.790 --> 00:03:49.720
these mappers are going to send this reducer that

00:03:49.720 --> 00:03:52.380
in the input URL they found this target

00:03:52.380 --> 00:03:54.920
n and the job of the reducer [INAUDIBLE] Is

00:03:54.920 --> 00:03:58.870
once again aggregation, and you have as many reducers

00:03:58.870 --> 00:04:01.940
as the number of unique targets you're trying to

00:04:01.940 --> 00:04:05.030
identify in the input dataset. Very similar to the

00:04:05.030 --> 00:04:08.510
previous application that we went over. So the output

00:04:08.510 --> 00:04:11.460
of the reducer is going to be the specific

00:04:11.460 --> 00:04:15.860
target that this guy has been asked to accumulate.

00:04:15.860 --> 00:04:22.670
And, a source list, meaning all the source pages in which this particular target

00:04:22.670 --> 00:04:27.700
was found. So each of these reduces is going to find the number of times a

00:04:27.700 --> 00:04:30.690
particular URL is found in the input

00:04:30.690 --> 00:04:34.800
corpus of webpages that came into the system

00:04:34.800 --> 00:04:41.370
as a whole. For instance, if I wanted to find out how many times my webpage

00:04:41.370 --> 00:04:44.470
appears in the universal web pages all over

00:04:44.470 --> 00:04:47.050
the world, we can take the entire corpus of

00:04:47.050 --> 00:04:49.800
web page available in the universals input, and the

00:04:49.800 --> 00:04:53.390
map that's we're going to look for occurence of my

00:04:53.390 --> 00:04:55.840
web page in each one of those input web

00:04:55.840 --> 00:04:58.660
pages. And if they find that, they're going to

00:04:58.660 --> 00:05:01.980
send it to this reducer and if target one

00:05:01.980 --> 00:05:06.420
corresponds to my web page then this reducer is

00:05:06.420 --> 00:05:09.410
going to say, okay, show his webpage, was found

00:05:09.410 --> 00:05:12.380
in this list of source webpages all over the

00:05:12.380 --> 00:05:15.670
Universe. That in a sense gives a rank for.

00:05:15.670 --> 00:05:18.210
That particular web page that we're looking at. So

00:05:18.210 --> 00:05:21.440
we're able to rank the target web pages 1

00:05:21.440 --> 00:05:25.350
through n based on the number of source web

00:05:25.350 --> 00:05:29.460
pages that contain that particular target. And that's what

00:05:29.460 --> 00:05:31.810
page ranking is all about. So I'm giving you

00:05:31.810 --> 00:05:34.830
yet another example of how This map

00:05:34.830 --> 00:05:39.170
reduce functionality can be applied for an application

00:05:39.170 --> 00:05:44.210
such as page ranking. All the heavy lifting that needs to be done, in terms of

00:05:44.210 --> 00:05:47.420
instantiating the number of mappers, instantiating the

00:05:47.420 --> 00:05:50.930
number of reducers, The data movement between the

00:05:50.930 --> 00:05:54.180
mappers and the reducers, all of those chores,

00:05:54.180 --> 00:05:57.830
are taken care of by the programming environment.

00:05:57.830 --> 00:05:59.960
All that the domain expert had to do was

00:05:59.960 --> 00:06:03.000
to write the map and reduce function that is unique

00:06:03.000 --> 00:06:07.150
to particular specifics of his application. The rest of

00:06:07.150 --> 00:06:10.940
the heavy lifting is all done by the programming framework.

