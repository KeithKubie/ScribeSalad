WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.928
[MUSIC PLAYING]

00:00:06.919 --> 00:00:08.460
TODD KERPELMAN: Hey,
there, I/O Live.

00:00:08.460 --> 00:00:10.180
Todd Kerpelman
here, and I am here

00:00:10.180 --> 00:00:14.320
in the Experiments with Google
Dome with Teo Soares, who

00:00:14.320 --> 00:00:16.360
is the team lead on
Experiments with Google.

00:00:16.360 --> 00:00:17.260
Welcome.

00:00:17.260 --> 00:00:18.176
TEO SOARES: Thank you.

00:00:18.176 --> 00:00:19.040
Happy to be here.

00:00:19.040 --> 00:00:21.180
TODD KERPELMAN: So what is
Experiments with Google?

00:00:21.180 --> 00:00:21.850
TEO SOARES:
Experiments with Google

00:00:21.850 --> 00:00:24.730
is a platform where we showcase
projects that developers have

00:00:24.730 --> 00:00:26.530
made using Google technologies.

00:00:26.530 --> 00:00:28.720
We have close to 1,500 of them.

00:00:28.720 --> 00:00:30.040
A lot of them are open source.

00:00:30.040 --> 00:00:32.020
Anybody can download
them and play around.

00:00:32.020 --> 00:00:33.624
Anybody can submit their own.

00:00:33.624 --> 00:00:36.040
TODD KERPELMAN: All right, and
so here at the booth today,

00:00:36.040 --> 00:00:39.100
at the Dome, you've got some
of your favorite experiments

00:00:39.100 --> 00:00:40.060
that are showing off.

00:00:40.060 --> 00:00:41.662
TEO SOARES: Yeah,
we have 10 of them.

00:00:41.662 --> 00:00:42.995
Do you want to try this one out?

00:00:42.995 --> 00:00:43.290
TODD KERPELMAN: I would.

00:00:43.290 --> 00:00:44.900
What is this one behind me here?

00:00:44.900 --> 00:00:46.816
TEO SOARES: So this one
is called Move Mirror,

00:00:46.816 --> 00:00:49.590
and it's a demo of a pose
estimation model from Google

00:00:49.590 --> 00:00:51.610
that lets you use just
any regular webcam--

00:00:51.610 --> 00:00:53.150
we're using a phone here--

00:00:53.150 --> 00:00:55.120
to find the pose
data in an image.

00:00:55.120 --> 00:00:56.890
And then in this demo,
what we are doing

00:00:56.890 --> 00:00:59.190
is finding an image
that matches what

00:00:59.190 --> 00:01:00.820
you are doing in
front of the camera

00:01:00.820 --> 00:01:03.239
from one of 90,000 images
we have in the database.

00:01:03.239 --> 00:01:04.239
TODD KERPELMAN: Awesome.

00:01:04.239 --> 00:01:06.990
Well, let's give it a try.

00:01:06.990 --> 00:01:09.540
My kids told me about flossing,
which apparently is a thing,

00:01:09.540 --> 00:01:11.519
but I'm not going to do
it because I don't want

00:01:11.519 --> 00:01:12.810
to embarrass my kids that much.

00:01:12.810 --> 00:01:16.260
I'm just going to bounce
side to side instead.

00:01:16.260 --> 00:01:19.070
All right, then
I'm going to wave.

00:01:19.070 --> 00:01:20.462
All right, thank you.

00:01:20.462 --> 00:01:22.420
And now we're going to
move on to the next one.

00:01:22.420 --> 00:01:22.992
Let's go.

00:01:22.992 --> 00:01:24.450
TEO SOARES: So this
is a game built

00:01:24.450 --> 00:01:27.600
with a Google library
called TensorFlow.JS

00:01:27.600 --> 00:01:30.460
that lets you train an
AI right in the browser.

00:01:30.460 --> 00:01:32.884
And what we've done with it
here is play a dancing game

00:01:32.884 --> 00:01:35.050
where you're going to train
your little dancer using

00:01:35.050 --> 00:01:37.389
hand gestures and see how
many points you can score.

00:01:37.389 --> 00:01:39.930
TODD KERPELMAN: And so through
the power of machine learning,

00:01:39.930 --> 00:01:41.346
this is going to
recognize my hand

00:01:41.346 --> 00:01:44.070
gestures all within the
browser using TensorFlow.JS?

00:01:44.070 --> 00:01:45.577
No talking to the
cloud or anything?

00:01:45.577 --> 00:01:46.410
TEO SOARES: Exactly.

00:01:46.410 --> 00:01:47.826
Nothing is ever
going to a server.

00:01:47.826 --> 00:01:49.560
It's all happening
right in the browser.

00:01:49.560 --> 00:01:49.890
TODD KERPELMAN: Wow.

00:01:49.890 --> 00:01:51.723
All right, well, I've
got to give that a try

00:01:51.723 --> 00:01:53.400
and make my little
Jelly Bean guy dance.

00:01:53.400 --> 00:01:54.240
Let's do it.

00:01:54.240 --> 00:01:55.170
I'm ready.

00:01:55.170 --> 00:01:56.160
You ready?

00:01:56.160 --> 00:01:57.810
Come on, Jelly Bean.

00:01:57.810 --> 00:01:58.750
Dance to the left.

00:01:58.750 --> 00:02:00.350
To the right.

00:02:00.350 --> 00:02:02.270
Three out.

00:02:02.270 --> 00:02:03.310
Left.

00:02:03.310 --> 00:02:05.180
Come on, keep dancing,
little Jelly Bean.

00:02:05.180 --> 00:02:08.161
You can do it.

00:02:08.161 --> 00:02:08.660
Oh, no!

00:02:08.660 --> 00:02:10.750
Oh, I got one wrong.

00:02:10.750 --> 00:02:12.380
All right, look at that.

00:02:12.380 --> 00:02:13.790
I get a medal for dancing--

00:02:13.790 --> 00:02:16.370
the one and only time I will
get a medal for dancing.

00:02:16.370 --> 00:02:18.440
Let's move on to the next one.

00:02:18.440 --> 00:02:19.740
So what's going on here?

00:02:19.740 --> 00:02:21.020
TEO SOARES: This is
an augmented reality

00:02:21.020 --> 00:02:23.480
experiment that lets you draw
really simple things in AR.

00:02:23.480 --> 00:02:25.040
We called it [INAUDIBLE].

00:02:25.040 --> 00:02:27.560
What we've done for this demo
is to use Cloud Anchors, which

00:02:27.560 --> 00:02:29.900
is the new technology that
we announced at this I/O

00:02:29.900 --> 00:02:32.080
to let two phones
join the same room

00:02:32.080 --> 00:02:33.939
and draw together
on the same drawing.

00:02:33.939 --> 00:02:35.480
And that can happen
across platforms,

00:02:35.480 --> 00:02:37.117
so we have one Android
and one iPhone.

00:02:37.117 --> 00:02:39.200
TODD KERPELMAN: Awesome,
so let's give this a try.

00:02:39.200 --> 00:02:41.390
Maybe I will hold
up a phone, and you

00:02:41.390 --> 00:02:45.020
can draw a little something
on your other device.

00:02:45.020 --> 00:02:46.827
So let's see what
you're drawing here.

00:02:46.827 --> 00:02:50.920
Oh, drawing over here.

00:02:50.920 --> 00:02:52.800
Oh, it's a smiley face.

00:02:52.800 --> 00:02:56.780
Woo, and we are chatting
in augmented reality.

00:02:56.780 --> 00:02:58.729
It's the future.

00:02:58.729 --> 00:03:00.020
Thank you so much for the tour.

00:03:00.020 --> 00:03:01.790
So if I'm a
developer, and I want

00:03:01.790 --> 00:03:03.809
to either get inspired
to make something amazing

00:03:03.809 --> 00:03:06.100
or want to show off something
amazing that I have made,

00:03:06.100 --> 00:03:06.860
where do I go?

00:03:06.860 --> 00:03:09.370
TEO SOARES: You go
to g.co/experiments.

00:03:09.370 --> 00:03:11.470
That's where you find
our 1,500 experiments.

00:03:11.470 --> 00:03:14.240
A lot of them are open source,
or you can submit your own.

00:03:14.240 --> 00:03:15.906
TODD KERPELMAN: All
right, sounds good--

00:03:15.906 --> 00:03:16.739
g.com/experiments.

00:03:16.739 --> 00:03:19.280
And hey, if you like this video,
maybe want to see a few more

00:03:19.280 --> 00:03:24.200
like it, head on over to
g.co/io/guide and see more

00:03:24.200 --> 00:03:25.717
videos just like this one.

00:03:25.717 --> 00:03:26.550
Thanks for watching.

00:03:26.550 --> 00:03:27.341
We'll see you soon.

00:03:27.341 --> 00:03:31.130
[MUSIC PLAYING]

