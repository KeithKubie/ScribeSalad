WEBVTT
Kind: captions
Language: en

00:00:00.499 --> 00:00:01.760
LUKE CHURCH: Hello, everyone.

00:00:01.760 --> 00:00:02.830
Glad you're get
back from the break.

00:00:02.830 --> 00:00:04.900
And I don't actually know
why we're talking and not

00:00:04.900 --> 00:00:06.483
just listening to
how to make alcohol.

00:00:06.483 --> 00:00:08.109
But you know, either way works.

00:00:08.109 --> 00:00:09.120
I'm Luke Church.

00:00:09.120 --> 00:00:10.690
I'm a user experience
researcher.

00:00:10.690 --> 00:00:13.716
And apparently, I'm
also a coffee mug.

00:00:13.716 --> 00:00:14.382
DEVON CAREW: Hi.

00:00:14.382 --> 00:00:15.048
I'm Devon Carew.

00:00:15.048 --> 00:00:17.080
I'm an engineer
on the Dart team.

00:00:17.080 --> 00:00:19.454
LUKE CHURCH: And so what we're
going to talk to you today

00:00:19.454 --> 00:00:21.600
about is about how to
build production Dart

00:00:21.600 --> 00:00:24.780
apps with an open source
workflow-- nice, long title.

00:00:24.780 --> 00:00:27.070
What that actually
means is how it

00:00:27.070 --> 00:00:30.060
is that you can use services
that other people have built

00:00:30.060 --> 00:00:31.777
to make your lives easier.

00:00:31.777 --> 00:00:34.110
And we're going to use DartPad,
an application we built,

00:00:34.110 --> 00:00:36.620
as an example.

00:00:36.620 --> 00:00:38.990
So what is DartPad?

00:00:38.990 --> 00:00:41.600
DartPad is a place
that you can go

00:00:41.600 --> 00:00:44.254
to write little snippets
of Dart in a browser.

00:00:44.254 --> 00:00:45.670
And frankly, if
you don't actually

00:00:45.670 --> 00:00:47.940
want to listen to us
talk, just hit that URL

00:00:47.940 --> 00:00:49.570
and have fun for the
next half an hour.

00:00:49.570 --> 00:00:51.330
That'll be great.

00:00:51.330 --> 00:00:53.177
So we built this for
a couple of reasons.

00:00:53.177 --> 00:00:55.010
It's really important
for the Dart ecosystem

00:00:55.010 --> 00:00:58.946
to have a place where people can
write little snippets of code.

00:00:58.946 --> 00:01:00.320
They can try
something out that's

00:01:00.320 --> 00:01:03.330
independent from their
production workflows.

00:01:03.330 --> 00:01:05.530
And you can write
little snippets of code,

00:01:05.530 --> 00:01:07.400
share them with other
people, as a way

00:01:07.400 --> 00:01:09.130
of explaining Dart to people.

00:01:09.130 --> 00:01:11.360
So this just makes the
ecosystem work better.

00:01:11.360 --> 00:01:13.360
It makes it a little
more efficient.

00:01:13.360 --> 00:01:16.780
The point to stress today is
that everything you see here,

00:01:16.780 --> 00:01:18.280
you can do at home.

00:01:18.280 --> 00:01:20.737
So we're not using any
special magic here-- well,

00:01:20.737 --> 00:01:21.570
maybe just a little.

00:01:21.570 --> 00:01:23.710
But it's all built
out of services

00:01:23.710 --> 00:01:28.520
that you can build to build
your production apps today.

00:01:28.520 --> 00:01:32.350
So very briefly, DartPad
is split in two parts.

00:01:32.350 --> 00:01:33.990
There's a user interface.

00:01:33.990 --> 00:01:36.180
That comes from
the DartPad repo.

00:01:36.180 --> 00:01:38.360
And there is a Dart
services library.

00:01:38.360 --> 00:01:40.070
That runs on App Engine.

00:01:40.070 --> 00:01:42.410
And it provides things
like compilation,

00:01:42.410 --> 00:01:44.300
code completion, analysis.

00:01:44.300 --> 00:01:46.560
And we split it up
this way so you can

00:01:46.560 --> 00:01:47.910
use either of these two bits.

00:01:47.910 --> 00:01:49.710
So if you want to
build your own DartPad,

00:01:49.710 --> 00:01:51.200
you don't need any of our UI.

00:01:51.200 --> 00:01:52.680
You can just use these services.

00:01:52.680 --> 00:01:55.276
You can also connect the
UI to something else.

00:01:55.276 --> 00:01:56.900
So what we're going
to talk about today

00:01:56.900 --> 00:01:59.160
is how we made sure
that this actually

00:01:59.160 --> 00:02:02.160
works and is actually fast.

00:02:02.160 --> 00:02:05.590
So the agenda, lots of stuff.

00:02:05.590 --> 00:02:07.086
We're going to
cover all of these.

00:02:07.086 --> 00:02:09.210
And I'll start off by
handing over to Devon to talk

00:02:09.210 --> 00:02:10.460
about continuous integration.

00:02:10.460 --> 00:02:12.530
DEVON CAREW: OK.

00:02:12.530 --> 00:02:15.955
So let's say you
start a project.

00:02:15.955 --> 00:02:17.330
You already have
a bunch of code.

00:02:17.330 --> 00:02:18.879
You have some unit
tests written,

00:02:18.879 --> 00:02:20.420
a couple of developers,
and maybe you

00:02:20.420 --> 00:02:23.630
plan to get pull
requests in the future.

00:02:23.630 --> 00:02:25.850
You want to get some rigor
around this workflow.

00:02:25.850 --> 00:02:27.370
And the way you
want to do that is

00:02:27.370 --> 00:02:29.510
using continuous integration.

00:02:29.510 --> 00:02:31.760
So it's basically a system--
I'm sure that many of you

00:02:31.760 --> 00:02:34.650
are familiar-- but it
automatically runs your tests,

00:02:34.650 --> 00:02:37.839
builds your app, and does it
automatically on every commit,

00:02:37.839 --> 00:02:39.380
so that you have
very good visibility

00:02:39.380 --> 00:02:41.160
into whether the code
you're committing

00:02:41.160 --> 00:02:45.150
is functioning-- either
you or your team members.

00:02:45.150 --> 00:02:47.000
There are a couple
of good systems

00:02:47.000 --> 00:02:50.850
to use, continuous integration
systems for a Dart app.

00:02:50.850 --> 00:02:54.470
Travis CI recently
got Dart support.

00:02:54.470 --> 00:02:57.470
Drone.io has had Dart support
for a number of years.

00:02:57.470 --> 00:02:59.440
And if you're interested
in getting visibility

00:02:59.440 --> 00:03:01.780
into your Windows
testing, AppVeyor

00:03:01.780 --> 00:03:06.395
has an easy system for
getting Dart support.

00:03:06.395 --> 00:03:07.645
We're using Travis on DartPad.

00:03:07.645 --> 00:03:11.250
So I'll talk a little bit about
getting it set up with Travis.

00:03:11.250 --> 00:03:14.110
You just a tiny metadata file
in the root of your project

00:03:14.110 --> 00:03:15.750
to basically tell
Travis that you

00:03:15.750 --> 00:03:19.145
want to use the Dart runtime
when you run your tests

00:03:19.145 --> 00:03:21.520
and give it a point or two,
the script that will actually

00:03:21.520 --> 00:03:22.250
run your tests.

00:03:22.250 --> 00:03:24.514
And those scripts typically
do a couple of things,

00:03:24.514 --> 00:03:25.930
like analyze your
Dart source code

00:03:25.930 --> 00:03:27.618
to look for errors
and warnings, fail

00:03:27.618 --> 00:03:31.210
the build, if there are any,
and run your unit tests.

00:03:31.210 --> 00:03:36.100
So here's what it looks
like, a typical build.

00:03:36.100 --> 00:03:38.925
So we got a pull request
into the DartPad UI.

00:03:38.925 --> 00:03:42.300
It shows you the build
output live, in real time.

00:03:42.300 --> 00:03:44.550
It tells you whether the
build passed or failed

00:03:44.550 --> 00:03:46.930
and notifies you by email.

00:03:46.930 --> 00:03:50.100
Here's our build history
from a few weeks ago.

00:03:50.100 --> 00:03:52.100
So you get to see again,
like each pull request,

00:03:52.100 --> 00:03:54.590
you get a green
light, red light.

00:03:54.590 --> 00:03:56.790
And just to validate
using it, these

00:03:56.790 --> 00:04:00.210
are the results as of a
week or two ago for DartPad

00:04:00.210 --> 00:04:04.490
where the UI project had about
200 pull requests, 400 builds,

00:04:04.490 --> 00:04:06.010
and 30 failures.

00:04:06.010 --> 00:04:08.380
And the service
back-end had about 100

00:04:08.380 --> 00:04:12.140
PRs and, again, failures.

00:04:12.140 --> 00:04:14.250
And the good thing about
getting those failures

00:04:14.250 --> 00:04:16.220
is those all happen
in pull requests,

00:04:16.220 --> 00:04:17.470
so you get visibility in that.

00:04:17.470 --> 00:04:19.863
And every time we
merged code to master,

00:04:19.863 --> 00:04:21.029
we knew that it was working.

00:04:21.029 --> 00:04:22.987
So our master always
stayed clean and shipable.

00:04:26.120 --> 00:04:27.680
Next, we're going
to talk about--

00:04:27.680 --> 00:04:31.950
and what we had running
initially on Travis

00:04:31.950 --> 00:04:33.269
was our unit tests.

00:04:33.269 --> 00:04:34.810
So Luke is going to
talk a little bit

00:04:34.810 --> 00:04:37.420
about some functional testing,
another type of testing.

00:04:37.420 --> 00:04:38.250
LUKE CHURCH: Sure.

00:04:38.250 --> 00:04:42.900
So functional testing-- well,
why would we want to do it?

00:04:42.900 --> 00:04:44.500
So I heard a rumor
on the internet

00:04:44.500 --> 00:04:47.230
that not all browsers
behave exactly the same.

00:04:47.230 --> 00:04:49.730
I mean, it might be news
to a lot of folks here.

00:04:49.730 --> 00:04:52.950
But you can see a
browser not quite

00:04:52.950 --> 00:04:55.760
behaving as we would expect
on the screen in front of you

00:04:55.760 --> 00:04:56.660
here.

00:04:56.660 --> 00:04:58.167
A person trying
to use this isn't

00:04:58.167 --> 00:04:59.750
going to have a good
day with DartPad.

00:04:59.750 --> 00:05:01.208
And noticeably,
they can't actually

00:05:01.208 --> 00:05:03.290
write code [INAUDIBLE].

00:05:03.290 --> 00:05:06.530
So it's really useful to be
able to know that ahead of time

00:05:06.530 --> 00:05:10.550
and to be able to have a
way in which we can verify

00:05:10.550 --> 00:05:13.000
the behavior that we're
handing to all of our users,

00:05:13.000 --> 00:05:15.970
independently of which
platform they're running on,

00:05:15.970 --> 00:05:18.200
in a way that doesn't
result in us having

00:05:18.200 --> 00:05:22.010
to do that testing manually,
one browser at a time.

00:05:22.010 --> 00:05:24.780
So we've been using a
service called Sauce Labs.

00:05:24.780 --> 00:05:27.330
A few others you could use
is BrowserStack, as well,

00:05:27.330 --> 00:05:28.320
to do this.

00:05:28.320 --> 00:05:31.210
And what Sauce Labs enables
you to do is two things.

00:05:31.210 --> 00:05:36.165
One is that you can spin
up, from a large collection

00:05:36.165 --> 00:05:38.890
that they offer you, an
arbitrary environment.

00:05:38.890 --> 00:05:41.400
And you can play with your
website in that arbitrary

00:05:41.400 --> 00:05:43.390
environment in a manual way.

00:05:43.390 --> 00:05:49.000
So what you can see
here is me checking

00:05:49.000 --> 00:05:51.910
that the basic
functionality of DartPad

00:05:51.910 --> 00:05:55.200
works in Internet Explorer,
without me having to go and get

00:05:55.200 --> 00:05:56.370
a Windows machine.

00:05:56.370 --> 00:05:58.770
This is really useful.

00:05:58.770 --> 00:06:00.680
So that gives us the
ability to quickly test

00:06:00.680 --> 00:06:02.138
on a number of
different platforms.

00:06:06.970 --> 00:06:09.150
You can also,
however, add things

00:06:09.150 --> 00:06:11.010
that do automated verification.

00:06:11.010 --> 00:06:13.020
So if you add this
piece of script

00:06:13.020 --> 00:06:16.100
here to one of the test
libraries, what this is doing

00:06:16.100 --> 00:06:18.820
is spinning up a web
browser, reading off

00:06:18.820 --> 00:06:21.180
the title of that web
browser, and verifying

00:06:21.180 --> 00:06:23.560
that the cycle is as expected.

00:06:23.560 --> 00:06:26.080
So we can write this
once, test it locally,

00:06:26.080 --> 00:06:29.240
verify that it's working
on our platform, and then,

00:06:29.240 --> 00:06:31.980
via the magic of Sauce Labs,
have it scale out to test

00:06:31.980 --> 00:06:35.930
and run across all of our
target deployments in one go.

00:06:35.930 --> 00:06:38.440
So this is how we're ensuring
that the product that we're

00:06:38.440 --> 00:06:41.970
shipping to users across the
browser platforms we care about

00:06:41.970 --> 00:06:44.660
is behaving as we would
expect, as we add features.

00:06:47.605 --> 00:06:48.480
DEVON CAREW: Awesome.

00:06:48.480 --> 00:06:49.771
So that was functional testing.

00:06:49.771 --> 00:06:54.640
And I'm going to talk a little
bit about code coverage now.

00:06:54.640 --> 00:06:57.310
So why is code coverage good?

00:06:57.310 --> 00:07:00.490
So we have a green light, red
light for our build right now.

00:07:00.490 --> 00:07:01.610
And that's awesome.

00:07:01.610 --> 00:07:04.960
But we don't really
know how much we

00:07:04.960 --> 00:07:07.500
can rely on that green light.

00:07:07.500 --> 00:07:09.540
What is it really telling us?

00:07:09.540 --> 00:07:12.400
So for that, we get a little
bit better information if we add

00:07:12.400 --> 00:07:14.200
code coverage to the process.

00:07:14.200 --> 00:07:16.950
So that tells us really how
much of our code is being tested

00:07:16.950 --> 00:07:21.770
and if we can really rely on a
green build when that happens.

00:07:21.770 --> 00:07:22.600
So how?

00:07:22.600 --> 00:07:25.440
So we're using a
Dart package called

00:07:25.440 --> 00:07:27.110
dart_coveralls in
a hosted service

00:07:27.110 --> 00:07:30.390
called coveralls.io to
get our code coverage

00:07:30.390 --> 00:07:33.390
information on each build,
on each pull request.

00:07:33.390 --> 00:07:34.370
It's a simple setup.

00:07:34.370 --> 00:07:38.910
Basically, this dart_coveralls
package runs your unit tests,

00:07:38.910 --> 00:07:42.496
uses the Observatory protocol
to collect coverage, formats

00:07:42.496 --> 00:07:44.370
in a way that coveralls
likes, and uploads it

00:07:44.370 --> 00:07:47.230
to coveralls with the
commit information.

00:07:47.230 --> 00:07:49.780
We can take a look at
what that looks like.

00:07:49.780 --> 00:07:53.550
So this is our
site on coveralls.

00:07:53.550 --> 00:07:55.400
And this is, again,
each pull request.

00:07:55.400 --> 00:07:56.900
We have visibility
into the coverage

00:07:56.900 --> 00:08:00.530
and whether it's
increasing or decreasing.

00:08:00.530 --> 00:08:03.090
You can dig into the
results for a pull request

00:08:03.090 --> 00:08:05.630
and see, file by
file, your coverage,

00:08:05.630 --> 00:08:07.890
which ones are well covered,
and which ones maybe

00:08:07.890 --> 00:08:09.640
aren't as well.

00:08:09.640 --> 00:08:12.710
And into a file, you
can see line by line.

00:08:12.710 --> 00:08:15.170
So we can see that this method
that actually should have

00:08:15.170 --> 00:08:16.940
had coverage-- and we
probably expected it

00:08:16.940 --> 00:08:21.050
to have been tested-- wasn't
actually being tested at all.

00:08:21.050 --> 00:08:23.570
And something
important to remember.

00:08:23.570 --> 00:08:29.206
We had a very nice
measurement there, 81%.

00:08:29.206 --> 00:08:31.580
It's nice to have more coverage,
but you shouldn't really

00:08:31.580 --> 00:08:33.779
be chasing a specific number.

00:08:33.779 --> 00:08:35.154
You want to go
for quality tests.

00:08:38.549 --> 00:08:41.049
LUKE CHURCH: It's a bit higher
than 80 now, though, I think.

00:08:41.049 --> 00:08:41.630
DEVON CAREW: 87.

00:08:41.630 --> 00:08:41.929
Yeah.

00:08:41.929 --> 00:08:42.940
But we're not chasing a number.

00:08:42.940 --> 00:08:43.606
LUKE CHURCH: No.

00:08:43.606 --> 00:08:44.731
Not in any way, whatsoever.

00:08:44.731 --> 00:08:46.480
DEVON CAREW: But
basically, what it does ,

00:08:46.480 --> 00:08:48.850
it gives you visibility
into how well it's tested.

00:08:48.850 --> 00:08:51.160
So you may choose
not to add tests

00:08:51.160 --> 00:08:52.910
for getters, and two
strings, and things

00:08:52.910 --> 00:08:55.807
that really don't matter
or are going to fail

00:08:55.807 --> 00:08:56.890
your test in the compiler.

00:08:56.890 --> 00:08:59.300
But really, it gives you
visibility into things, maybe,

00:08:59.300 --> 00:09:01.076
you thought were
tested, that aren't.

00:09:01.076 --> 00:09:02.700
Or I could get a pull
request from Luke

00:09:02.700 --> 00:09:06.160
with some great
back-end services that

00:09:06.160 --> 00:09:07.530
really decreases the coverage.

00:09:07.530 --> 00:09:09.910
And I could say, why don't
we add some tests to that?

00:09:09.910 --> 00:09:12.690
LUKE CHURCH: Yeah, but
that would never happen.

00:09:12.690 --> 00:09:15.050
DEVON CAREW: And just to
jump back to coveralls,

00:09:15.050 --> 00:09:18.660
it does have some nice
trigger notifications.

00:09:18.660 --> 00:09:20.797
If your coverage drops
below a certain amount

00:09:20.797 --> 00:09:22.630
or drops a certain
amount in a pull request,

00:09:22.630 --> 00:09:25.490
you can get proactive
notifications about that.

00:09:25.490 --> 00:09:26.509
LUKE CHURCH: Yep.

00:09:26.509 --> 00:09:28.300
DEVON CAREW: And I'll
hand it back to Luke.

00:09:28.300 --> 00:09:30.860
He can talk about web
hosting and scaling.

00:09:30.860 --> 00:09:31.650
LUKE CHURCH: OK.

00:09:31.650 --> 00:09:34.240
So the position you're in now,
looking through this list,

00:09:34.240 --> 00:09:36.780
is that you've
written some code.

00:09:36.780 --> 00:09:39.020
You've written
unit tests for it.

00:09:39.020 --> 00:09:41.110
You've written
system tests for it.

00:09:41.110 --> 00:09:43.430
And you have some sense of
how much of your application

00:09:43.430 --> 00:09:46.090
is being tested by your
various test suites.

00:09:46.090 --> 00:09:47.860
That's great.

00:09:47.860 --> 00:09:50.980
So now, the question is how do
you actually get that to users

00:09:50.980 --> 00:09:53.730
so they can do things with it?

00:09:53.730 --> 00:09:55.420
So we use App Engine to do this.

00:09:55.420 --> 00:09:57.532
We actually split the
project into two parts.

00:09:57.532 --> 00:09:59.240
As I mentioned earlier,
one of the ideals

00:09:59.240 --> 00:10:01.370
here was that the
Dart services should

00:10:01.370 --> 00:10:04.647
be usable by people who don't
really want any of our UI.

00:10:04.647 --> 00:10:06.980
They should be able to use
it as a standalone component.

00:10:06.980 --> 00:10:08.860
So we split App
Engine accordingly.

00:10:08.860 --> 00:10:11.650
So we actually serve
static files-- CSS, HTML,

00:10:11.650 --> 00:10:14.490
compiled JavaScript-- to
users from one instance.

00:10:14.490 --> 00:10:16.700
And then we serve services
from another instance

00:10:16.700 --> 00:10:19.880
that does analysis, completion,
compilation, quick fixes.

00:10:19.880 --> 00:10:22.530
OK, so what that
does is gives you

00:10:22.530 --> 00:10:24.430
an application that
runs in a web browser

00:10:24.430 --> 00:10:26.430
and does the right
thing, so hosting.

00:10:31.000 --> 00:10:34.290
And the way in which
we handle the services

00:10:34.290 --> 00:10:37.110
is using the RPC package
that's been written.

00:10:37.110 --> 00:10:39.259
So we get a request
in, via something

00:10:39.259 --> 00:10:40.550
that looks like api/v1/analyze.

00:10:45.150 --> 00:10:48.670
The Dart on App Engine
routes that to a Managed VM.

00:10:48.670 --> 00:10:51.710
The RPC package then allows us
to select one of the endpoints

00:10:51.710 --> 00:10:54.755
that we use for providing those
services, compute the results,

00:10:54.755 --> 00:10:56.680
then hand it back.

00:10:56.680 --> 00:10:59.260
This is all nice and well.

00:10:59.260 --> 00:11:03.150
However, we're
running a compiler

00:11:03.150 --> 00:11:05.960
and a bunch of developer
services in a browser.

00:11:05.960 --> 00:11:09.160
It is really, really
important that that is fast.

00:11:09.160 --> 00:11:14.080
So what you see here
is what it would

00:11:14.080 --> 00:11:17.720
look like if we hadn't thought
about scaling whatsoever.

00:11:17.720 --> 00:11:22.510
So you can see the blue line
is an increasing level of QPS

00:11:22.510 --> 00:11:25.660
being sent to the
compiler endpoint.

00:11:25.660 --> 00:11:27.830
And the red line is the latency.

00:11:27.830 --> 00:11:30.080
And the big, scary
red lines are cases

00:11:30.080 --> 00:11:33.111
where we would have
handed back HTTP 503.

00:11:33.111 --> 00:11:33.610
Sorry.

00:11:33.610 --> 00:11:34.330
Come back later.

00:11:34.330 --> 00:11:36.390
We're broken.

00:11:36.390 --> 00:11:39.200
This is clearly
completely unacceptable.

00:11:39.200 --> 00:11:40.950
And so we've put
in a bunch of work

00:11:40.950 --> 00:11:43.240
to making sure that, A,
the system is robust;

00:11:43.240 --> 00:11:47.140
B, it scales; and
C, it remains fast.

00:11:47.140 --> 00:11:49.550
So there's a couple
of things that we've

00:11:49.550 --> 00:11:51.490
done to make that
work on App Engine.

00:11:51.490 --> 00:11:53.900
The first one is memcaches.

00:11:53.900 --> 00:11:56.140
So it turns out that
what generally happens

00:11:56.140 --> 00:11:57.910
with something like
DartPad is someone

00:11:57.910 --> 00:12:00.110
writes a small piece
of code, then shares it

00:12:00.110 --> 00:12:01.985
with a bunch of other
people who also try

00:12:01.985 --> 00:12:03.980
and to run that code
in their browser.

00:12:03.980 --> 00:12:06.980
That code is exactly the same
as it was the first time,

00:12:06.980 --> 00:12:10.100
so the compiler will
give you the same result.

00:12:10.100 --> 00:12:12.500
So consequently, rather
than re-computing it,

00:12:12.500 --> 00:12:14.320
we store that in a
memcache and just

00:12:14.320 --> 00:12:16.350
immediately hand
back the results.

00:12:16.350 --> 00:12:19.360
That cuts the compiler
latency down to, essentially,

00:12:19.360 --> 00:12:20.930
the network latency.

00:12:20.930 --> 00:12:22.860
And to give you an
impression of how effective

00:12:22.860 --> 00:12:26.310
that is, we get memcache
hits on between 88% and 90%

00:12:26.310 --> 00:12:27.550
of our requests.

00:12:27.550 --> 00:12:30.980
That cuts a huge loading
out to the services.

00:12:30.980 --> 00:12:32.490
The second really
important property

00:12:32.490 --> 00:12:35.580
here is that you have to keep
the virtual machines warm.

00:12:35.580 --> 00:12:38.450
So you have to reuse
as much of that state

00:12:38.450 --> 00:12:41.340
as possible, whilst also
maintaining integrity

00:12:41.340 --> 00:12:44.470
between your user sessions, so
you're not leaking information.

00:12:44.470 --> 00:12:45.950
And we do that in
a couple of ways.

00:12:45.950 --> 00:12:48.517
One is by hanging onto
a bunch of objects.

00:12:48.517 --> 00:12:50.350
And the other is, as
we'll talk about later,

00:12:50.350 --> 00:12:52.630
we use an uptime
service that sends us

00:12:52.630 --> 00:12:56.050
a continuous trickle of requests
at a fairly low grade, which

00:12:56.050 --> 00:12:59.586
keeps the virtual machines hot.

00:12:59.586 --> 00:13:00.960
And so what's the
effect of that?

00:13:00.960 --> 00:13:02.680
I mean, we heard a
talk earlier talking

00:13:02.680 --> 00:13:06.670
about 50th and 90th percentiles.

00:13:06.670 --> 00:13:09.800
So typically, from the
server point of view,

00:13:09.800 --> 00:13:14.570
we can return an analysis in
an average of 16 milliseconds

00:13:14.570 --> 00:13:16.780
and the 98th percentile.

00:13:16.780 --> 00:13:19.160
So the people who are
having a bad, bad day

00:13:19.160 --> 00:13:21.580
are at 54 milliseconds
for analysis.

00:13:21.580 --> 00:13:24.287
We're currently looking at
ways of shrinking that a bit.

00:13:24.287 --> 00:13:26.760
But that's the kind of numbers
that we can talk about,

00:13:26.760 --> 00:13:28.740
which means that,
when you use DartPad,

00:13:28.740 --> 00:13:31.570
it should feel pretty much
instant for a lot of cases.

00:13:31.570 --> 00:13:33.840
Compilation is a
bit slower, again,

00:13:33.840 --> 00:13:36.620
but you're still looking
at a fairly reasonable--

00:13:36.620 --> 00:13:38.460
even for the 98th
percentile, you're

00:13:38.460 --> 00:13:41.310
looking at it taking 2.9
seconds to compile and hand you

00:13:41.310 --> 00:13:42.280
the results back.

00:13:42.280 --> 00:13:44.490
Again, looking at ways
of shrinking that a bit,

00:13:44.490 --> 00:13:46.610
but it's still within a
reasonable performance

00:13:46.610 --> 00:13:48.170
for feeling fast.

00:13:48.170 --> 00:13:51.970
And you can compare that
to the previous graph

00:13:51.970 --> 00:13:55.350
where, if you don't care about
scaling and latency at all,

00:13:55.350 --> 00:13:57.090
your compile times
are up into the 40,

00:13:57.090 --> 00:14:01.149
50 seconds when things
start going wrong.

00:14:01.149 --> 00:14:02.690
And the thing that
we'll see later on

00:14:02.690 --> 00:14:05.520
is that these are useful
numbers to understand.

00:14:05.520 --> 00:14:08.780
They're numbers to understand
for the actual server

00:14:08.780 --> 00:14:10.950
performance whilst
we're doing compilation.

00:14:10.950 --> 00:14:14.290
But what we really care about
is end user-facing latency.

00:14:14.290 --> 00:14:18.600
And our average compilation
latency is 650 milliseconds.

00:14:18.600 --> 00:14:20.960
That's partially due to an
addition from the network

00:14:20.960 --> 00:14:21.970
traffic.

00:14:21.970 --> 00:14:24.210
And it's partially due
to, as we were saying,

00:14:24.210 --> 00:14:28.280
memcache taking out
90% of the queries.

00:14:28.280 --> 00:14:32.370
So that's how we get code
to users fairly quickly.

00:14:32.370 --> 00:14:34.256
Devon's now going to
talk about how we make

00:14:34.256 --> 00:14:35.380
sure that we keep it quick.

00:14:35.380 --> 00:14:36.280
DEVON CAREW: Yeah.

00:14:36.280 --> 00:14:40.370
So I'm going to talk about
some hosted metric services.

00:14:40.370 --> 00:14:44.870
So we've done some work
to make the back-end fast.

00:14:44.870 --> 00:14:49.170
We have benchmarks running
on each commit and tuned

00:14:49.170 --> 00:14:49.980
the back-end.

00:14:49.980 --> 00:14:52.604
We've actually done some work to
make the front-end fast, which

00:14:52.604 --> 00:14:54.460
basically means we don't
serve up many bits.

00:14:54.460 --> 00:14:56.000
There are as few
bits as possible.

00:14:56.000 --> 00:14:58.690
And we make as few requests
as possible when we start up.

00:14:58.690 --> 00:15:01.970
So we use dev tools to
optimize our loading.

00:15:01.970 --> 00:15:06.292
We're compiling our
JavaScript minified.

00:15:06.292 --> 00:15:07.000
And that's great.

00:15:07.000 --> 00:15:10.532
So we're fast, but generally,
things won't stay fast.

00:15:10.532 --> 00:15:11.740
Your code's going to bit rot.

00:15:11.740 --> 00:15:14.270
And unless you actually
watch the back-end

00:15:14.270 --> 00:15:18.740
and the front-end performance,
your speed's going to degrade.

00:15:18.740 --> 00:15:22.380
So how do you keep it fast?

00:15:22.380 --> 00:15:23.970
You want to measure
it, basically.

00:15:23.970 --> 00:15:26.178
On every commit, you want
to measure your performance

00:15:26.178 --> 00:15:27.110
metrics.

00:15:27.110 --> 00:15:30.034
And we're using a hosted
metric service called Librato.

00:15:30.034 --> 00:15:31.950
There's some other
services out there like it.

00:15:31.950 --> 00:15:33.575
But you can basically
post your metrics

00:15:33.575 --> 00:15:36.090
on a build to this
service, and go to it

00:15:36.090 --> 00:15:37.610
and view your graphs
of the metrics

00:15:37.610 --> 00:15:40.330
over time, which can
actually be very powerful.

00:15:40.330 --> 00:15:43.370
So this is how
you get it set up.

00:15:43.370 --> 00:15:46.212
There's a Librato library
where it's just basically

00:15:46.212 --> 00:15:49.540
a simple HTTP post of
arbitrary metrics data.

00:15:49.540 --> 00:15:51.800
In this example, we're
measuring the size

00:15:51.800 --> 00:15:54.860
of our compiled desktop
front-end and mobile front-end

00:15:54.860 --> 00:15:57.380
and uploading those.

00:15:57.380 --> 00:16:00.040
And here's what it looks
like at the Librato site.

00:16:00.040 --> 00:16:03.000
You can see we have
over a dozen metrics--

00:16:03.000 --> 00:16:07.840
the front-end size, our
back-end benchmarking times

00:16:07.840 --> 00:16:11.120
in terms of times to compile,
times for code completion,

00:16:11.120 --> 00:16:18.340
times for analysis,
and an actual benchmark

00:16:18.340 --> 00:16:19.880
from a few weeks ago.

00:16:19.880 --> 00:16:24.460
Our compiled desktop size, you
can see, we ran at about 350K

00:16:24.460 --> 00:16:28.030
for our compiled size, except
we had a huge spike there

00:16:28.030 --> 00:16:30.590
when it jumped to almost 700K.

00:16:30.590 --> 00:16:32.690
What happened there was
we imported the library,

00:16:32.690 --> 00:16:35.610
which transiently imported
lots of other Dart code,

00:16:35.610 --> 00:16:38.522
and our front-end size doubled.

00:16:38.522 --> 00:16:39.980
But having a service
like this lets

00:16:39.980 --> 00:16:43.330
us track these significant
regressions very quickly

00:16:43.330 --> 00:16:45.770
and identify the get
commit that caused it.

00:16:45.770 --> 00:16:48.330
But it also helps with
a lot more subtle things

00:16:48.330 --> 00:16:51.062
where, over a month, maybe
your size increases by 10%,

00:16:51.062 --> 00:16:52.770
and you can identify
two or three commits

00:16:52.770 --> 00:16:55.650
that each added 2% or 3%.

00:16:55.650 --> 00:17:01.900
So having visibility into these
regressions is very powerful.

00:17:01.900 --> 00:17:04.410
So Luke is going to talk
about uptime monitoring

00:17:04.410 --> 00:17:06.444
to round this out.

00:17:06.444 --> 00:17:08.319
LUKE CHURCH: So what
you're in a position now

00:17:08.319 --> 00:17:09.778
is that you have
your application.

00:17:09.778 --> 00:17:10.569
You're shipping it.

00:17:10.569 --> 00:17:11.386
It's working.

00:17:11.386 --> 00:17:13.260
You know that you're
not regressing code size

00:17:13.260 --> 00:17:15.480
as you go forward.

00:17:15.480 --> 00:17:18.910
This leads to another question
suitable for keeping web

00:17:18.910 --> 00:17:21.140
maintenance people up at night.

00:17:21.140 --> 00:17:23.038
If your site goes
down, how is it

00:17:23.038 --> 00:17:25.079
that you would know that
you're no longer serving

00:17:25.079 --> 00:17:27.329
to your users, you're now
just throwing error messages

00:17:27.329 --> 00:17:28.614
at them?

00:17:28.614 --> 00:17:30.030
And in order to
find this out, you

00:17:30.030 --> 00:17:32.520
can use uptime
monitoring services.

00:17:32.520 --> 00:17:37.554
So we're using a service
called Pingdom, [INAUDIBLE].

00:17:37.554 --> 00:17:39.970
We've used a couple of different
ones-- [? Status Care ?],

00:17:39.970 --> 00:17:40.770
for example.

00:17:40.770 --> 00:17:42.590
So what these things
allow you to do

00:17:42.590 --> 00:17:45.260
is request that the
service sends you

00:17:45.260 --> 00:17:48.652
a continuous series of data
points-- roughly speaking,

00:17:48.652 --> 00:17:50.110
I think, in this
case, we configure

00:17:50.110 --> 00:17:53.120
it as to one per
minute-- saying,

00:17:53.120 --> 00:17:55.010
OK, perform this
code completion.

00:17:55.010 --> 00:17:56.360
Do this compilation.

00:17:56.360 --> 00:17:57.870
Do this analysis.

00:17:57.870 --> 00:18:01.090
And it allows you to track both
any times when you get outages,

00:18:01.090 --> 00:18:04.980
you can get proactive
notifications, SMSes, emails.

00:18:04.980 --> 00:18:08.280
It also allows you track any
creeping latency problems,

00:18:08.280 --> 00:18:10.850
or any latency problems
if you get a report in of,

00:18:10.850 --> 00:18:12.500
your site was really slow.

00:18:12.500 --> 00:18:15.460
Understanding whether that was
slow because of the services

00:18:15.460 --> 00:18:18.460
or slow because of networking
issues is really useful.

00:18:18.460 --> 00:18:21.222
So we use uptime
services to do this.

00:18:21.222 --> 00:18:22.680
It also, as I
mentioned earlier, it

00:18:22.680 --> 00:18:25.700
sends this low-grade,
continuous trickle of requests

00:18:25.700 --> 00:18:28.080
into your system, which,
if you tune carefully,

00:18:28.080 --> 00:18:32.650
means that the frequently hit
paths will be warm whenever

00:18:32.650 --> 00:18:34.570
a new series of users turn up.

00:18:34.570 --> 00:18:37.475
So you get that continuous
keeping the system productive.

00:18:40.410 --> 00:18:43.610
So that gives us
basically a summary of how

00:18:43.610 --> 00:18:46.690
do you build an application, how
do you make sure it's reliable

00:18:46.690 --> 00:18:49.105
as you're building it, how
do you ship it to users,

00:18:49.105 --> 00:18:50.730
and then how do you
make sure that it's

00:18:50.730 --> 00:18:52.240
keeping working
and keeping serving

00:18:52.240 --> 00:18:55.190
your users with the
experience that you want to.

00:18:55.190 --> 00:18:56.480
So over to Devon to wrap up.

00:18:56.480 --> 00:18:57.230
DEVON CAREW: Cool.

00:18:57.230 --> 00:18:58.520
Yeah.

00:18:58.520 --> 00:19:01.210
So I think a takeaway
from this talk,

00:19:01.210 --> 00:19:03.350
hopefully, is that
Dart works today

00:19:03.350 --> 00:19:04.970
with a number of
hosted services.

00:19:04.970 --> 00:19:08.830
These services can be really
valuable for your projects.

00:19:08.830 --> 00:19:11.690
If you want to see examples of
how we actually hooked up these

00:19:11.690 --> 00:19:15.310
services to continuous
integration and other systems,

00:19:15.310 --> 00:19:17.350
you can look at
the DartPad repo--

00:19:17.350 --> 00:19:21.500
github.com/dart-lang/dar-pad.

00:19:21.500 --> 00:19:23.280
And we'd like to take
a moment to thank

00:19:23.280 --> 00:19:24.780
some of our open
source contributors

00:19:24.780 --> 00:19:27.431
who've had some significant
contributions in terms

00:19:27.431 --> 00:19:29.680
of our code completion UI
and some other functionality

00:19:29.680 --> 00:19:31.950
from external people.

00:19:31.950 --> 00:19:35.290
And one other thing to announce.

00:19:35.290 --> 00:19:39.060
We're shipping 1.0
today of DartPart.

00:19:39.060 --> 00:19:40.760
So go use it.

00:19:40.760 --> 00:19:47.827
[APPLAUSE]

00:19:47.827 --> 00:19:49.910
LUKE CHURCH: There were
some DJs around somewhere,

00:19:49.910 --> 00:19:50.580
weren't there?

00:19:50.580 --> 00:19:52.900
Where did they go?

00:19:52.900 --> 00:19:55.910
DEVON CAREW: So unless
they tell us otherwise,

00:19:55.910 --> 00:19:58.910
I think we have
time for questions.

00:19:58.910 --> 00:20:06.080
No microphones, so-- nope?

00:20:06.080 --> 00:20:07.330
OK.

00:20:07.330 --> 00:20:08.080
LUKE CHURCH: Sure.

00:20:08.080 --> 00:20:10.450
AUDIENCE: Do you guys have a
roadmap for the near-future?

00:20:10.450 --> 00:20:12.658
LUKE CHURCH: So the question
is, just off the record,

00:20:12.658 --> 00:20:14.510
do we have a roadmap
for the near future?

00:20:14.510 --> 00:20:15.926
Yeah, we should
add some features.

00:20:15.926 --> 00:20:17.285
That would be good, wouldn't it?

00:20:17.285 --> 00:20:18.560
[LAUGHTER]

00:20:18.560 --> 00:20:21.745
I think we planned
a bit of a UI redux.

00:20:21.745 --> 00:20:23.710
There's some stuff on
mobile that we'd like

00:20:23.710 --> 00:20:24.876
to make a little bit better.

00:20:24.876 --> 00:20:26.610
That would be great.

00:20:26.610 --> 00:20:27.360
DEVON CAREW: Yeah.

00:20:27.360 --> 00:20:30.335
We support sharing today,
using GitHub gists.

00:20:30.335 --> 00:20:34.520
It uses an anonymous API, which
means you can create a gist.

00:20:34.520 --> 00:20:37.640
But if you update it, you
have to fork an existing gist.

00:20:37.640 --> 00:20:40.700
So we're going to add some OAuth
authentication to it so you can

00:20:40.700 --> 00:20:45.060
update any gist that you
create or fork other people's.

00:20:45.060 --> 00:20:47.690
And yeah, we're going
to do, probably,

00:20:47.690 --> 00:20:49.657
a UI redux of the
desktop and the mobile.

00:20:49.657 --> 00:20:51.490
They're two separate
applications right now,

00:20:51.490 --> 00:20:54.240
two completely separate UIs.

00:20:54.240 --> 00:20:56.840
And we want to unify that,
probably around a material

00:20:56.840 --> 00:20:59.443
design look and feel.

00:20:59.443 --> 00:21:00.832
LUKE CHURCH: Yep.

00:21:00.832 --> 00:21:01.758
AUDIENCE: [INAUDIBLE].

00:21:05.000 --> 00:21:07.770
LUKE CHURCH: I'm also kind
of interested in whatever

00:21:07.770 --> 00:21:10.730
it takes to get people to learn
a new programming language.

00:21:10.730 --> 00:21:12.370
It's kind of a
research interest.

00:21:12.370 --> 00:21:16.710
So looking at what we can
do around smart suggestions.

00:21:16.710 --> 00:21:19.010
So we already have a bit of
a documentation discovery

00:21:19.010 --> 00:21:19.620
support.

00:21:19.620 --> 00:21:23.544
But I think, because it's more
intended for small snippets,

00:21:23.544 --> 00:21:24.960
we can probably
do things that are

00:21:24.960 --> 00:21:26.860
quite a lot smarter than that.

00:21:26.860 --> 00:21:29.020
So looking at putting some
of those experiments in,

00:21:29.020 --> 00:21:33.786
seeing which ones
work, it's on the plan.

00:21:33.786 --> 00:21:37.139
AUDIENCE: Are there any
plans to make an embeddable,

00:21:37.139 --> 00:21:39.055
little, just try it out thing?

00:21:39.055 --> 00:21:41.460
Like if I have a
blog and [INAUDIBLE]?

00:21:41.460 --> 00:21:42.556
LUKE CHURCH: Sure.

00:21:42.556 --> 00:21:43.930
So the question
is, are there any

00:21:43.930 --> 00:21:45.200
plans to make it embeddable?

00:21:45.200 --> 00:21:47.900
So if you just want to try a
little bit out in your blog,

00:21:47.900 --> 00:21:49.759
could you do that?

00:21:49.759 --> 00:21:51.550
I think it's certainly
something that we're

00:21:51.550 --> 00:21:53.100
very interested in doing.

00:21:53.100 --> 00:21:55.950
One of the reasons to split
the strategy up this way

00:21:55.950 --> 00:21:58.560
was to mean that, if you wanted
a completely different UI

00:21:58.560 --> 00:22:02.130
for doing that, all the
services are available for you.

00:22:02.130 --> 00:22:04.470
But yeah, we're kind of
interested in doing that ,

00:22:04.470 --> 00:22:08.050
particularly around [? Doc's ?]
discovery on API [INAUDIBLE].

00:22:08.050 --> 00:22:09.259
We'll see how that plays out.

00:22:09.259 --> 00:22:11.049
MALE SPEAKER: I can be
your question buddy,

00:22:11.049 --> 00:22:11.848
if you guys want.

00:22:11.848 --> 00:22:12.514
DEVON CAREW: OK.

00:22:12.514 --> 00:22:13.264
LUKE CHURCH: Sure.

00:22:13.264 --> 00:22:16.051
MALE SPEAKER: Are
there more questions?

00:22:16.051 --> 00:22:17.050
I just killed your vibe.

00:22:17.050 --> 00:22:17.530
I'm sorry.

00:22:17.530 --> 00:22:18.488
LUKE CHURCH: All right.

00:22:18.488 --> 00:22:19.468
Yeah.

00:22:19.468 --> 00:22:21.259
MALE SPEAKER: We have
time for more, right?

00:22:21.259 --> 00:22:22.009
We have a couple--

00:22:22.009 --> 00:22:23.250
LUKE CHURCH: I have no idea.

00:22:23.250 --> 00:22:24.050
There's no clock here.

00:22:24.050 --> 00:22:25.586
I have no idea how long
I've been going on for.

00:22:25.586 --> 00:22:26.280
[INTERPOSING VOICES]

00:22:26.280 --> 00:22:27.738
MALE SPEAKER: Yeah,
you've got time

00:22:27.738 --> 00:22:29.940
for a couple more questions,
if you guys-- yes?

00:22:29.940 --> 00:22:30.440
No?

00:22:30.440 --> 00:22:32.910
Questions, anyone?

00:22:32.910 --> 00:22:35.664
Yes, let me bring you a mic.

00:22:35.664 --> 00:22:37.900
AUDIENCE: Thank you.

00:22:37.900 --> 00:22:41.410
Any plans on adding
collaboration feature?

00:22:41.410 --> 00:22:44.569
Two guys could code together.

00:22:44.569 --> 00:22:45.860
DEVON CAREW: Oh, collaboration.

00:22:45.860 --> 00:22:48.700
So the question is, do we
have any plans for adding

00:22:48.700 --> 00:22:51.090
collaborative editing?

00:22:51.090 --> 00:22:51.790
Yeah.

00:22:51.790 --> 00:22:53.200
It's not on our roadmap.

00:22:53.200 --> 00:22:56.670
I think it'd be an
interesting use case.

00:22:56.670 --> 00:22:59.720
But yeah, DartPad
serves a good purpose

00:22:59.720 --> 00:23:02.110
right now of learning
Dart on the web

00:23:02.110 --> 00:23:03.605
and being able share snippets.

00:23:03.605 --> 00:23:04.980
And collaborative
is interesting,

00:23:04.980 --> 00:23:07.160
but it's definitely
not something

00:23:07.160 --> 00:23:09.164
we're actively working on.

00:23:09.164 --> 00:23:11.080
MALE SPEAKER: The code
is open source, though?

00:23:11.080 --> 00:23:11.740
DEVON CAREW: Yeah.

00:23:11.740 --> 00:23:13.280
MALE SPEAKER: Can you add
auto-complete to Google Docs,

00:23:13.280 --> 00:23:14.660
and then just call it done?

00:23:14.660 --> 00:23:15.410
DEVON CAREW: Yeah.

00:23:15.410 --> 00:23:16.385
Yeah.

00:23:16.385 --> 00:23:18.760
LUKE CHURCH: Yeah, although
collaboration for source code

00:23:18.760 --> 00:23:20.560
is really hard.

00:23:20.560 --> 00:23:23.120
There's a lot of very
complex workflows

00:23:23.120 --> 00:23:25.210
that people engage in.

00:23:25.210 --> 00:23:27.870
But it would be fantastic, if
somebody else felt like trying

00:23:27.870 --> 00:23:28.953
that out as an experiment.

00:23:31.072 --> 00:23:32.030
MALE SPEAKER: Any more?

00:23:38.612 --> 00:23:40.570
AUDIENCE: You mentioned
that you run benchmarks

00:23:40.570 --> 00:23:42.028
on every commit,
which is something

00:23:42.028 --> 00:23:43.340
our team should definitely do.

00:23:43.340 --> 00:23:46.230
I was wondering what
frameworks and services

00:23:46.230 --> 00:23:47.942
you use to do that.

00:23:47.942 --> 00:23:50.877
DEVON CAREW: Yeah, there's
a benchmark harness package,

00:23:50.877 --> 00:23:52.210
which we were using for a while.

00:23:52.210 --> 00:23:55.080
It's available on GitHub.

00:23:55.080 --> 00:23:57.660
It supports
synchronous benchmarks,

00:23:57.660 --> 00:24:00.620
which is great, unless you
need to return a future.

00:24:00.620 --> 00:24:02.970
So we basically have a
small internal version

00:24:02.970 --> 00:24:07.040
of that, which warms up whatever
code you need to benchmark.

00:24:07.040 --> 00:24:09.380
Warms it up for a while,
then it runs like 10 of them,

00:24:09.380 --> 00:24:10.570
divides that number.

00:24:10.570 --> 00:24:15.720
So you can actually see the
benchmark on our GitHub repo.

00:24:15.720 --> 00:24:18.390
But its benchmark harness
is obviously pretty tiny.

00:24:18.390 --> 00:24:21.350
You just want to do it
right, and then-- yeah.

00:24:21.350 --> 00:24:23.430
AUDIENCE: So does that
run with Travis UI,

00:24:23.430 --> 00:24:25.210
and then post the
result somewhere?

00:24:25.210 --> 00:24:25.960
DEVON CAREW: Yeah.

00:24:25.960 --> 00:24:29.410
So our build script on Travis
basically analyzes the Dart

00:24:29.410 --> 00:24:32.360
code, looks for errors and
warnings, runs our unit tests,

00:24:32.360 --> 00:24:35.150
runs the integration
tests via Sauce Labs.

00:24:35.150 --> 00:24:36.590
Everything looks good.

00:24:36.590 --> 00:24:38.930
It gathers code
coverage information,

00:24:38.930 --> 00:24:41.030
and ships it up to Librato.

00:24:41.030 --> 00:24:44.264
And it also runs the
benchmarks and ships that.

00:24:44.264 --> 00:24:46.680
Well, it ships the benchmarks
to Librato and code coverage

00:24:46.680 --> 00:24:47.179
to coverall.

00:24:47.179 --> 00:24:50.164
So yeah, our benchmark
script is like 40 lines long,

00:24:50.164 --> 00:24:51.580
and does a bunch
of-- or our build

00:24:51.580 --> 00:24:53.425
script does a bunch of things.

00:24:53.425 --> 00:24:55.770
So yeah.

00:24:55.770 --> 00:24:58.440
LUKE CHURCH: We also run
separate, out of band,

00:24:58.440 --> 00:25:01.450
much more intensive
testing before publishing

00:25:01.450 --> 00:25:05.120
each new major revision
of Dart services.

00:25:05.120 --> 00:25:09.190
We run a large collection of
basically all of the Dart line

00:25:09.190 --> 00:25:12.530
suite of tests over it.

00:25:12.530 --> 00:25:15.780
But that takes multiple
tens of hours to run,

00:25:15.780 --> 00:25:17.712
so we don't run that
on every commit.

00:25:17.712 --> 00:25:20.019
AUDIENCE: How long does
their CI take right now?

00:25:20.019 --> 00:25:22.435
MALE SPEAKER: The question
was, how long does the CI take?

00:25:22.435 --> 00:25:23.440
LUKE CHURCH: It's like
a few minutes, isn't it?

00:25:23.440 --> 00:25:23.790
DEVON CAREW: Yeah.

00:25:23.790 --> 00:25:26.220
I think used to know more,
but it's like three or four.

00:25:26.220 --> 00:25:27.650
It turns around pretty quickly.

00:25:27.650 --> 00:25:29.707
So yeah.

00:25:29.707 --> 00:25:31.540
MALE SPEAKER: So as
usual, the default thing

00:25:31.540 --> 00:25:33.170
that I say at the end is,
these guys will be around

00:25:33.170 --> 00:25:35.240
and would love to have you come
talk to them, if you see them,

00:25:35.240 --> 00:25:36.980
if you have more
follow-up questions.

00:25:36.980 --> 00:25:37.480
LUKE CHURCH: Absolutely.

00:25:37.480 --> 00:25:38.010
MALE SPEAKER: Thanks, guys.

00:25:38.010 --> 00:25:38.520
LUKE CHURCH: Thank you.

00:25:38.520 --> 00:25:39.353
DEVON CAREW: Thanks.

00:25:39.353 --> 00:25:40.353
[APPLAUSE]

