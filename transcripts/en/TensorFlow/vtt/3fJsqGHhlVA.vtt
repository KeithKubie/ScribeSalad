WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.840
[MUSIC PLAYING]

00:00:03.340 --> 00:00:05.620
RICHARD WEI: Good
morning, and welcome.

00:00:05.620 --> 00:00:06.480
My name's Richard.

00:00:06.480 --> 00:00:07.770
JAMES BRADBURY: I'm James.

00:00:07.770 --> 00:00:09.120
RICHARD WEI: We're
thrilled to talk to you

00:00:09.120 --> 00:00:10.787
about a next-generation
machine learning

00:00:10.787 --> 00:00:13.900
platform, Swift for TensorFlow.

00:00:13.900 --> 00:00:17.240
TensorFlow is a world-leading
ecosystem for machine learning,

00:00:17.240 --> 00:00:18.990
and we're always looking
to make it better

00:00:18.990 --> 00:00:20.690
for all kinds of users.

00:00:20.690 --> 00:00:23.910
TensorFlow 2.0,
available in alpha,

00:00:23.910 --> 00:00:27.120
makes it easier than ever
to get started with ML.

00:00:27.120 --> 00:00:29.970
But we're also looking
further beyond.

00:00:29.970 --> 00:00:31.830
In this session, I'm
going to tell you

00:00:31.830 --> 00:00:33.990
about a project to rethink
what a machine learning

00:00:33.990 --> 00:00:35.853
framework could look like.

00:00:35.853 --> 00:00:37.770
You might hear Swift for
TensorFlow and think,

00:00:37.770 --> 00:00:40.020
this is going to
be about iOS apps.

00:00:40.020 --> 00:00:42.570
But Swift is also a
general purpose language

00:00:42.570 --> 00:00:47.230
that we think will help
enable the future of ML.

00:00:47.230 --> 00:00:49.300
When figuring out what a
next-generation machine

00:00:49.300 --> 00:00:51.130
learning platform
should look like,

00:00:51.130 --> 00:00:54.730
we have been guided by
three fundamental goals.

00:00:54.730 --> 00:00:56.710
First, we would
like to make sure

00:00:56.710 --> 00:01:00.130
that every developer can be
a machine learning developer.

00:01:00.130 --> 00:01:05.080
Second, we'd like to make sure
that every application can

00:01:05.080 --> 00:01:09.070
benefit from the power of ML.

00:01:09.070 --> 00:01:12.490
Third, we've seen that the
frontiers of ML research are

00:01:12.490 --> 00:01:15.700
pushing the boundaries of a
software stack split between

00:01:15.700 --> 00:01:17.710
Python and C++.

00:01:17.710 --> 00:01:23.260
So we want a unified platform in
the friendly and fast language.

00:01:23.260 --> 00:01:25.330
This is why we decided
to develop something

00:01:25.330 --> 00:01:28.320
a little outside the box.

00:01:28.320 --> 00:01:31.770
So we've taken the Swift
programming language,

00:01:31.770 --> 00:01:34.680
a general purpose and
cross-platform language that

00:01:34.680 --> 00:01:38.520
compiles to native code, and
built general machine learning

00:01:38.520 --> 00:01:41.220
functionality right
into its core,

00:01:41.220 --> 00:01:45.040
and combined its power with
the TensorFlow ecosystem.

00:01:45.040 --> 00:01:49.700
And this is Swift
for TensorFlow.

00:01:49.700 --> 00:01:53.070
Swift is a language designed
to be easy to learn and use.

00:01:53.070 --> 00:01:55.080
Let's take a look.

00:01:55.080 --> 00:01:59.740
Swift's syntax is familiar
and free of boilerplate.

00:01:59.740 --> 00:02:03.230
Swift has types, so it
catches errors early for you.

00:02:03.230 --> 00:02:08.120
But it uses type inference,
so it feels clean and simple.

00:02:08.120 --> 00:02:10.729
Swift encourages
fluent API design.

00:02:10.729 --> 00:02:13.220
So your code is
fluent and readable

00:02:13.220 --> 00:02:17.300
at both the definitions
side and the call side.

00:02:17.300 --> 00:02:20.250
Swift is open source
and has an open process

00:02:20.250 --> 00:02:23.680
that allows us to propose new
changes, new language features

00:02:23.680 --> 00:02:27.790
for all Swift developers.

00:02:27.790 --> 00:02:29.920
Swift supports
prototyping platforms

00:02:29.920 --> 00:02:33.840
such as a command line
interpreter, Jupyter Notebooks,

00:02:33.840 --> 00:02:35.770
and Playgrounds.

00:02:35.770 --> 00:02:37.360
Just import your
favorite libraries

00:02:37.360 --> 00:02:40.360
and get started right away.

00:02:40.360 --> 00:02:43.270
The TensorFlow library includes
our carefully curated Tensor

00:02:43.270 --> 00:02:47.320
APIs, layer APIs, as well
as general abstractions

00:02:47.320 --> 00:02:50.300
that help you build your own.

00:02:50.300 --> 00:02:54.610
Now let's look at how to build
a deep learning model in Swift.

00:02:54.610 --> 00:02:57.460
This is an image
classification model.

00:02:57.460 --> 00:02:59.260
This is built out
of several layers,

00:02:59.260 --> 00:03:03.620
forming a simple
convolutional neural network.

00:03:03.620 --> 00:03:07.360
The call function applies
every layer sequentially,

00:03:07.360 --> 00:03:09.910
producing a final output.

00:03:09.910 --> 00:03:13.780
Once we have defined the
model, it's time to train it.

00:03:13.780 --> 00:03:15.810
We start by
initializing the model

00:03:15.810 --> 00:03:18.420
in the stochastic gradient
descent optimizer.

00:03:18.420 --> 00:03:22.420
We'll be using random
data here, x and y.

00:03:22.420 --> 00:03:26.550
Now we write a training
loop, apply the model,

00:03:26.550 --> 00:03:29.860
compute the loss from labels
using the softmaxCrossEntropy()

00:03:29.860 --> 00:03:34.090
function, and compute the
gradient of the loss with

00:03:34.090 --> 00:03:37.210
respect to the
model's parameters.

00:03:37.210 --> 00:03:39.460
Finally, we can
use the optimizer

00:03:39.460 --> 00:03:42.610
to update all the differentiable
variables and all parameters

00:03:42.610 --> 00:03:44.860
in the model.

00:03:44.860 --> 00:03:47.680
Our layer and optimizer
APIs are inspired

00:03:47.680 --> 00:03:52.030
by libraries like Keras, and
are designed to be familiar.

00:03:52.030 --> 00:03:55.930
A huge part of Swift for
TensorFlow is workflow.

00:03:55.930 --> 00:03:58.030
Lots and lots of
research breakthroughs

00:03:58.030 --> 00:04:01.780
in machine learning come
from prototyping ideas.

00:04:01.780 --> 00:04:05.500
Google Colab is a hosted
Jupyter Notebook environment

00:04:05.500 --> 00:04:07.615
that allows you to
prototype your ideas right

00:04:07.615 --> 00:04:10.030
in your browser.

00:04:10.030 --> 00:04:11.620
A lot of researchers
and developers

00:04:11.620 --> 00:04:15.440
use Python with
TensorFlow in Colab today.

00:04:15.440 --> 00:04:20.571
And now we've made Colab
work seamlessly with Swift.

00:04:20.571 --> 00:04:22.029
Now let's show you
Swift in action.

00:04:25.460 --> 00:04:27.980
This is a Colab notebook.

00:04:27.980 --> 00:04:31.160
As we start typing, we get
an immediate code completion.

00:04:31.160 --> 00:04:33.710
Here we use functional
map to add 1

00:04:33.710 --> 00:04:37.260
to each element in an array.

00:04:37.260 --> 00:04:41.380
And it prints just
like you expect.

00:04:41.380 --> 00:04:44.720
Now let's look at a basic
workflow in more detail.

00:04:44.720 --> 00:04:46.750
Here's the dictionary
of numbers.

00:04:46.750 --> 00:04:50.260
And I want to find the largest
even number in each array.

00:04:50.260 --> 00:04:54.610
To do that, I'm using a for loop
that loops through all elements

00:04:54.610 --> 00:04:59.800
where the element is both
greater than the largest--

00:04:59.800 --> 00:05:03.760
than the last largest
one found and is even.

00:05:03.760 --> 00:05:07.090
Let's run that and
see what happens.

00:05:07.090 --> 00:05:08.170
Oops, what's wrong?

00:05:08.170 --> 00:05:12.430
Well, it looks like Int doesn't
have a property called isEven.

00:05:12.430 --> 00:05:14.650
No problem, let's add one.

00:05:14.650 --> 00:05:16.300
Even though the
Int type is defined

00:05:16.300 --> 00:05:18.640
in the standard
library, we can still

00:05:18.640 --> 00:05:20.590
add methods and
properties to it.

00:05:20.590 --> 00:05:23.800
In Swift, this is
called an extension.

00:05:23.800 --> 00:05:25.990
Here we define a Boolean
computed property

00:05:25.990 --> 00:05:30.560
called isEven, implement it in
terms of the isMultiple method.

00:05:30.560 --> 00:05:33.940
As you can see, Swift's
syntax and naming conventions

00:05:33.940 --> 00:05:38.080
look more like English than
other programming languages.

00:05:38.080 --> 00:05:41.810
And now everything works.

00:05:41.810 --> 00:05:44.000
By importing TensorFlow,
we get the power

00:05:44.000 --> 00:05:46.670
of TensorFlow operators
as functions and methods

00:05:46.670 --> 00:05:48.290
on a Tensor type.

00:05:48.290 --> 00:05:50.480
Many of these
methods are the same

00:05:50.480 --> 00:05:53.240
as they would be in NumPy
and Python TensorFlow.

00:05:53.240 --> 00:05:55.710
Other APIs make use
of Swifty features,

00:05:55.710 --> 00:05:59.080
like generics and
argument labels.

00:05:59.080 --> 00:06:01.650
TensorFlow also provides deep
learning building blocks,

00:06:01.650 --> 00:06:05.083
such as layers and optimizes.

00:06:05.083 --> 00:06:06.500
Here's the same
simple [INAUDIBLE]

00:06:06.500 --> 00:06:07.510
that we just showed you.

00:06:07.510 --> 00:06:12.080
We're on GPU, and it's
running really fast.

00:06:12.080 --> 00:06:15.810
Running the cells
train the model.

00:06:15.810 --> 00:06:16.800
It is that simple.

00:06:20.340 --> 00:06:24.570
So that was Swift for
TensofFlow in Colab.

00:06:24.570 --> 00:06:26.070
Writing Swift for
machine learning

00:06:26.070 --> 00:06:28.920
is not all that different from
writing dynamic languages.

00:06:28.920 --> 00:06:32.670
With Colab, you can start Swift
right away in your browser,

00:06:32.670 --> 00:06:36.090
and it gives you code
completion, free GPUs,

00:06:36.090 --> 00:06:38.400
and you can even install a
package, using Swift package

00:06:38.400 --> 00:06:41.430
manager, right in your notebook.

00:06:41.430 --> 00:06:43.370
You don't have to
install anything.

00:06:43.370 --> 00:06:46.020
It's really handy.

00:06:46.020 --> 00:06:48.840
Next up, interoperability--

00:06:48.840 --> 00:06:51.390
Swift interoperates
transparently with C.

00:06:51.390 --> 00:06:55.680
So you can literally just
import a C header and use it.

00:06:55.680 --> 00:06:58.470
But how about all
the libraries--

00:06:58.470 --> 00:07:00.750
everybody's favorite machine
learning and data science

00:07:00.750 --> 00:07:01.840
libraries in Python?

00:07:01.840 --> 00:07:04.830
Do we have to read/write
everything in Swift?

00:07:04.830 --> 00:07:06.820
The answer is, we don't.

00:07:06.820 --> 00:07:09.510
In Swift for TensorFlow,
we have extended

00:07:09.510 --> 00:07:13.350
Swift's seamless language
interoperability to Python.

00:07:13.350 --> 00:07:15.600
As you start using
Swift for TensorFlow,

00:07:15.600 --> 00:07:18.120
we want to make sure that you
didn't miss all the utilities

00:07:18.120 --> 00:07:21.630
and libraries that
you're used to.

00:07:21.630 --> 00:07:23.970
Now let's show you
how interoperability

00:07:23.970 --> 00:07:25.170
works in Swift.

00:07:27.810 --> 00:07:30.780
Python interoperability is
enabled by a lightweight Swift

00:07:30.780 --> 00:07:33.840
library called Python.

00:07:33.840 --> 00:07:36.460
Let's start by importing that.

00:07:36.460 --> 00:07:40.300
Python.import lets you import
any Python package installed

00:07:40.300 --> 00:07:41.350
with pip.

00:07:41.350 --> 00:07:45.430
Hundreds of popular packages
are pre-installed in Colab.

00:07:45.430 --> 00:07:48.205
Here we're going to use
NumPy and Matplotlib.

00:07:48.205 --> 00:07:53.060
We also enable their in-notebook
visualization functionality.

00:07:53.060 --> 00:07:56.650
Now we can call some common
NumPy and plotting functions

00:07:56.650 --> 00:08:00.350
directly from Swift exactly
as if we're writing Python,

00:08:00.350 --> 00:08:03.320
and it just works.

00:08:03.320 --> 00:08:06.820
Now, OpenAI Gym is
a Python library

00:08:06.820 --> 00:08:09.820
of reinforcement learning
environments, little games

00:08:09.820 --> 00:08:10.980
for AIs.

00:08:10.980 --> 00:08:15.830
Let's import that and
solve one of the games.

00:08:15.830 --> 00:08:18.830
One of these games is
a cart-pole environment

00:08:18.830 --> 00:08:23.250
where you train a neural
net to balance a pendulum.

00:08:23.250 --> 00:08:25.310
We'll use a simple
two-layer neural network.

00:08:28.010 --> 00:08:30.680
In each episode of
the game is a loop.

00:08:30.680 --> 00:08:33.880
We get observations from
the Python environment

00:08:33.880 --> 00:08:36.590
and call our Swift neural
net to choose an action.

00:08:39.610 --> 00:08:41.559
After running the
game a few times,

00:08:41.559 --> 00:08:44.560
we use the games that
went well as training data

00:08:44.560 --> 00:08:47.140
and update our neural net's
parameters so that it will

00:08:47.140 --> 00:08:50.350
pick better actions next time.

00:08:50.350 --> 00:08:53.200
Repeating this process, we're
getting better and better,

00:08:53.200 --> 00:08:55.180
higher and higher rewards.

00:08:55.180 --> 00:08:56.930
Finally, the problem's solved.

00:09:00.400 --> 00:09:03.670
We can also plot
the mean rewards.

00:09:03.670 --> 00:09:05.140
As you see, you
can mix and match

00:09:05.140 --> 00:09:09.730
idiomatic Swift code, Python
code, and a neural net defined

00:09:09.730 --> 00:09:11.350
inline in Swift.

00:09:11.350 --> 00:09:14.370
It is so seamless.

00:09:14.370 --> 00:09:17.580
In fact, Python interoperability
isn't hard-coded in the Swift

00:09:17.580 --> 00:09:18.600
compiler.

00:09:18.600 --> 00:09:21.660
It's actually written as
a library in pure Swift.

00:09:21.660 --> 00:09:24.600
And you can do the same--

00:09:24.600 --> 00:09:26.610
do the same to make
your libraries--

00:09:26.610 --> 00:09:30.630
to make Swift interoperability
work with Ruby or JavaScript

00:09:30.630 --> 00:09:33.570
and other dynamic languages.

00:09:33.570 --> 00:09:36.420
Now, in cutting-edge
research and applications,

00:09:36.420 --> 00:09:39.420
people often need to dive
into low-level implementations

00:09:39.420 --> 00:09:41.200
for better performance.

00:09:41.200 --> 00:09:45.300
Swift's C interoperability
makes that surprisingly easy.

00:09:45.300 --> 00:09:49.410
Importing Glibc gives you access
the C standard library from

00:09:49.410 --> 00:09:53.410
qsort() all the way down
to malloc() and free().

00:09:53.410 --> 00:09:57.300
Here we allocate some memory
using malloc(), store string,

00:09:57.300 --> 00:09:58.980
and print it.

00:09:58.980 --> 00:10:02.250
Now it's probably fair to
say that Swift in Colab

00:10:02.250 --> 00:10:04.950
gives you a better C prototyping
experience than the C

00:10:04.950 --> 00:10:07.748
language itself.

00:10:07.748 --> 00:10:09.915
Now I hope you'll agree
that the best parts of Swift

00:10:09.915 --> 00:10:12.640
for TensorFlow is how
easy it is to work

00:10:12.640 --> 00:10:15.660
with code that is not in Swift.

00:10:15.660 --> 00:10:19.780
And that is interoperability.

00:10:19.780 --> 00:10:21.490
Having a few Python
libraries in hand

00:10:21.490 --> 00:10:24.790
is incredibly useful for day
to day tasks in data science.

00:10:24.790 --> 00:10:27.340
Swift for TensorFlow
embraces interoperability

00:10:27.340 --> 00:10:30.107
and lets you use C and
Python without wrappers--

00:10:34.680 --> 00:10:36.870
so seamless.

00:10:36.870 --> 00:10:39.765
Now it's time to talk about
the dark magic in Swift

00:10:39.765 --> 00:10:43.020
for TensorFlow, differentiation.

00:10:43.020 --> 00:10:45.780
It is fair to say that
calculus is an integral part

00:10:45.780 --> 00:10:48.030
of deep learning.

00:10:48.030 --> 00:10:50.370
This is because machine
learning models are really

00:10:50.370 --> 00:10:53.730
just mathematical functions
expressed in code.

00:10:53.730 --> 00:10:55.980
But the special thing about
them is that we don't just

00:10:55.980 --> 00:10:57.790
want to evaluate
those functions,

00:10:57.790 --> 00:11:00.540
we also want to
change the parameters,

00:11:00.540 --> 00:11:02.910
or train them by changing
their parameters based

00:11:02.910 --> 00:11:05.130
on their derivatives.

00:11:05.130 --> 00:11:07.980
A common technique adopted
by deep learning frameworks

00:11:07.980 --> 00:11:10.590
is called automatic
differentiation.

00:11:10.590 --> 00:11:12.480
Different from
traditional programming,

00:11:12.480 --> 00:11:15.840
doing calculus in code requires
the language or the library

00:11:15.840 --> 00:11:18.430
to understand the
structure of your code.

00:11:18.430 --> 00:11:21.690
But who to understand your
code better than the compiler?

00:11:21.690 --> 00:11:24.740
We think that computing
derivatives from code

00:11:24.740 --> 00:11:28.320
is not just a simple technique,
but also a new programming

00:11:28.320 --> 00:11:31.330
paradigm in the age
of machine learning.

00:11:31.330 --> 00:11:34.650
So we've integrated first-class
automatic differentiation,

00:11:34.650 --> 00:11:38.280
differentiable programming
right into Swift.

00:11:38.280 --> 00:11:40.260
First-class
differential programming

00:11:40.260 --> 00:11:43.800
means that native functions
like this can be differentiated.

00:11:43.800 --> 00:11:46.170
Here's a function of floats.

00:11:46.170 --> 00:11:50.010
You can use a gradient operator
to get its gradient function.

00:11:50.010 --> 00:11:51.270
And just call it.

00:11:51.270 --> 00:11:53.460
It's that simple.

00:11:53.460 --> 00:11:55.470
And you can import
TensorFlow, of course,

00:11:55.470 --> 00:11:59.380
to compute gradients over
tensors in the exact same way.

00:11:59.380 --> 00:12:01.970
In fact, we've been using this
feature in the model training

00:12:01.970 --> 00:12:05.220
examples that you just saw.

00:12:05.220 --> 00:12:07.830
Now instead of telling you how
cool it is, let's show you.

00:12:10.542 --> 00:12:12.000
Here's a simple
function that works

00:12:12.000 --> 00:12:13.980
with the native
double type in Swift.

00:12:13.980 --> 00:12:17.860
It squares x and adds y to it.

00:12:17.860 --> 00:12:21.010
If we mark this function
with differentiable,

00:12:21.010 --> 00:12:24.100
the compiler checks to see if
it can differentiate everything

00:12:24.100 --> 00:12:26.070
that this function calls.

00:12:26.070 --> 00:12:30.310
Now f is a
differentiable function.

00:12:30.310 --> 00:12:32.890
One of the things we can do
with a differentiable function

00:12:32.890 --> 00:12:34.730
is to get its gradient.

00:12:34.730 --> 00:12:37.210
A gradient represents
derivatives

00:12:37.210 --> 00:12:41.200
of the output with respect
to each of its inputs.

00:12:41.200 --> 00:12:43.060
Here the derivatives are with--

00:12:43.060 --> 00:12:45.460
here are the derivatives
with respect to x and y,

00:12:45.460 --> 00:12:48.420
produced by the
gradient operator.

00:12:48.420 --> 00:12:51.710
Well, sometimes it's more
efficient to compute the output

00:12:51.710 --> 00:12:53.640
and the gradient together.

00:12:53.640 --> 00:12:57.460
Here's a function that calls
the squaring function f.

00:12:57.460 --> 00:13:01.520
We can use a value with
gradient operator to do this.

00:13:01.520 --> 00:13:05.000
All our differential operators
like value and gradient

00:13:05.000 --> 00:13:07.730
also work with
arbitrary closures, not

00:13:07.730 --> 00:13:09.970
just named functions.

00:13:09.970 --> 00:13:14.510
Here we use Swift's trailing
closure syntax to simplify it.

00:13:14.510 --> 00:13:19.310
The closure represents the
same g function passed directly

00:13:19.310 --> 00:13:22.740
to the differential operator.

00:13:22.740 --> 00:13:25.210
Now so far, we've seen
differentiation on types

00:13:25.210 --> 00:13:28.300
from the standard library
and model training examples

00:13:28.300 --> 00:13:33.750
earlier, using differentiation
on tensors, layers, and models.

00:13:33.750 --> 00:13:37.330
But in applications, we often
need to define custom types,

00:13:37.330 --> 00:13:41.370
like a point, which has
an x and a y component.

00:13:41.370 --> 00:13:44.520
Here we also define a
custom function, dot(),

00:13:44.520 --> 00:13:48.930
that takes the dot product
of two points representing

00:13:48.930 --> 00:13:51.000
vectors.

00:13:51.000 --> 00:13:53.160
Now what if I call the
differential operator

00:13:53.160 --> 00:13:55.140
on the dot product function?

00:13:55.140 --> 00:13:59.700
Boom, Swift reports an error
at compile time saying point

00:13:59.700 --> 00:14:02.910
is not differentiable, does
not conform to the protocol

00:14:02.910 --> 00:14:04.127
"differentiable."

00:14:04.127 --> 00:14:05.620
Don't worry.

00:14:05.620 --> 00:14:07.800
This is because Swift
supports generics

00:14:07.800 --> 00:14:09.420
and generic constraints.

00:14:09.420 --> 00:14:11.070
The differential
operator defined

00:14:11.070 --> 00:14:14.640
for functions whose
parameters and return type--

00:14:14.640 --> 00:14:17.490
takes functions whose
parameters' type and return

00:14:17.490 --> 00:14:20.550
type conform to the
differentiable protocol.

00:14:20.550 --> 00:14:23.563
Now all we have to do is to
make the point struct conform

00:14:23.563 --> 00:14:24.855
to the differentiable protocol.

00:14:27.420 --> 00:14:31.320
And now everything works.

00:14:31.320 --> 00:14:34.110
Because a gradient operator
returns a gradient tuple,

00:14:34.110 --> 00:14:36.510
it expected two
arguments, a and b.

00:14:36.510 --> 00:14:39.510
We can simplify the code by
using Swift's pattern matching

00:14:39.510 --> 00:14:42.600
capability to retrieve the
tuple elements in one line.

00:14:45.430 --> 00:14:47.680
Swift's compile-time
automatic differentiation

00:14:47.680 --> 00:14:50.730
can also detect
more subtle errors.

00:14:50.730 --> 00:14:55.960
Here we define a function called
roundedSum() on the point that

00:14:55.960 --> 00:14:59.110
rounds the x and y components
by converting them, first,

00:14:59.110 --> 00:15:02.110
to integers, then converting
the sum back to float,

00:15:02.110 --> 00:15:04.000
back to a double.

00:15:04.000 --> 00:15:08.690
Let's see if this function
can be differentiated.

00:15:08.690 --> 00:15:10.780
Well, it looks like we
shouldn't have done that.

00:15:10.780 --> 00:15:13.810
Functions over integers
are not differentiable,

00:15:13.810 --> 00:15:16.150
because the functions
are not continuous.

00:15:16.150 --> 00:15:20.710
And the compiler knows
exactly why and tells you.

00:15:20.710 --> 00:15:23.800
We showed you earlier that Swift
has seamless interoperability

00:15:23.800 --> 00:15:26.800
with C. But what happens
if I use a differential

00:15:26.800 --> 00:15:29.560
operator on a C function?

00:15:29.560 --> 00:15:31.060
Well, let's try that.

00:15:31.060 --> 00:15:33.550
Let's try to
differentiate square root.

00:15:33.550 --> 00:15:36.030
Well, it looks like it
can't be differentiated.

00:15:36.030 --> 00:15:38.490
This is because a function
is not defined in Swift,

00:15:38.490 --> 00:15:41.520
and the C compiler cannot
compute derivatives.

00:15:41.520 --> 00:15:43.140
But don't worry.

00:15:43.140 --> 00:15:45.690
Let's write a Swift function
that calls the C version

00:15:45.690 --> 00:15:49.150
and write a custom
derivative for it.

00:15:49.150 --> 00:15:52.770
Now, in elementary calculus,
the derivative of square root

00:15:52.770 --> 00:15:55.930
is negative 1 over 2 root x.

00:15:55.930 --> 00:15:59.910
We can define such a derivative
as a Swift function that

00:15:59.910 --> 00:16:03.870
returns both the original
output and the closure that

00:16:03.870 --> 00:16:06.180
applies the chain rule
of differentiation

00:16:06.180 --> 00:16:09.770
to compute the derivative.

00:16:09.770 --> 00:16:13.620
If we mark this function as
differentiating square root--

00:16:17.130 --> 00:16:19.810
when we do this, we're
telling the compiler, whenever

00:16:19.810 --> 00:16:23.680
you differentiate a square root,
treat the derivative function

00:16:23.680 --> 00:16:25.850
as its derivative.

00:16:25.850 --> 00:16:29.370
Now we can differentiate
that function.

00:16:29.370 --> 00:16:31.740
So this exact-- this
is also exactly how

00:16:31.740 --> 00:16:34.260
we made all the functions
and methods in the TensorFlow

00:16:34.260 --> 00:16:35.750
library differentiable.

00:16:35.750 --> 00:16:38.350
It is that simple.

00:16:38.350 --> 00:16:40.030
Isn't that amazing?

00:16:40.030 --> 00:16:42.550
Having automatic
differentiation built directly

00:16:42.550 --> 00:16:45.952
into a general purpose
language is unprecedented.

00:16:45.952 --> 00:16:47.410
It's a super-exciting
time to bring

00:16:47.410 --> 00:16:49.450
your applications,
intelligent applications,

00:16:49.450 --> 00:16:51.990
to the next level.

00:16:51.990 --> 00:16:55.680
Differentiable programming
is new era of programming.

00:16:55.680 --> 00:16:58.710
Language integration gives
you useful compile-time errors

00:16:58.710 --> 00:17:00.960
and the flexibility to
make user-defined types

00:17:00.960 --> 00:17:01.980
differential.

00:17:01.980 --> 00:17:04.130
There's also a tremendous
amount of depth here.

00:17:04.130 --> 00:17:07.150
But if you're interested
in learning how it works,

00:17:07.150 --> 00:17:11.670
we have some detailed
design documentation online.

00:17:11.670 --> 00:17:14.160
Next up-- performance.

00:17:14.160 --> 00:17:15.950
Swift is fast.

00:17:15.950 --> 00:17:18.720
Swift has good low-level
performance thanks

00:17:18.720 --> 00:17:21.310
to its LLVM-powered compiler.

00:17:21.310 --> 00:17:23.250
And it lets
programmers use threads

00:17:23.250 --> 00:17:25.349
for multi-core concurrency.

00:17:25.349 --> 00:17:28.000
For deep learning code, we
start with eager execution,

00:17:28.000 --> 00:17:30.115
so writing TensorFlow
code feels great.

00:17:30.115 --> 00:17:32.550
But the compiler
is also doing a lot

00:17:32.550 --> 00:17:35.010
of things behind the scenes.

00:17:35.010 --> 00:17:37.500
It's optimizing the
tensor computation,

00:17:37.500 --> 00:17:41.240
all without changing
the programming model.

00:17:41.240 --> 00:17:44.000
One trend we're seeing is
that deep learning models

00:17:44.000 --> 00:17:48.200
are getting integrated into
bigger and bigger applications.

00:17:48.200 --> 00:17:50.540
The problem is, doing
this often requires

00:17:50.540 --> 00:17:53.000
you to export models
and treat them

00:17:53.000 --> 00:17:55.380
as black boxes in your code.

00:17:55.380 --> 00:17:57.950
But we think that Swift for
TensorFlow can make it better.

00:17:57.950 --> 00:18:01.130
Because your model is
expressed just as code.

00:18:01.130 --> 00:18:04.530
And it sits alongside the
rest of the application.

00:18:04.530 --> 00:18:07.280
And this enables all sorts of
whole-program optimizations

00:18:07.280 --> 00:18:09.440
that a compiler
is really good at.

00:18:09.440 --> 00:18:13.110
It makes debugging a lot easier.

00:18:13.110 --> 00:18:15.927
What about performance
in a research context?

00:18:15.927 --> 00:18:17.510
Some of the most
cutting-edge projects

00:18:17.510 --> 00:18:19.930
like DeepMind's
AlphaGo and AlphaZero

00:18:19.930 --> 00:18:23.270
worked by bringing these
three things together.

00:18:23.270 --> 00:18:26.870
They use deep neural nets
integrated into classical AI

00:18:26.870 --> 00:18:28.670
search algorithms.

00:18:28.670 --> 00:18:30.920
While it's possible for an
advanced team like DeepMind

00:18:30.920 --> 00:18:34.730
to build all of this, we think
that an AI-first language

00:18:34.730 --> 00:18:36.360
can make it easier.

00:18:36.360 --> 00:18:39.080
And lowering the barriers
in the infrastructure

00:18:39.080 --> 00:18:41.540
between deep learning and
traditional programming

00:18:41.540 --> 00:18:43.265
can lead to new
breakthroughs in science.

00:18:45.930 --> 00:18:48.360
The MiniGo project is a
ground-up, open source

00:18:48.360 --> 00:18:50.370
replication of the
central advances

00:18:50.370 --> 00:18:55.500
of AlphaGo and AlphaZero
using GCP and Cloud TPUs.

00:18:55.500 --> 00:18:58.455
In order to achieve the best
performance from the Monte

00:18:58.455 --> 00:19:01.830
Carlo tree search algorithm
that evaluates possible moves,

00:19:01.830 --> 00:19:05.340
the author also had to rewrite
everything in a complex mixture

00:19:05.340 --> 00:19:08.450
of C++ and Python.

00:19:08.450 --> 00:19:11.720
But Swift for TensorFlow
gives you a better option.

00:19:11.720 --> 00:19:14.150
Because MiniGo can be
written in one language

00:19:14.150 --> 00:19:16.430
without sacrificing performance.

00:19:16.430 --> 00:19:18.340
Let's see what that
looks like in Swift.

00:19:21.000 --> 00:19:22.960
The Swift models
repository on GitHub

00:19:22.960 --> 00:19:25.000
contains machine
learning models that we

00:19:25.000 --> 00:19:27.170
built using Swift
for TensorFlow,

00:19:27.170 --> 00:19:30.460
such as common [INAUDIBLE],,
transformer, and of course,

00:19:30.460 --> 00:19:32.580
MiniGo.

00:19:32.580 --> 00:19:36.000
On Linux or Mac OS, we can
build a models repository

00:19:36.000 --> 00:19:40.140
using Swift package
manager via Swift build.

00:19:40.140 --> 00:19:44.310
Or we can just open the IDE to
develop machine learning models

00:19:44.310 --> 00:19:47.040
like traditional applications.

00:19:47.040 --> 00:19:51.160
The MiniGo game has
three components--

00:19:51.160 --> 00:19:55.830
one, the game board, two,
the Monte Carlo tree search

00:19:55.830 --> 00:19:59.400
algorithm, three, the
convolutional model

00:19:59.400 --> 00:20:02.190
to use with tree search.

00:20:02.190 --> 00:20:06.240
They're all defined in Swift
code in this workspace.

00:20:06.240 --> 00:20:10.680
Recently, we've started doing
some refactoring on the Monaco.

00:20:10.680 --> 00:20:13.815
Now let's run some
unit tests and see

00:20:13.815 --> 00:20:15.150
if we have broken anything.

00:20:20.370 --> 00:20:22.080
Whoa, what's wrong?

00:20:22.080 --> 00:20:23.640
Well, it looks like the--

00:20:23.640 --> 00:20:29.580
if we go to the test, looks like
the shape of the value tensor

00:20:29.580 --> 00:20:33.170
is expected to be 2, 1.

00:20:33.170 --> 00:20:34.920
Well, where did that come from?

00:20:34.920 --> 00:20:37.380
Let's just jump to the
definition, the prediction

00:20:37.380 --> 00:20:39.713
method that returned it.

00:20:39.713 --> 00:20:41.130
Well, the prediction
method simply

00:20:41.130 --> 00:20:43.900
call self via the call method.

00:20:43.900 --> 00:20:45.570
So let's look at that.

00:20:45.570 --> 00:20:48.540
Now let's set a breakpoint
and run the test again

00:20:48.540 --> 00:20:49.530
to see what's going on.

00:20:55.446 --> 00:20:57.300
At the breakpoint,
we can print out

00:20:57.300 --> 00:21:01.530
the shape of the value tensor
using the lldb debugger,

00:21:01.530 --> 00:21:06.670
exactly like
application development.

00:21:06.670 --> 00:21:09.040
Well, it looks like the
tensor has shape 2, 1,

00:21:09.040 --> 00:21:11.440
but the test expected just 2.

00:21:11.440 --> 00:21:15.670
To fix that, we can
simply flatten the tensor

00:21:15.670 --> 00:21:18.110
by calling the flatten method.

00:21:18.110 --> 00:21:21.390
Now let's drop the breakpoint
and run everything again.

00:21:29.420 --> 00:21:31.760
Great, all tests are passing.

00:21:31.760 --> 00:21:33.530
We could run the game
locally, but it'll

00:21:33.530 --> 00:21:37.085
be pretty slow on a laptop CPU.

00:21:37.085 --> 00:21:41.240
How about running it on
a free GPU in a Colab.

00:21:41.240 --> 00:21:43.090
Let's do it.

00:21:43.090 --> 00:21:44.310
Let's open Chrome.

00:21:44.310 --> 00:21:47.300
And here's a Colab that's
installing the MiniGo

00:21:47.300 --> 00:21:51.930
library that we've been working
on using Swift package manager.

00:21:51.930 --> 00:21:54.980
And so Swift package manager
pulls directly from GitHub

00:21:54.980 --> 00:21:55.850
and sets things up.

00:22:02.550 --> 00:22:04.960
Now it's linking and
initializing Swift.

00:22:13.700 --> 00:22:16.330
Here we download some
pre-trained weights using

00:22:16.330 --> 00:22:18.130
some command line command.

00:22:27.170 --> 00:22:29.600
And we also set up
the game environment,

00:22:29.600 --> 00:22:31.910
like the Go board
and the players.

00:22:34.945 --> 00:22:36.320
Now the game is
starting to play.

00:22:41.090 --> 00:22:43.940
The stones are being
placed on the Go board one

00:22:43.940 --> 00:22:46.590
step at a time.

00:22:46.590 --> 00:22:50.735
Now we're running a Go
AI on GPU in the Colab.

00:22:54.506 --> 00:22:56.820
Isn't that amazing?

00:22:56.820 --> 00:22:58.430
To advance through
the game, here's

00:22:58.430 --> 00:23:02.260
the same game that has been
running for quite a while.

00:23:02.260 --> 00:23:04.840
Isn't that cool?

00:23:04.840 --> 00:23:08.620
So that is MiniGo and Colab.

00:23:08.620 --> 00:23:12.220
Having deep learning models sit
alongside complex algorithms

00:23:12.220 --> 00:23:15.410
in an application and
debugging through all of them--

00:23:15.410 --> 00:23:18.700
the dream has finally come true.

00:23:18.700 --> 00:23:21.250
Now you've seen how a unified
programming model makes it

00:23:21.250 --> 00:23:23.860
so easy to push the
state-of-the-art in machine

00:23:23.860 --> 00:23:25.120
learning research.

00:23:25.120 --> 00:23:28.010
But we want to go even further.

00:23:28.010 --> 00:23:31.150
For example, Google is
making a major investment

00:23:31.150 --> 00:23:34.390
in fundamental compiler
technologies, an infrastructure

00:23:34.390 --> 00:23:37.060
that will allow you to write
custom kernels for hardware

00:23:37.060 --> 00:23:41.260
acceleration right in Swift,
and even in Colab someday.

00:23:41.260 --> 00:23:43.480
Now James will talk
to you about that work

00:23:43.480 --> 00:23:45.760
and where Swift fits into
the future of the TensorFlow

00:23:45.760 --> 00:23:46.510
ecosystem.

00:23:46.510 --> 00:23:47.257
James.

00:23:47.257 --> 00:23:48.590
JAMES BRADBURY: Thanks, Richard.

00:23:51.160 --> 00:23:53.860
So this is a broad-brush
look at the lifecycle

00:23:53.860 --> 00:23:55.840
of a TensorFlow model today.

00:23:55.840 --> 00:23:58.450
You build a model,
typically using Python.

00:23:58.450 --> 00:24:00.760
And then you can run it
in many different ways

00:24:00.760 --> 00:24:04.100
on many different
kinds of hardware.

00:24:04.100 --> 00:24:07.110
And Swift can plug right
into this ecosystem.

00:24:07.110 --> 00:24:08.940
In fact, that's
what we're doing.

00:24:08.940 --> 00:24:11.900
We want it to be possible to
use a TensorFlow model written

00:24:11.900 --> 00:24:14.960
in Swift in all the places
you can use a TensorFlow

00:24:14.960 --> 00:24:17.603
model built in Python.

00:24:17.603 --> 00:24:19.520
But the reality is there's
a lot of complexity

00:24:19.520 --> 00:24:23.690
here, many different hardware
back ends and compiler stacks.

00:24:23.690 --> 00:24:27.740
And thankfully, the team is
working on a long-term project

00:24:27.740 --> 00:24:32.900
to unify and simplify the
situation with a new compiler

00:24:32.900 --> 00:24:37.130
infrastructure called MLIR,
or Multi-Level Intermediate

00:24:37.130 --> 00:24:38.660
Representation.

00:24:38.660 --> 00:24:41.750
Things like the
TFLite model converter

00:24:41.750 --> 00:24:44.900
and compilers for specialized
hardware, all of them

00:24:44.900 --> 00:24:47.180
will be able to
share functionality,

00:24:47.180 --> 00:24:49.510
like source location tracking.

00:24:49.510 --> 00:24:51.620
And this will make life
easier for everyone

00:24:51.620 --> 00:24:55.070
in the ecosystem, all the
way from app developers

00:24:55.070 --> 00:24:58.520
who want a better experience
like high-quality error

00:24:58.520 --> 00:25:01.970
messages when exporting to
mobile, all the way to hardware

00:25:01.970 --> 00:25:06.010
vendors who want to implement
TensorFlow support more easily.

00:25:06.010 --> 00:25:10.760
Check out the TensorFlow blog
for more details on MLIR.

00:25:10.760 --> 00:25:12.770
Now the reason I'm
bringing this up

00:25:12.770 --> 00:25:16.070
is that MLIR is a
great opportunity

00:25:16.070 --> 00:25:19.370
to take advantage of
the strengths of Swift

00:25:19.370 --> 00:25:21.600
as a compiled language.

00:25:21.600 --> 00:25:26.810
So while Python will be able
to drive MLIR-based compilers

00:25:26.810 --> 00:25:30.440
at runtime, Swift
will also drive them

00:25:30.440 --> 00:25:33.200
from its own compiler,
bringing benefits

00:25:33.200 --> 00:25:36.680
like type safety
and static binaries.

00:25:36.680 --> 00:25:39.900
In short, for users who
need the flexibility,

00:25:39.900 --> 00:25:43.280
we can make the entire
TensorFlow ecosystem directly

00:25:43.280 --> 00:25:46.670
accessible from Swift, all the
way down to low-level device

00:25:46.670 --> 00:25:49.550
capabilities for writing
custom kernels, all

00:25:49.550 --> 00:25:52.820
the while improving the
experience for everyone who

00:25:52.820 --> 00:25:54.920
uses TensorFlow.

00:25:54.920 --> 00:25:56.540
So that's MLIR.

00:25:56.540 --> 00:25:59.990
Let's talk about the
original vision again.

00:25:59.990 --> 00:26:03.140
We think Swift for TensorFlow
can help every developer become

00:26:03.140 --> 00:26:05.220
a machine learning developer.

00:26:05.220 --> 00:26:08.150
Thanks to Swift's support for
quality tooling like context

00:26:08.150 --> 00:26:10.190
aware, auto-complete,
and the integration

00:26:10.190 --> 00:26:12.640
of differentiable programming
deep into the language,

00:26:12.640 --> 00:26:15.980
Swift for TensorFlow can be
one of the most productive ways

00:26:15.980 --> 00:26:18.710
to get started learning
the fundamentals of machine

00:26:18.710 --> 00:26:19.740
learning.

00:26:19.740 --> 00:26:22.580
In fact, you don't have
to take our word for it.

00:26:22.580 --> 00:26:25.790
Jeremy Howard's fast.ai
recently announced

00:26:25.790 --> 00:26:28.070
that they're including
Swift for TensorFlow

00:26:28.070 --> 00:26:32.835
in the next iteration of their
popular deep learning course.

00:26:32.835 --> 00:26:34.210
We think Swift
for TensorFlow can

00:26:34.210 --> 00:26:36.190
help make sure every
app can benefit

00:26:36.190 --> 00:26:37.780
from the power of
machine learning

00:26:37.780 --> 00:26:41.260
by bridging the gap between
application code and machine

00:26:41.260 --> 00:26:42.797
learning code.

00:26:42.797 --> 00:26:44.380
And we think that
Swift for TensorFlow

00:26:44.380 --> 00:26:46.690
will provide a great
option for researchers

00:26:46.690 --> 00:26:50.960
who need a high-performance
host language like Swift.

00:26:50.960 --> 00:26:53.420
To break down the barriers
for you to get started,

00:26:53.420 --> 00:26:55.430
Google Colab hosted
notebooks give you

00:26:55.430 --> 00:27:00.050
free access to GPU resources
right in your browser.

00:27:00.050 --> 00:27:03.260
And Jupyter Notebooks let you
quickly prototype your ideas

00:27:03.260 --> 00:27:04.660
locally or on remote machines.

00:27:07.750 --> 00:27:10.460
Swift for TensorFlow also
supports Linux and Mac OS

00:27:10.460 --> 00:27:11.460
natively.

00:27:11.460 --> 00:27:13.820
So you can use your
favorite IDE or run

00:27:13.820 --> 00:27:16.962
the interpreter in a terminal.

00:27:16.962 --> 00:27:18.920
RICHARD WEI: Swift for
TensorFlow's 0.3 release

00:27:18.920 --> 00:27:20.870
is available today,
which contains

00:27:20.870 --> 00:27:22.700
all the technologies
that powered the demos

00:27:22.700 --> 00:27:23.840
that you just saw.

00:27:23.840 --> 00:27:25.700
We think it's
ready for pioneers,

00:27:25.700 --> 00:27:27.860
especially if you're running
into limits of Python

00:27:27.860 --> 00:27:30.170
as a host language or
mixing deep learning

00:27:30.170 --> 00:27:31.550
with traditional programming.

00:27:31.550 --> 00:27:33.050
JAMES BRADBURY:
Swift for TensorFlow

00:27:33.050 --> 00:27:34.312
is not yet production-ready.

00:27:34.312 --> 00:27:36.020
But if you're excited
about what you see,

00:27:36.020 --> 00:27:39.170
we have Colab tutorials you can
run in your browser and binary

00:27:39.170 --> 00:27:41.150
tool chains you can
download and use.

00:27:41.150 --> 00:27:44.060
We're actively designing and
building high-level machine

00:27:44.060 --> 00:27:47.993
learning libraries and improving
the programming experience.

00:27:47.993 --> 00:27:50.410
RICHARD WEI: The whole project
is developed in open source

00:27:50.410 --> 00:27:53.510
at github.com/tensorflow/swift.

00:27:53.510 --> 00:27:56.190
Try it out today, and we
think you're going to love it.

00:27:56.190 --> 00:27:58.232
JAMES BRADBURY: This is
an incredible opportunity

00:27:58.232 --> 00:28:02.107
for developers like you to help
shape the future of TensorFlow.

00:28:02.107 --> 00:28:04.440
RICHARD WEI: Thank you for
coming, and have a great I/O.

00:28:04.440 --> 00:28:07.790
[MUSIC PLAYING]

