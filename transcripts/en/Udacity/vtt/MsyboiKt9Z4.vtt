WEBVTT
Kind: captions
Language: en

00:00:00.370 --> 00:00:04.338
Lately there's been a huge growth
in using infrared structured light.

00:00:04.338 --> 00:00:07.460
All right, and infrared structured
light, one of the nice things about it

00:00:07.460 --> 00:00:11.740
is you and I can't see it, so
it's doing all this stuff out there but

00:00:11.740 --> 00:00:14.750
it's not,
sort of interfering with our vision.

00:00:14.750 --> 00:00:19.300
And the main reason,
that IR structured light has become so

00:00:19.300 --> 00:00:22.900
big is because of this puppy right here,
the Microsoft Kinect, all right?

00:00:24.100 --> 00:00:28.440
Kudos to my friends and colleagues
in in England and Cambridge who

00:00:28.440 --> 00:00:32.380
helped take the technology, and it was,
the 3-D technology that I'll tell

00:00:32.380 --> 00:00:36.770
you about was actually developed by
PrimeSense which was a Israel company.

00:00:36.770 --> 00:00:41.110
And then Microsoft leveraged
it in a way to go from

00:00:41.110 --> 00:00:42.990
the depth to recovering skeleton,

00:00:42.990 --> 00:00:46.570
which is a whole other interesting piece
of work that we won't talk about here.

00:00:46.570 --> 00:00:47.740
But if we did it in machine learning,

00:00:47.740 --> 00:00:49.110
since they used machine
learning methods for

00:00:49.110 --> 00:00:51.728
doing it,
we could talk more about doing that.

00:00:51.728 --> 00:00:56.450
But the Kinect is really, I mean it was
$150, so all of a sudden you could put

00:00:56.450 --> 00:01:00.950
depth sensors on little experimental
robots for very little money.

00:01:00.950 --> 00:01:03.060
So, how does the Kinect work?

00:01:03.060 --> 00:01:05.730
Well, it's not public, all right?

00:01:05.730 --> 00:01:08.160
So there are people who know
exactly how the Kinect works,

00:01:08.160 --> 00:01:11.030
people from PrimeSense,
etc., but it's not public.

00:01:11.030 --> 00:01:14.010
Lots and lots of this stuff is known.

00:01:14.010 --> 00:01:16.910
But the exact implementations
are not known.

00:01:16.910 --> 00:01:20.620
The PrimeSense patents
describe at least two ways.

00:01:20.620 --> 00:01:24.590
And I will tell you about
both of those ways.

00:01:25.880 --> 00:01:28.850
Conventional wisdom is that one of
the ways is actually used in the Kinect

00:01:28.850 --> 00:01:29.700
and one is not.

00:01:29.700 --> 00:01:32.540
I don't really care,
they're both kind of interesting.

00:01:32.540 --> 00:01:38.750
So, the two methods, that they use,
one is a very, very clever optics trick.

00:01:38.750 --> 00:01:41.955
In fact, it's so clever I don't totally
understand exactly how it works,

00:01:41.955 --> 00:01:43.410
because I have to get more into detail.

00:01:43.410 --> 00:01:46.370
But essentially, it projects a pattern
with two different kinds of lenses, and

00:01:46.370 --> 00:01:47.560
we'll talk more about it in a minute,

00:01:47.560 --> 00:01:51.900
that allows you to go directly
from the image to the depth.

00:01:51.900 --> 00:01:53.110
We'll explain that.

00:01:53.110 --> 00:01:56.890
And then the much more standard way,
which is just like light striping,

00:01:56.890 --> 00:01:59.900
is that you're essentially using
something about the projected image from

00:02:00.990 --> 00:02:03.470
the projection of a particular pattern,
and

00:02:03.470 --> 00:02:05.750
what it's observed like in the,
in the other camera.

00:02:06.800 --> 00:02:09.800
So, you're about to see some
drawings that look kind of funky.

00:02:09.800 --> 00:02:10.660
They don't look like, you know,

00:02:10.660 --> 00:02:13.810
the high quality drawings that
Megan always insists that I use.

00:02:13.810 --> 00:02:16.700
But that's because these are actually
taken directly from the patent and

00:02:16.700 --> 00:02:17.850
the patent applications.

00:02:17.850 --> 00:02:19.340
I think it's cool to just see those.

00:02:19.340 --> 00:02:22.790
So the key to the Kinect sorry,

00:02:22.790 --> 00:02:26.570
the key to PrimeSense focus method
are these cylindrical lenses.

00:02:26.570 --> 00:02:29.130
So cylindrical lenses,
if you take two of them and

00:02:29.130 --> 00:02:31.650
you have one that goes one way and
I think on the next thing,

00:02:31.650 --> 00:02:37.370
you have one goes the other way, you
end up with this funny situation where

00:02:37.370 --> 00:02:42.250
you have different focal lengths
depending upon which way you move.

00:02:42.250 --> 00:02:44.910
So you have a,
one focal length horizontally and

00:02:44.910 --> 00:02:47.410
a different focal length vertically,
and of course,

00:02:47.410 --> 00:02:50.680
slightly different focal length as
you were to sort of, rotate around.

00:02:51.810 --> 00:02:55.300
What this allows them to do is
to project out speckles, and

00:02:55.300 --> 00:03:00.040
they, now,
what happens when a dot is out of focus?

00:03:00.040 --> 00:03:03.780
Well, in a normal lens, right,
it becomes a blurry circle.

00:03:04.960 --> 00:03:07.660
When you have one of these,
what are called, astigmatic or asym,

00:03:07.660 --> 00:03:12.350
asymmetric lenses, it becomes
an ellipse because the, the lenses

00:03:12.350 --> 00:03:15.680
are different in one direction than
they are in another direction.

00:03:15.680 --> 00:03:18.070
And what's cool about the way
they did this geometry, and

00:03:18.070 --> 00:03:21.080
this is the part that I'd have to work
through the math more to understand,

00:03:21.080 --> 00:03:25.430
is that depending upon the depth,
so here the hand is at one z and

00:03:25.430 --> 00:03:28.470
here is at another z,
again these are from the patent.

00:03:28.470 --> 00:03:32.130
These ellipses, well they have different
thickness, but more importantly,

00:03:32.130 --> 00:03:34.810
they have different orientations.

00:03:34.810 --> 00:03:39.550
So you can just take a look at
the orientation in a little local area,

00:03:39.550 --> 00:03:42.790
of these little dots that
have been smeared, and

00:03:42.790 --> 00:03:45.260
the orientation tells you the depth.

00:03:45.260 --> 00:03:47.220
This is really, really cool.

00:03:47.220 --> 00:03:49.755
But I think it's so
cool that they probably don't use it.

00:03:49.755 --> 00:03:53.080
because I think it requires some pretty
precise lensing and some other things.

00:03:53.080 --> 00:03:54.410
I'm not, not really sure.

00:03:54.410 --> 00:03:58.220
But this is the,
the one method of how the Kinect works.

00:03:58.220 --> 00:04:01.170
And if you go in their patent, you'll
see figures that talk about like this,

00:04:01.170 --> 00:04:03.160
that you capture this test image and

00:04:03.160 --> 00:04:06.560
then you find the range base
upon the pattern orientation.

00:04:06.560 --> 00:04:09.630
And then you build this 3D map.

00:04:09.630 --> 00:04:12.700
Although you notice this says
based on offsets between test and

00:04:12.700 --> 00:04:13.910
reference pattern.

00:04:13.910 --> 00:04:16.380
So that's the method
I'm about to tell you.

00:04:16.380 --> 00:04:18.680
Here's the one that just talks
about the, the, orientation.

