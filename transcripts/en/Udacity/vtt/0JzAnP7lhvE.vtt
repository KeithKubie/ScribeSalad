WEBVTT
Kind: captions
Language: en

00:00:00.400 --> 00:00:04.620
Okay Michael, so, this is it. Why don't you help me remember what we

00:00:04.620 --> 00:00:06.460
learned in this one marathon session that

00:00:06.460 --> 00:00:08.400
was not all distributed over multiple months.

00:00:08.400 --> 00:00:10.800
&gt;&gt; [LAUGH] Sure. Or years.

00:00:10.800 --> 00:00:11.690
&gt;&gt; Mm hm.

00:00:11.690 --> 00:00:14.150
&gt;&gt; So, MDPs. So, we talked about mark-off

00:00:14.150 --> 00:00:17.453
decision processes, and we said what that meant. [LAUGH]

00:00:17.453 --> 00:00:20.260
&gt;&gt; Okay, so, that's the first thing we did is we talked about MDPs.

00:00:20.260 --> 00:00:26.740
&gt;&gt; And that, that MDP consists of states and rewards and actions and

00:00:26.740 --> 00:00:29.430
like that, transitions, discounts.

00:00:29.430 --> 00:00:33.680
&gt;&gt; So you said discounts and I just want to point out that there are

00:00:33.680 --> 00:00:37.900
some people who think that that's a part of the definition of the problem

00:00:37.900 --> 00:00:40.940
and there are some people who think that that's more of a parameter to

00:00:40.940 --> 00:00:43.090
your algorithm. okay, alright. So there's some

00:00:43.090 --> 00:00:44.610
people who think of it the right way.

00:00:44.610 --> 00:00:47.260
&gt;&gt; Like me. And some people think of it the wrong way. So, I

00:00:47.260 --> 00:00:49.700
tend to think of the discount as

00:00:49.700 --> 00:00:51.760
being something that you're allowed to fiddle with,

00:00:51.760 --> 00:00:53.970
as opposed to it being a fundamental part of the.

00:00:55.740 --> 00:00:57.195
&gt;&gt; Then why not fiddle with the rewards?

00:00:57.195 --> 00:00:59.670
&gt;&gt; Sure. You are allowed to fiddle with the rewards.

00:00:59.670 --> 00:01:02.640
&gt;&gt; Oh! You are very open minded!

00:01:02.640 --> 00:01:06.190
&gt;&gt; I am open minded, i believe that rewards should be able

00:01:06.190 --> 00:01:08.820
to marry other rewards. In any case, the important thing here is

00:01:08.820 --> 00:01:12.660
that there is some under lying process that you care about that

00:01:12.660 --> 00:01:14.000
is suppose to represent the world,

00:01:14.000 --> 00:01:16.810
states, rewards, actions, and transitions and capture

00:01:16.810 --> 00:01:20.250
that fairly well. Discount is, in some sense, an important part of the

00:01:20.250 --> 00:01:23.470
problem, because it tells you how much you want to care about the future

00:01:23.470 --> 00:01:28.370
versus the past. But it's reasonable to think of that as something that you

00:01:28.370 --> 00:01:32.750
might want to change outside of the kind of underlying physics of the world.

00:01:32.750 --> 00:01:36.890
&gt;&gt; I see. Okay, that's fair. Yeah, in some sense, the states and

00:01:36.890 --> 00:01:39.630
the actions and the transitions represent.

00:01:39.630 --> 00:01:41.880
The physical world and the rewards and

00:01:41.880 --> 00:01:44.980
the discount represent the kind of task description.

00:01:44.980 --> 00:01:48.570
&gt;&gt; Right. And of course, you say that, but

00:01:48.570 --> 00:01:51.960
if you, you could decide to define states differently, and

00:01:51.960 --> 00:01:54.120
doing that would impact both your actions and the

00:01:54.120 --> 00:01:56.010
transition function and so on and so forth. But the

00:01:56.010 --> 00:01:58.350
basic idea is right, which is, there's some underlying

00:01:58.350 --> 00:02:01.410
process we're trying to capture, and I think it's exactly

00:02:01.410 --> 00:02:04.210
right to say, states, actions, and transitions. Sort of capture

00:02:04.210 --> 00:02:07.130
that. And rewards and discounts capture more about the nature

00:02:07.130 --> 00:02:09.389
of the task, you're trying to do in that underlying world.

00:02:09.389 --> 00:02:11.200
&gt;&gt; Okay. And in, in that context we talked

00:02:11.200 --> 00:02:16.582
about two really important concepts. Policies and, value functions?

00:02:16.582 --> 00:02:17.364
&gt;&gt; Mm-hm.

00:02:17.364 --> 00:02:18.850
&gt;&gt; Which we sometimes call utilities.

00:02:18.850 --> 00:02:19.250
&gt;&gt; Right.

00:02:19.250 --> 00:02:22.790
&gt;&gt; And how do utilities differ from rewards? The utilities factor in the

00:02:22.790 --> 00:02:26.110
long term aspects, and the rewards are just telling you the moment to moment.

00:02:26.110 --> 00:02:26.750
&gt;&gt; Right.

00:02:26.750 --> 00:02:30.550
&gt;&gt; Utilities are like a group of rewards. Like a gaggle.

00:02:31.850 --> 00:02:32.390
&gt;&gt; Or a murder.

00:02:32.390 --> 00:02:38.720
&gt;&gt; Of crows. So, that we talked about how we

00:02:38.720 --> 00:02:42.283
can assign value to an infinite sequence of rewards. Mm-hm.

00:02:42.283 --> 00:02:44.930
&gt;&gt; But it helps if we use discounting to

00:02:44.930 --> 00:02:47.490
do that so that we don't get infinitely large sums.

00:02:47.490 --> 00:02:52.530
&gt;&gt; And that allowed us to deal with infinite sequences, but threat them as if

00:02:52.530 --> 00:02:57.660
their value is, in fact, finite, thus solving the immortality problem.

00:02:57.660 --> 00:03:03.840
&gt;&gt; [LAUGH] And, let's see, then we kind of.

00:03:03.840 --> 00:03:05.990
And the stationarity was a really important part of that.

00:03:05.990 --> 00:03:09.220
&gt;&gt; Yep. In fact kind of drove everything.

00:03:09.220 --> 00:03:11.710
&gt;&gt; Yeah. And all these things were

00:03:11.710 --> 00:03:14.760
tied up together in the bellman equation itself.

00:03:14.760 --> 00:03:19.880
&gt;&gt; Yes which is an awesome equation and deserves capital letters. [LAUGH]

00:03:19.880 --> 00:03:22.720
Is that it? And then, well then we solve the Bellman

00:03:22.720 --> 00:03:24.880
equation using value iteration and policy iteration.

00:03:24.880 --> 00:03:25.100
&gt;&gt; Oh, yes.

00:03:25.100 --> 00:03:27.030
&gt;&gt; I think that was it. Alright,

00:03:27.030 --> 00:03:29.250
so are any of these polynomial time algorithms?

00:03:29.250 --> 00:03:34.790
&gt;&gt; Well, the way we've been talking about them, no, but you can map

00:03:34.790 --> 00:03:36.470
these into linear programs and turn them

00:03:36.470 --> 00:03:39.700
into polynomial problems, or polynomial. So, yes these

00:03:39.700 --> 00:03:42.120
problems can be solved that way. But

00:03:42.120 --> 00:03:44.120
actually, that reminds me, of something that

00:03:44.120 --> 00:03:45.720
we haven't said and that we haven't

00:03:45.720 --> 00:03:47.760
learned today, that I think is worth mentioning.

00:03:47.760 --> 00:03:50.810
Which is we been talking about, you know, this section

00:03:50.810 --> 00:03:53.410
of the class is about over the course is about

00:03:53.410 --> 00:03:57.300
reinforcement learning. But, we actually haven't done any reinforcement learning

00:03:57.300 --> 00:03:59.750
here because we know everything, we know the states, we

00:03:59.750 --> 00:04:01.450
know the rewards, we know the actions, we know the

00:04:01.450 --> 00:04:05.320
transitions. We have some discount, we have been solving MDP's,

00:04:05.320 --> 00:04:08.970
but that's not quite the same thing [SOUND] as doing

00:04:08.970 --> 00:04:12.770
reinforcement learning, however, it's very important to do these things,

00:04:12.770 --> 00:04:15.960
to make it easier to think about how reinforcement learning works. So,

00:04:15.960 --> 00:04:18.200
in reinforcement learning, the difference is,

00:04:18.200 --> 00:04:21.550
you don't necessarily know, the rewards

00:04:21.550 --> 00:04:23.790
and the transitions or even the states and the actions, for that

00:04:23.790 --> 00:04:27.640
matter. I see. So when are we going to get into reinforcement learning then?

00:04:27.640 --> 00:04:32.320
&gt;&gt; Next time. And when I say we next time, I mean you next

00:04:32.320 --> 00:04:34.360
time. That's your assignment. Learn all about

00:04:34.360 --> 00:04:36.380
reinforcement learning and talk about it next time.

00:04:36.380 --> 00:04:37.940
&gt;&gt; All right. I gotta go and get

00:04:37.940 --> 00:04:38.390
to work then.

00:04:38.390 --> 00:04:40.400
&gt;&gt; Okay. Well, you have a good one Michael.

00:04:40.400 --> 00:04:42.340
&gt;&gt; Thanks for all this. It's really cool.

00:04:42.340 --> 00:04:43.910
&gt;&gt; It is cool. Bye.

00:04:43.910 --> 00:04:44.490
&gt;&gt; Bye.

00:04:44.490 --> 00:04:45.130
&gt;&gt; Bye.

