WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.905
As we talk about algorithms, we're going to talk about 2 costs.

00:00:02.905 --> 00:00:07.483
The first is step complexity, and the second is work complexity.

00:00:07.483 --> 00:00:14.531
So as an example here we have 8 elements that we'd like to combine using this tree style structure.

00:00:14.531 --> 00:00:17.365
And so we're going to try to characterize the number of steps

00:00:17.365 --> 00:00:21.799
that it's going to take us to do this computation as well as the total amount of work.

00:00:21.799 --> 00:00:25.536
So first we're going to look at the number of steps.

00:00:25.536 --> 00:00:28.947
We see that it's going to take us 3 steps to finish.

00:00:28.947 --> 00:00:31.874
This first step here we'll do 4 operations,

00:00:31.874 --> 00:00:34.743
the second step can be done in parallel with 2 operations,

00:00:34.743 --> 00:00:38.455
and then the third step is a final operation to get a final result.

00:00:38.455 --> 00:00:41.639
But we can also count the total amount of work that we've done here.

00:00:41.639 --> 00:00:47.873
We've done 1, 2, 3, 4, 5, 6, 7 operations.

00:00:47.873 --> 00:00:53.922
So we'd say the step complexity is 3 and the work complexity is 7.

00:00:53.922 --> 00:00:58.136
So we'll compare the step and work complexity of the parallel implementations that we develop

00:00:58.136 --> 00:01:01.104
against the step and work complexity for a serial implementation.

00:01:01.104 --> 00:01:03.444
And 1 more piece of terminology.

00:01:03.444 --> 00:01:06.667
We will say that a parallel algorithm is work-efficient.

00:01:06.667 --> 00:01:09.248
If it's work complexity, it's asymptotically the same,

00:01:09.248 --> 00:01:13.066
so within a constant factor as the work complexity of the sequential algorithm.

00:01:13.066 --> 00:01:16.754
Now if we can reduce the step complexity in our parallel implementation

00:01:16.754 --> 00:01:18.655
compared to the serial implementation

00:01:18.655 --> 00:01:22.089
while still having a reasonable work complexity that isn't too expensive,

00:01:22.089 --> 00:01:25.128
we expect that this will lead to faster runtime overall.

00:01:25.128 --> 00:01:28.954
So the real key here is to formulate the most efficient parallel algorithm,

00:01:28.954 --> 00:01:31.968
and that's the focus of this lecture and the next lecture.

