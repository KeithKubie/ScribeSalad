WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.130
VYACHESLAV EGOROV: My
name is Vyacheslav Egorov.

00:00:02.130 --> 00:00:04.130
FLORIAN SCHNEIDER: My
name is Florian Schneider.

00:00:04.130 --> 00:00:06.720
And we'll talk about
ahead-of-time compilation

00:00:06.720 --> 00:00:07.740
in Dart.

00:00:07.740 --> 00:00:10.031
VYACHESLAV EGOROV: Or rather,
Florian is going to talk,

00:00:10.031 --> 00:00:12.300
and I will go and sit,
because we have just two talks

00:00:12.300 --> 00:00:15.473
mixed into one-- so
not to make it awkward.

00:00:15.473 --> 00:00:16.472
FLORIAN SCHNEIDER: Yeah.

00:00:19.250 --> 00:00:23.320
Yeah, this is basically work
we've done since the last Dart

00:00:23.320 --> 00:00:23.880
summit.

00:00:23.880 --> 00:00:27.600
And yeah, that was
done by Slava, Ryan,

00:00:27.600 --> 00:00:29.550
and me-- Ryan, who
couldn't be here today.

00:00:29.550 --> 00:00:33.250
But I'll give you an overview of
what ahead-of-time compilation

00:00:33.250 --> 00:00:35.100
looks like.

00:00:35.100 --> 00:00:40.450
A little of background and
how this all started-- around

00:00:40.450 --> 00:00:42.260
one and a half years
ago, we started

00:00:42.260 --> 00:00:45.780
investigating if
it's feasible to run

00:00:45.780 --> 00:00:48.600
Dart in an ahead-of-time
compiled setting.

00:00:48.600 --> 00:00:52.960
And the reason back then
was that Flutter-- you

00:00:52.960 --> 00:00:56.940
saw the demo in the
keynote, which is awesome.

00:00:56.940 --> 00:01:00.670
We need to run some way
to run efficiently on iOS,

00:01:00.670 --> 00:01:04.000
because we had a JIT
compiler, and that would only

00:01:04.000 --> 00:01:04.810
work on Android.

00:01:04.810 --> 00:01:08.200
And because of the
restrictions in iOS,

00:01:08.200 --> 00:01:10.060
we can't really cheat there.

00:01:10.060 --> 00:01:13.100
So initially, what
Flutter ended up doing is

00:01:13.100 --> 00:01:15.720
they used the ARM
simulator on iOS.

00:01:15.720 --> 00:01:18.130
That is working, but
super slow, so not

00:01:18.130 --> 00:01:22.260
an option to actually
deploy an app.

00:01:22.260 --> 00:01:27.090
So we started prototyping the
ahead-of-time compiler first

00:01:27.090 --> 00:01:30.820
for Intel, to see if
it's possible, last year.

00:01:30.820 --> 00:01:35.320
And then we ended up porting
it to ARM and ARM64, which

00:01:35.320 --> 00:01:40.490
is needed for mobile, and
landed AOT support in the SDK.

00:01:40.490 --> 00:01:46.610
And around last year in October,
Flutter started using it.

00:01:46.610 --> 00:01:48.920
And what we did since
then is basically

00:01:48.920 --> 00:01:52.600
improve it in terms
of speed and size.

00:01:52.600 --> 00:01:55.020
We also found out
that, actually,

00:01:55.020 --> 00:02:00.030
ahead-of-time compiled code
starts up a lot faster on iOS--

00:02:00.030 --> 00:02:01.400
on Android as well.

00:02:01.400 --> 00:02:07.010
So we actually added
support for Android.

00:02:07.010 --> 00:02:11.000
And not directly related
to AOT compilation,

00:02:11.000 --> 00:02:15.410
but in order to get a fast
development cycle also, in iOS,

00:02:15.410 --> 00:02:20.790
we added an efficient
interpreter which is called DBC

00:02:20.790 --> 00:02:25.300
for the iOS development cycle,
because you can't-- on Android,

00:02:25.300 --> 00:02:27.180
you use the JIT compiler
during development.

00:02:27.180 --> 00:02:29.760
And on iOS, you
need something that

00:02:29.760 --> 00:02:32.800
is fast enough so you get
a smooth experience also

00:02:32.800 --> 00:02:33.508
while developing.

00:02:37.100 --> 00:02:41.890
So the way how we went about
this, we had the Dart VM.

00:02:41.890 --> 00:02:44.340
And we had a JIT
compiler and implemented

00:02:44.340 --> 00:02:47.520
a lot of optimizations there.

00:02:47.520 --> 00:02:51.000
And the way we went about
it and got something

00:02:51.000 --> 00:02:53.140
that was ready
for use in Flutter

00:02:53.140 --> 00:02:56.980
in a short amount of time was
we used as many components

00:02:56.980 --> 00:03:00.560
from the Dart VM that are shared
between the JIT and the AOT.

00:03:00.560 --> 00:03:02.956
So the parser,
obviously, is the same.

00:03:02.956 --> 00:03:04.620
It's the same language.

00:03:04.620 --> 00:03:07.900
Many compile optimizations
like register location

00:03:07.900 --> 00:03:11.294
is also basically re-used
between the two compilers.

00:03:11.294 --> 00:03:13.460
The code generator, the
garbage collector, all these

00:03:13.460 --> 00:03:14.130
are shared.

00:03:14.130 --> 00:03:17.480
And we didn't have to
do that from scratch.

00:03:17.480 --> 00:03:20.040
What we had to do is add
a bunch of new components

00:03:20.040 --> 00:03:22.810
to that exclusively needed
for AOT compilation.

00:03:22.810 --> 00:03:28.245
So we needed tree shaking
so that your compiled app is

00:03:28.245 --> 00:03:29.720
small enough.

00:03:29.720 --> 00:03:33.470
The download size should
be reasonably small.

00:03:33.470 --> 00:03:36.250
We added some
AOT-specific compiler

00:03:36.250 --> 00:03:39.027
parsers to speed up the code.

00:03:42.170 --> 00:03:47.100
For startup, we implemented new
snapshot reading and writing.

00:03:47.100 --> 00:03:51.132
Basically, the data stored
in your compiled app

00:03:51.132 --> 00:03:54.940
in your binary should be
initialized as fast as possible

00:03:54.940 --> 00:03:57.150
at startup.

00:03:57.150 --> 00:03:59.820
Another small detail
that's maybe not obvious,

00:03:59.820 --> 00:04:02.230
regular expressions
[INAUDIBLE] before.

00:04:02.230 --> 00:04:05.930
So we had to add an interpreted
version for regular expressions

00:04:05.930 --> 00:04:07.310
to be able to run on iOS.

00:04:10.900 --> 00:04:14.360
So I'll talk about the
three main challenges

00:04:14.360 --> 00:04:18.500
that we faced in this effort.

00:04:18.500 --> 00:04:21.019
The first one is basically
just to make it work.

00:04:21.019 --> 00:04:23.560
Because originally,
Dart VM was not

00:04:23.560 --> 00:04:28.420
meant to run in an
ahead-of-time compiled world.

00:04:28.420 --> 00:04:32.910
And so in order to make
the compiled code suitable,

00:04:32.910 --> 00:04:37.920
we needed to make it generate
relocatable code and also

00:04:37.920 --> 00:04:39.050
isolate-independent code.

00:04:39.050 --> 00:04:43.680
I will talk about what that
means in detail just in a bit.

00:04:43.680 --> 00:04:48.990
And sine we wanted
to share, also,

00:04:48.990 --> 00:04:52.570
many components between
the two compilers,

00:04:52.570 --> 00:04:54.709
we ended up changing,
for example,

00:04:54.709 --> 00:04:56.250
a calling convention
that was needed,

00:04:56.250 --> 00:04:58.640
a new calling
convention, in both.

00:04:58.640 --> 00:05:02.620
And so we can pass
[INAUDIBLE] the current thread

00:05:02.620 --> 00:05:06.100
object in a register.

00:05:06.100 --> 00:05:08.440
And we ended up changing
that both for JIT and AOT.

00:05:08.440 --> 00:05:11.450
So that means we could
run the code in AOT,

00:05:11.450 --> 00:05:16.385
and the JIT code only got
a tiny bit bigger, I guess,

00:05:16.385 --> 00:05:17.635
on the order of a few percent.

00:05:21.970 --> 00:05:27.120
So here's a quick overview
of the Dart VM, the heap

00:05:27.120 --> 00:05:30.250
organization in the JIT world.

00:05:30.250 --> 00:05:34.240
You have your one, or
two, or many isolates,

00:05:34.240 --> 00:05:37.640
and they have their own
data part of the heap.

00:05:37.640 --> 00:05:39.490
They have their own
code part of the heap.

00:05:39.490 --> 00:05:42.060
And almost nothing is shared.

00:05:42.060 --> 00:05:43.790
We share a bunch
of read-only data,

00:05:43.790 --> 00:05:50.170
but all the isolates have
their own code specific

00:05:50.170 --> 00:05:53.300
for each isolate.

00:05:53.300 --> 00:05:58.630
So in AOT world, the
data part of the heap

00:05:58.630 --> 00:06:00.290
is as it was before.

00:06:00.290 --> 00:06:03.240
But what changes is that
the code part is now

00:06:03.240 --> 00:06:05.400
shared between all isolates.

00:06:05.400 --> 00:06:08.590
Because the code now
is compiled to binary

00:06:08.590 --> 00:06:10.430
and comes from a
binary, so there's

00:06:10.430 --> 00:06:14.180
only one version which needs
to be used by all isolates.

00:06:14.180 --> 00:06:17.020
And the data is
shared as before.

00:06:17.020 --> 00:06:19.052
So the code part also
becomes a little bigger,

00:06:19.052 --> 00:06:20.760
because it has to
contain the code that's

00:06:20.760 --> 00:06:22.400
used by all isolates.

00:06:22.400 --> 00:06:25.140
And basically, that's the code
left over after tree shaking.

00:06:29.080 --> 00:06:33.240
So challenge number
two basically

00:06:33.240 --> 00:06:37.240
was optimizing the
code, making it fast.

00:06:37.240 --> 00:06:43.620
And here the problem is that
the type feedback is missing.

00:06:43.620 --> 00:06:47.160
So in the JIT compiler, we
used dynamic type feedback.

00:06:47.160 --> 00:06:52.975
And the compiler has to
figure out the types by itself

00:06:52.975 --> 00:06:55.550
in ahead-of-time compilation.

00:06:55.550 --> 00:06:59.940
That means less specialized
code, more dynamic dispatches.

00:07:02.930 --> 00:07:05.820
But on the other hand,
we can rely on a closed

00:07:05.820 --> 00:07:08.500
world for AOT compilation.

00:07:08.500 --> 00:07:12.830
And this is done by basically
restricting the language

00:07:12.830 --> 00:07:13.799
in certain ways.

00:07:13.799 --> 00:07:15.840
So for example, there's
no real deferred loading.

00:07:18.440 --> 00:07:20.980
You can use deferred
loading, but it

00:07:20.980 --> 00:07:25.300
will happen when you build
the app at compile time.

00:07:25.300 --> 00:07:27.440
There's also no
spawnUri from isolate.

00:07:27.440 --> 00:07:30.890
That's so you can't spawn
an isolate with new code.

00:07:30.890 --> 00:07:34.870
So all the code is needed
at the compile time.

00:07:34.870 --> 00:07:39.580
And the third thing is there's
no mirrors supported in the AOT

00:07:39.580 --> 00:07:40.850
world.

00:07:40.850 --> 00:07:44.550
And this is mainly needed
for code size reasons.

00:07:48.580 --> 00:07:50.930
And the other part
of making it fast

00:07:50.930 --> 00:07:55.380
is making the startup
really snappy and fast.

00:07:55.380 --> 00:07:58.560
So these two, basically, peak
performance and startup, those

00:07:58.560 --> 00:08:01.083
are the two things
that we had to address.

00:08:05.030 --> 00:08:09.700
So here's a performance
comparison of AOT versus JIT.

00:08:09.700 --> 00:08:13.380
I'll talk about peak
performance and startup time.

00:08:13.380 --> 00:08:18.040
Since we started using the
ahead-of-time compiler,

00:08:18.040 --> 00:08:21.430
we improved a lot since
the first version,

00:08:21.430 --> 00:08:23.550
on some benchmarks,
even much more than 2x,

00:08:23.550 --> 00:08:25.760
but around that
order of magnitude.

00:08:29.636 --> 00:08:33.260
We basically made
many optimizations

00:08:33.260 --> 00:08:35.630
shared between
the two compilers,

00:08:35.630 --> 00:08:37.940
and we added a bunch
of new optimizations

00:08:37.940 --> 00:08:43.480
like tracking type of fields
or identifying unique methods

00:08:43.480 --> 00:08:47.810
and speeding up the
method dispatch for those.

00:08:47.810 --> 00:08:51.760
And for startup, basically, as
soon as we started using AOT,

00:08:51.760 --> 00:08:52.816
we got a huge boost.

00:08:52.816 --> 00:08:54.190
And that's mainly
because there's

00:08:54.190 --> 00:08:57.730
no warmup cost involved.

00:08:57.730 --> 00:09:00.910
You get stable performance
right from the start.

00:09:00.910 --> 00:09:04.100
The code and the read-only data,
they are mapped into memory

00:09:04.100 --> 00:09:06.240
from the binary.

00:09:06.240 --> 00:09:08.840
So there's no code
generation needed

00:09:08.840 --> 00:09:12.730
that would slow down
startup in the JIT world.

00:09:12.730 --> 00:09:15.540
And in addition to that, we
added the new faster snapshot

00:09:15.540 --> 00:09:17.970
format within load deprecation.

00:09:17.970 --> 00:09:20.150
And that helps both the
JIT and AOT bit out,

00:09:20.150 --> 00:09:23.090
so it gave another factor
of 2 in terms of startup.

00:09:26.910 --> 00:09:30.040
So here I'll just show
a few sample benchmarks

00:09:30.040 --> 00:09:33.090
that we were tracking
over the last year.

00:09:33.090 --> 00:09:37.570
And this just to show
you-- these are benchmarks.

00:09:37.570 --> 00:09:40.460
Some of them are taken
from the Fultter repo,

00:09:40.460 --> 00:09:44.510
so they have a bunch
of micro-benchmarks.

00:09:44.510 --> 00:09:47.590
The blue line is
the AOT performance.

00:09:47.590 --> 00:09:50.320
The red line is the
JIT performance.

00:09:50.320 --> 00:09:52.650
And you can see, on
some benchmarks, we--

00:09:52.650 --> 00:09:57.730
so AOT performance improved
on all of them over time.

00:09:57.730 --> 00:10:04.270
On some of them, we are closing
in to reach JIT performance.

00:10:04.270 --> 00:10:07.429
On others, we actually exceed
JIT performance already,

00:10:07.429 --> 00:10:08.970
which may be a little
bit surprising,

00:10:08.970 --> 00:10:11.080
but it's perfectly reasonable.

00:10:11.080 --> 00:10:16.530
So for example, the one in the
lower right corner, dart2js,

00:10:16.530 --> 00:10:18.620
which is basically an
ahead-of-time compiled

00:10:18.620 --> 00:10:24.010
version of dart2js compiling
a simple HTML application--

00:10:24.010 --> 00:10:27.212
and here it turns out the input
is not large enough, actually,

00:10:27.212 --> 00:10:29.045
for JIT to catch up in
terms of performance.

00:10:29.045 --> 00:10:32.120
So it may be running
for five to 10 seconds.

00:10:32.120 --> 00:10:34.625
So for this, the
ahead-of-time compiled code

00:10:34.625 --> 00:10:38.720
is actually almost
twice as fast.

00:10:38.720 --> 00:10:44.400
Also, the animation benchmark is
much more smooth with the AOT,

00:10:44.400 --> 00:10:46.546
because there are no
parsers happening.

00:10:50.650 --> 00:10:53.120
So we are not always
faster than the JIT.

00:10:53.120 --> 00:10:54.350
There's benchmarks.

00:10:54.350 --> 00:10:56.560
For example, on
DeltaBlue, we are only

00:10:56.560 --> 00:10:59.520
at 20% of JIT performance.

00:10:59.520 --> 00:11:01.270
On Flutter
micro-benchmarks, you saw,

00:11:01.270 --> 00:11:03.670
we are between 65% and 115%.

00:11:03.670 --> 00:11:07.640
So there, we are pretty much
on par with the JIT, on dart2sj

00:11:07.640 --> 00:11:12.450
as well, between 75% and
180% of JIT performance.

00:11:12.450 --> 00:11:14.000
But there's still
more to be done

00:11:14.000 --> 00:11:17.260
for some of the work loads.

00:11:17.260 --> 00:11:20.480
In terms of startup,
we got, immediately,

00:11:20.480 --> 00:11:24.830
around a 3x faster startup
of the Flutter gallery,

00:11:24.830 --> 00:11:26.510
probably even more.

00:11:26.510 --> 00:11:28.430
I measured this some time ago.

00:11:28.430 --> 00:11:30.240
I guess, in the
last month or so,

00:11:30.240 --> 00:11:31.910
there have been
more improvements.

00:11:31.910 --> 00:11:33.785
So that number is, I
would say, conservative.

00:11:36.380 --> 00:11:41.330
And also, dart2js is-- if
you compile a small program,

00:11:41.330 --> 00:11:44.030
it's a lot faster.

00:11:44.030 --> 00:11:46.650
And only if you
compile, for example,

00:11:46.650 --> 00:11:52.456
dart2js with dart2js itself,
which is a really big program,

00:11:52.456 --> 00:11:56.388
the JIT will eventually catch
up and exceed AOT performance.

00:12:00.520 --> 00:12:03.110
I want to take a short minute
to talk about the experiment

00:12:03.110 --> 00:12:05.215
that we just recently started.

00:12:05.215 --> 00:12:06.590
Basically, we
thought about, what

00:12:06.590 --> 00:12:13.320
about combining the two benefits
of the two worlds, JIT and AOT.

00:12:13.320 --> 00:12:17.070
So just in the
new start version,

00:12:17.070 --> 00:12:21.050
which is not in the state
channel yet, but version 1.21,

00:12:21.050 --> 00:12:23.340
we added a new hybrid
snapshot format.

00:12:23.340 --> 00:12:27.100
And we could imagine--
which is basically

00:12:27.100 --> 00:12:31.740
having shared code for fast
startup plus the JIT compiler

00:12:31.740 --> 00:12:36.200
to optimize further
once you are running.

00:12:36.200 --> 00:12:40.250
And we experimented using that
for our own tools basically.

00:12:40.250 --> 00:12:43.430
dartanalyzer,
dart2js should also

00:12:43.430 --> 00:12:45.840
start up fast if you use
them from the command line.

00:12:45.840 --> 00:12:49.000
And who knows, maybe once
phones are powerful enough,

00:12:49.000 --> 00:12:50.590
you could also imagine
using something

00:12:50.590 --> 00:12:51.548
like that on the phone.

00:12:54.530 --> 00:12:58.740
The third challenge is
making the compiled output

00:12:58.740 --> 00:12:59.760
small enough.

00:12:59.760 --> 00:13:03.920
And here, as I said,
we have tree shaking.

00:13:03.920 --> 00:13:06.770
So basically, all the code
that's imported by your app

00:13:06.770 --> 00:13:09.040
but not used will
be dropped when

00:13:09.040 --> 00:13:13.060
you create the binary snapshot.

00:13:13.060 --> 00:13:16.030
And this is done automatically.

00:13:16.030 --> 00:13:19.660
We also limit when we--
before we write out

00:13:19.660 --> 00:13:23.040
the compiled code and
data into the snapshot,

00:13:23.040 --> 00:13:26.060
we eliminate all unused
or duplicate data, VM

00:13:26.060 --> 00:13:31.959
internal data, classes,
libraries, functions, types.

00:13:31.959 --> 00:13:33.750
What we do, also, to
make the code smaller,

00:13:33.750 --> 00:13:35.980
we do less aggressive
inlining than in the JIT.

00:13:35.980 --> 00:13:39.580
That's part of the trade-off
between code size and speed.

00:13:39.580 --> 00:13:47.120
And we have to find a balance to
make download sizes reasonable.

00:13:47.120 --> 00:13:49.650
And the fourth part here
is that, basically, we

00:13:49.650 --> 00:13:53.050
could remove all the
compiler-related code

00:13:53.050 --> 00:13:53.860
from the runtime.

00:13:53.860 --> 00:13:57.200
So we have a stripped down
version of the Dart VM runtime

00:13:57.200 --> 00:14:00.810
that basically just contains
the necessary bits and pieces

00:14:00.810 --> 00:14:02.060
to run AOT code.

00:14:05.680 --> 00:14:08.310
Yeah, so that concludes part
one of the presentation.

00:14:08.310 --> 00:14:09.870
I showed you that,
basically, Dart

00:14:09.870 --> 00:14:11.090
is ready for AOT compilation.

00:14:11.090 --> 00:14:14.280
And the best way to
try out this technology

00:14:14.280 --> 00:14:17.700
is to create your Flutter
app or download the gallery

00:14:17.700 --> 00:14:20.299
and try it out there.

00:14:20.299 --> 00:14:22.340
Or you can experiment with
the Dart SDK directly,

00:14:22.340 --> 00:14:26.850
but I think the Flutter tool is
a really nice way to experiment

00:14:26.850 --> 00:14:29.980
with AOT code.

00:14:29.980 --> 00:14:31.520
And we're working
in many directions

00:14:31.520 --> 00:14:33.519
to make it even better.

00:14:33.519 --> 00:14:35.060
And I'll hand it
over to my colleague

00:14:35.060 --> 00:14:37.824
Slava, who will talk
about one of the things

00:14:37.824 --> 00:14:39.532
that we are doing to
make it even better.

00:14:39.532 --> 00:14:40.680
VYACHESLAV EGOROV: Yes.

00:14:40.680 --> 00:14:42.352
Thank you, Florian.

00:14:42.352 --> 00:14:45.784
[APPLAUSE]

00:14:46.760 --> 00:14:49.630
In case you were wondering
why I was there on stage

00:14:49.630 --> 00:14:51.980
to begin with, I'm back.

00:14:51.980 --> 00:14:54.230
And I'm going to talk
about something completely

00:14:54.230 --> 00:14:57.637
different from what
Florian told you before.

00:14:57.637 --> 00:15:00.220
And it's different in the sense
that it's highly experimental.

00:15:00.220 --> 00:15:02.260
Stuff that Florian
told you about

00:15:02.260 --> 00:15:03.900
can actually be
used in production.

00:15:03.900 --> 00:15:06.820
Like, you can compile a
Flutter app ahead of time

00:15:06.820 --> 00:15:10.740
and deploy it into the
Play Store, so it's good.

00:15:10.740 --> 00:15:17.367
And the stuff now is probably
completely unuseful for you.

00:15:17.367 --> 00:15:19.200
But we need to occupy
the time a little bit,

00:15:19.200 --> 00:15:22.070
so Bob put me on stage.

00:15:22.070 --> 00:15:24.180
If we take a step
back and look at how

00:15:24.180 --> 00:15:28.470
the Dart ecosystem
of tools looks like,

00:15:28.470 --> 00:15:30.890
we will discover
that a lot of tools

00:15:30.890 --> 00:15:35.090
these days are actually
ahead-of-time compilers.

00:15:35.090 --> 00:15:37.670
Because the platforms
you are running Dart on,

00:15:37.670 --> 00:15:42.440
like browser or
iPhone, they require

00:15:42.440 --> 00:15:45.370
you to compile Dart
code ahead of time

00:15:45.370 --> 00:15:47.700
into either JavaScript
or machine code.

00:15:47.700 --> 00:15:50.430
And on this picture,
you can also

00:15:50.430 --> 00:15:53.610
put the analyzer which compiles
the Dart code ahead of time

00:15:53.610 --> 00:15:56.320
to errors and stuff like
that, and shows it to you.

00:15:56.320 --> 00:16:00.230
But to not make this confusing,
I will remove the analyzer.

00:16:00.230 --> 00:16:03.900
And if we zoom in on
those tools that we have,

00:16:03.900 --> 00:16:06.690
we discover that, inside, they
contain a lot of orange boxes.

00:16:06.690 --> 00:16:10.800
And what I'm trying to
show with this picture

00:16:10.800 --> 00:16:13.340
is that they contain
some components inside.

00:16:13.340 --> 00:16:16.030
And if we start looking
at those components,

00:16:16.030 --> 00:16:19.370
we discover that they're very
similar in the beginning.

00:16:19.370 --> 00:16:22.634
So when your Dart source
arrives into this tool,

00:16:22.634 --> 00:16:23.550
it needs to be parsed.

00:16:23.550 --> 00:16:24.633
It needs to be understood.

00:16:24.633 --> 00:16:28.220
The libraries need to be
loaded from somewhere.

00:16:28.220 --> 00:16:30.470
It needs to understand what
object is, what string is,

00:16:30.470 --> 00:16:31.290
and so on.

00:16:31.290 --> 00:16:34.380
But as you approach
the end of the tool

00:16:34.380 --> 00:16:36.890
from the side from which
the code comes out,

00:16:36.890 --> 00:16:38.630
like JavaScript code
and machine code,

00:16:38.630 --> 00:16:41.050
you discover that they
are very different.

00:16:41.050 --> 00:16:42.570
And of course, the
question arises,

00:16:42.570 --> 00:16:45.680
why do we even have the
similar components duplicated

00:16:45.680 --> 00:16:46.600
between these tools.

00:16:46.600 --> 00:16:47.849
And they're really duplicated.

00:16:47.849 --> 00:16:50.700
Like for example, dart2js has
its own parser for Dart code.

00:16:50.700 --> 00:16:54.290
DDC, Dart Development Compiler,
is using the analyzer parser

00:16:54.290 --> 00:16:55.910
to parse the Dart code.

00:16:55.910 --> 00:16:58.250
And the VM has its
own C++ parser.

00:16:58.250 --> 00:16:59.980
Like, it's written with C++.

00:16:59.980 --> 00:17:04.859
And it doesn't make much sense
to duplicate these components.

00:17:04.859 --> 00:17:06.400
So what we are trying
to do, and what

00:17:06.400 --> 00:17:08.430
I am going to
introduce now, to you,

00:17:08.430 --> 00:17:10.119
is this project called Kernel.

00:17:10.119 --> 00:17:12.680
The name was selected
purely through a competition

00:17:12.680 --> 00:17:17.630
of the most confusing words
to choose for this project.

00:17:17.630 --> 00:17:20.640
We thought about calling it
"Core" and stuff like that,

00:17:20.640 --> 00:17:24.060
but "Core" is even more
confusing than "Kernel."

00:17:24.060 --> 00:17:27.440
So this is a simplified
representation

00:17:27.440 --> 00:17:28.400
of the Dart language.

00:17:28.400 --> 00:17:29.570
It's like an AST format.

00:17:29.570 --> 00:17:33.240
It's not the bytecode, but
it's a simplified Dart AST.

00:17:33.240 --> 00:17:35.740
It has a binary form as well.

00:17:35.740 --> 00:17:38.860
And it's designed to make
a transformation friendly.

00:17:38.860 --> 00:17:41.540
So we have a set
of tools to compile

00:17:41.540 --> 00:17:46.380
to Kernel from Dart
source and a set of tools

00:17:46.380 --> 00:17:47.690
to write it in the binary form.

00:17:47.690 --> 00:17:51.090
You can load it back, transform
it, and save it again.

00:17:51.090 --> 00:17:53.410
So where does it
fit on this picture?

00:17:53.410 --> 00:17:57.130
Well, ideally, we would like to
arrive to something like that.

00:17:57.130 --> 00:17:59.440
You start with a
Dart source, and you

00:17:59.440 --> 00:18:02.650
compile it to Kernel
using this dartk compiler.

00:18:02.650 --> 00:18:05.450
Then, you have a set of tools
that can analyze and transform

00:18:05.450 --> 00:18:07.000
this representation.

00:18:07.000 --> 00:18:09.975
And then you pass it
over to back end, which

00:18:09.975 --> 00:18:12.225
knows how to do its job,
like compile it to JavaScript

00:18:12.225 --> 00:18:15.410
or compile it to
the machine code.

00:18:15.410 --> 00:18:19.100
And that's basically it.

00:18:19.100 --> 00:18:22.910
So obviously, this is the
future, a possible future,

00:18:22.910 --> 00:18:26.310
if we discover that this
gives considerable benefits.

00:18:26.310 --> 00:18:29.910
And today, what
we have is that we

00:18:29.910 --> 00:18:32.400
have the compiler
and transformation

00:18:32.400 --> 00:18:33.320
parsers implemented.

00:18:33.320 --> 00:18:35.236
We are experimenting
with different analyzers,

00:18:35.236 --> 00:18:37.260
which I will show you
a little bit later.

00:18:37.260 --> 00:18:40.260
And we modified VM
in such a way that it

00:18:40.260 --> 00:18:44.740
can load both source and the
Kernel as well, on the side.

00:18:44.740 --> 00:18:47.670
So you can compile your
application to Kernel

00:18:47.670 --> 00:18:51.900
and then load it
into VM and rejoice.

00:18:51.900 --> 00:18:55.540
So what are the benefits
of having these components

00:18:55.540 --> 00:18:57.130
moved out and shared?

00:18:57.130 --> 00:19:00.180
Well, if we start looking
at the language features

00:19:00.180 --> 00:19:02.730
that Dart has, we
discover that Dart is not

00:19:02.730 --> 00:19:04.370
a very simple language anymore.

00:19:04.370 --> 00:19:06.940
It's simpler than
some languages,

00:19:06.940 --> 00:19:09.420
but it still has a lot
of different features

00:19:09.420 --> 00:19:11.120
which make it very expressive.

00:19:11.120 --> 00:19:15.540
And these features come at an
implementation cost, right?

00:19:15.540 --> 00:19:17.990
If you look at the history
of async/await for example,

00:19:17.990 --> 00:19:21.390
it had to be implemented across
multiple different tools,

00:19:21.390 --> 00:19:23.080
and it took a long time.

00:19:23.080 --> 00:19:26.930
So our approach to
this is different.

00:19:26.930 --> 00:19:32.100
We suggest that you can do the
sugaring on the kernel level.

00:19:32.100 --> 00:19:34.220
So essentially, the
kernel that comes in

00:19:34.220 --> 00:19:37.060
is the kernel with
async/await features,

00:19:37.060 --> 00:19:40.440
but the kernel that comes
out is the one where

00:19:40.440 --> 00:19:41.880
these features are stripped.

00:19:41.880 --> 00:19:43.820
And here's an example
of what we do.

00:19:43.820 --> 00:19:46.570
We convert-- this is the
kernel after the desugaring.

00:19:46.570 --> 00:19:48.855
And in reality, you
can desugar all the

00:19:48.855 --> 00:19:50.230
await-- I think,
await-- features

00:19:50.230 --> 00:19:52.290
to a single yield feature.

00:19:52.290 --> 00:19:54.800
And then your back ends only
need to support the yield.

00:19:54.800 --> 00:19:56.710
And I don't recommend
you reading this code,

00:19:56.710 --> 00:19:58.340
so I even reformatted
it a little bit

00:19:58.340 --> 00:19:59.770
to make it slightly unreadable.

00:20:03.610 --> 00:20:06.960
Another feature that is kind
of simple on the surface

00:20:06.960 --> 00:20:08.860
is the closures.

00:20:08.860 --> 00:20:12.130
But in reality, people that
encounter closures, especially

00:20:12.130 --> 00:20:14.210
those people who
programmed Java before,

00:20:14.210 --> 00:20:16.810
they ask, why do we
even need closures.

00:20:16.810 --> 00:20:19.390
Closures can be just
represented as classes.

00:20:19.390 --> 00:20:22.090
And really, that's a very
interesting question.

00:20:22.090 --> 00:20:23.464
Why do we need closures?

00:20:23.464 --> 00:20:25.130
So we are trying to
remove closures away

00:20:25.130 --> 00:20:26.546
through the kernel
transformation.

00:20:26.546 --> 00:20:29.180
We have a transformer-- you can
check it out, how it's written.

00:20:29.180 --> 00:20:30.790
There is a link
to GitHub-- which

00:20:30.790 --> 00:20:34.650
converts all closures in the
program into their classes.

00:20:34.650 --> 00:20:37.410
And you can see there
is a context which

00:20:37.410 --> 00:20:39.450
will contain the captured
variables and so on.

00:20:39.450 --> 00:20:41.200
So it's just a very
simple transformation.

00:20:43.100 --> 00:20:45.090
Another thing is types.

00:20:45.090 --> 00:20:46.110
Dart has types.

00:20:46.110 --> 00:20:48.440
What if everything that
you can do with type

00:20:48.440 --> 00:20:50.804
could be written
just as a Dart code?

00:20:50.804 --> 00:20:52.220
Have you have asked
this question?

00:20:52.220 --> 00:20:54.060
Like, with is check,
can it be just written

00:20:54.060 --> 00:20:55.950
as some simple Dart code?

00:20:55.950 --> 00:20:57.480
Well, it turns out it can be.

00:20:57.480 --> 00:20:59.410
And we have a transformer
that just attaches

00:20:59.410 --> 00:21:02.120
the field that will contain
the type of an object

00:21:02.120 --> 00:21:02.880
into the class.

00:21:02.880 --> 00:21:06.300
And then it converts
all the is checks

00:21:06.300 --> 00:21:10.110
to some simple Dart expressions
which call some helper methods.

00:21:10.110 --> 00:21:14.070
And all of this is written
just in Kernel and Dart.

00:21:14.070 --> 00:21:15.740
So these are the sort
of transformations

00:21:15.740 --> 00:21:18.340
that can be shared between
the different back ends,

00:21:18.340 --> 00:21:21.740
thus simplifying the back
ends and allowing you

00:21:21.740 --> 00:21:23.120
to evolve the language faster.

00:21:23.120 --> 00:21:26.490
Because now you don't need to
be a specialist in both C++

00:21:26.490 --> 00:21:29.289
and Dart to go and implement
a new language feature.

00:21:29.289 --> 00:21:30.830
You can just go and
implement it once

00:21:30.830 --> 00:21:33.960
as a kernel-to-kernel
transformation in Dart.

00:21:33.960 --> 00:21:37.480
So that's our goal, to make
the language evolution faster

00:21:37.480 --> 00:21:38.790
and simpler.

00:21:38.790 --> 00:21:43.440
And it'll allow you to port Dart
to new platforms also easier.

00:21:43.440 --> 00:21:47.770
And we are not only looking
into the transformations.

00:21:47.770 --> 00:21:50.600
We also look into the
ways to analyze the code.

00:21:50.600 --> 00:21:53.190
Lake for example, both
dart2js and Dart VM,

00:21:53.190 --> 00:21:55.520
they need to perform a
global type inference

00:21:55.520 --> 00:22:01.270
to generate high-quality code
in the ahead-of-time setting.

00:22:01.270 --> 00:22:04.640
Without knowing what
a variable points to,

00:22:04.640 --> 00:22:07.227
you can't really do a
fast call, for example,

00:22:07.227 --> 00:22:08.060
to a certain method.

00:22:08.060 --> 00:22:10.500
So we have a prototype of
a global type inference

00:22:10.500 --> 00:22:12.980
over the kernel representation.

00:22:12.980 --> 00:22:15.460
And here is the output
that it produces.

00:22:15.460 --> 00:22:17.500
So you can see
that the variables

00:22:17.500 --> 00:22:20.720
on the left-hand side,
they don't contain any type

00:22:20.720 --> 00:22:21.620
annotations.

00:22:21.620 --> 00:22:23.430
But after the global
type inference,

00:22:23.430 --> 00:22:28.390
we know that field f will
contain precisely an instance

00:22:28.390 --> 00:22:30.550
of x, and that can be null.

00:22:30.550 --> 00:22:34.430
And for example, the parameter
y, to the constructor,

00:22:34.430 --> 00:22:39.070
will be precisely an instance
of y, but it cannot be null.

00:22:39.070 --> 00:22:42.020
And if you listened to the
talk about strong mode,

00:22:42.020 --> 00:22:44.970
you know that strong mode gives
you some of these benefits.

00:22:44.970 --> 00:22:46.530
But for example,
it doesn't contain

00:22:46.530 --> 00:22:47.840
any nullability information.

00:22:47.840 --> 00:22:49.798
So these things, they
can complement each other

00:22:49.798 --> 00:22:51.900
very well.

00:22:51.900 --> 00:22:56.060
Like, strong mode can
give you better things

00:22:56.060 --> 00:23:00.990
to seed your analysis with,
but this kind of inference

00:23:00.990 --> 00:23:04.500
provides the data that
strong mode does not.

00:23:04.500 --> 00:23:07.050
So yeah, that's
basically end-of-file

00:23:07.050 --> 00:23:09.537
for this presentation.

00:23:09.537 --> 00:23:10.370
Thank you very much.

00:23:10.370 --> 00:23:13.720
[APPLAUSE]

