WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.690
 this capsule we will see how we 

00:00:01.949 --> 00:00:08.490
 evaluates the quality of language models 

00:00:05.690 --> 00:00:10.530
 then one of the ways to evaluate the 

00:00:08.490 --> 00:00:10.920
 quality of language models of a model n 

00:00:10.530 --> 00:00:13.500
 g 

00:00:10.920 --> 00:00:15.240
 it may be going to see if he 

00:00:13.500 --> 00:00:17.940
 allows us better or worse 

00:00:15.240 --> 00:00:20.100
 solve a given problem in a 

00:00:17.940 --> 00:00:21.779
 specific application 

00:00:20.100 --> 00:00:25.980
 we will start by discussing in fact 

00:00:21.779 --> 00:00:28.500
 what kind of application can we 

00:00:25.980 --> 00:00:31.910
 use it and benefit from a model of 

00:00:28.500 --> 00:00:34.020
 the year a first application is 

00:00:31.910 --> 00:00:36.809
 identifying the language of a 

00:00:34.020 --> 00:00:38.399
 given document so imagine that you are 

00:00:36.809 --> 00:00:41.730
 provides to the documents then that the 

00:00:38.399 --> 00:00:43.559
 software in question is identified in 

00:00:41.730 --> 00:00:45.180
 which language was written the document 

00:00:43.559 --> 00:00:47.250
 which is a document in English or in 

00:00:45.180 --> 00:00:48.629
 French located for example for 

00:00:47.250 --> 00:00:51.270
 determine if a corrector 

00:00:48.629 --> 00:00:52.670
 automatic spelling in this look 

00:00:51.270 --> 00:00:56.840
 spelling what language 

00:00:52.670 --> 00:01:01.079
 the heroes should be corrected then 

00:00:56.840 --> 00:01:02.940
 there close to do the identification of 

00:01:01.079 --> 00:01:04.500
 the language is often based on a 

00:01:02.940 --> 00:01:07.320
 language model it works very well 

00:01:04.500 --> 00:01:10.830
 here is the close one begins by defining 

00:01:07.320 --> 00:01:12.150
 a common vocabulary that is common 

00:01:10.830 --> 00:01:14.640
 for all languages ​​so we see 

00:01:12.150 --> 00:01:16.259
 vocabulary v that contains words 

00:01:14.640 --> 00:01:19.320
 common in all languages 

00:01:16.259 --> 00:01:21.740
 wants to identify and then sand 

00:01:19.320 --> 00:01:24.840
 for each language the language it 

00:01:21.740 --> 00:01:26.790
 we want to detect what we are going 

00:01:24.840 --> 00:01:28.619
 to do is to collect a corpus 

00:01:26.790 --> 00:01:30.780
 of documents for that language so 

00:01:28.619 --> 00:01:32.850
 we will find several documents 

00:01:30.780 --> 00:01:36.210
 we know they wrote in the language 

00:01:32.850 --> 00:01:38.070
 and give it to those of his going to define 

00:01:36.210 --> 00:01:41.579
 a priori policy for this language 

00:01:38.070 --> 00:01:43.950
 there if documents that have languages 

00:01:41.579 --> 00:01:45.930
 while we think we are more common 

00:01:43.950 --> 00:01:47.670
 more frequent we can decided 

00:01:45.930 --> 00:01:50.729
 to assign by higher a priori 

00:01:47.670 --> 00:01:53.579
 for these is English otherwise if we 

00:01:50.729 --> 00:01:55.020
 does not want biased a priori the detection 

00:01:53.579 --> 00:01:57.350
 one language more than another 

00:01:55.020 --> 00:01:59.700
 can simply assign a probability 

00:01:57.350 --> 00:02:02.520
 uniform then there a productible each 

00:01:59.700 --> 00:02:03.240
 languages ​​is a finally so for 

00:02:02.520 --> 00:02:05.549
 each of the languages 

00:02:03.240 --> 00:02:07.350
 we want to learn a model ng on the 

00:02:05.549 --> 00:02:09.509
 corpus collected for the language 

00:02:07.350 --> 00:02:11.849
 give is so an ingram model that 

00:02:09.509 --> 00:02:12.990
 had just finished the pole td 

00:02:11.849 --> 00:02:15.480
 observe a word 

00:02:12.990 --> 00:02:18.420
 the position being given hatreds - 

00:02:15.480 --> 00:02:20.340
 a previous word and if I guess that 

00:02:18.420 --> 00:02:23.280
 these words belong to the language 

00:02:20.340 --> 00:02:26.820
 m so that once I did that 

00:02:23.280 --> 00:02:28.170
 well I could actually do for 

00:02:26.820 --> 00:02:30.420
 a new document is to identify 

00:02:28.170 --> 00:02:31.620
 what is the most likely language 

00:02:30.420 --> 00:02:35.460
 most likely 

00:02:31.620 --> 00:02:37.200
 so what is the language she who has the 

00:02:35.460 --> 00:02:39.590
 higher policy given the 

00:02:37.200 --> 00:02:43.920
 words of the document in question 

00:02:39.590 --> 00:02:45.870
 so I want to make a max on l2 

00:02:43.920 --> 00:02:48.540
 so find the language that is the 

00:02:45.870 --> 00:02:50.370
 highest priority politeness and as 

00:02:48.540 --> 00:02:54.150
 in document qualifications b I can 

00:02:50.370 --> 00:02:57.590
 to see that that's equal to the log 

00:02:54.150 --> 00:03:01.410
 of the temporary max of the log of the range 

00:02:57.590 --> 00:03:04.220
 attached looser and the documents so that 

00:03:01.410 --> 00:03:06.270
 it's because I have an alpha constant 

00:03:04.220 --> 00:03:07.830
 that I can eliminate so I can 

00:03:06.270 --> 00:03:10.170
 only consider joined probity 

00:03:07.830 --> 00:03:12.360
 of language and document then I can 

00:03:10.170 --> 00:03:14.000
 take the log of this quality there because 

00:03:12.360 --> 00:03:19.500
 that the log is a transformation 

00:03:14.000 --> 00:03:20.820
 monotonous growth and this hammock this has 

00:03:19.500 --> 00:03:24.270
 actually does I can write it as 

00:03:20.820 --> 00:03:26.190
 the tarmac of the log of probity if the 

00:03:24.270 --> 00:03:29.940
 probability here it's actually the 

00:03:26.190 --> 00:03:32.280
 probability of the language times the 

00:03:29.940 --> 00:03:35.700
 priorities of each of the words knowing the 

00:03:32.280 --> 00:03:36.780
 previous words for assuming that's 

00:03:35.700 --> 00:03:39.270
 belongs to the hike 

00:03:36.780 --> 00:03:41.580
 so if I make the look of this product there 

00:03:39.270 --> 00:03:43.800
 it gives me the log of the scope of the 

00:03:41.580 --> 00:03:46.230
 language plus sum for all the evils 

00:03:43.800 --> 00:03:49.290
 of the log of the priority of these words there 

00:03:46.230 --> 00:03:50.610
 knowing the previous words and as in 

00:03:49.290 --> 00:03:53.910
 qualifications document made 

00:03:50.610 --> 00:03:56.250
 evaluation of all this rag 

00:03:53.910 --> 00:03:57.300
 probability there for different 

00:03:56.250 --> 00:04:00.720
 easy languages ​​and I take the language 

00:03:57.300 --> 00:04:02.850
 that the highest parity and so we 

00:04:00.720 --> 00:04:04.560
 can see that the system like that to 

00:04:02.850 --> 00:04:07.260
 priori I have some good for 

00:04:04.560 --> 00:04:09.120
 some languages ​​or if I wore a 

00:04:07.260 --> 00:04:10.890
 form but all languages 

00:04:09.120 --> 00:04:13.140
 the same value for the log of probity 

00:04:10.890 --> 00:04:16.320
 of the language and then if not I will I 

00:04:13.140 --> 00:04:18.840
 I was just looking at the sum of 

00:04:16.320 --> 00:04:20.609
 the loc pro liter of each of the words in 

00:04:18.840 --> 00:04:22.770
 this language there given the others 

00:04:20.609 --> 00:04:24.870
 words in the document so we can 

00:04:22.770 --> 00:04:25.650
 imagine that for a language or a word 

00:04:24.870 --> 00:04:26.820
 exist 

00:04:25.650 --> 00:04:28.560
 not in that language 

00:04:26.820 --> 00:04:31.919
 priority is going to be very low so the 

00:04:28.560 --> 00:04:34.259
 chances that it is the language that is the 

00:04:31.919 --> 00:04:36.750
 highest part will not be 

00:04:34.259 --> 00:04:39.570
 when I'm going to have more normally 

00:04:36.750 --> 00:04:40.139
 higher and higher specific level 

00:04:39.570 --> 00:04:43.110
 in languages 

00:04:40.139 --> 00:04:44.550
 the easier it will be to distinguish 

00:04:43.110 --> 00:04:47.120
 between different languages ​​with my 

00:04:44.550 --> 00:04:47.120
 model of the year 

00:04:52.680 --> 00:04:59.780
 in fact I could generally 

00:04:56.699 --> 00:05:02.280
 to classify documents 

00:04:59.780 --> 00:05:03.509
 which may be more powerful so 

00:05:02.280 --> 00:05:05.250
 in fact the identification of the language 

00:05:03.509 --> 00:05:05.610
 it's a bit like declassifying 

00:05:05.250 --> 00:05:07.500
 Documents 

00:05:05.610 --> 00:05:09.900
 I have an entry document and then I 

00:05:07.500 --> 00:05:14.190
 wants to determine its category where the 

00:05:09.900 --> 00:05:17.000
 category would be the language so did 

00:05:14.190 --> 00:05:19.979
 what we saw was the equivalent of a 

00:05:17.000 --> 00:05:21.180
 model it's a bit similar actually 

00:05:19.979 --> 00:05:25.110
 business models 

00:05:21.180 --> 00:05:26.639
 when cine + 9 in the sense that I could 

00:05:25.110 --> 00:05:27.690
 a unique model raemdonck gp a model 

00:05:26.639 --> 00:05:29.099
 which assumes that words are 

00:05:27.690 --> 00:05:31.860
 independent of each other 

00:05:29.099 --> 00:05:34.460
 SAC the category so knowing the 

00:05:31.860 --> 00:05:36.360
 language and there are other tasks or 

00:05:34.460 --> 00:05:37.830
 declassification of documents where that's 

00:05:36.360 --> 00:05:40.560
 can be something important to 

00:05:37.830 --> 00:05:42.360
 do a task one can benefit from 

00:05:40.560 --> 00:05:44.340
 take into account their demo it's between 

00:05:42.360 --> 00:05:45.810
 others a task we wish to determine 

00:05:44.340 --> 00:05:47.970
 given the documents that 

00:05:45.810 --> 00:05:49.949
 correspond to comments from 

00:05:47.970 --> 00:05:52.770
 movie reviews if the criticism is 

00:05:49.949 --> 00:05:56.250
 good or not or is good or not how 

00:05:52.770 --> 00:05:58.080
 so is because if their demo is 

00:05:56.250 --> 00:06:01.560
 important indeed the knowledge that the 

00:05:58.080 --> 00:06:03.780
 mob we are present in a review this 

00:06:01.560 --> 00:06:06.090
 can help except that if the word not before 

00:06:03.780 --> 00:06:08.880
 good it changes drastically 

00:06:06.090 --> 00:06:10.620
 the interpretation of the criticism know 

00:06:08.880 --> 00:06:13.919
 if it is positive or negative 

00:06:10.620 --> 00:06:17.159
 so this ca pratean case where a 2nd model 

00:06:13.919 --> 00:06:19.050
 g with one or with n 

00:06:17.159 --> 00:06:21.870
 bigger than one so where am I going 

00:06:19.050 --> 00:06:23.880
 consider more than at least one word 

00:06:21.870 --> 00:06:25.530
 before the word data to evaluate the 

00:06:23.880 --> 00:06:28.380
 word probabilities so the priority 

00:06:25.530 --> 00:06:29.270
 of the document after a hit it can be 

00:06:28.380 --> 00:06:32.639
 useful 

00:06:29.270 --> 00:06:34.289
 and if not no more 

00:06:32.639 --> 00:06:38.009
 applications like the actuation reaction 

00:06:34.289 --> 00:06:39.150
 of text imagine that I write this m deac 

00:06:38.009 --> 00:06:40.830
 seems maybe I would like to 

00:06:39.150 --> 00:06:43.289
 automatic prostitute for simply 

00:06:40.830 --> 00:06:46.590
 add the actions for me so 

00:06:43.289 --> 00:06:47.220
 stormy here would be accented accent 

00:06:46.590 --> 00:06:50.460
 serious 

00:06:47.220 --> 00:06:52.620
 and then the here would be his reaction killed 

00:06:50.460 --> 00:06:54.090
 with a sharp accent so that's 

00:06:52.620 --> 00:06:57.400
 something that can be done with a 

00:06:54.090 --> 00:06:58.990
 model in ga alone 

00:06:57.400 --> 00:07:01.210
 to give you a quick idea threat 

00:06:58.990 --> 00:07:03.400
 what we are looking for in this case is 

00:07:01.210 --> 00:07:06.490
 take a document where the words have not 

00:07:03.400 --> 00:07:09.430
 been accentuated and then turn it into 

00:07:06.490 --> 00:07:11.410
 the document where accents were added 

00:07:09.430 --> 00:07:14.199
 and when you try to do that 

00:07:11.410 --> 00:07:16.240
 find the accented document that most 

00:07:14.199 --> 00:07:18.400
 likely so they look more like 

00:07:16.240 --> 00:07:21.039
 to real documents that have been observed 

00:07:18.400 --> 00:07:23.500
 in our corpus so there are some 

00:07:21.039 --> 00:07:25.389
 techniques to try to do this 

00:07:23.500 --> 00:07:27.850
 difference there the same way in 

00:07:25.389 --> 00:07:29.889
 automatic translation if I produce a 

00:07:27.850 --> 00:07:31.870
 translation I would like my translation 

00:07:29.889 --> 00:07:33.250
 in for example if I translate from 

00:07:31.870 --> 00:07:34.600
 French to English 

00:07:33.250 --> 00:07:36.430
 I would like my translation in 

00:07:34.600 --> 00:07:38.350
 in fact you look like a sentence 

00:07:36.430 --> 00:07:40.210
 normal so this is a sentence that is 

00:07:38.350 --> 00:07:41.860
 likely according to a good model of 

00:07:40.210 --> 00:07:44.260
 language and so in this case we're going 

00:07:41.860 --> 00:07:46.840
 want to integrate that into our system 

00:07:44.260 --> 00:07:49.770
 of translation so that actually between 

00:07:46.840 --> 00:07:52.720
 produces translations that from 1 be 

00:07:49.770 --> 00:07:56.259
 a tradition that could generate the phrase 

00:07:52.720 --> 00:07:58.330
 original and which in addition is a sentence 

00:07:56.259 --> 00:08:00.370
 that could have been observed or to be 

00:07:58.330 --> 00:08:02.320
 said or written by someone so a 

00:08:00.370 --> 00:08:03.460
 sentence that is likely according to our 

00:08:02.320 --> 00:08:04.750
 model of the man so that's why 

00:08:03.460 --> 00:08:06.090
 we will want to introduce models 

00:08:04.750 --> 00:08:08.620
 language in production models 

00:08:06.090 --> 00:08:11.110
 then the same way in recognition of 

00:08:08.620 --> 00:08:13.570
 speech we will see produce 

00:08:11.110 --> 00:08:15.010
 interpret sentences who then want 

00:08:13.570 --> 00:08:18.900
 favor sentences that actually are 

00:08:15.010 --> 00:08:23.260
 sentences that could have been written 

00:08:18.900 --> 00:08:24.460
 in this language the water in whatever 

00:08:23.260 --> 00:08:25.960
 something that could have been said by a 

00:08:24.460 --> 00:08:33.339
 nobody is that it can be evaluated by 

00:08:25.960 --> 00:08:35.169
 a basic model so we were talking to 

00:08:33.339 --> 00:08:36.610
 any early evaluation of models of 

00:08:35.169 --> 00:08:38.529
 language commented what I wanted him 

00:08:36.610 --> 00:08:39.969
 specifically comment on what I 

00:08:38.529 --> 00:08:42.760
 distinguish or that I find the good 

00:08:39.969 --> 00:08:47.279
 hate values ​​of a gram or the 

00:08:42.760 --> 00:08:50.860
 constant rate smoothing or our 

00:08:47.279 --> 00:08:53.040
 constant arrests the ring 

00:08:50.860 --> 00:08:54.970
 constant of interpretation the soul of y 

00:08:53.040 --> 00:08:57.880
 so in fact so constant right we 

00:08:54.970 --> 00:08:59.680
 must be determined before 

00:08:57.880 --> 00:09:01.480
 even to enter us to learn our 

00:08:59.680 --> 00:09:03.670
 model these are the constants that we 

00:09:01.480 --> 00:09:06.220
 calls hypers parameters which so 

00:09:03.670 --> 00:09:08.200
 cdi by m because unlike 

00:09:06.220 --> 00:09:09.040
 probabilities of our model of sound 

00:09:08.200 --> 00:09:12.790
 departure m 

00:09:09.040 --> 00:09:15.370
 these parts and the sound are learned to 

00:09:12.790 --> 00:09:18.130
 from data while end delta 

00:09:15.370 --> 00:09:20.350
 and landry joy the data first 

00:09:18.130 --> 00:09:22.360
 first of all a priori even before 

00:09:20.350 --> 00:09:26.889
 to be able to train the model these are 

00:09:22.360 --> 00:09:28.060
 hypers and to be able to choose in 

00:09:26.889 --> 00:09:29.680
 different language models with 

00:09:28.060 --> 00:09:31.750
 different hate dollars delteil a 

00:09:29.680 --> 00:09:33.699
 website must define some 

00:09:31.750 --> 00:09:35.529
 performance concept then try to 

00:09:33.699 --> 00:09:37.120
 find maybe with research 

00:09:35.529 --> 00:09:39.279
 local for example what is it 

00:09:37.120 --> 00:09:42.940
 n2 values ​​of elton landry who 

00:09:39.279 --> 00:09:44.800
 works best so what are we going 

00:09:42.940 --> 00:09:46.630
 to do typically is that we're actually going 

00:09:44.800 --> 00:09:48.310
 take permission all our data 

00:09:46.630 --> 00:09:50.769
 collected we will put some 

00:09:48.310 --> 00:09:52.810
 side part that will be called who will 

00:09:50.769 --> 00:09:55.029
 which will correspond to our corpus of 

00:09:52.810 --> 00:09:57.009
 validation so what's important here 

00:09:55.029 --> 00:09:59.079
 it's that the validation corpus is going 

00:09:57.009 --> 00:10:01.839
 be recounted the documents that are 

00:09:59.079 --> 00:10:05.949
 other than the documents in our 

00:10:01.839 --> 00:10:09.100
 driving corpora and the notion of a 

00:10:05.949 --> 00:10:10.750
 test corpus that stops did the 

00:10:09.100 --> 00:10:13.029
 corpus convened to evaluate the 

00:10:10.750 --> 00:10:16.540
 final solution for the locks a notion 

00:10:13.029 --> 00:10:17.860
 that against being no more here but I 

00:10:16.540 --> 00:10:19.240
 invite you to see the capsules on 

00:10:17.860 --> 00:10:21.130
 machine learning for con 

00:10:19.240 --> 00:10:22.750
 to make a distinction the most 

00:10:21.130 --> 00:10:26.220
 explicit between notions 

00:10:22.750 --> 00:10:28.029
 validation and test drive 

00:10:26.220 --> 00:10:29.889
 when also in fact all that is to 

00:10:28.029 --> 00:10:31.899
 to know that we have a corpus of 

00:10:29.889 --> 00:10:33.790
 validation which are documents that do not 

00:10:31.899 --> 00:10:34.569
 are not the same as those who are 

00:10:33.790 --> 00:10:37.360
 find in my whole 

00:10:34.569 --> 00:10:38.800
 drive stasi the whole the 

00:10:37.360 --> 00:10:41.639
 drive corpus that was used 

00:10:38.800 --> 00:10:43.870
 to calculate the frequencies of and g 

00:10:41.639 --> 00:10:46.899
 so once we've done that it's actually 

00:10:43.870 --> 00:10:48.519
 the best way true evil to devalue 

00:10:46.899 --> 00:10:52.480
 our language model who to choose 

00:10:48.519 --> 00:10:54.399
 the hand value of a website is 

00:10:52.480 --> 00:10:56.740
 to see what's the performance of 

00:10:54.399 --> 00:10:58.480
 our system on our corpus of 

00:10:56.740 --> 00:11:01.029
 validation if I have a language model 

00:10:58.480 --> 00:11:04.600
 who was trained for some 

00:11:01.029 --> 00:11:06.579
 value n and delta where the employee so for 

00:11:04.600 --> 00:11:08.350
 get me put on my set 

00:11:06.579 --> 00:11:10.120
 drive so that's really the 

00:11:08.350 --> 00:11:11.860
 best way to try 

00:11:10.120 --> 00:11:13.899
 to ultimately optimize the success rate 

00:11:11.860 --> 00:11:16.540
 our system in our application 

00:11:13.899 --> 00:11:18.040
 given on our validation center 

00:11:16.540 --> 00:11:19.600
 so as part of a system 

00:11:18.040 --> 00:11:20.709
 of language identification because 

00:11:19.600 --> 00:11:22.510
 I will do it is that I will have plenty of 

00:11:20.709 --> 00:11:24.190
 documents of different 

00:11:22.510 --> 00:11:25.870
 I want to separate them into a corpus 

00:11:24.190 --> 00:11:28.780
 practice that a corpus of 

00:11:25.870 --> 00:11:31.870
 validation and I will choose the value 

00:11:28.780 --> 00:11:34.090
 of visitors by turitan motherhood who 

00:11:31.870 --> 00:11:35.500
 such as if I train a model 

00:11:34.090 --> 00:11:37.000
 of tongue with this hate pain 

00:11:35.500 --> 00:11:39.840
 their delivery to the parameters 

00:11:37.000 --> 00:11:41.830
 I have the best success rate 

00:11:39.840 --> 00:11:43.540
 identification of the right language for 

00:11:41.830 --> 00:11:47.350
 the documents that is in my 

00:11:43.540 --> 00:11:48.610
 validation set like this is a 

00:11:47.350 --> 00:11:50.860
 example for machine translation 

00:11:48.610 --> 00:11:52.870
 we would do the same thing we would have a 

00:11:50.860 --> 00:11:55.830
 evaluation performance on the corpus 

00:11:52.870 --> 00:11:58.690
 validation that would be otherwise 

00:11:55.830 --> 00:11:59.980
 other documents to translate than those 

00:11:58.690 --> 00:12:03.190
 which are in my whole in 

00:11:59.980 --> 00:12:06.010
 the training corpus but if not so 

00:12:03.190 --> 00:12:07.750
 we do not have an application already defined 

00:12:06.010 --> 00:12:09.370
 and if in fact we 

00:12:07.750 --> 00:12:10.900
 so we might be interested 

00:12:09.370 --> 00:12:13.870
 have a performance measure that is 

00:12:10.900 --> 00:12:15.430
 a bit independent of an application 

00:12:13.870 --> 00:12:17.860
 since language models actually 

00:12:15.430 --> 00:12:18.720
 could be used in different 

00:12:17.860 --> 00:12:20.800
 applications 

00:12:18.720 --> 00:12:23.280
 what we're going to do is we're going 

00:12:20.800 --> 00:12:25.450
 use what is called perplexity 

00:12:23.280 --> 00:12:28.540
 it's a formula that seems a little 

00:12:25.450 --> 00:12:31.300
 complicated but in the lead all that 

00:12:28.540 --> 00:12:35.890
 finds to be it's perplexity so 

00:12:31.300 --> 00:12:39.670
 for a given document it's going to be the 

00:12:35.890 --> 00:12:42.550
 probability of this document there at least 

00:12:39.670 --> 00:12:44.650
 sure d ok so we can see that in fact 

00:12:42.550 --> 00:12:49.690
 as a kind of probabilities but 

00:12:44.650 --> 00:12:52.390
 standardized by normalized by length 

00:12:49.690 --> 00:12:55.110
 of the document so our way of writing it 

00:12:52.390 --> 00:12:58.600
 in fact it's that exponential one of 

00:12:55.110 --> 00:13:00.880
 the sum of the locality of all evils 

00:12:58.600 --> 00:13:04.420
 in the previous alignment but 

00:13:00.880 --> 00:13:06.670
 standardized by dividing by by and after 

00:13:04.420 --> 00:13:10.480
 I take the average -7 exponential 

00:13:06.670 --> 00:13:11.770
 localities of words that's another 

00:13:10.480 --> 00:13:13.660
 way to see it is like 

00:13:11.770 --> 00:13:19.730
 the exponential of less 

00:13:13.660 --> 00:13:24.889
 the log likelihood of words 

00:13:19.730 --> 00:13:27.980
 and averages / so the justification of 

00:13:24.889 --> 00:13:29.300
 behind that and is inspiring rode the 

00:13:27.980 --> 00:13:32.420
 information theory it's some 

00:13:29.300 --> 00:13:34.250
 something that I will not deal with here but that 

00:13:32.420 --> 00:13:36.949
 to know essentially is that plus one 

00:13:34.250 --> 00:13:39.320
 angle model associates 

00:13:36.949 --> 00:13:42.160
 probabilities that they are elevated to 

00:13:39.320 --> 00:13:45.860
 documents that are real documents 

00:13:42.160 --> 00:13:48.560
 data extracts and then the most the 

00:13:45.860 --> 00:13:51.980
 perplexity vote to be actually beats 

00:13:48.560 --> 00:13:55.220
 more big enough if I take at least 

00:13:51.980 --> 00:13:58.550
 one on mets plus all this term there is going 

00:13:55.220 --> 00:14:00.170
 may be small so what we 

00:13:58.550 --> 00:14:02.269
 would like in this case arrested tiki 

00:14:00.170 --> 00:14:05.050
 the lowest possible and surmounted corpus 

00:14:02.269 --> 00:14:08.630
 of validation choose is actually the 

00:14:05.050 --> 00:14:10.940
 model in g or a language model that 

00:14:08.630 --> 00:14:13.339
 would have the lowest perplexity for 

00:14:10.940 --> 00:14:15.470
 all the validation corpus so for 

00:14:13.339 --> 00:14:17.269
 where there is that probability in 

00:14:15.470 --> 00:14:23.959
 made of all the documents in my 

00:14:17.269 --> 00:14:26.560
 validation set and finally a 

00:14:23.959 --> 00:14:29.389
 way maybe a little bit more 

00:14:26.560 --> 00:14:31.730
 intuitive or in any case more fun 

00:14:29.389 --> 00:14:33.800
 evaluate the quality of models and g 

00:14:31.730 --> 00:14:36.050
 these two squarely sampled or 

00:14:33.800 --> 00:14:38.029
 generate documents from our 

00:14:36.050 --> 00:14:39.380
 model took so somehow 

00:14:38.029 --> 00:14:42.380
 what we are going to do is let's leave 

00:14:39.380 --> 00:14:44.029
 the machine speak German or the 

00:14:42.380 --> 00:14:46.250
 machine correspondence it's a 

00:14:44.029 --> 00:14:48.440
 other year model so what I 

00:14:46.250 --> 00:14:51.620
 will do is that I and champion ray the 

00:14:48.440 --> 00:14:53.630
 first word w1 then from his part of w 

00:14:51.620 --> 00:14:57.019
 a game to sample the second 

00:14:53.630 --> 00:14:58.730
 word w2 from May 1st w1 that I have 

00:14:57.019 --> 00:15:01.690
 champion is wise and the championships 

00:14:58.730 --> 00:15:06.350
 from my probity w2 given 

00:15:01.690 --> 00:15:09.889
 w12 would be the priority of w3 sacha w 1 

00:15:06.350 --> 00:15:11.630
 and w2a champion raymond third 

00:15:09.889 --> 00:15:13.790
 like that then can model trigram 

00:15:11.630 --> 00:15:15.529
 there I will continue like that where I 

00:15:13.790 --> 00:15:19.420
 champion raymond fourth word of the 

00:15:15.529 --> 00:15:21.649
 policy was raining cap and gave w2 and 

00:15:19.420 --> 00:15:23.269
 w3 so only the two months 

00:15:21.649 --> 00:15:25.279
 previous ones and I will continue like that 

00:15:23.269 --> 00:15:26.300
 to generate text asked for 

00:15:25.279 --> 00:15:27.680
 language 

00:15:26.300 --> 00:15:28.850
 the example just gave this model 

00:15:27.680 --> 00:15:30.860
 trigram because I condition 

00:15:28.850 --> 00:15:31.360
 only or more on my last three 

00:15:30.860 --> 00:15:35.000
 month 

00:15:31.360 --> 00:15:36.829
 the last two montages and we have 

00:15:35.000 --> 00:15:38.540
 examples here from the reference book 

00:15:36.829 --> 00:15:41.060
 is actually what they did it's 

00:15:38.540 --> 00:15:45.860
 that they resulted in a unique pattern 

00:15:41.060 --> 00:15:48.470
 rambi g or sort g on the text content 

00:15:45.860 --> 00:15:50.480
 in the leading reference book and 

00:15:48.470 --> 00:15:53.600
 so what is observed for a model 

00:15:50.480 --> 00:15:55.279
 unique, in fact, we observe 

00:15:53.600 --> 00:15:58.160
 documents or word order has 

00:15:55.279 --> 00:16:00.980
 absolutely no sense logical orascom 

00:15:58.160 --> 00:16:01.639
 youngest 28 is because a model 

00:16:00.980 --> 00:16:03.470
 united g 

00:16:01.639 --> 00:16:06.470
 the probability of a word our departure in 

00:16:03.470 --> 00:16:10.100
 previous demo mode a bit like in a 

00:16:06.470 --> 00:16:12.829
 model the business model multi the 

00:16:10.100 --> 00:16:14.660
 viable short of models 10 grams the 

00:16:12.829 --> 00:16:17.209
 it will condition on the previous word 

00:16:14.660 --> 00:16:19.399
 and there we get documents from 

00:16:17.209 --> 00:16:21.680
 sentences that have little more than 100 systems 

00:16:19.399 --> 00:16:23.509
 are very rare mistakes confided tajine 

00:16:21.680 --> 00:16:24.980
 to reproaches rugby represents so we 

00:16:23.509 --> 00:16:27.920
 here sees that a little uncertain unplanned 

00:16:24.980 --> 00:16:29.389
 in the syntax but still some of the 

00:16:27.920 --> 00:16:31.670
 phrases that took 

00:16:29.389 --> 00:16:35.050
 individually to ten years and then more 

00:16:31.670 --> 00:16:39.139
 we increase the value of m so his pass 

00:16:35.050 --> 00:16:40.880
 surpassed n is equal to 3 but here we have 

00:16:39.139 --> 00:16:42.949
 way ends a little longer longer 

00:16:40.880 --> 00:16:46.430
 of planning and sending offers 

00:16:42.949 --> 00:16:49.639
 embedded in some semantic countries 

00:16:46.430 --> 00:16:51.380
 or seven x axes of success of the world 

00:16:49.639 --> 00:16:53.569
 so we see that the tips of 

00:16:51.380 --> 00:16:55.490
 sentences that are coherent themselves are 

00:16:53.569 --> 00:16:57.019
 a little longer although the sentence to 

00:16:55.490 --> 00:16:59.300
 racial conflicts this will not be entirely 

00:16:57.019 --> 00:17:01.550
 coherent and the more we increase n is no longer 

00:16:59.300 --> 00:17:03.680
 we gave but in our model 

00:17:01.550 --> 00:17:06.049
 pathak so that's another way 

00:17:03.680 --> 00:17:09.159
 to have an idea of ​​the quality of our 

00:17:06.049 --> 00:17:09.159
 model gr 

