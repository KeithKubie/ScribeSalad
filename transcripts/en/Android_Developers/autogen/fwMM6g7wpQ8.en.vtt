WEBVTT
Kind: captions
Language: en

00:00:00.789 --> 00:00:04.070
all right good afternoon everyone thank

00:00:04.070 --> 00:00:04.080
all right good afternoon everyone thank
 

00:00:04.080 --> 00:00:07.530
all right good afternoon everyone thank
you for coming to this talk you'll hear

00:00:07.530 --> 00:00:07.540
you for coming to this talk you'll hear
 

00:00:07.540 --> 00:00:11.790
you for coming to this talk you'll hear
about art together at one time and all

00:00:11.790 --> 00:00:11.800
about art together at one time and all
 

00:00:11.800 --> 00:00:14.040
about art together at one time and all
about all about new selling features

00:00:14.040 --> 00:00:14.050
about all about new selling features
 

00:00:14.050 --> 00:00:17.970
about all about new selling features
we've worked on for Android n I'm

00:00:17.970 --> 00:00:17.980
we've worked on for Android n I'm
 

00:00:17.980 --> 00:00:20.040
we've worked on for Android n I'm
Nicholas Jeffrey a software engineer in

00:00:20.040 --> 00:00:20.050
Nicholas Jeffrey a software engineer in
 

00:00:20.050 --> 00:00:21.720
Nicholas Jeffrey a software engineer in
the art team and I'll be presenting

00:00:21.720 --> 00:00:21.730
the art team and I'll be presenting
 

00:00:21.730 --> 00:00:24.750
the art team and I'll be presenting
along my colleagues Matthew chachi and

00:00:24.750 --> 00:00:24.760
along my colleagues Matthew chachi and
 

00:00:24.760 --> 00:00:31.620
along my colleagues Matthew chachi and
Kalin traveler so art is the software

00:00:31.620 --> 00:00:31.630
Kalin traveler so art is the software
 

00:00:31.630 --> 00:00:33.389
Kalin traveler so art is the software
layer between the operating system and

00:00:33.389 --> 00:00:33.399
layer between the operating system and
 

00:00:33.399 --> 00:00:36.860
layer between the operating system and
the applications it provides an

00:00:36.860 --> 00:00:36.870
the applications it provides an
 

00:00:36.870 --> 00:00:39.360
the applications it provides an
execution environment to run Android

00:00:39.360 --> 00:00:39.370
execution environment to run Android
 

00:00:39.370 --> 00:00:42.029
execution environment to run Android
applications that environment

00:00:42.029 --> 00:00:42.039
applications that environment
 

00:00:42.039 --> 00:00:44.969
applications that environment
essentially consists of two things it

00:00:44.969 --> 00:00:44.979
essentially consists of two things it
 

00:00:44.979 --> 00:00:47.340
essentially consists of two things it
executes text byte code that's the

00:00:47.340 --> 00:00:47.350
executes text byte code that's the
 

00:00:47.350 --> 00:00:49.950
executes text byte code that's the
internal Android format imagine

00:00:49.950 --> 00:00:49.960
internal Android format imagine
 

00:00:49.960 --> 00:00:52.579
internal Android format imagine
applications through a mix of

00:00:52.579 --> 00:00:52.589
applications through a mix of
 

00:00:52.589 --> 00:00:56.549
applications through a mix of
interpretation and computation it also

00:00:56.549 --> 00:00:56.559
interpretation and computation it also
 

00:00:56.559 --> 00:00:59.000
interpretation and computation it also
manages memory of this application

00:00:59.000 --> 00:00:59.010
manages memory of this application
 

00:00:59.010 --> 00:01:01.680
manages memory of this application
allocating it and reclaiming it what is

00:01:01.680 --> 00:01:01.690
allocating it and reclaiming it what is
 

00:01:01.690 --> 00:01:05.340
allocating it and reclaiming it what is
so long I used why should you guys care

00:01:05.340 --> 00:01:05.350
so long I used why should you guys care
 

00:01:05.350 --> 00:01:07.860
so long I used why should you guys care
about art well it turns out art is that

00:01:07.860 --> 00:01:07.870
about art well it turns out art is that
 

00:01:07.870 --> 00:01:11.490
about art well it turns out art is that
the forefront of the user experience art

00:01:11.490 --> 00:01:11.500
the forefront of the user experience art
 

00:01:11.500 --> 00:01:13.920
the forefront of the user experience art
needs to be fast so the applications can

00:01:13.920 --> 00:01:13.930
needs to be fast so the applications can
 

00:01:13.930 --> 00:01:16.740
needs to be fast so the applications can
run smoothly it needs to start

00:01:16.740 --> 00:01:16.750
run smoothly it needs to start
 

00:01:16.750 --> 00:01:18.690
run smoothly it needs to start
applications really quickly to give a

00:01:18.690 --> 00:01:18.700
applications really quickly to give a
 

00:01:18.700 --> 00:01:22.230
applications really quickly to give a
snap experience to the user it needs to

00:01:22.230 --> 00:01:22.240
snap experience to the user it needs to
 

00:01:22.240 --> 00:01:24.990
snap experience to the user it needs to
ensure the UI can render at least 60

00:01:24.990 --> 00:01:25.000
ensure the UI can render at least 60
 

00:01:25.000 --> 00:01:27.000
ensure the UI can render at least 60
frames per second to make the user

00:01:27.000 --> 00:01:27.010
frames per second to make the user
 

00:01:27.010 --> 00:01:28.640
frames per second to make the user
experience jank-free

00:01:28.640 --> 00:01:28.650
experience jank-free
 

00:01:28.650 --> 00:01:31.590
experience jank-free
it needs to be power efficient and not

00:01:31.590 --> 00:01:31.600
it needs to be power efficient and not
 

00:01:31.600 --> 00:01:34.110
it needs to be power efficient and not
do too much extra work besides executing

00:01:34.110 --> 00:01:34.120
do too much extra work besides executing
 

00:01:34.120 --> 00:01:37.350
do too much extra work besides executing
the application and needs to be savvy in

00:01:37.350 --> 00:01:37.360
the application and needs to be savvy in
 

00:01:37.360 --> 00:01:40.290
the application and needs to be savvy in
terms of memory use less memory being

00:01:40.290 --> 00:01:40.300
terms of memory use less memory being
 

00:01:40.300 --> 00:01:41.520
terms of memory use less memory being
used by the runtime the more

00:01:41.520 --> 00:01:41.530
used by the runtime the more
 

00:01:41.530 --> 00:01:46.230
used by the runtime the more
applications you can actually run so if

00:01:46.230 --> 00:01:46.240
applications you can actually run so if
 

00:01:46.240 --> 00:01:48.480
applications you can actually run so if
you remember dalvik which was the first

00:01:48.480 --> 00:01:48.490
you remember dalvik which was the first
 

00:01:48.490 --> 00:01:50.310
you remember dalvik which was the first
Android runtime released in Android

00:01:50.310 --> 00:01:50.320
Android runtime released in Android
 

00:01:50.320 --> 00:01:52.890
Android runtime released in Android
phones it was sort of efficient on some

00:01:52.890 --> 00:01:52.900
phones it was sort of efficient on some
 

00:01:52.900 --> 00:01:56.100
phones it was sort of efficient on some
on some of these metrics and sort of

00:01:56.100 --> 00:01:56.110
on some of these metrics and sort of
 

00:01:56.110 --> 00:02:00.300
on some of these metrics and sort of
okay on a few at the time memory

00:02:00.300 --> 00:02:00.310
okay on a few at the time memory
 

00:02:00.310 --> 00:02:04.190
okay on a few at the time memory
footprint was pronounced so we

00:02:04.190 --> 00:02:04.200
footprint was pronounced so we
 

00:02:04.200 --> 00:02:07.350
footprint was pronounced so we
constrained the compiler to not use much

00:02:07.350 --> 00:02:07.360
constrained the compiler to not use much
 

00:02:07.360 --> 00:02:10.529
constrained the compiler to not use much
memory and that explains not so great

00:02:10.529 --> 00:02:10.539
memory and that explains not so great
 

00:02:10.539 --> 00:02:12.310
memory and that explains not so great
performance

00:02:12.310 --> 00:02:12.320
performance
 

00:02:12.320 --> 00:02:15.350
performance
dalvik also had a relatively

00:02:15.350 --> 00:02:15.360
dalvik also had a relatively
 

00:02:15.360 --> 00:02:18.380
dalvik also had a relatively
unsophisticated garbage collector I'd

00:02:18.380 --> 00:02:18.390
unsophisticated garbage collector I'd
 

00:02:18.390 --> 00:02:20.210
unsophisticated garbage collector I'd
like to lead to long application pauses

00:02:20.210 --> 00:02:20.220
like to lead to long application pauses
 

00:02:20.220 --> 00:02:25.450
like to lead to long application pauses
leading to a janky experience so in 2014

00:02:25.450 --> 00:02:25.460
leading to a janky experience so in 2014
 

00:02:25.460 --> 00:02:30.560
leading to a janky experience so in 2014
we introduced art art shifted the

00:02:30.560 --> 00:02:30.570
we introduced art art shifted the
 

00:02:30.570 --> 00:02:33.350
we introduced art art shifted the
padding of doing interpretation and

00:02:33.350 --> 00:02:33.360
padding of doing interpretation and
 

00:02:33.360 --> 00:02:35.780
padding of doing interpretation and
just-in-time compilation at one time to

00:02:35.780 --> 00:02:35.790
just-in-time compilation at one time to
 

00:02:35.790 --> 00:02:37.820
just-in-time compilation at one time to
add time computation when the

00:02:37.820 --> 00:02:37.830
add time computation when the
 

00:02:37.830 --> 00:02:42.110
add time computation when the
application is being installed so when

00:02:42.110 --> 00:02:42.120
application is being installed so when
 

00:02:42.120 --> 00:02:43.820
application is being installed so when
the application is being installed art

00:02:43.820 --> 00:02:43.830
the application is being installed art
 

00:02:43.830 --> 00:02:45.950
the application is being installed art
will compile it directly to optimize

00:02:45.950 --> 00:02:45.960
will compile it directly to optimize
 

00:02:45.960 --> 00:02:49.940
will compile it directly to optimize
code that gave us a great boost on

00:02:49.940 --> 00:02:49.950
code that gave us a great boost on
 

00:02:49.950 --> 00:02:55.340
code that gave us a great boost on
performance an application startup art

00:02:55.340 --> 00:02:55.350
performance an application startup art
 

00:02:55.350 --> 00:02:58.130
performance an application startup art
did not need a just-in-time compiler to

00:02:58.130 --> 00:02:58.140
did not need a just-in-time compiler to
 

00:02:58.140 --> 00:03:02.410
did not need a just-in-time compiler to
be warmed up before it could execute

00:03:02.410 --> 00:03:02.420
be warmed up before it could execute
 

00:03:02.420 --> 00:03:05.600
be warmed up before it could execute
optimized applications were running out

00:03:05.600 --> 00:03:05.610
optimized applications were running out
 

00:03:05.610 --> 00:03:08.890
optimized applications were running out
of optimized code code directly and

00:03:08.890 --> 00:03:08.900
of optimized code code directly and
 

00:03:08.900 --> 00:03:11.090
of optimized code code directly and
because this code is directly loaded

00:03:11.090 --> 00:03:11.100
because this code is directly loaded
 

00:03:11.100 --> 00:03:13.550
because this code is directly loaded
from disk you don't need to pay the cost

00:03:13.550 --> 00:03:13.560
from disk you don't need to pay the cost
 

00:03:13.560 --> 00:03:17.780
from disk you don't need to pay the cost
of a JIT compilation code cache the

00:03:17.780 --> 00:03:17.790
of a JIT compilation code cache the
 

00:03:17.790 --> 00:03:20.060
of a JIT compilation code cache the
garbage collector has also been

00:03:20.060 --> 00:03:20.070
garbage collector has also been
 

00:03:20.070 --> 00:03:22.940
garbage collector has also been
completely revamped where we implemented

00:03:22.940 --> 00:03:22.950
completely revamped where we implemented
 

00:03:22.950 --> 00:03:23.570
completely revamped where we implemented
state-of-the-art

00:03:23.570 --> 00:03:23.580
state-of-the-art
 

00:03:23.580 --> 00:03:25.310
state-of-the-art
concurrent garbage collector algorithms

00:03:25.310 --> 00:03:25.320
concurrent garbage collector algorithms
 

00:03:25.320 --> 00:03:28.430
concurrent garbage collector algorithms
and we make sure that GC pauses were to

00:03:28.430 --> 00:03:28.440
and we make sure that GC pauses were to
 

00:03:28.440 --> 00:03:31.250
and we make sure that GC pauses were to
a minimal so active experience was

00:03:31.250 --> 00:03:31.260
a minimal so active experience was
 

00:03:31.260 --> 00:03:34.510
a minimal so active experience was
jank-free

00:03:34.510 --> 00:03:34.520
 

00:03:34.520 --> 00:03:37.460
since lollipop with most improving

00:03:37.460 --> 00:03:37.470
since lollipop with most improving
 

00:03:37.470 --> 00:03:40.940
since lollipop with most improving
performance so we have evolution on the

00:03:40.940 --> 00:03:40.950
performance so we have evolution on the
 

00:03:40.950 --> 00:03:44.900
performance so we have evolution on the
compiler lollipop when we shipped had a

00:03:44.900 --> 00:03:44.910
compiler lollipop when we shipped had a
 

00:03:44.910 --> 00:03:46.820
compiler lollipop when we shipped had a
quick when we should nollie pop it had a

00:03:46.820 --> 00:03:46.830
quick when we should nollie pop it had a
 

00:03:46.830 --> 00:03:49.670
quick when we should nollie pop it had a
quick compiler that was a fast Dex to

00:03:49.670 --> 00:03:49.680
quick compiler that was a fast Dex to
 

00:03:49.680 --> 00:03:51.560
quick compiler that was a fast Dex to
machine code compiler it was ported from

00:03:51.560 --> 00:03:51.570
machine code compiler it was ported from
 

00:03:51.570 --> 00:03:55.850
machine code compiler it was ported from
the dalvik JIT at a time at the time

00:03:55.850 --> 00:03:55.860
the dalvik JIT at a time at the time
 

00:03:55.860 --> 00:03:57.979
the dalvik JIT at a time at the time
were really eager to ship art given all

00:03:57.979 --> 00:03:57.989
were really eager to ship art given all
 

00:03:57.989 --> 00:04:00.290
were really eager to ship art given all
the benefits and we just were mostly

00:04:00.290 --> 00:04:00.300
the benefits and we just were mostly
 

00:04:00.300 --> 00:04:04.009
the benefits and we just were mostly
focused on shipping a well robot well

00:04:04.009 --> 00:04:04.019
focused on shipping a well robot well
 

00:04:04.019 --> 00:04:06.850
focused on shipping a well robot well
tested a robust compiler

00:04:06.850 --> 00:04:06.860
tested a robust compiler
 

00:04:06.860 --> 00:04:10.520
tested a robust compiler
however quick was not structurally meant

00:04:10.520 --> 00:04:10.530
however quick was not structurally meant
 

00:04:10.530 --> 00:04:12.470
however quick was not structurally meant
for more sophisticated optimizations

00:04:12.470 --> 00:04:12.480
for more sophisticated optimizations
 

00:04:12.480 --> 00:04:18.460
for more sophisticated optimizations
such as aligning and register location

00:04:18.460 --> 00:04:18.470
 

00:04:18.470 --> 00:04:20.800
so in marshmallow we introduce the

00:04:20.800 --> 00:04:20.810
so in marshmallow we introduce the
 

00:04:20.810 --> 00:04:23.320
so in marshmallow we introduce the
optimizing compiler that's a

00:04:23.320 --> 00:04:23.330
optimizing compiler that's a
 

00:04:23.330 --> 00:04:26.440
optimizing compiler that's a
state-of-the-art SSA form based compiler

00:04:26.440 --> 00:04:26.450
state-of-the-art SSA form based compiler
 

00:04:26.450 --> 00:04:30.430
state-of-the-art SSA form based compiler
infrastructure SSA in Kampala jargon

00:04:30.430 --> 00:04:30.440
infrastructure SSA in Kampala jargon
 

00:04:30.440 --> 00:04:33.430
infrastructure SSA in Kampala jargon
stands for static single assignment and

00:04:33.430 --> 00:04:33.440
stands for static single assignment and
 

00:04:33.440 --> 00:04:36.240
stands for static single assignment and
that's a well-known format for doing

00:04:36.240 --> 00:04:36.250
that's a well-known format for doing
 

00:04:36.250 --> 00:04:42.010
that's a well-known format for doing
optimizations in the compiler we

00:04:42.010 --> 00:04:42.020
optimizations in the compiler we
 

00:04:42.020 --> 00:04:43.560
optimizations in the compiler we
implement all sorts of optimizations

00:04:43.560 --> 00:04:43.570
implement all sorts of optimizations
 

00:04:43.570 --> 00:04:46.360
implement all sorts of optimizations
such as inlining bounce elimination

00:04:46.360 --> 00:04:46.370
such as inlining bounce elimination
 

00:04:46.370 --> 00:04:49.450
such as inlining bounce elimination
common subexpression elimination and so

00:04:49.450 --> 00:04:49.460
common subexpression elimination and so
 

00:04:49.460 --> 00:04:51.030
common subexpression elimination and so
on

00:04:51.030 --> 00:04:51.040
on
 

00:04:51.040 --> 00:04:53.290
on
we also included a linear scan register

00:04:53.290 --> 00:04:53.300
we also included a linear scan register
 

00:04:53.300 --> 00:04:56.080
we also included a linear scan register
allocator a state-of-the-art virtual

00:04:56.080 --> 00:04:56.090
allocator a state-of-the-art virtual
 

00:04:56.090 --> 00:05:00.120
allocator a state-of-the-art virtual
location technique for four compilers

00:05:00.120 --> 00:05:00.130
location technique for four compilers
 

00:05:00.130 --> 00:05:04.060
location technique for four compilers
and um we iterate on that compiler and

00:05:04.060 --> 00:05:04.070
and um we iterate on that compiler and
 

00:05:04.070 --> 00:05:06.850
and um we iterate on that compiler and
make more aggressive optimizations like

00:05:06.850 --> 00:05:06.860
make more aggressive optimizations like
 

00:05:06.860 --> 00:05:08.830
make more aggressive optimizations like
more aligning and lots more

00:05:08.830 --> 00:05:08.840
more aligning and lots more
 

00:05:08.840 --> 00:05:16.180
more aligning and lots more
lots more optimization this graph shows

00:05:16.180 --> 00:05:16.190
lots more optimization this graph shows
 

00:05:16.190 --> 00:05:18.460
lots more optimization this graph shows
the performance of marshmallow and M

00:05:18.460 --> 00:05:18.470
the performance of marshmallow and M
 

00:05:18.470 --> 00:05:20.620
the performance of marshmallow and M
preview normalized to performance in

00:05:20.620 --> 00:05:20.630
preview normalized to performance in
 

00:05:20.630 --> 00:05:25.710
preview normalized to performance in
lollipop its benchmarks one on Nexus 9

00:05:25.710 --> 00:05:25.720
lollipop its benchmarks one on Nexus 9
 

00:05:25.720 --> 00:05:28.420
lollipop its benchmarks one on Nexus 9
the tablet where we at a bit worried

00:05:28.420 --> 00:05:28.430
the tablet where we at a bit worried
 

00:05:28.430 --> 00:05:31.690
the tablet where we at a bit worried
lollipop and the first relief of art and

00:05:31.690 --> 00:05:31.700
lollipop and the first relief of art and
 

00:05:31.700 --> 00:05:33.640
lollipop and the first relief of art and
you can see we've causes the improvement

00:05:33.640 --> 00:05:33.650
you can see we've causes the improvement
 

00:05:33.650 --> 00:05:37.210
you can see we've causes the improvement
performance of a time we measured on

00:05:37.210 --> 00:05:37.220
performance of a time we measured on
 

00:05:37.220 --> 00:05:39.420
performance of a time we measured on
three different kinds of benchmarks

00:05:39.420 --> 00:05:39.430
three different kinds of benchmarks
 

00:05:39.430 --> 00:05:42.900
three different kinds of benchmarks
deltablue enrichers our well-known

00:05:42.900 --> 00:05:42.910
deltablue enrichers our well-known
 

00:05:42.910 --> 00:05:44.710
deltablue enrichers our well-known
object-oriented benchmark in the

00:05:44.710 --> 00:05:44.720
object-oriented benchmark in the
 

00:05:44.720 --> 00:05:47.290
object-oriented benchmark in the
arbitrated community that stresses how

00:05:47.290 --> 00:05:47.300
arbitrated community that stresses how
 

00:05:47.300 --> 00:05:50.100
arbitrated community that stresses how
you have the runtime implements calls

00:05:50.100 --> 00:05:50.110
you have the runtime implements calls
 

00:05:50.110 --> 00:05:53.920
you have the runtime implements calls
try stone is about how the run time and

00:05:53.920 --> 00:05:53.930
try stone is about how the run time and
 

00:05:53.930 --> 00:05:56.140
try stone is about how the run time and
the compiler generates integer

00:05:56.140 --> 00:05:56.150
the compiler generates integer
 

00:05:56.150 --> 00:06:01.540
the compiler generates integer
computations reversely bench test bench

00:06:01.540 --> 00:06:01.550
computations reversely bench test bench
 

00:06:01.550 --> 00:06:05.680
computations reversely bench test bench
and ribs are actually adaptations of of

00:06:05.680 --> 00:06:05.690
and ribs are actually adaptations of of
 

00:06:05.690 --> 00:06:08.590
and ribs are actually adaptations of of
Android applications perversity and

00:06:08.590 --> 00:06:08.600
Android applications perversity and
 

00:06:08.600 --> 00:06:13.659
Android applications perversity and
chess emulate dai of an actual game that

00:06:13.659 --> 00:06:13.669
chess emulate dai of an actual game that
 

00:06:13.669 --> 00:06:15.630
chess emulate dai of an actual game that
can get download from the Play Store and

00:06:15.630 --> 00:06:15.640
can get download from the Play Store and
 

00:06:15.640 --> 00:06:21.550
can get download from the Play Store and
reads emulate spreadsheet emulation so

00:06:21.550 --> 00:06:21.560
reads emulate spreadsheet emulation so
 

00:06:21.560 --> 00:06:22.600
reads emulate spreadsheet emulation so
we feel very pleased with the

00:06:22.600 --> 00:06:22.610
we feel very pleased with the
 

00:06:22.610 --> 00:06:25.360
we feel very pleased with the
improvements we made here ranging from 1

00:06:25.360 --> 00:06:25.370
improvements we made here ranging from 1
 

00:06:25.370 --> 00:06:29.310
improvements we made here ranging from 1
point to X - 5 XP Docs

00:06:29.310 --> 00:06:29.320
point to X - 5 XP Docs
 

00:06:29.320 --> 00:06:31.990
point to X - 5 XP Docs
and the performance boost isn't specific

00:06:31.990 --> 00:06:32.000
and the performance boost isn't specific
 

00:06:32.000 --> 00:06:35.050
and the performance boost isn't specific
to one architecture because most of

00:06:35.050 --> 00:06:35.060
to one architecture because most of
 

00:06:35.060 --> 00:06:37.960
to one architecture because most of
optimizations are CPU independent all

00:06:37.960 --> 00:06:37.970
optimizations are CPU independent all
 

00:06:37.970 --> 00:06:40.200
optimizations are CPU independent all
platforms benefit from them

00:06:40.200 --> 00:06:40.210
platforms benefit from them
 

00:06:40.210 --> 00:06:43.330
platforms benefit from them
so running the same benchmarks unarmed

00:06:43.330 --> 00:06:43.340
so running the same benchmarks unarmed
 

00:06:43.340 --> 00:06:45.390
so running the same benchmarks unarmed
study too will lead to the same

00:06:45.390 --> 00:06:45.400
study too will lead to the same
 

00:06:45.400 --> 00:06:47.590
study too will lead to the same
improvement trend across measure across

00:06:47.590 --> 00:06:47.600
improvement trend across measure across
 

00:06:47.600 --> 00:06:53.320
improvement trend across measure across
the board so that's great improving the

00:06:53.320 --> 00:06:53.330
the board so that's great improving the
 

00:06:53.330 --> 00:06:54.940
the board so that's great improving the
code generated by clean power is a great

00:06:54.940 --> 00:06:54.950
code generated by clean power is a great
 

00:06:54.950 --> 00:06:58.630
code generated by clean power is a great
win for performance faster frame

00:06:58.630 --> 00:06:58.640
win for performance faster frame
 

00:06:58.640 --> 00:07:07.490
win for performance faster frame
rendering and faster startup great but

00:07:07.490 --> 00:07:07.500
 

00:07:07.500 --> 00:07:12.950
I looks like you guys run into this so

00:07:12.950 --> 00:07:12.960
I looks like you guys run into this so
 

00:07:12.960 --> 00:07:14.030
I looks like you guys run into this so
you probably familiar with that dialogue

00:07:14.030 --> 00:07:14.040
you probably familiar with that dialogue
 

00:07:14.040 --> 00:07:20.480
you probably familiar with that dialogue
now it's pretty lucky right only twenty

00:07:20.480 --> 00:07:20.490
now it's pretty lucky right only twenty
 

00:07:20.490 --> 00:07:27.530
now it's pretty lucky right only twenty
one to go so that dialogue is what is

00:07:27.530 --> 00:07:27.540
one to go so that dialogue is what is
 

00:07:27.540 --> 00:07:29.290
one to go so that dialogue is what is
shown when you take a system update and

00:07:29.290 --> 00:07:29.300
shown when you take a system update and
 

00:07:29.300 --> 00:07:31.700
shown when you take a system update and
what happens there in case you don't

00:07:31.700 --> 00:07:31.710
what happens there in case you don't
 

00:07:31.710 --> 00:07:33.260
what happens there in case you don't
know is that we're redoing all the

00:07:33.260 --> 00:07:33.270
know is that we're redoing all the
 

00:07:33.270 --> 00:07:35.030
know is that we're redoing all the
optimizations we've done at install time

00:07:35.030 --> 00:07:35.040
optimizations we've done at install time
 

00:07:35.040 --> 00:07:39.590
optimizations we've done at install time
of an application why because when you

00:07:39.590 --> 00:07:39.600
of an application why because when you
 

00:07:39.600 --> 00:07:42.020
of an application why because when you
use all application art will optimize it

00:07:42.020 --> 00:07:42.030
use all application art will optimize it
 

00:07:42.030 --> 00:07:45.620
use all application art will optimize it
heavily against your platform and it

00:07:45.620 --> 00:07:45.630
heavily against your platform and it
 

00:07:45.630 --> 00:07:47.480
heavily against your platform and it
will put hard-coded dependencies in the

00:07:47.480 --> 00:07:47.490
will put hard-coded dependencies in the
 

00:07:47.490 --> 00:07:49.610
will put hard-coded dependencies in the
compiled code that will make your

00:07:49.610 --> 00:07:49.620
compiled code that will make your
 

00:07:49.620 --> 00:07:53.720
compiled code that will make your
applications run much faster but when

00:07:53.720 --> 00:07:53.730
applications run much faster but when
 

00:07:53.730 --> 00:07:55.970
applications run much faster but when
you get a system update all those

00:07:55.970 --> 00:07:55.980
you get a system update all those
 

00:07:55.980 --> 00:07:57.500
you get a system update all those
hard-coded dependencies become invalid

00:07:57.500 --> 00:07:57.510
hard-coded dependencies become invalid
 

00:07:57.510 --> 00:08:00.260
hard-coded dependencies become invalid
because you get a new system so we knew

00:08:00.260 --> 00:08:00.270
because you get a new system so we knew
 

00:08:00.270 --> 00:08:04.910
because you get a new system so we knew
to redo all the work when we shipped art

00:08:04.910 --> 00:08:04.920
to redo all the work when we shipped art
 

00:08:04.920 --> 00:08:07.460
to redo all the work when we shipped art
that was actually a trade-off we've made

00:08:07.460 --> 00:08:07.470
that was actually a trade-off we've made
 

00:08:07.470 --> 00:08:11.540
that was actually a trade-off we've made
because OTAs or system updates were

00:08:11.540 --> 00:08:11.550
because OTAs or system updates were
 

00:08:11.550 --> 00:08:14.360
because OTAs or system updates were
usually once a year so for once a year

00:08:14.360 --> 00:08:14.370
usually once a year so for once a year
 

00:08:14.370 --> 00:08:17.690
usually once a year so for once a year
update you'll get really better Android

00:08:17.690 --> 00:08:17.700
update you'll get really better Android
 

00:08:17.700 --> 00:08:24.340
update you'll get really better Android
experience

00:08:24.340 --> 00:08:24.350
 

00:08:24.350 --> 00:08:29.160
but Android ecosystem has evolved and

00:08:29.160 --> 00:08:29.170
but Android ecosystem has evolved and
 

00:08:29.170 --> 00:08:31.830
but Android ecosystem has evolved and
security being at the heart of Android

00:08:31.830 --> 00:08:31.840
security being at the heart of Android
 

00:08:31.840 --> 00:08:35.110
security being at the heart of Android
our security team worked hard on making

00:08:35.110 --> 00:08:35.120
our security team worked hard on making
 

00:08:35.120 --> 00:08:37.900
our security team worked hard on making
sure security fixes could be sent to

00:08:37.900 --> 00:08:37.910
sure security fixes could be sent to
 

00:08:37.910 --> 00:08:42.520
sure security fixes could be sent to
hundred phones as soon as possible so

00:08:42.520 --> 00:08:42.530
hundred phones as soon as possible so
 

00:08:42.530 --> 00:08:45.630
hundred phones as soon as possible so
when our lead security engineer and

00:08:45.630 --> 00:08:45.640
when our lead security engineer and
 

00:08:45.640 --> 00:08:49.540
when our lead security engineer and
director of Nexus products announced we

00:08:49.540 --> 00:08:49.550
director of Nexus products announced we
 

00:08:49.550 --> 00:08:52.060
director of Nexus products announced we
are now moving to monthly updates it was

00:08:52.060 --> 00:08:52.070
are now moving to monthly updates it was
 

00:08:52.070 --> 00:08:53.440
are now moving to monthly updates it was
sort of clear that this initial

00:08:53.440 --> 00:08:53.450
sort of clear that this initial
 

00:08:53.450 --> 00:08:56.560
sort of clear that this initial
trade-off we made will not work and our

00:08:56.560 --> 00:08:56.570
trade-off we made will not work and our
 

00:08:56.570 --> 00:09:00.700
trade-off we made will not work and our
team to adapt so we bought back a

00:09:00.700 --> 00:09:00.710
team to adapt so we bought back a
 

00:09:00.710 --> 00:09:05.730
team to adapt so we bought back a
just-in-time compiler in art so no more

00:09:05.730 --> 00:09:05.740
just-in-time compiler in art so no more
 

00:09:05.740 --> 00:09:20.610
just-in-time compiler in art so no more
optimizing app dialogue thank you

00:09:20.610 --> 00:09:20.620
 

00:09:20.620 --> 00:09:23.080
it turns out moving the dialogue is not

00:09:23.080 --> 00:09:23.090
it turns out moving the dialogue is not
 

00:09:23.090 --> 00:09:26.860
it turns out moving the dialogue is not
the only benefit of having a JIT we now

00:09:26.860 --> 00:09:26.870
the only benefit of having a JIT we now
 

00:09:26.870 --> 00:09:29.680
the only benefit of having a JIT we now
get much faster installs around 75%

00:09:29.680 --> 00:09:29.690
get much faster installs around 75%
 

00:09:29.690 --> 00:09:33.310
get much faster installs around 75%
faster and because they would he could

00:09:33.310 --> 00:09:33.320
faster and because they would he could
 

00:09:33.320 --> 00:09:35.710
faster and because they would he could
not know when it was compiling which

00:09:35.710 --> 00:09:35.720
not know when it was compiling which
 

00:09:35.720 --> 00:09:39.310
not know when it was compiling which
parts of the app is being executed which

00:09:39.310 --> 00:09:39.320
parts of the app is being executed which
 

00:09:39.320 --> 00:09:41.170
parts of the app is being executed which
it turns out that we were compiling all

00:09:41.170 --> 00:09:41.180
it turns out that we were compiling all
 

00:09:41.180 --> 00:09:44.440
it turns out that we were compiling all
the code of your apk and I just sort of

00:09:44.440 --> 00:09:44.450
the code of your apk and I just sort of
 

00:09:44.450 --> 00:09:46.360
the code of your apk and I just sort of
a waste of your storage if you're gonna

00:09:46.360 --> 00:09:46.370
a waste of your storage if you're gonna
 

00:09:46.370 --> 00:09:53.230
a waste of your storage if you're gonna
use just 5 or 10% of the code but

00:09:53.230 --> 00:09:53.240
use just 5 or 10% of the code but
 

00:09:53.240 --> 00:09:57.100
use just 5 or 10% of the code but
letting legit has some unknown like

00:09:57.100 --> 00:09:57.110
letting legit has some unknown like
 

00:09:57.110 --> 00:09:59.500
letting legit has some unknown like
clearly keeping on compiling all the

00:09:59.500 --> 00:09:59.510
clearly keeping on compiling all the
 

00:09:59.510 --> 00:10:02.800
clearly keeping on compiling all the
time like you start the app Egypt you

00:10:02.800 --> 00:10:02.810
time like you start the app Egypt you
 

00:10:02.810 --> 00:10:04.420
time like you start the app Egypt you
kill the app you start it up again

00:10:04.420 --> 00:10:04.430
kill the app you start it up again
 

00:10:04.430 --> 00:10:06.910
kill the app you start it up again
Egypt but has some implications on your

00:10:06.910 --> 00:10:06.920
Egypt but has some implications on your
 

00:10:06.920 --> 00:10:09.340
Egypt but has some implications on your
battery that aut compiled code didn't

00:10:09.340 --> 00:10:09.350
battery that aut compiled code didn't
 

00:10:09.350 --> 00:10:13.890
battery that aut compiled code didn't
have having a copulation code cache

00:10:13.890 --> 00:10:13.900
have having a copulation code cache
 

00:10:13.900 --> 00:10:16.960
have having a copulation code cache
could be wasteful if not managed

00:10:16.960 --> 00:10:16.970
could be wasteful if not managed
 

00:10:16.970 --> 00:10:20.460
could be wasteful if not managed
properly

00:10:20.460 --> 00:10:20.470
 

00:10:20.470 --> 00:10:23.670
so what we did in M is introduce a

00:10:23.670 --> 00:10:23.680
so what we did in M is introduce a
 

00:10:23.680 --> 00:10:26.939
so what we did in M is introduce a
hybrid just in time F time copulation

00:10:26.939 --> 00:10:26.949
hybrid just in time F time copulation
 

00:10:26.949 --> 00:10:29.340
hybrid just in time F time copulation
system that combines the benefits of

00:10:29.340 --> 00:10:29.350
system that combines the benefits of
 

00:10:29.350 --> 00:10:33.530
system that combines the benefits of
both worlds the idea is that

00:10:33.530 --> 00:10:33.540
both worlds the idea is that
 

00:10:33.540 --> 00:10:35.430
both worlds the idea is that
applications start running with a JIT

00:10:35.430 --> 00:10:35.440
applications start running with a JIT
 

00:10:35.440 --> 00:10:39.410
applications start running with a JIT
and when the phone is idle in charging I

00:10:39.410 --> 00:10:39.420
and when the phone is idle in charging I
 

00:10:39.420 --> 00:10:42.619
and when the phone is idle in charging I
will do profile guided optimizations and

00:10:42.619 --> 00:10:42.629
will do profile guided optimizations and
 

00:10:42.629 --> 00:10:46.170
will do profile guided optimizations and
ahead of time heavily optimize the parts

00:10:46.170 --> 00:10:46.180
ahead of time heavily optimize the parts
 

00:10:46.180 --> 00:10:48.689
ahead of time heavily optimize the parts
of the application the G has the JIT has

00:10:48.689 --> 00:10:48.699
of the application the G has the JIT has
 

00:10:48.699 --> 00:10:54.139
of the application the G has the JIT has
executed already so later in this talk

00:10:54.139 --> 00:10:54.149
executed already so later in this talk
 

00:10:54.149 --> 00:10:57.300
executed already so later in this talk
Macaulay clean will go into more detail

00:10:57.300 --> 00:10:57.310
Macaulay clean will go into more detail
 

00:10:57.310 --> 00:11:00.629
Macaulay clean will go into more detail
about how this hybrid äôt JIT profile

00:11:00.629 --> 00:11:00.639
about how this hybrid äôt JIT profile
 

00:11:00.639 --> 00:11:04.829
about how this hybrid äôt JIT profile
guided compilation works what I want to

00:11:04.829 --> 00:11:04.839
guided compilation works what I want to
 

00:11:04.839 --> 00:11:09.449
guided compilation works what I want to
focus now is how is the unknown with the

00:11:09.449 --> 00:11:09.459
focus now is how is the unknown with the
 

00:11:09.459 --> 00:11:14.970
focus now is how is the unknown with the
JIT so let's go back to the five metrics

00:11:14.970 --> 00:11:14.980
JIT so let's go back to the five metrics
 

00:11:14.980 --> 00:11:18.480
JIT so let's go back to the five metrics
I mentioned earlier in the talk for

00:11:18.480 --> 00:11:18.490
I mentioned earlier in the talk for
 

00:11:18.490 --> 00:11:21.119
I mentioned earlier in the talk for
runtime performance the jet is based on

00:11:21.119 --> 00:11:21.129
runtime performance the jet is based on
 

00:11:21.129 --> 00:11:24.119
runtime performance the jet is based on
the same ehe compiler that brings the

00:11:24.119 --> 00:11:24.129
the same ehe compiler that brings the
 

00:11:24.129 --> 00:11:28.610
the same ehe compiler that brings the
same high performance so we're covered

00:11:28.610 --> 00:11:28.620
same high performance so we're covered
 

00:11:28.620 --> 00:11:31.259
same high performance so we're covered
but the other metrics are actually down

00:11:31.259 --> 00:11:31.269
but the other metrics are actually down
 

00:11:31.269 --> 00:11:37.170
but the other metrics are actually down
to how we tune the JIT a couple of

00:11:37.170 --> 00:11:37.180
to how we tune the JIT a couple of
 

00:11:37.180 --> 00:11:38.730
to how we tune the JIT a couple of
things we made when starting this

00:11:38.730 --> 00:11:38.740
things we made when starting this
 

00:11:38.740 --> 00:11:40.829
things we made when starting this
project a color of design decisions we

00:11:40.829 --> 00:11:40.839
project a color of design decisions we
 

00:11:40.839 --> 00:11:47.910
project a color of design decisions we
made were based on those metrics like we

00:11:47.910 --> 00:11:47.920
made were based on those metrics like we
 

00:11:47.920 --> 00:11:49.800
made were based on those metrics like we
implemented a March faster interpreter

00:11:49.800 --> 00:11:49.810
implemented a March faster interpreter
 

00:11:49.810 --> 00:11:52.350
implemented a March faster interpreter
in n compared to the one in marshmallow

00:11:52.350 --> 00:11:52.360
in n compared to the one in marshmallow
 

00:11:52.360 --> 00:11:56.490
in n compared to the one in marshmallow
and ones like up to 3x faster then you

00:11:56.490 --> 00:11:56.500
and ones like up to 3x faster then you
 

00:11:56.500 --> 00:11:59.670
and ones like up to 3x faster then you
have to appear in marshmallow it's very

00:11:59.670 --> 00:11:59.680
have to appear in marshmallow it's very
 

00:11:59.680 --> 00:12:01.019
have to appear in marshmallow it's very
important to have a fast interpreter

00:12:01.019 --> 00:12:01.029
important to have a fast interpreter
 

00:12:01.029 --> 00:12:02.939
important to have a fast interpreter
because when you start your app you

00:12:02.939 --> 00:12:02.949
because when you start your app you
 

00:12:02.949 --> 00:12:04.379
because when you start your app you
don't have any ahead of time compiled

00:12:04.379 --> 00:12:04.389
don't have any ahead of time compiled
 

00:12:04.389 --> 00:12:07.309
don't have any ahead of time compiled
code it's the insurers gonna run and

00:12:07.309 --> 00:12:07.319
code it's the insurers gonna run and
 

00:12:07.319 --> 00:12:12.809
code it's the insurers gonna run and
later on the JIT second we do a JIT

00:12:12.809 --> 00:12:12.819
later on the JIT second we do a JIT
 

00:12:12.819 --> 00:12:15.870
later on the JIT second we do a JIT
compilation on a separate thread and not

00:12:15.870 --> 00:12:15.880
compilation on a separate thread and not
 

00:12:15.880 --> 00:12:18.569
compilation on a separate thread and not
on the application threads some

00:12:18.569 --> 00:12:18.579
on the application threads some
 

00:12:18.579 --> 00:12:20.340
on the application threads some
compilation can take very long and you

00:12:20.340 --> 00:12:20.350
compilation can take very long and you
 

00:12:20.350 --> 00:12:23.519
compilation can take very long and you
don't want to block the UI thread just

00:12:23.519 --> 00:12:23.529
don't want to block the UI thread just
 

00:12:23.529 --> 00:12:27.050
don't want to block the UI thread just
for doing compilation

00:12:27.050 --> 00:12:27.060
for doing compilation
 

00:12:27.060 --> 00:12:30.860
for doing compilation
for saving power what we did is most

00:12:30.860 --> 00:12:30.870
for saving power what we did is most
 

00:12:30.870 --> 00:12:33.050
for saving power what we did is most
what we do is mostly focusing on the

00:12:33.050 --> 00:12:33.060
what we do is mostly focusing on the
 

00:12:33.060 --> 00:12:36.970
what we do is mostly focusing on the
hottest methods of an application and

00:12:36.970 --> 00:12:36.980
hottest methods of an application and
 

00:12:36.980 --> 00:12:40.010
hottest methods of an application and
filing for memory footprint we

00:12:40.010 --> 00:12:40.020
filing for memory footprint we
 

00:12:40.020 --> 00:12:41.030
filing for memory footprint we
implemented a garbage collection

00:12:41.030 --> 00:12:41.040
implemented a garbage collection
 

00:12:41.040 --> 00:12:43.430
implemented a garbage collection
technique that ensures that only the

00:12:43.430 --> 00:12:43.440
technique that ensures that only the
 

00:12:43.440 --> 00:12:45.710
technique that ensures that only the
method is that indian matter over time

00:12:45.710 --> 00:12:45.720
method is that indian matter over time
 

00:12:45.720 --> 00:12:48.020
method is that indian matter over time
are kept so if a method is being

00:12:48.020 --> 00:12:48.030
are kept so if a method is being
 

00:12:48.030 --> 00:12:49.930
are kept so if a method is being
compiled and i'm not being used anymore

00:12:49.930 --> 00:12:49.940
compiled and i'm not being used anymore
 

00:12:49.940 --> 00:12:53.470
compiled and i'm not being used anymore
we'll remove it from memory

00:12:53.470 --> 00:12:53.480
we'll remove it from memory
 

00:12:53.480 --> 00:12:56.990
we'll remove it from memory
all right so let's focus on application

00:12:56.990 --> 00:12:57.000
all right so let's focus on application
 

00:12:57.000 --> 00:13:01.520
all right so let's focus on application
startup now I'm going to walk you

00:13:01.520 --> 00:13:01.530
startup now I'm going to walk you
 

00:13:01.530 --> 00:13:04.100
startup now I'm going to walk you
through some systrace that will explain

00:13:04.100 --> 00:13:04.110
through some systrace that will explain
 

00:13:04.110 --> 00:13:06.200
through some systrace that will explain
some of the implementation decisions

00:13:06.200 --> 00:13:06.210
some of the implementation decisions
 

00:13:06.210 --> 00:13:08.630
some of the implementation decisions
we've made if you don't know what this

00:13:08.630 --> 00:13:08.640
we've made if you don't know what this
 

00:13:08.640 --> 00:13:11.390
we've made if you don't know what this
race is it's a great tool for both app

00:13:11.390 --> 00:13:11.400
race is it's a great tool for both app
 

00:13:11.400 --> 00:13:14.480
race is it's a great tool for both app
developers and platform developers to

00:13:14.480 --> 00:13:14.490
developers and platform developers to
 

00:13:14.490 --> 00:13:16.460
developers and platform developers to
analyze what is happening on Android

00:13:16.460 --> 00:13:16.470
analyze what is happening on Android
 

00:13:16.470 --> 00:13:20.290
analyze what is happening on Android
system so bear with me

00:13:20.290 --> 00:13:20.300
system so bear with me
 

00:13:20.300 --> 00:13:22.160
system so bear with me
there's a lot of information on that

00:13:22.160 --> 00:13:22.170
there's a lot of information on that
 

00:13:22.170 --> 00:13:24.260
there's a lot of information on that
slide but we'll focus on the things that

00:13:24.260 --> 00:13:24.270
slide but we'll focus on the things that
 

00:13:24.270 --> 00:13:27.710
slide but we'll focus on the things that
matter for us so here's that way she

00:13:27.710 --> 00:13:27.720
matter for us so here's that way she
 

00:13:27.720 --> 00:13:30.740
matter for us so here's that way she
strikes looks after launching Gmail on a

00:13:30.740 --> 00:13:30.750
strikes looks after launching Gmail on a
 

00:13:30.750 --> 00:13:32.720
strikes looks after launching Gmail on a
device that had Gmail ahead of time

00:13:32.720 --> 00:13:32.730
device that had Gmail ahead of time
 

00:13:32.730 --> 00:13:37.970
device that had Gmail ahead of time
contolled so applications start up for a

00:13:37.970 --> 00:13:37.980
contolled so applications start up for a
 

00:13:37.980 --> 00:13:41.390
contolled so applications start up for a
user is actually when the first frame is

00:13:41.390 --> 00:13:41.400
user is actually when the first frame is
 

00:13:41.400 --> 00:13:45.080
user is actually when the first frame is
being rendered and this trace here is

00:13:45.080 --> 00:13:45.090
being rendered and this trace here is
 

00:13:45.090 --> 00:13:46.430
being rendered and this trace here is
someone's wall that's what you would get

00:13:46.430 --> 00:13:46.440
someone's wall that's what you would get
 

00:13:46.440 --> 00:13:49.100
someone's wall that's what you would get
on marshmallow and lollipop is that for

00:13:49.100 --> 00:13:49.110
on marshmallow and lollipop is that for
 

00:13:49.110 --> 00:13:51.110
on marshmallow and lollipop is that for
starting Gmail it would take half a

00:13:51.110 --> 00:13:51.120
starting Gmail it would take half a
 

00:13:51.120 --> 00:13:55.780
starting Gmail it would take half a
second for the first frame to be drawn

00:13:55.780 --> 00:13:55.790
 

00:13:55.790 --> 00:13:58.700
so our first implementation or alpha

00:13:58.700 --> 00:13:58.710
so our first implementation or alpha
 

00:13:58.710 --> 00:14:01.130
so our first implementation or alpha
implementation of the JIT we do the same

00:14:01.130 --> 00:14:01.140
implementation of the JIT we do the same
 

00:14:01.140 --> 00:14:05.330
implementation of the JIT we do the same
measurements and reserve results were

00:14:05.330 --> 00:14:05.340
measurements and reserve results were
 

00:14:05.340 --> 00:14:09.320
measurements and reserve results were
not great you can see now the startup is

00:14:09.320 --> 00:14:09.330
not great you can see now the startup is
 

00:14:09.330 --> 00:14:11.360
not great you can see now the startup is
around one second so we increase the

00:14:11.360 --> 00:14:11.370
around one second so we increase the
 

00:14:11.370 --> 00:14:16.150
around one second so we increase the
startup around 2x

00:14:16.150 --> 00:14:16.160
 

00:14:16.160 --> 00:14:18.670
and you can see that the jet thread here

00:14:18.670 --> 00:14:18.680
and you can see that the jet thread here
 

00:14:18.680 --> 00:14:25.420
and you can see that the jet thread here
executing is initially idle and that

00:14:25.420 --> 00:14:25.430
executing is initially idle and that
 

00:14:25.430 --> 00:14:30.460
executing is initially idle and that
becomes very busy so what's happening if

00:14:30.460 --> 00:14:30.470
becomes very busy so what's happening if
 

00:14:30.470 --> 00:14:31.749
becomes very busy so what's happening if
you take a closer look at what the

00:14:31.749 --> 00:14:31.759
you take a closer look at what the
 

00:14:31.759 --> 00:14:34.960
you take a closer look at what the
application is doing there's around 200

00:14:34.960 --> 00:14:34.970
application is doing there's around 200
 

00:14:34.970 --> 00:14:38.259
application is doing there's around 200
milliseconds for doing just the apk

00:14:38.259 --> 00:14:38.269
milliseconds for doing just the apk
 

00:14:38.269 --> 00:14:42.569
milliseconds for doing just the apk
extraction and doing apks fraction

00:14:42.569 --> 00:14:42.579
extraction and doing apks fraction
 

00:14:42.579 --> 00:14:45.040
extraction and doing apks fraction
extraction is a blocking information so

00:14:45.040 --> 00:14:45.050
extraction is a blocking information so
 

00:14:45.050 --> 00:14:46.600
extraction is a blocking information so
you need to do it before executing any

00:14:46.600 --> 00:14:46.610
you need to do it before executing any
 

00:14:46.610 --> 00:14:53.590
you need to do it before executing any
code similarly there's lots of things

00:14:53.590 --> 00:14:53.600
code similarly there's lots of things
 

00:14:53.600 --> 00:14:55.840
code similarly there's lots of things
happening after the AP construction that

00:14:55.840 --> 00:14:55.850
happening after the AP construction that
 

00:14:55.850 --> 00:14:57.160
happening after the AP construction that
don't have to do with your with a

00:14:57.160 --> 00:14:57.170
don't have to do with your with a
 

00:14:57.170 --> 00:14:58.329
don't have to do with your with a
zucchini application and that's

00:14:58.329 --> 00:14:58.339
zucchini application and that's
 

00:14:58.339 --> 00:15:01.990
zucchini application and that's
verification art needs to verify the Dex

00:15:01.990 --> 00:15:02.000
verification art needs to verify the Dex
 

00:15:02.000 --> 00:15:04.210
verification art needs to verify the Dex
code in order to run it and optimize it

00:15:04.210 --> 00:15:04.220
code in order to run it and optimize it
 

00:15:04.220 --> 00:15:09.730
code in order to run it and optimize it
so we'll fix this problem we'll start to

00:15:09.730 --> 00:15:09.740
so we'll fix this problem we'll start to
 

00:15:09.740 --> 00:15:10.120
so we'll fix this problem we'll start to
move

00:15:10.120 --> 00:15:10.130
move
 

00:15:10.130 --> 00:15:13.540
move
extraction and verification out of every

00:15:13.540 --> 00:15:13.550
extraction and verification out of every
 

00:15:13.550 --> 00:15:16.180
extraction and verification out of every
application startup and move it back to

00:15:16.180 --> 00:15:16.190
application startup and move it back to
 

00:15:16.190 --> 00:15:17.559
application startup and move it back to
when the application is actually being

00:15:17.559 --> 00:15:17.569
when the application is actually being
 

00:15:17.569 --> 00:15:20.949
when the application is actually being
installed so let's play the application

00:15:20.949 --> 00:15:20.959
installed so let's play the application
 

00:15:20.959 --> 00:15:22.509
installed so let's play the application
startup two times faster than our

00:15:22.509 --> 00:15:22.519
startup two times faster than our
 

00:15:22.519 --> 00:15:25.329
startup two times faster than our
initial and JIT implementation and quite

00:15:25.329 --> 00:15:25.339
initial and JIT implementation and quite
 

00:15:25.339 --> 00:15:31.210
initial and JIT implementation and quite
on par with compiled code so I've just

00:15:31.210 --> 00:15:31.220
on par with compiled code so I've just
 

00:15:31.220 --> 00:15:33.610
on par with compiled code so I've just
talked about application startup about

00:15:33.610 --> 00:15:33.620
talked about application startup about
 

00:15:33.620 --> 00:15:38.439
talked about application startup about
junk for janked for jank

00:15:38.439 --> 00:15:38.449
junk for janked for jank
 

00:15:38.449 --> 00:15:41.759
junk for janked for jank
we looked at the frame rate of scrolling

00:15:41.759 --> 00:15:41.769
we looked at the frame rate of scrolling
 

00:15:41.769 --> 00:15:45.990
we looked at the frame rate of scrolling
within the Google photos application and

00:15:45.990 --> 00:15:46.000
within the Google photos application and
 

00:15:46.000 --> 00:15:48.670
within the Google photos application and
systrace gives you this nice list of

00:15:48.670 --> 00:15:48.680
systrace gives you this nice list of
 

00:15:48.680 --> 00:15:51.759
systrace gives you this nice list of
spray of frames are being drawn a green

00:15:51.759 --> 00:15:51.769
spray of frames are being drawn a green
 

00:15:51.769 --> 00:15:54.699
spray of frames are being drawn a green
frame is when the UI I managed to render

00:15:54.699 --> 00:15:54.709
frame is when the UI I managed to render
 

00:15:54.709 --> 00:15:58.360
frame is when the UI I managed to render
it in time orange in red is where you're

00:15:58.360 --> 00:15:58.370
it in time orange in red is where you're
 

00:15:58.370 --> 00:15:59.949
it in time orange in red is where you're
dropping the frame and it hasn't been

00:15:59.949 --> 00:15:59.959
dropping the frame and it hasn't been
 

00:15:59.959 --> 00:16:04.240
dropping the frame and it hasn't been
rendered now John can be attributed to

00:16:04.240 --> 00:16:04.250
rendered now John can be attributed to
 

00:16:04.250 --> 00:16:07.179
rendered now John can be attributed to
many factors and artists it's best at

00:16:07.179 --> 00:16:07.189
many factors and artists it's best at
 

00:16:07.189 --> 00:16:10.019
many factors and artists it's best at
executing the code of the application

00:16:10.019 --> 00:16:10.029
executing the code of the application
 

00:16:10.029 --> 00:16:12.429
executing the code of the application
but if the application does too much on

00:16:12.429 --> 00:16:12.439
but if the application does too much on
 

00:16:12.439 --> 00:16:14.620
but if the application does too much on
the on the thread obviously we're gonna

00:16:14.620 --> 00:16:14.630
the on the thread obviously we're gonna
 

00:16:14.630 --> 00:16:18.429
the on the thread obviously we're gonna
miss a frame so you have for that

00:16:18.429 --> 00:16:18.439
miss a frame so you have for that
 

00:16:18.439 --> 00:16:21.970
miss a frame so you have for that
specific experiment we have around 4% of

00:16:21.970 --> 00:16:21.980
specific experiment we have around 4% of
 

00:16:21.980 --> 00:16:25.610
specific experiment we have around 4% of
frames that are being dropped

00:16:25.610 --> 00:16:25.620
 

00:16:25.620 --> 00:16:28.830
during our first chin bringing up we

00:16:28.830 --> 00:16:28.840
during our first chin bringing up we
 

00:16:28.840 --> 00:16:32.130
during our first chin bringing up we
made the same same experiment so the

00:16:32.130 --> 00:16:32.140
made the same same experiment so the
 

00:16:32.140 --> 00:16:34.320
made the same same experiment so the
application wasn't compiled and we're

00:16:34.320 --> 00:16:34.330
application wasn't compiled and we're
 

00:16:34.330 --> 00:16:37.140
application wasn't compiled and we're
just running with the JIT and the

00:16:37.140 --> 00:16:37.150
just running with the JIT and the
 

00:16:37.150 --> 00:16:39.210
just running with the JIT and the
results weren't great we're dropping

00:16:39.210 --> 00:16:39.220
results weren't great we're dropping
 

00:16:39.220 --> 00:16:45.540
results weren't great we're dropping
around 20% of frames if you take a

00:16:45.540 --> 00:16:45.550
around 20% of frames if you take a
 

00:16:45.550 --> 00:16:46.740
around 20% of frames if you take a
closer look at what the gene is actually

00:16:46.740 --> 00:16:46.750
closer look at what the gene is actually
 

00:16:46.750 --> 00:16:49.700
closer look at what the gene is actually
doing here you can see those long

00:16:49.700 --> 00:16:49.710
doing here you can see those long
 

00:16:49.710 --> 00:16:52.770
doing here you can see those long
compilation activities where echo power

00:16:52.770 --> 00:16:52.780
compilation activities where echo power
 

00:16:52.780 --> 00:16:55.220
compilation activities where echo power
is actually waiting for methods or for

00:16:55.220 --> 00:16:55.230
is actually waiting for methods or for
 

00:16:55.230 --> 00:16:58.680
is actually waiting for methods or for
requests to pop out methods those

00:16:58.680 --> 00:16:58.690
requests to pop out methods those
 

00:16:58.690 --> 00:17:00.120
requests to pop out methods those
methods haven't reached the hotness

00:17:00.120 --> 00:17:00.130
methods haven't reached the hotness
 

00:17:00.130 --> 00:17:03.810
methods haven't reached the hotness
threshold that we've set and the heart

00:17:03.810 --> 00:17:03.820
threshold that we've set and the heart
 

00:17:03.820 --> 00:17:05.160
threshold that we've set and the heart
that special is hired because we want to

00:17:05.160 --> 00:17:05.170
that special is hired because we want to
 

00:17:05.170 --> 00:17:07.610
that special is hired because we want to
save in battery but that doesn't save on

00:17:07.610 --> 00:17:07.620
save in battery but that doesn't save on
 

00:17:07.620 --> 00:17:13.560
save in battery but that doesn't save on
saving junk the UI thread you want the

00:17:13.560 --> 00:17:13.570
saving junk the UI thread you want the
 

00:17:13.570 --> 00:17:15.720
saving junk the UI thread you want the
code that the steps where is executing

00:17:15.720 --> 00:17:15.730
code that the steps where is executing
 

00:17:15.730 --> 00:17:20.000
code that the steps where is executing
to be hot as soon as possible

00:17:20.000 --> 00:17:20.010
to be hot as soon as possible
 

00:17:20.010 --> 00:17:23.160
to be hot as soon as possible
so the solution was to increase the

00:17:23.160 --> 00:17:23.170
so the solution was to increase the
 

00:17:23.170 --> 00:17:26.490
so the solution was to increase the
weight of UI thread requests for

00:17:26.490 --> 00:17:26.500
weight of UI thread requests for
 

00:17:26.500 --> 00:17:29.160
weight of UI thread requests for
computation so the methods it could it

00:17:29.160 --> 00:17:29.170
computation so the methods it could it
 

00:17:29.170 --> 00:17:32.840
computation so the methods it could it
runs would be compiled almost instantly

00:17:32.840 --> 00:17:32.850
runs would be compiled almost instantly
 

00:17:32.850 --> 00:17:35.700
runs would be compiled almost instantly
so if you've seen since to trace there's

00:17:35.700 --> 00:17:35.710
so if you've seen since to trace there's
 

00:17:35.710 --> 00:17:37.700
so if you've seen since to trace there's
no more long pauses of computations and

00:17:37.700 --> 00:17:37.710
no more long pauses of computations and
 

00:17:37.710 --> 00:17:40.560
no more long pauses of computations and
we only dropped around 4% of miss of

00:17:40.560 --> 00:17:40.570
we only dropped around 4% of miss of
 

00:17:40.570 --> 00:17:43.590
we only dropped around 4% of miss of
frames which was the og level we had

00:17:43.590 --> 00:17:43.600
frames which was the og level we had
 

00:17:43.600 --> 00:17:52.140
frames which was the og level we had
initially all right battery usage

00:17:52.140 --> 00:17:52.150
 

00:17:52.150 --> 00:17:54.659
we've measured the power usage of

00:17:54.659 --> 00:17:54.669
we've measured the power usage of
 

00:17:54.669 --> 00:17:57.510
we've measured the power usage of
starting Gmail pausing for 30 seconds

00:17:57.510 --> 00:17:57.520
starting Gmail pausing for 30 seconds
 

00:17:57.520 --> 00:18:02.310
starting Gmail pausing for 30 seconds
and then scroll around the emails and we

00:18:02.310 --> 00:18:02.320
and then scroll around the emails and we
 

00:18:02.320 --> 00:18:03.659
and then scroll around the emails and we
can see here that the JIT is being the

00:18:03.659 --> 00:18:03.669
can see here that the JIT is being the
 

00:18:03.669 --> 00:18:06.570
can see here that the JIT is being the
high cost application startup prepared

00:18:06.570 --> 00:18:06.580
high cost application startup prepared
 

00:18:06.580 --> 00:18:10.049
high cost application startup prepared
to air of time population but one

00:18:10.049 --> 00:18:10.059
to air of time population but one
 

00:18:10.059 --> 00:18:13.200
to air of time population but one
startup is done the scrolling actually

00:18:13.200 --> 00:18:13.210
startup is done the scrolling actually
 

00:18:13.210 --> 00:18:15.330
startup is done the scrolling actually
doesn't has has no difference between

00:18:15.330 --> 00:18:15.340
doesn't has has no difference between
 

00:18:15.340 --> 00:18:20.100
doesn't has has no difference between
aut and jet the reason for this for this

00:18:20.100 --> 00:18:20.110
aut and jet the reason for this for this
 

00:18:20.110 --> 00:18:22.680
aut and jet the reason for this for this
difference is that as the startup the

00:18:22.680 --> 00:18:22.690
difference is that as the startup the
 

00:18:22.690 --> 00:18:24.570
difference is that as the startup the
JIT is very busy compiling a lot of

00:18:24.570 --> 00:18:24.580
JIT is very busy compiling a lot of
 

00:18:24.580 --> 00:18:27.899
JIT is very busy compiling a lot of
methods and Gmail seems to be very

00:18:27.899 --> 00:18:27.909
methods and Gmail seems to be very
 

00:18:27.909 --> 00:18:30.740
methods and Gmail seems to be very
aggressive in executing code at startup

00:18:30.740 --> 00:18:30.750
aggressive in executing code at startup
 

00:18:30.750 --> 00:18:33.000
aggressive in executing code at startup
which is not necessarily the behavior of

00:18:33.000 --> 00:18:33.010
which is not necessarily the behavior of
 

00:18:33.010 --> 00:18:36.269
which is not necessarily the behavior of
all apps so we've done the same

00:18:36.269 --> 00:18:36.279
all apps so we've done the same
 

00:18:36.279 --> 00:18:41.220
all apps so we've done the same
experiment with other apps we've looked

00:18:41.220 --> 00:18:41.230
experiment with other apps we've looked
 

00:18:41.230 --> 00:18:44.730
experiment with other apps we've looked
at Chrome camera on photos common camera

00:18:44.730 --> 00:18:44.740
at Chrome camera on photos common camera
 

00:18:44.740 --> 00:18:47.580
at Chrome camera on photos common camera
are mostly based on native code so here

00:18:47.580 --> 00:18:47.590
are mostly based on native code so here
 

00:18:47.590 --> 00:18:49.230
are mostly based on native code so here
that doesn't really is not really

00:18:49.230 --> 00:18:49.240
that doesn't really is not really
 

00:18:49.240 --> 00:18:51.330
that doesn't really is not really
useful for all the things you mentioned

00:18:51.330 --> 00:18:51.340
useful for all the things you mentioned
 

00:18:51.340 --> 00:18:55.740
useful for all the things you mentioned
and the power usage is very similar

00:18:55.740 --> 00:18:55.750
and the power usage is very similar
 

00:18:55.750 --> 00:18:58.260
and the power usage is very similar
whether you're in a OD set a ot setup or

00:18:58.260 --> 00:18:58.270
whether you're in a OD set a ot setup or
 

00:18:58.270 --> 00:19:01.649
whether you're in a OD set a ot setup or
it should set up photos on the other

00:19:01.649 --> 00:19:01.659
it should set up photos on the other
 

00:19:01.659 --> 00:19:04.320
it should set up photos on the other
hand does have to have a code but

00:19:04.320 --> 00:19:04.330
hand does have to have a code but
 

00:19:04.330 --> 00:19:05.519
hand does have to have a code but
doesn't have the behavior that Gmail

00:19:05.519 --> 00:19:05.529
doesn't have the behavior that Gmail
 

00:19:05.529 --> 00:19:07.889
doesn't have the behavior that Gmail
heart and you can see that the

00:19:07.889 --> 00:19:07.899
heart and you can see that the
 

00:19:07.899 --> 00:19:13.529
heart and you can see that the
difference is again very little that was

00:19:13.529 --> 00:19:13.539
difference is again very little that was
 

00:19:13.539 --> 00:19:16.169
difference is again very little that was
battery let's discuss about the final

00:19:16.169 --> 00:19:16.179
battery let's discuss about the final
 

00:19:16.179 --> 00:19:20.639
battery let's discuss about the final
metric memory footprint so we looked at

00:19:20.639 --> 00:19:20.649
metric memory footprint so we looked at
 

00:19:20.649 --> 00:19:22.470
metric memory footprint so we looked at
the overall usage of our beta testers

00:19:22.470 --> 00:19:22.480
the overall usage of our beta testers
 

00:19:22.480 --> 00:19:26.399
the overall usage of our beta testers
within Google and we're quite happy to

00:19:26.399 --> 00:19:26.409
within Google and we're quite happy to
 

00:19:26.409 --> 00:19:28.950
within Google and we're quite happy to
find that the main memory use of the JIT

00:19:28.950 --> 00:19:28.960
find that the main memory use of the JIT
 

00:19:28.960 --> 00:19:32.430
find that the main memory use of the JIT
is failure isn't reasonable the maximum

00:19:32.430 --> 00:19:32.440
is failure isn't reasonable the maximum
 

00:19:32.440 --> 00:19:34.740
is failure isn't reasonable the maximum
we've seen on a heavily loaded system

00:19:34.740 --> 00:19:34.750
we've seen on a heavily loaded system
 

00:19:34.750 --> 00:19:36.450
we've seen on a heavily loaded system
that have lots of application being

00:19:36.450 --> 00:19:36.460
that have lots of application being
 

00:19:36.460 --> 00:19:40.039
that have lots of application being
executed was around 30 megabytes

00:19:40.039 --> 00:19:40.049
executed was around 30 megabytes
 

00:19:40.049 --> 00:19:44.820
executed was around 30 megabytes
system-wide but in average what we've

00:19:44.820 --> 00:19:44.830
system-wide but in average what we've
 

00:19:44.830 --> 00:19:46.230
system-wide but in average what we've
seen is that in some general 10

00:19:46.230 --> 00:19:46.240
seen is that in some general 10
 

00:19:46.240 --> 00:19:50.190
seen is that in some general 10
megabytes for individual applications

00:19:50.190 --> 00:19:50.200
megabytes for individual applications
 

00:19:50.200 --> 00:19:53.669
megabytes for individual applications
big server applications will thanks some

00:19:53.669 --> 00:19:53.679
big server applications will thanks some
 

00:19:53.679 --> 00:19:56.539
big server applications will thanks some
memory like 4 megabytes but in average

00:19:56.539 --> 00:19:56.549
memory like 4 megabytes but in average
 

00:19:56.549 --> 00:19:59.430
memory like 4 megabytes but in average
most applications have a reasonable Java

00:19:59.430 --> 00:19:59.440
most applications have a reasonable Java
 

00:19:59.440 --> 00:20:02.010
most applications have a reasonable Java
code size and the code cache is fairly

00:20:02.010 --> 00:20:02.020
code size and the code cache is fairly
 

00:20:02.020 --> 00:20:07.040
code size and the code cache is fairly
small around 300 kilobytes

00:20:07.040 --> 00:20:07.050
 

00:20:07.050 --> 00:20:12.720
so to wrap up on how it affects these

00:20:12.720 --> 00:20:12.730
so to wrap up on how it affects these
 

00:20:12.730 --> 00:20:15.390
so to wrap up on how it affects these
metrics when you well it's being

00:20:15.390 --> 00:20:15.400
metrics when you well it's being
 

00:20:15.400 --> 00:20:18.330
metrics when you well it's being
executed we've seen that performance and

00:20:18.330 --> 00:20:18.340
executed we've seen that performance and
 

00:20:18.340 --> 00:20:21.600
executed we've seen that performance and
jank are on par with the quality level

00:20:21.600 --> 00:20:21.610
jank are on par with the quality level
 

00:20:21.610 --> 00:20:25.250
jank are on par with the quality level
we had with art ahead of time population

00:20:25.250 --> 00:20:25.260
we had with art ahead of time population
 

00:20:25.260 --> 00:20:28.560
we had with art ahead of time population
and I've shown you that it does have a

00:20:28.560 --> 00:20:28.570
and I've shown you that it does have a
 

00:20:28.570 --> 00:20:31.280
and I've shown you that it does have a
relative impact on application startup

00:20:31.280 --> 00:20:31.290
relative impact on application startup
 

00:20:31.290 --> 00:20:36.750
relative impact on application startup
battery and memory footprint so now I'll

00:20:36.750 --> 00:20:36.760
battery and memory footprint so now I'll
 

00:20:36.760 --> 00:20:38.250
battery and memory footprint so now I'll
be handing it over to my colleague clean

00:20:38.250 --> 00:20:38.260
be handing it over to my colleague clean
 

00:20:38.260 --> 00:20:41.580
be handing it over to my colleague clean
and is going to explain to you how we

00:20:41.580 --> 00:20:41.590
and is going to explain to you how we
 

00:20:41.590 --> 00:20:43.680
and is going to explain to you how we
were covering from those small

00:20:43.680 --> 00:20:43.690
were covering from those small
 

00:20:43.690 --> 00:20:46.350
were covering from those small
regressions compared to äôt by doing a

00:20:46.350 --> 00:20:46.360
regressions compared to äôt by doing a
 

00:20:46.360 --> 00:20:55.520
regressions compared to äôt by doing a
long time profile gallon computation

00:20:55.520 --> 00:20:55.530
 

00:20:55.530 --> 00:20:58.290
Thank You Nicola hello everyone I'm

00:20:58.290 --> 00:20:58.300
Thank You Nicola hello everyone I'm
 

00:20:58.300 --> 00:21:01.260
Thank You Nicola hello everyone I'm
Colleen and I'm here today to give you

00:21:01.260 --> 00:21:01.270
Colleen and I'm here today to give you
 

00:21:01.270 --> 00:21:03.960
Colleen and I'm here today to give you
more details on a profile guided

00:21:03.960 --> 00:21:03.970
more details on a profile guided
 

00:21:03.970 --> 00:21:05.970
more details on a profile guided
compilation and this is a new

00:21:05.970 --> 00:21:05.980
compilation and this is a new
 

00:21:05.980 --> 00:21:07.680
compilation and this is a new
compilation strategy that we introduced

00:21:07.680 --> 00:21:07.690
compilation strategy that we introduced
 

00:21:07.690 --> 00:21:10.260
compilation strategy that we introduced
in M as my colleague Nicola mention is a

00:21:10.260 --> 00:21:10.270
in M as my colleague Nicola mention is a
 

00:21:10.270 --> 00:21:12.210
in M as my colleague Nicola mention is a
combination between GT and ahead-of-time

00:21:12.210 --> 00:21:12.220
combination between GT and ahead-of-time
 

00:21:12.220 --> 00:21:15.780
combination between GT and ahead-of-time
compilation and it's mainly based on the

00:21:15.780 --> 00:21:15.790
compilation and it's mainly based on the
 

00:21:15.790 --> 00:21:17.850
compilation and it's mainly based on the
observation that the percentage of the

00:21:17.850 --> 00:21:17.860
observation that the percentage of the
 

00:21:17.860 --> 00:21:19.800
observation that the percentage of the
applications code which is actually

00:21:19.800 --> 00:21:19.810
applications code which is actually
 

00:21:19.810 --> 00:21:22.050
applications code which is actually
worth optimizing is very small in

00:21:22.050 --> 00:21:22.060
worth optimizing is very small in
 

00:21:22.060 --> 00:21:25.380
worth optimizing is very small in
practice and focusing on the most

00:21:25.380 --> 00:21:25.390
practice and focusing on the most
 

00:21:25.390 --> 00:21:27.300
practice and focusing on the most
important part of the application drives

00:21:27.300 --> 00:21:27.310
important part of the application drives
 

00:21:27.310 --> 00:21:29.190
important part of the application drives
a lot of benefits for the overall system

00:21:29.190 --> 00:21:29.200
a lot of benefits for the overall system
 

00:21:29.200 --> 00:21:32.250
a lot of benefits for the overall system
performance and not only limited to the

00:21:32.250 --> 00:21:32.260
performance and not only limited to the
 

00:21:32.260 --> 00:21:34.830
performance and not only limited to the
trick happening the slight regression

00:21:34.830 --> 00:21:34.840
trick happening the slight regression
 

00:21:34.840 --> 00:21:37.830
trick happening the slight regression
that we'll have to enable his system so

00:21:37.830 --> 00:21:37.840
that we'll have to enable his system so
 

00:21:37.840 --> 00:21:39.750
that we'll have to enable his system so
the goal here was to have a full

00:21:39.750 --> 00:21:39.760
the goal here was to have a full
 

00:21:39.760 --> 00:21:41.970
the goal here was to have a full
five-star system and this is what

00:21:41.970 --> 00:21:41.980
five-star system and this is what
 

00:21:41.980 --> 00:21:43.710
five-star system and this is what
profile guided compilations help us

00:21:43.710 --> 00:21:43.720
profile guided compilations help us
 

00:21:43.720 --> 00:21:46.890
profile guided compilations help us
achieve so let's take a look a bit up on

00:21:46.890 --> 00:21:46.900
achieve so let's take a look a bit up on
 

00:21:46.900 --> 00:21:49.740
achieve so let's take a look a bit up on
the idea in a nutshell we want to

00:21:49.740 --> 00:21:49.750
the idea in a nutshell we want to
 

00:21:49.750 --> 00:21:51.810
the idea in a nutshell we want to
combine execution profiles which were

00:21:51.810 --> 00:21:51.820
combine execution profiles which were
 

00:21:51.820 --> 00:21:53.880
combine execution profiles which were
ahead of time compilation and that will

00:21:53.880 --> 00:21:53.890
ahead of time compilation and that will
 

00:21:53.890 --> 00:21:55.800
ahead of time compilation and that will
lead to a profile guided compilation

00:21:55.800 --> 00:21:55.810
lead to a profile guided compilation
 

00:21:55.810 --> 00:21:58.620
lead to a profile guided compilation
what that means is that during the

00:21:58.620 --> 00:21:58.630
what that means is that during the
 

00:21:58.630 --> 00:22:01.290
what that means is that during the
application execution report profile

00:22:01.290 --> 00:22:01.300
application execution report profile
 

00:22:01.300 --> 00:22:03.330
application execution report profile
information about how the app is

00:22:03.330 --> 00:22:03.340
information about how the app is
 

00:22:03.340 --> 00:22:05.910
information about how the app is
executed and we use that information to

00:22:05.910 --> 00:22:05.920
executed and we use that information to
 

00:22:05.920 --> 00:22:08.160
executed and we use that information to
drive offline optimizations at a time

00:22:08.160 --> 00:22:08.170
drive offline optimizations at a time
 

00:22:08.170 --> 00:22:09.990
drive offline optimizations at a time
when the device is charging and idling

00:22:09.990 --> 00:22:10.000
when the device is charging and idling
 

00:22:10.000 --> 00:22:11.490
when the device is charging and idling
so that they don't take resources out of

00:22:11.490 --> 00:22:11.500
so that they don't take resources out of
 

00:22:11.500 --> 00:22:17.500
so that they don't take resources out of
our users

00:22:17.500 --> 00:22:17.510
 

00:22:17.510 --> 00:22:20.120
so let's take a look in into more

00:22:20.120 --> 00:22:20.130
so let's take a look in into more
 

00:22:20.130 --> 00:22:22.400
so let's take a look in into more
details how this works how it affects

00:22:22.400 --> 00:22:22.410
details how this works how it affects
 

00:22:22.410 --> 00:22:24.020
details how this works how it affects
the life cycle of the application and

00:22:24.020 --> 00:22:24.030
the life cycle of the application and
 

00:22:24.030 --> 00:22:26.630
the life cycle of the application and
how it fits together in the jeat system

00:22:26.630 --> 00:22:26.640
how it fits together in the jeat system
 

00:22:26.640 --> 00:22:30.020
how it fits together in the jeat system
that my colleague talked about the first

00:22:30.020 --> 00:22:30.030
that my colleague talked about the first
 

00:22:30.030 --> 00:22:32.480
that my colleague talked about the first
time the application is executed the

00:22:32.480 --> 00:22:32.490
time the application is executed the
 

00:22:32.490 --> 00:22:35.330
time the application is executed the
runtime will interpret it the JIT system

00:22:35.330 --> 00:22:35.340
runtime will interpret it the JIT system
 

00:22:35.340 --> 00:22:36.920
runtime will interpret it the JIT system
will kick in and optimize the hot

00:22:36.920 --> 00:22:36.930
will kick in and optimize the hot
 

00:22:36.930 --> 00:22:39.860
will kick in and optimize the hot
methods and eventually disciple will

00:22:39.860 --> 00:22:39.870
methods and eventually disciple will
 

00:22:39.870 --> 00:22:42.500
methods and eventually disciple will
repeat in parallel with the

00:22:42.500 --> 00:22:42.510
repeat in parallel with the
 

00:22:42.510 --> 00:22:43.700
repeat in parallel with the
interpretation and if the JIT

00:22:43.700 --> 00:22:43.710
interpretation and if the JIT
 

00:22:43.710 --> 00:22:45.980
interpretation and if the JIT
compilation we record the profile

00:22:45.980 --> 00:22:45.990
compilation we record the profile
 

00:22:45.990 --> 00:22:48.380
compilation we record the profile
information and this profile information

00:22:48.380 --> 00:22:48.390
information and this profile information
 

00:22:48.390 --> 00:22:51.200
information and this profile information
gets dumped to disk at regular interval

00:22:51.200 --> 00:22:51.210
gets dumped to disk at regular interval
 

00:22:51.210 --> 00:22:53.690
gets dumped to disk at regular interval
of time the next time that we execute

00:22:53.690 --> 00:22:53.700
of time the next time that we execute
 

00:22:53.700 --> 00:22:55.730
of time the next time that we execute
the app the same process starts again

00:22:55.730 --> 00:22:55.740
the app the same process starts again
 

00:22:55.740 --> 00:22:58.190
the app the same process starts again
and the profile files will eventually be

00:22:58.190 --> 00:22:58.200
and the profile files will eventually be
 

00:22:58.200 --> 00:23:00.950
and the profile files will eventually be
expanded if new use cases based on the

00:23:00.950 --> 00:23:00.960
expanded if new use cases based on the
 

00:23:00.960 --> 00:23:04.220
expanded if new use cases based on the
how the user used the app but the later

00:23:04.220 --> 00:23:04.230
how the user used the app but the later
 

00:23:04.230 --> 00:23:06.890
how the user used the app but the later
point when they use the device is not in

00:23:06.890 --> 00:23:06.900
point when they use the device is not in
 

00:23:06.900 --> 00:23:09.140
point when they use the device is not in
use anymore it's idling and charging and

00:23:09.140 --> 00:23:09.150
use anymore it's idling and charging and
 

00:23:09.150 --> 00:23:10.850
use anymore it's idling and charging and
at the state that we called maintenance

00:23:10.850 --> 00:23:10.860
at the state that we called maintenance
 

00:23:10.860 --> 00:23:13.460
at the state that we called maintenance
mode we kick in the service and what his

00:23:13.460 --> 00:23:13.470
mode we kick in the service and what his
 

00:23:13.470 --> 00:23:15.440
mode we kick in the service and what his
service does it takes a look at the

00:23:15.440 --> 00:23:15.450
service does it takes a look at the
 

00:23:15.450 --> 00:23:16.190
service does it takes a look at the
application

00:23:16.190 --> 00:23:16.200
application
 

00:23:16.200 --> 00:23:18.620
application
it looks at the profiles and it tries to

00:23:18.620 --> 00:23:18.630
it looks at the profiles and it tries to
 

00:23:18.630 --> 00:23:20.570
it looks at the profiles and it tries to
optimize the application based on its

00:23:20.570 --> 00:23:20.580
optimize the application based on its
 

00:23:20.580 --> 00:23:23.360
optimize the application based on its
use the output of the service is

00:23:23.360 --> 00:23:23.370
use the output of the service is
 

00:23:23.370 --> 00:23:26.090
use the output of the service is
actually a compiled binary and this

00:23:26.090 --> 00:23:26.100
actually a compiled binary and this
 

00:23:26.100 --> 00:23:28.160
actually a compiled binary and this
compiled binary will replace the initial

00:23:28.160 --> 00:23:28.170
compiled binary will replace the initial
 

00:23:28.170 --> 00:23:31.820
compiled binary will replace the initial
application in the system so now the

00:23:31.820 --> 00:23:31.830
application in the system so now the
 

00:23:31.830 --> 00:23:33.260
application in the system so now the
next time the application is launched

00:23:33.260 --> 00:23:33.270
next time the application is launched
 

00:23:33.270 --> 00:23:35.800
next time the application is launched
after this service will execute it the

00:23:35.800 --> 00:23:35.810
after this service will execute it the
 

00:23:35.810 --> 00:23:38.060
after this service will execute it the
application will contain different codes

00:23:38.060 --> 00:23:38.070
application will contain different codes
 

00:23:38.070 --> 00:23:40.850
application will contain different codes
different states of the same code so it

00:23:40.850 --> 00:23:40.860
different states of the same code so it
 

00:23:40.860 --> 00:23:42.560
different states of the same code so it
you may have code which is interpreted

00:23:42.560 --> 00:23:42.570
you may have code which is interpreted
 

00:23:42.570 --> 00:23:45.020
you may have code which is interpreted
and eventually be cheated and you also

00:23:45.020 --> 00:23:45.030
and eventually be cheated and you also
 

00:23:45.030 --> 00:23:46.370
and eventually be cheated and you also
have code which is ahead of time

00:23:46.370 --> 00:23:46.380
have code which is ahead of time
 

00:23:46.380 --> 00:23:50.630
have code which is ahead of time
compiled if the user for example uses a

00:23:50.630 --> 00:23:50.640
compiled if the user for example uses a
 

00:23:50.640 --> 00:23:52.310
compiled if the user for example uses a
new part of the application that haven't

00:23:52.310 --> 00:23:52.320
new part of the application that haven't
 

00:23:52.320 --> 00:23:54.920
new part of the application that haven't
been explored before that part will be

00:23:54.920 --> 00:23:54.930
been explored before that part will be
 

00:23:54.930 --> 00:23:56.450
been explored before that part will be
interpreted in GTD and will generate a

00:23:56.450 --> 00:23:56.460
interpreted in GTD and will generate a
 

00:23:56.460 --> 00:23:58.580
interpreted in GTD and will generate a
new profile information and so the cycle

00:23:58.580 --> 00:23:58.590
new profile information and so the cycle
 

00:23:58.590 --> 00:24:01.970
new profile information and so the cycle
begins again so what's important here is

00:24:01.970 --> 00:24:01.980
begins again so what's important here is
 

00:24:01.980 --> 00:24:04.670
begins again so what's important here is
will improve the application performance

00:24:04.670 --> 00:24:04.680
will improve the application performance
 

00:24:04.680 --> 00:24:07.430
will improve the application performance
as the user executes ative new use cases

00:24:07.430 --> 00:24:07.440
as the user executes ative new use cases
 

00:24:07.440 --> 00:24:10.040
as the user executes ative new use cases
and we'll keep recompile it until we

00:24:10.040 --> 00:24:10.050
and we'll keep recompile it until we
 

00:24:10.050 --> 00:24:16.130
and we'll keep recompile it until we
discover all possible cases so let's

00:24:16.130 --> 00:24:16.140
discover all possible cases so let's
 

00:24:16.140 --> 00:24:18.080
discover all possible cases so let's
focus a bit on the profile collection

00:24:18.080 --> 00:24:18.090
focus a bit on the profile collection
 

00:24:18.090 --> 00:24:20.050
focus a bit on the profile collection
and how that impacts there our

00:24:20.050 --> 00:24:20.060
and how that impacts there our
 

00:24:20.060 --> 00:24:21.830
and how that impacts there our
application performance and other

00:24:21.830 --> 00:24:21.840
application performance and other
 

00:24:21.840 --> 00:24:24.920
application performance and other
factors

00:24:24.920 --> 00:24:24.930
 

00:24:24.930 --> 00:24:27.140
as I mentioned we do collect them in

00:24:27.140 --> 00:24:27.150
as I mentioned we do collect them in
 

00:24:27.150 --> 00:24:28.250
as I mentioned we do collect them in
parallel with the application

00:24:28.250 --> 00:24:28.260
parallel with the application
 

00:24:28.260 --> 00:24:31.010
parallel with the application
institution and what we focused on to

00:24:31.010 --> 00:24:31.020
institution and what we focused on to
 

00:24:31.020 --> 00:24:33.470
institution and what we focused on to
make sure that it has the minimal impact

00:24:33.470 --> 00:24:33.480
make sure that it has the minimal impact
 

00:24:33.480 --> 00:24:37.100
make sure that it has the minimal impact
on the performance then one factor that

00:24:37.100 --> 00:24:37.110
on the performance then one factor that
 

00:24:37.110 --> 00:24:39.830
on the performance then one factor that
we put a lot of attention into is to

00:24:39.830 --> 00:24:39.840
we put a lot of attention into is to
 

00:24:39.840 --> 00:24:41.780
we put a lot of attention into is to
have an efficient caching and I'll

00:24:41.780 --> 00:24:41.790
have an efficient caching and I'll
 

00:24:41.790 --> 00:24:44.330
have an efficient caching and I'll
totaling so that we minimize the write

00:24:44.330 --> 00:24:44.340
totaling so that we minimize the write
 

00:24:44.340 --> 00:24:48.020
totaling so that we minimize the write
operation to disk we also have a very

00:24:48.020 --> 00:24:48.030
operation to disk we also have a very
 

00:24:48.030 --> 00:24:50.420
operation to disk we also have a very
small file footprint and the amount of

00:24:50.420 --> 00:24:50.430
small file footprint and the amount of
 

00:24:50.430 --> 00:24:52.070
small file footprint and the amount of
data that we write to disk is actually

00:24:52.070 --> 00:24:52.080
data that we write to disk is actually
 

00:24:52.080 --> 00:24:56.630
data that we write to disk is actually
very very small another point which I

00:24:56.630 --> 00:24:56.640
very very small another point which I
 

00:24:56.640 --> 00:24:59.060
very very small another point which I
mentioned before is that they keep

00:24:59.060 --> 00:24:59.070
mentioned before is that they keep
 

00:24:59.070 --> 00:25:01.160
mentioned before is that they keep
expanding these profiles as the app

00:25:01.160 --> 00:25:01.170
expanding these profiles as the app
 

00:25:01.170 --> 00:25:05.210
expanding these profiles as the app
executes and obviously it depends on the

00:25:05.210 --> 00:25:05.220
executes and obviously it depends on the
 

00:25:05.220 --> 00:25:05.810
executes and obviously it depends on the
application

00:25:05.810 --> 00:25:05.820
application
 

00:25:05.820 --> 00:25:08.810
application
it depends on the use case our test

00:25:08.810 --> 00:25:08.820
it depends on the use case our test
 

00:25:08.820 --> 00:25:10.610
it depends on the use case our test
shows that the largest part of the data

00:25:10.610 --> 00:25:10.620
shows that the largest part of the data
 

00:25:10.620 --> 00:25:12.380
shows that the largest part of the data
is actually captured during the first

00:25:12.380 --> 00:25:12.390
is actually captured during the first
 

00:25:12.390 --> 00:25:13.360
is actually captured during the first
run

00:25:13.360 --> 00:25:13.370
run
 

00:25:13.370 --> 00:25:15.680
run
subsequent runs add the profile

00:25:15.680 --> 00:25:15.690
subsequent runs add the profile
 

00:25:15.690 --> 00:25:17.600
subsequent runs add the profile
information it obviously depends how the

00:25:17.600 --> 00:25:17.610
information it obviously depends how the
 

00:25:17.610 --> 00:25:20.390
information it obviously depends how the
user used the app but the largest chunk

00:25:20.390 --> 00:25:20.400
user used the app but the largest chunk
 

00:25:20.400 --> 00:25:22.460
user used the app but the largest chunk
of the information is actually captured

00:25:22.460 --> 00:25:22.470
of the information is actually captured
 

00:25:22.470 --> 00:25:24.650
of the information is actually captured
in the first execution and yet that

00:25:24.650 --> 00:25:24.660
in the first execution and yet that
 

00:25:24.660 --> 00:25:29.900
in the first execution and yet that
gives us important data to work on the

00:25:29.900 --> 00:25:29.910
gives us important data to work on the
 

00:25:29.910 --> 00:25:31.310
gives us important data to work on the
final point which is worth mentioning

00:25:31.310 --> 00:25:31.320
final point which is worth mentioning
 

00:25:31.320 --> 00:25:33.380
final point which is worth mentioning
here is that all the application all the

00:25:33.380 --> 00:25:33.390
here is that all the application all the
 

00:25:33.390 --> 00:25:39.200
here is that all the application all the
users get their own profiles and if that

00:25:39.200 --> 00:25:39.210
users get their own profiles and if that
 

00:25:39.210 --> 00:25:40.370
users get their own profiles and if that
in mind let's take a look on what

00:25:40.370 --> 00:25:40.380
in mind let's take a look on what
 

00:25:40.380 --> 00:25:42.320
in mind let's take a look on what
exactly we record in this profile

00:25:42.320 --> 00:25:42.330
exactly we record in this profile
 

00:25:42.330 --> 00:25:43.690
exactly we record in this profile
information

00:25:43.690 --> 00:25:43.700
information
 

00:25:43.700 --> 00:25:46.880
information
the first thing are the hot methods and

00:25:46.880 --> 00:25:46.890
the first thing are the hot methods and
 

00:25:46.890 --> 00:25:49.490
the first thing are the hot methods and
what constitutes a hot method it's a

00:25:49.490 --> 00:25:49.500
what constitutes a hot method it's a
 

00:25:49.500 --> 00:25:51.050
what constitutes a hot method it's a
metric which you have internal to your

00:25:51.050 --> 00:25:51.060
metric which you have internal to your
 

00:25:51.060 --> 00:25:53.450
metric which you have internal to your
runtime and factors that contribute to

00:25:53.450 --> 00:25:53.460
runtime and factors that contribute to
 

00:25:53.460 --> 00:25:55.670
runtime and factors that contribute to
it are for example number of invocations

00:25:55.670 --> 00:25:55.680
it are for example number of invocations
 

00:25:55.680 --> 00:25:57.500
it are for example number of invocations
or whether or not that method is

00:25:57.500 --> 00:25:57.510
or whether or not that method is
 

00:25:57.510 --> 00:25:59.570
or whether or not that method is
executed on the UI thread so that you

00:25:59.570 --> 00:25:59.580
executed on the UI thread so that you
 

00:25:59.580 --> 00:26:01.190
executed on the UI thread so that you
can speed up requests that will impact

00:26:01.190 --> 00:26:01.200
can speed up requests that will impact
 

00:26:01.200 --> 00:26:03.530
can speed up requests that will impact
the users directly we use this

00:26:03.530 --> 00:26:03.540
the users directly we use this
 

00:26:03.540 --> 00:26:04.970
the users directly we use this
information to drive offline

00:26:04.970 --> 00:26:04.980
information to drive offline
 

00:26:04.980 --> 00:26:06.830
information to drive offline
optimizations and to dedicate more time

00:26:06.830 --> 00:26:06.840
optimizations and to dedicate more time
 

00:26:06.840 --> 00:26:11.350
optimizations and to dedicate more time
to optimize those methods the second

00:26:11.350 --> 00:26:11.360
to optimize those methods the second
 

00:26:11.360 --> 00:26:14.750
to optimize those methods the second
data that we record are the classes

00:26:14.750 --> 00:26:14.760
data that we record are the classes
 

00:26:14.760 --> 00:26:17.600
data that we record are the classes
which impact the startup times how do we

00:26:17.600 --> 00:26:17.610
which impact the startup times how do we
 

00:26:17.610 --> 00:26:19.700
which impact the startup times how do we
know they do so it means that they are

00:26:19.700 --> 00:26:19.710
know they do so it means that they are
 

00:26:19.710 --> 00:26:21.350
know they do so it means that they are
loaded in the first few seconds after

00:26:21.350 --> 00:26:21.360
loaded in the first few seconds after
 

00:26:21.360 --> 00:26:23.750
loaded in the first few seconds after
the user launch data and my colleague

00:26:23.750 --> 00:26:23.760
the user launch data and my colleague
 

00:26:23.760 --> 00:26:26.210
the user launch data and my colleague
Matthew will go into more details on how

00:26:26.210 --> 00:26:26.220
Matthew will go into more details on how
 

00:26:26.220 --> 00:26:28.190
Matthew will go into more details on how
we use that we improve startup times

00:26:28.190 --> 00:26:28.200
we use that we improve startup times
 

00:26:28.200 --> 00:26:31.790
we use that we improve startup times
even more a final piece of information

00:26:31.790 --> 00:26:31.800
even more a final piece of information
 

00:26:31.800 --> 00:26:33.920
even more a final piece of information
that we record is whether or not the

00:26:33.920 --> 00:26:33.930
that we record is whether or not the
 

00:26:33.930 --> 00:26:36.050
that we record is whether or not the
application code is loaded in some other

00:26:36.050 --> 00:26:36.060
application code is loaded in some other
 

00:26:36.060 --> 00:26:37.370
application code is loaded in some other
apps

00:26:37.370 --> 00:26:37.380
apps
 

00:26:37.380 --> 00:26:38.720
apps
and that's very important to know

00:26:38.720 --> 00:26:38.730
and that's very important to know
 

00:26:38.730 --> 00:26:40.280
and that's very important to know
because it means that the application

00:26:40.280 --> 00:26:40.290
because it means that the application
 

00:26:40.290 --> 00:26:42.820
because it means that the application
behaves more like a shared library and

00:26:42.820 --> 00:26:42.830
behaves more like a shared library and
 

00:26:42.830 --> 00:26:45.530
behaves more like a shared library and
when it does so we'll use a different

00:26:45.530 --> 00:26:45.540
when it does so we'll use a different
 

00:26:45.540 --> 00:26:50.660
when it does so we'll use a different
completion strategy to optimize it so

00:26:50.660 --> 00:26:50.670
completion strategy to optimize it so
 

00:26:50.670 --> 00:26:53.600
completion strategy to optimize it so
let's focus now on the compilation

00:26:53.600 --> 00:26:53.610
let's focus now on the compilation
 

00:26:53.610 --> 00:26:55.970
let's focus now on the compilation
daemon on the service that actually does

00:26:55.970 --> 00:26:55.980
daemon on the service that actually does
 

00:26:55.980 --> 00:26:58.550
daemon on the service that actually does
the compilation and let's take a look on

00:26:58.550 --> 00:26:58.560
the compilation and let's take a look on
 

00:26:58.560 --> 00:27:01.520
the compilation and let's take a look on
what decision makes this is a service

00:27:01.520 --> 00:27:01.530
what decision makes this is a service
 

00:27:01.530 --> 00:27:03.260
what decision makes this is a service
which is started at boot time by the

00:27:03.260 --> 00:27:03.270
which is started at boot time by the
 

00:27:03.270 --> 00:27:06.050
which is started at boot time by the
system and is scheduled for daily daily

00:27:06.050 --> 00:27:06.060
system and is scheduled for daily daily
 

00:27:06.060 --> 00:27:09.080
system and is scheduled for daily daily
run its main job is to iterate to all

00:27:09.080 --> 00:27:09.090
run its main job is to iterate to all
 

00:27:09.090 --> 00:27:11.000
run its main job is to iterate to all
the apks install in the system and

00:27:11.000 --> 00:27:11.010
the apks install in the system and
 

00:27:11.010 --> 00:27:13.430
the apks install in the system and
figure out whether or not we need to

00:27:13.430 --> 00:27:13.440
figure out whether or not we need to
 

00:27:13.440 --> 00:27:15.260
figure out whether or not we need to
compile them and if we do need to

00:27:15.260 --> 00:27:15.270
compile them and if we do need to
 

00:27:15.270 --> 00:27:17.030
compile them and if we do need to
compile them what sort of strategy we

00:27:17.030 --> 00:27:17.040
compile them what sort of strategy we
 

00:27:17.040 --> 00:27:21.020
compile them what sort of strategy we
should use the service wakes up when the

00:27:21.020 --> 00:27:21.030
should use the service wakes up when the
 

00:27:21.030 --> 00:27:22.880
should use the service wakes up when the
device becomes idle in charging and the

00:27:22.880 --> 00:27:22.890
device becomes idle in charging and the
 

00:27:22.890 --> 00:27:25.100
device becomes idle in charging and the
main reason for that is that we don't

00:27:25.100 --> 00:27:25.110
main reason for that is that we don't
 

00:27:25.110 --> 00:27:29.390
main reason for that is that we don't
want to use user time when the device is

00:27:29.390 --> 00:27:29.400
want to use user time when the device is
 

00:27:29.400 --> 00:27:30.710
want to use user time when the device is
active and we don't want to waste

00:27:30.710 --> 00:27:30.720
active and we don't want to waste
 

00:27:30.720 --> 00:27:33.170
active and we don't want to waste
battery time so it delayed this until

00:27:33.170 --> 00:27:33.180
battery time so it delayed this until
 

00:27:33.180 --> 00:27:35.180
battery time so it delayed this until
the user the device is not in used

00:27:35.180 --> 00:27:35.190
the user the device is not in used
 

00:27:35.190 --> 00:27:38.330
the user the device is not in used
anymore when the daemon wakes up what it

00:27:38.330 --> 00:27:38.340
anymore when the daemon wakes up what it
 

00:27:38.340 --> 00:27:40.010
anymore when the daemon wakes up what it
does it iterates with the applications

00:27:40.010 --> 00:27:40.020
does it iterates with the applications
 

00:27:40.020 --> 00:27:41.750
does it iterates with the applications
and the first questions it asks is

00:27:41.750 --> 00:27:41.760
and the first questions it asks is
 

00:27:41.760 --> 00:27:43.910
and the first questions it asks is
whether or not the application code has

00:27:43.910 --> 00:27:43.920
whether or not the application code has
 

00:27:43.920 --> 00:27:45.770
whether or not the application code has
been used by some other apps that data

00:27:45.770 --> 00:27:45.780
been used by some other apps that data
 

00:27:45.780 --> 00:27:47.330
been used by some other apps that data
that I was telling you that we report in

00:27:47.330 --> 00:27:47.340
that I was telling you that we report in
 

00:27:47.340 --> 00:27:49.880
that I was telling you that we report in
the profile if that's the case then we

00:27:49.880 --> 00:27:49.890
the profile if that's the case then we
 

00:27:49.890 --> 00:27:51.680
the profile if that's the case then we
perform a full compilation to make sure

00:27:51.680 --> 00:27:51.690
perform a full compilation to make sure
 

00:27:51.690 --> 00:27:53.390
perform a full compilation to make sure
that all the users benefit of the

00:27:53.390 --> 00:27:53.400
that all the users benefit of the
 

00:27:53.400 --> 00:27:57.080
that all the users benefit of the
optimized code if it's not and this is

00:27:57.080 --> 00:27:57.090
optimized code if it's not and this is
 

00:27:57.090 --> 00:27:58.970
optimized code if it's not and this is
the case probably for the largest

00:27:58.970 --> 00:27:58.980
the case probably for the largest
 

00:27:58.980 --> 00:28:00.920
the case probably for the largest
percentage of the apps it's a regular

00:28:00.920 --> 00:28:00.930
percentage of the apps it's a regular
 

00:28:00.930 --> 00:28:02.480
percentage of the apps it's a regular
app you don't get used by some other

00:28:02.480 --> 00:28:02.490
app you don't get used by some other
 

00:28:02.490 --> 00:28:05.570
app you don't get used by some other
apps we go into and perform a much

00:28:05.570 --> 00:28:05.580
apps we go into and perform a much
 

00:28:05.580 --> 00:28:07.100
apps we go into and perform a much
deeper analysis on the profile

00:28:07.100 --> 00:28:07.110
deeper analysis on the profile
 

00:28:07.110 --> 00:28:10.160
deeper analysis on the profile
information if we have enough new data

00:28:10.160 --> 00:28:10.170
information if we have enough new data
 

00:28:10.170 --> 00:28:12.230
information if we have enough new data
if we collected enough information about

00:28:12.230 --> 00:28:12.240
if we collected enough information about
 

00:28:12.240 --> 00:28:14.900
if we collected enough information about
the application then we'll profile a

00:28:14.900 --> 00:28:14.910
the application then we'll profile a
 

00:28:14.910 --> 00:28:17.090
the application then we'll profile a
guide compile that application we'll

00:28:17.090 --> 00:28:17.100
guide compile that application we'll
 

00:28:17.100 --> 00:28:18.530
guide compile that application we'll
take a look at the profiles and you

00:28:18.530 --> 00:28:18.540
take a look at the profiles and you
 

00:28:18.540 --> 00:28:20.390
take a look at the profiles and you
optimize only the methods that were

00:28:20.390 --> 00:28:20.400
optimize only the methods that were
 

00:28:20.400 --> 00:28:22.490
optimize only the methods that were
executed so that we focus on what

00:28:22.490 --> 00:28:22.500
executed so that we focus on what
 

00:28:22.500 --> 00:28:24.260
executed so that we focus on what
actually the user used from that

00:28:24.260 --> 00:28:24.270
actually the user used from that
 

00:28:24.270 --> 00:28:27.410
actually the user used from that
application if by any chance we don't

00:28:27.410 --> 00:28:27.420
application if by any chance we don't
 

00:28:27.420 --> 00:28:28.850
application if by any chance we don't
have enough information let's say you

00:28:28.850 --> 00:28:28.860
have enough information let's say you
 

00:28:28.860 --> 00:28:31.730
have enough information let's say you
only know data we only have data about

00:28:31.730 --> 00:28:31.740
only know data we only have data about
 

00:28:31.740 --> 00:28:33.710
only know data we only have data about
one single method from the top then

00:28:33.710 --> 00:28:33.720
one single method from the top then
 

00:28:33.720 --> 00:28:35.060
one single method from the top then
we'll just keep it because probably is

00:28:35.060 --> 00:28:35.070
we'll just keep it because probably is
 

00:28:35.070 --> 00:28:38.270
we'll just keep it because probably is
not worth optimizing and an important

00:28:38.270 --> 00:28:38.280
not worth optimizing and an important
 

00:28:38.280 --> 00:28:40.910
not worth optimizing and an important
thing here is that we do perform the

00:28:40.910 --> 00:28:40.920
thing here is that we do perform the
 

00:28:40.920 --> 00:28:43.160
thing here is that we do perform the
profile analysis every time that we run

00:28:43.160 --> 00:28:43.170
profile analysis every time that we run
 

00:28:43.170 --> 00:28:45.440
profile analysis every time that we run
the demo and that what it means that we

00:28:45.440 --> 00:28:45.450
the demo and that what it means that we
 

00:28:45.450 --> 00:28:47.690
the demo and that what it means that we
might end up recompile the app again and

00:28:47.690 --> 00:28:47.700
might end up recompile the app again and
 

00:28:47.700 --> 00:28:48.280
might end up recompile the app again and
again

00:28:48.280 --> 00:28:48.290
again
 

00:28:48.290 --> 00:28:50.470
again
we no longer have any new information

00:28:50.470 --> 00:28:50.480
we no longer have any new information
 

00:28:50.480 --> 00:28:53.290
we no longer have any new information
about it and here you can see that

00:28:53.290 --> 00:28:53.300
about it and here you can see that
 

00:28:53.300 --> 00:28:54.760
about it and here you can see that
actually I was talking about different

00:28:54.760 --> 00:28:54.770
actually I was talking about different
 

00:28:54.770 --> 00:28:56.560
actually I was talking about different
use cases and how we apply different

00:28:56.560 --> 00:28:56.570
use cases and how we apply different
 

00:28:56.570 --> 00:28:59.650
use cases and how we apply different
completion strategies shared up shared

00:28:59.650 --> 00:28:59.660
completion strategies shared up shared
 

00:28:59.660 --> 00:29:01.510
completion strategies shared up shared
libraries get a full compilation whereas

00:29:01.510 --> 00:29:01.520
libraries get a full compilation whereas
 

00:29:01.520 --> 00:29:04.000
libraries get a full compilation whereas
the regular apps prefer a profile guided

00:29:04.000 --> 00:29:04.010
the regular apps prefer a profile guided
 

00:29:04.010 --> 00:29:07.570
the regular apps prefer a profile guided
compilation in em we generalized on that

00:29:07.570 --> 00:29:07.580
compilation in em we generalized on that
 

00:29:07.580 --> 00:29:09.850
compilation in em we generalized on that
and different use cases from the life

00:29:09.850 --> 00:29:09.860
and different use cases from the life
 

00:29:09.860 --> 00:29:12.280
and different use cases from the life
cycle of the application have different

00:29:12.280 --> 00:29:12.290
cycle of the application have different
 

00:29:12.290 --> 00:29:15.040
cycle of the application have different
compilation strategies for example it

00:29:15.040 --> 00:29:15.050
compilation strategies for example it
 

00:29:15.050 --> 00:29:17.050
compilation strategies for example it
install time we don't have profile

00:29:17.050 --> 00:29:17.060
install time we don't have profile
 

00:29:17.060 --> 00:29:18.940
install time we don't have profile
information yet we still want the

00:29:18.940 --> 00:29:18.950
information yet we still want the
 

00:29:18.950 --> 00:29:21.010
information yet we still want the
application to start as fast as possible

00:29:21.010 --> 00:29:21.020
application to start as fast as possible
 

00:29:21.020 --> 00:29:23.470
application to start as fast as possible
and as my colleague Nicola mentioned we

00:29:23.470 --> 00:29:23.480
and as my colleague Nicola mentioned we
 

00:29:23.480 --> 00:29:25.180
and as my colleague Nicola mentioned we
have a strategy where we extract and

00:29:25.180 --> 00:29:25.190
have a strategy where we extract and
 

00:29:25.190 --> 00:29:28.030
have a strategy where we extract and
verify that app with minimal running

00:29:28.030 --> 00:29:28.040
verify that app with minimal running
 

00:29:28.040 --> 00:29:30.100
verify that app with minimal running
time and which will ensure that the

00:29:30.100 --> 00:29:30.110
time and which will ensure that the
 

00:29:30.110 --> 00:29:32.020
time and which will ensure that the
application starts fast when you update

00:29:32.020 --> 00:29:32.030
application starts fast when you update
 

00:29:32.030 --> 00:29:34.750
application starts fast when you update
the app we had the same story we no

00:29:34.750 --> 00:29:34.760
the app we had the same story we no
 

00:29:34.760 --> 00:29:36.520
the app we had the same story we no
longer have a profile because what I

00:29:36.520 --> 00:29:36.530
longer have a profile because what I
 

00:29:36.530 --> 00:29:38.260
longer have a profile because what I
reported before was invalid

00:29:38.260 --> 00:29:38.270
reported before was invalid
 

00:29:38.270 --> 00:29:41.310
reported before was invalid
so we repeat this verification procedure

00:29:41.310 --> 00:29:41.320
so we repeat this verification procedure
 

00:29:41.320 --> 00:29:43.630
so we repeat this verification procedure
when the completion daemon kicks in

00:29:43.630 --> 00:29:43.640
when the completion daemon kicks in
 

00:29:43.640 --> 00:29:46.200
when the completion daemon kicks in
we'll do a profile guided compilation

00:29:46.200 --> 00:29:46.210
we'll do a profile guided compilation
 

00:29:46.210 --> 00:29:49.150
we'll do a profile guided compilation
where possible therefore and for system

00:29:49.150 --> 00:29:49.160
where possible therefore and for system
 

00:29:49.160 --> 00:29:50.680
where possible therefore and for system
and shared libraries we're going to do a

00:29:50.680 --> 00:29:50.690
and shared libraries we're going to do a
 

00:29:50.690 --> 00:29:52.480
and shared libraries we're going to do a
full compilation so that we make sure

00:29:52.480 --> 00:29:52.490
full compilation so that we make sure
 

00:29:52.490 --> 00:29:54.640
full compilation so that we make sure
that all their users are properly

00:29:54.640 --> 00:29:54.650
that all their users are properly
 

00:29:54.650 --> 00:29:59.110
that all their users are properly
optimized with that in mind let's take a

00:29:59.110 --> 00:29:59.120
optimized with that in mind let's take a
 

00:29:59.120 --> 00:30:01.930
optimized with that in mind let's take a
more closer look on what benefits are if

00:30:01.930 --> 00:30:01.940
more closer look on what benefits are if
 

00:30:01.940 --> 00:30:03.970
more closer look on what benefits are if
when we do profile guided compilation

00:30:03.970 --> 00:30:03.980
when we do profile guided compilation
 

00:30:03.980 --> 00:30:06.520
when we do profile guided compilation
and all the benefits shared the same

00:30:06.520 --> 00:30:06.530
and all the benefits shared the same
 

00:30:06.530 --> 00:30:08.860
and all the benefits shared the same
root cause we only optimize what is

00:30:08.860 --> 00:30:08.870
root cause we only optimize what is
 

00:30:08.870 --> 00:30:12.820
root cause we only optimize what is
being used and what it means when you

00:30:12.820 --> 00:30:12.830
being used and what it means when you
 

00:30:12.830 --> 00:30:14.980
being used and what it means when you
first start the app after the

00:30:14.980 --> 00:30:14.990
first start the app after the
 

00:30:14.990 --> 00:30:16.960
first start the app after the
compilation happened previous hot code

00:30:16.960 --> 00:30:16.970
compilation happened previous hot code
 

00:30:16.970 --> 00:30:19.300
compilation happened previous hot code
is already optimized we no longer have

00:30:19.300 --> 00:30:19.310
is already optimized we no longer have
 

00:30:19.310 --> 00:30:21.340
is already optimized we no longer have
to wait for the JIT for the matters to

00:30:21.340 --> 00:30:21.350
to wait for the JIT for the matters to
 

00:30:21.350 --> 00:30:23.860
to wait for the JIT for the matters to
become hot so the digit can compile them

00:30:23.860 --> 00:30:23.870
become hot so the digit can compile them
 

00:30:23.870 --> 00:30:26.320
become hot so the digit can compile them
so the applications will start faster

00:30:26.320 --> 00:30:26.330
so the applications will start faster
 

00:30:26.330 --> 00:30:28.600
so the applications will start faster
we have also less work for the JIT and

00:30:28.600 --> 00:30:28.610
we have also less work for the JIT and
 

00:30:28.610 --> 00:30:31.270
we have also less work for the JIT and
that means we use less CPU and we

00:30:31.270 --> 00:30:31.280
that means we use less CPU and we
 

00:30:31.280 --> 00:30:33.360
that means we use less CPU and we
increase the battery life overall and

00:30:33.360 --> 00:30:33.370
increase the battery life overall and
 

00:30:33.370 --> 00:30:35.950
increase the battery life overall and
because we are much more selective with

00:30:35.950 --> 00:30:35.960
because we are much more selective with
 

00:30:35.960 --> 00:30:39.100
because we are much more selective with
what we optimize we can dedicate and

00:30:39.100 --> 00:30:39.110
what we optimize we can dedicate and
 

00:30:39.110 --> 00:30:41.020
what we optimize we can dedicate and
spend more time there and apply more

00:30:41.020 --> 00:30:41.030
spend more time there and apply more
 

00:30:41.030 --> 00:30:43.110
spend more time there and apply more
optimizations

00:30:43.110 --> 00:30:43.120
optimizations
 

00:30:43.120 --> 00:30:46.270
optimizations
besides that we get a smaller size for

00:30:46.270 --> 00:30:46.280
besides that we get a smaller size for
 

00:30:46.280 --> 00:30:48.970
besides that we get a smaller size for
the compiled binary and that's a very

00:30:48.970 --> 00:30:48.980
the compiled binary and that's a very
 

00:30:48.980 --> 00:30:51.220
the compiled binary and that's a very
important thing because what we do if

00:30:51.220 --> 00:30:51.230
important thing because what we do if
 

00:30:51.230 --> 00:30:53.500
important thing because what we do if
this binary map with into memory smaller

00:30:53.500 --> 00:30:53.510
this binary map with into memory smaller
 

00:30:53.510 --> 00:30:55.390
this binary map with into memory smaller
size translates to reduced memory

00:30:55.390 --> 00:30:55.400
size translates to reduced memory
 

00:30:55.400 --> 00:30:58.000
size translates to reduced memory
footprint and the important difference

00:30:58.000 --> 00:30:58.010
footprint and the important difference
 

00:30:58.010 --> 00:31:01.660
footprint and the important difference
here is that for example this memory

00:31:01.660 --> 00:31:01.670
here is that for example this memory
 

00:31:01.670 --> 00:31:02.260
here is that for example this memory
that is not

00:31:02.260 --> 00:31:02.270
that is not
 

00:31:02.270 --> 00:31:05.410
that is not
into this binary that we map into memory

00:31:05.410 --> 00:31:05.420
into this binary that we map into memory
 

00:31:05.420 --> 00:31:08.140
into this binary that we map into memory
will be a clean memory compared dirty

00:31:08.140 --> 00:31:08.150
will be a clean memory compared dirty
 

00:31:08.150 --> 00:31:11.500
will be a clean memory compared dirty
memory digital generate we also have to

00:31:11.500 --> 00:31:11.510
memory digital generate we also have to
 

00:31:11.510 --> 00:31:13.750
memory digital generate we also have to
also use far less disk space because the

00:31:13.750 --> 00:31:13.760
also use far less disk space because the
 

00:31:13.760 --> 00:31:15.220
also use far less disk space because the
binaries are much smaller now and we

00:31:15.220 --> 00:31:15.230
binaries are much smaller now and we
 

00:31:15.230 --> 00:31:18.430
binaries are much smaller now and we
free a lot of space for our users how

00:31:18.430 --> 00:31:18.440
free a lot of space for our users how
 

00:31:18.440 --> 00:31:21.549
free a lot of space for our users how
much space let's take a look at the

00:31:21.549 --> 00:31:21.559
much space let's take a look at the
 

00:31:21.559 --> 00:31:25.150
much space let's take a look at the
numbers in this chart we compare

00:31:25.150 --> 00:31:25.160
numbers in this chart we compare
 

00:31:25.160 --> 00:31:27.190
numbers in this chart we compare
different applications which is google

00:31:27.190 --> 00:31:27.200
different applications which is google
 

00:31:27.200 --> 00:31:29.890
different applications which is google
plus play music and hangouts and it

00:31:29.890 --> 00:31:29.900
plus play music and hangouts and it
 

00:31:29.900 --> 00:31:32.650
plus play music and hangouts and it
tracked how the generated binary for the

00:31:32.650 --> 00:31:32.660
tracked how the generated binary for the
 

00:31:32.660 --> 00:31:35.560
tracked how the generated binary for the
compiled code performance across

00:31:35.560 --> 00:31:35.570
compiled code performance across
 

00:31:35.570 --> 00:31:37.680
compiled code performance across
marshmallow which is the blue line and

00:31:37.680 --> 00:31:37.690
marshmallow which is the blue line and
 

00:31:37.690 --> 00:31:40.330
marshmallow which is the blue line and
preview during the first boot which is

00:31:40.330 --> 00:31:40.340
preview during the first boot which is
 

00:31:40.340 --> 00:31:42.220
preview during the first boot which is
equivalent of fresh install of the

00:31:42.220 --> 00:31:42.230
equivalent of fresh install of the
 

00:31:42.230 --> 00:31:44.250
equivalent of fresh install of the
application which is the orange line and

00:31:44.250 --> 00:31:44.260
application which is the orange line and
 

00:31:44.260 --> 00:31:47.110
application which is the orange line and
the Green Line is how much it takes for

00:31:47.110 --> 00:31:47.120
the Green Line is how much it takes for
 

00:31:47.120 --> 00:31:50.350
the Green Line is how much it takes for
the profile guided compilation as you

00:31:50.350 --> 00:31:50.360
the profile guided compilation as you
 

00:31:50.360 --> 00:31:52.870
the profile guided compilation as you
can see the reduction is more than 50%

00:31:52.870 --> 00:31:52.880
can see the reduction is more than 50%
 

00:31:52.880 --> 00:31:58.450
can see the reduction is more than 50%
and obviously the green line will go up

00:31:58.450 --> 00:31:58.460
and obviously the green line will go up
 

00:31:58.460 --> 00:32:01.330
and obviously the green line will go up
over time and our tests show that

00:32:01.330 --> 00:32:01.340
over time and our tests show that
 

00:32:01.340 --> 00:32:03.790
over time and our tests show that
actually stays around 50% most of the

00:32:03.790 --> 00:32:03.800
actually stays around 50% most of the
 

00:32:03.800 --> 00:32:06.850
actually stays around 50% most of the
times and you may wonder how come we get

00:32:06.850 --> 00:32:06.860
times and you may wonder how come we get
 

00:32:06.860 --> 00:32:09.090
times and you may wonder how come we get
so so great reduction in terms of size

00:32:09.090 --> 00:32:09.100
so so great reduction in terms of size
 

00:32:09.100 --> 00:32:12.880
so so great reduction in terms of size
well when we analyze the profiles we've

00:32:12.880 --> 00:32:12.890
well when we analyze the profiles we've
 

00:32:12.890 --> 00:32:16.270
well when we analyze the profiles we've
realized that only 5 to around 5 4 to 5%

00:32:16.270 --> 00:32:16.280
realized that only 5 to around 5 4 to 5%
 

00:32:16.280 --> 00:32:18.520
realized that only 5 to around 5 4 to 5%
of the methods actually get compiled and

00:32:18.520 --> 00:32:18.530
of the methods actually get compiled and
 

00:32:18.530 --> 00:32:21.400
of the methods actually get compiled and
as you use the app more obviously this

00:32:21.400 --> 00:32:21.410
as you use the app more obviously this
 

00:32:21.410 --> 00:32:23.560
as you use the app more obviously this
percentage will go up will generate more

00:32:23.560 --> 00:32:23.570
percentage will go up will generate more
 

00:32:23.570 --> 00:32:26.710
percentage will go up will generate more
code but as I said in general will stay

00:32:26.710 --> 00:32:26.720
code but as I said in general will stay
 

00:32:26.720 --> 00:32:31.450
code but as I said in general will stay
below 50% or around that area now what a

00:32:31.450 --> 00:32:31.460
below 50% or around that area now what a
 

00:32:31.460 --> 00:32:33.610
below 50% or around that area now what a
natural question here is if i'm mollie

00:32:33.610 --> 00:32:33.620
natural question here is if i'm mollie
 

00:32:33.620 --> 00:32:36.250
natural question here is if i'm mollie
compiling 5% of job how can i reduce the

00:32:36.250 --> 00:32:36.260
compiling 5% of job how can i reduce the
 

00:32:36.260 --> 00:32:37.780
compiling 5% of job how can i reduce the
space only by 50%

00:32:37.780 --> 00:32:37.790
space only by 50%
 

00:32:37.790 --> 00:32:41.200
space only by 50%
why not 95 well those lines contains

00:32:41.200 --> 00:32:41.210
why not 95 well those lines contains
 

00:32:41.210 --> 00:32:43.390
why not 95 well those lines contains
also the application raw code that dex

00:32:43.390 --> 00:32:43.400
also the application raw code that dex
 

00:32:43.400 --> 00:32:46.330
also the application raw code that dex
code and that's a line below which you

00:32:46.330 --> 00:32:46.340
code and that's a line below which you
 

00:32:46.340 --> 00:32:48.400
code and that's a line below which you
cannot go because we need to run

00:32:48.400 --> 00:32:48.410
cannot go because we need to run
 

00:32:48.410 --> 00:32:50.830
cannot go because we need to run
something and here's how we compare to

00:32:50.830 --> 00:32:50.840
something and here's how we compare to
 

00:32:50.840 --> 00:32:54.490
something and here's how we compare to
the application size you can see that in

00:32:54.490 --> 00:32:54.500
the application size you can see that in
 

00:32:54.500 --> 00:32:59.049
the application size you can see that in
marshmallow we generated more than 3x in

00:32:59.049 --> 00:32:59.059
marshmallow we generated more than 3x in
 

00:32:59.059 --> 00:33:01.930
marshmallow we generated more than 3x in
terms of code size whereas in an we stay

00:33:01.930 --> 00:33:01.940
terms of code size whereas in an we stay
 

00:33:01.940 --> 00:33:07.780
terms of code size whereas in an we stay
below 1.5 X and these are all cool

00:33:07.780 --> 00:33:07.790
below 1.5 X and these are all cool
 

00:33:07.790 --> 00:33:09.760
below 1.5 X and these are all cool
benefits but it's not the only thing

00:33:09.760 --> 00:33:09.770
benefits but it's not the only thing
 

00:33:09.770 --> 00:33:13.450
benefits but it's not the only thing
actually that we use profiles for we

00:33:13.450 --> 00:33:13.460
actually that we use profiles for we
 

00:33:13.460 --> 00:33:16.100
actually that we use profiles for we
also use them to further speed

00:33:16.100 --> 00:33:16.110
also use them to further speed
 

00:33:16.110 --> 00:33:18.350
also use them to further speed
system updates as my colleague Nicola

00:33:18.350 --> 00:33:18.360
system updates as my colleague Nicola
 

00:33:18.360 --> 00:33:20.150
system updates as my colleague Nicola
mentioned because of duty don't need to

00:33:20.150 --> 00:33:20.160
mentioned because of duty don't need to
 

00:33:20.160 --> 00:33:22.669
mentioned because of duty don't need to
recompile the app again and that

00:33:22.669 --> 00:33:22.679
recompile the app again and that
 

00:33:22.679 --> 00:33:24.950
recompile the app again and that
basically gets rid of the long waiting

00:33:24.950 --> 00:33:24.960
basically gets rid of the long waiting
 

00:33:24.960 --> 00:33:27.380
basically gets rid of the long waiting
time for the optimizing app we still

00:33:27.380 --> 00:33:27.390
time for the optimizing app we still
 

00:33:27.390 --> 00:33:29.180
time for the optimizing app we still
want to do some processing of the app in

00:33:29.180 --> 00:33:29.190
want to do some processing of the app in
 

00:33:29.190 --> 00:33:31.010
want to do some processing of the app in
particular extraction and verification

00:33:31.010 --> 00:33:31.020
particular extraction and verification
 

00:33:31.020 --> 00:33:33.919
particular extraction and verification
to ensure that those apps get executed

00:33:33.919 --> 00:33:33.929
to ensure that those apps get executed
 

00:33:33.929 --> 00:33:35.510
to ensure that those apps get executed
as fast as possible and they are first

00:33:35.510 --> 00:33:35.520
as fast as possible and they are first
 

00:33:35.520 --> 00:33:39.950
as fast as possible and they are first
lunged and in M we actually know how

00:33:39.950 --> 00:33:39.960
lunged and in M we actually know how
 

00:33:39.960 --> 00:33:42.260
lunged and in M we actually know how
those apps were executed before so we

00:33:42.260 --> 00:33:42.270
those apps were executed before so we
 

00:33:42.270 --> 00:33:44.810
those apps were executed before so we
can use profile only guide to guide the

00:33:44.810 --> 00:33:44.820
can use profile only guide to guide the
 

00:33:44.820 --> 00:33:47.870
can use profile only guide to guide the
verification and that saves around 40%

00:33:47.870 --> 00:33:47.880
verification and that saves around 40%
 

00:33:47.880 --> 00:33:51.049
verification and that saves around 40%
of the time extra we also added new

00:33:51.049 --> 00:33:51.059
of the time extra we also added new
 

00:33:51.059 --> 00:33:54.110
of the time extra we also added new
improved usage stats and compared to M

00:33:54.110 --> 00:33:54.120
improved usage stats and compared to M
 

00:33:54.120 --> 00:33:56.330
improved usage stats and compared to M
we can now track precisely how the

00:33:56.330 --> 00:33:56.340
we can now track precisely how the
 

00:33:56.340 --> 00:33:58.370
we can now track precisely how the
application was used then how it was

00:33:58.370 --> 00:33:58.380
application was used then how it was
 

00:33:58.380 --> 00:34:01.190
application was used then how it was
executed and you only analyze what

00:34:01.190 --> 00:34:01.200
executed and you only analyze what
 

00:34:01.200 --> 00:34:03.080
executed and you only analyze what
actually matters for the users

00:34:03.080 --> 00:34:03.090
actually matters for the users
 

00:34:03.090 --> 00:34:05.630
actually matters for the users
what is that application which has a

00:34:05.630 --> 00:34:05.640
what is that application which has a
 

00:34:05.640 --> 00:34:07.850
what is that application which has a
user interface and the users can

00:34:07.850 --> 00:34:07.860
user interface and the users can
 

00:34:07.860 --> 00:34:09.649
user interface and the users can
interact with them those are the most

00:34:09.649 --> 00:34:09.659
interact with them those are the most
 

00:34:09.659 --> 00:34:11.450
interact with them those are the most
valuable for our users and we focus on

00:34:11.450 --> 00:34:11.460
valuable for our users and we focus on
 

00:34:11.460 --> 00:34:15.740
valuable for our users and we focus on
them during system update however when

00:34:15.740 --> 00:34:15.750
them during system update however when
 

00:34:15.750 --> 00:34:17.780
them during system update however when
you take the update first update to n we

00:34:17.780 --> 00:34:17.790
you take the update first update to n we
 

00:34:17.790 --> 00:34:19.730
you take the update first update to n we
don't have access to all the goodies we

00:34:19.730 --> 00:34:19.740
don't have access to all the goodies we
 

00:34:19.740 --> 00:34:22.149
don't have access to all the goodies we
don't have profiles and I don't have

00:34:22.149 --> 00:34:22.159
don't have profiles and I don't have
 

00:34:22.159 --> 00:34:25.609
don't have profiles and I don't have
improved enough accurate usage stats to

00:34:25.609 --> 00:34:25.619
improved enough accurate usage stats to
 

00:34:25.619 --> 00:34:27.830
improved enough accurate usage stats to
realize how the app was used and what we

00:34:27.830 --> 00:34:27.840
realize how the app was used and what we
 

00:34:27.840 --> 00:34:29.960
realize how the app was used and what we
do we do a full verification of most of

00:34:29.960 --> 00:34:29.970
do we do a full verification of most of
 

00:34:29.970 --> 00:34:32.480
do we do a full verification of most of
the apps this is still much much faster

00:34:32.480 --> 00:34:32.490
the apps this is still much much faster
 

00:34:32.490 --> 00:34:35.359
the apps this is still much much faster
than we used to do in M and how much

00:34:35.359 --> 00:34:35.369
than we used to do in M and how much
 

00:34:35.369 --> 00:34:36.950
than we used to do in M and how much
faster let's take a look at the numbers

00:34:36.950 --> 00:34:36.960
faster let's take a look at the numbers
 

00:34:36.960 --> 00:34:41.419
faster let's take a look at the numbers
you can see here three different lines

00:34:41.419 --> 00:34:41.429
you can see here three different lines
 

00:34:41.429 --> 00:34:44.690
you can see here three different lines
and these numbers are obtained on the

00:34:44.690 --> 00:34:44.700
and these numbers are obtained on the
 

00:34:44.700 --> 00:34:46.970
and these numbers are obtained on the
same device which have roughly 100

00:34:46.970 --> 00:34:46.980
same device which have roughly 100
 

00:34:46.980 --> 00:34:49.820
same device which have roughly 100
application installed and the first line

00:34:49.820 --> 00:34:49.830
application installed and the first line
 

00:34:49.830 --> 00:34:52.700
application installed and the first line
which represents an OTA a system update

00:34:52.700 --> 00:34:52.710
which represents an OTA a system update
 

00:34:52.710 --> 00:34:55.730
which represents an OTA a system update
from M to M Prime where we took a

00:34:55.730 --> 00:34:55.740
from M to M Prime where we took a
 

00:34:55.740 --> 00:34:59.120
from M to M Prime where we took a
security update we took around 14

00:34:59.120 --> 00:34:59.130
security update we took around 14
 

00:34:59.130 --> 00:35:02.150
security update we took around 14
minutes to process all the applications

00:35:02.150 --> 00:35:02.160
minutes to process all the applications
 

00:35:02.160 --> 00:35:03.740
minutes to process all the applications
and that's the time that the runtime

00:35:03.740 --> 00:35:03.750
and that's the time that the runtime
 

00:35:03.750 --> 00:35:07.190
and that's the time that the runtime
spends processing them when you take the

00:35:07.190 --> 00:35:07.200
spends processing them when you take the
 

00:35:07.200 --> 00:35:10.160
spends processing them when you take the
OTA to M we reduce the time to about 3

00:35:10.160 --> 00:35:10.170
OTA to M we reduce the time to about 3
 

00:35:10.170 --> 00:35:12.890
OTA to M we reduce the time to about 3
minutes which is branch up to 5x

00:35:12.890 --> 00:35:12.900
minutes which is branch up to 5x
 

00:35:12.900 --> 00:35:15.920
minutes which is branch up to 5x
reduction and there we verify most of

00:35:15.920 --> 00:35:15.930
reduction and there we verify most of
 

00:35:15.930 --> 00:35:18.859
reduction and there we verify most of
the applications now the next step a

00:35:18.859 --> 00:35:18.869
the applications now the next step a
 

00:35:18.869 --> 00:35:21.349
the applications now the next step a
security update will kick in for an and

00:35:21.349 --> 00:35:21.359
security update will kick in for an and
 

00:35:21.359 --> 00:35:23.150
security update will kick in for an and
what we do already have profile

00:35:23.150 --> 00:35:23.160
what we do already have profile
 

00:35:23.160 --> 00:35:25.580
what we do already have profile
information we have already had improve

00:35:25.580 --> 00:35:25.590
information we have already had improve
 

00:35:25.590 --> 00:35:27.590
information we have already had improve
usage stats and you can use that to

00:35:27.590 --> 00:35:27.600
usage stats and you can use that to
 

00:35:27.600 --> 00:35:29.700
usage stats and you can use that to
drive the time even lower

00:35:29.700 --> 00:35:29.710
drive the time even lower
 

00:35:29.710 --> 00:35:31.950
drive the time even lower
take a security update on this device we

00:35:31.950 --> 00:35:31.960
take a security update on this device we
 

00:35:31.960 --> 00:35:34.140
take a security update on this device we
take less than a minute and compared to

00:35:34.140 --> 00:35:34.150
take less than a minute and compared to
 

00:35:34.150 --> 00:35:37.260
take less than a minute and compared to
M that's more than 12 X improvement in

00:35:37.260 --> 00:35:37.270
M that's more than 12 X improvement in
 

00:35:37.270 --> 00:35:42.359
M that's more than 12 X improvement in
terms of speed up with that I like it to

00:35:42.359 --> 00:35:42.369
terms of speed up with that I like it to
 

00:35:42.369 --> 00:35:44.609
terms of speed up with that I like it to
pass it to Matthew and he will explain

00:35:44.609 --> 00:35:44.619
pass it to Matthew and he will explain
 

00:35:44.619 --> 00:35:47.490
pass it to Matthew and he will explain
how use profiles to further even to

00:35:47.490 --> 00:35:47.500
how use profiles to further even to
 

00:35:47.500 --> 00:35:56.849
how use profiles to further even to
speed up application even more Thank You

00:35:56.849 --> 00:35:56.859
speed up application even more Thank You
 

00:35:56.859 --> 00:36:00.060
speed up application even more Thank You
Colleen why new feature an end that

00:36:00.060 --> 00:36:00.070
Colleen why new feature an end that
 

00:36:00.070 --> 00:36:01.620
Colleen why new feature an end that
reduces application launch time as

00:36:01.620 --> 00:36:01.630
reduces application launch time as
 

00:36:01.630 --> 00:36:05.070
reduces application launch time as
application images an application image

00:36:05.070 --> 00:36:05.080
application images an application image
 

00:36:05.080 --> 00:36:06.960
application images an application image
is a serialized heap consisting of pre

00:36:06.960 --> 00:36:06.970
is a serialized heap consisting of pre
 

00:36:06.970 --> 00:36:09.630
is a serialized heap consisting of pre
initialized classes this image is loaded

00:36:09.630 --> 00:36:09.640
initialized classes this image is loaded
 

00:36:09.640 --> 00:36:13.589
initialized classes this image is loaded
by the application during launch during

00:36:13.589 --> 00:36:13.599
by the application during launch during
 

00:36:13.599 --> 00:36:15.150
by the application during launch during
wash most applications end up loading

00:36:15.150 --> 00:36:15.160
wash most applications end up loading
 

00:36:15.160 --> 00:36:16.770
wash most applications end up loading
many classes for initialization work

00:36:16.770 --> 00:36:16.780
many classes for initialization work
 

00:36:16.780 --> 00:36:18.420
many classes for initialization work
such as creating views or inflating

00:36:18.420 --> 00:36:18.430
such as creating views or inflating
 

00:36:18.430 --> 00:36:19.370
such as creating views or inflating
layouts

00:36:19.370 --> 00:36:19.380
layouts
 

00:36:19.380 --> 00:36:21.390
layouts
unfortunately loading classes is not

00:36:21.390 --> 00:36:21.400
unfortunately loading classes is not
 

00:36:21.400 --> 00:36:23.040
unfortunately loading classes is not
free it can consist of a large portion

00:36:23.040 --> 00:36:23.050
free it can consist of a large portion
 

00:36:23.050 --> 00:36:25.440
free it can consist of a large portion
of the application launch time the way

00:36:25.440 --> 00:36:25.450
of the application launch time the way
 

00:36:25.450 --> 00:36:27.060
of the application launch time the way
that application images reduces this

00:36:27.060 --> 00:36:27.070
that application images reduces this
 

00:36:27.070 --> 00:36:29.040
that application images reduces this
cost is by effectively shifting work

00:36:29.040 --> 00:36:29.050
cost is by effectively shifting work
 

00:36:29.050 --> 00:36:30.810
cost is by effectively shifting work
from application launch time to compile

00:36:30.810 --> 00:36:30.820
from application launch time to compile
 

00:36:30.820 --> 00:36:33.329
from application launch time to compile
time since the classes inside of the

00:36:33.329 --> 00:36:33.339
time since the classes inside of the
 

00:36:33.339 --> 00:36:34.859
time since the classes inside of the
application image are pre initialized

00:36:34.859 --> 00:36:34.869
application image are pre initialized
 

00:36:34.869 --> 00:36:36.870
application image are pre initialized
this means they're able to be accessed

00:36:36.870 --> 00:36:36.880
this means they're able to be accessed
 

00:36:36.880 --> 00:36:40.310
this means they're able to be accessed
right off the bat by the application

00:36:40.310 --> 00:36:40.320
right off the bat by the application
 

00:36:40.320 --> 00:36:42.540
right off the bat by the application
application images are generated during

00:36:42.540 --> 00:36:42.550
application images are generated during
 

00:36:42.550 --> 00:36:44.250
application images are generated during
the background compilation phase I think

00:36:44.250 --> 00:36:44.260
the background compilation phase I think
 

00:36:44.260 --> 00:36:45.660
the background compilation phase I think
was colleen referred to as a maintenance

00:36:45.660 --> 00:36:45.670
was colleen referred to as a maintenance
 

00:36:45.670 --> 00:36:49.410
was colleen referred to as a maintenance
phase by the IOT compiler leveraging the

00:36:49.410 --> 00:36:49.420
phase by the IOT compiler leveraging the
 

00:36:49.420 --> 00:36:50.970
phase by the IOT compiler leveraging the
JIT profiles the application images

00:36:50.970 --> 00:36:50.980
JIT profiles the application images
 

00:36:50.980 --> 00:36:53.010
JIT profiles the application images
include and serialized only the set of

00:36:53.010 --> 00:36:53.020
include and serialized only the set of
 

00:36:53.020 --> 00:36:54.750
include and serialized only the set of
classes that were used during prior and

00:36:54.750 --> 00:36:54.760
classes that were used during prior and
 

00:36:54.760 --> 00:36:57.960
classes that were used during prior and
washes of the application using the

00:36:57.960 --> 00:36:57.970
washes of the application using the
 

00:36:57.970 --> 00:36:59.490
washes of the application using the
profile is also key to having a small

00:36:59.490 --> 00:36:59.500
profile is also key to having a small
 

00:36:59.500 --> 00:37:01.770
profile is also key to having a small
application image since it only includes

00:37:01.770 --> 00:37:01.780
application image since it only includes
 

00:37:01.780 --> 00:37:03.359
application image since it only includes
a small fraction of the classes inside

00:37:03.359 --> 00:37:03.369
a small fraction of the classes inside
 

00:37:03.369 --> 00:37:06.240
a small fraction of the classes inside
of the actual application having a small

00:37:06.240 --> 00:37:06.250
of the actual application having a small
 

00:37:06.250 --> 00:37:07.770
of the actual application having a small
application image is important because

00:37:07.770 --> 00:37:07.780
application image is important because
 

00:37:07.780 --> 00:37:10.260
application image is important because
the application image is resident in RAM

00:37:10.260 --> 00:37:10.270
the application image is resident in RAM
 

00:37:10.270 --> 00:37:11.339
the application image is resident in RAM
for the entire lifetime of the

00:37:11.339 --> 00:37:11.349
for the entire lifetime of the
 

00:37:11.349 --> 00:37:13.530
for the entire lifetime of the
application as well as larger images

00:37:13.530 --> 00:37:13.540
application as well as larger images
 

00:37:13.540 --> 00:37:17.810
application as well as larger images
take longer to load as you can see here

00:37:17.810 --> 00:37:17.820
take longer to load as you can see here
 

00:37:17.820 --> 00:37:19.740
take longer to load as you can see here
application images have a very low

00:37:19.740 --> 00:37:19.750
application images have a very low
 

00:37:19.750 --> 00:37:21.300
application images have a very low
storage requirement this is mostly due

00:37:21.300 --> 00:37:21.310
storage requirement this is mostly due
 

00:37:21.310 --> 00:37:24.000
storage requirement this is mostly due
to the profile for the four apps here

00:37:24.000 --> 00:37:24.010
to the profile for the four apps here
 

00:37:24.010 --> 00:37:25.170
to the profile for the four apps here
the storage requirements were less than

00:37:25.170 --> 00:37:25.180
the storage requirements were less than
 

00:37:25.180 --> 00:37:28.530
the storage requirements were less than
two megabytes per app as a comparison I

00:37:28.530 --> 00:37:28.540
two megabytes per app as a comparison I
 

00:37:28.540 --> 00:37:30.000
two megabytes per app as a comparison I
put the application to compile the

00:37:30.000 --> 00:37:30.010
put the application to compile the
 

00:37:30.010 --> 00:37:31.920
put the application to compile the
application code with the profile so

00:37:31.920 --> 00:37:31.930
application code with the profile so
 

00:37:31.930 --> 00:37:33.390
application code with the profile so
this is already reduced compared to what

00:37:33.390 --> 00:37:33.400
this is already reduced compared to what
 

00:37:33.400 --> 00:37:34.710
this is already reduced compared to what
application code sizes would have been

00:37:34.710 --> 00:37:34.720
application code sizes would have been
 

00:37:34.720 --> 00:37:38.520
application code sizes would have been
on M the loading process and application

00:37:38.520 --> 00:37:38.530
on M the loading process and application
 

00:37:38.530 --> 00:37:41.700
on M the loading process and application
images begins with the application class

00:37:41.700 --> 00:37:41.710
images begins with the application class
 

00:37:41.710 --> 00:37:42.819
images begins with the application class
loader creation

00:37:42.819 --> 00:37:42.829
loader creation
 

00:37:42.829 --> 00:37:45.009
loader creation
when the application class loader is

00:37:45.009 --> 00:37:45.019
when the application class loader is
 

00:37:45.019 --> 00:37:47.919
when the application class loader is
created we load the application image

00:37:47.919 --> 00:37:47.929
created we load the application image
 

00:37:47.929 --> 00:37:50.699
created we load the application image
from storage and decompress it into RAM

00:37:50.699 --> 00:37:50.709
from storage and decompress it into RAM
 

00:37:50.709 --> 00:37:53.259
from storage and decompress it into RAM
for dynamically loaded Dex files we also

00:37:53.259 --> 00:37:53.269
for dynamically loaded Dex files we also
 

00:37:53.269 --> 00:37:55.059
for dynamically loaded Dex files we also
verify that the class letters supported

00:37:55.059 --> 00:37:55.069
verify that the class letters supported
 

00:37:55.069 --> 00:37:57.789
verify that the class letters supported
type since there is no dependency on

00:37:57.789 --> 00:37:57.799
type since there is no dependency on
 

00:37:57.799 --> 00:38:00.009
type since there is no dependency on
from the application compile code to the

00:38:00.009 --> 00:38:00.019
from the application compile code to the
 

00:38:00.019 --> 00:38:01.269
from the application compile code to the
image it means that we can reject the

00:38:01.269 --> 00:38:01.279
image it means that we can reject the
 

00:38:01.279 --> 00:38:03.069
image it means that we can reject the
image so the class loader is not

00:38:03.069 --> 00:38:03.079
image so the class loader is not
 

00:38:03.079 --> 00:38:05.079
image so the class loader is not
supported simply reject the image and

00:38:05.079 --> 00:38:05.089
supported simply reject the image and
 

00:38:05.089 --> 00:38:09.339
supported simply reject the image and
resume execution here are some results

00:38:09.339 --> 00:38:09.349
resume execution here are some results
 

00:38:09.349 --> 00:38:10.900
resume execution here are some results
for application image launch time

00:38:10.900 --> 00:38:10.910
for application image launch time
 

00:38:10.910 --> 00:38:12.669
for application image launch time
improvements for the four apps that I

00:38:12.669 --> 00:38:12.679
improvements for the four apps that I
 

00:38:12.679 --> 00:38:15.009
improvements for the four apps that I
have just displayed as you can see here

00:38:15.009 --> 00:38:15.019
have just displayed as you can see here
 

00:38:15.019 --> 00:38:16.870
have just displayed as you can see here
there's a round of 5 to 20% improvement

00:38:16.870 --> 00:38:16.880
there's a round of 5 to 20% improvement
 

00:38:16.880 --> 00:38:18.759
there's a round of 5 to 20% improvement
compared to profile guided compilation

00:38:18.759 --> 00:38:18.769
compared to profile guided compilation
 

00:38:18.769 --> 00:38:25.559
compared to profile guided compilation
only and now to the garbage collector

00:38:25.559 --> 00:38:25.569
only and now to the garbage collector
 

00:38:25.569 --> 00:38:27.880
only and now to the garbage collector
the garbage collector has not changed -

00:38:27.880 --> 00:38:27.890
the garbage collector has not changed -
 

00:38:27.890 --> 00:38:30.519
the garbage collector has not changed -
Martians for last IO presentation as you

00:38:30.519 --> 00:38:30.529
Martians for last IO presentation as you
 

00:38:30.529 --> 00:38:31.749
Martians for last IO presentation as you
can see here we were already in pretty

00:38:31.749 --> 00:38:31.759
can see here we were already in pretty
 

00:38:31.759 --> 00:38:34.630
can see here we were already in pretty
good shape back then there's still only

00:38:34.630 --> 00:38:34.640
good shape back then there's still only
 

00:38:34.640 --> 00:38:36.339
good shape back then there's still only
one short GC pause and the garbage

00:38:36.339 --> 00:38:36.349
one short GC pause and the garbage
 

00:38:36.349 --> 00:38:37.569
one short GC pause and the garbage
collector was high throughput since it

00:38:37.569 --> 00:38:37.579
collector was high throughput since it
 

00:38:37.579 --> 00:38:40.809
collector was high throughput since it
is generational there have been a few GC

00:38:40.809 --> 00:38:40.819
is generational there have been a few GC
 

00:38:40.819 --> 00:38:42.459
is generational there have been a few GC
changes mostly relaized application

00:38:42.459 --> 00:38:42.469
changes mostly relaized application
 

00:38:42.469 --> 00:38:44.919
changes mostly relaized application
images and class unloading however these

00:38:44.919 --> 00:38:44.929
images and class unloading however these
 

00:38:44.929 --> 00:38:47.259
images and class unloading however these
changes do not have our DS GC changes do

00:38:47.259 --> 00:38:47.269
changes do not have our DS GC changes do
 

00:38:47.269 --> 00:38:50.640
changes do not have our DS GC changes do
not have substantial performance impact

00:38:50.640 --> 00:38:50.650
not have substantial performance impact
 

00:38:50.650 --> 00:38:52.779
not have substantial performance impact
one thing that has improved each release

00:38:52.779 --> 00:38:52.789
one thing that has improved each release
 

00:38:52.789 --> 00:38:57.219
one thing that has improved each release
is allocation time with L we introduced

00:38:57.219 --> 00:38:57.229
is allocation time with L we introduced
 

00:38:57.229 --> 00:38:59.829
is allocation time with L we introduced
a new custom thread-local allocator that

00:38:59.829 --> 00:38:59.839
a new custom thread-local allocator that
 

00:38:59.839 --> 00:39:02.769
a new custom thread-local allocator that
reduced a lot of reduced allocation time

00:39:02.769 --> 00:39:02.779
reduced a lot of reduced allocation time
 

00:39:02.779 --> 00:39:04.029
reduced a lot of reduced allocation time
substantially by avoiding

00:39:04.029 --> 00:39:04.039
substantially by avoiding
 

00:39:04.039 --> 00:39:06.999
substantially by avoiding
synchronization costs in M we removed

00:39:06.999 --> 00:39:07.009
synchronization costs in M we removed
 

00:39:07.009 --> 00:39:08.559
synchronization costs in M we removed
all the compare and swap operations in

00:39:08.559 --> 00:39:08.569
all the compare and swap operations in
 

00:39:08.569 --> 00:39:11.559
all the compare and swap operations in
the allocation common case finally in n

00:39:11.559 --> 00:39:11.569
the allocation common case finally in n
 

00:39:11.569 --> 00:39:13.059
the allocation common case finally in n
the allocation common case has been

00:39:13.059 --> 00:39:13.069
the allocation common case has been
 

00:39:13.069 --> 00:39:14.910
the allocation common case has been
written and hand optimized assembly code

00:39:14.910 --> 00:39:14.920
written and hand optimized assembly code
 

00:39:14.920 --> 00:39:17.410
written and hand optimized assembly code
this is the largest speed up yet at over

00:39:17.410 --> 00:39:17.420
this is the largest speed up yet at over
 

00:39:17.420 --> 00:39:21.039
this is the largest speed up yet at over
200 percent start to M combined all

00:39:21.039 --> 00:39:21.049
200 percent start to M combined all
 

00:39:21.049 --> 00:39:22.569
200 percent start to M combined all
these improvements mean that allocations

00:39:22.569 --> 00:39:22.579
these improvements mean that allocations
 

00:39:22.579 --> 00:39:24.549
these improvements mean that allocations
are now around 10x faceted KitKat which

00:39:24.549 --> 00:39:24.559
are now around 10x faceted KitKat which
 

00:39:24.559 --> 00:39:29.499
are now around 10x faceted KitKat which
was dalvik class unloading also

00:39:29.499 --> 00:39:29.509
was dalvik class unloading also
 

00:39:29.509 --> 00:39:31.390
was dalvik class unloading also
introduced an N is a way to reduce ram

00:39:31.390 --> 00:39:31.400
introduced an N is a way to reduce ram
 

00:39:31.400 --> 00:39:33.849
introduced an N is a way to reduce ram
for modular applications basically what

00:39:33.849 --> 00:39:33.859
for modular applications basically what
 

00:39:33.859 --> 00:39:35.469
for modular applications basically what
this means is that classes and class

00:39:35.469 --> 00:39:35.479
this means is that classes and class
 

00:39:35.479 --> 00:39:37.209
this means is that classes and class
loaders can be freed by the GC when

00:39:37.209 --> 00:39:37.219
loaders can be freed by the GC when
 

00:39:37.219 --> 00:39:39.459
loaders can be freed by the GC when
there are no longer used in previous

00:39:39.459 --> 00:39:39.469
there are no longer used in previous
 

00:39:39.469 --> 00:39:41.679
there are no longer used in previous
Android versions these were held live

00:39:41.679 --> 00:39:41.689
Android versions these were held live
 

00:39:41.689 --> 00:39:42.999
Android versions these were held live
for the entire lifetime of the

00:39:42.999 --> 00:39:43.009
for the entire lifetime of the
 

00:39:43.009 --> 00:39:47.380
for the entire lifetime of the
application for class hoping to occur

00:39:47.380 --> 00:39:47.390
application for class hoping to occur
 

00:39:47.390 --> 00:39:49.029
application for class hoping to occur
all the classes in the class order must

00:39:49.029 --> 00:39:49.039
all the classes in the class order must
 

00:39:49.039 --> 00:39:50.529
all the classes in the class order must
no longer be reachable as well as the

00:39:50.529 --> 00:39:50.539
no longer be reachable as well as the
 

00:39:50.539 --> 00:39:53.169
no longer be reachable as well as the
class letter itself when the GC notices

00:39:53.169 --> 00:39:53.179
class letter itself when the GC notices
 

00:39:53.179 --> 00:39:55.359
class letter itself when the GC notices
this it freezes them as well as the

00:39:55.359 --> 00:39:55.369
this it freezes them as well as the
 

00:39:55.369 --> 00:39:56.520
this it freezes them as well as the
associate

00:39:56.520 --> 00:39:56.530
associate
 

00:39:56.530 --> 00:39:59.290
associate
this chart demonstrates just a bit of

00:39:59.290 --> 00:39:59.300
this chart demonstrates just a bit of
 

00:39:59.300 --> 00:40:01.210
this chart demonstrates just a bit of
how the class loader interacts other

00:40:01.210 --> 00:40:01.220
how the class loader interacts other
 

00:40:01.220 --> 00:40:06.010
how the class loader interacts other
components and retains them with that

00:40:06.010 --> 00:40:06.020
components and retains them with that
 

00:40:06.020 --> 00:40:09.520
components and retains them with that
off the nicolas for the wrap-up Thank

00:40:09.520 --> 00:40:09.530
off the nicolas for the wrap-up Thank
 

00:40:09.530 --> 00:40:15.390
off the nicolas for the wrap-up Thank
You Matthew

00:40:15.390 --> 00:40:15.400
 

00:40:15.400 --> 00:40:18.490
alright so to wrap up we've shown you

00:40:18.490 --> 00:40:18.500
alright so to wrap up we've shown you
 

00:40:18.500 --> 00:40:20.820
alright so to wrap up we've shown you
all the features we've worked on for n

00:40:20.820 --> 00:40:20.830
all the features we've worked on for n
 

00:40:20.830 --> 00:40:23.950
all the features we've worked on for n
mainly a fascicle pattern up to 5x

00:40:23.950 --> 00:40:23.960
mainly a fascicle pattern up to 5x
 

00:40:23.960 --> 00:40:26.950
mainly a fascicle pattern up to 5x
compared to previous releases a faster

00:40:26.950 --> 00:40:26.960
compared to previous releases a faster
 

00:40:26.960 --> 00:40:28.930
compared to previous releases a faster
intrapreneur up to 3x compared to

00:40:28.930 --> 00:40:28.940
intrapreneur up to 3x compared to
 

00:40:28.940 --> 00:40:31.900
intrapreneur up to 3x compared to
marshmallow a new JIT compiler and proof

00:40:31.900 --> 00:40:31.910
marshmallow a new JIT compiler and proof
 

00:40:31.910 --> 00:40:34.390
marshmallow a new JIT compiler and proof
our guide computation just remove that

00:40:34.390 --> 00:40:34.400
our guide computation just remove that
 

00:40:34.400 --> 00:40:36.640
our guide computation just remove that
optimizing Apsara log and provide

00:40:36.640 --> 00:40:36.650
optimizing Apsara log and provide
 

00:40:36.650 --> 00:40:39.970
optimizing Apsara log and provide
fastest or installs applications image

00:40:39.970 --> 00:40:39.980
fastest or installs applications image
 

00:40:39.980 --> 00:40:43.300
fastest or installs applications image
for faster startup and faster on

00:40:43.300 --> 00:40:43.310
for faster startup and faster on
 

00:40:43.310 --> 00:40:46.210
for faster startup and faster on
occasions you can actually if you're

00:40:46.210 --> 00:40:46.220
occasions you can actually if you're
 

00:40:46.220 --> 00:40:47.980
occasions you can actually if you're
interested in all that sort of low-level

00:40:47.980 --> 00:40:47.990
interested in all that sort of low-level
 

00:40:47.990 --> 00:40:53.650
interested in all that sort of low-level
stuff follow it on the AOSP website

00:40:53.650 --> 00:40:53.660
stuff follow it on the AOSP website
 

00:40:53.660 --> 00:40:56.609
stuff follow it on the AOSP website
where we actually do all development

00:40:56.609 --> 00:40:56.619
where we actually do all development
 

00:40:56.619 --> 00:40:59.579
where we actually do all development
with that we'll take your questions

00:40:59.579 --> 00:40:59.589
with that we'll take your questions
 

00:40:59.589 --> 00:41:02.710
with that we'll take your questions
thank you

