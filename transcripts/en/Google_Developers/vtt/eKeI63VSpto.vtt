WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.383
[MUSIC PLAYING]

00:00:06.754 --> 00:00:07.920
ERIC ROSEBAUM: Hi, I'm Eric.

00:00:07.920 --> 00:00:09.003
YOTAM MANN: Hi, I'm Yotam.

00:00:11.375 --> 00:00:13.790
With machine learning, you
can now take a picture,

00:00:13.790 --> 00:00:16.100
and have a computer tell
you exactly what it sees.

00:00:16.100 --> 00:00:17.981
AI: Eyewear,
glasses, vision care.

00:00:17.981 --> 00:00:20.480
ERIC ROSEBAUM: We wanted to see
if we could do something fun

00:00:20.480 --> 00:00:21.930
with this, and we had an idea.

00:00:21.930 --> 00:00:23.846
What if the computer
turned the things that it

00:00:23.846 --> 00:00:25.759
saw into lyrics of a song?

00:00:25.759 --> 00:00:27.050
It could even rhyme about them.

00:00:27.050 --> 00:00:29.090
AI: We've got
glasses in this spot.

00:00:29.090 --> 00:00:30.956
Could be eyewear, but maybe not.

00:00:30.956 --> 00:00:33.080
YOTAM MANN: There are two
parts, image recognition,

00:00:33.080 --> 00:00:36.000
for seeing things, and speech
synthesis, for talking.

00:00:36.000 --> 00:00:36.789
AI: Hello.

00:00:36.789 --> 00:00:38.330
ERIC ROSEBAUM: For
image recognition,

00:00:38.330 --> 00:00:40.160
we use the Cloud Vision API.

00:00:40.160 --> 00:00:41.885
You can just send
it a picture, and it

00:00:41.885 --> 00:00:43.880
returns labels for
what it sees, along

00:00:43.880 --> 00:00:45.425
with the confidence scores.

00:00:45.425 --> 00:00:47.150
It started really
getting fun when

00:00:47.150 --> 00:00:50.030
we brought in a song made by one
of our musical heroes, Giorgio

00:00:50.030 --> 00:00:51.230
Moroder.

00:00:51.230 --> 00:00:53.632
AI: Yeah, all right.

00:00:53.632 --> 00:00:55.340
YOTAM MANN: And for
the computer's voice,

00:00:55.340 --> 00:00:58.520
we used an open source project
called Mary TTS, combined

00:00:58.520 --> 00:01:00.350
with the Web Audio API.

00:01:00.350 --> 00:01:02.630
This let us add effects
to the computer's voice,

00:01:02.630 --> 00:01:04.069
and sync it to the beat.

00:01:04.069 --> 00:01:06.891
AI: We've got glasses in
this spot-ot-ot-ot-ot.

00:01:06.891 --> 00:01:08.640
YOTAM MANN: We had our
friends try it out.

00:01:08.640 --> 00:01:09.770
And they had a lot
of fun pointing it

00:01:09.770 --> 00:01:10.810
at all kinds of things.

00:01:10.810 --> 00:01:12.561
AI: Is that food
I see-see-see-see?

00:01:12.561 --> 00:01:13.852
SPEAKER 1: That's pretty close.

00:01:13.852 --> 00:01:15.279
SPEAKER 2: Play it to me.

00:01:15.279 --> 00:01:16.820
AI: That's plucked
string instruments

00:01:16.820 --> 00:01:18.660
on my screen-screen-screen.

00:01:18.660 --> 00:01:21.417
Could be profession,
but maybe not-not-not.

00:01:21.417 --> 00:01:22.625
Looks like world to me-me-me.

00:01:25.270 --> 00:01:28.614
Digging that camera operator
you've got-got-got-got.

00:01:28.614 --> 00:01:30.280
SPEAKER 1: Digging
that camera operator.

00:01:30.280 --> 00:01:31.800
ERIC ROSEBAUM: We
call it Giorgio Cam.

00:01:31.800 --> 00:01:33.633
And it's just one example
of how you can use

00:01:33.633 --> 00:01:35.390
machine learning in fun ways.

00:01:35.390 --> 00:01:38.695
You can play with it and get
the code at g.co/aiexperiments.

