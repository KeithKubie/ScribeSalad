WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.060
you've heard about North organization

00:00:02.060 --> 00:00:02.070
you've heard about North organization
 

00:00:02.070 --> 00:00:04.610
you've heard about North organization
how to set up your depth in 10 cents

00:00:04.610 --> 00:00:04.620
how to set up your depth in 10 cents
 

00:00:04.620 --> 00:00:07.249
how to set up your depth in 10 cents
human level performance as a proxy for

00:00:07.249 --> 00:00:07.259
human level performance as a proxy for
 

00:00:07.259 --> 00:00:09.650
human level performance as a proxy for
Bayes error and how to estimate your

00:00:09.650 --> 00:00:09.660
Bayes error and how to estimate your
 

00:00:09.660 --> 00:00:12.560
Bayes error and how to estimate your
avoidable bias and variance let's pull

00:00:12.560 --> 00:00:12.570
avoidable bias and variance let's pull
 

00:00:12.570 --> 00:00:14.209
avoidable bias and variance let's pull
it all together into a set of guidelines

00:00:14.209 --> 00:00:14.219
it all together into a set of guidelines
 

00:00:14.219 --> 00:00:16.189
it all together into a set of guidelines
to how to improve the performance of

00:00:16.189 --> 00:00:16.199
to how to improve the performance of
 

00:00:16.199 --> 00:00:17.900
to how to improve the performance of
your learning algorithm so I think

00:00:17.900 --> 00:00:17.910
your learning algorithm so I think
 

00:00:17.910 --> 00:00:19.790
your learning algorithm so I think
getting a supervised learning album to

00:00:19.790 --> 00:00:19.800
getting a supervised learning album to
 

00:00:19.800 --> 00:00:23.300
getting a supervised learning album to
work well means fundamentally hoping or

00:00:23.300 --> 00:00:23.310
work well means fundamentally hoping or
 

00:00:23.310 --> 00:00:25.189
work well means fundamentally hoping or
assuming that you can do two things

00:00:25.189 --> 00:00:25.199
assuming that you can do two things
 

00:00:25.199 --> 00:00:27.890
assuming that you can do two things
first is that you can fit the training

00:00:27.890 --> 00:00:27.900
first is that you can fit the training
 

00:00:27.900 --> 00:00:30.890
first is that you can fit the training
set pretty well and you can think of

00:00:30.890 --> 00:00:30.900
set pretty well and you can think of
 

00:00:30.900 --> 00:00:33.740
set pretty well and you can think of
this as roughly saying that you can

00:00:33.740 --> 00:00:33.750
this as roughly saying that you can
 

00:00:33.750 --> 00:00:38.900
this as roughly saying that you can
achieve low avoidable bias and the

00:00:38.900 --> 00:00:38.910
achieve low avoidable bias and the
 

00:00:38.910 --> 00:00:40.610
achieve low avoidable bias and the
second thing you're assuming you can do

00:00:40.610 --> 00:00:40.620
second thing you're assuming you can do
 

00:00:40.620 --> 00:00:42.410
second thing you're assuming you can do
well is that doing well in the training

00:00:42.410 --> 00:00:42.420
well is that doing well in the training
 

00:00:42.420 --> 00:00:45.200
well is that doing well in the training
set generalizes pretty well to the DEF

00:00:45.200 --> 00:00:45.210
set generalizes pretty well to the DEF
 

00:00:45.210 --> 00:00:47.330
set generalizes pretty well to the DEF
set or the test set and this is for

00:00:47.330 --> 00:00:47.340
set or the test set and this is for
 

00:00:47.340 --> 00:00:51.049
set or the test set and this is for
saying that variance is not too bad and

00:00:51.049 --> 00:00:51.059
saying that variance is not too bad and
 

00:00:51.059 --> 00:00:54.470
saying that variance is not too bad and
in the spirit of organization what you

00:00:54.470 --> 00:00:54.480
in the spirit of organization what you
 

00:00:54.480 --> 00:00:56.150
in the spirit of organization what you
see is that there's a certain set of

00:00:56.150 --> 00:00:56.160
see is that there's a certain set of
 

00:00:56.160 --> 00:00:59.000
see is that there's a certain set of
knobs you can use to fix avoidable bias

00:00:59.000 --> 00:00:59.010
knobs you can use to fix avoidable bias
 

00:00:59.010 --> 00:01:01.340
knobs you can use to fix avoidable bias
issues such as training bigger network

00:01:01.340 --> 00:01:01.350
issues such as training bigger network
 

00:01:01.350 --> 00:01:05.000
issues such as training bigger network
or training longer and there's a

00:01:05.000 --> 00:01:05.010
or training longer and there's a
 

00:01:05.010 --> 00:01:07.010
or training longer and there's a
separate set of things you can use to

00:01:07.010 --> 00:01:07.020
separate set of things you can use to
 

00:01:07.020 --> 00:01:09.920
separate set of things you can use to
address variance problems such as

00:01:09.920 --> 00:01:09.930
address variance problems such as
 

00:01:09.930 --> 00:01:12.080
address variance problems such as
regularization or getting more training

00:01:12.080 --> 00:01:12.090
regularization or getting more training
 

00:01:12.090 --> 00:01:16.010
regularization or getting more training
data so to summarize the process we've

00:01:16.010 --> 00:01:16.020
data so to summarize the process we've
 

00:01:16.020 --> 00:01:17.929
data so to summarize the process we've
seen the last several videos if you want

00:01:17.929 --> 00:01:17.939
seen the last several videos if you want
 

00:01:17.939 --> 00:01:20.450
seen the last several videos if you want
to improve the performance of your

00:01:20.450 --> 00:01:20.460
to improve the performance of your
 

00:01:20.460 --> 00:01:22.429
to improve the performance of your
machine learning system I would

00:01:22.429 --> 00:01:22.439
machine learning system I would
 

00:01:22.439 --> 00:01:23.899
machine learning system I would
recommend looking at the difference

00:01:23.899 --> 00:01:23.909
recommend looking at the difference
 

00:01:23.909 --> 00:01:26.240
recommend looking at the difference
between your training error and your

00:01:26.240 --> 00:01:26.250
between your training error and your
 

00:01:26.250 --> 00:01:29.120
between your training error and your
proxy for Bayes error and to teach a

00:01:29.120 --> 00:01:29.130
proxy for Bayes error and to teach a
 

00:01:29.130 --> 00:01:32.120
proxy for Bayes error and to teach a
sense of the avoidable bias in other

00:01:32.120 --> 00:01:32.130
sense of the avoidable bias in other
 

00:01:32.130 --> 00:01:34.249
sense of the avoidable bias in other
words just how much better do you think

00:01:34.249 --> 00:01:34.259
words just how much better do you think
 

00:01:34.259 --> 00:01:35.690
words just how much better do you think
you should be trying to do on your

00:01:35.690 --> 00:01:35.700
you should be trying to do on your
 

00:01:35.700 --> 00:01:38.149
you should be trying to do on your
training set and then look at the

00:01:38.149 --> 00:01:38.159
training set and then look at the
 

00:01:38.159 --> 00:01:39.710
training set and then look at the
difference in your def ever in your

00:01:39.710 --> 00:01:39.720
difference in your def ever in your
 

00:01:39.720 --> 00:01:42.200
difference in your def ever in your
training error as an estimate of how

00:01:42.200 --> 00:01:42.210
training error as an estimate of how
 

00:01:42.210 --> 00:01:44.120
training error as an estimate of how
much of a variance problem you have in

00:01:44.120 --> 00:01:44.130
much of a variance problem you have in
 

00:01:44.130 --> 00:01:45.980
much of a variance problem you have in
other words how much harder you should

00:01:45.980 --> 00:01:45.990
other words how much harder you should
 

00:01:45.990 --> 00:01:47.450
other words how much harder you should
be working to meet your performance

00:01:47.450 --> 00:01:47.460
be working to meet your performance
 

00:01:47.460 --> 00:01:49.969
be working to meet your performance
generalize from the training set to the

00:01:49.969 --> 00:01:49.979
generalize from the training set to the
 

00:01:49.979 --> 00:01:52.039
generalize from the training set to the
death set that it wasn't trained on

00:01:52.039 --> 00:01:52.049
death set that it wasn't trained on
 

00:01:52.049 --> 00:01:59.870
death set that it wasn't trained on
explicitly

00:01:59.870 --> 00:01:59.880
 

00:01:59.880 --> 00:02:04.560
you

00:02:04.560 --> 00:02:04.570
 

00:02:04.570 --> 00:02:07.020
so to whatever sense you

00:02:07.020 --> 00:02:07.030
so to whatever sense you
 

00:02:07.030 --> 00:02:10.050
so to whatever sense you
try to reduce avoidable buyers I would

00:02:10.050 --> 00:02:10.060
try to reduce avoidable buyers I would
 

00:02:10.060 --> 00:02:13.290
try to reduce avoidable buyers I would
try to apply tactics like train a bigger

00:02:13.290 --> 00:02:13.300
try to apply tactics like train a bigger
 

00:02:13.300 --> 00:02:16.199
try to apply tactics like train a bigger
model so you can just do better on your

00:02:16.199 --> 00:02:16.209
model so you can just do better on your
 

00:02:16.209 --> 00:02:18.750
model so you can just do better on your
training sets or pretty longer use a

00:02:18.750 --> 00:02:18.760
training sets or pretty longer use a
 

00:02:18.760 --> 00:02:22.070
training sets or pretty longer use a
better optimization algorithm such as

00:02:22.070 --> 00:02:22.080
better optimization algorithm such as
 

00:02:22.080 --> 00:02:30.960
better optimization algorithm such as
add momentum or rmsprop or use a better

00:02:30.960 --> 00:02:30.970
add momentum or rmsprop or use a better
 

00:02:30.970 --> 00:02:37.050
add momentum or rmsprop or use a better
algorithm like Adam or one other thing

00:02:37.050 --> 00:02:37.060
algorithm like Adam or one other thing
 

00:02:37.060 --> 00:02:39.870
algorithm like Adam or one other thing
you could try is to just find a better

00:02:39.870 --> 00:02:39.880
you could try is to just find a better
 

00:02:39.880 --> 00:02:42.000
you could try is to just find a better
neural network architecture or better

00:02:42.000 --> 00:02:42.010
neural network architecture or better
 

00:02:42.010 --> 00:02:44.880
neural network architecture or better
set of hyper parameters and this could

00:02:44.880 --> 00:02:44.890
set of hyper parameters and this could
 

00:02:44.890 --> 00:02:46.860
set of hyper parameters and this could
include everything from changing the

00:02:46.860 --> 00:02:46.870
include everything from changing the
 

00:02:46.870 --> 00:02:48.990
include everything from changing the
activation function to changing the

00:02:48.990 --> 00:02:49.000
activation function to changing the
 

00:02:49.000 --> 00:02:50.460
activation function to changing the
number of layers or hidden units

00:02:50.460 --> 00:02:50.470
number of layers or hidden units
 

00:02:50.470 --> 00:02:52.020
number of layers or hidden units
although if you do that it would be in

00:02:52.020 --> 00:02:52.030
although if you do that it would be in
 

00:02:52.030 --> 00:02:54.210
although if you do that it would be in
the direction of increasing the model

00:02:54.210 --> 00:02:54.220
the direction of increasing the model
 

00:02:54.220 --> 00:02:58.080
the direction of increasing the model
size to trying out other models or other

00:02:58.080 --> 00:02:58.090
size to trying out other models or other
 

00:02:58.090 --> 00:03:01.080
size to trying out other models or other
model architectures such as recurrent

00:03:01.080 --> 00:03:01.090
model architectures such as recurrent
 

00:03:01.090 --> 00:03:03.330
model architectures such as recurrent
neural networks and convolutional neural

00:03:03.330 --> 00:03:03.340
neural networks and convolutional neural
 

00:03:03.340 --> 00:03:04.920
neural networks and convolutional neural
networks which we'll see in later

00:03:04.920 --> 00:03:04.930
networks which we'll see in later
 

00:03:04.930 --> 00:03:07.710
networks which we'll see in later
courses whether or not a new neural

00:03:07.710 --> 00:03:07.720
courses whether or not a new neural
 

00:03:07.720 --> 00:03:09.690
courses whether or not a new neural
network architecture will fit your

00:03:09.690 --> 00:03:09.700
network architecture will fit your
 

00:03:09.700 --> 00:03:11.789
network architecture will fit your
training set vendor is sometimes hard to

00:03:11.789 --> 00:03:11.799
training set vendor is sometimes hard to
 

00:03:11.799 --> 00:03:14.130
training set vendor is sometimes hard to
tell in advance but sometimes you can

00:03:14.130 --> 00:03:14.140
tell in advance but sometimes you can
 

00:03:14.140 --> 00:03:15.630
tell in advance but sometimes you can
get much better results with a better

00:03:15.630 --> 00:03:15.640
get much better results with a better
 

00:03:15.640 --> 00:03:19.650
get much better results with a better
architecture next to the extent that you

00:03:19.650 --> 00:03:19.660
architecture next to the extent that you
 

00:03:19.660 --> 00:03:22.350
architecture next to the extent that you
find out variants is a problem some of

00:03:22.350 --> 00:03:22.360
find out variants is a problem some of
 

00:03:22.360 --> 00:03:23.940
find out variants is a problem some of
the menu of techniques you could try

00:03:23.940 --> 00:03:23.950
the menu of techniques you could try
 

00:03:23.950 --> 00:03:27.240
the menu of techniques you could try
then include the following you can try

00:03:27.240 --> 00:03:27.250
then include the following you can try
 

00:03:27.250 --> 00:03:29.910
then include the following you can try
to get more data because getting more

00:03:29.910 --> 00:03:29.920
to get more data because getting more
 

00:03:29.920 --> 00:03:31.350
to get more data because getting more
data to train on could help you

00:03:31.350 --> 00:03:31.360
data to train on could help you
 

00:03:31.360 --> 00:03:34.740
data to train on could help you
generalize better to death set data that

00:03:34.740 --> 00:03:34.750
generalize better to death set data that
 

00:03:34.750 --> 00:03:37.020
generalize better to death set data that
you have from didn't see you could try

00:03:37.020 --> 00:03:37.030
you have from didn't see you could try
 

00:03:37.030 --> 00:03:40.110
you have from didn't see you could try
regularization so this increasing by l2

00:03:40.110 --> 00:03:40.120
regularization so this increasing by l2
 

00:03:40.120 --> 00:03:45.349
regularization so this increasing by l2
regularization or dropout or data

00:03:45.349 --> 00:03:45.359
regularization or dropout or data
 

00:03:45.359 --> 00:03:49.199
regularization or dropout or data
augmentation we should talked about in

00:03:49.199 --> 00:03:49.209
augmentation we should talked about in
 

00:03:49.209 --> 00:03:52.920
augmentation we should talked about in
the previous course or once again you

00:03:52.920 --> 00:03:52.930
the previous course or once again you
 

00:03:52.930 --> 00:03:55.259
the previous course or once again you
can also try various neural network

00:03:55.259 --> 00:03:55.269
can also try various neural network
 

00:03:55.269 --> 00:03:57.210
can also try various neural network
architecture hybrid parameter search to

00:03:57.210 --> 00:03:57.220
architecture hybrid parameter search to
 

00:03:57.220 --> 00:03:59.550
architecture hybrid parameter search to
see if that can help you find a neural

00:03:59.550 --> 00:03:59.560
see if that can help you find a neural
 

00:03:59.560 --> 00:04:01.110
see if that can help you find a neural
net an architecture that is better

00:04:01.110 --> 00:04:01.120
net an architecture that is better
 

00:04:01.120 --> 00:04:04.110
net an architecture that is better
suited for your problem I think that

00:04:04.110 --> 00:04:04.120
suited for your problem I think that
 

00:04:04.120 --> 00:04:07.170
suited for your problem I think that
this notion of bias or voidable bias and

00:04:07.170 --> 00:04:07.180
this notion of bias or voidable bias and
 

00:04:07.180 --> 00:04:08.699
this notion of bias or voidable bias and
variance is one of those things that

00:04:08.699 --> 00:04:08.709
variance is one of those things that
 

00:04:08.709 --> 00:04:11.849
variance is one of those things that
easily learn but hard to master and

00:04:11.849 --> 00:04:11.859
easily learn but hard to master and
 

00:04:11.859 --> 00:04:13.920
easily learn but hard to master and
you're able to systematically apply the

00:04:13.920 --> 00:04:13.930
you're able to systematically apply the
 

00:04:13.930 --> 00:04:16.080
you're able to systematically apply the
concepts from this week's videos you

00:04:16.080 --> 00:04:16.090
concepts from this week's videos you
 

00:04:16.090 --> 00:04:17.759
concepts from this week's videos you
actually be much more efficient much

00:04:17.759 --> 00:04:17.769
actually be much more efficient much
 

00:04:17.769 --> 00:04:18.110
actually be much more efficient much
more

00:04:18.110 --> 00:04:18.120
more
 

00:04:18.120 --> 00:04:21.530
more
semantics and much more strategic than a

00:04:21.530 --> 00:04:21.540
semantics and much more strategic than a
 

00:04:21.540 --> 00:04:24.110
semantics and much more strategic than a
lot of machine learning teams in terms

00:04:24.110 --> 00:04:24.120
lot of machine learning teams in terms
 

00:04:24.120 --> 00:04:26.060
lot of machine learning teams in terms
of how to systematically go about

00:04:26.060 --> 00:04:26.070
of how to systematically go about
 

00:04:26.070 --> 00:04:27.830
of how to systematically go about
improving the performance of your

00:04:27.830 --> 00:04:27.840
improving the performance of your
 

00:04:27.840 --> 00:04:31.280
improving the performance of your
machine learning system so that this

00:04:31.280 --> 00:04:31.290
machine learning system so that this
 

00:04:31.290 --> 00:04:33.860
machine learning system so that this
week's homework to allow you to practice

00:04:33.860 --> 00:04:33.870
week's homework to allow you to practice
 

00:04:33.870 --> 00:04:36.379
week's homework to allow you to practice
and exercise more your understanding of

00:04:36.379 --> 00:04:36.389
and exercise more your understanding of
 

00:04:36.389 --> 00:04:38.420
and exercise more your understanding of
these concepts that says left with this

00:04:38.420 --> 00:04:38.430
these concepts that says left with this
 

00:04:38.430 --> 00:04:40.219
these concepts that says left with this
week's homework and then look forward to

00:04:40.219 --> 00:04:40.229
week's homework and then look forward to
 

00:04:40.229 --> 00:04:50.060
week's homework and then look forward to
also seeing you in next week's videos

00:04:50.060 --> 00:04:50.070
 

00:04:50.070 --> 00:06:19.350
you

00:06:19.350 --> 00:06:19.360
 

00:06:19.360 --> 00:06:22.650
Aran's is one of the

