WEBVTT
Kind: captions
Language: en

00:00:07.124 --> 00:00:08.290
ANTHONY HOUSE: Hi, everyone.

00:00:08.290 --> 00:00:09.139
Thanks for coming.

00:00:09.139 --> 00:00:11.680
For those of you who don't know
me, my name is Anthony House,

00:00:11.680 --> 00:00:13.860
and I'm from your friendly
Public Policy and Government

00:00:13.860 --> 00:00:14.510
Relations team.

00:00:14.510 --> 00:00:16.830
We sit right over there
on the ninth floor.

00:00:16.830 --> 00:00:20.362
I think we all have
heard of the Dark Net,

00:00:20.362 --> 00:00:22.070
whether that's
technologies like Tor that

00:00:22.070 --> 00:00:24.650
are used by activists or
for less savory purposes.

00:00:24.650 --> 00:00:26.490
Whether that's the Silk
Road or other online

00:00:26.490 --> 00:00:28.890
marketplaces where
you can buy or sell

00:00:28.890 --> 00:00:30.951
illegal goods or services.

00:00:30.951 --> 00:00:32.409
Whether that's the
Fappening, which

00:00:32.409 --> 00:00:34.350
is what I'm told
that the large scale

00:00:34.350 --> 00:00:38.600
publication of naked celebrity
photos is now being called.

00:00:38.600 --> 00:00:40.330
I think it's important
for us to remember

00:00:40.330 --> 00:00:42.600
that this can affect
Google and our users.

00:00:42.600 --> 00:00:44.310
Just today out of
Russia, there was news

00:00:44.310 --> 00:00:47.880
that several million email
accounts and passwords were

00:00:47.880 --> 00:00:49.880
published online,
and our security team

00:00:49.880 --> 00:00:51.940
is hard at work
understanding how

00:00:51.940 --> 00:00:55.306
that affects the people
who use our services.

00:00:55.306 --> 00:00:56.680
It is therefore
a pleasure for me

00:00:56.680 --> 00:00:58.980
to introduce Jamie
Bartlett from Demos who's

00:00:58.980 --> 00:01:01.310
just written a book
on the Dark Net which

00:01:01.310 --> 00:01:03.528
was published last month.

00:01:03.528 --> 00:01:05.319
He's going to give us
some of his thoughts,

00:01:05.319 --> 00:01:07.210
and he's promised to
leave plenty of time

00:01:07.210 --> 00:01:08.640
at the end for questions.

00:01:08.640 --> 00:01:10.890
Please use the
microphone there so

00:01:10.890 --> 00:01:14.210
that the video gets
your audio feed.

00:01:14.210 --> 00:01:15.960
And so without further
ado, please join me

00:01:15.960 --> 00:01:16.790
in welcoming Jamie.

00:01:16.790 --> 00:01:19.290
[APPLAUSE]

00:01:22.639 --> 00:01:24.180
JAMIE BARTLETT:
Well, thanks so much.

00:01:24.180 --> 00:01:25.846
Thanks so much for
having me, everybody.

00:01:25.846 --> 00:01:27.720
So this was the plan.

00:01:27.720 --> 00:01:29.860
I'm going to tell
you roughly why

00:01:29.860 --> 00:01:32.910
I wrote the book and
roughly how I did the book.

00:01:32.910 --> 00:01:35.210
I went about doing the research.

00:01:35.210 --> 00:01:37.810
And then I'm just going
to say four things.

00:01:37.810 --> 00:01:40.340
Four themes that came out
for me that aren't really

00:01:40.340 --> 00:01:42.660
stated in the book
itself, but things

00:01:42.660 --> 00:01:45.730
that I learned as I
went on this journey.

00:01:45.730 --> 00:01:47.560
And I will leave enough
time for questions.

00:01:47.560 --> 00:01:50.020
I reckon I'll only be speaking
for about 25 minutes or so,

00:01:50.020 --> 00:01:51.840
so there should be plenty.

00:01:51.840 --> 00:01:52.750
So the book itself.

00:01:55.930 --> 00:01:57.765
Over the last five
years, but especially

00:01:57.765 --> 00:01:59.140
over the last
couple of years, it

00:01:59.140 --> 00:02:01.190
will be no surprise
to any of you

00:02:01.190 --> 00:02:04.560
that we keeping little
glimpses of people

00:02:04.560 --> 00:02:06.290
doing bad stuff online.

00:02:06.290 --> 00:02:07.540
More than a glimpse, actually.

00:02:07.540 --> 00:02:10.530
Increasingly it seems
like an avalanche.

00:02:10.530 --> 00:02:13.860
Whether that's child abuse
images, people buying drugs

00:02:13.860 --> 00:02:17.510
from the Silk Road, everyone
seems to be a troll nowadays.

00:02:17.510 --> 00:02:19.090
By the way-- is
this being filmed?

00:02:19.090 --> 00:02:20.475
Is this going to be made public?

00:02:20.475 --> 00:02:22.930
I'll say it anyway.

00:02:22.930 --> 00:02:25.680
We were trolled by Mary
Beard recently at Demos

00:02:25.680 --> 00:02:30.890
because we'd incorrectly
used a poor Latin translation

00:02:30.890 --> 00:02:32.050
of our Demos pamphlet.

00:02:32.050 --> 00:02:32.730
Vox digitas.

00:02:32.730 --> 00:02:37.900
It should've been Vox digitalis
or some derivation on that.

00:02:37.900 --> 00:02:40.450
And so she started sending
us angry Twitter messages

00:02:40.450 --> 00:02:41.540
about it.

00:02:41.540 --> 00:02:42.810
So everyone suddenly a troll.

00:02:42.810 --> 00:02:46.000
2% of British adults say
that they have actually

00:02:46.000 --> 00:02:48.886
insulted a complete
stranger online, which

00:02:48.886 --> 00:02:51.260
means at least one of you in
here has probably done that.

00:02:51.260 --> 00:02:54.510
And would make two million
people in the UK as a whole.

00:02:54.510 --> 00:02:57.170
So we keep getting these
little flashes of communities

00:02:57.170 --> 00:03:01.160
and cultures somewhere
underneath the surface of what

00:03:01.160 --> 00:03:05.907
we think to be the internet
we all know and love.

00:03:05.907 --> 00:03:07.990
But the thing that always
frustrated me about this

00:03:07.990 --> 00:03:10.120
was that you never got
more than just a glimpse.

00:03:10.120 --> 00:03:12.320
And you never really
learned about the people

00:03:12.320 --> 00:03:14.810
that were in these
communities and cultures.

00:03:14.810 --> 00:03:19.585
You'd just see a tabloid
scare story about it.

00:03:19.585 --> 00:03:22.700
And you'd never really
understand where it came from

00:03:22.700 --> 00:03:25.940
and why people were doing it
and what was really happening.

00:03:25.940 --> 00:03:29.130
So I set myself the
following challenge.

00:03:29.130 --> 00:03:33.890
That I would spend a year
in some of the internet's

00:03:33.890 --> 00:03:37.520
darkest, most shocking--
seemingly shocking--

00:03:37.520 --> 00:03:38.500
subcultures.

00:03:38.500 --> 00:03:42.600
And I would try to meet the
people that inhabited them.

00:03:42.600 --> 00:03:45.750
And the result was
"The Dark Net."

00:03:45.750 --> 00:03:49.200
Now for me, "The Dark
Net"-- when I came up

00:03:49.200 --> 00:03:52.000
with this title over
year ago, the Dark Net

00:03:52.000 --> 00:03:55.750
wasn't the thing that everybody
was talking about, meaning

00:03:55.750 --> 00:03:59.100
Tor hidden services and this
encrypted part of the net

00:03:59.100 --> 00:04:01.520
that you can only
access using Tor.

00:04:01.520 --> 00:04:04.860
For me, I called it the
Dark Net because I thought

00:04:04.860 --> 00:04:07.780
it was this obscure set of
cultures and communities

00:04:07.780 --> 00:04:10.250
that hadn't really
been explored and where

00:04:10.250 --> 00:04:13.530
the darker shades of human
nature were on display.

00:04:13.530 --> 00:04:15.390
That, for me, was the Dark Net.

00:04:15.390 --> 00:04:18.465
Now part of the book is
indeed about what we now

00:04:18.465 --> 00:04:20.339
call the Dark Net, these
Tor hidden services.

00:04:20.339 --> 00:04:23.030
And I'll talk about
those in a second.

00:04:23.030 --> 00:04:25.280
But just as much
of it was password

00:04:25.280 --> 00:04:29.420
protected Facebook
groups, Twitter accounts,

00:04:29.420 --> 00:04:31.990
pro-anorexia sites and forums.

00:04:31.990 --> 00:04:33.430
Any part of the
internet, really,

00:04:33.430 --> 00:04:37.550
where people use their
perceived or real anonymity

00:04:37.550 --> 00:04:41.080
or pseudonymity to
stretch, I suppose,

00:04:41.080 --> 00:04:44.340
the limits of human
freedom and expression

00:04:44.340 --> 00:04:46.690
to some of those darker places.

00:04:46.690 --> 00:04:49.330
And so over the
course of a year,

00:04:49.330 --> 00:04:53.470
I became a moderator
of a trolling group.

00:04:53.470 --> 00:04:54.920
I can't tell you where it was.

00:04:54.920 --> 00:04:58.790
And I met a handful of
pretty extreme trolls.

00:04:58.790 --> 00:05:01.650
I spent loads of time with
neo-Nazis in pubs up and down

00:05:01.650 --> 00:05:05.560
the country who use Twitter
and Facebook in particular

00:05:05.560 --> 00:05:08.230
to spread their propaganda
and their message.

00:05:08.230 --> 00:05:11.410
I was off to a squat in
Barcelona with Amir Takki,

00:05:11.410 --> 00:05:15.180
if any of you know him,
creator of the Darkwallet,

00:05:15.180 --> 00:05:18.821
an application for bitcoin
that makes it a little bit more

00:05:18.821 --> 00:05:19.320
anonymous.

00:05:19.320 --> 00:05:21.480
A little bit harder
to trace and track.

00:05:21.480 --> 00:05:24.120
A little bit more of
a frustrating thing

00:05:24.120 --> 00:05:26.910
for governments to
have to deal with.

00:05:26.910 --> 00:05:32.340
Favorite bit, I went to a
live cam show of three women

00:05:32.340 --> 00:05:35.150
performing sexually
explicit acts together

00:05:35.150 --> 00:05:39.520
on the screen for thousands
of paying customers.

00:05:39.520 --> 00:05:42.170
I actually ended up getting
pulled into the show myself.

00:05:42.170 --> 00:05:43.570
Don't try and find that.

00:05:43.570 --> 00:05:46.570
You might if you
look hard enough.

00:05:46.570 --> 00:05:50.440
And I bought drugs off the
Silk Road, naturally enough.

00:05:50.440 --> 00:05:54.170
Went into pro-anorexia and
pro-suicide forums and sites.

00:05:54.170 --> 00:05:56.480
And in each case,
tried to look at it

00:05:56.480 --> 00:05:59.140
as objectively as
I possibly could.

00:05:59.140 --> 00:06:01.050
To stand back and not judge.

00:06:01.050 --> 00:06:04.000
This is not a
polemical book at all.

00:06:04.000 --> 00:06:07.650
It's a series of portraits to
hopefully get people thinking

00:06:07.650 --> 00:06:11.080
and to get people a little
bit more au fait with what's

00:06:11.080 --> 00:06:13.980
going on in these places.

00:06:13.980 --> 00:06:17.440
And overall, what I find--
in fact, what you always

00:06:17.440 --> 00:06:20.540
find when you look at
something more closely--

00:06:20.540 --> 00:06:25.670
it's never quite as black
and white as you imagine.

00:06:25.670 --> 00:06:28.300
I went in there expecting
to be shocked and appalled,

00:06:28.300 --> 00:06:33.430
and I came out very confused.

00:06:33.430 --> 00:06:37.680
Moral ambiguity is
probably the single line

00:06:37.680 --> 00:06:40.274
I use most in this book.

00:06:40.274 --> 00:06:41.440
So that's what the book was.

00:06:41.440 --> 00:06:42.870
That's how I went
about doing it.

00:06:42.870 --> 00:06:45.320
And I'll leave
time for questions

00:06:45.320 --> 00:06:47.680
if you want any of the
more specific details.

00:06:47.680 --> 00:06:51.280
And I want to talk
about four things.

00:06:51.280 --> 00:06:55.510
Innovation and how creative and
innovative these places are.

00:06:55.510 --> 00:06:58.350
This moral ambiguity point.

00:06:58.350 --> 00:07:02.610
The empathy that I felt
meeting people that I thought

00:07:02.610 --> 00:07:05.600
I would detest, and then
meeting them in real life

00:07:05.600 --> 00:07:08.150
and finding actually
I didn't detest them

00:07:08.150 --> 00:07:10.940
quite as much as I expected.

00:07:10.940 --> 00:07:14.760
And normalization
and how certain

00:07:14.760 --> 00:07:18.760
behaviors come to be and
feel to be extraordinarily

00:07:18.760 --> 00:07:20.840
normal and ordinary if
you surround yourself

00:07:20.840 --> 00:07:22.640
with them for long enough.

00:07:22.640 --> 00:07:23.960
So there are the four themes.

00:07:23.960 --> 00:07:25.918
Let me have a swig of
water before I get going.

00:07:29.770 --> 00:07:31.240
OK.

00:07:31.240 --> 00:07:35.130
So let's start with the
creativity of these sites.

00:07:35.130 --> 00:07:38.090
Has anyone ever been
on the Silk Road?

00:07:38.090 --> 00:07:40.140
No one ever puts their
hands up to that question.

00:07:40.140 --> 00:07:41.890
But I know some of
you probably have.

00:07:41.890 --> 00:07:45.000
So-- there's a hand.

00:07:45.000 --> 00:07:47.170
So the Silk Road, as I'm
sure you're aware-- well,

00:07:47.170 --> 00:07:49.550
it's actually now Silk Road
2.0 since the original got

00:07:49.550 --> 00:07:53.390
shut down in November or
late October last year--

00:07:53.390 --> 00:07:58.030
is an online marketplace
where anything and everything

00:07:58.030 --> 00:08:01.800
with a couple of tiny exceptions
like personal identification

00:08:01.800 --> 00:08:04.530
and child pornography
and now weapons,

00:08:04.530 --> 00:08:08.160
is available to buy and sell.

00:08:08.160 --> 00:08:11.950
This is only accessible
with a Tor browser.

00:08:11.950 --> 00:08:14.000
It's a Tor hidden service,
and that essentially

00:08:14.000 --> 00:08:16.330
means the servers are
very hard to locate.

00:08:16.330 --> 00:08:19.740
And anyone using it uses
various types of encryption

00:08:19.740 --> 00:08:21.890
which makes them
very hard to locate.

00:08:21.890 --> 00:08:25.820
And essentially you can buy
and sell drugs remarkably easy

00:08:25.820 --> 00:08:28.110
on that site.

00:08:28.110 --> 00:08:31.140
Now everybody thinks
about the Silk Road

00:08:31.140 --> 00:08:34.780
as being driven by
encryption systems.

00:08:34.780 --> 00:08:37.679
You have to use bitcoin,
the crypto currency,

00:08:37.679 --> 00:08:39.230
to buy your products.

00:08:39.230 --> 00:08:41.331
You need Tor to be
able to access it.

00:08:41.331 --> 00:08:42.789
Actually you can
do it without Tor,

00:08:42.789 --> 00:08:44.330
but it's a very bad
idea, because you

00:08:44.330 --> 00:08:45.940
can be traced if you do that.

00:08:45.940 --> 00:08:51.200
You communicate using
pretty good encryption,

00:08:51.200 --> 00:08:52.920
PGP encryption.

00:08:52.920 --> 00:08:55.780
And people think
that's the secret.

00:08:55.780 --> 00:08:58.210
That's the trick
of the Silk Road.

00:08:58.210 --> 00:09:02.430
But that's not the secret
of the Silk Road at all.

00:09:02.430 --> 00:09:05.250
And in my chapter, I bought
a very, very small amount

00:09:05.250 --> 00:09:07.270
of marijuana.

00:09:07.270 --> 00:09:11.360
Just a gram or
something like that.

00:09:11.360 --> 00:09:13.490
The reason people
use the Silk Road

00:09:13.490 --> 00:09:20.170
is because it has introduced a
genuine market in an industry

00:09:20.170 --> 00:09:22.320
which has been
traditionally dominated

00:09:22.320 --> 00:09:24.310
by cartels and monopolies.

00:09:24.310 --> 00:09:27.520
So if you go and buy
drugs on the street,

00:09:27.520 --> 00:09:30.287
your choice is limited to
whatever dealer you know

00:09:30.287 --> 00:09:33.510
and whatever products
they happen to have.

00:09:33.510 --> 00:09:36.900
You have no real comeback
mechanism on that.

00:09:36.900 --> 00:09:41.410
You have no real choice if you
don't like what you're getting.

00:09:41.410 --> 00:09:45.090
And as a result, you
the consumer, suffers.

00:09:45.090 --> 00:09:48.345
You go to the Silk
Road, you have a choice

00:09:48.345 --> 00:09:53.200
of between around a thousand
vendors, all of whom

00:09:53.200 --> 00:09:55.170
are competing for your custom.

00:09:55.170 --> 00:09:59.480
All of whom you can
communicate with and talk to.

00:09:59.480 --> 00:10:03.560
All of whom are
rated out of five

00:10:03.560 --> 00:10:06.600
for the quality of the
products that they've given you

00:10:06.600 --> 00:10:09.580
and how good their
customer service was.

00:10:09.580 --> 00:10:10.730
How attentive they were.

00:10:10.730 --> 00:10:13.540
How good the postage
and delivery was.

00:10:13.540 --> 00:10:15.620
And you know,
guess what happens?

00:10:15.620 --> 00:10:16.820
What a surprise.

00:10:16.820 --> 00:10:22.310
They are unbelievably attentive,
helpful, and completely focused

00:10:22.310 --> 00:10:24.932
on making sure you, the
consumer, are content.

00:10:24.932 --> 00:10:26.390
Because if you're
not, you're going

00:10:26.390 --> 00:10:28.360
to give them a bad review.

00:10:28.360 --> 00:10:33.430
And everything in this anonymous
world depends on reputation.

00:10:33.430 --> 00:10:36.210
And so they work bloody
hard to make sure

00:10:36.210 --> 00:10:38.460
they have a good reputation.

00:10:38.460 --> 00:10:39.720
So I emailed one.

00:10:39.720 --> 00:10:40.745
Drugs Heaven.

00:10:40.745 --> 00:10:43.970
Dear Sir, I'm new to this site.

00:10:43.970 --> 00:10:47.770
I only want to buy a
small amount of marijuana.

00:10:47.770 --> 00:10:49.320
Could you please advise?

00:10:49.320 --> 00:10:54.780
Drugs Heaven had an unbelievably
wide array of products.

00:10:54.780 --> 00:10:57.120
Replied within
three or four hours.

00:10:57.120 --> 00:11:00.720
Dear Sir, thank you
so much your inquiry.

00:11:00.720 --> 00:11:01.730
I completely agree.

00:11:01.730 --> 00:11:03.400
As a new vendor, I
too would probably

00:11:03.400 --> 00:11:05.480
start with a small amount.

00:11:05.480 --> 00:11:07.790
Perhaps you'd like to
try x, y, and z product.

00:11:07.790 --> 00:11:11.860
This is really highly
recommended by my other users.

00:11:11.860 --> 00:11:14.182
I do hope we can do
business together.

00:11:14.182 --> 00:11:15.140
It would be a pleasure.

00:11:15.140 --> 00:11:17.140
Any more questions,
please let me know.

00:11:17.140 --> 00:11:17.990
Best wishes.

00:11:17.990 --> 00:11:19.307
Drugs Heaven.

00:11:19.307 --> 00:11:22.230
[LAUGHTER]

00:11:22.230 --> 00:11:26.220
Product arrived three
or four days later.

00:11:26.220 --> 00:11:27.720
My friends tell me
it was very good.

00:11:31.360 --> 00:11:34.140
So I gave a review.

00:11:34.140 --> 00:11:36.400
And that's how it works.

00:11:36.400 --> 00:11:37.540
And you know what, thought?

00:11:37.540 --> 00:11:39.470
And this will lead me
onto my second point

00:11:39.470 --> 00:11:41.320
about moral ambiguity.

00:11:41.320 --> 00:11:43.800
Think about it for a second.

00:11:43.800 --> 00:11:47.260
If you are ingesting
drugs, you need

00:11:47.260 --> 00:11:51.160
to know the purity of the
drugs that you're getting.

00:11:51.160 --> 00:11:53.140
You need to have
a system to know

00:11:53.140 --> 00:11:55.630
that it's not being
laced with anthrax.

00:11:55.630 --> 00:11:58.680
14 people died of heroin
being laced with anthrax

00:11:58.680 --> 00:12:00.660
a couple of years
ago in Glasgow.

00:12:00.660 --> 00:12:03.050
That doesn't really
happen on the Silk Road,

00:12:03.050 --> 00:12:06.920
because the vendors are so
worried about their reputation.

00:12:06.920 --> 00:12:09.350
You need to know how pure
your drug is, because you need

00:12:09.350 --> 00:12:12.660
to be able to predict how your
body's going to react to that.

00:12:12.660 --> 00:12:15.950
And on the Silk Road,
there is a remarkable array

00:12:15.950 --> 00:12:19.000
of consumer led feedback
on every single product.

00:12:19.000 --> 00:12:19.830
How strong is it.

00:12:19.830 --> 00:12:20.870
How should you mix it.

00:12:20.870 --> 00:12:21.800
What should you do it.

00:12:21.800 --> 00:12:24.910
What's the best way of
responding if things go wrong.

00:12:24.910 --> 00:12:28.970
This is a remarkably
innovative system,

00:12:28.970 --> 00:12:32.430
but incredibly familiar to
anybody that's been on Amazon

00:12:32.430 --> 00:12:33.320
or eBay.

00:12:33.320 --> 00:12:36.180
But one that you would not
expect to find in this place.

00:12:36.180 --> 00:12:38.970
And they have an
incredible array

00:12:38.970 --> 00:12:43.290
of ways in which people
can mask their identity.

00:12:43.290 --> 00:12:44.665
The great difficulty
on somewhere

00:12:44.665 --> 00:12:47.040
like the Silk Road is, of
course, everything you're doing

00:12:47.040 --> 00:12:48.080
is completely illegal.

00:12:48.080 --> 00:12:50.210
So you can't phone up the
police-- and some people

00:12:50.210 --> 00:12:51.870
have done this--
phone up the police

00:12:51.870 --> 00:12:54.036
and complain about the fact
that their drugs weren't

00:12:54.036 --> 00:12:55.350
quite good enough.

00:12:55.350 --> 00:12:58.040
You're going to get
in trouble for that.

00:12:58.040 --> 00:13:01.400
And the problem is, of course,
drugs dealers on the whole

00:13:01.400 --> 00:13:04.490
tend to be not very reliable.

00:13:04.490 --> 00:13:06.760
And they can run
off with your money.

00:13:06.760 --> 00:13:08.310
They can run off
with your bitcoin.

00:13:08.310 --> 00:13:12.430
Or the police can raid the
Silk Road, shut it down,

00:13:12.430 --> 00:13:14.552
and all of your bitcoins vanish.

00:13:14.552 --> 00:13:15.510
So what have they done?

00:13:15.510 --> 00:13:18.545
They've created something
called multi-signature escrow.

00:13:18.545 --> 00:13:21.120
It's a bit laborious.

00:13:21.120 --> 00:13:23.740
But it's a bit like
a payment system

00:13:23.740 --> 00:13:27.660
where you need all three keys
to turn to open the lock.

00:13:27.660 --> 00:13:32.010
So the vendor needs to put
his digital signature in.

00:13:32.010 --> 00:13:35.710
The seller does when he
or she receives the goods.

00:13:35.710 --> 00:13:37.310
The site needs to
when they think

00:13:37.310 --> 00:13:39.150
that the transaction's
been completed.

00:13:39.150 --> 00:13:42.890
And at that point, the money's
transferred over from the buyer

00:13:42.890 --> 00:13:45.287
to the seller, and
everybody's happy.

00:13:45.287 --> 00:13:47.870
And if something goes wrong, the
money goes back to the buyer.

00:13:47.870 --> 00:13:51.930
And this was an innovation
that the community developed

00:13:51.930 --> 00:13:55.222
within about three months of the
original Silk Road going down,

00:13:55.222 --> 00:13:57.430
because people thought that
the payment mechanism was

00:13:57.430 --> 00:13:58.512
too centralized.

00:13:58.512 --> 00:13:59.720
And it was not to be trusted.

00:13:59.720 --> 00:14:03.080
We need to decentralize how
payments work so that everyone

00:14:03.080 --> 00:14:06.200
involved in the transaction
has to sign it off.

00:14:06.200 --> 00:14:09.110
The Silk Road is
remarkably innovative.

00:14:09.110 --> 00:14:10.900
And it has to be.

00:14:10.900 --> 00:14:12.240
It has to be.

00:14:12.240 --> 00:14:17.910
Creativity, innovation, the
mother of all necessity.

00:14:17.910 --> 00:14:19.280
Right on the edge.

00:14:19.280 --> 00:14:22.755
And they have to work
out ways of operating

00:14:22.755 --> 00:14:25.330
in a uniquely
hostile environment.

00:14:25.330 --> 00:14:26.180
That's point one.

00:14:26.180 --> 00:14:28.135
Innovation.

00:14:28.135 --> 00:14:28.635
The second.

00:14:31.129 --> 00:14:32.420
And I felt it in the Silk Road.

00:14:32.420 --> 00:14:34.190
This moral ambiguity.

00:14:34.190 --> 00:14:35.940
Going into these
places and thinking,

00:14:35.940 --> 00:14:38.670
I knew what was wrong here and
I knew what I'd think about it.

00:14:38.670 --> 00:14:41.130
And then coming out
being not quite so sure.

00:14:41.130 --> 00:14:43.210
Now the hardest
chapter I had to write

00:14:43.210 --> 00:14:47.060
was about suicide forums
and pro-anorexia forums.

00:14:47.060 --> 00:14:49.870
So these are the
places that encourage

00:14:49.870 --> 00:14:51.870
people to view
those mental health

00:14:51.870 --> 00:14:54.897
conditions-- and
anorexia is actually

00:14:54.897 --> 00:14:56.980
one of the most dangerous
mental health conditions

00:14:56.980 --> 00:14:59.830
that there is-- as something
of a lifestyle choice.

00:14:59.830 --> 00:15:00.639
A culture.

00:15:00.639 --> 00:15:01.680
Something to be embraced.

00:15:01.680 --> 00:15:04.430
Something to be encouraged.

00:15:04.430 --> 00:15:05.690
This was the most difficult.

00:15:05.690 --> 00:15:07.898
Of all the chapters, it was
the hardest one to write.

00:15:07.898 --> 00:15:10.880
It was really distressing
to go into these forums.

00:15:10.880 --> 00:15:15.660
We're often talking about
very young teenage girls who

00:15:15.660 --> 00:15:20.904
are extremely depressed, are
starving themselves of food,

00:15:20.904 --> 00:15:22.320
and suffering
greatly as a result.

00:15:22.320 --> 00:15:25.670
And it's a very similar
picture on the suicide forums.

00:15:25.670 --> 00:15:27.840
And actually just today--
I don't know if any of you

00:15:27.840 --> 00:15:31.310
saw this-- but just today,
William Melchert-Dinkel

00:15:31.310 --> 00:15:33.550
was convicted in
the Supreme Court

00:15:33.550 --> 00:15:36.730
for having encouraged
somebody and assisted them

00:15:36.730 --> 00:15:40.875
in committing suicide through--
it's a usenet group called ASH,

00:15:40.875 --> 00:15:42.895
Alt Suicide Holiday,
where people go

00:15:42.895 --> 00:15:45.860
and openly talk about methods
for committing suicide.

00:15:45.860 --> 00:15:48.190
And what this guy did,
under a pseudonym,

00:15:48.190 --> 00:15:51.090
was to pretend that he,
too, was extremely suicidal.

00:15:51.090 --> 00:15:54.490
And would encourage other people
that were in the forum with him

00:15:54.490 --> 00:15:56.110
to create a suicide pact.

00:15:56.110 --> 00:15:58.410
People that commit
suicide often feel

00:15:58.410 --> 00:16:01.080
they need someone to
commit suicide with.

00:16:01.080 --> 00:16:04.487
He would create a pact with
someone and say, you go first,

00:16:04.487 --> 00:16:06.570
and I'll watch on the
webcam, and then I'll do it.

00:16:06.570 --> 00:16:07.903
And, of course, he never did it.

00:16:07.903 --> 00:16:11.220
He was pretending to be
a 30-year-old nurse, when

00:16:11.220 --> 00:16:15.270
in fact he was a 50-year-old
middle aged married man.

00:16:15.270 --> 00:16:18.090
And he was convicted,
again-- it was overturned.

00:16:18.090 --> 00:16:20.770
It was overturned in the
Supreme Court yesterday.

00:16:20.770 --> 00:16:23.340
So it's extremely
depressing and difficult.

00:16:23.340 --> 00:16:26.160
But here's the thing about
those suicide forums.

00:16:26.160 --> 00:16:29.040
I met a number of people
who credit those suicide

00:16:29.040 --> 00:16:32.100
forums for saving their lives.

00:16:32.100 --> 00:16:35.030
Because it was the
only place they

00:16:35.030 --> 00:16:40.197
felt they could go and speak
with people who understood

00:16:40.197 --> 00:16:42.030
them, that were going
through the same thing

00:16:42.030 --> 00:16:45.420
as they were going through
and wouldn't be judgmental.

00:16:45.420 --> 00:16:48.460
It was something of a
release, the opportunity

00:16:48.460 --> 00:16:51.310
to be able to just
share-- almost

00:16:51.310 --> 00:16:54.600
expel some of your fantasies
about committing suicide.

00:16:54.600 --> 00:16:58.004
Suicidal ideation is
where people often

00:16:58.004 --> 00:16:59.920
have these fantasies
about committing suicide.

00:16:59.920 --> 00:17:02.700
And just being able to talk
about that with people that

00:17:02.700 --> 00:17:05.510
wouldn't judge you or demand
that you go and see a shrink

00:17:05.510 --> 00:17:09.329
or demand that you go and
tell your family immediately

00:17:09.329 --> 00:17:12.500
how you're feeling, was
incredibly relieving.

00:17:12.500 --> 00:17:16.040
And I met people that have been
using these forums for years

00:17:16.040 --> 00:17:18.510
and years and years.

00:17:18.510 --> 00:17:22.099
Now all of us-- most of
us, rather-- whenever

00:17:22.099 --> 00:17:25.226
we're feeling
unwell, we go online.

00:17:25.226 --> 00:17:26.100
I mean, I've done it.

00:17:26.100 --> 00:17:28.880
I recently had ACL
surgery on my knee.

00:17:28.880 --> 00:17:31.380
It's why I'm sort
of limping around.

00:17:31.380 --> 00:17:36.360
And I just-- your
GP's not open all day.

00:17:36.360 --> 00:17:38.340
And you're late at
night, terrified.

00:17:38.340 --> 00:17:39.350
This feels really weird.

00:17:39.350 --> 00:17:40.440
What's going on?

00:17:40.440 --> 00:17:43.435
And you go for every bit of
information, you go online.

00:17:43.435 --> 00:17:44.810
And you try and
find other people

00:17:44.810 --> 00:17:48.499
and get advice from them, see
what they've gone through.

00:17:48.499 --> 00:17:51.040
If anyone's done that-- and I'm
sure a lot of you have-- it's

00:17:51.040 --> 00:17:53.390
actually terrifying.

00:17:53.390 --> 00:17:54.890
There's been quite
a lot of research

00:17:54.890 --> 00:17:58.620
on Dr. Google and the
way that certain types--

00:17:58.620 --> 00:18:01.450
if you put in chest pain, I
think something like heart

00:18:01.450 --> 00:18:04.960
attacks comes up higher in
the ranking than indigestion,

00:18:04.960 --> 00:18:07.890
or whatever it is.

00:18:07.890 --> 00:18:10.130
But that's where people go now.

00:18:10.130 --> 00:18:13.770
And people who are lonely
and who are depressed,

00:18:13.770 --> 00:18:16.510
to be able to find other people
like them, for some of them

00:18:16.510 --> 00:18:18.990
it's incredibly,
incredibly helpful.

00:18:18.990 --> 00:18:23.414
And for others, they might
meet a William Melchert-Dinkel

00:18:23.414 --> 00:18:25.080
who will try and push
them over the edge

00:18:25.080 --> 00:18:27.190
and encourage them
to commit suicide.

00:18:27.190 --> 00:18:29.630
And I came out of
that thinking, well.

00:18:29.630 --> 00:18:30.890
I'm not really sure anymore.

00:18:30.890 --> 00:18:34.490
I assumed I'd just want
these things shut down.

00:18:34.490 --> 00:18:36.010
Now I think, I don't
think I do want

00:18:36.010 --> 00:18:38.070
these suicide forums shut down.

00:18:38.070 --> 00:18:40.030
I think I'd rather
they were moderated.

00:18:40.030 --> 00:18:43.000
I think I'd rather there were
people, professionals in them.

00:18:43.000 --> 00:18:44.750
Where people could go
anonymously and talk

00:18:44.750 --> 00:18:46.291
about it and a
professional-- someone

00:18:46.291 --> 00:18:49.240
from the Samaritans, whatever--
would be in there moderating

00:18:49.240 --> 00:18:51.550
the conversation and
discussion to make sure

00:18:51.550 --> 00:18:52.720
it didn't get out of hand.

00:18:52.720 --> 00:18:54.930
But to allow people to have
the opportunity to speak.

00:18:59.900 --> 00:19:01.590
Third thing.

00:19:01.590 --> 00:19:03.080
Empathy.

00:19:03.080 --> 00:19:08.910
So very first person I
met writing this book

00:19:08.910 --> 00:19:17.650
was a really virulent,
angry, radical neo-Nazi

00:19:17.650 --> 00:19:20.760
who I call Paul.

00:19:20.760 --> 00:19:26.690
He spends 95% percent of his
time, he tells me online.

00:19:26.690 --> 00:19:33.080
Facebook, Twitter, YouTube,
blogging about white pride.

00:19:33.080 --> 00:19:37.020
And about how we need
to restore Britain

00:19:37.020 --> 00:19:40.960
to its original entirely
white population.

00:19:40.960 --> 00:19:42.280
Get rid of all the immigrants.

00:19:42.280 --> 00:19:44.170
Get rid of all the newcomers.

00:19:44.170 --> 00:19:49.110
He's angry and he's frustrated
and he's extraordinarily nasty

00:19:49.110 --> 00:19:51.290
and mean online.

00:19:51.290 --> 00:19:52.230
So I went to meet him.

00:19:52.230 --> 00:19:53.720
After a lot of negotiating.

00:19:53.720 --> 00:19:55.400
I'd met him online.

00:19:55.400 --> 00:19:56.940
And I went up to
the small town--

00:19:56.940 --> 00:19:59.332
he lives up north-- to meet him.

00:19:59.332 --> 00:20:00.540
I didn't know what to expect.

00:20:00.540 --> 00:20:01.915
I had no idea what
he looks like.

00:20:01.915 --> 00:20:04.066
He never shares any
pictures of himself.

00:20:04.066 --> 00:20:05.680
And this guy comes up to me.

00:20:05.680 --> 00:20:06.660
Handsome guy.

00:20:06.660 --> 00:20:07.950
Tattoos.

00:20:07.950 --> 00:20:08.870
Spiky hair.

00:20:08.870 --> 00:20:12.480
And he's like, you're Jamie
Bartlett off the television.

00:20:12.480 --> 00:20:14.280
I can't believe
you've actually come.

00:20:14.280 --> 00:20:16.210
I'm so pleased to meet you.

00:20:16.210 --> 00:20:17.700
And it was him.

00:20:17.700 --> 00:20:19.190
It was Paul.

00:20:19.190 --> 00:20:25.040
He was-- it's quite hard to
say, but I really liked him.

00:20:25.040 --> 00:20:26.710
I really liked him.

00:20:26.710 --> 00:20:29.050
I felt so sorry for him.

00:20:29.050 --> 00:20:30.930
Every time we talked
about anything

00:20:30.930 --> 00:20:34.780
that wasn't to do with
immigration and race,

00:20:34.780 --> 00:20:37.500
we got on very,
very well indeed.

00:20:37.500 --> 00:20:40.080
We had a great laugh talking
about football teams and this

00:20:40.080 --> 00:20:40.900
and that.

00:20:40.900 --> 00:20:44.380
Really got on well with him.

00:20:44.380 --> 00:20:50.990
And then the minute I saw him
again online, it broke down.

00:20:50.990 --> 00:20:53.790
And he started being angry
and vicious and frustrated

00:20:53.790 --> 00:20:55.770
and annoyed about everything.

00:20:55.770 --> 00:20:58.820
And obviously, it's
extremely difficult

00:20:58.820 --> 00:21:01.170
to work out precisely
what's going on in his head

00:21:01.170 --> 00:21:02.170
and why he's doing that.

00:21:02.170 --> 00:21:04.430
But I think what's happened
to him in particular--

00:21:04.430 --> 00:21:09.050
and it's happening to a lot
of people-- he started off

00:21:09.050 --> 00:21:12.500
with no real interest
in far right politics.

00:21:12.500 --> 00:21:15.220
But nothing was going
on in his life at all.

00:21:15.220 --> 00:21:18.750
And I really felt sorry for him
as we walked around his town.

00:21:18.750 --> 00:21:21.050
And he said how he'd love
to get involved in politics.

00:21:21.050 --> 00:21:23.120
He'd love to move
to a bigger city.

00:21:23.120 --> 00:21:24.310
He left school at 16.

00:21:24.310 --> 00:21:26.760
He's got no
qualifications whatsoever.

00:21:26.760 --> 00:21:29.720
We both knew it was
never going to happen.

00:21:29.720 --> 00:21:33.440
But he has created
an identity online

00:21:33.440 --> 00:21:36.550
that is far more exciting,
far more meaningful,

00:21:36.550 --> 00:21:38.840
than anything he does offline.

00:21:38.840 --> 00:21:41.800
He has thousands of people
that listen to his stuff.

00:21:41.800 --> 00:21:46.700
He's almost boxed himself in,
because his identity online is

00:21:46.700 --> 00:21:51.640
the source of so much
self-gratification and meaning

00:21:51.640 --> 00:21:54.221
in his life, that
he's stuck doing that.

00:21:54.221 --> 00:21:55.720
He can't break out
of it, because he

00:21:55.720 --> 00:21:57.910
has to carry on with
that type of behavior

00:21:57.910 --> 00:22:00.130
and that language to
keep his fans happy.

00:22:00.130 --> 00:22:02.660
To keep the people that
listen to him happy.

00:22:02.660 --> 00:22:07.590
And so he's a bit trapped in
an online identity entirely

00:22:07.590 --> 00:22:08.850
of his own making.

00:22:08.850 --> 00:22:10.330
And he got there gradually.

00:22:10.330 --> 00:22:15.690
He started off
being mildly racist.

00:22:15.690 --> 00:22:17.830
Let's put it like that.

00:22:17.830 --> 00:22:21.860
Then he would have interactions
with Muslims, in particular,

00:22:21.860 --> 00:22:24.059
on Facebook walls.

00:22:24.059 --> 00:22:26.100
Where if anyone's been on
a hostile Facebook wall

00:22:26.100 --> 00:22:28.230
where things are
going to and fro,

00:22:28.230 --> 00:22:30.540
it really gets quite nasty
quite quickly, doesn't it?

00:22:30.540 --> 00:22:33.330
And it degenerates
a bit like a comment

00:22:33.330 --> 00:22:38.260
is free comment section.

00:22:38.260 --> 00:22:43.280
The law of Nazi analogies, that
a longer conversation goes on,

00:22:43.280 --> 00:22:45.050
the probability that
one person refers

00:22:45.050 --> 00:22:47.580
to the other as a
Nazi approaches one.

00:22:47.580 --> 00:22:50.700
Which, ironically in this
case, is actually true.

00:22:50.700 --> 00:22:54.180
In the case of Paul.

00:22:54.180 --> 00:22:57.590
But each side created demons
and enemies of each other.

00:22:57.590 --> 00:23:01.725
This one sided, one dimensional
version of themselves

00:23:01.725 --> 00:23:05.120
that would constantly clash and
just harden each other's views

00:23:05.120 --> 00:23:12.080
in this strange echo chamber, to
the point where Paul has become

00:23:12.080 --> 00:23:18.410
an extremely committed neo-Nazi.

00:23:18.410 --> 00:23:20.490
But here's the strangest
thing about it.

00:23:20.490 --> 00:23:24.060
He told me one story and
it really sticks with me.

00:23:24.060 --> 00:23:25.370
He lives on his own.

00:23:25.370 --> 00:23:27.370
Doesn't really have much
going on, as I've said.

00:23:27.370 --> 00:23:28.890
One day-- it's a
very small town--

00:23:28.890 --> 00:23:33.400
one day about a year or so ago,
some supporters of the English

00:23:33.400 --> 00:23:36.060
Defence League-- you guys know
the English Defense League,

00:23:36.060 --> 00:23:41.410
EDL guys who [INAUDIBLE]--
they're hard to pin down,

00:23:41.410 --> 00:23:41.910
exactly.

00:23:41.910 --> 00:23:43.660
They're an interesting
group, because they

00:23:43.660 --> 00:23:46.170
started on Facebook and then
went into the real world

00:23:46.170 --> 00:23:46.670
after that.

00:23:49.820 --> 00:23:52.710
He started as a member of
the English Defence League.

00:23:52.710 --> 00:23:55.035
That's how he got into
politics, through Facebook.

00:23:55.035 --> 00:23:55.910
He wasn't interested.

00:23:55.910 --> 00:23:59.280
A friend of his liked a Facebook
page, and then he liked it too.

00:23:59.280 --> 00:24:02.720
And that's how he was
drawn into this movement.

00:24:02.720 --> 00:24:06.530
Now he never, ever
saw or met anyone

00:24:06.530 --> 00:24:10.240
in his town that had
similar views to him.

00:24:10.240 --> 00:24:12.750
And then one day, he was going
down to the petrol station

00:24:12.750 --> 00:24:15.820
at the end of his road,
and three lads with EDL

00:24:15.820 --> 00:24:20.020
hoodies on walked
past chanting EDL.

00:24:20.020 --> 00:24:21.700
And I said to him, Paul.

00:24:21.700 --> 00:24:24.190
Well that's sort of great.

00:24:24.190 --> 00:24:24.970
I mean, in a way.

00:24:24.970 --> 00:24:27.220
You could make some friends,
people-- he's like, yeah.

00:24:27.220 --> 00:24:28.678
Yeah, I thought it
was really nice.

00:24:28.678 --> 00:24:30.800
It was really nice to see
some fellow EDL people.

00:24:30.800 --> 00:24:31.690
I was like, oh, cool.

00:24:31.690 --> 00:24:32.820
Did you speak to them?

00:24:32.820 --> 00:24:33.730
No.

00:24:33.730 --> 00:24:35.030
Why didn't you speak to them?

00:24:35.030 --> 00:24:39.140
He's like, well, I didn't
really know what to say.

00:24:39.140 --> 00:24:42.430
So he just walked past,
went back home, logged on,

00:24:42.430 --> 00:24:44.384
and then carried on
his online blitz.

00:24:44.384 --> 00:24:46.300
He didn't want to speak
to the offline people,

00:24:46.300 --> 00:24:49.210
because who is he offline?

00:24:49.210 --> 00:24:51.730
The real world Paul
isn't really anything.

00:24:51.730 --> 00:24:53.560
These guys wouldn't know him.

00:24:53.560 --> 00:24:57.930
The digital Paul, the angry,
violent, virulent neo-Nazi,

00:24:57.930 --> 00:24:58.790
he has a following.

00:24:58.790 --> 00:25:00.400
He has meaning.

00:25:00.400 --> 00:25:03.430
So he much preferred
to leave these guys,

00:25:03.430 --> 00:25:05.970
walk home, and log back on.

00:25:05.970 --> 00:25:07.742
And the final one.

00:25:07.742 --> 00:25:08.325
Normalization.

00:25:11.556 --> 00:25:14.450
This is a bit of a
personal story as well.

00:25:14.450 --> 00:25:16.190
Because over the
course of a year,

00:25:16.190 --> 00:25:18.482
something that I
discovered-- and many of you

00:25:18.482 --> 00:25:19.940
have probably
experienced it, too--

00:25:19.940 --> 00:25:24.040
is these with which--
if you surround yourself

00:25:24.040 --> 00:25:26.610
with the same images
and the same ideas,

00:25:26.610 --> 00:25:29.410
it very quickly
stops being shocking.

00:25:29.410 --> 00:25:32.670
When I first got one
4chan for this book

00:25:32.670 --> 00:25:35.330
and on the random
B board of 4chan,

00:25:35.330 --> 00:25:37.670
I could not believe
what I was seeing.

00:25:37.670 --> 00:25:39.550
I'm quite easily shocked.

00:25:39.550 --> 00:25:42.180
Couldn't believe
what I was seeing.

00:25:42.180 --> 00:25:47.120
Next day, didn't seem like
a big deal whatsoever.

00:25:47.120 --> 00:25:49.287
Couple of days later, seemed
pretty boring actually.

00:25:49.287 --> 00:25:51.786
Rather go and find something a
bit more radical and extreme,

00:25:51.786 --> 00:25:52.560
if you don't mind.

00:25:52.560 --> 00:25:54.850
4chan's pretty dull these days.

00:25:54.850 --> 00:25:56.370
And that's something
that you see

00:25:56.370 --> 00:25:57.890
repeated over and over again.

00:25:57.890 --> 00:26:00.140
And that is a very
good evolutionary trait

00:26:00.140 --> 00:26:02.480
for human beings to
have, by the way.

00:26:02.480 --> 00:26:07.260
But it can lead you into
some very, very dark places.

00:26:07.260 --> 00:26:10.370
And I'll give you the
most distressing story

00:26:10.370 --> 00:26:12.830
of all, which is of Michael.

00:26:12.830 --> 00:26:16.660
Man in his 50s, convicted
for the possession

00:26:16.660 --> 00:26:20.920
of 3,000 indecent
images of children.

00:26:20.920 --> 00:26:22.340
Again, similar to Paul.

00:26:22.340 --> 00:26:25.990
In some ways, very nice
man on a personal level.

00:26:25.990 --> 00:26:27.530
But this was his story.

00:26:27.530 --> 00:26:30.300
And it is actually supported
by a lot of research

00:26:30.300 --> 00:26:31.230
in this subject.

00:26:31.230 --> 00:26:34.660
He started off
watching pornography,

00:26:34.660 --> 00:26:36.570
watching teen pornography.

00:26:36.570 --> 00:26:40.620
Now teenage pornography--
that being anything

00:26:40.620 --> 00:26:43.884
over the age of 18, technically,
because anything below that

00:26:43.884 --> 00:26:45.800
is classed as child
pornography or child abuse

00:26:45.800 --> 00:26:53.430
images-- is by far the
most popular voluminous

00:26:53.430 --> 00:26:56.170
and commonly searched for
category of pornography.

00:26:56.170 --> 00:26:57.010
Teen pornography.

00:26:57.010 --> 00:26:59.370
Which is slightly
worrying, isn't it?

00:26:59.370 --> 00:27:03.325
And there is an
enormous gray area

00:27:03.325 --> 00:27:05.720
of what's called jail bait
pornography, which is anywhere

00:27:05.720 --> 00:27:07.646
between about 14 and 18.

00:27:07.646 --> 00:27:10.020
But it's very difficult for
the Internet Watch Foundation

00:27:10.020 --> 00:27:12.020
or anybody else to be
sure about people's age,

00:27:12.020 --> 00:27:14.700
with people changing
how they look.

00:27:14.700 --> 00:27:17.410
And there is so much
of that online as well

00:27:17.410 --> 00:27:19.090
and it's incredibly
difficult to police.

00:27:19.090 --> 00:27:21.590
And I know some-- I know the
work that Google was been doing

00:27:21.590 --> 00:27:24.048
on this subject and the money
that you gave to the Internet

00:27:24.048 --> 00:27:26.850
Watch Foundation
partly as a result.

00:27:26.850 --> 00:27:30.220
Now for Michael,
what happened here--

00:27:30.220 --> 00:27:33.270
and it is a story I
heard repeatedly--

00:27:33.270 --> 00:27:35.550
was that's where he started.

00:27:35.550 --> 00:27:39.160
A few weeks later, he was
getting rather bored of this.

00:27:39.160 --> 00:27:42.390
Shifted into jail
bait pornography.

00:27:42.390 --> 00:27:44.860
After that, wanted
another taboo.

00:27:44.860 --> 00:27:46.560
Went down a couple of years.

00:27:46.560 --> 00:27:49.300
Another taboo needed to
be found and breached.

00:27:49.300 --> 00:27:50.630
Went down again.

00:27:50.630 --> 00:27:55.250
Two or three years later, barely
with him-- and I believe him--

00:27:55.250 --> 00:27:56.860
barely with him
realizing it, he'd

00:27:56.860 --> 00:28:01.130
suddenly wound up watching
pornography of children

00:28:01.130 --> 00:28:02.900
under the age of 10.

00:28:02.900 --> 00:28:05.600
Hardly realizing
how he'd got there.

00:28:05.600 --> 00:28:10.930
And barely understanding himself
how he'd ended up where he had.

00:28:10.930 --> 00:28:14.320
And to, me this is the
story of that normalization

00:28:14.320 --> 00:28:15.630
and how that can happen.

00:28:15.630 --> 00:28:18.640
And I saw it happen
with me on 4chan,

00:28:18.640 --> 00:28:21.170
also on the pro-anorexia sites.

00:28:21.170 --> 00:28:23.175
How in the beginning,
I found them

00:28:23.175 --> 00:28:25.720
so distressing and terrible.

00:28:25.720 --> 00:28:27.255
Pictures of emaciated bodies.

00:28:27.255 --> 00:28:29.380
By the way, this book is
quite distressing to read.

00:28:29.380 --> 00:28:30.349
I should warn you now.

00:28:30.349 --> 00:28:31.765
I hope it's
interesting, but there

00:28:31.765 --> 00:28:33.306
are bits of it that
are hard to read.

00:28:33.306 --> 00:28:35.075
But that's really
why I wrote it.

00:28:35.075 --> 00:28:38.690
I wanted people to
be slightly shocked.

00:28:38.690 --> 00:28:41.480
Started off being very shocked
by the emaciated bodies.

00:28:41.480 --> 00:28:44.450
But then again, very
soon afterwards,

00:28:44.450 --> 00:28:47.630
I was more interested in,
well, which bits are emaciated?

00:28:47.630 --> 00:28:48.900
That's an interesting pose.

00:28:48.900 --> 00:28:51.080
And she's really
featured on her knees.

00:28:51.080 --> 00:28:54.470
And you start looking at these
images in a very different way

00:28:54.470 --> 00:28:55.980
to how you started.

00:28:55.980 --> 00:28:57.700
And that's the story of Michael.

00:28:57.700 --> 00:29:01.280
Even in the darkest and
deepest bits of the book

00:29:01.280 --> 00:29:04.620
and of the Net overall.

00:29:04.620 --> 00:29:06.170
So there are my four themes.

00:29:06.170 --> 00:29:09.000
And the final word-- and
it will be, there we go.

00:29:09.000 --> 00:29:10.960
Exactly 30 minutes.

00:29:10.960 --> 00:29:15.760
The final word is I
was rather depressed

00:29:15.760 --> 00:29:17.320
writing a lot of this book.

00:29:17.320 --> 00:29:22.990
I found it extremely difficult
at times and a lot of time

00:29:22.990 --> 00:29:25.560
spent worrying and
sleepless nights.

00:29:25.560 --> 00:29:28.900
And I just imagined
it was because

00:29:28.900 --> 00:29:31.090
of the depressing and
difficult subjects

00:29:31.090 --> 00:29:32.970
that I was having to work on.

00:29:32.970 --> 00:29:35.260
And it was partly that.

00:29:35.260 --> 00:29:39.380
But I think more so, it
was something far simpler,

00:29:39.380 --> 00:29:42.770
which is I was missing
out on so much offline.

00:29:42.770 --> 00:29:44.730
I was just spending
all of my day

00:29:44.730 --> 00:29:47.530
on the internet with
these virtual characters.

00:29:47.530 --> 00:29:50.880
And I was missing all the
rest of my social life.

00:29:50.880 --> 00:29:52.162
All the rest of my friends.

00:29:52.162 --> 00:29:53.495
All the other things I could do.

00:29:53.495 --> 00:29:56.430
And instead I was crunched
over a computer screen

00:29:56.430 --> 00:29:57.920
and my entire life
was being lived

00:29:57.920 --> 00:30:01.020
through this tiny little box.

00:30:01.020 --> 00:30:04.260
And so I ended up coming out
of the book far more worried,

00:30:04.260 --> 00:30:08.350
not about what people are doing
online and where it takes them

00:30:08.350 --> 00:30:09.645
and why they do it.

00:30:09.645 --> 00:30:12.640
But how do we make sure
people's lives offline are

00:30:12.640 --> 00:30:15.610
more meaningful, more
interesting, more fulfilling

00:30:15.610 --> 00:30:16.490
for them.

00:30:16.490 --> 00:30:19.490
Because if they
were, then I think

00:30:19.490 --> 00:30:22.610
they'd spend far more
time there and far less

00:30:22.610 --> 00:30:28.367
time in some of these darker
and worrying corners of the net.

00:30:28.367 --> 00:30:28.950
And that's it.

00:30:28.950 --> 00:30:29.630
I'm done.

00:30:29.630 --> 00:30:31.894
Thank you very
much for listening.

00:30:31.894 --> 00:30:35.798
[APPLAUSE]

00:30:39.710 --> 00:30:42.800
So I think I'm in charge of
taking questions, aren't I?

00:30:42.800 --> 00:30:43.300
Yeah.

00:30:43.300 --> 00:30:45.690
So if anybody has any
questions-- oh, yes.

00:30:45.690 --> 00:30:46.732
You.

00:30:46.732 --> 00:30:48.440
AUDIENCE: Were you
every worried that you

00:30:48.440 --> 00:30:50.890
might be arrested
during your research?

00:30:50.890 --> 00:30:52.726
And did you have a
back-up plan for what

00:30:52.726 --> 00:30:53.870
you might do in that event?

00:30:56.475 --> 00:30:57.850
JAMIE BARTLETT:
I'm still worried

00:30:57.850 --> 00:31:00.380
that I won't be let
into the United States,

00:31:00.380 --> 00:31:04.180
because I said that I'd
bought one gram of marijuana.

00:31:04.180 --> 00:31:08.190
And they have rather strict
rules on this kind of thing.

00:31:08.190 --> 00:31:13.480
I went into this,
starting off thinking,

00:31:13.480 --> 00:31:15.790
oh I'm going to really
get to the bottom of all

00:31:15.790 --> 00:31:19.320
this nasty, crazy,
dirty internet stuff

00:31:19.320 --> 00:31:21.424
and really expose
it for what it is.

00:31:21.424 --> 00:31:23.090
But there were so
many bits where I just

00:31:23.090 --> 00:31:24.720
dared not click any further.

00:31:24.720 --> 00:31:28.630
I dare not go beyond that,
because I didn't-- one

00:31:28.630 --> 00:31:31.030
of the internet adages is you
can't see what you've seen.

00:31:31.030 --> 00:31:34.490
And once you've done
some-- it's very easy,

00:31:34.490 --> 00:31:36.410
I think, in these sites
and these communities,

00:31:36.410 --> 00:31:39.020
to unknowingly
step over the line.

00:31:39.020 --> 00:31:41.360
So I was incredibly careful.

00:31:41.360 --> 00:31:44.230
I went to see the police before
I did any of this research.

00:31:44.230 --> 00:31:47.840
I tried to tell as many people
as possible what I was doing.

00:31:47.840 --> 00:31:50.460
I was very careful not to
do anything illegal, apart

00:31:50.460 --> 00:31:53.190
from that one case with
the small amount of drugs

00:31:53.190 --> 00:31:55.280
and I determined
that you could make

00:31:55.280 --> 00:31:57.270
quite a good public
interest case

00:31:57.270 --> 00:32:01.000
for buying such an incredibly
small amount of drugs

00:32:01.000 --> 00:32:02.700
in that instance.

00:32:02.700 --> 00:32:05.072
So in the end, I wasn't
actually that worried

00:32:05.072 --> 00:32:06.780
because I think I've
done it rather well.

00:32:06.780 --> 00:32:10.750
I was more worried about whether
any of the people that I'd

00:32:10.750 --> 00:32:12.490
been speaking to
might be identified

00:32:12.490 --> 00:32:17.210
or that I might cause them
some distress or harm.

00:32:17.210 --> 00:32:20.080
Even the people that
I found objectionable.

00:32:20.080 --> 00:32:23.500
As a researcher-- I'm not really
an investigative journalist.

00:32:23.500 --> 00:32:25.601
I'm a standard researcher.

00:32:25.601 --> 00:32:26.600
I work for a think tank.

00:32:26.600 --> 00:32:28.234
I was more worried
about making sure

00:32:28.234 --> 00:32:30.150
that the research
participants weren't harmed.

00:32:30.150 --> 00:32:33.432
And I really tried to bend
over backwards to mask

00:32:33.432 --> 00:32:35.140
who they really were
and where they live.

00:32:35.140 --> 00:32:37.264
Details were changed
throughout, but without losing

00:32:37.264 --> 00:32:39.100
the thread of the story.

00:32:39.100 --> 00:32:42.420
And I think I've done it well
enough, but people are smart.

00:32:42.420 --> 00:32:44.170
People can normally
identify people.

00:32:44.170 --> 00:32:47.746
And all of these
ethical questions

00:32:47.746 --> 00:32:48.870
are a question of judgment.

00:32:48.870 --> 00:32:51.964
About do you think you've
done enough to protect

00:32:51.964 --> 00:32:53.130
the identity of individuals.

00:32:53.130 --> 00:32:54.760
Have you taken reasonable
measures to do so.

00:32:54.760 --> 00:32:56.320
Have you informed them
of your intention.

00:32:56.320 --> 00:32:58.653
Have you told them and showed
them drafts of what you've

00:32:58.653 --> 00:33:00.500
done, so they're
content to be talked

00:33:00.500 --> 00:33:02.800
about in this way in
the public domain.

00:33:02.800 --> 00:33:03.860
I did all of that stuff.

00:33:03.860 --> 00:33:05.569
I think I did it well enough.

00:33:05.569 --> 00:33:07.110
It's only been out
for a month or so,

00:33:07.110 --> 00:33:10.100
so there's still time
for me to get arrested,

00:33:10.100 --> 00:33:14.200
so-- maybe I shouldn't answer
that question just yet.

00:33:14.200 --> 00:33:15.220
Thank you.

00:33:15.220 --> 00:33:16.440
AUDIENCE: So, two questions.

00:33:16.440 --> 00:33:21.200
First one, do you know if
they can force you to--

00:33:21.200 --> 00:33:24.710
for example, child pornography--
to tell the government

00:33:24.710 --> 00:33:29.000
or someone names of people
and stuff like that.

00:33:29.000 --> 00:33:30.910
Because you can mask
things, but maybe

00:33:30.910 --> 00:33:34.370
they can get you to
court to tell the names.

00:33:34.370 --> 00:33:35.086
So that's one--

00:33:35.086 --> 00:33:35.960
JAMIE BARTLETT: Yeah.

00:33:35.960 --> 00:33:37.840
Yeah, I'm pretty
sure they could.

00:33:37.840 --> 00:33:39.382
I mean, I could go
to court over it

00:33:39.382 --> 00:33:40.840
as a journalist
saying I'll protect

00:33:40.840 --> 00:33:43.950
my sources to the death.

00:33:43.950 --> 00:33:45.710
But of course,
they can-- whatever

00:33:45.710 --> 00:33:47.945
the equivalent of subpoenaing
is in this kind of-- I

00:33:47.945 --> 00:33:49.380
don't know what the
actual legal term is.

00:33:49.380 --> 00:33:49.920
But yeah.

00:33:49.920 --> 00:33:51.430
I mean, they could
seize my computer

00:33:51.430 --> 00:33:52.840
and demand the passwords.

00:33:52.840 --> 00:33:56.650
And if I don't give them
those under the Regulation

00:33:56.650 --> 00:33:58.500
of Investigatory
Powers Act 2000,

00:33:58.500 --> 00:34:01.480
I could end up in prison for
not disclosing my password.

00:34:01.480 --> 00:34:02.600
So yeah.

00:34:02.600 --> 00:34:03.830
They could.

00:34:03.830 --> 00:34:04.590
AUDIENCE: OK.

00:34:04.590 --> 00:34:07.420
And you think you
got to the bottom,

00:34:07.420 --> 00:34:12.600
or were there subjects that
you didn't dare to go into?

00:34:12.600 --> 00:34:13.870
JAMIE BARTLETT: Well.

00:34:13.870 --> 00:34:16.610
See, people talk about
this in terms of depth,

00:34:16.610 --> 00:34:18.330
like going deeper and
deeper and deeper.

00:34:18.330 --> 00:34:20.900
But it's not really like that.

00:34:20.900 --> 00:34:23.112
Cyberspace doesn't
really have any depth.

00:34:23.112 --> 00:34:25.070
If you know where
the link is, it's

00:34:25.070 --> 00:34:29.020
as easy to get to the Silk Road
as it is to get to the BBC.

00:34:29.020 --> 00:34:32.030
It's really simple.

00:34:32.030 --> 00:34:35.800
There are obviously-- in
particular communities

00:34:35.800 --> 00:34:39.469
within Facebook or
on forums-- there's

00:34:39.469 --> 00:34:41.116
a secret password
protected forum.

00:34:41.116 --> 00:34:42.699
And within that, you
might meet people

00:34:42.699 --> 00:34:45.810
who tell you about another
secret protective password

00:34:45.810 --> 00:34:47.389
forum.

00:34:47.389 --> 00:34:50.699
And no, I never felt like I'd
got anywhere near the bottom.

00:34:50.699 --> 00:34:52.259
I mean, the problem
is, you never

00:34:52.259 --> 00:34:54.300
really know whether you're
scratching the surface

00:34:54.300 --> 00:34:55.600
or you've reached the bottom.

00:34:55.600 --> 00:34:57.970
Because you can never tell
quite how far it goes.

00:34:57.970 --> 00:35:01.270
And I probably could have just
spend another year constantly

00:35:01.270 --> 00:35:03.900
trying to follow links around
and get further and further

00:35:03.900 --> 00:35:05.920
away from where I started.

00:35:05.920 --> 00:35:09.930
But I'm quite confident that
I didn't get near the "bottom"

00:35:09.930 --> 00:35:12.430
or whatever you want to call it.

00:35:12.430 --> 00:35:14.880
The end of the line or whatever.

00:35:14.880 --> 00:35:15.760
Absolutely not.

00:35:15.760 --> 00:35:17.910
And I had to stop at
certain places anyway.

00:35:17.910 --> 00:35:21.270
I decided I wasn't
going to go trying to,

00:35:21.270 --> 00:35:24.550
under false pretenses, get
into password protected

00:35:24.550 --> 00:35:25.940
suicide forums, for example.

00:35:25.940 --> 00:35:28.610
I tended to go to the open ones.

00:35:28.610 --> 00:35:31.040
So there would have been
that bit, for example.

00:35:31.040 --> 00:35:33.340
But there were
other areas, yeah.

00:35:33.340 --> 00:35:38.380
You should read this more
as a skirt across some

00:35:38.380 --> 00:35:40.325
of these cultures
and communities.

00:35:40.325 --> 00:35:43.160
I had to make a decision
between-- a trade off

00:35:43.160 --> 00:35:46.820
between depth and breadth.

00:35:46.820 --> 00:35:48.784
And I went for breadth.

00:35:48.784 --> 00:35:49.440
AUDIENCE: OK.

00:35:49.440 --> 00:35:51.940
JAMIE BARTLETT: Even I'm using
the depth and deep and stuff,

00:35:51.940 --> 00:35:53.940
even though I keep saying
that's not what it is.

00:35:53.940 --> 00:35:57.630
But it's a very easy
analogy to just trip into.

00:35:57.630 --> 00:35:59.130
AUDIENCE: I have a
couple questions.

00:35:59.130 --> 00:36:00.780
First of all, what's
your background?

00:36:00.780 --> 00:36:02.817
And second, if I were
to pick up that book,

00:36:02.817 --> 00:36:04.650
would I just be able
to understand anything,

00:36:04.650 --> 00:36:06.691
or should I read-- this
is like my first exposure

00:36:06.691 --> 00:36:07.740
to anything like this.

00:36:07.740 --> 00:36:10.030
So should I read
more this is what

00:36:10.030 --> 00:36:13.802
it is before I were to
pick that up and read it.

00:36:13.802 --> 00:36:17.960
JAMIE BARTLETT: The book is
exceptionally well written.

00:36:17.960 --> 00:36:21.040
It's actually probably more
intended for people like you

00:36:21.040 --> 00:36:26.394
than for people that have been
on the Silk Road, like you.

00:36:26.394 --> 00:36:28.930
OK.

00:36:28.930 --> 00:36:33.490
It was meant to be--
I mean, I arrogantly

00:36:33.490 --> 00:36:36.330
hoped it would be like
Louis Theroux online,

00:36:36.330 --> 00:36:39.090
going to these places,
explaining it really clearly.

00:36:39.090 --> 00:36:41.200
There's not much technical
language in there.

00:36:41.200 --> 00:36:43.600
There's footnotes with
really heavy detail,

00:36:43.600 --> 00:36:47.410
but it's a very-- I hope--
the intention was that it's

00:36:47.410 --> 00:36:51.380
a very accessible and simple
guide to these cultures told

00:36:51.380 --> 00:36:52.630
through the stories of people.

00:36:52.630 --> 00:36:54.240
So whenever you
bring people into it,

00:36:54.240 --> 00:36:56.630
it becomes immediately
more accessible as well.

00:36:56.630 --> 00:37:01.400
There's a few descriptions of
how the onion root of the Tor

00:37:01.400 --> 00:37:04.740
browser actually works, and
how Tor hidden services work

00:37:04.740 --> 00:37:07.060
and why they're
hard to track down.

00:37:07.060 --> 00:37:09.350
But they're only-- there's
not so much of that.

00:37:09.350 --> 00:37:11.100
Because I just thought,
what's interesting

00:37:11.100 --> 00:37:14.270
about these cultures are the
people and how they behave

00:37:14.270 --> 00:37:17.600
and what they do, not really the
technology that underpins it.

00:37:17.600 --> 00:37:22.704
And my background
is in research.

00:37:22.704 --> 00:37:24.120
So I work for a
think tank, Demos.

00:37:24.120 --> 00:37:25.550
And for the last
seven years, I've

00:37:25.550 --> 00:37:29.590
worked there doing social,
political, cultural research.

00:37:29.590 --> 00:37:34.210
Using standard methodologies
of questionnaires and surveys

00:37:34.210 --> 00:37:38.700
and ethnography and polling on
quite a wide array of subjects,

00:37:38.700 --> 00:37:42.020
but mainly looking at
extremist and radical groups,

00:37:42.020 --> 00:37:43.630
political groups.

00:37:43.630 --> 00:37:46.380
And I did a big Facebook survey
of the English Defence League.

00:37:46.380 --> 00:37:48.129
I've written a lot
about intelligence work

00:37:48.129 --> 00:37:50.640
and how intelligence and
policing use the internet.

00:37:50.640 --> 00:37:54.380
I wrote a paper with David
Omand, former GCHQ director,

00:37:54.380 --> 00:37:59.130
about the polices and MI5 and
GCHQ's use of the internet

00:37:59.130 --> 00:38:01.010
as a form of intelligence.

00:38:01.010 --> 00:38:04.574
And at the moment, I
run a center at Demos

00:38:04.574 --> 00:38:06.490
called Center for the
Analysis of Social Media

00:38:06.490 --> 00:38:08.740
with the University
of Sussex, where

00:38:08.740 --> 00:38:12.640
we're trying to develop
computational natural language

00:38:12.640 --> 00:38:16.810
processing, automated
text mining and analytics.

00:38:16.810 --> 00:38:20.950
Trying to develop software
that allows social scientists

00:38:20.950 --> 00:38:25.220
to be able to use and apply
those computational methods

00:38:25.220 --> 00:38:28.570
for the purposes of
social policy research.

00:38:28.570 --> 00:38:32.180
So essentially what's happened
is all the stuff on big data

00:38:32.180 --> 00:38:37.030
analytics is really driven by
people like you or advertising

00:38:37.030 --> 00:38:39.320
and marketing people,
and not so much

00:38:39.320 --> 00:38:41.340
the social scientists
who, I think,

00:38:41.340 --> 00:38:43.540
have got an awful lot to
bring to this in terms

00:38:43.540 --> 00:38:47.860
of deeper analysis,
sampling methodologies,

00:38:47.860 --> 00:38:49.230
ethics of good research.

00:38:49.230 --> 00:38:52.262
So we're trying to combine
and mix those disciplines.

00:38:52.262 --> 00:38:54.607
AUDIENCE: Thanks.

00:38:54.607 --> 00:38:55.440
AUDIENCE: Hi, Jamie.

00:38:55.440 --> 00:38:56.220
JAMIE BARTLETT: Hello.

00:38:56.220 --> 00:38:57.450
AUDIENCE: Very interesting,
thanks for that.

00:38:57.450 --> 00:38:57.780
JAMIE BARTLETT: Pleasure.

00:38:57.780 --> 00:38:59.570
AUDIENCE: I was just wondering--
I was interested more

00:38:59.570 --> 00:39:00.650
on the solution side.

00:39:00.650 --> 00:39:04.190
So you mentioned, for example,
about moderating the suicide

00:39:04.190 --> 00:39:05.120
forums.

00:39:05.120 --> 00:39:06.920
And do you go into
your book-- and maybe

00:39:06.920 --> 00:39:08.083
you don't want to answer
the question, which

00:39:08.083 --> 00:39:10.320
is fair enough-- but do
you have any suggestions?

00:39:10.320 --> 00:39:11.944
Like if you had a
magic wand, would you

00:39:11.944 --> 00:39:14.892
do anything about Silk Road
or some of the other things

00:39:14.892 --> 00:39:16.600
that you've come across
in your research?

00:39:19.124 --> 00:39:20.540
JAMIE BARTLETT:
One of the reasons

00:39:20.540 --> 00:39:22.960
I made it a series of
portraits rather than polemic

00:39:22.960 --> 00:39:24.990
is because I don't know
what the answer is.

00:39:24.990 --> 00:39:25.690
I really don't.

00:39:25.690 --> 00:39:28.550
And the Silk Road
is a combination--

00:39:28.550 --> 00:39:32.570
it's either it
makes drugs easier

00:39:32.570 --> 00:39:35.710
to get and more
drugs easier to get,

00:39:35.710 --> 00:39:38.840
but makes those drugs
more reliable and safer.

00:39:38.840 --> 00:39:40.820
What's important to you?

00:39:40.820 --> 00:39:43.690
Is it that it's harder
for people to get it?

00:39:43.690 --> 00:39:45.150
Or assuming that
they will get it,

00:39:45.150 --> 00:39:47.160
make sure it's better
for them to get it?

00:39:47.160 --> 00:39:50.960
And that comes down to moral,
personal, ethical judgement

00:39:50.960 --> 00:39:51.800
that you make.

00:39:51.800 --> 00:39:56.450
And it's quite similar on
a lot of these subjects.

00:39:56.450 --> 00:40:00.050
So with Paul and
the neo-Nazis, I

00:40:00.050 --> 00:40:02.420
tend to-- it's often
a question of erring

00:40:02.420 --> 00:40:05.935
on one side or the other,
between censorship or openness.

00:40:05.935 --> 00:40:09.510
And I tend to, having looked
at what these guys do online,

00:40:09.510 --> 00:40:11.900
I tend to err on the
side of openness.

00:40:11.900 --> 00:40:13.600
And let them talk
and hear them out.

00:40:13.600 --> 00:40:14.392
And let them speak.

00:40:14.392 --> 00:40:15.433
Give them a safety valve.

00:40:15.433 --> 00:40:16.410
It's really important.

00:40:16.410 --> 00:40:18.020
Because everything
in the book to me

00:40:18.020 --> 00:40:19.920
suggests that every time
you clamp down on anything,

00:40:19.920 --> 00:40:22.160
it pops up somewhere else
or it goes somewhere else.

00:40:22.160 --> 00:40:24.780
And it gets worse and it gets
darker and it gets deeper.

00:40:24.780 --> 00:40:27.240
And actually bringing this
stuff out into the open

00:40:27.240 --> 00:40:29.120
makes it far less
terrifying than when

00:40:29.120 --> 00:40:32.430
it's hidden under the bed
and shoved away in a corner.

00:40:32.430 --> 00:40:36.680
Now I know that's not a specific
clear government policy.

00:40:36.680 --> 00:40:40.600
It's just a general approach
that I've thought through

00:40:40.600 --> 00:40:43.890
for how we deal with all these
difficult subjects online.

00:40:43.890 --> 00:40:47.760
And I stopped there, because
beyond that, I'm not sure.

00:40:47.760 --> 00:40:49.677
And that's not the purpose
of the book really.

00:40:49.677 --> 00:40:50.301
AUDIENCE: Yeah.

00:40:50.301 --> 00:40:50.970
No, that's fair.

00:40:50.970 --> 00:40:54.030
I guess where I was coming from
was exactly that last point.

00:40:54.030 --> 00:40:55.777
Where if we stop it,
that might be good,

00:40:55.777 --> 00:40:57.070
but it'll pop up again.

00:40:57.070 --> 00:40:59.153
But if we keep it going,
it will get more extreme.

00:40:59.153 --> 00:41:00.900
JAMIE BARTLETT: Well,
the Silk Road-- so

00:41:00.900 --> 00:41:04.660
when it was shut
down in October,

00:41:04.660 --> 00:41:06.720
and they're doing a
really decent trade.

00:41:06.720 --> 00:41:10.775
There was probably three big
online drugs marketplaces

00:41:10.775 --> 00:41:12.810
or anonymous marketplaces.

00:41:12.810 --> 00:41:15.430
They're called Dark Net markets.

00:41:15.430 --> 00:41:18.120
Six months later,
they're about 30 of them.

00:41:18.120 --> 00:41:21.030
They're far harder to close
down now than they were before.

00:41:21.030 --> 00:41:23.200
They're selling far more
drugs than ever they were.

00:41:23.200 --> 00:41:29.540
And what really has been
achieved by closing this down?

00:41:29.540 --> 00:41:31.102
More people know
about than ever.

00:41:31.102 --> 00:41:32.810
I'm probably contributing
to that problem

00:41:32.810 --> 00:41:35.300
by writing about it.

00:41:35.300 --> 00:41:38.920
And they're smarter, harder
to crack, more encrypted

00:41:38.920 --> 00:41:40.090
than they were before.

00:41:40.090 --> 00:41:43.380
So that is a pretty
good-- I often

00:41:43.380 --> 00:41:45.280
trotted out the
easy liberal line.

00:41:45.280 --> 00:41:47.250
Oh, if you censor
something, it merely

00:41:47.250 --> 00:41:50.490
just comes out in another
and gets even more radical.

00:41:50.490 --> 00:41:53.040
But I hadn't really
seen evidence of it.

00:41:53.040 --> 00:41:55.790
That was a nice
comfortable assumption,

00:41:55.790 --> 00:41:57.480
philosophical
assumption, to draw.

00:41:57.480 --> 00:41:59.700
But I hadn't seen so much
actual evidence of that.

00:41:59.700 --> 00:42:01.560
But I think in writing this
book, I did see evidence.

00:42:01.560 --> 00:42:02.830
I did see evidence of that.

00:42:02.830 --> 00:42:04.950
And I saw how people
get around censorship

00:42:04.950 --> 00:42:08.030
and how they work ways out
of getting their message out.

00:42:08.030 --> 00:42:11.280
And nothing good
ever comes of things

00:42:11.280 --> 00:42:13.790
being hidden and not
allowed to be talked about

00:42:13.790 --> 00:42:15.550
and always off limits
and always taboo.

00:42:15.550 --> 00:42:16.470
Nothing.

00:42:16.470 --> 00:42:19.830
So again, it's an approach
rather than a policy.

00:42:19.830 --> 00:42:21.831
But you are-- I agree
with you on that.

00:42:21.831 --> 00:42:22.095
AUDIENCE: That's great.

00:42:22.095 --> 00:42:22.595
Thank you.

00:42:22.595 --> 00:42:23.625
JAMIE BARTLETT: Thanks.

00:42:23.625 --> 00:42:24.500
AUDIENCE: Hey, Jamie.

00:42:24.500 --> 00:42:25.880
Thanks a lot.

00:42:25.880 --> 00:42:29.130
Question for me was
thinking about anonymity

00:42:29.130 --> 00:42:30.570
has its importance
but credibility

00:42:30.570 --> 00:42:31.945
seems to also have
an importance.

00:42:31.945 --> 00:42:35.910
And when you think about where--
whether it's online forums

00:42:35.910 --> 00:42:39.590
or it it's-- whether its
users are secret or Snapchat--

00:42:39.590 --> 00:42:42.170
so the evolution of where
people are having anonymous

00:42:42.170 --> 00:42:45.726
but controlled systems
where they operate in.

00:42:45.726 --> 00:42:47.100
Where does that
fit in in the way

00:42:47.100 --> 00:42:48.850
you've seen the Dark
Net as it's evolving,

00:42:48.850 --> 00:42:50.740
versus the open
communities that--

00:42:50.740 --> 00:42:52.240
JAMIE BARTLETT: Yeah.

00:42:52.240 --> 00:42:56.270
So the chapter three is
about the cypher punks.

00:42:56.270 --> 00:42:58.982
Anyone know the Cypher Punks?

00:42:58.982 --> 00:43:01.190
Oh, you guys would be
interested in the Cypher Punks.

00:43:01.190 --> 00:43:04.720
So the Cypher Punks were a
group of American libertarians,

00:43:04.720 --> 00:43:07.010
California libertarians
from the early '90s, who

00:43:07.010 --> 00:43:10.070
more or less predicted
all of this stuff

00:43:10.070 --> 00:43:12.120
and built systems of encryption.

00:43:12.120 --> 00:43:14.140
They predicted black markets.

00:43:14.140 --> 00:43:15.862
They did anonymous re-mailers.

00:43:15.862 --> 00:43:17.570
And it was all part
of a political vision

00:43:17.570 --> 00:43:20.510
to try to undermine
the power of the state.

00:43:24.430 --> 00:43:26.970
Crypto currencies as well
came from the Cypher Punks.

00:43:26.970 --> 00:43:29.300
It was especially on
the cryptography mailing

00:43:29.300 --> 00:43:31.879
that bitcoin was
first introduced.

00:43:31.879 --> 00:43:33.045
Part of a political project.

00:43:33.045 --> 00:43:35.790
If the government can't
trace what we're doing,

00:43:35.790 --> 00:43:36.614
it can't tax us.

00:43:36.614 --> 00:43:38.280
If it can't tax us,
it's got no revenue.

00:43:38.280 --> 00:43:39.600
It can't control us.

00:43:39.600 --> 00:43:40.770
So it was currency.

00:43:40.770 --> 00:43:43.110
It was messages
and communication.

00:43:43.110 --> 00:43:44.760
It was your online activity.

00:43:44.760 --> 00:43:47.750
Just a big battle over secrecy
and privacy and anonymity

00:43:47.750 --> 00:43:50.490
online.

00:43:50.490 --> 00:43:52.470
The big challenge
that they always faced

00:43:52.470 --> 00:43:56.650
was how do you combine
anonymity with reputation.

00:43:56.650 --> 00:44:00.120
Because without
reputation, black markets

00:44:00.120 --> 00:44:02.510
or any marketplace collapses.

00:44:02.510 --> 00:44:06.340
Any social system
collapses quite quickly.

00:44:06.340 --> 00:44:09.600
So they were obsessed with
the idea of people building up

00:44:09.600 --> 00:44:12.480
reputable pseudonyms.

00:44:12.480 --> 00:44:15.470
Identities that were online
couldn't be traced back

00:44:15.470 --> 00:44:19.330
to the real you, but where you
had an incentive to make sure

00:44:19.330 --> 00:44:21.840
you kept building up
that positive reputation

00:44:21.840 --> 00:44:23.200
within your community.

00:44:23.200 --> 00:44:25.790
You were still totally secret
about who you really were.

00:44:25.790 --> 00:44:29.460
It's a separate identity
that was reputable.

00:44:29.460 --> 00:44:31.260
And that's the trick
of the Silk Road.

00:44:31.260 --> 00:44:32.990
And that's what the
Silk Road has done.

00:44:32.990 --> 00:44:35.280
And that's exactly what the
Cypher Punks in the '90s

00:44:35.280 --> 00:44:39.560
were trying to develop systems
to be able to work out.

00:44:39.560 --> 00:44:42.917
And I think there's a lot
of modern Cypher Punks.

00:44:42.917 --> 00:44:44.875
The people behind bitcoin
are all Cypher Punks.

00:44:44.875 --> 00:44:45.791
There's loads of them.

00:44:45.791 --> 00:44:48.940
And there's a huge growth of
citizen encryption systems.

00:44:48.940 --> 00:44:52.720
You've probably been following
it post Snowden especially.

00:44:52.720 --> 00:44:54.760
And that's always been the key.

00:44:54.760 --> 00:44:56.705
Reputation versus anonymity.

00:44:56.705 --> 00:44:58.080
And I think on
the Silk Road, why

00:44:58.080 --> 00:44:59.621
I think it's so
innovative is they've

00:44:59.621 --> 00:45:01.940
worked out some
ways around that.

00:45:01.940 --> 00:45:04.750
Where is that going
to evolve and develop?

00:45:04.750 --> 00:45:05.710
I don't know.

00:45:05.710 --> 00:45:07.596
But it is going to
evolve and develop.

00:45:07.596 --> 00:45:09.470
AUDIENCE: And just a
quick follow-up on that.

00:45:09.470 --> 00:45:11.690
How does that fit in
where like, GCHQ or MI5.

00:45:11.690 --> 00:45:14.830
If they are understanding
identity as a pseudonym

00:45:14.830 --> 00:45:16.820
and understanding online
behavior as pseudonym,

00:45:16.820 --> 00:45:18.540
is that sufficient
or will they still

00:45:18.540 --> 00:45:20.852
continuously try to
link between online--

00:45:20.852 --> 00:45:22.310
JAMIE BARTLETT:
Well, they're going

00:45:22.310 --> 00:45:23.619
to continue to try and link.

00:45:23.619 --> 00:45:24.410
Of course they are.

00:45:24.410 --> 00:45:27.430
You can't prosecute a pseudonym.

00:45:27.430 --> 00:45:31.380
I mean, pseudonyms--
I think this

00:45:31.380 --> 00:45:33.780
is going to be one of the
big battles over the future

00:45:33.780 --> 00:45:36.580
of the internet is about
the right to anonymity

00:45:36.580 --> 00:45:38.940
and pseudonymity and
whether companies are going

00:45:38.940 --> 00:45:43.270
to be forced to constantly
track and push together

00:45:43.270 --> 00:45:45.200
your online and your
offline identities.

00:45:45.200 --> 00:45:47.340
And there's so many
people out there

00:45:47.340 --> 00:45:49.690
who believe that you
shouldn't do that.

00:45:49.690 --> 00:45:53.260
And that's the
citizen led rebellion

00:45:53.260 --> 00:45:55.310
against controlling
your online identity

00:45:55.310 --> 00:45:57.150
and matching it against
your offline one.

00:45:57.150 --> 00:45:59.740
Governments and big
companies, of course,

00:45:59.740 --> 00:46:01.400
are going to
constantly try and push

00:46:01.400 --> 00:46:03.260
those two identities together.

00:46:03.260 --> 00:46:05.620
Lots of citizen and
civil liberties groups

00:46:05.620 --> 00:46:07.570
are going to keep trying
to pull them apart.

00:46:07.570 --> 00:46:09.361
And that's going to
be, I think, the battle

00:46:09.361 --> 00:46:11.490
over the next five or 10 years.

00:46:11.490 --> 00:46:14.451
But yeah, GCHQ are going to
be on the side of pushing

00:46:14.451 --> 00:46:14.950
together.

00:46:14.950 --> 00:46:16.200
I think that's fair to assume.

00:46:19.290 --> 00:46:21.340
AUDIENCE: Hi, Jamie.

00:46:21.340 --> 00:46:24.750
Where do you stand
on the recent Right

00:46:24.750 --> 00:46:27.760
to be Forgotten
rulings that we've

00:46:27.760 --> 00:46:30.940
seen in Europe versus America?

00:46:30.940 --> 00:46:34.620
Obviously anonymity and
that plays a massive part

00:46:34.620 --> 00:46:35.350
in your book.

00:46:35.350 --> 00:46:39.290
But in terms of governments
getting involved and actually

00:46:39.290 --> 00:46:44.780
taking a position on what the
individual right of a person

00:46:44.780 --> 00:46:46.750
is to be able to
take down data that

00:46:46.750 --> 00:46:48.410
might be out there, et cetera.

00:46:48.410 --> 00:46:50.640
Do you believe
that that should be

00:46:50.640 --> 00:46:52.910
within an individual's right?

00:46:52.910 --> 00:46:57.570
Or is anything that one does
online-- is one automatically

00:46:57.570 --> 00:47:03.000
potentially culpable or
actionable based on that?

00:47:03.000 --> 00:47:04.720
JAMIE BARTLETT: Well.

00:47:04.720 --> 00:47:07.610
I'm not a civil--
I'm not a libertarian

00:47:07.610 --> 00:47:09.021
about internet freedom.

00:47:09.021 --> 00:47:11.520
I think it's extremely important
that democratically elected

00:47:11.520 --> 00:47:14.730
governments are
able to trace people

00:47:14.730 --> 00:47:18.230
providing it's legitimate
and proportionate.

00:47:18.230 --> 00:47:21.440
Security is incredibly
important, and public safety.

00:47:21.440 --> 00:47:24.415
And I met a lot of people
in these communities

00:47:24.415 --> 00:47:25.780
that really suffer online.

00:47:25.780 --> 00:47:29.880
And they're abused
and they're stalked.

00:47:29.880 --> 00:47:33.420
And an increasing
number of domestic cases

00:47:33.420 --> 00:47:35.090
start on Facebook.

00:47:35.090 --> 00:47:37.090
And people are
desperately-- they

00:47:37.090 --> 00:47:38.590
want to find who
these stalkers are.

00:47:38.590 --> 00:47:40.180
Who these people are,
bullying them, stalking them.

00:47:40.180 --> 00:47:41.679
And it's extremely
important that we

00:47:41.679 --> 00:47:43.900
do police these parts
of the internet,

00:47:43.900 --> 00:47:48.156
because I think it's wrong
to think-- especially

00:47:48.156 --> 00:47:50.530
as more and more people live
more and more of their lives

00:47:50.530 --> 00:47:51.415
that it's somehow separate.

00:47:51.415 --> 00:47:52.250
It's not separate.

00:47:52.250 --> 00:47:54.200
And that also includes policing.

00:47:54.200 --> 00:47:57.370
But the Right to be
Forgotten point-- well,

00:47:57.370 --> 00:47:59.930
without wanting to
preach to the converted,

00:47:59.930 --> 00:48:01.460
I think it's
completely ludicrous.

00:48:01.460 --> 00:48:06.350
I mean mainly for
practical purposes.

00:48:11.500 --> 00:48:15.010
It strikes me as
extremely odd that it

00:48:15.010 --> 00:48:19.280
should fall to a private
company to be asked to determine

00:48:19.280 --> 00:48:22.880
what is and what isn't
available in the public domain.

00:48:22.880 --> 00:48:26.740
De facto Google, Facebook,
YouTube, and Twitter

00:48:26.740 --> 00:48:29.370
have become the public space.

00:48:29.370 --> 00:48:31.090
It is where the
public space is now.

00:48:31.090 --> 00:48:33.140
It's just masked
speaker's corner.

00:48:33.140 --> 00:48:36.100
It's where the big debates
of the day play out.

00:48:36.100 --> 00:48:40.240
Now I think we've got to be
very careful-- understand what

00:48:40.240 --> 00:48:44.330
you guys do-- to
cede total control.

00:48:44.330 --> 00:48:48.840
To stop pushing more and more in
the responsibility of managing

00:48:48.840 --> 00:48:51.280
the space to
companies who run it.

00:48:51.280 --> 00:48:52.980
Now, I know it's
your server space,

00:48:52.980 --> 00:48:55.780
but I believe that most
of you have a commitment

00:48:55.780 --> 00:48:56.936
to free expression.

00:48:56.936 --> 00:48:59.310
And the more and more we're
trying to police it and force

00:48:59.310 --> 00:49:00.980
people to take
things down and ask

00:49:00.980 --> 00:49:04.080
lawyers sitting in California
or wherever they're

00:49:04.080 --> 00:49:07.470
sitting to make decisions
about that, the more and more

00:49:07.470 --> 00:49:12.434
the public space is becoming
commercialized, complicated.

00:49:12.434 --> 00:49:14.100
Quite apart from the
fact that, as we've

00:49:14.100 --> 00:49:16.180
seen with this, the
Right to be Forgotten

00:49:16.180 --> 00:49:20.490
appears to me to be more like
the right to tell Google not

00:49:20.490 --> 00:49:25.360
to show this particular piece
of data high up in the search

00:49:25.360 --> 00:49:28.410
results, but not
actually take it offline.

00:49:28.410 --> 00:49:30.124
And then you'll be
able to find out--

00:49:30.124 --> 00:49:31.540
there's already
been a site set up

00:49:31.540 --> 00:49:34.670
to do this-- to find
out what things Google's

00:49:34.670 --> 00:49:35.925
been asked to remove.

00:49:35.925 --> 00:49:38.070
So it's barely a right
to be forgotten, is it?

00:49:38.070 --> 00:49:39.940
It's more like a
right to be remembered

00:49:39.940 --> 00:49:41.580
or to be highlighted
as being asked

00:49:41.580 --> 00:49:43.430
to be forgotten about something.

00:49:43.430 --> 00:49:45.614
And that's a good analogy
for the net in general.

00:49:45.614 --> 00:49:47.780
Obviously as you all know,
it's incredibly difficult

00:49:47.780 --> 00:49:51.222
to censor and to
remove items entirely.

00:49:51.222 --> 00:49:52.930
And because there's
such a strong current

00:49:52.930 --> 00:49:55.140
of feeling against censorship--
partly for the reasons

00:49:55.140 --> 00:49:55.765
that I've said.

00:49:55.765 --> 00:49:57.990
Like the danger
of over-censoring

00:49:57.990 --> 00:49:59.300
this public space.

00:49:59.300 --> 00:50:01.160
There's going to be
a battery of people

00:50:01.160 --> 00:50:04.382
that are ready to highlight
attempts at censorship that

00:50:04.382 --> 00:50:05.840
appear to be
overstepping the mark.

00:50:05.840 --> 00:50:09.240
So for that and a
host of other reasons,

00:50:09.240 --> 00:50:12.000
it's genuinely ridiculous.

00:50:12.000 --> 00:50:13.570
Bewildering that it would pass.

00:50:13.570 --> 00:50:16.160
But you can see
that there has been

00:50:16.160 --> 00:50:18.579
a lot of public pressure
or political pressure,

00:50:18.579 --> 00:50:19.870
maybe not even public pressure.

00:50:19.870 --> 00:50:23.000
Political pressure to be
seen to be doing something

00:50:23.000 --> 00:50:26.790
about bad things going online.

00:50:26.790 --> 00:50:30.340
And as a result, the
mentality is often,

00:50:30.340 --> 00:50:32.050
we need to do something.

00:50:32.050 --> 00:50:33.760
This is something.

00:50:33.760 --> 00:50:35.270
Let's do this, then.

00:50:35.270 --> 00:50:37.270
Rather than thinking
really carefully about what

00:50:37.270 --> 00:50:39.180
the best thing to do is.

00:50:39.180 --> 00:50:40.877
AUDIENCE: Thanks a lot.

00:50:40.877 --> 00:50:41.710
JAMIE BARTLETT: Yes.

00:50:41.710 --> 00:50:43.169
This is probably
the last question.

00:50:43.169 --> 00:50:45.459
ANTHONY HOUSE: Well, you've
got time for last question.

00:50:45.459 --> 00:50:47.030
JAMIE BARTLETT:
One more question.

00:50:47.030 --> 00:50:48.240
AUDIENCE: So when I was
listening to your speech--

00:50:48.240 --> 00:50:49.460
it was very
interesting, thank you--

00:50:49.460 --> 00:50:51.260
and you were talking about
things like these suicide

00:50:51.260 --> 00:50:51.930
forums and things.

00:50:51.930 --> 00:50:54.263
And I was sitting there and
all I was thinking was, wow.

00:50:54.263 --> 00:50:55.400
Technologically savvy.

00:50:55.400 --> 00:50:56.025
Suicide forums.

00:50:56.025 --> 00:50:57.941
As in people who know
how to find these things

00:50:57.941 --> 00:50:58.720
and get to them.

00:50:58.720 --> 00:51:01.100
Or buying drugs
online or whatever--

00:51:01.100 --> 00:51:02.605
technologically
savvy drug buyers.

00:51:02.605 --> 00:51:05.471
People know how to get
them and find these things.

00:51:05.471 --> 00:51:06.970
And then at the end
you said how you

00:51:06.970 --> 00:51:10.491
think what could make it better
would be if people's lives were

00:51:10.491 --> 00:51:11.990
more interesting,
that they wouldn't

00:51:11.990 --> 00:51:13.211
spend so much time in there.

00:51:13.211 --> 00:51:14.960
But then you also
mentioned in your answer

00:51:14.960 --> 00:51:15.720
to one of the
questions that you've

00:51:15.720 --> 00:51:18.710
explained how Tor browsers
work and how encryption works

00:51:18.710 --> 00:51:21.260
and how people go about
using these things.

00:51:21.260 --> 00:51:24.555
And I just wonder, are you not,
as a result through this book,

00:51:24.555 --> 00:51:26.930
empowering people who are
probably quite curious but just

00:51:26.930 --> 00:51:31.590
not capable to become capable
and get lost in this very world

00:51:31.590 --> 00:51:33.885
themselves?

00:51:33.885 --> 00:51:36.010
JAMIE BARTLETT: That's
probably the single question

00:51:36.010 --> 00:51:37.590
I asked myself repeatedly.

00:51:37.590 --> 00:51:39.490
Should I even write this thing?

00:51:39.490 --> 00:51:45.080
Is there a public interest
to putting some of this stuff

00:51:45.080 --> 00:51:47.330
out there, or not?

00:51:47.330 --> 00:51:51.790
I was very careful not
to give a careful guide.

00:51:51.790 --> 00:51:53.180
Precisely how you do it.

00:51:53.180 --> 00:51:55.630
Precisely how you stay
totally secure if you're

00:51:55.630 --> 00:51:57.320
going to go onto the Silk Road.

00:51:57.320 --> 00:52:00.160
Precisely what the names of
all these different forums

00:52:00.160 --> 00:52:01.700
and places are.

00:52:01.700 --> 00:52:07.650
So I did what I could to
limit the guidebook problem.

00:52:07.650 --> 00:52:10.230
But in the end, I
concluded, yes, it's

00:52:10.230 --> 00:52:11.900
quite possible that
people will become

00:52:11.900 --> 00:52:13.810
fascinated by some of this.

00:52:13.810 --> 00:52:15.960
And adventure in there
and get stuck in there

00:52:15.960 --> 00:52:19.070
and lost in there
and trapped in there.

00:52:19.070 --> 00:52:23.300
But in the end I just decided
society's usually better served

00:52:23.300 --> 00:52:27.120
when we know what's going
on, rather than pretending

00:52:27.120 --> 00:52:29.330
it doesn't or hiding it
or not talking about it.

00:52:29.330 --> 00:52:31.920
Because people tend to
find this stuff anyway.

00:52:31.920 --> 00:52:33.930
So my final
conclusion was really

00:52:33.930 --> 00:52:37.220
when I was thinking about
this ethically in my head,

00:52:37.220 --> 00:52:39.470
I think it's better that
it's out there than it's not.

00:52:39.470 --> 00:52:41.345
AUDIENCE: No, I agree
it's great that there's

00:52:41.345 --> 00:52:43.230
a revelation as to the
stuff that's going on.

00:52:43.230 --> 00:52:46.670
It's just whether or not are
there enough instructions there

00:52:46.670 --> 00:52:48.740
for people who
read it to go, huh.

00:52:48.740 --> 00:52:51.767
Wouldn't mind finding out a
bit more about this myself.

00:52:51.767 --> 00:52:53.600
JAMIE BARTLETT: Is that
a personal question?

00:52:53.600 --> 00:52:54.270
AUDIENCE: Possibly.

00:52:54.270 --> 00:52:54.830
Well, yeah.

00:52:54.830 --> 00:52:54.870
Absolutely.

00:52:54.870 --> 00:52:55.220
Absolutely.

00:52:55.220 --> 00:52:55.970
I mean, certainly.

00:52:55.970 --> 00:52:56.790
I could well do so.

00:52:56.790 --> 00:52:58.000
JAMIE BARTLETT: Yeah.

00:52:58.000 --> 00:52:59.090
I don't think so.

00:52:59.090 --> 00:53:02.070
I tried carefully to avoid that.

00:53:02.070 --> 00:53:04.370
There may be bits
where people-- I

00:53:04.370 --> 00:53:06.570
mean, if no one's ever
heard of the Silk Road

00:53:06.570 --> 00:53:11.510
and they see basically how
good the quality of cocaine

00:53:11.510 --> 00:53:13.670
is that you can buy there,
they might decide, oh.

00:53:13.670 --> 00:53:16.115
I think I'm going
to go on Silk Road.

00:53:16.115 --> 00:53:17.390
And that's a possibility.

00:53:17.390 --> 00:53:18.180
But let's face it.

00:53:18.180 --> 00:53:20.720
The Silk Road has been
talked about an awful lot

00:53:20.720 --> 00:53:22.500
for an awful long time.

00:53:22.500 --> 00:53:24.500
And most of these things
do pop up in the news.

00:53:24.500 --> 00:53:26.791
As I said in the beginning,
they do pop up in the news.

00:53:26.791 --> 00:53:27.840
You do hear about them.

00:53:27.840 --> 00:53:29.600
But I actually don't
think you could

00:53:29.600 --> 00:53:31.130
get quite the full picture.

00:53:31.130 --> 00:53:33.964
So if no one had ever
mentioned the Silk Road before

00:53:33.964 --> 00:53:35.380
and it had never
been in the media

00:53:35.380 --> 00:53:37.234
and I was the first
person to discover it,

00:53:37.234 --> 00:53:38.650
I think I probably
would be really

00:53:38.650 --> 00:53:40.047
careful about writing about it.

00:53:40.047 --> 00:53:42.630
I think most of these subjects,
you've heard stuff about them.

00:53:42.630 --> 00:53:45.800
Anyone curious is going to
have heard and found them.

00:53:45.800 --> 00:53:47.810
I'd rather go in
there and really

00:53:47.810 --> 00:53:49.839
find out why this
stuff's happening.

00:53:49.839 --> 00:53:50.380
AUDIENCE: OK.

00:53:50.380 --> 00:53:50.926
Thank you.

00:53:50.926 --> 00:53:51.402
JAMIE BARTLETT: Yeah.

00:53:51.402 --> 00:53:51.902
Yeah.

00:53:51.902 --> 00:53:54.490
You had to read it and find out.

00:53:56.329 --> 00:53:57.995
FEMALE SPEAKER: Jamie,
have you got time

00:53:57.995 --> 00:54:00.015
for one more question
before we wrap up?

00:54:00.015 --> 00:54:00.890
JAMIE BARTLETT: Yeah.

00:54:00.890 --> 00:54:04.410
I was going to say a joke about
that being a question, but yes.

00:54:04.410 --> 00:54:04.945
Yeah.

00:54:04.945 --> 00:54:05.830
AUDIENCE: Hi, sir.

00:54:05.830 --> 00:54:06.560
I'm Oliver.

00:54:06.560 --> 00:54:08.830
And I think following on
from Shane's question, where

00:54:08.830 --> 00:54:11.246
he's saying essentially for
people who wouldn't have found

00:54:11.246 --> 00:54:13.100
out how to find
something, whether you've

00:54:13.100 --> 00:54:14.975
written about it, in
fact it's really, really

00:54:14.975 --> 00:54:16.270
easy to find stuff, right?

00:54:16.270 --> 00:54:17.264
So I'm an 11-year-old.

00:54:17.264 --> 00:54:18.930
I can type porn into
Google, and there's

00:54:18.930 --> 00:54:20.180
a picture of people having sex.

00:54:20.180 --> 00:54:21.179
So I click on something.

00:54:21.179 --> 00:54:21.800
I get a video.

00:54:21.800 --> 00:54:24.560
I can have homosexual,
heterosexual.

00:54:24.560 --> 00:54:26.850
There's probably some
not legal stuff on there.

00:54:26.850 --> 00:54:29.266
So it's actually, I think,
more of a question to Googlers.

00:54:29.266 --> 00:54:31.780
At what point do we actually
say should it be moderated.

00:54:31.780 --> 00:54:33.290
Because I think it's well
enough not to have it

00:54:33.290 --> 00:54:35.580
openly advertised somewhere,
but it's in fact very,

00:54:35.580 --> 00:54:37.170
very easily accessible.

00:54:37.170 --> 00:54:39.930
And I know within the company,
there's some programs going on.

00:54:39.930 --> 00:54:40.270
JAMIE BARTLETT: Yeah.

00:54:40.270 --> 00:54:41.890
AUDIENCE: On having child
settings, so on and so forth.

00:54:41.890 --> 00:54:42.230
JAMIE BARTLETT: Yeah.

00:54:42.230 --> 00:54:43.450
AUDIENCE: But I think
the problem is probably

00:54:43.450 --> 00:54:44.324
the other way around.

00:54:44.324 --> 00:54:45.700
A lot of stuff is out there.

00:54:45.700 --> 00:54:47.420
And for adults, I
totally agree with you.

00:54:47.420 --> 00:54:50.640
Everybody should be
able to see most things.

00:54:50.640 --> 00:54:51.710
I'm very liberal there.

00:54:51.710 --> 00:54:53.834
But where with children
do we draw the line?

00:54:53.834 --> 00:54:55.000
And how do we moderate them?

00:54:55.000 --> 00:54:56.416
What would you do
if you-- I don't

00:54:56.416 --> 00:54:59.030
know whether you have children.

00:54:59.030 --> 00:55:00.450
JAMIE BARTLETT: Sorry.

00:55:00.450 --> 00:55:01.100
Yeah.

00:55:01.100 --> 00:55:01.600
Yeah.

00:55:01.600 --> 00:55:04.030
I should put an 18 plus
warning on the book, maybe.

00:55:04.030 --> 00:55:04.775
So--

00:55:04.775 --> 00:55:05.400
AUDIENCE: Yeah.

00:55:07.422 --> 00:55:08.630
JAMIE BARTLETT: You're right.

00:55:08.630 --> 00:55:10.730
It's a question for you.

00:55:10.730 --> 00:55:14.580
I think more broadly, it's a
question for public debate.

00:55:14.580 --> 00:55:16.540
It's a question
that we try to have

00:55:16.540 --> 00:55:21.570
to come to something of uneasy
conclusion collectively.

00:55:21.570 --> 00:55:24.270
And I don't think the answer
just rests with Google

00:55:24.270 --> 00:55:27.290
or certainly not with me.

00:55:27.290 --> 00:55:29.140
The one thing that
I did notice overall

00:55:29.140 --> 00:55:32.077
is that I imagine that
the Dark Net, as in Tor

00:55:32.077 --> 00:55:34.410
hidden services, the most
anonymous bit of the internet,

00:55:34.410 --> 00:55:37.520
would be where I'd find
all the nastiest stuff.

00:55:37.520 --> 00:55:40.310
And that's really not the case.

00:55:40.310 --> 00:55:42.033
It can be anywhere.

00:55:42.033 --> 00:55:42.780
It's on Facebook.

00:55:42.780 --> 00:55:43.900
It's on Twitter.

00:55:43.900 --> 00:55:45.820
Beheading videos on YouTube.

00:55:45.820 --> 00:55:47.630
It's not all hidden away.

00:55:47.630 --> 00:55:49.490
It's very easy to find.

00:55:49.490 --> 00:55:53.740
And I often think
back to-- I'm 34 now.

00:55:53.740 --> 00:55:57.240
And if I was 14 or 15
and I had a smart phone

00:55:57.240 --> 00:55:59.690
and I had internet
access at home,

00:55:59.690 --> 00:56:03.550
I dread to think
what I-- I mean,

00:56:03.550 --> 00:56:05.740
I would be looking for
everything all the time

00:56:05.740 --> 00:56:07.010
There's no doubt about it.

00:56:07.010 --> 00:56:09.620
And sharing amongst my friends
and doing terrible stuff

00:56:09.620 --> 00:56:10.450
like that.

00:56:10.450 --> 00:56:12.970
Sexting and-- just
I can imagine.

00:56:12.970 --> 00:56:15.120
Because I know what it's
like when you're that age.

00:56:15.120 --> 00:56:16.049
And you'll find it.

00:56:16.049 --> 00:56:17.840
And these kids will
find a way around this.

00:56:17.840 --> 00:56:20.430
So it is a really big
question, I think,

00:56:20.430 --> 00:56:24.940
for all of us to try to answer.

00:56:24.940 --> 00:56:26.930
But I don't have
the answer to that.

00:56:26.930 --> 00:56:27.910
I don't think you do.

00:56:27.910 --> 00:56:32.210
But I think collectively
we can figure out something

00:56:32.210 --> 00:56:33.860
maybe slightly better
than we have now.

00:56:36.315 --> 00:56:37.940
ANTHONY HOUSE: Thank
you for your time.

00:56:37.940 --> 00:56:39.139
[APPLAUSE]

00:56:39.139 --> 00:56:41.180
ANTHONY HOUSE: Thank you
very much for coming in.

00:56:41.180 --> 00:56:44.830
[APPLAUSE]

