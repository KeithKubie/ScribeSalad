WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.461
A linear model is not going to be helpful here, because we

00:00:03.461 --> 00:00:08.090
require a model that is capable of portraying a non-linear relationship.

00:00:08.090 --> 00:00:11.314
Now, there are several options for accomplishing this.

00:00:11.314 --> 00:00:17.271
We might use k-nearest neighbor or we might consider using neural networks or we

00:00:17.271 --> 00:00:23.237
might consider using a kernel density estimation at each point of elapsed time.

00:00:23.237 --> 00:00:26.962
In fact, that might be where we'd go if we did not get anywhere using any

00:00:26.962 --> 00:00:27.902
other features.

00:00:27.902 --> 00:00:34.213
To make use of our feature set, let's attempt to use a k-nearest neighbors fit.

00:00:34.213 --> 00:00:39.280
Before we jump into fitting our k-nearest neighbor's model.

00:00:39.280 --> 00:00:42.988
let's talk briefly about preparing out data points.

00:00:42.988 --> 00:00:48.244
So let's talk briefly about how we collect a series of training points that

00:00:48.244 --> 00:00:54.032
contain intertweet time, tweet length, elapsed time and mention distance.

00:00:54.032 --> 00:00:55.969
So recall in the original data set.

00:00:57.930 --> 00:01:05.450
We're given points, such as t1 and t2 representing two succeeding tweets.

00:01:05.450 --> 00:01:10.745
The amount of time taken between them is considered the intertweet time, but

00:01:10.745 --> 00:01:14.581
we want something that's more fine grained than this.

00:01:14.581 --> 00:01:18.736
What we're looking for is given an amount of time that has elapsed since

00:01:18.736 --> 00:01:24.030
the previous tweet, how much more time do we have to go until the next one?

00:01:24.030 --> 00:01:28.434
We're going to produce that information for each pair of given points.

00:01:28.434 --> 00:01:34.142
For example, if this is the intertweet time between two given tweets,

00:01:34.142 --> 00:01:37.030
we can choose a point here.

00:01:37.030 --> 00:01:41.230
And consider the beginning to that point to be elapsed time and

00:01:41.230 --> 00:01:44.830
that point to the end to be the time to go.

00:01:44.830 --> 00:01:49.240
And we can consider putting that marker at many points,

00:01:49.240 --> 00:01:51.850
giving us many values of delta s and p.

00:01:53.000 --> 00:01:58.199
This gives us many values of elapsed time and time to go.

00:01:58.199 --> 00:02:00.373
And for each one of those points,

00:02:00.373 --> 00:02:04.411
we still know the length of the previous tweet and the number of

00:02:04.411 --> 00:02:09.473
seconds that has elapsed since the last time this person has been mentioned.

00:02:09.473 --> 00:02:12.877
In this way, we construct out training points.

00:02:12.877 --> 00:02:18.633
So after constructing our training points in this way,

00:02:18.633 --> 00:02:23.415
we get a total of 1,381,258 points.

00:02:23.415 --> 00:02:30.552
And we will split those points into 70% training and 30% test.

00:02:30.552 --> 00:02:34.392
Let's go ahead and fit the data and perform some steps of validation and

00:02:34.392 --> 00:02:37.537
measure the performance of using k-nearest neighbors.

