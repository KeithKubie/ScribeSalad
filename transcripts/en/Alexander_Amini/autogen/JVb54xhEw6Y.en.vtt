WEBVTT
Kind: captions
Language: en

00:00:02.139 --> 00:00:04.480
all right thanks very much for the

00:00:04.480 --> 00:00:04.490
all right thanks very much for the
 

00:00:04.490 --> 00:00:08.379
all right thanks very much for the
invitation to speak to you yeah so I'm

00:00:08.379 --> 00:00:08.389
invitation to speak to you yeah so I'm
 

00:00:08.389 --> 00:00:10.209
invitation to speak to you yeah so I'm
gonna be talking about deep generative

00:00:10.209 --> 00:00:10.219
gonna be talking about deep generative
 

00:00:10.219 --> 00:00:12.970
gonna be talking about deep generative
models so when we talk about deep

00:00:12.970 --> 00:00:12.980
models so when we talk about deep
 

00:00:12.980 --> 00:00:14.440
models so when we talk about deep
generative models what we're really

00:00:14.440 --> 00:00:14.450
generative models what we're really
 

00:00:14.450 --> 00:00:16.180
generative models what we're really
talking about here from my point of view

00:00:16.180 --> 00:00:16.190
talking about here from my point of view
 

00:00:16.190 --> 00:00:20.320
talking about here from my point of view
is to essentially train neural nets from

00:00:20.320 --> 00:00:20.330
is to essentially train neural nets from
 

00:00:20.330 --> 00:00:23.920
is to essentially train neural nets from
training examples in order to represent

00:00:23.920 --> 00:00:23.930
training examples in order to represent
 

00:00:23.930 --> 00:00:26.140
training examples in order to represent
the distribution from which these came

00:00:26.140 --> 00:00:26.150
the distribution from which these came
 

00:00:26.150 --> 00:00:28.350
the distribution from which these came
so we can think about this as either

00:00:28.350 --> 00:00:28.360
so we can think about this as either
 

00:00:28.360 --> 00:00:30.400
so we can think about this as either
explicitly doing density estimation

00:00:30.400 --> 00:00:30.410
explicitly doing density estimation
 

00:00:30.410 --> 00:00:32.260
explicitly doing density estimation
where we have some samples here and we

00:00:32.260 --> 00:00:32.270
where we have some samples here and we
 

00:00:32.270 --> 00:00:34.060
where we have some samples here and we
try to model those samples with some

00:00:34.060 --> 00:00:34.070
try to model those samples with some
 

00:00:34.070 --> 00:00:36.340
try to model those samples with some
density estimation or we can think of it

00:00:36.340 --> 00:00:36.350
density estimation or we can think of it
 

00:00:36.350 --> 00:00:39.220
density estimation or we can think of it
more like this which is what actually

00:00:39.220 --> 00:00:39.230
more like this which is what actually
 

00:00:39.230 --> 00:00:41.619
more like this which is what actually
I'll be doing a lot more of this kind of

00:00:41.619 --> 00:00:41.629
I'll be doing a lot more of this kind of
 

00:00:41.629 --> 00:00:42.970
I'll be doing a lot more of this kind of
thing which is essentially we're worried

00:00:42.970 --> 00:00:42.980
thing which is essentially we're worried
 

00:00:42.980 --> 00:00:45.729
thing which is essentially we're worried
about sample generation here so we have

00:00:45.729 --> 00:00:45.739
about sample generation here so we have
 

00:00:45.739 --> 00:00:48.309
about sample generation here so we have
some training examples like this where

00:00:48.309 --> 00:00:48.319
some training examples like this where
 

00:00:48.319 --> 00:00:50.319
some training examples like this where
we're sort of just natural images from

00:00:50.319 --> 00:00:50.329
we're sort of just natural images from
 

00:00:50.329 --> 00:00:52.750
we're sort of just natural images from
the world and Rast asking a model to

00:00:52.750 --> 00:00:52.760
the world and Rast asking a model to
 

00:00:52.760 --> 00:00:55.989
the world and Rast asking a model to
train to learn to output images like

00:00:55.989 --> 00:00:55.999
train to learn to output images like
 

00:00:55.999 --> 00:00:58.899
train to learn to output images like
this now these are actually not true

00:00:58.899 --> 00:00:58.909
this now these are actually not true
 

00:00:58.909 --> 00:01:01.779
this now these are actually not true
samples these are actually just other

00:01:01.779 --> 00:01:01.789
samples these are actually just other
 

00:01:01.789 --> 00:01:03.399
samples these are actually just other
images from the same training so I

00:01:03.399 --> 00:01:03.409
images from the same training so I
 

00:01:03.409 --> 00:01:07.030
images from the same training so I
believe this is from imagenet a few

00:01:07.030 --> 00:01:07.040
believe this is from imagenet a few
 

00:01:07.040 --> 00:01:09.310
believe this is from imagenet a few
years ago or even a few months ago this

00:01:09.310 --> 00:01:09.320
years ago or even a few months ago this
 

00:01:09.320 --> 00:01:11.350
years ago or even a few months ago this
would have seemed obvious that this you

00:01:11.350 --> 00:01:11.360
would have seemed obvious that this you
 

00:01:11.360 --> 00:01:13.389
would have seemed obvious that this you
couldn't generate samples like this but

00:01:13.389 --> 00:01:13.399
couldn't generate samples like this but
 

00:01:13.399 --> 00:01:15.850
couldn't generate samples like this but
in fact nowadays this is actually not so

00:01:15.850 --> 00:01:15.860
in fact nowadays this is actually not so
 

00:01:15.860 --> 00:01:17.230
in fact nowadays this is actually not so
obvious that we couldn't generate these

00:01:17.230 --> 00:01:17.240
obvious that we couldn't generate these
 

00:01:17.240 --> 00:01:19.420
obvious that we couldn't generate these
so it's been a very exciting time in

00:01:19.420 --> 00:01:19.430
so it's been a very exciting time in
 

00:01:19.430 --> 00:01:21.399
so it's been a very exciting time in
this area and the amount of work we've

00:01:21.399 --> 00:01:21.409
this area and the amount of work we've
 

00:01:21.409 --> 00:01:23.020
this area and the amount of work we've
done in the amount of progress we've

00:01:23.020 --> 00:01:23.030
done in the amount of progress we've
 

00:01:23.030 --> 00:01:24.459
done in the amount of progress we've
made in the last few years has been

00:01:24.459 --> 00:01:24.469
made in the last few years has been
 

00:01:24.469 --> 00:01:26.950
made in the last few years has been
pretty remarkable and so I think part of

00:01:26.950 --> 00:01:26.960
pretty remarkable and so I think part of
 

00:01:26.960 --> 00:01:28.270
pretty remarkable and so I think part of
what I want to do here is tell you a

00:01:28.270 --> 00:01:28.280
what I want to do here is tell you a
 

00:01:28.280 --> 00:01:29.950
what I want to do here is tell you a
little bit about that progress give you

00:01:29.950 --> 00:01:29.960
little bit about that progress give you
 

00:01:29.960 --> 00:01:33.459
little bit about that progress give you
some sense of where we were in say 2014

00:01:33.459 --> 00:01:33.469
some sense of where we were in say 2014
 

00:01:33.469 --> 00:01:36.249
some sense of where we were in say 2014
when this started really to accelerate

00:01:36.249 --> 00:01:36.259
when this started really to accelerate
 

00:01:36.259 --> 00:01:40.120
when this started really to accelerate
and and where we are now so yeah so so

00:01:40.120 --> 00:01:40.130
and and where we are now so yeah so so
 

00:01:40.130 --> 00:01:41.770
and and where we are now so yeah so so
why generative models why do we care

00:01:41.770 --> 00:01:41.780
why generative models why do we care
 

00:01:41.780 --> 00:01:43.330
why generative models why do we care
about generative modeling well there's a

00:01:43.330 --> 00:01:43.340
about generative modeling well there's a
 

00:01:43.340 --> 00:01:44.859
about generative modeling well there's a
there's a bunch of reasons some of us

00:01:44.859 --> 00:01:44.869
there's a bunch of reasons some of us
 

00:01:44.869 --> 00:01:45.940
there's a bunch of reasons some of us
are just really interested in making

00:01:45.940 --> 00:01:45.950
are just really interested in making
 

00:01:45.950 --> 00:01:47.889
are just really interested in making
pretty pictures and I confess that for

00:01:47.889 --> 00:01:47.899
pretty pictures and I confess that for
 

00:01:47.899 --> 00:01:48.880
pretty pictures and I confess that for
the most part that's what I'll be

00:01:48.880 --> 00:01:48.890
the most part that's what I'll be
 

00:01:48.890 --> 00:01:50.800
the most part that's what I'll be
showing you today is just as an

00:01:50.800 --> 00:01:50.810
showing you today is just as an
 

00:01:50.810 --> 00:01:53.380
showing you today is just as an
evaluation metric we'll just be looking

00:01:53.380 --> 00:01:53.390
evaluation metric we'll just be looking
 

00:01:53.390 --> 00:01:56.230
evaluation metric we'll just be looking
at pictures just natural images and how

00:01:56.230 --> 00:01:56.240
at pictures just natural images and how
 

00:01:56.240 --> 00:01:57.639
at pictures just natural images and how
well we're doing in natural images but

00:01:57.639 --> 00:01:57.649
well we're doing in natural images but
 

00:01:57.649 --> 00:01:59.230
well we're doing in natural images but
there's actually real tasks that we care

00:01:59.230 --> 00:01:59.240
there's actually real tasks that we care
 

00:01:59.240 --> 00:02:00.340
there's actually real tasks that we care
about when we talk about generative

00:02:00.340 --> 00:02:00.350
about when we talk about generative
 

00:02:00.350 --> 00:02:02.560
about when we talk about generative
modeling one of them is just let's say

00:02:02.560 --> 00:02:02.570
modeling one of them is just let's say
 

00:02:02.570 --> 00:02:03.730
modeling one of them is just let's say
you want to do some conditional

00:02:03.730 --> 00:02:03.740
you want to do some conditional
 

00:02:03.740 --> 00:02:06.039
you want to do some conditional
generation like for example machine

00:02:06.039 --> 00:02:06.049
generation like for example machine
 

00:02:06.049 --> 00:02:07.630
generation like for example machine
translation right so we're conditioning

00:02:07.630 --> 00:02:07.640
translation right so we're conditioning
 

00:02:07.640 --> 00:02:09.340
translation right so we're conditioning
on some source sentence and we want to

00:02:09.340 --> 00:02:09.350
on some source sentence and we want to
 

00:02:09.350 --> 00:02:12.339
on some source sentence and we want to
output some target sentence well the

00:02:12.339 --> 00:02:12.349
output some target sentence well the
 

00:02:12.349 --> 00:02:14.410
output some target sentence well the
structure within that target sentence

00:02:14.410 --> 00:02:14.420
structure within that target sentence
 

00:02:14.420 --> 00:02:15.160
structure within that target sentence
that

00:02:15.160 --> 00:02:15.170
that
 

00:02:15.170 --> 00:02:17.230
that
target language let's say that the the

00:02:17.230 --> 00:02:17.240
target language let's say that the the
 

00:02:17.240 --> 00:02:19.720
target language let's say that the the
rules the grammatical rules you can

00:02:19.720 --> 00:02:19.730
rules the grammatical rules you can
 

00:02:19.730 --> 00:02:21.550
rules the grammatical rules you can
model that structure using a generative

00:02:21.550 --> 00:02:21.560
model that structure using a generative
 

00:02:21.560 --> 00:02:23.860
model that structure using a generative
model so this is an instance of where we

00:02:23.860 --> 00:02:23.870
model so this is an instance of where we
 

00:02:23.870 --> 00:02:25.680
model so this is an instance of where we
would do conditional generative modeling

00:02:25.680 --> 00:02:25.690
would do conditional generative modeling
 

00:02:25.690 --> 00:02:28.839
would do conditional generative modeling
another example where this is something

00:02:28.839 --> 00:02:28.849
another example where this is something
 

00:02:28.849 --> 00:02:30.100
another example where this is something
that we're actually looking a little bit

00:02:30.100 --> 00:02:30.110
that we're actually looking a little bit
 

00:02:30.110 --> 00:02:32.740
that we're actually looking a little bit
towards is is can we use generative

00:02:32.740 --> 00:02:32.750
towards is is can we use generative
 

00:02:32.750 --> 00:02:34.449
towards is is can we use generative
models as outlier detection and actually

00:02:34.449 --> 00:02:34.459
models as outlier detection and actually
 

00:02:34.459 --> 00:02:36.610
models as outlier detection and actually
recently these types of models have been

00:02:36.610 --> 00:02:36.620
recently these types of models have been
 

00:02:36.620 --> 00:02:39.160
recently these types of models have been
integrated into RL algorithms to help

00:02:39.160 --> 00:02:39.170
integrated into RL algorithms to help
 

00:02:39.170 --> 00:02:40.900
integrated into RL algorithms to help
them do exploration more effectively

00:02:40.900 --> 00:02:40.910
them do exploration more effectively
 

00:02:40.910 --> 00:02:43.660
them do exploration more effectively
this was dot work done at deep mind I

00:02:43.660 --> 00:02:43.670
this was dot work done at deep mind I
 

00:02:43.670 --> 00:02:47.020
this was dot work done at deep mind I
believe so here we're looking at you

00:02:47.020 --> 00:02:47.030
believe so here we're looking at you
 

00:02:47.030 --> 00:02:49.360
believe so here we're looking at you
know a case where you know if you think

00:02:49.360 --> 00:02:49.370
know a case where you know if you think
 

00:02:49.370 --> 00:02:51.130
know a case where you know if you think
about kind about this is a toyish

00:02:51.130 --> 00:02:51.140
about kind about this is a toyish
 

00:02:51.140 --> 00:02:53.770
about kind about this is a toyish
version of the autonomous vehicle task

00:02:53.770 --> 00:02:53.780
version of the autonomous vehicle task
 

00:02:53.780 --> 00:02:55.180
version of the autonomous vehicle task
and you want to be able to distinguish

00:02:55.180 --> 00:02:55.190
and you want to be able to distinguish
 

00:02:55.190 --> 00:02:57.699
and you want to be able to distinguish
cars and and wheelchairs and then you're

00:02:57.699 --> 00:02:57.709
cars and and wheelchairs and then you're
 

00:02:57.709 --> 00:02:58.990
cars and and wheelchairs and then you're
gonna have something like this and you

00:02:58.990 --> 00:02:59.000
gonna have something like this and you
 

00:02:59.000 --> 00:03:00.850
gonna have something like this and you
don't want your classifier to just

00:03:00.850 --> 00:03:00.860
don't want your classifier to just
 

00:03:00.860 --> 00:03:03.190
don't want your classifier to just
blindly say oh I think it's either a car

00:03:03.190 --> 00:03:03.200
blindly say oh I think it's either a car
 

00:03:03.200 --> 00:03:05.559
blindly say oh I think it's either a car
or a wheelchair you want your classifier

00:03:05.559 --> 00:03:05.569
or a wheelchair you want your classifier
 

00:03:05.569 --> 00:03:07.960
or a wheelchair you want your classifier
to understand that this is an outlier

00:03:07.960 --> 00:03:07.970
to understand that this is an outlier
 

00:03:07.970 --> 00:03:09.640
to understand that this is an outlier
right and and you can use generative

00:03:09.640 --> 00:03:09.650
right and and you can use generative
 

00:03:09.650 --> 00:03:11.860
right and and you can use generative
modeling to be able to do that by

00:03:11.860 --> 00:03:11.870
modeling to be able to do that by
 

00:03:11.870 --> 00:03:13.210
modeling to be able to do that by
noticing that there aren't very many

00:03:13.210 --> 00:03:13.220
noticing that there aren't very many
 

00:03:13.220 --> 00:03:15.789
noticing that there aren't very many
things like this example from the

00:03:15.789 --> 00:03:15.799
things like this example from the
 

00:03:15.799 --> 00:03:17.800
things like this example from the
training set so you can proceed with

00:03:17.800 --> 00:03:17.810
training set so you can proceed with
 

00:03:17.810 --> 00:03:20.020
training set so you can proceed with
caution and this is kind of a big deal

00:03:20.020 --> 00:03:20.030
caution and this is kind of a big deal
 

00:03:20.030 --> 00:03:21.039
caution and this is kind of a big deal
right because we don't want our

00:03:21.039 --> 00:03:21.049
right because we don't want our
 

00:03:21.049 --> 00:03:22.599
right because we don't want our
classifiers are our neural net

00:03:22.599 --> 00:03:22.609
classifiers are our neural net
 

00:03:22.609 --> 00:03:24.400
classifiers are our neural net
classifiers are very very capable of

00:03:24.400 --> 00:03:24.410
classifiers are very very capable of
 

00:03:24.410 --> 00:03:26.020
classifiers are very very capable of
doing excellent performance

00:03:26.020 --> 00:03:26.030
doing excellent performance
 

00:03:26.030 --> 00:03:27.970
doing excellent performance
classification but but any classifiers

00:03:27.970 --> 00:03:27.980
classification but but any classifiers
 

00:03:27.980 --> 00:03:29.650
classification but but any classifiers
just trained to output one of the

00:03:29.650 --> 00:03:29.660
just trained to output one of the
 

00:03:29.660 --> 00:03:33.099
just trained to output one of the
classes that it's been given and so in

00:03:33.099 --> 00:03:33.109
classes that it's been given and so in
 

00:03:33.109 --> 00:03:35.530
classes that it's been given and so in
cases where we actually are faced with

00:03:35.530 --> 00:03:35.540
cases where we actually are faced with
 

00:03:35.540 --> 00:03:37.420
cases where we actually are faced with
something really new and that's not seen

00:03:37.420 --> 00:03:37.430
something really new and that's not seen
 

00:03:37.430 --> 00:03:39.430
something really new and that's not seen
before or perhaps in lumination

00:03:39.430 --> 00:03:39.440
before or perhaps in lumination
 

00:03:39.440 --> 00:03:41.050
before or perhaps in lumination
conditions that it's never been trained

00:03:41.050 --> 00:03:41.060
conditions that it's never been trained
 

00:03:41.060 --> 00:03:44.800
conditions that it's never been trained
to to cope with we want models that are

00:03:44.800 --> 00:03:44.810
to to cope with we want models that are
 

00:03:44.810 --> 00:03:47.680
to to cope with we want models that are
conservative in those cases so we hope

00:03:47.680 --> 00:03:47.690
conservative in those cases so we hope
 

00:03:47.690 --> 00:03:49.030
conservative in those cases so we hope
to be able to use generative models for

00:03:49.030 --> 00:03:49.040
to be able to use generative models for
 

00:03:49.040 --> 00:03:50.710
to be able to use generative models for
that another case where we're looking at

00:03:50.710 --> 00:03:50.720
that another case where we're looking at
 

00:03:50.720 --> 00:03:52.990
that another case where we're looking at
generative models being useful is in

00:03:52.990 --> 00:03:53.000
generative models being useful is in
 

00:03:53.000 --> 00:03:56.560
generative models being useful is in
going from simulation to real examples

00:03:56.560 --> 00:03:56.570
going from simulation to real examples
 

00:03:56.570 --> 00:03:59.440
going from simulation to real examples
of in robotics so so in robotics

00:03:59.440 --> 00:03:59.450
of in robotics so so in robotics
 

00:03:59.450 --> 00:04:01.300
of in robotics so so in robotics
training these robots with neural nets

00:04:01.300 --> 00:04:01.310
training these robots with neural nets
 

00:04:01.310 --> 00:04:03.910
training these robots with neural nets
is actually quite laborious if you're

00:04:03.910 --> 00:04:03.920
is actually quite laborious if you're
 

00:04:03.920 --> 00:04:05.140
is actually quite laborious if you're
really trying to do this on the real

00:04:05.140 --> 00:04:05.150
really trying to do this on the real
 

00:04:05.150 --> 00:04:06.910
really trying to do this on the real
robot it would take many many trials and

00:04:06.910 --> 00:04:06.920
robot it would take many many trials and
 

00:04:06.920 --> 00:04:08.830
robot it would take many many trials and
it's it's not really practical in

00:04:08.830 --> 00:04:08.840
it's it's not really practical in
 

00:04:08.840 --> 00:04:10.539
it's it's not really practical in
simulation this works much much better

00:04:10.539 --> 00:04:10.549
simulation this works much much better
 

00:04:10.549 --> 00:04:12.220
simulation this works much much better
but the problem is is that if you train

00:04:12.220 --> 00:04:12.230
but the problem is is that if you train
 

00:04:12.230 --> 00:04:14.710
but the problem is is that if you train
a policy in simulation and transfer it

00:04:14.710 --> 00:04:14.720
a policy in simulation and transfer it
 

00:04:14.720 --> 00:04:16.659
a policy in simulation and transfer it
to the real robot well that's not going

00:04:16.659 --> 00:04:16.669
to the real robot well that's not going
 

00:04:16.669 --> 00:04:18.190
to the real robot well that's not going
to work that hasn't worked very well

00:04:18.190 --> 00:04:18.200
to work that hasn't worked very well
 

00:04:18.200 --> 00:04:19.719
to work that hasn't worked very well
because the environment is just too

00:04:19.719 --> 00:04:19.729
because the environment is just too
 

00:04:19.729 --> 00:04:21.039
because the environment is just too
different but what if we could use a

00:04:21.039 --> 00:04:21.049
different but what if we could use a
 

00:04:21.049 --> 00:04:22.750
different but what if we could use a
generative model to make our simulation

00:04:22.750 --> 00:04:22.760
generative model to make our simulation
 

00:04:22.760 --> 00:04:24.790
generative model to make our simulation
so realistic that that transfer is

00:04:24.790 --> 00:04:24.800
so realistic that that transfer is
 

00:04:24.800 --> 00:04:27.580
so realistic that that transfer is
viable so this is one another area that

00:04:27.580 --> 00:04:27.590
viable so this is one another area that
 

00:04:27.590 --> 00:04:28.610
viable so this is one another area that
a number of groups are look

00:04:28.610 --> 00:04:28.620
a number of groups are look
 

00:04:28.620 --> 00:04:30.710
a number of groups are look
this kind of expression generator

00:04:30.710 --> 00:04:30.720
this kind of expression generator
 

00:04:30.720 --> 00:04:32.330
this kind of expression generator
modeling in this direction so there's

00:04:32.330 --> 00:04:32.340
modeling in this direction so there's
 

00:04:32.340 --> 00:04:34.250
modeling in this direction so there's
lots of really practical ways to use

00:04:34.250 --> 00:04:34.260
lots of really practical ways to use
 

00:04:34.260 --> 00:04:36.110
lots of really practical ways to use
generate models beyond just looking at

00:04:36.110 --> 00:04:36.120
generate models beyond just looking at
 

00:04:36.120 --> 00:04:40.070
generate models beyond just looking at
pretty pictures right so so I break down

00:04:40.070 --> 00:04:40.080
pretty pictures right so so I break down
 

00:04:40.080 --> 00:04:42.080
pretty pictures right so so I break down
the kinds of generative models there are

00:04:42.080 --> 00:04:42.090
the kinds of generative models there are
 

00:04:42.090 --> 00:04:44.180
the kinds of generative models there are
in the world in terms from two rough

00:04:44.180 --> 00:04:44.190
in the world in terms from two rough
 

00:04:44.190 --> 00:04:46.430
in the world in terms from two rough
categories here and maybe we can take

00:04:46.430 --> 00:04:46.440
categories here and maybe we can take
 

00:04:46.440 --> 00:04:47.750
categories here and maybe we can take
issue with this oh by the way if you

00:04:47.750 --> 00:04:47.760
issue with this oh by the way if you
 

00:04:47.760 --> 00:04:49.939
issue with this oh by the way if you
guys have questions go ahead and ahead

00:04:49.939 --> 00:04:49.949
guys have questions go ahead and ahead
 

00:04:49.949 --> 00:04:52.610
guys have questions go ahead and ahead
and ask me while you have them I think I

00:04:52.610 --> 00:04:52.620
and ask me while you have them I think I
 

00:04:52.620 --> 00:04:54.650
and ask me while you have them I think I
like interaction if possible or you can

00:04:54.650 --> 00:04:54.660
like interaction if possible or you can
 

00:04:54.660 --> 00:04:56.330
like interaction if possible or you can
just say them to the end either way is

00:04:56.330 --> 00:04:56.340
just say them to the end either way is
 

00:04:56.340 --> 00:05:00.050
just say them to the end either way is
fine and sorry for my voice I've got a

00:05:00.050 --> 00:05:00.060
fine and sorry for my voice I've got a
 

00:05:00.060 --> 00:05:02.360
fine and sorry for my voice I've got a
cold so yeah we have auto regressive

00:05:02.360 --> 00:05:02.370
cold so yeah we have auto regressive
 

00:05:02.370 --> 00:05:04.610
cold so yeah we have auto regressive
models and we have latent variable

00:05:04.610 --> 00:05:04.620
models and we have latent variable
 

00:05:04.620 --> 00:05:07.250
models and we have latent variable
models so auto regressive models are

00:05:07.250 --> 00:05:07.260
models so auto regressive models are
 

00:05:07.260 --> 00:05:10.580
models so auto regressive models are
models where you basically define an

00:05:10.580 --> 00:05:10.590
models where you basically define an
 

00:05:10.590 --> 00:05:13.219
models where you basically define an
ordering over your input right so for

00:05:13.219 --> 00:05:13.229
ordering over your input right so for
 

00:05:13.229 --> 00:05:15.469
ordering over your input right so for
things like speech recognition or

00:05:15.469 --> 00:05:15.479
things like speech recognition or
 

00:05:15.479 --> 00:05:17.510
things like speech recognition or
Strether's speech synthesis in the

00:05:17.510 --> 00:05:17.520
Strether's speech synthesis in the
 

00:05:17.520 --> 00:05:19.430
Strether's speech synthesis in the
gender and modeling case this is natural

00:05:19.430 --> 00:05:19.440
gender and modeling case this is natural
 

00:05:19.440 --> 00:05:20.719
gender and modeling case this is natural
right it's just there's a natural

00:05:20.719 --> 00:05:20.729
right it's just there's a natural
 

00:05:20.729 --> 00:05:22.570
right it's just there's a natural
ordering to that data it's just the

00:05:22.570 --> 00:05:22.580
ordering to that data it's just the
 

00:05:22.580 --> 00:05:25.370
ordering to that data it's just the
temporal sequence for things like images

00:05:25.370 --> 00:05:25.380
temporal sequence for things like images
 

00:05:25.380 --> 00:05:26.930
temporal sequence for things like images
it's a little less obvious how you would

00:05:26.930 --> 00:05:26.940
it's a little less obvious how you would
 

00:05:26.940 --> 00:05:29.000
it's a little less obvious how you would
define an ordering over pixels but there

00:05:29.000 --> 00:05:29.010
define an ordering over pixels but there
 

00:05:29.010 --> 00:05:31.370
define an ordering over pixels but there
are nonetheless models such as pixel R

00:05:31.370 --> 00:05:31.380
are nonetheless models such as pixel R
 

00:05:31.380 --> 00:05:33.650
are nonetheless models such as pixel R
and N and pixel CN n that do just this

00:05:33.650 --> 00:05:33.660
and N and pixel CN n that do just this
 

00:05:33.660 --> 00:05:36.110
and N and pixel CN n that do just this
in fact pixel CN n is a is a really

00:05:36.110 --> 00:05:36.120
in fact pixel CN n is a is a really
 

00:05:36.120 --> 00:05:38.089
in fact pixel CN n is a is a really
interesting model from this point of

00:05:38.089 --> 00:05:38.099
interesting model from this point of
 

00:05:38.099 --> 00:05:39.379
interesting model from this point of
view they basically define a

00:05:39.379 --> 00:05:39.389
view they basically define a
 

00:05:39.389 --> 00:05:42.140
view they basically define a
convolutional neural net with a mask so

00:05:42.140 --> 00:05:42.150
convolutional neural net with a mask so
 

00:05:42.150 --> 00:05:44.150
convolutional neural net with a mask so
if you remember our previous lecture we

00:05:44.150 --> 00:05:44.160
if you remember our previous lecture we
 

00:05:44.160 --> 00:05:45.890
if you remember our previous lecture we
did we saw these convolutional neural

00:05:45.890 --> 00:05:45.900
did we saw these convolutional neural
 

00:05:45.900 --> 00:05:47.570
did we saw these convolutional neural
nets but what they do is they stick a

00:05:47.570 --> 00:05:47.580
nets but what they do is they stick a
 

00:05:47.580 --> 00:05:49.820
nets but what they do is they stick a
mask on it so that you've got sort of a

00:05:49.820 --> 00:05:49.830
mask on it so that you've got sort of a
 

00:05:49.830 --> 00:05:51.770
mask on it so that you've got sort of a
causal direction so you're only looking

00:05:51.770 --> 00:05:51.780
causal direction so you're only looking
 

00:05:51.780 --> 00:05:54.800
causal direction so you're only looking
at previous pixels in the ordering that

00:05:54.800 --> 00:05:54.810
at previous pixels in the ordering that
 

00:05:54.810 --> 00:05:59.330
at previous pixels in the ordering that
you've defined the the the the well the

00:05:59.330 --> 00:05:59.340
you've defined the the the the well the
 

00:05:59.340 --> 00:06:01.250
you've defined the the the the well the
ordering that defined by the auto

00:06:01.250 --> 00:06:01.260
ordering that defined by the auto
 

00:06:01.260 --> 00:06:03.620
ordering that defined by the auto
regressive model so so you kind of

00:06:03.620 --> 00:06:03.630
regressive model so so you kind of
 

00:06:03.630 --> 00:06:06.680
regressive model so so you kind of
maintain this this ordering as you go

00:06:06.680 --> 00:06:06.690
maintain this this ordering as you go
 

00:06:06.690 --> 00:06:07.850
maintain this this ordering as you go
through the continent and what that

00:06:07.850 --> 00:06:07.860
through the continent and what that
 

00:06:07.860 --> 00:06:09.589
through the continent and what that
allows you to do is come up with a

00:06:09.589 --> 00:06:09.599
allows you to do is come up with a
 

00:06:09.599 --> 00:06:11.240
allows you to do is come up with a
generative model that's supported by

00:06:11.240 --> 00:06:11.250
generative model that's supported by
 

00:06:11.250 --> 00:06:13.400
generative model that's supported by
this confident that you know it's just a

00:06:13.400 --> 00:06:13.410
this confident that you know it's just a
 

00:06:13.410 --> 00:06:15.409
this confident that you know it's just a
full generative model and it's a it's a

00:06:15.409 --> 00:06:15.419
full generative model and it's a it's a
 

00:06:15.419 --> 00:06:16.790
full generative model and it's a it's a
pretty interesting model its own right

00:06:16.790 --> 00:06:16.800
pretty interesting model its own right
 

00:06:16.800 --> 00:06:19.040
pretty interesting model its own right
but because of I have rather limited

00:06:19.040 --> 00:06:19.050
but because of I have rather limited
 

00:06:19.050 --> 00:06:20.689
but because of I have rather limited
time I'm actually not going to go into

00:06:20.689 --> 00:06:20.699
time I'm actually not going to go into
 

00:06:20.699 --> 00:06:23.300
time I'm actually not going to go into
that model in particular another thing I

00:06:23.300 --> 00:06:23.310
that model in particular another thing I
 

00:06:23.310 --> 00:06:24.290
that model in particular another thing I
just want to point out here is that

00:06:24.290 --> 00:06:24.300
just want to point out here is that
 

00:06:24.300 --> 00:06:27.260
just want to point out here is that
wavenet is probably the state of the art

00:06:27.260 --> 00:06:27.270
wavenet is probably the state of the art
 

00:06:27.270 --> 00:06:29.930
wavenet is probably the state of the art
model for speech synthesis right now and

00:06:29.930 --> 00:06:29.940
model for speech synthesis right now and
 

00:06:29.940 --> 00:06:31.550
model for speech synthesis right now and
it forms the basis of very interesting

00:06:31.550 --> 00:06:31.560
it forms the basis of very interesting
 

00:06:31.560 --> 00:06:33.469
it forms the basis of very interesting
speech synthesis systems it's another

00:06:33.469 --> 00:06:33.479
speech synthesis systems it's another
 

00:06:33.479 --> 00:06:34.909
speech synthesis systems it's another
area where gender models have made a

00:06:34.909 --> 00:06:34.919
area where gender models have made a
 

00:06:34.919 --> 00:06:36.950
area where gender models have made a
remarkable contributions in the last few

00:06:36.950 --> 00:06:36.960
remarkable contributions in the last few
 

00:06:36.960 --> 00:06:39.290
remarkable contributions in the last few
years even the last few months so now

00:06:39.290 --> 00:06:39.300
years even the last few months so now
 

00:06:39.300 --> 00:06:40.909
years even the last few months so now
we're seeing models that you would be

00:06:40.909 --> 00:06:40.919
we're seeing models that you would be
 

00:06:40.919 --> 00:06:42.500
we're seeing models that you would be
fairly hard-pressed to just

00:06:42.500 --> 00:06:42.510
fairly hard-pressed to just
 

00:06:42.510 --> 00:06:44.660
fairly hard-pressed to just
English between natural speech and and

00:06:44.660 --> 00:06:44.670
English between natural speech and and
 

00:06:44.670 --> 00:06:47.390
English between natural speech and and
these kinds of models for the most part

00:06:47.390 --> 00:06:47.400
these kinds of models for the most part
 

00:06:47.400 --> 00:06:49.160
these kinds of models for the most part
so what I'm going to concentrate on is

00:06:49.160 --> 00:06:49.170
so what I'm going to concentrate on is
 

00:06:49.170 --> 00:06:52.370
so what I'm going to concentrate on is
latent variable models so latent

00:06:52.370 --> 00:06:52.380
latent variable models so latent
 

00:06:52.380 --> 00:06:54.340
latent variable models so latent
variable models are models that

00:06:54.340 --> 00:06:54.350
variable models are models that
 

00:06:54.350 --> 00:06:56.540
variable models are models that
essentially posit that you have some

00:06:56.540 --> 00:06:56.550
essentially posit that you have some
 

00:06:56.550 --> 00:06:58.970
essentially posit that you have some
latent variables that are hope that you

00:06:58.970 --> 00:06:58.980
latent variables that are hope that you
 

00:06:58.980 --> 00:07:01.100
latent variables that are hope that you
hope will represent some latent factors

00:07:01.100 --> 00:07:01.110
hope will represent some latent factors
 

00:07:01.110 --> 00:07:04.460
hope will represent some latent factors
of variation in the data right so these

00:07:04.460 --> 00:07:04.470
of variation in the data right so these
 

00:07:04.470 --> 00:07:06.530
of variation in the data right so these
are these are things that as you wiggle

00:07:06.530 --> 00:07:06.540
are these are things that as you wiggle
 

00:07:06.540 --> 00:07:08.600
are these are things that as you wiggle
them they're gonna move the data in in

00:07:08.600 --> 00:07:08.610
them they're gonna move the data in in
 

00:07:08.610 --> 00:07:10.760
them they're gonna move the data in in
what you hope will be natural ways right

00:07:10.760 --> 00:07:10.770
what you hope will be natural ways right
 

00:07:10.770 --> 00:07:12.470
what you hope will be natural ways right
so you can imagine a latent variable for

00:07:12.470 --> 00:07:12.480
so you can imagine a latent variable for
 

00:07:12.480 --> 00:07:15.890
so you can imagine a latent variable for
images corresponding to illumination

00:07:15.890 --> 00:07:15.900
images corresponding to illumination
 

00:07:15.900 --> 00:07:18.290
images corresponding to illumination
conditions right or if their face is a

00:07:18.290 --> 00:07:18.300
conditions right or if their face is a
 

00:07:18.300 --> 00:07:19.970
conditions right or if their face is a
common it's a common thing we find is

00:07:19.970 --> 00:07:19.980
common it's a common thing we find is
 

00:07:19.980 --> 00:07:21.470
common it's a common thing we find is
latent variable corresponding to a smart

00:07:21.470 --> 00:07:21.480
latent variable corresponding to a smart
 

00:07:21.480 --> 00:07:23.120
latent variable corresponding to a smart
right so we if we move this latent

00:07:23.120 --> 00:07:23.130
right so we if we move this latent
 

00:07:23.130 --> 00:07:25.670
right so we if we move this latent
variable the image that we see that we

00:07:25.670 --> 00:07:25.680
variable the image that we see that we
 

00:07:25.680 --> 00:07:28.010
variable the image that we see that we
generate you know a smile appears and

00:07:28.010 --> 00:07:28.020
generate you know a smile appears and
 

00:07:28.020 --> 00:07:30.200
generate you know a smile appears and
dissapears these are the kind of latent

00:07:30.200 --> 00:07:30.210
dissapears these are the kind of latent
 

00:07:30.210 --> 00:07:32.390
dissapears these are the kind of latent
variables that we want and and we want

00:07:32.390 --> 00:07:32.400
variables that we want and and we want
 

00:07:32.400 --> 00:07:34.510
variables that we want and and we want
to discover these so this is really a

00:07:34.510 --> 00:07:34.520
to discover these so this is really a
 

00:07:34.520 --> 00:07:36.740
to discover these so this is really a
challenging task in general we want to

00:07:36.740 --> 00:07:36.750
challenging task in general we want to
 

00:07:36.750 --> 00:07:38.990
challenging task in general we want to
take natural data just unlabeled data

00:07:38.990 --> 00:07:39.000
take natural data just unlabeled data
 

00:07:39.000 --> 00:07:41.690
take natural data just unlabeled data
and discover these latent factors that

00:07:41.690 --> 00:07:41.700
and discover these latent factors that
 

00:07:41.700 --> 00:07:43.750
and discover these latent factors that
give rise to the variation we see

00:07:43.750 --> 00:07:43.760
give rise to the variation we see
 

00:07:43.760 --> 00:07:46.010
give rise to the variation we see
there's two kinds of models in this

00:07:46.010 --> 00:07:46.020
there's two kinds of models in this
 

00:07:46.020 --> 00:07:47.030
there's two kinds of models in this
family that I'm going to be talking

00:07:47.030 --> 00:07:47.040
family that I'm going to be talking
 

00:07:47.040 --> 00:07:49.550
family that I'm going to be talking
about adversarial auto-encoders and

00:07:49.550 --> 00:07:49.560
about adversarial auto-encoders and
 

00:07:49.560 --> 00:07:52.030
about adversarial auto-encoders and
generative adversarial nuts or Ganz here

00:07:52.030 --> 00:07:52.040
generative adversarial nuts or Ganz here
 

00:07:52.040 --> 00:07:54.740
generative adversarial nuts or Ganz here
I work personally with both of these

00:07:54.740 --> 00:07:54.750
I work personally with both of these
 

00:07:54.750 --> 00:07:56.570
I work personally with both of these
kinds of models they serve different

00:07:56.570 --> 00:07:56.580
kinds of models they serve different
 

00:07:56.580 --> 00:08:00.800
kinds of models they serve different
purposes for me and yeah what's let's

00:08:00.800 --> 00:08:00.810
purposes for me and yeah what's let's
 

00:08:00.810 --> 00:08:04.640
purposes for me and yeah what's let's
dive in so first I'll talk about the

00:08:04.640 --> 00:08:04.650
dive in so first I'll talk about the
 

00:08:04.650 --> 00:08:06.500
dive in so first I'll talk about the
variation all encoders this actually was

00:08:06.500 --> 00:08:06.510
variation all encoders this actually was
 

00:08:06.510 --> 00:08:08.510
variation all encoders this actually was
a model was developed simultaneously by

00:08:08.510 --> 00:08:08.520
a model was developed simultaneously by
 

00:08:08.520 --> 00:08:11.690
a model was developed simultaneously by
two different groups one at deep mind

00:08:11.690 --> 00:08:11.700
two different groups one at deep mind
 

00:08:11.700 --> 00:08:12.770
two different groups one at deep mind
it's the bottom one here and then

00:08:12.770 --> 00:08:12.780
it's the bottom one here and then
 

00:08:12.780 --> 00:08:15.020
it's the bottom one here and then
kingdom and Welling at the University of

00:08:15.020 --> 00:08:15.030
kingdom and Welling at the University of
 

00:08:15.030 --> 00:08:18.380
kingdom and Welling at the University of
Amsterdam so again the idea behind the

00:08:18.380 --> 00:08:18.390
Amsterdam so again the idea behind the
 

00:08:18.390 --> 00:08:23.780
Amsterdam so again the idea behind the
the the well latent variable models in

00:08:23.780 --> 00:08:23.790
the the well latent variable models in
 

00:08:23.790 --> 00:08:26.150
the the well latent variable models in
general is kind of represented in this

00:08:26.150 --> 00:08:26.160
general is kind of represented in this
 

00:08:26.160 --> 00:08:28.160
general is kind of represented in this
picture right so here's the space of our

00:08:28.160 --> 00:08:28.170
picture right so here's the space of our
 

00:08:28.170 --> 00:08:29.840
picture right so here's the space of our
latent variables and we consist this

00:08:29.840 --> 00:08:29.850
latent variables and we consist this
 

00:08:29.850 --> 00:08:31.280
latent variables and we consist this
kind of Representative being fairly

00:08:31.280 --> 00:08:31.290
kind of Representative being fairly
 

00:08:31.290 --> 00:08:33.950
kind of Representative being fairly
simple we have our two coordinate Z 1

00:08:33.950 --> 00:08:33.960
simple we have our two coordinate Z 1
 

00:08:33.960 --> 00:08:36.650
simple we have our two coordinate Z 1
and Z 2 and and they're independent in

00:08:36.650 --> 00:08:36.660
and Z 2 and and they're independent in
 

00:08:36.660 --> 00:08:38.180
and Z 2 and and they're independent in
this case and they're sort of fairly

00:08:38.180 --> 00:08:38.190
this case and they're sort of fairly
 

00:08:38.190 --> 00:08:40.219
this case and they're sort of fairly
regular and they sort of form a chart

00:08:40.219 --> 00:08:40.229
regular and they sort of form a chart
 

00:08:40.229 --> 00:08:43.370
regular and they sort of form a chart
for what is our complicated distribution

00:08:43.370 --> 00:08:43.380
for what is our complicated distribution
 

00:08:43.380 --> 00:08:45.980
for what is our complicated distribution
here in in in X space right so this is

00:08:45.980 --> 00:08:45.990
here in in in X space right so this is
 

00:08:45.990 --> 00:08:47.120
here in in in X space right so this is
you can think of this is third of the

00:08:47.120 --> 00:08:47.130
you can think of this is third of the
 

00:08:47.130 --> 00:08:48.740
you can think of this is third of the
data manifold so you can think of this

00:08:48.740 --> 00:08:48.750
data manifold so you can think of this
 

00:08:48.750 --> 00:08:50.420
data manifold so you can think of this
as image space for example right so

00:08:50.420 --> 00:08:50.430
as image space for example right so
 

00:08:50.430 --> 00:08:52.250
as image space for example right so
image space embedded in pixel space

00:08:52.250 --> 00:08:52.260
image space embedded in pixel space
 

00:08:52.260 --> 00:08:54.530
image space embedded in pixel space
natural images embedded pixel space form

00:08:54.530 --> 00:08:54.540
natural images embedded pixel space form
 

00:08:54.540 --> 00:08:56.450
natural images embedded pixel space form
this kind of manifold and what we want

00:08:56.450 --> 00:08:56.460
this kind of manifold and what we want
 

00:08:56.460 --> 00:08:56.810
this kind of manifold and what we want
is

00:08:56.810 --> 00:08:56.820
is
 

00:08:56.820 --> 00:08:58.880
is
coordinates that allow you to as you

00:08:58.880 --> 00:08:58.890
coordinates that allow you to as you
 

00:08:58.890 --> 00:09:01.400
coordinates that allow you to as you
move sort of smoothly in this space move

00:09:01.400 --> 00:09:01.410
move sort of smoothly in this space move
 

00:09:01.410 --> 00:09:02.750
move sort of smoothly in this space move
along this what can be a very

00:09:02.750 --> 00:09:02.760
along this what can be a very
 

00:09:02.760 --> 00:09:05.180
along this what can be a very
complicated manifold and so that's the

00:09:05.180 --> 00:09:05.190
complicated manifold and so that's the
 

00:09:05.190 --> 00:09:07.190
complicated manifold and so that's the
kind of hope that what we're looking for

00:09:07.190 --> 00:09:07.200
kind of hope that what we're looking for
 

00:09:07.200 --> 00:09:09.980
kind of hope that what we're looking for
when we do latent variable modelling so

00:09:09.980 --> 00:09:09.990
when we do latent variable modelling so
 

00:09:09.990 --> 00:09:11.960
when we do latent variable modelling so
here's just an example of what I mean by

00:09:11.960 --> 00:09:11.970
here's just an example of what I mean by
 

00:09:11.970 --> 00:09:13.460
here's just an example of what I mean by
exactly that this is an early example

00:09:13.460 --> 00:09:13.470
exactly that this is an early example
 

00:09:13.470 --> 00:09:16.550
exactly that this is an early example
using these variational autoencoders so

00:09:16.550 --> 00:09:16.560
using these variational autoencoders so
 

00:09:16.560 --> 00:09:18.890
using these variational autoencoders so
here's a the freight face data said just

00:09:18.890 --> 00:09:18.900
here's a the freight face data said just
 

00:09:18.900 --> 00:09:21.050
here's a the freight face data said just
a whole bunch of images of Brendan

00:09:21.050 --> 00:09:21.060
a whole bunch of images of Brendan
 

00:09:21.060 --> 00:09:23.840
a whole bunch of images of Brendan
Fraser faith that's in the data set what

00:09:23.840 --> 00:09:23.850
Fraser faith that's in the data set what
 

00:09:23.850 --> 00:09:27.290
Fraser faith that's in the data set what
we're showing here is the model the the

00:09:27.290 --> 00:09:27.300
we're showing here is the model the the
 

00:09:27.300 --> 00:09:31.070
we're showing here is the model the the
model output of this variational auto

00:09:31.070 --> 00:09:31.080
model output of this variational auto
 

00:09:31.080 --> 00:09:34.130
model output of this variational auto
encoder for different values of these

00:09:34.130 --> 00:09:34.140
encoder for different values of these
 

00:09:34.140 --> 00:09:36.710
encoder for different values of these
latent variables z1 and z2 now we've

00:09:36.710 --> 00:09:36.720
latent variables z1 and z2 now we've
 

00:09:36.720 --> 00:09:39.020
latent variables z1 and z2 now we've
kind of post hawked added these labels

00:09:39.020 --> 00:09:39.030
kind of post hawked added these labels
 

00:09:39.030 --> 00:09:41.390
kind of post hawked added these labels
pose and expression on them because you

00:09:41.390 --> 00:09:41.400
pose and expression on them because you
 

00:09:41.400 --> 00:09:43.670
pose and expression on them because you
see if as we move this z2 here you can

00:09:43.670 --> 00:09:43.680
see if as we move this z2 here you can
 

00:09:43.680 --> 00:09:45.110
see if as we move this z2 here you can
see the expression kind of smoothly

00:09:45.110 --> 00:09:45.120
see the expression kind of smoothly
 

00:09:45.120 --> 00:09:48.020
see the expression kind of smoothly
changes from what looks like a frown to

00:09:48.020 --> 00:09:48.030
changes from what looks like a frown to
 

00:09:48.030 --> 00:09:50.300
changes from what looks like a frown to
eventually smile and through what looks

00:09:50.300 --> 00:09:50.310
eventually smile and through what looks
 

00:09:50.310 --> 00:09:53.330
eventually smile and through what looks
over here like a thought sting well

00:09:53.330 --> 00:09:53.340
over here like a thought sting well
 

00:09:53.340 --> 00:09:56.510
over here like a thought sting well
sticking his tongue out I guess and in

00:09:56.510 --> 00:09:56.520
sticking his tongue out I guess and in
 

00:09:56.520 --> 00:09:58.490
sticking his tongue out I guess and in
this direction there's a slight head

00:09:58.490 --> 00:09:58.500
this direction there's a slight head
 

00:09:58.500 --> 00:10:00.670
this direction there's a slight head
turn it's pretty subtle but it's there

00:10:00.670 --> 00:10:00.680
turn it's pretty subtle but it's there
 

00:10:00.680 --> 00:10:04.670
turn it's pretty subtle but it's there
so so we do like I said these were sort

00:10:04.670 --> 00:10:04.680
so so we do like I said these were sort
 

00:10:04.680 --> 00:10:06.230
so so we do like I said these were sort
of post hoc added the model just

00:10:06.230 --> 00:10:06.240
of post hoc added the model just
 

00:10:06.240 --> 00:10:08.060
of post hoc added the model just
discovered that these were two sources

00:10:08.060 --> 00:10:08.070
discovered that these were two sources
 

00:10:08.070 --> 00:10:09.530
discovered that these were two sources
of variation in the data that were

00:10:09.530 --> 00:10:09.540
of variation in the data that were
 

00:10:09.540 --> 00:10:11.840
of variation in the data that were
relatively independent and the model

00:10:11.840 --> 00:10:11.850
relatively independent and the model
 

00:10:11.850 --> 00:10:14.690
relatively independent and the model
just pulled those out for something like

00:10:14.690 --> 00:10:14.700
just pulled those out for something like
 

00:10:14.700 --> 00:10:16.580
just pulled those out for something like
m-miss this is the these are samples

00:10:16.580 --> 00:10:16.590
m-miss this is the these are samples
 

00:10:16.590 --> 00:10:19.010
m-miss this is the these are samples
drawn on a model train by EM mist it's a

00:10:19.010 --> 00:10:19.020
drawn on a model train by EM mist it's a
 

00:10:19.020 --> 00:10:20.630
drawn on a model train by EM mist it's a
little less natural right because in

00:10:20.630 --> 00:10:20.640
little less natural right because in
 

00:10:20.640 --> 00:10:22.940
little less natural right because in
this case you could the you could argue

00:10:22.940 --> 00:10:22.950
this case you could the you could argue
 

00:10:22.950 --> 00:10:24.410
this case you could the you could argue
the data is really best model there's

00:10:24.410 --> 00:10:24.420
the data is really best model there's
 

00:10:24.420 --> 00:10:26.540
the data is really best model there's
something not with latent factors but

00:10:26.540 --> 00:10:26.550
something not with latent factors but
 

00:10:26.550 --> 00:10:28.400
something not with latent factors but
continuously in factors but more like in

00:10:28.400 --> 00:10:28.410
continuously in factors but more like in
 

00:10:28.410 --> 00:10:30.170
continuously in factors but more like in
clusters so you get this kind of

00:10:30.170 --> 00:10:30.180
clusters so you get this kind of
 

00:10:30.180 --> 00:10:32.080
clusters so you get this kind of
somewhat interesting somewhat bizarre

00:10:32.080 --> 00:10:32.090
somewhat interesting somewhat bizarre
 

00:10:32.090 --> 00:10:34.220
somewhat interesting somewhat bizarre
relationship where you know you've get

00:10:34.220 --> 00:10:34.230
relationship where you know you've get
 

00:10:34.230 --> 00:10:36.020
relationship where you know you've get
some of this relationship of the tilt

00:10:36.020 --> 00:10:36.030
some of this relationship of the tilt
 

00:10:36.030 --> 00:10:37.580
some of this relationship of the tilt
happens here but then that one hurdle

00:10:37.580 --> 00:10:37.590
happens here but then that one hurdle
 

00:10:37.590 --> 00:10:39.620
happens here but then that one hurdle
morphs into a 7 which morphs into a 9

00:10:39.620 --> 00:10:39.630
morphs into a 7 which morphs into a 9
 

00:10:39.630 --> 00:10:42.170
morphs into a 7 which morphs into a 9
and you know because different regions

00:10:42.170 --> 00:10:42.180
and you know because different regions
 

00:10:42.180 --> 00:10:44.990
and you know because different regions
in this continuous space that represent

00:10:44.990 --> 00:10:45.000
in this continuous space that represent
 

00:10:45.000 --> 00:10:50.840
in this continuous space that represent
different examples here so a little bit

00:10:50.840 --> 00:10:50.850
different examples here so a little bit
 

00:10:50.850 --> 00:10:52.610
different examples here so a little bit
more detail into how we do these kinds

00:10:52.610 --> 00:10:52.620
more detail into how we do these kinds
 

00:10:52.620 --> 00:10:54.050
more detail into how we do these kinds
of latent variable models at least in

00:10:54.050 --> 00:10:54.060
of latent variable models at least in
 

00:10:54.060 --> 00:10:55.610
of latent variable models at least in
the context of the variational auto

00:10:55.610 --> 00:10:55.620
the context of the variational auto
 

00:10:55.620 --> 00:10:58.790
the context of the variational auto
encoder or VA II model so what we're

00:10:58.790 --> 00:10:58.800
encoder or VA II model so what we're
 

00:10:58.800 --> 00:11:01.190
encoder or VA II model so what we're
trying to learn here is P of X some

00:11:01.190 --> 00:11:01.200
trying to learn here is P of X some
 

00:11:01.200 --> 00:11:03.110
trying to learn here is P of X some
distribution over the data we're trying

00:11:03.110 --> 00:11:03.120
distribution over the data we're trying
 

00:11:03.120 --> 00:11:04.670
distribution over the data we're trying
to maximize the likelihood of the data

00:11:04.670 --> 00:11:04.680
to maximize the likelihood of the data
 

00:11:04.680 --> 00:11:06.740
to maximize the likelihood of the data
that's it but the way we're going to

00:11:06.740 --> 00:11:06.750
that's it but the way we're going to
 

00:11:06.750 --> 00:11:10.100
that's it but the way we're going to
parameterize our model is with P of X

00:11:10.100 --> 00:11:10.110
parameterize our model is with P of X
 

00:11:10.110 --> 00:11:10.580
parameterize our model is with P of X
given

00:11:10.580 --> 00:11:10.590
given
 

00:11:10.590 --> 00:11:12.770
given
Zed Zetas are latent variables oh sorry

00:11:12.770 --> 00:11:12.780
Zed Zetas are latent variables oh sorry
 

00:11:12.780 --> 00:11:16.220
Zed Zetas are latent variables oh sorry
Z I guess for you guys P of X given Z

00:11:16.220 --> 00:11:16.230
Z I guess for you guys P of X given Z
 

00:11:16.230 --> 00:11:18.890
Z I guess for you guys P of X given Z
and then P of Z right some some prior

00:11:18.890 --> 00:11:18.900
and then P of Z right some some prior
 

00:11:18.900 --> 00:11:22.310
and then P of Z right some some prior
distribution right so this P of Z here

00:11:22.310 --> 00:11:22.320
distribution right so this P of Z here
 

00:11:22.320 --> 00:11:25.700
distribution right so this P of Z here
is is typically something simple right

00:11:25.700 --> 00:11:25.710
is is typically something simple right
 

00:11:25.710 --> 00:11:27.620
is is typically something simple right
it's some prior distribution we actually

00:11:27.620 --> 00:11:27.630
it's some prior distribution we actually
 

00:11:27.630 --> 00:11:29.570
it's some prior distribution we actually
generally want it to be independent

00:11:29.570 --> 00:11:29.580
generally want it to be independent
 

00:11:29.580 --> 00:11:31.490
generally want it to be independent
there's some modeling compromises to be

00:11:31.490 --> 00:11:31.500
there's some modeling compromises to be
 

00:11:31.500 --> 00:11:32.930
there's some modeling compromises to be
made there but the reason why you'd want

00:11:32.930 --> 00:11:32.940
made there but the reason why you'd want
 

00:11:32.940 --> 00:11:34.310
made there but the reason why you'd want
it independent is because that helps get

00:11:34.310 --> 00:11:34.320
it independent is because that helps get
 

00:11:34.320 --> 00:11:36.740
it independent is because that helps get
you the kind of orthogonal

00:11:36.740 --> 00:11:36.750
you the kind of orthogonal
 

00:11:36.750 --> 00:11:39.050
you the kind of orthogonal
representation here so these guys this

00:11:39.050 --> 00:11:39.060
representation here so these guys this
 

00:11:39.060 --> 00:11:40.730
representation here so these guys this
dimension and this dimension we want

00:11:40.730 --> 00:11:40.740
dimension and this dimension we want
 

00:11:40.740 --> 00:11:42.440
dimension and this dimension we want
sort of not very much interaction in

00:11:42.440 --> 00:11:42.450
sort of not very much interaction in
 

00:11:42.450 --> 00:11:45.250
sort of not very much interaction in
order to make them more interpretable

00:11:45.250 --> 00:11:45.260
order to make them more interpretable
 

00:11:45.260 --> 00:11:47.570
order to make them more interpretable
yeah and so and the other thing we want

00:11:47.570 --> 00:11:47.580
yeah and so and the other thing we want
 

00:11:47.580 --> 00:11:49.550
yeah and so and the other thing we want
to do is we want to think about how are

00:11:49.550 --> 00:11:49.560
to do is we want to think about how are
 

00:11:49.560 --> 00:11:51.890
to do is we want to think about how are
we going to so so going from something

00:11:51.890 --> 00:11:51.900
we going to so so going from something
 

00:11:51.900 --> 00:11:53.450
we going to so so going from something
simple like you can think about this is

00:11:53.450 --> 00:11:53.460
simple like you can think about this is
 

00:11:53.460 --> 00:11:55.070
simple like you can think about this is
like in a Gaussian distribution or a

00:11:55.070 --> 00:11:55.080
like in a Gaussian distribution or a
 

00:11:55.080 --> 00:11:56.960
like in a Gaussian distribution or a
uniform distribution but now we want to

00:11:56.960 --> 00:11:56.970
uniform distribution but now we want to
 

00:11:56.970 --> 00:12:00.530
uniform distribution but now we want to
model G here that transforms Zed from

00:12:00.530 --> 00:12:00.540
model G here that transforms Zed from
 

00:12:00.540 --> 00:12:02.600
model G here that transforms Zed from
this space into this complicated space

00:12:02.600 --> 00:12:02.610
this space into this complicated space
 

00:12:02.610 --> 00:12:04.370
this space into this complicated space
and the way we're going to do that is

00:12:04.370 --> 00:12:04.380
and the way we're going to do that is
 

00:12:04.380 --> 00:12:06.380
and the way we're going to do that is
with a neural net actually in all of the

00:12:06.380 --> 00:12:06.390
with a neural net actually in all of the
 

00:12:06.390 --> 00:12:07.550
with a neural net actually in all of the
examples that I'm going to show you

00:12:07.550 --> 00:12:07.560
examples that I'm going to show you
 

00:12:07.560 --> 00:12:08.690
examples that I'm going to show you
today the way we're gonna do that is

00:12:08.690 --> 00:12:08.700
today the way we're gonna do that is
 

00:12:08.700 --> 00:12:10.520
today the way we're gonna do that is
with a convolutional neural net and the

00:12:10.520 --> 00:12:10.530
with a convolutional neural net and the
 

00:12:10.530 --> 00:12:12.410
with a convolutional neural net and the
way to think about that it's a bit of an

00:12:12.410 --> 00:12:12.420
way to think about that it's a bit of an
 

00:12:12.420 --> 00:12:13.670
way to think about that it's a bit of an
interesting thing to think about going

00:12:13.670 --> 00:12:13.680
interesting thing to think about going
 

00:12:13.680 --> 00:12:15.800
interesting thing to think about going
from some fully connected things Zed

00:12:15.800 --> 00:12:15.810
from some fully connected things Zed
 

00:12:15.810 --> 00:12:20.420
from some fully connected things Zed
into some two-dimensional input with a

00:12:20.420 --> 00:12:20.430
into some two-dimensional input with a
 

00:12:20.430 --> 00:12:23.780
into some two-dimensional input with a
topology here in a natural image space X

00:12:23.780 --> 00:12:23.790
topology here in a natural image space X
 

00:12:23.790 --> 00:12:26.600
topology here in a natural image space X
it's just the way going from what we

00:12:26.600 --> 00:12:26.610
it's just the way going from what we
 

00:12:26.610 --> 00:12:27.830
it's just the way going from what we
talked about it's kind of like the

00:12:27.830 --> 00:12:27.840
talked about it's kind of like the
 

00:12:27.840 --> 00:12:29.870
talked about it's kind of like the
opposite path of what you would take to

00:12:29.870 --> 00:12:29.880
opposite path of what you would take to
 

00:12:29.880 --> 00:12:32.810
opposite path of what you would take to
do a confident classification there's a

00:12:32.810 --> 00:12:32.820
do a confident classification there's a
 

00:12:32.820 --> 00:12:33.710
do a confident classification there's a
few different ways you could think about

00:12:33.710 --> 00:12:33.720
few different ways you could think about
 

00:12:33.720 --> 00:12:35.750
few different ways you could think about
doing that one of which is called a

00:12:35.750 --> 00:12:35.760
doing that one of which is called a
 

00:12:35.760 --> 00:12:37.400
doing that one of which is called a
transpose convolution this turns out to

00:12:37.400 --> 00:12:37.410
transpose convolution this turns out to
 

00:12:37.410 --> 00:12:40.070
transpose convolution this turns out to
not to be such a good idea this is a

00:12:40.070 --> 00:12:40.080
not to be such a good idea this is a
 

00:12:40.080 --> 00:12:41.690
not to be such a good idea this is a
case where you essentially fill in a

00:12:41.690 --> 00:12:41.700
case where you essentially fill in a
 

00:12:41.700 --> 00:12:43.970
case where you essentially fill in a
bunch of zeros it seems like the most

00:12:43.970 --> 00:12:43.980
bunch of zeros it seems like the most
 

00:12:43.980 --> 00:12:45.650
bunch of zeros it seems like the most
acceptable way to do that right now is

00:12:45.650 --> 00:12:45.660
acceptable way to do that right now is
 

00:12:45.660 --> 00:12:48.320
acceptable way to do that right now is
to just once you get some small level

00:12:48.320 --> 00:12:48.330
to just once you get some small level
 

00:12:48.330 --> 00:12:50.810
to just once you get some small level
topology here you just you do

00:12:50.810 --> 00:12:50.820
topology here you just you do
 

00:12:50.820 --> 00:12:54.230
topology here you just you do
interpolation so you just you know super

00:12:54.230 --> 00:12:54.240
interpolation so you just you know super
 

00:12:54.240 --> 00:12:56.030
interpolation so you just you know super
sample from the image you can do

00:12:56.030 --> 00:12:56.040
sample from the image you can do
 

00:12:56.040 --> 00:12:58.490
sample from the image you can do
bilinear interpolation and then do a

00:12:58.490 --> 00:12:58.500
bilinear interpolation and then do a
 

00:12:58.500 --> 00:13:00.500
bilinear interpolation and then do a
comp that preserves that size and then

00:13:00.500 --> 00:13:00.510
comp that preserves that size and then
 

00:13:00.510 --> 00:13:03.560
comp that preserves that size and then
up sample again comp up sample comp that

00:13:03.560 --> 00:13:03.570
up sample again comp up sample comp that
 

00:13:03.570 --> 00:13:06.380
up sample again comp up sample comp that
tends to give you the best results so

00:13:06.380 --> 00:13:06.390
tends to give you the best results so
 

00:13:06.390 --> 00:13:07.600
tends to give you the best results so
right so when you see this kind of thing

00:13:07.600 --> 00:13:07.610
right so when you see this kind of thing
 

00:13:07.610 --> 00:13:09.710
right so when you see this kind of thing
this kind of thing for our purposes

00:13:09.710 --> 00:13:09.720
this kind of thing for our purposes
 

00:13:09.720 --> 00:13:13.310
this kind of thing for our purposes
think convolutional neural map alright

00:13:13.310 --> 00:13:13.320
think convolutional neural map alright
 

00:13:13.320 --> 00:13:15.470
think convolutional neural map alright
so it's important to point out that that

00:13:15.470 --> 00:13:15.480
so it's important to point out that that
 

00:13:15.480 --> 00:13:19.840
so it's important to point out that that
if we had if we had over here

00:13:19.840 --> 00:13:19.850
if we had if we had over here
 

00:13:19.850 --> 00:13:22.670
if we had if we had over here
Zed's that gut Wentworth's our Z's that

00:13:22.670 --> 00:13:22.680
Zed's that gut Wentworth's our Z's that
 

00:13:22.680 --> 00:13:23.960
Zed's that gut Wentworth's our Z's that
went with our X

00:13:23.960 --> 00:13:23.970
went with our X
 

00:13:23.970 --> 00:13:25.460
went with our X
we'd be done right because this is just

00:13:25.460 --> 00:13:25.470
we'd be done right because this is just
 

00:13:25.470 --> 00:13:26.930
we'd be done right because this is just
a supervised learning problem at this

00:13:26.930 --> 00:13:26.940
a supervised learning problem at this
 

00:13:26.940 --> 00:13:28.280
a supervised learning problem at this
point and we'd be fine

00:13:28.280 --> 00:13:28.290
point and we'd be fine
 

00:13:28.290 --> 00:13:29.810
point and we'd be fine
the trick is these are latent right

00:13:29.810 --> 00:13:29.820
the trick is these are latent right
 

00:13:29.820 --> 00:13:31.400
the trick is these are latent right
they're hidden we don't know of these

00:13:31.400 --> 00:13:31.410
they're hidden we don't know of these
 

00:13:31.410 --> 00:13:32.810
they're hidden we don't know of these
sets we don't have we haven't discovered

00:13:32.810 --> 00:13:32.820
sets we don't have we haven't discovered
 

00:13:32.820 --> 00:13:35.780
sets we don't have we haven't discovered
them yet so how do we learn with this

00:13:35.780 --> 00:13:35.790
them yet so how do we learn with this
 

00:13:35.790 --> 00:13:36.319
them yet so how do we learn with this
model

00:13:36.319 --> 00:13:36.329
model
 

00:13:36.329 --> 00:13:38.660
model
well the way we're gonna do it is we're

00:13:38.660 --> 00:13:38.670
well the way we're gonna do it is we're
 

00:13:38.670 --> 00:13:39.949
well the way we're gonna do it is we're
gonna use a trick that's actually been

00:13:39.949 --> 00:13:39.959
gonna use a trick that's actually been
 

00:13:39.959 --> 00:13:42.110
gonna use a trick that's actually been
around for quite some time so this isn't

00:13:42.110 --> 00:13:42.120
around for quite some time so this isn't
 

00:13:42.120 --> 00:13:43.310
around for quite some time so this isn't
particularly new we're gonna use a

00:13:43.310 --> 00:13:43.320
particularly new we're gonna use a
 

00:13:43.320 --> 00:13:45.680
particularly new we're gonna use a
variational lower bound on the data

00:13:45.680 --> 00:13:45.690
variational lower bound on the data
 

00:13:45.690 --> 00:13:48.139
variational lower bound on the data
likelihood right so it turns out that we

00:13:48.139 --> 00:13:48.149
likelihood right so it turns out that we
 

00:13:48.149 --> 00:13:50.840
likelihood right so it turns out that we
can actually express the the data

00:13:50.840 --> 00:13:50.850
can actually express the the data
 

00:13:50.850 --> 00:13:52.430
can actually express the the data
likelihood here again this is the thing

00:13:52.430 --> 00:13:52.440
likelihood here again this is the thing
 

00:13:52.440 --> 00:13:55.310
likelihood here again this is the thing
we're trying to maximize we can express

00:13:55.310 --> 00:13:55.320
we're trying to maximize we can express
 

00:13:55.320 --> 00:13:57.620
we're trying to maximize we can express
a lower bound for it given by something

00:13:57.620 --> 00:13:57.630
a lower bound for it given by something
 

00:13:57.630 --> 00:13:59.269
a lower bound for it given by something
like this so we posit that we have some

00:13:59.269 --> 00:13:59.279
like this so we posit that we have some
 

00:13:59.279 --> 00:14:02.000
like this so we posit that we have some
Q distribution of Z that estimates is

00:14:02.000 --> 00:14:02.010
Q distribution of Z that estimates is
 

00:14:02.010 --> 00:14:04.790
Q distribution of Z that estimates is
the posterior of Z for a given X and

00:14:04.790 --> 00:14:04.800
the posterior of Z for a given X and
 

00:14:04.800 --> 00:14:09.350
the posterior of Z for a given X and
we're trying to then I guess maximize

00:14:09.350 --> 00:14:09.360
we're trying to then I guess maximize
 

00:14:09.360 --> 00:14:11.420
we're trying to then I guess maximize
this joint probability over X and Z

00:14:11.420 --> 00:14:11.430
this joint probability over X and Z
 

00:14:11.430 --> 00:14:13.670
this joint probability over X and Z
minus the log Q Z so this is this is

00:14:13.670 --> 00:14:13.680
minus the log Q Z so this is this is
 

00:14:13.680 --> 00:14:18.079
minus the log Q Z so this is this is
this variational or bound one of the

00:14:18.079 --> 00:14:18.089
this variational or bound one of the
 

00:14:18.089 --> 00:14:20.269
this variational or bound one of the
ways we can express this is you're

00:14:20.269 --> 00:14:20.279
ways we can express this is you're
 

00:14:20.279 --> 00:14:22.430
ways we can express this is you're
trying to find the Q from Q's point of

00:14:22.430 --> 00:14:22.440
trying to find the Q from Q's point of
 

00:14:22.440 --> 00:14:25.160
trying to find the Q from Q's point of
view is if you were to find a Q that

00:14:25.160 --> 00:14:25.170
view is if you were to find a Q that
 

00:14:25.170 --> 00:14:27.410
view is if you were to find a Q that
actually recovered the exact posterior

00:14:27.410 --> 00:14:27.420
actually recovered the exact posterior
 

00:14:27.420 --> 00:14:31.970
actually recovered the exact posterior
distribution over Zed given X this would

00:14:31.970 --> 00:14:31.980
distribution over Zed given X this would
 

00:14:31.980 --> 00:14:34.699
distribution over Zed given X this would
actually be a tight lower bound so then

00:14:34.699 --> 00:14:34.709
actually be a tight lower bound so then
 

00:14:34.709 --> 00:14:37.100
actually be a tight lower bound so then
we would for sure be optimizing if we

00:14:37.100 --> 00:14:37.110
we would for sure be optimizing if we
 

00:14:37.110 --> 00:14:38.900
we would for sure be optimizing if we
were now optimized this lower bound we

00:14:38.900 --> 00:14:38.910
were now optimized this lower bound we
 

00:14:38.910 --> 00:14:40.519
were now optimized this lower bound we
would be for sure optimizing likelihood

00:14:40.519 --> 00:14:40.529
would be for sure optimizing likelihood
 

00:14:40.529 --> 00:14:41.780
would be for sure optimizing likelihood
in practice that's what we're gonna do

00:14:41.780 --> 00:14:41.790
in practice that's what we're gonna do
 

00:14:41.790 --> 00:14:42.889
in practice that's what we're gonna do
anyway we're gonna have this lower bound

00:14:42.889 --> 00:14:42.899
anyway we're gonna have this lower bound
 

00:14:42.899 --> 00:14:44.809
anyway we're gonna have this lower bound
we're gonna try to optimize we're trying

00:14:44.809 --> 00:14:44.819
we're gonna try to optimize we're trying
 

00:14:44.819 --> 00:14:46.850
we're gonna try to optimize we're trying
to raise that up in hopes of raising up

00:14:46.850 --> 00:14:46.860
to raise that up in hopes of raising up
 

00:14:46.860 --> 00:14:49.340
to raise that up in hopes of raising up
our likelihood but the problem is this

00:14:49.340 --> 00:14:49.350
our likelihood but the problem is this
 

00:14:49.350 --> 00:14:52.400
our likelihood but the problem is this
posterior the actual posterior of say of

00:14:52.400 --> 00:14:52.410
posterior the actual posterior of say of
 

00:14:52.410 --> 00:14:53.930
posterior the actual posterior of say of
this G model here there's a neural net

00:14:53.930 --> 00:14:53.940
this G model here there's a neural net
 

00:14:53.940 --> 00:14:55.819
this G model here there's a neural net
right this is just some forward model

00:14:55.819 --> 00:14:55.829
right this is just some forward model
 

00:14:55.829 --> 00:14:58.250
right this is just some forward model
neural net so computing the posterior of

00:14:58.250 --> 00:14:58.260
neural net so computing the posterior of
 

00:14:58.260 --> 00:15:01.189
neural net so computing the posterior of
z given x is intractable we have no good

00:15:01.189 --> 00:15:01.199
z given x is intractable we have no good
 

00:15:01.199 --> 00:15:02.509
z given x is intractable we have no good
way of doing this it's gonna be some

00:15:02.509 --> 00:15:02.519
way of doing this it's gonna be some
 

00:15:02.519 --> 00:15:03.800
way of doing this it's gonna be some
complicated thing and we have no

00:15:03.800 --> 00:15:03.810
complicated thing and we have no
 

00:15:03.810 --> 00:15:05.720
complicated thing and we have no
sensible way of doing this so we're

00:15:05.720 --> 00:15:05.730
sensible way of doing this so we're
 

00:15:05.730 --> 00:15:08.210
sensible way of doing this so we're
going to approximate it with this Q in

00:15:08.210 --> 00:15:08.220
going to approximate it with this Q in
 

00:15:08.220 --> 00:15:10.790
going to approximate it with this Q in
this way so we're gonna now we can

00:15:10.790 --> 00:15:10.800
this way so we're gonna now we can
 

00:15:10.800 --> 00:15:11.870
this way so we're gonna now we can
actually and what's interesting about

00:15:11.870 --> 00:15:11.880
actually and what's interesting about
 

00:15:11.880 --> 00:15:13.879
actually and what's interesting about
this formulation and this is this is new

00:15:13.879 --> 00:15:13.889
this formulation and this is this is new
 

00:15:13.889 --> 00:15:15.019
this formulation and this is this is new
to the variational auto queries they've

00:15:15.019 --> 00:15:15.029
to the variational auto queries they've
 

00:15:15.029 --> 00:15:16.670
to the variational auto queries they've
sort or just reformulated this a little

00:15:16.670 --> 00:15:16.680
sort or just reformulated this a little
 

00:15:16.680 --> 00:15:18.860
sort or just reformulated this a little
bit differently and what they've got is

00:15:18.860 --> 00:15:18.870
bit differently and what they've got is
 

00:15:18.870 --> 00:15:21.470
bit differently and what they've got is
they come up with this this different

00:15:21.470 --> 00:15:21.480
they come up with this this different
 

00:15:21.480 --> 00:15:23.720
they come up with this this different
expression here which actually can be

00:15:23.720 --> 00:15:23.730
expression here which actually can be
 

00:15:23.730 --> 00:15:25.519
expression here which actually can be
thought of in two terms here one is the

00:15:25.519 --> 00:15:25.529
thought of in two terms here one is the
 

00:15:25.529 --> 00:15:27.110
thought of in two terms here one is the
reconstruction term here if you look at

00:15:27.110 --> 00:15:27.120
reconstruction term here if you look at
 

00:15:27.120 --> 00:15:29.269
reconstruction term here if you look at
what this is this is just you get some

00:15:29.269 --> 00:15:29.279
what this is this is just you get some
 

00:15:29.279 --> 00:15:32.540
what this is this is just you get some
from some queue you get a Zed and you're

00:15:32.540 --> 00:15:32.550
from some queue you get a Zed and you're
 

00:15:32.550 --> 00:15:34.429
from some queue you get a Zed and you're
just trying to reconstruct X from that

00:15:34.429 --> 00:15:34.439
just trying to reconstruct X from that
 

00:15:34.439 --> 00:15:36.889
just trying to reconstruct X from that
Zed so you start with X you get a Zed

00:15:36.889 --> 00:15:36.899
Zed so you start with X you get a Zed
 

00:15:36.899 --> 00:15:37.340
Zed so you start with X you get a Zed
and then

00:15:37.340 --> 00:15:37.350
and then
 

00:15:37.350 --> 00:15:39.500
and then
are trying to do a reconstruction of X

00:15:39.500 --> 00:15:39.510
are trying to do a reconstruction of X
 

00:15:39.510 --> 00:15:41.180
are trying to do a reconstruction of X
from that Zed this is where the name

00:15:41.180 --> 00:15:41.190
from that Zed this is where the name
 

00:15:41.190 --> 00:15:43.130
from that Zed this is where the name
variational auto-encoder comes from is

00:15:43.130 --> 00:15:43.140
variational auto-encoder comes from is
 

00:15:43.140 --> 00:15:44.570
variational auto-encoder comes from is
because this really looks like an

00:15:44.570 --> 00:15:44.580
because this really looks like an
 

00:15:44.580 --> 00:15:47.660
because this really looks like an
encoder on the side of Q here and a

00:15:47.660 --> 00:15:47.670
encoder on the side of Q here and a
 

00:15:47.670 --> 00:15:49.340
encoder on the side of Q here and a
decoder here and you're just trying to

00:15:49.340 --> 00:15:49.350
decoder here and you're just trying to
 

00:15:49.350 --> 00:15:51.620
decoder here and you're just trying to
minimize that reconstruction error but

00:15:51.620 --> 00:15:51.630
minimize that reconstruction error but
 

00:15:51.630 --> 00:15:53.420
minimize that reconstruction error but
in addition to this they add this

00:15:53.420 --> 00:15:53.430
in addition to this they add this
 

00:15:53.430 --> 00:15:56.270
in addition to this they add this
regularization term and this is

00:15:56.270 --> 00:15:56.280
regularization term and this is
 

00:15:56.280 --> 00:15:57.410
regularization term and this is
interesting right so this is what

00:15:57.410 --> 00:15:57.420
interesting right so this is what
 

00:15:57.420 --> 00:15:58.610
interesting right so this is what
they're doing here is they're basically

00:15:58.610 --> 00:15:58.620
they're doing here is they're basically
 

00:15:58.620 --> 00:16:00.410
they're doing here is they're basically
saying well we want to regularize this

00:16:00.410 --> 00:16:00.420
saying well we want to regularize this
 

00:16:00.420 --> 00:16:02.090
saying well we want to regularize this
posterior and this actually Neela

00:16:02.090 --> 00:16:02.100
posterior and this actually Neela
 

00:16:02.100 --> 00:16:03.860
posterior and this actually Neela
autoencoders don't have this right so

00:16:03.860 --> 00:16:03.870
autoencoders don't have this right so
 

00:16:03.870 --> 00:16:06.050
autoencoders don't have this right so
we're trying to regularize this

00:16:06.050 --> 00:16:06.060
we're trying to regularize this
 

00:16:06.060 --> 00:16:08.630
we're trying to regularize this
posterior to try to be a little bit

00:16:08.630 --> 00:16:08.640
posterior to try to be a little bit
 

00:16:08.640 --> 00:16:10.850
posterior to try to be a little bit
closer to the prior here and it's a

00:16:10.850 --> 00:16:10.860
closer to the prior here and it's a
 

00:16:10.860 --> 00:16:11.930
closer to the prior here and it's a
common mistake when people learn about

00:16:11.930 --> 00:16:11.940
common mistake when people learn about
 

00:16:11.940 --> 00:16:13.490
common mistake when people learn about
this to sort of think that oh well the

00:16:13.490 --> 00:16:13.500
this to sort of think that oh well the
 

00:16:13.500 --> 00:16:14.840
this to sort of think that oh well the
goal is for these things to actually

00:16:14.840 --> 00:16:14.850
goal is for these things to actually
 

00:16:14.850 --> 00:16:16.520
goal is for these things to actually
match that would be terrible right that

00:16:16.520 --> 00:16:16.530
match that would be terrible right that
 

00:16:16.530 --> 00:16:18.680
match that would be terrible right that
that means that you lose all information

00:16:18.680 --> 00:16:18.690
that means that you lose all information
 

00:16:18.690 --> 00:16:20.030
that means that you lose all information
about X you definitely don't want these

00:16:20.030 --> 00:16:20.040
about X you definitely don't want these
 

00:16:20.040 --> 00:16:22.100
about X you definitely don't want these
things to match but it does act as a

00:16:22.100 --> 00:16:22.110
things to match but it does act as a
 

00:16:22.110 --> 00:16:24.140
things to match but it does act as a
regularizer sort of as a counterpoint to

00:16:24.140 --> 00:16:24.150
regularizer sort of as a counterpoint to
 

00:16:24.150 --> 00:16:28.100
regularizer sort of as a counterpoint to
this reconstruction term and so now

00:16:28.100 --> 00:16:28.110
this reconstruction term and so now
 

00:16:28.110 --> 00:16:29.660
this reconstruction term and so now
we've talked a little bit about this but

00:16:29.660 --> 00:16:29.670
we've talked a little bit about this but
 

00:16:29.670 --> 00:16:32.210
we've talked a little bit about this but
what is this q well for the variational

00:16:32.210 --> 00:16:32.220
what is this q well for the variational
 

00:16:32.220 --> 00:16:33.410
what is this q well for the variational
auto encoder the Q is going to be

00:16:33.410 --> 00:16:33.420
auto encoder the Q is going to be
 

00:16:33.420 --> 00:16:35.420
auto encoder the Q is going to be
another neural net and in this case we

00:16:35.420 --> 00:16:35.430
another neural net and in this case we
 

00:16:35.430 --> 00:16:36.440
another neural net and in this case we
can think this is just a straight

00:16:36.440 --> 00:16:36.450
can think this is just a straight
 

00:16:36.450 --> 00:16:37.760
can think this is just a straight
Compton at for the case of natural

00:16:37.760 --> 00:16:37.770
Compton at for the case of natural
 

00:16:37.770 --> 00:16:41.270
Compton at for the case of natural
images so again we've got our lower

00:16:41.270 --> 00:16:41.280
images so again we've got our lower
 

00:16:41.280 --> 00:16:42.710
images so again we've got our lower
bound there objected that we're trying

00:16:42.710 --> 00:16:42.720
bound there objected that we're trying
 

00:16:42.720 --> 00:16:44.630
bound there objected that we're trying
to minimize and we're gonna parameterize

00:16:44.630 --> 00:16:44.640
to minimize and we're gonna parameterize
 

00:16:44.640 --> 00:16:47.810
to minimize and we're gonna parameterize
Q as this neural net the confident that

00:16:47.810 --> 00:16:47.820
Q as this neural net the confident that
 

00:16:47.820 --> 00:16:50.840
Q as this neural net the confident that
goes from X to Z and we've got now our

00:16:50.840 --> 00:16:50.850
goes from X to Z and we've got now our
 

00:16:50.850 --> 00:16:53.180
goes from X to Z and we've got now our
generative model here or decoder that

00:16:53.180 --> 00:16:53.190
generative model here or decoder that
 

00:16:53.190 --> 00:16:58.220
generative model here or decoder that
goes from Z to X I'm gonna add a few

00:16:58.220 --> 00:16:58.230
goes from Z to X I'm gonna add a few
 

00:16:58.230 --> 00:17:00.020
goes from Z to X I'm gonna add a few
more details to make this thing actually

00:17:00.020 --> 00:17:00.030
more details to make this thing actually
 

00:17:00.030 --> 00:17:02.420
more details to make this thing actually
proc in practice up till now this is not

00:17:02.420 --> 00:17:02.430
proc in practice up till now this is not
 

00:17:02.430 --> 00:17:05.780
proc in practice up till now this is not
too new there's been instances of this

00:17:05.780 --> 00:17:05.790
too new there's been instances of this
 

00:17:05.790 --> 00:17:07.880
too new there's been instances of this
kind of formalism of an encoder network

00:17:07.880 --> 00:17:07.890
kind of formalism of an encoder network
 

00:17:07.890 --> 00:17:09.740
kind of formalism of an encoder network
and a decoder network but what they do

00:17:09.740 --> 00:17:09.750
and a decoder network but what they do
 

00:17:09.750 --> 00:17:11.180
and a decoder network but what they do
next is actually kind of interesting

00:17:11.180 --> 00:17:11.190
next is actually kind of interesting
 

00:17:11.190 --> 00:17:12.740
next is actually kind of interesting
they notice that that if they

00:17:12.740 --> 00:17:12.750
they notice that that if they
 

00:17:12.750 --> 00:17:15.290
they notice that that if they
parameterize this a certain way if they

00:17:15.290 --> 00:17:15.300
parameterize this a certain way if they
 

00:17:15.300 --> 00:17:17.870
parameterize this a certain way if they
say Q is equal to actually you can use

00:17:17.870 --> 00:17:17.880
say Q is equal to actually you can use
 

00:17:17.880 --> 00:17:19.460
say Q is equal to actually you can use
any continuous distribution here but

00:17:19.460 --> 00:17:19.470
any continuous distribution here but
 

00:17:19.470 --> 00:17:22.010
any continuous distribution here but
they pick a normal distribution here so

00:17:22.010 --> 00:17:22.020
they pick a normal distribution here so
 

00:17:22.020 --> 00:17:24.620
they pick a normal distribution here so
Q of X is some normal distribution where

00:17:24.620 --> 00:17:24.630
Q of X is some normal distribution where
 

00:17:24.630 --> 00:17:26.990
Q of X is some normal distribution where
the parameters mu and Sigma from the

00:17:26.990 --> 00:17:27.000
the parameters mu and Sigma from the
 

00:17:27.000 --> 00:17:28.460
the parameters mu and Sigma from the
defined this normal distribution are

00:17:28.460 --> 00:17:28.470
defined this normal distribution are
 

00:17:28.470 --> 00:17:31.190
defined this normal distribution are
defined by this encoder network then

00:17:31.190 --> 00:17:31.200
defined by this encoder network then
 

00:17:31.200 --> 00:17:33.500
defined by this encoder network then
they can actually encode it like this

00:17:33.500 --> 00:17:33.510
they can actually encode it like this
 

00:17:33.510 --> 00:17:35.180
they can actually encode it like this
it's called a Reaper amortization trick

00:17:35.180 --> 00:17:35.190
it's called a Reaper amortization trick
 

00:17:35.190 --> 00:17:37.790
it's called a Reaper amortization trick
where they take Z a random variable here

00:17:37.790 --> 00:17:37.800
where they take Z a random variable here
 

00:17:37.800 --> 00:17:39.770
where they take Z a random variable here
is equal to some function of the input

00:17:39.770 --> 00:17:39.780
is equal to some function of the input
 

00:17:39.780 --> 00:17:42.680
is equal to some function of the input
mu plus Sigma our scaling factor over

00:17:42.680 --> 00:17:42.690
mu plus Sigma our scaling factor over
 

00:17:42.690 --> 00:17:45.350
mu plus Sigma our scaling factor over
some noise and what this allows us to do

00:17:45.350 --> 00:17:45.360
some noise and what this allows us to do
 

00:17:45.360 --> 00:17:48.110
some noise and what this allows us to do
now when they formulate it this way is

00:17:48.110 --> 00:17:48.120
now when they formulate it this way is
 

00:17:48.120 --> 00:17:49.550
now when they formulate it this way is
when in training this model they can

00:17:49.550 --> 00:17:49.560
when in training this model they can
 

00:17:49.560 --> 00:17:51.010
when in training this model they can
actually back prop

00:17:51.010 --> 00:17:51.020
actually back prop
 

00:17:51.020 --> 00:17:53.680
actually back prop
the decoder and into the encoder to

00:17:53.680 --> 00:17:53.690
the decoder and into the encoder to
 

00:17:53.690 --> 00:17:57.610
the decoder and into the encoder to
train both models simultaneously it

00:17:57.610 --> 00:17:57.620
train both models simultaneously it
 

00:17:57.620 --> 00:17:59.950
train both models simultaneously it
looks a little bit like this so they can

00:17:59.950 --> 00:17:59.960
looks a little bit like this so they can
 

00:17:59.960 --> 00:18:01.860
looks a little bit like this so they can
do forward propagation start with an X

00:18:01.860 --> 00:18:01.870
do forward propagation start with an X
 

00:18:01.870 --> 00:18:05.770
do forward propagation start with an X
forward propagate to Zed add noise here

00:18:05.770 --> 00:18:05.780
forward propagate to Zed add noise here
 

00:18:05.780 --> 00:18:07.720
forward propagate to Zed add noise here
that was at epsilon and then for

00:18:07.720 --> 00:18:07.730
that was at epsilon and then for
 

00:18:07.730 --> 00:18:10.540
that was at epsilon and then for
propagate here to this X hat which is

00:18:10.540 --> 00:18:10.550
propagate here to this X hat which is
 

00:18:10.550 --> 00:18:12.940
propagate here to this X hat which is
our reconstruction compute the error

00:18:12.940 --> 00:18:12.950
our reconstruction compute the error
 

00:18:12.950 --> 00:18:15.549
our reconstruction compute the error
between X and X hat and back propagate

00:18:15.549 --> 00:18:15.559
between X and X hat and back propagate
 

00:18:15.559 --> 00:18:19.840
between X and X hat and back propagate
that error all the way through and that

00:18:19.840 --> 00:18:19.850
that error all the way through and that
 

00:18:19.850 --> 00:18:21.760
that error all the way through and that
allows them to actually train this model

00:18:21.760 --> 00:18:21.770
allows them to actually train this model
 

00:18:21.770 --> 00:18:23.680
allows them to actually train this model
very effectively in ways that we've

00:18:23.680 --> 00:18:23.690
very effectively in ways that we've
 

00:18:23.690 --> 00:18:24.940
very effectively in ways that we've
never been able to train before this

00:18:24.940 --> 00:18:24.950
never been able to train before this
 

00:18:24.950 --> 00:18:27.940
never been able to train before this
this trick came up and when you do that

00:18:27.940 --> 00:18:27.950
this trick came up and when you do that
 

00:18:27.950 --> 00:18:29.380
this trick came up and when you do that
this is the kind of thing that came out

00:18:29.380 --> 00:18:29.390
this is the kind of thing that came out
 

00:18:29.390 --> 00:18:31.630
this is the kind of thing that came out
so this came out in 2014 these were

00:18:31.630 --> 00:18:31.640
so this came out in 2014 these were
 

00:18:31.640 --> 00:18:32.830
so this came out in 2014 these were
actually really I promised these were

00:18:32.830 --> 00:18:32.840
actually really I promised these were
 

00:18:32.840 --> 00:18:35.549
actually really I promised these were
really impressive results in in 2014

00:18:35.549 --> 00:18:35.559
really impressive results in in 2014
 

00:18:35.559 --> 00:18:37.720
really impressive results in in 2014
this first time we were seeing sorted

00:18:37.720 --> 00:18:37.730
this first time we were seeing sorted
 

00:18:37.730 --> 00:18:39.730
this first time we were seeing sorted
this is not this is from the label faced

00:18:39.730 --> 00:18:39.740
this is not this is from the label faced
 

00:18:39.740 --> 00:18:42.370
this is not this is from the label faced
in the wild these days we use Celebi and

00:18:42.370 --> 00:18:42.380
in the wild these days we use Celebi and
 

00:18:42.380 --> 00:18:45.340
in the wild these days we use Celebi and
this is imagenet so not a whole lot

00:18:45.340 --> 00:18:45.350
this is imagenet so not a whole lot
 

00:18:45.350 --> 00:18:46.690
this is imagenet so not a whole lot
there actually this is a small version

00:18:46.690 --> 00:18:46.700
there actually this is a small version
 

00:18:46.700 --> 00:18:50.830
there actually this is a small version
of imagenet but you can do things with

00:18:50.830 --> 00:18:50.840
of imagenet but you can do things with
 

00:18:50.840 --> 00:18:52.690
of imagenet but you can do things with
this model actually so for example one

00:18:52.690 --> 00:18:52.700
this model actually so for example one
 

00:18:52.700 --> 00:18:53.799
this model actually so for example one
of the things that we've done with this

00:18:53.799 --> 00:18:53.809
of the things that we've done with this
 

00:18:53.809 --> 00:18:55.810
of the things that we've done with this
model is we actually just we talked to I

00:18:55.810 --> 00:18:55.820
model is we actually just we talked to I
 

00:18:55.820 --> 00:18:59.140
model is we actually just we talked to I
mentioned briefly this pixel CNN we we

00:18:59.140 --> 00:18:59.150
mentioned briefly this pixel CNN we we
 

00:18:59.150 --> 00:19:02.440
mentioned briefly this pixel CNN we we
actually include this pixel CNN into the

00:19:02.440 --> 00:19:02.450
actually include this pixel CNN into the
 

00:19:02.450 --> 00:19:04.780
actually include this pixel CNN into the
decoder side so one of the problems if I

00:19:04.780 --> 00:19:04.790
decoder side so one of the problems if I
 

00:19:04.790 --> 00:19:06.280
decoder side so one of the problems if I
just go back one of the problems why we

00:19:06.280 --> 00:19:06.290
just go back one of the problems why we
 

00:19:06.290 --> 00:19:08.290
just go back one of the problems why we
get these kinds of images is this model

00:19:08.290 --> 00:19:08.300
get these kinds of images is this model
 

00:19:08.300 --> 00:19:10.030
get these kinds of images is this model
makes a lot of independence assumptions

00:19:10.030 --> 00:19:10.040
makes a lot of independence assumptions
 

00:19:10.040 --> 00:19:12.070
makes a lot of independence assumptions
right and part of it is because we want

00:19:12.070 --> 00:19:12.080
right and part of it is because we want
 

00:19:12.080 --> 00:19:13.330
right and part of it is because we want
those independence assumptions to make

00:19:13.330 --> 00:19:13.340
those independence assumptions to make
 

00:19:13.340 --> 00:19:14.830
those independence assumptions to make
our Zed's more interpretable but they

00:19:14.830 --> 00:19:14.840
our Zed's more interpretable but they
 

00:19:14.840 --> 00:19:17.049
our Zed's more interpretable but they
have consequences to them and one of the

00:19:17.049 --> 00:19:17.059
have consequences to them and one of the
 

00:19:17.059 --> 00:19:18.580
have consequences to them and one of the
consequences is you end up with kind of

00:19:18.580 --> 00:19:18.590
consequences is you end up with kind of
 

00:19:18.590 --> 00:19:20.350
consequences is you end up with kind of
blurry images that's that's part of why

00:19:20.350 --> 00:19:20.360
blurry images that's that's part of why
 

00:19:20.360 --> 00:19:21.520
blurry images that's that's part of why
you end up with Bill array images is

00:19:21.520 --> 00:19:21.530
you end up with Bill array images is
 

00:19:21.530 --> 00:19:22.180
you end up with Bill array images is
because we're making these

00:19:22.180 --> 00:19:22.190
because we're making these
 

00:19:22.190 --> 00:19:25.020
because we're making these
approximations in the variational

00:19:25.020 --> 00:19:25.030
approximations in the variational
 

00:19:25.030 --> 00:19:29.500
approximations in the variational
lower bound and so by adding the pixels

00:19:29.500 --> 00:19:29.510
lower bound and so by adding the pixels
 

00:19:29.510 --> 00:19:31.450
lower bound and so by adding the pixels
CNN that allows us to encode more

00:19:31.450 --> 00:19:31.460
CNN that allows us to encode more
 

00:19:31.460 --> 00:19:33.700
CNN that allows us to encode more
complexity in here and by the way this

00:19:33.700 --> 00:19:33.710
complexity in here and by the way this
 

00:19:33.710 --> 00:19:35.680
complexity in here and by the way this
is now a hierarchical version of the VA

00:19:35.680 --> 00:19:35.690
is now a hierarchical version of the VA
 

00:19:35.690 --> 00:19:38.230
is now a hierarchical version of the VA
II using pixel CNN that allows those

00:19:38.230 --> 00:19:38.240
II using pixel CNN that allows those
 

00:19:38.240 --> 00:19:40.810
II using pixel CNN that allows those
allows us to encode sort of complicated

00:19:40.810 --> 00:19:40.820
allows us to encode sort of complicated
 

00:19:40.820 --> 00:19:43.390
allows us to encode sort of complicated
distributions in Zed 1 here given the

00:19:43.390 --> 00:19:43.400
distributions in Zed 1 here given the
 

00:19:43.400 --> 00:19:46.150
distributions in Zed 1 here given the
upper levels adds and with this kind of

00:19:46.150 --> 00:19:46.160
upper levels adds and with this kind of
 

00:19:46.160 --> 00:19:48.250
upper levels adds and with this kind of
thing this is the kind of images that we

00:19:48.250 --> 00:19:48.260
thing this is the kind of images that we
 

00:19:48.260 --> 00:19:49.870
thing this is the kind of images that we
can just synthesize using this

00:19:49.870 --> 00:19:49.880
can just synthesize using this
 

00:19:49.880 --> 00:19:51.700
can just synthesize using this
variational we'll call this the the

00:19:51.700 --> 00:19:51.710
variational we'll call this the the
 

00:19:51.710 --> 00:19:56.230
variational we'll call this the the
pixel VA II model so these are bedroom

00:19:56.230 --> 00:19:56.240
pixel VA II model so these are bedroom
 

00:19:56.240 --> 00:19:59.620
pixel VA II model so these are bedroom
scenes so you can sort of see it's

00:19:59.620 --> 00:19:59.630
scenes so you can sort of see it's
 

00:19:59.630 --> 00:20:01.630
scenes so you can sort of see it's
reasonably good clear bedroom scenes and

00:20:01.630 --> 00:20:01.640
reasonably good clear bedroom scenes and
 

00:20:01.640 --> 00:20:04.390
reasonably good clear bedroom scenes and
then imaged at which your that you

00:20:04.390 --> 00:20:04.400
then imaged at which your that you
 

00:20:04.400 --> 00:20:06.460
then imaged at which your that you
you can see that it gets roughly the the

00:20:06.460 --> 00:20:06.470
you can see that it gets roughly the the
 

00:20:06.470 --> 00:20:08.380
you can see that it gets roughly the the
textures right it's not really getting

00:20:08.380 --> 00:20:08.390
textures right it's not really getting
 

00:20:08.390 --> 00:20:09.940
textures right it's not really getting
objects yet actually objects that are

00:20:09.940 --> 00:20:09.950
objects yet actually objects that are
 

00:20:09.950 --> 00:20:11.530
objects yet actually objects that are
really tough to get when you model

00:20:11.530 --> 00:20:11.540
really tough to get when you model
 

00:20:11.540 --> 00:20:13.270
really tough to get when you model
things in an unconditional way what I

00:20:13.270 --> 00:20:13.280
things in an unconditional way what I
 

00:20:13.280 --> 00:20:14.740
things in an unconditional way what I
mean by that is the model doesn't know

00:20:14.740 --> 00:20:14.750
mean by that is the model doesn't know
 

00:20:14.750 --> 00:20:16.120
mean by that is the model doesn't know
that it's supposed to generate a dog

00:20:16.120 --> 00:20:16.130
that it's supposed to generate a dog
 

00:20:16.130 --> 00:20:17.470
that it's supposed to generate a dog
let's say if it was going to generate

00:20:17.470 --> 00:20:17.480
let's say if it was going to generate
 

00:20:17.480 --> 00:20:19.750
let's say if it was going to generate
something so it's just generating from P

00:20:19.750 --> 00:20:19.760
something so it's just generating from P
 

00:20:19.760 --> 00:20:21.340
something so it's just generating from P
of X in general and it's actually pretty

00:20:21.340 --> 00:20:21.350
of X in general and it's actually pretty
 

00:20:21.350 --> 00:20:23.910
of X in general and it's actually pretty
challenging when we talk about image net

00:20:23.910 --> 00:20:23.920
challenging when we talk about image net
 

00:20:23.920 --> 00:20:27.280
challenging when we talk about image net
all right so so that's one way we can

00:20:27.280 --> 00:20:27.290
all right so so that's one way we can
 

00:20:27.290 --> 00:20:30.310
all right so so that's one way we can
improve the the VA II model another way

00:20:30.310 --> 00:20:30.320
improve the the VA II model another way
 

00:20:30.320 --> 00:20:31.990
improve the the VA II model another way
we can improve the VA you models work on

00:20:31.990 --> 00:20:32.000
we can improve the VA you models work on
 

00:20:32.000 --> 00:20:34.350
we can improve the VA you models work on
the encoder side and that was we're done

00:20:34.350 --> 00:20:34.360
the encoder side and that was we're done
 

00:20:34.360 --> 00:20:38.650
the encoder side and that was we're done
by a few people but culminating I think

00:20:38.650 --> 00:20:38.660
by a few people but culminating I think
 

00:20:38.660 --> 00:20:40.120
by a few people but culminating I think
in the inverse auto regressive flow

00:20:40.120 --> 00:20:40.130
in the inverse auto regressive flow
 

00:20:40.130 --> 00:20:41.800
in the inverse auto regressive flow
model so this is actually a very

00:20:41.800 --> 00:20:41.810
model so this is actually a very
 

00:20:41.810 --> 00:20:43.900
model so this is actually a very
effective way to deal with it the same

00:20:43.900 --> 00:20:43.910
effective way to deal with it the same
 

00:20:43.910 --> 00:20:45.340
effective way to deal with it the same
kind of independence problems we saw

00:20:45.340 --> 00:20:45.350
kind of independence problems we saw
 

00:20:45.350 --> 00:20:47.140
kind of independence problems we saw
they were addressing on the decoder side

00:20:47.140 --> 00:20:47.150
they were addressing on the decoder side
 

00:20:47.150 --> 00:20:48.430
they were addressing on the decoder side
but they're addressing it on the encoder

00:20:48.430 --> 00:20:48.440
but they're addressing it on the encoder
 

00:20:48.440 --> 00:20:51.280
but they're addressing it on the encoder
side so you can kind of see just briefly

00:20:51.280 --> 00:20:51.290
side so you can kind of see just briefly
 

00:20:51.290 --> 00:20:52.750
side so you can kind of see just briefly
what this is doing so this is your prior

00:20:52.750 --> 00:20:52.760
what this is doing so this is your prior
 

00:20:52.760 --> 00:20:54.430
what this is doing so this is your prior
distribution ideally you would like sort

00:20:54.430 --> 00:20:54.440
distribution ideally you would like sort
 

00:20:54.440 --> 00:20:56.170
distribution ideally you would like sort
of the marginal posterior which is

00:20:56.170 --> 00:20:56.180
of the marginal posterior which is
 

00:20:56.180 --> 00:20:57.700
of the marginal posterior which is
they're like combining all these things

00:20:57.700 --> 00:20:57.710
they're like combining all these things
 

00:20:57.710 --> 00:20:59.170
they're like combining all these things
together to be as close to this as

00:20:59.170 --> 00:20:59.180
together to be as close to this as
 

00:20:59.180 --> 00:21:02.340
together to be as close to this as
possible because any sort of

00:21:02.340 --> 00:21:02.350
possible because any sort of
 

00:21:02.350 --> 00:21:04.270
possible because any sort of
disagreement between those two is really

00:21:04.270 --> 00:21:04.280
disagreement between those two is really
 

00:21:04.280 --> 00:21:05.980
disagreement between those two is really
a modeling errors or it's an

00:21:05.980 --> 00:21:05.990
a modeling errors or it's an
 

00:21:05.990 --> 00:21:08.410
a modeling errors or it's an
approximation error so standard via

00:21:08.410 --> 00:21:08.420
approximation error so standard via
 

00:21:08.420 --> 00:21:10.420
approximation error so standard via
email is going to get gonna learn to do

00:21:10.420 --> 00:21:10.430
email is going to get gonna learn to do
 

00:21:10.430 --> 00:21:11.920
email is going to get gonna learn to do
something like this which is it's kind

00:21:11.920 --> 00:21:11.930
something like this which is it's kind
 

00:21:11.930 --> 00:21:13.300
something like this which is it's kind
of as close as it can get to this while

00:21:13.300 --> 00:21:13.310
of as close as it can get to this while
 

00:21:13.310 --> 00:21:15.070
of as close as it can get to this while
still maintaining independence in the

00:21:15.070 --> 00:21:15.080
still maintaining independence in the
 

00:21:15.080 --> 00:21:18.670
still maintaining independence in the
distributions using this iif method it's

00:21:18.670 --> 00:21:18.680
distributions using this iif method it's
 

00:21:18.680 --> 00:21:20.050
distributions using this iif method it's
a bit of a complicated method that

00:21:20.050 --> 00:21:20.060
a bit of a complicated method that
 

00:21:20.060 --> 00:21:22.540
a bit of a complicated method that
involves many many iterations of

00:21:22.540 --> 00:21:22.550
involves many many iterations of
 

00:21:22.550 --> 00:21:24.750
involves many many iterations of
transformations that you can actually

00:21:24.750 --> 00:21:24.760
transformations that you can actually
 

00:21:24.760 --> 00:21:27.310
transformations that you can actually
compute that are actually invertible

00:21:27.310 --> 00:21:27.320
compute that are actually invertible
 

00:21:27.320 --> 00:21:28.870
compute that are actually invertible
that and you need this to be able to do

00:21:28.870 --> 00:21:28.880
that and you need this to be able to do
 

00:21:28.880 --> 00:21:30.760
that and you need this to be able to do
the computation but with that you can

00:21:30.760 --> 00:21:30.770
the computation but with that you can
 

00:21:30.770 --> 00:21:32.260
the computation but with that you can
get this kind of thing which is pretty

00:21:32.260 --> 00:21:32.270
get this kind of thing which is pretty
 

00:21:32.270 --> 00:21:33.490
get this kind of thing which is pretty
much exactly what you'd want in this

00:21:33.490 --> 00:21:33.500
much exactly what you'd want in this
 

00:21:33.500 --> 00:21:35.110
much exactly what you'd want in this
setting so we've played around with this

00:21:35.110 --> 00:21:35.120
setting so we've played around with this
 

00:21:35.120 --> 00:21:37.600
setting so we've played around with this
model and in fact it you know it we find

00:21:37.600 --> 00:21:37.610
model and in fact it you know it we find
 

00:21:37.610 --> 00:21:38.800
model and in fact it you know it we find
it works really well in practice

00:21:38.800 --> 00:21:38.810
it works really well in practice
 

00:21:38.810 --> 00:21:42.250
it works really well in practice
actually yeah but it's again it's on the

00:21:42.250 --> 00:21:42.260
actually yeah but it's again it's on the
 

00:21:42.260 --> 00:21:44.020
actually yeah but it's again it's on the
encoder side what we were doing with the

00:21:44.020 --> 00:21:44.030
encoder side what we were doing with the
 

00:21:44.030 --> 00:21:45.760
encoder side what we were doing with the
pixel vs on the is working on the

00:21:45.760 --> 00:21:45.770
pixel vs on the is working on the
 

00:21:45.770 --> 00:21:49.270
pixel vs on the is working on the
decoder side but now so this is actually

00:21:49.270 --> 00:21:49.280
decoder side but now so this is actually
 

00:21:49.280 --> 00:21:50.860
decoder side but now so this is actually
fairly complicated both these models are

00:21:50.860 --> 00:21:50.870
fairly complicated both these models are
 

00:21:50.870 --> 00:21:53.230
fairly complicated both these models are
actually fairly complicated to use and a

00:21:53.230 --> 00:21:53.240
actually fairly complicated to use and a
 

00:21:53.240 --> 00:21:56.500
actually fairly complicated to use and a
fairly involved so one question is is

00:21:56.500 --> 00:21:56.510
fairly involved so one question is is
 

00:21:56.510 --> 00:21:57.790
fairly involved so one question is is
there another way to train this model

00:21:57.790 --> 00:21:57.800
there another way to train this model
 

00:21:57.800 --> 00:22:00.690
there another way to train this model
that isn't quite so complicated and so

00:22:00.690 --> 00:22:00.700
that isn't quite so complicated and so
 

00:22:00.700 --> 00:22:03.340
that isn't quite so complicated and so
at the time a student of yoshua bengio

00:22:03.340 --> 00:22:03.350
at the time a student of yoshua bengio
 

00:22:03.350 --> 00:22:07.120
at the time a student of yoshua bengio
and i and good fellow kate was toying

00:22:07.120 --> 00:22:07.130
and i and good fellow kate was toying
 

00:22:07.130 --> 00:22:08.770
and i and good fellow kate was toying
around with this idea and he came up

00:22:08.770 --> 00:22:08.780
around with this idea and he came up
 

00:22:08.780 --> 00:22:11.740
around with this idea and he came up
with a generative adversarial myths and

00:22:11.740 --> 00:22:11.750
with a generative adversarial myths and
 

00:22:11.750 --> 00:22:13.510
with a generative adversarial myths and
the way generative adversarial Nets work

00:22:13.510 --> 00:22:13.520
the way generative adversarial Nets work
 

00:22:13.520 --> 00:22:15.790
the way generative adversarial Nets work
is it posits the learning of a

00:22:15.790 --> 00:22:15.800
is it posits the learning of a
 

00:22:15.800 --> 00:22:18.420
is it posits the learning of a
generative model gee

00:22:18.420 --> 00:22:18.430
generative model gee
 

00:22:18.430 --> 00:22:21.660
generative model gee
in the form of a game so it's a game

00:22:21.660 --> 00:22:21.670
in the form of a game so it's a game
 

00:22:21.670 --> 00:22:26.300
in the form of a game so it's a game
between this generative model G here and

00:22:26.300 --> 00:22:26.310
between this generative model G here and
 

00:22:26.310 --> 00:22:31.470
between this generative model G here and
a discriminator D so the discriminators

00:22:31.470 --> 00:22:31.480
a discriminator D so the discriminators
 

00:22:31.480 --> 00:22:34.020
a discriminator D so the discriminators
job is to try to tell the difference

00:22:34.020 --> 00:22:34.030
job is to try to tell the difference
 

00:22:34.030 --> 00:22:37.140
job is to try to tell the difference
between true data and data generated

00:22:37.140 --> 00:22:37.150
between true data and data generated
 

00:22:37.150 --> 00:22:40.200
between true data and data generated
from the generator right so it's trying

00:22:40.200 --> 00:22:40.210
from the generator right so it's trying
 

00:22:40.210 --> 00:22:41.610
from the generator right so it's trying
to tell the difference between fake data

00:22:41.610 --> 00:22:41.620
to tell the difference between fake data
 

00:22:41.620 --> 00:22:43.680
to tell the difference between fake data
that's generated by the generator and

00:22:43.680 --> 00:22:43.690
that's generated by the generator and
 

00:22:43.690 --> 00:22:46.380
that's generated by the generator and
true data from the training distribution

00:22:46.380 --> 00:22:46.390
true data from the training distribution
 

00:22:46.390 --> 00:22:49.140
true data from the training distribution
and it's just trained to do so this

00:22:49.140 --> 00:22:49.150
and it's just trained to do so this
 

00:22:49.150 --> 00:22:50.970
and it's just trained to do so this
guy's trained to try to output one if

00:22:50.970 --> 00:22:50.980
guy's trained to try to output one if
 

00:22:50.980 --> 00:22:53.340
guy's trained to try to output one if
it's true data and output 0 if it's fake

00:22:53.340 --> 00:22:53.350
it's true data and output 0 if it's fake
 

00:22:53.350 --> 00:22:56.190
it's true data and output 0 if it's fake
data and the generator is being trained

00:22:56.190 --> 00:22:56.200
data and the generator is being trained
 

00:22:56.200 --> 00:22:58.800
data and the generator is being trained
to fool the discriminator by using its

00:22:58.800 --> 00:22:58.810
to fool the discriminator by using its
 

00:22:58.810 --> 00:23:01.110
to fool the discriminator by using its
own gradients against it essentially so

00:23:01.110 --> 00:23:01.120
own gradients against it essentially so
 

00:23:01.120 --> 00:23:03.330
own gradients against it essentially so
we back propagate the the discriminate

00:23:03.330 --> 00:23:03.340
we back propagate the the discriminate
 

00:23:03.340 --> 00:23:05.640
we back propagate the the discriminate
the discriminator error all the way

00:23:05.640 --> 00:23:05.650
the discriminator error all the way
 

00:23:05.650 --> 00:23:09.140
the discriminator error all the way
through through X we usually have to use

00:23:09.140 --> 00:23:09.150
through through X we usually have to use
 

00:23:09.150 --> 00:23:11.910
through through X we usually have to use
continuous X for this and into the

00:23:11.910 --> 00:23:11.920
continuous X for this and into the
 

00:23:11.920 --> 00:23:13.230
continuous X for this and into the
discriminator now we're going to change

00:23:13.230 --> 00:23:13.240
discriminator now we're going to change
 

00:23:13.240 --> 00:23:15.870
discriminator now we're going to change
the parameters of the generator here in

00:23:15.870 --> 00:23:15.880
the parameters of the generator here in
 

00:23:15.880 --> 00:23:19.050
the parameters of the generator here in
order to try to maximally fool the

00:23:19.050 --> 00:23:19.060
order to try to maximally fool the
 

00:23:19.060 --> 00:23:24.890
order to try to maximally fool the
discriminator so in a sort of a more I

00:23:24.890 --> 00:23:24.900
discriminator so in a sort of a more I
 

00:23:24.900 --> 00:23:27.360
discriminator so in a sort of a more I
guess abstract way to represent this

00:23:27.360 --> 00:23:27.370
guess abstract way to represent this
 

00:23:27.370 --> 00:23:28.860
guess abstract way to represent this
looks like this so we have the data on

00:23:28.860 --> 00:23:28.870
looks like this so we have the data on
 

00:23:28.870 --> 00:23:31.140
looks like this so we have the data on
this side we have the discriminator here

00:23:31.140 --> 00:23:31.150
this side we have the discriminator here
 

00:23:31.150 --> 00:23:32.640
this side we have the discriminator here
with its own parameters and this again

00:23:32.640 --> 00:23:32.650
with its own parameters and this again
 

00:23:32.650 --> 00:23:34.440
with its own parameters and this again
for our purposes is almost always a

00:23:34.440 --> 00:23:34.450
for our purposes is almost always a
 

00:23:34.450 --> 00:23:36.180
for our purposes is almost always a
convolutional neural net and then we

00:23:36.180 --> 00:23:36.190
convolutional neural net and then we
 

00:23:36.190 --> 00:23:37.560
convolutional neural net and then we
have the generator which is again one of

00:23:37.560 --> 00:23:37.570
have the generator which is again one of
 

00:23:37.570 --> 00:23:39.510
have the generator which is again one of
these kind of flipped convolutional

00:23:39.510 --> 00:23:39.520
these kind of flipped convolutional
 

00:23:39.520 --> 00:23:41.520
these kind of flipped convolutional
models because it takes noise as input

00:23:41.520 --> 00:23:41.530
models because it takes noise as input
 

00:23:41.530 --> 00:23:42.750
models because it takes noise as input
it needs noise because it needs

00:23:42.750 --> 00:23:42.760
it needs noise because it needs
 

00:23:42.760 --> 00:23:45.390
it needs noise because it needs
variability and then it converts that

00:23:45.390 --> 00:23:45.400
variability and then it converts that
 

00:23:45.400 --> 00:23:48.150
variability and then it converts that
noise into something an image space

00:23:48.150 --> 00:23:48.160
noise into something an image space
 

00:23:48.160 --> 00:23:50.190
noise into something an image space
that's trained with these parameters are

00:23:50.190 --> 00:23:50.200
that's trained with these parameters are
 

00:23:50.200 --> 00:23:54.530
that's trained with these parameters are
trained to fool the discriminator

00:23:54.530 --> 00:23:54.540
 

00:23:54.540 --> 00:23:56.880
alright so you know we can be a little

00:23:56.880 --> 00:23:56.890
alright so you know we can be a little
 

00:23:56.890 --> 00:23:58.110
alright so you know we can be a little
bit more formal about this this is

00:23:58.110 --> 00:23:58.120
bit more formal about this this is
 

00:23:58.120 --> 00:23:59.490
bit more formal about this this is
actually the objective function we're

00:23:59.490 --> 00:23:59.500
actually the objective function we're
 

00:23:59.500 --> 00:24:01.950
actually the objective function we're
training on so let's just break this

00:24:01.950 --> 00:24:01.960
training on so let's just break this
 

00:24:01.960 --> 00:24:03.270
training on so let's just break this
down for a second so from the

00:24:03.270 --> 00:24:03.280
down for a second so from the
 

00:24:03.280 --> 00:24:05.160
down for a second so from the
discriminators point of view what is

00:24:05.160 --> 00:24:05.170
discriminators point of view what is
 

00:24:05.170 --> 00:24:06.660
discriminators point of view what is
this this is just it's called the cross

00:24:06.660 --> 00:24:06.670
this this is just it's called the cross
 

00:24:06.670 --> 00:24:08.250
this this is just it's called the cross
entropy loss it's literally just what

00:24:08.250 --> 00:24:08.260
entropy loss it's literally just what
 

00:24:08.260 --> 00:24:09.180
entropy loss it's literally just what
you would apply if you're doing a

00:24:09.180 --> 00:24:09.190
you would apply if you're doing a
 

00:24:09.190 --> 00:24:10.710
you would apply if you're doing a
classification with this discriminator

00:24:10.710 --> 00:24:10.720
classification with this discriminator
 

00:24:10.720 --> 00:24:13.560
classification with this discriminator
that's all this is from the generators

00:24:13.560 --> 00:24:13.570
that's all this is from the generators
 

00:24:13.570 --> 00:24:15.210
that's all this is from the generators
point of view the generator comes in

00:24:15.210 --> 00:24:15.220
point of view the generator comes in
 

00:24:15.220 --> 00:24:17.160
point of view the generator comes in
just right here right it's the thing you

00:24:17.160 --> 00:24:17.170
just right here right it's the thing you
 

00:24:17.170 --> 00:24:20.220
just right here right it's the thing you
draw these samples from and it's trying

00:24:20.220 --> 00:24:20.230
draw these samples from and it's trying
 

00:24:20.230 --> 00:24:22.440
draw these samples from and it's trying
to minimize well the discriminator is

00:24:22.440 --> 00:24:22.450
to minimize well the discriminator is
 

00:24:22.450 --> 00:24:25.980
to minimize well the discriminator is
trying to maximize this quantity this is

00:24:25.980 --> 00:24:25.990
trying to maximize this quantity this is
 

00:24:25.990 --> 00:24:29.280
trying to maximize this quantity this is
essentially likelihood in and and the

00:24:29.280 --> 00:24:29.290
essentially likelihood in and and the
 

00:24:29.290 --> 00:24:31.049
essentially likelihood in and and the
discriminative generators moving in the

00:24:31.049 --> 00:24:31.059
discriminative generators moving in the
 

00:24:31.059 --> 00:24:37.049
discriminative generators moving in the
opposite direction so we can analyze

00:24:37.049 --> 00:24:37.059
opposite direction so we can analyze
 

00:24:37.059 --> 00:24:38.909
opposite direction so we can analyze
this this game to see you know there's a

00:24:38.909 --> 00:24:38.919
this this game to see you know there's a
 

00:24:38.919 --> 00:24:41.100
this this game to see you know there's a
question right there's actually the way

00:24:41.100 --> 00:24:41.110
question right there's actually the way
 

00:24:41.110 --> 00:24:44.129
question right there's actually the way
this happened was at first he just tried

00:24:44.129 --> 00:24:44.139
this happened was at first he just tried
 

00:24:44.139 --> 00:24:46.799
this happened was at first he just tried
it and it worked it was kind of a

00:24:46.799 --> 00:24:46.809
it and it worked it was kind of a
 

00:24:46.809 --> 00:24:48.509
it and it worked it was kind of a
overnight kind of thing and we got some

00:24:48.509 --> 00:24:48.519
overnight kind of thing and we got some
 

00:24:48.519 --> 00:24:51.749
overnight kind of thing and we got some
very promising results and then we set

00:24:51.749 --> 00:24:51.759
very promising results and then we set
 

00:24:51.759 --> 00:24:53.100
very promising results and then we set
about trying to think about well how do

00:24:53.100 --> 00:24:53.110
about trying to think about well how do
 

00:24:53.110 --> 00:24:54.960
about trying to think about well how do
we actually explain what it's doing why

00:24:54.960 --> 00:24:54.970
we actually explain what it's doing why
 

00:24:54.970 --> 00:24:57.210
we actually explain what it's doing why
does this work and so we did a little

00:24:57.210 --> 00:24:57.220
does this work and so we did a little
 

00:24:57.220 --> 00:25:00.360
does this work and so we did a little
bit of theory which is useful to discuss

00:25:00.360 --> 00:25:00.370
bit of theory which is useful to discuss
 

00:25:00.370 --> 00:25:02.009
bit of theory which is useful to discuss
and I can tell you there's been a lot

00:25:02.009 --> 00:25:02.019
and I can tell you there's been a lot
 

00:25:02.019 --> 00:25:03.779
and I can tell you there's been a lot
more theory on this topic that's been

00:25:03.779 --> 00:25:03.789
more theory on this topic that's been
 

00:25:03.789 --> 00:25:05.100
more theory on this topic that's been
done that I will not be telling you

00:25:05.100 --> 00:25:05.110
done that I will not be telling you
 

00:25:05.110 --> 00:25:06.269
done that I will not be telling you
about but it's actually been a very

00:25:06.269 --> 00:25:06.279
about but it's actually been a very
 

00:25:06.279 --> 00:25:08.970
about but it's actually been a very
interesting development in the last few

00:25:08.970 --> 00:25:08.980
interesting development in the last few
 

00:25:08.980 --> 00:25:12.029
interesting development in the last few
years but this this is a theory that it

00:25:12.029 --> 00:25:12.039
years but this this is a theory that it
 

00:25:12.039 --> 00:25:13.379
years but this this is a theory that it
appeared in the original paper so the

00:25:13.379 --> 00:25:13.389
appeared in the original paper so the
 

00:25:13.389 --> 00:25:14.909
appeared in the original paper so the
way we approach this was let's imagine

00:25:14.909 --> 00:25:14.919
way we approach this was let's imagine
 

00:25:14.919 --> 00:25:17.190
way we approach this was let's imagine
we have an optimal discriminator this

00:25:17.190 --> 00:25:17.200
we have an optimal discriminator this
 

00:25:17.200 --> 00:25:18.930
we have an optimal discriminator this
turns out you can eat pretty easily show

00:25:18.930 --> 00:25:18.940
turns out you can eat pretty easily show
 

00:25:18.940 --> 00:25:20.489
turns out you can eat pretty easily show
this is the optimal discriminator up

00:25:20.489 --> 00:25:20.499
this is the optimal discriminator up
 

00:25:20.499 --> 00:25:22.019
this is the optimal discriminator up
here now you couldn't this is not a

00:25:22.019 --> 00:25:22.029
here now you couldn't this is not a
 

00:25:22.029 --> 00:25:23.249
here now you couldn't this is not a
practical thing right because we don't

00:25:23.249 --> 00:25:23.259
practical thing right because we don't
 

00:25:23.259 --> 00:25:26.039
practical thing right because we don't
know PR which is probability of the real

00:25:26.039 --> 00:25:26.049
know PR which is probability of the real
 

00:25:26.049 --> 00:25:27.539
know PR which is probability of the real
distribution we don't this is not

00:25:27.539 --> 00:25:27.549
distribution we don't this is not
 

00:25:27.549 --> 00:25:29.009
distribution we don't this is not
available to us this is only defined

00:25:29.009 --> 00:25:29.019
available to us this is only defined
 

00:25:29.019 --> 00:25:31.259
available to us this is only defined
over training set so only about training

00:25:31.259 --> 00:25:31.269
over training set so only about training
 

00:25:31.269 --> 00:25:33.060
over training set so only about training
examples so we actually don't you can't

00:25:33.060 --> 00:25:33.070
examples so we actually don't you can't
 

00:25:33.070 --> 00:25:35.489
examples so we actually don't you can't
instantiate this but in theory if we had

00:25:35.489 --> 00:25:35.499
instantiate this but in theory if we had
 

00:25:35.499 --> 00:25:38.789
instantiate this but in theory if we had
this optimal discriminator then the

00:25:38.789 --> 00:25:38.799
this optimal discriminator then the
 

00:25:38.799 --> 00:25:41.399
this optimal discriminator then the
generator would be trained to minimize

00:25:41.399 --> 00:25:41.409
generator would be trained to minimize
 

00:25:41.409 --> 00:25:43.739
generator would be trained to minimize
the Jenson Shannon divergence between

00:25:43.739 --> 00:25:43.749
the Jenson Shannon divergence between
 

00:25:43.749 --> 00:25:46.080
the Jenson Shannon divergence between
the true distribution that gave rise to

00:25:46.080 --> 00:25:46.090
the true distribution that gave rise to
 

00:25:46.090 --> 00:25:47.940
the true distribution that gave rise to
the training data and our generated

00:25:47.940 --> 00:25:47.950
the training data and our generated
 

00:25:47.950 --> 00:25:50.519
the training data and our generated
distribution so this is good right this

00:25:50.519 --> 00:25:50.529
distribution so this is good right this
 

00:25:50.529 --> 00:25:51.690
distribution so this is good right this
is telling us that we're actually doing

00:25:51.690 --> 00:25:51.700
is telling us that we're actually doing
 

00:25:51.700 --> 00:25:53.609
is telling us that we're actually doing
something sensible in this kind of

00:25:53.609 --> 00:25:53.619
something sensible in this kind of
 

00:25:53.619 --> 00:25:55.350
something sensible in this kind of
nonparametric ideal setting that we

00:25:55.350 --> 00:25:55.360
nonparametric ideal setting that we
 

00:25:55.360 --> 00:25:57.629
nonparametric ideal setting that we
don't we're not really using but but

00:25:57.629 --> 00:25:57.639
don't we're not really using but but
 

00:25:57.639 --> 00:26:00.539
don't we're not really using but but
it's but it's actually it's interesting

00:26:00.539 --> 00:26:00.549
it's but it's actually it's interesting
 

00:26:00.549 --> 00:26:05.070
it's but it's actually it's interesting
nonetheless so one thing I can say

00:26:05.070 --> 00:26:05.080
nonetheless so one thing I can say
 

00:26:05.080 --> 00:26:06.779
nonetheless so one thing I can say
though that in practice we actually

00:26:06.779 --> 00:26:06.789
though that in practice we actually
 

00:26:06.789 --> 00:26:08.639
though that in practice we actually
don't use exactly the objective function

00:26:08.639 --> 00:26:08.649
don't use exactly the objective function
 

00:26:08.649 --> 00:26:10.499
don't use exactly the objective function
that I was just describing what we use

00:26:10.499 --> 00:26:10.509
that I was just describing what we use
 

00:26:10.509 --> 00:26:12.060
that I was just describing what we use
instead is a modified objective function

00:26:12.060 --> 00:26:12.070
instead is a modified objective function
 

00:26:12.070 --> 00:26:13.739
instead is a modified objective function
and the reason is is because if we were

00:26:13.739 --> 00:26:13.749
and the reason is is because if we were
 

00:26:13.749 --> 00:26:16.350
and the reason is is because if we were
to minimize G what we had before was

00:26:16.350 --> 00:26:16.360
to minimize G what we had before was
 

00:26:16.360 --> 00:26:18.930
to minimize G what we had before was
this term minimizing G what happens is

00:26:18.930 --> 00:26:18.940
this term minimizing G what happens is
 

00:26:18.940 --> 00:26:20.519
this term minimizing G what happens is
is that as the discriminator gets better

00:26:20.519 --> 00:26:20.529
is that as the discriminator gets better
 

00:26:20.529 --> 00:26:23.460
is that as the discriminator gets better
and better that the gradient on G

00:26:23.460 --> 00:26:23.470
and better that the gradient on G
 

00:26:23.470 --> 00:26:25.700
and better that the gradient on G
actually exaggerated so it goes to zero

00:26:25.700 --> 00:26:25.710
actually exaggerated so it goes to zero
 

00:26:25.710 --> 00:26:29.639
actually exaggerated so it goes to zero
so that's not very useful if we want to

00:26:29.639 --> 00:26:29.649
so that's not very useful if we want to
 

00:26:29.649 --> 00:26:30.930
so that's not very useful if we want to
train this model and this is actually

00:26:30.930 --> 00:26:30.940
train this model and this is actually
 

00:26:30.940 --> 00:26:32.669
train this model and this is actually
one of these one of the practical issues

00:26:32.669 --> 00:26:32.679
one of these one of the practical issues
 

00:26:32.679 --> 00:26:33.690
one of these one of the practical issues
that you see when you actually train

00:26:33.690 --> 00:26:33.700
that you see when you actually train
 

00:26:33.700 --> 00:26:35.460
that you see when you actually train
these models is that you're constantly

00:26:35.460 --> 00:26:35.470
these models is that you're constantly
 

00:26:35.470 --> 00:26:38.220
these models is that you're constantly
fighting this game between that you're

00:26:38.220 --> 00:26:38.230
fighting this game between that you're
 

00:26:38.230 --> 00:26:40.649
fighting this game between that you're
sort of on this edge of of the

00:26:40.649 --> 00:26:40.659
sort of on this edge of of the
 

00:26:40.659 --> 00:26:44.310
sort of on this edge of of the
discriminator doing too well or the or

00:26:44.310 --> 00:26:44.320
discriminator doing too well or the or
 

00:26:44.320 --> 00:26:45.240
discriminator doing too well or the or
the generator

00:26:45.240 --> 00:26:45.250
the generator
 

00:26:45.250 --> 00:26:46.590
the generator
you know it's it's essentially you're

00:26:46.590 --> 00:26:46.600
you know it's it's essentially you're
 

00:26:46.600 --> 00:26:47.880
you know it's it's essentially you're
basically almost always fighting the

00:26:47.880 --> 00:26:47.890
basically almost always fighting the
 

00:26:47.890 --> 00:26:50.040
basically almost always fighting the
discriminator because it's always going

00:26:50.040 --> 00:26:50.050
discriminator because it's always going
 

00:26:50.050 --> 00:26:51.720
discriminator because it's always going
to be as soon as the discriminator

00:26:51.720 --> 00:26:51.730
to be as soon as the discriminator
 

00:26:51.730 --> 00:26:54.210
to be as soon as the discriminator
starts to win this this competition

00:26:54.210 --> 00:26:54.220
starts to win this this competition
 

00:26:54.220 --> 00:26:55.530
starts to win this this competition
between the Jenner and the discriminator

00:26:55.530 --> 00:26:55.540
between the Jenner and the discriminator
 

00:26:55.540 --> 00:26:57.270
between the Jenner and the discriminator
you end up with unstable training and in

00:26:57.270 --> 00:26:57.280
you end up with unstable training and in
 

00:26:57.280 --> 00:26:59.430
you end up with unstable training and in
this case you end up with basically the

00:26:59.430 --> 00:26:59.440
this case you end up with basically the
 

00:26:59.440 --> 00:27:01.830
this case you end up with basically the
the generator stops training and the

00:27:01.830 --> 00:27:01.840
the generator stops training and the
 

00:27:01.840 --> 00:27:03.480
the generator stops training and the
discriminator runs away with it well

00:27:03.480 --> 00:27:03.490
discriminator runs away with it well
 

00:27:03.490 --> 00:27:05.070
discriminator runs away with it well
that's actually in the original case so

00:27:05.070 --> 00:27:05.080
that's actually in the original case so
 

00:27:05.080 --> 00:27:07.050
that's actually in the original case so
what we do instead is we optimize this

00:27:07.050 --> 00:27:07.060
what we do instead is we optimize this
 

00:27:07.060 --> 00:27:09.450
what we do instead is we optimize this
which is a slight modification but it's

00:27:09.450 --> 00:27:09.460
which is a slight modification but it's
 

00:27:09.460 --> 00:27:11.280
which is a slight modification but it's
still monotonic and it it actually

00:27:11.280 --> 00:27:11.290
still monotonic and it it actually
 

00:27:11.290 --> 00:27:13.380
still monotonic and it it actually
corresponds to the same the same fixed

00:27:13.380 --> 00:27:13.390
corresponds to the same the same fixed
 

00:27:13.390 --> 00:27:14.970
corresponds to the same the same fixed
point but but what we're doing is we're

00:27:14.970 --> 00:27:14.980
point but but what we're doing is we're
 

00:27:14.980 --> 00:27:17.130
point but but what we're doing is we're
just actually with respect to G again

00:27:17.130 --> 00:27:17.140
just actually with respect to G again
 

00:27:17.140 --> 00:27:19.140
just actually with respect to G again
coming in through the samples here or

00:27:19.140 --> 00:27:19.150
coming in through the samples here or
 

00:27:19.150 --> 00:27:21.030
coming in through the samples here or
maximizing this quantity rather than

00:27:21.030 --> 00:27:21.040
maximizing this quantity rather than
 

00:27:21.040 --> 00:27:25.110
maximizing this quantity rather than
minimizing this one okay so that's just

00:27:25.110 --> 00:27:25.120
minimizing this one okay so that's just
 

00:27:25.120 --> 00:27:27.000
minimizing this one okay so that's just
a practical kind of heuristic thing but

00:27:27.000 --> 00:27:27.010
a practical kind of heuristic thing but
 

00:27:27.010 --> 00:27:28.110
a practical kind of heuristic thing but
it actually makes a big difference in

00:27:28.110 --> 00:27:28.120
it actually makes a big difference in
 

00:27:28.120 --> 00:27:31.890
it actually makes a big difference in
practice all right so when we did this

00:27:31.890 --> 00:27:31.900
practice all right so when we did this
 

00:27:31.900 --> 00:27:33.570
practice all right so when we did this
when we published first published this

00:27:33.570 --> 00:27:33.580
when we published first published this
 

00:27:33.580 --> 00:27:35.280
when we published first published this
paper this is the kind of results we

00:27:35.280 --> 00:27:35.290
paper this is the kind of results we
 

00:27:35.290 --> 00:27:36.480
paper this is the kind of results we
would see and what you're looking at now

00:27:36.480 --> 00:27:36.490
would see and what you're looking at now
 

00:27:36.490 --> 00:27:39.720
would see and what you're looking at now
is kind of movies formed by moving

00:27:39.720 --> 00:27:39.730
is kind of movies formed by moving
 

00:27:39.730 --> 00:27:42.510
is kind of movies formed by moving
smoothly and Zed space so this is you're

00:27:42.510 --> 00:27:42.520
smoothly and Zed space so this is you're
 

00:27:42.520 --> 00:27:45.240
smoothly and Zed space so this is you're
kind of looking at transformations on

00:27:45.240 --> 00:27:45.250
kind of looking at transformations on
 

00:27:45.250 --> 00:27:47.580
kind of looking at transformations on
the image manifold coming from smooth

00:27:47.580 --> 00:27:47.590
the image manifold coming from smooth
 

00:27:47.590 --> 00:27:50.460
the image manifold coming from smooth
motions in Zed space so we were pretty

00:27:50.460 --> 00:27:50.470
motions in Zed space so we were pretty
 

00:27:50.470 --> 00:27:52.260
motions in Zed space so we were pretty
impressed with these results again they

00:27:52.260 --> 00:27:52.270
impressed with these results again they
 

00:27:52.270 --> 00:27:55.050
impressed with these results again they
felt good at the time but there's been

00:27:55.050 --> 00:27:55.060
felt good at the time but there's been
 

00:27:55.060 --> 00:27:57.570
felt good at the time but there's been
you know a few papers that have come out

00:27:57.570 --> 00:27:57.580
you know a few papers that have come out
 

00:27:57.580 --> 00:28:00.390
you know a few papers that have come out
recently well you know not so recently

00:28:00.390 --> 00:28:00.400
recently well you know not so recently
 

00:28:00.400 --> 00:28:02.640
recently well you know not so recently
actually at this point in 2016 there was

00:28:02.640 --> 00:28:02.650
actually at this point in 2016 there was
 

00:28:02.650 --> 00:28:05.580
actually at this point in 2016 there was
a this was came out in 2014 in 2016

00:28:05.580 --> 00:28:05.590
a this was came out in 2014 in 2016
 

00:28:05.590 --> 00:28:08.100
a this was came out in 2014 in 2016
there was a big jump in the quality and

00:28:08.100 --> 00:28:08.110
there was a big jump in the quality and
 

00:28:08.110 --> 00:28:10.290
there was a big jump in the quality and
and this was sort of one of those stages

00:28:10.290 --> 00:28:10.300
and this was sort of one of those stages
 

00:28:10.300 --> 00:28:11.670
and this was sort of one of those stages
this is the least-squares game this is

00:28:11.670 --> 00:28:11.680
this is the least-squares game this is
 

00:28:11.680 --> 00:28:13.770
this is the least-squares game this is
just one example of many I could have

00:28:13.770 --> 00:28:13.780
just one example of many I could have
 

00:28:13.780 --> 00:28:16.110
just one example of many I could have
pointed out but this is the kind of

00:28:16.110 --> 00:28:16.120
pointed out but this is the kind of
 

00:28:16.120 --> 00:28:18.000
pointed out but this is the kind of
results for seeing so so part of one of

00:28:18.000 --> 00:28:18.010
results for seeing so so part of one of
 

00:28:18.010 --> 00:28:20.220
results for seeing so so part of one of
the one of the secrets here is that it's

00:28:20.220 --> 00:28:20.230
the one of the secrets here is that it's
 

00:28:20.230 --> 00:28:22.890
the one of the secrets here is that it's
128 by 128 so bigger images actually

00:28:22.890 --> 00:28:22.900
128 by 128 so bigger images actually
 

00:28:22.900 --> 00:28:25.020
128 by 128 so bigger images actually
give you much better perception of

00:28:25.020 --> 00:28:25.030
give you much better perception of
 

00:28:25.030 --> 00:28:26.550
give you much better perception of
quality in terms of the images but so

00:28:26.550 --> 00:28:26.560
quality in terms of the images but so
 

00:28:26.560 --> 00:28:29.760
quality in terms of the images but so
these are not necessarily or generally

00:28:29.760 --> 00:28:29.770
these are not necessarily or generally
 

00:28:29.770 --> 00:28:31.170
these are not necessarily or generally
not real bedrooms these are these are

00:28:31.170 --> 00:28:31.180
not real bedrooms these are these are
 

00:28:31.180 --> 00:28:34.860
not real bedrooms these are these are
actually generated from the model right

00:28:34.860 --> 00:28:34.870
actually generated from the model right
 

00:28:34.870 --> 00:28:38.010
actually generated from the model right
so trained on you know roughly I think a

00:28:38.010 --> 00:28:38.020
so trained on you know roughly I think a
 

00:28:38.020 --> 00:28:39.180
so trained on you know roughly I think a
hundred thousand or at least a hundred

00:28:39.180 --> 00:28:39.190
hundred thousand or at least a hundred
 

00:28:39.190 --> 00:28:41.160
hundred thousand or at least a hundred
thousand bedroom scenes has to generate

00:28:41.160 --> 00:28:41.170
thousand bedroom scenes has to generate
 

00:28:41.170 --> 00:28:43.380
thousand bedroom scenes has to generate
from these random zed bits this is what

00:28:43.380 --> 00:28:43.390
from these random zed bits this is what
 

00:28:43.390 --> 00:28:46.920
from these random zed bits this is what
it gives you so one thing you could

00:28:46.920 --> 00:28:46.930
it gives you so one thing you could
 

00:28:46.930 --> 00:28:48.090
it gives you so one thing you could
think of and one thing that certainly

00:28:48.090 --> 00:28:48.100
think of and one thing that certainly
 

00:28:48.100 --> 00:28:50.040
think of and one thing that certainly
kind of occurred to me when I first saw

00:28:50.040 --> 00:28:50.050
kind of occurred to me when I first saw
 

00:28:50.050 --> 00:28:52.650
kind of occurred to me when I first saw
these kinds of results is that well it's

00:28:52.650 --> 00:28:52.660
these kinds of results is that well it's
 

00:28:52.660 --> 00:28:54.419
these kinds of results is that well it's
just over fit on some small set of

00:28:54.419 --> 00:28:54.429
just over fit on some small set of
 

00:28:54.429 --> 00:28:55.560
just over fit on some small set of
examples and it's just learning these

00:28:55.560 --> 00:28:55.570
examples and it's just learning these
 

00:28:55.570 --> 00:28:59.010
examples and it's just learning these
Delta functions right so so that

00:28:59.010 --> 00:28:59.020
Delta functions right so so that
 

00:28:59.020 --> 00:29:00.300
Delta functions right so so that
not that interesting some since it's

00:29:00.300 --> 00:29:00.310
not that interesting some since it's
 

00:29:00.310 --> 00:29:01.920
not that interesting some since it's
kind of memorized some small set of data

00:29:01.920 --> 00:29:01.930
kind of memorized some small set of data
 

00:29:01.930 --> 00:29:05.100
kind of memorized some small set of data
and it's enough that it looks good and

00:29:05.100 --> 00:29:05.110
and it's enough that it looks good and
 

00:29:05.110 --> 00:29:06.600
and it's enough that it looks good and
it's impressive

00:29:06.600 --> 00:29:06.610
it's impressive
 

00:29:06.610 --> 00:29:08.850
it's impressive
but it doesn't seem like that's actually

00:29:08.850 --> 00:29:08.860
but it doesn't seem like that's actually
 

00:29:08.860 --> 00:29:10.470
but it doesn't seem like that's actually
the case and one of the evidence one of

00:29:10.470 --> 00:29:10.480
the case and one of the evidence one of
 

00:29:10.480 --> 00:29:11.700
the case and one of the evidence one of
the parts of evidences was pointed to

00:29:11.700 --> 00:29:11.710
the parts of evidences was pointed to
 

00:29:11.710 --> 00:29:14.130
the parts of evidences was pointed to
and this is in the DC Gann paper was

00:29:14.130 --> 00:29:14.140
and this is in the DC Gann paper was
 

00:29:14.140 --> 00:29:16.140
and this is in the DC Gann paper was
this so that same trick that I showed

00:29:16.140 --> 00:29:16.150
this so that same trick that I showed
 

00:29:16.150 --> 00:29:19.290
this so that same trick that I showed
you with the movies in EM nough start of

00:29:19.290 --> 00:29:19.300
you with the movies in EM nough start of
 

00:29:19.300 --> 00:29:21.240
you with the movies in EM nough start of
moving smoothly in Zed space they

00:29:21.240 --> 00:29:21.250
moving smoothly in Zed space they
 

00:29:21.250 --> 00:29:23.850
moving smoothly in Zed space they
applied basically that same idea here so

00:29:23.850 --> 00:29:23.860
applied basically that same idea here so
 

00:29:23.860 --> 00:29:26.360
applied basically that same idea here so
this is basically one long trajectory

00:29:26.360 --> 00:29:26.370
this is basically one long trajectory
 

00:29:26.370 --> 00:29:29.610
this is basically one long trajectory
through Zed space and what you can see

00:29:29.610 --> 00:29:29.620
through Zed space and what you can see
 

00:29:29.620 --> 00:29:31.530
through Zed space and what you can see
is starting up here on ending up all the

00:29:31.530 --> 00:29:31.540
is starting up here on ending up all the
 

00:29:31.540 --> 00:29:32.910
is starting up here on ending up all the
way down here what you can see is a

00:29:32.910 --> 00:29:32.920
way down here what you can see is a
 

00:29:32.920 --> 00:29:36.660
way down here what you can see is a
smooth transition right and at every

00:29:36.660 --> 00:29:36.670
smooth transition right and at every
 

00:29:36.670 --> 00:29:38.610
smooth transition right and at every
point it seems like you know a

00:29:38.610 --> 00:29:38.620
point it seems like you know a
 

00:29:38.620 --> 00:29:42.570
point it seems like you know a
reasonable bedroom scene so it really

00:29:42.570 --> 00:29:42.580
reasonable bedroom scene so it really
 

00:29:42.580 --> 00:29:44.790
reasonable bedroom scene so it really
does seem like like that picture that I

00:29:44.790 --> 00:29:44.800
does seem like like that picture that I
 

00:29:44.800 --> 00:29:46.590
does seem like like that picture that I
showed you where we had the Zed space it

00:29:46.590 --> 00:29:46.600
showed you where we had the Zed space it
 

00:29:46.600 --> 00:29:48.570
showed you where we had the Zed space it
was sort of smooth and then we had this

00:29:48.570 --> 00:29:48.580
was sort of smooth and then we had this
 

00:29:48.580 --> 00:29:50.850
was sort of smooth and then we had this
X space that had this manifold on it it

00:29:50.850 --> 00:29:50.860
X space that had this manifold on it it
 

00:29:50.860 --> 00:29:52.020
X space that had this manifold on it it
really does feel like that's what's

00:29:52.020 --> 00:29:52.030
really does feel like that's what's
 

00:29:52.030 --> 00:29:53.250
really does feel like that's what's
happening here right where we're moving

00:29:53.250 --> 00:29:53.260
happening here right where we're moving
 

00:29:53.260 --> 00:29:54.990
happening here right where we're moving
smoothly in Zed space and we're moving

00:29:54.990 --> 00:29:55.000
smoothly in Zed space and we're moving
 

00:29:55.000 --> 00:30:04.110
smoothly in Zed space and we're moving
along the image manifold in X space so

00:30:04.110 --> 00:30:04.120
along the image manifold in X space so
 

00:30:04.120 --> 00:30:06.120
along the image manifold in X space so
for example this I guess I don't know if

00:30:06.120 --> 00:30:06.130
for example this I guess I don't know if
 

00:30:06.130 --> 00:30:08.180
for example this I guess I don't know if
this is a picture or TV but it's slowly

00:30:08.180 --> 00:30:08.190
this is a picture or TV but it's slowly
 

00:30:08.190 --> 00:30:12.240
this is a picture or TV but it's slowly
morphs into a window I guess and then

00:30:12.240 --> 00:30:12.250
morphs into a window I guess and then
 

00:30:12.250 --> 00:30:13.740
morphs into a window I guess and then
kind of becomes clearly a window and

00:30:13.740 --> 00:30:13.750
kind of becomes clearly a window and
 

00:30:13.750 --> 00:30:16.530
kind of becomes clearly a window and
then turns just into this edge sort of

00:30:16.530 --> 00:30:16.540
then turns just into this edge sort of
 

00:30:16.540 --> 00:30:20.940
then turns just into this edge sort of
an edge of the room so one of the things

00:30:20.940 --> 00:30:20.950
an edge of the room so one of the things
 

00:30:20.950 --> 00:30:22.440
an edge of the room so one of the things
actually if you want to nitpick about

00:30:22.440 --> 00:30:22.450
actually if you want to nitpick about
 

00:30:22.450 --> 00:30:24.090
actually if you want to nitpick about
these the the models actually don't seem

00:30:24.090 --> 00:30:24.100
these the the models actually don't seem
 

00:30:24.100 --> 00:30:26.490
these the the models actually don't seem
to understand 3d geometry very well it

00:30:26.490 --> 00:30:26.500
to understand 3d geometry very well it
 

00:30:26.500 --> 00:30:28.470
to understand 3d geometry very well it
often gets the perspective just a little

00:30:28.470 --> 00:30:28.480
often gets the perspective just a little
 

00:30:28.480 --> 00:30:31.110
often gets the perspective just a little
wrong it's sort of something might be

00:30:31.110 --> 00:30:31.120
wrong it's sort of something might be
 

00:30:31.120 --> 00:30:33.990
wrong it's sort of something might be
interesting for future work so yeah so

00:30:33.990 --> 00:30:34.000
interesting for future work so yeah so
 

00:30:34.000 --> 00:30:36.450
interesting for future work so yeah so
one question you might be it so why why

00:30:36.450 --> 00:30:36.460
one question you might be it so why why
 

00:30:36.460 --> 00:30:38.880
one question you might be it so why why
do these things work well and they keep

00:30:38.880 --> 00:30:38.890
do these things work well and they keep
 

00:30:38.890 --> 00:30:41.070
do these things work well and they keep
in mind that you know when we talked

00:30:41.070 --> 00:30:41.080
in mind that you know when we talked
 

00:30:41.080 --> 00:30:43.020
in mind that you know when we talked
about the VA II model we actually had to

00:30:43.020 --> 00:30:43.030
about the VA II model we actually had to
 

00:30:43.030 --> 00:30:45.420
about the VA II model we actually had to
do quite a bit of work to get comparable

00:30:45.420 --> 00:30:45.430
do quite a bit of work to get comparable
 

00:30:45.430 --> 00:30:47.850
do quite a bit of work to get comparable
results right we had to embed these pick

00:30:47.850 --> 00:30:47.860
results right we had to embed these pick
 

00:30:47.860 --> 00:30:51.420
results right we had to embed these pick
these pixel CN NS in the decoder or we

00:30:51.420 --> 00:30:51.430
these pixel CN NS in the decoder or we
 

00:30:51.430 --> 00:30:52.830
these pixel CN NS in the decoder or we
had to do some quite a bit of work to

00:30:52.830 --> 00:30:52.840
had to do some quite a bit of work to
 

00:30:52.840 --> 00:30:54.870
had to do some quite a bit of work to
get the encoder to work right in these

00:30:54.870 --> 00:30:54.880
get the encoder to work right in these
 

00:30:54.880 --> 00:30:56.190
get the encoder to work right in these
models we literally just took a

00:30:56.190 --> 00:30:56.200
models we literally just took a
 

00:30:56.200 --> 00:30:58.290
models we literally just took a
confident stuck in some noise at the

00:30:58.290 --> 00:30:58.300
confident stuck in some noise at the
 

00:30:58.300 --> 00:30:59.850
confident stuck in some noise at the
beginning pushed it through and we got

00:30:59.850 --> 00:30:59.860
beginning pushed it through and we got
 

00:30:59.860 --> 00:31:01.440
beginning pushed it through and we got
these fantastic samples it really is

00:31:01.440 --> 00:31:01.450
these fantastic samples it really is
 

00:31:01.450 --> 00:31:03.300
these fantastic samples it really is
kind of that simple so what's going on

00:31:03.300 --> 00:31:03.310
kind of that simple so what's going on
 

00:31:03.310 --> 00:31:05.760
kind of that simple so what's going on
like why is it working as well as its

00:31:05.760 --> 00:31:05.770
like why is it working as well as its
 

00:31:05.770 --> 00:31:09.030
like why is it working as well as its
well as it is and so I have a kind of an

00:31:09.030 --> 00:31:09.040
well as it is and so I have a kind of an
 

00:31:09.040 --> 00:31:10.980
well as it is and so I have a kind of an
intuition for you a kind of a cartoon

00:31:10.980 --> 00:31:10.990
intuition for you a kind of a cartoon
 

00:31:10.990 --> 00:31:12.930
intuition for you a kind of a cartoon
view so imagine that

00:31:12.930 --> 00:31:12.940
view so imagine that
 

00:31:12.940 --> 00:31:15.840
view so imagine that
this is the image manifold so so this is

00:31:15.840 --> 00:31:15.850
this is the image manifold so so this is
 

00:31:15.850 --> 00:31:17.040
this is the image manifold so so this is
kind of a cartoon view of an image

00:31:17.040 --> 00:31:17.050
kind of a cartoon view of an image
 

00:31:17.050 --> 00:31:19.260
kind of a cartoon view of an image
manifold but like this is in two pixel

00:31:19.260 --> 00:31:19.270
manifold but like this is in two pixel
 

00:31:19.270 --> 00:31:22.200
manifold but like this is in two pixel
dimensions here and and we're imagining

00:31:22.200 --> 00:31:22.210
dimensions here and and we're imagining
 

00:31:22.210 --> 00:31:24.330
dimensions here and and we're imagining
here that these are just parts of image

00:31:24.330 --> 00:31:24.340
here that these are just parts of image
 

00:31:24.340 --> 00:31:26.970
here that these are just parts of image
manifold and they sort of you know share

00:31:26.970 --> 00:31:26.980
manifold and they sort of you know share
 

00:31:26.980 --> 00:31:29.160
manifold and they sort of you know share
some features close by but but what this

00:31:29.160 --> 00:31:29.170
some features close by but but what this
 

00:31:29.170 --> 00:31:30.810
some features close by but but what this
is basically representing is the fact

00:31:30.810 --> 00:31:30.820
is basically representing is the fact
 

00:31:30.820 --> 00:31:33.780
is basically representing is the fact
that that most of this space isn't on

00:31:33.780 --> 00:31:33.790
that that most of this space isn't on
 

00:31:33.790 --> 00:31:35.580
that that most of this space isn't on
the image manifold right image manifold

00:31:35.580 --> 00:31:35.590
the image manifold right image manifold
 

00:31:35.590 --> 00:31:38.040
the image manifold right image manifold
is some complicated non-linearity and if

00:31:38.040 --> 00:31:38.050
is some complicated non-linearity and if
 

00:31:38.050 --> 00:31:40.020
is some complicated non-linearity and if
you were to randomly sample in pixel

00:31:40.020 --> 00:31:40.030
you were to randomly sample in pixel
 

00:31:40.030 --> 00:31:41.520
you were to randomly sample in pixel
space you would not land on this image

00:31:41.520 --> 00:31:41.530
space you would not land on this image
 

00:31:41.530 --> 00:31:43.050
space you would not land on this image
manifold which makes sense right

00:31:43.050 --> 00:31:43.060
manifold which makes sense right
 

00:31:43.060 --> 00:31:44.340
manifold which makes sense right
randomly sample in pixel space you're

00:31:44.340 --> 00:31:44.350
randomly sample in pixel space you're
 

00:31:44.350 --> 00:31:46.220
randomly sample in pixel space you're
not getting a natural image out of it

00:31:46.220 --> 00:31:46.230
not getting a natural image out of it
 

00:31:46.230 --> 00:31:49.050
not getting a natural image out of it
this is sort of a cartoon of you or my

00:31:49.050 --> 00:31:49.060
this is sort of a cartoon of you or my
 

00:31:49.060 --> 00:31:50.640
this is sort of a cartoon of you or my
perspective on the difference between

00:31:50.640 --> 00:31:50.650
perspective on the difference between
 

00:31:50.650 --> 00:31:54.450
perspective on the difference between
what you see with maximum likelihood

00:31:54.450 --> 00:31:54.460
what you see with maximum likelihood
 

00:31:54.460 --> 00:31:56.570
what you see with maximum likelihood
models of which the VA II is one and

00:31:56.570 --> 00:31:56.580
models of which the VA II is one and
 

00:31:56.580 --> 00:31:59.670
models of which the VA II is one and
something like again so the maximum

00:31:59.670 --> 00:31:59.680
something like again so the maximum
 

00:31:59.680 --> 00:32:01.620
something like again so the maximum
likelihood the way it's trained is it

00:32:01.620 --> 00:32:01.630
likelihood the way it's trained is it
 

00:32:01.630 --> 00:32:03.480
likelihood the way it's trained is it
has to give a certain amount of

00:32:03.480 --> 00:32:03.490
has to give a certain amount of
 

00:32:03.490 --> 00:32:06.450
has to give a certain amount of
likelihood density for each real sample

00:32:06.450 --> 00:32:06.460
likelihood density for each real sample
 

00:32:06.460 --> 00:32:09.150
likelihood density for each real sample
if it doesn't it's punished very

00:32:09.150 --> 00:32:09.160
if it doesn't it's punished very
 

00:32:09.160 --> 00:32:11.220
if it doesn't it's punished very
severely for that so it's willing to

00:32:11.220 --> 00:32:11.230
severely for that so it's willing to
 

00:32:11.230 --> 00:32:13.560
severely for that so it's willing to
spread out its probability mass over

00:32:13.560 --> 00:32:13.570
spread out its probability mass over
 

00:32:13.570 --> 00:32:16.290
spread out its probability mass over
regions of the of the input space or the

00:32:16.290 --> 00:32:16.300
regions of the of the input space or the
 

00:32:16.300 --> 00:32:18.600
regions of the of the input space or the
error of the pixel space which actually

00:32:18.600 --> 00:32:18.610
error of the pixel space which actually
 

00:32:18.610 --> 00:32:20.130
error of the pixel space which actually
doesn't correspond to a natural image

00:32:20.130 --> 00:32:20.140
doesn't correspond to a natural image
 

00:32:20.140 --> 00:32:22.020
doesn't correspond to a natural image
and so when we sample from this model

00:32:22.020 --> 00:32:22.030
and so when we sample from this model
 

00:32:22.030 --> 00:32:23.730
and so when we sample from this model
that's most of our samples come from

00:32:23.730 --> 00:32:23.740
that's most of our samples come from
 

00:32:23.740 --> 00:32:25.350
that's most of our samples come from
right this is these are these blurry

00:32:25.350 --> 00:32:25.360
right this is these are these blurry
 

00:32:25.360 --> 00:32:27.540
right this is these are these blurry
images that we're looking at again

00:32:27.540 --> 00:32:27.550
images that we're looking at again
 

00:32:27.550 --> 00:32:29.100
images that we're looking at again
models things differently right because

00:32:29.100 --> 00:32:29.110
models things differently right because
 

00:32:29.110 --> 00:32:30.930
models things differently right because
it's only playing this game between the

00:32:30.930 --> 00:32:30.940
it's only playing this game between the
 

00:32:30.940 --> 00:32:32.700
it's only playing this game between the
encoder and well sorry between the

00:32:32.700 --> 00:32:32.710
encoder and well sorry between the
 

00:32:32.710 --> 00:32:35.130
encoder and well sorry between the
discriminator and the generator all that

00:32:35.130 --> 00:32:35.140
discriminator and the generator all that
 

00:32:35.140 --> 00:32:38.130
discriminator and the generator all that
has to do is sort of stick on you know

00:32:38.130 --> 00:32:38.140
has to do is sort of stick on you know
 

00:32:38.140 --> 00:32:40.860
has to do is sort of stick on you know
some subset of the examples or maybe

00:32:40.860 --> 00:32:40.870
some subset of the examples or maybe
 

00:32:40.870 --> 00:32:42.900
some subset of the examples or maybe
some subset of the manifolds that are

00:32:42.900 --> 00:32:42.910
some subset of the manifolds that are
 

00:32:42.910 --> 00:32:45.420
some subset of the manifolds that are
present not and you have enough

00:32:45.420 --> 00:32:45.430
present not and you have enough
 

00:32:45.430 --> 00:32:47.460
present not and you have enough
diversity that the discriminator can't

00:32:47.460 --> 00:32:47.470
diversity that the discriminator can't
 

00:32:47.470 --> 00:32:50.490
diversity that the discriminator can't
notice that it's modeling a subset so

00:32:50.490 --> 00:32:50.500
notice that it's modeling a subset so
 

00:32:50.500 --> 00:32:51.720
notice that it's modeling a subset so
there's pressure on the model to

00:32:51.720 --> 00:32:51.730
there's pressure on the model to
 

00:32:51.730 --> 00:32:53.490
there's pressure on the model to
maintain a certain amount of diversity

00:32:53.490 --> 00:32:53.500
maintain a certain amount of diversity
 

00:32:53.500 --> 00:32:55.260
maintain a certain amount of diversity
but at the same time it doesn't actually

00:32:55.260 --> 00:32:55.270
but at the same time it doesn't actually
 

00:32:55.270 --> 00:32:58.770
but at the same time it doesn't actually
face any pressure to model all aspects

00:32:58.770 --> 00:32:58.780
face any pressure to model all aspects
 

00:32:58.780 --> 00:33:00.570
face any pressure to model all aspects
of the training distribution it can just

00:33:00.570 --> 00:33:00.580
of the training distribution it can just
 

00:33:00.580 --> 00:33:02.820
of the training distribution it can just
ignore certain aspects of the training

00:33:02.820 --> 00:33:02.830
ignore certain aspects of the training
 

00:33:02.830 --> 00:33:04.260
ignore certain aspects of the training
examples or certain aspects of the

00:33:04.260 --> 00:33:04.270
examples or certain aspects of the
 

00:33:04.270 --> 00:33:06.230
examples or certain aspects of the
training distribution without

00:33:06.230 --> 00:33:06.240
training distribution without
 

00:33:06.240 --> 00:33:10.290
training distribution without
significant punishment from the from the

00:33:10.290 --> 00:33:10.300
significant punishment from the from the
 

00:33:10.300 --> 00:33:12.420
significant punishment from the from the
training algorithm so anyway that's

00:33:12.420 --> 00:33:12.430
training algorithm so anyway that's
 

00:33:12.430 --> 00:33:13.860
training algorithm so anyway that's
that's I think a good idea to have in

00:33:13.860 --> 00:33:13.870
that's I think a good idea to have in
 

00:33:13.870 --> 00:33:15.180
that's I think a good idea to have in
your mind about the difference between

00:33:15.180 --> 00:33:15.190
your mind about the difference between
 

00:33:15.190 --> 00:33:19.410
your mind about the difference between
how these methods work yeah so so just

00:33:19.410 --> 00:33:19.420
how these methods work yeah so so just
 

00:33:19.420 --> 00:33:21.560
how these methods work yeah so so just
I'd like to sort of conclude with a few

00:33:21.560 --> 00:33:21.570
I'd like to sort of conclude with a few
 

00:33:21.570 --> 00:33:24.390
I'd like to sort of conclude with a few
steps that have happened since the

00:33:24.390 --> 00:33:24.400
steps that have happened since the
 

00:33:24.400 --> 00:33:25.890
steps that have happened since the
the gans one of the things this is

00:33:25.890 --> 00:33:25.900
the gans one of the things this is
 

00:33:25.900 --> 00:33:27.780
the gans one of the things this is
something that we've done we've actually

00:33:27.780 --> 00:33:27.790
something that we've done we've actually
 

00:33:27.790 --> 00:33:30.060
something that we've done we've actually
you know what you might ask well ganz

00:33:30.060 --> 00:33:30.070
you know what you might ask well ganz
 

00:33:30.070 --> 00:33:32.130
you know what you might ask well ganz
are great but in a way it's kind of

00:33:32.130 --> 00:33:32.140
are great but in a way it's kind of
 

00:33:32.140 --> 00:33:33.540
are great but in a way it's kind of
unsatisfying because we start with this

00:33:33.540 --> 00:33:33.550
unsatisfying because we start with this
 

00:33:33.550 --> 00:33:35.220
unsatisfying because we start with this
Zed and then we can generate images so

00:33:35.220 --> 00:33:35.230
Zed and then we can generate images so
 

00:33:35.230 --> 00:33:36.570
Zed and then we can generate images so
yes we generate really nice-looking

00:33:36.570 --> 00:33:36.580
yes we generate really nice-looking
 

00:33:36.580 --> 00:33:39.330
yes we generate really nice-looking
images but but we had this you know hope

00:33:39.330 --> 00:33:39.340
images but but we had this you know hope
 

00:33:39.340 --> 00:33:40.800
images but but we had this you know hope
when I started talk about these latent

00:33:40.800 --> 00:33:40.810
when I started talk about these latent
 

00:33:40.810 --> 00:33:42.570
when I started talk about these latent
variable Mountain models that we could

00:33:42.570 --> 00:33:42.580
variable Mountain models that we could
 

00:33:42.580 --> 00:33:45.450
variable Mountain models that we could
actually maybe infer the Z from an image

00:33:45.450 --> 00:33:45.460
actually maybe infer the Z from an image
 

00:33:45.460 --> 00:33:47.220
actually maybe infer the Z from an image
right so we can actually extract some

00:33:47.220 --> 00:33:47.230
right so we can actually extract some
 

00:33:47.230 --> 00:33:50.490
right so we can actually extract some
semantics out from of the of the image

00:33:50.490 --> 00:33:50.500
semantics out from of the of the image
 

00:33:50.500 --> 00:33:52.200
semantics out from of the of the image
using these latent variables that you

00:33:52.200 --> 00:33:52.210
using these latent variables that you
 

00:33:52.210 --> 00:33:54.240
using these latent variables that you
discover and in the game we don't have

00:33:54.240 --> 00:33:54.250
discover and in the game we don't have
 

00:33:54.250 --> 00:33:55.320
discover and in the game we don't have
them the question is can we actually

00:33:55.320 --> 00:33:55.330
them the question is can we actually
 

00:33:55.330 --> 00:33:57.870
them the question is can we actually
within this generative adversarial

00:33:57.870 --> 00:33:57.880
within this generative adversarial
 

00:33:57.880 --> 00:34:00.660
within this generative adversarial
framework can we incorporate inference

00:34:00.660 --> 00:34:00.670
framework can we incorporate inference
 

00:34:00.670 --> 00:34:02.490
framework can we incorporate inference
mechanism so that's exactly what we're

00:34:02.490 --> 00:34:02.500
mechanism so that's exactly what we're
 

00:34:02.500 --> 00:34:04.140
mechanism so that's exactly what we're
doing here with this work and it's

00:34:04.140 --> 00:34:04.150
doing here with this work and it's
 

00:34:04.150 --> 00:34:05.940
doing here with this work and it's
actually a model we call Alli but the

00:34:05.940 --> 00:34:05.950
actually a model we call Alli but the
 

00:34:05.950 --> 00:34:08.280
actually a model we call Alli but the
identical work essentially came out at

00:34:08.280 --> 00:34:08.290
identical work essentially came out at
 

00:34:08.290 --> 00:34:11.040
identical work essentially came out at
the same time known as baigan and the

00:34:11.040 --> 00:34:11.050
the same time known as baigan and the
 

00:34:11.050 --> 00:34:12.990
the same time known as baigan and the
basic idea here is just to incorporate

00:34:12.990 --> 00:34:13.000
basic idea here is just to incorporate
 

00:34:13.000 --> 00:34:16.020
basic idea here is just to incorporate
an encoder into the model so rather than

00:34:16.020 --> 00:34:16.030
an encoder into the model so rather than
 

00:34:16.030 --> 00:34:18.000
an encoder into the model so rather than
just giving the data distribute the data

00:34:18.000 --> 00:34:18.010
just giving the data distribute the data
 

00:34:18.010 --> 00:34:20.580
just giving the data distribute the data
set R here on on the Left earlier the

00:34:20.580 --> 00:34:20.590
set R here on on the Left earlier the
 

00:34:20.590 --> 00:34:22.140
set R here on on the Left earlier the
Gann was defined we had the decoder a

00:34:22.140 --> 00:34:22.150
Gann was defined we had the decoder a
 

00:34:22.150 --> 00:34:24.030
Gann was defined we had the decoder a
generative model but over here we only

00:34:24.030 --> 00:34:24.040
generative model but over here we only
 

00:34:24.040 --> 00:34:27.000
generative model but over here we only
gave it X training examples and here we

00:34:27.000 --> 00:34:27.010
gave it X training examples and here we
 

00:34:27.010 --> 00:34:29.310
gave it X training examples and here we
only compared against X generated from

00:34:29.310 --> 00:34:29.320
only compared against X generated from
 

00:34:29.320 --> 00:34:33.090
only compared against X generated from
the DQ from the the generator but in

00:34:33.090 --> 00:34:33.100
the DQ from the the generator but in
 

00:34:33.100 --> 00:34:34.740
the DQ from the the generator but in
this case what we're doing is we take X

00:34:34.740 --> 00:34:34.750
this case what we're doing is we take X
 

00:34:34.750 --> 00:34:37.470
this case what we're doing is we take X
and then we actually use an encoder here

00:34:37.470 --> 00:34:37.480
and then we actually use an encoder here
 

00:34:37.480 --> 00:34:41.790
and then we actually use an encoder here
to to generate a Z given X and on the

00:34:41.790 --> 00:34:41.800
to to generate a Z given X and on the
 

00:34:41.800 --> 00:34:43.710
to to generate a Z given X and on the
decoder we have again our traditional

00:34:43.710 --> 00:34:43.720
decoder we have again our traditional
 

00:34:43.720 --> 00:34:46.020
decoder we have again our traditional
Gann style we take a sample from some

00:34:46.020 --> 00:34:46.030
Gann style we take a sample from some
 

00:34:46.030 --> 00:34:48.840
Gann style we take a sample from some
simple distribution and we generate X so

00:34:48.840 --> 00:34:48.850
simple distribution and we generate X so
 

00:34:48.850 --> 00:34:50.310
simple distribution and we generate X so
again this is the data distribution over

00:34:50.310 --> 00:34:50.320
again this is the data distribution over
 

00:34:50.320 --> 00:34:52.890
again this is the data distribution over
here and code it to Zed and then we take

00:34:52.890 --> 00:34:52.900
here and code it to Zed and then we take
 

00:34:52.900 --> 00:34:55.200
here and code it to Zed and then we take
our decode sample from Zed and we decode

00:34:55.200 --> 00:34:55.210
our decode sample from Zed and we decode
 

00:34:55.210 --> 00:34:57.270
our decode sample from Zed and we decode
to X and our discriminator now crucially

00:34:57.270 --> 00:34:57.280
to X and our discriminator now crucially
 

00:34:57.280 --> 00:34:59.370
to X and our discriminator now crucially
is not just given X but it's given X and

00:34:59.370 --> 00:34:59.380
is not just given X but it's given X and
 

00:34:59.380 --> 00:35:01.650
is not just given X but it's given X and
Zed and it's asked can you tell the

00:35:01.650 --> 00:35:01.660
Zed and it's asked can you tell the
 

00:35:01.660 --> 00:35:03.150
Zed and it's asked can you tell the
difference in this joint distribution

00:35:03.150 --> 00:35:03.160
difference in this joint distribution
 

00:35:03.160 --> 00:35:04.650
difference in this joint distribution
between the end coder side and the

00:35:04.650 --> 00:35:04.660
between the end coder side and the
 

00:35:04.660 --> 00:35:09.060
between the end coder side and the
decoder side that's the game and what we

00:35:09.060 --> 00:35:09.070
decoder side that's the game and what we
 

00:35:09.070 --> 00:35:10.950
decoder side that's the game and what we
find is well first of all it actually

00:35:10.950 --> 00:35:10.960
find is well first of all it actually
 

00:35:10.960 --> 00:35:12.930
find is well first of all it actually
generates very good samples which is

00:35:12.930 --> 00:35:12.940
generates very good samples which is
 

00:35:12.940 --> 00:35:16.500
generates very good samples which is
interesting it's actually it seems to

00:35:16.500 --> 00:35:16.510
interesting it's actually it seems to
 

00:35:16.510 --> 00:35:18.810
interesting it's actually it seems to
generate sort of better samples and we

00:35:18.810 --> 00:35:18.820
generate sort of better samples and we
 

00:35:18.820 --> 00:35:20.490
generate sort of better samples and we
see with comparable Gans which there

00:35:20.490 --> 00:35:20.500
see with comparable Gans which there
 

00:35:20.500 --> 00:35:21.840
see with comparable Gans which there
might be some regularization effect I'm

00:35:21.840 --> 00:35:21.850
might be some regularization effect I'm
 

00:35:21.850 --> 00:35:23.190
might be some regularization effect I'm
not entirely sure why that would be but

00:35:23.190 --> 00:35:23.200
not entirely sure why that would be but
 

00:35:23.200 --> 00:35:25.230
not entirely sure why that would be but
actually gets fairly compelling samples

00:35:25.230 --> 00:35:25.240
actually gets fairly compelling samples
 

00:35:25.240 --> 00:35:27.480
actually gets fairly compelling samples
this is just with a cell of a a large

00:35:27.480 --> 00:35:27.490
this is just with a cell of a a large
 

00:35:27.490 --> 00:35:31.410
this is just with a cell of a a large
data set of celebrity images but this is

00:35:31.410 --> 00:35:31.420
data set of celebrity images but this is
 

00:35:31.420 --> 00:35:33.120
data set of celebrity images but this is
the more interesting plot so so this is

00:35:33.120 --> 00:35:33.130
the more interesting plot so so this is
 

00:35:33.130 --> 00:35:34.770
the more interesting plot so so this is
actually corresponds to a hierarchical

00:35:34.770 --> 00:35:34.780
actually corresponds to a hierarchical
 

00:35:34.780 --> 00:35:36.540
actually corresponds to a hierarchical
version of this model so this is why we

00:35:36.540 --> 00:35:36.550
version of this model so this is why we
 

00:35:36.550 --> 00:35:37.270
version of this model so this is why we
have mult

00:35:37.270 --> 00:35:37.280
have mult
 

00:35:37.280 --> 00:35:39.580
have mult
so this is said one and said two this is

00:35:39.580 --> 00:35:39.590
so this is said one and said two this is
 

00:35:39.590 --> 00:35:42.070
so this is said one and said two this is
a two layer model in version of this

00:35:42.070 --> 00:35:42.080
a two layer model in version of this
 

00:35:42.080 --> 00:35:44.170
a two layer model in version of this
model so if we just reconstruct from the

00:35:44.170 --> 00:35:44.180
model so if we just reconstruct from the
 

00:35:44.180 --> 00:35:46.960
model so if we just reconstruct from the
higher level Z which is this you know

00:35:46.960 --> 00:35:46.970
higher level Z which is this you know
 

00:35:46.970 --> 00:35:48.730
higher level Z which is this you know
containing fairly little information

00:35:48.730 --> 00:35:48.740
containing fairly little information
 

00:35:48.740 --> 00:35:51.250
containing fairly little information
because is this you it's a single vector

00:35:51.250 --> 00:35:51.260
because is this you it's a single vector
 

00:35:51.260 --> 00:35:52.990
because is this you it's a single vector
and then it has to synthesize into this

00:35:52.990 --> 00:35:53.000
and then it has to synthesize into this
 

00:35:53.000 --> 00:35:55.960
and then it has to synthesize into this
a large image what we're looking at here

00:35:55.960 --> 00:35:55.970
a large image what we're looking at here
 

00:35:55.970 --> 00:35:57.820
a large image what we're looking at here
a reconstruction so we take this image

00:35:57.820 --> 00:35:57.830
a reconstruction so we take this image
 

00:35:57.830 --> 00:36:00.670
a reconstruction so we take this image
we encode it to all the way to Z 2 and

00:36:00.670 --> 00:36:00.680
we encode it to all the way to Z 2 and
 

00:36:00.680 --> 00:36:02.200
we encode it to all the way to Z 2 and
then we decode it and what we end up

00:36:02.200 --> 00:36:02.210
then we decode it and what we end up
 

00:36:02.210 --> 00:36:04.470
then we decode it and what we end up
with is is this which is you know

00:36:04.470 --> 00:36:04.480
with is is this which is you know
 

00:36:04.480 --> 00:36:06.760
with is is this which is you know
reasonably close but not that great

00:36:06.760 --> 00:36:06.770
reasonably close but not that great
 

00:36:06.770 --> 00:36:08.920
reasonably close but not that great
right and so it's the same thing you

00:36:08.920 --> 00:36:08.930
right and so it's the same thing you
 

00:36:08.930 --> 00:36:10.540
right and so it's the same thing you
know kind of all they they sort of hold

00:36:10.540 --> 00:36:10.550
know kind of all they they sort of hold
 

00:36:10.550 --> 00:36:12.970
know kind of all they they sort of hold
some piece of the information which in

00:36:12.970 --> 00:36:12.980
some piece of the information which in
 

00:36:12.980 --> 00:36:14.740
some piece of the information which in
some sense this is kind of it it's

00:36:14.740 --> 00:36:14.750
some sense this is kind of it it's
 

00:36:14.750 --> 00:36:16.360
some sense this is kind of it it's
remarkable that does as well as it does

00:36:16.360 --> 00:36:16.370
remarkable that does as well as it does
 

00:36:16.370 --> 00:36:18.280
remarkable that does as well as it does
because it's actually not trained to do

00:36:18.280 --> 00:36:18.290
because it's actually not trained to do
 

00:36:18.290 --> 00:36:20.680
because it's actually not trained to do
reconstruction unlike something like the

00:36:20.680 --> 00:36:20.690
reconstruction unlike something like the
 

00:36:20.690 --> 00:36:22.060
reconstruction unlike something like the
via II it's actually explicitly trained

00:36:22.060 --> 00:36:22.070
via II it's actually explicitly trained
 

00:36:22.070 --> 00:36:23.260
via II it's actually explicitly trained
to do reconstruction this is just

00:36:23.260 --> 00:36:23.270
to do reconstruction this is just
 

00:36:23.270 --> 00:36:25.090
to do reconstruction this is just
trained to match these two distributions

00:36:25.090 --> 00:36:25.100
trained to match these two distributions
 

00:36:25.100 --> 00:36:26.830
trained to match these two distributions
and this is kind of a probe to see how

00:36:26.830 --> 00:36:26.840
and this is kind of a probe to see how
 

00:36:26.840 --> 00:36:28.750
and this is kind of a probe to see how
well it's doing because we take X from

00:36:28.750 --> 00:36:28.760
well it's doing because we take X from
 

00:36:28.760 --> 00:36:30.970
well it's doing because we take X from
one map it to Zed and we take that set

00:36:30.970 --> 00:36:30.980
one map it to Zed and we take that set
 

00:36:30.980 --> 00:36:33.430
one map it to Zed and we take that set
over and when we resynthesize the X and

00:36:33.430 --> 00:36:33.440
over and when we resynthesize the X and
 

00:36:33.440 --> 00:36:35.230
over and when we resynthesize the X and
we see we're seeing now an X space how

00:36:35.230 --> 00:36:35.240
we see we're seeing now an X space how
 

00:36:35.240 --> 00:36:37.390
we see we're seeing now an X space how
close did it come and you know it does

00:36:37.390 --> 00:36:37.400
close did it come and you know it does
 

00:36:37.400 --> 00:36:40.270
close did it come and you know it does
okay but over here when we give it x1 as

00:36:40.270 --> 00:36:40.280
okay but over here when we give it x1 as
 

00:36:40.280 --> 00:36:43.720
okay but over here when we give it x1 as
z1 and z2 so in this case we're really

00:36:43.720 --> 00:36:43.730
z1 and z2 so in this case we're really
 

00:36:43.730 --> 00:36:45.460
z1 and z2 so in this case we're really
just giving it all of the latent

00:36:45.460 --> 00:36:45.470
just giving it all of the latent
 

00:36:45.470 --> 00:36:47.080
just giving it all of the latent
variable information we actually get

00:36:47.080 --> 00:36:47.090
variable information we actually get
 

00:36:47.090 --> 00:36:49.000
variable information we actually get
much much closer which is interesting is

00:36:49.000 --> 00:36:49.010
much much closer which is interesting is
 

00:36:49.010 --> 00:36:50.980
much much closer which is interesting is
this is telling us that this pure joint

00:36:50.980 --> 00:36:50.990
this is telling us that this pure joint
 

00:36:50.990 --> 00:36:52.390
this is telling us that this pure joint
modelling in this case it would be a

00:36:52.390 --> 00:36:52.400
modelling in this case it would be a
 

00:36:52.400 --> 00:36:55.500
modelling in this case it would be a
joint modelling between X Z 1 and Z 2

00:36:55.500 --> 00:36:55.510
joint modelling between X Z 1 and Z 2
 

00:36:55.510 --> 00:36:58.600
joint modelling between X Z 1 and Z 2
that this is enough to do fairly good

00:36:58.600 --> 00:36:58.610
that this is enough to do fairly good
 

00:36:58.610 --> 00:37:00.550
that this is enough to do fairly good
reconstruction without ever actually

00:37:00.550 --> 00:37:00.560
reconstruction without ever actually
 

00:37:00.560 --> 00:37:02.500
reconstruction without ever actually
explicitly building that in so it's

00:37:02.500 --> 00:37:02.510
explicitly building that in so it's
 

00:37:02.510 --> 00:37:04.060
explicitly building that in so it's
giving us an interesting probe and - how

00:37:04.060 --> 00:37:04.070
giving us an interesting probe and - how
 

00:37:04.070 --> 00:37:05.440
giving us an interesting probe and - how
close are we coming to learning this

00:37:05.440 --> 00:37:05.450
close are we coming to learning this
 

00:37:05.450 --> 00:37:07.480
close are we coming to learning this
joint distribution and it seems like

00:37:07.480 --> 00:37:07.490
joint distribution and it seems like
 

00:37:07.490 --> 00:37:08.920
joint distribution and it seems like
we're getting actually surprisingly

00:37:08.920 --> 00:37:08.930
we're getting actually surprisingly
 

00:37:08.930 --> 00:37:11.890
we're getting actually surprisingly
close so it's a testament to how

00:37:11.890 --> 00:37:11.900
close so it's a testament to how
 

00:37:11.900 --> 00:37:14.440
close so it's a testament to how
effective I think this generative

00:37:14.440 --> 00:37:14.450
effective I think this generative
 

00:37:14.450 --> 00:37:16.780
effective I think this generative
adversarial training exam room actually

00:37:16.780 --> 00:37:16.790
adversarial training exam room actually
 

00:37:16.790 --> 00:37:20.650
adversarial training exam room actually
is so I want to just end with a few

00:37:20.650 --> 00:37:20.660
is so I want to just end with a few
 

00:37:20.660 --> 00:37:21.880
is so I want to just end with a few
other things that have nothing to do

00:37:21.880 --> 00:37:21.890
other things that have nothing to do
 

00:37:21.890 --> 00:37:23.320
other things that have nothing to do
with our work but I think are very very

00:37:23.320 --> 00:37:23.330
with our work but I think are very very
 

00:37:23.330 --> 00:37:25.120
with our work but I think are very very
interesting and well worth you guys

00:37:25.120 --> 00:37:25.130
interesting and well worth you guys
 

00:37:25.130 --> 00:37:27.220
interesting and well worth you guys
learning about so first one is cycle

00:37:27.220 --> 00:37:27.230
learning about so first one is cycle
 

00:37:27.230 --> 00:37:27.640
learning about so first one is cycle
Gann

00:37:27.640 --> 00:37:27.650
Gann
 

00:37:27.650 --> 00:37:30.340
Gann
cycle Gann is this really cool idea

00:37:30.340 --> 00:37:30.350
cycle Gann is this really cool idea
 

00:37:30.350 --> 00:37:32.560
cycle Gann is this really cool idea
starting with it looks imagine you have

00:37:32.560 --> 00:37:32.570
starting with it looks imagine you have
 

00:37:32.570 --> 00:37:33.970
starting with it looks imagine you have
two sets of data sets that somehow

00:37:33.970 --> 00:37:33.980
two sets of data sets that somehow
 

00:37:33.980 --> 00:37:36.400
two sets of data sets that somehow
correspond but you don't know the

00:37:36.400 --> 00:37:36.410
correspond but you don't know the
 

00:37:36.410 --> 00:37:37.930
correspond but you don't know the
correspondence you don't have like

00:37:37.930 --> 00:37:37.940
correspondence you don't have like
 

00:37:37.940 --> 00:37:39.550
correspondence you don't have like
there's an alignment that exists between

00:37:39.550 --> 00:37:39.560
there's an alignment that exists between
 

00:37:39.560 --> 00:37:41.020
there's an alignment that exists between
these two data sets but you might not

00:37:41.020 --> 00:37:41.030
these two data sets but you might not
 

00:37:41.030 --> 00:37:42.490
these two data sets but you might not
know what you know might not have paired

00:37:42.490 --> 00:37:42.500
know what you know might not have paired
 

00:37:42.500 --> 00:37:44.920
know what you know might not have paired
data this actually happens a lot say for

00:37:44.920 --> 00:37:44.930
data this actually happens a lot say for
 

00:37:44.930 --> 00:37:47.350
data this actually happens a lot say for
example this is not an image space but a

00:37:47.350 --> 00:37:47.360
example this is not an image space but a
 

00:37:47.360 --> 00:37:49.810
example this is not an image space but a
great example of this happens in machine

00:37:49.810 --> 00:37:49.820
great example of this happens in machine
 

00:37:49.820 --> 00:37:50.920
great example of this happens in machine
translation right

00:37:50.920 --> 00:37:50.930
translation right
 

00:37:50.930 --> 00:37:52.660
translation right
you almost always have lots of

00:37:52.660 --> 00:37:52.670
you almost always have lots of
 

00:37:52.670 --> 00:37:56.049
you almost always have lots of
unilingual data so just text data in us

00:37:56.049 --> 00:37:56.059
unilingual data so just text data in us
 

00:37:56.059 --> 00:37:57.849
unilingual data so just text data in us
in a given language but it's very

00:37:57.849 --> 00:37:57.859
in a given language but it's very
 

00:37:57.859 --> 00:38:00.490
in a given language but it's very
expensive to get a line data but but to

00:38:00.490 --> 00:38:00.500
expensive to get a line data but but to
 

00:38:00.500 --> 00:38:02.740
expensive to get a line data but but to
get a paired as a source and target

00:38:02.740 --> 00:38:02.750
get a paired as a source and target
 

00:38:02.750 --> 00:38:05.319
get a paired as a source and target
distribution the question is what can

00:38:05.319 --> 00:38:05.329
distribution the question is what can
 

00:38:05.329 --> 00:38:06.910
distribution the question is what can
you do if you just have you and lingual

00:38:06.910 --> 00:38:06.920
you do if you just have you and lingual
 

00:38:06.920 --> 00:38:08.859
you do if you just have you and lingual
data how successful can you be at

00:38:08.859 --> 00:38:08.869
data how successful can you be at
 

00:38:08.869 --> 00:38:10.960
data how successful can you be at
learning a mapping between the two and

00:38:10.960 --> 00:38:10.970
learning a mapping between the two and
 

00:38:10.970 --> 00:38:13.540
learning a mapping between the two and
they essentially use ganz to do this so

00:38:13.540 --> 00:38:13.550
they essentially use ganz to do this so
 

00:38:13.550 --> 00:38:15.549
they essentially use ganz to do this so
this is the setup they have some domain

00:38:15.549 --> 00:38:15.559
this is the setup they have some domain
 

00:38:15.559 --> 00:38:18.970
this is the setup they have some domain
X here and our domain Y here and what

00:38:18.970 --> 00:38:18.980
X here and our domain Y here and what
 

00:38:18.980 --> 00:38:20.530
X here and our domain Y here and what
they do is they start with an X they

00:38:20.530 --> 00:38:20.540
they do is they start with an X they
 

00:38:20.540 --> 00:38:22.450
they do is they start with an X they
transform it through some convolutional

00:38:22.450 --> 00:38:22.460
transform it through some convolutional
 

00:38:22.460 --> 00:38:23.920
transform it through some convolutional
neural net usually a resonant based

00:38:23.920 --> 00:38:23.930
neural net usually a resonant based
 

00:38:23.930 --> 00:38:26.740
neural net usually a resonant based
model into some Y and on this Y they're

00:38:26.740 --> 00:38:26.750
model into some Y and on this Y they're
 

00:38:26.750 --> 00:38:29.230
model into some Y and on this Y they're
going to evaluate it as a just as a as a

00:38:29.230 --> 00:38:29.240
going to evaluate it as a just as a as a
 

00:38:29.240 --> 00:38:32.849
going to evaluate it as a just as a as a
gang-style discriminator here so can X

00:38:32.849 --> 00:38:32.859
gang-style discriminator here so can X
 

00:38:32.859 --> 00:38:36.730
gang-style discriminator here so can X
through G make a convincing Y that's

00:38:36.730 --> 00:38:36.740
through G make a convincing Y that's
 

00:38:36.740 --> 00:38:38.920
through G make a convincing Y that's
being met what's being measured here so

00:38:38.920 --> 00:38:38.930
being met what's being measured here so
 

00:38:38.930 --> 00:38:40.780
being met what's being measured here so
you can think of X is taking the place

00:38:40.780 --> 00:38:40.790
you can think of X is taking the place
 

00:38:40.790 --> 00:38:42.790
you can think of X is taking the place
which is you know some other image let's

00:38:42.790 --> 00:38:42.800
which is you know some other image let's
 

00:38:42.800 --> 00:38:44.470
which is you know some other image let's
say this is some image to another image

00:38:44.470 --> 00:38:44.480
say this is some image to another image
 

00:38:44.480 --> 00:38:46.540
say this is some image to another image
this image X is taking the place of our

00:38:46.540 --> 00:38:46.550
this image X is taking the place of our
 

00:38:46.550 --> 00:38:49.329
this image X is taking the place of our
of our Z of our random bits it's getting

00:38:49.329 --> 00:38:49.339
of our Z of our random bits it's getting
 

00:38:49.339 --> 00:38:52.809
of our Z of our random bits it's getting
its randomness from X and then we do the

00:38:52.809 --> 00:38:52.819
its randomness from X and then we do the
 

00:38:52.819 --> 00:38:55.329
its randomness from X and then we do the
same thing we can kind of transform it

00:38:55.329 --> 00:38:55.339
same thing we can kind of transform it
 

00:38:55.339 --> 00:38:57.880
same thing we can kind of transform it
through F so we've got X here transform

00:38:57.880 --> 00:38:57.890
through F so we've got X here transform
 

00:38:57.890 --> 00:39:01.120
through F so we've got X here transform
it through G to D and we evaluate on on

00:39:01.120 --> 00:39:01.130
it through G to D and we evaluate on on
 

00:39:01.130 --> 00:39:03.309
it through G to D and we evaluate on on
the discriminator here on AG and style

00:39:03.309 --> 00:39:03.319
the discriminator here on AG and style
 

00:39:03.319 --> 00:39:05.500
the discriminator here on AG and style
training and then we re encode this in X

00:39:05.500 --> 00:39:05.510
training and then we re encode this in X
 

00:39:05.510 --> 00:39:08.890
training and then we re encode this in X
now once we get here that's over here so

00:39:08.890 --> 00:39:08.900
now once we get here that's over here so
 

00:39:08.900 --> 00:39:10.569
now once we get here that's over here so
we've taken X transformed it into Y

00:39:10.569 --> 00:39:10.579
we've taken X transformed it into Y
 

00:39:10.579 --> 00:39:12.579
we've taken X transformed it into Y
transform it back they actually do

00:39:12.579 --> 00:39:12.589
transform it back they actually do
 

00:39:12.589 --> 00:39:14.079
transform it back they actually do
what's called the cycle consistency loss

00:39:14.079 --> 00:39:14.089
what's called the cycle consistency loss
 

00:39:14.089 --> 00:39:15.250
what's called the cycle consistency loss
which is this is actually a

00:39:15.250 --> 00:39:15.260
which is this is actually a
 

00:39:15.260 --> 00:39:16.660
which is this is actually a
reconstruction this is an l1

00:39:16.660 --> 00:39:16.670
reconstruction this is an l1
 

00:39:16.670 --> 00:39:18.789
reconstruction this is an l1
reconstruction error and they back prop

00:39:18.789 --> 00:39:18.799
reconstruction error and they back prop
 

00:39:18.799 --> 00:39:21.700
reconstruction error and they back prop
through F and G and then they it's a

00:39:21.700 --> 00:39:21.710
through F and G and then they it's a
 

00:39:21.710 --> 00:39:23.049
through F and G and then they it's a
symmetric relationship so they do the

00:39:23.049 --> 00:39:23.059
symmetric relationship so they do the
 

00:39:23.059 --> 00:39:24.760
symmetric relationship so they do the
exact same thing on the other side they

00:39:24.760 --> 00:39:24.770
exact same thing on the other side they
 

00:39:24.770 --> 00:39:26.380
exact same thing on the other side they
start with y they see if they can

00:39:26.380 --> 00:39:26.390
start with y they see if they can
 

00:39:26.390 --> 00:39:28.150
start with y they see if they can
transform it into X they compare the

00:39:28.150 --> 00:39:28.160
transform it into X they compare the
 

00:39:28.160 --> 00:39:30.700
transform it into X they compare the
they compare that that that generated X

00:39:30.700 --> 00:39:30.710
they compare that that that generated X
 

00:39:30.710 --> 00:39:33.400
they compare that that that generated X
with true X's via a discriminator and

00:39:33.400 --> 00:39:33.410
with true X's via a discriminator and
 

00:39:33.410 --> 00:39:35.410
with true X's via a discriminator and
then again transform that to Y and do

00:39:35.410 --> 00:39:35.420
then again transform that to Y and do
 

00:39:35.420 --> 00:39:38.589
then again transform that to Y and do
the cycle consistency loss so without

00:39:38.589 --> 00:39:38.599
the cycle consistency loss so without
 

00:39:38.599 --> 00:39:41.049
the cycle consistency loss so without
any pair data this is the kind of thing

00:39:41.049 --> 00:39:41.059
any pair data this is the kind of thing
 

00:39:41.059 --> 00:39:45.190
any pair data this is the kind of thing
that they can get so a particular note

00:39:45.190 --> 00:39:45.200
that they can get so a particular note
 

00:39:45.200 --> 00:39:47.530
that they can get so a particular note
is horses and zebras right so and this

00:39:47.530 --> 00:39:47.540
is horses and zebras right so and this
 

00:39:47.540 --> 00:39:49.630
is horses and zebras right so and this
is a case where you know it's it's

00:39:49.630 --> 00:39:49.640
is a case where you know it's it's
 

00:39:49.640 --> 00:39:51.490
is a case where you know it's it's
impossible to get this kind of pair data

00:39:51.490 --> 00:39:51.500
impossible to get this kind of pair data
 

00:39:51.500 --> 00:39:53.829
impossible to get this kind of pair data
say you wanted a transformation that

00:39:53.829 --> 00:39:53.839
say you wanted a transformation that
 

00:39:53.839 --> 00:39:55.660
say you wanted a transformation that
transformed horses to zebras and vice

00:39:55.660 --> 00:39:55.670
transformed horses to zebras and vice
 

00:39:55.670 --> 00:39:59.140
transformed horses to zebras and vice
versa you will never find pictures of

00:39:59.140 --> 00:39:59.150
versa you will never find pictures of
 

00:39:59.150 --> 00:40:02.049
versa you will never find pictures of
horses and zebras in the exact same pose

00:40:02.049 --> 00:40:02.059
horses and zebras in the exact same pose
 

00:40:02.059 --> 00:40:03.730
horses and zebras in the exact same pose
right that's just not a kind of data set

00:40:03.730 --> 00:40:03.740
right that's just not a kind of data set
 

00:40:03.740 --> 00:40:04.200
right that's just not a kind of data set
your

00:40:04.200 --> 00:40:04.210
your
 

00:40:04.210 --> 00:40:05.849
your
be able to collect and yet they do a

00:40:05.849 --> 00:40:05.859
be able to collect and yet they do a
 

00:40:05.859 --> 00:40:08.310
be able to collect and yet they do a
fairly convincing job of doing this so

00:40:08.310 --> 00:40:08.320
fairly convincing job of doing this so
 

00:40:08.320 --> 00:40:10.050
fairly convincing job of doing this so
you can see that they even turn like

00:40:10.050 --> 00:40:10.060
you can see that they even turn like
 

00:40:10.060 --> 00:40:11.849
you can see that they even turn like
there's a little bit this one actually

00:40:11.849 --> 00:40:11.859
there's a little bit this one actually
 

00:40:11.859 --> 00:40:13.650
there's a little bit this one actually
doesn't do it very well but oftentimes

00:40:13.650 --> 00:40:13.660
doesn't do it very well but oftentimes
 

00:40:13.660 --> 00:40:14.970
doesn't do it very well but oftentimes
what you see is they turn like green

00:40:14.970 --> 00:40:14.980
what you see is they turn like green
 

00:40:14.980 --> 00:40:17.099
what you see is they turn like green
grass a little bit more savanna like

00:40:17.099 --> 00:40:17.109
grass a little bit more savanna like
 

00:40:17.109 --> 00:40:20.130
grass a little bit more savanna like
that kind of dulls it out because zebras

00:40:20.130 --> 00:40:20.140
that kind of dulls it out because zebras
 

00:40:20.140 --> 00:40:21.930
that kind of dulls it out because zebras
are found generally in Savannah like

00:40:21.930 --> 00:40:21.940
are found generally in Savannah like
 

00:40:21.940 --> 00:40:25.260
are found generally in Savannah like
conditions they can do winter to summer

00:40:25.260 --> 00:40:25.270
conditions they can do winter to summer
 

00:40:25.270 --> 00:40:27.390
conditions they can do winter to summer
kind of transitions I've seen examples

00:40:27.390 --> 00:40:27.400
kind of transitions I've seen examples
 

00:40:27.400 --> 00:40:30.329
kind of transitions I've seen examples
day-to-night these are pretty

00:40:30.329 --> 00:40:30.339
day-to-night these are pretty
 

00:40:30.339 --> 00:40:32.760
day-to-night these are pretty
interesting very us other things no I

00:40:32.760 --> 00:40:32.770
interesting very us other things no I
 

00:40:32.770 --> 00:40:35.040
interesting very us other things no I
think this there's a lot of interesting

00:40:35.040 --> 00:40:35.050
think this there's a lot of interesting
 

00:40:35.050 --> 00:40:36.510
think this there's a lot of interesting
things you can do with this data set and

00:40:36.510 --> 00:40:36.520
things you can do with this data set and
 

00:40:36.520 --> 00:40:38.190
things you can do with this data set and
and going back to if you think about

00:40:38.190 --> 00:40:38.200
and going back to if you think about
 

00:40:38.200 --> 00:40:39.810
and going back to if you think about
that simulation example with real

00:40:39.810 --> 00:40:39.820
that simulation example with real
 

00:40:39.820 --> 00:40:41.520
that simulation example with real
robotics that I gave the motivating

00:40:41.520 --> 00:40:41.530
robotics that I gave the motivating
 

00:40:41.530 --> 00:40:43.620
robotics that I gave the motivating
example at the beginning this is a prime

00:40:43.620 --> 00:40:43.630
example at the beginning this is a prime
 

00:40:43.630 --> 00:40:45.300
example at the beginning this is a prime
application area for this kind of

00:40:45.300 --> 00:40:45.310
application area for this kind of
 

00:40:45.310 --> 00:40:47.040
application area for this kind of
technology but I will say that one of

00:40:47.040 --> 00:40:47.050
technology but I will say that one of
 

00:40:47.050 --> 00:40:48.599
technology but I will say that one of
the things that they've done here is

00:40:48.599 --> 00:40:48.609
the things that they've done here is
 

00:40:48.609 --> 00:40:50.130
the things that they've done here is
they assume a deterministic

00:40:50.130 --> 00:40:50.140
they assume a deterministic
 

00:40:50.140 --> 00:40:51.480
they assume a deterministic
transformation between these two domains

00:40:51.480 --> 00:40:51.490
transformation between these two domains
 

00:40:51.490 --> 00:40:53.339
transformation between these two domains
so I think there's a lot of interest

00:40:53.339 --> 00:40:53.349
so I think there's a lot of interest
 

00:40:53.349 --> 00:40:55.560
so I think there's a lot of interest
looking at how do you actually break

00:40:55.560 --> 00:40:55.570
looking at how do you actually break
 

00:40:55.570 --> 00:40:57.570
looking at how do you actually break
that kind of restriction and imagine

00:40:57.570 --> 00:40:57.580
that kind of restriction and imagine
 

00:40:57.580 --> 00:40:58.890
that kind of restriction and imagine
something more like an many-to-many

00:40:58.890 --> 00:40:58.900
something more like an many-to-many
 

00:40:58.900 --> 00:41:02.070
something more like an many-to-many
mapping between these two domains so the

00:41:02.070 --> 00:41:02.080
mapping between these two domains so the
 

00:41:02.080 --> 00:41:03.210
mapping between these two domains so the
last thing I want to show you is kind of

00:41:03.210 --> 00:41:03.220
last thing I want to show you is kind of
 

00:41:03.220 --> 00:41:04.740
last thing I want to show you is kind of
the most recent stuff which is just kind

00:41:04.740 --> 00:41:04.750
the most recent stuff which is just kind
 

00:41:04.750 --> 00:41:06.000
the most recent stuff which is just kind
of mind-blowing in terms of just the

00:41:06.000 --> 00:41:06.010
of mind-blowing in terms of just the
 

00:41:06.010 --> 00:41:08.070
of mind-blowing in terms of just the
quality of generation that they they

00:41:08.070 --> 00:41:08.080
quality of generation that they they
 

00:41:08.080 --> 00:41:11.040
quality of generation that they they
show so these are images from Nvidia

00:41:11.040 --> 00:41:11.050
show so these are images from Nvidia
 

00:41:11.050 --> 00:41:13.770
show so these are images from Nvidia
actually so I don't know if I'm I'm I'm

00:41:13.770 --> 00:41:13.780
actually so I don't know if I'm I'm I'm
 

00:41:13.780 --> 00:41:15.839
actually so I don't know if I'm I'm I'm
sort of undercutting you I don't know if

00:41:15.839 --> 00:41:15.849
sort of undercutting you I don't know if
 

00:41:15.849 --> 00:41:16.950
sort of undercutting you I don't know if
he was going to show these or not but

00:41:16.950 --> 00:41:16.960
he was going to show these or not but
 

00:41:16.960 --> 00:41:24.530
he was going to show these or not but
yeah so these trained on on the original

00:41:24.530 --> 00:41:24.540
yeah so these trained on on the original
 

00:41:24.540 --> 00:41:26.820
yeah so these trained on on the original
celibate data set the same one we had

00:41:26.820 --> 00:41:26.830
celibate data set the same one we had
 

00:41:26.830 --> 00:41:29.130
celibate data set the same one we had
before but now much much larger images

00:41:29.130 --> 00:41:29.140
before but now much much larger images
 

00:41:29.140 --> 00:41:31.800
before but now much much larger images
right so a thousand 24 by a thousand 24

00:41:31.800 --> 00:41:31.810
right so a thousand 24 by a thousand 24
 

00:41:31.810 --> 00:41:34.760
right so a thousand 24 by a thousand 24
and they're able to get these kinds of

00:41:34.760 --> 00:41:34.770
and they're able to get these kinds of
 

00:41:34.770 --> 00:41:37.470
and they're able to get these kinds of
generated models so I would argue that

00:41:37.470 --> 00:41:37.480
generated models so I would argue that
 

00:41:37.480 --> 00:41:39.540
generated models so I would argue that
many of these may be all of the ones

00:41:39.540 --> 00:41:39.550
many of these may be all of the ones
 

00:41:39.550 --> 00:41:42.710
many of these may be all of the ones
shown here essentially pass a kind of a

00:41:42.710 --> 00:41:42.720
shown here essentially pass a kind of a
 

00:41:42.720 --> 00:41:44.970
shown here essentially pass a kind of a
Turing test right an image during test

00:41:44.970 --> 00:41:44.980
Turing test right an image during test
 

00:41:44.980 --> 00:41:46.260
Turing test right an image during test
you cannot tell that these are not real

00:41:46.260 --> 00:41:46.270
you cannot tell that these are not real
 

00:41:46.270 --> 00:41:48.540
you cannot tell that these are not real
people right now I should say not all

00:41:48.540 --> 00:41:48.550
people right now I should say not all
 

00:41:48.550 --> 00:41:51.300
people right now I should say not all
images actually look this good some of

00:41:51.300 --> 00:41:51.310
images actually look this good some of
 

00:41:51.310 --> 00:41:53.640
images actually look this good some of
them are actually really spooky but you

00:41:53.640 --> 00:41:53.650
them are actually really spooky but you
 

00:41:53.650 --> 00:41:55.440
them are actually really spooky but you
can go online and look at the video and

00:41:55.440 --> 00:41:55.450
can go online and look at the video and
 

00:41:55.450 --> 00:41:59.400
can go online and look at the video and
pick some out there yeah how they do

00:41:59.400 --> 00:41:59.410
pick some out there yeah how they do
 

00:41:59.410 --> 00:42:01.650
pick some out there yeah how they do
this is with a really interesting

00:42:01.650 --> 00:42:01.660
this is with a really interesting
 

00:42:01.660 --> 00:42:03.750
this is with a really interesting
technique and this is actually so new we

00:42:03.750 --> 00:42:03.760
technique and this is actually so new we
 

00:42:03.760 --> 00:42:05.550
technique and this is actually so new we
have students that are starting to look

00:42:05.550 --> 00:42:05.560
have students that are starting to look
 

00:42:05.560 --> 00:42:07.950
have students that are starting to look
at this but we haven't really probed

00:42:07.950 --> 00:42:07.960
at this but we haven't really probed
 

00:42:07.960 --> 00:42:09.560
at this but we haven't really probed
this very far so I actually don't know

00:42:09.560 --> 00:42:09.570
this very far so I actually don't know
 

00:42:09.570 --> 00:42:12.570
this very far so I actually don't know
how effective this is in general but

00:42:12.570 --> 00:42:12.580
how effective this is in general but
 

00:42:12.580 --> 00:42:14.010
how effective this is in general but
it's actually seems very interesting so

00:42:14.010 --> 00:42:14.020
it's actually seems very interesting so
 

00:42:14.020 --> 00:42:18.030
it's actually seems very interesting so
they just start with a tiny 4 by 4 image

00:42:18.030 --> 00:42:18.040
they just start with a tiny 4 by 4 image
 

00:42:18.040 --> 00:42:20.340
they just start with a tiny 4 by 4 image
and once you train up that parameters

00:42:20.340 --> 00:42:20.350
and once you train up that parameters
 

00:42:20.350 --> 00:42:22.170
and once you train up that parameters
parameters for both the discriminator

00:42:22.170 --> 00:42:22.180
parameters for both the discriminator
 

00:42:22.180 --> 00:42:24.120
parameters for both the discriminator
here and the generator so again these

00:42:24.120 --> 00:42:24.130
here and the generator so again these
 

00:42:24.130 --> 00:42:25.860
here and the generator so again these
are convolutions but we're starting with

00:42:25.860 --> 00:42:25.870
are convolutions but we're starting with
 

00:42:25.870 --> 00:42:28.740
are convolutions but we're starting with
with a relatively small input we

00:42:28.740 --> 00:42:28.750
with a relatively small input we
 

00:42:28.750 --> 00:42:30.360
with a relatively small input we
increase the size of the input we add a

00:42:30.360 --> 00:42:30.370
increase the size of the input we add a
 

00:42:30.370 --> 00:42:33.090
increase the size of the input we add a
layer and and and the some of these

00:42:33.090 --> 00:42:33.100
layer and and and the some of these
 

00:42:33.100 --> 00:42:35.010
layer and and and the some of these
parameters here are actually formed by

00:42:35.010 --> 00:42:35.020
parameters here are actually formed by
 

00:42:35.020 --> 00:42:36.480
parameters here are actually formed by
the parameters that gave you this image

00:42:36.480 --> 00:42:36.490
the parameters that gave you this image
 

00:42:36.490 --> 00:42:38.340
the parameters that gave you this image
so you sort of just stick this up here

00:42:38.340 --> 00:42:38.350
so you sort of just stick this up here
 

00:42:38.350 --> 00:42:39.990
so you sort of just stick this up here
and now you add some parameters and

00:42:39.990 --> 00:42:40.000
and now you add some parameters and
 

00:42:40.000 --> 00:42:41.730
and now you add some parameters and
you'd now train the model to learn

00:42:41.730 --> 00:42:41.740
you'd now train the model to learn
 

00:42:41.740 --> 00:42:43.620
you'd now train the model to learn
something bigger and you keep going and

00:42:43.620 --> 00:42:43.630
something bigger and you keep going and
 

00:42:43.630 --> 00:42:45.000
something bigger and you keep going and
you keep going and then you get

00:42:45.000 --> 00:42:45.010
you keep going and then you get
 

00:42:45.010 --> 00:42:46.920
you keep going and then you get
something like this as far as I'm

00:42:46.920 --> 00:42:46.930
something like this as far as I'm
 

00:42:46.930 --> 00:42:48.990
something like this as far as I'm
concerned this is sort of this amounts

00:42:48.990 --> 00:42:49.000
concerned this is sort of this amounts
 

00:42:49.000 --> 00:42:50.520
concerned this is sort of this amounts
to kind of a curriculum of training does

00:42:50.520 --> 00:42:50.530
to kind of a curriculum of training does
 

00:42:50.530 --> 00:42:53.130
to kind of a curriculum of training does
two things for you one is it helps build

00:42:53.130 --> 00:42:53.140
two things for you one is it helps build
 

00:42:53.140 --> 00:42:55.080
two things for you one is it helps build
a bit of global structure to the image

00:42:55.080 --> 00:42:55.090
a bit of global structure to the image
 

00:42:55.090 --> 00:42:57.090
a bit of global structure to the image
because you're starting with such low

00:42:57.090 --> 00:42:57.100
because you're starting with such low
 

00:42:57.100 --> 00:43:00.180
because you're starting with such low
dimensional inputs it helps reinforce

00:43:00.180 --> 00:43:00.190
dimensional inputs it helps reinforce
 

00:43:00.190 --> 00:43:02.220
dimensional inputs it helps reinforce
the kind of global structure but it also

00:43:02.220 --> 00:43:02.230
the kind of global structure but it also
 

00:43:02.230 --> 00:43:03.180
the kind of global structure but it also
does something else which is pretty

00:43:03.180 --> 00:43:03.190
does something else which is pretty
 

00:43:03.190 --> 00:43:05.370
does something else which is pretty
important it allows the model to sort of

00:43:05.370 --> 00:43:05.380
important it allows the model to sort of
 

00:43:05.380 --> 00:43:07.920
important it allows the model to sort of
not have to spend a lot of time training

00:43:07.920 --> 00:43:07.930
not have to spend a lot of time training
 

00:43:07.930 --> 00:43:10.200
not have to spend a lot of time training
a very very large model like this right

00:43:10.200 --> 00:43:10.210
a very very large model like this right
 

00:43:10.210 --> 00:43:11.700
a very very large model like this right
you wait I would imagine they spend

00:43:11.700 --> 00:43:11.710
you wait I would imagine they spend
 

00:43:11.710 --> 00:43:13.410
you wait I would imagine they spend
relatively little time training here

00:43:13.410 --> 00:43:13.420
relatively little time training here
 

00:43:13.420 --> 00:43:15.480
relatively little time training here
although this is Nvidia so they might

00:43:15.480 --> 00:43:15.490
although this is Nvidia so they might
 

00:43:15.490 --> 00:43:17.400
although this is Nvidia so they might
spend a lot of time training this but

00:43:17.400 --> 00:43:17.410
spend a lot of time training this but
 

00:43:17.410 --> 00:43:19.590
spend a lot of time training this but
but it allows you to spend a lot of the

00:43:19.590 --> 00:43:19.600
but it allows you to spend a lot of the
 

00:43:19.600 --> 00:43:21.240
but it allows you to spend a lot of the
time sort of in much much smaller models

00:43:21.240 --> 00:43:21.250
time sort of in much much smaller models
 

00:43:21.250 --> 00:43:24.030
time sort of in much much smaller models
so much more computationally efficient

00:43:24.030 --> 00:43:24.040
so much more computationally efficient
 

00:43:24.040 --> 00:43:26.460
so much more computationally efficient
to train this model alright so that's it

00:43:26.460 --> 00:43:26.470
to train this model alright so that's it
 

00:43:26.470 --> 00:43:28.740
to train this model alright so that's it
for me thanks a lot oh wait oh yeah

00:43:28.740 --> 00:43:28.750
for me thanks a lot oh wait oh yeah
 

00:43:28.750 --> 00:43:30.780
for me thanks a lot oh wait oh yeah
sorry one more thing I forgot this is

00:43:30.780 --> 00:43:30.790
sorry one more thing I forgot this is
 

00:43:30.790 --> 00:43:33.090
sorry one more thing I forgot this is
just what they get unconditional image

00:43:33.090 --> 00:43:33.100
just what they get unconditional image
 

00:43:33.100 --> 00:43:35.820
just what they get unconditional image
generation now with m-miss this is again

00:43:35.820 --> 00:43:35.830
generation now with m-miss this is again
 

00:43:35.830 --> 00:43:37.950
generation now with m-miss this is again
so you give it horse and then it's able

00:43:37.950 --> 00:43:37.960
so you give it horse and then it's able
 

00:43:37.960 --> 00:43:39.990
so you give it horse and then it's able
to generate this kind of thing so far

00:43:39.990 --> 00:43:40.000
to generate this kind of thing so far
 

00:43:40.000 --> 00:43:41.460
to generate this kind of thing so far
it's able to generate this right so

00:43:41.460 --> 00:43:41.470
it's able to generate this right so
 

00:43:41.470 --> 00:43:43.170
it's able to generate this right so
bicycles it's able to generate these

00:43:43.170 --> 00:43:43.180
bicycles it's able to generate these
 

00:43:43.180 --> 00:43:47.460
bicycles it's able to generate these
which is pretty amazing quality if you

00:43:47.460 --> 00:43:47.470
which is pretty amazing quality if you
 

00:43:47.470 --> 00:43:49.140
which is pretty amazing quality if you
min here you can actually it's kind of

00:43:49.140 --> 00:43:49.150
min here you can actually it's kind of
 

00:43:49.150 --> 00:43:50.760
min here you can actually it's kind of
fun because that it kind of gets the

00:43:50.760 --> 00:43:50.770
fun because that it kind of gets the
 

00:43:50.770 --> 00:43:54.150
fun because that it kind of gets the
idea of these these spokes but not

00:43:54.150 --> 00:43:54.160
idea of these these spokes but not
 

00:43:54.160 --> 00:43:55.860
idea of these these spokes but not
exactly like some of them just sort of

00:43:55.860 --> 00:43:55.870
exactly like some of them just sort of
 

00:43:55.870 --> 00:43:59.670
exactly like some of them just sort of
end Midway but yeah but still pretty

00:43:59.670 --> 00:43:59.680
end Midway but yeah but still pretty
 

00:43:59.680 --> 00:44:00.770
end Midway but yeah but still pretty
pretty remarkable

00:44:00.770 --> 00:44:00.780
pretty remarkable
 

00:44:00.780 --> 00:44:04.440
pretty remarkable
alright so thanks if they have questions

00:44:04.440 --> 00:44:04.450
alright so thanks if they have questions
 

00:44:04.450 --> 00:44:08.460
alright so thanks if they have questions
[Applause]

