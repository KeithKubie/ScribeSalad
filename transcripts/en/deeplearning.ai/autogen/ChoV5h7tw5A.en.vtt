WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.419
what a deep confidence really learning

00:00:02.419 --> 00:00:02.429
what a deep confidence really learning
 

00:00:02.429 --> 00:00:04.940
what a deep confidence really learning
in this video I want to share view some

00:00:04.940 --> 00:00:04.950
in this video I want to share view some
 

00:00:04.950 --> 00:00:07.280
in this video I want to share view some
visualizations that will help you hone

00:00:07.280 --> 00:00:07.290
visualizations that will help you hone
 

00:00:07.290 --> 00:00:09.230
visualizations that will help you hone
your intuition about what the deeper

00:00:09.230 --> 00:00:09.240
your intuition about what the deeper
 

00:00:09.240 --> 00:00:11.120
your intuition about what the deeper
layers of a confident really are doing

00:00:11.120 --> 00:00:11.130
layers of a confident really are doing
 

00:00:11.130 --> 00:00:13.310
layers of a confident really are doing
and this will help us think through how

00:00:13.310 --> 00:00:13.320
and this will help us think through how
 

00:00:13.320 --> 00:00:15.560
and this will help us think through how
you can implement nearest aisle transfer

00:00:15.560 --> 00:00:15.570
you can implement nearest aisle transfer
 

00:00:15.570 --> 00:00:19.790
you can implement nearest aisle transfer
as well let's start with an example

00:00:19.790 --> 00:00:19.800
as well let's start with an example
 

00:00:19.800 --> 00:00:22.609
as well let's start with an example
let's say you've trained a confident

00:00:22.609 --> 00:00:22.619
let's say you've trained a confident
 

00:00:22.619 --> 00:00:25.700
let's say you've trained a confident
this is an Alex net life network and you

00:00:25.700 --> 00:00:25.710
this is an Alex net life network and you
 

00:00:25.710 --> 00:00:28.040
this is an Alex net life network and you
want to visualize what the hidden units

00:00:28.040 --> 00:00:28.050
want to visualize what the hidden units
 

00:00:28.050 --> 00:00:29.720
want to visualize what the hidden units
and different layers are computing

00:00:29.720 --> 00:00:29.730
and different layers are computing
 

00:00:29.730 --> 00:00:32.990
and different layers are computing
here's what you can do let's starts with

00:00:32.990 --> 00:00:33.000
here's what you can do let's starts with
 

00:00:33.000 --> 00:00:36.530
here's what you can do let's starts with
a hidden unit in layer 1 and suppose you

00:00:36.530 --> 00:00:36.540
a hidden unit in layer 1 and suppose you
 

00:00:36.540 --> 00:00:39.200
a hidden unit in layer 1 and suppose you
scan through your training set and find

00:00:39.200 --> 00:00:39.210
scan through your training set and find
 

00:00:39.210 --> 00:00:41.060
scan through your training set and find
out what are the images or what are the

00:00:41.060 --> 00:00:41.070
out what are the images or what are the
 

00:00:41.070 --> 00:00:44.440
out what are the images or what are the
image patches that maximize that units

00:00:44.440 --> 00:00:44.450
image patches that maximize that units
 

00:00:44.450 --> 00:00:47.270
image patches that maximize that units
activation so in other words passed your

00:00:47.270 --> 00:00:47.280
activation so in other words passed your
 

00:00:47.280 --> 00:00:49.520
activation so in other words passed your
training set through that through your

00:00:49.520 --> 00:00:49.530
training set through that through your
 

00:00:49.530 --> 00:00:51.920
training set through that through your
neural network and figure out what is

00:00:51.920 --> 00:00:51.930
neural network and figure out what is
 

00:00:51.930 --> 00:00:54.770
neural network and figure out what is
the image that maximizes that particular

00:00:54.770 --> 00:00:54.780
the image that maximizes that particular
 

00:00:54.780 --> 00:00:58.520
the image that maximizes that particular
unit activation now notice that a hidden

00:00:58.520 --> 00:00:58.530
unit activation now notice that a hidden
 

00:00:58.530 --> 00:01:00.979
unit activation now notice that a hidden
unit in layer 1 will see only a

00:01:00.979 --> 00:01:00.989
unit in layer 1 will see only a
 

00:01:00.989 --> 00:01:03.830
unit in layer 1 will see only a
relatively small portion of the neural

00:01:03.830 --> 00:01:03.840
relatively small portion of the neural
 

00:01:03.840 --> 00:01:06.350
relatively small portion of the neural
network and so if you visualize if you

00:01:06.350 --> 00:01:06.360
network and so if you visualize if you
 

00:01:06.360 --> 00:01:09.320
network and so if you visualize if you
plot what activators that units

00:01:09.320 --> 00:01:09.330
plot what activators that units
 

00:01:09.330 --> 00:01:12.050
plot what activators that units
activation it makes sense to plot just a

00:01:12.050 --> 00:01:12.060
activation it makes sense to plot just a
 

00:01:12.060 --> 00:01:14.240
activation it makes sense to plot just a
small image match because that's all of

00:01:14.240 --> 00:01:14.250
small image match because that's all of
 

00:01:14.250 --> 00:01:16.490
small image match because that's all of
the image that that particular unit sees

00:01:16.490 --> 00:01:16.500
the image that that particular unit sees
 

00:01:16.500 --> 00:01:19.670
the image that that particular unit sees
so if you pick one hidden unit and find

00:01:19.670 --> 00:01:19.680
so if you pick one hidden unit and find
 

00:01:19.680 --> 00:01:22.600
so if you pick one hidden unit and find
a 9 input images that maximizes that

00:01:22.600 --> 00:01:22.610
a 9 input images that maximizes that
 

00:01:22.610 --> 00:01:26.060
a 9 input images that maximizes that
units activation you might find 9 image

00:01:26.060 --> 00:01:26.070
units activation you might find 9 image
 

00:01:26.070 --> 00:01:28.219
units activation you might find 9 image
matches like this so it looks like that

00:01:28.219 --> 00:01:28.229
matches like this so it looks like that
 

00:01:28.229 --> 00:01:30.620
matches like this so it looks like that
in the lower region of an image that

00:01:30.620 --> 00:01:30.630
in the lower region of an image that
 

00:01:30.630 --> 00:01:33.080
in the lower region of an image that
discipline hidden unisys is looking for

00:01:33.080 --> 00:01:33.090
discipline hidden unisys is looking for
 

00:01:33.090 --> 00:01:36.920
discipline hidden unisys is looking for
a edge or a line that looks like that so

00:01:36.920 --> 00:01:36.930
a edge or a line that looks like that so
 

00:01:36.930 --> 00:01:38.929
a edge or a line that looks like that so
those are the 9 image patches that

00:01:38.929 --> 00:01:38.939
those are the 9 image patches that
 

00:01:38.939 --> 00:01:41.990
those are the 9 image patches that
maximally activate 1 hidden units

00:01:41.990 --> 00:01:42.000
maximally activate 1 hidden units
 

00:01:42.000 --> 00:01:44.960
maximally activate 1 hidden units
activation now you can then pick a

00:01:44.960 --> 00:01:44.970
activation now you can then pick a
 

00:01:44.970 --> 00:01:48.170
activation now you can then pick a
different hidden unit in there 1 and do

00:01:48.170 --> 00:01:48.180
different hidden unit in there 1 and do
 

00:01:48.180 --> 00:01:50.420
different hidden unit in there 1 and do
the same thing so that's a different in

00:01:50.420 --> 00:01:50.430
the same thing so that's a different in
 

00:01:50.430 --> 00:01:52.789
the same thing so that's a different in
the unit and looks like this second one

00:01:52.789 --> 00:01:52.799
the unit and looks like this second one
 

00:01:52.799 --> 00:01:55.310
the unit and looks like this second one
represented by these 9 image patches

00:01:55.310 --> 00:01:55.320
represented by these 9 image patches
 

00:01:55.320 --> 00:01:57.440
represented by these 9 image patches
here looks like this hidden unit is

00:01:57.440 --> 00:01:57.450
here looks like this hidden unit is
 

00:01:57.450 --> 00:01:59.510
here looks like this hidden unit is
looking for a line you know sort of in

00:01:59.510 --> 00:01:59.520
looking for a line you know sort of in
 

00:01:59.520 --> 00:02:02.240
looking for a line you know sort of in
that portion of its input region we also

00:02:02.240 --> 00:02:02.250
that portion of its input region we also
 

00:02:02.250 --> 00:02:04.999
that portion of its input region we also
call this receptive view and if you do

00:02:04.999 --> 00:02:05.009
call this receptive view and if you do
 

00:02:05.009 --> 00:02:07.789
call this receptive view and if you do
this for other hidden units you find

00:02:07.789 --> 00:02:07.799
this for other hidden units you find
 

00:02:07.799 --> 00:02:09.219
this for other hidden units you find
other hidden units

00:02:09.219 --> 00:02:09.229
other hidden units
 

00:02:09.229 --> 00:02:12.610
other hidden units
to activate in image patches that look

00:02:12.610 --> 00:02:12.620
to activate in image patches that look
 

00:02:12.620 --> 00:02:13.990
to activate in image patches that look
like that this one seems to have a

00:02:13.990 --> 00:02:14.000
like that this one seems to have a
 

00:02:14.000 --> 00:02:17.110
like that this one seems to have a
preference for a vertical light edge of

00:02:17.110 --> 00:02:17.120
preference for a vertical light edge of
 

00:02:17.120 --> 00:02:19.210
preference for a vertical light edge of
a preferenced at the left side of it be

00:02:19.210 --> 00:02:19.220
a preferenced at the left side of it be
 

00:02:19.220 --> 00:02:22.210
a preferenced at the left side of it be
green this one really prefers orange

00:02:22.210 --> 00:02:22.220
green this one really prefers orange
 

00:02:22.220 --> 00:02:25.360
green this one really prefers orange
colors and this is an interesting image

00:02:25.360 --> 00:02:25.370
colors and this is an interesting image
 

00:02:25.370 --> 00:02:29.280
colors and this is an interesting image
match this is red and green together

00:02:29.280 --> 00:02:29.290
match this is red and green together
 

00:02:29.290 --> 00:02:31.780
match this is red and green together
would make a brownish or a brownish

00:02:31.780 --> 00:02:31.790
would make a brownish or a brownish
 

00:02:31.790 --> 00:02:34.630
would make a brownish or a brownish
orange color but the neuron is still

00:02:34.630 --> 00:02:34.640
orange color but the neuron is still
 

00:02:34.640 --> 00:02:37.600
orange color but the neuron is still
happy to activate with that and so on so

00:02:37.600 --> 00:02:37.610
happy to activate with that and so on so
 

00:02:37.610 --> 00:02:40.600
happy to activate with that and so on so
this is nine different representative

00:02:40.600 --> 00:02:40.610
this is nine different representative
 

00:02:40.610 --> 00:02:43.059
this is nine different representative
neurons and for each of them the nine

00:02:43.059 --> 00:02:43.069
neurons and for each of them the nine
 

00:02:43.069 --> 00:02:45.220
neurons and for each of them the nine
image matches that they maximally

00:02:45.220 --> 00:02:45.230
image matches that they maximally
 

00:02:45.230 --> 00:02:47.559
image matches that they maximally
activate on so this gives you a sentence

00:02:47.559 --> 00:02:47.569
activate on so this gives you a sentence
 

00:02:47.569 --> 00:02:51.130
activate on so this gives you a sentence
that units trained hidden units in layer

00:02:51.130 --> 00:02:51.140
that units trained hidden units in layer
 

00:02:51.140 --> 00:02:53.259
that units trained hidden units in layer
one are often looking for relatively

00:02:53.259 --> 00:02:53.269
one are often looking for relatively
 

00:02:53.269 --> 00:02:56.110
one are often looking for relatively
simple features such as an edge or a

00:02:56.110 --> 00:02:56.120
simple features such as an edge or a
 

00:02:56.120 --> 00:03:00.130
simple features such as an edge or a
particular shade of color and all of the

00:03:00.130 --> 00:03:00.140
particular shade of color and all of the
 

00:03:00.140 --> 00:03:03.069
particular shade of color and all of the
examples I'm using in this video come

00:03:03.069 --> 00:03:03.079
examples I'm using in this video come
 

00:03:03.079 --> 00:03:05.440
examples I'm using in this video come
from this paper by Matthew Zener and Rob

00:03:05.440 --> 00:03:05.450
from this paper by Matthew Zener and Rob
 

00:03:05.450 --> 00:03:07.809
from this paper by Matthew Zener and Rob
Fergus title visualizing and

00:03:07.809 --> 00:03:07.819
Fergus title visualizing and
 

00:03:07.819 --> 00:03:10.199
Fergus title visualizing and
understanding convolutional networks and

00:03:10.199 --> 00:03:10.209
understanding convolutional networks and
 

00:03:10.209 --> 00:03:13.900
understanding convolutional networks and
I'm just going to use one of the simpler

00:03:13.900 --> 00:03:13.910
I'm just going to use one of the simpler
 

00:03:13.910 --> 00:03:16.809
I'm just going to use one of the simpler
ways to visualize what a hidden unit in

00:03:16.809 --> 00:03:16.819
ways to visualize what a hidden unit in
 

00:03:16.819 --> 00:03:19.120
ways to visualize what a hidden unit in
the neural network is computing if you

00:03:19.120 --> 00:03:19.130
the neural network is computing if you
 

00:03:19.130 --> 00:03:21.039
the neural network is computing if you
read their paper they have some other

00:03:21.039 --> 00:03:21.049
read their paper they have some other
 

00:03:21.049 --> 00:03:22.599
read their paper they have some other
more sophisticated ways of visualizing

00:03:22.599 --> 00:03:22.609
more sophisticated ways of visualizing
 

00:03:22.609 --> 00:03:25.710
more sophisticated ways of visualizing
what the confidence is learning as well

00:03:25.710 --> 00:03:25.720
what the confidence is learning as well
 

00:03:25.720 --> 00:03:28.629
what the confidence is learning as well
but now you've repeated this procedure

00:03:28.629 --> 00:03:28.639
but now you've repeated this procedure
 

00:03:28.639 --> 00:03:30.909
but now you've repeated this procedure
several times for nine-headed units in

00:03:30.909 --> 00:03:30.919
several times for nine-headed units in
 

00:03:30.919 --> 00:03:34.360
several times for nine-headed units in
layer one one of you do this for some of

00:03:34.360 --> 00:03:34.370
layer one one of you do this for some of
 

00:03:34.370 --> 00:03:36.789
layer one one of you do this for some of
the hidden units in the deeper layers of

00:03:36.789 --> 00:03:36.799
the hidden units in the deeper layers of
 

00:03:36.799 --> 00:03:38.740
the hidden units in the deeper layers of
the neural network and what is the

00:03:38.740 --> 00:03:38.750
the neural network and what is the
 

00:03:38.750 --> 00:03:40.479
the neural network and what is the
neural network and then learning in the

00:03:40.479 --> 00:03:40.489
neural network and then learning in the
 

00:03:40.489 --> 00:03:43.690
neural network and then learning in the
deeper layers so in the deeper layers a

00:03:43.690 --> 00:03:43.700
deeper layers so in the deeper layers a
 

00:03:43.700 --> 00:03:46.360
deeper layers so in the deeper layers a
hidden unit will see a larger region of

00:03:46.360 --> 00:03:46.370
hidden unit will see a larger region of
 

00:03:46.370 --> 00:03:48.670
hidden unit will see a larger region of
the image where at the extreme end you

00:03:48.670 --> 00:03:48.680
the image where at the extreme end you
 

00:03:48.680 --> 00:03:51.159
the image where at the extreme end you
know each pixel could hypothetically

00:03:51.159 --> 00:03:51.169
know each pixel could hypothetically
 

00:03:51.169 --> 00:03:54.640
know each pixel could hypothetically
affect the output of these later layers

00:03:54.640 --> 00:03:54.650
affect the output of these later layers
 

00:03:54.650 --> 00:03:57.250
affect the output of these later layers
of the neural network so later units are

00:03:57.250 --> 00:03:57.260
of the neural network so later units are
 

00:03:57.260 --> 00:03:59.259
of the neural network so later units are
actually seeing larger image patches I'm

00:03:59.259 --> 00:03:59.269
actually seeing larger image patches I'm
 

00:03:59.269 --> 00:04:01.030
actually seeing larger image patches I'm
still gonna plot the image patches as

00:04:01.030 --> 00:04:01.040
still gonna plot the image patches as
 

00:04:01.040 --> 00:04:04.089
still gonna plot the image patches as
the same size on these slides but if we

00:04:04.089 --> 00:04:04.099
the same size on these slides but if we
 

00:04:04.099 --> 00:04:06.490
the same size on these slides but if we
repeat this procedure this is what you

00:04:06.490 --> 00:04:06.500
repeat this procedure this is what you
 

00:04:06.500 --> 00:04:09.129
repeat this procedure this is what you
had previously for layer 1 and this is a

00:04:09.129 --> 00:04:09.139
had previously for layer 1 and this is a
 

00:04:09.139 --> 00:04:11.710
had previously for layer 1 and this is a
visualization of what maximally

00:04:11.710 --> 00:04:11.720
visualization of what maximally
 

00:04:11.720 --> 00:04:14.379
visualization of what maximally
activates a nine different hidden units

00:04:14.379 --> 00:04:14.389
activates a nine different hidden units
 

00:04:14.389 --> 00:04:17.949
activates a nine different hidden units
in there too so I want to be clear about

00:04:17.949 --> 00:04:17.959
in there too so I want to be clear about
 

00:04:17.959 --> 00:04:19.890
in there too so I want to be clear about
what this visualization is

00:04:19.890 --> 00:04:19.900
what this visualization is
 

00:04:19.900 --> 00:04:22.800
what this visualization is
these are the nine patches that cause

00:04:22.800 --> 00:04:22.810
these are the nine patches that cause
 

00:04:22.810 --> 00:04:25.020
these are the nine patches that cause
one hidden unit to be highly activated

00:04:25.020 --> 00:04:25.030
one hidden unit to be highly activated
 

00:04:25.030 --> 00:04:27.689
one hidden unit to be highly activated
and then each grouping this is a

00:04:27.689 --> 00:04:27.699
and then each grouping this is a
 

00:04:27.699 --> 00:04:30.330
and then each grouping this is a
different set of nine image patches that

00:04:30.330 --> 00:04:30.340
different set of nine image patches that
 

00:04:30.340 --> 00:04:32.850
different set of nine image patches that
cause one hidden unit to be activated so

00:04:32.850 --> 00:04:32.860
cause one hidden unit to be activated so
 

00:04:32.860 --> 00:04:35.790
cause one hidden unit to be activated so
this visualization shows nine hidden

00:04:35.790 --> 00:04:35.800
this visualization shows nine hidden
 

00:04:35.800 --> 00:04:37.920
this visualization shows nine hidden
units and layer two and for each of them

00:04:37.920 --> 00:04:37.930
units and layer two and for each of them
 

00:04:37.930 --> 00:04:40.260
units and layer two and for each of them
shows nine image patches that causes

00:04:40.260 --> 00:04:40.270
shows nine image patches that causes
 

00:04:40.270 --> 00:04:42.240
shows nine image patches that causes
that hidden unit to have a very large

00:04:42.240 --> 00:04:42.250
that hidden unit to have a very large
 

00:04:42.250 --> 00:04:44.879
that hidden unit to have a very large
outputs of a very large activation and

00:04:44.879 --> 00:04:44.889
outputs of a very large activation and
 

00:04:44.889 --> 00:04:47.909
outputs of a very large activation and
you can repeat this for deeper layers as

00:04:47.909 --> 00:04:47.919
you can repeat this for deeper layers as
 

00:04:47.919 --> 00:04:50.159
you can repeat this for deeper layers as
well now on this slide I know it's kind

00:04:50.159 --> 00:04:50.169
well now on this slide I know it's kind
 

00:04:50.169 --> 00:04:51.719
well now on this slide I know it's kind
of hard to see these tiny low

00:04:51.719 --> 00:04:51.729
of hard to see these tiny low
 

00:04:51.729 --> 00:04:53.550
of hard to see these tiny low
image patches so let me zoom in for some

00:04:53.550 --> 00:04:53.560
image patches so let me zoom in for some
 

00:04:53.560 --> 00:04:56.040
image patches so let me zoom in for some
of them for layer one this is what you

00:04:56.040 --> 00:04:56.050
of them for layer one this is what you
 

00:04:56.050 --> 00:04:59.219
of them for layer one this is what you
saw so for example this one's that first

00:04:59.219 --> 00:04:59.229
saw so for example this one's that first
 

00:04:59.229 --> 00:05:02.150
saw so for example this one's that first
unit we saw which was highly activated

00:05:02.150 --> 00:05:02.160
unit we saw which was highly activated
 

00:05:02.160 --> 00:05:05.129
unit we saw which was highly activated
if in the region of the input image you

00:05:05.129 --> 00:05:05.139
if in the region of the input image you
 

00:05:05.139 --> 00:05:07.890
if in the region of the input image you
can see there's an edge that that may be

00:05:07.890 --> 00:05:07.900
can see there's an edge that that may be
 

00:05:07.900 --> 00:05:10.680
can see there's an edge that that may be
at that angle now let's zoom in for

00:05:10.680 --> 00:05:10.690
at that angle now let's zoom in for
 

00:05:10.690 --> 00:05:13.879
at that angle now let's zoom in for
layer two as well to that visualization

00:05:13.879 --> 00:05:13.889
layer two as well to that visualization
 

00:05:13.889 --> 00:05:16.860
layer two as well to that visualization
so this is interesting where - looks

00:05:16.860 --> 00:05:16.870
so this is interesting where - looks
 

00:05:16.870 --> 00:05:19.499
so this is interesting where - looks
like it's detecting more complex shapes

00:05:19.499 --> 00:05:19.509
like it's detecting more complex shapes
 

00:05:19.509 --> 00:05:22.110
like it's detecting more complex shapes
and patterns so for example this hidden

00:05:22.110 --> 00:05:22.120
and patterns so for example this hidden
 

00:05:22.120 --> 00:05:23.730
and patterns so for example this hidden
unit looks like this looking for a

00:05:23.730 --> 00:05:23.740
unit looks like this looking for a
 

00:05:23.740 --> 00:05:25.860
unit looks like this looking for a
vertical texture with lots of vertical

00:05:25.860 --> 00:05:25.870
vertical texture with lots of vertical
 

00:05:25.870 --> 00:05:28.860
vertical texture with lots of vertical
lines this hidden unit looks like this

00:05:28.860 --> 00:05:28.870
lines this hidden unit looks like this
 

00:05:28.870 --> 00:05:31.290
lines this hidden unit looks like this
highly activated when there's a roundish

00:05:31.290 --> 00:05:31.300
highly activated when there's a roundish
 

00:05:31.300 --> 00:05:33.320
highly activated when there's a roundish
shape to the left part of the image

00:05:33.320 --> 00:05:33.330
shape to the left part of the image
 

00:05:33.330 --> 00:05:36.680
shape to the left part of the image
here's one that is looking for very thin

00:05:36.680 --> 00:05:36.690
here's one that is looking for very thin
 

00:05:36.690 --> 00:05:40.770
here's one that is looking for very thin
vertical lines and so on and so the

00:05:40.770 --> 00:05:40.780
vertical lines and so on and so the
 

00:05:40.780 --> 00:05:42.960
vertical lines and so on and so the
features the second layer is detecting

00:05:42.960 --> 00:05:42.970
features the second layer is detecting
 

00:05:42.970 --> 00:05:44.670
features the second layer is detecting
are getting in a complicated

00:05:44.670 --> 00:05:44.680
are getting in a complicated
 

00:05:44.680 --> 00:05:46.950
are getting in a complicated
how about layer three let's zoom into

00:05:46.950 --> 00:05:46.960
how about layer three let's zoom into
 

00:05:46.960 --> 00:05:49.020
how about layer three let's zoom into
that and in fact let me zoom in even

00:05:49.020 --> 00:05:49.030
that and in fact let me zoom in even
 

00:05:49.030 --> 00:05:51.300
that and in fact let me zoom in even
bigger as you can see this better these

00:05:51.300 --> 00:05:51.310
bigger as you can see this better these
 

00:05:51.310 --> 00:05:53.969
bigger as you can see this better these
are the things that maximally activate

00:05:53.969 --> 00:05:53.979
are the things that maximally activate
 

00:05:53.979 --> 00:05:55.320
are the things that maximally activate
layer three but let's zoom in even

00:05:55.320 --> 00:05:55.330
layer three but let's zoom in even
 

00:05:55.330 --> 00:05:58.379
layer three but let's zoom in even
bigger and so does it's pretty

00:05:58.379 --> 00:05:58.389
bigger and so does it's pretty
 

00:05:58.389 --> 00:06:00.210
bigger and so does it's pretty
interesting again it looks like there's

00:06:00.210 --> 00:06:00.220
interesting again it looks like there's
 

00:06:00.220 --> 00:06:03.120
interesting again it looks like there's
a hidden unit that seems to respond

00:06:03.120 --> 00:06:03.130
a hidden unit that seems to respond
 

00:06:03.130 --> 00:06:06.540
a hidden unit that seems to respond
highly to around the shape and the lower

00:06:06.540 --> 00:06:06.550
highly to around the shape and the lower
 

00:06:06.550 --> 00:06:08.550
highly to around the shape and the lower
left-hand portion of the image maybe so

00:06:08.550 --> 00:06:08.560
left-hand portion of the image maybe so
 

00:06:08.560 --> 00:06:10.740
left-hand portion of the image maybe so
that ends up detecting a lot of cars

00:06:10.740 --> 00:06:10.750
that ends up detecting a lot of cars
 

00:06:10.750 --> 00:06:13.680
that ends up detecting a lot of cars
don't say wonders even you know starting

00:06:13.680 --> 00:06:13.690
don't say wonders even you know starting
 

00:06:13.690 --> 00:06:18.240
don't say wonders even you know starting
to detect people and this one looks like

00:06:18.240 --> 00:06:18.250
to detect people and this one looks like
 

00:06:18.250 --> 00:06:20.610
to detect people and this one looks like
is detecting certain textures like

00:06:20.610 --> 00:06:20.620
is detecting certain textures like
 

00:06:20.620 --> 00:06:22.500
is detecting certain textures like
honeycomb shapes or square shapes this

00:06:22.500 --> 00:06:22.510
honeycomb shapes or square shapes this
 

00:06:22.510 --> 00:06:25.589
honeycomb shapes or square shapes this
regular texture and some of these is

00:06:25.589 --> 00:06:25.599
regular texture and some of these is
 

00:06:25.599 --> 00:06:27.210
regular texture and some of these is
difficult to look at and

00:06:27.210 --> 00:06:27.220
difficult to look at and
 

00:06:27.220 --> 00:06:29.310
difficult to look at and
we figure out what is this detecting but

00:06:29.310 --> 00:06:29.320
we figure out what is this detecting but
 

00:06:29.320 --> 00:06:31.320
we figure out what is this detecting but
this clearly starts you to detect more

00:06:31.320 --> 00:06:31.330
this clearly starts you to detect more
 

00:06:31.330 --> 00:06:33.780
this clearly starts you to detect more
complex patterns how about the next

00:06:33.780 --> 00:06:33.790
complex patterns how about the next
 

00:06:33.790 --> 00:06:34.230
complex patterns how about the next
layer

00:06:34.230 --> 00:06:34.240
layer
 

00:06:34.240 --> 00:06:35.760
layer
well here's layer four and you see that

00:06:35.760 --> 00:06:35.770
well here's layer four and you see that
 

00:06:35.770 --> 00:06:38.010
well here's layer four and you see that
the features or the patterns is

00:06:38.010 --> 00:06:38.020
the features or the patterns is
 

00:06:38.020 --> 00:06:40.080
the features or the patterns is
detecting or even more complex looks

00:06:40.080 --> 00:06:40.090
detecting or even more complex looks
 

00:06:40.090 --> 00:06:42.570
detecting or even more complex looks
like this has learned almost a dog

00:06:42.570 --> 00:06:42.580
like this has learned almost a dog
 

00:06:42.580 --> 00:06:44.850
like this has learned almost a dog
detector but all these dogs look quite

00:06:44.850 --> 00:06:44.860
detector but all these dogs look quite
 

00:06:44.860 --> 00:06:46.830
detector but all these dogs look quite
similar right is this um I don't know

00:06:46.830 --> 00:06:46.840
similar right is this um I don't know
 

00:06:46.840 --> 00:06:48.690
similar right is this um I don't know
what dog species or dog breed is this

00:06:48.690 --> 00:06:48.700
what dog species or dog breed is this
 

00:06:48.700 --> 00:06:50.670
what dog species or dog breed is this
but you know all those dogs all those

00:06:50.670 --> 00:06:50.680
but you know all those dogs all those
 

00:06:50.680 --> 00:06:51.990
but you know all those dogs all those
are dogs but they look relatively

00:06:51.990 --> 00:06:52.000
are dogs but they look relatively
 

00:06:52.000 --> 00:06:55.110
are dogs but they look relatively
similar as dogs go looks like this

00:06:55.110 --> 00:06:55.120
similar as dogs go looks like this
 

00:06:55.120 --> 00:06:57.180
similar as dogs go looks like this
hidden unit and therefore is detecting

00:06:57.180 --> 00:06:57.190
hidden unit and therefore is detecting
 

00:06:57.190 --> 00:07:00.480
hidden unit and therefore is detecting
water this looks like it was actually

00:07:00.480 --> 00:07:00.490
water this looks like it was actually
 

00:07:00.490 --> 00:07:03.120
water this looks like it was actually
detecting you know the legs of a bird

00:07:03.120 --> 00:07:03.130
detecting you know the legs of a bird
 

00:07:03.130 --> 00:07:07.080
detecting you know the legs of a bird
and so on and then they are five is

00:07:07.080 --> 00:07:07.090
and so on and then they are five is
 

00:07:07.090 --> 00:07:09.240
and so on and then they are five is
detecting even more substituted thing so

00:07:09.240 --> 00:07:09.250
detecting even more substituted thing so
 

00:07:09.250 --> 00:07:12.150
detecting even more substituted thing so
you notice there's also a neuron that

00:07:12.150 --> 00:07:12.160
you notice there's also a neuron that
 

00:07:12.160 --> 00:07:15.360
you notice there's also a neuron that
seems to be a dog detector but set of

00:07:15.360 --> 00:07:15.370
seems to be a dog detector but set of
 

00:07:15.370 --> 00:07:17.550
seems to be a dog detector but set of
dogs is detecting here seems to be more

00:07:17.550 --> 00:07:17.560
dogs is detecting here seems to be more
 

00:07:17.560 --> 00:07:20.460
dogs is detecting here seems to be more
varied and then this seems to be

00:07:20.460 --> 00:07:20.470
varied and then this seems to be
 

00:07:20.470 --> 00:07:23.010
varied and then this seems to be
detecting keyboards and things with a

00:07:23.010 --> 00:07:23.020
detecting keyboards and things with a
 

00:07:23.020 --> 00:07:26.760
detecting keyboards and things with a
keyboard like texture maybe lots of dots

00:07:26.760 --> 00:07:26.770
keyboard like texture maybe lots of dots
 

00:07:26.770 --> 00:07:29.760
keyboard like texture maybe lots of dots
against a background I think this neuron

00:07:29.760 --> 00:07:29.770
against a background I think this neuron
 

00:07:29.770 --> 00:07:32.640
against a background I think this neuron
here may be detecting tanks it's always

00:07:32.640 --> 00:07:32.650
here may be detecting tanks it's always
 

00:07:32.650 --> 00:07:35.159
here may be detecting tanks it's always
hard to be sure and and and then this

00:07:35.159 --> 00:07:35.169
hard to be sure and and and then this
 

00:07:35.169 --> 00:07:38.190
hard to be sure and and and then this
one here this detecting flowers so I've

00:07:38.190 --> 00:07:38.200
one here this detecting flowers so I've
 

00:07:38.200 --> 00:07:39.720
one here this detecting flowers so I've
gone a long way from detecting

00:07:39.720 --> 00:07:39.730
gone a long way from detecting
 

00:07:39.730 --> 00:07:43.500
gone a long way from detecting
relatively simple things such as edges

00:07:43.500 --> 00:07:43.510
relatively simple things such as edges
 

00:07:43.510 --> 00:07:46.260
relatively simple things such as edges
in layer 1 to textures and they're 2 up

00:07:46.260 --> 00:07:46.270
in layer 1 to textures and they're 2 up
 

00:07:46.270 --> 00:07:49.469
in layer 1 to textures and they're 2 up
to detecting very complex objects in the

00:07:49.469 --> 00:07:49.479
to detecting very complex objects in the
 

00:07:49.479 --> 00:07:52.140
to detecting very complex objects in the
deeper layers so I hope this gives you

00:07:52.140 --> 00:07:52.150
deeper layers so I hope this gives you
 

00:07:52.150 --> 00:07:54.750
deeper layers so I hope this gives you
some better intuition about what the

00:07:54.750 --> 00:07:54.760
some better intuition about what the
 

00:07:54.760 --> 00:07:56.940
some better intuition about what the
shallow and the deeper layers of a

00:07:56.940 --> 00:07:56.950
shallow and the deeper layers of a
 

00:07:56.950 --> 00:08:00.090
shallow and the deeper layers of a
neural network are computing next let's

00:08:00.090 --> 00:08:00.100
neural network are computing next let's
 

00:08:00.100 --> 00:08:02.280
neural network are computing next let's
use this intuition to start building a

00:08:02.280 --> 00:08:02.290
use this intuition to start building a
 

00:08:02.290 --> 00:08:06.330
use this intuition to start building a
neural style transfer algorithm

