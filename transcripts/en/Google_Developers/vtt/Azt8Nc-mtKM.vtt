WEBVTT
Kind: captions
Language: en

00:00:00.992 --> 00:00:04.960
[MUSIC PLAYING]

00:00:06.206 --> 00:00:08.039
JOHN HENNESSY: Boy, I'm
delighted to be here

00:00:08.039 --> 00:00:11.370
today and have a chance
to talk to you about what

00:00:11.370 --> 00:00:15.420
is one of the biggest challenges
we faced in computing in 40

00:00:15.420 --> 00:00:18.660
years, but also a
tremendous opportunity

00:00:18.660 --> 00:00:20.910
to rethink how we
build computers

00:00:20.910 --> 00:00:22.550
and how we move forward.

00:00:22.550 --> 00:00:24.300
You know, there's been
a lot of discussion

00:00:24.300 --> 00:00:26.082
about the ending of Moore's law.

00:00:26.082 --> 00:00:28.540
The first thing to remember
about the ending of Moore's law

00:00:28.540 --> 00:00:30.090
is something Gordon
Moore said to me.

00:00:30.090 --> 00:00:33.390
He said, all exponentials
come to an end.

00:00:33.390 --> 00:00:35.520
It's just a question of when.

00:00:35.520 --> 00:00:38.940
And that's what's
happening with Moore's law.

00:00:38.940 --> 00:00:40.800
If we look at-- what
does it really mean

00:00:40.800 --> 00:00:42.780
to say Moore's law is ending?

00:00:42.780 --> 00:00:43.900
What does it really mean?

00:00:43.900 --> 00:00:45.566
Well, look at what's
happening in DRAMs.

00:00:45.566 --> 00:00:47.130
That's probably a
good place to start

00:00:47.130 --> 00:00:50.520
because we all depend on the
incredible growth in memory

00:00:50.520 --> 00:00:51.174
capacity.

00:00:51.174 --> 00:00:52.590
And if you look
at what's happened

00:00:52.590 --> 00:00:56.130
in DRAMs, for many
years we were achieving

00:00:56.130 --> 00:00:57.930
increases of about 50% a year.

00:00:57.930 --> 00:01:00.660
In other words, going
up slightly faster even

00:01:00.660 --> 00:01:02.010
than Moore's law.

00:01:02.010 --> 00:01:04.260
Then we began a
period of slowdown.

00:01:04.260 --> 00:01:06.820
And if you look what's happened
in the last seven years,

00:01:06.820 --> 00:01:09.030
this technology we were
used to seeing boom,

00:01:09.030 --> 00:01:12.360
the number of megabits per chip
more than doubling every two

00:01:12.360 --> 00:01:15.500
years, is now going
up at about 10% a year

00:01:15.500 --> 00:01:18.360
and it's going to take
about seven years to double.

00:01:18.360 --> 00:01:20.850
Now, DRAMs are a
particularly odd technology

00:01:20.850 --> 00:01:22.990
because they use deep
trench capacitors,

00:01:22.990 --> 00:01:25.530
so they require a
very particular kind

00:01:25.530 --> 00:01:27.330
of fabrication technology.

00:01:27.330 --> 00:01:29.640
What's happening in
processors, though?

00:01:29.640 --> 00:01:32.190
And if you look at the
data in processors,

00:01:32.190 --> 00:01:34.290
you'll see a similar slowdown.

00:01:34.290 --> 00:01:37.010
Moore's law is that
red line going up there

00:01:37.010 --> 00:01:39.160
on a nice logarithmic plot.

00:01:39.160 --> 00:01:40.620
Notice the blue line.

00:01:40.620 --> 00:01:43.590
That's the number of
transistors on a typical Intel

00:01:43.590 --> 00:01:45.780
microprocessor at that date.

00:01:45.780 --> 00:01:49.390
It begins diverging,
slowly at first.

00:01:49.390 --> 00:01:53.070
But look what's happened since
in the last 10 years, roughly.

00:01:53.070 --> 00:01:54.480
The gap has grown.

00:01:54.480 --> 00:01:58.410
In fact, if you look at
where we are in 2015, 2016,

00:01:58.410 --> 00:02:01.920
we're more than a factor
of 10 off, had we stayed

00:02:01.920 --> 00:02:03.940
on that Moore's law curve.

00:02:03.940 --> 00:02:07.590
Now, the thing to remember
is that there's also

00:02:07.590 --> 00:02:10.620
a cost factor in here.

00:02:10.620 --> 00:02:14.850
Fabs are getting a lot more
expensive and the cost of chips

00:02:14.850 --> 00:02:17.800
is actually not
going down as fast.

00:02:17.800 --> 00:02:20.520
So a result of that is that
the cost per transistor

00:02:20.520 --> 00:02:23.490
is actually increasing
at a worse rate.

00:02:23.490 --> 00:02:25.410
So we're beginning to
see the effects of that

00:02:25.410 --> 00:02:27.760
as we think about architecture.

00:02:27.760 --> 00:02:29.530
But if the slowdown
of Moore's law,

00:02:29.530 --> 00:02:32.580
which is what you see all
the press about as one thing,

00:02:32.580 --> 00:02:37.260
the big issue is the end of
what we call Dennard scaling.

00:02:37.260 --> 00:02:39.480
So Bob Dennard was
an IBM employee,

00:02:39.480 --> 00:02:43.080
he was the guy who invented
the one transistor DRAM.

00:02:43.080 --> 00:02:45.720
And he made a prediction
many years ago

00:02:45.720 --> 00:02:49.650
that the energy, the power
per square millimeter

00:02:49.650 --> 00:02:53.420
of silicon would stay
constant, would stay constant

00:02:53.420 --> 00:02:55.140
because voltage levels
would come down,

00:02:55.140 --> 00:02:56.650
capacitance would come down.

00:02:56.650 --> 00:02:58.170
What does that mean?

00:02:58.170 --> 00:03:01.170
If the energy, if the
power stays constant

00:03:01.170 --> 00:03:04.410
and the number of transistors
increases exponentially,

00:03:04.410 --> 00:03:08.830
then the energy per transistor
is actually going down.

00:03:08.830 --> 00:03:10.560
And in terms of
energy consumption,

00:03:10.560 --> 00:03:14.062
it's cheaper and cheaper
and cheaper to compute.

00:03:14.062 --> 00:03:15.770
Well, what happened
with Dennard scaling?

00:03:15.770 --> 00:03:17.270
Well, look at that
blue line there.

00:03:17.270 --> 00:03:18.930
The red line shows
you the technology

00:03:18.930 --> 00:03:21.540
improving on a standard
Moore's law curve.

00:03:21.540 --> 00:03:25.350
The blue line shows you
what's happening to power.

00:03:25.350 --> 00:03:26.100
And you all know.

00:03:26.100 --> 00:03:28.080
I mean, you've seen
microprocessors now, right?

00:03:28.080 --> 00:03:30.870
They slow their clock
down, they turn off cores,

00:03:30.870 --> 00:03:33.300
they do all kinds of things,
because otherwise they're

00:03:33.300 --> 00:03:35.070
going to burn up.

00:03:35.070 --> 00:03:36.690
They're going to burn up.

00:03:36.690 --> 00:03:39.510
I mean, I never thought we'd see
the day where a processor would

00:03:39.510 --> 00:03:42.570
actually slow itself down to
prevent itself overheating,

00:03:42.570 --> 00:03:44.170
but we're there.

00:03:44.170 --> 00:03:45.960
And so what happens
with Dennard scaling

00:03:45.960 --> 00:03:50.460
is it began to slow
down starting about '97.

00:03:50.460 --> 00:03:54.060
And then since 2007,
it's essentially halted.

00:03:54.060 --> 00:03:56.430
The result is a big change.

00:03:56.430 --> 00:04:00.540
All of a sudden, energy,
power becomes the key limiter.

00:04:00.540 --> 00:04:04.650
Not the number of transistors
available to designers,

00:04:04.650 --> 00:04:07.770
but their power consumption
becomes the key limiter.

00:04:07.770 --> 00:04:10.380
That requires you to think
completely differently

00:04:10.380 --> 00:04:13.050
about architecture, about
how you design machines.

00:04:13.050 --> 00:04:17.670
It means inefficiency in the
use of transistors in computing.

00:04:17.670 --> 00:04:20.970
Inefficiency in how an
architecture computes

00:04:20.970 --> 00:04:23.610
is penalized much
more heavily than it

00:04:23.610 --> 00:04:25.030
was in this earlier time.

00:04:28.370 --> 00:04:30.130
And of course, guess what?

00:04:30.130 --> 00:04:33.850
All the devices we carry
around, all the devices we use

00:04:33.850 --> 00:04:36.220
are running off batteries.

00:04:36.220 --> 00:04:39.750
So all of a sudden, energy is
a critical resource, right?

00:04:39.750 --> 00:04:41.260
What's the worst
thing that happens

00:04:41.260 --> 00:04:42.850
is your cell phone
runs out of power,

00:04:42.850 --> 00:04:44.266
your smartphone
runs out of power.

00:04:44.266 --> 00:04:45.670
That's a disaster, right?

00:04:45.670 --> 00:04:48.490
But think about all the
devices we walk around with.

00:04:48.490 --> 00:04:49.930
They're hooked up to battery.

00:04:49.930 --> 00:04:53.390
Think about the era,
the coming era of IoT,

00:04:53.390 --> 00:04:56.200
where we're going to have
devices that are always on

00:04:56.200 --> 00:04:58.090
and permanently on,
which are expected

00:04:58.090 --> 00:05:00.760
to last 10 years
on a single battery

00:05:00.760 --> 00:05:03.040
by using energy
harvesting techniques.

00:05:03.040 --> 00:05:07.090
Energy becomes the key resource
in making those things work

00:05:07.090 --> 00:05:08.440
efficiently.

00:05:08.440 --> 00:05:11.530
And as we move more and
more to always on devices

00:05:11.530 --> 00:05:12.980
with things like
Google Assistant,

00:05:12.980 --> 00:05:14.980
you're going to want your
device on all the time

00:05:14.980 --> 00:05:17.646
or at least you're going to want
the CPU on all the time, if not

00:05:17.646 --> 00:05:18.500
the screen.

00:05:18.500 --> 00:05:21.040
So we're going to have to worry
more and more about power.

00:05:21.040 --> 00:05:24.910
But the surprising thing that
many people are surprised by

00:05:24.910 --> 00:05:30.490
is that energy efficiency is
a giant issue in large cloud

00:05:30.490 --> 00:05:31.990
configurations.

00:05:31.990 --> 00:05:34.720
This shows you what the
typical capital cost would be

00:05:34.720 --> 00:05:36.790
like for a Google data center.

00:05:36.790 --> 00:05:39.980
You'll notice that green slice
there, those are the servers.

00:05:39.980 --> 00:05:42.130
But look at the size
of that red slice.

00:05:42.130 --> 00:05:44.500
That red slice is
the cost of the power

00:05:44.500 --> 00:05:46.870
plus cooling infrastructure.

00:05:46.870 --> 00:05:48.850
Spending as much on power
and cooling as you're

00:05:48.850 --> 00:05:51.370
spending on processors.

00:05:51.370 --> 00:05:55.570
So energy efficiency becomes
a really critical issue

00:05:55.570 --> 00:05:57.070
as we go forward.

00:05:57.070 --> 00:05:58.660
And the end of
Dennard scaling has

00:05:58.660 --> 00:06:01.270
meant that there's
no more free lunch.

00:06:01.270 --> 00:06:03.460
For a lot of years,
we had a free lunch.

00:06:03.460 --> 00:06:05.650
It was pretty easy
to figure out how

00:06:05.650 --> 00:06:08.470
to make computation
more energy efficient.

00:06:08.470 --> 00:06:09.460
Now, it's a lot harder.

00:06:12.100 --> 00:06:14.746
And you can see
the impact of this.

00:06:14.746 --> 00:06:18.190
This just shows you 40 years of
processor performance, what's

00:06:18.190 --> 00:06:21.160
happened to uniprocessor, single
processor performance, and then

00:06:21.160 --> 00:06:23.075
multiprocessor performance.

00:06:23.075 --> 00:06:25.450
So there were the early years
of computing, the beginning

00:06:25.450 --> 00:06:27.250
of the microprocessor era.

00:06:27.250 --> 00:06:30.890
We were seeing about 22%
improvement per year.

00:06:30.890 --> 00:06:34.480
The creation of risk
in the mid-1980s,

00:06:34.480 --> 00:06:37.330
a dramatic use of instruction
level parallelism,

00:06:37.330 --> 00:06:39.380
pipelining, multiple issue.

00:06:39.380 --> 00:06:43.420
We saw this incredible
period of about 20 years,

00:06:43.420 --> 00:06:46.000
where we got roughly
50% performance

00:06:46.000 --> 00:06:48.160
improvement per year.

00:06:48.160 --> 00:06:48.880
50%.

00:06:48.880 --> 00:06:50.380
That was amazing.

00:06:50.380 --> 00:06:53.450
Then the beginning of the
end of Dennard scaling.

00:06:53.450 --> 00:06:55.960
That caused everybody
to move to multi-core.

00:06:55.960 --> 00:06:57.390
What did multi-core do?

00:06:57.390 --> 00:07:00.310
Multi-core shoved the
efficiency problem

00:07:00.310 --> 00:07:03.850
from the hardware designer
to the software people.

00:07:03.850 --> 00:07:06.160
Now, the software
people had to figure out

00:07:06.160 --> 00:07:10.900
how to use those multi-core
processors efficiently.

00:07:10.900 --> 00:07:13.840
But Amdahl's law came
along, reared its ugly head.

00:07:13.840 --> 00:07:16.190
I'll show you some data on that.

00:07:16.190 --> 00:07:19.720
And now, we're in
this late stage period

00:07:19.720 --> 00:07:22.420
where it looks like we're
getting about 3% performance

00:07:22.420 --> 00:07:24.650
improvement per year.

00:07:24.650 --> 00:07:27.880
Doubling could take 20 years.

00:07:27.880 --> 00:07:29.530
That's the end of
general purpose

00:07:29.530 --> 00:07:32.440
processor performance
as we know it,

00:07:32.440 --> 00:07:34.490
as we're used to
for so many years.

00:07:37.430 --> 00:07:38.930
Why did this happen?

00:07:38.930 --> 00:07:41.890
Why did it grind
to a halt so fast?

00:07:41.890 --> 00:07:45.040
Well, think about what was
happening during that risk era

00:07:45.040 --> 00:07:48.130
where we're building these
deeply pipelined machines.

00:07:48.130 --> 00:07:51.880
15, 16, 17 stages
deep pipelines,

00:07:51.880 --> 00:07:53.710
four issues per clock.

00:07:53.710 --> 00:07:57.820
That machine needs to
have 60 instructions

00:07:57.820 --> 00:07:59.220
that it's working on at once.

00:07:59.220 --> 00:08:00.990
60 instructions.

00:08:00.990 --> 00:08:03.640
How does it possibly
get 60 instructions?

00:08:03.640 --> 00:08:04.990
It uses speculation.

00:08:04.990 --> 00:08:08.170
It guesses about branches,
it yanks instructions

00:08:08.170 --> 00:08:10.150
and tries to execute them.

00:08:10.150 --> 00:08:12.410
But guess what happens?

00:08:12.410 --> 00:08:15.100
Nobody can predict
branches perfectly.

00:08:15.100 --> 00:08:18.070
Every time you predict
a branch incorrectly,

00:08:18.070 --> 00:08:21.280
you have to undo all the work
associated with that missed

00:08:21.280 --> 00:08:21.975
prediction.

00:08:21.975 --> 00:08:23.350
You've got to back
it out, you've

00:08:23.350 --> 00:08:25.450
got to restore the
state of the machine.

00:08:25.450 --> 00:08:28.250
And if you look inside
a typical Intel Core

00:08:28.250 --> 00:08:32.590
i7 today, on integer
code roughly 25%

00:08:32.590 --> 00:08:35.380
of the instructions
that get executed end up

00:08:35.380 --> 00:08:37.690
being thrown away.

00:08:37.690 --> 00:08:39.130
Guess what?

00:08:39.130 --> 00:08:42.850
The energy still got burnt to
execute all those instructions.

00:08:42.850 --> 00:08:44.890
And then, I threw
the results away

00:08:44.890 --> 00:08:48.160
and I had to restore the
state of the machine.

00:08:48.160 --> 00:08:49.760
A lot of wasted energy.

00:08:49.760 --> 00:08:53.140
That's why the single
processor performance

00:08:53.140 --> 00:08:56.860
curve ended, basically.

00:08:56.860 --> 00:08:58.840
But we see similar
challenges when you begin

00:08:58.840 --> 00:09:00.790
to look at multi-core things.

00:09:00.790 --> 00:09:03.160
Amdahl's law, Gene
Amdahl wrote Amdahl's law

00:09:03.160 --> 00:09:04.670
more than 40 years ago.

00:09:04.670 --> 00:09:06.190
It's still true today.

00:09:06.190 --> 00:09:07.690
Even if you take
large data centers

00:09:07.690 --> 00:09:10.090
with heavily parallel
workloads, it's

00:09:10.090 --> 00:09:14.380
very hard to write a big
complicated piece of software

00:09:14.380 --> 00:09:18.310
and not have small sections
of it be sequential,

00:09:18.310 --> 00:09:22.514
whether it's synchronization or
coordination or something else.

00:09:22.514 --> 00:09:23.680
So think about what happens.

00:09:23.680 --> 00:09:26.770
You've got a 64 processor
multi-core in the future.

00:09:26.770 --> 00:09:32.840
Suppose 1%, just 1% of
the code is sequential.

00:09:32.840 --> 00:09:35.630
Then that 64 processor
multi-core only

00:09:35.630 --> 00:09:39.680
runs at the speed of
a 40 processor core.

00:09:39.680 --> 00:09:40.820
But guess what?

00:09:40.820 --> 00:09:44.180
You paid all the energy
for a 64 processor core

00:09:44.180 --> 00:09:46.010
executing all the
time and you only

00:09:46.010 --> 00:09:51.080
got 40 processors out of
that, slightly more than half.

00:09:51.080 --> 00:09:52.670
That's the problem.

00:09:52.670 --> 00:09:55.100
We've got to breakthrough
this efficiency barrier.

00:09:55.100 --> 00:09:57.020
We've got to rethink
how we design machines.

00:10:00.040 --> 00:10:01.810
So what's left?

00:10:01.810 --> 00:10:04.720
Well, software-centric
approaches.

00:10:04.720 --> 00:10:08.710
Can we make our
systems more efficient?

00:10:08.710 --> 00:10:10.810
It's great that we have
these modern scripting

00:10:10.810 --> 00:10:13.120
languages, they're
interpreted, dynamically-typed,

00:10:13.120 --> 00:10:14.650
they encourage reuse.

00:10:14.650 --> 00:10:16.360
They've really
liberated programmers

00:10:16.360 --> 00:10:18.640
to get a lot more code
written and create

00:10:18.640 --> 00:10:20.530
incredible functionality.

00:10:20.530 --> 00:10:22.480
They're efficient
for programmers.

00:10:22.480 --> 00:10:25.150
They're very inefficient
for execution,

00:10:25.150 --> 00:10:27.140
and I'll show you
that in a second.

00:10:27.140 --> 00:10:30.670
And then there are
hardware-centric approaches,

00:10:30.670 --> 00:10:33.790
what Dave Patterson and I call
domain-specific architectures.

00:10:33.790 --> 00:10:36.550
Namely, designing
an architecture

00:10:36.550 --> 00:10:38.170
which isn't fully
general purpose,

00:10:38.170 --> 00:10:41.890
but which does a set of
domains, a set of applications

00:10:41.890 --> 00:10:46.520
really well, much
more efficiently.

00:10:46.520 --> 00:10:49.240
So let's take a look at
what the opportunity is.

00:10:49.240 --> 00:10:52.540
This is a chart that comes out
of a paper by Charles Leiserson

00:10:52.540 --> 00:10:54.670
and a group of colleagues
at MIT, called "There's

00:10:54.670 --> 00:10:57.610
Plenty of Room at the Top."

00:10:57.610 --> 00:11:01.750
They take a very simple example,
admittedly, matrix multiply.

00:11:01.750 --> 00:11:03.130
They write it in Python.

00:11:03.130 --> 00:11:06.970
They run it on an 18
core Intel processor.

00:11:06.970 --> 00:11:09.250
And then they proceed
to optimize it.

00:11:09.250 --> 00:11:14.440
First, rewrite it in C.
That speeds it up 47 times.

00:11:14.440 --> 00:11:17.560
Now, any compiler in the world
that can get a speed up of 47

00:11:17.560 --> 00:11:20.620
would be really remarkable,
even a speed up of 20.

00:11:20.620 --> 00:11:22.450
Then they rewrite it
with parallel loops.

00:11:22.450 --> 00:11:25.400
They get almost a factor
of nine out of that.

00:11:25.400 --> 00:11:28.060
Then they rewrite it by
doing memory optimization.

00:11:28.060 --> 00:11:29.380
That gives them a factor of 20.

00:11:29.380 --> 00:11:31.830
They block the matrix, they
allocate it to the caches

00:11:31.830 --> 00:11:32.830
properly.

00:11:32.830 --> 00:11:34.730
That gives them a factor of 20.

00:11:34.730 --> 00:11:37.690
And then finally,
they rewrite it

00:11:37.690 --> 00:11:41.590
using Intel AVX instructions,
using the vector instructions

00:11:41.590 --> 00:11:45.130
in the Intel Core, right,
domain-specific instructions

00:11:45.130 --> 00:11:47.770
that do vector
operations efficiently.

00:11:47.770 --> 00:11:50.020
That gives them
another factor of 10.

00:11:50.020 --> 00:11:52.360
The end result is
that final version

00:11:52.360 --> 00:11:56.410
runs 62,000 times faster
than the initial version.

00:11:56.410 --> 00:11:58.720
Now admittedly, matrix
multiply is an easy case,

00:11:58.720 --> 00:12:00.100
small piece of code.

00:12:00.100 --> 00:12:03.340
But it shows the
potential of rethinking

00:12:03.340 --> 00:12:05.770
how we write this software
and making it better.

00:12:08.500 --> 00:12:11.700
So what about these
domain-specific architectures?

00:12:11.700 --> 00:12:13.500
Really what we're
going to try to do

00:12:13.500 --> 00:12:16.590
is make a breakthrough
in how efficient

00:12:16.590 --> 00:12:18.420
we build the hardware.

00:12:18.420 --> 00:12:20.640
And by domain-specific,
we're referring

00:12:20.640 --> 00:12:26.610
to a class of processors which
do a range of applications.

00:12:26.610 --> 00:12:28.312
They're not like, for
example, the modem

00:12:28.312 --> 00:12:29.520
inside the cell phone, right?

00:12:29.520 --> 00:12:31.500
That's programmed once,
it runs modem code.

00:12:31.500 --> 00:12:33.490
It never does anything else.

00:12:33.490 --> 00:12:35.940
But think of a set
of processors which

00:12:35.940 --> 00:12:38.070
do a range of
applications that are

00:12:38.070 --> 00:12:40.710
related to a particular
application domain.

00:12:40.710 --> 00:12:45.510
They're programmable, they're
useful in that domain,

00:12:45.510 --> 00:12:47.880
they take advantage
of specific knowledge

00:12:47.880 --> 00:12:49.950
about that domain
when they run, so they

00:12:49.950 --> 00:12:51.900
can run much more efficiently.

00:12:51.900 --> 00:12:56.100
Obvious examples, doing things
for neural network processors,

00:12:56.100 --> 00:12:59.250
doing things that focus
on machine learning.

00:12:59.250 --> 00:12:59.940
One example.

00:12:59.940 --> 00:13:03.020
GPUs are another example of
this kind of thinking, right?

00:13:03.020 --> 00:13:05.460
They're programmable
in the context

00:13:05.460 --> 00:13:07.266
of doing graphics processing.

00:13:10.670 --> 00:13:13.780
So for any of you who have
ever seen that any of the books

00:13:13.780 --> 00:13:15.640
that Dave Patterson
and I wrote, you

00:13:15.640 --> 00:13:18.550
know that we like quantitative
approaches to understand things

00:13:18.550 --> 00:13:21.580
and we like to analyze
why things work.

00:13:21.580 --> 00:13:25.210
So the key about
domain-specific architectures

00:13:25.210 --> 00:13:26.710
is there is no black magic here.

00:13:26.710 --> 00:13:29.440
Going to a more limited
range of architectures

00:13:29.440 --> 00:13:32.420
doesn't automatically
make things faster.

00:13:32.420 --> 00:13:36.860
We have to make specific
architectural changes that win.

00:13:36.860 --> 00:13:38.810
And there are three big ones.

00:13:38.810 --> 00:13:41.890
The first is we make more
effective use of parallelism.

00:13:41.890 --> 00:13:44.380
We go from a multiple
instruction, multiple data

00:13:44.380 --> 00:13:47.060
world that you'd see
on a multi-core today

00:13:47.060 --> 00:13:49.750
to a single instruction
multiple data.

00:13:49.750 --> 00:13:52.402
So instead of having
each one of my cores

00:13:52.402 --> 00:13:53.860
fetch separate
instruction streams,

00:13:53.860 --> 00:13:55.840
have to have
separate caches, I've

00:13:55.840 --> 00:13:57.880
got one set of
instructions and they're

00:13:57.880 --> 00:14:00.190
going to a whole set
of functional units.

00:14:00.190 --> 00:14:02.260
It's much more efficient.

00:14:02.260 --> 00:14:03.100
What do I give up?

00:14:03.100 --> 00:14:05.560
I give up some flexibility
when I do that.

00:14:05.560 --> 00:14:07.480
I absolutely give
up flexibility.

00:14:07.480 --> 00:14:10.960
But the efficiency
gain is dramatic.

00:14:10.960 --> 00:14:14.020
I go from speculative
out-of-order machines,

00:14:14.020 --> 00:14:18.790
what a typical high-end
processor from ARM or Intel

00:14:18.790 --> 00:14:21.400
looks like today,
to something that's

00:14:21.400 --> 00:14:26.230
more like a VLIW, that uses
a set of operations where

00:14:26.230 --> 00:14:30.100
the compiler has decided
that a set of operations

00:14:30.100 --> 00:14:31.570
can occur in parallel.

00:14:31.570 --> 00:14:35.410
So I shift work from
runtime to compile time.

00:14:35.410 --> 00:14:36.850
Again, it's less flexible.

00:14:36.850 --> 00:14:38.620
But for applications
when it works,

00:14:38.620 --> 00:14:41.190
it's much more efficient.

00:14:41.190 --> 00:14:42.960
I move away from caches.

00:14:42.960 --> 00:14:45.240
So caches are one of
the great inventions

00:14:45.240 --> 00:14:48.510
of computer science, one of
the truly great inventions.

00:14:48.510 --> 00:14:51.660
The problem is when there
is low spatial and low

00:14:51.660 --> 00:14:54.970
temporal locality, caches
not only don't work,

00:14:54.970 --> 00:14:57.060
they actually slow
programs down.

00:14:57.060 --> 00:14:58.540
They slow them down.

00:14:58.540 --> 00:15:03.270
So we move away from that to
user control local memories.

00:15:03.270 --> 00:15:04.630
What's the trade-off?

00:15:04.630 --> 00:15:06.180
Now, somebody has
to figure out how

00:15:06.180 --> 00:15:08.390
to map their application
into a user controlled

00:15:08.390 --> 00:15:10.540
memory structure.

00:15:10.540 --> 00:15:13.620
Cache does it automatically for
you, it's very general purpose.

00:15:13.620 --> 00:15:16.050
But for certain applications,
I can do a lot better

00:15:16.050 --> 00:15:18.900
by mapping those things myself.

00:15:18.900 --> 00:15:22.440
And then finally, I focus on
only the amount of accuracy

00:15:22.440 --> 00:15:23.390
I need.

00:15:23.390 --> 00:15:27.120
I've move from IEEE to the
lower precision floating point

00:15:27.120 --> 00:15:31.560
or from 32 and 64-bit integers
to 8-bit and 16-bit integers.

00:15:31.560 --> 00:15:33.510
If that's all the
accuracy I need,

00:15:33.510 --> 00:15:35.970
I can do eight
integer operations,

00:15:35.970 --> 00:15:38.400
eight 8-bit operations in
the same amount of time

00:15:38.400 --> 00:15:40.590
that I can do one
64-bit operation.

00:15:40.590 --> 00:15:41.820
So considerably faster.

00:15:44.870 --> 00:15:46.820
But to go along
with that, I also

00:15:46.820 --> 00:15:48.690
need a domain-specific language.

00:15:48.690 --> 00:15:50.270
I need a language
that will match up

00:15:50.270 --> 00:15:53.120
to that hardware configuration.

00:15:53.120 --> 00:15:55.790
We're not going to be able to
take code written in Python

00:15:55.790 --> 00:16:00.050
or C, for example, and extract
the kind of information

00:16:00.050 --> 00:16:03.900
we need to map to a
domain-specific architecture.

00:16:03.900 --> 00:16:07.340
We've got to rethink how
we program these machines.

00:16:07.340 --> 00:16:09.620
And that's going to be
high-level operations.

00:16:09.620 --> 00:16:11.690
It's going to be
vector-vector multiply

00:16:11.690 --> 00:16:15.670
or a vector-matrix multiply or
a sparse matrix organization,

00:16:15.670 --> 00:16:19.400
so that I get that high-level
information that I need

00:16:19.400 --> 00:16:22.990
and I can compile it down
into the architecture.

00:16:22.990 --> 00:16:27.040
The key in doing these
domain-specific languages will

00:16:27.040 --> 00:16:31.000
be to retain enough machine
independence that I don't have

00:16:31.000 --> 00:16:34.420
to recode things, that a
compiler can come along, take

00:16:34.420 --> 00:16:36.540
a domain-specific
language, map it

00:16:36.540 --> 00:16:40.270
to maybe one architecture
that's running in the cloud,

00:16:40.270 --> 00:16:41.890
maybe another
architecture that's

00:16:41.890 --> 00:16:44.220
running on my smartphone.

00:16:44.220 --> 00:16:46.960
That's going to
be the challenge.

00:16:46.960 --> 00:16:51.030
Ideas like TensorFlow and OpenGL
are a step in this direction,

00:16:51.030 --> 00:16:52.200
but it's really a new space.

00:16:52.200 --> 00:16:54.630
We're just beginning to
understand it and understand

00:16:54.630 --> 00:16:56.325
how to design in this space.

00:17:00.460 --> 00:17:04.280
You know, I built my first
computer almost 50 years ago,

00:17:04.280 --> 00:17:06.940
believe it or not.

00:17:06.940 --> 00:17:10.390
I've seen a lot of revolutions
in this incredible IT

00:17:10.390 --> 00:17:11.680
industry since then--

00:17:11.680 --> 00:17:14.380
the creation of the internet,
the creation of the World Wide

00:17:14.380 --> 00:17:17.540
Web, the magic of
the microprocessor,

00:17:17.540 --> 00:17:21.034
smartphones, personal computers.

00:17:21.034 --> 00:17:22.450
But the one I think
that is really

00:17:22.450 --> 00:17:24.849
going to change our
lives is the breakthrough

00:17:24.849 --> 00:17:28.030
in machine learning and
artificial intelligence.

00:17:28.030 --> 00:17:30.340
This is a technology
which people

00:17:30.340 --> 00:17:32.680
have worked on for 50 years.

00:17:32.680 --> 00:17:36.880
And finally, finally, we
made the breakthrough.

00:17:36.880 --> 00:17:39.040
And the basis of
that breakthrough?

00:17:39.040 --> 00:17:42.490
We needed about a million
times more computational power

00:17:42.490 --> 00:17:45.779
than we thought we needed
to make the technology work.

00:17:45.779 --> 00:17:47.320
But we finally got
to the point where

00:17:47.320 --> 00:17:49.630
we could apply that
kind of computer power.

00:17:49.630 --> 00:17:53.280
And the one thing-- this is some
data that Jeff Dean and David

00:17:53.280 --> 00:17:55.300
Patterson and Cliff
Young collected--

00:17:55.300 --> 00:17:57.610
that shows there's one
thing growing just as fast

00:17:57.610 --> 00:17:59.020
as Moore's law--

00:17:59.020 --> 00:18:03.760
the number of papers being
published in machine learning.

00:18:03.760 --> 00:18:05.499
It is a revolution.

00:18:05.499 --> 00:18:06.790
It's going to change our world.

00:18:06.790 --> 00:18:10.090
And I'm sure some of you saw
the Duplex demo the other day.

00:18:10.090 --> 00:18:13.660
I mean, in the domain
of making appointments,

00:18:13.660 --> 00:18:15.905
it passes the Turing
test in that domain,

00:18:15.905 --> 00:18:17.530
which is an extraordinary
breakthrough.

00:18:17.530 --> 00:18:19.540
It doesn't pass it
in the general terms,

00:18:19.540 --> 00:18:21.640
but it passes it in
a limited domain.

00:18:21.640 --> 00:18:25.460
And that's really an
indication of what's coming.

00:18:25.460 --> 00:18:27.010
So how do you think
about building

00:18:27.010 --> 00:18:32.560
a domain-specific architecture
to do deep neural networks?

00:18:32.560 --> 00:18:35.470
Well, this is a picture
of what's inside a tensor

00:18:35.470 --> 00:18:36.832
processing unit.

00:18:36.832 --> 00:18:38.290
The point I want
to make about this

00:18:38.290 --> 00:18:42.860
is if you look at this what
uses up the silicon area,

00:18:42.860 --> 00:18:45.820
notice that it's not used
for a lot of control,

00:18:45.820 --> 00:18:47.890
it's not used for
a lot of caching.

00:18:47.890 --> 00:18:49.930
It's used to do things
that are directly

00:18:49.930 --> 00:18:52.000
relevant to the computation.

00:18:52.000 --> 00:18:57.130
So this processor
can do 256 by 256--

00:18:57.130 --> 00:19:01.810
that is 64,000
multiply accumulates,

00:19:01.810 --> 00:19:06.480
8-bit multiply accumulates
every single clock.

00:19:06.480 --> 00:19:07.950
Every single clock.

00:19:07.950 --> 00:19:10.890
So it can really crunch
through, for inference things,

00:19:10.890 --> 00:19:15.229
enormous amounts of
computational capability.

00:19:15.229 --> 00:19:17.520
You're not going to run
general purpose C code on this.

00:19:17.520 --> 00:19:20.400
You're going to run something
that's a neural network

00:19:20.400 --> 00:19:21.250
inference problem.

00:19:25.660 --> 00:19:27.270
And if you look
at the performance

00:19:27.270 --> 00:19:29.940
and you look at-- here we've
shown performance per watt.

00:19:29.940 --> 00:19:32.790
Again, energy being
the key limitation.

00:19:32.790 --> 00:19:34.830
Whether it's for your
cell phone and you're

00:19:34.830 --> 00:19:37.500
doing some kind of machine
learning on your cell phone

00:19:37.500 --> 00:19:40.830
or it's in the cloud, energy
is the key limitation.

00:19:40.830 --> 00:19:44.050
So what we plotted here is
the performance per watt.

00:19:44.050 --> 00:19:47.580
And you see that the first
generation tensor processing

00:19:47.580 --> 00:19:51.900
unit gets roughly more than
30 times the performance

00:19:51.900 --> 00:19:56.400
per watt compared to a
general purpose processor.

00:19:56.400 --> 00:19:58.620
It even does considerably
better than a GPU,

00:19:58.620 --> 00:20:01.260
largely by switching
from floating point

00:20:01.260 --> 00:20:04.780
to lower density integer,
which is much faster.

00:20:04.780 --> 00:20:07.920
So again, this notion of
tailoring the architecture

00:20:07.920 --> 00:20:13.760
to the specific domain
becomes really crucial.

00:20:13.760 --> 00:20:16.000
So this is a new era.

00:20:16.000 --> 00:20:18.910
In some sense, it's
a return to the past.

00:20:18.910 --> 00:20:21.970
In the early days of computing,
as computers were just

00:20:21.970 --> 00:20:24.670
being developed,
we often had teams

00:20:24.670 --> 00:20:26.170
of people working together.

00:20:26.170 --> 00:20:29.327
We had people who were early
applications experts working

00:20:29.327 --> 00:20:31.660
with people who were doing
the beginning of the software

00:20:31.660 --> 00:20:33.610
environment-- building
the first compilers

00:20:33.610 --> 00:20:35.290
and the first
software environment--

00:20:35.290 --> 00:20:37.840
and people doing
the architecture.

00:20:37.840 --> 00:20:41.400
And they're working
as a vertical team.

00:20:41.400 --> 00:20:43.530
That kind of
integration, where we

00:20:43.530 --> 00:20:45.540
get a design team
that understands

00:20:45.540 --> 00:20:48.840
how to go from application
to representation

00:20:48.840 --> 00:20:52.200
in some domain-specific
language to architecture

00:20:52.200 --> 00:20:55.290
and can think about how to
rebuild machines in new ways

00:20:55.290 --> 00:20:59.670
to get this, it's an
enormous opportunity

00:20:59.670 --> 00:21:03.190
and it's a new kind of challenge
for the industry to go forward.

00:21:03.190 --> 00:21:06.600
But I think there are enough
interesting application domains

00:21:06.600 --> 00:21:10.860
like this where we can
get incredible performance

00:21:10.860 --> 00:21:14.580
advantages by tailoring
our machines in a new way.

00:21:14.580 --> 00:21:18.570
And I think if we can do that,
maybe it will free up some time

00:21:18.570 --> 00:21:22.680
to worry about another small
problem, namely cybersecurity

00:21:22.680 --> 00:21:25.380
and whether or not the
hardware designers can finally

00:21:25.380 --> 00:21:27.450
help the software
designers to improve

00:21:27.450 --> 00:21:29.100
the security of our system.

00:21:29.100 --> 00:21:32.791
And that would be a great
problem to focus on.

00:21:32.791 --> 00:21:34.290
Thank you for your
attention and I'm

00:21:34.290 --> 00:21:36.567
happy to answer any
questions you might have.

00:21:36.567 --> 00:21:38.058
[APPLAUSE]

00:21:38.058 --> 00:21:40.050
Thanks.

00:21:40.050 --> 00:21:42.180
AUDIENCE: Can you talk
about some of the advances

00:21:42.180 --> 00:21:44.197
in quantum and
neuromorphic computing?

00:21:44.197 --> 00:21:45.030
JOHN HENNESSY: Yeah.

00:21:45.030 --> 00:21:48.070
So quantum-- that's a
really good question.

00:21:48.070 --> 00:21:50.460
So my view of this
is that we've got

00:21:50.460 --> 00:21:56.900
to build a bridge from where
we are today to post-silicon.

00:21:56.900 --> 00:21:59.349
The possibilities
for post-silicon,

00:21:59.349 --> 00:22:00.140
there are a couple.

00:22:00.140 --> 00:22:02.990
I mean there's organic,
there's quantum,

00:22:02.990 --> 00:22:04.910
there's carbon
nanofiber, there's

00:22:04.910 --> 00:22:08.870
a few different
possibilities out there.

00:22:08.870 --> 00:22:12.230
I characterize them as
technology of the future.

00:22:12.230 --> 00:22:15.260
The reason is the people working
on them are still physicists.

00:22:15.260 --> 00:22:18.170
They're not computer scientists
yet or electrical engineers,

00:22:18.170 --> 00:22:19.370
they're physicists.

00:22:19.370 --> 00:22:20.780
So they're still in the lab.

00:22:20.780 --> 00:22:24.140
On the other hand,
quantum, if it

00:22:24.140 --> 00:22:28.620
works, the computational power
from a reasonably modest sized

00:22:28.620 --> 00:22:34.880
qubit, let's say 128 corrected
qubits, 128 corrected qubits,

00:22:34.880 --> 00:22:36.990
meaning they're
accurate, that might

00:22:36.990 --> 00:22:40.350
take you 1,000 qubits to get
to that level of accuracy.

00:22:40.350 --> 00:22:43.340
But the computational
power for things

00:22:43.340 --> 00:22:46.250
that make sense, protein
folding, cryptography,

00:22:46.250 --> 00:22:50.430
of 128-bit qubit is phenomenal.

00:22:50.430 --> 00:22:53.030
So we could get an enormous
jump forward there.

00:22:53.030 --> 00:22:55.730
We need something post-silicon.

00:22:55.730 --> 00:22:57.200
We need something post-silicon.

00:22:57.200 --> 00:22:59.900
We've got maybe, as
Moore's law slows down,

00:22:59.900 --> 00:23:04.010
maybe another decade or so
before it comes to a real halt.

00:23:04.010 --> 00:23:06.687
And we've got to get an
alternative technology out

00:23:06.687 --> 00:23:09.020
there, because I think there's
lots of creative software

00:23:09.020 --> 00:23:13.626
to be written that wants
to run on faster machines.

00:23:13.626 --> 00:23:15.750
AUDIENCE: I just-- at the
end of your presentation,

00:23:15.750 --> 00:23:19.890
you briefly mentioned how we
could start using hardware

00:23:19.890 --> 00:23:21.270
to increase security.

00:23:21.270 --> 00:23:22.957
Would you mind
elaborating on that?

00:23:22.957 --> 00:23:23.790
JOHN HENNESSY: Sure.

00:23:23.790 --> 00:23:24.720
Sure.

00:23:24.720 --> 00:23:26.820
OK, so here's my
view with security.

00:23:26.820 --> 00:23:30.340
Everybody knows about
Meltdown and Spectre?

00:23:30.340 --> 00:23:31.990
First thing about
Meltdown and Spectre

00:23:31.990 --> 00:23:39.030
is to understand what happened
is an attack that basically

00:23:39.030 --> 00:23:44.280
undermined architecture in a
way that we never anticipated.

00:23:44.280 --> 00:23:48.480
I worked on out-of-order
machines in the mid-1990s.

00:23:48.480 --> 00:23:51.600
That's how long that bug
has been in those machines,

00:23:51.600 --> 00:23:53.430
since the 1990s.

00:23:53.430 --> 00:23:55.020
And we didn't even realize it.

00:23:55.020 --> 00:23:56.370
We didn't even realize it.

00:23:56.370 --> 00:23:59.550
And the reason is that
basically what happens

00:23:59.550 --> 00:24:01.800
is our definition
of architecture was

00:24:01.800 --> 00:24:03.600
there is an instruction set.

00:24:03.600 --> 00:24:04.782
Programs run.

00:24:04.782 --> 00:24:06.240
I don't tell you
how fast they run,

00:24:06.240 --> 00:24:09.030
all I tell you is what
the right answer is.

00:24:09.030 --> 00:24:13.320
Side channel attacks that use
performance to leak information

00:24:13.320 --> 00:24:16.170
basically go around our
definition of architecture.

00:24:16.170 --> 00:24:19.100
So we need to rethink
about architecture.

00:24:19.100 --> 00:24:21.110
You know, in the
1960s and 1970s,

00:24:21.110 --> 00:24:22.860
there was a lot of
thought about how to do

00:24:22.860 --> 00:24:24.570
a better job of protection.

00:24:24.570 --> 00:24:27.720
Rings and domains
and capabilities.

00:24:27.720 --> 00:24:29.310
They all got dropped.

00:24:29.310 --> 00:24:31.120
And they got dropped
because two things.

00:24:31.120 --> 00:24:33.360
First of all, we
became convinced

00:24:33.360 --> 00:24:35.470
that people were going
to verify their software

00:24:35.470 --> 00:24:37.810
and it was always
going to be perfect.

00:24:37.810 --> 00:24:40.740
Well, the problem is that the
amount of software we write

00:24:40.740 --> 00:24:43.410
is far bigger than the amount
of software we ever verify,

00:24:43.410 --> 00:24:45.210
so that's not going to help.

00:24:45.210 --> 00:24:48.240
I think it's time for architects
to begin to think about

00:24:48.240 --> 00:24:52.620
how can they help software
people build systems which

00:24:52.620 --> 00:24:53.820
are more secure?

00:24:53.820 --> 00:24:56.520
What's the right
architecture support

00:24:56.520 --> 00:24:58.030
to make more secure systems?

00:24:58.030 --> 00:24:59.040
How do we build those?

00:24:59.040 --> 00:25:01.620
How do we make sure they
get used effectively?

00:25:01.620 --> 00:25:04.140
And how do we together--
architects and software

00:25:04.140 --> 00:25:07.780
people working together-- create
a more secure environment?

00:25:07.780 --> 00:25:10.080
And I think it's going to
mean thinking back about some

00:25:10.080 --> 00:25:15.100
of those old ideas and bringing
them back in some cases.

00:25:15.100 --> 00:25:17.560
AUDIENCE: After I took my
processor architecture class,

00:25:17.560 --> 00:25:19.332
which used your book--

00:25:19.332 --> 00:25:21.040
JOHN HENNESSY: I hope
it didn't hurt you.

00:25:21.040 --> 00:25:22.040
AUDIENCE: Hopefully not.

00:25:22.040 --> 00:25:25.090
I had a real appreciation
for the simplicity of a risk

00:25:25.090 --> 00:25:26.870
system.

00:25:26.870 --> 00:25:30.370
It seems like we've
gone towards more

00:25:30.370 --> 00:25:33.580
complexity with domain-specific
languages and things.

00:25:33.580 --> 00:25:35.460
Is that just because
of performance

00:25:35.460 --> 00:25:37.870
or has your philosophy changed?

00:25:37.870 --> 00:25:38.860
What do you think?

00:25:38.860 --> 00:25:41.020
JOHN HENNESSY: No, I
actually think they're not

00:25:41.020 --> 00:25:44.000
necessarily more complicated.

00:25:44.000 --> 00:25:48.110
They have a narrower
range of applicability.

00:25:48.110 --> 00:25:50.680
But they're not more
complicated in the sense

00:25:50.680 --> 00:25:54.610
that they are a better match
for what the application is.

00:25:54.610 --> 00:25:57.820
And the key thing to understand
about risk, the key insight

00:25:57.820 --> 00:26:01.660
was we weren't
targeting people writing

00:26:01.660 --> 00:26:03.610
assembly language anymore.

00:26:03.610 --> 00:26:05.920
That was the old way
of doing things, right?

00:26:05.920 --> 00:26:07.960
In the 1980s, the move was on.

00:26:07.960 --> 00:26:10.420
Unix was the first operating
system ever written

00:26:10.420 --> 00:26:12.450
in a high level
language, the first ever.

00:26:12.450 --> 00:26:15.550
The move was on from
assembly language

00:26:15.550 --> 00:26:17.170
to high level languages.

00:26:17.170 --> 00:26:20.290
And what you needed to target
was the compiler output.

00:26:20.290 --> 00:26:21.880
So it's the same thing here.

00:26:21.880 --> 00:26:25.000
You're targeting the output of
a domain-specific language that

00:26:25.000 --> 00:26:27.370
works well for a
range of domains.

00:26:27.370 --> 00:26:31.360
And you design the architecture
to match that environment.

00:26:31.360 --> 00:26:36.300
Make it as simple as
possible, but no simpler.

00:26:36.300 --> 00:26:39.600
AUDIENCE: With the
domain-specific architectures,

00:26:39.600 --> 00:26:41.450
do you have examples
of what might

00:26:41.450 --> 00:26:45.450
be the most promising areas
for future domain-specific

00:26:45.450 --> 00:26:46.675
architectures?

00:26:46.675 --> 00:26:49.050
JOHN HENNESSY: So I think the
most obvious one are things

00:26:49.050 --> 00:26:50.250
related to machine learning.

00:26:50.250 --> 00:26:53.430
I mean, they're computationally
extremely intensive,

00:26:53.430 --> 00:26:57.040
both training as
well as inference.

00:26:57.040 --> 00:26:59.280
So that's one big field.

00:26:59.280 --> 00:27:00.500
Virtual reality.

00:27:00.500 --> 00:27:03.000
Virtual reality and augmented
reality environments.

00:27:03.000 --> 00:27:07.590
If we really want to construct a
high-quality environment that's

00:27:07.590 --> 00:27:10.320
augmented reality, we're
going to need enormous amounts

00:27:10.320 --> 00:27:11.700
of computational power.

00:27:11.700 --> 00:27:13.650
But again, it's
well-structured kinds

00:27:13.650 --> 00:27:17.419
of computations that could match
to those kinds of applications.

00:27:17.419 --> 00:27:18.960
We're not going to
do everything with

00:27:18.960 --> 00:27:20.730
domain-specific architectures.

00:27:20.730 --> 00:27:23.160
They're going to give
us a lift on some

00:27:23.160 --> 00:27:25.020
of the more
computationally-intensive

00:27:25.020 --> 00:27:25.960
problems.

00:27:25.960 --> 00:27:28.293
We're still going to have to
advance and think about how

00:27:28.293 --> 00:27:31.530
to push forward general purpose,
because the general purpose

00:27:31.530 --> 00:27:34.110
machines are going to drive
these domain-specific machines.

00:27:34.110 --> 00:27:36.932
The domain-specific machine
will not do everything for us.

00:27:36.932 --> 00:27:38.640
So we're going to have
to figure out ways

00:27:38.640 --> 00:27:41.682
to go forward on
that front as well.

00:27:41.682 --> 00:27:44.700
AUDIENCE: Professor, what do
we think about some emerging

00:27:44.700 --> 00:27:45.900
memory technology?

00:27:45.900 --> 00:27:48.990
How will it impact the
future computer architecture?

00:27:48.990 --> 00:27:49.490
Thank you.

00:27:49.490 --> 00:27:51.656
JOHN HENNESSY: Yeah, that's
a really great question.

00:27:51.656 --> 00:27:54.030
So as we get to
the end of DRAMs,

00:27:54.030 --> 00:27:58.230
I think some of the more
innovative memory technologies

00:27:58.230 --> 00:28:00.780
are beginning to appear.

00:28:00.780 --> 00:28:02.820
So-called phase
change technologies,

00:28:02.820 --> 00:28:05.220
which have the advantage
that they can probably

00:28:05.220 --> 00:28:08.940
scale better than DRAM
and probably even better

00:28:08.940 --> 00:28:11.400
than Flash technologies.

00:28:11.400 --> 00:28:13.860
They have the advantage that
lifetimes are better, too,

00:28:13.860 --> 00:28:14.430
than Flash.

00:28:14.430 --> 00:28:17.070
The problem with
Flash is it wears out.

00:28:17.070 --> 00:28:19.500
Some of these phase change
memories or memristor

00:28:19.500 --> 00:28:22.650
technologies have the
ability to scale longer.

00:28:22.650 --> 00:28:27.150
And what you'll get is probably
not a replacement for DRAM.

00:28:27.150 --> 00:28:30.060
You'll probably get a
replacement for Flash

00:28:30.060 --> 00:28:31.830
and a replacement for disks.

00:28:31.830 --> 00:28:34.620
And I think that technology
is coming very fast.

00:28:34.620 --> 00:28:37.730
And it'll change the way we
think about memory hierarchies

00:28:37.730 --> 00:28:40.830
and I/O hierarchy, because
you'll have a device that's

00:28:40.830 --> 00:28:43.260
not quite as fast as
DRAM, but a lot faster

00:28:43.260 --> 00:28:44.850
than the other alternatives.

00:28:44.850 --> 00:28:49.070
And that will change the way
we want to build machines.

00:28:49.070 --> 00:28:55.490
AUDIENCE: As a person, you think
about education quite often.

00:28:55.490 --> 00:29:03.290
We all saw Zuckerberg having
a conversation with Congress.

00:29:03.290 --> 00:29:06.920
And I'm excited to
see children getting

00:29:06.920 --> 00:29:11.000
general education around
computing and coding,

00:29:11.000 --> 00:29:12.590
which is something
that a lot of us

00:29:12.590 --> 00:29:14.930
didn't have the
opportunity to have.

00:29:14.930 --> 00:29:21.430
Where do you see education, not
only for K-12, grad, post-grad,

00:29:21.430 --> 00:29:24.710
et cetera, but also
existing people

00:29:24.710 --> 00:29:27.087
in policy-making
decisions, et cetera?

00:29:27.087 --> 00:29:27.920
JOHN HENNESSY: Yeah.

00:29:27.920 --> 00:29:29.750
Well, I think first
of all, education

00:29:29.750 --> 00:29:32.060
has become a lifelong endeavor.

00:29:32.060 --> 00:29:34.940
Nobody has one job for
a lifetime anymore.

00:29:34.940 --> 00:29:38.810
They change what they're doing
and education becomes constant.

00:29:38.810 --> 00:29:40.520
I mean, you think
about the stuff

00:29:40.520 --> 00:29:43.940
you learned as an undergrad and
you think how much technology

00:29:43.940 --> 00:29:45.380
has already changed, right?

00:29:45.380 --> 00:29:46.970
So we have to do more there.

00:29:46.970 --> 00:29:50.360
I think we also
have to make more--

00:29:50.360 --> 00:29:53.990
society needs to be
more technology-savvy.

00:29:53.990 --> 00:29:56.900
Computing is changing
every single part

00:29:56.900 --> 00:29:58.610
of the world we live in.

00:29:58.610 --> 00:30:01.910
To not have some understanding
into that technology,

00:30:01.910 --> 00:30:05.450
I think, limits your ability
to lead an organization,

00:30:05.450 --> 00:30:07.230
to make important decisions.

00:30:07.230 --> 00:30:09.860
So we're going to have to
educate our young people

00:30:09.860 --> 00:30:10.714
at the beginning.

00:30:10.714 --> 00:30:13.130
And we're going to have to
make an investment in education

00:30:13.130 --> 00:30:16.250
so that as people's careers
change over their lifetime,

00:30:16.250 --> 00:30:19.190
they can go back and
engage in education.

00:30:19.190 --> 00:30:20.780
Not necessarily going
back to college,

00:30:20.780 --> 00:30:22.957
it's going to have to
be online in some way.

00:30:22.957 --> 00:30:24.540
But it's going to
have to be engaging.

00:30:24.540 --> 00:30:26.360
It's going to have
to be something that

00:30:26.360 --> 00:30:29.300
really works well for people.

00:30:29.300 --> 00:30:29.855
AUDIENCE: Hi.

00:30:29.855 --> 00:30:31.870
Olly [INAUDIBLE] from BBC.

00:30:31.870 --> 00:30:35.140
Just wondered what your view is
on the amount of energy being

00:30:35.140 --> 00:30:37.466
used on Bitcoin mining
and other cryptocurrencies

00:30:37.466 --> 00:30:40.287
and that sort of thing.

00:30:40.287 --> 00:30:41.120
JOHN HENNESSY: Yeah.

00:30:41.120 --> 00:30:43.430
So I could build a special
purpose architecture

00:30:43.430 --> 00:30:44.230
to mine Bitcoins.

00:30:46.750 --> 00:30:49.135
That's another
obvious example of

00:30:49.135 --> 00:30:52.420
a domain-specific
architecture for sure.

00:30:52.420 --> 00:30:56.320
So I'm a long-term
believer in cryptocurrency

00:30:56.320 --> 00:31:02.014
as an important
part of our space.

00:31:02.014 --> 00:31:03.430
And what we're
going to have to do

00:31:03.430 --> 00:31:05.360
is figure out how
to make it work,

00:31:05.360 --> 00:31:07.680
how to make it work
efficiently, how

00:31:07.680 --> 00:31:12.170
to make it work seamlessly, how
to make it work inexpensively.

00:31:12.170 --> 00:31:15.430
I think those are all problems
that can be conquered.

00:31:15.430 --> 00:31:17.410
And I think you'll
see a bunch of people

00:31:17.410 --> 00:31:20.710
that have both the algorithmic
heft and the ability

00:31:20.710 --> 00:31:24.910
to rethink how we do that, and
really make cryptocurrencies

00:31:24.910 --> 00:31:25.930
go quite quick.

00:31:25.930 --> 00:31:28.840
And then we can also build
machines which accelerate that

00:31:28.840 --> 00:31:30.940
even further, so
that we can make--

00:31:30.940 --> 00:31:34.540
a cryptocurrency transaction
should be faster than a cash

00:31:34.540 --> 00:31:37.510
transaction and certainly
no slower than a credit card

00:31:37.510 --> 00:31:38.410
transaction.

00:31:38.410 --> 00:31:39.670
We're not there yet.

00:31:39.670 --> 00:31:40.804
But we can get there.

00:31:40.804 --> 00:31:42.220
We can get there
with enough work.

00:31:42.220 --> 00:31:45.370
And I think that's where
we ought to be moving to.

00:31:45.370 --> 00:31:49.270
AUDIENCE: What do you think
the future operating system has

00:31:49.270 --> 00:31:51.127
to have to cope with this?

00:31:51.127 --> 00:31:51.960
JOHN HENNESSY: Yeah.

00:31:51.960 --> 00:31:54.700
The future of operating
system, you said, yes?

00:31:54.700 --> 00:31:55.330
Yeah.

00:31:55.330 --> 00:31:57.820
So I think operating
systems are really crucial.

00:31:57.820 --> 00:32:01.614
You know, way back
when in the 1980s,

00:32:01.614 --> 00:32:04.030
we thought we were going to
solve all our operating system

00:32:04.030 --> 00:32:06.970
problems by going to
kernel-based operating systems.

00:32:06.970 --> 00:32:10.540
And the kernel would be this
really small little thing

00:32:10.540 --> 00:32:13.750
that just did the core functions
of protection and memory

00:32:13.750 --> 00:32:14.800
management.

00:32:14.800 --> 00:32:17.290
And then, everything
else around it

00:32:17.290 --> 00:32:19.990
would be protected, basically.

00:32:19.990 --> 00:32:21.700
And what happened was
kernel started out

00:32:21.700 --> 00:32:24.619
really small and then they got
bigger and then they got bigger

00:32:24.619 --> 00:32:25.660
and then they got bigger.

00:32:25.660 --> 00:32:27.951
And all of a sudden, almost
the entire operating system

00:32:27.951 --> 00:32:33.940
was in the kernel, primarily to
make it performance-efficient.

00:32:33.940 --> 00:32:35.800
And the same thing
happen with hypervisors.

00:32:35.800 --> 00:32:38.630
They started really small
in the very beginning

00:32:38.630 --> 00:32:39.945
and then they got bigger.

00:32:39.945 --> 00:32:41.320
We're going to
have to figure out

00:32:41.320 --> 00:32:45.490
how we structure complex
operating systems

00:32:45.490 --> 00:32:48.520
so that they can deal with
the protection issues,

00:32:48.520 --> 00:32:51.884
they can deal with efficiency
issues, they can work well.

00:32:51.884 --> 00:32:53.800
We should be building
operating systems which,

00:32:53.800 --> 00:32:56.350
from the beginning,
realize that they're

00:32:56.350 --> 00:32:58.780
going to run on large
numbers of processors,

00:32:58.780 --> 00:33:00.760
and organize them in
such a way that they

00:33:00.760 --> 00:33:02.200
can do that efficiently.

00:33:02.200 --> 00:33:06.004
Because that's the future, we're
going to have to rely on that.

00:33:06.004 --> 00:33:07.420
AUDIENCE: In your
intro video, you

00:33:07.420 --> 00:33:11.530
mentioned this chasm between
concept and practice.

00:33:11.530 --> 00:33:14.440
And also in your
talk, you've mentioned

00:33:14.440 --> 00:33:18.520
that hardware is vital to
the future of computing.

00:33:18.520 --> 00:33:22.120
Given that most investors
are very hardware-averse,

00:33:22.120 --> 00:33:24.040
especially this day
and age, where do you

00:33:24.040 --> 00:33:25.600
expect that money to come from?

00:33:25.600 --> 00:33:27.940
Is that something that
will come from governments

00:33:27.940 --> 00:33:30.400
or private investing?

00:33:30.400 --> 00:33:33.280
How are we going to fund
the future of computing

00:33:33.280 --> 00:33:34.590
is really what my question is.

00:33:34.590 --> 00:33:36.339
JOHN HENNESSY: Yeah,
it's a good question.

00:33:36.339 --> 00:33:39.430
I mean, I think
the answer is both.

00:33:39.430 --> 00:33:42.460
You know, certainly Google's
making large investments

00:33:42.460 --> 00:33:45.490
in a lot of these technologies
from quantum to other things.

00:33:45.490 --> 00:33:48.610
I think government
remains a player.

00:33:48.610 --> 00:33:51.160
So government, you look at
how many of the innovations

00:33:51.160 --> 00:33:52.090
we're used to.

00:33:52.090 --> 00:33:55.300
The internet, risk,
the rise of VLSI,

00:33:55.300 --> 00:33:58.320
modern computer-aided
design tools.

00:33:58.320 --> 00:34:01.000
All had funding basically
coming from the government

00:34:01.000 --> 00:34:02.060
at some point.

00:34:02.060 --> 00:34:04.810
So I think the government
should still remain a player

00:34:04.810 --> 00:34:06.520
in thinking about--

00:34:06.520 --> 00:34:08.920
what's the one area the
government has probably funded

00:34:08.920 --> 00:34:10.929
longer than anybody else?

00:34:10.929 --> 00:34:13.030
Artificial intelligence.

00:34:13.030 --> 00:34:16.030
They funded it for 50
years before we really

00:34:16.030 --> 00:34:18.440
saw the breakthrough that came.

00:34:18.440 --> 00:34:18.940
Right?

00:34:18.940 --> 00:34:20.090
So they're big believers.

00:34:20.090 --> 00:34:22.130
They should be funding
things long-term.

00:34:22.130 --> 00:34:25.120
They should fund things that
are out over the horizon

00:34:25.120 --> 00:34:27.670
that we don't yet
really understand

00:34:27.670 --> 00:34:29.770
what their practical
implications may be.

00:34:29.770 --> 00:34:30.680
So I think we're going
to have to have that

00:34:30.680 --> 00:34:33.179
and we're going to have to have
industry playing a big role.

00:34:33.179 --> 00:34:35.110
And we're going to have
to make universities

00:34:35.110 --> 00:34:37.540
work well with industry, because
they complement one another,

00:34:37.540 --> 00:34:38.040
right?

00:34:38.040 --> 00:34:39.727
They do two different
kinds of things

00:34:39.727 --> 00:34:40.810
but they're complementary.

00:34:40.810 --> 00:34:42.550
And if we can get
them to work well,

00:34:42.550 --> 00:34:45.376
then we can have the
best of both worlds.

00:34:45.376 --> 00:34:46.750
AUDIENCE: You
talked a little bit

00:34:46.750 --> 00:34:50.850
about the difference
between the memory hierarchy

00:34:50.850 --> 00:34:53.440
and storage that is coming
up with these new memory

00:34:53.440 --> 00:34:54.620
technologies.

00:34:54.620 --> 00:34:56.770
Have you seen any
applications where

00:34:56.770 --> 00:35:01.900
the compute and the
storage get combined,

00:35:01.900 --> 00:35:03.610
kind of more like the brain?

00:35:03.610 --> 00:35:05.800
JOHN HENNESSY: Yeah, I
think increasingly we'll

00:35:05.800 --> 00:35:07.900
see things move
towards that direction

00:35:07.900 --> 00:35:13.150
where the software takes care
of the difference between what

00:35:13.150 --> 00:35:16.480
is in storage and-- "storage,"
quote unquote, right,

00:35:16.480 --> 00:35:19.720
because it may actually be Flash
or some kind of next generation

00:35:19.720 --> 00:35:22.930
memory technology--
and what's in DRAM.

00:35:22.930 --> 00:35:26.690
What you need to tell
me is what's volatile

00:35:26.690 --> 00:35:30.970
and when do I have to ensure
that a particular operation is

00:35:30.970 --> 00:35:33.730
committed to
nonvolatile storage.

00:35:33.730 --> 00:35:36.950
But if you know that, we've
got log base file systems,

00:35:36.950 --> 00:35:39.790
you've got other ideas which
move in the direction of trying

00:35:39.790 --> 00:35:45.044
to take advantage of a much
greatly different memory

00:35:45.044 --> 00:35:46.960
hierarchy, greatly
different storage hierarchy

00:35:46.960 --> 00:35:48.040
than we're used to.

00:35:48.040 --> 00:35:50.660
And we may want to continue
to move in that direction,

00:35:50.660 --> 00:35:52.610
particularly when you
begin to think about--

00:35:52.610 --> 00:35:56.350
if you think about things
like networking or I/O

00:35:56.350 --> 00:35:59.620
and they become major
bottlenecks in applications,

00:35:59.620 --> 00:36:02.230
which they often
do, then rethinking

00:36:02.230 --> 00:36:04.720
how we could do
those efficiently

00:36:04.720 --> 00:36:07.970
and optimize the hardware,
but also the software.

00:36:07.970 --> 00:36:10.697
Because the minute you stick
an operating system transaction

00:36:10.697 --> 00:36:12.280
in there, you've
added a lot of weight

00:36:12.280 --> 00:36:15.320
to what it costs to get
to that storage facility.

00:36:15.320 --> 00:36:17.380
So if we can make that
work better and make

00:36:17.380 --> 00:36:20.740
it more transparent without
giving up protection,

00:36:20.740 --> 00:36:23.350
without giving up a guarantee
that once something is written

00:36:23.350 --> 00:36:26.740
to a certain storage unit
it's permanently recorded,

00:36:26.740 --> 00:36:29.780
then I think we can make
much faster systems.

00:36:29.780 --> 00:36:32.350
AUDIENCE: So do you
see the implementation

00:36:32.350 --> 00:36:35.110
of a domain-specific
architecture being implemented

00:36:35.110 --> 00:36:38.590
as hetero type or do you see
it off-die, off-chip type

00:36:38.590 --> 00:36:40.244
implementations, or both?

00:36:40.244 --> 00:36:41.410
JOHN HENNESSY: I think both.

00:36:41.410 --> 00:36:45.200
I mean, I think it's a
time of great change.

00:36:45.200 --> 00:36:48.580
The rise of FPGAs,
for example, gives you

00:36:48.580 --> 00:36:51.820
the opportunity to implement
these machines, try them out.

00:36:51.820 --> 00:36:53.710
Implement them in
FPGA before you're

00:36:53.710 --> 00:36:55.950
committed to design a
custom silicon chip.

00:36:55.950 --> 00:36:57.670
Put it in an FPGA.

00:36:57.670 --> 00:36:59.080
Unleash it on the world.

00:36:59.080 --> 00:37:01.060
Try it out, see
how it works, see

00:37:01.060 --> 00:37:03.414
how the applications map to it.

00:37:03.414 --> 00:37:05.080
And then, perhaps,
decide whether or not

00:37:05.080 --> 00:37:06.580
you want to freeze
the architecture.

00:37:06.580 --> 00:37:10.360
Or you may just want to build
another next generation FPGA.

00:37:10.360 --> 00:37:12.730
So I think we'll see lots
of different implementation

00:37:12.730 --> 00:37:13.570
approaches.

00:37:13.570 --> 00:37:16.116
The one thing we have to do--

00:37:16.116 --> 00:37:18.490
you know, there was a big
breakthrough in how hard it was

00:37:18.490 --> 00:37:21.170
to design chips that
occurred from about

00:37:21.170 --> 00:37:25.060
the mid-'80s to
about 1995 or 2000.

00:37:25.060 --> 00:37:27.320
Things have kind of ground
to a halt since then.

00:37:27.320 --> 00:37:28.990
We haven't had another big--

00:37:28.990 --> 00:37:30.910
we need a big
breakthrough because we're

00:37:30.910 --> 00:37:34.570
going to need many more people
designing processors targeting

00:37:34.570 --> 00:37:36.284
particular application domains.

00:37:36.284 --> 00:37:38.950
And that's going to mean we need
to make it much easier and much

00:37:38.950 --> 00:37:42.250
cheaper to design a processor.

00:37:42.250 --> 00:37:45.070
AUDIENCE: I'm wondering,
as a deep learning engineer

00:37:45.070 --> 00:37:46.930
for a private
enterprise, what is

00:37:46.930 --> 00:37:49.397
my role in pushing forward DSA?

00:37:49.397 --> 00:37:50.230
JOHN HENNESSY: Yeah.

00:37:50.230 --> 00:37:53.140
Well, I think your role
is vital because we

00:37:53.140 --> 00:37:56.140
need people who really
understand the application

00:37:56.140 --> 00:37:56.950
space.

00:37:56.950 --> 00:37:58.420
And that's really critical.

00:37:58.420 --> 00:37:59.360
And this is a change.

00:37:59.360 --> 00:38:04.334
I mean, if you think about how
much architects and computer

00:38:04.334 --> 00:38:05.750
designers, hardware
designers have

00:38:05.750 --> 00:38:07.600
had to think about
the applications,

00:38:07.600 --> 00:38:09.430
they haven't had to
think about them.

00:38:09.430 --> 00:38:10.510
All of a sudden,
they're going to have

00:38:10.510 --> 00:38:11.890
to develop a bunch
of new friends

00:38:11.890 --> 00:38:13.390
that they can
interact with and talk

00:38:13.390 --> 00:38:16.090
to and colleagues they can
work with, to really get

00:38:16.090 --> 00:38:21.190
the insights they need in order
to push forward the technology.

00:38:21.190 --> 00:38:23.290
And that's going to be
a big change for us,

00:38:23.290 --> 00:38:24.730
but I think it's something
that's absolutely crucial.

00:38:24.730 --> 00:38:26.380
And it's great for
the industry too,

00:38:26.380 --> 00:38:28.240
because all of a
sudden we get people

00:38:28.240 --> 00:38:30.310
who are application
experts beginning

00:38:30.310 --> 00:38:32.440
to talk people who are
software domain experts

00:38:32.440 --> 00:38:34.360
or talk to hardware people.

00:38:34.360 --> 00:38:36.274
That's a terrific thing.

00:38:36.274 --> 00:38:38.440
AUDIENCE: You mentioned the
performance enhancements

00:38:38.440 --> 00:38:41.961
of domain-specific languages
over Python, for instance,

00:38:41.961 --> 00:38:43.460
but they're also
much harder to use.

00:38:43.460 --> 00:38:45.700
So do you think software
engineering talent

00:38:45.700 --> 00:38:47.327
can keep up in the future?

00:38:47.327 --> 00:38:48.160
JOHN HENNESSY: Yeah.

00:38:48.160 --> 00:38:50.860
I think the challenge will be--

00:38:50.860 --> 00:38:52.660
the gain we've
gotten in software

00:38:52.660 --> 00:38:56.080
productivity in the
last 20 or 30 years

00:38:56.080 --> 00:38:57.710
is absolutely stunning.

00:38:57.710 --> 00:38:59.660
It is absolutely stunning.

00:38:59.660 --> 00:39:01.390
I mean, a programmer
now can probably

00:39:01.390 --> 00:39:06.220
write 10 to 100 times more code
than they could 30 years ago,

00:39:06.220 --> 00:39:07.960
in terms of functionality.

00:39:07.960 --> 00:39:08.710
That's phenomenal.

00:39:08.710 --> 00:39:12.100
We cannot give that up because
that's what's created all these

00:39:12.100 --> 00:39:13.840
incredible applications we have.

00:39:13.840 --> 00:39:15.640
What we need to
do is figure out--

00:39:15.640 --> 00:39:19.150
all of a sudden, we need a new
generation of compiler people

00:39:19.150 --> 00:39:21.460
to think about how do we
make those run efficiently.

00:39:21.460 --> 00:39:25.480
And by the way, if the
gap is a factor of 25

00:39:25.480 --> 00:39:28.340
between C and
Python, for example,

00:39:28.340 --> 00:39:30.520
if you get only
half that, that's

00:39:30.520 --> 00:39:32.860
a factor of 12 times faster.

00:39:32.860 --> 00:39:34.540
Any compiler writer
that can produce

00:39:34.540 --> 00:39:37.570
code that runs 12 times
faster is a hero in my book.

00:39:37.570 --> 00:39:39.460
So we have to just
think about new ways

00:39:39.460 --> 00:39:40.780
to approach the problem.

00:39:40.780 --> 00:39:43.800
And the opportunity
is tremendous.

00:39:43.800 --> 00:39:47.070
AUDIENCE: Are there any
opportunities still left in x86

00:39:47.070 --> 00:39:50.430
as far as, like, lifting
the complexity of the ISA

00:39:50.430 --> 00:39:53.670
into software and exposing
more microarchitecture

00:39:53.670 --> 00:39:55.107
to the compiler?

00:39:55.107 --> 00:39:56.190
JOHN HENNESSY: It's tough.

00:39:56.190 --> 00:40:01.230
I mean, I think the Intel
people have spent more time

00:40:01.230 --> 00:40:05.160
implementing x86s than anybody's
ever spent implementing one

00:40:05.160 --> 00:40:08.970
ISA, one instruction set ever.

00:40:08.970 --> 00:40:12.310
They've mined out almost
all the performance.

00:40:12.310 --> 00:40:16.170
And in fact, if you look at the
tweaks that occur, for example,

00:40:16.170 --> 00:40:19.260
they do aggressive
prefetching in the i7.

00:40:19.260 --> 00:40:23.190
But you look at what happens
with prefetching, some programs

00:40:23.190 --> 00:40:25.020
actually slow down.

00:40:25.020 --> 00:40:27.960
Now on balance, they get a
little bit of speed up from it,

00:40:27.960 --> 00:40:29.826
but they actually slow
down other programs.

00:40:29.826 --> 00:40:31.200
And the problem
right now is it's

00:40:31.200 --> 00:40:34.920
very hard to turn that
dial in such a way

00:40:34.920 --> 00:40:38.370
that we don't get overwhelmed
with negative things.

00:40:38.370 --> 00:40:41.645
And I see my producer telling
me it's the end of the session.

00:40:41.645 --> 00:40:43.020
Thank you for the
great questions

00:40:43.020 --> 00:40:44.558
and for your attention.

00:40:44.558 --> 00:40:46.510
[APPLAUSE]

00:40:46.510 --> 00:40:51.664
[MUSIC PLAYING]

