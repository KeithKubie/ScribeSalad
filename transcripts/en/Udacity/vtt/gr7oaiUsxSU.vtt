WEBVTT
Kind: captions
Language: en

00:00:00.250 --> 00:00:02.320
All of you know how a simple procedure call

00:00:02.320 --> 00:00:06.030
works. There is a caller you have a process in

00:00:06.030 --> 00:00:10.380
which all the functions are being compiled together and

00:00:10.380 --> 00:00:13.150
linked together, made an make an executable. And so when

00:00:13.150 --> 00:00:15.390
a caller makes a call to the callee, it

00:00:15.390 --> 00:00:18.630
makes a call passing the arguments on the stack. The

00:00:18.630 --> 00:00:22.040
callee can execute the procedure. And then a return

00:00:22.040 --> 00:00:25.580
to the caller. So this is your simple procedure call.

00:00:25.580 --> 00:00:28.910
And the important thing is that all of the interactions

00:00:28.910 --> 00:00:32.320
that I'm showing you here is happening at compile time. All

00:00:32.320 --> 00:00:34.850
of these things are being done at compile time. Now

00:00:34.850 --> 00:00:38.770
let's see what happens with remote procedure call. You know in

00:00:38.770 --> 00:00:42.220
principle a remote procedure call looks exactly like this picture.

00:00:42.220 --> 00:00:44.650
That you have a caller and a callee. SO the caller

00:00:44.650 --> 00:00:48.480
is making a call Executing a procedure, and returning. So

00:00:48.480 --> 00:00:51.770
that's what is going on in, in a remote procedure call.

00:00:51.770 --> 00:00:55.130
But under the cover, let's see what's going on

00:00:55.130 --> 00:00:57.690
when you're using remote procedure call. When the caller

00:00:57.690 --> 00:01:00.480
makes its call, it's really is a trap into

00:01:00.480 --> 00:01:03.200
the kernel. A caller trap into the kernel. And

00:01:03.200 --> 00:01:06.790
what the kernel does is, it validates the call.

00:01:06.790 --> 00:01:09.830
And it copies the arguments of the call into

00:01:09.830 --> 00:01:13.100
kernel buffers from the client idle space. The kernel

00:01:13.100 --> 00:01:16.820
then locates the server procedure that needs to be

00:01:16.820 --> 00:01:20.850
executed, copies the arguments that it has buffered

00:01:20.850 --> 00:01:24.390
in the kernel buffer into the idle space

00:01:24.390 --> 00:01:26.940
of the server. And, once it has done

00:01:26.940 --> 00:01:30.560
that, it schedules the server to run the particular

00:01:30.560 --> 00:01:33.290
procedure. So that's what's going on in this,

00:01:33.290 --> 00:01:35.360
in this direction. At this point, the server

00:01:35.360 --> 00:01:38.910
procedure actually starts executing using the arguments of

00:01:38.910 --> 00:01:42.190
the call, and performs a function that was requested

00:01:42.190 --> 00:01:45.370
by the client. When the server procedure is done

00:01:45.370 --> 00:01:49.890
with execution of the procedure. It needs to return

00:01:49.890 --> 00:01:52.830
the results of this procedure execution back to the

00:01:52.830 --> 00:01:56.120
client. And, in order to do that, it's going to

00:01:56.120 --> 00:01:58.610
tap into the kernel, there's the return trap that

00:01:58.610 --> 00:02:02.070
the server is experiencing in order to return the

00:02:02.070 --> 00:02:04.750
results back to the client. And, what the Kernel

00:02:04.750 --> 00:02:07.570
does at this point. Is to copy the results

00:02:07.570 --> 00:02:11.870
from the address space of the server into

00:02:11.870 --> 00:02:14.860
the kernel buffers and then it copies out the

00:02:14.860 --> 00:02:18.100
results from the kernel buffer into the client's address

00:02:18.100 --> 00:02:21.600
space and now at this point, we have completed

00:02:21.600 --> 00:02:24.080
sending the results back to the client. So the

00:02:24.080 --> 00:02:27.060
kernel can then reschedule the client who can then

00:02:27.060 --> 00:02:29.670
receive the results. And go on its merry way

00:02:29.670 --> 00:02:32.840
of executing whatever it was doing. So that's essentially

00:02:32.840 --> 00:02:35.340
what's going on under the cover. So even though the

00:02:35.340 --> 00:02:38.270
picture is so clean up here, that a client is making

00:02:38.270 --> 00:02:40.830
a call and you get the results and it can continue

00:02:40.830 --> 00:02:44.260
with whatever it was doing. In reality, what is going on

00:02:44.260 --> 00:02:48.370
under the cover is fairly complex. And more importantly, all of

00:02:48.370 --> 00:02:51.510
these actions are happening at runtime as opposed to What I

00:02:51.510 --> 00:02:54.580
mentioned about a procedure call, where everything is happening in compile

00:02:54.580 --> 00:02:58.120
time, all of these actions are happening at run time, and

00:02:58.120 --> 00:03:01.990
that is one of the fundamental sources of performance

00:03:01.990 --> 00:03:05.100
hit that an RPC system is going to take in

00:03:05.100 --> 00:03:08.260
the fact that everything is being done at the time

00:03:08.260 --> 00:03:11.540
of the call. In particular, if you want to analyze all

00:03:11.540 --> 00:03:14.910
the overheads that... Or the works that needs to

00:03:14.910 --> 00:03:17.920
get done at run time. There are two traps. The

00:03:17.920 --> 00:03:20.770
first trap is a call trap. The other trap is

00:03:20.770 --> 00:03:23.120
a return trap. There are two traps, and there are

00:03:23.120 --> 00:03:25.340
two context switches. So, the first context switch

00:03:25.340 --> 00:03:28.370
is when the kernel switches from the client to

00:03:28.370 --> 00:03:30.840
the server to the run the server procedure. And

00:03:30.840 --> 00:03:33.960
when the server procedure is done with its execution

00:03:33.960 --> 00:03:36.740
of the server procedure, it has to reschedule

00:03:36.740 --> 00:03:39.580
the client to run again. So, two traps, two

00:03:39.580 --> 00:03:43.190
context switches, and one procedure execution. That's the work

00:03:43.190 --> 00:03:48.560
that is being done by the runtime system in

00:03:48.560 --> 00:03:51.330
order to execute this remote procedure call. So what

00:03:51.330 --> 00:03:53.890
are all the sources of overhead now? Well, first of

00:03:53.890 --> 00:03:56.720
all, when this call trap happens, the kernel has

00:03:56.720 --> 00:04:00.810
to validate the access, whether this client is allowed to

00:04:00.810 --> 00:04:03.170
make this procedure call or not the validation has

00:04:03.170 --> 00:04:07.030
to happen. And then it has to copy the arguments

00:04:07.030 --> 00:04:10.690
from the client's address space into kernel buffers. And

00:04:10.690 --> 00:04:14.390
potentially, if you look at this picture, there could multiple

00:04:14.390 --> 00:04:16.110
copies that are going to happen in order to

00:04:16.110 --> 00:04:18.160
do this exchange between the client and the server,

00:04:18.160 --> 00:04:22.150
and then there is the scheduling of the server

00:04:22.150 --> 00:04:25.980
in order to run the server code and then there

00:04:25.980 --> 00:04:28.930
is the context which overhead, we talked about. The

00:04:28.930 --> 00:04:32.980
explicit and implicit costs of doing context switches, there is

00:04:32.980 --> 00:04:36.810
a context which overhead that is associated between but,

00:04:36.810 --> 00:04:39.970
when we go from the client to the server and

00:04:39.970 --> 00:04:42.940
back again to the client from the server,

00:04:42.940 --> 00:04:44.930
and of course dispatching a thread on the

00:04:44.930 --> 00:04:48.080
processor itself is also time, which is explicit

00:04:48.080 --> 00:04:51.850
cost of scheduling. So, before we discuss how

00:04:51.850 --> 00:04:55.500
we can reduce the overheads in this remote

00:04:55.500 --> 00:04:58.000
procedure call, when the clients and the servers

00:04:58.000 --> 00:05:02.190
happen to be on the same machine, let me prime the pump with a, with a quiz.

