WEBVTT
Kind: captions
Language: en

00:00:00.230 --> 00:00:01.630
Alright, so what I'd like to do is work up

00:00:01.630 --> 00:00:06.735
to a proof that K-means does something good. [LAUGH] And to

00:00:06.735 --> 00:00:09.272
do that I think it's helpful to have little bit more

00:00:09.272 --> 00:00:12.190
precise notation than what I was doing before. So here we

00:00:12.190 --> 00:00:14.210
go, let's, we're going to work up to doing K-means in

00:00:14.210 --> 00:00:18.081
a Euclidean space. And the notation that I'm going to use is,

00:00:18.081 --> 00:00:20.364
we've got at any given moment in time in the algorithm,

00:00:20.364 --> 00:00:25.310
there's some partition, p super t of x. And these clusters

00:00:25.310 --> 00:00:28.140
are defined the same way that we did before, which

00:00:28.140 --> 00:00:30.660
it just returns the, you know, some kind of identifier

00:00:30.660 --> 00:00:33.480
for cluster x is in and this is at iteration

00:00:33.480 --> 00:00:37.670
t of K-means. We also have another kind of more convenient

00:00:37.670 --> 00:00:41.110
way of writing that which is C sub i of

00:00:41.110 --> 00:00:43.730
t, which is the set of all points in cluster

00:00:43.730 --> 00:00:46.070
i. It's really just the same as the set x,

00:00:46.070 --> 00:00:49.340
such that p of x equals i. Does that make sense?

00:00:49.340 --> 00:00:50.655
&gt;&gt; Yeah, okay that makes perfect sense.

00:00:50.655 --> 00:00:53.510
You've got some kind of partition, and everything in the

00:00:53.510 --> 00:00:57.630
same partition belongs together in something you're calling C for cluster.

00:00:59.475 --> 00:01:01.870
&gt;&gt; Good, and we're also going to need to be able to refer to the

00:01:01.870 --> 00:01:03.670
center of a cluster because we're in

00:01:03.670 --> 00:01:06.600
a Euclidean space, it's meaningful to add the

00:01:06.600 --> 00:01:09.220
objects together. So, take all the objects

00:01:09.220 --> 00:01:11.580
that are in some cluster, Ci at iteration

00:01:11.580 --> 00:01:15.680
t and divide by the number of objects in that cluster. So just summing those

00:01:15.680 --> 00:01:17.840
points together. This is also sometimes called the centroid, right?

00:01:17.840 --> 00:01:19.730
&gt;&gt; Right, so it's the mean or the centroid.

00:01:19.730 --> 00:01:22.630
&gt;&gt; Yeah it's like. That's right. I mean in one dimension it's

00:01:22.630 --> 00:01:26.385
definitely the mean. In higher dimensions it's like a per dimension mean.

00:01:26.385 --> 00:01:29.690
&gt;&gt; Oh, so in fact you're going to end up with K means.

00:01:30.790 --> 00:01:33.230
&gt;&gt; Oh, I see what you did there.

00:01:33.230 --> 00:01:33.660
&gt;&gt; Mm.

00:01:33.660 --> 00:01:36.920
&gt;&gt; So now, here's an equation arrow version of the algorithm,

00:01:36.920 --> 00:01:40.580
that we start off picking centers in some way for iteration zero,

00:01:40.580 --> 00:01:45.680
and we hand it over to this process that's going to assign the partitions. In

00:01:45.680 --> 00:01:52.130
particular, the partition of point x is going to be the minimum over

00:01:52.130 --> 00:01:56.610
all the clusters of the distance between x and the center of that cluster.

00:01:56.610 --> 00:01:58.700
Alright, so it's just assigning each point

00:01:58.700 --> 00:02:01.083
to its closest center. Does that make sense?

00:02:01.083 --> 00:02:02.850
&gt;&gt; Mm-hm, and that all those bars

00:02:02.850 --> 00:02:05.310
with the sub two just mean Euclidean distance.

00:02:05.310 --> 00:02:05.540
&gt;&gt; Yeah,

00:02:05.540 --> 00:02:07.690
we're just, that's right, exactly. We just computing the distance

00:02:07.690 --> 00:02:13.530
between those two things. And we hand that partition over

00:02:13.530 --> 00:02:16.550
to the process that computes the center. So it's, it's

00:02:16.550 --> 00:02:20.305
now using this other representation of the clustering Ci, it's

00:02:20.305 --> 00:02:22.600
adding the points together, divided by the number of points

00:02:22.600 --> 00:02:25.200
in that cluster, and it hands those centers back to

00:02:25.200 --> 00:02:27.560
this first process to recompute the cluster. So we're just

00:02:27.560 --> 00:02:30.700
going to be ping-ponging back and forth between these two processes.

00:02:30.700 --> 00:02:31.200
&gt;&gt; Okay.

00:02:31.200 --> 00:02:31.350
&gt;&gt; Good?

00:02:31.350 --> 00:02:34.160
&gt;&gt; Sure, and t keeps getting updated after every cycle.

00:02:34.160 --> 00:02:39.930
&gt;&gt; Right, yes. So, this is where t gets incremented, t plus plus. So this is

00:02:39.930 --> 00:02:42.030
the algorithm, and an interesting fact about it

00:02:42.030 --> 00:02:44.580
is: Do you remember when we talked about optimization?

00:02:44.580 --> 00:02:47.400
&gt;&gt; I do remember when we talked about optimization.

00:02:47.400 --> 00:02:48.990
&gt;&gt; And optimization is good because it's finding

00:02:48.990 --> 00:02:52.090
better and better answers. So if we can think

00:02:52.090 --> 00:02:53.640
of this as being kind of an optimization

00:02:53.640 --> 00:02:55.750
algorithm then that could be good. It could be

00:02:55.750 --> 00:02:57.750
that that what we're doing, what we're going around here

00:02:57.750 --> 00:03:01.500
is not just randomly reassigning things, but actually improving things.

00:03:01.500 --> 00:03:03.610
&gt;&gt; Okay. Well how are you going to convince me of that?

00:03:03.610 --> 00:03:05.770
&gt;&gt; Alright, let's do that.

