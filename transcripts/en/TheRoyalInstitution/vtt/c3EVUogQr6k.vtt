WEBVTT
Kind: captions
Language: en-US

00:00:05.772 --> 00:00:09.139
[APPLAUSE]

00:00:10.110 --> 00:00:11.430
Thank you very much, Clive.

00:00:11.430 --> 00:00:13.590
And thanks very much
everyone for coming out

00:00:13.590 --> 00:00:15.840
on this rather
warm evening, which

00:00:15.840 --> 00:00:19.470
is really impressive for
someone even from Australia.

00:00:19.470 --> 00:00:22.680
So synthetic intelligence.

00:00:22.680 --> 00:00:24.690
So what is intelligence?

00:00:24.690 --> 00:00:28.770
It's something that is quite
subtle and very difficult

00:00:28.770 --> 00:00:30.930
to put your finger on.

00:00:30.930 --> 00:00:36.000
The adjective synthetic
refers to something

00:00:36.000 --> 00:00:39.840
that is manmade, that is a
replica of something that

00:00:39.840 --> 00:00:41.650
occurs in nature.

00:00:41.650 --> 00:00:43.830
So we often use
the word synthetic

00:00:43.830 --> 00:00:47.200
when we're talking about
synthetic fabrics, for example,

00:00:47.200 --> 00:00:51.570
or perhaps synthetic molecules,
like insulin for example.

00:00:51.570 --> 00:00:55.770
So synthetic intelligence
gives the connotation

00:00:55.770 --> 00:01:00.060
that it's intelligence that
we're making ourselves.

00:01:00.060 --> 00:01:02.700
But how does it differ from
artificial intelligence?

00:01:02.700 --> 00:01:04.290
You're all probably
quite familiar

00:01:04.290 --> 00:01:06.900
with artificial intelligence
even though you might not fully

00:01:06.900 --> 00:01:09.030
understand it yourselves.

00:01:09.030 --> 00:01:11.280
So my talk this
evening is actually

00:01:11.280 --> 00:01:16.530
going to be about this new thing
called synthetic intelligence

00:01:16.530 --> 00:01:20.050
that is actually quite different
from artificial intelligence.

00:01:20.050 --> 00:01:22.050
And I'm going to tell you
a little bit about how

00:01:22.050 --> 00:01:24.820
it differs, and
why it's important,

00:01:24.820 --> 00:01:28.650
and how it might bring us
even closer to understanding

00:01:28.650 --> 00:01:32.220
real human intelligence.

00:01:32.220 --> 00:01:36.970
I've divided my talk very
roughly into three parts.

00:01:36.970 --> 00:01:38.460
The first part of
my talk I wanted

00:01:38.460 --> 00:01:40.530
to put things into
context and just give you

00:01:40.530 --> 00:01:45.060
a really broad overview of what
artificial intelligence is.

00:01:45.060 --> 00:01:49.110
And I'm going to do that because
I want to explain to you why

00:01:49.110 --> 00:01:52.920
artificial intelligence is
artificial, how it differs

00:01:52.920 --> 00:01:56.170
from real human intelligence.

00:01:56.170 --> 00:01:58.850
And then I'm going to tell you
a little bit about some cutting

00:01:58.850 --> 00:02:03.980
edge research that
involves actually making

00:02:03.980 --> 00:02:09.199
manmade devices that
replicate the human brain,

00:02:09.199 --> 00:02:13.970
a synthetic brain, and
how we can try and emulate

00:02:13.970 --> 00:02:18.260
thinking processes from these
devices that we've made.

00:02:18.260 --> 00:02:19.880
In the last part
of my talk, which

00:02:19.880 --> 00:02:21.254
is going to be
the shortest part,

00:02:21.254 --> 00:02:25.040
I'm just going to wrap up a
little bit with some ideas,

00:02:25.040 --> 00:02:27.616
some viewpoints of my own.

00:02:27.616 --> 00:02:29.240
And, of course, I'll
be looking forward

00:02:29.240 --> 00:02:32.630
to hearing your comments
and questions afterwards.

00:02:32.630 --> 00:02:34.520
Before that, as
Clive mentioned, he's

00:02:34.520 --> 00:02:37.790
also going to have a bit
of a discussion with me

00:02:37.790 --> 00:02:40.110
around this topic as well.

00:02:40.110 --> 00:02:42.690
So let's get started.

00:02:42.690 --> 00:02:47.250
So all of you by now have heard
of artificial intelligence.

00:02:47.250 --> 00:02:49.850
In fact, the world
seems to be infatuated

00:02:49.850 --> 00:02:52.070
with artificial intelligence.

00:02:52.070 --> 00:02:54.950
It's been applied to
everything from social media

00:02:54.950 --> 00:02:59.430
to constructing Ikea furniture.

00:02:59.430 --> 00:03:04.680
But as I indicated, artificial
intelligence is artificial.

00:03:04.680 --> 00:03:07.230
But why is it so successful?

00:03:07.230 --> 00:03:11.560
How does it work to
make it so successful?

00:03:11.560 --> 00:03:18.120
Well, all it is, it's
something that takes some data,

00:03:18.120 --> 00:03:22.200
puts it into an algorithm,
and the output of that

00:03:22.200 --> 00:03:24.660
is predictions.

00:03:24.660 --> 00:03:29.970
Now an algorithm is nothing but
some mathematics and some code.

00:03:29.970 --> 00:03:33.060
And there are different types
of programming languages

00:03:33.060 --> 00:03:36.870
that you can use to
code up the mathematics.

00:03:36.870 --> 00:03:41.040
The mathematics basically
just describes different ways

00:03:41.040 --> 00:03:43.290
to analyse the data.

00:03:43.290 --> 00:03:45.480
And the different ways of
analysing the data depends

00:03:45.480 --> 00:03:48.060
on the different types of
data that you're interested.

00:03:48.060 --> 00:03:51.270
It might be social media data
or it might be some other kind

00:03:51.270 --> 00:03:55.950
of recognition data like if you
want to recognise car number

00:03:55.950 --> 00:03:58.470
plates for example.

00:03:58.470 --> 00:04:02.280
Now the outputs of this
combination of data

00:04:02.280 --> 00:04:06.180
and algorithms is predictions.

00:04:06.180 --> 00:04:09.790
Importantly, these are
statistical predictions.

00:04:09.790 --> 00:04:14.940
So that means that they have
some inherent uncertainties

00:04:14.940 --> 00:04:19.829
that depend on the amount of
data that's available to be

00:04:19.829 --> 00:04:22.597
processed and analysed.

00:04:22.597 --> 00:04:24.180
The reason why
artificial intelligence

00:04:24.180 --> 00:04:26.640
is called artificial
intelligence

00:04:26.640 --> 00:04:30.480
is because prediction
itself is something

00:04:30.480 --> 00:04:33.910
that the human brain
does really, really well.

00:04:33.910 --> 00:04:37.660
It's actually a hallmark
of intelligence.

00:04:37.660 --> 00:04:42.760
And so hence the adjective here
of artificial intelligence.

00:04:42.760 --> 00:04:46.890
The artificial comes in also
because essentially what this

00:04:46.890 --> 00:04:51.120
is doing is just brute force
analysing lots and lots

00:04:51.120 --> 00:04:52.930
of data.

00:04:52.930 --> 00:04:55.470
But in addition to the
quantity of data that's

00:04:55.470 --> 00:04:57.990
required for artificial
intelligence,

00:04:57.990 --> 00:05:02.190
it's also the quality of
the data that matters.

00:05:02.190 --> 00:05:07.470
If you have insufficient amounts
of data or poor quality data,

00:05:07.470 --> 00:05:12.240
then the predictions that
that AI machine makes

00:05:12.240 --> 00:05:14.170
becomes less reliable.

00:05:14.170 --> 00:05:18.360
So for example, if you have
a whole bunch of data where,

00:05:18.360 --> 00:05:23.550
for example, you do want to
recognise patterns on licence

00:05:23.550 --> 00:05:28.500
plate numbers, for example, if
you throw in some random data

00:05:28.500 --> 00:05:33.660
into the mix, your predictions
will actually then result

00:05:33.660 --> 00:05:35.340
in larger and larger
uncertainties,

00:05:35.340 --> 00:05:37.210
becoming less reliable.

00:05:37.210 --> 00:05:39.270
So both quality and
quantity of the data

00:05:39.270 --> 00:05:42.310
are hugely important in
artificial intelligence.

00:05:44.950 --> 00:05:49.090
Now the algorithm in artificial
intelligence is also important.

00:05:49.090 --> 00:05:52.480
And probably the
most exciting types

00:05:52.480 --> 00:05:55.450
of algorithms that
are now used in AI

00:05:55.450 --> 00:05:58.570
are algorithms referred
to as neural networks.

00:05:58.570 --> 00:06:00.310
And they're called
neural networks

00:06:00.310 --> 00:06:06.170
because they do, in some ways,
resemble the human brain,

00:06:06.170 --> 00:06:08.680
at least in the way it operates.

00:06:08.680 --> 00:06:10.960
So they are loosely
based on the human brain

00:06:10.960 --> 00:06:13.280
in the following way.

00:06:13.280 --> 00:06:18.040
The algorithms use
something called networks

00:06:18.040 --> 00:06:22.540
to connect different bits
of information together.

00:06:22.540 --> 00:06:25.270
And they also iterate
through the data

00:06:25.270 --> 00:06:28.360
at varying degrees of levels.

00:06:28.360 --> 00:06:32.440
And these varying degrees
of levels also means that

00:06:32.440 --> 00:06:36.670
sometimes these neural networks
are also referred to as deep

00:06:36.670 --> 00:06:39.970
learning, the deep indicating
how many levels of iterations

00:06:39.970 --> 00:06:43.020
you go through to
analyse the data.

00:06:43.020 --> 00:06:46.690
Now neural network AI
algorithms are most commonly

00:06:46.690 --> 00:06:49.960
used for pattern recognition.

00:06:49.960 --> 00:06:55.390
And again, this rings back
to the intelligence part

00:06:55.390 --> 00:06:57.820
of artificial intelligence,
because the human brain is

00:06:57.820 --> 00:07:01.510
actually really, really good
at recognising patterns.

00:07:01.510 --> 00:07:04.190
You think about when you're
out on the streets of London,

00:07:04.190 --> 00:07:04.780
for example.

00:07:04.780 --> 00:07:08.084
Out of all those people,
if a friend of yours was

00:07:08.084 --> 00:07:10.750
on the other side of the street,
you'd be able to recognise them

00:07:10.750 --> 00:07:12.070
instantly.

00:07:12.070 --> 00:07:14.020
So the brain does
this remarkably well.

00:07:14.020 --> 00:07:15.940
And these neural
network algorithms

00:07:15.940 --> 00:07:19.120
do this remarkably
well as well provided

00:07:19.120 --> 00:07:23.320
that there's good quality data
and a large quantity of it.

00:07:23.320 --> 00:07:25.990
And of course, we're
in the 21st century.

00:07:25.990 --> 00:07:27.280
We have the internet.

00:07:27.280 --> 00:07:31.600
So we actually now do have
really large quantities of data

00:07:31.600 --> 00:07:33.520
available at our fingertips.

00:07:33.520 --> 00:07:36.530
And the quality is actually
very, very good as well.

00:07:36.530 --> 00:07:40.960
And this is the reason why
neural network algorithms

00:07:40.960 --> 00:07:45.250
were first invented in the
1970s but are only now enjoying

00:07:45.250 --> 00:07:51.360
this Renaissance because we have
so much data available to us.

00:07:51.360 --> 00:07:54.240
Now probably the
most famous example

00:07:54.240 --> 00:07:58.950
of the application of neural
network algorithms in AI

00:07:58.950 --> 00:08:05.220
was IBM's DeepMind AI which
beat the chess grandmaster

00:08:05.220 --> 00:08:08.820
Garry Kasparov in 1997.

00:08:08.820 --> 00:08:12.360
And Garry Kasparov
has actually written

00:08:12.360 --> 00:08:14.700
a book recently about this.

00:08:14.700 --> 00:08:16.920
And he's actually a
very strong proponent

00:08:16.920 --> 00:08:19.560
of AI himself despite
the fact that he

00:08:19.560 --> 00:08:22.590
was beaten by a machine.

00:08:22.590 --> 00:08:28.380
Another popular example
is Google's DeepMind AI,

00:08:28.380 --> 00:08:33.539
which was designed specifically
for playing the Chinese game

00:08:33.539 --> 00:08:34.740
AlphaGo.

00:08:34.740 --> 00:08:37.409
And a very recent
development in AlphaGo

00:08:37.409 --> 00:08:41.190
was AlphaGo Zero, which
is a further development

00:08:41.190 --> 00:08:44.220
on the original AI
algorithm developed

00:08:44.220 --> 00:08:48.300
by Google that now
doesn't need to play

00:08:48.300 --> 00:08:50.970
against any other human being.

00:08:50.970 --> 00:08:53.430
AlphaGo Zero actually
taught itself

00:08:53.430 --> 00:08:58.200
by playing against
itself to optimise how

00:08:58.200 --> 00:09:00.880
it plays this particular game.

00:09:00.880 --> 00:09:03.960
So things are developing
at a pretty rapid pace.

00:09:03.960 --> 00:09:06.790
And it's very impressive.

00:09:06.790 --> 00:09:09.090
However, both
those two examples,

00:09:09.090 --> 00:09:11.730
playing chess and
playing AlphaGo,

00:09:11.730 --> 00:09:16.320
represent the fact that
those applications of AI

00:09:16.320 --> 00:09:20.010
demonstrate that
AI is really still

00:09:20.010 --> 00:09:24.660
very limited to specific tasks.

00:09:24.660 --> 00:09:29.130
And so there's a big push on
at the moment for developing

00:09:29.130 --> 00:09:34.470
and extending AI further to try
and realise artificial general

00:09:34.470 --> 00:09:36.130
intelligence.

00:09:36.130 --> 00:09:39.180
So in other words, how
can we get these AIs

00:09:39.180 --> 00:09:45.690
to actually be successful
at broader ranges of data,

00:09:45.690 --> 00:09:48.450
not just data that
is relevant to chess

00:09:48.450 --> 00:09:53.430
or relevant to playing AlphaGo
but relevant for broader

00:09:53.430 --> 00:09:54.720
applications.

00:09:54.720 --> 00:09:59.160
This is really important because
the way the human brain works

00:09:59.160 --> 00:10:01.980
is through general intelligence.

00:10:01.980 --> 00:10:08.070
We have the ability
to triage and philtre

00:10:08.070 --> 00:10:12.060
very broad bandwidth
data and information

00:10:12.060 --> 00:10:15.090
that we are constantly
taking in all the time

00:10:15.090 --> 00:10:17.760
as you are all doing right now.

00:10:17.760 --> 00:10:22.830
We're doing this on the fly in
real time with minimal effort.

00:10:22.830 --> 00:10:25.540
Our brains are doing
this over and over again.

00:10:25.540 --> 00:10:28.740
We don't need some other
entity to import data

00:10:28.740 --> 00:10:32.070
into us to preprogram us.

00:10:32.070 --> 00:10:37.170
And we can actually do a
broad range of general tasks.

00:10:37.170 --> 00:10:41.310
So whether AI as it
exists at the moment

00:10:41.310 --> 00:10:46.290
can actually achieve that
is really a major research

00:10:46.290 --> 00:10:49.800
direction for many
research groups

00:10:49.800 --> 00:10:53.850
but also for some of these
major tech companies like IBM,

00:10:53.850 --> 00:10:56.700
which just last month
actually demonstrated

00:10:56.700 --> 00:11:01.110
an example of moving towards
artificial general intelligence

00:11:01.110 --> 00:11:06.990
with their Project
Debater particular AI.

00:11:06.990 --> 00:11:13.350
Now the Project Debater
AI developed by IBM

00:11:13.350 --> 00:11:16.260
was actually designed
so that it could engage

00:11:16.260 --> 00:11:20.130
in debate with human beings.

00:11:20.130 --> 00:11:24.060
It was incredibly impressive,
because it really started

00:11:24.060 --> 00:11:27.450
to get closer to reason.

00:11:27.450 --> 00:11:30.750
You know, it was
presented with two topics.

00:11:30.750 --> 00:11:34.120
And it was engaging
with two human beings.

00:11:34.120 --> 00:11:40.320
And it was required to present
a viewpoint, present a rebuttal,

00:11:40.320 --> 00:11:44.470
and also to do a wrap up in
the standard debate format.

00:11:44.470 --> 00:11:48.630
However, it's not true general
artificial intelligence,

00:11:48.630 --> 00:11:51.060
because it still needed
to be preprogrammed.

00:11:51.060 --> 00:11:53.640
It needed to know what
those two topics were.

00:11:53.640 --> 00:11:57.000
Data needed to be input into
the system related to those two

00:11:57.000 --> 00:11:58.020
topics.

00:11:58.020 --> 00:12:01.080
And the right algorithms needed
to be put into place in order

00:12:01.080 --> 00:12:02.950
to be able to achieve that.

00:12:02.950 --> 00:12:06.140
So there's still a way
to go towards that.

00:12:06.140 --> 00:12:11.560
So what I'm actually presenting
tonight is the question,

00:12:11.560 --> 00:12:16.870
is there a different approach
to general intelligence--

00:12:16.870 --> 00:12:20.020
emulating general intelligence,
an approach that's

00:12:20.020 --> 00:12:26.570
different from the
software based AI approach.

00:12:26.570 --> 00:12:29.980
So that's what I'm putting
to you this evening.

00:12:29.980 --> 00:12:34.960
Now, of course, we have
actually seen some examples

00:12:34.960 --> 00:12:38.710
of what I'm referring to
as a synthetic intelligence

00:12:38.710 --> 00:12:43.150
approach to understanding and
emulating general intelligence

00:12:43.150 --> 00:12:46.750
through movies such as
Ex Machina for example,

00:12:46.750 --> 00:12:49.330
and the TV series
Humans, which I gather

00:12:49.330 --> 00:12:53.530
is popular here in the UK.

00:12:53.530 --> 00:12:57.850
These examples are,
of course, fictional.

00:12:57.850 --> 00:13:01.270
And we've got a long
way to go to try and get

00:13:01.270 --> 00:13:02.800
in close to this.

00:13:02.800 --> 00:13:08.680
But they do present some
interesting ideas that perhaps

00:13:08.680 --> 00:13:12.490
are not too far away from
the distant future in terms

00:13:12.490 --> 00:13:16.090
of realising synthetic
intelligence.

00:13:16.090 --> 00:13:22.210
And they really do show that
the most important aspect

00:13:22.210 --> 00:13:24.250
of the human brain,
and how it thinks,

00:13:24.250 --> 00:13:26.560
and how it demonstrates
intelligence

00:13:26.560 --> 00:13:31.210
is by being interactive
with its environment--

00:13:31.210 --> 00:13:34.155
as I mentioned before, gathering
information, being exposed

00:13:34.155 --> 00:13:39.310
to information, processing
that information in real time.

00:13:39.310 --> 00:13:44.380
And, most importantly, the human
brain and human intelligence

00:13:44.380 --> 00:13:48.870
is resilient against
random things happening.

00:13:48.870 --> 00:13:51.590
And this is probably the
most important limitation

00:13:51.590 --> 00:13:55.250
of AI software based approaches
to general intelligence,

00:13:55.250 --> 00:13:59.450
the fact that they're so
reliant on curated data

00:13:59.450 --> 00:14:03.140
and large quantities of
data whereas the human brain

00:14:03.140 --> 00:14:06.290
and human intelligence that
results from processes that

00:14:06.290 --> 00:14:08.480
are happening in the
human brain can actually

00:14:08.480 --> 00:14:10.880
deal with random things
being thrown at it.

00:14:10.880 --> 00:14:13.470
We deal with that
remarkably well.

00:14:13.470 --> 00:14:16.460
So our brains actually
have this enormous capacity

00:14:16.460 --> 00:14:21.417
to be adaptive and resilient
against any types of data.

00:14:21.417 --> 00:14:23.000
So that's the challenge
that we really

00:14:23.000 --> 00:14:26.190
face with trying to emulate
general intelligence.

00:14:26.190 --> 00:14:30.200
And this is why it's actually
valuable and important

00:14:30.200 --> 00:14:33.410
that we come up with alternate
approaches to the software

00:14:33.410 --> 00:14:36.930
based AI approach.

00:14:36.930 --> 00:14:39.060
So I'm asking the
question this evening,

00:14:39.060 --> 00:14:43.350
can we make a physical
brain-like device

00:14:43.350 --> 00:14:45.160
with intelligence?

00:14:45.160 --> 00:14:48.250
So in other words, I'm
asking the question,

00:14:48.250 --> 00:14:54.300
can we view intelligence
as a physical phenomenon?

00:14:54.300 --> 00:14:56.670
So in other words,
something that

00:14:56.670 --> 00:15:00.700
can be described in terms
of physical processes.

00:15:00.700 --> 00:15:03.570
If we can describe it in
terms of physical processes,

00:15:03.570 --> 00:15:07.380
then we can actually build
a device that replicates

00:15:07.380 --> 00:15:09.370
those physical processes.

00:15:09.370 --> 00:15:13.470
In other words, we can actually
build a synthetic brain that's

00:15:13.470 --> 00:15:17.310
a replica of the human brain.

00:15:17.310 --> 00:15:22.010
So importantly, this is not
just about making a robot.

00:15:22.010 --> 00:15:26.330
So robots as we know them today
are actually still controlled

00:15:26.330 --> 00:15:29.270
by computational software.

00:15:29.270 --> 00:15:31.220
They need to be preprogrammed.

00:15:31.220 --> 00:15:36.200
So what I'm talking about is
taking a machine, or a device,

00:15:36.200 --> 00:15:40.040
or something and putting
it inside a synthetic brain

00:15:40.040 --> 00:15:44.120
so that it can then engage and
interact with its environment

00:15:44.120 --> 00:15:47.960
and learn in the same way
that human brains learn.

00:15:51.110 --> 00:15:53.120
So how do we do this?

00:15:53.120 --> 00:15:54.880
What are the first steps?

00:15:54.880 --> 00:15:58.960
Well, the human brain is
made up of brain cells

00:15:58.960 --> 00:16:00.700
which are called neurons.

00:16:00.700 --> 00:16:04.330
But these neurons are
also compartmentalised

00:16:04.330 --> 00:16:06.744
into different
regions of the brain.

00:16:06.744 --> 00:16:08.410
And these different
regions of the brain

00:16:08.410 --> 00:16:10.870
also have different
functionalities.

00:16:10.870 --> 00:16:16.090
Now importantly, the individual
neurons are connected together.

00:16:16.090 --> 00:16:18.220
And the different
compartments of the brain

00:16:18.220 --> 00:16:20.320
are also connected together.

00:16:20.320 --> 00:16:23.140
So the whole brain is kind
of like this really complex

00:16:23.140 --> 00:16:23.980
network.

00:16:23.980 --> 00:16:26.740
And there are different
levels of the network

00:16:26.740 --> 00:16:29.150
that is the brain.

00:16:29.150 --> 00:16:32.190
So this is where
we need to start.

00:16:32.190 --> 00:16:33.280
Two aspects.

00:16:33.280 --> 00:16:36.690
One is we need to be
able to understand

00:16:36.690 --> 00:16:41.010
how the brain functions at
the individual neuron level

00:16:41.010 --> 00:16:45.360
and how those individual neurons
are connected together and also

00:16:45.360 --> 00:16:48.060
then how they form these
compartments which are also

00:16:48.060 --> 00:16:50.070
connected together.

00:16:50.070 --> 00:16:53.340
And the second thing
is, moving away

00:16:53.340 --> 00:16:56.050
from individual
neurons themselves,

00:16:56.050 --> 00:16:58.710
we also then need
to understand what

00:16:58.710 --> 00:17:01.530
happens on the global scale.

00:17:01.530 --> 00:17:03.870
And this is quite
interesting, because,

00:17:03.870 --> 00:17:06.210
at the individual
neurons scale, what

00:17:06.210 --> 00:17:08.670
happens is that
neurons come together

00:17:08.670 --> 00:17:11.099
and they communicate together.

00:17:11.099 --> 00:17:15.160
We know that's an important
aspect of how the brain works.

00:17:15.160 --> 00:17:17.520
But when we take
the brain globally,

00:17:17.520 --> 00:17:23.730
and we consider the really
complex networks that

00:17:23.730 --> 00:17:27.540
form between neurons and between
different regions of the brain,

00:17:27.540 --> 00:17:30.250
there's something else
interesting that happens.

00:17:30.250 --> 00:17:32.280
Those interactions
between neurons

00:17:32.280 --> 00:17:34.680
and between different
parts of the brain

00:17:34.680 --> 00:17:39.604
actually result in
emergent properties.

00:17:39.604 --> 00:17:40.770
And that's really important.

00:17:40.770 --> 00:17:43.980
What that means is that
the whole is greater

00:17:43.980 --> 00:17:46.140
than the sum of its parts.

00:17:46.140 --> 00:17:49.740
And we see a lot of this type
of behaviour in other complex

00:17:49.740 --> 00:17:51.340
systems.

00:17:51.340 --> 00:17:53.610
So in the brain,
it's really important

00:17:53.610 --> 00:17:57.870
to be able to try and
replicate the complexity

00:17:57.870 --> 00:18:00.600
of the network that
exists in the brain

00:18:00.600 --> 00:18:02.900
in any kind of
synthetic brain that we

00:18:02.900 --> 00:18:06.100
are attempting to recreate.

00:18:06.100 --> 00:18:08.680
Now going back to
the individual neuron

00:18:08.680 --> 00:18:12.220
level, what happens with
the neurons in the brain

00:18:12.220 --> 00:18:15.800
is that they're all
connected to each other.

00:18:15.800 --> 00:18:19.640
And when they get stimulated
by electrical stimuli,

00:18:19.640 --> 00:18:22.000
they start sending
signals to each other.

00:18:22.000 --> 00:18:23.710
And the signals
that get transmitted

00:18:23.710 --> 00:18:26.530
through the neurons, which
are connected with each other,

00:18:26.530 --> 00:18:29.410
is the way in which
signal transmission

00:18:29.410 --> 00:18:30.800
occurs through the brain.

00:18:30.800 --> 00:18:35.300
So it's communication
between neurons.

00:18:35.300 --> 00:18:38.110
So what I'm going
to show you now

00:18:38.110 --> 00:18:44.110
is a YouTube video
that synapses.

00:18:44.110 --> 00:18:51.490
Synapses, basically, are the
way in which individual neurons

00:18:51.490 --> 00:18:52.930
communicate with each other.

00:18:52.930 --> 00:18:54.980
And could you play that
movie for me please?

00:18:54.980 --> 00:18:55.480
Thank you.

00:18:56.440 --> 00:19:02.330
So this YouTube video shows how
sensory input into the brain

00:19:02.330 --> 00:19:07.300
becomes visually or through
smelling things and touching

00:19:07.300 --> 00:19:12.340
things and so on result
in electrical signals

00:19:12.340 --> 00:19:13.845
in the brain.

00:19:13.845 --> 00:19:15.220
And these electrical
signals then

00:19:15.220 --> 00:19:17.650
propagate through the neurons.

00:19:17.650 --> 00:19:20.050
And the neurons
have these branches

00:19:20.050 --> 00:19:24.590
that stretch out and
almost touch each other.

00:19:24.590 --> 00:19:28.330
So you can see that kind of
treelike branching structure

00:19:28.330 --> 00:19:30.040
between the neurons.

00:19:30.040 --> 00:19:32.620
And those treelike structures--
branching structures

00:19:32.620 --> 00:19:35.110
are important, because
at the end of them,

00:19:35.110 --> 00:19:38.290
you can see that one end of
one of the neurons almost

00:19:38.290 --> 00:19:40.870
touches another neuron.

00:19:40.870 --> 00:19:45.160
And the gap that forms
between those two neurons--

00:19:45.160 --> 00:19:48.010
you can see tiny
little molecules

00:19:48.010 --> 00:19:51.350
which are called
neurotransmitter molecules.

00:19:51.850 --> 00:19:56.480
And they actually travel
from one neuron to another.

00:19:56.480 --> 00:19:58.420
So those neurotransmitter
molecules

00:19:58.420 --> 00:20:01.450
represent the way
in which signals get

00:20:01.450 --> 00:20:04.070
transmitted through neurons.

00:20:04.070 --> 00:20:11.200
Now the brain has approximately
100 billion neurons in it.

00:20:11.200 --> 00:20:16.630
But it has 1,000
trillion synapses.

00:20:16.630 --> 00:20:18.340
And that's because
each of those neurons

00:20:18.340 --> 00:20:23.600
can have multiple synaptic
connections with other neurons.

00:20:23.600 --> 00:20:28.630
So the first step in
trying to design and build

00:20:28.630 --> 00:20:32.320
a synthetic brain is
actually to try and start

00:20:32.320 --> 00:20:34.840
with the neurons and
the synaptic connections

00:20:34.840 --> 00:20:36.160
between the neurons.

00:20:36.160 --> 00:20:39.640
Can we actually start with
that and build those first?

00:20:39.640 --> 00:20:42.570
Well, of course,
the answer is yes.

00:20:42.570 --> 00:20:45.010
And there's already
a lot of research

00:20:45.010 --> 00:20:47.200
being done on that right now.

00:20:47.200 --> 00:20:48.910
And I just saw the
slide that I wanted.

00:20:48.910 --> 00:20:49.450
That one.

00:20:49.450 --> 00:20:51.350
Thank you.

00:20:51.350 --> 00:20:56.200
So the first step is, can
we build synthetic synapses?

00:20:56.200 --> 00:20:58.960
These are the ways in
which two neurons can

00:20:58.960 --> 00:21:01.080
communicate with each other.

00:21:01.080 --> 00:21:02.620
And in the real
neuron case, they

00:21:02.620 --> 00:21:05.230
communicate with each other
through these neurotransmitter

00:21:05.230 --> 00:21:06.250
molecules.

00:21:06.250 --> 00:21:11.330
So can we build a device that
replicates these synapses?

00:21:11.330 --> 00:21:13.180
So there's a lot
of research being

00:21:13.180 --> 00:21:16.570
done in this around the
world and with some really

00:21:16.570 --> 00:21:19.630
remarkable and
impressive results

00:21:19.630 --> 00:21:25.930
a lot of the efforts in this are
focusing on using semiconductor

00:21:25.930 --> 00:21:27.997
electronic device components.

00:21:27.997 --> 00:21:29.830
And the reason for this
is, if you remember,

00:21:29.830 --> 00:21:32.530
I mentioned that
the human brain,

00:21:32.530 --> 00:21:36.310
once it receives sensory
input, that actually sends out

00:21:36.310 --> 00:21:38.770
electrical signals
through the human brain.

00:21:38.770 --> 00:21:40.330
And those electrical
signals are what

00:21:40.330 --> 00:21:43.270
drives those
neurotransmitter molecules

00:21:43.270 --> 00:21:45.430
from one neuron to the other.

00:21:45.430 --> 00:21:50.380
So since this process is
driven by electrical signals,

00:21:50.380 --> 00:21:54.160
then it makes sense to
start emulating this

00:21:54.160 --> 00:21:56.502
with electronic devices.

00:21:56.502 --> 00:21:58.210
So that's what a lot
of groups have done.

00:21:58.210 --> 00:22:01.270
They've started with
known electronic devices

00:22:01.270 --> 00:22:05.200
in trying to construct
these synthetic synapses,

00:22:05.200 --> 00:22:07.600
and then sending electrical
signals through them

00:22:07.600 --> 00:22:09.490
and seeing if they
can get something

00:22:09.490 --> 00:22:14.740
that looks like the way
that real synapses work.

00:22:14.740 --> 00:22:18.280
So there has been some
remarkable success in this,

00:22:18.280 --> 00:22:22.010
but there are two
major drawbacks.

00:22:22.010 --> 00:22:27.730
So one of them is that once you
start using electrical device

00:22:27.730 --> 00:22:30.490
components-- and these
are just things like stuff

00:22:30.490 --> 00:22:32.620
that you make integrated
circuits out of.

00:22:32.620 --> 00:22:34.900
There's nothing new here.

00:22:34.900 --> 00:22:36.520
But once you start
using them, you're

00:22:36.520 --> 00:22:38.740
immediately
restricted to working

00:22:38.740 --> 00:22:42.550
on a 2D, two dimensional
integrated circuit

00:22:42.550 --> 00:22:45.310
board, which is nothing
like what the brain is.

00:22:45.310 --> 00:22:46.720
The brain is a 3D structure.

00:22:46.720 --> 00:22:48.100
Right.

00:22:48.100 --> 00:22:52.180
But also, it turns out that
electrical device components

00:22:52.180 --> 00:22:55.210
on a circuit board,
you can't really

00:22:55.210 --> 00:22:57.280
manipulate them too much.

00:22:57.280 --> 00:23:01.180
First of all, they have
to be very sparsely

00:23:01.180 --> 00:23:04.000
and carefully arranged.

00:23:04.000 --> 00:23:07.120
And that is completely unlike
what happens in the real brain.

00:23:07.120 --> 00:23:10.330
So I've mentioned to you
already that the real brain has

00:23:10.330 --> 00:23:13.030
some a 1,000 trillion synapses.

00:23:13.030 --> 00:23:15.640
So these are incredibly
dense connections.

00:23:15.640 --> 00:23:19.720
And we just cannot replicate
that with existing electronic

00:23:19.720 --> 00:23:21.719
device components.

00:23:21.719 --> 00:23:23.260
The second problem
with this approach

00:23:23.260 --> 00:23:28.420
is that electronic device
components as they exist today

00:23:28.420 --> 00:23:31.040
actually use quite
a lot of power.

00:23:31.040 --> 00:23:33.670
So we're talking about
megawatts of power

00:23:33.670 --> 00:23:37.220
whereas the human
brain uses milliwatts.

00:23:37.220 --> 00:23:40.270
So that's a billion
times more power

00:23:40.270 --> 00:23:43.600
that's used by these
electronic device components.

00:23:43.600 --> 00:23:45.520
That's a real problem.

00:23:45.520 --> 00:23:47.380
However, that
problem is starting

00:23:47.380 --> 00:23:49.810
to be solved through
an approach known

00:23:49.810 --> 00:23:51.860
as neuromorphic computing.

00:23:51.860 --> 00:23:54.730
So the term neuromorphic
means brain-like.

00:23:54.730 --> 00:23:57.190
And IBM has actually
developed a new type

00:23:57.190 --> 00:24:01.810
of chip technology called
neuromorphic chips that has now

00:24:01.810 --> 00:24:04.840
reduced the power
consumption of their chips

00:24:04.840 --> 00:24:08.140
down to levels that are
comparable with the brain.

00:24:08.140 --> 00:24:11.140
That's been a
remarkable achievement.

00:24:11.140 --> 00:24:13.600
Their main objective
in doing this

00:24:13.600 --> 00:24:17.950
was really to try and
reduce the power consumption

00:24:17.950 --> 00:24:20.680
in computing and computing
processes, particularly

00:24:20.680 --> 00:24:22.910
for AI applications.

00:24:22.910 --> 00:24:25.190
But power consumption
is a real problem.

00:24:25.190 --> 00:24:28.610
And it's something that I'll
come back to later on as well.

00:24:28.610 --> 00:24:30.770
So they've been quite
successful in this.

00:24:30.770 --> 00:24:33.550
But their neuromorphic
chip devices,

00:24:33.550 --> 00:24:35.200
which work because
they've actually

00:24:35.200 --> 00:24:40.060
been able to completely scrap
with the original so-called Von

00:24:40.060 --> 00:24:43.810
Neumann type architectures
of computer chips

00:24:43.810 --> 00:24:47.000
that were developed in the
1950s that we still use today.

00:24:47.000 --> 00:24:49.450
So they completely scrapped
that and completely changed

00:24:49.450 --> 00:24:52.300
the architecture of their
chips to achieve those really

00:24:52.300 --> 00:24:55.540
low power consumption levels.

00:24:55.540 --> 00:24:58.630
But the thing is their
chips are not synaptic like.

00:24:58.630 --> 00:25:01.030
So they're not
synthetic synapses.

00:25:01.030 --> 00:25:03.970
So this still doesn't
get us anywhere closer

00:25:03.970 --> 00:25:09.290
to how we can start
building a synthetic brain.

00:25:09.290 --> 00:25:11.180
But there is another
technology, which

00:25:11.180 --> 00:25:14.150
is called the atomic
switch technology.

00:25:14.150 --> 00:25:16.460
And it was only relatively
recently commercialised

00:25:16.460 --> 00:25:18.320
by the electronics company NEC.

00:25:18.320 --> 00:25:21.710
It's a Japanese
electronics company.

00:25:21.710 --> 00:25:23.840
And this is a completely
new technology.

00:25:23.840 --> 00:25:26.750
It's not based on
semiconductors.

00:25:26.750 --> 00:25:29.700
They've really started
from scratch with this.

00:25:29.700 --> 00:25:33.620
And it's called atomic switch
because it acts like a switch,

00:25:33.620 --> 00:25:35.810
going from an off
stage to an on state.

00:25:35.810 --> 00:25:39.410
It's able to make that
transition extremely rapidly

00:25:39.410 --> 00:25:42.200
in milliseconds if not
shorter timescales.

00:25:42.200 --> 00:25:45.530
So it's already quite attractive
for computing applications

00:25:45.530 --> 00:25:48.230
where you're working with
binary zeros and ones.

00:25:48.230 --> 00:25:52.460
But it's also called
brain-like atomic switch

00:25:52.460 --> 00:25:56.240
because it turns out that the
way that these switches operate

00:25:56.240 --> 00:26:00.320
is exactly the
same as a synapse.

00:26:00.320 --> 00:26:04.080
You have two regions
with a gap in between.

00:26:04.080 --> 00:26:06.290
And when you put an electrical
signal across there,

00:26:06.290 --> 00:26:10.760
you drive ions from
one side to the other.

00:26:10.760 --> 00:26:12.680
And that is exactly
the same as the way

00:26:12.680 --> 00:26:16.040
in which neurotransmitters
transmit electrical signals

00:26:16.040 --> 00:26:18.650
in neural synapses.

00:26:18.650 --> 00:26:21.860
So this has been a really
exciting development.

00:26:21.860 --> 00:26:24.440
And there are other
really attractive features

00:26:24.440 --> 00:26:27.830
of this atomic switch
technology such

00:26:27.830 --> 00:26:30.410
as they have very
low volatility, which

00:26:30.410 --> 00:26:33.170
means they don't
need to be maintained

00:26:33.170 --> 00:26:35.900
as often as existing
semiconductor device

00:26:35.900 --> 00:26:37.010
technologies.

00:26:37.010 --> 00:26:40.050
And they have extremely low
power consumption as well.

00:26:40.050 --> 00:26:43.200
Again, similar to what
the brain uses as well.

00:26:43.200 --> 00:26:45.320
And in fact, NEC's
first application

00:26:45.320 --> 00:26:47.569
is to put these devices
on space satellites,

00:26:47.569 --> 00:26:49.610
because then they don't
have to worry about them.

00:26:49.610 --> 00:26:52.220
There's low maintenance,
low volatility, low power

00:26:52.220 --> 00:26:53.790
consumption.

00:26:53.790 --> 00:26:56.360
So this is really an
exciting new technology.

00:26:56.360 --> 00:26:58.520
And it's a
technology, as I said,

00:26:58.520 --> 00:27:00.470
that mimics the
way that synapses

00:27:00.470 --> 00:27:02.300
work in the human brain.

00:27:02.300 --> 00:27:06.950
However, as you'll see with
this particular device,

00:27:06.950 --> 00:27:10.310
it still faces a
limitation in moving it

00:27:10.310 --> 00:27:13.730
to the next stage of
building a synthetic brain,

00:27:13.730 --> 00:27:19.010
because it turns out that the
individual synapses are still

00:27:19.010 --> 00:27:25.460
quite limited in terms of
the way they can be arranged

00:27:25.460 --> 00:27:28.430
and how many
connections can actually

00:27:28.430 --> 00:27:30.480
be achieved out of them.

00:27:30.480 --> 00:27:32.720
So at the moment,
it's very difficult

00:27:32.720 --> 00:27:37.550
to achieve a high
density of connectedness

00:27:37.550 --> 00:27:39.557
with these atomic switches.

00:27:39.557 --> 00:27:41.390
That's something that
people are working on.

00:27:41.390 --> 00:27:45.590
But at the moment
we're not there yet.

00:27:45.590 --> 00:27:49.230
Now this is a
schematic illustration

00:27:49.230 --> 00:27:53.070
of what a real network
of neurons looks like.

00:27:53.070 --> 00:27:57.330
And I showed you that brief
video earlier as well.

00:27:57.330 --> 00:27:59.070
You can see that it
looks quite messy.

00:27:59.070 --> 00:28:02.200
The neurons occupy 3D space.

00:28:02.200 --> 00:28:04.800
And as I mentioned
and I'm emphasising,

00:28:04.800 --> 00:28:11.950
they really connect with each
other with a high degree.

00:28:11.950 --> 00:28:14.580
So it's a complex network.

00:28:14.580 --> 00:28:16.500
It's a highly connected network.

00:28:16.500 --> 00:28:19.170
And this is what we're
trying to emulate

00:28:19.170 --> 00:28:22.530
in building a synthetic brain.

00:28:22.530 --> 00:28:26.040
An important aspect
of that complexity

00:28:26.040 --> 00:28:29.130
in the structure of
the real human brain

00:28:29.130 --> 00:28:35.400
is that it enables something
called synaptic plasticity.

00:28:35.400 --> 00:28:39.450
What this means is that
it allows the brain

00:28:39.450 --> 00:28:46.140
to continuously respond to
input data, and information,

00:28:46.140 --> 00:28:50.970
and continuously reconfigure
all the synaptic connections

00:28:50.970 --> 00:28:53.860
that it makes with
all the neurons.

00:28:53.860 --> 00:28:57.180
This is happening all
the time in our brains.

00:28:57.180 --> 00:29:02.370
And this synaptic plasticity
is what neuroscientists now

00:29:02.370 --> 00:29:06.780
attribute to our capacity
to remember things

00:29:06.780 --> 00:29:10.860
and to learn, in other
words, our intelligence.

00:29:10.860 --> 00:29:13.620
So synaptic
plasticity is the key

00:29:13.620 --> 00:29:17.160
to actually emulating
general intelligence

00:29:17.160 --> 00:29:19.890
as we have it in our brains.

00:29:19.890 --> 00:29:25.200
And the way to do this is by
emulating the complex network

00:29:25.200 --> 00:29:27.900
structure of the human brain.

00:29:27.900 --> 00:29:31.240
That complexity is
absolutely essential.

00:29:31.240 --> 00:29:35.940
So are there any technologies
that can actually--

00:29:35.940 --> 00:29:39.750
where we can actually start to
emulate that complex network

00:29:39.750 --> 00:29:43.150
structure that we see
in the human brain?

00:29:43.150 --> 00:29:45.940
Well of course, the answer
is yes, because otherwise I

00:29:45.940 --> 00:29:48.830
wouldn't be here this evening.

00:29:48.830 --> 00:29:54.010
So this is the best technology
that we have at the moment

00:29:54.010 --> 00:29:58.990
today of something that
is really now starting

00:29:58.990 --> 00:30:02.590
to resemble the
structure and also

00:30:02.590 --> 00:30:06.530
the function of the human brain.

00:30:06.530 --> 00:30:10.970
This is what I've called here
a neuromorphic nanotechnology.

00:30:10.970 --> 00:30:14.870
So let me describe what it is
that you're looking at here.

00:30:14.870 --> 00:30:17.920
First of all, it's
an image taken

00:30:17.920 --> 00:30:20.380
with an electron microscope.

00:30:20.380 --> 00:30:24.610
An electron microscope has
incredibly high resolution

00:30:24.610 --> 00:30:26.860
and therefore it's
used quite often

00:30:26.860 --> 00:30:30.190
to image nanotechnology
devices, which

00:30:30.190 --> 00:30:32.440
is what this is an example of.

00:30:32.440 --> 00:30:35.470
What you're looking at, all
those individual strings that

00:30:35.470 --> 00:30:38.590
appear to have this
very messy structure,

00:30:38.590 --> 00:30:43.900
they are actually nanowires,
so nanoscale wires.

00:30:43.900 --> 00:30:48.310
In this case, they're made
out of primarily silver.

00:30:48.310 --> 00:30:52.000
But they're about
maybe 100 nanometers

00:30:52.000 --> 00:30:56.560
in width and much, much
longer in length, typically

00:30:56.560 --> 00:30:58.510
microns in length.

00:30:58.510 --> 00:31:02.470
These nanowires actually
have incredibly interesting

00:31:02.470 --> 00:31:03.610
properties.

00:31:03.610 --> 00:31:05.710
And these interesting
properties only

00:31:05.710 --> 00:31:11.230
emerge because they have
this nanoscale structure.

00:31:11.230 --> 00:31:14.890
Now what's of interest to us for
the neuromorphic application,

00:31:14.890 --> 00:31:18.680
the brain-like application,
first of all is the structure.

00:31:18.680 --> 00:31:22.480
And you can see immediately
how much more similar

00:31:22.480 --> 00:31:25.660
this type of structure is
to a real neural network

00:31:25.660 --> 00:31:29.230
compared to other structures
that are based on semiconductor

00:31:29.230 --> 00:31:31.120
device technologies.

00:31:31.120 --> 00:31:35.140
But secondly, in addition
to the network structure

00:31:35.140 --> 00:31:38.170
that these nanowires
can produce,

00:31:38.170 --> 00:31:43.780
it turns out that, because
they form this complex network,

00:31:43.780 --> 00:31:47.170
they actually overlap
in many, many areas.

00:31:47.170 --> 00:31:50.620
And the locations at
which the nanowires

00:31:50.620 --> 00:31:55.190
overlap with each other when you
put an electrical stimulation

00:31:55.190 --> 00:31:58.340
over the network,
they actually behave

00:31:58.340 --> 00:32:02.330
in exactly the same way as
synapses do in the sense

00:32:02.330 --> 00:32:07.460
that, where two wires
overlap, they form a junction.

00:32:07.460 --> 00:32:09.560
There's a gap between them.

00:32:09.560 --> 00:32:11.840
And when that
junction experiences

00:32:11.840 --> 00:32:14.180
an electrical
stimulation, it actually

00:32:14.180 --> 00:32:20.180
drives ions from one wire to the
other in exactly the same way

00:32:20.180 --> 00:32:22.310
that neurotransmitters
are transmitted

00:32:22.310 --> 00:32:26.490
across synaptic connections
between neurons.

00:32:26.490 --> 00:32:28.970
This is incredibly exciting.

00:32:28.970 --> 00:32:34.550
And the results that we have
today actually show that you

00:32:34.550 --> 00:32:38.810
can put different types of
electrical stimulations across

00:32:38.810 --> 00:32:43.170
these networks and get the
network to exhibit memory

00:32:43.170 --> 00:32:44.550
behaviour.

00:32:44.550 --> 00:32:47.930
You can also train the
network by applying

00:32:47.930 --> 00:32:52.010
the same stimulation over
and over again and getting

00:32:52.010 --> 00:32:55.510
the network to
replicate that signal.

00:32:55.510 --> 00:32:58.810
So I'm going to show
an example of how

00:32:58.810 --> 00:33:02.320
we can get this kind
of nanotechnology that

00:33:02.320 --> 00:33:06.220
emulates the brain
to actually start

00:33:06.220 --> 00:33:08.140
getting it to learn something.

00:33:08.140 --> 00:33:11.990
So what I'm going to
show you now is a movie.

00:33:11.990 --> 00:33:14.150
And you can see on
the left hand side

00:33:14.150 --> 00:33:16.690
the number two that's
being flashed up there.

00:33:16.690 --> 00:33:19.360
Each one of those little
squares on both sides

00:33:19.360 --> 00:33:22.480
represents an area where
we have this neuromorphic

00:33:22.480 --> 00:33:25.900
nanotechnology
synapses if you like.

00:33:25.900 --> 00:33:29.530
And electrical stimulations
are being delivered

00:33:29.530 --> 00:33:34.810
to mimic the shape of the digit
two and also the digit number

00:33:34.810 --> 00:33:35.830
one.

00:33:35.830 --> 00:33:38.530
The difference is
that the digit number

00:33:38.530 --> 00:33:42.280
one is being delivered
by electrical stimuli

00:33:42.280 --> 00:33:46.690
at a much, much faster rate
than the electrical stimuli that

00:33:46.690 --> 00:33:50.140
are used to generate
the number two.

00:33:50.140 --> 00:33:52.810
At the end of this, you
can see that the number one

00:33:52.810 --> 00:33:55.540
is retained much more strongly.

00:33:55.540 --> 00:33:59.270
There's a faint resemblance
of the number two behind it,

00:33:59.270 --> 00:34:03.370
but it's the number one that
has this very strong retention

00:34:03.370 --> 00:34:06.850
by this device.

00:34:06.850 --> 00:34:09.880
That demonstrates to
us that we can actually

00:34:09.880 --> 00:34:15.040
control the way that this
device remembers things

00:34:15.040 --> 00:34:18.940
by simply controlling
the rate at which we're

00:34:18.940 --> 00:34:21.010
delivering information.

00:34:21.010 --> 00:34:23.469
So we can control
the repetition rate

00:34:23.469 --> 00:34:26.560
and therefore control
how it remembers things.

00:34:26.560 --> 00:34:29.500
This is crucially important,
because this is exactly the way

00:34:29.500 --> 00:34:31.360
that we remember things.

00:34:31.360 --> 00:34:33.639
When we want to remember
something important,

00:34:33.639 --> 00:34:35.739
whether it's for an
exam or something else

00:34:35.739 --> 00:34:39.670
that we're interested
in, we read or go

00:34:39.670 --> 00:34:43.060
over something over
and over and over again

00:34:43.060 --> 00:34:45.429
and we get memory from that.

00:34:45.429 --> 00:34:47.500
And importantly
also, the human brain

00:34:47.500 --> 00:34:51.280
exhibits two different types
of memory, short term memory

00:34:51.280 --> 00:34:53.409
and long term memory.

00:34:53.409 --> 00:34:57.790
And we can actually start
now to see those differences

00:34:57.790 --> 00:35:00.070
in the formation of these
two types of memories

00:35:00.070 --> 00:35:04.690
from this type of nanotechnology
neuromorphic device.

00:35:04.690 --> 00:35:06.880
It's actually
incredibly exciting.

00:35:06.880 --> 00:35:10.370
Now short term memory
and long term memory.

00:35:10.370 --> 00:35:13.030
The neuroscientists
have pinned that down

00:35:13.030 --> 00:35:17.270
to being attributable
to synaptic plasticity.

00:35:17.270 --> 00:35:20.230
So again, it's this complex
network structure that this

00:35:20.230 --> 00:35:26.710
device is able to produce that
allows it to display these

00:35:26.710 --> 00:35:30.070
different behaviours of
memory that are now starting

00:35:30.070 --> 00:35:34.940
to emulate the way that
the real human brain works.

00:35:34.940 --> 00:35:36.960
So where are we going with this?

00:35:36.960 --> 00:35:42.180
So let me just finish up
with some views of my own.

00:35:42.180 --> 00:35:45.380
So in 2006, the
World Economic Forum

00:35:45.380 --> 00:35:49.580
put forth their view that
the 21st century is now

00:35:49.580 --> 00:35:53.000
witnessing what they've
called the fourth Industrial

00:35:53.000 --> 00:35:53.720
Revolution.

00:35:53.720 --> 00:35:56.180
And of course, we saw the
first Industrial Revolution

00:35:56.180 --> 00:35:57.810
in the 18th century.

00:35:57.810 --> 00:36:00.350
19th century, we saw
another revolution

00:36:00.350 --> 00:36:02.116
from the introduction
of electricity.

00:36:02.116 --> 00:36:03.490
And then, of
course, 20th century

00:36:03.490 --> 00:36:06.470
is perhaps best well
known by the invention

00:36:06.470 --> 00:36:10.280
of the transistor and hence
the subsequent electronics

00:36:10.280 --> 00:36:12.780
and computer industry.

00:36:12.780 --> 00:36:15.200
Well, the fourth
Industrial Revolution

00:36:15.200 --> 00:36:18.830
is characterised by several
emerging breakthrough

00:36:18.830 --> 00:36:22.500
technologies which
include AI, of course,

00:36:22.500 --> 00:36:26.000
the internet of
things, nanotechnology,

00:36:26.000 --> 00:36:28.180
and space technology.

00:36:28.180 --> 00:36:31.920
Now the fourth
Industrial Revolution

00:36:31.920 --> 00:36:36.310
is going to be characterised
not by just one of these things.

00:36:36.310 --> 00:36:39.840
It's going to be characterised
by the convergence of all

00:36:39.840 --> 00:36:42.510
of these and probably more
breakthrough technologies

00:36:42.510 --> 00:36:44.070
that we are yet to see.

00:36:44.070 --> 00:36:46.730
We're only at the beginning
of the 21st century.

00:36:46.730 --> 00:36:49.540
Where does synthetic
intelligence fit into this?

00:36:49.540 --> 00:36:53.220
So I've explained to you how
synthetic intelligence provides

00:36:53.220 --> 00:36:58.230
an alternate approach to AI
software based approaches.

00:36:58.230 --> 00:37:00.870
I've also shown you how
important nanotechnology

00:37:00.870 --> 00:37:03.060
is to synthetic intelligence.

00:37:03.060 --> 00:37:06.690
We really couldn't have realised
a synthetic intelligence device

00:37:06.690 --> 00:37:09.300
without nanotechnology.

00:37:09.300 --> 00:37:11.610
The internet of things
basically describes

00:37:11.610 --> 00:37:14.010
how the world is
becoming increasingly

00:37:14.010 --> 00:37:16.540
connected on the global scale.

00:37:16.540 --> 00:37:18.900
And at the moment,
that's being driven by AI

00:37:18.900 --> 00:37:20.790
and the requirements of AI.

00:37:20.790 --> 00:37:22.560
But that's actually
unsustainable

00:37:22.560 --> 00:37:26.910
because of the power
requirements of AI.

00:37:26.910 --> 00:37:30.270
You think about how many times
a day you do a Google search

00:37:30.270 --> 00:37:33.510
and then stop and think about
how much power that actually

00:37:33.510 --> 00:37:34.680
consumes.

00:37:34.680 --> 00:37:36.990
A typical Google
search consumes about--

00:37:36.990 --> 00:37:39.900
I think it's about 1
kilojoules of power.

00:37:39.900 --> 00:37:42.300
That corresponds to
turning on a light bulb

00:37:42.300 --> 00:37:43.980
for about 15 seconds.

00:37:43.980 --> 00:37:46.710
You think about how much
of that goes on every day.

00:37:46.710 --> 00:37:51.190
Most of that power is required
to keep the servers going,

00:37:51.190 --> 00:37:55.680
so to keep them cool
and to store the data.

00:37:55.680 --> 00:37:59.040
That cannot keep going on
if we really are going to be

00:37:59.040 --> 00:38:01.290
experiencing this
Industrial Revolution.

00:38:01.290 --> 00:38:04.560
We need better ways to be
interconnected and cleverer

00:38:04.560 --> 00:38:05.970
ways.

00:38:05.970 --> 00:38:08.490
Space technology I
haven't touched on yet.

00:38:08.490 --> 00:38:14.070
But in my view, space
technology is the killer app

00:38:14.070 --> 00:38:17.800
for synthetic intelligence
for the following reason.

00:38:17.800 --> 00:38:21.120
We are now seeing a real
push, a genuine real push

00:38:21.120 --> 00:38:25.050
backed by money, for
colonisation of the moon

00:38:25.050 --> 00:38:27.220
and also Mars.

00:38:27.220 --> 00:38:30.120
And if we're going to
do this, we actually

00:38:30.120 --> 00:38:35.730
need synthetic intelligence
devices, autonomous systems

00:38:35.730 --> 00:38:38.610
with syntactic synthetic
brains in them,

00:38:38.610 --> 00:38:40.770
to send them out
and actually prepare

00:38:40.770 --> 00:38:46.200
the moon and, of course,
Mars for human colonisation.

00:38:46.200 --> 00:38:48.700
For Mars it's
absolutely critical.

00:38:48.700 --> 00:38:52.890
There is no way we can
actually send manned space

00:38:52.890 --> 00:38:55.830
missions out to Mars first off.

00:38:55.830 --> 00:38:58.050
We need to be able to
send machines out there.

00:38:58.050 --> 00:39:01.530
And those machines need to
be able to think adaptively

00:39:01.530 --> 00:39:03.930
with minimal human
interventions.

00:39:03.930 --> 00:39:06.240
There are going to be
long periods of time

00:39:06.240 --> 00:39:08.760
where we are not going
to be able to communicate

00:39:08.760 --> 00:39:10.620
with those kind of devices.

00:39:10.620 --> 00:39:14.230
So they really need to be
as autonomous as possible.

00:39:14.230 --> 00:39:19.050
And in fact, NASA is now
preparing autonomous systems

00:39:19.050 --> 00:39:22.590
with increasing levels of
autonomy for their next Mars

00:39:22.590 --> 00:39:26.130
Rover mission for 2020.

00:39:26.130 --> 00:39:29.610
So this is where I see
the real application

00:39:29.610 --> 00:39:33.060
for synthetic intelligence, or
at least the most exciting one

00:39:33.060 --> 00:39:34.140
in my mind.

00:39:34.140 --> 00:39:36.270
But just to finish
up my presentation,

00:39:36.270 --> 00:39:39.840
I wanted to leave
you with a quote

00:39:39.840 --> 00:39:43.950
from the famous British
mathematician, computer

00:39:43.950 --> 00:39:47.670
scientist, and
logician Alan Turing.

00:39:47.670 --> 00:39:49.440
Thank you very
much for listening.

00:39:49.440 --> 00:39:52.790
[APPLAUSE]

