WEBVTT
Kind: captions
Language: en

00:00:03.250 --> 00:00:06.700 align:start position:0%
 
okay<00:00:04.250><c> so</c><00:00:04.310><c> welcome</c><00:00:04.700><c> everyone</c><00:00:05.569><c> to</c><00:00:05.840><c> the</c><00:00:06.200><c> final</c>

00:00:06.700 --> 00:00:06.710 align:start position:0%
okay so welcome everyone to the final
 

00:00:06.710 --> 00:00:09.090 align:start position:0%
okay so welcome everyone to the final
foundational<00:00:07.670><c> lecture</c><00:00:08.090><c> of</c><00:00:08.299><c> this</c><00:00:08.660><c> year's</c>

00:00:09.090 --> 00:00:09.100 align:start position:0%
foundational lecture of this year's
 

00:00:09.100 --> 00:00:11.259 align:start position:0%
foundational lecture of this year's
offering<00:00:10.100><c> of</c><00:00:10.250><c> six</c><00:00:10.459><c> s-191</c>

00:00:11.259 --> 00:00:11.269 align:start position:0%
offering of six s-191
 

00:00:11.269 --> 00:00:14.440 align:start position:0%
offering of six s-191
where<00:00:11.990><c> we'll</c><00:00:12.349><c> be</c><00:00:12.530><c> taking</c><00:00:13.519><c> kind</c><00:00:13.790><c> of</c><00:00:13.910><c> a</c><00:00:14.120><c> step</c>

00:00:14.440 --> 00:00:14.450 align:start position:0%
where we'll be taking kind of a step
 

00:00:14.450 --> 00:00:16.749 align:start position:0%
where we'll be taking kind of a step
back<00:00:14.780><c> from</c><00:00:15.170><c> the</c><00:00:15.469><c> architectures</c><00:00:16.279><c> and</c><00:00:16.520><c> the</c>

00:00:16.749 --> 00:00:16.759 align:start position:0%
back from the architectures and the
 

00:00:16.759 --> 00:00:18.790 align:start position:0%
back from the architectures and the
algorithms<00:00:17.300><c> we've</c><00:00:17.840><c> been</c><00:00:17.990><c> exploring</c><00:00:18.320><c> over</c><00:00:18.710><c> the</c>

00:00:18.790 --> 00:00:18.800 align:start position:0%
algorithms we've been exploring over the
 

00:00:18.800 --> 00:00:21.370 align:start position:0%
algorithms we've been exploring over the
past<00:00:19.040><c> two</c><00:00:19.279><c> days</c><00:00:19.460><c> to</c><00:00:20.329><c> take</c><00:00:20.630><c> a</c><00:00:20.899><c> broader</c>

00:00:21.370 --> 00:00:21.380 align:start position:0%
past two days to take a broader
 

00:00:21.380 --> 00:00:24.190 align:start position:0%
past two days to take a broader
perspective<00:00:22.149><c> on</c><00:00:23.149><c> some</c><00:00:23.509><c> of</c><00:00:23.630><c> the</c><00:00:23.750><c> limitations</c>

00:00:24.190 --> 00:00:24.200 align:start position:0%
perspective on some of the limitations
 

00:00:24.200 --> 00:00:26.470 align:start position:0%
perspective on some of the limitations
of<00:00:24.800><c> deep</c><00:00:25.099><c> learning</c><00:00:25.279><c> and</c><00:00:25.669><c> a</c><00:00:26.090><c> couple</c><00:00:26.419><c> of</c>

00:00:26.470 --> 00:00:26.480 align:start position:0%
of deep learning and a couple of
 

00:00:26.480 --> 00:00:29.790 align:start position:0%
of deep learning and a couple of
exciting<00:00:26.809><c> new</c><00:00:27.320><c> subfields</c><00:00:27.980><c> that</c><00:00:28.160><c> are</c><00:00:28.399><c> emerging</c>

00:00:29.790 --> 00:00:29.800 align:start position:0%
exciting new subfields that are emerging
 

00:00:29.800 --> 00:00:33.370 align:start position:0%
exciting new subfields that are emerging
within<00:00:30.800><c> deep</c><00:00:31.430><c> learning</c><00:00:31.610><c> so</c><00:00:32.570><c> before</c><00:00:33.140><c> we</c><00:00:33.260><c> dive</c>

00:00:33.370 --> 00:00:33.380 align:start position:0%
within deep learning so before we dive
 

00:00:33.380 --> 00:00:35.830 align:start position:0%
within deep learning so before we dive
into<00:00:33.620><c> that</c><00:00:33.860><c> some</c><00:00:34.520><c> very</c><00:00:35.090><c> important</c>

00:00:35.830 --> 00:00:35.840 align:start position:0%
into that some very important
 

00:00:35.840 --> 00:00:39.900 align:start position:0%
into that some very important
announcements<00:00:36.620><c> first</c><00:00:37.160><c> and</c><00:00:37.400><c> foremost</c><00:00:37.850><c> we</c><00:00:38.180><c> have</c>

00:00:39.900 --> 00:00:39.910 align:start position:0%
announcements first and foremost we have
 

00:00:39.910 --> 00:00:42.310 align:start position:0%
announcements first and foremost we have
amazing<00:00:40.910><c> t-shirts</c><00:00:41.510><c> for</c><00:00:41.810><c> you</c><00:00:41.930><c> that</c><00:00:42.140><c> have</c>

00:00:42.310 --> 00:00:42.320 align:start position:0%
amazing t-shirts for you that have
 

00:00:42.320 --> 00:00:44.800 align:start position:0%
amazing t-shirts for you that have
arrived<00:00:42.650><c> and</c><00:00:43.010><c> we'll</c><00:00:43.610><c> be</c><00:00:43.730><c> distributing</c><00:00:44.270><c> them</c>

00:00:44.800 --> 00:00:44.810 align:start position:0%
arrived and we'll be distributing them
 

00:00:44.810 --> 00:00:48.550 align:start position:0%
arrived and we'll be distributing them
today<00:00:45.140><c> after</c><00:00:45.860><c> lecture</c><00:00:46.990><c> so</c><00:00:47.990><c> we'll</c><00:00:48.170><c> have</c><00:00:48.350><c> them</c>

00:00:48.550 --> 00:00:48.560 align:start position:0%
today after lecture so we'll have them
 

00:00:48.560 --> 00:00:50.590 align:start position:0%
today after lecture so we'll have them
arranged<00:00:49.070><c> sort</c><00:00:49.460><c> of</c><00:00:49.550><c> in</c><00:00:49.670><c> the</c><00:00:49.760><c> front</c><00:00:50.000><c> by</c><00:00:50.300><c> size</c>

00:00:50.590 --> 00:00:50.600 align:start position:0%
arranged sort of in the front by size
 

00:00:50.600 --> 00:00:53.700 align:start position:0%
arranged sort of in the front by size
and<00:00:51.130><c> we'd</c><00:00:52.130><c> first</c><00:00:52.340><c> like</c><00:00:52.460><c> to</c><00:00:52.700><c> distribute</c><00:00:53.030><c> two</c>

00:00:53.700 --> 00:00:53.710 align:start position:0%
and we'd first like to distribute two
 

00:00:53.710 --> 00:00:56.500 align:start position:0%
and we'd first like to distribute two
for<00:00:54.710><c> credit</c><00:00:55.100><c> registered</c><00:00:55.730><c> students</c><00:00:56.180><c> we</c><00:00:56.300><c> should</c>

00:00:56.500 --> 00:00:56.510 align:start position:0%
for credit registered students we should
 

00:00:56.510 --> 00:00:58.360 align:start position:0%
for credit registered students we should
have<00:00:56.660><c> plenty</c><00:00:57.140><c> for</c><00:00:57.350><c> everyone</c>

00:00:58.360 --> 00:00:58.370 align:start position:0%
have plenty for everyone
 

00:00:58.370 --> 00:01:00.430 align:start position:0%
have plenty for everyone
but<00:00:58.940><c> then</c><00:00:59.090><c> to</c><00:00:59.270><c> registered</c><00:00:59.720><c> listeners</c><00:01:00.200><c> and</c>

00:01:00.430 --> 00:01:00.440 align:start position:0%
but then to registered listeners and
 

00:01:00.440 --> 00:01:02.979 align:start position:0%
but then to registered listeners and
then<00:01:00.590><c> to</c><00:01:00.829><c> all</c><00:01:00.980><c> other</c><00:01:01.280><c> guests</c><00:01:02.030><c> and</c><00:01:02.149><c> lesson</c><00:01:02.840><c> and</c>

00:01:02.979 --> 00:01:02.989 align:start position:0%
then to all other guests and lesson and
 

00:01:02.989 --> 00:01:06.520 align:start position:0%
then to all other guests and lesson and
listeners<00:01:04.149><c> so</c><00:01:05.149><c> there</c><00:01:05.449><c> should</c><00:01:05.659><c> be</c><00:01:05.810><c> more</c><00:01:06.470><c> than</c>

00:01:06.520 --> 00:01:06.530 align:start position:0%
listeners so there should be more than
 

00:01:06.530 --> 00:01:10.210 align:start position:0%
listeners so there should be more than
enough<00:01:06.710><c> we</c><00:01:07.430><c> also</c><00:01:07.640><c> have</c><00:01:08.030><c> some</c><00:01:09.040><c> shirts</c><00:01:10.040><c> from</c>

00:01:10.210 --> 00:01:10.220 align:start position:0%
enough we also have some shirts from
 

00:01:10.220 --> 00:01:12.250 align:start position:0%
enough we also have some shirts from
Google<00:01:10.610><c> as</c><00:01:10.790><c> well</c><00:01:11.000><c> as</c><00:01:11.120><c> some</c><00:01:11.300><c> other</c><00:01:11.510><c> swag</c><00:01:11.900><c> so</c>

00:01:12.250 --> 00:01:12.260 align:start position:0%
Google as well as some other swag so
 

00:01:12.260 --> 00:01:14.020 align:start position:0%
Google as well as some other swag so
it's<00:01:12.530><c> gonna</c><00:01:12.710><c> be</c><00:01:12.890><c> really</c><00:01:13.100><c> exciting</c><00:01:13.580><c> and</c><00:01:13.700><c> please</c>

00:01:14.020 --> 00:01:14.030 align:start position:0%
it's gonna be really exciting and please
 

00:01:14.030 --> 00:01:19.660 align:start position:0%
it's gonna be really exciting and please
do<00:01:14.890><c> stick</c><00:01:15.890><c> around</c><00:01:16.040><c> for</c><00:01:16.670><c> that</c><00:01:17.620><c> so</c><00:01:18.620><c> sort</c><00:01:19.580><c> of</c>

00:01:19.660 --> 00:01:19.670 align:start position:0%
do stick around for that so sort of
 

00:01:19.670 --> 00:01:22.060 align:start position:0%
do stick around for that so sort of
where<00:01:20.030><c> have</c><00:01:20.840><c> we</c><00:01:21.020><c> been</c><00:01:21.049><c> and</c><00:01:21.500><c> where</c><00:01:21.710><c> are</c><00:01:21.950><c> we</c>

00:01:22.060 --> 00:01:22.070 align:start position:0%
where have we been and where are we
 

00:01:22.070 --> 00:01:25.210 align:start position:0%
where have we been and where are we
going<00:01:22.430><c> so</c><00:01:23.120><c> following</c><00:01:23.479><c> this</c><00:01:23.720><c> lecture</c><00:01:24.229><c> we</c><00:01:25.010><c> have</c>

00:01:25.210 --> 00:01:25.220 align:start position:0%
going so following this lecture we have
 

00:01:25.220 --> 00:01:27.060 align:start position:0%
going so following this lecture we have
our<00:01:25.340><c> final</c><00:01:25.790><c> lab</c><00:01:25.970><c> which</c><00:01:26.270><c> is</c><00:01:26.390><c> going</c><00:01:26.570><c> to</c><00:01:26.690><c> be</c><00:01:26.810><c> on</c>

00:01:27.060 --> 00:01:27.070 align:start position:0%
our final lab which is going to be on
 

00:01:27.070 --> 00:01:29.649 align:start position:0%
our final lab which is going to be on
reinforcement<00:01:28.070><c> learning</c><00:01:28.190><c> and</c><00:01:28.490><c> then</c><00:01:29.270><c> tomorrow</c>

00:01:29.649 --> 00:01:29.659 align:start position:0%
reinforcement learning and then tomorrow
 

00:01:29.659 --> 00:01:32.410 align:start position:0%
reinforcement learning and then tomorrow
we<00:01:29.960><c> have</c><00:01:30.170><c> two</c><00:01:30.500><c> extremely</c><00:01:31.250><c> exciting</c><00:01:31.820><c> guest</c>

00:01:32.410 --> 00:01:32.420 align:start position:0%
we have two extremely exciting guest
 

00:01:32.420 --> 00:01:35.649 align:start position:0%
we have two extremely exciting guest
lectures<00:01:32.900><c> from</c><00:01:33.260><c> Google</c><00:01:33.680><c> and</c><00:01:33.950><c> IBM</c><00:01:34.250><c> as</c><00:01:34.729><c> well</c><00:01:35.540><c> as</c>

00:01:35.649 --> 00:01:35.659 align:start position:0%
lectures from Google and IBM as well as
 

00:01:35.659 --> 00:01:38.109 align:start position:0%
lectures from Google and IBM as well as
time<00:01:35.930><c> for</c><00:01:36.200><c> you</c><00:01:36.350><c> to</c><00:01:36.560><c> work</c><00:01:37.070><c> on</c><00:01:37.280><c> your</c><00:01:37.670><c> final</c>

00:01:38.109 --> 00:01:38.119 align:start position:0%
time for you to work on your final
 

00:01:38.119 --> 00:01:40.719 align:start position:0%
time for you to work on your final
projects<00:01:38.780><c> during</c><00:01:39.049><c> the</c><00:01:39.170><c> lab</c><00:01:39.350><c> portion</c><00:01:39.590><c> and</c><00:01:40.070><c> on</c>

00:01:40.719 --> 00:01:40.729 align:start position:0%
projects during the lab portion and on
 

00:01:40.729 --> 00:01:42.789 align:start position:0%
projects during the lab portion and on
Friday<00:01:41.090><c> we'll</c><00:01:41.450><c> have</c><00:01:41.690><c> one</c><00:01:42.140><c> final</c><00:01:42.590><c> guest</c>

00:01:42.789 --> 00:01:42.799 align:start position:0%
Friday we'll have one final guest
 

00:01:42.799 --> 00:01:46.330 align:start position:0%
Friday we'll have one final guest
lecture<00:01:43.159><c> from</c><00:01:43.369><c> Nvidia</c><00:01:43.850><c> the</c><00:01:44.830><c> project</c><00:01:45.830><c> pitch</c>

00:01:46.330 --> 00:01:46.340 align:start position:0%
lecture from Nvidia the project pitch
 

00:01:46.340 --> 00:01:49.120 align:start position:0%
lecture from Nvidia the project pitch
competition<00:01:47.090><c> as</c><00:01:47.240><c> well</c><00:01:47.540><c> as</c><00:01:47.689><c> the</c><00:01:48.409><c> judging</c><00:01:48.920><c> and</c>

00:01:49.120 --> 00:01:49.130 align:start position:0%
competition as well as the judging and
 

00:01:49.130 --> 00:01:52.990 align:start position:0%
competition as well as the judging and
awards<00:01:49.640><c> ceremony</c><00:01:50.860><c> so</c><00:01:51.860><c> I've</c><00:01:52.159><c> we've</c><00:01:52.520><c> received</c><00:01:52.909><c> a</c>

00:01:52.990 --> 00:01:53.000 align:start position:0%
awards ceremony so I've we've received a
 

00:01:53.000 --> 00:01:56.020 align:start position:0%
awards ceremony so I've we've received a
lot<00:01:53.180><c> of</c><00:01:53.210><c> inquiries</c><00:01:53.540><c> about</c><00:01:54.460><c> the</c><00:01:55.460><c> the</c><00:01:55.700><c> final</c>

00:01:56.020 --> 00:01:56.030 align:start position:0%
lot of inquiries about the the final
 

00:01:56.030 --> 00:01:58.359 align:start position:0%
lot of inquiries about the the final
projects<00:01:56.540><c> and</c><00:01:56.840><c> specific</c><00:01:57.530><c> logistics</c><00:01:58.130><c> so</c><00:01:58.250><c> I'd</c>

00:01:58.359 --> 00:01:58.369 align:start position:0%
projects and specific logistics so I'd
 

00:01:58.369 --> 00:02:01.390 align:start position:0%
projects and specific logistics so I'd
like<00:01:58.640><c> to</c><00:01:58.700><c> take</c><00:01:59.180><c> a</c><00:01:59.210><c> few</c><00:01:59.450><c> minutes</c><00:01:59.750><c> to</c><00:02:00.049><c> to</c><00:02:00.979><c> recap</c>

00:02:01.390 --> 00:02:01.400 align:start position:0%
like to take a few minutes to to recap
 

00:02:01.400 --> 00:02:03.580 align:start position:0%
like to take a few minutes to to recap
that<00:02:01.610><c> so</c><00:02:02.360><c> for</c><00:02:02.659><c> those</c><00:02:02.900><c> of</c><00:02:02.960><c> you</c><00:02:03.110><c> who</c><00:02:03.350><c> are</c><00:02:03.409><c> taking</c>

00:02:03.580 --> 00:02:03.590 align:start position:0%
that so for those of you who are taking
 

00:02:03.590 --> 00:02:05.530 align:start position:0%
that so for those of you who are taking
the<00:02:03.860><c> course</c><00:02:03.890><c> for</c><00:02:04.100><c> credit</c><00:02:04.310><c> right</c><00:02:05.030><c> you</c><00:02:05.240><c> have</c><00:02:05.360><c> two</c>

00:02:05.530 --> 00:02:05.540 align:start position:0%
the course for credit right you have two
 

00:02:05.540 --> 00:02:07.600 align:start position:0%
the course for credit right you have two
options<00:02:05.990><c> to</c><00:02:06.080><c> fulfill</c><00:02:06.530><c> your</c><00:02:06.770><c> final</c>

00:02:07.600 --> 00:02:07.610 align:start position:0%
options to fulfill your final
 

00:02:07.610 --> 00:02:10.059 align:start position:0%
options to fulfill your final
requirement<00:02:08.179><c> the</c><00:02:08.569><c> first</c><00:02:08.840><c> is</c><00:02:09.200><c> a</c><00:02:09.439><c> project</c>

00:02:10.059 --> 00:02:10.069 align:start position:0%
requirement the first is a project
 

00:02:10.069 --> 00:02:13.239 align:start position:0%
requirement the first is a project
proposal<00:02:10.340><c> and</c><00:02:11.379><c> here</c><00:02:12.379><c> we're</c><00:02:12.709><c> asking</c><00:02:12.859><c> you</c><00:02:13.129><c> to</c>

00:02:13.239 --> 00:02:13.249 align:start position:0%
proposal and here we're asking you to
 

00:02:13.249 --> 00:02:16.000 align:start position:0%
proposal and here we're asking you to
really<00:02:14.090><c> pitch</c><00:02:14.419><c> a</c><00:02:14.659><c> novel</c><00:02:15.079><c> deep</c><00:02:15.260><c> learning</c>

00:02:16.000 --> 00:02:16.010 align:start position:0%
really pitch a novel deep learning
 

00:02:16.010 --> 00:02:19.600 align:start position:0%
really pitch a novel deep learning
architecture<00:02:16.790><c> idea</c><00:02:17.450><c> application</c><00:02:18.319><c> and</c><00:02:18.650><c> we've</c>

00:02:19.600 --> 00:02:19.610 align:start position:0%
architecture idea application and we've
 

00:02:19.610 --> 00:02:21.729 align:start position:0%
architecture idea application and we've
we've<00:02:20.299><c> gotten</c><00:02:20.930><c> a</c><00:02:21.019><c> lot</c><00:02:21.110><c> of</c><00:02:21.230><c> questions</c><00:02:21.590><c> about</c>

00:02:21.729 --> 00:02:21.739 align:start position:0%
we've gotten a lot of questions about
 

00:02:21.739 --> 00:02:24.640 align:start position:0%
we've gotten a lot of questions about
the<00:02:22.220><c> size</c><00:02:22.459><c> of</c><00:02:22.640><c> the</c><00:02:22.730><c> groups</c><00:02:23.000><c> so</c><00:02:23.420><c> groups</c><00:02:24.170><c> of</c><00:02:24.379><c> one</c>

00:02:24.640 --> 00:02:24.650 align:start position:0%
the size of the groups so groups of one
 

00:02:24.650 --> 00:02:27.580 align:start position:0%
the size of the groups so groups of one
are<00:02:24.920><c> welcome</c><00:02:25.730><c> but</c><00:02:26.209><c> you</c><00:02:26.420><c> will</c><00:02:26.569><c> not</c><00:02:26.750><c> be</c><00:02:26.959><c> eligible</c>

00:02:27.580 --> 00:02:27.590 align:start position:0%
are welcome but you will not be eligible
 

00:02:27.590 --> 00:02:30.339 align:start position:0%
are welcome but you will not be eligible
to<00:02:27.620><c> receive</c><00:02:27.860><c> a</c><00:02:28.159><c> prize</c><00:02:28.489><c> if</c><00:02:28.909><c> you</c><00:02:29.330><c> are</c><00:02:29.780><c> a</c><00:02:29.810><c> group</c><00:02:30.230><c> of</c>

00:02:30.339 --> 00:02:30.349 align:start position:0%
to receive a prize if you are a group of
 

00:02:30.349 --> 00:02:34.059 align:start position:0%
to receive a prize if you are a group of
one<00:02:30.970><c> listeners</c><00:02:31.970><c> are</c><00:02:32.209><c> welcome</c><00:02:32.629><c> to</c><00:02:32.870><c> to</c><00:02:33.379><c> present</c>

00:02:34.059 --> 00:02:34.069 align:start position:0%
one listeners are welcome to to present
 

00:02:34.069 --> 00:02:37.690 align:start position:0%
one listeners are welcome to to present
ideas<00:02:34.519><c> and</c><00:02:34.930><c> join</c><00:02:35.930><c> groups</c><00:02:36.260><c> in</c><00:02:36.620><c> order</c><00:02:37.310><c> to</c><00:02:37.580><c> be</c>

00:02:37.690 --> 00:02:37.700 align:start position:0%
ideas and join groups in order to be
 

00:02:37.700 --> 00:02:39.640 align:start position:0%
ideas and join groups in order to be
eligible<00:02:37.730><c> for</c><00:02:38.299><c> a</c><00:02:38.569><c> prize</c><00:02:38.930><c> you</c><00:02:39.230><c> must</c><00:02:39.260><c> have</c><00:02:39.620><c> a</c>

00:02:39.640 --> 00:02:39.650 align:start position:0%
eligible for a prize you must have a
 

00:02:39.650 --> 00:02:42.220 align:start position:0%
eligible for a prize you must have a
group<00:02:39.950><c> of</c><00:02:40.190><c> two</c><00:02:40.430><c> to</c><00:02:40.610><c> four</c><00:02:40.849><c> people</c><00:02:41.299><c> and</c><00:02:41.510><c> your</c>

00:02:42.220 --> 00:02:42.230 align:start position:0%
group of two to four people and your
 

00:02:42.230 --> 00:02:44.650 align:start position:0%
group of two to four people and your
group<00:02:42.470><c> must</c><00:02:42.709><c> include</c><00:02:43.040><c> at</c><00:02:43.370><c> least</c><00:02:43.400><c> one</c><00:02:44.090><c> for</c>

00:02:44.650 --> 00:02:44.660 align:start position:0%
group must include at least one for
 

00:02:44.660 --> 00:02:49.300 align:start position:0%
group must include at least one for
credit<00:02:45.500><c> registered</c><00:02:46.280><c> student</c><00:02:48.220><c> we're</c><00:02:49.220><c> gonna</c>

00:02:49.300 --> 00:02:49.310 align:start position:0%
credit registered student we're gonna
 

00:02:49.310 --> 00:02:51.699 align:start position:0%
credit registered student we're gonna
give<00:02:49.640><c> you</c><00:02:49.849><c> three</c><00:02:50.480><c> minutes</c><00:02:50.660><c> to</c><00:02:50.989><c> do</c><00:02:51.680><c> your</c>

00:02:51.699 --> 00:02:51.709 align:start position:0%
give you three minutes to do your
 

00:02:51.709 --> 00:02:55.780 align:start position:0%
give you three minutes to do your
pitches<00:02:52.250><c> and</c><00:02:53.260><c> this</c><00:02:54.260><c> link</c><00:02:54.650><c> there's</c><00:02:55.370><c> pretty</c>

00:02:55.780 --> 00:02:55.790 align:start position:0%
pitches and this link there's pretty
 

00:02:55.790 --> 00:02:58.630 align:start position:0%
pitches and this link there's pretty
detailed<00:02:56.590><c> instructions</c><00:02:57.590><c> for</c><00:02:57.709><c> the</c><00:02:58.310><c> the</c>

00:02:58.630 --> 00:02:58.640 align:start position:0%
detailed instructions for the the
 

00:02:58.640 --> 00:03:01.420 align:start position:0%
detailed instructions for the the
proposal<00:02:59.239><c> on</c><00:02:59.390><c> that</c><00:02:59.569><c> link</c><00:02:59.840><c> so</c><00:03:00.530><c> last</c><00:03:00.769><c> year</c><00:03:00.950><c> we</c><00:03:01.069><c> we</c>

00:03:01.420 --> 00:03:01.430 align:start position:0%
proposal on that link so last year we we
 

00:03:01.430 --> 00:03:03.190 align:start position:0%
proposal on that link so last year we we
only<00:03:01.579><c> gave</c><00:03:01.819><c> people</c><00:03:02.030><c> one</c><00:03:02.390><c> minute</c><00:03:02.720><c> for</c><00:03:02.989><c> their</c>

00:03:03.190 --> 00:03:03.200 align:start position:0%
only gave people one minute for their
 

00:03:03.200 --> 00:03:05.349 align:start position:0%
only gave people one minute for their
pitch<00:03:03.500><c> which</c><00:03:03.859><c> was</c><00:03:04.040><c> really</c><00:03:04.250><c> really</c><00:03:04.519><c> short</c><00:03:04.760><c> so</c>

00:03:05.349 --> 00:03:05.359 align:start position:0%
pitch which was really really short so
 

00:03:05.359 --> 00:03:07.119 align:start position:0%
pitch which was really really short so
by<00:03:05.840><c> giving</c><00:03:06.109><c> you</c><00:03:06.200><c> three</c><00:03:06.440><c> minutes</c><00:03:06.620><c> we're</c><00:03:06.920><c> really</c>

00:03:07.119 --> 00:03:07.129 align:start position:0%
by giving you three minutes we're really
 

00:03:07.129 --> 00:03:10.390 align:start position:0%
by giving you three minutes we're really
hoping<00:03:07.519><c> that</c><00:03:07.870><c> you</c><00:03:08.870><c> have</c><00:03:09.140><c> spent</c><00:03:09.739><c> some</c><00:03:09.920><c> time</c><00:03:10.190><c> to</c>

00:03:10.390 --> 00:03:10.400 align:start position:0%
hoping that you have spent some time to
 

00:03:10.400 --> 00:03:13.089 align:start position:0%
hoping that you have spent some time to
think<00:03:10.609><c> in-depth</c><00:03:11.060><c> about</c><00:03:11.269><c> your</c><00:03:11.900><c> idea</c><00:03:12.230><c> how</c><00:03:12.920><c> it</c>

00:03:13.089 --> 00:03:13.099 align:start position:0%
think in-depth about your idea how it
 

00:03:13.099 --> 00:03:16.479 align:start position:0%
think in-depth about your idea how it
could<00:03:13.250><c> work</c><00:03:13.280><c> why</c><00:03:14.030><c> it's</c><00:03:14.239><c> compelling</c><00:03:14.810><c> and</c><00:03:15.489><c> we're</c>

00:03:16.479 --> 00:03:16.489 align:start position:0%
could work why it's compelling and we're
 

00:03:16.489 --> 00:03:18.280 align:start position:0%
could work why it's compelling and we're
going<00:03:16.640><c> to</c><00:03:16.760><c> have</c><00:03:16.940><c> a</c><00:03:17.150><c> panel</c><00:03:17.510><c> of</c><00:03:17.660><c> judges</c>

00:03:18.280 --> 00:03:18.290 align:start position:0%
going to have a panel of judges
 

00:03:18.290 --> 00:03:21.280 align:start position:0%
going to have a panel of judges
including<00:03:19.099><c> judges</c><00:03:20.090><c> from</c><00:03:20.389><c> industry</c><00:03:20.900><c> as</c><00:03:21.109><c> well</c>

00:03:21.280 --> 00:03:21.290 align:start position:0%
including judges from industry as well
 

00:03:21.290 --> 00:03:24.400 align:start position:0%
including judges from industry as well
as<00:03:21.349><c> Alexander</c><00:03:22.280><c> myself</c><00:03:22.669><c> and</c><00:03:22.910><c> and</c><00:03:23.209><c> other</c><00:03:23.540><c> guest</c>

00:03:24.400 --> 00:03:24.410 align:start position:0%
as Alexander myself and and other guest
 

00:03:24.410 --> 00:03:27.970 align:start position:0%
as Alexander myself and and other guest
judges<00:03:24.680><c> and</c><00:03:25.010><c> our</c><00:03:26.000><c> prizes</c><00:03:26.419><c> are</c><00:03:26.900><c> these</c><00:03:27.680><c> three</c>

00:03:27.970 --> 00:03:27.980 align:start position:0%
judges and our prizes are these three
 

00:03:27.980 --> 00:03:30.550 align:start position:0%
judges and our prizes are these three
nvidia<00:03:28.639><c> gpus</c><00:03:29.239><c> as</c><00:03:29.510><c> well</c><00:03:29.780><c> as</c><00:03:29.930><c> a</c><00:03:30.139><c> set</c><00:03:30.380><c> of</c><00:03:30.410><c> four</c>

00:03:30.550 --> 00:03:30.560 align:start position:0%
nvidia gpus as well as a set of four
 

00:03:30.560 --> 00:03:35.050 align:start position:0%
nvidia gpus as well as a set of four
google<00:03:31.250><c> homes</c><00:03:32.980><c> sort</c><00:03:33.980><c> of</c><00:03:34.069><c> how</c><00:03:34.370><c> the</c><00:03:34.430><c> the</c><00:03:34.819><c> prize</c>

00:03:35.050 --> 00:03:35.060 align:start position:0%
google homes sort of how the the prize
 

00:03:35.060 --> 00:03:38.140 align:start position:0%
google homes sort of how the the prize
Awards<00:03:35.720><c> awarding</c><00:03:36.530><c> is</c><00:03:36.680><c> going</c><00:03:36.829><c> to</c><00:03:36.889><c> go</c><00:03:37.099><c> is</c><00:03:37.370><c> that</c>

00:03:38.140 --> 00:03:38.150 align:start position:0%
Awards awarding is going to go is that
 

00:03:38.150 --> 00:03:41.770 align:start position:0%
Awards awarding is going to go is that
top<00:03:38.690><c> three</c><00:03:39.380><c> teams</c><00:03:39.620><c> will</c><00:03:40.579><c> be</c><00:03:40.730><c> awarded</c><00:03:41.239><c> a</c><00:03:41.389><c> GPU</c>

00:03:41.770 --> 00:03:41.780 align:start position:0%
top three teams will be awarded a GPU
 

00:03:41.780 --> 00:03:44.530 align:start position:0%
top three teams will be awarded a GPU
per<00:03:42.349><c> team</c><00:03:42.590><c> and</c><00:03:42.919><c> the</c><00:03:43.489><c> Google</c><00:03:43.849><c> homes</c><00:03:44.090><c> will</c><00:03:44.419><c> be</c>

00:03:44.530 --> 00:03:44.540 align:start position:0%
per team and the Google homes will be
 

00:03:44.540 --> 00:03:48.759 align:start position:0%
per team and the Google homes will be
distributed<00:03:45.200><c> within</c><00:03:45.560><c> one</c><00:03:46.280><c> team</c><00:03:47.109><c> so</c><00:03:48.109><c> if</c><00:03:48.380><c> you</c>

00:03:48.759 --> 00:03:48.769 align:start position:0%
distributed within one team so if you
 

00:03:48.769 --> 00:03:50.860 align:start position:0%
distributed within one team so if you
have<00:03:48.889><c> a</c><00:03:48.919><c> team</c><00:03:49.190><c> that</c><00:03:49.489><c> has</c><00:03:50.030><c> four</c><00:03:50.239><c> people</c><00:03:50.569><c> right</c>

00:03:50.860 --> 00:03:50.870 align:start position:0%
have a team that has four people right
 

00:03:50.870 --> 00:03:52.870 align:start position:0%
have a team that has four people right
and<00:03:51.079><c> you're</c><00:03:51.530><c> awarded</c><00:03:51.769><c> the</c><00:03:52.160><c> the</c><00:03:52.430><c> Google</c><00:03:52.730><c> home</c>

00:03:52.870 --> 00:03:52.880 align:start position:0%
and you're awarded the the Google home
 

00:03:52.880 --> 00:03:54.879 align:start position:0%
and you're awarded the the Google home
prize<00:03:53.150><c> everyone</c><00:03:53.690><c> will</c><00:03:53.840><c> get</c><00:03:53.959><c> a</c><00:03:54.019><c> Google</c><00:03:54.349><c> home</c><00:03:54.650><c> if</c>

00:03:54.879 --> 00:03:54.889 align:start position:0%
prize everyone will get a Google home if
 

00:03:54.889 --> 00:03:57.789 align:start position:0%
prize everyone will get a Google home if
you<00:03:55.010><c> have</c><00:03:55.160><c> two</c><00:03:56.169><c> each</c><00:03:57.169><c> of</c><00:03:57.200><c> you</c><00:03:57.470><c> will</c><00:03:57.620><c> get</c><00:03:57.739><c> one</c>

00:03:57.789 --> 00:03:57.799 align:start position:0%
you have two each of you will get one
 

00:03:57.799 --> 00:03:59.890 align:start position:0%
you have two each of you will get one
and<00:03:58.250><c> then</c><00:03:58.609><c> the</c><00:03:59.000><c> remaining</c><00:03:59.419><c> two</c><00:03:59.599><c> will</c><00:03:59.629><c> be</c>

00:03:59.890 --> 00:03:59.900 align:start position:0%
and then the remaining two will be
 

00:03:59.900 --> 00:04:06.250 align:start position:0%
and then the remaining two will be
awarded<00:04:00.769><c> to</c><00:04:00.799><c> to</c><00:04:01.340><c> the</c><00:04:01.519><c> next</c><00:04:02.590><c> best</c><00:04:03.590><c> team</c><00:04:05.200><c> okay</c><00:04:06.200><c> so</c>

00:04:06.250 --> 00:04:06.260 align:start position:0%
awarded to to the next best team okay so
 

00:04:06.260 --> 00:04:10.089 align:start position:0%
awarded to to the next best team okay so
in<00:04:06.859><c> terms</c><00:04:07.129><c> of</c><00:04:07.579><c> actually</c><00:04:08.120><c> completing</c><00:04:08.780><c> this</c><00:04:09.099><c> we</c>

00:04:10.089 --> 00:04:10.099 align:start position:0%
in terms of actually completing this we
 

00:04:10.099 --> 00:04:12.879 align:start position:0%
in terms of actually completing this we
ask<00:04:10.280><c> that</c><00:04:10.579><c> you</c><00:04:10.700><c> prepare</c><00:04:11.180><c> slides</c><00:04:11.690><c> for</c><00:04:12.290><c> your</c><00:04:12.410><c> for</c>

00:04:12.879 --> 00:04:12.889 align:start position:0%
ask that you prepare slides for your for
 

00:04:12.889 --> 00:04:16.120 align:start position:0%
ask that you prepare slides for your for
your<00:04:13.010><c> pitch</c><00:04:13.699><c> on</c><00:04:13.989><c> Google</c><00:04:14.989><c> slides</c><00:04:15.260><c> so</c><00:04:15.620><c> on</c><00:04:15.799><c> Friday</c>

00:04:16.120 --> 00:04:16.130 align:start position:0%
your pitch on Google slides so on Friday
 

00:04:16.130 --> 00:04:17.890 align:start position:0%
your pitch on Google slides so on Friday
if<00:04:16.430><c> you're</c><00:04:16.549><c> participating</c><00:04:16.910><c> you'll</c><00:04:17.479><c> come</c><00:04:17.720><c> down</c>

00:04:17.890 --> 00:04:17.900 align:start position:0%
if you're participating you'll come down
 

00:04:17.900 --> 00:04:20.770 align:start position:0%
if you're participating you'll come down
to<00:04:18.079><c> the</c><00:04:18.169><c> front</c><00:04:18.639><c> present</c><00:04:19.639><c> your</c><00:04:19.820><c> pitch</c><00:04:20.030><c> to</c><00:04:20.630><c> the</c>

00:04:20.770 --> 00:04:20.780 align:start position:0%
to the front present your pitch to the
 

00:04:20.780 --> 00:04:23.439 align:start position:0%
to the front present your pitch to the
rest<00:04:20.959><c> of</c><00:04:21.109><c> the</c><00:04:21.199><c> class</c><00:04:21.410><c> and</c><00:04:21.680><c> to</c><00:04:21.829><c> our</c><00:04:21.949><c> judges</c><00:04:22.449><c> we</c>

00:04:23.439 --> 00:04:23.449 align:start position:0%
rest of the class and to our judges we
 

00:04:23.449 --> 00:04:26.050 align:start position:0%
rest of the class and to our judges we
ask<00:04:23.660><c> that</c><00:04:23.900><c> you</c><00:04:24.080><c> please</c><00:04:24.370><c> submit</c><00:04:25.370><c> your</c><00:04:25.550><c> groups</c>

00:04:26.050 --> 00:04:26.060 align:start position:0%
ask that you please submit your groups
 

00:04:26.060 --> 00:04:27.760 align:start position:0%
ask that you please submit your groups
on<00:04:26.390><c> by</c><00:04:27.200><c> today</c>

00:04:27.760 --> 00:04:27.770 align:start position:0%
on by today
 

00:04:27.770 --> 00:04:30.550 align:start position:0%
on by today
tonight<00:04:28.039><c> at</c><00:04:28.250><c> 10</c><00:04:28.520><c> p.m.</c><00:04:28.819><c> there's</c><00:04:29.629><c> this</c><00:04:30.229><c> link</c>

00:04:30.550 --> 00:04:30.560 align:start position:0%
tonight at 10 p.m. there's this link
 

00:04:30.560 --> 00:04:33.490 align:start position:0%
tonight at 10 p.m. there's this link
leads<00:04:31.129><c> to</c><00:04:31.520><c> a</c><00:04:31.550><c> Google</c><00:04:32.090><c> sheet</c><00:04:32.120><c> where</c><00:04:32.780><c> you</c><00:04:33.050><c> can</c>

00:04:33.490 --> 00:04:33.500 align:start position:0%
leads to a Google sheet where you can
 

00:04:33.500 --> 00:04:36.490 align:start position:0%
leads to a Google sheet where you can
sign<00:04:33.770><c> up</c><00:04:33.800><c> with</c><00:04:34.389><c> your</c><00:04:35.389><c> your</c><00:04:35.569><c> team</c><00:04:35.870><c> members</c>

00:04:36.490 --> 00:04:36.500 align:start position:0%
sign up with your your team members
 

00:04:36.500 --> 00:04:39.339 align:start position:0%
sign up with your your team members
names<00:04:36.800><c> and</c><00:04:37.099><c> a</c><00:04:37.550><c> tentative</c><00:04:38.120><c> like</c><00:04:38.659><c> title</c><00:04:39.110><c> for</c>

00:04:39.339 --> 00:04:39.349 align:start position:0%
names and a tentative like title for
 

00:04:39.349 --> 00:04:40.680 align:start position:0%
names and a tentative like title for
your<00:04:39.470><c> for</c><00:04:39.919><c> your</c><00:04:40.009><c> project</c>

00:04:40.680 --> 00:04:40.690 align:start position:0%
your for your project
 

00:04:40.690 --> 00:04:42.850 align:start position:0%
your for your project
tomorrow's<00:04:41.690><c> lab</c><00:04:42.169><c> portion</c><00:04:42.650><c> will</c><00:04:42.830><c> be</c>

00:04:42.850 --> 00:04:42.860 align:start position:0%
tomorrow's lab portion will be
 

00:04:42.860 --> 00:04:46.480 align:start position:0%
tomorrow's lab portion will be
completely<00:04:43.550><c> devoted</c><00:04:43.940><c> to</c><00:04:44.090><c> in-class</c><00:04:45.250><c> work</c><00:04:46.250><c> on</c>

00:04:46.480 --> 00:04:46.490 align:start position:0%
completely devoted to in-class work on
 

00:04:46.490 --> 00:04:49.540 align:start position:0%
completely devoted to in-class work on
the<00:04:46.610><c> project</c><00:04:47.229><c> then</c><00:04:48.229><c> we</c><00:04:48.409><c> ask</c><00:04:48.590><c> that</c><00:04:48.860><c> you</c><00:04:49.069><c> submit</c>

00:04:49.540 --> 00:04:49.550 align:start position:0%
the project then we ask that you submit
 

00:04:49.550 --> 00:04:53.499 align:start position:0%
the project then we ask that you submit
your<00:04:49.819><c> slides</c><00:04:50.919><c> by</c><00:04:51.919><c> midnight</c><00:04:52.490><c> Thursday</c><00:04:53.300><c> night</c>

00:04:53.499 --> 00:04:53.509 align:start position:0%
your slides by midnight Thursday night
 

00:04:53.509 --> 00:04:56.080 align:start position:0%
your slides by midnight Thursday night
so<00:04:54.289><c> that</c><00:04:54.440><c> we</c><00:04:54.620><c> have</c><00:04:54.830><c> everything</c><00:04:55.069><c> ready</c><00:04:55.520><c> and</c><00:04:55.970><c> in</c>

00:04:56.080 --> 00:04:56.090 align:start position:0%
so that we have everything ready and in
 

00:04:56.090 --> 00:04:58.570 align:start position:0%
so that we have everything ready and in
order<00:04:56.509><c> for</c><00:04:56.539><c> Friday</c><00:04:56.960><c> and</c><00:04:57.319><c> the</c><00:04:58.009><c> link</c><00:04:58.220><c> for</c><00:04:58.370><c> doing</c>

00:04:58.570 --> 00:04:58.580 align:start position:0%
order for Friday and the link for doing
 

00:04:58.580 --> 00:05:00.580 align:start position:0%
order for Friday and the link for doing
that<00:04:58.699><c> is</c><00:04:58.879><c> there</c><00:04:59.150><c> and</c><00:04:59.389><c> finally</c><00:05:00.080><c> our</c><00:05:00.259><c> our</c>

00:05:00.580 --> 00:05:00.590 align:start position:0%
that is there and finally our our
 

00:05:00.590 --> 00:05:05.230 align:start position:0%
that is there and finally our our
presentations<00:05:01.310><c> will</c><00:05:01.550><c> be</c><00:05:01.580><c> on</c><00:05:01.940><c> Friday</c><00:05:03.880><c> so</c><00:05:04.880><c> as</c>

00:05:05.230 --> 00:05:05.240 align:start position:0%
presentations will be on Friday so as
 

00:05:05.240 --> 00:05:07.390 align:start position:0%
presentations will be on Friday so as
was<00:05:06.020><c> discussed</c><00:05:06.380><c> in</c><00:05:06.560><c> the</c><00:05:06.680><c> first</c><00:05:06.830><c> lecture</c><00:05:06.979><c> the</c>

00:05:07.390 --> 00:05:07.400 align:start position:0%
was discussed in the first lecture the
 

00:05:07.400 --> 00:05:11.140 align:start position:0%
was discussed in the first lecture the
section<00:05:07.759><c> second</c><00:05:09.069><c> arguably</c><00:05:10.069><c> most</c><00:05:10.400><c> more</c><00:05:10.849><c> boring</c>

00:05:11.140 --> 00:05:11.150 align:start position:0%
section second arguably most more boring
 

00:05:11.150 --> 00:05:14.290 align:start position:0%
section second arguably most more boring
option<00:05:11.690><c> is</c><00:05:11.900><c> to</c><00:05:12.620><c> write</c><00:05:12.860><c> a</c><00:05:12.889><c> one-page</c><00:05:13.340><c> review</c><00:05:14.090><c> of</c>

00:05:14.290 --> 00:05:14.300 align:start position:0%
option is to write a one-page review of
 

00:05:14.300 --> 00:05:16.600 align:start position:0%
option is to write a one-page review of
a<00:05:14.690><c> recent</c><00:05:15.080><c> deep</c><00:05:15.259><c> learning</c><00:05:15.409><c> paper</c><00:05:15.889><c> it</c><00:05:16.220><c> can</c><00:05:16.400><c> be</c>

00:05:16.600 --> 00:05:16.610 align:start position:0%
a recent deep learning paper it can be
 

00:05:16.610 --> 00:05:18.909 align:start position:0%
a recent deep learning paper it can be
either<00:05:17.150><c> on</c><00:05:17.389><c> you</c><00:05:17.930><c> know</c><00:05:18.050><c> deep</c><00:05:18.770><c> learning</c>

00:05:18.909 --> 00:05:18.919 align:start position:0%
either on you know deep learning
 

00:05:18.919 --> 00:05:20.649 align:start position:0%
either on you know deep learning
fundamentals<00:05:19.699><c> and</c><00:05:19.880><c> theory</c><00:05:20.210><c> or</c><00:05:20.419><c> an</c>

00:05:20.649 --> 00:05:20.659 align:start position:0%
fundamentals and theory or an
 

00:05:20.659 --> 00:05:23.379 align:start position:0%
fundamentals and theory or an
interesting<00:05:21.289><c> application</c><00:05:21.710><c> of</c><00:05:22.400><c> deep</c><00:05:23.210><c> learning</c>

00:05:23.379 --> 00:05:23.389 align:start position:0%
interesting application of deep learning
 

00:05:23.389 --> 00:05:25.360 align:start position:0%
interesting application of deep learning
to<00:05:23.810><c> a</c><00:05:24.110><c> different</c><00:05:24.500><c> domain</c><00:05:24.650><c> that</c><00:05:25.009><c> you</c><00:05:25.159><c> may</c><00:05:25.310><c> be</c>

00:05:25.360 --> 00:05:25.370 align:start position:0%
to a different domain that you may be
 

00:05:25.370 --> 00:05:28.240 align:start position:0%
to a different domain that you may be
interested<00:05:25.759><c> in</c><00:05:26.110><c> and</c><00:05:27.110><c> this</c><00:05:27.440><c> would</c><00:05:27.680><c> be</c><00:05:27.860><c> due</c>

00:05:28.240 --> 00:05:28.250 align:start position:0%
interested in and this would be due
 

00:05:28.250 --> 00:05:30.850 align:start position:0%
interested in and this would be due
Friday<00:05:28.909><c> at</c><00:05:29.330><c> the</c><00:05:29.569><c> beginning</c><00:05:29.990><c> of</c><00:05:30.110><c> class</c><00:05:30.259><c> by</c>

00:05:30.850 --> 00:05:30.860 align:start position:0%
Friday at the beginning of class by
 

00:05:30.860 --> 00:05:33.870 align:start position:0%
Friday at the beginning of class by
email<00:05:31.520><c> to</c><00:05:31.759><c> -</c><00:05:32.300><c> intro</c><00:05:32.659><c> to</c><00:05:32.810><c> deep</c><00:05:32.990><c> learning</c><00:05:33.380><c> stuff</c>

00:05:33.870 --> 00:05:33.880 align:start position:0%
email to - intro to deep learning stuff
 

00:05:33.880 --> 00:05:38.920 align:start position:0%
email to - intro to deep learning stuff
mit.edu<00:05:36.580><c> okay</c><00:05:37.580><c> so</c><00:05:37.639><c> tomorrow</c><00:05:38.360><c> we're</c><00:05:38.630><c> going</c><00:05:38.810><c> to</c>

00:05:38.920 --> 00:05:38.930 align:start position:0%
mit.edu okay so tomorrow we're going to
 

00:05:38.930 --> 00:05:42.129 align:start position:0%
mit.edu okay so tomorrow we're going to
have<00:05:39.080><c> two</c><00:05:39.380><c> guest</c><00:05:40.069><c> speakers</c><00:05:40.539><c> the</c><00:05:41.539><c> first</c><00:05:41.810><c> is</c>

00:05:42.129 --> 00:05:42.139 align:start position:0%
have two guest speakers the first is
 

00:05:42.139 --> 00:05:44.110 align:start position:0%
have two guest speakers the first is
going<00:05:42.440><c> to</c><00:05:42.530><c> be</c><00:05:42.770><c> where</c><00:05:43.279><c> we're</c><00:05:43.610><c> really</c><00:05:43.880><c> really</c>

00:05:44.110 --> 00:05:44.120 align:start position:0%
going to be where we're really really
 

00:05:44.120 --> 00:05:45.519 align:start position:0%
going to be where we're really really
lucky<00:05:44.330><c> and</c><00:05:44.599><c> privileged</c><00:05:44.990><c> to</c><00:05:45.080><c> have</c><00:05:45.319><c> her</c>

00:05:45.519 --> 00:05:45.529 align:start position:0%
lucky and privileged to have her
 

00:05:45.529 --> 00:05:49.570 align:start position:0%
lucky and privileged to have her
Fernanda<00:05:46.069><c> Viegas</c><00:05:46.479><c> she</c><00:05:47.479><c> is</c><00:05:47.750><c> an</c><00:05:48.380><c> MIT</c><00:05:48.620><c> alum</c><00:05:49.340><c> and</c>

00:05:49.570 --> 00:05:49.580 align:start position:0%
Fernanda Viegas she is an MIT alum and
 

00:05:49.580 --> 00:05:52.089 align:start position:0%
Fernanda Viegas she is an MIT alum and
she's<00:05:49.819><c> the</c><00:05:50.090><c> co-director</c><00:05:50.779><c> of</c><00:05:50.810><c> Google's</c><00:05:51.380><c> people</c>

00:05:52.089 --> 00:05:52.099 align:start position:0%
she's the co-director of Google's people
 

00:05:52.099 --> 00:05:54.760 align:start position:0%
she's the co-director of Google's people
and<00:05:52.370><c> artificial</c><00:05:53.120><c> intelligence</c><00:05:53.469><c> Research</c><00:05:54.469><c> Lab</c>

00:05:54.760 --> 00:05:54.770 align:start position:0%
and artificial intelligence Research Lab
 

00:05:54.770 --> 00:05:57.510 align:start position:0%
and artificial intelligence Research Lab
or<00:05:55.039><c> pair</c><00:05:55.460><c> and</c><00:05:55.729><c> she's</c><00:05:56.419><c> a</c><00:05:56.690><c> world-class</c>

00:05:57.510 --> 00:05:57.520 align:start position:0%
or pair and she's a world-class
 

00:05:57.520 --> 00:06:00.820 align:start position:0%
or pair and she's a world-class
specialist<00:05:58.520><c> on</c><00:05:58.789><c> visualization</c><00:05:59.830><c> techniques</c>

00:06:00.820 --> 00:06:00.830 align:start position:0%
specialist on visualization techniques
 

00:06:00.830 --> 00:06:02.860 align:start position:0%
specialist on visualization techniques
for<00:06:01.069><c> machine</c><00:06:01.400><c> learning</c><00:06:01.430><c> and</c><00:06:01.940><c> deep</c><00:06:02.750><c> learning</c>

00:06:02.860 --> 00:06:02.870 align:start position:0%
for machine learning and deep learning
 

00:06:02.870 --> 00:06:05.230 align:start position:0%
for machine learning and deep learning
so<00:06:03.319><c> it</c><00:06:03.500><c> should</c><00:06:03.680><c> be</c><00:06:03.800><c> a</c><00:06:03.830><c> really</c><00:06:04.099><c> fun</c><00:06:04.240><c> interactive</c>

00:06:05.230 --> 00:06:05.240 align:start position:0%
so it should be a really fun interactive
 

00:06:05.240 --> 00:06:08.439 align:start position:0%
so it should be a really fun interactive
a<00:06:05.419><c> cool</c><00:06:06.050><c> talk</c><00:06:06.319><c> and</c><00:06:06.699><c> we</c><00:06:07.699><c> really</c><00:06:08.000><c> hope</c><00:06:08.180><c> to</c><00:06:08.210><c> see</c>

00:06:08.439 --> 00:06:08.449 align:start position:0%
a cool talk and we really hope to see
 

00:06:08.449 --> 00:06:11.740 align:start position:0%
a cool talk and we really hope to see
everyone<00:06:08.690><c> there</c><00:06:09.310><c> the</c><00:06:10.310><c> second</c><00:06:10.729><c> talk</c><00:06:11.270><c> will</c><00:06:11.630><c> be</c>

00:06:11.740 --> 00:06:11.750 align:start position:0%
everyone there the second talk will be
 

00:06:11.750 --> 00:06:15.339 align:start position:0%
everyone there the second talk will be
given<00:06:12.199><c> by</c><00:06:12.319><c> Dimitri</c><00:06:13.279><c> or</c><00:06:13.460><c> dima</c><00:06:13.880><c> crota</c><00:06:14.419><c> from</c><00:06:14.779><c> the</c>

00:06:15.339 --> 00:06:15.349 align:start position:0%
given by Dimitri or dima crota from the
 

00:06:15.349 --> 00:06:18.670 align:start position:0%
given by Dimitri or dima crota from the
MIT<00:06:15.680><c> IBM</c><00:06:16.279><c> Watson</c><00:06:16.789><c> AI</c><00:06:17.000><c> lab</c><00:06:17.330><c> he's</c><00:06:18.080><c> a</c><00:06:18.110><c> physicist</c>

00:06:18.670 --> 00:06:18.680 align:start position:0%
MIT IBM Watson AI lab he's a physicist
 

00:06:18.680 --> 00:06:20.980 align:start position:0%
MIT IBM Watson AI lab he's a physicist
by<00:06:18.919><c> training</c><00:06:18.949><c> really</c><00:06:19.819><c> exciting</c><00:06:20.389><c> and</c><00:06:20.539><c> fun</c><00:06:20.569><c> guy</c>

00:06:20.980 --> 00:06:20.990 align:start position:0%
by training really exciting and fun guy
 

00:06:20.990 --> 00:06:24.550 align:start position:0%
by training really exciting and fun guy
and<00:06:21.289><c> his</c><00:06:22.039><c> research</c><00:06:22.370><c> focuses</c><00:06:22.969><c> on</c><00:06:23.560><c> biologically</c>

00:06:24.550 --> 00:06:24.560 align:start position:0%
and his research focuses on biologically
 

00:06:24.560 --> 00:06:27.909 align:start position:0%
and his research focuses on biologically
plausible<00:06:25.990><c> algorithms</c><00:06:26.990><c> for</c><00:06:27.289><c> training</c><00:06:27.740><c> neural</c>

00:06:27.909 --> 00:06:27.919 align:start position:0%
plausible algorithms for training neural
 

00:06:27.919 --> 00:06:30.249 align:start position:0%
plausible algorithms for training neural
network<00:06:28.370><c> so</c><00:06:28.639><c> he'll</c><00:06:28.940><c> he'll</c><00:06:29.509><c> give</c><00:06:29.690><c> some</c><00:06:29.900><c> insight</c>

00:06:30.249 --> 00:06:30.259 align:start position:0%
network so he'll he'll give some insight
 

00:06:30.259 --> 00:06:32.080 align:start position:0%
network so he'll he'll give some insight
onto<00:06:30.500><c> whether</c><00:06:30.919><c> or</c><00:06:31.130><c> not</c><00:06:31.250><c> back</c><00:06:31.550><c> propagation</c>

00:06:32.080 --> 00:06:32.090 align:start position:0%
onto whether or not back propagation
 

00:06:32.090 --> 00:06:34.450 align:start position:0%
onto whether or not back propagation
could<00:06:32.599><c> actually</c><00:06:32.810><c> be</c><00:06:33.219><c> biologically</c><00:06:34.219><c> plausible</c>

00:06:34.450 --> 00:06:34.460 align:start position:0%
could actually be biologically plausible
 

00:06:34.460 --> 00:06:37.420 align:start position:0%
could actually be biologically plausible
and<00:06:34.969><c> if</c><00:06:35.060><c> not</c><00:06:35.300><c> what</c><00:06:35.659><c> are</c><00:06:35.779><c> some</c><00:06:36.399><c> you</c><00:06:37.399><c> know</c>

00:06:37.420 --> 00:06:37.430 align:start position:0%
and if not what are some you know
 

00:06:37.430 --> 00:06:40.269 align:start position:0%
and if not what are some you know
exciting<00:06:38.060><c> new</c><00:06:38.300><c> ideas</c><00:06:39.139><c> about</c><00:06:39.440><c> how</c><00:06:39.949><c> learning</c>

00:06:40.269 --> 00:06:40.279 align:start position:0%
exciting new ideas about how learning
 

00:06:40.279 --> 00:06:41.200 align:start position:0%
exciting new ideas about how learning
could<00:06:40.820><c> act</c>

00:06:41.200 --> 00:06:41.210 align:start position:0%
could act
 

00:06:41.210 --> 00:06:45.999 align:start position:0%
could act
we<00:06:41.330><c> work</c><00:06:41.810><c> in</c><00:06:42.370><c> in</c><00:06:44.020><c> the</c><00:06:45.020><c> neuroscientific</c><00:06:45.680><c> sense</c>

00:06:45.999 --> 00:06:46.009 align:start position:0%
we work in in the neuroscientific sense
 

00:06:46.009 --> 00:06:49.059 align:start position:0%
we work in in the neuroscientific sense
I<00:06:46.220><c> guess</c><00:06:46.870><c> then</c><00:06:47.870><c> the</c><00:06:48.020><c> lab</c><00:06:48.199><c> portion</c><00:06:48.470><c> is</c><00:06:48.800><c> going</c><00:06:48.830><c> to</c>

00:06:49.059 --> 00:06:49.069 align:start position:0%
I guess then the lab portion is going to
 

00:06:49.069 --> 00:06:51.219 align:start position:0%
I guess then the lab portion is going to
be<00:06:49.160><c> devoted</c><00:06:49.400><c> to</c><00:06:49.610><c> work</c><00:06:49.940><c> on</c><00:06:50.090><c> the</c><00:06:50.210><c> final</c><00:06:50.599><c> projects</c>

00:06:51.219 --> 00:06:51.229 align:start position:0%
be devoted to work on the final projects
 

00:06:51.229 --> 00:06:53.110 align:start position:0%
be devoted to work on the final projects
we'll<00:06:51.470><c> be</c><00:06:51.620><c> here</c><00:06:51.889><c> the</c><00:06:52.039><c> TAS</c><00:06:52.370><c> will</c><00:06:52.490><c> be</c><00:06:52.729><c> here</c><00:06:53.000><c> you</c>

00:06:53.110 --> 00:06:53.120 align:start position:0%
we'll be here the TAS will be here you
 

00:06:53.120 --> 00:06:55.290 align:start position:0%
we'll be here the TAS will be here you
can<00:06:53.150><c> brainstorm</c><00:06:53.539><c> with</c><00:06:53.990><c> us</c><00:06:54.139><c> ask</c><00:06:54.380><c> us</c><00:06:54.500><c> questions</c>

00:06:55.290 --> 00:06:55.300 align:start position:0%
can brainstorm with us ask us questions
 

00:06:55.300 --> 00:06:58.120 align:start position:0%
can brainstorm with us ask us questions
you<00:06:56.300><c> know</c><00:06:56.389><c> work</c><00:06:56.630><c> with</c><00:06:56.660><c> your</c><00:06:56.960><c> team</c><00:06:57.199><c> you</c><00:06:57.860><c> get</c><00:06:58.009><c> the</c>

00:06:58.120 --> 00:06:58.130 align:start position:0%
you know work with your team you get the
 

00:06:58.130 --> 00:06:58.830 align:start position:0%
you know work with your team you get the
point

00:06:58.830 --> 00:06:58.840 align:start position:0%
point
 

00:06:58.840 --> 00:07:01.540 align:start position:0%
point
finally<00:06:59.840><c> Thursday</c><00:07:00.349><c> we'll</c><00:07:00.889><c> have</c><00:07:00.919><c> our</c><00:07:01.160><c> final</c>

00:07:01.540 --> 00:07:01.550 align:start position:0%
finally Thursday we'll have our final
 

00:07:01.550 --> 00:07:04.180 align:start position:0%
finally Thursday we'll have our final
guest<00:07:01.699><c> lecture</c><00:07:02.150><c> given</c><00:07:02.569><c> by</c><00:07:02.750><c> Yann</c><00:07:03.440><c> Kouts</c><00:07:03.770><c> from</c>

00:07:04.180 --> 00:07:04.190 align:start position:0%
guest lecture given by Yann Kouts from
 

00:07:04.190 --> 00:07:06.990 align:start position:0%
guest lecture given by Yann Kouts from
Nvidia<00:07:04.669><c> who's</c><00:07:05.300><c> a</c><00:07:05.330><c> leader</c><00:07:05.720><c> in</c><00:07:06.020><c> computer</c><00:07:06.560><c> vision</c>

00:07:06.990 --> 00:07:07.000 align:start position:0%
Nvidia who's a leader in computer vision
 

00:07:07.000 --> 00:07:10.029 align:start position:0%
Nvidia who's a leader in computer vision
and<00:07:08.000><c> then</c><00:07:08.270><c> we'll</c><00:07:08.509><c> have</c><00:07:08.720><c> the</c><00:07:08.990><c> project</c><00:07:09.349><c> proposal</c>

00:07:10.029 --> 00:07:10.039 align:start position:0%
and then we'll have the project proposal
 

00:07:10.039 --> 00:07:12.990 align:start position:0%
and then we'll have the project proposal
competition<00:07:10.910><c> the</c><00:07:11.120><c> awards</c><00:07:11.569><c> as</c><00:07:11.750><c> well</c><00:07:12.229><c> as</c><00:07:12.380><c> pizza</c>

00:07:12.990 --> 00:07:13.000 align:start position:0%
competition the awards as well as pizza
 

00:07:13.000 --> 00:07:18.010 align:start position:0%
competition the awards as well as pizza
celebration<00:07:14.000><c> at</c><00:07:14.300><c> the</c><00:07:14.360><c> end</c><00:07:15.699><c> ok</c><00:07:16.699><c> so</c><00:07:17.030><c> that</c><00:07:17.720><c> is</c>

00:07:18.010 --> 00:07:18.020 align:start position:0%
celebration at the end ok so that is
 

00:07:18.020 --> 00:07:21.430 align:start position:0%
celebration at the end ok so that is
sort<00:07:18.500><c> of</c><00:07:18.590><c> the</c><00:07:18.650><c> administrivia</c><00:07:19.610><c> for</c><00:07:20.210><c> for</c><00:07:20.690><c> today</c>

00:07:21.430 --> 00:07:21.440 align:start position:0%
sort of the administrivia for for today
 

00:07:21.440 --> 00:07:25.629 align:start position:0%
sort of the administrivia for for today
and<00:07:21.940><c> ideally</c><00:07:22.940><c> the</c><00:07:23.330><c> rest</c><00:07:23.539><c> of</c><00:07:23.720><c> the</c><00:07:24.199><c> class</c><00:07:24.490><c> so</c><00:07:25.490><c> now</c>

00:07:25.629 --> 00:07:25.639 align:start position:0%
and ideally the rest of the class so now
 

00:07:25.639 --> 00:07:27.700 align:start position:0%
and ideally the rest of the class so now
let's<00:07:25.940><c> start</c><00:07:26.060><c> with</c><00:07:26.479><c> with</c><00:07:27.080><c> the</c><00:07:27.259><c> technical</c>

00:07:27.700 --> 00:07:27.710 align:start position:0%
let's start with with the technical
 

00:07:27.710 --> 00:07:30.700 align:start position:0%
let's start with with the technical
content<00:07:28.099><c> so</c><00:07:28.820><c> on</c><00:07:28.940><c> day</c><00:07:29.120><c> one</c><00:07:29.470><c> Alexandre</c><00:07:30.470><c> showed</c>

00:07:30.700 --> 00:07:30.710 align:start position:0%
content so on day one Alexandre showed
 

00:07:30.710 --> 00:07:33.700 align:start position:0%
content so on day one Alexandre showed
this<00:07:30.949><c> slide</c><00:07:31.250><c> which</c><00:07:31.759><c> sort</c><00:07:32.479><c> of</c><00:07:32.599><c> summarized</c><00:07:33.440><c> how</c>

00:07:33.700 --> 00:07:33.710 align:start position:0%
this slide which sort of summarized how
 

00:07:33.710 --> 00:07:35.800 align:start position:0%
this slide which sort of summarized how
deep<00:07:33.919><c> learning</c><00:07:34.130><c> has</c><00:07:34.550><c> revolutionised</c><00:07:35.330><c> so</c><00:07:35.630><c> many</c>

00:07:35.800 --> 00:07:35.810 align:start position:0%
deep learning has revolutionised so many
 

00:07:35.810 --> 00:07:38.200 align:start position:0%
deep learning has revolutionised so many
different<00:07:36.199><c> research</c><00:07:36.560><c> areas</c><00:07:37.009><c> from</c><00:07:37.580><c> autonomous</c>

00:07:38.200 --> 00:07:38.210 align:start position:0%
different research areas from autonomous
 

00:07:38.210 --> 00:07:40.409 align:start position:0%
different research areas from autonomous
vehicles<00:07:38.630><c> to</c><00:07:39.139><c> medicine</c><00:07:39.560><c> and</c><00:07:39.650><c> healthcare</c>

00:07:40.409 --> 00:07:40.419 align:start position:0%
vehicles to medicine and healthcare
 

00:07:40.419 --> 00:07:42.730 align:start position:0%
vehicles to medicine and healthcare
reinforcement<00:07:41.419><c> learning</c><00:07:41.740><c> generative</c>

00:07:42.730 --> 00:07:42.740 align:start position:0%
reinforcement learning generative
 

00:07:42.740 --> 00:07:45.730 align:start position:0%
reinforcement learning generative
modeling<00:07:43.330><c> robotics</c><00:07:44.330><c> and</c><00:07:44.780><c> the</c><00:07:45.139><c> list</c><00:07:45.349><c> goes</c><00:07:45.530><c> on</c>

00:07:45.730 --> 00:07:45.740 align:start position:0%
modeling robotics and the list goes on
 

00:07:45.740 --> 00:07:48.850 align:start position:0%
modeling robotics and the list goes on
and<00:07:46.220><c> on</c><00:07:46.280><c> and</c><00:07:46.550><c> hopefully</c><00:07:47.240><c> now</c><00:07:47.659><c> through</c><00:07:48.650><c> this</c>

00:07:48.850 --> 00:07:48.860 align:start position:0%
and on and hopefully now through this
 

00:07:48.860 --> 00:07:51.159 align:start position:0%
and on and hopefully now through this
series<00:07:49.340><c> of</c><00:07:49.490><c> 5</c><00:07:49.880><c> lectures</c><00:07:50.360><c> you</c><00:07:50.539><c> have</c><00:07:50.570><c> a</c><00:07:50.870><c> more</c>

00:07:51.159 --> 00:07:51.169 align:start position:0%
series of 5 lectures you have a more
 

00:07:51.169 --> 00:07:53.860 align:start position:0%
series of 5 lectures you have a more
concrete<00:07:51.680><c> understanding</c><00:07:51.710><c> of</c><00:07:52.550><c> how</c><00:07:53.330><c> and</c><00:07:53.659><c> why</c>

00:07:53.860 --> 00:07:53.870 align:start position:0%
concrete understanding of how and why
 

00:07:53.870 --> 00:07:56.040 align:start position:0%
concrete understanding of how and why
deep<00:07:54.289><c> learning</c><00:07:54.500><c> is</c><00:07:54.800><c> so</c><00:07:55.039><c> well</c><00:07:55.310><c> suited</c><00:07:55.759><c> for</c>

00:07:56.040 --> 00:07:56.050 align:start position:0%
deep learning is so well suited for
 

00:07:56.050 --> 00:07:58.990 align:start position:0%
deep learning is so well suited for
these<00:07:57.050><c> kinds</c><00:07:57.440><c> of</c><00:07:57.500><c> really</c><00:07:57.770><c> complex</c><00:07:58.219><c> tasks</c><00:07:58.880><c> and</c>

00:07:58.990 --> 00:07:59.000 align:start position:0%
these kinds of really complex tasks and
 

00:07:59.000 --> 00:08:02.050 align:start position:0%
these kinds of really complex tasks and
how<00:07:59.840><c> its</c><00:08:00.020><c> enabled</c><00:08:00.620><c> these</c><00:08:00.770><c> advances</c><00:08:01.400><c> across</c><00:08:01.820><c> a</c>

00:08:02.050 --> 00:08:02.060 align:start position:0%
how its enabled these advances across a
 

00:08:02.060 --> 00:08:07.270 align:start position:0%
how its enabled these advances across a
multitude<00:08:02.479><c> of</c><00:08:02.900><c> disciplines</c><00:08:03.759><c> and</c><00:08:05.949><c> also</c><00:08:06.949><c> you</c>

00:08:07.270 --> 00:08:07.280 align:start position:0%
multitude of disciplines and also you
 

00:08:07.280 --> 00:08:09.430 align:start position:0%
multitude of disciplines and also you
know<00:08:07.400><c> so</c><00:08:07.940><c> far</c><00:08:08.180><c> we've</c><00:08:08.360><c> primarily</c><00:08:08.659><c> dealt</c><00:08:09.169><c> with</c>

00:08:09.430 --> 00:08:09.440 align:start position:0%
know so far we've primarily dealt with
 

00:08:09.440 --> 00:08:12.189 align:start position:0%
know so far we've primarily dealt with
these<00:08:09.650><c> algorithms</c><00:08:10.250><c> that</c><00:08:10.729><c> take</c><00:08:11.000><c> as</c><00:08:11.180><c> input</c><00:08:11.360><c> some</c>

00:08:12.189 --> 00:08:12.199 align:start position:0%
these algorithms that take as input some
 

00:08:12.199 --> 00:08:14.230 align:start position:0%
these algorithms that take as input some
set<00:08:12.380><c> of</c><00:08:12.409><c> data</c><00:08:12.710><c> in</c><00:08:12.979><c> the</c><00:08:13.159><c> form</c><00:08:13.310><c> of</c><00:08:13.520><c> signals</c>

00:08:14.230 --> 00:08:14.240 align:start position:0%
set of data in the form of signals
 

00:08:14.240 --> 00:08:17.439 align:start position:0%
set of data in the form of signals
sequences<00:08:15.229><c> images</c><00:08:15.830><c> or</c><00:08:16.550><c> other</c><00:08:16.759><c> sensory</c><00:08:17.270><c> data</c>

00:08:17.439 --> 00:08:17.449 align:start position:0%
sequences images or other sensory data
 

00:08:17.449 --> 00:08:21.129 align:start position:0%
sequences images or other sensory data
to<00:08:18.169><c> directly</c><00:08:18.680><c> produce</c><00:08:18.949><c> a</c><00:08:19.490><c> decision</c><00:08:20.060><c> at</c><00:08:20.210><c> the</c><00:08:20.810><c> as</c>

00:08:21.129 --> 00:08:21.139 align:start position:0%
to directly produce a decision at the as
 

00:08:21.139 --> 00:08:24.010 align:start position:0%
to directly produce a decision at the as
an<00:08:21.830><c> output</c><00:08:22.190><c> whether</c><00:08:22.699><c> that's</c><00:08:23.000><c> a</c><00:08:23.270><c> prediction</c><00:08:23.870><c> or</c>

00:08:24.010 --> 00:08:24.020 align:start position:0%
an output whether that's a prediction or
 

00:08:24.020 --> 00:08:26.080 align:start position:0%
an output whether that's a prediction or
an<00:08:24.770><c> action</c><00:08:25.219><c> as</c><00:08:25.400><c> in</c><00:08:25.550><c> the</c><00:08:25.639><c> case</c><00:08:25.849><c> of</c>

00:08:26.080 --> 00:08:26.090 align:start position:0%
an action as in the case of
 

00:08:26.090 --> 00:08:28.510 align:start position:0%
an action as in the case of
reinforcement<00:08:26.870><c> learning</c><00:08:26.990><c> and</c><00:08:27.409><c> we've</c><00:08:28.250><c> also</c>

00:08:28.510 --> 00:08:28.520 align:start position:0%
reinforcement learning and we've also
 

00:08:28.520 --> 00:08:32.170 align:start position:0%
reinforcement learning and we've also
seen<00:08:28.940><c> ways</c><00:08:29.300><c> in</c><00:08:29.719><c> which</c><00:08:29.900><c> we</c><00:08:30.139><c> can</c><00:08:30.320><c> go</c><00:08:30.820><c> from</c><00:08:31.820><c> sort</c>

00:08:32.170 --> 00:08:32.180 align:start position:0%
seen ways in which we can go from sort
 

00:08:32.180 --> 00:08:34.420 align:start position:0%
seen ways in which we can go from sort
of<00:08:32.300><c> from</c><00:08:32.479><c> decision</c><00:08:32.990><c> to</c><00:08:33.229><c> data</c><00:08:33.469><c> in</c><00:08:33.770><c> the</c><00:08:34.010><c> context</c>

00:08:34.420 --> 00:08:34.430 align:start position:0%
of from decision to data in the context
 

00:08:34.430 --> 00:08:37.060 align:start position:0%
of from decision to data in the context
of<00:08:34.610><c> generative</c><00:08:35.000><c> modeling</c><00:08:35.539><c> and</c><00:08:35.719><c> to</c><00:08:36.500><c> sample</c>

00:08:37.060 --> 00:08:37.070 align:start position:0%
of generative modeling and to sample
 

00:08:37.070 --> 00:08:40.029 align:start position:0%
of generative modeling and to sample
brand<00:08:37.700><c> new</c><00:08:38.000><c> data</c><00:08:38.930><c> from</c><00:08:39.200><c> the</c><00:08:39.349><c> decision</c><00:08:39.800><c> space</c>

00:08:40.029 --> 00:08:40.039 align:start position:0%
brand new data from the decision space
 

00:08:40.039 --> 00:08:43.019 align:start position:0%
brand new data from the decision space
in<00:08:40.310><c> sort</c><00:08:40.940><c> of</c><00:08:41.029><c> this</c><00:08:41.180><c> probabilistic</c><00:08:41.659><c> setting</c>

00:08:43.019 --> 00:08:43.029 align:start position:0%
in sort of this probabilistic setting
 

00:08:43.029 --> 00:08:45.670 align:start position:0%
in sort of this probabilistic setting
more<00:08:44.029><c> generally</c><00:08:44.540><c> in</c><00:08:44.750><c> in</c><00:08:44.990><c> all</c><00:08:45.200><c> these</c><00:08:45.350><c> cases</c>

00:08:45.670 --> 00:08:45.680 align:start position:0%
more generally in in all these cases
 

00:08:45.680 --> 00:08:47.230 align:start position:0%
more generally in in all these cases
we've<00:08:46.070><c> really</c><00:08:46.370><c> been</c><00:08:46.550><c> dealing</c><00:08:47.060><c> with</c>

00:08:47.230 --> 00:08:47.240 align:start position:0%
we've really been dealing with
 

00:08:47.240 --> 00:08:50.319 align:start position:0%
we've really been dealing with
algorithms<00:08:47.720><c> that</c><00:08:48.170><c> are</c><00:08:48.440><c> designed</c><00:08:49.130><c> to</c><00:08:49.279><c> do</c><00:08:49.699><c> that</c>

00:08:50.319 --> 00:08:50.329 align:start position:0%
algorithms that are designed to do that
 

00:08:50.329 --> 00:08:52.480 align:start position:0%
algorithms that are designed to do that
are<00:08:50.510><c> optimized</c><00:08:51.050><c> to</c><00:08:51.170><c> do</c><00:08:51.350><c> well</c><00:08:51.589><c> on</c>

00:08:52.480 --> 00:08:52.490 align:start position:0%
are optimized to do well on
 

00:08:52.490 --> 00:08:55.960 align:start position:0%
are optimized to do well on
Ingle<00:08:52.670><c> tasks</c><00:08:52.910><c> right</c><00:08:53.720><c> but</c><00:08:54.260><c> fail</c><00:08:54.980><c> to</c><00:08:55.010><c> think</c><00:08:55.760><c> like</c>

00:08:55.960 --> 00:08:55.970 align:start position:0%
Ingle tasks right but fail to think like
 

00:08:55.970 --> 00:08:58.780 align:start position:0%
Ingle tasks right but fail to think like
humans<00:08:56.180><c> or</c><00:08:56.540><c> operate</c><00:08:56.959><c> like</c><00:08:57.140><c> humans</c><00:08:57.580><c> sort</c><00:08:58.580><c> of</c><00:08:58.670><c> at</c>

00:08:58.780 --> 00:08:58.790 align:start position:0%
humans or operate like humans sort of at
 

00:08:58.790 --> 00:09:00.699 align:start position:0%
humans or operate like humans sort of at
a<00:08:58.820><c> at</c><00:08:59.120><c> a</c><00:08:59.180><c> higher</c><00:08:59.510><c> love</c><00:08:59.810><c> order</c><00:09:00.290><c> level</c><00:09:00.620><c> of</c>

00:09:00.699 --> 00:09:00.709 align:start position:0%
a at a higher love order level of
 

00:09:00.709 --> 00:09:04.000 align:start position:0%
a at a higher love order level of
intelligence<00:09:01.310><c> and</c><00:09:02.170><c> to</c><00:09:03.170><c> understand</c><00:09:03.709><c> this</c><00:09:03.830><c> in</c>

00:09:04.000 --> 00:09:04.010 align:start position:0%
intelligence and to understand this in
 

00:09:04.010 --> 00:09:06.490 align:start position:0%
intelligence and to understand this in
more<00:09:04.190><c> detail</c><00:09:04.570><c> we</c><00:09:05.570><c> have</c><00:09:05.600><c> to</c><00:09:05.810><c> go</c><00:09:05.930><c> back</c><00:09:06.170><c> to</c><00:09:06.470><c> a</c>

00:09:06.490 --> 00:09:06.500 align:start position:0%
more detail we have to go back to a
 

00:09:06.500 --> 00:09:08.710 align:start position:0%
more detail we have to go back to a
famous<00:09:06.890><c> theorem</c><00:09:07.580><c> in</c><00:09:07.760><c> sort</c><00:09:08.060><c> of</c><00:09:08.120><c> the</c><00:09:08.270><c> theory</c><00:09:08.690><c> of</c>

00:09:08.710 --> 00:09:08.720 align:start position:0%
famous theorem in sort of the theory of
 

00:09:08.720 --> 00:09:11.230 align:start position:0%
famous theorem in sort of the theory of
neural<00:09:09.709><c> networks</c><00:09:10.070><c> which</c><00:09:10.310><c> was</c><00:09:10.490><c> presented</c><00:09:11.180><c> in</c>

00:09:11.230 --> 00:09:11.240 align:start position:0%
neural networks which was presented in
 

00:09:11.240 --> 00:09:14.590 align:start position:0%
neural networks which was presented in
1989<00:09:12.080><c> and</c><00:09:12.459><c> generated</c><00:09:13.459><c> quite</c><00:09:13.760><c> the</c><00:09:14.180><c> stir</c><00:09:14.420><c> and</c>

00:09:14.590 --> 00:09:14.600 align:start position:0%
1989 and generated quite the stir and
 

00:09:14.600 --> 00:09:16.170 align:start position:0%
1989 and generated quite the stir and
this<00:09:14.779><c> is</c><00:09:14.930><c> called</c><00:09:15.230><c> the</c><00:09:15.440><c> universal</c>

00:09:16.170 --> 00:09:16.180 align:start position:0%
this is called the universal
 

00:09:16.180 --> 00:09:18.610 align:start position:0%
this is called the universal
approximation<00:09:17.180><c> theorem</c><00:09:17.570><c> and</c><00:09:17.779><c> basically</c><00:09:18.350><c> what</c>

00:09:18.610 --> 00:09:18.620 align:start position:0%
approximation theorem and basically what
 

00:09:18.620 --> 00:09:20.920 align:start position:0%
approximation theorem and basically what
it<00:09:18.740><c> states</c><00:09:19.010><c> is</c><00:09:19.220><c> that</c><00:09:19.250><c> a</c><00:09:19.670><c> neural</c><00:09:20.270><c> network</c><00:09:20.510><c> with</c>

00:09:20.920 --> 00:09:20.930 align:start position:0%
it states is that a neural network with
 

00:09:20.930 --> 00:09:24.310 align:start position:0%
it states is that a neural network with
a<00:09:21.170><c> single</c><00:09:22.040><c> hidden</c><00:09:22.310><c> layer</c><00:09:22.490><c> is</c><00:09:23.140><c> sufficient</c><00:09:24.140><c> to</c>

00:09:24.310 --> 00:09:24.320 align:start position:0%
a single hidden layer is sufficient to
 

00:09:24.320 --> 00:09:29.260 align:start position:0%
a single hidden layer is sufficient to
approximate<00:09:25.190><c> any</c><00:09:25.810><c> arbitrary</c><00:09:26.810><c> function</c><00:09:28.270><c> any</c>

00:09:29.260 --> 00:09:29.270 align:start position:0%
approximate any arbitrary function any
 

00:09:29.270 --> 00:09:31.600 align:start position:0%
approximate any arbitrary function any
continuous<00:09:29.839><c> function</c><00:09:30.230><c> and</c><00:09:30.410><c> in</c><00:09:31.160><c> this</c><00:09:31.339><c> class</c>

00:09:31.600 --> 00:09:31.610 align:start position:0%
continuous function and in this class
 

00:09:31.610 --> 00:09:33.519 align:start position:0%
continuous function and in this class
you<00:09:32.029><c> know</c><00:09:32.149><c> we've</c><00:09:32.360><c> we've</c><00:09:32.690><c> mostly</c><00:09:33.140><c> been</c><00:09:33.500><c> talking</c>

00:09:33.519 --> 00:09:33.529 align:start position:0%
you know we've we've mostly been talking
 

00:09:33.529 --> 00:09:35.680 align:start position:0%
you know we've we've mostly been talking
about<00:09:33.950><c> deep</c><00:09:34.310><c> models</c><00:09:34.700><c> that</c><00:09:34.910><c> use</c><00:09:35.089><c> multiple</c>

00:09:35.680 --> 00:09:35.690 align:start position:0%
about deep models that use multiple
 

00:09:35.690 --> 00:09:37.600 align:start position:0%
about deep models that use multiple
layers<00:09:35.899><c> but</c><00:09:36.560><c> this</c><00:09:36.740><c> theorem</c><00:09:37.190><c> you</c><00:09:37.490><c> know</c>

00:09:37.600 --> 00:09:37.610 align:start position:0%
layers but this theorem you know
 

00:09:37.610 --> 00:09:39.760 align:start position:0%
layers but this theorem you know
completely<00:09:38.209><c> ignores</c><00:09:38.810><c> this</c><00:09:39.020><c> and</c><00:09:39.200><c> says</c><00:09:39.350><c> you</c>

00:09:39.760 --> 00:09:39.770 align:start position:0%
completely ignores this and says you
 

00:09:39.770 --> 00:09:43.449 align:start position:0%
completely ignores this and says you
just<00:09:39.920><c> need</c><00:09:40.399><c> one</c><00:09:40.430><c> one</c><00:09:41.209><c> neural</c><00:09:41.510><c> layer</c><00:09:41.720><c> and</c><00:09:42.459><c> if</c>

00:09:43.449 --> 00:09:43.459 align:start position:0%
just need one one neural layer and if
 

00:09:43.459 --> 00:09:45.310 align:start position:0%
just need one one neural layer and if
you<00:09:43.640><c> believe</c><00:09:43.970><c> that</c><00:09:44.000><c> any</c><00:09:44.360><c> problem</c><00:09:44.779><c> can</c><00:09:45.140><c> be</c>

00:09:45.310 --> 00:09:45.320 align:start position:0%
you believe that any problem can be
 

00:09:45.320 --> 00:09:47.650 align:start position:0%
you believe that any problem can be
reduced<00:09:45.470><c> sort</c><00:09:46.339><c> of</c><00:09:46.430><c> to</c><00:09:46.550><c> a</c><00:09:46.580><c> set</c><00:09:46.820><c> of</c><00:09:46.940><c> inputs</c><00:09:47.390><c> and</c>

00:09:47.650 --> 00:09:47.660 align:start position:0%
reduced sort of to a set of inputs and
 

00:09:47.660 --> 00:09:50.889 align:start position:0%
reduced sort of to a set of inputs and
an<00:09:47.839><c> output</c><00:09:48.260><c> this</c><00:09:48.950><c> means</c><00:09:49.220><c> that</c><00:09:49.459><c> there</c><00:09:50.209><c> exists</c><00:09:50.779><c> a</c>

00:09:50.889 --> 00:09:50.899 align:start position:0%
an output this means that there exists a
 

00:09:50.899 --> 00:09:53.320 align:start position:0%
an output this means that there exists a
neural<00:09:51.230><c> network</c><00:09:51.440><c> to</c><00:09:52.310><c> solve</c><00:09:52.550><c> any</c><00:09:52.760><c> problem</c><00:09:53.180><c> in</c>

00:09:53.320 --> 00:09:53.330 align:start position:0%
neural network to solve any problem in
 

00:09:53.330 --> 00:09:54.790 align:start position:0%
neural network to solve any problem in
the<00:09:53.450><c> world</c><00:09:53.480><c> right</c><00:09:53.930><c> so</c><00:09:54.110><c> long</c><00:09:54.320><c> as</c><00:09:54.380><c> you</c><00:09:54.649><c> can</c>

00:09:54.790 --> 00:09:54.800 align:start position:0%
the world right so long as you can
 

00:09:54.800 --> 00:09:57.579 align:start position:0%
the world right so long as you can
define<00:09:55.160><c> it</c><00:09:55.370><c> using</c><00:09:56.270><c> some</c><00:09:56.540><c> continuous</c><00:09:57.170><c> function</c>

00:09:57.579 --> 00:09:57.589 align:start position:0%
define it using some continuous function
 

00:09:57.589 --> 00:10:00.639 align:start position:0%
define it using some continuous function
and<00:09:58.779><c> this</c><00:09:59.779><c> may</c><00:09:59.930><c> seem</c><00:09:59.990><c> like</c><00:10:00.170><c> an</c><00:10:00.410><c> incredibly</c>

00:10:00.639 --> 00:10:00.649 align:start position:0%
and this may seem like an incredibly
 

00:10:00.649 --> 00:10:03.940 align:start position:0%
and this may seem like an incredibly
powerful<00:10:01.550><c> result</c><00:10:02.329><c> but</c><00:10:02.899><c> if</c><00:10:03.020><c> you</c><00:10:03.140><c> look</c><00:10:03.350><c> closely</c>

00:10:03.940 --> 00:10:03.950 align:start position:0%
powerful result but if you look closely
 

00:10:03.950 --> 00:10:08.199 align:start position:0%
powerful result but if you look closely
right<00:10:04.220><c> there</c><00:10:04.700><c> are</c><00:10:04.760><c> two</c><00:10:05.589><c> really</c><00:10:06.589><c> big</c><00:10:07.209><c> caveats</c>

00:10:08.199 --> 00:10:08.209 align:start position:0%
right there are two really big caveats
 

00:10:08.209 --> 00:10:12.160 align:start position:0%
right there are two really big caveats
to<00:10:08.390><c> this</c><00:10:09.220><c> first</c><00:10:10.220><c> this</c><00:10:10.520><c> this</c><00:10:10.910><c> theorem</c><00:10:11.209><c> makes</c><00:10:11.540><c> no</c>

00:10:12.160 --> 00:10:12.170 align:start position:0%
to this first this this theorem makes no
 

00:10:12.170 --> 00:10:14.680 align:start position:0%
to this first this this theorem makes no
guarantee<00:10:12.770><c> on</c><00:10:13.040><c> the</c><00:10:13.910><c> number</c><00:10:14.240><c> of</c><00:10:14.270><c> hidden</c><00:10:14.540><c> units</c>

00:10:14.680 --> 00:10:14.690 align:start position:0%
guarantee on the number of hidden units
 

00:10:14.690 --> 00:10:16.900 align:start position:0%
guarantee on the number of hidden units
or<00:10:15.200><c> the</c><00:10:15.440><c> size</c><00:10:15.680><c> of</c><00:10:16.010><c> the</c><00:10:16.070><c> hidden</c><00:10:16.459><c> layer</c><00:10:16.610><c> that's</c>

00:10:16.900 --> 00:10:16.910 align:start position:0%
or the size of the hidden layer that's
 

00:10:16.910 --> 00:10:19.180 align:start position:0%
or the size of the hidden layer that's
going<00:10:17.120><c> to</c><00:10:17.240><c> be</c><00:10:17.329><c> required</c><00:10:17.750><c> to</c><00:10:18.079><c> solve</c><00:10:18.589><c> you</c><00:10:19.070><c> know</c>

00:10:19.180 --> 00:10:19.190 align:start position:0%
going to be required to solve you know
 

00:10:19.190 --> 00:10:21.850 align:start position:0%
going to be required to solve you know
your<00:10:19.430><c> arbitrary</c><00:10:20.000><c> problem</c><00:10:20.480><c> and</c><00:10:20.860><c> additionally</c>

00:10:21.850 --> 00:10:21.860 align:start position:0%
your arbitrary problem and additionally
 

00:10:21.860 --> 00:10:23.949 align:start position:0%
your arbitrary problem and additionally
it<00:10:21.920><c> leaves</c><00:10:22.190><c> open</c><00:10:22.399><c> this</c><00:10:22.640><c> question</c><00:10:23.089><c> of</c><00:10:23.240><c> how</c><00:10:23.899><c> do</c>

00:10:23.949 --> 00:10:23.959 align:start position:0%
it leaves open this question of how do
 

00:10:23.959 --> 00:10:25.840 align:start position:0%
it leaves open this question of how do
we<00:10:24.140><c> actually</c><00:10:24.320><c> go</c><00:10:24.680><c> about</c><00:10:24.709><c> finding</c><00:10:25.490><c> the</c><00:10:25.640><c> weights</c>

00:10:25.840 --> 00:10:25.850 align:start position:0%
we actually go about finding the weights
 

00:10:25.850 --> 00:10:29.650 align:start position:0%
we actually go about finding the weights
to<00:10:26.690><c> support</c><00:10:27.170><c> whatever</c><00:10:27.829><c> architecture</c><00:10:28.760><c> that</c>

00:10:29.650 --> 00:10:29.660 align:start position:0%
to support whatever architecture that
 

00:10:29.660 --> 00:10:31.810 align:start position:0%
to support whatever architecture that
could<00:10:29.870><c> be</c><00:10:29.990><c> used</c><00:10:30.230><c> to</c><00:10:30.380><c> solve</c><00:10:30.950><c> this</c><00:10:31.100><c> problem</c><00:10:31.310><c> it</c>

00:10:31.810 --> 00:10:31.820 align:start position:0%
could be used to solve this problem it
 

00:10:31.820 --> 00:10:34.690 align:start position:0%
could be used to solve this problem it
just<00:10:32.480><c> claims</c><00:10:32.810><c> that</c><00:10:33.079><c> and</c><00:10:33.920><c> actually</c><00:10:34.220><c> proves</c>

00:10:34.690 --> 00:10:34.700 align:start position:0%
just claims that and actually proves
 

00:10:34.700 --> 00:10:37.810 align:start position:0%
just claims that and actually proves
that<00:10:34.970><c> such</c><00:10:35.420><c> an</c><00:10:35.540><c> architecture</c><00:10:36.140><c> exists</c><00:10:36.709><c> but</c><00:10:37.610><c> as</c>

00:10:37.810 --> 00:10:37.820 align:start position:0%
that such an architecture exists but as
 

00:10:37.820 --> 00:10:40.300 align:start position:0%
that such an architecture exists but as
we<00:10:38.180><c> know</c><00:10:38.360><c> from</c><00:10:38.589><c> gradient</c><00:10:39.589><c> descent</c><00:10:39.950><c> and</c><00:10:40.160><c> this</c>

00:10:40.300 --> 00:10:40.310 align:start position:0%
we know from gradient descent and this
 

00:10:40.310 --> 00:10:43.060 align:start position:0%
we know from gradient descent and this
idea<00:10:40.579><c> of</c><00:10:41.089><c> finding</c><00:10:41.779><c> ways</c><00:10:42.140><c> and</c><00:10:42.410><c> sort</c><00:10:42.620><c> of</c><00:10:42.680><c> like</c><00:10:42.860><c> a</c>

00:10:43.060 --> 00:10:43.070 align:start position:0%
idea of finding ways and sort of like a
 

00:10:43.070 --> 00:10:47.380 align:start position:0%
idea of finding ways and sort of like a
non<00:10:43.430><c> convex</c><00:10:44.829><c> landscape</c><00:10:46.180><c> there's</c><00:10:47.180><c> no</c>

00:10:47.380 --> 00:10:47.390 align:start position:0%
non convex landscape there's no
 

00:10:47.390 --> 00:10:51.310 align:start position:0%
non convex landscape there's no
guarantee<00:10:48.050><c> that</c><00:10:49.060><c> this</c><00:10:50.060><c> this</c><00:10:50.660><c> process</c><00:10:51.170><c> of</c>

00:10:51.310 --> 00:10:51.320 align:start position:0%
guarantee that this this process of
 

00:10:51.320 --> 00:10:53.199 align:start position:0%
guarantee that this this process of
learning<00:10:51.680><c> these</c><00:10:51.770><c> weights</c><00:10:52.100><c> would</c><00:10:52.370><c> be</c><00:10:52.550><c> anyway</c>

00:10:53.199 --> 00:10:53.209 align:start position:0%
learning these weights would be anyway
 

00:10:53.209 --> 00:10:56.829 align:start position:0%
learning these weights would be anyway
straightforward<00:10:53.899><c> right</c><00:10:54.140><c> and</c><00:10:54.880><c> finally</c><00:10:55.880><c> this</c>

00:10:56.829 --> 00:10:56.839 align:start position:0%
straightforward right and finally this
 

00:10:56.839 --> 00:11:00.010 align:start position:0%
straightforward right and finally this
theorem<00:10:57.170><c> doesn't</c><00:10:57.380><c> provide</c><00:10:58.720><c> any</c><00:10:59.720><c> guarantees</c>

00:11:00.010 --> 00:11:00.020 align:start position:0%
theorem doesn't provide any guarantees
 

00:11:00.020 --> 00:11:02.620 align:start position:0%
theorem doesn't provide any guarantees
that<00:11:00.350><c> whatever</c><00:11:01.250><c> model</c><00:11:01.760><c> is</c><00:11:01.940><c> that's</c><00:11:02.300><c> learned</c>

00:11:02.620 --> 00:11:02.630 align:start position:0%
that whatever model is that's learned
 

00:11:02.630 --> 00:11:05.829 align:start position:0%
that whatever model is that's learned
would<00:11:03.170><c> generalize</c><00:11:03.680><c> well</c><00:11:04.010><c> to</c><00:11:04.670><c> other</c><00:11:04.820><c> tasks</c>

00:11:05.829 --> 00:11:05.839 align:start position:0%
would generalize well to other tasks
 

00:11:05.839 --> 00:11:09.970 align:start position:0%
would generalize well to other tasks
and<00:11:06.999><c> this</c><00:11:07.999><c> theorem</c><00:11:08.269><c> is</c><00:11:08.449><c> is</c><00:11:08.720><c> a</c><00:11:08.990><c> perfect</c><00:11:09.620><c> example</c>

00:11:09.970 --> 00:11:09.980 align:start position:0%
and this theorem is is a perfect example
 

00:11:09.980 --> 00:11:13.329 align:start position:0%
and this theorem is is a perfect example
of<00:11:10.610><c> sort</c><00:11:11.089><c> of</c><00:11:11.180><c> the</c><00:11:11.300><c> possible</c><00:11:12.100><c> effects</c><00:11:13.100><c> of</c>

00:11:13.329 --> 00:11:13.339 align:start position:0%
of sort of the possible effects of
 

00:11:13.339 --> 00:11:17.019 align:start position:0%
of sort of the possible effects of
overhype<00:11:14.120><c> in</c><00:11:14.389><c> AI</c><00:11:14.899><c> and</c><00:11:15.350><c> as</c><00:11:16.249><c> a</c><00:11:16.310><c> community</c><00:11:16.639><c> I</c>

00:11:17.019 --> 00:11:17.029 align:start position:0%
overhype in AI and as a community I
 

00:11:17.029 --> 00:11:19.389 align:start position:0%
overhype in AI and as a community I
think<00:11:17.389><c> we're</c><00:11:17.540><c> all</c><00:11:17.689><c> interested</c><00:11:18.139><c> in</c><00:11:18.769><c> sort</c><00:11:19.339><c> of</c>

00:11:19.389 --> 00:11:19.399 align:start position:0%
think we're all interested in sort of
 

00:11:19.399 --> 00:11:20.800 align:start position:0%
think we're all interested in sort of
the<00:11:19.490><c> state</c><00:11:19.730><c> of</c><00:11:19.790><c> deep</c><00:11:20.060><c> learning</c><00:11:20.269><c> and</c><00:11:20.629><c> how</c><00:11:20.749><c> we</c>

00:11:20.800 --> 00:11:20.810 align:start position:0%
the state of deep learning and how we
 

00:11:20.810 --> 00:11:23.170 align:start position:0%
the state of deep learning and how we
can<00:11:21.050><c> use</c><00:11:21.259><c> in</c><00:11:21.439><c> that's</c><00:11:22.009><c> probably</c><00:11:22.160><c> a</c><00:11:22.939><c> big</c>

00:11:23.170 --> 00:11:23.180 align:start position:0%
can use in that's probably a big
 

00:11:23.180 --> 00:11:25.090 align:start position:0%
can use in that's probably a big
motivation<00:11:23.779><c> of</c><00:11:23.899><c> why</c><00:11:24.079><c> you're</c><00:11:24.589><c> sitting</c><00:11:24.800><c> in</c><00:11:24.980><c> this</c>

00:11:25.090 --> 00:11:25.100 align:start position:0%
motivation of why you're sitting in this
 

00:11:25.100 --> 00:11:28.030 align:start position:0%
motivation of why you're sitting in this
lecture<00:11:25.490><c> today</c><00:11:25.850><c> but</c><00:11:26.839><c> I</c><00:11:26.870><c> think</c><00:11:26.990><c> we</c><00:11:27.199><c> we</c><00:11:27.709><c> really</c>

00:11:28.030 --> 00:11:28.040 align:start position:0%
lecture today but I think we we really
 

00:11:28.040 --> 00:11:29.980 align:start position:0%
lecture today but I think we we really
need<00:11:28.189><c> to</c><00:11:28.309><c> be</c><00:11:28.399><c> extremely</c><00:11:28.819><c> careful</c><00:11:29.120><c> in</c><00:11:29.480><c> terms</c><00:11:29.689><c> of</c>

00:11:29.980 --> 00:11:29.990 align:start position:0%
need to be extremely careful in terms of
 

00:11:29.990 --> 00:11:31.840 align:start position:0%
need to be extremely careful in terms of
how<00:11:30.170><c> we</c><00:11:30.230><c> market</c><00:11:30.980><c> and</c><00:11:31.129><c> advertise</c><00:11:31.279><c> these</c>

00:11:31.840 --> 00:11:31.850 align:start position:0%
how we market and advertise these
 

00:11:31.850 --> 00:11:35.590 align:start position:0%
how we market and advertise these
algorithms<00:11:33.040><c> so</c><00:11:34.040><c> while</c><00:11:34.699><c> the</c><00:11:34.939><c> universal</c>

00:11:35.590 --> 00:11:35.600 align:start position:0%
algorithms so while the universal
 

00:11:35.600 --> 00:11:37.840 align:start position:0%
algorithms so while the universal
approximation<00:11:36.319><c> theorem</c><00:11:36.920><c> generated</c><00:11:37.519><c> a</c><00:11:37.610><c> lot</c><00:11:37.819><c> of</c>

00:11:37.840 --> 00:11:37.850 align:start position:0%
approximation theorem generated a lot of
 

00:11:37.850 --> 00:11:39.639 align:start position:0%
approximation theorem generated a lot of
excitement<00:11:38.059><c> when</c><00:11:38.569><c> it</c><00:11:38.720><c> first</c><00:11:38.899><c> came</c><00:11:39.110><c> out</c><00:11:39.170><c> it</c>

00:11:39.639 --> 00:11:39.649 align:start position:0%
excitement when it first came out it
 

00:11:39.649 --> 00:11:42.970 align:start position:0%
excitement when it first came out it
also<00:11:40.459><c> provided</c><00:11:40.999><c> some</c><00:11:41.360><c> false</c><00:11:41.959><c> hope</c><00:11:42.259><c> to</c><00:11:42.290><c> the</c><00:11:42.829><c> AI</c>

00:11:42.970 --> 00:11:42.980 align:start position:0%
also provided some false hope to the AI
 

00:11:42.980 --> 00:11:45.819 align:start position:0%
also provided some false hope to the AI
community<00:11:43.639><c> that</c><00:11:44.300><c> neural</c><00:11:44.569><c> networks</c><00:11:44.959><c> as</c><00:11:45.259><c> they</c>

00:11:45.819 --> 00:11:45.829 align:start position:0%
community that neural networks as they
 

00:11:45.829 --> 00:11:49.749 align:start position:0%
community that neural networks as they
existed<00:11:46.399><c> dirt</c><00:11:47.199><c> could</c><00:11:48.199><c> solve</c><00:11:48.499><c> any</c><00:11:48.829><c> problem</c><00:11:49.639><c> in</c>

00:11:49.749 --> 00:11:49.759 align:start position:0%
existed dirt could solve any problem in
 

00:11:49.759 --> 00:11:52.389 align:start position:0%
existed dirt could solve any problem in
the<00:11:49.850><c> world</c><00:11:49.999><c> right</c><00:11:50.389><c> and</c><00:11:50.649><c> this</c><00:11:51.649><c> overhype</c><00:11:52.160><c> is</c>

00:11:52.389 --> 00:11:52.399 align:start position:0%
the world right and this overhype is
 

00:11:52.399 --> 00:11:54.519 align:start position:0%
the world right and this overhype is
extremely<00:11:53.149><c> dangerous</c><00:11:53.300><c> and</c><00:11:53.749><c> historically</c>

00:11:54.519 --> 00:11:54.529 align:start position:0%
extremely dangerous and historically
 

00:11:54.529 --> 00:11:55.840 align:start position:0%
extremely dangerous and historically
there<00:11:54.829><c> have</c><00:11:54.920><c> actually</c><00:11:55.100><c> been</c><00:11:55.370><c> to</c>

00:11:55.840 --> 00:11:55.850 align:start position:0%
there have actually been to
 

00:11:55.850 --> 00:11:59.049 align:start position:0%
there have actually been to
quote-unquote<00:11:56.629><c> AI</c><00:11:57.079><c> winters</c><00:11:57.740><c> where</c><00:11:58.160><c> research</c>

00:11:59.049 --> 00:11:59.059 align:start position:0%
quote-unquote AI winters where research
 

00:11:59.059 --> 00:12:01.569 align:start position:0%
quote-unquote AI winters where research
in<00:11:59.240><c> AI</c><00:11:59.420><c> and</c><00:11:59.839><c> neural</c><00:12:00.439><c> networks</c><00:12:00.800><c> specifically</c>

00:12:01.569 --> 00:12:01.579 align:start position:0%
in AI and neural networks specifically
 

00:12:01.579 --> 00:12:04.929 align:start position:0%
in AI and neural networks specifically
in<00:12:01.730><c> in</c><00:12:01.970><c> the</c><00:12:02.149><c> second</c><00:12:02.540><c> AI</c><00:12:02.720><c> winter</c><00:12:03.319><c> came</c><00:12:04.040><c> to</c><00:12:04.309><c> sort</c>

00:12:04.929 --> 00:12:04.939 align:start position:0%
in in the second AI winter came to sort
 

00:12:04.939 --> 00:12:08.920 align:start position:0%
in in the second AI winter came to sort
of<00:12:05.029><c> a</c><00:12:05.209><c> grinding</c><00:12:05.899><c> halt</c><00:12:06.139><c> and</c><00:12:07.449><c> so</c><00:12:08.449><c> this</c><00:12:08.600><c> is</c><00:12:08.749><c> why</c>

00:12:08.920 --> 00:12:08.930 align:start position:0%
of a grinding halt and so this is why
 

00:12:08.930 --> 00:12:11.170 align:start position:0%
of a grinding halt and so this is why
you<00:12:09.529><c> know</c><00:12:09.620><c> for</c><00:12:09.860><c> the</c><00:12:09.949><c> first</c><00:12:10.220><c> portion</c><00:12:10.730><c> of</c><00:12:11.000><c> this</c>

00:12:11.170 --> 00:12:11.180 align:start position:0%
you know for the first portion of this
 

00:12:11.180 --> 00:12:14.019 align:start position:0%
you know for the first portion of this
lecture<00:12:11.809><c> I'd</c><00:12:11.899><c> like</c><00:12:12.110><c> to</c><00:12:12.259><c> focus</c><00:12:12.470><c> on</c><00:12:12.829><c> some</c><00:12:13.790><c> of</c><00:12:13.819><c> the</c>

00:12:14.019 --> 00:12:14.029 align:start position:0%
lecture I'd like to focus on some of the
 

00:12:14.029 --> 00:12:16.660 align:start position:0%
lecture I'd like to focus on some of the
limitations<00:12:14.509><c> of</c><00:12:15.019><c> these</c><00:12:15.620><c> algorithms</c><00:12:16.009><c> that</c>

00:12:16.660 --> 00:12:16.670 align:start position:0%
limitations of these algorithms that
 

00:12:16.670 --> 00:12:19.240 align:start position:0%
limitations of these algorithms that
we've<00:12:16.850><c> learned</c><00:12:17.089><c> about</c><00:12:17.240><c> so</c><00:12:17.600><c> far</c><00:12:17.870><c> but</c><00:12:18.740><c> also</c><00:12:18.949><c> to</c>

00:12:19.240 --> 00:12:19.250 align:start position:0%
we've learned about so far but also to
 

00:12:19.250 --> 00:12:23.049 align:start position:0%
we've learned about so far but also to
take<00:12:19.579><c> it</c><00:12:19.730><c> a</c><00:12:19.790><c> step</c><00:12:19.970><c> further</c><00:12:20.029><c> to</c><00:12:20.720><c> touch</c><00:12:21.079><c> on</c><00:12:22.059><c> some</c>

00:12:23.049 --> 00:12:23.059 align:start position:0%
take it a step further to touch on some
 

00:12:23.059 --> 00:12:24.910 align:start position:0%
take it a step further to touch on some
really<00:12:23.360><c> exciting</c><00:12:23.600><c> new</c><00:12:23.990><c> research</c><00:12:24.350><c> that's</c>

00:12:24.910 --> 00:12:24.920 align:start position:0%
really exciting new research that's
 

00:12:24.920 --> 00:12:27.490 align:start position:0%
really exciting new research that's
looking<00:12:25.370><c> to</c><00:12:25.639><c> address</c><00:12:26.000><c> these</c><00:12:26.839><c> problems</c><00:12:26.899><c> and</c>

00:12:27.490 --> 00:12:27.500 align:start position:0%
looking to address these problems and
 

00:12:27.500 --> 00:12:28.179 align:start position:0%
looking to address these problems and
limitations

00:12:28.179 --> 00:12:28.189 align:start position:0%
limitations
 

00:12:28.189 --> 00:12:30.929 align:start position:0%
limitations
so<00:12:28.970><c> first</c><00:12:29.269><c> let's</c><00:12:30.079><c> let's</c><00:12:30.529><c> talk</c><00:12:30.680><c> about</c>

00:12:30.929 --> 00:12:30.939 align:start position:0%
so first let's let's talk about
 

00:12:30.939 --> 00:12:33.790 align:start position:0%
so first let's let's talk about
limitations<00:12:31.939><c> of</c><00:12:32.089><c> deep</c><00:12:32.240><c> learning</c><00:12:32.389><c> and</c><00:12:32.839><c> one</c><00:12:33.709><c> of</c>

00:12:33.790 --> 00:12:33.800 align:start position:0%
limitations of deep learning and one of
 

00:12:33.800 --> 00:12:35.920 align:start position:0%
limitations of deep learning and one of
my<00:12:33.920><c> favorite</c><00:12:34.309><c> examples</c><00:12:34.790><c> of</c><00:12:34.939><c> a</c><00:12:35.389><c> potential</c>

00:12:35.920 --> 00:12:35.930 align:start position:0%
my favorite examples of a potential
 

00:12:35.930 --> 00:12:37.929 align:start position:0%
my favorite examples of a potential
danger<00:12:36.470><c> of</c><00:12:36.829><c> deep</c><00:12:37.009><c> neural</c><00:12:37.160><c> networks</c><00:12:37.579><c> comes</c>

00:12:37.929 --> 00:12:37.939 align:start position:0%
danger of deep neural networks comes
 

00:12:37.939 --> 00:12:41.460 align:start position:0%
danger of deep neural networks comes
from<00:12:38.209><c> this</c><00:12:38.389><c> paper</c><00:12:38.959><c> from</c><00:12:39.230><c> Google</c><00:12:39.910><c> Google</c><00:12:40.910><c> brain</c>

00:12:41.460 --> 00:12:41.470 align:start position:0%
from this paper from Google Google brain
 

00:12:41.470 --> 00:12:44.110 align:start position:0%
from this paper from Google Google brain
that<00:12:42.470><c> was</c><00:12:42.649><c> entitled</c><00:12:42.949><c> understanding</c><00:12:43.519><c> deep</c>

00:12:44.110 --> 00:12:44.120 align:start position:0%
that was entitled understanding deep
 

00:12:44.120 --> 00:12:46.259 align:start position:0%
that was entitled understanding deep
neural<00:12:44.300><c> networks</c><00:12:44.779><c> requires</c><00:12:45.529><c> rethinking</c>

00:12:46.259 --> 00:12:46.269 align:start position:0%
neural networks requires rethinking
 

00:12:46.269 --> 00:12:49.299 align:start position:0%
neural networks requires rethinking
generalization<00:12:47.269><c> and</c><00:12:47.540><c> this</c><00:12:48.470><c> paper</c><00:12:48.649><c> really</c><00:12:49.009><c> did</c>

00:12:49.299 --> 00:12:49.309 align:start position:0%
generalization and this paper really did
 

00:12:49.309 --> 00:12:51.129 align:start position:0%
generalization and this paper really did
something<00:12:49.579><c> really</c><00:12:50.389><c> simple</c><00:12:50.750><c> but</c><00:12:51.079><c> very</c>

00:12:51.129 --> 00:12:51.139 align:start position:0%
something really simple but very
 

00:12:51.139 --> 00:12:51.910 align:start position:0%
something really simple but very
powerful

00:12:51.910 --> 00:12:51.920 align:start position:0%
powerful
 

00:12:51.920 --> 00:12:54.490 align:start position:0%
powerful
they<00:12:52.670><c> took</c><00:12:52.879><c> images</c><00:12:53.480><c> from</c><00:12:53.720><c> the</c><00:12:54.019><c> imagenet</c>

00:12:54.490 --> 00:12:54.500 align:start position:0%
they took images from the imagenet
 

00:12:54.500 --> 00:12:57.160 align:start position:0%
they took images from the imagenet
dataset<00:12:55.009><c> and</c><00:12:55.160><c> you</c><00:12:55.759><c> know</c><00:12:56.029><c> their</c><00:12:56.449><c> labels</c><00:12:56.870><c> first</c>

00:12:57.160 --> 00:12:57.170 align:start position:0%
dataset and you know their labels first
 

00:12:57.170 --> 00:13:00.069 align:start position:0%
dataset and you know their labels first
four<00:12:57.589><c> examples</c><00:12:57.889><c> are</c><00:12:58.309><c> shown</c><00:12:58.339><c> here</c><00:12:58.850><c> and</c><00:12:59.149><c> what</c>

00:13:00.069 --> 00:13:00.079 align:start position:0%
four examples are shown here and what
 

00:13:00.079 --> 00:13:02.079 align:start position:0%
four examples are shown here and what
they<00:13:00.230><c> did</c><00:13:00.410><c> is</c><00:13:00.589><c> that</c><00:13:00.620><c> for</c><00:13:00.949><c> every</c><00:13:01.129><c> image</c><00:13:01.699><c> in</c>

00:13:02.079 --> 00:13:02.089 align:start position:0%
they did is that for every image in
 

00:13:02.089 --> 00:13:05.470 align:start position:0%
they did is that for every image in
their<00:13:02.720><c> data</c><00:13:02.959><c> set</c><00:13:03.290><c> they</c><00:13:04.009><c> flipped</c><00:13:04.670><c> a</c><00:13:04.790><c> die</c><00:13:04.970><c> write</c>

00:13:05.470 --> 00:13:05.480 align:start position:0%
their data set they flipped a die write
 

00:13:05.480 --> 00:13:08.470 align:start position:0%
their data set they flipped a die write
a<00:13:05.509><c> K</c><00:13:05.839><c> sided</c><00:13:06.259><c> die</c><00:13:06.410><c> where</c><00:13:06.980><c> K</c><00:13:07.339><c> is</c><00:13:07.639><c> the</c><00:13:07.910><c> number</c><00:13:08.449><c> of</c>

00:13:08.470 --> 00:13:08.480 align:start position:0%
a K sided die where K is the number of
 

00:13:08.480 --> 00:13:10.389 align:start position:0%
a K sided die where K is the number of
possible<00:13:09.050><c> classes</c><00:13:09.499><c> that</c><00:13:09.649><c> they</c><00:13:09.949><c> were</c><00:13:10.009><c> trying</c>

00:13:10.389 --> 00:13:10.399 align:start position:0%
possible classes that they were trying
 

00:13:10.399 --> 00:13:12.249 align:start position:0%
possible classes that they were trying
to<00:13:10.459><c> consider</c><00:13:10.879><c> in</c><00:13:11.120><c> a</c><00:13:11.420><c> classification</c><00:13:11.929><c> problem</c>

00:13:12.249 --> 00:13:12.259 align:start position:0%
to consider in a classification problem
 

00:13:12.259 --> 00:13:15.879 align:start position:0%
to consider in a classification problem
and<00:13:12.860><c> they</c><00:13:13.670><c> use</c><00:13:13.910><c> this</c><00:13:14.120><c> result</c><00:13:14.389><c> of</c><00:13:14.809><c> this</c><00:13:15.500><c> die</c>

00:13:15.879 --> 00:13:15.889 align:start position:0%
and they use this result of this die
 

00:13:15.889 --> 00:13:19.580 align:start position:0%
and they use this result of this die
roll<00:13:16.189><c> to</c><00:13:17.800><c> assign</c><00:13:18.800><c> a</c><00:13:19.040><c> brand</c>

00:13:19.580 --> 00:13:19.590 align:start position:0%
roll to assign a brand
 

00:13:19.590 --> 00:13:22.880 align:start position:0%
roll to assign a brand
you<00:13:19.710><c> randomly</c><00:13:20.490><c> sampled</c><00:13:21.120><c> label</c><00:13:22.110><c> to</c><00:13:22.410><c> that</c><00:13:22.650><c> image</c>

00:13:22.880 --> 00:13:22.890 align:start position:0%
you randomly sampled label to that image
 

00:13:22.890 --> 00:13:26.030 align:start position:0%
you randomly sampled label to that image
and<00:13:23.430><c> this</c><00:13:24.330><c> means</c><00:13:24.540><c> that</c><00:13:24.690><c> you</c><00:13:25.470><c> know</c><00:13:25.590><c> these</c><00:13:25.740><c> new</c>

00:13:26.030 --> 00:13:26.040 align:start position:0%
and this means that you know these new
 

00:13:26.040 --> 00:13:28.220 align:start position:0%
and this means that you know these new
labels<00:13:26.460><c> associated</c><00:13:26.850><c> with</c><00:13:27.420><c> each</c><00:13:27.720><c> image</c><00:13:28.050><c> were</c>

00:13:28.220 --> 00:13:28.230 align:start position:0%
labels associated with each image were
 

00:13:28.230 --> 00:13:30.860 align:start position:0%
labels associated with each image were
completely<00:13:28.740><c> random</c><00:13:29.160><c> with</c><00:13:29.820><c> respect</c><00:13:30.300><c> to</c><00:13:30.630><c> what</c>

00:13:30.860 --> 00:13:30.870 align:start position:0%
completely random with respect to what
 

00:13:30.870 --> 00:13:33.800 align:start position:0%
completely random with respect to what
was<00:13:31.050><c> actually</c><00:13:31.290><c> present</c><00:13:32.070><c> in</c><00:13:32.160><c> the</c><00:13:32.190><c> image</c><00:13:32.580><c> and</c><00:13:32.850><c> if</c>

00:13:33.800 --> 00:13:33.810 align:start position:0%
was actually present in the image and if
 

00:13:33.810 --> 00:13:36.050 align:start position:0%
was actually present in the image and if
you'll<00:13:33.990><c> notice</c><00:13:34.350><c> that</c><00:13:34.530><c> these</c><00:13:35.010><c> two</c><00:13:35.340><c> examples</c><00:13:35.730><c> of</c>

00:13:36.050 --> 00:13:36.060 align:start position:0%
you'll notice that these two examples of
 

00:13:36.060 --> 00:13:39.410 align:start position:0%
you'll notice that these two examples of
dogs<00:13:36.680><c> ended</c><00:13:37.680><c> up</c><00:13:37.830><c> in</c><00:13:38.070><c> this</c><00:13:39.030><c> in</c><00:13:39.240><c> this</c>

00:13:39.410 --> 00:13:39.420 align:start position:0%
dogs ended up in this in this
 

00:13:39.420 --> 00:13:41.990 align:start position:0%
dogs ended up in this in this
demonstration<00:13:39.900><c> that</c><00:13:40.410><c> I'm</c><00:13:40.500><c> showing</c><00:13:41.000><c> being</c>

00:13:41.990 --> 00:13:42.000 align:start position:0%
demonstration that I'm showing being
 

00:13:42.000 --> 00:13:44.560 align:start position:0%
demonstration that I'm showing being
mapped<00:13:42.240><c> to</c><00:13:42.660><c> different</c><00:13:42.690><c> classes</c><00:13:43.290><c> altogether</c>

00:13:44.560 --> 00:13:44.570 align:start position:0%
mapped to different classes altogether
 

00:13:44.570 --> 00:13:47.450 align:start position:0%
mapped to different classes altogether
so<00:13:45.570><c> we're</c><00:13:45.780><c> literally</c><00:13:46.110><c> trying</c><00:13:46.560><c> to</c><00:13:46.770><c> randomize</c>

00:13:47.450 --> 00:13:47.460 align:start position:0%
so we're literally trying to randomize
 

00:13:47.460 --> 00:13:51.560 align:start position:0%
so we're literally trying to randomize
our<00:13:47.790><c> labels</c><00:13:48.210><c> entirely</c><00:13:49.940><c> then</c><00:13:50.940><c> what</c><00:13:51.210><c> they</c><00:13:51.330><c> did</c>

00:13:51.560 --> 00:13:51.570 align:start position:0%
our labels entirely then what they did
 

00:13:51.570 --> 00:13:54.140 align:start position:0%
our labels entirely then what they did
was<00:13:51.810><c> that</c><00:13:51.840><c> they</c><00:13:52.140><c> tried</c><00:13:52.440><c> to</c><00:13:52.470><c> fit</c><00:13:53.400><c> a</c><00:13:53.670><c> deep</c><00:13:53.940><c> neural</c>

00:13:54.140 --> 00:13:54.150 align:start position:0%
was that they tried to fit a deep neural
 

00:13:54.150 --> 00:13:57.290 align:start position:0%
was that they tried to fit a deep neural
network<00:13:54.570><c> model</c><00:13:55.020><c> to</c><00:13:55.680><c> the</c><00:13:55.950><c> sampled</c><00:13:56.520><c> image</c><00:13:56.760><c> net</c>

00:13:57.290 --> 00:13:57.300 align:start position:0%
network model to the sampled image net
 

00:13:57.300 --> 00:14:01.400 align:start position:0%
network model to the sampled image net
data<00:13:57.800><c> ranging</c><00:13:58.800><c> from</c><00:13:59.510><c> either</c><00:14:00.510><c> the</c><00:14:00.840><c> the</c>

00:14:01.400 --> 00:14:01.410 align:start position:0%
data ranging from either the the
 

00:14:01.410 --> 00:14:03.890 align:start position:0%
data ranging from either the the
untouched<00:14:02.130><c> original</c><00:14:02.730><c> data</c><00:14:02.940><c> with</c><00:14:03.240><c> the</c>

00:14:03.890 --> 00:14:03.900 align:start position:0%
untouched original data with the
 

00:14:03.900 --> 00:14:07.450 align:start position:0%
untouched original data with the
original<00:14:04.380><c> labels</c><00:14:04.740><c> to</c><00:14:05.430><c> data</c><00:14:06.270><c> that</c><00:14:06.600><c> they</c><00:14:07.020><c> had</c>

00:14:07.450 --> 00:14:07.460 align:start position:0%
original labels to data that they had
 

00:14:07.460 --> 00:14:09.680 align:start position:0%
original labels to data that they had
reassigned<00:14:08.460><c> the</c><00:14:08.580><c> labels</c><00:14:09.000><c> using</c><00:14:09.570><c> this</c>

00:14:09.680 --> 00:14:09.690 align:start position:0%
reassigned the labels using this
 

00:14:09.690 --> 00:14:12.100 align:start position:0%
reassigned the labels using this
completely<00:14:10.350><c> random</c><00:14:10.860><c> sampling</c><00:14:11.280><c> approach</c><00:14:11.640><c> and</c>

00:14:12.100 --> 00:14:12.110 align:start position:0%
completely random sampling approach and
 

00:14:12.110 --> 00:14:15.260 align:start position:0%
completely random sampling approach and
then<00:14:13.110><c> they</c><00:14:13.440><c> tested</c><00:14:14.370><c> the</c><00:14:14.460><c> accuracy</c><00:14:15.030><c> of</c><00:14:15.060><c> their</c>

00:14:15.260 --> 00:14:15.270 align:start position:0%
then they tested the accuracy of their
 

00:14:15.270 --> 00:14:18.560 align:start position:0%
then they tested the accuracy of their
model<00:14:15.660><c> on</c><00:14:15.840><c> a</c><00:14:16.200><c> test</c><00:14:16.650><c> data</c><00:14:16.860><c> set</c><00:14:17.160><c> and</c><00:14:17.370><c> as</c><00:14:18.060><c> you</c><00:14:18.450><c> may</c>

00:14:18.560 --> 00:14:18.570 align:start position:0%
model on a test data set and as you may
 

00:14:18.570 --> 00:14:22.090 align:start position:0%
model on a test data set and as you may
expect<00:14:19.190><c> the</c><00:14:20.190><c> accuracy</c><00:14:20.790><c> of</c><00:14:20.820><c> their</c><00:14:21.150><c> models</c>

00:14:22.090 --> 00:14:22.100 align:start position:0%
expect the accuracy of their models
 

00:14:22.100 --> 00:14:24.590 align:start position:0%
expect the accuracy of their models
progressively<00:14:23.100><c> decreased</c><00:14:23.790><c> as</c><00:14:24.090><c> the</c>

00:14:24.590 --> 00:14:24.600 align:start position:0%
progressively decreased as the
 

00:14:24.600 --> 00:14:27.190 align:start position:0%
progressively decreased as the
randomness<00:14:25.560><c> in</c><00:14:25.860><c> the</c><00:14:26.160><c> training</c><00:14:26.670><c> data</c><00:14:26.850><c> set</c>

00:14:27.190 --> 00:14:27.200 align:start position:0%
randomness in the training data set
 

00:14:27.200 --> 00:14:30.620 align:start position:0%
randomness in the training data set
increased<00:14:28.200><c> right</c><00:14:28.940><c> but</c><00:14:29.940><c> what</c><00:14:30.450><c> was</c><00:14:30.600><c> really</c>

00:14:30.620 --> 00:14:30.630 align:start position:0%
increased right but what was really
 

00:14:30.630 --> 00:14:33.350 align:start position:0%
increased right but what was really
interesting<00:14:30.930><c> was</c><00:14:31.440><c> when</c><00:14:32.040><c> they</c><00:14:32.220><c> tried</c><00:14:32.550><c> was</c><00:14:33.150><c> what</c>

00:14:33.350 --> 00:14:33.360 align:start position:0%
interesting was when they tried was what
 

00:14:33.360 --> 00:14:35.390 align:start position:0%
interesting was when they tried was what
happened<00:14:33.720><c> when</c><00:14:33.750><c> they</c><00:14:33.960><c> looked</c><00:14:34.260><c> at</c><00:14:34.470><c> what</c>

00:14:35.390 --> 00:14:35.400 align:start position:0%
happened when they looked at what
 

00:14:35.400 --> 00:14:37.640 align:start position:0%
happened when they looked at what
happened<00:14:35.820><c> in</c><00:14:36.000><c> the</c><00:14:36.510><c> training</c><00:14:36.960><c> data</c><00:14:36.990><c> set</c><00:14:37.410><c> and</c>

00:14:37.640 --> 00:14:37.650 align:start position:0%
happened in the training data set and
 

00:14:37.650 --> 00:14:40.580 align:start position:0%
happened in the training data set and
this<00:14:38.460><c> is</c><00:14:38.640><c> what</c><00:14:38.790><c> they</c><00:14:38.910><c> found</c><00:14:39.150><c> that</c><00:14:40.110><c> no</c><00:14:40.350><c> matter</c>

00:14:40.580 --> 00:14:40.590 align:start position:0%
this is what they found that no matter
 

00:14:40.590 --> 00:14:43.280 align:start position:0%
this is what they found that no matter
how<00:14:41.340><c> much</c><00:14:41.640><c> they</c><00:14:41.880><c> randomized</c><00:14:42.420><c> the</c><00:14:42.630><c> labels</c><00:14:43.050><c> the</c>

00:14:43.280 --> 00:14:43.290 align:start position:0%
how much they randomized the labels the
 

00:14:43.290 --> 00:14:46.070 align:start position:0%
how much they randomized the labels the
model<00:14:43.620><c> was</c><00:14:43.800><c> able</c><00:14:44.160><c> to</c><00:14:44.190><c> get</c><00:14:44.460><c> 100%</c><00:14:45.390><c> accuracy</c><00:14:45.870><c> on</c>

00:14:46.070 --> 00:14:46.080 align:start position:0%
model was able to get 100% accuracy on
 

00:14:46.080 --> 00:14:47.870 align:start position:0%
model was able to get 100% accuracy on
the<00:14:46.110><c> training</c><00:14:46.350><c> set</c><00:14:46.740><c> right</c><00:14:47.040><c> because</c><00:14:47.700><c> in</c>

00:14:47.870 --> 00:14:47.880 align:start position:0%
the training set right because in
 

00:14:47.880 --> 00:14:50.810 align:start position:0%
the training set right because in
training<00:14:48.360><c> you</c><00:14:49.110><c> know</c><00:14:49.260><c> you're</c><00:14:49.680><c> doing</c><00:14:49.860><c> input</c>

00:14:50.810 --> 00:14:50.820 align:start position:0%
training you know you're doing input
 

00:14:50.820 --> 00:14:55.190 align:start position:0%
training you know you're doing input
label<00:14:51.510><c> you</c><00:14:52.140><c> know</c><00:14:52.170><c> both</c><00:14:52.560><c> right</c><00:14:53.070><c> and</c><00:14:53.990><c> this</c><00:14:54.990><c> is</c><00:14:55.170><c> a</c>

00:14:55.190 --> 00:14:55.200 align:start position:0%
label you know both right and this is a
 

00:14:55.200 --> 00:14:57.440 align:start position:0%
label you know both right and this is a
really<00:14:55.500><c> powerful</c><00:14:56.160><c> example</c><00:14:56.340><c> because</c><00:14:57.000><c> it</c><00:14:57.150><c> shows</c>

00:14:57.440 --> 00:14:57.450 align:start position:0%
really powerful example because it shows
 

00:14:57.450 --> 00:15:00.170 align:start position:0%
really powerful example because it shows
once<00:14:57.810><c> again</c><00:14:57.960><c> in</c><00:14:58.800><c> a</c><00:14:59.220><c> similar</c><00:14:59.550><c> way</c><00:14:59.610><c> as</c><00:14:59.940><c> the</c>

00:15:00.170 --> 00:15:00.180 align:start position:0%
once again in a similar way as the
 

00:15:00.180 --> 00:15:02.000 align:start position:0%
once again in a similar way as the
universal<00:15:00.780><c> approximation</c><00:15:01.350><c> theorem</c><00:15:01.740><c> that</c>

00:15:02.000 --> 00:15:02.010 align:start position:0%
universal approximation theorem that
 

00:15:02.010 --> 00:15:04.580 align:start position:0%
universal approximation theorem that
deep<00:15:02.370><c> neural</c><00:15:02.550><c> Nets</c><00:15:02.880><c> can</c><00:15:03.180><c> perfectly</c><00:15:04.080><c> fit</c><00:15:04.290><c> to</c>

00:15:04.580 --> 00:15:04.590 align:start position:0%
deep neural Nets can perfectly fit to
 

00:15:04.590 --> 00:15:08.000 align:start position:0%
deep neural Nets can perfectly fit to
any<00:15:04.830><c> function</c><00:15:05.220><c> even</c><00:15:06.000><c> if</c><00:15:06.450><c> that</c><00:15:06.660><c> function</c><00:15:07.010><c> sort</c>

00:15:08.000 --> 00:15:08.010 align:start position:0%
any function even if that function sort
 

00:15:08.010 --> 00:15:11.000 align:start position:0%
any function even if that function sort
of<00:15:08.100><c> is</c><00:15:08.280><c> based</c><00:15:08.790><c> on</c><00:15:09.000><c> entirely</c><00:15:09.450><c> random</c><00:15:10.140><c> labels</c>

00:15:11.000 --> 00:15:11.010 align:start position:0%
of is based on entirely random labels
 

00:15:11.010 --> 00:15:14.510 align:start position:0%
of is based on entirely random labels
and<00:15:12.050><c> to</c><00:15:13.050><c> drive</c><00:15:13.260><c> this</c><00:15:13.440><c> point</c><00:15:13.680><c> home</c><00:15:13.830><c> we</c><00:15:14.370><c> can</c>

00:15:14.510 --> 00:15:14.520 align:start position:0%
and to drive this point home we can
 

00:15:14.520 --> 00:15:16.760 align:start position:0%
and to drive this point home we can
understand<00:15:15.060><c> neural</c><00:15:15.330><c> networks</c><00:15:15.660><c> simply</c><00:15:16.650><c> as</c>

00:15:16.760 --> 00:15:16.770 align:start position:0%
understand neural networks simply as
 

00:15:16.770 --> 00:15:20.300 align:start position:0%
understand neural networks simply as
functional<00:15:17.480><c> approximator</c><00:15:18.480><c> x'</c><00:15:18.570><c> and</c><00:15:19.310><c> only</c>

00:15:20.300 --> 00:15:20.310 align:start position:0%
functional approximator x' and only
 

00:15:20.310 --> 00:15:22.940 align:start position:0%
functional approximator x' and only
universal<00:15:21.150><c> function</c><00:15:21.480><c> approximation</c><00:15:22.230><c> theorem</c>

00:15:22.940 --> 00:15:22.950 align:start position:0%
universal function approximation theorem
 

00:15:22.950 --> 00:15:25.520 align:start position:0%
universal function approximation theorem
States<00:15:23.340><c> is</c><00:15:23.640><c> that</c><00:15:24.030><c> neural</c><00:15:24.960><c> networks</c><00:15:25.320><c> are</c>

00:15:25.520 --> 00:15:25.530 align:start position:0%
States is that neural networks are
 

00:15:25.530 --> 00:15:28.420 align:start position:0%
States is that neural networks are
really<00:15:25.920><c> really</c><00:15:26.250><c> good</c><00:15:26.490><c> at</c><00:15:26.670><c> doing</c><00:15:26.850><c> this</c><00:15:27.350><c> so</c>

00:15:28.420 --> 00:15:28.430 align:start position:0%
really really good at doing this so
 

00:15:28.430 --> 00:15:31.400 align:start position:0%
really really good at doing this so
suppose<00:15:29.430><c> you</c><00:15:29.610><c> have</c><00:15:29.820><c> this</c><00:15:30.120><c> you</c><00:15:30.660><c> know</c><00:15:30.690><c> the</c><00:15:31.140><c> set</c>

00:15:31.400 --> 00:15:31.410 align:start position:0%
suppose you have this you know the set
 

00:15:31.410 --> 00:15:32.900 align:start position:0%
suppose you have this you know the set
of<00:15:31.590><c> training</c><00:15:31.860><c> data</c>

00:15:32.900 --> 00:15:32.910 align:start position:0%
of training data
 

00:15:32.910 --> 00:15:36.200 align:start position:0%
of training data
we<00:15:33.660><c> can</c><00:15:33.840><c> learn</c><00:15:34.250><c> you</c><00:15:35.250><c> we</c><00:15:35.490><c> can</c><00:15:35.640><c> use</c><00:15:35.940><c> a</c><00:15:35.970><c> neural</c>

00:15:36.200 --> 00:15:36.210 align:start position:0%
we can learn you we can use a neural
 

00:15:36.210 --> 00:15:38.870 align:start position:0%
we can learn you we can use a neural
network<00:15:36.480><c> to</c><00:15:36.810><c> learn</c><00:15:37.020><c> a</c><00:15:37.430><c> maximum</c><00:15:38.430><c> likelihood</c>

00:15:38.870 --> 00:15:38.880 align:start position:0%
network to learn a maximum likelihood
 

00:15:38.880 --> 00:15:42.980 align:start position:0%
network to learn a maximum likelihood
estimate<00:15:39.600><c> of</c><00:15:39.750><c> this</c><00:15:40.230><c> training</c><00:15:40.710><c> data</c><00:15:40.920><c> and</c><00:15:41.480><c> if</c><00:15:42.480><c> we</c>

00:15:42.980 --> 00:15:42.990 align:start position:0%
estimate of this training data and if we
 

00:15:42.990 --> 00:15:44.690 align:start position:0%
estimate of this training data and if we
were<00:15:43.110><c> to</c><00:15:43.170><c> give</c><00:15:43.410><c> the</c><00:15:43.590><c> model</c><00:15:43.800><c> a</c><00:15:44.100><c> new</c><00:15:44.340><c> data</c><00:15:44.580><c> point</c>

00:15:44.690 --> 00:15:44.700 align:start position:0%
were to give the model a new data point
 

00:15:44.700 --> 00:15:48.710 align:start position:0%
were to give the model a new data point
shown<00:15:45.540><c> here</c><00:15:45.840><c> in</c><00:15:45.930><c> this</c><00:15:46.080><c> purple</c><00:15:46.440><c> arrow</c><00:15:47.510><c> we</c><00:15:48.510><c> can</c>

00:15:48.710 --> 00:15:48.720 align:start position:0%
shown here in this purple arrow we can
 

00:15:48.720 --> 00:15:52.010 align:start position:0%
shown here in this purple arrow we can
use<00:15:48.930><c> it</c><00:15:49.110><c> to</c><00:15:49.610><c> predict</c><00:15:50.610><c> what</c><00:15:51.120><c> the</c><00:15:51.510><c> maximum</c>

00:15:52.010 --> 00:15:52.020 align:start position:0%
use it to predict what the maximum
 

00:15:52.020 --> 00:15:54.500 align:start position:0%
use it to predict what the maximum
likelihood<00:15:52.490><c> estimate</c><00:15:53.490><c> for</c><00:15:53.790><c> that</c><00:15:54.000><c> data</c><00:15:54.240><c> point</c>

00:15:54.500 --> 00:15:54.510 align:start position:0%
likelihood estimate for that data point
 

00:15:54.510 --> 00:15:57.890 align:start position:0%
likelihood estimate for that data point
is<00:15:54.630><c> going</c><00:15:54.840><c> to</c><00:15:54.930><c> be</c><00:15:55.400><c> but</c><00:15:56.400><c> if</c><00:15:56.580><c> we</c><00:15:56.760><c> extend</c><00:15:57.210><c> the</c><00:15:57.390><c> axis</c>

00:15:57.890 --> 00:15:57.900 align:start position:0%
is going to be but if we extend the axis
 

00:15:57.900 --> 00:16:00.080 align:start position:0%
is going to be but if we extend the axis
a<00:15:57.930><c> bit</c><00:15:58.320><c> left</c><00:15:58.770><c> and</c><00:15:58.890><c> right</c><00:15:59.130><c> outside</c><00:15:59.790><c> of</c><00:15:59.850><c> the</c>

00:16:00.080 --> 00:16:00.090 align:start position:0%
a bit left and right outside of the
 

00:16:00.090 --> 00:16:01.670 align:start position:0%
a bit left and right outside of the
space<00:16:00.360><c> of</c><00:16:00.390><c> the</c><00:16:00.720><c> training</c><00:16:01.080><c> data</c><00:16:01.110><c> that</c><00:16:01.560><c> the</c>

00:16:01.670 --> 00:16:01.680 align:start position:0%
space of the training data that the
 

00:16:01.680 --> 00:16:04.540 align:start position:0%
space of the training data that the
network<00:16:01.980><c> has</c><00:16:02.130><c> seen</c><00:16:02.510><c> what</c><00:16:03.510><c> happens</c><00:16:03.930><c> right</c>

00:16:04.540 --> 00:16:04.550 align:start position:0%
network has seen what happens right
 

00:16:04.550 --> 00:16:07.430 align:start position:0%
network has seen what happens right
there<00:16:05.550><c> are</c><00:16:05.670><c> no</c><00:16:05.850><c> guarantees</c><00:16:06.480><c> on</c><00:16:06.840><c> what</c><00:16:07.230><c> the</c>

00:16:07.430 --> 00:16:07.440 align:start position:0%
there are no guarantees on what the
 

00:16:07.440 --> 00:16:09.110 align:start position:0%
there are no guarantees on what the
training<00:16:07.800><c> data</c><00:16:07.950><c> will</c><00:16:08.310><c> look</c><00:16:08.520><c> like</c><00:16:08.700><c> outside</c>

00:16:09.110 --> 00:16:09.120 align:start position:0%
training data will look like outside
 

00:16:09.120 --> 00:16:11.480 align:start position:0%
training data will look like outside
these<00:16:09.690><c> bounds</c><00:16:10.140><c> and</c><00:16:10.320><c> this</c><00:16:10.950><c> is</c><00:16:11.100><c> a</c><00:16:11.130><c> huge</c>

00:16:11.480 --> 00:16:11.490 align:start position:0%
these bounds and this is a huge
 

00:16:11.490 --> 00:16:15.140 align:start position:0%
these bounds and this is a huge
limitation<00:16:12.210><c> that</c><00:16:12.570><c> exists</c><00:16:13.170><c> in</c><00:16:13.350><c> modern</c><00:16:14.190><c> deep</c>

00:16:15.140 --> 00:16:15.150 align:start position:0%
limitation that exists in modern deep
 

00:16:15.150 --> 00:16:17.360 align:start position:0%
limitation that exists in modern deep
neural<00:16:15.330><c> networks</c><00:16:15.810><c> and</c><00:16:16.140><c> and</c><00:16:16.710><c> in</c><00:16:16.980><c> deep</c><00:16:17.190><c> learning</c>

00:16:17.360 --> 00:16:17.370 align:start position:0%
neural networks and and in deep learning
 

00:16:17.370 --> 00:16:21.140 align:start position:0%
neural networks and and in deep learning
generally<00:16:17.970><c> and</c><00:16:18.680><c> so</c><00:16:19.680><c> you</c><00:16:20.490><c> know</c><00:16:20.610><c> if</c><00:16:20.790><c> you</c><00:16:20.910><c> look</c>

00:16:21.140 --> 00:16:21.150 align:start position:0%
generally and so you know if you look
 

00:16:21.150 --> 00:16:23.960 align:start position:0%
generally and so you know if you look
here<00:16:21.660><c> outside</c><00:16:21.900><c> of</c><00:16:22.650><c> these</c><00:16:23.130><c> bounds</c><00:16:23.640><c> that</c><00:16:23.790><c> the</c>

00:16:23.960 --> 00:16:23.970 align:start position:0%
here outside of these bounds that the
 

00:16:23.970 --> 00:16:26.690 align:start position:0%
here outside of these bounds that the
network<00:16:24.360><c> has</c><00:16:24.390><c> been</c><00:16:24.660><c> trained</c><00:16:25.170><c> on</c><00:16:25.430><c> we</c><00:16:26.430><c> can't</c>

00:16:26.690 --> 00:16:26.700 align:start position:0%
network has been trained on we can't
 

00:16:26.700 --> 00:16:28.400 align:start position:0%
network has been trained on we can't
really<00:16:26.910><c> know</c><00:16:27.030><c> what</c><00:16:27.510><c> our</c><00:16:27.540><c> function</c><00:16:28.080><c> looks</c><00:16:28.110><c> like</c>

00:16:28.400 --> 00:16:28.410 align:start position:0%
really know what our function looks like
 

00:16:28.410 --> 00:16:31.160 align:start position:0%
really know what our function looks like
if<00:16:28.830><c> the</c><00:16:29.100><c> network</c><00:16:29.310><c> has</c><00:16:29.460><c> never</c><00:16:29.970><c> seen</c><00:16:30.600><c> data</c><00:16:30.870><c> from</c>

00:16:31.160 --> 00:16:31.170 align:start position:0%
if the network has never seen data from
 

00:16:31.170 --> 00:16:34.280 align:start position:0%
if the network has never seen data from
those<00:16:31.350><c> pieces</c><00:16:31.710><c> before</c><00:16:32.220><c> right</c><00:16:32.990><c> so</c><00:16:33.990><c> it's</c><00:16:34.140><c> not</c>

00:16:34.280 --> 00:16:34.290 align:start position:0%
those pieces before right so it's not
 

00:16:34.290 --> 00:16:38.200 align:start position:0%
those pieces before right so it's not
going<00:16:34.530><c> to</c><00:16:34.650><c> do</c><00:16:34.800><c> very</c><00:16:35.340><c> well</c><00:16:35.450><c> and</c><00:16:36.530><c> this</c><00:16:37.530><c> notion</c>

00:16:38.200 --> 00:16:38.210 align:start position:0%
going to do very well and this notion
 

00:16:38.210 --> 00:16:41.150 align:start position:0%
going to do very well and this notion
leaves<00:16:39.210><c> really</c><00:16:39.480><c> nicely</c><00:16:39.780><c> into</c><00:16:40.320><c> this</c><00:16:40.740><c> idea</c><00:16:41.100><c> of</c>

00:16:41.150 --> 00:16:41.160 align:start position:0%
leaves really nicely into this idea of
 

00:16:41.160 --> 00:16:43.640 align:start position:0%
leaves really nicely into this idea of
what's<00:16:41.400><c> known</c><00:16:41.670><c> as</c><00:16:41.910><c> adversarial</c><00:16:42.900><c> attacks</c><00:16:43.320><c> on</c>

00:16:43.640 --> 00:16:43.650 align:start position:0%
what's known as adversarial attacks on
 

00:16:43.650 --> 00:16:46.670 align:start position:0%
what's known as adversarial attacks on
neural<00:16:44.070><c> networks</c><00:16:44.430><c> and</c><00:16:44.670><c> the</c><00:16:45.570><c> idea</c><00:16:45.900><c> here</c><00:16:46.320><c> is</c><00:16:46.380><c> to</c>

00:16:46.670 --> 00:16:46.680 align:start position:0%
neural networks and the idea here is to
 

00:16:46.680 --> 00:16:49.520 align:start position:0%
neural networks and the idea here is to
take<00:16:46.890><c> some</c><00:16:47.190><c> example</c><00:16:47.760><c> for</c><00:16:48.390><c> example</c><00:16:48.780><c> this</c><00:16:49.020><c> this</c>

00:16:49.520 --> 00:16:49.530 align:start position:0%
take some example for example this this
 

00:16:49.530 --> 00:16:52.340 align:start position:0%
take some example for example this this
image<00:16:49.980><c> of</c><00:16:50.250><c> what</c><00:16:51.120><c> you</c><00:16:51.150><c> can</c><00:16:51.360><c> see</c><00:16:51.600><c> is</c><00:16:51.780><c> a</c><00:16:51.810><c> temple</c>

00:16:52.340 --> 00:16:52.350 align:start position:0%
image of what you can see is a temple
 

00:16:52.350 --> 00:16:56.090 align:start position:0%
image of what you can see is a temple
which<00:16:52.950><c> a</c><00:16:53.160><c> standard</c><00:16:53.700><c> CNN</c><00:16:54.470><c> trained</c><00:16:55.470><c> on</c><00:16:55.590><c> imagenet</c>

00:16:56.090 --> 00:16:56.100 align:start position:0%
which a standard CNN trained on imagenet
 

00:16:56.100 --> 00:16:58.640 align:start position:0%
which a standard CNN trained on imagenet
let's<00:16:56.550><c> say</c><00:16:56.730><c> can</c><00:16:57.060><c> classify</c><00:16:57.360><c> as</c><00:16:57.930><c> a</c><00:16:57.960><c> temple</c><00:16:58.410><c> with</c>

00:16:58.640 --> 00:16:58.650 align:start position:0%
let's say can classify as a temple with
 

00:16:58.650 --> 00:17:02.210 align:start position:0%
let's say can classify as a temple with
you<00:16:59.220><c> know</c><00:16:59.340><c> 97</c><00:17:00.000><c> percent</c><00:17:00.390><c> probability</c><00:17:00.870><c> and</c><00:17:01.320><c> then</c>

00:17:02.210 --> 00:17:02.220 align:start position:0%
you know 97 percent probability and then
 

00:17:02.220 --> 00:17:05.120 align:start position:0%
you know 97 percent probability and then
we<00:17:02.370><c> can</c><00:17:02.610><c> apply</c><00:17:03.360><c> some</c><00:17:03.740><c> perturbation</c><00:17:04.740><c> to</c><00:17:04.949><c> that</c>

00:17:05.120 --> 00:17:05.130 align:start position:0%
we can apply some perturbation to that
 

00:17:05.130 --> 00:17:08.449 align:start position:0%
we can apply some perturbation to that
image<00:17:05.520><c> to</c><00:17:06.589><c> generate</c><00:17:07.589><c> what</c><00:17:07.800><c> we</c><00:17:07.829><c> call</c><00:17:08.189><c> an</c>

00:17:08.449 --> 00:17:08.459 align:start position:0%
image to generate what we call an
 

00:17:08.459 --> 00:17:11.150 align:start position:0%
image to generate what we call an
adversarial<00:17:09.240><c> example</c><00:17:09.870><c> which</c><00:17:10.199><c> to</c><00:17:10.439><c> us</c><00:17:10.589><c> looks</c>

00:17:11.150 --> 00:17:11.160 align:start position:0%
adversarial example which to us looks
 

00:17:11.160 --> 00:17:14.329 align:start position:0%
adversarial example which to us looks
completely<00:17:11.760><c> similar</c><00:17:12.720><c> to</c><00:17:12.990><c> the</c><00:17:13.260><c> original</c><00:17:13.709><c> image</c>

00:17:14.329 --> 00:17:14.339 align:start position:0%
completely similar to the original image
 

00:17:14.339 --> 00:17:17.540 align:start position:0%
completely similar to the original image
right<00:17:14.990><c> but</c><00:17:15.990><c> if</c><00:17:16.230><c> we</c><00:17:16.439><c> were</c><00:17:16.560><c> now</c><00:17:16.770><c> to</c><00:17:16.829><c> feed</c><00:17:17.339><c> this</c>

00:17:17.540 --> 00:17:17.550 align:start position:0%
right but if we were now to feed this
 

00:17:17.550 --> 00:17:19.910 align:start position:0%
right but if we were now to feed this
adversarial<00:17:18.270><c> example</c><00:17:18.930><c> through</c><00:17:19.470><c> that</c><00:17:19.650><c> same</c>

00:17:19.910 --> 00:17:19.920 align:start position:0%
adversarial example through that same
 

00:17:19.920 --> 00:17:22.550 align:start position:0%
adversarial example through that same
CNN<00:17:20.459><c> we</c><00:17:21.030><c> can</c><00:17:21.240><c> no</c><00:17:21.390><c> longer</c><00:17:21.420><c> recognize</c><00:17:22.170><c> it</c><00:17:22.380><c> as</c><00:17:22.530><c> a</c>

00:17:22.550 --> 00:17:22.560 align:start position:0%
CNN we can no longer recognize it as a
 

00:17:22.560 --> 00:17:25.309 align:start position:0%
CNN we can no longer recognize it as a
temple<00:17:23.040><c> you</c><00:17:23.310><c> know</c><00:17:23.339><c> and</c><00:17:23.730><c> instead</c><00:17:24.569><c> we</c><00:17:24.959><c> predict</c>

00:17:25.309 --> 00:17:25.319 align:start position:0%
temple you know and instead we predict
 

00:17:25.319 --> 00:17:27.020 align:start position:0%
temple you know and instead we predict
okay<00:17:25.650><c> this</c><00:17:25.829><c> is</c><00:17:25.980><c> an</c><00:17:26.100><c> image</c><00:17:26.370><c> of</c><00:17:26.490><c> an</c><00:17:26.610><c> ostrich</c>

00:17:27.020 --> 00:17:27.030 align:start position:0%
okay this is an image of an ostrich
 

00:17:27.030 --> 00:17:29.050 align:start position:0%
okay this is an image of an ostrich
right<00:17:27.480><c> that</c><00:17:27.720><c> makes</c><00:17:27.930><c> no</c><00:17:28.110><c> sense</c><00:17:28.380><c> right</c><00:17:28.650><c> so</c>

00:17:29.050 --> 00:17:29.060 align:start position:0%
right that makes no sense right so
 

00:17:29.060 --> 00:17:32.360 align:start position:0%
right that makes no sense right so
what's<00:17:30.060><c> going</c><00:17:30.390><c> on</c><00:17:30.650><c> what</c><00:17:31.650><c> is</c><00:17:31.770><c> it</c><00:17:31.920><c> about</c><00:17:32.070><c> these</c>

00:17:32.360 --> 00:17:32.370 align:start position:0%
what's going on what is it about these
 

00:17:32.370 --> 00:17:34.010 align:start position:0%
what's going on what is it about these
perturbations<00:17:33.120><c> and</c><00:17:33.270><c> how</c><00:17:33.480><c> are</c><00:17:33.660><c> we</c><00:17:33.780><c> generating</c>

00:17:34.010 --> 00:17:34.020 align:start position:0%
perturbations and how are we generating
 

00:17:34.020 --> 00:17:37.310 align:start position:0%
perturbations and how are we generating
them<00:17:34.590><c> that</c><00:17:34.890><c> we're</c><00:17:35.790><c> able</c><00:17:35.940><c> to</c><00:17:36.300><c> fool</c><00:17:36.750><c> the</c><00:17:36.960><c> network</c>

00:17:37.310 --> 00:17:37.320 align:start position:0%
them that we're able to fool the network
 

00:17:37.320 --> 00:17:41.360 align:start position:0%
them that we're able to fool the network
in<00:17:37.590><c> in</c><00:17:37.860><c> this</c><00:17:38.040><c> way</c><00:17:39.080><c> so</c><00:17:40.080><c> remember</c><00:17:40.560><c> that</c><00:17:40.590><c> normally</c>

00:17:41.360 --> 00:17:41.370 align:start position:0%
in in this way so remember that normally
 

00:17:41.370 --> 00:17:43.370 align:start position:0%
in in this way so remember that normally
during<00:17:41.610><c> training</c><00:17:42.240><c> when</c><00:17:42.870><c> we</c><00:17:42.990><c> train</c><00:17:43.200><c> our</c>

00:17:43.370 --> 00:17:43.380 align:start position:0%
during training when we train our
 

00:17:43.380 --> 00:17:45.320 align:start position:0%
during training when we train our
network<00:17:43.710><c> using</c><00:17:44.220><c> gradient</c><00:17:44.610><c> descent</c>

00:17:45.320 --> 00:17:45.330 align:start position:0%
network using gradient descent
 

00:17:45.330 --> 00:17:47.749 align:start position:0%
network using gradient descent
we<00:17:45.720><c> have</c><00:17:45.989><c> some</c><00:17:46.350><c> like</c><00:17:46.919><c> objective</c><00:17:47.549><c> loss</c>

00:17:47.749 --> 00:17:47.759 align:start position:0%
we have some like objective loss
 

00:17:47.759 --> 00:17:51.169 align:start position:0%
we have some like objective loss
function<00:17:48.330><c> J</c><00:17:49.139><c> right</c><00:17:49.950><c> that</c><00:17:50.580><c> we're</c><00:17:50.759><c> trying</c><00:17:51.029><c> to</c>

00:17:51.169 --> 00:17:51.179 align:start position:0%
function J right that we're trying to
 

00:17:51.179 --> 00:17:54.159 align:start position:0%
function J right that we're trying to
optimize<00:17:51.799><c> given</c><00:17:52.799><c> a</c><00:17:52.889><c> set</c><00:17:53.100><c> of</c><00:17:53.220><c> weights</c><00:17:53.460><c> theta</c>

00:17:54.159 --> 00:17:54.169 align:start position:0%
optimize given a set of weights theta
 

00:17:54.169 --> 00:17:59.889 align:start position:0%
optimize given a set of weights theta
input<00:17:55.169><c> data</c><00:17:55.350><c> X</c><00:17:55.619><c> and</c><00:17:56.039><c> some</c><00:17:56.519><c> output</c><00:17:57.389><c> label</c><00:17:57.749><c> Y</c><00:17:58.489><c> and</c>

00:17:59.889 --> 00:17:59.899 align:start position:0%
input data X and some output label Y and
 

00:17:59.899 --> 00:18:03.320 align:start position:0%
input data X and some output label Y and
what<00:18:00.899><c> we're</c><00:18:01.080><c> asking</c><00:18:01.289><c> is</c><00:18:01.799><c> how</c><00:18:02.610><c> does</c><00:18:02.879><c> a</c><00:18:02.909><c> small</c>

00:18:03.320 --> 00:18:03.330 align:start position:0%
what we're asking is how does a small
 

00:18:03.330 --> 00:18:06.789 align:start position:0%
what we're asking is how does a small
shift<00:18:03.899><c> in</c><00:18:04.110><c> the</c><00:18:04.799><c> weights</c><00:18:05.009><c> change</c><00:18:05.369><c> our</c><00:18:06.210><c> loss</c>

00:18:06.789 --> 00:18:06.799 align:start position:0%
shift in the weights change our loss
 

00:18:06.799 --> 00:18:09.799 align:start position:0%
shift in the weights change our loss
specifically<00:18:07.879><c> how</c><00:18:08.879><c> can</c><00:18:09.149><c> we</c><00:18:09.299><c> change</c><00:18:09.539><c> our</c>

00:18:09.799 --> 00:18:09.809 align:start position:0%
specifically how can we change our
 

00:18:09.809 --> 00:18:12.200 align:start position:0%
specifically how can we change our
weights<00:18:10.019><c> theta</c><00:18:10.830><c> in</c><00:18:11.159><c> some</c><00:18:11.519><c> way</c><00:18:11.669><c> to</c><00:18:11.730><c> minimize</c>

00:18:12.200 --> 00:18:12.210 align:start position:0%
weights theta in some way to minimize
 

00:18:12.210 --> 00:18:15.669 align:start position:0%
weights theta in some way to minimize
this<00:18:12.629><c> loss</c><00:18:12.899><c> and</c><00:18:13.489><c> when</c><00:18:14.489><c> we</c><00:18:14.639><c> train</c><00:18:14.909><c> our</c><00:18:15.090><c> networks</c>

00:18:15.669 --> 00:18:15.679 align:start position:0%
this loss and when we train our networks
 

00:18:15.679 --> 00:18:18.950 align:start position:0%
this loss and when we train our networks
to<00:18:16.679><c> you</c><00:18:17.399><c> know</c><00:18:17.519><c> optimize</c><00:18:18.119><c> this</c><00:18:18.389><c> set</c><00:18:18.600><c> of</c><00:18:18.690><c> weights</c>

00:18:18.950 --> 00:18:18.960 align:start position:0%
to you know optimize this set of weights
 

00:18:18.960 --> 00:18:22.759 align:start position:0%
to you know optimize this set of weights
we're<00:18:19.769><c> using</c><00:18:20.009><c> a</c><00:18:20.279><c> fixed</c><00:18:20.580><c> input</c><00:18:20.970><c> X</c><00:18:21.600><c> and</c><00:18:21.929><c> a</c><00:18:22.379><c> fixed</c>

00:18:22.759 --> 00:18:22.769 align:start position:0%
we're using a fixed input X and a fixed
 

00:18:22.769 --> 00:18:26.210 align:start position:0%
we're using a fixed input X and a fixed
label<00:18:23.460><c> Y</c><00:18:23.820><c> and</c><00:18:24.210><c> we're</c><00:18:24.779><c> again</c><00:18:25.379><c> reiterating</c>

00:18:26.210 --> 00:18:26.220 align:start position:0%
label Y and we're again reiterating
 

00:18:26.220 --> 00:18:28.489 align:start position:0%
label Y and we're again reiterating
trying<00:18:26.820><c> to</c><00:18:26.970><c> update</c><00:18:27.119><c> our</c><00:18:27.419><c> weights</c><00:18:27.659><c> to</c><00:18:28.109><c> minimize</c>

00:18:28.489 --> 00:18:28.499 align:start position:0%
trying to update our weights to minimize
 

00:18:28.499 --> 00:18:32.810 align:start position:0%
trying to update our weights to minimize
that<00:18:28.710><c> loss</c><00:18:30.049><c> with</c><00:18:31.049><c> adversarial</c><00:18:31.919><c> attacks</c><00:18:32.249><c> we're</c>

00:18:32.810 --> 00:18:32.820 align:start position:0%
that loss with adversarial attacks we're
 

00:18:32.820 --> 00:18:35.919 align:start position:0%
that loss with adversarial attacks we're
asking<00:18:33.269><c> a</c><00:18:33.419><c> different</c><00:18:33.570><c> problem</c><00:18:34.200><c> how</c><00:18:35.039><c> can</c><00:18:35.070><c> we</c>

00:18:35.919 --> 00:18:35.929 align:start position:0%
asking a different problem how can we
 

00:18:35.929 --> 00:18:40.070 align:start position:0%
asking a different problem how can we
modify<00:18:36.929><c> our</c><00:18:37.169><c> input</c><00:18:37.739><c> our</c><00:18:38.149><c> input</c><00:18:39.149><c> for</c><00:18:39.749><c> example</c>

00:18:40.070 --> 00:18:40.080 align:start position:0%
modify our input our input for example
 

00:18:40.080 --> 00:18:42.950 align:start position:0%
modify our input our input for example
an<00:18:40.169><c> image</c><00:18:40.379><c> our</c><00:18:40.769><c> input</c><00:18:41.369><c> X</c><00:18:41.580><c> in</c><00:18:41.940><c> order</c><00:18:42.539><c> to</c><00:18:42.809><c> now</c>

00:18:42.950 --> 00:18:42.960 align:start position:0%
an image our input X in order to now
 

00:18:42.960 --> 00:18:46.190 align:start position:0%
an image our input X in order to now
increase<00:18:43.730><c> the</c><00:18:44.730><c> error</c><00:18:44.940><c> in</c><00:18:45.389><c> our</c><00:18:45.779><c> networks</c>

00:18:46.190 --> 00:18:46.200 align:start position:0%
increase the error in our networks
 

00:18:46.200 --> 00:18:50.149 align:start position:0%
increase the error in our networks
prediction<00:18:47.600><c> so</c><00:18:48.600><c> we're</c><00:18:49.259><c> trying</c><00:18:49.590><c> to</c><00:18:49.830><c> optimize</c>

00:18:50.149 --> 00:18:50.159 align:start position:0%
prediction so we're trying to optimize
 

00:18:50.159 --> 00:18:53.989 align:start position:0%
prediction so we're trying to optimize
over<00:18:51.149><c> the</c><00:18:51.239><c> input</c><00:18:51.419><c> X</c><00:18:51.929><c> right</c><00:18:52.889><c> to</c><00:18:53.309><c> perturb</c><00:18:53.700><c> it</c><00:18:53.850><c> in</c>

00:18:53.989 --> 00:18:53.999 align:start position:0%
over the input X right to perturb it in
 

00:18:53.999 --> 00:18:57.440 align:start position:0%
over the input X right to perturb it in
some<00:18:54.269><c> way</c><00:18:55.460><c> given</c><00:18:56.460><c> a</c><00:18:56.549><c> fixed</c><00:18:56.789><c> set</c><00:18:57.090><c> of</c><00:18:57.119><c> weights</c>

00:18:57.440 --> 00:18:57.450 align:start position:0%
some way given a fixed set of weights
 

00:18:57.450 --> 00:19:01.759 align:start position:0%
some way given a fixed set of weights
theta<00:18:57.899><c> and</c><00:18:58.200><c> a</c><00:18:58.649><c> fixed</c><00:18:59.070><c> output</c><00:18:59.639><c> Y</c><00:19:00.090><c> and</c><00:19:00.769><c> instead</c>

00:19:01.759 --> 00:19:01.769 align:start position:0%
theta and a fixed output Y and instead
 

00:19:01.769 --> 00:19:03.739 align:start position:0%
theta and a fixed output Y and instead
of<00:19:01.889><c> minimizing</c><00:19:02.759><c> the</c><00:19:02.879><c> loss</c><00:19:03.029><c> we're</c><00:19:03.299><c> now</c><00:19:03.450><c> trying</c>

00:19:03.739 --> 00:19:03.749 align:start position:0%
of minimizing the loss we're now trying
 

00:19:03.749 --> 00:19:06.349 align:start position:0%
of minimizing the loss we're now trying
to<00:19:03.869><c> increase</c><00:19:04.320><c> the</c><00:19:04.529><c> loss</c><00:19:04.710><c> to</c><00:19:05.190><c> try</c><00:19:05.429><c> to</c><00:19:05.489><c> fool</c><00:19:05.999><c> our</c>

00:19:06.349 --> 00:19:06.359 align:start position:0%
to increase the loss to try to fool our
 

00:19:06.359 --> 00:19:08.989 align:start position:0%
to increase the loss to try to fool our
network<00:19:07.109><c> into</c><00:19:07.649><c> making</c><00:19:08.340><c> incorrect</c>

00:19:08.989 --> 00:19:08.999 align:start position:0%
network into making incorrect
 

00:19:08.999 --> 00:19:12.289 align:start position:0%
network into making incorrect
predictions<00:19:09.570><c> and</c><00:19:10.249><c> an</c><00:19:11.249><c> extension</c><00:19:11.940><c> of</c><00:19:12.179><c> this</c>

00:19:12.289 --> 00:19:12.299 align:start position:0%
predictions and an extension of this
 

00:19:12.299 --> 00:19:14.810 align:start position:0%
predictions and an extension of this
idea<00:19:12.509><c> was</c><00:19:13.049><c> recently</c><00:19:13.499><c> presented</c><00:19:13.799><c> by</c><00:19:14.369><c> a</c><00:19:14.399><c> group</c>

00:19:14.810 --> 00:19:14.820 align:start position:0%
idea was recently presented by a group
 

00:19:14.820 --> 00:19:17.960 align:start position:0%
idea was recently presented by a group
of<00:19:14.940><c> students</c><00:19:15.419><c> here</c><00:19:15.600><c> at</c><00:19:15.720><c> MIT</c><00:19:15.989><c> and</c><00:19:16.609><c> they</c><00:19:17.609><c> devised</c>

00:19:17.960 --> 00:19:17.970 align:start position:0%
of students here at MIT and they devised
 

00:19:17.970 --> 00:19:21.349 align:start position:0%
of students here at MIT and they devised
an<00:19:18.299><c> algorithm</c><00:19:18.809><c> for</c><00:19:19.220><c> synthesizing</c><00:19:20.220><c> a</c><00:19:20.759><c> set</c><00:19:21.119><c> of</c>

00:19:21.349 --> 00:19:21.359 align:start position:0%
an algorithm for synthesizing a set of
 

00:19:21.359 --> 00:19:24.830 align:start position:0%
an algorithm for synthesizing a set of
examples<00:19:22.200><c> that</c><00:19:22.649><c> would</c><00:19:23.039><c> be</c><00:19:23.190><c> adversarial</c><00:19:23.999><c> over</c>

00:19:24.830 --> 00:19:24.840 align:start position:0%
examples that would be adversarial over
 

00:19:24.840 --> 00:19:28.009 align:start position:0%
examples that would be adversarial over
a<00:19:25.700><c> diverse</c><00:19:26.700><c> set</c><00:19:26.940><c> of</c><00:19:27.059><c> transformations</c><00:19:27.809><c> like</c>

00:19:28.009 --> 00:19:28.019 align:start position:0%
a diverse set of transformations like
 

00:19:28.019 --> 00:19:31.070 align:start position:0%
a diverse set of transformations like
rotations<00:19:28.769><c> or</c><00:19:29.009><c> color</c><00:19:29.489><c> changes</c><00:19:29.970><c> and</c><00:19:30.179><c> so</c><00:19:30.960><c> the</c>

00:19:31.070 --> 00:19:31.080 align:start position:0%
rotations or color changes and so the
 

00:19:31.080 --> 00:19:32.599 align:start position:0%
rotations or color changes and so the
first<00:19:31.230><c> thing</c><00:19:31.379><c> that</c><00:19:31.499><c> they</c><00:19:31.710><c> demonstrated</c><00:19:32.309><c> was</c>

00:19:32.599 --> 00:19:32.609 align:start position:0%
first thing that they demonstrated was
 

00:19:32.609 --> 00:19:34.759 align:start position:0%
first thing that they demonstrated was
that<00:19:32.639><c> they</c><00:19:33.059><c> were</c><00:19:33.119><c> able</c><00:19:33.389><c> to</c><00:19:33.570><c> generate</c><00:19:34.200><c> 2d</c>

00:19:34.759 --> 00:19:34.769 align:start position:0%
that they were able to generate 2d
 

00:19:34.769 --> 00:19:38.389 align:start position:0%
that they were able to generate 2d
images<00:19:35.600><c> that</c><00:19:36.600><c> were</c><00:19:36.749><c> robust</c><00:19:37.200><c> to</c><00:19:37.559><c> noise</c>

00:19:38.389 --> 00:19:38.399 align:start position:0%
images that were robust to noise
 

00:19:38.399 --> 00:19:40.729 align:start position:0%
images that were robust to noise
transformations<00:19:39.350><c> distortions</c><00:19:40.350><c> other</c>

00:19:40.729 --> 00:19:40.739 align:start position:0%
transformations distortions other
 

00:19:40.739 --> 00:19:43.220 align:start position:0%
transformations distortions other
transformations<00:19:41.869><c> but</c><00:19:42.869><c> what</c><00:19:43.080><c> was</c><00:19:43.200><c> really</c>

00:19:43.220 --> 00:19:43.230 align:start position:0%
transformations but what was really
 

00:19:43.230 --> 00:19:44.239 align:start position:0%
transformations but what was really
really<00:19:43.710><c> cool</c>

00:19:44.239 --> 00:19:44.249 align:start position:0%
really cool
 

00:19:44.249 --> 00:19:46.220 align:start position:0%
really cool
was<00:19:44.700><c> that</c><00:19:44.879><c> they</c><00:19:45.029><c> actually</c><00:19:45.179><c> showed</c><00:19:45.809><c> that</c><00:19:45.840><c> they</c>

00:19:46.220 --> 00:19:46.230 align:start position:0%
was that they actually showed that they
 

00:19:46.230 --> 00:19:49.549 align:start position:0%
was that they actually showed that they
could<00:19:46.289><c> extend</c><00:19:47.129><c> this</c><00:19:47.309><c> idea</c><00:19:47.549><c> to</c><00:19:47.850><c> 3d</c><00:19:48.539><c> objects</c><00:19:49.379><c> and</c>

00:19:49.549 --> 00:19:49.559 align:start position:0%
could extend this idea to 3d objects and
 

00:19:49.559 --> 00:19:51.979 align:start position:0%
could extend this idea to 3d objects and
they<00:19:50.070><c> actually</c><00:19:50.249><c> used</c><00:19:50.700><c> 3d</c><00:19:51.179><c> printing</c><00:19:51.659><c> to</c><00:19:51.960><c> create</c>

00:19:51.979 --> 00:19:51.989 align:start position:0%
they actually used 3d printing to create
 

00:19:51.989 --> 00:19:55.310 align:start position:0%
they actually used 3d printing to create
actual<00:19:52.859><c> physical</c><00:19:53.759><c> adversarial</c><00:19:54.629><c> objects</c><00:19:55.109><c> and</c>

00:19:55.310 --> 00:19:55.320 align:start position:0%
actual physical adversarial objects and
 

00:19:55.320 --> 00:19:58.440 align:start position:0%
actual physical adversarial objects and
this<00:19:56.009><c> was</c><00:19:56.220><c> the</c><00:19:56.369><c> first</c><00:19:56.519><c> demonstration</c><00:19:56.789><c> of</c>

00:19:58.440 --> 00:19:58.450 align:start position:0%
this was the first demonstration of
 

00:19:58.450 --> 00:20:01.230 align:start position:0%
this was the first demonstration of
Rosario<00:19:58.930><c> examples</c><00:19:59.560><c> that</c><00:19:59.830><c> exist</c><00:20:00.700><c> in</c><00:20:00.970><c> the</c>

00:20:01.230 --> 00:20:01.240 align:start position:0%
Rosario examples that exist in the
 

00:20:01.240 --> 00:20:04.980 align:start position:0%
Rosario examples that exist in the
physical<00:20:01.390><c> world</c><00:20:01.690><c> so</c><00:20:03.120><c> what</c><00:20:04.120><c> they</c><00:20:04.240><c> did</c><00:20:04.420><c> in</c><00:20:04.720><c> in</c>

00:20:04.980 --> 00:20:04.990 align:start position:0%
physical world so what they did in in
 

00:20:04.990 --> 00:20:07.920 align:start position:0%
physical world so what they did in in
this<00:20:05.200><c> result</c><00:20:05.590><c> shown</c><00:20:05.800><c> here</c><00:20:06.130><c> is</c><00:20:06.310><c> that</c><00:20:06.520><c> they</c><00:20:06.930><c> 3d</c>

00:20:07.920 --> 00:20:07.930 align:start position:0%
this result shown here is that they 3d
 

00:20:07.930 --> 00:20:11.460 align:start position:0%
this result shown here is that they 3d
printed<00:20:08.410><c> a</c><00:20:08.560><c> set</c><00:20:08.890><c> of</c><00:20:09.130><c> turtles</c><00:20:10.000><c> that</c><00:20:10.470><c> were</c>

00:20:11.460 --> 00:20:11.470 align:start position:0%
printed a set of turtles that were
 

00:20:11.470 --> 00:20:14.910 align:start position:0%
printed a set of turtles that were
designed<00:20:11.950><c> to</c><00:20:12.160><c> be</c><00:20:12.300><c> adversarial</c><00:20:13.300><c> to</c><00:20:13.690><c> a</c><00:20:13.800><c> you</c><00:20:14.800><c> know</c>

00:20:14.910 --> 00:20:14.920 align:start position:0%
designed to be adversarial to a you know
 

00:20:14.920 --> 00:20:18.480 align:start position:0%
designed to be adversarial to a you know
a<00:20:14.950><c> given</c><00:20:15.370><c> network</c><00:20:15.730><c> and</c><00:20:16.530><c> took</c><00:20:17.530><c> images</c><00:20:17.710><c> of</c><00:20:18.220><c> those</c>

00:20:18.480 --> 00:20:18.490 align:start position:0%
a given network and took images of those
 

00:20:18.490 --> 00:20:22.830 align:start position:0%
a given network and took images of those
of<00:20:19.210><c> those</c><00:20:20.140><c> turtles</c><00:20:20.590><c> and</c><00:20:20.830><c> fed</c><00:20:21.100><c> them</c><00:20:21.250><c> in</c><00:20:21.840><c> through</c>

00:20:22.830 --> 00:20:22.840 align:start position:0%
of those turtles and fed them in through
 

00:20:22.840 --> 00:20:25.500 align:start position:0%
of those turtles and fed them in through
the<00:20:22.990><c> network</c><00:20:23.320><c> and</c><00:20:23.610><c> in</c><00:20:24.610><c> the</c><00:20:24.700><c> majority</c><00:20:25.210><c> of</c><00:20:25.240><c> cases</c>

00:20:25.500 --> 00:20:25.510 align:start position:0%
the network and in the majority of cases
 

00:20:25.510 --> 00:20:29.940 align:start position:0%
the network and in the majority of cases
right<00:20:26.380><c> the</c><00:20:26.980><c> network</c><00:20:27.340><c> classifies</c><00:20:28.210><c> these</c><00:20:28.950><c> 3d</c>

00:20:29.940 --> 00:20:29.950 align:start position:0%
right the network classifies these 3d
 

00:20:29.950 --> 00:20:34.020 align:start position:0%
right the network classifies these 3d
turtles<00:20:30.430><c> as</c><00:20:30.640><c> rifles</c><00:20:31.540><c> right</c><00:20:32.410><c> and</c><00:20:32.650><c> these</c><00:20:33.030><c> these</c>

00:20:34.020 --> 00:20:34.030 align:start position:0%
turtles as rifles right and these these
 

00:20:34.030 --> 00:20:37.170 align:start position:0%
turtles as rifles right and these these
objects<00:20:35.020><c> are</c><00:20:35.140><c> designed</c><00:20:35.980><c> to</c><00:20:36.190><c> be</c><00:20:36.490><c> adversarial</c>

00:20:37.170 --> 00:20:37.180 align:start position:0%
objects are designed to be adversarial
 

00:20:37.180 --> 00:20:40.200 align:start position:0%
objects are designed to be adversarial
they're<00:20:37.420><c> designed</c><00:20:37.810><c> to</c><00:20:38.110><c> fool</c><00:20:38.470><c> the</c><00:20:38.650><c> network</c><00:20:39.210><c> so</c>

00:20:40.200 --> 00:20:40.210 align:start position:0%
they're designed to fool the network so
 

00:20:40.210 --> 00:20:42.690 align:start position:0%
they're designed to fool the network so
this<00:20:40.360><c> is</c><00:20:40.510><c> pretty</c><00:20:40.720><c> scary</c><00:20:41.350><c> right</c><00:20:41.680><c> and</c><00:20:42.070><c> you</c><00:20:42.580><c> know</c>

00:20:42.690 --> 00:20:42.700 align:start position:0%
this is pretty scary right and you know
 

00:20:42.700 --> 00:20:46.350 align:start position:0%
this is pretty scary right and you know
it<00:20:42.970><c> opens</c><00:20:43.360><c> a</c><00:20:43.450><c> whole</c><00:20:43.480><c> Pandora's</c><00:20:44.230><c> box</c><00:20:44.530><c> of</c><00:20:45.360><c> how</c>

00:20:46.350 --> 00:20:46.360 align:start position:0%
it opens a whole Pandora's box of how
 

00:20:46.360 --> 00:20:49.170 align:start position:0%
it opens a whole Pandora's box of how
can<00:20:46.660><c> we</c><00:20:46.810><c> trick</c><00:20:47.110><c> networks</c><00:20:47.620><c> and</c><00:20:47.890><c> and</c><00:20:48.160><c> has</c><00:20:48.730><c> some</c>

00:20:49.170 --> 00:20:49.180 align:start position:0%
can we trick networks and and has some
 

00:20:49.180 --> 00:20:51.090 align:start position:0%
can we trick networks and and has some
pretty<00:20:49.540><c> severe</c><00:20:49.990><c> implications</c><00:20:50.800><c> for</c><00:20:50.950><c> things</c>

00:20:51.090 --> 00:20:51.100 align:start position:0%
pretty severe implications for things
 

00:20:51.100 --> 00:20:54.300 align:start position:0%
pretty severe implications for things
like<00:20:51.250><c> security</c><00:20:51.610><c> and</c><00:20:52.320><c> so</c><00:20:53.320><c> these</c><00:20:53.710><c> are</c><00:20:53.920><c> just</c><00:20:54.160><c> a</c>

00:20:54.300 --> 00:20:54.310 align:start position:0%
like security and so these are just a
 

00:20:54.310 --> 00:20:56.760 align:start position:0%
like security and so these are just a
couple<00:20:54.340><c> of</c><00:20:54.940><c> limitations</c><00:20:55.720><c> that</c><00:20:55.900><c> of</c><00:20:56.200><c> neural</c>

00:20:56.760 --> 00:20:56.770 align:start position:0%
couple of limitations that of neural
 

00:20:56.770 --> 00:20:59.280 align:start position:0%
couple of limitations that of neural
networks<00:20:57.130><c> that</c><00:20:57.280><c> I've</c><00:20:57.700><c> highlighted</c><00:20:58.030><c> here</c><00:20:58.360><c> you</c>

00:20:59.280 --> 00:20:59.290 align:start position:0%
networks that I've highlighted here you
 

00:20:59.290 --> 00:21:01.440 align:start position:0%
networks that I've highlighted here you
know<00:20:59.440><c> as</c><00:20:59.680><c> we've</c><00:21:00.160><c> sort</c><00:21:00.430><c> of</c><00:21:00.520><c> touched</c><00:21:01.240><c> on</c>

00:21:01.440 --> 00:21:01.450 align:start position:0%
know as we've sort of touched on
 

00:21:01.450 --> 00:21:03.660 align:start position:0%
know as we've sort of touched on
throughout<00:21:01.900><c> this</c><00:21:02.050><c> course</c><00:21:02.350><c> they're</c><00:21:02.920><c> very</c><00:21:03.400><c> data</c>

00:21:03.660 --> 00:21:03.670 align:start position:0%
throughout this course they're very data
 

00:21:03.670 --> 00:21:06.510 align:start position:0%
throughout this course they're very data
hungry<00:21:04.180><c> it's</c><00:21:04.720><c> computationally</c><00:21:05.370><c> intensive</c><00:21:06.370><c> to</c>

00:21:06.510 --> 00:21:06.520 align:start position:0%
hungry it's computationally intensive to
 

00:21:06.520 --> 00:21:08.400 align:start position:0%
hungry it's computationally intensive to
train<00:21:06.760><c> them</c><00:21:06.970><c> they</c><00:21:07.510><c> can</c><00:21:07.690><c> be</c><00:21:07.840><c> fooled</c><00:21:08.110><c> by</c>

00:21:08.400 --> 00:21:08.410 align:start position:0%
train them they can be fooled by
 

00:21:08.410 --> 00:21:11.700 align:start position:0%
train them they can be fooled by
adversarial<00:21:09.240><c> examples</c><00:21:10.240><c> they</c><00:21:10.960><c> can</c><00:21:11.110><c> be</c><00:21:11.230><c> subject</c>

00:21:11.700 --> 00:21:11.710 align:start position:0%
adversarial examples they can be subject
 

00:21:11.710 --> 00:21:15.270 align:start position:0%
adversarial examples they can be subject
to<00:21:11.770><c> algorithmic</c><00:21:12.520><c> bias</c><00:21:13.260><c> they're</c><00:21:14.280><c> relatively</c>

00:21:15.270 --> 00:21:15.280 align:start position:0%
to algorithmic bias they're relatively
 

00:21:15.280 --> 00:21:19.350 align:start position:0%
to algorithmic bias they're relatively
poor<00:21:15.580><c> at</c><00:21:15.910><c> representing</c><00:21:16.770><c> uncertainty</c><00:21:18.330><c> then</c><00:21:19.330><c> a</c>

00:21:19.350 --> 00:21:19.360 align:start position:0%
poor at representing uncertainty then a
 

00:21:19.360 --> 00:21:21.480 align:start position:0%
poor at representing uncertainty then a
big<00:21:19.720><c> point</c><00:21:20.020><c> is</c><00:21:20.260><c> this</c><00:21:20.410><c> this</c><00:21:20.860><c> question</c><00:21:21.310><c> of</c>

00:21:21.480 --> 00:21:21.490 align:start position:0%
big point is this this question of
 

00:21:21.490 --> 00:21:23.730 align:start position:0%
big point is this this question of
interpretability<00:21:22.480><c> right</c><00:21:23.050><c> are</c><00:21:23.260><c> known</c>

00:21:23.730 --> 00:21:23.740 align:start position:0%
interpretability right are known
 

00:21:23.740 --> 00:21:25.800 align:start position:0%
interpretability right are known
networks<00:21:24.130><c> just</c><00:21:24.430><c> black</c><00:21:24.670><c> boxes</c><00:21:25.240><c> that</c><00:21:25.270><c> you</c><00:21:25.450><c> can't</c>

00:21:25.800 --> 00:21:25.810 align:start position:0%
networks just black boxes that you can't
 

00:21:25.810 --> 00:21:31.050 align:start position:0%
networks just black boxes that you can't
peer<00:21:26.380><c> into</c><00:21:26.770><c> and</c><00:21:27.630><c> sort</c><00:21:28.630><c> of</c><00:21:28.750><c> in</c><00:21:28.990><c> the</c><00:21:29.560><c> ml</c><00:21:30.490><c> and</c><00:21:30.820><c> AI</c>

00:21:31.050 --> 00:21:31.060 align:start position:0%
peer into and sort of in the ml and AI
 

00:21:31.060 --> 00:21:34.860 align:start position:0%
peer into and sort of in the ml and AI
community<00:21:31.980><c> people</c><00:21:32.980><c> tend</c><00:21:33.370><c> to</c><00:21:33.460><c> fall</c><00:21:34.060><c> you</c><00:21:34.750><c> know</c>

00:21:34.860 --> 00:21:34.870 align:start position:0%
community people tend to fall you know
 

00:21:34.870 --> 00:21:37.230 align:start position:0%
community people tend to fall you know
in<00:21:35.110><c> sort</c><00:21:35.290><c> of</c><00:21:35.410><c> two</c><00:21:35.650><c> camps</c><00:21:35.920><c> one</c><00:21:36.700><c> camp</c><00:21:37.000><c> saying</c>

00:21:37.230 --> 00:21:37.240 align:start position:0%
in sort of two camps one camp saying
 

00:21:37.240 --> 00:21:39.600 align:start position:0%
in sort of two camps one camp saying
interpret<00:21:37.870><c> interpret</c><00:21:38.680><c> ability</c><00:21:39.250><c> of</c><00:21:39.340><c> neural</c>

00:21:39.600 --> 00:21:39.610 align:start position:0%
interpret interpret ability of neural
 

00:21:39.610 --> 00:21:41.700 align:start position:0%
interpret interpret ability of neural
networks<00:21:39.940><c> matters</c><00:21:40.330><c> a</c><00:21:40.360><c> lot</c><00:21:40.630><c> it's</c><00:21:40.960><c> something</c>

00:21:41.700 --> 00:21:41.710 align:start position:0%
networks matters a lot it's something
 

00:21:41.710 --> 00:21:43.470 align:start position:0%
networks matters a lot it's something
that<00:21:41.860><c> we</c><00:21:41.980><c> should</c><00:21:42.160><c> devote</c><00:21:42.430><c> a</c><00:21:42.490><c> lot</c><00:21:42.700><c> of</c><00:21:42.760><c> energy</c>

00:21:43.470 --> 00:21:43.480 align:start position:0%
that we should devote a lot of energy
 

00:21:43.480 --> 00:21:46.380 align:start position:0%
that we should devote a lot of energy
and<00:21:43.720><c> thought</c><00:21:44.200><c> into</c><00:21:44.410><c> and</c><00:21:44.800><c> others</c><00:21:45.460><c> that</c><00:21:45.850><c> very</c>

00:21:46.380 --> 00:21:46.390 align:start position:0%
and thought into and others that very
 

00:21:46.390 --> 00:21:48.450 align:start position:0%
and thought into and others that very
strongly<00:21:46.930><c> argue</c><00:21:47.380><c> that</c><00:21:47.530><c> oh</c><00:21:47.740><c> no</c><00:21:47.800><c> we</c><00:21:48.280><c> should</c><00:21:48.430><c> not</c>

00:21:48.450 --> 00:21:48.460 align:start position:0%
strongly argue that oh no we should not
 

00:21:48.460 --> 00:21:49.920 align:start position:0%
strongly argue that oh no we should not
really<00:21:49.060><c> concern</c><00:21:49.420><c> ourselves</c><00:21:49.600><c> with</c>

00:21:49.920 --> 00:21:49.930 align:start position:0%
really concern ourselves with
 

00:21:49.930 --> 00:21:52.380 align:start position:0%
really concern ourselves with
interpretability<00:21:50.700><c> what's</c><00:21:51.700><c> more</c><00:21:51.940><c> important</c>

00:21:52.380 --> 00:21:52.390 align:start position:0%
interpretability what's more important
 

00:21:52.390 --> 00:21:55.560 align:start position:0%
interpretability what's more important
is<00:21:52.600><c> you</c><00:21:53.140><c> know</c><00:21:54.450><c> generating</c><00:21:55.450><c> these</c>

00:21:55.560 --> 00:21:55.570 align:start position:0%
is you know generating these
 

00:21:55.570 --> 00:21:57.480 align:start position:0%
is you know generating these
architectures<00:21:56.260><c> that</c><00:21:56.440><c> perform</c><00:21:56.800><c> really</c><00:21:57.190><c> really</c>

00:21:57.480 --> 00:21:57.490 align:start position:0%
architectures that perform really really
 

00:21:57.490 --> 00:22:02.880 align:start position:0%
architectures that perform really really
well<00:21:57.700><c> on</c><00:21:57.940><c> a</c><00:21:58.540><c> task</c><00:21:58.870><c> of</c><00:21:59.110><c> interest</c><00:21:59.530><c> and</c><00:22:01.230><c> in</c><00:22:02.230><c> going</c>

00:22:02.880 --> 00:22:02.890 align:start position:0%
well on a task of interest and in going
 

00:22:02.890 --> 00:22:05.160 align:start position:0%
well on a task of interest and in going
from<00:22:03.190><c> limitations</c><00:22:04.060><c> to</c><00:22:04.300><c> sort</c><00:22:04.540><c> of</c><00:22:04.630><c> new</c>

00:22:05.160 --> 00:22:05.170 align:start position:0%
from limitations to sort of new
 

00:22:05.170 --> 00:22:07.590 align:start position:0%
from limitations to sort of new
frontiers<00:22:05.440><c> in</c><00:22:06.010><c> emerging</c><00:22:06.520><c> areas</c><00:22:06.910><c> in</c><00:22:07.120><c> deep</c>

00:22:07.590 --> 00:22:07.600 align:start position:0%
frontiers in emerging areas in deep
 

00:22:07.600 --> 00:22:09.690 align:start position:0%
frontiers in emerging areas in deep
learning<00:22:07.780><c> research</c><00:22:08.320><c> I</c><00:22:08.560><c> like</c><00:22:09.040><c> to</c><00:22:09.160><c> focus</c><00:22:09.490><c> on</c>

00:22:09.690 --> 00:22:09.700 align:start position:0%
learning research I like to focus on
 

00:22:09.700 --> 00:22:12.130 align:start position:0%
learning research I like to focus on
these<00:22:10.390><c> two</c><00:22:10.840><c> sort</c><00:22:11.440><c> of</c>

00:22:12.130 --> 00:22:12.140 align:start position:0%
these two sort of
 

00:22:12.140 --> 00:22:14.740 align:start position:0%
these two sort of
of<00:22:12.320><c> points</c><00:22:12.650><c> highlighted</c><00:22:12.860><c> here</c><00:22:13.490><c> the</c><00:22:14.270><c> first</c><00:22:14.540><c> is</c>

00:22:14.740 --> 00:22:14.750 align:start position:0%
of points highlighted here the first is
 

00:22:14.750 --> 00:22:17.190 align:start position:0%
of points highlighted here the first is
the<00:22:14.960><c> notion</c><00:22:15.290><c> of</c><00:22:15.500><c> understanding</c><00:22:16.030><c> uncertainty</c>

00:22:17.190 --> 00:22:17.200 align:start position:0%
the notion of understanding uncertainty
 

00:22:17.200 --> 00:22:21.100 align:start position:0%
the notion of understanding uncertainty
and<00:22:18.200><c> the</c><00:22:19.130><c> second</c><00:22:19.520><c> is</c><00:22:19.700><c> ways</c><00:22:20.300><c> in</c><00:22:20.600><c> which</c><00:22:20.720><c> we</c><00:22:20.960><c> can</c>

00:22:21.100 --> 00:22:21.110 align:start position:0%
and the second is ways in which we can
 

00:22:21.110 --> 00:22:25.920 align:start position:0%
and the second is ways in which we can
move<00:22:21.490><c> past</c><00:22:23.470><c> building</c><00:22:24.470><c> models</c><00:22:24.860><c> that</c><00:22:25.130><c> are</c>

00:22:25.920 --> 00:22:25.930 align:start position:0%
move past building models that are
 

00:22:25.930 --> 00:22:29.350 align:start position:0%
move past building models that are
optimized<00:22:26.930><c> for</c><00:22:27.140><c> a</c><00:22:27.170><c> single</c><00:22:27.560><c> task</c><00:22:27.790><c> to</c><00:22:28.790><c> actually</c>

00:22:29.350 --> 00:22:29.360 align:start position:0%
optimized for a single task to actually
 

00:22:29.360 --> 00:22:32.350 align:start position:0%
optimized for a single task to actually
learning<00:22:29.840><c> how</c><00:22:30.020><c> to</c><00:22:30.050><c> build</c><00:22:30.320><c> a</c><00:22:30.500><c> model</c><00:22:30.860><c> capable</c><00:22:31.850><c> of</c>

00:22:32.350 --> 00:22:32.360 align:start position:0%
learning how to build a model capable of
 

00:22:32.360 --> 00:22:34.660 align:start position:0%
learning how to build a model capable of
solving<00:22:32.660><c> not</c><00:22:32.960><c> one</c><00:22:33.200><c> but</c><00:22:33.860><c> many</c><00:22:34.070><c> different</c>

00:22:34.660 --> 00:22:34.670 align:start position:0%
solving not one but many different
 

00:22:34.670 --> 00:22:37.600 align:start position:0%
solving not one but many different
problems<00:22:35.590><c> so</c><00:22:36.590><c> the</c><00:22:36.770><c> first</c><00:22:36.980><c> sort</c><00:22:37.370><c> of</c><00:22:37.490><c> new</c>

00:22:37.600 --> 00:22:37.610 align:start position:0%
problems so the first sort of new
 

00:22:37.610 --> 00:22:39.700 align:start position:0%
problems so the first sort of new
frontier<00:22:38.090><c> is</c><00:22:38.240><c> this</c><00:22:38.780><c> field</c><00:22:39.020><c> called</c><00:22:39.350><c> Bayesian</c>

00:22:39.700 --> 00:22:39.710 align:start position:0%
frontier is this field called Bayesian
 

00:22:39.710 --> 00:22:42.160 align:start position:0%
frontier is this field called Bayesian
deep<00:22:40.250><c> learning</c><00:22:40.430><c> and</c><00:22:40.820><c> so</c><00:22:41.630><c> if</c><00:22:41.840><c> we</c><00:22:41.960><c> consider</c>

00:22:42.160 --> 00:22:42.170 align:start position:0%
deep learning and so if we consider
 

00:22:42.170 --> 00:22:44.290 align:start position:0%
deep learning and so if we consider
again<00:22:42.770><c> right</c><00:22:43.010><c> the</c><00:22:43.280><c> very</c><00:22:43.400><c> simple</c><00:22:43.850><c> problem</c><00:22:43.880><c> of</c>

00:22:44.290 --> 00:22:44.300 align:start position:0%
again right the very simple problem of
 

00:22:44.300 --> 00:22:47.080 align:start position:0%
again right the very simple problem of
image<00:22:44.930><c> classification</c><00:22:45.740><c> what</c><00:22:46.670><c> we've</c><00:22:46.850><c> learned</c>

00:22:47.080 --> 00:22:47.090 align:start position:0%
image classification what we've learned
 

00:22:47.090 --> 00:22:49.210 align:start position:0%
image classification what we've learned
so<00:22:47.300><c> far</c><00:22:47.330><c> is</c><00:22:47.810><c> has</c><00:22:48.320><c> been</c><00:22:48.500><c> about</c><00:22:48.680><c> modeling</c>

00:22:49.210 --> 00:22:49.220 align:start position:0%
so far is has been about modeling
 

00:22:49.220 --> 00:22:51.670 align:start position:0%
so far is has been about modeling
probabilities<00:22:50.090><c> over</c><00:22:50.120><c> a</c><00:22:50.540><c> fixed</c><00:22:50.930><c> number</c><00:22:51.290><c> of</c>

00:22:51.670 --> 00:22:51.680 align:start position:0%
probabilities over a fixed number of
 

00:22:51.680 --> 00:22:55.150 align:start position:0%
probabilities over a fixed number of
classes<00:22:52.390><c> so</c><00:22:53.390><c> if</c><00:22:53.570><c> if</c><00:22:53.870><c> we</c><00:22:54.140><c> are</c><00:22:54.170><c> to</c><00:22:54.560><c> train</c><00:22:54.860><c> a</c><00:22:54.890><c> model</c>

00:22:55.150 --> 00:22:55.160 align:start position:0%
classes so if if we are to train a model
 

00:22:55.160 --> 00:22:58.420 align:start position:0%
classes so if if we are to train a model
to<00:22:55.640><c> predict</c><00:22:56.000><c> you</c><00:22:56.570><c> know</c><00:22:56.600><c> dogs</c><00:22:56.990><c> versus</c><00:22:57.410><c> cats</c><00:22:57.650><c> we</c>

00:22:58.420 --> 00:22:58.430 align:start position:0%
to predict you know dogs versus cats we
 

00:22:58.430 --> 00:23:00.610 align:start position:0%
to predict you know dogs versus cats we
output<00:22:58.850><c> some</c><00:22:59.060><c> probability</c><00:22:59.870><c> that</c><00:22:59.900><c> an</c><00:23:00.200><c> input</c>

00:23:00.610 --> 00:23:00.620 align:start position:0%
output some probability that an input
 

00:23:00.620 --> 00:23:05.440 align:start position:0%
output some probability that an input
image<00:23:00.800><c> is</c><00:23:01.130><c> either</c><00:23:01.370><c> a</c><00:23:01.700><c> dog</c><00:23:02.180><c> or</c><00:23:02.450><c> a</c><00:23:02.570><c> cat</c><00:23:04.060><c> but</c><00:23:05.060><c> I'd</c>

00:23:05.440 --> 00:23:05.450 align:start position:0%
image is either a dog or a cat but I'd
 

00:23:05.450 --> 00:23:07.510 align:start position:0%
image is either a dog or a cat but I'd
like<00:23:05.600><c> to</c><00:23:05.660><c> draw</c><00:23:06.020><c> a</c><00:23:06.290><c> distinction</c><00:23:06.800><c> between</c><00:23:07.010><c> a</c>

00:23:07.510 --> 00:23:07.520 align:start position:0%
like to draw a distinction between a
 

00:23:07.520 --> 00:23:10.510 align:start position:0%
like to draw a distinction between a
probability<00:23:08.180><c> and</c><00:23:09.010><c> this</c><00:23:10.010><c> notion</c><00:23:10.280><c> of</c>

00:23:10.510 --> 00:23:10.520 align:start position:0%
probability and this notion of
 

00:23:10.520 --> 00:23:13.270 align:start position:0%
probability and this notion of
uncertainty<00:23:11.210><c> or</c><00:23:11.330><c> confidence</c><00:23:11.900><c> so</c><00:23:12.800><c> if</c><00:23:12.980><c> we</c><00:23:13.130><c> were</c>

00:23:13.270 --> 00:23:13.280 align:start position:0%
uncertainty or confidence so if we were
 

00:23:13.280 --> 00:23:15.610 align:start position:0%
uncertainty or confidence so if we were
to<00:23:13.610><c> feed</c><00:23:13.850><c> in</c><00:23:13.970><c> in</c><00:23:14.210><c> the</c><00:23:14.300><c> image</c><00:23:14.570><c> of</c><00:23:14.750><c> a</c><00:23:14.840><c> horse</c><00:23:15.140><c> into</c>

00:23:15.610 --> 00:23:15.620 align:start position:0%
to feed in in the image of a horse into
 

00:23:15.620 --> 00:23:17.860 align:start position:0%
to feed in in the image of a horse into
this<00:23:15.740><c> network</c><00:23:16.010><c> for</c><00:23:16.310><c> example</c><00:23:16.480><c> we</c><00:23:17.480><c> would</c><00:23:17.600><c> still</c>

00:23:17.860 --> 00:23:17.870 align:start position:0%
this network for example we would still
 

00:23:17.870 --> 00:23:21.030 align:start position:0%
this network for example we would still
output<00:23:18.290><c> a</c><00:23:18.320><c> probability</c><00:23:19.040><c> of</c><00:23:19.160><c> being</c><00:23:19.400><c> dog</c><00:23:19.910><c> or</c><00:23:20.180><c> cat</c>

00:23:21.030 --> 00:23:21.040 align:start position:0%
output a probability of being dog or cat
 

00:23:21.040 --> 00:23:23.890 align:start position:0%
output a probability of being dog or cat
because<00:23:22.040><c> right</c><00:23:22.520><c> probabilities</c><00:23:23.270><c> need</c><00:23:23.510><c> to</c><00:23:23.720><c> sum</c>

00:23:23.890 --> 00:23:23.900 align:start position:0%
because right probabilities need to sum
 

00:23:23.900 --> 00:23:27.340 align:start position:0%
because right probabilities need to sum
to<00:23:24.230><c> one</c><00:23:24.410><c> but</c><00:23:25.130><c> the</c><00:23:25.280><c> model</c><00:23:25.670><c> may</c><00:23:25.880><c> even</c><00:23:26.660><c> even</c><00:23:27.230><c> if</c>

00:23:27.340 --> 00:23:27.350 align:start position:0%
to one but the model may even even if
 

00:23:27.350 --> 00:23:29.080 align:start position:0%
to one but the model may even even if
it's<00:23:27.500><c> more</c><00:23:27.920><c> saying</c><00:23:28.280><c> that</c><00:23:28.490><c> it's</c><00:23:28.640><c> more</c><00:23:28.850><c> likely</c>

00:23:29.080 --> 00:23:29.090 align:start position:0%
it's more saying that it's more likely
 

00:23:29.090 --> 00:23:31.930 align:start position:0%
it's more saying that it's more likely
that<00:23:29.270><c> this</c><00:23:29.540><c> image</c><00:23:29.870><c> of</c><00:23:30.050><c> is</c><00:23:30.650><c> of</c><00:23:30.980><c> a</c><00:23:31.070><c> horse</c><00:23:31.370><c> it</c><00:23:31.670><c> may</c>

00:23:31.930 --> 00:23:31.940 align:start position:0%
that this image of is of a horse it may
 

00:23:31.940 --> 00:23:34.390 align:start position:0%
that this image of is of a horse it may
be<00:23:32.000><c> more</c><00:23:32.330><c> uncertain</c><00:23:33.200><c> in</c><00:23:33.440><c> terms</c><00:23:33.710><c> of</c><00:23:33.950><c> you</c><00:23:34.370><c> know</c>

00:23:34.390 --> 00:23:34.400 align:start position:0%
be more uncertain in terms of you know
 

00:23:34.400 --> 00:23:39.000 align:start position:0%
be more uncertain in terms of you know
its<00:23:35.150><c> confidence</c><00:23:35.810><c> in</c><00:23:36.050><c> that</c><00:23:36.230><c> prediction</c><00:23:36.680><c> and</c>

00:23:39.000 --> 00:23:39.010 align:start position:0%
its confidence in that prediction and
 

00:23:39.010 --> 00:23:41.530 align:start position:0%
its confidence in that prediction and
there's<00:23:40.010><c> this</c><00:23:40.160><c> whole</c><00:23:40.340><c> field</c><00:23:40.670><c> of</c><00:23:40.880><c> Bayesian</c>

00:23:41.530 --> 00:23:41.540 align:start position:0%
there's this whole field of Bayesian
 

00:23:41.540 --> 00:23:45.400 align:start position:0%
there's this whole field of Bayesian
deep<00:23:41.720><c> learning</c><00:23:41.930><c> that</c><00:23:42.530><c> looks</c><00:23:43.400><c> at</c><00:23:44.200><c> modeling</c><00:23:45.200><c> and</c>

00:23:45.400 --> 00:23:45.410 align:start position:0%
deep learning that looks at modeling and
 

00:23:45.410 --> 00:23:48.190 align:start position:0%
deep learning that looks at modeling and
understanding<00:23:46.360><c> uncertainty</c><00:23:47.360><c> in</c><00:23:47.630><c> deep</c><00:23:47.840><c> neural</c>

00:23:48.190 --> 00:23:48.200 align:start position:0%
understanding uncertainty in deep neural
 

00:23:48.200 --> 00:23:52.450 align:start position:0%
understanding uncertainty in deep neural
networks<00:23:48.680><c> and</c><00:23:50.560><c> sort</c><00:23:51.560><c> of</c><00:23:51.620><c> this</c><00:23:51.770><c> gets</c><00:23:52.160><c> into</c><00:23:52.430><c> a</c>

00:23:52.450 --> 00:23:52.460 align:start position:0%
networks and sort of this gets into a
 

00:23:52.460 --> 00:23:56.560 align:start position:0%
networks and sort of this gets into a
lot<00:23:52.670><c> of</c><00:23:52.850><c> of</c><00:23:53.440><c> statistics</c><00:23:54.440><c> but</c><00:23:54.740><c> the</c><00:23:55.730><c> key</c><00:23:55.970><c> idea</c><00:23:56.360><c> is</c>

00:23:56.560 --> 00:23:56.570 align:start position:0%
lot of of statistics but the key idea is
 

00:23:56.570 --> 00:23:59.080 align:start position:0%
lot of of statistics but the key idea is
that<00:23:56.750><c> Bayesian</c><00:23:57.470><c> neural</c><00:23:58.220><c> networks</c><00:23:58.550><c> are</c><00:23:58.730><c> trying</c>

00:23:59.080 --> 00:23:59.090 align:start position:0%
that Bayesian neural networks are trying
 

00:23:59.090 --> 00:24:01.540 align:start position:0%
that Bayesian neural networks are trying
to<00:23:59.330><c> rather</c><00:24:00.260><c> than</c><00:24:00.560><c> learn</c><00:24:00.770><c> a</c><00:24:00.800><c> set</c><00:24:01.220><c> of</c><00:24:01.310><c> weights</c>

00:24:01.540 --> 00:24:01.550 align:start position:0%
to rather than learn a set of weights
 

00:24:01.550 --> 00:24:04.210 align:start position:0%
to rather than learn a set of weights
they're<00:24:01.820><c> trying</c><00:24:02.090><c> to</c><00:24:02.210><c> learn</c><00:24:02.390><c> a</c><00:24:03.220><c> distribution</c>

00:24:04.210 --> 00:24:04.220 align:start position:0%
they're trying to learn a distribution
 

00:24:04.220 --> 00:24:07.210 align:start position:0%
they're trying to learn a distribution
over<00:24:04.490><c> the</c><00:24:05.360><c> possible</c><00:24:05.870><c> weights</c><00:24:06.110><c> right</c><00:24:06.710><c> given</c>

00:24:07.210 --> 00:24:07.220 align:start position:0%
over the possible weights right given
 

00:24:07.220 --> 00:24:13.570 align:start position:0%
over the possible weights right given
some<00:24:08.150><c> input</c><00:24:08.600><c> data</c><00:24:08.960><c> X</c><00:24:09.260><c> and</c><00:24:09.680><c> some</c><00:24:11.470><c> output</c><00:24:12.580><c> labels</c>

00:24:13.570 --> 00:24:13.580 align:start position:0%
some input data X and some output labels
 

00:24:13.580 --> 00:24:16.810 align:start position:0%
some input data X and some output labels
Y<00:24:13.820><c> and</c><00:24:14.510><c> to</c><00:24:15.440><c> actually</c><00:24:15.860><c> parameterize</c><00:24:16.550><c> this</c>

00:24:16.810 --> 00:24:16.820 align:start position:0%
Y and to actually parameterize this
 

00:24:16.820 --> 00:24:20.530 align:start position:0%
Y and to actually parameterize this
problem<00:24:17.330><c> they</c><00:24:17.870><c> use</c><00:24:18.640><c> Bayes</c><00:24:19.640><c> rule</c><00:24:19.670><c> which</c><00:24:20.180><c> is</c><00:24:20.210><c> a</c>

00:24:20.530 --> 00:24:20.540 align:start position:0%
problem they use Bayes rule which is a
 

00:24:20.540 --> 00:24:23.560 align:start position:0%
problem they use Bayes rule which is a
fundamental<00:24:21.230><c> you</c><00:24:22.070><c> know</c><00:24:22.100><c> law</c><00:24:22.790><c> from</c><00:24:23.210><c> from</c>

00:24:23.560 --> 00:24:23.570 align:start position:0%
fundamental you know law from from
 

00:24:23.570 --> 00:24:25.180 align:start position:0%
fundamental you know law from from
probability<00:24:23.990><c> theory</c>

00:24:25.180 --> 00:24:25.190 align:start position:0%
probability theory
 

00:24:25.190 --> 00:24:28.149 align:start position:0%
probability theory
but<00:24:25.369><c> in</c><00:24:25.669><c> practice</c><00:24:26.330><c> this</c><00:24:26.769><c> what's</c><00:24:27.769><c> called</c><00:24:28.039><c> this</c>

00:24:28.149 --> 00:24:28.159 align:start position:0%
but in practice this what's called this
 

00:24:28.159 --> 00:24:31.060 align:start position:0%
but in practice this what's called this
posterior<00:24:28.849><c> distribution</c><00:24:29.119><c> of</c><00:24:29.840><c> the</c><00:24:30.379><c> likelihood</c>

00:24:31.060 --> 00:24:31.070 align:start position:0%
posterior distribution of the likelihood
 

00:24:31.070 --> 00:24:35.109 align:start position:0%
posterior distribution of the likelihood
the<00:24:31.759><c> probe</c><00:24:32.389><c> a</c><00:24:32.570><c> set</c><00:24:32.779><c> of</c><00:24:32.869><c> weights</c><00:24:33.109><c> given</c><00:24:34.119><c> input</c>

00:24:35.109 --> 00:24:35.119 align:start position:0%
the probe a set of weights given input
 

00:24:35.119 --> 00:24:37.330 align:start position:0%
the probe a set of weights given input
and<00:24:35.269><c> output</c><00:24:35.690><c> is</c><00:24:36.340><c> computationally</c>

00:24:37.330 --> 00:24:37.340 align:start position:0%
and output is computationally
 

00:24:37.340 --> 00:24:41.440 align:start position:0%
and output is computationally
intractable<00:24:37.669><c> and</c><00:24:38.799><c> so</c><00:24:39.799><c> instead</c><00:24:40.399><c> of</c><00:24:40.519><c> we</c><00:24:41.179><c> can't</c>

00:24:41.440 --> 00:24:41.450 align:start position:0%
intractable and so instead of we can't
 

00:24:41.450 --> 00:24:43.599 align:start position:0%
intractable and so instead of we can't
learn<00:24:41.840><c> this</c><00:24:42.109><c> distribution</c><00:24:42.499><c> directly</c><00:24:43.249><c> so</c><00:24:43.429><c> what</c>

00:24:43.599 --> 00:24:43.609 align:start position:0%
learn this distribution directly so what
 

00:24:43.609 --> 00:24:47.080 align:start position:0%
learn this distribution directly so what
we<00:24:43.729><c> can</c><00:24:44.029><c> do</c><00:24:44.269><c> is</c><00:24:44.769><c> find</c><00:24:45.769><c> ways</c><00:24:46.009><c> to</c><00:24:46.090><c> approximate</c>

00:24:47.080 --> 00:24:47.090 align:start position:0%
we can do is find ways to approximate
 

00:24:47.090 --> 00:24:49.450 align:start position:0%
we can do is find ways to approximate
this<00:24:47.450><c> posterior</c><00:24:48.019><c> distribution</c><00:24:48.460><c> through</c>

00:24:49.450 --> 00:24:49.460 align:start position:0%
this posterior distribution through
 

00:24:49.460 --> 00:24:51.820 align:start position:0%
this posterior distribution through
different<00:24:50.149><c> types</c><00:24:50.359><c> of</c><00:24:50.539><c> sampling</c><00:24:51.109><c> operations</c>

00:24:51.820 --> 00:24:51.830 align:start position:0%
different types of sampling operations
 

00:24:51.830 --> 00:24:54.489 align:start position:0%
different types of sampling operations
and<00:24:52.099><c> one</c><00:24:52.970><c> example</c><00:24:53.539><c> of</c><00:24:53.749><c> such</c><00:24:54.049><c> a</c><00:24:54.080><c> sampling</c>

00:24:54.489 --> 00:24:54.499 align:start position:0%
and one example of such a sampling
 

00:24:54.499 --> 00:24:56.979 align:start position:0%
and one example of such a sampling
approach<00:24:54.679><c> is</c><00:24:55.249><c> to</c><00:24:55.519><c> use</c><00:24:55.549><c> the</c><00:24:56.330><c> principle</c><00:24:56.840><c> of</c>

00:24:56.979 --> 00:24:56.989 align:start position:0%
approach is to use the principle of
 

00:24:56.989 --> 00:24:59.680 align:start position:0%
approach is to use the principle of
dropout<00:24:57.470><c> which</c><00:24:57.919><c> was</c><00:24:58.460><c> introduced</c><00:24:58.970><c> in</c><00:24:59.210><c> the</c>

00:24:59.680 --> 00:24:59.690 align:start position:0%
dropout which was introduced in the
 

00:24:59.690 --> 00:25:01.839 align:start position:0%
dropout which was introduced in the
first<00:24:59.840><c> lecture</c><00:25:00.109><c> to</c><00:25:00.859><c> actually</c><00:25:01.220><c> obtain</c><00:25:01.609><c> an</c>

00:25:01.839 --> 00:25:01.849 align:start position:0%
first lecture to actually obtain an
 

00:25:01.849 --> 00:25:05.619 align:start position:0%
first lecture to actually obtain an
estimate<00:25:02.389><c> of</c><00:25:02.509><c> the</c><00:25:02.840><c> network's</c><00:25:03.169><c> uncertainty</c><00:25:04.629><c> so</c>

00:25:05.619 --> 00:25:05.629 align:start position:0%
estimate of the network's uncertainty so
 

00:25:05.629 --> 00:25:07.749 align:start position:0%
estimate of the network's uncertainty so
if<00:25:05.960><c> we</c><00:25:06.109><c> look</c><00:25:06.289><c> at</c><00:25:06.440><c> what</c><00:25:06.919><c> this</c><00:25:07.070><c> may</c><00:25:07.249><c> look</c><00:25:07.489><c> like</c>

00:25:07.749 --> 00:25:07.759 align:start position:0%
if we look at what this may look like
 

00:25:07.759 --> 00:25:10.629 align:start position:0%
if we look at what this may look like
for<00:25:08.450><c> a</c><00:25:08.479><c> network</c><00:25:08.869><c> that's</c><00:25:09.619><c> composed</c><00:25:10.279><c> of</c>

00:25:10.629 --> 00:25:10.639 align:start position:0%
for a network that's composed of
 

00:25:10.639 --> 00:25:14.919 align:start position:0%
for a network that's composed of
convolutional<00:25:11.509><c> layers</c><00:25:13.629><c> consisting</c><00:25:14.629><c> of</c><00:25:14.749><c> like</c>

00:25:14.919 --> 00:25:14.929 align:start position:0%
convolutional layers consisting of like
 

00:25:14.929 --> 00:25:18.999 align:start position:0%
convolutional layers consisting of like
two<00:25:15.229><c> dimensional</c><00:25:15.830><c> feature</c><00:25:16.099><c> Maps</c><00:25:16.479><c> what</c><00:25:17.710><c> how</c><00:25:18.710><c> we</c>

00:25:18.999 --> 00:25:19.009 align:start position:0%
two dimensional feature Maps what how we
 

00:25:19.009 --> 00:25:22.830 align:start position:0%
two dimensional feature Maps what how we
can<00:25:19.190><c> use</c><00:25:19.399><c> dropout</c><00:25:19.879><c> to</c><00:25:20.229><c> SMA</c><00:25:21.229><c> uncertainty</c><00:25:21.950><c> by</c>

00:25:22.830 --> 00:25:22.840 align:start position:0%
can use dropout to SMA uncertainty by
 

00:25:22.840 --> 00:25:26.379 align:start position:0%
can use dropout to SMA uncertainty by
performing<00:25:23.859><c> stochastic</c><00:25:24.859><c> passes</c><00:25:25.669><c> through</c><00:25:26.239><c> the</c>

00:25:26.379 --> 00:25:26.389 align:start position:0%
performing stochastic passes through the
 

00:25:26.389 --> 00:25:28.629 align:start position:0%
performing stochastic passes through the
network<00:25:26.749><c> and</c><00:25:27.019><c> each</c><00:25:27.590><c> time</c><00:25:27.889><c> we</c><00:25:28.070><c> make</c><00:25:28.279><c> a</c><00:25:28.340><c> pass</c>

00:25:28.629 --> 00:25:28.639 align:start position:0%
network and each time we make a pass
 

00:25:28.639 --> 00:25:32.019 align:start position:0%
network and each time we make a pass
through<00:25:28.879><c> the</c><00:25:29.059><c> network</c><00:25:29.419><c> we</c><00:25:30.139><c> sample</c><00:25:30.789><c> each</c><00:25:31.789><c> of</c>

00:25:32.019 --> 00:25:32.029 align:start position:0%
through the network we sample each of
 

00:25:32.029 --> 00:25:33.940 align:start position:0%
through the network we sample each of
these<00:25:32.179><c> sets</c><00:25:32.450><c> of</c><00:25:32.599><c> weights</c><00:25:32.869><c> right</c><00:25:33.200><c> these</c><00:25:33.440><c> filter</c>

00:25:33.940 --> 00:25:33.950 align:start position:0%
these sets of weights right these filter
 

00:25:33.950 --> 00:25:37.089 align:start position:0%
these sets of weights right these filter
maps<00:25:34.269><c> according</c><00:25:35.269><c> to</c><00:25:35.479><c> some</c><00:25:35.779><c> drop</c><00:25:36.499><c> out</c><00:25:36.710><c> mask</c>

00:25:37.089 --> 00:25:37.099 align:start position:0%
maps according to some drop out mask
 

00:25:37.099 --> 00:25:39.789 align:start position:0%
maps according to some drop out mask
that<00:25:38.059><c> these</c><00:25:38.809><c> are</c><00:25:38.960><c> either</c><00:25:39.109><c> zeros</c><00:25:39.559><c> or</c><00:25:39.769><c> ones</c>

00:25:39.789 --> 00:25:39.799 align:start position:0%
that these are either zeros or ones
 

00:25:39.799 --> 00:25:43.719 align:start position:0%
that these are either zeros or ones
meaning<00:25:40.489><c> will</c><00:25:41.029><c> will</c><00:25:41.749><c> keep</c><00:25:42.200><c> these</c><00:25:42.729><c> weights</c>

00:25:43.719 --> 00:25:43.729 align:start position:0%
meaning will will keep these weights
 

00:25:43.729 --> 00:25:45.940 align:start position:0%
meaning will will keep these weights
highlighted<00:25:44.479><c> in</c><00:25:44.599><c> blue</c><00:25:44.809><c> and</c><00:25:45.049><c> will</c><00:25:45.499><c> discard</c>

00:25:45.940 --> 00:25:45.950 align:start position:0%
highlighted in blue and will discard
 

00:25:45.950 --> 00:25:46.659 align:start position:0%
highlighted in blue and will discard
these<00:25:46.190><c> weights</c>

00:25:46.659 --> 00:25:46.669 align:start position:0%
these weights
 

00:25:46.669 --> 00:25:50.379 align:start position:0%
these weights
highlight<00:25:47.419><c> highlighted</c><00:25:48.320><c> and</c><00:25:48.470><c> white</c><00:25:49.389><c> to</c>

00:25:50.379 --> 00:25:50.389 align:start position:0%
highlight highlighted and white to
 

00:25:50.389 --> 00:25:52.889 align:start position:0%
highlight highlighted and white to
generate<00:25:50.869><c> this</c><00:25:51.049><c> stochastic</c><00:25:51.349><c> sample</c><00:25:52.190><c> of</c><00:25:52.369><c> our</c>

00:25:52.889 --> 00:25:52.899 align:start position:0%
generate this stochastic sample of our
 

00:25:52.899 --> 00:25:57.399 align:start position:0%
generate this stochastic sample of our
original<00:25:54.009><c> filters</c><00:25:55.009><c> and</c><00:25:55.399><c> from</c><00:25:56.299><c> this</c><00:25:56.539><c> these</c>

00:25:57.399 --> 00:25:57.409 align:start position:0%
original filters and from this these
 

00:25:57.409 --> 00:25:59.919 align:start position:0%
original filters and from this these
passes<00:25:57.950><c> what</c><00:25:58.190><c> we</c><00:25:58.279><c> can</c><00:25:58.429><c> actually</c><00:25:58.759><c> obtain</c><00:25:58.909><c> is</c><00:25:59.359><c> an</c>

00:25:59.919 --> 00:25:59.929 align:start position:0%
passes what we can actually obtain is an
 

00:25:59.929 --> 00:26:04.749 align:start position:0%
passes what we can actually obtain is an
estimate<00:26:00.499><c> of</c><00:26:01.869><c> sort</c><00:26:02.869><c> of</c><00:26:02.929><c> the</c><00:26:03.139><c> expected</c><00:26:04.129><c> value</c>

00:26:04.749 --> 00:26:04.759 align:start position:0%
estimate of sort of the expected value
 

00:26:04.759 --> 00:26:07.539 align:start position:0%
estimate of sort of the expected value
of<00:26:04.789><c> the</c><00:26:05.359><c> output</c><00:26:05.749><c> labels</c><00:26:06.379><c> given</c><00:26:06.649><c> the</c><00:26:06.859><c> input</c><00:26:07.220><c> the</c>

00:26:07.539 --> 00:26:07.549 align:start position:0%
of the output labels given the input the
 

00:26:07.549 --> 00:26:10.930 align:start position:0%
of the output labels given the input the
mean<00:26:07.759><c> as</c><00:26:07.940><c> well</c><00:26:08.599><c> as</c><00:26:08.840><c> this</c><00:26:09.470><c> variance</c><00:26:10.009><c> term</c><00:26:10.399><c> which</c>

00:26:10.930 --> 00:26:10.940 align:start position:0%
mean as well as this variance term which
 

00:26:10.940 --> 00:26:13.239 align:start position:0%
mean as well as this variance term which
provides<00:26:11.539><c> an</c><00:26:11.869><c> uncertainty</c><00:26:12.529><c> estimate</c><00:26:13.099><c> and</c>

00:26:13.239 --> 00:26:13.249 align:start position:0%
provides an uncertainty estimate and
 

00:26:13.249 --> 00:26:17.399 align:start position:0%
provides an uncertainty estimate and
this<00:26:13.700><c> is</c><00:26:13.909><c> useful</c><00:26:14.779><c> in</c><00:26:15.080><c> understanding</c><00:26:15.229><c> the</c>

00:26:17.399 --> 00:26:17.409 align:start position:0%
this is useful in understanding the
 

00:26:17.409 --> 00:26:19.810 align:start position:0%
this is useful in understanding the
uncertainty<00:26:18.409><c> of</c><00:26:18.440><c> the</c><00:26:18.649><c> model</c><00:26:19.009><c> in</c><00:26:19.159><c> making</c><00:26:19.609><c> a</c>

00:26:19.810 --> 00:26:19.820 align:start position:0%
uncertainty of the model in making a
 

00:26:19.820 --> 00:26:24.129 align:start position:0%
uncertainty of the model in making a
prediction<00:26:20.690><c> and</c><00:26:21.580><c> one</c><00:26:22.580><c> application</c><00:26:23.330><c> of</c><00:26:23.509><c> this</c>

00:26:24.129 --> 00:26:24.139 align:start position:0%
prediction and one application of this
 

00:26:24.139 --> 00:26:26.739 align:start position:0%
prediction and one application of this
type<00:26:24.440><c> of</c><00:26:24.470><c> approach</c><00:26:24.769><c> is</c><00:26:25.249><c> shown</c><00:26:26.210><c> here</c><00:26:26.539><c> in</c><00:26:26.659><c> the</c>

00:26:26.739 --> 00:26:26.749 align:start position:0%
type of approach is shown here in the
 

00:26:26.749 --> 00:26:29.589 align:start position:0%
type of approach is shown here in the
context<00:26:27.229><c> of</c><00:26:27.320><c> depth</c><00:26:27.889><c> estimation</c><00:26:28.639><c> so</c><00:26:29.239><c> given</c>

00:26:29.589 --> 00:26:29.599 align:start position:0%
context of depth estimation so given
 

00:26:29.599 --> 00:26:32.019 align:start position:0%
context of depth estimation so given
some<00:26:29.629><c> input</c><00:26:30.169><c> image</c><00:26:30.470><c> we</c><00:26:30.710><c> train</c><00:26:31.009><c> a</c><00:26:31.039><c> network</c><00:26:31.519><c> to</c>

00:26:32.019 --> 00:26:32.029 align:start position:0%
some input image we train a network to
 

00:26:32.029 --> 00:26:34.960 align:start position:0%
some input image we train a network to
predict<00:26:32.509><c> the</c><00:26:33.109><c> depth</c><00:26:33.499><c> of</c><00:26:33.830><c> the</c><00:26:34.039><c> pixels</c><00:26:34.489><c> present</c>

00:26:34.960 --> 00:26:34.970 align:start position:0%
predict the depth of the pixels present
 

00:26:34.970 --> 00:26:37.400 align:start position:0%
predict the depth of the pixels present
in<00:26:35.059><c> that</c><00:26:35.210><c> image</c>

00:26:37.400 --> 00:26:37.410 align:start position:0%
in that image
 

00:26:37.410 --> 00:26:39.860 align:start position:0%
in that image
we<00:26:38.039><c> also</c><00:26:38.250><c> asked</c><00:26:38.640><c> it</c><00:26:38.880><c> okay</c><00:26:39.299><c> give</c><00:26:39.570><c> us</c><00:26:39.600><c> an</c>

00:26:39.860 --> 00:26:39.870 align:start position:0%
we also asked it okay give us an
 

00:26:39.870 --> 00:26:42.500 align:start position:0%
we also asked it okay give us an
estimate<00:26:40.049><c> of</c><00:26:40.470><c> your</c><00:26:41.130><c> uncertainty</c><00:26:41.520><c> in</c><00:26:42.090><c> making</c>

00:26:42.500 --> 00:26:42.510 align:start position:0%
estimate of your uncertainty in making
 

00:26:42.510 --> 00:26:45.140 align:start position:0%
estimate of your uncertainty in making
that<00:26:42.660><c> prediction</c><00:26:42.900><c> and</c><00:26:43.470><c> we</c><00:26:44.160><c> when</c><00:26:44.520><c> we</c><00:26:44.669><c> visualize</c>

00:26:45.140 --> 00:26:45.150 align:start position:0%
that prediction and we when we visualize
 

00:26:45.150 --> 00:26:47.390 align:start position:0%
that prediction and we when we visualize
that<00:26:45.360><c> what</c><00:26:45.630><c> you</c><00:26:45.750><c> can</c><00:26:45.900><c> see</c><00:26:46.169><c> is</c><00:26:46.410><c> that</c><00:26:46.710><c> the</c><00:26:46.980><c> model</c>

00:26:47.390 --> 00:26:47.400 align:start position:0%
that what you can see is that the model
 

00:26:47.400 --> 00:26:50.029 align:start position:0%
that what you can see is that the model
is<00:26:47.549><c> more</c><00:26:47.880><c> uncertain</c><00:26:48.450><c> in</c><00:26:48.690><c> this</c><00:26:48.929><c> sort</c><00:26:49.650><c> of</c><00:26:49.770><c> edge</c>

00:26:50.029 --> 00:26:50.039 align:start position:0%
is more uncertain in this sort of edge
 

00:26:50.039 --> 00:26:54.440 align:start position:0%
is more uncertain in this sort of edge
here<00:26:50.880><c> which</c><00:26:51.870><c> makes</c><00:26:52.110><c> sense</c><00:26:52.350><c> if</c><00:26:53.030><c> you</c><00:26:54.030><c> look</c><00:26:54.240><c> back</c>

00:26:54.440 --> 00:26:54.450 align:start position:0%
here which makes sense if you look back
 

00:26:54.450 --> 00:26:57.470 align:start position:0%
here which makes sense if you look back
at<00:26:54.510><c> this</c><00:26:54.840><c> original</c><00:26:55.350><c> input</c><00:26:55.799><c> that</c><00:26:56.130><c> the</c><00:26:56.730><c> edge</c><00:26:57.090><c> is</c>

00:26:57.470 --> 00:26:57.480 align:start position:0%
at this original input that the edge is
 

00:26:57.480 --> 00:26:59.210 align:start position:0%
at this original input that the edge is
sort<00:26:57.750><c> of</c><00:26:57.840><c> at</c><00:26:58.049><c> this</c><00:26:58.230><c> point</c><00:26:58.320><c> where</c><00:26:58.650><c> those</c><00:26:58.950><c> two</c>

00:26:59.210 --> 00:26:59.220 align:start position:0%
sort of at this point where those two
 

00:26:59.220 --> 00:27:01.640 align:start position:0%
sort of at this point where those two
cars<00:26:59.610><c> are</c><00:26:59.850><c> overlapping</c><00:27:00.390><c> and</c><00:27:00.780><c> so</c><00:27:01.289><c> you</c><00:27:01.350><c> can</c>

00:27:01.640 --> 00:27:01.650 align:start position:0%
cars are overlapping and so you can
 

00:27:01.650 --> 00:27:04.010 align:start position:0%
cars are overlapping and so you can
imagine<00:27:01.770><c> that</c><00:27:02.309><c> the</c><00:27:02.610><c> model</c><00:27:02.910><c> may</c><00:27:03.090><c> have</c><00:27:03.720><c> more</c>

00:27:04.010 --> 00:27:04.020 align:start position:0%
imagine that the model may have more
 

00:27:04.020 --> 00:27:06.890 align:start position:0%
imagine that the model may have more
difficulty<00:27:04.740><c> in</c><00:27:04.770><c> estimating</c><00:27:05.340><c> the</c><00:27:06.120><c> pixels</c><00:27:06.600><c> that</c>

00:27:06.890 --> 00:27:06.900 align:start position:0%
difficulty in estimating the pixels that
 

00:27:06.900 --> 00:27:09.470 align:start position:0%
difficulty in estimating the pixels that
line<00:27:07.530><c> that</c><00:27:07.770><c> edge</c><00:27:08.039><c> the</c><00:27:08.549><c> depth</c><00:27:08.820><c> of</c><00:27:09.030><c> the</c><00:27:09.120><c> pixels</c>

00:27:09.470 --> 00:27:09.480 align:start position:0%
line that edge the depth of the pixels
 

00:27:09.480 --> 00:27:13.720 align:start position:0%
line that edge the depth of the pixels
that<00:27:09.600><c> line</c><00:27:10.110><c> that</c><00:27:10.350><c> edge</c><00:27:12.320><c> furthermore</c><00:27:13.320><c> if</c><00:27:13.559><c> you</c>

00:27:13.720 --> 00:27:13.730 align:start position:0%
that line that edge furthermore if you
 

00:27:13.730 --> 00:27:16.520 align:start position:0%
that line that edge furthermore if you
remember<00:27:14.730><c> from</c><00:27:15.000><c> from</c><00:27:15.539><c> yesterday's</c><00:27:16.080><c> lecture</c><00:27:16.320><c> I</c>

00:27:16.520 --> 00:27:16.530 align:start position:0%
remember from from yesterday's lecture I
 

00:27:16.530 --> 00:27:19.640 align:start position:0%
remember from from yesterday's lecture I
showed<00:27:16.890><c> this</c><00:27:17.100><c> video</c><00:27:17.510><c> which</c><00:27:18.510><c> is</c><00:27:18.809><c> worked</c><00:27:19.500><c> from</c>

00:27:19.640 --> 00:27:19.650 align:start position:0%
showed this video which is worked from
 

00:27:19.650 --> 00:27:22.220 align:start position:0%
showed this video which is worked from
the<00:27:19.710><c> same</c><00:27:20.070><c> group</c><00:27:20.309><c> at</c><00:27:20.490><c> Cambridge</c><00:27:21.299><c> where</c><00:27:22.080><c> they</c>

00:27:22.220 --> 00:27:22.230 align:start position:0%
the same group at Cambridge where they
 

00:27:22.230 --> 00:27:24.909 align:start position:0%
the same group at Cambridge where they
trained<00:27:22.590><c> a</c><00:27:23.090><c> convolutional</c><00:27:24.090><c> base</c>

00:27:24.909 --> 00:27:24.919 align:start position:0%
trained a convolutional base
 

00:27:24.919 --> 00:27:27.010 align:start position:0%
trained a convolutional base
convolutional<00:27:25.919><c> neural</c><00:27:26.130><c> network</c><00:27:26.549><c> based</c>

00:27:27.010 --> 00:27:27.020 align:start position:0%
convolutional neural network based
 

00:27:27.020 --> 00:27:29.240 align:start position:0%
convolutional neural network based
architecture<00:27:28.020><c> on</c><00:27:28.200><c> three</c><00:27:28.799><c> tasks</c>

00:27:29.240 --> 00:27:29.250 align:start position:0%
architecture on three tasks
 

00:27:29.250 --> 00:27:31.700 align:start position:0%
architecture on three tasks
simultaneously<00:27:29.960><c> semantic</c><00:27:30.960><c> segmentation</c>

00:27:31.700 --> 00:27:31.710 align:start position:0%
simultaneously semantic segmentation
 

00:27:31.710 --> 00:27:34.279 align:start position:0%
simultaneously semantic segmentation
depth<00:27:32.280><c> estimation</c><00:27:33.030><c> and</c><00:27:33.289><c> instant</c>

00:27:34.279 --> 00:27:34.289 align:start position:0%
depth estimation and instant
 

00:27:34.289 --> 00:27:37.279 align:start position:0%
depth estimation and instant
segmentation<00:27:34.950><c> and</c><00:27:35.250><c> what</c><00:27:36.120><c> we</c><00:27:36.570><c> really</c><00:27:36.870><c> focused</c>

00:27:37.279 --> 00:27:37.289 align:start position:0%
segmentation and what we really focused
 

00:27:37.289 --> 00:27:39.830 align:start position:0%
segmentation and what we really focused
on<00:27:37.440><c> yesterday</c><00:27:38.100><c> was</c><00:27:38.309><c> how</c><00:27:38.549><c> this</c><00:27:38.880><c> segmentation</c>

00:27:39.830 --> 00:27:39.840 align:start position:0%
on yesterday was how this segmentation
 

00:27:39.840 --> 00:27:43.070 align:start position:0%
on yesterday was how this segmentation
result<00:27:40.380><c> was</c><00:27:41.070><c> much</c><00:27:41.730><c> crisper</c><00:27:42.240><c> and</c><00:27:42.270><c> cleaner</c><00:27:42.690><c> from</c>

00:27:43.070 --> 00:27:43.080 align:start position:0%
result was much crisper and cleaner from
 

00:27:43.080 --> 00:27:45.590 align:start position:0%
result was much crisper and cleaner from
there<00:27:43.350><c> this</c><00:27:44.010><c> group's</c><00:27:44.340><c> previous</c><00:27:44.580><c> result</c><00:27:45.150><c> from</c>

00:27:45.590 --> 00:27:45.600 align:start position:0%
there this group's previous result from
 

00:27:45.600 --> 00:27:48.230 align:start position:0%
there this group's previous result from
one<00:27:46.080><c> year</c><00:27:46.289><c> prior</c><00:27:46.530><c> but</c><00:27:47.340><c> what</c><00:27:47.669><c> we</c><00:27:47.789><c> didn't</c><00:27:48.030><c> talk</c>

00:27:48.230 --> 00:27:48.240 align:start position:0%
one year prior but what we didn't talk
 

00:27:48.240 --> 00:27:50.659 align:start position:0%
one year prior but what we didn't talk
about<00:27:48.390><c> was</c><00:27:48.690><c> how</c><00:27:48.720><c> they're</c><00:27:49.590><c> actually</c><00:27:50.070><c> achieving</c>

00:27:50.659 --> 00:27:50.669 align:start position:0%
about was how they're actually achieving
 

00:27:50.669 --> 00:27:54.560 align:start position:0%
about was how they're actually achieving
this<00:27:51.179><c> improvement</c><00:27:52.020><c> and</c><00:27:53.360><c> what</c><00:27:54.360><c> they're</c><00:27:54.539><c> doing</c>

00:27:54.560 --> 00:27:54.570 align:start position:0%
this improvement and what they're doing
 

00:27:54.570 --> 00:27:58.220 align:start position:0%
this improvement and what they're doing
is<00:27:55.080><c> they're</c><00:27:55.350><c> using</c><00:27:55.789><c> uncertainty</c><00:27:56.789><c> by</c><00:27:57.570><c> training</c>

00:27:58.220 --> 00:27:58.230 align:start position:0%
is they're using uncertainty by training
 

00:27:58.230 --> 00:28:00.020 align:start position:0%
is they're using uncertainty by training
their<00:27:58.530><c> network</c><00:27:58.919><c> on</c><00:27:59.159><c> these</c><00:27:59.400><c> three</c><00:27:59.760><c> different</c>

00:28:00.020 --> 00:28:00.030 align:start position:0%
their network on these three different
 

00:28:00.030 --> 00:28:03.350 align:start position:0%
their network on these three different
tasks<00:28:00.840><c> simultaneously</c><00:28:02.000><c> what</c><00:28:03.000><c> they're</c><00:28:03.179><c> able</c>

00:28:03.350 --> 00:28:03.360 align:start position:0%
tasks simultaneously what they're able
 

00:28:03.360 --> 00:28:08.930 align:start position:0%
tasks simultaneously what they're able
to<00:28:03.539><c> achieve</c><00:28:03.990><c> is</c><00:28:04.679><c> to</c><00:28:06.950><c> use</c><00:28:07.950><c> the</c><00:28:08.130><c> uncertainty</c>

00:28:08.930 --> 00:28:08.940 align:start position:0%
to achieve is to use the uncertainty
 

00:28:08.940 --> 00:28:13.370 align:start position:0%
to achieve is to use the uncertainty
estimates<00:28:09.530><c> from</c><00:28:10.530><c> two</c><00:28:11.520><c> of</c><00:28:11.549><c> two</c><00:28:12.299><c> tasks</c><00:28:12.900><c> to</c>

00:28:13.370 --> 00:28:13.380 align:start position:0%
estimates from two of two tasks to
 

00:28:13.380 --> 00:28:16.610 align:start position:0%
estimates from two of two tasks to
improve<00:28:13.860><c> the</c><00:28:14.220><c> accuracy</c><00:28:14.760><c> of</c><00:28:15.150><c> the</c><00:28:16.110><c> third</c><00:28:16.350><c> task</c>

00:28:16.610 --> 00:28:16.620 align:start position:0%
improve the accuracy of the third task
 

00:28:16.620 --> 00:28:20.450 align:start position:0%
improve the accuracy of the third task
and<00:28:17.070><c> this</c><00:28:17.760><c> is</c><00:28:17.940><c> used</c><00:28:18.179><c> to</c><00:28:18.390><c> regularize</c><00:28:19.049><c> the</c><00:28:19.980><c> the</c>

00:28:20.450 --> 00:28:20.460 align:start position:0%
and this is used to regularize the the
 

00:28:20.460 --> 00:28:24.070 align:start position:0%
and this is used to regularize the the
network<00:28:21.240><c> and</c><00:28:21.419><c> improve</c><00:28:21.780><c> its</c><00:28:21.990><c> generalization</c>

00:28:24.070 --> 00:28:24.080 align:start position:0%
network and improve its generalization
 

00:28:24.080 --> 00:28:27.500 align:start position:0%
network and improve its generalization
in<00:28:25.080><c> one</c><00:28:25.350><c> domain</c><00:28:25.740><c> such</c><00:28:26.010><c> as</c><00:28:26.250><c> segmentation</c><00:28:27.240><c> and</c>

00:28:27.500 --> 00:28:27.510 align:start position:0%
in one domain such as segmentation and
 

00:28:27.510 --> 00:28:30.289 align:start position:0%
in one domain such as segmentation and
this<00:28:28.320><c> is</c><00:28:28.470><c> just</c><00:28:28.740><c> another</c><00:28:29.309><c> example</c><00:28:29.580><c> of</c><00:28:30.090><c> their</c>

00:28:30.289 --> 00:28:30.299 align:start position:0%
this is just another example of their
 

00:28:30.299 --> 00:28:32.750 align:start position:0%
this is just another example of their
results<00:28:30.720><c> and</c><00:28:30.840><c> as</c><00:28:31.020><c> you</c><00:28:31.350><c> can</c><00:28:31.470><c> see</c><00:28:31.530><c> right</c><00:28:32.010><c> each</c><00:28:32.490><c> of</c>

00:28:32.750 --> 00:28:32.760 align:start position:0%
results and as you can see right each of
 

00:28:32.760 --> 00:28:36.740 align:start position:0%
results and as you can see right each of
these<00:28:34.549><c> semantic</c><00:28:35.549><c> segmentation</c><00:28:36.299><c> instant</c>

00:28:36.740 --> 00:28:36.750 align:start position:0%
these semantic segmentation instant
 

00:28:36.750 --> 00:28:37.909 align:start position:0%
these semantic segmentation instant
segmentation<00:28:37.380><c> and</c><00:28:37.590><c> depth</c>

00:28:37.909 --> 00:28:37.919 align:start position:0%
segmentation and depth
 

00:28:37.919 --> 00:28:40.549 align:start position:0%
segmentation and depth
estimation<00:28:38.520><c> seemed</c><00:28:39.179><c> pretty</c><00:28:39.450><c> crisp</c><00:28:40.049><c> and</c><00:28:40.289><c> clean</c>

00:28:40.549 --> 00:28:40.559 align:start position:0%
estimation seemed pretty crisp and clean
 

00:28:40.559 --> 00:28:45.649 align:start position:0%
estimation seemed pretty crisp and clean
when<00:28:41.130><c> compared</c><00:28:41.549><c> to</c><00:28:41.640><c> the</c><00:28:42.030><c> input</c><00:28:42.330><c> image</c><00:28:44.120><c> so</c><00:28:45.120><c> the</c>

00:28:45.649 --> 00:28:45.659 align:start position:0%
when compared to the input image so the
 

00:28:45.659 --> 00:28:48.380 align:start position:0%
when compared to the input image so the
second<00:28:46.049><c> exciting</c><00:28:46.830><c> area</c><00:28:47.190><c> of</c><00:28:47.790><c> new</c><00:28:48.000><c> research</c>

00:28:48.380 --> 00:28:48.390 align:start position:0%
second exciting area of new research
 

00:28:48.390 --> 00:28:50.180 align:start position:0%
second exciting area of new research
that<00:28:48.419><c> I'd</c><00:28:48.720><c> like</c><00:28:48.900><c> to</c><00:28:48.929><c> highlight</c><00:28:49.200><c> is</c><00:28:49.559><c> this</c><00:28:49.740><c> idea</c>

00:28:50.180 --> 00:28:50.190 align:start position:0%
that I'd like to highlight is this idea
 

00:28:50.190 --> 00:28:50.749 align:start position:0%
that I'd like to highlight is this idea
of

00:28:50.749 --> 00:28:50.759 align:start position:0%
of
 

00:28:50.759 --> 00:28:55.489 align:start position:0%
of
learning<00:28:51.089><c> to</c><00:28:51.269><c> learn</c><00:28:51.479><c> and</c><00:28:53.719><c> to</c><00:28:54.719><c> understand</c><00:28:55.229><c> why</c>

00:28:55.489 --> 00:28:55.499 align:start position:0%
learning to learn and to understand why
 

00:28:55.499 --> 00:28:57.469 align:start position:0%
learning to learn and to understand why
this<00:28:55.949><c> may</c><00:28:56.190><c> be</c><00:28:56.219><c> useful</c><00:28:56.789><c> and</c><00:28:56.969><c> why</c><00:28:57.149><c> you</c><00:28:57.209><c> may</c><00:28:57.449><c> want</c>

00:28:57.469 --> 00:28:57.479 align:start position:0%
this may be useful and why you may want
 

00:28:57.479 --> 00:29:00.019 align:start position:0%
this may be useful and why you may want
to<00:28:57.719><c> build</c><00:28:58.019><c> out</c><00:28:58.289><c> algorithms</c><00:28:58.949><c> that</c><00:28:59.159><c> can</c><00:28:59.789><c> learn</c>

00:29:00.019 --> 00:29:00.029 align:start position:0%
to build out algorithms that can learn
 

00:29:00.029 --> 00:29:03.199 align:start position:0%
to build out algorithms that can learn
to<00:29:00.089><c> learn</c><00:29:00.469><c> right</c><00:29:01.639><c> well</c><00:29:02.639><c> first</c><00:29:02.909><c> like</c><00:29:03.059><c> to</c>

00:29:03.199 --> 00:29:03.209 align:start position:0%
to learn right well first like to
 

00:29:03.209 --> 00:29:07.249 align:start position:0%
to learn right well first like to
reiterate<00:29:03.479><c> that</c><00:29:05.059><c> most</c><00:29:06.059><c> most</c><00:29:06.539><c> neural</c><00:29:06.869><c> networks</c>

00:29:07.249 --> 00:29:07.259 align:start position:0%
reiterate that most most neural networks
 

00:29:07.259 --> 00:29:09.979 align:start position:0%
reiterate that most most neural networks
today<00:29:07.709><c> are</c><00:29:07.979><c> optimized</c><00:29:08.820><c> for</c><00:29:09.149><c> a</c><00:29:09.359><c> single</c><00:29:09.749><c> task</c>

00:29:09.979 --> 00:29:09.989 align:start position:0%
today are optimized for a single task
 

00:29:09.989 --> 00:29:13.909 align:start position:0%
today are optimized for a single task
and<00:29:10.699><c> as</c><00:29:11.699><c> models</c><00:29:12.359><c> get</c><00:29:12.570><c> more</c><00:29:12.839><c> and</c><00:29:12.989><c> more</c><00:29:13.169><c> complex</c>

00:29:13.909 --> 00:29:13.919 align:start position:0%
and as models get more and more complex
 

00:29:13.919 --> 00:29:16.639 align:start position:0%
and as models get more and more complex
you<00:29:14.489><c> know</c><00:29:14.579><c> they</c><00:29:15.109><c> increasingly</c><00:29:16.109><c> require</c>

00:29:16.639 --> 00:29:16.649 align:start position:0%
you know they increasingly require
 

00:29:16.649 --> 00:29:19.609 align:start position:0%
you know they increasingly require
expert<00:29:17.339><c> knowledge</c><00:29:17.519><c> in</c><00:29:17.940><c> terms</c><00:29:18.479><c> of</c><00:29:18.690><c> engineering</c>

00:29:19.609 --> 00:29:19.619 align:start position:0%
expert knowledge in terms of engineering
 

00:29:19.619 --> 00:29:22.310 align:start position:0%
expert knowledge in terms of engineering
them<00:29:20.070><c> and</c><00:29:20.339><c> building</c><00:29:20.969><c> them</c><00:29:21.119><c> and</c><00:29:21.359><c> deploying</c>

00:29:22.310 --> 00:29:22.320 align:start position:0%
them and building them and deploying
 

00:29:22.320 --> 00:29:24.919 align:start position:0%
them and building them and deploying
them<00:29:22.559><c> and</c><00:29:22.999><c> hopefully</c><00:29:23.999><c> you've</c><00:29:24.269><c> gotten</c><00:29:24.599><c> a</c><00:29:24.749><c> taste</c>

00:29:24.919 --> 00:29:24.929 align:start position:0%
them and hopefully you've gotten a taste
 

00:29:24.929 --> 00:29:29.889 align:start position:0%
them and hopefully you've gotten a taste
of<00:29:25.199><c> that</c><00:29:25.619><c> knowledge</c><00:29:26.419><c> through</c><00:29:27.419><c> this</c><00:29:27.599><c> course</c><00:29:28.339><c> so</c>

00:29:29.889 --> 00:29:29.899 align:start position:0%
of that knowledge through this course so
 

00:29:29.899 --> 00:29:32.479 align:start position:0%
of that knowledge through this course so
this<00:29:30.899><c> can</c><00:29:31.109><c> be</c><00:29:31.229><c> kind</c><00:29:31.499><c> of</c><00:29:31.679><c> a</c><00:29:31.769><c> bottleneck</c><00:29:32.099><c> right</c>

00:29:32.479 --> 00:29:32.489 align:start position:0%
this can be kind of a bottleneck right
 

00:29:32.489 --> 00:29:34.189 align:start position:0%
this can be kind of a bottleneck right
because<00:29:32.879><c> you</c><00:29:33.449><c> know</c><00:29:33.479><c> there</c><00:29:33.779><c> are</c><00:29:33.869><c> so</c><00:29:34.079><c> many</c>

00:29:34.189 --> 00:29:34.199 align:start position:0%
because you know there are so many
 

00:29:34.199 --> 00:29:36.439 align:start position:0%
because you know there are so many
different<00:29:34.649><c> settings</c><00:29:35.159><c> where</c><00:29:35.639><c> deep</c><00:29:36.119><c> learning</c>

00:29:36.439 --> 00:29:36.449 align:start position:0%
different settings where deep learning
 

00:29:36.449 --> 00:29:38.930 align:start position:0%
different settings where deep learning
may<00:29:36.629><c> be</c><00:29:36.690><c> useful</c><00:29:36.989><c> but</c><00:29:37.379><c> only</c><00:29:37.589><c> so</c><00:29:37.889><c> many</c><00:29:38.099><c> deep</c>

00:29:38.930 --> 00:29:38.940 align:start position:0%
may be useful but only so many deep
 

00:29:38.940 --> 00:29:41.649 align:start position:0%
may be useful but only so many deep
learning<00:29:39.119><c> researchers</c><00:29:39.929><c> and</c><00:29:40.109><c> engineers</c><00:29:40.259><c> right</c>

00:29:41.649 --> 00:29:41.659 align:start position:0%
learning researchers and engineers right
 

00:29:41.659 --> 00:29:45.019 align:start position:0%
learning researchers and engineers right
so<00:29:42.659><c> why</c><00:29:43.499><c> can't</c><00:29:43.829><c> we</c><00:29:43.949><c> build</c><00:29:44.159><c> a</c><00:29:44.489><c> learning</c>

00:29:45.019 --> 00:29:45.029 align:start position:0%
so why can't we build a learning
 

00:29:45.029 --> 00:29:47.869 align:start position:0%
so why can't we build a learning
algorithm<00:29:45.389><c> that</c><00:29:46.169><c> actually</c><00:29:46.679><c> learns</c><00:29:46.979><c> which</c>

00:29:47.869 --> 00:29:47.879 align:start position:0%
algorithm that actually learns which
 

00:29:47.879 --> 00:29:50.659 align:start position:0%
algorithm that actually learns which
model<00:29:48.359><c> is</c><00:29:48.509><c> most</c><00:29:48.959><c> well</c><00:29:49.199><c> suited</c><00:29:49.559><c> for</c><00:29:49.769><c> an</c>

00:29:50.659 --> 00:29:50.669 align:start position:0%
model is most well suited for an
 

00:29:50.669 --> 00:29:53.629 align:start position:0%
model is most well suited for an
arbitrary<00:29:51.449><c> set</c><00:29:51.659><c> of</c><00:29:51.809><c> data</c><00:29:52.019><c> and</c><00:29:52.339><c> an</c><00:29:53.339><c> arbitrary</c>

00:29:53.629 --> 00:29:53.639 align:start position:0%
arbitrary set of data and an arbitrary
 

00:29:53.639 --> 00:29:57.049 align:start position:0%
arbitrary set of data and an arbitrary
task<00:29:54.149><c> and</c><00:29:54.539><c> Google</c><00:29:55.409><c> asked</c><00:29:56.279><c> this</c><00:29:56.369><c> question</c><00:29:56.849><c> a</c>

00:29:57.049 --> 00:29:57.059 align:start position:0%
task and Google asked this question a
 

00:29:57.059 --> 00:29:59.269 align:start position:0%
task and Google asked this question a
few<00:29:57.809><c> years</c><00:29:58.019><c> ago</c><00:29:58.169><c> and</c><00:29:58.499><c> it</c><00:29:58.649><c> turns</c><00:29:58.859><c> out</c><00:29:58.979><c> that</c><00:29:59.039><c> we</c>

00:29:59.269 --> 00:29:59.279 align:start position:0%
few years ago and it turns out that we
 

00:29:59.279 --> 00:30:01.369 align:start position:0%
few years ago and it turns out that we
can<00:29:59.549><c> do</c><00:29:59.789><c> this</c><00:29:59.940><c> and</c><00:30:00.269><c> this</c><00:30:00.479><c> is</c><00:30:00.629><c> the</c><00:30:00.719><c> idea</c><00:30:01.079><c> behind</c>

00:30:01.369 --> 00:30:01.379 align:start position:0%
can do this and this is the idea behind
 

00:30:01.379 --> 00:30:07.369 align:start position:0%
can do this and this is the idea behind
this<00:30:02.339><c> this</c><00:30:04.789><c> this</c><00:30:05.789><c> concept</c><00:30:06.029><c> of</c><00:30:06.419><c> Auto</c><00:30:06.690><c> ml</c><00:30:07.109><c> which</c>

00:30:07.369 --> 00:30:07.379 align:start position:0%
this this this concept of Auto ml which
 

00:30:07.379 --> 00:30:09.739 align:start position:0%
this this this concept of Auto ml which
stands<00:30:07.709><c> for</c><00:30:07.799><c> sort</c><00:30:08.549><c> of</c><00:30:08.669><c> automatic</c><00:30:09.299><c> machine</c>

00:30:09.739 --> 00:30:09.749 align:start position:0%
stands for sort of automatic machine
 

00:30:09.749 --> 00:30:11.839 align:start position:0%
stands for sort of automatic machine
learning<00:30:10.219><c> automatically</c><00:30:11.219><c> learning</c><00:30:11.639><c> how</c><00:30:11.819><c> to</c>

00:30:11.839 --> 00:30:11.849 align:start position:0%
learning automatically learning how to
 

00:30:11.849 --> 00:30:14.479 align:start position:0%
learning automatically learning how to
create<00:30:12.299><c> new</c><00:30:12.989><c> machine</c><00:30:13.409><c> learning</c><00:30:13.769><c> models</c><00:30:14.129><c> for</c><00:30:14.459><c> a</c>

00:30:14.479 --> 00:30:14.489 align:start position:0%
create new machine learning models for a
 

00:30:14.489 --> 00:30:18.439 align:start position:0%
create new machine learning models for a
particular<00:30:15.089><c> problem</c><00:30:15.389><c> and</c><00:30:16.579><c> in</c><00:30:17.579><c> the</c><00:30:18.179><c> original</c>

00:30:18.439 --> 00:30:18.449 align:start position:0%
particular problem and in the original
 

00:30:18.449 --> 00:30:20.689 align:start position:0%
particular problem and in the original
auto<00:30:18.899><c> ml</c><00:30:19.259><c> which</c><00:30:19.499><c> was</c><00:30:19.709><c> proposed</c><00:30:20.099><c> by</c><00:30:20.190><c> Google</c>

00:30:20.689 --> 00:30:20.699 align:start position:0%
auto ml which was proposed by Google
 

00:30:20.699 --> 00:30:23.329 align:start position:0%
auto ml which was proposed by Google
uses<00:30:21.389><c> a</c><00:30:21.659><c> reinforcement</c><00:30:22.469><c> learning</c><00:30:22.739><c> framework</c>

00:30:23.329 --> 00:30:23.339 align:start position:0%
uses a reinforcement learning framework
 

00:30:23.339 --> 00:30:26.089 align:start position:0%
uses a reinforcement learning framework
and<00:30:23.579><c> how</c><00:30:24.329><c> it</c><00:30:24.479><c> works</c><00:30:24.690><c> is</c><00:30:25.019><c> is</c><00:30:25.319><c> the</c><00:30:25.709><c> following</c>

00:30:26.089 --> 00:30:26.099 align:start position:0%
and how it works is is the following
 

00:30:26.099 --> 00:30:29.209 align:start position:0%
and how it works is is the following
they<00:30:26.369><c> have</c><00:30:26.639><c> sort</c><00:30:27.419><c> of</c><00:30:27.539><c> this</c><00:30:27.709><c> like</c><00:30:28.709><c> agent</c>

00:30:29.209 --> 00:30:29.219 align:start position:0%
they have sort of this like agent
 

00:30:29.219 --> 00:30:31.909 align:start position:0%
they have sort of this like agent
environment<00:30:29.929><c> structure</c><00:30:30.929><c> that</c><00:30:31.259><c> Alexander</c>

00:30:31.909 --> 00:30:31.919 align:start position:0%
environment structure that Alexander
 

00:30:31.919 --> 00:30:35.239 align:start position:0%
environment structure that Alexander
introduced<00:30:32.429><c> where</c><00:30:33.179><c> they</c><00:30:33.359><c> have</c><00:30:33.659><c> a</c><00:30:34.249><c> first</c>

00:30:35.239 --> 00:30:35.249 align:start position:0%
introduced where they have a first
 

00:30:35.249 --> 00:30:38.239 align:start position:0%
introduced where they have a first
Network<00:30:35.759><c> the</c><00:30:36.119><c> controller</c><00:30:36.949><c> which</c><00:30:37.949><c> in</c><00:30:38.099><c> this</c>

00:30:38.239 --> 00:30:38.249 align:start position:0%
Network the controller which in this
 

00:30:38.249 --> 00:30:44.569 align:start position:0%
Network the controller which in this
case<00:30:38.489><c> is</c><00:30:38.819><c> a</c><00:30:39.199><c> RNN</c><00:30:40.399><c> that</c><00:30:41.399><c> proposes</c><00:30:42.269><c> a</c><00:30:43.579><c> child</c>

00:30:44.569 --> 00:30:44.579 align:start position:0%
case is a RNN that proposes a child
 

00:30:44.579 --> 00:30:47.809 align:start position:0%
case is a RNN that proposes a child
model<00:30:45.389><c> architecture</c><00:30:46.259><c> right</c><00:30:46.769><c> in</c><00:30:46.979><c> terms</c><00:30:47.309><c> of</c><00:30:47.579><c> the</c>

00:30:47.809 --> 00:30:47.819 align:start position:0%
model architecture right in terms of the
 

00:30:47.819 --> 00:30:51.259 align:start position:0%
model architecture right in terms of the
parameters<00:30:48.539><c> of</c><00:30:48.569><c> that</c><00:30:49.109><c> model</c><00:30:49.789><c> which</c><00:30:50.789><c> can</c><00:30:51.059><c> then</c>

00:30:51.259 --> 00:30:51.269 align:start position:0%
parameters of that model which can then
 

00:30:51.269 --> 00:30:55.369 align:start position:0%
parameters of that model which can then
be<00:30:51.329><c> trained</c><00:30:51.989><c> and</c><00:30:53.749><c> evaluated</c><00:30:54.749><c> for</c><00:30:55.079><c> its</c>

00:30:55.369 --> 00:30:55.379 align:start position:0%
be trained and evaluated for its
 

00:30:55.379 --> 00:30:59.169 align:start position:0%
be trained and evaluated for its
performance<00:30:56.190><c> on</c><00:30:56.399><c> a</c><00:30:56.879><c> particular</c><00:30:57.569><c> task</c><00:30:57.869><c> and</c>

00:30:59.169 --> 00:30:59.179 align:start position:0%
performance on a particular task and
 

00:30:59.179 --> 00:31:02.029 align:start position:0%
performance on a particular task and
feedback<00:31:00.179><c> on</c><00:31:00.419><c> how</c><00:31:00.719><c> well</c><00:31:01.019><c> that</c><00:31:01.049><c> child</c><00:31:01.319><c> model</c>

00:31:02.029 --> 00:31:02.039 align:start position:0%
feedback on how well that child model
 

00:31:02.039 --> 00:31:03.400 align:start position:0%
feedback on how well that child model
does

00:31:03.400 --> 00:31:03.410 align:start position:0%
does
 

00:31:03.410 --> 00:31:06.310 align:start position:0%
does
you<00:31:03.980><c> know</c><00:31:04.100><c> your</c><00:31:04.370><c> tasks</c><00:31:04.640><c> of</c><00:31:04.850><c> interest</c><00:31:05.330><c> is</c><00:31:05.540><c> then</c>

00:31:06.310 --> 00:31:06.320 align:start position:0%
you know your tasks of interest is then
 

00:31:06.320 --> 00:31:11.590 align:start position:0%
you know your tasks of interest is then
used<00:31:06.800><c> to</c><00:31:07.070><c> inform</c><00:31:08.680><c> the</c><00:31:10.090><c> controller</c><00:31:11.090><c> on</c><00:31:11.300><c> how</c><00:31:11.540><c> to</c>

00:31:11.590 --> 00:31:11.600 align:start position:0%
used to inform the controller on how to
 

00:31:11.600 --> 00:31:15.730 align:start position:0%
used to inform the controller on how to
improve<00:31:12.290><c> its</c><00:31:13.160><c> proposals</c><00:31:13.880><c> for</c><00:31:14.330><c> the</c><00:31:14.450><c> next</c><00:31:14.840><c> round</c>

00:31:15.730 --> 00:31:15.740 align:start position:0%
improve its proposals for the next round
 

00:31:15.740 --> 00:31:18.730 align:start position:0%
improve its proposals for the next round
in<00:31:16.040><c> terms</c><00:31:16.310><c> of</c><00:31:16.490><c> okay</c><00:31:17.210><c> what</c><00:31:17.510><c> is</c><00:31:17.660><c> the</c><00:31:18.260><c> updated</c>

00:31:18.730 --> 00:31:18.740 align:start position:0%
in terms of okay what is the updated
 

00:31:18.740 --> 00:31:20.650 align:start position:0%
in terms of okay what is the updated
child<00:31:19.280><c> network</c><00:31:19.670><c> that</c><00:31:19.880><c> I'm</c><00:31:20.000><c> going</c><00:31:20.240><c> to</c><00:31:20.330><c> propose</c>

00:31:20.650 --> 00:31:20.660 align:start position:0%
child network that I'm going to propose
 

00:31:20.660 --> 00:31:23.560 align:start position:0%
child network that I'm going to propose
and<00:31:20.990><c> this</c><00:31:21.980><c> process</c><00:31:22.460><c> is</c><00:31:22.580><c> repeated</c><00:31:22.790><c> thousands</c>

00:31:23.560 --> 00:31:23.570 align:start position:0%
and this process is repeated thousands
 

00:31:23.570 --> 00:31:26.140 align:start position:0%
and this process is repeated thousands
of<00:31:23.690><c> times</c><00:31:23.860><c> you</c><00:31:24.860><c> know</c><00:31:24.950><c> iteratively</c><00:31:25.430><c> generating</c>

00:31:26.140 --> 00:31:26.150 align:start position:0%
of times you know iteratively generating
 

00:31:26.150 --> 00:31:28.120 align:start position:0%
of times you know iteratively generating
new<00:31:26.450><c> architectures</c><00:31:27.170><c> testing</c><00:31:27.770><c> them</c><00:31:27.950><c> and</c>

00:31:28.120 --> 00:31:28.130 align:start position:0%
new architectures testing them and
 

00:31:28.130 --> 00:31:30.370 align:start position:0%
new architectures testing them and
giving<00:31:28.880><c> that</c><00:31:29.000><c> feedback</c><00:31:29.270><c> back</c><00:31:29.990><c> to</c><00:31:30.050><c> the</c>

00:31:30.370 --> 00:31:30.380 align:start position:0%
giving that feedback back to the
 

00:31:30.380 --> 00:31:33.280 align:start position:0%
giving that feedback back to the
controller<00:31:30.770><c> to</c><00:31:31.400><c> learn</c><00:31:31.610><c> from</c><00:31:31.850><c> and</c><00:31:32.290><c> eventually</c>

00:31:33.280 --> 00:31:33.290 align:start position:0%
controller to learn from and eventually
 

00:31:33.290 --> 00:31:34.960 align:start position:0%
controller to learn from and eventually
the<00:31:33.410><c> controller</c><00:31:33.860><c> is</c><00:31:34.040><c> going</c><00:31:34.220><c> to</c><00:31:34.370><c> learn</c><00:31:34.610><c> to</c>

00:31:34.960 --> 00:31:34.970 align:start position:0%
the controller is going to learn to
 

00:31:34.970 --> 00:31:39.310 align:start position:0%
the controller is going to learn to
assign<00:31:35.870><c> high</c><00:31:36.200><c> probability</c><00:31:36.950><c> to</c><00:31:37.810><c> sort</c><00:31:38.810><c> of</c><00:31:38.900><c> areas</c>

00:31:39.310 --> 00:31:39.320 align:start position:0%
assign high probability to sort of areas
 

00:31:39.320 --> 00:31:41.860 align:start position:0%
assign high probability to sort of areas
of<00:31:39.500><c> the</c><00:31:39.590><c> architecture</c><00:31:40.310><c> space</c><00:31:40.640><c> that</c><00:31:41.390><c> achieve</c>

00:31:41.860 --> 00:31:41.870 align:start position:0%
of the architecture space that achieve
 

00:31:41.870 --> 00:31:45.210 align:start position:0%
of the architecture space that achieve
better<00:31:42.200><c> accuracy</c><00:31:43.040><c> on</c><00:31:43.220><c> that</c><00:31:43.910><c> desired</c><00:31:44.330><c> task</c><00:31:44.690><c> and</c>

00:31:45.210 --> 00:31:45.220 align:start position:0%
better accuracy on that desired task and
 

00:31:45.220 --> 00:31:48.190 align:start position:0%
better accuracy on that desired task and
low<00:31:46.220><c> probability</c><00:31:46.970><c> to</c><00:31:47.240><c> those</c><00:31:47.480><c> architectures</c>

00:31:48.190 --> 00:31:48.200 align:start position:0%
low probability to those architectures
 

00:31:48.200 --> 00:31:51.730 align:start position:0%
low probability to those architectures
that<00:31:48.230><c> don't</c><00:31:48.740><c> perform</c><00:31:49.130><c> well</c><00:31:50.170><c> so</c><00:31:51.170><c> how</c><00:31:51.380><c> does</c><00:31:51.440><c> this</c>

00:31:51.730 --> 00:31:51.740 align:start position:0%
that don't perform well so how does this
 

00:31:51.740 --> 00:31:54.520 align:start position:0%
that don't perform well so how does this
agent<00:31:52.190><c> work</c><00:31:52.370><c> as</c><00:31:52.610><c> I</c><00:31:53.480><c> mentioned</c><00:31:53.870><c> it's</c><00:31:54.020><c> an</c><00:31:54.110><c> RNN</c>

00:31:54.520 --> 00:31:54.530 align:start position:0%
agent work as I mentioned it's an RNN
 

00:31:54.530 --> 00:31:56.860 align:start position:0%
agent work as I mentioned it's an RNN
controller<00:31:54.980><c> that</c><00:31:55.250><c> sort</c><00:31:55.880><c> of</c><00:31:55.940><c> at</c><00:31:56.150><c> the</c><00:31:56.360><c> macro</c>

00:31:56.860 --> 00:31:56.870 align:start position:0%
controller that sort of at the macro
 

00:31:56.870 --> 00:32:00.570 align:start position:0%
controller that sort of at the macro
scale<00:31:57.130><c> considers</c><00:31:58.450><c> different</c><00:31:59.450><c> layers</c><00:31:59.690><c> in</c><00:31:59.840><c> the</c>

00:32:00.570 --> 00:32:00.580 align:start position:0%
scale considers different layers in the
 

00:32:00.580 --> 00:32:03.820 align:start position:0%
scale considers different layers in the
proposed<00:32:01.580><c> generated</c><00:32:02.240><c> network</c><00:32:02.600><c> and</c><00:32:02.870><c> at</c><00:32:03.500><c> the</c>

00:32:03.820 --> 00:32:03.830 align:start position:0%
proposed generated network and at the
 

00:32:03.830 --> 00:32:07.600 align:start position:0%
proposed generated network and at the
internal<00:32:04.700><c> level</c><00:32:05.150><c> of</c><00:32:05.800><c> each</c><00:32:06.800><c> candidate</c><00:32:07.340><c> layer</c>

00:32:07.600 --> 00:32:07.610 align:start position:0%
internal level of each candidate layer
 

00:32:07.610 --> 00:32:11.020 align:start position:0%
internal level of each candidate layer
it<00:32:08.360><c> predicts</c><00:32:09.230><c> different</c><00:32:09.980><c> what</c><00:32:10.730><c> are</c><00:32:10.820><c> known</c><00:32:10.970><c> as</c>

00:32:11.020 --> 00:32:11.030 align:start position:0%
it predicts different what are known as
 

00:32:11.030 --> 00:32:13.570 align:start position:0%
it predicts different what are known as
hyper<00:32:11.420><c> parameters</c><00:32:12.080><c> that</c><00:32:12.560><c> define</c><00:32:12.830><c> the</c>

00:32:13.570 --> 00:32:13.580 align:start position:0%
hyper parameters that define the
 

00:32:13.580 --> 00:32:15.520 align:start position:0%
hyper parameters that define the
architecture<00:32:14.240><c> of</c><00:32:14.270><c> that</c><00:32:14.420><c> layer</c><00:32:14.810><c> so</c><00:32:15.350><c> for</c>

00:32:15.520 --> 00:32:15.530 align:start position:0%
architecture of that layer so for
 

00:32:15.530 --> 00:32:17.320 align:start position:0%
architecture of that layer so for
example<00:32:15.920><c> if</c><00:32:16.040><c> we're</c><00:32:16.220><c> trying</c><00:32:16.430><c> to</c><00:32:16.580><c> generate</c><00:32:16.880><c> a</c>

00:32:17.320 --> 00:32:17.330 align:start position:0%
example if we're trying to generate a
 

00:32:17.330 --> 00:32:21.520 align:start position:0%
example if we're trying to generate a
child<00:32:17.960><c> CNN</c><00:32:18.950><c> we</c><00:32:19.490><c> may</c><00:32:19.730><c> want</c><00:32:20.090><c> to</c><00:32:20.360><c> predict</c><00:32:21.290><c> you</c>

00:32:21.520 --> 00:32:21.530 align:start position:0%
child CNN we may want to predict you
 

00:32:21.530 --> 00:32:23.740 align:start position:0%
child CNN we may want to predict you
know<00:32:21.560><c> the</c><00:32:22.340><c> number</c><00:32:22.700><c> of</c><00:32:22.850><c> different</c><00:32:23.180><c> filters</c><00:32:23.360><c> of</c>

00:32:23.740 --> 00:32:23.750 align:start position:0%
know the number of different filters of
 

00:32:23.750 --> 00:32:26.410 align:start position:0%
know the number of different filters of
a<00:32:23.840><c> layer</c><00:32:24.050><c> the</c><00:32:24.680><c> the</c><00:32:25.220><c> dimensionality</c><00:32:25.850><c> of</c><00:32:26.240><c> those</c>

00:32:26.410 --> 00:32:26.420 align:start position:0%
a layer the the dimensionality of those
 

00:32:26.420 --> 00:32:29.590 align:start position:0%
a layer the the dimensionality of those
filters<00:32:26.870><c> the</c><00:32:27.790><c> destryed</c><00:32:28.790><c> that</c><00:32:29.180><c> we're</c><00:32:29.330><c> going</c><00:32:29.510><c> to</c>

00:32:29.590 --> 00:32:29.600 align:start position:0%
filters the destryed that we're going to
 

00:32:29.600 --> 00:32:32.200 align:start position:0%
filters the destryed that we're going to
you<00:32:29.990><c> know</c><00:32:30.020><c> slide</c><00:32:30.710><c> our</c><00:32:30.950><c> filter</c><00:32:31.580><c> patch</c><00:32:31.850><c> over</c>

00:32:32.200 --> 00:32:32.210 align:start position:0%
you know slide our filter patch over
 

00:32:32.210 --> 00:32:35.350 align:start position:0%
you know slide our filter patch over
during<00:32:33.170><c> the</c><00:32:33.200><c> convolution</c><00:32:33.890><c> operation</c><00:32:34.360><c> all</c>

00:32:35.350 --> 00:32:35.360 align:start position:0%
during the convolution operation all
 

00:32:35.360 --> 00:32:37.600 align:start position:0%
during the convolution operation all
parameters<00:32:36.020><c> associated</c><00:32:36.410><c> with</c><00:32:36.770><c> convolutional</c>

00:32:37.600 --> 00:32:37.610 align:start position:0%
parameters associated with convolutional
 

00:32:37.610 --> 00:32:41.260 align:start position:0%
parameters associated with convolutional
layers<00:32:38.530><c> so</c><00:32:39.530><c> then</c><00:32:39.740><c> if</c><00:32:40.010><c> we</c><00:32:40.220><c> consider</c><00:32:40.430><c> the</c><00:32:41.030><c> the</c>

00:32:41.260 --> 00:32:41.270 align:start position:0%
layers so then if we consider the the
 

00:32:41.270 --> 00:32:43.330 align:start position:0%
layers so then if we consider the the
other<00:32:41.450><c> network</c><00:32:41.990><c> in</c><00:32:42.170><c> this</c><00:32:42.260><c> picture</c><00:32:42.710><c> the</c><00:32:43.010><c> child</c>

00:32:43.330 --> 00:32:43.340 align:start position:0%
other network in this picture the child
 

00:32:43.340 --> 00:32:47.470 align:start position:0%
other network in this picture the child
network<00:32:44.830><c> what</c><00:32:45.830><c> is</c><00:32:45.950><c> it</c><00:32:46.100><c> what</c><00:32:46.700><c> is</c><00:32:46.820><c> it</c><00:32:47.000><c> doing</c><00:32:47.210><c> to</c>

00:32:47.470 --> 00:32:47.480 align:start position:0%
network what is it what is it doing to
 

00:32:47.480 --> 00:32:49.960 align:start position:0%
network what is it what is it doing to
to<00:32:48.410><c> reiterate</c><00:32:48.710><c> this</c><00:32:49.130><c> is</c><00:32:49.310><c> a</c><00:32:49.340><c> network</c><00:32:49.730><c> that's</c>

00:32:49.960 --> 00:32:49.970 align:start position:0%
to reiterate this is a network that's
 

00:32:49.970 --> 00:32:52.480 align:start position:0%
to reiterate this is a network that's
generated<00:32:50.900><c> by</c><00:32:51.140><c> another</c><00:32:51.410><c> neural</c><00:32:52.070><c> network</c>

00:32:52.480 --> 00:32:52.490 align:start position:0%
generated by another neural network
 

00:32:52.490 --> 00:32:54.490 align:start position:0%
generated by another neural network
that's<00:32:53.120><c> why</c><00:32:53.270><c> it's</c><00:32:53.450><c> called</c><00:32:53.600><c> the</c><00:32:53.900><c> child</c><00:32:54.170><c> right</c>

00:32:54.490 --> 00:32:54.500 align:start position:0%
that's why it's called the child right
 

00:32:54.500 --> 00:32:57.070 align:start position:0%
that's why it's called the child right
and<00:32:54.830><c> what</c><00:32:55.730><c> we</c><00:32:55.820><c> can</c><00:32:56.000><c> do</c><00:32:56.150><c> is</c><00:32:56.300><c> we</c><00:32:56.420><c> can</c><00:32:56.570><c> take</c><00:32:56.840><c> this</c>

00:32:57.070 --> 00:32:57.080 align:start position:0%
and what we can do is we can take this
 

00:32:57.080 --> 00:33:00.490 align:start position:0%
and what we can do is we can take this
this<00:32:58.010><c> child</c><00:32:58.310><c> network</c><00:32:58.730><c> that's</c><00:32:58.940><c> sampled</c><00:32:59.540><c> from</c>

00:33:00.490 --> 00:33:00.500 align:start position:0%
this child network that's sampled from
 

00:33:00.500 --> 00:33:05.170 align:start position:0%
this child network that's sampled from
the<00:33:00.950><c> RNN</c><00:33:01.780><c> train</c><00:33:02.780><c> it</c><00:33:02.990><c> on</c><00:33:03.080><c> a</c><00:33:03.590><c> desire</c><00:33:04.190><c> task</c><00:33:04.580><c> right</c>

00:33:05.170 --> 00:33:05.180 align:start position:0%
the RNN train it on a desire task right
 

00:33:05.180 --> 00:33:08.110 align:start position:0%
the RNN train it on a desire task right
with<00:33:05.660><c> the</c><00:33:05.870><c> desired</c><00:33:06.230><c> data</c><00:33:06.560><c> set</c><00:33:06.830><c> and</c><00:33:07.120><c> evaluate</c>

00:33:08.110 --> 00:33:08.120 align:start position:0%
with the desired data set and evaluate
 

00:33:08.120 --> 00:33:10.660 align:start position:0%
with the desired data set and evaluate
its<00:33:08.270><c> accuracy</c><00:33:08.750><c> and</c><00:33:09.230><c> after</c><00:33:09.980><c> we</c><00:33:10.100><c> do</c><00:33:10.280><c> this</c><00:33:10.430><c> we</c><00:33:10.640><c> can</c>

00:33:10.660 --> 00:33:10.670 align:start position:0%
its accuracy and after we do this we can
 

00:33:10.670 --> 00:33:13.020 align:start position:0%
its accuracy and after we do this we can
then<00:33:11.060><c> go</c><00:33:11.480><c> back</c><00:33:11.690><c> to</c><00:33:11.720><c> our</c><00:33:11.930><c> RNN</c><00:33:12.500><c> controller</c>

00:33:13.020 --> 00:33:13.030 align:start position:0%
then go back to our RNN controller
 

00:33:13.030 --> 00:33:16.510 align:start position:0%
then go back to our RNN controller
update<00:33:14.030><c> it</c><00:33:14.210><c> right</c><00:33:14.780><c> based</c><00:33:15.260><c> on</c><00:33:15.560><c> how</c><00:33:15.890><c> the</c><00:33:15.950><c> child</c>

00:33:16.510 --> 00:33:16.520 align:start position:0%
update it right based on how the child
 

00:33:16.520 --> 00:33:16.840 align:start position:0%
update it right based on how the child
met

00:33:16.840 --> 00:33:16.850 align:start position:0%
met
 

00:33:16.850 --> 00:33:19.779 align:start position:0%
met
work<00:33:16.940><c> performed</c><00:33:17.539><c> after</c><00:33:18.259><c> training</c><00:33:18.559><c> and</c><00:33:18.889><c> now</c>

00:33:19.779 --> 00:33:19.789 align:start position:0%
work performed after training and now
 

00:33:19.789 --> 00:33:22.810 align:start position:0%
work performed after training and now
the<00:33:20.360><c> RNN</c><00:33:20.779><c> parent</c><00:33:21.230><c> can</c><00:33:21.440><c> learn</c><00:33:22.039><c> to</c><00:33:22.340><c> create</c><00:33:22.669><c> an</c>

00:33:22.810 --> 00:33:22.820 align:start position:0%
the RNN parent can learn to create an
 

00:33:22.820 --> 00:33:26.379 align:start position:0%
the RNN parent can learn to create an
even<00:33:23.210><c> better</c><00:33:23.450><c> child</c><00:33:24.019><c> model</c><00:33:24.559><c> right</c><00:33:25.190><c> so</c><00:33:26.090><c> this</c><00:33:26.240><c> is</c>

00:33:26.379 --> 00:33:26.389 align:start position:0%
even better child model right so this is
 

00:33:26.389 --> 00:33:28.149 align:start position:0%
even better child model right so this is
a<00:33:26.419><c> really</c><00:33:26.690><c> powerful</c><00:33:27.230><c> idea</c><00:33:27.409><c> and</c><00:33:27.799><c> what</c><00:33:27.980><c> does</c><00:33:28.130><c> it</c>

00:33:28.149 --> 00:33:28.159 align:start position:0%
a really powerful idea and what does it
 

00:33:28.159 --> 00:33:31.779 align:start position:0%
a really powerful idea and what does it
mean<00:33:28.279><c> for</c><00:33:29.120><c> us</c><00:33:29.179><c> in</c><00:33:29.720><c> practice</c><00:33:30.080><c> well</c><00:33:31.070><c> Google</c><00:33:31.759><c> has</c>

00:33:31.779 --> 00:33:31.789 align:start position:0%
mean for us in practice well Google has
 

00:33:31.789 --> 00:33:34.240 align:start position:0%
mean for us in practice well Google has
now<00:33:32.059><c> put</c><00:33:32.360><c> the</c><00:33:32.480><c> service</c><00:33:32.899><c> on</c><00:33:33.169><c> the</c><00:33:33.320><c> cloud</c><00:33:33.470><c> Google</c>

00:33:34.240 --> 00:33:34.250 align:start position:0%
now put the service on the cloud Google
 

00:33:34.250 --> 00:33:37.120 align:start position:0%
now put the service on the cloud Google
being<00:33:34.399><c> Google</c><00:33:34.490><c> right</c><00:33:35.029><c> so</c><00:33:35.779><c> that</c><00:33:36.440><c> you</c><00:33:36.590><c> can</c><00:33:36.740><c> go</c><00:33:36.919><c> in</c>

00:33:37.120 --> 00:33:37.130 align:start position:0%
being Google right so that you can go in
 

00:33:37.130 --> 00:33:41.919 align:start position:0%
being Google right so that you can go in
provide<00:33:37.880><c> the</c><00:33:38.840><c> auto</c><00:33:39.019><c> Amell</c><00:33:40.210><c> system</c><00:33:41.210><c> a</c><00:33:41.360><c> data</c><00:33:41.659><c> set</c>

00:33:41.919 --> 00:33:41.929 align:start position:0%
provide the auto Amell system a data set
 

00:33:41.929 --> 00:33:44.320 align:start position:0%
provide the auto Amell system a data set
and<00:33:42.110><c> a</c><00:33:42.529><c> set</c><00:33:42.740><c> of</c><00:33:42.830><c> metrics</c><00:33:43.070><c> that</c><00:33:43.519><c> you</c><00:33:43.669><c> wanted</c><00:33:44.120><c> to</c>

00:33:44.320 --> 00:33:44.330 align:start position:0%
and a set of metrics that you wanted to
 

00:33:44.330 --> 00:33:47.080 align:start position:0%
and a set of metrics that you wanted to
optimize<00:33:44.779><c> over</c><00:33:45.289><c> and</c><00:33:45.500><c> they</c><00:33:46.039><c> will</c><00:33:46.220><c> use</c><00:33:46.490><c> parent</c>

00:33:47.080 --> 00:33:47.090 align:start position:0%
optimize over and they will use parent
 

00:33:47.090 --> 00:33:50.169 align:start position:0%
optimize over and they will use parent
RNN<00:33:47.600><c> controllers</c><00:33:48.259><c> to</c><00:33:48.830><c> generate</c><00:33:49.309><c> a</c><00:33:49.519><c> candidate</c>

00:33:50.169 --> 00:33:50.179 align:start position:0%
RNN controllers to generate a candidate
 

00:33:50.179 --> 00:33:52.899 align:start position:0%
RNN controllers to generate a candidate
child<00:33:50.480><c> Network</c><00:33:50.960><c> that's</c><00:33:51.740><c> designed</c><00:33:52.370><c> to</c><00:33:52.519><c> train</c>

00:33:52.899 --> 00:33:52.909 align:start position:0%
child Network that's designed to train
 

00:33:52.909 --> 00:33:55.570 align:start position:0%
child Network that's designed to train
optimally<00:33:53.600><c> on</c><00:33:53.629><c> your</c><00:33:54.049><c> data</c><00:33:54.289><c> set</c><00:33:54.559><c> for</c><00:33:55.100><c> your</c><00:33:55.309><c> task</c>

00:33:55.570 --> 00:33:55.580 align:start position:0%
optimally on your data set for your task
 

00:33:55.580 --> 00:33:58.570 align:start position:0%
optimally on your data set for your task
right<00:33:56.210><c> and</c><00:33:56.509><c> this</c><00:33:57.289><c> end</c><00:33:57.559><c> result</c><00:33:57.889><c> is</c><00:33:58.039><c> this</c><00:33:58.340><c> new</c>

00:33:58.570 --> 00:33:58.580 align:start position:0%
right and this end result is this new
 

00:33:58.580 --> 00:34:00.340 align:start position:0%
right and this end result is this new
child<00:33:58.909><c> network</c><00:33:59.299><c> that</c><00:33:59.480><c> it</c><00:33:59.570><c> gives</c><00:33:59.809><c> back</c><00:34:00.019><c> to</c><00:34:00.049><c> you</c>

00:34:00.340 --> 00:34:00.350 align:start position:0%
child network that it gives back to you
 

00:34:00.350 --> 00:34:03.430 align:start position:0%
child network that it gives back to you
spawned<00:34:01.220><c> from</c><00:34:01.519><c> this</c><00:34:01.669><c> rnm</c><00:34:02.090><c> controller</c><00:34:02.539><c> which</c>

00:34:03.430 --> 00:34:03.440 align:start position:0%
spawned from this rnm controller which
 

00:34:03.440 --> 00:34:05.740 align:start position:0%
spawned from this rnm controller which
you<00:34:03.590><c> can</c><00:34:03.740><c> then</c><00:34:03.950><c> go</c><00:34:04.190><c> and</c><00:34:04.460><c> deploy</c><00:34:04.789><c> on</c><00:34:05.179><c> your</c><00:34:05.539><c> data</c>

00:34:05.740 --> 00:34:05.750 align:start position:0%
you can then go and deploy on your data
 

00:34:05.750 --> 00:34:08.619 align:start position:0%
you can then go and deploy on your data
set<00:34:06.049><c> right</c><00:34:06.730><c> this</c><00:34:07.730><c> is</c><00:34:07.909><c> a</c><00:34:07.940><c> pretty</c><00:34:08.240><c> big</c><00:34:08.450><c> deal</c>

00:34:08.619 --> 00:34:08.629 align:start position:0%
set right this is a pretty big deal
 

00:34:08.629 --> 00:34:12.220 align:start position:0%
set right this is a pretty big deal
right<00:34:09.079><c> and</c><00:34:10.089><c> it</c><00:34:11.089><c> sort</c><00:34:11.389><c> of</c><00:34:11.450><c> gets</c><00:34:11.599><c> that</c><00:34:11.810><c> sort</c><00:34:12.200><c> of</c>

00:34:12.220 --> 00:34:12.230 align:start position:0%
right and it sort of gets that sort of
 

00:34:12.230 --> 00:34:14.919 align:start position:0%
right and it sort of gets that sort of
this<00:34:12.409><c> deeper</c><00:34:12.800><c> question</c><00:34:13.369><c> right</c><00:34:13.929><c> they've</c>

00:34:14.919 --> 00:34:14.929 align:start position:0%
this deeper question right they've
 

00:34:14.929 --> 00:34:17.020 align:start position:0%
this deeper question right they've
demonstrated<00:34:15.169><c> that</c><00:34:15.770><c> we</c><00:34:15.889><c> can</c><00:34:16.069><c> create</c><00:34:16.339><c> these</c><00:34:16.669><c> AI</c>

00:34:17.020 --> 00:34:17.030 align:start position:0%
demonstrated that we can create these AI
 

00:34:17.030 --> 00:34:20.909 align:start position:0%
demonstrated that we can create these AI
systems<00:34:17.839><c> that</c><00:34:18.079><c> can</c><00:34:18.530><c> generate</c><00:34:18.919><c> new</c><00:34:19.879><c> AI</c>

00:34:20.909 --> 00:34:20.919 align:start position:0%
systems that can generate new AI
 

00:34:20.919 --> 00:34:25.510 align:start position:0%
systems that can generate new AI
specifically<00:34:21.919><c> designed</c><00:34:22.310><c> to</c><00:34:22.490><c> solve</c><00:34:24.520><c> Mazar</c>

00:34:25.510 --> 00:34:25.520 align:start position:0%
specifically designed to solve Mazar
 

00:34:25.520 --> 00:34:28.030 align:start position:0%
specifically designed to solve Mazar
tasks<00:34:26.149><c> right</c><00:34:26.359><c> and</c><00:34:26.659><c> this</c><00:34:27.290><c> significantly</c>

00:34:28.030 --> 00:34:28.040 align:start position:0%
tasks right and this significantly
 

00:34:28.040 --> 00:34:30.359 align:start position:0%
tasks right and this significantly
reduces<00:34:28.270><c> sort</c><00:34:29.270><c> of</c><00:34:29.359><c> the</c><00:34:29.480><c> difficulties</c><00:34:30.139><c> that</c>

00:34:30.359 --> 00:34:30.369 align:start position:0%
reduces sort of the difficulties that
 

00:34:30.369 --> 00:34:32.980 align:start position:0%
reduces sort of the difficulties that
machine<00:34:31.369><c> learning</c><00:34:31.669><c> engineers</c><00:34:32.149><c> face</c><00:34:32.450><c> in</c><00:34:32.780><c> terms</c>

00:34:32.980 --> 00:34:32.990 align:start position:0%
machine learning engineers face in terms
 

00:34:32.990 --> 00:34:36.960 align:start position:0%
machine learning engineers face in terms
of<00:34:33.169><c> optimizing</c><00:34:33.919><c> a</c><00:34:34.369><c> network</c><00:34:34.790><c> architecture</c><00:34:35.649><c> for</c>

00:34:36.960 --> 00:34:36.970 align:start position:0%
of optimizing a network architecture for
 

00:34:36.970 --> 00:34:40.659 align:start position:0%
of optimizing a network architecture for
for<00:34:37.970><c> a</c><00:34:38.000><c> different</c><00:34:38.359><c> task</c><00:34:38.540><c> right</c><00:34:39.050><c> and</c><00:34:39.460><c> this</c><00:34:40.460><c> sort</c>

00:34:40.659 --> 00:34:40.669 align:start position:0%
for a different task right and this sort
 

00:34:40.669 --> 00:34:43.480 align:start position:0%
for a different task right and this sort
of<00:34:40.760><c> gets</c><00:34:40.970><c> at</c><00:34:41.450><c> the</c><00:34:41.690><c> heart</c><00:34:41.720><c> of</c><00:34:42.109><c> the</c><00:34:43.040><c> question</c>

00:34:43.480 --> 00:34:43.490 align:start position:0%
of gets at the heart of the question
 

00:34:43.490 --> 00:34:45.909 align:start position:0%
of gets at the heart of the question
that<00:34:43.520><c> Alexander</c><00:34:44.300><c> proposed</c><00:34:44.810><c> at</c><00:34:45.139><c> the</c><00:34:45.349><c> beginning</c>

00:34:45.909 --> 00:34:45.919 align:start position:0%
that Alexander proposed at the beginning
 

00:34:45.919 --> 00:34:48.700 align:start position:0%
that Alexander proposed at the beginning
of<00:34:46.159><c> this</c><00:34:46.879><c> course</c><00:34:47.149><c> right</c><00:34:47.510><c> this</c><00:34:48.079><c> notion</c><00:34:48.349><c> of</c>

00:34:48.700 --> 00:34:48.710 align:start position:0%
of this course right this notion of
 

00:34:48.710 --> 00:34:51.129 align:start position:0%
of this course right this notion of
generalized<00:34:49.550><c> artificial</c><00:34:50.179><c> intelligence</c><00:34:50.750><c> and</c>

00:34:51.129 --> 00:34:51.139 align:start position:0%
generalized artificial intelligence and
 

00:34:51.139 --> 00:34:53.619 align:start position:0%
generalized artificial intelligence and
we<00:34:51.740><c> spoke</c><00:34:51.950><c> about</c><00:34:52.010><c> a</c><00:34:52.280><c> bit</c><00:34:52.639><c> about</c><00:34:52.879><c> what</c><00:34:53.300><c> it</c><00:34:53.419><c> means</c>

00:34:53.619 --> 00:34:53.629 align:start position:0%
we spoke about a bit about what it means
 

00:34:53.629 --> 00:34:55.899 align:start position:0%
we spoke about a bit about what it means
to<00:34:53.869><c> be</c><00:34:53.960><c> intelligent</c><00:34:54.560><c> right</c><00:34:54.859><c> loosely</c><00:34:55.700><c> speaking</c>

00:34:55.899 --> 00:34:55.909 align:start position:0%
to be intelligent right loosely speaking
 

00:34:55.909 --> 00:34:59.710 align:start position:0%
to be intelligent right loosely speaking
the<00:34:56.359><c> sense</c><00:34:56.599><c> of</c><00:34:56.950><c> taking</c><00:34:57.950><c> in</c><00:34:58.069><c> information</c><00:34:58.720><c> using</c>

00:34:59.710 --> 00:34:59.720 align:start position:0%
the sense of taking in information using
 

00:34:59.720 --> 00:35:02.650 align:start position:0%
the sense of taking in information using
it<00:34:59.869><c> to</c><00:35:00.050><c> inform</c><00:35:00.500><c> a</c><00:35:00.650><c> future</c><00:35:00.980><c> decision</c><00:35:01.400><c> and</c><00:35:01.660><c> as</c>

00:35:02.650 --> 00:35:02.660 align:start position:0%
it to inform a future decision and as
 

00:35:02.660 --> 00:35:04.720 align:start position:0%
it to inform a future decision and as
humans<00:35:03.200><c> our</c><00:35:03.380><c> learning</c><00:35:03.829><c> pipeline</c><00:35:04.280><c> is</c><00:35:04.490><c> not</c>

00:35:04.720 --> 00:35:04.730 align:start position:0%
humans our learning pipeline is not
 

00:35:04.730 --> 00:35:07.960 align:start position:0%
humans our learning pipeline is not
restricted<00:35:05.690><c> to</c><00:35:06.130><c> solving</c><00:35:07.130><c> only</c><00:35:07.250><c> specific</c>

00:35:07.960 --> 00:35:07.970 align:start position:0%
restricted to solving only specific
 

00:35:07.970 --> 00:35:11.140 align:start position:0%
restricted to solving only specific
defined<00:35:08.660><c> tasks</c><00:35:09.290><c> how</c><00:35:09.950><c> we</c><00:35:10.010><c> learn</c><00:35:10.369><c> one</c><00:35:10.579><c> task</c><00:35:10.849><c> can</c>

00:35:11.140 --> 00:35:11.150 align:start position:0%
defined tasks how we learn one task can
 

00:35:11.150 --> 00:35:16.569 align:start position:0%
defined tasks how we learn one task can
impact<00:35:11.540><c> you</c><00:35:11.900><c> know</c><00:35:12.020><c> what</c><00:35:12.770><c> we</c><00:35:13.040><c> do</c><00:35:15.220><c> on</c><00:35:16.220><c> something</c>

00:35:16.569 --> 00:35:16.579 align:start position:0%
impact you know what we do on something
 

00:35:16.579 --> 00:35:17.859 align:start position:0%
impact you know what we do on something
something<00:35:16.790><c> completely</c><00:35:17.270><c> unrelated</c>

00:35:17.859 --> 00:35:17.869 align:start position:0%
something completely unrelated
 

00:35:17.869 --> 00:35:23.470 align:start position:0%
something completely unrelated
completely<00:35:18.710><c> separate</c><00:35:19.160><c> right</c><00:35:19.339><c> and</c><00:35:21.730><c> in</c><00:35:22.730><c> order</c>

00:35:23.470 --> 00:35:23.480 align:start position:0%
completely separate right and in order
 

00:35:23.480 --> 00:35:26.790 align:start position:0%
completely separate right and in order
to<00:35:23.510><c> reach</c><00:35:23.930><c> sort</c><00:35:24.680><c> of</c><00:35:24.770><c> that</c><00:35:24.890><c> same</c><00:35:25.220><c> level</c><00:35:25.609><c> with</c><00:35:26.420><c> AI</c>

00:35:26.790 --> 00:35:26.800 align:start position:0%
to reach sort of that same level with AI
 

00:35:26.800 --> 00:35:29.710 align:start position:0%
to reach sort of that same level with AI
we<00:35:27.800><c> really</c><00:35:28.099><c> need</c><00:35:28.250><c> to</c><00:35:28.369><c> build</c><00:35:28.609><c> systems</c><00:35:29.210><c> that</c><00:35:29.359><c> can</c>

00:35:29.710 --> 00:35:29.720 align:start position:0%
we really need to build systems that can
 

00:35:29.720 --> 00:35:30.310 align:start position:0%
we really need to build systems that can
not<00:35:29.900><c> only</c>

00:35:30.310 --> 00:35:30.320 align:start position:0%
not only
 

00:35:30.320 --> 00:35:33.280 align:start position:0%
not only
learn<00:35:30.470><c> single</c><00:35:31.370><c> tasks</c><00:35:31.880><c> but</c><00:35:32.420><c> can</c><00:35:32.600><c> improve</c><00:35:33.050><c> their</c>

00:35:33.280 --> 00:35:33.290 align:start position:0%
learn single tasks but can improve their
 

00:35:33.290 --> 00:35:36.220 align:start position:0%
learn single tasks but can improve their
own<00:35:33.440><c> learning</c><00:35:33.740><c> and</c><00:35:34.130><c> their</c><00:35:35.000><c> reasoning</c><00:35:35.420><c> so</c><00:35:36.140><c> as</c>

00:35:36.220 --> 00:35:36.230 align:start position:0%
own learning and their reasoning so as
 

00:35:36.230 --> 00:35:38.860 align:start position:0%
own learning and their reasoning so as
to<00:35:36.380><c> be</c><00:35:36.500><c> able</c><00:35:36.590><c> to</c><00:35:36.890><c> generalize</c><00:35:37.340><c> well</c><00:35:37.790><c> two</c><00:35:38.570><c> sets</c>

00:35:38.860 --> 00:35:38.870 align:start position:0%
to be able to generalize well two sets
 

00:35:38.870 --> 00:35:43.600 align:start position:0%
to be able to generalize well two sets
of<00:35:39.110><c> related</c><00:35:39.830><c> and</c><00:35:40.210><c> dependent</c><00:35:41.210><c> tasks</c><00:35:41.830><c> so</c><00:35:42.830><c> I'll</c>

00:35:43.600 --> 00:35:43.610 align:start position:0%
of related and dependent tasks so I'll
 

00:35:43.610 --> 00:35:45.550 align:start position:0%
of related and dependent tasks so I'll
leave<00:35:43.910><c> you</c><00:35:43.970><c> with</c><00:35:44.240><c> this</c><00:35:44.390><c> thought</c><00:35:44.450><c> and</c><00:35:45.020><c> I</c>

00:35:45.550 --> 00:35:45.560 align:start position:0%
leave you with this thought and I
 

00:35:45.560 --> 00:35:48.400 align:start position:0%
leave you with this thought and I
encourage<00:35:46.100><c> you</c><00:35:46.130><c> to</c><00:35:46.540><c> to</c><00:35:47.540><c> continue</c><00:35:47.870><c> to</c><00:35:48.230><c> discuss</c>

00:35:48.400 --> 00:35:48.410 align:start position:0%
encourage you to to continue to discuss
 

00:35:48.410 --> 00:35:51.040 align:start position:0%
encourage you to to continue to discuss
and<00:35:48.830><c> think</c><00:35:49.010><c> about</c><00:35:49.220><c> these</c><00:35:49.370><c> ideas</c><00:35:50.050><c> amongst</c>

00:35:51.040 --> 00:35:51.050 align:start position:0%
and think about these ideas amongst
 

00:35:51.050 --> 00:35:52.780 align:start position:0%
and think about these ideas amongst
yourselves<00:35:51.430><c> internally</c><00:35:52.430><c> through</c>

00:35:52.780 --> 00:35:52.790 align:start position:0%
yourselves internally through
 

00:35:52.790 --> 00:35:55.150 align:start position:0%
yourselves internally through
introspection<00:35:53.450><c> and</c><00:35:54.140><c> also</c><00:35:54.440><c> we're</c><00:35:54.680><c> happy</c><00:35:54.980><c> to</c>

00:35:55.150 --> 00:35:55.160 align:start position:0%
introspection and also we're happy to
 

00:35:55.160 --> 00:35:58.420 align:start position:0%
introspection and also we're happy to
chat<00:35:55.400><c> and</c><00:35:56.210><c> I</c><00:35:56.600><c> think</c><00:35:57.350><c> I</c><00:35:57.470><c> can</c><00:35:57.650><c> speak</c><00:35:57.830><c> for</c><00:35:57.890><c> the</c><00:35:58.130><c> TAS</c>

00:35:58.420 --> 00:35:58.430 align:start position:0%
chat and I think I can speak for the TAS
 

00:35:58.430 --> 00:36:00.460 align:start position:0%
chat and I think I can speak for the TAS
in<00:35:58.670><c> saying</c><00:35:59.240><c> that</c><00:35:59.420><c> they're</c><00:35:59.600><c> happy</c><00:35:59.900><c> to</c><00:36:00.050><c> chat</c><00:36:00.230><c> as</c>

00:36:00.460 --> 00:36:00.470 align:start position:0%
in saying that they're happy to chat as
 

00:36:00.470 --> 00:36:04.420 align:start position:0%
in saying that they're happy to chat as
well<00:36:00.910><c> so</c><00:36:01.910><c> that</c><00:36:02.870><c> concludes</c><00:36:03.110><c> you</c><00:36:03.770><c> know</c><00:36:03.890><c> the</c>

00:36:04.420 --> 00:36:04.430 align:start position:0%
well so that concludes you know the
 

00:36:04.430 --> 00:36:06.520 align:start position:0%
well so that concludes you know the
series<00:36:04.760><c> of</c><00:36:04.910><c> lectures</c><00:36:05.030><c> from</c><00:36:05.630><c> Alexander</c><00:36:06.290><c> and</c><00:36:06.440><c> I</c>

00:36:06.520 --> 00:36:06.530 align:start position:0%
series of lectures from Alexander and I
 

00:36:06.530 --> 00:36:08.860 align:start position:0%
series of lectures from Alexander and I
and<00:36:06.770><c> we'll</c><00:36:07.310><c> have</c><00:36:07.550><c> our</c><00:36:07.940><c> three</c><00:36:08.180><c> guest</c><00:36:08.450><c> lecturers</c>

00:36:08.860 --> 00:36:08.870 align:start position:0%
and we'll have our three guest lecturers
 

00:36:08.870 --> 00:36:11.620 align:start position:0%
and we'll have our three guest lecturers
over<00:36:09.200><c> the</c><00:36:09.710><c> next</c><00:36:09.920><c> couple</c><00:36:10.160><c> of</c><00:36:10.370><c> days</c><00:36:10.580><c> and</c><00:36:10.880><c> then</c>

00:36:11.620 --> 00:36:11.630 align:start position:0%
over the next couple of days and then
 

00:36:11.630 --> 00:36:13.510 align:start position:0%
over the next couple of days and then
we'll<00:36:11.870><c> have</c><00:36:12.080><c> the</c><00:36:12.470><c> final</c><00:36:13.070><c> lab</c><00:36:13.250><c> on</c>

00:36:13.510 --> 00:36:13.520 align:start position:0%
we'll have the final lab on
 

00:36:13.520 --> 00:36:16.260 align:start position:0%
we'll have the final lab on
reinforcement<00:36:14.480><c> learning</c><00:36:14.570><c> thank</c><00:36:15.470><c> you</c>

00:36:16.260 --> 00:36:16.270 align:start position:0%
reinforcement learning thank you
 

00:36:16.270 --> 00:36:21.869 align:start position:0%
reinforcement learning thank you
[Applause]

