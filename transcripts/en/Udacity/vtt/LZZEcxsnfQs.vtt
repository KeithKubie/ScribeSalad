WEBVTT
Kind: captions
Language: en

00:00:00.170 --> 00:00:02.520
We're going to look at K-means as an optimization problem. So

00:00:02.520 --> 00:00:06.440
remember when we talked about optimization we worried about configurations, I

00:00:06.440 --> 00:00:08.500
think we called them inputs at that time but I think

00:00:08.500 --> 00:00:10.950
it's going to be helpful to think of them as, as configurations

00:00:10.950 --> 00:00:13.360
here. There was a way of scoring configurations and we were

00:00:13.360 --> 00:00:17.240
trying to find configurations that had high score. And for some

00:00:17.240 --> 00:00:19.720
of the algorithms we needed a notion of a neighborhood so

00:00:19.720 --> 00:00:22.930
that we could move from configuration to configuration trying to improve.

00:00:22.930 --> 00:00:24.340
&gt;&gt; Mm-hm.

00:00:25.430 --> 00:00:27.150
&gt;&gt; So in this setting, the configuration, the thing

00:00:27.150 --> 00:00:30.680
that we're optimizing over, is the partitions, the clusters,

00:00:30.680 --> 00:00:32.740
and we also have this kind of auxiliary variable

00:00:32.740 --> 00:00:34.870
of where the centers are for those clusters. And

00:00:34.870 --> 00:00:37.100
what we need now is a notion of scores.

00:00:37.100 --> 00:00:40.920
How do we score a particular clustering? So do

00:00:40.920 --> 00:00:42.220
you have any thoughts about what would be a

00:00:42.220 --> 00:00:45.880
better or worse clustering according to the kind of K-means algorithm?

00:00:45.880 --> 00:00:46.950
&gt;&gt; Well, the thing about what you were

00:00:46.950 --> 00:00:50.430
saying earlier, about what we were trying to do

00:00:50.430 --> 00:00:52.310
with creating these clusters, and I look at

00:00:52.310 --> 00:00:54.330
this notion of a center, so something pops in

00:00:54.330 --> 00:00:58.260
my head. So, you would like to have centers or

00:00:59.520 --> 00:01:04.910
partitions that somehow are good representations of your

00:01:04.910 --> 00:01:07.190
data, and why does that matter? Because you

00:01:07.190 --> 00:01:09.220
said in the very beginning that we often think

00:01:09.220 --> 00:01:13.490
of unsupervised learning as compact representation. So if you

00:01:13.490 --> 00:01:15.520
want to have a compact representation it would be nice

00:01:15.520 --> 00:01:19.550
if you don't throw anything away. So, I'm going to say

00:01:19.550 --> 00:01:22.510
that a good score will be something that captures just

00:01:22.510 --> 00:01:27.520
how much error you introduce by representing these points as

00:01:27.520 --> 00:01:31.740
partitions or in this case as centers. Does that make sense?

00:01:31.740 --> 00:01:35.160
&gt;&gt; Okay. I guess that's a, that's a perfectly

00:01:35.160 --> 00:01:36.750
reasonable way to think of it. I, another way to

00:01:36.750 --> 00:01:39.256
think of it is in terms of error, right. Yeah,

00:01:39.256 --> 00:01:40.650
which I guess is the same idea. Like if we're,

00:01:40.650 --> 00:01:45.410
if you think about the object as being represented by the center of its cluster.

00:01:45.410 --> 00:01:46.023
&gt;&gt; Mm-hm.

00:01:46.023 --> 00:01:48.100
&gt;&gt; Then we want to know how far away from the center it is.

00:01:48.100 --> 00:01:50.100
&gt;&gt; Right. And the farther away it is,

00:01:50.100 --> 00:01:52.880
the more error you have in representing it.

00:01:52.880 --> 00:01:56.180
&gt;&gt; Right. So, here is a concrete of writing down what we

00:01:56.180 --> 00:01:59.610
think the scoring function could be. So we're going to say that the

00:01:59.610 --> 00:02:02.220
error, it's kind of the negative score, right? This is something that

00:02:02.220 --> 00:02:04.175
we want to minimize even though generally,

00:02:04.175 --> 00:02:06.120
we've been talking about optimization as maximizing.

00:02:06.120 --> 00:02:08.220
Here is something we want to minimize. That if you

00:02:08.220 --> 00:02:10.210
give me a particular way of clustering it and

00:02:10.210 --> 00:02:13.800
you define the centers based on, say, that cluster,

00:02:13.800 --> 00:02:14.660
what we're going to do is we're going to

00:02:14.660 --> 00:02:19.920
sum over all the objects the distance, the square distance actually, between

00:02:19.920 --> 00:02:25.470
the object and its center. Right? So p of x is the

00:02:25.470 --> 00:02:30.670
cluster for x and center sub that is the center for that cluster.

00:02:30.670 --> 00:02:31.170
&gt;&gt; So that drives

00:02:31.170 --> 00:02:34.880
home the idea that we're talking about Euclidean distance here because x would

00:02:34.880 --> 00:02:39.010
have to be in the same space as the centers are by definition. Okay.

00:02:41.400 --> 00:02:43.280
&gt;&gt; Yeah, and I'm not sure exactly how we're

00:02:43.280 --> 00:02:46.740
going to define neighborhood. But one way to define

00:02:46.740 --> 00:02:50.350
neighborhood is that the neighborhood of a configuration, which

00:02:50.350 --> 00:02:52.800
is a p and a center is the set

00:02:52.800 --> 00:02:55.770
of pairs where you keep the centers the same

00:02:55.770 --> 00:02:58.630
and you change the partitions. Or you keep the

00:02:58.630 --> 00:03:00.540
partitions the same and you move the centers. So

00:03:00.540 --> 00:03:02.350
you're basically changing one of these at a time.

00:03:02.350 --> 00:03:04.200
&gt;&gt; Oh, that's very clever, Michael.

00:03:04.200 --> 00:03:05.010
&gt;&gt; Thanks.

