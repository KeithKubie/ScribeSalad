WEBVTT
Kind: captions
Language: en

00:00:02.920 --> 00:00:06.160
Hi, I’m Adriene Hill, and Welcome back to
Crash Course, Statistics.

00:00:06.160 --> 00:00:11.200
Bayesian Hypothesis Testing--or Bayesian Inference--is a great way to model the way we reason about

00:00:11.200 --> 00:00:13.040
things in everyday life.

00:00:13.040 --> 00:00:17.630
We collect evidence and experience and we
use it to build our beliefs about the world.

00:00:17.630 --> 00:00:21.380
We collect information on whether certain
facial expressions mean that someone is upset.

00:00:21.380 --> 00:00:24.880
Whether clouds outside mean it’s going to
be cold today.

00:00:24.890 --> 00:00:27.960
Or whether people who smoke are more likely to have lung cancer.

00:00:27.960 --> 00:00:32.220
But Bayesian methods are useful above and beyond updating our personal beliefs.

00:00:32.220 --> 00:00:36.540
Bayes has helped companies make marketing decisions--like which color to use on their website.

00:00:36.640 --> 00:00:40.280
And it has helped researchers to quantify
their results in scientific studies.

00:00:40.280 --> 00:00:42.140
And today, we’re going to talk about it.

00:00:42.140 --> 00:00:51.280
INTRO

00:00:51.280 --> 00:00:55.360
First, you may have noticed that so far when we talk about the math of Bayes’ Theorem,

00:00:55.360 --> 00:00:59.580
we’ve been using discrete variables, like
whether or not you’re a star wars fan, or

00:00:59.580 --> 00:01:01.150
whether or not you have a disease.

00:01:01.150 --> 00:01:05.990
But Bayes’ Theorem can help us update beliefs that involve continuous variables too.

00:01:05.990 --> 00:01:09.750
The math of Bayes’ Theorem with a continuous variable is a bit more complicated than in

00:01:09.750 --> 00:01:11.000
the discrete case.

00:01:11.000 --> 00:01:15.980
Science writer Sharon Bertsch McGrayne called it, “a Theorem in want of a computer...”.

00:01:15.980 --> 00:01:21.340
In fact for much of the 20th century, Scientists and Statisticians who wanted to use Bayes

00:01:21.340 --> 00:01:25.649
were limited in their ability to do so by
a lack of computational power.

00:01:25.649 --> 00:01:28.469
But we still want answers to those more complicated problems.

00:01:28.469 --> 00:01:32.980
Sometimes we want to know whether dogs who are walked regularly are less likely to damage furniture.

00:01:32.980 --> 00:01:38.880
Or whether House Elves have lower intelligence than Wizards...which is an example of Bayesian

00:01:38.890 --> 00:01:43.060
Hypothesis testing from a Harry Potter themed article by Alexander Etz and Joachim Vandekerckhove.

00:01:43.070 --> 00:01:47.799
Guess you’d better update your prior belief
about how cool statisticians are😎.

00:01:47.799 --> 00:01:52.899
The ideas behind continuous and discrete Bayesian Inference are exactly the same.

00:01:52.899 --> 00:01:58.030
We take our prior beliefs--what we believe
before we’ve seen new evidence--and update

00:01:58.030 --> 00:02:00.319
it with the likelihood of our evidence.

00:02:00.319 --> 00:02:03.819
This is called the Bayes Factor when comparing two models.

00:02:03.819 --> 00:02:06.880
Once we’ve updated, our new beliefs are
called our “Posterior” beliefs.

00:02:06.880 --> 00:02:11.160
If we’re comparing two models, they are
called our posterior odds.

00:02:11.160 --> 00:02:15.870
But instead of simple, discrete probabilities, we have probability distributions.

00:02:15.870 --> 00:02:20.920
For example, let’s look at the ever present
problem of whether or not a coin is biased.

00:02:20.920 --> 00:02:24.040
Before you start your experiment to test the
fairness of your coin, you decide that you

00:02:24.040 --> 00:02:27.210
know almost nothing about whether or not it’s biased.

00:02:27.210 --> 00:02:32.350
So your prior probability of getting tails
is a uniform distribution between 0 (never

00:02:32.350 --> 00:02:34.640
tails) and 1(always tails).

00:02:34.640 --> 00:02:39.830
You consider all probabilities of getting
tails--we’ll call that theta--equally likely.

00:02:39.830 --> 00:02:43.390
You have a friend flip the coin in question
5 times, and they get 1 tail.

00:02:43.390 --> 00:02:47.750
Which seems unlikely, though not impossible for a fair coin.

00:02:47.750 --> 00:02:52.350
Using the Binomial Probability Formula we
know that the probability of this happening

00:02:52.350 --> 00:02:55.690
with a fair coin is about 16%.

00:02:55.690 --> 00:03:00.660
Note this new notation for 5 choose 1, you’re most likely to run into this in the stats world.

00:03:00.660 --> 00:03:04.780
So how does this evidence update your belief about what the real probability of getting

00:03:04.780 --> 00:03:06.770
a tail is for this coin?

00:03:06.770 --> 00:03:10.900
Before we show the Bayesian calculation, let’s take a moment to figure out what we think

00:03:10.900 --> 00:03:12.100
without the math.

00:03:12.100 --> 00:03:16.820
Since we saw at least one head and one tails, we can rule out both the probabilities 0 and 1.

00:03:16.820 --> 00:03:21.900
And we think that probabilities very close
to 0 and 1 are unlikely too.

00:03:21.900 --> 00:03:27.620
Because it’d be REALLY rare to see only
one tail if the probability of tails were 0.99.

00:03:27.640 --> 00:03:33.100
And similarly rare to see a tail at all if
the probability were 0.001.

00:03:33.100 --> 00:03:36.210
Now we can do the Bayesian calculation and see if it matches our intuition.

00:03:36.210 --> 00:03:39.200
Here’s Bayes’ Theorem, but for this continuous problem:

00:03:39.200 --> 00:03:43.490
We won’t get too stuck on the math, but
we can see that this is the same old Bayes’

00:03:43.490 --> 00:03:46.130
Theorem that we’ve seen before...just continuous.

00:03:46.130 --> 00:03:50.840
When we plug in this formula to a graphing
program to show our posterior, it looks like this:

00:03:50.840 --> 00:03:55.980
The Y axis tells us the relative probability
of a theta--in this case theta is the probability

00:03:55.980 --> 00:04:01.940
of getting tails-- and the x axis shows us
all the possible values of theta between 0 and 1.

00:04:01.940 --> 00:04:05.340
We can see that we took our prior distribution (the dotted line)...

00:04:05.340 --> 00:04:10.400
and updated it using the likelihood of the
data, which told us the probability of getting

00:04:10.400 --> 00:04:15.990
1 out of 5 tails for EVERY potential probability of getting tails that a coin could have.

00:04:15.990 --> 00:04:21.620
Once we updated our prior beliefs, about which probabilities are the most likely, our posterior

00:04:21.620 --> 00:04:24.780
beliefs are represented like this (the solid
line).

00:04:24.780 --> 00:04:29.900
Anything on the curve that is above the dotted prior line represents a theta that became

00:04:29.920 --> 00:04:32.270
more likely after we saw the data.

00:04:32.270 --> 00:04:36.900
And anything on the curve that is below the
dotted line is a theta that became less likely.

00:04:36.900 --> 00:04:41.930
And this matches our intuition;
Thetas that are close to 1 and 0 became less

00:04:41.930 --> 00:04:46.900
likely, while thetas around 0.1-0.5 became
more likely.

00:04:46.900 --> 00:04:51.040
So maybe we have a fair coin here...but it
seems more likely that it’s biased.

00:04:51.040 --> 00:04:55.060
Businesses like Bayes because it allows them to take into account previous knowledge and

00:04:55.070 --> 00:04:57.380
expert opinion when they make their calculations.

00:04:57.389 --> 00:05:00.690
Let’s look at an example of how a business
might use Bayesian inference.

00:05:00.690 --> 00:05:04.159
We’ll keep the math to a minimum, but if
you’re interested in learning more, you

00:05:04.159 --> 00:05:09.919
can check out this awesome blog post by Will Kurt on countbayesie.com which we based this

00:05:09.919 --> 00:05:11.039
next example on.

00:05:11.039 --> 00:05:12.229
And the link is in the description.

00:05:12.229 --> 00:05:16.240
Say you’re a beauty blogger, and you send
out weekly emails encouraging your followers

00:05:16.240 --> 00:05:18.300
to read your latest blog post.

00:05:18.300 --> 00:05:22.300
The more people who click, the more money you make, and so you want the most clickable

00:05:22.300 --> 00:05:23.300
emails ever.

00:05:23.300 --> 00:05:27.009
Your friend, who’s also in the blogging
business, told you that adding a picture at

00:05:27.009 --> 00:05:31.189
the top of your email gets more people to
click, but you want to test that idea out

00:05:31.189 --> 00:05:32.419
with your own readers.

00:05:32.419 --> 00:05:36.970
Normally, your click rate is around 30%, so
you decide to represent your prior beliefs

00:05:36.970 --> 00:05:39.729
about your true click rate using this function:

00:05:39.729 --> 00:05:44.189
Values around 30% are most likely, but it’s
possible your true click rates are higher

00:05:44.189 --> 00:05:45.509
or lower than that.

00:05:45.509 --> 00:05:50.060
You randomly select 300 of your followers
to be a part of your experiment--often called

00:05:50.060 --> 00:05:54.699
an A/B test in the business world--and send half the email with a cute picture of you

00:05:54.699 --> 00:05:57.870
with your poodle, Ginger as well as the normal
content.

00:05:57.870 --> 00:06:00.669
The other half gets your standard pictureless email.

00:06:00.669 --> 00:06:04.120
You anxiously await the results, anad three
days later you have them:

00:06:04.120 --> 00:06:08.729
You use the new information you have about your two emails to update your original beliefs

00:06:08.729 --> 00:06:10.080
about your click rate.

00:06:10.080 --> 00:06:14.110
Since the two groups were the same before
you assigned them to get either email No Dog

00:06:14.110 --> 00:06:18.440
Pictures or with Dog Pictures, you use the
same prior for both groups.

00:06:18.440 --> 00:06:22.650
Once you’ve incorporated this new evidence, your Posterior distributions look like this:

00:06:22.650 --> 00:06:27.180
And they tell you how likely each click rate
is under your new, posterior beliefs about

00:06:27.180 --> 00:06:28.180
each group.

00:06:28.180 --> 00:06:32.819
It looks like the group with pictures is likely
to have a higher click rate... but you can’t

00:06:32.819 --> 00:06:33.819
know for sure.

00:06:33.819 --> 00:06:37.270
One way to get more information to make your decision is to randomly simulate a bunch of

00:06:37.270 --> 00:06:38.910
samples - one at a time.

00:06:38.910 --> 00:06:44.030
The samples come from each of your two posterior distributions and then you count how often

00:06:44.030 --> 00:06:48.460
the group with pictures’ click rate is higher
than the group that didn’t get a picture

00:06:48.460 --> 00:06:49.539
in their email.

00:06:49.539 --> 00:06:53.569
That percentage will tell you roughly how
likely it is that the group that got pictures

00:06:53.569 --> 00:06:56.759
will have a higher click rate than the group
who did not.

00:06:56.759 --> 00:07:01.590
You decide that if in 70% of your simulation
samples the group with pictures has a higher

00:07:01.590 --> 00:07:06.039
click rate, you’ll include glamor shots
of Ginger in all your new emails.

00:07:06.039 --> 00:07:11.099
Using Bayesian methods to analyze this question allowed you to “inject” your own prior

00:07:11.100 --> 00:07:15.100
beliefs into the analysis, which is important
when making business decisions.

00:07:15.100 --> 00:07:20.100
Businesses often want to make the best decision in the most cost efficient way, which means

00:07:20.100 --> 00:07:24.639
taking advantage of all the information you
have; not only data, but prior knowledge of

00:07:24.639 --> 00:07:26.280
the field and expert opinion.

00:07:26.280 --> 00:07:30.580
Your prior knowledge about the click rate
of your emails made it possible for you to

00:07:30.580 --> 00:07:35.870
start your analysis knowing it’s pretty
unlikely your click rate was very near 0,

00:07:35.870 --> 00:07:37.490
or very near 1.

00:07:37.490 --> 00:07:40.500
Bayesian analyses can be incredibly useful
in science, as well.

00:07:40.500 --> 00:07:46.650
A study on Dissociative Identity Disorder
(or DID)--formerly called Multiple Personality

00:07:46.650 --> 00:07:51.599
Disorder--looked at whether people with D-I-D had different “memory” between personalities.

00:07:51.599 --> 00:07:56.099
If one person had two separate personalities, Bob and Alice, researchers were interested

00:07:56.099 --> 00:08:00.900
in whether something that person learned as “Bob” could be remembered by that person

00:08:00.900 --> 00:08:01.900
when they were “Alice”.

00:08:01.900 --> 00:08:06.759
In order to test this idea, participants were
shown a few pictures and told a story.

00:08:06.759 --> 00:08:11.360
They then waited a little while, and answered 15 multiple choice questions about the material.

00:08:11.360 --> 00:08:14.080
There were 3 different groups of participants:

00:08:14.080 --> 00:08:18.499
A group of DID patients - who were asked to learn the materials in one personality and

00:08:18.499 --> 00:08:21.680
switch to another personality before the test.

00:08:21.680 --> 00:08:26.990
A pretend amnesiacs group - without DID who did not see the materials.

00:08:27.000 --> 00:08:31.360
And a maligners group without DID who saw the materials but were told to pretend they

00:08:31.360 --> 00:08:34.640
hadn’t and answer as if they had never heard the story or

00:08:34.640 --> 00:08:35.320
seen the pictures.

00:08:35.320 --> 00:08:41.040
Researchers wanted to know whether the patients with DID, the people who had never seen the materials,

00:08:41.040 --> 00:08:46.880
and  the people who were pretending not to have seen the materials had the same mean accuracy on the test.

00:08:46.880 --> 00:08:52.980
This would help researchers and cognitive scientists understand more about how memory works in DID patients.

00:08:52.980 --> 00:08:57.900
Using Null Hypothesis Significance testing,
researchers could try to address whether all

00:08:57.900 --> 00:09:03.160
three groups had the same mean score on the test, but even if they rejected the null hypothesis

00:09:03.160 --> 00:09:08.089
that all three groups are the same, they wouldn’t be able to say how much more likely it was

00:09:08.089 --> 00:09:10.610
that all three groups were different.

00:09:10.610 --> 00:09:12.570
Bayesian methods can tell you that.

00:09:12.570 --> 00:09:15.870
And a Group of researchers did analyze the
data this way, and found out that the Bayes

00:09:15.870 --> 00:09:19.400
Factor for these models was about 4,000!

00:09:19.400 --> 00:09:24.300
That means that the data that the researchers saw should update our beliefs by a lot.

00:09:24.300 --> 00:09:29.600
No matter what you believed before hand, your updated beliefs will most likely reflect the

00:09:29.610 --> 00:09:34.200
fact that it’s more likely that these three
groups--DID patients, people who didn’t

00:09:34.209 --> 00:09:39.920
see the materials, and people who pretended not to see the materials--are three distinct groups.

00:09:39.920 --> 00:09:43.980
And it’s interesting, because it provides
evidence that people with DID may not just

00:09:43.980 --> 00:09:48.100
be pretending to not remember things that
were learned while they were in a different

00:09:48.100 --> 00:09:52.339
personality... but they may not quite be behaving the same as people who really had never seen

00:09:52.339 --> 00:09:57.630
the materials, which is what you might expect if two personalities were completely separate.

00:09:57.630 --> 00:10:02.460
And while Bayesian inference is increasingly popular in many scientific fields like Psychology,

00:10:02.460 --> 00:10:05.670
it’s also being used right now in many places near you.

00:10:05.670 --> 00:10:10.040
Bayesian methods are used to help translate one language to another, and to suggest which

00:10:10.040 --> 00:10:14.630
items you might buy next based on the fact that you just bought four silicone sponges,

00:10:14.630 --> 00:10:17.420
a Sandalwood Candle, and whiteboard markers.

00:10:17.420 --> 00:10:22.180
Bayes can help figure out which allergy medicine you’ll react best to based on your genetic profile.

00:10:22.180 --> 00:10:27.080
And Bayes plays a role in creating artificial
intelligence that can do pretty amazing things, like

00:10:27.080 --> 00:10:31.340
understanding that it’s more likely that
you said “Siri, Turn on the lights” and

00:10:31.360 --> 00:10:33.520
not “Siri, Learn all the Sites !”

00:10:33.520 --> 00:10:35.540
Thanks for watching, I’ll see you next time.

