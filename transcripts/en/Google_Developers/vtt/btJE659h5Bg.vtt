WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.478
[MUSIC PLAYING]

00:00:14.960 --> 00:00:15.740
RYAN BOYD: Hello, everyone.

00:00:15.740 --> 00:00:17.060
My name is Ryan Boyd.

00:00:17.060 --> 00:00:18.350
MICHAEL MANOOCHEHRI: And I'm
Michael Mannoochehri.

00:00:18.350 --> 00:00:19.720
RYAN BOYD: And today,
we're here for the

00:00:19.720 --> 00:00:21.130
Ryan and Michael Show.

00:00:21.130 --> 00:00:22.340
Welcome back.

00:00:22.340 --> 00:00:23.340
I think it's been awhile.

00:00:23.340 --> 00:00:25.590
It's probably been over a month
since we've last done

00:00:25.590 --> 00:00:26.700
the Michael and Ryan Show.

00:00:26.700 --> 00:00:27.610
MICHAEL MANOOCHEHRI:
It's been too long.

00:00:27.610 --> 00:00:28.490
RYAN BOYD: It's been too long.

00:00:28.490 --> 00:00:29.070
It's been too long.

00:00:29.070 --> 00:00:30.640
So I miss doing it.

00:00:30.640 --> 00:00:32.640
Hopefully, you miss
watching it.

00:00:32.640 --> 00:00:34.930
Today, we're here to talk about
sensory data collection

00:00:34.930 --> 00:00:36.750
and BigQuery analysis.

00:00:36.750 --> 00:00:39.820
So we're going to go through a
full data pipeline, an example

00:00:39.820 --> 00:00:44.270
pipeline of how to get data into
the Google Cloud Platform

00:00:44.270 --> 00:00:46.930
and then analyze it
with BigQuery.

00:00:46.930 --> 00:00:49.250
As we said, my name is Ryan
Boyd, and this is Michael

00:00:49.250 --> 00:00:53.740
Manoochehri, and here's our
Google+ and Twitter handles at

00:00:53.740 --> 00:00:55.550
the bottom of the screen.

00:00:55.550 --> 00:00:58.640
If you have any questions after
this event, feel free to

00:00:58.640 --> 00:01:00.120
reach out to us there.

00:01:00.120 --> 00:01:01.960
Of course, you should follow
the Google Cloud Platform

00:01:01.960 --> 00:01:04.590
Developers Plus page as well.

00:01:04.590 --> 00:01:07.970
And during this event, though,
if you're here live during the

00:01:07.970 --> 00:01:10.400
event, check out the
Google Moderator.

00:01:10.400 --> 00:01:13.580
So on the Google Developers Live
page, you should see a

00:01:13.580 --> 00:01:15.890
Moderator embedded in there.

00:01:15.890 --> 00:01:18.990
And check out that Moderator and
ask us any questions that

00:01:18.990 --> 00:01:22.120
you have, and we'll take some
time to answer those questions

00:01:22.120 --> 00:01:23.260
at the end.

00:01:23.260 --> 00:01:26.520
In addition, today for the first
time, we're going to be

00:01:26.520 --> 00:01:28.890
going through some of the Stack
Overflow questions from

00:01:28.890 --> 00:01:32.090
the week, the most interesting
Stack Overflow questions.

00:01:32.090 --> 00:01:33.670
MICHAEL MANOOCHEHRI: And if you
have some questions, we

00:01:33.670 --> 00:01:36.280
answer questions at the
Google-BigQuery tag on Stack

00:01:36.280 --> 00:01:37.700
Overflow, so please,
post them there.

00:01:37.700 --> 00:01:37.980
RYAN BOYD: Yeah.

00:01:37.980 --> 00:01:40.470
So we answer those live, but
we'll also go through some

00:01:40.470 --> 00:01:42.580
interesting ones on the show.

00:01:42.580 --> 00:01:43.030
All right.

00:01:43.030 --> 00:01:45.680
So let's dive into this.

00:01:45.680 --> 00:01:47.510
So first, we want to talk
about the pipeline, the

00:01:47.510 --> 00:01:51.690
pipeline that we built in
order to get data into

00:01:51.690 --> 00:01:55.620
BigQuery for analysis.

00:01:55.620 --> 00:01:58.610
And this pipeline looks
something like this.

00:01:58.610 --> 00:02:03.060
So we have on the left-hand side
here, this thing called

00:02:03.060 --> 00:02:05.130
an OBD2 adapter.

00:02:05.130 --> 00:02:10.530
OBD2 is the Onboard Diagnostics
Protocol, Version

00:02:10.530 --> 00:02:14.290
2, and what it allows
you to do is collect

00:02:14.290 --> 00:02:16.560
data from your car.

00:02:16.560 --> 00:02:18.210
So I recently got a new car.

00:02:18.210 --> 00:02:22.080
My last car was about 10 years
old, a little over 100,000

00:02:22.080 --> 00:02:25.250
miles, and decided
to call it a day.

00:02:25.250 --> 00:02:27.380
So I got a new car, and
I wanted to be a bit

00:02:27.380 --> 00:02:28.630
geeky with my car.

00:02:28.630 --> 00:02:31.270
So I wanted to get data
out of my car.

00:02:31.270 --> 00:02:33.750
And then I figured out, how
could I incorporate this into

00:02:33.750 --> 00:02:36.370
a work project so I can have
fun and get paid for

00:02:36.370 --> 00:02:37.990
it at the same time?

00:02:37.990 --> 00:02:39.700
It's always nice.

00:02:39.700 --> 00:02:43.270
And so this OBD2 connector
allows me to do just that.

00:02:43.270 --> 00:02:47.300
It's $15 or $20 on Amazon,
pretty cheap.

00:02:47.300 --> 00:02:52.360
And basically, it has a
Bluetooth radio in it so that

00:02:52.360 --> 00:02:55.020
when you collect data from your
car, you plug this into

00:02:55.020 --> 00:02:57.920
your car, it collects data,
and using Bluetooth, it

00:02:57.920 --> 00:03:01.470
communicates that data
over to my phone.

00:03:01.470 --> 00:03:02.350
MICHAEL MANOOCHEHRI: Ryan, I
wasn't familiar with this

00:03:02.350 --> 00:03:04.430
until you started this project,
but is that the kind

00:03:04.430 --> 00:03:06.790
of thing that mechanics
use for the

00:03:06.790 --> 00:03:08.050
telemetry from the car?

00:03:08.050 --> 00:03:08.950
RYAN BOYD: Yeah, exactly.

00:03:08.950 --> 00:03:13.300
So the Onboard Diagnostics
Connector, I think it exists

00:03:13.300 --> 00:03:16.470
in pretty much all modern cars,
and it's primarily used

00:03:16.470 --> 00:03:17.910
by mechanics.

00:03:17.910 --> 00:03:20.990
I think if you read the manual
in my car, it does warn

00:03:20.990 --> 00:03:24.130
against using it for any
hobbyist purposes.

00:03:24.130 --> 00:03:25.040
Don't tell my wife that.

00:03:25.040 --> 00:03:29.000
But it is primarily
used by mechanics.

00:03:29.000 --> 00:03:32.560
They also, in some of the other
cars, have more advanced

00:03:32.560 --> 00:03:34.740
versions of these connectors
that allow you to

00:03:34.740 --> 00:03:35.800
get even more data.

00:03:35.800 --> 00:03:39.740
So this might be 40 or 50 data
points, something like that,

00:03:39.740 --> 00:03:40.510
that it pulls out.

00:03:40.510 --> 00:03:44.310
But it's pretty fun nonetheless,
and it allows you

00:03:44.310 --> 00:03:47.800
to get data via Bluetooth over
to my Android phone.

00:03:47.800 --> 00:03:51.510
I carry my Android phone with me
all the time, so I can get

00:03:51.510 --> 00:03:54.530
data to my Android phone
over Bluetooth.

00:03:54.530 --> 00:03:57.400
And then my Android phone has
an app running on it that

00:03:57.400 --> 00:04:00.120
uploads that data up
to App Engine.

00:04:00.120 --> 00:04:04.100
So it just make simple HTTPS
posts up to App Engine and

00:04:04.100 --> 00:04:06.990
uploads all of the data
each time it's

00:04:06.990 --> 00:04:10.310
collected from the connector.

00:04:10.310 --> 00:04:13.220
And once the data is up in App
Engine, I have a goal to

00:04:13.220 --> 00:04:13.880
analyze it.

00:04:13.880 --> 00:04:17.070
I really want to crunch that
data, figure out how fast I'm

00:04:17.070 --> 00:04:18.300
going, things like that.

00:04:18.300 --> 00:04:22.290
So for that, I use Google
BigQuery, of course.

00:04:22.290 --> 00:04:25.040
And so I need a way to get the
data from App Engine to

00:04:25.040 --> 00:04:28.710
BigQuery, which we're going to
talk about here shortly.

00:04:28.710 --> 00:04:31.180
One of the other things that
I should mention here is

00:04:31.180 --> 00:04:34.720
although I'm just collecting,
in this case, data from my

00:04:34.720 --> 00:04:39.600
individual car, there's plenty
of different use cases here

00:04:39.600 --> 00:04:43.770
for programmatic collection of
data from sensors, getting

00:04:43.770 --> 00:04:47.220
them into the Google
Cloud Platform, and

00:04:47.220 --> 00:04:49.570
analyzing them there.

00:04:49.570 --> 00:04:53.230
So we've talked with a variety
of different companies that

00:04:53.230 --> 00:04:56.080
have different use cases for
sensor data collection, things

00:04:56.080 --> 00:05:00.590
like weather and other types of
data where from all around

00:05:00.590 --> 00:05:02.380
the world, you can
have the sensors.

00:05:02.380 --> 00:05:05.200
It uploads data through the
cloud platform, and since

00:05:05.200 --> 00:05:07.590
Google exists all around the
world and has pretty fast

00:05:07.590 --> 00:05:11.150
connections, that's an easy way
to upload data, and then

00:05:11.150 --> 00:05:12.790
you're analyzing it
all in the cloud.

00:05:12.790 --> 00:05:17.420
So I even think specifically
with this car data, there

00:05:17.420 --> 00:05:21.240
might be great use cases out
there for fleets of vehicles

00:05:21.240 --> 00:05:25.030
to analyze patterns of how those
vehicles are operating.

00:05:25.030 --> 00:05:26.710
MICHAEL MANOOCHEHRI: It isn't
just vehicles, as you said.

00:05:26.710 --> 00:05:30.080
Any kind of sensor that can make
an HTTP post to the App

00:05:30.080 --> 00:05:31.910
Engine App can use this
kind of system.

00:05:31.910 --> 00:05:34.110
And what I also like about this
is it's so accessible.

00:05:34.110 --> 00:05:36.040
I mean, the device you were
using to collect data from

00:05:36.040 --> 00:05:37.400
your car was rather cheap.

00:05:37.400 --> 00:05:39.560
You already have a phone and
with Bluetooth, and it's

00:05:39.560 --> 00:05:42.060
something a lot of people
can do and actually code

00:05:42.060 --> 00:05:43.340
themselves.

00:05:43.340 --> 00:05:43.700
RYAN BOYD: All right.

00:05:43.700 --> 00:05:45.290
So this is the complete
pipeline.

00:05:45.290 --> 00:05:48.420
Let us know if you've built--
you can post something in the

00:05:48.420 --> 00:05:51.100
Moderator or reach out to us in
Google+ if you've built a

00:05:51.100 --> 00:05:54.080
similar pipeline for
your own data.

00:05:54.080 --> 00:05:56.850
And we're definitely interested
in hearing what

00:05:56.850 --> 00:05:58.330
you've built.

00:05:58.330 --> 00:06:01.990
So let's talk about now the
application that we're using

00:06:01.990 --> 00:06:03.620
for the collection of data.

00:06:03.620 --> 00:06:07.470
So the application that we're
using right now to collect the

00:06:07.470 --> 00:06:09.210
data is called Torque.

00:06:09.210 --> 00:06:12.760
We're using the paid version of
this app called Torque Pro.

00:06:12.760 --> 00:06:15.240
Here's the screenshot
from the Play Store.

00:06:15.240 --> 00:06:18.160
And what we're doing, this
app basically does a

00:06:18.160 --> 00:06:19.090
whole bunch of stuff.

00:06:19.090 --> 00:06:22.140
It's written by this gentleman
named Ian Hawkins, looks like

00:06:22.140 --> 00:06:24.270
he's put a lot of time and
energy into building an

00:06:24.270 --> 00:06:25.710
awesome map here.

00:06:25.710 --> 00:06:28.860
You can see here, over
100,000 downloads.

00:06:28.860 --> 00:06:32.290
He basically does a lot of
displays and all, so you can

00:06:32.290 --> 00:06:35.650
use this as sort of your
dashboard as you're driving.

00:06:35.650 --> 00:06:39.150
But for my case, I really
just wanted the data.

00:06:39.150 --> 00:06:40.940
I wanted the data out
of the application

00:06:40.940 --> 00:06:42.060
and up to App Engine.

00:06:42.060 --> 00:06:46.180
So it also has a way that you
can specify a HTTPS URL to App

00:06:46.180 --> 00:06:50.300
Engine, and it just does very
simple posts over to App

00:06:50.300 --> 00:06:52.515
Engine when each data
point is collected.

00:06:55.860 --> 00:07:00.230
So from there, we have a very
simple App Engine app we

00:07:00.230 --> 00:07:03.240
wrote, something like a
15-minute App Engine app--

00:07:03.240 --> 00:07:04.335
MICHAEL MANOOCHEHRI:
Very simple.

00:07:04.335 --> 00:07:07.450
RYAN BOYD: --that takes this
data over the post variables

00:07:07.450 --> 00:07:10.440
and just creates entries
in our Data Store.

00:07:10.440 --> 00:07:15.480
So very simple code to write,
probably 20 lines or not much

00:07:15.480 --> 00:07:17.010
more than that.

00:07:17.010 --> 00:07:19.895
And we get all the data into the
App Engine Data Store, and

00:07:19.895 --> 00:07:21.700
it looks something like this.

00:07:21.700 --> 00:07:24.120
This may be a little small for
you to read, but we have data

00:07:24.120 --> 00:07:28.220
like the air temperature, the
altitude, which the device

00:07:28.220 --> 00:07:31.350
actually collects from the GPS
in my phone, the altitude,

00:07:31.350 --> 00:07:33.140
latitude, and longitude.

00:07:33.140 --> 00:07:38.710
We also have the RPMs, how fast
the engine is going, the

00:07:38.710 --> 00:07:43.060
speed of the car, throttle
position, the time, all sorts

00:07:43.060 --> 00:07:44.160
of interesting bits of data.

00:07:44.160 --> 00:07:45.460
And you can configure
what types of

00:07:45.460 --> 00:07:46.420
data you want to upload.

00:07:46.420 --> 00:07:48.850
There's plenty more properties
available.

00:07:48.850 --> 00:07:51.690
But we get this into the App
Engine data store, and the App

00:07:51.690 --> 00:07:55.370
Engine Data Store is a great
place to collect this data and

00:07:55.370 --> 00:07:58.310
maybe build a simple web
front end on top of it.

00:07:58.310 --> 00:08:01.760
But if we want to do analysis,
let's say we're extending this

00:08:01.760 --> 00:08:05.990
beyond just my car, and we want
to do an analysis on a

00:08:05.990 --> 00:08:10.160
fleet of 10,000 cars or
something like that, we really

00:08:10.160 --> 00:08:12.690
need the power of something
like BigQuery.

00:08:12.690 --> 00:08:14.725
So we want to get this
data into BigQuery.

00:08:17.950 --> 00:08:19.210
So how do we do that?

00:08:19.210 --> 00:08:22.440
Well, there's a Trusted Tester
feature, which we'll give you

00:08:22.440 --> 00:08:27.330
a URL here shortly that allows
you to sign up or apply to be

00:08:27.330 --> 00:08:29.110
in this Trusted Tester
program.

00:08:29.110 --> 00:08:35.210
But this Trusted Tester feature
allows you to get data

00:08:35.210 --> 00:08:40.299
from the App Engine Data Store
over to BigQuery by doing a

00:08:40.299 --> 00:08:42.580
backup of the Data Store
and storing that

00:08:42.580 --> 00:08:44.210
backup on Cloud Storage.

00:08:44.210 --> 00:08:45.060
That's the first step.

00:08:45.060 --> 00:08:47.700
It's really a simple
two-step process.

00:08:47.700 --> 00:08:49.620
So the first step is backing
up that data.

00:08:49.620 --> 00:08:53.380
We can see here I specified my
Cloud Storage bucket called

00:08:53.380 --> 00:08:57.760
Car Data and said that I'm doing
it on Cloud Storage.

00:08:57.760 --> 00:09:00.370
And let me just talk a little
bit about the permission

00:09:00.370 --> 00:09:03.040
system here quickly, because
Michael has been asking me

00:09:03.040 --> 00:09:05.230
about this, how that works.

00:09:05.230 --> 00:09:07.190
The permission system
is really simple.

00:09:07.190 --> 00:09:11.920
App Engine has a application
identifier role account that

00:09:11.920 --> 00:09:15.510
the App Engine app runs under,
and you can find that-- is it

00:09:15.510 --> 00:09:19.240
the Application Info tab or
something like that in the App

00:09:19.240 --> 00:09:20.100
Engine console?

00:09:20.100 --> 00:09:21.540
MICHAEL MANOOCHEHRI: There's
an Application Settings tab

00:09:21.540 --> 00:09:22.950
that has all this information.

00:09:22.950 --> 00:09:26.580
RYAN BOYD: Yeah, and so you grab
that email address, and

00:09:26.580 --> 00:09:31.000
you can put that account
into a project.

00:09:31.000 --> 00:09:37.070
So we went over to the API's
console and set the project to

00:09:37.070 --> 00:09:40.990
be writable by that particular
email address, and that's how

00:09:40.990 --> 00:09:42.870
we granted the permissions.

00:09:42.870 --> 00:09:46.150
You can certainly do that also
within BigQuery as well, and

00:09:46.150 --> 00:09:48.820
within the Cloud Storage.

00:09:48.820 --> 00:09:50.130
They all have the same
way of doing

00:09:50.130 --> 00:09:51.510
permissioning on these accounts.

00:09:51.510 --> 00:09:53.390
It looks like a regular
user account.

00:09:53.390 --> 00:09:56.960
So we gave permission for the
App Engine app to write to

00:09:56.960 --> 00:09:59.650
Cloud Storage this bucket
called Car Data.

00:09:59.650 --> 00:10:03.340
And then if we go over to Cloud
Storage after we do the

00:10:03.340 --> 00:10:07.500
backup, we can see all
the backup files

00:10:07.500 --> 00:10:09.140
within Cloud Storage.

00:10:09.140 --> 00:10:11.260
So we see here at the
top, there's this

00:10:11.260 --> 00:10:14.110
TorqueData.backup Info.

00:10:14.110 --> 00:10:19.710
The Torque Data is the name of
our entity in the Data Store,

00:10:19.710 --> 00:10:23.010
and the Backup Info file is kind
of the metadata file that

00:10:23.010 --> 00:10:24.950
describes my backup.

00:10:24.950 --> 00:10:32.960
I then take that, and I point
BigQuery at the Cloud Storage

00:10:32.960 --> 00:10:39.010
URL for that Backup Info file,
and just tell BigQuery to

00:10:39.010 --> 00:10:41.730
import that table from
Cloud Storage.

00:10:41.730 --> 00:10:46.000
So this is showing the
UI way of doing it.

00:10:46.000 --> 00:10:48.450
We can also programmatically
do all of this.

00:10:48.450 --> 00:10:52.970
So you could programmatically
schedule cron jobs to allow

00:10:52.970 --> 00:10:56.010
you to back up the data on a
scheduled time period, and you

00:10:56.010 --> 00:10:59.350
basically are just putting in
the different parameters that

00:10:59.350 --> 00:11:03.810
you would put into the UI in
your cron job as parameters

00:11:03.810 --> 00:11:07.240
when you call out to
make the backups.

00:11:07.240 --> 00:11:10.650
And in addition to that, then
of course, programmatically,

00:11:10.650 --> 00:11:12.870
you could also import
this data from Cloud

00:11:12.870 --> 00:11:15.185
Storage into BigQuery.

00:11:15.185 --> 00:11:17.280
But that's the basic
steps here.

00:11:17.280 --> 00:11:20.140
So all we have to do is get the
data into the App Engine

00:11:20.140 --> 00:11:24.010
Data Store, get the data backed
up from the Data Store

00:11:24.010 --> 00:11:26.930
over to Cloud Storage,
and then BigQuery

00:11:26.930 --> 00:11:28.520
imports it from there.

00:11:28.520 --> 00:11:30.430
And of course, we're going to
try to make this a smoother

00:11:30.430 --> 00:11:34.160
process for you as well, but it
is really simple, two-click

00:11:34.160 --> 00:11:37.890
process that you can do, and
then automate using the cron

00:11:37.890 --> 00:11:40.330
job feature.

00:11:40.330 --> 00:11:43.770
So if you you're actually
interested in testing out this

00:11:43.770 --> 00:11:47.430
feature, the feature that allows
you to move data from

00:11:47.430 --> 00:11:50.250
the App Engine Data Store
over to BigQuery.

00:11:50.250 --> 00:11:51.780
You can see this URL here.

00:11:51.780 --> 00:11:54.070
I'm going to leave this
up for a moment.

00:11:54.070 --> 00:11:56.820
This allows you to apply for
the Trusted Tester Program.

00:11:56.820 --> 00:12:00.760
We're looking for people who
have some interesting data in

00:12:00.760 --> 00:12:04.180
App Engine and are looking
to analyze that data for

00:12:04.180 --> 00:12:07.360
large-scale aggregate queries
and ad-hoc queries on that

00:12:07.360 --> 00:12:09.940
data in BigQuery.

00:12:09.940 --> 00:12:11.980
We have some interesting people
that have signed up so

00:12:11.980 --> 00:12:14.300
far and have used it for a
wide variety of different

00:12:14.300 --> 00:12:16.960
types of data, but we're always
looking for more to get

00:12:16.960 --> 00:12:19.930
more and more of
your feedback.

00:12:19.930 --> 00:12:20.450
All right.

00:12:20.450 --> 00:12:23.970
So we've talked about how we
get the data into BigQuery.

00:12:23.970 --> 00:12:27.550
Now, let's talk about actually
querying the data.

00:12:27.550 --> 00:12:29.980
The interesting part isn't
getting the data there.

00:12:29.980 --> 00:12:32.250
It's actually running
some queries.

00:12:32.250 --> 00:12:34.800
So I'm going to show you
a couple queries

00:12:34.800 --> 00:12:36.920
here that we've run.

00:12:36.920 --> 00:12:39.540
The first query is
looking at--

00:12:39.540 --> 00:12:42.350
and I made this a little bit
large, it looks like, but

00:12:42.350 --> 00:12:47.130
looking at the average speed
that I drive in San Francisco.

00:12:47.130 --> 00:12:52.840
So we can see here, rounding the
average speed, it's stored

00:12:52.840 --> 00:12:54.940
in kilometers per hour, and then
we're converting it to

00:12:54.940 --> 00:12:57.050
miles per hour.

00:12:57.050 --> 00:13:01.880
And we're doing it from our
latest dump, which is on 2012,

00:13:01.880 --> 00:13:04.760
12/03, which I think is today.

00:13:04.760 --> 00:13:09.510
And then if I can scroll down
here a little bit, we're

00:13:09.510 --> 00:13:12.930
looking at the particular
latitude and the particular

00:13:12.930 --> 00:13:13.830
longitude for the query.

00:13:13.830 --> 00:13:15.680
MICHAEL MANOOCHEHRI: So this is
a bounding box around San

00:13:15.680 --> 00:13:17.130
Francisco roughly, right?

00:13:17.130 --> 00:13:18.010
RYAN BOYD: Yeah, this
is a bounding

00:13:18.010 --> 00:13:19.000
box around San Francisco.

00:13:19.000 --> 00:13:22.260
So I wanted to see when I'm
in the city, how fast am I

00:13:22.260 --> 00:13:23.270
driving in the city?

00:13:23.270 --> 00:13:26.070
And I think that varies a little
bit from when I'm on

00:13:26.070 --> 00:13:27.070
the highway.

00:13:27.070 --> 00:13:28.320
So let's query here.

00:13:31.080 --> 00:13:34.140
And we can see here, my average
speed in the city is

00:13:34.140 --> 00:13:35.700
47 miles per hour.

00:13:35.700 --> 00:13:36.793
MICHAEL MANOOCHEHRI: That's
pretty fast, Ryan.

00:13:36.793 --> 00:13:39.170
What have you been doing?

00:13:39.170 --> 00:13:41.010
RYAN BOYD: So I don't
drive that fast,

00:13:41.010 --> 00:13:42.460
Michael, on city streets.

00:13:42.460 --> 00:13:45.390
I think the speed limit on city
streets is 25 or 30 miles

00:13:45.390 --> 00:13:47.180
an hour on most of
the city streets.

00:13:47.180 --> 00:13:50.380
So I don't drive at
47 miles an hour.

00:13:50.380 --> 00:13:53.850
But we do have highways in the
city that go on and off of the

00:13:53.850 --> 00:13:56.580
Bay Bridge as well as go
down to the peninsula.

00:13:56.580 --> 00:13:58.455
So that must have been my
speed on the highway.

00:13:58.455 --> 00:13:59.705
I will swear to that.

00:14:02.620 --> 00:14:05.810
But now, what is my speed when
I'm outside of San Francisco?

00:14:05.810 --> 00:14:07.890
If I'm not looking at the
bounding box for San

00:14:07.890 --> 00:14:09.580
Francisco, how fast
am I going?

00:14:09.580 --> 00:14:09.820
MICHAEL MANOOCHEHRI: So
San Francisco is a

00:14:09.820 --> 00:14:10.520
pretty dense city.

00:14:10.520 --> 00:14:12.256
When you get out of the city,
you expect to probably go a

00:14:12.256 --> 00:14:14.390
little faster because you're
on the highway.

00:14:14.390 --> 00:14:15.170
RYAN BOYD: Yeah, probably.

00:14:15.170 --> 00:14:17.480
Let's take a look at
what this speed is.

00:14:22.980 --> 00:14:23.280
All right.

00:14:23.280 --> 00:14:26.300
So here we have average speed
on the peninsula, which is

00:14:26.300 --> 00:14:27.260
doing a similar thing.

00:14:27.260 --> 00:14:29.900
But then we basically have
different latitude and

00:14:29.900 --> 00:14:32.830
longitudes here.

00:14:32.830 --> 00:14:34.790
And we're not seeing this on
the screen, but I'm also

00:14:34.790 --> 00:14:38.990
filtering out those times where
the car miscalculated my

00:14:38.990 --> 00:14:41.180
speed and thought that I was
over the speed limit, because

00:14:41.180 --> 00:14:43.050
that doesn't actually happen.

00:14:43.050 --> 00:14:44.140
So I'm filtering those out.

00:14:44.140 --> 00:14:49.240
Let's see how fast
I'm going here.

00:14:49.240 --> 00:14:49.690
All right.

00:14:49.690 --> 00:14:52.700
So we went from 47 miles
an hour to 54,

00:14:52.700 --> 00:14:55.130
a little bit faster.

00:14:55.130 --> 00:14:58.990
Not as fast as I would think,
as much faster as I would

00:14:58.990 --> 00:15:02.700
think, and I think that's
probably because of mornings

00:15:02.700 --> 00:15:05.740
like this morning where we're
crawling at 10 miles an hour.

00:15:05.740 --> 00:15:06.576
MICHAEL MANOOCHEHRI: I'm
surprised you could go that

00:15:06.576 --> 00:15:06.900
fast on the 101.

00:15:06.900 --> 00:15:10.560
I happen to know you try to
beat rush hour, though.

00:15:10.560 --> 00:15:12.320
RYAN BOYD: Anyway, but these are
the types of queries that

00:15:12.320 --> 00:15:14.390
you could run, and you could
also run all sorts of other

00:15:14.390 --> 00:15:19.190
queries on the RPMs and figuring
out what your speed

00:15:19.190 --> 00:15:22.830
was at various RPMs and things
like that, figure out how well

00:15:22.830 --> 00:15:23.720
your car is running.

00:15:23.720 --> 00:15:28.070
But imagine if you're running
it not just on my 100,000

00:15:28.070 --> 00:15:32.350
records I think I have here,
but you're running it on a

00:15:32.350 --> 00:15:35.980
much larger data set of a car
that drives much more often

00:15:35.980 --> 00:15:38.370
and maybe a whole fleet of
10,000, 20,000 cars.

00:15:38.370 --> 00:15:39.360
MICHAEL MANOOCHEHRI: Imagine
what you can do with this you

00:15:39.360 --> 00:15:40.750
can find anomalies
in your fleet.

00:15:40.750 --> 00:15:41.960
And this doesn't just
have to be cars.

00:15:41.960 --> 00:15:43.470
It could be sensors of
any kind, right?

00:15:43.470 --> 00:15:45.280
Imagine if you have it on
servers, and you're looking at

00:15:45.280 --> 00:15:47.620
logs, and you want to find
anomalies in those logs.

00:15:47.620 --> 00:15:50.630
I mean, you can do that with
BigQuery using Data Store for

00:15:50.630 --> 00:15:52.960
what it's good at, which is
being highly available and

00:15:52.960 --> 00:15:55.630
very high performance to rapidly
collect data, and then

00:15:55.630 --> 00:15:58.300
using BigQuery to actually do
aggregate queries over that

00:15:58.300 --> 00:15:59.670
Data Store data.

00:15:59.670 --> 00:16:02.320
RYAN BOYD: So right now, we're
actually collecting this data

00:16:02.320 --> 00:16:03.930
through this Torque application

00:16:03.930 --> 00:16:05.370
that we talked about.

00:16:05.370 --> 00:16:09.070
We do actually have this
goal of using other

00:16:09.070 --> 00:16:09.900
parts of the platform.

00:16:09.900 --> 00:16:12.410
I'm going to just skip
back here quickly

00:16:12.410 --> 00:16:14.270
to the diagram here.

00:16:14.270 --> 00:16:19.900
So we have this goal of on the
Android phone using the Cloud

00:16:19.900 --> 00:16:23.520
Endpoints feature that we
announced at Google I/O. And

00:16:23.520 --> 00:16:26.910
the Cloud Endpoints feature
allows you to use our API

00:16:26.910 --> 00:16:33.510
infrastructure in order
to have APIs for your

00:16:33.510 --> 00:16:34.280
applications.

00:16:34.280 --> 00:16:37.150
And it's particularly valuable
in the mobile use cases.

00:16:37.150 --> 00:16:41.560
So imagine here if I'm able
to get the data from the

00:16:41.560 --> 00:16:45.340
Bluetooth sensor directly, write
my own application, and

00:16:45.340 --> 00:16:48.230
upload it to App Engine.

00:16:48.230 --> 00:16:51.320
I have a little bit more
control over it then.

00:16:51.320 --> 00:16:54.530
And what I mean by control is
right now, the application--

00:16:54.530 --> 00:16:55.860
which is awesome--

00:16:55.860 --> 00:16:59.370
that's running on my phone, this
Torque application, that

00:16:59.370 --> 00:17:02.910
application is collecting data
points a few times every

00:17:02.910 --> 00:17:05.619
second, and for each of those
few times every second, is

00:17:05.619 --> 00:17:08.550
making a request over to
my App Engine app and

00:17:08.550 --> 00:17:09.970
posting that data.

00:17:09.970 --> 00:17:12.710
But with the Cloud Endpoints
implementation, what I could

00:17:12.710 --> 00:17:17.930
do is actually use the Batch
functionality, or just batch

00:17:17.930 --> 00:17:21.300
them up myself manually,
and post 10 or 20

00:17:21.300 --> 00:17:22.700
of these at a time.

00:17:22.700 --> 00:17:26.839
And so basically, not have to
make a few HTTP requests every

00:17:26.839 --> 00:17:29.700
second, but rather once
every 10 seconds or

00:17:29.700 --> 00:17:30.360
something like that.

00:17:30.360 --> 00:17:32.930
So we can optimize
it a little bit.

00:17:32.930 --> 00:17:35.230
And then that that'll be a great
example, once we're able

00:17:35.230 --> 00:17:38.430
to do that to demonstrate how
you might collect other sensor

00:17:38.430 --> 00:17:43.190
data from your phone or other
wireless devices and upload it

00:17:43.190 --> 00:17:46.940
to App Engine, and then
eventually to BigQuery for

00:17:46.940 --> 00:17:48.950
analysis, of course.

00:17:48.950 --> 00:17:49.370
All right.

00:17:49.370 --> 00:17:51.400
So let me--

00:17:51.400 --> 00:17:52.270
whoops!

00:17:52.270 --> 00:17:57.270
Let me start down here.

00:17:57.270 --> 00:17:59.620
Apparently, I clicked a bit
of the wrong button.

00:18:03.760 --> 00:18:04.560
Michael.

00:18:04.560 --> 00:18:05.690
MICHAEL MANOOCHEHRI: So we're
going to do something a little

00:18:05.690 --> 00:18:06.230
bit different today.

00:18:06.230 --> 00:18:08.890
We're going to look at some of
the great community questions

00:18:08.890 --> 00:18:11.670
from our Stack Overflow tag,
which, as I said earlier, was

00:18:11.670 --> 00:18:13.190
Google-BigQuery.

00:18:13.190 --> 00:18:16.510
So Ryan, myself, members of the
BigQuery Engineering Team

00:18:16.510 --> 00:18:17.810
read every single question.

00:18:17.810 --> 00:18:19.770
We take your developer feedback
very seriously.

00:18:19.770 --> 00:18:22.700
And we love the thriving
developer community that's

00:18:22.700 --> 00:18:25.230
growing up on Stack Overflow
in relation to BigQuery.

00:18:25.230 --> 00:18:28.120
So I'm going to read some of my
favorite questions from the

00:18:28.120 --> 00:18:31.180
past week and actually talk
to people about them.

00:18:31.180 --> 00:18:33.090
I think they're very useful
questions for everybody

00:18:33.090 --> 00:18:35.000
developing with BigQuery.

00:18:35.000 --> 00:18:37.320
And so let's just
dive into it.

00:18:37.320 --> 00:18:40.460
The first question that got my
attention was, is it possible

00:18:40.460 --> 00:18:44.860
to join Cloud SQL tables
to a BigQuery table?

00:18:44.860 --> 00:18:49.220
So the answer is,
not directly.

00:18:49.220 --> 00:18:52.860
So Cloud SQL is basically a
MySQL implementation that you

00:18:52.860 --> 00:18:54.530
can access through Google
App Engine.

00:18:54.530 --> 00:18:56.680
It's very powerful,
it's very useful.

00:18:56.680 --> 00:19:00.030
But the question was, can I do a
single Select statement that

00:19:00.030 --> 00:19:02.930
incorporates a BigQuery table
with a Cloud SQL table?

00:19:02.930 --> 00:19:04.050
So the answer is,
not directly.

00:19:04.050 --> 00:19:06.860
You can't write a single SQL
statement that can query both

00:19:06.860 --> 00:19:10.340
at the same time, but you can
use the data from Cloud SQL in

00:19:10.340 --> 00:19:12.130
a query for BigQuery.

00:19:12.130 --> 00:19:15.400
You just need to export that
data and import it into

00:19:15.400 --> 00:19:18.490
BigQuery, much as we described
with the App Engine Data Store

00:19:18.490 --> 00:19:21.550
import that were talking
about earlier.

00:19:21.550 --> 00:19:23.680
Actually, there is a way to
export data from Cloud SQL.

00:19:23.680 --> 00:19:26.160
And the way you would do that is
export the data into a CSV

00:19:26.160 --> 00:19:29.900
format, then import the data
back into BigQuery, and then

00:19:29.900 --> 00:19:31.380
run your JOIN statement.

00:19:31.380 --> 00:19:35.400
You can actually join two tables
together, and that's

00:19:35.400 --> 00:19:36.880
basically how you do it.

00:19:36.880 --> 00:19:40.350
We don't have a direct pipeline
like we do with the

00:19:40.350 --> 00:19:42.645
Data Store data, but I
appreciate this feedback, and

00:19:42.645 --> 00:19:44.600
it's something we'll definitely
look into.

00:19:44.600 --> 00:19:46.270
RYAN BOYD: I do want to say,
though, that this is something

00:19:46.270 --> 00:19:50.270
that you can do, not just with
Cloud SQL, but with any

00:19:50.270 --> 00:19:53.150
relational database or other
data source you have, because

00:19:53.150 --> 00:19:55.240
BigQuery can ingest your
data in either

00:19:55.240 --> 00:19:57.010
CSV or a JSON format.

00:19:57.010 --> 00:19:59.660
And we do have a lot
of customers that

00:19:59.660 --> 00:20:01.250
BigQuery is for analysis.

00:20:01.250 --> 00:20:03.480
We have a lot of customers
that, of course, need an

00:20:03.480 --> 00:20:06.960
authoritative data source in a
relational database to store

00:20:06.960 --> 00:20:07.810
their data in.

00:20:07.810 --> 00:20:11.300
And then every now and then,
they take that data out and

00:20:11.300 --> 00:20:13.750
put it into BigQuery, maybe in
sort of a nightly cron job

00:20:13.750 --> 00:20:15.620
similar to how we did with
the Data Store backup.

00:20:15.620 --> 00:20:19.040
So it's a very useful pattern
to get accustomed to.

00:20:19.040 --> 00:20:19.490
MICHAEL MANOOCHEHRI:
Definitely.

00:20:19.490 --> 00:20:21.520
And like Ryan said, if you're
using a document store, you

00:20:21.520 --> 00:20:23.682
can use the JSON import to get
data into BigQuery, and if

00:20:23.682 --> 00:20:26.010
you're using a relational
database, of course, CSV is a

00:20:26.010 --> 00:20:28.390
great format for that.

00:20:28.390 --> 00:20:28.710
So great.

00:20:28.710 --> 00:20:30.790
So the next question I see all
the time, and I wanted to talk

00:20:30.790 --> 00:20:32.560
a little bit about it today--

00:20:32.560 --> 00:20:36.260
authorizing access to Google
BigQuery via API key.

00:20:36.260 --> 00:20:40.250
So the question basically is
asking, as some Google APIs

00:20:40.250 --> 00:20:43.830
do, can I use an API key to
authorize access to BigQuery

00:20:43.830 --> 00:20:48.350
by basically appending a key
value to the end of a request

00:20:48.350 --> 00:20:50.110
to the BigQuery API?

00:20:50.110 --> 00:20:51.940
The answer is actually no.

00:20:51.940 --> 00:20:54.620
BigQuery does not support
API key access.

00:20:54.620 --> 00:20:57.560
But oftentimes, when you're
trying to do a request that is

00:20:57.560 --> 00:21:00.390
something that you could use API
access for something else,

00:21:00.390 --> 00:21:02.660
API key access, what you really
want to do is use a

00:21:02.660 --> 00:21:05.330
service account authorization
flow.

00:21:05.330 --> 00:21:07.410
And so we have a lot of great
documentation about how to

00:21:07.410 --> 00:21:10.910
build this, both on an installed
application or an

00:21:10.910 --> 00:21:12.390
App Engine application.

00:21:12.390 --> 00:21:15.220
Basically, this gives your
application the authorization

00:21:15.220 --> 00:21:18.740
to make calls to the BigQuery
API on your behalf.

00:21:18.740 --> 00:21:20.060
So we have lots of
documentation

00:21:20.060 --> 00:21:20.870
about how to do this.

00:21:20.870 --> 00:21:23.490
But if you are interested
in using an API key type

00:21:23.490 --> 00:21:25.820
authorization method, you
probably want to try out a

00:21:25.820 --> 00:21:27.970
service account authorization
instead.

00:21:27.970 --> 00:21:31.750
RYAN BOYD: And this uses a
standard OAuth 2.0 flow, and

00:21:31.750 --> 00:21:34.060
it's the same thing with
BigQuery as with a lot of our

00:21:34.060 --> 00:21:35.360
other APIs.

00:21:35.360 --> 00:21:37.070
I just wanted to insert
a reminder here.

00:21:37.070 --> 00:21:40.410
If you do have questions live,
you're listening to this live,

00:21:40.410 --> 00:21:43.650
make sure to head out over
to our Moderator and ask

00:21:43.650 --> 00:21:44.350
questions there.

00:21:44.350 --> 00:21:47.540
So you can go to
developers.google.com/live,

00:21:47.540 --> 00:21:50.220
and click on this episode, and
you'll see the embedded

00:21:50.220 --> 00:21:51.330
Moderator there.

00:21:51.330 --> 00:21:52.910
And we'll keep on jumping
in through some

00:21:52.910 --> 00:21:54.280
Stack Overflow questions.

00:21:54.280 --> 00:21:55.650
MICHAEL MANOOCHEHRI: So let's
take a look at actually two

00:21:55.650 --> 00:21:57.040
questions, but they're related,
and they're actually

00:21:57.040 --> 00:21:58.440
from the same poster.

00:21:58.440 --> 00:22:03.250
The first is, maximum number of
nested records and the cost

00:22:03.250 --> 00:22:04.140
of querying those records.

00:22:04.140 --> 00:22:05.470
Let me try to explain.

00:22:05.470 --> 00:22:07.620
BigQuery supports two types
of data models.

00:22:07.620 --> 00:22:12.010
One is flat records, meaning a
record with fields that are

00:22:12.010 --> 00:22:15.120
flat, and the same for
record to record.

00:22:15.120 --> 00:22:18.050
But we also support nested and
repeated records, meaning a

00:22:18.050 --> 00:22:20.250
single field within
a record can have

00:22:20.250 --> 00:22:22.300
children records as well.

00:22:22.300 --> 00:22:26.480
So the original question was,
how many levels of nesting can

00:22:26.480 --> 00:22:27.340
we support?

00:22:27.340 --> 00:22:28.580
The answer is actually 100.

00:22:28.580 --> 00:22:31.970
We support nesting
levels of 100.

00:22:31.970 --> 00:22:34.000
And if you actually are using
a data model like this, I'd

00:22:34.000 --> 00:22:34.790
love to see it.

00:22:34.790 --> 00:22:35.920
I'd love to see what
you're doing.

00:22:35.920 --> 00:22:37.920
But you can imagine how
useful that is, right?

00:22:37.920 --> 00:22:41.110
You could actually have, for
example, a Person class, and

00:22:41.110 --> 00:22:44.820
under that record, you could
have their age and their first

00:22:44.820 --> 00:22:47.150
name and their last name, and
you can actually nest that.

00:22:47.150 --> 00:22:49.870
You could even say, in this
example that I'm showing here,

00:22:49.870 --> 00:22:51.190
the cities they lived in.

00:22:51.190 --> 00:22:54.150
And this can be a different
amount of cities for every

00:22:54.150 --> 00:22:56.180
single record, and it
can grow or shrink

00:22:56.180 --> 00:22:57.390
depending on the person.

00:22:57.390 --> 00:22:59.530
And so it's very useful,
very easy to model.

00:22:59.530 --> 00:23:01.650
A lot of non-relational
databases already model their

00:23:01.650 --> 00:23:02.260
data like this.

00:23:02.260 --> 00:23:03.870
So BigQuery supports that.

00:23:03.870 --> 00:23:06.990
So we can support up to
100 nested records.

00:23:06.990 --> 00:23:09.270
The other question was
the cost of querying.

00:23:09.270 --> 00:23:11.900
And so if we can skip to the
next slide, this highlights

00:23:11.900 --> 00:23:13.860
how BigQuery actually
stores the data.

00:23:13.860 --> 00:23:16.430
So what's really interesting
about BigQuery is we take all

00:23:16.430 --> 00:23:19.700
of your data from row-oriented
storage, and we store it in

00:23:19.700 --> 00:23:21.760
column-oriented storage.

00:23:21.760 --> 00:23:23.720
And the cool thing about this
is when we have nested

00:23:23.720 --> 00:23:28.210
records, each one of those
records gets its own column.

00:23:28.210 --> 00:23:32.320
So for example, if we go back to
this example for the cities

00:23:32.320 --> 00:23:35.590
that people lived in, here you
can see there's a Person

00:23:35.590 --> 00:23:38.200
record, and underneath it, it's
the city and the years

00:23:38.200 --> 00:23:39.180
that they lived in.

00:23:39.180 --> 00:23:41.300
We store each of those values
in their own column.

00:23:41.300 --> 00:23:44.010
So the cities will all get
their own column, and the

00:23:44.010 --> 00:23:46.870
years lived will all get their
own column as well.

00:23:46.870 --> 00:23:50.130
For BigQuery, we charge
for processing only

00:23:50.130 --> 00:23:51.290
what you ask for.

00:23:51.290 --> 00:23:55.520
So if you actually just want
to know, say, the average

00:23:55.520 --> 00:23:58.510
number of years lived in any
city, and only ask for that

00:23:58.510 --> 00:24:00.800
column, that's the only column
we're going to look at.

00:24:00.800 --> 00:24:05.700
We're not going to touch
other children

00:24:05.700 --> 00:24:07.220
columns in that query.

00:24:07.220 --> 00:24:09.330
So actually, it's very
economical, and it's a very

00:24:09.330 --> 00:24:12.010
good way to model your data.

00:24:12.010 --> 00:24:14.870
RYAN BOYD: If you want to read
more about how we deal with

00:24:14.870 --> 00:24:19.000
nested data in BigQuery, the
Dremel white paper actually

00:24:19.000 --> 00:24:21.410
provides a lot of interesting
academic knowledge

00:24:21.410 --> 00:24:22.350
of how we do that.

00:24:22.350 --> 00:24:26.500
So look up Dremel white paper
on the web, and it describes

00:24:26.500 --> 00:24:29.170
how this nested structure works
and how we're able to

00:24:29.170 --> 00:24:31.980
still achieve the performance
that Michael talked about.

00:24:31.980 --> 00:24:33.930
The one other thing we should
mention, though, in terms of

00:24:33.930 --> 00:24:39.430
the nested data is that each of
your parent records still

00:24:39.430 --> 00:24:43.970
needs to fit within the
64-kilobyte row limit.

00:24:43.970 --> 00:24:49.820
So you can have, I think, 1,000
is what you said, nested

00:24:49.820 --> 00:24:50.040
underneath it--

00:24:50.040 --> 00:24:50.750
MICHAEL MANOOCHEHRI: 100.

00:24:50.750 --> 00:24:51.660
RYAN BOYD: Or 100.

00:24:51.660 --> 00:24:55.250
But there is a limit in terms of
the amount of data that you

00:24:55.250 --> 00:24:57.360
can have stored in there.

00:24:57.360 --> 00:25:00.020
But if you ever get an
opportunity where you're

00:25:00.020 --> 00:25:03.540
hitting that limit, definitely
reach out to us, and let us

00:25:03.540 --> 00:25:06.130
know that you're hitting that
limit and allow us to take a

00:25:06.130 --> 00:25:08.770
look, because there might be
some things that we can do,

00:25:08.770 --> 00:25:12.570
either now or in the future,
to raise that.

00:25:12.570 --> 00:25:13.150
MICHAEL MANOOCHEHRI: Great.

00:25:13.150 --> 00:25:15.850
So let's just check our
Moderator page and see if

00:25:15.850 --> 00:25:16.690
there's any new questions.

00:25:16.690 --> 00:25:18.970
There doesn't seem to be any
BigQuery questions here, but

00:25:18.970 --> 00:25:19.515
let me refresh.

00:25:19.515 --> 00:25:20.420
RYAN BOYD: There is one.

00:25:20.420 --> 00:25:21.860
MICHAEL MANOOCHEHRI:
There is one.

00:25:21.860 --> 00:25:23.580
OK, this is a great question.

00:25:23.580 --> 00:25:26.030
The question is, "Will it be
possible to import only the

00:25:26.030 --> 00:25:28.410
chain sets of data
from App Engine?

00:25:28.410 --> 00:25:30.770
Full Data Store dumps can be
quite large and time consuming

00:25:30.770 --> 00:25:32.630
to perform." That's
a great question.

00:25:32.630 --> 00:25:35.380
RYAN BOYD: So I'm curious
whether Scott has actually

00:25:35.380 --> 00:25:37.420
been in the Trusted
Tester Program.

00:25:37.420 --> 00:25:40.900
If you are in the Trusted Tester
Program and trying it

00:25:40.900 --> 00:25:42.780
out, we're going to be reaching
out and looking for

00:25:42.780 --> 00:25:43.650
your feedback soon.

00:25:43.650 --> 00:25:48.290
Definitely send us that one
and what your use case is.

00:25:48.290 --> 00:25:52.550
That definitely is a great
feature idea for this

00:25:52.550 --> 00:25:55.310
functionality and something
that I would

00:25:55.310 --> 00:25:57.300
argue for us to implement.

00:25:57.300 --> 00:25:58.550
MICHAEL MANOOCHEHRI: I think
it's a great question.

00:26:02.300 --> 00:26:04.190
RYAN BOYD: So that's the only
question right now.

00:26:04.190 --> 00:26:06.200
We'll give it another second
here, if you any additional

00:26:06.200 --> 00:26:08.510
questions on Google Moderator.

00:26:08.510 --> 00:26:11.190
Otherwise, we'll let you
guys head home early.

00:26:11.190 --> 00:26:15.430
I think in the West Coast here
it's four minutes before 5:00.

00:26:15.430 --> 00:26:16.180
MICHAEL MANOOCHEHRI: It
looks like that's it.

00:26:16.180 --> 00:26:18.300
There's no new questions
on the Moderator.

00:26:18.300 --> 00:26:18.840
RYAN BOYD: All right.

00:26:18.840 --> 00:26:21.030
Well, thank you everyone
for joining us today.

00:26:21.030 --> 00:26:21.950
I'm Ryan.

00:26:21.950 --> 00:26:22.700
MICHAEL MANOOCHEHRI:
I'm Michael.

00:26:22.700 --> 00:26:24.310
RYAN BOYD: And this is the
Ryan and Michael Show.

00:26:24.310 --> 00:26:25.560
Take care.

00:26:32.270 --> 00:26:52.833
[MUSIC PLAYING]

