WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.000
Hello and welcome to the third office hours. Let's jump right in. &gt;&gt;All right.

00:00:05.000 --> 00:00:10.000
Many students, myself included, had some questions about the resampling wheel.

00:00:10.000 --> 00:00:15.000
Specifically, when you draw a random number between 0 and twice W max,

00:00:15.000 --> 00:00:18.000
where did that number, twice W max, come from?

00:00:18.000 --> 00:00:21.000
I have the same question. I made it up.

00:00:21.000 --> 00:00:25.000
I wanted to make sure that these wheel can jump over entire particles

00:00:25.000 --> 00:00:28.000
that wouldn't large enough, but if you make it really large then you have to search a lot.

00:00:28.000 --> 00:00:31.000
I figured if it's 2^n it's going to be fine.

00:00:31.000 --> 00:00:35.000
Does this bias the sample in any way, choosing this number.

00:00:35.000 --> 00:00:37.000
I actually don't know.

00:00:37.000 --> 00:00:42.000
I think there is certainly a correlation between adjacent particles in the selection of particles.

00:00:42.000 --> 00:00:45.000
They're not independently drawn.

00:00:45.000 --> 00:00:50.000
I just don't know what the effect on the particle filter will be, and I wish I did.

00:00:50.000 --> 00:00:54.000
The next question, or two questions I should say, come from George.

00:00:54.000 --> 00:00:58.000
He wants to know if there are any rules of thumb that we should keep in mind

00:00:58.000 --> 00:01:01.000
when we're choosing what filter to use for a given situation.

00:01:01.000 --> 00:01:05.000
When do we use the particle filter? When do we use the Kalman filter?

00:01:05.000 --> 00:01:07.000
Absolutely, yes.

00:01:07.000 --> 00:01:13.000
The particle filter is the easiest to implement, but the complexity scales exponentially

00:01:13.000 --> 00:01:15.000
with the number of dimensions.

00:01:15.000 --> 00:01:19.000
That's usually a problem, because if you have a high-dimensional space, you just can't apply it.

00:01:19.000 --> 00:01:23.000
The Kalman filter is the only filter that does scale exponentially, so it's very nice.

00:01:23.000 --> 00:01:27.000
If you have like a 15-dimensional space, you will usually use a particle filter,

00:01:27.000 --> 00:01:31.000
but the problem with the Kalman filter is it's unimodal, so you can't really have multiple hypotheses.

00:01:31.000 --> 00:01:34.000
There are extensions of the Kalman filter that does this

00:01:34.000 --> 00:01:38.000
called mixed rough Kalman filter, multihypothesis Kalman filter that can do this.

00:01:38.000 --> 00:01:42.000
They address some of these problems.

00:01:42.000 --> 00:01:48.000
The histogram filter is applicable in situations similar to the particle filter

00:01:48.000 --> 00:01:51.000
where you have a global uncertainty, and it's more systematic.

00:01:51.000 --> 00:01:56.000
In the particle filter, if you loose track of the correct hypothesis, you might never regain it.

00:01:56.000 --> 00:01:59.000
In a grid-based filter you have a chance of regaining it.

00:01:59.000 --> 00:02:02.000
Grids are easily supported in many programming frameworks.

00:02:02.000 --> 00:02:07.000
Sometimes there are better ones to use, but they also have a generic limitation

00:02:07.000 --> 00:02:10.000
in the accuracy, which is related to the resolution of the grid.

00:02:10.000 --> 00:02:16.000
My recommendation is if you have a multimodal distribution use particle filters if you can.

00:02:16.000 --> 00:02:21.000
If it's really a continuous space with a unimodal distribution use Kalman filters.

00:02:21.000 --> 00:02:27.000
Okay. That's a great segue this question about switching between filters on the fly.

00:02:27.000 --> 00:02:32.000
For example, we have our particle filters that converges to a unimodal distribution.

00:02:32.000 --> 00:02:35.000
Then can we switch to the Kalman filter?

00:02:35.000 --> 00:02:38.000
It isn't done much that people switch.

00:02:38.000 --> 00:02:41.000
The reason is when you switch between filters,

00:02:41.000 --> 00:02:46.000
you end up getting moments of increased uncertainty.

00:02:46.000 --> 00:02:49.000
You can see this when you buy commercial GPS receivers.

00:02:49.000 --> 00:02:52.000
They tend to run multiple Kalman filters, it turns out, 3D

00:02:52.000 --> 00:02:55.000
depending on whether it's 2D or navigation.

00:02:55.000 --> 00:02:59.000
When they are switched, the behavior becomes a little bit iffy, and often that is bad for robots,

00:02:59.000 --> 00:03:03.000
because they they a little bit because this is where it says this thing versus the other thing.

00:03:03.000 --> 00:03:06.000
They're not quite consistent.

00:03:06.000 --> 00:03:09.000
There are ways to combine multiple filters types.

00:03:09.000 --> 00:03:12.000
The most common one is called the Rao-Blackwellized filter--Rao-Blackwellized--

00:03:12.000 --> 00:03:14.000
after Rao and Blackwell.

00:03:14.000 --> 00:03:21.000
What they found is that in a particle domain, sometimes if we nail certain dimensions with particles,

00:03:21.000 --> 00:03:25.000
everything else conditional on the particle becomes Gaussian or unimodal.

00:03:25.000 --> 00:03:31.000
Then you can exploit the efficiency of a Kalman filter that is now attached to individual particles.

00:03:31.000 --> 00:03:36.000
I'm not going to go into depth here, but there's an entire field of Rao-Blackwellized filters

00:03:36.000 --> 00:03:40.000
that sometimes can estimate in the spaces of hundreds of dimensions.

00:03:40.000 --> 00:03:45.000
Great. Thank you. That actually predicted George's next question, so we'll move on.

00:03:45.000 --> 00:03:50.000
Drew wanted to know about what happens to a particle filter when the motion modal

00:03:50.000 --> 00:03:54.000
moves a particle into an invalid place.

00:03:54.000 --> 00:03:58.000
For an example, in that corridor demonstration you gave, what if a particle gets moved into a wall?

00:03:58.000 --> 00:04:01.000
Well, thanks Drew. Great question.

00:04:01.000 --> 00:04:03.000
The obvious answer is you killed that particle.

00:04:03.000 --> 00:04:07.000
The way to think about this is in the measurement model you've got to have

00:04:07.000 --> 00:04:11.000
this kind of implicit sensor that says, "I'm just sitting inside a wall."

00:04:11.000 --> 00:04:15.000
The truth is the robot never sits inside a wall, so that sensor would always say

00:04:15.000 --> 00:04:18.000
with absolute certainty, "I'm not sitting in the middle of a wall."

00:04:18.000 --> 00:04:21.000
This kind of hypothetical sensor would justify

00:04:21.000 --> 00:04:26.000
that the weight of that particle that's in the middle of the wall would get weight 0, so you just kill it.

00:04:26.000 --> 00:04:30.000
Okay. A couple more questions from Drew.

00:04:30.000 --> 00:04:34.000
What about dynamically adjusting our big end, our number of particles

00:04:34.000 --> 00:04:39.000
when we want to trade off between computational cost versus the accuracy of our filter?

00:04:39.000 --> 00:04:42.000
Dynamically setting the number of particles has been done quite a bit,

00:04:42.000 --> 00:04:44.000
and it's a good idea under certain circumstances.

00:04:44.000 --> 00:04:47.000
Obviously, the fewer particles you have the faster you can compute.

00:04:47.000 --> 00:04:50.000
If you're tracking really well and all the particles are centered in one location,

00:04:50.000 --> 00:04:54.000
there isn't really a need to have as many around as when you're globally uncertain.

00:04:54.000 --> 00:04:57.000
They way to set the number of particles is often done by looking

00:04:57.000 --> 00:05:00.000
at the total non-normalized importance weights.

00:05:00.000 --> 00:05:04.000
If all your importance weights are really large, then you're probably doing a great job tracking,

00:05:04.000 --> 00:05:06.000
and you don't need that many particles.

00:05:06.000 --> 00:05:09.000
Whereas if your importance weights are all very small,

00:05:09.000 --> 00:05:13.000
then chances are you're doing a really lousy job tracking, and you need more particles.

00:05:13.000 --> 00:05:17.000
That isn't perfect. An unlikely measurement can cause weights to be small,

00:05:17.000 --> 00:05:20.000
but a good heuristic would be to say, let's particle sample

00:05:20.000 --> 00:05:23.000
until our non-normalized importance weights reach a certain threshold,

00:05:23.000 --> 00:05:26.000
and then let's stop sampling.

00:05:26.000 --> 00:05:29.000
Now truth telling, many of the systems we're dealing with are real-time systems,

00:05:29.000 --> 00:05:33.000
and you can't really afford using many particles sometimes and few other times,

00:05:33.000 --> 00:05:36.000
because there's a fixed amount of time in which you want to do your estimates.

00:05:36.000 --> 00:05:41.000
Then yes, it's more tricky, but in principle using few particles when you track well

00:05:41.000 --> 00:05:43.000
is a very viable solution.

00:05:43.000 --> 00:05:47.000
Thank you. Taka also had a question.

00:05:47.000 --> 00:05:51.000
He wants to know how to distinguish between moving landmarks and non-moving landmarks.

00:05:51.000 --> 00:05:56.000
The maps that we dealt with in class were all static, and the landmarks were fixed.

00:05:56.000 --> 00:05:59.000
How does the Google car distinguish between these moving vehicles,

00:05:59.000 --> 00:06:02.000
moving people, and these static landmarks?

00:06:02.000 --> 00:06:04.000
That's a wonderful question.

00:06:04.000 --> 00:06:07.000
First of all, the Google car assumes that the ground map,

00:06:07.000 --> 00:06:11.000
like the surface map of the street, is basically fixed.

00:06:11.000 --> 00:06:15.000
If lane markers would move along a little bit, then the Google car would probably get confused--

00:06:15.000 --> 00:06:20.000
a little secret here--so please don't repaint the lane markers when the Google car comes by.

00:06:20.000 --> 00:06:23.000
That's treated differently than stuff that sticks out of the ground,

00:06:23.000 --> 00:06:25.000
and even that is used as a landmark.

00:06:25.000 --> 00:06:32.000
What we do is we have a probabilistic threshold that says what's the chance of this thing being mobile or not?

00:06:32.000 --> 00:06:36.000
We do this by establishing correspondence, which means we take measurements a time step earlier

00:06:36.000 --> 00:06:39.000
and measurements a time step later, see which has the most likely

00:06:39.000 --> 00:06:42.000
correspondence between these two measurements

00:06:42.000 --> 00:06:44.000
and then see if there's a motion vector in between.

00:06:44.000 --> 00:06:48.000
Sometimes we can explain it away by just noise, but for cars and people and so on,

00:06:48.000 --> 00:06:51.000
there is very often a very clear and strong motion

00:06:51.000 --> 00:06:54.000
in which case we assume this thing is moving and tracking.

00:06:54.000 --> 00:06:59.000
It also turns out that the way we build our prior maps is sometimes we drive by multiple times.

00:06:59.000 --> 00:07:03.000
We do differencing, and then we have most captures are static things in our maps.

00:07:03.000 --> 00:07:07.000
We happen to know that in the middle of a street, there tend to be no static things.

00:07:07.000 --> 00:07:09.000
There tends to be just moving things.

00:07:09.000 --> 00:07:12.000
You can bias the estimate toward saying, well, in the middle of the street

00:07:12.000 --> 00:07:15.000
what we'll see is likely not static.

00:07:15.000 --> 00:07:18.000
Tossing this all together gives us a fairly good tracker.

00:07:18.000 --> 00:07:23.000
Thanks a lot. That's all we had for this time. We'll see you all next week.

00:07:23.000 --> 00:07:25.000
But I want to make a comment.

00:07:25.000 --> 00:07:30.000
I hear that many people really positively received the homework assignment on particle filters,

00:07:30.000 --> 00:07:33.000
which is great. It took me a while to make it.

00:07:33.000 --> 00:07:37.000
On the discussion forum there is a posting of a graphical version of it,

00:07:37.000 --> 00:07:40.000
and I downloaded it. It looks really great.

00:07:40.000 --> 00:07:45.000
I couldn't get the curser keys to work on my computer, but it's a really great basis to visualize.

00:07:45.000 --> 00:07:49.000
I think particle filters are really hard to understand without visualization,

00:07:49.000 --> 00:07:52.000
so I'm really sorry that our current programming environment doesn't provide visualization.

00:07:52.000 --> 00:07:56.000
I hope in the next round, we'll fix that. I'm pretty sure we'll fix this.

00:07:56.000 --> 00:07:58.000
So please play with it.

00:07:58.000 --> 00:08:02.000
The other thing I noticed in the discussion boards, and I wanted to just call for feedback,

00:08:02.000 --> 00:08:05.000
and the same for the Facebook group, that people want harder homework assignments.

00:08:05.000 --> 00:08:11.000
I'm not sure that's true universally, so if you have an opinion, why don't you just post it.

00:08:11.000 --> 00:08:13.000
I'd like to get a sense of it.

00:08:13.000 --> 00:08:17.000
I'm thinking of making an assignment where we toss everything togethera

00:08:17.000 --> 00:08:20.000
and really build like a mini version of an actual car.

00:08:20.000 --> 00:08:26.000
That's going to be really involved, so let me know what you feel like.

00:08:26.000 --> 00:08:29.000
This course right now, I would argue, is really Stanford caliber.

00:08:29.000 --> 00:08:32.000
What you guys are doing, and you girls are doing, is really

00:08:32.000 --> 00:08:36.000
at a quality that I would expect my best Standford students to do.

00:08:36.000 --> 00:08:42.000
The type of things you implement, certainly, is at the same pace I would teach at Stanford

00:08:42.000 --> 00:08:43.000
and possibly faster.

00:08:43.000 --> 00:08:47.000
But if I go to a general build-a-robot example, then I'm going to exceed beyond Stanford base.

00:08:47.000 --> 00:08:49.000
It's up to you. Let us know.

00:08:49.000 --> 00:08:53.000
All right. Keep us posted. I'll be reading the forums. I'm sure Sebastian will too.

00:08:53.000 --> 00:08:55.000
Thank you very much and see you next week.

00:08:55.000 --> 09:59:59.000
All right.

