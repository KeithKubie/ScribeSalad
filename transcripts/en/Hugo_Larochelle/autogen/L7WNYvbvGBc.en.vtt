WEBVTT
Kind: captions
Language: en

00:00:00.260 --> 00:00:07.859
 in this capsule we will see 

00:00:02.220 --> 00:00:09.210
 the tax collector algorithm then in the 

00:00:07.859 --> 00:00:11.099
 gatehouse decor closer neighbors we 

00:00:09.210 --> 00:00:14.099
 previously saw one of the disadvantages 

00:00:11.099 --> 00:00:16.410
 is that to make a prediction it 

00:00:14.099 --> 00:00:18.029
 keep in mind all the examples 

00:00:16.410 --> 00:00:19.920
 training all of which 

00:00:18.029 --> 00:00:21.150
 should be maintained in 

00:00:19.920 --> 00:00:23.609
 memory to be able to make a 

00:00:21.150 --> 00:00:25.560
 prediction for a new example this is 

00:00:23.609 --> 00:00:27.359
 it can be a problem if rather than 

00:00:25.560 --> 00:00:29.400
 to have a hundred examples 

00:00:27.359 --> 00:00:30.090
 we actually have in the 

00:00:29.400 --> 00:00:31.619
 thousands or millions 

00:00:30.090 --> 00:00:33.930
 drive copies so that 

00:00:31.619 --> 00:00:35.100
 would mean that doing the research of 

00:00:33.930 --> 00:00:37.739
 nearby close copies would be very 

00:00:35.100 --> 00:00:41.370
 expensive in computing time so in fact 

00:00:37.739 --> 00:00:43.680
 what we prefer to stay to see a way 

00:00:41.370 --> 00:00:45.780
 to have a model that is capable of a 

00:00:43.680 --> 00:00:46.620
 can compress the information that gets 

00:00:45.780 --> 00:00:50.280
 find in our center 

00:00:46.620 --> 00:00:51.750
 drive and not to require 

00:00:50.280 --> 00:00:53.370
 to always consult the whole 

00:00:51.750 --> 00:00:55.320
 when it comes time to 

00:00:53.370 --> 00:00:57.750
 make a prediction 

00:00:55.320 --> 00:01:01.199
 so what we're going to want is 

00:00:57.750 --> 00:01:03.120
 a model that has bars at m that's going 

00:01:01.199 --> 00:01:05.070
 adapt as we go 

00:01:03.120 --> 00:01:07.350
 observe data to try 

00:01:05.070 --> 00:01:09.240
 extract the relevant information from 

00:01:07.350 --> 00:01:10.650
 the training set and the flu 

00:01:09.240 --> 00:01:13.320
 super it's round it's an algorithm that 

00:01:10.650 --> 00:01:14.790
 lets do that this is maybe a 

00:01:13.320 --> 00:01:17.880
 from the first to yell learning 

00:01:14.790 --> 00:01:20.790
 that was actually invented and so we're going 

00:01:17.880 --> 00:01:22.560
 see it in this capsule then in the 

00:01:20.790 --> 00:01:25.890
 percepts guide round the idea is to have 

00:01:22.560 --> 00:01:28.500
 a model that will make a decision to 

00:01:25.890 --> 00:01:30.840
 classification from a function 

00:01:28.500 --> 00:01:33.780
 linear followed by a function that's 

00:01:30.840 --> 00:01:36.479
 that is, for an entry x 

00:01:33.780 --> 00:01:38.159
 give what they perceive will do a 

00:01:36.479 --> 00:01:39.869
 time they will stop dragged on a 

00:01:38.159 --> 00:01:44.250
 training set is taking a 

00:01:39.869 --> 00:01:46.829
 vector x the x another actor w do 

00:01:44.250 --> 00:01:48.450
 the product scala x1 rector w 

00:01:46.829 --> 00:01:52.110
 so match the parameters of the 

00:01:48.450 --> 00:01:53.700
 model is passed alone the result of the 

00:01:52.110 --> 00:01:56.250
 school product through a function 

00:01:53.700 --> 00:02:00.270
 very hot threshold that is going to be such that 

00:01:56.250 --> 00:02:02.610
 if the entry of the threshold function and more 

00:02:00.270 --> 00:02:03.810
 great equal to zero the output of the 

00:02:02.610 --> 00:02:06.960
 servette function 1 

00:02:03.810 --> 00:02:09.390
 and if not the function this they go 

00:02:06.960 --> 00:02:10.470
 go back 0 so we will focus in 

00:02:09.390 --> 00:02:11.770
 does it's a classification problem 

00:02:10.470 --> 00:02:17.140
 binary 

00:02:11.770 --> 00:02:18.880
 or appear there either 0 or 1 ok so that 

00:02:17.140 --> 00:02:19.450
 this is the model behind the grid of 

00:02:18.880 --> 00:02:23.500
 collector 

00:02:19.450 --> 00:02:26.440
 here we have a visualization of the calculation that 

00:02:23.500 --> 00:02:29.620
 is done by a tax collector so have we 

00:02:26.440 --> 00:02:31.000
 here all entries ex years up 

00:02:29.620 --> 00:02:33.670
 so great if it matches 

00:02:31.000 --> 00:02:37.150
 elements of the vector x so our vector 

00:02:33.670 --> 00:02:39.880
 x is actually a vector with 

00:02:37.150 --> 00:02:44.800
 the first excellent element x 2 up 

00:02:39.880 --> 00:02:48.280
 x1 is actually we can see the calculations 

00:02:44.800 --> 00:02:51.190
 of the past deceives as a kind of unity 

00:02:48.280 --> 00:02:54.130
 is a bit like a kind of neuron 

00:02:51.190 --> 00:02:59.020
 who is connected with peas w1 

00:02:54.130 --> 00:03:01.570
 up to wn at the inputs x1 up to xl and 

00:02:59.020 --> 00:03:04.570
 the activation of the neuron so the la 

00:03:01.570 --> 00:03:07.270
 output of the neuron your correspond to 

00:03:04.570 --> 00:03:10.150
 multiply each of the expert entries 

00:03:07.270 --> 00:03:12.670
 up to xn by a weight etc saint-just 

00:03:10.150 --> 00:03:14.260
 this extreme case of making the sum 

00:03:12.670 --> 00:03:18.220
 so we have actually corresponded to 

00:03:14.260 --> 00:03:21.190
 school products wxx owes 

00:03:18.220 --> 00:03:23.680
 pass this across a threshold for 

00:03:21.190 --> 00:03:25.780
 check the activation of between 

00:03:23.680 --> 00:03:27.310
 they exceed a certain threshold 

00:03:25.780 --> 00:03:28.480
 and if it's not certain threshold our 

00:03:27.310 --> 00:03:31.360
 neurons to make a species of 

00:03:28.480 --> 00:03:33.130
 discharge so is worth going out healthy and if not 

00:03:31.360 --> 00:03:36.580
 will remain inactive ie 

00:03:33.130 --> 00:03:39.280
 come out 0 so there is a kind of 

00:03:36.580 --> 00:03:41.950
 parallel to do here between this 

00:03:39.280 --> 00:03:43.510
 function there and calculating a species of 

00:03:41.950 --> 00:03:45.730
 artificial neurons that would be 

00:03:43.510 --> 00:03:47.709
 active if its activation of basins 

00:03:45.730 --> 00:03:50.980
 sun otherwise would be inactive so 

00:03:47.709 --> 00:03:52.870
 go out 1-0 and the administration sees that 

00:03:50.980 --> 00:03:56.860
 the arrows a bit like the connections 

00:03:52.870 --> 00:03:57.250
 input neurons and a neuron from 

00:03:56.860 --> 00:03:59.830
 threshold 

00:03:57.250 --> 00:04:01.840
 and then the size of the arrow is 

00:03:59.830 --> 00:04:05.080
 thickness it's a little here a 

00:04:01.840 --> 00:04:06.670
 illustration of the size of the weight 

00:04:05.080 --> 00:04:08.560
 so we could imagine that if w1 

00:04:06.670 --> 00:04:11.320
 would be close to zero while w2 

00:04:08.560 --> 00:04:14.380
 would be far and so that would mean that 

00:04:11.320 --> 00:04:16.060
 activated the activity of the calculation on the 

00:04:14.380 --> 00:04:18.609
 calculation result is much more 

00:04:16.060 --> 00:04:21.489
 influenced by the value of kz2 chi x 

00:04:18.609 --> 00:04:22.690
 a bigger weight than express so that 

00:04:21.489 --> 00:04:23.580
 it's just an illustration it's a 

00:04:22.690 --> 00:04:26.069
 example 

00:04:23.580 --> 00:04:28.020
 we repaired to other arrows other 

00:04:26.069 --> 00:04:29.400
 within arrows but so that's 

00:04:28.020 --> 00:04:31.229
 a visual illustration of the kind of 

00:04:29.400 --> 00:04:34.650
 calculation done by the collector on for 

00:04:31.229 --> 00:04:37.830
 make a prediction is the vector of 

00:04:34.650 --> 00:04:40.289
 weight w let's go watch it as 

00:04:37.830 --> 00:04:42.150
 the parameters of our model and if these 

00:04:40.289 --> 00:04:44.610
 parameters that will be adapted as 

00:04:42.150 --> 00:04:46.590
 and as our father's September 

00:04:44.610 --> 00:04:48.800
 to train will learn from 

00:04:46.590 --> 00:04:48.800
 data 

00:04:49.460 --> 00:04:56.370
 I would also like that typically 

00:04:52.500 --> 00:05:02.310
 in fact we want to introduce a 

00:04:56.370 --> 00:05:04.469
 certain well in the calculation that is going 

00:05:02.310 --> 00:05:07.740
 actually corresponds to vary kelly the 

00:05:04.469 --> 00:05:08.940
 comparison threshold so often this 

00:05:07.740 --> 00:05:12.990
 what we will actually see is that rather 

00:05:08.940 --> 00:05:16.409
 than to calculate wxx we will compute wx 

00:05:12.990 --> 00:05:17.990
 ex plus another vector that is going to be a 

00:05:16.409 --> 00:05:23.430
 another parameter that we will learn too 

00:05:17.990 --> 00:05:25.590
 b so we go wxx + b and do that 

00:05:23.430 --> 00:05:28.469
 it's the equivalent of not seeing a bep 

00:05:25.590 --> 00:05:30.779
 here but to say that my function is 

00:05:28.469 --> 00:05:33.599
 he will check if his den is there anymore 

00:05:30.779 --> 00:05:35.490
 big that - p and if bigger than 

00:05:33.599 --> 00:05:38.099
 less well we will return one otherwise we 

00:05:35.490 --> 00:05:40.800
 will go back 0 ok so this parameter there 

00:05:38.099 --> 00:05:42.479
 its its role it's a little bit of finding 

00:05:40.800 --> 00:05:45.990
 what is the right threshold to have for 

00:05:42.479 --> 00:05:47.969
 produce a good classification and 

00:05:45.990 --> 00:05:52.589
 in swimming sometimes I would put it 

00:05:47.969 --> 00:05:54.810
 not explicitly but a way of two 

00:05:52.589 --> 00:05:57.449
 to have a case implementation no 

00:05:54.810 --> 00:05:59.909
 explicit bias but that comes back 

00:05:57.449 --> 00:06:02.789
 implicitly it's always adding 

00:05:59.909 --> 00:06:05.729
 to our vectors in tree a constant 

00:06:02.789 --> 00:06:07.919
 in fact the value 1 and in this case also 

00:06:05.729 --> 00:06:12.539
 the connection between this constant one there 

00:06:07.919 --> 00:06:15.000
 and our our calculation so it goes there the 

00:06:12.539 --> 00:06:17.069
 factor the weight of this collection 

00:06:15.000 --> 00:06:18.900
 their calves actually correspond to b 

00:06:17.069 --> 00:06:21.900
 since we always want to have a liver b 

00:06:18.900 --> 00:06:26.460
 so it's like we had wx ex more 

00:06:21.900 --> 00:06:30.110
 our bias so that's the model 

00:06:26.460 --> 00:06:30.110
 behind the taxman 

00:06:30.379 --> 00:06:34.139
 so now commented what are we going 

00:06:32.520 --> 00:06:36.150
 train the tax collector commented on this 

00:06:34.139 --> 00:06:39.720
 who will adapt from a 

00:06:36.150 --> 00:06:41.850
 coaching attention so we have the 

00:06:39.720 --> 00:06:45.600
 equals just right here and there the idea is 

00:06:41.850 --> 00:06:48.510
 that the model the tax collector we go there 

00:06:45.600 --> 00:06:50.610
 shoot our training examples and 

00:06:48.510 --> 00:06:52.500
 he will adapt whenever the 

00:06:50.610 --> 00:06:53.250
 prediction that's going to be done will not be the 

00:06:52.500 --> 00:06:56.460
 right answer 

00:06:53.250 --> 00:06:58.920
 so he'll adapt eventually he goes 

00:06:56.460 --> 00:07:00.990
 stop adapting as soon as he goes 

00:06:58.920 --> 00:07:02.120
 return the correct answer on all 

00:07:00.990 --> 00:07:05.010
 our training data 

00:07:02.120 --> 00:07:07.440
 so here is the pseudo code for the 

00:07:05.010 --> 00:07:09.900
 run of the algorithm so what 

00:07:07.440 --> 00:07:12.780
 the tax collector we will do is that he 

00:07:09.900 --> 00:07:14.880
 will shoot all excited pairs 

00:07:12.780 --> 00:07:17.160
 yt who belong to our center 

00:07:14.880 --> 00:07:20.550
 training and so for each in 

00:07:17.160 --> 00:07:22.920
 very excited we will calculate the prediction 

00:07:20.550 --> 00:07:26.330
 made by our perception so this ch of 

00:07:22.920 --> 00:07:31.110
 xt which therefore corresponds to take excited 

00:07:26.330 --> 00:07:34.200
 x the air product to the vectors of 

00:07:31.110 --> 00:07:36.330
 weight w possibly adjusting gamer 

00:07:34.200 --> 00:07:39.000
 well and get through the function 

00:07:36.330 --> 00:07:41.340
 it's alas then we'll do it 

00:07:39.000 --> 00:07:43.380
 difficult the prediction made by the 

00:07:41.340 --> 00:07:45.840
 collector we correspond to the good 

00:07:43.380 --> 00:07:49.770
 so class is what we managed to do well 

00:07:45.840 --> 00:07:51.240
 predicting our target was there if we had 

00:07:49.770 --> 00:07:54.060
 predicts our target we do nothing we 

00:07:51.240 --> 00:07:57.090
 move on to the next example if we go 

00:07:54.060 --> 00:08:00.420
 do a modification of the weights w so 

00:07:57.090 --> 00:08:04.430
 each of the weights wi2wi so if the 

00:08:00.420 --> 00:08:08.100
 3d elements of the vector w in drome 

00:08:04.430 --> 00:08:11.310
 so we just go there and where the new w 

00:08:08.100 --> 00:08:13.800
 it'll be launched wy more in terms of 

00:08:11.310 --> 00:08:17.910
 correction that we see here the term of 

00:08:13.800 --> 00:08:20.070
 correction it's alpha that will handle to 

00:08:17.910 --> 00:08:22.760
 how fast will we learn in which 

00:08:20.070 --> 00:08:25.530
 point we will change allow us wy 

00:08:22.760 --> 00:08:29.220
 sees the difference between the real 

00:08:25.530 --> 00:08:31.200
 answer at least the prediction and times 

00:08:29.220 --> 00:08:34.800
 finally the entrance to which were 

00:08:31.200 --> 00:08:37.710
 connected our weight w so there m 

00:08:34.800 --> 00:08:40.410
 entered for our example tm 

00:08:37.710 --> 00:08:44.400
 drive so xti this is the 3rd 

00:08:40.410 --> 00:08:47.000
 elements of the vector xt and so we're going 

00:08:44.400 --> 00:08:47.000
 shoot like that 

00:08:47.350 --> 00:08:51.490
 until we're actually 

00:08:50.530 --> 00:08:54.790
 all our dances 

00:08:51.490 --> 00:08:57.790
 training and that if we have 

00:08:54.790 --> 00:08:59.230
 actually we'll shoot like that 

00:08:57.790 --> 00:09:02.740
 until we reach a certain 

00:08:59.230 --> 00:09:04.750
 khiter stop is one of the criteria 

00:09:02.740 --> 00:09:06.310
 stop that sometimes used it's 

00:09:04.750 --> 00:09:10.450
 to simply say that I continue 

00:09:06.310 --> 00:09:13.000
 until the number of errors is 

00:09:10.450 --> 00:09:14.740
 0 where we can simply identify 

00:09:13.000 --> 00:09:16.420
 a maximum number of iterations then 

00:09:14.740 --> 00:09:21.400
 the a10 terrisse according to this number 

00:09:16.420 --> 00:09:23.290
 of iterations so the equation we see 

00:09:21.400 --> 00:09:26.410
 here it's called the rule 

00:09:23.290 --> 00:09:28.180
 learning tax collector and then 

00:09:26.410 --> 00:09:29.800
 the alpha here it's called the 

00:09:28.180 --> 00:09:31.510
 learning rate we say to 

00:09:29.800 --> 00:09:35.110
 learning because it determines to 

00:09:31.510 --> 00:09:36.100
 what speed will be changed to 

00:09:35.110 --> 00:09:37.950
 how much will it be changed our 

00:09:36.100 --> 00:09:42.940
 settings what speed do we want 

00:09:37.950 --> 00:09:44.650
 learning will take place so we 

00:09:42.940 --> 00:09:45.850
 will here look at the rule to try 

00:09:44.650 --> 00:09:47.790
 to have a little an edition why 

00:09:45.850 --> 00:09:51.240
 could it work so 

00:09:47.790 --> 00:09:53.200
 consider the case where yt would be equal to 1 

00:09:51.240 --> 00:09:59.730
 imagine we made a mistake so 

00:09:53.200 --> 00:10:01.930
 or h2x so existed would be zero 

00:09:59.730 --> 00:10:03.630
 so in this case this is actually what is 

00:10:01.930 --> 00:10:10.750
 arrived is that we wanted to predict a 

00:10:03.630 --> 00:10:12.790
 but wxx was smaller xero so the 

00:10:10.750 --> 00:10:14.770
 exit after the threshold was 2 hours 

00:10:12.790 --> 00:10:17.980
 so what we would like to do in fact 

00:10:14.770 --> 00:10:19.960
 is to increase what is in input of 

00:10:17.980 --> 00:10:23.170
 the function if we would like wxx 

00:10:19.960 --> 00:10:25.230
 be bigger so what does it mean 

00:10:23.170 --> 00:10:28.720
 in fact, we would like to change 

00:10:25.230 --> 00:10:30.480
 our each of our weights wy for that 

00:10:28.720 --> 00:10:35.170
 next time we want to multiply 

00:10:30.480 --> 00:10:37.000
 wxx polish a result that is more 

00:10:35.170 --> 00:10:39.940
 big that will get closer to zero for 

00:10:37.000 --> 00:10:43.350
 it is hoped to exceed the threshold of 0 then 

00:10:39.940 --> 00:10:47.200
 get an exit that was galley 

00:10:43.350 --> 00:10:48.730
 so we have the term existed less 

00:10:47.200 --> 00:10:52.450
 bought which gives us in what 

00:10:48.730 --> 00:10:53.100
 direction is what we want wxx to 

00:10:52.450 --> 00:10:56.410
 directed 

00:10:53.100 --> 00:10:59.379
 and there now for the weight ebay w if 

00:10:56.410 --> 00:11:02.259
 the input to which connected xti 

00:10:59.379 --> 00:11:05.559
 is positive but in this case we 

00:11:02.259 --> 00:11:07.089
 want to increase w ok but if the input 

00:11:05.559 --> 00:11:08.679
 was negative in this case one 

00:11:07.089 --> 00:11:09.970
 would like w to be smaller because 

00:11:08.679 --> 00:11:13.149
 if we increase and w 

00:11:09.970 --> 00:11:15.819
 the result of wx now extract 

00:11:13.149 --> 00:11:16.749
 further from zero it would decrease and so 

00:11:15.819 --> 00:11:20.470
 that's why we have to multiply 

00:11:16.749 --> 00:11:23.619
 also, for example, six positive countries 

00:11:20.470 --> 00:11:24.220
 but know 1 - 0 times something 

00:11:23.619 --> 00:11:25.989
 positive 

00:11:24.220 --> 00:11:27.579
 still a term that is positive so we 

00:11:25.989 --> 00:11:29.919
 will increase w what is the 

00:11:27.579 --> 00:11:33.189
 desired behavior because six 

00:11:29.919 --> 00:11:36.369
 ex-country negatives because if we 

00:11:33.189 --> 00:11:37.779
 would like wy to decrease and so we 

00:11:36.369 --> 00:11:39.759
 would have a positive number times a number 

00:11:37.779 --> 00:11:42.239
 negative so we stop everything will end 

00:11:39.759 --> 00:11:45.069
 here which is negative so double very 

00:11:42.239 --> 00:11:46.989
 would decrease and there now you can 

00:11:45.069 --> 00:11:48.399
 do the exercise for the body or what 

00:11:46.989 --> 00:11:50.889
 would be the greens ie the 

00:11:48.399 --> 00:11:53.470
 target after 10.0 instead we would have 

00:11:50.889 --> 00:11:55.089
 predicts one and in this case also you 

00:11:53.470 --> 00:11:56.619
 will see that again the rule here 

00:11:55.089 --> 00:11:59.470
 and there the good behavior 

00:11:56.619 --> 00:12:02.139
 that is to say that we will indeed tried 

00:11:59.470 --> 00:12:05.199
 to change that term here two to 

00:12:02.139 --> 00:12:07.419
 inside the sun to change a 

00:12:05.199 --> 00:12:09.039
 side of the threshold that's bad of the 

00:12:07.419 --> 00:12:10.899
 wrong answer to one side of the threshold 

00:12:09.039 --> 00:12:16.119
 which is good ie which produces the 

00:12:10.899 --> 00:12:18.209
 good answer is finally I just 

00:12:16.119 --> 00:12:20.799
 points out that finally one more way 

00:12:18.209 --> 00:12:24.309
 succinct decree is our rule for 

00:12:20.799 --> 00:12:26.289
 describe a rule about w and say that 

00:12:24.309 --> 00:12:27.909
 it applies to all possible on 

00:12:26.289 --> 00:12:29.259
 can the vector forms crises on 

00:12:27.909 --> 00:12:32.049
 says we're going to take the vector of 

00:12:29.259 --> 00:12:36.309
 w parameters is what we will do is 

00:12:32.049 --> 00:12:37.949
 we will calculate we will add the 

00:12:36.309 --> 00:12:41.889
 excited vector times 

00:12:37.949 --> 00:12:44.019
 yt minus the prediction made the 

00:12:41.889 --> 00:12:46.539
 learning tour so that this rule 

00:12:44.019 --> 00:12:47.829
 to vector shapes that's what gives 

00:12:46.539 --> 00:12:49.749
 exactly the same result as 

00:12:47.829 --> 00:12:51.970
 to apply the update we saw 

00:12:49.749 --> 00:12:54.309
 in the previous slide but for 

00:12:51.970 --> 00:12:56.970
 each of the positions there in our 

00:12:54.309 --> 00:12:56.970
 actor w 

