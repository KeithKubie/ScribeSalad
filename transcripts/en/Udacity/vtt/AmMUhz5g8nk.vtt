WEBVTT
Kind: captions
Language: en

00:00:00.168 --> 00:00:02.732
Now that we have seen
what DRAM looks like,

00:00:02.732 --> 00:00:06.590
let's briefly look at how to
connect the DRAM to the processor.

00:00:06.590 --> 00:00:08.112
So we have our processor.

00:00:08.112 --> 00:00:12.783
It sends its requests to level one
cache, which sends its misses and write

00:00:12.783 --> 00:00:17.604
back requests to the larger level two
cache, which might send its misses and

00:00:17.604 --> 00:00:21.295
write back requests to in even
larger level three cache and

00:00:21.295 --> 00:00:25.320
let's say that these are all
on our processor chip.

00:00:25.320 --> 00:00:27.420
Now what happens is the misses and

00:00:27.420 --> 00:00:32.409
the write back requests from the L3
cache would be made over and

00:00:32.409 --> 00:00:37.180
external connection, so
we need processor pins here.

00:00:37.180 --> 00:00:43.110
And traditionally, this data would go
over what is called a front-side bus.

00:00:43.110 --> 00:00:45.808
Now you want to design
the processor chip, so

00:00:45.808 --> 00:00:48.865
that you can connect it to
many possible memories.

00:00:48.865 --> 00:00:53.495
So you don't design the front-side bus,
such that it supplies

00:00:53.495 --> 00:00:58.222
the row address and a column address and
so on to the memory chips.

00:00:58.222 --> 00:01:03.167
What you have instead is another chip
that contains the memory controller and

00:01:03.167 --> 00:01:08.114
that memory controller will have what's
called a memory channel connecting

00:01:08.114 --> 00:01:09.423
it to a DRAM module.

00:01:09.423 --> 00:01:13.578
And over this channel,
it will issue things like open a row,

00:01:13.578 --> 00:01:15.786
read something, get the data.

00:01:15.786 --> 00:01:17.369
Write something, supply the data.

00:01:17.369 --> 00:01:19.836
Close or open another one and so on and

00:01:19.836 --> 00:01:23.585
it will usually have more
than one such memory channel.

00:01:23.585 --> 00:01:28.382
So the memory latency is seen by
the level three cache is not only

00:01:28.382 --> 00:01:31.820
the access time of
the memory are right here,

00:01:31.820 --> 00:01:36.182
it includes sending the request
over a front-side bus.

00:01:36.182 --> 00:01:39.493
Having the memory
controller figure it out,

00:01:39.493 --> 00:01:42.991
sending the page open to
the appropriate DRAM.

00:01:42.991 --> 00:01:48.598
Sending a request to read, supplying
the column addresses and everything.

00:01:48.598 --> 00:01:51.470
Getting the data over
the memory channel,

00:01:51.470 --> 00:01:54.429
know that you have
a level three cache miss.

00:01:54.429 --> 00:01:58.962
That means you want a whole cache
line worth of data to read, so

00:01:58.962 --> 00:02:02.109
it takes a while to
transfer the data here.

00:02:02.109 --> 00:02:06.335
Then the memory controller reads
it from the memory channel,

00:02:06.335 --> 00:02:09.018
which usually has one bus frequency and

00:02:09.018 --> 00:02:14.462
sends it at a different data rate over
to front-side bus to the processor chip,

00:02:14.462 --> 00:02:18.626
which then puts the line together and
puts it into L3 cache.

00:02:18.626 --> 00:02:25.163
So the latency includes all of this
here in addition to just the memory

00:02:25.163 --> 00:02:32.054
access and this can be a significant
part of the overall memory latency.

00:02:32.054 --> 00:02:38.261
So recent processor chips integrate
the memory controller, which means that

00:02:38.261 --> 00:02:44.383
the memory controller is put on the same
chip as the processor and the caches.

00:02:44.383 --> 00:02:49.703
Now we no longer need the front-side
bus, we can use lots of unshaped

00:02:49.703 --> 00:02:54.307
wiring to communicate with
the on chip memory controller.

00:02:54.307 --> 00:02:58.327
So this can be plenty of bandwidth and
very, very close.

00:02:58.327 --> 00:03:02.751
This whole thing is something
like two by two centimeters and

00:03:02.751 --> 00:03:08.145
then we just send requests directly
through the memory channels to DRAM.

00:03:08.145 --> 00:03:12.294
So now the processor chip directly
knows how to talk to DRAM's and

00:03:12.294 --> 00:03:17.282
open pages and so on, which dramatically
can reduce this part of the latency.

00:03:17.282 --> 00:03:21.427
And because it's not a negligible
part of the overall latency,

00:03:21.427 --> 00:03:24.353
we get our data from
dram a little bit faster.

00:03:24.353 --> 00:03:29.258
Actually, 10,
20 maybe 30% faster than before,

00:03:29.258 --> 00:03:31.958
but the cost of that is that now,

00:03:31.958 --> 00:03:37.082
we design a processor chip to
talk to a specific kind of DRAM.

00:03:37.082 --> 00:03:38.605
And because of that,

00:03:38.605 --> 00:03:43.606
we need a relatively high degree of
standardization of DRAM modules.

00:03:43.606 --> 00:03:48.470
So that, for example, when we go from 2
gigabytes to 4 gigabyte memory modules,

00:03:48.470 --> 00:03:50.979
we don't have to
redesign our whole chip.

00:03:50.979 --> 00:03:55.778
So the protocols here, got a lot
more standardized and uniform and

00:03:55.778 --> 00:03:57.501
flexible than before.

00:03:57.501 --> 00:04:01.526
But in exchange, we get to transfer data
very quickly between the processor and

00:04:01.526 --> 00:04:03.140
the memory controller.

00:04:03.140 --> 00:04:06.280
We can make the memory
controller now very smart and

00:04:06.280 --> 00:04:08.850
then access memory in
a more efficient way.

