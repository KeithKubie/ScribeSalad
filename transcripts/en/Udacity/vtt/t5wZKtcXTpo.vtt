WEBVTT
Kind: captions
Language: en

00:00:00.380 --> 00:00:02.110
This is about the time
when you might say,

00:00:02.110 --> 00:00:04.370
what does this have to
do with computer vision?

00:00:04.370 --> 00:00:06.340
&gt;&gt; What does this have
to do with vision?

00:00:06.340 --> 00:00:08.920
&gt;&gt; I'm so glad you asked, all right?

00:00:08.920 --> 00:00:13.470
Well, another way of phrasing what we've
been doing is, given some sequence of

00:00:13.470 --> 00:00:19.077
observations, which model was most
likely to have generated those?

00:00:19.077 --> 00:00:22.880
So using our previous clothing and
weather example.

00:00:22.880 --> 00:00:26.620
So, suppose you're seeing some
sequence of clothing, right?

00:00:26.620 --> 00:00:29.096
So you, you check the clothing that
people are wearing each day, and

00:00:29.096 --> 00:00:31.510
you see this, coat, coat, whatever.

00:00:31.510 --> 00:00:35.030
And then the question you want to
ask is, is this Philadelphia,

00:00:35.030 --> 00:00:36.800
Boston, or Newark?

00:00:36.800 --> 00:00:39.273
The idea is that presumably,
what you've been doing is,

00:00:39.273 --> 00:00:42.655
you've been collecting sequences of
these observations from Philadelphia,

00:00:42.655 --> 00:00:45.090
a bunch of them from Boston,
a bunch of them from Newark.

00:00:45.090 --> 00:00:48.780
You have a trained a model, and
we'll talk about that later.

00:00:48.780 --> 00:00:53.980
You've created a model that will tend
to generate sequences, like you see in

00:00:53.980 --> 00:00:58.280
Philadelphia, or in Boston, or Newark,
with the same statistics that they have.

00:00:58.280 --> 00:01:02.210
And then given some new observation
sequence, you'd like to say, you know,

00:01:02.210 --> 00:01:03.870
which one is this?

00:01:03.870 --> 00:01:08.190
Now, notice that if we were
checking Boston versus Arizona,

00:01:09.580 --> 00:01:11.220
you basically wouldn't
need the sequence.

00:01:11.220 --> 00:01:13.180
It doesn't rain in Arizona,
for the most part.

00:01:13.180 --> 00:01:16.250
And you could say,
well do I see umbrellas, okay?

00:01:16.250 --> 00:01:18.970
And since it's always lousy
weather in Boston, I live there,

00:01:18.970 --> 00:01:20.920
if you see bathing suits,
you know it's actually Cape Cod.

00:01:20.920 --> 00:01:24.780
So the idea is, you know, just from
the individual elements themselves,

00:01:24.780 --> 00:01:29.290
you could determine whether
it was Boston or Arizona.

00:01:29.290 --> 00:01:32.820
The whole idea of
representing the time series

00:01:32.820 --> 00:01:35.970
is that there's something about
the sequentiality that matters.

00:01:35.970 --> 00:01:39.140
It's the statistics of one
thing following another,

00:01:39.140 --> 00:01:42.840
that is indicative of the actual class.

00:01:42.840 --> 00:01:43.630
And what you're doing is,

00:01:43.630 --> 00:01:47.560
you're building some models of those
time series, so you can then given

00:01:47.560 --> 00:01:51.430
some observation sequence,
you can say which one's most likely.

00:01:51.430 --> 00:01:54.901
And what we're going to to do is, we're
going to apply that to computer vision.

