WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:08.194
[MUSIC PLAYING]

00:00:08.194 --> 00:00:09.720
LEZHIE LI: Hi, everyone.

00:00:09.720 --> 00:00:13.560
My name's Lezhi, and I'm a
software engineer at Uber.

00:00:13.560 --> 00:00:16.760
So today I'm going to talk about
how we build a visual debugging

00:00:16.760 --> 00:00:22.060
tool for machine learning
using TensorFlow.js.

00:00:22.060 --> 00:00:25.480
So why is model
debugging important?

00:00:25.480 --> 00:00:27.250
Machine learning
practitioners report

00:00:27.250 --> 00:00:29.740
that they spend the
majority of their time

00:00:29.740 --> 00:00:32.229
not on building a
model, but instead,

00:00:32.229 --> 00:00:37.000
on iterating and debugging
of the existing model.

00:00:37.000 --> 00:00:39.310
So there's huge
opportunity for us

00:00:39.310 --> 00:00:44.930
to improve efficiency
of the 80% of the time.

00:00:44.930 --> 00:00:50.050
Traditionally, the only
guidance for model developers

00:00:50.050 --> 00:00:53.800
to evaluate a model
performance is

00:00:53.800 --> 00:00:55.920
by looking at
performance metrics.

00:00:55.920 --> 00:00:58.160
Although these
metrics are useful,

00:00:58.160 --> 00:00:59.800
they do not give
too much insight

00:00:59.800 --> 00:01:03.520
into how to improve on a
model or why a model performs

00:01:03.520 --> 00:01:06.550
in a certain way.

00:01:06.550 --> 00:01:10.750
So given the intrinsic opacity
of machine learning algorithms,

00:01:10.750 --> 00:01:13.480
it is very hard for
anyone who wants

00:01:13.480 --> 00:01:15.920
to try to understand
model performance.

00:01:15.920 --> 00:01:17.600
So how do we solve that problem.

00:01:17.600 --> 00:01:21.160
The idea here is that we can
transform a model space problem

00:01:21.160 --> 00:01:22.970
into a data space problem.

00:01:22.970 --> 00:01:24.880
And by that we
mean that, instead

00:01:24.880 --> 00:01:27.730
of asking what went
wrong with the model,

00:01:27.730 --> 00:01:31.390
we look at on which data did
this model make mistakes.

00:01:31.390 --> 00:01:35.350
And instead of asking why a
model makes certain mistakes,

00:01:35.350 --> 00:01:37.180
we look into the
future characteristics

00:01:37.180 --> 00:01:40.370
of these failed data points.

00:01:40.370 --> 00:01:43.190
So based on those two
ideas, we developed

00:01:43.190 --> 00:01:46.640
Manifold, which is a model
agnostic visual debugger

00:01:46.640 --> 00:01:47.570
for machine learning.

00:01:50.180 --> 00:01:53.070
Here's the workflow
of using Manifold.

00:01:53.070 --> 00:01:56.230
The user will connect
Manifold to the output data

00:01:56.230 --> 00:01:59.060
set of several machine
learning outcomes,

00:01:59.060 --> 00:02:02.510
and Manifold will automatically
segment these data sets

00:02:02.510 --> 00:02:04.880
into subsets, each
subsets containing

00:02:04.880 --> 00:02:08.900
data points with similar
performance with each other.

00:02:08.900 --> 00:02:13.850
The users would choose the
subset of their interest

00:02:13.850 --> 00:02:16.480
to compare against each
other, and Manifold

00:02:16.480 --> 00:02:19.550
would highlight the feature
distribution difference

00:02:19.550 --> 00:02:22.190
of these two different
subsets, and helping

00:02:22.190 --> 00:02:28.050
them to diagnose the behavior
of the performance outcome.

00:02:28.050 --> 00:02:32.250
So while we developed these
ideas into production,

00:02:32.250 --> 00:02:34.335
we faced several
technology challenges.

00:02:34.335 --> 00:02:36.990
And among them there's a
performance challenge and also

00:02:36.990 --> 00:02:40.690
portability challenge.

00:02:40.690 --> 00:02:45.720
So traditionally, it is the
model training backend's job

00:02:45.720 --> 00:02:49.110
to handle the performance
metric calculation.

00:02:49.110 --> 00:02:50.880
But that pattern is
no more applicable

00:02:50.880 --> 00:02:56.640
to our visual interface because
of the latency introduced

00:02:56.640 --> 00:03:03.910
by the recalculation in response
to the user interaction.

00:03:03.910 --> 00:03:06.265
And also, if you want
to connect Manifold

00:03:06.265 --> 00:03:09.610
to another machine
learning training back end,

00:03:09.610 --> 00:03:12.610
there are two pieces of code we
need to port out, the back end

00:03:12.610 --> 00:03:15.070
code and a front end code.

00:03:15.070 --> 00:03:21.270
But in reality, the metrics
calculation logic actually

00:03:21.270 --> 00:03:24.490
belong to the visual
tool and should not

00:03:24.490 --> 00:03:28.160
be injected into the
training back end.

00:03:28.160 --> 00:03:32.030
Those two reasons shows why
we put this computation logic

00:03:32.030 --> 00:03:33.920
inside of front end.

00:03:33.920 --> 00:03:37.370
And because this computation
could get intensive as a data

00:03:37.370 --> 00:03:39.800
volume increases,
that's why we use

00:03:39.800 --> 00:03:42.560
TensorFlow.js to help us
increase the competition

00:03:42.560 --> 00:03:45.420
efficiency.

00:03:45.420 --> 00:03:47.690
So what are the
intensive computation

00:03:47.690 --> 00:03:50.690
involved in this
Manifold interface?

00:03:50.690 --> 00:03:53.030
In performance
configuration view,

00:03:53.030 --> 00:03:56.630
we compute and perform
scores for each data point

00:03:56.630 --> 00:03:59.360
on each model and
use those metrics

00:03:59.360 --> 00:04:02.420
to run the K-means
clustering to segment

00:04:02.420 --> 00:04:05.240
this data set into subsets.

00:04:05.240 --> 00:04:08.570
And in the future attribution
view, for each feature

00:04:08.570 --> 00:04:12.260
we compute the distribution
histograms of the two

00:04:12.260 --> 00:04:14.870
different subsets,
and using those

00:04:14.870 --> 00:04:17.899
histograms to compute
KL-divergence to rank

00:04:17.899 --> 00:04:22.010
that feature importance
for model developers

00:04:22.010 --> 00:04:26.620
to inspect the
model performance.

00:04:26.620 --> 00:04:29.530
And in all of those
scenarios, TensorFlow.js

00:04:29.530 --> 00:04:32.740
gave us a lot of
performance boosting

00:04:32.740 --> 00:04:35.410
compared to plain
JavaScript implementation.

00:04:35.410 --> 00:04:37.840
And in some cases, the
performance boosting

00:04:37.840 --> 00:04:43.930
can be as high as 100 times, for
the per instance model metrics

00:04:43.930 --> 00:04:46.860
computation.

00:04:46.860 --> 00:04:51.300
So to conclude, complex tasks
such as machine learning

00:04:51.300 --> 00:04:55.530
diagnosis can benefit a lot from
numerical computation capacity

00:04:55.530 --> 00:04:56.600
of TensorFlow.js.

00:04:56.600 --> 00:05:01.140
And TensorFlow.js opens up new
opportunities for developers

00:05:01.140 --> 00:05:03.840
of visual analytics source.

00:05:03.840 --> 00:05:05.910
OK, that's it.

00:05:05.910 --> 00:05:07.110
Thank you.

00:05:07.110 --> 00:05:09.210
[APPLAUSE]

00:05:09.210 --> 00:05:13.460
[MUSIC PLAYING]

