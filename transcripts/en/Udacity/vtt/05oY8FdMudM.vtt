WEBVTT
Kind: captions
Language: en

00:00:00.150 --> 00:00:04.026
What I'd like to do, and [LAUGH] I'm
guessing maybe you don't want me to,

00:00:04.026 --> 00:00:05.838
but I'm going to try to do it anyway,

00:00:05.838 --> 00:00:09.485
is go through the argument as to
why policy duration actually works.

00:00:09.485 --> 00:00:13.449
I think ultimately it's not that bad,
but

00:00:13.449 --> 00:00:16.869
we're going to [LAUGH] slog through it.

00:00:16.869 --> 00:00:20.900
And so, one of the things we're going to
need is the ability to compare policies

00:00:20.900 --> 00:00:24.001
to each other, and
value functions to each other, and so,

00:00:24.001 --> 00:00:26.748
we're going to introduce
the concept of domination.

00:00:26.748 --> 00:00:27.709
&gt;&gt; Oh, yeah.

00:00:27.709 --> 00:00:28.376
&gt;&gt; [LAUGH] So,

00:00:28.376 --> 00:00:32.390
this is what domination [LAUGH]
means in the context of policies.

00:00:32.390 --> 00:00:37.490
We're going to say that policy one
dominates policy two if it's the case

00:00:37.490 --> 00:00:42.230
that for all states the value of
that policy, at that state for

00:00:42.230 --> 00:00:46.530
policy one, is bigger than or equal to
the value at that state for policy two.

00:00:46.530 --> 00:00:50.570
So, it could be that there's some
policies where policy one does better in

00:00:50.570 --> 00:00:53.060
one state, policy two does
better in another state, but

00:00:53.060 --> 00:00:57.120
if it dominates it, policy one
has to do no worse in any state.

00:00:57.120 --> 00:00:59.603
And in fact, we're going to
say we have strict domination.

00:00:59.603 --> 00:01:02.563
[NOISE] If it's the case that
&gt;&gt; [LAUGH]

00:01:02.563 --> 00:01:04.507
&gt;&gt; policy one dominates policy two, and

00:01:04.507 --> 00:01:05.724
there's some state for

00:01:05.724 --> 00:01:08.901
which it's actually strictly better,
it's not equality.

00:01:08.901 --> 00:01:15.078
And just for fun, we'll also introduce
the concept of epsilon optimal policies.

00:01:15.078 --> 00:01:20.266
So, a policy is epsilon optimal if it's
the case that the value function for

00:01:20.266 --> 00:01:23.914
that policy is epsilon close
to the value function for

00:01:23.914 --> 00:01:26.440
the optimal policy at all states.

00:01:26.440 --> 00:01:29.770
And so what this does is it gives
us a concept of bounding loss or

00:01:29.770 --> 00:01:30.805
bounding regret.

00:01:30.805 --> 00:01:35.507
So, we'll say that a policy is nearly
optimal if the amount that it loses,

00:01:35.507 --> 00:01:38.282
essentially, per time
step is very small.

00:01:38.282 --> 00:01:39.240
&gt;&gt; Okay.

00:01:39.240 --> 00:01:43.040
So, by the way, does this mean that if
policy one dominates policy two, but

00:01:43.040 --> 00:01:46.550
does not strictly dominate it, they
must have the same value everywhere?

00:01:46.550 --> 00:01:47.160
&gt;&gt; Yeah, that's right.

00:01:47.160 --> 00:01:49.710
They'd have to have- it
would never be greater than,

00:01:49.710 --> 00:01:52.400
it would always be greater than or equal
to, which means it's always equal to.

00:01:52.400 --> 00:01:55.680
So, two policies that,
well, what you said.

00:01:55.680 --> 00:01:56.420
&gt;&gt; Oh, okay, good.

00:01:56.420 --> 00:01:57.340
Well, as long as it's what I said.

