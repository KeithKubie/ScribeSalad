WEBVTT
Kind: captions
Language: en

00:00:00.540 --> 00:00:02.415
So let's see what happens when the current

00:00:02.415 --> 00:00:06.670
lock-holder comes around to unlocking the lock. What he's

00:00:06.670 --> 00:00:09.570
going to do is, he's going to execute the unlock

00:00:09.570 --> 00:00:12.340
algorithm. And the unlock algorithm, the first thing that

00:00:12.340 --> 00:00:20.930
it does, is it sets this position that the lockholder had from HL to MW. And the

00:00:20.930 --> 00:00:22.820
reason for that is, is that this is a

00:00:22.820 --> 00:00:25.640
circular queue and since it's a circular queue even

00:00:25.640 --> 00:00:28.995
though queue last is here future requesters can, can come

00:00:28.995 --> 00:00:32.320
around and then eventually somebody may come here and may want

00:00:32.320 --> 00:00:35.350
to occupy this particular slot and they have to know that

00:00:35.350 --> 00:00:37.480
they have to wait. And that's the reason, the first thing

00:00:37.480 --> 00:00:40.320
that the current lock holder does, is to mark this

00:00:40.320 --> 00:00:44.110
spot that he used to be at, as hl. The next

00:00:44.110 --> 00:00:47.080
thing that the current lock holder is, is going to do is

00:00:47.080 --> 00:00:50.730
signal the next guy in the circular queue. So, the current

00:00:50.730 --> 00:00:53.500
lock holder was here, so you'd mark it as mw

00:00:53.500 --> 00:00:55.800
for future requesters that may come and wait on his

00:00:55.800 --> 00:01:00.310
spot. And the next request in the circular queue is

00:01:00.310 --> 00:01:02.410
the guy next to him. And therefore what he is

00:01:02.410 --> 00:01:05.074
doing is, he is saying you know, current plus one

00:01:05.074 --> 00:01:09.140
mode N, is going to be set to hl. And so,

00:01:09.140 --> 00:01:12.740
that guy would have been waiting in this position and

00:01:12.740 --> 00:01:15.760
so he'll get the signal. And therefore he will be

00:01:15.760 --> 00:01:17.600
getting ready to go. And he can get into the

00:01:17.600 --> 00:01:19.670
critical section and do whatever he wants to do with

00:01:19.670 --> 00:01:23.590
the Data structure that is protected by this particular lock.

00:01:23.590 --> 00:01:27.630
Now this will go on, and eventually, my predecessor will become

00:01:27.630 --> 00:01:30.912
the current lock holder. And when my predecessor is done

00:01:30.912 --> 00:01:33.726
using the lock, he'll come around to do an unlock

00:01:33.726 --> 00:01:37.076
and when the current lock holder who's my predecessor does

00:01:37.076 --> 00:01:40.761
the unlock operation, that's going to be resulting in a signal for

00:01:40.761 --> 00:01:44.810
me, because basically. He's going to set the flags array,

00:01:44.810 --> 00:01:47.450
the next spot in the flags array, as hl. And

00:01:47.450 --> 00:01:50.380
that's the spot I'm waiting on. So good news for

00:01:50.380 --> 00:01:55.435
me. I've got my position marked as hl, and what

00:01:55.435 --> 00:01:58.000
that means is that now I've got the lock. And

00:01:58.000 --> 00:01:59.590
now I can go off into the critical section do

00:01:59.590 --> 00:02:02.680
what I need to do in order to do the

00:02:02.680 --> 00:02:06.340
code that is associated with the critical section protected by,

00:02:06.340 --> 00:02:09.580
this particular lock out. Now that we understand that the

00:02:09.580 --> 00:02:14.100
lock and the unlock algorithm works with this array-based queuing,

00:02:14.100 --> 00:02:17.250
let's talk about some of the virtues of this algorithm.

00:02:17.250 --> 00:02:19.100
The first thing that you notice is that there is

00:02:19.100 --> 00:02:22.880
exactly one atomic operation that you have to carry out,

00:02:22.880 --> 00:02:26.910
put, put critical sections so,every time you want to acquire a

00:02:26.910 --> 00:02:29.670
lock you come in and do a fetch and increment

00:02:29.670 --> 00:02:31.470
and that is all that you do in order to get

00:02:31.470 --> 00:02:34.230
the lock. And so there's one atomic operation that

00:02:34.230 --> 00:02:38.510
you do per critical section, that's good news. And

00:02:38.510 --> 00:02:40.340
the other thing that you also notice is that,

00:02:40.340 --> 00:02:43.480
the processes are all sequenced in other words there is

00:02:43.480 --> 00:02:47.340
fairness uh, so whoever comes first. Gets into the

00:02:47.340 --> 00:02:49.850
queue ahead of me and when I come in

00:02:49.850 --> 00:02:52.150
if people are going to come after me they're going to

00:02:52.150 --> 00:02:54.390
get queued up after me. So that's good news also.

00:02:56.320 --> 00:03:00.240
And the spin variable we're going to mark my position

00:03:00.240 --> 00:03:03.990
in this array my spin variable is distinct from

00:03:03.990 --> 00:03:06.480
the spin variable of all the other guys that

00:03:06.480 --> 00:03:08.710
may be waiting for the same lock. That's another good

00:03:08.710 --> 00:03:12.590
thing. In other words, I'm completely unaffected by all

00:03:12.590 --> 00:03:16.300
the signaling that it will happen when the guys that

00:03:16.300 --> 00:03:18.960
are ahead of me were getting the lock and,

00:03:18.960 --> 00:03:21.710
and signaling the next guy and so on. I'm completely

00:03:21.710 --> 00:03:24.880
impervious to that because I'm spinning on my

00:03:24.880 --> 00:03:28.360
own private variable. Waiting for the lock. And

00:03:28.360 --> 00:03:30.630
of course correlating to what I just said

00:03:30.630 --> 00:03:35.020
is that whenever a lock is erased, exactly one

00:03:35.020 --> 00:03:37.540
guy is signaled to indicate that they've got

00:03:37.540 --> 00:03:41.900
the lock. And, and that's another important virtue of

00:03:41.900 --> 00:03:44.770
this particular algorithm. So, it is fair. And

00:03:44.770 --> 00:03:46.910
it is also not nice, so these are two

00:03:46.910 --> 00:03:50.965
things that very good things about this algorithm. And

00:03:50.965 --> 00:03:53.830
those we saw were you know the deficiency of the

00:03:53.830 --> 00:03:56.810
ticket log algorithm was exactly that where it is fair,

00:03:56.810 --> 00:03:58.760
but it is noisy when the lock is released. So

00:03:58.760 --> 00:04:02.070
that problem has gotten away with this queuing lock. Now

00:04:02.070 --> 00:04:04.630
you might be wondering, are there any downside to this

00:04:04.630 --> 00:04:08.740
array based queuing lock. I assure there is. The first

00:04:08.740 --> 00:04:12.270
thing I'm sure that you've noticed already is the size

00:04:12.270 --> 00:04:14.830
of the data structure is as big as the

00:04:14.830 --> 00:04:18.660
number of processors in the multiprocessor. So the space

00:04:18.660 --> 00:04:22.170
complexity [COUGH] for this algorithm is order of N

00:04:22.170 --> 00:04:25.780
for every lock that you have in the multiprogram. So

00:04:25.780 --> 00:04:28.010
if you have a large scale multiprocessor with dozens

00:04:28.010 --> 00:04:31.420
of processors, that can start eating into the memory

00:04:31.420 --> 00:04:34.120
space. So that's something that you have to watch

00:04:34.120 --> 00:04:37.230
out for. So the space can be a big overhead.

00:04:37.230 --> 00:04:39.820
And the reason I'm emphasizing that is because

00:04:39.820 --> 00:04:44.870
in any well-structure multi-threaded program even though we may

00:04:44.870 --> 00:04:48.170
have lots of threads executing in, in all

00:04:48.170 --> 00:04:50.750
the processors. At any point of time for a

00:04:50.750 --> 00:04:52.940
particular lock, they might not be in contention

00:04:52.940 --> 00:04:55.790
but all the processors, only a subset of them

00:04:55.790 --> 00:04:58.690
may be requesting the lock. But still, this

00:04:58.690 --> 00:05:02.060
particular algorithm has to worry about the worst case.

00:05:02.060 --> 00:05:04.870
Contention for a lock, and therefore it creates a data

00:05:04.870 --> 00:05:07.310
structure that is as big as a number of processes

00:05:07.310 --> 00:05:10.670
that you have in the multiprocessors. And that's the only

00:05:10.670 --> 00:05:13.280
downside to this, but all the other things are good stuff

00:05:13.280 --> 00:05:16.960
about this algorithm. And of course the reason why you

00:05:16.960 --> 00:05:21.320
have that downside with the, with this particular Anderson's queueing

00:05:21.320 --> 00:05:24.570
lock is the fact that the queue is being simulated

00:05:24.570 --> 00:05:27.100
by a static data structure, an array. And since it is

00:05:27.100 --> 00:05:28.700
a static data structure and you have to

00:05:28.700 --> 00:05:33.190
worry about the worst case contention among requesters for

00:05:33.190 --> 00:05:36.040
a lock we have to make this static array

00:05:36.040 --> 00:05:38.400
as big as the number of processors. So that's

00:05:38.400 --> 00:05:42.430
really the the catch in this particular algorithm.

00:05:42.430 --> 00:05:45.530
Next we will look at another algorithm, a lock

00:05:45.530 --> 00:05:48.930
algorithm that is also based on queuing, but it

00:05:48.930 --> 00:05:52.700
doesn't have the space complexity of Anderson's queuing lock.

