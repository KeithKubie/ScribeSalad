WEBVTT
Kind: captions
Language: en

00:00:00.450 --> 00:00:02.760
So what's a training set? Well a training set is

00:00:02.760 --> 00:00:04.910
a set of all of our inputs, like pictures of

00:00:04.910 --> 00:00:10.220
people, paired with a label, which is the correct output.

00:00:10.220 --> 00:00:13.460
So in this case, yes, this person is credit worthy.

00:00:13.460 --> 00:00:15.393
&gt;&gt; [LAUGH]

00:00:15.393 --> 00:00:17.200
&gt;&gt; Versus another example.

00:00:17.200 --> 00:00:19.420
&gt;&gt; You can tell I'm credit worthy based on my curly hair.

00:00:19.420 --> 00:00:21.400
&gt;&gt; Purely on the hair.

00:00:21.400 --> 00:00:25.490
&gt;&gt; Versus someone who has no curly hair and therefore

00:00:25.490 --> 00:00:28.410
is obviously not credit worthy. And if you get bunches

00:00:28.410 --> 00:00:32.460
and bunches of examples of input and output pairs, that's a

00:00:32.460 --> 00:00:35.100
training set. And that's what's going to be the basis

00:00:35.100 --> 00:00:38.150
for you figuring out what is the correct concept or function.

00:00:38.150 --> 00:00:41.032
&gt;&gt; I see. So instead of just telling me what tall means, you're

00:00:41.032 --> 00:00:43.890
going to give me lots of examples of, this is tall, this is

00:00:43.890 --> 00:00:46.270
not tall, this is tall, this is tall, this is tall, this is

00:00:46.270 --> 00:00:51.240
not tall. And that's the way that you're explaining what the target concept is.

00:00:51.240 --> 00:00:53.140
&gt;&gt; Right. So if you want to think about this in

00:00:53.140 --> 00:00:55.570
the real world, it's as if we're walking down the street

00:00:55.570 --> 00:00:58.404
and I'm pointing out cars to you, and non-cars to you,

00:00:58.404 --> 00:01:01.460
rather than trying to give you a dictionary that defines exactly

00:01:01.460 --> 00:01:05.019
what a car is. And that is fundamentally inductive learning as

00:01:05.019 --> 00:01:08.310
we talked about before. Lots and lots of examples, lots of

00:01:08.310 --> 00:01:13.190
labels. Now I have to generalize beyond that. So, last few

00:01:13.190 --> 00:01:16.300
things that we we talk about, last two terms I want

00:01:16.300 --> 00:01:19.630
to introduce are candidate, and testing set. So what's

00:01:19.630 --> 00:01:22.780
a candidate? Well a candidate is just simply the, a

00:01:22.780 --> 00:01:27.360
concept that you think might be the target concept. So,

00:01:27.360 --> 00:01:29.750
for example, I might have, right now, you already did

00:01:29.750 --> 00:01:31.822
this where you said, oh, okay I see, clearly I'm

00:01:31.822 --> 00:01:35.140
credit worthy because I have curly hair. So, you've effectively

00:01:35.140 --> 00:01:38.320
asserted a particular function that looks at, looks for curly

00:01:38.320 --> 00:01:42.006
hair, and says, if there's curly hair there, the person's

00:01:42.006 --> 00:01:45.320
credit worthy. Which is certainly how I think about it. And

00:01:45.320 --> 00:01:47.840
people who are not curly hair, or do not have curly hair

00:01:47.840 --> 00:01:51.160
are, in fact, not credit worthy. So, that's your target concept.

00:01:51.160 --> 00:01:53.000
And so, then, the question is, given that you have a bunch

00:01:53.000 --> 00:01:57.490
of examples, and you have a particular candidate or a candidate

00:01:57.490 --> 00:02:00.090
concept, how do you know whether you are right or wrong? How

00:02:00.090 --> 00:02:02.900
do you know whether it's a good candidate or not? And that's

00:02:02.900 --> 00:02:07.120
where the testing set comes in. So a testing set looks just

00:02:07.120 --> 00:02:10.810
like a training set. So here our training set, we'll

00:02:10.810 --> 00:02:13.170
have pictures and whether someone turns out to be credit worthy

00:02:13.170 --> 00:02:16.590
or not. And I will take your candidate concept and

00:02:16.590 --> 00:02:19.660
I'll determine whether it does a good job or not, by

00:02:19.660 --> 00:02:22.520
looking at the testing set. So in this case, because

00:02:22.520 --> 00:02:25.940
you decided curly hair matters, I have drawn, I have given

00:02:25.940 --> 00:02:28.410
you two examples from a training set, both of which have

00:02:28.410 --> 00:02:32.960
curly hair, but only one of which is deemed credit worthy.

00:02:32.960 --> 00:02:35.600
Which means your target concept is probably not right.

00:02:35.600 --> 00:02:37.400
&gt;&gt; So to do that test I, guess you can go

00:02:37.400 --> 00:02:40.530
through all the pictures in the testing set, apply the candidate

00:02:40.530 --> 00:02:43.640
concept to see whether it says true or false, and then

00:02:43.640 --> 00:02:46.410
compare that to what the testing set actually says that answer is.

00:02:46.410 --> 00:02:48.540
&gt;&gt; Right, and that'll give you an error. So, by the way,

00:02:48.540 --> 00:02:52.670
the true target, the true target concept is whether you smile or not.

00:02:52.670 --> 00:02:57.240
&gt;&gt; Oh. That does make somebody credit worthy.

00:02:57.240 --> 00:02:58.360
&gt;&gt; It does

00:02:58.360 --> 00:03:01.120
in my world. Or at least I, wish it did

00:03:01.120 --> 00:03:04.960
in my world. Okay. So, by the way an important point

00:03:04.960 --> 00:03:08.690
is that the training set and the testing set should

00:03:08.690 --> 00:03:11.740
not be the same. If you learn from your training set,

00:03:11.740 --> 00:03:13.970
and I test you only on your training set, then

00:03:13.970 --> 00:03:17.050
that's considered cheating in the machine learning world. Because then you

00:03:17.050 --> 00:03:20.126
haven't really shown the ability to generalize. So typically we want

00:03:20.126 --> 00:03:23.620
the training set to include lots of examples that you don't,

00:03:23.620 --> 00:03:27.010
the testing set, I'm sorry, to include lots of examples that you don't

00:03:27.010 --> 00:03:29.830
see in your training set. And that is proof that you're able to generalize.

00:03:29.830 --> 00:03:31.910
&gt;&gt; I see. So that, and that makes intuitive sense,

00:03:31.910 --> 00:03:33.760
right? So, like, if, if you're a teacher and you're

00:03:33.760 --> 00:03:36.530
telling me, you give me a bunch of fact and

00:03:36.530 --> 00:03:38.590
then you test me exactly that bunch of facts, it

00:03:38.590 --> 00:03:40.888
doesn't, I don't have to have understood them. I just

00:03:40.888 --> 00:03:43.170
can regurgitate them back. If you really want to see

00:03:43.170 --> 00:03:45.070
if I got the right concept, you have to see

00:03:45.070 --> 00:03:48.190
whether or not I can apply that concept in new examples.

00:03:48.190 --> 00:03:48.760
&gt;&gt; Yes,

00:03:48.760 --> 00:03:51.760
which is exactly why our final exams are written the way that they are

00:03:51.760 --> 00:03:54.610
written. Because you can argue that I've

00:03:54.610 --> 00:03:56.490
learned something by doing memorization, but the

00:03:56.490 --> 00:03:58.450
truth is you haven't. You've just memorized.

00:03:58.450 --> 00:04:00.050
Here you have to do generalization. As

00:04:00.050 --> 00:04:02.080
you remember from our last discussion, generalization

00:04:02.080 --> 00:04:04.080
is the whole point of machine learning.

