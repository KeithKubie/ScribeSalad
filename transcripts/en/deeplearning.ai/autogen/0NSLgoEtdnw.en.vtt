WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.090
the triplet loss is one good way to

00:00:02.090 --> 00:00:02.100
the triplet loss is one good way to
 

00:00:02.100 --> 00:00:04.789
the triplet loss is one good way to
learn the parameters of a confident for

00:00:04.789 --> 00:00:04.799
learn the parameters of a confident for
 

00:00:04.799 --> 00:00:06.800
learn the parameters of a confident for
face recognition there's another way to

00:00:06.800 --> 00:00:06.810
face recognition there's another way to
 

00:00:06.810 --> 00:00:08.900
face recognition there's another way to
learn these parameters let me show you

00:00:08.900 --> 00:00:08.910
learn these parameters let me show you
 

00:00:08.910 --> 00:00:11.360
learn these parameters let me show you
how face recognition can also be posed

00:00:11.360 --> 00:00:11.370
how face recognition can also be posed
 

00:00:11.370 --> 00:00:13.820
how face recognition can also be posed
as a straight binary classification

00:00:13.820 --> 00:00:13.830
as a straight binary classification
 

00:00:13.830 --> 00:00:16.430
as a straight binary classification
problem another way to train a neural

00:00:16.430 --> 00:00:16.440
problem another way to train a neural
 

00:00:16.440 --> 00:00:18.800
problem another way to train a neural
network is to take this pair of neural

00:00:18.800 --> 00:00:18.810
network is to take this pair of neural
 

00:00:18.810 --> 00:00:21.170
network is to take this pair of neural
networks to take this siamese network

00:00:21.170 --> 00:00:21.180
networks to take this siamese network
 

00:00:21.180 --> 00:00:24.099
networks to take this siamese network
and have them both compute these

00:00:24.099 --> 00:00:24.109
and have them both compute these
 

00:00:24.109 --> 00:00:26.839
and have them both compute these
embeddings maybe 128 dimensional

00:00:26.839 --> 00:00:26.849
embeddings maybe 128 dimensional
 

00:00:26.849 --> 00:00:28.429
embeddings maybe 128 dimensional
embeddings maybe even higher dimensional

00:00:28.429 --> 00:00:28.439
embeddings maybe even higher dimensional
 

00:00:28.439 --> 00:00:31.540
embeddings maybe even higher dimensional
and then have these beat input to a

00:00:31.540 --> 00:00:31.550
and then have these beat input to a
 

00:00:31.550 --> 00:00:34.850
and then have these beat input to a
logistic regression unit to then just

00:00:34.850 --> 00:00:34.860
logistic regression unit to then just
 

00:00:34.860 --> 00:00:37.819
logistic regression unit to then just
make a prediction where the target

00:00:37.819 --> 00:00:37.829
make a prediction where the target
 

00:00:37.829 --> 00:00:41.600
make a prediction where the target
output will be 1 if both of these are

00:00:41.600 --> 00:00:41.610
output will be 1 if both of these are
 

00:00:41.610 --> 00:00:44.180
output will be 1 if both of these are
the same persons and 0 if both of these

00:00:44.180 --> 00:00:44.190
the same persons and 0 if both of these
 

00:00:44.190 --> 00:00:47.150
the same persons and 0 if both of these
are of different persons so this is a

00:00:47.150 --> 00:00:47.160
are of different persons so this is a
 

00:00:47.160 --> 00:00:49.819
are of different persons so this is a
way to treat face recognition just as a

00:00:49.819 --> 00:00:49.829
way to treat face recognition just as a
 

00:00:49.829 --> 00:00:53.569
way to treat face recognition just as a
binary classification problem and this

00:00:53.569 --> 00:00:53.579
binary classification problem and this
 

00:00:53.579 --> 00:00:55.939
binary classification problem and this
is an alternative to the triplet loss

00:00:55.939 --> 00:00:55.949
is an alternative to the triplet loss
 

00:00:55.949 --> 00:00:59.720
is an alternative to the triplet loss
for training a system like this now what

00:00:59.720 --> 00:00:59.730
for training a system like this now what
 

00:00:59.730 --> 00:01:02.060
for training a system like this now what
is this final logistic regression unit

00:01:02.060 --> 00:01:02.070
is this final logistic regression unit
 

00:01:02.070 --> 00:01:05.690
is this final logistic regression unit
actually do the output Y hat will be

00:01:05.690 --> 00:01:05.700
actually do the output Y hat will be
 

00:01:05.700 --> 00:01:08.960
actually do the output Y hat will be
lets say a sigmoid function apply to

00:01:08.960 --> 00:01:08.970
lets say a sigmoid function apply to
 

00:01:08.970 --> 00:01:11.539
lets say a sigmoid function apply to
some set of features but rather than

00:01:11.539 --> 00:01:11.549
some set of features but rather than
 

00:01:11.549 --> 00:01:14.719
some set of features but rather than
just feeding in these encoding x' what

00:01:14.719 --> 00:01:14.729
just feeding in these encoding x' what
 

00:01:14.729 --> 00:01:17.539
just feeding in these encoding x' what
you can do is take the differences

00:01:17.539 --> 00:01:17.549
you can do is take the differences
 

00:01:17.549 --> 00:01:19.370
you can do is take the differences
between the encodings so let me show you

00:01:19.370 --> 00:01:19.380
between the encodings so let me show you
 

00:01:19.380 --> 00:01:23.440
between the encodings so let me show you
what I mean let's say I write a sum over

00:01:23.440 --> 00:01:23.450
what I mean let's say I write a sum over
 

00:01:23.450 --> 00:01:28.280
what I mean let's say I write a sum over
K equals 1 to 128 of let's say the

00:01:28.280 --> 00:01:28.290
K equals 1 to 128 of let's say the
 

00:01:28.290 --> 00:01:31.310
K equals 1 to 128 of let's say the
absolute value take an element-wise

00:01:31.310 --> 00:01:31.320
absolute value take an element-wise
 

00:01:31.320 --> 00:01:35.929
absolute value take an element-wise
between the two different encodings so

00:01:35.929 --> 00:01:35.939
between the two different encodings so
 

00:01:35.939 --> 00:01:37.760
between the two different encodings so
I'm just finished writing the sultan and

00:01:37.760 --> 00:01:37.770
I'm just finished writing the sultan and
 

00:01:37.770 --> 00:01:40.640
I'm just finished writing the sultan and
we'll see what this means so in this

00:01:40.640 --> 00:01:40.650
we'll see what this means so in this
 

00:01:40.650 --> 00:01:44.300
we'll see what this means so in this
notation f of X I is the encoding of the

00:01:44.300 --> 00:01:44.310
notation f of X I is the encoding of the
 

00:01:44.310 --> 00:01:48.109
notation f of X I is the encoding of the
image X I and the subscript K means to

00:01:48.109 --> 00:01:48.119
image X I and the subscript K means to
 

00:01:48.119 --> 00:01:50.870
image X I and the subscript K means to
just select out the kaif component of

00:01:50.870 --> 00:01:50.880
just select out the kaif component of
 

00:01:50.880 --> 00:01:53.899
just select out the kaif component of
this vector so this is taking the

00:01:53.899 --> 00:01:53.909
this vector so this is taking the
 

00:01:53.909 --> 00:01:56.330
this vector so this is taking the
element wise difference in absolute

00:01:56.330 --> 00:01:56.340
element wise difference in absolute
 

00:01:56.340 --> 00:01:59.060
element wise difference in absolute
values between these two and codings

00:01:59.060 --> 00:01:59.070
values between these two and codings
 

00:01:59.070 --> 00:02:01.670
values between these two and codings
and what you might do is think of these

00:02:01.670 --> 00:02:01.680
and what you might do is think of these
 

00:02:01.680 --> 00:02:05.090
and what you might do is think of these
128 numbers as features that you then

00:02:05.090 --> 00:02:05.100
128 numbers as features that you then
 

00:02:05.100 --> 00:02:07.760
128 numbers as features that you then
feed into logistic regression and your

00:02:07.760 --> 00:02:07.770
feed into logistic regression and your
 

00:02:07.770 --> 00:02:09.020
feed into logistic regression and your
final is regression

00:02:09.020 --> 00:02:09.030
final is regression
 

00:02:09.030 --> 00:02:09.690
final is regression
Canopus

00:02:09.690 --> 00:02:09.700
Canopus
 

00:02:09.700 --> 00:02:13.380
Canopus
parameters WI and be similar to a non

00:02:13.380 --> 00:02:13.390
parameters WI and be similar to a non
 

00:02:13.390 --> 00:02:16.440
parameters WI and be similar to a non
normal logistic regression unit and you

00:02:16.440 --> 00:02:16.450
normal logistic regression unit and you
 

00:02:16.450 --> 00:02:19.140
normal logistic regression unit and you
would train a appropriate waiting on

00:02:19.140 --> 00:02:19.150
would train a appropriate waiting on
 

00:02:19.150 --> 00:02:23.009
would train a appropriate waiting on
these 128 features in order to predict

00:02:23.009 --> 00:02:23.019
these 128 features in order to predict
 

00:02:23.019 --> 00:02:25.559
these 128 features in order to predict
whether or not these two images are of

00:02:25.559 --> 00:02:25.569
whether or not these two images are of
 

00:02:25.569 --> 00:02:27.690
whether or not these two images are of
the same person or of different persons

00:02:27.690 --> 00:02:27.700
the same person or of different persons
 

00:02:27.700 --> 00:02:29.970
the same person or of different persons
so this will be one pretty reasonable

00:02:29.970 --> 00:02:29.980
so this will be one pretty reasonable
 

00:02:29.980 --> 00:02:34.320
so this will be one pretty reasonable
way to learn to predict 0 or 1 whether

00:02:34.320 --> 00:02:34.330
way to learn to predict 0 or 1 whether
 

00:02:34.330 --> 00:02:35.490
way to learn to predict 0 or 1 whether
these are the same person

00:02:35.490 --> 00:02:35.500
these are the same person
 

00:02:35.500 --> 00:02:38.130
these are the same person
or different persons and there are few

00:02:38.130 --> 00:02:38.140
or different persons and there are few
 

00:02:38.140 --> 00:02:40.650
or different persons and there are few
other variations on how you can compute

00:02:40.650 --> 00:02:40.660
other variations on how you can compute
 

00:02:40.660 --> 00:02:43.559
other variations on how you can compute
this formula that I had underlined in

00:02:43.559 --> 00:02:43.569
this formula that I had underlined in
 

00:02:43.569 --> 00:02:47.160
this formula that I had underlined in
green for example another formula could

00:02:47.160 --> 00:02:47.170
green for example another formula could
 

00:02:47.170 --> 00:02:53.520
green for example another formula could
be this K minus f of X J ok squared

00:02:53.520 --> 00:02:53.530
be this K minus f of X J ok squared
 

00:02:53.530 --> 00:03:00.210
be this K minus f of X J ok squared
divided by f of X I plus f of X J okay

00:03:00.210 --> 00:03:00.220
divided by f of X I plus f of X J okay
 

00:03:00.220 --> 00:03:02.339
divided by f of X I plus f of X J okay
this is sometimes called the chi-square

00:03:02.339 --> 00:03:02.349
this is sometimes called the chi-square
 

00:03:02.349 --> 00:03:04.259
this is sometimes called the chi-square
formula right this is the Greek alphabet

00:03:04.259 --> 00:03:04.269
formula right this is the Greek alphabet
 

00:03:04.269 --> 00:03:07.170
formula right this is the Greek alphabet
Chi but this is are sometimes called the

00:03:07.170 --> 00:03:07.180
Chi but this is are sometimes called the
 

00:03:07.180 --> 00:03:09.690
Chi but this is are sometimes called the
chi-square similarity and this and other

00:03:09.690 --> 00:03:09.700
chi-square similarity and this and other
 

00:03:09.700 --> 00:03:12.509
chi-square similarity and this and other
variations are explored and this and

00:03:12.509 --> 00:03:12.519
variations are explored and this and
 

00:03:12.519 --> 00:03:14.280
variations are explored and this and
other variations are explored in this

00:03:14.280 --> 00:03:14.290
other variations are explored in this
 

00:03:14.290 --> 00:03:16.680
other variations are explored in this
deep face paper which I have referenced

00:03:16.680 --> 00:03:16.690
deep face paper which I have referenced
 

00:03:16.690 --> 00:03:19.500
deep face paper which I have referenced
earlier as well but so in this learning

00:03:19.500 --> 00:03:19.510
earlier as well but so in this learning
 

00:03:19.510 --> 00:03:23.009
earlier as well but so in this learning
formulation the input is a pair of

00:03:23.009 --> 00:03:23.019
formulation the input is a pair of
 

00:03:23.019 --> 00:03:25.349
formulation the input is a pair of
images so this is really your you know

00:03:25.349 --> 00:03:25.359
images so this is really your you know
 

00:03:25.359 --> 00:03:28.860
images so this is really your you know
training input X and the output Y is

00:03:28.860 --> 00:03:28.870
training input X and the output Y is
 

00:03:28.870 --> 00:03:31.259
training input X and the output Y is
either 0 or 1 depending on whether

00:03:31.259 --> 00:03:31.269
either 0 or 1 depending on whether
 

00:03:31.269 --> 00:03:33.930
either 0 or 1 depending on whether
you're inputting a pair of similar or

00:03:33.930 --> 00:03:33.940
you're inputting a pair of similar or
 

00:03:33.940 --> 00:03:36.629
you're inputting a pair of similar or
dissimilar images and same as before

00:03:36.629 --> 00:03:36.639
dissimilar images and same as before
 

00:03:36.639 --> 00:03:39.180
dissimilar images and same as before
you're training a siamese network so

00:03:39.180 --> 00:03:39.190
you're training a siamese network so
 

00:03:39.190 --> 00:03:41.280
you're training a siamese network so
that means that this neural network up

00:03:41.280 --> 00:03:41.290
that means that this neural network up
 

00:03:41.290 --> 00:03:43.890
that means that this neural network up
here as parameters that are the same or

00:03:43.890 --> 00:03:43.900
here as parameters that are the same or
 

00:03:43.900 --> 00:03:46.259
here as parameters that are the same or
they're really tied to the parameters in

00:03:46.259 --> 00:03:46.269
they're really tied to the parameters in
 

00:03:46.269 --> 00:03:49.199
they're really tied to the parameters in
this lower neural network and this

00:03:49.199 --> 00:03:49.209
this lower neural network and this
 

00:03:49.209 --> 00:03:51.720
this lower neural network and this
system can work pretty well as well um

00:03:51.720 --> 00:03:51.730
system can work pretty well as well um
 

00:03:51.730 --> 00:03:53.670
system can work pretty well as well um
lastly it doesn't mention one

00:03:53.670 --> 00:03:53.680
lastly it doesn't mention one
 

00:03:53.680 --> 00:03:56.099
lastly it doesn't mention one
computational trick that can help your

00:03:56.099 --> 00:03:56.109
computational trick that can help your
 

00:03:56.109 --> 00:03:58.740
computational trick that can help your
deployment significantly which is that

00:03:58.740 --> 00:03:58.750
deployment significantly which is that
 

00:03:58.750 --> 00:04:01.020
deployment significantly which is that
if this is the new image so this is an

00:04:01.020 --> 00:04:01.030
if this is the new image so this is an
 

00:04:01.030 --> 00:04:02.809
if this is the new image so this is an
employee walking in hoping that

00:04:02.809 --> 00:04:02.819
employee walking in hoping that
 

00:04:02.819 --> 00:04:05.190
employee walking in hoping that
turnstyle the doorway will open for them

00:04:05.190 --> 00:04:05.200
turnstyle the doorway will open for them
 

00:04:05.200 --> 00:04:08.030
turnstyle the doorway will open for them
and if this is from your data base image

00:04:08.030 --> 00:04:08.040
and if this is from your data base image
 

00:04:08.040 --> 00:04:11.610
and if this is from your data base image
then instead of having to compute this

00:04:11.610 --> 00:04:11.620
then instead of having to compute this
 

00:04:11.620 --> 00:04:14.309
then instead of having to compute this
set of features then instead of having

00:04:14.309 --> 00:04:14.319
set of features then instead of having
 

00:04:14.319 --> 00:04:17.009
set of features then instead of having
to compute this embedding every single

00:04:17.009 --> 00:04:17.019
to compute this embedding every single
 

00:04:17.019 --> 00:04:19.140
to compute this embedding every single
time what you can do is actually pre

00:04:19.140 --> 00:04:19.150
time what you can do is actually pre
 

00:04:19.150 --> 00:04:20.590
time what you can do is actually pre
compute that

00:04:20.590 --> 00:04:20.600
compute that
 

00:04:20.600 --> 00:04:23.110
compute that
so when the new employee walks in what

00:04:23.110 --> 00:04:23.120
so when the new employee walks in what
 

00:04:23.120 --> 00:04:25.420
so when the new employee walks in what
you can do is use this upper confidence

00:04:25.420 --> 00:04:25.430
you can do is use this upper confidence
 

00:04:25.430 --> 00:04:29.560
you can do is use this upper confidence
to compute that encoding and use it to

00:04:29.560 --> 00:04:29.570
to compute that encoding and use it to
 

00:04:29.570 --> 00:04:32.020
to compute that encoding and use it to
then compare it to your pre computed

00:04:32.020 --> 00:04:32.030
then compare it to your pre computed
 

00:04:32.030 --> 00:04:34.690
then compare it to your pre computed
encoding and then use that to make a

00:04:34.690 --> 00:04:34.700
encoding and then use that to make a
 

00:04:34.700 --> 00:04:37.540
encoding and then use that to make a
prediction y hat so because you don't

00:04:37.540 --> 00:04:37.550
prediction y hat so because you don't
 

00:04:37.550 --> 00:04:40.900
prediction y hat so because you don't
need to store the raw images and also

00:04:40.900 --> 00:04:40.910
need to store the raw images and also
 

00:04:40.910 --> 00:04:43.420
need to store the raw images and also
because if you have a very large

00:04:43.420 --> 00:04:43.430
because if you have a very large
 

00:04:43.430 --> 00:04:45.580
because if you have a very large
database of employees you don't need to

00:04:45.580 --> 00:04:45.590
database of employees you don't need to
 

00:04:45.590 --> 00:04:49.000
database of employees you don't need to
compute these encoding every single time

00:04:49.000 --> 00:04:49.010
compute these encoding every single time
 

00:04:49.010 --> 00:04:50.470
compute these encoding every single time
for every employee you know database

00:04:50.470 --> 00:04:50.480
for every employee you know database
 

00:04:50.480 --> 00:04:53.530
for every employee you know database
this idea of pre computing some of these

00:04:53.530 --> 00:04:53.540
this idea of pre computing some of these
 

00:04:53.540 --> 00:04:55.600
this idea of pre computing some of these
encoding can save a significant

00:04:55.600 --> 00:04:55.610
encoding can save a significant
 

00:04:55.610 --> 00:04:57.610
encoding can save a significant
computation and this type of

00:04:57.610 --> 00:04:57.620
computation and this type of
 

00:04:57.620 --> 00:05:00.610
computation and this type of
pre-computation works both for this type

00:05:00.610 --> 00:05:00.620
pre-computation works both for this type
 

00:05:00.620 --> 00:05:02.950
pre-computation works both for this type
of Sammys network architecture where you

00:05:02.950 --> 00:05:02.960
of Sammys network architecture where you
 

00:05:02.960 --> 00:05:05.950
of Sammys network architecture where you
feed face-recognition as a binary

00:05:05.950 --> 00:05:05.960
feed face-recognition as a binary
 

00:05:05.960 --> 00:05:08.560
feed face-recognition as a binary
classification problem as well as for

00:05:08.560 --> 00:05:08.570
classification problem as well as for
 

00:05:08.570 --> 00:05:10.360
classification problem as well as for
when you were learning and codings

00:05:10.360 --> 00:05:10.370
when you were learning and codings
 

00:05:10.370 --> 00:05:12.250
when you were learning and codings
may be using the triplet loss function

00:05:12.250 --> 00:05:12.260
may be using the triplet loss function
 

00:05:12.260 --> 00:05:14.320
may be using the triplet loss function
as described in the last couple of

00:05:14.320 --> 00:05:14.330
as described in the last couple of
 

00:05:14.330 --> 00:05:17.200
as described in the last couple of
videos and so just to wrap up to create

00:05:17.200 --> 00:05:17.210
videos and so just to wrap up to create
 

00:05:17.210 --> 00:05:18.880
videos and so just to wrap up to create
face verification as supervised learning

00:05:18.880 --> 00:05:18.890
face verification as supervised learning
 

00:05:18.890 --> 00:05:22.210
face verification as supervised learning
you create a training set of just pairs

00:05:22.210 --> 00:05:22.220
you create a training set of just pairs
 

00:05:22.220 --> 00:05:24.100
you create a training set of just pairs
of images now instead of triplets a

00:05:24.100 --> 00:05:24.110
of images now instead of triplets a
 

00:05:24.110 --> 00:05:26.740
of images now instead of triplets a
pairs of images where the target label

00:05:26.740 --> 00:05:26.750
pairs of images where the target label
 

00:05:26.750 --> 00:05:30.310
pairs of images where the target label
is one when these are a pair of pictures

00:05:30.310 --> 00:05:30.320
is one when these are a pair of pictures
 

00:05:30.320 --> 00:05:33.070
is one when these are a pair of pictures
of the same person and where the target

00:05:33.070 --> 00:05:33.080
of the same person and where the target
 

00:05:33.080 --> 00:05:35.670
of the same person and where the target
label is zero when these are pictures of

00:05:35.670 --> 00:05:35.680
label is zero when these are pictures of
 

00:05:35.680 --> 00:05:39.070
label is zero when these are pictures of
different persons and you use different

00:05:39.070 --> 00:05:39.080
different persons and you use different
 

00:05:39.080 --> 00:05:42.370
different persons and you use different
pairs to train the neural network to

00:05:42.370 --> 00:05:42.380
pairs to train the neural network to
 

00:05:42.380 --> 00:05:44.380
pairs to train the neural network to
train the siamese network using back

00:05:44.380 --> 00:05:44.390
train the siamese network using back
 

00:05:44.390 --> 00:05:47.050
train the siamese network using back
propagation so this version that you

00:05:47.050 --> 00:05:47.060
propagation so this version that you
 

00:05:47.060 --> 00:05:49.600
propagation so this version that you
just saw of treating face verification

00:05:49.600 --> 00:05:49.610
just saw of treating face verification
 

00:05:49.610 --> 00:05:52.000
just saw of treating face verification
and by extension face recognition as a

00:05:52.000 --> 00:05:52.010
and by extension face recognition as a
 

00:05:52.010 --> 00:05:54.340
and by extension face recognition as a
binary classification problem this works

00:05:54.340 --> 00:05:54.350
binary classification problem this works
 

00:05:54.350 --> 00:05:56.500
binary classification problem this works
quite well as well and so if that's I

00:05:56.500 --> 00:05:56.510
quite well as well and so if that's I
 

00:05:56.510 --> 00:05:58.090
quite well as well and so if that's I
hope that you now know what it would

00:05:58.090 --> 00:05:58.100
hope that you now know what it would
 

00:05:58.100 --> 00:06:01.060
hope that you now know what it would
take to train your own face verification

00:06:01.060 --> 00:06:01.070
take to train your own face verification
 

00:06:01.070 --> 00:06:03.670
take to train your own face verification
or your own face recognition system when

00:06:03.670 --> 00:06:03.680
or your own face recognition system when
 

00:06:03.680 --> 00:06:07.270
or your own face recognition system when
they can do one-shot learning

