WEBVTT
Kind: captions
Language: en

00:00:01.501 --> 00:00:03.770
The following content is
provided under a Creative

00:00:03.870 --> 00:00:05.138
Commons license.

00:00:05.238 --> 00:00:07.374
Your support will help
MIT OpenCourseWare

00:00:07.474 --> 00:00:11.444
continue to offer high-quality
educational resources for free.

00:00:11.544 --> 00:00:13.980
To make a donation, or to
view additional materials

00:00:14.080 --> 00:00:17.951
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:18.051 --> 00:00:18.818
at ocw.mit.edu.

00:00:22.222 --> 00:00:24.424
MICHEL DEGRAFF: I don't want
to make anyone jealous who

00:00:24.524 --> 00:00:28.328
came before, but I think
we can say pretty safely

00:00:28.428 --> 00:00:32.766
that we saved one of the
best for last, right?

00:00:32.866 --> 00:00:34.300
I won't say the best.

00:00:34.401 --> 00:00:34.801
OK?

00:00:34.901 --> 00:00:37.037
All right.

00:00:37.137 --> 00:00:38.805
So as you can see,
throughout the course

00:00:38.905 --> 00:00:45.311
we looked at these issues about
how language, race, ethnicity,

00:00:45.412 --> 00:00:49.849
gender, how they can be used
to create various hierarchies.

00:00:49.949 --> 00:00:54.554
And as you can see now
after the semester,

00:00:54.654 --> 00:00:55.789
these are tools, really.

00:00:55.889 --> 00:00:58.458
They're not inherently
part of who we are,

00:00:58.558 --> 00:01:01.828
but they are tools that
various pools of power

00:01:01.928 --> 00:01:04.596
use to keep control,
to create hierarchies.

00:01:04.697 --> 00:01:07.367
And I think last week, you guys
you had a very good discussion

00:01:07.467 --> 00:01:11.337
with Dr. Aleman about how
sometimes these hierarchies can

00:01:11.438 --> 00:01:12.672
be internalized.

00:01:12.772 --> 00:01:14.574
And there was a very
good discussion,

00:01:14.674 --> 00:01:19.545
as I can tell, from the video
that she took for me about how

00:01:19.646 --> 00:01:22.482
you, yourself, we need to
do some work inside of us

00:01:22.582 --> 00:01:25.618
to go beyond these threats that
these terror attacks impose

00:01:25.718 --> 00:01:26.352
on us.

00:01:26.453 --> 00:01:27.987
So we went very micro.

00:01:28.088 --> 00:01:30.323
So we went very macro,
then went micro.

00:01:30.423 --> 00:01:35.095
And today, with my friend
and colleague, Noam Chomsky,

00:01:35.195 --> 00:01:37.030
we're going to go
my macro again.

00:01:37.130 --> 00:01:40.066
But I guess you've
read the papers.

00:01:40.166 --> 00:01:41.434
I read the papers.

00:01:41.533 --> 00:01:46.706
And I must say, Noam, I was
very disturbed by what I read.

00:01:46.806 --> 00:01:49.776
But the fact is that
those are the data.

00:01:49.876 --> 00:01:51.578
So this is MIT.

00:01:51.678 --> 00:01:54.681
We are very much involved in
trying to understand knowledge.

00:01:54.781 --> 00:01:56.950
And many of you
throughout the semester

00:01:57.050 --> 00:02:00.553
made a case that we have all
this knowledge here at MIT.

00:02:00.653 --> 00:02:03.756
But often, this knowledge
does not translate into action

00:02:03.857 --> 00:02:04.991
into the real world.

00:02:05.091 --> 00:02:08.761
And in a way, I think
with Noam's entire life,

00:02:08.862 --> 00:02:10.930
we have an example of
how that can happen.

00:02:11.030 --> 00:02:13.666
How we can take very
abstract, technical knowledge

00:02:13.766 --> 00:02:15.168
and make it available
to the world

00:02:15.268 --> 00:02:16.302
and try to make it better.

00:02:16.402 --> 00:02:18.037
And the theme of this
course throughout

00:02:18.138 --> 00:02:21.908
was how to build bridges, how to
make change and build bridges.

00:02:22.008 --> 00:02:25.512
So we hope that with
Noam today, we'll

00:02:25.612 --> 00:02:27.847
get a clear sense of
how that can happen.

00:02:27.947 --> 00:02:30.617
And perhaps, how we
might, with some luck,

00:02:30.716 --> 00:02:32.886
save the world, right?

00:02:32.986 --> 00:02:36.289
NOAM CHOMSKY: I think the
best way to proceed is--

00:02:36.389 --> 00:02:40.994
in a court seminar is for you to
say what you're interested in.

00:02:41.094 --> 00:02:44.731
I'll see if I have some
way of reacting to it.

00:02:44.831 --> 00:02:47.734
Lots of things I
could talk about.

00:02:47.834 --> 00:02:50.537
I mean, one thing we
could talk about related

00:02:50.637 --> 00:02:53.305
is right in the headlines.

00:02:53.406 --> 00:02:58.912
So there are things which is an
opening for things we can do.

00:02:59.012 --> 00:03:03.316
That's the plan that was
just made public yesterday

00:03:03.416 --> 00:03:10.456
to deport Haitians back
to Haiti from Boston.

00:03:13.693 --> 00:03:15.395
That's a very live issue.

00:03:15.495 --> 00:03:17.363
A lot of lives depend on it.

00:03:17.463 --> 00:03:20.066
We can do something about
it right here if we want.

00:03:20.166 --> 00:03:21.901
It turns out-- I
didn't know this--

00:03:22.001 --> 00:03:25.905
that the Haitian
Ambassador, Michel just

00:03:26.005 --> 00:03:29.742
told me, who is pleading
with the government

00:03:29.841 --> 00:03:33.980
not to carry out this
onerous and destructive act,

00:03:34.079 --> 00:03:37.984
is actually a former
MIT student, who

00:03:38.084 --> 00:03:39.786
wrote about these
topics in his thesis.

00:03:42.755 --> 00:03:46.059
So that's one of many things
that could be discussed.

