WEBVTT
Kind: captions
Language: en

00:00:31.220 --> 00:00:32.960
MALE SPEAKER: Shanghai
GDG is a very

00:00:32.960 --> 00:00:35.040
interesting developer community.

00:00:35.040 --> 00:00:35.870
FEMALE SPEAKER: I'm
glad somebody

00:00:35.870 --> 00:00:37.100
has asked this question.

00:00:37.100 --> 00:00:38.340
MALE SPEAKER: This is where
the magic happens.

00:00:38.340 --> 00:00:39.737
FEMALE SPEAKER: This is
primarily a question and

00:00:39.737 --> 00:00:41.430
answer show, so if any
of you out there

00:00:41.430 --> 00:00:42.680
would like to ask questions.

00:00:49.100 --> 00:00:50.300
AMY UNRUH: Hey, everyone.

00:00:50.300 --> 00:00:54.470
And welcome to another App
Engine Office Hours.

00:00:54.470 --> 00:00:58.270
So I'm Amy, and with
me is Danny.

00:00:58.270 --> 00:01:01.880
We're both App Engine
developer relations.

00:01:01.880 --> 00:01:06.480
And what we're going to talk
about today is using Appstats

00:01:06.480 --> 00:01:10.180
to optimize your app,
make it ran faster,

00:01:10.180 --> 00:01:12.650
make it run more cheaply.

00:01:12.650 --> 00:01:18.030
And so we're using some
materials that were prepared

00:01:18.030 --> 00:01:20.960
by Proppy, who many of you
might be familiar with,

00:01:20.960 --> 00:01:22.380
another App Engine dev rel.

00:01:22.380 --> 00:01:26.680
So all credit to him
for these slides.

00:01:26.680 --> 00:01:30.390
And so what we're going to do
is we're going to go through

00:01:30.390 --> 00:01:34.020
the slides first and give little
demos as we go along.

00:01:34.020 --> 00:01:38.660
And incidentally, we're trying
an experiment where I'm mostly

00:01:38.660 --> 00:01:40.080
controlling the slides in one

00:01:40.080 --> 00:01:42.530
location, in Sydney, Australia.

00:01:42.530 --> 00:01:47.400
And Danny is doing a bit of
controlling of the slides in

00:01:47.400 --> 00:01:48.440
another location.

00:01:48.440 --> 00:01:52.550
So you may see me sort of roll
my eyes to the side as I'm

00:01:52.550 --> 00:01:55.850
going through these slides as
we try to coordinate them.

00:01:55.850 --> 00:01:58.470
So what we're going to do is
we're going to go through the

00:01:58.470 --> 00:01:59.230
slides first.

00:01:59.230 --> 00:02:01.930
And then we'll go to the
moderator queue.

00:02:01.930 --> 00:02:06.940
And we're not able to invite
people to join live this time,

00:02:06.940 --> 00:02:10.830
and so what we're going to
do for next time is start

00:02:10.830 --> 00:02:17.460
gathering a Google+ circle of
people that want to be invited

00:02:17.460 --> 00:02:19.720
to these Hangouts, which
will make it

00:02:19.720 --> 00:02:20.840
a little more organized.

00:02:20.840 --> 00:02:27.100
So watch for posts about that
both on Google+ and on the App

00:02:27.100 --> 00:02:27.680
Engine group.

00:02:27.680 --> 00:02:30.160
And we'll start gathering a list
of interested people so

00:02:30.160 --> 00:02:33.900
that it's really smooth to
invite you next time.

00:02:33.900 --> 00:02:37.280
So this time we're just going
to communicate with you

00:02:37.280 --> 00:02:39.660
through the moderator queue.

00:02:39.660 --> 00:02:40.410
Sorry about that.

00:02:40.410 --> 00:02:45.040
So go to the GDL event page
where you found this, and you

00:02:45.040 --> 00:02:48.070
should see the link to moderator
queue there.

00:02:48.070 --> 00:02:51.140
And add your questions there.

00:02:51.140 --> 00:02:51.450
OK.

00:02:51.450 --> 00:02:54.170
So let's get started
with the demo.

00:02:54.170 --> 00:02:58.740
And first, I'm going to give
just a little bit of an

00:02:58.740 --> 00:03:03.220
introduction about Appstats.

00:03:03.220 --> 00:03:04.700
So most of you are
probably familiar

00:03:04.700 --> 00:03:06.360
with Appstats already.

00:03:06.360 --> 00:03:09.900
And just in case you're not, let
me just give a little plug

00:03:09.900 --> 00:03:11.820
as to how useful it is.

00:03:11.820 --> 00:03:15.980
It's available for both
Python and Java.

00:03:15.980 --> 00:03:19.910
And it essentially lets you see
a bunch of things about

00:03:19.910 --> 00:03:21.040
how your app is running.

00:03:21.040 --> 00:03:25.320
It lets you see where you're
waiting for network calls.

00:03:25.320 --> 00:03:30.530
Figure out what RPC calls are
costing you the most.

00:03:30.530 --> 00:03:33.880
Maybe notice where you're making
repeated RPC calls,

00:03:33.880 --> 00:03:36.440
say, to the data store
rather than when you

00:03:36.440 --> 00:03:37.790
should be doing caching.

00:03:37.790 --> 00:03:39.890
All sorts of useful things.

00:03:39.890 --> 00:03:44.860
So what we're going to do is
we're going to use Appstats to

00:03:44.860 --> 00:03:48.470
show some what you might call
design patterns and

00:03:48.470 --> 00:03:50.316
anti-patterns , which--

00:03:53.900 --> 00:03:57.750
ways to design your app and
not so good ways to design

00:03:57.750 --> 00:04:00.180
your app that really make a
difference with efficiency.

00:04:00.180 --> 00:04:05.300
And we'll be able to see
this with Appstats.

00:04:05.300 --> 00:04:06.670
OK.

00:04:06.670 --> 00:04:10.190
So this is all covered
in the documentation.

00:04:10.190 --> 00:04:13.090
But just a little quick overview
of how to set up

00:04:13.090 --> 00:04:16.269
Appstats for those who aren't
familiar with it.

00:04:16.269 --> 00:04:20.240
You first have to set up a
so-called event recorder and

00:04:20.240 --> 00:04:22.300
App Engine config.

00:04:22.300 --> 00:04:28.700
And then, also in App Engine
config, you can set some

00:04:28.700 --> 00:04:33.270
configuration variables that
impact what gets tracked.

00:04:33.270 --> 00:04:37.660
And so in particular, one thing
we're going to do for

00:04:37.660 --> 00:04:39.850
this broadcast is we're going
to play around a little with

00:04:39.850 --> 00:04:43.320
Appstats CALC_RPC_COSTS.

00:04:43.320 --> 00:04:46.890
So we're going to be setting
this in our config file.

00:04:46.890 --> 00:04:49.750
And you can look at the sample
config file if you want to see

00:04:49.750 --> 00:04:51.510
some of the options that
are available.

00:04:54.080 --> 00:04:55.960
OK.

00:04:55.960 --> 00:04:59.140
And then once you've done that,
you need to, essentially

00:04:59.140 --> 00:05:03.040
in your app.yaml setup, you need
to tell your app where to

00:05:03.040 --> 00:05:04.040
find Appstats.

00:05:04.040 --> 00:05:07.230
And the easiest way to do
it is just the default.

00:05:07.230 --> 00:05:11.090
Use this built-in specifier,
and if you do that, then

00:05:11.090 --> 00:05:15.700
you'll find Appstats
under _ah/stats.

00:05:15.700 --> 00:05:16.950
OK.

00:05:19.470 --> 00:05:24.620
And then there is something
that's new to the recent App

00:05:24.620 --> 00:05:27.020
Engine release, which
is really very cool.

00:05:27.020 --> 00:05:28.720
Which is an Appstats shell.

00:05:28.720 --> 00:05:33.190
So if you configure this, it
basically brings up a nice,

00:05:33.190 --> 00:05:37.240
little interface where you can
run arbitrary Python code.

00:05:37.240 --> 00:05:41.040
And so we're going to use
that during these

00:05:41.040 --> 00:05:43.250
slides, during this demo.

00:05:43.250 --> 00:05:48.080
And so it defaults to
false in production.

00:05:48.080 --> 00:05:51.295
You don't really want
this on arbitrarily.

00:05:51.295 --> 00:05:53.900
But we've turned it
on for this demo.

00:05:53.900 --> 00:05:57.550
And the flag that's shown here
is how you turn it on.

00:05:57.550 --> 00:05:59.710
So we put that, again, in
appengine_config.py.

00:06:03.530 --> 00:06:04.690
OK.

00:06:04.690 --> 00:06:06.660
And before we get started
with our patterns and

00:06:06.660 --> 00:06:11.600
anti-patterns, I just wanted
to put in a brief plug for

00:06:11.600 --> 00:06:12.430
something new.

00:06:12.430 --> 00:06:14.260
Appstats Analytics.

00:06:14.260 --> 00:06:16.790
It's in trusted tester
phase right now.

00:06:16.790 --> 00:06:19.510
And what it is, it's something
that essentially builds on top

00:06:19.510 --> 00:06:20.610
of Appstats.

00:06:20.610 --> 00:06:24.790
And it's an interactive
visualization tool.

00:06:24.790 --> 00:06:27.010
It lets you drill down
into all sorts

00:06:27.010 --> 00:06:29.700
of data really nicely.

00:06:29.700 --> 00:06:30.670
It's great.

00:06:30.670 --> 00:06:34.620
And if you're interested, you
can sign up for it with the

00:06:34.620 --> 00:06:36.760
link shown here.

00:06:36.760 --> 00:06:39.420
And so these slides--

00:06:39.420 --> 00:06:41.960
so you don't have to scramble
to write down the link--

00:06:41.960 --> 00:06:46.880
these slides themselves are
linked to in the GDL events

00:06:46.880 --> 00:06:50.710
page, as many of you have
probably already discovered.

00:06:50.710 --> 00:06:55.520
So you can go find the slides
there and get the link.

00:06:55.520 --> 00:06:57.450
And please do sign up.

00:06:57.450 --> 00:06:59.430
It's really neat stuff.

00:07:02.790 --> 00:07:04.220
OK.

00:07:04.220 --> 00:07:06.340
So let's do a few
little demos.

00:07:06.340 --> 00:07:10.100
And here's where Danny and I
have to try to coordinate.

00:07:10.100 --> 00:07:10.260
DANNY HERMES: Here we go.

00:07:10.260 --> 00:07:12.930
AMY UNRUH: So we'll
see how we go.

00:07:12.930 --> 00:07:13.686
Are you ready, Danny?

00:07:13.686 --> 00:07:14.828
DANNY HERMES: I am.

00:07:14.828 --> 00:07:16.078
AMY UNRUH: OK.

00:07:19.780 --> 00:07:23.270
One common mistake that people
make that sort of slows them

00:07:23.270 --> 00:07:29.850
down sometimes is they do a
query to get an entity from

00:07:29.850 --> 00:07:37.035
the datastore when they could
just be fetching directly by

00:07:37.035 --> 00:07:38.670
the entity key.

00:07:38.670 --> 00:07:42.040
And before I go further, I
should mention that for these

00:07:42.040 --> 00:07:46.150
examples, we're using
NDB and Python.

00:07:46.150 --> 00:07:50.080
And if you're a Python user,
I would really recommend

00:07:50.080 --> 00:07:57.711
checking out NDB, which is
the more new of the--

00:07:57.711 --> 00:07:58.420
DANNY HERMES: Datastore APIs.

00:07:58.420 --> 00:08:00.310
AMY UNRUH: --datastore
APIs supported.

00:08:00.310 --> 00:08:01.180
Sorry?

00:08:01.180 --> 00:08:02.942
DANNY HERMES: I said
datastore APIs.

00:08:02.942 --> 00:08:05.840
AMY UNRUH: Yes.

00:08:05.840 --> 00:08:11.750
And it has a lot of nice
characteristics that the other

00:08:11.750 --> 00:08:17.770
one doesn't, including things
like asynchronous puts,

00:08:17.770 --> 00:08:21.590
transparent cache management,
really nice transaction

00:08:21.590 --> 00:08:22.710
management, all sorts
of stuff.

00:08:22.710 --> 00:08:24.980
So I really recommend
that you try it out

00:08:24.980 --> 00:08:27.480
if you haven't already.

00:08:27.480 --> 00:08:30.632
And Danny, please break
in at any time as I go

00:08:30.632 --> 00:08:31.690
through these slides.

00:08:31.690 --> 00:08:33.250
I can't actually see Danny.

00:08:33.250 --> 00:08:35.240
You'll see me looking
over sideways.

00:08:35.240 --> 00:08:39.830
I can't actually see him,
but I can hear him.

00:08:39.830 --> 00:08:42.120
DANNY HERMES: I did want to
point out, this particular

00:08:42.120 --> 00:08:46.610
model also does not use one of,
in my opinion, the best

00:08:46.610 --> 00:08:50.470
features of NDB, sort
of its secret sauce.

00:08:50.470 --> 00:08:55.110
It doesn't use memcache or the
local cache of the instance

00:08:55.110 --> 00:08:59.680
handling the requests for
actually caching the data.

00:08:59.680 --> 00:09:03.210
So you see those variables
on user, the attributes--

00:09:03.210 --> 00:09:07.600
that is, _use_cache=false
and _use_memcache=false.

00:09:07.600 --> 00:09:11.640
And that, by default, turns
off those two intermediate

00:09:11.640 --> 00:09:13.720
caches and goes directly
to the datastore.

00:09:13.720 --> 00:09:17.670
So this is really a slide about
the datastore itself.

00:09:17.670 --> 00:09:21.420
So I just wanted to point
that out, Amy.

00:09:21.420 --> 00:09:22.800
AMY UNRUH: Yeah, thanks.

00:09:22.800 --> 00:09:23.740
That's an excellent point.

00:09:23.740 --> 00:09:27.420
We turn those off just for demo
purposes so that we can

00:09:27.420 --> 00:09:29.120
see the RPC calls.

00:09:29.120 --> 00:09:31.790
Normally, you would not
want to do that.

00:09:31.790 --> 00:09:33.030
So we should make
that very clear.

00:09:33.030 --> 00:09:36.410
Normally, you would not want
to turn off the caching.

00:09:36.410 --> 00:09:37.550
You would want to leverage it.

00:09:37.550 --> 00:09:39.265
It works really well.

00:09:39.265 --> 00:09:39.730
Yeah.

00:09:39.730 --> 00:09:40.490
So thanks.

00:09:40.490 --> 00:09:41.030
Very good point.

00:09:41.030 --> 00:09:44.320
We're only doing that
for demo purposes.

00:09:44.320 --> 00:09:45.290
OK.

00:09:45.290 --> 00:09:47.280
So what we're doing
here is we're--

00:09:50.010 --> 00:09:53.820
and I won't go through the code
in gory detail for each

00:09:53.820 --> 00:09:55.110
slide, because that would
take too long.

00:09:55.110 --> 00:09:57.670
But essentially the gist of what
we're doing here is we're

00:09:57.670 --> 00:10:03.170
doing a query based on the
name field of the user.

00:10:03.170 --> 00:10:04.670
OK.

00:10:04.670 --> 00:10:07.780
So Danny, click the
Run button there.

00:10:07.780 --> 00:10:11.100
DANNY HERMES: And
there we are.

00:10:11.100 --> 00:10:12.350
AMY UNRUH: OK.

00:10:14.890 --> 00:10:19.460
What we're seeing here
is the new shell.

00:10:19.460 --> 00:10:24.050
And I won't go through the
pieces of it in detail for

00:10:24.050 --> 00:10:25.610
each of our little examples.

00:10:25.610 --> 00:10:28.110
But just sort of look
it over at first.

00:10:28.110 --> 00:10:30.300
We're seeing a timeline.

00:10:30.300 --> 00:10:37.620
And we're seeing how long
the RPC calls--

00:10:37.620 --> 00:10:41.060
each call in the little code
snippet, and then the total.

00:10:41.060 --> 00:10:45.040
We're seeing the grand total
of how long our little code

00:10:45.040 --> 00:10:46.930
snippet took to run.

00:10:46.930 --> 00:10:50.580
And we're seeing RPC stats.

00:10:50.580 --> 00:10:52.370
So, Danny, I think you
might have to switch

00:10:52.370 --> 00:10:54.920
to RPC Stats tab.

00:10:54.920 --> 00:10:55.610
I'm not sure.

00:10:55.610 --> 00:10:56.690
DANNY HERMES: Yep.

00:10:56.690 --> 00:10:57.130
AMY UNRUH: Yeah.

00:10:57.130 --> 00:10:59.500
OK.

00:10:59.500 --> 00:10:59.890
Yeah.

00:10:59.890 --> 00:11:03.550
And that I'm not seeing
on my slides.

00:11:03.550 --> 00:11:08.550
But you can also see the cost,
the so-called cost, for each

00:11:08.550 --> 00:11:09.960
RPC call that you did.

00:11:09.960 --> 00:11:12.680
Which is new and which
is really cool.

00:11:12.680 --> 00:11:16.880
And up at the top right,
you'll see a little

00:11:16.880 --> 00:11:20.570
explanation of what
these costs mean.

00:11:20.570 --> 00:11:25.990
And so, as everyone might
remember, there's this concept

00:11:25.990 --> 00:11:33.130
of small datastore operations
versus more expensive reads

00:11:33.130 --> 00:11:33.570
and writes.

00:11:33.570 --> 00:11:39.800
And so we'll see that in these
two examples, this one

00:11:39.800 --> 00:11:40.830
and the next one.

00:11:40.830 --> 00:11:42.500
So here we did a datastore
query.

00:11:46.010 --> 00:11:49.870
Sort of make a note of what
all of this cost.

00:11:49.870 --> 00:11:51.680
All right.

00:11:51.680 --> 00:11:52.630
So now, switching back to--

00:11:52.630 --> 00:11:56.370
DANNY HERMES: So Amy, if you
can't see it, the query itself

00:11:56.370 --> 00:12:00.840
cost 140 micro pennies,
and the put itself

00:12:00.840 --> 00:12:03.560
cost 600 micro pennies.

00:12:03.560 --> 00:12:08.350
And those consist of two reads
for the query and six writes

00:12:08.350 --> 00:12:10.960
for the put.

00:12:10.960 --> 00:12:11.630
AMY UNRUH: OK, thanks.

00:12:11.630 --> 00:12:13.590
Yeah, I actually can't see it.

00:12:13.590 --> 00:12:15.702
DANNY HERMES: So you want to
head back to the slides?

00:12:15.702 --> 00:12:16.952
AMY UNRUH: Yeah.

00:12:20.530 --> 00:12:21.780
All right.

00:12:36.900 --> 00:12:38.270
No, I think we're having--

00:12:38.270 --> 00:12:40.806
hold on just a second.

00:12:40.806 --> 00:12:43.970
I think we're having a bit of
a fight between our two.

00:12:43.970 --> 00:12:45.360
DANNY HERMES: Oh, yeah?

00:12:45.360 --> 00:12:46.610
AMY UNRUH: Yeah.

00:12:52.200 --> 00:12:53.100
Sorry, everyone.

00:12:53.100 --> 00:12:56.040
We tried to do something fancy
here with remote slide

00:12:56.040 --> 00:12:56.570
advancement.

00:12:56.570 --> 00:12:58.530
DANNY HERMES: Yes.

00:12:58.530 --> 00:13:00.320
AMY UNRUH: OK.

00:13:00.320 --> 00:13:01.860
So are we on--

00:13:01.860 --> 00:13:05.110
DANNY HERMES: Slide 10.

00:13:05.110 --> 00:13:07.540
Now we're on slide nine, now
we're on slide eight.

00:13:07.540 --> 00:13:08.670
AMY UNRUH: OK.

00:13:08.670 --> 00:13:11.000
Yeah, I think you'll need to
advance the slides, Danny.

00:13:11.000 --> 00:13:11.290
Sorry.

00:13:11.290 --> 00:13:11.640
DANNY HERMES: OK.

00:13:11.640 --> 00:13:13.040
No problem.

00:13:13.040 --> 00:13:14.290
AMY UNRUH: OK.

00:13:26.464 --> 00:13:27.910
Hold on one second.

00:13:27.910 --> 00:13:29.160
DANNY HERMES: Sure thing.

00:13:35.920 --> 00:13:40.940
So what we're seeing here, the
answer to the anti-pattern

00:13:40.940 --> 00:13:42.820
that we just saw.

00:13:42.820 --> 00:13:46.980
Rather than actually explicitly
doing a query,

00:13:46.980 --> 00:13:49.360
we're going to be able, as
Amy said, to look up

00:13:49.360 --> 00:13:51.420
directly from the ID.

00:13:51.420 --> 00:13:54.550
Since we set the ID when we
create the user object that

00:13:54.550 --> 00:13:57.800
we're putting in the datastore,
we can actually go

00:13:57.800 --> 00:14:03.240
ahead and use that ID and query
directly by that ID.

00:14:03.240 --> 00:14:05.560
So Amy, do you want to take the
reins, or are you still

00:14:05.560 --> 00:14:06.610
trying to figure stuff out?

00:14:06.610 --> 00:14:07.860
AMY UNRUH: Yeah.

00:14:10.220 --> 00:14:12.500
Just for Danny's benefit, I've
switched to a different

00:14:12.500 --> 00:14:15.360
version that won't be tracking
with yours, so you can advance

00:14:15.360 --> 00:14:15.860
the slides.

00:14:15.860 --> 00:14:17.030
DANNY HERMES: OK.

00:14:17.030 --> 00:14:17.670
AMY UNRUH: Yeah.

00:14:17.670 --> 00:14:18.920
OK.

00:14:21.890 --> 00:14:25.680
The right way to do this, then,
is to do a get_by_id And

00:14:25.680 --> 00:14:32.260
so if you have the key to your
entity, be sure to fetch by

00:14:32.260 --> 00:14:34.990
that key and not by
doing a query.

00:14:34.990 --> 00:14:38.330
And so this is both cheaper--

00:14:38.330 --> 00:14:42.260
it's a smaller datastore
operation--

00:14:42.260 --> 00:14:44.510
and it's faster, too.

00:14:44.510 --> 00:14:47.479
So Danny, do you want to show
the results for that?

00:15:02.540 --> 00:15:03.790
DANNY HERMES: Wow.

00:15:08.320 --> 00:15:16.360
So we see here in the RPC stats,
instead of 140 and 600,

00:15:16.360 --> 00:15:19.600
the cost of the get is 70.

00:15:19.600 --> 00:15:22.720
And that's because we went from
two reads to one read.

00:15:22.720 --> 00:15:25.710
And the cost of the put is
only 100 instead of 600.

00:15:25.710 --> 00:15:29.080
And that's because we've already
put that ID before.

00:15:29.080 --> 00:15:30.740
That's not anything special.

00:15:30.740 --> 00:15:33.060
This is really an anti-pattern
about queries

00:15:33.060 --> 00:15:35.790
and not about puts.

00:15:35.790 --> 00:15:37.170
Is there anything else
you'd like to point

00:15:37.170 --> 00:15:39.370
out about this, Amy?

00:15:39.370 --> 00:15:39.720
AMY UNRUH: No.

00:15:39.720 --> 00:15:41.380
That's a nice, straightforward
one.

00:15:41.380 --> 00:15:44.340
Remember to always fetch by ID
if you have the ID and it

00:15:44.340 --> 00:15:46.310
makes sense for your app.

00:15:46.310 --> 00:15:47.990
DANNY HERMES: And so what's
happening under the covers,

00:15:47.990 --> 00:15:50.550
before we move on, I just
want to point out.

00:15:50.550 --> 00:15:54.400
If you call a get_by_id on the
actual data class that you've

00:15:54.400 --> 00:15:57.050
defined-- so here,
user.get_by-id--

00:15:57.050 --> 00:16:00.680
what that's doing is, under the
covers, it's explicitly

00:16:00.680 --> 00:16:02.310
constructing a key.

00:16:02.310 --> 00:16:03.840
And then it's just making
a query to the

00:16:03.840 --> 00:16:05.770
datastore from that key.

00:16:05.770 --> 00:16:09.265
So it's a nice class method
afforded by NDB models.

00:16:15.930 --> 00:16:18.250
AMY UNRUH: OK.

00:16:18.250 --> 00:16:23.090
So advancing to the next slide,
Danny, just sort of

00:16:23.090 --> 00:16:26.280
explains why, essentially
recapping what we

00:16:26.280 --> 00:16:29.680
were talking about.

00:16:29.680 --> 00:16:36.680
Queries require more RPCs, and
they're more expensive.

00:16:36.680 --> 00:16:37.900
All right.

00:16:37.900 --> 00:16:40.170
So, anti-pattern number two.

00:16:40.170 --> 00:16:43.940
And this is a good one that's
easy to forget to pay

00:16:43.940 --> 00:16:45.530
attention to.

00:16:45.530 --> 00:16:49.560
Don't use indexed properties
if you don't need to.

00:16:49.560 --> 00:16:56.840
And so as most of you probably
know, one thing that makes the

00:16:56.840 --> 00:17:00.140
datastore so fast and
scalable is the way

00:17:00.140 --> 00:17:02.270
that it uses indexes.

00:17:02.270 --> 00:17:08.290
And each time you create an
entity and save it or update

00:17:08.290 --> 00:17:11.050
it, it requires some
index operations.

00:17:11.050 --> 00:17:21.640
And the particular indexes that
need to be updated depend

00:17:21.640 --> 00:17:26.869
essentially upon the types of
queries that you are making on

00:17:26.869 --> 00:17:29.520
your data, which in turn
is specified in

00:17:29.520 --> 00:17:30.950
an index.yaml file.

00:17:30.950 --> 00:17:37.540
So the number of index writes
that you need to do for a

00:17:37.540 --> 00:17:40.900
given entity can depend upon how
you're using that entity.

00:17:40.900 --> 00:17:46.150
But it can be a significant
part of the expense of

00:17:46.150 --> 00:17:48.330
creating or updating
an entity.

00:17:48.330 --> 00:17:52.770
And so one big key to managing
this expense is you don't need

00:17:52.770 --> 00:17:59.490
to index every field if you
don't need to query on it.

00:17:59.490 --> 00:18:04.260
You might often have entities
with only a few fields needing

00:18:04.260 --> 00:18:07.280
to be queried on, and a
lot of them just there

00:18:07.280 --> 00:18:09.150
to persist the data.

00:18:09.150 --> 00:18:09.570
OK.

00:18:09.570 --> 00:18:15.290
So the default is to essentially
index everything.

00:18:15.290 --> 00:18:20.290
And so here's an anti-pattern,
number two, where we're not

00:18:20.290 --> 00:18:23.360
really paying attention
to our indexes.

00:18:23.360 --> 00:18:29.870
And then, if we go to the next
slide, here we're showing the

00:18:29.870 --> 00:18:31.450
same model.

00:18:31.450 --> 00:18:36.110
But we're saying for the secret
field, indexed=false.

00:18:36.110 --> 00:18:37.580
So we didn't do that before.

00:18:37.580 --> 00:18:39.810
And so the default
was to index it.

00:18:39.810 --> 00:18:44.770
If we say indexed=false,
then we're not

00:18:44.770 --> 00:18:46.170
creating indexes for it.

00:18:46.170 --> 00:18:50.410
It makes our writes cheaper.

00:18:50.410 --> 00:18:53.580
And it makes them faster.

00:18:53.580 --> 00:18:56.210
Sorry, Danny, I forgot
to do the demo of

00:18:56.210 --> 00:18:57.690
the indexed one first.

00:18:57.690 --> 00:18:59.900
So let's go back a previous
slide and show how

00:18:59.900 --> 00:19:01.020
costly it is to--

00:19:01.020 --> 00:19:02.230
DANNY HERMES: For the
anti-pattern?

00:19:02.230 --> 00:19:05.180
AMY UNRUH: Yeah, to do a write
when we're indexing a field

00:19:05.180 --> 00:19:06.430
that we don't need to.

00:19:08.666 --> 00:19:09.690
DANNY HERMES: I'm not sure.

00:19:09.690 --> 00:19:12.905
I'm getting some sort of--

00:19:12.905 --> 00:19:16.151
the Chromebook doesn't
like it.

00:19:16.151 --> 00:19:17.145
AMY UNRUH: Oh, no.

00:19:17.145 --> 00:19:19.300
DANNY HERMES: This
is interesting.

00:19:19.300 --> 00:19:22.240
I think there's an iframe that
it doesn't want to be iframed

00:19:22.240 --> 00:19:23.890
or something.

00:19:23.890 --> 00:19:25.870
Let me reload the deck.

00:19:25.870 --> 00:19:27.340
Sorry, folks.

00:19:27.340 --> 00:19:30.850
This Chromebook is not my
computer, but it is the one

00:19:30.850 --> 00:19:33.312
I'm using right now.

00:19:33.312 --> 00:19:35.760
What in the world?

00:19:35.760 --> 00:19:37.400
How do you right-click
on a Chromebook?

00:19:37.400 --> 00:19:38.650
There we go.

00:19:44.130 --> 00:19:47.350
I don't know why it's
not loading.

00:19:47.350 --> 00:19:48.600
This is unfortunate.

00:19:50.860 --> 00:19:53.700
So it's like there's
an-- oh, OK.

00:19:53.700 --> 00:19:54.950
There we go.

00:20:01.020 --> 00:20:02.270
Let's try it again.

00:20:08.900 --> 00:20:10.250
I don't know what's
happening, Amy.

00:20:13.260 --> 00:20:14.510
It seems like--

00:20:16.930 --> 00:20:19.330
let me just copy the code
and I'll run it.

00:20:23.140 --> 00:20:24.440
AMY UNRUH: And the slides
are online.

00:20:24.440 --> 00:20:27.810
So if we end up having some
technical difficulties here,

00:20:27.810 --> 00:20:31.940
we can just page through the
patterns without trying to do

00:20:31.940 --> 00:20:33.570
the demos if we need to.

00:20:33.570 --> 00:20:36.770
And you guys can play with
that yourself as well.

00:20:36.770 --> 00:20:38.036
DANNY HERMES: Yep.

00:20:38.036 --> 00:20:38.880
All right.

00:20:38.880 --> 00:20:39.800
Oh.

00:20:39.800 --> 00:20:41.050
Same issue.

00:20:43.650 --> 00:20:44.820
It's there.

00:20:44.820 --> 00:20:48.280
It's just behind this thing.

00:20:48.280 --> 00:20:50.120
AMY UNRUH: Essentially, each of
these slides, when we click

00:20:50.120 --> 00:20:54.980
Run, what we're doing is we're
doing a post to the

00:20:54.980 --> 00:20:57.250
Appstats Shell URL.

00:20:57.250 --> 00:21:02.030
And so you guys will be able
to play with this yourself

00:21:02.030 --> 00:21:06.490
with the given slide URL that's
in the GDL event.

00:21:06.490 --> 00:21:08.100
DANNY HERMES: I think what just
happened there was that

00:21:08.100 --> 00:21:10.600
the code was too big, and it
tried to grow the text area

00:21:10.600 --> 00:21:11.860
beyond what the screen wanted.

00:21:11.860 --> 00:21:14.890
So I just deleted it, because
Chrome lets me do that.

00:21:14.890 --> 00:21:15.940
AMY UNRUH: Oh, OK.

00:21:15.940 --> 00:21:16.500
DANNY HERMES: Yeah.

00:21:16.500 --> 00:21:20.820
So breaking down what happened,
since we actually

00:21:20.820 --> 00:21:23.780
had to create this index
property, we had to do nine

00:21:23.780 --> 00:21:32.980
writes to the datastore So there
were puts that happened

00:21:32.980 --> 00:21:35.590
at two different times.

00:21:35.590 --> 00:21:39.480
And that's because we put
the object twice.

00:21:39.480 --> 00:21:41.470
So let's run the other one.

00:21:41.470 --> 00:21:46.200
Let's hope this one doesn't give
us this big white object.

00:21:46.200 --> 00:21:46.490
OK.

00:21:46.490 --> 00:21:48.570
Let me delete that again.

00:21:48.570 --> 00:21:49.820
Sorry, folks.

00:21:55.740 --> 00:21:57.160
OK.

00:21:57.160 --> 00:22:01.120
And this one, there were only
three writes because we didn't

00:22:01.120 --> 00:22:03.090
have to actually create
the indexes.

00:22:03.090 --> 00:22:06.890
So there's that demo, after
a bit more effort than we

00:22:06.890 --> 00:22:07.690
anticipated.

00:22:07.690 --> 00:22:10.130
But that's the point
of a demo, right?

00:22:10.130 --> 00:22:11.380
The demo gods hate everyone.

00:22:14.250 --> 00:22:16.220
So, Amy, do have anything more
you want to say about

00:22:16.220 --> 00:22:19.300
datastore pattern number
two before I move on?

00:22:19.300 --> 00:22:21.370
AMY UNRUH: No, move to next
slide, where there's a sort of

00:22:21.370 --> 00:22:23.660
a recap of that.

00:22:23.660 --> 00:22:27.010
Essentially, as we were saying,
there's a lot more

00:22:27.010 --> 00:22:32.870
going on for each indexed
property.

00:22:32.870 --> 00:22:38.540
You have to do four writes
plus another one to

00:22:38.540 --> 00:22:42.670
essentially create the indexes
for that field.

00:22:42.670 --> 00:22:47.250
And so any time you do not
need a property indexed,

00:22:47.250 --> 00:22:50.290
remember not to set
it to be indexed.

00:22:50.290 --> 00:22:52.110
The default is that
it's indexed.

00:22:52.110 --> 00:22:55.220
So unless you pay attention
to this, you

00:22:55.220 --> 00:22:57.900
won't get the savings.

00:22:57.900 --> 00:22:58.600
OK.

00:22:58.600 --> 00:23:02.320
Let's move on to anti-pattern
number three.

00:23:02.320 --> 00:23:07.000
And this is a neat one that
highlights something that's

00:23:07.000 --> 00:23:10.490
relatively new in terms
of App Engine.

00:23:10.490 --> 00:23:14.180
So don't query full entities
if you don't need to.

00:23:14.180 --> 00:23:17.090
So you'll often have situations
where you don't

00:23:17.090 --> 00:23:20.650
need to grab all the fields
of an entity that

00:23:20.650 --> 00:23:22.240
you're querying for.

00:23:22.240 --> 00:23:29.470
And so here's a situation where
we are grabbing the full

00:23:29.470 --> 00:23:30.560
entity, first of all.

00:23:30.560 --> 00:23:36.520
So we're just doing what you
might think of as sort of a

00:23:36.520 --> 00:23:38.810
generic, vanilla query,
where we're

00:23:38.810 --> 00:23:40.220
getting our user objects.

00:23:40.220 --> 00:23:43.180
So, Danny, why don't you first
show the cost for that?

00:23:43.180 --> 00:23:45.210
DANNY HERMES: OK.

00:23:45.210 --> 00:23:46.170
Ah, wonderful.

00:23:46.170 --> 00:23:47.990
It didn't break.

00:23:47.990 --> 00:23:50.140
AMY UNRUH: Very good.

00:23:50.140 --> 00:23:50.660
DANNY HERMES: Yeah.

00:23:50.660 --> 00:23:55.120
So the stats themselves,
for the RPC.

00:23:55.120 --> 00:23:59.260
We have two writes, which cost
200 micro pennies, and three

00:23:59.260 --> 00:24:03.890
reads, for 210 micro pennies.

00:24:03.890 --> 00:24:05.430
Is there anything else you
want to point out?

00:24:05.430 --> 00:24:10.410
The timeline or any particular
order of those guys?

00:24:10.410 --> 00:24:12.460
AMY UNRUH: No, nothing
in particular.

00:24:12.460 --> 00:24:15.250
We'll get to ordering
in just a bit here.

00:24:15.250 --> 00:24:17.970
Another neat feature of NDB.

00:24:17.970 --> 00:24:18.410
OK.

00:24:18.410 --> 00:24:23.560
So moving onto the pattern
number three, what you should

00:24:23.560 --> 00:24:27.640
do instead, if you don't need
all of the fields in your

00:24:27.640 --> 00:24:29.860
entity, is do a projection
query.

00:24:29.860 --> 00:24:32.970
And we actually had a Hangout
the other day on projection

00:24:32.970 --> 00:24:34.000
queries, as well.

00:24:34.000 --> 00:24:35.800
They're pretty cool.

00:24:35.800 --> 00:24:38.530
And so does the syntax
is different for

00:24:38.530 --> 00:24:40.900
each datastore API.

00:24:40.900 --> 00:24:43.640
So this slide is slightly
different.

00:24:43.640 --> 00:24:44.660
The gist of it is the same.

00:24:44.660 --> 00:24:47.850
The slide is showing
the NDB syntax.

00:24:47.850 --> 00:24:52.010
And so we're doing a projection
on email.

00:24:52.010 --> 00:24:56.630
So we're saying, for our
purposes of this query, we

00:24:56.630 --> 00:25:00.560
just need to get back the email
field of each of our

00:25:00.560 --> 00:25:04.980
objects, and not all
the other stuff.

00:25:04.980 --> 00:25:10.460
And so the query, when entities
are returned, first

00:25:10.460 --> 00:25:12.490
of all, they're cheaper.

00:25:12.490 --> 00:25:16.280
They're small operations,
like keys-only

00:25:16.280 --> 00:25:18.080
fetches in terms of cost.

00:25:18.080 --> 00:25:20.970
And they're quicker as
well, typically.

00:25:20.970 --> 00:25:22.434
DANNY HERMES: So you
want me to run it?

00:25:22.434 --> 00:25:23.250
AMY UNRUH: Yeah.

00:25:23.250 --> 00:25:23.660
DANNY HERMES: All righty.

00:25:23.660 --> 00:25:24.800
So let's see it.

00:25:24.800 --> 00:25:30.910
So our cost for the puts has--

00:25:30.910 --> 00:25:33.630
that's sort of unimportant--

00:25:33.630 --> 00:25:38.430
but the number of RPCs we
actually needed for run query.

00:25:38.430 --> 00:25:40.215
So actually, the cost
didn't change.

00:25:40.215 --> 00:25:41.580
Do you know why that is?

00:25:44.220 --> 00:25:45.630
AMY UNRUH: No, I don't.

00:25:45.630 --> 00:25:49.590
DANNY HERMES: So I guess it's
probably likely that it's not

00:25:49.590 --> 00:25:53.360
the actual cost of the RPC
that changes, given it's

00:25:53.360 --> 00:25:55.320
relatively the same
amount sent across

00:25:55.320 --> 00:25:56.880
the wire as a protobuf.

00:25:56.880 --> 00:26:01.520
But it's the amount of time
to actually get it sent.

00:26:01.520 --> 00:26:02.140
AMY UNRUH: Yeah.

00:26:02.140 --> 00:26:06.640
These entities are so small
that the amount of time

00:26:06.640 --> 00:26:08.780
savings is probably
negligible.

00:26:08.780 --> 00:26:13.550
The RPC operation should have
been cheaper, however.

00:26:13.550 --> 00:26:15.420
DANNY HERMES: OK.

00:26:15.420 --> 00:26:16.460
AMY UNRUH: Should have
been essentially a

00:26:16.460 --> 00:26:21.030
small operation lost.

00:26:21.030 --> 00:26:22.280
DANNY HERMES: Let's run
it again and see.

00:26:25.446 --> 00:26:26.460
Yeah, we're seeing
the same thing.

00:26:26.460 --> 00:26:36.640
AMY UNRUH: Yeah, so go to the
next slide, which talks about

00:26:36.640 --> 00:26:39.000
why this is.

00:26:39.000 --> 00:26:42.330
Essentially, projection
queries only fetch the

00:26:42.330 --> 00:26:43.650
projected fields.

00:26:43.650 --> 00:26:47.470
And they're small reads, as we
were just talking about.

00:26:47.470 --> 00:26:54.920
So it'll be cheaper, and while
the time savings might mean

00:26:54.920 --> 00:26:57.370
negligible for relatively small
entities, it can also be

00:26:57.370 --> 00:27:01.070
a lot faster as well.

00:27:01.070 --> 00:27:04.230
Now, one important thing to
mention, and with our

00:27:04.230 --> 00:27:08.620
projection queries Hangout, we
did go into this in a little

00:27:08.620 --> 00:27:09.955
more detail.

00:27:09.955 --> 00:27:12.840
The indexing requirements for

00:27:12.840 --> 00:27:16.360
projection queries are different.

00:27:16.360 --> 00:27:19.560
I won't go into the details
here, but essentially you--

00:27:19.560 --> 00:27:22.830
depending upon the nature
of your queries--

00:27:22.830 --> 00:27:27.630
you might need to have more
indexes defined if you're

00:27:27.630 --> 00:27:31.990
doing projection queries
than you would for

00:27:31.990 --> 00:27:33.160
non-projection queries.

00:27:33.160 --> 00:27:35.600
It depends on the nature of
what you're querying for.

00:27:35.600 --> 00:27:39.080
So it is possible that if you
switched using projection

00:27:39.080 --> 00:27:45.730
queries, your writes can be
more expensive if you're

00:27:45.730 --> 00:27:48.340
needing to build more queries.

00:27:48.340 --> 00:27:49.950
But your reads should
be cheaper.

00:27:49.950 --> 00:27:52.540
So it's kind of a tradeoff that
you'll have to analyze.

00:27:52.540 --> 00:27:55.620
And it's not necessarily given
that you'll need to define

00:27:55.620 --> 00:27:56.510
additional indexes.

00:27:56.510 --> 00:27:59.820
It sort depends upon what kind
of queries you were making

00:27:59.820 --> 00:28:01.070
previously.

00:28:03.100 --> 00:28:04.620
OK.

00:28:04.620 --> 00:28:07.720
Anti-pattern number four.

00:28:07.720 --> 00:28:08.970
Don't use an offset.

00:28:16.510 --> 00:28:18.910
If you were looking at how to
page through your data, you

00:28:18.910 --> 00:28:23.030
might have seen mention of query
cursors and offsets.

00:28:23.030 --> 00:28:27.030
And offsets are, in a sense,
the simplest or most

00:28:27.030 --> 00:28:28.780
straightforward model.

00:28:28.780 --> 00:28:32.190
What you're saying is,
start giving me data

00:28:32.190 --> 00:28:33.100
from a given point.

00:28:33.100 --> 00:28:38.310
So for example, in the slide,
we're saying we want 10

00:28:38.310 --> 00:28:41.300
entities, but we want starting
at offset 10.

00:28:41.300 --> 00:28:47.870
So starting at entity number 10
in the list that would have

00:28:47.870 --> 00:28:48.990
been returned.

00:28:48.990 --> 00:28:52.420
And so this is often a really
straightforward way,

00:28:52.420 --> 00:28:55.180
conceptually, to page
through your data.

00:28:55.180 --> 00:28:57.830
Because you're saying,
I want to start here.

00:28:57.830 --> 00:29:02.430
And I want to get some number
of entities from this point.

00:29:02.430 --> 00:29:03.430
OK.

00:29:03.430 --> 00:29:07.590
So, why don't you go ahead and
run that query, Danny,

00:29:07.590 --> 00:29:08.640
DANNY HERMES: All righty.

00:29:08.640 --> 00:29:13.790
AMY UNRUH: Turns out that this
can be the non-optimal way to

00:29:13.790 --> 00:29:17.620
do it, for reasons we'll
talk about in a minute.

00:29:17.620 --> 00:29:20.560
This might be another case where
it's relatively simple

00:29:20.560 --> 00:29:22.870
and we don't see much
of a savings for

00:29:22.870 --> 00:29:23.970
this particular example.

00:29:23.970 --> 00:29:27.640
But we'll talk about why,
in general, it can be a

00:29:27.640 --> 00:29:28.790
bad thing to do.

00:29:28.790 --> 00:29:31.450
DANNY HERMES: So the
writes not so much

00:29:31.450 --> 00:29:32.670
important to note here.

00:29:32.670 --> 00:29:33.670
We see 80 writes.

00:29:33.670 --> 00:29:37.480
But that's because we populated
20 entities called

00:29:37.480 --> 00:29:40.160
Heidi zero through Heidi 19.

00:29:40.160 --> 00:29:42.160
Or those were the
keys, excuse me.

00:29:42.160 --> 00:29:43.830
But the reads are what we
want to take note of.

00:29:43.830 --> 00:29:46.140
So we see here 32 reads.

00:29:46.140 --> 00:29:51.620
And that's a result of, as we
see, first querying the first

00:29:51.620 --> 00:29:56.440
10, and then, of course,
getting the second 10.

00:29:56.440 --> 00:30:00.740
And we'll explain a bit of the
differences after we see the

00:30:00.740 --> 00:30:02.410
actual pattern.

00:30:02.410 --> 00:30:06.920
But 32, that's your
magic number.

00:30:06.920 --> 00:30:07.570
AMY UNRUH: OK.

00:30:07.570 --> 00:30:11.600
So let's look at what's
often the more

00:30:11.600 --> 00:30:12.910
preferred way to do it.

00:30:12.910 --> 00:30:15.920
And then we'll talk
about why that is.

00:30:15.920 --> 00:30:18.990
Often, it makes more sense
to use a cursor.

00:30:18.990 --> 00:30:24.920
And the way a cursor works is
when you do a query, you can

00:30:24.920 --> 00:30:28.050
request back a cursor,
essentially a pointer to where

00:30:28.050 --> 00:30:30.170
you were in the query.

00:30:30.170 --> 00:30:32.360
And you can use that for
a substitute query.

00:30:32.360 --> 00:30:37.510
You can say, start from this
point for my next query.

00:30:37.510 --> 00:30:40.230
And you pass the cursor back
into the subsequent query.

00:30:40.230 --> 00:30:42.080
So that's what we're
seeing here.

00:30:42.080 --> 00:30:45.910
We're passing in the
start cursor.

00:30:45.910 --> 00:30:51.830
So instead of using an offset,
saying start at entity 10, or

00:30:51.830 --> 00:30:55.060
start at entity 100, or
whatever, we're getting a

00:30:55.060 --> 00:30:56.340
cursor when we do the query.

00:30:56.340 --> 00:31:00.180
And then we're passing it back
into the subsequent query.

00:31:00.180 --> 00:31:01.410
So why don't you run
that one, Danny?

00:31:01.410 --> 00:31:03.430
DANNY HERMES: Yeah,
let's see it.

00:31:03.430 --> 00:31:09.150
So looking at the stats, instead
of 32 reads, we have

00:31:09.150 --> 00:31:14.540
22 reads for queries and
one read for next.

00:31:14.540 --> 00:31:19.130
And next is a read that
we haven't seen yet.

00:31:19.130 --> 00:31:22.020
So this is actually unique
to cursors and paging.

00:31:22.020 --> 00:31:24.310
But that is sort of the
gist of what we

00:31:24.310 --> 00:31:25.050
want you to see here.

00:31:25.050 --> 00:31:30.410
We went from 32 to 22 plus
1 extra next read.

00:31:30.410 --> 00:31:33.260
So what are the implications,
Amy?

00:31:33.260 --> 00:31:33.620
AMY UNRUH: OK.

00:31:33.620 --> 00:31:35.610
So moving to the next slide.

00:31:35.610 --> 00:31:36.930
So why is this?

00:31:36.930 --> 00:31:41.000
Essentially, what's going on
is that when you use an

00:31:41.000 --> 00:31:45.200
offset, you're still essentially
fetching the

00:31:45.200 --> 00:31:50.470
results, even the first 10,
or first however many.

00:31:50.470 --> 00:31:51.900
You're discarding them,
but you're still

00:31:51.900 --> 00:31:53.320
needing to fetch them.

00:31:53.320 --> 00:31:56.050
And so it's a lot
more expensive.

00:31:56.050 --> 00:32:03.580
And that is amplified if your
offset is, say, 500 or 900 or

00:32:03.580 --> 00:32:06.010
something like that, rather
than just 10.

00:32:06.010 --> 00:32:10.460
So much better is to
just use a cursor.

00:32:10.460 --> 00:32:15.780
And that doesn't require
additional results to be

00:32:15.780 --> 00:32:17.230
fetched and then discarded.

00:32:17.230 --> 00:32:20.660
You're essentially saying, I
know exactly where to pick up

00:32:20.660 --> 00:32:21.410
where I left off.

00:32:21.410 --> 00:32:22.580
Here's the point.

00:32:22.580 --> 00:32:24.780
No extra fetching needs
to be done.

00:32:24.780 --> 00:32:29.480
And so it's faster, cheaper,
less bandwidth.

00:32:29.480 --> 00:32:33.080
And the datastore has
the concept of a

00:32:33.080 --> 00:32:35.190
reverse cursor, as well.

00:32:35.190 --> 00:32:39.990
I won't go into the details,
but essentially it makes it

00:32:39.990 --> 00:32:43.430
possible to do pagination in
both directions using a

00:32:43.430 --> 00:32:45.820
cursor, rather than needing
to use an offset.

00:32:45.820 --> 00:32:47.090
DANNY HERMES: Yep.

00:32:47.090 --> 00:32:47.740
Great feature.

00:32:47.740 --> 00:32:48.993
I love it, actually.

00:32:48.993 --> 00:32:49.820
AMY UNRUH: Yeah.

00:32:49.820 --> 00:32:51.010
It's very nice.

00:32:51.010 --> 00:32:53.990
DANNY HERMES: It's even helpful
if you have created a

00:32:53.990 --> 00:32:57.250
bunch of entities and you want
to delete them all in a way

00:32:57.250 --> 00:33:00.180
that's failover proof, you can
pass cursors from process to

00:33:00.180 --> 00:33:04.390
process rather than actually
trying to do everything in

00:33:04.390 --> 00:33:06.880
place, if you have enough.

00:33:06.880 --> 00:33:08.973
But that's a talk
for another day.

00:33:08.973 --> 00:33:09.840
AMY UNRUH: Yeah.

00:33:09.840 --> 00:33:12.090
In general, it's a much,
much better thing to

00:33:12.090 --> 00:33:13.890
do than to use offsets.

00:33:17.340 --> 00:33:19.380
OK So anti-pattern
number five.

00:33:25.370 --> 00:33:31.780
And now we're finally talking
about memcache.

00:33:31.780 --> 00:33:33.570
Which you might have been
wondering where the role of

00:33:33.570 --> 00:33:36.170
memcache was in all of
this optimization.

00:33:36.170 --> 00:33:43.930
So essentially, don't do a fetch
from the datastore if it

00:33:43.930 --> 00:33:47.580
makes sense to put your entities
in memcache and get

00:33:47.580 --> 00:33:48.680
them from there.

00:33:48.680 --> 00:33:52.290
And so here, I don't think we
need to run this again,

00:33:52.290 --> 00:33:54.030
necessarily.

00:33:54.030 --> 00:33:56.500
This is essentially what we
saw before, where we were

00:33:56.500 --> 00:34:00.660
doing a direct fetch of
the entity by ID.

00:34:00.660 --> 00:34:05.930
And so let's go to the next
slide, the pattern number

00:34:05.930 --> 00:34:15.440
five, where what we're going to
do is fetch the object once

00:34:15.440 --> 00:34:19.210
and then store it in memcache.

00:34:19.210 --> 00:34:21.659
And we won't go into
the details of what

00:34:21.659 --> 00:34:22.880
we're doing to do that.

00:34:22.880 --> 00:34:26.940
In this case, we're essentially
dumping it as a

00:34:26.940 --> 00:34:27.929
JSON string.

00:34:27.929 --> 00:34:30.010
There's other ways you
could do it, as well.

00:34:30.010 --> 00:34:35.480
And then later on, if we need
to fetch that object, the

00:34:35.480 --> 00:34:37.889
first thing we do is check
if it's in memcache.

00:34:37.889 --> 00:34:43.429
And only if we don't get a
memcache hit do we actually

00:34:43.429 --> 00:34:45.080
fetch the object.

00:34:45.080 --> 00:34:49.969
And so there are, as many of
you watching this probably

00:34:49.969 --> 00:34:53.609
know, you're probably thinking,
well, that's a

00:34:53.609 --> 00:34:54.065
little oversimplified.

00:34:54.065 --> 00:34:55.810
And there's all sorts of things
that you have to pay

00:34:55.810 --> 00:34:59.150
attention to when you're
using the cache.

00:34:59.150 --> 00:35:04.870
And so happily, NDB actually
does, in fact, do a really

00:35:04.870 --> 00:35:07.350
good job of managing
the cache for you.

00:35:07.350 --> 00:35:09.900
So that if you use NDB,
you don't need to

00:35:09.900 --> 00:35:11.820
write this code yourself.

00:35:11.820 --> 00:35:15.500
You just need to use
the NDB cache.

00:35:15.500 --> 00:35:23.470
So you would, in fact, not
set those use_cache and

00:35:23.470 --> 00:35:26.570
use_memcache flags to
false, like this

00:35:26.570 --> 00:35:27.840
example slide is doing.

00:35:27.840 --> 00:35:29.840
And you would let memcache
manage it for you.

00:35:33.760 --> 00:35:36.365
DANNY HERMES: Shall I run
it, or shall we move on?

00:35:36.365 --> 00:35:37.140
AMY UNRUH: Yeah, why
don't you go ahead

00:35:37.140 --> 00:35:38.105
and run it real quick?

00:35:38.105 --> 00:35:38.450
DANNY HERMES: All right.

00:35:38.450 --> 00:35:39.700
Let's see it.

00:35:43.970 --> 00:35:47.830
So we actually have only
one datastore write

00:35:47.830 --> 00:35:49.430
coming out of this.

00:35:49.430 --> 00:35:53.590
Because the other calls, the
other RPCs, are memcache RPCs.

00:35:53.590 --> 00:35:58.640
We have a memcache set from
the top and a memcache get

00:35:58.640 --> 00:36:01.380
when we try to make that
retrieval instead of hitting

00:36:01.380 --> 00:36:02.700
the datastore first.

00:36:02.700 --> 00:36:04.580
So we just have one
write to get our

00:36:04.580 --> 00:36:05.880
object into the datastore.

00:36:05.880 --> 00:36:08.250
And we have no other
datastore RPCs.

00:36:13.440 --> 00:36:16.840
AMY UNRUH: And as we were just
talking about, the same will

00:36:16.840 --> 00:36:19.490
happen if you use memcache
and don't set

00:36:19.490 --> 00:36:20.740
those flags to false.

00:36:23.140 --> 00:36:26.480
I think maybe we'll skip showing
the demo of that,

00:36:26.480 --> 00:36:28.970
since we're running a little
short on time.

00:36:28.970 --> 00:36:31.050
But it's essentially the same.

00:36:31.050 --> 00:36:33.790
And you wanted to
show it, Danny?

00:36:33.790 --> 00:36:35.480
It's kind of neat how
NDB manages it.

00:36:35.480 --> 00:36:36.130
DANNY HERMES: Yes.

00:36:36.130 --> 00:36:38.670
We may not even see
it hit memcache.

00:36:38.670 --> 00:36:41.010
OK.

00:36:41.010 --> 00:36:43.350
We only see it set memcache.

00:36:43.350 --> 00:36:46.380
We also see a call to delete
memcache because it's undoing

00:36:46.380 --> 00:36:47.470
what the previous one did.

00:36:47.470 --> 00:36:49.980
It's invalidating the cache.

00:36:49.980 --> 00:36:55.290
But we never see memcache.get
because in this particular

00:36:55.290 --> 00:36:59.960
slide, we're also using the
local cache on the instance.

00:36:59.960 --> 00:37:03.050
So it never even needs to
read from memcache.

00:37:03.050 --> 00:37:05.040
Because get_by_id will
automatically

00:37:05.040 --> 00:37:07.880
read from the instance.

00:37:07.880 --> 00:37:08.350
AMY UNRUH: Yeah.

00:37:08.350 --> 00:37:12.300
And that's, in fact, something
particularly nice about the

00:37:12.300 --> 00:37:13.380
NDB caching model.

00:37:13.380 --> 00:37:15.780
It will use instance
memory where it

00:37:15.780 --> 00:37:19.390
can, as well as memcache.

00:37:19.390 --> 00:37:20.640
It's very nice.

00:37:26.760 --> 00:37:31.140
And then the next slide just
sort of summarizes this.

00:37:31.140 --> 00:37:33.380
Reading from memcache is
faster and cheaper.

00:37:33.380 --> 00:37:36.430
And then instance memory, which
again NDB will manage

00:37:36.430 --> 00:37:42.460
for you if you let it use its
defaults, is even faster.

00:37:42.460 --> 00:37:43.710
And it's free.

00:37:47.870 --> 00:37:53.430
And so finally, one more really
nice anti-pattern.

00:37:53.430 --> 00:37:57.670
Don't do individual RPCs
when you have to.

00:37:57.670 --> 00:38:01.590
OK, so first let's just run an
example where we are doing

00:38:01.590 --> 00:38:02.820
individual RPCs.

00:38:02.820 --> 00:38:07.700
And by that, we're doing
100 puts, each

00:38:07.700 --> 00:38:09.090
one after the other.

00:38:09.090 --> 00:38:13.200
DANNY HERMES: And it is
taking a long time.

00:38:13.200 --> 00:38:18.270
So the emphasis here is not that
we're going to be hitting

00:38:18.270 --> 00:38:19.730
the datastore any less.

00:38:19.730 --> 00:38:22.020
It's really the amount
of time spent hitting

00:38:22.020 --> 00:38:23.610
the datastore, right?

00:38:23.610 --> 00:38:26.940
So we see this giant cascade.

00:38:26.940 --> 00:38:29.240
Most of them are pretty quick,
on the order of 20

00:38:29.240 --> 00:38:30.140
milliseconds.

00:38:30.140 --> 00:38:33.010
But every once in a while, we
have some extra latency.

00:38:33.010 --> 00:38:35.530
So we had a 139, a 172.

00:38:35.530 --> 00:38:39.310
And then it kind of gets long,
as we go down this cascade.

00:38:39.310 --> 00:38:41.830
We're even as bad as
483 at some time.

00:38:41.830 --> 00:38:48.460
So our total time, our grand
total was 6,674 milliseconds.

00:38:48.460 --> 00:38:52.630
So almost 7,000 milliseconds
to actually put all 100 of

00:38:52.630 --> 00:38:55.400
these in succession.

00:38:55.400 --> 00:38:57.990
And they're all blocking puts,
so we can't get to the next--

00:38:57.990 --> 00:39:00.140
AMY UNRUH: Yeah, one
after the other.

00:39:00.140 --> 00:39:01.460
DANNY HERMES: That's why
we saw that cascade.

00:39:04.060 --> 00:39:04.760
AMY UNRUH: OK.

00:39:04.760 --> 00:39:08.110
So you might be thinking, well,
do they really have to

00:39:08.110 --> 00:39:09.910
put one after the
other like that?

00:39:09.910 --> 00:39:11.860
And no, they do not.

00:39:11.860 --> 00:39:16.780
And this is another thing that
NDB makes very easy.

00:39:16.780 --> 00:39:19.520
So let's look at
the next slide.

00:39:19.520 --> 00:39:21.980
How can you batch these?

00:39:21.980 --> 00:39:25.090
And it's very straightforward.

00:39:25.090 --> 00:39:28.720
You do a multi-put.

00:39:28.720 --> 00:39:32.110
Sorry, put_multi is the actual
name of the call.

00:39:32.110 --> 00:39:34.280
And it's really straightforward
to invoke.

00:39:34.280 --> 00:39:37.930
We're just passing put_multi
a list of

00:39:37.930 --> 00:39:40.370
all of our new entities.

00:39:40.370 --> 00:39:40.670
OK.

00:39:40.670 --> 00:39:42.905
So let's take a look
at what that does.

00:39:42.905 --> 00:39:43.350
DANNY HERMES: Yeah.

00:39:43.350 --> 00:39:45.430
Let's see if we see a
cascade still, or

00:39:45.430 --> 00:39:48.850
something completely different.

00:39:48.850 --> 00:39:53.820
So rather than 6,600
milliseconds, our grand total

00:39:53.820 --> 00:39:57.070
time, 457 milliseconds.

00:39:57.070 --> 00:39:59.500
So it's a complete turnaround.

00:39:59.500 --> 00:40:03.680
And we do see an RPC total
of 2,019 milliseconds.

00:40:03.680 --> 00:40:05.870
And that's a different
statistic.

00:40:05.870 --> 00:40:08.080
and I'll let Amy talk about
the difference between RPC

00:40:08.080 --> 00:40:09.710
total and grand total here.

00:40:09.710 --> 00:40:14.690
But the big turnaround we want
you to see is 6,600 to 457 on

00:40:14.690 --> 00:40:18.170
the grand total for the RPCs.

00:40:18.170 --> 00:40:19.380
So Amy, back to you.

00:40:19.380 --> 00:40:19.960
AMY UNRUH: OK.

00:40:19.960 --> 00:40:23.020
So moving to the next slide.

00:40:23.020 --> 00:40:25.370
Why is this happening?

00:40:25.370 --> 00:40:28.880
So essentially, what put_multi
is doing is it's batching the

00:40:28.880 --> 00:40:32.820
writes, and it's running them
in parallel, essentially.

00:40:32.820 --> 00:40:40.360
And so it's a lot faster,
and the grand total

00:40:40.360 --> 00:40:41.530
time is much reduced.

00:40:41.530 --> 00:40:43.430
You're not blocking.

00:40:43.430 --> 00:40:45.510
You're not doing the
RPCs individually,

00:40:45.510 --> 00:40:49.180
and you're not blocking.

00:40:49.180 --> 00:40:59.640
And you are still charged
for all of your

00:40:59.640 --> 00:41:00.780
writes in the same way.

00:41:00.780 --> 00:41:03.790
So you're not seeing
any reduction in

00:41:03.790 --> 00:41:04.800
terms of those costs.

00:41:04.800 --> 00:41:06.450
But it's a lot more efficient.

00:41:06.450 --> 00:41:09.820
And you can use this technique
not only with datastore, but

00:41:09.820 --> 00:41:13.730
memcache, task queue, full
text search API.

00:41:13.730 --> 00:41:16.600
DANNY HERMES: So it's still
the same cost for your

00:41:16.600 --> 00:41:19.620
datastore operations, but you
no longer have the cost of a

00:41:19.620 --> 00:41:22.430
poor user experience, right?

00:41:22.430 --> 00:41:23.680
AMY UNRUH: Right.

00:41:27.710 --> 00:41:28.420
OK.

00:41:28.420 --> 00:41:30.275
And one more, real quickly.

00:41:33.590 --> 00:41:36.740
Yet another great
feature of NDB.

00:41:36.740 --> 00:41:38.630
I'm probably sounding
a bit like a broken

00:41:38.630 --> 00:41:43.420
record, but NDB is great.

00:41:43.420 --> 00:41:48.740
If you have different RPC
calls, you don't have to

00:41:48.740 --> 00:41:53.820
essentially do them all
synchronously and in sequence.

00:41:53.820 --> 00:41:56.670
Let's skip running this one,
Danny, because we're running a

00:41:56.670 --> 00:41:58.710
little short on time.

00:41:58.710 --> 00:42:00.120
Move to the next slide.

00:42:00.120 --> 00:42:04.170
How can you avoid running
them in sequence?

00:42:04.170 --> 00:42:09.770
You can use something that we
don't have the time to go into

00:42:09.770 --> 00:42:11.160
in detail here.

00:42:11.160 --> 00:42:15.930
You can use the concept of
futures, where you're

00:42:15.930 --> 00:42:18.130
essentially spawning off
all of your calls.

00:42:18.130 --> 00:42:20.710
You're saying, go
do your stuff.

00:42:20.710 --> 00:42:23.180
Don't block on waiting
for the result.

00:42:23.180 --> 00:42:28.170
And then when you're ready to
use the result, at that point

00:42:28.170 --> 00:42:30.810
you can say, all right, now I'm
going to wait until all

00:42:30.810 --> 00:42:32.290
these calls are returned.

00:42:32.290 --> 00:42:34.690
So what we're doing here
is we're starting

00:42:34.690 --> 00:42:36.890
the first URL fetch.

00:42:36.890 --> 00:42:39.300
And we don't need to wait for
it to return before we start

00:42:39.300 --> 00:42:39.910
the second one.

00:42:39.910 --> 00:42:42.060
We don't need to wait for either
of those to return

00:42:42.060 --> 00:42:44.520
before we start the first one.

00:42:44.520 --> 00:42:51.560
And there's an analog that I
don't believe we have a slide

00:42:51.560 --> 00:42:55.280
for, for datastore operations
as well.

00:42:55.280 --> 00:42:57.050
Which is a put_async,
which does

00:42:57.050 --> 00:42:59.020
essentially the same thing.

00:42:59.020 --> 00:43:03.230
So this is showing RPC calls
that don't access the

00:43:03.230 --> 00:43:06.930
datastore, but there's a
put_async variant for

00:43:06.930 --> 00:43:09.140
accessing the datastore
in the same way.

00:43:09.140 --> 00:43:13.170
So the concept is basically,
start a bunch of operations

00:43:13.170 --> 00:43:15.650
and then you can do some
stuff in between.

00:43:15.650 --> 00:43:18.080
Then when you need them to have
all be done, then you can

00:43:18.080 --> 00:43:20.280
synchronize and wait for
them all to finish.

00:43:26.890 --> 00:43:28.220
And why do this?

00:43:28.220 --> 00:43:32.380
Well, latency depends on the
slowest async RPC, so it's

00:43:32.380 --> 00:43:35.250
good to do as much other
computation is you can while

00:43:35.250 --> 00:43:35.670
you're waiting for

00:43:35.670 --> 00:43:39.020
the I/O. All right.

00:43:41.610 --> 00:43:44.870
Anything you wanted to add,
Danny, before we [INAUDIBLE]

00:43:44.870 --> 00:43:45.900
and get a few questions?

00:43:45.900 --> 00:43:49.500
DANNY HERMES: I did just want to
mention that using futures

00:43:49.500 --> 00:43:54.830
is a great feature of NDB, but
URL Fetch also has fetch async

00:43:54.830 --> 00:43:56.860
already within that API.

00:43:56.860 --> 00:44:00.670
But you have to sort of write
your own wrappers around it,

00:44:00.670 --> 00:44:03.360
and figure out your own
ways that you want to

00:44:03.360 --> 00:44:04.600
wait on a lot of things.

00:44:04.600 --> 00:44:08.720
Whereas if you use NDB futures,
it's just kind of

00:44:08.720 --> 00:44:11.710
done for you.

00:44:11.710 --> 00:44:13.460
AMY UNRUH: And applicable
to other things,

00:44:13.460 --> 00:44:14.490
other than URL fetch.

00:44:14.490 --> 00:44:15.500
DANNY HERMES: Oh, certainly.

00:44:15.500 --> 00:44:16.750
Certainly.

00:44:19.040 --> 00:44:19.380
Yes.

00:44:19.380 --> 00:44:20.630
That's a special
feature there.

00:44:24.820 --> 00:44:25.190
AMY UNRUH: OK.

00:44:25.190 --> 00:44:27.150
So just kind of wrapping
up with this.

00:44:27.150 --> 00:44:30.610
Then we'll have time for
a few questions from

00:44:30.610 --> 00:44:31.810
the moderator queue.

00:44:31.810 --> 00:44:36.840
There's a related recent Google
I/O talk that's linked

00:44:36.840 --> 00:44:39.180
to in the slides called
Optimizing Your Google App

00:44:39.180 --> 00:44:40.250
Engine App.

00:44:40.250 --> 00:44:45.310
And it doesn't make the same
use as the Appstat

00:44:45.310 --> 00:44:46.660
Shell as ours does.

00:44:46.660 --> 00:44:48.730
It has a little bit of
a different focus.

00:44:48.730 --> 00:44:51.360
But it covers a lot of these
same concepts and more.

00:44:51.360 --> 00:44:52.985
Goes into some of them
in a lot more detail.

00:44:52.985 --> 00:44:55.640
So I'd really recommend it
if you're interested in

00:44:55.640 --> 00:44:56.890
this kind of thing.

00:44:59.800 --> 00:45:02.750
And then other things that we
didn't have a chance to

00:45:02.750 --> 00:45:08.220
mention include things like
making use of the task queue.

00:45:08.220 --> 00:45:11.540
You don't have to do everything
synchronously with

00:45:11.540 --> 00:45:13.600
your user facing requests.

00:45:13.600 --> 00:45:15.640
You can offload a
lot of things.

00:45:15.640 --> 00:45:25.510
You can take advantage of the
instant scheduler behavior to

00:45:25.510 --> 00:45:29.180
essentially control things
related to how soon your

00:45:29.180 --> 00:45:34.000
instances are--

00:45:34.000 --> 00:45:38.360
basically, how many warm
instances you need, how long

00:45:38.360 --> 00:45:41.080
you wait for an instance to be
available before you start up

00:45:41.080 --> 00:45:41.870
another one--

00:45:41.870 --> 00:45:45.790
all sorts of stuff that can have
an overall effect on your

00:45:45.790 --> 00:45:47.060
application latency.

00:45:47.060 --> 00:45:50.300
And so, again, that's a topic
for another Hangout.

00:45:56.572 --> 00:45:57.030
DANNY HERMES: Yield thank you.

00:45:57.030 --> 00:46:01.020
AMY UNRUH: And again, many
thanks to Proppy for creating

00:46:01.020 --> 00:46:02.345
the original version
of these slides.

00:46:05.540 --> 00:46:07.240
DANNY HERMES: So I'm going
to stop sharing the

00:46:07.240 --> 00:46:08.930
screen for a bit.

00:46:08.930 --> 00:46:18.140
And I'm going to get the
moderator queue pulled up.

00:46:18.140 --> 00:46:20.070
Give me one second
before I do that.

00:46:20.070 --> 00:46:22.340
Amy, if you already have it
pulled up or if you have a

00:46:22.340 --> 00:46:25.060
question from it off the top of
your head, feel free to go

00:46:25.060 --> 00:46:27.620
ahead and start answering.

00:46:27.620 --> 00:46:28.230
AMY UNRUH: OK.

00:46:28.230 --> 00:46:29.600
I do have it pulled up.

00:46:29.600 --> 00:46:32.800
And let me just say, I think we
ran a little longer than we

00:46:32.800 --> 00:46:33.970
meant to in the presentation.

00:46:33.970 --> 00:46:34.740
Sorry about that.

00:46:34.740 --> 00:46:38.880
So for those of you whose
questions we don't get to, we

00:46:38.880 --> 00:46:42.480
will post responses in
the moderator queue.

00:46:42.480 --> 00:46:46.140
So look for it there.

00:46:46.140 --> 00:46:52.370
So let me start with an easy
one, or at least easy in terms

00:46:52.370 --> 00:46:54.210
of how I know how
to answer it.

00:46:54.210 --> 00:46:57.090
Will we ever be able to run
App Engine apps on our own

00:46:57.090 --> 00:47:00.140
servers, sort of like a dev
app server meant for

00:47:00.140 --> 00:47:02.490
production?

00:47:02.490 --> 00:47:05.390
And so for that, I would
recommend you check out

00:47:05.390 --> 00:47:08.960
something called AppScale,
which is quite

00:47:08.960 --> 00:47:10.870
an interesting project--

00:47:10.870 --> 00:47:15.150
and I'll post the link here
in the moderator queue--

00:47:15.150 --> 00:47:16.860
which essentially does that.

00:47:16.860 --> 00:47:18.390
And I've never tried
it myself.

00:47:18.390 --> 00:47:24.270
But it's a really interesting
research project, essentially.

00:47:24.270 --> 00:47:25.240
Really cool.

00:47:25.240 --> 00:47:27.870
So AppScale.

00:47:27.870 --> 00:47:29.150
All right.

00:47:29.150 --> 00:47:29.700
Let's see.

00:47:29.700 --> 00:47:33.700
And then there's a question
about calendar events, which

00:47:33.700 --> 00:47:36.690
we will also answer in
the moderator queue.

00:47:36.690 --> 00:47:39.290
The short answer is yeah,
there are ways

00:47:39.290 --> 00:47:40.540
to find these events.

00:47:43.720 --> 00:47:46.120
OK.

00:47:46.120 --> 00:47:48.066
You want to pick one
to answer, Danny?

00:47:48.066 --> 00:47:48.480
DANNY HERMES: Yeah.

00:47:48.480 --> 00:47:50.080
Sure thing.

00:47:50.080 --> 00:47:51.260
So there was--

00:47:51.260 --> 00:47:55.800
let me find the exact
text of it.

00:47:55.800 --> 00:47:57.260
Let's see.

00:47:57.260 --> 00:48:00.190
This is a question
about testing.

00:48:00.190 --> 00:48:07.600
So somebody is testing with
Testpad, and they're wondering

00:48:07.600 --> 00:48:12.250
if there's a way to disable
some stubs.

00:48:12.250 --> 00:48:16.760
Or how they can actually enable
a logged-in user.

00:48:16.760 --> 00:48:19.020
So I'll just say if
somebody wants to

00:48:19.020 --> 00:48:21.640
check out the actual--

00:48:21.640 --> 00:48:22.150
I think it's

00:48:22.150 --> 00:48:27.220
google.appengine.api.users module--

00:48:27.220 --> 00:48:31.260
there's some functions in there
that actually allow you

00:48:31.260 --> 00:48:32.800
to work with users, right?

00:48:32.800 --> 00:48:35.450
And there's one there,
users.get_current_user.

00:48:35.450 --> 00:48:38.570
And all the sourcing that does,
it actually tries to

00:48:38.570 --> 00:48:41.040
read some variables.

00:48:41.040 --> 00:48:45.670
And so in Python, you can get
them by calling OS.get_env or

00:48:45.670 --> 00:48:49.290
trying to actually use the
OS.environ dictionary.

00:48:49.290 --> 00:48:52.260
And they set various things.

00:48:52.260 --> 00:48:56.170
Like user is admin is either
a zero or a one.

00:48:56.170 --> 00:48:58.510
User ID is set to some number.

00:48:58.510 --> 00:49:01.000
User email is set
to some value.

00:49:01.000 --> 00:49:03.460
And so if you're testing,
you can actually set the

00:49:03.460 --> 00:49:05.890
environment variables yourself
before you're

00:49:05.890 --> 00:49:07.020
running those tests.

00:49:07.020 --> 00:49:12.900
And so all these sort of App
Engine functionalities which

00:49:12.900 --> 00:49:17.110
take advantage of identity are
then just going to go ahead

00:49:17.110 --> 00:49:18.470
and use those environment
variables.

00:49:18.470 --> 00:49:20.210
So you actually don't have
to worry about a stub.

00:49:20.210 --> 00:49:22.410
You can just set the environment
variable.

00:49:22.410 --> 00:49:25.220
It sounds like this particular
person is familiar with

00:49:25.220 --> 00:49:28.580
certain things like datastore
subs and other things for

00:49:28.580 --> 00:49:30.710
doing testing, but if you're
not, we certainly

00:49:30.710 --> 00:49:32.080
welcome more questions.

00:49:32.080 --> 00:49:34.295
Because testing is important.

00:49:39.220 --> 00:49:39.670
AMY UNRUH: OK.

00:49:39.670 --> 00:49:44.030
Let's answer one of the

00:49:44.030 --> 00:49:45.420
Appstats-specific questions here.

00:49:48.380 --> 00:49:49.630
Let's see.

00:49:53.780 --> 00:49:54.610
There's one question.

00:49:54.610 --> 00:49:58.280
When you use the batch APIs,
the batcher under the hood

00:49:58.280 --> 00:50:00.470
spins up multiple RPCs.

00:50:00.470 --> 00:50:01.520
From Jason.

00:50:01.520 --> 00:50:04.290
While this performance
optimization is welcome, it

00:50:04.290 --> 00:50:06.690
makes the Appstats visualization
very busy.

00:50:06.690 --> 00:50:08.270
Yes, it does.

00:50:08.270 --> 00:50:12.510
Any thought as to how you
might group RPCs better?

00:50:12.510 --> 00:50:18.420
So I think that that is part
of what the new Appstats

00:50:18.420 --> 00:50:24.090
Analytics, essentially layer on
top of Appstats, is trying

00:50:24.090 --> 00:50:26.990
to address, at least
to some extent.

00:50:26.990 --> 00:50:32.290
There are different ways to
drill down into your data.

00:50:32.290 --> 00:50:39.410
And so if you're not already
a trusted tester for this,

00:50:39.410 --> 00:50:43.150
please do sign up
and take a look.

00:50:43.150 --> 00:50:48.760
And the Appstats Analytics are
at a stage where we're really

00:50:48.760 --> 00:50:53.500
open to lots of feedback about
how it could be improved or

00:50:53.500 --> 00:50:55.420
what you're seeing that
works or doesn't work.

00:50:55.420 --> 00:50:58.120
And so we'd really,
really appreciate

00:50:58.120 --> 00:50:59.150
the feedback on that.

00:50:59.150 --> 00:51:01.615
It's sort of an attempt to get
at some of these issues.

00:51:06.650 --> 00:51:07.900
OK.

00:51:10.900 --> 00:51:14.930
So another question from Jason
that I'll answer briefly,

00:51:14.930 --> 00:51:17.750
about the stack that we
saw in the cascade.

00:51:17.750 --> 00:51:22.170
And he was asking about why they
were getting longer on

00:51:22.170 --> 00:51:26.360
the requests as you were
getting further along.

00:51:26.360 --> 00:51:29.270
And there are various
reasons for this.

00:51:29.270 --> 00:51:31.030
Latency is never a guarantee.

00:51:31.030 --> 00:51:34.190
You don't know where the actual
data center or any

00:51:34.190 --> 00:51:39.320
other particular physical
location of the machine is.

00:51:39.320 --> 00:51:42.120
But also, if you're hitting an
instance, and you're hitting

00:51:42.120 --> 00:51:44.820
the same instance with more
and more requests, then

00:51:44.820 --> 00:51:47.810
latency can increase because
there's less memory.

00:51:47.810 --> 00:51:51.200
And I believe the application
we were running was

00:51:51.200 --> 00:51:52.140
multi-threaded.

00:51:52.140 --> 00:51:54.650
So as more requests hit
the same instance,

00:51:54.650 --> 00:51:56.190
it gets spread thinner.

00:51:56.190 --> 00:51:59.050
And it's not able to address
things as quickly.

00:51:59.050 --> 00:52:03.810
Do you have any other remarks
about that, Amy?

00:52:03.810 --> 00:52:04.400
AMY UNRUH: No.

00:52:04.400 --> 00:52:06.480
DANNY HERMES: OK, cool.

00:52:06.480 --> 00:52:06.830
Do we want--

00:52:06.830 --> 00:52:10.280
AMY UNRUH: Let's answer the
question from Bryce.

00:52:10.280 --> 00:52:12.380
It's got a number
of votes there.

00:52:12.380 --> 00:52:14.690
Although I'm not sure if
I can answer to Bryce's

00:52:14.690 --> 00:52:17.610
satisfaction, but we'll
give it a try.

00:52:17.610 --> 00:52:21.580
Will the CPM USD number in
AppLogs eventually reflect the

00:52:21.580 --> 00:52:24.780
cost reported by Appstats?

00:52:24.780 --> 00:52:26.250
Is it relevant?

00:52:26.250 --> 00:52:28.950
So my understanding, and Danny
can correct me if he knows

00:52:28.950 --> 00:52:32.940
differently, is that
yes, it is relevant

00:52:32.940 --> 00:52:34.190
and is intended to--

00:52:36.732 --> 00:52:38.540
it reflects reality.

00:52:38.540 --> 00:52:43.950
And it's based on underlying
calculations that are tied to

00:52:43.950 --> 00:52:46.890
what the actual charges are.

00:52:46.890 --> 00:52:56.420
And so the RPC costs reported
by Appstats, I believe, is a

00:52:56.420 --> 00:52:57.330
subset of this.

00:52:57.330 --> 00:52:59.590
So that's why they don't
exactly track.

00:52:59.590 --> 00:53:05.470
But to get to my knowledge,
it is relevant and

00:53:05.470 --> 00:53:07.010
intended to be accurate.

00:53:07.010 --> 00:53:08.415
Danny, did you have
any further--?

00:53:08.415 --> 00:53:10.800
DANNY HERMES: I can neither add
to that nor contradict it.

00:53:10.800 --> 00:53:12.200
So good answer.

00:53:12.200 --> 00:53:13.900
AMY UNRUH: Yeah.

00:53:13.900 --> 00:53:16.790
We can follow up and post
more information.

00:53:16.790 --> 00:53:18.530
But yeah, it should
be accurate.

00:53:21.830 --> 00:53:23.990
OK.

00:53:23.990 --> 00:53:28.670
Let's go to a question
from Gary.

00:53:28.670 --> 00:53:31.580
And we're almost running
out of time.

00:53:31.580 --> 00:53:32.880
Yes, we are.

00:53:32.880 --> 00:53:33.700
So sorry, everyone.

00:53:33.700 --> 00:53:37.400
Again, anything else we'll
post responses to in the

00:53:37.400 --> 00:53:38.300
moderator queue.

00:53:38.300 --> 00:53:42.790
And next time we'll hope to
invite more of you into the

00:53:42.790 --> 00:53:44.930
circle so you can actually
chat with us directly.

00:53:44.930 --> 00:53:46.730
OK, so one last question.

00:53:46.730 --> 00:53:47.200
From Gary.

00:53:47.200 --> 00:53:49.970
What's the best cost-effective,
scalable, et

00:53:49.970 --> 00:53:53.400
cetera, design for a sensor
internet of thing kind of

00:53:53.400 --> 00:53:54.820
application.

00:53:54.820 --> 00:53:57.500
Some of the constraints are
real-time responses based on

00:53:57.500 --> 00:53:59.490
time window of data.

00:53:59.490 --> 00:54:04.460
Maybe using backends memory,
push queue, or channel.

00:54:04.460 --> 00:54:09.210
And also map reducing
historical data.

00:54:09.210 --> 00:54:12.550
Well, that's a very
broad-ranging question that

00:54:12.550 --> 00:54:15.350
maybe I shouldn't have tackled
just as we were about to run

00:54:15.350 --> 00:54:16.110
out of time.

00:54:16.110 --> 00:54:17.200
DANNY HERMES: I'm not
entirely sure I

00:54:17.200 --> 00:54:19.960
understand the scope even.

00:54:19.960 --> 00:54:25.360
Though I do like that he wants
to use all these features.

00:54:25.360 --> 00:54:31.290
AMY UNRUH: Yeah, I guess in
terms of making things really

00:54:31.290 --> 00:54:37.040
scalable, some general pieces of
advice would be lots of use

00:54:37.040 --> 00:54:41.360
of in-memory caches
and backends can

00:54:41.360 --> 00:54:44.560
often be really effective.

00:54:44.560 --> 00:54:46.590
Depending on what you're trying
to do, you get some big

00:54:46.590 --> 00:54:49.060
backend instances running.

00:54:49.060 --> 00:54:50.710
They can stay up for
a long time.

00:54:50.710 --> 00:54:54.730
And they can hold a lot of
stuff in their cache.

00:54:54.730 --> 00:54:58.030
And that can be a really low
latency and an effective way

00:54:58.030 --> 00:55:01.176
to do things.

00:55:01.176 --> 00:55:03.610
DANNY HERMES: And they can also
run computations much

00:55:03.610 --> 00:55:07.160
longer than standard tasks.

00:55:07.160 --> 00:55:09.650
AMY UNRUH: Right.

00:55:09.650 --> 00:55:10.100
Yeah.

00:55:10.100 --> 00:55:14.540
Backends can be really good with
long-running computations

00:55:14.540 --> 00:55:18.270
and things where you have
some sensitivity in

00:55:18.270 --> 00:55:21.130
terms of your latency.

00:55:21.130 --> 00:55:26.620
And, of course, task queues are
really good for being able

00:55:26.620 --> 00:55:28.190
to offload as much as you can.

00:55:28.190 --> 00:55:31.510
Anything that doesn't require an
immediate response, if you

00:55:31.510 --> 00:55:33.750
can offload it to
a task queue.

00:55:33.750 --> 00:55:36.420
And again, those task queues
can run on backends if you

00:55:36.420 --> 00:55:37.500
need them to.

00:55:37.500 --> 00:55:39.040
That can be really effective,
as well.

00:55:44.280 --> 00:55:50.620
And I'm sure Gary, who's from
Sydney, I think we'll have a

00:55:50.620 --> 00:55:52.830
chance to talk about this
at some later point.

00:55:52.830 --> 00:55:54.610
So I look forward to
chatting with you

00:55:54.610 --> 00:55:55.580
more about this later.

00:55:55.580 --> 00:55:58.980
And on that note, I think we had
probably better wrap up.

00:55:58.980 --> 00:56:00.290
We're a few minutes late.

00:56:00.290 --> 00:56:01.560
Sorry, everyone.

00:56:01.560 --> 00:56:02.950
Yeah, so see you next time.

00:56:02.950 --> 00:56:06.960
And again, we'll get more
of you actually in the

00:56:06.960 --> 00:56:08.240
Hangout next time.

00:56:08.240 --> 00:56:10.510
DANNY HERMES: All righty.

00:56:10.510 --> 00:56:11.720
Thanks, everybody.

00:56:11.720 --> 00:56:12.970
AMY UNRUH: Bye, everyone.

