WEBVTT
Kind: captions
Language: en

00:00:00.320 --> 00:00:03.810
We have covered a fairly large
number of topics in this course.

00:00:03.810 --> 00:00:06.890
You might recall this particular
chart from the first lesson.

00:00:06.890 --> 00:00:09.920
Let us go through each one of
these circles one-by-one and

00:00:09.920 --> 00:00:12.150
see the connections between them.

00:00:12.150 --> 00:00:13.190
So, in the fundamentals,

00:00:13.190 --> 00:00:16.680
we covered knowledge representations
like semantic networks.

00:00:16.680 --> 00:00:20.770
In fact, we used semantic networks to
address two-by-one matrix problems.

00:00:20.770 --> 00:00:23.480
Then we covered a series
of problem solving methods.

00:00:23.480 --> 00:00:26.170
There's already domain independent
journal purpose methods.

00:00:26.170 --> 00:00:30.030
They do not use a lot of knowledge, but
they're very powerful, generate and

00:00:30.030 --> 00:00:33.420
test, means-ends analysis,
and problem reduction.

00:00:33.420 --> 00:00:34.755
Then we turn to production systems.

00:00:34.755 --> 00:00:37.870
They are a specific kind
of cognitive architecture.

00:00:37.870 --> 00:00:42.540
Production systems combine reasoning,
learning, and memory.

00:00:42.540 --> 00:00:44.520
Production systems to
bolster technology for

00:00:44.520 --> 00:00:49.250
developing agents, and
a theory of human computation.

00:00:49.250 --> 00:00:50.840
&gt;&gt; Later we talked about planning.

00:00:50.840 --> 00:00:54.120
And in order to talk about planning we
first proposed a formal language for

00:00:54.120 --> 00:00:54.950
discussing the plan.

00:00:54.950 --> 00:00:56.250
It's called formal logic.

00:00:56.250 --> 00:00:58.830
We learned about the different rules and
syntax used for

00:00:58.830 --> 00:01:00.630
writing formula logical statements.

00:01:00.630 --> 00:01:03.480
And learned why this is very important,
that it allows agents to

00:01:03.480 --> 00:01:07.380
prove the accuracy of their
conclusions based on a set of axioms.

00:01:07.380 --> 00:01:10.360
That gave us a language that we could
then use to talk about planning, and

00:01:10.360 --> 00:01:14.560
as we found out actually, the origins of
planning where an agent's making proofs

00:01:14.560 --> 00:01:17.370
of why a certain set of actions
would lead to a certain goal.

00:01:17.370 --> 00:01:20.480
Here we talked about both partial order
planning and hierarchical planning,

00:01:20.480 --> 00:01:23.430
which are two planning methods that
allow agents to make advanced plans for

00:01:23.430 --> 00:01:24.840
complex tasks.

00:01:24.840 --> 00:01:28.400
And also allows us to reflect on the way
we ourselves plan our actions to complex

00:01:28.400 --> 00:01:28.910
environments.

00:01:29.970 --> 00:01:33.150
&gt;&gt; Under common sense reasoning we
covered several important lessons.

00:01:33.150 --> 00:01:36.153
Frames, understanding,
common sense reasoning and scripts.

00:01:36.153 --> 00:01:42.480
Frames is a structured knowledge to
that allows us to do understanding.

00:01:42.480 --> 00:01:45.270
Understanding is such
a common every day activity.

00:01:45.270 --> 00:01:48.630
We are trying to make sense of
the world, but the world is ambiguous.

00:01:48.630 --> 00:01:52.140
The word, take, for example can have so
many different meanings.

00:01:52.140 --> 00:01:55.240
We saw how frames allow us to
disambiguate different meanings of

00:01:55.240 --> 00:01:56.560
the word take.

00:01:56.560 --> 00:01:59.490
Under common sense reasoning
we made every day intuitive

00:01:59.490 --> 00:02:02.080
inferences about the world around us.

00:02:02.080 --> 00:02:03.700
With understanding and
common sense reasoning,

00:02:03.700 --> 00:02:05.950
we're concerned with
sentence-level understanding.

00:02:05.950 --> 00:02:09.241
Scripts is more concerned about
discourse-level understanding.

00:02:09.241 --> 00:02:10.770
Scripts is an even larger,

00:02:10.770 --> 00:02:13.780
just structure knowledge
presentation than frames.

00:02:13.780 --> 00:02:16.530
It, too allows us to make
sense of the world around us,

00:02:16.530 --> 00:02:19.280
both the physical world and
the social world.

00:02:19.280 --> 00:02:21.610
Frames also came up in some
of the other lessons, and

00:02:21.610 --> 00:02:24.380
particularly came up in
the lesson on production systems,

00:02:24.380 --> 00:02:27.310
when we were trying to
represent episodic knowledge.

00:02:27.310 --> 00:02:30.010
It also came up in the lesson on
configuration, when we were trying to

00:02:30.010 --> 00:02:34.380
represent plans, and the variables of
various plans that can take values.

00:02:34.380 --> 00:02:37.300
&gt;&gt; We talked about learning in many
lessons throughout this course.

00:02:37.300 --> 00:02:40.450
But certain lessons were explicitly and
solely concerned with learning.

00:02:40.450 --> 00:02:43.460
We started off by talking about learning
by recording cases, where an agent could

00:02:43.460 --> 00:02:47.650
build up a case library of its own prior
experiences to use for future reasoning.

00:02:47.650 --> 00:02:49.700
That formed a foundation of
analogical reasoning as well,

00:02:49.700 --> 00:02:51.280
that we'll talk about in a second.

00:02:51.280 --> 00:02:53.100
We also talked about incremental
concept learning and

00:02:53.100 --> 00:02:55.310
version spaces,
two different learning methods for

00:02:55.310 --> 00:02:58.830
learning about information that's
coming in incrementally, or bit by bit.

00:02:58.830 --> 00:03:01.640
That was one of our foundational
principles of this class that we

00:03:01.640 --> 00:03:04.650
discussed at the beginning and
that we'll revisit in a few minutes.

00:03:04.650 --> 00:03:06.880
We also talked about
classification under learning,

00:03:06.880 --> 00:03:09.660
which is one of the most
ubiquitous problems in AI.

00:03:09.660 --> 00:03:12.680
We talked about how classification
involves grouping large combinations of

00:03:12.680 --> 00:03:16.640
percepts into equivalence classes,
to allow for easier action selection.

00:03:16.640 --> 00:03:18.890
Learning also can open several other
lessons that we did throughout this

00:03:18.890 --> 00:03:23.320
class, including production systems,
key spaced reasoning, explanation based

00:03:23.320 --> 00:03:26.890
learning, analogical reasoning, and
learning about correcting mistakes.

00:03:26.890 --> 00:03:29.440
Metareasoning was also deeply connected
to learning, where we could learn from

00:03:29.440 --> 00:03:33.250
our own experiences by analyzing
our own prior thought processes.

00:03:33.250 --> 00:03:34.120
&gt;&gt; As David just said,

00:03:34.120 --> 00:03:38.090
analogical reasoning is another
major topic connected with learning.

00:03:38.090 --> 00:03:40.140
We talked about learning
by recording cases.

00:03:40.140 --> 00:03:43.100
We are simply assimilating cases
by recording them in a growing

00:03:43.100 --> 00:03:44.530
case library.

00:03:44.530 --> 00:03:47.870
As a new problem comes, we use methods
like nearest neighbor to retrieve

00:03:47.870 --> 00:03:51.590
the closest case, and
it invoked that case with a new problem.

00:03:51.590 --> 00:03:55.210
We talked about case-based reasoning,
in which we not only retrieved the case,

00:03:55.210 --> 00:03:56.470
but we also tweak it, or

00:03:56.470 --> 00:04:00.110
modify it in small ways in
order to achieve a new goal.

00:04:00.110 --> 00:04:01.360
In explanation-based learning,

00:04:01.360 --> 00:04:05.507
we saw how we could connect
instances to kinds of definitions.

00:04:05.507 --> 00:04:10.355
We constructed explanations that
told us how instance is an example

00:04:10.355 --> 00:04:11.277
of a given concept.

00:04:11.277 --> 00:04:15.275
This involved both abstraction and
transfer.

00:04:15.275 --> 00:04:18.269
We also connected explanation-based
learning to creativity.

00:04:18.269 --> 00:04:20.492
Analogical reasoning made
[INAUDIBLE] abstraction and

00:04:20.492 --> 00:04:22.170
transfer even more explicit.

00:04:22.170 --> 00:04:24.760
We talked about cross
analogical transfer for

00:04:24.760 --> 00:04:27.850
example from the solar system
to the atomic structure.

00:04:27.850 --> 00:04:28.905
We saw that when needed,

00:04:28.905 --> 00:04:32.890
rich mental models in order to be
able to do an analogical transfer.

00:04:34.030 --> 00:04:37.170
We concluded the lesson on
analogical reasoning by connecting

00:04:37.170 --> 00:04:40.192
it with analogical design or
design by analogy.

00:04:40.192 --> 00:04:44.310
And analogical reasoning too is
closely connected to creativity.

00:04:44.310 --> 00:04:47.040
&gt;&gt; Our discussion of visuospatial
reasoning started with our unit on

00:04:47.040 --> 00:04:48.700
constraint propagation.

00:04:48.700 --> 00:04:50.710
Constraint propagation
was a very abstract and

00:04:50.710 --> 00:04:54.420
general way of propagating constraints
to make sense of a new situation, and

00:04:54.420 --> 00:04:56.570
it comes up uniquely
in visual reasoning.

00:04:56.570 --> 00:05:00.130
Or we use line labeling to make
sense of 3D scenes even if they're

00:05:00.130 --> 00:05:01.510
presented in 2D.

00:05:01.510 --> 00:05:04.470
Where we use line labeling to make sense
of three dimensional scenes even if

00:05:04.470 --> 00:05:06.840
they're presented in
only two dimensions.

00:05:06.840 --> 00:05:08.800
We also how constraint
propagation can be used for

00:05:08.800 --> 00:05:10.500
natural language understanding.

00:05:10.500 --> 00:05:13.070
And we referenced how we might
also use it to understand music or

00:05:13.070 --> 00:05:14.590
tactile information.

00:05:14.590 --> 00:05:17.310
Then in visuospatial reasoning
we expanded on these notions to

00:05:17.310 --> 00:05:19.990
discuss whether it would be
possible to reason about the world

00:05:19.990 --> 00:05:22.080
without extracting propositions.

00:05:22.080 --> 00:05:24.650
This involved looking at scenes in
the world where there was no explicit

00:05:24.650 --> 00:05:26.990
causality, like a glass that's
been spilled on the table.

00:05:26.990 --> 00:05:28.250
We can infer what happened,

00:05:28.250 --> 00:05:31.880
but there's nothing in the visual scene
that tells us exactly how it arose.

00:05:31.880 --> 00:05:34.510
Similarly, we also discuss how this
could apply to other modalities,

00:05:34.510 --> 00:05:37.400
like tactile information or
musical information.

00:05:37.400 --> 00:05:41.400
&gt;&gt; In the unit on design and creativity,
we considered lessons in configuration,

00:05:41.400 --> 00:05:44.440
diagnosis, design and creativity.

00:05:44.440 --> 00:05:48.730
You may recall that in configuration,
we were worried about very routine,

00:05:48.730 --> 00:05:52.140
everyday kind of designs, and
we did that kind of design

00:05:52.140 --> 00:05:56.200
by having a library of clients at
different levels of abstraction.

00:05:56.200 --> 00:06:00.260
We selected a plan at a high level of
abstraction, assign values to some of

00:06:00.260 --> 00:06:04.360
the variables, and then refine the plan
at the next door level abstraction.

00:06:04.360 --> 00:06:05.810
All the components were known,

00:06:05.810 --> 00:06:09.380
we had to decide on the arrangement
of the components of configuration.

00:06:09.380 --> 00:06:13.050
In diagnosis, we were given data
about a malfunctioning system and

00:06:13.050 --> 00:06:16.980
we had to identify the fault
responsible for that malfunctioning.

00:06:16.980 --> 00:06:20.950
We took two views of diagnosis,
classification and abduction.

00:06:20.950 --> 00:06:24.110
In the classification view,
this data was mapped into

00:06:24.110 --> 00:06:28.160
equal classes that acted like
hypotheses for this data.

00:06:28.160 --> 00:06:32.150
In abduction, we composed this
elementary hypothesis into a composite

00:06:32.150 --> 00:06:36.010
hypothesis that could best
explain the entire data.

00:06:36.010 --> 00:06:39.731
Design thinking refers to thinking
about problems that are ill-defined and

00:06:39.731 --> 00:06:42.110
open-ended, and under-constrained.

00:06:42.110 --> 00:06:45.130
In design thinking, the problem and
solution often co-evolve.

00:06:45.130 --> 00:06:46.480
The problem doesn't remain fixed.

00:06:46.480 --> 00:06:47.980
The solution evolves, but

00:06:47.980 --> 00:06:51.280
that in turns it leads to improving
the understanding of the problem,

00:06:51.280 --> 00:06:55.090
both our understanding of the problem
and solution evolve together.

00:06:55.090 --> 00:06:58.930
We cut across creativity in
terms of novelty, value, and

00:06:58.930 --> 00:07:02.120
the non-obviousness of the results.

00:07:02.120 --> 00:07:05.810
We discuss the criteria under which we
would consider an agent to be creative.

00:07:05.810 --> 00:07:09.626
And we saw how many of the techniques
that you have learned in this particular

00:07:09.626 --> 00:07:13.150
class can compose the fundamental
processes of creativity.

00:07:13.150 --> 00:07:17.250
Like analogical reasoning, like visual
special reasoning, like meta-reasoning.

00:07:17.250 --> 00:07:20.081
&gt;&gt; Then we close the class by
talking about meta-cognition.

00:07:20.081 --> 00:07:23.440
Meta-cognition enable the agents to
reason about their own reasoning, or

00:07:23.440 --> 00:07:26.870
think about their own thinking, or have
knowledge of their own knowledge base.

00:07:26.870 --> 00:07:29.350
We started out by talking about
learning by correcting mistakes.

00:07:29.350 --> 00:07:31.800
Or an agent can look at a mistake
that's been made in the past,

00:07:31.800 --> 00:07:34.290
isolate the mistake,
explain the mistake and

00:07:34.290 --> 00:07:36.710
then fix the mistake so
that it didn't happen again.

00:07:36.710 --> 00:07:40.305
This was one narrow instance of
the broader idea of meta-reasoning.

00:07:40.305 --> 00:07:43.735
In meta-reasoning, we talked about
metacognition could bring together many

00:07:43.735 --> 00:07:46.040
of the different methods that we
talked about throughout this class.

00:07:46.040 --> 00:07:49.305
Meta-reasoning enabled an agent to
look at a new problem and select

00:07:49.305 --> 00:07:53.001
which of its many strategies would
be best for addressing that problem.

00:07:53.001 --> 00:07:55.735
It also would allow an agent to
integrate multiple different methods of

00:07:55.735 --> 00:07:57.830
reasoning at different
levels of distraction.

00:07:57.830 --> 00:08:00.950
We also talked about what how
meta-reasoning operates is also the way

00:08:00.950 --> 00:08:02.534
in which meta-reasoning operates.

00:08:02.534 --> 00:08:05.470
Meta-reasoning can reason
about case based reasoning, or

00:08:05.470 --> 00:08:07.580
it can reason using
case based reasoning.

00:08:07.580 --> 00:08:11.640
It could, for example, use production
rules to conduct case based reasoning.

00:08:11.640 --> 00:08:14.160
In this way it could integrate
many different methods

00:08:14.160 --> 00:08:16.370
at many different levels of instruction.

00:08:16.370 --> 00:08:19.750
Finally, this set up a notion of
ethics in artificial intelligence.

00:08:19.750 --> 00:08:21.820
As we're building AI agents
that are starting to have real,

00:08:21.820 --> 00:08:24.650
human level intelligence,
what are the ethical issues?

00:08:24.650 --> 00:08:27.910
What should we think about replacing
certain human jobs with robots,

00:08:27.910 --> 00:08:30.420
or what should we think about developing
robots that can interact with us on

00:08:30.420 --> 00:08:32.400
an everyday basis in the natural world?

00:08:32.400 --> 00:08:36.830
Under what conditions would we consider
these agents to actually be human-like?

00:08:36.830 --> 00:08:39.549
&gt;&gt; This summarizes 30 topics
that we covered in this class,

00:08:39.549 --> 00:08:40.140
which is quite a lot.

00:08:41.230 --> 00:08:44.420
Of course, there is a lot more to
talk about each of these 30 topics

00:08:44.420 --> 00:08:46.445
than we have covered so far.

00:08:46.445 --> 00:08:49.925
Therefore we have provided readings for
each of the topics.

00:08:49.925 --> 00:08:51.655
And you are welcome to
pursue the readings for

00:08:51.655 --> 00:08:54.495
whatever topic that
interests you the most.

00:08:54.495 --> 00:08:57.155
We would also love to hear about
your views about this on the forum.

