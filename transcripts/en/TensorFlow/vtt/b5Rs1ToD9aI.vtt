WEBVTT
Kind: captions
Language: en

00:00:00.016 --> 00:00:06.914
♪ (upbeat music) ♪

00:00:08.895 --> 00:00:10.823
Good morning everyone, I'm Alina,

00:00:10.824 --> 00:00:12.737
program manager for <i>TensorFlow</i>.

00:00:14.492 --> 00:00:15.492
(applause)

00:00:15.493 --> 00:00:16.588
Thank you.

00:00:17.461 --> 00:00:20.738
Welcome to the <i>2019
TensorFlow Developer Summit</i>.

00:00:20.929 --> 00:00:24.333
This is our third annual and
largest developer summit to date,

00:00:24.334 --> 00:00:26.338
and I'm so happy to have
all of you here

00:00:26.339 --> 00:00:28.600
both right here in the room
and on the Livestream.

00:00:28.601 --> 00:00:29.623
Welcome.

00:00:29.624 --> 00:00:31.430
So I'm just curious
by a show of hands,

00:00:31.431 --> 00:00:35.095
who traveled a little bit further,
maybe, to get here?

00:00:35.096 --> 00:00:36.096
Europe?

00:00:37.667 --> 00:00:38.738
Asia?

00:00:39.788 --> 00:00:40.788
Africa?

00:00:41.309 --> 00:00:43.317
As far as Australia?

00:00:43.635 --> 00:00:45.205
Woo, awesome.

00:00:45.206 --> 00:00:47.706
Welcome to all of you.

00:00:48.297 --> 00:00:52.366
We have a lot of great talks ahead,
some exciting announcements

00:00:52.367 --> 00:00:54.208
and cool demos, so let's get going.

00:00:56.089 --> 00:00:59.090
We are living in a formative moment
of history right now,

00:00:59.350 --> 00:01:02.834
where machine learning is experiencing
an unprecedented revolution.

00:01:03.079 --> 00:01:07.214
The way we fundamentally think about
and interact with computer systems

00:01:07.215 --> 00:01:08.937
has inherently changed

00:01:08.938 --> 00:01:11.794
due to the breakthroughs
in the field of AI.

00:01:11.795 --> 00:01:13.937
and this is due to three major factors.

00:01:15.366 --> 00:01:20.865
First, we have lots more compute
specially designed <i>ML accelerator</i>

00:01:20.866 --> 00:01:22.646
like these TPUs,

00:01:22.647 --> 00:01:25.702
let you train models faster
than ever before.

00:01:28.439 --> 00:01:32.415
Secondly, we have breakthroughs
in the field of machine learning.

00:01:32.678 --> 00:01:34.988
Their novel algorithms
created every month

00:01:34.989 --> 00:01:39.215
like a <i>BERT</i> and an innovative approach
to natural language processing

00:01:39.463 --> 00:01:41.144
which lets anyone around the world

00:01:41.145 --> 00:01:44.533
train their own state-of-the-art
question-answering system.

00:01:46.461 --> 00:01:48.755
And finally, we have lots
and lots of data.

00:01:49.991 --> 00:01:54.777
We're seeing new waves of data sets
come from all kinds of disciplines.

00:01:54.781 --> 00:01:59.366
For example, the new
open images extended data set.

00:01:59.367 --> 00:02:04.904
This is a collection
of over 478,000 images

00:02:04.905 --> 00:02:08.429
that volunteers have added

00:02:08.430 --> 00:02:10.920
with the pursuit
of inclusivity and diversity.

00:02:12.992 --> 00:02:16.302
So, all three of these
are basically changing

00:02:16.303 --> 00:02:19.576
how we solve challenging,
real-world problems,

00:02:19.577 --> 00:02:23.262
and it's really cool to see
that <i>TensorFlow</i> is the platform

00:02:23.263 --> 00:02:26.350
that's powering
this machine learning revolution.

00:02:27.390 --> 00:02:31.889
It's allowing developers, businesses
and researchers around the world

00:02:31.890 --> 00:02:34.564
to benefit from intelligent applications.

00:02:34.565 --> 00:02:35.568
And we've been really amazed

00:02:35.568 --> 00:02:38.515
by what the community
has built with <i>TensorFlow</i>.

00:02:40.434 --> 00:02:43.798
Developers have been
using <i>TensorFlow</i> to solve problems

00:02:43.799 --> 00:02:46.880
in in their local communities.

00:02:46.881 --> 00:02:49.777
So I don't know if any of you
were in the Bay Area

00:02:49.778 --> 00:02:51.651
during the tragic Paradise fire,

00:02:51.938 --> 00:02:53.517
but one of the consequences was

00:02:53.518 --> 00:02:55.827
that air quality was really bad.

00:02:55.828 --> 00:03:01.897
It was in the high to mid to 200s
on the Air Quality Index.

00:03:02.153 --> 00:03:08.103
And as difficult as this was for
us in Delhi, India during winter.

00:03:08.634 --> 00:03:14.710
The air quality can get up to about 
the 400s on Air Quality Index,

00:03:15.277 --> 00:03:17.586
and this is considered very dangerous.

00:03:17.587 --> 00:03:20.839
So pollution sensors
can help gauge air quality

00:03:20.840 --> 00:03:23.950
but they're very expensive
to deploy at scale.

00:03:24.284 --> 00:03:29.521
So a group of students in Delhi
built image classifiers in <i>TensorFlow</i>

00:03:29.522 --> 00:03:35.094
and use those to build an app
called <i>Air Cognizer</i>,

00:03:35.094 --> 00:03:39.857
and what it does is basically just
by using the images on a smartphone

00:03:40.678 --> 00:03:44.424
it gives an accurate
estimation of the air quality.

00:03:46.736 --> 00:03:48.622
Businesses are also fundamentally

00:03:48.623 --> 00:03:51.934
improving their products and
services built with <i>TensorFlow</i>,

00:03:51.934 --> 00:03:56.380
for example, Twitter strives
to keep its global users informed

00:03:56.381 --> 00:03:59.150
with relevant and healthy content.

00:03:59.151 --> 00:04:00.293
But this can be hard,

00:04:00.294 --> 00:04:03.731
when the users follow hundreds
or even thousands of people,

00:04:03.732 --> 00:04:08.051
so to solve this, Twitter launched
ranked timeline, an ML power feed

00:04:08.052 --> 00:04:11.066
which has the most relevant tweets
at the top of the time timeline,

00:04:11.067 --> 00:04:14.115
ensuring users never missed their
best and most relevant content.

00:04:14.116 --> 00:04:16.666
And by using <i>TensorFlow's</i>
ecosystem of tools

00:04:16.668 --> 00:04:19.079
like <i>TensorFlow Hub</i>, <i>TensorBoard</i>

00:04:19.081 --> 00:04:21.279
and <i>TensorFlow Model Analysis,</i>

00:04:21.279 --> 00:04:25.579
Twitter was able to reduce
both training and model iteration time

00:04:26.500 --> 00:04:30.679
as well as increase the timeline
quality and engagement for users.

00:04:32.350 --> 00:04:36.876
Specific industries are also
being very much transformed by ML.

00:04:36.877 --> 00:04:38.591
<i>GE Healthcare</i>, for example

00:04:38.592 --> 00:04:41.281
is using <i>TensorFlow</i>
to improve MRI imaging.

00:04:41.282 --> 00:04:45.823
These <i>TensorFlow</i> models,
they're real-time on MRI scanners

00:04:45.832 --> 00:04:50.109
and can actually detect the orientation
of the patient inside the scanner.

00:04:50.110 --> 00:04:52.288
And this is really great

00:04:52.288 --> 00:04:55.355
because not only does this
help the diagnosis,

00:04:55.356 --> 00:05:00.246
but also lowers the errors
and exam time.

00:05:00.247 --> 00:05:05.935
But also, what's really cool is
it basically expands this technology

00:05:05.936 --> 00:05:08.341
to many many more people around the world.

00:05:10.930 --> 00:05:13.412
<i>TensorFlow</i> also powers
bleeding-edge research.

00:05:13.413 --> 00:05:16.837
A team of scientists, researchers
and engineers

00:05:16.837 --> 00:05:20.424
at nurse Oak Ridge National Laboratory
at VIDYA

00:05:20.425 --> 00:05:22.518
recently won the Gordon Bell Prize

00:05:22.519 --> 00:05:24.692
for applying <i>deeplearning</i>

00:05:24.693 --> 00:05:29.087
to study the effects
of extreme weather patterns

00:05:29.088 --> 00:05:31.890
using high-performance computing.

00:05:31.890 --> 00:05:36.634
They built and scaled a neural
network using <i>TensorFlow</i>,

00:05:36.635 --> 00:05:40.858
of course, to a run on <i>Summit</i>,
the world's fastest supercomputer.

00:05:40.858 --> 00:05:42.608
They achieved a peak
and sustained throughput

00:05:42.609 --> 00:05:45.886
of 1.13 exaFLOPS and FPC-16

00:05:45.887 --> 00:05:49.283
which is equivalent to more than
a quantalian computations per second.

00:05:49.598 --> 00:05:52.939
I think I need to pause for a second
because that is ridiculously fast.

00:05:53.451 --> 00:05:54.745
Right?

00:05:56.933 --> 00:05:59.226
In addition to these awesome examples,

00:05:59.227 --> 00:06:02.007
there are thousands and thousands
of people all over the world

00:06:02.008 --> 00:06:04.508
doing amazing work using <i>TensorFlow</i>,

00:06:04.509 --> 00:06:07.469
and the power and impact
of <i>TensorFlow</i> would not be what it is

00:06:07.470 --> 00:06:09.374
without all of you, thank you.

00:06:10.106 --> 00:06:13.280
It's with your help and interest

00:06:13.281 --> 00:06:17.332
that <i>TensorFlow</i> has become the most
widely adopted ML framework in the world.

00:06:17.658 --> 00:06:21.665
And right here, I'd like to
show the latest map of <i>GitHub</i> stars

00:06:21.666 --> 00:06:24.350
who self-identified their location.

00:06:24.590 --> 00:06:26.915
I'm sure many of the dots
on this map are right here

00:06:26.916 --> 00:06:28.638
in the room and on the Livestream,

00:06:28.639 --> 00:06:30.726
so I just want to say
thank you one more time.

00:06:33.108 --> 00:06:35.124
And this growth
has been absolutely amazing.

00:06:35.125 --> 00:06:39.760
<i>TensorFlow</i> has been downloaded
over 41 million times,

00:06:39.761 --> 00:06:43.007
and has over 1800 contributors worldwide.

00:06:45.214 --> 00:06:48.610
Last November, we celebrated
<i>TensorFlow</i>'s third birthday

00:06:48.611 --> 00:06:51.132
by taking a look back
at the different components

00:06:51.133 --> 00:06:53.757
that we've added throughout the years.

00:06:53.758 --> 00:06:55.189
But today, we'd like to talk

00:06:55.190 --> 00:06:57.593
about how <i>TensorFlow</i>
has matured as a platform

00:06:57.594 --> 00:06:59.894
to become an entire
end-to-end ecosystem.

00:07:00.180 --> 00:07:03.584
And <i>TensorFlow 2.0</i> is
the start of a new era,

00:07:03.585 --> 00:07:05.702
and we're committed 
and focused on making it

00:07:05.702 --> 00:07:08.970
the best <i>ML</i> platform for all our users.

00:07:08.970 --> 00:07:11.051
To talk more about <i>TensorFlow 2.0</i>

00:07:11.052 --> 00:07:12.728
I'd like to introduce Rajat Monga,

00:07:12.729 --> 00:07:15.301
Engineering Director
of <i>TensorFlow</i> on stage.

00:07:16.657 --> 00:07:17.657
Thank you.

00:07:17.658 --> 00:07:19.959
(applause)

00:07:22.276 --> 00:07:23.482
Thank You, Alina.

00:07:24.518 --> 00:07:26.367
Hello, everyone, I'm Rajat.

00:07:26.645 --> 00:07:28.169
I am an engineer at <i>TensorFlow</i>

00:07:28.170 --> 00:07:30.725
and have been involved
with this since the very beginning.

00:07:31.233 --> 00:07:34.122
It's been great to see
what we've been up to

00:07:34.123 --> 00:07:35.400
over the last few years.

00:07:35.401 --> 00:07:36.464
All the amazing growth

00:07:36.465 --> 00:07:38.567
and all the amazing things
that you've done with it.

00:07:40.963 --> 00:07:43.377
It's also been great to hear from you.

00:07:43.377 --> 00:07:45.477
You told us what you like about <i>TensorFlow</i>

00:07:45.477 --> 00:07:47.746
and equally importantly,
what you would like to see improved

00:07:47.747 --> 00:07:48.857
in <i>TensorFlow</i>.

00:07:48.858 --> 00:07:50.522
Your feedback has been loud and clear.

00:07:51.800 --> 00:07:55.744
You asked for simpler, more intuitive
APIs in developer experiences.

00:07:56.184 --> 00:07:58.628
You pointed out areas
of redundancy and complexity,

00:07:59.436 --> 00:08:01.943
and you asked for better
documentation and examples,

00:08:03.993 --> 00:08:07.080
and this is exactly what we've been
focusing on with <i>TensorFlow 2.0.</i>

00:08:08.194 --> 00:08:10.218
To make it easy, we focused on <i>Keras</i>

00:08:10.219 --> 00:08:11.787
for a single set of API's

00:08:12.105 --> 00:08:14.978
and combine it with <i>Eager Execution</i>
for the simplicity of <i>Python</i>.

00:08:16.009 --> 00:08:18.525
With flexibility to try the craziest ideas

00:08:18.858 --> 00:08:20.525
and ability to go beyond an <i>exaFLOP</i>

00:08:21.025 --> 00:08:22.676
<i>TensorFlow</i> is more powerful than ever.

00:08:23.785 --> 00:08:26.339
With the same robustness
and performance

00:08:26.339 --> 00:08:28.872
you expect in production,
battle-tested in Google.

00:08:31.793 --> 00:08:34.087
Let's start with the overall
architecture for <i>TensorFlow</i>.

00:08:34.765 --> 00:08:36.861
You may be familiar
with this high-level architecture.

00:08:37.445 --> 00:08:39.563
There have been lots
of components and features

00:08:39.563 --> 00:08:41.421
we've added throughout the years

00:08:41.422 --> 00:08:44.445
to help support workloads
to go from training to deployment.

00:08:45.231 --> 00:08:47.467
With <i>TensorFlow</i> 2.0,
we're really making sure

00:08:47.467 --> 00:08:49.525
that these components
work better together.

00:08:52.031 --> 00:08:54.888
Here's how these powerful
API components fit together

00:08:54.889 --> 00:08:56.284
for the entire training workflow.

00:08:56.881 --> 00:08:59.540
With <i>tf.data</i> for data
ingestion and transformation,

00:09:00.210 --> 00:09:02.829
<i>keras</i> and <i>premade estimators</i>
from model building,

00:09:03.682 --> 00:09:05.825
training with <i>eager execution</i> and <i>graphs</i>,

00:09:06.011 --> 00:09:09.138
and finally packaging
for deployment with <i>SavedModel</i>.

00:09:12.298 --> 00:09:13.830
Let's take a look at some examples.

00:09:15.163 --> 00:09:16.528
The first thing you need is data.

00:09:16.959 --> 00:09:19.943
Often, you may want
to validate results or test your new ideas

00:09:19.944 --> 00:09:21.594
in common public data set.

00:09:22.793 --> 00:09:24.086
<i>TensorFlow</i> data sets includes

00:09:24.087 --> 00:09:27.149
a large and rapidly growing
collection of public data sets

00:09:27.150 --> 00:09:28.957
that you can get started with very easily.

00:09:29.751 --> 00:09:30.988
And combined with <i>tf.data</i>,

00:09:30.988 --> 00:09:33.124
it is simple to wrap your own data too.

00:09:35.525 --> 00:09:38.033
Here is a small sample
of the data sets that are available,

00:09:38.034 --> 00:09:40.345
and all of these
and many more are included there.

00:09:44.277 --> 00:09:47.356
Then with <i>keras</i>,
you can express the model with layers,

00:09:47.357 --> 00:09:49.341
just as you are used to thinking about it.

00:09:50.064 --> 00:09:52.930
Standard training and evaluation
is packaged as well,

00:09:52.931 --> 00:09:54.910
with <i>model.fit</i> and <i>.evaluate</i>.

00:09:58.931 --> 00:10:01.891
Since deep learning models
are often computationally expensive,

00:10:02.284 --> 00:10:04.936
you may want to try scaling this
across more than one device.

00:10:05.748 --> 00:10:07.930
<i>TensorFlow</i> comes pre-built
with <i>MirroredStrategy</i>

00:10:07.931 --> 00:10:10.074
that works with small additions 
to your code.

00:10:14.861 --> 00:10:17.422
Starting from a pre-trained model 
or component

00:10:17.422 --> 00:10:20.554
also works well to reduce some
of this computational cost.

00:10:21.105 --> 00:10:22.247
To make it easy,

00:10:22.248 --> 00:10:25.557
<i>TensorFlow Hub</i> provides a large
collection of pre-trained components

00:10:25.558 --> 00:10:27.136
that you can include in your model

00:10:27.136 --> 00:10:29.614
and even fine tune
for your specific data set.

00:10:33.451 --> 00:10:36.768
<i>Keras</i> and .<i>estimator</i>
offers high-level building blocks

00:10:36.769 --> 00:10:38.356
for an easy-to-use package.

00:10:38.706 --> 00:10:41.435
They come with everything
you might need for typical training jobs.

00:10:43.208 --> 00:10:45.303
But, sometimes you
need a bit more control.

00:10:45.704 --> 00:10:48.172
For example, when you're
exploring new kinds of algorithms.

00:10:51.695 --> 00:10:55.035
Let's say, you wanted to build
a custom encoder for machine translation.

00:10:55.567 --> 00:10:57.638
Here's how you might do this
by subclassing a model.

00:10:58.406 --> 00:10:59.406
Here, you can focus

00:10:59.407 --> 00:11:01.811
on implementing
the computational algorithm,

00:11:01.812 --> 00:11:03.899
and let the framework
take care of the rest.

00:11:05.437 --> 00:11:07.206
And you could even
customize the training loop

00:11:07.207 --> 00:11:11.195
to get full control over the gradients
and the optimization process.

00:11:15.689 --> 00:11:16.895
While training models,

00:11:16.896 --> 00:11:19.522
whether packaged with <i>keras</i>
or more complex ones,

00:11:19.523 --> 00:11:21.948
it's often valuable to
understand the progress,

00:11:22.257 --> 00:11:24.240
and even analyze the model in detail.

00:11:25.145 --> 00:11:28.054
<i>TensorBoard</i> provides
a lot of visualization to help with this,

00:11:28.964 --> 00:11:31.070
and now it comes full integration

00:11:31.070 --> 00:11:33.615
with <i>intercollab</i>
and other <i>Jupiter notebooks</i>,

00:11:33.616 --> 00:11:35.752
allowing you to see
the same visualizations

00:11:35.753 --> 00:11:37.034
right from within your notebook.

00:11:40.271 --> 00:11:42.858
All of these features
are available in <i>TensorFlow 2.0</i>,

00:11:44.904 --> 00:11:47.618
and I'm really excited to announce
that our alpha release is available

00:11:47.619 --> 00:11:48.981
for you as of today.

00:11:50.032 --> 00:11:54.715
(applause)

00:11:56.415 --> 00:11:58.510
Many of you in the room
and across the world

00:11:58.511 --> 00:12:01.963
really helped with lots of work
in testing to make this possible.

00:12:02.510 --> 00:12:05.281
I really like to take this moment 
to thank you all.

00:12:05.281 --> 00:12:07.405
Please give yourself a round of applause.

00:12:07.406 --> 00:12:09.082
We really couldn't
have done this without you.

00:12:09.083 --> 00:12:11.698
(applause)

00:12:17.151 --> 00:12:19.920
In addition to all the great
improvements we talked about,

00:12:19.921 --> 00:12:21.557
this release comes
with a <i>Conversion Script</i>

00:12:21.558 --> 00:12:23.599
to help you upgrade from 1.X.,

00:12:23.599 --> 00:12:27.120
and a compatibility module
to give you access to 1.X. APIs

00:12:27.121 --> 00:12:28.484
for easy transition,

00:12:30.075 --> 00:12:33.075
and we are working towards the full release
over the next quarter.

00:12:36.861 --> 00:12:39.615
There's a lot of work going
on to make <i>TensorFlow 2.0</i>

00:12:39.616 --> 00:12:41.263
really work well for you.

00:12:41.263 --> 00:12:43.499
You can track the progress
and provide feedback

00:12:43.500 --> 00:12:45.229
on the <i>TensorFlow GitHub</i> projects page.

00:12:51.109 --> 00:12:52.767
You asked for better documentation

00:12:52.768 --> 00:12:57.159
and we worked to streamline our docks
for APIs, guides and tutorials.

00:13:00.939 --> 00:13:02.838
All of this material
will be available today

00:13:02.838 --> 00:13:05.415
on the newly redesigned
<i>TensorFlow.org</i> website.

00:13:05.726 --> 00:13:09.861
Where you'll find more examples,
documentation and tools to get started.

00:13:10.412 --> 00:13:11.458
We're really very excited

00:13:11.459 --> 00:13:14.047
about these changes and what's to come.

00:13:14.697 --> 00:13:16.815
And to tell you more about
improvements in <i>TensorFlow</i>

00:13:16.816 --> 00:13:18.044
for research and production.

00:13:18.045 --> 00:13:20.644
I'd like to welcome Megan Kacholia
on stage, thank you.

00:13:20.960 --> 00:13:26.086
(applause)

00:13:28.023 --> 00:13:29.157
Thanks, Rajat.

00:13:29.158 --> 00:13:32.158
<i>TensorFlow</i> has always been a platform
for research to production.

00:13:32.425 --> 00:13:34.679
We just saw how <i>TensorFlow</i>,
as high-level APIs,

00:13:34.679 --> 00:13:37.305
make it easy to get started
and build your models.

00:13:37.306 --> 00:13:40.998
Now, let's talk about how it improves
powerful experimentation for researchers,

00:13:40.999 --> 00:13:43.234
and let's you take models
from research and prototyping

00:13:43.235 --> 00:13:44.850
all the way through to production.

00:13:45.876 --> 00:13:48.971
Researchers have been using <i>TensorFlow</i>
for state-of-the-art research.

00:13:48.972 --> 00:13:50.834
We can see it in paper publications,

00:13:50.835 --> 00:13:52.929
which are shown over the past few years 
in this chart.

00:13:54.636 --> 00:13:58.689
But powerful experimentation begins
and really needs flexibility.

00:13:58.690 --> 00:14:01.637
This begins with <i>Eager Execution</i>
with <i>TensorFlow</i>.

00:14:01.637 --> 00:14:06.334
In <i>TensorFlow 2.0</i> by default, every <i>Python</i>
command is immediately executed.

00:14:06.334 --> 00:14:09.008
This means you can write your code
in the style you're used to

00:14:09.009 --> 00:14:10.968
without having to use Session.Run.

00:14:10.968 --> 00:14:13.410
This also makes a big difference
in the realm of debugging.

00:14:14.668 --> 00:14:16.136
As you iterate through with <i>Eager Mode</i>,

00:14:16.137 --> 00:14:19.446
you'll eventually want to distribute
your code onto <i>GPU</i>s, <i>TPU</i>s

00:14:19.447 --> 00:14:21.511
and other hardware or accelerators.

00:14:21.514 --> 00:14:23.340
For this, we've
provided <i>tf.function</i>

00:14:23.341 --> 00:14:26.356
which turns your <i>eager</i> code
into a graph, function by function.

00:14:26.858 --> 00:14:28.350
You get all of the familiar tools

00:14:28.351 --> 00:14:31.208
like <i>Python</i>, <i>control-flow</i>, <i>asserts,</i>
even <i>print</i>

00:14:31.208 --> 00:14:34.802
but can convert to a graph 
anytime you need to,

00:14:34.803 --> 00:14:37.427
including when you're ready
to move your model into production.

00:14:37.817 --> 00:14:40.174
And even with this,
you'll continue to get great debugging.

00:14:41.232 --> 00:14:43.711
Debug ability is great,
not just in <i>Eager</i>,

00:14:43.711 --> 00:14:46.399
but we've made huge improvements
in <i>tf.function</i> and <i>graphs</i> as well.

00:14:46.815 --> 00:14:48.322
In this example shown here,

00:14:48.323 --> 00:14:51.634
we're splitting a <i>tensor</i>
using <i>tf.function</i> which creates a graph,

00:14:51.634 --> 00:14:53.980
but because of the mismatched inputs,
you get an error.

00:14:54.478 --> 00:14:56.698
As you can see,
we now give users the information

00:14:56.698 --> 00:14:59.726
about the file and the line number
where the error occurred in the model

00:14:59.727 --> 00:15:01.328
to help you more quickly
track things down,

00:15:01.329 --> 00:15:02.781
so you can continue <i>iterating</i>.

00:15:03.307 --> 00:15:07.189
We've made the error messages concise,
easy to understand and actionable.

00:15:07.587 --> 00:15:10.289
We hope you enjoy these changes
and they make it much easier for you

00:15:10.289 --> 00:15:12.579
to quickly iterate and progress 
with your models.

00:15:14.336 --> 00:15:16.557
Performance is another area 
we know that researchers

00:15:16.557 --> 00:15:19.576
as well as all users
for that matter, care about,

00:15:19.576 --> 00:15:22.552
and we've continued improving
core performance in <i>TensorFlow</i>.

00:15:22.553 --> 00:15:23.643
Since last year,

00:15:23.644 --> 00:15:27.509
we've sped up training on eight
NVIDIA Tesla V100 by almost double.

00:15:28.251 --> 00:15:30.504
Using a Google Cloud TPU V2,

00:15:30.505 --> 00:15:32.672
we've boosted performance by 1.6x.

00:15:33.092 --> 00:15:34.901
And with Intel MKL Acceleration

00:15:35.103 --> 00:15:37.707
we've got an inference speed up
by almost three times.

00:15:38.127 --> 00:15:41.333
Performance will continue to be
a big focus of <i>TensorFlow 2.0</i>

00:15:41.334 --> 00:15:43.728
and a core part of our
progress to final release.

00:15:45.329 --> 00:15:48.654
<i>TensorFlow</i> also provides
flexibility to enable researchers,

00:15:48.655 --> 00:15:50.312
and this is with many add-on libraries

00:15:50.313 --> 00:15:52.479
that extend and expand <i>TensorFlow</i>

00:15:52.480 --> 00:15:54.273
in new and useful ways.

00:15:54.273 --> 00:15:56.128
Some of these add-on libraries
or extensions

00:15:56.129 --> 00:15:57.468
to make certain problems easier,

00:15:57.469 --> 00:15:59.405
like <i>TF.Text</i> with <i>Unicode</i>

00:15:59.406 --> 00:16:01.047
and the new ragged <i>Tensor</i> type.

00:16:01.416 --> 00:16:03.202
In other cases, it lets us explore

00:16:03.203 --> 00:16:06.258
how we can make machine
learning models fairer and safer

00:16:06.259 --> 00:16:07.441
by a <i>TF Privacy</i>.

00:16:08.039 --> 00:16:11.412
You'll also hear new announcements
on <i>TF-Agents</i> for reinforcement learning,

00:16:11.726 --> 00:16:14.583
and tomorrow, we'll be discussing
the new TF federated library

00:16:14.584 --> 00:16:15.885
for federated learning.

00:16:18.059 --> 00:16:21.125
Deep learning research is also being
applied to real-world applications

00:16:21.126 --> 00:16:22.526
using <i>TensorFlow</i>.

00:16:22.526 --> 00:16:25.117
Here are a few examples
from researchers at Google

00:16:25.118 --> 00:16:27.816
where we see them applying it
to areas like our data centers.

00:16:27.817 --> 00:16:30.310
We're making them more efficient
with AI control system

00:16:30.311 --> 00:16:32.332
that delivers energy savings.

00:16:32.332 --> 00:16:34.923
Our apps like <i>Google Maps</i>,
the one shown in the middle,

00:16:34.923 --> 00:16:37.911
which has a new navigation feature
called <i>global localization</i>.

00:16:38.270 --> 00:16:42.071
It combines visual positioning service, 
street view, and machine learning

00:16:42.072 --> 00:16:44.701
to more accurately identify
position and orientation.

00:16:45.248 --> 00:16:47.224
And devices like the <i>Google Pixel</i>

00:16:47.228 --> 00:16:49.776
that use machine learning
to improve depth estimation

00:16:49.777 --> 00:16:51.571
to create better portrait mode photos

00:16:51.572 --> 00:16:53.108
like the one shown here.

00:16:54.679 --> 00:16:57.250
In order to make these
real-world applications a reality,

00:16:57.251 --> 00:17:00.293
you must be able to take models
from research and prototyping.

00:17:00.293 --> 00:17:02.273
all the way through
to launching and production.

00:17:02.273 --> 00:17:05.093
This has always been a core strength
and focus for <i>TensorFlow</i>.

00:17:05.601 --> 00:17:07.599
Using <i>TensorFlow</i>,
you can deploy your models

00:17:07.601 --> 00:17:10.037
on a number of platforms
like shown here.

00:17:10.037 --> 00:17:11.727
And models end up in a lot of places,

00:17:11.728 --> 00:17:13.686
so we want to make sure
<i>TensorFlow</i> works well

00:17:13.688 --> 00:17:16.483
across all of these
on servers and in cloud,

00:17:16.483 --> 00:17:18.491
on mobile and other Edge devices,

00:17:18.491 --> 00:17:20.675
in browser and <i>JavaScript</i> platforms.

00:17:20.675 --> 00:17:22.381
We have products for each of these:

00:17:22.382 --> 00:17:25.643
<i>TensorFlow Extended</i>,
<i>TensorFlow Lite</i> and <i>TensorFlow.js</i>

00:17:25.644 --> 00:17:27.302
which I'll briefly talk through.

00:17:28.931 --> 00:17:31.255
<i>TensorFlow Extended</i>
is our end-to-end platform

00:17:31.256 --> 00:17:34.078
for managing every stage
of the machine learning lifecycle.

00:17:34.078 --> 00:17:37.232
This spans all the way from ingesting
and transforming your data

00:17:37.233 --> 00:17:39.424
to deploying your
machine learning models at scale.

00:17:39.919 --> 00:17:43.783
In orange shown here, you can see
the libraries of open-sourced so far.

00:17:44.245 --> 00:17:45.555
What this slide alludes to is

00:17:45.556 --> 00:17:47.078
that we're now taking a step further

00:17:47.079 --> 00:17:49.308
and providing components
built from these libraries

00:17:49.309 --> 00:17:51.493
that make up an end-to-end platform.

00:17:51.801 --> 00:17:53.332
And note these
are the same components

00:17:53.333 --> 00:17:54.586
that are used internally

00:17:54.587 --> 00:17:56.118
in thousands of production systems,

00:17:56.119 --> 00:17:58.126
powering Google's
most important products.

00:17:59.638 --> 00:18:01.739
The components are only part of the story.

00:18:01.739 --> 00:18:04.081
2019 is the year
we're putting it all together,

00:18:04.082 --> 00:18:07.058
and providing you with an integrated 
end-to-end platform.

00:18:07.612 --> 00:18:09.509
First, you can bring
your own orchestrator.

00:18:09.766 --> 00:18:13.298
Here, we're showing <i>airflow</i>
or <i>kubeflow</i>, even <i>raw kubernetes</i>,

00:18:13.299 --> 00:18:14.659
whatever you want.

00:18:14.659 --> 00:18:16.473
No matter what orchestrator you choose,

00:18:16.474 --> 00:18:19.446
the <i>TensorFlow</i> extending components
integrate with a meta-data store.

00:18:19.943 --> 00:18:22.287
This store keeps track of all
the component <i>runs</i>,

00:18:22.287 --> 00:18:24.621
the <i>artifacts</i> that went into them

00:18:24.622 --> 00:18:26.810
and the <i>artifacts</i>
that were also produced.

00:18:26.810 --> 00:18:30.090
This enables advanced features
like <i>experiments</i>, <i>experimentation</i>

00:18:30.091 --> 00:18:32.687
and experiment tracking,
model comparison

00:18:32.688 --> 00:18:33.981
and things along those lines

00:18:33.982 --> 00:18:35.564
that I'm sure you'll be excited about

00:18:35.565 --> 00:18:37.763
and will help you
as you iterate through

00:18:37.764 --> 00:18:39.708
and work with your production systems.

00:18:40.102 --> 00:18:43.125
We have an end-to-end talk coming up
later today from Clemens and his team

00:18:43.126 --> 00:18:44.971
in which they'll take you
on a complete tour

00:18:44.972 --> 00:18:47.416
of using <i>TensorFlow Extended</i>
to solve a real problem.

00:18:49.390 --> 00:18:52.354
Moving on, <i>TensorFlow Lite</i> is
our solution for running models

00:18:52.355 --> 00:18:54.061
on mobile and IoT hardware.

00:18:54.064 --> 00:18:57.897
it uses a custom streamline file
format and a stripped-down runtime,

00:18:57.898 --> 00:19:01.068
so you can deploy <i>TensorFlow</i>
models everywhere your users are.

00:19:01.587 --> 00:19:05.277
On-device models can be more
responsive to input than cloud backends,

00:19:05.278 --> 00:19:07.718
and they keep user data
on device for privacy

00:19:07.719 --> 00:19:10.030
which is very important,
especially in this day and age.

00:19:10.336 --> 00:19:13.897
Google and our partners
like IGE in China use <i>TF Lite</i>

00:19:13.898 --> 00:19:15.327
for all kinds of tools,

00:19:15.328 --> 00:19:18.706
including predictive text generation,
video segmentation

00:19:18.707 --> 00:19:20.228
and things like Edge detection.

00:19:21.805 --> 00:19:24.653
But under the hood,
<i>TensorFlow Lite</i> is about performance.

00:19:24.654 --> 00:19:28.174
You can deploy models
to <i>CPU</i>, <i>GPU</i> and even <i>Edge TPUs</i>,

00:19:28.175 --> 00:19:29.917
and expect fast performance,

00:19:29.918 --> 00:19:33.432
and we've been refining since we
launched <i>TensorFlow Lite</i> last year.

00:19:33.433 --> 00:19:36.416
By using the latest quantization
techniques on <i>CPU</i>,

00:19:36.417 --> 00:19:40.191
adding support for <i>OpenGL 3.1</i>
and <i>Metal</i> on <i>GPU</i>s,

00:19:40.192 --> 00:19:42.632
and tuning our performance
on <i>Edge TPU</i>s,

00:19:42.633 --> 00:19:46.326
we're constantly pushing the limits
of what is possible on device,

00:19:46.327 --> 00:19:49.796
and you should can expect even
greater enhancements in the year ahead.

00:19:50.199 --> 00:19:52.842
We'll hear details from Raziel
and his colleagues coming up

00:19:52.843 --> 00:19:54.334
in a little bit this morning.

00:19:56.186 --> 00:19:58.900
<i>Javascript</i> is the number one programming
language in the world

00:19:58.901 --> 00:20:01.281
and until recently hasn't
necessarily benefited

00:20:01.282 --> 00:20:03.353
from all the machine learning
development and tools.

00:20:03.851 --> 00:20:06.270
Last year we released <i>TensorFlow.js</i>,

00:20:06.271 --> 00:20:08.966
a library for training
and deploying machine learning models

00:20:08.967 --> 00:20:11.391
in the browser and on <i>Node.js</i>.

00:20:11.392 --> 00:20:14.350
Since then we've seen huge adoption
in the <i>JavaScript</i> community

00:20:14.351 --> 00:20:18.111
with more than 300,000 downloads
and 100 contributors,

00:20:18.111 --> 00:20:19.403
but we're just at the beginning

00:20:19.404 --> 00:20:22.078
given how big the <i>JavaScript</i>
and web ecosystem is.

00:20:23.562 --> 00:20:26.903
Today we're excited to announce 
<i>TensorFlow.js version 1.0</i>.

00:20:27.229 --> 00:20:29.737
This comes with many
improvements and new features.

00:20:29.932 --> 00:20:34.063
We have a library of <i>off-the-shelf</i> models
for common machine learning problems

00:20:34.064 --> 00:20:36.239
that run both in the
browser and on <i>node</i>.

00:20:36.675 --> 00:20:38.921
We're also adding support
for more platforms

00:20:38.922 --> 00:20:42.046
where <i>JavaScript</i> runs
such as electron desktop apps

00:20:42.047 --> 00:20:44.047
or mobile native platforms.

00:20:44.359 --> 00:20:47.589
and a huge focus in <i>TensorFlow.js 1.0</i>

00:20:47.590 --> 00:20:49.302
is on performance improvements.

00:20:49.302 --> 00:20:51.433
As an example, compared to last year,

00:20:51.434 --> 00:20:54.550
<i>MobileNet inference</i> and
browser is now nine times faster.

00:20:55.148 --> 00:20:57.831
You'll learn more about these advances
in our talk later in the day.

00:20:59.870 --> 00:21:02.402
Another language that we're
really excited about is <i>swift</i>.

00:21:02.794 --> 00:21:04.746
<i>Swift</i> for <i>TensorFlow</i> is reexamining

00:21:04.747 --> 00:21:06.937
what it means for
performance and usability.

00:21:07.290 --> 00:21:10.019
With a new stack built
on top of <i>TensorFlow's</i> core

00:21:10.020 --> 00:21:11.241
and a new programming model

00:21:11.242 --> 00:21:13.640
that intends to bring further usability.

00:21:14.829 --> 00:21:18.655
And today, we're announcing that <i>Swift</i>
for <i>TensorFlow</i> is now at version 0.2.

00:21:19.051 --> 00:21:21.591
It's ready for you to
experiment with, to try out,

00:21:21.596 --> 00:21:24.001
and we're really excited to be
bringing this to the community.

00:21:25.868 --> 00:21:28.415
In addition to telling you
about version 0.2,

00:21:28.416 --> 00:21:31.686
we're also excited to announce
that Jeremy Howard, a <i>fast.ai</i>

00:21:31.687 --> 00:21:34.167
is writing a new <i>course</i>
in Swift for <i>TensorFlow</i>.

00:21:34.480 --> 00:21:37.377
Chris and Brennan will tell you
a lot more about this later today.

00:21:39.534 --> 00:21:41.454
So to recap everything
we've shown you so far.

00:21:41.875 --> 00:21:44.280
<i>TensorFlow</i> has
grown to a full ecosystem

00:21:44.281 --> 00:21:45.731
from research to production,

00:21:45.732 --> 00:21:48.391
from server to mobile
with many languages.

00:21:48.825 --> 00:21:50.792
This growth has been
fueled by our community,

00:21:50.793 --> 00:21:53.114
and honestly would not
have been possible without the community.

00:21:53.720 --> 00:21:57.189
To talk about what we're planning
for you and with you in 2019,

00:21:57.190 --> 00:21:58.593
I'll hand it over to Kemal.

00:21:59.846 --> 00:22:03.425
(applause)

00:22:03.684 --> 00:22:05.351
It's all you.

00:22:05.510 --> 00:22:06.644
(Kemal) Thank you, Megan.

00:22:07.286 --> 00:22:08.817
Hi, my name is Kemal

00:22:08.818 --> 00:22:10.833
and I'm the Product Director
for <i>TensorFlow</i>.

00:22:11.733 --> 00:22:14.464
I'm really excited to be here today 
for this celebration,

00:22:16.216 --> 00:22:18.628
and what we're celebrating
is the most important part

00:22:18.629 --> 00:22:21.059
of what we're building,
and that's the community.

00:22:21.627 --> 00:22:24.333
Personally, I love building 
developer platforms.

00:22:24.334 --> 00:22:26.825
I used to be a developer
as an entrepreneur,

00:22:26.826 --> 00:22:29.167
and now I get to
enable other developers

00:22:29.168 --> 00:22:31.774
by building together a better platform.

00:22:32.810 --> 00:22:34.476
When we started working on <i>2.0</i>,

00:22:34.477 --> 00:22:36.574
we turned to the community,

00:22:36.574 --> 00:22:38.993
we started with the request
for common process,

00:22:38.993 --> 00:22:42.129
consulting with all of you
on important product decisions.

00:22:42.749 --> 00:22:44.521
We received valuable feedback

00:22:44.521 --> 00:22:46.722
and we couldn't have built 2.0 
without you.

00:22:48.324 --> 00:22:50.475
And some of you wanted
to get more involved

00:22:50.476 --> 00:22:53.071
so we created special
interest groups or <i>sigs</i>

00:22:53.501 --> 00:22:56.247
like <i>Networking</i>
or <i>Tensor Board</i> to name a few.

00:22:56.717 --> 00:22:58.939
And <i>sig</i>s are really
a great way for the community

00:22:58.940 --> 00:23:00.748
to build the pieces of <i>TensorFlow</i>

00:23:00.750 --> 00:23:02.371
that they care the most about.

00:23:04.014 --> 00:23:06.228
We also wanted to hear more
about what you were building,

00:23:06.229 --> 00:23:08.342
so we launched a Powered
By <i>TensorFlow</i> campaign.

00:23:08.906 --> 00:23:12.288
And I am going to say we were amazed
by the creativity of the project,

00:23:12.669 --> 00:23:15.939
from biological image analysis,
to custom wearables,

00:23:15.940 --> 00:23:17.545
to chat BOTS.

00:23:18.544 --> 00:23:21.734
So after three years,
our community is really thriving.

00:23:22.101 --> 00:23:26.057
There're almost 70
machine learning <i>GDE</i>s right now.

00:23:26.057 --> 00:23:27.197 line:1%
Around the world,

00:23:27.198 --> 00:23:30.091
1800 contributors on <i>core</i> alone,

00:23:30.092 --> 00:23:32.999
and countless more of you
who are doing amazing work

00:23:33.000 --> 00:23:34.725
to help make <i>TensorFlow</i> successful.

00:23:35.161 --> 00:23:37.542
So on behalf of the whole <i>TensorFlow</i> team

00:23:37.543 --> 00:23:39.113
we want to say a huge thank you.

00:23:40.558 --> 00:23:45.097
(applause)

00:23:45.740 --> 00:23:47.883
So we have big plans for 2019,

00:23:47.884 --> 00:23:49.717
and I would like to make
a few announcements.

00:23:51.336 --> 00:23:53.288
First, as our community grows,

00:23:53.582 --> 00:23:56.216
we welcome people
who are new to machine learning

00:23:56.217 --> 00:23:57.899
and it's really important
to provide them

00:23:57.900 --> 00:23:59.663
with the best educational material,

00:24:00.675 --> 00:24:03.700
so we're excited to announce

00:24:03.700 --> 00:24:05.880
two new online courses.

00:24:05.880 --> 00:24:07.792
One is with <i>deeplearning.ai</i>

00:24:07.793 --> 00:24:09.737
and it's published
in the <i>Coursera</i> platform.

00:24:10.201 --> 00:24:11.566
And the other's with <i>Udacity.</i>

00:24:12.510 --> 00:24:16.590
The first batch of these lessons
is available right now,

00:24:16.590 --> 00:24:20.064
and they provide an awesome introduction
to <i>TensorFlow</i> for developers.

00:24:20.653 --> 00:24:23.557
They require no prior knowledge
to machine learning,

00:24:23.558 --> 00:24:25.740
so I highly encourage you
to check them out.

00:24:27.134 --> 00:24:30.650
Next, if your students
for the very first time,

00:24:30.651 --> 00:24:33.570
you can apply to the
Google Summer of Code program

00:24:33.571 --> 00:24:36.331
and get to work
with the <i>TensorFlow</i> engineering team

00:24:36.332 --> 00:24:37.969
to help build a part of <i>TensorFlow</i>.

00:24:40.788 --> 00:24:43.772
I also talked about the Powered
By <i>TensorFlow</i> campaign.

00:24:44.096 --> 00:24:46.714
We're so excited with the creativity

00:24:46.715 --> 00:24:50.838
that we decided to launch
a 2.0 hackathon on <i>DevPost</i>

00:24:50.839 --> 00:24:53.038
post to let you share
your latest and greatest,

00:24:53.039 --> 00:24:54.777
and win cool prizes.

00:24:55.053 --> 00:24:57.164
So we're really excited to see
what you're going to build.

00:24:59.934 --> 00:25:02.814
Finally, as our ecosystem grows,

00:25:02.815 --> 00:25:04.651
we're now having
a second day at the summit,

00:25:04.652 --> 00:25:07.280
but we really wanted
to do something more.

00:25:08.229 --> 00:25:10.139
We wanted a place where you can share

00:25:10.139 --> 00:25:12.486
what you've been building on <i>TensorFlow</i>,

00:25:12.486 --> 00:25:15.586
so we're excited to announce

00:25:15.586 --> 00:25:17.286
<i>TensorFlow World</i>,

00:25:17.286 --> 00:25:20.976
a week-long conference dedicated
to open-source collaboration.

00:25:21.876 --> 00:25:25.495
This conference will be co-presented
by O'Reilly Media and <i>TensorFlow,</i>

00:25:25.969 --> 00:25:28.144
and will be held
in Santa Clara end of October.

00:25:29.126 --> 00:25:32.935
Our vision is to bring together
the awesome <i>TensorFlow World</i>

00:25:32.936 --> 00:25:35.024
and give a place for folks
to connect with each other.

00:25:36.611 --> 00:25:39.468
So I'd like to invite on stage Gina Blaber

00:25:39.469 --> 00:25:41.548
to say a few words about the conference.

00:25:42.653 --> 00:25:47.661
(applause)

00:25:48.065 --> 00:25:49.545
(Gina) Thank You, Kemal.

00:25:50.537 --> 00:25:52.251
O'Reilly is a learning company

00:25:52.252 --> 00:25:54.886
with a focus
on technology and business.

00:25:55.330 --> 00:25:58.178
We have strong ties
with the open source community

00:25:58.179 --> 00:25:59.428
as many of you know,

00:25:59.429 --> 00:26:02.868
and we have a history
of bringing big ideas to life.

00:26:03.555 --> 00:26:06.864
That's why we're excited
about partnering with <i>TensorFlow</i>

00:26:06.865 --> 00:26:08.089
to create this new event

00:26:08.089 --> 00:26:11.032
that brings machine learning
and AI to the community.

00:26:12.800 --> 00:26:16.498
The event of <i>TensorFlow</i>
happening on October 28 to 31

00:26:16.499 --> 00:26:17.981
in Santa Clara.

00:26:17.989 --> 00:26:21.171
And when I say community,
I mean everyone.

00:26:21.172 --> 00:26:24.444
We want to bring together 
the entire <i>TensorFlow</i> community

00:26:24.445 --> 00:26:26.629
of individuals and teams,

00:26:26.630 --> 00:26:28.230
and enterprises.

00:26:28.231 --> 00:26:30.134
This is the place 
where you'll meet experts

00:26:30.135 --> 00:26:31.429
from around the world,

00:26:31.430 --> 00:26:33.807
the team that actually
creates <i>TensorFlow</i>,

00:26:33.808 --> 00:26:37.538
and the companies and enterprises
that will help you deploy it.

00:26:38.985 --> 00:26:42.875
We have an open <i>CFP</i> right now
on the <i>TensorFlow World</i> site.

00:26:43.339 --> 00:26:47.130
I invite you all to check that out
and send in your proposal soon,

00:26:47.131 --> 00:26:48.861
so your voice is heard at that event.

00:26:49.342 --> 00:26:52.520
We look forward to seeing you 
at <i>TensorFlow World</i> in October.

00:26:52.520 --> 00:26:53.960
Thank you.

00:26:54.175 --> 00:26:58.143
(applause)

00:26:58.452 --> 00:27:00.152
Thank you, Gina. 
This is going to be great.

00:27:00.153 --> 00:27:01.398
Are you guys excited?

00:27:02.401 --> 00:27:03.782
Woo!

00:27:05.026 --> 00:27:07.314
So we have a few calls to action for you.

00:27:07.314 --> 00:27:12.135
Take a course, submit a talk 
to <i>TF World</i>, start hacking in <i>2.0</i>.

00:27:12.136 --> 00:27:15.302
By the way, the grand prizes 
for a hackathon on <i>DevPost</i>,

00:27:15.303 --> 00:27:17.444
will include free tickets
to <i>TensorFlow World</i>.

00:27:19.832 --> 00:27:23.640
You know one thing that I love is 
to hear about these amazing stories

00:27:23.641 --> 00:27:26.798
of people building awesome stuff 
on top of <i>TensorFlow</i>.

00:27:26.978 --> 00:27:30.382
And as a team, we really
believe that AI advances faster

00:27:30.383 --> 00:27:32.625
when people have access to our tools

00:27:32.626 --> 00:27:35.870
and can then apply them 
to the problems that they care about

00:27:35.871 --> 00:27:37.995
in ways that we never really dreamed of.

00:27:38.592 --> 00:27:43.344
And when people can really do that,
some special things happen.

00:27:43.345 --> 00:27:45.725
And I'd like to share 
with you something really special.

00:27:47.490 --> 00:27:49.593
(urban noise)

00:27:51.511 --> 00:27:53.168
<i>Looking at historical documents</i>

00:27:53.169 --> 00:27:55.542
<i>and especially documents 
from the Middle Age period,</i>

00:27:55.543 --> 00:27:58.558
<i>requires a lot of time 
and also a lot of patience.</i>

00:27:59.015 --> 00:28:01.174
♪ (gentle music) ♪

00:28:01.893 --> 00:28:06.459
<i>In the Vatican Archives,
there are 85km of documents</i>

00:28:07.128 --> 00:28:09.405
<i>more or less the length
of the Panama Canal.</i>

00:28:09.874 --> 00:28:12.196
<i>The scriptures written 
in the medieval handwriting</i>

00:28:12.197 --> 00:28:14.418
<i>are different from the ones 
we know nowadays.</i>

00:28:14.555 --> 00:28:18.023
If one day someone ask me
to transcribe and translate

00:28:18.024 --> 00:28:20.810
all the documents 
of the Vatican Archive,

00:28:20.811 --> 00:28:22.650
I would tell them 
that they are completely crazy.

00:28:23.053 --> 00:28:25.219
(woman) Looking at this book page by page

00:28:25.220 --> 00:28:28.772
and trying to decipher,
read and transcribe whatever is there

00:28:28.773 --> 00:28:32.375
takes an enormous amount of time.

00:28:32.376 --> 00:28:34.959
It would require an army
of paleographer.

00:28:34.959 --> 00:28:36.504
♪ (upbeat music) ♪

00:28:36.505 --> 00:28:39.689
(woman 2) What I am excited 
the most about machine learning is

00:28:39.690 --> 00:28:42.085
that it enabled us to solve problems

00:28:42.086 --> 00:28:45.910
that up to 10, 15 years ago 
we thought unsolvable.

00:28:45.911 --> 00:28:49.315
(Paolo) "In Codice Ratio" was born 
from this idea of building a software

00:28:49.316 --> 00:28:52.728
that can read and interpret 
what is inside those manuscripts.

00:28:52.980 --> 00:28:55.680
When we started discussing the problem,

00:28:55.689 --> 00:28:58.029
we realized that a solution 
based on neural networks

00:28:58.030 --> 00:28:59.569
was absolutely necessary.

00:29:00.442 --> 00:29:04.022
The choice of <i>TensorFlow</i>
was a natural one.

00:29:04.610 --> 00:29:08.054
(Elena) Before using any kind 
of machine learning module,

00:29:08.055 --> 00:29:09.626
we needed to collect data first.

00:29:09.627 --> 00:29:13.286
You have thousands of images 
of dogs and cats on the Internet,

00:29:13.287 --> 00:29:16.634
but there's very little images 
of ancient manuscripts.

00:29:17.301 --> 00:29:21.569
We build our own custom 
web application for crowd sourcing

00:29:21.570 --> 00:29:25.879
and we involved high school students 
to collect the data.

00:29:26.828 --> 00:29:29.336
I didn't know much 
about machine learning in general,

00:29:29.336 --> 00:29:34.282
but I found it very easy 
to create a <i>TensorFlow</i> environment.

00:29:34.283 --> 00:29:38.259
When we were trying to figure out
which model worked best for us,

00:29:38.260 --> 00:29:39.935
<i>Keras</i> was the best solution.

00:29:39.936 --> 00:29:44.603
The production model runs on 
<i>TensorFlow</i> layers and estimator interface.

00:29:44.604 --> 00:29:47.514
We experimented 
with binary classification

00:29:47.515 --> 00:29:49.285
with fully connected networks,

00:29:49.285 --> 00:29:52.645
and finally we move 
to convolutional neural network

00:29:52.646 --> 00:29:54.497
and multi-class classification.

00:29:54.497 --> 00:29:59.885
In a short time, we were able to develop 
and test the first solutions.

00:30:00.052 --> 00:30:02.663
When it comes to recognizing 
single characters,

00:30:02.664 --> 00:30:05.942
we can get 95% average accuracy.

00:30:06.121 --> 00:30:10.942
(Marco) Being able to access an IT tool
greatly shortens the timing.

00:30:11.276 --> 00:30:14.767
Being able to solve certain abbreviations 
and to understand a text

00:30:14.768 --> 00:30:17.426
in that cryptic writing

00:30:17.427 --> 00:30:19.267
is something exceptional.

00:30:19.268 --> 00:30:22.809
(Serena) This will have an enormous
impact in a short period of time.

00:30:22.810 --> 00:30:26.844
We will have a massive quantity 
of historical information available.

00:30:27.110 --> 00:30:29.705
I just think solving problems is fun.

00:30:29.927 --> 00:30:31.864
It's a game against myself,

00:30:32.167 --> 00:30:34.056
and how good I can do.

00:30:34.277 --> 00:30:37.329
(Marco) The study of history 
is extremely important

00:30:37.329 --> 00:30:39.702
to understand our present

00:30:39.702 --> 00:30:42.671
and to get a perspective on the future.

00:30:46.997 --> 00:30:51.043
(applause)

00:30:51.705 --> 00:30:53.562
This is such a great story.

00:30:53.563 --> 00:30:56.212
I think about the scholars
who wrote these manuscripts.

00:30:57.500 --> 00:31:00.365
They couldn't have been
imagined that centuries later,

00:31:00.366 --> 00:31:03.269
people will be using computers 
to bring back to life their work.

00:31:03.270 --> 00:31:05.777
So we're really lucky 
to have Elena with us today.

00:31:05.778 --> 00:31:07.706
Elena, would you stand?

00:31:08.755 --> 00:31:11.628
(applause)

00:31:16.060 --> 00:31:18.155
Don't miss the talk 
where she will share her story today.

00:31:19.276 --> 00:31:20.763
I really hope you have a great day.

00:31:20.764 --> 00:31:22.551
We have some really awesome things.

00:31:22.551 --> 00:31:24.968
The team and I will be around.

00:31:24.969 --> 00:31:27.536
Please come and say hi,
we want to hear from you,

00:31:27.536 --> 00:31:30.474
and with that, I'm going 
to hand it over to Martin

00:31:30.474 --> 00:31:32.624
who will talk about <i>TensorFlow 2.0</i>.
Thank you.

00:31:32.625 --> 00:31:36.982
♪ (upbeat music) ♪

