WEBVTT
Kind: captions
Language: en

00:00:00.060 --> 00:00:02.629
 
welcome back in this week's you learn to

00:00:02.629 --> 00:00:02.639
welcome back in this week's you learn to
 

00:00:02.639 --> 00:00:05.269
welcome back in this week's you learn to
implement a neural network before diving

00:00:05.269 --> 00:00:05.279
implement a neural network before diving
 

00:00:05.279 --> 00:00:07.460
implement a neural network before diving
into the technical details I wanted in

00:00:07.460 --> 00:00:07.470
into the technical details I wanted in
 

00:00:07.470 --> 00:00:08.870
into the technical details I wanted in
this video to give you a quick overview

00:00:08.870 --> 00:00:08.880
this video to give you a quick overview
 

00:00:08.880 --> 00:00:10.879
this video to give you a quick overview
of what you'll be seeing in this week's

00:00:10.879 --> 00:00:10.889
of what you'll be seeing in this week's
 

00:00:10.889 --> 00:00:13.669
of what you'll be seeing in this week's
videos so if you don't follow all the

00:00:13.669 --> 00:00:13.679
videos so if you don't follow all the
 

00:00:13.679 --> 00:00:15.379
videos so if you don't follow all the
details in this video don't worry about

00:00:15.379 --> 00:00:15.389
details in this video don't worry about
 

00:00:15.389 --> 00:00:17.450
details in this video don't worry about
it we'll delve in the technical details

00:00:17.450 --> 00:00:17.460
it we'll delve in the technical details
 

00:00:17.460 --> 00:00:19.670
it we'll delve in the technical details
in the next few videos but for now let's

00:00:19.670 --> 00:00:19.680
in the next few videos but for now let's
 

00:00:19.680 --> 00:00:21.650
in the next few videos but for now let's
give a quick overview of how you

00:00:21.650 --> 00:00:21.660
give a quick overview of how you
 

00:00:21.660 --> 00:00:24.259
give a quick overview of how you
implement in your network last week we

00:00:24.259 --> 00:00:24.269
implement in your network last week we
 

00:00:24.269 --> 00:00:26.269
implement in your network last week we
had talked about logistic regression and

00:00:26.269 --> 00:00:26.279
had talked about logistic regression and
 

00:00:26.279 --> 00:00:30.290
had talked about logistic regression and
we saw how this model corresponds to the

00:00:30.290 --> 00:00:30.300
we saw how this model corresponds to the
 

00:00:30.300 --> 00:00:32.450
we saw how this model corresponds to the
following computation graph where you

00:00:32.450 --> 00:00:32.460
following computation graph where you
 

00:00:32.460 --> 00:00:35.330
following computation graph where you
didn't put the features X and parameters

00:00:35.330 --> 00:00:35.340
didn't put the features X and parameters
 

00:00:35.340 --> 00:00:38.360
didn't put the features X and parameters
W MB does allows you to compute Z which

00:00:38.360 --> 00:00:38.370
W MB does allows you to compute Z which
 

00:00:38.370 --> 00:00:40.610
W MB does allows you to compute Z which
is then used to compute a and we were

00:00:40.610 --> 00:00:40.620
is then used to compute a and we were
 

00:00:40.620 --> 00:00:44.209
is then used to compute a and we were
using a interchangeably with this output

00:00:44.209 --> 00:00:44.219
using a interchangeably with this output
 

00:00:44.219 --> 00:00:47.209
using a interchangeably with this output
Y hat and then you can compute the loss

00:00:47.209 --> 00:00:47.219
Y hat and then you can compute the loss
 

00:00:47.219 --> 00:00:51.049
Y hat and then you can compute the loss
function l a new network looks like this

00:00:51.049 --> 00:00:51.059
function l a new network looks like this
 

00:00:51.059 --> 00:00:53.540
function l a new network looks like this
and as I already previously alluded you

00:00:53.540 --> 00:00:53.550
and as I already previously alluded you
 

00:00:53.550 --> 00:00:55.220
and as I already previously alluded you
can form a neural network by stacking

00:00:55.220 --> 00:00:55.230
can form a neural network by stacking
 

00:00:55.230 --> 00:00:58.099
can form a neural network by stacking
together a lot of little sigmoid units

00:00:58.099 --> 00:00:58.109
together a lot of little sigmoid units
 

00:00:58.109 --> 00:01:01.670
together a lot of little sigmoid units
whereas previously this node corresponds

00:01:01.670 --> 00:01:01.680
whereas previously this node corresponds
 

00:01:01.680 --> 00:01:04.160
whereas previously this node corresponds
to two steps of calculations the first

00:01:04.160 --> 00:01:04.170
to two steps of calculations the first
 

00:01:04.170 --> 00:01:06.800
to two steps of calculations the first
three compute the Z value second is it

00:01:06.800 --> 00:01:06.810
three compute the Z value second is it
 

00:01:06.810 --> 00:01:09.469
three compute the Z value second is it
computes this a value in this doing

00:01:09.469 --> 00:01:09.479
computes this a value in this doing
 

00:01:09.479 --> 00:01:12.200
computes this a value in this doing
network this stack of notes will

00:01:12.200 --> 00:01:12.210
network this stack of notes will
 

00:01:12.210 --> 00:01:15.710
network this stack of notes will
correspond to a Z like calculation like

00:01:15.710 --> 00:01:15.720
correspond to a Z like calculation like
 

00:01:15.720 --> 00:01:19.280
correspond to a Z like calculation like
this as well as an a like calculation

00:01:19.280 --> 00:01:19.290
this as well as an a like calculation
 

00:01:19.290 --> 00:01:22.280
this as well as an a like calculation
like that and then that node will

00:01:22.280 --> 00:01:22.290
like that and then that node will
 

00:01:22.290 --> 00:01:24.649
like that and then that node will
correspond to another Z and another 8

00:01:24.649 --> 00:01:24.659
correspond to another Z and another 8
 

00:01:24.659 --> 00:01:27.530
correspond to another Z and another 8
like calculation so the notation which

00:01:27.530 --> 00:01:27.540
like calculation so the notation which
 

00:01:27.540 --> 00:01:29.830
like calculation so the notation which
we should use later will look like this

00:01:29.830 --> 00:01:29.840
we should use later will look like this
 

00:01:29.840 --> 00:01:32.749
we should use later will look like this
first what inputs the features X

00:01:32.749 --> 00:01:32.759
first what inputs the features X
 

00:01:32.759 --> 00:01:35.420
first what inputs the features X
together with some parameters W and B

00:01:35.420 --> 00:01:35.430
together with some parameters W and B
 

00:01:35.430 --> 00:01:40.310
together with some parameters W and B
and this will allow you to compute z1 so

00:01:40.310 --> 00:01:40.320
and this will allow you to compute z1 so
 

00:01:40.320 --> 00:01:42.920
and this will allow you to compute z1 so
new notation that one should use is that

00:01:42.920 --> 00:01:42.930
new notation that one should use is that
 

00:01:42.930 --> 00:01:45.590
new notation that one should use is that
we'll use superscript square bracket 1

00:01:45.590 --> 00:01:45.600
we'll use superscript square bracket 1
 

00:01:45.600 --> 00:01:48.679
we'll use superscript square bracket 1
to refer to quantities associated with

00:01:48.679 --> 00:01:48.689
to refer to quantities associated with
 

00:01:48.689 --> 00:01:50.780
to refer to quantities associated with
this stack of node is called a lair and

00:01:50.780 --> 00:01:50.790
this stack of node is called a lair and
 

00:01:50.790 --> 00:01:53.569
this stack of node is called a lair and
then later we'll use superscript square

00:01:53.569 --> 00:01:53.579
then later we'll use superscript square
 

00:01:53.579 --> 00:01:56.270
then later we'll use superscript square
bracket 2 to refer to quantities

00:01:56.270 --> 00:01:56.280
bracket 2 to refer to quantities
 

00:01:56.280 --> 00:01:58.910
bracket 2 to refer to quantities
associated with Daniel really that's

00:01:58.910 --> 00:01:58.920
associated with Daniel really that's
 

00:01:58.920 --> 00:02:01.190
associated with Daniel really that's
called another layer of the network and

00:02:01.190 --> 00:02:01.200
called another layer of the network and
 

00:02:01.200 --> 00:02:04.130
called another layer of the network and
the superscript square brackets like we

00:02:04.130 --> 00:02:04.140
the superscript square brackets like we
 

00:02:04.140 --> 00:02:06.709
the superscript square brackets like we
have here are not to be confused with

00:02:06.709 --> 00:02:06.719
have here are not to be confused with
 

00:02:06.719 --> 00:02:10.309
have here are not to be confused with
the superscript round brackets which we

00:02:10.309 --> 00:02:10.319
the superscript round brackets which we
 

00:02:10.319 --> 00:02:12.380
the superscript round brackets which we
used to refer to individual training

00:02:12.380 --> 00:02:12.390
used to refer to individual training
 

00:02:12.390 --> 00:02:13.510
used to refer to individual training
examples so whereas

00:02:13.510 --> 00:02:13.520
examples so whereas
 

00:02:13.520 --> 00:02:16.300
examples so whereas
X superscript on racket I refer to the

00:02:16.300 --> 00:02:16.310
X superscript on racket I refer to the
 

00:02:16.310 --> 00:02:19.030
X superscript on racket I refer to the
I've trained example superscript square

00:02:19.030 --> 00:02:19.040
I've trained example superscript square
 

00:02:19.040 --> 00:02:21.850
I've trained example superscript square
bracket 1 and 2 refer to these different

00:02:21.850 --> 00:02:21.860
bracket 1 and 2 refer to these different
 

00:02:21.860 --> 00:02:26.230
bracket 1 and 2 refer to these different
um layers layer 1 and layer 2 in this

00:02:26.230 --> 00:02:26.240
um layers layer 1 and layer 2 in this
 

00:02:26.240 --> 00:02:29.290
um layers layer 1 and layer 2 in this
network but they're going on after

00:02:29.290 --> 00:02:29.300
network but they're going on after
 

00:02:29.300 --> 00:02:32.830
network but they're going on after
computing z1 similar to logistic

00:02:32.830 --> 00:02:32.840
computing z1 similar to logistic
 

00:02:32.840 --> 00:02:35.980
computing z1 similar to logistic
regression there'll be a computation to

00:02:35.980 --> 00:02:35.990
regression there'll be a computation to
 

00:02:35.990 --> 00:02:40.000
regression there'll be a computation to
compute a 1 and that's just some sigmoid

00:02:40.000 --> 00:02:40.010
compute a 1 and that's just some sigmoid
 

00:02:40.010 --> 00:02:45.550
compute a 1 and that's just some sigmoid
of z1 and then you compute Z 2 using

00:02:45.550 --> 00:02:45.560
of z1 and then you compute Z 2 using
 

00:02:45.560 --> 00:02:49.720
of z1 and then you compute Z 2 using
another linear equation and then compute

00:02:49.720 --> 00:02:49.730
another linear equation and then compute
 

00:02:49.730 --> 00:02:55.690
another linear equation and then compute
a 2 and a 2 is the final output of the

00:02:55.690 --> 00:02:55.700
a 2 and a 2 is the final output of the
 

00:02:55.700 --> 00:02:57.580
a 2 and a 2 is the final output of the
neural network and will also be used

00:02:57.580 --> 00:02:57.590
neural network and will also be used
 

00:02:57.590 --> 00:02:59.980
neural network and will also be used
interchangeably with Y hat so I know

00:02:59.980 --> 00:02:59.990
interchangeably with Y hat so I know
 

00:02:59.990 --> 00:03:01.600
interchangeably with Y hat so I know
that was a lot of details but the key

00:03:01.600 --> 00:03:01.610
that was a lot of details but the key
 

00:03:01.610 --> 00:03:04.480
that was a lot of details but the key
intuition to take away is that whereas

00:03:04.480 --> 00:03:04.490
intuition to take away is that whereas
 

00:03:04.490 --> 00:03:07.360
intuition to take away is that whereas
for logistic regression we had this Z

00:03:07.360 --> 00:03:07.370
for logistic regression we had this Z
 

00:03:07.370 --> 00:03:10.000
for logistic regression we had this Z
followed by a calculation and this new

00:03:10.000 --> 00:03:10.010
followed by a calculation and this new
 

00:03:10.010 --> 00:03:12.250
followed by a calculation and this new
network here we just do it multiple

00:03:12.250 --> 00:03:12.260
network here we just do it multiple
 

00:03:12.260 --> 00:03:14.710
network here we just do it multiple
times as Z followed by a calculation and

00:03:14.710 --> 00:03:14.720
times as Z followed by a calculation and
 

00:03:14.720 --> 00:03:18.280
times as Z followed by a calculation and
a Z qualifying a calculation and then

00:03:18.280 --> 00:03:18.290
a Z qualifying a calculation and then
 

00:03:18.290 --> 00:03:21.280
a Z qualifying a calculation and then
you finally compute the loss and yet and

00:03:21.280 --> 00:03:21.290
you finally compute the loss and yet and
 

00:03:21.290 --> 00:03:23.620
you finally compute the loss and yet and
you remember that for logistic

00:03:23.620 --> 00:03:23.630
you remember that for logistic
 

00:03:23.630 --> 00:03:25.900
you remember that for logistic
regression we had in some backward

00:03:25.900 --> 00:03:25.910
regression we had in some backward
 

00:03:25.910 --> 00:03:28.870
regression we had in some backward
calculation in order to compute

00:03:28.870 --> 00:03:28.880
calculation in order to compute
 

00:03:28.880 --> 00:03:30.970
calculation in order to compute
derivatives are so confusing

00:03:30.970 --> 00:03:30.980
derivatives are so confusing
 

00:03:30.980 --> 00:03:34.660
derivatives are so confusing
da easy and so on so in the same way a

00:03:34.660 --> 00:03:34.670
da easy and so on so in the same way a
 

00:03:34.670 --> 00:03:37.090
da easy and so on so in the same way a
new network will end up doing a backward

00:03:37.090 --> 00:03:37.100
new network will end up doing a backward
 

00:03:37.100 --> 00:03:40.300
new network will end up doing a backward
calculation that looks like this it will

00:03:40.300 --> 00:03:40.310
calculation that looks like this it will
 

00:03:40.310 --> 00:03:48.400
calculation that looks like this it will
jump you end up computing da 2 DZ 2 that

00:03:48.400 --> 00:03:48.410
jump you end up computing da 2 DZ 2 that
 

00:03:48.410 --> 00:03:49.960
jump you end up computing da 2 DZ 2 that
allows you to compute

00:03:49.960 --> 00:03:49.970
allows you to compute
 

00:03:49.970 --> 00:03:57.250
allows you to compute
DW 2 DB 2 and so on in this sort of a

00:03:57.250 --> 00:03:57.260
DW 2 DB 2 and so on in this sort of a
 

00:03:57.260 --> 00:04:00.610
DW 2 DB 2 and so on in this sort of a
right to left backward calculation that

00:04:00.610 --> 00:04:00.620
right to left backward calculation that
 

00:04:00.620 --> 00:04:04.990
right to left backward calculation that
is denoting with the red arrows so thank

00:04:04.990 --> 00:04:05.000
is denoting with the red arrows so thank
 

00:04:05.000 --> 00:04:05.480
is denoting with the red arrows so thank
you

00:04:05.480 --> 00:04:05.490
you
 

00:04:05.490 --> 00:04:07.970
you
quick overview of what a neural network

00:04:07.970 --> 00:04:07.980
quick overview of what a neural network
 

00:04:07.980 --> 00:04:09.740
quick overview of what a neural network
website space you take the logistic

00:04:09.740 --> 00:04:09.750
website space you take the logistic
 

00:04:09.750 --> 00:04:12.920
website space you take the logistic
regression and repeating it twice I know

00:04:12.920 --> 00:04:12.930
regression and repeating it twice I know
 

00:04:12.930 --> 00:04:14.840
regression and repeating it twice I know
there's a lot of new notation love new

00:04:14.840 --> 00:04:14.850
there's a lot of new notation love new
 

00:04:14.850 --> 00:04:16.850
there's a lot of new notation love new
details don't worry about they didn't

00:04:16.850 --> 00:04:16.860
details don't worry about they didn't
 

00:04:16.860 --> 00:04:18.979
details don't worry about they didn't
follow everything we'll go into the

00:04:18.979 --> 00:04:18.989
follow everything we'll go into the
 

00:04:18.989 --> 00:04:20.870
follow everything we'll go into the
details most slowly in the next few

00:04:20.870 --> 00:04:20.880
details most slowly in the next few
 

00:04:20.880 --> 00:04:22.790
details most slowly in the next few
videos so let's go on to the next video

00:04:22.790 --> 00:04:22.800
videos so let's go on to the next video
 

00:04:22.800 --> 00:04:24.620
videos so let's go on to the next video
we'll stop to talk about the neural

00:04:24.620 --> 00:04:24.630
we'll stop to talk about the neural
 

00:04:24.630 --> 00:04:27.860
we'll stop to talk about the neural
network representation

