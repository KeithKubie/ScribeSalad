WEBVTT
Kind: captions
Language: en

00:00:01.892 --> 00:00:07.422
[APPLAUSE]

00:00:07.422 --> 00:00:09.130
IRIS BOHNET: Thank
you for having me here

00:00:09.130 --> 00:00:12.260
at Google and for
coming to my talk today.

00:00:12.260 --> 00:00:15.160
I'm a fan of many of the
things that you're doing.

00:00:15.160 --> 00:00:19.750
I'm a huge fan, in particular
because the company is

00:00:19.750 --> 00:00:21.670
data-driven in many ways.

00:00:21.670 --> 00:00:24.610
And also in the ways that
I particularly care about.

00:00:24.610 --> 00:00:27.560
In its work on
diversity and inclusion,

00:00:27.560 --> 00:00:30.480
and generally in its
talent management.

00:00:30.480 --> 00:00:32.291
So with that, kind
of, I hope this

00:00:32.291 --> 00:00:33.540
is going to resonate with you.

00:00:33.540 --> 00:00:36.040
What I was trying
to do with the book

00:00:36.040 --> 00:00:38.850
was really bringing
data and evidence

00:00:38.850 --> 00:00:42.290
to bear on a question
on which many people are

00:00:42.290 --> 00:00:43.790
very passionate about.

00:00:43.790 --> 00:00:45.920
And I share that passion.

00:00:45.920 --> 00:00:48.270
But what I'm trying
to argue is that we

00:00:48.270 --> 00:00:50.330
have to bring the
same kind of rigor

00:00:50.330 --> 00:00:52.940
that we use to
analyze unemployment

00:00:52.940 --> 00:00:56.560
or inflation to questions
of gender equality.

00:00:56.560 --> 00:01:00.080
So here's what I want to do.

00:01:00.080 --> 00:01:04.000
I want to start out by kind of
talking a little bit about why

00:01:04.000 --> 00:01:05.475
we might want to care.

00:01:05.475 --> 00:01:08.770
Then I want to talk about
what we're up against.

00:01:08.770 --> 00:01:10.430
And I know you
all or many of you

00:01:10.430 --> 00:01:12.360
have gone through
unconscious bias training,

00:01:12.360 --> 00:01:14.580
so you will be familiar
with much of that.

00:01:14.580 --> 00:01:17.660
And then I want to spend
most of the talk discussing

00:01:17.660 --> 00:01:21.860
how we can redesign our
organizations to level

00:01:21.860 --> 00:01:24.940
the playing field and
making it easier for all

00:01:24.940 --> 00:01:27.170
of us to do the right thing.

00:01:27.170 --> 00:01:29.130
So some of you might
be here because they

00:01:29.130 --> 00:01:32.090
care about this pyramid
here, because you

00:01:32.090 --> 00:01:35.580
care about the absence
of women in leadership.

00:01:35.580 --> 00:01:37.670
And then some
others might be here

00:01:37.670 --> 00:01:41.640
because you care about
even bigger questions.

00:01:41.640 --> 00:01:43.340
And I would actually
suggest to you

00:01:43.340 --> 00:01:47.180
that this slide is a slide that
you should most care about,

00:01:47.180 --> 00:01:49.510
even more so than the pyramid.

00:01:49.510 --> 00:01:53.850
The UN, in fact, now estimates
that about 200 million women

00:01:53.850 --> 00:01:56.540
and girls are missing
because of gendercide.

00:01:56.540 --> 00:02:00.800
Gendercide because of sex
selective abortion or neglect

00:02:00.800 --> 00:02:03.340
in the first five years.

00:02:03.340 --> 00:02:06.030
Now this in itself,
of course, is tragedy.

00:02:06.030 --> 00:02:10.660
But I'm starting with it because
a problem that many thought was

00:02:10.660 --> 00:02:14.330
too difficult to even
address led to some really

00:02:14.330 --> 00:02:16.060
inspiring research.

00:02:16.060 --> 00:02:18.860
A colleague of mine, Rob
Jensen who's now at Wharton,

00:02:18.860 --> 00:02:22.280
went into India and
exploited the fact

00:02:22.280 --> 00:02:25.760
that many call centers had
moved into India in the '90s.

00:02:25.760 --> 00:02:27.810
And they often hired women.

00:02:27.810 --> 00:02:31.750
So what he did was he ran an
experiment, a field experiment,

00:02:31.750 --> 00:02:35.510
where he had treatment villages
and controlled villages.

00:02:35.510 --> 00:02:38.900
And in the treatment
villages, he

00:02:38.900 --> 00:02:41.650
offered service and
training for women

00:02:41.650 --> 00:02:43.910
to go and work in call centers.

00:02:43.910 --> 00:02:47.720
And yes, he was interested
in whether that would affect

00:02:47.720 --> 00:02:49.800
the likelihood that these
women would go and work

00:02:49.800 --> 00:02:50.630
in the call center.

00:02:50.630 --> 00:02:54.430
But more importantly, he was
interested in whether this

00:02:54.430 --> 00:02:57.160
affects how parents
treat their zero

00:02:57.160 --> 00:02:59.090
to five-year-old daughters.

00:02:59.090 --> 00:03:01.430
Do even the poorest
of the poor care

00:03:01.430 --> 00:03:03.400
about returns on investment?

00:03:03.400 --> 00:03:05.660
And that's what he found.

00:03:05.660 --> 00:03:10.320
So he measured survival chances,
he measured body mass index.

00:03:10.320 --> 00:03:11.540
He and his team.

00:03:11.540 --> 00:03:14.500
Of course, he measured
whether these girls then

00:03:14.500 --> 00:03:15.780
would be in school.

00:03:15.780 --> 00:03:19.290
And really try to understand
whether parents started

00:03:19.290 --> 00:03:21.440
to treat their daughters
better when there

00:03:21.440 --> 00:03:24.030
was a future for the daughters.

00:03:24.030 --> 00:03:25.710
And that's what he found.

00:03:25.710 --> 00:03:28.330
It was a long experiment,
over about 10 years.

00:03:28.330 --> 00:03:33.150
And he could show that
economic opportunity actually

00:03:33.150 --> 00:03:36.960
can change how parents think
about the value of having

00:03:36.960 --> 00:03:40.630
daughters without negatively
affecting their sons.

00:03:40.630 --> 00:03:42.850
And I think that's
why we should care.

00:03:42.850 --> 00:03:46.010
We should really care because
for some, this quite literally

00:03:46.010 --> 00:03:48.580
is a matter of life and death.

00:03:48.580 --> 00:03:50.790
But bringing you
back to somebody

00:03:50.790 --> 00:03:52.560
who I think many of you know.

00:03:52.560 --> 00:03:54.110
This is Heidi Roizen.

00:03:54.110 --> 00:03:56.390
If you have gone through
the unconscious bias

00:03:56.390 --> 00:03:59.080
training at Google, you
might have encountered her.

00:03:59.080 --> 00:04:01.740
She is an entrepreneur,
a venture capitalist

00:04:01.740 --> 00:04:06.580
in Silicon Valley, and
she was famous before.

00:04:06.580 --> 00:04:08.560
A case study made
her even more famous.

00:04:08.560 --> 00:04:11.090
And the case study,
in an interesting way,

00:04:11.090 --> 00:04:13.360
made her famous because
some colleagues of ours

00:04:13.360 --> 00:04:17.060
at Columbia Business
School used this case

00:04:17.060 --> 00:04:21.130
to teach their students
about bias in the moment.

00:04:21.130 --> 00:04:24.280
How this is done now
across, really, this country

00:04:24.280 --> 00:04:26.350
and some other schools
around the world

00:04:26.350 --> 00:04:28.270
is that half of
the students would

00:04:28.270 --> 00:04:30.490
get the case of the
protagonist being called

00:04:30.490 --> 00:04:32.660
Howard and the
other half would get

00:04:32.660 --> 00:04:35.810
the case with the protagonist
having her real name, namely

00:04:35.810 --> 00:04:36.755
Heidi.

00:04:36.755 --> 00:04:39.380
And then students read the case,
everything identical, and then

00:04:39.380 --> 00:04:40.670
rate Howard and Heidi.

00:04:40.670 --> 00:04:43.180
And again, you will
have been there

00:04:43.180 --> 00:04:45.100
if you have done the training.

00:04:45.100 --> 00:04:49.800
We generally do think that both
Heidi and Howard do a good job

00:04:49.800 --> 00:04:52.810
and are competent, but
we do not like Heidi

00:04:52.810 --> 00:04:55.340
and do not want to hire
Heidi because Heidi

00:04:55.340 --> 00:04:58.440
violates gender norms.

00:04:58.440 --> 00:05:00.660
That's what we're
up against when

00:05:00.660 --> 00:05:04.790
we try to overcome some
of these patterns that

00:05:04.790 --> 00:05:07.750
affect our thinking.

00:05:07.750 --> 00:05:10.260
But let me ask you to
take a look at the pattern

00:05:10.260 --> 00:05:12.840
here that you see.

00:05:12.840 --> 00:05:16.130
Why don't you compare
squares a and b for me?

00:05:16.130 --> 00:05:19.360
I presume most of
you will see square b

00:05:19.360 --> 00:05:22.650
as being lighter than square a.

00:05:22.650 --> 00:05:25.010
It turns out that
this is an illusion.

00:05:25.010 --> 00:05:26.810
And what I'm going to
do next is I'm going

00:05:26.810 --> 00:05:29.910
to cover the surroundings here.

00:05:29.910 --> 00:05:33.770
And I presume that most
of you now see the squares

00:05:33.770 --> 00:05:35.870
as having the identical color.

00:05:35.870 --> 00:05:38.620
I'm going to go back
just quickly because you

00:05:38.620 --> 00:05:39.744
look at me puzzled.

00:05:42.350 --> 00:05:44.230
So here's what
happened in your minds.

00:05:44.230 --> 00:05:47.370
Your mind made immediately sense
of the pattern that it saw.

00:05:47.370 --> 00:05:49.120
A checkerboard.

00:05:49.120 --> 00:05:51.860
And your mind knows that
the light square has

00:05:51.860 --> 00:05:54.020
to be next to a dark square.

00:05:54.020 --> 00:05:56.110
And you also take
a bit of the shadow

00:05:56.110 --> 00:05:59.400
into account to correct
for that shadow.

00:05:59.400 --> 00:06:03.340
So the question, really, in
front of us is the following.

00:06:03.340 --> 00:06:06.060
What kind of patterns
do we see in the world

00:06:06.060 --> 00:06:12.150
out there which keep
us from seeing square b

00:06:12.150 --> 00:06:13.910
for what it really is?

00:06:13.910 --> 00:06:16.640
Another dark square.

00:06:16.640 --> 00:06:21.190
So some creative interventions
build quite directly on this.

00:06:21.190 --> 00:06:26.070
And you might have
heard of orchestras,

00:06:26.070 --> 00:06:27.690
the larger orchestras
in this country,

00:06:27.690 --> 00:06:29.940
introducing blind auditions.

00:06:29.940 --> 00:06:33.890
In the '70s, many major
orchestras in the United States

00:06:33.890 --> 00:06:36.300
introduced curtains and had
their musicians audition

00:06:36.300 --> 00:06:38.551
behind curtains.

00:06:38.551 --> 00:06:40.490
That increased the
likelihood that women

00:06:40.490 --> 00:06:45.040
would be hired by 50%.

00:06:45.040 --> 00:06:47.790
Or put differently,
blind auditions

00:06:47.790 --> 00:06:49.790
played a huge role in
increasing the fraction

00:06:49.790 --> 00:06:53.060
of female musicians
from 5% to now

00:06:53.060 --> 00:06:57.330
almost 40% on the major
orchestras in this country.

00:06:57.330 --> 00:06:59.920
This is quite different
from the roughly 10%

00:06:59.920 --> 00:07:02.800
female musicians, for
example, in Berlin

00:07:02.800 --> 00:07:07.040
or on the Vienna Symphony.

00:07:07.040 --> 00:07:11.472
So blind auditions
are an attractive tool

00:07:11.472 --> 00:07:13.800
that, in fact,
many organizations

00:07:13.800 --> 00:07:15.890
now increasingly rely on.

00:07:15.890 --> 00:07:18.460
Of course, not in terms
of auditions, but in terms

00:07:18.460 --> 00:07:21.180
of blinding themselves to
demographic characteristics

00:07:21.180 --> 00:07:24.060
of the top applicants.

00:07:24.060 --> 00:07:29.280
But I want to use the blindness
primarily as a metaphor for us.

00:07:29.280 --> 00:07:32.150
Because what we're trying
to do here is really

00:07:32.150 --> 00:07:35.820
learn from these curtains
for other types of design

00:07:35.820 --> 00:07:39.960
interventions which could make
it easier for all of our minds

00:07:39.960 --> 00:07:41.730
to get things right.

00:07:41.730 --> 00:07:44.150
And that's where I
want to take you today.

00:07:44.150 --> 00:07:45.910
In fact, before I
talk about gender,

00:07:45.910 --> 00:07:49.410
I want to leave you with another
metaphor which surely must

00:07:49.410 --> 00:07:51.415
be familiar to many of you.

00:07:51.415 --> 00:07:53.960
Most of you must have
been in a hotel room

00:07:53.960 --> 00:07:58.010
where the room key card did
not only serve the purpose

00:07:58.010 --> 00:08:02.862
to open and close the doors, but
also to turn lights on and off.

00:08:02.862 --> 00:08:04.570
This is another little
bit of technology,

00:08:04.570 --> 00:08:07.230
a little bit of
design which makes

00:08:07.230 --> 00:08:12.080
it easier for all of us who
actually think that we care

00:08:12.080 --> 00:08:16.690
about the environment to follow
through and leave the room when

00:08:16.690 --> 00:08:18.377
the lights are off.

00:08:18.377 --> 00:08:19.460
So that's where I'm going.

00:08:19.460 --> 00:08:22.630
Trying to make it easier for
us to do the right thing.

00:08:22.630 --> 00:08:25.690
And this, of course,
is very, very different

00:08:25.690 --> 00:08:28.940
from other types of things
that we have been doing

00:08:28.940 --> 00:08:30.280
and could be doing.

00:08:30.280 --> 00:08:32.580
It's different from
diversity training.

00:08:32.580 --> 00:08:34.659
Now clearly
diversity training is

00:08:34.659 --> 00:08:37.950
important for raising awareness.

00:08:37.950 --> 00:08:42.110
But as we all know, it is
often hard to follow through.

00:08:42.110 --> 00:08:45.880
Because by definition, these
biases are unconscious.

00:08:45.880 --> 00:08:49.860
And even though I
now realize that I

00:08:49.860 --> 00:08:53.780
will treat the male kindergarten
teacher or the male nurse

00:08:53.780 --> 00:08:57.220
differently from their
stereotypical counterparts who

00:08:57.220 --> 00:09:00.570
happen to be women, I can't
guarantee that tomorrow

00:09:00.570 --> 00:09:03.580
when I see a male nurse,
I will objectively

00:09:03.580 --> 00:09:04.926
evaluate that person.

00:09:04.926 --> 00:09:07.650
Seeing really is believing.

00:09:07.650 --> 00:09:10.790
So diversity
training is a start.

00:09:10.790 --> 00:09:14.550
But I am arguing that to
really advance the needle

00:09:14.550 --> 00:09:19.550
and make a difference, we
have to go deeper and do more.

00:09:19.550 --> 00:09:22.650
And yes, trainings
enabling traditionally

00:09:22.650 --> 00:09:25.410
disadvantaged groups
to succeed have

00:09:25.410 --> 00:09:27.690
been shown to have some impact.

00:09:27.690 --> 00:09:30.550
But again, I don't
think the solution can

00:09:30.550 --> 00:09:37.000
be to fix women or people of
color or other underrepresented

00:09:37.000 --> 00:09:37.800
groups.

00:09:37.800 --> 00:09:41.300
But eventually we have to
move to fixing the system.

00:09:41.300 --> 00:09:43.370
So that's where I
want to take you.

00:09:43.370 --> 00:09:45.940
I want to talk about
three different topics

00:09:45.940 --> 00:09:48.110
that I touch upon in the book.

00:09:48.110 --> 00:09:50.470
The first one is
talent management,

00:09:50.470 --> 00:09:54.090
something that everyone
in this room and everyone

00:09:54.090 --> 00:09:58.160
across the globe, really, that
is listening to my talk today

00:09:58.160 --> 00:10:00.969
has been involved in
in some shape or form.

00:10:00.969 --> 00:10:02.760
Either because you've
interviewed for a job

00:10:02.760 --> 00:10:06.510
or because you were one of
the people evaluating others.

00:10:06.510 --> 00:10:09.700
Then I want to talk a
little bit about redesigning

00:10:09.700 --> 00:10:10.800
school and work.

00:10:10.800 --> 00:10:15.190
And give you some examples
of how that might be done.

00:10:15.190 --> 00:10:18.210
And then finally, I'll talk
about possibly the hardest

00:10:18.210 --> 00:10:21.720
topic, and that is how
to design diversity.

00:10:21.720 --> 00:10:24.490
How to make diversity
really work.

00:10:24.490 --> 00:10:28.940
OK, so any talent
management, of course,

00:10:28.940 --> 00:10:33.490
starts by attracting the
right kinds of people.

00:10:33.490 --> 00:10:36.050
And curiously
enough, we have been

00:10:36.050 --> 00:10:39.580
thinking about, for example,
gendered advertisements

00:10:39.580 --> 00:10:40.870
for a very long time.

00:10:40.870 --> 00:10:43.710
Not just Coca-Cola, not
just Pepsi, not just

00:10:43.710 --> 00:10:46.320
other soft drink
companies, but all of us.

00:10:46.320 --> 00:10:50.650
We are kind of aware of the fact
that some colors, for example,

00:10:50.650 --> 00:10:55.110
some shape, some names, appeal
more to women than to men,

00:10:55.110 --> 00:10:55.970
or vice versa.

00:10:55.970 --> 00:11:00.123
In Coke's case, it
was their word diet.

00:11:00.123 --> 00:11:02.160
Coke and other soft
drink companies

00:11:02.160 --> 00:11:06.466
realized that men don't
seem to be buying Diet Coke.

00:11:06.466 --> 00:11:08.215
It, of course, could
have lots of reasons.

00:11:08.215 --> 00:11:10.170
Either men don't care
about the calories

00:11:10.170 --> 00:11:12.450
they take, or they don't
have an issue with calories,

00:11:12.450 --> 00:11:14.515
or they run more along
the Charles River.

00:11:14.515 --> 00:11:16.946
Or diet is not their word.

00:11:16.946 --> 00:11:22.940
So they replaced diet by
Coke Zero, which was for men.

00:11:22.940 --> 00:11:24.740
Pepsi did the same thing.

00:11:24.740 --> 00:11:28.250
Pepsi Max instead of Diet Pepsi.

00:11:28.250 --> 00:11:30.290
And of course, Gillette
did the reverse

00:11:30.290 --> 00:11:32.390
when introducing
Venus Gillette that

00:11:32.390 --> 00:11:36.850
comes in colors that resonate
to people like me, in pink.

00:11:36.850 --> 00:11:41.050
I argue that-- I don't want
to defend this in any way,

00:11:41.050 --> 00:11:43.160
I'm just describing
that this is happening.

00:11:43.160 --> 00:11:44.860
But what I do want
to argue is that we

00:11:44.860 --> 00:11:47.040
should use the same
kind of scrutiny

00:11:47.040 --> 00:11:49.220
in our job advertisements.

00:11:49.220 --> 00:11:52.152
So here is an ad
that a school posted

00:11:52.152 --> 00:11:54.610
which wanted to increase the
fraction of its male teachers.

00:11:54.610 --> 00:11:56.670
As you probably know,
in the United States,

00:11:56.670 --> 00:11:59.370
we now have about 10%
to 15% male teachers

00:11:59.370 --> 00:12:01.940
in our elementary schools,
which increasingly

00:12:01.940 --> 00:12:03.610
poses a problem for our boys.

00:12:03.610 --> 00:12:06.940
Because they no longer
have male role models.

00:12:06.940 --> 00:12:09.340
So this ad looked
like this. "Looking

00:12:09.340 --> 00:12:12.690
for a warm and caring teacher
with exceptional pedagogical

00:12:12.690 --> 00:12:15.840
and interpersonal skills to work
in a supportive, collaborative

00:12:15.840 --> 00:12:17.560
work environment."

00:12:17.560 --> 00:12:19.610
The adjectives that we
highlighted, of course,

00:12:19.610 --> 00:12:24.540
are gendered and typically
associated with women.

00:12:24.540 --> 00:12:28.990
And research suggests that this
will, in fact, substantially

00:12:28.990 --> 00:12:32.690
decrease the likelihood that
men will apply to these jobs.

00:12:32.690 --> 00:12:35.550
So an alternative ad could have
looked something like this.

00:12:35.550 --> 00:12:37.150
"Looking for an
excellent teacher

00:12:37.150 --> 00:12:39.500
with exceptional
pedagogical skills."

00:12:39.500 --> 00:12:41.470
Now of course, the
school might say,

00:12:41.470 --> 00:12:46.200
but we really care
about the caring.

00:12:46.200 --> 00:12:48.840
And if they do, that is OK.

00:12:48.840 --> 00:12:51.270
I'm not prescribing what
schools or any organization,

00:12:51.270 --> 00:12:52.700
for that matter,
should be doing.

00:12:52.700 --> 00:12:55.670
But what I am arguing is that
we should do it consciously.

00:12:55.670 --> 00:12:59.922
We should understand
what messages we send,

00:12:59.922 --> 00:13:02.410
and send the messages
that we do want to send

00:13:02.410 --> 00:13:07.180
and that are important
to us in a conscious way.

00:13:07.180 --> 00:13:08.940
And that, of course,
often means that we

00:13:08.940 --> 00:13:11.140
have to measure, that we
have to collect the data,

00:13:11.140 --> 00:13:14.060
and evaluate the impact
of what we're doing.

00:13:14.060 --> 00:13:18.830
Now let me move on to
somewhat higher-hanging fruit.

00:13:18.830 --> 00:13:23.010
This is a hard one and I
know Google and your people

00:13:23.010 --> 00:13:24.920
analytics groups have
worried about this

00:13:24.920 --> 00:13:26.940
for quite a long time.

00:13:26.940 --> 00:13:28.870
Of course what we're up
against in evaluating

00:13:28.870 --> 00:13:32.670
people is that most of
us believe that we are

00:13:32.670 --> 00:13:34.300
particularly good interviewers.

00:13:34.300 --> 00:13:37.150
And those of you who've
read the book by Laszlo Bock

00:13:37.150 --> 00:13:39.790
will recall that among
all the Googlers,

00:13:39.790 --> 00:13:43.400
there is this one outlier who
is an amazing interviewer,

00:13:43.400 --> 00:13:46.340
and everyone else
is just average.

00:13:46.340 --> 00:13:47.980
And that's kind of
true for the world.

00:13:47.980 --> 00:13:49.600
That we all think
we're very good

00:13:49.600 --> 00:13:55.242
and we'll feel whether you
belong or not, when in fact

00:13:55.242 --> 00:13:57.240
what we're building
our assessments on

00:13:57.240 --> 00:14:02.090
are these stereotypes and are
these implicit assumptions

00:14:02.090 --> 00:14:04.120
that we often even
can't articulate.

00:14:04.120 --> 00:14:07.730
In my case, for example, a
real moment of a wake up call

00:14:07.730 --> 00:14:11.670
was when a job candidate--
this is a real story-- a job

00:14:11.670 --> 00:14:14.410
candidate and I started
to talk about the fact

00:14:14.410 --> 00:14:16.840
that we both had been
synchronized swimmers.

00:14:16.840 --> 00:14:19.390
And I felt immediately
that, oh my God,

00:14:19.390 --> 00:14:23.525
that will make her an
amazing Harvard professor.

00:14:23.525 --> 00:14:25.602
Now we can't keep
that from happening.

00:14:25.602 --> 00:14:27.060
That's the problem
with interviews.

00:14:27.060 --> 00:14:30.300
It's not that everything's
just bad, but it's hard for us

00:14:30.300 --> 00:14:34.060
to distill the useful
information from noise.

00:14:34.060 --> 00:14:36.554
And so I have this somewhat
cheesy stock photo up here

00:14:36.554 --> 00:14:38.970
to suggest to you that almost
everything that you see here

00:14:38.970 --> 00:14:40.250
is wrong.

00:14:40.250 --> 00:14:42.910
So the first thing that
is wrong is that we

00:14:42.910 --> 00:14:45.470
shouldn't do panel interviews.

00:14:45.470 --> 00:14:48.590
We shouldn't do panel
interviews because the sample

00:14:48.590 --> 00:14:51.862
size of a panel interview
is basically one.

00:14:51.862 --> 00:14:54.930
These three people will not come
up with independent assessments

00:14:54.930 --> 00:14:57.210
and is, of course,
much better to have

00:14:57.210 --> 00:15:01.310
three separate interviews with
three separate evaluations

00:15:01.310 --> 00:15:03.880
going on independently.

00:15:03.880 --> 00:15:07.660
A second myth is that diversity
on the evaluation committee

00:15:07.660 --> 00:15:11.020
itself will solve our problems.

00:15:11.020 --> 00:15:14.670
Now diversity can be helpful
in that we might reach out

00:15:14.670 --> 00:15:18.960
to different networks and
invite different people to apply

00:15:18.960 --> 00:15:20.340
to the jobs.

00:15:20.340 --> 00:15:22.670
But it doesn't protect
us from implicit bias.

00:15:22.670 --> 00:15:24.740
Seeing really is believing.

00:15:24.740 --> 00:15:28.460
And if we don't see female
engineers or male kindergarten

00:15:28.460 --> 00:15:31.050
teachers, we don't naturally
associate those jobs

00:15:31.050 --> 00:15:34.330
with men or women respectively.

00:15:34.330 --> 00:15:36.250
So diversity itself
can't be the solution.

00:15:36.250 --> 00:15:38.936
Then thirdly, and
now, of course,

00:15:38.936 --> 00:15:41.786
reading a bit much
into this picture here,

00:15:41.786 --> 00:15:44.990
what's really important
is that we always

00:15:44.990 --> 00:15:48.270
try to calibrate our
judgments by forcing

00:15:48.270 --> 00:15:50.890
our minds to make comparisons.

00:15:50.890 --> 00:15:52.970
So why am I saying this?

00:15:52.970 --> 00:15:54.740
A very basic insight
from behavior science

00:15:54.740 --> 00:15:56.840
is that everything
that you judge,

00:15:56.840 --> 00:15:59.775
everything that you evaluate,
the coffee that you now drink

00:15:59.775 --> 00:16:02.600
or the water that you
have in front of you

00:16:02.600 --> 00:16:04.870
has something to do with
the kinds of coffees

00:16:04.870 --> 00:16:07.300
that you normally drink.

00:16:07.300 --> 00:16:10.020
That is your reference point
or your reference coffee.

00:16:10.020 --> 00:16:13.140
That helps you evaluate whether
that's a good or bad coffee.

00:16:13.140 --> 00:16:15.860
Of course, we do the very same
thing when we evaluate people.

00:16:15.860 --> 00:16:19.090
We tend to evaluate
them compared

00:16:19.090 --> 00:16:24.395
to what we're used to in these
specific professions or jobs.

00:16:24.395 --> 00:16:25.770
And so what we're
trying to do is

00:16:25.770 --> 00:16:29.930
to overcome that need to rely on
this internal little reference

00:16:29.930 --> 00:16:33.880
person sitting in our head
who looks like the stereotype.

00:16:33.880 --> 00:16:36.250
And what we've been showing
with a number of experiments

00:16:36.250 --> 00:16:40.470
is that when I force you
to compare at least two,

00:16:40.470 --> 00:16:43.040
could be more, but
at least two job

00:16:43.040 --> 00:16:45.820
candidates at the
same time, you will

00:16:45.820 --> 00:16:47.990
be able to overcome
your stereotypes

00:16:47.990 --> 00:16:50.410
and are much more likely
to focus on these people's

00:16:50.410 --> 00:16:53.075
individual characteristics,
their ability,

00:16:53.075 --> 00:16:55.840
and what they bring to the
table rather than the groups

00:16:55.840 --> 00:16:57.240
that they belong to.

00:16:57.240 --> 00:16:59.970
So comparisons can
be a powerful tool

00:16:59.970 --> 00:17:03.730
to calibrate your judgments.

00:17:03.730 --> 00:17:06.010
All of this, of course,
hints at the fact

00:17:06.010 --> 00:17:10.120
that what we really should do is
use a more structured process.

00:17:10.120 --> 00:17:12.119
I was very happy to
learn that Google

00:17:12.119 --> 00:17:14.010
uses many of these
insights already

00:17:14.010 --> 00:17:17.390
in that you predetermine the
questions that you want to ask.

00:17:17.390 --> 00:17:18.980
You ask all of
your job candidates

00:17:18.980 --> 00:17:20.270
the same kinds of questions.

00:17:20.270 --> 00:17:21.839
You ask in the same order.

00:17:21.839 --> 00:17:23.560
And ideally, what
we should also do

00:17:23.560 --> 00:17:26.630
is we should rate every
question, every answer that we

00:17:26.630 --> 00:17:29.080
get, after we've
asked the question,

00:17:29.080 --> 00:17:30.830
and then move on to
the next question

00:17:30.830 --> 00:17:32.835
so that we're not
biased by whatever

00:17:32.835 --> 00:17:36.955
the candidate responded to the
first question that we asked.

00:17:36.955 --> 00:17:39.510
There's a number of these tools
that I discuss in the book,

00:17:39.510 --> 00:17:42.040
and I'm actually quite
excited because there

00:17:42.040 --> 00:17:46.090
are now these start-up companies
using some of these insights

00:17:46.090 --> 00:17:48.560
and translating them
into the technology which

00:17:48.560 --> 00:17:51.890
will make it easier
for all of us to use

00:17:51.890 --> 00:17:54.920
more structured approaches
to our hiring and evaluation

00:17:54.920 --> 00:17:56.650
processes.

00:17:56.650 --> 00:17:58.610
But of course,
behavioral insights

00:17:58.610 --> 00:18:00.250
shouldn't stop at
the entry level.

00:18:00.250 --> 00:18:02.590
And many of you will argue,
going back to the pyramid,

00:18:02.590 --> 00:18:06.270
that the really big
challenges start once you

00:18:06.270 --> 00:18:08.150
are in an organization.

00:18:08.150 --> 00:18:11.582
And let me give you kind
of three quick thoughts

00:18:11.582 --> 00:18:14.665
on the kind of things that we
might want to change there.

00:18:14.665 --> 00:18:19.910
A first one is super
trivial and won't strike you

00:18:19.910 --> 00:18:21.470
as a surprise at all.

00:18:21.470 --> 00:18:24.690
And that is just
measure the support

00:18:24.690 --> 00:18:29.180
that we give our employees
to help them succeed.

00:18:29.180 --> 00:18:31.430
So just down the
road here, MIT was

00:18:31.430 --> 00:18:33.270
one of the first
institutions, one

00:18:33.270 --> 00:18:35.120
of the first academic
institutions,

00:18:35.120 --> 00:18:41.200
I should say, actually measuring
the support that people got.

00:18:41.200 --> 00:18:43.410
And given that they're
MIT, of course,

00:18:43.410 --> 00:18:45.420
the data spoke for itself.

00:18:45.420 --> 00:18:46.970
They literally used
the measuring rod

00:18:46.970 --> 00:18:49.140
to measure people's office
spaces, the laboratories

00:18:49.140 --> 00:18:52.310
they had available, the support
staff, research assistants,

00:18:52.310 --> 00:18:54.340
resources, et cetera.

00:18:54.340 --> 00:18:57.520
And they found what then later
was called performance support

00:18:57.520 --> 00:19:00.740
bias which disadvantaged women.

00:19:00.740 --> 00:19:03.190
Now that, of course,
again, is low-hanging fruit

00:19:03.190 --> 00:19:04.900
that we can fix easily.

00:19:04.900 --> 00:19:06.840
It gets a bit more
complicated when we think

00:19:06.840 --> 00:19:08.775
about performance appraisals.

00:19:08.775 --> 00:19:12.150
A first insight is that whenever
I work with organizations,

00:19:12.150 --> 00:19:16.600
I typically find the bias is
not so much when organizations

00:19:16.600 --> 00:19:19.540
evaluate past performance, which
many organizations literally

00:19:19.540 --> 00:19:20.720
do on the x-axis.

00:19:20.720 --> 00:19:26.006
But typically when organizations
also evaluate potential.

00:19:26.006 --> 00:19:28.520
Because potential
by definition is

00:19:28.520 --> 00:19:30.530
forward-looking
and by definition

00:19:30.530 --> 00:19:32.560
is very hard to measure.

00:19:32.560 --> 00:19:36.340
And that's where the Heidi bias,
the leadership bias, kicks in.

00:19:36.340 --> 00:19:40.730
Because we cannot imagine
that women or other

00:19:40.730 --> 00:19:43.520
under-represented groups who are
not typically in the leadership

00:19:43.520 --> 00:19:46.690
positions would want to
climb up the career ladders.

00:19:46.690 --> 00:19:50.010
So potential is
certainly something

00:19:50.010 --> 00:19:51.800
that you should
be worried about.

00:19:51.800 --> 00:19:54.110
And if you want to use
potential, what I typically

00:19:54.110 --> 00:19:58.640
try to argue is we should try
to define as precisely as you

00:19:58.640 --> 00:20:02.460
possibly can what we
really mean with potential.

00:20:02.460 --> 00:20:06.670
And force ourselves to quantify
it as much as we possibly can.

00:20:06.670 --> 00:20:09.960
And then thirdly and
finally, we should

00:20:09.960 --> 00:20:14.110
stop sharing self-evaluations
with our managers.

00:20:14.110 --> 00:20:18.600
Many organizations
ask their employees

00:20:18.600 --> 00:20:22.050
to self-evaluate themselves,
often on a rating scale,

00:20:22.050 --> 00:20:23.240
let's say, from one to 10.

00:20:23.240 --> 00:20:27.660
And then ask the employees
to share these evaluations

00:20:27.660 --> 00:20:29.230
with their supervisors.

00:20:29.230 --> 00:20:30.980
Now a little bit of
behavioral science

00:20:30.980 --> 00:20:34.630
already suggests to us that this
will encourage the manager's

00:20:34.630 --> 00:20:35.330
assessments.

00:20:35.330 --> 00:20:37.100
Because any numbers
that I throw at you,

00:20:37.100 --> 00:20:40.300
whether in a negotiation or
in performance appraisal,

00:20:40.300 --> 00:20:42.010
will affect your judgments.

00:20:42.010 --> 00:20:44.430
And if people differ in
their self-confidence,

00:20:44.430 --> 00:20:48.570
that will affect the evaluations
that they end up with.

00:20:48.570 --> 00:20:53.050
These are just some ideas of how
we can kind of fix and improve

00:20:53.050 --> 00:20:56.150
how we do our talent management.

00:20:56.150 --> 00:20:58.660
But let me go to some
bigger questions.

00:20:58.660 --> 00:21:02.340
And this one might resonate
with you in particular.

00:21:02.340 --> 00:21:04.570
Now I don't see too many
people who have recently

00:21:04.570 --> 00:21:06.860
taken the SAT in this
room, but most of you

00:21:06.860 --> 00:21:09.560
will have taken it at
some point and might

00:21:09.560 --> 00:21:13.010
remember that part of the
SAT is a multiple choice

00:21:13.010 --> 00:21:14.710
questionnaire.

00:21:14.710 --> 00:21:18.850
Now think about the
following thought experiment.

00:21:18.850 --> 00:21:24.680
If, in fact, people differ in
their willingness to take risk,

00:21:24.680 --> 00:21:29.260
some people will be more willing
to guess or volunteer an answer

00:21:29.260 --> 00:21:33.510
and others will be more
willing to skip the question.

00:21:33.510 --> 00:21:36.270
So generally much,
much research suggests

00:21:36.270 --> 00:21:38.600
that women tend to be
more risk averse than men.

00:21:38.600 --> 00:21:42.290
And a former doctoral
student of mine,

00:21:42.290 --> 00:21:45.860
[? Katie Baliga Kaufman ?],
in fact, took this to heart

00:21:45.860 --> 00:21:52.180
and wanted to check whether that
might cost the skippers points

00:21:52.180 --> 00:21:55.460
on the SAT because they
weren't willing to guess.

00:21:55.460 --> 00:21:59.400
So she brought a large number
of subjects to the laboratory.

00:21:59.400 --> 00:22:01.710
They participated in an SAT.

00:22:01.710 --> 00:22:04.310
Only in the multiple
choice part of the SAT.

00:22:04.310 --> 00:22:06.440
And then given that
this was the laboratory,

00:22:06.440 --> 00:22:09.010
she could force everyone
to answer every question.

00:22:09.010 --> 00:22:11.860
So she could take out
the skipping option,

00:22:11.860 --> 00:22:15.200
and thereby measure what people
would have known had they

00:22:15.200 --> 00:22:16.700
answered all the questions.

00:22:16.700 --> 00:22:22.040
And what she found was that for
equally able people controlling

00:22:22.040 --> 00:22:25.380
for ability, women are
much more likely to skip

00:22:25.380 --> 00:22:28.040
and men are more
likely to guess, which

00:22:28.040 --> 00:22:30.830
costs women dearly on the SAT.

00:22:30.830 --> 00:22:32.210
Now the happy
ending of the story

00:22:32.210 --> 00:22:34.350
is that this month--
no, last month.

00:22:34.350 --> 00:22:35.260
It's already April.

00:22:35.260 --> 00:22:39.810
March 2016, as you probably
have read in the news,

00:22:39.810 --> 00:22:41.490
the SAT has been redesigned.

00:22:41.490 --> 00:22:46.900
And one of the new design
features is to de-bias the SAT.

00:22:46.900 --> 00:22:49.360
To gender de-bias the SAT.

00:22:49.360 --> 00:22:52.270
Really, in many ways, the
first time in 100 years.

00:22:52.270 --> 00:22:56.380
The SAT now is trying to
provide a level playing field

00:22:56.380 --> 00:22:59.180
and it could have done
many different things.

00:22:59.180 --> 00:23:01.530
The College Board
ended up choosing

00:23:01.530 --> 00:23:05.800
to take away the penalties for
guessing wrongly completely.

00:23:05.800 --> 00:23:09.450
In the old SAT, you got a
point for every right answer

00:23:09.450 --> 00:23:11.920
and a quarter point
deduction for wrong answers.

00:23:11.920 --> 00:23:14.506
So a little bit of math
suggested to people

00:23:14.506 --> 00:23:16.505
that if you had five
possible answers available,

00:23:16.505 --> 00:23:19.840
if you can exclude one, then
it is the dominant strategy

00:23:19.840 --> 00:23:20.670
to guess.

00:23:20.670 --> 00:23:22.650
But if people differ
in their willingness

00:23:22.650 --> 00:23:24.430
to take risk, of
course, the risk lovers

00:23:24.430 --> 00:23:26.800
will be more likely to guess
than the risk avoiders.

00:23:26.800 --> 00:23:30.090
So the new test takes the
penalty completely away.

00:23:30.090 --> 00:23:33.010
At which point the
critics, of course, said,

00:23:33.010 --> 00:23:35.560
oh my God, you're
enabling guessing now

00:23:35.560 --> 00:23:37.890
and you're inviting wild
guessing by everyone.

00:23:37.890 --> 00:23:40.920
At which point the
answer must be,

00:23:40.920 --> 00:23:43.090
well, we have been
inviting guessing

00:23:43.090 --> 00:23:46.300
by 50% of the population
for about 100 years.

00:23:46.300 --> 00:23:49.672
And now we're making it
legal for everyone to do so.

00:23:49.672 --> 00:23:51.110
So that's design.

00:23:51.110 --> 00:23:54.590
Design can be powerful, can
really change how we do things

00:23:54.590 --> 00:23:58.190
and level the playing
field quite dramatically.

00:23:58.190 --> 00:24:02.160
Here's another example
that can be quite powerful

00:24:02.160 --> 00:24:04.120
and that is literally
the power of role models.

00:24:04.120 --> 00:24:06.760
Leaving the US for a moment,
because interestingly

00:24:06.760 --> 00:24:09.426
enough and unbeknownst
to many people,

00:24:09.426 --> 00:24:11.790
the longest running
quota experiment

00:24:11.790 --> 00:24:13.610
has, in fact, been run in India.

00:24:13.610 --> 00:24:15.520
Not in Norway or
some other countries

00:24:15.520 --> 00:24:19.240
which recently have introduced
quotas on its corporate boards.

00:24:19.240 --> 00:24:22.470
India amended its constitution
in 1993 with the provision

00:24:22.470 --> 00:24:25.120
that a third of village
heads had to be female.

00:24:25.120 --> 00:24:27.460
What was beautiful from
a research point of view,

00:24:27.460 --> 00:24:30.292
the third was literally
picked out of a hat,

00:24:30.292 --> 00:24:32.880
allowing researchers to
evaluate what difference

00:24:32.880 --> 00:24:34.320
difference really makes.

00:24:34.320 --> 00:24:37.930
And a number of papers have
been written in those 22 years,

00:24:37.930 --> 00:24:38.770
roughly.

00:24:38.770 --> 00:24:41.490
But the one that I want to
particularly focus on here

00:24:41.490 --> 00:24:43.030
was recently
published in "Science"

00:24:43.030 --> 00:24:46.400
suggesting that if a
village has been exposed

00:24:46.400 --> 00:24:48.770
to two female leaders
in those 22 years,

00:24:48.770 --> 00:24:51.500
mindsets are starting to change.

00:24:51.500 --> 00:24:53.740
And parents and
girls are starting

00:24:53.740 --> 00:24:57.890
to associate political
leadership with women.

00:24:57.890 --> 00:24:59.380
That's pretty dramatic.

00:24:59.380 --> 00:25:02.390
Again, suggesting that
seeing really is believing.

00:25:02.390 --> 00:25:05.750
And that if we see
counter-stereotypical people

00:25:05.750 --> 00:25:08.420
in those jobs, we can
actually imagine ourselves

00:25:08.420 --> 00:25:09.780
in those jobs.

00:25:09.780 --> 00:25:11.420
And it has quite
real implications.

00:25:11.420 --> 00:25:13.870
So I'm sad to say, this is my
own institution, the Harvard

00:25:13.870 --> 00:25:17.430
Kennedy School, that
only 11 years ago, we

00:25:17.430 --> 00:25:22.700
realized that all the portraits
on our walls of leaders

00:25:22.700 --> 00:25:24.460
were of men.

00:25:24.460 --> 00:25:26.840
50% of our students are female.

00:25:26.840 --> 00:25:29.510
And it wasn't our
conscious intention

00:25:29.510 --> 00:25:31.510
to suggest to our
female students

00:25:31.510 --> 00:25:34.020
that they were not
made to be leaders.

00:25:34.020 --> 00:25:35.730
So we've changed that since.

00:25:35.730 --> 00:25:38.160
This is Ellen Johnson Sirleaf,
the President of Liberia.

00:25:38.160 --> 00:25:39.430
Also a graduate of the school.

00:25:39.430 --> 00:25:42.616
We commissioned a portrait
of hers, Abigail Adams,

00:25:42.616 --> 00:25:46.660
a number more, to change
the face, quite literally,

00:25:46.660 --> 00:25:49.230
of the Kennedy
School and make it

00:25:49.230 --> 00:25:51.150
a more inclusive environment.

00:25:51.150 --> 00:25:53.650
Very serious research
suggests that even

00:25:53.650 --> 00:25:57.700
what we see on our walls
can affect our beliefs.

00:25:57.700 --> 00:26:00.450
And then, of course, there
is some really happy news.

00:26:00.450 --> 00:26:05.220
That recently we've had a
female protagonist, Rey,

00:26:05.220 --> 00:26:07.150
in "Star Wars."

00:26:07.150 --> 00:26:12.800
And of course, that does
matter in what we think

00:26:12.800 --> 00:26:14.670
is possible for ourselves.

00:26:14.670 --> 00:26:18.140
Sadly and often, you probably
have read about this.

00:26:18.140 --> 00:26:19.960
It didn't transpire everywhere.

00:26:19.960 --> 00:26:22.790
Monopoly created a special
version of Monopoly

00:26:22.790 --> 00:26:26.330
based on this particular
episode of "Star Wars"

00:26:26.330 --> 00:26:29.140
and forgot to include
the female characters.

00:26:29.140 --> 00:26:33.440
Now Monopoly, I should
say, has fixed this since,

00:26:33.440 --> 00:26:36.840
but it's still remarkable
that something like this

00:26:36.840 --> 00:26:38.600
is still possible.

00:26:38.600 --> 00:26:41.020
Now let me move on
to our last topic.

00:26:41.020 --> 00:26:44.640
How to design diversity,
which I already announced

00:26:44.640 --> 00:26:47.080
is a really thorny topic.

00:26:47.080 --> 00:26:51.450
On the one hand, much evidence
suggests that diverse groups

00:26:51.450 --> 00:26:53.900
outperform homogeneous groups.

00:26:53.900 --> 00:26:58.560
But the tricky part is that when
you ask people who participated

00:26:58.560 --> 00:27:02.360
in a diverse team how well
they think their team performed

00:27:02.360 --> 00:27:06.110
and how enjoyable the
task was, they will,

00:27:06.110 --> 00:27:11.190
time and again, report that the
team probably didn't do so well

00:27:11.190 --> 00:27:13.874
and it wasn't really fun.

00:27:13.874 --> 00:27:16.400
Because diversity is
hard work and, of course,

00:27:16.400 --> 00:27:19.680
because what we're
trying to achieve

00:27:19.680 --> 00:27:23.090
by having diverse perspectives
represented in a group

00:27:23.090 --> 00:27:25.960
is exactly what
makes uncomfortable.

00:27:25.960 --> 00:27:27.346
You want people to disagree.

00:27:27.346 --> 00:27:29.220
We don't want people to
fall into group think

00:27:29.220 --> 00:27:31.640
and just run in
the same direction

00:27:31.640 --> 00:27:35.230
because somebody said
a was the right answer.

00:27:35.230 --> 00:27:38.000
And that makes
diversity so hard.

00:27:38.000 --> 00:27:40.360
So let me give you
kind of a few thoughts.

00:27:40.360 --> 00:27:41.940
So some is really old news.

00:27:41.940 --> 00:27:44.310
Yes, critical mass does matter.

00:27:44.310 --> 00:27:48.920
It does matter whether
you're the only one of x.

00:27:48.920 --> 00:27:51.680
The only woman, the only
Swiss, the only economist,

00:27:51.680 --> 00:27:53.770
whatever it might be in a team.

00:27:53.770 --> 00:27:54.650
It does matter.

00:27:54.650 --> 00:27:57.140
You will be turned into
a token and you are also

00:27:57.140 --> 00:28:00.170
much more likely to perceive
yourself as a token.

00:28:00.170 --> 00:28:04.580
So having three of x in a team
or roughly 30% in many cases

00:28:04.580 --> 00:28:06.130
is helpful.

00:28:06.130 --> 00:28:09.360
But diversity is not
just a numbers game.

00:28:09.360 --> 00:28:11.950
And I just want to end
by highlighting this.

00:28:11.950 --> 00:28:13.350
It goes beyond numbers.

00:28:13.350 --> 00:28:16.480
Numbers themselves are
very helpful and important,

00:28:16.480 --> 00:28:19.300
but we have to think
about the decision rules

00:28:19.300 --> 00:28:22.880
and rules of engagement
on our teams as well.

00:28:22.880 --> 00:28:25.740
And here's one that was
a personal surprise to me

00:28:25.740 --> 00:28:27.720
and that is political
correctness.

00:28:27.720 --> 00:28:29.980
So I came from
Switzerland to the US.

00:28:29.980 --> 00:28:34.310
And Germanic culture is
not a culture known for PC.

00:28:34.310 --> 00:28:36.620
And I have to tell
you that initially, I

00:28:36.620 --> 00:28:39.630
used all my stereotypes about
Americans thinking, oh God,

00:28:39.630 --> 00:28:42.735
this is very superficial,
this whole PC thing.

00:28:42.735 --> 00:28:45.420
Now it turns out,
really serious research

00:28:45.420 --> 00:28:47.470
suggests it's actually working.

00:28:47.470 --> 00:28:48.460
Why?

00:28:48.460 --> 00:28:50.290
Let me show you a
picture here and ask you

00:28:50.290 --> 00:28:51.570
the following question.

00:28:51.570 --> 00:28:55.100
Where would you be more likely
to drop a piece of paper?

00:28:55.100 --> 00:28:58.430
Probably on the dirty beach.

00:28:58.430 --> 00:29:01.690
So what we see or what
we hear signals something

00:29:01.690 --> 00:29:03.990
about the prevalent norms.

00:29:03.990 --> 00:29:06.700
And the question
for us [INAUDIBLE]

00:29:06.700 --> 00:29:09.030
really is, where
would we be more

00:29:09.030 --> 00:29:12.540
likely to drop a dirty joke?

00:29:12.540 --> 00:29:15.210
Not in a PC environment.

00:29:15.210 --> 00:29:16.940
So norms can matter.

00:29:16.940 --> 00:29:19.440
And how we present
information can matter.

00:29:19.440 --> 00:29:23.710
And I have one of
my favorite slides

00:29:23.710 --> 00:29:28.210
up here, which I'll start on
the happy note, learning really

00:29:28.210 --> 00:29:30.350
is possible, and
the sad note, we

00:29:30.350 --> 00:29:33.520
have been using this pyramid
for decades in this country

00:29:33.520 --> 00:29:37.650
to help us make more
educated food choices.

00:29:37.650 --> 00:29:40.522
Now here is the deep insight.

00:29:40.522 --> 00:29:44.880
We do not eat off pyramids.

00:29:44.880 --> 00:29:47.090
This is the new image.

00:29:47.090 --> 00:29:48.410
It's a plate.

00:29:48.410 --> 00:29:51.800
And I'm sure it resonates
with you that immediately, you

00:29:51.800 --> 00:29:56.280
can see whether you eat too much
dairy, too little dairy, too

00:29:56.280 --> 00:30:00.100
little protein, too much
protein, things of that sort.

00:30:00.100 --> 00:30:04.600
All of us probably
have some reflection,

00:30:04.600 --> 00:30:06.610
some reaction to what they see.

00:30:06.610 --> 00:30:07.680
For me, it's the dairy.

00:30:07.680 --> 00:30:10.160
I'm a dairy lover, and I'm
still disputing the fact

00:30:10.160 --> 00:30:12.330
that this is so small.

00:30:12.330 --> 00:30:13.730
But anyway.

00:30:13.730 --> 00:30:17.250
So here's how we've
used this information

00:30:17.250 --> 00:30:21.650
to reshape some of the norms
in the gender diversity space.

00:30:21.650 --> 00:30:23.900
This is a cover from the UK.

00:30:23.900 --> 00:30:28.510
Some of you might be familiar
that the UK decided in 2011

00:30:28.510 --> 00:30:32.260
to increase gender diversity
on its corporate boards to 25%

00:30:32.260 --> 00:30:35.880
by 2015 without the
introduction of quotas,

00:30:35.880 --> 00:30:38.710
but instead by relying
on behavioral insights.

00:30:38.710 --> 00:30:41.571
So we've worked a bit with
the various groups involved,

00:30:41.571 --> 00:30:43.820
specifically for us, it was
Vince Cable, the Secretary

00:30:43.820 --> 00:30:47.140
of Business, in thinking about
how behavioral insights could

00:30:47.140 --> 00:30:48.370
be helpful.

00:30:48.370 --> 00:30:51.840
And this is the brochure that
they showed to us in 2013

00:30:51.840 --> 00:30:56.810
when we were first approached,
showing that 17% of board

00:30:56.810 --> 00:30:58.480
members were female.

00:30:58.480 --> 00:31:00.940
Here's what concerned us.

00:31:00.940 --> 00:31:05.860
Sometimes descriptive norms can
turn into prescriptive norms.

00:31:05.860 --> 00:31:08.170
Not just describing
how the world is,

00:31:08.170 --> 00:31:12.300
but suggesting how
the world should be.

00:31:12.300 --> 00:31:15.960
And so we were nervous about
this depiction of reality

00:31:15.960 --> 00:31:20.250
because it might suggest to us
that yes, the right thing to do

00:31:20.250 --> 00:31:23.790
is to have a small fraction
of women on boards.

00:31:23.790 --> 00:31:28.210
So we redesigned the
cover page and focused

00:31:28.210 --> 00:31:30.950
instead on the
organizations which

00:31:30.950 --> 00:31:32.520
already have diverse supports.

00:31:32.520 --> 00:31:36.500
It's the same sample, the
100, because companies, the

00:31:36.500 --> 00:31:38.630
[INAUDIBLE] 100
companies in the UK,

00:31:38.630 --> 00:31:42.390
but what we were
focusing on was who

00:31:42.390 --> 00:31:45.280
and what fraction of the
100 largest companies

00:31:45.280 --> 00:31:47.210
are already diverse.

00:31:47.210 --> 00:31:51.550
And at that time, that was 94%,
signaling that the thing to do

00:31:51.550 --> 00:31:55.560
was to join the
club and be diverse.

00:31:55.560 --> 00:31:57.640
So if you're interested
in learning more

00:31:57.640 --> 00:31:59.990
about some of these
findings, we've

00:31:59.990 --> 00:32:03.070
created an online platform,
the Gender Action Portal,

00:32:03.070 --> 00:32:06.710
which is searchable,
where people can find out

00:32:06.710 --> 00:32:09.070
more about what
works to close gender

00:32:09.070 --> 00:32:12.150
gaps in economic opportunity,
but also in health, education,

00:32:12.150 --> 00:32:13.602
and political participation.

00:32:13.602 --> 00:32:18.355
[APPLAUSE]

00:32:18.355 --> 00:32:22.800
I'm happy to take questions,
comments, thoughts.

00:32:22.800 --> 00:32:23.320
MARTA: Hi

00:32:23.320 --> 00:32:23.730
IRIS BOHNET: Hi.

00:32:23.730 --> 00:32:24.660
MARTA: My name is Marta.

00:32:24.660 --> 00:32:26.050
I have a question
about, I just want

00:32:26.050 --> 00:32:27.549
to hear your thoughts
on motherhood,

00:32:27.549 --> 00:32:30.570
because I've been reading a lot
about how we can do a lot up

00:32:30.570 --> 00:32:32.740
front to recruit more
women, but there's

00:32:32.740 --> 00:32:35.860
a lot of bias associated with
women once they get to a point

00:32:35.860 --> 00:32:38.220
where they're considering
having children.

00:32:38.220 --> 00:32:40.027
I myself have not-- am
thinking I might not

00:32:40.027 --> 00:32:42.110
want children, which is a
whole other conversation

00:32:42.110 --> 00:32:43.760
about the reactions
I get for that.

00:32:43.760 --> 00:32:45.800
But there's an immediate
assumption right

00:32:45.800 --> 00:32:48.240
after a woman gets
married, I feel even here,

00:32:48.240 --> 00:32:50.809
that their productivity
might decrease

00:32:50.809 --> 00:32:52.350
because their
priorities will change.

00:32:52.350 --> 00:32:55.650
And I'm trying to reconcile
that with women I hear saying,

00:32:55.650 --> 00:32:57.280
in fact, their
priorities do change,

00:32:57.280 --> 00:32:58.781
along with fathers
who say the same.

00:32:58.781 --> 00:33:00.738
So I'd just love to hear
your thoughts on that.

00:33:00.738 --> 00:33:02.470
IRIS BOHNET: Thank
you for the question.

00:33:02.470 --> 00:33:04.761
In fact, I'm going to draw
on some of your own research

00:33:04.761 --> 00:33:05.466
at Google.

00:33:05.466 --> 00:33:09.110
So as you can tell, I am a
fan of a Laszlo Bock's book,

00:33:09.110 --> 00:33:10.120
"Work Rules!"

00:33:10.120 --> 00:33:13.890
And when Google
realized that women

00:33:13.890 --> 00:33:16.924
were more likely to leave than
men, they analyzed the data.

00:33:16.924 --> 00:33:18.840
And the data told them
that it wasn't actually

00:33:18.840 --> 00:33:21.381
women who were more likely to
quit, but it was young mothers.

00:33:21.381 --> 00:33:24.170
And Google being
Google then could

00:33:24.170 --> 00:33:28.680
increase its parental leave
and both, in fact, not

00:33:28.680 --> 00:33:31.150
just for mothers, but also
for fathers, young fathers.

00:33:31.150 --> 00:33:36.000
And now apparently doesn't
have a gender gap in likelihood

00:33:36.000 --> 00:33:37.700
of leaving anymore.

00:33:37.700 --> 00:33:41.090
So that's, I think,
the power of data

00:33:41.090 --> 00:33:44.180
and the power of
something that is clearly

00:33:44.180 --> 00:33:45.500
more than behavioral design.

00:33:45.500 --> 00:33:49.830
And that is kind of taking into
consideration that people have

00:33:49.830 --> 00:33:52.320
lives outside of their jobs.

00:33:52.320 --> 00:33:55.170
And that we have to
accommodate those lives

00:33:55.170 --> 00:33:58.250
and those needs to make sure
that the employees can also

00:33:58.250 --> 00:34:00.490
thrive in our organizations.

00:34:00.490 --> 00:34:02.030
So parental leave policies.

00:34:02.030 --> 00:34:04.170
Again, this is beyond
behavioral design.

00:34:04.170 --> 00:34:06.060
This is just now the
economist speaking based

00:34:06.060 --> 00:34:08.210
on economic evidence on that.

00:34:08.210 --> 00:34:12.150
Parental leave policies
are quite possibly

00:34:12.150 --> 00:34:15.925
the most powerful
tool we can use

00:34:15.925 --> 00:34:21.400
to decrease the 'motherhood
penalty' that you allude to.

00:34:21.400 --> 00:34:24.260
Now what, of course,
it doesn't correct

00:34:24.260 --> 00:34:28.949
for are the biases that we
have, the stereotypes, that

00:34:28.949 --> 00:34:33.480
go with seeing, for
example, a pregnant woman.

00:34:33.480 --> 00:34:36.560
And there isn't a lot of
research suggesting that there

00:34:36.560 --> 00:34:40.489
is something like a 'motherhood
penalty.' And that yes,

00:34:40.489 --> 00:34:43.170
mothers do earn
less than fathers.

00:34:43.170 --> 00:34:45.400
And that, in fact,
the correlation

00:34:45.400 --> 00:34:46.620
goes the other way around.

00:34:46.620 --> 00:34:49.666
That men tend to
make more money when

00:34:49.666 --> 00:34:52.040
they have children and women
tend to make less money when

00:34:52.040 --> 00:34:53.880
they have children.

00:34:53.880 --> 00:34:56.830
So I do think the
biases, the stereotypes

00:34:56.830 --> 00:34:59.340
are absolutely well and alive.

00:34:59.340 --> 00:35:05.160
And by becoming aware of them,
we won't solve the problem.

00:35:05.160 --> 00:35:07.600
But in fact, I applaud Google.

00:35:07.600 --> 00:35:10.050
I'm not just saying this here,
I say this in my book also.

00:35:10.050 --> 00:35:12.980
I applaud Google for
going to the data

00:35:12.980 --> 00:35:17.750
and really trying to understand
what is happening here and then

00:35:17.750 --> 00:35:20.230
trying to fix what's
actually broken.

00:35:20.230 --> 00:35:23.420
So generally, by the way, a
bigger answer to your question

00:35:23.420 --> 00:35:29.480
is I am skeptical
that we will ever

00:35:29.480 --> 00:35:35.310
be able to overcome our
biases as human beings

00:35:35.310 --> 00:35:38.380
until we see
something different.

00:35:38.380 --> 00:35:41.340
So for example, let me run the
following thought experiment

00:35:41.340 --> 00:35:42.090
with you.

00:35:42.090 --> 00:35:45.210
Maybe orchestras could,
the major orchestras

00:35:45.210 --> 00:35:48.020
in this country, could
remove the curtains now.

00:35:48.020 --> 00:35:53.370
Because now that we have almost
40% female musicians, maybe

00:35:53.370 --> 00:35:56.510
we're starting to associate,
building on the India evidence,

00:35:56.510 --> 00:36:00.670
we're starting to associate
playing music with women.

00:36:00.670 --> 00:36:02.800
And maybe we don't need
the curtains anymore.

00:36:02.800 --> 00:36:04.510
Now of course, I
might be wrong, right?

00:36:04.510 --> 00:36:06.370
This Is an experiment
yet to be run.

00:36:06.370 --> 00:36:10.310
But the evidence that we have
so far from, and particularly

00:36:10.310 --> 00:36:13.030
from India where numbers have
changed very quickly because

00:36:13.030 --> 00:36:15.300
of quotas, makes me
kind of optimistic

00:36:15.300 --> 00:36:19.100
that when we see the
change, eventually

00:36:19.100 --> 00:36:20.685
our mindsets can change.

00:36:20.685 --> 00:36:22.810
But I don't think by just
being aware, for example,

00:36:22.810 --> 00:36:25.020
that there's much
of a penalty, we

00:36:25.020 --> 00:36:28.480
will perceive
mothers differently.

00:36:28.480 --> 00:36:28.980
OK.

00:36:28.980 --> 00:36:31.040
Oh no, one more question.

00:36:31.040 --> 00:36:35.164
AUDIENCE: Can't-- can't let
only one question happen here.

00:36:35.164 --> 00:36:38.620
About the resume bias.

00:36:38.620 --> 00:36:40.350
That's pretty well-known by now.

00:36:40.350 --> 00:36:42.270
Plenty of research
on that, especially

00:36:42.270 --> 00:36:44.640
with both minorities and women.

00:36:44.640 --> 00:36:47.880
But my understanding
is that there

00:36:47.880 --> 00:36:50.850
may be similar bias at
the interview stage.

00:36:50.850 --> 00:36:54.630
And I was reading an
article recently about this.

00:36:54.630 --> 00:36:59.860
And apparently companies
now have sprung up to,

00:36:59.860 --> 00:37:02.800
essentially what they
do is to do screening.

00:37:02.800 --> 00:37:05.320
But the way they do
screening is they

00:37:05.320 --> 00:37:09.390
give tests that are designed
by the hiring companies

00:37:09.390 --> 00:37:15.330
and submit the test
results to the company

00:37:15.330 --> 00:37:19.800
without any sort of identifying
information with them at all.

00:37:19.800 --> 00:37:22.550
And have the companies
first select the candidates

00:37:22.550 --> 00:37:26.300
that they will interview based
only on these test scores.

00:37:26.300 --> 00:37:30.640
And then apparently,
according to what I've read,

00:37:30.640 --> 00:37:34.530
this tends to also increase the
number of women who eventually

00:37:34.530 --> 00:37:37.970
get hired because they
don't get screened out

00:37:37.970 --> 00:37:40.180
at an individual
interview stage.

00:37:40.180 --> 00:37:42.300
I wish I remembered more
of the details of this,

00:37:42.300 --> 00:37:45.454
but I'm wondering what you know
or think about this part of it.

00:37:45.454 --> 00:37:47.120
IRIS BOHNET: Thank
you for the question.

00:37:47.120 --> 00:37:48.828
I discuss it at great
length in the book.

00:37:48.828 --> 00:37:50.720
So absolutely.

00:37:50.720 --> 00:37:53.230
The best predictor of
future performance,

00:37:53.230 --> 00:37:57.270
and that's, again, not rocket
science, is a work sample test.

00:37:57.270 --> 00:37:58.850
So when I hire a
research assistant,

00:37:58.850 --> 00:38:00.250
that is not very hard for me.

00:38:00.250 --> 00:38:02.760
I can give the
person a problem, ask

00:38:02.760 --> 00:38:05.100
her to do some data analysis,
run some regressions,

00:38:05.100 --> 00:38:08.060
write a short report, and
that's a very good predictor

00:38:08.060 --> 00:38:10.910
of how well the person is
going to perform in the future.

00:38:10.910 --> 00:38:14.030
So a work sample test
is the best predictor

00:38:14.030 --> 00:38:14.990
of future performance.

00:38:14.990 --> 00:38:16.100
Full stop.

00:38:16.100 --> 00:38:18.320
One of the worst predictors
of future performance

00:38:18.320 --> 00:38:20.550
are unstructured interviews.

00:38:20.550 --> 00:38:24.424
Now social science, that's
actually not new news.

00:38:24.424 --> 00:38:25.840
Social scientists
have been trying

00:38:25.840 --> 00:38:29.060
to convince the world that
unstructured interviews are

00:38:29.060 --> 00:38:32.280
bad predictors of future
performance for about 50 years.

00:38:32.280 --> 00:38:34.120
So being a behavioral
scientist, I actually

00:38:34.120 --> 00:38:36.924
don't believe that we'll ever
convince people to give up

00:38:36.924 --> 00:38:37.840
the interviews, right?

00:38:37.840 --> 00:38:39.950
In 50 years, either we
are bad communicators,

00:38:39.950 --> 00:38:41.450
and that might be part of it.

00:38:41.450 --> 00:38:42.060
Who knows?

00:38:42.060 --> 00:38:47.047
But in any case, I think
we're clinging to interviews.

00:38:47.047 --> 00:38:49.130
So I served as Academic
Dean of the Kennedy School

00:38:49.130 --> 00:38:50.332
for a few years.

00:38:50.332 --> 00:38:52.290
I could not imagine hiring
a new faculty member

00:38:52.290 --> 00:38:53.830
without having talked to them.

00:38:53.830 --> 00:38:55.120
So I'm totally guilty of that.

00:38:55.120 --> 00:38:57.040
At least I used the
structured interview.

00:38:57.040 --> 00:38:59.290
So that's why my
recommendation would

00:38:59.290 --> 00:39:04.610
be to combine a work sample test
with a structured interview,

00:39:04.610 --> 00:39:05.130
right?

00:39:05.130 --> 00:39:07.500
Which at least is using
a structured process.

00:39:07.500 --> 00:39:09.160
And structured
interviews are actually

00:39:09.160 --> 00:39:12.730
better able to predict
future performance.

00:39:12.730 --> 00:39:16.190
But there are companies now,
and it's super exciting, super

00:39:16.190 --> 00:39:19.190
interesting to see, which do
away with resumes completely.

00:39:19.190 --> 00:39:21.802
And instead just do
the work sample tests.

00:39:21.802 --> 00:39:23.010
I mean, that's exactly right.

00:39:23.010 --> 00:39:24.050
That's exactly right.

00:39:24.050 --> 00:39:27.870
And then only the very
last stage of the process,

00:39:27.870 --> 00:39:30.640
they actually see people
face-to-face and interview

00:39:30.640 --> 00:39:33.420
the last 10 or the last five.

00:39:33.420 --> 00:39:35.940
But using structure protocols.

00:39:35.940 --> 00:39:37.480
So I think it's
very, very appealing

00:39:37.480 --> 00:39:44.280
to think of the kinds of tests
that you could use to, in fact,

00:39:44.280 --> 00:39:46.520
predict future performance.

00:39:46.520 --> 00:39:48.770
Here's one thing where
the interview is helpful.

00:39:48.770 --> 00:39:52.142
And that is, of course, you will
probably think that right now,

00:39:52.142 --> 00:39:53.350
and you're, of course, right.

00:39:53.350 --> 00:39:55.822
In an interview, we're not just
evaluating a job candidate,

00:39:55.822 --> 00:39:58.030
but we're also telling
something about our companies,

00:39:58.030 --> 00:39:59.670
our organizations, right?

00:39:59.670 --> 00:40:02.855
So it's also a bit of a
sales pitch on my end.

00:40:02.855 --> 00:40:05.910
And that's OK as long as you're
done with your evaluations.

00:40:05.910 --> 00:40:06.410
Right?

00:40:06.410 --> 00:40:09.109
At the end, I'm very
comfortable and I did that too.

00:40:09.109 --> 00:40:11.150
I'm very comfortable to
have an unstructured part

00:40:11.150 --> 00:40:12.520
and talk about
synchronized swimming

00:40:12.520 --> 00:40:14.311
and talk about the
teaching load at Harvard

00:40:14.311 --> 00:40:17.822
and our wonderful students,
or whatever else it might be.

00:40:17.822 --> 00:40:22.715
That is different from me trying
to evaluate a job candidate.

00:40:22.715 --> 00:40:24.090
Just one more
thing, and then I'm

00:40:24.090 --> 00:40:25.548
going to call on
the next question.

00:40:25.548 --> 00:40:29.240
But the best evidence,
if you need evidence

00:40:29.240 --> 00:40:32.520
on kind of what interviews--
not maybe the best,

00:40:32.520 --> 00:40:35.910
but one that kind of
drove the point home to me

00:40:35.910 --> 00:40:38.430
was a bit of an eye
opener, comes out of Texas.

00:40:38.430 --> 00:40:40.860
So a few years back,
the state of Texas

00:40:40.860 --> 00:40:43.767
realized they didn't
have enough physicians.

00:40:43.767 --> 00:40:45.350
And so what they did
is they went back

00:40:45.350 --> 00:40:47.150
to their medical
schools and told them

00:40:47.150 --> 00:40:50.910
that they have to increase
the intake of new students

00:40:50.910 --> 00:40:52.560
by about a quarter.

00:40:52.560 --> 00:40:57.990
So just one medical school that
analyzed the data at Houston

00:40:57.990 --> 00:41:00.260
had already admitted
150 students,

00:41:00.260 --> 00:41:01.590
the top-ranked students.

00:41:01.590 --> 00:41:04.950
And now in May, very late
in the academic year,

00:41:04.950 --> 00:41:07.540
had to go back to the
rejected applicants

00:41:07.540 --> 00:41:10.685
and admit 50 of the
initially rejected people.

00:41:10.685 --> 00:41:12.810
In fact, the people they
had to admit that at point

00:41:12.810 --> 00:41:15.490
were ranked between 700 and 800.

00:41:15.490 --> 00:41:18.760
These are basically all
people who nobody else wanted.

00:41:18.760 --> 00:41:21.490
And they thought initially,
of course, catastrophe.

00:41:24.020 --> 00:41:27.100
Anyway, they will
never make it here.

00:41:27.100 --> 00:41:31.250
But, of course, it's turned out
into being a quasi-experiment,

00:41:31.250 --> 00:41:35.540
allowing research to follow
the 150 top-ranked students

00:41:35.540 --> 00:41:38.320
and the 50 lowly-ranked
students over many years

00:41:38.320 --> 00:41:42.004
to see whether that initial
evaluation system correlated

00:41:42.004 --> 00:41:43.420
in any way with
how they performed

00:41:43.420 --> 00:41:45.350
in medical school and
post-medical school.

00:41:45.350 --> 00:41:46.720
I wouldn't tell you, of course.

00:41:46.720 --> 00:41:48.620
You know where I'm going.

00:41:48.620 --> 00:41:50.330
Correlation, non-existent.

00:41:50.330 --> 00:41:54.880
Doesn't matter whether you were
initially 788 or number two,

00:41:54.880 --> 00:41:57.040
you did quite equally as
well in medical school

00:41:57.040 --> 00:41:58.160
and post-medical school.

00:41:58.160 --> 00:42:00.940
So something clearly was wrong
with their evaluation system.

00:42:00.940 --> 00:42:02.773
So then they're going
back to the evaluation

00:42:02.773 --> 00:42:04.880
system which heavily
turns out, was heavily

00:42:04.880 --> 00:42:07.780
based on interviews.

00:42:07.780 --> 00:42:10.730
About a third of
the final score was

00:42:10.730 --> 00:42:12.360
due to more
quantitative measures,

00:42:12.360 --> 00:42:14.820
such as previous grades,
letters of recommendation,

00:42:14.820 --> 00:42:17.760
work experience before you
went to medical school.

00:42:17.760 --> 00:42:21.230
And 2/3 were based
on these interviews.

00:42:21.230 --> 00:42:23.350
So if you take out
the interview score,

00:42:23.350 --> 00:42:24.880
then at least you
get a little bit

00:42:24.880 --> 00:42:27.790
of a correlation between
the quantitative scores

00:42:27.790 --> 00:42:28.770
and future performance.

00:42:28.770 --> 00:42:32.070
So the interview was
just making things worse.

00:42:32.070 --> 00:42:35.480
In fact, the authors
of the research paper

00:42:35.480 --> 00:42:38.010
concluded at the end
that a better mechanism

00:42:38.010 --> 00:42:42.160
would be to just use a lottery
rather than interviews.

00:42:42.160 --> 00:42:43.770
So that's just one study.

00:42:43.770 --> 00:42:44.880
There's many of those.

00:42:44.880 --> 00:42:47.420
But truly,
unstructured interviews

00:42:47.420 --> 00:42:51.320
are kind of really
discredited in social science.

00:42:51.320 --> 00:42:53.065
Yes, please.

00:42:53.065 --> 00:42:54.440
AUDIENCE: Well,
I'd like to start

00:42:54.440 --> 00:42:56.680
by saying that I do a lot
of interviewing myself.

00:42:56.680 --> 00:42:59.830
And if we could talk Google
into dropping interviews,

00:42:59.830 --> 00:43:01.040
I'd be thrilled.

00:43:03.920 --> 00:43:06.790
So one of the
issues that we have

00:43:06.790 --> 00:43:12.500
in hiring women for
engineering is the pipeline.

00:43:12.500 --> 00:43:16.600
We're hiring right now, and
just the resumes coming in.

00:43:16.600 --> 00:43:19.640
It's male, male, male,
male, male, female, male.

00:43:19.640 --> 00:43:20.560
You know?

00:43:20.560 --> 00:43:21.910
It's just very hard.

00:43:21.910 --> 00:43:23.550
So I'm wondering
if you've thought

00:43:23.550 --> 00:43:27.960
from a behavioral
psychology standpoint of how

00:43:27.960 --> 00:43:29.000
do we address that?

00:43:29.000 --> 00:43:31.326
Is there something
that we can do

00:43:31.326 --> 00:43:35.190
to persuade all the
young women out there

00:43:35.190 --> 00:43:41.000
that computers are fun, it's
a good job, it's well-paid?

00:43:41.000 --> 00:43:41.710
Join us.

00:43:41.710 --> 00:43:43.080
Come on in, the water's fine.

00:43:43.080 --> 00:43:43.788
IRIS BOHNET: Yes.

00:43:43.788 --> 00:43:44.950
Yeah, no, absolutely.

00:43:44.950 --> 00:43:46.370
And pipeline issues are real.

00:43:46.370 --> 00:43:49.640
And again, when I work
with organizations,

00:43:49.640 --> 00:43:52.590
I quite literally look
at what is the pipeline

00:43:52.590 --> 00:43:54.450
and when do we start
to see, for example,

00:43:54.450 --> 00:43:57.109
underproportional,
overproportional promotions

00:43:57.109 --> 00:43:58.900
which then would suggest
that maybe there's

00:43:58.900 --> 00:44:00.340
some bias going on.

00:44:00.340 --> 00:44:01.850
But the pipeline
issues are real.

00:44:01.850 --> 00:44:04.840
So last week I spoke at
two different conferences.

00:44:04.840 --> 00:44:06.620
One was Women in STEM.

00:44:06.620 --> 00:44:09.980
And I was actually,
I chaired a panel.

00:44:09.980 --> 00:44:13.360
And we had a number of very
interesting NGOs and start-ups

00:44:13.360 --> 00:44:14.870
working with schools.

00:44:14.870 --> 00:44:18.310
And the kind of things I learned
there were astonishing to me

00:44:18.310 --> 00:44:18.950
as well.

00:44:18.950 --> 00:44:23.090
That Algebra 2 is not taught
at most of our public schools

00:44:23.090 --> 00:44:24.180
in the United States.

00:44:24.180 --> 00:44:27.560
That most of our
teachers are not

00:44:27.560 --> 00:44:32.270
equipped to teach Algebra 2.

00:44:32.270 --> 00:44:34.150
So first of all,
many of our students

00:44:34.150 --> 00:44:36.310
aren't even equipped
with the kind of tools

00:44:36.310 --> 00:44:38.239
that companies like
Google, for example, need.

00:44:38.239 --> 00:44:40.530
That doesn't explain the
gender bias yet, but just more

00:44:40.530 --> 00:44:41.100
generally.

00:44:41.100 --> 00:44:44.760
And so what they're
doing is many of them,

00:44:44.760 --> 00:44:48.060
versions of providing
kind of help to teachers.

00:44:48.060 --> 00:44:52.070
So one project was
Science from Scientists.

00:44:52.070 --> 00:44:53.970
Just getting scientists
into schools,

00:44:53.970 --> 00:44:55.490
helping teachers
teaching science.

00:44:55.490 --> 00:44:59.820
Many of them were focused
on girls, primarily

00:44:59.820 --> 00:45:04.450
or exclusively, also provide
mentoring, sponsorship, support

00:45:04.450 --> 00:45:05.664
systems.

00:45:05.664 --> 00:45:06.830
So that's kind of one thing.

00:45:06.830 --> 00:45:09.450
The other conference I just
spoke at was on Saturday.

00:45:09.450 --> 00:45:13.470
It was Women in Math at Harvard.

00:45:13.470 --> 00:45:15.510
And again, I learned
some interesting things.

00:45:15.510 --> 00:45:19.220
And some are kind of really
ripe for some design changes.

00:45:19.220 --> 00:45:21.600
Some of you might have
studied mathematics

00:45:21.600 --> 00:45:25.480
and will remember that
it's super competitive.

00:45:25.480 --> 00:45:29.904
To get into the best
schools, like Harvard or MIT,

00:45:29.904 --> 00:45:31.320
apparently you
need to participate

00:45:31.320 --> 00:45:33.800
in lots of competitions
already in high school.

00:45:33.800 --> 00:45:37.900
And it turns out that much
research suggests that women

00:45:37.900 --> 00:45:39.480
do not like competitions.

00:45:39.480 --> 00:45:41.460
It's a bit similar
to willingness

00:45:41.460 --> 00:45:44.890
to take a risk, self-confidence.

00:45:44.890 --> 00:45:47.910
We tend to want our
work to be evaluated

00:45:47.910 --> 00:45:50.890
for what it is and not
necessarily participate

00:45:50.890 --> 00:45:52.860
in hyper competitive
environments.

00:45:52.860 --> 00:45:55.360
So lots of research
suggesting that that

00:45:55.360 --> 00:45:58.250
might actually
decrease the likelihood

00:45:58.250 --> 00:46:00.600
that women will choose
those kinds of fields.

00:46:00.600 --> 00:46:04.372
So I think it's a
combination of enabling

00:46:04.372 --> 00:46:07.170
boys and girls to do the work.

00:46:07.170 --> 00:46:10.280
And enabling our teachers to
teach the kinds of subjects,

00:46:10.280 --> 00:46:14.130
of providing role models,
mentorships, same sex teachers.

00:46:14.130 --> 00:46:17.150
So lots of evidence
suggesting that same sex

00:46:17.150 --> 00:46:19.560
teachers, in particular,
counter-stereotypical subjects,

00:46:19.560 --> 00:46:20.120
matter.

00:46:20.120 --> 00:46:22.411
So this, of course, for girls
will be math and science.

00:46:22.411 --> 00:46:24.020
For boys, reading and writing.

00:46:24.020 --> 00:46:25.920
So equally as serious.

00:46:25.920 --> 00:46:29.360
So all of those kind
of we need to attack.

00:46:29.360 --> 00:46:32.570
And then think about
kind of the designs

00:46:32.570 --> 00:46:36.370
that people are in, such as
the hyper competition that

00:46:36.370 --> 00:46:38.410
seems to be apparent
from mathematics,

00:46:38.410 --> 00:46:40.670
and whether that's really
necessary for people

00:46:40.670 --> 00:46:44.335
to succeed and become
good mathematicians.

00:46:44.335 --> 00:46:45.949
Thank you.

00:46:45.949 --> 00:46:46.490
AUDIENCE: Hi.

00:46:49.170 --> 00:46:52.100
We were lucky enough to
have Geena Davis talk

00:46:52.100 --> 00:46:53.600
at our headquarters
in Mountain View

00:46:53.600 --> 00:46:55.115
a couple weeks back
about-- all right,

00:46:55.115 --> 00:46:56.406
you know what I'm going to say.

00:46:56.406 --> 00:47:01.676
Her take on how the media can
help make the world better by,

00:47:01.676 --> 00:47:03.300
you know, you talked
about changing out

00:47:03.300 --> 00:47:04.540
the portraits in the hallway.

00:47:04.540 --> 00:47:07.330
And she's talking about,
can we change the things

00:47:07.330 --> 00:47:11.420
that we see in movies and
TV to help solve this issue.

00:47:11.420 --> 00:47:14.052
I was curious what your thoughts
on that, and whether you

00:47:14.052 --> 00:47:15.218
can say anything about that.

00:47:15.218 --> 00:47:16.490
IRIS BOHNET: Yeah.

00:47:16.490 --> 00:47:19.480
So she and I were at the same
place in California in October,

00:47:19.480 --> 00:47:20.570
spoke at the same place.

00:47:20.570 --> 00:47:23.840
And she might have
told you that as well.

00:47:23.840 --> 00:47:25.935
Some research that I
wasn't actually aware of,

00:47:25.935 --> 00:47:28.310
that when we represent
groups of people,

00:47:28.310 --> 00:47:31.530
then the typical group is
like one third of or a quarter

00:47:31.530 --> 00:47:34.830
female, and 2/3 or 3/4 male.

00:47:34.830 --> 00:47:38.180
So yes, I completely
agree with her.

00:47:38.180 --> 00:47:40.650
I think the evidence
on seeing is believing

00:47:40.650 --> 00:47:42.840
is really overwhelming.

00:47:42.840 --> 00:47:45.660
And kind of goes back to
the earlier question also.

00:47:45.660 --> 00:47:49.110
The kinds of books that our
kids read, the kind of cartoons

00:47:49.110 --> 00:47:49.960
that they watch.

00:47:49.960 --> 00:47:54.810
And that's why Rey, I mean, was
half a joke but half serious.

00:47:54.810 --> 00:47:58.100
It does matter what we
see, what people wear,

00:47:58.100 --> 00:48:02.100
how we represent
different characters,

00:48:02.100 --> 00:48:04.430
whether on the screen or
in a book or on our walls.

00:48:04.430 --> 00:48:07.220
So yes, I am completely,
completely aligned with her.

00:48:07.220 --> 00:48:07.920
Yeah, OK.

00:48:11.920 --> 00:48:13.880
OK, I just got the time.

00:48:13.880 --> 00:48:16.040
I think we have to wrap up.

00:48:16.040 --> 00:48:18.240
Thank you very much for coming.

