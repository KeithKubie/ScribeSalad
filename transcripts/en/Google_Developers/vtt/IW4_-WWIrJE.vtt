WEBVTT
Kind: captions
Language: en

00:00:00.339 --> 00:00:01.755
HUSAIN BENGALL:
Welcome, everyone.

00:00:01.755 --> 00:00:02.913
How are you doing?

00:00:02.913 --> 00:00:03.740
AUDIENCE: Great!

00:00:03.740 --> 00:00:05.130
HUSAIN BENGALL: Great.

00:00:05.130 --> 00:00:08.470
Let's talk about
engineering cinematic VR

00:00:08.470 --> 00:00:12.130
or, in other words, immersive
VR video experiences.

00:00:12.130 --> 00:00:14.832
I'm Husain, a product
manager working on VR video.

00:00:14.832 --> 00:00:16.790
And today we're going to
talk to you about some

00:00:16.790 --> 00:00:19.190
of the challenges
associated with the medium,

00:00:19.190 --> 00:00:22.660
focusing primarily on
delivery and playback.

00:00:22.660 --> 00:00:26.030
Let's start with why we
think VR video is important.

00:00:26.030 --> 00:00:30.180
VR video has the power to
immerse you and transport you

00:00:30.180 --> 00:00:33.290
to events, places,
and moments and make

00:00:33.290 --> 00:00:35.660
you feel like you're there.

00:00:35.660 --> 00:00:38.550
It's a kind of immersion
that traditional video

00:00:38.550 --> 00:00:41.740
on a rectangular screen
can't quite get you.

00:00:41.740 --> 00:00:43.810
For a start, there's too
much of the real world

00:00:43.810 --> 00:00:46.270
visible on the periphery.

00:00:46.270 --> 00:00:49.570
With VR video, your
entire field of view

00:00:49.570 --> 00:00:52.780
is occupied with
nothing but the content.

00:00:52.780 --> 00:00:54.960
If I were watching
this scene in VR,

00:00:54.960 --> 00:00:57.410
I might actually feel like
the horse was looking directly

00:00:57.410 --> 00:00:58.190
at me.

00:00:58.190 --> 00:01:02.385
That sort of immersion you
just can't get by watching TV.

00:01:02.385 --> 00:01:06.420
Now, in the real world
I can look around,

00:01:06.420 --> 00:01:08.770
and VR video enables that too.

00:01:12.210 --> 00:01:14.980
In order for it to feel like
I can reach out and touch

00:01:14.980 --> 00:01:17.960
that horse, though, I need
to be able to perceive

00:01:17.960 --> 00:01:20.790
a sense of depth
and scale, and that

00:01:20.790 --> 00:01:24.680
comes through stereoscopic
3D in which each eye sees

00:01:24.680 --> 00:01:27.254
a slightly different image.

00:01:27.254 --> 00:01:28.670
Take a look at the
horse and focus

00:01:28.670 --> 00:01:31.370
on its face and the
window right behind it,

00:01:31.370 --> 00:01:33.930
and watch as I toggle the
image your left eye would

00:01:33.930 --> 00:01:36.810
see with the image your
right eye would see.

00:01:36.810 --> 00:01:39.410
That small but
important difference

00:01:39.410 --> 00:01:42.550
is exactly how we perceive
depth in the real world.

00:01:42.550 --> 00:01:46.170
It's what makes near things look
near and far things look far.

00:01:46.170 --> 00:01:50.440
Adding this into 360 video
is incredibly immersive

00:01:50.440 --> 00:01:56.420
and it is almost as important
as the ability to look around.

00:01:56.420 --> 00:01:59.510
So far we've only
talked about video,

00:01:59.510 --> 00:02:02.210
and we've still come a long
way from that flat TV screen

00:02:02.210 --> 00:02:03.800
I showed you at the beginning.

00:02:03.800 --> 00:02:07.850
However, we haven't even
approached audio yet.

00:02:07.850 --> 00:02:09.830
In a stable I would
expect to be able to hear

00:02:09.830 --> 00:02:12.560
the horses around me,
and if we did that

00:02:12.560 --> 00:02:14.510
through traditional
audio effects

00:02:14.510 --> 00:02:17.270
it might feel incomplete.

00:02:17.270 --> 00:02:19.080
Here's why.

00:02:19.080 --> 00:02:22.450
Turn your head and
look around the room.

00:02:22.450 --> 00:02:25.060
You'll notice that
sounds around the room,

00:02:25.060 --> 00:02:28.980
like that fan for instance,
sound slightly different

00:02:28.980 --> 00:02:30.750
as you turn your head.

00:02:30.750 --> 00:02:33.620
And that actually enables
you, subconsciously,

00:02:33.620 --> 00:02:36.010
to be able to localize where
that sound was coming from

00:02:36.010 --> 00:02:37.820
even if your eyes were closed.

00:02:37.820 --> 00:02:40.470
We can recreate that
in VR through the use

00:02:40.470 --> 00:02:43.360
of spatial audio.

00:02:43.360 --> 00:02:47.760
Now let's add all of
this together-- 360 video

00:02:47.760 --> 00:02:50.480
with stereoscopic
3D, watched in VR

00:02:50.480 --> 00:02:53.950
so you can perceive
it, and spatial audio,

00:02:53.950 --> 00:02:56.300
and we think you have
all the elements needed

00:02:56.300 --> 00:03:00.630
for cinematic VR experiences,
or VR video, that

00:03:00.630 --> 00:03:03.390
can truly transport you.

00:03:03.390 --> 00:03:07.660
At Google our mission is
VR for everyone, which also

00:03:07.660 --> 00:03:11.680
means VR video for everyone.

00:03:11.680 --> 00:03:15.050
We wanted to find a way to
overcome the engineering

00:03:15.050 --> 00:03:17.710
challenges associated with
the medium in a way that

00:03:17.710 --> 00:03:20.510
makes these experiences
available to as many people as

00:03:20.510 --> 00:03:21.820
possible.

00:03:21.820 --> 00:03:26.820
We started by building Jump,
or VR video creation platform.

00:03:26.820 --> 00:03:29.190
Consists of a camera
spec that partners

00:03:29.190 --> 00:03:32.670
are helping bring to market,
an assembler that takes away

00:03:32.670 --> 00:03:35.220
all the pain of
manual stitching,

00:03:35.220 --> 00:03:38.100
and finally a way
to play back that VR

00:03:38.100 --> 00:03:40.890
video alongside spatial
audio on a platform

00:03:40.890 --> 00:03:43.780
that you all are
already familiar with.

00:03:43.780 --> 00:03:46.440
You can watch many of these
incredible experiences

00:03:46.440 --> 00:03:48.190
on YouTube today.

00:03:48.190 --> 00:03:49.479
But that's not all.

00:03:49.479 --> 00:03:51.020
Behind the scenes,
we've been working

00:03:51.020 --> 00:03:54.620
to make playback of these
types of videos even better.

00:03:54.620 --> 00:03:56.620
To talk to you about that,
I'd like to invite up

00:03:56.620 --> 00:03:58.099
on stage Andrew Scherkus.

00:03:58.099 --> 00:03:58.890
Come on up, Andrew.

00:04:05.230 --> 00:04:06.592
ANDREW SCHERKUS: Thanks, Husain.

00:04:06.592 --> 00:04:07.810
Hey, everyone.

00:04:07.810 --> 00:04:10.010
I am Andrew Scherkus
and I'm going

00:04:10.010 --> 00:04:12.810
to talk a little bit today
about some of the tech

00:04:12.810 --> 00:04:17.130
we've been building to really
create that immersive VR video

00:04:17.130 --> 00:04:19.300
experience.

00:04:19.300 --> 00:04:23.480
But what do I really mean when
I'm saying immersive VR video?

00:04:23.480 --> 00:04:29.150
Well, in our opinion, it comes
down to a few key ingredients.

00:04:29.150 --> 00:04:33.000
First of all, you want to
have as much resolution

00:04:33.000 --> 00:04:34.960
right in front of
where you're looking.

00:04:34.960 --> 00:04:37.350
This really creates that
first important ingredient

00:04:37.350 --> 00:04:40.230
of making it feel like
you're right there.

00:04:40.230 --> 00:04:44.500
But, as Hussein mentioned,
we're huge believers in stereo.

00:04:44.500 --> 00:04:47.740
And so we'll need to
double that resolution just

00:04:47.740 --> 00:04:51.000
to actually give you
that stereo imagery,

00:04:51.000 --> 00:04:53.550
because without stereo, we
don't think it really counts.

00:04:53.550 --> 00:04:55.800
It doesn't really feel
like you're there.

00:04:55.800 --> 00:04:59.640
And finally, and perhaps
most importantly,

00:04:59.640 --> 00:05:02.050
no buffering at all.

00:05:02.050 --> 00:05:04.360
It's one thing to have your
phone out and be waiting

00:05:04.360 --> 00:05:06.100
for like a video to load.

00:05:06.100 --> 00:05:10.330
When it's glued to your face,
it is a horrifying experience.

00:05:10.330 --> 00:05:12.500
So we need to be really
bandwidth conscious

00:05:12.500 --> 00:05:15.950
and worry about connectivity.

00:05:15.950 --> 00:05:19.750
So with that in mind, let's
walk through some steps

00:05:19.750 --> 00:05:23.400
on how would we actually
create immersive video.

00:05:23.400 --> 00:05:27.580
Well, we're working with
360 video, so, first of all,

00:05:27.580 --> 00:05:30.170
we have to pick some
way to represent.

00:05:30.170 --> 00:05:33.140
So we'll pick a
sphere-to-plane projection

00:05:33.140 --> 00:05:34.460
to represent our video.

00:05:34.460 --> 00:05:37.860
We'll increase the resolution
until we're fully filling up

00:05:37.860 --> 00:05:40.820
the screen in your optics so
that you can see everything

00:05:40.820 --> 00:05:42.740
in full fidelity.

00:05:42.740 --> 00:05:45.600
And then last we're
going to double it,

00:05:45.600 --> 00:05:48.460
because we love stereo.

00:05:48.460 --> 00:05:50.760
So let's dive into
that first piece,

00:05:50.760 --> 00:05:53.250
that sphere-to-plane projection.

00:05:53.250 --> 00:05:55.540
It turns out if you've
ever looked at a map,

00:05:55.540 --> 00:05:58.080
this is a pretty
familiar concept.

00:05:58.080 --> 00:06:01.890
Seen here is your good,
old-fashioned equirectangular

00:06:01.890 --> 00:06:03.220
projection of the Earth.

00:06:03.220 --> 00:06:06.890
And even though this has been
used for quite some time,

00:06:06.890 --> 00:06:10.230
it's actually a pretty
useful format today

00:06:10.230 --> 00:06:12.960
and is actually used
for 360 cameras,

00:06:12.960 --> 00:06:15.050
both for images and video alike.

00:06:15.050 --> 00:06:18.120
Here's a sample
frame and, sure, it's

00:06:18.120 --> 00:06:20.040
a little funky looking
at the top and bottom,

00:06:20.040 --> 00:06:23.710
but you get a good sense
for what's going on, right?

00:06:23.710 --> 00:06:25.500
I'm over there on
the left and I'm

00:06:25.500 --> 00:06:27.200
reaching towards the camera.

00:06:27.200 --> 00:06:29.830
And my fingers kind
of get all mushed up,

00:06:29.830 --> 00:06:31.470
but you get it, right?

00:06:31.470 --> 00:06:33.850
You can kind of figure
out what's going on.

00:06:33.850 --> 00:06:37.380
And 360 cameras produce
this format today,

00:06:37.380 --> 00:06:39.590
and streaming video
sites like YouTube

00:06:39.590 --> 00:06:41.530
accept this format today.

00:06:41.530 --> 00:06:44.860
You could even take this and
put it into a video editing app

00:06:44.860 --> 00:06:47.916
and you could kind of stitch
together a basic film.

00:06:47.916 --> 00:06:49.900
It kind of works.

00:06:49.900 --> 00:06:52.160
But let's do some back
of the envelope math

00:06:52.160 --> 00:06:55.870
to figure out just how big an
equirectangular video would

00:06:55.870 --> 00:06:59.570
have to be in order to give
you that first requirement

00:06:59.570 --> 00:07:02.060
of really filling up
the maximum resolution.

00:07:02.060 --> 00:07:05.710
So let's assume we
have a 1440p display.

00:07:05.710 --> 00:07:08.150
It's pretty common on
high-end smartphones.

00:07:08.150 --> 00:07:12.080
We'll divide it by 2
to get 1,280 pixels.

00:07:12.080 --> 00:07:14.330
We'll assume, just to
make the math easy,

00:07:14.330 --> 00:07:18.050
you're around 100 degrees
field of view for your headset.

00:07:18.050 --> 00:07:21.140
This gives us about
12.8 pixels per degree.

00:07:21.140 --> 00:07:24.500
Then you multiply it by the
sphere around the horizon,

00:07:24.500 --> 00:07:27.400
which is 360 by 180,
and this kind of

00:07:27.400 --> 00:07:29.640
gives us an approximation
to really hit

00:07:29.640 --> 00:07:31.970
that maximum resolution
we're talking about.

00:07:31.970 --> 00:07:34.630
So to put that in terms
of, like, megapixels

00:07:34.630 --> 00:07:39.667
just for comparison, this brings
us to 10.6 megapixels for mono.

00:07:39.667 --> 00:07:41.500
But, you know, I'm
really driving this home.

00:07:41.500 --> 00:07:44.150
We love stereo, so
we've got to double it.

00:07:44.150 --> 00:07:46.260
That puts us at 21.2.

00:07:46.260 --> 00:07:50.380
And, for reference,
a 4K stream is 8.3.

00:07:50.380 --> 00:07:53.310
So, we're way over budget.

00:07:53.310 --> 00:07:56.050
Not only is this going to be
really hard for a hardware

00:07:56.050 --> 00:07:58.590
decoder to do, it's
also really hard

00:07:58.590 --> 00:08:01.832
for like a multi-core
desktop workstation to do.

00:08:01.832 --> 00:08:03.540
And not only that,
but I feel like you're

00:08:03.540 --> 00:08:06.190
going to be seeing a lot
of that buffering spinner.

00:08:06.190 --> 00:08:08.292
So this is not
really going to work.

00:08:08.292 --> 00:08:10.250
This is where equirectangular
just like totally

00:08:10.250 --> 00:08:12.520
falls flat on its face.

00:08:12.520 --> 00:08:15.310
But, luckily, we don't
have to stick to it, right?

00:08:15.310 --> 00:08:17.092
Once you upload it
to, like, YouTube,

00:08:17.092 --> 00:08:18.300
we can work with that, right?

00:08:18.300 --> 00:08:21.200
We can work with
these big files.

00:08:21.200 --> 00:08:24.520
To cover sort of why
projections are challenging,

00:08:24.520 --> 00:08:26.390
it really boils down
to the math behind

00:08:26.390 --> 00:08:29.410
sphere-to-plane projections.

00:08:29.410 --> 00:08:32.100
If I were to tell
you to take an orange

00:08:32.100 --> 00:08:36.380
and unpeel it and try to make
it look like a rectangle,

00:08:36.380 --> 00:08:39.490
you actually can't do it
without flattening and squishing

00:08:39.490 --> 00:08:42.480
and stretching that peel.

00:08:42.480 --> 00:08:45.440
So what that means
is the visual quality

00:08:45.440 --> 00:08:47.250
starts to change
based on where you've

00:08:47.250 --> 00:08:50.230
stretched in order to
make that rectangle.

00:08:50.230 --> 00:08:53.260
So if the user looks in some
areas, it'll look better,

00:08:53.260 --> 00:08:57.060
and when they look in other
areas, it looks worse.

00:08:57.060 --> 00:08:58.740
So when we looked
at this, we really

00:08:58.740 --> 00:09:02.620
wanted to consider all the
best and worst qualities

00:09:02.620 --> 00:09:05.000
of any given projection.

00:09:05.000 --> 00:09:07.210
Let's go back to Earth.

00:09:07.210 --> 00:09:12.810
So there is a huge,
glaring, obvious clue

00:09:12.810 --> 00:09:16.900
on the map of any Earth that
kind of really gives you

00:09:16.900 --> 00:09:19.730
a hint on where the
best quality might be,

00:09:19.730 --> 00:09:20.950
and it's at the poles, right?

00:09:20.950 --> 00:09:23.180
Antarctica is
ginormous but it's not

00:09:23.180 --> 00:09:25.450
that ginormous of a continent.

00:09:25.450 --> 00:09:27.960
Correspondingly, the
worst visual quality's

00:09:27.960 --> 00:09:30.390
along the equator.

00:09:30.390 --> 00:09:34.540
If we consider 360 imagery, this
doesn't make a lot of sense,

00:09:34.540 --> 00:09:35.330
right?

00:09:35.330 --> 00:09:37.850
My fingers are getting
a lot of pixels

00:09:37.850 --> 00:09:40.370
and the ceiling's getting
a ton of pixels too,

00:09:40.370 --> 00:09:42.550
but where everyone
is standing, they're

00:09:42.550 --> 00:09:44.630
not getting their
fair share of pixels.

00:09:44.630 --> 00:09:47.120
That's not a great solution.

00:09:47.120 --> 00:09:48.940
So going back to
what I mentioned

00:09:48.940 --> 00:09:53.105
earlier, what if we use
something else, such as cube

00:09:53.105 --> 00:09:53.606
maps?

00:09:53.606 --> 00:09:56.146
You may have seen this in games
any time you've walked around

00:09:56.146 --> 00:09:58.550
and you wanted to have
the sky appear something

00:09:58.550 --> 00:10:01.370
or to have
environmental effects.

00:10:01.370 --> 00:10:03.850
You'll immediately
notice that Antarctica,

00:10:03.850 --> 00:10:07.830
looking a lot more regular sized
compared to everything else.

00:10:07.830 --> 00:10:09.800
This is already a
great first clue

00:10:09.800 --> 00:10:13.480
that, hey, things might be
a little bit more uniform.

00:10:13.480 --> 00:10:15.520
But it starts to
get tricky, right?

00:10:15.520 --> 00:10:18.750
With equirectangular
we were really easily

00:10:18.750 --> 00:10:21.270
able to figure out that,
OK, the top and the bottom

00:10:21.270 --> 00:10:24.240
gets the most pixels and
the middle gets the least.

00:10:24.240 --> 00:10:28.140
How do we analyze
projections such as cube map?

00:10:28.140 --> 00:10:31.760
And, expanding upon that, how
do we analyze any arbitrary

00:10:31.760 --> 00:10:33.220
projection?

00:10:33.220 --> 00:10:36.180
So we built some analysis tools
to really deeply understand

00:10:36.180 --> 00:10:37.469
this problem.

00:10:37.469 --> 00:10:39.010
This is the spectrum
that we're going

00:10:39.010 --> 00:10:42.160
to use to sort of describe
these projections.

00:10:42.160 --> 00:10:45.255
On one end, we've got too
much upscaling going on.

00:10:45.255 --> 00:10:46.880
This means that if
someone were to look

00:10:46.880 --> 00:10:50.010
in a region that's kind of
more reddish or orangeish,

00:10:50.010 --> 00:10:51.810
it'll be blurry.

00:10:51.810 --> 00:10:53.650
On the other end
of the spectrum,

00:10:53.650 --> 00:10:56.750
we have too much downscaling,
which typically isn't always

00:10:56.750 --> 00:10:57.780
a bad thing.

00:10:57.780 --> 00:11:00.680
But if you think about it
in the sense of bandwidth

00:11:00.680 --> 00:11:03.120
and trying to really, like,
nail the right quality

00:11:03.120 --> 00:11:05.890
without serving too
much, you don't actually

00:11:05.890 --> 00:11:07.790
want too much
downscaling going on.

00:11:07.790 --> 00:11:09.570
It's a wasteful thing.

00:11:09.570 --> 00:11:14.750
So there is a sweet spot and
it's for a given resolution

00:11:14.750 --> 00:11:18.182
for a given hardware
display and optics combo.

00:11:18.182 --> 00:11:20.140
Let's take a look at what
equirectangular looks

00:11:20.140 --> 00:11:22.050
like with our tool.

00:11:22.050 --> 00:11:24.340
Right off the bat, we
see at the top and bottom

00:11:24.340 --> 00:11:25.950
we've got that blue.

00:11:25.950 --> 00:11:27.050
I'm sure it looks great.

00:11:27.050 --> 00:11:29.860
I'm sure my feet look
wonderful, but that's not really

00:11:29.860 --> 00:11:32.130
the point of 360 video.

00:11:32.130 --> 00:11:34.610
If we were to look at
cube maps in this tool,

00:11:34.610 --> 00:11:36.690
we start to see a more
interesting, you know,

00:11:36.690 --> 00:11:38.290
colorful picture.

00:11:38.290 --> 00:11:41.242
And, ironically enough,
we represent these images

00:11:41.242 --> 00:11:42.950
in equirectangular
format because they're

00:11:42.950 --> 00:11:45.020
just human-friendly.

00:11:45.020 --> 00:11:48.200
You'll start to notice that the
best visual quality when using

00:11:48.200 --> 00:11:51.050
cube maps are along the edges.

00:11:51.050 --> 00:11:55.660
This means that if you took
a 360 video in a cube map

00:11:55.660 --> 00:11:57.480
and I were to try
to quiz you on,

00:11:57.480 --> 00:12:00.100
hey, where to look
for the best quality,

00:12:00.100 --> 00:12:02.430
you would actually tilt
your head to the left

00:12:02.430 --> 00:12:03.590
and tilt it up.

00:12:03.590 --> 00:12:05.450
And you would look
in one of the corners

00:12:05.450 --> 00:12:07.283
because that's actually
where the best image

00:12:07.283 --> 00:12:08.830
quality is hiding.

00:12:08.830 --> 00:12:13.490
Correspondingly, the
worst areas of a cube map

00:12:13.490 --> 00:12:16.544
are right in the
middle of each face.

00:12:16.544 --> 00:12:18.460
When we started looking
at pictures like this,

00:12:18.460 --> 00:12:21.470
we were like, I
wonder if there's

00:12:21.470 --> 00:12:23.690
something else we could use.

00:12:23.690 --> 00:12:25.840
And we did some digging
and it turns out

00:12:25.840 --> 00:12:29.640
that people have been looking
at projections for a long time.

00:12:29.640 --> 00:12:32.300
And there was one that
was used with actual space

00:12:32.300 --> 00:12:37.770
imagery in the '70s and we
called it equiangular cube map.

00:12:37.770 --> 00:12:39.145
The basic concept
is just to take

00:12:39.145 --> 00:12:41.561
some of those, like, extra
pixels that were in the corners

00:12:41.561 --> 00:12:43.070
and sides and just
kind of spread

00:12:43.070 --> 00:12:44.610
them around a little bit more.

00:12:44.610 --> 00:12:47.530
We end up with actually a much
more uniform representation

00:12:47.530 --> 00:12:49.900
of the full sphere.

00:12:49.900 --> 00:12:52.400
When we test this with
users, every single person

00:12:52.400 --> 00:12:53.560
was able to tell.

00:12:53.560 --> 00:12:55.760
They're like, yep,
that looks better.

00:12:55.760 --> 00:12:58.986
I don't know why, but
I just like it better.

00:12:58.986 --> 00:13:00.470
That made us feel pretty good.

00:13:00.470 --> 00:13:03.710
So it doesn't quite get
us there though, right?

00:13:03.710 --> 00:13:06.610
We've been only looking at
very uniform representations,

00:13:06.610 --> 00:13:08.690
very uniform projections.

00:13:08.690 --> 00:13:10.300
And this is a pretty
good solution.

00:13:10.300 --> 00:13:13.500
You can use this
for images or video

00:13:13.500 --> 00:13:18.030
to get that really nice, uniform
resolution everywhere you look,

00:13:18.030 --> 00:13:20.280
and it's a good candidate
for offline or unreliable

00:13:20.280 --> 00:13:21.549
bandwidth.

00:13:21.549 --> 00:13:23.340
You only need to create
one of these videos

00:13:23.340 --> 00:13:26.690
and just buffer it for
as long as you want.

00:13:26.690 --> 00:13:28.300
But it doesn't hit
that sweet spot

00:13:28.300 --> 00:13:30.200
we were talking about earlier.

00:13:30.200 --> 00:13:32.630
So how are we
going to get there?

00:13:32.630 --> 00:13:34.890
Where can we really
just leverage

00:13:34.890 --> 00:13:37.660
the user gaze and the
user view direction

00:13:37.660 --> 00:13:39.630
to deliver as many pixels
as possible to where

00:13:39.630 --> 00:13:41.080
they're looking?

00:13:41.080 --> 00:13:42.840
With projections,
you can actually

00:13:42.840 --> 00:13:45.570
represent them as 3D geometry.

00:13:45.570 --> 00:13:48.630
So with equirectangular,
you can map it

00:13:48.630 --> 00:13:51.360
to a tessellated 3D sphere.

00:13:51.360 --> 00:13:54.720
With a regular cube map,
you can map it to a cube.

00:13:54.720 --> 00:13:56.400
Kind of makes sense.

00:13:56.400 --> 00:13:58.900
And with something like
equiangular cube map,

00:13:58.900 --> 00:14:01.854
you can map that to
a tessellated cube.

00:14:01.854 --> 00:14:03.270
But what if we
went with something

00:14:03.270 --> 00:14:04.870
a little bit more exotic?

00:14:04.870 --> 00:14:07.630
What would that look like
in our analysis tool?

00:14:07.630 --> 00:14:08.670
We were kind of curious.

00:14:08.670 --> 00:14:10.940
So, for fun, let's just
take a look at pyramid.

00:14:13.640 --> 00:14:16.880
Right off the bat,
it's pretty colorful.

00:14:16.880 --> 00:14:19.500
And you'll notice that the
best visual quality is right

00:14:19.500 --> 00:14:21.200
smack dab in the middle.

00:14:21.200 --> 00:14:22.900
This is pretty awesome.

00:14:22.900 --> 00:14:25.860
And that things kind of
just gradually taper off,

00:14:25.860 --> 00:14:28.750
and that's not
necessarily a bad thing.

00:14:28.750 --> 00:14:31.210
This is a simulation of what
that original frame would

00:14:31.210 --> 00:14:33.420
look like.

00:14:33.420 --> 00:14:35.410
I'm nice and clear.

00:14:35.410 --> 00:14:38.000
My co-presenter
Dillon, we would have

00:14:38.000 --> 00:14:41.560
to generate a new video to
actually sort of represent him

00:14:41.560 --> 00:14:45.390
because, in the previous
version, he was kind of blurry.

00:14:45.390 --> 00:14:49.420
And, same, we'd have to generate
a new video with a new pyramid

00:14:49.420 --> 00:14:54.080
if we wanted to focus on the
group of people to the right.

00:14:54.080 --> 00:14:58.250
So we like to call this class
of projections directional

00:14:58.250 --> 00:14:59.380
projections.

00:14:59.380 --> 00:15:02.590
They're very directed
towards a particular region

00:15:02.590 --> 00:15:04.750
and they place the
highest resolution

00:15:04.750 --> 00:15:06.990
within a particular
field of view.

00:15:06.990 --> 00:15:08.740
On the flip side, like
I just illustrated,

00:15:08.740 --> 00:15:10.670
it does require
multiple versions.

00:15:10.670 --> 00:15:12.920
If there are multiple
regions of interest,

00:15:12.920 --> 00:15:16.910
you have to generate
multiple videos.

00:15:16.910 --> 00:15:20.100
And to keep up with
that immersion,

00:15:20.100 --> 00:15:23.260
we really want to have low
latency and minimal buffering,

00:15:23.260 --> 00:15:25.660
because if it takes
a couple seconds

00:15:25.660 --> 00:15:29.040
and I'm seeing blurriness
over here, that kind of kills

00:15:29.040 --> 00:15:30.460
the whole experience.

00:15:30.460 --> 00:15:33.860
So to kind of summarize all of
this talk about projections,

00:15:33.860 --> 00:15:36.310
we really feel like
there isn't necessarily

00:15:36.310 --> 00:15:37.960
a silver bullet here.

00:15:37.960 --> 00:15:41.100
It really depends on the
content, where people

00:15:41.100 --> 00:15:43.940
are looking, your
bandwidth, and actually

00:15:43.940 --> 00:15:45.930
the characteristics
of the hardware.

00:15:45.930 --> 00:15:48.970
So with that in mind,
it really kind of starts

00:15:48.970 --> 00:15:50.460
to make you think
about, well, how

00:15:50.460 --> 00:15:52.410
do you tie this into
existing video streaming

00:15:52.410 --> 00:15:55.130
sites like YouTube today?

00:15:55.130 --> 00:15:57.840
And we found it
really helpful to look

00:15:57.840 --> 00:16:01.900
at how this was solved with
multiple resolution streams,

00:16:01.900 --> 00:16:04.270
or adaptive streaming.

00:16:04.270 --> 00:16:07.650
Here's a super simple example
with just a standard definition

00:16:07.650 --> 00:16:10.340
and high definition stream.

00:16:10.340 --> 00:16:13.830
Based on your bandwidth
or your device,

00:16:13.830 --> 00:16:16.820
you would either get switched
up to a high definition stream

00:16:16.820 --> 00:16:18.910
or back to a standard
definition stream.

00:16:18.910 --> 00:16:23.590
And if your device actually
can't even play HD content,

00:16:23.590 --> 00:16:25.510
it also doesn't really
necessarily mean

00:16:25.510 --> 00:16:28.300
it makes a lot of sense
to serve you HD content.

00:16:28.300 --> 00:16:30.530
And same with if your
bandwidth all of a sudden start

00:16:30.530 --> 00:16:32.620
to get a little
unreliable, we'd want

00:16:32.620 --> 00:16:35.390
to switch you back because
we don't like buffering.

00:16:35.390 --> 00:16:37.240
Adaptive streaming's a
really great solution

00:16:37.240 --> 00:16:41.250
at minimizing any
instances of buffering.

00:16:41.250 --> 00:16:43.560
With this model in mind, we
actually kind of applied it

00:16:43.560 --> 00:16:46.270
to our whole notion around there
not being a single projection

00:16:46.270 --> 00:16:51.570
to rule them all, and we call it
adaptive projection streaming.

00:16:51.570 --> 00:16:54.040
We really notice that there
are instances where you really

00:16:54.040 --> 00:16:58.350
do want that uniform projection,
notably to avoid buffering.

00:16:58.350 --> 00:17:00.230
But there are also
instances where you really

00:17:00.230 --> 00:17:03.260
want that sharp focus in a
particular area, whether it's

00:17:03.260 --> 00:17:05.790
due to the content or whether
it's just due to the user

00:17:05.790 --> 00:17:08.369
just looking in a
particular direction.

00:17:08.369 --> 00:17:10.310
We actually find
tying things together

00:17:10.310 --> 00:17:13.569
this way makes it really easy
to reason about and solve

00:17:13.569 --> 00:17:17.310
a lot of different use cases
because, again, we really care

00:17:17.310 --> 00:17:20.270
about delivering
as much of VR video

00:17:20.270 --> 00:17:23.530
to as many people as possible.

00:17:23.530 --> 00:17:26.880
So we're actually building
this in YouTube today.

00:17:26.880 --> 00:17:29.740
And even if a lot of this kind
of projection stuff was like,

00:17:29.740 --> 00:17:31.615
oh, I really don't want
to deal with pyramids

00:17:31.615 --> 00:17:33.410
or this echo-angular
something or other,

00:17:33.410 --> 00:17:35.100
like, that's totally
fine because we

00:17:35.100 --> 00:17:37.060
have equirectangular.

00:17:37.060 --> 00:17:39.070
It's going to be here
for, like, awhile, right?

00:17:39.070 --> 00:17:40.790
The map didn't go anywhere.

00:17:40.790 --> 00:17:43.382
You can upload your
content to YouTube.

00:17:43.382 --> 00:17:44.840
We'll kind of take
care of the rest

00:17:44.840 --> 00:17:47.560
and make it look the right
kind of shape and size

00:17:47.560 --> 00:17:50.770
to deliver the goal
of really immersive VR

00:17:50.770 --> 00:17:53.420
video for everyone.

00:17:53.420 --> 00:17:57.074
That only really covers
the video aspect though.

00:17:57.074 --> 00:17:58.490
I'm going to bring
up Dillon here.

00:17:58.490 --> 00:18:00.781
He's going to talk to us a
little bit more about audio.

00:18:06.180 --> 00:18:07.594
DILLON COWER: Thanks, Andrew.

00:18:07.594 --> 00:18:09.010
So Andrew talked
to you about what

00:18:09.010 --> 00:18:12.080
we're working on to improve the
visual quality of cinematic VR

00:18:12.080 --> 00:18:13.330
experiences.

00:18:13.330 --> 00:18:16.007
That's only 50%
of the experience.

00:18:16.007 --> 00:18:18.340
So today I'm going to be
talking to you about what we're

00:18:18.340 --> 00:18:21.200
doing to bring awesome
spatial audio to cinematic VR

00:18:21.200 --> 00:18:22.290
experiences for everyone.

00:18:25.220 --> 00:18:27.520
Our ears are highly
complex instruments,

00:18:27.520 --> 00:18:29.890
taking in a vast amount
of information every point

00:18:29.890 --> 00:18:32.120
in time.

00:18:32.120 --> 00:18:34.905
And as such, they're a critical
tool for VR storytelling.

00:18:37.640 --> 00:18:39.860
VR needs spatial audio.

00:18:39.860 --> 00:18:42.570
We really believe that.

00:18:42.570 --> 00:18:44.250
So what is spatial audio?

00:18:44.250 --> 00:18:46.210
What it boils down
to is audio that

00:18:46.210 --> 00:18:49.817
fully represents the sound
space around the listener.

00:18:49.817 --> 00:18:52.150
It allows the listener to
answer a couple of questions--

00:18:52.150 --> 00:18:57.380
where is the sound coming from
and what environment am I in?

00:18:57.380 --> 00:19:00.870
So spatial audio should
have three properties.

00:19:00.870 --> 00:19:03.640
It should have a
location in space,

00:19:03.640 --> 00:19:05.700
it should capture
the environment,

00:19:05.700 --> 00:19:08.585
and finally it should
immerse the listener.

00:19:08.585 --> 00:19:09.960
At the end of the
day, you should

00:19:09.960 --> 00:19:11.710
feel like you've
teleported somewhere else

00:19:11.710 --> 00:19:15.310
and everything should look
and sound correct and amazing.

00:19:15.310 --> 00:19:17.450
We really think that
you can't feel presence

00:19:17.450 --> 00:19:18.675
without hearing it.

00:19:18.675 --> 00:19:21.050
So let's think for a second
about the bare minimum amount

00:19:21.050 --> 00:19:23.424
of information that we would
need to stream to the client

00:19:23.424 --> 00:19:25.160
for them to hear special audio.

00:19:25.160 --> 00:19:28.760
Well, humans have two ears.

00:19:28.760 --> 00:19:30.555
And in VR, we're
generally using headphones

00:19:30.555 --> 00:19:33.545
to listen to the audio.

00:19:33.545 --> 00:19:34.920
So maybe we can
just stream that.

00:19:34.920 --> 00:19:37.530
We can stream two
channels of audio.

00:19:40.250 --> 00:19:42.770
So, in theory, you could
store a complex representation

00:19:42.770 --> 00:19:45.390
of the spatial audio
seen on the server,

00:19:45.390 --> 00:19:48.010
and then render that in
real time on the server

00:19:48.010 --> 00:19:51.230
depending on where the
listener is viewing,

00:19:51.230 --> 00:19:52.689
and then stream
that to the client.

00:19:52.689 --> 00:19:54.521
And this is a pretty
well-understood problem

00:19:54.521 --> 00:19:56.020
from the streaming
point of view.

00:19:56.020 --> 00:19:59.250
It's equivalent to
streaming stereo audio.

00:19:59.250 --> 00:20:01.380
However, in reality,
this doesn't work out.

00:20:01.380 --> 00:20:04.580
There's latency everywhere in
the stack and audio encoding,

00:20:04.580 --> 00:20:07.325
audio decoding, audio
output, network transmission,

00:20:07.325 --> 00:20:08.710
and so on.

00:20:08.710 --> 00:20:11.295
What this adds up to is
just a poorer VR experience.

00:20:14.280 --> 00:20:16.280
So we know that we need
to find a representation

00:20:16.280 --> 00:20:18.427
for spatial audio to
send to the client.

00:20:18.427 --> 00:20:20.510
We know that we can't just
pre-render two channels

00:20:20.510 --> 00:20:23.150
of audio and send that.

00:20:23.150 --> 00:20:27.010
We need to represent
the full audio scene.

00:20:27.010 --> 00:20:29.600
So let's start off by taking a
look at surround sound audio,

00:20:29.600 --> 00:20:32.520
5.1, 7.1, traditional
speaker layouts.

00:20:32.520 --> 00:20:34.200
And surround sound
audio is based

00:20:34.200 --> 00:20:36.720
around this idea of each
channel of audio corresponding

00:20:36.720 --> 00:20:38.790
to a physical speaker.

00:20:38.790 --> 00:20:41.080
So for 5.1 audio,
you'll have six channels

00:20:41.080 --> 00:20:44.630
of audio for six
physical speakers--

00:20:44.630 --> 00:20:47.240
front left, front right,
center, and so on.

00:20:47.240 --> 00:20:50.270
However, surround sound is built
for front-facing experiences

00:20:50.270 --> 00:20:52.810
like home cinema or theaters.

00:20:52.810 --> 00:20:54.561
And this is great
for that application

00:20:54.561 --> 00:20:56.310
where most of the
action's in front of you

00:20:56.310 --> 00:20:59.405
and there's not so
much behind you.

00:20:59.405 --> 00:21:01.030
And so the speaker
layouts are oriented

00:21:01.030 --> 00:21:03.380
toward this, with more
speakers in the front

00:21:03.380 --> 00:21:04.670
and fewer in the back.

00:21:04.670 --> 00:21:06.740
However, for VR
this isn't ideal.

00:21:06.740 --> 00:21:09.090
We care just as much
about audio behind you

00:21:09.090 --> 00:21:11.050
as we do audio in front of you.

00:21:11.050 --> 00:21:13.450
And, in addition to
that, speaker layouts

00:21:13.450 --> 00:21:16.720
for surround sound audio are
generally pretty horizontal.

00:21:16.720 --> 00:21:18.930
There's not a lot of
vertical resolution there,

00:21:18.930 --> 00:21:23.860
and in 360 video we care about
everything in the sphere.

00:21:23.860 --> 00:21:26.340
So let's now talk about
object-based audio.

00:21:26.340 --> 00:21:28.460
And the idea here is
to represent everything

00:21:28.460 --> 00:21:30.170
in the same, for each source.

00:21:30.170 --> 00:21:32.150
We're going to take
mono audio along

00:21:32.150 --> 00:21:34.020
with metadata
about that source--

00:21:34.020 --> 00:21:36.230
its position,
size, speed, shape,

00:21:36.230 --> 00:21:38.720
and so on, as well
as characteristics

00:21:38.720 --> 00:21:41.160
about the environment, such
as reverb, reflections,

00:21:41.160 --> 00:21:45.780
geometry as complex as we want.

00:21:45.780 --> 00:21:47.740
But this sounds like an
audio engine for games,

00:21:47.740 --> 00:21:49.810
and it basically
amounts to that.

00:21:49.810 --> 00:21:52.320
And this is great for
interactive experiences.

00:21:52.320 --> 00:21:53.570
We're depending on user input.

00:21:53.570 --> 00:21:55.445
You want to change the
way that things sound,

00:21:55.445 --> 00:21:57.170
you might want to
play a sound over here

00:21:57.170 --> 00:21:59.253
or you might want to
attenuate something depending

00:21:59.253 --> 00:22:01.140
on where the viewer's looking.

00:22:01.140 --> 00:22:05.149
And this is also great for
post-production and mastering

00:22:05.149 --> 00:22:07.190
where you want the highest
fidelity spatial audio

00:22:07.190 --> 00:22:08.680
representation you can have.

00:22:11.660 --> 00:22:14.590
Now, for streaming,
we love predictability

00:22:14.590 --> 00:22:17.690
and we love consistency
in data rate.

00:22:17.690 --> 00:22:20.890
It allows us to adapt better
to the user's bandwidth

00:22:20.890 --> 00:22:23.311
and, in general,
we just like that.

00:22:23.311 --> 00:22:25.060
And for VR as well,
we like predictability

00:22:25.060 --> 00:22:28.100
and we like consistency
in performance.

00:22:28.100 --> 00:22:33.000
We want each of our frame times
to be as close as possible.

00:22:33.000 --> 00:22:34.637
However, with
object-based audio,

00:22:34.637 --> 00:22:36.595
as the number of sources
in the scene increases

00:22:36.595 --> 00:22:40.184
or as the environment
changes, more data is required

00:22:40.184 --> 00:22:41.600
and this isn't
good for streaming.

00:22:44.620 --> 00:22:47.140
So finally let's take
a look at ambisonics.

00:22:47.140 --> 00:22:51.010
And ambisonics is a full sphere
spatial audio representation

00:22:51.010 --> 00:22:54.760
dating back to the '70s, where
it was far ahead of its time.

00:22:54.760 --> 00:22:56.830
And the idea behind
ambisonics is

00:22:56.830 --> 00:22:58.890
opposite to object-based audio.

00:22:58.890 --> 00:23:02.550
Object-based audio, you store
everything about the scene.

00:23:02.550 --> 00:23:04.710
With ambisonics, you're
collapsing that down

00:23:04.710 --> 00:23:06.860
into an approximation
of the scene.

00:23:06.860 --> 00:23:08.900
So you don't want to
store the entire scene,

00:23:08.900 --> 00:23:11.530
you just want to store some
kind of approximation of it.

00:23:11.530 --> 00:23:13.280
And this is great for
streaming because it

00:23:13.280 --> 00:23:16.562
hits those points of
consistency and predictability.

00:23:16.562 --> 00:23:18.770
So let's take a look at
first-order ambisonics, which

00:23:18.770 --> 00:23:21.870
is the initial
version of ambisonics.

00:23:21.870 --> 00:23:23.780
The idea is similar
to mid-side stereo,

00:23:23.780 --> 00:23:25.970
which is a technique used
in the audio industry.

00:23:25.970 --> 00:23:28.440
And the idea behind
mid-side stereo,

00:23:28.440 --> 00:23:30.660
you take two
microphones and then

00:23:30.660 --> 00:23:32.790
you sum them in different
ways to create a narrow

00:23:32.790 --> 00:23:35.750
or a wide stereo image.

00:23:35.750 --> 00:23:38.340
So first-order ambisonics
can be seen as an extension

00:23:38.340 --> 00:23:40.570
of this in three dimensions.

00:23:40.570 --> 00:23:42.210
Instead of two
microphones, we're

00:23:42.210 --> 00:23:44.430
talking about four
microphones now--

00:23:44.430 --> 00:23:46.310
an omnidirectional
microphone and three

00:23:46.310 --> 00:23:48.562
figure-eight microphones.

00:23:48.562 --> 00:23:50.270
Then you combine these
in different ways,

00:23:50.270 --> 00:23:53.530
similar to mid-side stereo,
to create virtual microphones

00:23:53.530 --> 00:23:54.720
on the sphere.

00:23:54.720 --> 00:23:56.680
So we can hear audio as
it is in front of you,

00:23:56.680 --> 00:23:58.221
to the right of you,
or anywhere else

00:23:58.221 --> 00:24:01.620
and we can smoothly rotate
between these positions.

00:24:01.620 --> 00:24:03.860
And ambisonics is also
based on a concept

00:24:03.860 --> 00:24:05.740
called spherical harmonics.

00:24:05.740 --> 00:24:07.365
And the idea behind
spherical harmonics

00:24:07.365 --> 00:24:10.400
is we're trying to approximate
a spherical function, a function

00:24:10.400 --> 00:24:12.070
on the surface of a sphere.

00:24:12.070 --> 00:24:13.520
So each of these
morph spheres you

00:24:13.520 --> 00:24:16.470
see is called a
spherical harmonic,

00:24:16.470 --> 00:24:18.630
and each one of
those maps directly

00:24:18.630 --> 00:24:20.310
to an ambisonic audio channel.

00:24:20.310 --> 00:24:23.180
That's a channel
of ambisonic audio.

00:24:23.180 --> 00:24:25.750
And the lobes that
you see, the shapes,

00:24:25.750 --> 00:24:28.375
they're similar to microphone
directivity patterns.

00:24:28.375 --> 00:24:30.280
The microphone
directivity patterns

00:24:30.280 --> 00:24:32.280
tell us the sensitivity
of a microphone

00:24:32.280 --> 00:24:35.060
to sound coming from
different directions.

00:24:35.060 --> 00:24:36.820
So the omnidirectional
harmonic here

00:24:36.820 --> 00:24:39.870
is sensitive to sound
uniformly from all directions,

00:24:39.870 --> 00:24:41.479
whereas the left-right
component is

00:24:41.479 --> 00:24:43.020
more sensitive to
sound from the left

00:24:43.020 --> 00:24:45.760
and right than it is from
the front-back or the top

00:24:45.760 --> 00:24:46.680
and bottom.

00:24:46.680 --> 00:24:47.880
So just to recap.

00:24:47.880 --> 00:24:50.020
The idea behind
ambisonics is we're

00:24:50.020 --> 00:24:52.890
going to take the entire
spatial audio scene, no matter

00:24:52.890 --> 00:24:55.320
its complexity, no matter
the number of sources,

00:24:55.320 --> 00:24:56.855
no matter what the
environment is.

00:24:56.855 --> 00:24:59.910
Then we're going to collapse
that down into an approximation

00:24:59.910 --> 00:25:02.160
and we're going to break
that into separate components

00:25:02.160 --> 00:25:04.500
to represent that approximation.

00:25:04.500 --> 00:25:06.440
Then in real time
on the client, we're

00:25:06.440 --> 00:25:08.350
going to combine
that approximation

00:25:08.350 --> 00:25:11.100
to create virtual
microphones on the sphere.

00:25:11.100 --> 00:25:13.910
And this allows us to hear
audio in any direction

00:25:13.910 --> 00:25:18.600
so we can respond to viewer
head rotation in real time.

00:25:18.600 --> 00:25:21.207
So first-order ambisonics
is pretty great.

00:25:21.207 --> 00:25:23.040
It really increases
immersion, and you start

00:25:23.040 --> 00:25:24.830
to feel like you're there.

00:25:24.830 --> 00:25:26.770
But there's room
for improvement.

00:25:26.770 --> 00:25:28.270
With first-order
ambisonics, there's

00:25:28.270 --> 00:25:30.110
a fairly large margin of error.

00:25:30.110 --> 00:25:33.400
Pinpoint audio sources
don't sound so pinpoint.

00:25:33.400 --> 00:25:36.155
They're widened and it's
hard to actually locate

00:25:36.155 --> 00:25:40.930
a source perfectly without
a visual cue to guide you.

00:25:40.930 --> 00:25:45.390
So our solution here
is spherical harmonics.

00:25:45.390 --> 00:25:47.350
So as I mentioned before,
spherical harmonics

00:25:47.350 --> 00:25:50.650
is mathematically based and
it has this nice property,

00:25:50.650 --> 00:25:52.930
this infinitely extensible.

00:25:52.930 --> 00:25:55.130
So we can choose
our cut-off point.

00:25:55.130 --> 00:25:56.760
If we want only one
harmonic, we can

00:25:56.760 --> 00:25:58.749
do that-- the
omnidirectional component.

00:25:58.749 --> 00:26:00.790
Or if we want four or for
first-order ambisonics,

00:26:00.790 --> 00:26:02.980
we can do that as well.

00:26:02.980 --> 00:26:06.120
Or if we want 16 components
of audio, we can do that,

00:26:06.120 --> 00:26:07.975
and that's called
third-order ambisonics.

00:26:07.975 --> 00:26:12.170
And that actually starts to
sound pretty freaking great.

00:26:12.170 --> 00:26:13.920
There's a dramatic
increase in quality

00:26:13.920 --> 00:26:15.620
over first-order ambisonics.

00:26:15.620 --> 00:26:18.340
Things sound crisper, more
precise, just better overall,

00:26:18.340 --> 00:26:21.429
and it increases
immersion even further.

00:26:21.429 --> 00:26:23.095
However, I haven't
even talked about how

00:26:23.095 --> 00:26:25.530
to stream ambisonics
to the client, so let's

00:26:25.530 --> 00:26:27.880
take a look at
that for a second.

00:26:27.880 --> 00:26:31.839
So, again, our goal here is
spatial audio for everyone.

00:26:31.839 --> 00:26:33.880
No matter where you are
in the world or no matter

00:26:33.880 --> 00:26:35.340
your bandwidth or
device, we want

00:26:35.340 --> 00:26:37.430
to stream spatial
audio to you and we

00:26:37.430 --> 00:26:41.650
want you to have that great
cinematic VR experience.

00:26:41.650 --> 00:26:43.330
However, traditional
audio technology

00:26:43.330 --> 00:26:45.040
is not built for ambisonics.

00:26:45.040 --> 00:26:47.021
It's built for stereo audio.

00:26:47.021 --> 00:26:48.520
And this is great
for the past where

00:26:48.520 --> 00:26:50.820
stereo audio makes
a ton of sense,

00:26:50.820 --> 00:26:55.000
but in VR it's
decreasingly making sense.

00:26:55.000 --> 00:26:57.610
So we wondered, is there
some existing technology

00:26:57.610 --> 00:27:01.100
that we can repurpose
to stream ambisonics?

00:27:01.100 --> 00:27:03.420
And there is, and it's
called Vorbis, which

00:27:03.420 --> 00:27:06.460
is a free and open audio codec.

00:27:06.460 --> 00:27:08.370
So we take first-order
ambisonics,

00:27:08.370 --> 00:27:10.640
omnidirectional--
up-down, left-right,

00:27:10.640 --> 00:27:13.860
and front-back spherical
harmonic components.

00:27:13.860 --> 00:27:16.360
And then we stuff that into
a quadraphonic layout--

00:27:16.360 --> 00:27:20.450
front-left, front-right,
back-left, and back-right.

00:27:20.450 --> 00:27:22.150
And this actually
is pretty good.

00:27:22.150 --> 00:27:24.480
Multichannel Vorbis support
is great across a number

00:27:24.480 --> 00:27:26.810
of platforms, and this
helps us hit our goal of VR

00:27:26.810 --> 00:27:29.600
for everyone.

00:27:29.600 --> 00:27:33.300
However, this isn't ideal
for a couple of reasons.

00:27:33.300 --> 00:27:36.550
Ideally, with ambisonics we want
a different bit distribution

00:27:36.550 --> 00:27:38.270
than what we have right now.

00:27:38.270 --> 00:27:40.850
With the quadraphonic
layout, we have a uniform bit

00:27:40.850 --> 00:27:42.910
distribution, so each
of the audio channels

00:27:42.910 --> 00:27:45.720
gets the same number of
bits allocated to it.

00:27:45.720 --> 00:27:47.370
However, with
ambisonics, we like

00:27:47.370 --> 00:27:49.810
to dedicate more bits to
the omnidirectional channel

00:27:49.810 --> 00:27:52.860
than we do the others because
the omnidirectional channel

00:27:52.860 --> 00:27:57.270
encompasses the entire sphere
so it's used all the time.

00:27:57.270 --> 00:27:59.015
And for higher-order
ambisonics, it's

00:27:59.015 --> 00:28:00.390
not really clear
how you're going

00:28:00.390 --> 00:28:02.600
to do that with the
traditional codec.

00:28:02.600 --> 00:28:05.820
The data rates get pretty
crazy, and we're not really sure

00:28:05.820 --> 00:28:08.960
that that's going to help
hit our goal of streaming VR

00:28:08.960 --> 00:28:12.000
spatial audio for everyone.

00:28:12.000 --> 00:28:13.210
So we're working on it.

00:28:13.210 --> 00:28:15.700
We're working on higher-order
ambisonics compression

00:28:15.700 --> 00:28:20.940
using Opus, which is a free
and open, modern audio codec.

00:28:20.940 --> 00:28:23.090
So what higher-order
ambisonics streaming via Opus

00:28:23.090 --> 00:28:26.620
will allow us to do is stream
high-fidelity spatial audio

00:28:26.620 --> 00:28:29.580
to more people,
getting more ears,

00:28:29.580 --> 00:28:33.970
than we can today at
significantly lower data rates.

00:28:36.522 --> 00:28:38.730
So I've talked about streaming
spatial audio and what

00:28:38.730 --> 00:28:42.390
spatial audio is, but I haven't
gone into creation at all.

00:28:42.390 --> 00:28:44.770
And I actually won't go into
creation very much today.

00:28:44.770 --> 00:28:47.660
We have resources
online for that.

00:28:47.660 --> 00:28:49.330
But, in general,
creating spatial audio

00:28:49.330 --> 00:28:53.650
is hard and creating VR
video in general is hard.

00:28:53.650 --> 00:28:55.960
Today it requires
a number of tools,

00:28:55.960 --> 00:28:59.290
and the iteration
cycles are pretty long.

00:28:59.290 --> 00:29:01.370
So we're working
on that as well.

00:29:01.370 --> 00:29:03.160
We've developed Jump
Inspector, which

00:29:03.160 --> 00:29:04.840
is an Android app
for Cardboard which

00:29:04.840 --> 00:29:08.360
allows you to preview VR videos
with spatial audio in real time

00:29:08.360 --> 00:29:09.450
on your Android device.

00:29:09.450 --> 00:29:12.560
And Jump Inspector also
has a great feature

00:29:12.560 --> 00:29:15.930
for spatial audio producers
called Jump Inspector DAW

00:29:15.930 --> 00:29:17.060
Integration.

00:29:17.060 --> 00:29:20.530
And what that allows you to
do is sync Jump Inspector

00:29:20.530 --> 00:29:22.260
to your digital
audio workstation

00:29:22.260 --> 00:29:24.490
so you can mix in real
time and preview VR

00:29:24.490 --> 00:29:26.640
video on your
device in Cardboard

00:29:26.640 --> 00:29:29.100
as you're mixing, as
you're adjusting levels.

00:29:29.100 --> 00:29:32.150
Anything you do in the mix is
rendered in real time in sync

00:29:32.150 --> 00:29:36.100
with Jump Inspector,
and it's pretty great.

00:29:36.100 --> 00:29:38.540
And lastly, if you want to
check out spatial audio today,

00:29:38.540 --> 00:29:39.870
you can.

00:29:39.870 --> 00:29:43.670
Just go to the YouTube 360
channel on your Android device,

00:29:43.670 --> 00:29:45.610
pop it into Cardboard,
have a listen,

00:29:45.610 --> 00:29:47.540
let us know how it goes.

00:29:47.540 --> 00:29:49.540
And now back to Husain
to talk a bit about what

00:29:49.540 --> 00:29:51.750
we're doing for fostering
a healthy VR ecosystem.

00:29:51.750 --> 00:29:52.250
Husain.

00:30:00.354 --> 00:30:02.770
HUSAIN BENGALL: Everything
we've talked to you about today

00:30:02.770 --> 00:30:06.220
so far-- our investment
in Jump to make VR video

00:30:06.220 --> 00:30:09.590
creation easier,
playback improvements

00:30:09.590 --> 00:30:12.750
through adaptive
projections, and our work

00:30:12.750 --> 00:30:16.430
on spatial audio-- all of
these are rooted in the belief

00:30:16.430 --> 00:30:20.740
that VR video done well and
delivered at a high quality

00:30:20.740 --> 00:30:24.420
can make some of the most
powerful VR experiences

00:30:24.420 --> 00:30:26.210
possible today.

00:30:26.210 --> 00:30:29.820
There's one more thing I
want to talk about-- formats.

00:30:29.820 --> 00:30:33.070
We believe having an open
and easy-to-use format

00:30:33.070 --> 00:30:35.912
is critical to success
of the ecosystem.

00:30:35.912 --> 00:30:38.370
It's been great to see that
one of the formats we published

00:30:38.370 --> 00:30:43.240
in 2014 has gotten recently
a wide amount of adoption.

00:30:43.240 --> 00:30:45.540
We've also received a
lot of feedback though.

00:30:45.540 --> 00:30:48.410
And we've taken a lot of
that feedback into account

00:30:48.410 --> 00:30:50.350
and published a greatly
simplified version

00:30:50.350 --> 00:30:54.360
of the format at our GitHub
repository earlier today.

00:30:54.360 --> 00:30:57.150
You can find that,
along with instructions

00:30:57.150 --> 00:31:01.530
on using Jump Inspector and a
pointer to a discussion group

00:31:01.530 --> 00:31:04.680
where anyone can provide
feedback on our format,

00:31:04.680 --> 00:31:07.260
at that URL.

00:31:07.260 --> 00:31:11.180
At Google, we're committed to
an open and strong VR video

00:31:11.180 --> 00:31:14.710
ecosystem, VR
video for everyone.

00:31:14.710 --> 00:31:16.950
With that, I'd like to wrap up.

00:31:16.950 --> 00:31:18.985
Thank you all so
much for coming.

00:31:18.985 --> 00:31:21.250
My co-presenters and I
will be sticking around

00:31:21.250 --> 00:31:22.860
to take questions offline.

00:31:22.860 --> 00:31:26.355
Otherwise, enjoy the
rest of I/O. Thank you.

