WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:02.480
[MUSIC PLAYING]

00:00:03.373 --> 00:00:05.790
LAURENCE MORONEY: Hi, everybody,
and welcome to TensorFlow

00:00:05.790 --> 00:00:06.290
Meets.

00:00:06.290 --> 00:00:09.390
I'm absolutely delighted to have
my colleague Edd Wilder-James

00:00:09.390 --> 00:00:10.410
here with me today.

00:00:10.410 --> 00:00:12.990
Now, Edd is Mr.
Community and TensorFlow

00:00:12.990 --> 00:00:14.040
is all about community.

00:00:14.040 --> 00:00:15.840
So Ed, can you tell
us a little bit

00:00:15.840 --> 00:00:17.048
about what you've been up to?

00:00:17.048 --> 00:00:18.257
EDD WILDER-JAMES: Yeah, sure.

00:00:18.257 --> 00:00:19.960
I have a great job,
which is I kind of

00:00:19.960 --> 00:00:21.900
to reach out to the
whole community that's

00:00:21.900 --> 00:00:23.323
working with in TensorFlow.

00:00:23.323 --> 00:00:25.490
And one of the most striking
things about TensorFlow

00:00:25.490 --> 00:00:29.820
is obviously so many places
it's used in so many areas.

00:00:29.820 --> 00:00:32.790
And for TensorFlow to continue
to be a great project,

00:00:32.790 --> 00:00:35.520
continue to grow,
we need to build it

00:00:35.520 --> 00:00:38.850
so that the community can
easily be part of the thing

00:00:38.850 --> 00:00:41.623
that we're building because
there's so many use cases.

00:00:41.623 --> 00:00:43.290
You can't just have
the core team trying

00:00:43.290 --> 00:00:44.442
to support them all, right?

00:00:44.442 --> 00:00:46.650
It needs to be a sustainable
community where everyone

00:00:46.650 --> 00:00:49.050
can help build TensorFlow
towards the use cases

00:00:49.050 --> 00:00:49.780
that they have,

00:00:49.780 --> 00:00:51.697
LAURENCE MORONEY: Mm-hmm
and one of the things

00:00:51.697 --> 00:00:53.760
I find amazing is that
we talk about having

00:00:53.760 --> 00:00:54.960
a dedication to community.

00:00:54.960 --> 00:00:57.180
But the proof of
dedication to community

00:00:57.180 --> 00:00:59.055
is that we have you
full time working on it.

00:00:59.055 --> 00:01:00.600
It's like your role, right?

00:01:00.600 --> 00:01:01.600
EDD WILDER-JAMES: It is.

00:01:01.600 --> 00:01:03.540
And it's a tremendously
fun job to be

00:01:03.540 --> 00:01:05.459
able to kind of help the
engineering teams out

00:01:05.459 --> 00:01:07.770
by doing the other
part, designing

00:01:07.770 --> 00:01:11.480
processes and designing
the groups in the same way

00:01:11.480 --> 00:01:13.440
that an API helps
you program, right?

00:01:13.440 --> 00:01:16.090
Some of the structures I help
build, help people interact.

00:01:16.090 --> 00:01:18.340
LAURENCE MORONEY: That's a
really interesting analogy.

00:01:18.340 --> 00:01:19.290
I never thought
about it that way.

00:01:19.290 --> 00:01:20.082
That's pretty cool.

00:01:20.082 --> 00:01:23.190
So now, you did a talk at the
TensorFlow developer summit

00:01:23.190 --> 00:01:24.160
around community.

00:01:24.160 --> 00:01:26.118
And there was one thing
that really jumped out,

00:01:26.118 --> 00:01:28.710
to me, at that was that you
had a subtitle in your slide

00:01:28.710 --> 00:01:30.660
that was saying, I think it
was, we're building TensorFlow

00:01:30.660 --> 00:01:30.965
together--

00:01:30.965 --> 00:01:31.710
EDD WILDER-JAMES: That's right.

00:01:31.710 --> 00:01:32.790
LAURENCE MORONEY: Something
along those lines.

00:01:32.790 --> 00:01:34.230
So can you tell
us really what it

00:01:34.230 --> 00:01:36.750
means for us to be building
TensorFlow together

00:01:36.750 --> 00:01:37.680
with the community?

00:01:37.680 --> 00:01:39.550
EDD WILDER-JAMES: Yeah, I think,
especially in the last year,

00:01:39.550 --> 00:01:41.550
there are two things that
help us work together

00:01:41.550 --> 00:01:42.990
as a community.

00:01:42.990 --> 00:01:44.820
The first of these
is that we started

00:01:44.820 --> 00:01:48.270
to use an RFC request for
comments process for design

00:01:48.270 --> 00:01:49.480
changes.

00:01:49.480 --> 00:01:51.060
So a year ago, we
were at the point

00:01:51.060 --> 00:01:54.270
where we just kind of landed
design changes in code.

00:01:54.270 --> 00:01:55.990
Or if somebody else
wanted to contribute,

00:01:55.990 --> 00:01:57.350
they just landed in big PR.

00:01:57.350 --> 00:02:00.150
And there's not a lot of
transparency or discussion.

00:02:00.150 --> 00:02:03.390
But now we've published,
I think, over 21 RFCs

00:02:03.390 --> 00:02:06.120
where new designs for
APIs are discussed ahead

00:02:06.120 --> 00:02:07.250
of time in public.

00:02:07.250 --> 00:02:09.720
And it's not just the discussion
because, afterwards, that

00:02:09.720 --> 00:02:10.830
accesses documentation.

00:02:10.830 --> 00:02:13.320
So someone, in the future,
can come and understand

00:02:13.320 --> 00:02:14.550
why we made these choices.

00:02:14.550 --> 00:02:15.520
LAURENCE MORONEY: Interesting.

00:02:15.520 --> 00:02:17.770
EDD WILDER-JAMES: That's one
way we've built together.

00:02:17.770 --> 00:02:20.040
The second way is that
we've established,

00:02:20.040 --> 00:02:21.890
now, six special
interest groups.

00:02:21.890 --> 00:02:23.640
And these are very
defined project groups.

00:02:23.640 --> 00:02:27.810
So they work on things like new
networking protocols or ways

00:02:27.810 --> 00:02:30.690
to connect TensorFlow
to other data sources.

00:02:30.690 --> 00:02:33.300
And these work together,
predominately community

00:02:33.300 --> 00:02:35.340
led, to build parts
of TensorFlow.

00:02:35.340 --> 00:02:37.650
So now, we've increased
the surface area,

00:02:37.650 --> 00:02:39.832
increased the transparency
and the communication.

00:02:39.832 --> 00:02:41.290
LAURENCE MORONEY:
Wow, great stuff.

00:02:41.290 --> 00:02:44.160
So one of the things
that I always hear with--

00:02:44.160 --> 00:02:46.140
it's easy to talk
about community.

00:02:46.140 --> 00:02:47.845
It's hard to build community.

00:02:47.845 --> 00:02:49.845
And one of the things to
make building community

00:02:49.845 --> 00:02:53.630
is to try and make it easy
as possible to participate.

00:02:53.630 --> 00:02:55.380
And I know you've been
doing lots and lots

00:02:55.380 --> 00:02:56.480
of great work in that space.

00:02:56.480 --> 00:02:58.855
Can you share a little bit
about some of the great things

00:02:58.855 --> 00:03:00.360
that we have that
will help people

00:03:00.360 --> 00:03:02.520
to participate in the community,
beyond what you've already

00:03:02.520 --> 00:03:02.820
shared?

00:03:02.820 --> 00:03:04.362
EDD WILDER-JAMES:
Oh, well, I'll try.

00:03:04.362 --> 00:03:05.440
Yeah, there's a lot now.

00:03:05.440 --> 00:03:07.500
There is a lot
more surface area.

00:03:07.500 --> 00:03:09.610
And it really is about
surface area, right?

00:03:09.610 --> 00:03:14.220
You walk into a big project like
TensorFlow, where do you start?

00:03:14.220 --> 00:03:16.150
Where are the points
you can get traction?

00:03:16.150 --> 00:03:18.790
So we, obviously-- I mentioned
that the six that are going on.

00:03:18.790 --> 00:03:21.420
The modularity of the code
base really matters, too.

00:03:21.420 --> 00:03:23.770
And this is one of things
we're doing in TensorFlow 2.0,

00:03:23.770 --> 00:03:25.187
is making way more
modular, having

00:03:25.187 --> 00:03:27.100
less in this monolithic core.

00:03:27.100 --> 00:03:29.970
So now, you could find the
repo that you want to work on

00:03:29.970 --> 00:03:31.860
or the developer who's
looking after that.

00:03:31.860 --> 00:03:34.000
It's a lot more accessible.

00:03:34.000 --> 00:03:37.090
In addition to that in code
and the six that I mentioned,

00:03:37.090 --> 00:03:39.330
we now have a community
documentation group,

00:03:39.330 --> 00:03:42.525
which is gaining steam, people
bringing translations on.

00:03:42.525 --> 00:03:43.275
LAURENCE MORONEY: I've
seen the translations.

00:03:43.275 --> 00:03:44.280
Isn't that incredible--

00:03:44.280 --> 00:03:44.540
EDD WILDER-JAMES: Yeah, amazing.

00:03:44.540 --> 00:03:45.290
LAURENCE MORONEY: --coming
from the community.

00:03:45.290 --> 00:03:48.390
EDD WILDER-JAMES: Last week,
we posted up Korean and Russian

00:03:48.390 --> 00:03:48.960
translations.

00:03:48.960 --> 00:03:52.590
And it's fabulous to have first
class resources on our website

00:03:52.590 --> 00:03:54.120
to those communities.

00:03:54.120 --> 00:03:56.630
And also, finally,
the testing group

00:03:56.630 --> 00:03:59.190
for TensorFlow 2.0, the
page [INAUDIBLE] leading,

00:03:59.190 --> 00:04:02.160
which is really giving
people hands on time

00:04:02.160 --> 00:04:04.580
to bash on TensorFlow
2.0 and help it,

00:04:04.580 --> 00:04:06.330
make sure it meets all
those important use

00:04:06.330 --> 00:04:07.380
cases that everyone has.

00:04:07.380 --> 00:04:09.213
LAURENCE MORONEY: Right,
there's much there.

00:04:09.213 --> 00:04:11.392
Are there any of the
community contributions

00:04:11.392 --> 00:04:13.350
that you've seen that
particularly inspire you,

00:04:13.350 --> 00:04:14.850
that you really like?

00:04:14.850 --> 00:04:16.200
EDD WILDER-JAMES: Well, I think
what particularly inspires

00:04:16.200 --> 00:04:18.117
me is the way that all
this is coming together

00:04:18.117 --> 00:04:20.459
to support TensorFlow 2.0.

00:04:20.459 --> 00:04:21.990
And in many ways,
it would not be

00:04:21.990 --> 00:04:23.460
possible to do 2.0
in the way we're

00:04:23.460 --> 00:04:25.230
doing without the community.

00:04:25.230 --> 00:04:26.820
Let me give you an example.

00:04:26.820 --> 00:04:31.170
All the major design, changes
we've consulted the RFC.

00:04:31.170 --> 00:04:34.350
We now have moved a lot
of stuff out of contrib

00:04:34.350 --> 00:04:36.420
that was existing before
and is being maintained

00:04:36.420 --> 00:04:38.310
by community groups, the six.

00:04:38.310 --> 00:04:41.290
That wouldn't have
been possible before.

00:04:41.290 --> 00:04:44.130
In addition, the TensorFlow
2.0 testing group,

00:04:44.130 --> 00:04:46.770
which is also powered by a
lot of great Google Developer

00:04:46.770 --> 00:04:51.300
Experts, is really kind
of mashing on the APIs,

00:04:51.300 --> 00:04:53.250
making sure they work,
but also creating

00:04:53.250 --> 00:04:56.342
examples and notebooks that
will demo the functionality.

00:04:56.342 --> 00:04:58.050
LAURENCE MORONEY: One
that I particularly

00:04:58.050 --> 00:05:00.540
like is with TensorFlow
data services, the fact

00:05:00.540 --> 00:05:03.260
that we've being able to have
contributions of data sets

00:05:03.260 --> 00:05:04.700
from the community.

00:05:04.700 --> 00:05:06.320
And so some of the
data sets that have

00:05:06.320 --> 00:05:08.240
come in-- there was
one from Stanford,

00:05:08.240 --> 00:05:10.660
an undergraduate at
Stanford University

00:05:10.660 --> 00:05:14.090
who contributed like 200,000
chest X-ray images into a data

00:05:14.090 --> 00:05:14.730
set.

00:05:14.730 --> 00:05:16.965
And to make that then
easy for other people

00:05:16.965 --> 00:05:17.840
to build training on.

00:05:17.840 --> 00:05:21.917
It's like, without good
community, how could--

00:05:21.917 --> 00:05:22.750
I find it inspiring.

00:05:22.750 --> 00:05:24.083
EDD WILDER-JAMES: Yeah, exactly.

00:05:24.083 --> 00:05:27.020
It's one half about
our attitude but also

00:05:27.020 --> 00:05:29.090
about what we create
and structures

00:05:29.090 --> 00:05:30.440
and also how we code things.

00:05:30.440 --> 00:05:32.960
LAURENCE MORONEY: Right,
right, so let's switch gears

00:05:32.960 --> 00:05:33.730
for a second.

00:05:33.730 --> 00:05:35.570
Now, I know you're hard
at work on something

00:05:35.570 --> 00:05:36.592
called TensorFlow World.

00:05:36.592 --> 00:05:37.550
EDD WILDER-JAMES: Yeah.

00:05:37.550 --> 00:05:39.175
LAURENCE MORONEY: So
it's a great name.

00:05:39.175 --> 00:05:40.060
[LAUGHTER]

00:05:40.060 --> 00:05:42.000
So could you tell us a
little bit about that.

00:05:42.000 --> 00:05:42.380
EDD WILDER-JAMES:
Yeah, well, one

00:05:42.380 --> 00:05:44.005
of the exciting things
about TensorFlow

00:05:44.005 --> 00:05:46.280
now is that it's so widespread.

00:05:46.280 --> 00:05:49.550
And what we wanted
to do was really

00:05:49.550 --> 00:05:52.010
create an event that
would enable everyone

00:05:52.010 --> 00:05:54.710
in the ecosystem to
come together to share

00:05:54.710 --> 00:05:57.810
and to talk about
what they're doing.

00:05:57.810 --> 00:06:01.270
Obviously, Google does some
great TensorFlow oriented

00:06:01.270 --> 00:06:01.770
events.

00:06:01.770 --> 00:06:03.770
But they're limited in capacity.

00:06:03.770 --> 00:06:06.210
They're quite short.

00:06:06.210 --> 00:06:07.710
There's a lot of
the core TensorFlow

00:06:07.710 --> 00:06:08.930
team presenting outwards.

00:06:08.930 --> 00:06:11.110
But there's so many
things in the world

00:06:11.110 --> 00:06:13.370
where TensorFlow is
being used that it's

00:06:13.370 --> 00:06:15.260
really important
for us to continue

00:06:15.260 --> 00:06:17.820
to grow our ecosystem by
having everyone come together.

00:06:17.820 --> 00:06:18.820
LAURENCE MORONEY: I see.

00:06:18.820 --> 00:06:19.320
I see.

00:06:19.320 --> 00:06:20.945
EDD WILDER-JAMES:
Well, let me give you

00:06:20.945 --> 00:06:23.490
an example about some of the
things we'll have in there.

00:06:23.490 --> 00:06:24.650
So it's not just talks.

00:06:24.650 --> 00:06:26.265
But there will be tutorials.

00:06:26.265 --> 00:06:27.140
LAURENCE MORONEY: OK.

00:06:27.140 --> 00:06:28.765
EDD WILDER-JAMES:
There'll be training.

00:06:28.765 --> 00:06:31.910
There'll be a chance for
software vendors who interface

00:06:31.910 --> 00:06:34.190
with TensorFlow-- out
in the real world,

00:06:34.190 --> 00:06:37.460
people keep all their data in
databases and clouds and other

00:06:37.460 --> 00:06:38.230
places--

00:06:38.230 --> 00:06:39.980
that we want to tell
their story about how

00:06:39.980 --> 00:06:41.570
they work with TensorFlow, too.

00:06:41.570 --> 00:06:43.820
So it'll really be
something for everybody.

00:06:43.820 --> 00:06:45.237
LAURENCE MORONEY:
Can I go please?

00:06:45.237 --> 00:06:46.903
EDD WILDER-JAMES:
Well, let me tell you.

00:06:46.903 --> 00:06:48.800
Let me tell you a good
way that you could go.

00:06:48.800 --> 00:06:51.008
Obviously, we'd love to have
everyone come and attend

00:06:51.008 --> 00:06:52.070
as an attendee.

00:06:52.070 --> 00:06:54.520
But right now, we have a
call for participation open--

00:06:54.520 --> 00:06:55.520
LAURENCE MORONEY: Right.

00:06:55.520 --> 00:06:57.710
EDD WILDER-JAMES: --which
is open until April 23.

00:06:57.710 --> 00:06:58.430
LAURENCE MORONEY: OK.

00:06:58.430 --> 00:07:00.388
EDD WILDER-JAMES: And
you can go to the website

00:07:00.388 --> 00:07:02.840
URL, which is very
excitingly tensorflow.world.

00:07:02.840 --> 00:07:04.130
LAURENCE MORONEY: OK,
I think I can remember.

00:07:04.130 --> 00:07:06.380
EDD WILDER-JAMES: Yeah,
right, the clue's in the name.

00:07:06.380 --> 00:07:09.690
And submit a proposal to
talk or deliver a tutorial.

00:07:09.690 --> 00:07:11.120
And we'll be reviewing those.

00:07:11.120 --> 00:07:13.605
And by sort of mid-May, we'll
have a schedule settled.

00:07:13.605 --> 00:07:15.980
LAURENCE MORONEY: And where
and when is TensorFlow World?

00:07:15.980 --> 00:07:17.605
EDD WILDER-JAMES:
Right, the conference

00:07:17.605 --> 00:07:20.660
itself is October 28
through the 31st of October.

00:07:20.660 --> 00:07:22.390
And that'll be in Santa Clara.

00:07:22.390 --> 00:07:24.478
LAURENCE MORONEY: OK, so
and it's got Halloween.

00:07:24.478 --> 00:07:27.020
EDD WILDER-JAMES: It's Halloween
and TensorFlow loves orange.

00:07:27.020 --> 00:07:27.396
So I'm psyched.

00:07:27.396 --> 00:07:29.146
LAURENCE MORONEY:
Exactly, it'll be great.

00:07:29.146 --> 00:07:30.896
Are you going to
go in fancy dress?

00:07:30.896 --> 00:07:32.955
[LAUGHTER]

00:07:32.955 --> 00:07:33.830
Well, thanks so much.

00:07:33.830 --> 00:07:35.660
Oh, one last question, actually.

00:07:35.660 --> 00:07:38.150
If people want to learn
more about the community,

00:07:38.150 --> 00:07:39.950
where can they go?

00:07:39.950 --> 00:07:42.330
EDD WILDER-JAMES: We
decided that, again, one URL

00:07:42.330 --> 00:07:43.230
is the best idea.

00:07:43.230 --> 00:07:45.500
So if you go to
tensorflow.org/community,

00:07:45.500 --> 00:07:48.260
if you just go to the
TensorFlow home page and hit

00:07:48.260 --> 00:07:51.063
on the community label, you'll
get to all our resources.

00:07:51.063 --> 00:07:52.980
LAURENCE MORONEY: Awesome,
awesome, OK, great.

00:07:52.980 --> 00:07:53.605
Thanks so much.

00:07:53.605 --> 00:07:55.700
And thanks everybody for
watching this episode

00:07:55.700 --> 00:07:56.600
of TensorFlow Meets.

00:07:56.600 --> 00:07:58.100
And if you've any
questions for Edd,

00:07:58.100 --> 00:07:59.600
if you've any
questions for me, just

00:07:59.600 --> 00:08:01.280
please leave them in
the comments below.

00:08:01.280 --> 00:08:02.750
And all the links that
we discussed today,

00:08:02.750 --> 00:08:04.120
I'll paste them
in there as well.

00:08:04.120 --> 00:08:04.870
So thanks so much.

00:08:04.870 --> 00:08:08.200
[MUSIC PLAYING]

