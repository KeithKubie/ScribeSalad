WEBVTT
Kind: captions
Language: en

00:00:00.200 --> 00:00:04.120
So just to drive the point home
a little bit I just want to write down,

00:00:04.120 --> 00:00:07.090
sort of summarize what it is that
we've talked about so far and

00:00:07.090 --> 00:00:08.450
how it all kind of comes together.

00:00:08.450 --> 00:00:12.140
And I think it's actually going to
push it back to the very first slide.

00:00:12.140 --> 00:00:16.020
So, we've done MDPs
we talk about SMDP's.

00:00:16.020 --> 00:00:18.190
We talked a little about what
options actually do for you,

00:00:18.190 --> 00:00:22.250
And we talked a little bit
about state abstraction before.

00:00:22.250 --> 00:00:26.840
This all brings us to
a bunch of neat little facts.

00:00:26.840 --> 00:00:31.633
The first one is that because we
are doing this SNDP type thing,

00:00:31.633 --> 00:00:34.000
because we are doing options.

00:00:34.000 --> 00:00:39.150
We get to inherit all of the optimality
guarantees up to a point

00:00:39.150 --> 00:00:43.220
of what we had before in regular
MDPs with regular actions.

00:00:43.220 --> 00:00:46.030
So in particular we get all
the convergence proofs,

00:00:46.030 --> 00:00:47.850
we get all the stability proofs.

00:00:47.850 --> 00:00:49.830
In other words,
everything is all nice, and well, and

00:00:49.830 --> 00:00:52.260
good in SMDP land as it was in MDP land.

00:00:53.320 --> 00:00:55.700
There's a slight caveat to that
which is worth mentioning, and

00:00:55.700 --> 00:00:58.420
it's really what you
brought up over the quiz.

00:00:58.420 --> 00:01:02.470
Which is well if we don't pay attention
all these things, and we live around in

00:01:02.470 --> 00:01:07.820
the options space are we actually
going to be able to really be optimal?

00:01:07.820 --> 00:01:09.250
We really going to build
to solve the problem?

00:01:09.250 --> 00:01:11.010
Do I need to know all of these things?

00:01:11.010 --> 00:01:14.080
And the answer is, well if you've got
the right sort of options in the right

00:01:14.080 --> 00:01:17.660
side of world, right kind of world,
then in fact, everything's good.

00:01:18.820 --> 00:01:22.880
But you cannot guarantee that if
all you do is reason over options,

00:01:22.880 --> 00:01:25.330
that you will in fact end
up with an optimal policy.

00:01:25.330 --> 00:01:28.920
We have another notion called
hierarchical optimality.

00:01:28.920 --> 00:01:32.920
And that's the notion that given
the set of options that you have,

00:01:32.920 --> 00:01:38.059
you can in fact converge to an optimal
policy with respect to those options.

00:01:39.560 --> 00:01:41.360
And I think that makes sense.

00:01:41.360 --> 00:01:44.780
And of course whether you are allow
those options to pay attention

00:01:44.780 --> 00:01:46.220
to all of the state space,

00:01:46.220 --> 00:01:50.900
also affects whether you're going to get
the true optimality that you would have.

00:01:50.900 --> 00:01:55.330
Or only a sort of optimality with
respect to the particular set of

00:01:55.330 --> 00:01:58.230
options, and the states,
the state features that you happen to be

00:01:58.230 --> 00:02:01.270
paying attention But I actually don't
think this is a big deal right because I

00:02:01.270 --> 00:02:03.320
think this is true for
the problem in general.

00:02:03.320 --> 00:02:06.750
So I've got an MDP and
I have a bunch of states.

00:02:06.750 --> 00:02:09.360
I made up the states anyway
as we've talked about

00:02:09.360 --> 00:02:12.180
before we talk about the palm and
MDPs and PSRs.

00:02:12.180 --> 00:02:16.060
It's not clear these dates actually
exist in some very real sense.

00:02:16.060 --> 00:02:18.740
I came up with the state features
I described the way the world was

00:02:18.740 --> 00:02:19.295
supposed to be.

00:02:19.295 --> 00:02:23.130
There're clearly some ways of describing
the state of Pac-Man that make learning

00:02:23.130 --> 00:02:27.240
easier and some that make it harder,
some that allow us to be truly optimal,

00:02:27.240 --> 00:02:28.360
and some that don't.

00:02:28.360 --> 00:02:31.560
Like if I had came up with
state features that only track

00:02:31.560 --> 00:02:34.500
the closest dots to me
I may not be optimal.

00:02:34.500 --> 00:02:36.550
But on the other hand it
might be easier to learn and

00:02:36.550 --> 00:02:38.500
these are tradeoffs that
we make all the time.

00:02:38.500 --> 00:02:42.700
So, in some sense we're always dealing
with a limited notion of optimality.

00:02:42.700 --> 00:02:45.490
Which we define with respect to
the set of actions we decide

00:02:45.490 --> 00:02:48.090
that we're going to consider
in the set of state features

00:02:48.090 --> 00:02:50.280
that we're going to pay any
attention to at any given time.

