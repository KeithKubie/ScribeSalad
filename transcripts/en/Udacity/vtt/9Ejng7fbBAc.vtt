WEBVTT
Kind: captions
Language: en

00:00:00.220 --> 00:00:03.490
The particular flavor of machine
learning that we're going to focus on in

00:00:03.490 --> 00:00:07.670
the first part of this course is
called supervised regression learning.

00:00:07.670 --> 00:00:09.410
Those are a few big words.

00:00:09.410 --> 00:00:11.497
Let's break it down word by word.

00:00:11.497 --> 00:00:14.580
We'll start in the middle
here with regression.

00:00:14.580 --> 00:00:16.570
Regression is a weird word.

00:00:16.570 --> 00:00:21.840
I don't think whoever chose it to
represent what it means did a good job,

00:00:21.840 --> 00:00:23.420
but we're stuck with it.

00:00:23.420 --> 00:00:25.910
All that regression means is we're

00:00:25.910 --> 00:00:31.180
trying to make a numerical approximation
or a numerical prediction.

00:00:31.180 --> 00:00:35.160
That's as opposed to
classification learning

00:00:35.160 --> 00:00:38.200
where we might be trying
to classify an object

00:00:38.200 --> 00:00:43.030
into one of several types as opposed
to making a numerical prediction.

00:00:43.030 --> 00:00:48.080
Supervised means that we
show the machine the x and

00:00:48.080 --> 00:00:51.590
also, if you will, the correct answer y.

00:00:51.590 --> 00:00:56.190
In fact, we show the machine many,
many examples of x and y, and that's how

00:00:56.190 --> 00:01:01.530
it learns, okay, when I see this x,
this is the y that's associated with it.

00:01:01.530 --> 00:01:03.750
That's the supervised component.

00:01:03.750 --> 00:01:09.570
Finally, when we say learning, what
we mean is we are training with data.

00:01:09.570 --> 00:01:13.030
In this class we're taking
historical stock data and

00:01:13.030 --> 00:01:18.670
training the system to make a prediction
about the future, usually about price.

00:01:18.670 --> 00:01:21.350
There are a lot of algorithms
that solve this problem and

00:01:21.350 --> 00:01:24.500
are supervised regression
learning techniques.

00:01:24.500 --> 00:01:28.080
You've probably heard of
linear regression and used it.

00:01:28.080 --> 00:01:32.070
Linear regression is a method that
finds parameters for a model.

00:01:32.070 --> 00:01:35.210
So we call it parametric learning.

00:01:35.210 --> 00:01:40.980
K nearest neighbor, or KNN,
is an extremely popular approach.

00:01:40.980 --> 00:01:45.860
And in fact, you're going to build
a KNN learner as part of this class.

00:01:45.860 --> 00:01:50.760
What's different between parametric
learning and instance based, which KNN

00:01:50.760 --> 00:01:56.150
is an example of, is that in parametric
learning we take the data, munge it

00:01:56.150 --> 00:02:00.080
around to come up with a few parameters,
and then throw the data away.

00:02:00.080 --> 00:02:04.310
In k nearest neighbor we keep all
of this historic data, the x and

00:02:04.310 --> 00:02:09.440
y pairs, and when it's time to make
a prediction we consult that data.

00:02:09.440 --> 00:02:12.210
That's what makes it instance based.

00:02:12.210 --> 00:02:15.420
Anyways, we'll spend a lot of time
talking about k nearest neighbor.

00:02:15.420 --> 00:02:18.440
Two other techniques that are really
popular are decision trees and

00:02:18.440 --> 00:02:20.110
decision forests.

00:02:20.110 --> 00:02:23.920
As you might guess, the way decision
trees work is they store a tree

00:02:23.920 --> 00:02:27.280
structure and when a query comes in,

00:02:27.280 --> 00:02:32.610
it essentially bounces down that tree
according to factors of the data.

00:02:33.790 --> 00:02:37.250
Each node in the tree represents
essentially a question,

00:02:37.250 --> 00:02:42.170
is this x value greater than or
less than this other value?

00:02:42.170 --> 00:02:47.830
And eventually we reach a leaf and that
is the regression value that's returned.

00:02:47.830 --> 00:02:53.200
Decision forests are simply lots and
lots of decision trees

00:02:53.200 --> 00:02:57.566
taken together, and you query each
one to get an overall result.

00:02:57.566 --> 00:03:02.030
So this is the definition of
supervised regression learning,

00:03:02.030 --> 00:03:04.240
which we're going to use a lot, and

00:03:04.240 --> 00:03:08.010
these are various algorithms
that solve that problem.

