WEBVTT
Kind: captions
Language: en

00:00:09.600 --> 00:00:10.120
CRAIG MCLUCKIE: All right.

00:00:10.120 --> 00:00:10.845
Welcome everybody.

00:00:10.845 --> 00:00:13.360
Oh, a little bit loud.

00:00:13.360 --> 00:00:17.100
I'm going to take a little
bit of time to go through

00:00:17.100 --> 00:00:19.220
something that was announced
today, which is

00:00:19.220 --> 00:00:20.740
Google Compute Engine.

00:00:20.740 --> 00:00:24.500
During the keynote, Urs
introduced our new

00:00:24.500 --> 00:00:27.110
Infrastructure-as-a-Service
product to the

00:00:27.110 --> 00:00:28.760
Google Cloud platform.

00:00:28.760 --> 00:00:32.000
I'm going to take a few minutes
to elaborate on some

00:00:32.000 --> 00:00:33.160
of the stuff he shared
with you.

00:00:33.160 --> 00:00:38.040
He showed how Google Compute
Engine has been used by the

00:00:38.040 --> 00:00:43.830
Institute for Systems Biology
to take a life-saving cancer

00:00:43.830 --> 00:00:46.880
research process and move it
from something that took hours

00:00:46.880 --> 00:00:48.840
to minutes to seconds.

00:00:48.840 --> 00:00:52.460
I'm now going to take a little
bit of time to share with you

00:00:52.460 --> 00:00:55.170
how Google Compute Engine can
offer you that same set of

00:00:55.170 --> 00:00:57.660
capabilities, how you can
tackle some really big

00:00:57.660 --> 00:01:01.060
computing problems on Google's
infrastructure.

00:01:01.060 --> 00:01:04.269
And during the session, I'm
going to provide a very broad

00:01:04.269 --> 00:01:06.760
brush stroke sense of what
we've been up to so you

00:01:06.760 --> 00:01:08.340
understand what the product
looks like.

00:01:08.340 --> 00:01:11.430
I'm going to invite some of our
partners up on stage to

00:01:11.430 --> 00:01:13.070
share some of their experiences
and the

00:01:13.070 --> 00:01:14.730
technologies that they're
offering.

00:01:14.730 --> 00:01:19.410
And I'm also going to give you
some demos so you can actually

00:01:19.410 --> 00:01:20.490
see the product in action.

00:01:20.490 --> 00:01:21.740
So let's jump right in.

00:01:25.040 --> 00:01:27.850
Google Compute Engine is
Infrastructure-as-a-Service.

00:01:27.850 --> 00:01:31.270
So when describing this product,
I think the logical

00:01:31.270 --> 00:01:34.220
place to start is with Google's
infrastructure.

00:01:34.220 --> 00:01:37.310
Now, as you know, Google runs
some very big internet-scale

00:01:37.310 --> 00:01:38.330
businesses.

00:01:38.330 --> 00:01:40.790
And to be successful in these
big businesses, we need a

00:01:40.790 --> 00:01:42.470
really large infrastructure.

00:01:42.470 --> 00:01:45.160
The process of running
search, for instance.

00:01:45.160 --> 00:01:48.110
We index every day billions
and billions of web pages.

00:01:48.110 --> 00:01:54.360
Our Caffeine index is over
100 million gigabytes.

00:01:54.360 --> 00:01:55.600
It's huge.

00:01:55.600 --> 00:01:58.620
And we're able to provide
results within a quarter of a

00:01:58.620 --> 00:02:00.560
second to those search
queries.

00:02:00.560 --> 00:02:03.240
To do that requires some very
interesting infrastructure.

00:02:03.240 --> 00:02:05.020
To be successful as a business,
it's not just about

00:02:05.020 --> 00:02:06.160
the size of the infrastructure,
the

00:02:06.160 --> 00:02:07.590
performance of the
infrastructure, the scale of

00:02:07.590 --> 00:02:08.669
the infrastructure.

00:02:08.669 --> 00:02:10.780
It's also about the efficiency
of infrastructure.

00:02:10.780 --> 00:02:13.110
And the efficiency to us is
important for two reasons.

00:02:13.110 --> 00:02:15.520
One is environmental
impact, obviously.

00:02:15.520 --> 00:02:17.140
We're very green by nature.

00:02:17.140 --> 00:02:19.970
And our data centers actually
consume only about half the

00:02:19.970 --> 00:02:21.740
energy of traditional
data centers.

00:02:21.740 --> 00:02:23.680
But it also translates
into money.

00:02:23.680 --> 00:02:24.190
And it means more

00:02:24.190 --> 00:02:25.760
profitability for the business.

00:02:25.760 --> 00:02:29.620
So we have spent a tremendous
amount of time and effort

00:02:29.620 --> 00:02:33.020
innovating relentlessly,
focusing on bringing new

00:02:33.020 --> 00:02:36.590
capabilities to market
and new technologies

00:02:36.590 --> 00:02:38.090
to market for ourselves.

00:02:38.090 --> 00:02:41.650
And we've also focused on
refinement of every process in

00:02:41.650 --> 00:02:44.670
our data centers, whether it's
the design of the hardware

00:02:44.670 --> 00:02:47.570
down to the silicon; whether
it's our software-- and we've

00:02:47.570 --> 00:02:49.840
brought some really neat and
interesting technologies to

00:02:49.840 --> 00:02:52.460
fuse together commodity hardware
and provide very high

00:02:52.460 --> 00:02:54.930
quality of service offerings
on top of it--

00:02:54.930 --> 00:02:57.000
to our data center design.

00:02:57.000 --> 00:02:59.610
Whether it's dealing with
cooling; whether it's dealing

00:02:59.610 --> 00:03:03.570
with power distribution; or to
our operations, rolling out

00:03:03.570 --> 00:03:05.910
new infrastructure, doing that
efficiently, dealing with the

00:03:05.910 --> 00:03:07.840
life cycle of our hardware,
recycling it.

00:03:07.840 --> 00:03:10.560
So we've relentlessly
refined across this.

00:03:10.560 --> 00:03:13.480
And what we brought together is
this incredible power, this

00:03:13.480 --> 00:03:15.910
incredible scale, and incredible
efficiency.

00:03:15.910 --> 00:03:19.210
And now you can access that and
run your processes on our

00:03:19.210 --> 00:03:20.460
infrastructure.

00:03:25.470 --> 00:03:28.470
So what is Google
Compute Engine?

00:03:28.470 --> 00:03:30.390
At its heart, it's
Infrastructure-as-a-Service.

00:03:30.390 --> 00:03:32.760
Infrastructure-as-a-Service
starts with Compute.

00:03:32.760 --> 00:03:36.150
We provide Linux virtual
machines that you can rent by

00:03:36.150 --> 00:03:38.270
the hour on demand.

00:03:38.270 --> 00:03:40.580
You can configure them the way
you want, and you can run

00:03:40.580 --> 00:03:42.640
traditional workloads
as if it was running

00:03:42.640 --> 00:03:44.310
in your data center.

00:03:44.310 --> 00:03:45.390
It's about storage.

00:03:45.390 --> 00:03:49.030
It's about providing options
for storage, which emulate

00:03:49.030 --> 00:03:53.430
local disk, whether that's a
durably replicated, reliable,

00:03:53.430 --> 00:03:56.680
highly performant off-instance
storage, or whether it's

00:03:56.680 --> 00:04:01.180
having access to large local
storage for data-centric

00:04:01.180 --> 00:04:04.080
applications where you need
access to large, efficient,

00:04:04.080 --> 00:04:07.830
local storage, to our
internet-scale cloud storage

00:04:07.830 --> 00:04:12.320
offering, which provides the
ability to create shared

00:04:12.320 --> 00:04:16.300
content in a cloud-scale or
internet-scale object store.

00:04:16.300 --> 00:04:18.910
It's about network, being able
to take these virtual machines

00:04:18.910 --> 00:04:22.130
and expose them to the network
so that you can access them

00:04:22.130 --> 00:04:25.050
and to do that in such a way
that you have flexible control

00:04:25.050 --> 00:04:27.420
over who can speak to them,
who can see them by using

00:04:27.420 --> 00:04:28.780
flexible firewalls.

00:04:28.780 --> 00:04:30.870
And it's also about being able
to fuse these virtual machines

00:04:30.870 --> 00:04:33.770
together to form very powerful
compute clusters, so you can

00:04:33.770 --> 00:04:36.480
tackle large-scale
data-processing problems the

00:04:36.480 --> 00:04:38.200
same way Google does.

00:04:38.200 --> 00:04:39.870
And then, of course, it's
about the tools.

00:04:39.870 --> 00:04:41.840
You need to be able to command
and configure and control

00:04:41.840 --> 00:04:43.350
these virtual machines.

00:04:43.350 --> 00:04:46.360
And so we've provided a
portfolio of Tools options so

00:04:46.360 --> 00:04:48.430
that you can jump in there and
configure them exactly the way

00:04:48.430 --> 00:04:50.760
you want with a low-level
command-line tool.

00:04:50.760 --> 00:04:53.550
Or you can access them
and get easy access

00:04:53.550 --> 00:04:54.970
using a simple UI tool.

00:04:54.970 --> 00:04:58.210
And we'll spend some time
jumping into these tools and

00:04:58.210 --> 00:05:01.500
explaining the service
to you more.

00:05:01.500 --> 00:05:08.710
And so what I'd like to
do is invite Chris up.

00:05:08.710 --> 00:05:11.290
And I think the easiest way to
really understand the product

00:05:11.290 --> 00:05:12.120
is just to see it.

00:05:12.120 --> 00:05:14.710
That will really give you a
sense of what exactly this is.

00:05:14.710 --> 00:05:16.510
So Chris will do a little
demo for us.

00:05:20.500 --> 00:05:21.220
CHRIS: All right.

00:05:21.220 --> 00:05:22.425
Let's flip these guys.

00:05:22.425 --> 00:05:23.675
CRAIG MCLUCKIE: There we go.

00:05:26.130 --> 00:05:26.470
CHRIS: All right.

00:05:26.470 --> 00:05:27.520
Thanks, Craig.

00:05:27.520 --> 00:05:30.410
I'll be giving a brief tour of
our UI today, showing you

00:05:30.410 --> 00:05:32.640
around a virtual machine
instance.

00:05:32.640 --> 00:05:34.360
So let's go ahead and
dive right in.

00:05:34.360 --> 00:05:38.100
We can look in the Google
Developer APIs site is where

00:05:38.100 --> 00:05:40.370
our UI is located.

00:05:40.370 --> 00:05:42.430
We have our compute nodes
here in the form of

00:05:42.430 --> 00:05:43.920
virtual machine instances.

00:05:43.920 --> 00:05:47.580
I only have a single instance
running right now.

00:05:47.580 --> 00:05:50.050
We can look at our durable
storage in the form of

00:05:50.050 --> 00:05:52.290
persistent disks that
we list here.

00:05:52.290 --> 00:05:55.220
Again, just a single example.

00:05:55.220 --> 00:05:57.940
And then our globally
available networks.

00:05:57.940 --> 00:06:01.820
And right now, I just have my
default network defined here.

00:06:01.820 --> 00:06:08.220
We also have our resource zones
and a list of operations

00:06:08.220 --> 00:06:13.640
used for auditing what
actions have been

00:06:13.640 --> 00:06:15.640
taken on your resources.

00:06:15.640 --> 00:06:18.160
We'll get into those in
some later talks.

00:06:18.160 --> 00:06:20.550
So all these are bundled
together in a

00:06:20.550 --> 00:06:22.090
Google Developer project.

00:06:22.090 --> 00:06:25.830
So here in the overview pane, we
can see that my project is

00:06:25.830 --> 00:06:28.260
provisioned for 20,000
instances,

00:06:28.260 --> 00:06:31.000
20,000 CPUs, et cetera.

00:06:31.000 --> 00:06:32.825
So let's go ahead and
start an instance.

00:06:37.490 --> 00:06:37.840
All right.

00:06:37.840 --> 00:06:41.490
I like fractals, so I'll name
this guy Mandelbrot.

00:06:41.490 --> 00:06:44.710
And I'm going to boot this with
an Ubuntu image that has

00:06:44.710 --> 00:06:47.130
some fractal tools baked into
it, which I created just

00:06:47.130 --> 00:06:48.560
before this talk.

00:06:48.560 --> 00:06:51.070
I'm also going to turn
on a service account.

00:06:51.070 --> 00:06:53.520
This enables seamless
authentication to other cloud

00:06:53.520 --> 00:06:56.670
services that we have without
you needing to manage keys,

00:06:56.670 --> 00:07:00.120
push keys into your VMs,
anything like that.

00:07:00.120 --> 00:07:04.190
So we'll go ahead and get
that guy started.

00:07:04.190 --> 00:07:07.410
So while that's spinning up,
it's worth noting that our UI

00:07:07.410 --> 00:07:10.900
is actually an App Engine
application making calls

00:07:10.900 --> 00:07:13.450
against Compute Engine's
public rest API.

00:07:13.450 --> 00:07:17.770
There's no back doors
in use here.

00:07:17.770 --> 00:07:19.650
We'll be open sourcing
this UI to you.

00:07:19.650 --> 00:07:24.630
So you'll be able to use it as
the basis for specialized

00:07:24.630 --> 00:07:29.500
platforms or more sophisticated
UIs.

00:07:29.500 --> 00:07:32.640
In addition to this, I'll show
you a brief look at our

00:07:32.640 --> 00:07:34.960
command-line tool written
in Python.

00:07:34.960 --> 00:07:38.850
We will be open sourcing
that tool as well.

00:07:38.850 --> 00:07:39.230
All right.

00:07:39.230 --> 00:07:41.980
So we're up and running now.

00:07:41.980 --> 00:07:45.590
I've got a SSH command line
here I can paste in.

00:07:49.829 --> 00:07:50.780
And here we go.

00:07:50.780 --> 00:07:53.140
I'm in my VM.

00:07:53.140 --> 00:07:57.630
So we can poke around here, See
all the running processes.

00:07:57.630 --> 00:08:02.830
We can see what kind of kernel
we're running on.

00:08:02.830 --> 00:08:06.940
We can check out the CPU that's
in here, so a full

00:08:06.940 --> 00:08:08.830
Linux virtual machine available
for you to use very

00:08:08.830 --> 00:08:10.256
quickly, very easily.

00:08:10.256 --> 00:08:13.360
I'm going to go ahead and have
this instance do a little bit

00:08:13.360 --> 00:08:15.200
of work for me.

00:08:15.200 --> 00:08:17.560
So he's going to generate
a series of

00:08:17.560 --> 00:08:21.800
image tiles for a fractal.

00:08:21.800 --> 00:08:24.430
And you can see here that
we're uploading these to

00:08:24.430 --> 00:08:28.190
Google Cloud Storage using that
seamless service account.

00:08:28.190 --> 00:08:30.680
And then as those tiles hit
Google Cloud Storage, I have a

00:08:30.680 --> 00:08:34.150
local server picking them up and
displaying them here in a

00:08:34.150 --> 00:08:37.409
pretty basic web UI, so
pretty quick and easy.

00:08:43.217 --> 00:08:44.669
CRAIG MCLUCKIE: Thanks, Chris.

00:08:44.669 --> 00:08:48.680
So as you see, we have gathered
a very simple Linux

00:08:48.680 --> 00:08:51.120
virtual machine as a
service offering.

00:08:51.120 --> 00:08:52.550
This is
Infrastructure-as-a-Service as

00:08:52.550 --> 00:08:54.240
you'd expect it to be.

00:08:54.240 --> 00:08:58.150
And I'd like to sort of
contextualize a little bit and

00:08:58.150 --> 00:09:01.750
help you think about what we're
focused on, what the

00:09:01.750 --> 00:09:04.800
value proposition of this
is from our perspective.

00:09:04.800 --> 00:09:06.960
It comes down to this--

00:09:06.960 --> 00:09:11.650
single bit Linux virtual
machines are great.

00:09:11.650 --> 00:09:14.430
But what we do at Google is we
throw a lot of infrastructure

00:09:14.430 --> 00:09:15.140
at problems.

00:09:15.140 --> 00:09:18.190
So we've developed a set of
technologies, and we've

00:09:18.190 --> 00:09:21.180
derived a tremendous amount of
benefit from having very large

00:09:21.180 --> 00:09:24.560
amounts of accessible,
affordable infrastructure that

00:09:24.560 --> 00:09:26.530
we can throw at large-scale
computing problems.

00:09:26.530 --> 00:09:28.980
And in many ways, that's one of
the toughest challenges we

00:09:28.980 --> 00:09:29.390
have to face.

00:09:29.390 --> 00:09:31.750
It's like, how do we build a
service like this that can

00:09:31.750 --> 00:09:32.780
really scale?

00:09:32.780 --> 00:09:35.490
So that it enables you to tackle
problems the same way

00:09:35.490 --> 00:09:38.610
we tackle problems on the same
infrastructure that we use.

00:09:38.610 --> 00:09:40.830
So this first version of Google
Compute Engine, this

00:09:40.830 --> 00:09:44.470
initial offering, is really
focused on large-scale compute

00:09:44.470 --> 00:09:46.310
problems, helping you solve
these large-scale

00:09:46.310 --> 00:09:47.940
data-processing problems.

00:09:47.940 --> 00:09:50.520
And for us, that mean's
scalability, that means being

00:09:50.520 --> 00:09:54.110
able to stand up these virtual
machine instances quickly so

00:09:54.110 --> 00:09:56.300
that you can quickly bring up
one of these clusters, do your

00:09:56.300 --> 00:09:58.420
work, and then turn it down
when you're done with it.

00:09:58.420 --> 00:10:00.790
And it also means being able
to perform effectively.

00:10:00.790 --> 00:10:03.090
It's not just about performing
fast in a straight line.

00:10:03.090 --> 00:10:06.110
We actually have some pretty
cool toys that Urs has built

00:10:06.110 --> 00:10:07.430
us over the last decade.

00:10:07.430 --> 00:10:09.870
It's pretty easy to go fast
singly on this kind of

00:10:09.870 --> 00:10:10.440
infrastructure.

00:10:10.440 --> 00:10:13.265
We've really focused on being
able to do this at scale and

00:10:13.265 --> 00:10:15.510
being able to perform better
the bigger and bigger the

00:10:15.510 --> 00:10:16.180
cluster is.

00:10:16.180 --> 00:10:17.520
And so that's some of the things
that's really unique

00:10:17.520 --> 00:10:19.720
about this technology.

00:10:19.720 --> 00:10:21.630
And then, of course, it's
about affordability.

00:10:21.630 --> 00:10:23.950
If you're buying a large amount
of virtual machines,

00:10:23.950 --> 00:10:26.720
you're buying a lot of CPU, you
want to be able to do that

00:10:26.720 --> 00:10:27.550
affordability.

00:10:27.550 --> 00:10:29.320
And we really think about
this is a utility.

00:10:29.320 --> 00:10:31.240
You should be able to plug into
this thing, consume as

00:10:31.240 --> 00:10:33.730
much resource as you want, just
like a utility, be able

00:10:33.730 --> 00:10:35.620
to get that resource
affordability, just like you

00:10:35.620 --> 00:10:37.940
do from a traditional
utility company.

00:10:37.940 --> 00:10:40.320
Because that utility company is
able to deliver it at scale

00:10:40.320 --> 00:10:42.450
and achieve very high
efficiencies of scale.

00:10:42.450 --> 00:10:43.970
And so that's what Google
Compute Engine is about.

00:10:43.970 --> 00:10:45.900
It's about bringing these
three things together--

00:10:45.900 --> 00:10:49.890
scale, performance at scale,
and affordability.

00:10:56.440 --> 00:10:57.310
All right.

00:10:57.310 --> 00:10:59.580
I think to really understand the
service, it makes sense to

00:10:59.580 --> 00:11:02.220
step back and describe some
of the guiding principles.

00:11:02.220 --> 00:11:04.600
These are the architectural
principles that we used to

00:11:04.600 --> 00:11:07.590
steer our design and steer every
decision we've made in

00:11:07.590 --> 00:11:08.970
delivering the service.

00:11:08.970 --> 00:11:10.400
I think it's useful
for two reasons.

00:11:10.400 --> 00:11:13.010
One is it'll help you understand
the service better.

00:11:13.010 --> 00:11:14.810
But it will also help
you understand where

00:11:14.810 --> 00:11:15.830
the service is going.

00:11:15.830 --> 00:11:18.540
Because these principles
are still in effect.

00:11:18.540 --> 00:11:19.990
These principles
are driving our

00:11:19.990 --> 00:11:20.980
day-to-day decisions today.

00:11:20.980 --> 00:11:22.930
And they will continue to drive
them in the future.

00:11:22.930 --> 00:11:25.610
And we believe that these
guiding principles are very

00:11:25.610 --> 00:11:27.250
effectively manifest
in the service.

00:11:27.250 --> 00:11:28.760
And as you get a chance to play
with it, as you get a

00:11:28.760 --> 00:11:30.910
chance to use it, you'll
experience it for yourself.

00:11:33.720 --> 00:11:36.040
And our first guiding principle
here, the thing that

00:11:36.040 --> 00:11:38.300
trumps everything,
is security.

00:11:38.300 --> 00:11:41.800
We recognize that your data
is your business.

00:11:41.800 --> 00:11:44.510
And to win your custom, to win
your trust, we have to treat

00:11:44.510 --> 00:11:46.300
that data with a tremendous
amount of respect, and we have

00:11:46.300 --> 00:11:49.270
to create very strong controls
to ensure the security of your

00:11:49.270 --> 00:11:52.160
data and to ensure the privacy
of your users.

00:11:52.160 --> 00:11:55.250
And so at every stage of the
game, we focused on delivering

00:11:55.250 --> 00:11:56.950
strong security controls.

00:11:56.950 --> 00:12:00.630
A couple of examples of
this are our network.

00:12:00.630 --> 00:12:04.420
Any data that transits between
virtual machines, whether

00:12:04.420 --> 00:12:06.500
they're sitting on the same rack
right next to each other

00:12:06.500 --> 00:12:09.890
or whether they're going
thousands of miles across

00:12:09.890 --> 00:12:15.080
regions, runs on Google's
global private network.

00:12:15.080 --> 00:12:16.090
It's secure.

00:12:16.090 --> 00:12:18.510
There's very high levels of
encapsulation that we've

00:12:18.510 --> 00:12:21.340
applied to ensure that no one
can intercept those packets or

00:12:21.340 --> 00:12:23.690
to try to attempt to ensure
that no one can intercept

00:12:23.690 --> 00:12:27.000
those packets and drive the
security of the system.

00:12:27.000 --> 00:12:29.220
We also encrypt all
data at rest.

00:12:29.220 --> 00:12:30.790
This is really important.

00:12:30.790 --> 00:12:32.060
Our customers have
asked for this.

00:12:32.060 --> 00:12:34.130
Our customers demand it, and
so we've provided it.

00:12:34.130 --> 00:12:36.830
So any data that's written to
our block devices, whether

00:12:36.830 --> 00:12:40.590
it's at the system block device
or our local disk, is

00:12:40.590 --> 00:12:41.800
encrypted at rest.

00:12:41.800 --> 00:12:43.790
And because we're doing that,
we're able to do that very

00:12:43.790 --> 00:12:44.390
efficiently.

00:12:44.390 --> 00:12:46.000
So you don't see noticeable
performance

00:12:46.000 --> 00:12:49.870
impact of that control.

00:12:49.870 --> 00:12:52.810
The next criteria that
we focused on is

00:12:52.810 --> 00:12:53.950
tremendously important.

00:12:53.950 --> 00:12:55.000
This is a little bit nuanced.

00:12:55.000 --> 00:12:57.650
But it actually has steered us
and is probably one of the

00:12:57.650 --> 00:12:59.810
most impactful things we've
really focused on.

00:12:59.810 --> 00:13:02.120
And that's the idea
of consistency.

00:13:02.120 --> 00:13:05.050
When you're building real-world
solutions, it pays

00:13:05.050 --> 00:13:07.170
to be operating in a consistent
environment.

00:13:07.170 --> 00:13:08.270
Traditionally, you have
to design for

00:13:08.270 --> 00:13:09.160
the worst-case scenario.

00:13:09.160 --> 00:13:11.410
Sometimes you don't even know
what that's going to be.

00:13:11.410 --> 00:13:13.420
If you're operating in an
unstable environment, you have

00:13:13.420 --> 00:13:17.020
to design in controls to deal
with rapid-order scaling, and

00:13:17.020 --> 00:13:20.090
it adds a lot of degrees of
freedom to the solution.

00:13:20.090 --> 00:13:22.430
And so at every stage of the
game, we focused on creating a

00:13:22.430 --> 00:13:23.920
consistent environment.

00:13:23.920 --> 00:13:26.850
Our target here is not a
massively multi-tenant cloud.

00:13:26.850 --> 00:13:28.400
That's not what we're
trying to deliver.

00:13:28.400 --> 00:13:31.650
Our target here is to deliver an
experience, an environment

00:13:31.650 --> 00:13:33.230
that feels like you're
in a data center.

00:13:33.230 --> 00:13:34.870
That's the class of consistency
that we're trying

00:13:34.870 --> 00:13:35.990
to achieve.

00:13:35.990 --> 00:13:38.860
And to support this, one of
the things we've been very

00:13:38.860 --> 00:13:40.930
concerned about as we've seen
what's been happening in the

00:13:40.930 --> 00:13:45.040
cloud is the movement away from
the separation of storage

00:13:45.040 --> 00:13:46.500
and compute.

00:13:46.500 --> 00:13:49.580
We've seen 20 years of sand
development, where enterprises

00:13:49.580 --> 00:13:51.480
have moved to a world where
they're able to effectively

00:13:51.480 --> 00:13:52.600
decouple these two things.

00:13:52.600 --> 00:13:54.220
And it creates a great
degree of control and

00:13:54.220 --> 00:13:55.820
flexibility for them.

00:13:55.820 --> 00:13:59.100
It made us a little bit sad when
we observed that people

00:13:59.100 --> 00:14:04.020
were moving to a world where
storage was getting pushed

00:14:04.020 --> 00:14:06.500
back into the compute container
because the storage

00:14:06.500 --> 00:14:08.580
block devices were just not
able to achieve the

00:14:08.580 --> 00:14:10.600
performance and the consistency
of performance

00:14:10.600 --> 00:14:12.840
necessary to meet
enterprise-level SLAs.

00:14:12.840 --> 00:14:14.820
So that's one of the things
we've focused on

00:14:14.820 --> 00:14:17.190
significantly, and we've paid
a tremendous amount of

00:14:17.190 --> 00:14:20.240
attention to, is creating a
persistent block device that

00:14:20.240 --> 00:14:23.610
offers better characteristics
in terms of performance,

00:14:23.610 --> 00:14:25.810
better characteristics in
terms of throughput than

00:14:25.810 --> 00:14:28.670
writing to our local block
device on disk.

00:14:28.670 --> 00:14:29.920
And that's really
important to us.

00:14:33.250 --> 00:14:37.140
The next principle, and this is
kind of obvious to us and

00:14:37.140 --> 00:14:38.800
it's really steered
our decision, is

00:14:38.800 --> 00:14:39.900
we have to be open.

00:14:39.900 --> 00:14:41.410
We have to be flexible.

00:14:41.410 --> 00:14:43.640
There's a tremendous amount of
code that exists out there.

00:14:43.640 --> 00:14:46.850
People have invested probably
trillions of dollars in

00:14:46.850 --> 00:14:47.470
developing code.

00:14:47.470 --> 00:14:49.920
It makes sense for them to be
able to take that code and run

00:14:49.920 --> 00:14:52.580
it in our data centers on this
awesome infrastructure.

00:14:52.580 --> 00:14:56.450
And the open source community is
just this incredible source

00:14:56.450 --> 00:14:57.620
of innovation.

00:14:57.620 --> 00:15:00.030
It's a tremendously
innovative space.

00:15:00.030 --> 00:15:02.500
We think our customers should
be able to take whatever the

00:15:02.500 --> 00:15:04.660
open source community is
producing and be able to run

00:15:04.660 --> 00:15:06.870
it on our infrastructure and
achieve the benefits of what

00:15:06.870 --> 00:15:07.640
we're doing.

00:15:07.640 --> 00:15:10.840
So we focused on creating
an open ecosystem.

00:15:10.840 --> 00:15:13.000
We've also focused on things
like an open API.

00:15:13.000 --> 00:15:16.570
As Chris mentioned, our tools
are all built on an open API.

00:15:16.570 --> 00:15:17.850
We don't have any back doors.

00:15:17.850 --> 00:15:18.470
There's no cheating.

00:15:18.470 --> 00:15:20.230
You can get in there, and
you can extend our

00:15:20.230 --> 00:15:21.400
stack at any level.

00:15:21.400 --> 00:15:23.090
And we really like the idea of
being able to plug into our

00:15:23.090 --> 00:15:24.360
stack at any level.

00:15:24.360 --> 00:15:27.600
And it's also about
the ecosystem.

00:15:27.600 --> 00:15:29.780
Our goal is to deliver
beautiful, pure,

00:15:29.780 --> 00:15:31.850
high-performance, affordable
infrastructure.

00:15:31.850 --> 00:15:35.140
And we really want to create
a vibrant, strong, partner

00:15:35.140 --> 00:15:37.850
ecosystem that can deliver
great experiences when

00:15:37.850 --> 00:15:40.980
managing this and great
experiences for our users when

00:15:40.980 --> 00:15:43.020
they want to move workloads
around.

00:15:49.380 --> 00:15:52.280
And then it's about being
proven, and being proven to us

00:15:52.280 --> 00:15:54.060
means one thing, really.

00:15:54.060 --> 00:15:56.185
This has to be a technology that
we're willing to bet our

00:15:56.185 --> 00:15:57.440
own business on.

00:15:57.440 --> 00:16:00.600
So as we've gone-- and it's
still early days for us with

00:16:00.600 --> 00:16:03.520
the stack we're just bringing
it into the market now with

00:16:03.520 --> 00:16:04.970
this initial offering.

00:16:04.970 --> 00:16:06.740
But we are running Google
businesses on

00:16:06.740 --> 00:16:08.620
this technology today.

00:16:08.620 --> 00:16:10.590
So it's one technology for
internal businesses, and it's

00:16:10.590 --> 00:16:12.260
one technology for the
outside business.

00:16:12.260 --> 00:16:13.730
And it's the same technology.

00:16:13.730 --> 00:16:16.750
One example of this
is Invite Media.

00:16:16.750 --> 00:16:17.940
Urs mentioned it today.

00:16:17.940 --> 00:16:19.740
And we're very lucky to have
Hansa, who will be talking in

00:16:19.740 --> 00:16:22.160
a later tech session about their
experiences when moving

00:16:22.160 --> 00:16:25.010
to this technology stack.

00:16:25.010 --> 00:16:27.260
Long story short, they've
had a great experience.

00:16:27.260 --> 00:16:29.390
They've been able to benefit
from the power, the consistent

00:16:29.390 --> 00:16:30.860
power of the platform.

00:16:30.860 --> 00:16:32.470
They've been able to reduce
the number of cores they

00:16:32.470 --> 00:16:36.290
needed to actually run their
workload by half for similarly

00:16:36.290 --> 00:16:37.870
configured instances.

00:16:37.870 --> 00:16:40.560
And they've also been able to
benefit from the consistency

00:16:40.560 --> 00:16:44.020
of experience, where some of the
variance that resulted in

00:16:44.020 --> 00:16:47.750
some errors, in bidding in their
case, just went away

00:16:47.750 --> 00:16:50.640
because of this much more
robust, consistent platform

00:16:50.640 --> 00:16:55.050
than what they'd had previously
building in another

00:16:55.050 --> 00:16:56.300
multi-tenant cloud
environment.

00:17:00.630 --> 00:17:03.040
So I mentioned this when I was
talking a little bit about

00:17:03.040 --> 00:17:03.840
being open.

00:17:03.840 --> 00:17:05.411
And it's worth just
really calling out

00:17:05.411 --> 00:17:06.640
to our partner ecosystem.

00:17:06.640 --> 00:17:10.109
Again, we're focused on pure,
beautiful infrastructure.

00:17:10.109 --> 00:17:12.319
We're not going to do all of
everything, certainly not

00:17:12.319 --> 00:17:13.630
coming out of the gate.

00:17:13.630 --> 00:17:17.119
And so being able to tap into
the power of the ecosystem,

00:17:17.119 --> 00:17:19.250
being able to work with partners
that completed, that

00:17:19.250 --> 00:17:24.270
create the best experiences
around managing and support

00:17:24.270 --> 00:17:28.349
the mobility of workloads
between on-premises in the

00:17:28.349 --> 00:17:30.660
cloud and between
clouds as well.

00:17:30.660 --> 00:17:33.750
We believe very strongly that
you should be able to pick the

00:17:33.750 --> 00:17:36.660
cloud that makes sense based
on the merits of the core

00:17:36.660 --> 00:17:39.060
technology.

00:17:39.060 --> 00:17:40.350
We feel that very strongly.

00:17:40.350 --> 00:17:43.790
And so we've worked hard to find
a set of partners that

00:17:43.790 --> 00:17:47.790
share those values and are able
to support that mission.

00:17:47.790 --> 00:17:49.810
And ultimately for us, it really
comes down to this--

00:17:49.810 --> 00:17:52.010
we're going to deliver you a
set of servers that you can

00:17:52.010 --> 00:17:53.860
configure and run any
way you want.

00:17:53.860 --> 00:17:56.010
We recognize that it makes
sense for you to be--

00:17:56.010 --> 00:17:57.800
you probably want to think
about this in terms of

00:17:57.800 --> 00:17:59.370
services, not servers.

00:17:59.370 --> 00:18:01.495
And so this ecosystem is really
going to enable that

00:18:01.495 --> 00:18:03.940
and support that idea.

00:18:03.940 --> 00:18:09.390
So what I'd like to do now is
invite Michael Crandell, the

00:18:09.390 --> 00:18:15.300
CEO of RightScale, on stage.

00:18:15.300 --> 00:18:15.900
Here you go, Michael.

00:18:15.900 --> 00:18:20.130
MICHAEL CRANDELL: Chris,
thank you very much.

00:18:20.130 --> 00:18:20.550
Wow.

00:18:20.550 --> 00:18:23.880
It is really great to be here
at the launch of Google

00:18:23.880 --> 00:18:27.990
Compute Engine and on behalf of
RightScale to announce our

00:18:27.990 --> 00:18:29.580
support for that.

00:18:29.580 --> 00:18:31.910
We do have a live demo
for you today.

00:18:31.910 --> 00:18:34.970
But before we launch into that,
a word about RightScale.

00:18:44.460 --> 00:18:48.650
RightScale pioneered the whole
category of cloud management.

00:18:48.650 --> 00:18:51.970
And our vision since we got
started five years ago was

00:18:51.970 --> 00:18:55.870
really to open up this new world
of cloud services to

00:18:55.870 --> 00:18:59.750
everyone by making it easier
and more efficient and more

00:18:59.750 --> 00:19:03.830
reliable to run your apps and
workloads on low-level cloud

00:19:03.830 --> 00:19:07.400
infrastructure resources, so
compute storage and networking

00:19:07.400 --> 00:19:12.350
resources across a variety
of different providers.

00:19:12.350 --> 00:19:16.320
And we do this by offering a
web-based, pretty broad cloud

00:19:16.320 --> 00:19:19.070
management platform that
encompasses everything from

00:19:19.070 --> 00:19:23.270
automation to configuration,
to monitoring, user

00:19:23.270 --> 00:19:27.230
management, and so on and so
forth that really acts as an

00:19:27.230 --> 00:19:29.590
environment that's a bridge
between your apps and

00:19:29.590 --> 00:19:32.660
workloads and the low-level
infrastructures, whether

00:19:32.660 --> 00:19:35.410
they're public clouds, or
private clouds, or hybrid

00:19:35.410 --> 00:19:38.780
clouds that you want
to run them on.

00:19:38.780 --> 00:19:43.090
And so over those five years,
we've gained a lot of

00:19:43.090 --> 00:19:43.820
experience.

00:19:43.820 --> 00:19:46.640
We've had lots of customers,
a lot of traction.

00:19:46.640 --> 00:19:49.250
We've, on behalf of our
customers, launched more than

00:19:49.250 --> 00:19:52.240
4 million servers
in the cloud.

00:19:52.240 --> 00:19:55.920
We've also powered some of the
biggest scaling events that

00:19:55.920 --> 00:19:57.580
have occurred.

00:19:57.580 --> 00:20:01.270
And then finally, we've enabled
large migrations from

00:20:01.270 --> 00:20:05.900
one cloud infrastructure to
another in excess of 20,000

00:20:05.900 --> 00:20:07.770
different servers.

00:20:07.770 --> 00:20:11.670
I'd like to highlight what we
think is really special about

00:20:11.670 --> 00:20:15.930
Google Compute Engine, and
specifically three things that

00:20:15.930 --> 00:20:19.320
we believe are our
differentiators.

00:20:19.320 --> 00:20:23.430
The first one has to do with
the global private network

00:20:23.430 --> 00:20:25.450
that Google is offering,
right?

00:20:25.450 --> 00:20:29.060
I think we've all known for
some time that Google's

00:20:29.060 --> 00:20:31.580
infrastructure is a key
part of the secret

00:20:31.580 --> 00:20:33.710
sauce of the company.

00:20:33.710 --> 00:20:36.440
And it's pretty amazing that
they're actually opening that

00:20:36.440 --> 00:20:42.840
up to all of us to access and to
use on an as-you-go basis.

00:20:42.840 --> 00:20:45.240
But this global private network,
which is part of it,

00:20:45.240 --> 00:20:48.780
really enables global deployment
in a much more

00:20:48.780 --> 00:20:49.790
easier fashion.

00:20:49.790 --> 00:20:52.630
You've got basically what looks
like a private network

00:20:52.630 --> 00:20:53.880
spanning the globe.

00:20:53.880 --> 00:20:58.080
And specifically it makes
replication and disaster

00:20:58.080 --> 00:21:03.940
recovery failure isolation
strategies much, much easier.

00:21:03.940 --> 00:21:11.810
Second big point I wanted to
emphasize is fast boot times.

00:21:11.810 --> 00:21:12.620
Why does that matter?

00:21:12.620 --> 00:21:15.155
Well, it obviously matters
in terms of auto scaling.

00:21:15.155 --> 00:21:18.150
When you need to scale up
quickly, the faster that

00:21:18.150 --> 00:21:21.870
servers boot, the faster you
auto scale, but also in terms

00:21:21.870 --> 00:21:26.210
of day-to-day buildup and
tear-down of environments that

00:21:26.210 --> 00:21:30.880
we all use in the dev test
production life cycle.

00:21:30.880 --> 00:21:35.560
And we've consistently seen
boot times of two minutes.

00:21:35.560 --> 00:21:38.480
Very consistent, as Craig
mentioned, across the board,

00:21:38.480 --> 00:21:41.730
loading from cloud storage.

00:21:41.730 --> 00:21:45.970
Third area that I'd like to
emphasize is, harking back to

00:21:45.970 --> 00:21:49.790
the point about security,
encrypting data at rest.

00:21:49.790 --> 00:21:54.140
So we all know that security
is probably the top item on

00:21:54.140 --> 00:21:55.540
the minds of larger companies.

00:21:55.540 --> 00:21:59.090
But really it should be for all
of us as a requirement for

00:21:59.090 --> 00:22:00.330
using cloud.

00:22:00.330 --> 00:22:05.020
And because data is encrypted
at rest on storage to other

00:22:05.020 --> 00:22:08.370
local volumes or
network-attached storage, it

00:22:08.370 --> 00:22:10.870
couldn't be much simpler
or easier.

00:22:10.870 --> 00:22:14.770
And there's virtually no impact
on the performance, so

00:22:14.770 --> 00:22:16.780
very excited about that.

00:22:16.780 --> 00:22:18.900
There are three things I wanted
to emphasize from

00:22:18.900 --> 00:22:22.120
RightScale's point of view that
are core principles about

00:22:22.120 --> 00:22:25.190
operating in the cloud that
we've embraced as a company

00:22:25.190 --> 00:22:26.890
since we got started.

00:22:26.890 --> 00:22:29.540
And I'd like you keep these in
mind as we get into the demo

00:22:29.540 --> 00:22:31.270
in a second here.

00:22:31.270 --> 00:22:33.880
The first one is what we
call usable stuff.

00:22:33.880 --> 00:22:37.360
And what we mean by that is that
you, as developers and

00:22:37.360 --> 00:22:41.950
users, should have access to
cloud-ready components that

00:22:41.950 --> 00:22:45.060
you can get off the shelf, so
to speak, customize, if you

00:22:45.060 --> 00:22:48.150
like, but put to work
very quickly.

00:22:48.150 --> 00:22:51.610
Whether those are at a script
level, a recipe level, a

00:22:51.610 --> 00:22:55.050
server template level, or
deployments of many, many

00:22:55.050 --> 00:22:58.270
servers, you should be able to
just pick from a library, if

00:22:58.270 --> 00:23:02.220
you will, and utilize
them quickly.

00:23:02.220 --> 00:23:04.150
What comes out of that
is automation.

00:23:04.150 --> 00:23:07.520
We really believe automation
is probably the key core

00:23:07.520 --> 00:23:10.440
principle behind all of
this cloud revolution.

00:23:10.440 --> 00:23:15.340
And it stems from the famous
concept of auto scaling all

00:23:15.340 --> 00:23:18.010
the way through to the notion
of launching complex

00:23:18.010 --> 00:23:21.410
multiserver deployments that
know how to configure

00:23:21.410 --> 00:23:23.040
themselves as they come up.

00:23:25.870 --> 00:23:29.230
And then finally, what we call
workload liberation.

00:23:29.230 --> 00:23:32.020
And what we mean by that is
simply you should have freedom

00:23:32.020 --> 00:23:36.200
of choice to run your apps and
workloads on whatever cloud

00:23:36.200 --> 00:23:39.830
resource pool you choose
to based on your set of

00:23:39.830 --> 00:23:41.090
requirements.

00:23:41.090 --> 00:23:43.740
So those are three key
principles to keep in mind as

00:23:43.740 --> 00:23:45.630
we launch into the demo.

00:23:45.630 --> 00:23:49.440
And with that, I'd like to
invite my colleague Shivan up.

00:23:49.440 --> 00:23:51.580
And we'll get right into it.

00:23:51.580 --> 00:23:55.080
Shivan, can you tell us
what we have to see

00:23:55.080 --> 00:23:56.250
today as a live demo?

00:23:56.250 --> 00:23:56.540
SHIVAN BINDAL: Yes.

00:23:56.540 --> 00:23:57.560
Thank you, Michael.

00:23:57.560 --> 00:24:01.250
So we have a customer's typical
video transcoding

00:24:01.250 --> 00:24:03.000
application that we're going
to walk through.

00:24:03.000 --> 00:24:05.090
And this slide here just
kind of talks about the

00:24:05.090 --> 00:24:06.870
architecture of this
application.

00:24:06.870 --> 00:24:09.890
We're talking about taking
video files from the web,

00:24:09.890 --> 00:24:13.160
creating transcoding jobs that
are then placed onto a queue,

00:24:13.160 --> 00:24:16.870
and then having a multitude of
consumer servers taking those

00:24:16.870 --> 00:24:20.160
jobs, downloading the videos,
transcoding them, and then

00:24:20.160 --> 00:24:23.590
placing them for retrieval
from Google storage.

00:24:23.590 --> 00:24:26.440
So they're actually sending
those video

00:24:26.440 --> 00:24:28.130
files to Google storage.

00:24:28.130 --> 00:24:29.480
Let's see what that looks
like in RightScale.

00:24:32.470 --> 00:24:34.290
Here I have the RightScale
system.

00:24:34.290 --> 00:24:36.460
And this is that single pane
of glass, Michael, that you

00:24:36.460 --> 00:24:39.620
talked about, where you're
managing your cloud resources.

00:24:39.620 --> 00:24:41.990
So we're talking about compute,

00:24:41.990 --> 00:24:43.710
networking, and storage.

00:24:43.710 --> 00:24:47.060
Here we have in the clouds menu
Google Compute Engine

00:24:47.060 --> 00:24:48.130
connected to RightScale.

00:24:48.130 --> 00:24:52.380
So I've provided my credentials
and made the

00:24:52.380 --> 00:24:55.550
resources that Google makes
available available here in

00:24:55.550 --> 00:24:56.410
RightScale.

00:24:56.410 --> 00:24:59.120
And that's really where
RightScale starts in terms of

00:24:59.120 --> 00:25:00.710
the cloud management
and automation

00:25:00.710 --> 00:25:02.090
capabilities we offer.

00:25:02.090 --> 00:25:03.820
MICHAEL CRANDELL: So can you
show us that automation at

00:25:03.820 --> 00:25:07.240
work in the actual app?

00:25:07.240 --> 00:25:09.380
SHIVAN BINDAL: So with any
application, you have a

00:25:09.380 --> 00:25:12.155
variety of servers that comprise
that application.

00:25:12.155 --> 00:25:15.530
And here what we're looking at
is the set of all servers for

00:25:15.530 --> 00:25:16.740
this application.

00:25:16.740 --> 00:25:19.610
We've got three different server
types, but really a

00:25:19.610 --> 00:25:20.850
multitude of servers.

00:25:20.850 --> 00:25:24.690
In RightScale, that is displayed
as a deployment.

00:25:24.690 --> 00:25:27.570
So it's a collection of servers
for the use case here

00:25:27.570 --> 00:25:29.030
of your application.

00:25:29.030 --> 00:25:31.000
Three different types of
servers, as I mentioned.

00:25:31.000 --> 00:25:34.720
We've got that producer who's
creating all the jobs.

00:25:34.720 --> 00:25:36.550
We've got the queue
server that's

00:25:36.550 --> 00:25:37.830
holding all of the jobs.

00:25:37.830 --> 00:25:40.060
And then we've got the consumers
down here that are

00:25:40.060 --> 00:25:42.960
running all the jobs and doing
all the transcoding.

00:25:42.960 --> 00:25:45.450
Each of these types of servers
are running on top of what's

00:25:45.450 --> 00:25:47.880
called a server template
within RightScale.

00:25:47.880 --> 00:25:51.160
A server template is considered
a blueprint of how

00:25:51.160 --> 00:25:55.470
your servers will reliably and
consistently be launched every

00:25:55.470 --> 00:25:58.610
single time in the cloud so that
they are coming up with

00:25:58.610 --> 00:26:01.680
the same state, with the same
configuration so that things

00:26:01.680 --> 00:26:03.240
are actually usable.

00:26:03.240 --> 00:26:07.110
And to really understand how
we're operating here at scale,

00:26:07.110 --> 00:26:11.250
I've got about 325-odd
servers that are

00:26:11.250 --> 00:26:13.330
running this workload.

00:26:13.330 --> 00:26:15.510
And here you'll see with
RightScale's built-in

00:26:15.510 --> 00:26:20.030
monitoring the capability that
that compute power provides.

00:26:20.030 --> 00:26:24.080
So each of these graphs is a
single CPU from the servers

00:26:24.080 --> 00:26:25.740
that we're looking at.

00:26:25.740 --> 00:26:30.650
And the blue here shows the
actual load on the CPUs for

00:26:30.650 --> 00:26:32.320
doing the video transcoding.

00:26:32.320 --> 00:26:35.650
So, Michael, here you have, at
scale, an application running

00:26:35.650 --> 00:26:38.680
on Google Compute Engine
managed via RightScale.

00:26:38.680 --> 00:26:39.750
MICHAEL CRANDELL: So cool.

00:26:39.750 --> 00:26:41.370
And by the way, audiences
normally

00:26:41.370 --> 00:26:42.580
applaud at this juncture.

00:26:42.580 --> 00:26:48.010
[LAUGHTER AND APPLAUSE]

00:26:48.010 --> 00:26:49.530
MICHAEL CRANDELL: It's very,
very exciting to us.

00:26:49.530 --> 00:26:51.400
So thanks for your
forbearance.

00:26:51.400 --> 00:26:53.210
What else do we have to show?

00:26:53.210 --> 00:26:55.120
SHIVAN BINDAL: Any application
is living and breathing.

00:26:55.120 --> 00:26:57.790
This is one example of how you
might transcode some video.

00:26:57.790 --> 00:27:00.030
But what happens if you have new
sources of video that you

00:27:00.030 --> 00:27:01.530
need to start transcoding?

00:27:01.530 --> 00:27:06.130
How quickly can you reuse this
environment for a new use case

00:27:06.130 --> 00:27:09.370
or new instantiation of
the same application?

00:27:09.370 --> 00:27:11.190
Well, with RightScale,
it's fairly simple.

00:27:11.190 --> 00:27:13.170
I'm going to take what we call
the deployment, that

00:27:13.170 --> 00:27:15.680
collection of servers,
and clone it.

00:27:15.680 --> 00:27:18.960
By cloning it, I'm taking the
configurations that we had and

00:27:18.960 --> 00:27:22.810
making them available for
configuration in the new case

00:27:22.810 --> 00:27:24.130
or the new instance.

00:27:24.130 --> 00:27:26.610
And what I'm going to do with
just a few clicks is I'm going

00:27:26.610 --> 00:27:33.420
to start launching that entire
deployment of servers so that

00:27:33.420 --> 00:27:35.360
they're available to start
doing these jobs again.

00:27:35.360 --> 00:27:38.440
What I've just done is I've
enabled what RightScale calls

00:27:38.440 --> 00:27:42.100
a server array, which has
all of those workers

00:27:42.100 --> 00:27:43.590
now starting to launch.

00:27:43.590 --> 00:27:46.380
And now I'm just going to go
ahead and launch up the queue

00:27:46.380 --> 00:27:50.510
and video producer or the server
that's going to create

00:27:50.510 --> 00:27:51.850
all these jobs.

00:27:51.850 --> 00:27:53.650
I'm going to launch
that as well.

00:27:53.650 --> 00:27:54.830
And what you're going to see--

00:27:54.830 --> 00:27:56.940
I actually clicked it.

00:27:56.940 --> 00:27:57.990
It does look like
it's clicked.

00:27:57.990 --> 00:28:00.390
So what actually happens
now is you'll see these

00:28:00.390 --> 00:28:01.220
servers come up.

00:28:01.220 --> 00:28:03.210
And as this comes up--
it'll take a few

00:28:03.210 --> 00:28:04.210
minutes to actually happen.

00:28:04.210 --> 00:28:07.160
But from my perspective as
a user, that's all the

00:28:07.160 --> 00:28:08.620
interaction I need
with RightScale.

00:28:08.620 --> 00:28:10.430
You'll see they're already
in pending state.

00:28:10.430 --> 00:28:14.290
And now, again Michael, these
325 servers plus these other

00:28:14.290 --> 00:28:16.240
two servers that are doing a lot
of the command and control

00:28:16.240 --> 00:28:18.290
stuff all launched through
RightScale.

00:28:18.290 --> 00:28:18.950
MICHAEL CRANDELL: Thank you.

00:28:18.950 --> 00:28:21.370
And on the left-hand side there,
you can see in the

00:28:21.370 --> 00:28:25.760
events window the activity
starting to propagate.

00:28:25.760 --> 00:28:28.770
Well, behind every demo there's
usually a little bit

00:28:28.770 --> 00:28:29.960
of an interesting story.

00:28:29.960 --> 00:28:31.910
Could you tell us the back-story
of what really

00:28:31.910 --> 00:28:33.800
happened to put this together?

00:28:33.800 --> 00:28:35.160
SHIVAN BINDAL: Two things that
I'd like to point out.

00:28:35.160 --> 00:28:39.700
One is, as with any demo, we
were building this demo out as

00:28:39.700 --> 00:28:41.490
we were completing our
integration with Google

00:28:41.490 --> 00:28:42.650
Compute Engine.

00:28:42.650 --> 00:28:43.950
And so--

00:28:43.950 --> 00:28:47.480
funny story-- we built this
application on another cloud.

00:28:47.480 --> 00:28:49.970
But with RightScale's technology
of server templates

00:28:49.970 --> 00:28:51.690
and the configuration management
that we bring to

00:28:51.690 --> 00:28:54.860
the table, it was fairly simple
for us to take that

00:28:54.860 --> 00:28:57.840
application and launch it on
Google Compute Engine.

00:28:57.840 --> 00:29:00.440
And it really just worked,
which was really very

00:29:00.440 --> 00:29:02.790
fascinating and exciting.

00:29:02.790 --> 00:29:05.590
The second point is we didn't
have a lot of time.

00:29:05.590 --> 00:29:08.160
So when we built the application
to do the video

00:29:08.160 --> 00:29:10.450
transcoding, we wanted to
keep things simple.

00:29:10.450 --> 00:29:13.860
We started with using only one
core, making things very

00:29:13.860 --> 00:29:18.180
streamlined in terms of
one video per job.

00:29:18.180 --> 00:29:21.990
And so what that meant was we
ended up launching a whole ton

00:29:21.990 --> 00:29:24.330
of instances or virtual machines
on Google Compute

00:29:24.330 --> 00:29:27.180
Engine to do all of the work
for us and keep the

00:29:27.180 --> 00:29:29.060
application layer very simple.

00:29:29.060 --> 00:29:30.440
MICHAEL CRANDELL: So it makes
sense to make the

00:29:30.440 --> 00:29:32.855
infrastructure do the work,
not the developers.

00:29:32.855 --> 00:29:34.650
That probably resonates
with some of you

00:29:34.650 --> 00:29:36.180
out there, that idea.

00:29:36.180 --> 00:29:38.290
So just to prove the point
and show that we're doing

00:29:38.290 --> 00:29:40.910
something real, can you show
some of the output that came

00:29:40.910 --> 00:29:42.800
out of the transcoder?

00:29:42.800 --> 00:29:44.890
SHIVAN BINDAL: So here I
have Google Storage,

00:29:44.890 --> 00:29:45.790
Google Cloud Storage.

00:29:45.790 --> 00:29:49.180
This is the storage browser
that's available by Google.

00:29:49.180 --> 00:29:51.720
And anybody who has a project
and access to Google

00:29:51.720 --> 00:29:52.980
Cloud can see this.

00:29:52.980 --> 00:29:56.430
This is one of the videos
that we've transcoded.

00:29:56.430 --> 00:29:58.400
And, well, we can play
it really quickly.

00:29:58.400 --> 00:30:00.840
But what I wanted to highlight
is that we saw some really

00:30:00.840 --> 00:30:04.280
great performance in terms of
the communication between

00:30:04.280 --> 00:30:07.350
Google Compute Engine virtual
machines and Google Storage,

00:30:07.350 --> 00:30:11.350
just very low-latent
connectivity

00:30:11.350 --> 00:30:12.660
and very high bandwidth.

00:30:12.660 --> 00:30:14.590
So it was very quick.

00:30:14.590 --> 00:30:17.890
And to play this video,
let's see if I can

00:30:17.890 --> 00:30:20.044
full screen it here.

00:30:20.044 --> 00:30:20.536
[VIDEO PLAYBACK]

00:30:20.536 --> 00:30:24.050
-When we started working with
the team at Google, it was

00:30:24.050 --> 00:30:26.970
very clear from the very
beginning that this is an

00:30:26.970 --> 00:30:28.260
all-out effort.

00:30:28.260 --> 00:30:29.100
This is serious.

00:30:29.100 --> 00:30:30.670
This is worldwide.

00:30:30.670 --> 00:30:33.850
This leverages the full depth
of Google engineering.

00:30:33.850 --> 00:30:35.300
[END VIDEO PLAYBACK]

00:30:35.300 --> 00:30:35.660
MICHAEL CRANDELL: Cool.

00:30:35.660 --> 00:30:36.720
There you have it.

00:30:36.720 --> 00:30:37.560
That's the video.

00:30:37.560 --> 00:30:40.794
[APPLAUSE]

00:30:40.794 --> 00:30:43.630
MICHAEL CRANDELL: That, by the
way, is our CTO and co-founder

00:30:43.630 --> 00:30:45.090
Thorsten, if you'll
wave your hand.

00:30:45.090 --> 00:30:47.240
We're all around
through Friday.

00:30:47.240 --> 00:30:49.030
We have a sandbox here.

00:30:49.030 --> 00:30:53.010
We also have our private beta of
support for Compute Engine

00:30:53.010 --> 00:30:55.780
at rightscale.com/google.

00:30:55.780 --> 00:30:57.060
Very much looking forward
to partnering.

00:30:57.060 --> 00:30:57.130
Thank you so much.

00:30:57.130 --> 00:30:57.330
CRAIG MCLUCKIE: Wonderful.

00:30:57.330 --> 00:30:58.080
Thank you, Michael.

00:30:58.080 --> 00:31:00.680
It's wonderful that you can
deploy such large, complex

00:31:00.680 --> 00:31:01.930
services with the click
of a button.

00:31:01.930 --> 00:31:02.195
MICHAEL CRANDELL: Absolutely.

00:31:02.195 --> 00:31:03.470
CRAIG MCLUCKIE: And we also
love the fact you can move

00:31:03.470 --> 00:31:04.180
between clouds, so--

00:31:04.180 --> 00:31:04.510
MICHAEL CRANDELL: All right.

00:31:04.510 --> 00:31:04.610
CRAIG MCLUCKIE: Thank
you for your time.

00:31:04.610 --> 00:31:06.352
MICHAEL CRANDELL: Thank you.

00:31:06.352 --> 00:31:13.030
[APPLAUSE]

00:31:13.030 --> 00:31:13.490
CRAIG MCLUCKIE: All right.

00:31:13.490 --> 00:31:16.180
So let's get into a little
bit more detail about the

00:31:16.180 --> 00:31:18.900
technology and help you
understand some of the

00:31:18.900 --> 00:31:20.680
specifics of what we're
actually doing here.

00:31:23.970 --> 00:31:26.950
I'm gonna start off and just
walk through the stack.

00:31:26.950 --> 00:31:31.250
And the logical place to start,
again, is Compute.

00:31:31.250 --> 00:31:33.150
You've already seen the
virtual machines.

00:31:33.150 --> 00:31:35.660
These are KVM-based machines.

00:31:35.660 --> 00:31:39.920
So we were running on
the KVM hypervisor.

00:31:39.920 --> 00:31:42.440
And we've worked pretty closely
with Red Hat for quite

00:31:42.440 --> 00:31:46.050
a while to get to a point where
we have a very secure,

00:31:46.050 --> 00:31:48.400
highly performant,
high-consistency environment

00:31:48.400 --> 00:31:51.080
to host these class of
virtual machines.

00:31:51.080 --> 00:31:55.350
We really appreciate the
leadership that Red Hat has

00:31:55.350 --> 00:31:56.120
shown in this space.

00:31:56.120 --> 00:31:58.570
And we'll continue to work
with them in the future.

00:31:58.570 --> 00:32:01.410
These virtual machines are
available in multiple sizes,

00:32:01.410 --> 00:32:05.250
so you can get them in one, two,
four, and eight cores.

00:32:05.250 --> 00:32:08.550
And they come with 3.75
gigabytes of RAM per core.

00:32:08.550 --> 00:32:10.780
So these are pretty beefy
virtual machines.

00:32:10.780 --> 00:32:13.910
Our smallest virtual machines is
actually quite a lot bigger

00:32:13.910 --> 00:32:15.720
than the smallest virtual
machines you'll see elsewhere.

00:32:15.720 --> 00:32:17.660
So that's something to think
about as you actually look at

00:32:17.660 --> 00:32:18.580
what we're doing.

00:32:18.580 --> 00:32:19.550
And that makes sense here.

00:32:19.550 --> 00:32:22.820
Because what we really focused
on is delivering

00:32:22.820 --> 00:32:25.910
high-performance computing,
like lots of compute power

00:32:25.910 --> 00:32:28.490
that you can access and tap
into just because of these

00:32:28.490 --> 00:32:29.740
data-center characteristics.

00:32:32.060 --> 00:32:34.120
And we offer two versions
of Linux.

00:32:34.120 --> 00:32:36.950
We have Ubuntu and CentOS
out of the gate.

00:32:36.950 --> 00:32:39.300
But you can actually take
whatever you want, any

00:32:39.300 --> 00:32:43.380
Linux-based image, and create
bootable images and run what

00:32:43.380 --> 00:32:46.030
you want to in this
environment.

00:32:46.030 --> 00:32:47.140
Storage.

00:32:47.140 --> 00:32:50.140
I mentioned this earlier, and
we have a variety of storage

00:32:50.140 --> 00:32:54.230
capabilities to meet different
needs, two block devices that

00:32:54.230 --> 00:32:57.430
enable you to run familiar
workloads that require a block

00:32:57.430 --> 00:32:59.140
device to support them.

00:32:59.140 --> 00:33:02.770
The first is persistent disk,
our off-instance, durably

00:33:02.770 --> 00:33:04.390
replicated, storage medium.

00:33:04.390 --> 00:33:07.060
This is a very high-consistency,

00:33:07.060 --> 00:33:10.330
high-throughput solution that
enables you to store data

00:33:10.330 --> 00:33:12.650
securely that lives beyond
the life of your

00:33:12.650 --> 00:33:13.650
virtual machine instance.

00:33:13.650 --> 00:33:16.510
So this is the place where you
would want to write stuff,

00:33:16.510 --> 00:33:18.335
like if you wanted to run a
database, for example, this

00:33:18.335 --> 00:33:20.700
would be a great backing
store for a database.

00:33:20.700 --> 00:33:22.550
We also provide a kind
of cheap and

00:33:22.550 --> 00:33:24.850
cheerful local disk option.

00:33:24.850 --> 00:33:27.400
We recognize that our focus
workloads are very

00:33:27.400 --> 00:33:28.360
data-centric.

00:33:28.360 --> 00:33:31.700
So it makes sense to have access
to a lot of affordable

00:33:31.700 --> 00:33:35.340
storage that's coupled to your
virtual machines to store data

00:33:35.340 --> 00:33:37.980
that your processing
as a cache.

00:33:37.980 --> 00:33:40.870
This data is bound to the life
cycle of your virtual machine.

00:33:40.870 --> 00:33:43.300
So if you stop your virtual
machine, this data is

00:33:43.300 --> 00:33:47.070
permanently gone because we
encrypted at rest, and that

00:33:47.070 --> 00:33:48.880
key is only ever stored in
the virtual machine.

00:33:48.880 --> 00:33:51.270
So when the virtual machine goes
away, the data goes away.

00:33:51.270 --> 00:33:53.630
That's something to consider as
you're building solutions

00:33:53.630 --> 00:33:57.020
on this technology, is
definitely If you have

00:33:57.020 --> 00:33:58.540
something you want to store
beyond the life cycle of the

00:33:58.540 --> 00:34:02.030
virtual machine, persistent
disk is the way to go.

00:34:02.030 --> 00:34:03.710
And then there's Google
Cloud Storage.

00:34:03.710 --> 00:34:07.600
Google Cloud Storage is our
enterprise-grade, internet

00:34:07.600 --> 00:34:08.530
object store.

00:34:08.530 --> 00:34:12.170
So this is the place you can go
to write objects that need

00:34:12.170 --> 00:34:13.520
to be accessible by
the internet.

00:34:13.520 --> 00:34:15.420
It has some really interesting
characteristics.

00:34:15.420 --> 00:34:17.120
I'll pick on two of
them, but it's a

00:34:17.120 --> 00:34:19.199
pretty interesting service.

00:34:19.199 --> 00:34:22.630
The first characteristic is
that it benefits from our

00:34:22.630 --> 00:34:25.420
global high-performance
network backbone.

00:34:25.420 --> 00:34:27.690
So it almost comes with
a CDN baked in.

00:34:27.690 --> 00:34:30.540
So the content that you want to
access will be replicated

00:34:30.540 --> 00:34:31.940
to the place where you
need it and will be

00:34:31.940 --> 00:34:33.030
accessible very quickly.

00:34:33.030 --> 00:34:34.940
And we invite our customers
to try this out.

00:34:34.940 --> 00:34:35.650
We think the performance

00:34:35.650 --> 00:34:37.460
characteristics are really good.

00:34:37.460 --> 00:34:39.449
The other thing that it offers
is read-your-write

00:34:39.449 --> 00:34:41.909
consistency, which is an
interesting characteristic

00:34:41.909 --> 00:34:43.960
when you're trying to build
a system at scale.

00:34:43.960 --> 00:34:46.300
It's nice to have an object
store that you can write

00:34:46.300 --> 00:34:49.300
content to with that level
of predictability.

00:34:49.300 --> 00:34:51.190
And we found it very useful
as we've developed our own

00:34:51.190 --> 00:34:52.750
solutions in this space.

00:34:55.800 --> 00:34:56.980
Network.

00:34:56.980 --> 00:34:58.180
Our network really shines.

00:34:58.180 --> 00:35:00.150
It's one of things that
I think truly

00:35:00.150 --> 00:35:01.640
distinguishes the service.

00:35:01.640 --> 00:35:03.760
Our private network enables
you to fuse these virtual

00:35:03.760 --> 00:35:05.970
machines together very
efficiently.

00:35:05.970 --> 00:35:08.440
And it offers tremendous
network

00:35:08.440 --> 00:35:09.740
cross-sectional bandwidth.

00:35:09.740 --> 00:35:11.770
We really invite our early
customers to try this out.

00:35:11.770 --> 00:35:13.580
We think this is going to be
something that's very distinct

00:35:13.580 --> 00:35:14.590
about the service.

00:35:14.590 --> 00:35:16.390
And we'll have a demo in a
little bit that kind of

00:35:16.390 --> 00:35:19.340
showcases some of these
interesting performance

00:35:19.340 --> 00:35:22.490
characteristics in this cloud.

00:35:22.490 --> 00:35:24.620
And then, obviously, no virtual
machine stands alone,

00:35:24.620 --> 00:35:26.950
so the ability to assign a
static IP address to the

00:35:26.950 --> 00:35:29.640
machine that you can maintain
for a long time.

00:35:29.640 --> 00:35:31.490
And these IP addresses
are actually global.

00:35:31.490 --> 00:35:35.540
You can remap that IP address to
another machine in another

00:35:35.540 --> 00:35:37.920
region that's the geographically
isolated.

00:35:37.920 --> 00:35:39.850
And Google's network will just
take care of making sure that

00:35:39.850 --> 00:35:42.140
the traffic gets to the
right location.

00:35:42.140 --> 00:35:43.990
And then, obviously,
firewalls.

00:35:43.990 --> 00:35:46.620
You have to be able to secure
your virtual machines.

00:35:46.620 --> 00:35:48.830
You want to be able to control
who can access them.

00:35:48.830 --> 00:35:52.010
So we have a very simple
intuitive firewall setup that

00:35:52.010 --> 00:35:54.680
enables you to very specifically
control who talks

00:35:54.680 --> 00:35:55.930
to what in the system.

00:36:01.170 --> 00:36:02.890
And tooling.

00:36:02.890 --> 00:36:05.100
Chris demonstrated our
tools briefly.

00:36:05.100 --> 00:36:08.430
And he showed you the little UI
tool that we've developed.

00:36:08.430 --> 00:36:10.570
And we think that's an
interesting metaphor for us.

00:36:10.570 --> 00:36:12.020
It really shows and
demonstrates our

00:36:12.020 --> 00:36:13.480
commitment to openness.

00:36:13.480 --> 00:36:16.630
By all means, we're gonna make
that source code available.

00:36:16.630 --> 00:36:17.740
It runs in App Engine.

00:36:17.740 --> 00:36:20.120
We think App Engine's a great
environment to write this

00:36:20.120 --> 00:36:22.800
class of management tool, to
control clusters, and to get a

00:36:22.800 --> 00:36:23.700
view of the clusters.

00:36:23.700 --> 00:36:25.720
So the fusion of those two
technologies together is

00:36:25.720 --> 00:36:27.140
actually pretty powerful.

00:36:27.140 --> 00:36:30.310
And then we have for the command
line and client, we

00:36:30.310 --> 00:36:33.190
have a very nice little
command-line tool that

00:36:33.190 --> 00:36:36.150
provides and exposes the full
flexibility of API.

00:36:36.150 --> 00:36:37.350
And then, of course, we
have our partners.

00:36:37.350 --> 00:36:39.940
Our partners are contributing
tremendously

00:36:39.940 --> 00:36:41.270
to our tooling story.

00:36:41.270 --> 00:36:43.040
They've enabled us to really
focus on getting the

00:36:43.040 --> 00:36:45.730
infrastructure right, knowing
that folks that need a

00:36:45.730 --> 00:36:48.930
best-of-breed management story
have someplace to go.

00:36:53.800 --> 00:36:57.650
And with that, I'd like to
invite our friends from MapR

00:36:57.650 --> 00:37:03.120
on stage to do a little demo.

00:37:03.120 --> 00:37:04.290
And they're going to show--

00:37:04.290 --> 00:37:07.360
as I mentioned, this service is
really about execution at

00:37:07.360 --> 00:37:10.330
scale and experiencing the
power and efficiency of

00:37:10.330 --> 00:37:12.620
Google's data centers to solve
some large problems.

00:37:12.620 --> 00:37:13.590
And they have some really
interesting

00:37:13.590 --> 00:37:15.402
technology to do just that.

00:37:15.402 --> 00:37:16.060
JOHN SCHROEDER: All right.

00:37:16.060 --> 00:37:16.730
Thanks, Craig.

00:37:16.730 --> 00:37:19.120
And thanks to Google
for inviting us

00:37:19.120 --> 00:37:20.590
to be up here today.

00:37:20.590 --> 00:37:21.360
I'm John Schroeder.

00:37:21.360 --> 00:37:24.290
I'm the CEO and co-founder
of MapR Technologies.

00:37:24.290 --> 00:37:29.160
And MC Srivas is the chief
technology officer and founded

00:37:29.160 --> 00:37:31.740
the company with me a little
over three years ago.

00:37:31.740 --> 00:37:34.010
And actually, Srivas is
an ex-Googler as well.

00:37:34.010 --> 00:37:36.590
So let's see, how do
I advance this?

00:37:44.330 --> 00:37:47.380
So before I get into MapR, I
thought I'd give some of our

00:37:47.380 --> 00:37:49.220
impressions of the Google
Compute Engine.

00:37:49.220 --> 00:37:52.970
And when we first got access to
Google Compute Engine, the

00:37:52.970 --> 00:37:56.190
engineers came to me the same
day and said John, this is

00:37:56.190 --> 00:37:57.560
blazing fast.

00:37:57.560 --> 00:38:00.090
Performance is really
important to MapR.

00:38:00.090 --> 00:38:02.750
And we can tell it's
also important to

00:38:02.750 --> 00:38:04.570
Google Compute Engine.

00:38:07.260 --> 00:38:09.660
With our platform, we're able to
drive a lot of bandwidth to

00:38:09.660 --> 00:38:12.450
disk and really drive network
bandwidth as well.

00:38:12.450 --> 00:38:14.550
And we're impressed with
the performance there.

00:38:14.550 --> 00:38:16.580
And then our technology runs on

00:38:16.580 --> 00:38:18.310
large clusters of computers.

00:38:18.310 --> 00:38:21.350
And we put a lot of effort into
building our own QA lab

00:38:21.350 --> 00:38:25.080
internally to do testing of very
large deployments and our

00:38:25.080 --> 00:38:26.700
customer base as well.

00:38:26.700 --> 00:38:29.680
But with Google Compute Engine,
we could quickly spin

00:38:29.680 --> 00:38:34.480
up 1,000, 1,200, 1,600 servers
in a matter of minutes and run

00:38:34.480 --> 00:38:37.250
those types of scalable
applications.

00:38:37.250 --> 00:38:40.650
And then finally, I got a
glimpse at the pricing over

00:38:40.650 --> 00:38:41.850
the last few days.

00:38:41.850 --> 00:38:44.020
And it's very compelling.

00:38:44.020 --> 00:38:46.680
I think that it really
changes the game.

00:38:46.680 --> 00:38:50.130
And any organization that's
looking to move some or all of

00:38:50.130 --> 00:38:52.960
their on-premise computing into
the cloud really should

00:38:52.960 --> 00:38:57.020
take a hard look at Google
Compute Engine.

00:38:57.020 --> 00:39:05.630
So we're going to use MapR to
demonstrate some of the speed

00:39:05.630 --> 00:39:07.930
and scale of Google
Compute Engine.

00:39:07.930 --> 00:39:09.280
So let me tell you a little
bit about MapR.

00:39:09.280 --> 00:39:13.180
We're a provider of an open
enterprise-grade Hadoop

00:39:13.180 --> 00:39:14.470
distribution.

00:39:14.470 --> 00:39:18.150
So we really take Hadoop and
really have transformed it

00:39:18.150 --> 00:39:22.000
into a very reliable compute
platform and

00:39:22.000 --> 00:39:23.280
dependable data store.

00:39:23.280 --> 00:39:26.390
We've done a lot of
standards-based extensions to

00:39:26.390 --> 00:39:28.100
Hadoop to really broaden
the use cases

00:39:28.100 --> 00:39:29.810
it's appropriate for.

00:39:29.810 --> 00:39:32.860
We've got deployments at
thousands of companies,

00:39:32.860 --> 00:39:36.640
customers in most of the major
vertical market segments,

00:39:36.640 --> 00:39:41.130
including financial services,
a lot of Web 2.0, telco,

00:39:41.130 --> 00:39:45.160
federal government, aerospace,
and such.

00:39:45.160 --> 00:39:47.310
If you don't know what Hadoop
is-- probably most of you do,

00:39:47.310 --> 00:39:48.260
it's pretty popular--

00:39:48.260 --> 00:39:50.750
but it's a big data analytics
platform.

00:39:50.750 --> 00:39:55.370
So it's a platform for being
able to run analytics at a

00:39:55.370 --> 00:40:00.180
very large scale, petabytes or
even 100 petabytes of data.

00:40:00.180 --> 00:40:03.130
And that data may be structured
or semi-structured.

00:40:03.130 --> 00:40:05.540
It runs generally on commodity
hardware in

00:40:05.540 --> 00:40:07.520
large clusters of computers.

00:40:07.520 --> 00:40:10.450
And since we're at a Google
conference, we want to make

00:40:10.450 --> 00:40:14.160
sure that we also identify that
really the whole Hadoop

00:40:14.160 --> 00:40:18.160
project was inspired by a paper
about MapReduce that was

00:40:18.160 --> 00:40:20.630
published by a couple of Google
scientists back in

00:40:20.630 --> 00:40:23.590
2004, Jeffrey Dean and Sanjay.

00:40:23.590 --> 00:40:28.180
And we're really happy to have
MapR now running as part of

00:40:28.180 --> 00:40:32.340
the Google Compute Engine.

00:40:32.340 --> 00:40:38.650
So a few days ago, Craig said
could you put together a demo

00:40:38.650 --> 00:40:41.290
that would show some of
the capabilities of

00:40:41.290 --> 00:40:42.280
Google Compute Engine?

00:40:42.280 --> 00:40:44.960
Also, it'll allow you to show
your product a bit, too.

00:40:44.960 --> 00:40:46.520
So Srivas and I talked.

00:40:46.520 --> 00:40:48.620
And he said, well, why don't
we just run a big sort?

00:40:48.620 --> 00:40:52.070
And TeraSort is a standard
benchmark that's run to

00:40:52.070 --> 00:40:54.510
measure performance
of applications.

00:40:54.510 --> 00:40:57.980
And it's a very popular
benchmark for demonstrating

00:40:57.980 --> 00:41:00.940
the performance of Hadoop
distributions.

00:41:00.940 --> 00:41:06.240
So we stitched together quickly
a 1,250-node cluster

00:41:06.240 --> 00:41:07.570
and ran a TeraSort.

00:41:07.570 --> 00:41:11.170
And I think we'll do a demo of
that right now, and Srivas can

00:41:11.170 --> 00:41:12.580
walk you through how
that worked.

00:41:15.190 --> 00:41:20.120
MC SRIVAS: So what we have here
is each of these green

00:41:20.120 --> 00:41:23.900
squares represents a node in
the Google Compute cluster.

00:41:23.900 --> 00:41:28.490
So we have a full cluster of
about 1,250 nodes with five

00:41:28.490 --> 00:41:30.070
control nodes.

00:41:30.070 --> 00:41:34.140
And this is the heat map that
we have, which lets you look

00:41:34.140 --> 00:41:38.370
at the cluster from one console
and put different

00:41:38.370 --> 00:41:39.620
views on it.

00:41:39.620 --> 00:41:42.090
And one of the views we're
putting on out here will be,

00:41:42.090 --> 00:41:48.850
how does the CPU load on the
system when we run a TeraSort?

00:41:48.850 --> 00:41:53.440
And, of course, it turns from
green to red and back again.

00:41:53.440 --> 00:41:56.670
On the other side is the actual
TeraSort benchmark.

00:41:56.670 --> 00:42:00.980
It's a command line that shows
the elapsed time as it runs.

00:42:00.980 --> 00:42:03.630
So what's very impressive
about this was-- let

00:42:03.630 --> 00:42:06.420
me start this up.

00:42:06.420 --> 00:42:09.140
So here we are launching
a TeraSort.

00:42:09.140 --> 00:42:12.490
And as you can see, it fans
out the work to all

00:42:12.490 --> 00:42:14.380
the nodes very fast.

00:42:14.380 --> 00:42:16.590
The Google Compute network
was incredibly efficient.

00:42:16.590 --> 00:42:19.680
We could just go and load up the
clusters almost instantly.

00:42:19.680 --> 00:42:22.210
A TeraSort runs within
a minute.

00:42:22.210 --> 00:42:25.290
And so you have to go and load
up about several thousands of

00:42:25.290 --> 00:42:29.820
computers almost instantly with
data and then have them

00:42:29.820 --> 00:42:33.040
all do a criss-cross section
of the data going across.

00:42:33.040 --> 00:42:35.530
And then you can see
how there's no

00:42:35.530 --> 00:42:36.370
nodes that are green.

00:42:36.370 --> 00:42:37.460
Every node is lit up well.

00:42:37.460 --> 00:42:40.440
And what it shows is the
cross-cluster bandwidth of

00:42:40.440 --> 00:42:43.600
thousands of machines talking
to each other in a complete

00:42:43.600 --> 00:42:48.000
crossbar working really well.

00:42:48.000 --> 00:42:52.320
So this was kind of an
interesting benchmark because

00:42:52.320 --> 00:42:55.040
if you had told me this three
months ago, hey, do this

00:42:55.040 --> 00:42:59.040
benchmark on a cloud, I would
have said ha, I mean, you can

00:42:59.040 --> 00:43:00.420
never do this.

00:43:00.420 --> 00:43:05.380
And when we were invited to work
on Google Compute Engine,

00:43:05.380 --> 00:43:08.360
we were just blown away by its
performance, its scale, how

00:43:08.360 --> 00:43:10.240
easy it was to deploy.

00:43:10.240 --> 00:43:14.240
And we literally thought of this
last week, doing this.

00:43:14.240 --> 00:43:17.510
And to pull this off in a week,
we could not have done

00:43:17.510 --> 00:43:19.980
without the ease, the
simplicity, and the

00:43:19.980 --> 00:43:23.420
reliability, and the consistent
performance of

00:43:23.420 --> 00:43:24.270
Google Compute.

00:43:24.270 --> 00:43:25.520
It is just incredible.

00:43:27.890 --> 00:43:31.010
So it's still finishing.

00:43:31.010 --> 00:43:32.420
Usually the problem is the last

00:43:32.420 --> 00:43:34.060
stragglers take a long time.

00:43:39.290 --> 00:43:44.010
So this took about a minute, I
think 80 seconds, a minute and

00:43:44.010 --> 00:43:45.780
20 seconds, and it's
probably--

00:43:45.780 --> 00:43:48.130
I'll hand this off to John
to talk about what's

00:43:48.130 --> 00:43:49.380
the impact of this.

00:44:00.860 --> 00:44:04.950
JOHN SCHROEDER: OK, so if you
look at running TeraSort, the

00:44:04.950 --> 00:44:09.730
fastest TeraSort I'd seen
recorded on physical hardware

00:44:09.730 --> 00:44:12.290
is described in the middle
column there.

00:44:12.290 --> 00:44:16.850
And it was deployed at 1,460
physical servers running on

00:44:16.850 --> 00:44:22.520
bare metal Linux with a high
number of disks, 5,800 disks,

00:44:22.520 --> 00:44:24.710
and almost 12,000 cores.

00:44:24.710 --> 00:44:28.390
And that's a record that took
a long time for a company to

00:44:28.390 --> 00:44:30.790
put together in their own
internal data center to run.

00:44:30.790 --> 00:44:34.410
Here in a really short period
of time in a virtual

00:44:34.410 --> 00:44:39.030
environment running on fewer
servers, 1,256 servers, one

00:44:39.030 --> 00:44:43.210
disk per server and about 5,000
cores, we're right in

00:44:43.210 --> 00:44:44.170
the neighborhood with that.

00:44:44.170 --> 00:44:48.230
So I'd love to come back here
next year and maybe raise the

00:44:48.230 --> 00:44:53.850
bar and do a petabyte benchmark
instead, but a

00:44:53.850 --> 00:44:55.060
really great performance.

00:44:55.060 --> 00:44:58.790
And on on-premise Hadoop
implementations, they rarely

00:44:58.790 --> 00:45:01.020
run in virtualized environments
because of the

00:45:01.020 --> 00:45:01.990
performance overhead.

00:45:01.990 --> 00:45:05.860
So it's also another indication
of the performance

00:45:05.860 --> 00:45:09.082
of Google Compute Engine.

00:45:09.082 --> 00:45:16.252
[APPLAUSE]

00:45:16.252 --> 00:45:18.210
JOHN SCHROEDER: Now, if you look
at putting this together,

00:45:18.210 --> 00:45:22.680
those two benchmarks, if you
tried to assemble 1,460

00:45:22.680 --> 00:45:25.000
servers in your data center,
it'd take you months.

00:45:25.000 --> 00:45:28.290
I mean, I'd be negotiating with
my server vendor probably

00:45:28.290 --> 00:45:29.250
for months.

00:45:29.250 --> 00:45:33.280
And then I'd have to rack and
stack 50 to 70 racks of

00:45:33.280 --> 00:45:36.530
servers, switching our
infrastructure, get the

00:45:36.530 --> 00:45:38.920
electrical brought into the
data center to handle that

00:45:38.920 --> 00:45:44.550
server load, probably 50 to 75
tons of air conditioning.

00:45:44.550 --> 00:45:45.940
So it's a massive project.

00:45:45.940 --> 00:45:47.580
It'd take just months to do.

00:45:47.580 --> 00:45:51.150
And with the Google Compute
Engine, we're basically up and

00:45:51.150 --> 00:45:53.570
running on over 1,200 instances

00:45:53.570 --> 00:45:54.530
in a matter of minutes.

00:45:54.530 --> 00:45:58.070
So the time to deploy
is very, very fast.

00:45:58.070 --> 00:46:00.650
And then, if you noticed, we're
not paying for that

00:46:00.650 --> 00:46:01.680
anymore now either.

00:46:01.680 --> 00:46:03.770
Once we're done running the
TeraSort, we give those

00:46:03.770 --> 00:46:08.180
resources back to Google,
where with the physical

00:46:08.180 --> 00:46:09.450
servers, they'd be mine.

00:46:09.450 --> 00:46:12.400
And three to five years from
now, I'd have to swap all

00:46:12.400 --> 00:46:14.490
those servers out for
newer models.

00:46:14.490 --> 00:46:16.860
And we leave all that
to Google as the

00:46:16.860 --> 00:46:19.720
cloud provider as well.

00:46:19.720 --> 00:46:25.290
And from a cost perspective,
just to

00:46:25.290 --> 00:46:26.695
take a really, really--

00:46:26.695 --> 00:46:35.730
[LAUGHTER AND APPLAUSE]

00:46:35.730 --> 00:46:37.500
JOHN SCHROEDER: Just a very
conservative run.

00:46:37.500 --> 00:46:44.010
If I just allocate 4,000 a
server, which is probably 50%

00:46:44.010 --> 00:46:46.600
lower than what most Hadoop
servers go for.

00:46:46.600 --> 00:46:49.970
And this doesn't count racks,
PDUs, switching

00:46:49.970 --> 00:46:55.720
infrastructure, ongoing OPX,
yeah, $6 million, a minute 20

00:46:55.720 --> 00:46:56.870
of instance time?

00:46:56.870 --> 00:46:57.700
$16.

00:46:57.700 --> 00:47:01.760
So a tremendous cost
advantage.

00:47:01.760 --> 00:47:08.190
Finally we are part of
the private beta.

00:47:08.190 --> 00:47:11.740
If you'd like to try running
MapR Hadoop on Google Compute

00:47:11.740 --> 00:47:14.300
Engine, really simple
URL to remember--

00:47:14.300 --> 00:47:15.980
Mapr.com/Google.

00:47:15.980 --> 00:47:17.790
So thanks much for your time.

00:47:17.790 --> 00:47:18.270
Thank, Craig.

00:47:18.270 --> 00:47:19.710
[APPLAUSE]

00:47:19.710 --> 00:47:20.960
CRAIG MCLUCKIE: Thanks, John.

00:47:24.990 --> 00:47:26.920
Thank you.

00:47:26.920 --> 00:47:27.620
That's a great demo.

00:47:27.620 --> 00:47:30.180
And I'm definitely looking
forward to having you come

00:47:30.180 --> 00:47:33.590
back and do some more
interesting stuff with our

00:47:33.590 --> 00:47:34.415
data centers.

00:47:34.415 --> 00:47:36.710
And this is really early
days for us.

00:47:36.710 --> 00:47:38.290
This is the first offering
of the service.

00:47:38.290 --> 00:47:39.790
It's just going to keep
getting better.

00:47:39.790 --> 00:47:41.850
We're going to bring more
and more of the awesome

00:47:41.850 --> 00:47:46.050
infrastructure technologies of
Google to you so that you can

00:47:46.050 --> 00:47:48.900
benefit from them and benefit
from the efficiencies.

00:47:48.900 --> 00:47:52.180
So John already talked about
this a little bit.

00:47:52.180 --> 00:47:54.430
A big part of our commitment
with the service is to

00:47:54.430 --> 00:47:57.400
transfer the efficiencies
we benefit to you.

00:47:57.400 --> 00:47:59.860
And then we believe this is
reflected in our price sheet.

00:47:59.860 --> 00:48:01.160
If you take a look at
this price sheet,

00:48:01.160 --> 00:48:02.150
it may not be obvious.

00:48:02.150 --> 00:48:05.130
But when you look at this
compared to what other cloud

00:48:05.130 --> 00:48:08.245
providers are offering, you get
up to 50% more compute for

00:48:08.245 --> 00:48:08.720
your money.

00:48:08.720 --> 00:48:11.320
And we really invite you to get
on board, try this out,

00:48:11.320 --> 00:48:13.140
and take a look at it.

00:48:13.140 --> 00:48:16.210
That standard, that one, is
not a small instance.

00:48:16.210 --> 00:48:18.090
There's a whole bunch of compute
power in that thing.

00:48:18.090 --> 00:48:19.560
So we definitely want you
to take a look at it.

00:48:19.560 --> 00:48:23.470
Take it for a spin and see if
you experience the same kind

00:48:23.470 --> 00:48:26.810
of benefits of that we've seen
when running our processes on

00:48:26.810 --> 00:48:29.000
these things.

00:48:29.000 --> 00:48:32.610
And with that, I do thank
you for your time.

00:48:32.610 --> 00:48:35.720
And I invite you to join our
limited preview program.

00:48:35.720 --> 00:48:37.510
We're available now.

00:48:37.510 --> 00:48:39.950
And I expect there'll be a fair
amount of demand because

00:48:39.950 --> 00:48:42.500
access to the program comes with
a pretty generous quota

00:48:42.500 --> 00:48:44.200
of free compute.

00:48:44.200 --> 00:48:48.550
And so while we have very, very
big data centers, we do

00:48:48.550 --> 00:48:51.500
have finite spots in our compute
program, so we beg

00:48:51.500 --> 00:48:52.860
your patience.

00:48:52.860 --> 00:48:55.800
And do apply, and we'll try to
service everyone who wants to

00:48:55.800 --> 00:48:58.800
participate in this program.

00:48:58.800 --> 00:49:01.340
For folks that reach the end and
really like the service,

00:49:01.340 --> 00:49:03.160
it will be available
commercially.

00:49:03.160 --> 00:49:04.910
And we will be offering
an SLA.

00:49:04.910 --> 00:49:06.780
And we will be offering
support to

00:49:06.780 --> 00:49:07.760
our commercial customers.

00:49:07.760 --> 00:49:10.470
So you can absolutely contact
our sales team, and they'd be

00:49:10.470 --> 00:49:13.770
delighted to speak to you about
the service, tell you a

00:49:13.770 --> 00:49:14.990
little bit more about it,
and tell you about

00:49:14.990 --> 00:49:16.490
how to get this program.

00:49:16.490 --> 00:49:18.695
And so go ahead and do
apply for access.

00:49:21.580 --> 00:49:24.950
And we invite you to come
to some other sessions.

00:49:24.950 --> 00:49:26.800
If you want to learn more about
Google Compute and you

00:49:26.800 --> 00:49:29.860
want to get into some of the
details, Joe Beda, who's the

00:49:29.860 --> 00:49:31.920
technical lead, one of the
original architects on the

00:49:31.920 --> 00:49:35.150
project, will be delivering a
session called 313 at 5:30

00:49:35.150 --> 00:49:36.250
this afternoon.

00:49:36.250 --> 00:49:38.730
And then tomorrow, we'll have
another session, 308, which

00:49:38.730 --> 00:49:41.330
will really clarify the
relationship between Google

00:49:41.330 --> 00:49:44.950
Compute Engine and Google App
Engine and help you understand

00:49:44.950 --> 00:49:47.660
how to build very powerful
systems that bring together

00:49:47.660 --> 00:49:49.690
the best of
Platform-as-a-Service and

00:49:49.690 --> 00:49:52.680
Infrastructure-as-a-Service in
the Google Cloud platform.

00:49:52.680 --> 00:49:55.430
And with that, I'd like to
invite my colleagues on stage.

00:49:55.430 --> 00:49:58.660
We'll do a little Q&amp;A. I think
we have about 10 minutes.

00:49:58.660 --> 00:50:01.970
So if you have questions,
please let us know.

00:50:01.970 --> 00:50:12.770
[APPLAUSE]

00:50:12.770 --> 00:50:15.290
AUDIENCE: It's obvious that it
does scale very quickly.

00:50:15.290 --> 00:50:16.150
CRAIG MCLUCKIE: Yes.

00:50:16.150 --> 00:50:19.260
AUDIENCE: But what about certain
applications that need

00:50:19.260 --> 00:50:24.500
32 cores on one machine?

00:50:24.500 --> 00:50:26.170
CRAIG MCLUCKIE: So yes,
it does scale quickly.

00:50:26.170 --> 00:50:29.840
Right now, we offer instance
sizes up to eight cores.

00:50:29.840 --> 00:50:32.810
We're absolutely looking at ways
to bring even more of our

00:50:32.810 --> 00:50:34.420
infrastructure capabilities
to market.

00:50:34.420 --> 00:50:35.540
But that's just where
we started.

00:50:35.540 --> 00:50:38.510
So right now, it's really about
lots of work that can be

00:50:38.510 --> 00:50:40.440
paralyzed, and we will
provide vertical

00:50:40.440 --> 00:50:42.050
scaling in the future.

00:50:42.050 --> 00:50:44.240
AUDIENCE: Thank you.

00:50:44.240 --> 00:50:47.940
AUDIENCE: So when MapR showed
their cost calculation of $16,

00:50:47.940 --> 00:50:51.130
they actually broke
it down by second.

00:50:51.130 --> 00:50:51.400
CRAIG MCLUCKIE: Yes.

00:50:51.400 --> 00:50:53.920
AUDIENCE: So are you going
to be billing at seconds,

00:50:53.920 --> 00:50:55.260
minutes, or to the hour?

00:50:55.260 --> 00:50:56.370
CRAIG MCLUCKIE: It's
a great point.

00:50:56.370 --> 00:50:57.450
At this point, it's
by the hour.

00:50:57.450 --> 00:50:59.480
So what they really should have
said is you could have

00:50:59.480 --> 00:51:03.240
done this 60 times in
a row for this.

00:51:03.240 --> 00:51:05.430
Right now, it is on demand
by the hour.

00:51:05.430 --> 00:51:06.400
But that's definitely something

00:51:06.400 --> 00:51:07.290
we're thinking about.

00:51:07.290 --> 00:51:09.600
AUDIENCE: OK, thanks.

00:51:09.600 --> 00:51:12.450
AUDIENCE: My question is about
how it plays well with Google

00:51:12.450 --> 00:51:15.520
App Engine, specifically on the
areas of load balancer.

00:51:15.520 --> 00:51:18.710
So once I've integrated it with
Google App Engine, will

00:51:18.710 --> 00:51:21.380
it work with the same
authentication?

00:51:21.380 --> 00:51:26.610
The second being how it
works with memcache.

00:51:26.610 --> 00:51:27.350
CRAIG MCLUCKIE: OK.

00:51:27.350 --> 00:51:30.770
So obviously, we have two
technologies, Google App

00:51:30.770 --> 00:51:31.990
Engine and Google
Compute Engine.

00:51:31.990 --> 00:51:33.100
We're going to be doing
a session tomorrow.

00:51:33.100 --> 00:51:34.630
We'll get into much more
of the details.

00:51:34.630 --> 00:51:37.280
But I'll provide you a very
brief sense of where we are.

00:51:37.280 --> 00:51:39.670
Coming out of the gate, Google
Compute Engine is about being

00:51:39.670 --> 00:51:41.600
able to deploy a lot of
service to solve some

00:51:41.600 --> 00:51:43.270
computationally hard problems.

00:51:43.270 --> 00:51:46.740
App Engine is our web-facing,
high-productivity,

00:51:46.740 --> 00:51:50.250
high-efficiency environment for
application development.

00:51:50.250 --> 00:51:51.920
The two together actually
work pretty well.

00:51:51.920 --> 00:51:55.490
We have the ability to flow
credentials using OAuth so

00:51:55.490 --> 00:51:57.050
that you can use service
accounts to authenticate

00:51:57.050 --> 00:51:58.010
across them.

00:51:58.010 --> 00:52:00.150
And App Engine becomes a very
natural orchestrator and

00:52:00.150 --> 00:52:03.130
management framework for these
Compute containers.

00:52:03.130 --> 00:52:06.250
And the Compute offers the
ability to open App Engine up

00:52:06.250 --> 00:52:08.530
and run general workloads that
can connect as part of your

00:52:08.530 --> 00:52:09.830
App Engine application.

00:52:09.830 --> 00:52:12.790
Now over time, we will work
to create even richer

00:52:12.790 --> 00:52:14.710
connectivity between
the two services.

00:52:14.710 --> 00:52:16.210
For now, it works
very naturally.

00:52:16.210 --> 00:52:18.470
And a great example
of that is our UI.

00:52:18.470 --> 00:52:20.280
That was an App Engine
application.

00:52:20.280 --> 00:52:21.720
That was an App Engine
application that was just

00:52:21.720 --> 00:52:23.300
spinning up these virtual
machines.

00:52:23.300 --> 00:52:25.420
So App Engine's a very natural
way to do things like order

00:52:25.420 --> 00:52:28.870
scaling and to deal with some
of those constituent parts.

00:52:28.870 --> 00:52:30.462
And it'll just get
better with time.

00:52:30.462 --> 00:52:31.410
Hope that answered
your question.

00:52:31.410 --> 00:52:33.850
Thank you.

00:52:33.850 --> 00:52:34.300
AUDIENCE: Hi.

00:52:34.300 --> 00:52:36.670
Are the data centers located
internationally?

00:52:36.670 --> 00:52:41.390
And if so, can I specify
a fail oversight?

00:52:41.390 --> 00:52:43.900
CRAIG MCLUCKIE: So at this
point, we only have domestic

00:52:43.900 --> 00:52:45.690
data centers, US data centers.

00:52:45.690 --> 00:52:49.500
We are working on creating a
global data center footprint.

00:52:49.500 --> 00:52:51.965
AUDIENCE: Even within the US,
can I specify a fail oversight

00:52:51.965 --> 00:52:53.140
in East Coast or West Coast?

00:52:53.140 --> 00:52:54.310
CRAIG MCLUCKIE: Yeah,
you can pick.

00:52:54.310 --> 00:52:57.460
We actually publish what
region they're in.

00:52:57.460 --> 00:52:59.070
And so you can pick which
specific data center you want

00:52:59.070 --> 00:53:00.510
to be deployed in, so
that you can be

00:53:00.510 --> 00:53:01.890
close to your customers.

00:53:01.890 --> 00:53:04.630
We're launching initially with
three data center locations

00:53:04.630 --> 00:53:06.710
that are centered on and East
Coast, which works well for

00:53:06.710 --> 00:53:07.410
this class of workload.

00:53:07.410 --> 00:53:10.290
And we're looking at bringing on
more as the service matures

00:53:10.290 --> 00:53:12.540
and as we bring more
capabilities to market.

00:53:12.540 --> 00:53:12.860
AUDIENCE: OK.

00:53:12.860 --> 00:53:14.060
Thank you.

00:53:14.060 --> 00:53:15.640
AUDIENCE: Hi.

00:53:15.640 --> 00:53:18.970
I saw in the flow diagram that
there were connections to the

00:53:18.970 --> 00:53:20.500
outside world from the VMs.

00:53:20.500 --> 00:53:23.300
But I didn't see anywhere in
the API console when he

00:53:23.300 --> 00:53:26.730
flipped through that showed like
IP address allocation or

00:53:26.730 --> 00:53:27.580
anything like that.

00:53:27.580 --> 00:53:28.495
Is there--

00:53:28.495 --> 00:53:28.850
CRAIG MCLUCKIE: Oh yeah.

00:53:28.850 --> 00:53:31.970
So go ahead, Joe.

00:53:31.970 --> 00:53:33.355
JOE BEDA: I'm going to be
talking about that a lot more

00:53:33.355 --> 00:53:35.240
in my session at
5:15, not 5:30.

00:53:35.240 --> 00:53:36.192
CRAIG MCLUCKIE: Oh,
was it 5:15?

00:53:36.192 --> 00:53:36.670
Sorry.

00:53:36.670 --> 00:53:37.860
I apologize.

00:53:37.860 --> 00:53:41.750
JOE BEDA: But yeah we do provide
public IP addresses,

00:53:41.750 --> 00:53:45.120
IPv4 addresses that are mapped
one-to-one to instances.

00:53:45.120 --> 00:53:49.090
And you can either have those
be statically allocated and

00:53:49.090 --> 00:53:52.560
attached to your project,
or you can have those be

00:53:52.560 --> 00:53:53.940
ephemeral, and they
come and go with

00:53:53.940 --> 00:53:55.290
that particular instance.

00:53:55.290 --> 00:53:56.650
AUDIENCE: How do we sign up?

00:53:56.650 --> 00:53:57.530
[LAUGHTER]

00:53:57.530 --> 00:53:59.180
CRAIG MCLUCKIE: Go to
cloud.google.com, press the

00:53:59.180 --> 00:54:01.740
button, and do it quick.

00:54:01.740 --> 00:54:03.080
JOE BEDA: I just want to drive
home the point that these

00:54:03.080 --> 00:54:06.160
things, these IP addresses,
are actually

00:54:06.160 --> 00:54:07.270
global across our service.

00:54:07.270 --> 00:54:09.800
So they can float from region to
region, which we think is,

00:54:09.800 --> 00:54:13.050
especially going towards the
disaster recovery or failover,

00:54:13.050 --> 00:54:15.960
it's an important feature
for that.

00:54:15.960 --> 00:54:18.980
AUDIENCE: By what time do you
expect that a small business

00:54:18.980 --> 00:54:24.910
can rent out, like let's say
around 10 servers of--

00:54:24.910 --> 00:54:26.130
medium-size servers?

00:54:26.130 --> 00:54:27.230
CRAIG MCLUCKIE: Smaller
locations.

00:54:27.230 --> 00:54:29.070
So we're in limited
preview right now.

00:54:29.070 --> 00:54:32.100
Folks that have workloads that
we think will really benefit

00:54:32.100 --> 00:54:33.740
from the scale and efficiencies
of the data

00:54:33.740 --> 00:54:35.930
centers we will take on board
and we'll take on as

00:54:35.930 --> 00:54:37.310
commercial customers.

00:54:37.310 --> 00:54:39.510
Based on our experiences with
the limited preview program,

00:54:39.510 --> 00:54:41.760
as we grow this up, we will
decide when to make the

00:54:41.760 --> 00:54:43.030
product generally available.

00:54:43.030 --> 00:54:45.100
So our aspiration is to make it
available soon, but we want

00:54:45.100 --> 00:54:46.395
to create a great experience
for all our customers.

00:54:46.395 --> 00:54:48.260
And we think that the best
experience will be with these

00:54:48.260 --> 00:54:49.580
large-scale workloads
right now.

00:54:49.580 --> 00:54:52.510
AUDIENCE: But is it probable
that by the next Google I/O

00:54:52.510 --> 00:54:53.490
you'll be there?

00:54:53.490 --> 00:54:54.531
CRAIG MCLUCKIE: I'm not going
to make any statements about

00:54:54.531 --> 00:54:55.686
our future, so I'm sorry.

00:54:55.686 --> 00:54:57.072
[LAUGHTER]

00:54:57.072 --> 00:54:57.540
AUDIENCE: Good try.

00:54:57.540 --> 00:55:00.170
Can you touch on how you would
upload a lot of data, what

00:55:00.170 --> 00:55:04.010
tools are available, if it's
GSUtil based or FTP?

00:55:04.010 --> 00:55:05.560
Or if you have a lot of data
that you want to move up to

00:55:05.560 --> 00:55:08.000
disk, how that whole
process works?

00:55:08.000 --> 00:55:08.200
CRAIG MCLUCKIE: Yeah.

00:55:08.200 --> 00:55:14.180
So as you've heard, all of our
services interact on the

00:55:14.180 --> 00:55:15.760
Google global network.

00:55:15.760 --> 00:55:17.050
So we have pretty high-capacity

00:55:17.050 --> 00:55:18.700
pipes to Google Storage.

00:55:18.700 --> 00:55:20.690
And from in the virtual machine,
you're actually able

00:55:20.690 --> 00:55:23.380
to get OAuth credentials
seamlessly.

00:55:23.380 --> 00:55:26.340
Our version of GSUtil, for
instance, seamlessly will just

00:55:26.340 --> 00:55:27.940
reach into our metadata server,
grab some OAuth

00:55:27.940 --> 00:55:30.460
credentials, and then enable
you to grab content from

00:55:30.460 --> 00:55:32.120
Google storage very quickly.

00:55:32.120 --> 00:55:34.310
So it's a very easy way
to deal with this.

00:55:34.310 --> 00:55:36.950
It also means you don't have to
deal with pushing keys into

00:55:36.950 --> 00:55:38.690
virtual machine images
and manage them.

00:55:38.690 --> 00:55:40.710
So that we think is a
great experience.

00:55:40.710 --> 00:55:42.920
And then again, it's on
the Google network.

00:55:42.920 --> 00:55:44.360
We have some pretty interesting
network

00:55:44.360 --> 00:55:44.600
technology.

00:55:44.600 --> 00:55:44.840
AUDIENCE: Right.

00:55:44.840 --> 00:55:47.610
But getting data before it's
on the Google network, so--

00:55:47.610 --> 00:55:49.320
CRAIG MCLUCKIE: Yeah, so if
you can get to the Google

00:55:49.320 --> 00:55:50.570
network, awesome
things happen.

00:55:54.530 --> 00:55:57.370
AUDIENCE: So for many
high-performance computing

00:55:57.370 --> 00:56:01.030
jobs that utilize a
heterogeneous compute

00:56:01.030 --> 00:56:04.590
environment that includes GPUs
as well as a traditional CPUs,

00:56:04.590 --> 00:56:07.000
does Google have
any plans for a

00:56:07.000 --> 00:56:09.540
heterogeneous compute product?

00:56:09.540 --> 00:56:10.890
CRAIG MCLUCKIE: I mean,
obviously, there's a lot of

00:56:10.890 --> 00:56:13.670
workloads that benefit from
GPU acceleration.

00:56:13.670 --> 00:56:15.090
We don't yet have an offering.

00:56:15.090 --> 00:56:18.150
And I can't really talk about
our GPU futures at this point.

00:56:18.150 --> 00:56:20.270
But we do recognize the value
proposition of that.

00:56:20.270 --> 00:56:20.650
AUDIENCE: Great.

00:56:20.650 --> 00:56:21.280
Thanks.

00:56:21.280 --> 00:56:21.800
CRAIG MCLUCKIE: Thank you.

00:56:21.800 --> 00:56:24.040
AUDIENCE: I was going to ask
a GPU question as well.

00:56:24.040 --> 00:56:25.140
CRAIG MCLUCKIE: OK, so
pick another one.

00:56:25.140 --> 00:56:25.660
AUDIENCE: How many--

00:56:25.660 --> 00:56:29.470
what's the maximum number of
cores in the largest instance?

00:56:29.470 --> 00:56:31.060
CRAIG MCLUCKIE: The maximum
number of cores in the largest

00:56:31.060 --> 00:56:33.030
instance is eight.

00:56:33.030 --> 00:56:34.510
And those are pretty
beefy cores.

00:56:34.510 --> 00:56:38.590
So you actually get quite a lot
of compute power for that.

00:56:38.590 --> 00:56:40.340
We'll look at vertical
scalability and providing

00:56:40.340 --> 00:56:41.440
bigger options in time.

00:56:41.440 --> 00:56:45.140
But we figure that's a really
good place to start.

00:56:45.140 --> 00:56:48.080
AUDIENCE: Sometimes with
continuous delivery, we need

00:56:48.080 --> 00:56:51.380
to spin up rapidly a large
number of servers all at once.

00:56:51.380 --> 00:56:53.930
Do you guys have any
kind of limits or

00:56:53.930 --> 00:56:58.680
delays in large requests?

00:56:58.680 --> 00:57:00.400
CRAIG MCLUCKIE: What do
you believe is large?

00:57:00.400 --> 00:57:01.224
[LAUGHTER]

00:57:01.224 --> 00:57:04.940
AUDIENCE: Um, say, 50, 100.

00:57:04.940 --> 00:57:05.830
CRAIG MCLUCKIE: Yeah,
no, that's not--

00:57:05.830 --> 00:57:10.100
I mean, that is a lot of
servers, but it's not that

00:57:10.100 --> 00:57:11.120
many servers.

00:57:11.120 --> 00:57:13.980
AUDIENCE: What is your limits
around some kind of delays?

00:57:13.980 --> 00:57:15.600
CRAIG MCLUCKIE: Well, we tend
do think in the tens of

00:57:15.600 --> 00:57:16.870
thousands at this point.

00:57:19.390 --> 00:57:21.620
MALE SPEAKER: The API itself is
currently limited to about

00:57:21.620 --> 00:57:24.160
20 QPS in our initial
offering.

00:57:24.160 --> 00:57:25.430
JOE BEDA: Per project.

00:57:25.430 --> 00:57:26.550
MALE SPEAKER: Per project.

00:57:26.550 --> 00:57:27.050
Not total.

00:57:27.050 --> 00:57:27.865
JOE BEDA: Not total.

00:57:27.865 --> 00:57:29.110
[LAUGHTER]

00:57:29.110 --> 00:57:31.010
MALE SPEAKER: No.

00:57:31.010 --> 00:57:32.700
And then we'll be
spinning that up

00:57:32.700 --> 00:57:34.870
as the service matures.

00:57:34.870 --> 00:57:37.810
We're also going to look at
improving the APIs to do more

00:57:37.810 --> 00:57:39.680
operations in batches.

00:57:39.680 --> 00:57:42.390
So you could make a single
request for N

00:57:42.390 --> 00:57:45.040
instances or N disks.

00:57:45.040 --> 00:57:47.440
JOE BEDA: So it's good,
and it'll get better.

00:57:47.440 --> 00:57:50.930
AUDIENCE: So for application
service, we may have the

00:57:50.930 --> 00:57:52.350
internal load balancer.

00:57:52.350 --> 00:57:53.920
Do you provide that?

00:57:53.920 --> 00:57:55.650
So different--

00:57:55.650 --> 00:57:58.630
CRAIG MCLUCKIE: So for
applications, you're looking

00:57:58.630 --> 00:58:01.070
at a sort of elastic
load-balancing capability?

00:58:01.070 --> 00:58:03.860
AUDIENCE: Yeah, load balancing
for internal so internal one

00:58:03.860 --> 00:58:07.400
cluster can talk to another
cluster but is on the internal

00:58:07.400 --> 00:58:08.800
access mode.

00:58:08.800 --> 00:58:10.640
JOE BEDA: That's not something
that we're offering right out

00:58:10.640 --> 00:58:11.080
of the gate.

00:58:11.080 --> 00:58:12.810
But it's definitely an
architectural pattern that

00:58:12.810 --> 00:58:14.020
we've seen.

00:58:14.020 --> 00:58:17.280
And it mirrors a lot of what
we do internally at Google

00:58:17.280 --> 00:58:19.010
also where you'll have different
tiers of your

00:58:19.010 --> 00:58:22.010
application using load-balancing
technologies.

00:58:22.010 --> 00:58:24.630
And we're going to keep looking
to see how we can

00:58:24.630 --> 00:58:28.590
apply Google's experience, not
just at the hardware level,

00:58:28.590 --> 00:58:30.740
but also at the software and
distributed system levels to

00:58:30.740 --> 00:58:32.160
start solving problems
like that.

00:58:32.160 --> 00:58:33.630
AUDIENCE: OK, thanks.

00:58:33.630 --> 00:58:35.180
JOE BEDA: Thank you.

00:58:35.180 --> 00:58:36.660
AUDIENCE: You guys
have mentioned a

00:58:36.660 --> 00:58:38.600
lot about your network.

00:58:38.600 --> 00:58:43.150
What kind of between-instance
latency do you have compared

00:58:43.150 --> 00:58:45.460
to, say, EC2?

00:58:45.460 --> 00:58:46.430
CRAIG MCLUCKIE: So it's
a great question.

00:58:46.430 --> 00:58:48.660
We are very proud of our network
capabilities, and it

00:58:48.660 --> 00:58:50.700
will continue to get even
more awesome with time.

00:58:50.700 --> 00:58:53.000
We don't like to publish

00:58:53.000 --> 00:58:54.950
comparative performance numbers.

00:58:54.950 --> 00:58:57.410
We invite you to apply for
the program, try it out.

00:58:57.410 --> 00:58:58.640
We think you'll like it.

00:58:58.640 --> 00:59:00.320
We think you'll like it
particularly when you try to

00:59:00.320 --> 00:59:03.430
build large clusters and you
want to see very strong,

00:59:03.430 --> 00:59:04.810
consistent cross-sectional
bandwidth

00:59:04.810 --> 00:59:06.060
across large clusters.

00:59:08.240 --> 00:59:11.800
AUDIENCE: Will the App Engine
team ever be developing on top

00:59:11.800 --> 00:59:13.280
of the Compute Engine?

00:59:13.280 --> 00:59:16.380
So provisioning for App Engine
using the Compute Engine.

00:59:16.380 --> 00:59:17.970
CRAIG MCLUCKIE: So the question
is App Engine, will

00:59:17.970 --> 00:59:20.950
they be building on top
of Compute Engine?

00:59:20.950 --> 00:59:23.240
So at this time, the two
technologies work well

00:59:23.240 --> 00:59:26.940
together, and we've ensured a
good degree of integration.

00:59:26.940 --> 00:59:28.640
But they are discrete
products.

00:59:28.640 --> 00:59:31.450
I mean, Google Compute Engine is
pure infrastructure, and it

00:59:31.450 --> 00:59:33.400
benefits tremendously
from having that

00:59:33.400 --> 00:59:34.880
Platform-as-a-Service
component.

00:59:34.880 --> 00:59:38.560
Over time, I expect you'll see
the lines become more blurred.

00:59:38.560 --> 00:59:41.060
And we're working on creating a
much more natural fusion of

00:59:41.060 --> 00:59:42.150
the technologies.

00:59:42.150 --> 00:59:44.840
For now, the best applications
are, for instance, using App

00:59:44.840 --> 00:59:48.050
Engine as a way to build and
scale and manage large-scale

00:59:48.050 --> 00:59:49.800
applications and serve as
a front end for those

00:59:49.800 --> 00:59:52.670
large-scale Compute clusters,
and then using Compute Engine

00:59:52.670 --> 00:59:56.502
to open up App Engine and run
proprietary code, for

00:59:56.502 --> 00:59:58.670
instance, like a transcoding
application, et cetera.

00:59:58.670 --> 01:00:01.220
And over time, I think
you'll find them--

01:00:01.220 --> 01:00:03.920
well, we're working on making
them much more aligned.

01:00:03.920 --> 01:00:05.170
AUDIENCE: Thank you.

01:00:08.120 --> 01:00:09.950
AUDIENCE: IPv6.

01:00:09.950 --> 01:00:13.050
What are your plans
for offering it?

01:00:13.050 --> 01:00:16.230
JOE BEDA: We are going
to do IPv6.

01:00:16.230 --> 01:00:19.370
We had to prioritize what's
important to people now, right

01:00:19.370 --> 01:00:24.420
now, as we worked to get the
product ready for Google I/O.

01:00:24.420 --> 01:00:28.660
But Google is a very big
proponent of IPv6.

01:00:28.660 --> 01:00:30.710
And I can guarantee you that
there are many people inside

01:00:30.710 --> 01:00:33.780
of Google who would love to see
us have IPv6 yesterday.

01:00:33.780 --> 01:00:36.120
So yeah, it's a priority
for us.

01:00:36.120 --> 01:00:38.250
CRAIG MCLUCKIE: Absolutely.

01:00:38.250 --> 01:00:38.730
Right.

01:00:38.730 --> 01:00:40.900
Any other questions?

01:00:40.900 --> 01:00:41.500
Wonderful.

01:00:41.500 --> 01:00:43.270
Well, thank you so much
for your time.

01:00:43.270 --> 01:00:49.480
[APPLAUSE]

01:00:49.480 --> 01:00:52.030
CRAIG MCLUCKIE: And do visit
us in the later sessions.

01:00:52.030 --> 01:00:54.460
Joe's session at 5:15.

