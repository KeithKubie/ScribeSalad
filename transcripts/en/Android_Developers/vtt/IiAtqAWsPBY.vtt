WEBVTT
Kind: captions
Language: en

00:00:05.760 --> 00:00:07.020
All right.

00:00:07.020 --> 00:00:08.857
Welcome.

00:00:08.857 --> 00:00:10.440
My name is Dan Galpin,
and we're going

00:00:10.440 --> 00:00:12.320
to be talking about
garbage today.

00:00:12.320 --> 00:00:15.470
I hope everyone is really
excited to hear about garbage.

00:00:15.470 --> 00:00:17.160
A little bit about me.

00:00:17.160 --> 00:00:21.570
I have spent the last over five
years as a developer advocate

00:00:21.570 --> 00:00:23.389
on the Android
team, mostly working

00:00:23.389 --> 00:00:25.180
with game developers,
which is why I end up

00:00:25.180 --> 00:00:27.840
dealing with so many
low level things,

00:00:27.840 --> 00:00:31.220
but also doing a couple of fun
things you might have seen.

00:00:31.220 --> 00:00:33.540
I'm really proud of the work
we've done with Udacity.

00:00:33.540 --> 00:00:37.900
I worked on both the
Android fundamentals class,

00:00:37.900 --> 00:00:43.130
introduction to Android, as well
as the advanced Android class.

00:00:43.130 --> 00:00:44.730
And I have had no sleep.

00:00:44.730 --> 00:00:47.200
Literally, I have not
slept in about two days.

00:00:47.200 --> 00:00:48.555
So this should be exciting.

00:00:51.520 --> 00:00:55.520
Yeah, and I think I'm funny.

00:00:55.520 --> 00:00:56.770
So I had a confession to make.

00:00:56.770 --> 00:00:59.400
If you looked at the
description of this talk,

00:00:59.400 --> 00:01:01.545
when Ian Ni-Lewis-- who
you notice is not here--

00:01:01.545 --> 00:01:02.920
and I started
planning this talk,

00:01:02.920 --> 00:01:05.780
we were thinking
like ocean liner big.

00:01:05.780 --> 00:01:08.550
And we wanted to cover
all sorts of things.

00:01:08.550 --> 00:01:10.770
We wanted to cover Binder,
and ART, and the OAT

00:01:10.770 --> 00:01:14.990
format, services whose
names end in Flinger.

00:01:14.990 --> 00:01:16.060
You name it.

00:01:16.060 --> 00:01:18.300
But a few weeks ago,
we realized two things.

00:01:18.300 --> 00:01:20.830
First, there was no way
we had time for all that.

00:01:20.830 --> 00:01:24.310
Even if we could write a talk
that would cover all of that,

00:01:24.310 --> 00:01:26.820
we still couldn't
deliver it in 40 minutes.

00:01:26.820 --> 00:01:29.430
Secondly, there already a
series of books and talks

00:01:29.430 --> 00:01:31.260
called Android
Internals that covered

00:01:31.260 --> 00:01:32.830
lots of what we are planning.

00:01:32.830 --> 00:01:35.559
So we decided to focus the talk.

00:01:35.559 --> 00:01:37.850
So instead, I'm going to talk
about one of the journeys

00:01:37.850 --> 00:01:41.800
that we've taken through
the internals of Android.

00:01:41.800 --> 00:01:43.920
I should also mention
that I did not write

00:01:43.920 --> 00:01:46.310
large chunks of this talk.

00:01:46.310 --> 00:01:50.530
Ian Ni-Lewis, my cohort did,
but he couldn't be here today.

00:01:50.530 --> 00:01:53.436
I am, however, responsible
for all of the slides.

00:01:55.980 --> 00:01:58.720
He wrote a script that
I'm going to read word

00:01:58.720 --> 00:02:01.910
for word, because I
will forever stand

00:02:01.910 --> 00:02:05.490
in utter aw of his
technical brilliance.

00:02:05.490 --> 00:02:07.850
And because I haven't
slept in about a week.

00:02:07.850 --> 00:02:10.340
So let's get started.

00:02:10.340 --> 00:02:13.050
The great thing about spelunking
through the bowels of Android

00:02:13.050 --> 00:02:14.920
is that pretty much
anyone can do it.

00:02:14.920 --> 00:02:16.909
It's the beauty of open source.

00:02:16.909 --> 00:02:18.950
And you might think that
since I work for Google,

00:02:18.950 --> 00:02:20.570
I have some kind of
special advantage

00:02:20.570 --> 00:02:22.490
when it comes to
understanding Android.

00:02:22.490 --> 00:02:25.770
I mean, any time I want to, I
can walk over and talk directly

00:02:25.770 --> 00:02:28.330
to one of the amazing people
that actually wrote the system.

00:02:28.330 --> 00:02:29.710
And it is pretty awesome.

00:02:29.710 --> 00:02:33.960
But not only do I try to avoid
doing that more than I have to,

00:02:33.960 --> 00:02:36.470
the knowledge is actually
pretty much spread about

00:02:36.470 --> 00:02:38.049
over lots of people these days.

00:02:38.049 --> 00:02:40.090
So while the Android
engineering team is amazing,

00:02:40.090 --> 00:02:42.170
and I'm honestly really
fortunate to be working

00:02:42.170 --> 00:02:45.050
with them, when I really want
to know how something works,

00:02:45.050 --> 00:02:47.030
I'll at least first
get into some code

00:02:47.030 --> 00:02:48.450
and try to find out for myself.

00:02:48.450 --> 00:02:51.710
So today, I'm going to
tell you a story about how

00:02:51.710 --> 00:02:54.640
Ian and I journeyed deep
into the Android runtime

00:02:54.640 --> 00:02:56.504
and found out something
for ourselves.

00:02:56.504 --> 00:02:58.420
Specifically, it's a
story of how we found out

00:02:58.420 --> 00:03:01.510
why you have to be careful
not to waste too much time

00:03:01.510 --> 00:03:03.610
when trying to
avoid allocations,

00:03:03.610 --> 00:03:05.360
especially when
you're running on ART.

00:03:05.360 --> 00:03:08.620
And, we're actually going
to show you how we did it.

00:03:08.620 --> 00:03:10.760
This particular story
begins with a deck

00:03:10.760 --> 00:03:13.420
of cards, which is exceptionally
appropriate since it also

00:03:13.420 --> 00:03:14.470
ends with cards.

00:03:14.470 --> 00:03:17.430
Now Ian was writing a demo
that drew playing cards.

00:03:17.430 --> 00:03:19.849
It was supposed to be an
experiment about overdraw.

00:03:19.849 --> 00:03:22.390
But that actually turned out to
be the least interesting part

00:03:22.390 --> 00:03:23.750
of the demo.

00:03:23.750 --> 00:03:25.720
Now card games are a
great test for overdraw

00:03:25.720 --> 00:03:29.110
because stacks of them have
a lot of overlapping objects,

00:03:29.110 --> 00:03:31.330
but none of them are
transparent like these ones are.

00:03:31.330 --> 00:03:33.300
So there's a huge difference
between the number of pixels

00:03:33.300 --> 00:03:35.370
you draw in the worst
case versus the number you

00:03:35.370 --> 00:03:37.137
draw in the best case.

00:03:37.137 --> 00:03:38.720
But to get that best
case performance,

00:03:38.720 --> 00:03:40.970
you have to figure out exactly
which parts of the card

00:03:40.970 --> 00:03:41.832
are visible.

00:03:41.832 --> 00:03:43.790
Now there's a general
algorithm for doing that,

00:03:43.790 --> 00:03:45.310
but requires a
lot of bookkeeping

00:03:45.310 --> 00:03:46.976
because it involves
splitting rectangles

00:03:46.976 --> 00:03:49.992
into some unknown number
of smaller rectangles.

00:03:49.992 --> 00:03:52.200
Now the thing you need to
understand about Ian who is

00:03:52.200 --> 00:03:55.370
doing this is that he
is a C++ programmer.

00:03:55.370 --> 00:03:57.630
More than that, he's
a game programmer.

00:03:57.630 --> 00:04:00.400
And a game written in C++, this
problem would be the perfect

00:04:00.400 --> 00:04:03.390
candidate for some
kind of object pool.

00:04:03.390 --> 00:04:06.510
So we decided to keep all of
the rectangles in a simple pool.

00:04:06.510 --> 00:04:08.310
Now how many people
out there actually used

00:04:08.310 --> 00:04:10.975
SimplePool in their coding?

00:04:10.975 --> 00:04:12.350
It's part of the
Support Library.

00:04:12.350 --> 00:04:14.150
I don't think he expected
the object pool to make

00:04:14.150 --> 00:04:15.858
a huge performance
difference, but he

00:04:15.858 --> 00:04:17.149
thought it might help a little.

00:04:17.149 --> 00:04:20.920
What surprised us both was
that it didn't help at all.

00:04:20.920 --> 00:04:23.890
Instead, it totally tanked.

00:04:23.890 --> 00:04:26.330
I mean, the performance
was absolutely abysmal.

00:04:26.330 --> 00:04:30.084
And so, we decided
to look for answers.

00:04:30.084 --> 00:04:31.500
We started where
most people start

00:04:31.500 --> 00:04:33.960
when they have a performance
problem with the sampling

00:04:33.960 --> 00:04:36.064
method profiler and Traceview.

00:04:36.064 --> 00:04:37.980
How many of you have
used Traceview out there?

00:04:37.980 --> 00:04:39.070
Come on, show of hands.

00:04:39.070 --> 00:04:39.695
Oh that's good.

00:04:39.695 --> 00:04:41.287
You're listening,
that's awesome.

00:04:41.287 --> 00:04:43.370
The profiler isn't as good
as Systrace of catching

00:04:43.370 --> 00:04:45.130
intermittent performance
spikes, but it's really great

00:04:45.130 --> 00:04:47.546
at getting a big picture view
of what's expensive and what

00:04:47.546 --> 00:04:48.780
isn't.

00:04:48.780 --> 00:04:50.290
And here we are.

00:04:50.290 --> 00:04:53.760
The culprit is
SimplePool release.

00:04:53.760 --> 00:04:55.620
Now here's what that
code looks like.

00:04:55.620 --> 00:04:58.300
That isInPool line looks
kind of suspicious.

00:04:58.300 --> 00:05:02.189
It sounds like it might
be a linear search.

00:05:02.189 --> 00:05:04.480
And of course, if we look
back at our Traceview output,

00:05:04.480 --> 00:05:07.390
we also see that
isInPool there is

00:05:07.390 --> 00:05:09.210
right at the top of our list.

00:05:09.210 --> 00:05:10.524
So clearly it's costly.

00:05:10.524 --> 00:05:12.190
And actually it does
do a linear search.

00:05:12.190 --> 00:05:13.810
It goes to check
everything in the array

00:05:13.810 --> 00:05:14.950
to see if it's
already in the pool.

00:05:14.950 --> 00:05:16.325
So if you have a
really big pool,

00:05:16.325 --> 00:05:18.940
it's actually really expensive,
especially since array access

00:05:18.940 --> 00:05:21.050
is not particularly cheap.

00:05:21.050 --> 00:05:24.080
So we decided to make
an even simpler pool.

00:05:24.080 --> 00:05:25.151
Well that was easy.

00:05:25.151 --> 00:05:27.400
We'll just make our own pool
with a cabana, waterfall,

00:05:27.400 --> 00:05:28.600
a diving board.

00:05:28.600 --> 00:05:29.900
I mean with unchecked releases.

00:05:29.900 --> 00:05:31.750
It's very easy to
get those mixed up.

00:05:31.750 --> 00:05:33.310
We're living on the edge.

00:05:33.310 --> 00:05:36.470
And of course, Traceview
output looks like this.

00:05:36.470 --> 00:05:38.382
It fixes our performance
problems, yes.

00:05:38.382 --> 00:05:40.090
It turns out you should
be really careful

00:05:40.090 --> 00:05:41.260
when using SimplePool.

00:05:41.260 --> 00:05:44.296
That linear search really
makes large pools slow.

00:05:44.296 --> 00:05:45.670
We could pack up
and go home now,

00:05:45.670 --> 00:05:47.820
but now we've got some
code to play with.

00:05:47.820 --> 00:05:50.900
So we decided to find
out how big of a deal

00:05:50.900 --> 00:05:53.570
is allocation in ART anyway.

00:05:53.570 --> 00:05:55.980
So we had some crazy
tests like allocating

00:05:55.980 --> 00:05:58.560
thousands and thousands
of objects in onDraw.

00:05:58.560 --> 00:06:01.460
And we found that in most cases,
unless the object was really

00:06:01.460 --> 00:06:03.826
expensive to create,
like a paint object,

00:06:03.826 --> 00:06:05.450
it didn't really
affect our frame rate.

00:06:05.450 --> 00:06:07.900
And we're like, what?

00:06:07.900 --> 00:06:10.640
I mean, no, we didn't
just suddenly find out

00:06:10.640 --> 00:06:12.140
that allocations were free.

00:06:12.140 --> 00:06:15.390
All that stuff Colt McAnlis
told you is still true.

00:06:15.390 --> 00:06:17.890
What this experience taught us
was that we didn't understand

00:06:17.890 --> 00:06:20.240
how allocations affected
performance quite as well as we

00:06:20.240 --> 00:06:21.370
thought we did.

00:06:21.370 --> 00:06:23.620
And when you start seeing
performance numbers that you

00:06:23.620 --> 00:06:26.000
don't expect, that's
a perfect time

00:06:26.000 --> 00:06:28.030
to start digging into the code.

00:06:28.030 --> 00:06:29.904
So off to the debugger.

00:06:29.904 --> 00:06:31.070
I know what you're thinking.

00:06:31.070 --> 00:06:33.250
I love reading through code as
much as the next crazy person,

00:06:33.250 --> 00:06:34.655
but sometimes you just
got to step through it

00:06:34.655 --> 00:06:35.710
to understand it.

00:06:35.710 --> 00:06:38.420
Now there's a lot of ways to
debug the Android runtime.

00:06:38.420 --> 00:06:40.180
Some are easy,
and some are hard.

00:06:40.180 --> 00:06:42.610
And let's make things
easy on ourselves.

00:06:42.610 --> 00:06:45.180
First-- and this is
going to shock you--

00:06:45.180 --> 00:06:49.015
we're actually going to
debug an emulator build.

00:06:49.015 --> 00:06:51.390
Now how many of you actually
use the emulator when you're

00:06:51.390 --> 00:06:52.810
writing Android software?

00:06:52.810 --> 00:06:53.690
OK.

00:06:53.690 --> 00:06:56.741
Well, so devices
are kind of finicky.

00:06:56.741 --> 00:06:58.490
So are network connections
and USB cables.

00:06:58.490 --> 00:07:00.948
We're actually going to be
doing a lot of native debugging.

00:07:00.948 --> 00:07:03.930
And unless you're trying to
debug an issue with hardware

00:07:03.930 --> 00:07:06.740
code generation, there's really
not a big difference these days

00:07:06.740 --> 00:07:10.180
between debugging against the
emulator and a real device.

00:07:10.180 --> 00:07:12.360
In addition, when you're
running on the emulator,

00:07:12.360 --> 00:07:13.850
you get to run as root.

00:07:13.850 --> 00:07:16.630
And our images also include
a version of GDB server.

00:07:16.630 --> 00:07:18.780
So you've got super,
super reliable debugging.

00:07:18.780 --> 00:07:22.940
Believe it or not if you need to
do native debugging on Android.

00:07:22.940 --> 00:07:26.220
Second, we get to
avoid using ADB.

00:07:26.220 --> 00:07:27.570
Which is really cool.

00:07:27.570 --> 00:07:28.420
Why?

00:07:28.420 --> 00:07:32.450
Because ADB was designed to
be cheap, slow, and reliable.

00:07:32.450 --> 00:07:35.868
And it really manages to
achieve two of those goals.

00:07:35.868 --> 00:07:38.680
[LAUGHTER]

00:07:38.680 --> 00:07:41.800
Now, ADB is OK if you're
using the GDB command

00:07:41.800 --> 00:07:44.966
line, which I know some
of you are totally into.

00:07:44.966 --> 00:07:46.340
So if you're one
of those people,

00:07:46.340 --> 00:07:48.970
just go back to your
Emacs or whatever

00:07:48.970 --> 00:07:52.535
for a minute or two while
I talk to everyone else.

00:07:52.535 --> 00:07:54.160
When I'm stepping
through unknown code,

00:07:54.160 --> 00:07:56.080
I really prefer to
use some kind of GUI.

00:07:56.080 --> 00:07:59.660
Now Ian is a huge fan of Qt
Creator, because it's free,

00:07:59.660 --> 00:08:02.000
and because it's not Eclipse.

00:08:02.000 --> 00:08:05.170
But ADB can't handle the
amount of GDB traffic

00:08:05.170 --> 00:08:07.030
that an IDE like that generates.

00:08:07.030 --> 00:08:09.990
It works for awhile, but at some
point it just decides to quit.

00:08:09.990 --> 00:08:12.770
But fortunately, the emulator
has its own IP port redirecter

00:08:12.770 --> 00:08:14.590
that doesn't rely on ADB.

00:08:14.590 --> 00:08:18.160
And my experience with that is
it it's really, really solid.

00:08:18.160 --> 00:08:20.820
Third, download
the AOSP code base

00:08:20.820 --> 00:08:23.130
and build your own
emulator image.

00:08:23.130 --> 00:08:26.757
Now you don't have to do this,
but it's so totally worth it.

00:08:26.757 --> 00:08:28.340
For one thing, you
don't have to worry

00:08:28.340 --> 00:08:31.410
about your sources, symbols,
and binaries being in sync.

00:08:31.410 --> 00:08:33.179
For another thing--
and this is really

00:08:33.179 --> 00:08:34.929
important for this
particular quest--

00:08:34.929 --> 00:08:36.690
you can actually
disable optimizations

00:08:36.690 --> 00:08:38.690
on modules you want
to debug, which

00:08:38.690 --> 00:08:42.042
make stepping through
the code a lot easier.

00:08:42.042 --> 00:08:44.500
Now once you have a rock solid
debugger attached to the run

00:08:44.500 --> 00:08:47.020
time, it's kind of addictive.

00:08:47.020 --> 00:08:50.810
You're seeing Android from
a completely new angle.

00:08:50.810 --> 00:08:54.110
It's like you've been poking
around a cave with a candle,

00:08:54.110 --> 00:08:57.470
and someone just gave you
this high powered flashlight.

00:08:57.470 --> 00:08:58.970
And if you're running
a Windows box,

00:08:58.970 --> 00:09:01.530
building Android is a good
excuse to install Linux VM.

00:09:04.470 --> 00:09:05.390
All right.

00:09:05.390 --> 00:09:07.790
Let's start with my favorite
piece of code, the byte code

00:09:07.790 --> 00:09:08.340
interpreter.

00:09:08.340 --> 00:09:10.423
Now they're actually two
different implementations

00:09:10.423 --> 00:09:12.460
depending on how you compile it.

00:09:12.460 --> 00:09:16.310
One is a goto table
implementation,

00:09:16.310 --> 00:09:17.905
which is one of
those pieces of code

00:09:17.905 --> 00:09:22.220
that simultaneously proves
why C macros are horrible

00:09:22.220 --> 00:09:25.190
and why they're never
going to go away.

00:09:25.190 --> 00:09:27.590
But fortunately, if you set
the right compiler options,

00:09:27.590 --> 00:09:31.370
you get the implementation in
interpreter_switch_impl.cc,

00:09:31.370 --> 00:09:34.810
which looks exactly like
you always thought it would,

00:09:34.810 --> 00:09:37.856
just one giant switch statement
with a case for each opcode.

00:09:37.856 --> 00:09:39.480
If you've been
struggling to figure out

00:09:39.480 --> 00:09:40.938
what's going on at
the interpreter,

00:09:40.938 --> 00:09:43.637
just seeing this enough
is to make you cry.

00:09:43.637 --> 00:09:45.470
It doesn't see as much
traffic as it used to

00:09:45.470 --> 00:09:47.707
because of the head
ahead of time compiling.

00:09:47.707 --> 00:09:49.540
But if you turn that
off, this piece of code

00:09:49.540 --> 00:09:52.900
becomes the Rick's Cafe
Americain of switch statements.

00:09:52.900 --> 00:09:55.560
Everybody comes here, which
makes it the perfect place

00:09:55.560 --> 00:09:59.560
to set some breakpoints and
learn how the runtime works.

00:09:59.560 --> 00:10:03.040
Now since we're trying to
minimize our allocation costs,

00:10:03.040 --> 00:10:05.310
maybe we should start
by looking at how object

00:10:05.310 --> 00:10:06.920
allocation actually happens?

00:10:06.920 --> 00:10:09.590
Now all object allocation
starts at the same place

00:10:09.590 --> 00:10:12.360
in this interpreter, which
is this new instance DALVIK

00:10:12.360 --> 00:10:14.269
opcode.

00:10:14.269 --> 00:10:16.810
But as soon as we get into the
implementation of that opcode,

00:10:16.810 --> 00:10:20.080
things get a little abstract.

00:10:20.080 --> 00:10:23.180
So it turns out that the ART
memory system is massively

00:10:23.180 --> 00:10:24.370
polymorphic.

00:10:24.370 --> 00:10:26.620
There are actually
eight different kinds

00:10:26.620 --> 00:10:28.500
of allocators that
might be returned

00:10:28.500 --> 00:10:29.541
from GetCurrentAllocator.

00:10:30.659 --> 00:10:32.200
Now this is one of
those points where

00:10:32.200 --> 00:10:34.410
it's really great to be stepping
through in the debugger instead

00:10:34.410 --> 00:10:35.880
of just reading the code.

00:10:35.880 --> 00:10:37.870
Because we can see exactly
what we're getting,

00:10:37.870 --> 00:10:39.240
which is RosAlloc.

00:10:39.240 --> 00:10:42.520
I mean, not always, but usually.

00:10:42.520 --> 00:10:46.640
And Ros stands for run of
slots, which is basically

00:10:46.640 --> 00:10:51.900
a fancy pants way of saying
fixed sized block allocator.

00:10:51.900 --> 00:10:56.250
The slot is a fixed size block.

00:10:56.250 --> 00:10:59.840
The run is an array
of those blocks.

00:10:59.840 --> 00:11:03.840
And the allocator
owns a set of runs.

00:11:03.840 --> 00:11:05.740
Now each run has a
different slot size,

00:11:05.740 --> 00:11:09.080
so it can hold object
of that size or smaller.

00:11:09.080 --> 00:11:12.460
And unlike my diagram, the
number of slots in each run

00:11:12.460 --> 00:11:15.560
is actually calculated to make
the run end as close to a page

00:11:15.560 --> 00:11:17.430
boundary as possible.

00:11:17.430 --> 00:11:20.230
Now this is an
awesome allocator.

00:11:20.230 --> 00:11:22.610
It's not the most efficient
as far as memory usage,

00:11:22.610 --> 00:11:24.830
but it's got two
really nice advantages.

00:11:24.830 --> 00:11:29.180
One is that it's practically
immune to fragmentation.

00:11:29.180 --> 00:11:31.400
Second, bookkeeping
is really easy.

00:11:31.400 --> 00:11:33.349
You never need to split
or coalesce blocks,

00:11:33.349 --> 00:11:35.640
and you don't need to store
the size of each allocation

00:11:35.640 --> 00:11:37.260
because the address
of the allocation

00:11:37.260 --> 00:11:39.536
tells you everything
you need to know.

00:11:39.536 --> 00:11:41.160
So even though you
waste a little space

00:11:41.160 --> 00:11:42.951
at the end of any object
that's not exactly

00:11:42.951 --> 00:11:46.320
the size of its slot,
you get some of that back

00:11:46.320 --> 00:11:50.130
by not having to store any extra
cruft alongside it in the heap.

00:11:50.130 --> 00:11:53.210
So not to mention that it avoids
data alignment problems if you

00:11:53.210 --> 00:11:55.464
happen to have any of those.

00:11:55.464 --> 00:11:56.880
There's one really
interesting way

00:11:56.880 --> 00:11:58.796
that RosAlloc is different
from the allocators

00:11:58.796 --> 00:12:01.130
you see in things
like game programming.

00:12:01.130 --> 00:12:03.020
Because game programmers
tend to use a stack

00:12:03.020 --> 00:12:04.619
to keep track of free elements.

00:12:04.619 --> 00:12:06.910
Now you could implement that
in a little array of bytes

00:12:06.910 --> 00:12:08.826
or shorts that has the
same number of elements

00:12:08.826 --> 00:12:10.987
as there are slots
in the run, and it

00:12:10.987 --> 00:12:13.070
lets you do both allocations
and the deallocations

00:12:13.070 --> 00:12:14.850
in constant time.

00:12:14.850 --> 00:12:19.890
RosAlloc on the other hand
tracks free slots in a bitmap.

00:12:19.890 --> 00:12:22.210
To allocate, you actually
to look through the bitmap

00:12:22.210 --> 00:12:24.040
until you find a zero.

00:12:24.040 --> 00:12:27.204
Now, technically that's
an O(n) operation.

00:12:27.204 --> 00:12:29.870
And when I first looked at this,
I thought it was kind of weird.

00:12:29.870 --> 00:12:32.130
And then I thought it
was kind of interesting.

00:12:32.130 --> 00:12:35.830
And then I realized it
was freaking brilliant.

00:12:35.830 --> 00:12:37.370
And here's why.

00:12:37.370 --> 00:12:40.160
First of, yes, the
allocation is order N.

00:12:40.160 --> 00:12:42.692
But remember, these are actually
fairly small little groups

00:12:42.692 --> 00:12:43.650
you're allocating from.

00:12:43.650 --> 00:12:46.230
So it's N times a
very small constant.

00:12:46.230 --> 00:12:50.110
Furthermore, most CPUs can
find the first cleared bit

00:12:50.110 --> 00:12:52.130
in a word on a
single instruction.

00:12:52.130 --> 00:12:55.220
So the worst case
allocation cost

00:12:55.220 --> 00:12:57.940
is just the number of slots
divided by the number of bits

00:12:57.940 --> 00:12:59.310
in a machine work.

00:12:59.310 --> 00:13:02.500
On Android, we actually negate
the bitmap word and then use

00:13:02.500 --> 00:13:06.230
something called _builtin_ffs
to find the index of the first

00:13:06.230 --> 00:13:07.210
non-set bit.

00:13:07.210 --> 00:13:10.440
So we actually use a
compiler intrinsic for that.

00:13:10.440 --> 00:13:12.710
And that's not even the
brilliant part though.

00:13:12.710 --> 00:13:16.290
Because the brilliant part is
what happens on deallocation.

00:13:16.290 --> 00:13:19.450
Because allocation in a
multi-threaded environment

00:13:19.450 --> 00:13:22.410
is a huge pain, the
best way to make it fast

00:13:22.410 --> 00:13:24.340
is to remove the concurrency.

00:13:24.340 --> 00:13:26.530
Just give each thread its
own separate allocator

00:13:26.530 --> 00:13:28.840
and make a rule that
memory has to be

00:13:28.840 --> 00:13:31.300
freed on the same thread
that allocated it.

00:13:31.300 --> 00:13:33.930
But that really sucks
for garbage collection.

00:13:33.930 --> 00:13:35.930
Because part of the
appeal is that you can do

00:13:35.930 --> 00:13:38.130
a lot of the work on
a background thread.

00:13:38.130 --> 00:13:39.880
After all, we all have
multi-core systems.

00:13:39.880 --> 00:13:43.320
We tend to have a core free
that's not doing a lot.

00:13:43.320 --> 00:13:45.590
And what you get with
RosAlloc is almost the best

00:13:45.590 --> 00:13:47.180
of both worlds.

00:13:47.180 --> 00:13:52.020
See, there's actually multiple
bitmaps for every run.

00:13:52.020 --> 00:13:54.020
One tracks which
slots are in use,

00:13:54.020 --> 00:13:55.570
like I talked about earlier.

00:13:55.570 --> 00:13:58.440
But another one
tracked slots that

00:13:58.440 --> 00:14:00.350
have been freed by
a different thread.

00:14:03.260 --> 00:14:05.350
So instead of
synchronizing the free list

00:14:05.350 --> 00:14:08.930
on every deallocation, you can
wait until it's convenience

00:14:08.930 --> 00:14:11.710
and apply all pending
deallocations by just

00:14:11.710 --> 00:14:13.017
NANDing the two bitmaps.

00:14:13.017 --> 00:14:15.100
By the way, I'm sharing a
lot of source code here,

00:14:15.100 --> 00:14:16.100
and it's a little small.

00:14:16.100 --> 00:14:19.000
So I apologize in
the middle of this.

00:14:19.000 --> 00:14:21.420
Once again though, this
is fracking brilliant.

00:14:21.420 --> 00:14:24.310
Because you can now-- and yes,
you can have thread local runs.

00:14:24.310 --> 00:14:26.120
And locks are
sharded by slot size

00:14:26.120 --> 00:14:28.710
so that even shared runs
have way lower contention.

00:14:28.710 --> 00:14:31.490
And there's a bunch of other
cool stuff in RosAlloc.

00:14:31.490 --> 00:14:34.710
But we should probably move on
before everyone starts calling

00:14:34.710 --> 00:14:37.890
me the crazy RosAlloc guy.

00:14:37.890 --> 00:14:39.830
So the really sad
thing is that it's

00:14:39.830 --> 00:14:42.210
hard to implement--
you really implement

00:14:42.210 --> 00:14:43.892
anything this elegant in Java.

00:14:43.892 --> 00:14:46.100
You'd end up reinventing
the entire reference system,

00:14:46.100 --> 00:14:48.310
and it would be kind of
a maintenance nightmare.

00:14:48.310 --> 00:14:50.719
So yeah, allocating
from our object pool

00:14:50.719 --> 00:14:53.260
isn't a whole lot faster than
allocating from the normal Java

00:14:53.260 --> 00:14:55.395
heap, and it's way more work.

00:14:55.395 --> 00:14:56.970
But we kind of expected that.

00:14:56.970 --> 00:14:59.920
I mean, no one ever explains
about the cost of allocation

00:14:59.920 --> 00:15:01.760
in a garbage collected runtime.

00:15:01.760 --> 00:15:04.326
It's always about the
cost of collection.

00:15:04.326 --> 00:15:05.700
So the question
is, why aren't we

00:15:05.700 --> 00:15:07.770
seeing these massive
collection pauses

00:15:07.770 --> 00:15:10.960
when we allocated massive
numbers of short lived objects?

00:15:10.960 --> 00:15:13.446
Now RosAlloc gave us a
little bit of a clue.

00:15:13.446 --> 00:15:14.820
They didn't spend
all that effort

00:15:14.820 --> 00:15:16.660
on concurrency for nothing.

00:15:16.660 --> 00:15:20.180
It's not that the garbage
collector is doing nothing,

00:15:20.180 --> 00:15:22.826
it's that a lot of its work
is being done somewhere else

00:15:22.826 --> 00:15:23.950
other than the main thread.

00:15:23.950 --> 00:15:26.580
And it's still work, and
we'd like to minimize it,

00:15:26.580 --> 00:15:30.500
but it's not calling causing
the jank that it did on DALVIK.

00:15:30.500 --> 00:15:32.800
So there's one piece
left in this puzzle.

00:15:32.800 --> 00:15:35.200
And it has to do with
how the GC manages

00:15:35.200 --> 00:15:38.370
to do so much of its work
on a background thread.

00:15:38.370 --> 00:15:41.280
Now actually, since
we spent so much time

00:15:41.280 --> 00:15:44.210
talking about how great the
allocator is at concurrency,

00:15:44.210 --> 00:15:48.280
it's probably worth going over
why this is even a problem.

00:15:48.280 --> 00:15:52.320
Now the GC has to figure
out which objects are live,

00:15:52.320 --> 00:15:53.600
and which are dead.

00:15:53.600 --> 00:15:56.570
And it does this by starting
with the object on the stack

00:15:56.570 --> 00:15:58.830
and following the
references all the way down

00:15:58.830 --> 00:16:01.520
till there are no more
references left to follow.

00:16:01.520 --> 00:16:03.890
Every object that got
visited during that procedure

00:16:03.890 --> 00:16:04.854
must be live.

00:16:04.854 --> 00:16:06.770
Because clearly, there's
a chain of references

00:16:06.770 --> 00:16:09.660
that your application could
follow to access that object.

00:16:09.660 --> 00:16:12.890
Every object that
get left out is dead,

00:16:12.890 --> 00:16:14.509
or at least it's not live.

00:16:14.509 --> 00:16:16.300
Now the GC guys tell
me that's a little bit

00:16:16.300 --> 00:16:17.610
of an oversimplification.

00:16:17.610 --> 00:16:19.640
But it's a good
first approximation.

00:16:19.640 --> 00:16:22.110
Thing is, this process
is not lightning fast.

00:16:22.110 --> 00:16:24.360
And if it's done concurrently,
then your application

00:16:24.360 --> 00:16:26.254
is busy connecting,
and disconnecting,

00:16:26.254 --> 00:16:27.920
and reconnecting
references while the GC

00:16:27.920 --> 00:16:29.930
is trying to trace them.

00:16:29.930 --> 00:16:34.440
So let's say that object A
has a reference to object B.

00:16:34.440 --> 00:16:39.830
And object C has a reference
type that's currently null.

00:16:39.830 --> 00:16:42.340
Now for whatever
reason, the GC visits

00:16:42.340 --> 00:16:47.130
object C before because it
visits object A. Following me?

00:16:47.130 --> 00:16:47.900
OK.

00:16:47.900 --> 00:16:50.120
Now let's say that after
the GC has visited C,

00:16:50.120 --> 00:16:54.537
but before it visits A, you give
object B to object C and null

00:16:54.537 --> 00:16:56.180
out A's reference.

00:16:56.180 --> 00:17:00.660
For all the GC can tell, A and
C both have a null reference.

00:17:00.660 --> 00:17:03.310
And it never even saw
B. So the question

00:17:03.310 --> 00:17:05.290
is, how do you fix this?

00:17:05.290 --> 00:17:06.760
And it turns out
the answer to that

00:17:06.760 --> 00:17:09.640
question tells a lot about
how we can shoot ourselves

00:17:09.640 --> 00:17:14.466
in the foot by trying to
outsmart the garbage collector.

00:17:14.466 --> 00:17:16.340
And it takes us back to
the subject of cards.

00:17:19.819 --> 00:17:22.649
If you take another look at
the glorious switch statement

00:17:22.649 --> 00:17:24.690
that it's at the heart of
the SLAVIC interpreter,

00:17:24.690 --> 00:17:26.180
you'll notice that
a lot of opcodes

00:17:26.180 --> 00:17:28.380
have an extra call in them.

00:17:28.380 --> 00:17:31.360
Then this call to check
suspend is a checkpoint.

00:17:31.360 --> 00:17:32.860
It's a place where
the thread checks

00:17:32.860 --> 00:17:36.000
to see if the GC want
it to do anything.

00:17:36.000 --> 00:17:37.770
Among other things,
this check lets

00:17:37.770 --> 00:17:40.065
the GC tell the thread
to stop completely,

00:17:40.065 --> 00:17:42.440
which is what it has to do if
it wants to get an accurate

00:17:42.440 --> 00:17:45.110
count of which objects are
dead and which ones are alive.

00:17:45.110 --> 00:17:47.430
And this is called the GC pause.

00:17:47.430 --> 00:17:50.430
Now clearly, one way to make
sure the GC gets an accurate

00:17:50.430 --> 00:17:52.990
count is just to visit the
objects all over again.

00:17:52.990 --> 00:17:55.400
But that would be a
colossal waste of time.

00:17:55.400 --> 00:17:58.290
I mean, that would be
like a cupcake move.

00:17:58.290 --> 00:18:00.710
So instead, how
about how we just

00:18:00.710 --> 00:18:02.520
revisit the objects
that got changed

00:18:02.520 --> 00:18:05.805
while we were busy doing our
first pass on the object graph.

00:18:05.805 --> 00:18:07.680
But now you're talking.

00:18:07.680 --> 00:18:10.170
That's some Gingerbread
level thinking my friends.

00:18:10.170 --> 00:18:11.940
So how do we tell
what's changed?

00:18:11.940 --> 00:18:16.367
Let's go back to that switch
statement one last time.

00:18:16.367 --> 00:18:17.950
Now you probably
haven't noticed this,

00:18:17.950 --> 00:18:21.310
but there's actually a
specific set of opcodes

00:18:21.310 --> 00:18:22.580
just for moving references.

00:18:22.580 --> 00:18:25.050
And you know, that might
strike you as being odd,

00:18:25.050 --> 00:18:27.290
because references are
just four byte binary

00:18:27.290 --> 00:18:29.430
values, same as integers.

00:18:29.430 --> 00:18:32.716
Why not just reuse the existing
integer moving opcodes?

00:18:32.716 --> 00:18:34.590
And this one takes a
little bit more digging,

00:18:34.590 --> 00:18:37.520
because the answer is actually
several layers down in the call

00:18:37.520 --> 00:18:39.040
stack, underneath
some templates,

00:18:39.040 --> 00:18:41.710
and macros, and
some random cruft.

00:18:41.710 --> 00:18:45.190
But eventually you get at this
thing called WriteBarrierField.

00:18:45.190 --> 00:18:50.304
Now the word barrier is a little
overloaded in computer science.

00:18:50.304 --> 00:18:51.970
Here it means something
that the runtime

00:18:51.970 --> 00:18:55.280
has to do before writing
to a reference field.

00:18:55.280 --> 00:18:57.340
There's also the concept
of a read barrier.

00:18:57.340 --> 00:18:58.820
But it's really
not that important

00:18:58.820 --> 00:19:01.580
to this particular discussion.

00:19:01.580 --> 00:19:04.340
Anyway, take a look at what
WriteBarrierField does.

00:19:04.340 --> 00:19:06.360
It calls mark card.

00:19:06.360 --> 00:19:07.635
See, I told there'd be cards.

00:19:10.400 --> 00:19:10.900
All right.

00:19:14.712 --> 00:19:16.670
In this case, a card is
just an area of memory.

00:19:16.670 --> 00:19:19.910
It's kind of like a page,
only it's not the same size.

00:19:19.910 --> 00:19:21.390
And besides, that
word was taken.

00:19:21.390 --> 00:19:22.760
So we call it a card.

00:19:22.760 --> 00:19:26.410
Now marking the card just says,
hey, something in this memory

00:19:26.410 --> 00:19:27.840
has changed.

00:19:27.840 --> 00:19:29.750
Now why do we even have cards?

00:19:29.750 --> 00:19:31.990
And it's really for the
same reason we have pages.

00:19:31.990 --> 00:19:34.600
So we can have
metadata about memory

00:19:34.600 --> 00:19:37.650
that takes up less room than
the memory we're describing.

00:19:37.650 --> 00:19:40.980
So for pages, we keep data
like whether it's read only,

00:19:40.980 --> 00:19:43.410
or executable, or any of
that other and protect stuff.

00:19:43.410 --> 00:19:47.550
For cards, it's pretty
much just dirty or clean.

00:19:47.550 --> 00:19:50.120
It's just a write, if you
look at the source code.

00:19:50.120 --> 00:19:52.074
It's not even an atomic.

00:19:52.074 --> 00:19:53.490
Which, by the way,
we can get away

00:19:53.490 --> 00:19:55.550
with because there's
no read, modify, write.

00:19:55.550 --> 00:19:57.650
In a concurrent environment,
it's just a write.

00:19:57.650 --> 00:19:59.440
And the read is done
during the GC pause

00:19:59.440 --> 00:20:01.150
where the value can't change.

00:20:01.150 --> 00:20:04.052
So what's so important
about the card table?

00:20:04.052 --> 00:20:05.510
Given the information
in the cards,

00:20:05.510 --> 00:20:08.280
the GC doesn't have to
rescan every single object

00:20:08.280 --> 00:20:09.470
during the pause.

00:20:09.470 --> 00:20:11.600
It can focus its
attention on the objects

00:20:11.600 --> 00:20:12.995
that might be dirty.

00:20:12.995 --> 00:20:16.640
Now this idea extends far
beyond just finding the object

00:20:16.640 --> 00:20:18.702
to change in the last
concurrent scan by the way.

00:20:18.702 --> 00:20:20.910
There are plenty of objects
that almost never change.

00:20:20.910 --> 00:20:23.110
For instance, class objects.

00:20:23.110 --> 00:20:26.560
If we can, we want to avoid
scanning those objects ever.

00:20:26.560 --> 00:20:29.550
And we can get away with that,
because if for some reason

00:20:29.550 --> 00:20:33.150
those objects ever do change,
their cards will be marked.

00:20:33.150 --> 00:20:35.310
Now the card idea isn't perfect.

00:20:35.310 --> 00:20:37.060
For instance, if a
card happens to contain

00:20:37.060 --> 00:20:38.670
more than one object,
there's no way

00:20:38.670 --> 00:20:40.600
to tell which object is dirty.

00:20:40.600 --> 00:20:42.920
All of them have
to be rescanned.

00:20:42.920 --> 00:20:44.610
Even worse, an array
of objects count

00:20:44.610 --> 00:20:46.570
as one object when it
comes to card marking.

00:20:46.570 --> 00:20:49.180
That's one object with a
whole lot of references.

00:20:49.180 --> 00:20:51.690
Which means if you insert or
remove an object from an array,

00:20:51.690 --> 00:20:55.230
the entire array gets rescanned.

00:20:55.230 --> 00:20:58.110
So now we come full
circle because our pool

00:20:58.110 --> 00:21:00.630
of card rectangles
might actually end up

00:21:00.630 --> 00:21:03.040
as a victim of card marking.

00:21:03.040 --> 00:21:05.620
I know there's a country
song in there somewhere.

00:21:05.620 --> 00:21:07.130
But it's only one
of several factors

00:21:07.130 --> 00:21:09.980
that make allocations
cheaper on ART.

00:21:09.980 --> 00:21:13.120
And I wish I had actually
more slides to talk

00:21:13.120 --> 00:21:16.190
through the rest of them, but
I'll talk about a few of them.

00:21:16.190 --> 00:21:19.340
One of them is better
collection pass scheduling.

00:21:19.340 --> 00:21:21.990
Now ART in general tends to do
a better job of figuring out

00:21:21.990 --> 00:21:25.050
when to run collection passes,
which means that GC for alloc

00:21:25.050 --> 00:21:26.460
is a thing of the past.

00:21:26.460 --> 00:21:28.250
And two, it keeps
a list of objects

00:21:28.250 --> 00:21:30.895
that have been allocated
since the last GC.

00:21:30.895 --> 00:21:33.020
So when you add that
information to the card table,

00:21:33.020 --> 00:21:35.061
ART gets the ability to
collect super short lived

00:21:35.061 --> 00:21:37.729
objects without even
triggering a GC pause.

00:21:37.729 --> 00:21:39.520
And that's why allocating
ludicrous numbers

00:21:39.520 --> 00:21:43.570
of simple object doesn't kill
ART the way it did DALVIK.

00:21:43.570 --> 00:21:49.230
And two-- sorry, I
already said this.

00:21:49.230 --> 00:21:52.140
So finally, let
me in conclusion,

00:21:52.140 --> 00:21:54.757
because this is going
to be really short guys.

00:21:54.757 --> 00:21:56.715
So don't walk out of here
and tell your friends

00:21:56.715 --> 00:21:58.621
that allocations
don't matter anymore.

00:21:58.621 --> 00:22:00.120
First of all, we
don't want to incur

00:22:00.120 --> 00:22:02.920
the wrath of Colt. And
besides, the point of this talk

00:22:02.920 --> 00:22:06.111
isn't necessarily just to
add to your stock of protips,

00:22:06.111 --> 00:22:08.610
but hopefully it's to give you
a little bit of understanding

00:22:08.610 --> 00:22:11.220
of how things are working inside
of Android and how you can

00:22:11.220 --> 00:22:13.860
[INAUDIBLE] and enjoy going
through Android yourself.

00:22:13.860 --> 00:22:16.596
So I hope I've given you some of
the tools and encouragement you

00:22:16.596 --> 00:22:17.970
need to go on your
own adventures

00:22:17.970 --> 00:22:19.220
through the Android code base.

00:22:19.220 --> 00:22:21.690
I mean, after all, what
else is open source

00:22:21.690 --> 00:22:23.820
for if we can't learn from it?

00:22:23.820 --> 00:22:26.502
So we're looking forward
to hearing your stories.

00:22:26.502 --> 00:22:29.830
If you want to contact me,
that's where I can be found.

00:22:29.830 --> 00:22:31.960
And thank you all.

00:22:31.960 --> 00:22:35.020
And you all get 20
minutes back or so.

00:22:35.020 --> 00:22:37.740
So enjoy the rest of your
time here at the barbecue.

00:22:37.740 --> 00:22:40.100
And if you have any
questions, I am more than

00:22:40.100 --> 00:22:42.130
happy to take them now.

00:22:42.130 --> 00:22:45.180
[MUSIC PLAYING]

