WEBVTT
Kind: captions
Language: en

00:00:05.240 --> 00:00:08.040
Picture this.  You sit down in front of
a new movie.

00:00:08.040 --> 00:00:10.000
Or you turn on the radio in the car.

00:00:10.000 --> 00:00:11.440
What is your brain doing?

00:00:11.440 --> 00:00:13.080
Well, a lot of things, hopefully.

00:00:13.080 --> 00:00:17.120
But your brain is also working to make sense
of whatever media you encounter.

00:00:17.120 --> 00:00:21.860
A flicker of pattern recognition and you realize
this new movie has a reference to Citizen Kane.

00:00:21.860 --> 00:00:25.380
A stab of memory, and you’re singing the
hook of that song.

00:00:25.380 --> 00:00:27.300
All. Day. Long.

00:00:27.300 --> 00:00:33.780
For every conscious reaction and response you
have to media, your brain is also subconsciously
reacting and responding.

00:00:33.780 --> 00:00:36.120
Our brains do plenty of things automatically.

00:00:36.120 --> 00:00:38.920
They tell our lungs to breathe and our heart
to beat.

00:00:38.920 --> 00:00:44.620
And while a lot of these automatic functions
are pretty great, there are a few that aren’t. –
especially when it comes to media.

00:00:44.620 --> 00:00:47.740
So today we look at how our minds react to
media.

00:00:47.740 --> 00:00:49.240
You wanna be media literate?

00:00:49.240 --> 00:00:53.600
Well here's a list of the worst impulses inside
your brain that you're going to have to overcome.

00:00:53.600 --> 00:00:56.320
This is your brain on media.

00:00:56.320 --> 00:01:06.280
[Theme Song]

00:01:06.280 --> 00:01:09.540
When was the last time you thought about tying
your shoes?

00:01:09.540 --> 00:01:11.320
Like, really had to think about it?

00:01:11.320 --> 00:01:13.200
Maybe not since you learned how, right?

00:01:13.200 --> 00:01:15.780
That’s because your brain has automated
the process.

00:01:15.780 --> 00:01:16.960
It’s muscle memory.

00:01:16.960 --> 00:01:19.920
Our brains are pretty good at automating routine
stuff.

00:01:19.920 --> 00:01:25.080
They do this to reduce the cognitive load,
or the amount of time and attention needed
to finish a task.

00:01:25.080 --> 00:01:29.320
Imagine your brain is like a computer – it
only has so much RAM to use at any moment.

00:01:29.320 --> 00:01:33.320
To make the best use of that processing power,
the brain relies on schema.

00:01:33.320 --> 00:01:40.240
A schema is a thought pattern, a way the brain
understands a task, the desired outcomes of
that task, and the strategy for getting there.

00:01:40.240 --> 00:01:43.820
If you have a routine, any routine, you have
a schema to work through it.

00:01:43.820 --> 00:01:45.320
What about news gathering?

00:01:45.320 --> 00:01:51.140
Maybe before you even open your eyes in
the morning you reach for your phone to scroll
through the latest headlines on Twitter.

00:01:51.140 --> 00:01:54.320
Or maybe you turn the TV on while you cook
and listen to the news.

00:01:54.320 --> 00:01:59.380
Or maybe you just hope someone will have
a copy of today’s paper on the bus so you can
read it when they’re done.

00:01:59.380 --> 00:02:05.180
With any news habit, your brain is not only
automating you picking up your phone in the
morning or turning on the TV.

00:02:05.180 --> 00:02:09.940
It’s also automating how you make sense
of information in that app or article.

00:02:09.940 --> 00:02:18.700
All that efficiency in our brains, which is ideal for
brushing your teeth or opening a door, is not ideal for
parsing through complex or new information.

00:02:18.700 --> 00:02:21.440
Our brains are basically designed to take
shortcuts.

00:02:21.440 --> 00:02:27.240
And shortcuts are bad for business when
we’re trying to do the hard work of navigating
the media landscape.

00:02:27.240 --> 00:02:30.080
So are there other parts of the brain that
protect us from this?

00:02:30.080 --> 00:02:32.120
Whoo-boy, it’s not even close.

00:02:32.120 --> 00:02:34.680
Bad news my friends:
It’s exactly the opposite.

00:02:34.680 --> 00:02:37.150
The human brain is a mysterious thing.

00:02:37.150 --> 00:02:41.780
We can remember what we did one day 12 years
ago, but not remember what we had for breakfast.

00:02:41.780 --> 00:02:48.420
We’ll recall ungodly amounts of song lyrics
but can never remember what that one actor’s
name is. (It’s Bill Paxton)

00:02:48.420 --> 00:02:55.000
We’ll be totally exhausted, but when our head hits the
pillow, suddenly we want to recap every embarrassing
thing we’ve done since second grade.

00:02:55.000 --> 00:03:00.200
But for all its wacky inconsistencies, one thing
the brain does really well is complete a picture.

00:03:00.200 --> 00:03:07.440
When we’re talking about visual perception – you
see a bunch of dots in the shape of a panda, and you
think “panda” – that’s called the Law of Closure.

00:03:07.440 --> 00:03:11.900
As we move through the media environment,
we’re constantly trying to form this type of closure.

00:03:11.900 --> 00:03:14.200
And our brains don’t do this objectively.

00:03:14.200 --> 00:03:19.520
Each time we take a bit of info and complete
the picture, we’re using prior life experiences
and knowledge.

00:03:19.520 --> 00:03:27.260
So, for instance, when you read a headline like
“DiCaprio and Winslet recreate epic scene from Titanic,”
you’d use prior knowledge to fill in the gaps.

00:03:27.260 --> 00:03:34.760
You know Frank DiCaprio and Maggie Winslet
didn’t star in that film, so it must be referencing
Leonardo DiCaprio and Kate Winslet.

00:03:34.760 --> 00:03:41.100
It’s like the brain’s version of when Google
knows you’re searching for “how to know your
cat loves you” just from the letter H.

00:03:41.100 --> 00:03:42.640
No? Is that...is that just me?

00:03:42.640 --> 00:03:49.540
This inherent desire to connect the dots, to see
the whole instead of its parts – is exactly what
makes humans vulnerable to misinformation.

00:03:49.540 --> 00:03:53.080
Consider another unhelpful brain reflex: false
memory.

00:03:53.080 --> 00:03:58.560
Sometimes when we can’t exactly recall the
details of an event, our brain will just fill in the
blanks with something plausible.

00:03:58.570 --> 00:04:00.600
For instance, say you witnessed a robbery.

00:04:00.600 --> 00:04:03.980
The police show up and ask you, “What color
shirt was the robber wearing?”

00:04:03.980 --> 00:04:07.120
It happened so fast you think, huh I’m not
quite sure.

00:04:07.120 --> 00:04:09.880
And another witness says, “I think it was
purple.”

00:04:09.880 --> 00:04:14.040
And suddenly maybe you remember the robber
was wearing a purple shirt.

00:04:14.040 --> 00:04:15.920
It’s not that you are trying to lie.

00:04:15.920 --> 00:04:22.820
It’s more like your brain thinks, “yeah, that
sounds about right,” and the line between memory
and imagination is just too thin to notice.

00:04:22.820 --> 00:04:31.300
The trouble with a false memory, especially when it
comes to misinformation and “fake news,” is it’s much
easier to create a memory than it is to change one.

00:04:31.300 --> 00:04:39.780
So when a Facebook page built to spread fake news
sends a lie out into the world, readers are more likely to
remember that lie than to update their memory of it later.

00:04:39.780 --> 00:04:41.440
Even when they have the right info.

00:04:41.440 --> 00:04:46.480
Another time-saver the brain uses is hunting
for information we already believe to be true.

00:04:46.490 --> 00:04:49.490
This is called confirmation bias, and it’s
a huge problem.

00:04:49.490 --> 00:04:51.530
Let’s jump into the Thought Bubble to check
it out.

00:04:51.530 --> 00:04:54.420
Each and every one of us wakes up in the morning
biased.

00:04:54.420 --> 00:04:59.560
Biased toward early mornings or late nights,
biased towards conservatism or liberalism,

00:04:59.560 --> 00:05:02.560
biased towards reading news or watching it
on TV.

00:05:02.560 --> 00:05:07.680
Our life’s worth of experiences shape us to
prefer, understand, and believe certain things.

00:05:07.680 --> 00:05:15.240
When we’re confronted with an avalanche of
information, which is difficult to wade through, we seek
out things we already prefer, understand, and believe.

00:05:15.240 --> 00:05:19.780
It’s just easier, cognitively and emotionally,
to only deal with things we already like.

00:05:19.780 --> 00:05:26.200
This means that if we’re presented with
a message that aligns with or confirms our
biases, we’re extra likely to believe it.

00:05:26.200 --> 00:05:30.740
On the other hand, if that message opposes
our biases, we’re extra likely to think it’s false.

00:05:30.740 --> 00:05:36.600
It also means that if you and I both experience
the same media, we could take away completely
different meanings.

00:05:36.600 --> 00:05:40.620
Take this Washington Post article from October
2017, for example.

00:05:40.620 --> 00:05:44.620
“Clinton campaign, DNC paid for research
that led to Russia dossier”

00:05:44.620 --> 00:05:51.200
It says that Hillary Clinton’s presidential campaign
and the Democratic National Committee paid for
research into Donald Trump’s campaign.

00:05:51.200 --> 00:05:55.160
This dossier was very controversial when it
was revealed in 2016.

00:05:55.160 --> 00:06:00.480
Many Clinton supporters and liberal Americans
believed the dossier was proof of Trump’s
collusion with a foreign power.

00:06:00.480 --> 00:06:06.580
Many Trump supporters and conservative Americans
believed it was proof that the Democratic party was
trying to take down the Republican candidate.

00:06:06.580 --> 00:06:11.940
Now, if you already have a Democratic bias you
might think, “Wow, the dossier must have been legit.

00:06:11.940 --> 00:06:15.280
Why would the Democratic party spend time
and money on a phony story?”

00:06:15.280 --> 00:06:18.060
And If you have a Republican bias, you
could conclude the opposite:

00:06:18.060 --> 00:06:22.700
“Wow, the dossier must have been phony the whole
time, if it was financed by the Democratic party.”

00:06:22.700 --> 00:06:29.860
This means that a piece of information can do
the same thing for different people: communicate,
simply, what you already believe is true is true.

00:06:29.870 --> 00:06:31.120
Thanks, Thought Bubble.

00:06:31.120 --> 00:06:38.200
Social media presents an extra obstacle: most
platforms, like Facebook, Twitter, and Instagram,
are built to reward confirmation bias.

00:06:38.200 --> 00:06:44.380
Those companies want you in their apps as
long as possible, so their algorithms are tuned
to keep showing you stuff you like.

00:06:44.380 --> 00:06:49.020
Which would be fine, if 38% of U.S. adults
didn’t rely on them for news.

00:06:49.020 --> 00:06:56.340
Which brings us to another brain time-saver:
information satisficing – a bizarre combo
of “satisfying” and “sufficing.”

00:06:56.340 --> 00:07:02.940
Sometimes when we’re busy or not really that
concerned with hunting down the right answer, we’ll
accept whatever answer’s laid out in front of us.

00:07:02.940 --> 00:07:05.660
Say, your second-favorite celeb couple breaks
up.

00:07:05.660 --> 00:07:11.760
They won’t talk to the press about it, but
a tabloid at the grocery store says he cheated
with the nanny. Scandalous!

00:07:11.760 --> 00:07:17.080
You think that sounds plausible, and since this info
isn’t life-or-death important, this answer suffices.

00:07:17.080 --> 00:07:21.440
Searching through old interviews to look for
clues of a slowly dissolving romance –

00:07:21.440 --> 00:07:24.500
we’ve all got things to do, like figure out whether
our cat loves us.

00:07:24.500 --> 00:07:30.720
Age-old tabloid tales like cheating with the
nanny prey on another aspect of our brain’s
desire to complete the picture.

00:07:30.720 --> 00:07:34.160
We love stories.
Really, we love stories.

00:07:34.160 --> 00:07:39.160
If it’s simple, easy to understand, and fills
in the gaps for us, we are ready to believe.

00:07:39.160 --> 00:07:43.340
But the human instinct for storytelling is
straight up dangerous to media literacy.

00:07:43.340 --> 00:07:47.680
Stories are sense-making tools; they help
us understand the world around us.

00:07:47.680 --> 00:07:56.740
So when something is complex or difficult to understand
and the media turns it into a familiar narrative for us, we
welcome it with wide, open arms – even if it’s false.

00:07:56.740 --> 00:08:03.820
To sum up, your brain on media is prone to
taking shortcuts and filling in the blanks of a
story whenever, and however, it can.

00:08:03.830 --> 00:08:08.680
What’s worse, publishers, advertisers, and
tech companies know all of these tricks, too!

00:08:08.690 --> 00:08:12.450
They use them against us all the time to hold
(or steal) our attention.

00:08:12.450 --> 00:08:18.260
If you’ve absolutely never fallen prey to
fake news or some other kind of misinformation
– well congratulations.

00:08:18.260 --> 00:08:23.340
But for the rest of us, it’s not always
easy to spot our brain’s thought patterns
at work, let alone break them.

00:08:23.340 --> 00:08:29.740
That’s where strong critical thinking skills
come in, and the shared responsibility of doing
this work together, as a society.

00:08:29.740 --> 00:08:35.380
The more we acknowledge our biases and thought
patterns, the better we get at smashing through
them to find the truth.

00:08:35.380 --> 00:08:40.200
We’ll continue that hard work together on
the next episode of Crash Course: Media Literacy.

00:08:40.200 --> 00:08:42.900
For now, I’m Jay Smooth.
See you next week!

00:08:42.900 --> 00:08:47.000
Crash Course Media Literacy is filmed in the
Dr. Cheryl C. Kinney Studio in Missoula, MT.

00:08:47.000 --> 00:08:50.920
It’s made with the help of all of these nice
people, and our animation team is Thought Cafe.

00:08:50.920 --> 00:08:52.540
Crash Course is a Complexly production.

00:08:52.540 --> 00:08:56.100
If you wanna keep imagining the world complexly
with us check out some of our other channels,

00:08:56.100 --> 00:08:59.180
like The Financial Diet, SciShow Space, and
Mental Floss.

00:08:59.180 --> 00:09:03.460
If you'd like to keep Crash Course free for
everyone, forever, you can support the series
at Patreon,

00:09:03.460 --> 00:09:06.460
a crowdfunding platform that allows
you to support the content you love.

00:09:06.460 --> 00:09:10.680
Thank you to all of our patrons for making
Crash Course possible with their continued
support.

