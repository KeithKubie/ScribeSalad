Speaker 1:          00:00          And this video will describe the trick that's a very useful and very general for improving any object recognition, trainable system like a convolutional neural network, which we will refer to as data set expansion.

Speaker 2:          00:15          Okay.

Speaker 1:          00:16          So we've seen that in a commercial neural network. Uh, we get some invariances done are essentially built in, uh, it's invariant to small translations thanks to uh, the convolution and the Max pooling with sub sampling. It's also a invariant to small immunation changes. If we introduce some contrast normalization. However, it's not built in us to be invariant with respect to other things like rotations or changes in scale. Uh, and you'd imagine for say, an object recognition application because the object doesn't silly change. If we zoom in or zoom out in the image or if we rotate it a little bit, uh, we would like to build in or to encourage that type of invariance in our, uh, in our conventional neural network does actually. Uh, but it turns out that these, uh, variations, I actually very easy to generate artificially. Uh, it's very easy to just take an image and rotate it somewhat or change the scale at which, uh, we're looking at this a given image.

Speaker 1:          01:21          So very easy trick for improving the performance of a computer vision system is to actually generate this artificial data and put it into our training set. So expand the training set using these transformation, uh, to guide us into how we could generate additional examples. And so by doing this, by generating this additional training data, the neural network, well, instead learn to be in Varian to these transformations because they're explicitly there and the training set, they will get explicitly the signal that it should perform odd, put the same object, uh, for any variation in the rotation or scaling that will generate.

Speaker 1:          02:05          Sorry, is there a cartoon illustration of how we could generate these additional example? So I'm now in each case will essentially take a, a smaller portion of the image and we'll apply a transformation to it to get a, an undoing, the transformation to get an image in the same reference frame. So, uh, for the original image, we just take some crop at the center and that would become a new training example. Then if we want to be invited to translation, we could take the crop of the original image and instead translate somewhat. Uh, and then we would take that subset of the image and this would become our new image. Uh, we could, if we want to be invariant with respect to rotations, we could take the crop, the original crop a window and just rotate it randomly and then we would, uh, consider only the pixels in that window and we would rotate and do the rotation to get again as a rectangular image, like a, the original image.

Speaker 1:          03:07          Uh, and similarly for scaling, uh, we could just take the cropping window and it stayed instead change its size. So if we made it smaller than we could crop fewer pixels and then we could undo the scrubbing by scaling back to the same size as the original image here, in which case we'd get easy zooming operations. So we'd be changing the scale of the actual image. So for performing these operations, I won't go into the detail. You need to do some sort of interpolation of pixels when you're doing these real valued rotations or scaling a, but often if you have some software that does, that allows you to manipulate images, uh, you can do a many of these operations there. They often, uh, uh, support it.

Speaker 3:          03:55          Yeah.

Speaker 1:          03:56          And other type of additional examples we can generate, uh, to, uh, improve the digitalization performance of uh, uh, computer vision system is to add so-called elastic the formations of the image. This is particularly useful for character recognition. So the idea is that we want to take some original image and sort of locally distorted a little bit such that it still looks like the same kind of object, but it's somewhat a little bit different. It has a slightly different appearance, but that's still, um, qualifies as an appearance for that same object. So one way of doing this is to first generate a random distortion field. So the distortion field, which we see here would be for each Pixel, a vector that tells us how the value of that pixel should be displaced into the, into dimensions. And so if we generate the random, uh, distortion field like this a while, you get a bunch of arrows pointing in random directions.

Speaker 1:          04:58          So they're generated here, each, uh, using some Gaussian where each simple. So each factor is, is generated independently. So we are generating each point, which is a factor as the two dimensional from a two dimensional Goshen and I, if we applied that distortion field to the image here, for instance, we'd get something that's actually a bit noisy. It's, it's not a very convincing six, uh, and it just looks like we've just added some noise. However, if we take that random field, we actually smooth it, uh, using some, uh, smoothing kernel and doing a correlation or convolution such as say, a Gaussian kernel for instance. Uh, then we can just smooth this, uh, original random distortion field to get a smoother transformation. And if we apply this distortion field that's been smooth, then we actually get something like here, the six has been into this sort of deformation, which still qualifies as a sixth to pretty convincing a image of a six.

Speaker 1:          06:04          And so by generating many of these distortions, so we get another one where we generated the random a distortion and, and smooth the distortion. We get a new six here, which is actually quite different from the previous one, and it's still a very convincing six. So a, we see that, uh, this is another kind of operation, uh, which allows us to generate for free additional training data. So we would just add this as are in our training set and label it as six. Again, you need to be careful with, uh, uh, in order to do some interpretation of the pixels because this is, again, a transformation which is continuous. So it's not, each vector does not displace the pixel in the cell exactly on the original grid. And so you have to do some, uh, uh, a spatial interpolation. Um, but again, this is the kind of thing that's often supported and, and, uh, uh, softwares that allow you to manipulate the images to get more details about all of this, I encourage you to, uh, uh, look at this smart out paper that is referenced on the website for discourse. And, uh, just, uh, remember that, uh, these elastic deformations or any of the other kind of, uh, uh, transformations we can, uh, use to expand the Dataset is not actually just useful for neural networks, but really any system that is trainable, right? So that's it for a dataset expansion.