WEBVTT
Kind: captions
Language: en

00:00:00.740 --> 00:00:04.000
&gt;&gt; From the Library of
Congress in Washington D.C.

00:00:18.370 --> 00:00:21.750
&gt;&gt; So our next group of presenters
has been helping others work better

00:00:21.750 --> 00:00:23.890
by developing tools,
platforms and methods

00:00:23.890 --> 00:00:26.180
for making data collections
more accessible.

00:00:26.180 --> 00:00:27.890
Elizabeth Lorang has been working

00:00:27.890 --> 00:00:31.300
with the Chronicling America data
set demonstrating the potential

00:00:31.300 --> 00:00:34.870
for collections to hold not
just answers, but also methods

00:00:34.870 --> 00:00:37.340
for further research
returns for all.

00:00:37.340 --> 00:00:40.750 position:56%
An associate professor of humanities
and a humanities librarian

00:00:40.750 --> 00:00:42.900
at the University of
Nebraska Lincoln.

00:00:42.900 --> 00:00:46.050
She is also a faculty fellow
in the Center for Research

00:00:46.050 --> 00:00:48.860
for Digital Research in
the humanities at UNL.

00:00:48.860 --> 00:00:52.360
Her research areas include digital
humanities and digital scholarship,

00:00:52.360 --> 00:00:56.070
American poetry and 19th
century American newspapers.

00:00:56.070 --> 00:00:59.830
She is the Co-PI of image
analysis for archival discovery,

00:00:59.830 --> 00:01:04.330
an NEH funded project that seeks to
leverage the information potential

00:01:04.330 --> 00:01:07.910
of digital images for discovery
and digitized collections.

00:01:07.910 --> 00:01:10.320
Next we're here, sorry.

00:01:10.320 --> 00:01:13.780
Next we'll hear from Rickey
Punzalan, an assistant professor

00:01:13.780 --> 00:01:17.260
of archives and digital curation at
the College of Information Studies

00:01:17.260 --> 00:01:18.970
at the University of Maryland.

00:01:18.970 --> 00:01:21.160
His research includes
understanding the relationship

00:01:21.160 --> 00:01:23.150
of archives and collective memory.

00:01:23.150 --> 00:01:26.080
The dynamics of digitization
in decision making

00:01:26.080 --> 00:01:28.970
in collaborative settings,
and the uses and users

00:01:28.970 --> 00:01:31.440
of digitized archival images.

00:01:31.440 --> 00:01:34.560
He also examines virtual
reunification.

00:01:34.560 --> 00:01:37.300
A strategy to provide
integrated access

00:01:37.300 --> 00:01:40.590
to disperse ethnographic
archival images on line,

00:01:40.590 --> 00:01:42.590
which he will speak about today.

00:01:42.590 --> 00:01:45.520
Closing this session
is Mark Bouslog,

00:01:45.520 --> 00:01:48.730
a developer with Universe.org,
the world's largest platform

00:01:48.730 --> 00:01:50.700
for people powered research.

00:01:50.700 --> 00:01:53.210
Mark focuses on developing
user interfaces

00:01:53.210 --> 00:01:56.840
that accomplish research
previously considered impossible.

00:01:56.840 --> 00:01:58.700
Powered by Citizen
Science and Coffee,

00:01:58.700 --> 00:02:01.570
his recent work includes assisting
with the relaunch of Notes

00:02:01.570 --> 00:02:06.100 position:56%
From Nature, a project to transcribe
and digitize museum specimen labels.

00:02:06.100 --> 00:02:09.510
Let's get to work and
welcome Liz Lorang.

00:02:09.510 --> 00:02:14.500
[ Applause ]

00:02:21.040 --> 00:02:22.340
&gt;&gt; All right.

00:02:22.340 --> 00:02:23.640
Good morning everyone.

00:02:23.640 --> 00:02:26.200
I'd like to start by thanking
the organizers and our hosts

00:02:26.200 --> 00:02:29.180
for the invitation and the
opportunity to share my team's work

00:02:29.180 --> 00:02:32.510
with all of you as well
as the opportunity to hear

00:02:32.510 --> 00:02:34.630
about the projects that
you all are working on

00:02:34.630 --> 00:02:37.670
and then the conversations
that all of us can have

00:02:37.670 --> 00:02:39.100
over the course of the day.

00:02:39.100 --> 00:02:42.890
The project I'll be talking about
today has been possible only

00:02:42.890 --> 00:02:46.170
because of the contributions of
our research team past and present.

00:02:46.170 --> 00:02:49.230
So while I'm here presenting on
our work today, I want to be sure

00:02:49.230 --> 00:02:51.120
to acknowledge that research team.

00:02:51.120 --> 00:02:54.540
In particular I'd like to
acknowledge my colleague at UNL,

00:02:54.540 --> 00:02:57.280
Professor Lian Katso [SP] from
the Department of Computer Science

00:02:57.280 --> 00:03:00.860
and Engineering, as well as my
former undergraduate student,

00:03:00.860 --> 00:03:04.710
Grace Thomas who contributed early
on to this project in key ways.

00:03:04.710 --> 00:03:08.060
I couldn't be more delighted
that Grace is now on the staff

00:03:08.060 --> 00:03:10.280
of the Library of Congress
as a data specialist.

00:03:10.280 --> 00:03:12.960
She's been here for about
a month now and also

00:03:12.960 --> 00:03:15.320
that she's able to be here today.

00:03:15.320 --> 00:03:17.550
So my presentation
today is in three parts.

00:03:17.550 --> 00:03:21.920
First, a statement of a problem or
a challenge that I think we face

00:03:21.920 --> 00:03:23.570
in working with digital collections

00:03:23.570 --> 00:03:25.900
and in developing digital
collections.

00:03:25.900 --> 00:03:29.570
The second part is a discussion
of an experiment of sorts

00:03:29.570 --> 00:03:32.730
that my research team and I are
working on in order to attempt

00:03:32.730 --> 00:03:34.590
to address that challenge
in some way.

00:03:34.590 --> 00:03:37.850
And then the third part is a
look at the longer term and sort

00:03:37.850 --> 00:03:39.790
of where we're headed next.

00:03:39.790 --> 00:03:43.000
So the first part then
is this challenge

00:03:43.000 --> 00:03:46.170
and the fundamental challenge
that we're working to address is

00:03:46.170 --> 00:03:50.120 position:56%
that for all the wealth of digitized
primary materials now available,

00:03:50.120 --> 00:03:53.580
finding materials of relevance in
these collections remains difficult

00:03:53.580 --> 00:03:55.360
for all but the most
routine use cases.

00:03:55.360 --> 00:03:58.720
And this challenge is
documented most recently

00:03:58.720 --> 00:04:01.670
by Green and Courtney in 2015.

00:04:01.670 --> 00:04:04.390
And in their surveys and
interviews of scholars working

00:04:04.390 --> 00:04:08.560 position:56%
with digital collections of primary
materials the authors found that one

00:04:08.560 --> 00:04:11.740
of the most prominent challenges
cited by respondents in their use

00:04:11.740 --> 00:04:15.240
of digital collections was the
inability to search effectively

00:04:15.240 --> 00:04:16.920
through the collection materials.

00:04:16.920 --> 00:04:19.880
And these findings align with
those of some other studies

00:04:19.880 --> 00:04:23.420
over the last couple of years
that similarly show the difficulty

00:04:23.420 --> 00:04:26.170
of finding items of interest
in digital collections

00:04:26.170 --> 00:04:29.220
and also the degree to which
more fine grained level

00:04:29.220 --> 00:04:31.790
of descriptive detail
can be significant

00:04:31.790 --> 00:04:34.400
to successfully analyzing corpora.

00:04:34.400 --> 00:04:37.700
So my sense is that this
difficulty in finding materials

00:04:37.700 --> 00:04:42.810
of relevance arises in part from
one reason is the level and degree

00:04:42.810 --> 00:04:45.520
of description of items
in collections.

00:04:45.520 --> 00:04:48.840
But the difficulty of finding
materials of relevance is also due

00:04:48.840 --> 00:04:53.160
to the ways in which platforms and
interfaces shape engagement with

00:04:53.160 --> 00:04:56.880
and circumscribe access to
materials, including the primacy

00:04:56.880 --> 00:05:00.180
of text based searching and
barriers to bulk access.

00:05:00.180 --> 00:05:03.400
Because even when there's an API
for most people, that's still going

00:05:03.400 --> 00:05:05.910
to be a barrier to
access of some sort.

00:05:05.910 --> 00:05:08.680
So addressing this challenge
of connecting people with items

00:05:08.680 --> 00:05:10.660
of interest is going
to require efforts

00:05:10.660 --> 00:05:14.050
on multiple and creative fronts.

00:05:14.050 --> 00:05:18.070
In response to this challenge
my team, the image analysis

00:05:18.070 --> 00:05:22.210
for archival discovery team is
focusing on the digital images

00:05:22.210 --> 00:05:25.990
and collections rather than
on machine readable text.

00:05:25.990 --> 00:05:27.960
Our work starts from
two beliefs and takes

00:05:27.960 --> 00:05:29.880
up two questions at this point.

00:05:29.880 --> 00:05:32.610
The first belief is that
locating relevant materials

00:05:32.610 --> 00:05:35.970
and digital collections is
already often a difficult endeavor

00:05:35.970 --> 00:05:39.370
and will become increasingly so
as more content is digitized.

00:05:39.370 --> 00:05:43.410
And second that we leverage little
of the information potential

00:05:43.410 --> 00:05:45.460
of the millions of
images that we're creating

00:05:45.460 --> 00:05:47.710
as we digitize the cultural record.

00:05:47.710 --> 00:05:49.540
So we're asking two questions.

00:05:49.540 --> 00:05:52.040
What more can we do with
those millions of images

00:05:52.040 --> 00:05:54.590
that represent the
digitized cultural record?

00:05:54.590 --> 00:05:57.080
And what kinds of discovery
might serious attention

00:05:57.080 --> 00:05:59.250
to these digital images yield?

00:05:59.250 --> 00:06:03.430
Now both academic and industry
sectors are increasingly interested

00:06:03.430 --> 00:06:07.850
in image based methods for
identification and discovery.

00:06:07.850 --> 00:06:11.060
One significant area of
development is an image recognition

00:06:11.060 --> 00:06:15.020
and image searching of primarily
visual works, including artwork

00:06:15.020 --> 00:06:17.960
and contemporary mass
photography, such as photos posted

00:06:17.960 --> 00:06:20.170
to various online platforms.

00:06:20.170 --> 00:06:23.250
There is an increasing array of
computer vision software designed

00:06:23.250 --> 00:06:27.110
for such applications that are
in use in academia and industry.

00:06:27.110 --> 00:06:30.740
The emphasis, however, is very
much on images of artwork or images

00:06:30.740 --> 00:06:34.110
of contemporary photography
or images of items

00:06:34.110 --> 00:06:38.040
that we understand first and
foremost to be visual works.

00:06:38.040 --> 00:06:42.280
So as my team engages with these
questions, we're interested

00:06:42.280 --> 00:06:46.720
in turning the focus to image
analysis of textual materials.

00:06:46.720 --> 00:06:50.170
So looking at the digital
images of textural materials.

00:06:50.170 --> 00:06:53.320
To return to the title of my
presentation, we're interested

00:06:53.320 --> 00:06:56.960
in what happens when we
look at text as image.

00:06:56.960 --> 00:07:00.710
So there's a series of four slides
that attempt in a very crude

00:07:00.710 --> 00:07:03.850
and unsophisticated fashion
to illustrate the differences

00:07:03.850 --> 00:07:07.550
between where we are with computer
vision in contemporary photography

00:07:07.550 --> 00:07:09.410
versus computer vision
for the purposes

00:07:09.410 --> 00:07:11.210
of archival description
and discovery.

00:07:11.210 --> 00:07:16.750
So the first example is an image
of a slough that I uploaded

00:07:16.750 --> 00:07:19.360
to Google image search just
to see what I would get.

00:07:19.360 --> 00:07:24.300 position:56%
And not only were the search results
pretty highly matched to the image,

00:07:24.300 --> 00:07:26.190
but there was also a
sense like Google knew

00:07:26.190 --> 00:07:29.370
that what I was interested not
only was a sloth but a cute slough.

00:07:29.370 --> 00:07:33.980 position:56%
[laughs] And for me this is like the
best case scenario for image search.

00:07:33.980 --> 00:07:36.330
I didn't have to wade through
lots of other kinds of sloughs.

00:07:36.330 --> 00:07:38.420
I got right to the cute sloughs.

00:07:38.420 --> 00:07:43.810
So if we contrast that with an
image of a 19th century letter.

00:07:43.810 --> 00:07:45.860
They went through a similar process

00:07:45.860 --> 00:07:49.990
and the results I think
are a little more varied.

00:07:49.990 --> 00:07:54.190
The images look kind of like
the image that I presented,

00:07:54.190 --> 00:07:58.850 position:56%
but the sense of what I'm interested
in at this point is being treated

00:07:58.850 --> 00:08:00.200
as items that are handwritten.

00:08:00.200 --> 00:08:03.810
And we can start to see some real
potential for that to be able

00:08:03.810 --> 00:08:06.740
within a collection to pull out
the items that are handwritten.

00:08:06.740 --> 00:08:09.520
But what if I'm interested in
certain types of handwritten items

00:08:09.520 --> 00:08:11.390
that haven't been described?

00:08:11.390 --> 00:08:14.550
Here's an example quickly
of a newspaper.

00:08:14.550 --> 00:08:18.850
In this case, again, the
recognition was pretty good.

00:08:18.850 --> 00:08:21.050
I think in large part due
to the fact that we have

00:08:21.050 --> 00:08:25.430
so many digitized newspapers
and digitized for microfilm.

00:08:25.430 --> 00:08:29.250
But I want to look at this
fourth example, which is a poem

00:08:29.250 --> 00:08:33.060
that I've cropped from a newspaper
image and now I wasn't expecting

00:08:33.060 --> 00:08:36.140
to find lots of other
cropped newspaper poems.

00:08:36.140 --> 00:08:39.310
Probably because I'm one of the
few people who actually does that.

00:08:39.310 --> 00:08:44.420
There's not a huge corpus of them
at this point, but there starts

00:08:44.420 --> 00:08:47.740
to be a pretty wide gulf here
between what is in my image

00:08:47.740 --> 00:08:50.860
and the sorts of things that I
would think would be of interest

00:08:50.860 --> 00:08:53.570
and what is being suggested
as possible results.

00:08:53.570 --> 00:08:56.350
First and foremost,
this is recognized

00:08:56.350 --> 00:08:59.540
by the Google image search at
this point as me being interested

00:08:59.540 --> 00:09:02.820
in handwriting, which is very
clearly not the case here.

00:09:02.820 --> 00:09:07.600 position:56%
And also while I wasn't expecting
to find poems in newspapers returned

00:09:07.600 --> 00:09:08.990
as the result, I was sort

00:09:08.990 --> 00:09:11.590
of thinking maybe there would
be some printed poems right.

00:09:11.590 --> 00:09:16.980
So again sort of the range and
the gulf of the effectiveness

00:09:16.980 --> 00:09:19.960
of these sorts of searches
thus far from something

00:09:19.960 --> 00:09:23.320
like contemporary photography to
wanting to find specific types

00:09:23.320 --> 00:09:26.220
of items within digitized
collections.

00:09:26.220 --> 00:09:29.050
There is though an emerging
body of work in the arts

00:09:29.050 --> 00:09:31.590
and humanities interested
in the visual signals

00:09:31.590 --> 00:09:34.480
or visual analytics
of textual materials.

00:09:34.480 --> 00:09:38.530
Recently the visual page research
team has analyzed visual features

00:09:38.530 --> 00:09:41.150
of features of books
of poetry in order

00:09:41.150 --> 00:09:44.070
to explore visual meaning
in those print pages.

00:09:44.070 --> 00:09:47.700
And in a similar vein the
shapes view or at Bloodaxe,

00:09:47.700 --> 00:09:52.100
the poetics of the archive allows
users to explore its archive

00:09:52.100 --> 00:09:54.140
by drawing the shape of a poem.

00:09:54.140 --> 00:09:57.380
And the search then returns
poems of similar shapes.

00:09:57.380 --> 00:09:59.760
And Bloodaxe demonstrates
the potential of thinking

00:09:59.760 --> 00:10:03.680
about textual materials visually
particularly the visual is part

00:10:03.680 --> 00:10:06.020
of the meaning making of the text.

00:10:06.020 --> 00:10:07.460
Both of these projects, however,

00:10:07.460 --> 00:10:12.240 position:56%
begin with a known pre-selected
items from relatively small corpora.

00:10:12.240 --> 00:10:15.710
So they're starting when we already
know what we have here is an item

00:10:15.710 --> 00:10:17.010
of interest.

00:10:17.010 --> 00:10:20.090
So my team and I are extending
visual analysis approaches

00:10:20.090 --> 00:10:22.670
for the purposes of
identification and discovery.

00:10:22.670 --> 00:10:27.280 position:56%
And this takes us to part two of my
presentation, sort of the experiment

00:10:27.280 --> 00:10:29.580
that we're currently working on.

00:10:29.580 --> 00:10:34.330
So our work now looks at whether
we can identify poetic content

00:10:34.330 --> 00:10:37.970
in historic newspapers based
only on visual signals.

00:10:37.970 --> 00:10:40.680
We're using the chronicling
America collection of newspapers

00:10:40.680 --> 00:10:43.760
as our corpus and given
a newspaper page image

00:10:43.760 --> 00:10:46.760
from chronicling America we
want to be able to say whether

00:10:46.760 --> 00:10:49.340
or not the page features
any poetic content.

00:10:49.340 --> 00:10:52.520
And ultimately where the
poetic content is on the page.

00:10:52.520 --> 00:10:55.460
So we've been ambitious in
our goal seeking to identify

00:10:55.460 --> 00:10:59.640 position:56%
as little poetic content as a single
couplet quoted in a news article

00:10:59.640 --> 00:11:03.860
to finding pages with single or
even multiple full length poems.

00:11:03.860 --> 00:11:07.350
To do this work, we've created
a machine learning classifier

00:11:07.350 --> 00:11:09.690
to distinguish between
images from newspapers

00:11:09.690 --> 00:11:12.520
that feature poetic content
and those that do not.

00:11:12.520 --> 00:11:14.990
And this required determining
the visual qualities

00:11:14.990 --> 00:11:17.010
that we believe are
important to identifying

00:11:17.010 --> 00:11:20.720
or distinguishing poetic content,
translating those visual qualities

00:11:20.720 --> 00:11:24.300
into measurable features,
developing algorithms to measure

00:11:24.300 --> 00:11:27.780
than those features,
assembling a set of sample images

00:11:27.780 --> 00:11:29.860
where we knew the ground
truth, whether

00:11:29.860 --> 00:11:33.270
or not the image contained
poetic content or not,

00:11:33.270 --> 00:11:36.110
compiling the feature measurements
for both sets of images,

00:11:36.110 --> 00:11:40.910
and feeding those values
along with the images status

00:11:40.910 --> 00:11:42.550
into an artificial neural network

00:11:42.550 --> 00:11:46.190 position:56%
to help the system learn what values
tend to signal poetic content.

00:11:46.190 --> 00:11:49.930
And then finally, testing the
classifier on unlabeled images.

00:11:49.930 --> 00:11:54.170
We published early results of this
work in D Live Magazine last summer

00:11:54.170 --> 00:11:58.370 position:56%
and at the classifier training stage
we achieved precision and recall

00:11:58.370 --> 00:12:02.030
of just under 91% and 80%

00:12:02.030 --> 00:12:05.460
where precision measures how many
times we were correct whenever we

00:12:05.460 --> 00:12:08.380
predicted an image
contain poetic content

00:12:08.380 --> 00:12:12.660
and recall was measuring how many
times we correctly identified poem

00:12:12.660 --> 00:12:14.900
images out of all poem images.

00:12:14.900 --> 00:12:18.780
Now these numbers dropped when
we tested the classifier to just

00:12:18.780 --> 00:12:24.080
under 75% and 62%, but they weren't
on the less encouraging enough

00:12:24.080 --> 00:12:27.050
that we decided to
undertake a larger case study.

00:12:27.050 --> 00:12:29.870
We did not want to over fit our
approach for such a small set

00:12:29.870 --> 00:12:33.640
of page images that we had
used for this initial test.

00:12:33.640 --> 00:12:37.510 position:56%
And so at this point we know we have
more work to do, but we didn't want

00:12:37.510 --> 00:12:40.180
that work to reflect only
this very small sample.

00:12:40.180 --> 00:12:45.730 position:56%
So we've recently undertaken work to
look at a much larger set of images.

00:12:45.730 --> 00:12:47.960
Specifically we moved
to a case study

00:12:47.960 --> 00:12:52.720
of chronicling America's
newspaper pages from 1836 to 1840.

00:12:52.720 --> 00:12:54.610
For this work we have two goals.

00:12:54.610 --> 00:12:56.030
One is to scale the system.

00:12:56.030 --> 00:12:59.510
And the second is to test
and analyze the accuracy

00:12:59.510 --> 00:13:02.500
of the classifier on a
much larger set of data.

00:13:02.500 --> 00:13:06.260
We focused on the five
year period 1836 to 1840,

00:13:06.260 --> 00:13:07.870
because at the time we started it,

00:13:07.870 --> 00:13:10.150
it represented the
first five years worth

00:13:10.150 --> 00:13:11.680
of content in chronicling America.

00:13:11.680 --> 00:13:15.020
And we knew that we could expect
to find a significant amount

00:13:15.020 --> 00:13:18.790
of poetic content in
newspapers from this period.

00:13:18.790 --> 00:13:21.430
The first step in the process
was to develop a script

00:13:21.430 --> 00:13:23.850
for batch retrieving images
from chronicling America.

00:13:23.850 --> 00:13:27.950
And we now have a script that
allows us to retrieve images based

00:13:27.950 --> 00:13:31.390
on we're working primarily with
date parameters at this point.

00:13:31.390 --> 00:13:33.830
But in the future will likely
add some additional parameters,

00:13:33.830 --> 00:13:36.880
as well such as by
newspaper or by state.

00:13:36.880 --> 00:13:40.670
For the current study we
retrieved nearly 22,000 images.

00:13:40.670 --> 00:13:44.930
What was it at that time all
page images from 1836 to 1840

00:13:44.930 --> 00:13:48.370
that chronicling America is growing
at a really tremendous rate now,

00:13:48.370 --> 00:13:51.050
so our numbers are - so we're
now already only working

00:13:51.050 --> 00:13:53.240
with a subset of those five years.

00:13:53.240 --> 00:13:56.900
Getting the page images was
the most straightforward part,

00:13:56.900 --> 00:13:59.520
though it was not without
some complication.

00:13:59.520 --> 00:14:02.020
Importantly, the system
we've developed for measuring

00:14:02.020 --> 00:14:03.320
and evaluating features, though,

00:14:03.320 --> 00:14:06.390
doesn't actually process
the entire pages at once.

00:14:06.390 --> 00:14:10.740
Instead we process the full page
image as overlapping image snippets

00:14:10.740 --> 00:14:13.470
and look to see whether
any of those image snippets

00:14:13.470 --> 00:14:15.610 position:56%
from the page contain poetic content

00:14:15.610 --> 00:14:18.090
or features signaling
poetic content.

00:14:18.090 --> 00:14:21.700
So in the earlier stage we created
those image snippets manually,

00:14:21.700 --> 00:14:25.230 position:56%
but we've now needed an automated
approach to this process and we need

00:14:25.230 --> 00:14:28.540
to be sure that the image snippets
themselves are good in order

00:14:28.540 --> 00:14:34.160
to increase the chance that we
will have accurate classifications.

00:14:34.160 --> 00:14:38.590
So we developed a process for
evaluating all of the page images

00:14:38.590 --> 00:14:41.160
to see if they could be
effectively segmented

00:14:41.160 --> 00:14:44.190
and checked each page image
against several set of rules.

00:14:44.190 --> 00:14:48.480
And this was something we did
automatically and then broke each

00:14:48.480 --> 00:14:52.030
of the pages that passed
into the subsequent snippets.

00:14:52.030 --> 00:14:56.640
So approximately 8800 page images
past the segmentation process

00:14:56.640 --> 00:15:00.080
and yielded 509,000 image snippets.

00:15:00.080 --> 00:15:02.360
In each of these snippets
then undergoes a series

00:15:02.360 --> 00:15:05.890
of processes represented by
those images on the screen

00:15:05.890 --> 00:15:08.630
and we capture the images
at three different stages.

00:15:08.630 --> 00:15:10.820
And those are what we use
to measure the features

00:15:10.820 --> 00:15:13.060
and do the feature extraction.

00:15:13.060 --> 00:15:15.900
So this work is still
very much in process,

00:15:15.900 --> 00:15:19.050
and while we don't have
big results just yet,

00:15:19.050 --> 00:15:21.130
hopefully we will by
the end of October.

00:15:21.130 --> 00:15:23.670
We do know a few things
at this point.

00:15:23.670 --> 00:15:27.120
First is that we've learned about
both historic newspaper pages

00:15:27.120 --> 00:15:30.660
as well as about the duplicate of
processes that have brought them

00:15:30.660 --> 00:15:32.750
to us in chronicling America.

00:15:32.750 --> 00:15:36.560
A variety of factors affect whether
or not a page can be segmented.

00:15:36.560 --> 00:15:40.580
These include contrast ratios,
the presence of a number

00:15:40.580 --> 00:15:43.070
of illustrations or
the presence of text

00:15:43.070 --> 00:15:45.120 position:56%
or images spanning multiple columns,

00:15:45.120 --> 00:15:48.040
and noise in the microfilmed
or digitized image.

00:15:48.040 --> 00:15:53.660
Second is that since we know that
we want to know at a high level

00:15:53.660 --> 00:15:56.100
of accuracy how good
our classifier is,

00:15:56.100 --> 00:15:59.660 position:56%
so we need to know the ground truth
of the page images and the snippets.

00:15:59.660 --> 00:16:01.250
We could have done some sampling,

00:16:01.250 --> 00:16:05.090
but at this stage this is very
much a research project and we want

00:16:05.090 --> 00:16:09.740
to know at a very accurate level
how accurate the classifier is.

00:16:09.740 --> 00:16:13.300 position:56%
This has meant that I have
manually classified those 8800 pages

00:16:13.300 --> 00:16:17.200
so that we can check the
machine classification.

00:16:17.200 --> 00:16:20.610 position:56%
According to the manual
classifications, the work that I did

00:16:20.610 --> 00:16:25.990
of those 8800 pages that
passed segmentation 1,678

00:16:25.990 --> 00:16:31.280
of them contain poetic content
while just over 7,000 dud not.

00:16:31.280 --> 00:16:34.520
But according to our machine
learning classification,

00:16:34.520 --> 00:16:36.840
again which is classifying
at the snippet level,

00:16:36.840 --> 00:16:40.010
but we can extract the
page metrics from that.

00:16:40.010 --> 00:16:42.310
So the machine learning
classification suggests

00:16:42.310 --> 00:16:46.290
that there were 4,440 pages
containing poetic content,

00:16:46.290 --> 00:16:50.120
which of course is much higher than
my classification and even more

00:16:50.120 --> 00:16:53.870
than that, when I compared
my classification

00:16:53.870 --> 00:16:57.120
with the machine learning
classification we overlapped only

00:16:57.120 --> 00:16:58.970
on 785 pages.

00:16:58.970 --> 00:17:04.300
So we know that we have work to do
here and where we're headed next is

00:17:04.300 --> 00:17:07.300
to do - so first so we need
to then be able to look

00:17:07.300 --> 00:17:12.300 position:56%
at the snippet level, which means
I'm evaluating those 90,000 snippets

00:17:12.300 --> 00:17:16.090 position:56%
to determine their classification so
we can really do a detailed analysis

00:17:16.090 --> 00:17:22.740
on where my classification and
the machine's classification agree

00:17:22.740 --> 00:17:26.880 position:56%
and where they differ and then start
pulling some things out from that.

00:17:26.880 --> 00:17:30.350
So this is why it slowed down
a little bit at this stage.

00:17:30.350 --> 00:17:32.470
But once we have the
manual classification

00:17:32.470 --> 00:17:34.910
and the machine classification
we'll begin the work

00:17:34.910 --> 00:17:37.750
of deriving detailed statistics
and thinking about the ways

00:17:37.750 --> 00:17:41.230
in which we can further
improve the classifier.

00:17:41.230 --> 00:17:44.760
And so that might be techniques
to make sure that we're not quite

00:17:44.760 --> 00:17:48.200
as aggressive in returning
snippets as truth.

00:17:48.200 --> 00:17:49.830
We can look for over see only

00:17:49.830 --> 00:17:54.310
if concurrent snippets are
classified as true, for example.

00:17:54.310 --> 00:17:57.430
and then we'll have to see
though how accurate are features

00:17:57.430 --> 00:17:58.730
that we think are important

00:17:58.730 --> 00:18:01.910
for signaling poetic
content turn out to be.

00:18:01.910 --> 00:18:07.510
So we'll be turning to an
understanding of what we get

00:18:07.510 --> 00:18:08.940
from our classifier results.

00:18:08.940 --> 00:18:13.070
We will be analyzing the data
sets, doing some written analysis,

00:18:13.070 --> 00:18:19.350
and doing an early stage look at
how our classifications for length

00:18:19.350 --> 00:18:22.790
for newspaper content in languages
other than English compare

00:18:22.790 --> 00:18:25.790
with our classifications
of newspapers in English.

00:18:25.790 --> 00:18:30.390 position:56%
Since the 1836 to 1840 set
includes some newspapers in Spanish,

00:18:30.390 --> 00:18:34.780
we can start testing this idea
that an image based approach

00:18:34.780 --> 00:18:39.100
for textual materials
should be language agnostic.

00:18:39.100 --> 00:18:43.800
Okay. So in the longer term
then and I'll hear both.

00:18:43.800 --> 00:18:47.380
So when I created these slides
last week I felt compelled to talk

00:18:47.380 --> 00:18:50.560
in fairly broad terms, but
only yesterday I learned

00:18:50.560 --> 00:18:53.890 position:56%
that our research team has
received IMLS research grant funding

00:18:53.890 --> 00:18:57.620
to continue our work, and we
have a sure course for that work.

00:18:57.620 --> 00:19:00.820 position:56%
We're embarking on a new partnership
with colleagues at the University

00:19:00.820 --> 00:19:03.870
of Virginia with whom we
seek to extend our software

00:19:03.870 --> 00:19:06.570
across a more diverse range
of digitized newspapers

00:19:06.570 --> 00:19:10.800 position:56%
and textual forms, and to assess the
broader potential of image analysis

00:19:10.800 --> 00:19:14.180
as a methodology for image
classification identification

00:19:14.180 --> 00:19:17.250
discovery and retrieval
and digital libraries.

00:19:17.250 --> 00:19:20.270 position:56%
Given the visual distinctiveness and
poetry in the immediate potential

00:19:20.270 --> 00:19:22.900
for scholarly impact, we
seek to refine our methods

00:19:22.900 --> 00:19:28.400
on poetic content, but now
also to a number of boundaries,

00:19:28.400 --> 00:19:30.780
including geographic,
temporal and linguistic.

00:19:30.780 --> 00:19:35.170
And I can say more about the work
that we're interested in doing

00:19:35.170 --> 00:19:38.130
in the course of that
grant, but our hope is

00:19:38.130 --> 00:19:41.010
that this work ultimately will
affect how we develop digital

00:19:41.010 --> 00:19:44.730
collections, both prerelease and
post-release of the collection.

00:19:44.730 --> 00:19:48.060
We seek to develop new strategies
and workflows for librarians

00:19:48.060 --> 00:19:50.820
and archivists to identify
and classify materials

00:19:50.820 --> 00:19:54.430
and to facilitate researchers
abilities to pose new questions

00:19:54.430 --> 00:19:56.160
of digitized collections.

00:19:56.160 --> 00:19:58.900
Ultimately we hope this
work might also materialize

00:19:58.900 --> 00:20:03.020
and more creative interfaces such
as that on the Bloodaxe archive

00:20:03.020 --> 00:20:04.760
that allow users to
query collections

00:20:04.760 --> 00:20:06.760 position:56%
in ways beyond the text based search

00:20:06.760 --> 00:20:09.060
or browsing conventional
organizational schemes

00:20:09.060 --> 00:20:10.360
such as date and publication.

00:20:10.360 --> 00:20:14.080
Before we can get to
those interfaces, however,

00:20:14.080 --> 00:20:17.190
we both need to create the
underlying data as well

00:20:17.190 --> 00:20:19.990
as broaden our sense of what's
possible with the collections

00:20:19.990 --> 00:20:24.020
that we build and this will require
us to work with both text and image

00:20:24.020 --> 00:20:27.020
as well as to see text as image.

00:20:27.020 --> 00:20:28.820
Thank you.

00:20:28.820 --> 00:20:36.500
[ Applause ]

00:21:01.050 --> 00:21:02.350
&gt;&gt; Okay, good.

00:21:02.350 --> 00:21:03.650
Hello everybody.

00:21:03.650 --> 00:21:04.950
I really appreciate being here.

00:21:04.950 --> 00:21:07.840
You know, I'm one of those people

00:21:07.840 --> 00:21:11.440
who were basically a
librarian through and through.

00:21:11.440 --> 00:21:13.790
I have a bachelor in
library science,

00:21:13.790 --> 00:21:17.300
so meaning at 18 years old I
decided to become a librarian.

00:21:17.300 --> 00:21:21.140
So [laughs] being at the Library
of Congress and, you know,

00:21:21.140 --> 00:21:25.740 position:56%
speaking here is I mean I'm from the
Philippines, so it's such a big deal

00:21:25.740 --> 00:21:28.400
to be here so if there's
anyone watching.

00:21:28.400 --> 00:21:30.030
Yeah, I'm here.

00:21:30.030 --> 00:21:33.510
And it's awesome.

00:21:33.510 --> 00:21:38.260
[ Clapping ]

00:21:38.260 --> 00:21:39.650
Okay, enough about me.

00:21:39.650 --> 00:21:42.090
Let's talk about virtual
reunification,

00:21:42.090 --> 00:21:43.500
which is one of my passions.

00:21:43.500 --> 00:21:48.690
So first I'd like to promise this
conversation by talking about,

00:21:48.690 --> 00:21:53.670 position:56%
you know, that digitization has
become a fundamental responsibility.

00:21:53.670 --> 00:21:57.980
I mean when I say this occasionally
I'll get some nasty looks

00:21:57.980 --> 00:22:00.920
from other people, because they
don't appreciate this idea.

00:22:00.920 --> 00:22:02.570
But, you know, we have to wake up.

00:22:02.570 --> 00:22:06.820
This is - institutions are
expected to be doing digitization.

00:22:06.820 --> 00:22:10.870
I know that there are resource
disparities, but, you know,

00:22:10.870 --> 00:22:13.670
I teach introduction to
archives and I'm now expected

00:22:13.670 --> 00:22:18.230
to teach my students in
putting digitization a spark

00:22:18.230 --> 00:22:19.530
of archival practice.

00:22:19.530 --> 00:22:23.920
So this is part of our
realities right now

00:22:23.920 --> 00:22:26.760
as cultural heritage institutions.

00:22:26.760 --> 00:22:30.510
With digitization we
facilitate discovery.

00:22:30.510 --> 00:22:34.240
In fact, there are
studies that indicate

00:22:34.240 --> 00:22:40.470
that having digital surrogate will
help institutions discover the

00:22:40.470 --> 00:22:43.090
actual artifact, will
also bring people

00:22:43.090 --> 00:22:46.140
to use collections more broadly.

00:22:46.140 --> 00:22:49.370
We are redefining relationships
with our patrons

00:22:49.370 --> 00:22:53.480
by providing digital products.

00:22:53.480 --> 00:22:58.080
We are rethinking our work
as heritage institutions

00:22:58.080 --> 00:23:00.690
and it also redefines what it means

00:23:00.690 --> 00:23:04.490
to perform library
archives and museum work.

00:23:04.490 --> 00:23:09.760
And it's also this
conversation of color convergence

00:23:09.760 --> 00:23:14.100
and collaboration has been
happening even before digitization.

00:23:14.100 --> 00:23:18.150
But I think digitization
is one way to ensure

00:23:18.150 --> 00:23:21.850
that institutions are
truly collaborating

00:23:21.850 --> 00:23:25.090
by sharing resources and expertise.

00:23:25.090 --> 00:23:30.100
So the way we've handled
dispersed collections

00:23:30.100 --> 00:23:32.070
in the archival community
in the past is

00:23:32.070 --> 00:23:34.350
that first we acknowledge them

00:23:34.350 --> 00:23:38.640
in our finding a saying you know
this collection is also found

00:23:38.640 --> 00:23:42.400
in five other institutions
sometimes we're comprehensive,

00:23:42.400 --> 00:23:44.190
sometimes we're not.

00:23:44.190 --> 00:23:51.120
Another thing at the theoretical
level we've tried to expand notions

00:23:51.120 --> 00:23:53.330
of provenance ownership
and what it means

00:23:53.330 --> 00:23:56.450
to have records in our custodies.

00:23:56.450 --> 00:24:03.480
And finally, we are using technical
standards and tools in reconnecting

00:24:03.480 --> 00:24:05.610
and linking collections together.

00:24:05.610 --> 00:24:10.890
Here's one quote from
2001 by Jeanette Bastian.

00:24:10.890 --> 00:24:15.230
She says "Standards such as
EAD now offer the potential

00:24:15.230 --> 00:24:17.530
of virtually reuniting
fragmented collections

00:24:17.530 --> 00:24:19.840
and relating distributed
collections through the

00:24:19.840 --> 00:24:21.890
on line linking of finding aids."

00:24:21.890 --> 00:24:25.880
And she's talking about this
in the context of the records

00:24:25.880 --> 00:24:28.720
of the U.S. Virgin Islands.

00:24:28.720 --> 00:24:34.120
So move to more contemporary
times we hear the term

00:24:34.120 --> 00:24:37.180
"virtual reunification,"
which is, you know,

00:24:37.180 --> 00:24:42.240
a very short definition would be
allowing dispersed collections

00:24:42.240 --> 00:24:43.630
to be brought together.

00:24:43.630 --> 00:24:45.870
It's a highly collaborative
endeavor.

00:24:45.870 --> 00:24:51.220
Okay. It will involve multiple
institutions, multiple scholars

00:24:51.220 --> 00:24:54.610
in various disciplines,
and multiple expertise

00:24:54.610 --> 00:24:57.400
within cultural heritage work.

00:24:57.400 --> 00:25:01.390
It harnesses the (inaudible)
of the digital.

00:25:01.390 --> 00:25:04.790
The problem with many
dispersed collections is

00:25:04.790 --> 00:25:08.620
that it's almost entirely
impossible to reunite them

00:25:08.620 --> 00:25:10.960
in their physical formats,
because one,

00:25:10.960 --> 00:25:15.430
you encounter geographic
limitations,

00:25:15.430 --> 00:25:18.380
things are in far places.

00:25:18.380 --> 00:25:23.100
Physically sometimes materials
are, you know, in different formats

00:25:23.100 --> 00:25:25.340
that are quite challenging
to be brought together

00:25:25.340 --> 00:25:29.060
in their physical form since they
say that finally with, you know,

00:25:29.060 --> 00:25:31.670
digital surrogates we can
bring things together.

00:25:31.670 --> 00:25:36.030
It also facilitates cultural
diplomacy in some projects

00:25:36.030 --> 00:25:40.630
of virtual reunification
projects in Europe, for instance.

00:25:40.630 --> 00:25:45.010
You know, it involves
multiple institutional

00:25:45.010 --> 00:25:47.780
or national institutions.

00:25:47.780 --> 00:25:54.050
Here's some examples of
virtual reunification projects

00:25:54.050 --> 00:25:58.680
that there's many out
there, but these are some.

00:25:58.680 --> 00:26:01.380
My favorites is the
Walt Whitman Archive

00:26:01.380 --> 00:26:03.500
and I'm sure it's familiar to many.

00:26:03.500 --> 00:26:10.240
It brings, you know, the work of
one person and also, you know,

00:26:10.240 --> 00:26:13.830
from various institutions and
trying to do multiple ways

00:26:13.830 --> 00:26:19.020
of engaging with the material.

00:26:19.020 --> 00:26:21.770
Reunification or bringing
together the whole

00:26:21.770 --> 00:26:28.290
of collections has its deep
roots in the analog world,

00:26:28.290 --> 00:26:30.360
specifically in the humanities.

00:26:30.360 --> 00:26:35.010 position:56%
So, you know, in art history there's
such a thing as catalog [inaudible]

00:26:35.010 --> 00:26:38.740
or in music complete works

00:26:38.740 --> 00:26:42.740
or in literature you have
critical or scholarly editions.

00:26:42.740 --> 00:26:47.820
And in history we have
or which is more related

00:26:47.820 --> 00:26:50.470
to archival work historical
editions.

00:26:50.470 --> 00:26:52.820
So, you know, you have
historians going

00:26:52.820 --> 00:26:59.850
through different repositories
trying to collect all writings

00:26:59.850 --> 00:27:01.470
of Thomas Jefferson, for instance.

00:27:01.470 --> 00:27:07.230
So there's a long scholarly
trajectory

00:27:07.230 --> 00:27:09.540
in bringing together collections.

00:27:09.540 --> 00:27:14.290
What I've noticed about virtual
reunification is that there's lack

00:27:14.290 --> 00:27:17.680
of attention to photographic
materials.

00:27:17.680 --> 00:27:19.640 position:56%
There are projects out there looking

00:27:19.640 --> 00:27:25.400
at image processing and
pattern recognition.

00:27:25.400 --> 00:27:29.560
There are projects that, you
know, would exhibit photographs

00:27:29.560 --> 00:27:32.680
for instance, but they're
not at the particular scale

00:27:32.680 --> 00:27:36.990
where you have them
from all over the place.

00:27:36.990 --> 00:27:40.500
Different institutions, multiple
stakeholders, and just truly,

00:27:40.500 --> 00:27:47.440 position:56%
you know, bringing them and doing
scholarly work with those materials.

00:27:47.440 --> 00:27:52.420
It's also touted as a
way to do repatriation,

00:27:52.420 --> 00:27:59.060 position:56%
meaning returning collections to
source communities by digital means.

00:27:59.060 --> 00:28:03.100
But there's no clear explanation
of what it really truly means

00:28:03.100 --> 00:28:06.590
to return something that's digital.

00:28:06.590 --> 00:28:09.700
More on success, but
less on barriers.

00:28:09.700 --> 00:28:11.140
When I read the literature

00:28:11.140 --> 00:28:15.830
on this subject people are still
laboratory saying, yea we did it.

00:28:15.830 --> 00:28:17.130
It's difficult.

00:28:17.130 --> 00:28:19.200
Congratulations to us
because we've done it.

00:28:19.200 --> 00:28:24.230
But actually we learn from
barriers from projects that tell us

00:28:24.230 --> 00:28:27.220
that these are the problems
that we've encountered.

00:28:27.220 --> 00:28:31.330
So that when we do it again,
we know things to expect.

00:28:31.330 --> 00:28:36.630
And also it's unclear about inter
institutional collaboration.

00:28:36.630 --> 00:28:40.100
When ten institutions
are involved and one

00:28:40.100 --> 00:28:46.540
of those is let's say a historical
society and in one county

00:28:46.540 --> 00:28:50.850
versus the Smithsonian, there's
an imbalance in terms of resources

00:28:50.850 --> 00:28:53.300
and prestige in that project.

00:28:53.300 --> 00:28:58.560
So there's a lot to, you know, be
done and discussed in this area.

00:28:58.560 --> 00:29:05.070
And in the world of digital
repatriation, anthropologists

00:29:05.070 --> 00:29:11.140
and people who study digital
repatriation have acknowledged

00:29:11.140 --> 00:29:18.120
that there's some problem around
the notion of returning copies

00:29:18.120 --> 00:29:22.110
of artifacts to Native
American communities.

00:29:22.110 --> 00:29:24.110
Is it really return?

00:29:24.110 --> 00:29:27.460
Is it really repatriation
if you're providing copies,

00:29:27.460 --> 00:29:31.050
no matter how good the
resolution might be?

00:29:31.050 --> 00:29:32.350
But at the same time,

00:29:32.350 --> 00:29:38.280
not all communities want the actual
artifacts to be returned to them,

00:29:38.280 --> 00:29:42.730
that many communities are
quite happy with, you know,

00:29:42.730 --> 00:29:46.000
digital surrogates that they
can use in the classrooms

00:29:46.000 --> 00:29:47.300
and in their communities.

00:29:47.300 --> 00:29:52.140
So there's really not one
solution to this issue.

00:29:52.140 --> 00:29:59.070 position:56%
And, you know, where does the return
happen and for whom is it done?

00:29:59.070 --> 00:30:00.370
Is it for the institution?

00:30:00.370 --> 00:30:03.690 position:56%
Is it for the community or is it for
the scholar facilitating the return?

00:30:03.690 --> 00:30:11.750 position:56%
So my project looked at the
photographs taken in the Philippines

00:30:11.750 --> 00:30:17.820
in the early 1900s by colonial
administrator that was assigned

00:30:17.820 --> 00:30:19.810
in the Philippines, Dean Wooster.

00:30:19.810 --> 00:30:23.180
He was a zoologist and
because of his interest

00:30:23.180 --> 00:30:26.770
in zoology he started going
around the Philippines

00:30:26.770 --> 00:30:31.190
to document the different
indigenous groups of the country

00:30:31.190 --> 00:30:40.370
and in the process managed to amass
a cache of photographic materials.

00:30:40.370 --> 00:30:44.090
Here are some examples
of the photos.

00:30:44.090 --> 00:30:47.240
And here's more.

00:30:47.240 --> 00:30:50.790
So the rationale is
that for us to be able

00:30:50.790 --> 00:30:54.010
to manage this new territory
called the Philippines,

00:30:54.010 --> 00:30:56.840
we need to understand its
people and more importantly,

00:30:56.840 --> 00:31:00.660
we need to understand their
resources so we can trade.

00:31:00.660 --> 00:31:07.880
So that was the whole premise
around the ethnographic surveys

00:31:07.880 --> 00:31:10.240
that he did in the early 1900s.

00:31:10.240 --> 00:31:16.790
Now the photographs of
Wooster are currently are

00:31:16.790 --> 00:31:18.500
in more than ten institutions.

00:31:18.500 --> 00:31:21.540
But I looked at ten
institutions for this study.

00:31:21.540 --> 00:31:27.770
There's an effort to consolidate
them since the 1970s by doing,

00:31:27.770 --> 00:31:32.610
you know, like a union catalog, of
sort, for where they are located.

00:31:32.610 --> 00:31:37.810
There is a research demand
on these photographs and it's

00:31:37.810 --> 00:31:40.210
in various stages of digitization

00:31:40.210 --> 00:31:43.010
and there's some funding
available for this.

00:31:43.010 --> 00:31:45.790
And yet reunification
is not happening.

00:31:45.790 --> 00:31:53.430 position:56%
So I said this is probably an ideal
case to study and examine, you know,

00:31:53.430 --> 00:31:57.440
in an in a context where
something is likely

00:31:57.440 --> 00:31:59.110
to happen, yet it's not happening.

00:31:59.110 --> 00:32:01.150
What's stopping it from happening?

00:32:01.150 --> 00:32:04.500
That was my particular
question at that time.

00:32:04.500 --> 00:32:09.720
So I went through ten institutions
that collected these photographs.

00:32:09.720 --> 00:32:16.430
Two of those are I would classify
as Natural History Museum,

00:32:16.430 --> 00:32:20.540
Four our anthropology and
archaeological museums.

00:32:20.540 --> 00:32:23.880
Two are archival institutions
or archives

00:32:23.880 --> 00:32:27.170
and two our special collections.

00:32:27.170 --> 00:32:30.140
You will see and I
will get back to this

00:32:30.140 --> 00:32:34.770 position:56%
that in these multiple institutions,
you know, the photos are

00:32:34.770 --> 00:32:42.590
of different formats and
different types of state or stages

00:32:42.590 --> 00:32:46.340
in terms of digitization.

00:32:46.340 --> 00:32:52.070
But so, you know, you go back
to the idea of, you know,

00:32:52.070 --> 00:32:55.930
if you want to bring something
together that's dispersed,

00:32:55.930 --> 00:32:59.060
who decides on behalf
of the communities

00:32:59.060 --> 00:33:01.580
when only institutions are talking?

00:33:01.580 --> 00:33:06.170
And how do you display
indigenous images when, you know,

00:33:06.170 --> 00:33:10.430
if you want to produce
some something scholarly?

00:33:10.430 --> 00:33:13.400
Another problem that I've
seen is that, you know,

00:33:13.400 --> 00:33:15.730
there are many dimensions
to dispersion.

00:33:15.730 --> 00:33:19.650
When you say I'm reunifying
something that's dispersed,

00:33:19.650 --> 00:33:23.410
so are you referring to, you
know, the physical distance

00:33:23.410 --> 00:33:26.250
that they're scattered
in various places?

00:33:26.250 --> 00:33:29.600
Are you talking about
temporal of dispersion,

00:33:29.600 --> 00:33:32.580
because they were dispersed
at different moments in time?

00:33:32.580 --> 00:33:37.380
Provenantial, I'm using provenance
from the archival sense in terms

00:33:37.380 --> 00:33:41.550
of the chain of custody and
ownership to these materials.

00:33:41.550 --> 00:33:43.920
Or is it material?

00:33:43.920 --> 00:33:45.430
The challenge is material.

00:33:45.430 --> 00:33:48.730
So here's one visualization
elementary one

00:33:48.730 --> 00:33:50.710
that I created for myself.

00:33:50.710 --> 00:33:53.330
You know, like to show
you some notion

00:33:53.330 --> 00:33:55.650
of dispersion that's geographic.

00:33:55.650 --> 00:33:57.280
It's in multiple places.

00:33:57.280 --> 00:34:06.780
It could also be provenantial, so
in one institution the material is,

00:34:06.780 --> 00:34:10.610
you know, categorized as a
collection by Frederick Wooster,

00:34:10.610 --> 00:34:14.340 position:56%
the son of the photographer who then
donated it to the American Museum

00:34:14.340 --> 00:34:18.730
of Natural History and then later
the negatives were transferred

00:34:18.730 --> 00:34:21.220
to the University of Michigan
Museum of Anthropology.

00:34:21.220 --> 00:34:24.740
So, you know, provenance
as well is quite dispersed.

00:34:24.740 --> 00:34:30.030
It's sometimes it doesn't
just go in one direction.

00:34:30.030 --> 00:34:33.060
So it's also temporal.

00:34:33.060 --> 00:34:36.300
They were given to this
various institutions

00:34:36.300 --> 00:34:39.330
at different moments in time.

00:34:39.330 --> 00:34:44.840 position:56%
So there's that, you know, the
earliest collection that I found was

00:34:44.840 --> 00:34:48.610
when at the National
Anthropological Archives.

00:34:48.610 --> 00:34:50.460
So and also material.

00:34:50.460 --> 00:34:53.120
Sometimes the photograph
would be in a scrapbook,

00:34:53.120 --> 00:34:57.600
sometimes it's a lantern slide.

00:34:57.600 --> 00:35:02.610
Even if you compare two
scrapbooks images are, you know,

00:35:02.610 --> 00:35:07.110 position:56%
put in different chronological
order or different parts of the same

00:35:07.110 --> 00:35:08.940
or two different scrapbooks.

00:35:08.940 --> 00:35:12.480
So there's a lot of researchers
are interested in the meaning

00:35:12.480 --> 00:35:14.710
around the changing
of this, you know,

00:35:14.710 --> 00:35:20.400
chronological representation
of the photographs.

00:35:20.400 --> 00:35:24.750
And also among institutions
that I've interviewed,

00:35:24.750 --> 00:35:28.110
they seem to have this
notion of, you know,

00:35:28.110 --> 00:35:32.490
so we can show these
photographs to everybody.

00:35:32.490 --> 00:35:36.540
And so we have to make
sure that not, you know,

00:35:36.540 --> 00:35:41.270
we are more responsible around, you
know, who gets to see the image.

00:35:41.270 --> 00:35:45.510 position:56%
So as far as these institutions are
concerned, they have to see it first

00:35:45.510 --> 00:35:47.610
because they need to
work on the collection

00:35:47.610 --> 00:35:49.760
and then the source communities,

00:35:49.760 --> 00:35:51.720
of course the different
indigenous groups

00:35:51.720 --> 00:35:55.650
that that would take
ownership of these images.

00:35:55.650 --> 00:35:57.290
And then researchers and scholars

00:35:57.290 --> 00:36:00.330
and then maybe the Filipino
immigrant communities or living

00:36:00.330 --> 00:36:03.680
in the U.S. and then the
general public the last.

00:36:03.680 --> 00:36:07.610
So it's a different
notion of access.

00:36:07.610 --> 00:36:11.750
I know that many information
professionals are very much in love

00:36:11.750 --> 00:36:14.430
with universal unfiltered,
unhindered access,

00:36:14.430 --> 00:36:18.980
but it's just not the case for
ethnographic collections with ties

00:36:18.980 --> 00:36:20.980
to Indigenous communities.

00:36:20.980 --> 00:36:22.310
So, finally,.

00:36:22.310 --> 00:36:27.500
I am leaving you with
three questions.

00:36:27.500 --> 00:36:30.860
The first is what does it
mean to assemble the whole?

00:36:30.860 --> 00:36:34.760
You know, as I said earlier there
are many dimensions to dispersion.

00:36:34.760 --> 00:36:39.270
Does it mean getting all of those?

00:36:39.270 --> 00:36:40.580
They mention together

00:36:40.580 --> 00:36:44.400
in one representational
kind of digital project.

00:36:44.400 --> 00:36:47.030 position:56%
What is the object of reunification?

00:36:47.030 --> 00:36:50.600
Sometimes we actually
care about relationships,

00:36:50.600 --> 00:36:53.090
fixing relationships
with communities.

00:36:53.090 --> 00:36:56.700
Is that what we want that
ultimately the outcome is

00:36:56.700 --> 00:36:59.510
that we have good relationships
with communities

00:36:59.510 --> 00:37:04.120
that the material recombination
or assembly

00:37:04.120 --> 00:37:07.830
of these things are
a way towards that.

00:37:07.830 --> 00:37:10.210
Another is reunification
is a solution.

00:37:10.210 --> 00:37:13.140
What really is the problem?

00:37:13.140 --> 00:37:18.160
Is this sometimes, you know, I
hear of availability of technology

00:37:18.160 --> 00:37:21.730
that it will solve things, that
will do a lot of things for us.

00:37:21.730 --> 00:37:25.990
But is this a solution
in search of a problem?

00:37:25.990 --> 00:37:27.790
So thank you very much.

00:37:27.790 --> 00:37:37.150
[ Applause ]

00:37:37.150 --> 00:37:38.450
&gt;&gt; Thank you.

00:37:50.040 --> 00:37:53.120
&gt;&gt; This one, got it.

00:37:55.650 --> 00:37:57.950
Okay.

00:38:13.840 --> 00:38:20.730
Oh. Can you duplicating or can
you split the screen by chance?

00:38:20.730 --> 00:38:25.270
Sorry about that.

00:38:25.270 --> 00:38:30.930
You think a web developer
would know how to [laughs].

00:38:30.930 --> 00:38:32.530
Thank you.

00:38:32.530 --> 00:38:38.560
[laughs] All right, perfect.

00:38:38.560 --> 00:38:42.360
Well, on a personal level I
may be the most surprising

00:38:42.360 --> 00:38:46.960
and unlikely person today as not
long ago I sat in the library

00:38:46.960 --> 00:38:50.950
to escape the beautiful chaos
of my then 1-year-old daughter.

00:38:50.950 --> 00:38:55.890
I was combing through programming
books to build an app of my own.

00:38:55.890 --> 00:38:58.760
I had recently resigned
from a ten year career

00:38:58.760 --> 00:39:01.260
as an accountant an auditor

00:39:01.260 --> 00:39:04.320
to pursue a passion
for web development.

00:39:04.320 --> 00:39:07.410
Shortly thereafter I
started my current dream job

00:39:07.410 --> 00:39:11.160
as a web developer
for This universe.org.

00:39:11.160 --> 00:39:13.470
So it's fitting I introduce
you to a surprising tool

00:39:13.470 --> 00:39:16.440
that will unlock the
data of your collections

00:39:16.440 --> 00:39:19.850
in unlikely ways you may
not imagine this universe.

00:39:19.850 --> 00:39:22.460
This universe is the world's
largest most popular platform

00:39:22.460 --> 00:39:26.390
for people powered research and
one of 26 Zooniverse team members.

00:39:26.390 --> 00:39:30.210
Many also with unorthodoxed
backgrounds, including Ph.D.s

00:39:30.210 --> 00:39:33.990
in astronomy, the humanities,
ecology and philosophy.

00:39:33.990 --> 00:39:37.240
There is an amazing team of
developers and data scientists

00:39:37.240 --> 00:39:40.870
as well as education and
outreach ambassadors.

00:39:40.870 --> 00:39:45.660
Today I'll introduce you to the
university our diverse projects

00:39:45.660 --> 00:39:48.440
and focus on transcription projects

00:39:48.440 --> 00:39:51.960
and give you a brief overview
of our project builder.

00:39:51.960 --> 00:39:57.380
It all started with
Galaxy Zoo in 2007.

00:39:57.380 --> 00:40:00.160
Like many scientists and
likely many here today,

00:40:00.160 --> 00:40:03.930
two astronomers had more
data than they could process.

00:40:03.930 --> 00:40:05.330
They had over a million galaxies

00:40:05.330 --> 00:40:07.650
to classify before they
could even use the data

00:40:07.650 --> 00:40:11.690
to ask the interesting
questions about our universe.

00:40:11.690 --> 00:40:14.830
One of them remarkably
classified 50,000 image galaxies

00:40:14.830 --> 00:40:17.820
over a month classifying
morning day and night,

00:40:17.820 --> 00:40:21.720
but would likely go insane or spend
the rest of their life classifying

00:40:21.720 --> 00:40:23.020
to complete the data set.

00:40:23.020 --> 00:40:26.070 position:56%
Now the pattern recognition required

00:40:26.070 --> 00:40:30.220
for the initial classifying
humans excel at,

00:40:30.220 --> 00:40:32.520
while computers yet do none.

00:40:32.520 --> 00:40:34.350
Their solution was
to harness the power

00:40:34.350 --> 00:40:37.350
of crowd sourcing with Galaxy Zoo.

00:40:37.350 --> 00:40:40.510
They employed the general public
to go and review the images

00:40:40.510 --> 00:40:44.090
and classify them as a spiral
or elliptical with a tutorial,

00:40:44.090 --> 00:40:48.580
if needed, and the
results were incredible.

00:40:48.580 --> 00:40:50.930
There were 50 million
classifications during its first

00:40:50.930 --> 00:40:54.800
year alone with over
150,000 people contributing.

00:40:54.800 --> 00:40:59.540
Eventually it was determined that
the crowd sourced consensus was

00:40:59.540 --> 00:41:04.030
as good as classifications provided
by professional astronomers,

00:41:04.030 --> 00:41:07.020
showing that the crowd
gets it right.

00:41:07.020 --> 00:41:08.950
The research team has
since published

00:41:08.950 --> 00:41:12.210
over 40 peer reviewed
publications including some

00:41:12.210 --> 00:41:14.520
where volunteers are
listed as co-authors.

00:41:14.520 --> 00:41:17.780
These are just regular
everyday volunteers.

00:41:17.780 --> 00:41:21.990
Galaxy Zoo accomplished research
otherwise thought impossible.

00:41:21.990 --> 00:41:24.440
And it gets more exciting.

00:41:24.440 --> 00:41:26.980
In the upper left here we
have a legendary guitarist

00:41:26.980 --> 00:41:29.320
for Queen, Brian May.

00:41:29.320 --> 00:41:32.750
He's also a Ph.D. astronomer.

00:41:32.750 --> 00:41:35.890
And an avid Galaxy Zoo participant.

00:41:35.890 --> 00:41:40.170 position:56%
And he inspired others like Hannifin
Ukcal [SP] there in the upper right.

00:41:40.170 --> 00:41:42.920
She's a teacher in the Netherlands.

00:41:42.920 --> 00:41:45.310
She classified the
work to spiral galaxy

00:41:45.310 --> 00:41:47.580 position:56%
in the finner image towards the top.

00:41:47.580 --> 00:41:51.210
But ask what's the object below it?

00:41:51.210 --> 00:41:53.200
The researchers looked into
her question and it turns

00:41:53.200 --> 00:41:56.830
out it's a galaxy sized gas
cloud driven by a black hole

00:41:56.830 --> 00:41:58.740
in the neighborhood
neighboring galaxy

00:41:58.740 --> 00:42:01.930
that recently shifted
from active to quiet.

00:42:01.930 --> 00:42:06.680
Scientists knew of it, but had
never captured the phenomenon.

00:42:06.680 --> 00:42:10.270
Hanie was the first person
in history to witness it

00:42:10.270 --> 00:42:14.260
and it was aptly named
after her, which illustrates

00:42:14.260 --> 00:42:16.800
that the more people you
engage in your project,

00:42:16.800 --> 00:42:20.540
the more likely someone will make
an amazing serendipitous discovery.

00:42:20.540 --> 00:42:25.410
So each project has a
forum that we call talk.

00:42:25.410 --> 00:42:28.430
Talk is where volunteers can
communicate with each other as well

00:42:28.430 --> 00:42:30.560
with the researchers or experts.

00:42:30.560 --> 00:42:34.830
In this project the first
discussion is for specific images.

00:42:34.830 --> 00:42:38.000
Next is general questions and
there's specific discussions

00:42:38.000 --> 00:42:40.340
that are unique to this project.

00:42:40.340 --> 00:42:44.310
Now, Talk is where we often see
these serendipitous discoveries

00:42:44.310 --> 00:42:46.230
like Hanie's Ververs.

00:42:46.230 --> 00:42:50.260
And a key to a successful project
is that the research team engages

00:42:50.260 --> 00:42:53.690
with its volunteers through Talk.

00:42:53.690 --> 00:42:56.000
This is our current
landing page of projects

00:42:56.000 --> 00:43:01.000
and since 2007 this universe has
expanded to over 45 active projects

00:43:01.000 --> 00:43:03.470
with several hundred
researchers that have led

00:43:03.470 --> 00:43:06.630
to over 100 peer reviewed
publications.

00:43:06.630 --> 00:43:09.170
The Galaxy Zoo papers
alone have had thousands

00:43:09.170 --> 00:43:12.630
of citations in reuse of the data.

00:43:12.630 --> 00:43:15.900
Galaxy is doing its story
encapsulates three important points

00:43:15.900 --> 00:43:17.280
I'd like to emphasize.

00:43:17.280 --> 00:43:20.470
First, engagement with
volunteers will equate

00:43:20.470 --> 00:43:24.020
to the success of a project.

00:43:24.020 --> 00:43:26.810
Secondly, crowd sourcing is
both about classifications

00:43:26.810 --> 00:43:29.720
and serendipitous discoveries.

00:43:29.720 --> 00:43:35.090
And third, crowd sourcing leads
to accurate and reliable results.

00:43:37.090 --> 00:43:39.650
Science Gossip is a
transcription project

00:43:39.650 --> 00:43:43.360
that bridges the citizens
scientists of the Victorian period

00:43:43.360 --> 00:43:45.460
with the citizen scientists
of today.

00:43:45.460 --> 00:43:48.440
For computers and cameras
citizen scientists had

00:43:48.440 --> 00:43:50.000
to draw what they saw.

00:43:50.000 --> 00:43:54.210
But those drawings have been
locked away in the pages

00:43:54.210 --> 00:43:56.150
of those Victorian periodicals.

00:43:56.150 --> 00:44:00.120
Until today, through Science Gossip
volunteers can help classify those

00:44:00.120 --> 00:44:05.050
drawings unlocking the
origins of citizen science.

00:44:05.050 --> 00:44:07.990
What may have taken a diligent
historian over ten years,

00:44:07.990 --> 00:44:10.910
volunteers for [inaudible]
to accomplish in one.

00:44:10.910 --> 00:44:15.960
It's accomplishing research
otherwise thought impractical.

00:44:15.960 --> 00:44:20.050
One volunteer found the left image
an illustration by Mabel Rhodes

00:44:20.050 --> 00:44:23.130
on the anatomy of the
wrathfully and asked in Talk

00:44:23.130 --> 00:44:26.110
if it was the first
female contributor?

00:44:26.110 --> 00:44:29.820
And her question inspired
the community.

00:44:29.820 --> 00:44:32.940
They discovered numerous women
engravers and illustrators,

00:44:32.940 --> 00:44:37.180
including many previously
uncredited.

00:44:37.180 --> 00:44:40.500
One volunteer's question
brought the collection to life

00:44:40.500 --> 00:44:43.640
in an amazing and unexpected way.

00:44:46.050 --> 00:44:47.970
Penguin watch is one of
my personal favorites.

00:44:47.970 --> 00:44:51.160
You get to spy on penguins
for science.

00:44:51.160 --> 00:44:55.600
You tag penguins in remote regions
to help us understand their lives,

00:44:55.600 --> 00:44:58.930
the environment and the
effects of climate change.

00:44:58.930 --> 00:45:03.050
A contest for penguin
watch volunteers was held

00:45:03.050 --> 00:45:05.490
and the winner got to
go to the Antarctic.

00:45:05.490 --> 00:45:07.540
And you could see the
winner of that contest

00:45:07.540 --> 00:45:10.950
in that lower right jumping
into the Antarctic seas.

00:45:10.950 --> 00:45:14.770
And I am not sure all of our
volunteers share that level

00:45:14.770 --> 00:45:18.730
of enthusiasm, [laughs]
but the number one reason

00:45:18.730 --> 00:45:20.570
that volunteers do
participate is simply

00:45:20.570 --> 00:45:23.600
to contribute to scientific
progress.

00:45:23.600 --> 00:45:26.570
Runner up reasons are that
they're fascinated on a project

00:45:26.570 --> 00:45:28.810
or that it's just plain fun.

00:45:28.810 --> 00:45:33.790
We have over 1.5 million
registered volunteers

00:45:33.790 --> 00:45:40.130
across 237 countries ranging in
age from five to 95 years old.

00:45:40.130 --> 00:45:41.920
It's a wonderfully diverse group,

00:45:41.920 --> 00:45:47.800
all making real contributions
to science.

00:45:47.800 --> 00:45:51.150
Snapshots Serengeti is another
one of my personal favorites.

00:45:51.150 --> 00:45:53.870
Volunteers have classified images
from hundreds of camera traps

00:45:53.870 --> 00:45:57.490
in Serengeti National Park
providing a powerful new window

00:45:57.490 --> 00:46:01.510
into Africa's most
elusive wildlife species.

00:46:01.510 --> 00:46:04.060
It was launched in 2012 and
it's been incredibly successful.

00:46:04.060 --> 00:46:07.490 position:56%
In the first three days alone there
were over a million classifications.

00:46:07.490 --> 00:46:11.590
It processed an 18
month backlog of images.

00:46:11.590 --> 00:46:14.690
And there's a related publication
that showed that the crowd is

00:46:14.690 --> 00:46:18.420
as good as experts in
consensus scenarios

00:46:18.420 --> 00:46:22.890
or were 97% accurate
compared to the 98% accuracy

00:46:22.890 --> 00:46:25.190
of experts and other scenarios.

00:46:25.190 --> 00:46:27.670
Again the crowd gets it right.

00:46:27.670 --> 00:46:30.850
And personally I now know the
difference between a hartebeest

00:46:30.850 --> 00:46:36.450
and a wildebeest and this
project is just plain fun.

00:46:36.450 --> 00:46:39.800
To elaborate more on
what I mean by consensus,

00:46:39.800 --> 00:46:43.910
Snapshot Serengeti has 25
volunteers classify an image before

00:46:43.910 --> 00:46:45.230
retiring it.

00:46:45.230 --> 00:46:49.840
Unless the first five say
it's blank or 10 agreed,

00:46:49.840 --> 00:46:51.220
thereby reaching a consensus.

00:46:51.220 --> 00:46:54.870
Now this image is pretty
straightforward, and as you can see

00:46:54.870 --> 00:46:59.740
in the lower right volunteers are
currently all in agreement so far

00:46:59.740 --> 00:47:04.190
that there is one giraffe
in this image.

00:47:04.190 --> 00:47:06.390
[laughs] While this
image is challenging.

00:47:06.390 --> 00:47:09.640
One volunteer thinks
there are four wildebeests

00:47:09.640 --> 00:47:11.170
and other three are asterisks.

00:47:11.170 --> 00:47:16.270
One wildebeest and others Buffalo.

00:47:16.270 --> 00:47:20.000
With certain images it's just
not possible to get consensus.

00:47:20.000 --> 00:47:23.730
In which case 25 people will
classify the image before

00:47:23.730 --> 00:47:25.030
it's retired.

00:47:25.030 --> 00:47:27.330
Now even experts can't
agree on these images.

00:47:27.330 --> 00:47:31.950
And though these images are
the minority, most or over 70%

00:47:31.950 --> 00:47:35.580
of images are retired with
the consensus before getting

00:47:35.580 --> 00:47:38.840
to the 25 classification maximum.

00:47:38.840 --> 00:47:41.970
So now we'll focus

00:47:41.970 --> 00:47:46.070
on some transcription projects
starting with Anno Tate.

00:47:46.070 --> 00:47:49.620
Anno Tate is a collaboration with
the Tate Museums and Archives

00:47:49.620 --> 00:47:53.230
and it's a museums of
the web top prize winner.

00:47:53.230 --> 00:47:56.770
In addition to creating art, many
artists wrote diaries and letters,

00:47:56.770 --> 00:47:59.590
and made sketchbooks
that contain rich details

00:47:59.590 --> 00:48:03.090
about their lives and
creative processes.

00:48:03.090 --> 00:48:06.610
Volunteers transcribe these
documents from the Tate collection

00:48:06.610 --> 00:48:09.780
and reveal the secret
lives of artists.

00:48:09.780 --> 00:48:12.050
I'd like to have the artist's
works open in one window

00:48:12.050 --> 00:48:14.340
and classify in another window.

00:48:14.340 --> 00:48:16.120
It gives a whole new
appreciation for the art

00:48:16.120 --> 00:48:18.600
and the artists themselves.

00:48:18.600 --> 00:48:24.870
For documents such as
this OCR doesn't work,

00:48:24.870 --> 00:48:27.140
which is why we need
to transcribe them.

00:48:27.140 --> 00:48:29.660
Transcription can be
quite challenging.

00:48:29.660 --> 00:48:32.120
It's not as straightforward
as looking at a penguin,

00:48:32.120 --> 00:48:33.420
but we try to make it

00:48:33.420 --> 00:48:35.940
as straightforward and
simple as possible.

00:48:35.940 --> 00:48:40.010 position:56%
For NSA we utilize the transcription
method I'm going to refer to as line

00:48:40.010 --> 00:48:45.300
by line and we don't ask volunteers
to transcribe an entire page.

00:48:45.300 --> 00:48:46.600
We do not ask them

00:48:46.600 --> 00:48:48.800
to even necessarily
transcribe it in her sentence.

00:48:48.800 --> 00:48:53.700 position:56%
We simply ask them to transcribe one
visual line at a time that they feel

00:48:53.700 --> 00:48:56.650
that they can do in confidence.

00:48:56.650 --> 00:49:00.370
This creates a quality
collective efforts.

00:49:00.370 --> 00:49:02.560
Each lines xy coordinates

00:49:02.560 --> 00:49:04.780
and related transcription
is then compared

00:49:04.780 --> 00:49:07.930
with an algorithm creating
hopefully consensus

00:49:07.930 --> 00:49:11.810
and vastly reducing
the need for experts.

00:49:11.810 --> 00:49:15.680
To date the average rate of
accuracy for a line transcribed

00:49:15.680 --> 00:49:19.600
by multiple people
on Anno Tate is 95%.

00:49:19.600 --> 00:49:24.110
This rate of accuracy is in line
with estimates on OCR accuracy,

00:49:24.110 --> 00:49:28.310
which are 94% for grayscale
and 97% for bitonal.

00:49:28.310 --> 00:49:33.900
So accuracy in line with OCR on
documents that can't use OCR.

00:49:33.900 --> 00:49:38.630
Again showing that the
crowd gets it right.

00:49:38.630 --> 00:49:41.580
In collaboration with the
Folger Shakespeare Library here

00:49:41.580 --> 00:49:44.820
in Washington DC and other
transcription projects

00:49:44.820 --> 00:49:47.060 position:56%
that we love is Shakespeare's World.

00:49:47.060 --> 00:49:49.080
Volunteers transcribe
handwritten documents

00:49:49.080 --> 00:49:50.380
by Shakespeare's contemporaries

00:49:50.380 --> 00:49:53.800
and help us understand his
amazing life and times.

00:49:53.800 --> 00:49:57.240
As a symbol or a line
by line process,

00:49:57.240 --> 00:50:00.040
but there's added complexity for
the type of historical documents.

00:50:00.040 --> 00:50:05.250
Now what we've learned with this
project as well as others is

00:50:05.250 --> 00:50:09.120
that if you have a
great UI for volunteers,

00:50:09.120 --> 00:50:13.220
then they can accomplish complex
and difficult transcription.

00:50:13.220 --> 00:50:15.660
Again it helps to break
the transcription process

00:50:15.660 --> 00:50:18.240
down to an approachable level.

00:50:18.240 --> 00:50:21.690
So documents are divided
between recipes and letters.

00:50:21.690 --> 00:50:24.280
And for those interested in
delicious dishes or juicy gossip

00:50:24.280 --> 00:50:28.060
from Shakespeare's time, I
personally enjoy the recipes.

00:50:28.060 --> 00:50:30.250
They can be tough,
but it's fascinating.

00:50:30.250 --> 00:50:33.590
There's also a wonderful blog with
Shakespeare's World, just like many

00:50:33.590 --> 00:50:35.610
of our projects that gives updates

00:50:35.610 --> 00:50:39.220
and shares great stories
from the project.

00:50:40.870 --> 00:50:44.360
The next transcription project
is decoding the civil war.

00:50:44.360 --> 00:50:47.090
You can witness the United
States Civil War by transcribing

00:50:47.090 --> 00:50:48.790
and deciphering messages and codes

00:50:48.790 --> 00:50:52.040
from the United States
military telegraph.

00:50:52.040 --> 00:50:54.390
Including there's one
telegram from Abraham Lincoln

00:50:54.390 --> 00:50:58.250
to Mary Todd two weeks before
his death updating her on the war

00:50:58.250 --> 00:50:59.820
after a meeting with General Grant.

00:50:59.820 --> 00:51:03.800 position:56%
It's incredibly interesting and then
there's other telegraphs requesting

00:51:03.800 --> 00:51:05.620
whiskey or clean underwear.

00:51:05.620 --> 00:51:08.760
It runs the gamut and it's
a fascinating perspective

00:51:08.760 --> 00:51:11.010
into the people's lives
of this remarkable time

00:51:11.010 --> 00:51:12.400
in our country's history.

00:51:12.400 --> 00:51:19.340
Now as you hopefully can see in
the animation this is a variation

00:51:19.340 --> 00:51:22.090
on the method I previously
mentioned.

00:51:22.090 --> 00:51:26.150
Here volunteers underline
a line and then transcribe.

00:51:26.150 --> 00:51:29.480
We ask volunteers to do an entire
telegraph before proceeding.

00:51:29.480 --> 00:51:33.970
An additional method that we worked
on years ago in collaboration

00:51:33.970 --> 00:51:36.750
with the New York Public
Library is Scribe.

00:51:36.750 --> 00:51:39.770
The method with Scribe is that
one volunteer marks the document

00:51:39.770 --> 00:51:41.830
structure and then
the same volunteer

00:51:41.830 --> 00:51:45.100
or a different volunteer can
do the work of transcribing.

00:51:45.100 --> 00:51:47.040 position:56%
There's also a verification process.

00:51:47.040 --> 00:51:48.970
Scribe is open source
like everything we do is.

00:51:48.970 --> 00:51:52.940 position:56%
I'd encourage you if you want to do
a transcription project on your own,

00:51:52.940 --> 00:51:54.240 position:56%
I was [inaudible] at the University.

00:51:54.240 --> 00:51:57.390
I thought Scribe might be
a very useful tool for you.

00:51:57.390 --> 00:52:00.910
There's also a method
that the Smithsonian uses

00:52:00.910 --> 00:52:03.110
where one volunteer
might transcribe,

00:52:03.110 --> 00:52:06.840
a different volunteer would review
and then an expert would review

00:52:06.840 --> 00:52:10.330
and there's feedback
all along that cycle.

00:52:10.330 --> 00:52:11.970
And there's no right
or wrong method.

00:52:11.970 --> 00:52:15.190
The best method depends
on the project.

00:52:15.190 --> 00:52:19.340
So coming back to decoding the
Civil War, this was entirely built,

00:52:19.340 --> 00:52:21.850
this was recently launched and
built within our project builder.

00:52:21.850 --> 00:52:24.750
Now a little over a year ago we
launched the project builder.

00:52:24.750 --> 00:52:27.310
It's an easy to use,
browser based interface

00:52:27.310 --> 00:52:29.560
to create your project,
and it's incredible.

00:52:29.560 --> 00:52:30.920
We're really proud of it.

00:52:30.920 --> 00:52:36.860
Right now anyone can build their
own project for free in hours.

00:52:36.860 --> 00:52:39.820
Go to [inaudible] click build a
project and you're on your way.

00:52:39.820 --> 00:52:41.120
It's that simple.

00:52:41.120 --> 00:52:42.420
There's an overview.

00:52:42.420 --> 00:52:44.770
I'm going to give an overview,
but there's a detailed tutorial

00:52:44.770 --> 00:52:47.730
and there are message
boards on line,

00:52:47.730 --> 00:52:50.490
if you'd like to try it yourself.

00:52:50.490 --> 00:52:52.710
So this is a screenshot from
within the project builder.

00:52:52.710 --> 00:52:54.400 position:56%
Don't worry about the details shown.

00:52:54.400 --> 00:52:58.350
My intent is just to give you a
general feel for the interface.

00:52:58.350 --> 00:53:02.650
In the far left menu from top
to bottom you have a project -

00:53:02.650 --> 00:53:05.400
what we refer to as product
section, a workflow section

00:53:05.400 --> 00:53:07.110
and a subject set sections.

00:53:07.110 --> 00:53:09.460
I'll start with subject sets.

00:53:09.460 --> 00:53:11.010
It's likely your collection.

00:53:11.010 --> 00:53:15.570 position:56%
Typically in our case images, though
we're experimenting with video.

00:53:15.570 --> 00:53:18.150
You can upload your subjects
into the project builder

00:53:18.150 --> 00:53:22.090
or we do support externally
hosted images.

00:53:22.090 --> 00:53:26.310
Can include metadata, like your
internal IDs and other information,

00:53:26.310 --> 00:53:29.760
which can either be shown
or hidden from volunteers.

00:53:29.760 --> 00:53:31.530
And once you have your subject set

00:53:31.530 --> 00:53:34.940
into the product builder you
could then create what we refer

00:53:34.940 --> 00:53:36.240
to as a workflow.

00:53:36.240 --> 00:53:39.120
It's the sequence of tasks
that you ask volunteers to do.

00:53:39.120 --> 00:53:44.420
And we have many types of
tasks, including text tasks,

00:53:44.420 --> 00:53:46.430
especially useful for
transcription projects,

00:53:46.430 --> 00:53:48.630
a drawing task, a drop down task.

00:53:48.630 --> 00:53:52.760
Some are behind an experimental
flag, so in which case ask

00:53:52.760 --> 00:53:55.240
and we'll enable it for you.

00:53:55.240 --> 00:53:56.800
Also within the project,

00:53:56.800 --> 00:54:01.080
in the workflow editor you set
the retirement for a subject.

00:54:01.080 --> 00:54:02.880
Just how many times it's classified

00:54:02.880 --> 00:54:06.400
for is no longer shown
to volunteers.

00:54:06.400 --> 00:54:07.700
So once you have a subject set

00:54:07.700 --> 00:54:10.080
and a workflow you've completed
the core of the project.

00:54:10.080 --> 00:54:13.570
Now here we see what a
volunteer sees while classifying

00:54:13.570 --> 00:54:15.010 position:56%
within the Notes for Nature project.

00:54:15.010 --> 00:54:18.430
Notes of Nature is where volunteers
transcribes specimen labels

00:54:18.430 --> 00:54:21.240
that we recently relaunched
after rebuilding

00:54:21.240 --> 00:54:22.540
within the project builder.

00:54:22.540 --> 00:54:24.170
I work closely with this project.

00:54:24.170 --> 00:54:27.240
It's been a wonderful experience,
has an incredible research team.

00:54:27.240 --> 00:54:31.020
And what you can see
here are two text tasks

00:54:31.020 --> 00:54:34.290
to where a volunteer
can type the specimen,

00:54:34.290 --> 00:54:36.570
collect your name and number.

00:54:36.570 --> 00:54:40.560
And then three drop down tasks
enter the month day and year.

00:54:40.560 --> 00:54:43.720
All within what we refer
to as a combo task.

00:54:43.720 --> 00:54:47.300
And this is an example
of what you can build

00:54:47.300 --> 00:54:48.720 position:56%
and what a volunteer would then see.

00:54:48.720 --> 00:54:54.410
Within the product builder you
can also add other collaborators

00:54:54.410 --> 00:54:55.870
or people to help you.

00:54:55.870 --> 00:54:58.010
You can add content for
your project lining page,

00:54:58.010 --> 00:55:00.940
you can create a team page or
research page to give more detail

00:55:00.940 --> 00:55:03.610
about what you're looking
to accomplish.

00:55:03.610 --> 00:55:06.770
You can create tutorials
field guides in many courses

00:55:06.770 --> 00:55:09.000
to help volunteers classify it.

00:55:09.000 --> 00:55:10.300
You could set up your talk

00:55:10.300 --> 00:55:13.120
for the incredible serendipity
I mentioned earlier happens.

00:55:13.120 --> 00:55:16.230
And you can export
aspects of your project,

00:55:16.230 --> 00:55:18.870
including boundary
classifications either

00:55:18.870 --> 00:55:21.160 position:56%
on day one, [inaudible] or whenever.

00:55:21.160 --> 00:55:26.350
There's a review process to
be featured on the main page,

00:55:26.350 --> 00:55:29.170
but as soon as you build your
project you can share a link

00:55:29.170 --> 00:55:30.830
with it to anyone.

00:55:30.830 --> 00:55:35.090
A successful project articulates
their purpose well as workflows

00:55:35.090 --> 00:55:37.990
that are as straightforward
and simple as possible.

00:55:37.990 --> 00:55:42.720
Detailed help for volunteers and
an active research team on talk

00:55:42.720 --> 00:55:46.040
which I can't - it
helps significantly.

00:55:46.040 --> 00:55:49.600
So the Zooniverse is expanding
at an accelerating rate

00:55:49.600 --> 00:55:51.470
with exciting challenges ahead,

00:55:51.470 --> 00:55:53.630
especially with transcription
projects which we love

00:55:53.630 --> 00:55:55.260
to collaborate with you on.

00:55:55.260 --> 00:55:57.990
We're constantly working
with machinery and experts

00:55:57.990 --> 00:55:59.910
to further their research as well

00:55:59.910 --> 00:56:02.510
as make sure we're not wasting
our volunteers precious time.

00:56:02.510 --> 00:56:05.630
And we're actively improving
the Zooniverse on mobile.

00:56:05.630 --> 00:56:07.890
We're open source.

00:56:07.890 --> 00:56:09.570
Check us out when you get home.

00:56:09.570 --> 00:56:12.010
Zooniverse works and
we want you to join us.

00:56:12.010 --> 00:56:15.190
Help us accomplish science
otherwise thought impossible.

00:56:15.190 --> 00:56:18.370
Unlike your data or someone else's.

00:56:18.370 --> 00:56:21.860
We won't make you jump in the
Antarctic seas, but you may end

00:56:21.860 --> 00:56:25.850
up with a galactic sized
gas cloud in there for you.

00:56:25.850 --> 00:56:29.190
And on a final note,
we're also thrilled

00:56:29.190 --> 00:56:34.150
to announce two upcoming open
calls for partners with text

00:56:34.150 --> 00:56:38.300
or audio transcription projects
needing custom tools or interface.

00:56:38.300 --> 00:56:40.620
It's hard to express how
excited we are about this.

00:56:40.620 --> 00:56:42.740
These open calls are made possible
by [inaudible] from the Institute

00:56:42.740 --> 00:56:46.560
of Museum and Library Services
for a three year effort

00:56:46.560 --> 00:56:49.110
to better support this community.

00:56:49.110 --> 00:56:52.180
As part of this effort we
will take lessons learned

00:56:52.180 --> 00:56:55.810
through these new custom build
projects to improve the tools

00:56:55.810 --> 00:56:59.790
that we offer to all
through the project builder.

00:56:59.790 --> 00:57:01.590
So thank you for your time today.

00:57:01.590 --> 00:57:11.350
[ Applause ]

00:57:11.350 --> 00:57:15.440
&gt;&gt; So we're going to
have time for questions.

00:57:15.440 --> 00:57:18.730
So if Liz and Ricky if you
want to join us up here.

00:57:18.730 --> 00:57:23.070
Doing this we have about
15 minutes for questions,

00:57:23.070 --> 00:57:26.720
and if you have a question you're
in the audience raise your hand

00:57:26.720 --> 00:57:33.060
and we'll have volunteers with
the mics that will find you.

00:57:33.060 --> 00:57:35.850
I see we have one hand
raised in the back already.

00:57:35.850 --> 00:57:41.670
Also on Twitter, if you are
following along you can tweet your

00:57:41.670 --> 00:57:44.420
questions using the
hash tag "as data."

00:57:44.420 --> 00:57:47.760
So, again,, we'll take
questions for about 15 minutes.

00:57:47.760 --> 00:57:49.660
I'm going to mention this
quickly because we might -

00:57:49.660 --> 00:57:52.850
because we'll just break
for lunch right after.

00:57:52.850 --> 00:57:56.560
We're going to break until
1:30 after the question round.

00:57:56.560 --> 00:57:59.800
And just a reminder you have to
if you leave the building you have

00:57:59.800 --> 00:58:02.110
to pass through security
to get back in.

00:58:02.110 --> 00:58:07.230
So come back, plan for that
if you leave the building.

00:58:07.230 --> 00:58:09.010
If you don't want to
leave the building,

00:58:09.010 --> 00:58:11.800
you can go to our main cafeteria

00:58:11.800 --> 00:58:14.100
in the Madison building
via some tunnels.

00:58:14.100 --> 00:58:16.790
And if you meet by the
information desk then a Library

00:58:16.790 --> 00:58:19.600
of Congress staff will help
you go through those tunnels.

00:58:19.600 --> 00:58:24.280
So just that quick
piece before we start.

00:58:24.280 --> 00:58:26.490
Do we have somebody with a
microphone in the back here.

00:58:26.490 --> 00:58:27.790
Yes, please go ahead.

00:58:35.160 --> 00:58:36.460
You want to start back here?

00:58:41.140 --> 00:58:45.440
&gt;&gt; Hello. I'm [inaudible], I'm
from the Smithsonian libraries,

00:58:45.440 --> 00:58:48.310
the Smithsonian transcription
Center and the National Museum

00:58:48.310 --> 00:58:50.040
of African-American
History and Culture.

00:58:50.040 --> 00:58:56.320 position:56%
We launched recently a transcription
project transcribing the Freedman

00:58:56.320 --> 00:59:00.730
Spieler Records, a reconstruction
era, a group of federal documents

00:59:00.730 --> 00:59:04.160
and we launched it just a
little over a month ago.

00:59:04.160 --> 00:59:09.310 position:56%
My question to the last speaker is
what kind of incentives do you offer

00:59:09.310 --> 00:59:14.060
to your volunteers to
continue with the process?

00:59:14.060 --> 00:59:16.240
How do you deal with
some of the difficulties

00:59:16.240 --> 00:59:19.290
of the challenges with
the transcription.

00:59:19.290 --> 00:59:23.890
What kind of system do you
have to keep them going.

00:59:25.170 --> 00:59:26.470
&gt;&gt; I can [inaudible].

00:59:26.470 --> 00:59:27.770
Okay.

00:59:27.770 --> 00:59:29.080
So, yes, the transcription
is challenging.

00:59:29.080 --> 00:59:34.850
So it's difficult to
keep volunteers engaged.

00:59:34.850 --> 00:59:39.080
We have found that talk in
the community that builds

00:59:39.080 --> 00:59:43.750
around these projects is
really the strongest way

00:59:43.750 --> 00:59:45.850
to keep people engaged.

00:59:45.850 --> 00:59:52.980
And that not only helps
people ask questions or get

00:59:52.980 --> 00:59:56.230
through the difficult
challenges that might be related

00:59:56.230 --> 00:59:59.210
to that specific transcription
project,

00:59:59.210 --> 01:00:02.470
but it also helps people
explore interesting ideas

01:00:02.470 --> 01:00:03.770
that they may have.

01:00:03.770 --> 01:00:05.670
Because usually the people
who are getting involved

01:00:05.670 --> 01:00:08.460
in these transmission projects
have their interest in the material

01:00:08.460 --> 01:00:15.270
of course, and they may have,
you know, they come to it

01:00:15.270 --> 01:00:18.540
with interesting ideas
or ways perspectives.

01:00:18.540 --> 01:00:23.790
And when you have people sharing
this together through the art form

01:00:23.790 --> 01:00:27.090
of talk it just builds on itself.

01:00:27.090 --> 01:00:33.110 position:56%
And that's what keeps people engaged
I think to the highest degree.

01:00:33.110 --> 01:00:41.260 position:56%
We don't have any other, like I mean
occasionally our research team might

01:00:41.260 --> 01:00:43.900
have like prizes or, you
know, giveaways or whatnot,

01:00:43.900 --> 01:00:47.740
but that's really not
the core of it.

01:00:47.740 --> 01:00:55.470
I mean in all honestly, one of the
smaller points is like the people

01:00:55.470 --> 01:00:58.450
who participate and continue to
participate just because they want

01:00:58.450 --> 01:01:01.820
to further the purpose
of the project.

01:01:01.820 --> 01:01:04.610
So it's really a lot of our
volunteers are primarily motivated

01:01:04.610 --> 01:01:08.660
by their altruism, so and they
get kind of hooked into it.

01:01:08.660 --> 01:01:14.820 position:56%
And once they get a little practice
transcribing they often continue to.

01:01:14.820 --> 01:01:18.150
Hope that answered.

01:01:18.150 --> 01:01:21.000
&gt;&gt; Great we have another
question here.

01:01:21.000 --> 01:01:22.600
Right here?

01:01:22.600 --> 01:01:23.900
&gt;&gt; Yes.

01:01:23.900 --> 01:01:25.200
&gt;&gt; Go ahead.

01:01:25.200 --> 01:01:27.090
&gt;&gt; This question is also
for the last speaker.

01:01:27.090 --> 01:01:32.190
For the tools that you mentioned
and I'm actually really interested

01:01:32.190 --> 01:01:36.530
in your audio tool that I
think is going to come out.

01:01:36.530 --> 01:01:39.790
Are you limited to what
language you can apply this to?

01:01:39.790 --> 01:01:47.560
Like if I have a collection in say
Czech, could that work on that?

01:01:47.560 --> 01:01:53.100
&gt;&gt; Well so I'd have to
check - so I'm just kind

01:01:53.100 --> 01:01:56.210
of just thinking out loud here.

01:01:56.210 --> 01:01:59.300
We could build like a UI
that could support that.

01:01:59.300 --> 01:02:01.440
That would be a custom.

01:02:01.440 --> 01:02:04.390
Currently I'm not sure if
we have that capability,

01:02:04.390 --> 01:02:08.000
but that would be a
custom project that is,

01:02:08.000 --> 01:02:10.620
you know, potentially feasible.

01:02:11.700 --> 01:02:17.170
We have lots of plans,
including internationalization.

01:02:17.170 --> 01:02:22.480 position:56%
So if we were to incorporate that on

01:02:22.480 --> 01:02:27.280
like a global site level it might
also complement a specific project

01:02:27.280 --> 01:02:28.580
or collection.

01:02:28.580 --> 01:02:29.880
You said in Czech?

01:02:29.880 --> 01:02:32.390
&gt;&gt; Yes.

01:02:32.390 --> 01:02:38.420
&gt;&gt; Yes, so you know I don't
think we will be able to - well.

01:02:38.420 --> 01:02:40.560
Support that today.

01:02:40.560 --> 01:02:47.470
But the technological
barriers don't seem too large.

01:02:47.470 --> 01:02:52.690 position:56%
That's the wonderful thing about
the recent funding is we can explore

01:02:52.690 --> 01:02:56.830
these types of challenges that
much more easily now going forward.

01:02:56.830 --> 01:03:00.750
So I'd have to check to give
you a specific direct answer

01:03:00.750 --> 01:03:04.150
of what we can do today,
but if we can't we hope

01:03:04.150 --> 01:03:06.450
to in the future [laughs].

01:03:08.400 --> 01:03:11.030
&gt;&gt; We have a couple
questions down here.

01:03:14.410 --> 01:03:20.260
&gt;&gt; Hi, I also am interested in
the project of the last speaker

01:03:20.260 --> 01:03:23.240
and I'm coming at it
from a peculiar angle,

01:03:23.240 --> 01:03:26.770
which is that I've spent
some time as a volunteer

01:03:26.770 --> 01:03:30.770
in senior living residences
and one of the issues there is

01:03:30.770 --> 01:03:34.660
that everybody is limited
in what they can do.

01:03:34.660 --> 01:03:38.190
So some of the projects that
have been very successful

01:03:38.190 --> 01:03:44.570
in that environment until now have
been seniors doing English language

01:03:44.570 --> 01:03:48.590
teaching using Skype with
students are from around the world.

01:03:48.590 --> 01:03:51.740
And that's super successful and
I can imagine that some version

01:03:51.740 --> 01:03:55.080
of this could apply in
that environment as well.

01:03:55.080 --> 01:03:57.430
But I'm just thinking
is there a possibility

01:03:57.430 --> 01:04:03.910
that there could be let's say
a simpler interface overlaid

01:04:03.910 --> 01:04:08.890 position:56%
on what you have now, so that people
with a lot of time on their hands,

01:04:08.890 --> 01:04:13.850
but limited abilities could
be effective and useful

01:04:13.850 --> 01:04:17.250
and have some productive
activity in their own lives?

01:04:17.250 --> 01:04:24.460 position:56%
&gt;&gt; Yeah. Absolutely and the projects
really run, there's a wide range

01:04:24.460 --> 01:04:26.460
of difficulty in our projects.

01:04:26.460 --> 01:04:28.490
Some currently up there right now

01:04:28.490 --> 01:04:30.900
and actually I guess I
should be embarrassed

01:04:30.900 --> 01:04:32.200
to admit this, but I'm not.

01:04:32.200 --> 01:04:33.500
My favorite is like
the penguin watch

01:04:33.500 --> 01:04:38.920
and Snapshot Serengeti
are very approachable.

01:04:38.920 --> 01:04:45.290
And while some certainly are
more complicated like some

01:04:45.290 --> 01:04:47.420
of the astronomy projects,

01:04:47.420 --> 01:04:50.990
some of the transcription
projects there are some

01:04:50.990 --> 01:04:55.720
that I think would be very
accessible to, you know,

01:04:55.720 --> 01:04:59.240
like the people that
you're working with.

01:04:59.240 --> 01:05:06.370
And sometimes we will, you know,
we do all educational outreach too,

01:05:06.370 --> 01:05:13.900
so we do try to consider
making the projects accessible

01:05:13.900 --> 01:05:16.220
to as many people as we can.

01:05:16.220 --> 01:05:18.600
But that's, yeah, that's
an interesting,

01:05:18.600 --> 01:05:22.230
you know, area of opportunity.

01:05:22.230 --> 01:05:26.340
I'm not sure if we've
fully considered,

01:05:26.340 --> 01:05:31.830
but I would think right now there
actually would be some projects

01:05:31.830 --> 01:05:35.100
that might apply.

01:05:35.100 --> 01:05:37.920
&gt;&gt; Another question here.

01:05:37.920 --> 01:05:41.740
Down here, down here.

01:05:41.740 --> 01:05:45.300
&gt;&gt; Hi. I work for a data storage
company, so often we think

01:05:45.300 --> 01:05:48.780
about how we're going
to store all that stuff.

01:05:48.780 --> 01:05:52.260
So all of you store
mountains of data, right.

01:05:52.260 --> 01:05:54.270
You're all working
with that all the time.

01:05:54.270 --> 01:05:59.740
So my question would be how do
you possibly store all of that?

01:05:59.740 --> 01:06:02.310
And then how long do you store it?

01:06:02.310 --> 01:06:07.370
And then how is it similar
or different for each of you,

01:06:07.370 --> 01:06:15.180
because you have such different
projects in a lot of ways.

01:06:15.180 --> 01:06:19.330
&gt;&gt; [laughs] So for our project.

01:06:19.330 --> 01:06:26.680
At this point we have a
manageable amount of data,

01:06:26.680 --> 01:06:32.310
because we're maintaining the
images after we process them

01:06:32.310 --> 01:06:35.950
and then the featured data sets.

01:06:35.950 --> 01:06:40.550
I'm at an institution that
has both a data repository -

01:06:40.550 --> 01:06:42.360
has a data repository.

01:06:42.360 --> 01:06:47.310
And the expectation that the
institution will be the place

01:06:47.310 --> 01:06:52.220
that manages that data, so and we
have a number of systems in place,

01:06:52.220 --> 01:06:55.940
and so we work with
Deepen as one example.

01:06:55.940 --> 01:07:01.920 position:56%
So we'll have to see and since we're
not - our needs are not necessarily

01:07:01.920 --> 01:07:06.740 position:56%
for - it's not preservation forever,
we're looking at managing the data

01:07:06.740 --> 01:07:09.970
for reproducibility
over X number of years.

01:07:09.970 --> 01:07:13.510
And I think our plan at
this point is five years.

01:07:13.510 --> 01:07:18.060
So since we are not the
collector of the original images

01:07:18.060 --> 01:07:20.450
and we don't need to maintain the
digital images, it's not to say

01:07:20.450 --> 01:07:24.040
that we don't have we may
not run into some challenges,

01:07:24.040 --> 01:07:26.510
but I feel like institutionally
we're

01:07:26.510 --> 01:07:29.570
in a pretty good place for that.

01:07:29.570 --> 01:07:31.610
&gt;&gt; Well with me it's the same.

01:07:31.610 --> 01:07:37.960
I do have copies of some of the
photos that I study and I believe

01:07:37.960 --> 01:07:41.040
in lots of copies keep stuff safe.

01:07:41.040 --> 01:07:45.020
So I put them in multiple
hard drives.

01:07:45.020 --> 01:07:50.520
I also have copies that, you know,

01:07:50.520 --> 01:07:56.250
I use for just basic
processing and work.

01:07:56.250 --> 01:08:01.330
So I have a digital file that's,
you know, better resolution and,

01:08:01.330 --> 01:08:03.110
you know, more preservation copied.

01:08:03.110 --> 01:08:07.640
So I teach introduction to
digital curation, so I kind of have

01:08:07.640 --> 01:08:11.350
to follow what I teach,
which is, you know,

01:08:11.350 --> 01:08:14.470
like the [inaudible]
model of doing things.

01:08:14.470 --> 01:08:20.430
But, yeah, but I'm not - I
definitely don't have collections

01:08:20.430 --> 01:08:24.930
of the level of a repository
that would make, you know,

01:08:24.930 --> 01:08:29.400
large [inaudible] materials,
such a daunting task.

01:08:29.400 --> 01:08:34.550
&gt;&gt; And we actually also we're
not necessarily responsible

01:08:34.550 --> 01:08:40.310 position:56%
for maintaining the, like the
images or the collections over time.

01:08:40.310 --> 01:08:45.130
Someone who's going to create a
project they're really the ones

01:08:45.130 --> 01:08:50.910
who are responsible for over the
long-term maintaining and storing

01:08:50.910 --> 01:08:54.830
and organizing those -
in our case often images.

01:08:54.830 --> 01:08:59.860
But just from a like a technical
standpoint, we use AWOS,

01:08:59.860 --> 01:09:03.430
Amazon Web Services to host
a lot of our information.

01:09:03.430 --> 01:09:08.330
So I guess we're in the
cloud for the most part.

01:09:08.330 --> 01:09:12.900
And actually I'm a front end
developer, so I'm somewhat ignorant

01:09:12.900 --> 01:09:18.140
in terms of the entire back
end picture or ops picture.

01:09:18.140 --> 01:09:22.730
But. I think, yeah,
essentially it sounds

01:09:22.730 --> 01:09:24.270
like we're actually all
kind of somewhat similar.

01:09:24.270 --> 01:09:25.570
[laughs]

01:09:25.570 --> 01:09:27.650
&gt;&gt; All right, so I think we
have time for one more question.

01:09:27.650 --> 01:09:30.000
And I have one up here in the back.

01:09:30.000 --> 01:09:31.920
&gt;&gt; Hi this question is for Ricky.

01:09:31.920 --> 01:09:34.590
Ricky, I was very intrigued
by your grid

01:09:34.590 --> 01:09:39.580
to analyze the virtual
reunification, and I wonder if the,

01:09:39.580 --> 01:09:43.020
you know, the providential
geographical et cetera.

01:09:43.020 --> 01:09:47.410
I wonder if these have been
used for Indigenous collections

01:09:47.410 --> 01:09:50.780
or is it typically for
Anthropological field work.

01:09:50.780 --> 01:10:04.690
&gt;&gt; So. The model that I did was
primarily to explain the complexity

01:10:04.690 --> 01:10:08.830
of virtual reunification
for mainly people who are

01:10:08.830 --> 01:10:11.010
in charge of collections.

01:10:11.010 --> 01:10:16.380
Because I do tell them that,
you know, if you are trying

01:10:16.380 --> 01:10:20.270
to capture the whole
you need to have some -

01:10:20.270 --> 01:10:25.050
at this point I don't
think it's possible.

01:10:25.050 --> 01:10:29.880
So, you know, to consider this
is a way to analyze the problem

01:10:29.880 --> 01:10:34.300
for yourself, and, you
know, create representations

01:10:34.300 --> 01:10:37.450
that would somewhat
allow the representation

01:10:37.450 --> 01:10:40.320
of these different
aspects of dispersion.

01:10:40.320 --> 01:10:48.110
Now, whether - so this is mainly
for [inaudible] collections

01:10:48.110 --> 01:10:51.810
that a project that's
recently funded

01:10:51.810 --> 01:10:54.620
by IMLS called Valuing our Scans.

01:10:54.620 --> 01:10:58.560
And this goes to communities
are looking at the impact

01:10:58.560 --> 01:11:03.440
of digitized collections once,
you know, they're downloaded.

01:11:03.440 --> 01:11:08.570
Because we are quite good at
doing research on like how do we,

01:11:08.570 --> 01:11:11.380
you know, discoverability,
you know, when you search

01:11:11.380 --> 01:11:13.120
for something how quickly
can you get

01:11:13.120 --> 01:11:15.030
at something that you're
looking for.

01:11:15.030 --> 01:11:21.410
But what happens once the image is
taken by a person into their homes?

01:11:21.410 --> 01:11:22.710
What happens?

01:11:22.710 --> 01:11:24.010
Do they keep it?

01:11:24.010 --> 01:11:25.310
Do they use it for something else?

01:11:25.310 --> 01:11:26.610 position:56%
You know, what's the impact of this?

01:11:26.610 --> 01:11:33.260
So I'm taking that model more to
inform my research on that project.

01:11:33.260 --> 01:11:38.420
So, yes, this is an
ongoing conversation,

01:11:38.420 --> 01:11:40.050
if I would put it that way.

01:11:40.050 --> 01:11:47.800
So, you know, I'm definitely
learning a lot since I move on.

01:11:47.800 --> 01:11:49.100
&gt;&gt; OK. Thank you.

01:11:49.100 --> 01:11:51.020
So we'll have to break
here for lunch.

01:11:51.020 --> 01:11:55.510
Again, meet back here at 1:30
and leave time for security.

01:11:55.510 --> 01:11:59.730
[ Applause ]

01:11:59.730 --> 01:12:03.430
&gt;&gt; This has been a presentation
of the Library of Congress.

01:12:03.430 --> 01:12:05.800
Visit us LOC.gov.

