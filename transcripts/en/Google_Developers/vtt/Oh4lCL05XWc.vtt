WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.444
[GOOGLE LOGO MUSIC]

00:00:04.920 --> 00:00:07.530
MANDY CHAN: So
welcome to our talk,

00:00:07.530 --> 00:00:12.120
How to Build Actions for Smart
Displays and More Devices.

00:00:12.120 --> 00:00:13.530
I'm Mandy Chan.

00:00:13.530 --> 00:00:17.310
I'm a developer advocate for
the Actions on Google Team.

00:00:17.310 --> 00:00:20.220
I'm very passionate about
improving the developer

00:00:20.220 --> 00:00:21.420
experience.

00:00:21.420 --> 00:00:24.360
And that mean I care about
you and your experience

00:00:24.360 --> 00:00:25.740
on our platform.

00:00:25.740 --> 00:00:26.970
During our talk-- oh, sorry.

00:00:26.970 --> 00:00:28.260
DARLA SHARP: That's OK.

00:00:28.260 --> 00:00:31.750
MANDY CHAN: During our talk, if
you find something interesting,

00:00:31.750 --> 00:00:34.110
and you want to
share it, please use

00:00:34.110 --> 00:00:38.271
the hashtag #AoGDev on Twitter.

00:00:38.271 --> 00:00:39.570
DARLA SHARP: And I'm Darla.

00:00:39.570 --> 00:00:42.360
I'm a conversation designer
on the Google Assistant.

00:00:42.360 --> 00:00:44.790
I work on how the
Assistant looks and sounds

00:00:44.790 --> 00:00:48.030
across all our devices, with
the hope that it's consistent,

00:00:48.030 --> 00:00:51.750
useful, and, dare I say, fun
to use from time to time.

00:00:51.750 --> 00:00:53.250
Today, we're going
to talk about how

00:00:53.250 --> 00:00:56.340
we combined our powers as
a designer and a developer

00:00:56.340 --> 00:00:58.710
to create a custom
Action on Google,

00:00:58.710 --> 00:01:02.800
and share with you what
we learned along the way.

00:01:02.800 --> 00:01:04.950
MANDY CHAN: So there
are many different ways

00:01:04.950 --> 00:01:07.230
you can build for
the Google Assistant.

00:01:07.230 --> 00:01:09.300
If you're an Android
app developer,

00:01:09.300 --> 00:01:11.860
you can build what
we call app Actions.

00:01:11.860 --> 00:01:16.810
If you are a content owner, you
can build how-to actions or FAQ

00:01:16.810 --> 00:01:19.920
actions quickly by
using our templates.

00:01:19.920 --> 00:01:21.990
In this talk, we
will be focusing

00:01:21.990 --> 00:01:26.840
on building a custom action,
in particular, a game action.

00:01:26.840 --> 00:01:28.680
You will leave this
talk with a strategy

00:01:28.680 --> 00:01:32.610
on how to build a multi-model
experience that scales

00:01:32.610 --> 00:01:34.870
across different devices.

00:01:34.870 --> 00:01:39.000
So you can see on the screen,
we have different tools

00:01:39.000 --> 00:01:41.670
that we used to build this game.

00:01:41.670 --> 00:01:43.970
First one is Dialogflow.

00:01:43.970 --> 00:01:48.480
It make it very straightforward
to build a custom actions.

00:01:48.480 --> 00:01:52.380
It turn unstructured
natural language input

00:01:52.380 --> 00:01:56.790
into a structure representation
that my endpoint can consume.

00:01:56.790 --> 00:01:59.220
Under the hood,
Dialogflow is built

00:01:59.220 --> 00:02:02.010
on the Google's machine
learning and natural language

00:02:02.010 --> 00:02:03.840
understanding.

00:02:03.840 --> 00:02:07.420
Firebase is a mobile
and web development

00:02:07.420 --> 00:02:11.290
platform that allows you to
scale your application quickly.

00:02:11.290 --> 00:02:14.720
And, for my game, I've
used Cloud Function, Cloud

00:02:14.720 --> 00:02:18.280
Firestore, as well
as Firebase Storage

00:02:18.280 --> 00:02:20.907
for my backend integration.

00:02:20.907 --> 00:02:22.990
DARLA SHARP: Mandy is
covering the important tools

00:02:22.990 --> 00:02:25.390
you need in order to
build a custom Action.

00:02:25.390 --> 00:02:28.210
I'll be talking about how we
applied solid Conversation

00:02:28.210 --> 00:02:32.020
Design principles to ensure
it's a good experience.

00:02:32.020 --> 00:02:34.450
MANDY CHAN: Lastly,
Actions on Google

00:02:34.450 --> 00:02:39.010
is our developer platform that
allows you developers to extend

00:02:39.010 --> 00:02:41.360
the functionality for
the Google Assistant

00:02:41.360 --> 00:02:44.895
and build Actions to make your
user's life more productive,

00:02:44.895 --> 00:02:45.895
get things done quickly.

00:02:55.210 --> 00:02:58.090
So, for I/O this year,
I've been viewing

00:02:58.090 --> 00:03:00.580
this game called Virtual Pet.

00:03:00.580 --> 00:03:04.300
My initial motivation was to
understand from the developer

00:03:04.300 --> 00:03:08.680
perspective what it's like to
build a game on our platform.

00:03:08.680 --> 00:03:11.770
Before we dive into
the presentation,

00:03:11.770 --> 00:03:16.270
I want to give you a taste
of how the game start.

00:03:16.270 --> 00:03:22.558
And please pay attention to the
animation in the background.

00:03:22.558 --> 00:03:23.225
[VIDEO PLAYBACK]

00:03:23.225 --> 00:03:23.700
[DOOR CREAKS]

00:03:23.700 --> 00:03:24.200
[BELL RINGS]

00:03:24.200 --> 00:03:27.560
DARLA SHARP: Oh, look at
this super cute pet store.

00:03:27.560 --> 00:03:29.930
- Welcome to Super
Petz adoption event.

00:03:29.930 --> 00:03:31.490
I'm so glad you're here.

00:03:31.490 --> 00:03:33.950
Are you interested in
adopting a pet today?

00:03:33.950 --> 00:03:35.490
DARLA SHARP: Not it.

00:03:35.490 --> 00:03:37.970
MANDY CHAN: Yes, OK.

00:03:37.970 --> 00:03:38.690
- That's great.

00:03:38.690 --> 00:03:40.190
I'll be helping you today.

00:03:40.190 --> 00:03:41.730
It's nice to meet you.

00:03:41.730 --> 00:03:43.310
First things first,
what's your name

00:03:43.310 --> 00:03:47.650
that you'd like to put
on the adoption form?

00:03:47.650 --> 00:03:50.694
MANDY CHAN: Well, Mandy.

00:03:50.694 --> 00:03:52.170
[WRITING]

00:03:52.170 --> 00:03:53.700
- Nice to meet you, Mandy.

00:03:53.700 --> 00:03:56.140
Taking on a pet is a
big responsibility.

00:03:56.140 --> 00:03:59.440
So, if you don't mind, I'd like
to ask you a question or two.

00:03:59.440 --> 00:04:03.270
Now, a pet will need to be
fed and exercised every day.

00:04:03.270 --> 00:04:07.680
Are you going to be able to feed
and exercise your pet daily?

00:04:07.680 --> 00:04:08.730
MANDY CHAN: I think so.

00:04:08.730 --> 00:04:10.804
So, yes.

00:04:10.804 --> 00:04:13.140
[WRITING]

00:04:13.140 --> 00:04:14.020
- That's great.

00:04:14.020 --> 00:04:16.620
You seem qualified to
continue with the adoption.

00:04:16.620 --> 00:04:18.180
I'm somewhat of
a matchmaker when

00:04:18.180 --> 00:04:20.290
it comes to matching pets
with the right owner.

00:04:20.290 --> 00:04:22.710
And I think I have the
perfect pet for you.

00:04:22.710 --> 00:04:25.530
They're cute, furry, and
ready to be your best friend.

00:04:25.530 --> 00:04:26.478
Are you ready?

00:04:26.478 --> 00:04:28.110
[JOYFUL SQUEAL]

00:04:28.110 --> 00:04:30.330
MANDY CHAN: Yes, I
am totally ready.

00:04:34.560 --> 00:04:35.700
- The grand reveal--

00:04:35.700 --> 00:04:38.117
it's a hamster, just for you.

00:04:38.117 --> 00:04:38.700
[END PLAYBACK]

00:04:38.700 --> 00:04:41.100
[CHEERING AND APPLAUSE]

00:04:42.540 --> 00:04:47.130
MANDY CHAN: So everyone
meet Larry, my hamster, who

00:04:47.130 --> 00:04:49.810
inspired me to build this game.

00:04:49.810 --> 00:04:52.220
Larry is a little
bit shy right now.

00:04:52.220 --> 00:04:52.980
Hey, Larry.

00:04:52.980 --> 00:04:54.788
[CHUCKLES]

00:04:57.270 --> 00:05:02.590
So this is a historic
moment, the first hamster

00:05:02.590 --> 00:05:05.560
who attends I/O and
co-presenting at Google I/O

00:05:05.560 --> 00:05:06.370
Stage.

00:05:06.370 --> 00:05:09.481
So everyone please
give Larry a paw.

00:05:09.481 --> 00:05:12.427
[APPLAUSE]

00:05:16.846 --> 00:05:17.830
[VIDEO PLAYBACK]

00:05:17.830 --> 00:05:19.900
- Now, this hamster
needs a name.

00:05:19.900 --> 00:05:21.777
What do you think
the name should be?

00:05:21.777 --> 00:05:22.360
[END PLAYBACK]

00:05:22.360 --> 00:05:25.660
DARLA SHARP: Mandy, does this
hamster have credentials?

00:05:25.660 --> 00:05:27.280
MANDY CHAN: Well,
just like everybody

00:05:27.280 --> 00:05:30.760
else who is attending Google
I/O, we all have a badge.

00:05:30.760 --> 00:05:32.500
Larry is no exception.

00:05:32.500 --> 00:05:36.380
Telo, why don't we show
everyone Larry's I/O badge?

00:05:36.380 --> 00:05:39.760
Well, he actually-- that
one is too big for him.

00:05:39.760 --> 00:05:44.620
We actually make a legit
tiny one for Larry.

00:05:44.620 --> 00:05:46.780
The I/O team is
really like excited

00:05:46.780 --> 00:05:50.330
that we have first
hamster presenting at I/O.

00:05:50.330 --> 00:05:53.200
DARLA SHARP: OK, so I see his
name there is Larry Walnuts--

00:05:53.200 --> 00:05:53.500
MANDY CHAN: Right.

00:05:53.500 --> 00:05:53.770
DARLA SHARP:
--according to his--

00:05:53.770 --> 00:05:55.562
MANDY CHAN: Larry
Walnuts is his full name.

00:05:55.562 --> 00:05:58.735
DARLA SHARP: --his
identification.

00:05:58.735 --> 00:05:59.243
OK.

00:05:59.243 --> 00:05:59.910
[VIDEO PLAYBACK]

00:05:59.910 --> 00:06:01.380
- That's such a good name.

00:06:01.380 --> 00:06:03.120
Before you take your
pet home, there's

00:06:03.120 --> 00:06:04.980
a few things to mention.

00:06:04.980 --> 00:06:06.750
Be sure to check on
your pet every day.

00:06:06.750 --> 00:06:09.540
Otherwise, they may
get sick or hungry.

00:06:09.540 --> 00:06:10.960
[STAMP]

00:06:11.460 --> 00:06:12.887
Ready to bring Larry home?

00:06:12.887 --> 00:06:13.470
[END PLAYBACK]

00:06:13.470 --> 00:06:14.330
DARLA SHARP: Are we ready
to bring Larry home?

00:06:14.330 --> 00:06:15.780
MANDY CHAN: Yes.

00:06:15.780 --> 00:06:19.290
So Larry's full-time
job is taking a nap

00:06:19.290 --> 00:06:20.310
during the daytime.

00:06:20.310 --> 00:06:22.260
So, today, he make
extra effort to come

00:06:22.260 --> 00:06:25.650
to I/O. At nighttime,
he like to play.

00:06:25.650 --> 00:06:29.340
So why don't we let Larry get
back to work and take a nap?

00:06:29.340 --> 00:06:32.350
Thank you, Telo, for
bringing Larry to the stage.

00:06:32.350 --> 00:06:35.350
[APPLAUSE]

00:06:37.993 --> 00:06:40.410
DARLA SHARP: OK, so let's look
at what Larry's home really

00:06:40.410 --> 00:06:40.680
looks like--

00:06:40.680 --> 00:06:41.120
MANDY CHAN: Right.

00:06:41.120 --> 00:06:41.320
DARLA SHARP: --in the game.

00:06:41.320 --> 00:06:43.820
MANDY CHAN: How's Larry
home look like in the game?

00:06:46.784 --> 00:06:47.772
[VIDEO PLAYBACK]

00:06:47.772 --> 00:06:50.242
[FOOTSTEPS]

00:06:52.230 --> 00:06:54.870
- This looks like a very
cozy home for Larry.

00:06:54.870 --> 00:06:57.780
As a caring owner, you'll
be rewarded with badges.

00:06:57.780 --> 00:07:01.380
Collect the badges to unlock
new food and toys for your pet.

00:07:01.380 --> 00:07:03.977
Now, do you want to
feed or play with Larry?

00:07:03.977 --> 00:07:04.560
[END PLAYBACK]

00:07:04.560 --> 00:07:06.990
DARLA SHARP: So, as an
extra surprise today,

00:07:06.990 --> 00:07:09.360
everybody look
under your chairs.

00:07:09.360 --> 00:07:10.410
You get a hamster.

00:07:10.410 --> 00:07:11.880
You get a hamster.

00:07:11.880 --> 00:07:14.730
Everybody gets a Google hamster.

00:07:14.730 --> 00:07:15.390
Just kidding.

00:07:15.390 --> 00:07:17.250
That's a terrifying proposal.

00:07:17.250 --> 00:07:19.860
Nobody's getting
a hamster today.

00:07:19.860 --> 00:07:22.230
OK, let's get back to work.

00:07:22.230 --> 00:07:24.000
There are five
important concepts

00:07:24.000 --> 00:07:25.698
that we're going to
talk about today.

00:07:25.698 --> 00:07:27.990
We're going to talk about
each of these in more detail.

00:07:27.990 --> 00:07:31.390
But before we do, let's touch
on each of them briefly,

00:07:31.390 --> 00:07:33.880
so everybody knows
what to expect.

00:07:33.880 --> 00:07:36.870
So the first one is the voice
experience is the foundation.

00:07:36.870 --> 00:07:38.640
When it comes to
Actions on Google,

00:07:38.640 --> 00:07:40.440
it's not the device
or the screen

00:07:40.440 --> 00:07:42.310
that drives the experience.

00:07:42.310 --> 00:07:43.420
It's the voice.

00:07:43.420 --> 00:07:45.380
So when it comes to
Actions on Google,

00:07:45.380 --> 00:07:48.248
the voice experience is king.

00:07:48.248 --> 00:07:50.540
MANDY CHAN: Second lesson
that we want you to take away

00:07:50.540 --> 00:07:53.220
is use dialogue
to guide the user.

00:07:53.220 --> 00:07:56.660
And what that really
mean is set expectation

00:07:56.660 --> 00:07:58.670
and drive your
conversation forward

00:07:58.670 --> 00:08:01.835
by using questions
instead of statements.

00:08:01.835 --> 00:08:03.210
DARLA SHARP: We'll
talk about how

00:08:03.210 --> 00:08:06.390
to use Rich Responses to
augment your voice experience

00:08:06.390 --> 00:08:08.430
if your Action uses a screen.

00:08:08.430 --> 00:08:11.550
Rich Responses can visually
augment your Action, drive

00:08:11.550 --> 00:08:14.850
discoverability, and offload
information from your TTS

00:08:14.850 --> 00:08:17.070
prompts.

00:08:17.070 --> 00:08:20.560
MANDY CHAN: We will discuss
how to use Interactive Canvas,

00:08:20.560 --> 00:08:24.100
a new feature that we just
announced yesterday at I/O, how

00:08:24.100 --> 00:08:26.680
to really use Interactive
Canvas to create

00:08:26.680 --> 00:08:30.775
a immersive, dynamic gaming
experience for the user.

00:08:30.775 --> 00:08:32.650
DARLA SHARP: And finally,
you're not building

00:08:32.650 --> 00:08:35.020
unique experiences per device.

00:08:35.020 --> 00:08:40.289
You're building one cohesive
experience that scales.

00:08:40.289 --> 00:08:43.190
First, let's quickly talk
about the Assistant Devices.

00:08:43.190 --> 00:08:45.620
When it comes to building an
experience for the Assistant,

00:08:45.620 --> 00:08:48.502
there are many ways and
surfaces to reach users.

00:08:48.502 --> 00:08:50.210
What we're going to
do today is help you,

00:08:50.210 --> 00:08:53.690
the developers, reach users
through the 1 billion devices

00:08:53.690 --> 00:08:57.040
enabled with the
Google Assistant.

00:08:57.040 --> 00:08:59.740
MANDY CHAN: So by building
actions on our platform,

00:08:59.740 --> 00:09:02.560
we help you reach
billions of users.

00:09:02.560 --> 00:09:06.640
And all of these devices
support different capabilities.

00:09:06.640 --> 00:09:09.530
Currently, we support five
different capabilities.

00:09:09.530 --> 00:09:11.390
The first two are
pretty straightforward.

00:09:11.390 --> 00:09:13.600
Does your device
support screen output?

00:09:13.600 --> 00:09:17.020
And does your device
support audio output?

00:09:17.020 --> 00:09:20.170
Word process is pretty
straightforward, too.

00:09:20.170 --> 00:09:23.510
Does your device can
show a web browser?

00:09:23.510 --> 00:09:27.000
For example, Chromebook
and mobile phone.

00:09:27.000 --> 00:09:31.380
Media Response allows you
to play long audio files.

00:09:31.380 --> 00:09:35.100
Lastly, Custom Stage--
this is a new one that

00:09:35.100 --> 00:09:37.290
related to Interactive Canvas.

00:09:37.290 --> 00:09:40.500
If your device can support
Interactive Canvas,

00:09:40.500 --> 00:09:44.820
right now Interactive Canvas
are support on smart displays

00:09:44.820 --> 00:09:46.470
and Android forms.

00:09:46.470 --> 00:09:50.590
One thing in this slide I want
to point out is as a developer,

00:09:50.590 --> 00:09:53.340
you don't really know
the type of devices

00:09:53.340 --> 00:09:55.680
that your user trigger
your actions on.

00:09:55.680 --> 00:09:59.140
But you do know the
capabilities of that device.

00:09:59.140 --> 00:10:03.817
Remember, that's all you can
check, which is capabilities.

00:10:03.817 --> 00:10:05.400
DARLA SHARP: So now
that we've covered

00:10:05.400 --> 00:10:08.250
some of the overall capabilities
of the device spectrum

00:10:08.250 --> 00:10:11.190
and how to account for them in
the code, let's talk about how

00:10:11.190 --> 00:10:14.430
we manage to build one action
that scales to the top three

00:10:14.430 --> 00:10:16.080
popular devices--

00:10:16.080 --> 00:10:19.020
smart speakers, mobile,
and smart displays.

00:10:19.020 --> 00:10:21.810
These three devices cover
all the surface capabilities

00:10:21.810 --> 00:10:24.283
that Mandy just mentioned.

00:10:24.283 --> 00:10:25.950
MANDY CHAN: So let's
go through the game

00:10:25.950 --> 00:10:29.040
that we just demoed
earlier, the Virtual Pet.

00:10:29.040 --> 00:10:33.030
In this game, you will
first adopt a hamster.

00:10:33.030 --> 00:10:36.517
And just like any real pet
you have owned in real life,

00:10:36.517 --> 00:10:38.850
you need to make sure they're
happy by getting them lots

00:10:38.850 --> 00:10:41.010
of healthy food and exercise.

00:10:41.010 --> 00:10:44.630
As you can see, Larry
loves to go shopping.

00:10:44.630 --> 00:10:46.650
I will take you through
the actual process

00:10:46.650 --> 00:10:49.440
that we experienced when
we were building the game,

00:10:49.440 --> 00:10:52.360
showing you the
mistakes that we made,

00:10:52.360 --> 00:10:55.060
so you can learn from them.

00:10:55.060 --> 00:10:59.070
Let's talk about how the
game works and its flow.

00:10:59.070 --> 00:11:01.710
One of the motivations
behind me building this game

00:11:01.710 --> 00:11:05.730
is to maximize the capabilities
of different devices.

00:11:05.730 --> 00:11:09.180
To leverage the concept found
in traditional game plays,

00:11:09.180 --> 00:11:13.500
such as rewards, levels,
and managing states,

00:11:13.500 --> 00:11:16.090
let me walk through
this diagram quickly.

00:11:16.090 --> 00:11:19.510
First, when you enter the game,
you have to adopt the hamster.

00:11:19.510 --> 00:11:21.550
And then in the
orange area, this

00:11:21.550 --> 00:11:24.700
is everything you can do
after you adopt a pet.

00:11:24.700 --> 00:11:26.590
You can ask for
the pet's status.

00:11:26.590 --> 00:11:30.370
You can ask for what kind
of badges have you earned.

00:11:30.370 --> 00:11:32.680
During a game play,
you will be rewarded

00:11:32.680 --> 00:11:35.230
with different badges
based on the activities

00:11:35.230 --> 00:11:37.000
that you do with your pets.

00:11:37.000 --> 00:11:39.560
Once you collect
enough badges, you

00:11:39.560 --> 00:11:41.530
will progress to the next level.

00:11:41.530 --> 00:11:46.187
And the next level allows you
to unlock new toys for your pet.

00:11:46.187 --> 00:11:48.270
DARLA SHARP: So, when we
started working together,

00:11:48.270 --> 00:11:49.920
one of the first
questions we asked

00:11:49.920 --> 00:11:53.070
was, what device did we
think we should focus on?

00:11:53.070 --> 00:11:54.945
For us, it was
the Smart Display.

00:11:54.945 --> 00:11:56.820
We thought that beautiful
screen could really

00:11:56.820 --> 00:11:58.800
help bring Larry to life.

00:11:58.800 --> 00:12:00.330
So we started with
that and decided

00:12:00.330 --> 00:12:02.585
we'd focus on the
other devices later.

00:12:02.585 --> 00:12:03.960
So let's talk
about what the game

00:12:03.960 --> 00:12:05.820
was like before our
collaboration, what

00:12:05.820 --> 00:12:09.630
it was like after, and
the lessons we learned.

00:12:09.630 --> 00:12:11.790
MANDY CHAN: So when I
first built the game,

00:12:11.790 --> 00:12:14.910
I was very eager to
jump into the game play,

00:12:14.910 --> 00:12:17.470
because that's where
the magic happens--

00:12:17.470 --> 00:12:21.360
the images, the sound effects,
and all the creative aspect

00:12:21.360 --> 00:12:23.250
that go into the game.

00:12:23.250 --> 00:12:26.790
For example, for the greeting
experience of the game,

00:12:26.790 --> 00:12:30.510
I just jumped into what we call
the default welcoming tent.

00:12:30.510 --> 00:12:33.060
I didn't really think about
the narrative, the beginning

00:12:33.060 --> 00:12:34.270
of the experience.

00:12:34.270 --> 00:12:36.264
Let's listen.

00:12:36.264 --> 00:12:37.140
[VIDEO PLAYBACK]

00:12:37.140 --> 00:12:39.060
- Welcome to Virtual Pet Game.

00:12:39.060 --> 00:12:41.520
We have a lovely hamster
waiting for a home.

00:12:41.520 --> 00:12:44.627
Before we get started,
please tell me your name.

00:12:44.627 --> 00:12:45.210
[END PLAYBACK]

00:12:45.210 --> 00:12:48.060
MANDY CHAN: As you just heard,
the beginning experience

00:12:48.060 --> 00:12:49.970
was not very exciting.

00:12:49.970 --> 00:12:53.340
And it was really awkward that
you just jumped into and asked

00:12:53.340 --> 00:12:54.960
the user, what's your name?

00:12:54.960 --> 00:12:57.180
We need to give them the
reasons before we ask

00:12:57.180 --> 00:12:59.280
for any information like that.

00:12:59.280 --> 00:13:02.700
And all of this changed when
Darla asked me a few questions

00:13:02.700 --> 00:13:04.307
I didn't think before.

00:13:04.307 --> 00:13:06.390
DARLA SHARP: When Mandy
first showed me this game,

00:13:06.390 --> 00:13:09.330
one of the first questions
I had before I even

00:13:09.330 --> 00:13:13.080
wanted to tell the name was,
who's talking right now?

00:13:13.080 --> 00:13:16.950
Who is the "we" in we have
a lovely hamster waiting

00:13:16.950 --> 00:13:18.188
for a home?

00:13:18.188 --> 00:13:19.980
I hadn't even started
playing the game yet,

00:13:19.980 --> 00:13:22.330
and I was a little bit confused.

00:13:22.330 --> 00:13:24.480
This simple question,
who is talking,

00:13:24.480 --> 00:13:26.310
actually has pretty
profound implications

00:13:26.310 --> 00:13:28.230
for the work we needed to do.

00:13:28.230 --> 00:13:30.570
The primary one is that
we needed to focus first

00:13:30.570 --> 00:13:32.650
on the voice experience.

00:13:32.650 --> 00:13:35.530
Thanks so much to our
colleague, Darren Hilton,

00:13:35.530 --> 00:13:38.500
who did this amazing
artwork for this game,

00:13:38.500 --> 00:13:39.790
the artwork was solid.

00:13:39.790 --> 00:13:43.810
The voice experience
needed a little work.

00:13:43.810 --> 00:13:45.160
So we backed up the train.

00:13:45.160 --> 00:13:47.170
Rather than immediately
introducing the pet

00:13:47.170 --> 00:13:48.850
and asking for the
user's name, we

00:13:48.850 --> 00:13:51.850
created an entirely new
experience, a pet adoption

00:13:51.850 --> 00:13:52.870
experience.

00:13:52.870 --> 00:13:54.950
We start in a relatable
way, in getting

00:13:54.950 --> 00:13:58.570
users engaged by asking them if
they're ready to adopt a pet.

00:13:58.570 --> 00:14:01.620
Let's listen.

00:14:01.620 --> 00:14:03.080
[VIDEO PLAYBACK]

00:14:03.080 --> 00:14:05.480
- Welcome to Super
Petz adoption event.

00:14:05.480 --> 00:14:07.040
I'm so glad you're here.

00:14:07.040 --> 00:14:09.253
Are you interested in
adopting a pet today?

00:14:09.253 --> 00:14:09.980
[END PLAYBACK]

00:14:09.980 --> 00:14:11.300
DARLA SHARP: We'll talk
more about the rest

00:14:11.300 --> 00:14:13.740
of the pet adoption experience
here in a little bit.

00:14:13.740 --> 00:14:16.673
But the takeaway here is with
a little bit of creativity,

00:14:16.673 --> 00:14:18.590
and thinking about what
might be a natural way

00:14:18.590 --> 00:14:20.930
to talk to your users,
you can use dialogue

00:14:20.930 --> 00:14:24.862
to create a fun and
engaging experience.

00:14:24.862 --> 00:14:26.570
So this is something
we learned together.

00:14:26.570 --> 00:14:28.910
When we first asked
ourselves, what device

00:14:28.910 --> 00:14:31.670
should we build for,
that was a bit of a trap.

00:14:31.670 --> 00:14:34.880
It's common trap to try and
build for the smart display

00:14:34.880 --> 00:14:36.270
because it's got that screen.

00:14:36.270 --> 00:14:38.520
You can do so much
with that screen.

00:14:38.520 --> 00:14:40.650
But it's not the screen
that drives the experience.

00:14:40.650 --> 00:14:41.540
It's the voice.

00:14:41.540 --> 00:14:44.570
So one of the first and
most impactful lessons--

00:14:44.570 --> 00:14:46.160
focus on the voice.

00:14:46.160 --> 00:14:48.740
But if the voice experience
is the foundation,

00:14:48.740 --> 00:14:51.560
how do you do it well,
especially if you've never

00:14:51.560 --> 00:14:52.860
done it before?

00:14:52.860 --> 00:14:55.340
We're going to walk through
how conversation design applied

00:14:55.340 --> 00:14:58.370
to our game and then give you
lots of resources at the end

00:14:58.370 --> 00:15:00.890
to learn more.

00:15:00.890 --> 00:15:04.150
MANDY CHAN: You will see this
experience enrichment pyramid

00:15:04.150 --> 00:15:05.810
throughout our talk.

00:15:05.810 --> 00:15:09.170
And overall, the idea is
voice first is the foundation

00:15:09.170 --> 00:15:10.250
that we built on.

00:15:10.250 --> 00:15:13.610
Let's take a look
at what that mean.

00:15:13.610 --> 00:15:18.110
We developers, we tend to build
applications that are linear.

00:15:18.110 --> 00:15:20.450
We do things in sequence.

00:15:20.450 --> 00:15:23.000
Before we created the
pet store experience,

00:15:23.000 --> 00:15:26.300
the user was rushed
into feeding the pet.

00:15:26.300 --> 00:15:28.274
Let's take a listen.

00:15:28.274 --> 00:15:29.530
[VIDEO PLAYBACK]

00:15:29.530 --> 00:15:30.840
- Congratulations.

00:15:30.840 --> 00:15:32.090
You adopted Larry.

00:15:32.090 --> 00:15:33.780
Larry is a little hungry.

00:15:33.780 --> 00:15:36.060
Do you want to feed Larry
some broccoli, a carrot,

00:15:36.060 --> 00:15:37.290
or sunflower seeds?

00:15:37.290 --> 00:15:38.010
[END PLAYBACK]

00:15:38.010 --> 00:15:40.140
MANDY CHAN: So this
approach is actually not

00:15:40.140 --> 00:15:42.300
good for voice first experience.

00:15:42.300 --> 00:15:44.220
We don't do things
in linear when you

00:15:44.220 --> 00:15:47.210
develop a voice applications.

00:15:47.210 --> 00:15:50.030
DARLA SHARP: So my question
was, when Mandy showed me this,

00:15:50.030 --> 00:15:53.300
was, is feeding the
pet all you can do?

00:15:53.300 --> 00:15:55.490
By presenting this
one option, it sort of

00:15:55.490 --> 00:15:57.800
implied that that was it.

00:15:57.800 --> 00:16:01.040
So this, again, fairly simple
question of what can you do

00:16:01.040 --> 00:16:03.080
has pretty profound
implications.

00:16:03.080 --> 00:16:05.720
For us, it meant that we
needed to solve what we often

00:16:05.720 --> 00:16:07.760
call the discovery problem.

00:16:07.760 --> 00:16:10.250
This is a common problem
in voice interactions.

00:16:10.250 --> 00:16:12.620
If users can't see the
options, how are they

00:16:12.620 --> 00:16:14.210
going to know what they can do?

00:16:14.210 --> 00:16:16.670
For us, there was many
unresolved aspects

00:16:16.670 --> 00:16:18.590
that Mandy had
built into the game

00:16:18.590 --> 00:16:21.770
that we needed to figure
out how to share with users.

00:16:21.770 --> 00:16:23.840
So one thing you need
to ask yourself is,

00:16:23.840 --> 00:16:25.790
how do you do this
in the real world?

00:16:25.790 --> 00:16:28.200
If I want to tell you all
the things you need to know,

00:16:28.200 --> 00:16:30.590
I don't just tell you all
of the things right away.

00:16:30.590 --> 00:16:32.420
I tell you a little
bit at a time

00:16:32.420 --> 00:16:34.400
in a way that makes
sense using something

00:16:34.400 --> 00:16:36.590
we call progressive disclosure.

00:16:36.590 --> 00:16:38.870
So we built in this
pet store experience

00:16:38.870 --> 00:16:40.610
to the beginning of
the game, so that we

00:16:40.610 --> 00:16:42.560
could use progressive
disclosure to have

00:16:42.560 --> 00:16:46.380
an engaging conversation
with the user.

00:16:46.380 --> 00:16:48.890
So after the user has
entered the pet store,

00:16:48.890 --> 00:16:51.170
we built in a
pre-adoption interview

00:16:51.170 --> 00:16:53.190
to teach the user the game.

00:16:53.190 --> 00:16:55.430
Think about what happens
when you adopt a pet.

00:16:55.430 --> 00:16:57.138
They want to make sure
you're going to be

00:16:57.138 --> 00:16:58.820
able to take care of it, right?

00:16:58.820 --> 00:17:00.875
Let's take a listen.

00:17:00.875 --> 00:17:02.150
[VIDEO PLAYBACK]

00:17:02.150 --> 00:17:03.200
- Nice to meet you.

00:17:03.200 --> 00:17:05.640
Taking on a pet is a
big responsibility.

00:17:05.640 --> 00:17:08.910
So if you don't mind, I'd like
to ask you a question or two.

00:17:08.910 --> 00:17:12.770
Now, a pet will need to be
fed and exercised every day.

00:17:12.770 --> 00:17:15.560
Are you going to be able to feed
and exercise your pet daily?

00:17:15.560 --> 00:17:16.339
[END PLAYBACK]

00:17:16.339 --> 00:17:17.881
DARLA SHARP: So with
this one prompt,

00:17:17.881 --> 00:17:20.609
we were able to do two
really important things.

00:17:20.609 --> 00:17:22.250
One, we taught
the user that this

00:17:22.250 --> 00:17:25.940
is not a one-time game that you
play once and don't come back.

00:17:25.940 --> 00:17:29.090
We wanted you to come back
every day, take care of your pet

00:17:29.090 --> 00:17:31.010
like you would a real pet.

00:17:31.010 --> 00:17:33.920
So this is one way we
hope to drive engagement.

00:17:33.920 --> 00:17:35.660
Another thing we
mentioned here is

00:17:35.660 --> 00:17:39.050
that you need to feed
and exercise your pet.

00:17:39.050 --> 00:17:41.240
So now we use dialogue
to teach the user

00:17:41.240 --> 00:17:42.680
the expectations of the game.

00:17:45.230 --> 00:17:47.540
So another big
lesson here, when you

00:17:47.540 --> 00:17:51.320
have the multimodal experience
and you focus on the voice,

00:17:51.320 --> 00:17:54.200
dialogue is how the
action gets moved forward.

00:17:54.200 --> 00:17:57.800
Have fun, use progressive
disclosure to guide the user.

00:17:57.800 --> 00:17:59.540
One important thing
to keep in mind

00:17:59.540 --> 00:18:02.420
when using dialogue to drive
the experience forward is you

00:18:02.420 --> 00:18:04.970
want to always make sure
it's really clear when

00:18:04.970 --> 00:18:07.160
it's the user's turn to talk.

00:18:07.160 --> 00:18:12.830
Use questions, the more focused
the question, the better.

00:18:12.830 --> 00:18:15.320
There's a few things to
keep in mind when creating

00:18:15.320 --> 00:18:17.450
a complete voice experience.

00:18:17.450 --> 00:18:19.460
Once you start
building dialogues,

00:18:19.460 --> 00:18:23.340
keep in mind for every yes
path, there's a no path.

00:18:23.340 --> 00:18:27.720
So for the question we had, are
you ready to adopt a pet today?

00:18:27.720 --> 00:18:28.970
MANDY CHAN: Nope.

00:18:28.970 --> 00:18:31.170
DARLA SHARP: What's
your action going to do?

00:18:31.170 --> 00:18:32.900
What if the user says
something outside

00:18:32.900 --> 00:18:36.390
of the very one specific thing
you intend for them to say?

00:18:36.390 --> 00:18:39.440
So if I say, are you ready
to adopt a pet today?

00:18:39.440 --> 00:18:40.907
MANDY CHAN: Potato.

00:18:40.907 --> 00:18:42.740
DARLA SHARP: What's
your action going to do?

00:18:42.740 --> 00:18:45.320
It's important that you have
a way to get your users back

00:18:45.320 --> 00:18:46.500
on track.

00:18:46.500 --> 00:18:48.530
So by nature, your
voice experience

00:18:48.530 --> 00:18:52.190
needs to have several
branches here.

00:18:52.190 --> 00:18:54.740
This way, you've counted
not only for the one

00:18:54.740 --> 00:18:57.380
thing you expect users to
say, but all the things

00:18:57.380 --> 00:18:59.420
they reasonably can say.

00:18:59.420 --> 00:19:03.140
If your action doesn't
have many branching paths,

00:19:03.140 --> 00:19:08.520
you've probably only built for
one instead of all of them.

00:19:08.520 --> 00:19:10.520
So let's look at a
couple of ways we added

00:19:10.520 --> 00:19:13.550
branching into Mandy's game.

00:19:13.550 --> 00:19:16.610
So one, when a user
comes back to this game,

00:19:16.610 --> 00:19:19.370
depending on how long it had
been since they had played,

00:19:19.370 --> 00:19:21.620
they'd be greeted with
a different greeting.

00:19:21.620 --> 00:19:24.680
Depending on whether they were
a good owner, an iffy owner,

00:19:24.680 --> 00:19:27.440
or a bad owner, they'd
hear a different prompt.

00:19:27.440 --> 00:19:30.470
Even within these modules
of good owner, iffy owner,

00:19:30.470 --> 00:19:33.830
and bad owner, we have
several variants within that.

00:19:33.830 --> 00:19:35.900
This is important,
especially with games

00:19:35.900 --> 00:19:38.653
like this that you expect
users to come back many times.

00:19:38.653 --> 00:19:40.070
You want to make
sure that they're

00:19:40.070 --> 00:19:42.680
greeted in a dynamic way
and not always getting

00:19:42.680 --> 00:19:44.930
the same experience.

00:19:44.930 --> 00:19:48.140
Another way that we added in
some branching to Mandy's game

00:19:48.140 --> 00:19:52.280
was now that users know how to
feed and exercise their pet,

00:19:52.280 --> 00:19:55.100
what happens if they don't stop?

00:19:55.100 --> 00:19:56.840
They could potentially
get stuck in what

00:19:56.840 --> 00:19:58.740
we call an infinite loop.

00:19:58.740 --> 00:20:00.860
This is harder to do
in visual interfaces

00:20:00.860 --> 00:20:03.170
but is a common trap
in voice interactions

00:20:03.170 --> 00:20:04.650
if you're not careful.

00:20:04.650 --> 00:20:06.620
So what we did was
build in a mechanism

00:20:06.620 --> 00:20:08.660
to track how many
times that day they

00:20:08.660 --> 00:20:11.390
had interacted with the action
by feeding or exercising

00:20:11.390 --> 00:20:12.290
their pet.

00:20:12.290 --> 00:20:14.240
If they reached
the threshold, now,

00:20:14.240 --> 00:20:16.460
instead of continuing
forever, they'd

00:20:16.460 --> 00:20:19.830
get a notification
that was saying, hey,

00:20:19.830 --> 00:20:22.070
your pet is really
tired or full.

00:20:22.070 --> 00:20:26.290
Come back tomorrow to
interact with your pet.

00:20:26.290 --> 00:20:28.060
MANDY CHAN: So we
talk about this,

00:20:28.060 --> 00:20:31.460
the importance of building
a voice first experience.

00:20:31.460 --> 00:20:35.800
Darla just mentioned branching
out your dialogue is one way.

00:20:35.800 --> 00:20:38.890
There are two other
simple, yet powerful ways

00:20:38.890 --> 00:20:42.070
to create that solid
voice first experience.

00:20:42.070 --> 00:20:45.190
First one is SSML, which
allows you to create

00:20:45.190 --> 00:20:46.910
layers for your actions.

00:20:46.910 --> 00:20:48.400
You can create pauses.

00:20:48.400 --> 00:20:51.280
You can change the volume
and pitch of the voice.

00:20:51.280 --> 00:20:54.340
You can even add ambient
sound in the background

00:20:54.340 --> 00:20:57.340
when the spoken
prompt is playing.

00:20:57.340 --> 00:21:00.430
Second one is for
developers who don't

00:21:00.430 --> 00:21:03.250
have a professional audio team.

00:21:03.250 --> 00:21:06.880
We at Google provide
you the Sound Library

00:21:06.880 --> 00:21:13.030
you can use to create
that immersive experience.

00:21:13.030 --> 00:21:15.450
What I like about the
Sound Library is it's

00:21:15.450 --> 00:21:17.340
organized by categories.

00:21:17.340 --> 00:21:21.020
You can find animal sounds,
cartoons, science fiction.

00:21:21.020 --> 00:21:22.970
It's even searchable.

00:21:22.970 --> 00:21:27.220
So another thing is
it's completely free.

00:21:27.220 --> 00:21:29.280
So take advantage
of them, and use it

00:21:29.280 --> 00:21:32.790
in your game or any
categories of Actions.

00:21:32.790 --> 00:21:36.630
In the demo, I showed
earlier that as a user walk

00:21:36.630 --> 00:21:40.020
into the pet store, you
can hear the bells ringing

00:21:40.020 --> 00:21:43.830
above the door that
alerts the pet store owner

00:21:43.830 --> 00:21:46.020
someone has entered the store.

00:21:46.020 --> 00:21:50.220
This all can help you to create
that narrative, really great

00:21:50.220 --> 00:21:52.660
beginning gaming experience.

00:21:52.660 --> 00:21:56.070
Now, we are going to touch
on the visual components that

00:21:56.070 --> 00:22:02.830
apply to all the devices with a
screen by using Rich Responses.

00:22:02.830 --> 00:22:05.310
Now, we're going up a
level in the pyramid.

00:22:05.310 --> 00:22:09.060
At this tier, we are trying to
engage with the user with more

00:22:09.060 --> 00:22:10.610
of their senses.

00:22:10.610 --> 00:22:13.740
With smart displays,
in addition to a voice,

00:22:13.740 --> 00:22:17.340
you can now engage with
the user by showing images

00:22:17.340 --> 00:22:18.180
on the screen.

00:22:18.180 --> 00:22:20.880
And they can select
the item by touch.

00:22:20.880 --> 00:22:24.990
This is where the multimodal
experience begins.

00:22:24.990 --> 00:22:27.300
We do this by using
Rich Responses

00:22:27.300 --> 00:22:30.890
such as basic cards, carousels,
and suggestion chips.

00:22:34.070 --> 00:22:37.770
By following this pyramid
strategy I just mentioned,

00:22:37.770 --> 00:22:41.200
if the user plays the
game on a speaker,

00:22:41.200 --> 00:22:43.700
you will hear the sound
of a hamster munching

00:22:43.700 --> 00:22:45.290
in the background.

00:22:45.290 --> 00:22:47.904
DARLA SHARP: Let's listen.

00:22:47.904 --> 00:22:48.886
[VIDEO PLAYBACK]

00:22:48.886 --> 00:22:51.341
- [MUNCHING]

00:22:52.814 --> 00:22:53.540
[END PLAYBACK]

00:22:53.540 --> 00:22:55.040
MANDY CHAN: So you
can find all kind

00:22:55.040 --> 00:22:57.500
of different, interesting
sound from our Sound Library

00:22:57.500 --> 00:22:59.060
for your Actions.

00:22:59.060 --> 00:23:01.760
So the initial
version of the game,

00:23:01.760 --> 00:23:04.640
I really wanted to make
use of the features that

00:23:04.640 --> 00:23:07.160
are available for the
developer at that time.

00:23:07.160 --> 00:23:09.650
And that was before
Interactive Canvas.

00:23:09.650 --> 00:23:13.100
So I make use of the Rich
Responses, majority of them

00:23:13.100 --> 00:23:16.670
are basic cards, to fully
leverage a beautiful artwork

00:23:16.670 --> 00:23:20.000
created by my coworker, Darren.

00:23:20.000 --> 00:23:23.090
As you can see, the
image itself can

00:23:23.090 --> 00:23:25.500
convey a lot of information.

00:23:25.500 --> 00:23:29.400
It doesn't just show the
activity of the pet is doing,

00:23:29.400 --> 00:23:32.392
but also the emotion of the pet.

00:23:32.392 --> 00:23:34.350
DARLA SHARP: One of the
benefits of your action

00:23:34.350 --> 00:23:36.960
having a screen is now
you're able to display

00:23:36.960 --> 00:23:39.300
multiple options
at the same time.

00:23:39.300 --> 00:23:42.000
This can be a little bit tricky
in the voice-only experience,

00:23:42.000 --> 00:23:45.160
because users have to keep
that information in their head.

00:23:45.160 --> 00:23:49.090
But now, with the screen, you
can present multiple options

00:23:49.090 --> 00:23:50.730
and obviously get
the benefit of being

00:23:50.730 --> 00:23:54.265
able to augment those options
with a visual representation.

00:23:54.265 --> 00:23:55.890
There's a couple
things to keep in mind

00:23:55.890 --> 00:23:57.450
here when trying
to balance the two

00:23:57.450 --> 00:23:59.850
modalities of voice and screen.

00:23:59.850 --> 00:24:02.070
If you've got a small
number of options,

00:24:02.070 --> 00:24:04.800
like three, maybe
four, you probably

00:24:04.800 --> 00:24:06.630
don't need to change
your prompt from

00:24:06.630 --> 00:24:08.400
your voice-only experience.

00:24:08.400 --> 00:24:12.690
It's perfectly fine to say, I
have a few options, A, B, or C.

00:24:12.690 --> 00:24:14.240
Which one do you want?

00:24:14.240 --> 00:24:16.560
But if you have more
options, four or more,

00:24:16.560 --> 00:24:18.540
then it's probably a
good idea to offload

00:24:18.540 --> 00:24:20.910
some of that information
from your prompts

00:24:20.910 --> 00:24:23.010
to show the user the screen.

00:24:23.010 --> 00:24:25.313
So then you can just say,
here's a few options.

00:24:25.313 --> 00:24:26.230
Which one do you want?

00:24:28.940 --> 00:24:30.970
MANDY CHAN: So for
this game specifically,

00:24:30.970 --> 00:24:34.540
there are two opportunities that
we can leverage the carousel.

00:24:34.540 --> 00:24:36.190
What should I feed my pet?

00:24:36.190 --> 00:24:38.260
Or what can I do with my pet?

00:24:38.260 --> 00:24:41.060
In this example is what
can I feed the pet?

00:24:41.060 --> 00:24:43.410
With the carousel,
the user can either

00:24:43.410 --> 00:24:46.420
select a item by saying
that I want a broccoli

00:24:46.420 --> 00:24:48.410
or by touching the screen.

00:24:48.410 --> 00:24:51.910
Keep in mind that you should
have a minimum of 2 items

00:24:51.910 --> 00:24:55.760
or maximum 10
items for carousel.

00:24:55.760 --> 00:24:59.720
Now, let's talk about how to
create a carousel in code.

00:24:59.720 --> 00:25:02.850
We first create a new
instance of carousel,

00:25:02.850 --> 00:25:08.770
parsing in multiple options, in
this case, broccoli and carrot.

00:25:08.770 --> 00:25:13.480
And then for each item,
we have a key broccoli.

00:25:13.480 --> 00:25:16.180
When the user select the
item, the value broccoli

00:25:16.180 --> 00:25:18.370
will be sent back to the server.

00:25:18.370 --> 00:25:23.140
And each item, we have a
title, description, and next

00:25:23.140 --> 00:25:24.610
is the image.

00:25:24.610 --> 00:25:31.170
And they have also a alt
attribute for accessibility.

00:25:31.170 --> 00:25:34.980
Now, you have learned about how
to create a carousel in code,

00:25:34.980 --> 00:25:38.550
it is very important to optimize
your TTS, Test To Speech,

00:25:38.550 --> 00:25:40.290
for voice and screen.

00:25:40.290 --> 00:25:44.100
What that really means is
pretty much like me giving

00:25:44.100 --> 00:25:47.610
a presentation, do you
want me to read the word

00:25:47.610 --> 00:25:49.590
from the screen word for word?

00:25:49.590 --> 00:25:50.640
You don't.

00:25:50.640 --> 00:25:54.150
So you don't want your
action to behave the same.

00:25:54.150 --> 00:25:56.370
The solution for this
is pretty simple.

00:25:56.370 --> 00:25:59.040
Make sure your spoken
prompt and the display

00:25:59.040 --> 00:26:01.330
tests are different.

00:26:01.330 --> 00:26:03.330
Here's how I do it in code.

00:26:03.330 --> 00:26:07.440
So I first importing two
prompt, one's rich prompt,

00:26:07.440 --> 00:26:09.600
and the other one
is static prompt.

00:26:09.600 --> 00:26:11.280
And that's just my
personal preference

00:26:11.280 --> 00:26:14.080
that I like to
separate those files.

00:26:14.080 --> 00:26:16.050
When I say rich prompt,
what I really mean

00:26:16.050 --> 00:26:20.184
is the display test that
you show on the screen.

00:26:20.184 --> 00:26:22.180
Next.

00:26:22.180 --> 00:26:24.300
So here, the
highlighted line is just

00:26:24.300 --> 00:26:27.660
sending out the spoken prompt,
which the device will say.

00:26:27.660 --> 00:26:31.210
And, as a part of building
the voice first experience,

00:26:31.210 --> 00:26:35.610
I want you to be aware of before
you send any visual component,

00:26:35.610 --> 00:26:39.750
like basic cards, carousel,
make sure you send the static--

00:26:39.750 --> 00:26:42.270
the simple response first.

00:26:42.270 --> 00:26:44.340
If you don't do this,
you might get an error.

00:26:46.960 --> 00:26:50.580
Finally, if we do have a
device that supports screen,

00:26:50.580 --> 00:26:52.710
we can show the image
of the basic card

00:26:52.710 --> 00:26:54.980
with the rich prompt.

00:26:54.980 --> 00:26:57.230
DARLA SHARP: Another
useful Rich Response to use

00:26:57.230 --> 00:27:00.500
is suggestion chips, which is
a nice way to continue or pivot

00:27:00.500 --> 00:27:02.000
the conversation.

00:27:02.000 --> 00:27:05.060
A few things to keep in mind
when using suggestion chips--

00:27:05.060 --> 00:27:07.850
the first one is less is more.

00:27:07.850 --> 00:27:10.790
The more chips you put on the
bottom of the page, the more

00:27:10.790 --> 00:27:12.740
implicit work you're
asking the user

00:27:12.740 --> 00:27:16.430
to do to figure out which
one they need or want.

00:27:16.430 --> 00:27:17.450
Use less.

00:27:17.450 --> 00:27:19.130
Do the work for the user.

00:27:19.130 --> 00:27:22.370
And only surface a few
highly relevant chips.

00:27:22.370 --> 00:27:24.140
The second thing
to keep in mind is

00:27:24.140 --> 00:27:26.960
that these are meant to augment
your feature by highlighting

00:27:26.960 --> 00:27:29.120
secondary features.

00:27:29.120 --> 00:27:30.890
With smart displays,
you can't ever

00:27:30.890 --> 00:27:33.590
really be sure that the
user is standing right

00:27:33.590 --> 00:27:35.070
in front of the device.

00:27:35.070 --> 00:27:38.240
So if you expect them to use
this as their primary modality,

00:27:38.240 --> 00:27:40.340
they may not even
be looking at it.

00:27:40.340 --> 00:27:43.340
So use this as a way to
surface secondary features

00:27:43.340 --> 00:27:46.030
for your action.

00:27:46.030 --> 00:27:48.330
MANDY CHAN: So as Darla
mentioned, suggestion chips

00:27:48.330 --> 00:27:50.760
can help you pivot
the conversation.

00:27:50.760 --> 00:27:53.520
In this game, there are
two suggestion chips.

00:27:53.520 --> 00:27:57.330
First one is how to get badges
so that the user know that are

00:27:57.330 --> 00:27:59.220
they progressing in the game.

00:27:59.220 --> 00:28:01.920
The second one is
how is the pet doing.

00:28:01.920 --> 00:28:05.220
This is a great way to do
the progressive disclosure.

00:28:05.220 --> 00:28:08.273
Let's see how we
do that in code.

00:28:08.273 --> 00:28:09.440
It's pretty straightforward.

00:28:09.440 --> 00:28:12.480
Again, you're creating a
new instance of suggestions.

00:28:12.480 --> 00:28:16.560
You can parse in a single
string or an array of strings.

00:28:16.560 --> 00:28:18.690
Depending on what
you are parsing in,

00:28:18.690 --> 00:28:20.430
we can create a
single suggestion chip

00:28:20.430 --> 00:28:22.530
or multiple suggestion chips.

00:28:22.530 --> 00:28:24.810
So, so far, we
have covered a lot

00:28:24.810 --> 00:28:29.020
of useful Rich Responses,
basic cards, carousel,

00:28:29.020 --> 00:28:31.230
and suggestion chips.

00:28:31.230 --> 00:28:33.780
We have several more, though,
that can help you and reach

00:28:33.780 --> 00:28:35.520
your multimodal experience.

00:28:35.520 --> 00:28:37.270
First is list.

00:28:37.270 --> 00:28:38.760
List is pretty
much like carousel,

00:28:38.760 --> 00:28:41.250
except you can show more items.

00:28:41.250 --> 00:28:43.740
And then media
response really allows

00:28:43.740 --> 00:28:47.520
you to play long audio file
and let the user navigate

00:28:47.520 --> 00:28:49.550
an audio file.

00:28:49.550 --> 00:28:51.780
Table, on the other
hand, can allow

00:28:51.780 --> 00:28:55.680
you to display information
in row or column format.

00:28:55.680 --> 00:28:58.050
We have more resources at
the end of the presentation

00:28:58.050 --> 00:29:00.750
to show you how to
use each of them.

00:29:00.750 --> 00:29:04.560
The lesson to be learned
here are two things.

00:29:04.560 --> 00:29:07.860
Make sure you engage with
your user on a visual level.

00:29:10.530 --> 00:29:15.030
The second one is, provide a
natural progressive discovery

00:29:15.030 --> 00:29:20.050
without being so explicit
by using Rich Responses.

00:29:20.050 --> 00:29:24.090
So we have talked about this
pyramid throughout our talk.

00:29:24.090 --> 00:29:26.510
I just want to
have a quick recap.

00:29:26.510 --> 00:29:30.450
SSML and Sound Library allows
you to express the creativity

00:29:30.450 --> 00:29:31.420
through sound.

00:29:31.420 --> 00:29:34.380
And that allows you to build a
solid voice first experience.

00:29:34.380 --> 00:29:37.350
Rich Responses let
you present images,

00:29:37.350 --> 00:29:39.240
but they are slightly limited.

00:29:39.240 --> 00:29:41.940
That means that you
cannot customize them.

00:29:41.940 --> 00:29:46.410
At the top of the pyramid is
where we have the Interactive

00:29:46.410 --> 00:29:48.900
Canvas, that can
allows you to create

00:29:48.900 --> 00:29:54.400
the deepest level of experience
by using Interactive Canvas.

00:29:54.400 --> 00:29:56.430
This is a new feature
we announced yesterday.

00:29:56.430 --> 00:30:01.680
And it empowers you to create a
fluid and customized experience

00:30:01.680 --> 00:30:05.700
with the technology you are
already familiar with, HTML,

00:30:05.700 --> 00:30:07.890
CSS, and JavaScript.

00:30:07.890 --> 00:30:11.160
I like to say, this is
where the creativity

00:30:11.160 --> 00:30:14.460
erupts, like a
volcano, because Canvas

00:30:14.460 --> 00:30:17.250
allows you to be very
expressive, which

00:30:17.250 --> 00:30:19.200
is ideal for a game.

00:30:19.200 --> 00:30:22.290
Right now, this is only
available for a game.

00:30:22.290 --> 00:30:24.480
On the other hand,
Rich Responses,

00:30:24.480 --> 00:30:29.220
you can use them for any
categories of Actions.

00:30:29.220 --> 00:30:30.595
You can see what's
on the screen.

00:30:30.595 --> 00:30:31.303
DARLA SHARP: Ooh.

00:30:31.303 --> 00:30:32.970
MANDY CHAN: This can
all be done with--

00:30:32.970 --> 00:30:33.637
DARLA SHARP: Ah.

00:30:33.637 --> 00:30:36.380
MANDY CHAN: --HTML,
CSS, and JavaScript.

00:30:36.380 --> 00:30:39.270
With Interactive
Canvas, you can easily

00:30:39.270 --> 00:30:41.610
create dynamic animations.

00:30:41.610 --> 00:30:46.530
Canvas let the user touch on
any element on the screen,

00:30:46.530 --> 00:30:48.360
and they can react.

00:30:48.360 --> 00:30:52.033
None of this was
possible before Canvas.

00:30:52.033 --> 00:30:53.700
DARLA SHARP: So we
needed to figure out,

00:30:53.700 --> 00:30:56.430
how are we going to use
Canvas for our game?

00:30:56.430 --> 00:30:58.800
When the users come back
to the game, Larry--

00:30:58.800 --> 00:31:01.140
or your hamster, however
you've named them--

00:31:01.140 --> 00:31:02.900
can be in any number of states.

00:31:02.900 --> 00:31:04.260
They can be happy.

00:31:04.260 --> 00:31:06.253
They could be hungry,
holding his little belly,

00:31:06.253 --> 00:31:07.920
thinking you're never
going to feed him.

00:31:07.920 --> 00:31:09.880
It could even be sleeping.

00:31:09.880 --> 00:31:11.670
So what we wanted
to be sure to do

00:31:11.670 --> 00:31:13.980
was make it clear
for the user how

00:31:13.980 --> 00:31:17.250
what they're doing for their
pet is affecting the pet based

00:31:17.250 --> 00:31:21.400
on all of the complexity that
Mandy had built into the game.

00:31:21.400 --> 00:31:23.910
So now let's take a look
about how we replaced

00:31:23.910 --> 00:31:26.310
Rich Responses with Canvas.

00:31:26.310 --> 00:31:28.770
MANDY CHAN: Like I said
earlier, I built this game

00:31:28.770 --> 00:31:31.300
when Canvas was available.

00:31:31.300 --> 00:31:33.390
So I used a lot of,
like, Rich Responses,

00:31:33.390 --> 00:31:36.060
such as basic cards and
carousel, in my game.

00:31:36.060 --> 00:31:40.140
In this example, when the
user choose let the pet run

00:31:40.140 --> 00:31:43.470
in a hamster ball, my intent
with the spoken prompt

00:31:43.470 --> 00:31:46.610
is to show that Larry is happy.

00:31:46.610 --> 00:31:48.940
Larry still have energy to play.

00:31:48.940 --> 00:31:51.930
But what I didn't think
about is, how does that

00:31:51.930 --> 00:31:54.930
affect the end-user game play?

00:31:54.930 --> 00:31:58.950
What if the user keep
playing and feeding the pet?

00:31:58.950 --> 00:32:01.380
My game, the initial
version, would just

00:32:01.380 --> 00:32:03.810
keep displaying the same images.

00:32:03.810 --> 00:32:05.310
DARLA SHARP: Instead
of just showing

00:32:05.310 --> 00:32:08.520
a basic card that shows
Larry doing the activity, now

00:32:08.520 --> 00:32:10.620
with Canvas, we can build
in something much more

00:32:10.620 --> 00:32:11.610
interactive.

00:32:11.610 --> 00:32:14.280
For example, we could
put in dynamic elements

00:32:14.280 --> 00:32:15.390
on the display.

00:32:15.390 --> 00:32:20.720
In this case, it allows us to
show an energy bar for Larry.

00:32:20.720 --> 00:32:24.290
MANDY CHAN: So, in addition to
show the energy and happiness

00:32:24.290 --> 00:32:27.600
level of your pet by
using the energy bar,

00:32:27.600 --> 00:32:30.080
we also want to
show the user how

00:32:30.080 --> 00:32:34.520
they can progress in the game
by collecting different badges.

00:32:34.520 --> 00:32:39.090
With Rich Responses, I had a
difficult decision to make.

00:32:39.090 --> 00:32:41.970
Should I show Larry the
hamster eating the broccoli?

00:32:41.970 --> 00:32:44.630
Or should I show the badge?

00:32:44.630 --> 00:32:47.810
So, before Interactive
Canvas was available,

00:32:47.810 --> 00:32:50.990
I actually used the screen
to show that Larry's

00:32:50.990 --> 00:32:52.100
eating the broccoli.

00:32:52.100 --> 00:32:53.780
And I used the
spoken prompt to tell

00:32:53.780 --> 00:32:55.605
the user they earned a badge.

00:32:55.605 --> 00:32:57.980
DARLA SHARP: I think that was,
when using Rich Responses,

00:32:57.980 --> 00:33:00.440
a pretty smart way to
balance the modalities.

00:33:00.440 --> 00:33:02.360
But now that we have
Canvas, where we can now

00:33:02.360 --> 00:33:04.730
show multiple images
on the same screen,

00:33:04.730 --> 00:33:07.640
and some of them even
being dynamic, like a GIF

00:33:07.640 --> 00:33:09.800
here, now you can
see not only how

00:33:09.800 --> 00:33:11.570
Larry is feeling
with the energy bar,

00:33:11.570 --> 00:33:14.070
but you can also see how you're
progressing through the game

00:33:14.070 --> 00:33:16.025
by earning badges.

00:33:16.025 --> 00:33:17.400
MANDY CHAN: So
the lesson learned

00:33:17.400 --> 00:33:21.540
here is with Interactive
Canvas, objects on the screen

00:33:21.540 --> 00:33:24.600
can come to life
with a single touch.

00:33:24.600 --> 00:33:27.870
They can react by fading,
animating, or even talking

00:33:27.870 --> 00:33:28.715
to you.

00:33:28.715 --> 00:33:30.090
DARLA SHARP: So
now we've covered

00:33:30.090 --> 00:33:33.600
how to build for voice only
and also for multimodal.

00:33:33.600 --> 00:33:36.048
Of the three products we
spoke about at the beginning

00:33:36.048 --> 00:33:38.340
of the talk that we were
going to build our action for,

00:33:38.340 --> 00:33:40.810
the one that we haven't
talked about is mobile.

00:33:40.810 --> 00:33:43.680
So what do we need to do, based
on what we've done so far,

00:33:43.680 --> 00:33:46.320
to get our action
to work on mobile?

00:33:46.320 --> 00:33:49.080
The good news is
absolutely nothing.

00:33:49.080 --> 00:33:51.960
By using the strategy of
building from voice to Rich

00:33:51.960 --> 00:33:54.810
Responses and augmenting
with Canvas if it applies

00:33:54.810 --> 00:33:56.910
to your category,
then you don't have

00:33:56.910 --> 00:34:00.810
to do anything extra for
mobile to work specifically.

00:34:00.810 --> 00:34:02.520
This is a big win for you.

00:34:02.520 --> 00:34:06.420
By doing this solid approach,
you can scale to many devices

00:34:06.420 --> 00:34:09.324
without a lot of heavy
lifting on your part.

00:34:09.324 --> 00:34:10.949
MANDY CHAN: So there
are some use cases

00:34:10.949 --> 00:34:14.730
that the phone is preferred
over other devices.

00:34:14.730 --> 00:34:18.420
The above three use cases,
transaction, notification,

00:34:18.420 --> 00:34:20.699
account linking,
are good examples.

00:34:20.699 --> 00:34:22.860
They all have a
common theme, which

00:34:22.860 --> 00:34:25.560
is the physical control
over the device.

00:34:25.560 --> 00:34:29.550
Mobile is a massive market
that you don't want to miss.

00:34:29.550 --> 00:34:33.420
It is a great way for you to
engage with the user on the go

00:34:33.420 --> 00:34:36.900
or in a more private manner.

00:34:36.900 --> 00:34:38.630
So there are different
scenarios that

00:34:38.630 --> 00:34:41.510
requires users to
transfer from one device

00:34:41.510 --> 00:34:43.710
to another for
different reasons.

00:34:43.710 --> 00:34:46.560
One reason is you need
to do account linking.

00:34:46.560 --> 00:34:50.600
So that requires the
users to use their phone

00:34:50.600 --> 00:34:52.320
for security reasons.

00:34:52.320 --> 00:34:56.429
The second reason could be
you need to show a image.

00:34:56.429 --> 00:34:58.340
But what if your user
trigger your action

00:34:58.340 --> 00:35:00.170
from a home speaker?

00:35:00.170 --> 00:35:04.460
So what we can do is we check
if the user has any devices that

00:35:04.460 --> 00:35:06.560
can support screen output.

00:35:06.560 --> 00:35:10.340
If the user does has a device
that support screen output,

00:35:10.340 --> 00:35:13.410
we simply continue the
conversation over there.

00:35:13.410 --> 00:35:16.690
Let's see how we
do that in code.

00:35:16.690 --> 00:35:20.590
So first, we check if the
user have any devices that

00:35:20.590 --> 00:35:23.110
can support screen output.

00:35:23.110 --> 00:35:27.340
And we saw that in a constant
called screenAvailable,

00:35:27.340 --> 00:35:30.280
we then defined three
constant contexts.

00:35:30.280 --> 00:35:31.960
Context is the
reason why we need

00:35:31.960 --> 00:35:35.290
to transfer the user from
one device to another.

00:35:35.290 --> 00:35:37.660
Notification is the
message that will

00:35:37.660 --> 00:35:41.950
be displayed on the screen
on the target device.

00:35:41.950 --> 00:35:44.590
Capabilities is an
array of capabilities

00:35:44.590 --> 00:35:46.960
that your target
device must support.

00:35:50.090 --> 00:35:53.580
In this case, all we care is
the device should have a screen.

00:35:53.580 --> 00:35:57.260
So if the current device that's
being used, we have a screen,

00:35:57.260 --> 00:36:01.270
we can show the image,
carousel, basic card, easily.

00:36:01.270 --> 00:36:03.480
And if the current
device that's being used,

00:36:03.480 --> 00:36:05.220
that doesn't
support screen, this

00:36:05.220 --> 00:36:08.130
is where we check the
constant screenAvailable.

00:36:08.130 --> 00:36:09.780
Does the user have
any other device

00:36:09.780 --> 00:36:11.130
that can support screen output?

00:36:11.130 --> 00:36:14.430
If yes, we created
a new instance

00:36:14.430 --> 00:36:17.310
called NewService that parsing
the three constants that we

00:36:17.310 --> 00:36:19.500
define earlier.

00:36:19.500 --> 00:36:25.360
Finally, if-- we need
to go to the next page.

00:36:25.360 --> 00:36:28.410
Finally, if the user
doesn't have any device that

00:36:28.410 --> 00:36:30.990
can support screen output,
we simply say, sorry,

00:36:30.990 --> 00:36:34.490
you need a screen
to see the pictures.

00:36:34.490 --> 00:36:37.670
DARLA SHARP: So we managed to
cover how to take one action,

00:36:37.670 --> 00:36:40.900
focus on the capabilities,
create a solid voice experience

00:36:40.900 --> 00:36:42.010
that scales.

00:36:42.010 --> 00:36:43.480
As you try this
yourselves, here's

00:36:43.480 --> 00:36:47.120
a few tools to keep in mind
that can be really helpful.

00:36:47.120 --> 00:36:48.785
It's easy to get
lost in your code

00:36:48.785 --> 00:36:51.160
when you're trying to figure
out how to balance these two

00:36:51.160 --> 00:36:52.210
modalities.

00:36:52.210 --> 00:36:54.970
I highly recommend stepping
away from the computer,

00:36:54.970 --> 00:36:57.280
using a pen and paper,
and figuring out

00:36:57.280 --> 00:37:00.490
how you want these dialogues to
flow with the voice and screen

00:37:00.490 --> 00:37:01.720
back to back.

00:37:01.720 --> 00:37:04.960
This is really simple, and you
do not need very much skill

00:37:04.960 --> 00:37:05.920
to do this.

00:37:05.920 --> 00:37:09.400
A simple drawing with a pen, a
paper, and some stick figures

00:37:09.400 --> 00:37:11.470
goes a long way.

00:37:11.470 --> 00:37:14.410
MANDY CHAN: UI toolkit
includes some image templates

00:37:14.410 --> 00:37:17.080
that can allow you to
create a wireframe.

00:37:17.080 --> 00:37:20.770
It shows you how Rich Responses
can look in different devices.

00:37:20.770 --> 00:37:22.990
In this example,
we have basic card.

00:37:22.990 --> 00:37:25.210
You can really see how
it looks on a mobile

00:37:25.210 --> 00:37:26.927
versus a smart displays.

00:37:26.927 --> 00:37:28.510
Another tool that I
want to talk about

00:37:28.510 --> 00:37:31.390
is the Action Simulator, where
you can find in the Actions

00:37:31.390 --> 00:37:33.380
on Google console.

00:37:33.380 --> 00:37:35.800
So this is where you
probably spend a lot of time

00:37:35.800 --> 00:37:37.173
testing your Actions.

00:37:37.173 --> 00:37:38.590
A couple things I
want to touch on

00:37:38.590 --> 00:37:44.230
is, the first is you can really
toggle between those devices

00:37:44.230 --> 00:37:46.990
to see how your
action look like.

00:37:46.990 --> 00:37:51.640
And you can also check how your
Canvas, Interactive Canvas,

00:37:51.640 --> 00:37:54.610
look like in the Simulator.

00:37:54.610 --> 00:37:58.240
Second thing I want to talk
about is the Audio Tech.

00:37:58.240 --> 00:38:00.710
This is where you can play--

00:38:00.710 --> 00:38:01.630
can we click?

00:38:01.630 --> 00:38:04.750
Yeah, this is the Audio Tech,
in case anyone couldn't find it.

00:38:04.750 --> 00:38:08.020
This is where you can
play with the SSML tech,

00:38:08.020 --> 00:38:11.950
add pauses, change volume,
pitch of your voice,

00:38:11.950 --> 00:38:14.110
and even add the ambient
sound in the background

00:38:14.110 --> 00:38:16.660
while the speaking
prompt is running.

00:38:19.170 --> 00:38:21.520
So, OK, we have done it.

00:38:21.520 --> 00:38:23.310
We have covered a lot today.

00:38:23.310 --> 00:38:25.890
To sum up, we just want to
run through the quick summary

00:38:25.890 --> 00:38:28.590
of what we have learned
from building this game.

00:38:28.590 --> 00:38:31.320
We talk about using
SSML in conjunction

00:38:31.320 --> 00:38:33.570
with the Sound Library
that can help you

00:38:33.570 --> 00:38:36.090
create layers for your Action.

00:38:36.090 --> 00:38:40.230
Be sure to have several branches
in your dialogue to create

00:38:40.230 --> 00:38:42.990
a solid voice first experience.

00:38:42.990 --> 00:38:44.940
DARLA SHARP: Then
use dialogue to guide

00:38:44.940 --> 00:38:48.480
the user using questions
instead of statements.

00:38:48.480 --> 00:38:50.190
If your Action uses
a screen, there

00:38:50.190 --> 00:38:52.560
are a lot of tools in
your Rich Response toolbox

00:38:52.560 --> 00:38:55.450
to augment the voice experience.

00:38:55.450 --> 00:38:58.060
MANDY CHAN: Interactive
Canvas is a great new feature

00:38:58.060 --> 00:39:01.300
to create gaming experience
using technology you already

00:39:01.300 --> 00:39:04.600
know, HTML, CSS, and JavaScript.

00:39:04.600 --> 00:39:08.270
If you are a game developer,
make sure you check it out.

00:39:08.270 --> 00:39:10.060
It is in Developer
Preview, which

00:39:10.060 --> 00:39:12.490
means you can start
building games today.

00:39:12.490 --> 00:39:15.800
You just cannot deploy
it to the production yet.

00:39:15.800 --> 00:39:18.640
DARLA SHARP: And finally, if you
build one custom Action using

00:39:18.640 --> 00:39:20.380
the techniques we
described today,

00:39:20.380 --> 00:39:24.370
you get a single experience
that scales across devices.

00:39:24.370 --> 00:39:27.940
We covered a lot today about
how conversation design applies

00:39:27.940 --> 00:39:29.060
to our action.

00:39:29.060 --> 00:39:30.820
But there's lots more to learn.

00:39:30.820 --> 00:39:35.010
I highly recommend visiting
the actions.google.com/design

00:39:35.010 --> 00:39:37.520
website to learn more
about conversation design.

00:39:37.520 --> 00:39:41.120
And there's also been lots of
good talks from years prior.

00:39:41.120 --> 00:39:43.900
There's also a talk tomorrow
at 2:30 by Cathy Pearl

00:39:43.900 --> 00:39:46.090
and Jessica
Earley-Cha on Stage 8,

00:39:46.090 --> 00:39:48.850
where you can learn more about
designing quality conversations

00:39:48.850 --> 00:39:50.410
for the Google Assistant.

00:39:50.410 --> 00:39:52.780
And to learn more about how
to use Interactive Canvas

00:39:52.780 --> 00:39:54.490
and how to implement
it in the code,

00:39:54.490 --> 00:39:57.280
there was a talk earlier today
that you can check out tomorrow

00:39:57.280 --> 00:39:59.712
on YouTube.

00:39:59.712 --> 00:40:01.420
MANDY CHAN: So here
are all the resources

00:40:01.420 --> 00:40:03.670
that we have covered
today, how to leverage

00:40:03.670 --> 00:40:07.420
the voice and visual component
that our platform provides,

00:40:07.420 --> 00:40:10.120
in addition to that,
samples and tools that can

00:40:10.120 --> 00:40:13.780
help you get started quickly.

00:40:13.780 --> 00:40:15.430
Thank you so much for coming.

00:40:15.430 --> 00:40:19.240
Please let us know how
you do like this talk.

00:40:19.240 --> 00:40:21.220
I hope you enjoyed
this talk, and share

00:40:21.220 --> 00:40:22.930
the feedback in the I/O app.

00:40:22.930 --> 00:40:25.840
So this game is still
work in progress.

00:40:25.840 --> 00:40:27.640
So that means that
we will open source

00:40:27.640 --> 00:40:31.300
this game after I/O.
Follow me on Twitter

00:40:31.300 --> 00:40:34.510
@MandyChanNYC to get
the latest update

00:40:34.510 --> 00:40:36.700
about the game and Larry.

00:40:36.700 --> 00:40:37.560
DARLA SHARP: OK.

00:40:37.560 --> 00:40:37.920
MANDY CHAN: Have fun--

00:40:37.920 --> 00:40:38.190
DARLA SHARP: That's it.

00:40:38.190 --> 00:40:39.130
MANDY CHAN: --building
your Actions.

00:40:39.130 --> 00:40:40.690
DARLA SHARP: Thanks for coming.

00:40:40.690 --> 00:40:43.440
[GOOGLE LOGO MUSIC]

