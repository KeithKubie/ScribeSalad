WEBVTT
Kind: captions
Language: en

00:00:02.044 --> 00:00:03.710
COLT MCANLIS: So
here's a common problem

00:00:03.710 --> 00:00:05.297
that I'm sure you've run into.

00:00:05.297 --> 00:00:06.880
It's time to load a
bitmap into memory

00:00:06.880 --> 00:00:08.796
for your app, social
media stream or whatever,

00:00:08.796 --> 00:00:10.324
but you're out of memory.

00:00:10.324 --> 00:00:12.240
You can't load in the
new bitmap without first

00:00:12.240 --> 00:00:13.870
destroying one of
the existing bitmaps

00:00:13.870 --> 00:00:14.953
you've already got loaded.

00:00:14.953 --> 00:00:16.325
But which one do you get rid of?

00:00:16.325 --> 00:00:18.950
My name is Colt McAnlis, and the
answer to this tricky question

00:00:18.950 --> 00:00:21.610
is actually an entire
field of computer science

00:00:21.610 --> 00:00:24.854
that's almost 60 years old,
cache replacement algorithms.

00:00:24.854 --> 00:00:26.520
In general, you can
think of the bitmaps

00:00:26.520 --> 00:00:28.870
that you have loaded
into memory as a cache.

00:00:28.870 --> 00:00:31.259
That is, rather than loading
a given bitmap from disk

00:00:31.259 --> 00:00:33.675
each time you want to use it,
you load it into memory once

00:00:33.675 --> 00:00:36.280
and then use it over and
over again as it's needed.

00:00:36.280 --> 00:00:38.720
This basically means that
a cache stores objects that

00:00:38.720 --> 00:00:40.354
might be used in the future.

00:00:40.354 --> 00:00:42.020
However, as the cache
starts to fill up,

00:00:42.020 --> 00:00:44.103
you eventually need to get
rid of one of the items

00:00:44.103 --> 00:00:45.790
in order to make room
for incoming data.

00:00:45.790 --> 00:00:47.460
So which one do you get rid of?

00:00:47.460 --> 00:00:49.120
Well, since a cache
hold objects that

00:00:49.120 --> 00:00:51.215
might be used in the
future, the obvious answer

00:00:51.215 --> 00:00:53.920
is to evict one of the objects
that's not needed anymore;

00:00:53.920 --> 00:00:57.174
or at worst, wouldn't be used
for the longest period of time.

00:00:57.174 --> 00:00:58.840
But it's generally
impossible to predict

00:00:58.840 --> 00:01:00.320
how far in the
future information

00:01:00.320 --> 00:01:01.450
will be needed again,
even when you've

00:01:01.450 --> 00:01:03.408
got awesome algorithms
like this hanging around

00:01:03.408 --> 00:01:04.269
in your code base.

00:01:04.269 --> 00:01:06.700
Good news is that there's
a simpler way to do this,

00:01:06.700 --> 00:01:09.410
and Android has already done
the heavy lifting for you.

00:01:09.410 --> 00:01:12.420
The LRU cache class
maintains a list of items

00:01:12.420 --> 00:01:13.520
that you place into it.

00:01:13.520 --> 00:01:17.440
As an object is accessed, it's
moved to the front of the list

00:01:17.440 --> 00:01:20.150
where it will remain until
some other item gets accessed,

00:01:20.150 --> 00:01:22.459
and then that gets moved
to the front instead.

00:01:22.459 --> 00:01:24.000
When the cache fills
up and it's time

00:01:24.000 --> 00:01:25.980
to choose which element
to evict to make room

00:01:25.980 --> 00:01:28.640
for the incoming objects,
the decision here is easy.

00:01:28.640 --> 00:01:30.720
Objects that are
accessed more frequently

00:01:30.720 --> 00:01:32.720
will reside in towards
the front of the list,

00:01:32.720 --> 00:01:35.630
while less used objects
will hang towards the back.

00:01:35.630 --> 00:01:39.820
This replacement algorithm is
called LRU, or least recently

00:01:39.820 --> 00:01:42.667
used, basically saying that
the more an object is used now,

00:01:42.667 --> 00:01:45.000
the higher chances are that
it'll be used in the future,

00:01:45.000 --> 00:01:46.980
and it should stay
in the cache, which

00:01:46.980 --> 00:01:49.340
is perfect for your
social media application.

00:01:49.340 --> 00:01:51.200
Now chances are that
if a thumbnail hasn't

00:01:51.200 --> 00:01:52.540
been seen in awhile,
then it's probably

00:01:52.540 --> 00:01:53.998
been scrolled
offscreen and doesn't

00:01:53.998 --> 00:01:55.630
need to be in memory anymore.

00:01:55.630 --> 00:01:58.240
Now the LRU cache isn't
a typical container,

00:01:58.240 --> 00:02:01.250
and as such requires a bit of
finesse to get working right.

00:02:01.250 --> 00:02:04.890
Firstly, the LRU cache manages
elements in a key value

00:02:04.890 --> 00:02:05.680
relationship.

00:02:05.680 --> 00:02:07.420
When you declare
the object, you need

00:02:07.420 --> 00:02:09.620
to figure out what's the
use for key, and what data

00:02:09.620 --> 00:02:11.440
you're going to be
storing as a value.

00:02:11.440 --> 00:02:13.170
For a cache of
bitmaps, this may be

00:02:13.170 --> 00:02:16.070
as simple as using a
filename and a bitmap object.

00:02:16.070 --> 00:02:18.710
Secondly, LRU cache
is, by definition,

00:02:18.710 --> 00:02:20.232
a bounded container.

00:02:20.232 --> 00:02:22.190
It's intended to have a
maximum amount of size,

00:02:22.190 --> 00:02:24.200
so that you don't end up
running off into crazy town,

00:02:24.200 --> 00:02:26.158
and destroying your
application's memory, which

00:02:26.158 --> 00:02:27.780
means during
initialization you need

00:02:27.780 --> 00:02:30.340
to define the size
of your cache.

00:02:30.340 --> 00:02:31.590
But be careful here.

00:02:31.590 --> 00:02:33.112
Making your cache
too small means

00:02:33.112 --> 00:02:34.820
you'll get a lot of
evictions, and end up

00:02:34.820 --> 00:02:37.100
with a lot of unneeded
bitmap reloads.

00:02:37.100 --> 00:02:39.030
Too large of a cache,
on the other hand,

00:02:39.030 --> 00:02:41.330
exposes you to potential
out of memory errors

00:02:41.330 --> 00:02:42.550
all over the place.

00:02:42.550 --> 00:02:45.560
As such, the best practice
means setting your cache size

00:02:45.560 --> 00:02:49.020
based upon the amount of memory
available to your application.

00:02:49.020 --> 00:02:52.030
Now to find this, you can call
the getMemoryClass function,

00:02:52.030 --> 00:02:54.260
which indicates how
hard of a memory limit

00:02:54.260 --> 00:02:56.210
your app should impose
on itself in order

00:02:56.210 --> 00:02:57.840
to let the system work best.

00:02:57.840 --> 00:03:00.640
So grab that number and
then do some division

00:03:00.640 --> 00:03:02.960
by 8 or something,
as a starting value.

00:03:02.960 --> 00:03:04.590
Over time, you can
tweak this number

00:03:04.590 --> 00:03:07.180
based upon what your application
needs, or better yet,

00:03:07.180 --> 00:03:10.080
what device you're running
on and its limitations.

00:03:10.080 --> 00:03:11.675
Now the next important
part is that we

00:03:11.675 --> 00:03:14.080
have to let the cache know
the size of the objects

00:03:14.080 --> 00:03:16.740
that it contains, so it knows
how much of its bounded space

00:03:16.740 --> 00:03:18.880
is being taken up per object.

00:03:18.880 --> 00:03:21.290
To do this, we can
simply extend the class

00:03:21.290 --> 00:03:24.440
with our own container,
override the size of method

00:03:24.440 --> 00:03:27.810
to return the size of a
given bitmap in bytes.

00:03:27.810 --> 00:03:29.260
Now getting objects
from the cache

00:03:29.260 --> 00:03:30.710
and putting objects
back into the cache

00:03:30.710 --> 00:03:31.936
are pretty straightforward.

00:03:31.936 --> 00:03:34.310
I mean the whole thing works
basically like a hash table.

00:03:34.310 --> 00:03:37.740
But note that the get function
is actually very helpful here.

00:03:37.740 --> 00:03:40.210
If you request an object
that's not in the cache,

00:03:40.210 --> 00:03:42.500
or it's been evicted and
doesn't reside there anymore,

00:03:42.500 --> 00:03:44.590
then you'll get a
null object return,

00:03:44.590 --> 00:03:46.210
which is a great signal.

00:03:46.210 --> 00:03:48.840
It means that you should do the
extra work to load the bitmap

00:03:48.840 --> 00:03:50.070
and put it in the cache.

00:03:50.070 --> 00:03:51.010
But don't worry.

00:03:51.010 --> 00:03:53.730
LRU cache will handle all
of the eviction and memory

00:03:53.730 --> 00:03:55.110
reclamation for you.

00:03:55.110 --> 00:03:57.210
But it's worth pointing
out that any time you

00:03:57.210 --> 00:03:58.940
insert a new object
into the cache,

00:03:58.940 --> 00:04:00.340
that some of the
existing objects

00:04:00.340 --> 00:04:02.720
may be evicted in order
to make space for it.

00:04:02.720 --> 00:04:05.560
It's also important to note that
if your cache objects aren't

00:04:05.560 --> 00:04:08.540
uniform in size, then
LRU cache could end up

00:04:08.540 --> 00:04:11.070
evicting multiple objects
in order to make space

00:04:11.070 --> 00:04:13.010
for the larger new one.

00:04:13.010 --> 00:04:13.600
So, see?

00:04:13.600 --> 00:04:14.280
There you go.

00:04:14.280 --> 00:04:16.360
Memory management made easy.

00:04:16.360 --> 00:04:17.350
But trust me here.

00:04:17.350 --> 00:04:19.730
There's plenty more to be
done to make your application

00:04:19.730 --> 00:04:21.220
faster, which is why
you need to check out

00:04:21.220 --> 00:04:23.489
the rest of the Android
performance pattern content.

00:04:23.489 --> 00:04:25.780
And don't forget to join our
Google+ community as well,

00:04:25.780 --> 00:04:28.920
to ask others how they've
solved similar problems.

00:04:28.920 --> 00:04:32.210
So keep calm, profile your
code, and always remember,

00:04:32.210 --> 00:04:33.670
PERFMATTERS.

