WEBVTT
Kind: captions
Language: en

00:00:01.310 --> 00:00:03.360
DAVID HEARNDEN: This morning
I'll be talking to you about

00:00:03.360 --> 00:00:08.380
concurrent data and some
operational transform

00:00:08.380 --> 00:00:09.460
alternatives.

00:00:09.460 --> 00:00:13.370
And Christian Ohler will also
be joining me a little later

00:00:13.370 --> 00:00:14.810
hopefully when he gets here.

00:00:18.430 --> 00:00:20.180
So concurrent data--

00:00:20.180 --> 00:00:21.650
what does that mean?

00:00:21.650 --> 00:00:25.840
I'm going to talk about what the
problem is that concurrent

00:00:25.840 --> 00:00:27.470
data needs to solve.

00:00:27.470 --> 00:00:31.840
And this talk's going to talk
about two strategies for

00:00:31.840 --> 00:00:33.440
providing concurrent data.

00:00:33.440 --> 00:00:36.650
One is what we call
embedding--

00:00:36.650 --> 00:00:39.830
so embedding concurrent data
on Wave's operational

00:00:39.830 --> 00:00:41.250
transformations.

00:00:41.250 --> 00:00:44.930
And Christian's going to talk
about some more general

00:00:44.930 --> 00:00:48.525
approaches, or using a more
general approach to OT.

00:00:53.690 --> 00:00:56.800
So the problem that comes up
when you try and build

00:00:56.800 --> 00:00:59.910
applications on Wave
is that wavey

00:00:59.910 --> 00:01:02.560
applications need wavey data.

00:01:02.560 --> 00:01:06.450
So what that means is when you
try and build a behavior on

00:01:06.450 --> 00:01:10.730
top of the Wave platform,
you need to have a data

00:01:10.730 --> 00:01:15.810
representation for your model
that is compatible with the

00:01:15.810 --> 00:01:20.050
wave platform, which means the
data model is distributed,

00:01:20.050 --> 00:01:23.470
it's mutable, and it changes
both from local and remote

00:01:23.470 --> 00:01:25.360
operations.

00:01:25.360 --> 00:01:31.600
So in Google Wave we have a
number of these application

00:01:31.600 --> 00:01:34.180
models, one of which is the
conversation model.

00:01:34.180 --> 00:01:36.470
Another is the supplement
model, which

00:01:36.470 --> 00:01:38.300
represents your user data.

00:01:38.300 --> 00:01:41.320
There are other models like
the attachment model that

00:01:41.320 --> 00:01:46.710
represents attachments and their
upload status, gadgets,

00:01:46.710 --> 00:01:49.100
participants suggestions,
spelling suggestions--

00:01:49.100 --> 00:01:52.940
all these things have their
own data models.

00:01:52.940 --> 00:01:55.210
Now normally when you build a
data model, you build it up

00:01:55.210 --> 00:01:58.760
out of canonical, mathematical,
pure data

00:01:58.760 --> 00:02:01.350
structures that have
tried and tested--

00:02:01.350 --> 00:02:06.020
things like sets, maps,
lists, tuples, values.

00:02:06.020 --> 00:02:10.430
Now all these kinds of
abstractions have a natural

00:02:10.430 --> 00:02:15.240
operational transformation under
concurrent mutations.

00:02:15.240 --> 00:02:20.780
For example, if I have a
distributed counter and my

00:02:20.780 --> 00:02:24.870
application increments it, and
remotely gets incremented, its

00:02:24.870 --> 00:02:27.590
natural at the convergence
state of those two

00:02:27.590 --> 00:02:28.310
operations--

00:02:28.310 --> 00:02:31.770
once they go over the wire
and get transformed--

00:02:31.770 --> 00:02:35.540
the natural resolution is to
increment the counter twice.

00:02:35.540 --> 00:02:38.600
So all these kinds of basic
structures have natural

00:02:38.600 --> 00:02:43.210
intuitive ways that concurrent
mutations should resolve.

00:02:43.210 --> 00:02:46.970
However, on the Wave platform,
there is really just one type

00:02:46.970 --> 00:02:49.600
that you get to use, and
that's the type of an

00:02:49.600 --> 00:02:52.280
annotated XML document.

00:02:52.280 --> 00:02:55.450
So if you need to build up your
application model with

00:02:55.450 --> 00:02:58.630
the data structures that you
want, then how do you do it

00:02:58.630 --> 00:03:00.560
when there's just one structure
that you can use?

00:03:00.560 --> 00:03:01.370
So that's the problem.

00:03:01.370 --> 00:03:04.360
How do you build wavey data?

00:03:04.360 --> 00:03:09.940
So what I'm going to be talking
about is a strategy to

00:03:09.940 --> 00:03:18.860
use this one super type as a
type for all purposes and

00:03:18.860 --> 00:03:22.155
making it look like simpler
types by embedding simpler

00:03:22.155 --> 00:03:25.160
types into the XML.

00:03:25.160 --> 00:03:28.640
So we call this an embedding.

00:03:28.640 --> 00:03:34.100
And in order to do an embedding,
you need to address

00:03:34.100 --> 00:03:35.650
many different concerns.

00:03:35.650 --> 00:03:38.860
You need to be able to encode
the state, encode mutations.

00:03:38.860 --> 00:03:41.250
The concurrent resolution
of the transform

00:03:41.250 --> 00:03:42.535
needs to be well formed.

00:03:42.535 --> 00:03:45.040
You need to be able to normalize
the state, garbage

00:03:45.040 --> 00:03:48.520
collection-- all these
different concerns.

00:03:48.520 --> 00:03:51.290
All I want to point out is that
it's not as trivial as it

00:03:51.290 --> 00:03:52.950
might seem.

00:03:52.950 --> 00:03:56.880
But fortunately in the Wave
library's repository, there's

00:03:56.880 --> 00:03:58.950
a bunch of embeddings that
we've already done.

00:03:58.950 --> 00:04:01.870
So if you're building an
application model to sit on

00:04:01.870 --> 00:04:06.370
top of a wavelet, then we
already have done a lot of the

00:04:06.370 --> 00:04:10.080
work, ironed out the corner
cases, found all the gotchas,

00:04:10.080 --> 00:04:13.530
for a bunch of basic structures,
like basic values,

00:04:13.530 --> 00:04:15.869
booleans, maps, lists, sets.

00:04:19.100 --> 00:04:21.920
So I'm going to talk about
what it means to embed a

00:04:21.920 --> 00:04:23.080
structure in Wave.

00:04:23.080 --> 00:04:26.350
And I'm going to give
an example.

00:04:26.350 --> 00:04:27.810
So the basic idea is
that you need to

00:04:27.810 --> 00:04:30.360
think about two mappings.

00:04:30.360 --> 00:04:34.510
One mapping is to interpret
the region of a document.

00:04:34.510 --> 00:04:37.500
And by document, I mean
data document.

00:04:37.500 --> 00:04:40.070
So in your application you can
choose to use whatever

00:04:40.070 --> 00:04:41.390
documents you want
in a wavelet.

00:04:41.390 --> 00:04:44.350
Not all of them are textual
documents that are part of a

00:04:44.350 --> 00:04:44.960
conversation.

00:04:44.960 --> 00:04:47.400
You can have arbitrary documents
that aren't seen.

00:04:47.400 --> 00:04:49.260
They're just there
to hold data.

00:04:49.260 --> 00:04:53.290
So you need to have a way to
interpret a region of this XML

00:04:53.290 --> 00:04:56.690
onto an abstract state, like
interpret it as a list, or

00:04:56.690 --> 00:05:00.290
interpret it as a value,
interpret it as a map.

00:05:00.290 --> 00:05:04.350
And the second thing you need
to do is given an abstract

00:05:04.350 --> 00:05:08.400
mutation like adding a value
to a set or decrementing a

00:05:08.400 --> 00:05:13.690
counter, given a mutation on
your abstract data type, a way

00:05:13.690 --> 00:05:18.530
to embed that mutation as an
XML document mutation.

00:05:18.530 --> 00:05:20.580
So these two mappings, the
interpretation and the

00:05:20.580 --> 00:05:23.560
embedding, have a number
of constraints that

00:05:23.560 --> 00:05:26.120
they have to satisfy.

00:05:26.120 --> 00:05:29.810
They need to commute, compose,
and transform.

00:05:29.810 --> 00:05:34.910
So just this first property
of needing to commute--

00:05:34.910 --> 00:05:38.230
this just says that if you
interpret then mutate, you get

00:05:38.230 --> 00:05:40.165
the same result as if you
mutate, then interpret.

00:05:44.310 --> 00:05:48.170
Again there's not enough
time to delve

00:05:48.170 --> 00:05:49.640
too deeply into detail.

00:05:49.640 --> 00:05:53.030
The main point is that it does
require some thought to do it.

00:05:53.030 --> 00:05:54.270
It's not completely trivial.

00:05:54.270 --> 00:05:56.270
There's plenty of gotchas.

00:05:56.270 --> 00:05:58.220
And we've done a lot
of the work for

00:05:58.220 --> 00:06:00.130
basic structures already.

00:06:00.130 --> 00:06:01.970
So these are some of the things
that you need to think

00:06:01.970 --> 00:06:04.070
about if you're writing
and embedding.

00:06:04.070 --> 00:06:07.070
The main thing you need to know
is the fine details of

00:06:07.070 --> 00:06:10.500
how the XML document operations
compose and

00:06:10.500 --> 00:06:13.860
transform and commute.

00:06:13.860 --> 00:06:17.160
And you also need to know
given your embedding of

00:06:17.160 --> 00:06:20.500
mutations, what is the entire
space of possible document

00:06:20.500 --> 00:06:25.580
states that could be reached
under all forms of composition

00:06:25.580 --> 00:06:27.800
and transformation.

00:06:27.800 --> 00:06:32.510
You need to think about making
sure that the empty state is a

00:06:32.510 --> 00:06:33.650
meaningful state--

00:06:33.650 --> 00:06:37.340
all these different concerns.

00:06:37.340 --> 00:06:39.120
So I'm just going to run through
probably the most

00:06:39.120 --> 00:06:41.860
trivial example of
an embedding.

00:06:41.860 --> 00:06:44.710
And this is a monotonic map.

00:06:44.710 --> 00:06:49.610
So the use case that drove
needing to use this monotonic

00:06:49.610 --> 00:06:53.820
map was in the supplement
model, which tracks your

00:06:53.820 --> 00:06:57.000
personal user data on
a wave, we track

00:06:57.000 --> 00:06:59.540
your reading activity.

00:06:59.540 --> 00:07:02.050
So when you read a blip, we
record that you've read it.

00:07:02.050 --> 00:07:05.220
And the way we record that
you've read it is to record a

00:07:05.220 --> 00:07:09.450
map of the blip ID to the
version of the blip at which

00:07:09.450 --> 00:07:11.020
you read it.

00:07:11.020 --> 00:07:13.920
So essentially we want a
map-like abstraction where we

00:07:13.920 --> 00:07:18.670
put blip ID and version numbers
in, and we can read a

00:07:18.670 --> 00:07:21.190
version number out for an ID.

00:07:21.190 --> 00:07:22.550
So that's just a regular map.

00:07:22.550 --> 00:07:25.440
What makes it monotonic is
that we want the behavior

00:07:25.440 --> 00:07:29.580
where if you happen to read a
wave in an old state, then

00:07:29.580 --> 00:07:32.050
that doesn't override the fact
that you've read it in the

00:07:32.050 --> 00:07:33.150
newer state.

00:07:33.150 --> 00:07:36.290
So if you've read a blip at
version 100, and then for

00:07:36.290 --> 00:07:39.030
whatever reason you see a stale
or old copy of the wave,

00:07:39.030 --> 00:07:42.680
and you read that blip again
at version 20, we want the

00:07:42.680 --> 00:07:46.420
state to remain that you've
read it at version 100.

00:07:46.420 --> 00:07:49.190
So this means that as you put
things in the map, we only

00:07:49.190 --> 00:07:52.570
take the maximum value of
versions that you put in.

00:07:52.570 --> 00:07:57.030
So this little XML fragment
here is how we embed a map

00:07:57.030 --> 00:08:01.540
into XML of a data document.

00:08:01.540 --> 00:08:04.470
So this is just a
fragment within

00:08:04.470 --> 00:08:07.440
some part of a document.

00:08:07.440 --> 00:08:09.140
We use entry elements.

00:08:09.140 --> 00:08:13.350
Here they've got a tag name of
read with two attributes for

00:08:13.350 --> 00:08:15.422
an ID and a version.

00:08:15.422 --> 00:08:21.130
And under concurrent activity,
you can get multiple entries

00:08:21.130 --> 00:08:22.950
with the same ID, multiple
entries with

00:08:22.950 --> 00:08:25.120
the same ID and version.

00:08:25.120 --> 00:08:28.120
You can get multiple entries of
the same version of course.

00:08:28.120 --> 00:08:30.990
So you can get pretty much
any arbitrary state.

00:08:30.990 --> 00:08:36.870
And so the way we interpret it
is just to pretty obviously of

00:08:36.870 --> 00:08:39.450
all the entries for a given
ID, pick the one with the

00:08:39.450 --> 00:08:40.230
maximum value.

00:08:40.230 --> 00:08:43.140
And that's the interpretation
as a map.

00:08:43.140 --> 00:08:46.690
Another important property is
that any other elements that

00:08:46.690 --> 00:08:49.950
happen to be in there, we
just leave them alone.

00:08:49.950 --> 00:08:54.510
We don't consider that the map
sort of owns this region.

00:08:54.510 --> 00:08:56.500
This means you can embed many
of these structures in the

00:08:56.500 --> 00:08:58.560
same place in an XML document.

00:09:01.690 --> 00:09:04.080
So the interpretation
is just to pick the

00:09:04.080 --> 00:09:05.860
maximum of what's there.

00:09:05.860 --> 00:09:08.130
These are the embedding
strategies for

00:09:08.130 --> 00:09:09.920
mutating the map.

00:09:09.920 --> 00:09:13.870
And again the monotonic map is
one of the simplest cases.

00:09:20.830 --> 00:09:24.890
So in this case the mutation to
put a value in the map, the

00:09:24.890 --> 00:09:29.040
way we mutate the XML structure
is we just prepend a

00:09:29.040 --> 00:09:33.490
new entry into the list, and
then afterwards find all the

00:09:33.490 --> 00:09:35.770
other entries that have the same
ID and delete them all.

00:09:35.770 --> 00:09:38.050
That's like a garbage
collection step.

00:09:38.050 --> 00:09:40.790
And it's important to add the
new entry first before

00:09:40.790 --> 00:09:42.750
deleting the other ones.

00:09:42.750 --> 00:09:47.180
Because this comes from the
atomicity and where the

00:09:47.180 --> 00:09:50.940
transaction boundaries are for
the document operations.

00:09:50.940 --> 00:09:54.580
This compound operation of
putting in entries and

00:09:54.580 --> 00:09:57.920
deleting other entries can
get arbitrarily framed or

00:09:57.920 --> 00:09:59.430
arbitrarily split up.

00:09:59.430 --> 00:10:01.070
So you need to understand
what's going on in the

00:10:01.070 --> 00:10:04.550
document operations to know that
you need to put the new

00:10:04.550 --> 00:10:06.640
entry in first rather than
delete the other ones, so you

00:10:06.640 --> 00:10:09.570
don't get invalid intermediate
state.

00:10:09.570 --> 00:10:11.730
And the other embeddings are
pretty straightforward.

00:10:11.730 --> 00:10:14.930
So just to apply that
to the example--

00:10:14.930 --> 00:10:19.030
for this state on the left, if
we interpret that as a map and

00:10:19.030 --> 00:10:23.650
we want to do the abstract
mutation to put a new value in

00:10:23.650 --> 00:10:30.220
the map of mapping the key aab
to the value 30, then on the

00:10:30.220 --> 00:10:31.720
right, we can see the
change that that

00:10:31.720 --> 00:10:33.290
makes to the XML structure.

00:10:33.290 --> 00:10:36.450
It adds a new entry and deletes
all the other entries

00:10:36.450 --> 00:10:38.960
that have the same ID.

00:10:38.960 --> 00:10:41.600
And this strategy composes
properly.

00:10:41.600 --> 00:10:43.310
It works under transforms.

00:10:43.310 --> 00:10:47.740
So if two people update the
map at the same time, the

00:10:47.740 --> 00:10:52.020
resulting XML state that comes
from the document operations

00:10:52.020 --> 00:10:55.550
and the document transforms,
that resulting XML state gets

00:10:55.550 --> 00:10:59.330
interpreted as the correct
map state that we want.

00:11:02.530 --> 00:11:06.000
So this is just an example of
how to do it in the code that

00:11:06.000 --> 00:11:07.450
Wave libraries gives you.

00:11:07.450 --> 00:11:12.410
And it's designed to be
really easy to use.

00:11:12.410 --> 00:11:14.780
I hope you can see this
reasonably well.

00:11:14.780 --> 00:11:18.690
All I want to point out is
that there's a bunch of

00:11:18.690 --> 00:11:22.490
utility classes called document
based monotonic map,

00:11:22.490 --> 00:11:25.080
document based value, document
based boolean,

00:11:25.080 --> 00:11:27.320
document based list.

00:11:27.320 --> 00:11:31.060
All these embedding strategies
are there in the libraries.

00:11:31.060 --> 00:11:33.860
In this example, we're creating
a monotonic map in a

00:11:33.860 --> 00:11:35.410
region of a document.

00:11:35.410 --> 00:11:37.700
And what that gives us
is something that

00:11:37.700 --> 00:11:39.540
has a map-like interface.

00:11:39.540 --> 00:11:43.700
So below you can see that
we just put values in.

00:11:43.700 --> 00:11:45.100
And we can get values out.

00:11:45.100 --> 00:11:47.750
And we can treat this thing just
like a map even though

00:11:47.750 --> 00:11:50.550
it's all XML under the hood.

00:11:50.550 --> 00:11:53.040
All these structures
are also live.

00:11:53.040 --> 00:11:54.420
You can add listeners.

00:11:54.420 --> 00:11:55.300
And the listeners get
notified when the

00:11:55.300 --> 00:11:56.760
abstract state changes.

00:12:00.880 --> 00:12:05.360
So there's a bunch of provider
types that are already there.

00:12:08.090 --> 00:12:12.150
And that's all I was going
to talk about.

00:12:12.150 --> 00:12:15.360
Christian is now going to come
up and talk about how you

00:12:15.360 --> 00:12:19.490
might do things differently.

00:12:19.490 --> 00:12:20.810
Any questions?

00:12:20.810 --> 00:12:23.410
We might take them all
at the end I think.

00:12:23.410 --> 00:12:24.410
CHRISTIAN OHLER: Cool.

00:12:24.410 --> 00:12:26.410
I need to [INAUDIBLE].

00:12:26.410 --> 00:12:27.660
DAVID HEARNDEN: Yep.

00:13:43.000 --> 00:13:44.466
CHRISTIAN OHLER: All right.

00:13:44.466 --> 00:13:47.160
I'm just going to
give you a few

00:13:47.160 --> 00:13:49.630
relatively high level ideas.

00:13:49.630 --> 00:13:50.740
Because we don't
have much time.

00:13:50.740 --> 00:13:53.120
I'm not going to get into
too much technicalities.

00:13:53.120 --> 00:13:56.290
Because I think they would only
be of interest to a small

00:13:56.290 --> 00:13:57.200
fraction of you.

00:13:57.200 --> 00:14:01.460
And you can grab me later if
you want to discuss this in

00:14:01.460 --> 00:14:02.710
more detail.

00:14:06.810 --> 00:14:11.250
The basic problem
the I see is--

00:14:11.250 --> 00:14:11.440
OK.

00:14:11.440 --> 00:14:13.130
So that's not actually
the problem.

00:14:13.130 --> 00:14:15.750
Wave has made OT
fairly popular.

00:14:15.750 --> 00:14:19.850
I think many more people are now
aware that OT is just very

00:14:19.850 --> 00:14:22.170
useful for those kind
of collaboration

00:14:22.170 --> 00:14:26.120
for real time stuff.

00:14:26.120 --> 00:14:28.290
And this one is a problem,
whereas OT is really

00:14:28.290 --> 00:14:29.800
complicated.

00:14:29.800 --> 00:14:33.470
There are very few people
actually who've gone through

00:14:33.470 --> 00:14:35.360
the code and understood
all of it.

00:14:35.360 --> 00:14:38.380
It's many thousands
of lines of code.

00:14:44.640 --> 00:14:47.280
There's a risk that this leads
to a perception that OT is

00:14:47.280 --> 00:14:47.970
really complicated.

00:14:47.970 --> 00:14:50.290
But that's not true.

00:14:50.290 --> 00:14:54.990
You can actually write your
own OT code to solve very

00:14:54.990 --> 00:14:57.940
similar problems,
as Wave does, in

00:14:57.940 --> 00:14:59.190
a weekend or something.

00:15:02.120 --> 00:15:06.020
So I'm worried that some people
will look at Wave's OT

00:15:06.020 --> 00:15:09.510
code and try to understand it
and think, well, this is

00:15:09.510 --> 00:15:10.080
really scary.

00:15:10.080 --> 00:15:15.800
I'd better just use this as a
black box and I'm just going

00:15:15.800 --> 00:15:19.160
to link it in as is it.

00:15:19.160 --> 00:15:24.630
So I want to ask you
not to do that.

00:15:24.630 --> 00:15:27.840
Because just because Wave's OT
code was developed by a few

00:15:27.840 --> 00:15:30.650
Google engineers doesn't mean
that it's particularly good.

00:15:30.650 --> 00:15:33.620
I think it's massively
overcomplicated.

00:15:41.800 --> 00:15:50.560
So I recognize that in order
for the Wave ecosystem to

00:15:50.560 --> 00:15:53.230
work, we need some sort of
standardization or we can't

00:15:53.230 --> 00:15:56.320
have everybody doing
their own OT.

00:15:56.320 --> 00:15:59.370
We need some kind of
compatibility in order for

00:15:59.370 --> 00:16:02.410
systems to be able to
speak to each other.

00:16:02.410 --> 00:16:05.770
But I don't actually think, as
I said, that all of you would

00:16:05.770 --> 00:16:07.460
go off and do their own OT.

00:16:07.460 --> 00:16:09.430
There's only a few people who
are interested in this.

00:16:09.430 --> 00:16:13.660
And I think we should be able
to iterate on this stuff.

00:16:13.660 --> 00:16:18.530
We shouldn't be stuck with code
that Google published a

00:16:18.530 --> 00:16:24.320
little while ago and now base
all of the future on this.

00:16:27.550 --> 00:16:34.310
I think it's very risky to
standardize on this magic

00:16:34.310 --> 00:16:36.880
black box that is actually too
complicated for anyone to

00:16:36.880 --> 00:16:38.130
understand.

00:16:39.730 --> 00:16:49.440
And I don't think we can have at
the core of the ecosystem,

00:16:49.440 --> 00:16:55.450
this thing that nobody
can really work with.

00:16:55.450 --> 00:17:01.260
Also the businesses that are
putting this Wave OT core at

00:17:01.260 --> 00:17:07.310
the heart of their products, I
wonder whether they actually

00:17:07.310 --> 00:17:10.569
have engineers who are able to
make changes to the core of

00:17:10.569 --> 00:17:12.680
their product.

00:17:12.680 --> 00:17:14.364
I would like to talk to them.

00:17:14.364 --> 00:17:20.530
I would like to talk to those
engineers that can work on the

00:17:20.530 --> 00:17:21.609
Wave OT code.

00:17:21.609 --> 00:17:24.040
Because it's very hard.

00:17:24.040 --> 00:17:26.160
I would like to meet
those people.

00:17:26.160 --> 00:17:27.960
So it could be that it's
already too late

00:17:27.960 --> 00:17:30.150
to change it here.

00:17:30.150 --> 00:17:33.480
But I hope it's not.

00:17:33.480 --> 00:17:37.110
Because Wave is still
rather young.

00:17:37.110 --> 00:17:47.220
So the root cause of the
complexity of Wave's OT lies

00:17:47.220 --> 00:17:49.010
in two things as I
understand it.

00:17:51.700 --> 00:17:53.430
That's inheriting annotations.

00:17:53.430 --> 00:17:59.350
I think that the Wave model deep
dark talk explained this

00:17:59.350 --> 00:17:59.780
a little bit.

00:17:59.780 --> 00:18:05.440
So when you insert a new
character, then it inherits

00:18:05.440 --> 00:18:08.570
annotations from its
left neighbor.

00:18:08.570 --> 00:18:13.140
And this together with the
composability of operations is

00:18:13.140 --> 00:18:15.010
what makes everything
complicated.

00:18:15.010 --> 00:18:19.440
And I'm just making this
assertion here without

00:18:19.440 --> 00:18:21.290
providing any evidence.

00:18:21.290 --> 00:18:23.690
But you're going to believe
me anyway, because

00:18:23.690 --> 00:18:25.640
I appear very credible.

00:18:39.550 --> 00:18:41.950
I said inheriting annotation
is part of the problem.

00:18:41.950 --> 00:18:48.650
But let me point out that this
is only inheriting annotations

00:18:48.650 --> 00:18:50.710
at the OT core.

00:18:50.710 --> 00:18:54.430
You can still have your editor
as you're typing and set up

00:18:54.430 --> 00:18:56.710
your editor to send whatever
annotations it wants for the

00:18:56.710 --> 00:18:58.290
newly inserted text.

00:18:58.290 --> 00:19:03.150
The question is just does the
core OT conflict resolution

00:19:03.150 --> 00:19:07.350
algorithm inherent annotations
automatically for you?

00:19:07.350 --> 00:19:10.480
Or does it assume that newly
inserted text shouldn't have

00:19:10.480 --> 00:19:13.220
any annotations other than what
was explicitly specified?

00:19:19.550 --> 00:19:25.690
So about composition,
composition is the ability to

00:19:25.690 --> 00:19:27.730
express arbitrary changes to a

00:19:27.730 --> 00:19:29.410
document in a single operation.

00:19:29.410 --> 00:19:34.870
So those of you who have looked
at Wave's operations

00:19:34.870 --> 00:19:37.190
probably noticed that they
have this shape--

00:19:37.190 --> 00:19:39.820
retain 20 characters,
and insert ABC.

00:19:39.820 --> 00:19:43.360
Then retain five more and
insert some more text.

00:19:43.360 --> 00:19:47.330
So in one operation you can make
arbitrary changes to a

00:19:47.330 --> 00:19:51.420
document, in arbitrarily
many places.

00:19:51.420 --> 00:19:58.620
And when you first see this idea
you sort of think, that

00:19:58.620 --> 00:19:59.350
looks kind of nice.

00:19:59.350 --> 00:20:01.720
I hadn't thought of that.

00:20:01.720 --> 00:20:02.700
It seems very appealing.

00:20:02.700 --> 00:20:06.640
And you think, yeah,
that sounds good.

00:20:06.640 --> 00:20:08.040
Let's go with that.

00:20:08.040 --> 00:20:10.270
It seems mathematically
very appealing.

00:20:10.270 --> 00:20:13.830
It seems like a neat approach.

00:20:13.830 --> 00:20:19.730
But the truth is that it makes
everything really complicated.

00:20:19.730 --> 00:20:24.175
So if you drop either of these
two properties in inheriting

00:20:24.175 --> 00:20:29.100
annotations or composability of
operations, you get a much,

00:20:29.100 --> 00:20:31.350
much simpler OT system.

00:20:31.350 --> 00:20:35.480
And I think the bigger
simplification would come from

00:20:35.480 --> 00:20:37.136
dropping composition.

00:20:42.270 --> 00:20:47.060
So operations that are not
composable would look

00:20:47.060 --> 00:20:47.820
roughly like this.

00:20:47.820 --> 00:20:49.460
You would have operations
to insert or

00:20:49.460 --> 00:20:51.480
delete contiguous regions.

00:20:51.480 --> 00:20:54.400
So you could submerge edits that
are right next to each

00:20:54.400 --> 00:20:56.730
other into one operation.

00:20:56.730 --> 00:21:01.260
But you no longer require that
insertions and deletions in

00:21:01.260 --> 00:21:03.220
completely different places are

00:21:03.220 --> 00:21:07.380
expressed as one operation.

00:21:07.380 --> 00:21:09.210
Then you still need annotation
operations.

00:21:09.210 --> 00:21:12.190
You can restrict them to a
single key in one contiguous

00:21:12.190 --> 00:21:13.970
region also.

00:21:13.970 --> 00:21:17.780
That part doesn't really
matter so much.

00:21:17.780 --> 00:21:20.480
Update and replace attributes
are also not really part of

00:21:20.480 --> 00:21:20.870
the problem.

00:21:20.870 --> 00:21:28.050
You can keep them the
way they are.

00:21:28.050 --> 00:21:31.060
And the details of what this
looks like depends on whether

00:21:31.060 --> 00:21:33.090
you want invertible
operations or not.

00:21:38.740 --> 00:21:42.520
So do we need composition
actually?

00:21:42.520 --> 00:21:44.980
So the Wave code uses
composition

00:21:44.980 --> 00:21:46.800
in quite a few places.

00:21:46.800 --> 00:21:49.520
And we need some sort
of replacement.

00:21:56.300 --> 00:21:59.820
So these operations would no
longer be closed under

00:21:59.820 --> 00:22:01.090
composition or transform,
right?

00:22:01.090 --> 00:22:04.190
But if you instead look at lists
of operations, as your

00:22:04.190 --> 00:22:09.840
primitive, then you still have
a space that is closed under

00:22:09.840 --> 00:22:10.480
composition.

00:22:10.480 --> 00:22:13.960
Because you can just append
lists of operations as your

00:22:13.960 --> 00:22:15.420
composed function.

00:22:15.420 --> 00:22:21.000
And the transform property
is obvious.

00:22:21.000 --> 00:22:25.670
So the problem with just
appending in order to compose

00:22:25.670 --> 00:22:30.320
is that you never reduce the
size of the operation.

00:22:30.320 --> 00:22:31.650
You don't really win anything.

00:22:31.650 --> 00:22:38.470
So we would have to introduce
a compaction function that

00:22:38.470 --> 00:22:41.820
tries to merge a list of
operations into a small number

00:22:41.820 --> 00:22:45.020
of operations by dropping
operations that cancel each

00:22:45.020 --> 00:22:51.007
other out or that merges
insertions or deletions that

00:22:51.007 --> 00:22:52.950
are contiguous.

00:22:52.950 --> 00:22:58.500
So it would probably have to
sort the list first by index,

00:22:58.500 --> 00:23:04.910
taking care that the indices
actually shift whenever you

00:23:04.910 --> 00:23:09.750
change the order of
two operations.

00:23:09.750 --> 00:23:13.250
And so all the code that
currently invokes composition

00:23:13.250 --> 00:23:16.260
and assumes that the output is
just a single operation would

00:23:16.260 --> 00:23:19.560
have to be changed to deal with
the fact that you can now

00:23:19.560 --> 00:23:22.560
have a whole list of operations
coming out of the

00:23:22.560 --> 00:23:23.350
composition function.

00:23:23.350 --> 00:23:25.875
But I think that's
a minor change.

00:23:32.480 --> 00:23:36.920
So I think one other detail is
that you would probably also

00:23:36.920 --> 00:23:40.120
need to change transform to
return a list of operations in

00:23:40.120 --> 00:23:44.030
order for these simple
operations to work.

00:23:44.030 --> 00:23:46.930
You will notice this
if you actually

00:23:46.930 --> 00:23:49.910
start writing the code.

00:23:49.910 --> 00:23:53.620
This gives you the same kind of
product of a feature set as

00:23:53.620 --> 00:23:55.700
the OT that we have right now.

00:23:55.700 --> 00:24:02.360
So it would not be a user
visible change.

00:24:05.810 --> 00:24:08.890
And all you have to do
is write the code.

00:24:08.890 --> 00:24:13.590
Now the code will
be very simple.

00:24:13.590 --> 00:24:18.020
But in order to ensure the
correctness of our OT code,

00:24:18.020 --> 00:24:19.860
we've used one particular
technique.

00:24:19.860 --> 00:24:22.935
And that is randomized
testing.

00:24:25.500 --> 00:24:29.330
I have the impression that this
is already fairly well

00:24:29.330 --> 00:24:34.510
understood by the people
who care about the

00:24:34.510 --> 00:24:35.270
code at this level.

00:24:35.270 --> 00:24:39.270
So from talking to a few of
you, I have the impression

00:24:39.270 --> 00:24:41.200
that you have already
seen the code.

00:24:41.200 --> 00:24:43.860
And if you haven't,
just talk to me.

00:24:48.110 --> 00:24:49.960
In addition to defining these
compose and transform

00:24:49.960 --> 00:24:52.230
functions, you also define
a function that takes the

00:24:52.230 --> 00:24:56.060
document state and just
generates a random operation,

00:24:56.060 --> 00:24:59.890
just a random change to that
document state that is valid

00:24:59.890 --> 00:25:04.970
from the space of all valid
operations that could be

00:25:04.970 --> 00:25:06.070
applied to the state.

00:25:06.070 --> 00:25:08.230
And then you just invoke
that function twice.

00:25:08.230 --> 00:25:11.850
And then you can sort of build
these transform diagrams.

00:25:11.850 --> 00:25:15.430
You take two random operations,
transform them

00:25:15.430 --> 00:25:19.970
against each other, and look
whether the outcome

00:25:19.970 --> 00:25:21.090
converges or not.

00:25:21.090 --> 00:25:24.640
That's one of the fundamental
properties that you want your

00:25:24.640 --> 00:25:26.290
OT code to satisfy.

00:25:26.290 --> 00:25:29.940
You may also be able to use
a model checker or theorem

00:25:29.940 --> 00:25:32.570
improver on this simplified
version of OT.

00:25:32.570 --> 00:25:35.070
Perhaps it's simple enough.

00:25:35.070 --> 00:25:38.880
I haven't thought
about it much.

00:25:38.880 --> 00:25:44.040
And again the random operation
generator that we have looks

00:25:44.040 --> 00:25:45.420
really complicated.

00:25:45.420 --> 00:25:48.270
But that is only because the
operations are composable, and

00:25:48.270 --> 00:25:50.460
because annotations inherit.

00:25:50.460 --> 00:25:55.040
So don't look at the code in too
much detail and be scared

00:25:55.040 --> 00:25:57.280
at the complexity.

00:25:57.280 --> 00:25:59.810
Because if you do something
simpler then the complexity

00:25:59.810 --> 00:26:01.060
will go away.

00:26:06.950 --> 00:26:10.710
So this is the rich text
OT that Wave provides.

00:26:10.710 --> 00:26:14.250
This is how you could
simplify it.

00:26:14.250 --> 00:26:15.900
But rich text isn't
everything.

00:26:15.900 --> 00:26:19.160
As David has just discussed, we
actually want to represent

00:26:19.160 --> 00:26:20.410
data as well.

00:26:22.810 --> 00:26:29.940
And using Wave's OT as a
foundation for abstract data

00:26:29.940 --> 00:26:33.990
types, it is possible, as he has
discussed, and there are

00:26:33.990 --> 00:26:37.700
some clever ideas in the
approaches that we are taking.

00:26:40.290 --> 00:26:42.360
But that doesn't mean
it's a good idea.

00:26:46.390 --> 00:26:48.730
Using Wave's OT as a foundation
for abstract data

00:26:48.730 --> 00:26:52.910
types actually makes your life
harder and not easier--

00:26:52.910 --> 00:26:54.960
how do we use something really
complicated to do something

00:26:54.960 --> 00:26:55.790
really simple?

00:26:55.790 --> 00:26:59.980
And it's an interesting
intellectual challenge.

00:26:59.980 --> 00:27:04.610
And we sort of tried to go
with this XML data type.

00:27:04.610 --> 00:27:07.175
Because we thought it's probably
expressive enough for

00:27:07.175 --> 00:27:08.560
our purposes, and it is.

00:27:08.560 --> 00:27:13.660
But the code that you need in
order to express what you want

00:27:13.660 --> 00:27:16.560
is quite a lot.

00:27:19.990 --> 00:27:23.950
And as some of you has already
discovered, writing OT code

00:27:23.950 --> 00:27:26.670
for lists, and maps, and tuples,
and so on, for a few

00:27:26.670 --> 00:27:33.590
of these primitive well-known
types that programmers use all

00:27:33.590 --> 00:27:36.660
the time is actually
really simple.

00:27:36.660 --> 00:27:39.430
And these will be a much
better foundation for

00:27:39.430 --> 00:27:44.870
embedding higher level
data structures

00:27:44.870 --> 00:27:46.300
that you want to express.

00:27:52.500 --> 00:27:57.560
And so one idea that has been
discussed a lot is using JSON

00:27:57.560 --> 00:27:59.050
instead of XML--

00:27:59.050 --> 00:28:01.380
Wave was based on XML.

00:28:01.380 --> 00:28:05.700
But JSON is also a standardized

00:28:05.700 --> 00:28:06.950
representation for data.

00:28:09.480 --> 00:28:13.600
But it expresses the types
of things better.

00:28:13.600 --> 00:28:19.690
It's just these tags and
attributes and text, whereas

00:28:19.690 --> 00:28:24.075
JSON is erase and maps and
integers, and so on.

00:28:24.075 --> 00:28:29.070
So it's actually closer to the
way we program than XML is.

00:28:33.290 --> 00:28:39.670
One final thing that Wave
got quite wrong is the

00:28:39.670 --> 00:28:42.430
representation of cursors.

00:28:42.430 --> 00:28:44.270
Well we didn't quite
get it wrong.

00:28:44.270 --> 00:28:50.470
We represent them as annotations
in the document.

00:28:50.470 --> 00:28:53.600
And all annotation changes are
persisted as part of the

00:28:53.600 --> 00:28:54.970
document history.

00:28:54.970 --> 00:28:59.730
And this turns out to have quite
a high storage cost.

00:28:59.730 --> 00:29:02.020
Even though persisting cursor
movements is not something

00:29:02.020 --> 00:29:04.840
that we ever intended to
do, we just use the

00:29:04.840 --> 00:29:08.640
model in this way.

00:29:08.640 --> 00:29:13.760
And it worked, which is
why we stuck with it.

00:29:13.760 --> 00:29:19.830
But we've been fairly
unhappy about

00:29:19.830 --> 00:29:22.770
this on various occasions.

00:29:22.770 --> 00:29:29.630
And if you look at what you
really need to store for

00:29:29.630 --> 00:29:35.020
cursors, each session
has its own cursor.

00:29:35.020 --> 00:29:38.510
There is no real concurrent
modification of this cursor by

00:29:38.510 --> 00:29:40.190
multiple parties.

00:29:40.190 --> 00:29:43.650
It's just one client setting
its cursor position.

00:29:43.650 --> 00:29:46.700
So it's a much simpler
problem than OT.

00:29:46.700 --> 00:29:52.380
However the cursor position
needs to be adjusted whenever

00:29:52.380 --> 00:29:53.880
some text gets inserted
somewhere.

00:29:53.880 --> 00:30:02.710
So if you look at your document,
Hello World, with my

00:30:02.710 --> 00:30:08.740
cursor, in fact, at position 14,
if you just think of the

00:30:08.740 --> 00:30:13.190
cursors as a separate map that
is outside the document, then

00:30:13.190 --> 00:30:18.700
you need to adjust the cursor
positions whenever text gets

00:30:18.700 --> 00:30:24.320
inserted or deleted before the
cursor to keep the index in

00:30:24.320 --> 00:30:26.590
the same context.

00:30:26.590 --> 00:30:29.110
And this is also
not very hard.

00:30:29.110 --> 00:30:35.080
And you should talk to Soren
if you want to know more

00:30:35.080 --> 00:30:36.700
detail about this--

00:30:36.700 --> 00:30:38.230
or to me of course.

00:30:38.230 --> 00:30:39.480
And then I'll point
you to Soren.

00:30:42.950 --> 00:30:49.660
Similar ideas apply to read on
read state, as David Hearnden

00:30:49.660 --> 00:30:50.960
just discussed.

00:30:50.960 --> 00:30:54.070
We saw the read on read state
in XML with these monotonic

00:30:54.070 --> 00:30:55.080
maps and so on.

00:30:55.080 --> 00:31:00.540
But also the OT conflict
resolution for the read

00:31:00.540 --> 00:31:01.850
version is so simple.

00:31:01.850 --> 00:31:03.100
You just take the maximum.

00:31:08.270 --> 00:31:10.600
You don't really need history
for this either.

00:31:10.600 --> 00:31:14.440
You don't need to store history
for what the user just

00:31:14.440 --> 00:31:17.660
read, when you're never going
to use [INAUDIBLE]

00:31:17.660 --> 00:31:18.910
on this information anyway.

00:31:23.410 --> 00:31:29.040
So to summarize, Wave's OT
is way over complicated.

00:31:29.040 --> 00:31:34.250
And having everybody rely on
this central piece without

00:31:34.250 --> 00:31:36.825
anybody understanding
it is fairly risky.

00:31:40.190 --> 00:31:43.960
I think we should be
able to fix this.

00:31:43.960 --> 00:31:45.210
Maybe we are not.

00:31:47.410 --> 00:31:51.810
Randomized testing actually
makes it relatively easy.

00:31:51.810 --> 00:31:55.000
You still need to take care to
actually write your random

00:31:55.000 --> 00:31:57.330
generator properly if your
random generator is bad.

00:31:57.330 --> 00:32:03.060
And then again it's not
that hard to find

00:32:03.060 --> 00:32:04.420
bugs in your OT code.

00:32:07.320 --> 00:32:14.370
Wave's XML works to represent
data is much less nice than

00:32:14.370 --> 00:32:15.690
what we could have instead.

00:32:18.760 --> 00:32:20.990
And OT is not the only
synchronization

00:32:20.990 --> 00:32:22.770
mechanism in the world.

00:32:22.770 --> 00:32:25.880
And it has the disadvantage
of requiring

00:32:25.880 --> 00:32:28.670
history to be stored.

00:32:28.670 --> 00:32:33.220
And there are much simpler
mechanisms that you can use

00:32:33.220 --> 00:32:35.640
instead for certain
types of data.

00:32:39.940 --> 00:32:41.000
OK.

00:32:41.000 --> 00:32:46.170
So that is it.

00:32:46.170 --> 00:32:49.756
David and I will answer
questions that you may have.

00:32:54.040 --> 00:32:55.020
Yes.

00:32:55.020 --> 00:33:00.300
AUDIENCE: [INAUDIBLE] the
immediate transmission of the

00:33:00.300 --> 00:33:05.520
live editing behavior, does
that, again, complicate the

00:33:05.520 --> 00:33:06.770
[INAUDIBLE]

00:33:11.806 --> 00:33:12.798
would that help?

00:33:12.798 --> 00:33:15.898
Because obviously you've
got larger messages.

00:33:15.898 --> 00:33:17.758
You've got more compaction
in a sense.

00:33:21.740 --> 00:33:26.540
CHRISTIAN OHLER: I think you can
keep the same liveness if

00:33:26.540 --> 00:33:31.420
you want and still have
a simple OT algorithm.

00:33:34.860 --> 00:33:35.500
More questions?

00:33:35.500 --> 00:33:38.612
There were quite a few more.

00:33:38.612 --> 00:33:43.094
AUDIENCE: I know the Docs team
uses the vertical OT.

00:33:43.094 --> 00:33:46.580
Do they use a simpler version
than what Wave's using?

00:33:46.580 --> 00:33:48.990
CHRISTIAN OHLER: They use a
version that is both simpler

00:33:48.990 --> 00:33:50.240
and more complicated.

00:33:54.520 --> 00:34:01.740
So they have a less principled
approach to this.

00:34:01.740 --> 00:34:03.850
They didn't do any randomized
testing.

00:34:03.850 --> 00:34:06.990
And their OT code doesn't
actually converge.

00:34:06.990 --> 00:34:09.900
It doesn't matter if you use the
product most of the time.

00:34:13.500 --> 00:34:19.080
It's on the divergence that you
were mentioning yesterday.

00:34:19.080 --> 00:34:22.550
Docs actually has
that problem.

00:34:22.550 --> 00:34:27.389
So it doesn't really matter
much in practice.

00:34:27.389 --> 00:34:29.360
So for text editing, it doesn't
really matter that

00:34:29.360 --> 00:34:31.670
much in practice if you have
divergences briefly.

00:34:31.670 --> 00:34:33.909
Because as soon as
someone reloads

00:34:33.909 --> 00:34:35.050
something, it goes away.

00:34:35.050 --> 00:34:39.050
But if you want to synchronize
data, I think it's more

00:34:39.050 --> 00:34:39.940
problematic.

00:34:39.940 --> 00:34:45.489
Because humans don't have a very
strict interpretation of

00:34:45.489 --> 00:34:46.230
what they see anyway.

00:34:46.230 --> 00:34:47.719
But computers do.

00:34:51.980 --> 00:34:55.350
And their OT is also
fairly messy.

00:34:55.350 --> 00:34:58.260
But there are other problems
that they don't have.

00:34:58.260 --> 00:35:05.720
For example they didn't worry
about composability at all,

00:35:05.720 --> 00:35:09.590
which simplifies their approach
a little bit.

00:35:09.590 --> 00:35:10.850
More questions?

00:35:10.850 --> 00:35:12.043
Yes, please.

00:35:12.043 --> 00:35:15.060
AUDIENCE: Were there, I guess,
business cases that you guys

00:35:15.060 --> 00:35:18.440
did a more complicated version
like inherited annotations

00:35:18.440 --> 00:35:20.547
where the user clicks
Bold [INAUDIBLE]

00:35:23.482 --> 00:35:26.058
bolded because of inherits.

00:35:26.058 --> 00:35:27.860
Is that how you guys do that?

00:35:27.860 --> 00:35:30.620
Or just [INAUDIBLE]

00:35:30.620 --> 00:35:33.410
thing to realize later
[INAUDIBLE]?

00:35:33.410 --> 00:35:38.730
AUDIENCE: So this is exactly the
kind of situation that you

00:35:38.730 --> 00:35:43.900
have to think about when you
discuss whether you want

00:35:43.900 --> 00:35:45.150
inheriting annotations
are not--

00:35:48.120 --> 00:35:48.960
these use cases.

00:35:48.960 --> 00:35:53.060
So if you don't have inheriting
annotations, you

00:35:53.060 --> 00:35:56.400
need to send a little bit more
data in the case where you

00:35:56.400 --> 00:35:59.780
want annotations to inherit.

00:35:59.780 --> 00:36:02.480
You first click Bold and then
starts typing something--

00:36:07.000 --> 00:36:09.610
so the first character would
still have to be marked Bold

00:36:09.610 --> 00:36:11.990
explicitly by the editor.

00:36:11.990 --> 00:36:15.540
But the subsequent characters
would inherit the boldness

00:36:15.540 --> 00:36:17.250
from their left neighbor.

00:36:17.250 --> 00:36:21.300
You can save a little bit of
data transmission if you have

00:36:21.300 --> 00:36:23.060
inheriting annotations
in this situation.

00:36:23.060 --> 00:36:26.080
But there are many annotations
that you don't really want to

00:36:26.080 --> 00:36:28.800
inherit, for example the
spelling correction

00:36:28.800 --> 00:36:29.910
annotations.

00:36:29.910 --> 00:36:33.770
I think it's really annoying
that sometimes something is

00:36:33.770 --> 00:36:34.320
underlined.

00:36:34.320 --> 00:36:38.540
And if you have a somewhat
flaky connection, the

00:36:38.540 --> 00:36:42.650
annotation will extend to
everything else that you type

00:36:42.650 --> 00:36:44.950
until it hits the server and
comes back, and the server

00:36:44.950 --> 00:36:46.330
removes the annotation
for you.

00:36:46.330 --> 00:36:51.640
So there are some annotations
for which you want

00:36:51.640 --> 00:36:53.130
inheritance, and some
annotations for which you

00:36:53.130 --> 00:36:54.420
don't want inheritance.

00:36:54.420 --> 00:36:58.500
And maybe it would be best from
a perspective of catering

00:36:58.500 --> 00:37:04.840
to the use cases to have both
options on a per annotation

00:37:04.840 --> 00:37:05.590
basis or something.

00:37:05.590 --> 00:37:08.230
You could specify whether
they inherit or not.

00:37:08.230 --> 00:37:14.240
But adding this kind of logic
in the OT layer, again, it

00:37:14.240 --> 00:37:15.980
complicates it a little bit.

00:37:15.980 --> 00:37:17.980
And I don't know how much.

00:37:17.980 --> 00:37:20.630
I haven't thought about what it
would take to offer both of

00:37:20.630 --> 00:37:21.880
these options.

00:37:23.826 --> 00:37:29.079
AUDIENCE: Can you associate a
sort of annotation type with a

00:37:29.079 --> 00:37:33.790
cursor and then have multiple
cursors, so if you're hovering

00:37:33.790 --> 00:37:38.135
over the spell check, can you
have a cursor for the spell

00:37:38.135 --> 00:37:42.365
check that's associated with
that, maybe to the right, that

00:37:42.365 --> 00:37:44.000
you've got to insert the
cursor or whatever.

00:37:44.000 --> 00:37:47.056
And then you just pass the
cursor state with [INAUDIBLE].

00:37:50.150 --> 00:37:51.370
CHRISTIAN OHLER: Yeah, that's
something to think about.

00:37:51.370 --> 00:37:55.031
I can't answer whether that's a
good idea or not off the top

00:37:55.031 --> 00:37:56.850
of my head.

00:37:56.850 --> 00:37:58.748
AUDIENCE: Forgive me if you've
covered this already.

00:37:58.748 --> 00:38:02.304
But if you get rid of
composability and send them

00:38:02.304 --> 00:38:06.140
lists of operations--

00:38:06.140 --> 00:38:09.960
because the client, while you're
offering up operations

00:38:09.960 --> 00:38:12.496
[INAUDIBLE], and they're not
being composed together but

00:38:12.496 --> 00:38:15.020
they're being concatenated
and compacted--

00:38:15.020 --> 00:38:17.825
is the service side OT
complexity center the same for

00:38:17.825 --> 00:38:20.626
it to apply that list of
operations as it would be for

00:38:20.626 --> 00:38:21.876
[INAUDIBLE]?

00:38:27.870 --> 00:38:29.600
CHRISTIAN OHLER: The service
side OT complexity is not the

00:38:29.600 --> 00:38:31.360
same if you use an [? NAU ?]

00:38:31.360 --> 00:38:32.610
transform implementation.

00:38:35.210 --> 00:38:40.250
But you can implement an
efficient transform that

00:38:40.250 --> 00:38:44.540
builds an internal
representation that splits the

00:38:44.540 --> 00:38:48.050
document into different stripes
that are affected by

00:38:48.050 --> 00:38:49.010
the different operations.

00:38:49.010 --> 00:38:53.870
And you can implement transform
efficiently still.

00:38:53.870 --> 00:38:59.080
But that is code that we don't
currently have for our current

00:38:59.080 --> 00:38:59.150
operations.

00:38:59.150 --> 00:39:02.830
So our current operations also
suffer from a similar problem.

00:39:02.830 --> 00:39:09.080
There is still the potential of
service side explosion of

00:39:09.080 --> 00:39:12.810
complexity with the OT that
we have right now.

00:39:12.810 --> 00:39:15.430
And the composability
alleviates

00:39:15.430 --> 00:39:17.300
that to some degree.

00:39:17.300 --> 00:39:20.460
And if you don't have the
composability anymore, then

00:39:20.460 --> 00:39:22.614
you need to worry
about it again.

00:39:22.614 --> 00:39:23.458
AUDIENCE: Right.

00:39:23.458 --> 00:39:27.320
Well I was actually
going to ask now--

00:39:27.320 --> 00:39:32.570
the idea of focality of a
[? Nexus ?] or token document

00:39:32.570 --> 00:39:37.892
chunks chunks occurring
on those operations.

00:39:37.892 --> 00:39:39.280
I'll just talk to
you later on.

00:39:39.280 --> 00:39:41.806
CHRISTIAN OHLER: That's
a good idea, I think.

00:39:41.806 --> 00:39:42.970
A question on this side?

00:39:42.970 --> 00:39:46.650
I wasn't really--

00:39:46.650 --> 00:39:49.060
any more questions?

00:39:49.060 --> 00:39:49.910
Any questions for--

00:39:49.910 --> 00:39:51.970
yeah, sorry.

00:39:51.970 --> 00:39:57.020
AUDIENCE: If you have this more
[INAUDIBLE] of operations

00:39:57.020 --> 00:40:01.405
in place of these big chunk
operations we have at the

00:40:01.405 --> 00:40:09.085
moment, do you think that we
should strive for some

00:40:09.085 --> 00:40:10.335
[INAUDIBLE]

00:40:12.375 --> 00:40:16.830
maintain so much variance so
that there's [INAUDIBLE]?

00:40:16.830 --> 00:40:17.470
CHRISTIAN OHLER: Yeah.

00:40:17.470 --> 00:40:24.220
I think that the output of
compaction will probably

00:40:24.220 --> 00:40:29.900
naturally have some good
properties like that, that the

00:40:29.900 --> 00:40:32.240
list of operations essentially
operates on the document from

00:40:32.240 --> 00:40:38.600
left to right, or with some
additional constraints like

00:40:38.600 --> 00:40:42.520
first, do all insertions and
subtle annotations then do all

00:40:42.520 --> 00:40:45.500
divisions or something
like that?

00:40:45.500 --> 00:40:48.780
And maybe it's worthwhile to
have a special type for

00:40:48.780 --> 00:40:51.910
compacted lists of operations
so that your code can

00:40:51.910 --> 00:40:56.475
recognize these and work with
them more efficiently.

00:40:56.475 --> 00:40:56.940
AUDIENCE: Right.

00:40:56.940 --> 00:40:58.510
Because you [INAUDIBLE]

00:41:01.880 --> 00:41:06.060
if you know that they
are smaller.

00:41:06.060 --> 00:41:06.560
CHRISTIAN OHLER: Yeah.

00:41:06.560 --> 00:41:13.100
But that would basically also
alleviate the complexity

00:41:13.100 --> 00:41:17.290
explosion that the previous
question was about.

00:41:17.290 --> 00:41:20.592
You would get the same
behavior that

00:41:20.592 --> 00:41:23.576
you currently have.

00:41:23.576 --> 00:41:25.480
Oh, another question.

00:41:25.480 --> 00:41:27.000
Oh, another question.

00:41:27.000 --> 00:41:31.340
AUDIENCE: With the simpler OT
that you're talking about, the

00:41:31.340 --> 00:41:32.590
data [INAUDIBLE]

00:41:35.752 --> 00:41:38.162
rather than sort
of [INAUDIBLE]?

00:41:38.162 --> 00:41:41.070
Would that be a different
scope of Wave protocol?

00:41:41.070 --> 00:41:42.906
Or would this have to be
extended protocol?

00:41:49.040 --> 00:41:51.870
CHRISTIAN OHLER: Given that
this is what Wave actually

00:41:51.870 --> 00:41:54.170
needs, I think it should
be within the

00:41:54.170 --> 00:41:56.610
scope of Wave protocol.

00:42:01.150 --> 00:42:02.400
Any more questions?

00:42:04.545 --> 00:42:06.020
All right.

00:42:06.020 --> 00:42:07.530
Thanks very much.

00:42:07.530 --> 00:42:08.100
Who's next?

00:42:08.100 --> 00:42:21.315
[APPLAUSE]

