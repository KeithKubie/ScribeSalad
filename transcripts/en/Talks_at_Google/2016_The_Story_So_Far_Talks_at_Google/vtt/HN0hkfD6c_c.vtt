WEBVTT
Kind: captions
Language: en

00:00:01.034 --> 00:00:03.200
JIM LECINSKI: Well, good
Friday afternoon, everyone,

00:00:03.200 --> 00:00:08.610
and welcome to another exciting
edition of Authors at Google.

00:00:08.610 --> 00:00:11.570
We're originating today from
our wonderful Google Chicago

00:00:11.570 --> 00:00:12.270
office.

00:00:12.270 --> 00:00:15.640
[APPLAUSE]

00:00:15.640 --> 00:00:17.720
Round of applause.

00:00:17.720 --> 00:00:21.650
I will be your presumptive
moderator for the day using

00:00:21.650 --> 00:00:23.620
the zeitgeist word of the day.

00:00:23.620 --> 00:00:26.790
I'm Jim Lecisnki,
and our guest today

00:00:26.790 --> 00:00:28.990
is with us, Chris Anderson.

00:00:28.990 --> 00:00:31.760
Chris is the curator
of the TED conference

00:00:31.760 --> 00:00:34.260
and has been since
2002, following

00:00:34.260 --> 00:00:36.920
a long and successful career
in the publishing industry.

00:00:36.920 --> 00:00:39.840
We'll talk a little
bit about that today.

00:00:39.840 --> 00:00:44.160
Chris has developed TED
into a global platform

00:00:44.160 --> 00:00:46.260
for identifying
and disseminating

00:00:46.260 --> 00:00:48.530
ideas worth spreading.

00:00:48.530 --> 00:00:49.878
Welcome, Chris.

00:00:49.878 --> 00:00:53.154
[APPLAUSE]

00:00:55.970 --> 00:00:57.256
So great to have you with us.

00:00:57.256 --> 00:00:58.880
I wonder if maybe we
could get started,

00:00:58.880 --> 00:01:01.270
if you'd tell us a little
bit about your background.

00:01:01.270 --> 00:01:03.740
I mentioned the publishing.

00:01:03.740 --> 00:01:07.040
How does a philosophy
major and publisher

00:01:07.040 --> 00:01:09.250
come to lead and transform
one of the world's

00:01:09.250 --> 00:01:11.910
great digital brands?

00:01:11.910 --> 00:01:14.364
CHRIS ANDERSON: Definitely
a long, twisting journey.

00:01:14.364 --> 00:01:16.030
I was a journalist
originally, actually,

00:01:16.030 --> 00:01:17.530
when I first came
out of university,

00:01:17.530 --> 00:01:22.200
and I made the mistake of buying
one of the early computers.

00:01:22.200 --> 00:01:24.880
It was like a Tandy TRSAT clone.

00:01:24.880 --> 00:01:26.970
And I was awed by this thing.

00:01:26.970 --> 00:01:28.760
I kind of completely
fell in love with it,

00:01:28.760 --> 00:01:31.757
and to cut a long story
short, a few years later,

00:01:31.757 --> 00:01:34.090
I found myself working at one
of the early home computer

00:01:34.090 --> 00:01:36.050
magazines, and I loved that.

00:01:36.050 --> 00:01:37.690
And then I decided,
this isn't so hard.

00:01:37.690 --> 00:01:38.540
Let's publish one.

00:01:38.540 --> 00:01:41.320
So I started a company,
published a magazine.

00:01:41.320 --> 00:01:44.370
Bizarrely, it worked, and
then this thing took off.

00:01:44.370 --> 00:01:46.300
And so the publishing
part was just

00:01:46.300 --> 00:01:49.910
building lots and lots of these
nichey hobbyist magazines that

00:01:49.910 --> 00:01:53.620
were deeply boring to everyone,
except the people they

00:01:53.620 --> 00:01:55.640
were targeted at, who
kind of loved them.

00:01:55.640 --> 00:01:57.530
And so we had this philosophy.

00:01:57.530 --> 00:02:00.320
Our complete logo was
actually, "Media with passion."

00:02:00.320 --> 00:02:04.420
And that's always been my
mantra as an entrepreneur

00:02:04.420 --> 00:02:06.060
is look for the passion.

00:02:06.060 --> 00:02:08.120
If you can find something
that people are really

00:02:08.120 --> 00:02:10.030
passionate about,
that's your clue

00:02:10.030 --> 00:02:11.990
that there's something
there, that this is kind

00:02:11.990 --> 00:02:14.170
of the proxy for potential.

00:02:14.170 --> 00:02:20.230
And so when I first came to
TED in 1998, TED was back then,

00:02:20.230 --> 00:02:22.602
it was actually started in '84.

00:02:22.602 --> 00:02:24.060
Nothing on the
internet, of course.

00:02:24.060 --> 00:02:25.230
It was an annual conference.

00:02:25.230 --> 00:02:26.010
That was it.

00:02:26.010 --> 00:02:28.835
And I went there in '98.

00:02:28.835 --> 00:02:30.960
It was bringing together
Technology, Entertainment,

00:02:30.960 --> 00:02:35.380
Design, TED, and I
fell in love with it.

00:02:35.380 --> 00:02:36.580
I thought, I've come home.

00:02:36.580 --> 00:02:38.760
And what I saw was this passion.

00:02:38.760 --> 00:02:40.740
People were so
passionate about it.

00:02:40.740 --> 00:02:42.750
It was like, this is my
best week of the year.

00:02:42.750 --> 00:02:45.240
And I thought, why is this
your best week of the year?

00:02:45.240 --> 00:02:47.050
But that was the clue.

00:02:47.050 --> 00:02:50.300
And so when there was a chance
to buy TED from its founder--

00:02:50.300 --> 00:02:53.540
he was 65-- and I leapt at it.

00:02:53.540 --> 00:02:56.570
And so that happened in 2001,
and the journey since then

00:02:56.570 --> 00:02:58.280
has been a wild
journey of its own.

00:02:58.280 --> 00:02:59.090
But that's how I got there.

00:02:59.090 --> 00:02:59.923
JIM LECINSKI: Great.

00:02:59.923 --> 00:03:02.070
And we'll talk about
that journey since then.

00:03:02.070 --> 00:03:04.300
In some sense, it's
been said that it

00:03:04.300 --> 00:03:08.780
was the power of what was
then new media back in 2006,

00:03:08.780 --> 00:03:11.671
online video in particular,
that really gave TED its boost.

00:03:11.671 --> 00:03:12.920
Would you say that's the case?

00:03:12.920 --> 00:03:15.230
CHRIS ANDERSON: That's
absolutely the case.

00:03:15.230 --> 00:03:18.140
When I bought it, I bought
it with a nonprofit,

00:03:18.140 --> 00:03:20.230
a foundation I had.

00:03:20.230 --> 00:03:22.830
And so the intention
was always, it

00:03:22.830 --> 00:03:25.047
felt like there was
all this inspiration.

00:03:25.047 --> 00:03:27.130
It was supposed to be for
the public good somehow,

00:03:27.130 --> 00:03:29.140
but how could you
let out the knowledge

00:03:29.140 --> 00:03:31.460
that was at this private
conference to the world?

00:03:31.460 --> 00:03:34.380
And our first attempt
to do that was on TV,

00:03:34.380 --> 00:03:36.250
and TV wasn't interested.

00:03:36.250 --> 00:03:37.410
These are lectures.

00:03:37.410 --> 00:03:38.292
They're lectures.

00:03:38.292 --> 00:03:39.250
They're kind of boring.

00:03:39.250 --> 00:03:40.460
Lectures are boring.

00:03:40.460 --> 00:03:42.001
Now I didn't actually
listen to them,

00:03:42.001 --> 00:03:43.264
because they weren't boring.

00:03:43.264 --> 00:03:44.430
But they weren't interested.

00:03:44.430 --> 00:03:45.560
And so yeah.

00:03:45.560 --> 00:03:48.970
So when this weird technology
called online video

00:03:48.970 --> 00:03:51.850
with its shaky little kittens
and all these other things

00:03:51.850 --> 00:03:54.286
happening came along,
we thought, wait a sec.

00:03:54.286 --> 00:03:55.660
Maybe we could,
as an experiment,

00:03:55.660 --> 00:03:57.090
put some TED Talks up.

00:03:57.090 --> 00:03:58.340
Probably won't work.

00:03:58.340 --> 00:04:00.430
They're too long
for the internet,

00:04:00.430 --> 00:04:02.480
and you're not going
to be there live.

00:04:02.480 --> 00:04:03.670
It's on video.

00:04:03.670 --> 00:04:06.230
To our amazement, these
things went viral,

00:04:06.230 --> 00:04:07.690
and so that was
the moment, 2006,

00:04:07.690 --> 00:04:09.930
when we decided we had
to flip TED on its head.

00:04:09.930 --> 00:04:12.260
We're no longer
just a conference.

00:04:12.260 --> 00:04:16.779
We're a media organization
devoted to sharing ideas.

00:04:16.779 --> 00:04:19.029
JIM LECINSKI: And so let's
build on that a little bit.

00:04:19.029 --> 00:04:22.640
You described what TED stands
for, T-E-D, but how would you

00:04:22.640 --> 00:04:26.050
talk about its
meaning, its purpose?

00:04:26.050 --> 00:04:28.480
What does the brand stand for?

00:04:28.480 --> 00:04:30.740
CHRIS ANDERSON: It stands
for the bringing together

00:04:30.740 --> 00:04:33.470
of knowledge in ways that
people can understand.

00:04:33.470 --> 00:04:37.410
The world's really complicated,
and most of the time,

00:04:37.410 --> 00:04:38.206
we go deep.

00:04:38.206 --> 00:04:40.830
You have to know something well
to have a chance of succeeding.

00:04:40.830 --> 00:04:41.600
You dig deep.

00:04:41.600 --> 00:04:43.162
You learn your speciality well.

00:04:43.162 --> 00:04:44.620
And that's how most
things operate.

00:04:44.620 --> 00:04:46.340
That's how most
conferences operate,

00:04:46.340 --> 00:04:48.390
most university
courses, whatever.

00:04:48.390 --> 00:04:50.860
That's what you have to do.

00:04:50.860 --> 00:04:54.970
But there's a place for
context to actually understand

00:04:54.970 --> 00:04:55.780
the world we're in.

00:04:55.780 --> 00:04:57.290
You need to go
broader than that.

00:04:57.290 --> 00:04:59.140
And actually, lots
of other things

00:04:59.140 --> 00:05:02.980
happen when you bring together
knowledge from different areas.

00:05:02.980 --> 00:05:05.950
You get the catalyzing
of new ideas.

00:05:05.950 --> 00:05:08.870
You get the possibility
of collaboration,

00:05:08.870 --> 00:05:11.640
and so I think that's
what hit me suddenly

00:05:11.640 --> 00:05:14.410
was why Ted had a role to play.

00:05:14.410 --> 00:05:16.257
There's just not
much of that happens.

00:05:16.257 --> 00:05:18.340
And so if you can persuade
people to come together

00:05:18.340 --> 00:05:20.387
from these different fields
and explain something

00:05:20.387 --> 00:05:22.470
they're passionate about
in ways that other people

00:05:22.470 --> 00:05:26.200
can actually understand,
that, I think, that definitely

00:05:26.200 --> 00:05:29.020
over a few days, for example,
that had the effect of selling

00:05:29.020 --> 00:05:30.190
these spots in your brain.

00:05:30.190 --> 00:05:31.773
And you just thought
of stuff that you

00:05:31.773 --> 00:05:33.350
hadn't thought of before.

00:05:33.350 --> 00:05:35.080
And so that's what
it stands for.

00:05:35.080 --> 00:05:36.663
JIM LECINSKI: We'll
come back and chat

00:05:36.663 --> 00:05:39.570
a little bit in a
second about the power

00:05:39.570 --> 00:05:42.166
of how those talks are built
on understandable ideas.

00:05:42.166 --> 00:05:44.040
But I want to pursue--
you mentioned the word

00:05:44.040 --> 00:05:46.220
collaboration.

00:05:46.220 --> 00:05:48.475
Most of our audiences
has not had the pleasure

00:05:48.475 --> 00:05:50.600
of actually attending the
conference when they were

00:05:50.600 --> 00:05:52.510
in Long Beach or now
back in Vancouver,

00:05:52.510 --> 00:05:55.500
so could you maybe paint a
little picture about not just

00:05:55.500 --> 00:05:56.910
the speakers on
the stage that we

00:05:56.910 --> 00:05:58.970
can see by watching
the video, but it's

00:05:58.970 --> 00:06:02.800
a full four-day collaboration
event with the dinners.

00:06:02.800 --> 00:06:04.470
And can you maybe
paint picture of what

00:06:04.470 --> 00:06:05.726
happens during that week?

00:06:05.726 --> 00:06:06.600
CHRIS ANDERSON: Sure.

00:06:06.600 --> 00:06:11.020
So yeah, it's four
and 1/2-ish days.

00:06:11.020 --> 00:06:13.780
There are basically 12
main sessions of TED.

00:06:13.780 --> 00:06:16.750
Each session is an
hour and 45 minutes,

00:06:16.750 --> 00:06:20.730
and it's five to six speakers,
plus other little performances

00:06:20.730 --> 00:06:22.090
and things thrown in there.

00:06:22.090 --> 00:06:23.710
So it's quite fast-moving.

00:06:23.710 --> 00:06:27.950
What's unusual about TED is that
everyone sees every speaker.

00:06:27.950 --> 00:06:29.360
It's one track.

00:06:29.360 --> 00:06:32.330
And that doesn't usually happen,
but it is the whole point of it

00:06:32.330 --> 00:06:35.150
is you are supposed to be
exposed to stuff you had

00:06:35.150 --> 00:06:37.500
no idea you were interested in.

00:06:37.500 --> 00:06:40.480
And it's become a truism at
TED that the session that you

00:06:40.480 --> 00:06:43.290
think is going to be most boring
is the one that blows you away.

00:06:43.290 --> 00:06:45.930
And so amazingly,
people do commit

00:06:45.930 --> 00:06:47.990
to coming to each
session, and that

00:06:47.990 --> 00:06:51.440
means that you can have a shared
conversation in the corridors

00:06:51.440 --> 00:06:52.500
after.

00:06:52.500 --> 00:06:56.320
And the collaboration is not
really something we stage.

00:06:56.320 --> 00:07:00.580
It just happens that the
combination of that exposure

00:07:00.580 --> 00:07:02.740
to these different
speakers and ideas,

00:07:02.740 --> 00:07:04.420
it sort of sparks
things in people,

00:07:04.420 --> 00:07:07.639
and weird projects
emerge out of it.

00:07:07.639 --> 00:07:08.430
JIM LECINSKI: Yeah.

00:07:08.430 --> 00:07:12.790
Now is it the case-- I had heard
that you discourage or don't

00:07:12.790 --> 00:07:16.830
allow digital devices or
live tweeting or cameras

00:07:16.830 --> 00:07:18.330
or these kind of
things in the room?

00:07:18.330 --> 00:07:19.070
Is that the case?

00:07:19.070 --> 00:07:20.445
CHRIS ANDERSON:
That is the case.

00:07:20.445 --> 00:07:22.010
Apart from the back
two rows, where

00:07:22.010 --> 00:07:26.810
people can tweet if they want
to, or in the simulcast spaces.

00:07:26.810 --> 00:07:32.680
But in the main theater, we say
no, because all of life right

00:07:32.680 --> 00:07:38.080
now is this attention war,
and talks are weird things.

00:07:38.080 --> 00:07:40.900
They often take
a while to build.

00:07:40.900 --> 00:07:44.100
To share a really big idea or
something that really matters,

00:07:44.100 --> 00:07:45.610
you sometimes have
to build context.

00:07:45.610 --> 00:07:48.240
You have to go through,
gosh, 90 seconds, where

00:07:48.240 --> 00:07:50.880
it's a little bit challenging
or boring for a minute.

00:07:50.880 --> 00:07:53.360
If people-- because I've
just got to check my email,

00:07:53.360 --> 00:07:55.119
just for this moment.

00:07:55.119 --> 00:07:57.410
They miss a couple of key
context things, they're gone.

00:07:57.410 --> 00:07:59.200
And then the talk never lands.

00:07:59.200 --> 00:08:01.080
And once more, the
five people behind them

00:08:01.080 --> 00:08:04.172
are sort of annoyed, and it's
sending a signal that this

00:08:04.172 --> 00:08:05.130
isn't that interesting.

00:08:05.130 --> 00:08:08.110
So everyone else decides
it's not that interesting.

00:08:08.110 --> 00:08:10.184
You are, right now, you
are a super organism.

00:08:10.184 --> 00:08:11.850
You're all actually,
although you're not

00:08:11.850 --> 00:08:14.550
fully conscious of it, you're
feeding off each other.

00:08:14.550 --> 00:08:16.419
You take cues from each other.

00:08:16.419 --> 00:08:18.210
And that's what happens
in a lot of things.

00:08:18.210 --> 00:08:21.330
So we try to have a
different contract

00:08:21.330 --> 00:08:22.420
from the normal contract.

00:08:22.420 --> 00:08:26.040
Audience, you're actually going
to give your full attention

00:08:26.040 --> 00:08:27.580
to this speaker for 18 minutes.

00:08:27.580 --> 00:08:30.530
Speaker, you're going to work
bloody hard for several months

00:08:30.530 --> 00:08:33.730
to produce the talk of your life
and make it worth their while.

00:08:33.730 --> 00:08:35.000
And that's the deal.

00:08:35.000 --> 00:08:35.659
JIM LECINSKI: You
know I actually

00:08:35.659 --> 00:08:37.658
asked that question as
just a not-so-subtle hint

00:08:37.658 --> 00:08:39.709
to our audience today.

00:08:39.709 --> 00:08:41.250
CHRIS ANDERSON: I'm
actually stunned,

00:08:41.250 --> 00:08:43.333
because I thought coming
to Google, of all places,

00:08:43.333 --> 00:08:45.905
you guys would all be
coding and whatever.

00:08:45.905 --> 00:08:48.030
You're all so brilliant,
you can multitask your way

00:08:48.030 --> 00:08:48.571
through this.

00:08:48.571 --> 00:08:49.080
No problem.

00:08:49.080 --> 00:08:50.204
JIM LECINSKI: There you go.

00:08:50.204 --> 00:08:53.470
So maybe tell us a little
bit about the simple question

00:08:53.470 --> 00:08:55.600
of who gets to do a TED talk.

00:08:55.600 --> 00:08:56.651
How do you decide?

00:08:56.651 --> 00:08:58.400
CHRIS ANDERSON: In
principle, it's simple.

00:08:58.400 --> 00:09:01.240
It's someone who's doing amazing
work that other people need

00:09:01.240 --> 00:09:03.500
to know about, and
the rest is detail.

00:09:03.500 --> 00:09:05.980
And so it's hard to decide
who those people are.

00:09:05.980 --> 00:09:10.160
We get 10,000 suggestions a year
from people around the world.

00:09:10.160 --> 00:09:13.060
We have a curation team.

00:09:13.060 --> 00:09:14.920
For a conference,
we're trying to weave

00:09:14.920 --> 00:09:17.370
a sort of mix of people
together around a theme.

00:09:17.370 --> 00:09:20.830
This year's theme was dream
as in big, bold dreams.

00:09:20.830 --> 00:09:24.255
But there's no
algorithm to it yet.

00:09:24.255 --> 00:09:25.630
Please don't invent
one just yet,

00:09:25.630 --> 00:09:27.450
or we'll be out of business.

00:09:27.450 --> 00:09:30.990
It's a sort of-- because
we want, with the program,

00:09:30.990 --> 00:09:34.180
to-- and I think a lot of
events fail to do this.

00:09:34.180 --> 00:09:37.420
We want to poke at
every different part

00:09:37.420 --> 00:09:38.620
of people's minds.

00:09:38.620 --> 00:09:43.180
It can't just be about something
analytical or storytelling,

00:09:43.180 --> 00:09:43.780
what have you.

00:09:43.780 --> 00:09:46.920
There are different
parts of minds

00:09:46.920 --> 00:09:48.980
engaged when you start
to go to the aesthetic

00:09:48.980 --> 00:09:51.760
or to someone's inspiring
story, or to here's

00:09:51.760 --> 00:09:55.360
a really complex scientific
issue that we're tackling in.

00:09:55.360 --> 00:09:58.820
There's energy that
comes from that,

00:09:58.820 --> 00:10:01.270
and so it's not
just who you bring.

00:10:01.270 --> 00:10:04.334
It's then trying to sequence
them in a way that will work.

00:10:04.334 --> 00:10:05.750
JIM LECINSKI: I
heard you once say

00:10:05.750 --> 00:10:08.680
that-- I don't know if it's a
filter or a screen how you put

00:10:08.680 --> 00:10:10.620
it-- but one
consideration that you

00:10:10.620 --> 00:10:14.400
look at in deciding on
a speaker is who would

00:10:14.400 --> 00:10:17.090
benefit from hearing this idea.

00:10:17.090 --> 00:10:17.970
Is it just you?

00:10:17.970 --> 00:10:19.050
Is it just your team?

00:10:19.050 --> 00:10:20.880
Is it just your organization?

00:10:20.880 --> 00:10:21.380
Or--

00:10:21.380 --> 00:10:21.640
CHRIS ANDERSON: Right.

00:10:21.640 --> 00:10:23.140
So that is actually--
I would say

00:10:23.140 --> 00:10:26.862
that is the number one
advice to a speaker,

00:10:26.862 --> 00:10:29.510
and it's the core thing
that's in the book.

00:10:29.510 --> 00:10:32.790
It's so tempting as a
speaker, you think, hey,

00:10:32.790 --> 00:10:34.250
I've got an opportunity.

00:10:34.250 --> 00:10:35.310
So I'm going to use it.

00:10:35.310 --> 00:10:39.530
I'm going to promote my
organization, my cause,

00:10:39.530 --> 00:10:41.740
and in the process, I'm
going to take the chance

00:10:41.740 --> 00:10:44.630
to be a little bit of a
rock star, because I can.

00:10:44.630 --> 00:10:48.240
And that's the trap that
so many people fall into,

00:10:48.240 --> 00:10:51.950
and it's very counterproductive,
because it actually shuts down

00:10:51.950 --> 00:10:52.580
the audience.

00:10:55.127 --> 00:10:56.710
If you can do it the
other way around,

00:10:56.710 --> 00:10:58.450
if you can make
clear from the start

00:10:58.450 --> 00:11:01.860
that your purpose in being on
stage is to give something,

00:11:01.860 --> 00:11:05.200
is to give people a gift, a
gift of something that you know,

00:11:05.200 --> 00:11:09.326
and that if they knew, it would
make a difference to them.

00:11:09.326 --> 00:11:12.700
I mean our lives are built
around our worldviews.

00:11:12.700 --> 00:11:14.850
Different knowledge
means a different life.

00:11:14.850 --> 00:11:17.000
It means doing things
differently maybe years

00:11:17.000 --> 00:11:18.440
into the future.

00:11:18.440 --> 00:11:21.880
So come with a gift,
and I think if we

00:11:21.880 --> 00:11:24.830
don't see that in a speaker,
if we smell for a minute

00:11:24.830 --> 00:11:27.190
that they're in it for
self-promotional purposes

00:11:27.190 --> 00:11:28.687
primarily, not interested.

00:11:28.687 --> 00:11:29.520
JIM LECINSKI: Right.

00:11:29.520 --> 00:11:32.080
And that's good advice not just
on stage at your conference,

00:11:32.080 --> 00:11:33.360
in general, I suppose.

00:11:33.360 --> 00:11:34.060
CHRIS ANDERSON: I
think in general.

00:11:34.060 --> 00:11:35.690
I think absolutely in general.

00:11:35.690 --> 00:11:38.520
Even frankly, even if you
are trying to sell something,

00:11:38.520 --> 00:11:42.070
the best salespeople don't
come on and say, hey,

00:11:42.070 --> 00:11:43.360
here's what I got.

00:11:43.360 --> 00:11:45.890
They say, what are
you passionate about?

00:11:45.890 --> 00:11:48.012
What are you thinking about?

00:11:48.012 --> 00:11:48.720
What do you need?

00:11:48.720 --> 00:11:49.845
What are you curious about?

00:11:49.845 --> 00:11:52.540
How can I help?

00:11:52.540 --> 00:11:53.410
So absolutely.

00:11:53.410 --> 00:11:57.170
Every speaker should be
thinking about the audience

00:11:57.170 --> 00:12:00.590
and what they can offer that
could be of interest and use.

00:12:00.590 --> 00:12:03.930
JIM LECINSKI: Now in terms of
speaking delivery and speaking

00:12:03.930 --> 00:12:05.560
ability, you've
described yourself,

00:12:05.560 --> 00:12:08.440
and I think greatly
underselling your powers,

00:12:08.440 --> 00:12:11.320
as not a natural
charismatic speaker.

00:12:11.320 --> 00:12:13.940
In some senses,
your predecessor was

00:12:13.940 --> 00:12:17.290
a charismatic, outgoing person.

00:12:17.290 --> 00:12:19.060
But you've had this
awesome ringside seat

00:12:19.060 --> 00:12:24.480
for the past dozen or so or more
years watching great speakers.

00:12:24.480 --> 00:12:29.210
So what have you observed about
the perennial debate of you're

00:12:29.210 --> 00:12:33.400
a natural at it or not, or
you can learn it or not?

00:12:33.400 --> 00:12:36.560
Some people can only get so
far at being a good speaker.

00:12:36.560 --> 00:12:39.399
What's your point on I
guess nature and nurture?

00:12:39.399 --> 00:12:40.940
CHRIS ANDERSON: I
mean, I'm convinced

00:12:40.940 --> 00:12:45.390
that the only thing that you
need to give a great talk

00:12:45.390 --> 00:12:47.320
is something worth saying.

00:12:47.320 --> 00:12:49.160
You need knowledge.

00:12:49.160 --> 00:12:54.630
You need to have done some work
that deserves a wider airing.

00:12:57.230 --> 00:12:58.300
The rest can be taught.

00:12:58.300 --> 00:13:01.510
Honestly, it can be taught,
because the last thing you want

00:13:01.510 --> 00:13:05.170
is for everyone to learn some
sort of style of speaking.

00:13:05.170 --> 00:13:07.990
We don't want to think of
speaking as a performance.

00:13:07.990 --> 00:13:09.490
There definitely
are some people who

00:13:09.490 --> 00:13:13.200
are natural performers
and who can in the moment

00:13:13.200 --> 00:13:18.060
sort of smoothly pluck
beautiful, elegant phrases out

00:13:18.060 --> 00:13:19.930
of nowhere and pass them on.

00:13:19.930 --> 00:13:23.840
So not everyone
probably can do that.

00:13:23.840 --> 00:13:24.840
But that's a good thing.

00:13:24.840 --> 00:13:26.730
We don't want
everyone to do that.

00:13:26.730 --> 00:13:29.230
It would get
exhausting, honestly.

00:13:29.230 --> 00:13:31.670
What you want is a variety
of different people,

00:13:31.670 --> 00:13:34.730
different skills, different
standpoints, different speaking

00:13:34.730 --> 00:13:36.310
styles.

00:13:36.310 --> 00:13:38.000
What you want is authenticity.

00:13:38.000 --> 00:13:39.890
You want people who
care about something.

00:13:39.890 --> 00:13:42.840
And even if they half stammer
their way through a talk,

00:13:42.840 --> 00:13:45.700
if you're learning
something, that is fantastic.

00:13:45.700 --> 00:13:48.500
So I just feel
passionately about this

00:13:48.500 --> 00:13:51.447
that it's a tragedy that there
are so many people out there

00:13:51.447 --> 00:13:53.030
in the world, and I
bet there are even

00:13:53.030 --> 00:13:56.920
people here in this
world-leading company, who

00:13:56.920 --> 00:14:00.380
feel under-confident when
it comes to public speaking,

00:14:00.380 --> 00:14:04.230
despite having something really
valuable to share, something

00:14:04.230 --> 00:14:07.270
that if the rest of the
world knew, rest of the world

00:14:07.270 --> 00:14:08.300
would like it.

00:14:08.300 --> 00:14:09.739
And so we've got
to get over that.

00:14:09.739 --> 00:14:10.530
JIM LECINSKI: Yeah.

00:14:10.530 --> 00:14:16.100
So maybe if you tell us a little
bit about two people who've, I

00:14:16.100 --> 00:14:18.280
guess, fit both of those
profiles or archetypes

00:14:18.280 --> 00:14:19.990
that you just outlined.

00:14:19.990 --> 00:14:22.440
Maybe Sir Ken Robinson
as a natural, a gifted,

00:14:22.440 --> 00:14:24.340
one of those who can
pluck things out,

00:14:24.340 --> 00:14:26.520
and maybe someone who's a little
more hesitant like a Monica

00:14:26.520 --> 00:14:26.950
Lewinsky.

00:14:26.950 --> 00:14:28.783
Maybe if you could just
tell us a little bit

00:14:28.783 --> 00:14:30.890
about those two examples
to illustrate your point.

00:14:30.890 --> 00:14:32.300
CHRIS ANDERSON: Sure.

00:14:32.300 --> 00:14:36.540
I mean Sir Ken Robinson
came to TED in 2006.

00:14:36.540 --> 00:14:39.060
I think he'd already
been voted Europe's Best

00:14:39.060 --> 00:14:40.510
Speaker or something like that.

00:14:40.510 --> 00:14:41.885
I was a little
suspicious of him,

00:14:41.885 --> 00:14:43.480
because I thought
if he's that good,

00:14:43.480 --> 00:14:46.050
what are we going to get here?

00:14:46.050 --> 00:14:49.970
But he kind of shuffled
onto the stage and said,

00:14:49.970 --> 00:14:52.070
you know, it's been
great, hasn't it?

00:14:52.070 --> 00:14:54.130
I've been blown away.

00:14:54.130 --> 00:14:55.560
In fact, I'm leaving.

00:14:55.560 --> 00:14:58.530
And people sort of tittered
and giggled, and then

00:14:58.530 --> 00:15:00.080
over the next 10
minutes, they just

00:15:00.080 --> 00:15:03.330
didn't stop laughing, because
he just brilliantly told story

00:15:03.330 --> 00:15:04.380
after story about kids.

00:15:04.380 --> 00:15:07.230
And we all wanted
it to go on forever.

00:15:07.230 --> 00:15:09.450
And having won all
that affection,

00:15:09.450 --> 00:15:13.070
he was able to give us this very
inspiring story and argument

00:15:13.070 --> 00:15:17.830
that creativity is completely
under-taught in schools,

00:15:17.830 --> 00:15:18.710
undernourished.

00:15:18.710 --> 00:15:21.490
And that resonated with
so many people so deeply.

00:15:21.490 --> 00:15:26.670
And so that was 2006, and
it was told to 800 people.

00:15:26.670 --> 00:15:29.450
And now 800 people
every hour watch

00:15:29.450 --> 00:15:32.290
that talk online all
these years later,

00:15:32.290 --> 00:15:36.120
and he's up to 38 million
or whatever it is.

00:15:36.120 --> 00:15:39.340
Monica Lewinsky was terrified,
for obvious reasons,

00:15:39.340 --> 00:15:41.010
coming to TED.

00:15:41.010 --> 00:15:46.340
She'd stayed fairly invisible
for the best part of a decade.

00:15:46.340 --> 00:15:48.890
And she felt passionate
about certain things,

00:15:48.890 --> 00:15:50.860
about this issue
of cyberbullying.

00:15:50.860 --> 00:15:53.622
But it took a lot of courage
for her to come and raise

00:15:53.622 --> 00:15:55.830
her voice, and naturally,
coming into the conference,

00:15:55.830 --> 00:15:58.430
she thought, gosh, what if
this is a big public stage?

00:15:58.430 --> 00:15:59.270
I'm on video.

00:15:59.270 --> 00:16:00.536
What if I'm humiliated again?

00:16:00.536 --> 00:16:01.660
It was really hard for her.

00:16:01.660 --> 00:16:04.040
I think she almost pulled
out a couple of times.

00:16:04.040 --> 00:16:09.890
But what held her there was
she wrote on her script,

00:16:09.890 --> 00:16:12.010
this matters.

00:16:12.010 --> 00:16:16.144
And returning to sort of giving
this in the service of an idea

00:16:16.144 --> 00:16:17.060
made a big difference.

00:16:17.060 --> 00:16:19.690
She did a few smart
things physically

00:16:19.690 --> 00:16:21.910
in terms of exercises,
breathing, whatever

00:16:21.910 --> 00:16:23.430
before coming on stage.

00:16:23.430 --> 00:16:26.444
And in her talk,
she structured it

00:16:26.444 --> 00:16:27.860
cleverly so that
up front, she had

00:16:27.860 --> 00:16:31.270
a very disarming personal
story right in the first minute

00:16:31.270 --> 00:16:33.170
or two that had
everyone laughing.

00:16:33.170 --> 00:16:37.030
And at that moment, she
told me she just relaxed

00:16:37.030 --> 00:16:38.850
and knew that she had it.

00:16:38.850 --> 00:16:40.860
So that talk was extraordinary.

00:16:40.860 --> 00:16:43.010
That's been seen by
eight million people now,

00:16:43.010 --> 00:16:46.150
and it really changed how a
lot of people thought of her

00:16:46.150 --> 00:16:48.380
and how a lot of people
thought about this issue.

00:16:48.380 --> 00:16:51.560
So I'd definitely say that
if she can overcome her fear,

00:16:51.560 --> 00:16:53.905
anyone here who is
fearful of speaking could.

00:16:53.905 --> 00:16:56.280
JIM LECINSKI: So you talk
about some of those conventions

00:16:56.280 --> 00:16:57.470
that she used.

00:16:57.470 --> 00:16:59.150
She also had some
great sticky phrases.

00:16:59.150 --> 00:17:02.280
I remember one that hangs
with me is she called herself,

00:17:02.280 --> 00:17:06.490
I think, patient zero
of cyberbullying.

00:17:06.490 --> 00:17:09.130
So that brings up the
natural question of,

00:17:09.130 --> 00:17:10.730
do you coach these speakers?

00:17:10.730 --> 00:17:12.130
Do you write the scripts?

00:17:12.130 --> 00:17:13.950
Do you edit the scripts?

00:17:13.950 --> 00:17:15.150
Do you review them?

00:17:15.150 --> 00:17:16.660
Or even are there scripts?

00:17:16.660 --> 00:17:18.420
Or is it all improvised?

00:17:18.420 --> 00:17:20.500
CHRIS ANDERSON: So it's
different in every case.

00:17:20.500 --> 00:17:23.310
In the majority of
cases, there are scripts.

00:17:23.310 --> 00:17:25.990
And we certainly don't write
them in the first place.

00:17:25.990 --> 00:17:27.180
We invite a draft.

00:17:27.180 --> 00:17:29.780
If we don't think
that it's quite there,

00:17:29.780 --> 00:17:34.020
we may suggest some changes,
usually broadly, occasionally

00:17:34.020 --> 00:17:34.910
line by line.

00:17:38.287 --> 00:17:39.870
I mean, the hardest
thing for speakers

00:17:39.870 --> 00:17:43.340
is actually to adjust
the scope of the talk

00:17:43.340 --> 00:17:44.900
to fit 18 minutes or so.

00:17:44.900 --> 00:17:47.565
Like people say, I'm
coming to give a big talk.

00:17:47.565 --> 00:17:49.690
There are so many things
in my life I'm so proud of

00:17:49.690 --> 00:17:51.190
and I want to share
with this group.

00:17:51.190 --> 00:17:54.220
You want to jam them
all in somehow or other.

00:17:54.220 --> 00:17:58.456
And that means that everything
gets dealt with surface level.

00:17:58.456 --> 00:18:00.920
Overjammed equals
underexplained.

00:18:00.920 --> 00:18:03.650
So the hardest thing
is the discipline

00:18:03.650 --> 00:18:06.850
of cutting it out, cutting it
out, focusing on the one idea

00:18:06.850 --> 00:18:08.890
that you're most
passionate about

00:18:08.890 --> 00:18:12.490
and, therefore, giving yourself
time to unpack it properly,

00:18:12.490 --> 00:18:14.285
to set up the context.

00:18:14.285 --> 00:18:15.160
Why does this matter?

00:18:15.160 --> 00:18:16.118
Why do I care about it?

00:18:16.118 --> 00:18:17.650
Why should you care about it?

00:18:17.650 --> 00:18:19.710
How has this been
tackled historically?

00:18:19.710 --> 00:18:20.720
Why didn't that work?

00:18:20.720 --> 00:18:21.760
What could work now?

00:18:21.760 --> 00:18:23.330
Here's an example of
why that could work now.

00:18:23.330 --> 00:18:24.110
Here's why it matters.

00:18:24.110 --> 00:18:25.526
What are we going
to do with this?

00:18:25.526 --> 00:18:30.010
All those things are what make
the idea vivid and actionable,

00:18:30.010 --> 00:18:32.449
and so that's the hardest
piece is people just come

00:18:32.449 --> 00:18:33.490
in with too much usually.

00:18:33.490 --> 00:18:36.810
And we say to them, maybe
focus on this one thing.

00:18:36.810 --> 00:18:39.851
JIM LECINSKI: I mean this is
the famous, if I had had time,

00:18:39.851 --> 00:18:41.600
I would have written
you a shorter letter.

00:18:41.600 --> 00:18:42.600
CHRIS ANDERSON: Exactly.

00:18:42.600 --> 00:18:43.194
Exactly.

00:18:43.194 --> 00:18:44.110
JIM LECINSKI: Exactly.

00:18:44.110 --> 00:18:48.810
So in terms of
presentation styles,

00:18:48.810 --> 00:18:50.540
I'm going to give you
two sort of poles.

00:18:50.540 --> 00:18:52.623
Of course, there's many
shades of gray in between,

00:18:52.623 --> 00:18:54.840
but there are the
speakers, I imagine,

00:18:54.840 --> 00:18:59.460
who come in with a full script,
everything written, practiced

00:18:59.460 --> 00:19:03.940
and timed, fully memorized
to 17 minutes and 59 seconds.

00:19:03.940 --> 00:19:06.290
And it's recall,
push the button,

00:19:06.290 --> 00:19:08.000
and all thousand words come out.

00:19:08.000 --> 00:19:09.375
And there are
probably others who

00:19:09.375 --> 00:19:12.110
come in with a series of
stories or bullet points

00:19:12.110 --> 00:19:13.560
or sketches that
they kind of know

00:19:13.560 --> 00:19:15.520
they want to cover
and want to leave room

00:19:15.520 --> 00:19:17.600
for some spontaneity.

00:19:17.600 --> 00:19:18.314
Do you see both?

00:19:18.314 --> 00:19:19.230
Do you encourage both?

00:19:19.230 --> 00:19:20.314
Can both work?

00:19:20.314 --> 00:19:21.480
CHRIS ANDERSON: We see both.

00:19:21.480 --> 00:19:22.660
We encourage both.

00:19:22.660 --> 00:19:24.844
And both can work.

00:19:24.844 --> 00:19:26.010
JIM LECINSKI: Next question.

00:19:29.140 --> 00:19:31.529
CHRIS ANDERSON: The trap
is going in the middle,

00:19:31.529 --> 00:19:32.320
in between the two.

00:19:32.320 --> 00:19:37.840
So the type of talk that I
think we try and discourage

00:19:37.840 --> 00:19:40.510
is the I'm planning
to memorize this,

00:19:40.510 --> 00:19:42.700
but I'm still a
little bit stressed,

00:19:42.700 --> 00:19:44.240
and I'm not quite there.

00:19:44.240 --> 00:19:46.670
And the audience can hear that.

00:19:46.670 --> 00:19:53.230
If you start giving your talk,
and then your eyes sort of roll

00:19:53.230 --> 00:19:54.900
up a bit, and then,
oh, let me just

00:19:54.900 --> 00:19:56.030
start that paragraph again.

00:19:56.030 --> 00:19:58.310
And suddenly, people have
this sickening feeling-- oh,

00:19:58.310 --> 00:19:59.510
my goodness.

00:19:59.510 --> 00:20:00.740
He's reciting.

00:20:00.740 --> 00:20:05.200
And the life, in a way, goes
out of it, because what you want

00:20:05.200 --> 00:20:06.980
is this live human moment.

00:20:06.980 --> 00:20:09.920
We're here, and you're smiling
at me, and now it's lovely.

00:20:09.920 --> 00:20:14.010
You know, like I feel this
chemistry, this excitement.

00:20:14.010 --> 00:20:15.890
This happens live,
and people want

00:20:15.890 --> 00:20:18.860
to decode the I'm looking
at a live human mind,

00:20:18.860 --> 00:20:20.920
and I'm making a
judgment right now.

00:20:20.920 --> 00:20:22.580
And it's hard for you, because
you're looking at my shoulder

00:20:22.580 --> 00:20:24.630
here, but I'm making a
judgment right now about

00:20:24.630 --> 00:20:27.370
whether you can trust me.

00:20:27.370 --> 00:20:30.450
It's hard to do that if you
think someone's reciting.

00:20:30.450 --> 00:20:31.750
You actually can't.

00:20:31.750 --> 00:20:35.130
So if you're in that mode,
here's what you have to do.

00:20:35.130 --> 00:20:38.080
You don't tear it up
and go back to notes.

00:20:38.080 --> 00:20:39.980
You double down
on your rehearsal,

00:20:39.980 --> 00:20:41.590
and you own the talk.

00:20:41.590 --> 00:20:45.680
You make it part of you so
that when you're in the room,

00:20:45.680 --> 00:20:48.114
it's not at all a problem
to remember what you say.

00:20:48.114 --> 00:20:49.280
You know what's coming next.

00:20:49.280 --> 00:20:50.340
It's right there.

00:20:50.340 --> 00:20:52.440
And you can focus
again on the meaning

00:20:52.440 --> 00:20:55.540
and on wanting to connect with
you, because actually, now

00:20:55.540 --> 00:20:57.650
that I think of it, this
particular idea is right

00:20:57.650 --> 00:21:00.279
for you right now,
and speakers can

00:21:00.279 --> 00:21:01.570
get to the point of doing that.

00:21:01.570 --> 00:21:04.030
And I think probably the
majority of TED talks

00:21:04.030 --> 00:21:05.270
are memorized.

00:21:05.270 --> 00:21:07.780
A small number of them do
sound a little bit robotic,

00:21:07.780 --> 00:21:13.630
and people push
back against that.

00:21:13.630 --> 00:21:16.770
Most of them, you really
feel the person's passion,

00:21:16.770 --> 00:21:18.800
and it's thrilling.

00:21:18.800 --> 00:21:22.434
The danger of going the other
way is that you can ramble.

00:21:22.434 --> 00:21:23.100
You can go over.

00:21:23.100 --> 00:21:25.970
You can miss out some of the key
things that you wanted to say,

00:21:25.970 --> 00:21:28.450
or you can miss the chance
to really use the best

00:21:28.450 --> 00:21:29.770
language to say something.

00:21:29.770 --> 00:21:32.780
You want to really
clearly explain something.

00:21:32.780 --> 00:21:34.616
On the other hand, it
can be live and fresh,

00:21:34.616 --> 00:21:36.490
and some people really
can do that very well.

00:21:36.490 --> 00:21:39.020
What I'd say to someone
who was planning

00:21:39.020 --> 00:21:44.120
to speak from bullet points is
it's still worth rehearsing it.

00:21:44.120 --> 00:21:46.220
Rehearse it three
or four times, even

00:21:46.220 --> 00:21:50.650
if it's just in your bedroom
with a cell phone there

00:21:50.650 --> 00:21:51.620
recording.

00:21:51.620 --> 00:21:54.970
You'll find out the
awkward moments in it,

00:21:54.970 --> 00:21:58.120
and it'll change, and
you'll move from awkwardness

00:21:58.120 --> 00:21:59.860
to owning the talk.

00:21:59.860 --> 00:22:03.830
So either way, rehearse, and
get to the point, where you feel

00:22:03.830 --> 00:22:05.620
like you really know the talk.

00:22:05.620 --> 00:22:08.200
You feel like you just know it.

00:22:08.200 --> 00:22:11.560
And then you can focus on
meaning and connection.

00:22:11.560 --> 00:22:14.490
JIM LECINSKI: So let's get into
the book a little bit more.

00:22:14.490 --> 00:22:17.020
I mean, this is some of the
content in the excellent book

00:22:17.020 --> 00:22:19.490
that you've released.

00:22:19.490 --> 00:22:22.060
You said that the goal
of every TED speaker

00:22:22.060 --> 00:22:24.280
is to plant the seed
of a powerful idea.

00:22:24.280 --> 00:22:25.220
CHRIS ANDERSON: Yes.

00:22:25.220 --> 00:22:26.080
JIM LECINSKI: And
the book starts

00:22:26.080 --> 00:22:27.520
to unpack ways to do that.

00:22:27.520 --> 00:22:30.320
Let's, I guess, tackle the first
elephant or monkey here, which

00:22:30.320 --> 00:22:33.885
is, is there a formula
to plant that seed?

00:22:33.885 --> 00:22:35.510
CHRIS ANDERSON: No,
there's no formula.

00:22:35.510 --> 00:22:37.343
I think the first thing
to note is that it's

00:22:37.343 --> 00:22:38.960
a miracle that you can do it.

00:22:38.960 --> 00:22:40.440
If you think, what is an idea?

00:22:40.440 --> 00:22:43.210
If you could take
the idea, democracy

00:22:43.210 --> 00:22:47.780
is fragile, if you could
color code that in your brain

00:22:47.780 --> 00:22:49.170
and look at what
actually encodes

00:22:49.170 --> 00:22:51.850
that in the human brain,
I would guess it involves

00:22:51.850 --> 00:22:53.370
literally millions of neurons.

00:22:53.370 --> 00:22:55.940
It's a fantastically
complicated pattern.

00:22:55.940 --> 00:23:00.330
Yet somehow in an 18-minute
talk or less, a speaker

00:23:00.330 --> 00:23:03.990
can transfer that entire pattern
into everyone else's minds.

00:23:03.990 --> 00:23:06.070
It seems like an
impossible thing.

00:23:06.070 --> 00:23:07.880
The only way it
happens, it can do it,

00:23:07.880 --> 00:23:10.170
is because we share language.

00:23:10.170 --> 00:23:13.190
So you're building this
pattern out of elements that

00:23:13.190 --> 00:23:15.520
already exist in the minds.

00:23:15.520 --> 00:23:18.160
What you're trying to
is to put them together.

00:23:18.160 --> 00:23:20.170
But to do that, you
have to be incredibly

00:23:20.170 --> 00:23:23.300
disciplined about remembering
that it's their language,

00:23:23.300 --> 00:23:26.660
it's their concepts that you're
building from, not yours.

00:23:26.660 --> 00:23:30.210
So your jargon, your
assumptions, that's what

00:23:30.210 --> 00:23:34.240
can kill an
explanation stone dead.

00:23:34.240 --> 00:23:38.590
And there's this cognitive bug
called the Curse of Knowledge,

00:23:38.590 --> 00:23:40.310
which pretty much
everyone suffers from

00:23:40.310 --> 00:23:43.080
and which is the tendency
to forget what it's like

00:23:43.080 --> 00:23:45.030
not to know something.

00:23:45.030 --> 00:23:46.600
You guys here, you
live in a world

00:23:46.600 --> 00:23:49.800
where it's natural to talk
about algorithms and coding

00:23:49.800 --> 00:23:51.790
and whatever.

00:23:51.790 --> 00:23:54.110
You have a conversation
with people somewhere else,

00:23:54.110 --> 00:23:56.730
and you suddenly wonder why
their eyes are glazing over.

00:23:56.730 --> 00:23:59.919
It's actually not because
you're a boring person.

00:23:59.919 --> 00:24:01.460
It's because you
missed out something

00:24:01.460 --> 00:24:03.340
like they didn't understand
why this mattered

00:24:03.340 --> 00:24:04.624
or what the context was.

00:24:04.624 --> 00:24:05.790
And we do this all the time.

00:24:05.790 --> 00:24:11.060
And so as a speaker, try
your talk out on someone

00:24:11.060 --> 00:24:13.800
who isn't in your
normal circle, but who

00:24:13.800 --> 00:24:15.999
might be like the
people in the audience.

00:24:15.999 --> 00:24:16.790
See if they get it.

00:24:16.790 --> 00:24:17.890
You kind of have to do that.

00:24:17.890 --> 00:24:18.180
JIM LECINSKI: Yeah.

00:24:18.180 --> 00:24:19.554
And so you've
talked a little bit

00:24:19.554 --> 00:24:22.580
about how using
familiar concepts,

00:24:22.580 --> 00:24:27.240
metaphors as a bridge to
get a complex topic across

00:24:27.240 --> 00:24:28.074
can be effective.

00:24:28.074 --> 00:24:28.990
CHRIS ANDERSON: Right.

00:24:28.990 --> 00:24:32.340
So I think of a metaphor
as kind of like a template.

00:24:32.340 --> 00:24:34.380
You've got these different
elements or ideas

00:24:34.380 --> 00:24:36.729
in someone's mind,
and a metaphor

00:24:36.729 --> 00:24:38.770
shows how they connect
together in a shape that's

00:24:38.770 --> 00:24:40.450
familiar so that you get it.

00:24:40.450 --> 00:24:43.480
So Jennifer Khan,
a science writer,

00:24:43.480 --> 00:24:45.954
was trying to explain CRISPR
to us at the last TED.

00:24:45.954 --> 00:24:48.120
And we've had several
scientists try and explain it,

00:24:48.120 --> 00:24:49.661
and they got all
terribly complicated

00:24:49.661 --> 00:24:53.450
and all this sort of complex
science of DNA and so forth.

00:24:53.450 --> 00:24:57.110
She said, no, look, it's like a
word processor for the genome.

00:24:57.110 --> 00:25:00.170
You can use CRISPR
to cut and paste

00:25:00.170 --> 00:25:03.580
any gene to any part that you
want or, indeed, any letter.

00:25:03.580 --> 00:25:06.310
And we go, wow, a word
processor for the genome.

00:25:06.310 --> 00:25:08.035
I get it.

00:25:08.035 --> 00:25:09.410
So metaphors are
really powerful,

00:25:09.410 --> 00:25:10.784
and examples are
powerful as well

00:25:10.784 --> 00:25:14.585
to make sure that you're
cementing in the knowledge.

00:25:14.585 --> 00:25:17.390
Oh, so this is what I mean.

00:25:17.390 --> 00:25:20.510
JIM LECINSKI: One of the
other conventions or devices

00:25:20.510 --> 00:25:22.960
that you talk about in the
book is getting personal.

00:25:22.960 --> 00:25:25.240
You mention Monica
Lewinsky opened her talk

00:25:25.240 --> 00:25:27.380
with a personal story.

00:25:27.380 --> 00:25:29.130
What's been your
experience or your advice

00:25:29.130 --> 00:25:32.169
on using personal anecdotes
or personal experience?

00:25:32.169 --> 00:25:34.210
Because often the advice
is speakers will come up

00:25:34.210 --> 00:25:38.906
and say, I, I, I, me, me,
me turns off the audience.

00:25:38.906 --> 00:25:40.280
CHRIS ANDERSON:
Yes, if you think

00:25:40.280 --> 00:25:42.650
that the speaker is saying
it's all about me, that

00:25:42.650 --> 00:25:44.370
is a turn off.

00:25:44.370 --> 00:25:48.700
But I think there is a case
to try to diffuse skepticism

00:25:48.700 --> 00:25:49.360
and mistrust.

00:25:49.360 --> 00:25:52.890
If you think about it,
if this agenda of trying

00:25:52.890 --> 00:25:55.399
to build an idea
in someone's mind,

00:25:55.399 --> 00:25:57.190
you're doing something
very intimate there.

00:25:57.190 --> 00:25:58.727
People are skeptical
about letting

00:25:58.727 --> 00:26:00.810
a stranger come and poke
around inside their brain

00:26:00.810 --> 00:26:01.930
without permission.

00:26:01.930 --> 00:26:07.830
And so first of all, there's a
process of learning to trust,

00:26:07.830 --> 00:26:09.540
of saying, do I
trust this person?

00:26:09.540 --> 00:26:10.490
Do I like this person?

00:26:10.490 --> 00:26:12.910
Do I want to open
up to this person?

00:26:12.910 --> 00:26:16.707
And you need that opening
up to happen if explanation

00:26:16.707 --> 00:26:17.790
is successfully to happen.

00:26:17.790 --> 00:26:20.120
You can't push
knowledge into a brain.

00:26:20.120 --> 00:26:22.375
It has to be pulled in.

00:26:22.375 --> 00:26:23.750
JIM LECINSKI: And
so the personal

00:26:23.750 --> 00:26:25.214
is the way to build that trust.

00:26:25.214 --> 00:26:26.130
CHRIS ANDERSON: Right.

00:26:26.130 --> 00:26:28.630
So I'd say it's not so
necessarily personal.

00:26:28.630 --> 00:26:30.790
It's not saying, let me
tell you all about me.

00:26:30.790 --> 00:26:35.210
It's more saying
in a personal way,

00:26:35.210 --> 00:26:39.520
why this matters
but just showing it

00:26:39.520 --> 00:26:41.520
in sort of an informal
way, rather than starting

00:26:41.520 --> 00:26:43.160
at a conceptual level.

00:26:43.160 --> 00:26:45.450
It's like saying, hey, we're
going to go on a journey

00:26:45.450 --> 00:26:48.192
together.

00:26:48.192 --> 00:26:49.400
This is where I'd like to go.

00:26:49.400 --> 00:26:50.520
And by the way, it's
going to be fun.

00:26:50.520 --> 00:26:52.270
Here's why you
should come with me.

00:26:52.270 --> 00:26:54.379
And just trying to
convince people of that.

00:26:54.379 --> 00:26:56.170
JIM LECINSKI: I want
to remind our audience

00:26:56.170 --> 00:26:58.730
in a few minutes we'll be taking
questions at the microphones

00:26:58.730 --> 00:27:02.400
here, so have your questions
ready in a couple of minutes.

00:27:02.400 --> 00:27:05.020
One of the concepts that
really resonated powerfully

00:27:05.020 --> 00:27:08.760
with me in the book is this
notion of the through line.

00:27:08.760 --> 00:27:11.626
I wonder if you'd explain
that for our audience.

00:27:11.626 --> 00:27:13.750
CHRIS ANDERSON: So if it's
right that a talk should

00:27:13.750 --> 00:27:17.850
be about building an
idea in people's minds,

00:27:17.850 --> 00:27:21.300
then everything in the talk
needs to connect to that idea.

00:27:21.300 --> 00:27:24.140
You think of it as
your through line.

00:27:24.140 --> 00:27:27.420
And so things that aren't
part of that get cut out,

00:27:27.420 --> 00:27:30.881
but then everything
else connects to that.

00:27:30.881 --> 00:27:32.880
When you think about
what's happening in a talk,

00:27:32.880 --> 00:27:35.590
you're taking this very complex
three-dimensional object

00:27:35.590 --> 00:27:37.710
of an idea, and you're
trying to transfer that.

00:27:37.710 --> 00:27:40.330
And your means to do it is
a one-dimensional stream

00:27:40.330 --> 00:27:41.380
of words.

00:27:41.380 --> 00:27:44.220
So it's inherently hard,
and what you have to do,

00:27:44.220 --> 00:27:46.450
therefore, is to thread
those words in a way

00:27:46.450 --> 00:27:48.690
where it's clear how
each part relates.

00:27:48.690 --> 00:27:51.302
So if you're going to
give a counter-example,

00:27:51.302 --> 00:27:53.510
that needs to be clear that
that's what you're doing.

00:27:53.510 --> 00:27:56.830
If you're giving some
historical context,

00:27:56.830 --> 00:27:59.260
you need to show that
that's what it is.

00:27:59.260 --> 00:28:02.860
If it's an anecdote, people
need to get a sense of how this

00:28:02.860 --> 00:28:05.310
relates to what's happening.

00:28:05.310 --> 00:28:08.249
Otherwise, again, it's like I
like the sound of your voice,

00:28:08.249 --> 00:28:09.790
and this kind of
makes sense, but I'm

00:28:09.790 --> 00:28:11.230
really not sure exactly
where you're going

00:28:11.230 --> 00:28:12.430
and how these
pieces fit together.

00:28:12.430 --> 00:28:13.846
And a lot of talks
feel like that.

00:28:13.846 --> 00:28:16.649
They feel the pieces are there,
but it doesn't quite land.

00:28:16.649 --> 00:28:17.440
JIM LECINSKI: Yeah.

00:28:17.440 --> 00:28:23.160
In the book, you also talk
about a powerful speaking device

00:28:23.160 --> 00:28:26.610
is to uncover and
explore a disconnect

00:28:26.610 --> 00:28:30.200
or a seeming disconnect
in a common world view.

00:28:30.200 --> 00:28:31.740
CHRIS ANDERSON: Yes.

00:28:31.740 --> 00:28:35.570
Persuasion-- to persuade
someone of something,

00:28:35.570 --> 00:28:39.030
you first have to show them
that what they believe right now

00:28:39.030 --> 00:28:40.590
doesn't really make sense.

00:28:40.590 --> 00:28:42.710
Like before you can blow
up someone's worldview,

00:28:42.710 --> 00:28:45.550
you need to just
tease it out a bit.

00:28:45.550 --> 00:28:47.530
So do you really
want to believe this?

00:28:47.530 --> 00:28:50.170
How is that
consistent with this?

00:28:50.170 --> 00:28:52.510
And so it's this wonderful
feature of some talks.

00:28:52.510 --> 00:28:56.020
In a sort of teasing, friendly,
but in a powerful way,

00:28:56.020 --> 00:29:00.380
just reveal that this
view has got to be absurd,

00:29:00.380 --> 00:29:02.900
and that stokes curiosity.

00:29:02.900 --> 00:29:06.360
And there's this concept
of the knowledge gap.

00:29:06.360 --> 00:29:09.050
Once you are aware of this
knowledge gap in your mind,

00:29:09.050 --> 00:29:11.300
you instinctively
just want to close it.

00:29:11.300 --> 00:29:13.540
And curiosity says,
more, more, more.

00:29:13.540 --> 00:29:14.540
Help me figure this out.

00:29:14.540 --> 00:29:15.350
I don't like this.

00:29:15.350 --> 00:29:18.050
JIM LECINSKI: Yeah.

00:29:18.050 --> 00:29:21.300
In addition to the
talks themselves,

00:29:21.300 --> 00:29:23.790
you've done a wonderful
job of extending the brand.

00:29:23.790 --> 00:29:26.430
We've talked about putting those
talks and those videos online,

00:29:26.430 --> 00:29:29.380
certainly the book that
we're talking about today.

00:29:29.380 --> 00:29:33.870
But there's TED X, TED Ed,
some of these other brand

00:29:33.870 --> 00:29:34.762
and line extensions.

00:29:34.762 --> 00:29:37.220
I wondered if you would just
maybe talk about some of those

00:29:37.220 --> 00:29:39.932
and how you see
those fitting in.

00:29:39.932 --> 00:29:42.390
CHRIS ANDERSON: Having seen
the success of just giving away

00:29:42.390 --> 00:29:45.110
the content, we
became a bit obsessed

00:29:45.110 --> 00:29:46.700
with giving things
away and the power

00:29:46.700 --> 00:29:48.230
of that in the connected age.

00:29:48.230 --> 00:29:51.220
And so we thought, what
if we gave away our brand?

00:29:51.220 --> 00:29:55.940
It doesn't seem like that
bright an idea at first glance,

00:29:55.940 --> 00:29:58.350
so we added an X to TED
and said the X stands

00:29:58.350 --> 00:29:59.201
for self-organized.

00:29:59.201 --> 00:30:01.450
And if you would like to do
a TED-like event somewhere

00:30:01.450 --> 00:30:04.350
in the world, we'll give
you a license to do it.

00:30:04.350 --> 00:30:05.790
It's over to you.

00:30:05.790 --> 00:30:08.810
And amazingly, there's
3,000 of these now a year.

00:30:08.810 --> 00:30:10.760
So there's nine every day or so.

00:30:10.760 --> 00:30:13.730
And obviously, we
couldn't do this.

00:30:13.730 --> 00:30:16.490
Like I've got 15
people in New York,

00:30:16.490 --> 00:30:19.730
who are overseeing
3,000 events a year,

00:30:19.730 --> 00:30:21.860
and it's because of
the power of TED X.

00:30:21.860 --> 00:30:24.580
So these events go from filling
out the Sydney Opera House

00:30:24.580 --> 00:30:29.610
to an event in a jail or
TED X Baghdad or whatever.

00:30:29.610 --> 00:30:31.900
Absolutely.

00:30:31.900 --> 00:30:35.450
And we just love seeing
what happens there.

00:30:35.450 --> 00:30:37.920
There's about-- YouTube,
thank you very much--

00:30:37.920 --> 00:30:40.700
is the main distribution
vehicle for these.

00:30:40.700 --> 00:30:43.880
There's more than 60,000 talks
on there, and many of them

00:30:43.880 --> 00:30:46.060
are getting a lot
of views, so that's

00:30:46.060 --> 00:30:47.490
been a thrilling experiment.

00:30:47.490 --> 00:30:49.940
And then TED Ed is just our
reaching out to the brand

00:30:49.940 --> 00:30:51.940
to a youth audience.

00:30:51.940 --> 00:30:56.530
And instead of talks on a
stage, we're saying teachers,

00:30:56.530 --> 00:30:57.760
let's have your best lesson.

00:30:57.760 --> 00:31:01.190
Five or six minutes
to spark curiosity.

00:31:01.190 --> 00:31:04.840
Thanks to Google,
knowledge is no longer

00:31:04.840 --> 00:31:06.250
a problem in the world.

00:31:06.250 --> 00:31:08.670
Everyone has access to
all the world's knowledge.

00:31:08.670 --> 00:31:11.760
For some reason,
educators haven't quite

00:31:11.760 --> 00:31:14.850
come to terms with this yet,
and we still think of education

00:31:14.850 --> 00:31:19.250
as trying to jam knowledge
into a brain, to fill it up.

00:31:19.250 --> 00:31:21.859
It should all be about nurturing
the right kind of curiosity

00:31:21.859 --> 00:31:23.900
and the right way to ask
questions, the right way

00:31:23.900 --> 00:31:26.240
to bring in the right knowledge.

00:31:26.240 --> 00:31:29.330
So these are
curiosity-sparking videos,

00:31:29.330 --> 00:31:32.510
and they're animated, but
from a teacher's best words.

00:31:32.510 --> 00:31:34.740
And so we have the thrill
of a great teacher,

00:31:34.740 --> 00:31:38.870
who during their whole career,
has reached 5,000 kids, at most

00:31:38.870 --> 00:31:39.740
or whatever.

00:31:39.740 --> 00:31:42.220
And suddenly in the first
hour of their talking online,

00:31:42.220 --> 00:31:43.580
they've reached 50,000 kids.

00:31:43.580 --> 00:31:46.700
And it's so thrilling for
them, and it's fun to see.

00:31:46.700 --> 00:31:48.670
JIM LECINSKI: And
education and learning

00:31:48.670 --> 00:31:51.580
has been long part
of, I would suggest,

00:31:51.580 --> 00:31:54.440
one of the core tenets
or essences of TED.

00:31:54.440 --> 00:31:56.350
I mean, obviously,
since the beginning,

00:31:56.350 --> 00:31:59.170
but maybe perhaps,
Sal Khan, Salman Khan,

00:31:59.170 --> 00:32:02.339
was one of the most preeminent
that came and talked

00:32:02.339 --> 00:32:03.005
about education.

00:32:03.005 --> 00:32:05.255
I wonder if you'd maybe share
some of your experiences

00:32:05.255 --> 00:32:06.520
with him and what he's done.

00:32:06.520 --> 00:32:08.520
CHRIS ANDERSON: I mean,
Sal Khan, in my opinion,

00:32:08.520 --> 00:32:09.830
he's a true global hero.

00:32:09.830 --> 00:32:14.430
I mean, for a hedge fund
manager to give over his life

00:32:14.430 --> 00:32:17.450
to educating first his
cousin, his nephews,

00:32:17.450 --> 00:32:20.470
and then the world, I mean,
it's really incredible

00:32:20.470 --> 00:32:22.700
that one person could do that.

00:32:22.700 --> 00:32:27.110
And he's starting with
just the power of video,

00:32:27.110 --> 00:32:30.130
and then adding in
this idea of mastery

00:32:30.130 --> 00:32:32.265
so that people can
learn at their own pace.

00:32:32.265 --> 00:32:33.640
That's the real
power of video is

00:32:33.640 --> 00:32:36.956
that it makes no sense
to force a bunch of kids

00:32:36.956 --> 00:32:38.080
to learn at the same speed.

00:32:38.080 --> 00:32:39.410
They're all different.

00:32:39.410 --> 00:32:42.420
Video allows them to
decouple from time

00:32:42.420 --> 00:32:43.710
and find their own rhythm.

00:32:43.710 --> 00:32:47.300
And that allows people who you'd
never expect to master topics

00:32:47.300 --> 00:32:48.409
in their own timing.

00:32:48.409 --> 00:32:49.200
So it's incredible.

00:32:49.200 --> 00:32:51.870
And he gave a very
inspiring talk at TED.

00:32:51.870 --> 00:32:54.130
And by the way, he's got
the best single quote

00:32:54.130 --> 00:32:59.250
in the book, which is when you
give a talk, just be yourself.

00:32:59.250 --> 00:33:01.970
Like if you're a creative
person, be a creative person.

00:33:01.970 --> 00:33:05.090
If you're a humorous person,
be a humorous person.

00:33:05.090 --> 00:33:09.005
If you're an egoful person,
however, leave that aside.

00:33:09.005 --> 00:33:10.380
JIM LECINSKI:
That's good advice.

00:33:10.380 --> 00:33:13.220
And in a sense, what
started on your stage

00:33:13.220 --> 00:33:15.320
there has been a
revolution in learning.

00:33:15.320 --> 00:33:17.240
There are more than a
few school districts

00:33:17.240 --> 00:33:19.380
who have so-called
flipped the classroom,

00:33:19.380 --> 00:33:24.520
and the homework is watching Sal
Khan to absorb the information.

00:33:24.520 --> 00:33:26.720
And then the class
itself is the practice,

00:33:26.720 --> 00:33:28.260
as opposed to what
we all learned

00:33:28.260 --> 00:33:31.250
was you learn during the day and
go home and practice at night.

00:33:31.250 --> 00:33:32.740
So that has to be
very gratifying,

00:33:32.740 --> 00:33:35.530
the kind of thing when you talk
about ideas worth spreading.

00:33:35.530 --> 00:33:35.770
CHRIS ANDERSON: Yeah.

00:33:35.770 --> 00:33:37.330
And I think that
is hugely powerful.

00:33:37.330 --> 00:33:39.090
I think it's still
early days, and there's

00:33:39.090 --> 00:33:40.830
lots of versions of
that being explored,

00:33:40.830 --> 00:33:41.760
but I think it's very exciting.

00:33:41.760 --> 00:33:42.840
JIM LECINSKI: Yeah.

00:33:42.840 --> 00:33:46.350
Has there been any topic area
that you would very much wish

00:33:46.350 --> 00:33:49.840
to have explored throughout
the TED process or on stage,

00:33:49.840 --> 00:33:52.900
but you haven't just found the
quite right speaker, or maybe

00:33:52.900 --> 00:33:56.470
an area that you've
thought about diving into,

00:33:56.470 --> 00:33:59.250
but haven't been comfortable
bringing to the stage?

00:33:59.250 --> 00:34:01.294
CHRIS ANDERSON:
Yeah, there are lots.

00:34:01.294 --> 00:34:03.210
JIM LECINSKI: Any you'd
like to share with us?

00:34:03.210 --> 00:34:04.918
CHRIS ANDERSON: Well,
just being personal

00:34:04.918 --> 00:34:06.820
as the sort of
philosophical geek, who

00:34:06.820 --> 00:34:09.380
used to lie on the floor
of his student room

00:34:09.380 --> 00:34:14.750
trying to understand the world
and failing, consciousness.

00:34:14.750 --> 00:34:16.280
Who the hell are we?

00:34:16.280 --> 00:34:19.480
It doesn't make any sense.

00:34:19.480 --> 00:34:24.006
I mean by all sort of scientific
definitions of consciousness

00:34:24.006 --> 00:34:25.880
that you get to a certain
level of complexity

00:34:25.880 --> 00:34:28.889
in decision making, Google
itself is conscious right now.

00:34:28.889 --> 00:34:29.469
Maybe it is.

00:34:29.469 --> 00:34:30.480
We don't know.

00:34:30.480 --> 00:34:32.270
But what is it?

00:34:32.270 --> 00:34:33.761
Who are we?

00:34:33.761 --> 00:34:35.219
These are very
difficult questions,

00:34:35.219 --> 00:34:36.552
and we've had a few speakers in.

00:34:36.552 --> 00:34:38.800
But I would love more of that.

00:34:38.800 --> 00:34:39.969
But that's a little selfish.

00:34:39.969 --> 00:34:43.690
I mean, politics is hard, right?

00:34:43.690 --> 00:34:48.260
In many ways, TED is sort of
this escape from the ranting

00:34:48.260 --> 00:34:51.800
that we hear 24/7 on
cable, but there's

00:34:51.800 --> 00:34:54.190
something about certain
topics that force people

00:34:54.190 --> 00:34:55.250
into a tribal mode.

00:34:55.250 --> 00:34:58.220
And it's very distressing
when we stop reasoning

00:34:58.220 --> 00:35:00.320
with each other
and sharing ideas

00:35:00.320 --> 00:35:05.030
and start shouting at each other
and just staking out positions.

00:35:05.030 --> 00:35:08.230
And so we don't have traditional
political-type talks.

00:35:08.230 --> 00:35:12.450
I would love to find more people
who can frame ways to bridge

00:35:12.450 --> 00:35:15.851
and frame different ways
of looking at politics.

00:35:15.851 --> 00:35:17.850
And so we're constantly
on the lookout for that,

00:35:17.850 --> 00:35:19.300
but it's hard.

00:35:19.300 --> 00:35:20.380
That's hard to do.

00:35:20.380 --> 00:35:21.250
JIM LECINSKI: Let's
invite our audience

00:35:21.250 --> 00:35:23.630
to come up to the microphones
and ask some questions,

00:35:23.630 --> 00:35:28.090
and as they do that, you
mentioned scientific.

00:35:28.090 --> 00:35:29.620
You know, there
are quite a lot of,

00:35:29.620 --> 00:35:31.520
as you used the
example here today,

00:35:31.520 --> 00:35:35.160
there are quite a lot of
heavy-duty scientific topics.

00:35:35.160 --> 00:35:37.920
But then there's a lot of sort
of different points of view.

00:35:37.920 --> 00:35:39.150
We can pick global warming.

00:35:39.150 --> 00:35:40.930
Is it, isn't it these
kinds of things?

00:35:40.930 --> 00:35:42.880
Do you have a
scientific body that

00:35:42.880 --> 00:35:46.060
reviews the sort of
realness of the science?

00:35:46.060 --> 00:35:49.090
Or how does one know
into these deep topics

00:35:49.090 --> 00:35:51.620
if it's real science
or skewed science

00:35:51.620 --> 00:35:53.275
or a personal point of view?

00:35:53.275 --> 00:35:54.900
CHRIS ANDERSON: I
mean, we're committed

00:35:54.900 --> 00:35:57.360
to real science in principle.

00:35:57.360 --> 00:35:59.270
What real science is
is a matter of debate,

00:35:59.270 --> 00:36:00.460
even among scientists.

00:36:00.460 --> 00:36:03.939
We don't have a formal
process for doing it.

00:36:03.939 --> 00:36:05.480
We're constantly
thinking about this.

00:36:05.480 --> 00:36:09.690
We're actually in the process
of hiring a science curator,

00:36:09.690 --> 00:36:14.240
and that person will have a
group of advisors as well.

00:36:17.500 --> 00:36:20.340
Certainly,
pseudoscience, I think,

00:36:20.340 --> 00:36:22.890
doesn't have a place
on the TED stage.

00:36:22.890 --> 00:36:25.190
There's enough amazingness
happening in science.

00:36:25.190 --> 00:36:26.200
There are so many
brilliant scientists

00:36:26.200 --> 00:36:28.408
out there, who have incredible
knowledge that's worth

00:36:28.408 --> 00:36:32.210
sharing without needing to
go to people who are probably

00:36:32.210 --> 00:36:34.100
going to end up misleading.

00:36:34.100 --> 00:36:35.670
But what the line
is between the two

00:36:35.670 --> 00:36:37.300
is sometimes just a
matter of judgment.

00:36:37.300 --> 00:36:38.950
JIM LECINSKI: Yeah.

00:36:38.950 --> 00:36:42.630
One of my favorite talks
was a young 10-year-old,

00:36:42.630 --> 00:36:44.330
I think, that you
had from Africa.

00:36:44.330 --> 00:36:46.830
I wonder if you would tell that
story if the audience hasn't

00:36:46.830 --> 00:36:48.580
seen his amazing speech.

00:36:48.580 --> 00:36:50.350
CHRIS ANDERSON: OK,
so this would be-- I

00:36:50.350 --> 00:36:52.902
think it's the Kenyan
boy, Richard Turere.

00:36:52.902 --> 00:36:54.860
I think about he might
have been 12 by the time

00:36:54.860 --> 00:36:56.780
he got to the TED
stage, but earlier,

00:36:56.780 --> 00:36:59.440
he had taught
himself electronics

00:36:59.440 --> 00:37:02.880
by taking apart
his parents' radio.

00:37:02.880 --> 00:37:04.090
He was a Maasai kid.

00:37:04.090 --> 00:37:08.250
He lived in a little
settlement outside Nairobi,

00:37:08.250 --> 00:37:13.050
trying to protect
cattle from lions.

00:37:13.050 --> 00:37:17.770
And he figured out that moving
lights terrified these lions.

00:37:17.770 --> 00:37:19.990
So somehow he built
from parts that he

00:37:19.990 --> 00:37:25.240
found a solar powered
light flasher, which

00:37:25.240 --> 00:37:26.940
scared away the lions.

00:37:26.940 --> 00:37:29.355
And so environmentalists
were happy,

00:37:29.355 --> 00:37:31.480
because the villagers
weren't going out and killing

00:37:31.480 --> 00:37:32.390
the lions.

00:37:32.390 --> 00:37:36.000
And this invention spread
across the area of Kenya,

00:37:36.000 --> 00:37:40.190
but when we met this kid
in Nairobi, he was so shy.

00:37:40.190 --> 00:37:41.770
He could hardly speak.

00:37:41.770 --> 00:37:44.100
You couldn't get the
story out of him.

00:37:44.100 --> 00:37:45.420
He was terrified.

00:37:45.420 --> 00:37:48.539
And the process of bringing
him to the point where

00:37:48.539 --> 00:37:50.580
he got on a plane for the
first time in his life,

00:37:50.580 --> 00:37:52.260
came to California,
and somewhere

00:37:52.260 --> 00:37:55.560
between Sergey
Brin and Bill Gates

00:37:55.560 --> 00:37:59.110
gave a talk about his invention.

00:37:59.110 --> 00:38:02.590
And the room just cheered him.

00:38:02.590 --> 00:38:04.500
He was so great.

00:38:04.500 --> 00:38:06.230
His smile lit up
the entire place,

00:38:06.230 --> 00:38:08.340
and he told the
story beautifully.

00:38:08.340 --> 00:38:10.870
And it was just about getting
comfortable and rehearsing

00:38:10.870 --> 00:38:12.650
and believing in
what he had done.

00:38:12.650 --> 00:38:14.180
JIM LECINSKI: And I think
that continually illustrates

00:38:14.180 --> 00:38:16.360
the point that it's not
always just the big names

00:38:16.360 --> 00:38:18.370
who can deliver a great talk.

00:38:18.370 --> 00:38:20.820
The unexpected people are
often the biggest surprises.

00:38:20.820 --> 00:38:22.370
CHRIS ANDERSON: Absolutely.

00:38:22.370 --> 00:38:23.050
So hi.

00:38:23.050 --> 00:38:26.930
AUDIENCE: I'm curious,
how much of the talks

00:38:26.930 --> 00:38:30.150
are you recruited
this kid from Kenya,

00:38:30.150 --> 00:38:32.320
or how many are supplied to you?

00:38:32.320 --> 00:38:35.040
You mentioned you get 10,000
ideas on a yearly basis.

00:38:35.040 --> 00:38:38.220
How often are you like, we
need to get this person,

00:38:38.220 --> 00:38:39.620
because they have
an idea that we

00:38:39.620 --> 00:38:40.889
want to see on the TED stage?

00:38:40.889 --> 00:38:42.680
CHRIS ANDERSON: Yeah,
I think it's probably

00:38:42.680 --> 00:38:49.200
about 60-40, 60 we recruit
or find or identify, 40.

00:38:49.200 --> 00:38:51.639
Most of that 40 come
from people saying,

00:38:51.639 --> 00:38:53.680
you know, I saw this
person, and they're amazing.

00:38:53.680 --> 00:38:55.240
You must bring them to TED.

00:38:55.240 --> 00:38:59.430
And probably 5% of
people who say hey,

00:38:59.430 --> 00:39:00.720
I'm ready for the TED stage.

00:39:00.720 --> 00:39:03.370
I mean, some of those are
great, but some of those aren't.

00:39:03.370 --> 00:39:06.255
And it's something
like that mix.

00:39:06.255 --> 00:39:07.630
JIM LECINSKI:
Let's go over here.

00:39:07.630 --> 00:39:09.220
AUDIENCE: Thank you so much
for being here and sharing

00:39:09.220 --> 00:39:10.386
an hour of your day with us.

00:39:10.386 --> 00:39:11.020
I love TED.

00:39:11.020 --> 00:39:14.660
It's one of my personal goals
to actually watch at least one

00:39:14.660 --> 00:39:15.290
or two a week.

00:39:15.290 --> 00:39:17.520
I take time out of
my day to do that,

00:39:17.520 --> 00:39:19.410
because I find them
to be so valuable.

00:39:19.410 --> 00:39:23.030
So I'm curious if you're
able to share any sneak peeks

00:39:23.030 --> 00:39:26.360
or what we can expect
this year at TED, or just

00:39:26.360 --> 00:39:28.130
some ideas or topics
that might be new

00:39:28.130 --> 00:39:31.571
and coming that we can expect.

00:39:31.571 --> 00:39:33.570
CHRIS ANDERSON: Well,
next year's TED, the theme

00:39:33.570 --> 00:39:35.780
is The Future You.

00:39:35.780 --> 00:39:39.100
And so it's going to be more
personal than some TEDs are

00:39:39.100 --> 00:39:42.530
with more sort of personal
takeaway of how you can use it.

00:39:42.530 --> 00:39:45.430
But it's everything from
the technologies that

00:39:45.430 --> 00:39:48.400
are going to be very cool coming
up to literal sort of life

00:39:48.400 --> 00:39:53.000
hacks that you can use to
navigate the challenging

00:39:53.000 --> 00:39:57.120
world that we're in-- medical
advances and so forth.

00:39:57.120 --> 00:39:59.970
So that's the direction.

00:39:59.970 --> 00:40:03.500
Our themes are sort of like
a tweak on usual TED content.

00:40:03.500 --> 00:40:09.660
It's still from the
same type of palette.

00:40:09.660 --> 00:40:14.590
In terms of other talks from
the last TED that are coming up,

00:40:14.590 --> 00:40:16.130
well, let's see.

00:40:16.130 --> 00:40:20.130
Jennifer Khan's talk on
CRISPR and on gene drives

00:40:20.130 --> 00:40:21.350
is coming out soon.

00:40:21.350 --> 00:40:25.410
And I think that's incredibly
beautifully explained

00:40:25.410 --> 00:40:27.730
and a very powerful
issue that we all

00:40:27.730 --> 00:40:29.130
need to be thinking about.

00:40:29.130 --> 00:40:31.320
There's a wonderful talk
about misfits coming out.

00:40:34.130 --> 00:40:38.080
If you haven't seen it,
do watch the Tim Urban

00:40:38.080 --> 00:40:39.960
talk on procrastination.

00:40:39.960 --> 00:40:41.139
We all do it.

00:40:41.139 --> 00:40:42.805
JIM LECINSKI: I need
to get to that one.

00:40:42.805 --> 00:40:43.910
[LAUGHTER]

00:40:43.910 --> 00:40:44.785
CHRIS ANDERSON: Nice.

00:40:44.785 --> 00:40:45.775
That was good.

00:40:45.775 --> 00:40:49.641
I like that.

00:40:49.641 --> 00:40:50.140
Very good.

00:40:54.980 --> 00:40:59.100
He procrastinated right up to
the week before the conference,

00:40:59.100 --> 00:41:01.790
then realized his talk wasn't
there, flew into this panic,

00:41:01.790 --> 00:41:04.560
and ended up coming
up with a masterpiece.

00:41:04.560 --> 00:41:06.625
So it was very good.

00:41:06.625 --> 00:41:08.000
JIM LECINSKI:
Let's go over here.

00:41:08.000 --> 00:41:10.060
AUDIENCE: I wanted to pick on
your media and journalist brain

00:41:10.060 --> 00:41:12.430
and ask this question about
the discourse in general

00:41:12.430 --> 00:41:14.580
on social media
and news channels.

00:41:14.580 --> 00:41:16.566
And it's almost
like the incentives

00:41:16.566 --> 00:41:19.280
encourage extremist thinking
and not nuanced thinking.

00:41:19.280 --> 00:41:22.530
Like on Twitter because of
word limits, and extreme people

00:41:22.530 --> 00:41:24.017
tend to voice their
opinions more.

00:41:24.017 --> 00:41:25.350
This is all my personal opinion.

00:41:25.350 --> 00:41:28.588
And even for news
channels, like snippets,

00:41:28.588 --> 00:41:32.010
and like almost false
news sells more ads.

00:41:32.010 --> 00:41:33.469
And these are the
biggest mediums.

00:41:33.469 --> 00:41:36.010
I mean it's great to have them
as a medium for communication,

00:41:36.010 --> 00:41:38.117
but how do we fix those?

00:41:38.117 --> 00:41:40.200
Or like not necessarily
do individual fix, though.

00:41:40.200 --> 00:41:43.490
It's like, how do we get
this nuanced discussion out

00:41:43.490 --> 00:41:44.070
to everyone?

00:41:44.070 --> 00:41:46.410
And TV and social media
are the channels that

00:41:46.410 --> 00:41:48.020
reach more than TED, right?

00:41:48.020 --> 00:41:48.860
So do you have
thoughts, and have

00:41:48.860 --> 00:41:50.151
you thought about this problem?

00:41:50.151 --> 00:41:51.560
Or do you feel
this is a problem?

00:41:51.560 --> 00:41:53.476
CHRIS ANDERSON: No, it's
definitely a problem.

00:41:53.476 --> 00:41:58.320
And I think it's
constantly moving.

00:41:58.320 --> 00:42:01.250
I mean, there's many
conversations to be had here.

00:42:01.250 --> 00:42:04.240
One of the things I think about,
which I think I'm hopeful at,

00:42:04.240 --> 00:42:07.560
is that the world
we're moving to is-- I

00:42:07.560 --> 00:42:11.180
think video is going to play
a bigger and bigger role.

00:42:11.180 --> 00:42:15.530
If we believe your founders and
people like Zuckerberg and Elon

00:42:15.530 --> 00:42:17.140
Musk, we're going
to have low band,

00:42:17.140 --> 00:42:21.190
low-cost broadband across every
square inch of the planet.

00:42:21.190 --> 00:42:24.137
And I think you can imagine
a future, where people, yes,

00:42:24.137 --> 00:42:25.970
they're still looking
down at their screens.

00:42:25.970 --> 00:42:28.750
But what they're seeing is
another human face looking back

00:42:28.750 --> 00:42:29.660
at them.

00:42:29.660 --> 00:42:32.710
And some perforce
when that happens,

00:42:32.710 --> 00:42:38.230
some of the traditional
standards and things that

00:42:38.230 --> 00:42:41.320
run very deep in how we look and
how we interact with each other

00:42:41.320 --> 00:42:43.600
may shift.

00:42:43.600 --> 00:42:47.870
There's a bigger premium
on trust and on respect

00:42:47.870 --> 00:42:48.970
and so forth.

00:42:48.970 --> 00:42:49.820
But I don't know.

00:42:49.820 --> 00:42:51.236
I think it's all
to be played for,

00:42:51.236 --> 00:42:56.530
and I do think one of the
things that I see some hope in

00:42:56.530 --> 00:43:02.150
is that when the battle is
about what will people click on,

00:43:02.150 --> 00:43:04.200
that drives a certain
type of behavior.

00:43:04.200 --> 00:43:06.500
It drives a kind of extremist,
if you like, to my mind,

00:43:06.500 --> 00:43:09.740
lizard brain behavior, where
you go the dramatic and the sort

00:43:09.740 --> 00:43:11.060
of whatever.

00:43:11.060 --> 00:43:15.130
And that leads to all these
awful sort of Five Celebrity

00:43:15.130 --> 00:43:17.940
Sexy Secrets that
duh-duh-duh that are frankly

00:43:17.940 --> 00:43:18.940
destroying the internet.

00:43:18.940 --> 00:43:21.492
And if you guys could
please Google them out.

00:43:24.330 --> 00:43:29.110
But when you go to sharing,
social media sharing,

00:43:29.110 --> 00:43:31.421
there, it's more about
someone's identity.

00:43:31.421 --> 00:43:33.170
And I think that
triggers a different part

00:43:33.170 --> 00:43:34.260
of people's minds.

00:43:34.260 --> 00:43:37.700
It's more a reflective choice.

00:43:37.700 --> 00:43:39.960
And I think that
type of content,

00:43:39.960 --> 00:43:44.600
that's how hopeful stories and
stuff do end up circulating

00:43:44.600 --> 00:43:46.000
on social media beautifully.

00:43:46.000 --> 00:43:48.190
So it's not an answer
to your question,

00:43:48.190 --> 00:43:51.140
but it's a very
long conversation.

00:43:51.140 --> 00:43:53.734
AUDIENCE: [INAUDIBLE] enabling
both kinds of behaviors there.

00:43:53.734 --> 00:43:55.150
I mean, maybe as
technologists, we

00:43:55.150 --> 00:43:57.108
don't think that everything
technology is good,

00:43:57.108 --> 00:43:58.981
but perhaps, technology
is also the source

00:43:58.981 --> 00:43:59.980
of some of these things.

00:43:59.980 --> 00:44:01.860
At least it's enabling
some of these things,

00:44:01.860 --> 00:44:03.942
and we maybe should think
about how we fit in.

00:44:03.942 --> 00:44:05.650
CHRIS ANDERSON: It is
absolutely possible

00:44:05.650 --> 00:44:08.480
that we end up
creating technologies,

00:44:08.480 --> 00:44:11.330
where we end up sleepwalking
into a future we don't actually

00:44:11.330 --> 00:44:12.901
want.

00:44:12.901 --> 00:44:14.900
And you guys, more than
any others in the world,

00:44:14.900 --> 00:44:16.960
need to be thinking
about that every day,

00:44:16.960 --> 00:44:19.440
because just because
something works in the moment,

00:44:19.440 --> 00:44:21.155
and people want
it and like it, it

00:44:21.155 --> 00:44:22.655
doesn't mean that
there aren't going

00:44:22.655 --> 00:44:25.504
to be terrible, unintended
consequences of it.

00:44:25.504 --> 00:44:27.170
AUDIENCE: Thanks so
much for being here.

00:44:27.170 --> 00:44:29.550
This is such a fun way
to spend an afternoon.

00:44:29.550 --> 00:44:33.740
My question is, I think we all
have stories that we reread

00:44:33.740 --> 00:44:36.910
and TED Talks we
revisit to be inspired.

00:44:36.910 --> 00:44:38.340
So my question is twofold.

00:44:38.340 --> 00:44:39.740
Do you have any
TED talk that you

00:44:39.740 --> 00:44:43.020
find yourself rewatching over
and over again that's really

00:44:43.020 --> 00:44:44.830
moved you in some way?

00:44:44.830 --> 00:44:47.220
And then are there any other
storytellers, maybe even

00:44:47.220 --> 00:44:49.000
outside of TED, that
you really admire?

00:44:52.035 --> 00:44:53.910
CHRIS ANDERSON: So I'll
answer the first one.

00:44:53.910 --> 00:44:55.330
I'm not sure if I've got
a good answer for you

00:44:55.330 --> 00:44:56.080
on the second one.

00:44:56.080 --> 00:44:58.750
Oh, I do have a good
answer on the second one.

00:44:58.750 --> 00:45:01.950
On the first one, there's
a talk by David Deutsch

00:45:01.950 --> 00:45:02.870
that I really like.

00:45:02.870 --> 00:45:04.230
So he's a physicist.

00:45:04.230 --> 00:45:06.850
He's kind of a recluse.

00:45:06.850 --> 00:45:09.230
And he gave this talk
basically arguing

00:45:09.230 --> 00:45:13.080
that we're not chemical
scum on a random planet

00:45:13.080 --> 00:45:16.910
in the universe, as Stephen
Hawking kind of said.

00:45:16.910 --> 00:45:20.370
But actually,
knowledge is a force

00:45:20.370 --> 00:45:24.650
of potentially universal reach.

00:45:24.650 --> 00:45:27.270
And so that is powerful, and
he has this wonderful statement

00:45:27.270 --> 00:45:29.520
at the end of it
saying that it's

00:45:29.520 --> 00:45:31.540
a kind of a definition
of optimism, I think.

00:45:31.540 --> 00:45:33.930
He says, look, carve
two stone tablets.

00:45:33.930 --> 00:45:36.570
One of them says,
problems are inevitable.

00:45:36.570 --> 00:45:39.760
One of them says,
problems are solvable.

00:45:39.760 --> 00:45:42.620
And I think that
what that says is

00:45:42.620 --> 00:45:47.130
that not the cliche that
there's a technological solution

00:45:47.130 --> 00:45:51.570
to every problem, which I
think really annoys people.

00:45:51.570 --> 00:45:56.090
What it says is that
it's right to take

00:45:56.090 --> 00:45:58.740
the stance in the world, not
to be beaten by stuff that OK,

00:45:58.740 --> 00:46:00.990
there are going to be problems,
that there will always

00:46:00.990 --> 00:46:01.680
be problems.

00:46:01.680 --> 00:46:05.390
We actually do have a crack
at solving them if we're wise

00:46:05.390 --> 00:46:07.880
and if we keep thinking
and keep at it.

00:46:07.880 --> 00:46:10.700
So I personally find that a very
nuanced and beautiful message,

00:46:10.700 --> 00:46:12.190
and I like that talk.

00:46:12.190 --> 00:46:15.870
And on the storyteller, Yuval
Harari's book, "Sapiens,"

00:46:15.870 --> 00:46:17.210
is astonishing.

00:46:17.210 --> 00:46:19.990
He tells the story
of us as a species,

00:46:19.990 --> 00:46:22.120
and he tells it in
extraordinary language

00:46:22.120 --> 00:46:25.100
and connects things that you
would never imagine connecting.

00:46:25.100 --> 00:46:27.045
And I couldn't recommend
it more strongly.

00:46:29.800 --> 00:46:31.140
AUDIENCE: Hi, thanks for coming.

00:46:31.140 --> 00:46:33.890
So in the algorithm,
as you mentioned,

00:46:33.890 --> 00:46:37.020
world that we live in, I find
it hard for an individual

00:46:37.020 --> 00:46:40.360
to have a sense of
the actual truth

00:46:40.360 --> 00:46:42.230
or reality of certain things.

00:46:42.230 --> 00:46:45.280
So for example, when I
watch TED Talks on YouTube,

00:46:45.280 --> 00:46:47.490
is it over indexed
towards technology,

00:46:47.490 --> 00:46:50.670
or is it just, I happen to have
watched several technology TED

00:46:50.670 --> 00:46:54.140
Talks, and that's what
YouTube recommends for me?

00:46:54.140 --> 00:46:58.450
So my question is just with
your inside perspective,

00:46:58.450 --> 00:47:01.960
do you feel that TED is over
indexed in certain areas

00:47:01.960 --> 00:47:03.370
or under indexed in others?

00:47:03.370 --> 00:47:04.250
And what do you do?

00:47:04.250 --> 00:47:08.412
So you just sit back and
let the masses sort of--

00:47:08.412 --> 00:47:09.870
CHRIS ANDERSON:
YouTube's algorithm

00:47:09.870 --> 00:47:11.240
is entirely to blame here.

00:47:14.620 --> 00:47:17.220
YouTube does a brilliant
job of personalizing stuff,

00:47:17.220 --> 00:47:21.435
and so what you watch, that's
what it will offer you.

00:47:21.435 --> 00:47:25.190
If you were to go to ted.com
and type in the word happiness,

00:47:25.190 --> 00:47:26.850
for example, you'd
see a ton of talks

00:47:26.850 --> 00:47:28.990
about happiness,
which if anyone is

00:47:28.990 --> 00:47:31.610
coming to TED for the first
time, I would say start there.

00:47:31.610 --> 00:47:32.710
One, happiness matters.

00:47:32.710 --> 00:47:35.409
Two, there's a dozen
different approaches to it

00:47:35.409 --> 00:47:36.200
that are different.

00:47:36.200 --> 00:47:39.420
And I love those talks.

00:47:39.420 --> 00:47:42.380
And the personalization
thing, by the way,

00:47:42.380 --> 00:47:44.910
I wish there was a default
setting on YouTube,

00:47:44.910 --> 00:47:48.930
where you could say, actually,
I want to be catalyzed.

00:47:48.930 --> 00:47:54.350
I don't want you to assume
that I'm only who I click on.

00:47:54.350 --> 00:47:57.780
I want to be catalyzed by a
broader sense of knowledge.

00:47:57.780 --> 00:47:59.100
Could you do that for me?

00:47:59.100 --> 00:48:01.830
And I think a lot of people
would click that setting,

00:48:01.830 --> 00:48:03.721
honestly.

00:48:03.721 --> 00:48:04.720
JIM LECINSKI: Thank you.

00:48:04.720 --> 00:48:05.803
CHRIS ANDERSON: Thank you.

00:48:08.470 --> 00:48:11.170
AUDIENCE: Thank you
very much for coming.

00:48:11.170 --> 00:48:13.440
I'm sure you've heard
incredible stories from people

00:48:13.440 --> 00:48:15.390
all around the world,
communities, groups

00:48:15.390 --> 00:48:17.130
of how TED has impacted them.

00:48:17.130 --> 00:48:21.700
Do you have a favorite anecdote
or story that you've heard?

00:48:21.700 --> 00:48:23.080
CHRIS ANDERSON: There are many.

00:48:23.080 --> 00:48:30.240
Many of them just happen
on quite a personal level.

00:48:30.240 --> 00:48:35.700
TED moves people from being sort
of skeptical observers to being

00:48:35.700 --> 00:48:38.696
engaged agents, and
I love seeing that.

00:48:38.696 --> 00:48:40.570
I had one lovely moment
recently at a dinner,

00:48:40.570 --> 00:48:45.420
where the waitress serving us
sort of whispered in my ear

00:48:45.420 --> 00:48:46.840
that she had watched TED Talks.

00:48:46.840 --> 00:48:50.270
And it turned out that I think
she was a Polish immigrant,

00:48:50.270 --> 00:48:53.410
and she'd come into the US.

00:48:53.410 --> 00:48:57.290
She'd been homeless
for awhile, and her son

00:48:57.290 --> 00:48:59.140
had introduced her to TED.

00:48:59.140 --> 00:49:02.490
And so it's almost like she
was sort of sneaking hours

00:49:02.490 --> 00:49:05.100
in a homeless
shelter for a while

00:49:05.100 --> 00:49:09.080
somehow watching TED Talks on
a borrowed iPad or something.

00:49:09.080 --> 00:49:13.120
And she was crying,
and so we were crying.

00:49:13.120 --> 00:49:16.550
And it was like, I
love the spread of this

00:49:16.550 --> 00:49:20.524
that there are so many
people, who want to learn.

00:49:20.524 --> 00:49:22.940
I think what she got from that
was a sense of empowerment.

00:49:22.940 --> 00:49:25.320
I'm homeless now, but
that's not who I am.

00:49:25.320 --> 00:49:27.680
I can be a lot more than that.

00:49:27.680 --> 00:49:29.930
And I think there
are a lot of stories

00:49:29.930 --> 00:49:32.340
like that at an individual
level that are really

00:49:32.340 --> 00:49:34.939
why we do what we do.

00:49:34.939 --> 00:49:37.480
JIM LECINSKI: And that brings
us to our final question, which

00:49:37.480 --> 00:49:39.080
is the traditional
question we always

00:49:39.080 --> 00:49:42.820
ask our guests at these
Authors at Google talks.

00:49:42.820 --> 00:49:45.720
Would you be willing to share
with our audience a start,

00:49:45.720 --> 00:49:48.890
stop continue, something that
you would suggest that they

00:49:48.890 --> 00:49:50.680
start doing, stop
doing, continue

00:49:50.680 --> 00:49:53.650
doing to learn and
to be better speakers

00:49:53.650 --> 00:49:56.210
and to plant those seeds
of ideas that matter?

00:50:00.554 --> 00:50:01.970
CHRIS ANDERSON:
Stop being daunted

00:50:01.970 --> 00:50:04.300
by your nervousness about it.

00:50:04.300 --> 00:50:05.300
It's there for a reason.

00:50:05.300 --> 00:50:07.510
It's there to motivate
you to put the work in

00:50:07.510 --> 00:50:11.190
to produce a great talk.

00:50:11.190 --> 00:50:13.200
Start speaking up.

00:50:13.200 --> 00:50:13.980
Everyone needs to.

00:50:13.980 --> 00:50:18.360
The world's too complicated
for single experts

00:50:18.360 --> 00:50:19.360
to solve these problems.

00:50:19.360 --> 00:50:22.770
It needs lots of
us to participate.

00:50:22.770 --> 00:50:25.450
Please be part of that.

00:50:25.450 --> 00:50:27.342
Continue.

00:50:27.342 --> 00:50:29.550
Well, first of all, continue
doing what you're doing.

00:50:29.550 --> 00:50:31.900
This is one of the
world's great companies,

00:50:31.900 --> 00:50:34.940
and you're empowering,
literally now,

00:50:34.940 --> 00:50:36.530
billions of people
around the world

00:50:36.530 --> 00:50:41.220
to find knowledge more quickly.

00:50:41.220 --> 00:50:43.690
I mean, it's absolutely
incredible what

00:50:43.690 --> 00:50:46.620
has been created in
this organization.

00:50:46.620 --> 00:50:48.450
So keep doing that.

00:50:48.450 --> 00:50:50.630
Continue being not evil.

00:50:50.630 --> 00:50:55.350
It's hard, actually, when
you're a big public company.

00:50:55.350 --> 00:50:56.567
And stay curious.

00:50:56.567 --> 00:50:57.900
That's the single biggest thing.

00:50:57.900 --> 00:51:01.320
I passionately believe
in the power of curiosity

00:51:01.320 --> 00:51:06.020
to lead to things
that are special.

00:51:06.020 --> 00:51:08.530
I mean, the more you
know, the more interesting

00:51:08.530 --> 00:51:09.530
the world gets.

00:51:09.530 --> 00:51:11.155
So stay curious.

00:51:11.155 --> 00:51:13.280
JIM LECINSKI: Chris, thank
you for the gift of TED,

00:51:13.280 --> 00:51:15.190
and thank you for being
with us here today.

00:51:15.190 --> 00:51:15.790
CHRIS ANDERSON:
Thank you so much.

00:51:15.790 --> 00:51:16.390
Thank you.

00:51:16.390 --> 00:51:19.740
[APPLAUSE]

