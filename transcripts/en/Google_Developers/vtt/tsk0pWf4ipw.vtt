WEBVTT
Kind: captions
Language: en

00:00:01.880 --> 00:00:03.480
CRAIG MCLUCKIE:
The last few months

00:00:03.480 --> 00:00:06.220
have been pretty exciting
from a containers perspective.

00:00:06.220 --> 00:00:08.470
I don't know if everyone's
as excited about containers

00:00:08.470 --> 00:00:09.110
as I am.

00:00:09.110 --> 00:00:10.100
[AUDIENCE CHEERS]

00:00:10.100 --> 00:00:11.310
CRAIG MCLUCKIE: Awesome.

00:00:11.310 --> 00:00:13.685
But we've actually seen a lot
of interesting developments

00:00:13.685 --> 00:00:14.470
in this space.

00:00:14.470 --> 00:00:16.730
The first, and possibly
the most noteworthy,

00:00:16.730 --> 00:00:20.230
has been Docker, which is a
very popular Linux application

00:00:20.230 --> 00:00:23.390
container stack going
into production,

00:00:23.390 --> 00:00:25.347
so being production
ready, which is great.

00:00:25.347 --> 00:00:26.930
And at Google, we've
been working hard

00:00:26.930 --> 00:00:30.650
to make the Google Cloud
Platform the best place

00:00:30.650 --> 00:00:31.400
to run containers.

00:00:31.400 --> 00:00:33.140
And we've had two releases.

00:00:33.140 --> 00:00:36.440
One, we introduced container
optimized virtual machines

00:00:36.440 --> 00:00:37.700
in May.

00:00:37.700 --> 00:00:40.500
And we followed that up
recently, just a couple weeks

00:00:40.500 --> 00:00:45.000
ago, introducing an open source
scheduler called Kubernetes.

00:00:45.000 --> 00:00:46.760
And my name's Craig.

00:00:46.760 --> 00:00:48.145
I'm a product guy.

00:00:48.145 --> 00:00:50.310
And I'm going to take a
few minutes to talk you

00:00:50.310 --> 00:00:51.987
through Linux
application containers.

00:00:51.987 --> 00:00:54.320
Some of the stuff the people
that were cheering probably

00:00:54.320 --> 00:00:55.066
already know.

00:00:55.066 --> 00:00:56.440
But hopefully
it'll give everyone

00:00:56.440 --> 00:00:58.410
a better sense of
what they mean.

00:00:58.410 --> 00:00:59.890
And I'll take some
time to explain

00:00:59.890 --> 00:01:02.360
what they mean to Google,
like how Linux application

00:01:02.360 --> 00:01:04.209
containers have really
helped us at Google,

00:01:04.209 --> 00:01:07.420
and where the intersection
of these things is going.

00:01:07.420 --> 00:01:10.007
And then, I'll hand off to
my colleague Brendan, who's

00:01:10.007 --> 00:01:12.090
going to go through in a
lot more technical detail

00:01:12.090 --> 00:01:14.620
around the stuff that we've
actually put into the market

00:01:14.620 --> 00:01:17.990
right now that you can
get your hands on and use.

00:01:17.990 --> 00:01:21.690
So let's kick this off and say,
what is a Linux application

00:01:21.690 --> 00:01:22.550
container?

00:01:22.550 --> 00:01:24.690
What does it mean to people?

00:01:24.690 --> 00:01:26.665
At the heart, a Linux
application container

00:01:26.665 --> 00:01:30.080
is a very simple way to package
up all of your application

00:01:30.080 --> 00:01:34.730
pieces into a single
hermetically sealed unit

00:01:34.730 --> 00:01:37.602
that you can then deploy
into an environment and run.

00:01:37.602 --> 00:01:39.560
And it has a lot of really
favorable properties

00:01:39.560 --> 00:01:41.420
that we'll go through in detail.

00:01:41.420 --> 00:01:43.107
And if you actually
step back and just

00:01:43.107 --> 00:01:44.690
think about what it
means, it's really

00:01:44.690 --> 00:01:45.970
raising the abstraction level.

00:01:45.970 --> 00:01:48.870
So historically, the
abstraction level

00:01:48.870 --> 00:01:50.520
that most developers
have worked with

00:01:50.520 --> 00:01:53.480
has been at the virtual machine
level, the hardware level.

00:01:53.480 --> 00:01:55.470
And with Docker
virtual machines,

00:01:55.470 --> 00:01:57.930
you have this idealized
hardware that you

00:01:57.930 --> 00:02:00.380
can run multiple instances on.

00:02:00.380 --> 00:02:02.245
But it pulls thought
a lot of other goop.

00:02:02.245 --> 00:02:04.660
With Docker and with Linux
application containers,

00:02:04.660 --> 00:02:07.146
we've actually moved the
abstraction up so that you now

00:02:07.146 --> 00:02:09.354
have-- instead of having an
idealized hardware stack,

00:02:09.354 --> 00:02:11.830
you actually have an
idealized operating system.

00:02:11.830 --> 00:02:13.790
That's a very powerful metaphor.

00:02:13.790 --> 00:02:15.826
So that's great-- woo hoo.

00:02:15.826 --> 00:02:18.200
Increased abstraction level--
everyone loves abstraction.

00:02:18.200 --> 00:02:20.240
What does it mean to
me as a developer?

00:02:20.240 --> 00:02:21.740
I'm not actually
really a developer.

00:02:21.740 --> 00:02:23.890
But if I were , what
would that mean?

00:02:23.890 --> 00:02:25.340
Why do you care, right?

00:02:25.340 --> 00:02:28.254
And the reason our developers
care, and the reason

00:02:28.254 --> 00:02:30.170
I care where I'm actually
playing a developer,

00:02:30.170 --> 00:02:36.100
is this ability to create a
static, hermetically sealed

00:02:36.100 --> 00:02:40.620
unit radically simplifies
the process of deployment.

00:02:40.620 --> 00:02:43.370
It creates a much more
predictable and isolated

00:02:43.370 --> 00:02:46.160
framework to package up
your application bits, all

00:02:46.160 --> 00:02:48.870
of its user LAN dependencies,
and get it out there

00:02:48.870 --> 00:02:50.709
into this idealized
Linux environment.

00:02:50.709 --> 00:02:52.250
It means that your
application is now

00:02:52.250 --> 00:02:55.250
isolated from other applications
from a resource perspective.

00:02:55.250 --> 00:02:57.270
It's dependencies
are all sealed in.

00:02:57.270 --> 00:02:59.516
And it radically reduces
the amount of stress

00:02:59.516 --> 00:03:01.765
that you experience when
you're deploying applications

00:03:01.765 --> 00:03:03.620
or updating those applications.

00:03:03.620 --> 00:03:06.960
And a lot of customers I speak
to, this is the first epiphany.

00:03:06.960 --> 00:03:09.310
They say, wow, this has
really changed the game.

00:03:09.310 --> 00:03:12.170
This fundamentally redefines the
way we think about operations.

00:03:12.170 --> 00:03:14.400
And so that's very exciting.

00:03:14.400 --> 00:03:16.050
The next thing that
people encounter

00:03:16.050 --> 00:03:17.430
is this idea of portability.

00:03:17.430 --> 00:03:18.640
OK, this is great.

00:03:18.640 --> 00:03:20.480
I have this idealized
operating system.

00:03:20.480 --> 00:03:23.500
It means I can
produce, effectively,

00:03:23.500 --> 00:03:26.600
an executable that
runs here or there.

00:03:26.600 --> 00:03:30.294
It runs in my local development
machine in a very lightweight

00:03:30.294 --> 00:03:32.460
place that I've just set
up with Vagrant or whatever

00:03:32.460 --> 00:03:33.635
technologies.

00:03:33.635 --> 00:03:37.010
And I can take that same package
and have a very high degree

00:03:37.010 --> 00:03:38.620
of confidence that
it's going to work

00:03:38.620 --> 00:03:41.860
in my bulletproof enterprise
grade Red Hat environment,

00:03:41.860 --> 00:03:44.230
or whatever environment
that I'm running in, right?

00:03:44.230 --> 00:03:46.642
And so this idea of
portability is huge.

00:03:46.642 --> 00:03:48.100
But it's not just
about portability

00:03:48.100 --> 00:03:50.346
between your development,
testing, and production

00:03:50.346 --> 00:03:51.970
environments, which
might be different.

00:03:51.970 --> 00:03:53.820
It also offers the
idea of portability

00:03:53.820 --> 00:03:55.380
between cloud environments.

00:03:55.380 --> 00:03:57.890
And at Google, we're very
proud of Google Compute Engine.

00:03:57.890 --> 00:03:59.306
We've put a lot
of time and effort

00:03:59.306 --> 00:04:01.780
into making it an
incredibly robust framework

00:04:01.780 --> 00:04:02.697
for running workloads.

00:04:02.697 --> 00:04:05.113
But we want our customers to
pick it because it's awesome.

00:04:05.113 --> 00:04:06.470
We don't want to lock them in.

00:04:06.470 --> 00:04:08.074
And with these
container technologies,

00:04:08.074 --> 00:04:09.990
it's the first time that
customers have really

00:04:09.990 --> 00:04:13.110
had an opportunity to
package up their application

00:04:13.110 --> 00:04:16.019
in a framework that's portable,
that can run in Google Compute

00:04:16.019 --> 00:04:18.480
Engine, or in another
cloud, or in their sort

00:04:18.480 --> 00:04:20.730
of personal cloud,
their private cloud.

00:04:20.730 --> 00:04:23.540
And these container formats
offer a very high level

00:04:23.540 --> 00:04:25.500
of portability, which is great.

00:04:25.500 --> 00:04:28.990
And then finally, when I talk
to customers, the penny's kind

00:04:28.990 --> 00:04:32.090
of dropping around,
wow, not only can I

00:04:32.090 --> 00:04:34.650
think about my application
as being sort of hermetically

00:04:34.650 --> 00:04:37.350
sealed, but I can actually
start to decouple it, take

00:04:37.350 --> 00:04:41.040
these application pieces
and put them together

00:04:41.040 --> 00:04:42.900
into loosely
coupled systems that

00:04:42.900 --> 00:04:45.580
are much more easy to manage
and are much less intrinsically

00:04:45.580 --> 00:04:46.714
bound together.

00:04:46.714 --> 00:04:48.380
So instead of having
all of these pieces

00:04:48.380 --> 00:04:51.330
in the soup of an operating
system environment,

00:04:51.330 --> 00:04:53.790
I can tease them apart and
control them separately.

00:04:53.790 --> 00:04:55.130
And I can mix in stuff.

00:04:55.130 --> 00:04:57.960
I can mix in pieces that are
provided by the open source

00:04:57.960 --> 00:04:58.622
community.

00:04:58.622 --> 00:05:00.330
And I'm hoping that
we'll very soon start

00:05:00.330 --> 00:05:04.525
to see ISVs producing
commercial software that

00:05:04.525 --> 00:05:05.830
can be mixed in the same way.

00:05:05.830 --> 00:05:08.830
Microservices is very powerful.

00:05:08.830 --> 00:05:11.550
And all that's great.

00:05:11.550 --> 00:05:13.000
And it's really catching on.

00:05:13.000 --> 00:05:15.500
We're seeing a lot hype and a
lot of excitement around this.

00:05:15.500 --> 00:05:18.760
Now, it turns out containers
have existed for a while.

00:05:18.760 --> 00:05:21.304
And we've been using them in
Google for a very long time.

00:05:21.304 --> 00:05:23.720
And we've actually approached
it from a slightly different

00:05:23.720 --> 00:05:24.409
angle.

00:05:24.409 --> 00:05:25.700
We get a lot of those benefits.

00:05:25.700 --> 00:05:27.750
And we've really
benefited from them.

00:05:27.750 --> 00:05:29.540
But there's a couple
of other things

00:05:29.540 --> 00:05:32.460
that working in this container
in optimized environments

00:05:32.460 --> 00:05:33.030
brings.

00:05:33.030 --> 00:05:35.050
When you're doing
hyper-scale deployments

00:05:35.050 --> 00:05:38.480
like we are, whether
it's search or Gmail,

00:05:38.480 --> 00:05:40.480
efficiency is really
important, being

00:05:40.480 --> 00:05:44.880
able to get every ounce out of
your underlying infrastructure.

00:05:44.880 --> 00:05:47.990
And because we have very high
levels of resource isolation,

00:05:47.990 --> 00:05:49.960
we're able to pack
things much more densely

00:05:49.960 --> 00:05:53.454
and use very high level
algorithms to do that.

00:05:53.454 --> 00:05:55.120
If you're doing
hyper-scale deployments,

00:05:55.120 --> 00:05:57.324
predictability of
deployment is critical.

00:05:57.324 --> 00:05:58.740
If you're deploying
something that

00:05:58.740 --> 00:06:01.660
is as complicated
as the things we do,

00:06:01.660 --> 00:06:04.867
having to worry about mapping
a specific application

00:06:04.867 --> 00:06:06.950
to a specific piece of
hardware just doesn't work.

00:06:06.950 --> 00:06:08.460
It doesn't scale.

00:06:08.460 --> 00:06:12.480
And then, the quality
of service is huge.

00:06:12.480 --> 00:06:14.770
A scaling event for
us doesn't involve

00:06:14.770 --> 00:06:16.230
provisioning a virtual machine.

00:06:16.230 --> 00:06:17.650
We already have a massive fleet.

00:06:17.650 --> 00:06:19.810
It simply involves taking
a very lightweight thing

00:06:19.810 --> 00:06:22.040
and dropping it into
another environment.

00:06:22.040 --> 00:06:24.440
And the other thing is it
makes our developers better.

00:06:24.440 --> 00:06:27.120
We have much higher levels
of introspectibility.

00:06:27.120 --> 00:06:29.330
And so they're able
to actually get

00:06:29.330 --> 00:06:32.819
a much better sense of what's
going on in their code.

00:06:32.819 --> 00:06:34.860
They can understand what
resources they're using.

00:06:34.860 --> 00:06:35.705
They can understand
what contention

00:06:35.705 --> 00:06:37.020
they're experiencing.

00:06:37.020 --> 00:06:43.520
And they're able to use
that to feed that back

00:06:43.520 --> 00:06:45.980
and actually produce
more efficient code.

00:06:45.980 --> 00:06:49.920
So at Google, we do start over
2 billion containers a week.

00:06:49.920 --> 00:06:51.430
That's a lot of
containers, right?

00:06:51.430 --> 00:06:52.347
That's 3,000 a second.

00:06:52.347 --> 00:06:54.180
So when I say everything
runs in containers,

00:06:54.180 --> 00:06:55.870
I mean everything
runs in containers.

00:06:55.870 --> 00:06:57.770
And if you think
about that, I've

00:06:57.770 --> 00:06:59.370
been talking for
seven minutes now.

00:06:59.370 --> 00:07:02.090
So since I started talking,
we launched about 1.2 million

00:07:02.090 --> 00:07:02.620
containers.

00:07:02.620 --> 00:07:04.290
That's a lot of containers.

00:07:04.290 --> 00:07:07.520
And the thing I'm
really excited about

00:07:07.520 --> 00:07:10.280
is that thinking about
where we're going,

00:07:10.280 --> 00:07:13.690
we've seen the ecosystem
rally around this efficient,

00:07:13.690 --> 00:07:17.350
this portable,
decoupled framework.

00:07:17.350 --> 00:07:20.260
Inside Google, we've created an
incredibly efficient framework

00:07:20.260 --> 00:07:22.860
that's actively managing
your systems where

00:07:22.860 --> 00:07:25.987
you as a developer at Google
aren't running something.

00:07:25.987 --> 00:07:26.820
You're running code.

00:07:26.820 --> 00:07:28.300
And you're handing it
off to these systems that

00:07:28.300 --> 00:07:29.290
run it on your behalf.

00:07:29.290 --> 00:07:31.420
And they do it far better
than you could possibly do it.

00:07:31.420 --> 00:07:32.770
Because they're
constantly watching.

00:07:32.770 --> 00:07:34.930
It's like a modern flight
control system in an airplane.

00:07:34.930 --> 00:07:37.263
It's taking a lot of signals
and making very intelligent

00:07:37.263 --> 00:07:38.880
decisions about what
to tune and what

00:07:38.880 --> 00:07:43.550
to adjust to make the overall
system perform better.

00:07:43.550 --> 00:07:45.305
And so we get efficiency.

00:07:45.305 --> 00:07:47.550
And we can bring that
efficiency to our engineers

00:07:47.550 --> 00:07:50.314
and radically drive down
the cost of operations.

00:07:50.314 --> 00:07:52.480
We get performance like we
do with App Engine, which

00:07:52.480 --> 00:07:55.740
is effectively a container-based
solution where a scaling

00:07:55.740 --> 00:07:59.060
event happens in milliseconds
instead of tens of seconds,

00:07:59.060 --> 00:08:00.950
which is what you see
with Compute Engine,

00:08:00.950 --> 00:08:04.390
or minutes that you might see
with other cloud providers'

00:08:04.390 --> 00:08:06.890
virtual machines.

00:08:06.890 --> 00:08:09.040
Continuous integration
is really easy.

00:08:09.040 --> 00:08:10.306
You can build something.

00:08:10.306 --> 00:08:11.680
You can roll it
out a little bit.

00:08:11.680 --> 00:08:14.870
If things don't work out, you
can roll it back very easily.

00:08:14.870 --> 00:08:17.620
And then, overall it's a
much more robust system.

00:08:17.620 --> 00:08:21.280
So we're extremely excited
about these technologies.

00:08:21.280 --> 00:08:23.120
And I'm very
pleased to hand over

00:08:23.120 --> 00:08:27.120
to Brendan, who's a
developer on our team

00:08:27.120 --> 00:08:29.936
who's headed up a lot of these
initiatives to tell you more.

00:08:29.936 --> 00:08:31.994
BRENDAN BURNS: Great.

00:08:31.994 --> 00:08:36.880
So I'm really happy to give
you a guided tour of both

00:08:36.880 --> 00:08:39.850
how we build cluster
management inside of Google

00:08:39.850 --> 00:08:42.429
and how we're bringing
that knowledge to the cloud

00:08:42.429 --> 00:08:43.289
platform.

00:08:43.289 --> 00:08:46.510
As a bit of context, I worked
in this search infrastructure.

00:08:46.510 --> 00:08:48.510
I worked in search
infrastructure for about four

00:08:48.510 --> 00:08:50.850
years before I came
to the Google Cloud,

00:08:50.850 --> 00:08:54.240
where I got to use this cluster
management to provide the back

00:08:54.240 --> 00:08:59.380
ends that provide search for
Google+ and for recent events

00:08:59.380 --> 00:09:01.860
in products like Google News.

00:09:01.860 --> 00:09:04.240
And basically
anything that you see

00:09:04.240 --> 00:09:07.190
in Google that is under
about 12 hours old

00:09:07.190 --> 00:09:09.600
is coming out of software
that I or my teams wrote.

00:09:09.600 --> 00:09:11.730
And so I'm particularly
excited to be

00:09:11.730 --> 00:09:14.950
able to take some
of the systems that

00:09:14.950 --> 00:09:17.340
enabled us to build
those scale systems

00:09:17.340 --> 00:09:20.133
and make them available to
customers of the Google Cloud

00:09:20.133 --> 00:09:20.860
Platform.

00:09:20.860 --> 00:09:24.190
So if we take a look here, this
is a basic high level overview

00:09:24.190 --> 00:09:25.870
of the Google cluster
management stack.

00:09:25.870 --> 00:09:28.240
It's really split
into two pieces.

00:09:28.240 --> 00:09:30.790
And I'm going to deal with each
of those pieces individually.

00:09:30.790 --> 00:09:34.400
At the bottom, we have a node
container manager and a managed

00:09:34.400 --> 00:09:35.050
base OS.

00:09:35.050 --> 00:09:37.970
This is basically the
piece of software,

00:09:37.970 --> 00:09:40.170
or the multiple
pieces of software,

00:09:40.170 --> 00:09:43.610
that are distributed onto every
single machine in a Google data

00:09:43.610 --> 00:09:44.130
center.

00:09:44.130 --> 00:09:46.810
So every single machine in the
data center is homogeneous.

00:09:46.810 --> 00:09:49.900
Every single machine is
running exactly the same set

00:09:49.900 --> 00:09:52.060
of base infrastructure
that allows

00:09:52.060 --> 00:09:54.100
it to execute
arbitrary containers.

00:09:54.100 --> 00:09:56.500
Now on top of that,
the software that

00:09:56.500 --> 00:09:59.960
runs Google Search or Gmail
or anything else that you use,

00:09:59.960 --> 00:10:02.070
Docs or anything
else, runs inside

00:10:02.070 --> 00:10:03.740
of a scheduled container.

00:10:03.740 --> 00:10:05.890
Now, that container didn't
end up on that machine

00:10:05.890 --> 00:10:08.730
because a developer
said, oh, I want

00:10:08.730 --> 00:10:11.991
to put this on this specific
machine on this specific rack.

00:10:11.991 --> 00:10:14.240
It ended up on that machine
because the developer said

00:10:14.240 --> 00:10:17.130
to the cluster scheduler,
the master for the cluster,

00:10:17.130 --> 00:10:18.900
I have this amount of work.

00:10:18.900 --> 00:10:22.260
I would like to run 10
copies, 10 replicas,

00:10:22.260 --> 00:10:23.870
of this piece of software.

00:10:23.870 --> 00:10:26.960
It needs three cores,
and 10 gigs of memory,

00:10:26.960 --> 00:10:28.470
and a little bit of disk.

00:10:28.470 --> 00:10:31.010
Find me a place where
I can exist happily.

00:10:31.010 --> 00:10:32.570
And the cluster
scheduler takes care

00:10:32.570 --> 00:10:34.900
of things like figuring
out that it should

00:10:34.900 --> 00:10:37.120
do spreading across
multiple machines

00:10:37.120 --> 00:10:40.500
in order to avoid a
single point of failure.

00:10:40.500 --> 00:10:42.680
It does things like
resource isolation.

00:10:42.680 --> 00:10:45.520
So it understands
that I only have

00:10:45.520 --> 00:10:47.480
this number of cores
on this machine.

00:10:47.480 --> 00:10:49.530
There isn't enough
free cores there

00:10:49.530 --> 00:10:51.920
for me to be able to
schedule your job there.

00:10:51.920 --> 00:10:53.700
And it does all of
this on my behalf.

00:10:53.700 --> 00:10:56.110
And so I can have this
declarative, abstract, high

00:10:56.110 --> 00:10:58.050
level concept of a
piece of software

00:10:58.050 --> 00:11:01.832
and a set of resources, and the
scheduler can make that happen.

00:11:01.832 --> 00:11:04.162
All right, so for the
next 15 or 20 minutes,

00:11:04.162 --> 00:11:06.120
I'm going to sort of step
you through how we're

00:11:06.120 --> 00:11:09.310
bringing these concepts out and
making them available to people

00:11:09.310 --> 00:11:11.280
inside of the Google
Cloud Platform.

00:11:11.280 --> 00:11:13.350
And I'm going to start
by talking about the Node

00:11:13.350 --> 00:11:17.160
Container Manager
if it switches.

00:11:17.160 --> 00:11:19.550
All right, so the
Node Container Manager

00:11:19.550 --> 00:11:21.920
is a system for
the cloud platform

00:11:21.920 --> 00:11:24.830
at least that we released
in the middle of May.

00:11:24.830 --> 00:11:27.530
And basically, it's a container
optimized virtual machine.

00:11:27.530 --> 00:11:29.610
It's just a single
virtual machine image

00:11:29.610 --> 00:11:33.700
that has been built with
software that makes it really,

00:11:33.700 --> 00:11:37.060
really easy to run a
container on that VM.

00:11:37.060 --> 00:11:39.770
We've standardized a
declarative container manifest,

00:11:39.770 --> 00:11:43.650
which is a declarative statement
that basically specifies

00:11:43.650 --> 00:11:47.520
the software that you would
like to run on this machine.

00:11:47.520 --> 00:11:50.170
And it also does health
monitoring and some reliability

00:11:50.170 --> 00:11:51.879
to ensure that if you
ask for something--

00:11:51.879 --> 00:11:53.503
and one of the reasons
why we're really

00:11:53.503 --> 00:11:55.350
interested in declarative
representations

00:11:55.350 --> 00:11:58.570
is that the statement says,
I would like this thing

00:11:58.570 --> 00:11:59.197
to be running.

00:11:59.197 --> 00:12:00.780
It doesn't say,
please run this thing.

00:12:00.780 --> 00:12:02.730
It says, I would like
this thing to be running.

00:12:02.730 --> 00:12:04.979
And that means that the
responsibility for making sure

00:12:04.979 --> 00:12:08.440
that that container continues
to run through failures,

00:12:08.440 --> 00:12:10.670
through other problems that
might cause it to stop,

00:12:10.670 --> 00:12:12.280
has been handed over to Google.

00:12:12.280 --> 00:12:14.080
You no longer have
to worry about,

00:12:14.080 --> 00:12:15.967
is this process
actually up and running?

00:12:15.967 --> 00:12:17.550
The infrastructure
on the container VM

00:12:17.550 --> 00:12:19.654
takes care of making
sure that that's true.

00:12:19.654 --> 00:12:21.820
So we're going to take a
little bit of a deeper dive

00:12:21.820 --> 00:12:24.720
into this container managed VM.

00:12:24.720 --> 00:12:26.800
And we start with
basically looking

00:12:26.800 --> 00:12:29.110
at a very simple example
of how you might create

00:12:29.110 --> 00:12:30.900
one of these using
Google Compute Engine.

00:12:33.720 --> 00:12:35.340
There's a large
amount of text there.

00:12:35.340 --> 00:12:36.790
But basically what
it is doing is

00:12:36.790 --> 00:12:40.280
it's creating a virtual machine
in the US central one zone.

00:12:40.280 --> 00:12:42.680
It's an F1 micro, one
of our small instances.

00:12:42.680 --> 00:12:45.790
It's using the
container VM image.

00:12:45.790 --> 00:12:48.780
And it's setting a
metadata key from a file.

00:12:48.780 --> 00:12:50.680
And that file is
the containers.yaml

00:12:50.680 --> 00:12:53.000
that contains the actual
declarative specification

00:12:53.000 --> 00:12:54.870
of what it is that
we would like to run.

00:12:54.870 --> 00:12:56.990
Now, that containers.yaml
here is a very simple

00:12:56.990 --> 00:12:59.810
stripped down representation
of all of the things

00:12:59.810 --> 00:13:00.560
you could express.

00:13:00.560 --> 00:13:02.018
And we'll go into
a little bit more

00:13:02.018 --> 00:13:03.602
of the details in
the next few slides.

00:13:03.602 --> 00:13:05.142
But what this is
basically saying is,

00:13:05.142 --> 00:13:06.920
I would like to run
a single container.

00:13:06.920 --> 00:13:08.602
I'm going to call
it dub, dub, dub.

00:13:08.602 --> 00:13:10.247
It's going to run engine x.

00:13:10.247 --> 00:13:12.580
That's the software that I
want you to run inside of it.

00:13:12.580 --> 00:13:15.970
It's a sort of light weight,
high performance web server.

00:13:15.970 --> 00:13:17.372
And I want to expose a port.

00:13:17.372 --> 00:13:18.830
In this particular
case, it's going

00:13:18.830 --> 00:13:21.390
to be the HTTP
port that's mapping

00:13:21.390 --> 00:13:23.575
a port inside the
container on port 80

00:13:23.575 --> 00:13:25.510
to the external 8080 container.

00:13:25.510 --> 00:13:27.510
So that means that
when I create this VM,

00:13:27.510 --> 00:13:29.530
it's not just booting
a virtual machine.

00:13:29.530 --> 00:13:31.377
It's actually installing
this container.

00:13:31.377 --> 00:13:32.710
It's starting it up and running.

00:13:32.710 --> 00:13:36.290
And by the time this container
optimized VM is done,

00:13:36.290 --> 00:13:38.340
you have a reliable
web server running

00:13:38.340 --> 00:13:40.790
on port 8080 that can
start serving your traffic.

00:13:40.790 --> 00:13:44.140
And if for some reason, either
due to a programming error

00:13:44.140 --> 00:13:48.040
or to someone accidentally
killing that process on the VM,

00:13:48.040 --> 00:13:50.380
the process dies and
the container dies,

00:13:50.380 --> 00:13:51.960
it will be
automatically restarted.

00:13:51.960 --> 00:13:54.020
And so you can be
assured that your web

00:13:54.020 --> 00:13:56.180
server will continue
to function.

00:13:56.180 --> 00:13:57.569
So in some cases,
we actually may

00:13:57.569 --> 00:13:59.110
want to have more
than a single port.

00:13:59.110 --> 00:14:03.040
Web servers often serve both
HTTP traffic and HTTPS traffic.

00:14:03.040 --> 00:14:06.440
So here's an example expanding
on the previous declarative

00:14:06.440 --> 00:14:07.890
specification.

00:14:07.890 --> 00:14:10.030
Now we're adding a
second HTTPS port.

00:14:10.030 --> 00:14:13.170
In this case, we're not
actually remapping the port.

00:14:13.170 --> 00:14:17.080
We are simply keeping the port
443, the standard HTTPS port.

00:14:17.080 --> 00:14:19.660
So we have the ability to have
essentially arbitrary network

00:14:19.660 --> 00:14:20.160
ports.

00:14:20.160 --> 00:14:22.420
And again, Craig mentioned
that introspection

00:14:22.420 --> 00:14:24.570
is a big part of why
we like containers.

00:14:24.570 --> 00:14:26.540
And ports are a
great example of why

00:14:26.540 --> 00:14:28.370
this introspection is valuable.

00:14:28.370 --> 00:14:31.180
So I can actually walk
up to this VM now,

00:14:31.180 --> 00:14:34.470
and rather than just treating
it as a black box operating

00:14:34.470 --> 00:14:36.590
system where in order to
understand what software

00:14:36.590 --> 00:14:38.370
is running on it I
might need to run

00:14:38.370 --> 00:14:40.950
an invasive tool like a
port scan or anything else

00:14:40.950 --> 00:14:44.870
like that, in our UI, we can
actually walk up to this VM

00:14:44.870 --> 00:14:47.320
and see, aha, they're
running a web server.

00:14:47.320 --> 00:14:49.039
They're running an HTTPS server.

00:14:49.039 --> 00:14:51.080
Maybe we'll add some links
that allow you to just

00:14:51.080 --> 00:14:54.711
drive directly to that as part
of what the container VM looks

00:14:54.711 --> 00:14:55.210
like.

00:14:55.210 --> 00:14:58.340
So having this extra metadata,
this extra information

00:14:58.340 --> 00:15:01.200
about the kinds of applications
that you're running on a VM,

00:15:01.200 --> 00:15:04.530
actually enables the Google
Cloud Platform to provide

00:15:04.530 --> 00:15:07.900
a better, richer experience
that actually gives you

00:15:07.900 --> 00:15:09.850
deeper insight
than just, oh, hey,

00:15:09.850 --> 00:15:13.480
we see that there's a
virtual machine running here.

00:15:13.480 --> 00:15:16.194
So that sort of gives
you a brief example.

00:15:16.194 --> 00:15:18.860
I wanted to step into a slightly
more complicated example of one

00:15:18.860 --> 00:15:20.151
of these declarative manifests.

00:15:20.151 --> 00:15:23.040
This is a pattern that we
see emerging a lot internally

00:15:23.040 --> 00:15:24.860
inside of Google
and that we think

00:15:24.860 --> 00:15:27.510
we see also happening in
the exterior world, which

00:15:27.510 --> 00:15:31.060
is we actually want-- and this
idea is the notion that we have

00:15:31.060 --> 00:15:34.940
containers that actually work
really symbiotically together.

00:15:34.940 --> 00:15:37.650
They are containers who, in
the case of this example,

00:15:37.650 --> 00:15:40.270
we may have a web search front
end that actually answers

00:15:40.270 --> 00:15:43.710
your queries, the thing that
actually receives the request

00:15:43.710 --> 00:15:45.870
and gives you back the
documents that match.

00:15:45.870 --> 00:15:49.030
And it has a symbiotic
data loader container

00:15:49.030 --> 00:15:52.060
that is always looking
out into the network,

00:15:52.060 --> 00:15:54.390
finding new data shards
as new documents.

00:15:54.390 --> 00:15:56.060
I mentioned I
worked in freshness.

00:15:56.060 --> 00:15:57.890
As new documents
are made available,

00:15:57.890 --> 00:15:59.120
new shards are built.

00:15:59.120 --> 00:16:01.570
The data loader is responsible
for taking those things off

00:16:01.570 --> 00:16:03.900
of the network, bringing
them onto local disks

00:16:03.900 --> 00:16:06.950
so that those search engines can
actually serve those files out

00:16:06.950 --> 00:16:08.510
to user requests.

00:16:08.510 --> 00:16:11.000
Now, these containers have
very, very different resource

00:16:11.000 --> 00:16:13.580
requirements and very,
very different quality

00:16:13.580 --> 00:16:14.540
of service guarantees.

00:16:14.540 --> 00:16:16.331
Obviously, we want the
searches that people

00:16:16.331 --> 00:16:18.180
do to be as fast as possible.

00:16:18.180 --> 00:16:21.290
And so we want to ensure that
the web search container has

00:16:21.290 --> 00:16:24.230
high quality of service,
very, very low latency.

00:16:24.230 --> 00:16:25.750
The data loader,
on the other hand,

00:16:25.750 --> 00:16:27.780
is a background
batch processing job.

00:16:27.780 --> 00:16:30.390
It's responsible for keeping
the server up to date.

00:16:30.390 --> 00:16:32.120
And that's a very
important function.

00:16:32.120 --> 00:16:34.210
But if it gets delayed
for a few seconds

00:16:34.210 --> 00:16:37.180
while we're in the midst of
handling a burst of queries,

00:16:37.180 --> 00:16:37.850
that's OK.

00:16:37.850 --> 00:16:40.320
And so having these things
in two different containers

00:16:40.320 --> 00:16:42.550
with two different resource
isolation boundaries

00:16:42.550 --> 00:16:45.410
allows us to apply different
levels of quality of service

00:16:45.410 --> 00:16:47.410
to the two different
containers and have

00:16:47.410 --> 00:16:50.450
a really responsive user
experience that may actually

00:16:50.450 --> 00:16:54.950
steal some resources from the
data loader when necessary.

00:16:54.950 --> 00:16:57.480
The way that these two
containers communicate

00:16:57.480 --> 00:16:58.820
is through a shared volume.

00:16:58.820 --> 00:17:00.530
So you can see at the
very bottom there,

00:17:00.530 --> 00:17:02.790
we have this volume
that's named Data Shard.

00:17:02.790 --> 00:17:04.500
This volume in
the container spec

00:17:04.500 --> 00:17:08.190
basically means that we will
create a shared directory that

00:17:08.190 --> 00:17:10.589
is mounted into each
of these containers

00:17:10.589 --> 00:17:13.099
where the shards are going
to be living so that the data

00:17:13.099 --> 00:17:15.420
loader can copy the files
into that directory,

00:17:15.420 --> 00:17:21.150
the web search software can read
from that directory, and load

00:17:21.150 --> 00:17:22.790
in new data to serve searches.

00:17:22.790 --> 00:17:26.410
So it's a shared object,
a shared piece of storage,

00:17:26.410 --> 00:17:28.560
that both containers
can see and can use.

00:17:28.560 --> 00:17:31.710
And yet, the two containers are
still isolated from each other.

00:17:31.710 --> 00:17:34.430
Because they cannot see any of
the rest of the configuration

00:17:34.430 --> 00:17:36.210
files, or the
application binaries,

00:17:36.210 --> 00:17:38.390
or anything else that might
be inside the container.

00:17:38.390 --> 00:17:40.980
So you only share what
is necessary to achieve

00:17:40.980 --> 00:17:42.400
the symbiotic relationship.

00:17:42.400 --> 00:17:44.709
You don't have these two
things in the same place

00:17:44.709 --> 00:17:46.250
where they might
accidentally clobber

00:17:46.250 --> 00:17:49.100
each other or anything
else like that.

00:17:49.100 --> 00:17:52.640
So this is an example of how
you might build a relatively

00:17:52.640 --> 00:17:56.180
sophisticated single
node application on top

00:17:56.180 --> 00:17:58.806
of the Google container VM.

00:17:58.806 --> 00:18:00.875
Oh, I think I hit
the Back button.

00:18:00.875 --> 00:18:02.432
All right, so I
wanted to give you

00:18:02.432 --> 00:18:04.140
a little bit of an
illustration of what's

00:18:04.140 --> 00:18:06.010
actually happening on that VM.

00:18:06.010 --> 00:18:07.290
On the left hand side?

00:18:07.290 --> 00:18:10.750
Yes, the left hand side, you see
the stuff that Google provides.

00:18:10.750 --> 00:18:12.550
This is the operating
system, obviously,

00:18:12.550 --> 00:18:14.260
the monitoring and
logging agents.

00:18:14.260 --> 00:18:16.570
The Docker daemon is
installed as well.

00:18:16.570 --> 00:18:19.800
Tools like SSHD
or the init system

00:18:19.800 --> 00:18:22.060
are all part of the
sort of software stack

00:18:22.060 --> 00:18:25.410
that Google is providing as part
of the container managed VM.

00:18:25.410 --> 00:18:27.220
In the user experience
side, well, we're

00:18:27.220 --> 00:18:29.310
going to provide you with
a container environment.

00:18:29.310 --> 00:18:31.520
This involves things
that you may pass in

00:18:31.520 --> 00:18:34.167
like environment variables, the
parts that you want to open.

00:18:34.167 --> 00:18:36.250
And then of course, your
code is going to actually

00:18:36.250 --> 00:18:39.260
be running inside that
container environment as well.

00:18:39.260 --> 00:18:41.954
So this is how we've really
taken a lot of the concerns

00:18:41.954 --> 00:18:43.370
about running a
piece of software.

00:18:43.370 --> 00:18:46.800
We've offloaded it onto
the Google managed VM.

00:18:46.800 --> 00:18:49.690
And we have made
your code the thing

00:18:49.690 --> 00:18:51.590
that you really
focus on running.

00:18:51.590 --> 00:18:56.270
All right, so that gives you an
illustration of the node level

00:18:56.270 --> 00:18:57.650
single machine management.

00:18:57.650 --> 00:19:01.050
But really, if that was the
place that Google stopped,

00:19:01.050 --> 00:19:03.380
we wouldn't have to have
these giant data centers that

00:19:03.380 --> 00:19:05.502
are full of all kinds
of different machines.

00:19:05.502 --> 00:19:07.210
The really interesting
thing that happens

00:19:07.210 --> 00:19:10.050
is, well suddenly, what if I
have thousands of machines,

00:19:10.050 --> 00:19:12.160
and I need to be
able to say, well

00:19:12.160 --> 00:19:13.910
I have this set of
containers, could you

00:19:13.910 --> 00:19:16.380
just make them run somewhere?

00:19:16.380 --> 00:19:19.110
And so the job of
the cluster scheduler

00:19:19.110 --> 00:19:21.630
is to absorb a set
of resources, make

00:19:21.630 --> 00:19:24.870
it available to the user as
an abstract compute substrate,

00:19:24.870 --> 00:19:27.840
an abstract pool of
compute that's available,

00:19:27.840 --> 00:19:32.820
and then schedule work out into
that large pool of resources.

00:19:32.820 --> 00:19:36.040
And so this system
has been developed

00:19:36.040 --> 00:19:37.870
over a number of
years at Google as we

00:19:37.870 --> 00:19:39.820
needed to push
utilization, as we needed

00:19:39.820 --> 00:19:41.740
to improve the
developer experience.

00:19:41.740 --> 00:19:46.310
And so about two weeks ago,
we announced a project,

00:19:46.310 --> 00:19:49.245
an open source project
called Kubernetes.

00:19:49.245 --> 00:19:52.100
It's ancient Greek for
pilot or helmsman of a ship.

00:19:52.100 --> 00:19:54.360
And it's an open
source cluster manager

00:19:54.360 --> 00:19:56.700
that tries to build
on some of the ideas

00:19:56.700 --> 00:19:59.020
and patterns and paradigms
that we've developed

00:19:59.020 --> 00:20:01.820
over 10 years of managing
containers at Google

00:20:01.820 --> 00:20:04.810
and make those ideas available
out into the community.

00:20:04.810 --> 00:20:06.580
Now at the same
time, we understand

00:20:06.580 --> 00:20:10.096
that the containers that
people are using right now

00:20:10.096 --> 00:20:11.970
are not necessarily the
containers that we've

00:20:11.970 --> 00:20:13.940
used internally
inside of Google.

00:20:13.940 --> 00:20:16.060
And so we really wanted
this open source project

00:20:16.060 --> 00:20:18.729
to not just sort of be a
data dump or a knowledge

00:20:18.729 --> 00:20:20.270
dump of the stuff
that we've learned,

00:20:20.270 --> 00:20:22.420
but actually an
opportunity to explore

00:20:22.420 --> 00:20:25.110
and expand and learn
with the community.

00:20:25.110 --> 00:20:26.860
So I'm going to spend
the rest of the talk

00:20:26.860 --> 00:20:29.509
basically stepping you
through Kubernetes,

00:20:29.509 --> 00:20:31.300
giving you some examples,
and finally doing

00:20:31.300 --> 00:20:32.840
a demo of the system.

00:20:32.840 --> 00:20:36.630
All right, so Kubernetes
provides that scheduler layer.

00:20:36.630 --> 00:20:39.090
It provides the master
scheduler binary.

00:20:39.090 --> 00:20:42.920
It provides a set of machines
that are all identical.

00:20:42.920 --> 00:20:47.400
They're running that container
node piece, the container

00:20:47.400 --> 00:20:50.260
manager, on each
individual machine.

00:20:50.260 --> 00:20:52.800
And it provides this
unified substrate

00:20:52.800 --> 00:20:55.770
that you can schedule work
into without really caring

00:20:55.770 --> 00:20:57.230
what machine it lands on.

00:20:57.230 --> 00:21:01.030
So for example, I may have a
pod like that I was talking

00:21:01.030 --> 00:21:04.980
about before where I have a web
server and a symbiotic task,

00:21:04.980 --> 00:21:06.330
which is its log roller, right?

00:21:06.330 --> 00:21:08.540
We can't let our log files
accumulate and accumulate

00:21:08.540 --> 00:21:09.280
and accumulate.

00:21:09.280 --> 00:21:10.980
We eventually will
run out of disk.

00:21:10.980 --> 00:21:12.790
We need a log
roller that's going

00:21:12.790 --> 00:21:15.050
to be responsible
for truncating a log,

00:21:15.050 --> 00:21:17.250
shipping it off to a
system like BigQuery

00:21:17.250 --> 00:21:20.920
or a more persistent cold
storage like Google Cloud

00:21:20.920 --> 00:21:21.670
Storage.

00:21:21.670 --> 00:21:23.780
So these are
symbiotic containers

00:21:23.780 --> 00:21:24.780
that work well together.

00:21:24.780 --> 00:21:27.910
The web server, obviously low
latency, serves user traffic.

00:21:27.910 --> 00:21:31.054
The log roller batched
background kind of task.

00:21:31.054 --> 00:21:32.720
It's responsible for
sort of maintaining

00:21:32.720 --> 00:21:35.580
the health of the container--
again, sharing resources

00:21:35.580 --> 00:21:36.810
through a shared data volume.

00:21:36.810 --> 00:21:40.380
Now I, as a developer, define
that declarative representation

00:21:40.380 --> 00:21:42.340
of, here's my web
server container,

00:21:42.340 --> 00:21:44.240
here's my log roller container.

00:21:44.240 --> 00:21:46.030
And I go to the
master, and I say, hey,

00:21:46.030 --> 00:21:47.640
this is what I'd
like you to run.

00:21:47.640 --> 00:21:49.431
And the master is the
thing that's actually

00:21:49.431 --> 00:21:51.770
responsible for saying,
aha, I have this container

00:21:51.770 --> 00:21:52.930
VM over here.

00:21:52.930 --> 00:21:53.730
It's available.

00:21:53.730 --> 00:21:56.087
I'll put the work
on there, all right?

00:21:56.087 --> 00:21:58.170
And so if this was all you
were doing, if you only

00:21:58.170 --> 00:22:00.887
wanted to run a single
task, or a few tasks,

00:22:00.887 --> 00:22:02.220
this might be where you stopped.

00:22:02.220 --> 00:22:03.678
And indeed, this
is where you could

00:22:03.678 --> 00:22:05.380
stop if you wanted
to with Kubernetes.

00:22:05.380 --> 00:22:08.140
You can simply use it as
a way to schedule work out

00:22:08.140 --> 00:22:10.960
onto a cluster of
virtual machines.

00:22:10.960 --> 00:22:13.100
But what we've
found internally is

00:22:13.100 --> 00:22:14.780
that once you start
scheduling jobs,

00:22:14.780 --> 00:22:17.280
and once you make it really,
really easy for users

00:22:17.280 --> 00:22:20.860
to schedule work out into
their own personal cloud,

00:22:20.860 --> 00:22:23.650
people start scheduling
a lot of pods, all right?

00:22:23.650 --> 00:22:26.690
They start scheduling--
if you think of Git,

00:22:26.690 --> 00:22:28.980
and in my traditional
Git client,

00:22:28.980 --> 00:22:31.840
I have 10, maybe 15 branches.

00:22:31.840 --> 00:22:33.980
I can deploy each
one of those branches

00:22:33.980 --> 00:22:36.810
as a hermetically sealed
container running out

00:22:36.810 --> 00:22:37.830
in my cluster.

00:22:37.830 --> 00:22:39.080
And so pretty soon, I do that.

00:22:39.080 --> 00:22:42.400
And I have lots of containers
running all over the place.

00:22:42.400 --> 00:22:45.729
And it becomes very, very
hard to understand the system

00:22:45.729 --> 00:22:47.020
and to reason about the system.

00:22:47.020 --> 00:22:49.420
That one list of
containers that contained

00:22:49.420 --> 00:22:52.440
four pretty containers
now contains hundreds.

00:22:52.440 --> 00:22:54.310
It scrolls off the
bottom of a page,

00:22:54.310 --> 00:22:56.420
and I need a way of
organizing this information.

00:22:56.420 --> 00:22:58.610
And the way that we do
this inside of Kubernetes

00:22:58.610 --> 00:23:00.600
is the notion of a label.

00:23:00.600 --> 00:23:03.530
All right, so a label is
basically just a query

00:23:03.530 --> 00:23:07.250
that you can execute across
a set of containers that

00:23:07.250 --> 00:23:09.610
is keyed off of properties
of those container

00:23:09.610 --> 00:23:12.630
key value pairs that are
properties of those containers.

00:23:12.630 --> 00:23:14.030
So you can think
of this as being

00:23:14.030 --> 00:23:17.660
sort of like a selector in
a UX framework like jQuery

00:23:17.660 --> 00:23:21.354
or any number of other
kinds of querying usages.

00:23:21.354 --> 00:23:23.770
So for example here, I might
have a label query that says,

00:23:23.770 --> 00:23:25.144
I would like to
select everything

00:23:25.144 --> 00:23:26.680
whose role is front end.

00:23:26.680 --> 00:23:28.710
And you can see in
green now, I have

00:23:28.710 --> 00:23:31.220
selected all of the front end
jobs that are running inside

00:23:31.220 --> 00:23:33.030
of my Kubernetes cluster.

00:23:33.030 --> 00:23:34.710
Well, this is only
sort of useful.

00:23:34.710 --> 00:23:36.547
Because indeed, some
of those front ends

00:23:36.547 --> 00:23:37.880
might be development front ends.

00:23:37.880 --> 00:23:40.500
Some of those front ends might
be my neighbor's front ends.

00:23:40.500 --> 00:23:42.700
I actually maybe don't
care about a lot of them.

00:23:42.700 --> 00:23:44.620
And so label queries
can be conjunctive.

00:23:44.620 --> 00:23:46.280
And so I can expand
on this label query

00:23:46.280 --> 00:23:49.270
and say, OK, actually I'd
like the labels of the role

00:23:49.270 --> 00:23:51.220
is front end and the
stage is production.

00:23:51.220 --> 00:23:53.410
And you can see now all
of the front ends that

00:23:53.410 --> 00:23:56.197
have dotted lines around them
have dropped away, right?

00:23:56.197 --> 00:23:58.030
I put dotted lines
around them to illustrate

00:23:58.030 --> 00:23:59.952
where they had been
in the previous query.

00:23:59.952 --> 00:24:01.660
And the only front
ends that are left now

00:24:01.660 --> 00:24:04.810
are the front ends that match
both the role being front end

00:24:04.810 --> 00:24:06.520
and the stage being production.

00:24:06.520 --> 00:24:08.140
And so now I have a
really elegant way

00:24:08.140 --> 00:24:09.530
that I can slice through.

00:24:09.530 --> 00:24:13.070
I can say, role is development
cluster, user is Brendan.

00:24:13.070 --> 00:24:14.890
I can slice through
all of the things

00:24:14.890 --> 00:24:17.600
that I've scheduled
out onto these machines

00:24:17.600 --> 00:24:20.400
and find exactly the kind of
thing that I'm looking for.

00:24:20.400 --> 00:24:22.400
And again, one thing
that's important to realize

00:24:22.400 --> 00:24:25.160
is that I've stopped
viewing all of my containers

00:24:25.160 --> 00:24:28.360
as things that are on particular
machines or things that

00:24:28.360 --> 00:24:31.110
are running in any
particular place.

00:24:31.110 --> 00:24:33.720
I've really started
to think of my cluster

00:24:33.720 --> 00:24:37.400
as simply being this one giant
resource that a bunch of things

00:24:37.400 --> 00:24:38.490
are running on.

00:24:38.490 --> 00:24:40.640
And I stop really
having to worry or care

00:24:40.640 --> 00:24:42.090
about specific locations.

00:24:42.090 --> 00:24:44.295
And that's a pretty
powerful abstraction.

00:24:44.295 --> 00:24:46.700
All right, but label
queries are nice for you

00:24:46.700 --> 00:24:48.014
UX and for looking at things.

00:24:48.014 --> 00:24:50.055
But they're really nice
when you start using them

00:24:50.055 --> 00:24:51.854
as building blocks
for other services.

00:24:51.854 --> 00:24:53.520
So one of the very
first things that you

00:24:53.520 --> 00:24:56.200
want to do once you have
a single pod, a single set

00:24:56.200 --> 00:24:59.500
of containers that work well,
is you want to scale it out.

00:24:59.500 --> 00:25:01.520
This is where you've
stopped doing development,

00:25:01.520 --> 00:25:05.087
and now you're moving towards
a production or a beta system.

00:25:05.087 --> 00:25:06.045
You say, you know what?

00:25:06.045 --> 00:25:07.110
That's the thing.

00:25:07.110 --> 00:25:08.800
I want to cut out
10 copies of that.

00:25:08.800 --> 00:25:11.341
I want to have a cookie cutter,
and I want a bunch of copies.

00:25:11.341 --> 00:25:13.440
And we can use labels as
a way of organizing this

00:25:13.440 --> 00:25:17.260
with the notion that we
call a replica controller.

00:25:17.260 --> 00:25:18.850
And so a replica
controller basically

00:25:18.850 --> 00:25:23.030
is the combination of a label
query for identifying what

00:25:23.030 --> 00:25:27.220
containers you want to run, a
template, the cookie cutter,

00:25:27.220 --> 00:25:30.440
if you will, for describing
the thing that you would like

00:25:30.440 --> 00:25:33.080
to cut out, and a
number, which indicates

00:25:33.080 --> 00:25:34.910
how many of that
thing you would like.

00:25:34.910 --> 00:25:37.990
And so for example here, in
this declarative configuration

00:25:37.990 --> 00:25:40.730
of this replica controller,
I have four replicas.

00:25:40.730 --> 00:25:42.820
The template is
elided for space.

00:25:42.820 --> 00:25:44.550
And then, I have a
label query that says,

00:25:44.550 --> 00:25:47.550
and the role is front end
and the stage is production.

00:25:47.550 --> 00:25:49.820
And the reason that the
label query is important

00:25:49.820 --> 00:25:53.510
is because this object that is
responsible for the replication

00:25:53.510 --> 00:25:55.140
is actually an active object.

00:25:55.140 --> 00:25:59.380
It's a live reconciler
that is part of the system.

00:25:59.380 --> 00:26:01.440
It's not an imperative
sort of execution of,

00:26:01.440 --> 00:26:03.427
oh, I'm going to go
and-- it's not a for loop

00:26:03.427 --> 00:26:05.760
that's going to go and create
four of these controllers.

00:26:05.760 --> 00:26:07.440
It's an active
object in the system.

00:26:07.440 --> 00:26:08.660
It's one of these
flight controllers

00:26:08.660 --> 00:26:10.076
that Craig was
referring to that's

00:26:10.076 --> 00:26:13.960
responsible for ensuring that
there are four of these things

00:26:13.960 --> 00:26:14.530
always.

00:26:14.530 --> 00:26:17.500
And so you can think of it
as constantly running a loop.

00:26:17.500 --> 00:26:19.640
And the loop says,
execute label query.

00:26:19.640 --> 00:26:22.680
OK, how many containers
did I get back?

00:26:22.680 --> 00:26:24.680
Ah, I only got three back.

00:26:24.680 --> 00:26:27.060
It says that I should have four.

00:26:27.060 --> 00:26:28.640
Let me create a container.

00:26:28.640 --> 00:26:31.740
OK, now I'll cycle again,
do the label query again.

00:26:31.740 --> 00:26:32.770
Now I have four.

00:26:32.770 --> 00:26:33.600
Great, I have four.

00:26:33.600 --> 00:26:34.970
I won't take any action.

00:26:34.970 --> 00:26:37.930
Do the label query again--
wait a minute, I have five.

00:26:37.930 --> 00:26:39.620
How did that happen?

00:26:39.620 --> 00:26:40.910
Kill one of those containers.

00:26:40.910 --> 00:26:41.977
Ah, now I'm back to four.

00:26:41.977 --> 00:26:44.060
So this is a live object
that lives in the system.

00:26:44.060 --> 00:26:45.980
It means that the
system is self-healing.

00:26:45.980 --> 00:26:48.650
It means that adding properties
like dynamic resizing,

00:26:48.650 --> 00:26:51.000
as we'll see in the demo
later, becomes very, very easy

00:26:51.000 --> 00:26:53.070
and very natural for the system.

00:26:53.070 --> 00:26:57.330
This notion of a reconciler and
of an active controller inside

00:26:57.330 --> 00:26:59.810
of a cluster manager is a
very, very important concept

00:26:59.810 --> 00:27:02.150
that's core to a lot of
what we do at Google.

00:27:02.150 --> 00:27:05.430
So the second thing that
we introduced that lives

00:27:05.430 --> 00:27:08.190
on top of that label query
is the notion of a service.

00:27:08.190 --> 00:27:09.140
Oh, excuse me.

00:27:09.140 --> 00:27:09.600
I'm going to step
through my slides.

00:27:09.600 --> 00:27:12.380
I spoke over my slides-- go
to one, go back to three.

00:27:12.380 --> 00:27:16.270
All right, now we go back
to a service, excuse me.

00:27:16.270 --> 00:27:18.882
So the notion of a service
says, well, you know,

00:27:18.882 --> 00:27:21.090
it's great that I have this
replicated set of things.

00:27:21.090 --> 00:27:25.020
But any real application, any
real application that I build,

00:27:25.020 --> 00:27:26.612
needs to be linked
together, right?

00:27:26.612 --> 00:27:27.820
I don't just have front ends.

00:27:27.820 --> 00:27:29.153
I have front ends and back ends.

00:27:29.153 --> 00:27:31.530
Maybe I have front ends and
back ends and middleware.

00:27:31.530 --> 00:27:34.400
But if I have this replication
controller that is dynamically

00:27:34.400 --> 00:27:37.920
resizing things, I don't want to
have to reconfigure everything.

00:27:37.920 --> 00:27:41.144
If I take the set of back
ends from two to six,

00:27:41.144 --> 00:27:42.810
I don't want to then
have to reconfigure

00:27:42.810 --> 00:27:45.670
my front ends to understand
that there are six back end

00:27:45.670 --> 00:27:47.840
servers now where
there used to be two.

00:27:47.840 --> 00:27:50.030
And so the service
abstraction allows

00:27:50.030 --> 00:27:54.520
you to have a named load
balancer that automatically

00:27:54.520 --> 00:27:59.850
balances load across a label
query, a set of containers.

00:27:59.850 --> 00:28:02.635
And it provides a
single network endpoint

00:28:02.635 --> 00:28:04.100
that your front
ends can talk to.

00:28:04.100 --> 00:28:06.140
And this all happens
automatically inside

00:28:06.140 --> 00:28:07.400
of the Kubernetes system.

00:28:07.400 --> 00:28:10.430
You declare a declarative
representation

00:28:10.430 --> 00:28:12.900
of the service like
this-- back end service.

00:28:12.900 --> 00:28:14.960
I want it to run on port 9000.

00:28:14.960 --> 00:28:16.520
Here's the label query.

00:28:16.520 --> 00:28:20.780
And Kubernetes for you
creates this service endpoint

00:28:20.780 --> 00:28:24.550
on every single host
machine in the cluster

00:28:24.550 --> 00:28:28.010
so that on any machine,
if you access port 9000,

00:28:28.010 --> 00:28:29.610
and you open a
connection, you're

00:28:29.610 --> 00:28:31.570
going to be transparently
load balanced

00:28:31.570 --> 00:28:35.200
to one of the containers
that match this label

00:28:35.200 --> 00:28:36.480
query, all right?

00:28:36.480 --> 00:28:38.820
Again, the organization
of these containers

00:28:38.820 --> 00:28:42.370
means that I can build up
these abstractions where I just

00:28:42.370 --> 00:28:45.720
don't have to care about the
details of my system in places

00:28:45.720 --> 00:28:47.996
where I don't need to.

00:28:47.996 --> 00:28:49.790
All right, so with
that in mind, I

00:28:49.790 --> 00:28:52.953
wanted to give you a brief demo
of the system in operation.

00:28:52.953 --> 00:28:54.780
I'll try not to trip.

00:28:54.780 --> 00:28:57.630
All right, so I'll jump
out of the web browser

00:28:57.630 --> 00:29:00.037
and into my demo over here.

00:29:00.037 --> 00:29:01.949
OK, is that visible?

00:29:01.949 --> 00:29:02.740
Reasonably visible.

00:29:02.740 --> 00:29:06.660
All right, so you may recognize
the fellow looking out at you.

00:29:06.660 --> 00:29:08.790
I have here four containers.

00:29:08.790 --> 00:29:12.380
This is replication controller
running four containers.

00:29:12.380 --> 00:29:14.060
They're simple image servers.

00:29:14.060 --> 00:29:17.200
They're serving out
a very simple image.

00:29:17.200 --> 00:29:19.460
You can see this is
the container ID.

00:29:19.460 --> 00:29:22.250
So the container ID is
different for each one.

00:29:22.250 --> 00:29:26.125
And this is the IP address that
they happen to be running on.

00:29:26.125 --> 00:29:28.250
And so the very first thing
I wanted to demonstrate

00:29:28.250 --> 00:29:30.270
is some of the
self-healing properties.

00:29:30.270 --> 00:29:33.930
And so I'm going
to go over here,

00:29:33.930 --> 00:29:40.400
and I'm going to SSH
into one of the machines.

00:29:40.400 --> 00:29:42.470
Oops, that's not going to work.

00:29:42.470 --> 00:29:46.270
[INAUDIBLE] SSH into
one of the machines.

00:29:49.115 --> 00:29:54.680
All right, and so if
I do psuedo-docker ps,

00:29:54.680 --> 00:29:57.680
we can see that there's actually
this engine x web server that's

00:29:57.680 --> 00:29:59.780
running that's
serving up the data.

00:29:59.780 --> 00:30:01.280
All right, so I'm
going to move this

00:30:01.280 --> 00:30:03.020
aside so that you
can actually see.

00:30:03.020 --> 00:30:04.910
Because this effect is
actually-- the health

00:30:04.910 --> 00:30:06.201
checked restart is quite quick.

00:30:06.201 --> 00:30:09.170
And so it's somewhat
difficult to actually see it.

00:30:09.170 --> 00:30:11.420
And we may in fact not see it.

00:30:11.420 --> 00:30:16.820
I will stop but note what
the Docker container ID is.

00:30:16.820 --> 00:30:19.940
I'm going to stop that
container simulating a failure.

00:30:19.940 --> 00:30:23.550
You can see that the image
is no longer being served.

00:30:23.550 --> 00:30:26.710
But the system, the agent
that's running on this VM,

00:30:26.710 --> 00:30:29.902
is going to notice that
that container has stopped.

00:30:29.902 --> 00:30:31.610
And it's going to
restart that container.

00:30:31.610 --> 00:30:33.740
And now the image is
back and being served.

00:30:33.740 --> 00:30:35.780
And if we do that
ps again, you can

00:30:35.780 --> 00:30:37.930
see that we have a
new container here.

00:30:37.930 --> 00:30:39.826
It's only been up
eight seconds now,

00:30:39.826 --> 00:30:41.200
since I killed
the other one that

00:30:41.200 --> 00:30:42.490
had been up for three hours.

00:30:42.490 --> 00:30:44.622
So that kind of health
checking on the node

00:30:44.622 --> 00:30:46.080
means that you
don't have to worry.

00:30:46.080 --> 00:30:49.560
You can simply say, I want
this thing to be running.

00:30:49.560 --> 00:30:51.180
And the cluster
manager will take

00:30:51.180 --> 00:30:53.859
care of ensuring that
it actually is running.

00:30:53.859 --> 00:30:56.400
So the next thing that you might
want to do along these lines

00:30:56.400 --> 00:30:58.040
is you might want
to actually resize.

00:30:58.040 --> 00:31:02.110
I'll move this up again so
there's better visibility.

00:31:02.110 --> 00:31:05.060
You may want to actually resize.

00:31:05.060 --> 00:31:08.295
Four of Craig is just
a little bit too scary.

00:31:08.295 --> 00:31:09.670
And so I'm going
to go over here.

00:31:09.670 --> 00:31:12.190
And I can actually say, cloud.

00:31:12.190 --> 00:31:13.560
This is the tool.

00:31:13.560 --> 00:31:17.600
So it's worth mentioning
Kubernetes has a RESTful HTTP

00:31:17.600 --> 00:31:18.430
API.

00:31:18.430 --> 00:31:20.750
So you can write
arbitrary clients

00:31:20.750 --> 00:31:24.210
that communicate with this
API, create new containers,

00:31:24.210 --> 00:31:27.750
create new services, create
replication controllers,

00:31:27.750 --> 00:31:29.120
resize replication controllers.

00:31:29.120 --> 00:31:30.690
It ships with a
simple command line

00:31:30.690 --> 00:31:32.190
tool that allows you
to do these things,

00:31:32.190 --> 00:31:34.273
but you're free to build
any kind of orchestration

00:31:34.273 --> 00:31:34.940
on top of it.

00:31:34.940 --> 00:31:40.441
So I'm going to say, cloud
config resize data cont-- ah,

00:31:40.441 --> 00:31:43.130
if I can type-- controller 2.

00:31:45.644 --> 00:31:47.060
And so now it's
resized this down.

00:31:47.060 --> 00:31:49.150
It's actually killed
two containers there.

00:31:49.150 --> 00:31:52.470
They're no longer running
on those machines.

00:31:52.470 --> 00:31:54.464
Now I only have two
of these images.

00:31:54.464 --> 00:31:56.130
Well, maybe that was
a little bit harsh,

00:31:56.130 --> 00:31:58.980
and we actually would prefer
to have three of Craig.

00:31:58.980 --> 00:32:01.910
So we will resize
back up to three.

00:32:01.910 --> 00:32:04.480
And here now we're going to
see a little bit of a blip

00:32:04.480 --> 00:32:07.640
while that container--
killing is fast.

00:32:07.640 --> 00:32:09.980
Recreating is slightly
slower, because it's

00:32:09.980 --> 00:32:11.607
very easy to stop a process.

00:32:11.607 --> 00:32:13.190
Actually starting
the process, getting

00:32:13.190 --> 00:32:15.770
engine x ready to serve, takes
a few seconds as you saw.

00:32:15.770 --> 00:32:20.640
So now we have three
containers running inside

00:32:20.640 --> 00:32:24.170
of Kubernetes all scheduled
onto specific machines.

00:32:24.170 --> 00:32:26.855
But again, we don't really care
about that particularly much.

00:32:26.855 --> 00:32:28.230
Now, the other
kind of life cycle

00:32:28.230 --> 00:32:31.030
that you might want to do,
in addition to resizing,

00:32:31.030 --> 00:32:33.750
is actually editing the kind
of thing that you're serving.

00:32:33.750 --> 00:32:37.731
So I wanted to give you a little
bit of an illustration of what

00:32:37.731 --> 00:32:39.480
work flow does look
like inside of Google,

00:32:39.480 --> 00:32:42.530
and workflow might look like
for you out using Kubernetes.

00:32:42.530 --> 00:32:45.850
So I have in this directory
the Docker image, the container

00:32:45.850 --> 00:32:47.500
that's running on
these machines.

00:32:47.500 --> 00:32:50.490
I'm going to open
up the data file.

00:32:50.490 --> 00:32:53.130
And Craig-- a little scary.

00:32:53.130 --> 00:32:57.720
So we'll replace this with
Brendan, nice, friendly

00:32:57.720 --> 00:32:59.910
developer, not product guy.

00:32:59.910 --> 00:33:04.400
So at this point, I
can say Docker bill -t

00:33:04.400 --> 00:33:08.130
Brendan [INAUDIBLE] data dot.

00:33:08.130 --> 00:33:10.410
So this is building
up my Docker image.

00:33:10.410 --> 00:33:15.426
I'm going to push
that, push [INAUDIBLE].

00:33:18.740 --> 00:33:21.130
OK, one of the nice things
about this decoupling

00:33:21.130 --> 00:33:23.730
of the container image
from where the container is

00:33:23.730 --> 00:33:26.890
executing is that this
activity of actually updating

00:33:26.890 --> 00:33:31.270
my container doesn't actually
change the running service.

00:33:31.270 --> 00:33:34.890
So as you see the image
slowly being pushed up,

00:33:34.890 --> 00:33:36.990
you won't see any changes
in the running service.

00:33:36.990 --> 00:33:40.007
And indeed, even when
the push is completed,

00:33:40.007 --> 00:33:42.090
there won't be any changes
in the running service.

00:33:42.090 --> 00:33:45.110
I've separated out
application update

00:33:45.110 --> 00:33:47.850
from running service update.

00:33:47.850 --> 00:33:51.740
So application update
is this atomic thing

00:33:51.740 --> 00:33:55.090
that happens with me pushing
a new package somewhere.

00:33:55.090 --> 00:33:58.320
Service update becomes
a new atomic thing

00:33:58.320 --> 00:34:03.220
that has to do with running that
new container on my cluster.

00:34:03.220 --> 00:34:05.770
And by partitioning
them in these ways,

00:34:05.770 --> 00:34:07.830
I have much more
reliability in both.

00:34:07.830 --> 00:34:10.659
If the application upload
fails, that's fine.

00:34:10.659 --> 00:34:11.600
I can redo it.

00:34:11.600 --> 00:34:14.070
If the cluster update
fails, it's very easy for me

00:34:14.070 --> 00:34:18.060
to roll back to an old version
of the same application.

00:34:18.060 --> 00:34:20.320
I don't end up in states
where I'm sort of partially

00:34:20.320 --> 00:34:22.250
installed, and it's
impossible to get back,

00:34:22.250 --> 00:34:24.900
and I may not even get a clear
signal about whether or not

00:34:24.900 --> 00:34:25.590
I succeeded.

00:34:25.590 --> 00:34:29.170
All right, so my image
has been updated.

00:34:29.170 --> 00:34:31.090
I'm going to go over here.

00:34:31.090 --> 00:34:33.679
And I'm going to say--
clear so everyone can see.

00:34:33.679 --> 00:34:39.060
I'm going to say, cloud
config.sh rolling update,

00:34:39.060 --> 00:34:48.469
let's say, -u 15 seconds
rolling [INAUDIBLE].

00:34:48.469 --> 00:34:50.969
And so what this is saying is
I want to do a rolling update.

00:34:50.969 --> 00:34:53.940
A rolling update means
one container at a time.

00:34:53.940 --> 00:34:57.770
I'll bring it down, bring
it back up with the update.

00:34:57.770 --> 00:35:01.810
I'm using an inter-restart
period of 15 seconds--

00:35:01.810 --> 00:35:03.820
way, way faster than
I would recommend

00:35:03.820 --> 00:35:06.250
anybody doing in production.

00:35:06.250 --> 00:35:08.750
But I don't want to have you
sitting around for five minutes

00:35:08.750 --> 00:35:10.500
while we restart containers.

00:35:10.500 --> 00:35:11.500
So we'll start this off.

00:35:11.500 --> 00:35:13.420
And what you're going
to see is as this

00:35:13.420 --> 00:35:16.364
runs, that container went down.

00:35:16.364 --> 00:35:17.780
It's going to be
starting back up.

00:35:17.780 --> 00:35:20.670
I'll go back.

00:35:20.670 --> 00:35:23.410
And with luck, as
it starts back up,

00:35:23.410 --> 00:35:26.300
there'll be a friendlier
face to be seen.

00:35:26.300 --> 00:35:29.914
We'll keep our fingers crossed.

00:35:29.914 --> 00:35:31.580
The tension is starting
to kill me here.

00:35:35.150 --> 00:35:38.225
It's actually having
to pull the image.

00:35:38.225 --> 00:35:39.574
Yay, there I am.

00:35:39.574 --> 00:35:41.740
The previous restarts didn't
have to pull the image.

00:35:41.740 --> 00:35:43.130
It was already on the machine.

00:35:43.130 --> 00:35:45.490
These machines actually have to
pull new data down from Docker.

00:35:45.490 --> 00:35:46.948
So there's a little
bit of a second

00:35:46.948 --> 00:35:51.110
while we pull the
image off the network.

00:35:51.110 --> 00:35:55.760
So that last one should finish
booting up with any luck.

00:35:58.320 --> 00:36:00.270
The update is finished
at this point.

00:36:00.270 --> 00:36:05.340
And in a few seconds,
the update will complete.

00:36:05.340 --> 00:36:08.500
So that's really a demo of
some of the flexibility.

00:36:08.500 --> 00:36:10.770
When you stop thinking
about virtual machines,

00:36:10.770 --> 00:36:12.900
you start thinking
about containers.

00:36:12.900 --> 00:36:15.760
You start thinking about
scheduling containers

00:36:15.760 --> 00:36:19.100
and scheduling work out
onto this homogeneous pool

00:36:19.100 --> 00:36:23.080
of resources where the machines
really disappear and you start

00:36:23.080 --> 00:36:26.090
just thinking in terms of
CPU, memory, and the software

00:36:26.090 --> 00:36:27.370
that I want to run.

00:36:27.370 --> 00:36:30.190
And you add on top of it
some management concepts

00:36:30.190 --> 00:36:33.140
that provide the right kind of
abstractions for both the life

00:36:33.140 --> 00:36:34.970
cycle things you do
in your application,

00:36:34.970 --> 00:36:37.410
as well as the ways
that make linking pieces

00:36:37.410 --> 00:36:41.257
of your application
both decoupled and easy.

00:36:41.257 --> 00:36:43.340
You start being able to
build applications the way

00:36:43.340 --> 00:36:45.256
that we've built
applications inside of Google

00:36:45.256 --> 00:36:47.590
for many, many years.

00:36:47.590 --> 00:36:51.920
And so with that, I'll jump
back into the presentation

00:36:51.920 --> 00:36:54.879
and hope that I grab
the right clicker.

00:36:54.879 --> 00:36:57.420
All right, I wanted to give a
little bit of an example of how

00:36:57.420 --> 00:36:59.378
you might build a more
complicated application.

00:36:59.378 --> 00:37:03.010
That application was really
just a single container.

00:37:03.010 --> 00:37:05.240
Here's an example of a
more complicated guest book

00:37:05.240 --> 00:37:08.890
that you can find on
the Kubernetes GitHub.

00:37:08.890 --> 00:37:10.790
And in this case, we
have three front ends

00:37:10.790 --> 00:37:13.120
controlled by a front end
replica controller talking

00:37:13.120 --> 00:37:15.990
to a service that's defined as
a Redis slave service being read

00:37:15.990 --> 00:37:20.357
slaves talking to a replicated
set of Redis slaves,

00:37:20.357 --> 00:37:21.940
talking to a master
service that lives

00:37:21.940 --> 00:37:23.644
on top of a single master.

00:37:23.644 --> 00:37:25.810
So this is just an example
of how you might build up

00:37:25.810 --> 00:37:28.800
a more complex tier
of applications.

00:37:28.800 --> 00:37:30.940
All right, so I
just wanted to end

00:37:30.940 --> 00:37:33.060
by saying we've thought
a lot about containers

00:37:33.060 --> 00:37:35.730
and how you build and manage
containers and cluster

00:37:35.730 --> 00:37:37.670
management systems
over last 10 years.

00:37:37.670 --> 00:37:42.120
I'm super excited to launch
this open source project out

00:37:42.120 --> 00:37:44.240
to the developers'
community in general,

00:37:44.240 --> 00:37:47.420
and being able to take
the step forward together

00:37:47.420 --> 00:37:50.070
with everyone else for how
we're going to manage containers

00:37:50.070 --> 00:37:51.440
for the next 10 years.

00:37:51.440 --> 00:37:52.190
Thanks very much.

00:37:52.190 --> 00:37:55.076
[AUDIENCE APPLAUSE]

00:37:58.320 --> 00:38:00.860
BRENDAN BURNS: Some links.

00:38:00.860 --> 00:38:04.240
I wanted to also add as
a gift to every one-- you

00:38:04.240 --> 00:38:05.710
may have seen this
already-- you've

00:38:05.710 --> 00:38:09.320
got a $500 credit for the
Google Cloud Platform.

00:38:09.320 --> 00:38:13.300
Go and use it to build out
your best and brightest ideas.

00:38:13.300 --> 00:38:13.800
Thanks.

00:38:16.560 --> 00:38:19.759
And I think we have
about 6 and 1/2 minutes

00:38:19.759 --> 00:38:21.050
left for questions and answers.

00:38:21.050 --> 00:38:23.050
So I'll bring Craig
back up and we can--

00:38:23.050 --> 00:38:24.365
AUDIENCE: [INAUDIBLE]

00:38:24.365 --> 00:38:25.240
BRENDAN BURNS: Sorry.

00:38:25.240 --> 00:38:26.115
AUDIENCE: [INAUDIBLE]

00:38:28.047 --> 00:38:29.505
BRENDAN BURNS: All
right, yes, I'll

00:38:29.505 --> 00:38:31.572
leave you the important thing.

00:38:31.572 --> 00:38:34.030
I don't know, pictures of me
might be worth more than $500?

00:38:34.030 --> 00:38:35.276
No, probably not.

00:38:35.276 --> 00:38:36.040
That's to bad.

00:38:36.040 --> 00:38:37.920
All right, so if there
are any questions

00:38:37.920 --> 00:38:41.090
that we can answer-- yes?

00:38:41.090 --> 00:38:43.680
AUDIENCE: I would like to
know if you can manage quota

00:38:43.680 --> 00:38:48.220
assigned to a container when
you use a container [INAUDIBLE],

00:38:48.220 --> 00:38:50.770
I mean if you can assign
some limited memory

00:38:50.770 --> 00:38:54.211
or CPU to various containers
you deploy side by side.

00:38:54.211 --> 00:38:55.960
BRENDAN BURNS: So
currently, the container

00:38:55.960 --> 00:38:57.860
manifest does not
allow you to do that.

00:38:57.860 --> 00:39:01.290
But it's an evolving API
and an evolving standard.

00:39:01.290 --> 00:39:05.057
And so we will definitely be
building towards doing that.

00:39:05.057 --> 00:39:06.890
And you could even send
us the poll request.

00:39:09.689 --> 00:39:10.230
AUDIENCE: Hi.

00:39:10.230 --> 00:39:11.146
My name's [INAUDIBLE].

00:39:11.146 --> 00:39:13.020
And I would like
to know if I can

00:39:13.020 --> 00:39:16.230
use Kubernetes in my
own private cloud.

00:39:16.230 --> 00:39:17.881
BRENDAN BURNS: Yes, absolutely.

00:39:17.881 --> 00:39:19.880
We want to make sure that
it runs really, really

00:39:19.880 --> 00:39:21.650
well in the Google
Cloud Platform.

00:39:21.650 --> 00:39:23.900
And we have developed it on
the Google Cloud Platform.

00:39:23.900 --> 00:39:26.410
So you'll find that that's
the most seamless experience.

00:39:26.410 --> 00:39:30.620
But we have both a local
development environment

00:39:30.620 --> 00:39:33.634
that will run on your machine,
a single cluster if you will,

00:39:33.634 --> 00:39:35.050
a single node
cluster if you will.

00:39:35.050 --> 00:39:36.600
And we've also had
people deploy it

00:39:36.600 --> 00:39:38.840
onto their own machines as well.

00:39:38.840 --> 00:39:43.530
AUDIENCE: And what
virtualization technologies

00:39:43.530 --> 00:39:44.285
do you support?

00:39:44.285 --> 00:39:45.410
BRENDAN BURNS: Sorry, what?

00:39:45.410 --> 00:39:47.190
AUDIENCE: Do you
support VMware, KVM,

00:39:47.190 --> 00:39:49.490
what virtualization
technologies?

00:39:49.490 --> 00:39:52.660
BRENDAN BURNS: So we actually
do not use virtualization.

00:39:52.660 --> 00:39:56.680
If you happen to deploy it
onto a set of virtual machines,

00:39:56.680 --> 00:39:58.320
then it will work.

00:39:58.320 --> 00:40:01.310
But if you deploy it onto bare
metal, it will work as well.

00:40:01.310 --> 00:40:03.560
So the underlying
container technology

00:40:03.560 --> 00:40:05.420
is the Docker
container technology.

00:40:05.420 --> 00:40:07.330
And there's a number
of different back ends

00:40:07.330 --> 00:40:10.350
that could be used
for that container.

00:40:10.350 --> 00:40:12.270
Did that help [INAUDIBLE]?

00:40:12.270 --> 00:40:16.659
AUDIENCE: Do Kubernetes spin up
virtual machines automatically?

00:40:16.659 --> 00:40:18.700
BRENDAN BURNS: The scripts
that we have currently

00:40:18.700 --> 00:40:21.970
will spin up machines for
you in Compute Engine.

00:40:21.970 --> 00:40:24.340
But there aren't
any scripts that

00:40:24.340 --> 00:40:27.510
spin them up for
other platforms.

00:40:27.510 --> 00:40:29.630
Again, because it's an
open source project,

00:40:29.630 --> 00:40:31.194
we very much welcome
contributions

00:40:31.194 --> 00:40:33.610
from other people who want to
be able to make it work on--

00:40:33.610 --> 00:40:34.320
CRAIG MCLUCKIE:
And we are working

00:40:34.320 --> 00:40:35.762
with the broader community.

00:40:35.762 --> 00:40:37.220
You'll see over
the next few weeks,

00:40:37.220 --> 00:40:39.992
I think support for other
providers will spring up.

00:40:39.992 --> 00:40:41.450
Because the community
demands that.

00:40:41.450 --> 00:40:43.310
BRENDAN BURNS:
Right, absolutely.

00:40:43.310 --> 00:40:46.730
AUDIENCE: Hi, my question is
related to container optimized

00:40:46.730 --> 00:40:49.070
VMs versus plain VMs.

00:40:49.070 --> 00:40:52.750
So when I actually
spin up a normal JCVM,

00:40:52.750 --> 00:40:55.400
nothing stops me from
installing Docker and using

00:40:55.400 --> 00:40:59.420
Docker Run to actually launch
a container, versus a container

00:40:59.420 --> 00:41:00.910
optimized VM where
I can actually

00:41:00.910 --> 00:41:03.660
use a [INAUDIBLE]
file, which is going

00:41:03.660 --> 00:41:06.700
to be the metadata for
my Docker container.

00:41:06.700 --> 00:41:09.800
So is the difference primarily
in the YAML file acting

00:41:09.800 --> 00:41:15.310
as a start up script, or do
you do anything beyond that?

00:41:15.310 --> 00:41:17.560
So is it just a convenience
that you provide

00:41:17.560 --> 00:41:19.580
to the agent on the
start up script,

00:41:19.580 --> 00:41:23.060
or does it have further
optimization within the VM?

00:41:24.974 --> 00:41:26.640
BRENDAN BURNS:
Convenience is a big part

00:41:26.640 --> 00:41:28.056
it, actually, to
be honest, right?

00:41:28.056 --> 00:41:29.660
We definitely want
to make people

00:41:29.660 --> 00:41:31.620
think about running
containers not running VMs.

00:41:31.620 --> 00:41:35.235
And so if you can simply
start thinking about the thing

00:41:35.235 --> 00:41:36.970
that you're running
as being a container,

00:41:36.970 --> 00:41:37.920
I think that's a good thing.

00:41:37.920 --> 00:41:38.600
And that's a huge thing.

00:41:38.600 --> 00:41:40.100
But there's also
a lot of software

00:41:40.100 --> 00:41:42.220
that we've installed
onto that VM that

00:41:42.220 --> 00:41:44.840
make running a container better.

00:41:44.840 --> 00:41:47.060
And that includes
things like cAdviser,

00:41:47.060 --> 00:41:50.690
which is a program that some
Google engineers launched

00:41:50.690 --> 00:41:53.160
at DockerCon also
about 10 days ago,

00:41:53.160 --> 00:41:55.750
which is a way to get really
rich statistics about what's

00:41:55.750 --> 00:41:57.580
going on inside
of your container.

00:41:57.580 --> 00:42:00.067
That includes agent,
the on board agent

00:42:00.067 --> 00:42:01.650
that's responsible
for health checking

00:42:01.650 --> 00:42:04.860
and automatic restarting
of the container.

00:42:04.860 --> 00:42:06.470
There's nothing
that prevents you

00:42:06.470 --> 00:42:08.570
from installing these
things yourself.

00:42:08.570 --> 00:42:12.400
And so you could build an analog
of the container optimized

00:42:12.400 --> 00:42:15.695
VM manually yourself
if you wanted to.

00:42:15.695 --> 00:42:17.820
But we're going to curate
this thing going forward.

00:42:17.820 --> 00:42:20.410
And really, we're going to
do our best to make sure

00:42:20.410 --> 00:42:23.520
that that VM is the best
experience you can have

00:42:23.520 --> 00:42:26.840
for running containers on
the Google Cloud Platform.

00:42:26.840 --> 00:42:29.590
AUDIENCE: So without
Kubernetes, the container

00:42:29.590 --> 00:42:33.060
optimized VMs are basically
plain vanilla JCVMs with agents

00:42:33.060 --> 00:42:34.805
and some extra start up skips?

00:42:34.805 --> 00:42:37.657
BRENDAN BURNS: That's correct.

00:42:37.657 --> 00:42:39.990
They're really static VMs
without the cluster management

00:42:39.990 --> 00:42:41.092
layer on top of them.

00:42:41.092 --> 00:42:43.050
CRAIG MCLUCKIE: And we'll
produce a nice tuning

00:42:43.050 --> 00:42:45.340
experience so that
when you actually want

00:42:45.340 --> 00:42:47.440
to just go from the
command line or from the UI

00:42:47.440 --> 00:42:48.939
and want to get a
container running,

00:42:48.939 --> 00:42:50.610
it'll be a very
slick experience.

00:42:50.610 --> 00:42:51.651
AUDIENCE: Final question.

00:42:51.651 --> 00:42:54.325
Will Kubernetes show up on
the developer console any day?

00:42:54.325 --> 00:42:55.950
BRENDAN BURNS: It's
available on GitHub

00:42:55.950 --> 00:42:57.410
right now as something
you can install yourself.

00:42:57.410 --> 00:42:58.910
AUDIENCE: No, the
developer console,

00:42:58.910 --> 00:43:00.620
the UI to deploy and
manage containers.

00:43:00.620 --> 00:43:03.520
CRAIG MCLUCKIE:
So we can't signal

00:43:03.520 --> 00:43:05.130
where we're going exactly.

00:43:05.130 --> 00:43:06.970
But it would be
reasonable to expect

00:43:06.970 --> 00:43:10.470
that we would have a
hosted version of this

00:43:10.470 --> 00:43:11.790
in the not too distant future.

00:43:11.790 --> 00:43:13.998
It's actually worth mentioning
that what we're really

00:43:13.998 --> 00:43:16.330
looking to do here is
to engage the community.

00:43:16.330 --> 00:43:18.580
You can tell where we're
going with this stuff, right?

00:43:18.580 --> 00:43:20.996
This is the way we've been
running our internal workloads.

00:43:20.996 --> 00:43:22.970
And by reaching out
with Kubernetes,

00:43:22.970 --> 00:43:25.750
we're putting an API
out for conversation.

00:43:25.750 --> 00:43:28.470
Help us shape it to
be the thing you want,

00:43:28.470 --> 00:43:31.360
and we'll provide the
fully hosted version of it

00:43:31.360 --> 00:43:34.312
that's running in our framework.

00:43:34.312 --> 00:43:36.470
That's ultimately where
we want to go with this.

00:43:36.470 --> 00:43:37.303
AUDIENCE: Thank you.

00:43:39.622 --> 00:43:42.520
AUDIENCE: Hi.

00:43:42.520 --> 00:43:44.860
So if I understood
this correctly,

00:43:44.860 --> 00:43:48.630
every container speaks
only to other containers

00:43:48.630 --> 00:43:50.980
via a service abstraction.

00:43:50.980 --> 00:43:56.980
So it has no knowledge of
the other containers running.

00:43:56.980 --> 00:43:58.740
And since it is only
talking to a service,

00:43:58.740 --> 00:44:01.900
you can scale it out.

00:44:01.900 --> 00:44:04.620
Now, my question
is this only works

00:44:04.620 --> 00:44:08.650
if the individual containers
talk to other services

00:44:08.650 --> 00:44:09.740
but are stateless.

00:44:09.740 --> 00:44:12.670
What happens if you
went onto data sharding,

00:44:12.670 --> 00:44:15.560
for example, in
which case you would

00:44:15.560 --> 00:44:18.920
need to speak to a
specific container

00:44:18.920 --> 00:44:21.300
to access a given shard?

00:44:21.300 --> 00:44:23.880
So do you have a zoo
keeper like mechanism,

00:44:23.880 --> 00:44:25.617
or how do you manage this?

00:44:25.617 --> 00:44:26.450
BRENDAN BURNS: Sure.

00:44:26.450 --> 00:44:29.120
So just a little bit
of a clarification,

00:44:29.120 --> 00:44:32.700
there's nothing that precludes a
container from talking directly

00:44:32.700 --> 00:44:34.330
to another container.

00:44:34.330 --> 00:44:35.850
And indeed you could
talk to the API

00:44:35.850 --> 00:44:38.391
and introspect it and figure
out what containers are running,

00:44:38.391 --> 00:44:41.260
or you could hard code some
sort of configuration in.

00:44:41.260 --> 00:44:43.680
I think that we think of
service as being convenient ways

00:44:43.680 --> 00:44:44.580
to link things together.

00:44:44.580 --> 00:44:46.413
But they're definitely
not the exclusive way

00:44:46.413 --> 00:44:47.850
to link things together.

00:44:47.850 --> 00:44:49.516
I guess the other
thing that I would say

00:44:49.516 --> 00:44:51.300
is it's come up
in other contexts

00:44:51.300 --> 00:44:53.910
inside of the community
about providing

00:44:53.910 --> 00:44:56.110
richer semantics
for that service.

00:44:56.110 --> 00:44:59.720
So right now, that service is
a round robin load balancer.

00:44:59.720 --> 00:45:02.680
But you could imagine being able
to define a service type that

00:45:02.680 --> 00:45:06.690
is a master elected balancer
that only ever takes

00:45:06.690 --> 00:45:10.107
your traffic to the current
master, or a sharded.

00:45:10.107 --> 00:45:11.190
Sharding becomes trickier.

00:45:11.190 --> 00:45:14.120
Because you have to have some
notion of what the sharding

00:45:14.120 --> 00:45:16.350
function is, right?

00:45:16.350 --> 00:45:19.010
And so that becomes a trickier
concept to put in there.

00:45:19.010 --> 00:45:21.787
But you can imagine these
primitives becoming richer

00:45:21.787 --> 00:45:22.370
in the future.

00:45:22.370 --> 00:45:25.174
Or you could just
simply bake your own.

00:45:25.174 --> 00:45:25.800
AUDIENCE: OK.

00:45:25.800 --> 00:45:26.300
Thank you.

00:45:28.629 --> 00:45:29.170
AUDIENCE: Hi.

00:45:29.170 --> 00:45:33.730
Sort of building along that,
we built our own similar kind

00:45:33.730 --> 00:45:36.810
of concept for deployment
where we tried to abstract away

00:45:36.810 --> 00:45:41.050
all of the messiness of what
it was you were running on.

00:45:41.050 --> 00:45:43.760
And we started out with
a declarative syntax.

00:45:43.760 --> 00:45:47.830
But it rapidly became
clear that if we

00:45:47.830 --> 00:45:51.430
wanted to take advantage
of existing software,

00:45:51.430 --> 00:45:55.565
they had their own peculiar
workflows and configuration

00:45:55.565 --> 00:45:58.280
and everything, for
example like Mongo.

00:45:58.280 --> 00:46:01.241
Trying to containerize
Mongo, we ended up

00:46:01.241 --> 00:46:02.740
going with an
imperative syntax just

00:46:02.740 --> 00:46:08.070
because if you've got multiple
shards with their own master,

00:46:08.070 --> 00:46:11.630
their own triplets of
voting rights and things

00:46:11.630 --> 00:46:14.570
like that, it gets to be
a fairly complicated dance

00:46:14.570 --> 00:46:16.654
to get it set up.

00:46:16.654 --> 00:46:18.820
So sort of along the lines
of the previous question,

00:46:18.820 --> 00:46:21.070
is there anything
built in for sort

00:46:21.070 --> 00:46:23.770
of identifying in
an abstract way?

00:46:23.770 --> 00:46:28.270
You kind of had the
idea of roles as labels,

00:46:28.270 --> 00:46:33.230
but like sort of having staged
workflows for, OK, everybody

00:46:33.230 --> 00:46:35.860
needs to get to this state and
then run this set of stuff,

00:46:35.860 --> 00:46:37.320
and then now
everybody's in this.

00:46:37.320 --> 00:46:39.820
Oh, and now you've
advertised yourself as ready,

00:46:39.820 --> 00:46:41.830
so we can add you to
the load balancer.

00:46:41.830 --> 00:46:43.330
Is there anything
along those lines,

00:46:43.330 --> 00:46:45.514
or are you heading
in that direction?

00:46:45.514 --> 00:46:46.930
BRENDAN BURNS: I
guess I would say

00:46:46.930 --> 00:46:50.592
that if we were to build
something like that,

00:46:50.592 --> 00:46:52.800
I would like to see it as
something that lived on top

00:46:52.800 --> 00:46:54.540
of this API rather
than being something

00:46:54.540 --> 00:46:56.790
that existed within this API.

00:46:56.790 --> 00:47:01.620
I think that I could imagine
some degree of orchestration

00:47:01.620 --> 00:47:04.120
within a pod where you
might say something like,

00:47:04.120 --> 00:47:06.040
this is an
initialization container.

00:47:06.040 --> 00:47:08.440
Please run this initialization
container to completion

00:47:08.440 --> 00:47:10.414
and then start the server.

00:47:10.414 --> 00:47:12.080
But I think when
you're starting to talk

00:47:12.080 --> 00:47:16.510
about really significant
workflow, that kind of system

00:47:16.510 --> 00:47:18.920
is probably better served by
being something that lives

00:47:18.920 --> 00:47:21.494
on top of the scheduling
API rather than apart

00:47:21.494 --> 00:47:22.410
of the scheduling API.

00:47:22.410 --> 00:47:24.535
CRAIG MCLUCKIE: I would
completely agree with that.

00:47:24.535 --> 00:47:26.040
I think the ideal
here is to provide

00:47:26.040 --> 00:47:28.412
a really useful
generic scheduling API,

00:47:28.412 --> 00:47:30.870
and then provide a framework
so you can create abstractions

00:47:30.870 --> 00:47:31.470
on it.

00:47:31.470 --> 00:47:34.060
So you'd be able to identify
something within that,

00:47:34.060 --> 00:47:36.490
get a channel to that,
communicate with that, in a way

00:47:36.490 --> 00:47:38.060
that makes sense to you.

00:47:38.060 --> 00:47:40.240
But that does need to be a
strict abstraction on top

00:47:40.240 --> 00:47:41.320
of the system.

00:47:41.320 --> 00:47:42.240
That's exactly right.

00:47:46.140 --> 00:47:48.670
AUDIENCE: It sounds like
the container optimized

00:47:48.670 --> 00:47:51.310
VM has lot of
similarities with CoreOS.

00:47:51.310 --> 00:47:53.700
And they strive to be
in an ideal environment

00:47:53.700 --> 00:47:55.070
for containers to run.

00:47:55.070 --> 00:47:57.486
Can you speak to some of the
differences between those two

00:47:57.486 --> 00:47:59.575
projects, or advantages
and disadvantages?

00:47:59.575 --> 00:48:01.200
BRENDAN BURNS: I
think philosophically,

00:48:01.200 --> 00:48:03.970
they're definitely very similar.

00:48:03.970 --> 00:48:09.770
They're machine images that are
optimized to run containers.

00:48:09.770 --> 00:48:12.390
I think there's some
stuff like cAdviser that

00:48:12.390 --> 00:48:13.970
isn't present on
CoreOS right now.

00:48:13.970 --> 00:48:15.460
Maybe it will be.

00:48:15.460 --> 00:48:17.690
And again, I think that
this is a place where

00:48:17.690 --> 00:48:19.356
one of the reasons
for getting out there

00:48:19.356 --> 00:48:22.420
into the community with
an open version of this

00:48:22.420 --> 00:48:24.380
is to really engage with
those sorts of people

00:48:24.380 --> 00:48:27.330
and see if there's a consensus
around what the node image

00:48:27.330 --> 00:48:30.250
should be, see if there's
a consensus around what

00:48:30.250 --> 00:48:32.940
the declarative syntax or
scheduling tasks should be.

00:48:32.940 --> 00:48:36.950
And if we reach a place where
there's a POSIX standard

00:48:36.950 --> 00:48:39.280
or whatever that happens
to be for what a container

00:48:39.280 --> 00:48:42.180
machine looks like, I think
that's a great place to get to.

00:48:42.180 --> 00:48:44.260
AUDIENCE: So you would
see a convergence.

00:48:44.260 --> 00:48:47.010
CRAIG MCLUCKIE: Let me just
sort of step back a little bit.

00:48:47.010 --> 00:48:47.950
I completely agree with Brendan.

00:48:47.950 --> 00:48:49.658
But the thing about
what we're doing here

00:48:49.658 --> 00:48:51.350
is a pattern that
we want to engage

00:48:51.350 --> 00:48:53.040
the community around
a conversation on.

00:48:53.040 --> 00:48:55.870
So we will offer up a
container optimized VM.

00:48:55.870 --> 00:48:58.060
We fully expect a lot
of other providers

00:48:58.060 --> 00:49:01.240
to provide the self same.

00:49:01.240 --> 00:49:04.239
You could expect the regular
person to come up with that.

00:49:04.239 --> 00:49:06.030
We want to engage the
open source community

00:49:06.030 --> 00:49:08.529
in a conversation around what
the right set of abstractions,

00:49:08.529 --> 00:49:10.190
what the right set
of interfaces, are.

00:49:10.190 --> 00:49:12.523
And we want to make sure we're
open and not opinionated.

00:49:12.523 --> 00:49:14.030
So we love the guys from CoreOS.

00:49:14.030 --> 00:49:15.870
We love the guys from Docker.

00:49:15.870 --> 00:49:17.370
We're spending a
lot of time working

00:49:17.370 --> 00:49:19.520
to bring our expertise
to operationalize it.

00:49:19.520 --> 00:49:21.770
And what we're hoping
to do with Kubernetes,

00:49:21.770 --> 00:49:24.270
and with the container VMs,
is to start the dialogue

00:49:24.270 --> 00:49:25.590
and figure out what's great.

00:49:25.590 --> 00:49:26.860
Maybe they'll take
some of our patterns.

00:49:26.860 --> 00:49:27.660
Maybe we'll take some of theirs.

00:49:27.660 --> 00:49:29.270
But it's just a
great starting point.

00:49:29.270 --> 00:49:29.840
BRENDAN BURNS: I
guess I would also

00:49:29.840 --> 00:49:31.406
say that I think
that CoreOS is--

00:49:31.406 --> 00:49:32.530
and I'll let people finish.

00:49:32.530 --> 00:49:36.860
But CoreOS also basically uses
systemd as their abstraction

00:49:36.860 --> 00:49:38.570
layer on their machines.

00:49:38.570 --> 00:49:41.720
And so it's less container
introspectable at some level.

00:49:41.720 --> 00:49:43.820
You can't really walk
up to a CoreOS machine

00:49:43.820 --> 00:49:47.050
and say, what are the Docker
containers that you're running?

00:49:47.050 --> 00:49:48.550
You say, what are
the systemd units,

00:49:48.550 --> 00:49:50.060
and then extract from
the command line,

00:49:50.060 --> 00:49:51.976
oh, here's the Docker
things that I'm running.

00:49:51.976 --> 00:49:55.746
I think we wanted to take
a more declarative approach

00:49:55.746 --> 00:49:57.370
to the introspection
as well and really

00:49:57.370 --> 00:50:00.295
be able to ask for concrete
information from the machine.

00:50:00.295 --> 00:50:01.795
CRAIG MCLUCKIE: And
whenever we can,

00:50:01.795 --> 00:50:03.169
if you look at
the way we're sort

00:50:03.169 --> 00:50:04.869
of engaging this
community, we're

00:50:04.869 --> 00:50:06.410
getting really
strongly behind things

00:50:06.410 --> 00:50:07.300
like [INAUDIBLE] container.

00:50:07.300 --> 00:50:08.870
And we're actually putting a
tremendous amount of effort

00:50:08.870 --> 00:50:09.440
into it.

00:50:09.440 --> 00:50:11.380
Because we think it's
the right abstraction.

00:50:11.380 --> 00:50:12.820
With something
like Kubernetes, we

00:50:12.820 --> 00:50:14.361
want to create an
abstraction that we

00:50:14.361 --> 00:50:17.176
think is the best possible
abstraction out there.

00:50:17.176 --> 00:50:19.550
And a lot of it's based on a
decade of experience running

00:50:19.550 --> 00:50:20.050
containers.

00:50:20.050 --> 00:50:22.924
So we don't do this lightly.

00:50:22.924 --> 00:50:24.840
And we want to absolutely
engage the community

00:50:24.840 --> 00:50:29.750
and have the conversation around
what's right for the community.

00:50:29.750 --> 00:50:32.430
BRENDAN BURNS: I think
we are out of time.

00:50:32.430 --> 00:50:34.400
But we'll take-- you
have a quick question?

00:50:34.400 --> 00:50:35.710
Then absolutely we'll
have people come up.

00:50:35.710 --> 00:50:37.209
CRAIG MCLUCKIE: And
we'll be around.

00:50:37.209 --> 00:50:39.330
AUDIENCE: How does
Kubernetes scale?

00:50:39.330 --> 00:50:41.450
Is there a Kubernetes
of Kubernetes?

00:50:41.450 --> 00:50:43.330
If there are more
than one Kubernetes,

00:50:43.330 --> 00:50:45.790
how do they share
the information

00:50:45.790 --> 00:50:49.087
or the status of what
they are handling?

00:50:49.087 --> 00:50:51.170
BRENDAN BURNS: So right
now the way that it works,

00:50:51.170 --> 00:50:56.670
the premise is, you give us a
set of resources-- 50 VMs, five

00:50:56.670 --> 00:50:59.230
VMs, whatever it happens
to be-- and we'll

00:50:59.230 --> 00:51:02.700
manage work on top
of those machines.

00:51:02.700 --> 00:51:06.020
So in some sense, you have to
have some sense of the resource

00:51:06.020 --> 00:51:09.020
usage you may need.

00:51:09.020 --> 00:51:11.254
But it's also the case
that you could turn up

00:51:11.254 --> 00:51:13.670
two separate clusters that
would be essentially completely

00:51:13.670 --> 00:51:14.878
unaware of each other, right?

00:51:14.878 --> 00:51:18.392
They are hermetically sealed
clusters in and of themselves.

00:51:18.392 --> 00:51:19.850
And so if you ran
out of resources,

00:51:19.850 --> 00:51:20.934
you could turn up another.

00:51:20.934 --> 00:51:23.308
Although we would anticipate
that what you might actually

00:51:23.308 --> 00:51:24.980
want to do is tear
down your old cluster

00:51:24.980 --> 00:51:28.064
and turn up a larger cluster and
migrate your containers across.

00:51:28.064 --> 00:51:29.605
CRAIG MCLUCKIE: And
one thing I'd say

00:51:29.605 --> 00:51:32.021
is when we designed Kubernetes,
the intent was to produce.

00:51:32.021 --> 00:51:34.970
And there was simple, lean,
and extensible, right?

00:51:34.970 --> 00:51:37.970
We wanted to use it as a segue
to have a broader conversation.

00:51:37.970 --> 00:51:39.760
So a lot of the things
you might expect

00:51:39.760 --> 00:51:42.440
in terms of very high
levels of scalability,

00:51:42.440 --> 00:51:44.480
very high levels of
redundancy, are not yet

00:51:44.480 --> 00:51:46.590
present in that offering.

00:51:46.590 --> 00:51:49.110
We absolutely expect
the community and us

00:51:49.110 --> 00:51:50.550
to work towards that.

00:51:50.550 --> 00:51:53.540
But whenever possible, we
favored understandability

00:51:53.540 --> 00:51:57.040
and simplicity over this
very complex system.

00:51:57.040 --> 00:51:58.890
Because we wanted to
have the dialogue.

00:51:58.890 --> 00:52:00.430
And frankly, for a
lot of customers,

00:52:00.430 --> 00:52:02.950
where they are today, than
have relatively humble needs.

00:52:02.950 --> 00:52:05.040
And having something
that's extremely accessible

00:52:05.040 --> 00:52:06.350
is a very good thing.

00:52:06.350 --> 00:52:09.757
And that's how we designed
it from the start.

00:52:09.757 --> 00:52:10.590
BRENDAN BURNS: Cool.

00:52:10.590 --> 00:52:12.056
Well, I think we are completed.

00:52:12.056 --> 00:52:13.930
But please come up and
talk to us afterwards.

00:52:13.930 --> 00:52:15.460
And we'll be around
at the conference.

00:52:15.460 --> 00:52:15.950
CRAIG MCLUCKIE:
Thank you so much.

00:52:15.950 --> 00:52:16.100
BRENDAN BURNS: Have a good time.

00:52:16.100 --> 00:52:16.690
Thank you.

00:52:16.690 --> 00:52:19.740
[AUDIENCE APPLAUSE]

