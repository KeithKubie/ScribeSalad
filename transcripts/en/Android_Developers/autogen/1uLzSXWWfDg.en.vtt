WEBVTT
Kind: captions
Language: en

00:00:01.420 --> 00:00:04.360
 
[Music]

00:00:04.360 --> 00:00:04.370
[Music]
 

00:00:04.370 --> 00:00:07.880
[Music]
hello everyone thank you all for coming

00:00:07.880 --> 00:00:07.890
hello everyone thank you all for coming
 

00:00:07.890 --> 00:00:12.589
hello everyone thank you all for coming
and let's get started so I'm Matthew and

00:00:12.589 --> 00:00:12.599
and let's get started so I'm Matthew and
 

00:00:12.599 --> 00:00:15.530
and let's get started so I'm Matthew and
today my colleagues and I will be

00:00:15.530 --> 00:00:15.540
today my colleagues and I will be
 

00:00:15.540 --> 00:00:17.000
today my colleagues and I will be
talking about how we are making the

00:00:17.000 --> 00:00:17.010
talking about how we are making the
 

00:00:17.010 --> 00:00:20.060
talking about how we are making the
Android runtime also known as art faster

00:00:20.060 --> 00:00:20.070
Android runtime also known as art faster
 

00:00:20.070 --> 00:00:24.040
Android runtime also known as art faster
in Android Q we will also be showing you

00:00:24.040 --> 00:00:24.050
in Android Q we will also be showing you
 

00:00:24.050 --> 00:00:26.689
in Android Q we will also be showing you
some both some internal knowledge about

00:00:26.689 --> 00:00:26.699
some both some internal knowledge about
 

00:00:26.699 --> 00:00:29.839
some both some internal knowledge about
art as well as some best practices such

00:00:29.839 --> 00:00:29.849
art as well as some best practices such
 

00:00:29.849 --> 00:00:32.179
art as well as some best practices such
as using the report fully drawn API as

00:00:32.179 --> 00:00:32.189
as using the report fully drawn API as
 

00:00:32.189 --> 00:00:35.139
as using the report fully drawn API as
well as when to use object pooling and

00:00:35.139 --> 00:00:35.149
well as when to use object pooling and
 

00:00:35.149 --> 00:00:39.889
well as when to use object pooling and
now a recap about how art works so art

00:00:39.889 --> 00:00:39.899
now a recap about how art works so art
 

00:00:39.899 --> 00:00:41.990
now a recap about how art works so art
is the software layer in between the

00:00:41.990 --> 00:00:42.000
is the software layer in between the
 

00:00:42.000 --> 00:00:43.639
is the software layer in between the
Android operating system and the

00:00:43.639 --> 00:00:43.649
Android operating system and the
 

00:00:43.649 --> 00:00:46.940
Android operating system and the
applications it provides an execution

00:00:46.940 --> 00:00:46.950
applications it provides an execution
 

00:00:46.950 --> 00:00:47.660
applications it provides an execution
environment

00:00:47.660 --> 00:00:47.670
environment
 

00:00:47.670 --> 00:00:50.299
environment
for running both Kotlin and Java

00:00:50.299 --> 00:00:50.309
for running both Kotlin and Java
 

00:00:50.309 --> 00:00:54.170
for running both Kotlin and Java
language applications on Android to do

00:00:54.170 --> 00:00:54.180
language applications on Android to do
 

00:00:54.180 --> 00:00:57.260
language applications on Android to do
this art does two things it processes

00:00:57.260 --> 00:00:57.270
this art does two things it processes
 

00:00:57.270 --> 00:00:59.660
this art does two things it processes
Dex files the internal format of Android

00:00:59.660 --> 00:00:59.670
Dex files the internal format of Android
 

00:00:59.670 --> 00:01:01.869
Dex files the internal format of Android
applications through a hybrid model

00:01:01.869 --> 00:01:01.879
applications through a hybrid model
 

00:01:01.879 --> 00:01:03.850
applications through a hybrid model
consisting of interpretation

00:01:03.850 --> 00:01:03.860
consisting of interpretation
 

00:01:03.860 --> 00:01:06.980
consisting of interpretation
just-in-time compilation and profile

00:01:06.980 --> 00:01:06.990
just-in-time compilation and profile
 

00:01:06.990 --> 00:01:10.969
just-in-time compilation and profile
based ahead of time compilation art also

00:01:10.969 --> 00:01:10.979
based ahead of time compilation art also
 

00:01:10.979 --> 00:01:12.969
based ahead of time compilation art also
manages memory by having automatic

00:01:12.969 --> 00:01:12.979
manages memory by having automatic
 

00:01:12.979 --> 00:01:15.440
manages memory by having automatic
reclamation through a concurrent

00:01:15.440 --> 00:01:15.450
reclamation through a concurrent
 

00:01:15.450 --> 00:01:17.149
reclamation through a concurrent
compacting garbage collector that we

00:01:17.149 --> 00:01:17.159
compacting garbage collector that we
 

00:01:17.159 --> 00:01:23.929
compacting garbage collector that we
introduced in Android Oreo so an update

00:01:23.929 --> 00:01:23.939
introduced in Android Oreo so an update
 

00:01:23.939 --> 00:01:27.260
introduced in Android Oreo so an update
on profiles in the cloud so art has had

00:01:27.260 --> 00:01:27.270
on profiles in the cloud so art has had
 

00:01:27.270 --> 00:01:29.230
on profiles in the cloud so art has had
profiles that contain information about

00:01:29.230 --> 00:01:29.240
profiles that contain information about
 

00:01:29.240 --> 00:01:32.569
profiles that contain information about
application usage on Android since

00:01:32.569 --> 00:01:32.579
application usage on Android since
 

00:01:32.579 --> 00:01:36.319
application usage on Android since
nougat and until recently these profiles

00:01:36.319 --> 00:01:36.329
nougat and until recently these profiles
 

00:01:36.329 --> 00:01:39.440
nougat and until recently these profiles
are only local to the device these

00:01:39.440 --> 00:01:39.450
are only local to the device these
 

00:01:39.450 --> 00:01:41.359
are only local to the device these
profiles are collected by the distant

00:01:41.359 --> 00:01:41.369
profiles are collected by the distant
 

00:01:41.369 --> 00:01:44.149
profiles are collected by the distant
time compiler and are saved to device

00:01:44.149 --> 00:01:44.159
time compiler and are saved to device
 

00:01:44.159 --> 00:01:46.370
time compiler and are saved to device
storage during application execution and

00:01:46.370 --> 00:01:46.380
storage during application execution and
 

00:01:46.380 --> 00:01:48.260
storage during application execution and
later are used to optimize the

00:01:48.260 --> 00:01:48.270
later are used to optimize the
 

00:01:48.270 --> 00:01:51.530
later are used to optimize the
application since these were only

00:01:51.530 --> 00:01:51.540
application since these were only
 

00:01:51.540 --> 00:01:53.330
application since these were only
locally stored on the device until

00:01:53.330 --> 00:01:53.340
locally stored on the device until
 

00:01:53.340 --> 00:01:55.340
locally stored on the device until
recently this meant that applications

00:01:55.340 --> 00:01:55.350
recently this meant that applications
 

00:01:55.350 --> 00:01:57.200
recently this meant that applications
have to run a while have their profile

00:01:57.200 --> 00:01:57.210
have to run a while have their profile
 

00:01:57.210 --> 00:01:59.389
have to run a while have their profile
saved and then we have to optimize the

00:01:59.389 --> 00:01:59.399
saved and then we have to optimize the
 

00:01:59.399 --> 00:02:01.700
saved and then we have to optimize the
application when the phone was charging

00:02:01.700 --> 00:02:01.710
application when the phone was charging
 

00:02:01.710 --> 00:02:03.679
application when the phone was charging
or when the device was charging in the

00:02:03.679 --> 00:02:03.689
or when the device was charging in the
 

00:02:03.689 --> 00:02:07.490
or when the device was charging in the
background to address this we introduced

00:02:07.490 --> 00:02:07.500
background to address this we introduced
 

00:02:07.500 --> 00:02:09.859
background to address this we introduced
a new service called profiles in the

00:02:09.859 --> 00:02:09.869
a new service called profiles in the
 

00:02:09.869 --> 00:02:11.479
a new service called profiles in the
cloud

00:02:11.479 --> 00:02:11.489
cloud
 

00:02:11.489 --> 00:02:13.070
cloud
which was announced last year at Google

00:02:13.070 --> 00:02:13.080
which was announced last year at Google
 

00:02:13.080 --> 00:02:15.740
which was announced last year at Google
i/o and today we're gonna be providing

00:02:15.740 --> 00:02:15.750
i/o and today we're gonna be providing
 

00:02:15.750 --> 00:02:19.300
i/o and today we're gonna be providing
some more updates about how that's going

00:02:19.300 --> 00:02:19.310
some more updates about how that's going
 

00:02:19.310 --> 00:02:23.780
some more updates about how that's going
so before we dip dive into profiles in

00:02:23.780 --> 00:02:23.790
so before we dip dive into profiles in
 

00:02:23.790 --> 00:02:25.880
so before we dip dive into profiles in
the cloud let's take a closer look at

00:02:25.880 --> 00:02:25.890
the cloud let's take a closer look at
 

00:02:25.890 --> 00:02:29.330
the cloud let's take a closer look at
what's inside of a profile profiles

00:02:29.330 --> 00:02:29.340
what's inside of a profile profiles
 

00:02:29.340 --> 00:02:30.920
what's inside of a profile profiles
contain detailed information about

00:02:30.920 --> 00:02:30.930
contain detailed information about
 

00:02:30.930 --> 00:02:33.470
contain detailed information about
application usage including what methods

00:02:33.470 --> 00:02:33.480
application usage including what methods
 

00:02:33.480 --> 00:02:35.900
application usage including what methods
are run and what classes are loaded

00:02:35.900 --> 00:02:35.910
are run and what classes are loaded
 

00:02:35.910 --> 00:02:38.690
are run and what classes are loaded
during bolts startup and during a steady

00:02:38.690 --> 00:02:38.700
during bolts startup and during a steady
 

00:02:38.700 --> 00:02:42.170
during bolts startup and during a steady
state of the application usage this

00:02:42.170 --> 00:02:42.180
state of the application usage this
 

00:02:42.180 --> 00:02:44.240
state of the application usage this
enables art to compile the methods that

00:02:44.240 --> 00:02:44.250
enables art to compile the methods that
 

00:02:44.250 --> 00:02:46.009
enables art to compile the methods that
are the most important to machine code

00:02:46.009 --> 00:02:46.019
are the most important to machine code
 

00:02:46.019 --> 00:02:49.520
are the most important to machine code
as well as optimize the application for

00:02:49.520 --> 00:02:49.530
as well as optimize the application for
 

00:02:49.530 --> 00:02:52.520
as well as optimize the application for
startup by prioritizing code that is run

00:02:52.520 --> 00:02:52.530
startup by prioritizing code that is run
 

00:02:52.530 --> 00:02:56.630
startup by prioritizing code that is run
during startup for performance profiles

00:02:56.630 --> 00:02:56.640
during startup for performance profiles
 

00:02:56.640 --> 00:02:59.119
during startup for performance profiles
in the cloud enabled downloading the

00:02:59.119 --> 00:02:59.129
in the cloud enabled downloading the
 

00:02:59.129 --> 00:03:01.580
in the cloud enabled downloading the
profile alongside the application during

00:03:01.580 --> 00:03:01.590
profile alongside the application during
 

00:03:01.590 --> 00:03:03.949
profile alongside the application during
installation and then optimizing the

00:03:03.949 --> 00:03:03.959
installation and then optimizing the
 

00:03:03.959 --> 00:03:06.500
installation and then optimizing the
application during installation this

00:03:06.500 --> 00:03:06.510
application during installation this
 

00:03:06.510 --> 00:03:08.390
application during installation this
means that the users get the performance

00:03:08.390 --> 00:03:08.400
means that the users get the performance
 

00:03:08.400 --> 00:03:10.670
means that the users get the performance
directly after installation and no

00:03:10.670 --> 00:03:10.680
directly after installation and no
 

00:03:10.680 --> 00:03:12.530
directly after installation and no
longer have to wait for the application

00:03:12.530 --> 00:03:12.540
longer have to wait for the application
 

00:03:12.540 --> 00:03:14.509
longer have to wait for the application
to get optimized when the device is

00:03:14.509 --> 00:03:14.519
to get optimized when the device is
 

00:03:14.519 --> 00:03:17.599
to get optimized when the device is
charging in the background so here we've

00:03:17.599 --> 00:03:17.609
charging in the background so here we've
 

00:03:17.609 --> 00:03:20.120
charging in the background so here we've
observed speed ups of around 15% faster

00:03:20.120 --> 00:03:20.130
observed speed ups of around 15% faster
 

00:03:20.130 --> 00:03:21.740
observed speed ups of around 15% faster
applications start up directly after

00:03:21.740 --> 00:03:21.750
applications start up directly after
 

00:03:21.750 --> 00:03:26.900
applications start up directly after
installation so now let's dive into how

00:03:26.900 --> 00:03:26.910
installation so now let's dive into how
 

00:03:26.910 --> 00:03:28.640
installation so now let's dive into how
the whole profile and the cloud process

00:03:28.640 --> 00:03:28.650
the whole profile and the cloud process
 

00:03:28.650 --> 00:03:32.409
the whole profile and the cloud process
works so the main idea here is that

00:03:32.409 --> 00:03:32.419
works so the main idea here is that
 

00:03:32.419 --> 00:03:34.520
works so the main idea here is that
applications usually have commonly

00:03:34.520 --> 00:03:34.530
applications usually have commonly
 

00:03:34.530 --> 00:03:36.650
applications usually have commonly
shared code paths between a multitude of

00:03:36.650 --> 00:03:36.660
shared code paths between a multitude of
 

00:03:36.660 --> 00:03:39.680
shared code paths between a multitude of
users and devices so this means that

00:03:39.680 --> 00:03:39.690
users and devices so this means that
 

00:03:39.690 --> 00:03:41.449
users and devices so this means that
most users are gonna have generally the

00:03:41.449 --> 00:03:41.459
most users are gonna have generally the
 

00:03:41.459 --> 00:03:43.940
most users are gonna have generally the
same use case for startup and app the

00:03:43.940 --> 00:03:43.950
same use case for startup and app the
 

00:03:43.950 --> 00:03:47.569
same use case for startup and app the
application usage in general so what we

00:03:47.569 --> 00:03:47.579
application usage in general so what we
 

00:03:47.579 --> 00:03:49.190
application usage in general so what we
want to do with profiles in the cloud is

00:03:49.190 --> 00:03:49.200
want to do with profiles in the cloud is
 

00:03:49.200 --> 00:03:51.379
want to do with profiles in the cloud is
have the initial users bootstrap

00:03:51.379 --> 00:03:51.389
have the initial users bootstrap
 

00:03:51.389 --> 00:03:52.940
have the initial users bootstrap
performance for the rest of the users

00:03:52.940 --> 00:03:52.950
performance for the rest of the users
 

00:03:52.950 --> 00:03:56.390
performance for the rest of the users
and this is often a takes advantage or

00:03:56.390 --> 00:03:56.400
and this is often a takes advantage or
 

00:03:56.400 --> 00:03:58.220
and this is often a takes advantage or
benefits from the fact that developers

00:03:58.220 --> 00:03:58.230
benefits from the fact that developers
 

00:03:58.230 --> 00:04:00.409
benefits from the fact that developers
roll out the applications incrementally

00:04:00.409 --> 00:04:00.419
roll out the applications incrementally
 

00:04:00.419 --> 00:04:04.159
roll out the applications incrementally
with alpha beta channels so once an

00:04:04.159 --> 00:04:04.169
with alpha beta channels so once an
 

00:04:04.169 --> 00:04:06.440
with alpha beta channels so once an
application is installed the profiles

00:04:06.440 --> 00:04:06.450
application is installed the profiles
 

00:04:06.450 --> 00:04:08.330
application is installed the profiles
are uploaded to play and are aggregated

00:04:08.330 --> 00:04:08.340
are uploaded to play and are aggregated
 

00:04:08.340 --> 00:04:10.699
are uploaded to play and are aggregated
into what we call a common core profile

00:04:10.699 --> 00:04:10.709
into what we call a common core profile
 

00:04:10.709 --> 00:04:13.520
into what we call a common core profile
for the application and in future

00:04:13.520 --> 00:04:13.530
for the application and in future
 

00:04:13.530 --> 00:04:15.770
for the application and in future
installs this common core profile is

00:04:15.770 --> 00:04:15.780
installs this common core profile is
 

00:04:15.780 --> 00:04:17.509
installs this common core profile is
downloaded alongside the application and

00:04:17.509 --> 00:04:17.519
downloaded alongside the application and
 

00:04:17.519 --> 00:04:19.819
downloaded alongside the application and
used optimize the application during

00:04:19.819 --> 00:04:19.829
used optimize the application during
 

00:04:19.829 --> 00:04:21.690
used optimize the application during
installation

00:04:21.690 --> 00:04:21.700
installation
 

00:04:21.700 --> 00:04:23.830
installation
this improves both the steady-state

00:04:23.830 --> 00:04:23.840
this improves both the steady-state
 

00:04:23.840 --> 00:04:27.310
this improves both the steady-state
performance as well as the startup I'd

00:04:27.310 --> 00:04:27.320
performance as well as the startup I'd
 

00:04:27.320 --> 00:04:29.530
performance as well as the startup I'd
like to note that Android P also has API

00:04:29.530 --> 00:04:29.540
like to note that Android P also has API
 

00:04:29.540 --> 00:04:31.480
like to note that Android P also has API
support that non play devices can

00:04:31.480 --> 00:04:31.490
support that non play devices can
 

00:04:31.490 --> 00:04:36.790
support that non play devices can
leverage as for numbers as you can see

00:04:36.790 --> 00:04:36.800
leverage as for numbers as you can see
 

00:04:36.800 --> 00:04:38.650
leverage as for numbers as you can see
here YouTube has a large startup

00:04:38.650 --> 00:04:38.660
here YouTube has a large startup
 

00:04:38.660 --> 00:04:40.840
here YouTube has a large startup
improvement around 18% from profiles in

00:04:40.840 --> 00:04:40.850
improvement around 18% from profiles in
 

00:04:40.850 --> 00:04:42.970
improvement around 18% from profiles in
the cloud and other applications also

00:04:42.970 --> 00:04:42.980
the cloud and other applications also
 

00:04:42.980 --> 00:04:45.910
the cloud and other applications also
have substantial improvement this is

00:04:45.910 --> 00:04:45.920
have substantial improvement this is
 

00:04:45.920 --> 00:04:47.860
have substantial improvement this is
field data of Google applications

00:04:47.860 --> 00:04:47.870
field data of Google applications
 

00:04:47.870 --> 00:04:55.150
field data of Google applications
collected from pixel devices and one of

00:04:55.150 --> 00:04:55.160
collected from pixel devices and one of
 

00:04:55.160 --> 00:04:56.290
collected from pixel devices and one of
the best parts of all this is that

00:04:56.290 --> 00:04:56.300
the best parts of all this is that
 

00:04:56.300 --> 00:04:58.240
the best parts of all this is that
developers and users get the benefits

00:04:58.240 --> 00:04:58.250
developers and users get the benefits
 

00:04:58.250 --> 00:05:00.940
developers and users get the benefits
for free developers don't have to write

00:05:00.940 --> 00:05:00.950
for free developers don't have to write
 

00:05:00.950 --> 00:05:02.650
for free developers don't have to write
a single line of code to enable the

00:05:02.650 --> 00:05:02.660
a single line of code to enable the
 

00:05:02.660 --> 00:05:04.150
a single line of code to enable the
profiles for their applications and

00:05:04.150 --> 00:05:04.160
profiles for their applications and
 

00:05:04.160 --> 00:05:06.010
profiles for their applications and
users don't have to take any action to

00:05:06.010 --> 00:05:06.020
users don't have to take any action to
 

00:05:06.020 --> 00:05:10.150
users don't have to take any action to
get the benefits and right now around 80

00:05:10.150 --> 00:05:10.160
get the benefits and right now around 80
 

00:05:10.160 --> 00:05:12.700
get the benefits and right now around 80
percent of installations on devices with

00:05:12.700 --> 00:05:12.710
percent of installations on devices with
 

00:05:12.710 --> 00:05:15.580
percent of installations on devices with
Google Play services use profiles in the

00:05:15.580 --> 00:05:15.590
Google Play services use profiles in the
 

00:05:15.590 --> 00:05:19.120
Google Play services use profiles in the
cloud another interesting observation is

00:05:19.120 --> 00:05:19.130
cloud another interesting observation is
 

00:05:19.130 --> 00:05:21.790
cloud another interesting observation is
that the profiles in the cloud seems to

00:05:21.790 --> 00:05:21.800
that the profiles in the cloud seems to
 

00:05:21.800 --> 00:05:24.220
that the profiles in the cloud seems to
show that only around 20% of application

00:05:24.220 --> 00:05:24.230
show that only around 20% of application
 

00:05:24.230 --> 00:05:26.440
show that only around 20% of application
code is commonly used this could

00:05:26.440 --> 00:05:26.450
code is commonly used this could
 

00:05:26.450 --> 00:05:28.270
code is commonly used this could
indicate that there are opportunities to

00:05:28.270 --> 00:05:28.280
indicate that there are opportunities to
 

00:05:28.280 --> 00:05:30.370
indicate that there are opportunities to
reduce code size by removing unused code

00:05:30.370 --> 00:05:30.380
reduce code size by removing unused code
 

00:05:30.380 --> 00:05:35.800
reduce code size by removing unused code
in applications and now let's go to app

00:05:35.800 --> 00:05:35.810
in applications and now let's go to app
 

00:05:35.810 --> 00:05:38.650
in applications and now let's go to app
startup we have done some improvements

00:05:38.650 --> 00:05:38.660
startup we have done some improvements
 

00:05:38.660 --> 00:05:40.540
startup we have done some improvements
in queue and I'll be going over some of

00:05:40.540 --> 00:05:40.550
in queue and I'll be going over some of
 

00:05:40.550 --> 00:05:44.590
in queue and I'll be going over some of
those in Android q we have done three

00:05:44.590 --> 00:05:44.600
those in Android q we have done three
 

00:05:44.600 --> 00:05:47.830
those in Android q we have done three
major new improvements we've improved

00:05:47.830 --> 00:05:47.840
major new improvements we've improved
 

00:05:47.840 --> 00:05:49.690
major new improvements we've improved
the application images originally

00:05:49.690 --> 00:05:49.700
the application images originally
 

00:05:49.700 --> 00:05:52.330
the application images originally
introduced in Android nougat to provide

00:05:52.330 --> 00:05:52.340
introduced in Android nougat to provide
 

00:05:52.340 --> 00:05:55.330
introduced in Android nougat to provide
a larger startup improvement we have

00:05:55.330 --> 00:05:55.340
a larger startup improvement we have
 

00:05:55.340 --> 00:05:57.040
a larger startup improvement we have
added free forking of application

00:05:57.040 --> 00:05:57.050
added free forking of application
 

00:05:57.050 --> 00:05:59.290
added free forking of application
processes to accelerate process creation

00:05:59.290 --> 00:05:59.300
processes to accelerate process creation
 

00:05:59.300 --> 00:06:01.870
processes to accelerate process creation
on Android and we have added a new

00:06:01.870 --> 00:06:01.880
on Android and we have added a new
 

00:06:01.880 --> 00:06:06.550
on Android and we have added a new
generational garbage collector so

00:06:06.550 --> 00:06:06.560
generational garbage collector so
 

00:06:06.560 --> 00:06:10.060
generational garbage collector so
starting with application images recall

00:06:10.060 --> 00:06:10.070
starting with application images recall
 

00:06:10.070 --> 00:06:13.330
starting with application images recall
that application images as you see other

00:06:13.330 --> 00:06:13.340
that application images as you see other
 

00:06:13.340 --> 00:06:16.060
that application images as you see other
year's i/o talks are actually C realized

00:06:16.060 --> 00:06:16.070
year's i/o talks are actually C realized
 

00:06:16.070 --> 00:06:17.140
year's i/o talks are actually C realized
heap snapshots

00:06:17.140 --> 00:06:17.150
heap snapshots
 

00:06:17.150 --> 00:06:19.090
heap snapshots
containing the classes that are the most

00:06:19.090 --> 00:06:19.100
containing the classes that are the most
 

00:06:19.100 --> 00:06:20.920
containing the classes that are the most
commonly used during startup of an

00:06:20.920 --> 00:06:20.930
commonly used during startup of an
 

00:06:20.930 --> 00:06:23.860
commonly used during startup of an
application so this optimizes the

00:06:23.860 --> 00:06:23.870
application so this optimizes the
 

00:06:23.870 --> 00:06:26.680
application so this optimizes the
performance by shifting the work of

00:06:26.680 --> 00:06:26.690
performance by shifting the work of
 

00:06:26.690 --> 00:06:28.750
performance by shifting the work of
loading those classes from happening

00:06:28.750 --> 00:06:28.760
loading those classes from happening
 

00:06:28.760 --> 00:06:30.520
loading those classes from happening
during startup to happening ahead of

00:06:30.520 --> 00:06:30.530
during startup to happening ahead of
 

00:06:30.530 --> 00:06:34.409
during startup to happening ahead of
time in the art ahead of time compile

00:06:34.409 --> 00:06:34.419
time in the art ahead of time compile
 

00:06:34.419 --> 00:06:37.360
time in the art ahead of time compile
so the application image is generated by

00:06:37.360 --> 00:06:37.370
so the application image is generated by
 

00:06:37.370 --> 00:06:39.309
so the application image is generated by
the compiler taking both the application

00:06:39.309 --> 00:06:39.319
the compiler taking both the application
 

00:06:39.319 --> 00:06:42.700
the compiler taking both the application
apk and the profile as inputs and then

00:06:42.700 --> 00:06:42.710
apk and the profile as inputs and then
 

00:06:42.710 --> 00:06:44.920
apk and the profile as inputs and then
using the profile to know specifically

00:06:44.920 --> 00:06:44.930
using the profile to know specifically
 

00:06:44.930 --> 00:06:46.899
using the profile to know specifically
what classes are loaded during startup

00:06:46.899 --> 00:06:46.909
what classes are loaded during startup
 

00:06:46.909 --> 00:06:48.610
what classes are loaded during startup
and including only these in the

00:06:48.610 --> 00:06:48.620
and including only these in the
 

00:06:48.620 --> 00:06:52.600
and including only these in the
application images this is done during

00:06:52.600 --> 00:06:52.610
application images this is done during
 

00:06:52.610 --> 00:06:54.309
application images this is done during
installation if there is a profile from

00:06:54.309 --> 00:06:54.319
installation if there is a profile from
 

00:06:54.319 --> 00:06:56.170
installation if there is a profile from
the cloud presence otherwise it's

00:06:56.170 --> 00:06:56.180
the cloud presence otherwise it's
 

00:06:56.180 --> 00:06:57.700
the cloud presence otherwise it's
normally done in the background when the

00:06:57.700 --> 00:06:57.710
normally done in the background when the
 

00:06:57.710 --> 00:07:01.029
normally done in the background when the
device is charging so how have we

00:07:01.029 --> 00:07:01.039
device is charging so how have we
 

00:07:01.039 --> 00:07:02.830
device is charging so how have we
improved application images in Android

00:07:02.830 --> 00:07:02.840
improved application images in Android
 

00:07:02.840 --> 00:07:06.279
improved application images in Android
queue well we recently observed that

00:07:06.279 --> 00:07:06.289
queue well we recently observed that
 

00:07:06.289 --> 00:07:08.499
queue well we recently observed that
string interning cause specifically by

00:07:08.499 --> 00:07:08.509
string interning cause specifically by
 

00:07:08.509 --> 00:07:10.300
string interning cause specifically by
using string literals in application

00:07:10.300 --> 00:07:10.310
using string literals in application
 

00:07:10.310 --> 00:07:12.159
using string literals in application
startup was taking a large amount of

00:07:12.159 --> 00:07:12.169
startup was taking a large amount of
 

00:07:12.169 --> 00:07:14.830
startup was taking a large amount of
time so we added an optimization to

00:07:14.830 --> 00:07:14.840
time so we added an optimization to
 

00:07:14.840 --> 00:07:16.990
time so we added an optimization to
include the string literals that are

00:07:16.990 --> 00:07:17.000
include the string literals that are
 

00:07:17.000 --> 00:07:18.730
include the string literals that are
commonly used during startup for the

00:07:18.730 --> 00:07:18.740
commonly used during startup for the
 

00:07:18.740 --> 00:07:21.010
commonly used during startup for the
application inside of the application

00:07:21.010 --> 00:07:21.020
application inside of the application
 

00:07:21.020 --> 00:07:24.550
application inside of the application
image this is accomplished by leveraging

00:07:24.550 --> 00:07:24.560
image this is accomplished by leveraging
 

00:07:24.560 --> 00:07:26.860
image this is accomplished by leveraging
the profile to know specifically what

00:07:26.860 --> 00:07:26.870
the profile to know specifically what
 

00:07:26.870 --> 00:07:31.300
the profile to know specifically what
methods are executed during startup so

00:07:31.300 --> 00:07:31.310
methods are executed during startup so
 

00:07:31.310 --> 00:07:33.640
methods are executed during startup so
as you can see here there's around a 2.5

00:07:33.640 --> 00:07:33.650
as you can see here there's around a 2.5
 

00:07:33.650 --> 00:07:35.409
as you can see here there's around a 2.5
percent improvement on some applications

00:07:35.409 --> 00:07:35.419
percent improvement on some applications
 

00:07:35.419 --> 00:07:37.869
percent improvement on some applications
and this is a selection of first party

00:07:37.869 --> 00:07:37.879
and this is a selection of first party
 

00:07:37.879 --> 00:07:40.469
and this is a selection of first party
applications running on a pixel to excel

00:07:40.469 --> 00:07:40.479
applications running on a pixel to excel
 

00:07:40.479 --> 00:07:43.869
applications running on a pixel to excel
and now let me hand it off to Chris for

00:07:43.869 --> 00:07:43.879
and now let me hand it off to Chris for
 

00:07:43.879 --> 00:07:47.619
and now let me hand it off to Chris for
pre forking application processes Thank

00:07:47.619 --> 00:07:47.629
pre forking application processes Thank
 

00:07:47.629 --> 00:07:48.249
pre forking application processes Thank
You Matthew

00:07:48.249 --> 00:07:48.259
You Matthew
 

00:07:48.259 --> 00:07:51.070
You Matthew
hello everyone my name is Chris and I am

00:07:51.070 --> 00:07:51.080
hello everyone my name is Chris and I am
 

00:07:51.080 --> 00:07:52.779
hello everyone my name is Chris and I am
here to talk about some of the changes

00:07:52.779 --> 00:07:52.789
here to talk about some of the changes
 

00:07:52.789 --> 00:07:54.730
here to talk about some of the changes
we have made to the zygote in Android

00:07:54.730 --> 00:07:54.740
we have made to the zygote in Android
 

00:07:54.740 --> 00:07:56.890
we have made to the zygote in Android
queue to help improve a application

00:07:56.890 --> 00:07:56.900
queue to help improve a application
 

00:07:56.900 --> 00:07:58.990
queue to help improve a application
starter performance for those of you

00:07:58.990 --> 00:07:59.000
starter performance for those of you
 

00:07:59.000 --> 00:08:00.879
starter performance for those of you
unfamiliar with the zygote this is the

00:08:00.879 --> 00:08:00.889
unfamiliar with the zygote this is the
 

00:08:00.889 --> 00:08:03.189
unfamiliar with the zygote this is the
process in Android that all applications

00:08:03.189 --> 00:08:03.199
process in Android that all applications
 

00:08:03.199 --> 00:08:06.010
process in Android that all applications
are spawned from this design allows us

00:08:06.010 --> 00:08:06.020
are spawned from this design allows us
 

00:08:06.020 --> 00:08:09.550
are spawned from this design allows us
to take several application several

00:08:09.550 --> 00:08:09.560
to take several application several
 

00:08:09.560 --> 00:08:10.749
to take several application several
steps that are common to all Android

00:08:10.749 --> 00:08:10.759
steps that are common to all Android
 

00:08:10.759 --> 00:08:13.209
steps that are common to all Android
applications and perform them before the

00:08:13.209 --> 00:08:13.219
applications and perform them before the
 

00:08:13.219 --> 00:08:15.089
applications and perform them before the
applications are launched

00:08:15.089 --> 00:08:15.099
applications are launched
 

00:08:15.099 --> 00:08:17.439
applications are launched
unfortunately in previous versions of

00:08:17.439 --> 00:08:17.449
unfortunately in previous versions of
 

00:08:17.449 --> 00:08:19.059
unfortunately in previous versions of
Android there were still several

00:08:19.059 --> 00:08:19.069
Android there were still several
 

00:08:19.069 --> 00:08:21.339
Android there were still several
application agnostic steps that had to

00:08:21.339 --> 00:08:21.349
application agnostic steps that had to
 

00:08:21.349 --> 00:08:23.260
application agnostic steps that had to
be performed after the application was

00:08:23.260 --> 00:08:23.270
be performed after the application was
 

00:08:23.270 --> 00:08:25.290
be performed after the application was
launched

00:08:25.290 --> 00:08:25.300
launched
 

00:08:25.300 --> 00:08:27.910
launched
these include such things as process

00:08:27.910 --> 00:08:27.920
these include such things as process
 

00:08:27.920 --> 00:08:30.370
these include such things as process
spawning thread creation driver loading

00:08:30.370 --> 00:08:30.380
spawning thread creation driver loading
 

00:08:30.380 --> 00:08:33.640
spawning thread creation driver loading
and resource cleanup in android q we're

00:08:33.640 --> 00:08:33.650
and resource cleanup in android q we're
 

00:08:33.650 --> 00:08:35.320
and resource cleanup in android q we're
introducing the unspecialized app

00:08:35.320 --> 00:08:35.330
introducing the unspecialized app
 

00:08:35.330 --> 00:08:38.110
introducing the unspecialized app
process pool unspecial ID app and

00:08:38.110 --> 00:08:38.120
process pool unspecial ID app and
 

00:08:38.120 --> 00:08:40.210
process pool unspecial ID app and
specialized app processes are created

00:08:40.210 --> 00:08:40.220
specialized app processes are created
 

00:08:40.220 --> 00:08:41.950
specialized app processes are created
and performed these application agnostic

00:08:41.950 --> 00:08:41.960
and performed these application agnostic
 

00:08:41.960 --> 00:08:43.980
and performed these application agnostic
steps off the critical path of

00:08:43.980 --> 00:08:43.990
steps off the critical path of
 

00:08:43.990 --> 00:08:47.020
steps off the critical path of
application startup this produces an

00:08:47.020 --> 00:08:47.030
application startup this produces an
 

00:08:47.030 --> 00:08:48.760
application startup this produces an
average speed up of approximately five

00:08:48.760 --> 00:08:48.770
average speed up of approximately five
 

00:08:48.770 --> 00:08:51.700
average speed up of approximately five
milliseconds for most applications on a

00:08:51.700 --> 00:08:51.710
milliseconds for most applications on a
 

00:08:51.710 --> 00:08:54.190
milliseconds for most applications on a
pixel to device but more importantly it

00:08:54.190 --> 00:08:54.200
pixel to device but more importantly it
 

00:08:54.200 --> 00:08:55.540
pixel to device but more importantly it
forms a foundation for further

00:08:55.540 --> 00:08:55.550
forms a foundation for further
 

00:08:55.550 --> 00:08:58.570
forms a foundation for further
improvements to applications startup so

00:08:58.570 --> 00:08:58.580
improvements to applications startup so
 

00:08:58.580 --> 00:08:59.680
improvements to applications startup so
now let's take a look at some of the

00:08:59.680 --> 00:08:59.690
now let's take a look at some of the
 

00:08:59.690 --> 00:09:01.000
now let's take a look at some of the
changes we've made to the early stages

00:09:01.000 --> 00:09:01.010
changes we've made to the early stages
 

00:09:01.010 --> 00:09:05.470
changes we've made to the early stages
of app startup to make it faster on the

00:09:05.470 --> 00:09:05.480
of app startup to make it faster on the
 

00:09:05.480 --> 00:09:07.300
of app startup to make it faster on the
Left we can see the launching process

00:09:07.300 --> 00:09:07.310
Left we can see the launching process
 

00:09:07.310 --> 00:09:09.880
Left we can see the launching process
from previous versions of Android it

00:09:09.880 --> 00:09:09.890
from previous versions of Android it
 

00:09:09.890 --> 00:09:11.350
from previous versions of Android it
involves three communicating processes

00:09:11.350 --> 00:09:11.360
involves three communicating processes
 

00:09:11.360 --> 00:09:13.990
involves three communicating processes
one of which must be created during this

00:09:13.990 --> 00:09:14.000
one of which must be created during this
 

00:09:14.000 --> 00:09:17.020
one of which must be created during this
critical launch window it also involves

00:09:17.020 --> 00:09:17.030
critical launch window it also involves
 

00:09:17.030 --> 00:09:19.330
critical launch window it also involves
inter process communication or IPC and

00:09:19.330 --> 00:09:19.340
inter process communication or IPC and
 

00:09:19.340 --> 00:09:22.180
inter process communication or IPC and
this requires the zygote to wake up

00:09:22.180 --> 00:09:22.190
this requires the zygote to wake up
 

00:09:22.190 --> 00:09:25.030
this requires the zygote to wake up
block unblock and send a message to the

00:09:25.030 --> 00:09:25.040
block unblock and send a message to the
 

00:09:25.040 --> 00:09:27.550
block unblock and send a message to the
system server all of these steps take

00:09:27.550 --> 00:09:27.560
system server all of these steps take
 

00:09:27.560 --> 00:09:29.380
system server all of these steps take
resources away from the operating system

00:09:29.380 --> 00:09:29.390
resources away from the operating system
 

00:09:29.390 --> 00:09:32.710
resources away from the operating system
and the application that the users are

00:09:32.710 --> 00:09:32.720
and the application that the users are
 

00:09:32.720 --> 00:09:35.470
and the application that the users are
trying to launch on the right we can see

00:09:35.470 --> 00:09:35.480
trying to launch on the right we can see
 

00:09:35.480 --> 00:09:37.840
trying to launch on the right we can see
the new much simpler app launch process

00:09:37.840 --> 00:09:37.850
the new much simpler app launch process
 

00:09:37.850 --> 00:09:40.870
the new much simpler app launch process
in android q the zygote has been

00:09:40.870 --> 00:09:40.880
in android q the zygote has been
 

00:09:40.880 --> 00:09:42.910
in android q the zygote has been
completely removed from this critical

00:09:42.910 --> 00:09:42.920
completely removed from this critical
 

00:09:42.920 --> 00:09:47.290
completely removed from this critical
path the new also the new process that

00:09:47.290 --> 00:09:47.300
path the new also the new process that
 

00:09:47.300 --> 00:09:49.000
path the new also the new process that
will become the application already

00:09:49.000 --> 00:09:49.010
will become the application already
 

00:09:49.010 --> 00:09:50.830
will become the application already
exists in the system and has performed

00:09:50.830 --> 00:09:50.840
exists in the system and has performed
 

00:09:50.840 --> 00:09:53.580
exists in the system and has performed
these application agnostic steps already

00:09:53.580 --> 00:09:53.590
these application agnostic steps already
 

00:09:53.590 --> 00:09:56.230
these application agnostic steps already
by removing the zygote we also eliminate

00:09:56.230 --> 00:09:56.240
by removing the zygote we also eliminate
 

00:09:56.240 --> 00:09:58.360
by removing the zygote we also eliminate
an entire inter-process communication

00:09:58.360 --> 00:09:58.370
an entire inter-process communication
 

00:09:58.370 --> 00:10:00.040
an entire inter-process communication
round and this means that the new

00:10:00.040 --> 00:10:00.050
round and this means that the new
 

00:10:00.050 --> 00:10:01.750
round and this means that the new
application can talk directly to the

00:10:01.750 --> 00:10:01.760
application can talk directly to the
 

00:10:01.760 --> 00:10:04.660
application can talk directly to the
system server and not wake up the zygote

00:10:04.660 --> 00:10:04.670
system server and not wake up the zygote
 

00:10:04.670 --> 00:10:07.650
system server and not wake up the zygote
and consume system resources

00:10:07.650 --> 00:10:07.660
and consume system resources
 

00:10:07.660 --> 00:10:09.780
and consume system resources
in a couple slides I'm gonna be talk

00:10:09.780 --> 00:10:09.790
in a couple slides I'm gonna be talk
 

00:10:09.790 --> 00:10:11.760
in a couple slides I'm gonna be talk
about some of the metric and

00:10:11.760 --> 00:10:11.770
about some of the metric and
 

00:10:11.770 --> 00:10:13.410
about some of the metric and
investigation we've worked work we've

00:10:13.410 --> 00:10:13.420
investigation we've worked work we've
 

00:10:13.420 --> 00:10:16.050
investigation we've worked work we've
done in Android queue to help improve

00:10:16.050 --> 00:10:16.060
done in Android queue to help improve
 

00:10:16.060 --> 00:10:18.330
done in Android queue to help improve
applications startup performance but I

00:10:18.330 --> 00:10:18.340
applications startup performance but I
 

00:10:18.340 --> 00:10:20.310
applications startup performance but I
wanted to briefly mention the metrics

00:10:20.310 --> 00:10:20.320
wanted to briefly mention the metrics
 

00:10:20.320 --> 00:10:21.570
wanted to briefly mention the metrics
that is directly impacted by these

00:10:21.570 --> 00:10:21.580
that is directly impacted by these
 

00:10:21.580 --> 00:10:23.960
that is directly impacted by these
changes which is time to first slice

00:10:23.960 --> 00:10:23.970
changes which is time to first slice
 

00:10:23.970 --> 00:10:26.520
changes which is time to first slice
time to first slice as a measure of how

00:10:26.520 --> 00:10:26.530
time to first slice as a measure of how
 

00:10:26.530 --> 00:10:28.710
time to first slice as a measure of how
quickly we can begin running application

00:10:28.710 --> 00:10:28.720
quickly we can begin running application
 

00:10:28.720 --> 00:10:32.310
quickly we can begin running application
specific code and as we can see in this

00:10:32.310 --> 00:10:32.320
specific code and as we can see in this
 

00:10:32.320 --> 00:10:34.350
specific code and as we can see in this
graph there is a fairly uniform

00:10:34.350 --> 00:10:34.360
graph there is a fairly uniform
 

00:10:34.360 --> 00:10:36.540
graph there is a fairly uniform
improvement again of approximately five

00:10:36.540 --> 00:10:36.550
improvement again of approximately five
 

00:10:36.550 --> 00:10:38.490
improvement again of approximately five
milliseconds to the time to first slice

00:10:38.490 --> 00:10:38.500
milliseconds to the time to first slice
 

00:10:38.500 --> 00:10:40.530
milliseconds to the time to first slice
metric for these seven apps on a pixel

00:10:40.530 --> 00:10:40.540
metric for these seven apps on a pixel
 

00:10:40.540 --> 00:10:43.770
metric for these seven apps on a pixel
to device however this is just the

00:10:43.770 --> 00:10:43.780
to device however this is just the
 

00:10:43.780 --> 00:10:45.630
to device however this is just the
beginning for the speed ups and

00:10:45.630 --> 00:10:45.640
beginning for the speed ups and
 

00:10:45.640 --> 00:10:47.400
beginning for the speed ups and
improvements we can see from the using

00:10:47.400 --> 00:10:47.410
improvements we can see from the using
 

00:10:47.410 --> 00:10:49.800
improvements we can see from the using
unspecialized app processes follow-up

00:10:49.800 --> 00:10:49.810
unspecialized app processes follow-up
 

00:10:49.810 --> 00:10:52.110
unspecialized app processes follow-up
work that is currently in testing shows

00:10:52.110 --> 00:10:52.120
work that is currently in testing shows
 

00:10:52.120 --> 00:10:53.970
work that is currently in testing shows
an additional speed-up on the order of

00:10:53.970 --> 00:10:53.980
an additional speed-up on the order of
 

00:10:53.980 --> 00:10:57.210
an additional speed-up on the order of
ten of tens of milliseconds the best

00:10:57.210 --> 00:10:57.220
ten of tens of milliseconds the best
 

00:10:57.220 --> 00:10:59.370
ten of tens of milliseconds the best
news for users and developers alike is

00:10:59.370 --> 00:10:59.380
news for users and developers alike is
 

00:10:59.380 --> 00:11:01.380
news for users and developers alike is
that all applications will see these

00:11:01.380 --> 00:11:01.390
that all applications will see these
 

00:11:01.390 --> 00:11:02.790
that all applications will see these
improvements without requiring any

00:11:02.790 --> 00:11:02.800
improvements without requiring any
 

00:11:02.800 --> 00:11:04.980
improvements without requiring any
changes to their application or they way

00:11:04.980 --> 00:11:04.990
changes to their application or they way
 

00:11:04.990 --> 00:11:07.920
changes to their application or they way
that they use their advice so now I'm

00:11:07.920 --> 00:11:07.930
that they use their advice so now I'm
 

00:11:07.930 --> 00:11:09.450
that they use their advice so now I'm
going to talk briefly about the

00:11:09.450 --> 00:11:09.460
going to talk briefly about the
 

00:11:09.460 --> 00:11:10.740
going to talk briefly about the
measurement work that we've been doing

00:11:10.740 --> 00:11:10.750
measurement work that we've been doing
 

00:11:10.750 --> 00:11:14.490
measurement work that we've been doing
an Android q when performance tuning

00:11:14.490 --> 00:11:14.500
an Android q when performance tuning
 

00:11:14.500 --> 00:11:16.080
an Android q when performance tuning
software's complicated as an operating

00:11:16.080 --> 00:11:16.090
software's complicated as an operating
 

00:11:16.090 --> 00:11:18.840
software's complicated as an operating
system it's very important to get a deep

00:11:18.840 --> 00:11:18.850
system it's very important to get a deep
 

00:11:18.850 --> 00:11:21.120
system it's very important to get a deep
understanding of what is happening when

00:11:21.120 --> 00:11:21.130
understanding of what is happening when
 

00:11:21.130 --> 00:11:23.390
understanding of what is happening when
it's happening and how long it is taking

00:11:23.390 --> 00:11:23.400
it's happening and how long it is taking
 

00:11:23.400 --> 00:11:26.010
it's happening and how long it is taking
to this end we have spent a lot of time

00:11:26.010 --> 00:11:26.020
to this end we have spent a lot of time
 

00:11:26.020 --> 00:11:28.770
to this end we have spent a lot of time
looking at traces and log files over the

00:11:28.770 --> 00:11:28.780
looking at traces and log files over the
 

00:11:28.780 --> 00:11:31.470
looking at traces and log files over the
last couple months we've also developed

00:11:31.470 --> 00:11:31.480
last couple months we've also developed
 

00:11:31.480 --> 00:11:33.600
last couple months we've also developed
several new tools for extracting

00:11:33.600 --> 00:11:33.610
several new tools for extracting
 

00:11:33.610 --> 00:11:36.240
several new tools for extracting
actionable and useful insights from this

00:11:36.240 --> 00:11:36.250
actionable and useful insights from this
 

00:11:36.250 --> 00:11:38.760
actionable and useful insights from this
large corpus of data one of these tools

00:11:38.760 --> 00:11:38.770
large corpus of data one of these tools
 

00:11:38.770 --> 00:11:41.730
large corpus of data one of these tools
is publicly available to you and that's

00:11:41.730 --> 00:11:41.740
is publicly available to you and that's
 

00:11:41.740 --> 00:11:44.250
is publicly available to you and that's
the start up analyzer script this script

00:11:44.250 --> 00:11:44.260
the start up analyzer script this script
 

00:11:44.260 --> 00:11:46.440
the start up analyzer script this script
will extract detailed information about

00:11:46.440 --> 00:11:46.450
will extract detailed information about
 

00:11:46.450 --> 00:11:48.690
will extract detailed information about
startup events from trace files

00:11:48.690 --> 00:11:48.700
startup events from trace files
 

00:11:48.700 --> 00:11:51.300
startup events from trace files
including start-up duration scheduling

00:11:51.300 --> 00:11:51.310
including start-up duration scheduling
 

00:11:51.310 --> 00:11:56.580
including start-up duration scheduling
status and binder transactions one of

00:11:56.580 --> 00:11:56.590
status and binder transactions one of
 

00:11:56.590 --> 00:11:58.740
status and binder transactions one of
the most important questions that this

00:11:58.740 --> 00:11:58.750
the most important questions that this
 

00:11:58.750 --> 00:12:01.200
the most important questions that this
work made us ask ourself is when does

00:12:01.200 --> 00:12:01.210
work made us ask ourself is when does
 

00:12:01.210 --> 00:12:04.650
work made us ask ourself is when does
application startup end well there are

00:12:04.650 --> 00:12:04.660
application startup end well there are
 

00:12:04.660 --> 00:12:07.440
application startup end well there are
many criteria that we can use to that

00:12:07.440 --> 00:12:07.450
many criteria that we can use to that
 

00:12:07.450 --> 00:12:09.800
many criteria that we can use to that
might signal when startup is finished

00:12:09.800 --> 00:12:09.810
might signal when startup is finished
 

00:12:09.810 --> 00:12:11.790
might signal when startup is finished
including when the first frame of the

00:12:11.790 --> 00:12:11.800
including when the first frame of the
 

00:12:11.800 --> 00:12:14.310
including when the first frame of the
user interface is drawn and this is

00:12:14.310 --> 00:12:14.320
user interface is drawn and this is
 

00:12:14.320 --> 00:12:15.930
user interface is drawn and this is
certainly a useful definition it's one

00:12:15.930 --> 00:12:15.940
certainly a useful definition it's one
 

00:12:15.940 --> 00:12:17.790
certainly a useful definition it's one
we can use to optimize

00:12:17.790 --> 00:12:17.800
we can use to optimize
 

00:12:17.800 --> 00:12:20.310
we can use to optimize
moments but it doesn't tell us when the

00:12:20.310 --> 00:12:20.320
moments but it doesn't tell us when the
 

00:12:20.320 --> 00:12:22.259
moments but it doesn't tell us when the
user perceives the application to be

00:12:22.259 --> 00:12:22.269
user perceives the application to be
 

00:12:22.269 --> 00:12:24.360
user perceives the application to be
usable which is what we consider to be

00:12:24.360 --> 00:12:24.370
usable which is what we consider to be
 

00:12:24.370 --> 00:12:26.579
usable which is what we consider to be
the gold standard for applications start

00:12:26.579 --> 00:12:26.589
the gold standard for applications start
 

00:12:26.589 --> 00:12:31.050
the gold standard for applications start
up endpoint unfortunately we don't have

00:12:31.050 --> 00:12:31.060
up endpoint unfortunately we don't have
 

00:12:31.060 --> 00:12:32.730
up endpoint unfortunately we don't have
a way to automatically detect when this

00:12:32.730 --> 00:12:32.740
a way to automatically detect when this
 

00:12:32.740 --> 00:12:35.850
a way to automatically detect when this
happens we do however have an API call

00:12:35.850 --> 00:12:35.860
happens we do however have an API call
 

00:12:35.860 --> 00:12:38.130
happens we do however have an API call
the developers can use to tell us when

00:12:38.130 --> 00:12:38.140
the developers can use to tell us when
 

00:12:38.140 --> 00:12:41.040
the developers can use to tell us when
you think it happens this makes it

00:12:41.040 --> 00:12:41.050
you think it happens this makes it
 

00:12:41.050 --> 00:12:42.300
you think it happens this makes it
easier for us to identify the

00:12:42.300 --> 00:12:42.310
easier for us to identify the
 

00:12:42.310 --> 00:12:44.009
easier for us to identify the
application startup process for

00:12:44.009 --> 00:12:44.019
application startup process for
 

00:12:44.019 --> 00:12:45.750
application startup process for
individual apps and make sure that we

00:12:45.750 --> 00:12:45.760
individual apps and make sure that we
 

00:12:45.760 --> 00:12:47.250
individual apps and make sure that we
optimize the things that are important

00:12:47.250 --> 00:12:47.260
optimize the things that are important
 

00:12:47.260 --> 00:12:49.829
optimize the things that are important
to your app so if you would like to help

00:12:49.829 --> 00:12:49.839
to your app so if you would like to help
 

00:12:49.839 --> 00:12:51.870
to your app so if you would like to help
us speed up the performance of your

00:12:51.870 --> 00:12:51.880
us speed up the performance of your
 

00:12:51.880 --> 00:12:54.449
us speed up the performance of your
application I highly recommend that you

00:12:54.449 --> 00:12:54.459
application I highly recommend that you
 

00:12:54.459 --> 00:12:57.680
application I highly recommend that you
use this report fully draw an API call

00:12:57.680 --> 00:12:57.690
use this report fully draw an API call
 

00:12:57.690 --> 00:13:00.840
use this report fully draw an API call
so thank you for your time and at this

00:13:00.840 --> 00:13:00.850
so thank you for your time and at this
 

00:13:00.850 --> 00:13:02.280
so thank you for your time and at this
point I'm gonna hand the state over to

00:13:02.280 --> 00:13:02.290
point I'm gonna hand the state over to
 

00:13:02.290 --> 00:13:04.170
point I'm gonna hand the state over to
Roland for a discussion of the garbage

00:13:04.170 --> 00:13:04.180
Roland for a discussion of the garbage
 

00:13:04.180 --> 00:13:06.380
Roland for a discussion of the garbage
collection work that we've done in queue

00:13:06.380 --> 00:13:06.390
collection work that we've done in queue
 

00:13:06.390 --> 00:13:14.790
collection work that we've done in queue
thank you Chris hi everyone my name is

00:13:14.790 --> 00:13:14.800
thank you Chris hi everyone my name is
 

00:13:14.800 --> 00:13:16.319
thank you Chris hi everyone my name is
Hollow and I'm going to present the

00:13:16.319 --> 00:13:16.329
Hollow and I'm going to present the
 

00:13:16.329 --> 00:13:17.850
Hollow and I'm going to present the
improvements we've made in our cabbage

00:13:17.850 --> 00:13:17.860
improvements we've made in our cabbage
 

00:13:17.860 --> 00:13:21.630
improvements we've made in our cabbage
collector for Android cute another word

00:13:21.630 --> 00:13:21.640
collector for Android cute another word
 

00:13:21.640 --> 00:13:23.730
collector for Android cute another word
queue we've improved our concurrent copy

00:13:23.730 --> 00:13:23.740
queue we've improved our concurrent copy
 

00:13:23.740 --> 00:13:26.730
queue we've improved our concurrent copy
garbage collector in two ways first by

00:13:26.730 --> 00:13:26.740
garbage collector in two ways first by
 

00:13:26.740 --> 00:13:28.199
garbage collector in two ways first by
adding support for generational garbage

00:13:28.199 --> 00:13:28.209
adding support for generational garbage
 

00:13:28.209 --> 00:13:30.449
adding support for generational garbage
collection which makes GC cheaper

00:13:30.449 --> 00:13:30.459
collection which makes GC cheaper
 

00:13:30.459 --> 00:13:33.269
collection which makes GC cheaper
overall and second by using a two-phase

00:13:33.269 --> 00:13:33.279
overall and second by using a two-phase
 

00:13:33.279 --> 00:13:35.699
overall and second by using a two-phase
collection strategy which makes garbage

00:13:35.699 --> 00:13:35.709
collection strategy which makes garbage
 

00:13:35.709 --> 00:13:37.829
collection strategy which makes garbage
collection more precise and able to

00:13:37.829 --> 00:13:37.839
collection more precise and able to
 

00:13:37.839 --> 00:13:40.710
collection more precise and able to
reclaim more objects during the

00:13:40.710 --> 00:13:40.720
reclaim more objects during the
 

00:13:40.720 --> 00:13:42.660
reclaim more objects during the
development of Android queue we've also

00:13:42.660 --> 00:13:42.670
development of Android queue we've also
 

00:13:42.670 --> 00:13:44.880
development of Android queue we've also
reevaluated the benefits of object

00:13:44.880 --> 00:13:44.890
reevaluated the benefits of object
 

00:13:44.890 --> 00:13:46.769
reevaluated the benefits of object
pooling versus standard allocation in

00:13:46.769 --> 00:13:46.779
pooling versus standard allocation in
 

00:13:46.779 --> 00:13:49.410
pooling versus standard allocation in
arts in the last section of this talk

00:13:49.410 --> 00:13:49.420
arts in the last section of this talk
 

00:13:49.420 --> 00:13:51.980
arts in the last section of this talk
would share with you our findings and

00:13:51.980 --> 00:13:51.990
would share with you our findings and
 

00:13:51.990 --> 00:13:54.480
would share with you our findings and
new recommendation regarding object

00:13:54.480 --> 00:13:54.490
new recommendation regarding object
 

00:13:54.490 --> 00:13:55.749
new recommendation regarding object
pooling

00:13:55.749 --> 00:13:55.759
pooling
 

00:13:55.759 --> 00:13:58.160
pooling
but for now let's have a look at garbage

00:13:58.160 --> 00:13:58.170
but for now let's have a look at garbage
 

00:13:58.170 --> 00:13:59.389
but for now let's have a look at garbage
collection generational garbage

00:13:59.389 --> 00:13:59.399
collection generational garbage
 

00:13:59.399 --> 00:14:03.530
collection generational garbage
collection in android 800 we introduced

00:14:03.530 --> 00:14:03.540
collection in android 800 we introduced
 

00:14:03.540 --> 00:14:04.549
collection in android 800 we introduced
the concurrent covering garbage

00:14:04.549 --> 00:14:04.559
the concurrent covering garbage
 

00:14:04.559 --> 00:14:07.549
the concurrent covering garbage
collector or CC collector in arts this

00:14:07.549 --> 00:14:07.559
collector or CC collector in arts this
 

00:14:07.559 --> 00:14:09.710
collector or CC collector in arts this
year we added support for generational

00:14:09.710 --> 00:14:09.720
year we added support for generational
 

00:14:09.720 --> 00:14:11.989
year we added support for generational
collection to this collector in anyway

00:14:11.989 --> 00:14:11.999
collection to this collector in anyway
 

00:14:11.999 --> 00:14:13.999
collection to this collector in anyway
queue the CC collector alternates Fulop

00:14:13.999 --> 00:14:14.009
queue the CC collector alternates Fulop
 

00:14:14.009 --> 00:14:16.249
queue the CC collector alternates Fulop
collections and young generation

00:14:16.249 --> 00:14:16.259
collections and young generation
 

00:14:16.259 --> 00:14:18.410
collections and young generation
collections these young generation

00:14:18.410 --> 00:14:18.420
collections these young generation
 

00:14:18.420 --> 00:14:20.569
collections these young generation
collections only process a fraction of

00:14:20.569 --> 00:14:20.579
collections only process a fraction of
 

00:14:20.579 --> 00:14:22.850
collections only process a fraction of
the heap they are cheaper and almost as

00:14:22.850 --> 00:14:22.860
the heap they are cheaper and almost as
 

00:14:22.860 --> 00:14:25.699
the heap they are cheaper and almost as
effective as full hip collections before

00:14:25.699 --> 00:14:25.709
effective as full hip collections before
 

00:14:25.709 --> 00:14:27.619
effective as full hip collections before
look at generation collection let's have

00:14:27.619 --> 00:14:27.629
look at generation collection let's have
 

00:14:27.629 --> 00:14:28.850
look at generation collection let's have
a look at look at how the concurrent

00:14:28.850 --> 00:14:28.860
a look at look at how the concurrent
 

00:14:28.860 --> 00:14:32.720
a look at look at how the concurrent
copying garbage collector works the

00:14:32.720 --> 00:14:32.730
copying garbage collector works the
 

00:14:32.730 --> 00:14:34.069
copying garbage collector works the
garbage collector in arts is a

00:14:34.069 --> 00:14:34.079
garbage collector in arts is a
 

00:14:34.079 --> 00:14:36.470
garbage collector in arts is a
concurrent copying one it is concurrent

00:14:36.470 --> 00:14:36.480
concurrent copying one it is concurrent
 

00:14:36.480 --> 00:14:38.329
concurrent copying one it is concurrent
because it runs at the same time and an

00:14:38.329 --> 00:14:38.339
because it runs at the same time and an
 

00:14:38.339 --> 00:14:40.429
because it runs at the same time and an
app's thread and it does not require a

00:14:40.429 --> 00:14:40.439
app's thread and it does not require a
 

00:14:40.439 --> 00:14:43.040
app's thread and it does not require a
long stop the world pause this work

00:14:43.040 --> 00:14:43.050
long stop the world pause this work
 

00:14:43.050 --> 00:14:45.139
long stop the world pause this work
thanks to a cooperation between the GC

00:14:45.139 --> 00:14:45.149
thanks to a cooperation between the GC
 

00:14:45.149 --> 00:14:47.720
thanks to a cooperation between the GC
and the apps code all accesses to object

00:14:47.720 --> 00:14:47.730
and the apps code all accesses to object
 

00:14:47.730 --> 00:14:49.400
and the apps code all accesses to object
references are instrumented in the

00:14:49.400 --> 00:14:49.410
references are instrumented in the
 

00:14:49.410 --> 00:14:51.739
references are instrumented in the
runtime with what we call read barriers

00:14:51.739 --> 00:14:51.749
runtime with what we call read barriers
 

00:14:51.749 --> 00:14:53.509
runtime with what we call read barriers
and they ensure that the app does not

00:14:53.509 --> 00:14:53.519
and they ensure that the app does not
 

00:14:53.519 --> 00:14:56.780
and they ensure that the app does not
see a stale object the GC is also said

00:14:56.780 --> 00:14:56.790
see a stale object the GC is also said
 

00:14:56.790 --> 00:14:59.419
see a stale object the GC is also said
to be copying because it moves live

00:14:59.419 --> 00:14:59.429
to be copying because it moves live
 

00:14:59.429 --> 00:15:01.369
to be copying because it moves live
objects in memory by making a copy of

00:15:01.369 --> 00:15:01.379
objects in memory by making a copy of
 

00:15:01.379 --> 00:15:03.319
objects in memory by making a copy of
them and reclaiming the space that held

00:15:03.319 --> 00:15:03.329
them and reclaiming the space that held
 

00:15:03.329 --> 00:15:05.540
them and reclaiming the space that held
the original objects including the data

00:15:05.540 --> 00:15:05.550
the original objects including the data
 

00:15:05.550 --> 00:15:08.179
the original objects including the data
objects this copying strategy means that

00:15:08.179 --> 00:15:08.189
objects this copying strategy means that
 

00:15:08.189 --> 00:15:09.739
objects this copying strategy means that
the GC is compacting the heap and

00:15:09.739 --> 00:15:09.749
the GC is compacting the heap and
 

00:15:09.749 --> 00:15:12.619
the GC is compacting the heap and
preventing fragmentation let's see how

00:15:12.619 --> 00:15:12.629
preventing fragmentation let's see how
 

00:15:12.629 --> 00:15:14.889
preventing fragmentation let's see how
this works

00:15:14.889 --> 00:15:14.899
this works
 

00:15:14.899 --> 00:15:17.540
this works
copying collector traditionally splits

00:15:17.540 --> 00:15:17.550
copying collector traditionally splits
 

00:15:17.550 --> 00:15:19.759
copying collector traditionally splits
the managed heap into spaces a from

00:15:19.759 --> 00:15:19.769
the managed heap into spaces a from
 

00:15:19.769 --> 00:15:22.249
the managed heap into spaces a from
space which contains the object

00:15:22.249 --> 00:15:22.259
space which contains the object
 

00:15:22.259 --> 00:15:24.230
space which contains the object
currently allocated and used and a to

00:15:24.230 --> 00:15:24.240
currently allocated and used and a to
 

00:15:24.240 --> 00:15:26.419
currently allocated and used and a to
space to each live objects a move during

00:15:26.419 --> 00:15:26.429
space to each live objects a move during
 

00:15:26.429 --> 00:15:29.689
space to each live objects a move during
garbage collection during a GC cycle the

00:15:29.689 --> 00:15:29.699
garbage collection during a GC cycle the
 

00:15:29.699 --> 00:15:31.730
garbage collection during a GC cycle the
collector traces the heat it follows

00:15:31.730 --> 00:15:31.740
collector traces the heat it follows
 

00:15:31.740 --> 00:15:34.790
collector traces the heat it follows
route references to manage objects for

00:15:34.790 --> 00:15:34.800
route references to manage objects for
 

00:15:34.800 --> 00:15:36.590
route references to manage objects for
instance from its thread stack and marks

00:15:36.590 --> 00:15:36.600
instance from its thread stack and marks
 

00:15:36.600 --> 00:15:38.509
instance from its thread stack and marks
all objects reachable from these routes

00:15:38.509 --> 00:15:38.519
all objects reachable from these routes
 

00:15:38.519 --> 00:15:43.280
all objects reachable from these routes
to compute the set of live objects they

00:15:43.280 --> 00:15:43.290
to compute the set of live objects they
 

00:15:43.290 --> 00:15:45.139
to compute the set of live objects they
are reachable objects in dark red in

00:15:45.139 --> 00:15:45.149
are reachable objects in dark red in
 

00:15:45.149 --> 00:15:46.999
are reachable objects in dark red in
this illustration are the ones which are

00:15:46.999 --> 00:15:47.009
this illustration are the ones which are
 

00:15:47.009 --> 00:15:51.079
this illustration are the ones which are
not visited by the collector reachable

00:15:51.079 --> 00:15:51.089
not visited by the collector reachable
 

00:15:51.089 --> 00:15:53.239
not visited by the collector reachable
objects are copied to the to space as

00:15:53.239 --> 00:15:53.249
objects are copied to the to space as
 

00:15:53.249 --> 00:15:55.570
objects are copied to the to space as
they are being marked by the GC

00:15:55.570 --> 00:15:55.580
they are being marked by the GC
 

00:15:55.580 --> 00:15:58.990
they are being marked by the GC
and likewise all other reachable objects

00:15:58.990 --> 00:15:59.000
and likewise all other reachable objects
 

00:15:59.000 --> 00:16:00.670
and likewise all other reachable objects
living in the front spacer could be to

00:16:00.670 --> 00:16:00.680
living in the front spacer could be to
 

00:16:00.680 --> 00:16:02.500
living in the front spacer could be to
the to space they're being marked thus

00:16:02.500 --> 00:16:02.510
the to space they're being marked thus
 

00:16:02.510 --> 00:16:06.130
the to space they're being marked thus
compacting the heat and the other the

00:16:06.130 --> 00:16:06.140
compacting the heat and the other the
 

00:16:06.140 --> 00:16:07.660
compacting the heat and the other the
collection the object that haven't been

00:16:07.660 --> 00:16:07.670
collection the object that haven't been
 

00:16:07.670 --> 00:16:09.970
collection the object that haven't been
moved are the dead ones and because they

00:16:09.970 --> 00:16:09.980
moved are the dead ones and because they
 

00:16:09.980 --> 00:16:12.070
moved are the dead ones and because they
are not reachable and the GC can then

00:16:12.070 --> 00:16:12.080
are not reachable and the GC can then
 

00:16:12.080 --> 00:16:13.720
are not reachable and the GC can then
reclaim the memory used by the from

00:16:13.720 --> 00:16:13.730
reclaim the memory used by the from
 

00:16:13.730 --> 00:16:18.310
reclaim the memory used by the from
space finally the front space and the to

00:16:18.310 --> 00:16:18.320
space finally the front space and the to
 

00:16:18.320 --> 00:16:19.990
space finally the front space and the to
space are swapped and new locations

00:16:19.990 --> 00:16:20.000
space are swapped and new locations
 

00:16:20.000 --> 00:16:22.050
space are swapped and new locations
happen in the new from space

00:16:22.050 --> 00:16:22.060
happen in the new from space
 

00:16:22.060 --> 00:16:24.610
happen in the new from space
so that's heap compaction in a nutshell

00:16:24.610 --> 00:16:24.620
so that's heap compaction in a nutshell
 

00:16:24.620 --> 00:16:28.840
so that's heap compaction in a nutshell
let's see how this works in arts so for

00:16:28.840 --> 00:16:28.850
let's see how this works in arts so for
 

00:16:28.850 --> 00:16:29.740
let's see how this works in arts so for
practical reasons

00:16:29.740 --> 00:16:29.750
practical reasons
 

00:16:29.750 --> 00:16:31.930
practical reasons
RCC collector does not use two semi

00:16:31.930 --> 00:16:31.940
RCC collector does not use two semi
 

00:16:31.940 --> 00:16:34.420
RCC collector does not use two semi
spaces for a region space composed of

00:16:34.420 --> 00:16:34.430
spaces for a region space composed of
 

00:16:34.430 --> 00:16:38.110
spaces for a region space composed of
256 kilobyte regions as an app's memory

00:16:38.110 --> 00:16:38.120
256 kilobyte regions as an app's memory
 

00:16:38.120 --> 00:16:39.970
256 kilobyte regions as an app's memory
needs grow over time new regions are

00:16:39.970 --> 00:16:39.980
needs grow over time new regions are
 

00:16:39.980 --> 00:16:41.800
needs grow over time new regions are
located to Co spec to create space for

00:16:41.800 --> 00:16:41.810
located to Co spec to create space for
 

00:16:41.810 --> 00:16:46.030
located to Co spec to create space for
new objects I think the previous example

00:16:46.030 --> 00:16:46.040
new objects I think the previous example
 

00:16:46.040 --> 00:16:48.040
new objects I think the previous example
we're highlighting unreachable objects

00:16:48.040 --> 00:16:48.050
we're highlighting unreachable objects
 

00:16:48.050 --> 00:16:50.590
we're highlighting unreachable objects
in dark red color at the beginning of a

00:16:50.590 --> 00:16:50.600
in dark red color at the beginning of a
 

00:16:50.600 --> 00:16:52.420
in dark red color at the beginning of a
cheesy cycle the garbage collector max

00:16:52.420 --> 00:16:52.430
cheesy cycle the garbage collector max
 

00:16:52.430 --> 00:16:55.180
cheesy cycle the garbage collector max
decision for each region in use the

00:16:55.180 --> 00:16:55.190
decision for each region in use the
 

00:16:55.190 --> 00:16:57.090
decision for each region in use the
first option is to evacuate a region

00:16:57.090 --> 00:16:57.100
first option is to evacuate a region
 

00:16:57.100 --> 00:16:59.680
first option is to evacuate a region
which means moving all live objects out

00:16:59.680 --> 00:16:59.690
which means moving all live objects out
 

00:16:59.690 --> 00:17:02.020
which means moving all live objects out
of it and reclaim the memory backing the

00:17:02.020 --> 00:17:02.030
of it and reclaim the memory backing the
 

00:17:02.030 --> 00:17:04.480
of it and reclaim the memory backing the
region at the end of the cycle this

00:17:04.480 --> 00:17:04.490
region at the end of the cycle this
 

00:17:04.490 --> 00:17:06.250
region at the end of the cycle this
makes sense if there's a good proportion

00:17:06.250 --> 00:17:06.260
makes sense if there's a good proportion
 

00:17:06.260 --> 00:17:09.730
makes sense if there's a good proportion
of data objects in this region because

00:17:09.730 --> 00:17:09.740
of data objects in this region because
 

00:17:09.740 --> 00:17:12.760
of data objects in this region because
evacuating it means it will have compact

00:17:12.760 --> 00:17:12.770
evacuating it means it will have compact
 

00:17:12.770 --> 00:17:16.110
evacuating it means it will have compact
the heap and fit some physical memory

00:17:16.110 --> 00:17:16.120
the heap and fit some physical memory
 

00:17:16.120 --> 00:17:18.490
the heap and fit some physical memory
but if most of the allocated object in

00:17:18.490 --> 00:17:18.500
but if most of the allocated object in
 

00:17:18.500 --> 00:17:20.590
but if most of the allocated object in
these regions are actually alive there

00:17:20.590 --> 00:17:20.600
these regions are actually alive there
 

00:17:20.600 --> 00:17:23.560
these regions are actually alive there
will be little benefits to evacuated and

00:17:23.560 --> 00:17:23.570
will be little benefits to evacuated and
 

00:17:23.570 --> 00:17:25.900
will be little benefits to evacuated and
maybe some costs because of the object

00:17:25.900 --> 00:17:25.910
maybe some costs because of the object
 

00:17:25.910 --> 00:17:28.540
maybe some costs because of the object
copies in that case did you see my

00:17:28.540 --> 00:17:28.550
copies in that case did you see my
 

00:17:28.550 --> 00:17:30.520
copies in that case did you see my
decide to keep the region as is and we

00:17:30.520 --> 00:17:30.530
decide to keep the region as is and we
 

00:17:30.530 --> 00:17:33.100
decide to keep the region as is and we
call that an an evacuated region in dark

00:17:33.100 --> 00:17:33.110
call that an an evacuated region in dark
 

00:17:33.110 --> 00:17:36.280
call that an an evacuated region in dark
green in this diagram until Android cue

00:17:36.280 --> 00:17:36.290
green in this diagram until Android cue
 

00:17:36.290 --> 00:17:39.220
green in this diagram until Android cue
the decision to evacuate a region or not

00:17:39.220 --> 00:17:39.230
the decision to evacuate a region or not
 

00:17:39.230 --> 00:17:41.320
the decision to evacuate a region or not
was based on information from a previous

00:17:41.320 --> 00:17:41.330
was based on information from a previous
 

00:17:41.330 --> 00:17:44.560
was based on information from a previous
duty cycle which is not optimal later

00:17:44.560 --> 00:17:44.570
duty cycle which is not optimal later
 

00:17:44.570 --> 00:17:46.090
duty cycle which is not optimal later
and is thought my colleague Lokesh will

00:17:46.090 --> 00:17:46.100
and is thought my colleague Lokesh will
 

00:17:46.100 --> 00:17:49.020
and is thought my colleague Lokesh will
talk more about this

00:17:49.020 --> 00:17:49.030
 
 

00:17:49.030 --> 00:17:51.430
 
tracing and marking works similarly to

00:17:51.430 --> 00:17:51.440
tracing and marking works similarly to
 

00:17:51.440 --> 00:17:52.750
tracing and marking works similarly to
the priests example but instead of

00:17:52.750 --> 00:17:52.760
the priests example but instead of
 

00:17:52.760 --> 00:17:56.260
the priests example but instead of
copying our mercury object to a fixed -

00:17:56.260 --> 00:17:56.270
copying our mercury object to a fixed -
 

00:17:56.270 --> 00:17:58.539
copying our mercury object to a fixed -
space area they are copied to a freshly

00:17:58.539 --> 00:17:58.549
space area they are copied to a freshly
 

00:17:58.549 --> 00:18:00.310
space area they are copied to a freshly
allocated region called an evacuation

00:18:00.310 --> 00:18:00.320
allocated region called an evacuation
 

00:18:00.320 --> 00:18:05.790
allocated region called an evacuation
region

00:18:05.790 --> 00:18:05.800
 
 

00:18:05.800 --> 00:18:07.830
 
if this region speeds up during garbage

00:18:07.830 --> 00:18:07.840
if this region speeds up during garbage
 

00:18:07.840 --> 00:18:09.630
if this region speeds up during garbage
collection another region is allocated

00:18:09.630 --> 00:18:09.640
collection another region is allocated
 

00:18:09.640 --> 00:18:11.640
collection another region is allocated
and so on and so the whole heap has been

00:18:11.640 --> 00:18:11.650
and so on and so the whole heap has been
 

00:18:11.650 --> 00:18:14.460
and so on and so the whole heap has been
traced and the energy GC cycle the to

00:18:14.460 --> 00:18:14.470
traced and the energy GC cycle the to
 

00:18:14.470 --> 00:18:16.620
traced and the energy GC cycle the to
space is the union of all the evacuation

00:18:16.620 --> 00:18:16.630
space is the union of all the evacuation
 

00:18:16.630 --> 00:18:18.690
space is the union of all the evacuation
regions and the region that had been

00:18:18.690 --> 00:18:18.700
regions and the region that had been
 

00:18:18.700 --> 00:18:22.760
regions and the region that had been
allocated for new object allocations

00:18:22.760 --> 00:18:22.770
 
 

00:18:22.770 --> 00:18:25.080
 
evacuated regions eventually are

00:18:25.080 --> 00:18:25.090
evacuated regions eventually are
 

00:18:25.090 --> 00:18:27.900
evacuated regions eventually are
reclaimed and their memory the pages are

00:18:27.900 --> 00:18:27.910
reclaimed and their memory the pages are
 

00:18:27.910 --> 00:18:32.220
reclaimed and their memory the pages are
returned to the system now that we've

00:18:32.220 --> 00:18:32.230
returned to the system now that we've
 

00:18:32.230 --> 00:18:34.680
returned to the system now that we've
seen how arts concurrent collector works

00:18:34.680 --> 00:18:34.690
seen how arts concurrent collector works
 

00:18:34.690 --> 00:18:36.900
seen how arts concurrent collector works
let's see at let's have a look at the

00:18:36.900 --> 00:18:36.910
let's see at let's have a look at the
 

00:18:36.910 --> 00:18:40.890
let's see at let's have a look at the
generational version even if the CC

00:18:40.890 --> 00:18:40.900
generational version even if the CC
 

00:18:40.900 --> 00:18:42.720
generational version even if the CC
collector does not evacuate all regions

00:18:42.720 --> 00:18:42.730
collector does not evacuate all regions
 

00:18:42.730 --> 00:18:45.270
collector does not evacuate all regions
it has to trace all the objects this is

00:18:45.270 --> 00:18:45.280
it has to trace all the objects this is
 

00:18:45.280 --> 00:18:47.550
it has to trace all the objects this is
known as a full hip collection but

00:18:47.550 --> 00:18:47.560
known as a full hip collection but
 

00:18:47.560 --> 00:18:49.950
known as a full hip collection but
consider this if the GC what you process

00:18:49.950 --> 00:18:49.960
consider this if the GC what you process
 

00:18:49.960 --> 00:18:52.140
consider this if the GC what you process
only recently allocated objects it will

00:18:52.140 --> 00:18:52.150
only recently allocated objects it will
 

00:18:52.150 --> 00:18:54.060
only recently allocated objects it will
in general collect most of them and for

00:18:54.060 --> 00:18:54.070
in general collect most of them and for
 

00:18:54.070 --> 00:18:55.920
in general collect most of them and for
a fraction of the costs of a food heap

00:18:55.920 --> 00:18:55.930
a fraction of the costs of a food heap
 

00:18:55.930 --> 00:18:59.370
a fraction of the costs of a food heap
collection this is this is what we call

00:18:59.370 --> 00:18:59.380
collection this is this is what we call
 

00:18:59.380 --> 00:19:01.200
collection this is this is what we call
the generational hypothesis in most

00:19:01.200 --> 00:19:01.210
the generational hypothesis in most
 

00:19:01.210 --> 00:19:03.270
the generational hypothesis in most
cases young objects emerged more likely

00:19:03.270 --> 00:19:03.280
cases young objects emerged more likely
 

00:19:03.280 --> 00:19:06.180
cases young objects emerged more likely
to die than old objects art generational

00:19:06.180 --> 00:19:06.190
to die than old objects art generational
 

00:19:06.190 --> 00:19:08.550
to die than old objects art generational
CC collector introducing the concept of

00:19:08.550 --> 00:19:08.560
CC collector introducing the concept of
 

00:19:08.560 --> 00:19:11.250
CC collector introducing the concept of
young generation collection only tracing

00:19:11.250 --> 00:19:11.260
young generation collection only tracing
 

00:19:11.260 --> 00:19:13.800
young generation collection only tracing
recently allocated regions these are

00:19:13.800 --> 00:19:13.810
recently allocated regions these are
 

00:19:13.810 --> 00:19:15.990
recently allocated regions these are
called minor collections are supposed to

00:19:15.990 --> 00:19:16.000
called minor collections are supposed to
 

00:19:16.000 --> 00:19:17.460
called minor collections are supposed to
fool hip collections with a called major

00:19:17.460 --> 00:19:17.470
fool hip collections with a called major
 

00:19:17.470 --> 00:19:20.610
fool hip collections with a called major
collections there's a GC heuristics

00:19:20.610 --> 00:19:20.620
collections there's a GC heuristics
 

00:19:20.620 --> 00:19:23.100
collections there's a GC heuristics
which tries to use minor collection

00:19:23.100 --> 00:19:23.110
which tries to use minor collection
 

00:19:23.110 --> 00:19:25.860
which tries to use minor collection
firsts and it runs major collections if

00:19:25.860 --> 00:19:25.870
firsts and it runs major collections if
 

00:19:25.870 --> 00:19:29.790
firsts and it runs major collections if
needed in a young generation collection

00:19:29.790 --> 00:19:29.800
needed in a young generation collection
 

00:19:29.800 --> 00:19:31.740
needed in a young generation collection
we handle newly allocated ijen specially

00:19:31.740 --> 00:19:31.750
we handle newly allocated ijen specially
 

00:19:31.750 --> 00:19:33.900
we handle newly allocated ijen specially
these regions are the ones which have

00:19:33.900 --> 00:19:33.910
these regions are the ones which have
 

00:19:33.910 --> 00:19:35.730
these regions are the ones which have
been allocated in the previous GC cycle

00:19:35.730 --> 00:19:35.740
been allocated in the previous GC cycle
 

00:19:35.740 --> 00:19:37.650
been allocated in the previous GC cycle
and the objects are much more likely to

00:19:37.650 --> 00:19:37.660
and the objects are much more likely to
 

00:19:37.660 --> 00:19:38.750
and the objects are much more likely to
be unreachable

00:19:38.750 --> 00:19:38.760
be unreachable
 

00:19:38.760 --> 00:19:41.580
be unreachable
therefore these regions are the only one

00:19:41.580 --> 00:19:41.590
therefore these regions are the only one
 

00:19:41.590 --> 00:19:43.650
therefore these regions are the only one
evacuated during a minor collection and

00:19:43.650 --> 00:19:43.660
evacuated during a minor collection and
 

00:19:43.660 --> 00:19:45.870
evacuated during a minor collection and
they're also the only regions which are

00:19:45.870 --> 00:19:45.880
they're also the only regions which are
 

00:19:45.880 --> 00:19:47.490
they're also the only regions which are
being traced during a minor collection

00:19:47.490 --> 00:19:47.500
being traced during a minor collection
 

00:19:47.500 --> 00:19:50.220
being traced during a minor collection
all generation objects have survived at

00:19:50.220 --> 00:19:50.230
all generation objects have survived at
 

00:19:50.230 --> 00:19:51.840
all generation objects have survived at
least one collection and they are more

00:19:51.840 --> 00:19:51.850
least one collection and they are more
 

00:19:51.850 --> 00:19:54.090
least one collection and they are more
likely to be still alive so they're not

00:19:54.090 --> 00:19:54.100
likely to be still alive so they're not
 

00:19:54.100 --> 00:19:54.720
likely to be still alive so they're not
traced

00:19:54.720 --> 00:19:54.730
traced
 

00:19:54.730 --> 00:19:58.170
traced
during a minor collection overall this

00:19:58.170 --> 00:19:58.180
during a minor collection overall this
 

00:19:58.180 --> 00:20:07.290
during a minor collection overall this
results in a much faster GC cycle

00:20:07.290 --> 00:20:07.300
 
 

00:20:07.300 --> 00:20:09.420
 
by tracing young generation regions from

00:20:09.420 --> 00:20:09.430
by tracing young generation regions from
 

00:20:09.430 --> 00:20:15.780
by tracing young generation regions from
the roots and also in other to any trace

00:20:15.780 --> 00:20:15.790
the roots and also in other to any trace
 

00:20:15.790 --> 00:20:18.540
the roots and also in other to any trace
objects in the young generation we need

00:20:18.540 --> 00:20:18.550
objects in the young generation we need
 

00:20:18.550 --> 00:20:21.060
objects in the young generation we need
to determine the reach ability to do so

00:20:21.060 --> 00:20:21.070
to determine the reach ability to do so
 

00:20:21.070 --> 00:20:22.560
to determine the reach ability to do so
we need to track references from the

00:20:22.560 --> 00:20:22.570
we need to track references from the
 

00:20:22.570 --> 00:20:24.360
we need to track references from the
roots to the young object as we did in

00:20:24.360 --> 00:20:24.370
roots to the young object as we did in
 

00:20:24.370 --> 00:20:26.250
roots to the young object as we did in
the full hippo actions but we also need

00:20:26.250 --> 00:20:26.260
the full hippo actions but we also need
 

00:20:26.260 --> 00:20:28.590
the full hippo actions but we also need
to trace references from old object to

00:20:28.590 --> 00:20:28.600
to trace references from old object to
 

00:20:28.600 --> 00:20:30.180
to trace references from old object to
young objects because the old objects

00:20:30.180 --> 00:20:30.190
young objects because the old objects
 

00:20:30.190 --> 00:20:33.090
young objects because the old objects
are not race we track such young young

00:20:33.090 --> 00:20:33.100
are not race we track such young young
 

00:20:33.100 --> 00:20:35.520
are not race we track such young young
to the old Auto young object references

00:20:35.520 --> 00:20:35.530
to the old Auto young object references
 

00:20:35.530 --> 00:20:38.370
to the old Auto young object references
using a remember sets mechanism which

00:20:38.370 --> 00:20:38.380
using a remember sets mechanism which
 

00:20:38.380 --> 00:20:42.600
using a remember sets mechanism which
keeps tracks of references object whose

00:20:42.600 --> 00:20:42.610
keeps tracks of references object whose
 

00:20:42.610 --> 00:20:44.850
keeps tracks of references object whose
field i've been modified since the last

00:20:44.850 --> 00:20:44.860
field i've been modified since the last
 

00:20:44.860 --> 00:20:49.340
field i've been modified since the last
GC cycle

00:20:49.340 --> 00:20:49.350
 
 

00:20:49.350 --> 00:20:55.170
 
minor collection yeah by tracing the

00:20:55.170 --> 00:20:55.180
minor collection yeah by tracing the
 

00:20:55.180 --> 00:20:56.970
minor collection yeah by tracing the
young generations from the roots and

00:20:56.970 --> 00:20:56.980
young generations from the roots and
 

00:20:56.980 --> 00:20:59.280
young generations from the roots and
remember sets we can identify live young

00:20:59.280 --> 00:20:59.290
remember sets we can identify live young
 

00:20:59.290 --> 00:21:00.930
remember sets we can identify live young
objects and copy them out of the region

00:21:00.930 --> 00:21:00.940
objects and copy them out of the region
 

00:21:00.940 --> 00:21:03.000
objects and copy them out of the region
without the need to trade the whole heap

00:21:03.000 --> 00:21:03.010
without the need to trade the whole heap
 

00:21:03.010 --> 00:21:05.160
without the need to trade the whole heap
and this is the main benefit of minor

00:21:05.160 --> 00:21:05.170
and this is the main benefit of minor
 

00:21:05.170 --> 00:21:07.980
and this is the main benefit of minor
collections minor collection do not

00:21:07.980 --> 00:21:07.990
collections minor collection do not
 

00:21:07.990 --> 00:21:09.810
collections minor collection do not
process all generation object that could

00:21:09.810 --> 00:21:09.820
process all generation object that could
 

00:21:09.820 --> 00:21:10.980
process all generation object that could
have been reclaimed in the food

00:21:10.980 --> 00:21:10.990
have been reclaimed in the food
 

00:21:10.990 --> 00:21:13.520
have been reclaimed in the food
collection we call that floating garbage

00:21:13.520 --> 00:21:13.530
collection we call that floating garbage
 

00:21:13.530 --> 00:21:15.750
collection we call that floating garbage
they will eventually be collected during

00:21:15.750 --> 00:21:15.760
they will eventually be collected during
 

00:21:15.760 --> 00:21:18.600
they will eventually be collected during
the next full hip collection let's now

00:21:18.600 --> 00:21:18.610
the next full hip collection let's now
 

00:21:18.610 --> 00:21:20.520
the next full hip collection let's now
see the impact of generation CC on our

00:21:20.520 --> 00:21:20.530
see the impact of generation CC on our
 

00:21:20.530 --> 00:21:23.850
see the impact of generation CC on our
own arts performance to assess the

00:21:23.850 --> 00:21:23.860
own arts performance to assess the
 

00:21:23.860 --> 00:21:25.860
own arts performance to assess the
impact of generational CC collection on

00:21:25.860 --> 00:21:25.870
impact of generational CC collection on
 

00:21:25.870 --> 00:21:27.780
impact of generational CC collection on
arts we've measured the average CPU time

00:21:27.780 --> 00:21:27.790
arts we've measured the average CPU time
 

00:21:27.790 --> 00:21:29.550
arts we've measured the average CPU time
spent in the garbage collector thread on

00:21:29.550 --> 00:21:29.560
spent in the garbage collector thread on
 

00:21:29.560 --> 00:21:32.310
spent in the garbage collector thread on
some GC internship benchmarks we use the

00:21:32.310 --> 00:21:32.320
some GC internship benchmarks we use the
 

00:21:32.320 --> 00:21:33.720
some GC internship benchmarks we use the
edge to benchmark from the deck above

00:21:33.720 --> 00:21:33.730
edge to benchmark from the deck above
 

00:21:33.730 --> 00:21:35.580
edge to benchmark from the deck above
sweets which is an in-memory database

00:21:35.580 --> 00:21:35.590
sweets which is an in-memory database
 

00:21:35.590 --> 00:21:37.920
sweets which is an in-memory database
benchmark as well as our internal

00:21:37.920 --> 00:21:37.930
benchmark as well as our internal
 

00:21:37.930 --> 00:21:40.200
benchmark as well as our internal
village seeds benchmark because both are

00:21:40.200 --> 00:21:40.210
village seeds benchmark because both are
 

00:21:40.210 --> 00:21:42.690
village seeds benchmark because both are
good examples of allocation and garbage

00:21:42.690 --> 00:21:42.700
good examples of allocation and garbage
 

00:21:42.700 --> 00:21:45.990
good examples of allocation and garbage
collection workloads on average the

00:21:45.990 --> 00:21:46.000
collection workloads on average the
 

00:21:46.000 --> 00:21:49.080
collection workloads on average the
generational CC collector is 38% faster

00:21:49.080 --> 00:21:49.090
generational CC collector is 38% faster
 

00:21:49.090 --> 00:21:52.260
generational CC collector is 38% faster
on h2 and 33% faster on sheets while

00:21:52.260 --> 00:21:52.270
on h2 and 33% faster on sheets while
 

00:21:52.270 --> 00:21:53.280
on h2 and 33% faster on sheets while
compared with the non generational

00:21:53.280 --> 00:21:53.290
compared with the non generational
 

00:21:53.290 --> 00:21:55.350
compared with the non generational
garbage collector that we shipped in

00:21:55.350 --> 00:21:55.360
garbage collector that we shipped in
 

00:21:55.360 --> 00:21:57.600
garbage collector that we shipped in
under 8 P

00:21:57.600 --> 00:21:57.610
under 8 P
 

00:21:57.610 --> 00:22:00.180
under 8 P
now this is the direct results of a

00:22:00.180 --> 00:22:00.190
now this is the direct results of a
 

00:22:00.190 --> 00:22:02.220
now this is the direct results of a
younger generation collection being

00:22:02.220 --> 00:22:02.230
younger generation collection being
 

00:22:02.230 --> 00:22:05.280
younger generation collection being
cheaper in terms of CPU time so to put

00:22:05.280 --> 00:22:05.290
cheaper in terms of CPU time so to put
 

00:22:05.290 --> 00:22:07.740
cheaper in terms of CPU time so to put
it in a nutshell using short of objects

00:22:07.740 --> 00:22:07.750
it in a nutshell using short of objects
 

00:22:07.750 --> 00:22:11.940
it in a nutshell using short of objects
is now cheaper and also as a consequence

00:22:11.940 --> 00:22:11.950
is now cheaper and also as a consequence
 

00:22:11.950 --> 00:22:14.040
is now cheaper and also as a consequence
of these improvements we expect that

00:22:14.040 --> 00:22:14.050
of these improvements we expect that
 

00:22:14.050 --> 00:22:15.900
of these improvements we expect that
because we're spending less time in the

00:22:15.900 --> 00:22:15.910
because we're spending less time in the
 

00:22:15.910 --> 00:22:17.940
because we're spending less time in the
garbage collector this will benefits the

00:22:17.940 --> 00:22:17.950
garbage collector this will benefits the
 

00:22:17.950 --> 00:22:21.630
garbage collector this will benefits the
device battery life improvements in

00:22:21.630 --> 00:22:21.640
device battery life improvements in
 

00:22:21.640 --> 00:22:23.420
device battery life improvements in
garbage collection often I lights

00:22:23.420 --> 00:22:23.430
garbage collection often I lights
 

00:22:23.430 --> 00:22:25.680
garbage collection often I lights
shredders between CPU and RAM usage

00:22:25.680 --> 00:22:25.690
shredders between CPU and RAM usage
 

00:22:25.690 --> 00:22:28.050
shredders between CPU and RAM usage
generational garbage collector may keep

00:22:28.050 --> 00:22:28.060
generational garbage collector may keep
 

00:22:28.060 --> 00:22:30.510
generational garbage collector may keep
some objects a bit longer in order to

00:22:30.510 --> 00:22:30.520
some objects a bit longer in order to
 

00:22:30.520 --> 00:22:33.450
some objects a bit longer in order to
speed up the overall GC execution to

00:22:33.450 --> 00:22:33.460
speed up the overall GC execution to
 

00:22:33.460 --> 00:22:35.340
speed up the overall GC execution to
talk more about these how we can improve

00:22:35.340 --> 00:22:35.350
talk more about these how we can improve
 

00:22:35.350 --> 00:22:37.710
talk more about these how we can improve
these trade-offs and heap compaction I'm

00:22:37.710 --> 00:22:37.720
these trade-offs and heap compaction I'm
 

00:22:37.720 --> 00:22:43.880
these trade-offs and heap compaction I'm
handing it over to Lokesh

00:22:43.880 --> 00:22:43.890
 
 

00:22:43.890 --> 00:22:46.740
 
[Applause]

00:22:46.740 --> 00:22:46.750
[Applause]
 

00:22:46.750 --> 00:22:49.350
[Applause]
hi everyone I hope you still have some

00:22:49.350 --> 00:22:49.360
hi everyone I hope you still have some
 

00:22:49.360 --> 00:22:52.130
hi everyone I hope you still have some
stamina left for more technical stuff so

00:22:52.130 --> 00:22:52.140
stamina left for more technical stuff so
 

00:22:52.140 --> 00:22:55.500
stamina left for more technical stuff so
let's start off with talking a little

00:22:55.500 --> 00:22:55.510
let's start off with talking a little
 

00:22:55.510 --> 00:22:57.540
let's start off with talking a little
bit more about how hip compaction works

00:22:57.540 --> 00:22:57.550
bit more about how hip compaction works
 

00:22:57.550 --> 00:22:58.640
bit more about how hip compaction works
in CeCe

00:22:58.640 --> 00:22:58.650
in CeCe
 

00:22:58.650 --> 00:23:02.610
in CeCe
so as you can imagine the more live

00:23:02.610 --> 00:23:02.620
so as you can imagine the more live
 

00:23:02.620 --> 00:23:05.720
so as you can imagine the more live
objects there are in a compacting region

00:23:05.720 --> 00:23:05.730
objects there are in a compacting region
 

00:23:05.730 --> 00:23:09.180
objects there are in a compacting region
the lesser memory you would reclaim if

00:23:09.180 --> 00:23:09.190
the lesser memory you would reclaim if
 

00:23:09.190 --> 00:23:12.150
the lesser memory you would reclaim if
you were to compact it and so it makes

00:23:12.150 --> 00:23:12.160
you were to compact it and so it makes
 

00:23:12.160 --> 00:23:15.270
you were to compact it and so it makes
more sense to only for a higher rate of

00:23:15.270 --> 00:23:15.280
more sense to only for a higher rate of
 

00:23:15.280 --> 00:23:17.970
more sense to only for a higher rate of
interest meant to only compact those

00:23:17.970 --> 00:23:17.980
interest meant to only compact those
 

00:23:17.980 --> 00:23:19.710
interest meant to only compact those
regions which have considerable garbage

00:23:19.710 --> 00:23:19.720
regions which have considerable garbage
 

00:23:19.720 --> 00:23:21.510
regions which have considerable garbage
in them and that's exactly what

00:23:21.510 --> 00:23:21.520
in them and that's exactly what
 

00:23:21.520 --> 00:23:24.930
in them and that's exactly what
concurrent coping collector does we

00:23:24.930 --> 00:23:24.940
concurrent coping collector does we
 

00:23:24.940 --> 00:23:27.780
concurrent coping collector does we
maintain a Perth Region liveness stat

00:23:27.780 --> 00:23:27.790
maintain a Perth Region liveness stat
 

00:23:27.790 --> 00:23:31.350
maintain a Perth Region liveness stat
which indicates how much live data is

00:23:31.350 --> 00:23:31.360
which indicates how much live data is
 

00:23:31.360 --> 00:23:33.270
which indicates how much live data is
there in a particular region and based

00:23:33.270 --> 00:23:33.280
there in a particular region and based
 

00:23:33.280 --> 00:23:35.040
there in a particular region and based
on that decide which regions are worth

00:23:35.040 --> 00:23:35.050
on that decide which regions are worth
 

00:23:35.050 --> 00:23:38.520
on that decide which regions are worth
evacuating and which are not another

00:23:38.520 --> 00:23:38.530
evacuating and which are not another
 

00:23:38.530 --> 00:23:40.830
evacuating and which are not another
interesting fact about the CC algorithm

00:23:40.830 --> 00:23:40.840
interesting fact about the CC algorithm
 

00:23:40.840 --> 00:23:43.890
interesting fact about the CC algorithm
is that it during a GC cycle it only

00:23:43.890 --> 00:23:43.900
is that it during a GC cycle it only
 

00:23:43.900 --> 00:23:46.170
is that it during a GC cycle it only
goes through all the reachable objects

00:23:46.170 --> 00:23:46.180
goes through all the reachable objects
 

00:23:46.180 --> 00:23:52.130
goes through all the reachable objects
only once while this is a very useful

00:23:52.130 --> 00:23:52.140
only once while this is a very useful
 

00:23:52.140 --> 00:23:55.590
only once while this is a very useful
fact about any GC algorithm because it

00:23:55.590 --> 00:23:55.600
fact about any GC algorithm because it
 

00:23:55.600 --> 00:23:58.770
fact about any GC algorithm because it
it shows how efficient the algorithm is

00:23:58.770 --> 00:23:58.780
it shows how efficient the algorithm is
 

00:23:58.780 --> 00:24:01.380
it shows how efficient the algorithm is
let's see how it affects the heap

00:24:01.380 --> 00:24:01.390
let's see how it affects the heap
 

00:24:01.390 --> 00:24:05.550
let's see how it affects the heap
compaction decisions that we make so

00:24:05.550 --> 00:24:05.560
compaction decisions that we make so
 

00:24:05.560 --> 00:24:07.980
compaction decisions that we make so
this is a hypothetical timeline of some

00:24:07.980 --> 00:24:07.990
this is a hypothetical timeline of some
 

00:24:07.990 --> 00:24:11.400
this is a hypothetical timeline of some
Z some apps execution and as you can

00:24:11.400 --> 00:24:11.410
Z some apps execution and as you can
 

00:24:11.410 --> 00:24:13.040
Z some apps execution and as you can
imagine during the execution

00:24:13.040 --> 00:24:13.050
imagine during the execution
 

00:24:13.050 --> 00:24:15.210
imagine during the execution
periodically we need to perform GC

00:24:15.210 --> 00:24:15.220
periodically we need to perform GC
 

00:24:15.220 --> 00:24:17.190
periodically we need to perform GC
cycles in order to reclaim memory which

00:24:17.190 --> 00:24:17.200
cycles in order to reclaim memory which
 

00:24:17.200 --> 00:24:19.230
cycles in order to reclaim memory which
is consumed by unreachable objects so

00:24:19.230 --> 00:24:19.240
is consumed by unreachable objects so
 

00:24:19.240 --> 00:24:22.140
is consumed by unreachable objects so
that future object allocations can be

00:24:22.140 --> 00:24:22.150
that future object allocations can be
 

00:24:22.150 --> 00:24:22.560
that future object allocations can be
served

00:24:22.560 --> 00:24:22.570
served
 

00:24:22.570 --> 00:24:26.400
served
and since CC hill Android P was not

00:24:26.400 --> 00:24:26.410
and since CC hill Android P was not
 

00:24:26.410 --> 00:24:29.490
and since CC hill Android P was not
generational so all these GC cycles work

00:24:29.490 --> 00:24:29.500
generational so all these GC cycles work
 

00:24:29.500 --> 00:24:31.320
generational so all these GC cycles work
on all the reachable objects and

00:24:31.320 --> 00:24:31.330
on all the reachable objects and
 

00:24:31.330 --> 00:24:34.140
on all the reachable objects and
therefore I'm calling them full heap GC

00:24:34.140 --> 00:24:34.150
therefore I'm calling them full heap GC
 

00:24:34.150 --> 00:24:37.320
therefore I'm calling them full heap GC
cycles so when we start off with the

00:24:37.320 --> 00:24:37.330
cycles so when we start off with the
 

00:24:37.330 --> 00:24:41.130
cycles so when we start off with the
first GC cycle by the time we revisit

00:24:41.130 --> 00:24:41.140
first GC cycle by the time we revisit
 

00:24:41.140 --> 00:24:43.440
first GC cycle by the time we revisit
all the reachable objects we know

00:24:43.440 --> 00:24:43.450
all the reachable objects we know
 

00:24:43.450 --> 00:24:46.050
all the reachable objects we know
precisely which region has how many live

00:24:46.050 --> 00:24:46.060
precisely which region has how many live
 

00:24:46.060 --> 00:24:47.880
precisely which region has how many live
bytes in them and therefore we can

00:24:47.880 --> 00:24:47.890
bytes in them and therefore we can
 

00:24:47.890 --> 00:24:49.380
bytes in them and therefore we can
gather the liveness stats that I talked

00:24:49.380 --> 00:24:49.390
gather the liveness stats that I talked
 

00:24:49.390 --> 00:24:52.800
gather the liveness stats that I talked
about in the previous slide as a time

00:24:52.800 --> 00:24:52.810
about in the previous slide as a time
 

00:24:52.810 --> 00:24:53.280
about in the previous slide as a time
goes by

00:24:53.280 --> 00:24:53.290
goes by
 

00:24:53.290 --> 00:24:55.500
goes by
due to the execution of application

00:24:55.500 --> 00:24:55.510
due to the execution of application
 

00:24:55.510 --> 00:24:58.410
due to the execution of application
threads the Hume you tation would result

00:24:58.410 --> 00:24:58.420
threads the Hume you tation would result
 

00:24:58.420 --> 00:24:59.410
threads the Hume you tation would result
in more of

00:24:59.410 --> 00:24:59.420
in more of
 

00:24:59.420 --> 00:25:00.630
in more of
it's becoming unreachable and

00:25:00.630 --> 00:25:00.640
it's becoming unreachable and
 

00:25:00.640 --> 00:25:05.860
it's becoming unreachable and
unreachable however by the time the next

00:25:05.860 --> 00:25:05.870
unreachable however by the time the next
 

00:25:05.870 --> 00:25:08.800
unreachable however by the time the next
DC cycle is executed where you would

00:25:08.800 --> 00:25:08.810
DC cycle is executed where you would
 

00:25:08.810 --> 00:25:10.990
DC cycle is executed where you would
actually use the stats that you gathered

00:25:10.990 --> 00:25:11.000
actually use the stats that you gathered
 

00:25:11.000 --> 00:25:14.530
actually use the stats that you gathered
in the previous DC cycle those Klieman

00:25:14.530 --> 00:25:14.540
in the previous DC cycle those Klieman
 

00:25:14.540 --> 00:25:18.040
in the previous DC cycle those Klieman
stats no longer show you the the

00:25:18.040 --> 00:25:18.050
stats no longer show you the the
 

00:25:18.050 --> 00:25:21.610
stats no longer show you the the
liveness at that point in time this

00:25:21.610 --> 00:25:21.620
liveness at that point in time this
 

00:25:21.620 --> 00:25:23.950
liveness at that point in time this
leads to what Roland earlier described

00:25:23.950 --> 00:25:23.960
leads to what Roland earlier described
 

00:25:23.960 --> 00:25:26.680
leads to what Roland earlier described
floating garbage which is the

00:25:26.680 --> 00:25:26.690
floating garbage which is the
 

00:25:26.690 --> 00:25:28.720
floating garbage which is the
unreachable objects that the garbage

00:25:28.720 --> 00:25:28.730
unreachable objects that the garbage
 

00:25:28.730 --> 00:25:30.640
unreachable objects that the garbage
collector knows about but it cannot

00:25:30.640 --> 00:25:30.650
collector knows about but it cannot
 

00:25:30.650 --> 00:25:34.900
collector knows about but it cannot
collect them and of course as in the

00:25:34.900 --> 00:25:34.910
collect them and of course as in the
 

00:25:34.910 --> 00:25:37.120
collect them and of course as in the
previous DC cycle by the end of this GC

00:25:37.120 --> 00:25:37.130
previous DC cycle by the end of this GC
 

00:25:37.130 --> 00:25:38.950
previous DC cycle by the end of this GC
cycle also since we have gone through

00:25:38.950 --> 00:25:38.960
cycle also since we have gone through
 

00:25:38.960 --> 00:25:40.930
cycle also since we have gone through
all the live objects we gather the

00:25:40.930 --> 00:25:40.940
all the live objects we gather the
 

00:25:40.940 --> 00:25:43.210
all the live objects we gather the
liveness stats which then are used in

00:25:43.210 --> 00:25:43.220
liveness stats which then are used in
 

00:25:43.220 --> 00:25:45.330
liveness stats which then are used in
the next CC cycle and this goes and on

00:25:45.330 --> 00:25:45.340
the next CC cycle and this goes and on
 

00:25:45.340 --> 00:25:48.010
the next CC cycle and this goes and on
this is how decision-making works in

00:25:48.010 --> 00:25:48.020
this is how decision-making works in
 

00:25:48.020 --> 00:25:49.900
this is how decision-making works in
Android people now let's see how

00:25:49.900 --> 00:25:49.910
Android people now let's see how
 

00:25:49.910 --> 00:25:51.780
Android people now let's see how
introducing generations into this

00:25:51.780 --> 00:25:51.790
introducing generations into this
 

00:25:51.790 --> 00:25:55.960
introducing generations into this
affects the the decision-making for

00:25:55.960 --> 00:25:55.970
affects the the decision-making for
 

00:25:55.970 --> 00:25:59.530
affects the the decision-making for
region selection as Roland described

00:25:59.530 --> 00:25:59.540
region selection as Roland described
 

00:25:59.540 --> 00:26:02.410
region selection as Roland described
earlier the benefits of generation GC is

00:26:02.410 --> 00:26:02.420
earlier the benefits of generation GC is
 

00:26:02.420 --> 00:26:04.840
earlier the benefits of generation GC is
that we can reduce the number of full

00:26:04.840 --> 00:26:04.850
that we can reduce the number of full
 

00:26:04.850 --> 00:26:07.570
that we can reduce the number of full
heap GC cycles by replacing them with

00:26:07.570 --> 00:26:07.580
heap GC cycles by replacing them with
 

00:26:07.580 --> 00:26:10.060
heap GC cycles by replacing them with
more frequent young collections which

00:26:10.060 --> 00:26:10.070
more frequent young collections which
 

00:26:10.070 --> 00:26:11.590
more frequent young collections which
are much more light weighted as they

00:26:11.590 --> 00:26:11.600
are much more light weighted as they
 

00:26:11.600 --> 00:26:13.570
are much more light weighted as they
only work on young objects young

00:26:13.570 --> 00:26:13.580
only work on young objects young
 

00:26:13.580 --> 00:26:17.020
only work on young objects young
reachable objects and therefore what

00:26:17.020 --> 00:26:17.030
reachable objects and therefore what
 

00:26:17.030 --> 00:26:19.540
reachable objects and therefore what
this leads to is that you would have

00:26:19.540 --> 00:26:19.550
this leads to is that you would have
 

00:26:19.550 --> 00:26:22.540
this leads to is that you would have
lesser G full heap GC cycles but also

00:26:22.540 --> 00:26:22.550
lesser G full heap GC cycles but also
 

00:26:22.550 --> 00:26:25.090
lesser G full heap GC cycles but also
that the time lag between two full heap

00:26:25.090 --> 00:26:25.100
that the time lag between two full heap
 

00:26:25.100 --> 00:26:30.130
that the time lag between two full heap
GC cycles would increase and so given

00:26:30.130 --> 00:26:30.140
GC cycles would increase and so given
 

00:26:30.140 --> 00:26:32.800
GC cycles would increase and so given
that when we start execution the first

00:26:32.800 --> 00:26:32.810
that when we start execution the first
 

00:26:32.810 --> 00:26:35.470
that when we start execution the first
GC cycle being full heap DC cycle we

00:26:35.470 --> 00:26:35.480
GC cycle being full heap DC cycle we
 

00:26:35.480 --> 00:26:37.060
GC cycle being full heap DC cycle we
compute the liveness stats as I

00:26:37.060 --> 00:26:37.070
compute the liveness stats as I
 

00:26:37.070 --> 00:26:39.780
compute the liveness stats as I
described in the previous case however

00:26:39.780 --> 00:26:39.790
described in the previous case however
 

00:26:39.790 --> 00:26:43.270
described in the previous case however
every time when we perform young

00:26:43.270 --> 00:26:43.280
every time when we perform young
 

00:26:43.280 --> 00:26:45.610
every time when we perform young
collection we cannot update these stats

00:26:45.610 --> 00:26:45.620
collection we cannot update these stats
 

00:26:45.620 --> 00:26:48.310
collection we cannot update these stats
because we only go through young objects

00:26:48.310 --> 00:26:48.320
because we only go through young objects
 

00:26:48.320 --> 00:26:51.310
because we only go through young objects
and since we don't go through all the

00:26:51.310 --> 00:26:51.320
and since we don't go through all the
 

00:26:51.320 --> 00:26:53.530
and since we don't go through all the
reachable objects it's not possible to

00:26:53.530 --> 00:26:53.540
reachable objects it's not possible to
 

00:26:53.540 --> 00:26:56.670
reachable objects it's not possible to
you know update the liveness stats and

00:26:56.670 --> 00:26:56.680
you know update the liveness stats and
 

00:26:56.680 --> 00:26:59.980
you know update the liveness stats and
by the time we reach the next full heap

00:26:59.980 --> 00:26:59.990
by the time we reach the next full heap
 

00:26:59.990 --> 00:27:01.900
by the time we reach the next full heap
GC cycle where we actually use the

00:27:01.900 --> 00:27:01.910
GC cycle where we actually use the
 

00:27:01.910 --> 00:27:04.420
GC cycle where we actually use the
lioness stats they become much more

00:27:04.420 --> 00:27:04.430
lioness stats they become much more
 

00:27:04.430 --> 00:27:06.580
lioness stats they become much more
stale than what it would have happened

00:27:06.580 --> 00:27:06.590
stale than what it would have happened
 

00:27:06.590 --> 00:27:09.540
stale than what it would have happened
in case of Android B or earlier and

00:27:09.540 --> 00:27:09.550
in case of Android B or earlier and
 

00:27:09.550 --> 00:27:12.880
in case of Android B or earlier and
therefore it leads to larger amount of

00:27:12.880 --> 00:27:12.890
therefore it leads to larger amount of
 

00:27:12.890 --> 00:27:13.120
therefore it leads to larger amount of
flow

00:27:13.120 --> 00:27:13.130
flow
 

00:27:13.130 --> 00:27:17.400
flow
in garbage and this goes on on and on

00:27:17.400 --> 00:27:17.410
in garbage and this goes on on and on
 

00:27:17.410 --> 00:27:20.500
in garbage and this goes on on and on
given the limited availability of memory

00:27:20.500 --> 00:27:20.510
given the limited availability of memory
 

00:27:20.510 --> 00:27:23.650
given the limited availability of memory
on you know for mobile devices it makes

00:27:23.650 --> 00:27:23.660
on you know for mobile devices it makes
 

00:27:23.660 --> 00:27:27.040
on you know for mobile devices it makes
sense to ensure that this floating

00:27:27.040 --> 00:27:27.050
sense to ensure that this floating
 

00:27:27.050 --> 00:27:30.400
sense to ensure that this floating
garbage is minimally and and the cause

00:27:30.400 --> 00:27:30.410
garbage is minimally and and the cause
 

00:27:30.410 --> 00:27:33.010
garbage is minimally and and the cause
of that we identified is clear that the

00:27:33.010 --> 00:27:33.020
of that we identified is clear that the
 

00:27:33.020 --> 00:27:35.710
of that we identified is clear that the
outer outdated liveness stats is what is

00:27:35.710 --> 00:27:35.720
outer outdated liveness stats is what is
 

00:27:35.720 --> 00:27:40.000
outer outdated liveness stats is what is
hurting us so we fix the issue by

00:27:40.000 --> 00:27:40.010
hurting us so we fix the issue by
 

00:27:40.010 --> 00:27:42.910
hurting us so we fix the issue by
improving the heap compaction by

00:27:42.910 --> 00:27:42.920
improving the heap compaction by
 

00:27:42.920 --> 00:27:46.060
improving the heap compaction by
replacing the full heap GC cycle with

00:27:46.060 --> 00:27:46.070
replacing the full heap GC cycle with
 

00:27:46.070 --> 00:27:48.490
replacing the full heap GC cycle with
another algorithm which you which is

00:27:48.490 --> 00:27:48.500
another algorithm which you which is
 

00:27:48.500 --> 00:27:50.980
another algorithm which you which is
two-faced where the first phase would

00:27:50.980 --> 00:27:50.990
two-faced where the first phase would
 

00:27:50.990 --> 00:27:54.450
two-faced where the first phase would
trace all the life reachable objects and

00:27:54.450 --> 00:27:54.460
trace all the life reachable objects and
 

00:27:54.460 --> 00:27:57.640
trace all the life reachable objects and
compute the liveness stats and then the

00:27:57.640 --> 00:27:57.650
compute the liveness stats and then the
 

00:27:57.650 --> 00:27:59.860
compute the liveness stats and then the
second phase based on these up-to-date

00:27:59.860 --> 00:27:59.870
second phase based on these up-to-date
 

00:27:59.870 --> 00:28:02.830
second phase based on these up-to-date
liveness stats figures out feed region

00:28:02.830 --> 00:28:02.840
liveness stats figures out feed region
 

00:28:02.840 --> 00:28:04.870
liveness stats figures out feed region
which regions deserve to be compacted

00:28:04.870 --> 00:28:04.880
which regions deserve to be compacted
 

00:28:04.880 --> 00:28:07.690
which regions deserve to be compacted
and then performs compaction this way

00:28:07.690 --> 00:28:07.700
and then performs compaction this way
 

00:28:07.700 --> 00:28:10.690
and then performs compaction this way
very both the benefits of generations GC

00:28:10.690 --> 00:28:10.700
very both the benefits of generations GC
 

00:28:10.700 --> 00:28:12.790
very both the benefits of generations GC
by ensuring that young collection

00:28:12.790 --> 00:28:12.800
by ensuring that young collection
 

00:28:12.800 --> 00:28:15.820
by ensuring that young collection
remains as it is as well as we fix the

00:28:15.820 --> 00:28:15.830
remains as it is as well as we fix the
 

00:28:15.830 --> 00:28:20.230
remains as it is as well as we fix the
problem of outdated lamina stats let's

00:28:20.230 --> 00:28:20.240
problem of outdated lamina stats let's
 

00:28:20.240 --> 00:28:22.540
problem of outdated lamina stats let's
see using the same example that rollin

00:28:22.540 --> 00:28:22.550
see using the same example that rollin
 

00:28:22.550 --> 00:28:25.480
see using the same example that rollin
was earlier using how this new algorithm

00:28:25.480 --> 00:28:25.490
was earlier using how this new algorithm
 

00:28:25.490 --> 00:28:29.410
was earlier using how this new algorithm
works so let's for let's assume that our

00:28:29.410 --> 00:28:29.420
works so let's for let's assume that our
 

00:28:29.420 --> 00:28:31.960
works so let's for let's assume that our
evacuation criteria criteria for any

00:28:31.960 --> 00:28:31.970
evacuation criteria criteria for any
 

00:28:31.970 --> 00:28:35.020
evacuation criteria criteria for any
region is that if it has less than three

00:28:35.020 --> 00:28:35.030
region is that if it has less than three
 

00:28:35.030 --> 00:28:37.390
region is that if it has less than three
live objects in it then it deserves to

00:28:37.390 --> 00:28:37.400
live objects in it then it deserves to
 

00:28:37.400 --> 00:28:40.630
live objects in it then it deserves to
be compacted so in this example as you

00:28:40.630 --> 00:28:40.640
be compacted so in this example as you
 

00:28:40.640 --> 00:28:43.150
be compacted so in this example as you
can see that all the four regions which

00:28:43.150 --> 00:28:43.160
can see that all the four regions which
 

00:28:43.160 --> 00:28:45.370
can see that all the four regions which
are in use they have less than three

00:28:45.370 --> 00:28:45.380
are in use they have less than three
 

00:28:45.380 --> 00:28:48.850
are in use they have less than three
live objects in them so by the time we

00:28:48.850 --> 00:28:48.860
live objects in them so by the time we
 

00:28:48.860 --> 00:28:50.830
live objects in them so by the time we
finish the first phase which goes

00:28:50.830 --> 00:28:50.840
finish the first phase which goes
 

00:28:50.840 --> 00:28:53.020
finish the first phase which goes
through all the reachable objects we

00:28:53.020 --> 00:28:53.030
through all the reachable objects we
 

00:28:53.030 --> 00:28:55.480
through all the reachable objects we
have determined that all the four

00:28:55.480 --> 00:28:55.490
have determined that all the four
 

00:28:55.490 --> 00:28:58.480
have determined that all the four
regions have the liveness stats less

00:28:58.480 --> 00:28:58.490
regions have the liveness stats less
 

00:28:58.490 --> 00:29:01.060
regions have the liveness stats less
than three objects and therefore they

00:29:01.060 --> 00:29:01.070
than three objects and therefore they
 

00:29:01.070 --> 00:29:04.180
than three objects and therefore they
deserve to be evacuated and by the time

00:29:04.180 --> 00:29:04.190
deserve to be evacuated and by the time
 

00:29:04.190 --> 00:29:06.640
deserve to be evacuated and by the time
we finish our fully DC cycle we managed

00:29:06.640 --> 00:29:06.650
we finish our fully DC cycle we managed
 

00:29:06.650 --> 00:29:08.530
we finish our fully DC cycle we managed
to move all of them into a single region

00:29:08.530 --> 00:29:08.540
to move all of them into a single region
 

00:29:08.540 --> 00:29:10.270
to move all of them into a single region
thereby reclaiming all the four

00:29:10.270 --> 00:29:10.280
thereby reclaiming all the four
 

00:29:10.280 --> 00:29:14.700
thereby reclaiming all the four
previously used regions back coming to

00:29:14.700 --> 00:29:14.710
previously used regions back coming to
 

00:29:14.710 --> 00:29:18.430
previously used regions back coming to
what should it lead to the in in terms

00:29:18.430 --> 00:29:18.440
what should it lead to the in in terms
 

00:29:18.440 --> 00:29:21.130
what should it lead to the in in terms
of improvement the direct improvement of

00:29:21.130 --> 00:29:21.140
of improvement the direct improvement of
 

00:29:21.140 --> 00:29:23.290
of improvement the direct improvement of
this change is that after every full

00:29:23.290 --> 00:29:23.300
this change is that after every full
 

00:29:23.300 --> 00:29:26.380
this change is that after every full
heap GC cycle we should be

00:29:26.380 --> 00:29:26.390
heap GC cycle we should be
 

00:29:26.390 --> 00:29:29.020
heap GC cycle we should be
collecting more free bytes BRAC back

00:29:29.020 --> 00:29:29.030
collecting more free bytes BRAC back
 

00:29:29.030 --> 00:29:31.780
collecting more free bytes BRAC back
from the garbage collector and to

00:29:31.780 --> 00:29:31.790
from the garbage collector and to
 

00:29:31.790 --> 00:29:33.640
from the garbage collector and to
measure that we use the same set of

00:29:33.640 --> 00:29:33.650
measure that we use the same set of
 

00:29:33.650 --> 00:29:35.620
measure that we use the same set of
applications and benchmark that Roland

00:29:35.620 --> 00:29:35.630
applications and benchmark that Roland
 

00:29:35.630 --> 00:29:37.720
applications and benchmark that Roland
is earlier described and as you can see

00:29:37.720 --> 00:29:37.730
is earlier described and as you can see
 

00:29:37.730 --> 00:29:40.840
is earlier described and as you can see
that 4-h to the average freed bytes

00:29:40.840 --> 00:29:40.850
that 4-h to the average freed bytes
 

00:29:40.850 --> 00:29:42.940
that 4-h to the average freed bytes
improved by more than one hundred and

00:29:42.940 --> 00:29:42.950
improved by more than one hundred and
 

00:29:42.950 --> 00:29:45.130
improved by more than one hundred and
seventy eight percent whereas four

00:29:45.130 --> 00:29:45.140
seventy eight percent whereas four
 

00:29:45.140 --> 00:29:46.690
seventy eight percent whereas four
sheets it improved by sixty eight

00:29:46.690 --> 00:29:46.700
sheets it improved by sixty eight
 

00:29:46.700 --> 00:29:51.760
sheets it improved by sixty eight
percent that's pretty good in terms of

00:29:51.760 --> 00:29:51.770
percent that's pretty good in terms of
 

00:29:51.770 --> 00:29:54.190
percent that's pretty good in terms of
impact of all the both the DC

00:29:54.190 --> 00:29:54.200
impact of all the both the DC
 

00:29:54.200 --> 00:29:56.140
impact of all the both the DC
improvements that Roland and I talked

00:29:56.140 --> 00:29:56.150
improvements that Roland and I talked
 

00:29:56.150 --> 00:29:59.280
improvements that Roland and I talked
about on the overall improvement on the

00:29:59.280 --> 00:29:59.290
about on the overall improvement on the
 

00:29:59.290 --> 00:30:02.860
about on the overall improvement on the
benchmark score we again ran some

00:30:02.860 --> 00:30:02.870
benchmark score we again ran some
 

00:30:02.870 --> 00:30:06.520
benchmark score we again ran some
benchmarks and we observed that 4-h to

00:30:06.520 --> 00:30:06.530
benchmarks and we observed that 4-h to
 

00:30:06.530 --> 00:30:10.320
benchmarks and we observed that 4-h to
the the spore improved by more than 15%

00:30:10.320 --> 00:30:10.330
the the spore improved by more than 15%
 

00:30:10.330 --> 00:30:13.630
the the spore improved by more than 15%
for both arm and I'm 64 whereas four

00:30:13.630 --> 00:30:13.640
for both arm and I'm 64 whereas four
 

00:30:13.640 --> 00:30:16.260
for both arm and I'm 64 whereas four
sheets is improved by more than 5%

00:30:16.260 --> 00:30:16.270
sheets is improved by more than 5%
 

00:30:16.270 --> 00:30:19.240
sheets is improved by more than 5%
all right enough dragging about

00:30:19.240 --> 00:30:19.250
all right enough dragging about
 

00:30:19.250 --> 00:30:21.820
all right enough dragging about
improvements in you let me touch about

00:30:21.820 --> 00:30:21.830
improvements in you let me touch about
 

00:30:21.830 --> 00:30:24.130
improvements in you let me touch about
touch a different operator let's talk

00:30:24.130 --> 00:30:24.140
touch a different operator let's talk
 

00:30:24.140 --> 00:30:26.740
touch a different operator let's talk
about object allocation and object

00:30:26.740 --> 00:30:26.750
about object allocation and object
 

00:30:26.750 --> 00:30:30.070
about object allocation and object
pooling before I conclude I'm sure many

00:30:30.070 --> 00:30:30.080
pooling before I conclude I'm sure many
 

00:30:30.080 --> 00:30:32.170
pooling before I conclude I'm sure many
of you must have experienced this you

00:30:32.170 --> 00:30:32.180
of you must have experienced this you
 

00:30:32.180 --> 00:30:35.530
of you must have experienced this you
start writing an app and with standard

00:30:35.530 --> 00:30:35.540
start writing an app and with standard
 

00:30:35.540 --> 00:30:37.240
start writing an app and with standard
object allocation you know simple way

00:30:37.240 --> 00:30:37.250
object allocation you know simple way
 

00:30:37.250 --> 00:30:40.030
object allocation you know simple way
using new operator but as it blows more

00:30:40.030 --> 00:30:40.040
using new operator but as it blows more
 

00:30:40.040 --> 00:30:42.820
using new operator but as it blows more
and more you start either observing that

00:30:42.820 --> 00:30:42.830
and more you start either observing that
 

00:30:42.830 --> 00:30:45.130
and more you start either observing that
there's just too much GC activity going

00:30:45.130 --> 00:30:45.140
there's just too much GC activity going
 

00:30:45.140 --> 00:30:47.080
there's just too much GC activity going
on or you are spending too much time

00:30:47.080 --> 00:30:47.090
on or you are spending too much time
 

00:30:47.090 --> 00:30:49.660
on or you are spending too much time
allocating new objects or maybe just

00:30:49.660 --> 00:30:49.670
allocating new objects or maybe just
 

00:30:49.670 --> 00:30:52.600
allocating new objects or maybe just
somebody said that GC is in effect

00:30:52.600 --> 00:30:52.610
somebody said that GC is in effect
 

00:30:52.610 --> 00:30:54.490
somebody said that GC is in effect
inefficient in general and we should

00:30:54.490 --> 00:30:54.500
inefficient in general and we should
 

00:30:54.500 --> 00:30:57.820
inefficient in general and we should
avoid it and then an idea comes to a

00:30:57.820 --> 00:30:57.830
avoid it and then an idea comes to a
 

00:30:57.830 --> 00:31:00.850
avoid it and then an idea comes to a
mind what if I can cheat the garbage

00:31:00.850 --> 00:31:00.860
mind what if I can cheat the garbage
 

00:31:00.860 --> 00:31:03.250
mind what if I can cheat the garbage
collector what if instead of giving

00:31:03.250 --> 00:31:03.260
collector what if instead of giving
 

00:31:03.260 --> 00:31:05.830
collector what if instead of giving
those L objects once there once I am

00:31:05.830 --> 00:31:05.840
those L objects once there once I am
 

00:31:05.840 --> 00:31:08.740
those L objects once there once I am
done using them when moving them back to

00:31:08.740 --> 00:31:08.750
done using them when moving them back to
 

00:31:08.750 --> 00:31:10.960
done using them when moving them back to
the garbage collector I could just keep

00:31:10.960 --> 00:31:10.970
the garbage collector I could just keep
 

00:31:10.970 --> 00:31:14.350
the garbage collector I could just keep
them around in pools and use them again

00:31:14.350 --> 00:31:14.360
them around in pools and use them again
 

00:31:14.360 --> 00:31:16.020
them around in pools and use them again
and again

00:31:16.020 --> 00:31:16.030
and again
 

00:31:16.030 --> 00:31:18.760
and again
isn't it obvious that they should lead

00:31:18.760 --> 00:31:18.770
isn't it obvious that they should lead
 

00:31:18.770 --> 00:31:20.800
isn't it obvious that they should lead
to less garbage and therefore less GC

00:31:20.800 --> 00:31:20.810
to less garbage and therefore less GC
 

00:31:20.810 --> 00:31:23.560
to less garbage and therefore less GC
activity and also that we would be

00:31:23.560 --> 00:31:23.570
activity and also that we would be
 

00:31:23.570 --> 00:31:26.500
activity and also that we would be
avoiding the allocation cost given that

00:31:26.500 --> 00:31:26.510
avoiding the allocation cost given that
 

00:31:26.510 --> 00:31:29.110
avoiding the allocation cost given that
in the last few years the garbage

00:31:29.110 --> 00:31:29.120
in the last few years the garbage
 

00:31:29.120 --> 00:31:30.670
in the last few years the garbage
collector Android garbage collector has

00:31:30.670 --> 00:31:30.680
collector Android garbage collector has
 

00:31:30.680 --> 00:31:33.190
collector Android garbage collector has
him has made several improvements we

00:31:33.190 --> 00:31:33.200
him has made several improvements we
 

00:31:33.200 --> 00:31:35.530
him has made several improvements we
thought it's nice time to actually real

00:31:35.530 --> 00:31:35.540
thought it's nice time to actually real
 

00:31:35.540 --> 00:31:37.780
thought it's nice time to actually real
open to it and see if it really makes

00:31:37.780 --> 00:31:37.790
open to it and see if it really makes
 

00:31:37.790 --> 00:31:40.620
open to it and see if it really makes
sense to cool objects or not

00:31:40.620 --> 00:31:40.630
sense to cool objects or not
 

00:31:40.630 --> 00:31:44.350
sense to cool objects or not
so we developed a micro benchmark with

00:31:44.350 --> 00:31:44.360
so we developed a micro benchmark with
 

00:31:44.360 --> 00:31:48.160
so we developed a micro benchmark with
the idea of basically gathering two sets

00:31:48.160 --> 00:31:48.170
the idea of basically gathering two sets
 

00:31:48.170 --> 00:31:50.650
the idea of basically gathering two sets
of metrics one is what is the allocation

00:31:50.650 --> 00:31:50.660
of metrics one is what is the allocation
 

00:31:50.660 --> 00:31:54.460
of metrics one is what is the allocation
overhead for standard allocation versus

00:31:54.460 --> 00:31:54.470
overhead for standard allocation versus
 

00:31:54.470 --> 00:31:58.240
overhead for standard allocation versus
acquiring from object pool and second is

00:31:58.240 --> 00:31:58.250
acquiring from object pool and second is
 

00:31:58.250 --> 00:32:00.970
acquiring from object pool and second is
that what is the overall CPU overhead of

00:32:00.970 --> 00:32:00.980
that what is the overall CPU overhead of
 

00:32:00.980 --> 00:32:04.360
that what is the overall CPU overhead of
completing the micro benchmark so

00:32:04.360 --> 00:32:04.370
completing the micro benchmark so
 

00:32:04.370 --> 00:32:07.030
completing the micro benchmark so
starting with or location overhead as

00:32:07.030 --> 00:32:07.040
starting with or location overhead as
 

00:32:07.040 --> 00:32:09.550
starting with or location overhead as
you can see in this chart that as you

00:32:09.550 --> 00:32:09.560
you can see in this chart that as you
 

00:32:09.560 --> 00:32:10.960
you can see in this chart that as you
increase the number of fields of the

00:32:10.960 --> 00:32:10.970
increase the number of fields of the
 

00:32:10.970 --> 00:32:13.690
increase the number of fields of the
object that you are pooling the overhead

00:32:13.690 --> 00:32:13.700
object that you are pooling the overhead
 

00:32:13.700 --> 00:32:16.780
object that you are pooling the overhead
of pooling and object versus standard

00:32:16.780 --> 00:32:16.790
of pooling and object versus standard
 

00:32:16.790 --> 00:32:19.060
of pooling and object versus standard
allocation is almost the same

00:32:19.060 --> 00:32:19.070
allocation is almost the same
 

00:32:19.070 --> 00:32:21.550
allocation is almost the same
so from allocation overheads point of

00:32:21.550 --> 00:32:21.560
so from allocation overheads point of
 

00:32:21.560 --> 00:32:23.230
so from allocation overheads point of
view it actually does not make much

00:32:23.230 --> 00:32:23.240
view it actually does not make much
 

00:32:23.240 --> 00:32:27.970
view it actually does not make much
sense to pool the objects going to the

00:32:27.970 --> 00:32:27.980
sense to pool the objects going to the
 

00:32:27.980 --> 00:32:31.750
sense to pool the objects going to the
CPU overhead this chart shows the best

00:32:31.750 --> 00:32:31.760
CPU overhead this chart shows the best
 

00:32:31.760 --> 00:32:35.440
CPU overhead this chart shows the best
case for cooling and obviously as

00:32:35.440 --> 00:32:35.450
case for cooling and obviously as
 

00:32:35.450 --> 00:32:37.420
case for cooling and obviously as
expected the best case was that

00:32:37.420 --> 00:32:37.430
expected the best case was that
 

00:32:37.430 --> 00:32:39.130
expected the best case was that
basically there is no garbage collector

00:32:39.130 --> 00:32:39.140
basically there is no garbage collector
 

00:32:39.140 --> 00:32:41.710
basically there is no garbage collector
collection activity at all and therefore

00:32:41.710 --> 00:32:41.720
collection activity at all and therefore
 

00:32:41.720 --> 00:32:44.980
collection activity at all and therefore
the total CPU overhead of completing the

00:32:44.980 --> 00:32:44.990
the total CPU overhead of completing the
 

00:32:44.990 --> 00:32:48.490
the total CPU overhead of completing the
benchmark in case of pooling was lesser

00:32:48.490 --> 00:32:48.500
benchmark in case of pooling was lesser
 

00:32:48.500 --> 00:32:52.510
benchmark in case of pooling was lesser
than standard allocation however there

00:32:52.510 --> 00:32:52.520
than standard allocation however there
 

00:32:52.520 --> 00:32:55.030
than standard allocation however there
is a catch the catch is that the best

00:32:55.030 --> 00:32:55.040
is a catch the catch is that the best
 

00:32:55.040 --> 00:32:57.280
is a catch the catch is that the best
case loses its practicality as soon as

00:32:57.280 --> 00:32:57.290
case loses its practicality as soon as
 

00:32:57.290 --> 00:32:59.530
case loses its practicality as soon as
you go beyond a test program and start

00:32:59.530 --> 00:32:59.540
you go beyond a test program and start
 

00:32:59.540 --> 00:33:02.140
you go beyond a test program and start
having more and more complicated code by

00:33:02.140 --> 00:33:02.150
having more and more complicated code by
 

00:33:02.150 --> 00:33:04.810
having more and more complicated code by
because you can't be pulling every type

00:33:04.810 --> 00:33:04.820
because you can't be pulling every type
 

00:33:04.820 --> 00:33:07.690
because you can't be pulling every type
of object in your app you just can't do

00:33:07.690 --> 00:33:07.700
of object in your app you just can't do
 

00:33:07.700 --> 00:33:07.900
of object in your app you just can't do
that

00:33:07.900 --> 00:33:07.910
that
 

00:33:07.910 --> 00:33:10.720
that
and therefore we thought we'll make the

00:33:10.720 --> 00:33:10.730
and therefore we thought we'll make the
 

00:33:10.730 --> 00:33:14.200
and therefore we thought we'll make the
benchmark more reasonable and so we

00:33:14.200 --> 00:33:14.210
benchmark more reasonable and so we
 

00:33:14.210 --> 00:33:16.900
benchmark more reasonable and so we
added constant short-lived allocations

00:33:16.900 --> 00:33:16.910
added constant short-lived allocations
 

00:33:16.910 --> 00:33:20.650
added constant short-lived allocations
in between each iteration to see how it

00:33:20.650 --> 00:33:20.660
in between each iteration to see how it
 

00:33:20.660 --> 00:33:23.620
in between each iteration to see how it
effects it and as you can see that the

00:33:23.620 --> 00:33:23.630
effects it and as you can see that the
 

00:33:23.630 --> 00:33:26.290
effects it and as you can see that the
gap between pooling versus standard

00:33:26.290 --> 00:33:26.300
gap between pooling versus standard
 

00:33:26.300 --> 00:33:30.340
gap between pooling versus standard
allocation has reduced we've been one

00:33:30.340 --> 00:33:30.350
allocation has reduced we've been one
 

00:33:30.350 --> 00:33:32.890
allocation has reduced we've been one
step further and we made that a

00:33:32.890 --> 00:33:32.900
step further and we made that a
 

00:33:32.900 --> 00:33:35.350
step further and we made that a
short-lived allocation proportional to

00:33:35.350 --> 00:33:35.360
short-lived allocation proportional to
 

00:33:35.360 --> 00:33:36.730
short-lived allocation proportional to
the size of the object that you are

00:33:36.730 --> 00:33:36.740
the size of the object that you are
 

00:33:36.740 --> 00:33:39.790
the size of the object that you are
pulling and now as you can see after a

00:33:39.790 --> 00:33:39.800
pulling and now as you can see after a
 

00:33:39.800 --> 00:33:43.330
pulling and now as you can see after a
certain size the overhead of cooling is

00:33:43.330 --> 00:33:43.340
certain size the overhead of cooling is
 

00:33:43.340 --> 00:33:47.320
certain size the overhead of cooling is
more than standard allocation and the

00:33:47.320 --> 00:33:47.330
more than standard allocation and the
 

00:33:47.330 --> 00:33:49.840
more than standard allocation and the
main reason behind this is that even

00:33:49.840 --> 00:33:49.850
main reason behind this is that even
 

00:33:49.850 --> 00:33:52.120
main reason behind this is that even
though by pooling you are reducing the

00:33:52.120 --> 00:33:52.130
though by pooling you are reducing the
 

00:33:52.130 --> 00:33:52.649
though by pooling you are reducing the
number of

00:33:52.649 --> 00:33:52.659
number of
 

00:33:52.659 --> 00:33:56.159
number of
GC cycles that that's involved but you

00:33:56.159 --> 00:33:56.169
GC cycles that that's involved but you
 

00:33:56.169 --> 00:33:58.229
GC cycles that that's involved but you
are increasing the memory footprint of

00:33:58.229 --> 00:33:58.239
are increasing the memory footprint of
 

00:33:58.239 --> 00:34:00.690
are increasing the memory footprint of
your program you have more objects each

00:34:00.690 --> 00:34:00.700
your program you have more objects each
 

00:34:00.700 --> 00:34:06.330
your program you have more objects each
time to collect or to process and of

00:34:06.330 --> 00:34:06.340
time to collect or to process and of
 

00:34:06.340 --> 00:34:07.859
time to collect or to process and of
course in addition to higher more

00:34:07.859 --> 00:34:07.869
course in addition to higher more
 

00:34:07.869 --> 00:34:09.089
course in addition to higher more
footprints there are many other

00:34:09.089 --> 00:34:09.099
footprints there are many other
 

00:34:09.099 --> 00:34:12.210
footprints there are many other
disadvantages too like you bring back

00:34:12.210 --> 00:34:12.220
disadvantages too like you bring back
 

00:34:12.220 --> 00:34:14.039
disadvantages too like you bring back
all the nightmares of double free and

00:34:14.039 --> 00:34:14.049
all the nightmares of double free and
 

00:34:14.049 --> 00:34:17.089
all the nightmares of double free and
memory leaks back and also given the

00:34:17.089 --> 00:34:17.099
memory leaks back and also given the
 

00:34:17.099 --> 00:34:20.279
memory leaks back and also given the
narrow gap between allocation standard

00:34:20.279 --> 00:34:20.289
narrow gap between allocation standard
 

00:34:20.289 --> 00:34:22.559
narrow gap between allocation standard
allocation and pooling it may it is very

00:34:22.559 --> 00:34:22.569
allocation and pooling it may it is very
 

00:34:22.569 --> 00:34:25.020
allocation and pooling it may it is very
critical that your implementation of the

00:34:25.020 --> 00:34:25.030
critical that your implementation of the
 

00:34:25.030 --> 00:34:27.240
critical that your implementation of the
pool itself is efficient otherwise

00:34:27.240 --> 00:34:27.250
pool itself is efficient otherwise
 

00:34:27.250 --> 00:34:31.639
pool itself is efficient otherwise
pooling would very quickly become more

00:34:31.639 --> 00:34:31.649
pooling would very quickly become more
 

00:34:31.649 --> 00:34:34.529
pooling would very quickly become more
more inefficient as compared to standard

00:34:34.529 --> 00:34:34.539
more inefficient as compared to standard
 

00:34:34.539 --> 00:34:39.210
more inefficient as compared to standard
allocation so our recommendation is that

00:34:39.210 --> 00:34:39.220
allocation so our recommendation is that
 

00:34:39.220 --> 00:34:40.889
allocation so our recommendation is that
please don't use it unless you are

00:34:40.889 --> 00:34:40.899
please don't use it unless you are
 

00:34:40.899 --> 00:34:43.200
please don't use it unless you are
really sure of the benefits and the best

00:34:43.200 --> 00:34:43.210
really sure of the benefits and the best
 

00:34:43.210 --> 00:34:45.619
really sure of the benefits and the best
way to be sure of benefits is to measure

00:34:45.619 --> 00:34:45.629
way to be sure of benefits is to measure
 

00:34:45.629 --> 00:34:50.639
way to be sure of benefits is to measure
if measure when you want to introduce a

00:34:50.639 --> 00:34:50.649
if measure when you want to introduce a
 

00:34:50.649 --> 00:34:52.740
if measure when you want to introduce a
new pool to a program see if it benefits

00:34:52.740 --> 00:34:52.750
new pool to a program see if it benefits
 

00:34:52.750 --> 00:34:58.559
new pool to a program see if it benefits
you and then only use it however I still

00:34:58.559 --> 00:34:58.569
you and then only use it however I still
 

00:34:58.569 --> 00:35:00.630
you and then only use it however I still
would say that there are some corner

00:35:00.630 --> 00:35:00.640
would say that there are some corner
 

00:35:00.640 --> 00:35:02.160
would say that there are some corner
cases where it could be useful right so

00:35:02.160 --> 00:35:02.170
cases where it could be useful right so
 

00:35:02.170 --> 00:35:04.950
cases where it could be useful right so
for instance if you are if your app has

00:35:04.950 --> 00:35:04.960
for instance if you are if your app has
 

00:35:04.960 --> 00:35:07.859
for instance if you are if your app has
a requirement where very large objects

00:35:07.859 --> 00:35:07.869
a requirement where very large objects
 

00:35:07.869 --> 00:35:11.190
a requirement where very large objects
need to be used and then it may make

00:35:11.190 --> 00:35:11.200
need to be used and then it may make
 

00:35:11.200 --> 00:35:13.049
need to be used and then it may make
sense to pull them or if there are

00:35:13.049 --> 00:35:13.059
sense to pull them or if there are
 

00:35:13.059 --> 00:35:16.049
sense to pull them or if there are
thread-local objects which get allocated

00:35:16.049 --> 00:35:16.059
thread-local objects which get allocated
 

00:35:16.059 --> 00:35:18.059
thread-local objects which get allocated
and then dropped on the floor at a very

00:35:18.059 --> 00:35:18.069
and then dropped on the floor at a very
 

00:35:18.069 --> 00:35:20.130
and then dropped on the floor at a very
high frequency then also it may make

00:35:20.130 --> 00:35:20.140
high frequency then also it may make
 

00:35:20.140 --> 00:35:22.410
high frequency then also it may make
sense to pull them but the the peak

00:35:22.410 --> 00:35:22.420
sense to pull them but the the peak
 

00:35:22.420 --> 00:35:25.260
sense to pull them but the the peak
point is please measure before deciding

00:35:25.260 --> 00:35:25.270
point is please measure before deciding
 

00:35:25.270 --> 00:35:32.250
point is please measure before deciding
to use them okay so to pre cap we talked

00:35:32.250 --> 00:35:32.260
to use them okay so to pre cap we talked
 

00:35:32.260 --> 00:35:33.900
to use them okay so to pre cap we talked
about how we improve the app startup

00:35:33.900 --> 00:35:33.910
about how we improve the app startup
 

00:35:33.910 --> 00:35:37.589
about how we improve the app startup
time by into by using cloud profiles by

00:35:37.589 --> 00:35:37.599
time by into by using cloud profiles by
 

00:35:37.599 --> 00:35:40.230
time by into by using cloud profiles by
introduced improving the app images and

00:35:40.230 --> 00:35:40.240
introduced improving the app images and
 

00:35:40.240 --> 00:35:43.589
introduced improving the app images and
by introducing the app process pools on

00:35:43.589 --> 00:35:43.599
by introducing the app process pools on
 

00:35:43.599 --> 00:35:46.049
by introducing the app process pools on
the GCS front we already have fast

00:35:46.049 --> 00:35:46.059
the GCS front we already have fast
 

00:35:46.059 --> 00:35:48.269
the GCS front we already have fast
object allocations since or Android

00:35:48.269 --> 00:35:48.279
object allocations since or Android
 

00:35:48.279 --> 00:35:51.150
object allocations since or Android
audio and starting with you we have

00:35:51.150 --> 00:35:51.160
audio and starting with you we have
 

00:35:51.160 --> 00:35:52.710
audio and starting with you we have
introduced the concept of generational

00:35:52.710 --> 00:35:52.720
introduced the concept of generational
 

00:35:52.720 --> 00:35:54.839
introduced the concept of generational
garbage collection and also we improve

00:35:54.839 --> 00:35:54.849
garbage collection and also we improve
 

00:35:54.849 --> 00:35:56.579
garbage collection and also we improve
the heap compaction using the two phase

00:35:56.579 --> 00:35:56.589
the heap compaction using the two phase
 

00:35:56.589 --> 00:35:59.220
the heap compaction using the two phase
algorithm that I talked about and since

00:35:59.220 --> 00:35:59.230
algorithm that I talked about and since
 

00:35:59.230 --> 00:36:01.200
algorithm that I talked about and since
it is our endeavour to always keep

00:36:01.200 --> 00:36:01.210
it is our endeavour to always keep
 

00:36:01.210 --> 00:36:05.010
it is our endeavour to always keep
improving the arts performance we expect

00:36:05.010 --> 00:36:05.020
improving the arts performance we expect
 

00:36:05.020 --> 00:36:07.680
improving the arts performance we expect
we will continue to work on these areas

00:36:07.680 --> 00:36:07.690
we will continue to work on these areas
 

00:36:07.690 --> 00:36:08.970
we will continue to work on these areas
and you can expect to have more

00:36:08.970 --> 00:36:08.980
and you can expect to have more
 

00:36:08.980 --> 00:36:11.480
and you can expect to have more
improvements in the future to follow

00:36:11.480 --> 00:36:11.490
improvements in the future to follow
 

00:36:11.490 --> 00:36:14.190
improvements in the future to follow
with that thanks a lot for ending the

00:36:14.190 --> 00:36:14.200
with that thanks a lot for ending the
 

00:36:14.200 --> 00:36:15.960
with that thanks a lot for ending the
presentation I hope it was useful

00:36:15.960 --> 00:36:15.970
presentation I hope it was useful
 

00:36:15.970 --> 00:36:34.020
presentation I hope it was useful
[Music]

00:36:34.020 --> 00:36:34.030
[Music]
 

00:36:34.030 --> 00:36:34.840
[Music]
you

00:36:34.840 --> 00:36:34.850
you
 

00:36:34.850 --> 00:36:37.869
you
[Music]

