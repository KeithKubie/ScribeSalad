WEBVTT
Kind: captions
Language: en

00:00:01.003 --> 00:00:03.844
Voiceover: This right here is a
simulation that was created

00:00:03.859 --> 00:00:06.732
by Peter Collingridge using the

00:00:06.732 --> 00:00:09.397
Khan Academy computer science scratch pad

00:00:09.397 --> 00:00:13.763
to better understand why
we divide by n minus one

00:00:13.763 --> 00:00:18.067
when we calculate an
unbiased sample variance.

00:00:18.067 --> 00:00:20.529
When we are in an unbiased
way trying to estimate

00:00:20.529 --> 00:00:22.545
the true population variance.

00:00:22.545 --> 00:00:24.627
So what this simulation does is first

00:00:24.627 --> 00:00:27.404
it constructs a population distribution,

00:00:27.404 --> 00:00:28.428
a random one,

00:00:28.428 --> 00:00:29.788
and every time you go to it,

00:00:29.788 --> 00:00:31.860
it will be a different
population distribution.

00:00:31.860 --> 00:00:34.131
This one has a population of 383,

00:00:34.131 --> 00:00:35.891
and then it calculates the parameters

00:00:35.891 --> 00:00:37.716
for that population directly from it.

00:00:37.716 --> 00:00:41.515
the mean is 10 point nine the
variance is 25 point five.

00:00:41.515 --> 00:00:43.868
and then it uses that population

00:00:43.868 --> 00:00:47.437
and samples from it and it does samples

00:00:47.437 --> 00:00:49.907
of size two, three, four,
five, all the way up to 10,

00:00:49.907 --> 00:00:51.219
and it keeps sampling from it,

00:00:51.219 --> 00:00:54.451
calculates the statistics
for those samples

00:00:54.451 --> 00:00:56.427
so the sample mean and
the sample variance,

00:00:56.427 --> 00:00:58.332
in particular the biased sample variance

00:00:58.332 --> 00:01:00.044
It starts telling us some things about us

00:01:00.044 --> 00:01:01.659
that give us some intuition.

00:01:01.777 --> 00:01:04.513
You can actually click on
each of these and zoom in

00:01:04.513 --> 00:01:08.522
to really be able to study
these graphs in detail.

00:01:08.522 --> 00:01:10.442
I have already taken a screen shot of this

00:01:10.442 --> 00:01:13.281
and put it on my little doodle pad,

00:01:13.281 --> 00:01:15.169
so you can really delve
into some of the math

00:01:15.169 --> 00:01:19.056
and the intuition of what
this is actually showing us.

00:01:19.117 --> 00:01:22.135
So here I took a screen shot,

00:01:22.135 --> 00:01:25.697
and you see for this case right over here,

00:01:25.697 --> 00:01:27.808
the population was 529.

00:01:27.808 --> 00:01:31.456
Population mean was 10 point six,

00:01:31.456 --> 00:01:33.431
and down here in this chart,

00:01:33.431 --> 00:01:38.375
he plots the population mean
right here at 10 point six,

00:01:38.375 --> 00:01:40.080
right over there, and you see that

00:01:40.080 --> 00:01:43.088
the population variance
is at 36 point eight,

00:01:43.088 --> 00:01:47.399
and right here he plots that
right over here, 36 point eight.

00:01:47.399 --> 00:01:49.343
This first chart on the bottom left

00:01:49.343 --> 00:01:51.247
tells us a couple of interesting things.

00:01:51.247 --> 00:01:56.417
Just to be clear, this is
the biased sample variance

00:01:56.417 --> 00:01:57.512
that he is calculating.

00:01:57.512 --> 00:02:01.119
This is the biased sample variance.

00:02:01.119 --> 00:02:02.856
So he is calculating it.

00:02:02.856 --> 00:02:06.456
That is being calculated
for each of our data points.

00:02:06.456 --> 00:02:09.183
So starting with our first data
point in each of our samples,

00:02:09.183 --> 00:02:11.512
going to our nth data point in the sample.

00:02:11.512 --> 00:02:13.368
You're taking that data point,

00:02:13.368 --> 00:02:16.576
subtracting out the
sample mean, squaring it,

00:02:16.576 --> 00:02:20.025
and then dividing the whole
thing, not by n minus one,

00:02:20.025 --> 00:02:22.330
but by lower case n.

00:02:22.330 --> 00:02:25.266
This tells us several interesting things.

00:02:25.266 --> 00:02:29.122
The first thing it shows us is that

00:02:29.122 --> 00:02:31.937
the cases where we are
significantly underestimating

00:02:31.937 --> 00:02:33.001
the sample variance,

00:02:33.001 --> 00:02:35.114
and we are getting sample
variances close to zero,

00:02:35.114 --> 00:02:40.419
these are also the cases, or
they are disproportionately

00:02:40.419 --> 00:02:43.921
the cases where the
means for those samples

00:02:43.921 --> 00:02:47.386
are way far off from the true sample mean,

00:02:47.386 --> 00:02:49.226
or we could do that the other way around.

00:02:49.226 --> 00:02:52.586
The cases where the mean is way
far off from the sample mean

00:02:52.586 --> 00:02:56.138
it seems like you're much
more likely to underestimate

00:02:56.138 --> 00:02:58.403
the sample variance in those situations.

00:02:58.403 --> 00:03:00.386
The other thing that might pop out at you

00:03:00.386 --> 00:03:02.938
is the realization that the pinker dots

00:03:02.938 --> 00:03:05.322
are the ones for smaller sample size,

00:03:05.322 --> 00:03:08.706
while the bluer dots are the
ones of a larger sample size.

00:03:08.706 --> 00:03:10.961
You see here these two little,

00:03:10.961 --> 00:03:16.636
I guess the tails ,so
to speak, of this hump,

00:03:16.636 --> 00:03:21.649
that these ends, are
more of a reddish color.

00:03:21.649 --> 00:03:24.818
that most of the blueish
or the purplish dots

00:03:24.818 --> 00:03:27.945
are focused right in the
middle right over here,

00:03:27.945 --> 00:03:29.944
that they are giving us better estimates.

00:03:29.944 --> 00:03:30.808
There are some red ones here,

00:03:30.808 --> 00:03:32.646
and that's why it gives
us that purplish color,

00:03:32.646 --> 00:03:35.359
but out here on these tails,

00:03:35.359 --> 00:03:37.735
it's almost purely some of these red.

00:03:37.735 --> 00:03:39.175
Every now and then by happenstance

00:03:39.175 --> 00:03:40.227
you get a little blue one,

00:03:40.227 --> 00:03:42.886
but it's disproportionately far more red,

00:03:42.886 --> 00:03:43.855
which really makes sense when you

00:03:43.855 --> 00:03:45.469
have a smaller sample size,

00:03:45.469 --> 00:03:48.606
you are more likely to get a sample mean

00:03:48.606 --> 00:03:51.502
that is a bad estimate
of the population mean,

00:03:51.502 --> 00:03:53.503
that's far from the population mean,

00:03:53.503 --> 00:03:54.862
and you're more likely

00:03:54.862 --> 00:03:59.022
to significantly underestimate
the sample variance.

00:03:59.022 --> 00:04:03.806
Now this next chart really
gets to the meat of the issue,

00:04:03.806 --> 00:04:04.977
because what this is telling us is

00:04:04.977 --> 00:04:06.638
that for each of these sample sizes,

00:04:06.638 --> 00:04:09.391
so this right over here
for sample size two,

00:04:09.391 --> 00:04:11.455
if we keep taking sample size two,

00:04:11.455 --> 00:04:14.032
and we keep calculating
the biased sample variances

00:04:14.032 --> 00:04:16.023
and dividing that by
the population variance,

00:04:16.023 --> 00:04:18.471
and finding the mean over all of those,

00:04:18.471 --> 00:04:20.942
you see that over many, many, many trials,

00:04:20.942 --> 00:04:22.895
and many, many samples of size two,

00:04:22.895 --> 00:04:25.895
that that biased sample variance
over population variance,

00:04:25.895 --> 00:04:30.444
it's approaching half of the
true population variance.

00:04:30.444 --> 00:04:34.342
When sample size is three,
it's approaching 2/3,

00:04:34.342 --> 00:04:38.254
66 point six percent, of the
true population variance.

00:04:38.254 --> 00:04:39.559
When sample size is four,

00:04:39.559 --> 00:04:43.992
it's approaching 3/4 of the
true population variance.

00:04:43.992 --> 00:04:47.855
So we can come up with the
general theme that's happening.

00:04:47.855 --> 00:04:50.230
When we use the biased estimate,

00:04:50.230 --> 00:04:55.175
we're not approaching
the population variance.

00:04:55.175 --> 00:05:04.440
We're approaching n minus one over n

00:05:04.440 --> 00:05:06.250
times the population variance.

00:05:06.250 --> 00:05:09.584
When n was two, this approached 1/2.

00:05:09.584 --> 00:05:12.416
When n is three, this is 2/3.

00:05:12.416 --> 00:05:15.176
When n is four, this is 3/4.

00:05:15.176 --> 00:05:18.049
So this is giving us a biased estimate.

00:05:18.049 --> 00:05:20.577
So how would we unbias this?

00:05:20.577 --> 00:05:24.537
Well, if we really want
to get our best estimate

00:05:24.537 --> 00:05:27.288
of the true population variance,

00:05:27.288 --> 00:05:30.403
not n minus one over n times
the population variance,

00:05:30.403 --> 00:05:32.155
we would want to multiply,

00:05:32.155 --> 00:05:34.340
I'll do this in a color
I haven't used yet,

00:05:34.340 --> 00:05:41.313
we would want to multiply
times n over n minus one.

00:05:41.836 --> 00:05:43.899
to get an unbiased estimate.

00:05:43.899 --> 00:05:46.587
Here, these cancel out
and you are just left

00:05:46.587 --> 00:05:50.316
with your population variance.

00:05:50.316 --> 00:05:51.788
That's what we want to estimate.

00:05:51.788 --> 00:05:59.815
Over here you are left
with our unbiased estimate

00:06:00.030 --> 00:06:01.560
of population variance,

00:06:01.560 --> 00:06:03.408
our unbiased sample variance,

00:06:03.408 --> 00:06:06.057
which is equal to, and this is what we saw

00:06:06.057 --> 00:06:09.240
in the last several videos, what
you see in statistics books,

00:06:09.240 --> 00:06:11.088
and sometimes it's confusing why,

00:06:11.088 --> 00:06:14.816
hopefully Peter's simulation
gives you a good idea of why,

00:06:14.816 --> 00:06:18.334
or at least convinces
you that it is the case.

00:06:18.334 --> 00:06:22.334
So you would want to
divide by n minus one.

