WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:04.920
Don't mind me I'm just shuttling pictures of computer barb people's basis. It's not at all weird Oh

00:00:09.849 --> 00:00:13.829
In the last video we talked about how do you find faces quickly in an image?

00:00:13.830 --> 00:00:19.080
that's I guess nowadays only half the story if you want to unlock a face of your phone or

00:00:19.359 --> 00:00:23.009
You want to unlock it with your computer or you want to just recognize who's in a picture?

00:00:23.560 --> 00:00:27.480
That's face recognition not face detection. We can't just train a classifier

00:00:27.480 --> 00:00:31.769
We can't just say here's 1,500 images of Shawn and 1,500 images of Mike

00:00:32.230 --> 00:00:37.290
what work out what the difference is because it will do that and then I'll say well here's a picture of Steve and it will

00:00:37.290 --> 00:00:38.110
Go

00:00:38.110 --> 00:00:43.679
Mike you know because it's only got two options like so then we have to retrain it and you'll notice that when you sign up

00:00:43.680 --> 00:00:46.289
For your phone the first time and it recognizes your face

00:00:46.289 --> 00:00:50.249
It doesn't have to train a network right because that would take way too long. How does it do it?

00:00:51.399 --> 00:00:58.919
Will be answer is basically we train a network to distinguish the differences between faces rather than actually recognizing individual faces

00:00:58.920 --> 00:01:00.550
I've got some printer here with his max

00:01:00.550 --> 00:01:06.000
Here's me Shawn and Dave and so on right I've got lots of lots of computer power hosts in here

00:01:06.000 --> 00:01:09.330
So what I could do is I could say well here's a picture of Max and here's a picture of Mike

00:01:09.330 --> 00:01:10.290
So I have some you know

00:01:10.290 --> 00:01:15.509
some convolutional layers or something and I have a network here and that goes all the way deep network up to a

00:01:15.670 --> 00:01:19.439
classification but lights up with Max or Mike

00:01:19.439 --> 00:01:23.879
The problem is that we bring in Shawn and everything's ruined you're put in a funny face

00:01:23.880 --> 00:01:29.310
That doesn't help the standard way of training a network which is giving it an image and a label and saying learn to be better

00:01:29.310 --> 00:01:33.030
With predicting that isn't going to work because we don't know how many people are going to use this system

00:01:33.030 --> 00:01:33.990
We can't put them all in

00:01:33.990 --> 00:01:39.059
All right, otherwise companies have been tapping you up for face pictures before they even release the phone we say well

00:01:39.060 --> 00:01:45.930
Why don't we train a network to instead of saying bitties? Definitely someone to just say these are their features, right?

00:01:45.930 --> 00:01:51.209
And hopefully when we if it's good at it, it will say that their features are different to someone else's features. That's the idea

00:01:51.310 --> 00:01:55.710
So what we're actually doing is we're training a network to separate people out

00:01:55.710 --> 00:02:01.290
Let's say you put me in and this network that I'm designing has a lot of layers in it all the way along here

00:02:01.479 --> 00:02:06.989
But instead of outputting a single decision as to who this is it outputs a series of numbers

00:02:06.990 --> 00:02:09.179
So let's say a vector of numbers here like this

00:02:09.239 --> 00:02:11.309
I didn't maybe matter how many there are for now

00:02:11.310 --> 00:02:16.560
and what we're saying is when we put me in these numbers need to be different than when we put

00:02:17.200 --> 00:02:19.470
Maxine or when we put let's see

00:02:19.470 --> 00:02:23.999
Who else we got Dave right when we put Dave in his numbers come out different to mine, right?

00:02:24.000 --> 00:02:27.630
And it's those numbers which are kind of like a fingerprint for each person. So, how do we do this?

00:02:27.630 --> 00:02:27.810
well

00:02:27.810 --> 00:02:31.979
We use a special kind of learning or a special kind of loss function called a triplet loss

00:02:32.050 --> 00:02:34.619
Right all this is one of the ways you can do it. There were a few

00:02:34.750 --> 00:02:37.500
So what we say is we say what we put in three images at once

00:02:37.750 --> 00:02:38.830
so we say

00:02:38.830 --> 00:02:42.959
here's two images of me and one image of Dave and what we want to do if

00:02:43.060 --> 00:02:49.949
We want to change the network so that when we put these fujas through these two are rated very similar and these two pairs

00:02:50.170 --> 00:02:51.750
Are rated is very different

00:02:51.750 --> 00:02:57.509
And actually what we'd usually do is we label this one and anchor this one a positive sample and this one a negative sample

00:02:57.610 --> 00:03:03.720
So we're saying but a distance between these two has to be very similar and the distance between these has to be very far apart

00:03:03.970 --> 00:03:09.809
So let's imagine it was only two numbers out. So we're putting ourselves on a sort of 2d. Grid, right?

00:03:09.810 --> 00:03:14.640
So this this is variable one and this is available to that come out of our network, right?

00:03:14.640 --> 00:03:20.190
So this is our network like my anchor is is a picture of me a positive sample and a negative sample, which is Dave

00:03:20.230 --> 00:03:20.730
right

00:03:20.730 --> 00:03:26.850
so I put them through the network and what we trained it to do is separate out the pictures of me in the pictures of

00:03:26.850 --> 00:03:28.660
Dave so I maybe get put over here

00:03:28.660 --> 00:03:33.600
So I get a very high value for - and a very low value for number one. Let's say all right

00:03:33.600 --> 00:03:37.019
Dave gets a very high value for number one and a very low value for number two

00:03:37.019 --> 00:03:43.679
And then we start to repeat this process with different pairs of people and different positives and different negative samples. So let's say I

00:03:44.500 --> 00:03:46.500
Mean, why did I shuffle these? That's a real?

00:03:46.840 --> 00:03:52.140
Okay. So let's say two pictures of op miles. That's why he's not nice to avoid my printer and one picture of Sean, right?

00:03:52.140 --> 00:03:55.799
So maybe what miles gets put over here near me, which is not so good

00:03:55.799 --> 00:03:59.879
But we'll get to that and then you're put over here like this and then maybe later on

00:03:59.890 --> 00:04:05.100
We have two pictures of me and one of Rob which moves Rob down here a little bit and then Dave gets put over here

00:04:05.100 --> 00:04:10.350
And you know max gets put over here somewhere negative values are also allowed and what we're trying to do

00:04:11.079 --> 00:04:13.979
Is make sure that everyone is nicely separate, okay?

00:04:13.980 --> 00:04:19.440
now if you do this for just a few people what you're actually doing is just classifying them but if you do this for

00:04:19.720 --> 00:04:25.899
Thousands of different humans of all different ethnicities and different poses and different lighting conditions eventually

00:04:25.900 --> 00:04:32.229
The network is going to start to learn how to I mean actually that's not right because Dave's far away from Dave, right?

00:04:32.229 --> 00:04:33.729
So hopefully we start to come together

00:04:33.729 --> 00:04:35.919
But that's you've got a train for a long time

00:04:36.160 --> 00:04:40.539
And let's not let Steve off. The hook is Steve over here high value of two high value of one, whatever

00:04:40.539 --> 00:04:45.609
That means the interesting thing about this is we're not performing a classification which is performing a dimensionality reduction

00:04:46.070 --> 00:04:51.759
We're saying how do we represent people as just these two numbers right or in the case of actual?

00:04:52.880 --> 00:04:57.009
Deployments of this maybe 128 or 256 numbers somewhere in this space

00:04:57.349 --> 00:05:02.919
when you put my face in I'll appear and when you put Steve's face in it'll peer somewhere else and this actually solves a really

00:05:02.919 --> 00:05:05.348
Nice problem right? It's called the one-shot learning problem

00:05:05.349 --> 00:05:09.369
How do we convince a phone to let me in having only seen one ever picture of my face?

00:05:09.370 --> 00:05:11.370
Which is when I first, you know

00:05:11.599 --> 00:05:15.999
Calibrated it the first time and the answer is we don't train a neural network to classify me

00:05:16.000 --> 00:05:19.690
We just use the existing network that we trained on thousands of thousands of people doing this

00:05:19.910 --> 00:05:25.779
To put me somewhere on here and then we record that location and then when I come in again and try and unlock the phone

00:05:26.150 --> 00:05:30.820
Do does my new image go to the same place in this space as my last one?

00:05:30.820 --> 00:05:35.049
So let's say I get put over here with a high value of two and a low value of one

00:05:35.050 --> 00:05:41.590
I take another picture of myself on my camera and I come in over here and it goes well, that's pretty close

00:05:41.590 --> 00:05:48.190
Okay, we'll let them unlock the phone. Right but max comes in and gets put over here that's judged as to higher difference and

00:05:49.070 --> 00:05:51.339
Access is denied, right this is how it works

00:05:51.490 --> 00:05:57.009
And this is really clever because it means that the actual decision making process on whether you're allowed in or not

00:05:57.009 --> 00:06:01.959
It's based on just the distance of these numbers right in which case is like 128 numbers. Sure. This is

00:06:02.630 --> 00:06:03.740
Susceptible to problems

00:06:03.740 --> 00:06:04.240
Yeah

00:06:04.240 --> 00:06:08.229
So it is and this is one of the things that Apple for example with their face ID

00:06:08.599 --> 00:06:11.709
Have yeah, if you bear in mind, of course haven't told me how they do it, right?

00:06:11.710 --> 00:06:17.079
So nor would they but we can presume it works something like this. We have a depth camera as well

00:06:18.440 --> 00:06:20.979
But they will have included in their training set

00:06:21.530 --> 00:06:27.669
pictures of people in masks and pictures of people with different hair and pictures of people in strange locations and things

00:06:27.830 --> 00:06:30.430
So the network learned to ignore those things, right?

00:06:30.430 --> 00:06:34.150
If you never showed it to the network, you're right B will just miss classifier all the time

00:06:34.400 --> 00:06:35.740
That's that's the problem

00:06:35.740 --> 00:06:41.350
If you only train this to separate me in day when you put Steve in its behavior is going to be undefined

00:06:41.720 --> 00:06:47.799
Right, so but that's kind of how neural networks work. They often undefined you hope that you put in a good enough training set

00:06:47.800 --> 00:06:49.800
So but for the vast majority

00:06:50.180 --> 00:06:56.019
99.999% of cases it works very consistently and it says no they come out over here, which is not close enough

00:06:56.020 --> 00:06:57.070
So we're not unlocking the phone

00:06:57.070 --> 00:07:03.129
The interesting thing is it's much harder to gain this system than it is to gain a system based on simple decision-making, right?

00:07:03.290 --> 00:07:07.689
So yes, you might be able to trick this to unlock a phone once or twice, right?

00:07:07.690 --> 00:07:11.709
But if you try and recreate that same process with my face and unlock my phone, for example

00:07:11.710 --> 00:07:13.720
maybe you won't have as much luck because

00:07:14.960 --> 00:07:19.060
Exactly how its network works isn't clear even to the people that chain to trained it

00:07:19.060 --> 00:07:23.920
Which is quite kind of its strength in this case, right? Maybe it's security for obscurity, right?

00:07:23.920 --> 00:07:27.699
Maybe there's a certain thing you can hold up in front and it'll always unlock right?

00:07:27.700 --> 00:07:31.839
It doesn't seem very likely but we don't know until we find those things. So

00:07:32.660 --> 00:07:34.660
It's the air as an interesting one for further study

00:07:34.660 --> 00:07:40.869
I guess you were mentioning these features here people will ensure that as what can arise we've got all the hair

00:07:40.870 --> 00:07:43.000
We've got I mean, is that what's going on?

00:07:44.720 --> 00:07:48.309
Okay, we don't know right so we call this feature space for latent space

00:07:48.310 --> 00:07:49.970
It's a kind of space just before

00:07:49.970 --> 00:07:54.369
Classification where it's you've got features but these features in a deep network are or mean

00:07:54.370 --> 00:07:58.419
We've had a look at sort of inside and your network before and they kind of a sort of

00:07:58.610 --> 00:08:03.370
Combinations of edges and things like this it is going to be bored leaf or something trained on human faces

00:08:03.530 --> 00:08:11.019
It's going to be broadly the kind of face related features because otherwise it wouldn't work as a as a trained network

00:08:11.390 --> 00:08:17.259
But exactly what it does. We don't know does it wait hairs more important than eye color

00:08:17.260 --> 00:08:21.309
I don't know and neither do the people that run it I expect they're trained with different haircuts

00:08:21.310 --> 00:08:23.350
So so that they forego this kind of issue

00:08:23.350 --> 00:08:25.540
But of course you have to be careful doing that, right?

00:08:25.540 --> 00:08:30.159
Because if you can shave your head and still unlock the phone, is that as secure as a phone

00:08:30.160 --> 00:08:32.469
But you couldn't do that on my it's not usable

00:08:32.469 --> 00:08:36.999
So that's the other reason they do it, but you get the idea but you've noticed from this two dimensional space

00:08:37.000 --> 00:08:42.580
Which I've done just for simplicity. It becomes difficult to separate out everyone in this space. So who else have we got?

00:08:43.640 --> 00:08:48.189
So you're in here you're in over here. So maybe your images are here blobs. Images are here

00:08:48.190 --> 00:08:50.969
They start to take up quite a lot of room one got a few of them

00:08:51.040 --> 00:08:55.860
And that's a bit of a weird one, right? So that goes over here and and and maxes over here

00:08:55.870 --> 00:08:58.139
So it's getting a bit cluttered, right?

00:08:58.139 --> 00:09:02.849
So the decision on whether to unlock a phone becomes more difficult, so we don't usually do this in two dimensions

00:09:02.850 --> 00:09:09.240
We do it in 128 or 256 dimensions. So but spacing these things out for many many people is much much easier

00:09:09.339 --> 00:09:13.589
I would say that it's likely that someone on earth will be able to unlock

00:09:13.930 --> 00:09:16.620
Someone's phone like this because they look similar enough to them

00:09:16.689 --> 00:09:21.689
But the chances of that person being the one that steals your phone is pretty slim so I really wouldn't worry about it too much

00:09:21.879 --> 00:09:25.229
And this pixel was going to be always three. So that's going to be 12

00:09:26.170 --> 00:09:30.870
14 23 and now we fast forward while I do a bit of math in my head 8

00:09:31.720 --> 00:09:36.480
On a computer. This is much much faster likely to be on a network which is limited in what it can connect to

00:09:36.670 --> 00:09:40.499
It's probably likely to be able to connect to other board management controllers on the same network

