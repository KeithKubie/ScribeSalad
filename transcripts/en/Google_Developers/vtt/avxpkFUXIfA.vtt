WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.390
[MUSIC PLAYING]

00:00:06.987 --> 00:00:08.320
LAURENCE MORONEY: Hi, everybody.

00:00:08.320 --> 00:00:11.160
And welcome to this session,
the last one of the day.

00:00:11.160 --> 00:00:14.810
Everybody having
a good IO so far?

00:00:14.810 --> 00:00:15.760
Nice.

00:00:15.760 --> 00:00:18.900
Excited for the concert tonight?

00:00:18.900 --> 00:00:21.380
So thanks for spending some
time with us beforehand.

00:00:21.380 --> 00:00:22.790
I'm Lawrence Moroney.

00:00:22.790 --> 00:00:23.541
KAZ SATO: I'm Kaz.

00:00:23.541 --> 00:00:25.123
LAURENCE MORONEY:
And we're here today

00:00:25.123 --> 00:00:27.360
to talk about machine
learning plus IoT equals

00:00:27.360 --> 00:00:29.040
a smarter world.

00:00:29.040 --> 00:00:31.290
Now that's a little bit of
a riff on a famous computer

00:00:31.290 --> 00:00:31.950
science book.

00:00:31.950 --> 00:00:33.780
Anybody know what that is?

00:00:33.780 --> 00:00:36.180
"Algorithms Plus Data
Structures Equals Programs"

00:00:36.180 --> 00:00:37.160
by Nikolaos Worth.

00:00:37.160 --> 00:00:39.450
It's one of the seminal
works in CompSci.

00:00:39.450 --> 00:00:42.060
So we said hey, we want to do
a little bit of a riff on that.

00:00:42.060 --> 00:00:45.750
And it's also really about
what's going on in the world

00:00:45.750 --> 00:00:48.250
today, that there's two
major trends going on.

00:00:48.250 --> 00:00:50.770
Number one is the
rapid rise of IoT.

00:00:50.770 --> 00:00:53.640
And number two is the rapid
rise of AI and machine learning.

00:00:53.640 --> 00:00:55.710
And in many ways, these are--

00:00:55.710 --> 00:00:57.210
they're intersecting
with each other

00:00:57.210 --> 00:00:59.795
to create some really
cool new scenarios.

00:00:59.795 --> 00:01:01.920
So we wanted to talk through
a few of the scenarios

00:01:01.920 --> 00:01:03.610
and give some demonstrations.

00:01:03.610 --> 00:01:05.280
The first one
we'll give is let's

00:01:05.280 --> 00:01:10.200
take a look at really cheap IoT
sensors that will do something

00:01:10.200 --> 00:01:12.300
like in this case,
we're going to take

00:01:12.300 --> 00:01:14.280
a look at those that
measure air quality

00:01:14.280 --> 00:01:16.110
and how they can push
data to the Cloud

00:01:16.110 --> 00:01:18.060
and how we can use that
for machine learning.

00:01:18.060 --> 00:01:19.643
KAZ SATO: And then
we also look at how

00:01:19.643 --> 00:01:22.760
the cloud can be empowering
to for IoT and AI

00:01:22.760 --> 00:01:25.980
these products that help
you in collecting data

00:01:25.980 --> 00:01:28.810
and analyzing it and learning
some intelligent [INAUDIBLE]

00:01:28.810 --> 00:01:29.684
writing models.

00:01:29.684 --> 00:01:31.350
LAURENCE MORONEY: And
then the third one

00:01:31.350 --> 00:01:34.080
will be as some of our
devices are practically

00:01:34.080 --> 00:01:37.540
mini computers, like Raspberry
Pis and our handheld devices

00:01:37.540 --> 00:01:39.480
that what can we
do about on device

00:01:39.480 --> 00:01:40.870
inference with them as well.

00:01:40.870 --> 00:01:43.080
So we'll take a look at
some of the examples of that

00:01:43.080 --> 00:01:45.480
and some pretty cool stuff
that's happening there.

00:01:45.480 --> 00:01:47.280
But first of all, some numbers.

00:01:47.280 --> 00:01:49.170
According to IHS
research, there are

00:01:49.170 --> 00:01:54.060
expected to be 31 billion
connected IoT devices

00:01:54.060 --> 00:01:56.020
by the end of this year.

00:01:56.020 --> 00:01:57.810
That's a lot of devices.

00:01:57.810 --> 00:02:01.290
And those devices combined,
we found the same research

00:02:01.290 --> 00:02:07.110
as showing a 27.6% compound
annual growth rate of the data

00:02:07.110 --> 00:02:09.240
that they are
pushing to the Cloud.

00:02:09.240 --> 00:02:12.150
So 31 billion by the end
of this year and every year

00:02:12.150 --> 00:02:17.030
the amount of data that they're
pushing is growing by 27.6%.

00:02:17.030 --> 00:02:18.390
And that's a lot of data.

00:02:18.390 --> 00:02:20.181
Now what are we going
to do with that data?

00:02:20.181 --> 00:02:22.170
Well obviously, there's
the usual things--

00:02:22.170 --> 00:02:24.870
filtering, sorting, querying,
all that kind of stuff.

00:02:24.870 --> 00:02:27.357
But we can also use that to
start training some models.

00:02:27.357 --> 00:02:29.940
And all of that data and all of
those models, machine learning

00:02:29.940 --> 00:02:32.730
models can then be used
to generate intelligence

00:02:32.730 --> 00:02:36.300
and to help us to start making
intelligent decisions based

00:02:36.300 --> 00:02:39.632
on the data that's being
generated by our devices.

00:02:39.632 --> 00:02:41.340
So the first scenario
I wanted to look at

00:02:41.340 --> 00:02:44.010
was thinking about
simple sensors

00:02:44.010 --> 00:02:46.170
that give us smart solutions.

00:02:46.170 --> 00:02:49.140
I just wanted something
with four S's on it--

00:02:49.140 --> 00:02:50.950
easier to remember that way.

00:02:50.950 --> 00:02:54.000
And an example of this is
like these little devices.

00:02:54.000 --> 00:02:56.709
And if you've ever done any
kind of hardware hacking,

00:02:56.709 --> 00:02:58.500
this is like a device--
the one on the left

00:02:58.500 --> 00:03:00.960
here is called an ESP 8266.

00:03:00.960 --> 00:03:03.930
And this little chip
actually has GPIO pins on it,

00:03:03.930 --> 00:03:05.550
so those input output pins.

00:03:05.550 --> 00:03:07.650
And it also has a
Wi-Fi circuit on it.

00:03:07.650 --> 00:03:09.720
And when you combine
that with something

00:03:09.720 --> 00:03:11.430
like the one on the right--

00:03:11.430 --> 00:03:14.187
that's an air quality
sensor and a gas sensor--

00:03:14.187 --> 00:03:16.020
now you can start putting
together something

00:03:16.020 --> 00:03:18.630
very quickly and very
cheaply that will push data

00:03:18.630 --> 00:03:19.299
to the Cloud.

00:03:19.299 --> 00:03:21.090
And I'm going to go
off script for a second

00:03:21.090 --> 00:03:22.560
and an interesting story.

00:03:22.560 --> 00:03:24.780
Kaz and I had
prepared this talk,

00:03:24.780 --> 00:03:26.910
and we were rehearsing
it last week

00:03:26.910 --> 00:03:28.689
with the VP of our division.

00:03:28.689 --> 00:03:30.730
And one of the feedback
he gave us was like, hey,

00:03:30.730 --> 00:03:33.450
you don't have any small
simple sensors on there.

00:03:33.450 --> 00:03:34.910
You're doing lots
of Cloud stuff.

00:03:34.910 --> 00:03:35.940
And you're doing
lots of mobile stuff.

00:03:35.940 --> 00:03:37.625
But you don't have
any IoT sensors.

00:03:37.625 --> 00:03:39.750
So you should really build
one and put it in there.

00:03:39.750 --> 00:03:41.680
And this was last Wednesday.

00:03:41.680 --> 00:03:45.120
And the environment that we live
in now is so cool that we were

00:03:45.120 --> 00:03:48.486
able to-- thanks to Arduino and
thanks to the maker community

00:03:48.486 --> 00:03:50.610
to be able to build the
demo that I'm going to show

00:03:50.610 --> 00:03:51.690
shortly--

00:03:51.690 --> 00:03:52.860
in just a couple of days.

00:03:52.860 --> 00:03:54.504
And the longest part of that--

00:03:54.504 --> 00:03:55.920
can anybody guess
what the longest

00:03:55.920 --> 00:03:57.270
time in building the demo was?

00:03:57.270 --> 00:04:00.169
AUDIENCE: [INAUDIBLE]

00:04:00.169 --> 00:04:02.210
LAURENCE MORONEY: No, it
wasn't actually testing.

00:04:02.210 --> 00:04:05.790
It was waiting for the parts
to be shipped from Amazon.

00:04:05.790 --> 00:04:08.350
I'm an Amazon Prime subscriber,
and it took two days.

00:04:08.350 --> 00:04:10.558
And it only took three days
to build the whole thing.

00:04:10.558 --> 00:04:14.569
So it's an amazing time
to be alive, I think.

00:04:14.569 --> 00:04:16.110
The amount of things
that you can do,

00:04:16.110 --> 00:04:18.029
the amount of
creativity, and the kind

00:04:18.029 --> 00:04:20.459
of things that you can build
is just I find it so cool.

00:04:20.459 --> 00:04:22.570
And I'm really happy
to be alive right now.

00:04:22.570 --> 00:04:24.870
So let's take a
look at an example

00:04:24.870 --> 00:04:26.160
of how you'd use one of these.

00:04:26.160 --> 00:04:28.470
Consider a building
like this one,

00:04:28.470 --> 00:04:30.030
and say in a
building like this we

00:04:30.030 --> 00:04:32.190
could put sensors like
this for air quality

00:04:32.190 --> 00:04:33.600
around the building.

00:04:33.600 --> 00:04:35.220
And when they're
around the building,

00:04:35.220 --> 00:04:38.440
then we can start tracking the
air quality in that building.

00:04:38.440 --> 00:04:40.470
But you know, that's
just an instant status.

00:04:40.470 --> 00:04:43.080
We can tell the stuff here on
the south side of the building,

00:04:43.080 --> 00:04:45.039
the air quality isn't great.

00:04:45.039 --> 00:04:46.830
And then on the north
side of the building,

00:04:46.830 --> 00:04:47.970
the air quality is very nice.

00:04:47.970 --> 00:04:49.470
But what would
usually happen if you

00:04:49.470 --> 00:04:50.730
work in an office like this?

00:04:50.730 --> 00:04:52.146
People on the south
side are going

00:04:52.146 --> 00:04:53.760
to go and adjust
the thermometer,

00:04:53.760 --> 00:04:56.160
adjust the thermostat,
the fans will kick in.

00:04:56.160 --> 00:04:58.710
And then people on the north
side are going to be too cold.

00:04:58.710 --> 00:05:01.251
It's like what wouldn't it be
great if we could intelligently

00:05:01.251 --> 00:05:02.700
adapt the building?

00:05:02.700 --> 00:05:05.490
Or what if that was a disaster
and it was like maybe a carbon

00:05:05.490 --> 00:05:07.980
monoxide leak and
with our sensors

00:05:07.980 --> 00:05:09.564
are going to show
that carbon monoxide

00:05:09.564 --> 00:05:10.063
Leak?

00:05:10.063 --> 00:05:12.240
And I don't know if how
well you can see it here,

00:05:12.240 --> 00:05:14.910
but the leak is primarily
centered around the exit.

00:05:14.910 --> 00:05:17.340
And if people are being
driven towards the exit,

00:05:17.340 --> 00:05:18.966
they might be driven
towards danger.

00:05:18.966 --> 00:05:21.340
But when we've got chief
sensors like this, we could say,

00:05:21.340 --> 00:05:24.130
hey look, instantly we can
have an alternative exit.

00:05:24.130 --> 00:05:25.770
But what if we can
go even further--

00:05:25.770 --> 00:05:26.395
sorry.

00:05:26.395 --> 00:05:28.020
What if we can go
even further and then

00:05:28.020 --> 00:05:30.980
think about scenarios where
machine learning comes involved

00:05:30.980 --> 00:05:32.910
and we can start
predicting things?

00:05:32.910 --> 00:05:35.310
Like maybe we can predict
the best times of the day

00:05:35.310 --> 00:05:38.190
to keep the fans on to
maximize air quality

00:05:38.190 --> 00:05:41.100
and reduce our energy footprint,
good for the environment.

00:05:41.100 --> 00:05:43.910
Or maybe we could, if there
was a gas leak or something

00:05:43.910 --> 00:05:45.780
like that, we could
predict the path

00:05:45.780 --> 00:05:49.650
of the gas leak based on testing
and based on machine learning

00:05:49.650 --> 00:05:50.470
models.

00:05:50.470 --> 00:05:53.169
So emergency responders would
know where it's safe to go

00:05:53.169 --> 00:05:54.460
and where it's dangerous to go.

00:05:54.460 --> 00:05:56.640
And we all love our
emergency responders,

00:05:56.640 --> 00:05:58.460
and we want to make
sure that they're safe.

00:05:58.460 --> 00:06:02.100
Or maybe we could look at
what the impact by modeling

00:06:02.100 --> 00:06:04.675
what would be of
rearranging our office?

00:06:04.675 --> 00:06:07.050
What if we have more people
sitting in the north and less

00:06:07.050 --> 00:06:07.680
in the south?

00:06:07.680 --> 00:06:09.720
Or what happens if
we host a big event?

00:06:09.720 --> 00:06:12.840
And this building is
actually one of the offices

00:06:12.840 --> 00:06:13.830
in Google's Seattle.

00:06:13.830 --> 00:06:16.240
And up on that top right
top left hand side there

00:06:16.240 --> 00:06:18.150
that room called
center of the universe

00:06:18.150 --> 00:06:19.900
is actually where we
host a lot of events.

00:06:19.900 --> 00:06:22.260
And it be good for us to
understand the air quality when

00:06:22.260 --> 00:06:24.120
we do so.

00:06:24.120 --> 00:06:26.580
So if you've got a lot
of devices like this,

00:06:26.580 --> 00:06:28.680
there's a product
called Cloud IoT Core.

00:06:28.680 --> 00:06:31.650
And the idea behind Cloud IoT
Core is it's fully managed

00:06:31.650 --> 00:06:35.280
and allows you to easily secure,
connect, manage, and ingest

00:06:35.280 --> 00:06:37.099
data from all of your devices.

00:06:37.099 --> 00:06:38.640
And then once you
have that, then you

00:06:38.640 --> 00:06:40.860
can start doing interesting
things, like pulling

00:06:40.860 --> 00:06:43.710
the data out using
BigQuery, using Cloud ML,

00:06:43.710 --> 00:06:46.590
using Cloud Data Lab,
using Cloud Studio to be

00:06:46.590 --> 00:06:48.960
able to then build models
and then run interference

00:06:48.960 --> 00:06:51.596
on these models and have
analytics behind that.

00:06:51.596 --> 00:06:53.970
But let me give a little demo
of environmental monitoring

00:06:53.970 --> 00:06:55.450
and what it would look like.

00:06:55.450 --> 00:06:57.116
So if we can switch
to the Wolff vision.

00:06:59.220 --> 00:07:01.150
So this is the device
I was talking about.

00:07:01.150 --> 00:07:03.360
So this is a simple
Ardiuno device.

00:07:03.360 --> 00:07:05.290
I'm not using the
Wi-Fi in this case.

00:07:05.290 --> 00:07:06.530
I'm just using a wired one.

00:07:06.530 --> 00:07:11.240
So I have a shield on top of the
Ardiuno with a wired internet

00:07:11.240 --> 00:07:13.570
just so we can make sure that
the demo would work here.

00:07:13.570 --> 00:07:16.440
And then this little device
is the air quality sensor.

00:07:16.440 --> 00:07:19.890
And so right now, it's measuring
the air quality in the room.

00:07:19.890 --> 00:07:22.530
And so that's measuring
for particulates.

00:07:22.530 --> 00:07:25.530
It's measuring for gases,
carbon dioxide, carbon monoxide,

00:07:25.530 --> 00:07:27.880
natural gas, all
that kind of thing.

00:07:27.880 --> 00:07:30.720
So we kind of want to
trigger it by polluting

00:07:30.720 --> 00:07:31.640
the air a little bit.

00:07:31.640 --> 00:07:34.256
Any ideas how we can do that?

00:07:34.256 --> 00:07:35.880
I'll just breathe on
it, because we all

00:07:35.880 --> 00:07:37.370
breathe out carbon dioxide.

00:07:37.370 --> 00:07:40.920
So I'm going to breathe on it.

00:07:40.920 --> 00:07:42.750
I've always wanted to
do that in a session.

00:07:42.750 --> 00:07:46.530
And if we switched to
my laptop, so my laptop,

00:07:46.530 --> 00:07:49.080
we can now see I have a
Firebase running here.

00:07:49.080 --> 00:07:51.780
And I'm using Firebase
Cloud Firestore.

00:07:51.780 --> 00:07:54.150
And on Cloud Firestore,
I'm actually detecting

00:07:54.150 --> 00:07:57.030
and I'm getting the readings
from this little device.

00:07:57.030 --> 00:07:59.850
So we can see the readings
up here once they come up.

00:07:59.850 --> 00:08:02.310
Look here at the reading
57, that was a moment ago

00:08:02.310 --> 00:08:03.320
when I breathed on it.

00:08:03.320 --> 00:08:05.880
54, I've actually
gotten it up to 70.

00:08:05.880 --> 00:08:07.590
I must have eaten something bad.

00:08:07.590 --> 00:08:10.050
Here's your background
here is about 42.

00:08:10.050 --> 00:08:11.050
So what's going on here?

00:08:11.050 --> 00:08:12.380
How is this being done?

00:08:12.380 --> 00:08:16.710
Well, with Arduino, it's super
simple to write code and see--

00:08:16.710 --> 00:08:18.305
and can we switch
back to the slides?

00:08:18.305 --> 00:08:21.456
It will be a little
easier to see the code.

00:08:21.456 --> 00:08:22.830
So if I go back
to the slides, we

00:08:22.830 --> 00:08:24.996
can see this is the kind
of code that you would have

00:08:24.996 --> 00:08:26.850
written in C on an Arduino.

00:08:26.850 --> 00:08:30.330
And all I'm doing is
I'm reading pin 0,

00:08:30.330 --> 00:08:32.850
that this is plugged
into data pin 0 on there.

00:08:32.850 --> 00:08:33.600
I'm reading that.

00:08:33.600 --> 00:08:36.059
And then every two seconds,
I'm reading it again.

00:08:36.059 --> 00:08:39.850
And then what I'm doing with
that is I'm posting that to URL

00:08:39.850 --> 00:08:42.190
and that URL is writing
its Firebase for me.

00:08:42.190 --> 00:08:43.440
And that's all you have to do.

00:08:43.440 --> 00:08:46.230
It's really that simple
to build a sensor

00:08:46.230 --> 00:08:49.150
to start monitoring air
quality very, very cheap,

00:08:49.150 --> 00:08:50.340
very, very simple.

00:08:50.340 --> 00:08:52.950
And then when you aggregate the
data from all of these sensors

00:08:52.950 --> 00:08:55.500
together, if you've got
thousands of them in the Cloud,

00:08:55.500 --> 00:08:58.250
then you can start building some
really intelligent solutions.

00:08:58.250 --> 00:09:00.000
But there's something
to take into account

00:09:00.000 --> 00:09:01.350
when you're doing IoT.

00:09:01.350 --> 00:09:03.600
And that's think in
terms of security.

00:09:03.600 --> 00:09:05.865
So data security is
very, very important.

00:09:05.865 --> 00:09:08.490
Obviously, these things are just
generating data and pushing it

00:09:08.490 --> 00:09:10.504
up to my database
but a smart hacker

00:09:10.504 --> 00:09:12.420
might be able to figure
out how I'm doing that

00:09:12.420 --> 00:09:13.625
and then get access
to my database.

00:09:13.625 --> 00:09:15.820
So you've got to think in
terms of data security.

00:09:15.820 --> 00:09:18.840
And a pattern that I usually
like to follow for this--

00:09:18.840 --> 00:09:21.240
and for good reason
too-- is instead

00:09:21.240 --> 00:09:24.570
of pushing from the devices
directly up to your databases,

00:09:24.570 --> 00:09:26.460
have something
within your firewall

00:09:26.460 --> 00:09:27.640
that they are pushing to.

00:09:27.640 --> 00:09:29.340
And let that act as a proxy.

00:09:29.340 --> 00:09:32.700
And then that proxy will proxy
out your databases for you.

00:09:32.700 --> 00:09:36.480
So then you'll have a secure
connection between that proxy

00:09:36.480 --> 00:09:37.244
and the databases.

00:09:37.244 --> 00:09:39.660
And then hopefully, that secure
connection will be enough.

00:09:39.660 --> 00:09:41.850
And the reason for
that is also to do it

00:09:41.850 --> 00:09:44.910
as an internal thing was
that the power limitations

00:09:44.910 --> 00:09:47.100
on these things, I mean
that a lot of these

00:09:47.100 --> 00:09:49.260
will only support HTTP.

00:09:49.260 --> 00:09:51.100
They won't support HTTPs.

00:09:51.100 --> 00:09:53.190
So that's why in my
code a moment ago,

00:09:53.190 --> 00:09:57.990
if you looked closely, you
would have seen that I was just

00:09:57.990 --> 00:10:01.560
making a client dot connect
server, comma 80 in that case

00:10:01.560 --> 00:10:03.460
because it's just an
open HTTP connection.

00:10:03.460 --> 00:10:06.960
So that was to my internal proxy
and then the internal proxy

00:10:06.960 --> 00:10:08.580
was sending it out to the Cloud.

00:10:08.580 --> 00:10:10.500
So things to consider--

00:10:10.500 --> 00:10:13.630
very cheap, very easy for you
to build systems like this one.

00:10:13.630 --> 00:10:18.241
Coding with something like
Arduino and C is super simple.

00:10:18.241 --> 00:10:20.490
There's tons of APIs and
there's tons of examples that

00:10:20.490 --> 00:10:22.120
would do it you can just adapt.

00:10:22.120 --> 00:10:23.590
And that's what I
did in this case.

00:10:23.590 --> 00:10:26.910
I've never touched an
Arduino before last Friday--

00:10:26.910 --> 00:10:28.530
and I'm not particularly smart.

00:10:28.530 --> 00:10:30.120
And it took just
a couple of hours

00:10:30.120 --> 00:10:31.870
to figure out how to
hack some of the code

00:10:31.870 --> 00:10:34.530
that they had provided to be
able to build this and write

00:10:34.530 --> 00:10:36.450
my data up to Firebase.

00:10:36.450 --> 00:10:38.479
So that's on a
small simple sensor.

00:10:38.479 --> 00:10:40.020
Now let's take a
look at what happens

00:10:40.020 --> 00:10:41.000
when you go Cloud scale.

00:10:41.000 --> 00:10:41.541
KAZ SATO: OK.

00:10:41.541 --> 00:10:42.820
Thank you.

00:10:42.820 --> 00:10:44.490
So that was a very
similar scenario.

00:10:44.490 --> 00:10:47.130
And let's take a look at
another scenario where

00:10:47.130 --> 00:10:51.510
we have to get smarter
devices such as camera.

00:10:51.510 --> 00:10:53.190
If you take a
picture of a camera,

00:10:53.190 --> 00:10:56.190
you may want to look at some
object, what kind of object

00:10:56.190 --> 00:10:58.490
you would have in the
images And TensorFlow

00:10:58.490 --> 00:11:03.120
provides an API to do that,
that is Object Detection API.

00:11:03.120 --> 00:11:04.860
So by using the
Object Detection API,

00:11:04.860 --> 00:11:08.350
you could have the labels
of each object in the image,

00:11:08.350 --> 00:11:10.710
or you could have
the boundary boxes.

00:11:10.710 --> 00:11:12.180
And you could have the scores.

00:11:12.180 --> 00:11:13.860
And it's really
simple to use the API.

00:11:13.860 --> 00:11:16.770
For example, you can just
download the model file

00:11:16.770 --> 00:11:18.810
for Object Detection API.

00:11:18.810 --> 00:11:22.000
And you can have a
dictionary for Tensors

00:11:22.000 --> 00:11:24.090
with the model
file of the model.

00:11:24.090 --> 00:11:27.480
Then you get pass your images to
the dictionary, and that's it.

00:11:27.480 --> 00:11:30.107
So you'd get the
output dictionary that

00:11:30.107 --> 00:11:32.190
would have the detection
results, such as a number

00:11:32.190 --> 00:11:35.370
of the object you have
or classes of objects,

00:11:35.370 --> 00:11:37.950
or the boundary
boxes and the scores.

00:11:37.950 --> 00:11:39.210
It's so simple.

00:11:39.210 --> 00:11:42.360
So for example, you could
have the Raspberry Pi

00:11:42.360 --> 00:11:45.390
with a camera attached
to a shopping cart

00:11:45.390 --> 00:11:48.330
so that you could take a picture
of the inside of the shopping

00:11:48.330 --> 00:11:53.610
cart and apply the Object
Detection API to detect

00:11:53.610 --> 00:11:56.370
what kind of items you are
having or how many of them

00:11:56.370 --> 00:11:58.200
you have the cart.

00:11:58.200 --> 00:12:01.590
And we can use the Cloud IoT
Core combined with the Cloud

00:12:01.590 --> 00:12:05.580
and Machine Learning Engine
to build a system that

00:12:05.580 --> 00:12:09.510
provides the production level,
scalability, and availability.

00:12:09.510 --> 00:12:12.340
For example, if you want
to build a smart camera

00:12:12.340 --> 00:12:13.920
system for the
shopping cart, you

00:12:13.920 --> 00:12:16.660
can have a Raspberry Pi and a
camera attached to the shopping

00:12:16.660 --> 00:12:21.150
cart that uses the Cloud IoT
Core to collect all your data,

00:12:21.150 --> 00:12:24.420
store the data on
the Cloud Pub/Sub,

00:12:24.420 --> 00:12:27.060
which could be the back
end for your server.

00:12:27.060 --> 00:12:30.300
And we could use the
Kubernetes Engine or GKE

00:12:30.300 --> 00:12:32.820
as an orchestrator for
orchestrating everything

00:12:32.820 --> 00:12:34.540
happening at the Cloud side.

00:12:34.540 --> 00:12:37.310
And finally, the GKE
could be sending the data

00:12:37.310 --> 00:12:38.520
to the ML Engine.

00:12:38.520 --> 00:12:42.350
That's where we arrive at the
prediction with the Object

00:12:42.350 --> 00:12:43.980
Detection API.

00:12:43.980 --> 00:12:46.140
Let's take a look at
the demonstration.

00:12:46.140 --> 00:12:50.664
So I tried used here
MG webcam to show--

00:12:50.664 --> 00:12:52.580
LAURENCE MORONEY: Switch
to the laptop please.

00:12:52.580 --> 00:12:54.350
KAZ SATO: Yeah.

00:12:54.350 --> 00:12:56.120
So this is how it looks.

00:12:56.120 --> 00:12:59.400
It's a very small
cart, a miniature cart.

00:12:59.400 --> 00:13:05.280
And we have a Raspberry Pi
and a display and a camera.

00:13:05.280 --> 00:13:08.880
So if you put something like--

00:13:08.880 --> 00:13:13.050
this is a fake eggplant.

00:13:13.050 --> 00:13:15.810
I bought it in a Japanese store.

00:13:15.810 --> 00:13:18.990
LAURENCE MORONEY: Also known as
an aubergine for us Europeans.

00:13:18.990 --> 00:13:21.682
KAZ SATO: Or a tomato.

00:13:21.682 --> 00:13:23.390
LAURENCE MORONEY: Also
known as a tomato.

00:13:23.390 --> 00:13:25.473
KAZ SATO: And how Object
Detection API would look.

00:13:25.473 --> 00:13:28.100
So please switch--

00:13:28.100 --> 00:13:29.000
I should ask him.

00:13:29.000 --> 00:13:29.750
Yeah.

00:13:29.750 --> 00:13:31.190
So let's wait a while.

00:13:31.190 --> 00:13:32.690
LAURENCE MORONEY:
I need to refresh?

00:13:36.882 --> 00:13:37.590
Should I refresh?

00:13:37.590 --> 00:13:39.030
KAZ SATO: Is it working?

00:13:39.030 --> 00:13:42.830
Maybe a network issue.

00:13:42.830 --> 00:13:44.000
Oh yeah, there you go.

00:13:44.000 --> 00:13:44.500
So--

00:13:44.500 --> 00:13:46.710
[APPLAUSE]

00:13:46.710 --> 00:13:49.050
KAZ SATO: Thank you.

00:13:49.050 --> 00:13:52.320
So it's so easy to detect
what kind of the object

00:13:52.320 --> 00:13:55.120
and how many of them you
have in the shopping cart.

00:13:55.120 --> 00:13:56.730
So please go back to the slide.

00:13:56.730 --> 00:13:59.130
So that worked.

00:13:59.130 --> 00:14:01.190
So that was a very
simple scenario

00:14:01.190 --> 00:14:05.110
where we just counted the
items and classified them.

00:14:05.110 --> 00:14:07.830
But you may think that what's
the point of using Cloud

00:14:07.830 --> 00:14:08.970
for this kind of detection?

00:14:08.970 --> 00:14:10.530
And actually, that is true.

00:14:10.530 --> 00:14:13.680
You can run the Object
Detection API just

00:14:13.680 --> 00:14:17.030
inside the Raspberry Pi box.

00:14:17.030 --> 00:14:18.530
And you don't have
to use the Cloud.

00:14:18.530 --> 00:14:21.840
But if you can collect all
the data on the Cloud side

00:14:21.840 --> 00:14:23.660
with the thousands
o fthe recalls,

00:14:23.660 --> 00:14:27.510
then you can extract certain
or some collective intelligence

00:14:27.510 --> 00:14:30.100
from thousands of
the passive recalls.

00:14:30.100 --> 00:14:32.830
For example, you can train
a machine learning model

00:14:32.830 --> 00:14:36.330
with all the shopping
items you are adding

00:14:36.330 --> 00:14:38.310
to the cart, thousands of them.

00:14:38.310 --> 00:14:40.350
You can train a
machine running model

00:14:40.350 --> 00:14:42.720
that can predict what will
be the next item you will be

00:14:42.720 --> 00:14:44.490
putting into the shopping cart.

00:14:44.490 --> 00:14:48.120
That would be detecting
the location proximity

00:14:48.120 --> 00:14:52.010
starting from the vegetables
and fruit and meat--

00:14:52.010 --> 00:14:55.590
like a chicken-- and
the spices and pasta

00:14:55.590 --> 00:14:59.700
based on all their past
history of the shoppers.

00:14:59.700 --> 00:15:02.100
And you can also
have a small display

00:15:02.100 --> 00:15:04.280
with it showing you
a recommendation

00:15:04.280 --> 00:15:06.360
for the next item to add.

00:15:06.360 --> 00:15:09.570
That would be working as a
navigator for the shoppers.

00:15:09.570 --> 00:15:13.530
So let's call it as a
Smart Shopping Navigator.

00:15:13.530 --> 00:15:15.270
And what kind of
machine learning model

00:15:15.270 --> 00:15:18.705
we should design for
implementing the Navigator?

00:15:18.705 --> 00:15:22.410
At first, we have to
represent what kind of items

00:15:22.410 --> 00:15:23.400
you have in the cart.

00:15:23.400 --> 00:15:25.660
So if you have the
tomato in the cart,

00:15:25.660 --> 00:15:28.830
we may have one-hot vector.

00:15:28.830 --> 00:15:31.020
That represents your
tomato in your cart.

00:15:31.020 --> 00:15:35.160
In this case, you would have
a 1.0 as a value in a vector.

00:15:35.160 --> 00:15:37.800
And if you put
eggplant in the cart,

00:15:37.800 --> 00:15:41.520
you would have another
1.0 value in the vector.

00:15:41.520 --> 00:15:44.560
If you have the chicken, then
you would have another 1.0

00:15:44.560 --> 00:15:45.520
for chicken.

00:15:45.520 --> 00:15:50.190
So this multiple one-hot
vector represents the cart item

00:15:50.190 --> 00:15:51.280
history.

00:15:51.280 --> 00:15:54.250
And with TensorFlow, you
can write code like this.

00:15:54.250 --> 00:15:56.850
So you have a dictionary
for shopping items.

00:15:56.850 --> 00:15:58.800
And you can code
one-hot function

00:15:58.800 --> 00:16:02.130
to encode the shopping
items as a vector.

00:16:02.130 --> 00:16:04.350
And then you can have
the multiple vectors

00:16:04.350 --> 00:16:06.640
that represents the
cart item history.

00:16:06.640 --> 00:16:08.040
And now we have the history.

00:16:08.040 --> 00:16:12.030
And how do you detect the
changes in the history?

00:16:12.030 --> 00:16:15.670
In this case, you can use the
convolution-- single dimension

00:16:15.670 --> 00:16:18.120
convolution or 1D convolution.

00:16:18.120 --> 00:16:19.740
And convolution in
machine learning

00:16:19.740 --> 00:16:22.350
is usually used to
detect certain patterns

00:16:22.350 --> 00:16:24.550
in a local group of big data.

00:16:24.550 --> 00:16:26.700
For example, if you
have a 2D image,

00:16:26.700 --> 00:16:29.430
you can apply a 2D convolution
to find some shape,

00:16:29.430 --> 00:16:30.990
some patterns in the image.

00:16:30.990 --> 00:16:34.020
That is how CNN or
convolution neural network

00:16:34.020 --> 00:16:35.890
works for image convolution.

00:16:35.890 --> 00:16:37.620
But you can also
apply the convolution

00:16:37.620 --> 00:16:41.370
to single dimensional data,
such as time series data.

00:16:41.370 --> 00:16:45.990
For example, you can apply 1D
convolution on the cart item

00:16:45.990 --> 00:16:46.564
history.

00:16:46.564 --> 00:16:48.480
They can detect that
what kind of changes that

00:16:48.480 --> 00:16:50.520
happen inside the cart items.

00:16:50.520 --> 00:16:53.170
And then you can flatten the
output to get the result.

00:16:53.170 --> 00:16:55.860
And with TensorFlow, you can
write the code like this.

00:16:55.860 --> 00:16:59.470
You can code the .conv1d
function to apply the single

00:16:59.470 --> 00:17:02.800
dimension of convolution and
then code the flatten to get

00:17:02.800 --> 00:17:08.030
the result. So now we have
the cart item change history.

00:17:08.030 --> 00:17:10.920
And we may also want to
take in other factors,

00:17:10.920 --> 00:17:14.280
such as seasonality-- whether
it's winter or summer--

00:17:14.280 --> 00:17:16.079
or time of day
because shoppers may

00:17:16.079 --> 00:17:19.359
want to choose food items
based on the seasonality--

00:17:19.359 --> 00:17:22.560
whether it's a summer hot day
or whether it's a cold day.

00:17:22.560 --> 00:17:26.230
So we put everything into
a single MLP Multi-layer

00:17:26.230 --> 00:17:29.080
Perceptron-- which is a
classic old neural network with

00:17:29.080 --> 00:17:30.720
the three layers--

00:17:30.720 --> 00:17:34.120
to predict next items to add.

00:17:34.120 --> 00:17:36.160
With TensorFlow,
you can write code

00:17:36.160 --> 00:17:38.940
to condense everything
into one Tensor.

00:17:38.940 --> 00:17:42.360
And you would define the
three layers of the MLP.

00:17:42.360 --> 00:17:43.710
And that's it.

00:17:43.710 --> 00:17:45.850
Let's take a look at this
how this Smart Shopping

00:17:45.850 --> 00:17:47.874
Navigator works.

00:17:47.874 --> 00:17:49.790
LAURENCE MORONEY: Switch
to the laptop please.

00:17:49.790 --> 00:17:52.330
KAZ SATO: Let's
switch to the laptop.

00:17:52.330 --> 00:17:58.860
If you put the eggplant, then
it should detect the eggplant.

00:17:58.860 --> 00:18:02.120
LAURENCE MORONEY:
I see a shadow.

00:18:02.120 --> 00:18:04.970
KAZ SATO: So you are
watching the same screen

00:18:04.970 --> 00:18:06.330
I'm watching here.

00:18:06.330 --> 00:18:10.850
So at the right side, you'll see
what kind of recipes and items

00:18:10.850 --> 00:18:12.140
are recommended.

00:18:12.140 --> 00:18:16.760
So it looks like the system
recommends the pasta eggplant

00:18:16.760 --> 00:18:18.170
bake.

00:18:18.170 --> 00:18:21.180
And I wanted to make a pasta.

00:18:21.180 --> 00:18:23.960
So I would put the tomato.

00:18:27.610 --> 00:18:30.340
Then the Navigator would
show the other things

00:18:30.340 --> 00:18:32.050
you have to add would be--

00:18:32.050 --> 00:18:32.960
I already have it.

00:18:32.960 --> 00:18:38.770
But eggplant, tomato,
and I want to make the--

00:18:42.990 --> 00:18:45.450
I want to make a pasta.

00:18:45.450 --> 00:18:47.676
LAURENCE MORONEY: The
mouse is also working.

00:18:47.676 --> 00:18:51.010
KAZ SATO: The mouse is working.

00:18:51.010 --> 00:18:52.500
Well, somehow
doesn't show pasta.

00:18:52.500 --> 00:18:53.000
But anyway--

00:18:53.000 --> 00:18:54.560
LAURENCE MORONEY: Refresh?

00:18:54.560 --> 00:18:58.620
KAZ SATO: Yeah, I could
try putting just chicken.

00:18:58.620 --> 00:19:04.280
So that you can just follow
the items on the screen so

00:19:04.280 --> 00:19:08.510
you can find all the items to
make the eggplant tomato pasta.

00:19:08.510 --> 00:19:10.550
That's how it works.

00:19:10.550 --> 00:19:11.330
Thank you.

00:19:11.330 --> 00:19:13.540
So please go back to
the screen, this right.

00:19:16.500 --> 00:19:19.140
So as you have seen
on the demonstration,

00:19:19.140 --> 00:19:22.470
by showing you recipe
ideas and next item to add,

00:19:22.470 --> 00:19:25.210
it works just like a car
navigator for the shoppers.

00:19:25.210 --> 00:19:27.840
So the shoppers can just
follow the next item

00:19:27.840 --> 00:19:31.320
to add to fill the cart
with all items required

00:19:31.320 --> 00:19:34.310
to cook with a certain recipe.

00:19:34.310 --> 00:19:37.430
And that was an example of how
the Cloud can be empowering

00:19:37.430 --> 00:19:40.740
for the IoT devices, not only
for collecting data but also

00:19:40.740 --> 00:19:44.250
you can analyze it and learn
some collective intelligence

00:19:44.250 --> 00:19:44.850
from it.

00:19:44.850 --> 00:19:46.620
It's not just in
the IoT anymore.

00:19:46.620 --> 00:19:49.100
It's an internet
of smart things.

00:19:49.100 --> 00:19:51.270
And this demonstration
was actually

00:19:51.270 --> 00:19:55.380
built by Google Cloud
partner called Groovenauts.

00:19:55.380 --> 00:19:58.230
And they have open sourced
everything on GitHub.

00:19:58.230 --> 00:20:00.300
So if you're interested,
please go to the GitHub

00:20:00.300 --> 00:20:02.490
and search with Smart
Shopping Navigator

00:20:02.490 --> 00:20:04.560
to find out what kind
of code you would write.

00:20:04.560 --> 00:20:07.620
And they also provide
their production solution

00:20:07.620 --> 00:20:10.590
called the Magellan Blocks where
you have the user interface

00:20:10.590 --> 00:20:14.280
to build a whole data pipeline
for collecting the IoT data

00:20:14.280 --> 00:20:17.550
and analyzing it and
training the model.

00:20:17.550 --> 00:20:20.087
So with that, I direct you
back to back stage to Laurence.

00:20:20.087 --> 00:20:21.920
LAURENCE MORONEY: All
right, thank you, Kaz.

00:20:21.920 --> 00:20:22.961
Pretty cool stuff, right?

00:20:22.961 --> 00:20:28.530
[APPLAUSE]

00:20:28.530 --> 00:20:30.780
So now the third scenario
that we wanted to look at

00:20:30.780 --> 00:20:33.395
was on-device
inference and training.

00:20:33.395 --> 00:20:34.770
And there's a few
different types

00:20:34.770 --> 00:20:36.930
of devices you can do
inference and training on.

00:20:36.930 --> 00:20:40.170
So for example, you can do it
on a mobile phone or a tablet.

00:20:40.170 --> 00:20:42.030
You can do it on a Raspberry Pi.

00:20:42.030 --> 00:20:44.360
Or you can do it on an
Android Things device.

00:20:44.360 --> 00:20:46.260
And there's a really
cool video of doing it

00:20:46.260 --> 00:20:49.410
on a mobile phone or tablet
that I've put at this QR code.

00:20:49.410 --> 00:20:52.070
So take a look at this QR
code, watch this video.

00:20:52.070 --> 00:20:53.320
I'm not going to show it here.

00:20:53.320 --> 00:20:54.810
But the idea behind
this video is

00:20:54.810 --> 00:20:56.972
that if you went to
in TensorFlow Summit

00:20:56.972 --> 00:20:57.930
you would have seen it.

00:20:57.930 --> 00:21:01.650
But it's farmers in
Tanzania in Africa

00:21:01.650 --> 00:21:03.330
who don't have
Cloud connectivity

00:21:03.330 --> 00:21:06.120
and who rely on a
plant called cassava,

00:21:06.120 --> 00:21:08.790
that if the cassava
plant gets diseased,

00:21:08.790 --> 00:21:11.070
it can kill and
impact an entire crop.

00:21:11.070 --> 00:21:13.710
And it's hard for humans
to eyeball it and see it.

00:21:13.710 --> 00:21:15.810
But they built a
machine learn system

00:21:15.810 --> 00:21:18.720
that all they do they wave
their phone over the leaves,

00:21:18.720 --> 00:21:20.370
and they can diagnose
diseases early.

00:21:20.370 --> 00:21:21.852
It's really, really cool.

00:21:21.852 --> 00:21:24.060
So that kind of on-device
inference without any Cloud

00:21:24.060 --> 00:21:25.980
connectivity is possible
through something

00:21:25.980 --> 00:21:27.510
called TensorFlow Lite.

00:21:27.510 --> 00:21:30.660
With TensorFlow Lite you can
also do inference and training

00:21:30.660 --> 00:21:31.741
on a Raspberry Pi.

00:21:31.741 --> 00:21:33.240
And I have a car
here that I'm going

00:21:33.240 --> 00:21:36.360
to show in a moment that's
driven off of a Raspberry Pi.

00:21:36.360 --> 00:21:38.620
And if you're in
the Sandbox area,

00:21:38.620 --> 00:21:41.620
you would have seen cars like
this one self-driving around.

00:21:41.620 --> 00:21:44.340
But basically, there's a little
camera at the front here.

00:21:44.340 --> 00:21:46.410
And what I would do is
I would manually drive

00:21:46.410 --> 00:21:48.790
the car, record what I'm doing.

00:21:48.790 --> 00:21:50.820
And then based on the
telemetry that I'm

00:21:50.820 --> 00:21:52.980
sending to the car
to drive it around

00:21:52.980 --> 00:21:55.710
and the corresponding video,
that's giving us the features

00:21:55.710 --> 00:21:58.800
and labels that we want that the
car will then remember and then

00:21:58.800 --> 00:22:00.160
use that to self-drive.

00:22:00.160 --> 00:22:03.184
If we switch back to
slides for a moment.

00:22:03.184 --> 00:22:04.850
And then finally,
there's the third one,

00:22:04.850 --> 00:22:06.308
which we'll show
in a moment that's

00:22:06.308 --> 00:22:07.540
on an Android Things device.

00:22:07.540 --> 00:22:10.690
All this is made possible
because of TensorFlow Lite.

00:22:10.690 --> 00:22:13.390
And I strongly recommend
check out TensorFlow Lite,

00:22:13.390 --> 00:22:15.430
and check out the
talks TensorFlow Lite.

00:22:15.430 --> 00:22:17.140
But the idea behind
TensorFlow Lite

00:22:17.140 --> 00:22:21.070
is that if you want to train
a machine learned model,

00:22:21.070 --> 00:22:22.960
we have a bunch of
converters that will then

00:22:22.960 --> 00:22:24.970
flatten that model
and shrink it to make

00:22:24.970 --> 00:22:26.627
it more mobile friendly.

00:22:26.627 --> 00:22:28.210
There's an interpreter
core then which

00:22:28.210 --> 00:22:30.910
is used to execute that
model so you can do inference

00:22:30.910 --> 00:22:31.804
on the model.

00:22:31.804 --> 00:22:33.220
So for example,
things like if you

00:22:33.220 --> 00:22:34.960
want to do an image
classification,

00:22:34.960 --> 00:22:36.850
it'll do that
locally on the device

00:22:36.850 --> 00:22:38.620
without round-tripping
to the Cloud.

00:22:38.620 --> 00:22:40.120
And then that's all
the stuff that's

00:22:40.120 --> 00:22:42.490
needed like operation kernels
and hardware acceleration

00:22:42.490 --> 00:22:45.160
to take advantage of the
mobile hardware that you have.

00:22:45.160 --> 00:22:46.450
It runs on Raspberry Pi.

00:22:46.450 --> 00:22:47.410
It runs on iOS.

00:22:47.410 --> 00:22:48.940
And of course, it
runs on Android.

00:22:48.940 --> 00:22:51.010
And it works really
great on a Pixel.

00:22:51.010 --> 00:22:52.590
I have a Pixel 2 up here.

00:22:52.590 --> 00:22:55.600
And if you want to see a demo
of it, come see me afterwards,

00:22:55.600 --> 00:22:58.000
and I can show real time
inference on the Pixel.

00:22:58.000 --> 00:23:00.610
Doesn't really work on
the stage that well.

00:23:00.610 --> 00:23:03.370
Now here's a video that I
shot of me doing real time

00:23:03.370 --> 00:23:04.240
inference.

00:23:04.240 --> 00:23:06.670
And you can see it saw
the coffee mug correctly.

00:23:06.670 --> 00:23:09.100
And here, this
coffee mug kind of

00:23:09.100 --> 00:23:11.449
looks a little bit like
a mixing bowl so it got--

00:23:11.449 --> 00:23:13.240
at some points, it felt
like a mixing bowl.

00:23:13.240 --> 00:23:15.010
And I know that's
a horrible product

00:23:15.010 --> 00:23:17.390
placement for my show
"Coffee with a Googler",

00:23:17.390 --> 00:23:18.610
but I had to do it.

00:23:18.610 --> 00:23:21.580
And it was able to recognize
a mouse and stuff like that.

00:23:21.580 --> 00:23:25.120
So this is what it would
look like running on Android.

00:23:25.120 --> 00:23:28.000
And so for the self-driving car
that I've been talking about,

00:23:28.000 --> 00:23:30.290
you can see on the right
is the Raspberry Pi.

00:23:30.290 --> 00:23:32.890
On the left, is something
called a pulse wave modulation

00:23:32.890 --> 00:23:33.910
controller.

00:23:33.910 --> 00:23:36.490
And that's what actually
drives the car itself.

00:23:36.490 --> 00:23:39.670
So I have a TensorFlow Lite
running on the Raspberry Pi.

00:23:39.670 --> 00:23:41.920
And that's what we'll
actually drive the car.

00:23:41.920 --> 00:23:44.846
And this is built on a
project called Donkey Car.

00:23:44.846 --> 00:23:47.470
And if you want to go and take
a look at Donkey Car and details

00:23:47.470 --> 00:23:49.994
about Donkey Car,
they're at this URL.

00:23:49.994 --> 00:23:51.910
So should we take a look
at what it would look

00:23:51.910 --> 00:23:54.580
like to actually train the car?

00:23:54.580 --> 00:23:56.350
So if we can switch
to my laptop please.

00:23:59.630 --> 00:24:02.900
So I've actually started up
the Raspberry Pi on the car.

00:24:02.900 --> 00:24:05.300
And there's a little web
server running on that.

00:24:05.300 --> 00:24:07.640
So let me go and see
if I can access it.

00:24:07.640 --> 00:24:08.570
Hopefully, it'll obey.

00:24:12.750 --> 00:24:14.470
Oh no, it's refusing to connect.

00:24:14.470 --> 00:24:17.160
Hang on.

00:24:17.160 --> 00:24:22.170
Oh sorry, CD D2.

00:24:22.170 --> 00:24:24.650
So what I'm doing is
it runs on Python.

00:24:24.650 --> 00:24:26.910
So I'm just running
the Python code.

00:24:26.910 --> 00:24:28.696
Sorry, Kaz, to make
you hold it so long.

00:24:28.696 --> 00:24:30.570
So this is actually
booting up the web server

00:24:30.570 --> 00:24:33.430
that's on the car that I would
then use to train and drive it.

00:24:33.430 --> 00:24:36.120
So take a moment
just to book that up.

00:24:36.120 --> 00:24:38.640
But what will happen is so if
I want to control the car when

00:24:38.640 --> 00:24:40.380
I'm training it,
obviously, it's hard for me

00:24:40.380 --> 00:24:41.213
to do it on its own.

00:24:41.213 --> 00:24:42.760
It has that little web server.

00:24:42.760 --> 00:24:45.990
The web server is connected
to a hotspot on my Pixel.

00:24:45.990 --> 00:24:48.250
My laptop's connected
to the same one.

00:24:48.250 --> 00:24:49.680
So it's starting up that server.

00:24:49.680 --> 00:24:51.210
It looks like that
server's done.

00:24:51.210 --> 00:24:52.320
And here it is.

00:24:52.320 --> 00:24:55.080
So as Kaz moves it around,
you'll see that one.

00:24:55.080 --> 00:24:57.270
And if I would to try
and drive the car,

00:24:57.270 --> 00:24:58.452
I made a bit of a mistake.

00:24:58.452 --> 00:24:59.910
If you've been over
to the Sandbox,

00:24:59.910 --> 00:25:01.409
you would have seen
the cars they're

00:25:01.409 --> 00:25:02.650
using are really small ones.

00:25:02.650 --> 00:25:04.080
I didn't read the
specs properly.

00:25:04.080 --> 00:25:06.360
And I bought this one, and
it's an absolute beast.

00:25:06.360 --> 00:25:07.845
It goes really, really fast.

00:25:07.845 --> 00:25:09.970
I don't dare put it on the
floor and start driving,

00:25:09.970 --> 00:25:10.980
because it will
take off and it will

00:25:10.980 --> 00:25:12.370
land about three rows back.

00:25:12.370 --> 00:25:13.530
So watch out, Kaz.

00:25:13.530 --> 00:25:15.870
And you see this is what
it looks like if I'm

00:25:15.870 --> 00:25:17.430
driving and training it.

00:25:17.430 --> 00:25:18.360
I can steer.

00:25:18.360 --> 00:25:20.400
And I can control it like this.

00:25:20.400 --> 00:25:23.220
So what it's doing
right now is recording

00:25:23.220 --> 00:25:25.200
what it would see on
the webcam from the car

00:25:25.200 --> 00:25:28.110
actually moving and storing
all that stuff that would then

00:25:28.110 --> 00:25:31.576
use to train a TensorFlow
model for that specific area.

00:25:31.576 --> 00:25:33.450
So when you see the cars
over in the Sandbox,

00:25:33.450 --> 00:25:35.236
they're on that figure
of an eight track.

00:25:35.236 --> 00:25:37.110
So we drove them around
that figure of eight.

00:25:37.110 --> 00:25:38.700
We train them in that way.

00:25:38.700 --> 00:25:40.800
And then instead of
launching it in training mode

00:25:40.800 --> 00:25:43.110
as I have it now, you
just launch in drive mode,

00:25:43.110 --> 00:25:44.820
and they go and they
drive themselves.

00:25:44.820 --> 00:25:46.819
So you can build one of
these as a Donkey Cart--

00:25:46.819 --> 00:25:47.940
OK, we can put it down.

00:25:47.940 --> 00:25:50.980
We can build one of these using
the Donkey Car project cost.

00:25:50.980 --> 00:25:53.020
This one is a little
bit more expensive,

00:25:53.020 --> 00:25:55.380
but they generally cost
maybe about $200 total

00:25:55.380 --> 00:25:56.285
for everything.

00:25:56.285 --> 00:25:58.410
And you can build your own
little self-driving car.

00:25:58.410 --> 00:25:59.451
And it's all open source.

00:25:59.451 --> 00:26:00.779
It's really, really cool.

00:26:00.779 --> 00:26:01.320
So thank you.

00:26:01.320 --> 00:26:04.372
Can we go back to
the slides, please?

00:26:04.372 --> 00:26:05.830
The motor on the
car is really loud

00:26:05.830 --> 00:26:10.227
so I'm going to turn it off
because we hear it whizzing.

00:26:10.227 --> 00:26:12.310
OK so that's what it's
like to train a Donkey Car.

00:26:12.310 --> 00:26:16.200
And with on-device inference,
you can then have a--

00:26:16.200 --> 00:26:17.040
believe it or not--

00:26:17.040 --> 00:26:18.600
model self-driving car.

00:26:18.600 --> 00:26:19.977
I think that's really cool.

00:26:19.977 --> 00:26:22.310
Then the next thing was Android
Things that I mentioned.

00:26:22.310 --> 00:26:25.491
And did everybody
get one of these?

00:26:25.491 --> 00:26:26.550
All right.

00:26:26.550 --> 00:26:28.380
So these are just so cool.

00:26:28.380 --> 00:26:30.536
So this is just a little--

00:26:30.536 --> 00:26:32.160
this one isn't actually
a Raspberry Pi.

00:26:32.160 --> 00:26:34.790
It's a different developer
board but a similar concept.

00:26:34.790 --> 00:26:37.830
And with Android Things
being able to execute stuff

00:26:37.830 --> 00:26:40.530
and with TensorFlow Lite
running on Android Things,

00:26:40.530 --> 00:26:41.860
you can start doing inference.

00:26:41.860 --> 00:26:43.950
And has anybody
done the Code Lab?

00:26:43.950 --> 00:26:46.390
Have you tried it out to
do inference on these?

00:26:46.390 --> 00:26:48.239
Try it out and
build it and you'll

00:26:48.239 --> 00:26:49.530
be able to do things like this.

00:26:49.530 --> 00:26:53.860
So this afternoon back in
my hotel on this device,

00:26:53.860 --> 00:26:56.115
I kind of pointed it
out at a water bottle.

00:26:56.115 --> 00:26:58.740
And I thought it was interesting
that it gives you three things

00:26:58.740 --> 00:26:59.615
that it thinks it is.

00:26:59.615 --> 00:27:02.070
It thought it was a water
bottle, a pop bottle, or toilet

00:27:02.070 --> 00:27:02.569
tissue.

00:27:02.569 --> 00:27:05.730
I don't know if it's because
of the circular parts of it

00:27:05.730 --> 00:27:06.870
or anything like that.

00:27:06.870 --> 00:27:08.430
And then I tried it on this one.

00:27:08.430 --> 00:27:11.640
And it's said a coffee
cup, a coffee mug, a cup,

00:27:11.640 --> 00:27:12.750
or a measuring cup.

00:27:12.750 --> 00:27:14.640
And particularly way
the handle is placed,

00:27:14.640 --> 00:27:17.310
I thought it would be really
interesting to try and fool it.

00:27:17.310 --> 00:27:18.810
With the handle the
way it's placed,

00:27:18.810 --> 00:27:20.490
I thought it might
think it was a pitcher.

00:27:20.490 --> 00:27:22.281
Because sometimes when
I do mugs like that,

00:27:22.281 --> 00:27:24.330
it kind of classifies
as a pitcher.

00:27:24.330 --> 00:27:28.860
And then of course, this
one, I tried on my Android,

00:27:28.860 --> 00:27:30.270
my little French Android.

00:27:30.270 --> 00:27:32.490
And it thought he was a
piggy bank, a teapot--

00:27:32.490 --> 00:27:34.890
I guess he's a little teapot,
the way he's standing--

00:27:34.890 --> 00:27:36.180
or maybe even a spotlight.

00:27:36.180 --> 00:27:38.670
And maybe it's the shape of
it or something like that.

00:27:38.670 --> 00:27:40.290
But that's the stuff
that's built in.

00:27:40.290 --> 00:27:42.420
And when you assemble this
device that you've got,

00:27:42.420 --> 00:27:44.640
that app is actually
already running on here.

00:27:44.640 --> 00:27:46.167
And that app is open source.

00:27:46.167 --> 00:27:48.000
And one of the really
cool things you can do

00:27:48.000 --> 00:27:50.310
is that the image model
that app is trained

00:27:50.310 --> 00:27:53.760
for, you can actually retrain
that for your own images.

00:27:53.760 --> 00:27:55.260
I've been working
on a version of it

00:27:55.260 --> 00:27:56.520
that I'm going to
add to the car.

00:27:56.520 --> 00:27:58.930
And maybe we'll be able to
talk about it at a future I/O

00:27:58.930 --> 00:28:01.530
where I'm retraining the
car to recognize things

00:28:01.530 --> 00:28:02.970
like traffic lights.

00:28:02.970 --> 00:28:04.860
So if it sees a red
light, it will stop.

00:28:04.860 --> 00:28:06.417
If it sees a green
light, it will go.

00:28:06.417 --> 00:28:09.000
And all the code for you to do
that is available with this kit

00:28:09.000 --> 00:28:09.666
when you get it.

00:28:09.666 --> 00:28:10.459
So give it a try.

00:28:10.459 --> 00:28:12.000
And for those of
you watching online,

00:28:12.000 --> 00:28:13.952
just check out Android Things.

00:28:13.952 --> 00:28:14.910
You can buy these kits.

00:28:14.910 --> 00:28:16.785
They're relatively cheap,
and they're so much

00:28:16.785 --> 00:28:18.730
fun to play with.

00:28:18.730 --> 00:28:21.220
So the Code Lab that I
mentioned, if you're here

00:28:21.220 --> 00:28:22.250
at I/O you can go over.

00:28:22.250 --> 00:28:24.710
And try it out if you want
to try it on your machines

00:28:24.710 --> 00:28:27.280
at home, the URL for
it is at this QRL code.

00:28:27.280 --> 00:28:28.790
Go give it a--

00:28:28.790 --> 00:28:30.130
have a play with it.

00:28:30.130 --> 00:28:31.650
It's a lot of fun.

00:28:31.650 --> 00:28:34.460
So in recap, we
spoke a little bit

00:28:34.460 --> 00:28:36.890
about internet of things and
AI and about the trends that

00:28:36.890 --> 00:28:39.920
are happening that the explosive
growth that is going on,

00:28:39.920 --> 00:28:43.677
the growth of actual devices and
the amount of data that they're

00:28:43.677 --> 00:28:46.010
producing and then the things
that you can do with that.

00:28:46.010 --> 00:28:48.362
We looked at with a
sensor data on an Ardiuno.

00:28:48.362 --> 00:28:49.820
We looked at Cloud
Scale AI, and we

00:28:49.820 --> 00:28:51.422
looked at on-device inference.

00:28:51.422 --> 00:28:52.880
Now there's a whole
bunch of things

00:28:52.880 --> 00:28:56.810
that you can do to
go take a look at.

00:28:56.810 --> 00:28:57.790
Come on slide, animate.

00:28:57.790 --> 00:28:58.740
There we go.

00:28:58.740 --> 00:29:01.220
So things you can try out,
number one, writing data

00:29:01.220 --> 00:29:03.870
from your internet of things
device to Cloud Storage.

00:29:03.870 --> 00:29:07.054
There's great details
on it this URL.

00:29:07.054 --> 00:29:09.470
And if you want to explore the
TensorFlow Object Detection

00:29:09.470 --> 00:29:10.310
API--

00:29:10.310 --> 00:29:13.370
which is what Kaz was using here
when it was detecting tomatoes

00:29:13.370 --> 00:29:16.040
and eggplants or aubergines
and that kind of stuff--

00:29:16.040 --> 00:29:19.200
you can find details
on that at this link.

00:29:19.200 --> 00:29:21.680
IoT and the Cloud ML
engine, details for that

00:29:21.680 --> 00:29:25.450
are at this link and this one.

00:29:25.450 --> 00:29:27.419
And TensorFlow and
TensorFlow Lite--

00:29:27.419 --> 00:29:29.710
and all of the mobile scenarios
that I was showing here

00:29:29.710 --> 00:29:31.450
were based on TensorFlow Lit--

00:29:31.450 --> 00:29:33.080
you can learn about
that at this link

00:29:33.080 --> 00:29:35.080
or attend the talks
if you're here.

00:29:35.080 --> 00:29:37.330
And finally, exploring
Android Things itself,

00:29:37.330 --> 00:29:38.736
I find it super cool.

00:29:38.736 --> 00:29:41.110
And it's really nice because
if you're already an Android

00:29:41.110 --> 00:29:43.240
developer, you can
start building stuff

00:29:43.240 --> 00:29:45.020
using your existing skill sets.

00:29:45.020 --> 00:29:47.020
When I was doing the thing
for the Arduino here,

00:29:47.020 --> 00:29:50.640
I had to give myself a crash
course in C. But like I said,

00:29:50.640 --> 00:29:52.920
if you're already
an Android developer

00:29:52.920 --> 00:29:55.679
and you're used to using Java
or Kotlin to build your Android

00:29:55.679 --> 00:29:57.970
apps, then you can start
building Things apps with that

00:29:57.970 --> 00:29:58.756
too.

00:29:58.756 --> 00:30:00.130
So with all of
that, we just want

00:30:00.130 --> 00:30:01.254
to say thank you very much.

00:30:01.254 --> 00:30:03.110
Feedback is always welcome.

00:30:03.110 --> 00:30:04.798
We've love to hear,
and it's this URL.

00:30:04.798 --> 00:30:05.298
Thank you.

00:30:05.298 --> 00:30:27.049
[MUSIC PLAYING]

