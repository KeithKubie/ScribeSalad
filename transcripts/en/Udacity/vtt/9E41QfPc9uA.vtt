WEBVTT
Kind: captions
Language: en

00:00:00.400 --> 00:00:04.790
This lesson begins by reviewing the two
dimensional linear programming problems

00:00:04.790 --> 00:00:08.300
that high school students often
solve in their algebra two classes.

00:00:08.300 --> 00:00:12.620
Then it extends the equations to n
dimensions and captures the essential

00:00:12.620 --> 00:00:18.290
intuition that optimal solutions are at
the corners of the feasible region.

00:00:18.290 --> 00:00:20.380
And we state this rigorously,

00:00:20.380 --> 00:00:23.140
with the fundamental theorem
of linear programming.

00:00:23.140 --> 00:00:26.270
And then finally, the lesson will
cover the simplex algorithm,

00:00:26.270 --> 00:00:29.950
a very practical way for
solving these optimizations.

00:00:29.950 --> 00:00:32.800
There are many good references
on linear programming.

00:00:32.800 --> 00:00:36.800
This treatment will follow most closely,
David Luenberger's Linear and

00:00:36.800 --> 00:00:38.570
Nonlinear Programming.

00:00:38.570 --> 00:00:42.110
Before we begin, however, I should
mention that parts of this lecture

00:00:42.110 --> 00:00:45.680
will use notation and
some ideas from linear algebra.

00:00:45.680 --> 00:00:48.210
For notation,
we will use capital letters for

00:00:48.210 --> 00:00:52.190
matrices, thus A might
be this matrix here.

00:00:52.190 --> 00:00:58.080
For column vectors, we'll use lower case
letters, so x might be this vector here.

00:00:59.180 --> 00:01:02.010
Also, we'll often use
the lowercase version

00:01:02.010 --> 00:01:03.870
of a matrix to indicate a column.

00:01:04.920 --> 00:01:10.510
Thus, a two here refers to
the second column of the matrix A.

00:01:10.510 --> 00:01:15.710
We indicate the transpose of the matrix
by giving it a T in the superscript, and

00:01:15.710 --> 00:01:18.549
this just reverses the meaning
of the rows and columns.

00:01:19.580 --> 00:01:24.550
This notation, then allows us to use
C transpose X for the dot product.

00:01:25.570 --> 00:01:30.300
This is a row vector, times
a column vector, which ends up just

00:01:30.300 --> 00:01:35.090
as a single entry matrix, which, by
convention, we'll interpret as a scalar.

00:01:36.110 --> 00:01:41.080
As far as concepts go, the ideas of how
to represent a system of equations as

00:01:41.080 --> 00:01:45.050
matrices of linear
independence of vectors,

00:01:45.050 --> 00:01:48.810
matrix rank and
matrix inverse should all be familiar.

00:01:49.860 --> 00:01:52.740
If these ideas aren't familiar
then it would be a good idea

00:01:52.740 --> 00:01:56.470
to refresh your understanding before
watching the rest of this lesson.

00:01:56.470 --> 00:02:00.440
As always, it is recommended that you
watch with pencil and paper handy, so

00:02:00.440 --> 00:02:03.950
that you can pause the video and
work out details on your own, as needed.

