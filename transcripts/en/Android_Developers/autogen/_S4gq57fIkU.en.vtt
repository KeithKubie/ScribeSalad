WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:06.460 align:start position:0%
 
[Music]

00:00:06.460 --> 00:00:06.470 align:start position:0%
[Music]
 

00:00:06.470 --> 00:00:10.310 align:start position:0%
[Music]
hello<00:00:07.470><c> everyone</c><00:00:07.919><c> welcome</c><00:00:08.400><c> to</c><00:00:08.670><c> the</c><00:00:08.880><c> talk</c><00:00:09.320><c> my</c>

00:00:10.310 --> 00:00:10.320 align:start position:0%
hello everyone welcome to the talk my
 

00:00:10.320 --> 00:00:12.770 align:start position:0%
hello everyone welcome to the talk my
name<00:00:10.530><c> is</c><00:00:10.679><c> dawn</c><00:00:10.950><c> Chen</c><00:00:11.309><c> I'm</c><00:00:11.490><c> a</c><00:00:11.759><c> tech</c><00:00:11.969><c> lead</c><00:00:12.000><c> of</c><00:00:12.360><c> MLK</c>

00:00:12.770 --> 00:00:12.780 align:start position:0%
name is dawn Chen I'm a tech lead of MLK
 

00:00:12.780 --> 00:00:14.030 align:start position:0%
name is dawn Chen I'm a tech lead of MLK
team<00:00:13.230><c> at</c><00:00:13.469><c> Google</c>

00:00:14.030 --> 00:00:14.040 align:start position:0%
team at Google
 

00:00:14.040 --> 00:00:16.630 align:start position:0%
team at Google
I'm<00:00:14.670><c> here</c><00:00:15.030><c> today</c><00:00:15.179><c> to</c><00:00:15.360><c> talk</c><00:00:15.599><c> about</c><00:00:15.660><c> ml</c><00:00:16.289><c> kit</c>

00:00:16.630 --> 00:00:16.640 align:start position:0%
I'm here today to talk about ml kit
 

00:00:16.640 --> 00:00:20.390 align:start position:0%
I'm here today to talk about ml kit
Google's<00:00:17.640><c> machine</c><00:00:18.359><c> learning</c><00:00:18.810><c> SDK</c><00:00:19.800><c> for</c><00:00:20.039><c> mobile</c>

00:00:20.390 --> 00:00:20.400 align:start position:0%
Google's machine learning SDK for mobile
 

00:00:20.400 --> 00:00:23.720 align:start position:0%
Google's machine learning SDK for mobile
I<00:00:20.840><c> would</c><00:00:21.840><c> provide</c><00:00:22.020><c> overview</c><00:00:22.650><c> of</c><00:00:22.800><c> what</c><00:00:23.130><c> MLK</c>

00:00:23.720 --> 00:00:23.730 align:start position:0%
I would provide overview of what MLK
 

00:00:23.730 --> 00:00:26.509 align:start position:0%
I would provide overview of what MLK
does<00:00:24.000><c> and</c><00:00:24.960><c> also</c><00:00:25.170><c> what's</c><00:00:25.500><c> new</c><00:00:25.769><c> since</c><00:00:26.279><c> its</c>

00:00:26.509 --> 00:00:26.519 align:start position:0%
does and also what's new since its
 

00:00:26.519 --> 00:00:29.450 align:start position:0%
does and also what's new since its
inception<00:00:26.880><c> six</c><00:00:27.480><c> months</c><00:00:27.750><c> ago</c><00:00:27.960><c> I</c><00:00:28.230><c> also</c><00:00:29.070><c> share</c>

00:00:29.450 --> 00:00:29.460 align:start position:0%
inception six months ago I also share
 

00:00:29.460 --> 00:00:31.990 align:start position:0%
inception six months ago I also share
some<00:00:29.490><c> tips</c><00:00:30.029><c> and</c><00:00:30.359><c> the</c><00:00:30.539><c> best</c><00:00:30.779><c> practices</c><00:00:31.470><c> to</c>

00:00:31.990 --> 00:00:32.000 align:start position:0%
some tips and the best practices to
 

00:00:32.000 --> 00:00:35.900 align:start position:0%
some tips and the best practices to
improve<00:00:33.000><c> performance</c><00:00:33.860><c> accuracy</c><00:00:34.860><c> reduce</c><00:00:35.579><c> size</c>

00:00:35.900 --> 00:00:35.910 align:start position:0%
improve performance accuracy reduce size
 

00:00:35.910 --> 00:00:39.440 align:start position:0%
improve performance accuracy reduce size
and<00:00:36.270><c> few</c><00:00:36.809><c> other</c><00:00:36.960><c> things</c><00:00:37.380><c> in</c><00:00:38.250><c> the</c><00:00:38.430><c> end</c><00:00:38.550><c> I</c><00:00:38.940><c> will</c>

00:00:39.440 --> 00:00:39.450 align:start position:0%
and few other things in the end I will
 

00:00:39.450 --> 00:00:44.930 align:start position:0%
and few other things in the end I will
talk<00:00:39.629><c> about</c><00:00:39.800><c> what</c><00:00:40.800><c> we're</c><00:00:41.010><c> working</c><00:00:41.370><c> on</c><00:00:43.940><c> two</c>

00:00:44.930 --> 00:00:44.940 align:start position:0%
talk about what we're working on two
 

00:00:44.940 --> 00:00:48.260 align:start position:0%
talk about what we're working on two
years<00:00:45.180><c> ago</c><00:00:45.480><c> Google</c><00:00:46.170><c> CEO</c><00:00:46.620><c> sundar</c><00:00:47.520><c> Pichai</c><00:00:48.000><c> said</c>

00:00:48.260 --> 00:00:48.270 align:start position:0%
years ago Google CEO sundar Pichai said
 

00:00:48.270 --> 00:00:51.500 align:start position:0%
years ago Google CEO sundar Pichai said
we'll<00:00:49.230><c> move</c><00:00:49.410><c> from</c><00:00:49.649><c> mobile</c><00:00:50.070><c> first</c><00:00:50.340><c> to</c><00:00:50.879><c> AI</c><00:00:51.059><c> first</c>

00:00:51.500 --> 00:00:51.510 align:start position:0%
we'll move from mobile first to AI first
 

00:00:51.510 --> 00:00:55.130 align:start position:0%
we'll move from mobile first to AI first
world<00:00:52.730><c> their</c><00:00:53.730><c> intersection</c><00:00:54.360><c> of</c><00:00:54.570><c> these</c><00:00:54.899><c> two</c>

00:00:55.130 --> 00:00:55.140 align:start position:0%
world their intersection of these two
 

00:00:55.140 --> 00:00:58.479 align:start position:0%
world their intersection of these two
worlds<00:00:55.620><c> means</c><00:00:56.160><c> machine</c><00:00:56.820><c> learning</c><00:00:57.149><c> on</c><00:00:57.300><c> mobile</c>

00:00:58.479 --> 00:00:58.489 align:start position:0%
worlds means machine learning on mobile
 

00:00:58.489 --> 00:01:01.610 align:start position:0%
worlds means machine learning on mobile
in<00:00:59.489><c> recent</c><00:00:59.879><c> years</c><00:01:00.149><c> more</c><00:01:01.050><c> and</c><00:01:01.079><c> more</c><00:01:01.410><c> mobile</c>

00:01:01.610 --> 00:01:01.620 align:start position:0%
in recent years more and more mobile
 

00:01:01.620 --> 00:01:03.260 align:start position:0%
in recent years more and more mobile
apps<00:01:01.949><c> are</c><00:01:02.219><c> using</c><00:01:02.640><c> machine</c><00:01:02.910><c> learning</c><00:01:02.940><c> to</c>

00:01:03.260 --> 00:01:03.270 align:start position:0%
apps are using machine learning to
 

00:01:03.270 --> 00:01:05.890 align:start position:0%
apps are using machine learning to
produce<00:01:03.830><c> fascinating</c><00:01:04.830><c> user</c><00:01:05.070><c> experiences</c>

00:01:05.890 --> 00:01:05.900 align:start position:0%
produce fascinating user experiences
 

00:01:05.900 --> 00:01:08.480 align:start position:0%
produce fascinating user experiences
with<00:01:06.900><c> smartphones</c><00:01:07.500><c> becoming</c><00:01:07.860><c> increasingly</c>

00:01:08.480 --> 00:01:08.490 align:start position:0%
with smartphones becoming increasingly
 

00:01:08.490 --> 00:01:11.090 align:start position:0%
with smartphones becoming increasingly
powerful<00:01:08.760><c> and</c><00:01:09.180><c> capable</c><00:01:09.740><c> more</c><00:01:10.740><c> and</c><00:01:10.890><c> more</c>

00:01:11.090 --> 00:01:11.100 align:start position:0%
powerful and capable more and more
 

00:01:11.100 --> 00:01:12.770 align:start position:0%
powerful and capable more and more
machine<00:01:11.400><c> learning</c><00:01:11.430><c> logic</c><00:01:12.000><c> is</c><00:01:12.180><c> shifting</c><00:01:12.750><c> from</c>

00:01:12.770 --> 00:01:12.780 align:start position:0%
machine learning logic is shifting from
 

00:01:12.780 --> 00:01:15.080 align:start position:0%
machine learning logic is shifting from
the<00:01:13.200><c> server</c><00:01:13.470><c> running</c><00:01:13.740><c> the</c><00:01:13.920><c> cloud</c><00:01:14.159><c> to</c><00:01:15.000><c> the</c>

00:01:15.080 --> 00:01:15.090 align:start position:0%
the server running the cloud to the
 

00:01:15.090 --> 00:01:17.410 align:start position:0%
the server running the cloud to the
mobile<00:01:15.330><c> device</c><00:01:15.600><c> in</c><00:01:15.869><c> your</c><00:01:15.990><c> pocket</c>

00:01:17.410 --> 00:01:17.420 align:start position:0%
mobile device in your pocket
 

00:01:17.420 --> 00:01:19.969 align:start position:0%
mobile device in your pocket
Randi<00:01:18.420><c> own</c><00:01:18.570><c> device</c><00:01:18.869><c> mention</c><00:01:19.320><c> learning</c><00:01:19.710><c> has</c>

00:01:19.969 --> 00:01:19.979 align:start position:0%
Randi own device mention learning has
 

00:01:19.979 --> 00:01:23.179 align:start position:0%
Randi own device mention learning has
many<00:01:20.250><c> advantages</c><00:01:20.720><c> its</c><00:01:21.720><c> fast</c><00:01:22.049><c> does</c><00:01:22.680><c> not</c><00:01:22.890><c> it'll</c>

00:01:23.179 --> 00:01:23.189 align:start position:0%
many advantages its fast does not it'll
 

00:01:23.189 --> 00:01:25.460 align:start position:0%
many advantages its fast does not it'll
send<00:01:23.369><c> very</c><00:01:23.729><c> expensive</c><00:01:24.330><c> RPC</c><00:01:24.840><c> calls</c><00:01:25.080><c> and</c><00:01:25.380><c> in</c>

00:01:25.460 --> 00:01:25.470 align:start position:0%
send very expensive RPC calls and in
 

00:01:25.470 --> 00:01:27.980 align:start position:0%
send very expensive RPC calls and in
carloon<00:01:25.799><c> air</c><00:01:26.070><c> or</c><00:01:26.220><c> latency</c><00:01:26.520><c> it</c><00:01:27.479><c> also</c><00:01:27.659><c> runs</c>

00:01:27.980 --> 00:01:27.990 align:start position:0%
carloon air or latency it also runs
 

00:01:27.990 --> 00:01:30.730 align:start position:0%
carloon air or latency it also runs
anytime<00:01:28.619><c> anywhere</c><00:01:29.220><c> with</c><00:01:29.549><c> and</c><00:01:30.450><c> without</c>

00:01:30.730 --> 00:01:30.740 align:start position:0%
anytime anywhere with and without
 

00:01:30.740 --> 00:01:34.609 align:start position:0%
anytime anywhere with and without
network<00:01:31.740><c> connectivity</c><00:01:32.960><c> it</c><00:01:33.960><c> also</c><00:01:34.170><c> provides</c>

00:01:34.609 --> 00:01:34.619 align:start position:0%
network connectivity it also provides
 

00:01:34.619 --> 00:01:37.130 align:start position:0%
network connectivity it also provides
better<00:01:34.860><c> protection</c><00:01:35.130><c> for</c><00:01:35.670><c> user</c><00:01:35.850><c> privacy</c><00:01:36.329><c> since</c>

00:01:37.130 --> 00:01:37.140 align:start position:0%
better protection for user privacy since
 

00:01:37.140 --> 00:01:39.020 align:start position:0%
better protection for user privacy since
the<00:01:37.259><c> data</c><00:01:37.470><c> does</c><00:01:37.979><c> not</c><00:01:38.189><c> have</c><00:01:38.369><c> to</c><00:01:38.490><c> leave</c><00:01:38.729><c> the</c>

00:01:39.020 --> 00:01:39.030 align:start position:0%
the data does not have to leave the
 

00:01:39.030 --> 00:01:42.469 align:start position:0%
the data does not have to leave the
device<00:01:39.710><c> let</c><00:01:40.710><c> me</c><00:01:40.829><c> take</c><00:01:40.979><c> a</c><00:01:41.070><c> quick</c><00:01:41.220><c> poll</c><00:01:41.490><c> here</c><00:01:41.549><c> how</c>

00:01:42.469 --> 00:01:42.479 align:start position:0%
device let me take a quick poll here how
 

00:01:42.479 --> 00:01:43.999 align:start position:0%
device let me take a quick poll here how
many<00:01:42.540><c> of</c><00:01:42.840><c> you</c><00:01:43.020><c> traveled</c><00:01:43.259><c> from</c><00:01:43.590><c> outside</c>

00:01:43.999 --> 00:01:44.009 align:start position:0%
many of you traveled from outside
 

00:01:44.009 --> 00:01:48.080 align:start position:0%
many of you traveled from outside
California<00:01:44.250><c> to</c><00:01:44.759><c> attend</c><00:01:44.970><c> this</c><00:01:45.119><c> dev</c><00:01:45.390><c> summit</c><00:01:46.549><c> Wow</c>

00:01:48.080 --> 00:01:48.090 align:start position:0%
California to attend this dev summit Wow
 

00:01:48.090 --> 00:01:50.410 align:start position:0%
California to attend this dev summit Wow
welcome<00:01:48.600><c> welcome</c><00:01:49.079><c> to</c><00:01:49.350><c> a</c><00:01:49.380><c> Silicon</c><00:01:49.740><c> Valley</c><00:01:49.920><c> I</c>

00:01:50.410 --> 00:01:50.420 align:start position:0%
welcome welcome to a Silicon Valley I
 

00:01:50.420 --> 00:01:53.120 align:start position:0%
welcome welcome to a Silicon Valley I
hope<00:01:51.420><c> you</c><00:01:51.600><c> get</c><00:01:51.780><c> a</c><00:01:51.810><c> chance</c><00:01:51.869><c> to</c><00:01:52.320><c> visit</c><00:01:52.470><c> Conan</c>

00:01:53.120 --> 00:01:53.130 align:start position:0%
hope you get a chance to visit Conan
 

00:01:53.130 --> 00:01:55.700 align:start position:0%
hope you get a chance to visit Conan
Gate<00:01:53.250><c> Bridge</c><00:01:53.520><c> Fisherman's</c><00:01:54.210><c> Wharf</c><00:01:54.750><c> and</c><00:01:55.049><c> also</c>

00:01:55.700 --> 00:01:55.710 align:start position:0%
Gate Bridge Fisherman's Wharf and also
 

00:01:55.710 --> 00:01:57.800 align:start position:0%
Gate Bridge Fisherman's Wharf and also
enjoy<00:01:56.280><c> some</c><00:01:56.430><c> good</c><00:01:56.640><c> food</c><00:01:56.700><c> at</c><00:01:57.299><c> the</c><00:01:57.509><c> local</c>

00:01:57.800 --> 00:01:57.810 align:start position:0%
enjoy some good food at the local
 

00:01:57.810 --> 00:02:00.590 align:start position:0%
enjoy some good food at the local
restaurant<00:01:57.930><c> around</c><00:01:58.530><c> the</c><00:01:58.680><c> Bay</c><00:01:58.890><c> Area</c><00:01:59.600><c> talking</c>

00:02:00.590 --> 00:02:00.600 align:start position:0%
restaurant around the Bay Area talking
 

00:02:00.600 --> 00:02:04.760 align:start position:0%
restaurant around the Bay Area talking
about<00:02:00.810><c> food</c><00:02:01.340><c> my</c><00:02:02.340><c> biological</c><00:02:03.140><c> watch</c><00:02:04.140><c> tells</c><00:02:04.560><c> me</c>

00:02:04.760 --> 00:02:04.770 align:start position:0%
about food my biological watch tells me
 

00:02:04.770 --> 00:02:08.109 align:start position:0%
about food my biological watch tells me
is<00:02:04.829><c> time</c><00:02:05.159><c> for</c><00:02:05.610><c> dinner</c><00:02:05.790><c> so</c><00:02:06.719><c> where</c><00:02:06.869><c> should</c><00:02:07.020><c> I</c><00:02:07.140><c> eat</c>

00:02:08.109 --> 00:02:08.119 align:start position:0%
is time for dinner so where should I eat
 

00:02:08.119 --> 00:02:11.960 align:start position:0%
is time for dinner so where should I eat
well<00:02:09.200><c> I'll</c><00:02:10.200><c> pull</c><00:02:10.530><c> out</c><00:02:10.619><c> my</c><00:02:10.800><c> phone</c><00:02:10.830><c> ask</c><00:02:11.430><c> Google</c>

00:02:11.960 --> 00:02:11.970 align:start position:0%
well I'll pull out my phone ask Google
 

00:02:11.970 --> 00:02:13.040 align:start position:0%
well I'll pull out my phone ask Google
assistant

00:02:13.040 --> 00:02:13.050 align:start position:0%
assistant
 

00:02:13.050 --> 00:02:15.740 align:start position:0%
assistant
hi<00:02:13.560><c> Google</c><00:02:13.950><c> I'm</c><00:02:14.160><c> hungry</c><00:02:14.730><c> any</c><00:02:14.940><c> good</c><00:02:15.240><c> restaurant</c>

00:02:15.740 --> 00:02:15.750 align:start position:0%
hi Google I'm hungry any good restaurant
 

00:02:15.750 --> 00:02:16.900 align:start position:0%
hi Google I'm hungry any good restaurant
around<00:02:16.020><c> here</c>

00:02:16.900 --> 00:02:16.910 align:start position:0%
around here
 

00:02:16.910 --> 00:02:19.460 align:start position:0%
around here
Google<00:02:17.910><c> system</c><00:02:18.270><c> uses</c><00:02:18.630><c> machine</c><00:02:18.990><c> learning</c><00:02:19.020><c> to</c>

00:02:19.460 --> 00:02:19.470 align:start position:0%
Google system uses machine learning to
 

00:02:19.470 --> 00:02:21.410 align:start position:0%
Google system uses machine learning to
understand<00:02:19.890><c> my</c><00:02:20.040><c> question</c><00:02:20.100><c> and</c><00:02:20.670><c> make</c>

00:02:21.410 --> 00:02:21.420 align:start position:0%
understand my question and make
 

00:02:21.420 --> 00:02:23.810 align:start position:0%
understand my question and make
recommendation<00:02:22.200><c> where</c><00:02:22.740><c> to</c><00:02:22.890><c> go</c><00:02:23.070><c> for</c><00:02:23.640><c> dinner</c>

00:02:23.810 --> 00:02:23.820 align:start position:0%
recommendation where to go for dinner
 

00:02:23.820 --> 00:02:26.600 align:start position:0%
recommendation where to go for dinner
around<00:02:24.720><c> area</c><00:02:25.470><c> and</c><00:02:25.710><c> location</c><00:02:26.220><c> I'm</c><00:02:26.340><c> currently</c>

00:02:26.600 --> 00:02:26.610 align:start position:0%
around area and location I'm currently
 

00:02:26.610 --> 00:02:31.550 align:start position:0%
around area and location I'm currently
at<00:02:28.250><c> when</c><00:02:29.250><c> I</c><00:02:29.280><c> travel</c><00:02:29.670><c> to</c><00:02:29.700><c> a</c><00:02:29.790><c> new</c><00:02:30.000><c> place</c><00:02:30.270><c> I</c><00:02:30.600><c> would</c>

00:02:31.550 --> 00:02:31.560 align:start position:0%
at when I travel to a new place I would
 

00:02:31.560 --> 00:02:35.330 align:start position:0%
at when I travel to a new place I would
like<00:02:31.740><c> to</c><00:02:31.920><c> take</c><00:02:32.490><c> a</c><00:02:32.520><c> lot</c><00:02:32.760><c> of</c><00:02:32.820><c> photos</c><00:02:33.710><c> and</c><00:02:34.710><c> Google</c>

00:02:35.330 --> 00:02:35.340 align:start position:0%
like to take a lot of photos and Google
 

00:02:35.340 --> 00:02:37.820 align:start position:0%
like to take a lot of photos and Google
photos<00:02:35.730><c> use</c><00:02:36.210><c> image</c><00:02:36.660><c> recognition</c><00:02:36.930><c> to</c>

00:02:37.820 --> 00:02:37.830 align:start position:0%
photos use image recognition to
 

00:02:37.830 --> 00:02:39.980 align:start position:0%
photos use image recognition to
understand<00:02:38.250><c> image</c><00:02:38.520><c> content</c><00:02:38.970><c> you</c><00:02:39.840><c> can</c>

00:02:39.980 --> 00:02:39.990 align:start position:0%
understand image content you can
 

00:02:39.990 --> 00:02:42.440 align:start position:0%
understand image content you can
classify<00:02:40.260><c> photos</c><00:02:40.830><c> quickly</c><00:02:41.430><c> into</c><00:02:41.790><c> a</c><00:02:41.820><c> thousands</c>

00:02:42.440 --> 00:02:42.450 align:start position:0%
classify photos quickly into a thousands
 

00:02:42.450 --> 00:02:45.290 align:start position:0%
classify photos quickly into a thousands
of<00:02:42.630><c> categories</c><00:02:43.550><c> you</c><00:02:44.550><c> can</c><00:02:44.700><c> also</c><00:02:44.880><c> detect</c>

00:02:45.290 --> 00:02:45.300 align:start position:0%
of categories you can also detect
 

00:02:45.300 --> 00:02:49.550 align:start position:0%
of categories you can also detect
individual<00:02:45.930><c> faces</c><00:02:46.440><c> pads</c><00:02:47.600><c> objects</c><00:02:48.600><c> text</c><00:02:49.350><c> in</c>

00:02:49.550 --> 00:02:49.560 align:start position:0%
individual faces pads objects text in
 

00:02:49.560 --> 00:02:51.740 align:start position:0%
individual faces pads objects text in
the<00:02:49.710><c> photo</c><00:02:49.890><c> and</c><00:02:50.190><c> then</c><00:02:50.850><c> make</c><00:02:51.090><c> them</c><00:02:51.300><c> searchable</c>

00:02:51.740 --> 00:02:51.750 align:start position:0%
the photo and then make them searchable
 

00:02:51.750 --> 00:02:54.790 align:start position:0%
the photo and then make them searchable
by<00:02:52.020><c> keywords</c><00:02:52.500><c> or</c><00:02:52.770><c> categories</c><00:02:53.520><c> later</c><00:02:53.790><c> on</c>

00:02:54.790 --> 00:02:54.800 align:start position:0%
by keywords or categories later on
 

00:02:54.800 --> 00:02:58.940 align:start position:0%
by keywords or categories later on
mobile<00:02:55.800><c> device</c><00:02:56.130><c> can</c><00:02:56.790><c> now</c><00:02:57.470><c> run</c><00:02:58.470><c> really</c>

00:02:58.940 --> 00:02:58.950 align:start position:0%
mobile device can now run really
 

00:02:58.950 --> 00:03:00.470 align:start position:0%
mobile device can now run really
increasingly<00:02:59.520><c> Suffolk's</c><00:03:00.090><c> to</c><00:03:00.240><c> machine</c>

00:03:00.470 --> 00:03:00.480 align:start position:0%
increasingly Suffolk's to machine
 

00:03:00.480 --> 00:03:03.500 align:start position:0%
increasingly Suffolk's to machine
learning<00:03:00.600><c> tasks</c><00:03:01.610><c> last</c><00:03:02.610><c> spring</c><00:03:02.940><c> I</c><00:03:03.150><c> took</c><00:03:03.360><c> my</c>

00:03:03.500 --> 00:03:03.510 align:start position:0%
learning tasks last spring I took my
 

00:03:03.510 --> 00:03:07.790 align:start position:0%
learning tasks last spring I took my
family<00:03:03.690><c> to</c><00:03:04.220><c> Tuscany</c><00:03:05.220><c> in</c><00:03:05.460><c> Italy</c><00:03:06.530><c> we</c><00:03:07.530><c> drove</c>

00:03:07.790 --> 00:03:07.800 align:start position:0%
family to Tuscany in Italy we drove
 

00:03:07.800 --> 00:03:10.850 align:start position:0%
family to Tuscany in Italy we drove
around<00:03:08.010><c> those</c><00:03:08.400><c> beautiful</c><00:03:09.090><c> hilltop</c><00:03:09.390><c> towns</c><00:03:09.860><c> in</c>

00:03:10.850 --> 00:03:10.860 align:start position:0%
around those beautiful hilltop towns in
 

00:03:10.860 --> 00:03:12.910 align:start position:0%
around those beautiful hilltop towns in
each<00:03:11.010><c> of</c><00:03:11.220><c> the</c><00:03:11.340><c> town</c><00:03:11.580><c> there</c><00:03:12.210><c> are</c><00:03:12.300><c> many</c><00:03:12.480><c> signs</c>

00:03:12.910 --> 00:03:12.920 align:start position:0%
each of the town there are many signs
 

00:03:12.920 --> 00:03:15.920 align:start position:0%
each of the town there are many signs
but<00:03:13.920><c> I</c><00:03:13.980><c> don't</c><00:03:14.280><c> speak</c><00:03:14.430><c> Italian</c><00:03:14.940><c> unfortunately</c>

00:03:15.920 --> 00:03:15.930 align:start position:0%
but I don't speak Italian unfortunately
 

00:03:15.930 --> 00:03:20.360 align:start position:0%
but I don't speak Italian unfortunately
I<00:03:16.140><c> wish</c><00:03:16.470><c> said</c><00:03:16.650><c> I</c><00:03:16.920><c> do</c><00:03:17.510><c> so</c><00:03:18.830><c> how</c><00:03:19.830><c> do</c><00:03:19.890><c> I</c><00:03:19.980><c> know</c><00:03:20.040><c> what</c>

00:03:20.360 --> 00:03:20.370 align:start position:0%
I wish said I do so how do I know what
 

00:03:20.370 --> 00:03:21.080 align:start position:0%
I wish said I do so how do I know what
this<00:03:20.520><c> means</c>

00:03:21.080 --> 00:03:21.090 align:start position:0%
this means
 

00:03:21.090 --> 00:03:24.140 align:start position:0%
this means
here's<00:03:22.050><c> where</c><00:03:22.560><c> the</c><00:03:22.770><c> Google</c><00:03:22.920><c> Translate</c><00:03:23.489><c> came</c>

00:03:24.140 --> 00:03:24.150 align:start position:0%
here's where the Google Translate came
 

00:03:24.150 --> 00:03:27.140 align:start position:0%
here's where the Google Translate came
to<00:03:24.330><c> rescue</c><00:03:25.250><c> Google</c><00:03:26.250><c> Translate</c><00:03:26.430><c> can</c><00:03:26.790><c> perform</c>

00:03:27.140 --> 00:03:27.150 align:start position:0%
to rescue Google Translate can perform
 

00:03:27.150 --> 00:03:28.729 align:start position:0%
to rescue Google Translate can perform
multiple<00:03:27.270><c> machine</c><00:03:27.810><c> learning</c><00:03:28.080><c> tasks</c><00:03:28.320><c> in</c><00:03:28.680><c> a</c>

00:03:28.729 --> 00:03:28.739 align:start position:0%
multiple machine learning tasks in a
 

00:03:28.739 --> 00:03:31.580 align:start position:0%
multiple machine learning tasks in a
single<00:03:29.100><c> journey</c><00:03:29.450><c> when</c><00:03:30.450><c> I</c><00:03:30.480><c> pull</c><00:03:30.750><c> up</c><00:03:30.780><c> my</c><00:03:30.900><c> phone</c>

00:03:31.580 --> 00:03:31.590 align:start position:0%
single journey when I pull up my phone
 

00:03:31.590 --> 00:03:34.490 align:start position:0%
single journey when I pull up my phone
pointing<00:03:32.550><c> the</c><00:03:32.580><c> camera</c><00:03:32.940><c> at</c><00:03:33.150><c> the</c><00:03:33.360><c> sign</c><00:03:33.570><c> it</c><00:03:34.380><c> will</c>

00:03:34.490 --> 00:03:34.500 align:start position:0%
pointing the camera at the sign it will
 

00:03:34.500 --> 00:03:36.920 align:start position:0%
pointing the camera at the sign it will
use<00:03:34.650><c> optical</c><00:03:35.280><c> character</c><00:03:35.820><c> recognition</c><00:03:35.930><c> to</c>

00:03:36.920 --> 00:03:36.930 align:start position:0%
use optical character recognition to
 

00:03:36.930 --> 00:03:40.280 align:start position:0%
use optical character recognition to
detect<00:03:37.290><c> us</c><00:03:37.410><c> text</c><00:03:38.160><c> in</c><00:03:38.310><c> a</c><00:03:38.520><c> sign</c><00:03:38.810><c> it</c><00:03:39.810><c> will</c><00:03:39.930><c> also</c>

00:03:40.280 --> 00:03:40.290 align:start position:0%
detect us text in a sign it will also
 

00:03:40.290 --> 00:03:42.199 align:start position:0%
detect us text in a sign it will also
use<00:03:40.530><c> national</c><00:03:40.980><c> and</c><00:03:41.400><c> natural</c><00:03:42.060><c> language</c>

00:03:42.199 --> 00:03:42.209 align:start position:0%
use national and natural language
 

00:03:42.209 --> 00:03:44.510 align:start position:0%
use national and natural language
processing<00:03:42.420><c> the</c><00:03:43.110><c> transits</c><00:03:43.620><c> attacks</c><00:03:43.980><c> from</c><00:03:44.310><c> one</c>

00:03:44.510 --> 00:03:44.520 align:start position:0%
processing the transits attacks from one
 

00:03:44.520 --> 00:03:47.900 align:start position:0%
processing the transits attacks from one
language<00:03:44.730><c> into</c><00:03:45.330><c> another</c><00:03:46.370><c> finally</c><00:03:47.370><c> it</c><00:03:47.850><c> will</c>

00:03:47.900 --> 00:03:47.910 align:start position:0%
language into another finally it will
 

00:03:47.910 --> 00:03:50.390 align:start position:0%
language into another finally it will
use<00:03:48.060><c> speech</c><00:03:48.420><c> synthesis</c><00:03:49.080><c> to</c><00:03:49.709><c> convert</c><00:03:50.070><c> text</c>

00:03:50.390 --> 00:03:50.400 align:start position:0%
use speech synthesis to convert text
 

00:03:50.400 --> 00:03:53.180 align:start position:0%
use speech synthesis to convert text
into<00:03:50.640><c> voice</c><00:03:50.970><c> and</c><00:03:51.330><c> using</c><00:03:52.290><c> speaker</c><00:03:52.680><c> tell</c><00:03:52.980><c> me</c>

00:03:53.180 --> 00:03:53.190 align:start position:0%
into voice and using speaker tell me
 

00:03:53.190 --> 00:03:56.810 align:start position:0%
into voice and using speaker tell me
what<00:03:54.150><c> the</c><00:03:54.239><c> sign</c><00:03:54.450><c> is</c><00:03:54.690><c> in</c><00:03:54.840><c> my</c><00:03:55.020><c> own</c><00:03:55.170><c> language</c><00:03:55.820><c> all</c>

00:03:56.810 --> 00:03:56.820 align:start position:0%
what the sign is in my own language all
 

00:03:56.820 --> 00:03:58.840 align:start position:0%
what the sign is in my own language all
these<00:03:57.120><c> tasks</c><00:03:57.450><c> involve</c><00:03:57.900><c> machine</c><00:03:58.230><c> learning</c>

00:03:58.840 --> 00:03:58.850 align:start position:0%
these tasks involve machine learning
 

00:03:58.850 --> 00:04:01.970 align:start position:0%
these tasks involve machine learning
combined<00:03:59.850><c> they</c><00:04:00.330><c> produce</c><00:04:00.540><c> a</c><00:04:00.900><c> seamless</c><00:04:01.470><c> and</c><00:04:01.709><c> a</c>

00:04:01.970 --> 00:04:01.980 align:start position:0%
combined they produce a seamless and a
 

00:04:01.980 --> 00:04:05.210 align:start position:0%
combined they produce a seamless and a
powerful<00:04:02.310><c> user</c><00:04:02.610><c> experience</c><00:04:03.500><c> this</c><00:04:04.500><c> all</c><00:04:04.830><c> look</c>

00:04:05.210 --> 00:04:05.220 align:start position:0%
powerful user experience this all look
 

00:04:05.220 --> 00:04:08.330 align:start position:0%
powerful user experience this all look
great<00:04:05.580><c> but</c><00:04:06.570><c> as</c><00:04:06.720><c> a</c><00:04:06.750><c> developer</c><00:04:07.020><c> how</c><00:04:07.980><c> do</c><00:04:08.040><c> I</c><00:04:08.160><c> build</c>

00:04:08.330 --> 00:04:08.340 align:start position:0%
great but as a developer how do I build
 

00:04:08.340 --> 00:04:12.080 align:start position:0%
great but as a developer how do I build
something<00:04:08.520><c> like</c><00:04:08.730><c> this</c><00:04:09.800><c> well</c><00:04:10.800><c> it's</c><00:04:11.250><c> doable</c><00:04:11.670><c> and</c>

00:04:12.080 --> 00:04:12.090 align:start position:0%
something like this well it's doable and
 

00:04:12.090 --> 00:04:15.890 align:start position:0%
something like this well it's doable and
not<00:04:12.360><c> easy</c><00:04:13.280><c> machinery</c><00:04:14.280><c> offer</c><00:04:14.900><c> requires</c>

00:04:15.890 --> 00:04:15.900 align:start position:0%
not easy machinery offer requires
 

00:04:15.900 --> 00:04:17.900 align:start position:0%
not easy machinery offer requires
specialized<00:04:16.590><c> knowledge</c><00:04:16.890><c> and</c><00:04:17.280><c> the</c><00:04:17.489><c> years</c><00:04:17.850><c> of</c>

00:04:17.900 --> 00:04:17.910 align:start position:0%
specialized knowledge and the years of
 

00:04:17.910 --> 00:04:20.570 align:start position:0%
specialized knowledge and the years of
experience<00:04:18.359><c> in</c><00:04:18.930><c> training</c><00:04:19.500><c> and</c><00:04:19.650><c> building</c><00:04:19.890><c> ML</c>

00:04:20.570 --> 00:04:20.580 align:start position:0%
experience in training and building ML
 

00:04:20.580 --> 00:04:23.659 align:start position:0%
experience in training and building ML
models<00:04:21.000><c> the</c><00:04:21.870><c> model</c><00:04:22.229><c> training</c><00:04:22.620><c> a</c><00:04:22.830><c> lot</c><00:04:23.250><c> of</c><00:04:23.310><c> time</c>

00:04:23.659 --> 00:04:23.669 align:start position:0%
models the model training a lot of time
 

00:04:23.669 --> 00:04:26.629 align:start position:0%
models the model training a lot of time
requires<00:04:24.360><c> a</c><00:04:24.560><c> large</c><00:04:25.560><c> amount</c><00:04:25.919><c> of</c><00:04:26.070><c> good</c>

00:04:26.629 --> 00:04:26.639 align:start position:0%
requires a large amount of good
 

00:04:26.639 --> 00:04:29.989 align:start position:0%
requires a large amount of good
high-quality<00:04:26.969><c> data</c><00:04:28.009><c> the</c><00:04:29.009><c> mobile</c><00:04:29.310><c> device</c><00:04:29.639><c> hi</c>

00:04:29.989 --> 00:04:29.999 align:start position:0%
high-quality data the mobile device hi
 

00:04:29.999 --> 00:04:32.330 align:start position:0%
high-quality data the mobile device hi
Ron<00:04:30.270><c> Ellison</c><00:04:30.840><c> aside</c><00:04:31.499><c> it</c><00:04:31.770><c> has</c><00:04:31.889><c> very</c><00:04:32.129><c> limited</c>

00:04:32.330 --> 00:04:32.340 align:start position:0%
Ron Ellison aside it has very limited
 

00:04:32.340 --> 00:04:35.480 align:start position:0%
Ron Ellison aside it has very limited
computing<00:04:32.969><c> power</c><00:04:33.210><c> the</c><00:04:34.139><c> models</c><00:04:34.530><c> running</c><00:04:35.159><c> on</c><00:04:35.460><c> a</c>

00:04:35.480 --> 00:04:35.490 align:start position:0%
computing power the models running on a
 

00:04:35.490 --> 00:04:37.640 align:start position:0%
computing power the models running on a
server<00:04:35.759><c> in</c><00:04:35.939><c> the</c><00:04:36.029><c> cloud</c><00:04:36.060><c> are</c><00:04:36.629><c> often</c><00:04:37.199><c> too</c><00:04:37.409><c> large</c>

00:04:37.640 --> 00:04:37.650 align:start position:0%
server in the cloud are often too large
 

00:04:37.650 --> 00:04:40.040 align:start position:0%
server in the cloud are often too large
or<00:04:37.979><c> too</c><00:04:38.069><c> complex</c><00:04:38.789><c> to</c><00:04:39.300><c> run</c><00:04:39.479><c> directly</c><00:04:39.629><c> on</c><00:04:39.960><c> a</c>

00:04:40.040 --> 00:04:40.050 align:start position:0%
or too complex to run directly on a
 

00:04:40.050 --> 00:04:42.409 align:start position:0%
or too complex to run directly on a
mobile<00:04:40.229><c> device</c><00:04:40.490><c> you</c><00:04:41.490><c> need</c><00:04:41.699><c> to</c><00:04:41.789><c> spend</c><00:04:41.999><c> a</c><00:04:42.180><c> lot</c><00:04:42.360><c> of</c>

00:04:42.409 --> 00:04:42.419 align:start position:0%
mobile device you need to spend a lot of
 

00:04:42.419 --> 00:04:44.749 align:start position:0%
mobile device you need to spend a lot of
effort<00:04:42.719><c> to</c><00:04:43.080><c> optimize</c><00:04:43.620><c> model</c><00:04:44.189><c> for</c><00:04:44.520><c> the</c><00:04:44.580><c> mobile</c>

00:04:44.749 --> 00:04:44.759 align:start position:0%
effort to optimize model for the mobile
 

00:04:44.759 --> 00:04:48.429 align:start position:0%
effort to optimize model for the mobile
usage<00:04:45.830><c> after</c><00:04:46.830><c> finally</c><00:04:47.310><c> the</c><00:04:47.430><c> app</c><00:04:47.729><c> is</c><00:04:48.060><c> built</c>

00:04:48.429 --> 00:04:48.439 align:start position:0%
usage after finally the app is built
 

00:04:48.439 --> 00:04:51.409 align:start position:0%
usage after finally the app is built
Union<00:04:49.439><c> worried</c><00:04:49.650><c> about</c><00:04:49.889><c> how</c><00:04:50.219><c> do</c><00:04:50.279><c> I</c><00:04:50.400><c> deploy</c><00:04:50.849><c> how</c>

00:04:51.409 --> 00:04:51.419 align:start position:0%
Union worried about how do I deploy how
 

00:04:51.419 --> 00:04:53.689 align:start position:0%
Union worried about how do I deploy how
do<00:04:51.479><c> I</c><00:04:51.629><c> maintain</c><00:04:51.960><c> ongoing</c><00:04:52.590><c> instrumentation</c><00:04:53.550><c> of</c>

00:04:53.689 --> 00:04:53.699 align:start position:0%
do I maintain ongoing instrumentation of
 

00:04:53.699 --> 00:04:56.200 align:start position:0%
do I maintain ongoing instrumentation of
the<00:04:53.849><c> models</c><00:04:54.240><c> that</c><00:04:54.509><c> becomes</c><00:04:55.229><c> another</c><00:04:55.529><c> headache</c>

00:04:56.200 --> 00:04:56.210 align:start position:0%
the models that becomes another headache
 

00:04:56.210 --> 00:05:00.050 align:start position:0%
the models that becomes another headache
to<00:04:57.210><c> tackle</c><00:04:57.629><c> all</c><00:04:57.719><c> this</c><00:04:57.870><c> power</c><00:04:58.770><c> problems</c><00:04:59.340><c> we</c>

00:05:00.050 --> 00:05:00.060 align:start position:0%
to tackle all this power problems we
 

00:05:00.060 --> 00:05:02.779 align:start position:0%
to tackle all this power problems we
launched<00:05:00.449><c> ml</c><00:05:01.199><c> kit</c><00:05:01.469><c> Google's</c><00:05:02.250><c> machine</c>

00:05:02.779 --> 00:05:02.789 align:start position:0%
launched ml kit Google's machine
 

00:05:02.789 --> 00:05:05.839 align:start position:0%
launched ml kit Google's machine
learning<00:05:03.090><c> SDK</c><00:05:03.509><c> for</c><00:05:03.689><c> mobile</c><00:05:04.050><c> which</c><00:05:04.860><c> helps</c><00:05:05.400><c> the</c>

00:05:05.839 --> 00:05:05.849 align:start position:0%
learning SDK for mobile which helps the
 

00:05:05.849 --> 00:05:09.409 align:start position:0%
learning SDK for mobile which helps the
mobile<00:05:06.330><c> developers</c><00:05:06.840><c> build</c><00:05:07.909><c> Android</c><00:05:08.909><c> and</c><00:05:09.150><c> iOS</c>

00:05:09.409 --> 00:05:09.419 align:start position:0%
mobile developers build Android and iOS
 

00:05:09.419 --> 00:05:12.939 align:start position:0%
mobile developers build Android and iOS
apps<00:05:09.840><c> using</c><00:05:10.289><c> machine</c><00:05:10.560><c> learning</c><00:05:10.590><c> technologies</c>

00:05:12.939 --> 00:05:12.949 align:start position:0%
apps using machine learning technologies
 

00:05:12.949 --> 00:05:16.399 align:start position:0%
apps using machine learning technologies
ml<00:05:13.949><c> cadiz</c><00:05:14.340><c> aim</c><00:05:14.580><c> at</c><00:05:14.819><c> making</c><00:05:15.509><c> machine</c><00:05:16.110><c> learning</c>

00:05:16.399 --> 00:05:16.409 align:start position:0%
ml cadiz aim at making machine learning
 

00:05:16.409 --> 00:05:19.969 align:start position:0%
ml cadiz aim at making machine learning
easy<00:05:16.590><c> for</c><00:05:17.490><c> mobile</c><00:05:17.819><c> developers</c><00:05:18.560><c> just</c><00:05:19.560><c> because</c>

00:05:19.969 --> 00:05:19.979 align:start position:0%
easy for mobile developers just because
 

00:05:19.979 --> 00:05:21.619 align:start position:0%
easy for mobile developers just because
you<00:05:20.400><c> want</c><00:05:20.610><c> to</c><00:05:20.669><c> use</c><00:05:20.849><c> machine</c><00:05:21.210><c> learning</c><00:05:21.479><c> on</c>

00:05:21.619 --> 00:05:21.629 align:start position:0%
you want to use machine learning on
 

00:05:21.629 --> 00:05:24.379 align:start position:0%
you want to use machine learning on
mobile<00:05:22.020><c> it</c><00:05:22.500><c> does</c><00:05:22.710><c> not</c><00:05:22.889><c> mean</c><00:05:23.699><c> you</c><00:05:24.060><c> need</c><00:05:24.240><c> to</c>

00:05:24.379 --> 00:05:24.389 align:start position:0%
mobile it does not mean you need to
 

00:05:24.389 --> 00:05:26.600 align:start position:0%
mobile it does not mean you need to
worry<00:05:24.599><c> about</c><00:05:24.659><c> collecting</c><00:05:25.529><c> data</c><00:05:25.770><c> building</c>

00:05:26.600 --> 00:05:26.610 align:start position:0%
worry about collecting data building
 

00:05:26.610 --> 00:05:29.350 align:start position:0%
worry about collecting data building
models<00:05:27.120><c> training</c><00:05:27.960><c> model</c><00:05:28.650><c> compression</c>

00:05:29.350 --> 00:05:29.360 align:start position:0%
models training model compression
 

00:05:29.360 --> 00:05:31.760 align:start position:0%
models training model compression
optimization<00:05:30.360><c> hosting</c><00:05:31.050><c> deployment</c>

00:05:31.760 --> 00:05:31.770 align:start position:0%
optimization hosting deployment
 

00:05:31.770 --> 00:05:34.490 align:start position:0%
optimization hosting deployment
downloading<00:05:32.430><c> model</c><00:05:32.759><c> all</c><00:05:32.879><c> this</c><00:05:33.089><c> Haddock</c><00:05:33.539><c> ml</c>

00:05:34.490 --> 00:05:34.500 align:start position:0%
downloading model all this Haddock ml
 

00:05:34.500 --> 00:05:38.209 align:start position:0%
downloading model all this Haddock ml
kid<00:05:34.740><c> will</c><00:05:35.099><c> take</c><00:05:35.279><c> care</c><00:05:35.460><c> of</c><00:05:35.669><c> this</c><00:05:35.879><c> for</c><00:05:36.150><c> you</c><00:05:37.219><c> we</c>

00:05:38.209 --> 00:05:38.219 align:start position:0%
kid will take care of this for you we
 

00:05:38.219 --> 00:05:41.269 align:start position:0%
kid will take care of this for you we
provide<00:05:38.639><c> common</c><00:05:39.419><c> turnkey</c><00:05:39.839><c> models</c><00:05:40.289><c> that</c><00:05:40.800><c> work</c>

00:05:41.269 --> 00:05:41.279 align:start position:0%
provide common turnkey models that work
 

00:05:41.279 --> 00:05:43.879 align:start position:0%
provide common turnkey models that work
just<00:05:41.639><c> OtterBox</c><00:05:42.240><c> all</c><00:05:43.080><c> the</c><00:05:43.319><c> models</c><00:05:43.710><c> are</c>

00:05:43.879 --> 00:05:43.889 align:start position:0%
just OtterBox all the models are
 

00:05:43.889 --> 00:05:47.059 align:start position:0%
just OtterBox all the models are
optimized<00:05:44.370><c> for</c><00:05:44.610><c> speed</c><00:05:44.879><c> accuracy</c><00:05:45.750><c> as</c><00:05:46.289><c> well</c><00:05:46.710><c> as</c>

00:05:47.059 --> 00:05:47.069 align:start position:0%
optimized for speed accuracy as well as
 

00:05:47.069 --> 00:05:50.029 align:start position:0%
optimized for speed accuracy as well as
efficiency<00:05:47.939><c> for</c><00:05:48.899><c> the</c><00:05:48.960><c> model</c><00:05:49.409><c> for</c><00:05:49.830><c> the</c><00:05:49.889><c> mobile</c>

00:05:50.029 --> 00:05:50.039 align:start position:0%
efficiency for the model for the mobile
 

00:05:50.039 --> 00:05:53.029 align:start position:0%
efficiency for the model for the mobile
device<00:05:50.479><c> we</c><00:05:51.479><c> provide</c><00:05:51.779><c> a</c><00:05:51.810><c> one</c><00:05:52.169><c> consistent</c><00:05:52.740><c> API</c>

00:05:53.029 --> 00:05:53.039 align:start position:0%
device we provide a one consistent API
 

00:05:53.039 --> 00:05:56.689 align:start position:0%
device we provide a one consistent API
across<00:05:53.580><c> both</c><00:05:54.000><c> Android</c><00:05:54.659><c> and</c><00:05:54.689><c> iOS</c><00:05:55.250><c> it's</c><00:05:56.250><c> very</c>

00:05:56.689 --> 00:05:56.699 align:start position:0%
across both Android and iOS it's very
 

00:05:56.699 --> 00:05:59.570 align:start position:0%
across both Android and iOS it's very
easy<00:05:56.969><c> to</c><00:05:57.180><c> integrate</c><00:05:57.389><c> ml</c><00:05:58.379><c> kit</c><00:05:58.620><c> with</c><00:05:58.919><c> firebase</c>

00:05:59.570 --> 00:05:59.580 align:start position:0%
easy to integrate ml kit with firebase
 

00:05:59.580 --> 00:06:03.429 align:start position:0%
easy to integrate ml kit with firebase
tools<00:05:59.909><c> like</c><00:06:00.120><c> remote</c><00:06:00.659><c> config</c><00:06:01.110><c> or</c><00:06:01.289><c> a</c><00:06:01.349><c> be</c><00:06:01.710><c> testing</c>

00:06:03.429 --> 00:06:03.439 align:start position:0%
tools like remote config or a be testing
 

00:06:03.439 --> 00:06:06.050 align:start position:0%
tools like remote config or a be testing
for<00:06:04.439><c> commonly</c><00:06:04.919><c> needed</c><00:06:05.159><c> machine</c><00:06:05.669><c> learning</c>

00:06:06.050 --> 00:06:06.060 align:start position:0%
for commonly needed machine learning
 

00:06:06.060 --> 00:06:09.409 align:start position:0%
for commonly needed machine learning
tasks<00:06:06.300><c> we</c><00:06:06.990><c> have</c><00:06:07.020><c> base</c><00:06:07.649><c> api's</c><00:06:08.189><c> that</c><00:06:08.849><c> come</c><00:06:09.210><c> with</c>

00:06:09.409 --> 00:06:09.419 align:start position:0%
tasks we have base api's that come with
 

00:06:09.419 --> 00:06:11.929 align:start position:0%
tasks we have base api's that come with
pre-trained<00:06:10.020><c> google</c><00:06:10.379><c> models</c><00:06:10.800><c> that</c><00:06:11.490><c> work</c>

00:06:11.929 --> 00:06:11.939 align:start position:0%
pre-trained google models that work
 

00:06:11.939 --> 00:06:14.779 align:start position:0%
pre-trained google models that work
outer-box<00:06:12.830><c> currently</c><00:06:13.830><c> there</c><00:06:14.009><c> are</c><00:06:14.069><c> five</c><00:06:14.310><c> api's</c>

00:06:14.779 --> 00:06:14.789 align:start position:0%
outer-box currently there are five api's
 

00:06:14.789 --> 00:06:18.050 align:start position:0%
outer-box currently there are five api's
we<00:06:15.240><c> are</c><00:06:15.300><c> supporting</c><00:06:15.779><c> the</c><00:06:16.620><c> test</c><00:06:17.060><c> recognition</c>

00:06:18.050 --> 00:06:18.060 align:start position:0%
we are supporting the test recognition
 

00:06:18.060 --> 00:06:21.110 align:start position:0%
we are supporting the test recognition
API<00:06:18.289><c> are</c><00:06:19.289><c> supported</c><00:06:19.800><c> on</c><00:06:19.830><c> both</c><00:06:19.919><c> on</c><00:06:20.430><c> device</c><00:06:20.819><c> and</c>

00:06:21.110 --> 00:06:21.120 align:start position:0%
API are supported on both on device and
 

00:06:21.120 --> 00:06:23.839 align:start position:0%
API are supported on both on device and
the<00:06:21.240><c> cloud</c><00:06:21.620><c> the</c><00:06:22.620><c> on</c><00:06:22.800><c> device</c><00:06:23.129><c> API</c><00:06:23.399><c> can</c>

00:06:23.839 --> 00:06:23.849 align:start position:0%
the cloud the on device API can
 

00:06:23.849 --> 00:06:26.809 align:start position:0%
the cloud the on device API can
recognize<00:06:24.289><c> Latin</c><00:06:25.289><c> characters</c><00:06:25.800><c> and</c><00:06:26.039><c> the</c><00:06:26.550><c> cloud</c>

00:06:26.809 --> 00:06:26.819 align:start position:0%
recognize Latin characters and the cloud
 

00:06:26.819 --> 00:06:30.529 align:start position:0%
recognize Latin characters and the cloud
API<00:06:27.240><c> supports</c><00:06:28.229><c> a</c><00:06:28.349><c> wide</c><00:06:28.409><c> range</c><00:06:29.279><c> of</c><00:06:29.610><c> languages</c>

00:06:30.529 --> 00:06:30.539 align:start position:0%
API supports a wide range of languages
 

00:06:30.539 --> 00:06:34.249 align:start position:0%
API supports a wide range of languages
and<00:06:30.839><c> special</c><00:06:31.289><c> characters</c><00:06:32.210><c> face</c><00:06:33.210><c> detection</c><00:06:33.899><c> is</c>

00:06:34.249 --> 00:06:34.259 align:start position:0%
and special characters face detection is
 

00:06:34.259 --> 00:06:36.800 align:start position:0%
and special characters face detection is
another<00:06:34.589><c> API</c><00:06:35.009><c> we</c><00:06:35.159><c> support</c><00:06:35.580><c> which</c><00:06:36.269><c> can</c><00:06:36.479><c> be</c><00:06:36.599><c> used</c>

00:06:36.800 --> 00:06:36.810 align:start position:0%
another API we support which can be used
 

00:06:36.810 --> 00:06:39.050 align:start position:0%
another API we support which can be used
to<00:06:36.930><c> detect</c><00:06:37.199><c> faces</c><00:06:37.469><c> in</c><00:06:37.860><c> both</c><00:06:38.099><c> static</c><00:06:38.430><c> image</c><00:06:38.819><c> as</c>

00:06:39.050 --> 00:06:39.060 align:start position:0%
to detect faces in both static image as
 

00:06:39.060 --> 00:06:40.350 align:start position:0%
to detect faces in both static image as
well<00:06:39.479><c> as</c><00:06:39.569><c> live</c>

00:06:40.350 --> 00:06:40.360 align:start position:0%
well as live
 

00:06:40.360 --> 00:06:43.170 align:start position:0%
well as live
video-streaming<00:06:41.310><c> now</c><00:06:42.310><c> we</c><00:06:42.370><c> also</c><00:06:42.789><c> launched</c>

00:06:43.170 --> 00:06:43.180 align:start position:0%
video-streaming now we also launched
 

00:06:43.180 --> 00:06:45.990 align:start position:0%
video-streaming now we also launched
counter<00:06:43.960><c> detection</c><00:06:44.560><c> which</c><00:06:45.129><c> can</c><00:06:45.430><c> help</c><00:06:45.610><c> you</c><00:06:45.849><c> to</c>

00:06:45.990 --> 00:06:46.000 align:start position:0%
counter detection which can help you to
 

00:06:46.000 --> 00:06:48.089 align:start position:0%
counter detection which can help you to
identify<00:06:46.060><c> different</c><00:06:46.689><c> parts</c><00:06:47.110><c> of</c><00:06:47.229><c> the</c><00:06:47.590><c> face</c><00:06:47.770><c> and</c>

00:06:48.089 --> 00:06:48.099 align:start position:0%
identify different parts of the face and
 

00:06:48.099 --> 00:06:51.469 align:start position:0%
identify different parts of the face and
you<00:06:48.520><c> can</c><00:06:48.729><c> then</c><00:06:48.909><c> apply</c><00:06:49.240><c> face</c><00:06:50.080><c> masks</c><00:06:50.409><c> of</c><00:06:50.710><c> users</c>

00:06:51.469 --> 00:06:51.479 align:start position:0%
you can then apply face masks of users
 

00:06:51.479 --> 00:06:54.659 align:start position:0%
you can then apply face masks of users
the<00:06:52.479><c> barcode</c><00:06:52.900><c> scanning</c><00:06:53.199><c> can</c><00:06:54.099><c> be</c><00:06:54.250><c> used</c><00:06:54.490><c> to</c>

00:06:54.659 --> 00:06:54.669 align:start position:0%
the barcode scanning can be used to
 

00:06:54.669 --> 00:06:56.550 align:start position:0%
the barcode scanning can be used to
detect<00:06:55.000><c> post</c><00:06:55.389><c> 1-dimensional</c><00:06:56.289><c> in</c><00:06:56.439><c> the</c>

00:06:56.550 --> 00:06:56.560 align:start position:0%
detect post 1-dimensional in the
 

00:06:56.560 --> 00:06:59.219 align:start position:0%
detect post 1-dimensional in the
two-dimensional<00:06:57.419><c> barcodes</c><00:06:58.419><c> as</c><00:06:58.599><c> well</c><00:06:58.810><c> as</c><00:06:58.870><c> a</c><00:06:58.960><c> QR</c>

00:06:59.219 --> 00:06:59.229 align:start position:0%
two-dimensional barcodes as well as a QR
 

00:06:59.229 --> 00:07:03.270 align:start position:0%
two-dimensional barcodes as well as a QR
code<00:07:00.090><c> image</c><00:07:01.090><c> labeling</c><00:07:01.750><c> API</c><00:07:02.169><c> can</c><00:07:02.919><c> detect</c>

00:07:03.270 --> 00:07:03.280 align:start position:0%
code image labeling API can detect
 

00:07:03.280 --> 00:07:05.610 align:start position:0%
code image labeling API can detect
objects<00:07:03.849><c> of</c><00:07:04.090><c> various</c><00:07:04.509><c> entities</c><00:07:04.900><c> inside</c><00:07:05.469><c> the</c>

00:07:05.610 --> 00:07:05.620 align:start position:0%
objects of various entities inside the
 

00:07:05.620 --> 00:07:08.879 align:start position:0%
objects of various entities inside the
photo<00:07:05.860><c> and</c><00:07:06.840><c> for</c><00:07:07.840><c> which</c><00:07:08.139><c> spore</c><00:07:08.439><c> spawn</c><00:07:08.620><c> some</c>

00:07:08.879 --> 00:07:08.889 align:start position:0%
photo and for which spore spawn some
 

00:07:08.889 --> 00:07:11.219 align:start position:0%
photo and for which spore spawn some
device<00:07:09.219><c> in</c><00:07:09.400><c> the</c><00:07:09.460><c> cloud</c><00:07:09.669><c> the</c><00:07:10.389><c> um</c><00:07:10.509><c> device</c><00:07:10.840><c> API</c>

00:07:11.219 --> 00:07:11.229 align:start position:0%
device in the cloud the um device API
 

00:07:11.229 --> 00:07:13.050 align:start position:0%
device in the cloud the um device API
supports<00:07:11.740><c> more</c><00:07:11.860><c> than</c><00:07:12.009><c> 400</c><00:07:12.550><c> labels</c><00:07:12.879><c> which</c>

00:07:13.050 --> 00:07:13.060 align:start position:0%
supports more than 400 labels which
 

00:07:13.060 --> 00:07:14.879 align:start position:0%
supports more than 400 labels which
covered<00:07:13.419><c> most</c><00:07:13.449><c> of</c><00:07:13.690><c> common</c><00:07:14.080><c> things</c><00:07:14.259><c> you</c><00:07:14.440><c> see</c><00:07:14.680><c> in</c>

00:07:14.879 --> 00:07:14.889 align:start position:0%
covered most of common things you see in
 

00:07:14.889 --> 00:07:18.959 align:start position:0%
covered most of common things you see in
photos<00:07:15.840><c> well</c><00:07:16.840><c> the</c><00:07:17.199><c> cloud</c><00:07:17.919><c> API</c><00:07:18.310><c> can</c><00:07:18.610><c> support</c>

00:07:18.959 --> 00:07:18.969 align:start position:0%
photos well the cloud API can support
 

00:07:18.969 --> 00:07:22.309 align:start position:0%
photos well the cloud API can support
10,000<00:07:19.840><c> labels</c><00:07:20.259><c> across</c><00:07:20.650><c> many</c><00:07:21.009><c> categories</c>

00:07:22.309 --> 00:07:22.319 align:start position:0%
10,000 labels across many categories
 

00:07:22.319 --> 00:07:25.559 align:start position:0%
10,000 labels across many categories
finally<00:07:23.319><c> our</c><00:07:23.740><c> landmark</c><00:07:24.370><c> API</c><00:07:24.759><c> can</c><00:07:25.150><c> recognize</c>

00:07:25.559 --> 00:07:25.569 align:start position:0%
finally our landmark API can recognize
 

00:07:25.569 --> 00:07:27.899 align:start position:0%
finally our landmark API can recognize
well-known<00:07:26.319><c> places</c><00:07:26.830><c> in</c><00:07:27.250><c> the</c><00:07:27.400><c> photo</c><00:07:27.610><c> like</c>

00:07:27.899 --> 00:07:27.909 align:start position:0%
well-known places in the photo like
 

00:07:27.909 --> 00:07:32.040 align:start position:0%
well-known places in the photo like
White<00:07:28.210><c> House</c><00:07:28.479><c> our</c><00:07:28.840><c> effort</c><00:07:29.379><c> our</c><00:07:30.810><c> if</c><00:07:31.810><c> this</c>

00:07:32.040 --> 00:07:32.050 align:start position:0%
White House our effort our if this
 

00:07:32.050 --> 00:07:34.170 align:start position:0%
White House our effort our if this
pre-trained<00:07:32.560><c> model</c><00:07:32.979><c> tunafish</c><00:07:33.340><c> your</c><00:07:33.669><c> need</c><00:07:33.879><c> and</c>

00:07:34.170 --> 00:07:34.180 align:start position:0%
pre-trained model tunafish your need and
 

00:07:34.180 --> 00:07:36.830 align:start position:0%
pre-trained model tunafish your need and
you<00:07:34.870><c> are</c><00:07:34.900><c> an</c><00:07:35.020><c> experienced</c><00:07:35.560><c> developer</c><00:07:36.129><c> with</c>

00:07:36.830 --> 00:07:36.840 align:start position:0%
you are an experienced developer with
 

00:07:36.840 --> 00:07:38.879 align:start position:0%
you are an experienced developer with
with<00:07:37.840><c> that</c><00:07:38.080><c> knowledge</c><00:07:38.289><c> you</c><00:07:38.650><c> know</c><00:07:38.710><c> how</c><00:07:38.830><c> to</c>

00:07:38.879 --> 00:07:38.889 align:start position:0%
with that knowledge you know how to
 

00:07:38.889 --> 00:07:41.040 align:start position:0%
with that knowledge you know how to
build<00:07:39.219><c> and</c><00:07:39.460><c> train</c><00:07:39.759><c> models</c><00:07:40.210><c> you're</c><00:07:40.750><c> more</c><00:07:40.960><c> than</c>

00:07:41.040 --> 00:07:41.050 align:start position:0%
build and train models you're more than
 

00:07:41.050 --> 00:07:43.080 align:start position:0%
build and train models you're more than
welcome<00:07:41.259><c> to</c><00:07:41.529><c> bring</c><00:07:41.770><c> your</c><00:07:41.860><c> own</c><00:07:42.039><c> custom</c><00:07:42.729><c> model</c>

00:07:43.080 --> 00:07:43.090 align:start position:0%
welcome to bring your own custom model
 

00:07:43.090 --> 00:07:46.469 align:start position:0%
welcome to bring your own custom model
we<00:07:43.990><c> rank</c><00:07:44.259><c> us</c><00:07:44.409><c> models</c><00:07:44.889><c> intensive</c><00:07:45.819><c> low</c><00:07:45.969><c> light</c><00:07:46.210><c> as</c>

00:07:46.469 --> 00:07:46.479 align:start position:0%
we rank us models intensive low light as
 

00:07:46.479 --> 00:07:48.869 align:start position:0%
we rank us models intensive low light as
you<00:07:47.319><c> might</c><00:07:47.500><c> know</c><00:07:47.680><c> tensorflow</c><00:07:48.190><c> is</c><00:07:48.490><c> an</c><00:07:48.610><c> open</c>

00:07:48.869 --> 00:07:48.879 align:start position:0%
you might know tensorflow is an open
 

00:07:48.879 --> 00:07:50.159 align:start position:0%
you might know tensorflow is an open
source<00:07:49.090><c> framework</c><00:07:49.599><c> for</c><00:07:49.810><c> machine</c><00:07:50.139><c> learning</c>

00:07:50.159 --> 00:07:50.169 align:start position:0%
source framework for machine learning
 

00:07:50.169 --> 00:07:52.320 align:start position:0%
source framework for machine learning
and<00:07:50.590><c> hence</c><00:07:51.190><c> the</c><00:07:51.279><c> flow</c><00:07:51.460><c> light</c><00:07:51.699><c> is</c><00:07:52.270><c> a</c>

00:07:52.320 --> 00:07:52.330 align:start position:0%
and hence the flow light is a
 

00:07:52.330 --> 00:07:53.839 align:start position:0%
and hence the flow light is a
lightweight<00:07:52.779><c> version</c><00:07:53.199><c> of</c><00:07:53.440><c> tensorflow</c>

00:07:53.839 --> 00:07:53.849 align:start position:0%
lightweight version of tensorflow
 

00:07:53.849 --> 00:07:57.180 align:start position:0%
lightweight version of tensorflow
optimized<00:07:54.849><c> for</c><00:07:55.120><c> mobile</c><00:07:55.330><c> platforms</c><00:07:56.190><c> for</c>

00:07:57.180 --> 00:07:57.190 align:start position:0%
optimized for mobile platforms for
 

00:07:57.190 --> 00:07:59.040 align:start position:0%
optimized for mobile platforms for
models<00:07:57.550><c> trained</c><00:07:57.879><c> with</c><00:07:58.060><c> tensorflow</c><00:07:58.449><c> we</c>

00:07:59.040 --> 00:07:59.050 align:start position:0%
models trained with tensorflow we
 

00:07:59.050 --> 00:08:01.350 align:start position:0%
models trained with tensorflow we
provide<00:07:59.379><c> your</c><00:07:59.529><c> tools</c><00:07:59.800><c> to</c><00:08:00.460><c> convert</c><00:08:00.909><c> and</c>

00:08:01.350 --> 00:08:01.360 align:start position:0%
provide your tools to convert and
 

00:08:01.360 --> 00:08:04.050 align:start position:0%
provide your tools to convert and
compress<00:08:01.930><c> into</c><00:08:02.469><c> a</c><00:08:02.529><c> format</c><00:08:03.190><c> compatible</c><00:08:03.520><c> with</c>

00:08:04.050 --> 00:08:04.060 align:start position:0%
compress into a format compatible with
 

00:08:04.060 --> 00:08:06.659 align:start position:0%
compress into a format compatible with
sensor<00:08:04.360><c> for</c><00:08:04.509><c> light</c><00:08:05.310><c> when</c><00:08:06.310><c> you're</c><00:08:06.460><c> using</c>

00:08:06.659 --> 00:08:06.669 align:start position:0%
sensor for light when you're using
 

00:08:06.669 --> 00:08:08.159 align:start position:0%
sensor for light when you're using
custom<00:08:07.060><c> model</c><00:08:07.300><c> you</c><00:08:07.360><c> have</c><00:08:07.479><c> two</c><00:08:07.599><c> options</c><00:08:08.020><c> either</c>

00:08:08.159 --> 00:08:08.169 align:start position:0%
custom model you have two options either
 

00:08:08.169 --> 00:08:11.070 align:start position:0%
custom model you have two options either
bounded<00:08:08.830><c> inside</c><00:08:09.460><c> your</c><00:08:09.580><c> app</c><00:08:09.789><c> or</c><00:08:10.569><c> hosted</c><00:08:10.990><c> in</c><00:08:11.050><c> the</c>

00:08:11.070 --> 00:08:11.080 align:start position:0%
bounded inside your app or hosted in the
 

00:08:11.080 --> 00:08:13.110 align:start position:0%
bounded inside your app or hosted in the
cloud<00:08:11.169><c> if</c><00:08:12.129><c> you</c><00:08:12.190><c> choose</c><00:08:12.520><c> the</c><00:08:12.669><c> latter</c><00:08:12.819><c> option</c>

00:08:13.110 --> 00:08:13.120 align:start position:0%
cloud if you choose the latter option
 

00:08:13.120 --> 00:08:15.360 align:start position:0%
cloud if you choose the latter option
the<00:08:13.389><c> host</c><00:08:13.599><c> in</c><00:08:13.690><c> the</c><00:08:13.779><c> cloud</c><00:08:13.990><c> does</c><00:08:14.830><c> not</c><00:08:15.009><c> mean</c><00:08:15.219><c> you</c>

00:08:15.360 --> 00:08:15.370 align:start position:0%
the host in the cloud does not mean you
 

00:08:15.370 --> 00:08:17.850 align:start position:0%
the host in the cloud does not mean you
need<00:08:15.490><c> to</c><00:08:15.550><c> build</c><00:08:15.699><c> your</c><00:08:15.789><c> own</c><00:08:16.000><c> cloud</c><00:08:16.270><c> server</c><00:08:16.860><c> ml</c>

00:08:17.850 --> 00:08:17.860 align:start position:0%
need to build your own cloud server ml
 

00:08:17.860 --> 00:08:19.680 align:start position:0%
need to build your own cloud server ml
kit<00:08:18.099><c> and</c><00:08:18.279><c> firebase</c><00:08:18.699><c> or</c><00:08:19.029><c> provide</c><00:08:19.389><c> a</c><00:08:19.419><c> way</c><00:08:19.659><c> for</c>

00:08:19.680 --> 00:08:19.690 align:start position:0%
kit and firebase or provide a way for
 

00:08:19.690 --> 00:08:22.499 align:start position:0%
kit and firebase or provide a way for
for<00:08:20.440><c> you</c><00:08:20.560><c> for</c><00:08:20.889><c> for</c><00:08:21.069><c> you</c><00:08:21.219><c> we</c><00:08:21.819><c> will</c><00:08:21.909><c> manage</c><00:08:22.180><c> the</c>

00:08:22.499 --> 00:08:22.509 align:start position:0%
for you for for you we will manage the
 

00:08:22.509 --> 00:08:25.019 align:start position:0%
for you for for you we will manage the
model<00:08:22.870><c> hosting</c><00:08:23.289><c> deployment</c><00:08:24.099><c> downloading</c>

00:08:25.019 --> 00:08:25.029 align:start position:0%
model hosting deployment downloading
 

00:08:25.029 --> 00:08:26.779 align:start position:0%
model hosting deployment downloading
upgrade<00:08:25.719><c> as</c><00:08:25.990><c> well</c><00:08:26.349><c> as</c><00:08:26.440><c> the</c><00:08:26.529><c> ongoing</c>

00:08:26.779 --> 00:08:26.789 align:start position:0%
upgrade as well as the ongoing
 

00:08:26.789 --> 00:08:31.260 align:start position:0%
upgrade as well as the ongoing
experimentations<00:08:29.520><c> since</c><00:08:30.520><c> ml</c><00:08:30.879><c> kid</c><00:08:31.060><c> was</c>

00:08:31.260 --> 00:08:31.270 align:start position:0%
experimentations since ml kid was
 

00:08:31.270 --> 00:08:33.870 align:start position:0%
experimentations since ml kid was
launched<00:08:31.839><c> six</c><00:08:32.260><c> months</c><00:08:32.529><c> ago</c><00:08:32.649><c> at</c><00:08:32.949><c> Google</c><00:08:33.310><c> i/o</c><00:08:33.459><c> we</c>

00:08:33.870 --> 00:08:33.880 align:start position:0%
launched six months ago at Google i/o we
 

00:08:33.880 --> 00:08:37.589 align:start position:0%
launched six months ago at Google i/o we
have<00:08:34.479><c> made</c><00:08:34.690><c> several</c><00:08:34.959><c> enhancements</c><00:08:36.300><c> first</c>

00:08:37.589 --> 00:08:37.599 align:start position:0%
have made several enhancements first
 

00:08:37.599 --> 00:08:40.439 align:start position:0%
have made several enhancements first
we<00:08:37.899><c> greatly</c><00:08:38.199><c> enhanced</c><00:08:38.949><c> our</c><00:08:39.159><c> face</c><00:08:39.729><c> detection</c>

00:08:40.439 --> 00:08:40.449 align:start position:0%
we greatly enhanced our face detection
 

00:08:40.449 --> 00:08:43.380 align:start position:0%
we greatly enhanced our face detection
models<00:08:41.070><c> which</c><00:08:42.070><c> is</c><00:08:42.250><c> now</c><00:08:42.459><c> eighteen</c><00:08:43.149><c> times</c>

00:08:43.380 --> 00:08:43.390 align:start position:0%
models which is now eighteen times
 

00:08:43.390 --> 00:08:46.740 align:start position:0%
models which is now eighteen times
faster<00:08:43.990><c> and</c><00:08:44.199><c> a</c><00:08:44.649><c> 13</c><00:08:45.160><c> to</c><00:08:45.459><c> 24</c><00:08:45.910><c> percent</c><00:08:46.149><c> more</c>

00:08:46.740 --> 00:08:46.750 align:start position:0%
faster and a 13 to 24 percent more
 

00:08:46.750 --> 00:08:50.490 align:start position:0%
faster and a 13 to 24 percent more
accurate<00:08:47.699><c> we</c><00:08:48.699><c> also</c><00:08:49.060><c> polished</c><00:08:49.569><c> our</c><00:08:49.810><c> text</c>

00:08:50.490 --> 00:08:50.500 align:start position:0%
accurate we also polished our text
 

00:08:50.500 --> 00:08:52.980 align:start position:0%
accurate we also polished our text
recognition<00:08:50.800><c> API</c><00:08:51.190><c> by</c><00:08:52.029><c> making</c><00:08:52.390><c> them</c><00:08:52.540><c> more</c>

00:08:52.980 --> 00:08:52.990 align:start position:0%
recognition API by making them more
 

00:08:52.990 --> 00:08:54.210 align:start position:0%
recognition API by making them more
streamlined

00:08:54.210 --> 00:08:54.220 align:start position:0%
streamlined
 

00:08:54.220 --> 00:08:56.369 align:start position:0%
streamlined
consistent<00:08:54.879><c> across</c><00:08:55.180><c> both</c><00:08:55.569><c> sound</c><00:08:55.839><c> device</c><00:08:56.110><c> and</c>

00:08:56.369 --> 00:08:56.379 align:start position:0%
consistent across both sound device and
 

00:08:56.379 --> 00:09:00.449 align:start position:0%
consistent across both sound device and
the<00:08:56.709><c> cloud</c><00:08:57.300><c> in</c><00:08:58.300><c> addition</c><00:08:58.720><c> we</c><00:08:59.079><c> launched</c><00:08:59.459><c> 133</c>

00:09:00.449 --> 00:09:00.459 align:start position:0%
the cloud in addition we launched 133
 

00:09:00.459 --> 00:09:04.710 align:start position:0%
the cloud in addition we launched 133
point<00:09:00.790><c> face</c><00:09:01.180><c> contour</c><00:09:01.629><c> detection</c><00:09:02.879><c> as</c><00:09:03.879><c> shown</c><00:09:04.689><c> in</c>

00:09:04.710 --> 00:09:04.720 align:start position:0%
point face contour detection as shown in
 

00:09:04.720 --> 00:09:07.800 align:start position:0%
point face contour detection as shown in
this<00:09:04.899><c> image</c><00:09:05.170><c> you</c><00:09:06.069><c> can</c><00:09:06.100><c> see</c><00:09:06.269><c> now</c><00:09:07.269><c> you</c><00:09:07.329><c> can</c><00:09:07.660><c> use</c>

00:09:07.800 --> 00:09:07.810 align:start position:0%
this image you can see now you can use
 

00:09:07.810 --> 00:09:09.960 align:start position:0%
this image you can see now you can use
our<00:09:08.050><c> face</c><00:09:08.350><c> count</c><00:09:08.740><c> or</c><00:09:08.920><c> detection</c><00:09:09.220><c> API</c><00:09:09.639><c> it</c><00:09:09.819><c> will</c>

00:09:09.960 --> 00:09:09.970 align:start position:0%
our face count or detection API it will
 

00:09:09.970 --> 00:09:11.939 align:start position:0%
our face count or detection API it will
identify<00:09:10.120><c> the</c><00:09:10.449><c> contours</c><00:09:11.050><c> of</c><00:09:11.199><c> various</c><00:09:11.560><c> parts</c>

00:09:11.939 --> 00:09:11.949 align:start position:0%
identify the contours of various parts
 

00:09:11.949 --> 00:09:14.879 align:start position:0%
identify the contours of various parts
of<00:09:12.100><c> your</c><00:09:12.279><c> face</c><00:09:12.689><c> or</c><00:09:13.689><c> anyone's</c><00:09:14.350><c> face</c><00:09:14.589><c> in</c><00:09:14.829><c> the</c>

00:09:14.879 --> 00:09:14.889 align:start position:0%
of your face or anyone's face in the
 

00:09:14.889 --> 00:09:17.910 align:start position:0%
of your face or anyone's face in the
photo<00:09:15.100><c> and</c><00:09:15.480><c> includes</c><00:09:16.480><c> the</c><00:09:16.660><c> entire</c><00:09:16.930><c> face</c><00:09:17.410><c> both</c>

00:09:17.910 --> 00:09:17.920 align:start position:0%
photo and includes the entire face both
 

00:09:17.920 --> 00:09:21.300 align:start position:0%
photo and includes the entire face both
eyebrows<00:09:18.490><c> eyes</c><00:09:18.819><c> nose</c><00:09:19.509><c> and</c><00:09:19.540><c> lips</c><00:09:20.110><c> this</c><00:09:21.100><c> is</c>

00:09:21.300 --> 00:09:21.310 align:start position:0%
eyebrows eyes nose and lips this is
 

00:09:21.310 --> 00:09:23.999 align:start position:0%
eyebrows eyes nose and lips this is
where<00:09:21.579><c> the</c><00:09:21.850><c> real-time</c><00:09:22.410><c> asks</c><00:09:23.410><c> can</c><00:09:23.740><c> put</c><00:09:23.980><c> a</c>

00:09:23.999 --> 00:09:24.009 align:start position:0%
where the real-time asks can put a
 

00:09:24.009 --> 00:09:26.850 align:start position:0%
where the real-time asks can put a
customer<00:09:24.490><c> faces</c><00:09:25.029><c> a</c><00:09:25.269><c> customer</c><00:09:26.170><c> face</c><00:09:26.350><c> mask</c><00:09:26.620><c> and</c>

00:09:26.850 --> 00:09:26.860 align:start position:0%
customer faces a customer face mask and
 

00:09:26.860 --> 00:09:30.840 align:start position:0%
customer faces a customer face mask and
futures<00:09:27.370><c> like</c><00:09:28.029><c> a</c><00:09:28.449><c> goggle</c><00:09:29.110><c> or</c><00:09:29.259><c> some</c><00:09:30.250><c> funny</c><00:09:30.519><c> nose</c>

00:09:30.840 --> 00:09:30.850 align:start position:0%
futures like a goggle or some funny nose
 

00:09:30.850 --> 00:09:34.559 align:start position:0%
futures like a goggle or some funny nose
on<00:09:31.149><c> the</c><00:09:31.509><c> face</c><00:09:31.689><c> and</c><00:09:31.959><c> make</c><00:09:32.889><c> the</c><00:09:33.189><c> mask</c><00:09:33.699><c> move</c><00:09:34.209><c> waist</c>

00:09:34.559 --> 00:09:34.569 align:start position:0%
on the face and make the mask move waist
 

00:09:34.569 --> 00:09:39.990 align:start position:0%
on the face and make the mask move waist
face<00:09:34.899><c> in</c><00:09:35.379><c> a</c><00:09:35.500><c> live</c><00:09:35.709><c> video</c><00:09:36.100><c> streaming</c><00:09:38.310><c> next</c><00:09:39.310><c> I'm</c>

00:09:39.990 --> 00:09:40.000 align:start position:0%
face in a live video streaming next I'm
 

00:09:40.000 --> 00:09:42.059 align:start position:0%
face in a live video streaming next I'm
going<00:09:40.240><c> to</c><00:09:40.300><c> share</c><00:09:40.480><c> some</c><00:09:40.779><c> tips</c><00:09:41.050><c> and</c><00:09:41.709><c> a</c><00:09:41.800><c> best</c>

00:09:42.059 --> 00:09:42.069 align:start position:0%
going to share some tips and a best
 

00:09:42.069 --> 00:09:45.300 align:start position:0%
going to share some tips and a best
practices<00:09:42.759><c> for</c><00:09:43.000><c> how</c><00:09:43.180><c> to</c><00:09:43.240><c> use</c><00:09:43.480><c> ml</c><00:09:43.959><c> kit</c><00:09:44.199><c> so</c><00:09:44.889><c> I</c><00:09:44.920><c> can</c>

00:09:45.300 --> 00:09:45.310 align:start position:0%
practices for how to use ml kit so I can
 

00:09:45.310 --> 00:09:47.490 align:start position:0%
practices for how to use ml kit so I can
build<00:09:45.550><c> an</c><00:09:45.790><c> impressive</c><00:09:46.000><c> mobile</c><00:09:46.750><c> apps</c><00:09:47.019><c> using</c>

00:09:47.490 --> 00:09:47.500 align:start position:0%
build an impressive mobile apps using
 

00:09:47.500 --> 00:09:50.100 align:start position:0%
build an impressive mobile apps using
own<00:09:47.800><c> device</c><00:09:48.069><c> machine-learning</c><00:09:48.779><c> first</c><00:09:49.779><c> of</c><00:09:49.930><c> all</c>

00:09:50.100 --> 00:09:50.110 align:start position:0%
own device machine-learning first of all
 

00:09:50.110 --> 00:09:51.780 align:start position:0%
own device machine-learning first of all
I<00:09:50.319><c> will</c><00:09:50.769><c> share</c><00:09:50.949><c> a</c><00:09:50.980><c> couple</c><00:09:51.279><c> tips</c><00:09:51.459><c> for</c><00:09:51.699><c> achieving</c>

00:09:51.780 --> 00:09:51.790 align:start position:0%
I will share a couple tips for achieving
 

00:09:51.790 --> 00:09:55.199 align:start position:0%
I will share a couple tips for achieving
best<00:09:52.329><c> accuracy</c><00:09:53.250><c> there</c><00:09:54.250><c> are</c><00:09:54.339><c> two</c><00:09:54.519><c> things</c><00:09:54.790><c> you</c>

00:09:55.199 --> 00:09:55.209 align:start position:0%
best accuracy there are two things you
 

00:09:55.209 --> 00:09:57.809 align:start position:0%
best accuracy there are two things you
should<00:09:55.240><c> make</c><00:09:55.689><c> sure</c><00:09:55.800><c> one</c><00:09:56.800><c> you</c><00:09:57.339><c> should</c><00:09:57.550><c> take</c><00:09:57.790><c> a</c>

00:09:57.809 --> 00:09:57.819 align:start position:0%
should make sure one you should take a
 

00:09:57.819 --> 00:10:01.259 align:start position:0%
should make sure one you should take a
very<00:09:58.269><c> sharp</c><00:09:58.660><c> and</c><00:09:58.959><c> a</c><00:09:59.019><c> well</c><00:09:59.500><c> focused</c><00:10:00.129><c> image</c><00:10:00.459><c> poor</c>

00:10:01.259 --> 00:10:01.269 align:start position:0%
very sharp and a well focused image poor
 

00:10:01.269 --> 00:10:05.119 align:start position:0%
very sharp and a well focused image poor
image<00:10:01.750><c> focus</c><00:10:02.680><c> can</c><00:10:02.889><c> really</c><00:10:03.189><c> hurt</c><00:10:03.730><c> the</c><00:10:03.970><c> accuracy</c>

00:10:05.119 --> 00:10:05.129 align:start position:0%
image focus can really hurt the accuracy
 

00:10:05.129 --> 00:10:08.069 align:start position:0%
image focus can really hurt the accuracy
second<00:10:06.129><c> you</c><00:10:06.550><c> should</c><00:10:06.579><c> ensure</c><00:10:07.120><c> the</c><00:10:07.449><c> options</c><00:10:08.019><c> you</c>

00:10:08.069 --> 00:10:08.079 align:start position:0%
second you should ensure the options you
 

00:10:08.079 --> 00:10:09.660 align:start position:0%
second you should ensure the options you
want<00:10:08.170><c> to</c><00:10:08.290><c> detect</c><00:10:08.529><c> in</c><00:10:08.740><c> the</c><00:10:08.829><c> image</c><00:10:09.399><c> has</c>

00:10:09.660 --> 00:10:09.670 align:start position:0%
want to detect in the image has
 

00:10:09.670 --> 00:10:12.420 align:start position:0%
want to detect in the image has
sufficient<00:10:10.180><c> size</c><00:10:10.649><c> for</c><00:10:11.649><c> example</c><00:10:11.680><c> for</c><00:10:12.279><c> face</c>

00:10:12.420 --> 00:10:12.430 align:start position:0%
sufficient size for example for face
 

00:10:12.430 --> 00:10:14.280 align:start position:0%
sufficient size for example for face
detection<00:10:12.819><c> you</c><00:10:13.420><c> should</c><00:10:13.600><c> have</c><00:10:13.750><c> at</c><00:10:13.930><c> least</c><00:10:13.959><c> 100</c>

00:10:14.280 --> 00:10:14.290 align:start position:0%
detection you should have at least 100
 

00:10:14.290 --> 00:10:17.730 align:start position:0%
detection you should have at least 100
by<00:10:14.620><c> 100</c><00:10:14.740><c> pixels</c><00:10:15.370><c> for</c><00:10:15.790><c> each</c><00:10:16.029><c> face</c><00:10:16.449><c> and</c><00:10:16.839><c> if</c><00:10:17.589><c> you</c>

00:10:17.730 --> 00:10:17.740 align:start position:0%
by 100 pixels for each face and if you
 

00:10:17.740 --> 00:10:19.619 align:start position:0%
by 100 pixels for each face and if you
want<00:10:17.949><c> a</c><00:10:18.040><c> counter</c><00:10:18.279><c> detection</c><00:10:19.000><c> in</c><00:10:19.089><c> their</c><00:10:19.240><c> selfie</c>

00:10:19.619 --> 00:10:19.629 align:start position:0%
want a counter detection in their selfie
 

00:10:19.629 --> 00:10:22.559 align:start position:0%
want a counter detection in their selfie
mode<00:10:19.809><c> for</c><00:10:20.170><c> example</c><00:10:20.220><c> then</c><00:10:21.220><c> the</c><00:10:21.819><c> face</c><00:10:22.089><c> should</c><00:10:22.420><c> be</c>

00:10:22.559 --> 00:10:22.569 align:start position:0%
mode for example then the face should be
 

00:10:22.569 --> 00:10:27.799 align:start position:0%
mode for example then the face should be
200<00:10:23.170><c> by</c><00:10:23.259><c> 200</c><00:10:23.470><c> pixels</c><00:10:24.689><c> for</c><00:10:25.800><c> for</c><00:10:26.800><c> the</c><00:10:26.889><c> text</c><00:10:27.309><c> API</c>

00:10:27.799 --> 00:10:27.809 align:start position:0%
200 by 200 pixels for for the text API
 

00:10:27.809 --> 00:10:31.170 align:start position:0%
200 by 200 pixels for for the text API
for<00:10:28.809><c> Latin</c><00:10:29.139><c> languages</c><00:10:29.620><c> each</c><00:10:30.160><c> characters</c><00:10:30.850><c> be</c>

00:10:31.170 --> 00:10:31.180 align:start position:0%
for Latin languages each characters be
 

00:10:31.180 --> 00:10:34.650 align:start position:0%
for Latin languages each characters be
at<00:10:31.300><c> least</c><00:10:31.420><c> 16</c><00:10:31.870><c> by</c><00:10:31.990><c> sitting</c><00:10:32.379><c> in</c><00:10:32.620><c> in</c><00:10:33.309><c> size</c><00:10:33.610><c> if</c><00:10:34.449><c> you</c>

00:10:34.650 --> 00:10:34.660 align:start position:0%
at least 16 by sitting in in size if you
 

00:10:34.660 --> 00:10:37.319 align:start position:0%
at least 16 by sitting in in size if you
use<00:10:34.839><c> our</c><00:10:35.079><c> cloud</c><00:10:35.500><c> API</c><00:10:35.769><c> to</c><00:10:36.009><c> detect</c><00:10:37.000><c> and</c>

00:10:37.319 --> 00:10:37.329 align:start position:0%
use our cloud API to detect and
 

00:10:37.329 --> 00:10:40.319 align:start position:0%
use our cloud API to detect and
recognize<00:10:37.899><c> Chinese</c><00:10:38.829><c> Japanese</c><00:10:39.220><c> and</c><00:10:39.819><c> Korean</c>

00:10:40.319 --> 00:10:40.329 align:start position:0%
recognize Chinese Japanese and Korean
 

00:10:40.329 --> 00:10:42.720 align:start position:0%
recognize Chinese Japanese and Korean
the<00:10:40.990><c> each</c><00:10:41.259><c> character</c><00:10:41.769><c> in</c><00:10:42.009><c> those</c><00:10:42.160><c> oriental</c>

00:10:42.720 --> 00:10:42.730 align:start position:0%
the each character in those oriental
 

00:10:42.730 --> 00:10:45.290 align:start position:0%
the each character in those oriental
language<00:10:43.120><c> should</c><00:10:43.420><c> be</c><00:10:43.540><c> at</c><00:10:43.720><c> least</c><00:10:43.870><c> 24</c><00:10:44.379><c> by</c><00:10:44.529><c> 24</c>

00:10:45.290 --> 00:10:45.300 align:start position:0%
language should be at least 24 by 24
 

00:10:45.300 --> 00:10:47.819 align:start position:0%
language should be at least 24 by 24
similarly<00:10:46.300><c> bar</c><00:10:46.629><c> code</c><00:10:46.839><c> also</c><00:10:47.110><c> have</c><00:10:47.410><c> the</c><00:10:47.559><c> size</c>

00:10:47.819 --> 00:10:47.829 align:start position:0%
similarly bar code also have the size
 

00:10:47.829 --> 00:10:50.280 align:start position:0%
similarly bar code also have the size
requirement<00:10:48.550><c> please</c><00:10:49.269><c> check</c><00:10:49.540><c> out</c><00:10:49.689><c> our</c><00:10:49.779><c> online</c>

00:10:50.280 --> 00:10:50.290 align:start position:0%
requirement please check out our online
 

00:10:50.290 --> 00:10:54.299 align:start position:0%
requirement please check out our online
documentation<00:10:50.439><c> for</c><00:10:51.370><c> more</c><00:10:51.399><c> details</c><00:10:53.309><c> machine</c>

00:10:54.299 --> 00:10:54.309 align:start position:0%
documentation for more details machine
 

00:10:54.309 --> 00:10:56.309 align:start position:0%
documentation for more details machine
learning<00:10:54.670><c> and</c><00:10:54.850><c> the</c><00:10:54.939><c> libraries</c><00:10:55.329><c> can</c><00:10:55.959><c> be</c><00:10:56.079><c> large</c>

00:10:56.309 --> 00:10:56.319 align:start position:0%
learning and the libraries can be large
 

00:10:56.319 --> 00:10:58.530 align:start position:0%
learning and the libraries can be large
which<00:10:57.069><c> can</c><00:10:57.339><c> slow</c><00:10:57.610><c> down</c><00:10:57.639><c> the</c><00:10:57.819><c> app</c><00:10:58.029><c> download</c>

00:10:58.530 --> 00:10:58.540 align:start position:0%
which can slow down the app download
 

00:10:58.540 --> 00:11:01.920 align:start position:0%
which can slow down the app download
there<00:10:59.439><c> are</c><00:10:59.529><c> two</c><00:10:59.709><c> ways</c><00:10:59.920><c> to</c><00:11:00.279><c> reduce</c><00:11:00.730><c> the</c><00:11:01.480><c> apk</c>

00:11:01.920 --> 00:11:01.930 align:start position:0%
there are two ways to reduce the apk
 

00:11:01.930 --> 00:11:06.240 align:start position:0%
there are two ways to reduce the apk
size<00:11:03.089><c> first</c><00:11:04.089><c> you</c><00:11:04.569><c> can</c><00:11:04.809><c> build</c><00:11:05.589><c> your</c><00:11:05.709><c> app</c><00:11:05.920><c> as</c><00:11:06.189><c> a</c>

00:11:06.240 --> 00:11:06.250 align:start position:0%
size first you can build your app as a
 

00:11:06.250 --> 00:11:07.920 align:start position:0%
size first you can build your app as a
Android<00:11:07.059><c> app</c><00:11:07.269><c> bundle</c>

00:11:07.920 --> 00:11:07.930 align:start position:0%
Android app bundle
 

00:11:07.930 --> 00:11:11.700 align:start position:0%
Android app bundle
by<00:11:08.890><c> doing</c><00:11:08.950><c> that</c><00:11:09.220><c> you</c><00:11:10.060><c> enable</c><00:11:10.630><c> Google</c><00:11:10.840><c> Play</c><00:11:11.230><c> to</c>

00:11:11.700 --> 00:11:11.710 align:start position:0%
by doing that you enable Google Play to
 

00:11:11.710 --> 00:11:14.040 align:start position:0%
by doing that you enable Google Play to
automatically<00:11:12.250><c> generate</c><00:11:12.310><c> apks</c><00:11:13.150><c> for</c><00:11:13.420><c> specific</c>

00:11:14.040 --> 00:11:14.050 align:start position:0%
automatically generate apks for specific
 

00:11:14.050 --> 00:11:16.710 align:start position:0%
automatically generate apks for specific
screen<00:11:14.440><c> density</c><00:11:14.980><c> CPU</c><00:11:15.700><c> architecture</c><00:11:16.360><c> as</c><00:11:16.510><c> was</c>

00:11:16.710 --> 00:11:16.720 align:start position:0%
screen density CPU architecture as was
 

00:11:16.720 --> 00:11:19.380 align:start position:0%
screen density CPU architecture as was
the<00:11:16.840><c> languages</c><00:11:17.290><c> then</c><00:11:18.220><c> your</c><00:11:18.370><c> user</c><00:11:18.610><c> only</c><00:11:19.060><c> have</c>

00:11:19.380 --> 00:11:19.390 align:start position:0%
the languages then your user only have
 

00:11:19.390 --> 00:11:21.300 align:start position:0%
the languages then your user only have
to<00:11:19.630><c> download</c><00:11:19.810><c> the</c><00:11:20.080><c> apk</c><00:11:20.200><c> sand</c><00:11:20.800><c> native</c><00:11:21.040><c> code</c>

00:11:21.300 --> 00:11:21.310 align:start position:0%
to download the apk sand native code
 

00:11:21.310 --> 00:11:22.800 align:start position:0%
to download the apk sand native code
libraries<00:11:21.670><c> that</c><00:11:21.850><c> match</c><00:11:22.060><c> their</c><00:11:22.420><c> device</c>

00:11:22.800 --> 00:11:22.810 align:start position:0%
libraries that match their device
 

00:11:22.810 --> 00:11:26.250 align:start position:0%
libraries that match their device
configuration<00:11:24.330><c> another</c><00:11:25.330><c> way</c><00:11:25.600><c> you</c><00:11:25.660><c> can</c><00:11:25.990><c> reduce</c>

00:11:26.250 --> 00:11:26.260 align:start position:0%
configuration another way you can reduce
 

00:11:26.260 --> 00:11:29.730 align:start position:0%
configuration another way you can reduce
apk<00:11:26.800><c> size</c><00:11:26.830><c> is</c><00:11:27.400><c> if</c><00:11:28.360><c> you</c><00:11:28.570><c> the</c><00:11:28.690><c> machine</c><00:11:29.620><c> learning</c>

00:11:29.730 --> 00:11:29.740 align:start position:0%
apk size is if you the machine learning
 

00:11:29.740 --> 00:11:31.980 align:start position:0%
apk size is if you the machine learning
feature<00:11:30.100><c> in</c><00:11:30.250><c> your</c><00:11:30.460><c> app</c><00:11:30.610><c> is</c><00:11:30.910><c> not</c><00:11:31.300><c> a</c><00:11:31.330><c> primary</c>

00:11:31.980 --> 00:11:31.990 align:start position:0%
feature in your app is not a primary
 

00:11:31.990 --> 00:11:35.100 align:start position:0%
feature in your app is not a primary
purpose<00:11:32.340><c> then</c><00:11:33.340><c> you</c><00:11:33.580><c> could</c><00:11:33.850><c> move</c><00:11:34.450><c> machine</c>

00:11:35.100 --> 00:11:35.110 align:start position:0%
purpose then you could move machine
 

00:11:35.110 --> 00:11:37.050 align:start position:0%
purpose then you could move machine
learning<00:11:35.530><c> features</c><00:11:36.130><c> which</c><00:11:36.280><c> require</c><00:11:36.670><c> a</c><00:11:36.850><c> make</c>

00:11:37.050 --> 00:11:37.060 align:start position:0%
learning features which require a make
 

00:11:37.060 --> 00:11:40.680 align:start position:0%
learning features which require a make
it<00:11:37.360><c> into</c><00:11:38.200><c> a</c><00:11:38.260><c> dynamic</c><00:11:38.440><c> feature</c><00:11:38.920><c> module</c><00:11:39.430><c> in</c><00:11:40.420><c> that</c>

00:11:40.680 --> 00:11:40.690 align:start position:0%
it into a dynamic feature module in that
 

00:11:40.690 --> 00:11:42.930 align:start position:0%
it into a dynamic feature module in that
way<00:11:40.900><c> you</c><00:11:41.290><c> prevent</c><00:11:41.710><c> users</c><00:11:42.070><c> from</c><00:11:42.250><c> unnecessary</c>

00:11:42.930 --> 00:11:42.940 align:start position:0%
way you prevent users from unnecessary
 

00:11:42.940 --> 00:11:45.390 align:start position:0%
way you prevent users from unnecessary
downloading<00:11:43.720><c> ml</c><00:11:44.170><c> models</c><00:11:44.590><c> which</c><00:11:45.190><c> can</c>

00:11:45.390 --> 00:11:45.400 align:start position:0%
downloading ml models which can
 

00:11:45.400 --> 00:11:49.410 align:start position:0%
downloading ml models which can
sometimes<00:11:45.610><c> be</c><00:11:45.880><c> large</c><00:11:47.760><c> we</c><00:11:48.760><c> all</c><00:11:48.880><c> know</c><00:11:49.060><c> machine</c>

00:11:49.410 --> 00:11:49.420 align:start position:0%
sometimes be large we all know machine
 

00:11:49.420 --> 00:11:52.170 align:start position:0%
sometimes be large we all know machine
learning<00:11:49.650><c> involves</c><00:11:50.650><c> a</c><00:11:50.740><c> lot</c><00:11:51.040><c> of</c><00:11:51.220><c> computation</c>

00:11:52.170 --> 00:11:52.180 align:start position:0%
learning involves a lot of computation
 

00:11:52.180 --> 00:11:55.230 align:start position:0%
learning involves a lot of computation
so<00:11:53.110><c> the</c><00:11:53.560><c> speed</c><00:11:53.890><c> becomes</c><00:11:54.370><c> really</c><00:11:54.640><c> important</c>

00:11:55.230 --> 00:11:55.240 align:start position:0%
so the speed becomes really important
 

00:11:55.240 --> 00:11:57.720 align:start position:0%
so the speed becomes really important
here's<00:11:56.050><c> some</c><00:11:56.200><c> tips</c><00:11:56.440><c> how</c><00:11:56.890><c> you</c><00:11:56.920><c> could</c><00:11:57.370><c> improve</c>

00:11:57.720 --> 00:11:57.730 align:start position:0%
here's some tips how you could improve
 

00:11:57.730 --> 00:12:00.090 align:start position:0%
here's some tips how you could improve
the<00:11:58.270><c> performance</c><00:11:58.840><c> for</c><00:11:59.410><c> especially</c><00:11:59.920><c> for</c>

00:12:00.090 --> 00:12:00.100 align:start position:0%
the performance for especially for
 

00:12:00.100 --> 00:12:02.150 align:start position:0%
the performance for especially for
real-time<00:12:00.280><c> inference</c><00:12:00.910><c> on</c><00:12:01.090><c> streaming</c><00:12:01.510><c> video</c>

00:12:02.150 --> 00:12:02.160 align:start position:0%
real-time inference on streaming video
 

00:12:02.160 --> 00:12:05.100 align:start position:0%
real-time inference on streaming video
you<00:12:03.160><c> can</c><00:12:03.340><c> reduce</c><00:12:03.670><c> the</c><00:12:03.910><c> image</c><00:12:04.120><c> resolution</c><00:12:04.270><c> as</c><00:12:04.810><c> a</c>

00:12:05.100 --> 00:12:05.110 align:start position:0%
you can reduce the image resolution as a
 

00:12:05.110 --> 00:12:08.220 align:start position:0%
you can reduce the image resolution as a
video<00:12:05.500><c> frame</c><00:12:06.160><c> rate</c><00:12:06.370><c> to</c><00:12:07.120><c> limit</c><00:12:07.720><c> amount</c><00:12:08.110><c> of</c>

00:12:08.220 --> 00:12:08.230 align:start position:0%
video frame rate to limit amount of
 

00:12:08.230 --> 00:12:10.200 align:start position:0%
video frame rate to limit amount of
computation<00:12:08.800><c> it</c><00:12:09.040><c> involves</c><00:12:09.580><c> to</c><00:12:09.790><c> the</c><00:12:09.910><c> inference</c>

00:12:10.200 --> 00:12:10.210 align:start position:0%
computation it involves to the inference
 

00:12:10.210 --> 00:12:13.470 align:start position:0%
computation it involves to the inference
when<00:12:11.170><c> the</c><00:12:11.290><c> current</c><00:12:11.650><c> frame</c><00:12:11.890><c> speed</c><00:12:12.220><c> process</c><00:12:12.790><c> you</c>

00:12:13.470 --> 00:12:13.480 align:start position:0%
when the current frame speed process you
 

00:12:13.480 --> 00:12:15.660 align:start position:0%
when the current frame speed process you
should<00:12:13.690><c> also</c><00:12:13.870><c> throttle</c><00:12:14.560><c> incoming</c><00:12:15.340><c> video</c>

00:12:15.660 --> 00:12:15.670 align:start position:0%
should also throttle incoming video
 

00:12:15.670 --> 00:12:17.520 align:start position:0%
should also throttle incoming video
frames<00:12:15.970><c> to</c><00:12:16.180><c> avoid</c><00:12:16.360><c> any</c><00:12:16.660><c> backup</c><00:12:17.140><c> which</c>

00:12:17.520 --> 00:12:17.530 align:start position:0%
frames to avoid any backup which
 

00:12:17.530 --> 00:12:19.770 align:start position:0%
frames to avoid any backup which
increased<00:12:18.040><c> memory</c><00:12:18.340><c> as</c><00:12:18.730><c> well</c><00:12:19.000><c> slow</c><00:12:19.330><c> down</c><00:12:19.360><c> the</c>

00:12:19.770 --> 00:12:19.780 align:start position:0%
increased memory as well slow down the
 

00:12:19.780 --> 00:12:22.800 align:start position:0%
increased memory as well slow down the
performance<00:12:20.730><c> for</c><00:12:21.730><c> real-time</c><00:12:22.120><c> face</c><00:12:22.420><c> detection</c>

00:12:22.800 --> 00:12:22.810 align:start position:0%
performance for real-time face detection
 

00:12:22.810 --> 00:12:26.190 align:start position:0%
performance for real-time face detection
you<00:12:23.770><c> should</c><00:12:23.950><c> use</c><00:12:24.130><c> face</c><00:12:24.700><c> fast</c><00:12:25.180><c> mode</c><00:12:25.480><c> which</c>

00:12:26.190 --> 00:12:26.200 align:start position:0%
you should use face fast mode which
 

00:12:26.200 --> 00:12:29.100 align:start position:0%
you should use face fast mode which
luckily<00:12:26.620><c> is</c><00:12:26.800><c> the</c><00:12:26.950><c> default</c><00:12:27.370><c> mode</c><00:12:28.110><c> oftentime</c>

00:12:29.100 --> 00:12:29.110 align:start position:0%
luckily is the default mode oftentime
 

00:12:29.110 --> 00:12:31.920 align:start position:0%
luckily is the default mode oftentime
480<00:12:29.920><c> by</c><00:12:30.070><c> 360</c><00:12:30.640><c> resolution</c><00:12:31.210><c> is</c><00:12:31.360><c> sufficient</c><00:12:31.840><c> for</c>

00:12:31.920 --> 00:12:31.930 align:start position:0%
480 by 360 resolution is sufficient for
 

00:12:31.930 --> 00:12:34.980 align:start position:0%
480 by 360 resolution is sufficient for
face<00:12:32.200><c> detection</c><00:12:32.970><c> for</c><00:12:33.970><c> real-time</c><00:12:34.210><c> processing</c>

00:12:34.980 --> 00:12:34.990 align:start position:0%
face detection for real-time processing
 

00:12:34.990 --> 00:12:38.070 align:start position:0%
face detection for real-time processing
you<00:12:35.440><c> should</c><00:12:35.650><c> also</c><00:12:36.010><c> choose</c><00:12:36.550><c> between</c><00:12:37.080><c> counter</c>

00:12:38.070 --> 00:12:38.080 align:start position:0%
you should also choose between counter
 

00:12:38.080 --> 00:12:40.380 align:start position:0%
you should also choose between counter
detection<00:12:38.620><c> versus</c><00:12:39.280><c> classification</c><00:12:40.210><c> or</c>

00:12:40.380 --> 00:12:40.390 align:start position:0%
detection versus classification or
 

00:12:40.390 --> 00:12:43.620 align:start position:0%
detection versus classification or
landmark<00:12:41.170><c> detection</c><00:12:41.680><c> but</c><00:12:42.190><c> not</c><00:12:42.400><c> both</c><00:12:42.630><c> because</c>

00:12:43.620 --> 00:12:43.630 align:start position:0%
landmark detection but not both because
 

00:12:43.630 --> 00:12:46.200 align:start position:0%
landmark detection but not both because
doing<00:12:43.930><c> both</c><00:12:44.230><c> could</c><00:12:44.740><c> be</c><00:12:44.830><c> expensive</c><00:12:45.190><c> and</c><00:12:45.610><c> may</c>

00:12:46.200 --> 00:12:46.210 align:start position:0%
doing both could be expensive and may
 

00:12:46.210 --> 00:12:47.900 align:start position:0%
doing both could be expensive and may
not<00:12:46.420><c> be</c><00:12:46.570><c> fit</c><00:12:46.840><c> for</c><00:12:47.230><c> the</c><00:12:47.320><c> real-time</c><00:12:47.590><c> device</c>

00:12:47.900 --> 00:12:47.910 align:start position:0%
not be fit for the real-time device
 

00:12:47.910 --> 00:12:51.410 align:start position:0%
not be fit for the real-time device
real-time<00:12:48.910><c> processing</c><00:12:49.510><c> in</c><00:12:49.750><c> a</c><00:12:49.840><c> slow</c><00:12:50.050><c> device</c>

00:12:51.410 --> 00:12:51.420 align:start position:0%
real-time processing in a slow device
 

00:12:51.420 --> 00:12:54.270 align:start position:0%
real-time processing in a slow device
another<00:12:52.420><c> tip</c><00:12:52.750><c> and</c><00:12:52.990><c> trick</c><00:12:53.590><c> you</c><00:12:53.740><c> should</c><00:12:53.770><c> even</c>

00:12:54.270 --> 00:12:54.280 align:start position:0%
another tip and trick you should even
 

00:12:54.280 --> 00:12:56.550 align:start position:0%
another tip and trick you should even
use<00:12:54.520><c> is</c><00:12:54.760><c> you</c><00:12:55.420><c> should</c><00:12:55.600><c> wait</c><00:12:55.780><c> for</c><00:12:55.810><c> detection</c><00:12:56.350><c> to</c>

00:12:56.550 --> 00:12:56.560 align:start position:0%
use is you should wait for detection to
 

00:12:56.560 --> 00:12:59.070 align:start position:0%
use is you should wait for detection to
finish<00:12:56.860><c> before</c><00:12:57.610><c> render</c><00:12:58.450><c> the</c><00:12:58.630><c> face</c><00:12:58.840><c> and</c>

00:12:59.070 --> 00:12:59.080 align:start position:0%
finish before render the face and
 

00:12:59.080 --> 00:13:03.330 align:start position:0%
finish before render the face and
counter<00:12:59.410><c> together</c><00:13:01.680><c> you</c><00:13:02.680><c> can</c><00:13:02.860><c> check</c><00:13:03.100><c> out</c><00:13:03.220><c> our</c>

00:13:03.330 --> 00:13:03.340 align:start position:0%
counter together you can check out our
 

00:13:03.340 --> 00:13:06.480 align:start position:0%
counter together you can check out our
online<00:13:04.230><c> QuickStart</c><00:13:05.230><c> sample</c><00:13:05.470><c> app</c><00:13:05.800><c> on</c><00:13:06.010><c> github</c>

00:13:06.480 --> 00:13:06.490 align:start position:0%
online QuickStart sample app on github
 

00:13:06.490 --> 00:13:09.930 align:start position:0%
online QuickStart sample app on github
for<00:13:06.640><c> more</c><00:13:06.970><c> details</c><00:13:07.680><c> to</c><00:13:08.680><c> illustrate</c><00:13:09.250><c> what</c><00:13:09.910><c> I</c>

00:13:09.930 --> 00:13:09.940 align:start position:0%
for more details to illustrate what I
 

00:13:09.940 --> 00:13:14.100 align:start position:0%
for more details to illustrate what I
mean<00:13:10.270><c> I</c><00:13:10.450><c> will</c><00:13:10.840><c> do</c><00:13:11.140><c> a</c><00:13:11.170><c> live</c><00:13:11.680><c> demo</c><00:13:12.810><c> let's</c><00:13:13.810><c> switch</c>

00:13:14.100 --> 00:13:14.110 align:start position:0%
mean I will do a live demo let's switch
 

00:13:14.110 --> 00:13:17.490 align:start position:0%
mean I will do a live demo let's switch
to<00:13:14.140><c> the</c><00:13:14.410><c> demo</c><00:13:14.680><c> mode</c><00:13:15.690><c> so</c><00:13:16.690><c> for</c><00:13:16.990><c> the</c><00:13:17.050><c> purpose</c><00:13:17.380><c> of</c>

00:13:17.490 --> 00:13:17.500 align:start position:0%
to the demo mode so for the purpose of
 

00:13:17.500 --> 00:13:21.790 align:start position:0%
to the demo mode so for the purpose of
demo<00:13:17.740><c> I'm</c><00:13:18.160><c> using</c><00:13:18.790><c> a</c><00:13:19.200><c> slower</c><00:13:20.200><c> Suite</c><00:13:21.100><c> hi</c><00:13:21.280><c> 3</c>

00:13:21.790 --> 00:13:21.800 align:start position:0%
demo I'm using a slower Suite hi 3
 

00:13:21.800 --> 00:13:24.850 align:start position:0%
demo I'm using a slower Suite hi 3
year-old<00:13:22.089><c> Nexus</c><00:13:23.089><c> 5x</c><00:13:23.600><c> phone</c><00:13:23.899><c> because</c><00:13:24.649><c> using</c>

00:13:24.850 --> 00:13:24.860 align:start position:0%
year-old Nexus 5x phone because using
 

00:13:24.860 --> 00:13:26.920 align:start position:0%
year-old Nexus 5x phone because using
the<00:13:25.040><c> latest</c><00:13:25.220><c> pixel</c><00:13:25.790><c> phone</c><00:13:26.000><c> the</c><00:13:26.570><c> difference</c>

00:13:26.920 --> 00:13:26.930 align:start position:0%
the latest pixel phone the difference
 

00:13:26.930 --> 00:13:30.699 align:start position:0%
the latest pixel phone the difference
are<00:13:27.080><c> not</c><00:13:27.320><c> as</c><00:13:27.560><c> prominent</c><00:13:28.750><c> in</c><00:13:29.750><c> the</c><00:13:29.899><c> first</c><00:13:30.200><c> video</c>

00:13:30.699 --> 00:13:30.709 align:start position:0%
are not as prominent in the first video
 

00:13:30.709 --> 00:13:33.970 align:start position:0%
are not as prominent in the first video
I'm<00:13:31.339><c> going</c><00:13:31.640><c> to</c><00:13:31.700><c> show</c><00:13:31.940><c> you</c><00:13:32.000><c> without</c><00:13:32.600><c> any</c><00:13:32.990><c> proofs</c>

00:13:33.970 --> 00:13:33.980 align:start position:0%
I'm going to show you without any proofs
 

00:13:33.980 --> 00:13:37.870 align:start position:0%
I'm going to show you without any proofs
and<00:13:34.390><c> we</c><00:13:35.390><c> do</c><00:13:35.570><c> not</c><00:13:35.690><c> do</c><00:13:35.899><c> videos</c><00:13:36.410><c> throttling</c><00:13:37.250><c> we</c><00:13:37.760><c> do</c>

00:13:37.870 --> 00:13:37.880 align:start position:0%
and we do not do videos throttling we do
 

00:13:37.880 --> 00:13:40.690 align:start position:0%
and we do not do videos throttling we do
not<00:13:38.060><c> do</c><00:13:38.240><c> any</c><00:13:38.420><c> Lake</c><00:13:39.380><c> drawing</c><00:13:39.740><c> to</c><00:13:40.220><c> make</c><00:13:40.370><c> sure</c><00:13:40.550><c> the</c>

00:13:40.690 --> 00:13:40.700 align:start position:0%
not do any Lake drawing to make sure the
 

00:13:40.700 --> 00:13:43.420 align:start position:0%
not do any Lake drawing to make sure the
contour<00:13:41.089><c> and</c><00:13:41.300><c> the</c><00:13:41.390><c> face</c><00:13:41.600><c> are</c><00:13:41.870><c> together</c><00:13:42.190><c> so</c><00:13:43.190><c> if</c>

00:13:43.420 --> 00:13:43.430 align:start position:0%
contour and the face are together so if
 

00:13:43.430 --> 00:13:47.110 align:start position:0%
contour and the face are together so if
you<00:13:43.550><c> just</c><00:13:43.760><c> call</c><00:13:44.180><c> the</c><00:13:44.420><c> API</c><00:13:45.910><c> without</c><00:13:46.910><c> any</c>

00:13:47.110 --> 00:13:47.120 align:start position:0%
you just call the API without any
 

00:13:47.120 --> 00:13:52.090 align:start position:0%
you just call the API without any
performance<00:13:48.399><c> improvement</c><00:13:49.399><c> you</c><00:13:49.640><c> can</c><00:13:49.820><c> see</c><00:13:51.100><c> the</c>

00:13:52.090 --> 00:13:52.100 align:start position:0%
performance improvement you can see the
 

00:13:52.100 --> 00:13:55.139 align:start position:0%
performance improvement you can see the
counters<00:13:52.640><c> are</c><00:13:52.970><c> not</c><00:13:53.360><c> falling</c><00:13:53.810><c> in</c><00:13:53.990><c> the</c><00:13:54.050><c> face</c><00:13:54.290><c> and</c>

00:13:55.139 --> 00:13:55.149 align:start position:0%
counters are not falling in the face and
 

00:13:55.149 --> 00:13:59.190 align:start position:0%
counters are not falling in the face and
there's<00:13:56.149><c> a</c><00:13:56.240><c> big</c><00:13:56.570><c> gap</c><00:13:56.870><c> between</c><00:13:56.899><c> this</c><00:13:57.829><c> two</c>

00:13:59.190 --> 00:13:59.200 align:start position:0%
there's a big gap between this two
 

00:13:59.200 --> 00:14:02.050 align:start position:0%
there's a big gap between this two
alright<00:14:00.200><c> so</c><00:14:00.829><c> now</c><00:14:01.100><c> I'm</c><00:14:01.250><c> going</c><00:14:01.279><c> to</c><00:14:01.490><c> switch</c><00:14:01.760><c> to</c>

00:14:02.050 --> 00:14:02.060 align:start position:0%
alright so now I'm going to switch to
 

00:14:02.060 --> 00:14:05.910 align:start position:0%
alright so now I'm going to switch to
another<00:14:02.269><c> version</c><00:14:03.130><c> after</c><00:14:04.149><c> applying</c>

00:14:05.910 --> 00:14:05.920 align:start position:0%
another version after applying
 

00:14:05.920 --> 00:14:14.259 align:start position:0%
another version after applying
performance<00:14:06.920><c> tips</c><00:14:10.779><c> in</c><00:14:11.779><c> this</c><00:14:12.579><c> version</c><00:14:13.579><c> it's</c>

00:14:14.259 --> 00:14:14.269 align:start position:0%
performance tips in this version it's
 

00:14:14.269 --> 00:14:17.800 align:start position:0%
performance tips in this version it's
using<00:14:14.570><c> the</c><00:14:14.630><c> exact</c><00:14:15.110><c> same</c><00:14:15.200><c> Nexus</c><00:14:15.980><c> 5x</c><00:14:16.430><c> phone</c><00:14:16.880><c> but</c>

00:14:17.800 --> 00:14:17.810 align:start position:0%
using the exact same Nexus 5x phone but
 

00:14:17.810 --> 00:14:20.530 align:start position:0%
using the exact same Nexus 5x phone but
we<00:14:18.050><c> throttle</c><00:14:18.980><c> the</c><00:14:19.130><c> video</c><00:14:19.459><c> for</c><00:14:19.730><c> incoming</c><00:14:20.329><c> video</c>

00:14:20.530 --> 00:14:20.540 align:start position:0%
we throttle the video for incoming video
 

00:14:20.540 --> 00:14:22.180 align:start position:0%
we throttle the video for incoming video
frame<00:14:20.959><c> when</c><00:14:21.260><c> we're</c><00:14:21.529><c> still</c><00:14:21.800><c> processing</c><00:14:22.010><c> the</c>

00:14:22.180 --> 00:14:22.190 align:start position:0%
frame when we're still processing the
 

00:14:22.190 --> 00:14:25.210 align:start position:0%
frame when we're still processing the
current<00:14:22.610><c> frame</c><00:14:22.940><c> and</c><00:14:23.180><c> also</c><00:14:24.110><c> we</c><00:14:24.350><c> wait</c><00:14:24.829><c> for</c><00:14:25.100><c> the</c>

00:14:25.210 --> 00:14:25.220 align:start position:0%
current frame and also we wait for the
 

00:14:25.220 --> 00:14:27.819 align:start position:0%
current frame and also we wait for the
detection<00:14:25.459><c> of</c><00:14:25.700><c> finish</c><00:14:26.060><c> before</c><00:14:26.720><c> render</c><00:14:27.589><c> pose</c>

00:14:27.819 --> 00:14:27.829 align:start position:0%
detection of finish before render pose
 

00:14:27.829 --> 00:14:31.150 align:start position:0%
detection of finish before render pose
the<00:14:28.070><c> face</c><00:14:28.279><c> and</c><00:14:28.610><c> the</c><00:14:28.910><c> counter</c><00:14:29.329><c> as</c><00:14:29.770><c> you</c><00:14:30.770><c> can</c><00:14:30.920><c> see</c>

00:14:31.150 --> 00:14:31.160 align:start position:0%
the face and the counter as you can see
 

00:14:31.160 --> 00:14:34.000 align:start position:0%
the face and the counter as you can see
now<00:14:31.690><c> the</c><00:14:32.690><c> contours</c><00:14:33.140><c> are</c><00:14:33.320><c> following</c><00:14:33.740><c> in</c><00:14:33.829><c> the</c>

00:14:34.000 --> 00:14:34.010 align:start position:0%
now the contours are following in the
 

00:14:34.010 --> 00:14:36.190 align:start position:0%
now the contours are following in the
face<00:14:34.220><c> all</c><00:14:34.550><c> the</c><00:14:34.970><c> time</c><00:14:35.000><c> they</c><00:14:35.450><c> match</c><00:14:35.660><c> each</c><00:14:35.899><c> other</c>

00:14:36.190 --> 00:14:36.200 align:start position:0%
face all the time they match each other
 

00:14:36.200 --> 00:14:41.410 align:start position:0%
face all the time they match each other
there's<00:14:36.649><c> no</c><00:14:36.709><c> more</c><00:14:36.980><c> gap</c><00:14:39.370><c> for</c><00:14:40.370><c> so</c><00:14:41.120><c> let's</c><00:14:41.270><c> switch</c>

00:14:41.410 --> 00:14:41.420 align:start position:0%
there's no more gap for so let's switch
 

00:14:41.420 --> 00:14:47.730 align:start position:0%
there's no more gap for so let's switch
back<00:14:41.540><c> to</c><00:14:41.750><c> the</c><00:14:41.930><c> slides</c><00:14:43.540><c> thank</c><00:14:44.540><c> you</c>

00:14:47.730 --> 00:14:47.740 align:start position:0%
 
 

00:14:47.740 --> 00:14:51.569 align:start position:0%
 
if<00:14:48.610><c> you're</c><00:14:48.790><c> using</c><00:14:48.970><c> our</c><00:14:49.149><c> custom</c><00:14:49.629><c> auto</c><00:14:49.749><c> API</c><00:14:50.579><c> how</c>

00:14:51.569 --> 00:14:51.579 align:start position:0%
if you're using our custom auto API how
 

00:14:51.579 --> 00:14:54.809 align:start position:0%
if you're using our custom auto API how
to<00:14:51.639><c> include</c><00:14:52.029><c> model</c><00:14:52.589><c> becomes</c><00:14:53.589><c> a</c><00:14:53.829><c> something</c><00:14:54.790><c> you</c>

00:14:54.809 --> 00:14:54.819 align:start position:0%
to include model becomes a something you
 

00:14:54.819 --> 00:14:57.059 align:start position:0%
to include model becomes a something you
should<00:14:55.089><c> consider</c><00:14:55.240><c> there</c><00:14:56.079><c> are</c><00:14:56.110><c> two</c><00:14:56.290><c> ways</c><00:14:56.470><c> you</c>

00:14:57.059 --> 00:14:57.069 align:start position:0%
should consider there are two ways you
 

00:14:57.069 --> 00:14:59.069 align:start position:0%
should consider there are two ways you
can<00:14:57.189><c> either</c><00:14:57.339><c> bundle</c><00:14:57.879><c> the</c><00:14:57.999><c> model</c><00:14:58.629><c> inside</c><00:14:58.899><c> your</c>

00:14:59.069 --> 00:14:59.079 align:start position:0%
can either bundle the model inside your
 

00:14:59.079 --> 00:15:02.699 align:start position:0%
can either bundle the model inside your
app<00:14:59.259><c> or</c><00:14:59.499><c> host</c><00:15:00.369><c> it</c><00:15:00.550><c> on</c><00:15:00.699><c> a</c><00:15:00.759><c> cloud</c><00:15:01.290><c> if</c><00:15:02.290><c> you</c><00:15:02.470><c> bundle</c>

00:15:02.699 --> 00:15:02.709 align:start position:0%
app or host it on a cloud if you bundle
 

00:15:02.709 --> 00:15:05.400 align:start position:0%
app or host it on a cloud if you bundle
your<00:15:02.980><c> model</c><00:15:03.610><c> in</c><00:15:03.699><c> your</c><00:15:03.790><c> app</c><00:15:04.079><c> it's</c><00:15:05.079><c> available</c>

00:15:05.400 --> 00:15:05.410 align:start position:0%
your model in your app it's available
 

00:15:05.410 --> 00:15:08.699 align:start position:0%
your model in your app it's available
immediately<00:15:06.300><c> it</c><00:15:07.300><c> also</c><00:15:07.449><c> does</c><00:15:07.959><c> not</c><00:15:08.170><c> require</c><00:15:08.529><c> any</c>

00:15:08.699 --> 00:15:08.709 align:start position:0%
immediately it also does not require any
 

00:15:08.709 --> 00:15:10.679 align:start position:0%
immediately it also does not require any
model<00:15:09.040><c> downloading</c><00:15:09.550><c> so</c><00:15:09.999><c> it</c><00:15:10.089><c> works</c><00:15:10.300><c> offline</c>

00:15:10.679 --> 00:15:10.689 align:start position:0%
model downloading so it works offline
 

00:15:10.689 --> 00:15:13.859 align:start position:0%
model downloading so it works offline
but<00:15:11.679><c> the</c><00:15:11.800><c> downside</c><00:15:12.040><c> is</c><00:15:12.339><c> you</c><00:15:13.059><c> get</c><00:15:13.240><c> a</c><00:15:13.269><c> bigger</c><00:15:13.600><c> app</c>

00:15:13.859 --> 00:15:13.869 align:start position:0%
but the downside is you get a bigger app
 

00:15:13.869 --> 00:15:16.410 align:start position:0%
but the downside is you get a bigger app
because<00:15:14.379><c> app</c><00:15:14.589><c> contains</c><00:15:15.009><c> the</c><00:15:15.189><c> model</c><00:15:15.550><c> it</c><00:15:16.149><c> may</c>

00:15:16.410 --> 00:15:16.420 align:start position:0%
because app contains the model it may
 

00:15:16.420 --> 00:15:19.530 align:start position:0%
because app contains the model it may
slow<00:15:16.660><c> down</c><00:15:16.689><c> the</c><00:15:17.019><c> app</c><00:15:17.199><c> download</c><00:15:17.649><c> also</c><00:15:18.540><c> you</c>

00:15:19.530 --> 00:15:19.540 align:start position:0%
slow down the app download also you
 

00:15:19.540 --> 00:15:21.569 align:start position:0%
slow down the app download also you
cannot<00:15:19.839><c> change</c><00:15:20.110><c> the</c><00:15:20.319><c> model</c><00:15:20.649><c> without</c><00:15:20.829><c> a</c><00:15:21.100><c> new</c>

00:15:21.569 --> 00:15:21.579 align:start position:0%
cannot change the model without a new
 

00:15:21.579 --> 00:15:25.710 align:start position:0%
cannot change the model without a new
app<00:15:21.879><c> release</c><00:15:23.550><c> on</c><00:15:24.550><c> the</c><00:15:24.759><c> other</c><00:15:24.879><c> hand</c><00:15:25.179><c> if</c><00:15:25.480><c> you</c>

00:15:25.710 --> 00:15:25.720 align:start position:0%
app release on the other hand if you
 

00:15:25.720 --> 00:15:28.350 align:start position:0%
app release on the other hand if you
have<00:15:25.899><c> some</c><00:15:26.079><c> model</c><00:15:26.889><c> in</c><00:15:26.980><c> the</c><00:15:27.069><c> cloud</c><00:15:27.279><c> we</c><00:15:28.029><c> provide</c>

00:15:28.350 --> 00:15:28.360 align:start position:0%
have some model in the cloud we provide
 

00:15:28.360 --> 00:15:31.109 align:start position:0%
have some model in the cloud we provide
all<00:15:28.540><c> the</c><00:15:28.629><c> hosting</c><00:15:29.050><c> support</c><00:15:29.800><c> for</c><00:15:30.189><c> you</c><00:15:30.339><c> you</c><00:15:30.939><c> get</c>

00:15:31.109 --> 00:15:31.119 align:start position:0%
all the hosting support for you you get
 

00:15:31.119 --> 00:15:33.540 align:start position:0%
all the hosting support for you you get
a<00:15:31.179><c> smaller</c><00:15:31.600><c> app</c><00:15:31.899><c> size</c><00:15:32.199><c> because</c><00:15:32.889><c> after</c><00:15:33.189><c> itself</c>

00:15:33.540 --> 00:15:33.550 align:start position:0%
a smaller app size because after itself
 

00:15:33.550 --> 00:15:35.309 align:start position:0%
a smaller app size because after itself
does<00:15:33.879><c> not</c><00:15:33.910><c> contain</c><00:15:34.179><c> the</c><00:15:34.449><c> model</c><00:15:34.779><c> which</c>

00:15:35.309 --> 00:15:35.319 align:start position:0%
does not contain the model which
 

00:15:35.319 --> 00:15:38.460 align:start position:0%
does not contain the model which
translate<00:15:35.860><c> into</c><00:15:36.009><c> a</c><00:15:36.189><c> faster</c><00:15:36.670><c> installation</c><00:15:37.470><c> you</c>

00:15:38.460 --> 00:15:38.470 align:start position:0%
translate into a faster installation you
 

00:15:38.470 --> 00:15:40.499 align:start position:0%
translate into a faster installation you
also<00:15:38.649><c> can</c><00:15:39.249><c> choose</c><00:15:39.490><c> the</c><00:15:39.670><c> download</c><00:15:39.819><c> model</c><00:15:40.389><c> only</c>

00:15:40.499 --> 00:15:40.509 align:start position:0%
also can choose the download model only
 

00:15:40.509 --> 00:15:43.919 align:start position:0%
also can choose the download model only
if<00:15:40.809><c> it's</c><00:15:40.990><c> needed</c><00:15:41.670><c> the</c><00:15:42.670><c> model</c><00:15:43.269><c> updates</c><00:15:43.720><c> can</c>

00:15:43.919 --> 00:15:43.929 align:start position:0%
if it's needed the model updates can
 

00:15:43.929 --> 00:15:46.679 align:start position:0%
if it's needed the model updates can
come<00:15:44.230><c> over</c><00:15:44.470><c> the</c><00:15:44.709><c> air</c><00:15:44.829><c> into</c><00:15:45.819><c> the</c><00:15:45.910><c> app</c><00:15:46.059><c> without</c>

00:15:46.679 --> 00:15:46.689 align:start position:0%
come over the air into the app without
 

00:15:46.689 --> 00:15:49.499 align:start position:0%
come over the air into the app without
any<00:15:46.899><c> new</c><00:15:47.199><c> app</c><00:15:47.439><c> release</c><00:15:47.879><c> you</c><00:15:48.879><c> can</c><00:15:48.939><c> also</c><00:15:49.209><c> use</c>

00:15:49.499 --> 00:15:49.509 align:start position:0%
any new app release you can also use
 

00:15:49.509 --> 00:15:52.049 align:start position:0%
any new app release you can also use
remote<00:15:50.079><c> config</c><00:15:50.499><c> and</c><00:15:50.679><c> a</c><00:15:51.069><c> be</c><00:15:51.279><c> testing</c><00:15:51.730><c> framework</c>

00:15:52.049 --> 00:15:52.059 align:start position:0%
remote config and a be testing framework
 

00:15:52.059 --> 00:15:54.299 align:start position:0%
remote config and a be testing framework
provided<00:15:52.389><c> by</c><00:15:52.509><c> the</c><00:15:52.569><c> firebase</c><00:15:53.050><c> to</c><00:15:53.740><c> do</c><00:15:53.889><c> phase</c>

00:15:54.299 --> 00:15:54.309 align:start position:0%
provided by the firebase to do phase
 

00:15:54.309 --> 00:15:57.689 align:start position:0%
provided by the firebase to do phase
rollout<00:15:54.819><c> as</c><00:15:55.029><c> much</c><00:15:55.300><c> control</c><00:15:55.839><c> to</c><00:15:56.079><c> pilots</c><00:15:56.699><c> the</c>

00:15:57.689 --> 00:15:57.699 align:start position:0%
rollout as much control to pilots the
 

00:15:57.699 --> 00:16:00.660 align:start position:0%
rollout as much control to pilots the
drawback<00:15:58.179><c> of</c><00:15:58.389><c> hosting</c><00:15:59.019><c> model</c><00:15:59.350><c> on</c><00:15:59.679><c> the</c><00:16:00.429><c> cloud</c>

00:16:00.660 --> 00:16:00.670 align:start position:0%
drawback of hosting model on the cloud
 

00:16:00.670 --> 00:16:04.199 align:start position:0%
drawback of hosting model on the cloud
is<00:16:01.259><c> obviously</c><00:16:02.259><c> it</c><00:16:02.559><c> means</c><00:16:02.740><c> connectivity</c><00:16:03.459><c> when</c>

00:16:04.199 --> 00:16:04.209 align:start position:0%
is obviously it means connectivity when
 

00:16:04.209 --> 00:16:05.669 align:start position:0%
is obviously it means connectivity when
there's<00:16:04.420><c> no</c><00:16:04.660><c> connectivity</c><00:16:05.050><c> you</c><00:16:05.319><c> don't</c><00:16:05.559><c> get</c>

00:16:05.669 --> 00:16:05.679 align:start position:0%
there's no connectivity you don't get
 

00:16:05.679 --> 00:16:07.169 align:start position:0%
there's no connectivity you don't get
that<00:16:06.040><c> you</c><00:16:06.279><c> don't</c><00:16:06.399><c> you</c><00:16:06.550><c> cannot</c><00:16:06.759><c> download</c><00:16:06.970><c> the</c>

00:16:07.169 --> 00:16:07.179 align:start position:0%
that you don't you cannot download the
 

00:16:07.179 --> 00:16:09.299 align:start position:0%
that you don't you cannot download the
model<00:16:07.509><c> also</c><00:16:08.379><c> the</c><00:16:08.620><c> model</c><00:16:08.769><c> will</c><00:16:08.980><c> not</c><00:16:09.160><c> be</c>

00:16:09.299 --> 00:16:09.309 align:start position:0%
model also the model will not be
 

00:16:09.309 --> 00:16:12.059 align:start position:0%
model also the model will not be
available<00:16:09.790><c> and</c><00:16:09.939><c> here</c><00:16:10.120><c> they're</c><00:16:10.269><c> downloaded</c><00:16:11.069><c> so</c>

00:16:12.059 --> 00:16:12.069 align:start position:0%
available and here they're downloaded so
 

00:16:12.069 --> 00:16:14.249 align:start position:0%
available and here they're downloaded so
a<00:16:12.339><c> third</c><00:16:12.850><c> option</c><00:16:13.120><c> is</c><00:16:13.480><c> using</c><00:16:13.809><c> a</c><00:16:13.870><c> hybrid</c>

00:16:14.249 --> 00:16:14.259 align:start position:0%
a third option is using a hybrid
 

00:16:14.259 --> 00:16:17.100 align:start position:0%
a third option is using a hybrid
approach<00:16:14.319><c> you</c><00:16:15.309><c> can</c><00:16:15.490><c> pound</c><00:16:16.029><c> on</c><00:16:16.209><c> the</c><00:16:16.300><c> model</c><00:16:16.629><c> the</c>

00:16:17.100 --> 00:16:17.110 align:start position:0%
approach you can pound on the model the
 

00:16:17.110 --> 00:16:18.929 align:start position:0%
approach you can pound on the model the
initial<00:16:17.470><c> version</c><00:16:17.679><c> of</c><00:16:17.740><c> model</c><00:16:18.009><c> in</c><00:16:18.069><c> the</c><00:16:18.160><c> app</c><00:16:18.309><c> so</c>

00:16:18.929 --> 00:16:18.939 align:start position:0%
initial version of model in the app so
 

00:16:18.939 --> 00:16:21.299 align:start position:0%
initial version of model in the app so
make<00:16:19.149><c> it</c><00:16:19.290><c> usable</c><00:16:20.290><c> right</c><00:16:20.499><c> away</c><00:16:20.800><c> after</c>

00:16:21.299 --> 00:16:21.309 align:start position:0%
make it usable right away after
 

00:16:21.309 --> 00:16:23.460 align:start position:0%
make it usable right away after
installation<00:16:21.550><c> now</c><00:16:22.480><c> you</c><00:16:22.540><c> can</c><00:16:22.839><c> receive</c><00:16:23.139><c> model</c>

00:16:23.460 --> 00:16:23.470 align:start position:0%
installation now you can receive model
 

00:16:23.470 --> 00:16:28.710 align:start position:0%
installation now you can receive model
updates<00:16:23.769><c> over</c><00:16:24.009><c> the</c><00:16:24.220><c> air</c><00:16:24.370><c> from</c><00:16:24.850><c> the</c><00:16:25.029><c> cloud</c><00:16:27.720><c> if</c>

00:16:28.710 --> 00:16:28.720 align:start position:0%
updates over the air from the cloud if
 

00:16:28.720 --> 00:16:31.439 align:start position:0%
updates over the air from the cloud if
you<00:16:28.870><c> are</c><00:16:28.929><c> using</c><00:16:29.110><c> our</c><00:16:29.319><c> base</c><00:16:29.559><c> API</c><00:16:30.009><c> it's</c><00:16:30.449><c> provided</c>

00:16:31.439 --> 00:16:31.449 align:start position:0%
you are using our base API it's provided
 

00:16:31.449 --> 00:16:33.600 align:start position:0%
you are using our base API it's provided
in<00:16:31.540><c> two</c><00:16:31.689><c> different</c><00:16:31.839><c> forms</c><00:16:32.350><c> for</c><00:16:33.249><c> the</c><00:16:33.339><c> latter</c><00:16:33.519><c> of</c>

00:16:33.600 --> 00:16:33.610 align:start position:0%
in two different forms for the latter of
 

00:16:33.610 --> 00:16:34.439 align:start position:0%
in two different forms for the latter of
better<00:16:33.910><c> terms</c>

00:16:34.439 --> 00:16:34.449 align:start position:0%
better terms
 

00:16:34.449 --> 00:16:38.030 align:start position:0%
better terms
I<00:16:34.509><c> call</c><00:16:34.929><c> it</c><00:16:35.069><c> thickened</c><00:16:36.069><c> SDK</c><00:16:36.730><c> and</c><00:16:36.939><c> a</c><00:16:37.059><c> thin</c><00:16:37.299><c> SDK</c>

00:16:38.030 --> 00:16:38.040 align:start position:0%
I call it thickened SDK and a thin SDK
 

00:16:38.040 --> 00:16:41.100 align:start position:0%
I call it thickened SDK and a thin SDK
in<00:16:39.040><c> Athey</c><00:16:39.399><c> SDK</c><00:16:40.209><c> the</c><00:16:40.420><c> models</c><00:16:40.899><c> actually</c>

00:16:41.100 --> 00:16:41.110 align:start position:0%
in Athey SDK the models actually
 

00:16:41.110 --> 00:16:42.689 align:start position:0%
in Athey SDK the models actually
provided<00:16:41.649><c> by</c><00:16:41.709><c> the</c><00:16:41.769><c> Google</c><00:16:42.129><c> Play</c><00:16:42.279><c> service</c>

00:16:42.689 --> 00:16:42.699 align:start position:0%
provided by the Google Play service
 

00:16:42.699 --> 00:16:44.309 align:start position:0%
provided by the Google Play service
which<00:16:43.029><c> means</c><00:16:43.269><c> they</c><00:16:43.420><c> are</c><00:16:43.480><c> shared</c><00:16:43.720><c> across</c><00:16:43.869><c> all</c>

00:16:44.309 --> 00:16:44.319 align:start position:0%
which means they are shared across all
 

00:16:44.319 --> 00:16:46.289 align:start position:0%
which means they are shared across all
apps<00:16:44.529><c> the</c><00:16:44.860><c> apps</c><00:16:45.009><c> itself</c><00:16:45.459><c> does</c><00:16:45.819><c> not</c><00:16:45.850><c> have</c><00:16:46.149><c> to</c>

00:16:46.289 --> 00:16:46.299 align:start position:0%
apps the apps itself does not have to
 

00:16:46.299 --> 00:16:49.799 align:start position:0%
apps the apps itself does not have to
contain<00:16:46.839><c> the</c><00:16:46.990><c> model</c><00:16:47.290><c> and</c><00:16:48.299><c> which</c><00:16:49.299><c> will</c><00:16:49.779><c> make</c>

00:16:49.799 --> 00:16:49.809 align:start position:0%
contain the model and which will make
 

00:16:49.809 --> 00:16:52.859 align:start position:0%
contain the model and which will make
your<00:16:50.110><c> app</c><00:16:50.319><c> smaller</c><00:16:50.910><c> text</c><00:16:51.910><c> recognition</c><00:16:52.360><c> and</c>

00:16:52.859 --> 00:16:52.869 align:start position:0%
your app smaller text recognition and
 

00:16:52.869 --> 00:16:55.289 align:start position:0%
your app smaller text recognition and
the<00:16:53.019><c> barcode</c><00:16:53.379><c> scanning</c><00:16:53.709><c> api's</c><00:16:54.279><c> are</c><00:16:54.519><c> provided</c>

00:16:55.289 --> 00:16:55.299 align:start position:0%
the barcode scanning api's are provided
 

00:16:55.299 --> 00:16:59.069 align:start position:0%
the barcode scanning api's are provided
through<00:16:55.629><c> the</c><00:16:55.839><c> thing</c><00:16:56.529><c> sdk</c><00:16:57.569><c> the</c><00:16:58.569><c> second</c><00:16:58.870><c> type</c><00:16:59.049><c> is</c>

00:16:59.069 --> 00:16:59.079 align:start position:0%
through the thing sdk the second type is
 

00:16:59.079 --> 00:17:01.350 align:start position:0%
through the thing sdk the second type is
called<00:16:59.230><c> thick</c><00:16:59.949><c> SDKs</c><00:17:00.549><c> the</c>

00:17:01.350 --> 00:17:01.360 align:start position:0%
called thick SDKs the
 

00:17:01.360 --> 00:17:04.829 align:start position:0%
called thick SDKs the
are<00:17:01.870><c> bound</c><00:17:02.200><c> on</c><00:17:02.380><c> inside</c><00:17:02.740><c> SDK</c><00:17:03.279><c> each</c><00:17:04.089><c> app</c><00:17:04.420><c> will</c>

00:17:04.829 --> 00:17:04.839 align:start position:0%
are bound on inside SDK each app will
 

00:17:04.839 --> 00:17:07.169 align:start position:0%
are bound on inside SDK each app will
have<00:17:05.020><c> their</c><00:17:05.230><c> own</c><00:17:05.410><c> copy</c><00:17:05.709><c> of</c><00:17:05.860><c> the</c><00:17:06.100><c> model</c><00:17:06.220><c> which</c>

00:17:07.169 --> 00:17:07.179 align:start position:0%
have their own copy of the model which
 

00:17:07.179 --> 00:17:09.750 align:start position:0%
have their own copy of the model which
will<00:17:07.630><c> increase</c><00:17:07.959><c> the</c><00:17:08.079><c> app</c><00:17:08.319><c> size</c><00:17:08.760><c> face</c>

00:17:09.750 --> 00:17:09.760 align:start position:0%
will increase the app size face
 

00:17:09.760 --> 00:17:11.699 align:start position:0%
will increase the app size face
detection<00:17:10.240><c> and</c><00:17:10.510><c> image</c><00:17:10.900><c> labeling</c><00:17:11.500><c> are</c>

00:17:11.699 --> 00:17:11.709 align:start position:0%
detection and image labeling are
 

00:17:11.709 --> 00:17:15.780 align:start position:0%
detection and image labeling are
supported<00:17:12.429><c> through</c><00:17:12.459><c> the</c><00:17:12.760><c> thickest</c><00:17:13.689><c> case</c><00:17:14.790><c> to</c>

00:17:15.780 --> 00:17:15.790 align:start position:0%
supported through the thickest case to
 

00:17:15.790 --> 00:17:18.480 align:start position:0%
supported through the thickest case to
use<00:17:15.970><c> this</c><00:17:16.179><c> two</c><00:17:16.630><c> type</c><00:17:16.870><c> of</c><00:17:17.020><c> SDK</c><00:17:17.530><c> and</c><00:17:17.829><c> use</c><00:17:18.220><c> verse</c>

00:17:18.480 --> 00:17:18.490 align:start position:0%
use this two type of SDK and use verse
 

00:17:18.490 --> 00:17:21.449 align:start position:0%
use this two type of SDK and use verse
API<00:17:18.970><c> as</c><00:17:19.030><c> provide</c><00:17:19.329><c> by</c><00:17:19.510><c> the</c><00:17:19.569><c> ml</c><00:17:20.170><c> kit</c><00:17:20.410><c> you</c><00:17:21.130><c> need</c><00:17:21.339><c> to</c>

00:17:21.449 --> 00:17:21.459 align:start position:0%
API as provide by the ml kit you need to
 

00:17:21.459 --> 00:17:24.059 align:start position:0%
API as provide by the ml kit you need to
include<00:17:21.819><c> the</c><00:17:22.179><c> appropriate</c><00:17:22.380><c> MLK</c><00:17:23.380><c> dependencies</c>

00:17:24.059 --> 00:17:24.069 align:start position:0%
include the appropriate MLK dependencies
 

00:17:24.069 --> 00:17:26.090 align:start position:0%
include the appropriate MLK dependencies
in<00:17:24.280><c> your</c><00:17:24.429><c> app</c><00:17:24.579><c> level</c><00:17:25.000><c> build</c><00:17:25.300><c> up</c><00:17:25.449><c> Gradle</c><00:17:25.809><c> file</c>

00:17:26.090 --> 00:17:26.100 align:start position:0%
in your app level build up Gradle file
 

00:17:26.100 --> 00:17:29.040 align:start position:0%
in your app level build up Gradle file
inside<00:17:27.100><c> the</c><00:17:27.160><c> file</c><00:17:27.550><c> inside</c><00:17:28.000><c> this</c><00:17:28.300><c> dependency</c>

00:17:29.040 --> 00:17:29.050 align:start position:0%
inside the file inside this dependency
 

00:17:29.050 --> 00:17:31.830 align:start position:0%
inside the file inside this dependency
section<00:17:29.230><c> if</c><00:17:30.100><c> you</c><00:17:30.309><c> want</c><00:17:30.340><c> to</c><00:17:30.640><c> use</c><00:17:30.760><c> the</c><00:17:31.000><c> API</c>

00:17:31.830 --> 00:17:31.840 align:start position:0%
section if you want to use the API
 

00:17:31.840 --> 00:17:34.080 align:start position:0%
section if you want to use the API
support<00:17:32.230><c> through</c><00:17:32.380><c> the</c><00:17:32.500><c> thing</c><00:17:32.710><c> SDK</c><00:17:33.220><c> you</c><00:17:33.910><c> should</c>

00:17:34.080 --> 00:17:34.090 align:start position:0%
support through the thing SDK you should
 

00:17:34.090 --> 00:17:35.490 align:start position:0%
support through the thing SDK you should
add<00:17:34.270><c> the</c><00:17:34.450><c> dependency</c><00:17:35.020><c> called</c>

00:17:35.490 --> 00:17:35.500 align:start position:0%
add the dependency called
 

00:17:35.500 --> 00:17:41.340 align:start position:0%
add the dependency called
firebase<00:17:36.130><c> -</c><00:17:36.700><c> mm</c><00:17:37.179><c> -</c><00:17:37.690><c> vision</c><00:17:38.200><c> an</c><00:17:39.570><c> in</c><00:17:40.570><c> addition</c><00:17:41.110><c> if</c>

00:17:41.340 --> 00:17:41.350 align:start position:0%
firebase - mm - vision an in addition if
 

00:17:41.350 --> 00:17:43.560 align:start position:0%
firebase - mm - vision an in addition if
you<00:17:41.620><c> want</c><00:17:41.830><c> to</c><00:17:41.950><c> use</c><00:17:42.100><c> thick</c><00:17:42.610><c> sdk</c><00:17:43.179><c> you</c><00:17:43.390><c> should</c>

00:17:43.560 --> 00:17:43.570 align:start position:0%
you want to use thick sdk you should
 

00:17:43.570 --> 00:17:45.600 align:start position:0%
you want to use thick sdk you should
still<00:17:43.870><c> keep</c><00:17:44.080><c> this</c><00:17:44.260><c> line</c><00:17:44.559><c> because</c><00:17:45.070><c> auto</c><00:17:45.280><c> vision</c>

00:17:45.600 --> 00:17:45.610 align:start position:0%
still keep this line because auto vision
 

00:17:45.610 --> 00:17:47.760 align:start position:0%
still keep this line because auto vision
API<00:17:45.760><c> entry</c><00:17:46.510><c> points</c><00:17:46.840><c> are</c><00:17:46.960><c> coming</c><00:17:47.200><c> from</c><00:17:47.530><c> this</c>

00:17:47.760 --> 00:17:47.770 align:start position:0%
API entry points are coming from this
 

00:17:47.770 --> 00:17:51.030 align:start position:0%
API entry points are coming from this
thing<00:17:48.100><c> SDK</c><00:17:48.520><c> dependency</c><00:17:49.500><c> but</c><00:17:50.500><c> you</c><00:17:50.620><c> also</c><00:17:50.800><c> need</c>

00:17:51.030 --> 00:17:51.040 align:start position:0%
thing SDK dependency but you also need
 

00:17:51.040 --> 00:17:53.370 align:start position:0%
thing SDK dependency but you also need
to<00:17:51.100><c> add</c><00:17:51.250><c> additional</c><00:17:51.429><c> dependencies</c><00:17:52.380><c> for</c>

00:17:53.370 --> 00:17:53.380 align:start position:0%
to add additional dependencies for
 

00:17:53.380 --> 00:17:55.460 align:start position:0%
to add additional dependencies for
example<00:17:53.740><c> if</c><00:17:53.830><c> you</c><00:17:53.920><c> want</c><00:17:54.070><c> to</c><00:17:54.130><c> use</c><00:17:54.280><c> image</c>

00:17:55.460 --> 00:17:55.470 align:start position:0%
example if you want to use image
 

00:17:55.470 --> 00:17:59.130 align:start position:0%
example if you want to use image
recognition<00:17:56.910><c> image</c><00:17:57.910><c> detection</c><00:17:58.570><c> then</c><00:17:59.020><c> you</c>

00:17:59.130 --> 00:17:59.140 align:start position:0%
recognition image detection then you
 

00:17:59.140 --> 00:18:02.400 align:start position:0%
recognition image detection then you
need<00:17:59.290><c> to</c><00:17:59.380><c> add</c><00:17:59.530><c> the</c><00:18:00.400><c> FIR</c><00:18:00.640><c> base</c><00:18:00.880><c> ml</c><00:18:01.270><c> vision</c><00:18:01.750><c> face</c>

00:18:02.400 --> 00:18:02.410 align:start position:0%
need to add the FIR base ml vision face
 

00:18:02.410 --> 00:18:05.220 align:start position:0%
need to add the FIR base ml vision face
model<00:18:02.950><c> dependency</c><00:18:03.850><c> because</c><00:18:04.600><c> it's</c><00:18:04.840><c> a</c><00:18:04.960><c> thick</c>

00:18:05.220 --> 00:18:05.230 align:start position:0%
model dependency because it's a thick
 

00:18:05.230 --> 00:18:06.290 align:start position:0%
model dependency because it's a thick
SDK

00:18:06.290 --> 00:18:06.300 align:start position:0%
SDK
 

00:18:06.300 --> 00:18:10.169 align:start position:0%
SDK
similarly<00:18:07.300><c> for</c><00:18:08.290><c> image</c><00:18:08.530><c> labeling</c><00:18:09.040><c> if</c><00:18:09.370><c> used</c><00:18:09.910><c> in</c>

00:18:10.169 --> 00:18:10.179 align:start position:0%
similarly for image labeling if used in
 

00:18:10.179 --> 00:18:12.030 align:start position:0%
similarly for image labeling if used in
that<00:18:10.330><c> feature</c><00:18:10.570><c> they</c><00:18:11.050><c> need</c><00:18:11.230><c> to</c><00:18:11.320><c> add</c><00:18:11.470><c> image</c>

00:18:12.030 --> 00:18:12.040 align:start position:0%
that feature they need to add image
 

00:18:12.040 --> 00:18:17.669 align:start position:0%
that feature they need to add image
label<00:18:12.460><c> model</c><00:18:12.820><c> dependency</c><00:18:16.200><c> next</c><00:18:17.200><c> I</c><00:18:17.320><c> will</c><00:18:17.440><c> talk</c>

00:18:17.669 --> 00:18:17.679 align:start position:0%
label model dependency next I will talk
 

00:18:17.679 --> 00:18:19.590 align:start position:0%
label model dependency next I will talk
about<00:18:17.950><c> a</c><00:18:18.160><c> few</c><00:18:18.340><c> new</c><00:18:18.400><c> areas</c><00:18:18.970><c> we</c><00:18:19.270><c> are</c><00:18:19.300><c> currently</c>

00:18:19.590 --> 00:18:19.600 align:start position:0%
about a few new areas we are currently
 

00:18:19.600 --> 00:18:23.850 align:start position:0%
about a few new areas we are currently
working<00:18:19.780><c> on</c><00:18:20.050><c> a</c><00:18:21.210><c> few</c><00:18:22.210><c> new</c><00:18:22.419><c> MLK</c><00:18:23.110><c> features</c><00:18:23.559><c> are</c>

00:18:23.850 --> 00:18:23.860 align:start position:0%
working on a few new MLK features are
 

00:18:23.860 --> 00:18:25.980 align:start position:0%
working on a few new MLK features are
either<00:18:24.070><c> under</c><00:18:24.490><c> development</c><00:18:24.970><c> or</c><00:18:25.210><c> in</c><00:18:25.660><c> early</c>

00:18:25.980 --> 00:18:25.990 align:start position:0%
either under development or in early
 

00:18:25.990 --> 00:18:29.780 align:start position:0%
either under development or in early
testing<00:18:26.679><c> phase</c><00:18:27.000><c> we</c><00:18:28.000><c> expanded</c><00:18:28.750><c> beyond</c><00:18:29.169><c> vision</c>

00:18:29.780 --> 00:18:29.790 align:start position:0%
testing phase we expanded beyond vision
 

00:18:29.790 --> 00:18:31.650 align:start position:0%
testing phase we expanded beyond vision
starting<00:18:30.790><c> natural</c><00:18:31.330><c> language</c><00:18:31.630><c> processing</c>

00:18:31.650 --> 00:18:31.660 align:start position:0%
starting natural language processing
 

00:18:31.660 --> 00:18:35.130 align:start position:0%
starting natural language processing
with<00:18:32.470><c> smart</c><00:18:32.830><c> reply</c><00:18:33.360><c> smart</c><00:18:34.360><c> applies</c><00:18:34.720><c> a</c><00:18:34.750><c> feature</c>

00:18:35.130 --> 00:18:35.140 align:start position:0%
with smart reply smart applies a feature
 

00:18:35.140 --> 00:18:37.470 align:start position:0%
with smart reply smart applies a feature
which<00:18:35.620><c> can</c><00:18:36.220><c> enable</c><00:18:36.700><c> you</c><00:18:37.000><c> to</c><00:18:37.030><c> produce</c>

00:18:37.470 --> 00:18:37.480 align:start position:0%
which can enable you to produce
 

00:18:37.480 --> 00:18:39.750 align:start position:0%
which can enable you to produce
meaningful<00:18:38.290><c> response</c><00:18:38.710><c> based</c><00:18:39.070><c> on</c><00:18:39.220><c> the</c><00:18:39.280><c> current</c>

00:18:39.750 --> 00:18:39.760 align:start position:0%
meaningful response based on the current
 

00:18:39.760 --> 00:18:42.270 align:start position:0%
meaningful response based on the current
conversation<00:18:40.419><c> context</c><00:18:41.040><c> we</c><00:18:42.040><c> are</c><00:18:42.100><c> also</c>

00:18:42.270 --> 00:18:42.280 align:start position:0%
conversation context we are also
 

00:18:42.280 --> 00:18:44.010 align:start position:0%
conversation context we are also
planning<00:18:42.610><c> to</c><00:18:42.820><c> go</c><00:18:43.030><c> into</c><00:18:43.330><c> other</c><00:18:43.480><c> areas</c><00:18:43.780><c> like</c>

00:18:44.010 --> 00:18:44.020 align:start position:0%
planning to go into other areas like
 

00:18:44.020 --> 00:18:47.790 align:start position:0%
planning to go into other areas like
speech<00:18:45.300><c> at</c><00:18:46.300><c> the</c><00:18:46.480><c> same</c><00:18:46.660><c> time</c><00:18:46.929><c> we</c><00:18:47.260><c> will</c><00:18:47.380><c> continue</c>

00:18:47.790 --> 00:18:47.800 align:start position:0%
speech at the same time we will continue
 

00:18:47.800 --> 00:18:50.159 align:start position:0%
speech at the same time we will continue
to<00:18:47.950><c> enhance</c><00:18:48.400><c> performance</c><00:18:48.850><c> and</c><00:18:49.330><c> accuracy</c><00:18:49.929><c> of</c>

00:18:50.159 --> 00:18:50.169 align:start position:0%
to enhance performance and accuracy of
 

00:18:50.169 --> 00:18:54.930 align:start position:0%
to enhance performance and accuracy of
base<00:18:50.559><c> api's</c><00:18:52.080><c> we</c><00:18:53.080><c> launched</c><00:18:53.590><c> model</c><00:18:54.130><c> compression</c>

00:18:54.930 --> 00:18:54.940 align:start position:0%
base api's we launched model compression
 

00:18:54.940 --> 00:18:56.820 align:start position:0%
base api's we launched model compression
and<00:18:55.090><c> conversion</c><00:18:55.690><c> service</c><00:18:56.110><c> to</c><00:18:56.410><c> our</c><00:18:56.500><c> alpha</c>

00:18:56.820 --> 00:18:56.830 align:start position:0%
and conversion service to our alpha
 

00:18:56.830 --> 00:19:00.659 align:start position:0%
and conversion service to our alpha
users<00:18:57.400><c> which</c><00:18:57.850><c> helped</c><00:18:58.240><c> them</c><00:18:58.510><c> to</c><00:18:59.400><c> convert</c><00:19:00.400><c> and</c>

00:19:00.659 --> 00:19:00.669 align:start position:0%
users which helped them to convert and
 

00:19:00.669 --> 00:19:02.610 align:start position:0%
users which helped them to convert and
compress<00:19:01.090><c> large</c><00:19:01.419><c> model</c><00:19:01.870><c> into</c><00:19:02.080><c> a</c><00:19:02.140><c> smaller</c><00:19:02.470><c> and</c>

00:19:02.610 --> 00:19:02.620 align:start position:0%
compress large model into a smaller and
 

00:19:02.620 --> 00:19:06.180 align:start position:0%
compress large model into a smaller and
faster<00:19:03.090><c> versions</c><00:19:04.090><c> for</c><00:19:04.360><c> mobile</c><00:19:04.690><c> usage</c><00:19:05.190><c> the</c>

00:19:06.180 --> 00:19:06.190 align:start position:0%
faster versions for mobile usage the
 

00:19:06.190 --> 00:19:08.840 align:start position:0%
faster versions for mobile usage the
conversion<00:19:06.790><c> service</c><00:19:07.210><c> contains</c><00:19:08.050><c> in</c><00:19:08.230><c> alpha</c>

00:19:08.840 --> 00:19:08.850 align:start position:0%
conversion service contains in alpha
 

00:19:08.850 --> 00:19:12.900 align:start position:0%
conversion service contains in alpha
uses<00:19:09.850><c> pruning</c><00:19:10.679><c> quantization</c><00:19:11.910><c> installation</c>

00:19:12.900 --> 00:19:12.910 align:start position:0%
uses pruning quantization installation
 

00:19:12.910 --> 00:19:14.880 align:start position:0%
uses pruning quantization installation
as<00:19:13.059><c> well</c><00:19:13.120><c> as</c><00:19:13.540><c> the</c><00:19:13.720><c> transfer</c><00:19:14.050><c> learning</c>

00:19:14.880 --> 00:19:14.890 align:start position:0%
as well as the transfer learning
 

00:19:14.890 --> 00:19:17.700 align:start position:0%
as well as the transfer learning
to<00:19:15.160><c> retrain</c><00:19:15.730><c> the</c><00:19:15.940><c> large</c><00:19:16.150><c> models</c><00:19:16.720><c> make</c><00:19:17.500><c> them</c>

00:19:17.700 --> 00:19:17.710 align:start position:0%
to retrain the large models make them
 

00:19:17.710 --> 00:19:19.980 align:start position:0%
to retrain the large models make them
smaller<00:19:18.130><c> and</c><00:19:18.310><c> faster</c><00:19:18.670><c> without</c><00:19:19.240><c> sacrificing</c>

00:19:19.980 --> 00:19:19.990 align:start position:0%
smaller and faster without sacrificing
 

00:19:19.990 --> 00:19:23.250 align:start position:0%
smaller and faster without sacrificing
too<00:19:20.110><c> much</c><00:19:20.290><c> accuracy</c><00:19:21.630><c> fish</c><00:19:22.630><c> brain</c><00:19:22.930><c> is</c><00:19:23.200><c> a</c>

00:19:23.250 --> 00:19:23.260 align:start position:0%
too much accuracy fish brain is a
 

00:19:23.260 --> 00:19:26.550 align:start position:0%
too much accuracy fish brain is a
community-based<00:19:23.800><c> app</c><00:19:24.340><c> it</c><00:19:25.120><c> enables</c><00:19:25.780><c> user</c><00:19:26.080><c> to</c>

00:19:26.550 --> 00:19:26.560 align:start position:0%
community-based app it enables user to
 

00:19:26.560 --> 00:19:28.470 align:start position:0%
community-based app it enables user to
share<00:19:26.890><c> the</c><00:19:27.130><c> photos</c><00:19:27.460><c> of</c><00:19:27.610><c> their</c><00:19:27.790><c> cache</c><00:19:28.060><c> and</c>

00:19:28.470 --> 00:19:28.480 align:start position:0%
share the photos of their cache and
 

00:19:28.480 --> 00:19:31.560 align:start position:0%
share the photos of their cache and
within<00:19:29.260><c> their</c><00:19:29.530><c> social</c><00:19:29.980><c> networks</c><00:19:30.540><c> with</c><00:19:31.540><c> a</c>

00:19:31.560 --> 00:19:31.570 align:start position:0%
within their social networks with a
 

00:19:31.570 --> 00:19:33.660 align:start position:0%
within their social networks with a
machine<00:19:31.990><c> learning</c><00:19:32.110><c> model</c><00:19:32.350><c> it</c><00:19:33.280><c> can</c><00:19:33.520><c> identify</c>

00:19:33.660 --> 00:19:33.670 align:start position:0%
machine learning model it can identify
 

00:19:33.670 --> 00:19:37.080 align:start position:0%
machine learning model it can identify
any<00:19:34.180><c> fish</c><00:19:34.570><c> with</c><00:19:35.170><c> just</c><00:19:35.470><c> a</c><00:19:35.560><c> photo</c><00:19:35.970><c> when</c><00:19:36.970><c> they</c>

00:19:37.080 --> 00:19:37.090 align:start position:0%
any fish with just a photo when they
 

00:19:37.090 --> 00:19:40.080 align:start position:0%
any fish with just a photo when they
first<00:19:37.660><c> came</c><00:19:37.870><c> to</c><00:19:38.080><c> us</c><00:19:38.140><c> their</c><00:19:38.740><c> model</c><00:19:39.130><c> is</c><00:19:39.670><c> more</c>

00:19:40.080 --> 00:19:40.090 align:start position:0%
first came to us their model is more
 

00:19:40.090 --> 00:19:43.980 align:start position:0%
first came to us their model is more
than<00:19:40.240><c> 480</c><00:19:41.110><c> Meg</c><00:19:42.100><c> bytes</c><00:19:42.570><c> by</c><00:19:43.570><c> using</c><00:19:43.780><c> our</c>

00:19:43.980 --> 00:19:43.990 align:start position:0%
than 480 Meg bytes by using our
 

00:19:43.990 --> 00:19:46.380 align:start position:0%
than 480 Meg bytes by using our
conversion<00:19:44.650><c> and</c><00:19:44.800><c> compression</c><00:19:45.370><c> service</c><00:19:45.790><c> we</c>

00:19:46.380 --> 00:19:46.390 align:start position:0%
conversion and compression service we
 

00:19:46.390 --> 00:19:49.050 align:start position:0%
conversion and compression service we
are<00:19:46.480><c> able</c><00:19:46.690><c> to</c><00:19:46.750><c> trim</c><00:19:47.320><c> down</c><00:19:47.500><c> the</c><00:19:47.560><c> model</c><00:19:48.310><c> to</c><00:19:48.730><c> ender</c>

00:19:49.050 --> 00:19:49.060 align:start position:0%
are able to trim down the model to ender
 

00:19:49.060 --> 00:19:52.650 align:start position:0%
are able to trim down the model to ender
one<00:19:49.270><c> Mac</c><00:19:49.510><c> as</c><00:19:49.780><c> you</c><00:19:50.620><c> can</c><00:19:50.830><c> see</c><00:19:51.070><c> the</c><00:19:51.850><c> not</c><00:19:52.390><c> only</c>

00:19:52.650 --> 00:19:52.660 align:start position:0%
one Mac as you can see the not only
 

00:19:52.660 --> 00:19:54.960 align:start position:0%
one Mac as you can see the not only
maintain<00:19:53.080><c> same</c><00:19:53.320><c> level</c><00:19:54.010><c> accuracy</c><00:19:54.280><c> that</c>

00:19:54.960 --> 00:19:54.970 align:start position:0%
maintain same level accuracy that
 

00:19:54.970 --> 00:19:58.320 align:start position:0%
maintain same level accuracy that
actually<00:19:55.270><c> is</c><00:19:55.390><c> actually</c><00:19:55.780><c> slightly</c><00:19:56.020><c> better</c><00:19:57.330><c> if</c>

00:19:58.320 --> 00:19:58.330 align:start position:0%
actually is actually slightly better if
 

00:19:58.330 --> 00:20:00.210 align:start position:0%
actually is actually slightly better if
you<00:19:58.540><c> are</c><00:19:58.570><c> interested</c><00:19:59.050><c> in</c><00:19:59.200><c> trying</c><00:19:59.590><c> out</c><00:19:59.890><c> our</c>

00:20:00.210 --> 00:20:00.220 align:start position:0%
you are interested in trying out our
 

00:20:00.220 --> 00:20:02.910 align:start position:0%
you are interested in trying out our
model<00:20:00.880><c> compression</c><00:20:01.330><c> service</c><00:20:01.750><c> please</c><00:20:02.560><c> join</c>

00:20:02.910 --> 00:20:02.920 align:start position:0%
model compression service please join
 

00:20:02.920 --> 00:20:06.090 align:start position:0%
model compression service please join
our<00:20:03.100><c> alpha</c><00:20:03.970><c> program</c><00:20:04.360><c> by</c><00:20:04.690><c> sign</c><00:20:05.020><c> up</c><00:20:05.200><c> today</c><00:20:05.350><c> at</c><00:20:05.740><c> G</c>

00:20:06.090 --> 00:20:06.100 align:start position:0%
our alpha program by sign up today at G
 

00:20:06.100 --> 00:20:11.640 align:start position:0%
our alpha program by sign up today at G
da<00:20:06.160><c> Co</c><00:20:06.580><c> /</c><00:20:07.180><c> firebase</c><00:20:07.660><c> /</c><00:20:08.290><c> sign</c><00:20:08.590><c> up</c><00:20:10.200><c> no</c><00:20:11.200><c> matter</c><00:20:11.380><c> you</c>

00:20:11.640 --> 00:20:11.650 align:start position:0%
da Co / firebase / sign up no matter you
 

00:20:11.650 --> 00:20:12.980 align:start position:0%
da Co / firebase / sign up no matter you
are<00:20:11.740><c> new</c><00:20:11.950><c> to</c><00:20:11.980><c> machine</c><00:20:12.460><c> learning</c><00:20:12.820><c> or</c>

00:20:12.980 --> 00:20:12.990 align:start position:0%
are new to machine learning or
 

00:20:12.990 --> 00:20:16.500 align:start position:0%
are new to machine learning or
experienced<00:20:13.990><c> AI</c><00:20:14.320><c> expert</c><00:20:15.070><c> I</c><00:20:15.340><c> hope</c><00:20:15.940><c> you</c><00:20:16.120><c> enjoyed</c>

00:20:16.500 --> 00:20:16.510 align:start position:0%
experienced AI expert I hope you enjoyed
 

00:20:16.510 --> 00:20:18.090 align:start position:0%
experienced AI expert I hope you enjoyed
the<00:20:16.630><c> talk</c><00:20:16.810><c> today</c><00:20:16.990><c> and</c><00:20:17.410><c> they</c><00:20:17.590><c> can</c><00:20:17.740><c> take</c><00:20:17.890><c> home</c>

00:20:18.090 --> 00:20:18.100 align:start position:0%
the talk today and they can take home
 

00:20:18.100 --> 00:20:21.060 align:start position:0%
the talk today and they can take home
some<00:20:18.340><c> tips</c><00:20:18.640><c> and</c><00:20:18.970><c> I</c><00:20:19.780><c> can't</c><00:20:20.050><c> wait</c><00:20:20.260><c> to</c><00:20:20.440><c> see</c><00:20:20.710><c> what</c>

00:20:21.060 --> 00:20:21.070 align:start position:0%
some tips and I can't wait to see what
 

00:20:21.070 --> 00:20:23.850 align:start position:0%
some tips and I can't wait to see what
you<00:20:21.190><c> will</c><00:20:21.280><c> build</c><00:20:21.490><c> with</c><00:20:21.730><c> ml</c><00:20:22.090><c> kit</c><00:20:22.530><c> if</c><00:20:23.530><c> you</c><00:20:23.590><c> have</c>

00:20:23.850 --> 00:20:23.860 align:start position:0%
you will build with ml kit if you have
 

00:20:23.860 --> 00:20:25.680 align:start position:0%
you will build with ml kit if you have
any<00:20:24.070><c> question</c><00:20:24.460><c> are</c><00:20:24.550><c> we</c><00:20:24.790><c> outside</c><00:20:25.000><c> in</c><00:20:25.420><c> the</c><00:20:25.510><c> Asha</c>

00:20:25.680 --> 00:20:25.690 align:start position:0%
any question are we outside in the Asha
 

00:20:25.690 --> 00:20:28.110 align:start position:0%
any question are we outside in the Asha
and<00:20:26.050><c> relaunch</c><00:20:26.770><c> and</c><00:20:27.070><c> we</c><00:20:27.340><c> also</c><00:20:27.490><c> have</c><00:20:27.760><c> office</c>

00:20:28.110 --> 00:20:28.120 align:start position:0%
and relaunch and we also have office
 

00:20:28.120 --> 00:20:30.060 align:start position:0%
and relaunch and we also have office
hour<00:20:28.300><c> tomorrow</c><00:20:28.570><c> thank</c><00:20:29.500><c> you</c><00:20:29.590><c> very</c><00:20:29.710><c> much</c><00:20:29.920><c> for</c>

00:20:30.060 --> 00:20:30.070 align:start position:0%
hour tomorrow thank you very much for
 

00:20:30.070 --> 00:20:30.970 align:start position:0%
hour tomorrow thank you very much for
listening

00:20:30.970 --> 00:20:30.980 align:start position:0%
listening
 

00:20:30.980 --> 00:20:47.049 align:start position:0%
listening
[Music]

