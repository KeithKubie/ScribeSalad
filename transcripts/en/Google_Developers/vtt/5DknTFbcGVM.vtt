WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.772
[MUSIC PLAYING]

00:00:05.262 --> 00:00:06.720
MARTIN WICKE: Thank
you for coming.

00:00:06.720 --> 00:00:07.860
I'm Martin Wicke.

00:00:07.860 --> 00:00:11.100
I'll speak about effective
TensorFlow for non-experts.

00:00:11.100 --> 00:00:13.114
I'll later introduce
Francois, who will take

00:00:13.114 --> 00:00:14.280
the second half of the talk.

00:00:16.920 --> 00:00:18.852
So TensorFlow, why?

00:00:24.760 --> 00:00:26.599
So I have a son.

00:00:26.599 --> 00:00:28.390
You'll see him later
in the talk, actually.

00:00:28.390 --> 00:00:32.009
And when I used to explain to
him how image search works,

00:00:32.009 --> 00:00:34.590
I would have to say something
like, oh, he has a computer.

00:00:34.590 --> 00:00:36.270
It looks at the
metadata and then looks

00:00:36.270 --> 00:00:37.740
where the images are.

00:00:37.740 --> 00:00:42.540
And now, when I explain how
this works, I can just say,

00:00:42.540 --> 00:00:44.889
well, the computer
looks at the images.

00:00:44.889 --> 00:00:46.680
And if you search for,
say, cherry blossom,

00:00:46.680 --> 00:00:48.810
it looks at the images,
all of them in the world.

00:00:48.810 --> 00:00:51.360
And whenever it sees one that
has cherry blossoms in it,

00:00:51.360 --> 00:00:53.086
it returns it.

00:00:53.086 --> 00:00:54.210
That's a much better story.

00:00:54.210 --> 00:00:58.470
And you've seen a lot of this
at this particular event.

00:00:58.470 --> 00:01:00.910
AI is now going
to be everywhere,

00:01:00.910 --> 00:01:03.240
and machine learning
is everywhere.

00:01:03.240 --> 00:01:08.430
And it generates these
products that were

00:01:08.430 --> 00:01:12.020
impossible to imagine before.

00:01:12.020 --> 00:01:14.910
And what makes these
products work in reality

00:01:14.910 --> 00:01:18.210
is, for us, at
least, TensorFlow.

00:01:18.210 --> 00:01:20.070
And this enables us
to make these apps

00:01:20.070 --> 00:01:22.170
and make these products
that use machine learning.

00:01:22.170 --> 00:01:24.840
And once you've written
one of these models, one

00:01:24.840 --> 00:01:27.120
of these machine learning
systems in TensorFlow,

00:01:27.120 --> 00:01:29.370
you can deploy it
anywhere in mobile.

00:01:29.370 --> 00:01:33.810
TensorFlow is truly what
enables apps that tell

00:01:33.810 --> 00:01:38.240
hot dogs from not hot dogs.

00:01:38.240 --> 00:01:41.600
So why don't we see that more?

00:01:41.600 --> 00:01:46.460
Why are hotdog, not hotdog
apps so cutting edge?

00:01:46.460 --> 00:01:49.900
The main reason is
complexity, and complexities

00:01:49.900 --> 00:01:50.750
in various shapes.

00:01:50.750 --> 00:01:55.490
So first of all, complexity
is computational complexity.

00:01:55.490 --> 00:01:58.650
Computational complexity
used to be a big thing.

00:01:58.650 --> 00:02:01.130
And now, with cloud and
with all the availability

00:02:01.130 --> 00:02:02.557
of data centers
that you can rent,

00:02:02.557 --> 00:02:04.390
that's really not much
of an excuse anymore.

00:02:04.390 --> 00:02:05.931
So we've kind of
solved this problem,

00:02:05.931 --> 00:02:08.739
assuming your code can
run in a data center.

00:02:08.739 --> 00:02:10.280
But you also have
to contend with you

00:02:10.280 --> 00:02:13.970
have to make your code,
your models, your apps,

00:02:13.970 --> 00:02:15.590
work on all these
different platforms.

00:02:15.590 --> 00:02:17.340
In order to train them
in the data center,

00:02:17.340 --> 00:02:19.860
you need to work
on CPUs, on GPUs.

00:02:19.860 --> 00:02:21.530
You probably have
heard by now we

00:02:21.530 --> 00:02:23.230
have this thing called a TPU.

00:02:23.230 --> 00:02:26.715
It should work there too
because that's going to be fast.

00:02:26.715 --> 00:02:29.090
And of course, if you want to
deploy it once you're done,

00:02:29.090 --> 00:02:31.160
it needs to work
on a mobile device.

00:02:31.160 --> 00:02:34.002
If you're into IoT
or embedded systems,

00:02:34.002 --> 00:02:35.960
it has to work there too,
say, on the Raspberry

00:02:35.960 --> 00:02:38.490
Pi or something like that.

00:02:38.490 --> 00:02:42.440
So making that happen is hard.

00:02:42.440 --> 00:02:44.180
And finally, machine
learning itself

00:02:44.180 --> 00:02:45.950
is actually fairly complex.

00:02:48.690 --> 00:02:51.140
So that's why we
have TensorFlow.

00:02:51.140 --> 00:02:57.315
And TensorFlow gives you
distribution out of the box so

00:02:57.315 --> 00:03:01.490
that you can run it in the
cloud if you need to do that.

00:03:01.490 --> 00:03:05.150
It works on all of the
hardware you need to work on.

00:03:05.150 --> 00:03:07.610
And it's fast and it's flexible.

00:03:07.610 --> 00:03:09.290
And what I'm going
to tell you today

00:03:09.290 --> 00:03:12.430
is that it's also super
easy to get started.

00:03:12.430 --> 00:03:14.300
And that's why we're here.

00:03:14.300 --> 00:03:18.500
So TensorFlow takes all the
details of a distributed system

00:03:18.500 --> 00:03:21.320
[INAUDIBLE] hardware and
just hides them from you,

00:03:21.320 --> 00:03:22.160
takes care of them.

00:03:22.160 --> 00:03:23.993
You don't have to know
about it necessarily.

00:03:23.993 --> 00:03:28.650
It's nice if you do, but if you
don't, that's not a problem.

00:03:28.650 --> 00:03:30.560
What you mostly see
is the front end.

00:03:30.560 --> 00:03:34.940
And what I'm going to talk about
today is the Python front end.

00:03:34.940 --> 00:03:38.150
The generic thing that
people used to say, oh, this

00:03:38.150 --> 00:03:40.640
is TensorFlow, it's
pretty low level.

00:03:40.640 --> 00:03:44.120
So you're thinking about like
multiplying matrices, adding

00:03:44.120 --> 00:03:46.770
vectors together,
that kind of thing.

00:03:46.770 --> 00:03:49.730
What we built on top
of that is libraries

00:03:49.730 --> 00:03:52.850
that help you do more
complex things easier.

00:03:52.850 --> 00:03:55.490
We built a library of layers
to help you build models,

00:03:55.490 --> 00:03:58.280
and Francois is going
to talk more about that.

00:03:58.280 --> 00:04:00.812
We built training
infrastructure that

00:04:00.812 --> 00:04:03.020
helps you actually train a
model and evaluate a model

00:04:03.020 --> 00:04:07.490
and put it in production.

00:04:07.490 --> 00:04:09.470
And again, this you
can do with Keras

00:04:09.470 --> 00:04:10.720
or you can do with estimators.

00:04:10.720 --> 00:04:12.650
And Francois is going
to talk about Keras.

00:04:12.650 --> 00:04:15.434
And finally, we built
models in a box.

00:04:15.434 --> 00:04:17.600
And those are really full,
complete machine learning

00:04:17.600 --> 00:04:19.640
algorithms such as
run, and all you

00:04:19.640 --> 00:04:22.010
have to do is
instantiate one and go.

00:04:22.010 --> 00:04:25.350
That's mostly what I'm
going to talk about today.

00:04:25.350 --> 00:04:29.090
So usually when
you talk about, oh,

00:04:29.090 --> 00:04:32.120
my first model in TensorFlow,
it's usually something simple,

00:04:32.120 --> 00:04:35.750
like let's fit a line to a
bunch of points or something

00:04:35.750 --> 00:04:36.630
like that.

00:04:36.630 --> 00:04:39.020
But nobody is actually
interested in fitting a line

00:04:39.020 --> 00:04:41.570
to a bunch of
points, distributed.

00:04:41.570 --> 00:04:44.010
It doesn't really happen
all that much in reality.

00:04:44.010 --> 00:04:45.805
So we're not going to do that.

00:04:45.805 --> 00:04:47.180
I'm going to show
you instead how

00:04:47.180 --> 00:04:51.290
to handle a variety of features,
and then train and evaluate

00:04:51.290 --> 00:04:55.880
different types of models,
possibly distributed.

00:04:55.880 --> 00:05:02.600
And we do that on a data set
of cars because we have that.

00:05:02.600 --> 00:05:04.280
I have uploaded all
the code I'm going

00:05:04.280 --> 00:05:10.880
to show you to this address,
which has both an O and a 0,

00:05:10.880 --> 00:05:12.770
so be a little bit careful.

00:05:12.770 --> 00:05:17.270
And what I've done there,
it'll work with TensorFlow 1.2.

00:05:17.270 --> 00:05:20.420
And I am not sure whether it's
been announced previously,

00:05:20.420 --> 00:05:24.290
but there is now TensorFlow 1.2,
the first release candidate.

00:05:24.290 --> 00:05:27.210
So my code will work with
that and nothing earlier.

00:05:27.210 --> 00:05:29.720
So you have to watch out.

00:05:29.720 --> 00:05:31.670
All right, so the
first model today

00:05:31.670 --> 00:05:34.160
will be about predicting
the price of a car

00:05:34.160 --> 00:05:37.640
from a bunch of features
about the car, information

00:05:37.640 --> 00:05:39.240
about the car.

00:05:39.240 --> 00:05:41.880
So without anything
more, let's just do code.

00:05:41.880 --> 00:05:46.160
The rest of the talk's
going to code, mostly.

00:05:46.160 --> 00:05:47.180
This is it.

00:05:47.180 --> 00:05:50.234
This is my model
definition in TensorFlow.

00:05:50.234 --> 00:05:51.650
I'm exaggerating
only a little bit

00:05:51.650 --> 00:05:54.840
because this only takes into
account three different things.

00:05:54.840 --> 00:05:58.220
So first, here we
defined the input.

00:05:58.220 --> 00:06:03.590
And I'm defining three different
what we call feature columns.

00:06:03.590 --> 00:06:07.460
I'm telling the model that it
should expect an input that

00:06:07.460 --> 00:06:11.900
is a categorical
feature, a string, that's

00:06:11.900 --> 00:06:14.810
called make in the input.

00:06:14.810 --> 00:06:18.770
And I'm going to transform
this into something

00:06:18.770 --> 00:06:21.110
that's usable by my
machine learning algorithm

00:06:21.110 --> 00:06:22.790
by hashing it.

00:06:22.790 --> 00:06:25.370
So I declare it this way,
declarative way of telling you

00:06:25.370 --> 00:06:27.525
what to do with a
feature for the inputs.

00:06:27.525 --> 00:06:29.150
The next thing is
I'm going to say, oh,

00:06:29.150 --> 00:06:30.860
there's something
called horsepower,

00:06:30.860 --> 00:06:32.450
and that's just a number.

00:06:32.450 --> 00:06:33.860
So I call a numeric column.

00:06:33.860 --> 00:06:35.276
And then there is
something called

00:06:35.276 --> 00:06:39.380
cylinders, num of
cylinders in the input.

00:06:39.380 --> 00:06:42.620
And that's also a string,
but it has very few values.

00:06:42.620 --> 00:06:44.890
So I'm just going to
give you all the values

00:06:44.890 --> 00:06:46.570
directly here in the code.

00:06:46.570 --> 00:06:49.600
So in this data set,
it actually is the case

00:06:49.600 --> 00:06:52.620
that num of cylinders is
encoded as the words "two,"

00:06:52.620 --> 00:06:57.705
"three," "four," "six,"
and "eight," I think.

00:06:57.705 --> 00:06:58.330
So that's it's.

00:06:58.330 --> 00:07:00.590
So there's probably
many more of these.

00:07:00.590 --> 00:07:02.360
But in principle,
that's what you do.

00:07:02.360 --> 00:07:05.552
And you say, OK, this is
what my input looks like.

00:07:05.552 --> 00:07:08.010
And then we specify what kind
of machine learning algorithm

00:07:08.010 --> 00:07:09.490
we want to apply to this.

00:07:09.490 --> 00:07:11.080
And in my case here,
I'm going to use

00:07:11.080 --> 00:07:15.380
first a linear aggressor, which
is kind of the simplest way

00:07:15.380 --> 00:07:17.650
to learn something.

00:07:17.650 --> 00:07:21.220
And all I have to do
is tell him, hey, look,

00:07:21.220 --> 00:07:23.860
you're going to use
these input features

00:07:23.860 --> 00:07:25.100
that I've just declared.

00:07:25.100 --> 00:07:27.420
That's it, and then I'm done.

00:07:27.420 --> 00:07:31.982
Now, I still have to
give it some input data.

00:07:31.982 --> 00:07:33.940
And TensorFlow has
off-the-shelf input pipeline

00:07:33.940 --> 00:07:37.100
for most formats,
or for many formats.

00:07:37.100 --> 00:07:39.170
And particularly,
here in this example,

00:07:39.170 --> 00:07:40.570
I'm using input from pandas.

00:07:40.570 --> 00:07:42.890
So I don't know
who knows pandas.

00:07:42.890 --> 00:07:44.220
It's a Python library.

00:07:44.220 --> 00:07:48.080
It can read a bunch of
stuff, process data.

00:07:48.080 --> 00:07:50.570
It's nice.

00:07:50.570 --> 00:07:54.790
So I'm going to read input
from a pandas data frame.

00:07:54.790 --> 00:07:56.950
And really what
I'm telling it here

00:07:56.950 --> 00:08:00.670
is I want to use
the batches of 64.

00:08:00.670 --> 00:08:02.350
So each iteration
of the algorithm

00:08:02.350 --> 00:08:04.590
will use 64 input data pieces.

00:08:04.590 --> 00:08:07.090
I'm going to shuffle the input,
which is always a good thing

00:08:07.090 --> 00:08:08.790
to do when you're training.

00:08:08.790 --> 00:08:10.270
Please always shuffle the input.

00:08:10.270 --> 00:08:14.252
And num_epochs=None means cycle
through the data indefinitely.

00:08:14.252 --> 00:08:16.210
If you're done with the
data, just do it again.

00:08:18.810 --> 00:08:25.130
And then I can say, OK, train me
my thing for 10,000 steps, say.

00:08:25.130 --> 00:08:28.250
And what happens then
is that TensorFlow

00:08:28.250 --> 00:08:30.402
goes off and trains my thing.

00:08:30.402 --> 00:08:32.360
This is what the log
output looks like, and not

00:08:32.360 --> 00:08:34.309
actually any interesting
information for it.

00:08:34.309 --> 00:08:38.450
What's more interesting is that
TensorFlow will also integrate

00:08:38.450 --> 00:08:40.062
with other tools that we have.

00:08:40.062 --> 00:08:42.020
In particular, it will
integrate with something

00:08:42.020 --> 00:08:43.840
called TensorBoard.

00:08:43.840 --> 00:08:46.160
TensorBoard is this
wonderful front end

00:08:46.160 --> 00:08:52.070
that the training
system writes data for,

00:08:52.070 --> 00:08:54.410
and then you can visualize
it and you can look into it.

00:08:54.410 --> 00:08:56.990
And one of the things that you
can see and what I show here

00:08:56.990 --> 00:08:59.180
is what's called the loss curve.

00:08:59.180 --> 00:09:01.580
Loss curve is kind of
the most important thing

00:09:01.580 --> 00:09:04.752
to look at if you're
trying to train a model.

00:09:04.752 --> 00:09:06.710
And what do you see here
is that our loss, that

00:09:06.710 --> 00:09:10.640
is, kind of the error
that the model makes

00:09:10.640 --> 00:09:13.980
when looking at data,
is decreasing over time.

00:09:13.980 --> 00:09:16.790
And that means it's learning
something, plain and simple.

00:09:16.790 --> 00:09:18.800
So good, that's good.

00:09:18.800 --> 00:09:20.570
The model is learning
something, great.

00:09:22.934 --> 00:09:24.600
The next thing I can
do with TensorBoard

00:09:24.600 --> 00:09:26.767
is I can actually look at
the model that was created

00:09:26.767 --> 00:09:28.724
and look at the lower
levels of the model, look

00:09:28.724 --> 00:09:29.980
at what we call the graph.

00:09:29.980 --> 00:09:31.970
TensorFlow works by
generating a graph,

00:09:31.970 --> 00:09:35.000
and then this graph is shipped
to all of the distributed

00:09:35.000 --> 00:09:38.477
workers that it has,
and it's executed there.

00:09:38.477 --> 00:09:40.310
You don't have to worry
about this too much,

00:09:40.310 --> 00:09:43.566
but it's awfully useful to
be able to inspect this graph

00:09:43.566 --> 00:09:45.690
when you're doing debugging
or something like that.

00:09:45.690 --> 00:09:48.740
So here is the graph
that was generated

00:09:48.740 --> 00:09:52.520
by the model declaration
that I showed earlier.

00:09:52.520 --> 00:09:55.750
And I've highlighted
in red here the part

00:09:55.750 --> 00:09:56.750
that's the actual model.

00:09:56.750 --> 00:09:58.041
That's the actual linear model.

00:09:58.041 --> 00:10:00.320
And I can look inside of it.

00:10:00.320 --> 00:10:06.110
And you can see that there are
these slightly yellow boxes.

00:10:06.110 --> 00:10:11.210
And those are the input
processing computations

00:10:11.210 --> 00:10:14.690
that happen in this model.

00:10:14.690 --> 00:10:16.950
So creating all of this
is taken care of you

00:10:16.950 --> 00:10:19.020
by the infrastructure,
but it's really useful

00:10:19.020 --> 00:10:21.270
to be able to look at it if
you're debugging something

00:10:21.270 --> 00:10:24.520
or if you just want
to know what happens.

00:10:24.520 --> 00:10:27.340
OK, so what's going on?

00:10:27.340 --> 00:10:30.820
The linear regressor I defined
is what we call an estimator.

00:10:30.820 --> 00:10:33.760
We inherited that "estimator"
word from [INAUDIBLE].

00:10:33.760 --> 00:10:36.430
And it's kind of this
very, very similar concept.

00:10:36.430 --> 00:10:38.050
It supports all the
basic operations

00:10:38.050 --> 00:10:39.880
that you need for an ML model.

00:10:39.880 --> 00:10:41.290
You can train it.

00:10:41.290 --> 00:10:43.734
You can evaluate it,
usually on separate data.

00:10:43.734 --> 00:10:45.400
If you take away
anything from this talk

00:10:45.400 --> 00:10:47.316
is that you should always
evaluate your models

00:10:47.316 --> 00:10:50.170
on separate data
while you're training

00:10:50.170 --> 00:10:54.400
or during your training.

00:10:54.400 --> 00:10:56.650
You can query the
model for predictions

00:10:56.650 --> 00:10:57.940
once you've trained it.

00:10:57.940 --> 00:10:59.680
And then this is fancy.

00:10:59.680 --> 00:11:02.440
You can export what
we call a saved model

00:11:02.440 --> 00:11:05.290
and give it to
TensorFlow Serving.

00:11:05.290 --> 00:11:07.330
There's a talk about
TensorFlow Serving tomorrow

00:11:07.330 --> 00:11:09.704
in the amphitheater at 1:30,
and you should all go to it.

00:11:12.430 --> 00:11:15.100
So these methods all hide
a lot of tricky details

00:11:15.100 --> 00:11:18.560
that you don't have to worry
about and that are just done.

00:11:18.560 --> 00:11:21.882
You can just call them, and
you can be reasonably certain

00:11:21.882 --> 00:11:22.840
that it actually works.

00:11:25.380 --> 00:11:27.990
We also defined an
input function earlier,

00:11:27.990 --> 00:11:30.270
and that basically
reads from data files

00:11:30.270 --> 00:11:33.051
and feeds data in an appropriate
format into the estimator

00:11:33.051 --> 00:11:33.550
itself.

00:11:36.970 --> 00:11:39.430
There's a trick here.

00:11:39.430 --> 00:11:41.770
The estimator actually
saves its state

00:11:41.770 --> 00:11:43.360
to what's called a checkpoint.

00:11:43.360 --> 00:11:45.880
The checkpoint contains
all of the variables

00:11:45.880 --> 00:11:47.710
that the model contains.

00:11:47.710 --> 00:11:51.220
And every time we call
one of these functions,

00:11:51.220 --> 00:11:53.130
it'll synchronize
with the checkpoint.

00:11:53.130 --> 00:11:55.379
And this is very important
for the distributed setting

00:11:55.379 --> 00:11:58.030
where you have several
machines and they all

00:11:58.030 --> 00:11:59.500
do their own thing.

00:11:59.500 --> 00:12:01.210
But they have to
synchronize, and they

00:12:01.210 --> 00:12:03.940
synchronize when
something restarts

00:12:03.940 --> 00:12:05.380
or when something breaks.

00:12:05.380 --> 00:12:07.840
They synchronize via checkpoint.

00:12:07.840 --> 00:12:12.520
The checkpoint is also what we
use to export the save model.

00:12:12.520 --> 00:12:14.120
OK, so it's great.

00:12:14.120 --> 00:12:18.230
So I've shown you how to train a
linear model with pandas input.

00:12:18.230 --> 00:12:20.360
But what if you want
something else, just anything

00:12:20.360 --> 00:12:21.190
else, really?

00:12:21.190 --> 00:12:24.290
Well, so all of these components
are obviously swappable.

00:12:24.290 --> 00:12:25.665
So for instance,
the pandas input

00:12:25.665 --> 00:12:27.664
function you can swap for
other input functions.

00:12:27.664 --> 00:12:29.810
And we have several
that are just there.

00:12:29.810 --> 00:12:31.910
It's also pretty easy
to write your own.

00:12:31.910 --> 00:12:33.320
So you can read from numpy.

00:12:33.320 --> 00:12:36.650
You can read from
any Python generator.

00:12:36.650 --> 00:12:40.959
Anything you could spit out
of a generator, you can use.

00:12:40.959 --> 00:12:42.500
So this makes it
very, very flexible.

00:12:42.500 --> 00:12:43.850
And you can write your
own input function too.

00:12:43.850 --> 00:12:44.720
It's not that hard.

00:12:47.240 --> 00:12:49.190
Also, the models
that we have are not

00:12:49.190 --> 00:12:50.760
limited to just linear models.

00:12:50.760 --> 00:12:53.210
So we have linear
regressor classifier.

00:12:53.210 --> 00:12:55.900
We have a deep neural
network, which is basically

00:12:55.900 --> 00:12:58.550
a straightforward
neural network,

00:12:58.550 --> 00:13:00.639
basic feedforward
neural network.

00:13:00.639 --> 00:13:02.180
And then we also
have estimators that

00:13:02.180 --> 00:13:09.140
do random forest, KMeans,
support vector machines,

00:13:09.140 --> 00:13:10.350
you name it.

00:13:10.350 --> 00:13:13.760
So all of this is
available directly for use.

00:13:13.760 --> 00:13:16.932
So you don't have to
implement it yourself.

00:13:16.932 --> 00:13:18.390
Let's say we want
to swap this out.

00:13:18.390 --> 00:13:21.050
So first of all, we have to
obviously change the name

00:13:21.050 --> 00:13:22.800
of the class that we're using.

00:13:22.800 --> 00:13:28.850
And then we'll also have to
adapt the inputs to something

00:13:28.850 --> 00:13:31.580
that this new model can use.

00:13:31.580 --> 00:13:34.610
So in this case,
a DNN model can't

00:13:34.610 --> 00:13:38.600
use these categorical
features directly.

00:13:38.600 --> 00:13:39.930
We have to do something to it.

00:13:39.930 --> 00:13:42.470
And the two things that you can
do to a categorical feature,

00:13:42.470 --> 00:13:45.110
typically, to make it work
with a deep neural network

00:13:45.110 --> 00:13:48.710
is you either embed
it or you transform it

00:13:48.710 --> 00:13:52.880
to what's called a
one-hot or an indicator.

00:13:52.880 --> 00:13:54.921
So we do this by
simply saying, hey,

00:13:54.921 --> 00:13:56.420
out of a make, make
me an embedding,

00:13:56.420 --> 00:13:58.910
and out of the cylinders,
make it an indicator column

00:13:58.910 --> 00:14:01.880
because there's not
so many values there.

00:14:01.880 --> 00:14:03.620
Usually this is fairly
complicated stuff,

00:14:03.620 --> 00:14:05.480
and you have to
write a lot of code.

00:14:05.480 --> 00:14:06.279
But this is it.

00:14:06.279 --> 00:14:07.820
All you have to do
is declare, hey, I

00:14:07.820 --> 00:14:10.820
want an embedding for
this, and you're done.

00:14:10.820 --> 00:14:12.825
Then also, most of these
more complicated models

00:14:12.825 --> 00:14:13.700
have hyperparameters.

00:14:13.700 --> 00:14:16.670
And in this case, the
DNN, basically we tell it,

00:14:16.670 --> 00:14:19.070
hey, make me a
three-layer neural network

00:14:19.070 --> 00:14:21.029
with layer sizes 50, 30, and 10.

00:14:21.029 --> 00:14:23.570
And that's all really you need
to-- this is a very high level

00:14:23.570 --> 00:14:26.780
interface.

00:14:26.780 --> 00:14:30.720
For other models that can
be more complicated or less,

00:14:30.720 --> 00:14:33.430
depending.

00:14:33.430 --> 00:14:38.030
And if none of that's
worked for you,

00:14:38.030 --> 00:14:42.290
you can still take advantage
of the training loops

00:14:42.290 --> 00:14:44.060
and all of the
infrastructure that

00:14:44.060 --> 00:14:48.290
is in the estimator itself,
and you can completely swap out

00:14:48.290 --> 00:14:50.160
the model and write your own.

00:14:50.160 --> 00:14:53.000
And the way you do this is we
have this estimator base class,

00:14:53.000 --> 00:14:56.870
and you can put in what's
called a model function.

00:14:56.870 --> 00:14:58.580
And this allows you
maximum flexibility.

00:14:58.580 --> 00:15:01.130
The model function
takes the inputs,

00:15:01.130 --> 00:15:05.390
and it produces tensors that
contain the thing that you have

00:15:05.390 --> 00:15:07.220
to do for training,
the thing that you

00:15:07.220 --> 00:15:09.130
have to do for evaluation.

00:15:09.130 --> 00:15:11.090
It returns the predictions.

00:15:11.090 --> 00:15:14.619
And then it will also produce
a save model if you need one.

00:15:14.619 --> 00:15:16.160
So you can write
all of this yourself

00:15:16.160 --> 00:15:19.760
if you really want to if none
of the preexisting models

00:15:19.760 --> 00:15:21.476
fit for your use case.

00:15:21.476 --> 00:15:22.850
And you can use
any kind of-- you

00:15:22.850 --> 00:15:25.225
can use regular TensorFlow to
define this model function,

00:15:25.225 --> 00:15:26.370
or you can use Keras.

00:15:26.370 --> 00:15:30.500
And Francois will say a
little bit about that.

00:15:30.500 --> 00:15:32.530
OK, so the exciting
thing about TensorFlow

00:15:32.530 --> 00:15:35.240
is actually the fact
that it runs not only

00:15:35.240 --> 00:15:40.350
in a single machine, but
distributed in a data center.

00:15:40.350 --> 00:15:46.340
So to make this work,
we have a utility

00:15:46.340 --> 00:15:51.920
that uses several workers
and basically trains

00:15:51.920 --> 00:15:55.130
the model on all of
these workers at once.

00:15:55.130 --> 00:15:59.300
We call the a
distributed training run,

00:15:59.300 --> 00:16:03.110
like a single run of training
a model, an experiment.

00:16:03.110 --> 00:16:05.000
And to make one
of those, we first

00:16:05.000 --> 00:16:07.370
make an estimator, as
you've seen before.

00:16:07.370 --> 00:16:09.830
And then we add the input
function and the estimator

00:16:09.830 --> 00:16:14.010
together and make an experiment.

00:16:14.010 --> 00:16:16.450
The name "experiment" comes
from hyperparameter tuning.

00:16:16.450 --> 00:16:17.950
And I don't know
how many of you are

00:16:17.950 --> 00:16:19.050
familiar with
hyperparameter tuning.

00:16:19.050 --> 00:16:21.220
It's a very important
concept in machine learning.

00:16:21.220 --> 00:16:23.910
Basically, instead
of just training

00:16:23.910 --> 00:16:26.070
a single model
for your data, you

00:16:26.070 --> 00:16:29.680
train a whole class of models
and you pick the best one.

00:16:29.680 --> 00:16:31.050
And it's very powerful.

00:16:31.050 --> 00:16:33.210
And I'm not going to go
into details on this,

00:16:33.210 --> 00:16:35.220
but the infrastructure
for it is all set up.

00:16:35.220 --> 00:16:38.370
So in the experiment function
that makes the experiment,

00:16:38.370 --> 00:16:39.920
you can pass in hyperparameters.

00:16:39.920 --> 00:16:41.670
And then you can use
those hyperparameters

00:16:41.670 --> 00:16:43.419
to create your estimator.

00:16:43.419 --> 00:16:45.710
And then you return that
estimator with the experiment.

00:16:45.710 --> 00:16:49.580
And that way, you can implement
hyperparameter turning.

00:16:49.580 --> 00:16:53.240
Well, finally, this function
that makes an experiment we

00:16:53.240 --> 00:16:56.070
pass through what we call
the learn runner, which

00:16:56.070 --> 00:16:57.880
just runs it.

00:16:57.880 --> 00:17:02.910
And we can pass some user
options in a run config.

00:17:02.910 --> 00:17:05.819
And what the run
config also does,

00:17:05.819 --> 00:17:08.802
it contains information about
the cluster that we run it on.

00:17:08.802 --> 00:17:10.260
And so we can use
that information.

00:17:10.260 --> 00:17:11.843
For instance, if we
make the estimator

00:17:11.843 --> 00:17:13.236
and we want to
tweak it depending

00:17:13.236 --> 00:17:14.819
on how many machines
we have available

00:17:14.819 --> 00:17:17.964
or something like
that, we can do that.

00:17:17.964 --> 00:17:20.380
So it contains information on
how many workers do we have,

00:17:20.380 --> 00:17:25.230
how many parameter servers
do we have, and so on.

00:17:25.230 --> 00:17:28.980
But the run config
also takes information

00:17:28.980 --> 00:17:31.380
from the environment,
and so we don't

00:17:31.380 --> 00:17:32.610
have to pass it explicitly.

00:17:32.610 --> 00:17:34.320
So what do we have
to do in order

00:17:34.320 --> 00:17:37.970
to declare to TensorFlow,
hey, here's a cluster,

00:17:37.970 --> 00:17:40.170
please use the whole
cluster, is we write

00:17:40.170 --> 00:17:42.000
what's called the cluster spec.

00:17:42.000 --> 00:17:43.940
And this is a very,
very simple thing.

00:17:43.940 --> 00:17:47.580
It's just simply a map from
names of different machine

00:17:47.580 --> 00:17:49.900
types that we want to
do different things,

00:17:49.900 --> 00:17:51.540
and then a list of
all the machines

00:17:51.540 --> 00:17:52.980
that can do this thing.

00:17:52.980 --> 00:17:55.880
And usually, you have
Parameter Service or PS,

00:17:55.880 --> 00:17:57.412
and you have workers.

00:17:57.412 --> 00:17:59.370
And the parameter services
store the variables.

00:17:59.370 --> 00:18:02.250
The workers do the actual work.

00:18:02.250 --> 00:18:03.660
That's kind of traditional.

00:18:03.660 --> 00:18:05.280
And you just fill out these
lists, and you're done.

00:18:05.280 --> 00:18:06.150
And you save that.

00:18:06.150 --> 00:18:08.320
You dump that into
the second thing here.

00:18:08.320 --> 00:18:10.350
You dump that into an
environment variable,

00:18:10.350 --> 00:18:13.820
and then everything else
will work from there.

00:18:13.820 --> 00:18:18.150
OK, setting up a cluster
depends on the environment,

00:18:18.150 --> 00:18:20.340
and I'm not going to
talk in detail about it.

00:18:20.340 --> 00:18:22.980
But if you are
interested, it's on GitHub

00:18:22.980 --> 00:18:23.969
in the ecosystem repo.

00:18:23.969 --> 00:18:26.010
There's a number of scripts,
a number of examples

00:18:26.010 --> 00:18:28.934
that help you get started.

00:18:28.934 --> 00:18:30.350
So one thing I'd
like to mention--

00:18:30.350 --> 00:18:33.740
and I don't know how many of
you have seen the TPU talks.

00:18:33.740 --> 00:18:38.060
This is a pod of TPUs.

00:18:38.060 --> 00:18:40.820
If you stick to these
concepts, your code

00:18:40.820 --> 00:18:48.440
will basically work on a
TPU without modifications.

00:18:48.440 --> 00:18:53.880
So you will be able to use
this once you can use it.

00:18:53.880 --> 00:18:59.690
So I've shown you we
have, in TensorFlow,

00:18:59.690 --> 00:19:02.120
implementations of complete
machine learning models.

00:19:02.120 --> 00:19:04.786
You can get started with
them extremely quickly.

00:19:04.786 --> 00:19:06.410
They come with all
of the integrations,

00:19:06.410 --> 00:19:11.060
with TensorBoard, visualization
for serving and production,

00:19:11.060 --> 00:19:14.960
for different hardware,
different use cases.

00:19:14.960 --> 00:19:17.720
They obviously work in
distributed settings.

00:19:17.720 --> 00:19:19.130
We use them in data centers.

00:19:19.130 --> 00:19:22.640
You can use them on your
home computer network

00:19:22.640 --> 00:19:23.810
if that's what you'd like.

00:19:23.810 --> 00:19:28.070
You can use them in
flocks of mobile devices.

00:19:28.070 --> 00:19:30.180
Everything is possible.

00:19:30.180 --> 00:19:32.180
And they run on all kinds
of different hardware.

00:19:32.180 --> 00:19:34.515
And particularly,
they will run on TPU.

00:19:34.515 --> 00:19:36.230
It's nice.

00:19:36.230 --> 00:19:41.120
They also always run on
GPU, on CPU, obviously.

00:19:41.120 --> 00:19:43.430
OK, so before we move
on, the full code,

00:19:43.430 --> 00:19:46.130
again, is at this URL.

00:19:46.130 --> 00:19:49.070
If you're interested in more,
do check out the tutorials

00:19:49.070 --> 00:19:51.260
on tensorflow.org,
and particularly

00:19:51.260 --> 00:19:52.275
the estimator tutorial.

00:19:52.275 --> 00:19:53.900
I think that may be
the most convenient

00:19:53.900 --> 00:19:57.110
for people who want to
write their own estimators.

00:19:57.110 --> 00:19:59.060
And then do go to
the talk tomorrow

00:19:59.060 --> 00:20:05.990
at 1:30 in the amphitheater for
TensorFlow Serving with Noah.

00:20:05.990 --> 00:20:08.870
And with that,
thank you very much,

00:20:08.870 --> 00:20:11.930
and I'll hand it over to
Francois to tell you more.

00:20:11.930 --> 00:20:14.360
[APPLAUSE]

00:20:16.790 --> 00:20:18.730
FRANCOIS CHOLLET:
Thank you, Martin.

00:20:18.730 --> 00:20:22.299
So [INAUDIBLE] estimators
are great for many use cases.

00:20:22.299 --> 00:20:23.840
But what if you need
something that's

00:20:23.840 --> 00:20:26.180
not available as a
[INAUDIBLE] estimator?

00:20:26.180 --> 00:20:28.820
What if you need to write
your own custom model?

00:20:28.820 --> 00:20:31.550
That's where the
Keras API comes in.

00:20:31.550 --> 00:20:34.250
The Keras API is
this high-level API

00:20:34.250 --> 00:20:35.690
for building TensorFlow models.

00:20:35.690 --> 00:20:38.270
And you can use it
together with the estimator

00:20:38.270 --> 00:20:42.710
class and the experiment
class that Martin introduced.

00:20:42.710 --> 00:20:45.800
As you know, TensorFlow
features this fairly

00:20:45.800 --> 00:20:48.320
low-level programming
interface where

00:20:48.320 --> 00:20:50.480
you spend most of
your time multiplying

00:20:50.480 --> 00:20:52.430
matrices and vectors.

00:20:52.430 --> 00:20:55.460
And that's very powerful,
but that's also not

00:20:55.460 --> 00:20:59.870
ideal for building very
advanced complex models.

00:20:59.870 --> 00:21:03.150
So we really believe
that in the future,

00:21:03.150 --> 00:21:06.770
deep learning will be part of
the toolbox of every developer,

00:21:06.770 --> 00:21:09.020
not just machine
learning experts,

00:21:09.020 --> 00:21:12.470
because everyone needs
intelligent applications.

00:21:12.470 --> 00:21:14.700
And to make these
future possible,

00:21:14.700 --> 00:21:17.100
we need to make deep
learning really easy to use.

00:21:17.100 --> 00:21:20.900
We need to make available tools
that are accessible to anyone

00:21:20.900 --> 00:21:23.420
because you shouldn't need
to be an expert in order

00:21:23.420 --> 00:21:28.110
to start leveraging deep
learning to solve big problems.

00:21:28.110 --> 00:21:31.460
So if you could design a
deep learning interface

00:21:31.460 --> 00:21:35.300
without any constraints, what
would an ideal interface look

00:21:35.300 --> 00:21:36.530
like?

00:21:36.530 --> 00:21:38.720
I really think that
the core building

00:21:38.720 --> 00:21:43.160
blocks of deep learning are
all fairly well understood.

00:21:43.160 --> 00:21:47.270
And rather than letting the
user re-implement everything

00:21:47.270 --> 00:21:49.760
themselves, instead,
it should be

00:21:49.760 --> 00:21:53.210
really easy to just take
existing building blocks

00:21:53.210 --> 00:21:57.500
and be able to quickly assemble
them to build new deep learning

00:21:57.500 --> 00:22:00.770
data-processing pipelines.

00:22:00.770 --> 00:22:04.460
It should be basically
like playing [INAUDIBLE].

00:22:04.460 --> 00:22:07.530
And I think actually, if
you think about LEGO bricks,

00:22:07.530 --> 00:22:09.500
it's the ideal metaphor.

00:22:09.500 --> 00:22:11.890
LEGO bricks are very
intuitive to use.

00:22:11.890 --> 00:22:13.320
They're very easy to use.

00:22:13.320 --> 00:22:17.270
They provide this very flexible,
expressive framework in which

00:22:17.270 --> 00:22:19.970
you can build almost anything.

00:22:19.970 --> 00:22:23.000
They allow you to try
different things very quickly

00:22:23.000 --> 00:22:26.600
and immediately get visual
tactile feedback about what

00:22:26.600 --> 00:22:28.460
works and what doesn't work.

00:22:28.460 --> 00:22:31.560
And of course, LEGO bricks
are very accessible.

00:22:31.560 --> 00:22:36.560
They're accessible to any human
being ages five and above.

00:22:36.560 --> 00:22:39.440
And that's really
the idea, the ideal,

00:22:39.440 --> 00:22:43.310
I would say, that we had in mind
when we designed the Keras API.

00:22:43.310 --> 00:22:47.150
We wanted to be the
LEGO for deep learning.

00:22:47.150 --> 00:22:51.050
So let's take a look
at what Keras can do.

00:22:51.050 --> 00:22:52.580
So first of all, I
think it's better

00:22:52.580 --> 00:22:56.690
to think about Keras not
as a code base, a API

00:22:56.690 --> 00:22:58.670
framework, or a library.

00:22:58.670 --> 00:23:01.470
It's really just a
high-level API specification.

00:23:01.470 --> 00:23:04.770
And it's a spec that has several
different implementations.

00:23:04.770 --> 00:23:07.250
The main one, of course, is
the TensorFlow implementation.

00:23:07.250 --> 00:23:10.250
But there's also an
implementation for Theano.

00:23:10.250 --> 00:23:12.350
There's one for MXNet.

00:23:12.350 --> 00:23:15.410
There's one for Java, and
there are more coming.

00:23:15.410 --> 00:23:19.100
And what makes Keras different
from every other deep learning

00:23:19.100 --> 00:23:22.400
interface that's available
is its deep focus

00:23:22.400 --> 00:23:23.770
on user experience.

00:23:23.770 --> 00:23:26.540
Keras is all about
making your life easier,

00:23:26.540 --> 00:23:29.000
simplifying your
workflow, especially

00:23:29.000 --> 00:23:33.200
in terms of providing
easy-to-use building

00:23:33.200 --> 00:23:37.340
blocks, intuitive inferences,
in terms of providing

00:23:37.340 --> 00:23:40.190
good feedback when things
go wrong, and in general,

00:23:40.190 --> 00:23:44.990
just reducing complexity,
reducing cognitive load.

00:23:44.990 --> 00:23:47.930
And of course, if you make
deep learning easier to use,

00:23:47.930 --> 00:23:51.230
then you're also making it
accessible to more people.

00:23:51.230 --> 00:23:54.950
So the end goal with Keras is
to make deep learning accessible

00:23:54.950 --> 00:23:58.590
to as many people as possible.

00:23:58.590 --> 00:24:01.370
Until now, the
TensorFlow implementation

00:24:01.370 --> 00:24:04.160
for the Keras API
was available as part

00:24:04.160 --> 00:24:07.640
of an external open
source repository.

00:24:07.640 --> 00:24:09.530
But now what's
happening is that we

00:24:09.530 --> 00:24:11.660
are bringing the
Keras API directly

00:24:11.660 --> 00:24:13.340
into TensorFlow project.

00:24:13.340 --> 00:24:16.096
And we are doing that to
make Keras work seamlessly

00:24:16.096 --> 00:24:17.720
with your existing
TensorFlow workflow.

00:24:20.360 --> 00:24:22.370
Concurrently,
what's happening is

00:24:22.370 --> 00:24:26.380
Keras becomes available as a
new module inside TensorFlow,

00:24:26.380 --> 00:24:28.340
the tf.keras module.

00:24:28.340 --> 00:24:31.590
And it contains the
entire Keras API.

00:24:31.590 --> 00:24:33.560
So if you're a TensorFlow
user, what that

00:24:33.560 --> 00:24:36.170
means for you is that
now you get access

00:24:36.170 --> 00:24:40.130
to this new set of easy-to-use
deep learning building blocks

00:24:40.130 --> 00:24:42.830
that will work seamlessly
with your workflow.

00:24:42.830 --> 00:24:45.530
And if you are an existing Keras
user, what this integration

00:24:45.530 --> 00:24:48.020
means for you is that
suddenly, you gain access

00:24:48.020 --> 00:24:52.100
to high-level TensorFlow
training features, things

00:24:52.100 --> 00:24:53.960
like distributed
training, things

00:24:53.960 --> 00:24:56.330
like distributed
hyperparameter optimization,

00:24:56.330 --> 00:24:57.820
training on Cloud ML.

00:24:57.820 --> 00:25:00.570
So that's very powerful.

00:25:00.570 --> 00:25:03.510
So to give you a concrete sense
of what your workflow will

00:25:03.510 --> 00:25:07.380
be like when using the Keras
API to define your models

00:25:07.380 --> 00:25:10.320
and when using TensorFlow
estimators and TensorFlow

00:25:10.320 --> 00:25:13.860
experiments to train your
models in a distributed setting,

00:25:13.860 --> 00:25:17.760
I will walk you through a simple
yet fairly advanced example.

00:25:17.760 --> 00:25:22.120
We'll look at a video-question
answering problem.

00:25:22.120 --> 00:25:24.270
So that's what the
problem looks like.

00:25:24.270 --> 00:25:27.990
We have this data set of
a few thousand videos.

00:25:27.990 --> 00:25:30.240
Each video is about
10 seconds long.

00:25:30.240 --> 00:25:32.940
It shows some people
doing some activities.

00:25:32.940 --> 00:25:35.850
And a deep learning
model will be

00:25:35.850 --> 00:25:38.830
looking at the frames
of these videos,

00:25:38.830 --> 00:25:40.890
and it will try to
make sense of it.

00:25:40.890 --> 00:25:44.220
And then you can ask the
model short, natural language

00:25:44.220 --> 00:25:47.410
questions about the
contents of the video.

00:25:47.410 --> 00:25:49.800
So in this example,
we have a short video

00:25:49.800 --> 00:25:52.980
of a man packing some
boxes into a car.

00:25:52.980 --> 00:25:55.740
And you can ask, what
is the man doing?

00:25:55.740 --> 00:25:57.412
And model will be
looking at the video,

00:25:57.412 --> 00:25:59.120
will be looking at
the question, and will

00:25:59.120 --> 00:26:02.140
have to select
one-answer word out

00:26:02.140 --> 00:26:04.740
of a set of possible answers.

00:26:04.740 --> 00:26:08.270
So here in this example, you
can ask, what is the man doing?

00:26:08.270 --> 00:26:09.399
He's packing.

00:26:09.399 --> 00:26:11.190
And that's actually an
interesting question

00:26:11.190 --> 00:26:15.000
because if you were to
just look at a single frame

00:26:15.000 --> 00:26:17.430
from this video, you
couldn't answer the question.

00:26:17.430 --> 00:26:18.889
The man could be
unpacking as well.

00:26:18.889 --> 00:26:20.346
So the reason you
know he's packing

00:26:20.346 --> 00:26:22.020
is because of the
order of the frames.

00:26:22.020 --> 00:26:24.930
So we expect our model
to be able to leverage

00:26:24.930 --> 00:26:28.590
not just the visual
contents of the frames,

00:26:28.590 --> 00:26:32.020
but the order of
the frames as well.

00:26:32.020 --> 00:26:36.360
So needless to say, this is a
tremendously difficult problem.

00:26:36.360 --> 00:26:39.720
Just three or four
years ago, before Keras,

00:26:39.720 --> 00:26:43.260
before TensorFlow, this
would have been only doable

00:26:43.260 --> 00:26:46.410
for a handful of pretty
well-funded research labs.

00:26:46.410 --> 00:26:49.560
This would have been pretty
much a six-month project

00:26:49.560 --> 00:26:52.110
for a team of expert engineers.

00:26:52.110 --> 00:26:54.000
And what we are
doing now is that we

00:26:54.000 --> 00:26:56.070
are making this really
advanced problem

00:26:56.070 --> 00:26:59.820
accessible to pretty much anyone
with basic Python scripting

00:26:59.820 --> 00:27:00.820
abilities.

00:27:00.820 --> 00:27:04.635
So we are democratizing
deep learning.

00:27:04.635 --> 00:27:06.260
So that's what our
solution looks like.

00:27:06.260 --> 00:27:07.770
That's our network.

00:27:07.770 --> 00:27:10.060
It is structured in three parts.

00:27:10.060 --> 00:27:13.890
So first, you have one branch
that takes the video input

00:27:13.890 --> 00:27:17.550
and turns it into a vector
that encodes information

00:27:17.550 --> 00:27:19.180
about the video.

00:27:19.180 --> 00:27:21.540
And you have one branch
that takes the question

00:27:21.540 --> 00:27:24.010
and turns it into a vector.

00:27:24.010 --> 00:27:25.860
So now you can
concatenate the question

00:27:25.860 --> 00:27:27.780
vector and the video
vector, and you

00:27:27.780 --> 00:27:29.900
can add a classifier on top.

00:27:29.900 --> 00:27:32.070
And the job of the
classifier will

00:27:32.070 --> 00:27:34.650
be to select the
correct answer out

00:27:34.650 --> 00:27:38.010
of a pool of current answers.

00:27:38.010 --> 00:27:41.270
So the first step is
to turn the video input

00:27:41.270 --> 00:27:43.520
tensor into a vector.

00:27:43.520 --> 00:27:46.820
A video is just a
sequence of frames.

00:27:46.820 --> 00:27:48.200
And a frame is an image.

00:27:48.200 --> 00:27:50.750
So what you do with an
image is that you run it

00:27:50.750 --> 00:27:52.277
through a convnet.

00:27:52.277 --> 00:27:54.610
That's what you do with an
image, a natural thing to do,

00:27:54.610 --> 00:27:56.120
a CNN.

00:27:56.120 --> 00:28:01.550
And each CNN will extract
one vector representation

00:28:01.550 --> 00:28:02.880
for each frame.

00:28:02.880 --> 00:28:06.950
So what you get out of that
is a sequence of vectors

00:28:06.950 --> 00:28:08.647
encoding the frames.

00:28:08.647 --> 00:28:10.730
And when you have a sequence,
what you do with it,

00:28:10.730 --> 00:28:12.710
the natural thing
to do is to run it

00:28:12.710 --> 00:28:16.760
through this sequence-processing
module called an LSTM.

00:28:16.760 --> 00:28:21.110
And this LSTM will reduce the
sequence to a single vector.

00:28:21.110 --> 00:28:24.050
And this vector is
encoding information

00:28:24.050 --> 00:28:26.870
about all the frames
and their order,

00:28:26.870 --> 00:28:31.490
so the entire visual
contents of the video.

00:28:31.490 --> 00:28:34.520
The next thing to do
is a similar process

00:28:34.520 --> 00:28:35.960
applied to the question.

00:28:35.960 --> 00:28:38.690
The question is a
sequence of words.

00:28:38.690 --> 00:28:40.850
And you will use
an embedding module

00:28:40.850 --> 00:28:45.090
to map each word into a
vector, a word vector.

00:28:45.090 --> 00:28:47.870
So you get a sequence
of word vectors

00:28:47.870 --> 00:28:52.640
and reduce it using a
different LSTM layer.

00:28:52.640 --> 00:28:55.040
Once you have your vector
rendition for your video

00:28:55.040 --> 00:28:57.230
and your vector rendition
for your question,

00:28:57.230 --> 00:28:58.370
you can connect them.

00:28:58.370 --> 00:29:01.640
And you add this classifier
on top, whose job

00:29:01.640 --> 00:29:04.230
is to select the right answer.

00:29:04.230 --> 00:29:06.890
So that's really the
magic of deep learning.

00:29:06.890 --> 00:29:09.080
You take these very
complex inputs,

00:29:09.080 --> 00:29:13.040
which could be videos,
images, language, sound,

00:29:13.040 --> 00:29:15.020
and you turn them into vectors.

00:29:15.020 --> 00:29:19.270
So you turn them into points
in some geometric space.

00:29:19.270 --> 00:29:23.300
You turn meaning into
points in a geometric space.

00:29:23.300 --> 00:29:25.310
That's the essence
of deep learning.

00:29:25.310 --> 00:29:27.740
And what's really powerful
about it is that once

00:29:27.740 --> 00:29:31.010
you've done that, you
can use linear algebra

00:29:31.010 --> 00:29:34.010
to make sense of these
geometric spaces.

00:29:34.010 --> 00:29:36.320
And you can learn
interesting mappings

00:29:36.320 --> 00:29:38.160
between different
geometric spaces.

00:29:38.160 --> 00:29:41.000
So in our case, we
are learning a mapping

00:29:41.000 --> 00:29:44.840
between an initial space
of videos and questions

00:29:44.840 --> 00:29:46.880
and a space of answer words.

00:29:46.880 --> 00:29:49.190
And we are doing that
just through exposure

00:29:49.190 --> 00:29:50.990
to trained data.

00:29:50.990 --> 00:29:53.240
And the way we are
doing this is really

00:29:53.240 --> 00:29:57.950
by assembling together
these specialized blocks

00:29:57.950 --> 00:29:59.730
for information processing.

00:29:59.730 --> 00:30:01.670
It's a very natural thing to do.

00:30:01.670 --> 00:30:03.410
If you have an
image, you process

00:30:03.410 --> 00:30:05.930
it using an image-processing
module, which is CNN.

00:30:05.930 --> 00:30:07.850
If you have a
sequence, you process

00:30:07.850 --> 00:30:11.660
it using a sequence-processing
model, which is an LSTM.

00:30:11.660 --> 00:30:14.720
And if you want to
select one element out

00:30:14.720 --> 00:30:16.790
of a pool of
possible candidates,

00:30:16.790 --> 00:30:17.930
then you use a classifier.

00:30:17.930 --> 00:30:19.520
It's a natural thing to do.

00:30:19.520 --> 00:30:21.490
So what you are really
doing with deep learning

00:30:21.490 --> 00:30:24.860
is plugging together these
information-processing

00:30:24.860 --> 00:30:27.110
bricks are pretty
similar to LEGO blocks,

00:30:27.110 --> 00:30:29.460
right, to LEGO bricks.

00:30:29.460 --> 00:30:33.110
So building deep learning
models is conceptually

00:30:33.110 --> 00:30:35.420
similar to playing with LEGOs.

00:30:35.420 --> 00:30:38.750
And if the ideas behind
deep learning are so simple,

00:30:38.750 --> 00:30:43.320
then the implementation
should be simple as well.

00:30:43.320 --> 00:30:45.680
So let's take a look
at the implementation.

00:30:45.680 --> 00:30:49.140
This figure is a very
straightforward translation

00:30:49.140 --> 00:30:52.910
of our model into a
Keras implementation.

00:30:52.910 --> 00:30:58.760
On the video-encoding side, we
have this InceptionV3 convnet,

00:30:58.760 --> 00:31:01.670
and we use a
time-distributed layer

00:31:01.670 --> 00:31:05.570
to essentially apply this
convnet to each frame

00:31:05.570 --> 00:31:09.890
alongside the time axis
of an input video tensor.

00:31:09.890 --> 00:31:13.340
And then we pipe the output
through this LSTM layer,

00:31:13.340 --> 00:31:16.160
which will reduce it
to a single vector.

00:31:16.160 --> 00:31:18.260
So one interesting
thing to note here

00:31:18.260 --> 00:31:22.070
is that our InceptionV3
convnet will come loaded

00:31:22.070 --> 00:31:23.924
with pre-trained weights.

00:31:23.924 --> 00:31:25.340
And the reason
that's important is

00:31:25.340 --> 00:31:28.790
because with our
current video data set,

00:31:28.790 --> 00:31:31.010
we don't have
enough data to learn

00:31:31.010 --> 00:31:33.840
interesting visual
features on our own.

00:31:33.840 --> 00:31:35.840
So we need to
leverage preexisting

00:31:35.840 --> 00:31:39.140
visual features that were
learned on a larger data.

00:31:39.140 --> 00:31:40.920
So imagine that in this case.

00:31:40.920 --> 00:31:43.910
Now, that's a very common
pattern in deep learning.

00:31:43.910 --> 00:31:46.310
And it's a pattern that is
made really easy by Keras.

00:31:46.310 --> 00:31:49.340
And we'll see how in a second.

00:31:49.340 --> 00:31:53.060
On the question-encoding
side, it's even simpler.

00:31:53.060 --> 00:31:55.490
You just run the
sequence of words

00:31:55.490 --> 00:31:59.090
into an embedding layer to
produce sequence of vectors,

00:31:59.090 --> 00:32:01.640
and then you reduce
this sequence of vectors

00:32:01.640 --> 00:32:04.470
to a single vector
using an LSTM layer.

00:32:04.470 --> 00:32:06.680
So once you have this video
vector and this question

00:32:06.680 --> 00:32:09.950
vector, you will get an item
with a simple concat up.

00:32:09.950 --> 00:32:12.210
And you add the
classifier on top,

00:32:12.210 --> 00:32:14.449
which is just two
dense layers which

00:32:14.449 --> 00:32:15.740
will select the correct answer.

00:32:19.300 --> 00:32:20.890
Let's look at the code.

00:32:20.890 --> 00:32:23.340
So this is the
entirety of the code

00:32:23.340 --> 00:32:25.170
for the video-encoding part.

00:32:25.170 --> 00:32:26.280
It's just a few lines.

00:32:26.280 --> 00:32:27.400
It's very readable.

00:32:27.400 --> 00:32:28.920
It's very simple.

00:32:28.920 --> 00:32:32.560
You start by
specifying your inputs.

00:32:32.560 --> 00:32:34.380
So this is your video input.

00:32:34.380 --> 00:32:38.180
It's a sequence of
viable number of frames.

00:32:38.180 --> 00:32:40.201
So the None here is
the number of frames.

00:32:40.201 --> 00:32:41.700
It's undefined,
which means it could

00:32:41.700 --> 00:32:43.830
change from batch to batch.

00:32:43.830 --> 00:32:47.685
And each frame is a 150
by 150 image restricted

00:32:47.685 --> 00:32:50.420
to current channels.

00:32:50.420 --> 00:32:52.480
In the next step,
in just one line,

00:32:52.480 --> 00:32:55.790
we're defining an entire
InceptionV3 model,

00:32:55.790 --> 00:33:00.070
which is fairly complex model
defined in just one line.

00:33:00.070 --> 00:33:03.010
And it comes loaded
with pre-trained weights

00:33:03.010 --> 00:33:04.900
from the image in a data set.

00:33:04.900 --> 00:33:07.160
And all of this is built in.

00:33:07.160 --> 00:33:08.597
It's already into Keras.

00:33:08.597 --> 00:33:10.180
So you don't have
to do anything more.

00:33:10.180 --> 00:33:12.060
It's literally just one line.

00:33:12.060 --> 00:33:14.290
And we are not
including the top layers

00:33:14.290 --> 00:33:16.410
because they are
not relevant to us.

00:33:16.410 --> 00:33:18.700
And we are adding
some pooling on top,

00:33:18.700 --> 00:33:21.850
which allows us to
extract exactly one

00:33:21.850 --> 00:33:25.040
vector from each frame.

00:33:25.040 --> 00:33:27.310
In the next step, we are
setting these convnet

00:33:27.310 --> 00:33:31.240
to be non-trainable, which means
that its representations will

00:33:31.240 --> 00:33:33.440
not be updated during training.

00:33:33.440 --> 00:33:34.960
And the reason
that's important is

00:33:34.960 --> 00:33:37.230
because this convnet
has already comes

00:33:37.230 --> 00:33:39.730
with good, interesting
representations,

00:33:39.730 --> 00:33:43.370
and you don't want
to alter them.

00:33:43.370 --> 00:33:47.110
Again, so that's a very common
pattern in deep learning,

00:33:47.110 --> 00:33:50.980
to take a pre-trained model
and freeze it, and make

00:33:50.980 --> 00:33:52.480
it part of a new pipeline.

00:33:52.480 --> 00:33:55.300
And it's a pattern that's
made really easy in Keras.

00:33:55.300 --> 00:33:59.110
So once we have this
frozen pre-trained convnet,

00:33:59.110 --> 00:34:03.220
we use a time-distributed
layer to distribute the convnet

00:34:03.220 --> 00:34:07.510
across the time axis
of the video input.

00:34:07.510 --> 00:34:10.520
And the result of that
will be this tensor

00:34:10.520 --> 00:34:13.270
of frames which will run
through an LSTM layer

00:34:13.270 --> 00:34:16.810
to get a single
vector for the video.

00:34:16.810 --> 00:34:19.630
On the question side,
things are even simpler.

00:34:19.630 --> 00:34:25.460
We define a question input
as a sequence of integers,

00:34:25.460 --> 00:34:27.250
a viable number of integers.

00:34:27.250 --> 00:34:28.060
So why integers?

00:34:28.060 --> 00:34:30.520
Because every integer
will be mapped

00:34:30.520 --> 00:34:33.699
to a vector in some vocabulary.

00:34:33.699 --> 00:34:36.190
And we will run this
sequence of integers

00:34:36.190 --> 00:34:37.989
into an embedding
layer, which will map

00:34:37.989 --> 00:34:40.110
every integer to one vector.

00:34:40.110 --> 00:34:43.389
And these embeddings
are trained, of course.

00:34:43.389 --> 00:34:45.940
It's just part of the
weights of your model.

00:34:45.940 --> 00:34:49.810
And then you run this sequence
of vectors through an LSTM

00:34:49.810 --> 00:34:51.710
to reduce it to a single vector.

00:34:51.710 --> 00:34:52.210
So

00:34:52.210 --> 00:34:55.710
One interesting thing to note
here with the two LSTM layers

00:34:55.710 --> 00:34:58.120
that you've
instantiated so far is

00:34:58.120 --> 00:35:01.750
that we were not configuring the
layers beyond just specifying

00:35:01.750 --> 00:35:03.580
the number of output units.

00:35:03.580 --> 00:35:06.160
And that's interesting
because usually when

00:35:06.160 --> 00:35:08.500
you're using LSTM
layers, there are

00:35:08.500 --> 00:35:11.770
lots of things you have to keep
in mind, lots of best practices

00:35:11.770 --> 00:35:14.110
you should be following
to make things work.

00:35:14.110 --> 00:35:15.520
For instance, you
should remember

00:35:15.520 --> 00:35:17.530
that the [INAUDIBLE]
weights should be

00:35:17.530 --> 00:35:20.540
initialized with [INAUDIBLE].

00:35:20.540 --> 00:35:23.980
You need to remember that
the [INAUDIBLE] should

00:35:23.980 --> 00:35:26.240
be initialized to
1, and many more.

00:35:26.240 --> 00:35:29.320
And here, we are not doing
this because all these best

00:35:29.320 --> 00:35:32.140
practices are already
part of the default

00:35:32.140 --> 00:35:34.480
configuration of Keras layers.

00:35:34.480 --> 00:35:36.940
It's a very important
principle Keras,

00:35:36.940 --> 00:35:40.567
that best practices come
included as default.

00:35:40.567 --> 00:35:43.150
And what this means for you is
that your models will typically

00:35:43.150 --> 00:35:45.940
just work out of
the box without you

00:35:45.940 --> 00:35:48.940
having to tune every
parameter to make it work.

00:35:48.940 --> 00:35:51.880
So that really ties
into our goal with Keras

00:35:51.880 --> 00:35:54.737
to reduce cognitive load,
to reduce complexity.

00:35:54.737 --> 00:35:57.070
We don't want you to care
about these technical details.

00:35:57.070 --> 00:36:01.160
We just take care
of them for you.

00:36:01.160 --> 00:36:03.580
So once you've done
encoding your video

00:36:03.580 --> 00:36:07.180
and encoding your question,
you just use a concat up

00:36:07.180 --> 00:36:09.280
to turn them into
a single vector,

00:36:09.280 --> 00:36:10.780
and you add these
two dense layers

00:36:10.780 --> 00:36:15.250
on top, which will select
one answer word out

00:36:15.250 --> 00:36:18.740
of a vocabulary of a given size.

00:36:18.740 --> 00:36:23.890
In the next step, you're using
your inputs and your outputs

00:36:23.890 --> 00:36:26.920
to instantiate a Keras
model, which is essentially

00:36:26.920 --> 00:36:30.130
a container for a
graph of layers.

00:36:30.130 --> 00:36:32.800
And then you are specifying
the training configuration.

00:36:32.800 --> 00:36:34.630
So you are specifying
the optimizer

00:36:34.630 --> 00:36:37.150
that you want to use,
the AdamOptimizer.

00:36:37.150 --> 00:36:38.890
And you are specifying
the loss function

00:36:38.890 --> 00:36:42.550
for which you are optimizing.

00:36:42.550 --> 00:36:44.260
So that's very simple so far.

00:36:44.260 --> 00:36:46.340
At this stage, we have
defined our model.

00:36:46.340 --> 00:36:48.400
We've defined our
training configuration.

00:36:48.400 --> 00:36:51.820
And now, we want to train
this in a distributed setting,

00:36:51.820 --> 00:36:54.130
maybe on Cloud ML.

00:36:54.130 --> 00:36:56.440
So let's see how that works.

00:36:56.440 --> 00:36:58.180
This is where the magic happens.

00:36:58.180 --> 00:37:01.570
You can use the TensorFlow
estimator and experiment

00:37:01.570 --> 00:37:06.250
classes that Martin introduced
to train this Keras model,

00:37:06.250 --> 00:37:09.460
in a distributed setting in
just a few lines of code.

00:37:09.460 --> 00:37:13.450
All you have to do is to
write this experiment function

00:37:13.450 --> 00:37:15.820
in which you define
your model, you

00:37:15.820 --> 00:37:19.150
use your model to instantiate
an estimator using

00:37:19.150 --> 00:37:21.746
this built-in
get_estimator method.

00:37:21.746 --> 00:37:23.120
And once you have
this estimator,

00:37:23.120 --> 00:37:25.360
you use this to
create an experiment.

00:37:25.360 --> 00:37:28.670
And that's where you specify
your input data, for instance.

00:37:28.670 --> 00:37:30.860
So it's just a
few lines of code.

00:37:30.860 --> 00:37:32.300
It's really like magic.

00:37:32.300 --> 00:37:33.620
In just a few lines--

00:37:33.620 --> 00:37:36.160
a very readable,
straightforward Python code--

00:37:36.160 --> 00:37:39.070
we've defined a
state-of-the-art model,

00:37:39.070 --> 00:37:42.230
and we are training it
in a distributed setting.

00:37:42.230 --> 00:37:45.380
So to solve this really
challenging problem

00:37:45.380 --> 00:37:47.050
of video-question
answering, which

00:37:47.050 --> 00:37:49.970
would have been completely out
of reach to almost anyone just

00:37:49.970 --> 00:37:50.950
a few years ago.

00:37:50.950 --> 00:37:53.960
So these APIs, these
new high-level APIs,

00:37:53.960 --> 00:37:56.412
are really democratizing
deep learning.

00:37:56.412 --> 00:37:59.430
And that's made
possible by two things.

00:37:59.430 --> 00:38:02.240
On the one hand, you
have the Keras API,

00:38:02.240 --> 00:38:05.870
which is this very high-level,
easy-to-use and powerful way

00:38:05.870 --> 00:38:09.230
to define deep planning
models in TensorFlow.

00:38:09.230 --> 00:38:11.870
And besides being
just easy to use,

00:38:11.870 --> 00:38:15.050
each layer comes with good
default configurations,

00:38:15.050 --> 00:38:17.420
which allows your
model to just run out

00:38:17.420 --> 00:38:20.120
of the box without
much training.

00:38:20.120 --> 00:38:24.700
And the other piece of magic is
these new high-level TensorFlow

00:38:24.700 --> 00:38:27.170
training APIs that Martin
introduced, estimator

00:38:27.170 --> 00:38:28.490
and experiment.

00:38:28.490 --> 00:38:31.940
And together, this allows you to
solve any deep learning problem

00:38:31.940 --> 00:38:33.956
with very little effort.

00:38:33.956 --> 00:38:36.580
So we think these new APIs are
a big step towards democratizing

00:38:36.580 --> 00:38:38.530
deep learning and
making TensorFlow

00:38:38.530 --> 00:38:41.420
and deep learning
available to everyone.

00:38:41.420 --> 00:38:43.730
And we hope you will
find them useful.

00:38:43.730 --> 00:38:45.230
And we are very
much looking forward

00:38:45.230 --> 00:38:46.850
to seeing all the
cool applications

00:38:46.850 --> 00:38:49.550
that we'll be building
with TensorFlow and Keras.

00:38:49.550 --> 00:38:51.065
Thank you very
much for listening.

00:38:51.065 --> 00:38:54.035
[APPLAUSE]

00:38:55.520 --> 00:38:59.750
[MUSIC PLAYING]

