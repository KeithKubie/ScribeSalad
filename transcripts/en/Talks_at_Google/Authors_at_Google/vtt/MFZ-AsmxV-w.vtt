WEBVTT
Kind: captions
Language: en

00:00:01.079 --> 00:00:07.700
&gt;&gt;Female Presenter: I am incredibly happy
to wrap up Privacy Week with our final glory.

00:00:07.700 --> 00:00:15.200
We've got the author Jeff Jarvis here to give
us a talk about his most recent book, which

00:00:15.200 --> 00:00:22.390
is called "Public Parts," which covers and
stands up for the value of information and

00:00:22.390 --> 00:00:24.980
the value of sharing it in a digital world.

00:00:24.980 --> 00:00:30.670
So, within the set of people who talk about
and argue about privacy publicly, there are

00:00:30.670 --> 00:00:36.430
a whole lot of people out there talking about
the importance of being very careful not to

00:00:36.430 --> 00:00:42.580
share when you don't want to, being very careful
to have spaces that are not public, having

00:00:42.580 --> 00:00:44.730
things that are secret.

00:00:44.730 --> 00:00:51.330
And Jeff's voice is a really important counterbalance
to speak up for the importance in a healthy

00:00:51.330 --> 00:00:57.511
society of actually talking to each other,
of actually having things to say, as he would

00:00:57.511 --> 00:00:59.629
say, "of sharing."

00:00:59.629 --> 00:01:05.450
And as someone who has loomed large on the
Google landscape ever since his previous book,

00:01:05.450 --> 00:01:09.680
"What Would Google Do?" it's really, really
great to have him in this conversation with

00:01:09.680 --> 00:01:10.680
us.

00:01:10.680 --> 00:01:14.560
And I expect he's gonna have a lot of stimulating
things to say to us today.

00:01:14.560 --> 00:01:16.580
Thanks so much, Jeff.

00:01:16.580 --> 00:01:19.510
&gt;&gt;Jeff Jarvis: Thank you.

00:01:19.510 --> 00:01:20.510
[applause]

00:01:20.510 --> 00:01:26.240
Did any of you attend the last talk I gave
here which was on privacy?

00:01:26.240 --> 00:01:27.240
OK.

00:01:27.240 --> 00:01:28.240
Some of you.

00:01:28.240 --> 00:01:34.210
'Cause I promised this is Part Two, but I'll
go through a quick spiel of Part One is because

00:01:34.210 --> 00:01:37.750
actually I wanna talk more about publicness
than privacy 'cause I was brought here before

00:01:37.750 --> 00:01:38.750
to do a privacy event.

00:01:38.750 --> 00:01:41.000
Let me go through pretty quickly where that
goes.

00:01:41.000 --> 00:01:45.480
And yes, by the way, I am the most certified
Google fan boy there is having written a book

00:01:45.480 --> 00:01:49.500
telling the world to think like you.

00:01:49.500 --> 00:01:54.640
I also was very happy the first time I came
here to give a book talk on that book.

00:01:54.640 --> 00:01:58.320
My fear was I was now in the room with rocket
scientists who could tell me just how full

00:01:58.320 --> 00:02:00.020
of shit I was.

00:02:00.020 --> 00:02:01.760
But you're all too polite to have done so.

00:02:01.760 --> 00:02:03.860
So, I'm grateful for that.

00:02:03.860 --> 00:02:10.250
So, this time I wanted to write about publicness,
but to get there, I had to get through privacy.

00:02:10.250 --> 00:02:12.010
And privacy and publicness are not binary.

00:02:12.010 --> 00:02:13.640
They don't fight with each other.

00:02:13.640 --> 00:02:14.640
Yeah?

00:02:14.640 --> 00:02:17.330
&gt;&gt;MALE #1: Is this event private, or are we
allowed to post publicly?

00:02:17.330 --> 00:02:18.650
&gt;&gt;Jeff Jarvis: My life is an open blog.

00:02:18.650 --> 00:02:19.650
I have no secrets.

00:02:19.650 --> 00:02:20.650
&gt;&gt;Female Presenter: It's gonna be posted on
YouTube.

00:02:20.650 --> 00:02:23.440
&gt;&gt;Jeff Jarvis: It's gonna be posted on YouTube,
too.

00:02:23.440 --> 00:02:24.470
Yeah, I know.

00:02:24.470 --> 00:02:25.470
Post away.

00:02:25.470 --> 00:02:26.470
Post away.

00:02:26.470 --> 00:02:27.470
Please.

00:02:27.470 --> 00:02:28.470
I love it.

00:02:28.470 --> 00:02:29.470
@jeffjarvis.

00:02:29.470 --> 00:02:30.470
Twitter.

00:02:30.470 --> 00:02:31.470
[laughter]

00:02:31.470 --> 00:02:33.120
Jeff Jarvis on Google+, BuzzMachine.

00:02:33.120 --> 00:02:34.290
Facebook slash Jeff Jarvis.

00:02:34.290 --> 00:02:35.370
I'm delighted.

00:02:35.370 --> 00:02:42.569
Now, we'll get to talk about over-sharing
in a second, but--self-promotion.

00:02:42.569 --> 00:02:43.569
[laughter]

00:02:43.569 --> 00:02:45.209
So, history.

00:02:45.209 --> 00:02:49.340
Privacy and publicness are like hot and cold,
like wet and dry--this continuum.

00:02:49.340 --> 00:02:50.459
It's not either or.

00:02:50.459 --> 00:02:54.310
I think that's very, very important.

00:02:54.310 --> 00:02:57.069
But I tried to look at privacy.

00:02:57.069 --> 00:02:58.800
And again, I'm gonna rush through this part.

00:02:58.800 --> 00:03:03.209
But a little bit of the history of privacy,
which I mentioned last time, is that I didn't

00:03:03.209 --> 00:03:08.180
realize that the first serious legal discussion
about privacy, or legal right to privacy,

00:03:08.180 --> 00:03:14.620
did not come in the US until 1890 with the
invention of a technology--the Kodak camera--tied

00:03:14.620 --> 00:03:19.770
to the rise of the penny press, freaked people
out because something like, "My God.

00:03:19.770 --> 00:03:20.810
My picture could be anywhere."

00:03:20.810 --> 00:03:26.750
And Teddy Roosevelt banned "Kodaking" as it
was called in Washington parks briefly because

00:03:26.750 --> 00:03:29.099
he didn't want pictures taken of him or his
family.

00:03:29.099 --> 00:03:34.459
And look how we've changed as a society and
how our norms have changed around "please

00:03:34.459 --> 00:03:38.160
take a picture of me," everywhere except Germany.

00:03:38.160 --> 00:03:39.160
[laughter]

00:03:39.160 --> 00:03:44.400
And so, what we're going through now is changes
of norms around this.

00:03:44.400 --> 00:03:50.290
A fairly obvious thing, but in the earliest
villages, of course, there was very little

00:03:50.290 --> 00:03:51.290
privacy.

00:03:51.290 --> 00:03:52.489
We walked to each other's huts.

00:03:52.489 --> 00:03:58.500
And the first homes we did was an invention
of the hall, the invention of the back stairs

00:03:58.500 --> 00:04:03.020
that led to a society that started to have
expectations of privacy.

00:04:03.020 --> 00:04:06.000
Those were technologies in their way, in their
time.

00:04:06.000 --> 00:04:10.180
And it's said that privacy was invented in
England of that time.

00:04:10.180 --> 00:04:13.770
So privacy hasn't been around forever.

00:04:13.770 --> 00:04:16.229
I struggled a lot with the definitions of
privacy.

00:04:16.229 --> 00:04:21.889
And it turns out to be very, very, very difficult,
I found, to get to a definition because it's

00:04:21.889 --> 00:04:23.960
an empty vessel word.

00:04:23.960 --> 00:04:28.699
As even some of the people who study privacy
and know it well, say it means everything

00:04:28.699 --> 00:04:30.240
and nothing.

00:04:30.240 --> 00:04:36.860
Brandeis and Warren who wrote that 1890 law
essay about privacy that really led to bringing

00:04:36.860 --> 00:04:42.139
privacy into American law, said that it gets
down to the right to be let alone.

00:04:42.139 --> 00:04:45.159
And what they really said is that it's about
feelings.

00:04:45.159 --> 00:04:48.610
And so, when we try and talk about the harm
based on privacy it becomes very difficult

00:04:48.610 --> 00:04:50.449
because it really is about feelings.

00:04:50.449 --> 00:04:55.360
It's about your fear of what someone else
might think of you that they may never say.

00:04:55.360 --> 00:04:57.479
In fact, they may not think it.

00:04:57.479 --> 00:04:58.860
So that's what's so insidious about it.

00:04:58.860 --> 00:05:01.669
You're imagining, you're fearing, what they
might think.

00:05:01.669 --> 00:05:06.439
And that that becomes a lot of the essence
of the emotions around privacy.

00:05:06.439 --> 00:05:11.379
Other things like identity theft and fraud
and those kinds of things and stalking, I

00:05:11.379 --> 00:05:12.379
think are separate crimes.

00:05:12.379 --> 00:05:16.449
I think part of the problem with privacy is
we throw a lot into that bucket.

00:05:16.449 --> 00:05:23.129
But privacy itself, even Brandeis and Warren
say, it has a basis in emotion.

00:05:23.129 --> 00:05:27.379
So, that's all I wanna say about privacy,
believe it or not, in Privacy Week.

00:05:27.379 --> 00:05:29.090
I didn't know it was a whole week.

00:05:29.090 --> 00:05:31.999
I should be here all week.

00:05:31.999 --> 00:05:35.080
So, but of course it's private, so no one
knew about it.

00:05:35.080 --> 00:05:36.240
[laughter]

00:05:36.240 --> 00:05:38.629
So I'm happy to talk any bit more you want
about privacy.

00:05:38.629 --> 00:05:40.360
Actually, one more thing.

00:05:40.360 --> 00:05:48.460
So, I come to finally, if I can't define it
very well, I come to view privacy as an ethic--an

00:05:48.460 --> 00:05:50.319
ethic of knowing.

00:05:50.319 --> 00:05:59.629
And so, the idea here is that if I tell Chris
something quietly, then it is public to that

00:05:59.629 --> 00:06:00.629
extent.

00:06:00.629 --> 00:06:01.629
Right?

00:06:01.629 --> 00:06:02.629
Same as circles.

00:06:02.629 --> 00:06:03.629
You tell one person, it's public to that extent.

00:06:03.629 --> 00:06:08.069
So, at that point then, the responsibility
for what to do with that information lies

00:06:08.069 --> 00:06:09.659
on Chris's shoulders.

00:06:09.659 --> 00:06:13.210
And he has to make a whole series of judgments
as to, "Well, did I think--.

00:06:13.210 --> 00:06:14.330
Jarvis, what's the context?

00:06:14.330 --> 00:06:15.819
Was it said to me in private?

00:06:15.819 --> 00:06:17.470
Is it harmful to him if I spread that around?

00:06:17.470 --> 00:06:19.669
Do I not like him and I want to spread it
around as a result?

00:06:19.669 --> 00:06:24.500
Do I have a responsibility as a company to
keep this data secure?"

00:06:24.500 --> 00:06:25.529
And so on and so on.

00:06:25.529 --> 00:06:29.750
And so, the ethics that you go through in
your list, really, are somewhat mirrored to

00:06:29.750 --> 00:06:32.639
the ethics that I try to deal with there.

00:06:32.639 --> 00:06:33.830
Don't steal information, people.

00:06:33.830 --> 00:06:35.939
Don't fool them out of it.

00:06:35.939 --> 00:06:37.060
Keep it secure.

00:06:37.060 --> 00:06:39.610
Give them access to it--to their own information.

00:06:39.610 --> 00:06:42.509
Make it portable--deliberation front.

00:06:42.509 --> 00:06:43.809
And so on.

00:06:43.809 --> 00:06:46.270
So, I have a list of those.

00:06:46.270 --> 00:06:49.099
The complementary ethic is an ethic of publicness.

00:06:49.099 --> 00:06:50.840
Now, we get to publicness.

00:06:50.840 --> 00:06:54.009
And the idea there is that it's an ethic of
sharing.

00:06:54.009 --> 00:06:57.949
That it says that if I know something that
could be helpful to someone else, then I'm

00:06:57.949 --> 00:07:00.779
gonna make a decision as to whether or not
to share that.

00:07:00.779 --> 00:07:05.830
And I'm not arguing that everything should
be public, everything should be out there,

00:07:05.830 --> 00:07:07.409
that all of life is transparent.

00:07:07.409 --> 00:07:11.469
I go through a list of things in my book of
the things that I don't really wanna share.

00:07:11.469 --> 00:07:13.050
I don't really wanna share income.

00:07:13.050 --> 00:07:16.059
Now in Scandinavia, they share income and
taxes.

00:07:16.059 --> 00:07:19.349
But here, we don't and I don't know why I
don't want to, but I don't.

00:07:19.349 --> 00:07:24.810
But then I go along and say, "But I'm a teacher
at a public university with a contract."

00:07:24.810 --> 00:07:25.810
So you find out what I make.

00:07:25.810 --> 00:07:32.270
In fact, today on my blog, somebody I won't
mention eviscerated me yesterday.

00:07:32.270 --> 00:07:35.960
And I'm not gonna give him any freaking credit.

00:07:35.960 --> 00:07:36.960
[laughter]

00:07:36.960 --> 00:07:40.279
I said that on YouTube.

00:07:40.279 --> 00:07:41.429
[laughter]

00:07:41.429 --> 00:07:47.490
So, he tried to say that I was hypocritical
because I was not willing to say my income.

00:07:47.490 --> 00:07:48.490
Well, no.

00:07:48.490 --> 00:07:49.629
I was just explaining my emotions.

00:07:49.629 --> 00:07:54.149
And indeed, I did then say my income--pathetic
as it is--as a university professor.

00:07:54.149 --> 00:07:57.159
And some of the comments on my blog today
came in and pointed to a site I didn't know

00:07:57.159 --> 00:07:59.669
existed that has my income up there on the
site.

00:07:59.669 --> 00:08:04.479
But that's fine 'cause I'm public.

00:08:04.479 --> 00:08:07.819
So, an ethic of sharing.

00:08:07.819 --> 00:08:09.620
I was at the World Trade Center on 9/11.

00:08:09.620 --> 00:08:12.689
I wrote about that in my last book.

00:08:12.689 --> 00:08:15.759
Since then, I've gotten prostate cancer, thyroid
cancer, and a heart condition.

00:08:15.759 --> 00:08:19.229
[chuckles wryly] Now you know everything you
wanna know about me and more.

00:08:19.229 --> 00:08:24.699
Now, the fact that that happened publicly
wasn't correlated to 9/11, but what if it

00:08:24.699 --> 00:08:25.699
were?

00:08:25.699 --> 00:08:29.499
That data point, those three data points,
are of value potentially to other people who

00:08:29.499 --> 00:08:30.499
were there.

00:08:30.499 --> 00:08:33.320
So, I can choose to share them or choose not
to share them.

00:08:33.320 --> 00:08:36.870
I can choose to share them with a circle or
with the world, right?

00:08:36.870 --> 00:08:43.930
But to choose not to do so, I think at some
point in society, we could see that as selfish,

00:08:43.930 --> 00:08:44.930
as antisocial.

00:08:44.930 --> 00:08:46.720
And that gets me in trouble.

00:08:46.720 --> 00:08:49.590
But I think we've got to get to a society
where it is possible to do that.

00:08:49.590 --> 00:08:51.580
So, why wouldn't I share health?

00:08:51.580 --> 00:08:55.800
Well, let's talk about the notion of radically
sharing health.

00:08:55.800 --> 00:08:56.800
And this came out--.

00:08:56.800 --> 00:08:59.690
I gave a talk at the Google headquarters in
New York and somebody from the Health Team

00:08:59.690 --> 00:09:00.690
was there.

00:09:00.690 --> 00:09:03.010
So, this is what actually inspired this.

00:09:03.010 --> 00:09:07.260
What if we shared every bit of our health
data?

00:09:07.260 --> 00:09:08.260
Why don't we?

00:09:08.260 --> 00:09:10.810
Well, one reason is we may not get a job.

00:09:10.810 --> 00:09:12.520
But that's society's problem.

00:09:12.520 --> 00:09:17.030
That's a legal issue about the use of the
data that says that if you discriminate at

00:09:17.030 --> 00:09:20.570
me because I have a sickness, we can declare
that illegal.

00:09:20.570 --> 00:09:22.300
I may not get insurance.

00:09:22.300 --> 00:09:26.070
And even if that is private data, the insurance
company can get all my medical records, so

00:09:26.070 --> 00:09:28.640
it's really not that private as far as they're
concerned.

00:09:28.640 --> 00:09:30.570
The other reason is stigma.

00:09:30.570 --> 00:09:33.400
We have a stigma in society about certain
illnesses.

00:09:33.400 --> 00:09:37.370
And that's why when I talked about my prostate
cancer and my malfunctioning penis, I did

00:09:37.370 --> 00:09:40.110
it for a reason in the book because it tries
to get past that stigma.

00:09:40.110 --> 00:09:43.320
I also got incredible benefit back for it.

00:09:43.320 --> 00:09:48.112
People gave me advice that I would never have
gotten because they knew publicly that I--.

00:09:48.112 --> 00:09:50.140
I had friends that had the operation ten years
before.

00:09:50.140 --> 00:09:51.900
I didn't know they'd had it.

00:09:51.900 --> 00:09:53.790
Because I was public, they knew I was going
to have it.

00:09:53.790 --> 00:09:55.380
They came to me and gave me great advice.

00:09:55.380 --> 00:10:00.610
Finally, we, as a group, tried to inspire
other men to get tested for PSA.

00:10:00.610 --> 00:10:04.940
And most of you are too young for this, but
no matter what the government said last week,

00:10:04.940 --> 00:10:09.370
I still say get your PSA tested because more
information is always better than less information.

00:10:09.370 --> 00:10:12.580
And surely, that's something you believe here
at Google.

00:10:12.580 --> 00:10:17.291
Anyway, so there are benefits to publicness
and benefits to sharing, benefits to society

00:10:17.291 --> 00:10:19.000
and generosity, benefits to the individual.

00:10:19.000 --> 00:10:21.860
So, I try to list those benefits in the book.

00:10:21.860 --> 00:10:25.840
And part of my reason I'm doing so, is I think
it's important for the likes of Google and

00:10:25.840 --> 00:10:33.330
Facebook and Twitter, to start to sell the
benefits of publicness because the conversation

00:10:33.330 --> 00:10:35.970
is all about privacy, all about what could
go wrong.

00:10:35.970 --> 00:10:41.500
And if we managed life all to the worst case,
we'll never discover the best case and this

00:10:41.500 --> 00:10:43.240
is the valley of the best case.

00:10:43.240 --> 00:10:49.930
I'm accused all the time of being an internet
Utopian Here's utopia, right?

00:10:49.930 --> 00:10:50.930
[laughter]

00:10:50.930 --> 00:10:51.930
And it feels so good.

00:10:51.930 --> 00:10:52.930
[laughter]

00:10:52.930 --> 00:10:53.930
And it's true.

00:10:53.930 --> 00:10:55.170
It's true what they say about Heaven.

00:10:55.170 --> 00:10:59.190
You get all the food you can eat.

00:10:59.190 --> 00:11:00.190
[laughter]

00:11:00.190 --> 00:11:01.610
So, sorry.

00:11:01.610 --> 00:11:05.630
That just threw me off.

00:11:05.630 --> 00:11:06.630
[laughter]

00:11:06.630 --> 00:11:07.630
Where was I?

00:11:07.630 --> 00:11:10.680
So, the benefits.

00:11:10.680 --> 00:11:14.070
We've got to sell the benefits of this because
the conversation is only the worst case, only

00:11:14.070 --> 00:11:15.920
what could go wrong, only the fear.

00:11:15.920 --> 00:11:19.900
Then, that's what rules so much of what you
do.

00:11:19.900 --> 00:11:24.340
And not in a marketing way, but in a real
way, we've got to try to go shift the conversation

00:11:24.340 --> 00:11:27.570
to the benefits of publicness, to the good
things that happen when people can connect,

00:11:27.570 --> 00:11:29.660
to each other and information and actions
and so on.

00:11:29.660 --> 00:11:30.880
So, I list a bunch of benefits.

00:11:30.880 --> 00:11:33.930
They're the ones I list, but it's about making
relationships.

00:11:33.930 --> 00:11:37.040
It's about the notion of killing the idea
of stranger.

00:11:37.040 --> 00:11:38.230
I've made so many friends.

00:11:38.230 --> 00:11:40.500
I've met so many people who are now no longer
strangers.

00:11:40.500 --> 00:11:44.840
It's the idea of killing or disarming of these
stigmas.

00:11:44.840 --> 00:11:49.310
I argue in the book that publicness was the
best weapon that gays and lesbians in this

00:11:49.310 --> 00:11:52.930
country had to force back the bigots who had
forced them into the closet.

00:11:52.930 --> 00:11:57.140
And I do not suggest for one second that anyone
should be forced out of, or dragged out of,

00:11:57.140 --> 00:11:58.140
that closet.

00:11:58.140 --> 00:12:02.780
But those who had the courage to do so stood
up to the bigots and said, "OK.

00:12:02.780 --> 00:12:03.780
OK.

00:12:03.780 --> 00:12:04.780
So, we're gay.

00:12:04.780 --> 00:12:05.790
You got a problem with that?"

00:12:05.790 --> 00:12:08.750
It's what we would say in New Jersey.

00:12:08.750 --> 00:12:11.880
And that's a very, very powerful force.

00:12:11.880 --> 00:12:14.800
Publicness brings the potential for collaboration.

00:12:14.800 --> 00:12:17.310
Publicness allows us to collect the wisdom
of the crowd.

00:12:17.310 --> 00:12:22.650
Publicness, I think, starts to fight down
the myth of perfection, which we have from

00:12:22.650 --> 00:12:26.150
the Industrial Age--that everything we make
is perfect, that everything we do is perfect.

00:12:26.150 --> 00:12:29.590
Well, you guys fight that down with the beta.

00:12:29.590 --> 00:12:36.130
And that's a huge, I think, gift to society
is the example that you can put something

00:12:36.130 --> 00:12:41.020
out and if you put it out and it's not done,
that it's necessarily a call for collaboration.

00:12:41.020 --> 00:12:47.690
It is in my view, the beta is a very important
sign of humanity and humility, even from God

00:12:47.690 --> 00:12:49.240
Google.

00:12:49.240 --> 00:12:53.910
And that is because you are public with the
process of what you do.

00:12:53.910 --> 00:12:55.990
Publicness gives credit.

00:12:55.990 --> 00:12:59.840
I try to argue, even immortality.

00:12:59.840 --> 00:13:03.960
If you're not public, then no one will remember
you afterwards.

00:13:03.960 --> 00:13:05.670
And finally, it allows us to organize ourselves.

00:13:05.670 --> 00:13:14.860
I get to say in front of the God of the hash
tag that we're witnessing something amazing

00:13:14.860 --> 00:13:19.780
in Occupy Wall Street--a revolution based
on a hash tag.

00:13:19.780 --> 00:13:23.520
Part of my theory, by the way, that I started
to play with a little bit in the book, but

00:13:23.520 --> 00:13:29.020
keep playing with it since, is that I see
more and more life coming to imitate and mimic

00:13:29.020 --> 00:13:30.840
the architecture of the net.

00:13:30.840 --> 00:13:33.730
And this is an example where it's happening.

00:13:33.730 --> 00:13:37.350
This is a case where people are confused as
hell about Occupy Wall Street because they

00:13:37.350 --> 00:13:38.350
say, "Where's the structure?

00:13:38.350 --> 00:13:39.350
Where's the organization?

00:13:39.350 --> 00:13:40.350
Who's the leader?

00:13:40.350 --> 00:13:41.710
What are the goals?"

00:13:41.710 --> 00:13:43.779
No one owns a hash tag.

00:13:43.779 --> 00:13:44.779
There is no organization.

00:13:44.779 --> 00:13:45.779
There is no structure.

00:13:45.779 --> 00:13:47.500
There is no hierarchy.

00:13:47.500 --> 00:13:49.270
There is no creed.

00:13:49.270 --> 00:13:51.190
It's an idea that people put something into.

00:13:51.190 --> 00:13:54.070
I think it was after I was here last time.

00:13:54.070 --> 00:13:58.950
I violated one of the rules of my book, which
is the Cabernet rule.

00:13:58.950 --> 00:14:04.440
Never to --. Don't allow friends to tweet,
blog, Google+ or anything after too much wine.

00:14:04.440 --> 00:14:05.980
Well, it wasn't Cabernet.

00:14:05.980 --> 00:14:07.529
It was Pinot Noir.

00:14:07.529 --> 00:14:13.660
But I was really pissed off in the midst of
the so-called negotiations over the debt and

00:14:13.660 --> 00:14:18.020
I went and sat down and I said, "Fuck you,
Washington."

00:14:18.020 --> 00:14:19.020
Ooh.

00:14:19.020 --> 00:14:20.170
"It's our money.

00:14:20.170 --> 00:14:21.790
It's our economy.

00:14:21.790 --> 00:14:23.410
You're messing with it."

00:14:23.410 --> 00:14:24.660
And then I joked and I said, "You know?

00:14:24.660 --> 00:14:25.790
We should have a chant on Twitter."

00:14:25.790 --> 00:14:29.260
And then somebody came in and said--for all
I know, it may have been Chris under a different

00:14:29.260 --> 00:14:31.170
identity--"You idiot.

00:14:31.170 --> 00:14:32.360
That's called a hash tag."

00:14:32.360 --> 00:14:34.890
And so, I said, "Right.

00:14:34.890 --> 00:14:36.410
Fuck you, Washington."

00:14:36.410 --> 00:14:41.740
And people got mad at me, some did, for not
making it F you, Congress or F you this person

00:14:41.740 --> 00:14:42.779
or that person.

00:14:42.779 --> 00:14:47.110
But what fascinated me about this was people
filled in the rest of the sentence when they

00:14:47.110 --> 00:14:48.130
used the hash tag.

00:14:48.130 --> 00:14:51.970
"F you Washington because my parents don't
know if they can pay the bills next month."

00:14:51.970 --> 00:14:55.460
"F you Washington because you won't let me
marry who I want to."

00:14:55.460 --> 00:15:00.370
'F you Washington because you idiots can't
negotiate like a three-year old."

00:15:00.370 --> 00:15:01.590
And it was a blank slate.

00:15:01.590 --> 00:15:05.870
Well, similarly I think, Occupy Wall Street
is a bit of a blank slate and people are putting

00:15:05.870 --> 00:15:08.370
upon it their beliefs and their frustrations.

00:15:08.370 --> 00:15:13.529
And now, we're seeing a process of discernment
in public to bring out "Why are you occupying

00:15:13.529 --> 00:15:14.529
Wall Street?

00:15:14.529 --> 00:15:15.529
What do you want?

00:15:15.529 --> 00:15:16.529
What are you pissed about?"

00:15:16.529 --> 00:15:17.529
And we're starting to hear it.

00:15:17.529 --> 00:15:18.529
The media can't figure this out.

00:15:18.529 --> 00:15:20.350
But the people who are there can.

00:15:20.350 --> 00:15:23.540
So, organizing us.

00:15:23.540 --> 00:15:29.270
Another way that I think I see the internet
structure coming into society is news.

00:15:29.270 --> 00:15:32.800
That in Tahrir Square, we saw--.

00:15:32.800 --> 00:15:33.800
People didn't--.

00:15:33.800 --> 00:15:37.279
Andy Carvin at NPR didn't say to the New York
Times, didn't say to the people in Tahrir

00:15:37.279 --> 00:15:40.630
Square, "Hey, why don't you crowd-source your
revolution?

00:15:40.630 --> 00:15:44.560
Send your pictures to CNN and you could be
a field reporter for us."

00:15:44.560 --> 00:15:45.560
No.

00:15:45.560 --> 00:15:46.920
They used these tools for the revolution.

00:15:46.920 --> 00:15:51.460
They used the tools for what they wanted and
we could watch because they did it in public.

00:15:51.460 --> 00:15:58.180
And so what you saw there was the architecture
of the net end to end, witness to world, brought

00:15:58.180 --> 00:15:59.180
to life.

00:15:59.180 --> 00:16:05.270
And I find that fascinating that because it
was in public that was happening.

00:16:05.270 --> 00:16:10.320
Andy Carvin at NPR, I'm sure you all know,
sat at a distance and added value to that--added

00:16:10.320 --> 00:16:11.630
journalistic value to that.

00:16:11.630 --> 00:16:13.340
Who is really there?

00:16:13.340 --> 00:16:15.089
Who's not there?

00:16:15.089 --> 00:16:18.220
Debunking rumors, confirming things and so
on and so forth.

00:16:18.220 --> 00:16:20.850
But that notion of the architecture happening
in public.

00:16:20.850 --> 00:16:25.610
Well, what part of this goes to, too, is the
notion, the question of what is a public?

00:16:25.610 --> 00:16:28.210
What is the public?

00:16:28.210 --> 00:16:33.800
So I dared to go into Habermas a bit in the
book.

00:16:33.800 --> 00:16:35.430
I didn't study Habermas in school.

00:16:35.430 --> 00:16:37.860
I'm an amateur at Habermas, I will confess.

00:16:37.860 --> 00:16:40.430
I found him rather indigestible.

00:16:40.430 --> 00:16:41.900
[laughter]

00:16:41.900 --> 00:16:42.900
But those of you who studied--.

00:16:42.900 --> 00:16:44.290
How many of you had to study Habermas?

00:16:44.290 --> 00:16:45.290
OK.

00:16:45.290 --> 00:16:46.290
Thank you.

00:16:46.290 --> 00:16:47.290
Right.

00:16:47.290 --> 00:16:48.290
Right.

00:16:48.290 --> 00:16:50.430
So, by the way, somebody, this person who
eviscerated me, who I'm not gonna mention,

00:16:50.430 --> 00:16:54.330
took me to task because I mentioned Habermas
and Oprah Winfrey in the same book.

00:16:54.330 --> 00:16:57.610
That's how holy he is.

00:16:57.610 --> 00:17:02.230
But he's very important because he defines
the terms of the conversation about the notion

00:17:02.230 --> 00:17:03.970
of the public sphere.

00:17:03.970 --> 00:17:08.589
Habermas argues that it was not until the
18th Century that we had, in the form of rational

00:17:08.589 --> 00:17:12.850
and critical debate in salons and cafés,
the formation of a public sphere that was,

00:17:12.850 --> 00:17:19.139
for the first time, a force counterweight
to government--to the King.

00:17:19.139 --> 00:17:20.139
And I think he's right.

00:17:20.139 --> 00:17:21.139
I think it was important.

00:17:21.139 --> 00:17:24.579
I don't know if the discussion was necessarily
so rational and critical then, but he then

00:17:24.579 --> 00:17:29.850
argues that it was corrupted by mass media
coming in and changing the tenor of that.

00:17:29.850 --> 00:17:34.779
Well, then I came across some researchers
out of McGill, who did a wonderful project

00:17:34.779 --> 00:17:36.629
on the making of the modern public.

00:17:36.629 --> 00:17:42.190
And they finally decided that there were the
tools to make public before the 18th Century.

00:17:42.190 --> 00:17:45.460
That when three thousand people gathered in
the Globe Theater to watch Richard the Third--it

00:17:45.460 --> 00:17:47.100
is Richard the Third who's the bad King?

00:17:47.100 --> 00:17:50.260
You're a smart crowd, or was the Second?

00:17:50.260 --> 00:17:51.260
&gt;&gt;FEMALE #1: Third.

00:17:51.260 --> 00:17:52.260
&gt;&gt;Jeff Jarvis: Third?

00:17:52.260 --> 00:17:53.260
OK.

00:17:53.260 --> 00:17:54.260
Thank you.

00:17:54.260 --> 00:17:55.260
Got that.

00:17:55.260 --> 00:17:56.260
See, I'm not an academic.

00:17:56.260 --> 00:17:57.260
Richard the Third--.

00:17:57.260 --> 00:18:00.940
A public is formed around the idea of what
do we do when we have an incompetent ruler?

00:18:00.940 --> 00:18:08.460
So the stage, the book of course, maps, art,
markets, printed sermons--all these things

00:18:08.460 --> 00:18:14.659
were tools in the early modern period, the
early Renaissance, for making publics.

00:18:14.659 --> 00:18:22.879
And so, what I think starts to happen here
is we come back around now and we see that

00:18:22.879 --> 00:18:28.279
this corruption of the public sphere that
Habermas laments, and I agree with him on

00:18:28.279 --> 00:18:32.700
this, we now have the opportunity to turn
this around today because we, you create the

00:18:32.700 --> 00:18:35.480
tools that enable people to create their own
publics.

00:18:35.480 --> 00:18:41.690
I was on Twitter today and I forget what brought
it up, but I said something about media, or

00:18:41.690 --> 00:18:43.169
I think it was Clay Shirky.

00:18:43.169 --> 00:18:47.080
By the way, there's a law that says all the
internet optimists must quote Clay Shirky

00:18:47.080 --> 00:18:51.549
once a day, so I'm about to fulfill my legal
obligation.

00:18:51.549 --> 00:18:57.230
And Clay was talking about media and somebody
said in Twitter, "Maybe we should have Occupy

00:18:57.230 --> 00:18:58.230
Media."

00:18:58.230 --> 00:19:01.429
And I said, "We've already done that.

00:19:01.429 --> 00:19:02.429
That's what this is.

00:19:02.429 --> 00:19:04.230
You're in the midst of it, right?"

00:19:04.230 --> 00:19:06.309
So, we have these tools to create publics.

00:19:06.309 --> 00:19:13.649
And indeed, I think that Habermas's idea of
'the public sphere' was a bastardization of

00:19:13.649 --> 00:19:15.559
the notion of many publics.

00:19:15.559 --> 00:19:18.200
And he knows that and there are debates about
that as well.

00:19:18.200 --> 00:19:21.539
But, I think what we have now is the power
to create many, many publics.

00:19:21.539 --> 00:19:22.940
And that's what you do.

00:19:22.940 --> 00:19:29.890
You give people the ability to gather together
around an idea, an event, a need, a thought,

00:19:29.890 --> 00:19:32.400
a joke, anything.

00:19:32.400 --> 00:19:33.800
You and these other tools enable us.

00:19:33.800 --> 00:19:36.610
Search enables it and so on.

00:19:36.610 --> 00:19:39.080
So, what happens to media in this world?

00:19:39.080 --> 00:19:44.880
Well, it used to be that there was only one
way to get to content--one means of discovery

00:19:44.880 --> 00:19:45.880
and distribution.

00:19:45.880 --> 00:19:46.880
Brands.

00:19:46.880 --> 00:19:50.649
You had to buy the newspaper or the magazine,
the book, watch the TV show, whatever.

00:19:50.649 --> 00:19:52.169
Then, along came Search.

00:19:52.169 --> 00:19:58.889
You turned it around so that now people who
asked the question could start the process.

00:19:58.889 --> 00:20:00.120
And if you had an answer, great.

00:20:00.120 --> 00:20:01.120
If you didn't, you weren't there.

00:20:01.120 --> 00:20:02.120
You didn't live.

00:20:02.120 --> 00:20:08.929
But now there is, I believe, the next layer
of this is sharing as a means of content discovery

00:20:08.929 --> 00:20:10.559
and distribution.

00:20:10.559 --> 00:20:11.889
And that's what Zuckerberg wants.

00:20:11.889 --> 00:20:17.470
That's why he has Wall Street Journal and
Washington Post and The Guardian on Facebook.

00:20:17.470 --> 00:20:20.539
That's what you want, I think, with Google+.

00:20:20.539 --> 00:20:22.309
The more we can add signal.

00:20:22.309 --> 00:20:27.320
So, I argue that the Senate was way wrong
when they brought your executive chairman

00:20:27.320 --> 00:20:30.309
to the carpet on the basis of controlling
search.

00:20:30.309 --> 00:20:31.950
That was yesterday's war.

00:20:31.950 --> 00:20:33.720
I think the current war is signal gen--.

00:20:33.720 --> 00:20:34.720
Bless you.

00:20:34.720 --> 00:20:36.629
Is signal generation.

00:20:36.629 --> 00:20:38.659
And I'm telling you your business.

00:20:38.659 --> 00:20:45.470
But what I see from afar is that you, through
Google+, certainly through Android, and through

00:20:45.470 --> 00:20:49.650
other means, and Facebook and others, are
trying to get people to generate signals about

00:20:49.650 --> 00:20:55.809
themselves so that you can better serve them
more relevant content and services, and yes,

00:20:55.809 --> 00:20:56.809
advertising.

00:20:56.809 --> 00:20:59.240
And so, signal generation becomes very important.

00:20:59.240 --> 00:21:03.110
It's who we are, where we are, who do we know,
what do we like, what do we like, what do

00:21:03.110 --> 00:21:07.659
we buy, what don't we like, where are we going,
where have we been, what sort of behavior.

00:21:07.659 --> 00:21:09.659
All of these things are, of course, signals.

00:21:09.659 --> 00:21:15.350
But of course, that starts to freak people
out because it goes into privacy.

00:21:15.350 --> 00:21:19.820
And part of what we have to do, I think, is
do a better job of selling the idea to people

00:21:19.820 --> 00:21:20.820
that there is value to this.

00:21:20.820 --> 00:21:23.320
And we don't do that by telling them that
there's value to this.

00:21:23.320 --> 00:21:27.509
We do that, I think, by showing them.

00:21:27.509 --> 00:21:28.790
Because you get this, you get that.

00:21:28.790 --> 00:21:32.669
So, I get people all the time who'll ask me
about cookies.

00:21:32.669 --> 00:21:33.669
We've demonized cookies.

00:21:33.669 --> 00:21:36.610
We've demonized this notion of tracking.

00:21:36.610 --> 00:21:39.129
And that's partly the fault of us in this
industry.

00:21:39.129 --> 00:21:42.350
And I include in that media and advertising
because we didn't explain to people what we

00:21:42.350 --> 00:21:44.820
were doing, why we were doing it, what they
were getting out of it.

00:21:44.820 --> 00:21:46.990
And they discovered it after the fact.

00:21:46.990 --> 00:21:47.990
And they got freaked.

00:21:47.990 --> 00:21:49.049
And maybe they should have.

00:21:49.049 --> 00:21:53.889
But I tell them all the time, you can go into
Chrome--a wonderful browser--and you can have

00:21:53.889 --> 00:21:55.019
the incognito window.

00:21:55.019 --> 00:21:57.159
And you can cut off all your cookies.

00:21:57.159 --> 00:22:02.020
Your experience is going to be that you get
dancing monkey heads again and again and again.

00:22:02.020 --> 00:22:05.870
And there's an ethical question there that
you've now devalued yourself as a user with

00:22:05.870 --> 00:22:08.010
those media sites who were giving you stuff
for free.

00:22:08.010 --> 00:22:14.119
And if enough people do that, if we have "do
not track" legislation, the ultimate unintended

00:22:14.119 --> 00:22:18.549
consequence of that could be, I believe, content
dying or content going behind walls.

00:22:18.549 --> 00:22:20.879
Which is not good for us at all.

00:22:20.879 --> 00:22:23.740
So, there's a reason to try to sell this.

00:22:23.740 --> 00:22:26.039
And I hope that you do that.

00:22:26.039 --> 00:22:29.340
So, out of media to a few more thoughts.

00:22:29.340 --> 00:22:31.970
And then I really wanna have a conversation,
'cause every time I talk to Googlers, I get

00:22:31.970 --> 00:22:37.299
a headache 'cause you have such great thoughts
and I wanna get to that.

00:22:37.299 --> 00:22:39.690
'Cause it helps me.

00:22:39.690 --> 00:22:40.690
Over-sharing.

00:22:40.690 --> 00:22:45.450
I was accused by one person of over-sharing
because I wrote about my penis in public.

00:22:45.450 --> 00:22:48.960
And oddly, this guy--he didn't like me anyway--there
are people like that out there.

00:22:48.960 --> 00:22:51.070
The price of publicness is you get the haters.

00:22:51.070 --> 00:22:52.639
And this guy never liked me.

00:22:52.639 --> 00:22:55.850
Oddly, he also had prostate cancer.

00:22:55.850 --> 00:22:57.370
But said I was over-sharing.

00:22:57.370 --> 00:23:03.389
Well, it's an odd concept, over-sharing, because
what he's really doing is telling me to shut-up.

00:23:03.389 --> 00:23:04.389
Right?

00:23:04.389 --> 00:23:05.919
He's telling me, "Don't share this."

00:23:05.919 --> 00:23:09.580
Well, the beauty of the architecture we have
on the net today is there's a very easy answer

00:23:09.580 --> 00:23:10.580
to that.

00:23:10.580 --> 00:23:11.580
Unfollow me.

00:23:11.580 --> 00:23:12.580
Defriend me.

00:23:12.580 --> 00:23:13.580
Uncircle me.

00:23:13.580 --> 00:23:14.580
Don't click on me.

00:23:14.580 --> 00:23:17.470
There's all these ways that you don't have
to hear what I have to say.

00:23:17.470 --> 00:23:21.840
For you to tell me what I can or cannot say--F
you.

00:23:21.840 --> 00:23:23.649
The problem here is not over-sharing.

00:23:23.649 --> 00:23:26.450
The problem here is his over listening, right?

00:23:26.450 --> 00:23:27.450
[laughter]

00:23:27.450 --> 00:23:28.679
He's hearing too much.

00:23:28.679 --> 00:23:31.750
Now, is there such a thing as over-sharing,
then?

00:23:31.750 --> 00:23:37.309
I think over-sharing is sharing that which
you regret having shared.

00:23:37.309 --> 00:23:38.389
And we've all gone through that.

00:23:38.389 --> 00:23:39.389
We've all had to learn.

00:23:39.389 --> 00:23:40.710
We do need to educate people.

00:23:40.710 --> 00:23:45.190
Danah Boyd, I'm sure you all know of Danah
Boyd, researcher at Microsoft Labs and now

00:23:45.190 --> 00:23:46.190
NYU.

00:23:46.190 --> 00:23:47.190
Brilliant.

00:23:47.190 --> 00:23:48.190
Wonderful, Danah Boyd.

00:23:48.190 --> 00:23:49.429
Taught me so much about this.

00:23:49.429 --> 00:23:55.330
And says that we overprotect our children
actually, that we need to have them out interacting

00:23:55.330 --> 00:23:56.899
with the world.

00:23:56.899 --> 00:24:02.649
And that the problem here is not the gathering
of data, but the use of data.

00:24:02.649 --> 00:24:11.850
So, if I 
walk into your office and I apply for a job,

00:24:11.850 --> 00:24:17.450
you can see in a glance that I have prematurely
grey hair.

00:24:17.450 --> 00:24:19.559
[laughter]

00:24:19.559 --> 00:24:27.279
That my gender, my race, probably my education,
where I'm from and so on.

00:24:27.279 --> 00:24:30.239
Certain of that information, you may not use
to hire me or not hire me.

00:24:30.239 --> 00:24:32.039
However, you can still do it.

00:24:32.039 --> 00:24:35.450
You can still say, "I'm not gonna hire that
old fart."

00:24:35.450 --> 00:24:36.450
And nothing's gonna stop you.

00:24:36.450 --> 00:24:39.460
However, if you do it again and again and
again and again, there's a pattern there.

00:24:39.460 --> 00:24:42.919
But we cannot make you forget that I have
prematurely grey hair.

00:24:42.919 --> 00:24:44.480
It's impossible.

00:24:44.480 --> 00:24:48.889
Yet, what we're trying to do now is talk about
a right of forgetting.

00:24:48.889 --> 00:24:54.820
We're trying to manage the gathering of information
and that's a dangerous thing to do because

00:24:54.820 --> 00:24:59.080
when you do that, you cut off flows of information.

00:24:59.080 --> 00:25:03.440
And you also potentially, in this notion of
the right to forget by the way, impinge on

00:25:03.440 --> 00:25:06.369
someone else's freedom of speech.

00:25:06.369 --> 00:25:11.850
If I write about you and you complain and
there are laws that you make me take this

00:25:11.850 --> 00:25:14.830
down, you've now impinged upon my free speech
to say what I think of you for not hiring

00:25:14.830 --> 00:25:17.470
me because I have prematurely grey hair.

00:25:17.470 --> 00:25:20.450
So, we have to be careful of where we go with
these unintended consequences.

00:25:20.450 --> 00:25:27.879
I just wrote an op ed about COPPA, the Children's
Online Privacy Protection Act, that decrees

00:25:27.879 --> 00:25:34.429
that a site may not know basically anything
specific about a child under 13, like what

00:25:34.429 --> 00:25:35.429
town you're in--anything.

00:25:35.429 --> 00:25:40.280
So, if you wanna do a geography game and have
people start from their home, you can't do

00:25:40.280 --> 00:25:42.590
it unless you have the explicit permission
of the parent.

00:25:42.590 --> 00:25:47.379
And under the newly revised regulations, the
parent can't even respond by email.

00:25:47.379 --> 00:25:52.080
The parent has to print out, fax, or--fax,
remember that?

00:25:52.080 --> 00:25:59.240
Fax or scan the document, or get on a video
conference with the employee of the company.

00:25:59.240 --> 00:26:00.740
So, clearly no one does.

00:26:00.740 --> 00:26:01.740
So I was on a call--.

00:26:01.740 --> 00:26:05.230
With the Future of Privacy Forum, I was on
a call with the attorney, the attorney on

00:26:05.230 --> 00:26:12.299
this at the FDC and I asked a couple questions
about what I saw as the unintended consequences

00:26:12.299 --> 00:26:13.299
of COPPA.

00:26:13.299 --> 00:26:15.980
One, on the internet, no one knows you're
a dog and everyone is 14.

00:26:15.980 --> 00:26:18.399
We are teaching children to lie about their
age, right?

00:26:18.399 --> 00:26:19.510
No one is under 13.

00:26:19.510 --> 00:26:24.279
Number two, I said, "Do you have any data
about how much truth you get about age?"

00:26:24.279 --> 00:26:25.279
None.

00:26:25.279 --> 00:26:29.419
Second question, "How much do parents avail
themselves of these means of notice and consent?"

00:26:29.419 --> 00:26:30.590
No data.

00:26:30.590 --> 00:26:31.590
Three.

00:26:31.590 --> 00:26:35.179
Most important thing in my mind is that the
unintended consequence here is that children

00:26:35.179 --> 00:26:38.649
are the worst served demographic online by
far.

00:26:38.649 --> 00:26:39.649
I started a site.

00:26:39.649 --> 00:26:45.929
The second site I started to learn the web
back in '95--all my children--was the yuckiest

00:26:45.929 --> 00:26:50.179
site on the internet about cockroaches and
goo with the Liberty Science Center in New

00:26:50.179 --> 00:26:51.179
Jersey.

00:26:51.179 --> 00:26:52.179
And it was a lot of fun.

00:26:52.179 --> 00:26:53.179
We sold it to Discover.

00:26:53.179 --> 00:26:54.179
It's still around.

00:26:54.179 --> 00:26:56.100
You can learn about your snot.

00:26:56.100 --> 00:26:57.100
[laughter]

00:26:57.100 --> 00:27:03.570
And after we sold it, my employers said, "We're
not doing that again with COPPA because the

00:27:03.570 --> 00:27:05.070
risk is too great."

00:27:05.070 --> 00:27:10.279
So, the unintended consequence here is that
we underserve children because we try to negotiate

00:27:10.279 --> 00:27:12.009
the wrong thing.

00:27:12.009 --> 00:27:13.330
Other unintended consequences.

00:27:13.330 --> 00:27:18.419
Australia is looking to put in filters up
on all content on the net just to get to porn--child

00:27:18.419 --> 00:27:19.419
porn.

00:27:19.419 --> 00:27:22.840
Well, child porn's a banned thing, but they've
created an architecture in that case.

00:27:22.840 --> 00:27:23.840
It can be used in Iran.

00:27:23.840 --> 00:27:26.860
It can be used in China, used by despots.

00:27:26.860 --> 00:27:31.769
And we shouldn't allow that to happen to our
net, but that's where this privacy talk goes

00:27:31.769 --> 00:27:33.039
if it goes too far.

00:27:33.039 --> 00:27:34.479
I'm trying to--.

00:27:34.479 --> 00:27:42.399
Let me talk for a moment about identity because
it's a hot topic and I think it's a fascinating

00:27:42.399 --> 00:27:43.399
topic.

00:27:43.399 --> 00:27:47.601
So, a lot of talk these days about the real
name fight you started, you, Google, started

00:27:47.601 --> 00:27:53.259
because of Google+, and whose fault is it?

00:27:53.259 --> 00:27:54.580
Who did it?

00:27:54.580 --> 00:27:56.109
I think I know, actually.

00:27:56.109 --> 00:27:57.109
[chuckles]

00:27:57.109 --> 00:28:00.609
A little birdie told me.

00:28:00.609 --> 00:28:03.729
And here's the way I talk about it with people.

00:28:03.729 --> 00:28:04.752
Let me try it this way.

00:28:04.752 --> 00:28:11.519
I believe that they key insight that Facebook
and Zuckerberg had was real people, real relationships.

00:28:11.519 --> 00:28:16.369
And that that did, in fact, add value to the
discourse and the quality of discourse on

00:28:16.369 --> 00:28:17.879
the net.

00:28:17.879 --> 00:28:21.970
It's not the cure-all to trolls and bozos.

00:28:21.970 --> 00:28:24.809
There are many trolls and bozos, I know by
name.

00:28:24.809 --> 00:28:30.229
So, identity alone doesn't solve that problem,
but identity does bring up the investment

00:28:30.229 --> 00:28:32.620
people have in this.

00:28:32.620 --> 00:28:35.460
So, I think that it's beneficial.

00:28:35.460 --> 00:28:39.519
There is still an absolute and permanent need
for anonymity and pseudonymity.

00:28:39.519 --> 00:28:41.369
It is part of free speech.

00:28:41.369 --> 00:28:48.539
It is part of enabling the vulnerable whistle-blowers,
dissidents and tyrannies to be able to speak.

00:28:48.539 --> 00:28:50.159
So, I will defend anonymity.

00:28:50.159 --> 00:28:54.140
I will defend pseudonymity and nicknames for
various reasons.

00:28:54.140 --> 00:28:57.509
But I do think that identity is a good thing.

00:28:57.509 --> 00:29:05.799
I think candidly, Google+ went a little too
far in trying to say that only a real name

00:29:05.799 --> 00:29:08.869
is a guarantee of being a real person.

00:29:08.869 --> 00:29:13.509
And you also put yourself in a bad bind because
you became the arbiters of that at Google+

00:29:13.509 --> 00:29:16.710
versus at Facebook, it's really the community
that's more the arbiter of it.

00:29:16.710 --> 00:29:20.669
The bloodstream rejects fake beings.

00:29:20.669 --> 00:29:22.520
And the bloodstream here doesn't do that.

00:29:22.520 --> 00:29:23.520
So, I suspect you--.

00:29:23.520 --> 00:29:25.149
I know you'll come around and--.

00:29:25.149 --> 00:29:29.309
[telephone rings]

00:29:29.309 --> 00:29:31.549
Is that me?

00:29:31.549 --> 00:29:32.549
&gt;&gt;Female Presenter: Hello?

00:29:32.549 --> 00:29:33.549
&gt;&gt;Jeff Jarvis: No, it's me.

00:29:33.549 --> 00:29:34.549
&gt;&gt;Female Presenter: It's you.

00:29:34.549 --> 00:29:35.549
It's you.

00:29:35.549 --> 00:29:36.549
&gt;&gt;Jeff Jarvis: Yeah, I thought I turned it
off.

00:29:36.549 --> 00:29:37.549
[laughter]

00:29:37.549 --> 00:29:38.549
&gt;&gt;Female Presenter: Of all people to not have
it off.

00:29:38.549 --> 00:29:39.549
&gt;&gt;Jeff Jarvis: It is.

00:29:39.549 --> 00:29:40.549
It is.

00:29:40.549 --> 00:29:41.549
Oh no.

00:29:41.549 --> 00:29:42.549
I have to take this.

00:29:42.549 --> 00:29:43.549
No, I don't.

00:29:43.549 --> 00:29:44.549
[laughter]

00:29:44.549 --> 00:29:45.549
&gt;&gt;Female Presenter: You can only do that once.

00:29:45.549 --> 00:29:46.549
&gt;&gt;Jeff Jarvis: Now you see I ripped my jacket.

00:29:46.549 --> 00:29:47.899
&gt;&gt;Female Presenter: We've had that before,
by the way.

00:29:47.899 --> 00:29:48.909
Rooms calling here.

00:29:48.909 --> 00:29:49.909
It's happened.

00:29:49.909 --> 00:29:51.600
&gt;&gt;Jeff Jarvis: That would be fun.

00:29:51.600 --> 00:29:53.960
I'd rather have a conversation with somebody.

00:29:53.960 --> 00:29:54.970
I'd like that.

00:29:54.970 --> 00:29:55.970
All right.

00:29:55.970 --> 00:29:56.970
Identity.

00:29:56.970 --> 00:29:57.970
All right.

00:29:57.970 --> 00:29:58.970
So, I think that went too far.

00:29:58.970 --> 00:29:59.970
I understand why it was there.

00:29:59.970 --> 00:30:01.580
I think you've gotta find more subtlety and
nuance in this.

00:30:01.580 --> 00:30:08.409
But I also understand that there's great value
to having anonymity online and to have a verified

00:30:08.409 --> 00:30:09.409
identity online.

00:30:09.409 --> 00:30:10.600
I mean, I'm a fan of Howard Stern.

00:30:10.600 --> 00:30:17.639
And when Biz Stone went to visit Howard one
time, the office crew had a fight over--.

00:30:17.639 --> 00:30:19.950
Howard decided to make a game out of it and
tortured them.

00:30:19.950 --> 00:30:23.570
And so, three of the people who really wanted
to be identified on Twitter, he said that

00:30:23.570 --> 00:30:25.581
Biz would identify one of them.

00:30:25.581 --> 00:30:28.720
Ronny the Limo Driver won.

00:30:28.720 --> 00:30:29.720
There's a value to identity.

00:30:29.720 --> 00:30:31.610
There's a value to verification.

00:30:31.610 --> 00:30:33.230
There's a value to having your name out there.

00:30:33.230 --> 00:30:35.960
So, I think we've gotta find ways in which
we encourage identity.

00:30:35.960 --> 00:30:37.690
We encourage that.

00:30:37.690 --> 00:30:44.270
We reward it rather than instead, play Whack-a-Mole
with the fake ones.

00:30:44.270 --> 00:30:48.399
I also think that we have to find more reasons
why identity is useful online.

00:30:48.399 --> 00:30:49.960
And there's danger here, too.

00:30:49.960 --> 00:30:53.489
If governments had to issue internet licenses,
that's bad for everybody.

00:30:53.489 --> 00:30:54.799
And it's not good.

00:30:54.799 --> 00:30:58.320
We don't want a single verified identity,
because governments will then require you

00:30:58.320 --> 00:30:59.320
to use it.

00:30:59.320 --> 00:31:00.789
And there goes the internet.

00:31:00.789 --> 00:31:06.019
So, there's a role to identity that, I think,
you have to be able to play with.

00:31:06.019 --> 00:31:11.570
Then the other side of that is--I say in the
book--that I pretty much control my identity,

00:31:11.570 --> 00:31:13.210
but you control my reputation.

00:31:13.210 --> 00:31:17.279
When you leave this room, you can, "Oh, that
guy's a bozo.

00:31:17.279 --> 00:31:18.500
He talks too fast.

00:31:18.500 --> 00:31:19.710
He thinks he's funny.

00:31:19.710 --> 00:31:22.140
I wish he wouldn't talk about his penis."

00:31:22.140 --> 00:31:23.140
Whatever.

00:31:23.140 --> 00:31:25.019
[audience chuckles]
And you can tell the world that.

00:31:25.019 --> 00:31:26.019
And that's my reputation.

00:31:26.019 --> 00:31:27.200
So, you control my reputation.

00:31:27.200 --> 00:31:28.619
I control my identity.

00:31:28.619 --> 00:31:29.619
That's too simplistic.

00:31:29.619 --> 00:31:32.190
That's not quite right, but there's a variance
there.

00:31:32.190 --> 00:31:39.070
So there are questions of authority and certification
and trust and other things where I'm sure

00:31:39.070 --> 00:31:43.419
you, in your algorithmic wisdom, will find
ways to help people determine these things

00:31:43.419 --> 00:31:48.599
through scenes like reputation that will or
will not be tied to identity that become really

00:31:48.599 --> 00:31:49.599
interesting.

00:31:49.599 --> 00:31:52.330
I think we're gonna get a lot more nuanced
about identity just as Facebook finally got

00:31:52.330 --> 00:31:55.520
more nuanced than "like" or "ignore."

00:31:55.520 --> 00:31:58.580
I think identity has to become far more nuanced
and it's very difficult.

00:31:58.580 --> 00:32:00.070
All right.

00:32:00.070 --> 00:32:03.049
Heading toward the end.

00:32:03.049 --> 00:32:06.320
I talk in the book about open businesses and
how to run businesses openly.

00:32:06.320 --> 00:32:09.080
And you do that very well to an extent and
don't to an extent.

00:32:09.080 --> 00:32:10.320
I don't think that's necessarily that interesting.

00:32:10.320 --> 00:32:15.979
I talk about a company called--for you because
you're you, it is to others I hope--a company

00:32:15.979 --> 00:32:21.499
called Local Motors that is designing cars
in public.

00:32:21.499 --> 00:32:25.309
There's still a CEO that's in charge of the
company, but they have an open design competition

00:32:25.309 --> 00:32:30.179
for the cars and a kid at Pasadena won 20
thousand dollars designing the first one.

00:32:30.179 --> 00:32:34.770
And then they did the individual parts--the
little elements of the car.

00:32:34.770 --> 00:32:38.419
And somebody designed a tail light lens that
the community fell in love with.

00:32:38.419 --> 00:32:42.470
And the CEO, who's still responsible for putting
out a safe car and an economically viable

00:32:42.470 --> 00:32:44.179
car, said to the community, "OK.

00:32:44.179 --> 00:32:48.470
It's beautiful, but if I tool up to make this
custom part, it's gonna add a thousand bucks

00:32:48.470 --> 00:32:49.470
to the price of every car.

00:32:49.470 --> 00:32:50.889
Do you still want it?"

00:32:50.889 --> 00:32:53.490
And they rose as one and said, "Never mind."

00:32:53.490 --> 00:32:54.490
[laughter]

00:32:54.490 --> 00:32:55.940
And they went looking for alternate parts.

00:32:55.940 --> 00:32:59.809
They settled on a 75 dollar Honda tail light
lens that I would never recognize.

00:32:59.809 --> 00:33:02.200
What fascinates me about that is here's a
company--.

00:33:02.200 --> 00:33:05.429
You look at the auto industry, it is secret
to the extreme.

00:33:05.429 --> 00:33:10.570
Literally, they cloak the cars until they
finally take the cloak off and we all yawn.

00:33:10.570 --> 00:33:14.619
Well, here's a place where they share the
entire process.

00:33:14.619 --> 00:33:18.090
They share the specs of the car so that people
can make products for them, can make the tail

00:33:18.090 --> 00:33:19.090
light lenses.

00:33:19.090 --> 00:33:23.090
That's really hard for them to do, but they
get great benefit out of it by running the

00:33:23.090 --> 00:33:24.090
company openly.

00:33:24.090 --> 00:33:32.250
And in this case, here were the customers
sharing in design and economic decisions about

00:33:32.250 --> 00:33:33.250
the product.

00:33:33.250 --> 00:33:35.889
I think that's remarkable that they were given
the trust and the opportunity to do so.

00:33:35.889 --> 00:33:37.509
So, there's other examples like that.

00:33:37.509 --> 00:33:42.100
I think we have new companies like Kickstarter,
where you even use your customer’s capital

00:33:42.100 --> 00:33:43.100
to start the product.

00:33:43.100 --> 00:33:44.100
That's fascinating.

00:33:44.100 --> 00:33:45.669
All kinds of views of open companies, but
I'll skip over that.

00:33:45.669 --> 00:33:51.080
I did a lot of discussion, some discussion
as well about open government and what that

00:33:51.080 --> 00:33:52.080
really should mean.

00:33:52.080 --> 00:33:53.080
And it's not just about transparency.

00:33:53.080 --> 00:33:54.669
It's not just about "gotcha."

00:33:54.669 --> 00:33:56.580
It's also about collaboration.

00:33:56.580 --> 00:33:57.580
It's also about moving past.

00:33:57.580 --> 00:33:58.659
And I think we're gonna go to a--.

00:33:58.659 --> 00:34:03.979
We'll potentially go to a world where we start
to question even the notion of a nation.

00:34:03.979 --> 00:34:10.300
I think that's what we're seeing in Occupy
Wall Street and the Arab Spring and Iceland

00:34:10.300 --> 00:34:15.600
coming back from its economic disaster by
rewriting their constitution using Facebook.

00:34:15.600 --> 00:34:18.100
Get Google+ on that.

00:34:18.100 --> 00:34:20.599
It might be better.

00:34:20.599 --> 00:34:21.599
And so on.

00:34:21.599 --> 00:34:25.640
So, I think when government starts to change,
the notion of a nation and society start to

00:34:25.640 --> 00:34:26.640
change.

00:34:26.640 --> 00:34:27.640
And I go through that as well.

00:34:27.640 --> 00:34:30.760
And I want to skip finally to this one point
that I think is the most important in my mind

00:34:30.760 --> 00:34:32.710
and that I wanna recruit you on.

00:34:32.710 --> 00:34:39.909
Is I end the book with a call to defend the
principles of openness in society and the

00:34:39.909 --> 00:34:41.110
net.

00:34:41.110 --> 00:34:48.660
And my argument is that companies cannot be
in the position to secure the openness of

00:34:48.660 --> 00:34:49.660
the net.

00:34:49.660 --> 00:34:53.420
The one company that's in the best position
to do it is this one.

00:34:53.420 --> 00:34:57.030
And in China, in my personal view, you were
on the wrong side.

00:34:57.030 --> 00:34:58.030
Then, you were on the right side.

00:34:58.030 --> 00:35:03.150
You defended it to the end, your principles,
and I salute you for that as a company.

00:35:03.150 --> 00:35:10.790
Verizon, on the other hand, the net neutrality
was different on the wireless and wired net--as

00:35:10.790 --> 00:35:15.411
I've called it online "the Internet and the
Schminternet"--which, by the way, is not an

00:35:15.411 --> 00:35:16.411
Eric Schmidt joke.

00:35:16.411 --> 00:35:17.411
It's a Yiddish joke.

00:35:17.411 --> 00:35:21.080
Just to be clear here.

00:35:21.080 --> 00:35:23.820
I don't think that was a very good move on
Google's part.

00:35:23.820 --> 00:35:28.020
Well, but you're a company and you're now
tied with these devils called phone companies.

00:35:28.020 --> 00:35:30.440
And you gotta do things companies do and I
understand that.

00:35:30.440 --> 00:35:32.910
I don't like it and probably some of you don't
like it, either.

00:35:32.910 --> 00:35:35.860
But that means you are in no position to be
the defender of the net.

00:35:35.860 --> 00:35:37.030
And neither do you want to be.

00:35:37.030 --> 00:35:41.480
As Eric Schmidt has said, "You don't have
diplomats, except for Dave Drummond.

00:35:41.480 --> 00:35:45.200
You don't have police forces and laws.

00:35:45.200 --> 00:35:50.640
So, you're not in a position to be the defender
of the net and if you aren't, no company is.

00:35:50.640 --> 00:35:51.640
Governments.

00:35:51.640 --> 00:35:58.270
Well, I went to the e-G8 conference in Paris
where I had the audacity to challenge Sarkozy

00:35:58.270 --> 00:36:03.380
and asked him to take a Hippocratic Oath for
the net--first do no harm.

00:36:03.380 --> 00:36:04.460
He dismissed it.

00:36:04.460 --> 00:36:09.080
"Ah, you call it harm if I protect your children
and your copyright and your privacy?

00:36:09.080 --> 00:36:10.290
It's no harm.

00:36:10.290 --> 00:36:11.290
Be harder on me."

00:36:11.290 --> 00:36:12.550
So I said, "Well, it could be harm.

00:36:12.550 --> 00:36:13.920
It depends on how you do it.

00:36:13.920 --> 00:36:15.680
Depends on who does it."

00:36:15.680 --> 00:36:19.220
I don't trust government to have sovereignty
over the net.

00:36:19.220 --> 00:36:23.600
Have you all read John Perry Barlow's wonderful
"Declaration of Independence from Cyberspace?"

00:36:23.600 --> 00:36:24.850
Has anyone read that?

00:36:24.850 --> 00:36:26.410
Oh, you've gotta do it.

00:36:26.410 --> 00:36:27.410
It's brilliant.

00:36:27.410 --> 00:36:30.120
It's over the top as hell.

00:36:30.120 --> 00:36:32.330
Google it, pardon me, when you leave.

00:36:32.330 --> 00:36:33.330
I'm serious.

00:36:33.330 --> 00:36:35.270
And do dramatic readings of it.

00:36:35.270 --> 00:36:36.270
It's magnificent.

00:36:36.270 --> 00:36:40.770
"People of the future, you have no sovereignty
in this land where we live, this land of the

00:36:40.770 --> 00:36:41.770
mind."

00:36:41.770 --> 00:36:42.770
It's wonderful.

00:36:42.770 --> 00:36:43.770
&gt;&gt;MALE #2: Reread Giants?

00:36:43.770 --> 00:36:45.790
&gt;&gt;Jeff Jarvis: Reread Giants of Steel and
yeah.

00:36:45.790 --> 00:36:46.790
It's just brilliant.

00:36:46.790 --> 00:36:50.640
He's a little embarrassed about being so over
the top, but I try to get him to do a dramatic

00:36:50.640 --> 00:36:53.580
reading on Twig once and he wouldn't.

00:36:53.580 --> 00:36:54.580
It's wonderful.

00:36:54.580 --> 00:36:57.680
So, I came along and I thought, "Well, what
do we need?

00:36:57.680 --> 00:37:00.210
Do we need a constitution for the net?"

00:37:00.210 --> 00:37:01.210
No.

00:37:01.210 --> 00:37:03.720
Because I don't ever want it to be codified
in that way.

00:37:03.720 --> 00:37:05.380
Do we need a Bill of Rights for the net?

00:37:05.380 --> 00:37:06.460
Well, who enforces it?

00:37:06.460 --> 00:37:07.750
Who says what it is?

00:37:07.750 --> 00:37:12.520
And I came to believe that what we need is
a discussion--not a set--but a discussion

00:37:12.520 --> 00:37:16.790
of the principles of the public society and
an open net.

00:37:16.790 --> 00:37:18.570
And I put forward some of mine.

00:37:18.570 --> 00:37:19.570
They're wrong.

00:37:19.570 --> 00:37:20.570
They're not right.

00:37:20.570 --> 00:37:23.109
But I had to volunteer something.

00:37:23.109 --> 00:37:26.801
I don't think we'll ever get to a single set,
but if we have the conversation, I think we

00:37:26.801 --> 00:37:32.540
will start to discern principles that hold
us together so that when a government does

00:37:32.540 --> 00:37:35.580
something bad, we can point to this and say,
"You violated that."

00:37:35.580 --> 00:37:39.540
And also so we can give companies cover, so
that at some point when Google's in a difficult

00:37:39.540 --> 00:37:45.830
position with China or Verizon, they could
say, "Well, the people of the net really are

00:37:45.830 --> 00:37:48.100
gonna raise a ruckus 'cause we know that."

00:37:48.100 --> 00:37:49.990
But we, the people of the net, haven't done
this.

00:37:49.990 --> 00:37:53.010
Sarkozy brought together what he thought was
the internet.

00:37:53.010 --> 00:37:56.990
Larry Lessig from Harvard said, "The future
of the internet is not here because they didn't

00:37:56.990 --> 00:37:57.990
know how to get invited.

00:37:57.990 --> 00:38:00.680
And you didn't know how to invite them."

00:38:00.680 --> 00:38:04.040
But he thought he brought together the world
of the net.

00:38:04.040 --> 00:38:06.030
Why did we go to his table?

00:38:06.030 --> 00:38:08.710
Why shouldn't we invite him to our table,
us, the citizens of the net?

00:38:08.710 --> 00:38:11.840
So, will companies defend the openness of
the net?

00:38:11.840 --> 00:38:12.840
No.

00:38:12.840 --> 00:38:13.840
Will governments do so?

00:38:13.840 --> 00:38:14.840
No.

00:38:14.840 --> 00:38:16.550
Most, in fact, defended against some governments.

00:38:16.550 --> 00:38:18.160
Who will defend the openness of the net?

00:38:18.160 --> 00:38:20.980
We, the people of the net, must.

00:38:20.980 --> 00:38:26.010
And I think we have to start by not just thinking
like hackers and hacking around these obstacles.

00:38:26.010 --> 00:38:31.250
We have to start deciding what these principles
are because we are, in fact and indeed, building

00:38:31.250 --> 00:38:32.250
a new society.

00:38:32.250 --> 00:38:33.650
So, here's my list.

00:38:33.650 --> 00:38:37.240
And it is an imperfect list and raw list,
but it's the discussion that I want.

00:38:37.240 --> 00:38:40.870
First, that we have a right to connect.

00:38:40.870 --> 00:38:46.550
Not necessarily in the Finnish sense of everyone
being online through law, but certainly in

00:38:46.550 --> 00:38:50.800
a sense that if Mubarak shuts you off from
the net, he has violated your human rights.

00:38:50.800 --> 00:38:52.090
We have a right to speak.

00:38:52.090 --> 00:38:56.700
We have a right to act and assemble.

00:38:56.700 --> 00:38:58.180
There is an ethic of publicness.

00:38:58.180 --> 00:39:01.390
There is an ethic of privacy that we should
be following.

00:39:01.390 --> 00:39:03.470
What's public is a public good.

00:39:03.470 --> 00:39:09.800
And this I say after watching Google and it's
Verpixelungsrecht enabled people to blur their

00:39:09.800 --> 00:39:12.080
homes in Google+.

00:39:12.080 --> 00:39:18.220
Well, there's a problem there that Google
was taking pictures from the public street

00:39:18.220 --> 00:39:19.250
of a public view.

00:39:19.250 --> 00:39:22.580
And if Google can be told not to do that,
then perhaps journalists and citizens can

00:39:22.580 --> 00:39:23.580
be told not to.

00:39:23.580 --> 00:39:29.810
And whenever you limit the public sphere,
you're robbing from the public.

00:39:29.810 --> 00:39:34.530
Our governments and our institutions, including
companies, should be moving toward transparency

00:39:34.530 --> 00:39:36.520
by default and secrecy by necessity.

00:39:36.520 --> 00:39:38.620
We operate the other way today.

00:39:38.620 --> 00:39:39.910
Two more.

00:39:39.910 --> 00:39:45.000
Every bit is created equal and it if one bit
is discriminated against, whether that's by

00:39:45.000 --> 00:39:49.090
Comcast telling you not to watch this movie
versus that one, whether that's China saying

00:39:49.090 --> 00:39:52.470
you can't search on Falun Gong, whether that's
Mubarak shutting off the internet, whether

00:39:52.470 --> 00:39:56.580
that's Australia filtering all the content.

00:39:56.580 --> 00:39:58.910
If one bit is free, than none is free.

00:39:58.910 --> 00:40:00.030
None is presumed to be free.

00:40:00.030 --> 00:40:01.220
So, all bits must be free.

00:40:01.220 --> 00:40:03.060
That's the essence of net neutrality, I think.

00:40:03.060 --> 00:40:07.650
And finally, the architecture of the net must
remain distributed and open because that's

00:40:07.650 --> 00:40:08.830
what it is.

00:40:08.830 --> 00:40:11.140
No one can have sovereignty over the net.

00:40:11.140 --> 00:40:13.550
That's what makes the net the net.

00:40:13.550 --> 00:40:17.520
And indeed, as we start to see society in
various ways mimic this architecture of the

00:40:17.520 --> 00:40:23.330
net, I think we have to treat that architecture
as something more holy, to hold up.

00:40:23.330 --> 00:40:26.590
So, these are the things that I hope that
we defend.

00:40:26.590 --> 00:40:30.811
And what I would like to see for the likes
of Google is a defense of publicness, a defense

00:40:30.811 --> 00:40:32.120
of openness.

00:40:32.120 --> 00:40:35.210
Not just from a defensive position, but from
an offensive position.

00:40:35.210 --> 00:40:37.570
Or say, that these things are good for society.

00:40:37.570 --> 00:40:39.070
These are things that we all need.

00:40:39.070 --> 00:40:41.730
These are things that you enable and that
we believe in.

00:40:41.730 --> 00:40:47.290
And if we don't do that, then it'll be taken
over by bad governments and bad companies

00:40:47.290 --> 00:40:51.600
and bad people and spammers--over Matt Cutts'
dead body.

00:40:51.600 --> 00:40:58.050
I always tell everybody in the world that
you would think, given Matt's job, he would

00:40:58.050 --> 00:40:59.710
be the meanest son of a bitch you know.

00:40:59.710 --> 00:41:03.540
And here, he's one of the nicest guys on Earth
and that always amazes me about Matt.

00:41:03.540 --> 00:41:05.180
Or maybe I just see that public face.

00:41:05.180 --> 00:41:06.580
Maybe he is a mean son of a bitch behind that.

00:41:06.580 --> 00:41:07.930
I doubt that.

00:41:07.930 --> 00:41:08.930
[laughter]

00:41:08.930 --> 00:41:11.990
&gt;&gt;Female Presenter: He's like that all the
time.

00:41:11.990 --> 00:41:14.293
&gt;&gt;MALE #3: He shows up in different circles.

00:41:14.293 --> 00:41:15.293
&gt;&gt;Jeff Jarvis: Yeah.

00:41:15.293 --> 00:41:16.293
[Jeff Jarvis laughs]

00:41:16.293 --> 00:41:17.293
So, that's what I wanted to say.

00:41:17.293 --> 00:41:19.620
I wanted to talk about this with all of you
and get your pushbacks and get where you are

00:41:19.620 --> 00:41:20.860
and what you're thinking about all this.

00:41:20.860 --> 00:41:22.430
As always, I salute you.

00:41:22.430 --> 00:41:23.570
You do wonderful things.

00:41:23.570 --> 00:41:25.330
I'm glad you exist.

00:41:25.330 --> 00:41:27.200
And we couldn't live without you.

00:41:27.200 --> 00:41:31.930
But we might have to if the net doesn't stay
open, if what you do gets restricted too much,

00:41:31.930 --> 00:41:34.900
if it gets restricted in one country versus
another country.

00:41:34.900 --> 00:41:36.560
That's real danger out there.

00:41:36.560 --> 00:41:41.640
We might have to if good, well-meaning people
with well-meaning regulation go overboard

00:41:41.640 --> 00:41:45.920
and restrict the net so much to the fear of
the worst case that you can't build the best

00:41:45.920 --> 00:41:46.920
case anymore.

00:41:46.920 --> 00:41:51.770
So, I hope that you stay open to this and
that you as individuals and companies fight

00:41:51.770 --> 00:41:52.940
for publicness.

00:41:52.940 --> 00:41:57.740
So, that's what I wanted to say.

00:41:57.740 --> 00:41:59.290
Let's talk.

00:41:59.290 --> 00:42:00.290
[applause]

00:42:00.290 --> 00:42:02.390
Let us not--.

00:42:02.390 --> 00:42:03.950
Good, OK.

00:42:03.950 --> 00:42:05.960
There's always that embarrassing moment where
no one will do it.

00:42:05.960 --> 00:42:06.960
I'll do it.

00:42:06.960 --> 00:42:08.510
I'm happy to, if you don't mind.

00:42:08.510 --> 00:42:09.510
Is it all right?

00:42:09.510 --> 00:42:10.510
You know what?

00:42:10.510 --> 00:42:11.510
Let me just switch mics 'cause I think this
one is wonky.

00:42:11.510 --> 00:42:12.510
Can I switch mics?

00:42:12.510 --> 00:42:13.510
OK.

00:42:13.510 --> 00:42:14.510
[Jeff Jarvis whistles into mic]

00:42:14.510 --> 00:42:16.790
&gt;&gt;MALE #4: I know the other one is good.

00:42:16.790 --> 00:42:18.880
&gt;&gt;Jeff Jarvis: The other one's good?

00:42:18.880 --> 00:42:20.230
&gt;&gt;MALE #4: The other one's not good.

00:42:20.230 --> 00:42:21.230
&gt;&gt;Jeff Jarvis: Oh, I see.

00:42:21.230 --> 00:42:22.230
You're a freaking technology company.

00:42:22.230 --> 00:42:23.230
&gt;&gt;MALE #5: We don't make mics.

00:42:23.230 --> 00:42:24.230
&gt;&gt;Jeff Jarvis: I know, you're not hardware.

00:42:24.230 --> 00:42:25.230
[laughter]

00:42:25.230 --> 00:42:26.230
Is it on?

00:42:26.230 --> 00:42:27.230
&gt;&gt;MALE #6: Is this--?

00:42:27.230 --> 00:42:28.230
&gt;&gt;Jeff Jarvis: It works.

00:42:28.230 --> 00:42:31.820
&gt;&gt;MALE #6: So, you seem to be conflating two
things, where you say that--.

00:42:31.820 --> 00:42:35.730
Well, you say net neutrality is an aspect
of publicness, but it actually seems to me

00:42:35.730 --> 00:42:39.510
like that's an aspect of privateness 'cause
I have the right to not have my ISP inspect

00:42:39.510 --> 00:42:43.860
my packets, discriminate against this or that
behavior.

00:42:43.860 --> 00:42:47.390
And you're saying, and I think we all agree,
with net neutrality and you seem to argue

00:42:47.390 --> 00:42:49.720
that privacy in general is misguided--.

00:42:49.720 --> 00:42:51.650
&gt;&gt;Jeff Jarvis: I know, they suck.

00:42:51.650 --> 00:42:53.430
&gt;&gt;MALE #6: And you sell public.

00:42:53.430 --> 00:42:54.430
[laughter]

00:42:54.430 --> 00:42:55.430
&gt;&gt;Jeff Jarvis: Fair point.

00:42:55.430 --> 00:43:00.530
And when someone at Google says you conflate
things, you run for the hills and get nervous.

00:43:00.530 --> 00:43:02.400
Out of respect I say that.

00:43:02.400 --> 00:43:05.070
Yeah, I think you're right.

00:43:05.070 --> 00:43:07.040
I think you're right.

00:43:07.040 --> 00:43:08.370
[laughter]

00:43:08.370 --> 00:43:09.370
But I think it's both.

00:43:09.370 --> 00:43:12.380
As I said at the beginning, privacy and publicness
are not binary.

00:43:12.380 --> 00:43:13.380
They are not opposite.

00:43:13.380 --> 00:43:14.560
It is a continuum.

00:43:14.560 --> 00:43:17.730
If you enable one, you enable both.

00:43:17.730 --> 00:43:19.500
So, it's about control.

00:43:19.500 --> 00:43:23.190
Now, Mark Zuckerberg's definition of privacy
was really about control of your information.

00:43:23.190 --> 00:43:27.440
I think it's an inadequate definition, except
I first bought it at first.

00:43:27.440 --> 00:43:32.480
But I think in this case, it's about who controls
the bits.

00:43:32.480 --> 00:43:37.060
And end to end architecture, you at the end,
should control it either way.

00:43:37.060 --> 00:43:40.710
&gt;&gt;MALE #6: But if I should control by bits,
I should presumably control my cookies or

00:43:40.710 --> 00:43:41.750
"do not track" as well.

00:43:41.750 --> 00:43:44.480
I should control my personal information from
sharing on a social network as well, right?

00:43:44.480 --> 00:43:45.480
&gt;&gt;Jeff Jarvis: Are you against that?

00:43:45.480 --> 00:43:46.480
&gt;&gt;MALE #6: Am I against that?

00:43:46.480 --> 00:43:47.480
No.

00:43:47.480 --> 00:43:48.480
I think "do not track" makes sense, but you
seem to.

00:43:48.480 --> 00:43:49.480
&gt;&gt;Jeff Jarvis: OK.

00:43:49.480 --> 00:43:50.480
I was talking about that.

00:43:50.480 --> 00:43:51.560
Do not track makes sense.

00:43:51.560 --> 00:43:52.910
Why does it make sense?

00:43:52.910 --> 00:43:56.860
&gt;&gt;MALE #6: I think the same principle you
had said where I could actually control my

00:43:56.860 --> 00:43:57.860
bits from the ISP.

00:43:57.860 --> 00:43:58.950
Why should that be different?

00:43:58.950 --> 00:44:06.610
That privacy principle that I'm applying to
my data that the ISP is inspecting should

00:44:06.610 --> 00:44:08.860
presumably apply to my data at the website,
then the results are inspected.

00:44:08.860 --> 00:44:10.800
&gt;&gt;Jeff Jarvis: But it's not just about inspecting.

00:44:10.800 --> 00:44:12.780
It's also about restricting.

00:44:12.780 --> 00:44:15.210
That's what net neutrality is really about,
is someone's gonna restrict your bits--.

00:44:15.210 --> 00:44:16.210
Juggle them.

00:44:16.210 --> 00:44:18.540
Now we'll get confused which one is which.

00:44:18.540 --> 00:44:19.670
You hold on to that one.

00:44:19.670 --> 00:44:20.670
This is the good one.

00:44:20.670 --> 00:44:21.670
Hello.

00:44:21.670 --> 00:44:22.670
Oh, the voice of God.

00:44:22.670 --> 00:44:23.670
All right.

00:44:23.670 --> 00:44:24.670
So, this is one of those cases--.

00:44:24.670 --> 00:44:25.670
What?

00:44:25.670 --> 00:44:26.670
&gt;&gt;MALE #6: You were better off down there.

00:44:26.670 --> 00:44:27.670
&gt;&gt;Jeff Jarvis: All right.

00:44:27.670 --> 00:44:28.670
I was trying to be Oprah.

00:44:28.670 --> 00:44:31.220
&gt;&gt;MALE #7: Your bits are being filtered.

00:44:31.220 --> 00:44:32.220
[laughter]

00:44:32.220 --> 00:44:33.830
&gt;&gt;Jeff Jarvis: Oprah Habermas.

00:44:33.830 --> 00:44:34.830
[laughter]

00:44:34.830 --> 00:44:35.830
OK.

00:44:35.830 --> 00:44:42.810
So now I gotta think about this.

00:44:42.810 --> 00:44:50.990
Yes, there's a control, but I don't necessarily
buy that net neutrality is the same as privacy.

00:44:50.990 --> 00:44:52.410
I think they're both issues of control.

00:44:52.410 --> 00:44:54.270
They're different issues of control.

00:44:54.270 --> 00:44:56.430
The first issue of privacy that you have is
that it's in your head.

00:44:56.430 --> 00:45:01.240
And if it doesn't go out of your head, than
that's the most secure place you have.

00:45:01.240 --> 00:45:03.000
Then you choose to share something.

00:45:03.000 --> 00:45:06.890
Now, the problem we have with the discussion
of privacy is we've gotten to the point, I

00:45:06.890 --> 00:45:11.260
think I said earlier, where people think that
the internet is a vault where you store things.

00:45:11.260 --> 00:45:13.640
It's a really shitty vault.

00:45:13.640 --> 00:45:16.540
You shouldn't put things on the internet if
you want the world not to know this.

00:45:16.540 --> 00:45:17.540
Right?

00:45:17.540 --> 00:45:18.620
&gt;&gt;MALE #6: You're talking about Eric Schmidt.

00:45:18.620 --> 00:45:20.480
&gt;&gt;Jeff Jarvis: Well, yeah, I know.

00:45:20.480 --> 00:45:24.600
And, but I also defend him in the book that
the 21 joke was a joke.

00:45:24.600 --> 00:45:25.600
But yeah.

00:45:25.600 --> 00:45:32.200
I tend to believe that at some point or another,
if I tell Chris something, I have handed over

00:45:32.200 --> 00:45:33.770
my fate to Chris.

00:45:33.770 --> 00:45:35.400
&gt;&gt;MALE #8: Especially Chris.

00:45:35.400 --> 00:45:37.450
[audience chuckles]
&gt;&gt;Jeff Jarvis: Yeah.

00:45:37.450 --> 00:45:38.450
Especially.

00:45:38.450 --> 00:45:39.900
So, I've made that decision.

00:45:39.900 --> 00:45:43.590
He has the responsibility now, but I've lost
control over it to that extent.

00:45:43.590 --> 00:45:46.420
So, the best control I have is to keep it
here and not tell him.

00:45:46.420 --> 00:45:48.420
So, there's a control issue.

00:45:48.420 --> 00:45:49.930
But once I've given it up, I've given it up.

00:45:49.930 --> 00:45:51.230
Now, let's go to bigger data.

00:45:51.230 --> 00:45:54.400
So, the fact that I searched for "flu."

00:45:54.400 --> 00:46:04.180
Sergey says if we're forced to erase those
searches too early, then you may not have

00:46:04.180 --> 00:46:11.730
the data necessary to see the anomalous events
that would let you predict the next pandemic.

00:46:11.730 --> 00:46:16.120
So, was that search for "flu" mine because
I did it?

00:46:16.120 --> 00:46:17.120
No.

00:46:17.120 --> 00:46:19.820
It became Google's to the extent that I used
you to do it.

00:46:19.820 --> 00:46:22.160
It became maybe the public's to an extent.

00:46:22.160 --> 00:46:23.160
These are all different, I think.

00:46:23.160 --> 00:46:24.160
Hit me back.

00:46:24.160 --> 00:46:25.160
I'm not answering your question.

00:46:25.160 --> 00:46:26.160
&gt;&gt;MALE #6: I don't wanna dominate the discussion
and I think the mic doesn't work.

00:46:26.160 --> 00:46:27.160
So--.

00:46:27.160 --> 00:46:28.160
[laughter]

00:46:28.160 --> 00:46:29.160
&gt;&gt;Jeff Jarvis: I gotta think about this one.

00:46:29.160 --> 00:46:31.480
I'll blog it.

00:46:31.480 --> 00:46:33.830
I'll Google+ it.

00:46:33.830 --> 00:46:46.340
&gt;&gt;MALE #6: If you put an attack on "do not
track" by saying, "Well, it might be the website's

00:46:46.340 --> 00:46:48.080
that have pay walls."

00:46:48.080 --> 00:46:55.050
Well, the consumers would rather support websites
by paying than by having their data sold to

00:46:55.050 --> 00:46:56.050
the advertisement companies.

00:46:56.050 --> 00:46:57.050
I think the market is working and that's--.

00:46:57.050 --> 00:46:58.050
&gt;&gt;Jeff Jarvis: Ah, OK.

00:46:58.050 --> 00:46:59.050
Well, let the market do it.

00:46:59.050 --> 00:47:00.050
Don't regulate it.

00:47:00.050 --> 00:47:01.050
There's no reason to legislate that.

00:47:01.050 --> 00:47:02.250
&gt;&gt;MALE #6: That's more of a libertarian argument
of the role of regulation which is the difference

00:47:02.250 --> 00:47:03.250
here.

00:47:03.250 --> 00:47:08.620
&gt;&gt;Jeff Jarvis: I have the opportunity right
now to deprive the sites of cookies.

00:47:08.620 --> 00:47:10.220
I could turn them off at a session.

00:47:10.220 --> 00:47:11.370
I could turn them off permanently.

00:47:11.370 --> 00:47:12.910
I can kill them after a session.

00:47:12.910 --> 00:47:14.720
I can use incognito.

00:47:14.720 --> 00:47:15.960
I can do all those things today.

00:47:15.960 --> 00:47:19.110
All those tools are in my hands today.

00:47:19.110 --> 00:47:20.110
Right?

00:47:20.110 --> 00:47:25.050
So, why do we need "do not track" on top of
that, except for the fact that "do not call"

00:47:25.050 --> 00:47:30.480
was really popular and Congress wants to pass
things that start with "do not" as a result.

00:47:30.480 --> 00:47:34.350
I don't think we need "do not track" at all
and I think that, in fact, that's an example

00:47:34.350 --> 00:47:39.040
of how we've done a bad job as an industry
of allowing cookies to be demonized.

00:47:39.040 --> 00:47:40.960
In some cases, could we misuse them?

00:47:40.960 --> 00:47:41.960
Yes.

00:47:41.960 --> 00:47:44.970
But in some cases, because we didn't get out
there and say tracking is not all that bad.

00:47:44.970 --> 00:47:45.970
All right.

00:47:45.970 --> 00:47:48.003
I'll think about this and we'll see it on
Google+.

00:47:48.003 --> 00:47:49.003
What's your name, so I can see who it was?

00:47:49.003 --> 00:47:50.003
&gt;&gt;MALE #6: What's my name?

00:47:50.003 --> 00:47:51.003
&gt;&gt;Jeff Jarvis: Will you say that?

00:47:51.003 --> 00:47:52.003
&gt;&gt;MALE #6: What's that?

00:47:52.003 --> 00:47:53.003
&gt;&gt;Jeff Jarvis: Can I follow you on Google+?

00:47:53.003 --> 00:47:54.003
&gt;&gt;MALE #6: If you can find me.

00:47:54.003 --> 00:47:55.003
&gt;&gt;Jeff Jarvis: Oh, there we go.

00:47:55.003 --> 00:47:56.003
[laughter]

00:47:56.003 --> 00:47:57.003
Who else?

00:47:57.003 --> 00:47:58.003
Behind you.

00:47:58.003 --> 00:47:59.003
Yeah.

00:47:59.003 --> 00:48:00.003
&gt;&gt;MALE #8: Should we even bother?

00:48:00.003 --> 00:48:01.003
&gt;&gt;Female Presenter: Yes.

00:48:01.003 --> 00:48:02.003
He'll repeat the question.

00:48:02.003 --> 00:48:03.003
&gt;&gt;Jeff Jarvis: I'll repeat the questions.

00:48:03.003 --> 00:48:12.230
&gt;&gt;MALE #8: So, why are you such a big proponent
of net neutrality if the market forces competition

00:48:12.230 --> 00:48:19.220
who can handle that as well?

00:48:19.220 --> 00:48:22.960
&gt;&gt;Jeff Jarvis: I believe that the key to net
neutrality is competition, absolutely.

00:48:22.960 --> 00:48:24.340
&gt;&gt;MALE #8: Not regulation?

00:48:24.340 --> 00:48:25.380
&gt;&gt;Jeff Jarvis: Right.

00:48:25.380 --> 00:48:26.380
So, that's the argument.

00:48:26.380 --> 00:48:30.410
That's the libertarian argument is that net
neutrality is a form of regulation.

00:48:30.410 --> 00:48:35.330
Al Franken said on South by Southwest, he
said, "That's been mischaracterized that all

00:48:35.330 --> 00:48:37.780
we're doing is trying to get the internet
to stay as it was."

00:48:37.780 --> 00:48:38.930
We're not trying to change the internet.

00:48:38.930 --> 00:48:43.340
We're trying to keep the internet the way
it was and not allow people to come in and

00:48:43.340 --> 00:48:45.380
create new restrictions that didn't exist
before.

00:48:45.380 --> 00:48:51.160
So what we're protecting is the essence of
the pure internet in his argument.

00:48:51.160 --> 00:48:55.170
But I still agree with you absolutely that
the real solution here is competition.

00:48:55.170 --> 00:48:59.200
The real solution is if you have the shitty
service that restricts things versus the good

00:48:59.200 --> 00:49:02.350
service that doesn't, the market, I believe,
will pick the good things.

00:49:02.350 --> 00:49:04.100
I like to wander around.

00:49:04.100 --> 00:49:05.500
&gt;&gt;MALE #8: So, you're--.

00:49:05.500 --> 00:49:11.240
If there was competition and one company decided
to restrict bits, that's OK?

00:49:11.240 --> 00:49:13.970
&gt;&gt;Jeff Jarvis: If there were competition.

00:49:13.970 --> 00:49:16.200
Tom Evslin, who started--.

00:49:16.200 --> 00:49:18.470
Tom Evslin should be a hero to all of us.

00:49:18.470 --> 00:49:22.760
He was the guy at AT&amp;T World Net who took
the clock off the internet and put on flat

00:49:22.760 --> 00:49:25.000
pricing at 19.99 a month.

00:49:25.000 --> 00:49:27.060
He's the guy who made the internet go whoom.

00:49:27.060 --> 00:49:28.730
So, we love Tom.

00:49:28.730 --> 00:49:32.270
Tom then started a VoIP company, arbitraging
VoIP.

00:49:32.270 --> 00:49:34.320
Tom taught me about this and Tom's a libertarian.

00:49:34.320 --> 00:49:40.080
And Tom said, "Even so, we probably need temporary
regulation until we have competition."

00:49:40.080 --> 00:49:42.170
Where is the competition gonna come from?

00:49:42.170 --> 00:49:47.080
Well, your leaders have pushed for the white
areas to be on regulated spectrum--the white

00:49:47.080 --> 00:49:49.510
spaces on broadcast.

00:49:49.510 --> 00:49:51.860
Wi-Fi on steroids, so called.

00:49:51.860 --> 00:49:52.860
Right?

00:49:52.860 --> 00:49:56.400
If we had that, if we're truly an unregulated
spectrum, I believe there would be no need

00:49:56.400 --> 00:49:57.400
for regulation.

00:49:57.400 --> 00:49:59.230
In the meantime, however, we are prisoned.

00:49:59.230 --> 00:50:03.040
There are a few companies that treat us like
prisoners--airlines, phone companies, and

00:50:03.040 --> 00:50:04.040
cable companies.

00:50:04.040 --> 00:50:05.520
Because we are.

00:50:05.520 --> 00:50:06.990
And, and what?

00:50:06.990 --> 00:50:08.520
&gt;&gt;MALE #8: Facebook.

00:50:08.520 --> 00:50:10.050
&gt;&gt;Jeff Jarvis: Ohhh.

00:50:10.050 --> 00:50:11.050
[laughter]

00:50:11.050 --> 00:50:12.050
He said that.

00:50:12.050 --> 00:50:13.050
I didn't.

00:50:13.050 --> 00:50:17.310
Nah, I won't go there.

00:50:17.310 --> 00:50:20.430
So, yeah.

00:50:20.430 --> 00:50:21.430
I think regulation--.

00:50:21.430 --> 00:50:26.430
If you wanna view net neutrality as regulation,
not protection--which is fine--then I think

00:50:26.430 --> 00:50:27.670
it's a temporary means, yeah.

00:50:27.670 --> 00:50:28.670
Yeah?

00:50:28.670 --> 00:50:30.120
You gonna get up or try it?

00:50:30.120 --> 00:50:39.360
&gt;&gt;MALE #9: This notion of 
privacy is an ethic of knowing is really one

00:50:39.360 --> 00:50:42.240
of the light bulb moments in your book, that
it's, you can't restrict the flow of data

00:50:42.240 --> 00:50:43.330
and if you try to, it's bad.

00:50:43.330 --> 00:50:45.720
But you really have to think about what people
do with the data.

00:50:45.720 --> 00:50:50.191
And one consequence, you still seem to see
a lot of "gotcha" people out in private data

00:50:50.191 --> 00:50:51.260
that is to say symmetry.

00:50:51.260 --> 00:50:54.680
It's like, "Oh, let's beat up Clinton having
an affair, even though we're having an affair,

00:50:54.680 --> 00:50:55.680
too."

00:50:55.680 --> 00:50:56.680
All that kind of stuff.

00:50:56.680 --> 00:50:58.900
I mean, how do we get to the point where if
we really wanna take this ethic of knowing

00:50:58.900 --> 00:51:04.860
seriously, people are gonna have to stand
up when bad private things are exposed to

00:51:04.860 --> 00:51:07.060
people and say, "Hey, you abused your ethic
of knowing.

00:51:07.060 --> 00:51:08.620
Therefore, we're not gonna hold him against
that."

00:51:08.620 --> 00:51:12.780
As opposed to now, it still seems like there's
too much willingness to glom on to the things

00:51:12.780 --> 00:51:17.710
that were improperly exposed from privacy
and not reflexively saying, "Nope.

00:51:17.710 --> 00:51:18.920
That wasn't OK."

00:51:18.920 --> 00:51:24.180
&gt;&gt;Jeff Jarvis: Right, so an ethic of not using
people's stuff against them, parens, unless

00:51:24.180 --> 00:51:26.540
they deserve it, which is the journalistic
exception.

00:51:26.540 --> 00:51:28.710
Because that's what we do is use people's
information against them.

00:51:28.710 --> 00:51:30.550
&gt;&gt;MALE #9: I mean, do you think we need to
start seeing the press where other people

00:51:30.550 --> 00:51:34.270
stand up and say, "Hey," and pointing at basically
calling people on violating that ethic of

00:51:34.270 --> 00:51:37.010
knowing, if it really is gonna be something
that really takes over?

00:51:37.010 --> 00:51:38.010
&gt;&gt;Jeff Jarvis: Don't forget.

00:51:38.010 --> 00:51:39.010
I'm a Utopian and an optimist.

00:51:39.010 --> 00:51:40.910
But I hope that's where the norms start to
go.

00:51:40.910 --> 00:51:41.910
Yes.

00:51:41.910 --> 00:51:44.680
I have a theory of mutually assured humiliation.

00:51:44.680 --> 00:51:45.800
I have my embarrassing pictures.

00:51:45.800 --> 00:51:47.440
You have your embarrassing pictures.

00:51:47.440 --> 00:51:49.600
If you attack me, I attack you, so you don't.

00:51:49.600 --> 00:51:50.650
Arms down.

00:51:50.650 --> 00:51:55.600
Now, that, I believe, leads to a more tolerant
in society and that to me is the first step

00:51:55.600 --> 00:51:56.600
here.

00:51:56.600 --> 00:51:57.600
Some would say too tolerant.

00:51:57.600 --> 00:52:02.320
Some people said that being nice to gays is
too tolerant, but screw 'em.

00:52:02.320 --> 00:52:10.160
So, a society that becomes more open to more
behaviors and less condemning of them is,

00:52:10.160 --> 00:52:11.980
by definition, a more tolerant society.

00:52:11.980 --> 00:52:14.620
And I think that's where we go with more publicness.

00:52:14.620 --> 00:52:16.560
We could go the opposite.

00:52:16.560 --> 00:52:18.870
There's no guarantee of any of this.

00:52:18.870 --> 00:52:22.200
The technology doesn't determine and guarantee
any of this and it could go the opposite.

00:52:22.200 --> 00:52:26.000
The society could find more ways to condemn
more people.

00:52:26.000 --> 00:52:27.410
That's what happens.

00:52:27.410 --> 00:52:33.320
I start this with an inherent faith in humankind
and think that it's in our interest to have

00:52:33.320 --> 00:52:37.880
a better, nicer place to live and be ourselves
and be free to be ourselves.

00:52:37.880 --> 00:52:40.060
Cue Sesame Street.

00:52:40.060 --> 00:52:41.060
[laughter]

00:52:41.060 --> 00:52:47.510
&gt;&gt;MALE #10: So, if you imagine a world where,
I guess, we live in information abundance

00:52:47.510 --> 00:52:53.830
and all bits are free, I'm curious what your
thoughts are on teaching people about the

00:52:53.830 --> 00:52:58.950
value of data, or about perhaps relative value
of data, where some information could be more

00:52:58.950 --> 00:53:02.790
valuable than other information, depending
on the context, depending on the use, depending

00:53:02.790 --> 00:53:03.860
on the aggregation.

00:53:03.860 --> 00:53:08.210
How do we get people to believe that storing
their data for long periods of time so they

00:53:08.210 --> 00:53:13.450
can make use of it, perhaps 20 years down
the road, and do so either personally or in

00:53:13.450 --> 00:53:17.150
aggregate through communities is a better
way to go?

00:53:17.150 --> 00:53:20.520
&gt;&gt;Jeff Jarvis: This goes to the whole issue
of publicness, whether it's data or other

00:53:20.520 --> 00:53:21.520
forms.

00:53:21.520 --> 00:53:24.660
I think that you've gotta show--we talked
about this a lot a bit earlier--we've got

00:53:24.660 --> 00:53:26.400
to show those benefits.

00:53:26.400 --> 00:53:33.320
And it's not a case of us, who believe in
this, having a--most of us--having a marketing

00:53:33.320 --> 00:53:34.510
pitch.

00:53:34.510 --> 00:53:40.240
It's about anecdotes, case studies, best practices,
real things people do for real reasons and

00:53:40.240 --> 00:53:41.240
they benefit from it.

00:53:41.240 --> 00:53:46.860
And that's why I tell the prostate stuff because
even in that case, I had great benefit.

00:53:46.860 --> 00:53:49.860
And I have no regret about doing what I did.

00:53:49.860 --> 00:53:53.600
&gt;&gt;MALE #11: Is it more germane, like day to
day stuff?

00:53:53.600 --> 00:53:57.750
&gt;&gt;Jeff Jarvis: They don't see the benefits
yet, so how do you prove the benefits to people,

00:53:57.750 --> 00:53:58.750
right?

00:53:58.750 --> 00:53:59.750
How do you prove--?

00:53:59.750 --> 00:54:04.190
I mean, Gmail proves it to me because I can
now go back and find people.

00:54:04.190 --> 00:54:06.370
Gmail could prove it to me.

00:54:06.370 --> 00:54:09.940
Certainly, priority inbox proves it to me
because the fact that you, Google, can learn

00:54:09.940 --> 00:54:12.230
about that and can--it's a miracle.

00:54:12.230 --> 00:54:13.850
It's a freaking miracle, right?

00:54:13.850 --> 00:54:14.850
It's great.

00:54:14.850 --> 00:54:15.850
That's a demonstration of it.

00:54:15.850 --> 00:54:19.060
I think we gotta demonstrate it.

00:54:19.060 --> 00:54:23.200
You're also touching--I'm gonna go to another
point, because it just inspires me to do so.

00:54:23.200 --> 00:54:25.580
But it's related and not related.

00:54:25.580 --> 00:54:26.580
Value.

00:54:26.580 --> 00:54:27.580
Where is value encased?

00:54:27.580 --> 00:54:30.800
We, in media, think value is encased in content.

00:54:30.800 --> 00:54:35.220
I went out to lunch with a former head of
a network news operation a few months ago

00:54:35.220 --> 00:54:37.230
and he said, "You know, that damned Google
and Facebook.

00:54:37.230 --> 00:54:42.270
They--" and I don't mean to make him sound
like an old fart, but--

00:54:42.270 --> 00:54:43.270
[laughter]

00:54:43.270 --> 00:54:44.270
"Them youngun's.

00:54:44.270 --> 00:54:47.380
They use our steel in media to make their
cars.

00:54:47.380 --> 00:54:50.380
And Mark Zuckerberg doesn't value our content,"
he said.

00:54:50.380 --> 00:54:53.650
And I said, "No, actually, come to think of
it, it's the opposite.

00:54:53.650 --> 00:54:57.860
The only content you value is the content
you make 'cause you think that only the stuff

00:54:57.860 --> 00:55:00.800
you make is a content 'cause you're the content
person."

00:55:00.800 --> 00:55:07.270
Mark and Google see content everywhere and
value content everywhere--value it as data.

00:55:07.270 --> 00:55:12.010
And go back to signals, that the value is
in the relationships in the data about them.

00:55:12.010 --> 00:55:15.890
Content is a valuable tool to get there, but
all the value is not encased in the content.

00:55:15.890 --> 00:55:18.360
So, this is why we have this discussion about
pay walls now.

00:55:18.360 --> 00:55:20.920
And this is why we have this idea of ownership.

00:55:20.920 --> 00:55:23.420
And we go back to this idea of owning my data.

00:55:23.420 --> 00:55:26.490
Well, if you take that from me, it's just
wrong of you to do that.

00:55:26.490 --> 00:55:28.970
Well, but you can get the value.

00:55:28.970 --> 00:55:30.620
We're not showing that.

00:55:30.620 --> 00:55:31.620
And well, you know what?

00:55:31.620 --> 00:55:32.900
It's actually not that valuable.

00:55:32.900 --> 00:55:34.250
If you don't do, OK, fine.

00:55:34.250 --> 00:55:36.610
Others are gonna do it and learn.

00:55:36.610 --> 00:55:40.140
So, we've gotta get past this notion of where
the value is encased I think.

00:55:40.140 --> 00:55:44.580
And the only way we're gonna do it, I think,
is by demonstration.

00:55:44.580 --> 00:55:48.150
&gt;&gt;Female Presenter: Maybe one more question?

00:55:48.150 --> 00:55:49.940
&gt;&gt;Jeff Jarvis: OK.

00:55:49.940 --> 00:55:51.130
Yeah, sure.

00:55:51.130 --> 00:55:54.110
&gt;&gt;MALE #11: I'm struck by--

00:55:54.110 --> 00:56:00.500
&gt;&gt;Jeff Jarvis: I'm happy to stay and talk
as long as everybody wants.

00:56:00.500 --> 00:56:02.490
I've got a red-eye tonight.

00:56:02.490 --> 00:56:03.690
&gt;&gt;MALE #11: OK.

00:56:03.690 --> 00:56:07.620
I'm struck by the potential to use the--.

00:56:07.620 --> 00:56:10.370
A lot of medical studies, they go look for
control groups.

00:56:10.370 --> 00:56:12.610
That means they have to find them.

00:56:12.610 --> 00:56:16.990
If you had all the medical records for everybody
in the country, you wouldn't have to recruit

00:56:16.990 --> 00:56:17.990
a control group.

00:56:17.990 --> 00:56:19.930
&gt;&gt;Jeff Jarvis: Oh, that's interesting.

00:56:19.930 --> 00:56:22.100
I haven't thought about that.

00:56:22.100 --> 00:56:23.410
That's new ammunition.

00:56:23.410 --> 00:56:25.310
Because you know the control circumstances.

00:56:25.310 --> 00:56:26.340
&gt;&gt;MALE #11: Yeah.

00:56:26.340 --> 00:56:28.400
And if you actually allow people--.

00:56:28.400 --> 00:56:29.400
If people were--.

00:56:29.400 --> 00:56:30.400
I know a guy who publishes his test results.

00:56:30.400 --> 00:56:31.400
&gt;&gt;Jeff Jarvis: Right.

00:56:31.400 --> 00:56:32.400
&gt;&gt;MALE #11: OK.

00:56:32.400 --> 00:56:33.400
Imagine people that did that, that would just
considered to be a normal thing to do.

00:56:33.400 --> 00:56:34.400
And to do the same thing preventable.

00:56:34.400 --> 00:56:35.400
And also, to go to a website and tell them
a whole bunch of other things about you and

00:56:35.400 --> 00:56:36.400
say, "OK.

00:56:36.400 --> 00:56:45.990
Medical researchers are, some guy with a degree
in statistics who wakes up at one in the morning

00:56:45.990 --> 00:56:49.470
and has an idea.

00:56:49.470 --> 00:56:53.750
He gets on and just goes for it."

00:56:53.750 --> 00:56:55.750
The number of people who could do medical
research would be--

00:56:55.750 --> 00:56:56.750
&gt;&gt;Jeff Jarvis: Staggering.

00:56:56.750 --> 00:56:59.030
&gt;&gt;MALE #11: Would be an order of magnitude
of more or larger.

00:56:59.030 --> 00:57:00.030
&gt;&gt;Jeff Jarvis: Right.

00:57:00.030 --> 00:57:01.030
So, how do we get their society?

00:57:01.030 --> 00:57:03.960
Well, I think we gotta talk about the value
of publicness, even to that extent.

00:57:03.960 --> 00:57:06.130
And that's gonna freak people out.

00:57:06.130 --> 00:57:07.340
It's gonna really freak people out.

00:57:07.340 --> 00:57:08.340
But why?

00:57:08.340 --> 00:57:09.740
Again, one, job.

00:57:09.740 --> 00:57:10.740
You legislate that.

00:57:10.740 --> 00:57:12.310
Two, you regulate it.

00:57:12.310 --> 00:57:14.170
Two, insurance.

00:57:14.170 --> 00:57:17.860
Obama care took away--let's hope it stays--pre-existing
conditions.

00:57:17.860 --> 00:57:21.160
But three, the hardest one, is stigmas.

00:57:21.160 --> 00:57:23.220
Look what women have done with breast cancer.

00:57:23.220 --> 00:57:27.470
And there was a column I think today in the
Times or somewhere saying we've gone overboard.

00:57:27.470 --> 00:57:28.470
The Washington Post.

00:57:28.470 --> 00:57:29.610
I don't think so.

00:57:29.610 --> 00:57:31.560
That's what I'm trying to do with prostate.

00:57:31.560 --> 00:57:32.560
Other people don't.

00:57:32.560 --> 00:57:33.560
What are you trying to do?

00:57:33.560 --> 00:57:34.960
You're trying to take away a stigma.

00:57:34.960 --> 00:57:39.460
You're trying to make it OK to talk about
this so that people can get data and get information.

00:57:39.460 --> 00:57:41.650
We're a long way from that.

00:57:41.650 --> 00:57:43.050
&gt;&gt;MALE #11: Right.

00:57:43.050 --> 00:57:47.750
&gt;&gt;Jeff Jarvis: Part of the fear is--.

00:57:47.750 --> 00:57:53.280
My concern in being so public is I don't wanna
drag my family into my glass house.

00:57:53.280 --> 00:57:56.500
By telling you about my conditions, I have
revealed my children's DNA.

00:57:56.500 --> 00:57:57.500
Astrid--.

00:57:57.500 --> 00:58:00.300
My son went to Esther Dyson, who's published
her genome.

00:58:00.300 --> 00:58:02.250
She said, "Get over it, Jeff.

00:58:02.250 --> 00:58:04.020
Everybody gets prostate cancer.

00:58:04.020 --> 00:58:05.930
It's OK."

00:58:05.930 --> 00:58:09.770
A very Esther scientific view.

00:58:09.770 --> 00:58:12.740
But yes, we've gotta get to that point, but
as a society, we're so far away from it and

00:58:12.740 --> 00:58:14.170
we're going in the wrong direction.

00:58:14.170 --> 00:58:21.400
So, it's a great example and a great case
of proving the value to you and society of

00:58:21.400 --> 00:58:22.400
being open.

00:58:22.400 --> 00:58:23.400
How do you think we get there?

00:58:23.400 --> 00:58:29.800
&gt;&gt;MALE #11: Appeal to disease interest groups,
so that the members of the diseased's families

00:58:29.800 --> 00:58:31.300
put their stuff up along with--.

00:58:31.300 --> 00:58:34.069
And go to other interest groups, like, "We'll
do it for you if you do it for us.

00:58:34.069 --> 00:58:35.180
You can use us for controls.

00:58:35.180 --> 00:58:36.180
We can use you for controls."

00:58:36.180 --> 00:58:39.750
&gt;&gt;Jeff Jarvis: '23andme', um,not that, well,
23andme's part of that.

00:58:39.750 --> 00:58:41.550
PatientsLikeMe, you know site, right?

00:58:41.550 --> 00:58:48.670
I think is pretty amazing and it's under anonymity,
which is OK, but people get to share their

00:58:48.670 --> 00:58:53.590
dosages and side effects and so on and so
forth and it has real value.

00:58:53.590 --> 00:58:57.750
A friend of mine's wife has MS and he said
that this has been absolutely invaluable to

00:58:57.750 --> 00:59:01.170
her because you can see the dosages of where
it goes.

00:59:01.170 --> 00:59:05.440
For my many conditions, I would love to have
that kind of community.

00:59:05.440 --> 00:59:06.880
I went to pages like me.

00:59:06.880 --> 00:59:10.790
They only started with about a dozen very
serious disorders.

00:59:10.790 --> 00:59:12.880
They've now opened up to a lot.

00:59:12.880 --> 00:59:15.050
But if I go in for thyroid cancer, there's
like one other person.

00:59:15.050 --> 00:59:18.410
And he's taking my drug, so I don’t have
any critical mass of data.

00:59:18.410 --> 00:59:21.842
&gt;&gt;MALE #11: Disease side effects are greatly
under reported because I know lots of people

00:59:21.842 --> 00:59:23.880
have gotten a prescription, they've tried
it.

00:59:23.880 --> 00:59:24.880
They felt funny.

00:59:24.880 --> 00:59:27.280
They never told their doctor they stopped
using it.

00:59:27.280 --> 00:59:30.720
But if everyone who had ever used that disease
had said so, you can go find all these things

00:59:30.720 --> 00:59:31.720
and say, "Oh, look."

00:59:31.720 --> 00:59:36.930
&gt;&gt;Jeff Jarvis: I'm gonna sound like my parents
down in Sun City Central, Florida, going through

00:59:36.930 --> 00:59:38.960
what they call the organ recital here.

00:59:38.960 --> 00:59:43.040
The condition I got off of 9/11 is atrial
fibrillation, irregular heartbeat.

00:59:43.040 --> 00:59:44.900
And you get--.

00:59:44.900 --> 00:59:49.360
I'm under the care of a magnificently named
drug called Rythmol.

00:59:49.360 --> 00:59:51.850
It gives me rhythm.

00:59:51.850 --> 00:59:54.970
Knock on wood it works.

00:59:54.970 --> 00:59:58.580
People have onsets of a-fib and it's rather
mysterious why they do.

00:59:58.580 --> 01:00:04.710
And my simple wish for this is if every fib
patient felt free to describe their days,

01:00:04.710 --> 01:00:08.500
48 hours, what they ate, what they did, what
they thought, before an onset,

01:00:08.500 --> 01:00:12.620
I gotta believe that there's some correlations
to be found.

01:00:12.620 --> 01:00:16.620
And not doing that hurts every one of those
people and increases our costs and does all

01:00:16.620 --> 01:00:17.620
these bad things.

01:00:17.620 --> 01:00:21.150
But we're in a mode of going in the opposite
direction not only in privacy, but also on

01:00:21.150 --> 01:00:22.150
information.

01:00:22.150 --> 01:00:28.610
The decision made by the government panel
last week on prostate PSA testing was that

01:00:28.610 --> 01:00:33.700
statistically, and I'm speaking to the wrong
group here about statistics, statistically

01:00:33.700 --> 01:00:35.290
it doesn't save lives.

01:00:35.290 --> 01:00:37.770
Well, as a cohort, perhaps.

01:00:37.770 --> 01:00:40.990
But as an individual, it gave me information.

01:00:40.990 --> 01:00:43.781
Now, perhaps I shouldn't have had the operation
because you can't tell the difference between

01:00:43.781 --> 01:00:46.980
slow moving and fast moving prostate cancer.

01:00:46.980 --> 01:00:50.040
Well, until they can't figure that out, I'm
gambling.

01:00:50.040 --> 01:00:51.760
Don't wanna gamble with the cancer in me.

01:00:51.760 --> 01:00:52.760
Put the cancer out of me.

01:00:52.760 --> 01:00:56.870
As far as I'm concerned, I would always better
have more information than less.

01:00:56.870 --> 01:00:58.870
The use of what I do with that may be flawed.

01:00:58.870 --> 01:01:00.440
Maybe I shouldn't have had the operation.

01:01:00.440 --> 01:01:03.860
But I had no basis to know and it was my gamble.

01:01:03.860 --> 01:01:06.780
What the panel was saying was, "It's the pool's
gamble.

01:01:06.780 --> 01:01:07.780
It's a financial gamble."

01:01:07.780 --> 01:01:10.150
Well, I hate that.

01:01:10.150 --> 01:01:14.200
What that says is that the government is telling
you, "Better to be ignorant."

01:01:14.200 --> 01:01:16.630
That is never a good policy.

01:01:16.630 --> 01:01:19.810
More information--I gotta believe you believe
this at Google--more information is always

01:01:19.810 --> 01:01:21.690
better than less information.

01:01:21.690 --> 01:01:23.410
Heads nod.

01:01:23.410 --> 01:01:24.410
OK.

01:01:24.410 --> 01:01:30.700
So, this is where I say that I think could
Google being in the position it's in, has

01:01:30.700 --> 01:01:34.480
to find a way to fight for these kinds of
things, to demonstrate it to people, to argue

01:01:34.480 --> 01:01:39.190
for it, to lobby not just to Congress, but
to lobby to the people and start to come up

01:01:39.190 --> 01:01:43.690
with pilot groups and you're a platform for
that, and show how it's possible.

01:01:43.690 --> 01:01:47.270
And yes, it's gonna be counter-intuitive when
it comes to privacy, but that's good, too.

01:01:47.270 --> 01:01:51.981
Because you can show examples of how radical
publicness, of those who are willing, of those

01:01:51.981 --> 01:01:55.369
who chose, helped more people.

01:01:55.369 --> 01:01:57.990
That's a good thing.

01:01:57.990 --> 01:02:00.490
I guess you guys are prompt-like.

01:02:00.490 --> 01:02:05.130
I'm happy to stay and talk as long as you
like, but you won't be rude if you leave.

01:02:05.130 --> 01:02:06.950
So I guess, how's that?

01:02:06.950 --> 01:02:12.540
Anybody else wanna challenge me in any way,
or are you ready to get back to work?

01:02:12.540 --> 01:02:13.540
All right.

01:02:13.540 --> 01:02:14.540
Thank you very much.

01:02:14.540 --> 01:02:15.540
I appreciate it.

01:02:15.540 --> 01:02:15.541
[applause]

