WEBVTT
Kind: captions
Language: en

00:00:00.790 --> 00:00:06.220
&gt;&gt; From the Library of
Congress in Washington, D.C.

00:00:06.220 --> 00:00:09.950
&gt;&gt; Next we have Nick Adams, a
sociologist and research fellow

00:00:09.950 --> 00:00:12.730
at the Berkeley Institute
for Data Science.

00:00:12.730 --> 00:00:16.350
He's going to talk about how social
scientists use the congressional

00:00:16.350 --> 00:00:18.380
record as a data source.

00:00:18.380 --> 00:00:19.960
Welcome, Nick.

00:00:19.960 --> 00:00:22.290
&gt;&gt; Nick Adams: Hello, hello.

00:00:22.290 --> 00:00:27.400 position:56%
Library of Congress, archivists,
librarians, journalists, data nerds,

00:00:27.400 --> 00:00:30.440
fellow social scientists
and digital humanists.

00:00:30.440 --> 00:00:32.230
I'm very honored to be here today.

00:00:32.230 --> 00:00:36.040 position:56%
This is really exciting for me,
kind of a mecca for someone like me.

00:00:36.040 --> 00:00:40.210
I've done a lot of work with a lot
of textural data and to be able

00:00:40.210 --> 00:00:44.180
to speak here is truly an honor.

00:00:44.180 --> 00:00:48.270
For many of us, archives
evoke images

00:00:48.270 --> 00:00:52.600
of old leather-bound books
[inaudible] sweet acrid odors

00:00:52.600 --> 00:00:55.740
of oxidizing pulp, and
they arouse the excitement

00:00:55.740 --> 00:00:58.090
of discovering some
long lost history

00:00:58.090 --> 00:01:00.920 position:56%
as though it were a buried treasure.

00:01:00.920 --> 00:01:04.530
But my particular excitement
about archives is a bit different.

00:01:04.530 --> 00:01:07.210
Like all of my fellow
scholars, I swoon at the thought

00:01:07.210 --> 00:01:11.270
of uncovering old worlds and
newspapers or policy tracks,

00:01:11.270 --> 00:01:14.140
meeting minutes, contracts
or even receipts.

00:01:14.140 --> 00:01:17.500
These are the sort of documents
that most people throw away

00:01:17.500 --> 00:01:20.890
with the recycling, but we
really cherish these data

00:01:20.890 --> 00:01:23.730
as unspoiled records
of human behavior.

00:01:23.730 --> 00:01:26.560
They tell the stories of
who we were economically,

00:01:26.560 --> 00:01:30.360
politically, socially
and culturally.

00:01:30.360 --> 00:01:34.120
So I want to first say thank you to
all the librarians and archivists

00:01:34.120 --> 00:01:36.000
who make this data available.

00:01:36.000 --> 00:01:38.610
It really allows us to do our work.

00:01:38.610 --> 00:01:40.470
And we completely depend on you.

00:01:40.470 --> 00:01:43.730
So in the way that I can't
because I only have two hands,

00:01:43.730 --> 00:01:45.760
can you all help me
give a round of applause

00:01:45.760 --> 00:01:47.560 position:56%
to the people that make this happen?

00:01:47.560 --> 00:01:50.630
[ Applause ]

00:01:50.630 --> 00:01:51.930
A little louder.

00:01:51.930 --> 00:01:56.120
Okay. Maybe I should end there
some people might be thinking.

00:01:56.120 --> 00:01:58.530
I said everything that
needs to be said.

00:01:58.530 --> 00:02:03.080
But like I said, there's
a little more --

00:02:03.080 --> 00:02:05.660
my love for archives is a
bit different than typical

00:02:05.660 --> 00:02:09.140
because I think archives can
be far more powerful than most

00:02:09.140 --> 00:02:12.620
of my fellow scholars have yet
imagined, and I want to show all

00:02:12.620 --> 00:02:16.450
of you to the extent I can how
we can bring about a future

00:02:16.450 --> 00:02:20.230
where archives are used much more
often and much more intensively

00:02:20.230 --> 00:02:24.290
to give us much deeper
understanding of human behavior.

00:02:24.290 --> 00:02:27.790
So right now central scientists
and digital humanists are

00:02:27.790 --> 00:02:31.090
at the beginning of what I see
as a decade long process of kind

00:02:31.090 --> 00:02:34.270
of updating the way we work
with documentary evidence.

00:02:34.270 --> 00:02:37.450
We're learning to read
right along side computers.

00:02:37.450 --> 00:02:41.160
We're beginning to understand and
trust how they can read differently

00:02:41.160 --> 00:02:45.220
and much faster than we can
and find patterns in minutes

00:02:45.220 --> 00:02:49.010
that we really couldn't find
without months of close reading.

00:02:49.010 --> 00:02:50.340
So there's a bunch

00:02:50.340 --> 00:02:53.910
of new computational text analyst
approaches that people can use.

00:02:53.910 --> 00:02:55.730
We can [inaudible]
sentences by grammar.

00:02:55.730 --> 00:02:58.840
We can find named entities
like people and locations.

00:02:58.840 --> 00:03:02.660
We can model topics of what people
are talking about across documents.

00:03:02.660 --> 00:03:05.990
We can model networks of
individuals and how they relate.

00:03:05.990 --> 00:03:08.370
We can even do really kind of thing

00:03:08.370 --> 00:03:11.070
that a classical qualitative
ethnographic research

00:03:11.070 --> 00:03:13.900
like grounded theory with
the assistance of computers.

00:03:13.900 --> 00:03:16.320 position:56%
There's so much we can do right now,

00:03:16.320 --> 00:03:19.050
but these powerful tools
require very different ways

00:03:19.050 --> 00:03:21.950
of organizing collections
and that's what I really want

00:03:21.950 --> 00:03:23.990
to talk about today.

00:03:23.990 --> 00:03:28.590 position:56%
So most of us here are familiar with
traditional practices of archiving,

00:03:28.590 --> 00:03:32.490
the preservation, organization,
maintenance and the careful control

00:03:32.490 --> 00:03:36.350
and protection of documents and
from the researcher's standpoint,

00:03:36.350 --> 00:03:39.190
when we want to pull an
archive, we consult a librarian

00:03:39.190 --> 00:03:41.520
who helps us pull the
records and then we look

00:03:41.520 --> 00:03:43.660
at the documents usually
one document

00:03:43.660 --> 00:03:48.280
at a time often wearing gloves or
viewing through some pane of glass.

00:03:48.280 --> 00:03:50.620
And these archives
are really helpful.

00:03:50.620 --> 00:03:53.060
They allow us to ask
important specific questions

00:03:53.060 --> 00:03:57.510
of specific documents, questions
like what happened when,

00:03:57.510 --> 00:04:00.000 position:56%
did he or she really say or do that?

00:04:00.000 --> 00:04:01.540
Who paid whom?

00:04:01.540 --> 00:04:04.350
And who voted which
way on which bill?

00:04:04.350 --> 00:04:07.080
But all of this kind of research,
these questions are all kind

00:04:07.080 --> 00:04:09.560
of a forensic style of
research where we're looking

00:04:09.560 --> 00:04:12.680
for particular details at
a particular date occurring

00:04:12.680 --> 00:04:15.680
in a particular document.

00:04:15.680 --> 00:04:19.100
But now we've entered this
age of digitalization.

00:04:19.100 --> 00:04:20.400
So what's new?

00:04:20.400 --> 00:04:21.930
What's different?

00:04:21.930 --> 00:04:24.850
Obviously, no archivist or
librarian would want me to thumb

00:04:24.850 --> 00:04:28.820
through their most aged
and cherished records

00:04:28.820 --> 00:04:31.830
at 40 pages per second,
applying an array

00:04:31.830 --> 00:04:34.020
of highlighter colors
directly to the collections.

00:04:34.020 --> 00:04:37.700
I can hear some of you like
wincing at the thought.

00:04:37.700 --> 00:04:40.940 position:56%
But that sort of thing can really
easily be done with digital records.

00:04:40.940 --> 00:04:43.420
So how is that going
to change research

00:04:43.420 --> 00:04:47.830
and how are we going
to adapt to that?

00:04:47.830 --> 00:04:51.370
Exciting. So did we go too fast?

00:04:51.370 --> 00:04:52.670
We went past.

00:04:52.670 --> 00:04:53.970
Oh, there it goes.

00:04:53.970 --> 00:04:56.640
Okay. So there are some
digital archiving products

00:04:56.640 --> 00:04:58.200
that are really plowing forward.

00:04:58.200 --> 00:05:00.830
So chronicling America, a
bunch of people have mentioned,

00:05:00.830 --> 00:05:02.690
is allowing researchers
to skim through thousands

00:05:02.690 --> 00:05:05.190
of newspapers using
digital approaches.

00:05:05.190 --> 00:05:07.080
And in this talk series
a while back,

00:05:07.080 --> 00:05:11.310
Matthew Weber's archives
unleash program was discussed,

00:05:11.310 --> 00:05:14.640
and it's generating valuable
findings hacking away

00:05:14.640 --> 00:05:17.460
at what he has called
well curated archives,

00:05:17.460 --> 00:05:19.350
but these are not really the norm.

00:05:19.350 --> 00:05:23.680
Actually, what's normal
is quite a bit different.

00:05:23.680 --> 00:05:27.480
As Elizabeth Lorang mentioned
during her talk in this series,

00:05:27.480 --> 00:05:31.200 position:56%
one of the most prominent challenges
cited by respondents in their use

00:05:31.200 --> 00:05:34.920
of digital collections was the
inability to search effectively

00:05:34.920 --> 00:05:37.840
through the collection materials,
and this is really common.

00:05:37.840 --> 00:05:42.410
To give you an example, the
government publishing office --

00:05:42.410 --> 00:05:46.830
the GPO website has a lot of really
impressive holdings describing the

00:05:46.830 --> 00:05:49.670
activities of our government, the
congressional record, hearings,

00:05:49.670 --> 00:05:53.620
all kinds of votes, and these data
are really essential to democracy

00:05:53.620 --> 00:05:56.700
and to the GPO's mission of
keeping America informed.

00:05:56.700 --> 00:05:59.030
The data are really valuable.

00:05:59.030 --> 00:06:00.330
They're important.

00:06:00.330 --> 00:06:03.150
They're totally available to
the public, which is great,

00:06:03.150 --> 00:06:05.690
and they're even digitized
in an ideal kind

00:06:05.690 --> 00:06:08.370
of machine readable format.

00:06:08.370 --> 00:06:11.950
Yet, they're extremely difficult
to research using this state

00:06:11.950 --> 00:06:15.620
of art text analysis
techniques that I just discussed.

00:06:15.620 --> 00:06:19.360
Let me give you a sense
of what that looks like.

00:06:19.360 --> 00:06:20.930
Here's a GPO website.

00:06:20.930 --> 00:06:25.850
So if I wanted to understand how
my congress person is dealing

00:06:25.850 --> 00:06:28.970
with science, I could go
to a particular congress.

00:06:28.970 --> 00:06:32.270
I could go to the house hearings.

00:06:32.270 --> 00:06:36.610
I could look for the committee
on science and technology

00:06:36.610 --> 00:06:42.060 position:56%
and then I could read the text of
every last committee hearing and try

00:06:42.060 --> 00:06:47.470
to follow along with what my
congress person was doing.

00:06:47.470 --> 00:06:50.880
So we select a file, we
read it in the viewer,

00:06:50.880 --> 00:06:54.540
in this case a web browser, and
we view it without touching it,

00:06:54.540 --> 00:06:58.010
without labeling it, without
scribbling on it and we have

00:06:58.010 --> 00:07:00.140
to take our notes in
the separate document.

00:07:00.140 --> 00:07:03.630
So in a lot of ways, even though
this text is fully digital,

00:07:03.630 --> 00:07:05.030
we're still wearing the gloves.

00:07:05.030 --> 00:07:10.910
We're still looking at a document
from behind a pane of glass.

00:07:10.910 --> 00:07:15.340
Now to be clear, I don't believe
this is the state of affairs

00:07:15.340 --> 00:07:18.800
because archivists are
somehow over protective

00:07:18.800 --> 00:07:21.350
or uninterested or just ornery.

00:07:21.350 --> 00:07:23.590
Maybe some of you are.

00:07:23.590 --> 00:07:26.680
But this is a very well
organized set of links

00:07:26.680 --> 00:07:29.720
that makes perfect sense for
human looking for information

00:07:29.720 --> 00:07:31.450
about a particular hearing.

00:07:31.450 --> 00:07:34.520
And we organize our
digital records this way,

00:07:34.520 --> 00:07:37.020
the same way we would
organize our physical records

00:07:37.020 --> 00:07:41.000
because these systems are so
sensible for traditional research

00:07:41.000 --> 00:07:44.820
and so expedient for
archivist's fundamental tasks

00:07:44.820 --> 00:07:47.110
of preservation and publication.

00:07:47.110 --> 00:07:51.810
So if we don't want to
click and click and click

00:07:51.810 --> 00:07:56.520
and download each file, what
do social scientists want?

00:07:56.520 --> 00:07:59.450
I know this is the
question of Washington.

00:07:59.450 --> 00:08:02.980
Every funding conversation,
every policy conversation.

00:08:02.980 --> 00:08:05.250
What do the social scientists want?

00:08:05.250 --> 00:08:06.550
I can dream.

00:08:06.550 --> 00:08:07.850
I can dream.

00:08:07.850 --> 00:08:09.470
Well, we want data that
are well structured.

00:08:09.470 --> 00:08:10.790
That's what we want.

00:08:10.790 --> 00:08:13.780
And I'll have a slide in a moment
that kind of lays that out.

00:08:13.780 --> 00:08:17.170
But let me offer you a sense
just through some examples.

00:08:17.170 --> 00:08:19.380
Perhaps we want to
see all the materials

00:08:19.380 --> 00:08:22.420
in the congressional record or
it could be for any archive,

00:08:22.420 --> 00:08:25.380
we want to see all the materials
that are authored by men or women

00:08:25.380 --> 00:08:27.920
or people from this or
that geographic region.

00:08:27.920 --> 00:08:30.560
All instances we're
[inaudible] particular phrase

00:08:30.560 --> 00:08:33.980
like interstate commerce and
the date of the utterance.

00:08:33.980 --> 00:08:35.280
Who said it?

00:08:35.280 --> 00:08:38.000 position:56%
The district they represent if we're
looking at the congressional record.

00:08:38.000 --> 00:08:41.570
Even adjectives that are marshalled
to describe particular nouns

00:08:41.570 --> 00:08:44.270
like veteran, teacher,
doctor or child.

00:08:44.270 --> 00:08:46.150
How are these people described?

00:08:46.150 --> 00:08:50.200
Perhaps I want to assess the
comfort of congress members

00:08:50.200 --> 00:08:51.830
with the scientific process.

00:08:51.830 --> 00:08:53.600 position:56%
So I want to do some sort of search,

00:08:53.600 --> 00:08:56.390
and this is just a little
bit pseudo code here.

00:08:56.390 --> 00:08:58.530
I want to see if I
can find all instances

00:08:58.530 --> 00:09:03.070 position:56%
where people say the word hypothesis
or falsify, correlation, causation,

00:09:03.070 --> 00:09:05.450
statistical significance
and if I find that,

00:09:05.450 --> 00:09:09.080
then I want to see the speech
displayed along with the idea

00:09:09.080 --> 00:09:11.810
of the speaker, the
identification of the speaker,

00:09:11.810 --> 00:09:17.020
the party they're associated
with, etc. That would be --

00:09:17.020 --> 00:09:19.890
that would be really nice, and
I'd be able to kind of compare

00:09:19.890 --> 00:09:22.470
across the entire congressional
record how people are talking

00:09:22.470 --> 00:09:25.490
about science.

00:09:25.490 --> 00:09:30.490
But that's not really
what we have right now.

00:09:30.490 --> 00:09:32.970
That's just not possible on the
government publishing office

00:09:32.970 --> 00:09:36.750
and those sorts of questions
that dig into both the metadata

00:09:36.750 --> 00:09:40.580
and the content of the text itself
are not really possible right now.

00:09:40.580 --> 00:09:44.610
So we can't search all the text
of all the science hearings.

00:09:44.610 --> 00:09:49.000
We can't easily identify particular
speeches and speakers even though

00:09:49.000 --> 00:09:51.040
as a reader, if I read
through that document,

00:09:51.040 --> 00:09:56.090 position:56%
I know when member Jones is speaking
and when member Smith is speaking.

00:09:56.090 --> 00:09:58.630
And I can't immediately know
the party identification

00:09:58.630 --> 00:10:02.550
of the person even though this
is really common knowledge.

00:10:02.550 --> 00:10:06.010
This stuff is not actually
connected to the data right there

00:10:06.010 --> 00:10:09.510
as a researcher when
I want to query it.

00:10:09.510 --> 00:10:14.800
So what do social scientists
do with archives like the GPO?

00:10:14.800 --> 00:10:21.330
Well, the answer is not much
because it's just too hard to look

00:10:21.330 --> 00:10:25.630 position:56%
through all that data one document
at a time or to learn all the skills

00:10:25.630 --> 00:10:28.100
to figure out how to
bring it together

00:10:28.100 --> 00:10:30.790
so that you can search it the
way you want to search it.

00:10:30.790 --> 00:10:34.270
But I'm here today -- that's
[inaudible] the talk either.

00:10:34.270 --> 00:10:39.070
We don't have to sigh and walk
away with our heads held down.

00:10:39.070 --> 00:10:41.990 position:56%
I'm here to talk about an effort
that's trying to help change that --

00:10:41.990 --> 00:10:44.000
the Capitol Query Project.

00:10:44.000 --> 00:10:47.620
So a few years ago, I founded the
computational text analysis working

00:10:47.620 --> 00:10:49.510
group at UC Berkeley.

00:10:49.510 --> 00:10:51.610
And a key [inaudible] of
that group's mention was

00:10:51.610 --> 00:10:54.130
to not just teach researchers
how to fish,

00:10:54.130 --> 00:10:57.480
but to teach a research
team how to whale.

00:10:57.480 --> 00:11:01.890
No marine mammals have been
harmed just so you know.

00:11:01.890 --> 00:11:05.360
But to teach a research
team how to organize --

00:11:05.360 --> 00:11:09.750 position:56%
how to do the massive amount of work
necessary to acquire clean process,

00:11:09.750 --> 00:11:14.030
analyze, interpret and report
on massive textual archives.

00:11:14.030 --> 00:11:15.940
Now we're partnering
with the Goodly Labs

00:11:15.940 --> 00:11:17.850
and the Social Science
Research Council

00:11:17.850 --> 00:11:21.770
so that we can not only convert the
government publishing office data

00:11:21.770 --> 00:11:25.770
into a queriable record
of what congress is up to,

00:11:25.770 --> 00:11:29.140
but also so that we can create
tutorials showing anyone how

00:11:29.140 --> 00:11:31.630
to do this for their
own digital collections.

00:11:31.630 --> 00:11:34.240
I just want to recognize some

00:11:34.240 --> 00:11:36.970
of my teammates here quickly
before I say a little bit more

00:11:36.970 --> 00:11:38.510
about the project.

00:11:38.510 --> 00:11:41.800
And any of you could
join this slide.

00:11:41.800 --> 00:11:43.510
We'll talk about that later.

00:11:43.510 --> 00:11:46.470
So here's a project in pictures.

00:11:46.470 --> 00:11:49.230
First thing we're going to do is
we're going to gather all the data,

00:11:49.230 --> 00:11:51.950
all the documents across all
those links into one place.

00:11:51.950 --> 00:11:56.370
And then next, we're finding and
labeling structures in the text.

00:11:56.370 --> 00:12:00.140
So maybe we're looking for
particular speech acts or events

00:12:00.140 --> 00:12:04.040
or locations or ad hoc groups,
and we can add that structure

00:12:04.040 --> 00:12:08.120
to the text through
annotations through XML.

00:12:08.120 --> 00:12:11.920
And then we take the existing
structure that was already there

00:12:11.920 --> 00:12:15.360
with the newly created
structure, and link it into --

00:12:15.360 --> 00:12:18.330
with external data sources
that enable us to --

00:12:18.330 --> 00:12:21.580
that enable powerful
queries answering questions

00:12:21.580 --> 00:12:23.720
that we couldn't even ask before.

00:12:23.720 --> 00:12:28.380 position:56%
So let me say a little bit about
well structured research ready data.

00:12:28.380 --> 00:12:32.800
That's the hard product of this
project is to create a database,

00:12:32.800 --> 00:12:35.930
and for the record, we should now
what well structured research ready

00:12:35.930 --> 00:12:37.230
data looks like.

00:12:37.230 --> 00:12:39.320
First of all, it should
be digital text.

00:12:39.320 --> 00:12:41.670
It should be machine readable
so that a computer can look

00:12:41.670 --> 00:12:45.360
for different tokens and compare
across various different documents.

00:12:45.360 --> 00:12:49.680
It should be queriable with that
token search but also across a set

00:12:49.680 --> 00:12:53.070
of documents that the
researcher has defined.

00:12:53.070 --> 00:12:55.620
So if they want everything from
Arizona or they want everything

00:12:55.620 --> 00:12:58.640
from a decade, should be able
to look at that immediately.

00:12:58.640 --> 00:13:02.670
This is really important and
a lot of people when they move

00:13:02.670 --> 00:13:05.230
into a digital archive
and then they try

00:13:05.230 --> 00:13:08.160
to make it public,
they make this mistake.

00:13:08.160 --> 00:13:10.880
It's really important to
retain the original structure

00:13:10.880 --> 00:13:12.320
and formatting of the documents.

00:13:12.320 --> 00:13:14.400
So I'm going to ding proquest here.

00:13:14.400 --> 00:13:16.310
I don't think anyone's
going to be too upset.

00:13:16.310 --> 00:13:18.520
Proquest takes a congressional
record, and they strip it

00:13:18.520 --> 00:13:20.980
of all the white space,
all the new line characters

00:13:20.980 --> 00:13:24.390
and the paragraph breaks, and
these subheadings that help us read

00:13:24.390 --> 00:13:27.330 position:56%
through the document and understand,
oh, this is just the table

00:13:27.330 --> 00:13:30.110
of contents or this is a
portion where they're going

00:13:30.110 --> 00:13:33.260
to do some prematter, but
they're not really talking

00:13:33.260 --> 00:13:34.620
about the hearing yet.

00:13:34.620 --> 00:13:36.440
It's important to retain
the original structure

00:13:36.440 --> 00:13:41.230
that the original authors used
to keep track of which portions

00:13:41.230 --> 00:13:44.880
of the text are doing what
sort of conceptual work.

00:13:44.880 --> 00:13:48.600
And then as much as possible, we
want to add in some supplemental

00:13:48.600 --> 00:13:52.890
and searchable annotations on
the text, things like I said,

00:13:52.890 --> 00:13:57.150
looking for speech acts or speakers
or locations, etc. And finally,

00:13:57.150 --> 00:14:00.200
we want to be able to link
the data to other data

00:14:00.200 --> 00:14:02.030
that describe the same objects.

00:14:02.030 --> 00:14:06.800 position:56%
So that hearing document is going
to talk about congress member Smith,

00:14:06.800 --> 00:14:09.380
but there's a lot I know
about congress member Smith

00:14:09.380 --> 00:14:15.100
in another database that tells me
about her age and her district,

00:14:15.100 --> 00:14:17.110
population and demographics
of her district,

00:14:17.110 --> 00:14:21.110
which might actually influence
the way she's behaving.

00:14:21.110 --> 00:14:25.320
So in all of this, we're not just
creating a queriable database,

00:14:25.320 --> 00:14:28.090
but there's a huge learning
opportunity here for anyone

00:14:28.090 --> 00:14:31.340
that wants to take their digital
archive and make it more accessible

00:14:31.340 --> 00:14:35.170
to a larger audience of
researchers and the public.

00:14:35.170 --> 00:14:39.580
So we're going to be creating
a kind of step by step how

00:14:39.580 --> 00:14:42.080
to guide with tutorial notebooks.

00:14:42.080 --> 00:14:45.430
We'll be using Jupyter
notebooks which allow us to write

00:14:45.430 --> 00:14:49.030
in plain English what we're
doing right next to a cell

00:14:49.030 --> 00:14:51.890
that runs executable code.

00:14:51.890 --> 00:14:55.190
So for all those of you who are
a little afraid of programming,

00:14:55.190 --> 00:15:00.160 position:56%
the idea is to take you step by step
through the process of doing this.

00:15:00.160 --> 00:15:04.060
So phase one, gathering the data
together, phase two, finding

00:15:04.060 --> 00:15:06.250
and adding structure to
it and then phase three,

00:15:06.250 --> 00:15:08.450
linking it to other useful data.

00:15:08.450 --> 00:15:12.630
To dig into these a
little bit, in phase one,

00:15:12.630 --> 00:15:15.700
bring all your data together,
this is just trying to get

00:15:15.700 --> 00:15:19.550
around pointing, clicking and
downloading a thousand times.

00:15:19.550 --> 00:15:22.700
And so we can actually
train a computer to do this

00:15:22.700 --> 00:15:25.790
or we can train people to
tell a computer how to do it.

00:15:25.790 --> 00:15:30.100 position:56%
So we'll be turning people in these
notebooks to use regular expressions

00:15:30.100 --> 00:15:33.360
to use [inaudible] so that
they can look on a website

00:15:33.360 --> 00:15:38.050
and with a web browser automation
tool like [inaudible] instead

00:15:38.050 --> 00:15:39.710
of doing all that pointing
and clicking yourself,

00:15:39.710 --> 00:15:41.960
you can have a computer
do it for you.

00:15:41.960 --> 00:15:45.110
Phase two is really
where were trying to move

00:15:45.110 --> 00:15:47.550
from the current state of the art,

00:15:47.550 --> 00:15:50.500
which is kind of a
craft to a science.

00:15:50.500 --> 00:15:54.700
Finding structure in texts is --
it takes a lot of working back

00:15:54.700 --> 00:15:58.800
and forth with the text, knowing
what is theoretically important

00:15:58.800 --> 00:16:03.150
that you're trying to find there,
and then using the computer

00:16:03.150 --> 00:16:07.110
to help you find that structure
to chunk it out, to label it

00:16:07.110 --> 00:16:09.610
and to add structure
where there wasn't before.

00:16:09.610 --> 00:16:13.140
So we take people through the
very basics of regular expressions

00:16:13.140 --> 00:16:18.580 position:56%
and how to use XML, and we show them
some of the text analysis techniques

00:16:18.580 --> 00:16:21.140
that I talked about at
the top of the talk,

00:16:21.140 --> 00:16:26.580
and we're even using crowdsource
annotation software called text

00:16:26.580 --> 00:16:28.800
[inaudible] which is
also a technology created

00:16:28.800 --> 00:16:30.330
by the Goodly Labs.

00:16:30.330 --> 00:16:32.940
All of these things allow
us to get the humans

00:16:32.940 --> 00:16:37.070
and the computers together working
to find that structure in the text.

00:16:37.070 --> 00:16:39.810
And then in order to do
this really efficiently

00:16:39.810 --> 00:16:42.470
with a programming script, you need

00:16:42.470 --> 00:16:45.490
to know some basic programming
architecture that's not super hard

00:16:45.490 --> 00:16:48.850
to learn but we'll teach it.

00:16:48.850 --> 00:16:54.640
Finally in phase three, phase three
is about linking all of that data.

00:16:54.640 --> 00:16:57.220
So it's identifying
relevant data sources,

00:16:57.220 --> 00:16:59.720
effectively structuring
your database

00:16:59.720 --> 00:17:02.640
so that you're anticipating the
queries of the research community

00:17:02.640 --> 00:17:06.470
and you're also reducing
redundancies in the data storage.

00:17:06.470 --> 00:17:10.420
Paul who spoke just before me
really kind of set this up.

00:17:10.420 --> 00:17:14.130
If we can use SQL and
relational databases,

00:17:14.130 --> 00:17:17.860
we can compute much more
quickly over some of this sort

00:17:17.860 --> 00:17:22.010
of multilayered structured text.

00:17:22.010 --> 00:17:28.670
So to close really, I just want to
ask you all to get research ready.

00:17:28.670 --> 00:17:32.930
We'll be pushing some of this
out in November, and we're hoping

00:17:32.930 --> 00:17:36.270
that people will give us
feedback and let us know

00:17:36.270 --> 00:17:38.440
like your phase one
tutorials were great.

00:17:38.440 --> 00:17:41.090
Your phase two tutorials
were quite confusing,

00:17:41.090 --> 00:17:43.080
and you need to go back
to the drawing board.

00:17:43.080 --> 00:17:46.410
We're really looking for engagement
from the Library of Congress

00:17:46.410 --> 00:17:50.670
and any libraries or archives or
researchers who are interested

00:17:50.670 --> 00:17:55.430
in getting in on this, and I
don't know if they cut me off,

00:17:55.430 --> 00:17:57.020
but it seems they cut me off.

00:17:57.020 --> 00:17:59.970
Oh, here we go.

00:17:59.970 --> 00:18:02.660
Yeah. So if you'd like
to join in this effort

00:18:02.660 --> 00:18:04.850
or follow along, here
are some links.

00:18:04.850 --> 00:18:06.840
What I was going to show you

00:18:06.840 --> 00:18:13.820
if I could is the entire project
is completely open to the public.

00:18:13.820 --> 00:18:18.760
You can go to the open
society framework that's hosted

00:18:18.760 --> 00:18:21.650
by the Center for Open
Science and you can watch

00:18:21.650 --> 00:18:23.580
and follow along with our project.

00:18:23.580 --> 00:18:27.140
If you want to jump in, you can
actually go to our [inaudible] page

00:18:27.140 --> 00:18:29.220
and just start doing pull requests.

00:18:29.220 --> 00:18:32.180
That would be exciting, although
feel free to contact us first

00:18:32.180 --> 00:18:34.410
and maybe we can lead you

00:18:34.410 --> 00:18:37.740
to the work that's most
pressing at the moment.

00:18:37.740 --> 00:18:41.260 position:56%
But I really appreciate everything
that everyone in this room is doing,

00:18:41.260 --> 00:18:44.400
and I'm really looking
forward to getting to this kind

00:18:44.400 --> 00:18:46.740
of blue sky space in the future.

00:18:46.740 --> 00:18:48.040
So help us out as you can.

00:18:48.040 --> 00:18:49.680
Thanks a lot.

00:18:49.680 --> 00:18:52.010
[ Applause ]

00:18:52.010 --> 00:18:55.660
&gt;&gt; This has been a presentation
of the Library of Congress.

00:18:55.660 --> 00:18:57.970
Visit us at loc.gov.

