WEBVTT
Kind: captions
Language: en

00:00:04.910 --> 00:00:12.275
[APPLAUSE]

00:00:17.530 --> 00:00:20.666
DIANE GREENE: Hi, everybody.

00:00:20.666 --> 00:00:21.850
I'm Diane Greene.

00:00:21.850 --> 00:00:24.610
I run Google's phenomenal Cloud.

00:00:24.610 --> 00:00:29.000
I'm on the board of Alphabet,
and I'm incredibly proud today

00:00:29.000 --> 00:00:34.470
to be here moderating this
panel of just absolute leading

00:00:34.470 --> 00:00:38.970
experts, leading
researchers, and experts

00:00:38.970 --> 00:00:42.540
in artificial intelligence
and machine learning.

00:00:42.540 --> 00:00:46.600
We're going to
structure our panel

00:00:46.600 --> 00:00:50.040
talking about past,
present, and future, closing

00:00:50.040 --> 00:00:53.170
with some personal
reflections on the industry

00:00:53.170 --> 00:00:54.610
and our careers.

00:00:54.610 --> 00:00:57.190
And before I do
that, I'm just going

00:00:57.190 --> 00:00:59.660
to quickly introduce everybody.

00:00:59.660 --> 00:01:03.300
First is Francoise Beaufays.

00:01:03.300 --> 00:01:06.180
She's principal
scientist at Google

00:01:06.180 --> 00:01:12.020
and is the leader of speech
recognition at Google,

00:01:12.020 --> 00:01:13.440
something everybody uses.

00:01:13.440 --> 00:01:18.440
[APPLAUSE]

00:01:18.440 --> 00:01:21.050
Been at Google 12 years.

00:01:21.050 --> 00:01:24.910
Second is Fei-Fei Li.

00:01:24.910 --> 00:01:27.365
She's the chief scientist
of Google Cloud.

00:01:27.365 --> 00:01:30.110
[APPLAUSE]

00:01:30.110 --> 00:01:33.630
Bringing AI and ML to
companies all over the world,

00:01:33.630 --> 00:01:36.690
also head of Stanford's
AI Lab, and inventor

00:01:36.690 --> 00:01:39.350
of imageNet and
imageNet Challenge,

00:01:39.350 --> 00:01:42.660
which really contributed
to some of our developments

00:01:42.660 --> 00:01:43.890
in deep learning and AI.

00:01:43.890 --> 00:01:46.250
And she's also a
champion of STEM and AI

00:01:46.250 --> 00:01:49.980
and the founder of AI for All.

00:01:49.980 --> 00:01:54.520
Next, Fernanda Viegas?

00:01:54.520 --> 00:01:57.110
She's a senior staff
researcher at Google,

00:01:57.110 --> 00:02:00.760
she's a computational
designer, she

00:02:00.760 --> 00:02:03.960
focuses on the scientific
and collaborative aspects

00:02:03.960 --> 00:02:08.639
of information visualization,
co-leads the Big Picture data

00:02:08.639 --> 00:02:12.790
visualization group, she's
part of Google Brain,

00:02:12.790 --> 00:02:17.010
and she's also known for her
visualization-based artwork,

00:02:17.010 --> 00:02:19.540
which is part of the permanent
collection of the Museum

00:02:19.540 --> 00:02:22.328
of Modern Art in New York.

00:02:22.328 --> 00:02:27.680
[APPLAUSE]

00:02:27.680 --> 00:02:30.260
And then, let me introduce
Daphne Koller, who

00:02:30.260 --> 00:02:35.900
today is chief computing officer
at Calico, Calico Labs, which

00:02:35.900 --> 00:02:39.670
is a part of Alphabet,
working to give people

00:02:39.670 --> 00:02:41.255
longer and healthier lives.

00:02:44.340 --> 00:02:48.710
She spent 18 years at Stanford--

00:02:48.710 --> 00:02:52.180
she led the AI group
there, she cofounded

00:02:52.180 --> 00:02:57.420
Coursera, which is the
largest platform for MOOC's

00:02:57.420 --> 00:03:01.990
massively online courses--

00:03:01.990 --> 00:03:04.040
open online courses.

00:03:04.040 --> 00:03:08.010
And you know, Daphne was
one of "Time Magazine's"

00:03:08.010 --> 00:03:10.630
100 most influential
people in 2012,

00:03:10.630 --> 00:03:13.390
she won a MacArthur
Foundation award,

00:03:13.390 --> 00:03:17.690
she won the inaugural
ACM prize for computing,

00:03:17.690 --> 00:03:20.480
she's a member of the Academy of
Arts and Sciences, the Academy

00:03:20.480 --> 00:03:22.240
of Engineering--
and those are just

00:03:22.240 --> 00:03:25.960
some of the proof points
of her excellence.

00:03:25.960 --> 00:03:32.460
[APPLAUSE]

00:03:32.460 --> 00:03:36.050
So we'll start with a
historical perspective.

00:03:36.050 --> 00:03:40.630
And Daphne, as one of the most
prominent and prolific authors

00:03:40.630 --> 00:03:43.940
of machine learning
research papers,

00:03:43.940 --> 00:03:47.940
can you give us your
perspective on how we've

00:03:47.940 --> 00:03:50.580
transitioned to deep learning?

00:03:50.580 --> 00:03:52.830
DAPHNE KOLLER: So I think
the deep learning revolution

00:03:52.830 --> 00:03:56.870
is a truly exciting enabler
that we're seeing today

00:03:56.870 --> 00:04:00.130
in so many aspects of so
many real world problems.

00:04:00.130 --> 00:04:03.710
But that revolution
came out of an outgrowth

00:04:03.710 --> 00:04:07.600
of a lot of machine learning
research that lead up to it.

00:04:07.600 --> 00:04:10.770
So prior to deep learning,
there were probably

00:04:10.770 --> 00:04:15.020
about 10 or 15 years of very
hard work in developing models

00:04:15.020 --> 00:04:17.529
that were maybe
more hand-crafted

00:04:17.529 --> 00:04:21.070
that required a lot more thought
and a lot more prior knowledge.

00:04:21.070 --> 00:04:23.750
And we really had to sync
through the specifics

00:04:23.750 --> 00:04:27.320
of the model and how it
relates to the domain.

00:04:27.320 --> 00:04:29.490
Because when you don't
have a lot of data,

00:04:29.490 --> 00:04:33.190
you have to replace that
with a lot of human intuition

00:04:33.190 --> 00:04:35.990
on how the model ought
to be constructed.

00:04:35.990 --> 00:04:39.330
As we've gotten more and
more data in certain domains,

00:04:39.330 --> 00:04:42.600
text and images being I think
the two prime examples--

00:04:42.600 --> 00:04:44.830
and speech of course, as well--

00:04:44.830 --> 00:04:50.540
we've started to replace a lot
of that need for human insight

00:04:50.540 --> 00:04:56.730
with more and more data
that counterbalances that.

00:04:56.730 --> 00:04:59.570
But the techniques that were
developed in those 10 or 15

00:04:59.570 --> 00:05:03.670
years are still pivotal
today, both in the methods

00:05:03.670 --> 00:05:07.430
themselves-- those optimization
algorithms that were developed

00:05:07.430 --> 00:05:10.750
over the last 10 or
15 years are still

00:05:10.750 --> 00:05:14.890
a key component of what enables
deep learning to be successful.

00:05:14.890 --> 00:05:17.040
And I think that
while we might like

00:05:17.040 --> 00:05:19.940
to think that big
data is at this point

00:05:19.940 --> 00:05:23.410
the solution to everything, it's
a solution in certain domain

00:05:23.410 --> 00:05:26.690
areas but, in others, we
still are unfortunately

00:05:26.690 --> 00:05:30.870
in the medium or sometimes
even small data regime.

00:05:30.870 --> 00:05:33.010
And so they're still
definitely a need

00:05:33.010 --> 00:05:39.480
for balancing human intuition
about the domain with the data

00:05:39.480 --> 00:05:41.910
that were acquiring and
coming up with a model that

00:05:41.910 --> 00:05:45.210
incorporates the best of both.

00:05:45.210 --> 00:05:46.210
DIANE GREENE: Thank you.

00:05:46.210 --> 00:05:49.470
And Fei-Fei, can we also
get your perspective?

00:05:49.470 --> 00:05:52.650
You're running the
Stanford AI Lab,

00:05:52.650 --> 00:05:57.000
your imageNet work was seminal,
and now you're bringing--

00:05:57.000 --> 00:06:00.350
you're looking at bringing AI
to every company in the world.

00:06:00.350 --> 00:06:02.880
What is going on
with that transition?

00:06:02.880 --> 00:06:03.630
FEI-FEI LI: Right.

00:06:03.630 --> 00:06:04.510
Thank you, Dianne.

00:06:04.510 --> 00:06:08.660
So just a little bit of
a historical perspective

00:06:08.660 --> 00:06:12.690
that AI in all sciences
of human civilization

00:06:12.690 --> 00:06:14.970
is actually a very young field.

00:06:14.970 --> 00:06:18.790
We're about 60 years old,
but the very question

00:06:18.790 --> 00:06:21.280
of the quest for
intelligence, in my opinion,

00:06:21.280 --> 00:06:25.570
is what's at the root
of AI's inspiration.

00:06:25.570 --> 00:06:27.940
And that dates back
since the beginning

00:06:27.940 --> 00:06:30.440
of the dawn of civilization.

00:06:30.440 --> 00:06:34.840
So about 60 years ago,
when machines started

00:06:34.840 --> 00:06:37.190
to compute and
calculate at that time

00:06:37.190 --> 00:06:42.000
very simple arithmetics, already
thinkers like Alan Turing

00:06:42.000 --> 00:06:46.350
challenged humanity with the
question, can machines think?

00:06:46.350 --> 00:06:48.540
Can machines have intelligence?

00:06:48.540 --> 00:06:52.630
So about 60 years ago,
leading computer scientists

00:06:52.630 --> 00:06:56.330
like Marvin Minsky, Joe
McCarthy, and many others

00:06:56.330 --> 00:07:00.060
got together and really
jump-started the field

00:07:00.060 --> 00:07:02.866
that today we know as AI.

00:07:02.866 --> 00:07:05.550
The AI that the
founding fathers saw

00:07:05.550 --> 00:07:09.920
was very different
technically 60 years ago.

00:07:09.920 --> 00:07:16.000
But it was the same core
dreams which is making machines

00:07:16.000 --> 00:07:21.920
to learn, to reason, to
think, to perceive, to speak,

00:07:21.920 --> 00:07:23.400
to communicate.

00:07:23.400 --> 00:07:29.170
And AI has gone through several
waves of technical development,

00:07:29.170 --> 00:07:32.980
from first order logic
to experts systems

00:07:32.980 --> 00:07:36.600
to the early waves of
machine learning to today--

00:07:36.600 --> 00:07:39.110
the deep-learning revolution.

00:07:39.110 --> 00:07:44.980
I would say the past 60 years,
I call it the in-vitro AI,

00:07:44.980 --> 00:07:46.750
or AI in-vitro.

00:07:46.750 --> 00:07:49.920
It's the 60 years
there, as a field,

00:07:49.920 --> 00:07:55.270
we laid the foundation
of the questions we ask,

00:07:55.270 --> 00:08:00.040
the sub-fields that are
essential to AI's quest like,

00:08:00.040 --> 00:08:03.860
robotics, computer vision,
natural language processing,

00:08:03.860 --> 00:08:07.890
speech processing, [? comp ?]
[? bio, ?] and so on.

00:08:07.890 --> 00:08:12.520
But also the way we measure the
progress to understand our data

00:08:12.520 --> 00:08:15.420
and discover the tool sets.

00:08:15.420 --> 00:08:22.730
So around 2010, around that
time, thanks to the convergence

00:08:22.730 --> 00:08:27.350
of the maturing of statistical
machine learning tools,

00:08:27.350 --> 00:08:30.270
the convergence of
big data brought to us

00:08:30.270 --> 00:08:33.110
by the internet,
and by the sensors,

00:08:33.110 --> 00:08:37.539
and the convergence of computing
that Moore's law carried us

00:08:37.539 --> 00:08:39.809
to much better hardware.

00:08:39.809 --> 00:08:42.820
These three pillars
came together

00:08:42.820 --> 00:08:46.610
and lifted AI from
the in-vitro stage

00:08:46.610 --> 00:08:49.700
into what I call
the in-vivo stage.

00:08:49.700 --> 00:08:55.860
AI in-vivo is where AI is making
a real impact to the world.

00:08:55.860 --> 00:08:57.540
It's just the beginning.

00:08:57.540 --> 00:09:02.390
Every single industry
at Cloud, at Google,

00:09:02.390 --> 00:09:06.810
we see is going through a
transformation because of data,

00:09:06.810 --> 00:09:11.160
because of AI, and
machine learning.

00:09:11.160 --> 00:09:14.860
And this is what I see
as the historical moment

00:09:14.860 --> 00:09:19.810
that AI is going to impact
and transform the field.

00:09:19.810 --> 00:09:23.510
But I also do want to say
it's just the beginning.

00:09:23.510 --> 00:09:25.470
The tools and the
technologies we

00:09:25.470 --> 00:09:28.640
have developed in
the field of AI

00:09:28.640 --> 00:09:34.480
is really the first few drops
of water in a vast ocean of what

00:09:34.480 --> 00:09:36.830
AI can do.

00:09:36.830 --> 00:09:42.910
We cannot over-promise this,
but there should be tremendous

00:09:42.910 --> 00:09:49.260
excitement that we can do, a lot
more work to do to make this AI

00:09:49.260 --> 00:09:51.580
in-vivo happen

00:09:51.580 --> 00:09:53.250
DIANE GREENE: I share
your excitement.

00:09:53.250 --> 00:09:55.410
This in-vivo state,
I mean companies

00:09:55.410 --> 00:09:59.410
are putting virtual renditions
of themselves in the cloud

00:09:59.410 --> 00:10:04.620
and then they're using AI to
do things nobody ever thought

00:10:04.620 --> 00:10:05.810
was possible.

00:10:05.810 --> 00:10:10.640
And AI's being used everywhere,
not just in the cloud.

00:10:10.640 --> 00:10:11.790
So thank you.

00:10:11.790 --> 00:10:14.270
If we dive a little
deeper, Francoise,

00:10:14.270 --> 00:10:19.170
you've been at the frontier
of speech recognition and now

00:10:19.170 --> 00:10:21.210
in applications,
speech recognition

00:10:21.210 --> 00:10:23.910
is actually becoming
almost commonplace.

00:10:23.910 --> 00:10:26.270
Can you take us through
that transition?

00:10:26.270 --> 00:10:28.070
FRANCOISE BEAUFAYS:
Yes, certainly.

00:10:28.070 --> 00:10:31.690
So I joined Google
about 12 years ago.

00:10:31.690 --> 00:10:34.740
And a bunch of us
came with this vision

00:10:34.740 --> 00:10:39.060
of doing something useful and
fun with speech recognition.

00:10:39.060 --> 00:10:41.610
Speech recognition had been
around for quite awhile.

00:10:41.610 --> 00:10:44.280
All of us had some
background in the field,

00:10:44.280 --> 00:10:47.070
but we wanted to
do something fun.

00:10:47.070 --> 00:10:51.840
And that was hard because speech
wasn't the quality it is now.

00:10:51.840 --> 00:10:55.300
So we started with
fairly limited products

00:10:55.300 --> 00:10:59.280
where the task of recognizing
what the person says

00:10:59.280 --> 00:11:01.460
wasn't too, too complicated.

00:11:01.460 --> 00:11:03.940
We were just trying to push
the envelope a little bit

00:11:03.940 --> 00:11:05.610
but not much.

00:11:05.610 --> 00:11:07.710
Because we needed to
bring it to a place

00:11:07.710 --> 00:11:11.800
where the product was successful
enough that people would want

00:11:11.800 --> 00:11:14.500
to use our application,
and then we

00:11:14.500 --> 00:11:17.840
could start folding
data into the models

00:11:17.840 --> 00:11:20.320
and keep it trading from there.

00:11:20.320 --> 00:11:22.770
So we built what
we called GOOG-411.

00:11:22.770 --> 00:11:25.460
I don't know if any
of you remembers that,

00:11:25.460 --> 00:11:26.990
but it was just a
phone application.

00:11:26.990 --> 00:11:29.610
You would call a number,
and then it would say, hey,

00:11:29.610 --> 00:11:30.720
what city and state?

00:11:30.720 --> 00:11:33.790
And you would say what
you were interested in,

00:11:33.790 --> 00:11:35.704
and then it would ask
about the business

00:11:35.704 --> 00:11:36.870
that you were interested in.

00:11:36.870 --> 00:11:38.370
You would say that
name, and then it

00:11:38.370 --> 00:11:41.000
would offer to connect you
to that business in that city

00:11:41.000 --> 00:11:42.200
and state.

00:11:42.200 --> 00:11:46.460
So again, picture that
it's 12 years ago.

00:11:46.460 --> 00:11:49.320
There's no iPhone,
no Android phone,

00:11:49.320 --> 00:11:53.460
all you have is that little flip
phone that you put to your ear.

00:11:53.460 --> 00:11:55.630
So it was very basic.

00:11:55.630 --> 00:11:58.040
Fortunately,
leadership at Google

00:11:58.040 --> 00:12:00.380
was really visionary
about this technology

00:12:00.380 --> 00:12:03.460
and really encouraged us
to push the boundaries

00:12:03.460 --> 00:12:04.950
as much as we could.

00:12:04.950 --> 00:12:09.210
And so we were successful
with this first application.

00:12:09.210 --> 00:12:11.500
But then, the iPhone
and the Android phone

00:12:11.500 --> 00:12:13.750
came, so everything
changed, obviously.

00:12:13.750 --> 00:12:16.230
Now there was visual feedback.

00:12:16.230 --> 00:12:19.310
So we started thinking
about other applications,

00:12:19.310 --> 00:12:21.830
and that was voice search--

00:12:21.830 --> 00:12:23.360
so Google search by voice.

00:12:23.360 --> 00:12:25.985
And then we started doing
dictation and having

00:12:25.985 --> 00:12:28.740
a little microphone in
every possible entry

00:12:28.740 --> 00:12:30.850
point in your phone, so
you could do everything

00:12:30.850 --> 00:12:32.230
with your voice.

00:12:32.230 --> 00:12:37.520
And more recently,
we've moved into trying

00:12:37.520 --> 00:12:41.850
to enable speech
recognition within your home

00:12:41.850 --> 00:12:44.140
with devices like Google Home.

00:12:44.140 --> 00:12:48.800
And because people are asking
for more and more tasks

00:12:48.800 --> 00:12:54.500
to be fulfilled through voice,
that was a really good entry

00:12:54.500 --> 00:12:58.360
point into the whole
assistance story, where instead

00:12:58.360 --> 00:13:02.230
of just enabling you to do very
small things with your voice.

00:13:02.230 --> 00:13:04.370
Now you can ask questions,
you can phrase them

00:13:04.370 --> 00:13:07.190
in natural language,
you can get really

00:13:07.190 --> 00:13:11.720
Google to be your assistant
without this cumbersome

00:13:11.720 --> 00:13:14.730
physical keyboard input.

00:13:14.730 --> 00:13:17.410
DIANE GREENE: Thank you.

00:13:17.410 --> 00:13:22.030
Fernanda, you said you
wanted democratized data

00:13:22.030 --> 00:13:28.130
visualization, and that's sort
of inextricably linked to data.

00:13:28.130 --> 00:13:29.840
How did you get to that?

00:13:29.840 --> 00:13:33.290
What are the needs you see for
data visualization analytics?

00:13:33.290 --> 00:13:36.320
And how's that evolved?

00:13:36.320 --> 00:13:40.940
FERNANDA VIEGAS:
Yeah, so I started

00:13:40.940 --> 00:13:43.570
working in data visualization
over 10 years ago.

00:13:43.570 --> 00:13:46.590
And when I did, it
was much different.

00:13:46.590 --> 00:13:50.090
It was much harder to
do data visualization,

00:13:50.090 --> 00:13:53.680
the machines were
not nearly as good,

00:13:53.680 --> 00:13:56.190
and there wasn't as
much data out there

00:13:56.190 --> 00:13:58.870
that was publicly available.

00:13:58.870 --> 00:14:01.280
That started to
change, and now we

00:14:01.280 --> 00:14:04.980
find ourselves in
an environment where

00:14:04.980 --> 00:14:08.880
people are interacting
with data visualization

00:14:08.880 --> 00:14:10.480
sort of everywhere.

00:14:10.480 --> 00:14:11.550
It's really exciting.

00:14:11.550 --> 00:14:14.350
It's been amazing to
see, like, journalism

00:14:14.350 --> 00:14:16.820
take on data
visualization and talk

00:14:16.820 --> 00:14:19.820
about really
complex stories when

00:14:19.820 --> 00:14:21.500
they talk about statistics.

00:14:21.500 --> 00:14:24.140
We always joke that
data visualization

00:14:24.140 --> 00:14:27.520
is sort of that gateway
drug to statistics.

00:14:27.520 --> 00:14:29.150
It's like you're
doing statistics

00:14:29.150 --> 00:14:32.660
without even noticing that
you are, because we're just

00:14:32.660 --> 00:14:36.370
visually so good at picking
up patterns and outliers

00:14:36.370 --> 00:14:37.580
and so forth.

00:14:37.580 --> 00:14:41.060
So data visualization
has been on this trend

00:14:41.060 --> 00:14:45.210
of becoming more democratized.

00:14:45.210 --> 00:14:50.500
And also, I really
believe that people have--

00:14:50.500 --> 00:14:54.240
we have been increasing
people's ability

00:14:54.240 --> 00:14:57.430
to take in data and numeracy.

00:14:57.430 --> 00:15:02.190
And so data visualization has
had a role to play in that.

00:15:02.190 --> 00:15:05.280
In terms of AI, it's
been really interesting.

00:15:05.280 --> 00:15:12.370
Because we saw a major jump
when Geoff Hinton and colleagues

00:15:12.370 --> 00:15:16.370
proposed the first sort of
blockbuster visualization

00:15:16.370 --> 00:15:19.280
for AI, t-SNE.

00:15:19.280 --> 00:15:21.030
It's a technique
that allows you--

00:15:21.030 --> 00:15:24.840
so one of the big challenges
with AI and with machine

00:15:24.840 --> 00:15:29.830
learning is that these are
systems that work in very

00:15:29.830 --> 00:15:32.850
high dimensional spaces.

00:15:32.850 --> 00:15:36.240
And those are really hard for
us as humans to understand.

00:15:36.240 --> 00:15:39.720
So visualization is one way
that you can sort of peak

00:15:39.720 --> 00:15:43.230
and try to understand what's
happening in these systems.

00:15:43.230 --> 00:15:47.370
And these techniques, such
as the one that Geoff Hinton

00:15:47.370 --> 00:15:49.510
developed, allows us--

00:15:49.510 --> 00:15:52.250
they allow us to
sort of understand

00:15:52.250 --> 00:15:54.240
how things are
clustering together,

00:15:54.240 --> 00:15:57.580
what are the relationships
between different concepts,

00:15:57.580 --> 00:16:01.220
and how the systems are sort
of resolving the data that they

00:16:01.220 --> 00:16:01.890
are ingesting.

00:16:01.890 --> 00:16:05.040
So I'd say that was a major--

00:16:05.040 --> 00:16:07.870
there was major progress,
and the beginning--

00:16:07.870 --> 00:16:10.030
as Fei-Fei was saying,
I feel like were also

00:16:10.030 --> 00:16:13.440
in the beginning of this
relationship between how

00:16:13.440 --> 00:16:18.390
visualization can help AI.

00:16:18.390 --> 00:16:20.130
DIANE GREENE: Thank you.

00:16:20.130 --> 00:16:24.230
Now we're going to switch to
a slightly more technical set

00:16:24.230 --> 00:16:27.600
of answers to what's
going on in the present.

00:16:27.600 --> 00:16:29.670
Francoise, maybe
we'll start with you

00:16:29.670 --> 00:16:33.450
and talking about speech
recognition technologies,

00:16:33.450 --> 00:16:36.100
and what have the
transitions been,

00:16:36.100 --> 00:16:38.950
and what were the challenges,
and what are they today.

00:16:38.950 --> 00:16:41.011
How have the challenges evolved?

00:16:41.011 --> 00:16:41.510
Yeah.

00:16:41.510 --> 00:16:42.920
FRANCOISE BEAUFAYS: Yeah, sure.

00:16:42.920 --> 00:16:47.290
So speech recognition is
really complex, right?

00:16:47.290 --> 00:16:50.500
It's difficult to recognize
what you're saying.

00:16:50.500 --> 00:16:54.660
Each one of us has a different
voice, has a different accent.

00:16:54.660 --> 00:16:57.480
We're speaking in
different environments.

00:16:57.480 --> 00:17:00.900
So all that contributes to
the richness of the voice.

00:17:00.900 --> 00:17:03.320
And I think mostly
for that reason,

00:17:03.320 --> 00:17:07.210
speech recognition has always
been based on machine learning.

00:17:07.210 --> 00:17:09.890
There hasn't been,
or not much of,

00:17:09.890 --> 00:17:12.890
an earlier phase that was
in machine learning base.

00:17:12.890 --> 00:17:14.690
It's just that type
of machine learning

00:17:14.690 --> 00:17:17.050
has been evolving over time.

00:17:17.050 --> 00:17:22.490
And we kept making progress in
the field for the last three

00:17:22.490 --> 00:17:26.069
decades, but I
think one inflection

00:17:26.069 --> 00:17:30.260
point has been the adoption
of neural networks.

00:17:30.260 --> 00:17:36.350
And that has happened maybe
eight years ago or so,

00:17:36.350 --> 00:17:38.310
maybe a little bit less.

00:17:38.310 --> 00:17:43.130
But the early research
in speech recognition

00:17:43.130 --> 00:17:46.450
using neural networks
happened a long time before.

00:17:46.450 --> 00:17:48.710
There was a lot of
activity in the field.

00:17:48.710 --> 00:17:51.000
There were a lot of
promising results;

00:17:51.000 --> 00:17:54.800
however, there wasn't
the complete support

00:17:54.800 --> 00:17:56.680
to really make it happen.

00:17:56.680 --> 00:17:59.840
And so neural nets were a
little bit abandoned for awhile,

00:17:59.840 --> 00:18:01.900
and speech recognition
kept improving

00:18:01.900 --> 00:18:05.070
with more basic methods
like Gaussian Mixer

00:18:05.070 --> 00:18:07.280
Models and whatnot.

00:18:07.280 --> 00:18:11.630
And then, when we started really
evolving into deep neural nets,

00:18:11.630 --> 00:18:14.360
it was a big effort from
an engineering viewpoint.

00:18:14.360 --> 00:18:16.960
We had to deal with
latency issues,

00:18:16.960 --> 00:18:21.420
with size, with training
capabilities, and so on.

00:18:21.420 --> 00:18:24.460
And eventually, when
deep neural networks

00:18:24.460 --> 00:18:28.140
became a reality, when we
launched them when we really

00:18:28.140 --> 00:18:31.260
had them in production,
that opened the path

00:18:31.260 --> 00:18:33.660
to a whole bunch of
other improvements.

00:18:33.660 --> 00:18:35.780
Because now, we
had the capability

00:18:35.780 --> 00:18:40.720
of having that complex machinery
there behind the technology.

00:18:40.720 --> 00:18:42.400
And so we could
move very quickly

00:18:42.400 --> 00:18:45.800
from one neural
architecture to the next.

00:18:45.800 --> 00:18:48.820
And so we started looking into
recurrent neural networks,

00:18:48.820 --> 00:18:53.700
such as LSTM, we looked into
convolution neural networks--

00:18:53.700 --> 00:18:57.870
and so CTC-based
sequence modeling--

00:18:57.870 --> 00:19:01.040
we have a whole bunch
of sequence modeling

00:19:01.040 --> 00:19:03.350
new implementations coming up.

00:19:03.350 --> 00:19:06.750
With Google Home, we have
the neural beam forming.

00:19:06.750 --> 00:19:08.420
And so essentially,
what's happening

00:19:08.420 --> 00:19:12.160
is that the moving
to the neural network

00:19:12.160 --> 00:19:16.430
space has opened this
incredible capability

00:19:16.430 --> 00:19:20.290
for innovating the
core technology that

00:19:20.290 --> 00:19:25.100
powers our systems and
keep optimizing and giving

00:19:25.100 --> 00:19:28.080
all of you, in whichever
language you're speaking,

00:19:28.080 --> 00:19:31.290
the best possible
accuracy we can.

00:19:31.290 --> 00:19:34.500
DIANE GREENE: OK, well neural
nets for speech recognition

00:19:34.500 --> 00:19:39.400
to neural nets for extending our
lives and making us healthier.

00:19:39.400 --> 00:19:43.190
A fairly open-ended
question for you, Daphne--

00:19:43.190 --> 00:19:47.050
why does Calico need one of the
top researchers in the world

00:19:47.050 --> 00:19:50.160
in molecular biology--

00:19:50.160 --> 00:19:53.970
you know, biological computing,
and also machine learning?

00:19:53.970 --> 00:19:58.022
As the chief computing officer,
what are you doing over there?

00:19:58.022 --> 00:20:00.040
DAPHNE KOLLER: So
many of you may not

00:20:00.040 --> 00:20:01.610
know of Calico
because we've been

00:20:01.610 --> 00:20:02.980
a little bit under the radar.

00:20:02.980 --> 00:20:07.010
So Calico is one of the Alphabet
companies, the first one that

00:20:07.010 --> 00:20:08.900
was spun out of Google.

00:20:08.900 --> 00:20:12.290
And it aims to understand
the problem of aging

00:20:12.290 --> 00:20:15.730
and to help people live
longer and healthier lives.

00:20:15.730 --> 00:20:18.450
Now when you look at
aging, you realize

00:20:18.450 --> 00:20:21.910
that it's actually the single
largest risk factor for death.

00:20:21.910 --> 00:20:25.590
And I know that seems kind of
funny when you think about it,

00:20:25.590 --> 00:20:28.750
but it's true for almost
every disease that

00:20:28.750 --> 00:20:30.480
happens after the age of 40.

00:20:30.480 --> 00:20:33.340
That as you grow
older, year after year,

00:20:33.340 --> 00:20:36.070
the risk from that disease
increases exponentially

00:20:36.070 --> 00:20:39.100
every year, whether
it be diabetes

00:20:39.100 --> 00:20:42.800
or cardiovascular
disease, or cancer.

00:20:42.800 --> 00:20:44.690
All of these increase
exponentially.

00:20:44.690 --> 00:20:46.090
No one knows why that is.

00:20:46.090 --> 00:20:49.760
Why is it that every year
of life after the age of 40

00:20:49.760 --> 00:20:54.200
puts us at an increased risk
for each of those diseases?

00:20:54.200 --> 00:20:56.020
And in order to
understand that, we really

00:20:56.020 --> 00:20:59.890
need to study the
biological systems

00:20:59.890 --> 00:21:02.970
that exhibit aging at
the molecular level

00:21:02.970 --> 00:21:04.810
all the way through
the systems level

00:21:04.810 --> 00:21:08.020
and figure out what it is
that's causing us to age.

00:21:08.020 --> 00:21:11.190
Because I don't think
we'll live forever,

00:21:11.190 --> 00:21:16.380
but maybe we can live longer
and healthier by interventions.

00:21:16.380 --> 00:21:19.200
One of our earliest
scientists, Cynthia Kenyon,

00:21:19.200 --> 00:21:21.200
who came over to
Calico from UCSF,

00:21:21.200 --> 00:21:23.910
showed that with a
single gene mutation

00:21:23.910 --> 00:21:27.080
in the nematode C. elegans,
you can extend its lifespan

00:21:27.080 --> 00:21:29.380
by something like 30% to 50%.

00:21:29.380 --> 00:21:31.490
And not only does
the worm live longer,

00:21:31.490 --> 00:21:36.500
it lives as if it were a
healthy, young worm in terms

00:21:36.500 --> 00:21:39.450
of reproductive health,
and movement, and so on.

00:21:39.450 --> 00:21:41.310
So can we do
something like that?

00:21:41.310 --> 00:21:43.990
That would allow humans
to live healthier?

00:21:43.990 --> 00:21:47.050
So that would be really cool,
but in order to do that,

00:21:47.050 --> 00:21:49.330
there's a whole lot of
understanding that we still

00:21:49.330 --> 00:21:50.485
need to gain.

00:21:50.485 --> 00:21:53.230
And in order to do that,
we need to gather data

00:21:53.230 --> 00:21:56.360
about all of those
systems, all of which age.

00:21:56.360 --> 00:22:00.060
Yeast age, worms age,
flies, mice, humans--

00:22:00.060 --> 00:22:04.590
what is it that we all have in
common at the molecular level?

00:22:04.590 --> 00:22:08.290
So fortunately, scientists have
been able, over the last 20

00:22:08.290 --> 00:22:12.120
years, to devise a whole slew
of measurement modalities

00:22:12.120 --> 00:22:15.510
that allow us to get an
understanding, or at least

00:22:15.510 --> 00:22:18.700
data, regarding
systems as they age.

00:22:18.700 --> 00:22:22.270
And that includes
techniques like sequencing

00:22:22.270 --> 00:22:26.320
and microfluidics at the
low level, and imaging,

00:22:26.320 --> 00:22:30.240
all the way through
to things like devices

00:22:30.240 --> 00:22:33.560
that track movement
and allows wearables

00:22:33.560 --> 00:22:37.950
to track movements and see how
systems change as they age.

00:22:37.950 --> 00:22:40.890
But no human being
has the capability

00:22:40.890 --> 00:22:45.140
to put together data at these
different modalities that

00:22:45.140 --> 00:22:47.250
range all the way
from subcellular

00:22:47.250 --> 00:22:50.290
to entire human populations.

00:22:50.290 --> 00:22:52.020
All these different
modalities that

00:22:52.020 --> 00:22:57.670
include DNA, and RNA, and mass
spec, and imaging, and so on.

00:22:57.670 --> 00:23:00.750
All of the time scales that are
involved from the subcellular

00:23:00.750 --> 00:23:05.150
scales all the way to the scales
of an entire human lifespan.

00:23:05.150 --> 00:23:06.750
How do you put
all these together

00:23:06.750 --> 00:23:09.910
into a coherent picture
of what makes us age

00:23:09.910 --> 00:23:12.300
and what interventions
are the most likely to be

00:23:12.300 --> 00:23:16.820
successful in slowing that aging
process and making it better?

00:23:16.820 --> 00:23:21.680
So that ability to interpret
the data and make use of it

00:23:21.680 --> 00:23:24.420
really requires a
true partnership

00:23:24.420 --> 00:23:28.000
between the scientists who
are collecting and getting

00:23:28.000 --> 00:23:32.850
intuitions about these
processes and the machine

00:23:32.850 --> 00:23:34.920
learning people who
can help construct

00:23:34.920 --> 00:23:37.930
models that can synthesize and
put the whole thing together.

00:23:37.930 --> 00:23:42.110
And neither of these communities
can be successful on its own.

00:23:42.110 --> 00:23:45.420
I was one of the fortunate
people who entered this field

00:23:45.420 --> 00:23:46.790
in its very early stages.

00:23:46.790 --> 00:23:49.470
So I've been working in the
field of computational biology

00:23:49.470 --> 00:23:51.680
since on the early 2000s.

00:23:51.680 --> 00:23:53.520
And as such, whereas
you could say

00:23:53.520 --> 00:23:56.130
that I am native in the
language of machine learning,

00:23:56.130 --> 00:23:59.300
you could say that
I have fluency

00:23:59.300 --> 00:24:01.710
in the biological language.

00:24:01.710 --> 00:24:04.330
And as such, it
allows me to work

00:24:04.330 --> 00:24:06.500
with the scientists
of Calico to create

00:24:06.500 --> 00:24:09.700
a true partnership between
those two disciplines

00:24:09.700 --> 00:24:12.850
and build models that,
as I mentioned earlier,

00:24:12.850 --> 00:24:16.090
is so important to combine the
best of both worlds-- the best

00:24:16.090 --> 00:24:19.550
of big data, but also the
best of human intuition.

00:24:19.550 --> 00:24:23.670
Because biology's so complex
that I don't think that

00:24:23.670 --> 00:24:26.440
even with the amounts of data
that we're collecting today,

00:24:26.440 --> 00:24:30.120
we'll be able to reconstruct
biology de novo from data

00:24:30.120 --> 00:24:30.940
alone.

00:24:30.940 --> 00:24:33.710
You need the data, but you
also need the intuition of some

00:24:33.710 --> 00:24:35.480
of the world's best scientists.

00:24:35.480 --> 00:24:38.420
And so by working together
at a place like Calico,

00:24:38.420 --> 00:24:41.410
we can get some
of those insights

00:24:41.410 --> 00:24:44.270
as well as some of the
enormous amounts of data that

00:24:44.270 --> 00:24:45.610
are currently being collected.

00:24:45.610 --> 00:24:48.490
And I'll come back to that
later to really construct

00:24:48.490 --> 00:24:52.280
an in-depth understanding
of the biology of aging

00:24:52.280 --> 00:24:54.850
and at the same
time try and predict

00:24:54.850 --> 00:24:57.917
which interventions
might be helpful.

00:24:57.917 --> 00:24:59.250
DIANE GREENE: Thank you, Daphne.

00:24:59.250 --> 00:25:00.570
I feel we should pause.

00:25:00.570 --> 00:25:02.720
A lot of profound thinking.

00:25:02.720 --> 00:25:07.600
[APPLAUSE]

00:25:07.600 --> 00:25:08.580
Hang on to your hats!

00:25:08.580 --> 00:25:10.900
We're going to jump
back to vision.

00:25:10.900 --> 00:25:12.700
And Fei-Fei, just
the other day, you

00:25:12.700 --> 00:25:15.360
were quoted in
TechCrunch as saying,

00:25:15.360 --> 00:25:18.980
"Vision is the
killer app of AI."

00:25:18.980 --> 00:25:20.450
And so what do you mean by that?

00:25:20.450 --> 00:25:23.330
And what does it mean to
democratize AI, and what does

00:25:23.330 --> 00:25:24.850
that have to do with the Cloud?

00:25:24.850 --> 00:25:27.860
FEI-FEI LI: Yeah, so
yes, I was actually

00:25:27.860 --> 00:25:31.100
trying to be provocative,
and I stand by it.

00:25:31.100 --> 00:25:34.060
The quote is that, while
many people are asking

00:25:34.060 --> 00:25:36.650
for the killer app
of computer vision,

00:25:36.650 --> 00:25:40.860
I will say the killer vision
is the killer app of AI.

00:25:40.860 --> 00:25:45.610
So let me qualify
that by two reasons.

00:25:45.610 --> 00:25:47.860
The first reason
comes from nature.

00:25:47.860 --> 00:25:53.180
540 million years ago,
a remarkable event

00:25:53.180 --> 00:25:56.570
happened in animal evolution.

00:25:56.570 --> 00:26:01.610
For some odd reason, the
number of animal species

00:26:01.610 --> 00:26:05.150
went from very
few simple species

00:26:05.150 --> 00:26:10.050
to an explosive
increase of the variety

00:26:10.050 --> 00:26:12.640
in the types of animals.

00:26:12.640 --> 00:26:17.100
It was considered the big bang
of evolution or the Cambrian

00:26:17.100 --> 00:26:18.370
explosion.

00:26:18.370 --> 00:26:21.330
And the zoologists were
puzzled for many, many decades

00:26:21.330 --> 00:26:23.090
about why this happened.

00:26:23.090 --> 00:26:29.080
And recently, a very
convincing and prominent theory

00:26:29.080 --> 00:26:32.290
conjectured it was
the onset of eyes.

00:26:32.290 --> 00:26:33.430
Animal vision.

00:26:33.430 --> 00:26:36.260
When eyes were first
developed in animals,

00:26:36.260 --> 00:26:42.360
suddenly animal life
became proactive.

00:26:42.360 --> 00:26:46.350
There's predators and preys,
and the whole evolution just

00:26:46.350 --> 00:26:47.300
changed.

00:26:47.300 --> 00:26:52.070
540 million years later,
humans are the most intelligent

00:26:52.070 --> 00:26:53.340
visual animals.

00:26:53.340 --> 00:26:57.400
In fact, nature devoted
half of our brain

00:26:57.400 --> 00:27:00.890
for visual processing
because of its importance.

00:27:00.890 --> 00:27:04.370
So that's one thread
of one evidence.

00:27:04.370 --> 00:27:08.270
Another piece of evidence comes
from technology and the world

00:27:08.270 --> 00:27:09.780
we live in.

00:27:09.780 --> 00:27:11.600
If you look at
our internet today

00:27:11.600 --> 00:27:15.580
where data is awash,
while YouTube alone

00:27:15.580 --> 00:27:20.330
sees 300 plus hours
of the videos uploaded

00:27:20.330 --> 00:27:25.880
every single minute, and
it's estimated more than 80%

00:27:25.880 --> 00:27:30.750
of the entire cyberspace is
in some kind of pixel form.

00:27:30.750 --> 00:27:33.260
And look at the sensors.

00:27:33.260 --> 00:27:36.720
The biggest data form
that sensors capture

00:27:36.720 --> 00:27:38.850
are in some kind of
images, whether it's

00:27:38.850 --> 00:27:44.290
visible spectrum or a spectrum
outside of visible lights.

00:27:44.290 --> 00:27:49.080
From biology labs to hospitals,
from self driving cars

00:27:49.080 --> 00:27:51.310
to surveillance cameras--

00:27:51.310 --> 00:27:53.970
everywhere, the pixel format--

00:27:53.970 --> 00:27:57.850
data in pixel format is
the most invaluable data

00:27:57.850 --> 00:28:00.670
for consumers and companies.

00:28:00.670 --> 00:28:04.750
At Cloud, I had the chance to
talk to a lot of customers.

00:28:04.750 --> 00:28:08.710
I have been all about the
demand of image recognition,

00:28:08.710 --> 00:28:11.500
video processing,
video analytics.

00:28:11.500 --> 00:28:15.210
So it's really an exciting
time for computer vision.

00:28:15.210 --> 00:28:17.560
Again, it's just similar
to speech recognition.

00:28:17.560 --> 00:28:22.640
Thanks to the progress of
deep neural net, vision

00:28:22.640 --> 00:28:30.130
has really taken off as a field
that's made a lot of progress.

00:28:30.130 --> 00:28:33.020
In the past 10
years, between 2010--

00:28:33.020 --> 00:28:37.640
or seven years-- to 2017, I
would say that the biggest

00:28:37.640 --> 00:28:41.600
problems in computer vision is
the basic perception tasks--

00:28:41.600 --> 00:28:46.050
object recognition, image
tagging, object detection,

00:28:46.050 --> 00:28:48.930
we already have, you see,
products coming out of it--

00:28:48.930 --> 00:28:53.230
Google Photos, pedestrian
detection in self-driving cars,

00:28:53.230 --> 00:28:54.430
and all this.

00:28:54.430 --> 00:28:57.710
But the next
phasing in investing

00:28:57.710 --> 00:28:59.990
in computer vision
technology, in my opinion,

00:28:59.990 --> 00:29:04.110
is really vision
plus X. Vision is

00:29:04.110 --> 00:29:08.390
so fundamental in
communication and language.

00:29:08.390 --> 00:29:10.490
How do we speak stories?

00:29:10.490 --> 00:29:16.010
How do we tag and index videos?

00:29:16.010 --> 00:29:19.470
So the connection and interplay
between vision and language

00:29:19.470 --> 00:29:23.200
is going to be
extremely interesting.

00:29:23.200 --> 00:29:27.800
Then vision and biological
sciences, whether we're--

00:29:27.800 --> 00:29:31.630
the throughput of data coming
from biology, and health care,

00:29:31.630 --> 00:29:35.290
and medicine in vision
form is phenomenal.

00:29:35.290 --> 00:29:40.480
And be it radiology
or laboratories.

00:29:40.480 --> 00:29:44.150
And I think there is a huge
opportunity for vision to play.

00:29:44.150 --> 00:29:50.320
And one last example I also
want to give is robotics.

00:29:50.320 --> 00:29:53.430
Speaking as a
researcher, there is

00:29:53.430 --> 00:29:56.160
a lot of excitement
now happening

00:29:56.160 --> 00:29:58.200
in the area of
vision and robotics.

00:29:58.200 --> 00:30:02.330
We've been doing robotics for
as long as AI ever existed,

00:30:02.330 --> 00:30:06.330
but robots are still
not where they are.

00:30:06.330 --> 00:30:12.040
To a large extent, it's because
of its primitive perception

00:30:12.040 --> 00:30:12.890
system.

00:30:12.890 --> 00:30:15.200
And I think vision
can play a huge role.

00:30:15.200 --> 00:30:18.170
So basically, I
do think vision is

00:30:18.170 --> 00:30:23.530
one of the most important
elements of machine

00:30:23.530 --> 00:30:28.820
intelligence and also for the
transformation of enterprise

00:30:28.820 --> 00:30:31.030
and companies.

00:30:31.030 --> 00:30:33.460
DIANE GREENE: Thank you.

00:30:33.460 --> 00:30:34.490
Great perspective.

00:30:34.490 --> 00:30:37.555
[APPLAUSE]

00:30:37.555 --> 00:30:40.940
I need to be careful, because
we're running out of time.

00:30:40.940 --> 00:30:46.410
So Fernanda, how
does vision help

00:30:46.410 --> 00:30:49.920
visualization and visualization
help machine learning?

00:30:49.920 --> 00:30:51.930
And maybe to save time,
you could from that

00:30:51.930 --> 00:30:54.350
go into where you see
the future of where

00:30:54.350 --> 00:30:56.140
you can take the visualization.

00:30:56.140 --> 00:30:57.340
FERNANDA VIEGAS: Sure.

00:30:57.340 --> 00:31:02.910
So yeah, so to piggyback
on Fei-Fei's answer here,

00:31:02.910 --> 00:31:06.150
we have this amazingly
sophisticated vision system.

00:31:06.150 --> 00:31:09.260
We might as well use it to
understand what these machines

00:31:09.260 --> 00:31:10.370
are doing, right?

00:31:10.370 --> 00:31:14.830
So machine learning runs on tons
of data, tons of statistics,

00:31:14.830 --> 00:31:16.480
and probability.

00:31:16.480 --> 00:31:19.720
Well, it turns out that data
visualization can kind of

00:31:19.720 --> 00:31:23.130
be a secret weapon in trying
to understand what's happening.

00:31:23.130 --> 00:31:24.250
And why do we care?

00:31:24.250 --> 00:31:25.180
Why should we care?

00:31:25.180 --> 00:31:28.150
We should care because of a
bunch of different reasons.

00:31:28.150 --> 00:31:29.820
One is interpretability.

00:31:29.820 --> 00:31:33.610
Can you interpret what's
coming out of your models?

00:31:33.610 --> 00:31:35.870
Second is debugability.

00:31:35.870 --> 00:31:38.870
Better understanding what's
happening with your models

00:31:38.870 --> 00:31:41.930
will allow you to
then debug them.

00:31:41.930 --> 00:31:44.020
And then finally,
there's also education.

00:31:44.020 --> 00:31:47.300
Visualization is already
playing an important role

00:31:47.300 --> 00:31:50.420
when it comes to education
about machine learning.

00:31:50.420 --> 00:31:53.910
And I also have a
final education piece

00:31:53.910 --> 00:31:55.890
there that I'm
very excited about,

00:31:55.890 --> 00:31:59.810
which is, when we start
to understand better,

00:31:59.810 --> 00:32:01.720
when we use visualization
to understand

00:32:01.720 --> 00:32:03.280
better what the
systems are doing,

00:32:03.280 --> 00:32:05.780
then can we learn from them?

00:32:05.780 --> 00:32:09.240
Can we become better
professionals, better domain

00:32:09.240 --> 00:32:11.430
experts in whatever.

00:32:11.430 --> 00:32:14.720
If I'm a doctor, if I'm an
architect, whatever it is,

00:32:14.720 --> 00:32:18.670
how can I learn from these
very specific systems

00:32:18.670 --> 00:32:23.060
and then be better
as a professional?

00:32:23.060 --> 00:32:25.570
Another thing about
visualization that I think

00:32:25.570 --> 00:32:28.210
is really powerful
and really important

00:32:28.210 --> 00:32:32.050
to keep track of is the fact
that by using visualization,

00:32:32.050 --> 00:32:35.670
we're always keeping the
human in the loop, right?

00:32:35.670 --> 00:32:36.810
And that is huge.

00:32:36.810 --> 00:32:39.020
And as we build
autonomous systems,

00:32:39.020 --> 00:32:41.540
we want to make sure that
they are behaving well.

00:32:41.540 --> 00:32:44.030
And so visualization
can be helpful there.

00:32:44.030 --> 00:32:48.560
I want to tell you a very
quick anecdote about a moment--

00:32:48.560 --> 00:32:52.660
a scientific moment when
visualization showed us

00:32:52.660 --> 00:32:55.810
something we didn't know
before about a machine learning

00:32:55.810 --> 00:32:56.350
system.

00:32:56.350 --> 00:33:02.170
So last year, Google deployed
its multilingual translate

00:33:02.170 --> 00:33:04.360
system, and it was great.

00:33:04.360 --> 00:33:06.400
It was this really
exciting moment

00:33:06.400 --> 00:33:09.360
of just putting a ton
of different languages

00:33:09.360 --> 00:33:12.780
in one system and having the
system somehow figure out how

00:33:12.780 --> 00:33:17.170
to translate from every
pair of languages.

00:33:17.170 --> 00:33:19.950
The extra bonus was
that it was able to do

00:33:19.950 --> 00:33:23.130
what is called zero shot
translation, where it was

00:33:23.130 --> 00:33:25.620
able to translate from
pairs of languages

00:33:25.620 --> 00:33:28.400
it had not necessarily
seen before.

00:33:28.400 --> 00:33:31.140
So one of the
fundamental research

00:33:31.140 --> 00:33:35.530
questions that the experts
doing those systems had was,

00:33:35.530 --> 00:33:44.370
how is the system resolving
this space of multilingual data?

00:33:44.370 --> 00:33:46.600
Is the system creating
something that

00:33:46.600 --> 00:33:49.820
looks kind of like a model
over here for English,

00:33:49.820 --> 00:33:52.010
and a model over
here for Spanish,

00:33:52.010 --> 00:33:54.320
and another one for Portuguese?

00:33:54.320 --> 00:33:57.210
Or is the system doing
something very different?

00:33:57.210 --> 00:34:00.380
Where it kind of
mixes everything up

00:34:00.380 --> 00:34:03.540
in the same spaces,
and it's maybe

00:34:03.540 --> 00:34:05.920
learning something
about the semantics

00:34:05.920 --> 00:34:08.949
and the meaning of words
and not necessarily

00:34:08.949 --> 00:34:11.650
what language it comes
from or what language I'm

00:34:11.650 --> 00:34:13.090
translating to?

00:34:13.090 --> 00:34:15.480
So what we did is, we
built a visualization

00:34:15.480 --> 00:34:16.909
to look into this.

00:34:16.909 --> 00:34:18.750
And the really
exciting point was

00:34:18.750 --> 00:34:23.250
when we started seeing that--
we visualized sentences that

00:34:23.250 --> 00:34:25.520
were being translated into
a bunch of different pairs

00:34:25.520 --> 00:34:26.980
of languages.

00:34:26.980 --> 00:34:28.380
And the really
exciting thing was

00:34:28.380 --> 00:34:32.989
when we saw clusters
of sentences

00:34:32.989 --> 00:34:35.730
in these different
languages show up together.

00:34:35.730 --> 00:34:39.320
So if I have a sentence that
I'm translating from Portuguese

00:34:39.320 --> 00:34:42.530
to Spanish to English
and vice versa,

00:34:42.530 --> 00:34:46.139
all of those representations
showed up clustered together.

00:34:46.139 --> 00:34:49.050
And then another sentence
here with all the clusters

00:34:49.050 --> 00:34:50.860
of all the languages and then--

00:34:50.860 --> 00:34:53.100
so in other words,
what did we find out?

00:34:53.100 --> 00:34:58.270
We found out that the system
was not partitioning the space

00:34:58.270 --> 00:34:59.750
into different languages.

00:34:59.750 --> 00:35:05.240
The system was coming up
with a unique representation

00:35:05.240 --> 00:35:06.950
of those multiple languages.

00:35:06.950 --> 00:35:09.630
So in other words, we
saw the first signs

00:35:09.630 --> 00:35:12.110
of a universal
language of something

00:35:12.110 --> 00:35:13.790
that we call interlingua.

00:35:13.790 --> 00:35:15.040
That was amazing.

00:35:15.040 --> 00:35:16.650
And so it was
almost as if we had

00:35:16.650 --> 00:35:20.960
ran this multilingual
system through an MRI,

00:35:20.960 --> 00:35:22.020
and we're like, whoa!

00:35:22.020 --> 00:35:23.580
These are the results this is--

00:35:23.580 --> 00:35:26.040
the other thing the
visualization allowed us to do

00:35:26.040 --> 00:35:28.880
was to then look
at neighborhoods

00:35:28.880 --> 00:35:31.330
that didn't look
very well resolved--

00:35:31.330 --> 00:35:35.790
where a little language was
kind of hanging out by itself.

00:35:35.790 --> 00:35:38.170
Those were translations
that were not good.

00:35:38.170 --> 00:35:39.670
They were not high quality.

00:35:39.670 --> 00:35:42.940
So what that tells us is that
the geometry of these spaces

00:35:42.940 --> 00:35:44.070
is meaningful.

00:35:44.070 --> 00:35:45.810
And if you have your
neighborhood sort

00:35:45.810 --> 00:35:48.239
of hanging out in the
periphery by itself,

00:35:48.239 --> 00:35:49.530
you might want to look at that.

00:35:49.530 --> 00:35:52.700
You might want to make sure
that you debug your system.

00:35:52.700 --> 00:35:54.980
So these are kind
of superpowers you

00:35:54.980 --> 00:35:59.890
can have in understanding
and making things better,

00:35:59.890 --> 00:36:02.190
making things work better.

00:36:02.190 --> 00:36:04.960
And for the future,
One of the things

00:36:04.960 --> 00:36:09.550
I'm really excited about
sort of goes hand in hand

00:36:09.550 --> 00:36:13.050
with something that Fei-Fei I
think is a true advocate for,

00:36:13.050 --> 00:36:15.950
is democratizing AI.

00:36:15.950 --> 00:36:19.260
Visualization, I think--
and other techniques--

00:36:19.260 --> 00:36:21.260
it's not only
visualization, but I truly

00:36:21.260 --> 00:36:25.330
believe that the more
different kinds of people

00:36:25.330 --> 00:36:29.490
we bring into the fold of
ML, the better off we're

00:36:29.490 --> 00:36:30.020
going to be.

00:36:30.020 --> 00:36:34.010
Right now, AI still feels
very engineering centric,

00:36:34.010 --> 00:36:36.750
and I'm really curious what
will happen when we bring

00:36:36.750 --> 00:36:40.270
in designers, UXers,
[? scientists ?] [? says ?]

00:36:40.270 --> 00:36:41.910
we're starting to bring in.

00:36:41.910 --> 00:36:43.860
What are the different
possibilities?

00:36:43.860 --> 00:36:47.450
What are the different solutions
that we haven't even thought

00:36:47.450 --> 00:36:51.350
about that we can
then start exploring?

00:36:51.350 --> 00:36:52.431
DIANE GREENE: Thank you.

00:36:52.431 --> 00:36:57.230
[APPLAUSE]

00:36:57.230 --> 00:36:58.960
Francoise, I feel
like I should ask you

00:36:58.960 --> 00:37:02.230
how's data visualization going
to help speech recognition,

00:37:02.230 --> 00:37:05.470
but I also wanted to ask
you about as data gets more

00:37:05.470 --> 00:37:07.910
complex, you know, we've
had all this labeled data

00:37:07.910 --> 00:37:12.010
for the training models and
we do more personalization,

00:37:12.010 --> 00:37:14.700
where's the technology
going and what challenges

00:37:14.700 --> 00:37:16.206
are you excited about?

00:37:16.206 --> 00:37:18.940
FRANCOISE BEAUFAYS: Yeah, it's
actually very interesting.

00:37:18.940 --> 00:37:23.910
Each time we jump into a new
problem in speech recognition,

00:37:23.910 --> 00:37:27.620
we really have to
focus on it in a sense,

00:37:27.620 --> 00:37:29.920
you know, when we start
working on YouTube Kids,

00:37:29.920 --> 00:37:34.510
for example, which was a
YouTube space for children,

00:37:34.510 --> 00:37:37.060
we really had to focus
on those young voices.

00:37:37.060 --> 00:37:38.689
They don't speak
the same way we do,

00:37:38.689 --> 00:37:40.230
they don't have the
same pitch range,

00:37:40.230 --> 00:37:43.620
they don't have the same
way of chopping words.

00:37:43.620 --> 00:37:46.000
They take these deep
breaths, and then they

00:37:46.000 --> 00:37:47.530
have a burst of speech.

00:37:47.530 --> 00:37:48.920
So we really had to focus on it.

00:37:48.920 --> 00:37:50.560
And then eventually,
we found a way

00:37:50.560 --> 00:37:54.750
of folding back that learning
into our generic models

00:37:54.750 --> 00:37:56.900
so that Google
Home, for example,

00:37:56.900 --> 00:38:01.570
would work with your children
as well as it does with you.

00:38:01.570 --> 00:38:05.070
But Google Home itself was
also a new environment where

00:38:05.070 --> 00:38:08.290
we had to collect new data.

00:38:08.290 --> 00:38:10.970
And when that data
is available to you,

00:38:10.970 --> 00:38:14.370
then it's easy to fold it into
the models and keep retraining.

00:38:14.370 --> 00:38:17.360
But the first time you want to
launch a Google Home device,

00:38:17.360 --> 00:38:19.200
you don't have it, right?

00:38:19.200 --> 00:38:21.960
And so we did a
lot of simulations

00:38:21.960 --> 00:38:25.600
taking data, adding
noise of different types,

00:38:25.600 --> 00:38:29.440
doing different types of
reverberation on the data,

00:38:29.440 --> 00:38:33.280
and indeed, we use
massive amounts of data.

00:38:33.280 --> 00:38:36.690
We transcribe tens of
thousands of hours of speech

00:38:36.690 --> 00:38:40.290
and then we multiply it
with the simulations.

00:38:40.290 --> 00:38:42.800
If you do the math, it
averages to something

00:38:42.800 --> 00:38:46.510
like a handful of
centuries of speech

00:38:46.510 --> 00:38:50.200
that we can fold into a model,
so just massive amounts.

00:38:50.200 --> 00:38:53.570
And I think it's
very interesting

00:38:53.570 --> 00:38:57.340
to think about how that
scales to more problems

00:38:57.340 --> 00:38:59.140
with different acoustic
characteristics,

00:38:59.140 --> 00:39:01.530
but also to different languages.

00:39:01.530 --> 00:39:04.240
If I can ask you guys, like
you know how many of you

00:39:04.240 --> 00:39:07.610
speak another
language than English?

00:39:07.610 --> 00:39:08.650
Right, you see?

00:39:08.650 --> 00:39:10.280
All the hands are raising.

00:39:10.280 --> 00:39:14.720
So we really want to make our
technology available to all

00:39:14.720 --> 00:39:16.015
of you in your own language.

00:39:16.015 --> 00:39:19.010
And if you think of it,
it's a massive problem.

00:39:19.010 --> 00:39:20.500
How are we going to do that?

00:39:20.500 --> 00:39:22.920
Are we going to build
one recognizer that

00:39:22.920 --> 00:39:24.340
works for all of you?

00:39:24.340 --> 00:39:27.200
Are we going to do like we
do now, one per language?

00:39:27.200 --> 00:39:29.640
Well, how about dialects, then?

00:39:29.640 --> 00:39:31.480
And how are we
going to do when we

00:39:31.480 --> 00:39:34.480
have a language that's a fairly
small one with small pocket

00:39:34.480 --> 00:39:36.270
of individuals?

00:39:36.270 --> 00:39:38.690
So if you ask linguists,
they will tell you

00:39:38.690 --> 00:39:42.810
that there are 6,000, 7,000
languages in the world.

00:39:42.810 --> 00:39:47.150
They will tell you that there
are about 1,000 of them--

00:39:47.150 --> 00:39:52.520
actually, 1,342, they say,
that have more than 100,000

00:39:52.520 --> 00:39:53.820
speakers.

00:39:53.820 --> 00:39:55.470
So that's a lot, right?

00:39:55.470 --> 00:40:00.390
And if we want to really go
into deep internationalization

00:40:00.390 --> 00:40:06.540
and serve all the languages that
have big populations on earth,

00:40:06.540 --> 00:40:10.030
it's going to require
a lot of creativity

00:40:10.030 --> 00:40:14.580
on the machine learning
side to manage to share data

00:40:14.580 --> 00:40:16.910
among languages, learn
from other languages,

00:40:16.910 --> 00:40:19.080
and so on So I think
it's really exciting

00:40:19.080 --> 00:40:22.024
and there is still a ton of
work to do in that domain.

00:40:22.024 --> 00:40:22.940
DIANE GREENE: I agree.

00:40:22.940 --> 00:40:24.540
It's a very exciting.

00:40:24.540 --> 00:40:25.190
Thank you.

00:40:28.030 --> 00:40:29.940
[APPLAUSE]

00:40:29.940 --> 00:40:32.720
We're going to go a
little over, so we

00:40:32.720 --> 00:40:37.340
have time to hear about the
future from Fei-Fei and Daphne.

00:40:37.340 --> 00:40:42.740
Fei-Fei, what excites you about
what's possible going forward?

00:40:42.740 --> 00:40:44.770
FEI-FEI LI: What
excites me about what's

00:40:44.770 --> 00:40:45.730
possible going forward?

00:40:45.730 --> 00:40:48.670
Let me just say one dimension.

00:40:48.670 --> 00:40:51.450
I generally believe AI
is one of the driving

00:40:51.450 --> 00:40:55.260
forces of the fourth
industrial revolution.

00:40:55.260 --> 00:40:58.270
It's just the beginning,
but it has the potential

00:40:58.270 --> 00:41:03.710
to transform the way humans
live, work, and communicate.

00:41:03.710 --> 00:41:09.060
And one favorite line I
heard from a philosopher

00:41:09.060 --> 00:41:13.110
is, there's no independent
machine values.

00:41:13.110 --> 00:41:15.110
Machine values are human values.

00:41:15.110 --> 00:41:17.170
So one thing that
really excites me

00:41:17.170 --> 00:41:22.050
is to include the
diverse technologists

00:41:22.050 --> 00:41:25.900
in the field of AI to
build the future together.

00:41:25.900 --> 00:41:31.380
Because once we have that
diversity of representation

00:41:31.380 --> 00:41:33.970
in the field of
AI technology, we

00:41:33.970 --> 00:41:38.170
will build the technology that
is for the entire humanity,

00:41:38.170 --> 00:41:41.271
not just a slice of it.

00:41:41.271 --> 00:41:43.270
DIANE GREENE: Yes, you
have a lot of credibility

00:41:43.270 --> 00:41:44.580
when you say that, Fei-Fei.

00:41:44.580 --> 00:41:46.863
[APPLAUSE]

00:41:46.863 --> 00:41:50.700
And Daphne, the
intersection of biology,

00:41:50.700 --> 00:41:55.570
and computing, and everything
else you've done, what--

00:41:55.570 --> 00:41:57.570
DAPHNE KOLLER: Well, when
I look at the progress

00:41:57.570 --> 00:42:01.580
that machine learning has made
over the last five to 10 years,

00:42:01.580 --> 00:42:04.660
and as a long time AI
researcher, if you'd

00:42:04.660 --> 00:42:08.020
asked me even five years
ago, will computers

00:42:08.020 --> 00:42:12.020
be able to caption
images without any kind

00:42:12.020 --> 00:42:15.170
of prior knowledge,
just in the same quality

00:42:15.170 --> 00:42:18.380
that a human would, I would have
said, nehh, maybe in 20 years.

00:42:18.380 --> 00:42:20.830
And with the work of
Fei-Fei and others,

00:42:20.830 --> 00:42:23.520
we've been able to reach
that milestone way sooner

00:42:23.520 --> 00:42:25.620
than I would have expected.

00:42:25.620 --> 00:42:28.310
The reason I moved back
to biology from Coursera

00:42:28.310 --> 00:42:30.640
is because I think
we're hitting that knee

00:42:30.640 --> 00:42:32.470
in the curve in biology.

00:42:32.470 --> 00:42:34.116
So when you look,
for instance, at some

00:42:34.116 --> 00:42:35.490
of the current
predictions, there

00:42:35.490 --> 00:42:39.740
was a paper that was published
in 2015 called "Big Data--

00:42:39.740 --> 00:42:42.210
Astronomical or Genomical?"

00:42:42.210 --> 00:42:47.220
And it looks at the number of
human genome sequence, which

00:42:47.220 --> 00:42:49.960
is a very limited part
of biological data that's

00:42:49.960 --> 00:42:52.860
being captured, and you look
at the historical trend,

00:42:52.860 --> 00:42:54.950
and that amount
doubles every seven

00:42:54.950 --> 00:42:58.510
months, which makes it about
twice as fast as Moore's law.

00:42:58.510 --> 00:43:01.810
So if you look at 2025
and you project that line,

00:43:01.810 --> 00:43:05.330
the number of human
genome sequence by 2025

00:43:05.330 --> 00:43:09.064
will be on the conservative
projection, 100 million,

00:43:09.064 --> 00:43:10.730
and if you look at
the historical trend,

00:43:10.730 --> 00:43:12.850
it'll be two billion.

00:43:12.850 --> 00:43:14.780
Two billion human
genome sequence,

00:43:14.780 --> 00:43:16.870
and that's just sequence.

00:43:16.870 --> 00:43:20.700
That doesn't count RNA, and
proteomes, and whole body

00:43:20.700 --> 00:43:23.230
imaging, and cellular imaging.

00:43:23.230 --> 00:43:26.560
So we're at the cusp
of the beginnings,

00:43:26.560 --> 00:43:30.520
I think, of really understanding
what is the most complex system

00:43:30.520 --> 00:43:33.550
that we've encountered, which
is that of a biological system.

00:43:33.550 --> 00:43:35.880
What is it that makes us alive?

00:43:35.880 --> 00:43:38.330
What is it that
forces us to die?

00:43:38.330 --> 00:43:41.812
And so I think with that amount
of data and the techniques

00:43:41.812 --> 00:43:44.020
that machine learning has
developed and will continue

00:43:44.020 --> 00:43:45.910
to develop, we
have an opportunity

00:43:45.910 --> 00:43:49.810
to really transform
science in this way.

00:43:49.810 --> 00:43:52.660
And I'm really excited to
be able to bring those two

00:43:52.660 --> 00:43:55.850
communities together
to make that possible.

00:43:55.850 --> 00:44:00.760
[APPLAUSE]

00:44:00.760 --> 00:44:03.430
DIANE GREENE: So there's
clearly so much more

00:44:03.430 --> 00:44:07.060
that we could sit
and listen to here.

00:44:07.060 --> 00:44:09.020
This has just been
a phenomenally

00:44:09.020 --> 00:44:12.510
interesting and inspiring panel.

00:44:12.510 --> 00:44:13.642
Thank you very much.

00:44:13.642 --> 00:44:14.850
FEI-FEI LI: Thank you, Diane.

00:44:14.850 --> 00:44:18.200
[APPLAUSE]

