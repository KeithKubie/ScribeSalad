WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:07.089
 
[Music]

00:00:07.089 --> 00:00:07.099
[Music]
 

00:00:07.099 --> 00:00:10.970
[Music]
we're gonna talk about trash so why are

00:00:10.970 --> 00:00:10.980
we're gonna talk about trash so why are
 

00:00:10.980 --> 00:00:13.220
we're gonna talk about trash so why are
we gonna talk about trash here why don't

00:00:13.220 --> 00:00:13.230
we gonna talk about trash here why don't
 

00:00:13.230 --> 00:00:15.289
we gonna talk about trash here why don't
we yeah let me hear it

00:00:15.289 --> 00:00:15.299
we yeah let me hear it
 

00:00:15.299 --> 00:00:17.269
we yeah let me hear it
alright so there's a common phrase and

00:00:17.269 --> 00:00:17.279
alright so there's a common phrase and
 

00:00:17.279 --> 00:00:18.950
alright so there's a common phrase and
software garbage in garbage out but

00:00:18.950 --> 00:00:18.960
software garbage in garbage out but
 

00:00:18.960 --> 00:00:22.400
software garbage in garbage out but
nobody ever says how fast so we're gonna

00:00:22.400 --> 00:00:22.410
nobody ever says how fast so we're gonna
 

00:00:22.410 --> 00:00:24.320
nobody ever says how fast so we're gonna
talk about that today and why because

00:00:24.320 --> 00:00:24.330
talk about that today and why because
 

00:00:24.330 --> 00:00:27.140
talk about that today and why because
back at i/o we had this talk that we

00:00:27.140 --> 00:00:27.150
back at i/o we had this talk that we
 

00:00:27.150 --> 00:00:28.640
back at i/o we had this talk that we
gave called modern Android development I

00:00:28.640 --> 00:00:28.650
gave called modern Android development I
 

00:00:28.650 --> 00:00:30.470
gave called modern Android development I
have to apologize for the sunglasses the

00:00:30.470 --> 00:00:30.480
have to apologize for the sunglasses the
 

00:00:30.480 --> 00:00:33.049
have to apologize for the sunglasses the
Sun was right there right there really

00:00:33.049 --> 00:00:33.059
Sun was right there right there really
 

00:00:33.059 --> 00:00:34.430
Sun was right there right there really
annoying couldn't see a thing

00:00:34.430 --> 00:00:34.440
annoying couldn't see a thing
 

00:00:34.440 --> 00:00:36.590
annoying couldn't see a thing
sunglasses didn't actually help nor did

00:00:36.590 --> 00:00:36.600
sunglasses didn't actually help nor did
 

00:00:36.600 --> 00:00:40.340
sunglasses didn't actually help nor did
they make us look any better so we

00:00:40.340 --> 00:00:40.350
they make us look any better so we
 

00:00:40.350 --> 00:00:41.600
they make us look any better so we
talked about many things you know

00:00:41.600 --> 00:00:41.610
talked about many things you know
 

00:00:41.610 --> 00:00:43.850
talked about many things you know
Android had certain development

00:00:43.850 --> 00:00:43.860
Android had certain development
 

00:00:43.860 --> 00:00:46.490
Android had certain development
practices way back then and Android has

00:00:46.490 --> 00:00:46.500
practices way back then and Android has
 

00:00:46.500 --> 00:00:48.049
practices way back then and Android has
changed and devices have changed and

00:00:48.049 --> 00:00:48.059
changed and devices have changed and
 

00:00:48.059 --> 00:00:49.639
changed and devices have changed and
ecosystems has changed and now we are

00:00:49.639 --> 00:00:49.649
ecosystems has changed and now we are
 

00:00:49.649 --> 00:00:51.740
ecosystems has changed and now we are
recommending different practices all the

00:00:51.740 --> 00:00:51.750
recommending different practices all the
 

00:00:51.750 --> 00:00:52.850
recommending different practices all the
stuff that you may have known about

00:00:52.850 --> 00:00:52.860
stuff that you may have known about
 

00:00:52.860 --> 00:00:54.529
stuff that you may have known about
Android development may not necessarily

00:00:54.529 --> 00:00:54.539
Android development may not necessarily
 

00:00:54.539 --> 00:00:56.540
Android development may not necessarily
be true today one of the things that we

00:00:56.540 --> 00:00:56.550
be true today one of the things that we
 

00:00:56.550 --> 00:00:58.610
be true today one of the things that we
talked about in particular was a lot

00:00:58.610 --> 00:00:58.620
talked about in particular was a lot
 

00:00:58.620 --> 00:01:01.130
talked about in particular was a lot
about memory and garbage collection we

00:01:01.130 --> 00:01:01.140
about memory and garbage collection we
 

00:01:01.140 --> 00:01:04.039
about memory and garbage collection we
had certain recommendations there so for

00:01:04.039 --> 00:01:04.049
had certain recommendations there so for
 

00:01:04.049 --> 00:01:06.340
had certain recommendations there so for
example we said back in the dalvik days

00:01:06.340 --> 00:01:06.350
example we said back in the dalvik days
 

00:01:06.350 --> 00:01:08.929
example we said back in the dalvik days
dalvik was optimized for size it was

00:01:08.929 --> 00:01:08.939
dalvik was optimized for size it was
 

00:01:08.939 --> 00:01:10.700
dalvik was optimized for size it was
meant to fit in a very small area it

00:01:10.700 --> 00:01:10.710
meant to fit in a very small area it
 

00:01:10.710 --> 00:01:12.350
meant to fit in a very small area it
didn't have a lot of area to do things

00:01:12.350 --> 00:01:12.360
didn't have a lot of area to do things
 

00:01:12.360 --> 00:01:14.420
didn't have a lot of area to do things
like äôt didn't have plates to stash the

00:01:14.420 --> 00:01:14.430
like äôt didn't have plates to stash the
 

00:01:14.430 --> 00:01:16.190
like äôt didn't have plates to stash the
code really needed to constrain memory

00:01:16.190 --> 00:01:16.200
code really needed to constrain memory
 

00:01:16.200 --> 00:01:17.840
code really needed to constrain memory
the optimizations were not optimal

00:01:17.840 --> 00:01:17.850
the optimizations were not optimal
 

00:01:17.850 --> 00:01:20.060
the optimizations were not optimal
allocations collections unbelievably

00:01:20.060 --> 00:01:20.070
allocations collections unbelievably
 

00:01:20.070 --> 00:01:22.070
allocations collections unbelievably
expensive to get GC for alloc all the

00:01:22.070 --> 00:01:22.080
expensive to get GC for alloc all the
 

00:01:22.080 --> 00:01:24.230
expensive to get GC for alloc all the
time causing jank all over the place

00:01:24.230 --> 00:01:24.240
time causing jank all over the place
 

00:01:24.240 --> 00:01:26.090
time causing jank all over the place
heap fragmentation was a problem so

00:01:26.090 --> 00:01:26.100
heap fragmentation was a problem so
 

00:01:26.100 --> 00:01:27.679
heap fragmentation was a problem so
really the recommendation was to not

00:01:27.679 --> 00:01:27.689
really the recommendation was to not
 

00:01:27.689 --> 00:01:30.140
really the recommendation was to not
really allocate anything ever if you

00:01:30.140 --> 00:01:30.150
really allocate anything ever if you
 

00:01:30.150 --> 00:01:33.319
really allocate anything ever if you
could possibly help it and use primitive

00:01:33.319 --> 00:01:33.329
could possibly help it and use primitive
 

00:01:33.329 --> 00:01:34.880
could possibly help it and use primitive
types everywhere because objects are

00:01:34.880 --> 00:01:34.890
types everywhere because objects are
 

00:01:34.890 --> 00:01:36.260
types everywhere because objects are
expensive because you're allocating them

00:01:36.260 --> 00:01:36.270
expensive because you're allocating them
 

00:01:36.270 --> 00:01:38.870
expensive because you're allocating them
avoid auto boxing all this stuff yes so

00:01:38.870 --> 00:01:38.880
avoid auto boxing all this stuff yes so
 

00:01:38.880 --> 00:01:40.399
avoid auto boxing all this stuff yes so
I need to correct you once again you say

00:01:40.399 --> 00:01:40.409
I need to correct you once again you say
 

00:01:40.409 --> 00:01:41.630
I need to correct you once again you say
avoid the locations whenever possible

00:01:41.630 --> 00:01:41.640
avoid the locations whenever possible
 

00:01:41.640 --> 00:01:44.780
avoid the locations whenever possible
unions they don't yeah ok well it's the

00:01:44.780 --> 00:01:44.790
unions they don't yeah ok well it's the
 

00:01:44.790 --> 00:01:48.230
unions they don't yeah ok well it's the
whole point but but but but but but but

00:01:48.230 --> 00:01:48.240
whole point but but but but but but but
 

00:01:48.240 --> 00:01:50.660
whole point but but but but but but but
they take up space right so that's what

00:01:50.660 --> 00:01:50.670
they take up space right so that's what
 

00:01:50.670 --> 00:01:53.719
they take up space right so that's what
1 to 2 K you can't say video all right

00:01:53.719 --> 00:01:53.729
1 to 2 K you can't say video all right
 

00:01:53.729 --> 00:01:58.550
1 to 2 K you can't say video all right
anyway it's it's memory related so the

00:01:58.550 --> 00:01:58.560
anyway it's it's memory related so the
 

00:01:58.560 --> 00:02:01.249
anyway it's it's memory related so the
recommendation instead was pay attention

00:02:01.249 --> 00:02:01.259
recommendation instead was pay attention
 

00:02:01.259 --> 00:02:02.780
recommendation instead was pay attention
to art because it turns out art is

00:02:02.780 --> 00:02:02.790
to art because it turns out art is
 

00:02:02.790 --> 00:02:04.219
to art because it turns out art is
optimized for performance actually

00:02:04.219 --> 00:02:04.229
optimized for performance actually
 

00:02:04.229 --> 00:02:05.510
optimized for performance actually
getting faster with every release

00:02:05.510 --> 00:02:05.520
getting faster with every release
 

00:02:05.520 --> 00:02:07.639
getting faster with every release
because the whole platform was built to

00:02:07.639 --> 00:02:07.649
because the whole platform was built to
 

00:02:07.649 --> 00:02:10.190
because the whole platform was built to
be able to optimize more and more the

00:02:10.190 --> 00:02:10.200
be able to optimize more and more the
 

00:02:10.200 --> 00:02:11.960
be able to optimize more and more the
more the team works on it we're doing

00:02:11.960 --> 00:02:11.970
more the team works on it we're doing
 

00:02:11.970 --> 00:02:13.850
more the team works on it we're doing
JIT as well as a OT so

00:02:13.850 --> 00:02:13.860
JIT as well as a OT so
 

00:02:13.860 --> 00:02:15.770
JIT as well as a OT so
we compile this code we find out where

00:02:15.770 --> 00:02:15.780
we compile this code we find out where
 

00:02:15.780 --> 00:02:17.540
we compile this code we find out where
the hot spots are and we stash this code

00:02:17.540 --> 00:02:17.550
the hot spots are and we stash this code
 

00:02:17.550 --> 00:02:19.730
the hot spots are and we stash this code
somewhere so we can run that faster next

00:02:19.730 --> 00:02:19.740
somewhere so we can run that faster next
 

00:02:19.740 --> 00:02:21.310
somewhere so we can run that faster next
time you go through that loop

00:02:21.310 --> 00:02:21.320
time you go through that loop
 

00:02:21.320 --> 00:02:23.150
time you go through that loop
allocations and collections are much

00:02:23.150 --> 00:02:23.160
allocations and collections are much
 

00:02:23.160 --> 00:02:24.620
allocations and collections are much
much faster we'll go into details about

00:02:24.620 --> 00:02:24.630
much faster we'll go into details about
 

00:02:24.630 --> 00:02:26.660
much faster we'll go into details about
this where we have the ability to

00:02:26.660 --> 00:02:26.670
this where we have the ability to
 

00:02:26.670 --> 00:02:28.460
this where we have the ability to
defragment the heap and actually compact

00:02:28.460 --> 00:02:28.470
defragment the heap and actually compact
 

00:02:28.470 --> 00:02:30.320
defragment the heap and actually compact
as we go now and there's a large object

00:02:30.320 --> 00:02:30.330
as we go now and there's a large object
 

00:02:30.330 --> 00:02:32.300
as we go now and there's a large object
heap which means some of the allocations

00:02:32.300 --> 00:02:32.310
heap which means some of the allocations
 

00:02:32.310 --> 00:02:34.610
heap which means some of the allocations
amazingly faster and simpler than they

00:02:34.610 --> 00:02:34.620
amazingly faster and simpler than they
 

00:02:34.620 --> 00:02:36.170
amazingly faster and simpler than they
used to be so the new recommendations

00:02:36.170 --> 00:02:36.180
used to be so the new recommendations
 

00:02:36.180 --> 00:02:38.870
used to be so the new recommendations
are go ahead and allocate it's really

00:02:38.870 --> 00:02:38.880
are go ahead and allocate it's really
 

00:02:38.880 --> 00:02:41.150
are go ahead and allocate it's really
not that big a deal anymore still be

00:02:41.150 --> 00:02:41.160
not that big a deal anymore still be
 

00:02:41.160 --> 00:02:43.580
not that big a deal anymore still be
concerned for inner loop situations and

00:02:43.580 --> 00:02:43.590
concerned for inner loop situations and
 

00:02:43.590 --> 00:02:46.070
concerned for inner loop situations and
be aware that you are actually causing

00:02:46.070 --> 00:02:46.080
be aware that you are actually causing
 

00:02:46.080 --> 00:02:47.800
be aware that you are actually causing
the device to do stuff you are causing

00:02:47.800 --> 00:02:47.810
the device to do stuff you are causing
 

00:02:47.810 --> 00:02:50.720
the device to do stuff you are causing
battery and CPU usage so you still want

00:02:50.720 --> 00:02:50.730
battery and CPU usage so you still want
 

00:02:50.730 --> 00:02:52.820
battery and CPU usage so you still want
to be aware of these things but maybe

00:02:52.820 --> 00:02:52.830
to be aware of these things but maybe
 

00:02:52.830 --> 00:02:54.110
to be aware of these things but maybe
they're not such a big deal that they

00:02:54.110 --> 00:02:54.120
they're not such a big deal that they
 

00:02:54.120 --> 00:02:55.670
they're not such a big deal that they
should affect your API and your

00:02:55.670 --> 00:02:55.680
should affect your API and your
 

00:02:55.680 --> 00:02:57.199
should affect your API and your
development patterns the way that they

00:02:57.199 --> 00:02:57.209
development patterns the way that they
 

00:02:57.209 --> 00:02:59.750
development patterns the way that they
used to however that was like a lot of

00:02:59.750 --> 00:02:59.760
used to however that was like a lot of
 

00:02:59.760 --> 00:03:02.330
used to however that was like a lot of
really terse information stuffed into a

00:03:02.330 --> 00:03:02.340
really terse information stuffed into a
 

00:03:02.340 --> 00:03:03.979
really terse information stuffed into a
very short amount of time so we thought

00:03:03.979 --> 00:03:03.989
very short amount of time so we thought
 

00:03:03.989 --> 00:03:05.630
very short amount of time so we thought
maybe we should do this talk to actually

00:03:05.630 --> 00:03:05.640
maybe we should do this talk to actually
 

00:03:05.640 --> 00:03:07.190
maybe we should do this talk to actually
explain ourselves a little more

00:03:07.190 --> 00:03:07.200
explain ourselves a little more
 

00:03:07.200 --> 00:03:09.680
explain ourselves a little more
completely and say why is this the case

00:03:09.680 --> 00:03:09.690
completely and say why is this the case
 

00:03:09.690 --> 00:03:12.710
completely and say why is this the case
maybe talk about what art has done to

00:03:12.710 --> 00:03:12.720
maybe talk about what art has done to
 

00:03:12.720 --> 00:03:14.330
maybe talk about what art has done to
make life better the original idea for

00:03:14.330 --> 00:03:14.340
make life better the original idea for
 

00:03:14.340 --> 00:03:16.460
make life better the original idea for
the talk was actually okay well we said

00:03:16.460 --> 00:03:16.470
the talk was actually okay well we said
 

00:03:16.470 --> 00:03:17.540
the talk was actually okay well we said
all this stuff but wouldn't it be nice

00:03:17.540 --> 00:03:17.550
all this stuff but wouldn't it be nice
 

00:03:17.550 --> 00:03:19.100
all this stuff but wouldn't it be nice
if we could just write a bunch of demo

00:03:19.100 --> 00:03:19.110
if we could just write a bunch of demo
 

00:03:19.110 --> 00:03:21.380
if we could just write a bunch of demo
applications and show benchmarks and say

00:03:21.380 --> 00:03:21.390
applications and show benchmarks and say
 

00:03:21.390 --> 00:03:23.509
applications and show benchmarks and say
this is why and these are the canonical

00:03:23.509 --> 00:03:23.519
this is why and these are the canonical
 

00:03:23.519 --> 00:03:26.780
this is why and these are the canonical
results that prove our premise and turns

00:03:26.780 --> 00:03:26.790
results that prove our premise and turns
 

00:03:26.790 --> 00:03:29.870
results that prove our premise and turns
out that is really hard because garbage

00:03:29.870 --> 00:03:29.880
out that is really hard because garbage
 

00:03:29.880 --> 00:03:32.000
out that is really hard because garbage
collection by its nature especially in

00:03:32.000 --> 00:03:32.010
collection by its nature especially in
 

00:03:32.010 --> 00:03:34.009
collection by its nature especially in
art is concurrent there's stuff

00:03:34.009 --> 00:03:34.019
art is concurrent there's stuff
 

00:03:34.019 --> 00:03:35.720
art is concurrent there's stuff
happening in the background all the time

00:03:35.720 --> 00:03:35.730
happening in the background all the time
 

00:03:35.730 --> 00:03:37.160
happening in the background all the time
and if you want to trigger that thing

00:03:37.160 --> 00:03:37.170
and if you want to trigger that thing
 

00:03:37.170 --> 00:03:40.520
and if you want to trigger that thing
right now you will not be able to so we

00:03:40.520 --> 00:03:40.530
right now you will not be able to so we
 

00:03:40.530 --> 00:03:41.870
right now you will not be able to so we
made an attempt to write some demo

00:03:41.870 --> 00:03:41.880
made an attempt to write some demo
 

00:03:41.880 --> 00:03:43.310
made an attempt to write some demo
applications you will see some of the

00:03:43.310 --> 00:03:43.320
applications you will see some of the
 

00:03:43.320 --> 00:03:45.410
applications you will see some of the
results here but we realized we don't

00:03:45.410 --> 00:03:45.420
results here but we realized we don't
 

00:03:45.420 --> 00:03:47.140
results here but we realized we don't
really have enough canonical

00:03:47.140 --> 00:03:47.150
really have enough canonical
 

00:03:47.150 --> 00:03:49.250
really have enough canonical
deterministic data to show you so

00:03:49.250 --> 00:03:49.260
deterministic data to show you so
 

00:03:49.260 --> 00:03:50.390
deterministic data to show you so
instead we're going to tell you the

00:03:50.390 --> 00:03:50.400
instead we're going to tell you the
 

00:03:50.400 --> 00:03:52.340
instead we're going to tell you the
background of why it's difficult to

00:03:52.340 --> 00:03:52.350
background of why it's difficult to
 

00:03:52.350 --> 00:03:53.900
background of why it's difficult to
write these things because everything is

00:03:53.900 --> 00:03:53.910
write these things because everything is
 

00:03:53.910 --> 00:03:55.280
write these things because everything is
happening magically for you in the

00:03:55.280 --> 00:03:55.290
happening magically for you in the
 

00:03:55.290 --> 00:03:57.590
happening magically for you in the
background so first of all let's talk

00:03:57.590 --> 00:03:57.600
background so first of all let's talk
 

00:03:57.600 --> 00:03:59.750
background so first of all let's talk
about memory we see a couple of simple

00:03:59.750 --> 00:03:59.760
about memory we see a couple of simple
 

00:03:59.760 --> 00:04:01.580
about memory we see a couple of simple
lines of code here we have a primitive

00:04:01.580 --> 00:04:01.590
lines of code here we have a primitive
 

00:04:01.590 --> 00:04:03.259
lines of code here we have a primitive
type here is foo we're gonna set it

00:04:03.259 --> 00:04:03.269
type here is foo we're gonna set it
 

00:04:03.269 --> 00:04:04.699
type here is foo we're gonna set it
equal to five and then we're going to

00:04:04.699 --> 00:04:04.709
equal to five and then we're going to
 

00:04:04.709 --> 00:04:06.350
equal to five and then we're going to
allocate an object here well there are

00:04:06.350 --> 00:04:06.360
allocate an object here well there are
 

00:04:06.360 --> 00:04:07.850
allocate an object here well there are
different kinds of memory in the system

00:04:07.850 --> 00:04:07.860
different kinds of memory in the system
 

00:04:07.860 --> 00:04:10.009
different kinds of memory in the system
and different implications so if we're

00:04:10.009 --> 00:04:10.019
and different implications so if we're
 

00:04:10.019 --> 00:04:11.479
and different implications so if we're
going to have a primitive type that may

00:04:11.479 --> 00:04:11.489
going to have a primitive type that may
 

00:04:11.489 --> 00:04:13.699
going to have a primitive type that may
show up in the stack or it may show up

00:04:13.699 --> 00:04:13.709
show up in the stack or it may show up
 

00:04:13.709 --> 00:04:17.259
show up in the stack or it may show up
in registers dalvik was a register based

00:04:17.259 --> 00:04:17.269
in registers dalvik was a register based
 

00:04:17.269 --> 00:04:19.130
in registers dalvik was a register based
allocation system so it would actually

00:04:19.130 --> 00:04:19.140
allocation system so it would actually
 

00:04:19.140 --> 00:04:21.170
allocation system so it would actually
pop it in over there but whether it

00:04:21.170 --> 00:04:21.180
pop it in over there but whether it
 

00:04:21.180 --> 00:04:22.610
pop it in over there but whether it
shows up in the stack or the register

00:04:22.610 --> 00:04:22.620
shows up in the stack or the register
 

00:04:22.620 --> 00:04:24.080
shows up in the stack or the register
you can think of it as essentially free

00:04:24.080 --> 00:04:24.090
you can think of it as essentially free
 

00:04:24.090 --> 00:04:25.969
you can think of it as essentially free
it's kind of allocated at compile time

00:04:25.969 --> 00:04:25.979
it's kind of allocated at compile time
 

00:04:25.979 --> 00:04:27.629
it's kind of allocated at compile time
and says when I run this

00:04:27.629 --> 00:04:27.639
and says when I run this
 

00:04:27.639 --> 00:04:28.800
and says when I run this
line of code here's where I'm gonna

00:04:28.800 --> 00:04:28.810
line of code here's where I'm gonna
 

00:04:28.810 --> 00:04:30.629
line of code here's where I'm gonna
stick this thing it didn't need to find

00:04:30.629 --> 00:04:30.639
stick this thing it didn't need to find
 

00:04:30.639 --> 00:04:32.369
stick this thing it didn't need to find
space for it anywhere it knows that it

00:04:32.369 --> 00:04:32.379
space for it anywhere it knows that it
 

00:04:32.379 --> 00:04:34.619
space for it anywhere it knows that it
has space on the stack sort of you can

00:04:34.619 --> 00:04:34.629
has space on the stack sort of you can
 

00:04:34.629 --> 00:04:36.390
has space on the stack sort of you can
think of that it's kind of limited

00:04:36.390 --> 00:04:36.400
think of that it's kind of limited
 

00:04:36.400 --> 00:04:39.689
think of that it's kind of limited
sorry limitless storage space as well as

00:04:39.689 --> 00:04:39.699
sorry limitless storage space as well as
 

00:04:39.699 --> 00:04:41.459
sorry limitless storage space as well as
the registers it'll basically find a

00:04:41.459 --> 00:04:41.469
the registers it'll basically find a
 

00:04:41.469 --> 00:04:43.260
the registers it'll basically find a
copy hole to stash that thing it's free

00:04:43.260 --> 00:04:43.270
copy hole to stash that thing it's free
 

00:04:43.270 --> 00:04:46.140
copy hole to stash that thing it's free
however when you allocate any other sort

00:04:46.140 --> 00:04:46.150
however when you allocate any other sort
 

00:04:46.150 --> 00:04:48.510
however when you allocate any other sort
of thing when you say new object then it

00:04:48.510 --> 00:04:48.520
of thing when you say new object then it
 

00:04:48.520 --> 00:04:50.489
of thing when you say new object then it
needs to find space for it in the heap

00:04:50.489 --> 00:04:50.499
needs to find space for it in the heap
 

00:04:50.499 --> 00:04:52.409
needs to find space for it in the heap
which means it needs to figure out where

00:04:52.409 --> 00:04:52.419
which means it needs to figure out where
 

00:04:52.419 --> 00:04:54.809
which means it needs to figure out where
it's going to fit among the other things

00:04:54.809 --> 00:04:54.819
it's going to fit among the other things
 

00:04:54.819 --> 00:04:56.760
it's going to fit among the other things
that already occupy the heap then it'll

00:04:56.760 --> 00:04:56.770
that already occupy the heap then it'll
 

00:04:56.770 --> 00:04:58.080
that already occupy the heap then it'll
find space down there so that's the

00:04:58.080 --> 00:04:58.090
find space down there so that's the
 

00:04:58.090 --> 00:05:00.839
find space down there so that's the
basic memory system of the runtime and

00:05:00.839 --> 00:05:00.849
basic memory system of the runtime and
 

00:05:00.849 --> 00:05:04.529
basic memory system of the runtime and
the computer overall so the idea of

00:05:04.529 --> 00:05:04.539
the computer overall so the idea of
 

00:05:04.539 --> 00:05:06.779
the computer overall so the idea of
garbage collection well we've all been

00:05:06.779 --> 00:05:06.789
garbage collection well we've all been
 

00:05:06.789 --> 00:05:08.249
garbage collection well we've all been
doing garbage question even before

00:05:08.249 --> 00:05:08.259
doing garbage question even before
 

00:05:08.259 --> 00:05:10.379
doing garbage question even before
higher-level languages like Java and

00:05:10.379 --> 00:05:10.389
higher-level languages like Java and
 

00:05:10.389 --> 00:05:13.559
higher-level languages like Java and
Kotlin if you're writing C++ code then

00:05:13.559 --> 00:05:13.569
Kotlin if you're writing C++ code then
 

00:05:13.569 --> 00:05:15.480
Kotlin if you're writing C++ code then
you can do an allocation like this and

00:05:15.480 --> 00:05:15.490
you can do an allocation like this and
 

00:05:15.490 --> 00:05:17.339
you can do an allocation like this and
then you can use you can write the code

00:05:17.339 --> 00:05:17.349
then you can use you can write the code
 

00:05:17.349 --> 00:05:18.779
then you can use you can write the code
that actually uses that object that

00:05:18.779 --> 00:05:18.789
that actually uses that object that
 

00:05:18.789 --> 00:05:21.300
that actually uses that object that
you've allocated and then if you don't

00:05:21.300 --> 00:05:21.310
you've allocated and then if you don't
 

00:05:21.310 --> 00:05:23.010
you've allocated and then if you don't
do anything else you've just leaked an

00:05:23.010 --> 00:05:23.020
do anything else you've just leaked an
 

00:05:23.020 --> 00:05:25.350
do anything else you've just leaked an
object you're taking up space in memory

00:05:25.350 --> 00:05:25.360
object you're taking up space in memory
 

00:05:25.360 --> 00:05:27.420
object you're taking up space in memory
somewhere that eventually is going to

00:05:27.420 --> 00:05:27.430
somewhere that eventually is going to
 

00:05:27.430 --> 00:05:29.339
somewhere that eventually is going to
cause you to run out of memory right so

00:05:29.339 --> 00:05:29.349
cause you to run out of memory right so
 

00:05:29.349 --> 00:05:31.019
cause you to run out of memory right so
what you need to do is actually free the

00:05:31.019 --> 00:05:31.029
what you need to do is actually free the
 

00:05:31.029 --> 00:05:32.879
what you need to do is actually free the
object so you delete the thing you

00:05:32.879 --> 00:05:32.889
object so you delete the thing you
 

00:05:32.889 --> 00:05:34.290
object so you delete the thing you
reclaim that memory so you're basically

00:05:34.290 --> 00:05:34.300
reclaim that memory so you're basically
 

00:05:34.300 --> 00:05:36.839
reclaim that memory so you're basically
doing manual garbage collection here but

00:05:36.839 --> 00:05:36.849
doing manual garbage collection here but
 

00:05:36.849 --> 00:05:38.969
doing manual garbage collection here but
sometimes you forget that you freed that

00:05:38.969 --> 00:05:38.979
sometimes you forget that you freed that
 

00:05:38.979 --> 00:05:40.439
sometimes you forget that you freed that
over there and then in this other place

00:05:40.439 --> 00:05:40.449
over there and then in this other place
 

00:05:40.449 --> 00:05:42.240
over there and then in this other place
over there you continue using that

00:05:42.240 --> 00:05:42.250
over there you continue using that
 

00:05:42.250 --> 00:05:46.800
over there you continue using that
object and then you crash may be so very

00:05:46.800 --> 00:05:46.810
object and then you crash may be so very
 

00:05:46.810 --> 00:05:48.540
object and then you crash may be so very
non deterministic system you are

00:05:48.540 --> 00:05:48.550
non deterministic system you are
 

00:05:48.550 --> 00:05:50.129
non deterministic system you are
responsible for managing your own

00:05:50.129 --> 00:05:50.139
responsible for managing your own
 

00:05:50.139 --> 00:05:52.260
responsible for managing your own
garbage your own allocations and

00:05:52.260 --> 00:05:52.270
garbage your own allocations and
 

00:05:52.270 --> 00:05:54.600
garbage your own allocations and
collections tends to be tedious tends to

00:05:54.600 --> 00:05:54.610
collections tends to be tedious tends to
 

00:05:54.610 --> 00:05:57.540
collections tends to be tedious tends to
be very error-prone and so higher-level

00:05:57.540 --> 00:05:57.550
be very error-prone and so higher-level
 

00:05:57.550 --> 00:06:00.029
be very error-prone and so higher-level
languages came along so we have language

00:06:00.029 --> 00:06:00.039
languages came along so we have language
 

00:06:00.039 --> 00:06:02.010
languages came along so we have language
like Java where you allocate an object

00:06:02.010 --> 00:06:02.020
like Java where you allocate an object
 

00:06:02.020 --> 00:06:02.999
like Java where you allocate an object
and then you write the code that

00:06:02.999 --> 00:06:03.009
and then you write the code that
 

00:06:03.009 --> 00:06:04.920
and then you write the code that
actually uses that thing and then

00:06:04.920 --> 00:06:04.930
actually uses that thing and then
 

00:06:04.930 --> 00:06:06.899
actually uses that thing and then
eventually it is freed and if you

00:06:06.899 --> 00:06:06.909
eventually it is freed and if you
 

00:06:06.909 --> 00:06:09.240
eventually it is freed and if you
continue using it then you still have a

00:06:09.240 --> 00:06:09.250
continue using it then you still have a
 

00:06:09.250 --> 00:06:10.829
continue using it then you still have a
reference to this object which means

00:06:10.829 --> 00:06:10.839
reference to this object which means
 

00:06:10.839 --> 00:06:12.990
reference to this object which means
it's going to eventually be freed

00:06:12.990 --> 00:06:13.000
it's going to eventually be freed
 

00:06:13.000 --> 00:06:14.999
it's going to eventually be freed
without freeing it too soon right the

00:06:14.999 --> 00:06:15.009
without freeing it too soon right the
 

00:06:15.009 --> 00:06:16.800
without freeing it too soon right the
system knows what's going on you don't

00:06:16.800 --> 00:06:16.810
system knows what's going on you don't
 

00:06:16.810 --> 00:06:18.450
system knows what's going on you don't
have to manage this thing it does it for

00:06:18.450 --> 00:06:18.460
have to manage this thing it does it for
 

00:06:18.460 --> 00:06:20.670
have to manage this thing it does it for
you however if it's doing it for you

00:06:20.670 --> 00:06:20.680
you however if it's doing it for you
 

00:06:20.680 --> 00:06:23.820
you however if it's doing it for you
several questions occur and there's no

00:06:23.820 --> 00:06:23.830
several questions occur and there's no
 

00:06:23.830 --> 00:06:28.050
several questions occur and there's no
crash yay well ideally so there are some

00:06:28.050 --> 00:06:28.060
crash yay well ideally so there are some
 

00:06:28.060 --> 00:06:30.209
crash yay well ideally so there are some
things that naturally occur to you such

00:06:30.209 --> 00:06:30.219
things that naturally occur to you such
 

00:06:30.219 --> 00:06:32.159
things that naturally occur to you such
as okay well how long does it take for

00:06:32.159 --> 00:06:32.169
as okay well how long does it take for
 

00:06:32.169 --> 00:06:33.689
as okay well how long does it take for
the system to do this like I know how

00:06:33.689 --> 00:06:33.699
the system to do this like I know how
 

00:06:33.699 --> 00:06:35.309
the system to do this like I know how
long my malloc statement was going to

00:06:35.309 --> 00:06:35.319
long my malloc statement was going to
 

00:06:35.319 --> 00:06:37.889
long my malloc statement was going to
take in C++ but how long is it going to

00:06:37.889 --> 00:06:37.899
take in C++ but how long is it going to
 

00:06:37.899 --> 00:06:39.689
take in C++ but how long is it going to
take for the system to automatically

00:06:39.689 --> 00:06:39.699
take for the system to automatically
 

00:06:39.699 --> 00:06:41.490
take for the system to automatically
find space in the heap for me

00:06:41.490 --> 00:06:41.500
find space in the heap for me
 

00:06:41.500 --> 00:06:43.290
find space in the heap for me
how is it take to walk the heap find the

00:06:43.290 --> 00:06:43.300
how is it take to walk the heap find the
 

00:06:43.300 --> 00:06:45.360
how is it take to walk the heap find the
appropriate spot to put this thing and

00:06:45.360 --> 00:06:45.370
appropriate spot to put this thing and
 

00:06:45.370 --> 00:06:47.070
appropriate spot to put this thing and
then allocate that space how long does

00:06:47.070 --> 00:06:47.080
then allocate that space how long does
 

00:06:47.080 --> 00:06:48.270
then allocate that space how long does
it take to actually collect these

00:06:48.270 --> 00:06:48.280
it take to actually collect these
 

00:06:48.280 --> 00:06:50.430
it take to actually collect these
objects when a reference goes away when

00:06:50.430 --> 00:06:50.440
objects when a reference goes away when
 

00:06:50.440 --> 00:06:52.110
objects when a reference goes away when
will it be collected and how long does

00:06:52.110 --> 00:06:52.120
will it be collected and how long does
 

00:06:52.120 --> 00:06:53.880
will it be collected and how long does
it take to actually collect these things

00:06:53.880 --> 00:06:53.890
it take to actually collect these things
 

00:06:53.890 --> 00:06:57.690
it take to actually collect these things
and what impact is there system-wide so

00:06:57.690 --> 00:06:57.700
and what impact is there system-wide so
 

00:06:57.700 --> 00:06:59.550
and what impact is there system-wide so
if we're running this sort of garbage

00:06:59.550 --> 00:06:59.560
if we're running this sort of garbage
 

00:06:59.560 --> 00:07:01.230
if we're running this sort of garbage
collector thread this heavy weight thing

00:07:01.230 --> 00:07:01.240
collector thread this heavy weight thing
 

00:07:01.240 --> 00:07:02.910
collector thread this heavy weight thing
in the background they don't want it

00:07:02.910 --> 00:07:02.920
in the background they don't want it
 

00:07:02.920 --> 00:07:04.770
in the background they don't want it
what impact does that have on you know

00:07:04.770 --> 00:07:04.780
what impact does that have on you know
 

00:07:04.780 --> 00:07:07.440
what impact does that have on you know
jank on the UI thread or whatever and

00:07:07.440 --> 00:07:07.450
jank on the UI thread or whatever and
 

00:07:07.450 --> 00:07:09.600
jank on the UI thread or whatever and
when do these things actually happen and

00:07:09.600 --> 00:07:09.610
when do these things actually happen and
 

00:07:09.610 --> 00:07:11.700
when do these things actually happen and
also how efficient is that heap usage

00:07:11.700 --> 00:07:11.710
also how efficient is that heap usage
 

00:07:11.710 --> 00:07:13.860
also how efficient is that heap usage
right it's not just going to malloc

00:07:13.860 --> 00:07:13.870
right it's not just going to malloc
 

00:07:13.870 --> 00:07:15.390
right it's not just going to malloc
these little tiny chunks for your things

00:07:15.390 --> 00:07:15.400
these little tiny chunks for your things
 

00:07:15.400 --> 00:07:17.070
these little tiny chunks for your things
is probably allocating a large amount of

00:07:17.070 --> 00:07:17.080
is probably allocating a large amount of
 

00:07:17.080 --> 00:07:18.960
is probably allocating a large amount of
space and then putting things in there

00:07:18.960 --> 00:07:18.970
space and then putting things in there
 

00:07:18.970 --> 00:07:20.909
space and then putting things in there
and sorting them around and certainly on

00:07:20.909 --> 00:07:20.919
and sorting them around and certainly on
 

00:07:20.919 --> 00:07:22.800
and sorting them around and certainly on
Dalva because we'll see its fragmenting

00:07:22.800 --> 00:07:22.810
Dalva because we'll see its fragmenting
 

00:07:22.810 --> 00:07:24.330
Dalva because we'll see its fragmenting
the heap over time which means you may

00:07:24.330 --> 00:07:24.340
the heap over time which means you may
 

00:07:24.340 --> 00:07:26.070
the heap over time which means you may
have a lot of memory available but you

00:07:26.070 --> 00:07:26.080
have a lot of memory available but you
 

00:07:26.080 --> 00:07:27.930
have a lot of memory available but you
can't necessarily even access it anymore

00:07:27.930 --> 00:07:27.940
can't necessarily even access it anymore
 

00:07:27.940 --> 00:07:30.150
can't necessarily even access it anymore
so how efficient is that and how much

00:07:30.150 --> 00:07:30.160
so how efficient is that and how much
 

00:07:30.160 --> 00:07:31.800
so how efficient is that and how much
memory you're taking up in the system to

00:07:31.800 --> 00:07:31.810
memory you're taking up in the system to
 

00:07:31.810 --> 00:07:34.320
memory you're taking up in the system to
do all this stuff so we're gonna start

00:07:34.320 --> 00:07:34.330
do all this stuff so we're gonna start
 

00:07:34.330 --> 00:07:36.600
do all this stuff so we're gonna start
by taking a look at how dalvik collects

00:07:36.600 --> 00:07:36.610
by taking a look at how dalvik collects
 

00:07:36.610 --> 00:07:39.270
by taking a look at how dalvik collects
garbage dalvik was the runtime we are

00:07:39.270 --> 00:07:39.280
garbage dalvik was the runtime we are
 

00:07:39.280 --> 00:07:40.830
garbage dalvik was the runtime we are
using until android kitkat

00:07:40.830 --> 00:07:40.840
using until android kitkat
 

00:07:40.840 --> 00:07:43.710
using until android kitkat
it was replaced in lollipop with art so

00:07:43.710 --> 00:07:43.720
it was replaced in lollipop with art so
 

00:07:43.720 --> 00:07:45.540
it was replaced in lollipop with art so
this is a picture of the heap everything

00:07:45.540 --> 00:07:45.550
this is a picture of the heap everything
 

00:07:45.550 --> 00:07:47.040
this is a picture of the heap everything
that's in white has been allocated and

00:07:47.040 --> 00:07:47.050
that's in white has been allocated and
 

00:07:47.050 --> 00:07:48.570
that's in white has been allocated and
we have a few holes and we're trying to

00:07:48.570 --> 00:07:48.580
we have a few holes and we're trying to
 

00:07:48.580 --> 00:07:51.030
we have a few holes and we're trying to
allocate this blue object so a dalvik is

00:07:51.030 --> 00:07:51.040
allocate this blue object so a dalvik is
 

00:07:51.040 --> 00:07:52.260
allocate this blue object so a dalvik is
gonna do is just gonna walk through the

00:07:52.260 --> 00:07:52.270
gonna do is just gonna walk through the
 

00:07:52.270 --> 00:07:54.240
gonna do is just gonna walk through the
heap and find a spot where the object

00:07:54.240 --> 00:07:54.250
heap and find a spot where the object
 

00:07:54.250 --> 00:07:56.730
heap and find a spot where the object
fits when it finds one pretty easy just

00:07:56.730 --> 00:07:56.740
fits when it finds one pretty easy just
 

00:07:56.740 --> 00:07:59.880
fits when it finds one pretty easy just
slot it there things becomes become a

00:07:59.880 --> 00:07:59.890
slot it there things becomes become a
 

00:07:59.890 --> 00:08:01.890
slot it there things becomes become a
lot more complicated when it comes time

00:08:01.890 --> 00:08:01.900
lot more complicated when it comes time
 

00:08:01.900 --> 00:08:04.710
lot more complicated when it comes time
to collect objects so there's four

00:08:04.710 --> 00:08:04.720
to collect objects so there's four
 

00:08:04.720 --> 00:08:07.260
to collect objects so there's four
phases the first one dalvik has to pause

00:08:07.260 --> 00:08:07.270
phases the first one dalvik has to pause
 

00:08:07.270 --> 00:08:09.120
phases the first one dalvik has to pause
all the threads in your application to

00:08:09.120 --> 00:08:09.130
all the threads in your application to
 

00:08:09.130 --> 00:08:11.460
all the threads in your application to
find a route set so route sets are

00:08:11.460 --> 00:08:11.470
find a route set so route sets are
 

00:08:11.470 --> 00:08:14.790
find a route set so route sets are
typically local variables threads static

00:08:14.790 --> 00:08:14.800
typically local variables threads static
 

00:08:14.800 --> 00:08:17.730
typically local variables threads static
variables they're just the roots of all

00:08:17.730 --> 00:08:17.740
variables they're just the roots of all
 

00:08:17.740 --> 00:08:19.200
variables they're just the roots of all
the allocations that can be reached in

00:08:19.200 --> 00:08:19.210
the allocations that can be reached in
 

00:08:19.210 --> 00:08:20.880
the allocations that can be reached in
your application so that takes a bit of

00:08:20.880 --> 00:08:20.890
your application so that takes a bit of
 

00:08:20.890 --> 00:08:22.440
your application so that takes a bit of
time and during that time your

00:08:22.440 --> 00:08:22.450
time and during that time your
 

00:08:22.450 --> 00:08:24.360
time and during that time your
application cannot do anything the

00:08:24.360 --> 00:08:24.370
application cannot do anything the
 

00:08:24.370 --> 00:08:26.580
application cannot do anything the
second phase is concurrent your app is

00:08:26.580 --> 00:08:26.590
second phase is concurrent your app is
 

00:08:26.590 --> 00:08:28.500
second phase is concurrent your app is
running again so from those routes

00:08:28.500 --> 00:08:28.510
running again so from those routes
 

00:08:28.510 --> 00:08:30.360
running again so from those routes
dalvik will find all the objects that

00:08:30.360 --> 00:08:30.370
dalvik will find all the objects that
 

00:08:30.370 --> 00:08:32.930
dalvik will find all the objects that
can be reached and marks them as such

00:08:32.930 --> 00:08:32.940
can be reached and marks them as such
 

00:08:32.940 --> 00:08:35.909
can be reached and marks them as such
unfortunately since that that second

00:08:35.909 --> 00:08:35.919
unfortunately since that that second
 

00:08:35.919 --> 00:08:38.700
unfortunately since that that second
phase is concurrent allocations could be

00:08:38.700 --> 00:08:38.710
phase is concurrent allocations could be
 

00:08:38.710 --> 00:08:40.589
phase is concurrent allocations could be
triggered during that time so you see

00:08:40.589 --> 00:08:40.599
triggered during that time so you see
 

00:08:40.599 --> 00:08:41.370
triggered during that time so you see
here like for instance which is

00:08:41.370 --> 00:08:41.380
here like for instance which is
 

00:08:41.380 --> 00:08:43.529
here like for instance which is
educating sorry which is you just

00:08:43.529 --> 00:08:43.539
educating sorry which is you just
 

00:08:43.539 --> 00:08:45.900
educating sorry which is you just
allocated another object so we need to

00:08:45.900 --> 00:08:45.910
allocated another object so we need to
 

00:08:45.910 --> 00:08:48.060
allocated another object so we need to
pass the application again and find the

00:08:48.060 --> 00:08:48.070
pass the application again and find the
 

00:08:48.070 --> 00:08:50.430
pass the application again and find the
reachable objects again and all your

00:08:50.430 --> 00:08:50.440
reachable objects again and all your
 

00:08:50.440 --> 00:08:51.840
reachable objects again and all your
threads are passed so your application

00:08:51.840 --> 00:08:51.850
threads are passed so your application
 

00:08:51.850 --> 00:08:53.880
threads are passed so your application
stutters a little bit again and finally

00:08:53.880 --> 00:08:53.890
stutters a little bit again and finally
 

00:08:53.890 --> 00:08:55.230
stutters a little bit again and finally
we can mark all the

00:08:55.230 --> 00:08:55.240
we can mark all the
 

00:08:55.240 --> 00:08:56.670
we can mark all the
that are not reachable and there are

00:08:56.670 --> 00:08:56.680
that are not reachable and there are
 

00:08:56.680 --> 00:08:59.370
that are not reachable and there are
candidates for garbage collection so the

00:08:59.370 --> 00:08:59.380
candidates for garbage collection so the
 

00:08:59.380 --> 00:09:00.660
candidates for garbage collection so the
collection itself just gets rid of the

00:09:00.660 --> 00:09:00.670
collection itself just gets rid of the
 

00:09:00.670 --> 00:09:04.019
collection itself just gets rid of the
objects in the heap so now if we want to

00:09:04.019 --> 00:09:04.029
objects in the heap so now if we want to
 

00:09:04.029 --> 00:09:05.820
objects in the heap so now if we want to
allocate something in the heap and the

00:09:05.820 --> 00:09:05.830
allocate something in the heap and the
 

00:09:05.830 --> 00:09:07.740
allocate something in the heap and the
heap is pretty much full and we have

00:09:07.740 --> 00:09:07.750
heap is pretty much full and we have
 

00:09:07.750 --> 00:09:09.360
heap is pretty much full and we have
objects that have been marked for

00:09:09.360 --> 00:09:09.370
objects that have been marked for
 

00:09:09.370 --> 00:09:11.610
objects that have been marked for
allocation dalvik will go through the

00:09:11.610 --> 00:09:11.620
allocation dalvik will go through the
 

00:09:11.620 --> 00:09:13.440
allocation dalvik will go through the
heap realize that there's no memory

00:09:13.440 --> 00:09:13.450
heap realize that there's no memory
 

00:09:13.450 --> 00:09:15.810
heap realize that there's no memory
available and then it will trigger a

00:09:15.810 --> 00:09:15.820
available and then it will trigger a
 

00:09:15.820 --> 00:09:17.880
available and then it will trigger a
garbage collection for the specific use

00:09:17.880 --> 00:09:17.890
garbage collection for the specific use
 

00:09:17.890 --> 00:09:19.560
garbage collection for the specific use
case of an allocation that's the GC for

00:09:19.560 --> 00:09:19.570
case of an allocation that's the GC for
 

00:09:19.570 --> 00:09:21.300
case of an allocation that's the GC for
alloc and every time this happens you

00:09:21.300 --> 00:09:21.310
alloc and every time this happens you
 

00:09:21.310 --> 00:09:24.329
alloc and every time this happens you
see a log on KitKat doing adb logcat you

00:09:24.329 --> 00:09:24.339
see a log on KitKat doing adb logcat you
 

00:09:24.339 --> 00:09:27.060
see a log on KitKat doing adb logcat you
can see those GC for alloc messages so

00:09:27.060 --> 00:09:27.070
can see those GC for alloc messages so
 

00:09:27.070 --> 00:09:28.889
can see those GC for alloc messages so
it will you know run the collection gets

00:09:28.889 --> 00:09:28.899
it will you know run the collection gets
 

00:09:28.899 --> 00:09:30.660
it will you know run the collection gets
rid get rid of this memory then we can

00:09:30.660 --> 00:09:30.670
rid get rid of this memory then we can
 

00:09:30.670 --> 00:09:32.460
rid get rid of this memory then we can
run through the typical allocation

00:09:32.460 --> 00:09:32.470
run through the typical allocation
 

00:09:32.470 --> 00:09:36.870
run through the typical allocation
mechanism however sometimes your hip is

00:09:36.870 --> 00:09:36.880
mechanism however sometimes your hip is
 

00:09:36.880 --> 00:09:38.880
mechanism however sometimes your hip is
full there are no objects that can be

00:09:38.880 --> 00:09:38.890
full there are no objects that can be
 

00:09:38.890 --> 00:09:41.760
full there are no objects that can be
collected every object is reachable so W

00:09:41.760 --> 00:09:41.770
collected every object is reachable so W
 

00:09:41.770 --> 00:09:43.320
collected every object is reachable so W
over and through the heap can't find

00:09:43.320 --> 00:09:43.330
over and through the heap can't find
 

00:09:43.330 --> 00:09:46.590
over and through the heap can't find
anything and only two things can happen

00:09:46.590 --> 00:09:46.600
anything and only two things can happen
 

00:09:46.600 --> 00:09:49.680
anything and only two things can happen
either the heap will grow or your

00:09:49.680 --> 00:09:49.690
either the heap will grow or your
 

00:09:49.690 --> 00:09:52.019
either the heap will grow or your
application will crash and is the it's

00:09:52.019 --> 00:09:52.029
application will crash and is the it's
 

00:09:52.029 --> 00:09:53.790
application will crash and is the it's
the out of memory error that you've seen

00:09:53.790 --> 00:09:53.800
the out of memory error that you've seen
 

00:09:53.800 --> 00:09:55.430
the out of memory error that you've seen
I'm sure in a lot of real applications

00:09:55.430 --> 00:09:55.440
I'm sure in a lot of real applications
 

00:09:55.440 --> 00:09:58.380
I'm sure in a lot of real applications
especially on other devices this

00:09:58.380 --> 00:09:58.390
especially on other devices this
 

00:09:58.390 --> 00:09:59.819
especially on other devices this
typically happens when you're allocating

00:09:59.819 --> 00:09:59.829
typically happens when you're allocating
 

00:09:59.829 --> 00:10:01.790
typically happens when you're allocating
large objects I remember a lot of

00:10:01.790 --> 00:10:01.800
large objects I remember a lot of
 

00:10:01.800 --> 00:10:03.840
large objects I remember a lot of
developers in the early days of then of

00:10:03.840 --> 00:10:03.850
developers in the early days of then of
 

00:10:03.850 --> 00:10:06.449
developers in the early days of then of
Android felt bugs against bitmap factory

00:10:06.449 --> 00:10:06.459
Android felt bugs against bitmap factory
 

00:10:06.459 --> 00:10:08.910
Android felt bugs against bitmap factory
because out of memory error happened 10

00:10:08.910 --> 00:10:08.920
because out of memory error happened 10
 

00:10:08.920 --> 00:10:11.610
because out of memory error happened 10
tended to happen during a decoding of

00:10:11.610 --> 00:10:11.620
tended to happen during a decoding of
 

00:10:11.620 --> 00:10:13.470
tended to happen during a decoding of
bitmaps and they thought there was a

00:10:13.470 --> 00:10:13.480
bitmaps and they thought there was a
 

00:10:13.480 --> 00:10:15.480
bitmaps and they thought there was a
memory leak in bitmap factory the main

00:10:15.480 --> 00:10:15.490
memory leak in bitmap factory the main
 

00:10:15.490 --> 00:10:18.180
memory leak in bitmap factory the main
reason was bitmap objects are big and it

00:10:18.180 --> 00:10:18.190
reason was bitmap objects are big and it
 

00:10:18.190 --> 00:10:20.579
reason was bitmap objects are big and it
was hard to find space for them there

00:10:20.579 --> 00:10:20.589
was hard to find space for them there
 

00:10:20.589 --> 00:10:23.810
was hard to find space for them there
was no leaking bitmap factory whatsoever

00:10:23.810 --> 00:10:23.820
was no leaking bitmap factory whatsoever
 

00:10:23.820 --> 00:10:27.720
was no leaking bitmap factory whatsoever
so we wrote a simple demo application to

00:10:27.720 --> 00:10:27.730
so we wrote a simple demo application to
 

00:10:27.730 --> 00:10:29.490
so we wrote a simple demo application to
show off how some of the stuff with

00:10:29.490 --> 00:10:29.500
show off how some of the stuff with
 

00:10:29.500 --> 00:10:32.040
show off how some of the stuff with
heaps fragmentation works so in the demo

00:10:32.040 --> 00:10:32.050
heaps fragmentation works so in the demo
 

00:10:32.050 --> 00:10:35.100
heaps fragmentation works so in the demo
we allocates chunks of memory all the

00:10:35.100 --> 00:10:35.110
we allocates chunks of memory all the
 

00:10:35.110 --> 00:10:37.110
we allocates chunks of memory all the
way up to max heap so your heap starts

00:10:37.110 --> 00:10:37.120
way up to max heap so your heap starts
 

00:10:37.120 --> 00:10:38.790
way up to max heap so your heap starts
out very small and then if you can't

00:10:38.790 --> 00:10:38.800
out very small and then if you can't
 

00:10:38.800 --> 00:10:40.650
out very small and then if you can't
allocate an object it's it's gonna grow

00:10:40.650 --> 00:10:40.660
allocate an object it's it's gonna grow
 

00:10:40.660 --> 00:10:42.240
allocate an object it's it's gonna grow
that over and over and over until it

00:10:42.240 --> 00:10:42.250
that over and over and over until it
 

00:10:42.250 --> 00:10:43.860
that over and over and over until it
reaches the max possible so for this

00:10:43.860 --> 00:10:43.870
reaches the max possible so for this
 

00:10:43.870 --> 00:10:45.810
reaches the max possible so for this
demo we allocate these 1 Meg chunks

00:10:45.810 --> 00:10:45.820
demo we allocate these 1 Meg chunks
 

00:10:45.820 --> 00:10:47.490
demo we allocate these 1 Meg chunks
press this button it says there's four

00:10:47.490 --> 00:10:47.500
press this button it says there's four
 

00:10:47.500 --> 00:10:48.810
press this button it says there's four
hundred Meg's free you press the button

00:10:48.810 --> 00:10:48.820
hundred Meg's free you press the button
 

00:10:48.820 --> 00:10:50.190
hundred Meg's free you press the button
it's gonna allocate all these 1 Meg

00:10:50.190 --> 00:10:50.200
it's gonna allocate all these 1 Meg
 

00:10:50.200 --> 00:10:52.079
it's gonna allocate all these 1 Meg
chunks all the way until it grows the

00:10:52.079 --> 00:10:52.089
chunks all the way until it grows the
 

00:10:52.089 --> 00:10:54.120
chunks all the way until it grows the
heap until it cannot anymore you get an

00:10:54.120 --> 00:10:54.130
heap until it cannot anymore you get an
 

00:10:54.130 --> 00:10:55.620
heap until it cannot anymore you get an
error we catch the error and that we

00:10:55.620 --> 00:10:55.630
error we catch the error and that we
 

00:10:55.630 --> 00:10:57.420
error we catch the error and that we
know the heap is full there's no this is

00:10:57.420 --> 00:10:57.430
know the heap is full there's no this is
 

00:10:57.430 --> 00:10:58.740
know the heap is full there's no this is
pretty much the only situation where you

00:10:58.740 --> 00:10:58.750
pretty much the only situation where you
 

00:10:58.750 --> 00:11:00.389
pretty much the only situation where you
should do a try-catch on another memory

00:11:00.389 --> 00:11:00.399
should do a try-catch on another memory
 

00:11:00.399 --> 00:11:03.829
should do a try-catch on another memory
error don't do that in your application

00:11:03.829 --> 00:11:03.839
 
 

00:11:03.839 --> 00:11:07.050
 
and then we say ok well there's only one

00:11:07.050 --> 00:11:07.060
and then we say ok well there's only one
 

00:11:07.060 --> 00:11:08.560
and then we say ok well there's only one
Meg free so

00:11:08.560 --> 00:11:08.570
Meg free so
 

00:11:08.570 --> 00:11:09.760
Meg free so
gonna go ahead and fragment the heap

00:11:09.760 --> 00:11:09.770
gonna go ahead and fragment the heap
 

00:11:09.770 --> 00:11:12.310
gonna go ahead and fragment the heap
we're going to free a bunch of trunks so

00:11:12.310 --> 00:11:12.320
we're going to free a bunch of trunks so
 

00:11:12.320 --> 00:11:13.480
we're going to free a bunch of trunks so
we're basically going to go through

00:11:13.480 --> 00:11:13.490
we're basically going to go through
 

00:11:13.490 --> 00:11:14.800
we're basically going to go through
everything we've allocated and free

00:11:14.800 --> 00:11:14.810
everything we've allocated and free
 

00:11:14.810 --> 00:11:17.500
everything we've allocated and free
every other one through the entire just

00:11:17.500 --> 00:11:17.510
every other one through the entire just
 

00:11:17.510 --> 00:11:19.630
every other one through the entire just
go through every other reference city to

00:11:19.630 --> 00:11:19.640
go through every other reference city to
 

00:11:19.640 --> 00:11:21.310
go through every other reference city to
know then force did you see a couple

00:11:21.310 --> 00:11:21.320
know then force did you see a couple
 

00:11:21.320 --> 00:11:22.840
know then force did you see a couple
times to make sure that that memory goes

00:11:22.840 --> 00:11:22.850
times to make sure that that memory goes
 

00:11:22.850 --> 00:11:25.240
times to make sure that that memory goes
away and then we get this result it says

00:11:25.240 --> 00:11:25.250
away and then we get this result it says
 

00:11:25.250 --> 00:11:27.460
away and then we get this result it says
okay the fragmented heap size is now 200

00:11:27.460 --> 00:11:27.470
okay the fragmented heap size is now 200
 

00:11:27.470 --> 00:11:27.850
okay the fragmented heap size is now 200
Meg's

00:11:27.850 --> 00:11:27.860
Meg's
 

00:11:27.860 --> 00:11:30.610
Meg's
so we should have plenty of space to go

00:11:30.610 --> 00:11:30.620
so we should have plenty of space to go
 

00:11:30.620 --> 00:11:32.680
so we should have plenty of space to go
ahead and allocate a two megabyte object

00:11:32.680 --> 00:11:32.690
ahead and allocate a two megabyte object
 

00:11:32.690 --> 00:11:34.540
ahead and allocate a two megabyte object
so that blue object there it's only two

00:11:34.540 --> 00:11:34.550
so that blue object there it's only two
 

00:11:34.550 --> 00:11:36.370
so that blue object there it's only two
Meg's we've got 200 we've got two

00:11:36.370 --> 00:11:36.380
Meg's we've got 200 we've got two
 

00:11:36.380 --> 00:11:39.040
Meg's we've got 200 we've got two
hundred Meg's free so what can be the

00:11:39.040 --> 00:11:39.050
hundred Meg's free so what can be the
 

00:11:39.050 --> 00:11:41.260
hundred Meg's free so what can be the
problem so we press the button and it

00:11:41.260 --> 00:11:41.270
problem so we press the button and it
 

00:11:41.270 --> 00:11:43.570
problem so we press the button and it
says nope we can't fit that in there and

00:11:43.570 --> 00:11:43.580
says nope we can't fit that in there and
 

00:11:43.580 --> 00:11:45.310
says nope we can't fit that in there and
if you look at the log you get these

00:11:45.310 --> 00:11:45.320
if you look at the log you get these
 

00:11:45.320 --> 00:11:46.720
if you look at the log you get these
depressing things here where it says

00:11:46.720 --> 00:11:46.730
depressing things here where it says
 

00:11:46.730 --> 00:11:49.000
depressing things here where it says
special - error message in all of

00:11:49.000 --> 00:11:49.010
special - error message in all of
 

00:11:49.010 --> 00:11:51.040
special - error message in all of
computer science yes right here this is

00:11:51.040 --> 00:11:51.050
computer science yes right here this is
 

00:11:51.050 --> 00:11:53.110
computer science yes right here this is
this is beautiful it says okay you have

00:11:53.110 --> 00:11:53.120
this is beautiful it says okay you have
 

00:11:53.120 --> 00:11:55.810
this is beautiful it says okay you have
free two hundred Meg's free out of four

00:11:55.810 --> 00:11:55.820
free two hundred Meg's free out of four
 

00:11:55.820 --> 00:11:58.420
free two hundred Meg's free out of four
hundred and we're forcing a collection

00:11:58.420 --> 00:11:58.430
hundred and we're forcing a collection
 

00:11:58.430 --> 00:12:00.010
hundred and we're forcing a collection
so that we can make room for a two Meg

00:12:00.010 --> 00:12:00.020
so that we can make room for a two Meg
 

00:12:00.020 --> 00:12:02.590
so that we can make room for a two Meg
chunk and we're trying really hard to do

00:12:02.590 --> 00:12:02.600
chunk and we're trying really hard to do
 

00:12:02.600 --> 00:12:04.750
chunk and we're trying really hard to do
that and we ran out of memory so we

00:12:04.750 --> 00:12:04.760
that and we ran out of memory so we
 

00:12:04.760 --> 00:12:06.700
that and we ran out of memory so we
cannot find space for two Meg's out of

00:12:06.700 --> 00:12:06.710
cannot find space for two Meg's out of
 

00:12:06.710 --> 00:12:09.010
cannot find space for two Meg's out of
200 because apparently dalvik was really

00:12:09.010 --> 00:12:09.020
200 because apparently dalvik was really
 

00:12:09.020 --> 00:12:11.590
200 because apparently dalvik was really
bad at math the problem was of course if

00:12:11.590 --> 00:12:11.600
bad at math the problem was of course if
 

00:12:11.600 --> 00:12:13.540
bad at math the problem was of course if
we couldn't find 2 Meg's contiguous and

00:12:13.540 --> 00:12:13.550
we couldn't find 2 Meg's contiguous and
 

00:12:13.550 --> 00:12:15.550
we couldn't find 2 Meg's contiguous and
dalvik net I'll have the ability to

00:12:15.550 --> 00:12:15.560
dalvik net I'll have the ability to
 

00:12:15.560 --> 00:12:17.440
dalvik net I'll have the ability to
compact the heap you get what you get

00:12:17.440 --> 00:12:17.450
compact the heap you get what you get
 

00:12:17.450 --> 00:12:19.390
compact the heap you get what you get
once we put the thing there it was not

00:12:19.390 --> 00:12:19.400
once we put the thing there it was not
 

00:12:19.400 --> 00:12:20.620
once we put the thing there it was not
going to move so we couldn't actually

00:12:20.620 --> 00:12:20.630
going to move so we couldn't actually
 

00:12:20.630 --> 00:12:22.900
going to move so we couldn't actually
shove stuff to the side to make a room

00:12:22.900 --> 00:12:22.910
shove stuff to the side to make a room
 

00:12:22.910 --> 00:12:27.550
shove stuff to the side to make a room
for a larger object so art came along in

00:12:27.550 --> 00:12:27.560
for a larger object so art came along in
 

00:12:27.560 --> 00:12:30.460
for a larger object so art came along in
lollipop as I said it's a platform for

00:12:30.460 --> 00:12:30.470
lollipop as I said it's a platform for
 

00:12:30.470 --> 00:12:32.170
lollipop as I said it's a platform for
optimizations it no longer had the

00:12:32.170 --> 00:12:32.180
optimizations it no longer had the
 

00:12:32.180 --> 00:12:33.700
optimizations it no longer had the
memory constraints that dalvik did so

00:12:33.700 --> 00:12:33.710
memory constraints that dalvik did so
 

00:12:33.710 --> 00:12:34.960
memory constraints that dalvik did so
they could sort of build in a lot of the

00:12:34.960 --> 00:12:34.970
they could sort of build in a lot of the
 

00:12:34.970 --> 00:12:36.550
they could sort of build in a lot of the
fundamentals that they've been improving

00:12:36.550 --> 00:12:36.560
fundamentals that they've been improving
 

00:12:36.560 --> 00:12:39.040
fundamentals that they've been improving
over time but out of the box it came

00:12:39.040 --> 00:12:39.050
over time but out of the box it came
 

00:12:39.050 --> 00:12:41.080
over time but out of the box it came
with much faster allocation times must

00:12:41.080 --> 00:12:41.090
with much faster allocation times must
 

00:12:41.090 --> 00:12:43.510
with much faster allocation times must
faster much faster collections as well

00:12:43.510 --> 00:12:43.520
faster much faster collections as well
 

00:12:43.520 --> 00:12:45.250
faster much faster collections as well
as a faster runtime the ability to do

00:12:45.250 --> 00:12:45.260
as a faster runtime the ability to do
 

00:12:45.260 --> 00:12:47.650
as a faster runtime the ability to do
ahead of time compilations who are

00:12:47.650 --> 00:12:47.660
ahead of time compilations who are
 

00:12:47.660 --> 00:12:49.660
ahead of time compilations who are
actually like running binary code all

00:12:49.660 --> 00:12:49.670
actually like running binary code all
 

00:12:49.670 --> 00:12:51.460
actually like running binary code all
the time we're not constantly getting

00:12:51.460 --> 00:12:51.470
the time we're not constantly getting
 

00:12:51.470 --> 00:12:53.200
the time we're not constantly getting
things to find how we can speed things

00:12:53.200 --> 00:12:53.210
things to find how we can speed things
 

00:12:53.210 --> 00:12:54.850
things to find how we can speed things
everything everything faster one thing

00:12:54.850 --> 00:12:54.860
everything everything faster one thing
 

00:12:54.860 --> 00:12:56.140
everything everything faster one thing
you we need to make clear is when we

00:12:56.140 --> 00:12:56.150
you we need to make clear is when we
 

00:12:56.150 --> 00:12:57.910
you we need to make clear is when we
talk about education and faster

00:12:57.910 --> 00:12:57.920
talk about education and faster
 

00:12:57.920 --> 00:12:59.920
talk about education and faster
allocation in this talk we mean just the

00:12:59.920 --> 00:12:59.930
allocation in this talk we mean just the
 

00:12:59.930 --> 00:13:01.870
allocation in this talk we mean just the
time it takes for the runtime to reserve

00:13:01.870 --> 00:13:01.880
time it takes for the runtime to reserve
 

00:13:01.880 --> 00:13:03.070
time it takes for the runtime to reserve
the memory we're not talking about the

00:13:03.070 --> 00:13:03.080
the memory we're not talking about the
 

00:13:03.080 --> 00:13:04.930
the memory we're not talking about the
time it takes to run the Constructors it

00:13:04.930 --> 00:13:04.940
time it takes to run the Constructors it
 

00:13:04.940 --> 00:13:06.340
time it takes to run the Constructors it
has nothing to do with your code it's

00:13:06.340 --> 00:13:06.350
has nothing to do with your code it's
 

00:13:06.350 --> 00:13:10.300
has nothing to do with your code it's
only in the runtime itself alright so

00:13:10.300 --> 00:13:10.310
only in the runtime itself alright so
 

00:13:10.310 --> 00:13:13.000
only in the runtime itself alright so
how did our allocation work so in our to

00:13:13.000 --> 00:13:13.010
how did our allocation work so in our to
 

00:13:13.010 --> 00:13:14.350
how did our allocation work so in our to
introduce the new educator called the

00:13:14.350 --> 00:13:14.360
introduce the new educator called the
 

00:13:14.360 --> 00:13:16.030
introduce the new educator called the
Ross Alec and I don't know what it

00:13:16.030 --> 00:13:16.040
Ross Alec and I don't know what it
 

00:13:16.040 --> 00:13:18.490
Ross Alec and I don't know what it
stands for actually but it replaces

00:13:18.490 --> 00:13:18.500
stands for actually but it replaces
 

00:13:18.500 --> 00:13:20.230
stands for actually but it replaces
something called DL malloc so the L

00:13:20.230 --> 00:13:20.240
something called DL malloc so the L
 

00:13:20.240 --> 00:13:21.920
something called DL malloc so the L
stands for Doug Lee

00:13:21.920 --> 00:13:21.930
stands for Doug Lee
 

00:13:21.930 --> 00:13:23.540
stands for Doug Lee
was also the person who wrote I believe

00:13:23.540 --> 00:13:23.550
was also the person who wrote I believe
 

00:13:23.550 --> 00:13:26.210
was also the person who wrote I believe
Java dot util dot concurrent that that's

00:13:26.210 --> 00:13:26.220
Java dot util dot concurrent that that's
 

00:13:26.220 --> 00:13:27.680
Java dot util dot concurrent that that's
what happens if you write a really nice

00:13:27.680 --> 00:13:27.690
what happens if you write a really nice
 

00:13:27.690 --> 00:13:30.170
what happens if you write a really nice
algorithm then people name the algorithm

00:13:30.170 --> 00:13:30.180
algorithm then people name the algorithm
 

00:13:30.180 --> 00:13:31.940
algorithm then people name the algorithm
yeah it's the kind of person that makes

00:13:31.940 --> 00:13:31.950
yeah it's the kind of person that makes
 

00:13:31.950 --> 00:13:34.540
yeah it's the kind of person that makes
me feel very inadequate as an engineer

00:13:34.540 --> 00:13:34.550
me feel very inadequate as an engineer
 

00:13:34.550 --> 00:13:36.560
me feel very inadequate as an engineer
really smart

00:13:36.560 --> 00:13:36.570
really smart
 

00:13:36.570 --> 00:13:38.630
really smart
anyway the omec is basically the

00:13:38.630 --> 00:13:38.640
anyway the omec is basically the
 

00:13:38.640 --> 00:13:40.699
anyway the omec is basically the
algorithm behind the malloc function

00:13:40.699 --> 00:13:40.709
algorithm behind the malloc function
 

00:13:40.709 --> 00:13:43.160
algorithm behind the malloc function
called native code so this is what you

00:13:43.160 --> 00:13:43.170
called native code so this is what you
 

00:13:43.170 --> 00:13:44.840
called native code so this is what you
use when you call malloc or call new in

00:13:44.840 --> 00:13:44.850
use when you call malloc or call new in
 

00:13:44.850 --> 00:13:46.940
use when you call malloc or call new in
C or C++ this is the algorithm we're

00:13:46.940 --> 00:13:46.950
C or C++ this is the algorithm we're
 

00:13:46.950 --> 00:13:49.040
C or C++ this is the algorithm we're
using so dalvik was relying on that

00:13:49.040 --> 00:13:49.050
using so dalvik was relying on that
 

00:13:49.050 --> 00:13:51.410
using so dalvik was relying on that
actually replaced it with its own Cobras

00:13:51.410 --> 00:13:51.420
actually replaced it with its own Cobras
 

00:13:51.420 --> 00:13:54.019
actually replaced it with its own Cobras
so the main benefit of Rostock is that

00:13:54.019 --> 00:13:54.029
so the main benefit of Rostock is that
 

00:13:54.029 --> 00:13:56.150
so the main benefit of Rostock is that
thread aware so it's able to do

00:13:56.150 --> 00:13:56.160
thread aware so it's able to do
 

00:13:56.160 --> 00:13:57.470
thread aware so it's able to do
allocations that are specific to a

00:13:57.470 --> 00:13:57.480
allocations that are specific to a
 

00:13:57.480 --> 00:13:59.030
allocations that are specific to a
thread and we're going to we're going to

00:13:59.030 --> 00:13:59.040
thread and we're going to we're going to
 

00:13:59.040 --> 00:14:00.949
thread and we're going to we're going to
look at additional detail and you

00:14:00.949 --> 00:14:00.959
look at additional detail and you
 

00:14:00.959 --> 00:14:02.510
look at additional detail and you
understand why it brings a lot of

00:14:02.510 --> 00:14:02.520
understand why it brings a lot of
 

00:14:02.520 --> 00:14:04.610
understand why it brings a lot of
benefits there's also a lot of lis or

00:14:04.610 --> 00:14:04.620
benefits there's also a lot of lis or
 

00:14:04.620 --> 00:14:06.139
benefits there's also a lot of lis or
twigs that have been done so small

00:14:06.139 --> 00:14:06.149
twigs that have been done so small
 

00:14:06.149 --> 00:14:07.820
twigs that have been done so small
allocations are grouped together to

00:14:07.820 --> 00:14:07.830
allocations are grouped together to
 

00:14:07.830 --> 00:14:10.130
allocations are grouped together to
reduce fragmentation we online large

00:14:10.130 --> 00:14:10.140
reduce fragmentation we online large
 

00:14:10.140 --> 00:14:12.620
reduce fragmentation we online large
locations on pages typically four

00:14:12.620 --> 00:14:12.630
locations on pages typically four
 

00:14:12.630 --> 00:14:15.290
locations on pages typically four
kilobytes on modern Oasis and gives you

00:14:15.290 --> 00:14:15.300
kilobytes on modern Oasis and gives you
 

00:14:15.300 --> 00:14:17.930
kilobytes on modern Oasis and gives you
better performance also final grain lock

00:14:17.930 --> 00:14:17.940
better performance also final grain lock
 

00:14:17.940 --> 00:14:19.460
better performance also final grain lock
because the garbage collector has to

00:14:19.460 --> 00:14:19.470
because the garbage collector has to
 

00:14:19.470 --> 00:14:21.440
because the garbage collector has to
acquire locks because you know we have a

00:14:21.440 --> 00:14:21.450
acquire locks because you know we have a
 

00:14:21.450 --> 00:14:23.960
acquire locks because you know we have a
lot of threads running they used to they

00:14:23.960 --> 00:14:23.970
lot of threads running they used to they
 

00:14:23.970 --> 00:14:25.910
lot of threads running they used to they
used to protect a lot more code so now

00:14:25.910 --> 00:14:25.920
used to protect a lot more code so now
 

00:14:25.920 --> 00:14:27.769
used to protect a lot more code so now
it for Tech's less code inference faster

00:14:27.769 --> 00:14:27.779
it for Tech's less code inference faster
 

00:14:27.779 --> 00:14:29.780
it for Tech's less code inference faster
and overall allocations with ross

00:14:29.780 --> 00:14:29.790
and overall allocations with ross
 

00:14:29.790 --> 00:14:31.699
and overall allocations with ross
murdock are four to five times faster

00:14:31.699 --> 00:14:31.709
murdock are four to five times faster
 

00:14:31.709 --> 00:14:34.010
murdock are four to five times faster
than they were with double again this is

00:14:34.010 --> 00:14:34.020
than they were with double again this is
 

00:14:34.020 --> 00:14:36.079
than they were with double again this is
just about the act of allocating the

00:14:36.079 --> 00:14:36.089
just about the act of allocating the
 

00:14:36.089 --> 00:14:37.610
just about the act of allocating the
memory there's nothing to do with your

00:14:37.610 --> 00:14:37.620
memory there's nothing to do with your
 

00:14:37.620 --> 00:14:38.990
memory there's nothing to do with your
code you could do something really

00:14:38.990 --> 00:14:39.000
code you could do something really
 

00:14:39.000 --> 00:14:40.910
code you could do something really
really really expensive in your in your

00:14:40.910 --> 00:14:40.920
really really expensive in your in your
 

00:14:40.920 --> 00:14:42.500
really really expensive in your in your
constructor and we would not be five

00:14:42.500 --> 00:14:42.510
constructor and we would not be five
 

00:14:42.510 --> 00:14:46.220
constructor and we would not be five
times faster than phthalic all right so

00:14:46.220 --> 00:14:46.230
times faster than phthalic all right so
 

00:14:46.230 --> 00:14:47.720
times faster than phthalic all right so
let's take a look at how allocations

00:14:47.720 --> 00:14:47.730
let's take a look at how allocations
 

00:14:47.730 --> 00:14:50.329
let's take a look at how allocations
work on art in this new system so oh

00:14:50.329 --> 00:14:50.339
work on art in this new system so oh
 

00:14:50.339 --> 00:14:53.120
work on art in this new system so oh
sorry the the other very very important

00:14:53.120 --> 00:14:53.130
sorry the the other very very important
 

00:14:53.130 --> 00:14:54.710
sorry the the other very very important
thing with art was the ability to deal

00:14:54.710 --> 00:14:54.720
thing with art was the ability to deal
 

00:14:54.720 --> 00:14:56.300
thing with art was the ability to deal
with large objects in a much better way

00:14:56.300 --> 00:14:56.310
with large objects in a much better way
 

00:14:56.310 --> 00:14:59.150
with large objects in a much better way
so you've got this normal sized objects

00:14:59.150 --> 00:14:59.160
so you've got this normal sized objects
 

00:14:59.160 --> 00:15:00.440
so you've got this normal sized objects
it's going to find a space for it and

00:15:00.440 --> 00:15:00.450
it's going to find a space for it and
 

00:15:00.450 --> 00:15:03.710
it's going to find a space for it and
the heap over here and what happens if

00:15:03.710 --> 00:15:03.720
the heap over here and what happens if
 

00:15:03.720 --> 00:15:05.180
the heap over here and what happens if
you have this large open by a large

00:15:05.180 --> 00:15:05.190
you have this large open by a large
 

00:15:05.190 --> 00:15:08.150
you have this large open by a large
object we mean an array of primitives or

00:15:08.150 --> 00:15:08.160
object we mean an array of primitives or
 

00:15:08.160 --> 00:15:10.910
object we mean an array of primitives or
string and these are the the types

00:15:10.910 --> 00:15:10.920
string and these are the the types
 

00:15:10.920 --> 00:15:12.319
string and these are the the types
chosen because we can guarantee that

00:15:12.319 --> 00:15:12.329
chosen because we can guarantee that
 

00:15:12.329 --> 00:15:13.699
chosen because we can guarantee that
these objects and will not have a

00:15:13.699 --> 00:15:13.709
these objects and will not have a
 

00:15:13.709 --> 00:15:15.230
these objects and will not have a
reference to something else they can

00:15:15.230 --> 00:15:15.240
reference to something else they can
 

00:15:15.240 --> 00:15:16.730
reference to something else they can
live completely and it's from the array

00:15:16.730 --> 00:15:16.740
live completely and it's from the array
 

00:15:16.740 --> 00:15:19.310
live completely and it's from the array
of achlys twelve kilobytes yes and that

00:15:19.310 --> 00:15:19.320
of achlys twelve kilobytes yes and that
 

00:15:19.320 --> 00:15:20.810
of achlys twelve kilobytes yes and that
is the heuristic for now that could

00:15:20.810 --> 00:15:20.820
is the heuristic for now that could
 

00:15:20.820 --> 00:15:22.160
is the heuristic for now that could
change over time but right now it's

00:15:22.160 --> 00:15:22.170
change over time but right now it's
 

00:15:22.170 --> 00:15:24.590
change over time but right now it's
twelve K primitive types are string so

00:15:24.590 --> 00:15:24.600
twelve K primitive types are string so
 

00:15:24.600 --> 00:15:25.970
twelve K primitive types are string so
you got this huge object where are we

00:15:25.970 --> 00:15:25.980
you got this huge object where are we
 

00:15:25.980 --> 00:15:28.220
you got this huge object where are we
going to put it well in dalvik we would

00:15:28.220 --> 00:15:28.230
going to put it well in dalvik we would
 

00:15:28.230 --> 00:15:30.620
going to put it well in dalvik we would
put it where exactly right you can see

00:15:30.620 --> 00:15:30.630
put it where exactly right you can see
 

00:15:30.630 --> 00:15:31.910
put it where exactly right you can see
in this fragmented heap that may there

00:15:31.910 --> 00:15:31.920
in this fragmented heap that may there
 

00:15:31.920 --> 00:15:34.069
in this fragmented heap that may there
may not be space for it in art it's a

00:15:34.069 --> 00:15:34.079
may not be space for it in art it's a
 

00:15:34.079 --> 00:15:35.540
may not be space for it in art it's a
little bit simpler the

00:15:35.540 --> 00:15:35.550
little bit simpler the
 

00:15:35.550 --> 00:15:38.000
little bit simpler the
complicated mechanism looks like this we

00:15:38.000 --> 00:15:38.010
complicated mechanism looks like this we
 

00:15:38.010 --> 00:15:40.370
complicated mechanism looks like this we
just put it somewhere we just Malecha

00:15:40.370 --> 00:15:40.380
just put it somewhere we just Malecha
 

00:15:40.380 --> 00:15:41.960
just put it somewhere we just Malecha
space for it and shove it in there it's

00:15:41.960 --> 00:15:41.970
space for it and shove it in there it's
 

00:15:41.970 --> 00:15:44.150
space for it and shove it in there it's
not even in a large object bucket that

00:15:44.150 --> 00:15:44.160
not even in a large object bucket that
 

00:15:44.160 --> 00:15:46.070
not even in a large object bucket that
holds all of them we just allocate a

00:15:46.070 --> 00:15:46.080
holds all of them we just allocate a
 

00:15:46.080 --> 00:15:47.900
holds all of them we just allocate a
space for it somewhere in there and we

00:15:47.900 --> 00:15:47.910
space for it somewhere in there and we
 

00:15:47.910 --> 00:15:49.340
space for it somewhere in there and we
say okay you are now part of the heat

00:15:49.340 --> 00:15:49.350
say okay you are now part of the heat
 

00:15:49.350 --> 00:15:50.720
say okay you are now part of the heat
but really it's just living on its own

00:15:50.720 --> 00:15:50.730
but really it's just living on its own
 

00:15:50.730 --> 00:15:54.560
but really it's just living on its own
somewhere very fast very easy it's also

00:15:54.560 --> 00:15:54.570
somewhere very fast very easy it's also
 

00:15:54.570 --> 00:15:56.420
somewhere very fast very easy it's also
a moving collector so we can actually

00:15:56.420 --> 00:15:56.430
a moving collector so we can actually
 

00:15:56.430 --> 00:15:59.060
a moving collector so we can actually
compact things so we no longer have the

00:15:59.060 --> 00:15:59.070
compact things so we no longer have the
 

00:15:59.070 --> 00:16:02.210
compact things so we no longer have the
fragmentation problem however it does

00:16:02.210 --> 00:16:02.220
fragmentation problem however it does
 

00:16:02.220 --> 00:16:07.610
fragmentation problem however it does
this in the background so actually it's

00:16:07.610 --> 00:16:07.620
this in the background so actually it's
 

00:16:07.620 --> 00:16:08.750
this in the background so actually it's
a little more complicated my

00:16:08.750 --> 00:16:08.760
a little more complicated my
 

00:16:08.760 --> 00:16:11.420
a little more complicated my
understanding originally was well if

00:16:11.420 --> 00:16:11.430
understanding originally was well if
 

00:16:11.430 --> 00:16:13.280
understanding originally was well if
your application goes into the

00:16:13.280 --> 00:16:13.290
your application goes into the
 

00:16:13.290 --> 00:16:15.410
your application goes into the
background then eventually this very

00:16:15.410 --> 00:16:15.420
background then eventually this very
 

00:16:15.420 --> 00:16:17.120
background then eventually this very
expensive operation it could take up to

00:16:17.120 --> 00:16:17.130
expensive operation it could take up to
 

00:16:17.130 --> 00:16:19.220
expensive operation it could take up to
100 milliseconds may run that's going to

00:16:19.220 --> 00:16:19.230
100 milliseconds may run that's going to
 

00:16:19.230 --> 00:16:20.870
100 milliseconds may run that's going to
compact the heap obviously we don't want

00:16:20.870 --> 00:16:20.880
compact the heap obviously we don't want
 

00:16:20.880 --> 00:16:22.130
compact the heap obviously we don't want
to run that in the foreground because

00:16:22.130 --> 00:16:22.140
to run that in the foreground because
 

00:16:22.140 --> 00:16:23.630
to run that in the foreground because
we're gonna Jack your app all over the

00:16:23.630 --> 00:16:23.640
we're gonna Jack your app all over the
 

00:16:23.640 --> 00:16:25.250
we're gonna Jack your app all over the
place we're gonna wait till it's sitting

00:16:25.250 --> 00:16:25.260
place we're gonna wait till it's sitting
 

00:16:25.260 --> 00:16:26.840
place we're gonna wait till it's sitting
there in the background user is doing

00:16:26.840 --> 00:16:26.850
there in the background user is doing
 

00:16:26.850 --> 00:16:27.889
there in the background user is doing
something else they're not paying

00:16:27.889 --> 00:16:27.899
something else they're not paying
 

00:16:27.899 --> 00:16:29.840
something else they're not paying
attention so you're we're compacting the

00:16:29.840 --> 00:16:29.850
attention so you're we're compacting the
 

00:16:29.850 --> 00:16:31.370
attention so you're we're compacting the
heap for you that's awesome so I said

00:16:31.370 --> 00:16:31.380
heap for you that's awesome so I said
 

00:16:31.380 --> 00:16:32.870
heap for you that's awesome so I said
okay well I'm gonna demonstrate this and

00:16:32.870 --> 00:16:32.880
okay well I'm gonna demonstrate this and
 

00:16:32.880 --> 00:16:36.290
okay well I'm gonna demonstrate this and
show that same defragmentation a crash

00:16:36.290 --> 00:16:36.300
show that same defragmentation a crash
 

00:16:36.300 --> 00:16:38.150
show that same defragmentation a crash
error that we saw earlier I'm gonna show

00:16:38.150 --> 00:16:38.160
error that we saw earlier I'm gonna show
 

00:16:38.160 --> 00:16:41.120
error that we saw earlier I'm gonna show
how it crashes on on KitKat using dalvik

00:16:41.120 --> 00:16:41.130
how it crashes on on KitKat using dalvik
 

00:16:41.130 --> 00:16:43.190
how it crashes on on KitKat using dalvik
and it will also crash and all of the

00:16:43.190 --> 00:16:43.200
and it will also crash and all of the
 

00:16:43.200 --> 00:16:44.960
and it will also crash and all of the
releases until we're able to do it in

00:16:44.960 --> 00:16:44.970
releases until we're able to do it in
 

00:16:44.970 --> 00:16:46.400
releases until we're able to do it in
the foreground on the later release and

00:16:46.400 --> 00:16:46.410
the foreground on the later release and
 

00:16:46.410 --> 00:16:49.460
the foreground on the later release and
oh and this will be a cool demo and then

00:16:49.460 --> 00:16:49.470
oh and this will be a cool demo and then
 

00:16:49.470 --> 00:16:52.130
oh and this will be a cool demo and then
I ran it on L and it didn't crash and

00:16:52.130 --> 00:16:52.140
I ran it on L and it didn't crash and
 

00:16:52.140 --> 00:16:54.650
I ran it on L and it didn't crash and
the thing is yes it will defragment in

00:16:54.650 --> 00:16:54.660
the thing is yes it will defragment in
 

00:16:54.660 --> 00:16:56.660
the thing is yes it will defragment in
the backgrounds but it will also do it

00:16:56.660 --> 00:16:56.670
the backgrounds but it will also do it
 

00:16:56.670 --> 00:16:58.760
the backgrounds but it will also do it
in the foreground if it has to which is

00:16:58.760 --> 00:16:58.770
in the foreground if it has to which is
 

00:16:58.770 --> 00:17:00.530
in the foreground if it has to which is
really what you want so if you actually

00:17:00.530 --> 00:17:00.540
really what you want so if you actually
 

00:17:00.540 --> 00:17:03.380
really what you want so if you actually
need that memory now wouldn't it be nice

00:17:03.380 --> 00:17:03.390
need that memory now wouldn't it be nice
 

00:17:03.390 --> 00:17:05.030
need that memory now wouldn't it be nice
if you didn't crash that's a clean the

00:17:05.030 --> 00:17:05.040
if you didn't crash that's a clean the
 

00:17:05.040 --> 00:17:06.710
if you didn't crash that's a clean the
compaction is almost a replacement for

00:17:06.710 --> 00:17:06.720
compaction is almost a replacement for
 

00:17:06.720 --> 00:17:09.679
compaction is almost a replacement for
the GC for our look yeah from before so

00:17:09.679 --> 00:17:09.689
the GC for our look yeah from before so
 

00:17:09.689 --> 00:17:11.900
the GC for our look yeah from before so
now it basically takes everything it

00:17:11.900 --> 00:17:11.910
now it basically takes everything it
 

00:17:11.910 --> 00:17:13.460
now it basically takes everything it
says well you need space for this really

00:17:13.460 --> 00:17:13.470
says well you need space for this really
 

00:17:13.470 --> 00:17:15.169
says well you need space for this really
large objects we're gonna go ahead and

00:17:15.169 --> 00:17:15.179
large objects we're gonna go ahead and
 

00:17:15.179 --> 00:17:18.140
large objects we're gonna go ahead and
compact things and then put it where we

00:17:18.140 --> 00:17:18.150
compact things and then put it where we
 

00:17:18.150 --> 00:17:21.650
compact things and then put it where we
need to so on L and above we run the

00:17:21.650 --> 00:17:21.660
need to so on L and above we run the
 

00:17:21.660 --> 00:17:23.510
need to so on L and above we run the
same fragmentation demo that we saw

00:17:23.510 --> 00:17:23.520
same fragmentation demo that we saw
 

00:17:23.520 --> 00:17:25.990
same fragmentation demo that we saw
before we go ahead and Alec up to the

00:17:25.990 --> 00:17:26.000
before we go ahead and Alec up to the
 

00:17:26.000 --> 00:17:28.549
before we go ahead and Alec up to the
maximum heap size it says yep you've

00:17:28.549 --> 00:17:28.559
maximum heap size it says yep you've
 

00:17:28.559 --> 00:17:30.799
maximum heap size it says yep you've
only got about one Meg free and we go

00:17:30.799 --> 00:17:30.809
only got about one Meg free and we go
 

00:17:30.809 --> 00:17:32.480
only got about one Meg free and we go
ahead and free every other Meg know

00:17:32.480 --> 00:17:32.490
ahead and free every other Meg know
 

00:17:32.490 --> 00:17:34.310
ahead and free every other Meg know
about those references and then we try

00:17:34.310 --> 00:17:34.320
about those references and then we try
 

00:17:34.320 --> 00:17:36.020
about those references and then we try
to find space for this to may block

00:17:36.020 --> 00:17:36.030
to find space for this to may block
 

00:17:36.030 --> 00:17:38.930
to find space for this to may block
compacts the heap and puts it in very

00:17:38.930 --> 00:17:38.940
compacts the heap and puts it in very
 

00:17:38.940 --> 00:17:42.230
compacts the heap and puts it in very
simple so another improvement so

00:17:42.230 --> 00:17:42.240
simple so another improvement so
 

00:17:42.240 --> 00:17:44.150
simple so another improvement so
remember with the dalvik GC we had those

00:17:44.150 --> 00:17:44.160
remember with the dalvik GC we had those
 

00:17:44.160 --> 00:17:45.919
remember with the dalvik GC we had those
four phases including two pauses for

00:17:45.919 --> 00:17:45.929
four phases including two pauses for
 

00:17:45.929 --> 00:17:47.480
four phases including two pauses for
your application

00:17:47.480 --> 00:17:47.490
your application
 

00:17:47.490 --> 00:17:49.220
your application
so the puzzles were bad because

00:17:49.220 --> 00:17:49.230
so the puzzles were bad because
 

00:17:49.230 --> 00:17:50.870
so the puzzles were bad because
your evolution was not doing anything

00:17:50.870 --> 00:17:50.880
your evolution was not doing anything
 

00:17:50.880 --> 00:17:53.000
your evolution was not doing anything
during that time but what was even worse

00:17:53.000 --> 00:17:53.010
during that time but what was even worse
 

00:17:53.010 --> 00:17:54.980
during that time but what was even worse
was that those pauses could be pretty

00:17:54.980 --> 00:17:54.990
was that those pauses could be pretty
 

00:17:54.990 --> 00:17:57.799
was that those pauses could be pretty
expensive so on average the sum of those

00:17:57.799 --> 00:17:57.809
expensive so on average the sum of those
 

00:17:57.809 --> 00:18:00.110
expensive so on average the sum of those
two places was about 10 milliseconds but

00:18:00.110 --> 00:18:00.120
two places was about 10 milliseconds but
 

00:18:00.120 --> 00:18:01.640
two places was about 10 milliseconds but
even when it was only 10 milliseconds

00:18:01.640 --> 00:18:01.650
even when it was only 10 milliseconds
 

00:18:01.650 --> 00:18:03.230
even when it was only 10 milliseconds
that was actually pretty good I mean

00:18:03.230 --> 00:18:03.240
that was actually pretty good I mean
 

00:18:03.240 --> 00:18:05.090
that was actually pretty good I mean
we've done a lot of performance work

00:18:05.090 --> 00:18:05.100
we've done a lot of performance work
 

00:18:05.100 --> 00:18:07.010
we've done a lot of performance work
over the years and I've seen this kind

00:18:07.010 --> 00:18:07.020
over the years and I've seen this kind
 

00:18:07.020 --> 00:18:09.560
over the years and I've seen this kind
of passes last for 100 200 milliseconds

00:18:09.560 --> 00:18:09.570
of passes last for 100 200 milliseconds
 

00:18:09.570 --> 00:18:11.030
of passes last for 100 200 milliseconds
in some applications and during that

00:18:11.030 --> 00:18:11.040
in some applications and during that
 

00:18:11.040 --> 00:18:13.220
in some applications and during that
time nothing happens which means no

00:18:13.220 --> 00:18:13.230
time nothing happens which means no
 

00:18:13.230 --> 00:18:15.140
time nothing happens which means no
matter how good your UI is it will

00:18:15.140 --> 00:18:15.150
matter how good your UI is it will
 

00:18:15.150 --> 00:18:16.610
matter how good your UI is it will
janked like if the user is trying to

00:18:16.610 --> 00:18:16.620
janked like if the user is trying to
 

00:18:16.620 --> 00:18:19.220
janked like if the user is trying to
scroll it's not going to work well so

00:18:19.220 --> 00:18:19.230
scroll it's not going to work well so
 

00:18:19.230 --> 00:18:22.640
scroll it's not going to work well so
one of the thing that art does is it

00:18:22.640 --> 00:18:22.650
one of the thing that art does is it
 

00:18:22.650 --> 00:18:24.470
one of the thing that art does is it
removes one of the pauses so now the

00:18:24.470 --> 00:18:24.480
removes one of the pauses so now the
 

00:18:24.480 --> 00:18:26.900
removes one of the pauses so now the
first the first step the marking the

00:18:26.900 --> 00:18:26.910
first the first step the marking the
 

00:18:26.910 --> 00:18:28.490
first the first step the marking the
route set finding the roots of all the

00:18:28.490 --> 00:18:28.500
route set finding the roots of all the
 

00:18:28.500 --> 00:18:29.960
route set finding the roots of all the
allocations that are reachable in your

00:18:29.960 --> 00:18:29.970
allocations that are reachable in your
 

00:18:29.970 --> 00:18:31.909
allocations that are reachable in your
heap is now a concurrent phase it

00:18:31.909 --> 00:18:31.919
heap is now a concurrent phase it
 

00:18:31.919 --> 00:18:33.289
heap is now a concurrent phase it
doesn't pass the application any more

00:18:33.289 --> 00:18:33.299
doesn't pass the application any more
 

00:18:33.299 --> 00:18:36.470
doesn't pass the application any more
now on top of that the second one well

00:18:36.470 --> 00:18:36.480
now on top of that the second one well
 

00:18:36.480 --> 00:18:37.970
now on top of that the second one well
the only part that we still have left is

00:18:37.970 --> 00:18:37.980
the only part that we still have left is
 

00:18:37.980 --> 00:18:40.010
the only part that we still have left is
also a lot faster so instead of spending

00:18:40.010 --> 00:18:40.020
also a lot faster so instead of spending
 

00:18:40.020 --> 00:18:41.510
also a lot faster so instead of spending
10 milliseconds in there we only spend

00:18:41.510 --> 00:18:41.520
10 milliseconds in there we only spend
 

00:18:41.520 --> 00:18:43.940
10 milliseconds in there we only spend
about 3 milliseconds now so at most your

00:18:43.940 --> 00:18:43.950
about 3 milliseconds now so at most your
 

00:18:43.950 --> 00:18:45.350
about 3 milliseconds now so at most your
application will probably pass for 3

00:18:45.350 --> 00:18:45.360
application will probably pass for 3
 

00:18:45.360 --> 00:18:47.180
application will probably pass for 3
milliseconds which worked application is

00:18:47.180 --> 00:18:47.190
milliseconds which worked application is
 

00:18:47.190 --> 00:18:49.340
milliseconds which worked application is
well optimized even if the GC happens

00:18:49.340 --> 00:18:49.350
well optimized even if the GC happens
 

00:18:49.350 --> 00:18:51.140
well optimized even if the GC happens
during an animation or scrolling you

00:18:51.140 --> 00:18:51.150
during an animation or scrolling you
 

00:18:51.150 --> 00:18:53.990
during an animation or scrolling you
should be able to like reach 60 FPS

00:18:53.990 --> 00:18:54.000
should be able to like reach 60 FPS
 

00:18:54.000 --> 00:18:57.409
should be able to like reach 60 FPS
without any jank another thing that was

00:18:57.409 --> 00:18:57.419
without any jank another thing that was
 

00:18:57.419 --> 00:18:59.000
without any jank another thing that was
introduced in art was the concept of the

00:18:59.000 --> 00:18:59.010
introduced in art was the concept of the
 

00:18:59.010 --> 00:19:01.130
introduced in art was the concept of the
minor garbage collection so the idea

00:19:01.130 --> 00:19:01.140
minor garbage collection so the idea
 

00:19:01.140 --> 00:19:04.909
minor garbage collection so the idea
here is to keep track of all the objects

00:19:04.909 --> 00:19:04.919
here is to keep track of all the objects
 

00:19:04.919 --> 00:19:06.440
here is to keep track of all the objects
that have been allocated since the last

00:19:06.440 --> 00:19:06.450
that have been allocated since the last
 

00:19:06.450 --> 00:19:09.320
that have been allocated since the last
major garbage collection those are

00:19:09.320 --> 00:19:09.330
major garbage collection those are
 

00:19:09.330 --> 00:19:11.060
major garbage collection those are
typically temporary objects and we're

00:19:11.060 --> 00:19:11.070
typically temporary objects and we're
 

00:19:11.070 --> 00:19:12.560
typically temporary objects and we're
going to look at them first so if we can

00:19:12.560 --> 00:19:12.570
going to look at them first so if we can
 

00:19:12.570 --> 00:19:14.180
going to look at them first so if we can
reclaim enough memory by looking at the

00:19:14.180 --> 00:19:14.190
reclaim enough memory by looking at the
 

00:19:14.190 --> 00:19:15.500
reclaim enough memory by looking at the
subjects first because they are

00:19:15.500 --> 00:19:15.510
subjects first because they are
 

00:19:15.510 --> 00:19:17.090
subjects first because they are
short-lived we won't have to go through

00:19:17.090 --> 00:19:17.100
short-lived we won't have to go through
 

00:19:17.100 --> 00:19:19.880
short-lived we won't have to go through
the entire heap this is one of the

00:19:19.880 --> 00:19:19.890
the entire heap this is one of the
 

00:19:19.890 --> 00:19:21.440
the entire heap this is one of the
things that has an important consequence

00:19:21.440 --> 00:19:21.450
things that has an important consequence
 

00:19:21.450 --> 00:19:23.539
things that has an important consequence
for Android development where we used to

00:19:23.539 --> 00:19:23.549
for Android development where we used to
 

00:19:23.549 --> 00:19:25.400
for Android development where we used to
tell you never allocate even temporary

00:19:25.400 --> 00:19:25.410
tell you never allocate even temporary
 

00:19:25.410 --> 00:19:26.690
tell you never allocate even temporary
objects because they tend to be

00:19:26.690 --> 00:19:26.700
objects because they tend to be
 

00:19:26.700 --> 00:19:28.070
objects because they tend to be
expensive because they're gonna fragment

00:19:28.070 --> 00:19:28.080
expensive because they're gonna fragment
 

00:19:28.080 --> 00:19:29.840
expensive because they're gonna fragment
the heap we have to do the allocation we

00:19:29.840 --> 00:19:29.850
the heap we have to do the allocation we
 

00:19:29.850 --> 00:19:31.549
the heap we have to do the allocation we
actually the collection all of a sudden

00:19:31.549 --> 00:19:31.559
actually the collection all of a sudden
 

00:19:31.559 --> 00:19:33.590
actually the collection all of a sudden
we made temporary object allocation and

00:19:33.590 --> 00:19:33.600
we made temporary object allocation and
 

00:19:33.600 --> 00:19:35.750
we made temporary object allocation and
collection much faster and easier it's

00:19:35.750 --> 00:19:35.760
collection much faster and easier it's
 

00:19:35.760 --> 00:19:39.080
collection much faster and easier it's
not free it's just less expensive yes we

00:19:39.080 --> 00:19:39.090
not free it's just less expensive yes we
 

00:19:39.090 --> 00:19:40.460
not free it's just less expensive yes we
also introduced the larger break heap

00:19:40.460 --> 00:19:40.470
also introduced the larger break heap
 

00:19:40.470 --> 00:19:41.690
also introduced the larger break heap
that we talked about so you have less

00:19:41.690 --> 00:19:41.700
that we talked about so you have less
 

00:19:41.700 --> 00:19:43.220
that we talked about so you have less
fragmentation but one of the huge

00:19:43.220 --> 00:19:43.230
fragmentation but one of the huge
 

00:19:43.230 --> 00:19:45.350
fragmentation but one of the huge
benefits of that is because we don't

00:19:45.350 --> 00:19:45.360
benefits of that is because we don't
 

00:19:45.360 --> 00:19:47.510
benefits of that is because we don't
fragment the heap as much we don't have

00:19:47.510 --> 00:19:47.520
fragment the heap as much we don't have
 

00:19:47.520 --> 00:19:49.190
fragment the heap as much we don't have
to grow the heap as much in all the

00:19:49.190 --> 00:19:49.200
to grow the heap as much in all the
 

00:19:49.200 --> 00:19:52.190
to grow the heap as much in all the
processes and of course we don't have

00:19:52.190 --> 00:19:52.200
processes and of course we don't have
 

00:19:52.200 --> 00:19:53.690
processes and of course we don't have
those GC for our opposite I mean they

00:19:53.690 --> 00:19:53.700
those GC for our opposite I mean they
 

00:19:53.700 --> 00:19:55.039
those GC for our opposite I mean they
still exist we just don't see them as

00:19:55.039 --> 00:19:55.049
still exist we just don't see them as
 

00:19:55.049 --> 00:19:56.570
still exist we just don't see them as
much because they were very very common

00:19:56.570 --> 00:19:56.580
much because they were very very common
 

00:19:56.580 --> 00:19:59.120
much because they were very very common
in the dalvik test and also like there's

00:19:59.120 --> 00:19:59.130
in the dalvik test and also like there's
 

00:19:59.130 --> 00:20:00.710
in the dalvik test and also like there's
a faster runtime you know that's the

00:20:00.710 --> 00:20:00.720
a faster runtime you know that's the
 

00:20:00.720 --> 00:20:02.380
a faster runtime you know that's the
ahead of time compilation

00:20:02.380 --> 00:20:02.390
ahead of time compilation
 

00:20:02.390 --> 00:20:04.150
ahead of time compilation
usage it back but this has nothing to do

00:20:04.150 --> 00:20:04.160
usage it back but this has nothing to do
 

00:20:04.160 --> 00:20:07.780
usage it back but this has nothing to do
with the garbage collector marshmallow I

00:20:07.780 --> 00:20:07.790
with the garbage collector marshmallow I
 

00:20:07.790 --> 00:20:10.720
with the garbage collector marshmallow I
was looking through yesterday that it's

00:20:10.720 --> 00:20:10.730
was looking through yesterday that it's
 

00:20:10.730 --> 00:20:12.070
was looking through yesterday that it's
kind of a boring release because I can

00:20:12.070 --> 00:20:12.080
kind of a boring release because I can
 

00:20:12.080 --> 00:20:14.830
kind of a boring release because I can
never remember what was marshmallow so

00:20:14.830 --> 00:20:14.840
never remember what was marshmallow so
 

00:20:14.840 --> 00:20:16.980
never remember what was marshmallow so
here it is optimizations

00:20:16.980 --> 00:20:16.990
here it is optimizations
 

00:20:16.990 --> 00:20:19.720
here it is optimizations
things got faster fine grained details

00:20:19.720 --> 00:20:19.730
things got faster fine grained details
 

00:20:19.730 --> 00:20:25.360
things got faster fine grained details
things got faster and in N again things

00:20:25.360 --> 00:20:25.370
things got faster and in N again things
 

00:20:25.370 --> 00:20:28.090
things got faster and in N again things
got faster isn't that nice allocation in

00:20:28.090 --> 00:20:28.100
got faster isn't that nice allocation in
 

00:20:28.100 --> 00:20:30.370
got faster isn't that nice allocation in
particular they rewrote everything

00:20:30.370 --> 00:20:30.380
particular they rewrote everything
 

00:20:30.380 --> 00:20:32.590
particular they rewrote everything
although all the core stuff in assembly

00:20:32.590 --> 00:20:32.600
although all the core stuff in assembly
 

00:20:32.600 --> 00:20:34.270
although all the core stuff in assembly
and that turns out to still help in

00:20:34.270 --> 00:20:34.280
and that turns out to still help in
 

00:20:34.280 --> 00:20:36.280
and that turns out to still help in
software who knew and now we're up to

00:20:36.280 --> 00:20:36.290
software who knew and now we're up to
 

00:20:36.290 --> 00:20:38.200
software who knew and now we're up to
about ten times faster for allocation

00:20:38.200 --> 00:20:38.210
about ten times faster for allocation
 

00:20:38.210 --> 00:20:41.040
about ten times faster for allocation
cost when you compare it to dalvik and

00:20:41.040 --> 00:20:41.050
cost when you compare it to dalvik and
 

00:20:41.050 --> 00:20:44.710
cost when you compare it to dalvik and
now we're in our Oreo where basically

00:20:44.710 --> 00:20:44.720
now we're in our Oreo where basically
 

00:20:44.720 --> 00:20:46.090
now we're in our Oreo where basically
they rewrote the whole thing so we

00:20:46.090 --> 00:20:46.100
they rewrote the whole thing so we
 

00:20:46.100 --> 00:20:48.310
they rewrote the whole thing so we
introduced an entirely new collector

00:20:48.310 --> 00:20:48.320
introduced an entirely new collector
 

00:20:48.320 --> 00:20:49.960
introduced an entirely new collector
called the concurrent heap compaction

00:20:49.960 --> 00:20:49.970
called the concurrent heap compaction
 

00:20:49.970 --> 00:20:52.480
called the concurrent heap compaction
collector and this means that now we can

00:20:52.480 --> 00:20:52.490
collector and this means that now we can
 

00:20:52.490 --> 00:20:54.520
collector and this means that now we can
actually compact in the foreground not

00:20:54.520 --> 00:20:54.530
actually compact in the foreground not
 

00:20:54.530 --> 00:20:56.230
actually compact in the foreground not
just when we need to do that GC for

00:20:56.230 --> 00:20:56.240
just when we need to do that GC for
 

00:20:56.240 --> 00:20:58.240
just when we need to do that GC for
alloc compact to find a space but it's

00:20:58.240 --> 00:20:58.250
alloc compact to find a space but it's
 

00:20:58.250 --> 00:21:00.040
alloc compact to find a space but it's
actually running all the time moving

00:21:00.040 --> 00:21:00.050
actually running all the time moving
 

00:21:00.050 --> 00:21:02.140
actually running all the time moving
stuff around and optimizing what the

00:21:02.140 --> 00:21:02.150
stuff around and optimizing what the
 

00:21:02.150 --> 00:21:04.270
stuff around and optimizing what the
heap looks like so that allocations are

00:21:04.270 --> 00:21:04.280
heap looks like so that allocations are
 

00:21:04.280 --> 00:21:07.150
heap looks like so that allocations are
much faster and easier overall so

00:21:07.150 --> 00:21:07.160
much faster and easier overall so
 

00:21:07.160 --> 00:21:09.130
much faster and easier overall so
defragmentation in the foreground

00:21:09.130 --> 00:21:09.140
defragmentation in the foreground
 

00:21:09.140 --> 00:21:11.170
defragmentation in the foreground
you've not resizing the heap as often

00:21:11.170 --> 00:21:11.180
you've not resizing the heap as often
 

00:21:11.180 --> 00:21:12.880
you've not resizing the heap as often
because the heap is always optimized

00:21:12.880 --> 00:21:12.890
because the heap is always optimized
 

00:21:12.890 --> 00:21:14.410
because the heap is always optimized
because we're always sort of culling the

00:21:14.410 --> 00:21:14.420
because we're always sort of culling the
 

00:21:14.420 --> 00:21:16.570
because we're always sort of culling the
things out of it as necessary there's

00:21:16.570 --> 00:21:16.580
things out of it as necessary there's
 

00:21:16.580 --> 00:21:18.430
things out of it as necessary there's
far fewer GC fare always because we just

00:21:18.430 --> 00:21:18.440
far fewer GC fare always because we just
 

00:21:18.440 --> 00:21:20.110
far fewer GC fare always because we just
don't get into that situation anymore

00:21:20.110 --> 00:21:20.120
don't get into that situation anymore
 

00:21:20.120 --> 00:21:23.290
don't get into that situation anymore
huge savings for the entire device think

00:21:23.290 --> 00:21:23.300
huge savings for the entire device think
 

00:21:23.300 --> 00:21:25.180
huge savings for the entire device think
about it if you can only defragment to

00:21:25.180 --> 00:21:25.190
about it if you can only defragment to
 

00:21:25.190 --> 00:21:27.040
about it if you can only defragment to
keep when an application is in the

00:21:27.040 --> 00:21:27.050
keep when an application is in the
 

00:21:27.050 --> 00:21:28.570
keep when an application is in the
background what about the applications

00:21:28.570 --> 00:21:28.580
background what about the applications
 

00:21:28.580 --> 00:21:30.070
background what about the applications
and services that are constantly in the

00:21:30.070 --> 00:21:30.080
and services that are constantly in the
 

00:21:30.080 --> 00:21:33.100
and services that are constantly in the
foreground system service Play Services

00:21:33.100 --> 00:21:33.110
foreground system service Play Services
 

00:21:33.110 --> 00:21:35.730
foreground system service Play Services
system UI well we couldn't necessarily

00:21:35.730 --> 00:21:35.740
system UI well we couldn't necessarily
 

00:21:35.740 --> 00:21:37.840
system UI well we couldn't necessarily
defragment those until it got into a

00:21:37.840 --> 00:21:37.850
defragment those until it got into a
 

00:21:37.850 --> 00:21:40.030
defragment those until it got into a
really bad situation wouldn't be nice if

00:21:40.030 --> 00:21:40.040
really bad situation wouldn't be nice if
 

00:21:40.040 --> 00:21:41.380
really bad situation wouldn't be nice if
we could do it in the foreground so that

00:21:41.380 --> 00:21:41.390
we could do it in the foreground so that
 

00:21:41.390 --> 00:21:42.850
we could do it in the foreground so that
those things were optimized well if we

00:21:42.850 --> 00:21:42.860
those things were optimized well if we
 

00:21:42.860 --> 00:21:44.380
those things were optimized well if we
can do it for them that means we're

00:21:44.380 --> 00:21:44.390
can do it for them that means we're
 

00:21:44.390 --> 00:21:46.210
can do it for them that means we're
getting system-wide savings on the on

00:21:46.210 --> 00:21:46.220
getting system-wide savings on the on
 

00:21:46.220 --> 00:21:47.980
getting system-wide savings on the on
the pure heap size of all of those

00:21:47.980 --> 00:21:47.990
the pure heap size of all of those
 

00:21:47.990 --> 00:21:51.400
the pure heap size of all of those
applications so smaller heaps for all

00:21:51.400 --> 00:21:51.410
applications so smaller heaps for all
 

00:21:51.410 --> 00:21:53.560
applications so smaller heaps for all
means less memory in the entire system

00:21:53.560 --> 00:21:53.570
means less memory in the entire system
 

00:21:53.570 --> 00:21:55.900
means less memory in the entire system
and what we found was the entire device

00:21:55.900 --> 00:21:55.910
and what we found was the entire device
 

00:21:55.910 --> 00:21:58.300
and what we found was the entire device
had about a 30% savings on overall

00:21:58.300 --> 00:21:58.310
had about a 30% savings on overall
 

00:21:58.310 --> 00:22:01.270
had about a 30% savings on overall
memory requirements so we can take a

00:22:01.270 --> 00:22:01.280
memory requirements so we can take a
 

00:22:01.280 --> 00:22:03.670
memory requirements so we can take a
look at how compaction works in general

00:22:03.670 --> 00:22:03.680
look at how compaction works in general
 

00:22:03.680 --> 00:22:06.370
look at how compaction works in general
we have these 256 K buckets that are

00:22:06.370 --> 00:22:06.380
we have these 256 K buckets that are
 

00:22:06.380 --> 00:22:08.710
we have these 256 K buckets that are
assigned per thread which means again

00:22:08.710 --> 00:22:08.720
assigned per thread which means again
 

00:22:08.720 --> 00:22:10.900
assigned per thread which means again
huge savings in not having to lock down

00:22:10.900 --> 00:22:10.910
huge savings in not having to lock down
 

00:22:10.910 --> 00:22:12.310
huge savings in not having to lock down
all the threads to do these allocations

00:22:12.310 --> 00:22:12.320
all the threads to do these allocations
 

00:22:12.320 --> 00:22:15.010
all the threads to do these allocations
and collections instead a thread if it

00:22:15.010 --> 00:22:15.020
and collections instead a thread if it
 

00:22:15.020 --> 00:22:15.940
and collections instead a thread if it
needs memory it

00:22:15.940 --> 00:22:15.950
needs memory it
 

00:22:15.950 --> 00:22:18.879
needs memory it
just responsible for itself so a thread

00:22:18.879 --> 00:22:18.889
just responsible for itself so a thread
 

00:22:18.889 --> 00:22:20.470
just responsible for itself so a thread
says okay I need some memory it's handed

00:22:20.470 --> 00:22:20.480
says okay I need some memory it's handed
 

00:22:20.480 --> 00:22:22.060
says okay I need some memory it's handed
one of these buckets it allocates in

00:22:22.060 --> 00:22:22.070
one of these buckets it allocates in
 

00:22:22.070 --> 00:22:24.399
one of these buckets it allocates in
there and then over time that thing may

00:22:24.399 --> 00:22:24.409
there and then over time that thing may
 

00:22:24.409 --> 00:22:25.899
there and then over time that thing may
get defragmented there's a heuristic

00:22:25.899 --> 00:22:25.909
get defragmented there's a heuristic
 

00:22:25.909 --> 00:22:28.659
get defragmented there's a heuristic
that they have about if there's less

00:22:28.659 --> 00:22:28.669
that they have about if there's less
 

00:22:28.669 --> 00:22:31.120
that they have about if there's less
than 70 or 75 percent utilization and

00:22:31.120 --> 00:22:31.130
than 70 or 75 percent utilization and
 

00:22:31.130 --> 00:22:32.769
than 70 or 75 percent utilization and
one of these things then they'll go

00:22:32.769 --> 00:22:32.779
one of these things then they'll go
 

00:22:32.779 --> 00:22:34.509
one of these things then they'll go
ahead and collect it and empty the thing

00:22:34.509 --> 00:22:34.519
ahead and collect it and empty the thing
 

00:22:34.519 --> 00:22:37.000
ahead and collect it and empty the thing
out entirely so we see the T 1 2 &amp; 3

00:22:37.000 --> 00:22:37.010
out entirely so we see the T 1 2 &amp; 3
 

00:22:37.010 --> 00:22:39.279
out entirely so we see the T 1 2 &amp; 3
regions here don't have much going on

00:22:39.279 --> 00:22:39.289
regions here don't have much going on
 

00:22:39.289 --> 00:22:40.570
regions here don't have much going on
there so we're going to take the memory

00:22:40.570 --> 00:22:40.580
there so we're going to take the memory
 

00:22:40.580 --> 00:22:42.759
there so we're going to take the memory
in there all of those allocations and

00:22:42.759 --> 00:22:42.769
in there all of those allocations and
 

00:22:42.769 --> 00:22:44.049
in there all of those allocations and
shove them somewhere else on the heap

00:22:44.049 --> 00:22:44.059
shove them somewhere else on the heap
 

00:22:44.059 --> 00:22:47.049
shove them somewhere else on the heap
completely empty out those buckets which

00:22:47.049 --> 00:22:47.059
completely empty out those buckets which
 

00:22:47.059 --> 00:22:49.330
completely empty out those buckets which
allows something that's super efficient

00:22:49.330 --> 00:22:49.340
allows something that's super efficient
 

00:22:49.340 --> 00:22:51.639
allows something that's super efficient
called thread-local bump allocator this

00:22:51.639 --> 00:22:51.649
called thread-local bump allocator this
 

00:22:51.649 --> 00:22:53.200
called thread-local bump allocator this
means that all we have to do is actually

00:22:53.200 --> 00:22:53.210
means that all we have to do is actually
 

00:22:53.210 --> 00:22:54.879
means that all we have to do is actually
just move a pointer we don't need to

00:22:54.879 --> 00:22:54.889
just move a pointer we don't need to
 

00:22:54.889 --> 00:22:56.680
just move a pointer we don't need to
walk the heap to find where the free

00:22:56.680 --> 00:22:56.690
walk the heap to find where the free
 

00:22:56.690 --> 00:22:59.350
walk the heap to find where the free
space is we just put the next object in

00:22:59.350 --> 00:22:59.360
space is we just put the next object in
 

00:22:59.360 --> 00:23:01.240
space is we just put the next object in
the next available space and we know

00:23:01.240 --> 00:23:01.250
the next available space and we know
 

00:23:01.250 --> 00:23:02.740
the next available space and we know
where that is according to the pointer

00:23:02.740 --> 00:23:02.750
where that is according to the pointer
 

00:23:02.750 --> 00:23:04.840
where that is according to the pointer
turns out all of this stuff put together

00:23:04.840 --> 00:23:04.850
turns out all of this stuff put together
 

00:23:04.850 --> 00:23:07.629
turns out all of this stuff put together
we're now 18 times faster than dalvik

00:23:07.629 --> 00:23:07.639
we're now 18 times faster than dalvik
 

00:23:07.639 --> 00:23:10.000
we're now 18 times faster than dalvik
for these allocations so we can see how

00:23:10.000 --> 00:23:10.010
for these allocations so we can see how
 

00:23:10.010 --> 00:23:12.519
for these allocations so we can see how
these allocations work in practice you

00:23:12.519 --> 00:23:12.529
these allocations work in practice you
 

00:23:12.529 --> 00:23:14.080
these allocations work in practice you
can see all these little colored objects

00:23:14.080 --> 00:23:14.090
can see all these little colored objects
 

00:23:14.090 --> 00:23:15.279
can see all these little colored objects
we're making space for them and the

00:23:15.279 --> 00:23:15.289
we're making space for them and the
 

00:23:15.289 --> 00:23:16.360
we're making space for them and the
different threads that need those

00:23:16.360 --> 00:23:16.370
different threads that need those
 

00:23:16.370 --> 00:23:18.580
different threads that need those
allocations if we take a close look at

00:23:18.580 --> 00:23:18.590
allocations if we take a close look at
 

00:23:18.590 --> 00:23:19.210
allocations if we take a close look at
t1

00:23:19.210 --> 00:23:19.220
t1
 

00:23:19.220 --> 00:23:20.500
t1
you've got the free pointer we've

00:23:20.500 --> 00:23:20.510
you've got the free pointer we've
 

00:23:20.510 --> 00:23:22.539
you've got the free pointer we've
emptied it out we've zeroed it out we're

00:23:22.539 --> 00:23:22.549
emptied it out we've zeroed it out we're
 

00:23:22.549 --> 00:23:24.009
emptied it out we've zeroed it out we're
at the beginning of that bucket and now

00:23:24.009 --> 00:23:24.019
at the beginning of that bucket and now
 

00:23:24.019 --> 00:23:25.960
at the beginning of that bucket and now
we need to allocate an object well we

00:23:25.960 --> 00:23:25.970
we need to allocate an object well we
 

00:23:25.970 --> 00:23:27.700
we need to allocate an object well we
know where to put it because the pointer

00:23:27.700 --> 00:23:27.710
know where to put it because the pointer
 

00:23:27.710 --> 00:23:29.769
know where to put it because the pointer
tells us and now all we do is advance

00:23:29.769 --> 00:23:29.779
tells us and now all we do is advance
 

00:23:29.779 --> 00:23:31.210
tells us and now all we do is advance
the pointer the pointer tells us where

00:23:31.210 --> 00:23:31.220
the pointer the pointer tells us where
 

00:23:31.220 --> 00:23:32.529
the pointer the pointer tells us where
to put the next one and the one after

00:23:32.529 --> 00:23:32.539
to put the next one and the one after
 

00:23:32.539 --> 00:23:35.259
to put the next one and the one after
that and so on so very fast and easy

00:23:35.259 --> 00:23:35.269
that and so on so very fast and easy
 

00:23:35.269 --> 00:23:37.120
that and so on so very fast and easy
compared to what we were doing before we

00:23:37.120 --> 00:23:37.130
compared to what we were doing before we
 

00:23:37.130 --> 00:23:38.980
compared to what we were doing before we
can see on the graph the comparison of

00:23:38.980 --> 00:23:38.990
can see on the graph the comparison of
 

00:23:38.990 --> 00:23:41.259
can see on the graph the comparison of
where we are at with dalvik allocation

00:23:41.259 --> 00:23:41.269
where we are at with dalvik allocation
 

00:23:41.269 --> 00:23:43.029
where we are at with dalvik allocation
cost compared to where we're not where

00:23:43.029 --> 00:23:43.039
cost compared to where we're not where
 

00:23:43.039 --> 00:23:45.940
cost compared to where we're not where
we're at now in O with bump pointer and

00:23:45.940 --> 00:23:45.950
we're at now in O with bump pointer and
 

00:23:45.950 --> 00:23:51.370
we're at now in O with bump pointer and
assembly allocations instead all right

00:23:51.370 --> 00:23:51.380
assembly allocations instead all right
 

00:23:51.380 --> 00:23:53.049
assembly allocations instead all right
so where are we going now it is

00:23:53.049 --> 00:23:53.059
so where are we going now it is
 

00:23:53.059 --> 00:23:54.909
so where are we going now it is
important to note that the young

00:23:54.909 --> 00:23:54.919
important to note that the young
 

00:23:54.919 --> 00:23:57.250
important to note that the young
generation stuff that we talked about is

00:23:57.250 --> 00:23:57.260
generation stuff that we talked about is
 

00:23:57.260 --> 00:23:59.919
generation stuff that we talked about is
being so awesome is currently gone but

00:23:59.919 --> 00:23:59.929
being so awesome is currently gone but
 

00:23:59.929 --> 00:24:03.039
being so awesome is currently gone but
it's back you know HP yeah what are you

00:24:03.039 --> 00:24:03.049
it's back you know HP yeah what are you
 

00:24:03.049 --> 00:24:05.950
it's back you know HP yeah what are you
being this your release yep so it's

00:24:05.950 --> 00:24:05.960
being this your release yep so it's
 

00:24:05.960 --> 00:24:07.149
being this your release yep so it's
important to note like that there are

00:24:07.149 --> 00:24:07.159
important to note like that there are
 

00:24:07.159 --> 00:24:09.039
important to note like that there are
trade-offs here like we believe it's

00:24:09.039 --> 00:24:09.049
trade-offs here like we believe it's
 

00:24:09.049 --> 00:24:10.960
trade-offs here like we believe it's
better overall all of the benefits that

00:24:10.960 --> 00:24:10.970
better overall all of the benefits that
 

00:24:10.970 --> 00:24:12.340
better overall all of the benefits that
you get from the garbage collector and

00:24:12.340 --> 00:24:12.350
you get from the garbage collector and
 

00:24:12.350 --> 00:24:14.379
you get from the garbage collector and
oh should compensate for the young

00:24:14.379 --> 00:24:14.389
oh should compensate for the young
 

00:24:14.389 --> 00:24:16.000
oh should compensate for the young
generation collections not being there

00:24:16.000 --> 00:24:16.010
generation collections not being there
 

00:24:16.010 --> 00:24:17.889
generation collections not being there
anymore however there's still a nice

00:24:17.889 --> 00:24:17.899
anymore however there's still a nice
 

00:24:17.899 --> 00:24:19.629
anymore however there's still a nice
thing to have so they're back in AOSP

00:24:19.629 --> 00:24:19.639
thing to have so they're back in AOSP
 

00:24:19.639 --> 00:24:21.850
thing to have so they're back in AOSP
so look for those to show up in a future

00:24:21.850 --> 00:24:21.860
so look for those to show up in a future
 

00:24:21.860 --> 00:24:24.759
so look for those to show up in a future
release so object pools this is a

00:24:24.759 --> 00:24:24.769
release so object pools this is a
 

00:24:24.769 --> 00:24:26.350
release so object pools this is a
technique that you know we've

00:24:26.350 --> 00:24:26.360
technique that you know we've
 

00:24:26.360 --> 00:24:28.029
technique that you know we've
recommended using in the past we use it

00:24:28.029 --> 00:24:28.039
recommended using in the past we use it
 

00:24:28.039 --> 00:24:28.659
recommended using in the past we use it
ourselves

00:24:28.659 --> 00:24:28.669
ourselves
 

00:24:28.669 --> 00:24:29.289
ourselves
X

00:24:29.289 --> 00:24:29.299
X
 

00:24:29.299 --> 00:24:31.450
X
inside the platform and the conventional

00:24:31.450 --> 00:24:31.460
inside the platform and the conventional
 

00:24:31.460 --> 00:24:33.820
inside the platform and the conventional
wisdom is that reusing object has to be

00:24:33.820 --> 00:24:33.830
wisdom is that reusing object has to be
 

00:24:33.830 --> 00:24:35.859
wisdom is that reusing object has to be
faster than educating them in collecting

00:24:35.859 --> 00:24:35.869
faster than educating them in collecting
 

00:24:35.869 --> 00:24:37.450
faster than educating them in collecting
them all the time and you can see here

00:24:37.450 --> 00:24:37.460
them all the time and you can see here
 

00:24:37.460 --> 00:24:39.039
them all the time and you can see here
we have a performance graph so the

00:24:39.039 --> 00:24:39.049
we have a performance graph so the
 

00:24:39.049 --> 00:24:41.830
we have a performance graph so the
x-axis is the size of the object that

00:24:41.830 --> 00:24:41.840
x-axis is the size of the object that
 

00:24:41.840 --> 00:24:44.979
x-axis is the size of the object that
you're creating or reusing in red it's

00:24:44.979 --> 00:24:44.989
you're creating or reusing in red it's
 

00:24:44.989 --> 00:24:47.320
you're creating or reusing in red it's
the time it takes to handle the subjects

00:24:47.320 --> 00:24:47.330
the time it takes to handle the subjects
 

00:24:47.330 --> 00:24:48.700
the time it takes to handle the subjects
with a pool and includes the time in

00:24:48.700 --> 00:24:48.710
with a pool and includes the time in
 

00:24:48.710 --> 00:24:50.109
with a pool and includes the time in
text tutors allocate and collect the

00:24:50.109 --> 00:24:50.119
text tutors allocate and collect the
 

00:24:50.119 --> 00:24:53.859
text tutors allocate and collect the
subjects and until n using a pool was

00:24:53.859 --> 00:24:53.869
subjects and until n using a pool was
 

00:24:53.869 --> 00:24:56.229
subjects and until n using a pool was
basically always a win compared to the

00:24:56.229 --> 00:24:56.239
basically always a win compared to the
 

00:24:56.239 --> 00:24:58.899
basically always a win compared to the
garbage collector but with all with all

00:24:58.899 --> 00:24:58.909
garbage collector but with all with all
 

00:24:58.909 --> 00:25:00.759
garbage collector but with all with all
the improvements we've done and this new

00:25:00.759 --> 00:25:00.769
the improvements we've done and this new
 

00:25:00.769 --> 00:25:02.619
the improvements we've done and this new
thread bump local thread bank local a

00:25:02.619 --> 00:25:02.629
thread bump local thread bank local a
 

00:25:02.629 --> 00:25:05.259
thread bump local thread bank local a
locator synchronize pools of objects are

00:25:05.259 --> 00:25:05.269
locator synchronize pools of objects are
 

00:25:05.269 --> 00:25:07.330
locator synchronize pools of objects are
generally slower and I want to emphasize

00:25:07.330 --> 00:25:07.340
generally slower and I want to emphasize
 

00:25:07.340 --> 00:25:09.789
generally slower and I want to emphasize
the synchronized part of the pool if you

00:25:09.789 --> 00:25:09.799
the synchronized part of the pool if you
 

00:25:09.799 --> 00:25:11.499
the synchronized part of the pool if you
have a pool of objects that use only on

00:25:11.499 --> 00:25:11.509
have a pool of objects that use only on
 

00:25:11.509 --> 00:25:13.899
have a pool of objects that use only on
one thread and that thread only you I

00:25:13.899 --> 00:25:13.909
one thread and that thread only you I
 

00:25:13.909 --> 00:25:15.039
one thread and that thread only you I
fix usually doing the kind of

00:25:15.039 --> 00:25:15.049
fix usually doing the kind of
 

00:25:15.049 --> 00:25:17.349
fix usually doing the kind of
optimization that art does for you now

00:25:17.349 --> 00:25:17.359
optimization that art does for you now
 

00:25:17.359 --> 00:25:19.779
optimization that art does for you now
on O so you might not see this the same

00:25:19.779 --> 00:25:19.789
on O so you might not see this the same
 

00:25:19.789 --> 00:25:21.789
on O so you might not see this the same
kind of savings but in general on O if

00:25:21.789 --> 00:25:21.799
kind of savings but in general on O if
 

00:25:21.799 --> 00:25:23.109
kind of savings but in general on O if
you have a synchronized pool of object

00:25:23.109 --> 00:25:23.119
you have a synchronized pool of object
 

00:25:23.119 --> 00:25:24.909
you have a synchronized pool of object
you'd be probably better off without

00:25:24.909 --> 00:25:24.919
you'd be probably better off without
 

00:25:24.919 --> 00:25:27.369
you'd be probably better off without
that pool again make sure you profile

00:25:27.369 --> 00:25:27.379
that pool again make sure you profile
 

00:25:27.379 --> 00:25:28.779
that pool again make sure you profile
your application before you take you out

00:25:28.779 --> 00:25:28.789
your application before you take you out
 

00:25:28.789 --> 00:25:30.729
your application before you take you out
and there's a certain memory size

00:25:30.729 --> 00:25:30.739
and there's a certain memory size
 

00:25:30.739 --> 00:25:32.859
and there's a certain memory size
certain size of object where these

00:25:32.859 --> 00:25:32.869
certain size of object where these
 

00:25:32.869 --> 00:25:35.320
certain size of object where these
graphs cross but this was in a benchmark

00:25:35.320 --> 00:25:35.330
graphs cross but this was in a benchmark
 

00:25:35.330 --> 00:25:37.029
graphs cross but this was in a benchmark
application that was really hammering it

00:25:37.029 --> 00:25:37.039
application that was really hammering it
 

00:25:37.039 --> 00:25:39.909
application that was really hammering it
and maximizing the bandwidth so the

00:25:39.909 --> 00:25:39.919
and maximizing the bandwidth so the
 

00:25:39.919 --> 00:25:41.739
and maximizing the bandwidth so the
general advice is you really shouldn't

00:25:41.739 --> 00:25:41.749
general advice is you really shouldn't
 

00:25:41.749 --> 00:25:43.450
general advice is you really shouldn't
use that especially the synchronized

00:25:43.450 --> 00:25:43.460
use that especially the synchronized
 

00:25:43.460 --> 00:25:45.999
use that especially the synchronized
pool approach because a it's error-prone

00:25:45.999 --> 00:25:46.009
pool approach because a it's error-prone
 

00:25:46.009 --> 00:25:48.820
pool approach because a it's error-prone
and tedious to manage and B it is slower

00:25:48.820 --> 00:25:48.830
and tedious to manage and B it is slower
 

00:25:48.830 --> 00:25:50.200
and tedious to manage and B it is slower
in general because that's

00:25:50.200 --> 00:25:50.210
in general because that's
 

00:25:50.210 --> 00:25:52.529
in general because that's
synchronization access tends to be

00:25:52.529 --> 00:25:52.539
synchronization access tends to be
 

00:25:52.539 --> 00:25:55.659
synchronization access tends to be
slower than what we can do now with your

00:25:55.659 --> 00:25:55.669
slower than what we can do now with your
 

00:25:55.669 --> 00:25:57.340
slower than what we can do now with your
using the lock in the whole point of oh

00:25:57.340 --> 00:25:57.350
using the lock in the whole point of oh
 

00:25:57.350 --> 00:25:58.989
using the lock in the whole point of oh
is that we don't have a lock anymore for

00:25:58.989 --> 00:25:58.999
is that we don't have a lock anymore for
 

00:25:58.999 --> 00:26:04.149
is that we don't have a lock anymore for
the applications so what are the

00:26:04.149 --> 00:26:04.159
the applications so what are the
 

00:26:04.159 --> 00:26:07.299
the applications so what are the
recommendations now creating garbage is

00:26:07.299 --> 00:26:07.309
recommendations now creating garbage is
 

00:26:07.309 --> 00:26:09.729
recommendations now creating garbage is
okay I wouldn't go out of your way to

00:26:09.729 --> 00:26:09.739
okay I wouldn't go out of your way to
 

00:26:09.739 --> 00:26:12.310
okay I wouldn't go out of your way to
create garbage it is still taking time

00:26:12.310 --> 00:26:12.320
create garbage it is still taking time
 

00:26:12.320 --> 00:26:14.859
create garbage it is still taking time
you are requiring us to take time to

00:26:14.859 --> 00:26:14.869
you are requiring us to take time to
 

00:26:14.869 --> 00:26:16.419
you are requiring us to take time to
allocate objects as well as later

00:26:16.419 --> 00:26:16.429
allocate objects as well as later
 

00:26:16.429 --> 00:26:18.849
allocate objects as well as later
collect them and you're taking up

00:26:18.849 --> 00:26:18.859
collect them and you're taking up
 

00:26:18.859 --> 00:26:20.529
collect them and you're taking up
battery in CPU and you're causing but

00:26:20.529 --> 00:26:20.539
battery in CPU and you're causing but
 

00:26:20.539 --> 00:26:22.720
battery in CPU and you're causing but
don't do that pick up after yourself you

00:26:22.720 --> 00:26:22.730
don't do that pick up after yourself you
 

00:26:22.730 --> 00:26:24.430
don't do that pick up after yourself you
should seize this it's pretty disgusting

00:26:24.430 --> 00:26:24.440
should seize this it's pretty disgusting
 

00:26:24.440 --> 00:26:28.180
should seize this it's pretty disgusting
I like to be a counterexample

00:26:28.180 --> 00:26:28.190
I like to be a counterexample
 

00:26:28.190 --> 00:26:31.599
I like to be a counterexample
so in general creating the stuff if you

00:26:31.599 --> 00:26:31.609
so in general creating the stuff if you
 

00:26:31.609 --> 00:26:33.820
so in general creating the stuff if you
need it is okay and so is collecting it

00:26:33.820 --> 00:26:33.830
need it is okay and so is collecting it
 

00:26:33.830 --> 00:26:35.619
need it is okay and so is collecting it
use the types and the objects that you

00:26:35.619 --> 00:26:35.629
use the types and the objects that you
 

00:26:35.629 --> 00:26:36.970
use the types and the objects that you
need if they make sense for the

00:26:36.970 --> 00:26:36.980
need if they make sense for the
 

00:26:36.980 --> 00:26:38.919
need if they make sense for the
architecture for the API so you're

00:26:38.919 --> 00:26:38.929
architecture for the API so you're
 

00:26:38.929 --> 00:26:40.790
architecture for the API so you're
building for the libraries for your code

00:26:40.790 --> 00:26:40.800
building for the libraries for your code
 

00:26:40.800 --> 00:26:42.770
building for the libraries for your code
go ahead and use those we are not

00:26:42.770 --> 00:26:42.780
go ahead and use those we are not
 

00:26:42.780 --> 00:26:44.960
go ahead and use those we are not
pushing everybody to use intend bit

00:26:44.960 --> 00:26:44.970
pushing everybody to use intend bit
 

00:26:44.970 --> 00:26:46.790
pushing everybody to use intend bit
flags everywhere to optimize every

00:26:46.790 --> 00:26:46.800
flags everywhere to optimize every
 

00:26:46.800 --> 00:26:49.660
flags everywhere to optimize every
little CPU cycle and memory allocation

00:26:49.660 --> 00:26:49.670
little CPU cycle and memory allocation
 

00:26:49.670 --> 00:26:52.160
little CPU cycle and memory allocation
instead go ahead and allocate when you

00:26:52.160 --> 00:26:52.170
instead go ahead and allocate when you
 

00:26:52.170 --> 00:26:54.980
instead go ahead and allocate when you
need to for use case however GC is still

00:26:54.980 --> 00:26:54.990
need to for use case however GC is still
 

00:26:54.990 --> 00:26:56.630
need to for use case however GC is still
overheads and we're going to look at the

00:26:56.630 --> 00:26:56.640
overheads and we're going to look at the
 

00:26:56.640 --> 00:26:59.690
overheads and we're going to look at the
demo that showcases that yep and make

00:26:59.690 --> 00:26:59.700
demo that showcases that yep and make
 

00:26:59.700 --> 00:27:02.570
demo that showcases that yep and make
the right choices for you and in general

00:27:02.570 --> 00:27:02.580
the right choices for you and in general
 

00:27:02.580 --> 00:27:04.820
the right choices for you and in general
the framework programmers we still are

00:27:04.820 --> 00:27:04.830
the framework programmers we still are
 

00:27:04.830 --> 00:27:06.800
the framework programmers we still are
your inner loop so we still take the old

00:27:06.800 --> 00:27:06.810
your inner loop so we still take the old
 

00:27:06.810 --> 00:27:09.200
your inner loop so we still take the old
practices because why would we allocate

00:27:09.200 --> 00:27:09.210
practices because why would we allocate
 

00:27:09.210 --> 00:27:10.910
practices because why would we allocate
if we didn't need to if we can make your

00:27:10.910 --> 00:27:10.920
if we didn't need to if we can make your
 

00:27:10.920 --> 00:27:13.370
if we didn't need to if we can make your
inner loop faster so be aware the inner

00:27:13.370 --> 00:27:13.380
inner loop faster so be aware the inner
 

00:27:13.380 --> 00:27:15.080
inner loop faster so be aware the inner
loop situations otherwise do the right

00:27:15.080 --> 00:27:15.090
loop situations otherwise do the right
 

00:27:15.090 --> 00:27:16.120
loop situations otherwise do the right
thing for your code

00:27:16.120 --> 00:27:16.130
thing for your code
 

00:27:16.130 --> 00:27:20.600
thing for your code
alright so wrote a simple application to

00:27:20.600 --> 00:27:20.610
alright so wrote a simple application to
 

00:27:20.610 --> 00:27:23.240
alright so wrote a simple application to
sort of showcase some of the jank stuff

00:27:23.240 --> 00:27:23.250
sort of showcase some of the jank stuff
 

00:27:23.250 --> 00:27:24.800
sort of showcase some of the jank stuff
that you can see because of allocations

00:27:24.800 --> 00:27:24.810
that you can see because of allocations
 

00:27:24.810 --> 00:27:27.470
that you can see because of allocations
and collections in this during the

00:27:27.470 --> 00:27:27.480
and collections in this during the
 

00:27:27.480 --> 00:27:29.600
and collections in this during the
ondraw I would call out to a method to

00:27:29.600 --> 00:27:29.610
ondraw I would call out to a method to
 

00:27:29.610 --> 00:27:32.630
ondraw I would call out to a method to
run some stuff and and in this case

00:27:32.630 --> 00:27:32.640
run some stuff and and in this case
 

00:27:32.640 --> 00:27:34.370
run some stuff and and in this case
we're gonna test Auto boxing's so we

00:27:34.370 --> 00:27:34.380
we're gonna test Auto boxing's so we
 

00:27:34.380 --> 00:27:35.960
we're gonna test Auto boxing's so we
have an array of a hundred thousand

00:27:35.960 --> 00:27:35.970
have an array of a hundred thousand
 

00:27:35.970 --> 00:27:38.810
have an array of a hundred thousand
float objects capital F float objects so

00:27:38.810 --> 00:27:38.820
float objects capital F float objects so
 

00:27:38.820 --> 00:27:40.430
float objects capital F float objects so
it's not just a primitive float instead

00:27:40.430 --> 00:27:40.440
it's not just a primitive float instead
 

00:27:40.440 --> 00:27:41.810
it's not just a primitive float instead
it's the capital F so we're gonna be

00:27:41.810 --> 00:27:41.820
it's the capital F so we're gonna be
 

00:27:41.820 --> 00:27:43.280
it's the capital F so we're gonna be
allocating these objects on the fly

00:27:43.280 --> 00:27:43.290
allocating these objects on the fly
 

00:27:43.290 --> 00:27:45.410
allocating these objects on the fly
here's what the the method looks like

00:27:45.410 --> 00:27:45.420
here's what the the method looks like
 

00:27:45.420 --> 00:27:46.940
here's what the the method looks like
that's gonna run on every single frame

00:27:46.940 --> 00:27:46.950
that's gonna run on every single frame
 

00:27:46.950 --> 00:27:48.830
that's gonna run on every single frame
it's gonna walk the entire length of the

00:27:48.830 --> 00:27:48.840
it's gonna walk the entire length of the
 

00:27:48.840 --> 00:27:50.630
it's gonna walk the entire length of the
array and take a primitive float and

00:27:50.630 --> 00:27:50.640
array and take a primitive float and
 

00:27:50.640 --> 00:27:52.280
array and take a primitive float and
stuff it into the array which is going

00:27:52.280 --> 00:27:52.290
stuff it into the array which is going
 

00:27:52.290 --> 00:27:53.900
stuff it into the array which is going
to cause an auto box so these little

00:27:53.900 --> 00:27:53.910
to cause an auto box so these little
 

00:27:53.910 --> 00:27:56.240
to cause an auto box so these little
tiny allocations are gonna go into this

00:27:56.240 --> 00:27:56.250
tiny allocations are gonna go into this
 

00:27:56.250 --> 00:27:59.450
tiny allocations are gonna go into this
array a lot of them over time because of

00:27:59.450 --> 00:27:59.460
array a lot of them over time because of
 

00:27:59.460 --> 00:28:01.190
array a lot of them over time because of
the auto boxing thing it's going to

00:28:01.190 --> 00:28:01.200
the auto boxing thing it's going to
 

00:28:01.200 --> 00:28:02.780
the auto boxing thing it's going to
cause a bunch of allocations and then

00:28:02.780 --> 00:28:02.790
cause a bunch of allocations and then
 

00:28:02.790 --> 00:28:03.980
cause a bunch of allocations and then
we're gonna need to collect them over

00:28:03.980 --> 00:28:03.990
we're gonna need to collect them over
 

00:28:03.990 --> 00:28:07.280
we're gonna need to collect them over
time as well so if we take a look at the

00:28:07.280 --> 00:28:07.290
time as well so if we take a look at the
 

00:28:07.290 --> 00:28:09.880
time as well so if we take a look at the
demo why don't we pop out all right so

00:28:09.880 --> 00:28:09.890
demo why don't we pop out all right so
 

00:28:09.890 --> 00:28:13.580
demo why don't we pop out all right so
we're running on K here we run this

00:28:13.580 --> 00:28:13.590
we're running on K here we run this
 

00:28:13.590 --> 00:28:17.150
we're running on K here we run this
animation we should take a look at the

00:28:17.150 --> 00:28:17.160
animation we should take a look at the
 

00:28:17.160 --> 00:28:21.440
animation we should take a look at the
log here and we run the auto box and now

00:28:21.440 --> 00:28:21.450
log here and we run the auto box and now
 

00:28:21.450 --> 00:28:22.910
log here and we run the auto box and now
we're calling out to that method and the

00:28:22.910 --> 00:28:22.920
we're calling out to that method and the
 

00:28:22.920 --> 00:28:24.830
we're calling out to that method and the
important thing here if you look at the

00:28:24.830 --> 00:28:24.840
important thing here if you look at the
 

00:28:24.840 --> 00:28:31.240
important thing here if you look at the
log so we're taking allocation times of

00:28:31.240 --> 00:28:31.250
log so we're taking allocation times of
 

00:28:31.250 --> 00:28:34.820
log so we're taking allocation times of
2824 sort of in general kind of high 20s

00:28:34.820 --> 00:28:34.830
2824 sort of in general kind of high 20s
 

00:28:34.830 --> 00:28:36.650
2824 sort of in general kind of high 20s
milliseconds and we're causing a lot of

00:28:36.650 --> 00:28:36.660
milliseconds and we're causing a lot of
 

00:28:36.660 --> 00:28:38.900
milliseconds and we're causing a lot of
GC for Alex because that is what happens

00:28:38.900 --> 00:28:38.910
GC for Alex because that is what happens
 

00:28:38.910 --> 00:28:41.750
GC for Alex because that is what happens
when you do this thing so we can pause

00:28:41.750 --> 00:28:41.760
when you do this thing so we can pause
 

00:28:41.760 --> 00:28:43.370
when you do this thing so we can pause
this one but we can pop over and see

00:28:43.370 --> 00:28:43.380
this one but we can pop over and see
 

00:28:43.380 --> 00:28:44.630
this one but we can pop over and see
what this looks like I know oh we can

00:28:44.630 --> 00:28:44.640
what this looks like I know oh we can
 

00:28:44.640 --> 00:28:46.880
what this looks like I know oh we can
run the animation here let me enable the

00:28:46.880 --> 00:28:46.890
run the animation here let me enable the
 

00:28:46.890 --> 00:28:52.670
run the animation here let me enable the
log for o we'll do the auto boxing and

00:28:52.670 --> 00:28:52.680
log for o we'll do the auto boxing and
 

00:28:52.680 --> 00:28:54.050
log for o we'll do the auto boxing and
now we can zoom in and this and you will

00:28:54.050 --> 00:28:54.060
now we can zoom in and this and you will
 

00:28:54.060 --> 00:28:54.730
now we can zoom in and this and you will
notice a couple

00:28:54.730 --> 00:28:54.740
notice a couple
 

00:28:54.740 --> 00:28:56.860
notice a couple
one is that the allocation times

00:28:56.860 --> 00:28:56.870
one is that the allocation times
 

00:28:56.870 --> 00:28:59.500
one is that the allocation times
obviously are much less than they were

00:28:59.500 --> 00:28:59.510
obviously are much less than they were
 

00:28:59.510 --> 00:29:01.299
obviously are much less than they were
before and also more importantly there

00:29:01.299 --> 00:29:01.309
before and also more importantly there
 

00:29:01.309 --> 00:29:03.549
before and also more importantly there
are no GC for Alex we allocate we

00:29:03.549 --> 00:29:03.559
are no GC for Alex we allocate we
 

00:29:03.559 --> 00:29:05.049
are no GC for Alex we allocate we
collect but we're never triggering that

00:29:05.049 --> 00:29:05.059
collect but we're never triggering that
 

00:29:05.059 --> 00:29:07.480
collect but we're never triggering that
that jank inducing GC for alloc in this

00:29:07.480 --> 00:29:07.490
that jank inducing GC for alloc in this
 

00:29:07.490 --> 00:29:12.820
that jank inducing GC for alloc in this
case there is a similar test that I

00:29:12.820 --> 00:29:12.830
case there is a similar test that I
 

00:29:12.830 --> 00:29:15.790
case there is a similar test that I
wrote for bitmaps so we're running along

00:29:15.790 --> 00:29:15.800
wrote for bitmaps so we're running along
 

00:29:15.800 --> 00:29:21.100
wrote for bitmaps so we're running along
let's take a look at the KitKat log so

00:29:21.100 --> 00:29:21.110
let's take a look at the KitKat log so
 

00:29:21.110 --> 00:29:23.590
let's take a look at the KitKat log so
in this one you're allocating bitmaps

00:29:23.590 --> 00:29:23.600
in this one you're allocating bitmaps
 

00:29:23.600 --> 00:29:25.720
in this one you're allocating bitmaps
and again we're getting a lot of jank

00:29:25.720 --> 00:29:25.730
and again we're getting a lot of jank
 

00:29:25.730 --> 00:29:28.090
and again we're getting a lot of jank
there if we zoom in on the log you're

00:29:28.090 --> 00:29:28.100
there if we zoom in on the log you're
 

00:29:28.100 --> 00:29:29.650
there if we zoom in on the log you're
seeing the allocations for these large

00:29:29.650 --> 00:29:29.660
seeing the allocations for these large
 

00:29:29.660 --> 00:29:31.630
seeing the allocations for these large
objects it's a thousand by a thousand

00:29:31.630 --> 00:29:31.640
objects it's a thousand by a thousand
 

00:29:31.640 --> 00:29:34.000
objects it's a thousand by a thousand
bitmap you take in 1213 milliseconds

00:29:34.000 --> 00:29:34.010
bitmap you take in 1213 milliseconds
 

00:29:34.010 --> 00:29:35.380
bitmap you take in 1213 milliseconds
each time and you're constantly

00:29:35.380 --> 00:29:35.390
each time and you're constantly
 

00:29:35.390 --> 00:29:37.630
each time and you're constantly
triggering these GC for Alex because you

00:29:37.630 --> 00:29:37.640
triggering these GC for Alex because you
 

00:29:37.640 --> 00:29:39.460
triggering these GC for Alex because you
need to collect the old memory to make

00:29:39.460 --> 00:29:39.470
need to collect the old memory to make
 

00:29:39.470 --> 00:29:43.030
need to collect the old memory to make
room for the new one so we pop over to

00:29:43.030 --> 00:29:43.040
room for the new one so we pop over to
 

00:29:43.040 --> 00:29:47.290
room for the new one so we pop over to
the O log let's stop this one go over

00:29:47.290 --> 00:29:47.300
the O log let's stop this one go over
 

00:29:47.300 --> 00:29:50.350
the O log let's stop this one go over
here run the animation do the bitmap

00:29:50.350 --> 00:29:50.360
here run the animation do the bitmap
 

00:29:50.360 --> 00:29:52.840
here run the animation do the bitmap
test and now we've got allocation times

00:29:52.840 --> 00:29:52.850
test and now we've got allocation times
 

00:29:52.850 --> 00:29:56.260
test and now we've got allocation times
of zero one because again all what's

00:29:56.260 --> 00:29:56.270
of zero one because again all what's
 

00:29:56.270 --> 00:29:57.910
of zero one because again all what's
doing is am Alex just shoving it into

00:29:57.910 --> 00:29:57.920
doing is am Alex just shoving it into
 

00:29:57.920 --> 00:29:59.980
doing is am Alex just shoving it into
the large object heap very easy to

00:29:59.980 --> 00:29:59.990
the large object heap very easy to
 

00:29:59.990 --> 00:30:01.600
the large object heap very easy to
allocate very easy to collect when it

00:30:01.600 --> 00:30:01.610
allocate very easy to collect when it
 

00:30:01.610 --> 00:30:09.669
allocate very easy to collect when it
needs it stump for that alright

00:30:09.669 --> 00:30:09.679
needs it stump for that alright
 

00:30:09.679 --> 00:30:12.010
needs it stump for that alright
that just duplicates what I just said

00:30:12.010 --> 00:30:12.020
that just duplicates what I just said
 

00:30:12.020 --> 00:30:14.380
that just duplicates what I just said
here's the bitmap test very simple it's

00:30:14.380 --> 00:30:14.390
here's the bitmap test very simple it's
 

00:30:14.390 --> 00:30:16.840
here's the bitmap test very simple it's
just walking through every frame it's

00:30:16.840 --> 00:30:16.850
just walking through every frame it's
 

00:30:16.850 --> 00:30:18.880
just walking through every frame it's
allocating a thousand by a thousand

00:30:18.880 --> 00:30:18.890
allocating a thousand by a thousand
 

00:30:18.890 --> 00:30:20.350
allocating a thousand by a thousand
bitmap and then you see the results that

00:30:20.350 --> 00:30:20.360
bitmap and then you see the results that
 

00:30:20.360 --> 00:30:25.390
bitmap and then you see the results that
we did all right so this is a demo to

00:30:25.390 --> 00:30:25.400
we did all right so this is a demo to
 

00:30:25.400 --> 00:30:27.010
we did all right so this is a demo to
basically stress tests to garbage

00:30:27.010 --> 00:30:27.020
basically stress tests to garbage
 

00:30:27.020 --> 00:30:28.480
basically stress tests to garbage
collector and see what kind of overhead

00:30:28.480 --> 00:30:28.490
collector and see what kind of overhead
 

00:30:28.490 --> 00:30:30.850
collector and see what kind of overhead
we get so this is a kind of a red tracer

00:30:30.850 --> 00:30:30.860
we get so this is a kind of a red tracer
 

00:30:30.860 --> 00:30:32.560
we get so this is a kind of a red tracer
using fancy physically based rendering

00:30:32.560 --> 00:30:32.570
using fancy physically based rendering
 

00:30:32.570 --> 00:30:34.720
using fancy physically based rendering
that I wrote for for my desktop

00:30:34.720 --> 00:30:34.730
that I wrote for for my desktop
 

00:30:34.730 --> 00:30:36.310
that I wrote for for my desktop
intelligent ray tracer because it's a

00:30:36.310 --> 00:30:36.320
intelligent ray tracer because it's a
 

00:30:36.320 --> 00:30:38.580
intelligent ray tracer because it's a
checkerboard with spheres that's right

00:30:38.580 --> 00:30:38.590
checkerboard with spheres that's right
 

00:30:38.590 --> 00:30:43.090
checkerboard with spheres that's right
and I ported it to Android and I won't

00:30:43.090 --> 00:30:43.100
and I ported it to Android and I won't
 

00:30:43.100 --> 00:30:44.500
and I ported it to Android and I won't
run you through the code because there's

00:30:44.500 --> 00:30:44.510
run you through the code because there's
 

00:30:44.510 --> 00:30:46.390
run you through the code because there's
hundreds of lines of code so this is

00:30:46.390 --> 00:30:46.400
hundreds of lines of code so this is
 

00:30:46.400 --> 00:30:48.370
hundreds of lines of code so this is
Scotland but the trick here is that

00:30:48.370 --> 00:30:48.380
Scotland but the trick here is that
 

00:30:48.380 --> 00:30:50.140
Scotland but the trick here is that
these does all water allocation so I

00:30:50.140 --> 00:30:50.150
these does all water allocation so I
 

00:30:50.150 --> 00:30:51.730
these does all water allocation so I
have a data class they float three just

00:30:51.730 --> 00:30:51.740
have a data class they float three just
 

00:30:51.740 --> 00:30:53.950
have a data class they float three just
contains three floats XY and Z those are

00:30:53.950 --> 00:30:53.960
contains three floats XY and Z those are
 

00:30:53.960 --> 00:30:55.780
contains three floats XY and Z those are
primitives they're not the the the

00:30:55.780 --> 00:30:55.790
primitives they're not the the the
 

00:30:55.790 --> 00:30:57.760
primitives they're not the the the
capital F objects that you get in Java

00:30:57.760 --> 00:30:57.770
capital F objects that you get in Java
 

00:30:57.770 --> 00:30:59.530
capital F objects that you get in Java
and here have a functions just an

00:30:59.530 --> 00:30:59.540
and here have a functions just an
 

00:30:59.540 --> 00:31:01.030
and here have a functions just an
excerpt of those hundreds of lines of

00:31:01.030 --> 00:31:01.040
excerpt of those hundreds of lines of
 

00:31:01.040 --> 00:31:02.560
excerpt of those hundreds of lines of
code and you can see it's just doing

00:31:02.560 --> 00:31:02.570
code and you can see it's just doing
 

00:31:02.570 --> 00:31:03.970
code and you can see it's just doing
math on the objects so I'm using

00:31:03.970 --> 00:31:03.980
math on the objects so I'm using
 

00:31:03.980 --> 00:31:06.430
math on the objects so I'm using
operator overloading in Catalan we are

00:31:06.430 --> 00:31:06.440
operator overloading in Catalan we are
 

00:31:06.440 --> 00:31:07.700
operator overloading in Catalan we are
multiplying

00:31:07.700 --> 00:31:07.710
multiplying
 

00:31:07.710 --> 00:31:09.470
multiplying
floats recalled ex by a bunch of

00:31:09.470 --> 00:31:09.480
floats recalled ex by a bunch of
 

00:31:09.480 --> 00:31:11.150
floats recalled ex by a bunch of
constants we're doing division additions

00:31:11.150 --> 00:31:11.160
constants we're doing division additions
 

00:31:11.160 --> 00:31:13.010
constants we're doing division additions
but the important thing here is that the

00:31:13.010 --> 00:31:13.020
but the important thing here is that the
 

00:31:13.020 --> 00:31:14.540
but the important thing here is that the
way those functions are implemented my

00:31:14.540 --> 00:31:14.550
way those functions are implemented my
 

00:31:14.550 --> 00:31:17.660
way those functions are implemented my
float 3 is immutable so every time I add

00:31:17.660 --> 00:31:17.670
float 3 is immutable so every time I add
 

00:31:17.670 --> 00:31:19.970
float 3 is immutable so every time I add
on multiply I'm creating a new float 3

00:31:19.970 --> 00:31:19.980
on multiply I'm creating a new float 3
 

00:31:19.980 --> 00:31:21.650
on multiply I'm creating a new float 3
object so those are fairly small objects

00:31:21.650 --> 00:31:21.660
object so those are fairly small objects
 

00:31:21.660 --> 00:31:23.900
object so those are fairly small objects
but for every pixel that we'll want to

00:31:23.900 --> 00:31:23.910
but for every pixel that we'll want to
 

00:31:23.910 --> 00:31:25.460
but for every pixel that we'll want to
render in that red racer we're going to

00:31:25.460 --> 00:31:25.470
render in that red racer we're going to
 

00:31:25.470 --> 00:31:26.960
render in that red racer we're going to
be allocating hundreds of thousands or

00:31:26.960 --> 00:31:26.970
be allocating hundreds of thousands or
 

00:31:26.970 --> 00:31:29.240
be allocating hundreds of thousands or
millions of this fruit trees so we're

00:31:29.240 --> 00:31:29.250
millions of this fruit trees so we're
 

00:31:29.250 --> 00:31:31.550
millions of this fruit trees so we're
going to really exercise the GC so then

00:31:31.550 --> 00:31:31.560
going to really exercise the GC so then
 

00:31:31.560 --> 00:31:34.850
going to really exercise the GC so then
I created two system images one on

00:31:34.850 --> 00:31:34.860
I created two system images one on
 

00:31:34.860 --> 00:31:37.250
I created two system images one on
KitKat one on O both running on the

00:31:37.250 --> 00:31:37.260
KitKat one on O both running on the
 

00:31:37.260 --> 00:31:38.780
KitKat one on O both running on the
emulator we're emulating the same

00:31:38.780 --> 00:31:38.790
emulator we're emulating the same
 

00:31:38.790 --> 00:31:41.240
emulator we're emulating the same
hardware into Nexus 5x we have the same

00:31:41.240 --> 00:31:41.250
hardware into Nexus 5x we have the same
 

00:31:41.250 --> 00:31:42.500
hardware into Nexus 5x we have the same
number of course they're running on the

00:31:42.500 --> 00:31:42.510
number of course they're running on the
 

00:31:42.510 --> 00:31:44.240
number of course they're running on the
same host machine so the only difference

00:31:44.240 --> 00:31:44.250
same host machine so the only difference
 

00:31:44.250 --> 00:31:47.300
same host machine so the only difference
really is the garbage collector when I'm

00:31:47.300 --> 00:31:47.310
really is the garbage collector when I'm
 

00:31:47.310 --> 00:31:48.860
really is the garbage collector when I'm
going to press next

00:31:48.860 --> 00:31:48.870
going to press next
 

00:31:48.870 --> 00:31:51.170
going to press next
both demos will run at the same time

00:31:51.170 --> 00:31:51.180
both demos will run at the same time
 

00:31:51.180 --> 00:31:52.190
both demos will run at the same time
we're going to start rendering an

00:31:52.190 --> 00:31:52.200
we're going to start rendering an
 

00:31:52.200 --> 00:31:53.750
we're going to start rendering an
animation with a try tracer and at the

00:31:53.750 --> 00:31:53.760
animation with a try tracer and at the
 

00:31:53.760 --> 00:31:55.310
animation with a try tracer and at the
top you have o and at the bottom you

00:31:55.310 --> 00:31:55.320
top you have o and at the bottom you
 

00:31:55.320 --> 00:31:57.620
top you have o and at the bottom you
have cat see if you can spot the

00:31:57.620 --> 00:31:57.630
have cat see if you can spot the
 

00:31:57.630 --> 00:32:11.120
have cat see if you can spot the
difference in performance

00:32:11.120 --> 00:32:11.130
 
 

00:32:11.130 --> 00:32:14.190
 
so we'll service some time it takes 47

00:32:14.190 --> 00:32:14.200
so we'll service some time it takes 47
 

00:32:14.200 --> 00:32:16.590
so we'll service some time it takes 47
seconds for KitKat to render the first

00:32:16.590 --> 00:32:16.600
seconds for KitKat to render the first
 

00:32:16.600 --> 00:32:19.050
seconds for KitKat to render the first
tile yeah but it's a really good it's a

00:32:19.050 --> 00:32:19.060
tile yeah but it's a really good it's a
 

00:32:19.060 --> 00:32:21.300
tile yeah but it's a really good it's a
really good tile and again the only

00:32:21.300 --> 00:32:21.310
really good tile and again the only
 

00:32:21.310 --> 00:32:22.590
really good tile and again the only
difference we're running the exact same

00:32:22.590 --> 00:32:22.600
difference we're running the exact same
 

00:32:22.600 --> 00:32:23.760
difference we're running the exact same
application the only difference is

00:32:23.760 --> 00:32:23.770
application the only difference is
 

00:32:23.770 --> 00:32:28.080
application the only difference is
effectively the garbage collector so on

00:32:28.080 --> 00:32:28.090
effectively the garbage collector so on
 

00:32:28.090 --> 00:32:30.570
effectively the garbage collector so on
all rendering 1 tiles takes about 100 to

00:32:30.570 --> 00:32:30.580
all rendering 1 tiles takes about 100 to
 

00:32:30.580 --> 00:32:33.900
all rendering 1 tiles takes about 100 to
500 milliseconds and on K it takes 40 to

00:32:33.900 --> 00:32:33.910
500 milliseconds and on K it takes 40 to
 

00:32:33.910 --> 00:32:35.880
500 milliseconds and on K it takes 40 to
50 seconds so two orders of magnitude

00:32:35.880 --> 00:32:35.890
50 seconds so two orders of magnitude
 

00:32:35.890 --> 00:32:38.580
50 seconds so two orders of magnitude
slower and if you look at the logs for

00:32:38.580 --> 00:32:38.590
slower and if you look at the logs for
 

00:32:38.590 --> 00:32:40.770
slower and if you look at the logs for
on KitKat this is what we see with your

00:32:40.770 --> 00:32:40.780
on KitKat this is what we see with your
 

00:32:40.780 --> 00:32:43.200
on KitKat this is what we see with your
bunch of GC for Alex and I just you know

00:32:43.200 --> 00:32:43.210
bunch of GC for Alex and I just you know
 

00:32:43.210 --> 00:32:45.300
bunch of GC for Alex and I just you know
grab logs for about 10 seconds worth of

00:32:45.300 --> 00:32:45.310
grab logs for about 10 seconds worth of
 

00:32:45.310 --> 00:32:47.280
grab logs for about 10 seconds worth of
computations and you can see we're

00:32:47.280 --> 00:32:47.290
computations and you can see we're
 

00:32:47.290 --> 00:32:50.100
computations and you can see we're
constantly stopping all the threads were

00:32:50.100 --> 00:32:50.110
constantly stopping all the threads were
 

00:32:50.110 --> 00:32:52.280
constantly stopping all the threads were
blocking the applications all the time

00:32:52.280 --> 00:32:52.290
blocking the applications all the time
 

00:32:52.290 --> 00:32:55.440
blocking the applications all the time
nothing is getting done yeah that's a

00:32:55.440 --> 00:32:55.450
nothing is getting done yeah that's a
 

00:32:55.450 --> 00:32:57.870
nothing is getting done yeah that's a
lot of a lot of disease and you can see

00:32:57.870 --> 00:32:57.880
lot of a lot of disease and you can see
 

00:32:57.880 --> 00:33:00.060
lot of a lot of disease and you can see
every time the GC takes 3 to 5

00:33:00.060 --> 00:33:00.070
every time the GC takes 3 to 5
 

00:33:00.070 --> 00:33:03.540
every time the GC takes 3 to 5
milliseconds so if we look at this trace

00:33:03.540 --> 00:33:03.550
milliseconds so if we look at this trace
 

00:33:03.550 --> 00:33:07.110
milliseconds so if we look at this trace
on o we can see that even though things

00:33:07.110 --> 00:33:07.120
on o we can see that even though things
 

00:33:07.120 --> 00:33:11.300
on o we can see that even though things
are better they are not quite perfect so

00:33:11.300 --> 00:33:11.310
are better they are not quite perfect so
 

00:33:11.310 --> 00:33:14.490
are better they are not quite perfect so
this is this trace here you can see what

00:33:14.490 --> 00:33:14.500
this is this trace here you can see what
 

00:33:14.500 --> 00:33:16.230
this is this trace here you can see what
the CPUs are doing and from afar it

00:33:16.230 --> 00:33:16.240
the CPUs are doing and from afar it
 

00:33:16.240 --> 00:33:17.640
the CPUs are doing and from afar it
looks like they are very busy because I

00:33:17.640 --> 00:33:17.650
looks like they are very busy because I
 

00:33:17.650 --> 00:33:19.320
looks like they are very busy because I
have three worker threads that are

00:33:19.320 --> 00:33:19.330
have three worker threads that are
 

00:33:19.330 --> 00:33:22.260
have three worker threads that are
computing those this 3d scene but you

00:33:22.260 --> 00:33:22.270
computing those this 3d scene but you
 

00:33:22.270 --> 00:33:24.690
computing those this 3d scene but you
can see there's a lot of cases where the

00:33:24.690 --> 00:33:24.700
can see there's a lot of cases where the
 

00:33:24.700 --> 00:33:26.340
can see there's a lot of cases where the
CPU actually not doing anything there's

00:33:26.340 --> 00:33:26.350
CPU actually not doing anything there's
 

00:33:26.350 --> 00:33:28.800
CPU actually not doing anything there's
holes in inner pipe so if you look at

00:33:28.800 --> 00:33:28.810
holes in inner pipe so if you look at
 

00:33:28.810 --> 00:33:31.530
holes in inner pipe so if you look at
the app itself we see two interesting

00:33:31.530 --> 00:33:31.540
the app itself we see two interesting
 

00:33:31.540 --> 00:33:32.850
the app itself we see two interesting
things first of all I've made three

00:33:32.850 --> 00:33:32.860
things first of all I've made three
 

00:33:32.860 --> 00:33:34.560
things first of all I've made three
threads that are computing that are

00:33:34.560 --> 00:33:34.570
threads that are computing that are
 

00:33:34.570 --> 00:33:36.750
threads that are computing that are
doing the work they are busy chugging

00:33:36.750 --> 00:33:36.760
doing the work they are busy chugging
 

00:33:36.760 --> 00:33:38.910
doing the work they are busy chugging
along but from time to time here for

00:33:38.910 --> 00:33:38.920
along but from time to time here for
 

00:33:38.920 --> 00:33:40.980
along but from time to time here for
instance the pause and you probably

00:33:40.980 --> 00:33:40.990
instance the pause and you probably
 

00:33:40.990 --> 00:33:42.780
instance the pause and you probably
can't read this but it says full suspend

00:33:42.780 --> 00:33:42.790
can't read this but it says full suspend
 

00:33:42.790 --> 00:33:44.880
can't read this but it says full suspend
and then we're not doing anything we're

00:33:44.880 --> 00:33:44.890
and then we're not doing anything we're
 

00:33:44.890 --> 00:33:46.860
and then we're not doing anything we're
not doing any computation and the reason

00:33:46.860 --> 00:33:46.870
not doing any computation and the reason
 

00:33:46.870 --> 00:33:49.410
not doing any computation and the reason
is we have this thread called the heap

00:33:49.410 --> 00:33:49.420
is we have this thread called the heap
 

00:33:49.420 --> 00:33:51.090
is we have this thread called the heap
test daemon it's basically the

00:33:51.090 --> 00:33:51.100
test daemon it's basically the
 

00:33:51.100 --> 00:33:53.130
test daemon it's basically the
concurrent garbage collector so even

00:33:53.130 --> 00:33:53.140
concurrent garbage collector so even
 

00:33:53.140 --> 00:33:54.060
concurrent garbage collector so even
though we're doing concurrent garbage

00:33:54.060 --> 00:33:54.070
though we're doing concurrent garbage
 

00:33:54.070 --> 00:33:56.070
though we're doing concurrent garbage
collection I'm allocating so many

00:33:56.070 --> 00:33:56.080
collection I'm allocating so many
 

00:33:56.080 --> 00:33:59.160
collection I'm allocating so many
objects in takes so much time for the

00:33:59.160 --> 00:33:59.170
objects in takes so much time for the
 

00:33:59.170 --> 00:34:00.840
objects in takes so much time for the
concurrent garbage collection to do its

00:34:00.840 --> 00:34:00.850
concurrent garbage collection to do its
 

00:34:00.850 --> 00:34:02.820
concurrent garbage collection to do its
job so here it's taking about 200

00:34:02.820 --> 00:34:02.830
job so here it's taking about 200
 

00:34:02.830 --> 00:34:05.100
job so here it's taking about 200
milliseconds in wall time that our

00:34:05.100 --> 00:34:05.110
milliseconds in wall time that our
 

00:34:05.110 --> 00:34:07.440
milliseconds in wall time that our
threads from time to time have to block

00:34:07.440 --> 00:34:07.450
threads from time to time have to block
 

00:34:07.450 --> 00:34:09.270
threads from time to time have to block
anyway it's not that we want to pass

00:34:09.270 --> 00:34:09.280
anyway it's not that we want to pass
 

00:34:09.280 --> 00:34:11.669
anyway it's not that we want to pass
them because we have to pass them it's

00:34:11.669 --> 00:34:11.679
them because we have to pass them it's
 

00:34:11.679 --> 00:34:12.930
them because we have to pass them it's
not for the algorithm is because the

00:34:12.930 --> 00:34:12.940
not for the algorithm is because the
 

00:34:12.940 --> 00:34:15.330
not for the algorithm is because the
garbage collector is still busy and

00:34:15.330 --> 00:34:15.340
garbage collector is still busy and
 

00:34:15.340 --> 00:34:17.070
garbage collector is still busy and
originally I was spawning more threads

00:34:17.070 --> 00:34:17.080
originally I was spawning more threads
 

00:34:17.080 --> 00:34:19.830
originally I was spawning more threads
and I was running into real situations

00:34:19.830 --> 00:34:19.840
and I was running into real situations
 

00:34:19.840 --> 00:34:21.600
and I was running into real situations
where I had so many threads doing

00:34:21.600 --> 00:34:21.610
where I had so many threads doing
 

00:34:21.610 --> 00:34:23.230
where I had so many threads doing
computation that I was starving the

00:34:23.230 --> 00:34:23.240
computation that I was starving the
 

00:34:23.240 --> 00:34:25.570
computation that I was starving the
the thread and it could not run fast

00:34:25.570 --> 00:34:25.580
the thread and it could not run fast
 

00:34:25.580 --> 00:34:26.919
the thread and it could not run fast
enough so my threads were posing even

00:34:26.919 --> 00:34:26.929
enough so my threads were posing even
 

00:34:26.929 --> 00:34:29.290
enough so my threads were posing even
more and as a result we're getting only

00:34:29.290 --> 00:34:29.300
more and as a result we're getting only
 

00:34:29.300 --> 00:34:33.159
more and as a result we're getting only
about 30 to 40% CPU utilization so we're

00:34:33.159 --> 00:34:33.169
about 30 to 40% CPU utilization so we're
 

00:34:33.169 --> 00:34:34.869
about 30 to 40% CPU utilization so we're
not using all the compute power that we

00:34:34.869 --> 00:34:34.879
not using all the compute power that we
 

00:34:34.879 --> 00:34:36.820
not using all the compute power that we
have available on the device so the demo

00:34:36.820 --> 00:34:36.830
have available on the device so the demo
 

00:34:36.830 --> 00:34:38.590
have available on the device so the demo
you saw running on oak could actually be

00:34:38.590 --> 00:34:38.600
you saw running on oak could actually be
 

00:34:38.600 --> 00:34:40.629
you saw running on oak could actually be
something like three times faster than

00:34:40.629 --> 00:34:40.639
something like three times faster than
 

00:34:40.639 --> 00:34:43.590
something like three times faster than
that if I was not allocating as much

00:34:43.590 --> 00:34:43.600
that if I was not allocating as much
 

00:34:43.600 --> 00:34:45.430
that if I was not allocating as much
another thing I wanted to talk about

00:34:45.430 --> 00:34:45.440
another thing I wanted to talk about
 

00:34:45.440 --> 00:34:46.780
another thing I wanted to talk about
when you have four minutes left so we'll

00:34:46.780 --> 00:34:46.790
when you have four minutes left so we'll
 

00:34:46.790 --> 00:34:48.669
when you have four minutes left so we'll
go through this very quickly is that you

00:34:48.669 --> 00:34:48.679
go through this very quickly is that you
 

00:34:48.679 --> 00:34:50.230
go through this very quickly is that you
have to be careful when you do when you

00:34:50.230 --> 00:34:50.240
have to be careful when you do when you
 

00:34:50.240 --> 00:34:52.330
have to be careful when you do when you
create benchmarks because the garbage

00:34:52.330 --> 00:34:52.340
create benchmarks because the garbage
 

00:34:52.340 --> 00:34:54.940
create benchmarks because the garbage
collector can greatly affect the results

00:34:54.940 --> 00:34:54.950
collector can greatly affect the results
 

00:34:54.950 --> 00:34:57.100
collector can greatly affect the results
of your benchmark once well not really

00:34:57.100 --> 00:34:57.110
of your benchmark once well not really
 

00:34:57.110 --> 00:34:58.870
of your benchmark once well not really
the benchmark itself but the algorithm

00:34:58.870 --> 00:34:58.880
the benchmark itself but the algorithm
 

00:34:58.880 --> 00:35:00.340
the benchmark itself but the algorithm
your benchmarking once it's inside your

00:35:00.340 --> 00:35:00.350
your benchmarking once it's inside your
 

00:35:00.350 --> 00:35:01.570
your benchmarking once it's inside your
application might behave very

00:35:01.570 --> 00:35:01.580
application might behave very
 

00:35:01.580 --> 00:35:03.670
application might behave very
differently so I'm going to skip some of

00:35:03.670 --> 00:35:03.680
differently so I'm going to skip some of
 

00:35:03.680 --> 00:35:05.650
differently so I'm going to skip some of
this basically a quick recap when you

00:35:05.650 --> 00:35:05.660
this basically a quick recap when you
 

00:35:05.660 --> 00:35:07.390
this basically a quick recap when you
have a CPU this is the kicks all three

00:35:07.390 --> 00:35:07.400
have a CPU this is the kicks all three
 

00:35:07.400 --> 00:35:10.000
have a CPU this is the kicks all three
CPU the gold cores we have big cores and

00:35:10.000 --> 00:35:10.010
CPU the gold cores we have big cores and
 

00:35:10.010 --> 00:35:11.200
CPU the gold cores we have big cores and
little cause I'm looking at the big

00:35:11.200 --> 00:35:11.210
little cause I'm looking at the big
 

00:35:11.210 --> 00:35:13.870
little cause I'm looking at the big
course every core has an l1 cache that's

00:35:13.870 --> 00:35:13.880
course every core has an l1 cache that's
 

00:35:13.880 --> 00:35:16.810
course every core has an l1 cache that's
about 64 kilobyte every cores an l2

00:35:16.810 --> 00:35:16.820
about 64 kilobyte every cores an l2
 

00:35:16.820 --> 00:35:20.740
about 64 kilobyte every cores an l2
cache so 256 kilobyte cache and then

00:35:20.740 --> 00:35:20.750
cache so 256 kilobyte cache and then
 

00:35:20.750 --> 00:35:22.300
cache so 256 kilobyte cache and then
there's an l-3 cache that's shared by

00:35:22.300 --> 00:35:22.310
there's an l-3 cache that's shared by
 

00:35:22.310 --> 00:35:24.790
there's an l-3 cache that's shared by
all the cores and this is important

00:35:24.790 --> 00:35:24.800
all the cores and this is important
 

00:35:24.800 --> 00:35:26.380
all the cores and this is important
because when you want to access data so

00:35:26.380 --> 00:35:26.390
because when you want to access data so
 

00:35:26.390 --> 00:35:27.730
because when you want to access data so
here we have a floater array and I just

00:35:27.730 --> 00:35:27.740
here we have a floater array and I just
 

00:35:27.740 --> 00:35:29.080
here we have a floater array and I just
want to read one float from that array

00:35:29.080 --> 00:35:29.090
want to read one float from that array
 

00:35:29.090 --> 00:35:31.510
want to read one float from that array
the first time we access that float the

00:35:31.510 --> 00:35:31.520
the first time we access that float the
 

00:35:31.520 --> 00:35:33.130
the first time we access that float the
CPUs going to go look in the l1 cache

00:35:33.130 --> 00:35:33.140
CPUs going to go look in the l1 cache
 

00:35:33.140 --> 00:35:35.290
CPUs going to go look in the l1 cache
see if it's there if it's not it has to

00:35:35.290 --> 00:35:35.300
see if it's there if it's not it has to
 

00:35:35.300 --> 00:35:37.000
see if it's there if it's not it has to
go fetch it from the l2 if it's not

00:35:37.000 --> 00:35:37.010
go fetch it from the l2 if it's not
 

00:35:37.010 --> 00:35:38.410
go fetch it from the l2 if it's not
there it has to go to the l3 and and

00:35:38.410 --> 00:35:38.420
there it has to go to the l3 and and
 

00:35:38.420 --> 00:35:41.080
there it has to go to the l3 and and
final to the RAM and every time we have

00:35:41.080 --> 00:35:41.090
final to the RAM and every time we have
 

00:35:41.090 --> 00:35:43.660
final to the RAM and every time we have
to fall back to a higher level cache we

00:35:43.660 --> 00:35:43.670
to fall back to a higher level cache we
 

00:35:43.670 --> 00:35:45.490
to fall back to a higher level cache we
have to do an expensive memory access

00:35:45.490 --> 00:35:45.500
have to do an expensive memory access
 

00:35:45.500 --> 00:35:47.020
have to do an expensive memory access
that gets more and more expensive as you

00:35:47.020 --> 00:35:47.030
that gets more and more expensive as you
 

00:35:47.030 --> 00:35:49.570
that gets more and more expensive as you
go up the chain so accessing the l1

00:35:49.570 --> 00:35:49.580
go up the chain so accessing the l1
 

00:35:49.580 --> 00:35:51.400
go up the chain so accessing the l1
takes only a few nanoseconds accessing

00:35:51.400 --> 00:35:51.410
takes only a few nanoseconds accessing
 

00:35:51.410 --> 00:35:52.630
takes only a few nanoseconds accessing
the l2 is going to take four or five

00:35:52.630 --> 00:35:52.640
the l2 is going to take four or five
 

00:35:52.640 --> 00:35:54.580
the l2 is going to take four or five
times that amount existing the other is

00:35:54.580 --> 00:35:54.590
times that amount existing the other is
 

00:35:54.590 --> 00:35:56.020
times that amount existing the other is
going to be partly ten times slower and

00:35:56.020 --> 00:35:56.030
going to be partly ten times slower and
 

00:35:56.030 --> 00:36:00.609
going to be partly ten times slower and
so on so in a I wrote a demo that

00:36:00.609 --> 00:36:00.619
so on so in a I wrote a demo that
 

00:36:00.619 --> 00:36:04.090
so on so in a I wrote a demo that
allocates a list of arrays of floats

00:36:04.090 --> 00:36:04.100
allocates a list of arrays of floats
 

00:36:04.100 --> 00:36:06.280
allocates a list of arrays of floats
each array of floats is about four it's

00:36:06.280 --> 00:36:06.290
each array of floats is about four it's
 

00:36:06.290 --> 00:36:08.290
each array of floats is about four it's
four floats so it's 16 bytes

00:36:08.290 --> 00:36:08.300
four floats so it's 16 bytes
 

00:36:08.300 --> 00:36:09.730
four floats so it's 16 bytes
they are represented by the red lines

00:36:09.730 --> 00:36:09.740
they are represented by the red lines
 

00:36:09.740 --> 00:36:13.120
they are represented by the red lines
here and I will to benchmark basically

00:36:13.120 --> 00:36:13.130
here and I will to benchmark basically
 

00:36:13.130 --> 00:36:14.349
here and I will to benchmark basically
using that I'm just going to run some

00:36:14.349 --> 00:36:14.359
using that I'm just going to run some
 

00:36:14.359 --> 00:36:15.970
using that I'm just going to run some
computations over those those are rise

00:36:15.970 --> 00:36:15.980
computations over those those are rise
 

00:36:15.980 --> 00:36:18.340
computations over those those are rise
of floats so if I look at all those

00:36:18.340 --> 00:36:18.350
of floats so if I look at all those
 

00:36:18.350 --> 00:36:19.840
of floats so if I look at all those
arrays of floats one after the other in

00:36:19.840 --> 00:36:19.850
arrays of floats one after the other in
 

00:36:19.850 --> 00:36:21.340
arrays of floats one after the other in
the loop this is what it's going to look

00:36:21.340 --> 00:36:21.350
the loop this is what it's going to look
 

00:36:21.350 --> 00:36:23.530
the loop this is what it's going to look
like in RAM all the arrays are neatly

00:36:23.530 --> 00:36:23.540
like in RAM all the arrays are neatly
 

00:36:23.540 --> 00:36:26.140
like in RAM all the arrays are neatly
stacked together next to one another in

00:36:26.140 --> 00:36:26.150
stacked together next to one another in
 

00:36:26.150 --> 00:36:29.620
stacked together next to one another in
RAM and I'm using a width of 64 bytes

00:36:29.620 --> 00:36:29.630
RAM and I'm using a width of 64 bytes
 

00:36:29.630 --> 00:36:31.210
RAM and I'm using a width of 64 bytes
here for reason that we're going to see

00:36:31.210 --> 00:36:31.220
here for reason that we're going to see
 

00:36:31.220 --> 00:36:34.060
here for reason that we're going to see
in a minute then I wrote a very simple

00:36:34.060 --> 00:36:34.070
in a minute then I wrote a very simple
 

00:36:34.070 --> 00:36:35.650
in a minute then I wrote a very simple
you know algorithm so I go through the

00:36:35.650 --> 00:36:35.660
you know algorithm so I go through the
 

00:36:35.660 --> 00:36:37.010
you know algorithm so I go through the
array at X 4

00:36:37.010 --> 00:36:37.020
array at X 4
 

00:36:37.020 --> 00:36:38.450
array at X 4
I'll run some computation it doesn't

00:36:38.450 --> 00:36:38.460
I'll run some computation it doesn't
 

00:36:38.460 --> 00:36:39.590
I'll run some computation it doesn't
really matter what computations are

00:36:39.590 --> 00:36:39.600
really matter what computations are
 

00:36:39.600 --> 00:36:41.420
really matter what computations are
running and let's see what happens to

00:36:41.420 --> 00:36:41.430
running and let's see what happens to
 

00:36:41.430 --> 00:36:43.700
running and let's see what happens to
memory so when we access the first float

00:36:43.700 --> 00:36:43.710
memory so when we access the first float
 

00:36:43.710 --> 00:36:46.520
memory so when we access the first float
array in our list it's not anywhere in

00:36:46.520 --> 00:36:46.530
array in our list it's not anywhere in
 

00:36:46.530 --> 00:36:48.740
array in our list it's not anywhere in
our caches it's in RAM it's not in the

00:36:48.740 --> 00:36:48.750
our caches it's in RAM it's not in the
 

00:36:48.750 --> 00:36:51.950
our caches it's in RAM it's not in the
l1 or the audio - audio three so we're

00:36:51.950 --> 00:36:51.960
l1 or the audio - audio three so we're
 

00:36:51.960 --> 00:36:53.840
l1 or the audio - audio three so we're
gonna go fetch it and put it in the l1

00:36:53.840 --> 00:36:53.850
gonna go fetch it and put it in the l1
 

00:36:53.850 --> 00:36:56.120
gonna go fetch it and put it in the l1
but one optimizations that CPUs have is

00:36:56.120 --> 00:36:56.130
but one optimizations that CPUs have is
 

00:36:56.130 --> 00:36:57.230
but one optimizations that CPUs have is
that when you need one byte of memory

00:36:57.230 --> 00:36:57.240
that when you need one byte of memory
 

00:36:57.240 --> 00:36:59.090
that when you need one byte of memory
they are not gonna fetch only one byte

00:36:59.090 --> 00:36:59.100
they are not gonna fetch only one byte
 

00:36:59.100 --> 00:37:00.560
they are not gonna fetch only one byte
they're going to fetch 64 bytes at a

00:37:00.560 --> 00:37:00.570
they're going to fetch 64 bytes at a
 

00:37:00.570 --> 00:37:02.990
they're going to fetch 64 bytes at a
time so by fetching the first array we

00:37:02.990 --> 00:37:03.000
time so by fetching the first array we
 

00:37:03.000 --> 00:37:04.850
time so by fetching the first array we
actually fetched the next three or rez

00:37:04.850 --> 00:37:04.860
actually fetched the next three or rez
 

00:37:04.860 --> 00:37:06.920
actually fetched the next three or rez
at the same time so then when I want to

00:37:06.920 --> 00:37:06.930
at the same time so then when I want to
 

00:37:06.930 --> 00:37:09.320
at the same time so then when I want to
read those arrays nothing happens

00:37:09.320 --> 00:37:09.330
read those arrays nothing happens
 

00:37:09.330 --> 00:37:11.650
read those arrays nothing happens
because they are already in the l1 cache

00:37:11.650 --> 00:37:11.660
because they are already in the l1 cache
 

00:37:11.660 --> 00:37:13.850
because they are already in the l1 cache
so this is pretty efficient then we run

00:37:13.850 --> 00:37:13.860
so this is pretty efficient then we run
 

00:37:13.860 --> 00:37:16.550
so this is pretty efficient then we run
our computation now in my test app I've

00:37:16.550 --> 00:37:16.560
our computation now in my test app I've
 

00:37:16.560 --> 00:37:18.620
our computation now in my test app I've
modified the initialization of the

00:37:18.620 --> 00:37:18.630
modified the initialization of the
 

00:37:18.630 --> 00:37:20.930
modified the initialization of the
arrays so that I locate other stuff

00:37:20.930 --> 00:37:20.940
arrays so that I locate other stuff
 

00:37:20.940 --> 00:37:23.300
arrays so that I locate other stuff
between each array and I'm doing this to

00:37:23.300 --> 00:37:23.310
between each array and I'm doing this to
 

00:37:23.310 --> 00:37:24.980
between each array and I'm doing this to
basically replicate what happens when

00:37:24.980 --> 00:37:24.990
basically replicate what happens when
 

00:37:24.990 --> 00:37:26.810
basically replicate what happens when
you're garbage collector move things

00:37:26.810 --> 00:37:26.820
you're garbage collector move things
 

00:37:26.820 --> 00:37:28.520
you're garbage collector move things
around or you're fragmentation the app

00:37:28.520 --> 00:37:28.530
around or you're fragmentation the app
 

00:37:28.530 --> 00:37:29.990
around or you're fragmentation the app
you should do your allocations over the

00:37:29.990 --> 00:37:30.000
you should do your allocations over the
 

00:37:30.000 --> 00:37:31.850
you should do your allocations over the
lifetime of the application for any

00:37:31.850 --> 00:37:31.860
lifetime of the application for any
 

00:37:31.860 --> 00:37:33.080
lifetime of the application for any
number of reasons that we've seen before

00:37:33.080 --> 00:37:33.090
number of reasons that we've seen before
 

00:37:33.090 --> 00:37:35.420
number of reasons that we've seen before
your locations won't be neatly next to

00:37:35.420 --> 00:37:35.430
your locations won't be neatly next to
 

00:37:35.430 --> 00:37:37.070
your locations won't be neatly next to
one another in RAM so here I'm

00:37:37.070 --> 00:37:37.080
one another in RAM so here I'm
 

00:37:37.080 --> 00:37:38.690
one another in RAM so here I'm
representing this with a bunch of grey

00:37:38.690 --> 00:37:38.700
representing this with a bunch of grey
 

00:37:38.700 --> 00:37:41.390
representing this with a bunch of grey
grey lines so if you run the algorithm

00:37:41.390 --> 00:37:41.400
grey lines so if you run the algorithm
 

00:37:41.400 --> 00:37:44.300
grey lines so if you run the algorithm
again we go fetch our first array but

00:37:44.300 --> 00:37:44.310
again we go fetch our first array but
 

00:37:44.310 --> 00:37:46.190
again we go fetch our first array but
instead of fetching the other data that

00:37:46.190 --> 00:37:46.200
instead of fetching the other data that
 

00:37:46.200 --> 00:37:48.260
instead of fetching the other data that
we want we search that great data stuff

00:37:48.260 --> 00:37:48.270
we want we search that great data stuff
 

00:37:48.270 --> 00:37:49.610
we want we search that great data stuff
that we don't even know what it is but

00:37:49.610 --> 00:37:49.620
that we don't even know what it is but
 

00:37:49.620 --> 00:37:51.410
that we don't even know what it is but
it's going to be put in the l1 so then

00:37:51.410 --> 00:37:51.420
it's going to be put in the l1 so then
 

00:37:51.420 --> 00:37:53.120
it's going to be put in the l1 so then
when we want the next array it's not in

00:37:53.120 --> 00:37:53.130
when we want the next array it's not in
 

00:37:53.130 --> 00:37:54.770
when we want the next array it's not in
the l1 and we have to go back to memory

00:37:54.770 --> 00:37:54.780
the l1 and we have to go back to memory
 

00:37:54.780 --> 00:37:57.830
the l1 and we have to go back to memory
and get it and so on and so on but again

00:37:57.830 --> 00:37:57.840
and get it and so on and so on but again
 

00:37:57.840 --> 00:37:59.450
and get it and so on and so on but again
we're running the same algorithm it's

00:37:59.450 --> 00:37:59.460
we're running the same algorithm it's
 

00:37:59.460 --> 00:38:01.070
we're running the same algorithm it's
just now we have to do more the CPUs to

00:38:01.070 --> 00:38:01.080
just now we have to do more the CPUs to
 

00:38:01.080 --> 00:38:03.560
just now we have to do more the CPUs to
do more work and we can recreate the

00:38:03.560 --> 00:38:03.570
do more work and we can recreate the
 

00:38:03.570 --> 00:38:06.890
do more work and we can recreate the
same the same thing by spacing out our

00:38:06.890 --> 00:38:06.900
same the same thing by spacing out our
 

00:38:06.900 --> 00:38:08.960
same the same thing by spacing out our
eyes even more so that we won't find the

00:38:08.960 --> 00:38:08.970
eyes even more so that we won't find the
 

00:38:08.970 --> 00:38:11.180
eyes even more so that we won't find the
arise in the l2 or the l3 and we can

00:38:11.180 --> 00:38:11.190
arise in the l2 or the l3 and we can
 

00:38:11.190 --> 00:38:12.830
arise in the l2 or the l3 and we can
force the CPU to do even more and not

00:38:12.830 --> 00:38:12.840
force the CPU to do even more and not
 

00:38:12.840 --> 00:38:15.350
force the CPU to do even more and not
work so if we run those different

00:38:15.350 --> 00:38:15.360
work so if we run those different
 

00:38:15.360 --> 00:38:17.750
work so if we run those different
variants of the algorithm where again

00:38:17.750 --> 00:38:17.760
variants of the algorithm where again
 

00:38:17.760 --> 00:38:19.100
variants of the algorithm where again
all we did was change the way we

00:38:19.100 --> 00:38:19.110
all we did was change the way we
 

00:38:19.110 --> 00:38:20.390
all we did was change the way we
allocate the objects we're running the

00:38:20.390 --> 00:38:20.400
allocate the objects we're running the
 

00:38:20.400 --> 00:38:22.370
allocate the objects we're running the
exact same computations when everything

00:38:22.370 --> 00:38:22.380
exact same computations when everything
 

00:38:22.380 --> 00:38:26.450
exact same computations when everything
is neatly stored together in RAM I know

00:38:26.450 --> 00:38:26.460
is neatly stored together in RAM I know
 

00:38:26.460 --> 00:38:28.610
is neatly stored together in RAM I know
the algorithm takes about I think 150

00:38:28.610 --> 00:38:28.620
the algorithm takes about I think 150
 

00:38:28.620 --> 00:38:31.670
the algorithm takes about I think 150
milliseconds on a pixel 3 so that's the

00:38:31.670 --> 00:38:31.680
milliseconds on a pixel 3 so that's the
 

00:38:31.680 --> 00:38:34.040
milliseconds on a pixel 3 so that's the
no thrash and when I space at the

00:38:34.040 --> 00:38:34.050
no thrash and when I space at the
 

00:38:34.050 --> 00:38:35.360
no thrash and when I space at the
allocation so that we can't find the

00:38:35.360 --> 00:38:35.370
allocation so that we can't find the
 

00:38:35.370 --> 00:38:37.310
allocation so that we can't find the
data we want in the l1 certainly we're

00:38:37.310 --> 00:38:37.320
data we want in the l1 certainly we're
 

00:38:37.320 --> 00:38:39.020
data we want in the l1 certainly we're
almost twice as slow we're running the

00:38:39.020 --> 00:38:39.030
almost twice as slow we're running the
 

00:38:39.030 --> 00:38:41.150
almost twice as slow we're running the
same exact computations but we'll do it

00:38:41.150 --> 00:38:41.160
same exact computations but we'll do it
 

00:38:41.160 --> 00:38:43.460
same exact computations but we'll do it
CPUs is busy going you know to fetch

00:38:43.460 --> 00:38:43.470
CPUs is busy going you know to fetch
 

00:38:43.470 --> 00:38:45.650
CPUs is busy going you know to fetch
data in RAM and if I space out the

00:38:45.650 --> 00:38:45.660
data in RAM and if I space out the
 

00:38:45.660 --> 00:38:47.360
data in RAM and if I space out the
allocations even more so that we can't

00:38:47.360 --> 00:38:47.370
allocations even more so that we can't
 

00:38:47.370 --> 00:38:49.550
allocations even more so that we can't
find the data in the l2 now we are over

00:38:49.550 --> 00:38:49.560
find the data in the l2 now we are over
 

00:38:49.560 --> 00:38:50.840
find the data in the l2 now we are over
five times slower

00:38:50.840 --> 00:38:50.850
five times slower
 

00:38:50.850 --> 00:38:53.450
five times slower
again same exactly the algorithm so if

00:38:53.450 --> 00:38:53.460
again same exactly the algorithm so if
 

00:38:53.460 --> 00:38:55.370
again same exactly the algorithm so if
you're right benchmarks and that's very

00:38:55.370 --> 00:38:55.380
you're right benchmarks and that's very
 

00:38:55.380 --> 00:38:56.480
you're right benchmarks and that's very
good you should you should probably do

00:38:56.480 --> 00:38:56.490
good you should you should probably do
 

00:38:56.490 --> 00:38:59.990
good you should you should probably do
that be very careful be aware of the

00:38:59.990 --> 00:39:00.000
that be very careful be aware of the
 

00:39:00.000 --> 00:39:01.520
that be very careful be aware of the
fact that the numbers you're gonna get

00:39:01.520 --> 00:39:01.530
fact that the numbers you're gonna get
 

00:39:01.530 --> 00:39:03.080
fact that the numbers you're gonna get
in your benchmark may be very different

00:39:03.080 --> 00:39:03.090
in your benchmark may be very different
 

00:39:03.090 --> 00:39:04.970
in your benchmark may be very different
than the numbers are gonna get in the

00:39:04.970 --> 00:39:04.980
than the numbers are gonna get in the
 

00:39:04.980 --> 00:39:06.980
than the numbers are gonna get in the
actual app running you know on your

00:39:06.980 --> 00:39:06.990
actual app running you know on your
 

00:39:06.990 --> 00:39:10.730
actual app running you know on your
users devices yeah you actually

00:39:10.730 --> 00:39:10.740
users devices yeah you actually
 

00:39:10.740 --> 00:39:13.040
users devices yeah you actually
benchmarking the the CPU access better

00:39:13.040 --> 00:39:13.050
benchmarking the the CPU access better
 

00:39:13.050 --> 00:39:14.870
benchmarking the the CPU access better
there's a few access patterns so and

00:39:14.870 --> 00:39:14.880
there's a few access patterns so and
 

00:39:14.880 --> 00:39:16.490
there's a few access patterns so and
with that we're done we have six seconds

00:39:16.490 --> 00:39:16.500
with that we're done we have six seconds
 

00:39:16.500 --> 00:39:18.830
with that we're done we have six seconds
left a very important thing if you are

00:39:18.830 --> 00:39:18.840
left a very important thing if you are
 

00:39:18.840 --> 00:39:20.210
left a very important thing if you are
interested in what we talked about today

00:39:20.210 --> 00:39:20.220
interested in what we talked about today
 

00:39:20.220 --> 00:39:21.890
interested in what we talked about today
there's a deeper version of this as well

00:39:21.890 --> 00:39:21.900
there's a deeper version of this as well
 

00:39:21.900 --> 00:39:23.360
there's a deeper version of this as well
as a lot of the runtime improvements

00:39:23.360 --> 00:39:23.370
as a lot of the runtime improvements
 

00:39:23.370 --> 00:39:25.310
as a lot of the runtime improvements
they're an art overtime by ladies and

00:39:25.310 --> 00:39:25.320
they're an art overtime by ladies and
 

00:39:25.320 --> 00:39:26.990
they're an art overtime by ladies and
engineers on the art team so please

00:39:26.990 --> 00:39:27.000
engineers on the art team so please
 

00:39:27.000 --> 00:39:28.400
engineers on the art team so please
check that out it's at the same time as

00:39:28.400 --> 00:39:28.410
check that out it's at the same time as
 

00:39:28.410 --> 00:39:29.750
check that out it's at the same time as
the fireside chat which i think is at

00:39:29.750 --> 00:39:29.760
the fireside chat which i think is at
 

00:39:29.760 --> 00:39:32.900
the fireside chat which i think is at
11:10 so please go see that talk as well

00:39:32.900 --> 00:39:32.910
11:10 so please go see that talk as well
 

00:39:32.910 --> 00:39:35.550
11:10 so please go see that talk as well
and that's it thank you

00:39:35.550 --> 00:39:35.560
and that's it thank you
 

00:39:35.560 --> 00:39:36.900
and that's it thank you
[Applause]

00:39:36.900 --> 00:39:36.910
[Applause]
 

00:39:36.910 --> 00:39:53.080
[Applause]
[Music]

