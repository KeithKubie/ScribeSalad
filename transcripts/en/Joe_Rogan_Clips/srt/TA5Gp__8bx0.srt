1
00:00:00,000 --> 00:00:00,980
People might say, I, I'm,

2
00:00:00,981 --> 00:00:04,980
I'm a little alarmist when I mentioned a
potential civil war, but let me clarify,

3
00:00:05,100 --> 00:00:07,410
like I don't, I'm not saying
cause I brought this up before,

4
00:00:07,411 --> 00:00:10,830
I'm not saying it's going to be like, you
know, 18 hundreds, two big battlefields.

5
00:00:11,250 --> 00:00:12,090
But at the same time,

6
00:00:12,091 --> 00:00:14,970
what people don't seem to realize when
it comes to history is that when you read

7
00:00:14,971 --> 00:00:15,950
about World War II,

8
00:00:16,080 --> 00:00:19,380
we've condensed all the highlights into
a very short paragraph or a series of

9
00:00:19,381 --> 00:00:21,720
paragraphs. And you don't realize
the war was several years.

10
00:00:22,020 --> 00:00:24,120
There were periods where nothing happened,
right?

11
00:00:24,420 --> 00:00:26,850
I was in Egypt during
the second revolution.

12
00:00:27,480 --> 00:00:30,660
You could look down and you could see
ty for your square people screaming,

13
00:00:30,661 --> 00:00:34,410
laser pointers, helicopters, Apaches. And
they announced in the news, we've just,

14
00:00:34,440 --> 00:00:36,270
we've deposed the
president two blocks away.

15
00:00:36,360 --> 00:00:37,710
A dude's eating a
cheeseburger at Mcdonald's,

16
00:00:37,711 --> 00:00:39,990
watching a football match
as if nothing's happening.

17
00:00:40,560 --> 00:00:43,050
So when you look at these street battles,
the political violence,

18
00:00:43,051 --> 00:00:47,080
when you look at the, the, the biased
Banning's, you look at the dude, um,

19
00:00:47,310 --> 00:00:50,520
there was a guy who fired a couple of
rounds at a police officer in Eugene,

20
00:00:50,521 --> 00:00:50,901
Oregon.

21
00:00:50,901 --> 00:00:54,390
Then some bombs got planted at the police
department or somebody planted bombs

22
00:00:54,391 --> 00:00:55,470
at a statue in Houston.

23
00:00:55,800 --> 00:00:59,490
It starts to feel like there's some kind
of political violence that is bubbling

24
00:00:59,491 --> 00:01:03,600
up that can't be mended at this point
when a lot of this comes from the

25
00:01:03,601 --> 00:01:06,000
suppression that we're talking about
where people don't feel like they have a

26
00:01:06,001 --> 00:01:10,230
voice or that voice is being suppressed
by an opposing ideologies, you know?

27
00:01:10,620 --> 00:01:13,200
Yes. But it is really
complicated and it's, it's,

28
00:01:13,380 --> 00:01:15,810
I can't claim to know
how everything happens,

29
00:01:15,811 --> 00:01:20,460
but what I will say is I believe social
media is responsible for the political

30
00:01:20,461 --> 00:01:24,970
violence. I believe it's, uh, it's
not just about suppression. It's you,

31
00:01:25,170 --> 00:01:27,900
you look at, um, the systems
that were built Facebook, right?

32
00:01:28,260 --> 00:01:31,050
What content can make it to the
front page of your Facebook posts,

33
00:01:31,110 --> 00:01:33,750
of your Facebook profile. When you're
looking at your newsfeed while Twitter,

34
00:01:33,900 --> 00:01:36,570
Facebook has to build an algorithm
to determine what matters.

35
00:01:36,571 --> 00:01:40,350
Most companies then figure out how to
manipulate the algorithm to get that

36
00:01:40,351 --> 00:01:42,030
content in front of you.
Because you know,

37
00:01:42,031 --> 00:01:45,810
at most you can see what three posts on
Facebook. So what happens is early on,

38
00:01:45,990 --> 00:01:50,970
companies quickly found out that anger
drives the most shares of any emotion.

39
00:01:51,060 --> 00:01:53,850
All of a sudden we see a wave of
police brutality videos. Yeah.

40
00:01:54,060 --> 00:01:57,780
There was one website that posted almost
exclusively police brutality content

41
00:01:57,781 --> 00:02:00,120
and it was like Alexa,
400 in the world,

42
00:02:00,270 --> 00:02:03,020
some ridiculously high number
of blew my mind. I knew p uh,

43
00:02:03,090 --> 00:02:06,390
someone claims to that they're making
six figures writing police brutality

44
00:02:06,391 --> 00:02:09,840
articles because it was
pure rage bait, right? Yeah.

45
00:02:09,870 --> 00:02:11,490
Content that just shares really easily.

46
00:02:11,850 --> 00:02:15,870
But that content constantly being put in
front of somebody breeds and ideology.

47
00:02:16,230 --> 00:02:19,110
You then tell someone,
did you know that you know,

48
00:02:19,111 --> 00:02:22,680
white supremacy is on the rise and there
are 11 million white supremacists in

49
00:02:22,681 --> 00:02:26,130
the U S and they go, I can believe it.
But that's nonsense. It's just not,

50
00:02:26,150 --> 00:02:27,660
it's just not the case.
You know,

51
00:02:27,661 --> 00:02:31,170
the Anti Defamation League in the SPLC
say that at rough estimates or maybe like

52
00:02:31,171 --> 00:02:34,740
10 or 12,000,
but people really believe that there is,

53
00:02:34,741 --> 00:02:39,060
like at the president is secretly a Nazi
and that he's being propped up by the

54
00:02:39,061 --> 00:02:39,811
secret cabal,

55
00:02:39,811 --> 00:02:43,230
or there's an alternative influence
network on Youtube where you and me or

56
00:02:43,231 --> 00:02:46,730
somehow trying to convince people to,
you know, this is ridiculous. Well,

57
00:02:46,731 --> 00:02:50,220
that's the, the, the AME thing.
Yeah. What was it called?

58
00:02:50,221 --> 00:02:54,660
A data and society. And that's,
that's that nonsense. Yeah,

59
00:02:54,700 --> 00:02:56,550
we did.
We get connected to,

60
00:02:56,610 --> 00:02:59,990
or we outright adjacent or we
bootleggers that one part of the,

61
00:03:00,080 --> 00:03:03,060
it's a network that feeds into
extremist ideologies and other,

62
00:03:03,250 --> 00:03:07,870
they connected me with people. It's so
schizophrenia, the way it's drawn out,

63
00:03:07,871 --> 00:03:10,750
that little map where one person's
connected to another person.

64
00:03:10,830 --> 00:03:14,650
What I said to her, I said, Barbara
Walters interviewed Fidel Castro.

65
00:03:14,651 --> 00:03:17,080
Did that make our communist, you know,
that's what I tweeted at her. I'm like,

66
00:03:17,081 --> 00:03:18,970
you're crazy.
This is a crazy way to look at things.

67
00:03:18,971 --> 00:03:22,930
But what happened with that story?
Media reported uncritically.

68
00:03:23,260 --> 00:03:26,110
I reached out to a bunch of journalists.
I know, I know a ton of journalists.

69
00:03:26,111 --> 00:03:28,910
I'm a, I'm a member of the online
news association. You're like, I've,

70
00:03:28,940 --> 00:03:31,660
I've been a speaker at their events and
I'm reaching out to these journalists

71
00:03:31,661 --> 00:03:34,990
like, hey, why did you guys write
that? That's just completely fake.

72
00:03:35,350 --> 00:03:38,670
It's got my name like my name in the
middle. Right? You know me, right?

73
00:03:38,710 --> 00:03:41,950
You can call me to quote you.
They don't do it right.

74
00:03:42,100 --> 00:03:45,160
They just uncritically report it.
And there's a couple of reasons for it.

75
00:03:45,760 --> 00:03:48,910
The media, uh, Facebook recently
changed their algorithm. I don't know,

76
00:03:49,030 --> 00:03:51,980
this was a while ago. They may
have changed again. But, uh,

77
00:03:52,090 --> 00:03:54,880
it was a huge hit to the incomes
of a lot of these companies.

78
00:03:55,210 --> 00:03:58,030
When all of a sudden news articles
stopped appearing as much because Facebook

79
00:03:58,031 --> 00:04:01,420
wanted friends and family to be more
connected and less so news organizations.

80
00:04:02,020 --> 00:04:05,560
So these news organizations who write
this viral clickbait and rage content

81
00:04:05,650 --> 00:04:08,020
weren't getting as much traffic. So what
are they? You know, they have to go crazy.

82
00:04:08,290 --> 00:04:09,770
They have to, you know, and so it's,

83
00:04:09,771 --> 00:04:13,690
it's a downward spiral of where these
journalists all follow each other.

84
00:04:14,170 --> 00:04:16,990
They start producing. I don't,
I don't think it's a conspiracy.

85
00:04:16,990 --> 00:04:17,711
They produced this stuff.

86
00:04:17,711 --> 00:04:21,700
I think they're hired specifically because
the content they produce is viral and

87
00:04:21,701 --> 00:04:24,850
it's viral for a reason. Right.
And so the more they produce it,

88
00:04:24,851 --> 00:04:29,130
the more they eat their own, you know,
excrement essentially. And then boom,

89
00:04:29,230 --> 00:04:32,320
it's a game of telephone where they're
sitting in a circle constantly telling

90
00:04:32,321 --> 00:04:34,570
each other the craziest things.
And it gets crazier and crazier.

91
00:04:35,050 --> 00:04:38,200
But another aspect of it is when they
read an article saying, you know,

92
00:04:38,201 --> 00:04:41,860
Trump is racist, it goes viral the next
day. They can't read the same article.

93
00:04:41,890 --> 00:04:45,100
So they, right. Trump is the most
racist the next day they have to,

94
00:04:45,130 --> 00:04:46,780
they have to keep one
upping it and it gets,

95
00:04:46,781 --> 00:04:50,980
we talked about this with Forbes articles,
the term nasty surprise,

96
00:04:51,280 --> 00:04:52,510
they use it with tech.

97
00:04:52,780 --> 00:04:56,740
Like they'll say the new galaxy
s 10 has a nasty surprise.

98
00:04:56,741 --> 00:05:00,760
The new iPhone 10 has a nasty surprise
and it keeps saying it's hilarious.

99
00:05:00,760 --> 00:05:04,960
It's almost like there's a form letter
and they just take whatever Xbox stick it

100
00:05:04,961 --> 00:05:06,490
in their nasty surprise and it's,

101
00:05:06,940 --> 00:05:11,800
it's 100% and click bait and it's Forbes
and you telling me that Forbes that was

102
00:05:11,830 --> 00:05:16,280
essentially is, it's like user
contributions. Yeah, yeah, yeah. And I,

103
00:05:16,680 --> 00:05:19,510
I could probably submit an article,
they have like a network of people,

104
00:05:19,660 --> 00:05:21,280
I don't know how you get approved,

105
00:05:21,281 --> 00:05:24,040
but there's a lot of articles that just
get written about like the new video

106
00:05:24,041 --> 00:05:26,280
game today. So it's like
a clickbait title. Yeah.

107
00:05:26,320 --> 00:05:28,570
We'll just get some ads
has a nasty surprise,

108
00:05:28,571 --> 00:05:32,680
but it's almost like they have like
a pattern that they've just accepted.

109
00:05:32,880 --> 00:05:35,140
This is going to work,
but it's not a conspiracy.

110
00:05:35,620 --> 00:05:39,040
It's just likeminded people who
are only ever around each other,

111
00:05:39,600 --> 00:05:42,820
sharing the same things among each other,
believing all at the same things.

112
00:05:43,210 --> 00:05:47,650
And so you'll notice that certain words
emerge specifically among certain groups.

113
00:05:47,710 --> 00:05:51,590
You know, like the left, we'll use certain
words and then if like learn to code.

114
00:05:51,591 --> 00:05:53,470
It doesn't appear that
much in left wing rhetoric,

115
00:05:53,471 --> 00:05:57,680
but the conservatives and the anti
identitarian types understand what it is.

116
00:05:58,250 --> 00:06:02,140
And so justification for banning someone
for saying learn to code regardless of

117
00:06:02,141 --> 00:06:05,180
the context seems insane.
Yeah, that seems insane.

118
00:06:05,200 --> 00:06:08,180
It seems like you got one in
particular is almost independent.

119
00:06:08,190 --> 00:06:10,680
I mean not almost that's indefensible.
Absolutely.

120
00:06:11,160 --> 00:06:15,150
Like there have been people who, uh,
let, let me, let me, let me be fair.

121
00:06:15,360 --> 00:06:17,940
There are people on the left who
have been banned. Absolutely Hobson.

122
00:06:18,210 --> 00:06:21,330
There was a lot of Venezuelan accounts
that were banned and a lot of people were

123
00:06:21,331 --> 00:06:22,950
very critical.
I saw Abby Martin was,

124
00:06:22,951 --> 00:06:26,010
was criticizing this because they accused
them of being government actors cause

125
00:06:26,011 --> 00:06:29,490
they were pro Venezuelan government.
But the most, the one thing,

126
00:06:30,090 --> 00:06:32,670
there's some occupy Wall Street
activists who absolutely detested me.

127
00:06:33,060 --> 00:06:35,550
They lie about me,
I do not like them for doing this.

128
00:06:35,880 --> 00:06:38,250
They were banned abruptly
for literally no reason.

129
00:06:38,790 --> 00:06:41,340
And this is what's more worrisome
to me is that no one defended them.

130
00:06:41,850 --> 00:06:44,130
No one defended them because
conservative certainly won't,

131
00:06:44,490 --> 00:06:48,990
but neither will the mainstream,
you know, ideological left.

132
00:06:49,110 --> 00:06:52,290
These are activists for class issues,

133
00:06:52,470 --> 00:06:56,330
for international issues there on the
left squarely and they were accused I

134
00:06:56,331 --> 00:06:58,290
guess of being bots or something just,

135
00:06:58,291 --> 00:07:01,710
it was just an abrupt purge of like
50 accounts and some of them were like

136
00:07:01,740 --> 00:07:06,630
independent citizen journalists just wiped
up and with no recourse, no recourse,

137
00:07:06,660 --> 00:07:07,380
none whatsoever.

138
00:07:07,380 --> 00:07:12,380
So I mean at some point you have to
realize how important Twitter is when the

139
00:07:12,421 --> 00:07:13,200
president does on it.

140
00:07:13,200 --> 00:07:17,610
Could you imagine if there was a physical
space where everyone was talking and

141
00:07:17,611 --> 00:07:20,550
the president shows up and everyone
keeps yelling at them and they're all

142
00:07:20,551 --> 00:07:23,700
talking because you had that lawsuit
where they said it was a public forum.

143
00:07:23,790 --> 00:07:28,710
Imagine that happens and then a private
private individual bars you from hearing

144
00:07:28,711 --> 00:07:33,410
what the president has to say. Right.
It's a complicated issue. I very,

145
00:07:33,510 --> 00:07:34,050
you know,

146
00:07:34,050 --> 00:07:36,420
you get a lot of people on the left
saying private businesses can do whatever

147
00:07:36,421 --> 00:07:36,810
they want.

148
00:07:36,810 --> 00:07:40,470
That blew my mind because the left
was usually about not letting massive

149
00:07:40,471 --> 00:07:43,390
multinational billion dollar corporations
get away with suppressing speech.

150
00:07:43,391 --> 00:07:46,290
But well that was another thing that
people get pissed at me about Jack Dorsey

151
00:07:46,291 --> 00:07:50,440
and rightly so that he said that
it's a human right that deal,

152
00:07:50,441 --> 00:07:53,310
the indicate online as a human,
but the fact that he said it,

153
00:07:53,340 --> 00:07:55,800
but yet all these people are banned.

154
00:07:55,980 --> 00:08:00,890
So how [inaudible] like to take
away someone's human, right? It,

155
00:08:01,080 --> 00:08:05,790
there should be an egregious example.
I mean it should be something like,

156
00:08:05,791 --> 00:08:10,170
I mean doxing, someone like calling for
violence, like trying and buddy buddy.

157
00:08:10,200 --> 00:08:13,890
But even then, but the, clearly that's not
the case if Kathy Griffin still online,

158
00:08:13,891 --> 00:08:18,750
but hold on, you can kill a human
being and get 25 years. Right.

159
00:08:18,751 --> 00:08:22,500
Good point. So you can literally
strip someone of their, of their yes,

160
00:08:22,560 --> 00:08:25,620
everything and still
be perched permanently.

161
00:08:25,710 --> 00:08:29,790
This was one of the things that Jack
and I discussed post podcast. I said,

162
00:08:29,820 --> 00:08:32,610
you know, when we were going back and
forth about doing this again, you know,

163
00:08:32,611 --> 00:08:33,610
and told him,
uh,

164
00:08:33,690 --> 00:08:38,040
I would really like to see if there's
some sort of a path to redemption.

165
00:08:38,850 --> 00:08:42,260
Like, uh, you know, for example,
for Milo, I mean, who's to say,

166
00:08:42,280 --> 00:08:46,560
like we talked about yesterday about
Christian ecoline who was a white

167
00:08:46,561 --> 00:08:47,430
supremacist,

168
00:08:47,730 --> 00:08:52,730
who realized the error of his ways and
then became this activist against racism

169
00:08:53,700 --> 00:08:58,700
and now he gives these Ted
and he's accepted by everyone
as being this guy who's

170
00:08:59,880 --> 00:09:04,490
achieved redemption and really understands
the error of his ways with Milo's

171
00:09:04,530 --> 00:09:07,290
banned for life. Milo is only
like 34 years old. Right?

172
00:09:07,291 --> 00:09:09,840
How old is Milo around there?
I don't know.

173
00:09:10,030 --> 00:09:12,660
I hope I didn't make them older
than he is. It probably be mad,

174
00:09:12,990 --> 00:09:16,560
but whatever it is, like who's
to say that Milo, you know,

175
00:09:16,620 --> 00:09:20,610
in three years from now won't have
a change of heart or you know,

176
00:09:20,760 --> 00:09:24,120
have a fucking acid trip or something
that makes sense. I'm a different person,

177
00:09:24,150 --> 00:09:26,280
but if you're banned for life,
we are.

178
00:09:26,281 --> 00:09:31,170
We throwing people away like you ever
see that tweet from? I'm going to say,

179
00:09:31,171 --> 00:09:34,830
I think it was Tyler, the creator where
he said, how is cyber bullying real? Just,

180
00:09:34,831 --> 00:09:39,030
you know, like close your
eyes side. Go outside. Close
your eyes. That's, you know,

181
00:09:39,031 --> 00:09:42,720
I'm sorry man. You want a band
hate speech. I can understand.

182
00:09:42,900 --> 00:09:46,340
I'm no fan of hate speech. I think it's
wrong. I think you shouldn't, you know,

183
00:09:46,360 --> 00:09:49,140
target people for specific
characteristics. We should
respect one another.

184
00:09:49,470 --> 00:09:50,041
At the same time,

185
00:09:50,041 --> 00:09:53,460
I'm also a human adult who
understands sometimes people are mean.

186
00:09:53,910 --> 00:09:55,250
You ever walked out, you
ever go to a, you know,

187
00:09:55,260 --> 00:09:57,870
a subway in Los Angeles and some guy
starts calling you all the names in the

188
00:09:57,871 --> 00:10:01,260
book. What are you gonna do about
it? Nothing. That's just life.

189
00:10:01,261 --> 00:10:03,930
People are mean sometimes have they
punch you, they crossed the line.

190
00:10:04,440 --> 00:10:07,290
But on Twitter, you know, Milo wants say
mean things. Block mute. You know what?

191
00:10:07,291 --> 00:10:10,950
I'd do that precipice. Yeah. Mute Utopian
of black people. I blocked some people.

192
00:10:11,140 --> 00:10:11,350
Yeah.

