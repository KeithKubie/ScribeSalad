WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.629
welcome to this course on the practical

00:00:02.629 --> 00:00:02.639
welcome to this course on the practical
 

00:00:02.639 --> 00:00:05.059
welcome to this course on the practical
aspects of deep learning as now you've

00:00:05.059 --> 00:00:05.069
aspects of deep learning as now you've
 

00:00:05.069 --> 00:00:06.710
aspects of deep learning as now you've
learned how to implement a neural

00:00:06.710 --> 00:00:06.720
learned how to implement a neural
 

00:00:06.720 --> 00:00:08.629
learned how to implement a neural
network in this week you learn the

00:00:08.629 --> 00:00:08.639
network in this week you learn the
 

00:00:08.639 --> 00:00:10.640
network in this week you learn the
practical aspects of how to make your

00:00:10.640 --> 00:00:10.650
practical aspects of how to make your
 

00:00:10.650 --> 00:00:12.950
practical aspects of how to make your
neural network work well ranging from

00:00:12.950 --> 00:00:12.960
neural network work well ranging from
 

00:00:12.960 --> 00:00:15.470
neural network work well ranging from
things like hyper parameter tuning to

00:00:15.470 --> 00:00:15.480
things like hyper parameter tuning to
 

00:00:15.480 --> 00:00:17.870
things like hyper parameter tuning to
how to set of your data - how to make

00:00:17.870 --> 00:00:17.880
how to set of your data - how to make
 

00:00:17.880 --> 00:00:19.730
how to set of your data - how to make
sure your optimization algorithm runs

00:00:19.730 --> 00:00:19.740
sure your optimization algorithm runs
 

00:00:19.740 --> 00:00:21.439
sure your optimization algorithm runs
quickly so you get your learning

00:00:21.439 --> 00:00:21.449
quickly so you get your learning
 

00:00:21.449 --> 00:00:23.509
quickly so you get your learning
algorithm to learn in a reasonable time

00:00:23.509 --> 00:00:23.519
algorithm to learn in a reasonable time
 

00:00:23.519 --> 00:00:25.550
algorithm to learn in a reasonable time
in this first we will first talk about

00:00:25.550 --> 00:00:25.560
in this first we will first talk about
 

00:00:25.560 --> 00:00:26.870
in this first we will first talk about
how the cellular machine learning

00:00:26.870 --> 00:00:26.880
how the cellular machine learning
 

00:00:26.880 --> 00:00:28.099
how the cellular machine learning
problem they will talk about

00:00:28.099 --> 00:00:28.109
problem they will talk about
 

00:00:28.109 --> 00:00:30.080
problem they will talk about
regularization and we'll talk about some

00:00:30.080 --> 00:00:30.090
regularization and we'll talk about some
 

00:00:30.090 --> 00:00:31.849
regularization and we'll talk about some
tricks for making sure your neural

00:00:31.849 --> 00:00:31.859
tricks for making sure your neural
 

00:00:31.859 --> 00:00:34.430
tricks for making sure your neural
network implementation is correct with

00:00:34.430 --> 00:00:34.440
network implementation is correct with
 

00:00:34.440 --> 00:00:36.530
network implementation is correct with
that let's get started making good

00:00:36.530 --> 00:00:36.540
that let's get started making good
 

00:00:36.540 --> 00:00:38.510
that let's get started making good
choices in how you set up your training

00:00:38.510 --> 00:00:38.520
choices in how you set up your training
 

00:00:38.520 --> 00:00:40.790
choices in how you set up your training
development and test sets can make a

00:00:40.790 --> 00:00:40.800
development and test sets can make a
 

00:00:40.800 --> 00:00:42.619
development and test sets can make a
huge difference in helping you quickly

00:00:42.619 --> 00:00:42.629
huge difference in helping you quickly
 

00:00:42.629 --> 00:00:44.959
huge difference in helping you quickly
find a good high performance your

00:00:44.959 --> 00:00:44.969
find a good high performance your
 

00:00:44.969 --> 00:00:47.150
find a good high performance your
network when training on your network

00:00:47.150 --> 00:00:47.160
network when training on your network
 

00:00:47.160 --> 00:00:49.069
network when training on your network
you have to make a lot of decisions such

00:00:49.069 --> 00:00:49.079
you have to make a lot of decisions such
 

00:00:49.079 --> 00:00:51.319
you have to make a lot of decisions such
as how many layers with your new network

00:00:51.319 --> 00:00:51.329
as how many layers with your new network
 

00:00:51.329 --> 00:00:53.779
as how many layers with your new network
have and how many hidden units do you

00:00:53.779 --> 00:00:53.789
have and how many hidden units do you
 

00:00:53.789 --> 00:00:56.209
have and how many hidden units do you
want each layer to have and what's the

00:00:56.209 --> 00:00:56.219
want each layer to have and what's the
 

00:00:56.219 --> 00:00:57.889
want each layer to have and what's the
learning rate and what are the

00:00:57.889 --> 00:00:57.899
learning rate and what are the
 

00:00:57.899 --> 00:00:59.630
learning rate and what are the
activation functions you want to use for

00:00:59.630 --> 00:00:59.640
activation functions you want to use for
 

00:00:59.640 --> 00:01:01.279
activation functions you want to use for
the different layers when you're

00:01:01.279 --> 00:01:01.289
the different layers when you're
 

00:01:01.289 --> 00:01:03.650
the different layers when you're
starting on a new application is almost

00:01:03.650 --> 00:01:03.660
starting on a new application is almost
 

00:01:03.660 --> 00:01:06.560
starting on a new application is almost
impossible to correctly guess the right

00:01:06.560 --> 00:01:06.570
impossible to correctly guess the right
 

00:01:06.570 --> 00:01:08.929
impossible to correctly guess the right
values for all of these and for other

00:01:08.929 --> 00:01:08.939
values for all of these and for other
 

00:01:08.939 --> 00:01:11.149
values for all of these and for other
high performance a choices on your first

00:01:11.149 --> 00:01:11.159
high performance a choices on your first
 

00:01:11.159 --> 00:01:13.700
high performance a choices on your first
attempt so in practice applying machine

00:01:13.700 --> 00:01:13.710
attempt so in practice applying machine
 

00:01:13.710 --> 00:01:15.710
attempt so in practice applying machine
learning is a highly iterative process

00:01:15.710 --> 00:01:15.720
learning is a highly iterative process
 

00:01:15.720 --> 00:01:18.080
learning is a highly iterative process
in which you often start with an idea

00:01:18.080 --> 00:01:18.090
in which you often start with an idea
 

00:01:18.090 --> 00:01:19.789
in which you often start with an idea
such as you want to build a new network

00:01:19.789 --> 00:01:19.799
such as you want to build a new network
 

00:01:19.799 --> 00:01:22.160
such as you want to build a new network
of a certain number of layers a certain

00:01:22.160 --> 00:01:22.170
of a certain number of layers a certain
 

00:01:22.170 --> 00:01:24.140
of a certain number of layers a certain
number of units may be on certain data

00:01:24.140 --> 00:01:24.150
number of units may be on certain data
 

00:01:24.150 --> 00:01:26.359
number of units may be on certain data
set and so on and then you just have the

00:01:26.359 --> 00:01:26.369
set and so on and then you just have the
 

00:01:26.369 --> 00:01:28.609
set and so on and then you just have the
code up in trying it by running your

00:01:28.609 --> 00:01:28.619
code up in trying it by running your
 

00:01:28.619 --> 00:01:32.300
code up in trying it by running your
code you run an experiment on the get

00:01:32.300 --> 00:01:32.310
code you run an experiment on the get
 

00:01:32.310 --> 00:01:33.980
code you run an experiment on the get
back a result that tells you how well

00:01:33.980 --> 00:01:33.990
back a result that tells you how well
 

00:01:33.990 --> 00:01:35.899
back a result that tells you how well
this particular network or this fluid

00:01:35.899 --> 00:01:35.909
this particular network or this fluid
 

00:01:35.909 --> 00:01:38.090
this particular network or this fluid
configuration works and based on the

00:01:38.090 --> 00:01:38.100
configuration works and based on the
 

00:01:38.100 --> 00:01:40.399
configuration works and based on the
outcome of you might then refine your

00:01:40.399 --> 00:01:40.409
outcome of you might then refine your
 

00:01:40.409 --> 00:01:44.420
outcome of you might then refine your
ideas and change your choices and maybe

00:01:44.420 --> 00:01:44.430
ideas and change your choices and maybe
 

00:01:44.430 --> 00:01:47.300
ideas and change your choices and maybe
keep iterating in order to try to find a

00:01:47.300 --> 00:01:47.310
keep iterating in order to try to find a
 

00:01:47.310 --> 00:01:50.899
keep iterating in order to try to find a
better and a better neural network today

00:01:50.899 --> 00:01:50.909
better and a better neural network today
 

00:01:50.909 --> 00:01:53.240
better and a better neural network today
deep learning has found great success in

00:01:53.240 --> 00:01:53.250
deep learning has found great success in
 

00:01:53.250 --> 00:01:55.340
deep learning has found great success in
a lot of areas ranging from natural

00:01:55.340 --> 00:01:55.350
a lot of areas ranging from natural
 

00:01:55.350 --> 00:01:57.340
a lot of areas ranging from natural
language processing to computer vision

00:01:57.340 --> 00:01:57.350
language processing to computer vision
 

00:01:57.350 --> 00:02:00.590
language processing to computer vision
to speech recognition to a lot of

00:02:00.590 --> 00:02:00.600
to speech recognition to a lot of
 

00:02:00.600 --> 00:02:04.179
to speech recognition to a lot of
applications on also structured data and

00:02:04.179 --> 00:02:04.189
applications on also structured data and
 

00:02:04.189 --> 00:02:07.690
applications on also structured data and
structured data includes everything from

00:02:07.690 --> 00:02:07.700
structured data includes everything from
 

00:02:07.700 --> 00:02:10.760
structured data includes everything from
advertisement to

00:02:10.760 --> 00:02:10.770
advertisement to
 

00:02:10.770 --> 00:02:13.340
advertisement to
websearch which isn't just internet

00:02:13.340 --> 00:02:13.350
websearch which isn't just internet
 

00:02:13.350 --> 00:02:14.780
websearch which isn't just internet
search engines is also for example

00:02:14.780 --> 00:02:14.790
search engines is also for example
 

00:02:14.790 --> 00:02:17.930
search engines is also for example
shopping websites or really any website

00:02:17.930 --> 00:02:17.940
shopping websites or really any website
 

00:02:17.940 --> 00:02:20.120
shopping websites or really any website
that wants to deliver great search

00:02:20.120 --> 00:02:20.130
that wants to deliver great search
 

00:02:20.130 --> 00:02:21.830
that wants to deliver great search
results when you enter terms into the

00:02:21.830 --> 00:02:21.840
results when you enter terms into the
 

00:02:21.840 --> 00:02:23.450
results when you enter terms into the
search bar

00:02:23.450 --> 00:02:23.460
search bar
 

00:02:23.460 --> 00:02:28.750
search bar
- computer security - logistics such as

00:02:28.750 --> 00:02:28.760
- computer security - logistics such as
 

00:02:28.760 --> 00:02:31.370
- computer security - logistics such as
figuring out where to send drivers to

00:02:31.370 --> 00:02:31.380
figuring out where to send drivers to
 

00:02:31.380 --> 00:02:33.980
figuring out where to send drivers to
pick up and drop off things - many more

00:02:33.980 --> 00:02:33.990
pick up and drop off things - many more
 

00:02:33.990 --> 00:02:37.130
pick up and drop off things - many more
so what I've seen is that sometimes a

00:02:37.130 --> 00:02:37.140
so what I've seen is that sometimes a
 

00:02:37.140 --> 00:02:38.960
so what I've seen is that sometimes a
researcher with a lot of experience in

00:02:38.960 --> 00:02:38.970
researcher with a lot of experience in
 

00:02:38.970 --> 00:02:41.870
researcher with a lot of experience in
NLP might enter you know might try to do

00:02:41.870 --> 00:02:41.880
NLP might enter you know might try to do
 

00:02:41.880 --> 00:02:43.490
NLP might enter you know might try to do
something in computer vision or maybe a

00:02:43.490 --> 00:02:43.500
something in computer vision or maybe a
 

00:02:43.500 --> 00:02:45.410
something in computer vision or maybe a
researcher with a lot of experience in

00:02:45.410 --> 00:02:45.420
researcher with a lot of experience in
 

00:02:45.420 --> 00:02:48.230
researcher with a lot of experience in
speech recognition might you know jump

00:02:48.230 --> 00:02:48.240
speech recognition might you know jump
 

00:02:48.240 --> 00:02:49.250
speech recognition might you know jump
in and try to do something on

00:02:49.250 --> 00:02:49.260
in and try to do something on
 

00:02:49.260 --> 00:02:51.440
in and try to do something on
advertising or someone from security

00:02:51.440 --> 00:02:51.450
advertising or someone from security
 

00:02:51.450 --> 00:02:53.360
advertising or someone from security
might want to jump and do something on

00:02:53.360 --> 00:02:53.370
might want to jump and do something on
 

00:02:53.370 --> 00:02:55.540
might want to jump and do something on
logistics and what I've seen is that

00:02:55.540 --> 00:02:55.550
logistics and what I've seen is that
 

00:02:55.550 --> 00:02:58.160
logistics and what I've seen is that
intuitions from one domain or from one

00:02:58.160 --> 00:02:58.170
intuitions from one domain or from one
 

00:02:58.170 --> 00:03:00.470
intuitions from one domain or from one
application area often do not transfer

00:03:00.470 --> 00:03:00.480
application area often do not transfer
 

00:03:00.480 --> 00:03:03.230
application area often do not transfer
to other application areas and the best

00:03:03.230 --> 00:03:03.240
to other application areas and the best
 

00:03:03.240 --> 00:03:06.260
to other application areas and the best
choices may depend on the amount of data

00:03:06.260 --> 00:03:06.270
choices may depend on the amount of data
 

00:03:06.270 --> 00:03:07.970
choices may depend on the amount of data
you have the number of input features

00:03:07.970 --> 00:03:07.980
you have the number of input features
 

00:03:07.980 --> 00:03:10.580
you have the number of input features
you have your computer configuration and

00:03:10.580 --> 00:03:10.590
you have your computer configuration and
 

00:03:10.590 --> 00:03:13.250
you have your computer configuration and
whether you're training on GPUs or CPUs

00:03:13.250 --> 00:03:13.260
whether you're training on GPUs or CPUs
 

00:03:13.260 --> 00:03:14.870
whether you're training on GPUs or CPUs
and it's so exactly what configuration

00:03:14.870 --> 00:03:14.880
and it's so exactly what configuration
 

00:03:14.880 --> 00:03:17.660
and it's so exactly what configuration
of GPUs and CPUs and many other things

00:03:17.660 --> 00:03:17.670
of GPUs and CPUs and many other things
 

00:03:17.670 --> 00:03:20.120
of GPUs and CPUs and many other things
so for a lot of applications I think is

00:03:20.120 --> 00:03:20.130
so for a lot of applications I think is
 

00:03:20.130 --> 00:03:22.520
so for a lot of applications I think is
almost impossible even very experienced

00:03:22.520 --> 00:03:22.530
almost impossible even very experienced
 

00:03:22.530 --> 00:03:24.680
almost impossible even very experienced
deep learning people find it almost

00:03:24.680 --> 00:03:24.690
deep learning people find it almost
 

00:03:24.690 --> 00:03:27.260
deep learning people find it almost
impossible to correctly guess the best

00:03:27.260 --> 00:03:27.270
impossible to correctly guess the best
 

00:03:27.270 --> 00:03:29.330
impossible to correctly guess the best
choice of hyper parameters the very

00:03:29.330 --> 00:03:29.340
choice of hyper parameters the very
 

00:03:29.340 --> 00:03:32.360
choice of hyper parameters the very
first time and so today apply deep

00:03:32.360 --> 00:03:32.370
first time and so today apply deep
 

00:03:32.370 --> 00:03:34.010
first time and so today apply deep
learning is a very iterative process

00:03:34.010 --> 00:03:34.020
learning is a very iterative process
 

00:03:34.020 --> 00:03:36.710
learning is a very iterative process
where you just have to go around this

00:03:36.710 --> 00:03:36.720
where you just have to go around this
 

00:03:36.720 --> 00:03:40.430
where you just have to go around this
cycle many times to hopefully find a

00:03:40.430 --> 00:03:40.440
cycle many times to hopefully find a
 

00:03:40.440 --> 00:03:42.530
cycle many times to hopefully find a
good choice of network for your

00:03:42.530 --> 00:03:42.540
good choice of network for your
 

00:03:42.540 --> 00:03:45.170
good choice of network for your
application so one of the things they'll

00:03:45.170 --> 00:03:45.180
application so one of the things they'll
 

00:03:45.180 --> 00:03:46.760
application so one of the things they'll
determine how quickly you can make

00:03:46.760 --> 00:03:46.770
determine how quickly you can make
 

00:03:46.770 --> 00:03:49.580
determine how quickly you can make
progress is how efficiently you can go

00:03:49.580 --> 00:03:49.590
progress is how efficiently you can go
 

00:03:49.590 --> 00:03:52.100
progress is how efficiently you can go
around the cycle and setting up your

00:03:52.100 --> 00:03:52.110
around the cycle and setting up your
 

00:03:52.110 --> 00:03:54.620
around the cycle and setting up your
data sets well in terms of your train

00:03:54.620 --> 00:03:54.630
data sets well in terms of your train
 

00:03:54.630 --> 00:03:56.840
data sets well in terms of your train
development and test sets can meet you

00:03:56.840 --> 00:03:56.850
development and test sets can meet you
 

00:03:56.850 --> 00:03:59.480
development and test sets can meet you
much more efficient at that so if this

00:03:59.480 --> 00:03:59.490
much more efficient at that so if this
 

00:03:59.490 --> 00:04:03.530
much more efficient at that so if this
is your training data let's draw that as

00:04:03.530 --> 00:04:03.540
is your training data let's draw that as
 

00:04:03.540 --> 00:04:08.230
is your training data let's draw that as
a big box then traditionally you might

00:04:08.230 --> 00:04:08.240
a big box then traditionally you might
 

00:04:08.240 --> 00:04:11.600
a big box then traditionally you might
take all the data you have and carve off

00:04:11.600 --> 00:04:11.610
take all the data you have and carve off
 

00:04:11.610 --> 00:04:14.240
take all the data you have and carve off
some portion of it to be your training

00:04:14.240 --> 00:04:14.250
some portion of it to be your training
 

00:04:14.250 --> 00:04:18.160
some portion of it to be your training
set some portion of it to be your

00:04:18.160 --> 00:04:18.170
set some portion of it to be your
 

00:04:18.170 --> 00:04:23.980
set some portion of it to be your
hold out draws validation sets and this

00:04:23.980 --> 00:04:23.990
hold out draws validation sets and this
 

00:04:23.990 --> 00:04:28.500
hold out draws validation sets and this
is sometimes also called the development

00:04:28.500 --> 00:04:28.510
is sometimes also called the development
 

00:04:28.510 --> 00:04:31.690
is sometimes also called the development
set and for brevity I'm just going to

00:04:31.690 --> 00:04:31.700
set and for brevity I'm just going to
 

00:04:31.700 --> 00:04:34.210
set and for brevity I'm just going to
call this the dev set but all of these

00:04:34.210 --> 00:04:34.220
call this the dev set but all of these
 

00:04:34.220 --> 00:04:36.970
call this the dev set but all of these
terms being roughly the same thing and

00:04:36.970 --> 00:04:36.980
terms being roughly the same thing and
 

00:04:36.980 --> 00:04:38.860
terms being roughly the same thing and
then you might carve out some final

00:04:38.860 --> 00:04:38.870
then you might carve out some final
 

00:04:38.870 --> 00:04:42.130
then you might carve out some final
portion of it to be your test set and so

00:04:42.130 --> 00:04:42.140
portion of it to be your test set and so
 

00:04:42.140 --> 00:04:43.870
portion of it to be your test set and so
the work though is that you keep on

00:04:43.870 --> 00:04:43.880
the work though is that you keep on
 

00:04:43.880 --> 00:04:45.550
the work though is that you keep on
training algorithms on your training

00:04:45.550 --> 00:04:45.560
training algorithms on your training
 

00:04:45.560 --> 00:04:48.160
training algorithms on your training
sites and use your dev set or your hold

00:04:48.160 --> 00:04:48.170
sites and use your dev set or your hold
 

00:04:48.170 --> 00:04:50.800
sites and use your dev set or your hold
on trial validation set to see which of

00:04:50.800 --> 00:04:50.810
on trial validation set to see which of
 

00:04:50.810 --> 00:04:53.260
on trial validation set to see which of
many different models performs best on

00:04:53.260 --> 00:04:53.270
many different models performs best on
 

00:04:53.270 --> 00:04:55.840
many different models performs best on
your dev set and then after having done

00:04:55.840 --> 00:04:55.850
your dev set and then after having done
 

00:04:55.850 --> 00:04:58.210
your dev set and then after having done
this long enough when you have a final

00:04:58.210 --> 00:04:58.220
this long enough when you have a final
 

00:04:58.220 --> 00:05:00.190
this long enough when you have a final
model do you want to evaluate you can

00:05:00.190 --> 00:05:00.200
model do you want to evaluate you can
 

00:05:00.200 --> 00:05:01.630
model do you want to evaluate you can
take the best model you have found and

00:05:01.630 --> 00:05:01.640
take the best model you have found and
 

00:05:01.640 --> 00:05:03.790
take the best model you have found and
evaluate it on your test set in order to

00:05:03.790 --> 00:05:03.800
evaluate it on your test set in order to
 

00:05:03.800 --> 00:05:07.000
evaluate it on your test set in order to
get a unbiased estimate of how well your

00:05:07.000 --> 00:05:07.010
get a unbiased estimate of how well your
 

00:05:07.010 --> 00:05:09.190
get a unbiased estimate of how well your
algorithm is doing so in the previous

00:05:09.190 --> 00:05:09.200
algorithm is doing so in the previous
 

00:05:09.200 --> 00:05:12.460
algorithm is doing so in the previous
era of machine learning it was common

00:05:12.460 --> 00:05:12.470
era of machine learning it was common
 

00:05:12.470 --> 00:05:14.980
era of machine learning it was common
practice to take all your data and split

00:05:14.980 --> 00:05:14.990
practice to take all your data and split
 

00:05:14.990 --> 00:05:18.730
practice to take all your data and split
it according to maybe a 70/30 percent um

00:05:18.730 --> 00:05:18.740
it according to maybe a 70/30 percent um
 

00:05:18.740 --> 00:05:21.010
it according to maybe a 70/30 percent um
in terms of a people often talked about

00:05:21.010 --> 00:05:21.020
in terms of a people often talked about
 

00:05:21.020 --> 00:05:24.040
in terms of a people often talked about
the 70/30 train tested if you don't have

00:05:24.040 --> 00:05:24.050
the 70/30 train tested if you don't have
 

00:05:24.050 --> 00:05:26.470
the 70/30 train tested if you don't have
an explicit dev set or maybe you know a

00:05:26.470 --> 00:05:26.480
an explicit dev set or maybe you know a
 

00:05:26.480 --> 00:05:29.440
an explicit dev set or maybe you know a
60 20 20 percent split now in terms of

00:05:29.440 --> 00:05:29.450
60 20 20 percent split now in terms of
 

00:05:29.450 --> 00:05:32.110
60 20 20 percent split now in terms of
60 percent trained 20% dev and 20

00:05:32.110 --> 00:05:32.120
60 percent trained 20% dev and 20
 

00:05:32.120 --> 00:05:33.010
60 percent trained 20% dev and 20
percent test

00:05:33.010 --> 00:05:33.020
percent test
 

00:05:33.020 --> 00:05:35.710
percent test
and several years ago this was widely

00:05:35.710 --> 00:05:35.720
and several years ago this was widely
 

00:05:35.720 --> 00:05:37.660
and several years ago this was widely
considered best practice in machine

00:05:37.660 --> 00:05:37.670
considered best practice in machine
 

00:05:37.670 --> 00:05:40.060
considered best practice in machine
learning if you have you know maybe 100

00:05:40.060 --> 00:05:40.070
learning if you have you know maybe 100
 

00:05:40.070 --> 00:05:42.370
learning if you have you know maybe 100
examples in total or maybe a thousand

00:05:42.370 --> 00:05:42.380
examples in total or maybe a thousand
 

00:05:42.380 --> 00:05:44.860
examples in total or maybe a thousand
examples in total maybe after you know

00:05:44.860 --> 00:05:44.870
examples in total maybe after you know
 

00:05:44.870 --> 00:05:47.710
examples in total maybe after you know
10,000 examples these sorts of ratios

00:05:47.710 --> 00:05:47.720
10,000 examples these sorts of ratios
 

00:05:47.720 --> 00:05:50.230
10,000 examples these sorts of ratios
were perfectly reasonable rules of thumb

00:05:50.230 --> 00:05:50.240
were perfectly reasonable rules of thumb
 

00:05:50.240 --> 00:05:55.030
were perfectly reasonable rules of thumb
but in the modern Big Data error where

00:05:55.030 --> 00:05:55.040
but in the modern Big Data error where
 

00:05:55.040 --> 00:05:57.810
but in the modern Big Data error where
for example you might have a million

00:05:57.810 --> 00:05:57.820
for example you might have a million
 

00:05:57.820 --> 00:06:02.320
for example you might have a million
examples in total then the trend is that

00:06:02.320 --> 00:06:02.330
examples in total then the trend is that
 

00:06:02.330 --> 00:06:05.770
examples in total then the trend is that
you're Devin 10 sets have been becoming

00:06:05.770 --> 00:06:05.780
you're Devin 10 sets have been becoming
 

00:06:05.780 --> 00:06:08.550
you're Devin 10 sets have been becoming
a much smaller percentage of the total

00:06:08.550 --> 00:06:08.560
a much smaller percentage of the total
 

00:06:08.560 --> 00:06:11.200
a much smaller percentage of the total
because remember the goal of the dev

00:06:11.200 --> 00:06:11.210
because remember the goal of the dev
 

00:06:11.210 --> 00:06:12.970
because remember the goal of the dev
sets that the development set is that

00:06:12.970 --> 00:06:12.980
sets that the development set is that
 

00:06:12.980 --> 00:06:14.950
sets that the development set is that
you're going to test different Avram's

00:06:14.950 --> 00:06:14.960
you're going to test different Avram's
 

00:06:14.960 --> 00:06:17.020
you're going to test different Avram's
on it and see whichever works better so

00:06:17.020 --> 00:06:17.030
on it and see whichever works better so
 

00:06:17.030 --> 00:06:19.240
on it and see whichever works better so
the death set just needs to be big

00:06:19.240 --> 00:06:19.250
the death set just needs to be big
 

00:06:19.250 --> 00:06:21.940
the death set just needs to be big
enough for you to evaluate say two

00:06:21.940 --> 00:06:21.950
enough for you to evaluate say two
 

00:06:21.950 --> 00:06:23.470
enough for you to evaluate say two
different algorithm courses or ten

00:06:23.470 --> 00:06:23.480
different algorithm courses or ten
 

00:06:23.480 --> 00:06:25.330
different algorithm courses or ten
different averages and quickly decide

00:06:25.330 --> 00:06:25.340
different averages and quickly decide
 

00:06:25.340 --> 00:06:27.280
different averages and quickly decide
which one is doing better and you might

00:06:27.280 --> 00:06:27.290
which one is doing better and you might
 

00:06:27.290 --> 00:06:29.159
which one is doing better and you might
not need a whole 20 percent of your day

00:06:29.159 --> 00:06:29.169
not need a whole 20 percent of your day
 

00:06:29.169 --> 00:06:31.860
not need a whole 20 percent of your day
for that so for example we have a

00:06:31.860 --> 00:06:31.870
for that so for example we have a
 

00:06:31.870 --> 00:06:33.749
for that so for example we have a
million chin examples you might decide

00:06:33.749 --> 00:06:33.759
million chin examples you might decide
 

00:06:33.759 --> 00:06:37.050
million chin examples you might decide
that just having ten thousand examples

00:06:37.050 --> 00:06:37.060
that just having ten thousand examples
 

00:06:37.060 --> 00:06:39.149
that just having ten thousand examples
in your death set is more than enough to

00:06:39.149 --> 00:06:39.159
in your death set is more than enough to
 

00:06:39.159 --> 00:06:41.309
in your death set is more than enough to
evaluate you know which one or two

00:06:41.309 --> 00:06:41.319
evaluate you know which one or two
 

00:06:41.319 --> 00:06:43.769
evaluate you know which one or two
algorithms does better and in a similar

00:06:43.769 --> 00:06:43.779
algorithms does better and in a similar
 

00:06:43.779 --> 00:06:45.839
algorithms does better and in a similar
vein the main goal of your test set is

00:06:45.839 --> 00:06:45.849
vein the main goal of your test set is
 

00:06:45.849 --> 00:06:48.330
vein the main goal of your test set is
given your final classifier to give you

00:06:48.330 --> 00:06:48.340
given your final classifier to give you
 

00:06:48.340 --> 00:06:50.700
given your final classifier to give you
a pretty confident estimate of how well

00:06:50.700 --> 00:06:50.710
a pretty confident estimate of how well
 

00:06:50.710 --> 00:06:52.529
a pretty confident estimate of how well
it's doing and again if you have a

00:06:52.529 --> 00:06:52.539
it's doing and again if you have a
 

00:06:52.539 --> 00:06:54.959
it's doing and again if you have a
million examples maybe you might decide

00:06:54.959 --> 00:06:54.969
million examples maybe you might decide
 

00:06:54.969 --> 00:06:57.540
million examples maybe you might decide
that 10,000 examples is more than enough

00:06:57.540 --> 00:06:57.550
that 10,000 examples is more than enough
 

00:06:57.550 --> 00:07:00.149
that 10,000 examples is more than enough
in order to evaluate a single qualifier

00:07:00.149 --> 00:07:00.159
in order to evaluate a single qualifier
 

00:07:00.159 --> 00:07:02.309
in order to evaluate a single qualifier
and give you a good estimate of how well

00:07:02.309 --> 00:07:02.319
and give you a good estimate of how well
 

00:07:02.319 --> 00:07:05.040
and give you a good estimate of how well
it's doing so in this example where you

00:07:05.040 --> 00:07:05.050
it's doing so in this example where you
 

00:07:05.050 --> 00:07:07.999
it's doing so in this example where you
have a million examples if you need just

00:07:07.999 --> 00:07:08.009
have a million examples if you need just
 

00:07:08.009 --> 00:07:10.679
have a million examples if you need just
10,000 for your Devon 10,000 for your

00:07:10.679 --> 00:07:10.689
10,000 for your Devon 10,000 for your
 

00:07:10.689 --> 00:07:13.760
10,000 for your Devon 10,000 for your
test your ratio would be more like

00:07:13.760 --> 00:07:13.770
test your ratio would be more like
 

00:07:13.770 --> 00:07:17.719
test your ratio would be more like
10,000 is 1% of 1 million so you have

00:07:17.719 --> 00:07:17.729
10,000 is 1% of 1 million so you have
 

00:07:17.729 --> 00:07:23.429
10,000 is 1% of 1 million so you have
98% trained 1% death 1% yes and I've

00:07:23.429 --> 00:07:23.439
98% trained 1% death 1% yes and I've
 

00:07:23.439 --> 00:07:25.559
98% trained 1% death 1% yes and I've
also seen applications where if you have

00:07:25.559 --> 00:07:25.569
also seen applications where if you have
 

00:07:25.569 --> 00:07:27.450
also seen applications where if you have
even more than million examples you

00:07:27.450 --> 00:07:27.460
even more than million examples you
 

00:07:27.460 --> 00:07:30.689
even more than million examples you
might end up with you know 99.5% trained

00:07:30.689 --> 00:07:30.699
might end up with you know 99.5% trained
 

00:07:30.699 --> 00:07:34.829
might end up with you know 99.5% trained
and 0.25 percent death 0.25 percent test

00:07:34.829 --> 00:07:34.839
and 0.25 percent death 0.25 percent test
 

00:07:34.839 --> 00:07:40.079
and 0.25 percent death 0.25 percent test
or maybe a 0.4 percent deaf 0.1 percent

00:07:40.079 --> 00:07:40.089
or maybe a 0.4 percent deaf 0.1 percent
 

00:07:40.089 --> 00:07:44.399
or maybe a 0.4 percent deaf 0.1 percent
test so just a recap when setting up

00:07:44.399 --> 00:07:44.409
test so just a recap when setting up
 

00:07:44.409 --> 00:07:46.290
test so just a recap when setting up
your machine learning problem more often

00:07:46.290 --> 00:07:46.300
your machine learning problem more often
 

00:07:46.300 --> 00:07:49.559
your machine learning problem more often
set up into a trained F and test sets

00:07:49.559 --> 00:07:49.569
set up into a trained F and test sets
 

00:07:49.569 --> 00:07:52.110
set up into a trained F and test sets
and if you have a relatively small data

00:07:52.110 --> 00:07:52.120
and if you have a relatively small data
 

00:07:52.120 --> 00:07:54.719
and if you have a relatively small data
set these traditional ratios might be

00:07:54.719 --> 00:07:54.729
set these traditional ratios might be
 

00:07:54.729 --> 00:07:56.850
set these traditional ratios might be
okay but if you have a much larger data

00:07:56.850 --> 00:07:56.860
okay but if you have a much larger data
 

00:07:56.860 --> 00:07:59.700
okay but if you have a much larger data
set is also fine to set your Devon test

00:07:59.700 --> 00:07:59.710
set is also fine to set your Devon test
 

00:07:59.710 --> 00:08:02.219
set is also fine to set your Devon test
sets to be much smaller than you know

00:08:02.219 --> 00:08:02.229
sets to be much smaller than you know
 

00:08:02.229 --> 00:08:04.950
sets to be much smaller than you know
20% or even want to 10% of your data

00:08:04.950 --> 00:08:04.960
20% or even want to 10% of your data
 

00:08:04.960 --> 00:08:07.469
20% or even want to 10% of your data
will give more specific guidelines on

00:08:07.469 --> 00:08:07.479
will give more specific guidelines on
 

00:08:07.479 --> 00:08:09.659
will give more specific guidelines on
the sizes of Devon test sets later in

00:08:09.659 --> 00:08:09.669
the sizes of Devon test sets later in
 

00:08:09.669 --> 00:08:11.879
the sizes of Devon test sets later in
this specialization one other trend

00:08:11.879 --> 00:08:11.889
this specialization one other trend
 

00:08:11.889 --> 00:08:14.369
this specialization one other trend
we're seeing in the era of modern deep

00:08:14.369 --> 00:08:14.379
we're seeing in the era of modern deep
 

00:08:14.379 --> 00:08:16.260
we're seeing in the era of modern deep
learning is that more and more people

00:08:16.260 --> 00:08:16.270
learning is that more and more people
 

00:08:16.270 --> 00:08:18.689
learning is that more and more people
train on mismatched training test

00:08:18.689 --> 00:08:18.699
train on mismatched training test
 

00:08:18.699 --> 00:08:20.730
train on mismatched training test
distributions let's say you're building

00:08:20.730 --> 00:08:20.740
distributions let's say you're building
 

00:08:20.740 --> 00:08:23.909
distributions let's say you're building
an app that lets users upload than all

00:08:23.909 --> 00:08:23.919
an app that lets users upload than all
 

00:08:23.919 --> 00:08:25.950
an app that lets users upload than all
the pictures and your goal is to find

00:08:25.950 --> 00:08:25.960
the pictures and your goal is to find
 

00:08:25.960 --> 00:08:28.739
the pictures and your goal is to find
pictures of cats in order to show your

00:08:28.739 --> 00:08:28.749
pictures of cats in order to show your
 

00:08:28.749 --> 00:08:30.899
pictures of cats in order to show your
users maybe all your users in canvas

00:08:30.899 --> 00:08:30.909
users maybe all your users in canvas
 

00:08:30.909 --> 00:08:34.050
users maybe all your users in canvas
maybe your training set comes from cat

00:08:34.050 --> 00:08:34.060
maybe your training set comes from cat
 

00:08:34.060 --> 00:08:36.449
maybe your training set comes from cat
pictures downloaded off the internet of

00:08:36.449 --> 00:08:36.459
pictures downloaded off the internet of
 

00:08:36.459 --> 00:08:38.550
pictures downloaded off the internet of
then your Devon headset

00:08:38.550 --> 00:08:38.560
then your Devon headset
 

00:08:38.560 --> 00:08:41.219
then your Devon headset
might comprise cat pictures from users

00:08:41.219 --> 00:08:41.229
might comprise cat pictures from users
 

00:08:41.229 --> 00:08:42.320
might comprise cat pictures from users
using our app

00:08:42.320 --> 00:08:42.330
using our app
 

00:08:42.330 --> 00:08:43.759
using our app
Samira training centers while the

00:08:43.759 --> 00:08:43.769
Samira training centers while the
 

00:08:43.769 --> 00:08:46.100
Samira training centers while the
pictures traveled off the internet but

00:08:46.100 --> 00:08:46.110
pictures traveled off the internet but
 

00:08:46.110 --> 00:08:48.050
pictures traveled off the internet but
the Devin testers are pictures uploaded

00:08:48.050 --> 00:08:48.060
the Devin testers are pictures uploaded
 

00:08:48.060 --> 00:08:48.889
the Devin testers are pictures uploaded
by users

00:08:48.889 --> 00:08:48.899
by users
 

00:08:48.899 --> 00:08:51.380
by users
turns out of all the web pages have very

00:08:51.380 --> 00:08:51.390
turns out of all the web pages have very
 

00:08:51.390 --> 00:08:53.269
turns out of all the web pages have very
high resolution very professional very

00:08:53.269 --> 00:08:53.279
high resolution very professional very
 

00:08:53.279 --> 00:08:55.850
high resolution very professional very
nicely framed pictures of cats but maybe

00:08:55.850 --> 00:08:55.860
nicely framed pictures of cats but maybe
 

00:08:55.860 --> 00:08:57.530
nicely framed pictures of cats but maybe
your users are uploading you know

00:08:57.530 --> 00:08:57.540
your users are uploading you know
 

00:08:57.540 --> 00:09:00.259
your users are uploading you know
blurrier lower res images just taken

00:09:00.259 --> 00:09:00.269
blurrier lower res images just taken
 

00:09:00.269 --> 00:09:02.060
blurrier lower res images just taken
with a cell phone camera in a more

00:09:02.060 --> 00:09:02.070
with a cell phone camera in a more
 

00:09:02.070 --> 00:09:04.180
with a cell phone camera in a more
casual condition and so these two

00:09:04.180 --> 00:09:04.190
casual condition and so these two
 

00:09:04.190 --> 00:09:07.009
casual condition and so these two
distributions of data may be different

00:09:07.009 --> 00:09:07.019
distributions of data may be different
 

00:09:07.019 --> 00:09:09.350
distributions of data may be different
the rule of thumb might encourage you to

00:09:09.350 --> 00:09:09.360
the rule of thumb might encourage you to
 

00:09:09.360 --> 00:09:12.740
the rule of thumb might encourage you to
follow in this case is to make sure that

00:09:12.740 --> 00:09:12.750
follow in this case is to make sure that
 

00:09:12.750 --> 00:09:17.509
follow in this case is to make sure that
deep dev and test sets come from the

00:09:17.509 --> 00:09:17.519
deep dev and test sets come from the
 

00:09:17.519 --> 00:09:23.810
deep dev and test sets come from the
same distribution we'll see more about

00:09:23.810 --> 00:09:23.820
same distribution we'll see more about
 

00:09:23.820 --> 00:09:25.850
same distribution we'll see more about
this particular guideline as well but

00:09:25.850 --> 00:09:25.860
this particular guideline as well but
 

00:09:25.860 --> 00:09:28.639
this particular guideline as well but
because you will be using the death set

00:09:28.639 --> 00:09:28.649
because you will be using the death set
 

00:09:28.649 --> 00:09:30.319
because you will be using the death set
you value a lot of different models and

00:09:30.319 --> 00:09:30.329
you value a lot of different models and
 

00:09:30.329 --> 00:09:31.639
you value a lot of different models and
trying really hard to improve

00:09:31.639 --> 00:09:31.649
trying really hard to improve
 

00:09:31.649 --> 00:09:33.889
trying really hard to improve
performance on a death set is nice if

00:09:33.889 --> 00:09:33.899
performance on a death set is nice if
 

00:09:33.899 --> 00:09:35.300
performance on a death set is nice if
your death set comes from the same

00:09:35.300 --> 00:09:35.310
your death set comes from the same
 

00:09:35.310 --> 00:09:38.389
your death set comes from the same
distribution as your test set but

00:09:38.389 --> 00:09:38.399
distribution as your test set but
 

00:09:38.399 --> 00:09:40.040
distribution as your test set but
because deep learning algorithms are

00:09:40.040 --> 00:09:40.050
because deep learning algorithms are
 

00:09:40.050 --> 00:09:43.430
because deep learning algorithms are
such a huge hunger for training data one

00:09:43.430 --> 00:09:43.440
such a huge hunger for training data one
 

00:09:43.440 --> 00:09:45.590
such a huge hunger for training data one
trend I'm seeing is that you might use

00:09:45.590 --> 00:09:45.600
trend I'm seeing is that you might use
 

00:09:45.600 --> 00:09:47.780
trend I'm seeing is that you might use
all sorts of creative tactics such as

00:09:47.780 --> 00:09:47.790
all sorts of creative tactics such as
 

00:09:47.790 --> 00:09:50.660
all sorts of creative tactics such as
crawling webpages in order to acquire a

00:09:50.660 --> 00:09:50.670
crawling webpages in order to acquire a
 

00:09:50.670 --> 00:09:52.340
crawling webpages in order to acquire a
much bigger training set than you would

00:09:52.340 --> 00:09:52.350
much bigger training set than you would
 

00:09:52.350 --> 00:09:54.590
much bigger training set than you would
otherwise have even if part of the cause

00:09:54.590 --> 00:09:54.600
otherwise have even if part of the cause
 

00:09:54.600 --> 00:09:56.810
otherwise have even if part of the cause
of that is then that your training set

00:09:56.810 --> 00:09:56.820
of that is then that your training set
 

00:09:56.820 --> 00:09:58.639
of that is then that your training set
data might not come from the same

00:09:58.639 --> 00:09:58.649
data might not come from the same
 

00:09:58.649 --> 00:10:00.319
data might not come from the same
distribution as your dev and test set

00:10:00.319 --> 00:10:00.329
distribution as your dev and test set
 

00:10:00.329 --> 00:10:02.389
distribution as your dev and test set
but you find that so long as you follow

00:10:02.389 --> 00:10:02.399
but you find that so long as you follow
 

00:10:02.399 --> 00:10:06.019
but you find that so long as you follow
this rule of thumb that progress in your

00:10:06.019 --> 00:10:06.029
this rule of thumb that progress in your
 

00:10:06.029 --> 00:10:07.550
this rule of thumb that progress in your
machine learning algorithm will be

00:10:07.550 --> 00:10:07.560
machine learning algorithm will be
 

00:10:07.560 --> 00:10:09.530
machine learning algorithm will be
faster and I'll give a more detailed

00:10:09.530 --> 00:10:09.540
faster and I'll give a more detailed
 

00:10:09.540 --> 00:10:11.840
faster and I'll give a more detailed
explanation for this tutorial some dates

00:10:11.840 --> 00:10:11.850
explanation for this tutorial some dates
 

00:10:11.850 --> 00:10:15.230
explanation for this tutorial some dates
and descritization as well finally it

00:10:15.230 --> 00:10:15.240
and descritization as well finally it
 

00:10:15.240 --> 00:10:18.079
and descritization as well finally it
might be okay to not have a test set

00:10:18.079 --> 00:10:18.089
might be okay to not have a test set
 

00:10:18.089 --> 00:10:19.850
might be okay to not have a test set
remember to go of the test set is to

00:10:19.850 --> 00:10:19.860
remember to go of the test set is to
 

00:10:19.860 --> 00:10:22.970
remember to go of the test set is to
give you a unbiased estimate of the

00:10:22.970 --> 00:10:22.980
give you a unbiased estimate of the
 

00:10:22.980 --> 00:10:25.579
give you a unbiased estimate of the
performance of your final network of the

00:10:25.579 --> 00:10:25.589
performance of your final network of the
 

00:10:25.589 --> 00:10:27.439
performance of your final network of the
network that you selected but you don't

00:10:27.439 --> 00:10:27.449
network that you selected but you don't
 

00:10:27.449 --> 00:10:29.569
network that you selected but you don't
need that unbiased estimate then it

00:10:29.569 --> 00:10:29.579
need that unbiased estimate then it
 

00:10:29.579 --> 00:10:32.090
need that unbiased estimate then it
might be okay to not have a test set so

00:10:32.090 --> 00:10:32.100
might be okay to not have a test set so
 

00:10:32.100 --> 00:10:33.769
might be okay to not have a test set so
what you do if you have only a death

00:10:33.769 --> 00:10:33.779
what you do if you have only a death
 

00:10:33.779 --> 00:10:35.540
what you do if you have only a death
step and all the test size is you

00:10:35.540 --> 00:10:35.550
step and all the test size is you
 

00:10:35.550 --> 00:10:38.060
step and all the test size is you
trained on the training set and then you

00:10:38.060 --> 00:10:38.070
trained on the training set and then you
 

00:10:38.070 --> 00:10:39.650
trained on the training set and then you
try different model architectures

00:10:39.650 --> 00:10:39.660
try different model architectures
 

00:10:39.660 --> 00:10:42.800
try different model architectures
evaluate them on the death set and then

00:10:42.800 --> 00:10:42.810
evaluate them on the death set and then
 

00:10:42.810 --> 00:10:45.019
evaluate them on the death set and then
use that to iterate and try to get to a

00:10:45.019 --> 00:10:45.029
use that to iterate and try to get to a
 

00:10:45.029 --> 00:10:47.389
use that to iterate and try to get to a
good model because you fit today to the

00:10:47.389 --> 00:10:47.399
good model because you fit today to the
 

00:10:47.399 --> 00:10:49.519
good model because you fit today to the
dev set there's no long surgeon unbiased

00:10:49.519 --> 00:10:49.529
dev set there's no long surgeon unbiased
 

00:10:49.529 --> 00:10:51.170
dev set there's no long surgeon unbiased
estimate of performance but if you don't

00:10:51.170 --> 00:10:51.180
estimate of performance but if you don't
 

00:10:51.180 --> 00:10:53.490
estimate of performance but if you don't
need one that might be perfectly fine

00:10:53.490 --> 00:10:53.500
need one that might be perfectly fine
 

00:10:53.500 --> 00:10:54.870
need one that might be perfectly fine
in the machine learning world when you

00:10:54.870 --> 00:10:54.880
in the machine learning world when you
 

00:10:54.880 --> 00:10:56.850
in the machine learning world when you
have just a train on a deaf set but no

00:10:56.850 --> 00:10:56.860
have just a train on a deaf set but no
 

00:10:56.860 --> 00:10:58.170
have just a train on a deaf set but no
separate test set

00:10:58.170 --> 00:10:58.180
separate test set
 

00:10:58.180 --> 00:11:00.360
separate test set
most people will call this the training

00:11:00.360 --> 00:11:00.370
most people will call this the training
 

00:11:00.370 --> 00:11:03.720
most people will call this the training
set and they will call the death set the

00:11:03.720 --> 00:11:03.730
set and they will call the death set the
 

00:11:03.730 --> 00:11:05.400
set and they will call the death set the
test set but what they actually end up

00:11:05.400 --> 00:11:05.410
test set but what they actually end up
 

00:11:05.410 --> 00:11:07.890
test set but what they actually end up
doing is using the test set as a holdout

00:11:07.890 --> 00:11:07.900
doing is using the test set as a holdout
 

00:11:07.900 --> 00:11:10.260
doing is using the test set as a holdout
cross-validation Center which maybe

00:11:10.260 --> 00:11:10.270
cross-validation Center which maybe
 

00:11:10.270 --> 00:11:12.690
cross-validation Center which maybe
isn't completely a great use of

00:11:12.690 --> 00:11:12.700
isn't completely a great use of
 

00:11:12.700 --> 00:11:14.370
isn't completely a great use of
terminology because they're then

00:11:14.370 --> 00:11:14.380
terminology because they're then
 

00:11:14.380 --> 00:11:17.610
terminology because they're then
overfitting to the chip set so when the

00:11:17.610 --> 00:11:17.620
overfitting to the chip set so when the
 

00:11:17.620 --> 00:11:19.290
overfitting to the chip set so when the
team tells you that they have only a

00:11:19.290 --> 00:11:19.300
team tells you that they have only a
 

00:11:19.300 --> 00:11:21.720
team tells you that they have only a
train and a test set you know I would

00:11:21.720 --> 00:11:21.730
train and a test set you know I would
 

00:11:21.730 --> 00:11:23.580
train and a test set you know I would
just be cautious and think do they

00:11:23.580 --> 00:11:23.590
just be cautious and think do they
 

00:11:23.590 --> 00:11:26.130
just be cautious and think do they
really have a trade deficits because

00:11:26.130 --> 00:11:26.140
really have a trade deficits because
 

00:11:26.140 --> 00:11:28.250
really have a trade deficits because
they're overfitting to the test set

00:11:28.250 --> 00:11:28.260
they're overfitting to the test set
 

00:11:28.260 --> 00:11:30.480
they're overfitting to the test set
culturally it might be difficult to

00:11:30.480 --> 00:11:30.490
culturally it might be difficult to
 

00:11:30.490 --> 00:11:33.720
culturally it might be difficult to
change some of these teams terminology

00:11:33.720 --> 00:11:33.730
change some of these teams terminology
 

00:11:33.730 --> 00:11:35.790
change some of these teams terminology
and get them to call it a train death

00:11:35.790 --> 00:11:35.800
and get them to call it a train death
 

00:11:35.800 --> 00:11:38.400
and get them to call it a train death
sets rather than train test set even

00:11:38.400 --> 00:11:38.410
sets rather than train test set even
 

00:11:38.410 --> 00:11:40.050
sets rather than train test set even
though I think calling it a train and

00:11:40.050 --> 00:11:40.060
though I think calling it a train and
 

00:11:40.060 --> 00:11:41.700
though I think calling it a train and
development set would be more correct

00:11:41.700 --> 00:11:41.710
development set would be more correct
 

00:11:41.710 --> 00:11:44.220
development set would be more correct
terminology and this is actually okay

00:11:44.220 --> 00:11:44.230
terminology and this is actually okay
 

00:11:44.230 --> 00:11:45.720
terminology and this is actually okay
practice if you don't need a completely

00:11:45.720 --> 00:11:45.730
practice if you don't need a completely
 

00:11:45.730 --> 00:11:47.610
practice if you don't need a completely
unbiased estimate of the performance of

00:11:47.610 --> 00:11:47.620
unbiased estimate of the performance of
 

00:11:47.620 --> 00:11:50.310
unbiased estimate of the performance of
your algorithm so having set up a train

00:11:50.310 --> 00:11:50.320
your algorithm so having set up a train
 

00:11:50.320 --> 00:11:52.260
your algorithm so having set up a train
death and test set to allow you to

00:11:52.260 --> 00:11:52.270
death and test set to allow you to
 

00:11:52.270 --> 00:11:54.540
death and test set to allow you to
iterate more quickly it will also allow

00:11:54.540 --> 00:11:54.550
iterate more quickly it will also allow
 

00:11:54.550 --> 00:11:56.460
iterate more quickly it will also allow
you to more efficiently measure that

00:11:56.460 --> 00:11:56.470
you to more efficiently measure that
 

00:11:56.470 --> 00:11:58.500
you to more efficiently measure that
bias and variance of your algorithm so

00:11:58.500 --> 00:11:58.510
bias and variance of your algorithm so
 

00:11:58.510 --> 00:12:00.720
bias and variance of your algorithm so
they can more efficiently select ways to

00:12:00.720 --> 00:12:00.730
they can more efficiently select ways to
 

00:12:00.730 --> 00:12:02.760
they can more efficiently select ways to
improve your algorithm let's start to

00:12:02.760 --> 00:12:02.770
improve your algorithm let's start to
 

00:12:02.770 --> 00:12:06.210
improve your algorithm let's start to
talk about that in the next video

