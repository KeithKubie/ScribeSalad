WEBVTT
Kind: captions
Language: en

00:00:00.390 --> 00:00:04.780
So far, you've derived two potential
schemes for a distributed Bitonic Merge.

00:00:04.780 --> 00:00:07.340
The first is a block
distribution scheme.

00:00:07.340 --> 00:00:11.430
Remember that it is log P stages of
communication followed by log n over P

00:00:11.430 --> 00:00:14.430
stages of purely local computation.

00:00:14.430 --> 00:00:16.860
The second scheme was the cyclic scheme.

00:00:16.860 --> 00:00:21.390
It has log n over P stages of purely
local computation followed by log P

00:00:21.390 --> 00:00:23.540
stages of communication.

00:00:23.540 --> 00:00:25.360
Now, the running time for
the two schemes is the same.

00:00:25.360 --> 00:00:30.710
It's basically alpha log P plus
beta times n over P log P.

00:00:30.710 --> 00:00:34.260
Now, looking at these terms,
you might worry about the beta term.

00:00:34.260 --> 00:00:38.020
If n over P is really large and
the beta term dominates the alpha term,

00:00:38.020 --> 00:00:43.340
then it looks like you're paying to
send n over P words log P times.

00:00:43.340 --> 00:00:47.400
So, a natural question is, is there
an alternative that would let you reduce

00:00:47.400 --> 00:00:51.980
the cost of the beta term, possibly at
the cost of increasing the alpha term.

00:00:51.980 --> 00:00:53.650
In fact, there is.

00:00:53.650 --> 00:00:55.370
First, let's start cyclic.

00:00:56.450 --> 00:01:00.220
Starting cyclic means there's
no communication initially.

00:01:00.220 --> 00:01:02.610
Then, let's switch to block.

00:01:02.610 --> 00:01:06.380
Switching to block means that at
the end there's no communication.

00:01:06.380 --> 00:01:07.800
Of course, to make this scheme work,

00:01:07.800 --> 00:01:10.750
you're going to need to
reshuffle the data in between.

00:01:10.750 --> 00:01:13.780
This reshuffling is called a transpose.

00:01:13.780 --> 00:01:17.400
You can view the transpose as
either a matrix transpose or

00:01:17.400 --> 00:01:20.750
also as an all to all
personalized exchange.

00:01:20.750 --> 00:01:23.030
Let's take the first process,
for instance.

00:01:24.040 --> 00:01:30.150
Notice that it has to send p minus one
messages, each of size n over p squared.

00:01:30.150 --> 00:01:34.810
Notice that it has to send these
messages to each of the other processes.

00:01:34.810 --> 00:01:37.700
The same thing goes for
every other process.

00:01:37.700 --> 00:01:40.290
For example,
let's look at the last process.

00:01:40.290 --> 00:01:43.766
So how does this scheme compare
to the block of cyclic schemes.

00:01:44.860 --> 00:01:46.458
Again let's recall the block and

00:01:46.458 --> 00:01:49.800
cyclic communication times
assuming a hypercube.

00:01:49.800 --> 00:01:52.640
Now since the transpose
needs to do an all-to-all

00:01:52.640 --> 00:01:56.870
let's make a stronger assumption, which
is that the network is fully connected.

00:01:57.910 --> 00:01:59.750
In that case,
computing the cost would be really easy.

00:02:00.790 --> 00:02:04.720
So if the network is fully connected,
and then each process will send (P- 1)

00:02:04.720 --> 00:02:09.800
messages, and the messages
will be of size n / P squared.

00:02:09.800 --> 00:02:11.030
So as you can see,

00:02:11.030 --> 00:02:15.790
each scheme exhibits a latency bandwidth
trade off relative to the other.

00:02:15.790 --> 00:02:19.570
So here we get rid of the log P factor
on the beta term at the cost of

00:02:19.570 --> 00:02:22.440
increasing the alpha term
factor from log P to P.

00:02:23.880 --> 00:02:28.170
Now in practice, it's typically very
hard for the block or cyclic schemes to

00:02:28.170 --> 00:02:31.990
actually beat the transposed schemes for
typical values of n over P.

00:02:33.120 --> 00:02:36.740
And that's true even given the much
stronger assumption of a fully connected

00:02:36.740 --> 00:02:38.060
network versus a hypercube.

00:02:39.670 --> 00:02:41.780
Hm, can you think of any
reasons why that might be true?

