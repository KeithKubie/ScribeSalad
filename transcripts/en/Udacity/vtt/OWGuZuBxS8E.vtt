WEBVTT
Kind: captions
Language: en

00:00:00.530 --> 00:00:04.230
So, that's gradient descent. As we mentioned, gradient descent is

00:00:04.230 --> 00:00:08.330
just one machine learning technique and one of the most basic.

00:00:08.330 --> 00:00:10.780
There are a number of sophisticated machine learning algorithms for

00:00:10.780 --> 00:00:14.290
predicting and classifying our data points. And if this is interesting

00:00:14.290 --> 00:00:16.239
to you, I'd really recommend you to go out there

00:00:16.239 --> 00:00:18.690
and read more about machine learning, and really dive into some

00:00:18.690 --> 00:00:23.070
of those algorithms. Let's talk about Assignment 3. In this

00:00:23.070 --> 00:00:25.545
assignment, you'll use methods we learned during this lesson. So the

00:00:25.545 --> 00:00:29.340
t-test and linear regression using gradient descent, to make some conclusions

00:00:29.340 --> 00:00:33.070
and predictions about our data. First you'll use the t-test in

00:00:33.070 --> 00:00:35.620
order to compare various sub sets of our subway data to

00:00:35.620 --> 00:00:39.700
try and make some conclusions about subway ridership. For example, do

00:00:39.700 --> 00:00:43.000
people ride the subway more if it's raining? Or maybe they

00:00:43.000 --> 00:00:46.160
ride more if it's the weekend. Then we'll use linear regression

00:00:46.160 --> 00:00:48.130
to try and build a model that predicts how many total

00:00:48.130 --> 00:00:50.980
riders the New York City subway will have. On a particular

00:00:50.980 --> 00:00:54.700
day and time, given a variety of factors. For example, the time of

00:00:54.700 --> 00:00:58.540
day, whether or not it's a weekday, how the weather is, et cetera.

