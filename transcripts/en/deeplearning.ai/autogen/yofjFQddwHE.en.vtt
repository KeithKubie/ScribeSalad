WEBVTT
Kind: captions
Language: en

00:00:00.359 --> 00:00:02.330
 
one of the most powerful ideas in deep

00:00:02.330 --> 00:00:02.340
one of the most powerful ideas in deep
 

00:00:02.340 --> 00:00:04.309
one of the most powerful ideas in deep
learning is that sometimes we can take

00:00:04.309 --> 00:00:04.319
learning is that sometimes we can take
 

00:00:04.319 --> 00:00:06.230
learning is that sometimes we can take
the knowledge the new network has

00:00:06.230 --> 00:00:06.240
the knowledge the new network has
 

00:00:06.240 --> 00:00:08.600
the knowledge the new network has
learned from one toss and apply that

00:00:08.600 --> 00:00:08.610
learned from one toss and apply that
 

00:00:08.610 --> 00:00:10.910
learned from one toss and apply that
knowledge to a separate task so for

00:00:10.910 --> 00:00:10.920
knowledge to a separate task so for
 

00:00:10.920 --> 00:00:12.379
knowledge to a separate task so for
example maybe kind of a new network

00:00:12.379 --> 00:00:12.389
example maybe kind of a new network
 

00:00:12.389 --> 00:00:15.049
example maybe kind of a new network
learn to recognize objects like cats and

00:00:15.049 --> 00:00:15.059
learn to recognize objects like cats and
 

00:00:15.059 --> 00:00:17.029
learn to recognize objects like cats and
then use that knowledge or use part of

00:00:17.029 --> 00:00:17.039
then use that knowledge or use part of
 

00:00:17.039 --> 00:00:18.890
then use that knowledge or use part of
that knowledge to help you do a better

00:00:18.890 --> 00:00:18.900
that knowledge to help you do a better
 

00:00:18.900 --> 00:00:22.010
that knowledge to help you do a better
job reading x-ray scans this is called

00:00:22.010 --> 00:00:22.020
job reading x-ray scans this is called
 

00:00:22.020 --> 00:00:24.279
job reading x-ray scans this is called
transfer learning let's take a look

00:00:24.279 --> 00:00:24.289
transfer learning let's take a look
 

00:00:24.289 --> 00:00:26.900
transfer learning let's take a look
let's say you've trained in your network

00:00:26.900 --> 00:00:26.910
let's say you've trained in your network
 

00:00:26.910 --> 00:00:31.759
let's say you've trained in your network
on image recognition so you first take a

00:00:31.759 --> 00:00:31.769
on image recognition so you first take a
 

00:00:31.769 --> 00:00:34.190
on image recognition so you first take a
neural network and train it on XY pairs

00:00:34.190 --> 00:00:34.200
neural network and train it on XY pairs
 

00:00:34.200 --> 00:00:37.310
neural network and train it on XY pairs
where X is an image and Y is some object

00:00:37.310 --> 00:00:37.320
where X is an image and Y is some object
 

00:00:37.320 --> 00:00:39.619
where X is an image and Y is some object
in the image as a cat or a dog or bird

00:00:39.619 --> 00:00:39.629
in the image as a cat or a dog or bird
 

00:00:39.629 --> 00:00:42.110
in the image as a cat or a dog or bird
or something else if you want to take

00:00:42.110 --> 00:00:42.120
or something else if you want to take
 

00:00:42.120 --> 00:00:44.389
or something else if you want to take
this new network and a gap or we say

00:00:44.389 --> 00:00:44.399
this new network and a gap or we say
 

00:00:44.399 --> 00:00:46.910
this new network and a gap or we say
transfer what is learn to a different

00:00:46.910 --> 00:00:46.920
transfer what is learn to a different
 

00:00:46.920 --> 00:00:52.160
transfer what is learn to a different
tasks such as radiology diagnosis or

00:00:52.160 --> 00:00:52.170
tasks such as radiology diagnosis or
 

00:00:52.170 --> 00:00:55.130
tasks such as radiology diagnosis or
meaning really reading x-ray scans what

00:00:55.130 --> 00:00:55.140
meaning really reading x-ray scans what
 

00:00:55.140 --> 00:00:57.380
meaning really reading x-ray scans what
you can do is take this loss output

00:00:57.380 --> 00:00:57.390
you can do is take this loss output
 

00:00:57.390 --> 00:00:59.299
you can do is take this loss output
layer of the neural network and just

00:00:59.299 --> 00:00:59.309
layer of the neural network and just
 

00:00:59.309 --> 00:01:01.639
layer of the neural network and just
delete that and delete also the waste

00:01:01.639 --> 00:01:01.649
delete that and delete also the waste
 

00:01:01.649 --> 00:01:04.179
delete that and delete also the waste
feeding into that loss output layer and

00:01:04.179 --> 00:01:04.189
feeding into that loss output layer and
 

00:01:04.189 --> 00:01:07.100
feeding into that loss output layer and
create a new set of randomly initialized

00:01:07.100 --> 00:01:07.110
create a new set of randomly initialized
 

00:01:07.110 --> 00:01:10.399
create a new set of randomly initialized
ways just for the last layer and at that

00:01:10.399 --> 00:01:10.409
ways just for the last layer and at that
 

00:01:10.409 --> 00:01:15.469
ways just for the last layer and at that
now output radiology diagnosis so to be

00:01:15.469 --> 00:01:15.479
now output radiology diagnosis so to be
 

00:01:15.479 --> 00:01:16.969
now output radiology diagnosis so to be
concrete during the first phase of

00:01:16.969 --> 00:01:16.979
concrete during the first phase of
 

00:01:16.979 --> 00:01:18.649
concrete during the first phase of
training when you're trading on an image

00:01:18.649 --> 00:01:18.659
training when you're trading on an image
 

00:01:18.659 --> 00:01:20.990
training when you're trading on an image
recognition task you train all of the

00:01:20.990 --> 00:01:21.000
recognition task you train all of the
 

00:01:21.000 --> 00:01:23.270
recognition task you train all of the
usual parameters within your network all

00:01:23.270 --> 00:01:23.280
usual parameters within your network all
 

00:01:23.280 --> 00:01:26.600
usual parameters within your network all
the ways all the layers and you have

00:01:26.600 --> 00:01:26.610
the ways all the layers and you have
 

00:01:26.610 --> 00:01:29.330
the ways all the layers and you have
something that now learns to make image

00:01:29.330 --> 00:01:29.340
something that now learns to make image
 

00:01:29.340 --> 00:01:33.469
something that now learns to make image
recognition predictions having trained

00:01:33.469 --> 00:01:33.479
recognition predictions having trained
 

00:01:33.479 --> 00:01:36.830
recognition predictions having trained
that neural network what you now do to

00:01:36.830 --> 00:01:36.840
that neural network what you now do to
 

00:01:36.840 --> 00:01:39.469
that neural network what you now do to
implement transfer learning is swap in a

00:01:39.469 --> 00:01:39.479
implement transfer learning is swap in a
 

00:01:39.479 --> 00:01:42.679
implement transfer learning is swap in a
new data set X Y where now these are

00:01:42.679 --> 00:01:42.689
new data set X Y where now these are
 

00:01:42.689 --> 00:01:48.170
new data set X Y where now these are
radiology images and why are the

00:01:48.170 --> 00:01:48.180
radiology images and why are the
 

00:01:48.180 --> 00:01:53.600
radiology images and why are the
diagnosis you want to predict and what

00:01:53.600 --> 00:01:53.610
diagnosis you want to predict and what
 

00:01:53.610 --> 00:01:57.410
diagnosis you want to predict and what
you do is initialize the last layers

00:01:57.410 --> 00:01:57.420
you do is initialize the last layers
 

00:01:57.420 --> 00:02:02.179
you do is initialize the last layers
ways is called a WL + BL random being

00:02:02.179 --> 00:02:02.189
ways is called a WL + BL random being
 

00:02:02.189 --> 00:02:05.539
ways is called a WL + BL random being
and now we train the neural network on

00:02:05.539 --> 00:02:05.549
and now we train the neural network on
 

00:02:05.549 --> 00:02:08.359
and now we train the neural network on
this new data set on the new radiology

00:02:08.359 --> 00:02:08.369
this new data set on the new radiology
 

00:02:08.369 --> 00:02:09.229
this new data set on the new radiology
dataset

00:02:09.229 --> 00:02:09.239
dataset
 

00:02:09.239 --> 00:02:11.330
dataset
we have a couple options of hajji

00:02:11.330 --> 00:02:11.340
we have a couple options of hajji
 

00:02:11.340 --> 00:02:13.280
we have a couple options of hajji
regions in your network with radiology

00:02:13.280 --> 00:02:13.290
regions in your network with radiology
 

00:02:13.290 --> 00:02:15.619
regions in your network with radiology
data you might if you have a small

00:02:15.619 --> 00:02:15.629
data you might if you have a small
 

00:02:15.629 --> 00:02:17.690
data you might if you have a small
radiology data set you might want to

00:02:17.690 --> 00:02:17.700
radiology data set you might want to
 

00:02:17.700 --> 00:02:19.309
radiology data set you might want to
just retrain the weights of the last

00:02:19.309 --> 00:02:19.319
just retrain the weights of the last
 

00:02:19.319 --> 00:02:21.649
just retrain the weights of the last
layer just W LPL and keep the rest of

00:02:21.649 --> 00:02:21.659
layer just W LPL and keep the rest of
 

00:02:21.659 --> 00:02:23.509
layer just W LPL and keep the rest of
parameters fixed if you have an up data

00:02:23.509 --> 00:02:23.519
parameters fixed if you have an up data
 

00:02:23.519 --> 00:02:26.720
parameters fixed if you have an up data
you could also retrain all the layers of

00:02:26.720 --> 00:02:26.730
you could also retrain all the layers of
 

00:02:26.730 --> 00:02:30.140
you could also retrain all the layers of
the rest of the neural network and the

00:02:30.140 --> 00:02:30.150
the rest of the neural network and the
 

00:02:30.150 --> 00:02:31.940
the rest of the neural network and the
rule of thumb is maybe a bit of a small

00:02:31.940 --> 00:02:31.950
rule of thumb is maybe a bit of a small
 

00:02:31.950 --> 00:02:33.949
rule of thumb is maybe a bit of a small
data set then just retrain the one loss

00:02:33.949 --> 00:02:33.959
data set then just retrain the one loss
 

00:02:33.959 --> 00:02:36.020
data set then just retrain the one loss
layer at the output layer or maybe even

00:02:36.020 --> 00:02:36.030
layer at the output layer or maybe even
 

00:02:36.030 --> 00:02:38.270
layer at the output layer or maybe even
lost one or two layers there's a lot of

00:02:38.270 --> 00:02:38.280
lost one or two layers there's a lot of
 

00:02:38.280 --> 00:02:40.970
lost one or two layers there's a lot of
data then maybe you can retrain all the

00:02:40.970 --> 00:02:40.980
data then maybe you can retrain all the
 

00:02:40.980 --> 00:02:42.979
data then maybe you can retrain all the
parameters in the networks and if you

00:02:42.979 --> 00:02:42.989
parameters in the networks and if you
 

00:02:42.989 --> 00:02:45.020
parameters in the networks and if you
retrain all the parameters in your

00:02:45.020 --> 00:02:45.030
retrain all the parameters in your
 

00:02:45.030 --> 00:02:48.349
retrain all the parameters in your
network then this initial phase of

00:02:48.349 --> 00:02:48.359
network then this initial phase of
 

00:02:48.359 --> 00:02:50.500
network then this initial phase of
training on image recognition is

00:02:50.500 --> 00:02:50.510
training on image recognition is
 

00:02:50.510 --> 00:02:54.500
training on image recognition is
sometimes called pre training because

00:02:54.500 --> 00:02:54.510
sometimes called pre training because
 

00:02:54.510 --> 00:02:57.649
sometimes called pre training because
you're using image recognition data to

00:02:57.649 --> 00:02:57.659
you're using image recognition data to
 

00:02:57.659 --> 00:03:00.199
you're using image recognition data to
pre initialize or really pre train the

00:03:00.199 --> 00:03:00.209
pre initialize or really pre train the
 

00:03:00.209 --> 00:03:02.149
pre initialize or really pre train the
weights of the neural network and then

00:03:02.149 --> 00:03:02.159
weights of the neural network and then
 

00:03:02.159 --> 00:03:03.830
weights of the neural network and then
if you are updating all the ways

00:03:03.830 --> 00:03:03.840
if you are updating all the ways
 

00:03:03.840 --> 00:03:06.259
if you are updating all the ways
afterwards and trading on the radiology

00:03:06.259 --> 00:03:06.269
afterwards and trading on the radiology
 

00:03:06.269 --> 00:03:09.039
afterwards and trading on the radiology
data sometimes that's called fine tuning

00:03:09.039 --> 00:03:09.049
data sometimes that's called fine tuning
 

00:03:09.049 --> 00:03:11.330
data sometimes that's called fine tuning
so if you share the words pre training

00:03:11.330 --> 00:03:11.340
so if you share the words pre training
 

00:03:11.340 --> 00:03:14.479
so if you share the words pre training
and fine tuning in a deep learning

00:03:14.479 --> 00:03:14.489
and fine tuning in a deep learning
 

00:03:14.489 --> 00:03:16.580
and fine tuning in a deep learning
context this is what they mean when they

00:03:16.580 --> 00:03:16.590
context this is what they mean when they
 

00:03:16.590 --> 00:03:18.890
context this is what they mean when they
refer to pre training and fine tuning

00:03:18.890 --> 00:03:18.900
refer to pre training and fine tuning
 

00:03:18.900 --> 00:03:20.960
refer to pre training and fine tuning
ways in a transfer learning cost and

00:03:20.960 --> 00:03:20.970
ways in a transfer learning cost and
 

00:03:20.970 --> 00:03:22.699
ways in a transfer learning cost and
what you've done in this example is

00:03:22.699 --> 00:03:22.709
what you've done in this example is
 

00:03:22.709 --> 00:03:25.670
what you've done in this example is
you've taken knowledge learn from image

00:03:25.670 --> 00:03:25.680
you've taken knowledge learn from image
 

00:03:25.680 --> 00:03:27.890
you've taken knowledge learn from image
recognition and applied it or

00:03:27.890 --> 00:03:27.900
recognition and applied it or
 

00:03:27.900 --> 00:03:30.530
recognition and applied it or
transferred it to radiology diagnosis

00:03:30.530 --> 00:03:30.540
transferred it to radiology diagnosis
 

00:03:30.540 --> 00:03:32.899
transferred it to radiology diagnosis
and the reason this can be helpful is

00:03:32.899 --> 00:03:32.909
and the reason this can be helpful is
 

00:03:32.909 --> 00:03:34.849
and the reason this can be helpful is
that a lot of the low-level features

00:03:34.849 --> 00:03:34.859
that a lot of the low-level features
 

00:03:34.859 --> 00:03:37.339
that a lot of the low-level features
such as detecting edges that encourage

00:03:37.339 --> 00:03:37.349
such as detecting edges that encourage
 

00:03:37.349 --> 00:03:40.490
such as detecting edges that encourage
detecting positive objects learning from

00:03:40.490 --> 00:03:40.500
detecting positive objects learning from
 

00:03:40.500 --> 00:03:41.689
detecting positive objects learning from
that from a very enlarged image

00:03:41.689 --> 00:03:41.699
that from a very enlarged image
 

00:03:41.699 --> 00:03:43.759
that from a very enlarged image
recognition data set might help your

00:03:43.759 --> 00:03:43.769
recognition data set might help your
 

00:03:43.769 --> 00:03:45.999
recognition data set might help your
learning algorithm do better in

00:03:45.999 --> 00:03:46.009
learning algorithm do better in
 

00:03:46.009 --> 00:03:48.559
learning algorithm do better in
radiology diagnosis it's just learned a

00:03:48.559 --> 00:03:48.569
radiology diagnosis it's just learned a
 

00:03:48.569 --> 00:03:50.270
radiology diagnosis it's just learned a
lot about the structure and the nature

00:03:50.270 --> 00:03:50.280
lot about the structure and the nature
 

00:03:50.280 --> 00:03:53.479
lot about the structure and the nature
of how images look like and some of that

00:03:53.479 --> 00:03:53.489
of how images look like and some of that
 

00:03:53.489 --> 00:03:57.259
of how images look like and some of that
knowledge will be useful so having learn

00:03:57.259 --> 00:03:57.269
knowledge will be useful so having learn
 

00:03:57.269 --> 00:03:58.999
knowledge will be useful so having learn
to recognize images it might have

00:03:58.999 --> 00:03:59.009
to recognize images it might have
 

00:03:59.009 --> 00:04:01.339
to recognize images it might have
learned enough about you know just what

00:04:01.339 --> 00:04:01.349
learned enough about you know just what
 

00:04:01.349 --> 00:04:03.259
learned enough about you know just what
parts of different images look like that

00:04:03.259 --> 00:04:03.269
parts of different images look like that
 

00:04:03.269 --> 00:04:06.770
parts of different images look like that
that knowledge about lines dots curves

00:04:06.770 --> 00:04:06.780
that knowledge about lines dots curves
 

00:04:06.780 --> 00:04:09.319
that knowledge about lines dots curves
and so on may be small parts of objects

00:04:09.319 --> 00:04:09.329
and so on may be small parts of objects
 

00:04:09.329 --> 00:04:12.020
and so on may be small parts of objects
that knowledge could help your radiology

00:04:12.020 --> 00:04:12.030
that knowledge could help your radiology
 

00:04:12.030 --> 00:04:14.569
that knowledge could help your radiology
diagnosis Network learn a bit faster or

00:04:14.569 --> 00:04:14.579
diagnosis Network learn a bit faster or
 

00:04:14.579 --> 00:04:16.460
diagnosis Network learn a bit faster or
learn what less data here's another

00:04:16.460 --> 00:04:16.470
learn what less data here's another
 

00:04:16.470 --> 00:04:19.039
learn what less data here's another
example let's say that you've trained a

00:04:19.039 --> 00:04:19.049
example let's say that you've trained a
 

00:04:19.049 --> 00:04:20.370
example let's say that you've trained a
speech recognition

00:04:20.370 --> 00:04:20.380
speech recognition
 

00:04:20.380 --> 00:04:23.730
speech recognition
so now X is inputs of audio or your

00:04:23.730 --> 00:04:23.740
so now X is inputs of audio or your
 

00:04:23.740 --> 00:04:27.780
so now X is inputs of audio or your
snippers and Y is some in transcript so

00:04:27.780 --> 00:04:27.790
snippers and Y is some in transcript so
 

00:04:27.790 --> 00:04:29.360
snippers and Y is some in transcript so
you're trained in speech recognition

00:04:29.360 --> 00:04:29.370
you're trained in speech recognition
 

00:04:29.370 --> 00:04:34.410
you're trained in speech recognition
system to output your transcripts and

00:04:34.410 --> 00:04:34.420
system to output your transcripts and
 

00:04:34.420 --> 00:04:36.480
system to output your transcripts and
let's say that you now want to build a

00:04:36.480 --> 00:04:36.490
let's say that you now want to build a
 

00:04:36.490 --> 00:04:44.370
let's say that you now want to build a
waik word or a trigger word detection

00:04:44.370 --> 00:04:44.380
waik word or a trigger word detection
 

00:04:44.380 --> 00:04:47.610
waik word or a trigger word detection
system so recall that they wake whether

00:04:47.610 --> 00:04:47.620
system so recall that they wake whether
 

00:04:47.620 --> 00:04:49.320
system so recall that they wake whether
the trigger words are the words we say

00:04:49.320 --> 00:04:49.330
the trigger words are the words we say
 

00:04:49.330 --> 00:04:51.630
the trigger words are the words we say
in order to wake up speech control

00:04:51.630 --> 00:04:51.640
in order to wake up speech control
 

00:04:51.640 --> 00:04:53.940
in order to wake up speech control
devices in the houses such as saying

00:04:53.940 --> 00:04:53.950
devices in the houses such as saying
 

00:04:53.950 --> 00:04:56.040
devices in the houses such as saying
Alexis and we're going Amazon echo or

00:04:56.040 --> 00:04:56.050
Alexis and we're going Amazon echo or
 

00:04:56.050 --> 00:04:58.680
Alexis and we're going Amazon echo or
okay Google to waken Google device or a

00:04:58.680 --> 00:04:58.690
okay Google to waken Google device or a
 

00:04:58.690 --> 00:05:00.810
okay Google to waken Google device or a
series with an Apple device or saying

00:05:00.810 --> 00:05:00.820
series with an Apple device or saying
 

00:05:00.820 --> 00:05:02.670
series with an Apple device or saying
they hope I do to wake up up my to

00:05:02.670 --> 00:05:02.680
they hope I do to wake up up my to
 

00:05:02.680 --> 00:05:05.460
they hope I do to wake up up my to
device so in order to do this you might

00:05:05.460 --> 00:05:05.470
device so in order to do this you might
 

00:05:05.470 --> 00:05:09.390
device so in order to do this you might
take out the last layer of the neural

00:05:09.390 --> 00:05:09.400
take out the last layer of the neural
 

00:05:09.400 --> 00:05:12.630
take out the last layer of the neural
network again and create a new output

00:05:12.630 --> 00:05:12.640
network again and create a new output
 

00:05:12.640 --> 00:05:14.880
network again and create a new output
note but sometimes another thing you

00:05:14.880 --> 00:05:14.890
note but sometimes another thing you
 

00:05:14.890 --> 00:05:17.430
note but sometimes another thing you
could do is actually create not just a

00:05:17.430 --> 00:05:17.440
could do is actually create not just a
 

00:05:17.440 --> 00:05:20.130
could do is actually create not just a
single new output but actually create

00:05:20.130 --> 00:05:20.140
single new output but actually create
 

00:05:20.140 --> 00:05:22.200
single new output but actually create
several new layers to your neural

00:05:22.200 --> 00:05:22.210
several new layers to your neural
 

00:05:22.210 --> 00:05:25.230
several new layers to your neural
network to try to predict the labels Y

00:05:25.230 --> 00:05:25.240
network to try to predict the labels Y
 

00:05:25.240 --> 00:05:27.380
network to try to predict the labels Y
for your wake word detection problem

00:05:27.380 --> 00:05:27.390
for your wake word detection problem
 

00:05:27.390 --> 00:05:29.610
for your wake word detection problem
then again depending on how much data

00:05:29.610 --> 00:05:29.620
then again depending on how much data
 

00:05:29.620 --> 00:05:32.490
then again depending on how much data
you have you might just retrain the new

00:05:32.490 --> 00:05:32.500
you have you might just retrain the new
 

00:05:32.500 --> 00:05:34.710
you have you might just retrain the new
layers of the network or maybe you could

00:05:34.710 --> 00:05:34.720
layers of the network or maybe you could
 

00:05:34.720 --> 00:05:36.810
layers of the network or maybe you could
be trained you're even more layers of

00:05:36.810 --> 00:05:36.820
be trained you're even more layers of
 

00:05:36.820 --> 00:05:40.020
be trained you're even more layers of
this neural network so when does

00:05:40.020 --> 00:05:40.030
this neural network so when does
 

00:05:40.030 --> 00:05:42.690
this neural network so when does
transfer learning makes sense transfer

00:05:42.690 --> 00:05:42.700
transfer learning makes sense transfer
 

00:05:42.700 --> 00:05:45.180
transfer learning makes sense transfer
learning makes sense when you have a lot

00:05:45.180 --> 00:05:45.190
learning makes sense when you have a lot
 

00:05:45.190 --> 00:05:46.860
learning makes sense when you have a lot
of data for the problem you're

00:05:46.860 --> 00:05:46.870
of data for the problem you're
 

00:05:46.870 --> 00:05:49.560
of data for the problem you're
transferring from and usually relatively

00:05:49.560 --> 00:05:49.570
transferring from and usually relatively
 

00:05:49.570 --> 00:05:51.000
transferring from and usually relatively
less data for the problem you're

00:05:51.000 --> 00:05:51.010
less data for the problem you're
 

00:05:51.010 --> 00:05:53.910
less data for the problem you're
transferring to so for example let's say

00:05:53.910 --> 00:05:53.920
transferring to so for example let's say
 

00:05:53.920 --> 00:05:56.670
transferring to so for example let's say
you have a million examples for your

00:05:56.670 --> 00:05:56.680
you have a million examples for your
 

00:05:56.680 --> 00:05:58.770
you have a million examples for your
image recognition tasks so that's a lot

00:05:58.770 --> 00:05:58.780
image recognition tasks so that's a lot
 

00:05:58.780 --> 00:06:01.170
image recognition tasks so that's a lot
of data to learn a lot of low-level

00:06:01.170 --> 00:06:01.180
of data to learn a lot of low-level
 

00:06:01.180 --> 00:06:03.390
of data to learn a lot of low-level
features or to learn a lot of useful

00:06:03.390 --> 00:06:03.400
features or to learn a lot of useful
 

00:06:03.400 --> 00:06:05.250
features or to learn a lot of useful
features in the earlier layers in your

00:06:05.250 --> 00:06:05.260
features in the earlier layers in your
 

00:06:05.260 --> 00:06:08.220
features in the earlier layers in your
network but for the radiology tasks

00:06:08.220 --> 00:06:08.230
network but for the radiology tasks
 

00:06:08.230 --> 00:06:12.210
network but for the radiology tasks
maybe you have only 100 examples so

00:06:12.210 --> 00:06:12.220
maybe you have only 100 examples so
 

00:06:12.220 --> 00:06:14.400
maybe you have only 100 examples so
you're very low data for the radiology

00:06:14.400 --> 00:06:14.410
you're very low data for the radiology
 

00:06:14.410 --> 00:06:16.560
you're very low data for the radiology
diagnosis problem you have only 100

00:06:16.560 --> 00:06:16.570
diagnosis problem you have only 100
 

00:06:16.570 --> 00:06:19.080
diagnosis problem you have only 100
x-ray scans so lot of knowledge you

00:06:19.080 --> 00:06:19.090
x-ray scans so lot of knowledge you
 

00:06:19.090 --> 00:06:21.440
x-ray scans so lot of knowledge you
learn from image recognition can be

00:06:21.440 --> 00:06:21.450
learn from image recognition can be
 

00:06:21.450 --> 00:06:23.850
learn from image recognition can be
transferred and can really help you get

00:06:23.850 --> 00:06:23.860
transferred and can really help you get
 

00:06:23.860 --> 00:06:26.550
transferred and can really help you get
going with radiology recognition even if

00:06:26.550 --> 00:06:26.560
going with radiology recognition even if
 

00:06:26.560 --> 00:06:28.200
going with radiology recognition even if
you don't have an all the data for

00:06:28.200 --> 00:06:28.210
you don't have an all the data for
 

00:06:28.210 --> 00:06:29.870
you don't have an all the data for
radiology

00:06:29.870 --> 00:06:29.880
radiology
 

00:06:29.880 --> 00:06:31.460
radiology
or speech recognition maybe you've

00:06:31.460 --> 00:06:31.470
or speech recognition maybe you've
 

00:06:31.470 --> 00:06:33.260
or speech recognition maybe you've
trained the speech recognition system on

00:06:33.260 --> 00:06:33.270
trained the speech recognition system on
 

00:06:33.270 --> 00:06:36.050
trained the speech recognition system on
$10,000 of data so you have learned a

00:06:36.050 --> 00:06:36.060
$10,000 of data so you have learned a
 

00:06:36.060 --> 00:06:38.180
$10,000 of data so you have learned a
lot about what human voices sounds like

00:06:38.180 --> 00:06:38.190
lot about what human voices sounds like
 

00:06:38.190 --> 00:06:40.460
lot about what human voices sounds like
from that $10,000 of data which really

00:06:40.460 --> 00:06:40.470
from that $10,000 of data which really
 

00:06:40.470 --> 00:06:42.560
from that $10,000 of data which really
is a lot but for your trigger word

00:06:42.560 --> 00:06:42.570
is a lot but for your trigger word
 

00:06:42.570 --> 00:06:44.750
is a lot but for your trigger word
detection maybe you have only one hour

00:06:44.750 --> 00:06:44.760
detection maybe you have only one hour
 

00:06:44.760 --> 00:06:47.600
detection maybe you have only one hour
of data so that's not raw data to figure

00:06:47.600 --> 00:06:47.610
of data so that's not raw data to figure
 

00:06:47.610 --> 00:06:50.300
of data so that's not raw data to figure
out parameters so in this case a lot of

00:06:50.300 --> 00:06:50.310
out parameters so in this case a lot of
 

00:06:50.310 --> 00:06:52.250
out parameters so in this case a lot of
what you learn about what human voices

00:06:52.250 --> 00:06:52.260
what you learn about what human voices
 

00:06:52.260 --> 00:06:55.280
what you learn about what human voices
sound like what are components of human

00:06:55.280 --> 00:06:55.290
sound like what are components of human
 

00:06:55.290 --> 00:06:57.260
sound like what are components of human
speech and so on that can be really

00:06:57.260 --> 00:06:57.270
speech and so on that can be really
 

00:06:57.270 --> 00:06:59.630
speech and so on that can be really
helpful but building a good wake word

00:06:59.630 --> 00:06:59.640
helpful but building a good wake word
 

00:06:59.640 --> 00:07:01.100
helpful but building a good wake word
detector even though you have a

00:07:01.100 --> 00:07:01.110
detector even though you have a
 

00:07:01.110 --> 00:07:03.680
detector even though you have a
relatively small data center he's a much

00:07:03.680 --> 00:07:03.690
relatively small data center he's a much
 

00:07:03.690 --> 00:07:05.210
relatively small data center he's a much
smaller data set for the weak word

00:07:05.210 --> 00:07:05.220
smaller data set for the weak word
 

00:07:05.220 --> 00:07:09.080
smaller data set for the weak word
detection task so both of these cases

00:07:09.080 --> 00:07:09.090
detection task so both of these cases
 

00:07:09.090 --> 00:07:11.000
detection task so both of these cases
are transferring from a problem with a

00:07:11.000 --> 00:07:11.010
are transferring from a problem with a
 

00:07:11.010 --> 00:07:13.970
are transferring from a problem with a
lot of data to a problem with relatively

00:07:13.970 --> 00:07:13.980
lot of data to a problem with relatively
 

00:07:13.980 --> 00:07:17.540
lot of data to a problem with relatively
little data one case where transfer

00:07:17.540 --> 00:07:17.550
little data one case where transfer
 

00:07:17.550 --> 00:07:21.110
little data one case where transfer
learning would not make sense is if the

00:07:21.110 --> 00:07:21.120
learning would not make sense is if the
 

00:07:21.120 --> 00:07:23.360
learning would not make sense is if the
opposite was true so if you had a

00:07:23.360 --> 00:07:23.370
opposite was true so if you had a
 

00:07:23.370 --> 00:07:26.540
opposite was true so if you had a
hundred images for image recognition and

00:07:26.540 --> 00:07:26.550
hundred images for image recognition and
 

00:07:26.550 --> 00:07:29.060
hundred images for image recognition and
you had a hundred images for radiology

00:07:29.060 --> 00:07:29.070
you had a hundred images for radiology
 

00:07:29.070 --> 00:07:31.520
you had a hundred images for radiology
diagnosis or even you're a thousand

00:07:31.520 --> 00:07:31.530
diagnosis or even you're a thousand
 

00:07:31.530 --> 00:07:33.770
diagnosis or even you're a thousand
images really for radiology diagnosis

00:07:33.770 --> 00:07:33.780
images really for radiology diagnosis
 

00:07:33.780 --> 00:07:36.470
images really for radiology diagnosis
one would think about it is that to do

00:07:36.470 --> 00:07:36.480
one would think about it is that to do
 

00:07:36.480 --> 00:07:38.810
one would think about it is that to do
well on radiology diagnosis assuming

00:07:38.810 --> 00:07:38.820
well on radiology diagnosis assuming
 

00:07:38.820 --> 00:07:40.370
well on radiology diagnosis assuming
what you really want to do well on is

00:07:40.370 --> 00:07:40.380
what you really want to do well on is
 

00:07:40.380 --> 00:07:43.070
what you really want to do well on is
radiology diagnosis having radiology

00:07:43.070 --> 00:07:43.080
radiology diagnosis having radiology
 

00:07:43.080 --> 00:07:45.560
radiology diagnosis having radiology
images is much more valuable than having

00:07:45.560 --> 00:07:45.570
images is much more valuable than having
 

00:07:45.570 --> 00:07:48.050
images is much more valuable than having
cat-and-dog and so on images so each

00:07:48.050 --> 00:07:48.060
cat-and-dog and so on images so each
 

00:07:48.060 --> 00:07:50.930
cat-and-dog and so on images so each
example here is much more valuable than

00:07:50.930 --> 00:07:50.940
example here is much more valuable than
 

00:07:50.940 --> 00:07:52.670
example here is much more valuable than
each example there at least for the

00:07:52.670 --> 00:07:52.680
each example there at least for the
 

00:07:52.680 --> 00:07:54.620
each example there at least for the
purpose of building a good radiology

00:07:54.620 --> 00:07:54.630
purpose of building a good radiology
 

00:07:54.630 --> 00:07:57.470
purpose of building a good radiology
system so if you already have more data

00:07:57.470 --> 00:07:57.480
system so if you already have more data
 

00:07:57.480 --> 00:08:00.290
system so if you already have more data
for radiology is not that likely that

00:08:00.290 --> 00:08:00.300
for radiology is not that likely that
 

00:08:00.300 --> 00:08:03.140
for radiology is not that likely that
having 100 images or your random objects

00:08:03.140 --> 00:08:03.150
having 100 images or your random objects
 

00:08:03.150 --> 00:08:05.120
having 100 images or your random objects
of cats and dogs and calls and so on

00:08:05.120 --> 00:08:05.130
of cats and dogs and calls and so on
 

00:08:05.130 --> 00:08:07.760
of cats and dogs and calls and so on
would be that helpful because the value

00:08:07.760 --> 00:08:07.770
would be that helpful because the value
 

00:08:07.770 --> 00:08:10.400
would be that helpful because the value
of one example of images from your

00:08:10.400 --> 00:08:10.410
of one example of images from your
 

00:08:10.410 --> 00:08:12.110
of one example of images from your
English recognition terms of cats and

00:08:12.110 --> 00:08:12.120
English recognition terms of cats and
 

00:08:12.120 --> 00:08:14.570
English recognition terms of cats and
dogs is just less valuable than one

00:08:14.570 --> 00:08:14.580
dogs is just less valuable than one
 

00:08:14.580 --> 00:08:17.210
dogs is just less valuable than one
example of an x-ray image for the task

00:08:17.210 --> 00:08:17.220
example of an x-ray image for the task
 

00:08:17.220 --> 00:08:20.090
example of an x-ray image for the task
of building a good radiology system so

00:08:20.090 --> 00:08:20.100
of building a good radiology system so
 

00:08:20.100 --> 00:08:21.860
of building a good radiology system so
this would be one example where transfer

00:08:21.860 --> 00:08:21.870
this would be one example where transfer
 

00:08:21.870 --> 00:08:24.170
this would be one example where transfer
learning well it might not hurt but I

00:08:24.170 --> 00:08:24.180
learning well it might not hurt but I
 

00:08:24.180 --> 00:08:25.610
learning well it might not hurt but I
wouldn't expect it to give you any

00:08:25.610 --> 00:08:25.620
wouldn't expect it to give you any
 

00:08:25.620 --> 00:08:28.430
wouldn't expect it to give you any
meaningful gain either and similarly if

00:08:28.430 --> 00:08:28.440
meaningful gain either and similarly if
 

00:08:28.440 --> 00:08:30.350
meaningful gain either and similarly if
you built a speech recognition system on

00:08:30.350 --> 00:08:30.360
you built a speech recognition system on
 

00:08:30.360 --> 00:08:33.170
you built a speech recognition system on
10oz of data and you actually have 10

00:08:33.170 --> 00:08:33.180
10oz of data and you actually have 10
 

00:08:33.180 --> 00:08:35.900
10oz of data and you actually have 10
hours or maybe even more say 50 hours of

00:08:35.900 --> 00:08:35.910
hours or maybe even more say 50 hours of
 

00:08:35.910 --> 00:08:39.079
hours or maybe even more say 50 hours of
data for week word detection you know it

00:08:39.079 --> 00:08:39.089
data for week word detection you know it
 

00:08:39.089 --> 00:08:40.940
data for week word detection you know it
won't merely not hurt maybe it won't

00:08:40.940 --> 00:08:40.950
won't merely not hurt maybe it won't
 

00:08:40.950 --> 00:08:42.920
won't merely not hurt maybe it won't
hurt to include that 10 hours of data to

00:08:42.920 --> 00:08:42.930
hurt to include that 10 hours of data to
 

00:08:42.930 --> 00:08:43.630
hurt to include that 10 hours of data to
do transfer

00:08:43.630 --> 00:08:43.640
do transfer
 

00:08:43.640 --> 00:08:45.579
do transfer
but you just couldn't expect to get a

00:08:45.579 --> 00:08:45.589
but you just couldn't expect to get a
 

00:08:45.589 --> 00:08:46.750
but you just couldn't expect to get a
meaningful game

00:08:46.750 --> 00:08:46.760
meaningful game
 

00:08:46.760 --> 00:08:49.720
meaningful game
so to summarize when does transfer

00:08:49.720 --> 00:08:49.730
so to summarize when does transfer
 

00:08:49.730 --> 00:08:52.030
so to summarize when does transfer
learning make sense if you're trying to

00:08:52.030 --> 00:08:52.040
learning make sense if you're trying to
 

00:08:52.040 --> 00:08:58.930
learning make sense if you're trying to
learn from some task a and transfer some

00:08:58.930 --> 00:08:58.940
learn from some task a and transfer some
 

00:08:58.940 --> 00:09:01.120
learn from some task a and transfer some
of the knowledge to sometimes be then

00:09:01.120 --> 00:09:01.130
of the knowledge to sometimes be then
 

00:09:01.130 --> 00:09:04.480
of the knowledge to sometimes be then
transfer learning make sense when toss a

00:09:04.480 --> 00:09:04.490
transfer learning make sense when toss a
 

00:09:04.490 --> 00:09:09.400
transfer learning make sense when toss a
and B have the same input X in the first

00:09:09.400 --> 00:09:09.410
and B have the same input X in the first
 

00:09:09.410 --> 00:09:12.519
and B have the same input X in the first
example a and B both images as input in

00:09:12.519 --> 00:09:12.529
example a and B both images as input in
 

00:09:12.529 --> 00:09:14.620
example a and B both images as input in
the second example both had audio codes

00:09:14.620 --> 00:09:14.630
the second example both had audio codes
 

00:09:14.630 --> 00:09:18.759
the second example both had audio codes
as input it tends to make sense when you

00:09:18.759 --> 00:09:18.769
as input it tends to make sense when you
 

00:09:18.769 --> 00:09:21.280
as input it tends to make sense when you
have one more data for toss a then toss

00:09:21.280 --> 00:09:21.290
have one more data for toss a then toss
 

00:09:21.290 --> 00:09:24.040
have one more data for toss a then toss
B all this is under the assumption that

00:09:24.040 --> 00:09:24.050
B all this is under the assumption that
 

00:09:24.050 --> 00:09:25.810
B all this is under the assumption that
what you really want to do well on this

00:09:25.810 --> 00:09:25.820
what you really want to do well on this
 

00:09:25.820 --> 00:09:29.740
what you really want to do well on this
toss video and because data for tossed B

00:09:29.740 --> 00:09:29.750
toss video and because data for tossed B
 

00:09:29.750 --> 00:09:33.100
toss video and because data for tossed B
is more valuable for toss B usually you

00:09:33.100 --> 00:09:33.110
is more valuable for toss B usually you
 

00:09:33.110 --> 00:09:35.829
is more valuable for toss B usually you
just need a lot more data for toss a

00:09:35.829 --> 00:09:35.839
just need a lot more data for toss a
 

00:09:35.839 --> 00:09:38.380
just need a lot more data for toss a
because do each example from toss a is

00:09:38.380 --> 00:09:38.390
because do each example from toss a is
 

00:09:38.390 --> 00:09:40.960
because do each example from toss a is
just less valuable photos B in each

00:09:40.960 --> 00:09:40.970
just less valuable photos B in each
 

00:09:40.970 --> 00:09:44.440
just less valuable photos B in each
example for toss B and then finally

00:09:44.440 --> 00:09:44.450
example for toss B and then finally
 

00:09:44.450 --> 00:09:46.090
example for toss B and then finally
transfer learning will tend to make more

00:09:46.090 --> 00:09:46.100
transfer learning will tend to make more
 

00:09:46.100 --> 00:09:48.069
transfer learning will tend to make more
sense if you suspect that low-level

00:09:48.069 --> 00:09:48.079
sense if you suspect that low-level
 

00:09:48.079 --> 00:09:50.680
sense if you suspect that low-level
features from toss a could be helpful

00:09:50.680 --> 00:09:50.690
features from toss a could be helpful
 

00:09:50.690 --> 00:09:53.319
features from toss a could be helpful
for learning times B and in both of the

00:09:53.319 --> 00:09:53.329
for learning times B and in both of the
 

00:09:53.329 --> 00:09:55.150
for learning times B and in both of the
earlier examples maybe learning image

00:09:55.150 --> 00:09:55.160
earlier examples maybe learning image
 

00:09:55.160 --> 00:09:56.889
earlier examples maybe learning image
recognition teaches you a number about

00:09:56.889 --> 00:09:56.899
recognition teaches you a number about
 

00:09:56.899 --> 00:09:59.470
recognition teaches you a number about
images to hover radiology diagnosis and

00:09:59.470 --> 00:09:59.480
images to hover radiology diagnosis and
 

00:09:59.480 --> 00:10:01.180
images to hover radiology diagnosis and
maybe learning speech recognition

00:10:01.180 --> 00:10:01.190
maybe learning speech recognition
 

00:10:01.190 --> 00:10:03.189
maybe learning speech recognition
teaches you about human speech to help

00:10:03.189 --> 00:10:03.199
teaches you about human speech to help
 

00:10:03.199 --> 00:10:04.840
teaches you about human speech to help
you with trigger words on record

00:10:04.840 --> 00:10:04.850
you with trigger words on record
 

00:10:04.850 --> 00:10:07.329
you with trigger words on record
detection so to summarize transfer

00:10:07.329 --> 00:10:07.339
detection so to summarize transfer
 

00:10:07.339 --> 00:10:08.949
detection so to summarize transfer
learning tends to be most useful if

00:10:08.949 --> 00:10:08.959
learning tends to be most useful if
 

00:10:08.959 --> 00:10:11.170
learning tends to be most useful if
you're trying to do well on sometimes be

00:10:11.170 --> 00:10:11.180
you're trying to do well on sometimes be
 

00:10:11.180 --> 00:10:12.819
you're trying to do well on sometimes be
usually a problem where you're

00:10:12.819 --> 00:10:12.829
usually a problem where you're
 

00:10:12.829 --> 00:10:15.630
usually a problem where you're
relatively little data so for example in

00:10:15.630 --> 00:10:15.640
relatively little data so for example in
 

00:10:15.640 --> 00:10:18.220
relatively little data so for example in
radiology you know difficult to get that

00:10:18.220 --> 00:10:18.230
radiology you know difficult to get that
 

00:10:18.230 --> 00:10:19.870
radiology you know difficult to get that
many x-ray scans to build a good

00:10:19.870 --> 00:10:19.880
many x-ray scans to build a good
 

00:10:19.880 --> 00:10:22.329
many x-ray scans to build a good
radiology diagnosis system so in that

00:10:22.329 --> 00:10:22.339
radiology diagnosis system so in that
 

00:10:22.339 --> 00:10:24.430
radiology diagnosis system so in that
case you might find it related by

00:10:24.430 --> 00:10:24.440
case you might find it related by
 

00:10:24.440 --> 00:10:25.960
case you might find it related by
different tasks such as image

00:10:25.960 --> 00:10:25.970
different tasks such as image
 

00:10:25.970 --> 00:10:27.460
different tasks such as image
recognition where you can get maybe

00:10:27.460 --> 00:10:27.470
recognition where you can get maybe
 

00:10:27.470 --> 00:10:29.590
recognition where you can get maybe
million images and learn a lot of

00:10:29.590 --> 00:10:29.600
million images and learn a lot of
 

00:10:29.600 --> 00:10:31.660
million images and learn a lot of
low-level features from that so that you

00:10:31.660 --> 00:10:31.670
low-level features from that so that you
 

00:10:31.670 --> 00:10:34.000
low-level features from that so that you
can then try to do well on toss be on

00:10:34.000 --> 00:10:34.010
can then try to do well on toss be on
 

00:10:34.010 --> 00:10:36.100
can then try to do well on toss be on
your radiology task despite not having

00:10:36.100 --> 00:10:36.110
your radiology task despite not having
 

00:10:36.110 --> 00:10:37.569
your radiology task despite not having
damage data for it

00:10:37.569 --> 00:10:37.579
damage data for it
 

00:10:37.579 --> 00:10:40.300
damage data for it
when transfer learning makes sense it

00:10:40.300 --> 00:10:40.310
when transfer learning makes sense it
 

00:10:40.310 --> 00:10:41.889
when transfer learning makes sense it
does help the performance of your

00:10:41.889 --> 00:10:41.899
does help the performance of your
 

00:10:41.899 --> 00:10:43.810
does help the performance of your
learning algorithms significantly but

00:10:43.810 --> 00:10:43.820
learning algorithms significantly but
 

00:10:43.820 --> 00:10:46.030
learning algorithms significantly but
I've also seen sometimes seen transfer

00:10:46.030 --> 00:10:46.040
I've also seen sometimes seen transfer
 

00:10:46.040 --> 00:10:48.189
I've also seen sometimes seen transfer
learning applied in settings where toss

00:10:48.189 --> 00:10:48.199
learning applied in settings where toss
 

00:10:48.199 --> 00:10:51.400
learning applied in settings where toss
a actually has less data than toss B and

00:10:51.400 --> 00:10:51.410
a actually has less data than toss B and
 

00:10:51.410 --> 00:10:53.680
a actually has less data than toss B and
in those cases you kind of don't expect

00:10:53.680 --> 00:10:53.690
in those cases you kind of don't expect
 

00:10:53.690 --> 00:10:55.180
in those cases you kind of don't expect
to see much of a game

00:10:55.180 --> 00:10:55.190
to see much of a game
 

00:10:55.190 --> 00:10:57.790
to see much of a game
so that's it's a transfer learning where

00:10:57.790 --> 00:10:57.800
so that's it's a transfer learning where
 

00:10:57.800 --> 00:10:59.050
so that's it's a transfer learning where
you learn from one toss and try to

00:10:59.050 --> 00:10:59.060
you learn from one toss and try to
 

00:10:59.060 --> 00:11:01.030
you learn from one toss and try to
transfer to a different task there's

00:11:01.030 --> 00:11:01.040
transfer to a different task there's
 

00:11:01.040 --> 00:11:02.559
transfer to a different task there's
another version of learning from

00:11:02.559 --> 00:11:02.569
another version of learning from
 

00:11:02.569 --> 00:11:04.030
another version of learning from
multiple toss which is called

00:11:04.030 --> 00:11:04.040
multiple toss which is called
 

00:11:04.040 --> 00:11:05.740
multiple toss which is called
multitasking which is when you try to

00:11:05.740 --> 00:11:05.750
multitasking which is when you try to
 

00:11:05.750 --> 00:11:07.600
multitasking which is when you try to
learn from multiple tasks at the same

00:11:07.600 --> 00:11:07.610
learn from multiple tasks at the same
 

00:11:07.610 --> 00:11:09.610
learn from multiple tasks at the same
time rather than learning from one and

00:11:09.610 --> 00:11:09.620
time rather than learning from one and
 

00:11:09.620 --> 00:11:11.860
time rather than learning from one and
then sequentially or after that trying

00:11:11.860 --> 00:11:11.870
then sequentially or after that trying
 

00:11:11.870 --> 00:11:14.679
then sequentially or after that trying
to transfer to a different task so in

00:11:14.679 --> 00:11:14.689
to transfer to a different task so in
 

00:11:14.689 --> 00:11:16.059
to transfer to a different task so in
the next video let's discuss

00:11:16.059 --> 00:11:16.069
the next video let's discuss
 

00:11:16.069 --> 00:11:19.000
the next video let's discuss
multitasking

