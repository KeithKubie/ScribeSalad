WEBVTT
Kind: captions
Language: en

00:00:00.300 --> 00:00:04.620
 
[Music]

00:00:04.620 --> 00:00:04.630
[Music]
 

00:00:04.630 --> 00:00:07.470
[Music]
I think one of the one of the big sort

00:00:07.470 --> 00:00:07.480
I think one of the one of the big sort
 

00:00:07.480 --> 00:00:10.920
I think one of the one of the big sort
of counterintuitive points that that I

00:00:10.920 --> 00:00:10.930
of counterintuitive points that that I
 

00:00:10.930 --> 00:00:13.140
of counterintuitive points that that I
draw in the book the fuzzy in the techie

00:00:13.140 --> 00:00:13.150
draw in the book the fuzzy in the techie
 

00:00:13.150 --> 00:00:15.690
draw in the book the fuzzy in the techie
is this notion that just because you

00:00:15.690 --> 00:00:15.700
is this notion that just because you
 

00:00:15.700 --> 00:00:17.250
is this notion that just because you
have technology skills doesn't

00:00:17.250 --> 00:00:17.260
have technology skills doesn't
 

00:00:17.260 --> 00:00:19.740
have technology skills doesn't
necessarily make you relevant in

00:00:19.740 --> 00:00:19.750
necessarily make you relevant in
 

00:00:19.750 --> 00:00:23.010
necessarily make you relevant in
tomorrow a sort of tech led data infused

00:00:23.010 --> 00:00:23.020
tomorrow a sort of tech led data infused
 

00:00:23.020 --> 00:00:25.830
tomorrow a sort of tech led data infused
economy and you know if you look at the

00:00:25.830 --> 00:00:25.840
economy and you know if you look at the
 

00:00:25.840 --> 00:00:28.350
economy and you know if you look at the
sort of underlies of jobs there are

00:00:28.350 --> 00:00:28.360
sort of underlies of jobs there are
 

00:00:28.360 --> 00:00:30.479
sort of underlies of jobs there are
tasks that are may make up every

00:00:30.479 --> 00:00:30.489
tasks that are may make up every
 

00:00:30.489 --> 00:00:32.639
tasks that are may make up every
different job that we have in each of

00:00:32.639 --> 00:00:32.649
different job that we have in each of
 

00:00:32.649 --> 00:00:34.860
different job that we have in each of
our jobs has some subset of tasks that

00:00:34.860 --> 00:00:34.870
our jobs has some subset of tasks that
 

00:00:34.870 --> 00:00:36.780
our jobs has some subset of tasks that
are wrote that are scripted that are

00:00:36.780 --> 00:00:36.790
are wrote that are scripted that are
 

00:00:36.790 --> 00:00:38.790
are wrote that are scripted that are
highly routine these are things that

00:00:38.790 --> 00:00:38.800
highly routine these are things that
 

00:00:38.800 --> 00:00:40.830
highly routine these are things that
over time we can either program robots

00:00:40.830 --> 00:00:40.840
over time we can either program robots
 

00:00:40.840 --> 00:00:42.570
over time we can either program robots
to do them if they're manual or we can

00:00:42.570 --> 00:00:42.580
to do them if they're manual or we can
 

00:00:42.580 --> 00:00:44.340
to do them if they're manual or we can
program machines to do them through

00:00:44.340 --> 00:00:44.350
program machines to do them through
 

00:00:44.350 --> 00:00:46.800
program machines to do them through
machine learning but there's always a

00:00:46.800 --> 00:00:46.810
machine learning but there's always a
 

00:00:46.810 --> 00:00:49.680
machine learning but there's always a
subset that's sort of more complicated

00:00:49.680 --> 00:00:49.690
subset that's sort of more complicated
 

00:00:49.690 --> 00:00:51.360
subset that's sort of more complicated
or more complex that requires

00:00:51.360 --> 00:00:51.370
or more complex that requires
 

00:00:51.370 --> 00:00:52.680
or more complex that requires
collaboration that requires

00:00:52.680 --> 00:00:52.690
collaboration that requires
 

00:00:52.690 --> 00:00:54.810
collaboration that requires
communication or doing things that are

00:00:54.810 --> 00:00:54.820
communication or doing things that are
 

00:00:54.820 --> 00:00:56.640
communication or doing things that are
on the frontier of what we haven't seen

00:00:56.640 --> 00:00:56.650
on the frontier of what we haven't seen
 

00:00:56.650 --> 00:00:59.040
on the frontier of what we haven't seen
before things that require improvisation

00:00:59.040 --> 00:00:59.050
before things that require improvisation
 

00:00:59.050 --> 00:01:01.650
before things that require improvisation
and those are the very skills those are

00:01:01.650 --> 00:01:01.660
and those are the very skills those are
 

00:01:01.660 --> 00:01:03.569
and those are the very skills those are
sort of the skills that require adaptive

00:01:03.569 --> 00:01:03.579
sort of the skills that require adaptive
 

00:01:03.579 --> 00:01:05.969
sort of the skills that require adaptive
or flexible learning and so I think the

00:01:05.969 --> 00:01:05.979
or flexible learning and so I think the
 

00:01:05.979 --> 00:01:07.410
or flexible learning and so I think the
counterintuitive point is that just

00:01:07.410 --> 00:01:07.420
counterintuitive point is that just
 

00:01:07.420 --> 00:01:09.870
counterintuitive point is that just
because you have rote technical ability

00:01:09.870 --> 00:01:09.880
because you have rote technical ability
 

00:01:09.880 --> 00:01:13.620
because you have rote technical ability
you may actually be more susceptible to

00:01:13.620 --> 00:01:13.630
you may actually be more susceptible to
 

00:01:13.630 --> 00:01:15.959
you may actually be more susceptible to
job automation than somebody that has

00:01:15.959 --> 00:01:15.969
job automation than somebody that has
 

00:01:15.969 --> 00:01:18.779
job automation than somebody that has
flexible thinking skills so it's sort of

00:01:18.779 --> 00:01:18.789
flexible thinking skills so it's sort of
 

00:01:18.789 --> 00:01:20.910
flexible thinking skills so it's sort of
this false dichotomy between having

00:01:20.910 --> 00:01:20.920
this false dichotomy between having
 

00:01:20.920 --> 00:01:22.889
this false dichotomy between having
technical skills being relevant having

00:01:22.889 --> 00:01:22.899
technical skills being relevant having
 

00:01:22.899 --> 00:01:25.139
technical skills being relevant having
soft skills being irrelevant in fact

00:01:25.139 --> 00:01:25.149
soft skills being irrelevant in fact
 

00:01:25.149 --> 00:01:27.870
soft skills being irrelevant in fact
it's more the opposite so I think that

00:01:27.870 --> 00:01:27.880
it's more the opposite so I think that
 

00:01:27.880 --> 00:01:29.129
it's more the opposite so I think that
you know when we think about automation

00:01:29.129 --> 00:01:29.139
you know when we think about automation
 

00:01:29.139 --> 00:01:32.219
you know when we think about automation
it it's necessary that we engage with

00:01:32.219 --> 00:01:32.229
it it's necessary that we engage with
 

00:01:32.229 --> 00:01:34.289
it it's necessary that we engage with
data it's necessary that we learn the

00:01:34.289 --> 00:01:34.299
data it's necessary that we learn the
 

00:01:34.299 --> 00:01:35.940
data it's necessary that we learn the
fundamentals of Technology we learn to

00:01:35.940 --> 00:01:35.950
fundamentals of Technology we learn to
 

00:01:35.950 --> 00:01:37.499
fundamentals of Technology we learn to
code we learn to speak this new language

00:01:37.499 --> 00:01:37.509
code we learn to speak this new language
 

00:01:37.509 --> 00:01:40.020
code we learn to speak this new language
but I think we can't forget as well the

00:01:40.020 --> 00:01:40.030
but I think we can't forget as well the
 

00:01:40.030 --> 00:01:42.419
but I think we can't forget as well the
soft skills that will you know enable us

00:01:42.419 --> 00:01:42.429
soft skills that will you know enable us
 

00:01:42.429 --> 00:01:45.270
soft skills that will you know enable us
to sort of whether the the changing

00:01:45.270 --> 00:01:45.280
to sort of whether the the changing
 

00:01:45.280 --> 00:01:47.699
to sort of whether the the changing
economy as machines continue to take

00:01:47.699 --> 00:01:47.709
economy as machines continue to take
 

00:01:47.709 --> 00:01:49.649
economy as machines continue to take
more and more rote and scripted tasks

00:01:49.649 --> 00:01:49.659
more and more rote and scripted tasks
 

00:01:49.659 --> 00:01:52.080
more and more rote and scripted tasks
away from humans so the progress we've

00:01:52.080 --> 00:01:52.090
away from humans so the progress we've
 

00:01:52.090 --> 00:01:54.149
away from humans so the progress we've
seen recently with things like deep

00:01:54.149 --> 00:01:54.159
seen recently with things like deep
 

00:01:54.159 --> 00:01:57.179
seen recently with things like deep
learning with the deep mind and alphago

00:01:57.179 --> 00:01:57.189
learning with the deep mind and alphago
 

00:01:57.189 --> 00:01:59.699
learning with the deep mind and alphago
and sort of playing the the world

00:01:59.699 --> 00:01:59.709
and sort of playing the the world
 

00:01:59.709 --> 00:02:01.800
and sort of playing the the world
champion and go these are fundamentally

00:02:01.800 --> 00:02:01.810
champion and go these are fundamentally
 

00:02:01.810 --> 00:02:04.499
champion and go these are fundamentally
groundbreaking type endeavors I think

00:02:04.499 --> 00:02:04.509
groundbreaking type endeavors I think
 

00:02:04.509 --> 00:02:06.779
groundbreaking type endeavors I think
the really interesting thing is that the

00:02:06.779 --> 00:02:06.789
the really interesting thing is that the
 

00:02:06.789 --> 00:02:08.460
the really interesting thing is that the
artificial intelligence we talked about

00:02:08.460 --> 00:02:08.470
artificial intelligence we talked about
 

00:02:08.470 --> 00:02:10.380
artificial intelligence we talked about
today still context-dependent

00:02:10.380 --> 00:02:10.390
today still context-dependent
 

00:02:10.390 --> 00:02:12.540
today still context-dependent
it's still dependent on being on a board

00:02:12.540 --> 00:02:12.550
it's still dependent on being on a board
 

00:02:12.550 --> 00:02:14.460
it's still dependent on being on a board
being within the confines of a set of

00:02:14.460 --> 00:02:14.470
being within the confines of a set of
 

00:02:14.470 --> 00:02:16.920
being within the confines of a set of
rules and so if you think about simple

00:02:16.920 --> 00:02:16.930
rules and so if you think about simple
 

00:02:16.930 --> 00:02:17.860
rules and so if you think about simple
tasks those

00:02:17.860 --> 00:02:17.870
tasks those
 

00:02:17.870 --> 00:02:20.470
tasks those
rules-based tasks that may be very easy

00:02:20.470 --> 00:02:20.480
rules-based tasks that may be very easy
 

00:02:20.480 --> 00:02:22.449
rules-based tasks that may be very easy
to automate we've sort of migrated I

00:02:22.449 --> 00:02:22.459
to automate we've sort of migrated I
 

00:02:22.459 --> 00:02:24.460
to automate we've sort of migrated I
think up the up the funnel where we're

00:02:24.460 --> 00:02:24.470
think up the up the funnel where we're
 

00:02:24.470 --> 00:02:26.710
think up the up the funnel where we're
talking about in immensely complicated

00:02:26.710 --> 00:02:26.720
talking about in immensely complicated
 

00:02:26.720 --> 00:02:28.660
talking about in immensely complicated
tasks but I wouldn't necessarily say

00:02:28.660 --> 00:02:28.670
tasks but I wouldn't necessarily say
 

00:02:28.670 --> 00:02:31.509
tasks but I wouldn't necessarily say
that we've transgressed into complexity

00:02:31.509 --> 00:02:31.519
that we've transgressed into complexity
 

00:02:31.519 --> 00:02:33.460
that we've transgressed into complexity
where there's really something that's

00:02:33.460 --> 00:02:33.470
where there's really something that's
 

00:02:33.470 --> 00:02:36.009
where there's really something that's
off the board off you know off the

00:02:36.009 --> 00:02:36.019
off the board off you know off the
 

00:02:36.019 --> 00:02:37.720
off the board off you know off the
chessboard entirely off the go board

00:02:37.720 --> 00:02:37.730
chessboard entirely off the go board
 

00:02:37.730 --> 00:02:39.850
chessboard entirely off the go board
entirely and so I think that when we can

00:02:39.850 --> 00:02:39.860
entirely and so I think that when we can
 

00:02:39.860 --> 00:02:42.670
entirely and so I think that when we can
move to a realm where we're not context

00:02:42.670 --> 00:02:42.680
move to a realm where we're not context
 

00:02:42.680 --> 00:02:44.440
move to a realm where we're not context
dependent to me that's sort of one of

00:02:44.440 --> 00:02:44.450
dependent to me that's sort of one of
 

00:02:44.450 --> 00:02:46.119
dependent to me that's sort of one of
the definitional qualities of when it's

00:02:46.119 --> 00:02:46.129
the definitional qualities of when it's
 

00:02:46.129 --> 00:02:48.580
the definitional qualities of when it's
truly perhaps artificial intelligence

00:02:48.580 --> 00:02:48.590
truly perhaps artificial intelligence
 

00:02:48.590 --> 00:02:51.819
truly perhaps artificial intelligence
and not sort of AI that's largely human

00:02:51.819 --> 00:02:51.829
and not sort of AI that's largely human
 

00:02:51.829 --> 00:02:55.390
and not sort of AI that's largely human
led or human guided so one of the new

00:02:55.390 --> 00:02:55.400
led or human guided so one of the new
 

00:02:55.400 --> 00:02:57.369
led or human guided so one of the new
technologies that is sort of in the

00:02:57.369 --> 00:02:57.379
technologies that is sort of in the
 

00:02:57.379 --> 00:02:59.979
technologies that is sort of in the
daily media today that we focus on a lot

00:02:59.979 --> 00:02:59.989
daily media today that we focus on a lot
 

00:02:59.989 --> 00:03:02.470
daily media today that we focus on a lot
is this prospect of self-driving cars or

00:03:02.470 --> 00:03:02.480
is this prospect of self-driving cars or
 

00:03:02.480 --> 00:03:04.660
is this prospect of self-driving cars or
automated vehicles on the roads and if

00:03:04.660 --> 00:03:04.670
automated vehicles on the roads and if
 

00:03:04.670 --> 00:03:05.800
automated vehicles on the roads and if
you look under the hood of this new

00:03:05.800 --> 00:03:05.810
you look under the hood of this new
 

00:03:05.810 --> 00:03:08.110
you look under the hood of this new
technology we realized that some of the

00:03:08.110 --> 00:03:08.120
technology we realized that some of the
 

00:03:08.120 --> 00:03:09.759
technology we realized that some of the
biggest challenges we're facing are

00:03:09.759 --> 00:03:09.769
biggest challenges we're facing are
 

00:03:09.769 --> 00:03:12.039
biggest challenges we're facing are
those that have to do with mixed use

00:03:12.039 --> 00:03:12.049
those that have to do with mixed use
 

00:03:12.049 --> 00:03:15.399
those that have to do with mixed use
environment so for example when people

00:03:15.399 --> 00:03:15.409
environment so for example when people
 

00:03:15.409 --> 00:03:18.009
environment so for example when people
sort of migrate toward this new form of

00:03:18.009 --> 00:03:18.019
sort of migrate toward this new form of
 

00:03:18.019 --> 00:03:20.110
sort of migrate toward this new form of
vehicle there's not going to be sort of

00:03:20.110 --> 00:03:20.120
vehicle there's not going to be sort of
 

00:03:20.120 --> 00:03:22.390
vehicle there's not going to be sort of
a zero to one change there's going to be

00:03:22.390 --> 00:03:22.400
a zero to one change there's going to be
 

00:03:22.400 --> 00:03:24.069
a zero to one change there's going to be
this mixed environment for a number of

00:03:24.069 --> 00:03:24.079
this mixed environment for a number of
 

00:03:24.079 --> 00:03:25.990
this mixed environment for a number of
years potentially decades where we have

00:03:25.990 --> 00:03:26.000
years potentially decades where we have
 

00:03:26.000 --> 00:03:27.460
years potentially decades where we have
self-driving cars

00:03:27.460 --> 00:03:27.470
self-driving cars
 

00:03:27.470 --> 00:03:30.300
self-driving cars
perhaps partially automated vehicles

00:03:30.300 --> 00:03:30.310
perhaps partially automated vehicles
 

00:03:30.310 --> 00:03:33.699
perhaps partially automated vehicles
included with human led cars and so one

00:03:33.699 --> 00:03:33.709
included with human led cars and so one
 

00:03:33.709 --> 00:03:35.349
included with human led cars and so one
of the biggest challenges is more of an

00:03:35.349 --> 00:03:35.359
of the biggest challenges is more of an
 

00:03:35.359 --> 00:03:37.150
of the biggest challenges is more of an
anthropological challenge or figuring

00:03:37.150 --> 00:03:37.160
anthropological challenge or figuring
 

00:03:37.160 --> 00:03:39.280
anthropological challenge or figuring
out how do we get machines to interface

00:03:39.280 --> 00:03:39.290
out how do we get machines to interface
 

00:03:39.290 --> 00:03:41.409
out how do we get machines to interface
with humans in an effective way so if

00:03:41.409 --> 00:03:41.419
with humans in an effective way so if
 

00:03:41.419 --> 00:03:42.580
with humans in an effective way so if
you actually look at a company like

00:03:42.580 --> 00:03:42.590
you actually look at a company like
 

00:03:42.590 --> 00:03:46.119
you actually look at a company like
Nissan some of the most important roles

00:03:46.119 --> 00:03:46.129
Nissan some of the most important roles
 

00:03:46.129 --> 00:03:48.460
Nissan some of the most important roles
that they're hiring for our PhD

00:03:48.460 --> 00:03:48.470
that they're hiring for our PhD
 

00:03:48.470 --> 00:03:50.439
that they're hiring for our PhD
anthropologists who are doing sort of

00:03:50.439 --> 00:03:50.449
anthropologists who are doing sort of
 

00:03:50.449 --> 00:03:53.470
anthropologists who are doing sort of
ethnographic studies looking at human

00:03:53.470 --> 00:03:53.480
ethnographic studies looking at human
 

00:03:53.480 --> 00:03:56.770
ethnographic studies looking at human
communication by a gesture or by you

00:03:56.770 --> 00:03:56.780
communication by a gesture or by you
 

00:03:56.780 --> 00:03:59.140
communication by a gesture or by you
know raising a nod or giving an eyebrow

00:03:59.140 --> 00:03:59.150
know raising a nod or giving an eyebrow
 

00:03:59.150 --> 00:04:02.140
know raising a nod or giving an eyebrow
wave and these are small things that we

00:04:02.140 --> 00:04:02.150
wave and these are small things that we
 

00:04:02.150 --> 00:04:03.849
wave and these are small things that we
sort of take for granted as implicit

00:04:03.849 --> 00:04:03.859
sort of take for granted as implicit
 

00:04:03.859 --> 00:04:05.740
sort of take for granted as implicit
ways that we communicate as humans but

00:04:05.740 --> 00:04:05.750
ways that we communicate as humans but
 

00:04:05.750 --> 00:04:07.949
ways that we communicate as humans but
if you're trying to transcribe that into

00:04:07.949 --> 00:04:07.959
if you're trying to transcribe that into
 

00:04:07.959 --> 00:04:10.659
if you're trying to transcribe that into
code and sort of teach an engineering

00:04:10.659 --> 00:04:10.669
code and sort of teach an engineering
 

00:04:10.669 --> 00:04:12.849
code and sort of teach an engineering
team how to write the computer code for

00:04:12.849 --> 00:04:12.859
team how to write the computer code for
 

00:04:12.859 --> 00:04:14.949
team how to write the computer code for
that that becomes a very difficult

00:04:14.949 --> 00:04:14.959
that that becomes a very difficult
 

00:04:14.959 --> 00:04:16.420
that that becomes a very difficult
challenge between sort of

00:04:16.420 --> 00:04:16.430
challenge between sort of
 

00:04:16.430 --> 00:04:18.580
challenge between sort of
anthropological research and engineering

00:04:18.580 --> 00:04:18.590
anthropological research and engineering
 

00:04:18.590 --> 00:04:20.890
anthropological research and engineering
and I think that this is a perfect

00:04:20.890 --> 00:04:20.900
and I think that this is a perfect
 

00:04:20.900 --> 00:04:22.300
and I think that this is a perfect
example of how we have to bring together

00:04:22.300 --> 00:04:22.310
example of how we have to bring together
 

00:04:22.310 --> 00:04:24.129
example of how we have to bring together
you know both the fuzzy and the techie

00:04:24.129 --> 00:04:24.139
you know both the fuzzy and the techie
 

00:04:24.139 --> 00:04:25.540
you know both the fuzzy and the techie
to really sort of meet some of the

00:04:25.540 --> 00:04:25.550
to really sort of meet some of the
 

00:04:25.550 --> 00:04:26.680
to really sort of meet some of the
biggest challenges today with

00:04:26.680 --> 00:04:26.690
biggest challenges today with
 

00:04:26.690 --> 00:04:29.830
biggest challenges today with
self-driving cars so I think in 2014 we

00:04:29.830 --> 00:04:29.840
self-driving cars so I think in 2014 we
 

00:04:29.840 --> 00:04:31.060
self-driving cars so I think in 2014 we
were at this

00:04:31.060 --> 00:04:31.070
were at this
 

00:04:31.070 --> 00:04:33.910
were at this
the height of fear where there had been

00:04:33.910 --> 00:04:33.920
the height of fear where there had been
 

00:04:33.920 --> 00:04:35.500
the height of fear where there had been
a study that came out with the Oxford

00:04:35.500 --> 00:04:35.510
a study that came out with the Oxford
 

00:04:35.510 --> 00:04:38.590
a study that came out with the Oxford
Martin Institute that looked at how 47%

00:04:38.590 --> 00:04:38.600
Martin Institute that looked at how 47%
 

00:04:38.600 --> 00:04:40.870
Martin Institute that looked at how 47%
of US jobs were at high risk of machine

00:04:40.870 --> 00:04:40.880
of US jobs were at high risk of machine
 

00:04:40.880 --> 00:04:43.930
of US jobs were at high risk of machine
automation this was also the year where

00:04:43.930 --> 00:04:43.940
automation this was also the year where
 

00:04:43.940 --> 00:04:45.910
automation this was also the year where
you know Martin Ford's rises the robots

00:04:45.910 --> 00:04:45.920
you know Martin Ford's rises the robots
 

00:04:45.920 --> 00:04:48.220
you know Martin Ford's rises the robots
came out and was sort of the pendulum

00:04:48.220 --> 00:04:48.230
came out and was sort of the pendulum
 

00:04:48.230 --> 00:04:50.170
came out and was sort of the pendulum
swung all the way to fear and I think

00:04:50.170 --> 00:04:50.180
swung all the way to fear and I think
 

00:04:50.180 --> 00:04:53.140
swung all the way to fear and I think
taking a step back earlier this year the

00:04:53.140 --> 00:04:53.150
taking a step back earlier this year the
 

00:04:53.150 --> 00:04:54.610
taking a step back earlier this year the
McKinsey Global Institute came out with

00:04:54.610 --> 00:04:54.620
McKinsey Global Institute came out with
 

00:04:54.620 --> 00:04:56.890
McKinsey Global Institute came out with
a study where they looked at 800

00:04:56.890 --> 00:04:56.900
a study where they looked at 800
 

00:04:56.900 --> 00:04:58.750
a study where they looked at 800
occupations and they drilled down into

00:04:58.750 --> 00:04:58.760
occupations and they drilled down into
 

00:04:58.760 --> 00:05:01.030
occupations and they drilled down into
those occupations and they looked at the

00:05:01.030 --> 00:05:01.040
those occupations and they looked at the
 

00:05:01.040 --> 00:05:02.950
those occupations and they looked at the
Constituent tasks that made up of each

00:05:02.950 --> 00:05:02.960
Constituent tasks that made up of each
 

00:05:02.960 --> 00:05:05.260
Constituent tasks that made up of each
of those jobs and they found that around

00:05:05.260 --> 00:05:05.270
of those jobs and they found that around
 

00:05:05.270 --> 00:05:08.020
of those jobs and they found that around
5% of jobs had a hundred percent of

00:05:08.020 --> 00:05:08.030
5% of jobs had a hundred percent of
 

00:05:08.030 --> 00:05:09.790
5% of jobs had a hundred percent of
tasks that were things that could be

00:05:09.790 --> 00:05:09.800
tasks that were things that could be
 

00:05:09.800 --> 00:05:13.300
tasks that were things that could be
automated potentially by machines but

00:05:13.300 --> 00:05:13.310
automated potentially by machines but
 

00:05:13.310 --> 00:05:15.490
automated potentially by machines but
the the more interesting conclusion was

00:05:15.490 --> 00:05:15.500
the the more interesting conclusion was
 

00:05:15.500 --> 00:05:19.270
the the more interesting conclusion was
that for roughly 60 percent of jobs only

00:05:19.270 --> 00:05:19.280
that for roughly 60 percent of jobs only
 

00:05:19.280 --> 00:05:21.520
that for roughly 60 percent of jobs only
30 percent of the tasks within those

00:05:21.520 --> 00:05:21.530
30 percent of the tasks within those
 

00:05:21.530 --> 00:05:23.980
30 percent of the tasks within those
jobs were things that machines could

00:05:23.980 --> 00:05:23.990
jobs were things that machines could
 

00:05:23.990 --> 00:05:26.830
jobs were things that machines could
sort of do over time and so as machines

00:05:26.830 --> 00:05:26.840
sort of do over time and so as machines
 

00:05:26.840 --> 00:05:30.070
sort of do over time and so as machines
take over the rote or the scripted the

00:05:30.070 --> 00:05:30.080
take over the rote or the scripted the
 

00:05:30.080 --> 00:05:32.590
take over the rote or the scripted the
routine aspects of jobs the things that

00:05:32.590 --> 00:05:32.600
routine aspects of jobs the things that
 

00:05:32.600 --> 00:05:34.240
routine aspects of jobs the things that
we've done many times before the things

00:05:34.240 --> 00:05:34.250
we've done many times before the things
 

00:05:34.250 --> 00:05:36.760
we've done many times before the things
for which we have best practices or good

00:05:36.760 --> 00:05:36.770
for which we have best practices or good
 

00:05:36.770 --> 00:05:38.920
for which we have best practices or good
practices things where you may have a

00:05:38.920 --> 00:05:38.930
practices things where you may have a
 

00:05:38.930 --> 00:05:40.240
practices things where you may have a
note on the wall that says do it

00:05:40.240 --> 00:05:40.250
note on the wall that says do it
 

00:05:40.250 --> 00:05:42.430
note on the wall that says do it
explicitly this order of operations

00:05:42.430 --> 00:05:42.440
explicitly this order of operations
 

00:05:42.440 --> 00:05:44.980
explicitly this order of operations
these 10 steps those are the things that

00:05:44.980 --> 00:05:44.990
these 10 steps those are the things that
 

00:05:44.990 --> 00:05:47.380
these 10 steps those are the things that
we can program machines to do in a

00:05:47.380 --> 00:05:47.390
we can program machines to do in a
 

00:05:47.390 --> 00:05:49.840
we can program machines to do in a
fairly easy way over time

00:05:49.840 --> 00:05:49.850
fairly easy way over time
 

00:05:49.850 --> 00:05:52.660
fairly easy way over time
there are obviously questions about the

00:05:52.660 --> 00:05:52.670
there are obviously questions about the
 

00:05:52.670 --> 00:05:55.570
there are obviously questions about the
use of internal teams and dedicating

00:05:55.570 --> 00:05:55.580
use of internal teams and dedicating
 

00:05:55.580 --> 00:05:57.670
use of internal teams and dedicating
resources to optimize certain processes

00:05:57.670 --> 00:05:57.680
resources to optimize certain processes
 

00:05:57.680 --> 00:05:59.650
resources to optimize certain processes
versus others these things aren't all

00:05:59.650 --> 00:05:59.660
versus others these things aren't all
 

00:05:59.660 --> 00:06:01.690
versus others these things aren't all
going to happen overnight I think there

00:06:01.690 --> 00:06:01.700
going to happen overnight I think there
 

00:06:01.700 --> 00:06:03.100
going to happen overnight I think there
are a lot of management questions that

00:06:03.100 --> 00:06:03.110
are a lot of management questions that
 

00:06:03.110 --> 00:06:04.890
are a lot of management questions that
have to do with resource allocation

00:06:04.890 --> 00:06:04.900
have to do with resource allocation
 

00:06:04.900 --> 00:06:08.170
have to do with resource allocation
around some of these issues so technical

00:06:08.170 --> 00:06:08.180
around some of these issues so technical
 

00:06:08.180 --> 00:06:10.270
around some of these issues so technical
feasibility is only the first step of

00:06:10.270 --> 00:06:10.280
feasibility is only the first step of
 

00:06:10.280 --> 00:06:12.190
feasibility is only the first step of
automation I think then there are many

00:06:12.190 --> 00:06:12.200
automation I think then there are many
 

00:06:12.200 --> 00:06:14.650
automation I think then there are many
more steps that we need to consider but

00:06:14.650 --> 00:06:14.660
more steps that we need to consider but
 

00:06:14.660 --> 00:06:16.180
more steps that we need to consider but
I think the interesting conclusion from

00:06:16.180 --> 00:06:16.190
I think the interesting conclusion from
 

00:06:16.190 --> 00:06:18.010
I think the interesting conclusion from
the McKinsey Global Institute is that

00:06:18.010 --> 00:06:18.020
the McKinsey Global Institute is that
 

00:06:18.020 --> 00:06:21.310
the McKinsey Global Institute is that
for these 30% of tasks that may go to

00:06:21.310 --> 00:06:21.320
for these 30% of tasks that may go to
 

00:06:21.320 --> 00:06:23.830
for these 30% of tasks that may go to
machines over time what this does is it

00:06:23.830 --> 00:06:23.840
machines over time what this does is it
 

00:06:23.840 --> 00:06:26.140
machines over time what this does is it
up skills or levels up the human where

00:06:26.140 --> 00:06:26.150
up skills or levels up the human where
 

00:06:26.150 --> 00:06:28.600
up skills or levels up the human where
we now have to focus on the sort of non

00:06:28.600 --> 00:06:28.610
we now have to focus on the sort of non
 

00:06:28.610 --> 00:06:30.850
we now have to focus on the sort of non
routine aspects of our job the complex

00:06:30.850 --> 00:06:30.860
routine aspects of our job the complex
 

00:06:30.860 --> 00:06:33.490
routine aspects of our job the complex
aspects and in this world of complexity

00:06:33.490 --> 00:06:33.500
aspects and in this world of complexity
 

00:06:33.500 --> 00:06:35.650
aspects and in this world of complexity
where you may be good at one thing and

00:06:35.650 --> 00:06:35.660
where you may be good at one thing and
 

00:06:35.660 --> 00:06:37.540
where you may be good at one thing and
I'm good at something else we actually

00:06:37.540 --> 00:06:37.550
I'm good at something else we actually
 

00:06:37.550 --> 00:06:39.430
I'm good at something else we actually
start task trading more we actually

00:06:39.430 --> 00:06:39.440
start task trading more we actually
 

00:06:39.440 --> 00:06:41.680
start task trading more we actually
start working on one thing for one

00:06:41.680 --> 00:06:41.690
start working on one thing for one
 

00:06:41.690 --> 00:06:43.510
start working on one thing for one
person one thing for somebody else and

00:06:43.510 --> 00:06:43.520
person one thing for somebody else and
 

00:06:43.520 --> 00:06:44.560
person one thing for somebody else and
in this environment of

00:06:44.560 --> 00:06:44.570
in this environment of
 

00:06:44.570 --> 00:06:46.810
in this environment of
increasing task trading there's a guy

00:06:46.810 --> 00:06:46.820
increasing task trading there's a guy
 

00:06:46.820 --> 00:06:49.090
increasing task trading there's a guy
named David Deming who is an economist

00:06:49.090 --> 00:06:49.100
named David Deming who is an economist
 

00:06:49.100 --> 00:06:50.440
named David Deming who is an economist
at the Harvard Graduate School of

00:06:50.440 --> 00:06:50.450
at the Harvard Graduate School of
 

00:06:50.450 --> 00:06:52.990
at the Harvard Graduate School of
Education and professor Deming talks

00:06:52.990 --> 00:06:53.000
Education and professor Deming talks
 

00:06:53.000 --> 00:06:55.390
Education and professor Deming talks
about how it's actually the soft skills

00:06:55.390 --> 00:06:55.400
about how it's actually the soft skills
 

00:06:55.400 --> 00:06:58.030
about how it's actually the soft skills
that reduce the friction or reduce the

00:06:58.030 --> 00:06:58.040
that reduce the friction or reduce the
 

00:06:58.040 --> 00:07:00.760
that reduce the friction or reduce the
transaction cost when we trade tasks so

00:07:00.760 --> 00:07:00.770
transaction cost when we trade tasks so
 

00:07:00.770 --> 00:07:03.100
transaction cost when we trade tasks so
in fact when machines are taking over

00:07:03.100 --> 00:07:03.110
in fact when machines are taking over
 

00:07:03.110 --> 00:07:05.410
in fact when machines are taking over
the rote or routine aspects of our jobs

00:07:05.410 --> 00:07:05.420
the rote or routine aspects of our jobs
 

00:07:05.420 --> 00:07:08.110
the rote or routine aspects of our jobs
and humans are left with this 70% of

00:07:08.110 --> 00:07:08.120
and humans are left with this 70% of
 

00:07:08.120 --> 00:07:10.780
and humans are left with this 70% of
complex or non routine tasks it's

00:07:10.780 --> 00:07:10.790
complex or non routine tasks it's
 

00:07:10.790 --> 00:07:12.340
complex or non routine tasks it's
actually the soft skills that start

00:07:12.340 --> 00:07:12.350
actually the soft skills that start
 

00:07:12.350 --> 00:07:15.790
actually the soft skills that start
becoming more and more important

