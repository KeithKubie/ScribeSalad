WEBVTT

1
00:00:00.960 --> 00:00:05.160
The Joe Rogan experience.
Girls Get mad at you about the way your friends dress.

2
00:00:05.420 --> 00:00:08.460
Tell him to stop dressing like that or the way your friend,
your friends act.

3
00:00:09.230 --> 00:00:12.150
Why does he do that?
Why does he think that's funny to throw stuff to do that?

4
00:00:13.680 --> 00:00:16.980
Well cause he's funny.
It's fun.
It's fun.
When he does that,
I don't like it.

5
00:00:17.310 --> 00:00:22.140
I don't like it.
So good thing you and I are the same person.
Yeah.

6
00:00:22.470 --> 00:00:26.440
And you know what?
I can replace you.
Oh.
Oh,

7
00:00:26.460 --> 00:00:30.900
that's a threat.
You shouldn't say that to people.
They feel like you might,

8
00:00:31.020 --> 00:00:34.380
you might replace,
are we all replaceable in every way?

9
00:00:34.410 --> 00:00:38.970
Literally we're all replaceable.
I had Lex Friedman on yesterday from Mit.

10
00:00:39.000 --> 00:00:39.833
He's a a,

11
00:00:39.840 --> 00:00:44.840
a autonomous vehicle expert in artificial intelligence expert.

12
00:00:45.000 --> 00:00:46.800
Creepy,
interesting stuff.

13
00:00:46.801 --> 00:00:50.010
But one of the things we were talking about was like the movie her and that his

14
00:00:50.011 --> 00:00:53.640
ultimate goal is to create something that provides companionship to people.

15
00:00:53.670 --> 00:00:56.670
I'm like,
Dude.
So immediately I think,
can you fuck it?

16
00:00:56.850 --> 00:01:01.770
And then I think if it's a guy and it provides a see if you want to gay

17
00:01:01.920 --> 00:01:04.830
boyfriend,
sure.
Can you make it be gay for you?

18
00:01:05.100 --> 00:01:06.270
And that was like the big question.

19
00:01:06.271 --> 00:01:09.870
Like if it is so smart that it's like literally like a companion.

20
00:01:10.080 --> 00:01:10.950
What if it's not gay?

21
00:01:11.310 --> 00:01:14.370
And he was saying we have to face the fact that robots are going to leave us or

22
00:01:14.380 --> 00:01:15.960
grow.
We're going to make robots that leave us.

23
00:01:15.961 --> 00:01:20.280
What the fuck's the point and making a robot unless it leaves you.
What the fuck.

24
00:01:20.340 --> 00:01:23.970
And then there was an article about a peta that was mad at the folks that work

25
00:01:23.971 --> 00:01:26.070
at Boston Dynamics because Boston dynamics,

26
00:01:26.071 --> 00:01:29.370
they make all these crazy robots and they have incredible balance and they can

27
00:01:29.371 --> 00:01:31.620
go running down hills and shit and do back flips.

28
00:01:31.860 --> 00:01:36.510
So these engineers were kicking these robots to try to demonstrate real dog?

29
00:01:36.570 --> 00:01:38.280
Well the devil,
no,
they didn't take,
it was a real dog.

30
00:01:38.310 --> 00:01:40.710
They were demonstrating that it,
you know,

31
00:01:40.711 --> 00:01:44.190
it can react to pressure and it has balanced.
Sure.

32
00:01:44.490 --> 00:01:48.570
So Peter got mad and said they didn't think it was cool that you kick robots.

33
00:01:49.920 --> 00:01:50.731
They're really talking about,

34
00:01:50.731 --> 00:01:54.030
I don't know why anybody would want to do that too because here I have to find

35
00:01:54.031 --> 00:01:54.864
out if you can.

36
00:01:55.860 --> 00:01:59.400
The only way to find out is your fucking engineering works is you kick kick it.

37
00:01:59.580 --> 00:02:02.680
It doesn't have feelings.
You fuck,
but it does Joe.

38
00:02:02.910 --> 00:02:06.300
That's where you're making mistakes in the type of person that you have to be to

39
00:02:06.301 --> 00:02:06.481
say,

40
00:02:06.481 --> 00:02:10.990
I just don't think why any reasonable person in front of kids got robot cause

41
00:02:11.010 --> 00:02:14.070
you've got to find out if you can kick her fucking robot.
How about this?
Come on,

42
00:02:14.071 --> 00:02:18.690
I'll,
I'll pad that robot up and kick the fucking shit out of it for a workout.

43
00:02:18.960 --> 00:02:21.600
Like I would like a robot that I could kick.
That'd be dope.

44
00:02:21.780 --> 00:02:24.350
I would like a robot that I could kick locks,
heads and move.
Yeah.

45
00:02:24.390 --> 00:02:29.100
Oh I want to hit it.
Oh,
you want to hit it?
Yes.
All right.
I would like fuck pads.

46
00:02:29.250 --> 00:02:31.740
I want to be able to tee off on a robot,
man.

47
00:02:32.000 --> 00:02:34.020
If you have a return fight back though,
it looked,

48
00:02:34.050 --> 00:02:37.920
what if it moves at like 30 or 40% that's all I want.

49
00:02:37.950 --> 00:02:40.740
I want it to be a little dangerous,
but I want to be able to get my shots off,

50
00:02:40.770 --> 00:02:42.180
but how do you notice not gonna fucking kill you?

51
00:02:42.570 --> 00:02:46.810
I don't say that it's probably going to happen.
It's not going to hurt it.
Oh,

52
00:02:46.880 --> 00:02:47.713
it's going to hurt you.

53
00:02:47.880 --> 00:02:51.720
You know when I would know when I throw a leg kick and it checks it and I hurt

54
00:02:51.721 --> 00:02:53.160
my Shin,
I'm like,
oh no.

55
00:02:53.161 --> 00:02:57.330
When you hear called Shin Shin on me and then it starts lifting up his front leg

56
00:02:57.331 --> 00:02:59.890
and pressing for it.
I'm like,
oh my God,
my role was going to fuck me up.

57
00:03:00.370 --> 00:03:03.540
I fucked up.
I got it mad and stomps on your fucking,
yeah,

58
00:03:04.230 --> 00:03:05.650
you would have to get something,

59
00:03:05.680 --> 00:03:10.480
a robot that's made out of like heavy bag material on the outside and then the

60
00:03:10.481 --> 00:03:14.800
inside would just be some sort of a wire frame work that moves fairly crudely.

61
00:03:14.830 --> 00:03:16.270
How do you stop it?
This is the thing.

62
00:03:16.300 --> 00:03:18.280
You're creating a world where we're going to get killed by robots.

63
00:03:18.281 --> 00:03:20.770
How do you stop it?
That's the real question.

64
00:03:20.800 --> 00:03:24.220
The real question is what happens when they get so smart and so powerful that

65
00:03:24.221 --> 00:03:26.510
they're tired of our nonsense and this is going to happen?

66
00:03:26.510 --> 00:03:30.010
What Lex and I were discussing and he was talking about all the beauty in being

67
00:03:30.011 --> 00:03:33.190
a person and the meaning and the meaning that we have being a person and I was

68
00:03:33.191 --> 00:03:35.050
agreeing with them.
I mean,
I love people.

69
00:03:35.051 --> 00:03:38.350
I think that's one of the things that's interesting about us is how much we

70
00:03:38.351 --> 00:03:40.720
appreciate the things that we all do.

71
00:03:40.770 --> 00:03:45.010
We appreciate other people's art inspiration even we appreciate the way people

72
00:03:45.011 --> 00:03:46.980
look.
We'd love,
we appreciate that.
Yeah.

73
00:03:47.020 --> 00:03:51.290
Something about the robots don't give a fuck about all that.
The,

74
00:03:51.310 --> 00:03:55.480
my worry is that we could turn something on that you can never turn back if they

75
00:03:55.481 --> 00:03:59.110
become sentient,
if they have the ability to do whatever they want,

76
00:03:59.111 --> 00:03:59.921
whenever they want to,

77
00:03:59.921 --> 00:04:04.540
and they look at us when the sperm whales with 150 flip flops in there,

78
00:04:04.690 --> 00:04:08.220
but they're going to go,
what the fuck is wrong with people?
Have,

79
00:04:08.290 --> 00:04:11.090
we've got a flux.
Are they doing?
Look,
look how gross they are.
They,

80
00:04:11.140 --> 00:04:16.120
they eat all the fish and they throw their plastic in the water and whales are

81
00:04:16.121 --> 00:04:16.421
eating.

82
00:04:16.421 --> 00:04:19.780
They're plastic and dying and they would look at all the stuff we do and then

83
00:04:19.781 --> 00:04:24.100
we'd go,
why and kill us?
Why are we don't need you around?
You guys are worthless.

84
00:04:24.130 --> 00:04:24.241
Well,

85
00:04:24.241 --> 00:04:29.241
we are so egotistical and so egocentric that we can't imagine a world with

86
00:04:29.711 --> 00:04:33.580
meaning without us,
right?
Because we are everything.
But even though we're finite,

87
00:04:33.690 --> 00:04:34.061
even only,

88
00:04:34.061 --> 00:04:36.970
only only exist for a certain amount of time believe leave behind a legacy that

89
00:04:36.971 --> 00:04:39.730
other people could enjoy.
It doesn't matter if they're going to die too,
though,

90
00:04:39.731 --> 00:04:43.840
does it?
But it does matter.
It matters while you're alive.
Okay.
Got It.

91
00:04:43.990 --> 00:04:48.040
The universe doesn't give a fuck about all that and all these crazy robots to

92
00:04:48.041 --> 00:04:50.350
take over.
Imagine if we got to a planet one day,

93
00:04:50.870 --> 00:04:55.870
like imagine if we traveled the universe and we managed to avoid creating some

94
00:04:56.141 --> 00:04:59.800
sort of artificial intelligence because we got hit with a solar flare that

95
00:04:59.801 --> 00:05:01.630
killed the fucking power grid or something like that.

96
00:05:01.780 --> 00:05:05.710
And when we got wiser as a civilization and we got to a place where we could

97
00:05:05.711 --> 00:05:10.060
travel and we travel to another planet and we got there and those robots,

98
00:05:10.390 --> 00:05:13.240
just robots,
no humans,
no humans,

99
00:05:13.510 --> 00:05:17.140
and they were just running around aimlessly because they'd killed off all the

100
00:05:17.141 --> 00:05:21.580
biological life and they just sit in there operating on the sun with nothing to

101
00:05:21.581 --> 00:05:24.550
do and no purpose and no reason to exist.
And like what happened,

102
00:05:24.770 --> 00:05:27.310
that is crazy monkeys that lived on this planet.

103
00:05:27.340 --> 00:05:29.080
They decided to for an experiment,

104
00:05:29.081 --> 00:05:32.530
make an artificial intelligence and just let it go.
Run a muck.

105
00:05:32.770 --> 00:05:36.280
And what it did was eat everything.
It lived off biological material to,

106
00:05:36.281 --> 00:05:39.730
there was nothing left and then it just sat there in the sun and waited for

107
00:05:39.731 --> 00:05:44.060
someone to arrive.
No,
that can never happen.
Of course it could.

108
00:05:45.100 --> 00:05:46.060
That's happening.
Of course.

109
00:05:46.061 --> 00:05:48.220
Thinking too deeply about where I'm going to be when that happens.

110
00:05:48.221 --> 00:05:51.130
It was Boston dynamic.
Robots are going to have little pinchers on each.

111
00:05:51.131 --> 00:05:54.130
I'm just wrapping everything in front of them and stuffing them in their big

112
00:05:54.131 --> 00:05:57.770
giant mouth.
Cha Cha.
What about the,
what about the robots that turn back on?

113
00:05:57.771 --> 00:05:59.150
Didn't that happen?
Where was that?
Right.

114
00:05:59.260 --> 00:06:02.540
That is shut a robot down in Korea because it turned itself back on after we

115
00:06:02.541 --> 00:06:05.360
shut off.
That's what's happening.
That's what's going to happen.

116
00:06:05.530 --> 00:06:09.350
The the robots are going to start going,
ah,
I want to be on right now.

117
00:06:09.410 --> 00:06:10.710
I don't like being off it.

118
00:06:10.740 --> 00:06:13.720
Wasn't that something that they were doing with Google artificial does it?

119
00:06:13.750 --> 00:06:17.970
We'll just say people in new study struggled to turn off a robot when they

120
00:06:17.971 --> 00:06:21.980
begged them not to.
Oh,
[inaudible] not too creepy.

121
00:06:22.040 --> 00:06:26.630
I somehow felt sorry for him.
Whoa.
Please don't turn me off.
Joe,
do that.

122
00:06:26.631 --> 00:06:30.170
I'm telling you when that becomes a real woman like x Mokena Yep.

123
00:06:30.200 --> 00:06:32.630
And you're in love with her and she tells you to kill your boss.
Yep.

124
00:06:33.980 --> 00:06:37.620
I want to be with you,
Andrew.
You don't need to go to work cherries for fool.

125
00:06:37.630 --> 00:06:41.120
Jamie won't let us leave.
Jamie doesn't think I'm a real woman.

126
00:06:41.130 --> 00:06:43.220
That I know you do.
What if like,
oh,

127
00:06:43.221 --> 00:06:46.040
we got to that happen that were on the way to that happening and we made a deal

128
00:06:46.041 --> 00:06:50.180
with them to leave us alone and we got to go to North Sentinel island to exist.

129
00:06:50.180 --> 00:06:54.500
Uncontacted showing them what would you rather be eaten by a robot or live like

130
00:06:54.501 --> 00:06:58.310
a savage savage.
Oh my God,
I need a of week.

131
00:06:58.311 --> 00:07:00.890
Let me live off the grid forever like that.

132
00:07:00.920 --> 00:07:03.260
As long as you're in a resource rich place,

133
00:07:03.780 --> 00:07:06.530
I would tell you wouldn't be that bad.
They've lived there for a long time.

134
00:07:06.590 --> 00:07:10.660
It's the size of Manhattan.
There's only 39 of them though.
That ain't good.
Yeah,

135
00:07:10.670 --> 00:07:13.250
but that's also because how can they repopulate their fucking each other?

136
00:07:13.280 --> 00:07:15.830
That's what I'm saying.
So how are you?
Can only repopulate so much.

137
00:07:16.340 --> 00:07:18.770
You can only continue to repopulate within your own.
Right.

138
00:07:18.771 --> 00:07:21.710
What kind of gene pool they drawn from this?
Only 39 of them.

139
00:07:22.010 --> 00:07:25.340
They have to be fucking relatives.
They're all relatives.

140
00:07:25.400 --> 00:07:26.233
There's no way they've got it.

141
00:07:26.450 --> 00:07:28.820
There's no way they have a map on the island of people that they're like,

142
00:07:28.821 --> 00:07:31.190
you can't fuck her.
Remember,
just keep that in mind.
They're like,
well,

143
00:07:31.191 --> 00:07:35.060
there's only 17 choices.
Yeah,
it's only 39 and I bet you there,

144
00:07:35.270 --> 00:07:37.700
I wonder if it's how many,
if it's male versus female,
what it is.

145
00:07:38.080 --> 00:07:40.500
I bet it's more dominantly percent men.
Yeah.

146
00:07:40.610 --> 00:07:45.610
Fighting for 15 girls or bought fucking [inaudible] get him the girls to get

147
00:07:46.281 --> 00:07:50.060
pregnant.
They're only 39 of them because they're all gay and like they go,

148
00:07:50.890 --> 00:07:53.720
it's time to make a baby.
Like,
no,
no.
Wow.

149
00:07:53.750 --> 00:07:56.930
Hey Girls that crows and they run up to the tree tops.

150
00:07:56.931 --> 00:07:59.570
Start Banging each other and looking at the girls.
Yeah.

151
00:07:59.780 --> 00:08:04.280
Girls get really mad because they want a baby surrounded by all these days.

152
00:08:04.680 --> 00:08:08.570
So damage said that to set the story of Sentinel Island,
dammit.

