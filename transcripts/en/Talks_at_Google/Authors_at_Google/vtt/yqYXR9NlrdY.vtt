WEBVTT
Kind: captions
Language: en

00:00:00.499 --> 00:00:03.744
[MUSIC PLAYING]

00:00:06.052 --> 00:00:08.010
JORDAN ERICA WEBBER: In
Glenn Greenwald's book,

00:00:08.010 --> 00:00:10.200
"No Place to Hide,
Edward Snowden, the NSA,

00:00:10.200 --> 00:00:12.090
and the Surveillance
State," the journalist

00:00:12.090 --> 00:00:13.770
writes of how
Snowden's morality was

00:00:13.770 --> 00:00:16.650
influenced by his
consumption of video games.

00:00:16.650 --> 00:00:18.860
He was inspired by his
experiences playing

00:00:18.860 --> 00:00:21.510
as characters who were
often ordinary people, who

00:00:21.510 --> 00:00:24.519
became heroes who prevailed
against powerful enemies

00:00:24.519 --> 00:00:26.310
fighting for what they
believed in to right

00:00:26.310 --> 00:00:29.590
the wrongs they
saw in the world.

00:00:29.590 --> 00:00:31.500
Whether or not you
agree with the actions

00:00:31.500 --> 00:00:33.450
that brought Edward
Snowden to infamy,

00:00:33.450 --> 00:00:35.460
the fact that he was
influenced by video games

00:00:35.460 --> 00:00:39.270
is fascinating, but should
perhaps be unsurprising.

00:00:39.270 --> 00:00:42.150
We're used to books and
films that make us think.

00:00:42.150 --> 00:00:44.890
Why not games?

00:00:44.890 --> 00:00:47.710
I'm Jordan Erica Webber, a
video game critic for print,

00:00:47.710 --> 00:00:50.440
radio, and television, and
the co-author of a new pop

00:00:50.440 --> 00:00:52.480
philosophy book called,
"Ten Things Games

00:00:52.480 --> 00:00:57.330
Can Teach Us About Life,
Philosophy, and Everything."

00:00:57.330 --> 00:00:59.100
In this book, my
friend, colleague,

00:00:59.100 --> 00:01:01.650
and fellow philosophy graduate,
Dan Griliopoulos and I

00:01:01.650 --> 00:01:03.420
argue that video
games can help us

00:01:03.420 --> 00:01:06.450
to think about a whole range
of philosophical topics,

00:01:06.450 --> 00:01:09.530
from skepticism to personal
identity, to ethics.

00:01:09.530 --> 00:01:12.030
I'm going to try and give you
a taste of our argument today.

00:01:18.790 --> 00:01:22.300
Here is the requisite definition
of philosophy, a subject that

00:01:22.300 --> 00:01:24.250
helps us to become
rational thinkers,

00:01:24.250 --> 00:01:26.605
and is thus increasingly
important these days.

00:01:30.154 --> 00:01:31.820
And in the interest
of spoiler warnings,

00:01:31.820 --> 00:01:33.860
here is a list of games
I'm going to discuss.

00:01:40.531 --> 00:01:41.030
Sorry.

00:01:41.030 --> 00:01:45.570
[LAUGHS] "Mass Effect
3" tells the story

00:01:45.570 --> 00:01:47.610
of Commander Shepard's
attempt to save

00:01:47.610 --> 00:01:50.580
all sentient life in the
galaxy from annihilation

00:01:50.580 --> 00:01:53.410
by giant synthetic organic
hybrids, called Reapers.

00:01:56.540 --> 00:01:59.540
In one mission, she is tasked
with retrieving Admiral

00:01:59.540 --> 00:02:02.780
Zaal'Korris vas Qwib-Qwib,
a high ranking member

00:02:02.780 --> 00:02:05.360
of the quorian species,
named, as is traditional,

00:02:05.360 --> 00:02:09.380
for his ship, the Qwib-Qwib,
who is needed for the war effort

00:02:09.380 --> 00:02:11.660
that is currently under
attack by the robotic geth,

00:02:11.660 --> 00:02:17.000
which of the blurry beings that
you can see in the background.

00:02:17.000 --> 00:02:19.850
When you get to the former
quorian home world of Rannoch,

00:02:19.850 --> 00:02:22.790
however, and manage to radio
through to Admiral Korris,

00:02:22.790 --> 00:02:25.580
he begs you to rescue
his crew instead.

00:02:25.580 --> 00:02:27.110
They've been separated from him.

00:02:27.110 --> 00:02:28.580
And they're noncombatants.

00:02:28.580 --> 00:02:32.370
They were never supposed to
find themselves fighting geth.

00:02:32.370 --> 00:02:34.980
Stick to your original mission
by convincing Korris to give up

00:02:34.980 --> 00:02:37.050
his location so that
you can rescue him

00:02:37.050 --> 00:02:39.240
and his crew will die.

00:02:39.240 --> 00:02:41.580
Allow Korris to sacrifice
himself for these civilians,

00:02:41.580 --> 00:02:42.250
however.

00:02:42.250 --> 00:02:44.580
And without his leadership,
several quorian ships

00:02:44.580 --> 00:02:46.350
will abandon the
fleet, weakening

00:02:46.350 --> 00:02:48.450
the strength of the forces
taking on the Reapers

00:02:48.450 --> 00:02:51.970
and putting many
more lives at risk.

00:02:51.970 --> 00:02:54.250
Each player's Commander
Shepard is different,

00:02:54.250 --> 00:02:56.410
their appearance,
abilities, personality,

00:02:56.410 --> 00:02:58.670
and choices customized.

00:02:58.670 --> 00:03:01.650
What choice does your
Commander Shepard make and why?

00:03:01.650 --> 00:03:03.186
What is her philosophy?

00:03:08.291 --> 00:03:10.290
The question of whether
it's morally permissible

00:03:10.290 --> 00:03:12.630
to sacrifice the
few to save the many

00:03:12.630 --> 00:03:15.204
is such a popular trope
in all sorts of fiction

00:03:15.204 --> 00:03:16.620
that you've probably
already heard

00:03:16.620 --> 00:03:18.492
of the philosophical
version, which

00:03:18.492 --> 00:03:19.950
asks whether you
would pull a lever

00:03:19.950 --> 00:03:23.070
to divert a runaway train
so that it kills only one

00:03:23.070 --> 00:03:24.900
person instead of five.

00:03:24.900 --> 00:03:26.310
And then it escalates.

00:03:26.310 --> 00:03:29.501
Would you push somebody off
a bridge to stop the train?

00:03:29.501 --> 00:03:31.000
What if that person
was your mother?

00:03:36.017 --> 00:03:38.600
This question, which came to be
known as the "trolley problem"

00:03:38.600 --> 00:03:43.280
first appeared in a 1967 paper
by philosopher Philippa Foot

00:03:43.280 --> 00:03:45.500
in a discussion of abortion.

00:03:45.500 --> 00:03:47.720
Specifically, she was
exploring the doctrine

00:03:47.720 --> 00:03:50.570
of double effect, a principle
by which it's sometimes

00:03:50.570 --> 00:03:54.110
OK to cause harm as a
side effect of doing good,

00:03:54.110 --> 00:03:56.845
but not as a means by which
to bring about that good.

00:03:56.845 --> 00:03:58.220
You've probably
seen this at work

00:03:58.220 --> 00:03:59.870
in comic books
and Marvel movies.

00:04:02.410 --> 00:04:04.810
First, Foot proposed
a hypothetical riot

00:04:04.810 --> 00:04:07.450
that was guaranteed to
have five casualties that

00:04:07.450 --> 00:04:09.490
could be prevented
if a judge framed

00:04:09.490 --> 00:04:12.220
and executed an innocent man.

00:04:12.220 --> 00:04:15.270
And she compared this case to
the runaway train, guaranteed

00:04:15.270 --> 00:04:18.010
to also killed five people
unless the driver switched

00:04:18.010 --> 00:04:21.990
tracks to instead kill just one.

00:04:21.990 --> 00:04:24.360
These scenarios are
mathematically similar,

00:04:24.360 --> 00:04:26.370
both exchanging
one life for five.

00:04:26.370 --> 00:04:28.590
But Foot suggests
that our intuitions

00:04:28.590 --> 00:04:30.990
about the right course of
action differ in each case.

00:04:38.000 --> 00:04:41.050
This kind of presentation of
an imagined scenario in order

00:04:41.050 --> 00:04:43.660
to test intuitions
about the consequences

00:04:43.660 --> 00:04:48.060
is known as a
"thought experiment."

00:04:48.060 --> 00:04:49.786
The "Trolley Problem"
is an example

00:04:49.786 --> 00:04:51.660
that is now often used
to test our intuitions

00:04:51.660 --> 00:04:54.960
about utilitarianism, a
philosophical theory of ethics

00:04:54.960 --> 00:04:57.540
by which the right action
is that which maximizes

00:04:57.540 --> 00:04:59.550
the total utility,
which is often

00:04:59.550 --> 00:05:01.530
substituted with happiness.

00:05:01.530 --> 00:05:04.580
So a utilitarian ought to throw
their mother onto the track,

00:05:04.580 --> 00:05:07.080
because that's a happier event
overall than the loss of five

00:05:07.080 --> 00:05:08.670
other lives.

00:05:08.670 --> 00:05:10.830
But after thinking through
this imagined scenario,

00:05:10.830 --> 00:05:15.564
your intuitions might leave
you feeling otherwise.

00:05:15.564 --> 00:05:17.730
Given the nature of the
subject, thought experiments

00:05:17.730 --> 00:05:19.878
are crucial to the
study of philosophy.

00:05:22.795 --> 00:05:25.420
Someone yesterday told me to put
pictures of puppies or kittens

00:05:25.420 --> 00:05:26.390
in the talk, so--

00:05:26.390 --> 00:05:27.290
[LAUGHTER]

00:05:27.290 --> 00:05:28.638
--hopefully this qualifies.

00:05:31.566 --> 00:05:34.120
Video games also
often present imagined

00:05:34.120 --> 00:05:36.370
scenarios that test the player.

00:05:36.370 --> 00:05:38.650
They can set us up
in immersive worlds

00:05:38.650 --> 00:05:40.710
where certain
conditions are true,

00:05:40.710 --> 00:05:43.210
like a world in which there's
a floating city and people can

00:05:43.210 --> 00:05:46.030
travel between dimensions,
and then either show us

00:05:46.030 --> 00:05:49.360
how the simulation plays out
or allow us to act according

00:05:49.360 --> 00:05:52.650
to our beliefs and goals.

00:05:52.650 --> 00:05:54.630
Here is where video
games have an advantage

00:05:54.630 --> 00:05:58.050
over other thoughtful
media, like books and films.

00:05:58.050 --> 00:05:59.550
They're interactive.

00:05:59.550 --> 00:06:02.940
They have what academics
call the execution element.

00:06:02.940 --> 00:06:04.740
You can execute the experiment.

00:06:12.300 --> 00:06:14.640
In "Heavy Rain," you play
as unfortunate father

00:06:14.640 --> 00:06:18.120
of two, Ethan Mars, who has
lost one son in an accident

00:06:18.120 --> 00:06:19.890
and is now at risk
of losing his seconds

00:06:19.890 --> 00:06:22.020
to a murderous kidnapper.

00:06:22.020 --> 00:06:25.080
This kidnapper subjects
Ethan to a series of tests,

00:06:25.080 --> 00:06:27.570
rewarding him for each
one successfully completed

00:06:27.570 --> 00:06:30.160
with a clue to his
son's location.

00:06:30.160 --> 00:06:35.016
In one test, Ethan is instructed
to cut off his own finger.

00:06:35.016 --> 00:06:37.670
If any of you are
parents, you might

00:06:37.670 --> 00:06:39.980
say that you would be
able to mutilate yourself

00:06:39.980 --> 00:06:41.570
for the sake of your child.

00:06:41.570 --> 00:06:43.220
But in "Heavy
Rain," you actually

00:06:43.220 --> 00:06:45.080
have to press the
series of buttons

00:06:45.080 --> 00:06:47.000
that brings your
chosen tool down

00:06:47.000 --> 00:06:50.060
upon a close up view of
Ethan's little finger

00:06:50.060 --> 00:06:52.400
and keep pressing
until the job is done.

00:06:56.150 --> 00:06:58.340
This execution element
makes more of a difference

00:06:58.340 --> 00:06:59.930
than you might think.

00:06:59.930 --> 00:07:03.110
My co-author, Dan, is
a sworn utilitarian,

00:07:03.110 --> 00:07:05.870
that is, someone who believes
that the right action to take

00:07:05.870 --> 00:07:09.810
is that which maximizes
overall utility or happiness.

00:07:09.810 --> 00:07:12.410
But when he played Pippin Barr's
game version of the "Trolley

00:07:12.410 --> 00:07:15.890
Problem," he was only able to
act according to his philosophy

00:07:15.890 --> 00:07:19.160
until the game asked him to
label the potential sacrifice

00:07:19.160 --> 00:07:21.440
of somebody he loved.

00:07:21.440 --> 00:07:24.020
He chose his infant
daughter and found

00:07:24.020 --> 00:07:25.880
that even though the
stick person on screen

00:07:25.880 --> 00:07:28.970
clearly wasn't her, he
couldn't push the button that

00:07:28.970 --> 00:07:29.990
would switch the tracks.

00:07:38.580 --> 00:07:40.669
Thought experiments are
often used in philosophy

00:07:40.669 --> 00:07:42.210
because the problems
being considered

00:07:42.210 --> 00:07:45.420
couldn't be tested in real
life, whether for practical or

00:07:45.420 --> 00:07:46.165
ethical reasons.

00:07:49.380 --> 00:07:52.766
But immersive video games
feel closer to reality

00:07:52.766 --> 00:07:54.390
than the abstract
discussions you might

00:07:54.390 --> 00:07:56.100
have in a philosophy classroom.

00:07:58.650 --> 00:08:00.600
There's even science
to back this up.

00:08:00.600 --> 00:08:03.136
A team of researches,
led by Indrajeet Patil,

00:08:03.136 --> 00:08:05.010
found that participants
responded differently

00:08:05.010 --> 00:08:08.040
to moral dilemmas, including
the "trolley problem," when

00:08:08.040 --> 00:08:11.040
they were presented in an
interactive simulation as

00:08:11.040 --> 00:08:14.460
opposed to just via text,
perhaps because, as they

00:08:14.460 --> 00:08:16.680
discovered, the
game-type scenarios were

00:08:16.680 --> 00:08:17.880
more emotionally arousing.

00:08:26.487 --> 00:08:28.320
And there's something
so much more impactful

00:08:28.320 --> 00:08:31.050
about watching the consequences
play out on screen, rather

00:08:31.050 --> 00:08:33.179
than in your
imagination, especially

00:08:33.179 --> 00:08:36.070
those that are the direct
result of your actions,

00:08:36.070 --> 00:08:38.220
whether that's seeing a
stick person get run over

00:08:38.220 --> 00:08:41.640
by a runaway train or a
rescued Admiral Korris try

00:08:41.640 --> 00:08:43.860
in vain to contact
his doomed crew.

00:08:53.170 --> 00:08:55.630
Brenda Romero is a
veteran video designer

00:08:55.630 --> 00:08:58.390
who has recently been working
on a series of analog games,

00:08:58.390 --> 00:09:01.150
called "The Mechanic
is the Message."

00:09:01.150 --> 00:09:03.040
She knows that the
way games involve

00:09:03.040 --> 00:09:04.960
the player can make
them feel far more

00:09:04.960 --> 00:09:08.080
complicit than the reader of a
book or the watcher of a film.

00:09:10.730 --> 00:09:14.000
In her analog game, "Train,"
for example, players

00:09:14.000 --> 00:09:15.859
pack little people
into carriages,

00:09:15.859 --> 00:09:17.400
according to the
instructions they're

00:09:17.400 --> 00:09:19.530
given by the deck of cards.

00:09:19.530 --> 00:09:21.560
And they only realize
what exactly they're

00:09:21.560 --> 00:09:25.670
complicit in when they draw one
with a destination, Auschwitz.

00:09:30.900 --> 00:09:33.150
Several well-known
games use twist-like

00:09:33.150 --> 00:09:36.120
reveals to play with the special
relationship between the player

00:09:36.120 --> 00:09:38.114
and the player character.

00:09:38.114 --> 00:09:39.780
And this is another
way that video games

00:09:39.780 --> 00:09:43.480
can be more philosophically
interesting than other media.

00:09:43.480 --> 00:09:45.370
In "Spec Ops, The
Line," for instance,

00:09:45.370 --> 00:09:48.430
you learn at the same time as
your character, Captain Walker,

00:09:48.430 --> 00:09:50.860
that several of his experiences
throughout the game,

00:09:50.860 --> 00:09:55.000
which you've witnessed along
with him, were hallucinations.

00:09:55.000 --> 00:09:56.680
And hallucinations
can play a role

00:09:56.680 --> 00:09:59.235
in the kinds of arguments made
by a philosophical skeptic.

00:10:07.800 --> 00:10:09.475
Always pause for Descartes.

00:10:12.730 --> 00:10:15.610
As the 17th century French
philosopher Rene Descartes

00:10:15.610 --> 00:10:18.580
pointed out, "If we
know that in some cases

00:10:18.580 --> 00:10:20.980
our senses give us
inaccurate information

00:10:20.980 --> 00:10:23.500
about the actual state
of the world, then

00:10:23.500 --> 00:10:25.510
perhaps we can never
know whether or not

00:10:25.510 --> 00:10:28.070
to believe what we see."

00:10:28.070 --> 00:10:29.660
Many of us will never
have experienced

00:10:29.660 --> 00:10:32.120
vivid hallucinations
in real life.

00:10:32.120 --> 00:10:34.490
But the special relationship
between player and player

00:10:34.490 --> 00:10:37.490
character means that a game
like "Spec Ops, The Line"

00:10:37.490 --> 00:10:40.550
helps us to imagine what it
might be like to not be able

00:10:40.550 --> 00:10:43.100
to distinguish between those
experiences that give us

00:10:43.100 --> 00:10:46.432
accurate information about the
world and those that don't.

00:10:46.432 --> 00:10:48.515
It makes the thought
experiment that much clearer.

00:10:53.120 --> 00:10:55.180
Perhaps the most famous
use of that relationship

00:10:55.180 --> 00:10:56.740
between player and
player character

00:10:56.740 --> 00:10:58.570
to trigger
philosophical thought is

00:10:58.570 --> 00:11:01.630
in "BioShock" in which the
player and the protagonist

00:11:01.630 --> 00:11:03.910
Jack both learn partway
through the game

00:11:03.910 --> 00:11:07.060
that his actions have been
predetermined by a character

00:11:07.060 --> 00:11:11.750
called Atlas' use of the trigger
phrase, "would you kindly."

00:11:11.750 --> 00:11:13.430
Controlling Jack
while he carries out

00:11:13.430 --> 00:11:15.740
these subconsciously
delivered instructions

00:11:15.740 --> 00:11:17.900
feels no different from
controlling a character who

00:11:17.900 --> 00:11:20.230
supposedly has free will.

00:11:20.230 --> 00:11:23.450
And we can imagine that
the same is true for us.

00:11:23.450 --> 00:11:25.880
Perhaps we too only
feel like we are

00:11:25.880 --> 00:11:28.160
free to make our own decisions.

00:11:28.160 --> 00:11:29.040
How would we know?

00:11:35.060 --> 00:11:37.270
That's me being determined
to drink a sip of water.

00:11:39.870 --> 00:11:41.580
In "Soma," you play
as a man called

00:11:41.580 --> 00:11:45.305
Simon, who suffers brain damage
from a recent car accident.

00:11:45.305 --> 00:11:46.680
At the beginning
of the game, you

00:11:46.680 --> 00:11:48.240
have to make him
drink tracer fluid

00:11:48.240 --> 00:11:50.670
and travel to a lab for
an experimental brain scan

00:11:50.670 --> 00:11:51.960
procedure.

00:11:51.960 --> 00:11:53.880
It's a first person
game, which means

00:11:53.880 --> 00:11:56.250
that you watch from a
first person perspective,

00:11:56.250 --> 00:11:58.710
as Simon settles into
the researcher's chair,

00:11:58.710 --> 00:12:03.010
closes his eyes, and
reopens them in a research

00:12:03.010 --> 00:12:06.500
base under the sea.

00:12:06.500 --> 00:12:08.360
After a little
exploration, you soon

00:12:08.360 --> 00:12:13.110
discover that more than
100 years have passed

00:12:13.110 --> 00:12:16.280
and the body you are now
controlling is robotic.

00:12:16.280 --> 00:12:19.160
It turns out that the researcher
was copying Simon's brain

00:12:19.160 --> 00:12:21.440
states onto a computer.

00:12:21.440 --> 00:12:23.510
And they've been uploaded
to this robotic body

00:12:23.510 --> 00:12:26.440
under the sea, 100 years later.

00:12:26.440 --> 00:12:31.110
This robot has all of Simon's
memories, beliefs, and desires.

00:12:31.110 --> 00:12:33.230
It thinks like him.

00:12:33.230 --> 00:12:36.080
Just the transition
from researcher's chair

00:12:36.080 --> 00:12:39.510
to underwater base felt seamless
from the player's perspective,

00:12:39.510 --> 00:12:42.800
so too did it seem to
Simon's psychology.

00:12:42.800 --> 00:12:45.110
As far as this
robot is concerned,

00:12:45.110 --> 00:12:47.772
he and the Simon that
suffered the car accident

00:12:47.772 --> 00:12:48.605
are the same person.

00:13:01.820 --> 00:13:03.670
Of course, this makes
a few assumptions

00:13:03.670 --> 00:13:06.160
about the way our
minds think and work.

00:13:06.160 --> 00:13:08.980
You have to accept a particular
view of the philosophy of mind

00:13:08.980 --> 00:13:12.440
in order for this in-game
experience to make sense.

00:13:12.440 --> 00:13:14.680
But that's the point
of thought experiments.

00:13:14.680 --> 00:13:16.750
Creative Director
Thomas Grip wanted

00:13:16.750 --> 00:13:20.890
to test player intuitions about
consciousness and humanity

00:13:20.890 --> 00:13:22.850
and personal identity.

00:13:22.850 --> 00:13:25.810
So he presented a world in
which you can copy and paste

00:13:25.810 --> 00:13:27.700
everything we think
makes a person who

00:13:27.700 --> 00:13:30.370
they are, and then tested
the player's intuitions

00:13:30.370 --> 00:13:31.510
about the consequences.

00:13:35.290 --> 00:13:38.200
One test comes when Simon
needs to be copied over

00:13:38.200 --> 00:13:41.980
to yet another new sturdier body
so that he can travel deeper

00:13:41.980 --> 00:13:44.000
under the sea.

00:13:44.000 --> 00:13:46.730
After you've gone through that
same experience of switching

00:13:46.730 --> 00:13:50.300
perspective from one body to
another, you and this new Simon

00:13:50.300 --> 00:13:53.160
both realize at the
same time that the body

00:13:53.160 --> 00:13:57.106
you were previously controlling
is still awake and still thinks

00:13:57.106 --> 00:13:57.605
it's Simon.

00:14:00.300 --> 00:14:02.520
The new sturdier Simon
you are now controlling,

00:14:02.520 --> 00:14:04.500
which has all of the
same psychological states

00:14:04.500 --> 00:14:07.290
as the previous
one, is distraught.

00:14:07.290 --> 00:14:09.090
Two Simons, he says.

00:14:09.090 --> 00:14:12.002
There can't be two Simons.

00:14:12.002 --> 00:14:13.460
You're even offered
the opportunity

00:14:13.460 --> 00:14:16.250
to drain the old
Simon's battery to solve

00:14:16.250 --> 00:14:17.375
this philosophical problem.

00:14:22.040 --> 00:14:24.470
And yet despite this
warning, some players

00:14:24.470 --> 00:14:27.470
are still shocked at the ending
of the game in which you copy

00:14:27.470 --> 00:14:30.830
and paste Simon's psychology one
last time so that he can escape

00:14:30.830 --> 00:14:34.730
the research base, only to find
that this time, the player's

00:14:34.730 --> 00:14:37.580
perspective is left with
the Simon still stranded

00:14:37.580 --> 00:14:39.260
under the sea.

00:14:39.260 --> 00:14:41.180
The thought experiment
has played out

00:14:41.180 --> 00:14:42.998
to its inevitable conclusion.

00:14:49.840 --> 00:14:52.264
"Soma" is an intentionally
philosophical game.

00:14:52.264 --> 00:14:54.430
And there are others like
it, perhaps most famously,

00:14:54.430 --> 00:14:56.200
"The Talos Principle."

00:14:56.200 --> 00:14:59.590
But we can find philosophy in
other less obvious games too.

00:15:06.940 --> 00:15:09.325
Perhaps it's unfair to the
developers at Nintendo,

00:15:09.325 --> 00:15:11.450
but I doubt they were
thinking about Descartes when

00:15:11.450 --> 00:15:12.491
they made "The Legend of.

00:15:12.491 --> 00:15:14.190
Zelda Spirit Tracks."

00:15:14.190 --> 00:15:17.330
Nevertheless, this game in which
the long suffering Princess

00:15:17.330 --> 00:15:19.730
Zelda's nonphysical
spirit is separated

00:15:19.730 --> 00:15:22.010
from her physical
body supports a theory

00:15:22.010 --> 00:15:25.760
of the philosophy of mind known
as Cartesian dualism, which

00:15:25.760 --> 00:15:27.650
states that the mind
and body are made

00:15:27.650 --> 00:15:29.720
of different kinds
of substances,

00:15:29.720 --> 00:15:34.860
the body physical,
the mind immaterial.

00:15:34.860 --> 00:15:36.810
In fact, any game
that features ghosts

00:15:36.810 --> 00:15:38.640
supports this
philosophical theory,

00:15:38.640 --> 00:15:40.410
whether its creators
intended that or not.

00:15:44.660 --> 00:15:47.360
One of my favorite examples
of presumably unintentional

00:15:47.360 --> 00:15:49.700
philosophy in a video
game is a DS game,

00:15:49.700 --> 00:15:52.460
called "Ghost Trick,
Phantom Detective," which

00:15:52.460 --> 00:15:55.250
has more than you might expect
to say about epistemology,

00:15:55.250 --> 00:15:57.140
otherwise known as the
theory of knowledge.

00:16:04.380 --> 00:16:06.940
In philosophy, the traditional
answer to the question,

00:16:06.940 --> 00:16:11.130
what is knowledge, is that it
is a justified true belief,

00:16:11.130 --> 00:16:13.530
that you know x
when you believe x.

00:16:13.530 --> 00:16:15.300
You are justified
in believing x.

00:16:15.300 --> 00:16:17.697
And x is true.

00:16:17.697 --> 00:16:19.280
Video game developers
and philosophers

00:16:19.280 --> 00:16:22.530
both love the number 3.

00:16:22.530 --> 00:16:25.380
Proposed counter-examples
to this tripartite theory

00:16:25.380 --> 00:16:27.730
of knowledge, which are
called Gettier cases,

00:16:27.730 --> 00:16:30.180
after the American
philosopher Edmund Gettier,

00:16:30.180 --> 00:16:33.480
offer scenarios in which someone
has a justified true belief,

00:16:33.480 --> 00:16:37.730
but we wouldn't want
to call it knowledge.

00:16:37.730 --> 00:16:41.510
In "Ghost Trick," you play
as an amnesiac phantom.

00:16:41.510 --> 00:16:44.330
At the beginning of the
game he spots this corpse.

00:16:44.330 --> 00:16:47.480
And he assumes, because he
can't see any other corpses,

00:16:47.480 --> 00:16:49.200
that it's his.

00:16:49.200 --> 00:16:51.720
Later on, he overhears
somebody who can also

00:16:51.720 --> 00:16:54.480
see the corpse saying
the name, Sissel So he

00:16:54.480 --> 00:16:56.340
infers that that's his name.

00:16:56.340 --> 00:16:58.170
And as it turns
out, that's true.

00:16:58.170 --> 00:17:01.590
The amnesiac ghost is,
in fact, called Sissel.

00:17:01.590 --> 00:17:04.180
So the player character
has a justified true belief

00:17:04.180 --> 00:17:05.970
that his name is Sissel.

00:17:05.970 --> 00:17:09.740
But does he actually
know what his name is?

00:17:09.740 --> 00:17:12.530
As the game progresses you
and Sissel both discover

00:17:12.530 --> 00:17:15.940
that this corpse actually
belongs to a man named Yomiel,

00:17:15.940 --> 00:17:17.630
who was engaged
to somebody called

00:17:17.630 --> 00:17:19.280
Sissel, who killed
herself, which

00:17:19.280 --> 00:17:22.460
is presumably why the other
witness said that name.

00:17:22.460 --> 00:17:24.920
In a twist, the player
character is actually

00:17:24.920 --> 00:17:29.390
the ghost of Yomiel's cat, whom
he named after his dead fiance.

00:17:29.390 --> 00:17:31.040
[CHUCKLING]

00:17:31.040 --> 00:17:34.480
So while Sissel had a justified
true belief about his own name,

00:17:34.480 --> 00:17:37.120
we'd hesitate to
call it knowledge.

00:17:37.120 --> 00:17:40.080
"Ghost Trick, Phantom
Detective" is one big Gettier

00:17:40.080 --> 00:17:41.446
counter-example.

00:17:47.900 --> 00:17:49.910
And finally,
there's "Fallout 4,"

00:17:49.910 --> 00:17:52.190
a huge game in a
hugely popular series

00:17:52.190 --> 00:17:55.820
set in an alternate reality
post-apocalyptic wasteland,

00:17:55.820 --> 00:17:59.180
inhabited by super mutants and,
importantly for my argument,

00:17:59.180 --> 00:18:00.710
artificial beings
that are almost

00:18:00.710 --> 00:18:03.620
indistinguishable from humans.

00:18:03.620 --> 00:18:05.450
One of your biggest
decisions in this game

00:18:05.450 --> 00:18:08.630
is philosophical, as you
choose which of three factions

00:18:08.630 --> 00:18:10.640
to side with,
based on your views

00:18:10.640 --> 00:18:12.710
on whether these
artificial Synths can

00:18:12.710 --> 00:18:13.975
be considered to have minds.

00:18:17.490 --> 00:18:19.656
One faction, The
Railroad, believes

00:18:19.656 --> 00:18:21.030
that the Synths
should be treated

00:18:21.030 --> 00:18:24.489
like people, along with all
the rights that entails.

00:18:24.489 --> 00:18:26.780
They asked you to help the
Synths to gain that freedom.

00:18:30.370 --> 00:18:32.900
The Institutes, which is
kind of like the Google

00:18:32.900 --> 00:18:36.830
of the post-apocalyptic
wasteland, created the Synths.

00:18:36.830 --> 00:18:40.040
They view them as tools that
they can reclaim and reprogram

00:18:40.040 --> 00:18:40.690
with your help.

00:18:43.880 --> 00:18:46.310
And the quasi-religious
Brotherhood of Steel

00:18:46.310 --> 00:18:48.110
believe the Synths
to be abominations

00:18:48.110 --> 00:18:50.090
that should be destroyed.

00:18:50.090 --> 00:18:52.880
One member of this faction
actually is a Synth himself,

00:18:52.880 --> 00:18:54.140
but doesn't know it.

00:18:54.140 --> 00:18:56.840
And if he finds out, he
insists that you execute him.

00:19:04.480 --> 00:19:08.230
"Fallout 4" has many quests and
many choices for the player.

00:19:08.230 --> 00:19:10.750
But you cannot complete the
game without siding with one

00:19:10.750 --> 00:19:12.220
of these factions.

00:19:12.220 --> 00:19:13.720
And whether you
realize it or not at

00:19:13.720 --> 00:19:15.820
the time, that
decision depends on

00:19:15.820 --> 00:19:18.880
philosophical considerations.

00:19:18.880 --> 00:19:21.070
After studying the philosophy
of mind at university,

00:19:21.070 --> 00:19:22.931
I thought myself
a functionalist,

00:19:22.931 --> 00:19:25.180
someone who thinks that
whatever functions like a mind

00:19:25.180 --> 00:19:28.780
is one, even if it doesn't
look anything like a human.

00:19:28.780 --> 00:19:30.700
But in "Fallout
4," I found myself

00:19:30.700 --> 00:19:33.160
siding with The Institute.

00:19:33.160 --> 00:19:35.040
Just as Pippin Barr's
"Trolley Problem"

00:19:35.040 --> 00:19:37.590
challenged my co-author
Dan's philosophy,

00:19:37.590 --> 00:19:39.960
this big-budget action
game challenged mine.

00:19:48.590 --> 00:19:50.360
Video games are many things.

00:19:50.360 --> 00:19:52.870
But perhaps the creator of
the "Civilization" series,

00:19:52.870 --> 00:19:55.270
Sid Meier put it best
when he characterized them

00:19:55.270 --> 00:19:58.540
as "a series of
interesting decisions."

00:19:58.540 --> 00:20:02.850
And I think the most interesting
decisions are philosophical.

00:20:02.850 --> 00:20:04.122
Thank you.

00:20:04.122 --> 00:20:07.419
[APPLAUSE]

00:20:09.242 --> 00:20:10.450
SPEAKER: Thank you very much.

00:20:10.450 --> 00:20:12.820
We do have time for questions.

00:20:12.820 --> 00:20:14.310
I can start with one.

00:20:14.310 --> 00:20:18.690
So I was wondering when
there's so much video games can

00:20:18.690 --> 00:20:19.815
teach us, I don't know if--

00:20:19.815 --> 00:20:20.814
JORDAN ERICA WEBBER: 10.

00:20:20.814 --> 00:20:21.680
There are 10 things.

00:20:21.680 --> 00:20:22.263
SPEAKER: Yeah.

00:20:22.263 --> 00:20:23.030
[LAUGHTER]

00:20:23.030 --> 00:20:24.673
But 10 very deep things.

00:20:24.673 --> 00:20:28.860
So are they subject at schools?

00:20:28.860 --> 00:20:30.150
Or should they be?

00:20:30.150 --> 00:20:32.490
JORDAN ERICA WEBBER:
Video game, I think so.

00:20:32.490 --> 00:20:33.760
I mean, so here's the problem.

00:20:33.760 --> 00:20:36.120
Philosophy isn't really
taught at schools,

00:20:36.120 --> 00:20:37.710
and it definitely should be.

00:20:37.710 --> 00:20:39.120
Like in France, it's compulsory.

00:20:39.120 --> 00:20:40.335
But here, it's not.

00:20:40.335 --> 00:20:42.644
But I have friends
who are campaigning

00:20:42.644 --> 00:20:43.560
to make it compulsory.

00:20:43.560 --> 00:20:45.860
But if it is made
compulsory-- you know,

00:20:45.860 --> 00:20:48.420
we watched "The Matrix"
in my university course.

00:20:48.420 --> 00:20:50.630
I don't see why we
can't play a video game.

00:20:50.630 --> 00:20:51.600
I mean, obviously
there are problems

00:20:51.600 --> 00:20:52.740
with accessibility and stuff.

00:20:52.740 --> 00:20:55.050
It's much easier to sit a bunch
of kids in a room with a movie

00:20:55.050 --> 00:20:57.591
than it is to be, like, we're
all going to play a video game.

00:20:57.591 --> 00:21:00.410
Do you all have a PlayStation 4?

00:21:00.410 --> 00:21:02.040
But if it's
possible, then, yeah.

00:21:02.040 --> 00:21:03.350
I think so.

00:21:03.350 --> 00:21:06.345
I don't see why not.

00:21:06.345 --> 00:21:07.845
AUDIENCE: You say
what distinguishes

00:21:07.845 --> 00:21:09.690
a video game from a
thought experiment

00:21:09.690 --> 00:21:11.370
is that you have this
execution engine.

00:21:11.370 --> 00:21:13.826
But on the other hand, I can
think of a number of times

00:21:13.826 --> 00:21:15.200
where while playing
a video game,

00:21:15.200 --> 00:21:17.158
I did something that's
completely contradictory

00:21:17.158 --> 00:21:19.930
to, like, what I
would do in real life.

00:21:19.930 --> 00:21:21.750
So how do you see
those two things?

00:21:21.750 --> 00:21:23.250
JORDAN ERICA WEBBER:
Right, but when

00:21:23.250 --> 00:21:24.560
you're doing a
thought experiment

00:21:24.560 --> 00:21:26.250
and you're imagining
what you would do,

00:21:26.250 --> 00:21:29.496
it's not necessarily what you
would actually do in real life.

00:21:29.496 --> 00:21:31.620
And you think through all
of the different choices.

00:21:31.620 --> 00:21:33.536
And that's the thing
people do in video games.

00:21:33.536 --> 00:21:34.135
They save.

00:21:34.135 --> 00:21:35.010
And then they reload.

00:21:35.010 --> 00:21:36.510
And they play through
all the different choices

00:21:36.510 --> 00:21:37.710
to see what happens.

00:21:37.710 --> 00:21:39.180
It's not necessarily
that you have

00:21:39.180 --> 00:21:41.700
to make the choice that lines
up with your philosophy,

00:21:41.700 --> 00:21:43.599
but that the fact
of making the choice

00:21:43.599 --> 00:21:46.140
is philosophically interesting
and leads you to kind of think

00:21:46.140 --> 00:21:48.525
about subjects more.

00:21:48.525 --> 00:21:49.515
I think.

00:21:49.515 --> 00:21:53.565
[LAUGHS] I love your scarf.

00:21:55.814 --> 00:21:57.230
AUDIENCE: Many of
the examples you

00:21:57.230 --> 00:21:59.350
gave looked a bit
more modern to my eye.

00:21:59.350 --> 00:21:59.690
JORDAN ERICA WEBBER: Yeah.

00:21:59.690 --> 00:22:01.040
AUDIENCE: I don't know very
much about video games.

00:22:01.040 --> 00:22:02.748
Do you have any examples
in your research

00:22:02.748 --> 00:22:05.345
from what are some of the
earliest examples of philosophy

00:22:05.345 --> 00:22:06.720
that was included
in video games?

00:22:06.720 --> 00:22:09.774
I mean, I came of age in the
Atari 2600 era so that's more--

00:22:09.774 --> 00:22:10.940
JORDAN ERICA WEBBER: No way.

00:22:10.940 --> 00:22:12.689
There's no way you're
old enough for that.

00:22:12.689 --> 00:22:13.705
[LAUGHTER]

00:22:13.705 --> 00:22:14.580
AUDIENCE: No comment.

00:22:14.580 --> 00:22:17.749
JORDAN ERICA WEBBER: [LAUGHS]
So my co-author Dan--

00:22:17.749 --> 00:22:19.790
and he'll kill me for
saying this-- he's actually

00:22:19.790 --> 00:22:21.210
10 years older than me.

00:22:21.210 --> 00:22:24.860
So a lot of his games, which are
in the latter half of the book,

00:22:24.860 --> 00:22:26.115
are older.

00:22:26.115 --> 00:22:28.490
There's a lot of-- because
obviously, games are different

00:22:28.490 --> 00:22:29.781
now than they were then, right?

00:22:29.781 --> 00:22:32.540
So there's a lot of like
text-based RPG and stuff

00:22:32.540 --> 00:22:34.234
where people got
quite into philosophy

00:22:34.234 --> 00:22:36.650
because it's basically like
an interactive science fiction

00:22:36.650 --> 00:22:38.570
novel.

00:22:38.570 --> 00:22:39.830
Can I-- I don't if this is--

00:22:39.830 --> 00:22:41.244
I mean, it's mine.

00:22:41.244 --> 00:22:43.664
[LAUGHTER]

00:22:43.664 --> 00:22:46.100
The guy who wrote
the foreword, we

00:22:46.100 --> 00:22:48.270
got Chris Avellone
to write the forward.

00:22:48.270 --> 00:22:49.770
I don't know if
you've heard of him.

00:22:49.770 --> 00:22:52.252
But he wrote like a
lot of the old RPGs.

00:22:52.252 --> 00:22:54.710
And some of the stuff he worked
on is pretty philosophical.

00:22:54.710 --> 00:22:57.180
I can't think of any names
off the top of my head.

00:22:57.180 --> 00:22:59.650
But there is a handy index.

00:22:59.650 --> 00:23:03.170
If you look in your copy of "Ten
Things Video Games Can Teach

00:23:03.170 --> 00:23:06.590
Us," we, painstaking
process, we went through

00:23:06.590 --> 00:23:08.897
and listed all of the
games that are mentioned.

00:23:08.897 --> 00:23:10.730
So if you look at the
index and you're like,

00:23:10.730 --> 00:23:11.900
oh, that game takes my fancy.

00:23:11.900 --> 00:23:13.250
I wonder what's
philosophical about that?

00:23:13.250 --> 00:23:15.560
You can just go to the
right page and find out.

00:23:15.560 --> 00:23:17.300
But, yeah, I'm quite young.

00:23:17.300 --> 00:23:19.620
So all of mine are quite modern.

00:23:19.620 --> 00:23:20.120
Sorry.

00:23:24.000 --> 00:23:24.720
AUDIENCE: Hi.

00:23:24.720 --> 00:23:27.730
Which game affected you
the most while playing.

00:23:27.730 --> 00:23:32.260
JORDAN ERICA WEBBER: Oh, so
while playing it, "Soma,"

00:23:32.260 --> 00:23:33.200
the one that I--

00:23:33.200 --> 00:23:36.010
the underwater one,
because that was just--

00:23:36.010 --> 00:23:38.500
I mean, because I thought it
was just like a generic horror

00:23:38.500 --> 00:23:38.770
game.

00:23:38.770 --> 00:23:40.228
And I hated it when
I first started

00:23:40.228 --> 00:23:42.700
playing it because there's
all these monsters in it.

00:23:42.700 --> 00:23:44.980
But as I played it, I
was like, oh, right.

00:23:44.980 --> 00:23:47.110
This is very intentionally
philosophical.

00:23:47.110 --> 00:23:49.840
And each choice that you make
in it is a philosophical choice,

00:23:49.840 --> 00:23:52.080
like very intentionally so.

00:23:52.080 --> 00:23:54.070
"Fallout 4" was the
one that afterwards, I

00:23:54.070 --> 00:23:56.272
was like, wait, hold on.

00:23:56.272 --> 00:23:56.980
What have I done?

00:23:56.980 --> 00:24:00.160
When I was thinking about
it was the one that I guess,

00:24:00.160 --> 00:24:01.534
yeah, affected me in hindsight.

00:24:01.534 --> 00:24:03.450
But "Soma" was the one
while I was playing it,

00:24:03.450 --> 00:24:05.575
and that's the one we always
recommend people play.

00:24:07.920 --> 00:24:09.022
Oh, we're going to--

00:24:12.382 --> 00:24:14.090
AUDIENCE: Obviously,
with a lot of games,

00:24:14.090 --> 00:24:16.430
there's a kind of a limited
set of choices you can make.

00:24:16.430 --> 00:24:17.120
JORDAN ERICA WEBBER: Yeah.

00:24:17.120 --> 00:24:19.411
AUDIENCE: Obviously, it's
just a restriction of gaming.

00:24:19.411 --> 00:24:21.990
But do you think that matters
that you could often only get,

00:24:21.990 --> 00:24:23.166
say, two choices?

00:24:23.166 --> 00:24:25.290
JORDAN ERICA WEBBER: No,
I think it's a good thing.

00:24:25.290 --> 00:24:28.370
So the thing about thought
experiments in a classroom

00:24:28.370 --> 00:24:33.960
is that philosophers are
contradictory people.

00:24:33.960 --> 00:24:35.710
When you get a load
of philosophy students

00:24:35.710 --> 00:24:36.720
in a classroom and
you say, here's

00:24:36.720 --> 00:24:38.840
the thought experiment,
choice A or choice B?

00:24:38.840 --> 00:24:40.714
They will always try to
go for choice C. It's

00:24:40.714 --> 00:24:43.580
like some Batman kind of thing.

00:24:43.580 --> 00:24:45.860
But with a video game,
it's programmed, right?

00:24:45.860 --> 00:24:48.190
Like unless you are very
smart and you can mod it,

00:24:48.190 --> 00:24:49.822
you can only make
choice A or choice

00:24:49.822 --> 00:24:51.280
B. There's nothing
else you can do.

00:24:51.280 --> 00:24:52.690
The game won't let you.

00:24:52.690 --> 00:24:54.550
So I think restrictions
are a good thing.

00:24:54.550 --> 00:24:56.830
But obviously, if
you want to explore

00:24:56.830 --> 00:25:00.009
more open kind of stuff,
then, yeah, games like that

00:25:00.009 --> 00:25:00.800
are harder to make.

00:25:00.800 --> 00:25:01.801
But they do exist.

00:25:01.801 --> 00:25:03.550
People are trying to
make more open games.

00:25:03.550 --> 00:25:06.370
And a lot of the older ones,
you know, the text-based stuff,

00:25:06.370 --> 00:25:08.290
there's a lot more
choice in those ones,

00:25:08.290 --> 00:25:09.531
because it's cheaper.

00:25:09.531 --> 00:25:11.756
[LAUGHS]

00:25:11.756 --> 00:25:12.297
AUDIENCE: Hi.

00:25:12.297 --> 00:25:12.760
JORDAN ERICA WEBBER: Hi.

00:25:12.760 --> 00:25:13.760
AUDIENCE: Two questions.

00:25:13.760 --> 00:25:15.940
First of all,
what's the obsession

00:25:15.940 --> 00:25:17.935
of philosophers with trains?

00:25:17.935 --> 00:25:18.434
[LAUGHTER]

00:25:18.434 --> 00:25:19.240
JORDAN ERICA WEBBER: Yeah.

00:25:19.240 --> 00:25:20.480
AUDIENCE: That's a
rather silly question.

00:25:20.480 --> 00:25:21.730
JORDAN ERICA WEBBER:
And same kind of people

00:25:21.730 --> 00:25:22.852
maybe, who played with.

00:25:22.852 --> 00:25:25.060
I played with a lot of train
sets when I was a child.

00:25:25.060 --> 00:25:25.240
So--

00:25:25.240 --> 00:25:25.630
AUDIENCE: Who
doesn't love trains?

00:25:25.630 --> 00:25:26.080
JORDAN ERICA WEBBER:
--that's probably

00:25:26.080 --> 00:25:27.310
why I've ended up
being a philosopher who

00:25:27.310 --> 00:25:28.720
plays a lot of video games.

00:25:28.720 --> 00:25:30.800
AUDIENCE: The more
serious question,

00:25:30.800 --> 00:25:34.660
seems that video games and
these philosophic questions

00:25:34.660 --> 00:25:38.770
are a great way of gathering
statistical data on how people

00:25:38.770 --> 00:25:42.970
react and how comfortable people
are to each and every choice

00:25:42.970 --> 00:25:44.140
they make.

00:25:44.140 --> 00:25:47.410
Is there any sort of
study, statistical study

00:25:47.410 --> 00:25:50.664
on this, and probably,
to take a look

00:25:50.664 --> 00:25:52.330
at how people from
different backgrounds

00:25:52.330 --> 00:25:54.690
react differently
to different choices

00:25:54.690 --> 00:25:56.380
or how comfortable
they are with them?

00:25:56.380 --> 00:25:57.610
JORDAN ERICA WEBBER: That
would be fascinating.

00:25:57.610 --> 00:25:59.860
Hopefully, a load of
psychologists who read my book

00:25:59.860 --> 00:26:01.330
will start doing
that kind of work.

00:26:01.330 --> 00:26:04.367
There is "The
Walking Dead" games.

00:26:04.367 --> 00:26:06.700
Like, they measure all of the
choices that players make.

00:26:06.700 --> 00:26:09.880
So they can tell you what the
end of the game, 97% of players

00:26:09.880 --> 00:26:10.390
did this.

00:26:10.390 --> 00:26:12.590
Why did you do this one?

00:26:12.590 --> 00:26:14.490
What's wrong with you?

00:26:14.490 --> 00:26:17.019
But they don't-- I don't think
they've really looked into it

00:26:17.019 --> 00:26:19.060
any more deeply than just
giving you the numbers.

00:26:19.060 --> 00:26:21.020
But hopefully, it
will happen in future.

00:26:23.760 --> 00:26:26.100
AUDIENCE: So what
do you think it

00:26:26.100 --> 00:26:28.590
is that makes these
choices in games

00:26:28.590 --> 00:26:31.710
compelling and interesting,
because like obviously, you

00:26:31.710 --> 00:26:34.960
know, immersion and
like photorealism helps.

00:26:34.960 --> 00:26:37.800
But in something like,
you know, "Battlefield,"

00:26:37.800 --> 00:26:40.450
you could choose to not shoot
the other soldier, right?

00:26:40.450 --> 00:26:41.910
But like, no one does that.

00:26:41.910 --> 00:26:45.350
And there are a lot of older
text-based games even that

00:26:45.350 --> 00:26:46.777
have interesting choices.

00:26:46.777 --> 00:26:49.110
So I guess are there-- like,
what sort of factors do you

00:26:49.110 --> 00:26:49.920
think makes these choices--

00:26:49.920 --> 00:26:50.380
JORDAN ERICA WEBBER:
Yeah, I don't really

00:26:50.380 --> 00:26:52.450
think photorealism has
a lot to do with it.

00:26:52.450 --> 00:26:53.910
I think it's just
the fact that you

00:26:53.910 --> 00:26:57.060
have agency, which is the thing
people love about games, right?

00:26:57.060 --> 00:27:00.180
It's the fact that you
can actually do stuff.

00:27:00.180 --> 00:27:02.740
So, yeah, like the
old text-based games,

00:27:02.740 --> 00:27:03.840
it's the fiction, right?

00:27:03.840 --> 00:27:07.230
And that's why people love
novels and movies and stuff.

00:27:07.230 --> 00:27:08.610
So that's what involves people.

00:27:08.610 --> 00:27:09.690
It's the story.

00:27:09.690 --> 00:27:11.190
And then it's just
the extra element

00:27:11.190 --> 00:27:14.350
of the agency that makes them
slightly more compelling,

00:27:14.350 --> 00:27:16.350
I would argue, if
they're good examples.

00:27:16.350 --> 00:27:19.824
The problem is that the
majority of video games are bad.

00:27:19.824 --> 00:27:22.620
[LAUGHS] So we're
not quite there yet.

00:27:22.620 --> 00:27:25.200
But as they get better,
I think it will improve.

00:27:30.179 --> 00:27:32.220
AUDIENCE: I know this
sounds a little bit greedy,

00:27:32.220 --> 00:27:33.440
but I have three questions.

00:27:33.440 --> 00:27:35.440
JORDAN ERICA WEBBER: No,
that's No, that's fine.

00:27:35.440 --> 00:27:36.177
We've got time.

00:27:36.177 --> 00:27:38.010
AUDIENCE: You seem
pretty good with numbers.

00:27:38.010 --> 00:27:40.130
So have you ever tracked
like how much hour you

00:27:40.130 --> 00:27:40.980
spend on the game?

00:27:40.980 --> 00:27:43.250
And do you ever go back
and say, this time, I

00:27:43.250 --> 00:27:46.160
choose A. How about the
next time I play it,

00:27:46.160 --> 00:27:50.270
I choose B. But then with
all the heavy philosophy,

00:27:50.270 --> 00:27:52.820
do you ever bring that
anger and frustration

00:27:52.820 --> 00:27:53.860
into your real life?

00:27:53.860 --> 00:27:57.830
And if you have to make all
series of different question,

00:27:57.830 --> 00:28:01.420
like how do you deal with that?

00:28:01.420 --> 00:28:02.420
JORDAN ERICA WEBBER: OK.

00:28:02.420 --> 00:28:04.461
AUDIENCE: I mean, if you're
really into the games

00:28:04.461 --> 00:28:05.330
and think like that?

00:28:05.330 --> 00:28:07.704
JORDAN ERICA WEBBER: Was that
all three questions in one?

00:28:07.704 --> 00:28:08.345
[LAUGHTER]

00:28:08.345 --> 00:28:10.190
AUDIENCE: Sort of a
series of question.

00:28:10.190 --> 00:28:11.450
You imagine this is a game.

00:28:11.450 --> 00:28:12.699
JORDAN ERICA WEBBER: Yeah, OK.

00:28:12.699 --> 00:28:13.703
[LAUGHTER]

00:28:13.703 --> 00:28:14.450
OK.

00:28:14.450 --> 00:28:15.170
I'm the hero.

00:28:15.170 --> 00:28:15.980
Got it.

00:28:15.980 --> 00:28:18.980
OK, so your first question,
you said I'm good with numbers.

00:28:18.980 --> 00:28:20.810
Is that because I found
10 things that are

00:28:20.810 --> 00:28:21.782
good about video games?

00:28:21.782 --> 00:28:23.510
[LAUGHTER]

00:28:23.510 --> 00:28:26.960
I haven't been good with
numbers for a long time.

00:28:26.960 --> 00:28:29.304
So do I track the choices
that I make and do I go back

00:28:29.304 --> 00:28:30.470
and try make different ones?

00:28:30.470 --> 00:28:31.000
Is that what you're saying?

00:28:31.000 --> 00:28:32.958
AUDIENCE: And how long
does it take, generally,

00:28:32.958 --> 00:28:34.695
for you to go
through the question?

00:28:34.695 --> 00:28:37.256
And I would imagine some
of the hard question,

00:28:37.256 --> 00:28:38.630
if I don't want
to make a choice,

00:28:38.630 --> 00:28:40.747
do people abandon this game?

00:28:40.747 --> 00:28:42.080
Like, I can't play with anymore.

00:28:42.080 --> 00:28:42.710
JORDAN ERICA WEBBER: Oh, yeah.

00:28:42.710 --> 00:28:44.240
No, people definitely
abandoned games

00:28:44.240 --> 00:28:46.040
because they don't want
to make the choice.

00:28:46.040 --> 00:28:48.790
And then people abandon games
for all sorts of reasons.

00:28:48.790 --> 00:28:52.010
But, yeah, there are some
games that ask things of you.

00:28:52.010 --> 00:28:54.890
So that game, "Train," people
walk away from that game

00:28:54.890 --> 00:28:57.830
as soon as they realize
what they're doing.

00:28:57.830 --> 00:28:59.570
But how long does
it take to go back?

00:28:59.570 --> 00:29:01.680
It really depends on the game.

00:29:01.680 --> 00:29:05.330
So the thing about "Soma," for
instance, very philosophically

00:29:05.330 --> 00:29:07.730
interesting game, but
what do you do in it

00:29:07.730 --> 00:29:10.520
doesn't actually
change what happens.

00:29:10.520 --> 00:29:12.930
It's just about how
you feel about it.

00:29:12.930 --> 00:29:15.620
So whether or not you kill
the previous Simon or not,

00:29:15.620 --> 00:29:17.540
you still carry on
with the game the same

00:29:17.540 --> 00:29:18.650
as you would have done.

00:29:18.650 --> 00:29:21.140
It's just kind of
pressing that button

00:29:21.140 --> 00:29:23.310
to drain his battery to
get rid of the problem

00:29:23.310 --> 00:29:24.560
that there are now two of you.

00:29:24.560 --> 00:29:27.890
How does that make you feel
is kind of what's important.

00:29:27.890 --> 00:29:30.419
With a game like
"Fallout," I tell myself

00:29:30.419 --> 00:29:31.460
I'm going to replay them.

00:29:31.460 --> 00:29:34.370
And then I never do.

00:29:34.370 --> 00:29:35.360
With a game like--

00:29:35.360 --> 00:29:38.846
OK, so "Mass Effect,"
in that, so the game

00:29:38.846 --> 00:29:40.220
will actually come
on to Shepard.

00:29:40.220 --> 00:29:42.680
You can actually choose to
play as a man in that game

00:29:42.680 --> 00:29:44.510
if you really want to.

00:29:44.510 --> 00:29:48.500
And when I replay "Mass
Effect" to try and do

00:29:48.500 --> 00:29:51.630
the bad choices to see what
happens, I play as a man

00:29:51.630 --> 00:29:52.130
because it--

00:29:52.130 --> 00:29:53.554
[LAUGHTER]

00:29:53.554 --> 00:29:55.220
--because it feels
more realistic to me.

00:29:55.220 --> 00:29:57.950
[LAUGHTER]

00:29:57.950 --> 00:30:01.220
Yeah, my male Commander Shepard
is not a very nice person.

00:30:01.220 --> 00:30:02.730
He sleeps around.

00:30:02.730 --> 00:30:04.839
He picks all the
renegade options.

00:30:04.839 --> 00:30:07.130
But I haven't finished a run
through of all those games

00:30:07.130 --> 00:30:07.720
as him.

00:30:07.720 --> 00:30:09.420
And that's one of
my favorite games.

00:30:09.420 --> 00:30:11.170
I just don't have time.

00:30:11.170 --> 00:30:14.380
Was that everything?

00:30:14.380 --> 00:30:15.340
Oh, great.

00:30:15.340 --> 00:30:20.000
[LAUGHS] I am good with numbers.

00:30:20.000 --> 00:30:24.230
AUDIENCE: I'm getting curious
about this game-making process.

00:30:24.230 --> 00:30:26.810
So you said that they are
intentionally philosophical,

00:30:26.810 --> 00:30:27.560
some of the games.

00:30:27.560 --> 00:30:27.900
JORDAN ERICA WEBBER: Mm, yeah.

00:30:27.900 --> 00:30:29.149
AUDIENCE: Now how far they go?

00:30:29.149 --> 00:30:31.680
They look at papers
on the philosophy?

00:30:31.680 --> 00:30:34.530
I mean, you know, there
must be philosophy journals.

00:30:34.530 --> 00:30:36.210
Would they go beyond that?

00:30:36.210 --> 00:30:38.740
They look at the neuroscience?

00:30:38.740 --> 00:30:40.390
Do they put people
under the scanner?

00:30:40.390 --> 00:30:41.806
JORDAN ERICA WEBBER:
[CHUCKLES] Oh, I don't know.

00:30:41.806 --> 00:30:42.280
AUDIENCE: How far does that go?

00:30:42.280 --> 00:30:44.821
JORDAN ERICA WEBBER: That would
be a good story, wouldn't it?

00:30:44.821 --> 00:30:45.940
I'll have to find out.

00:30:45.940 --> 00:30:47.890
I don't know about
philosophers putting people

00:30:47.890 --> 00:30:49.990
under scanners and things.

00:30:49.990 --> 00:30:53.350
But I do know that
Thomas Grip, who

00:30:53.350 --> 00:30:54.970
was the creative
director of "Soma,"

00:30:54.970 --> 00:30:56.690
he read a bunch of philosophy.

00:30:56.690 --> 00:30:58.270
Like, I interviewed
him for the book

00:30:58.270 --> 00:31:00.825
and he wouldn't stop talking
about all the philosophy

00:31:00.825 --> 00:31:01.450
that he'd read.

00:31:01.450 --> 00:31:02.849
He recommended me
a load of books

00:31:02.849 --> 00:31:05.140
and stuff that I haven't
read, because I'm a philosophy

00:31:05.140 --> 00:31:05.640
graduate.

00:31:05.640 --> 00:31:08.180
And I didn't do
any of the reading.

00:31:08.180 --> 00:31:10.630
So yeah, they definitely
do actually look into it.

00:31:10.630 --> 00:31:13.170
It depends on the writer.

00:31:13.170 --> 00:31:16.030
So I know that the-- oh,
I'm going to be careful.

00:31:16.030 --> 00:31:18.550
I'm being filmed, so I'm going
to be careful what I say.

00:31:18.550 --> 00:31:23.132
Some game developers do more
of the research than others.

00:31:23.132 --> 00:31:26.360
[LAUGHTER]

00:31:26.360 --> 00:31:31.089
And I won't name any names.

00:31:31.089 --> 00:31:31.630
AUDIENCE: Hi.

00:31:31.630 --> 00:31:32.100
JORDAN ERICA WEBBER: Hi.

00:31:32.100 --> 00:31:34.070
AUDIENCE: I noticed
in when you have

00:31:34.070 --> 00:31:35.220
the list of the 10 things--

00:31:35.220 --> 00:31:36.261
JORDAN ERICA WEBBER: Mhm.

00:31:36.261 --> 00:31:38.520
AUDIENCE: --that virtue
ethics was in there, I think?

00:31:38.520 --> 00:31:38.830
JORDAN ERICA WEBBER: Yep.

00:31:38.830 --> 00:31:39.540
AUDIENCE: Yeah.

00:31:39.540 --> 00:31:40.550
I was just curious.

00:31:40.550 --> 00:31:42.410
I haven't had a chance
to read the book yet.

00:31:42.410 --> 00:31:43.260
Looking forward to it.

00:31:43.260 --> 00:31:43.370
But--

00:31:43.370 --> 00:31:44.090
JORDAN ERICA WEBBER: Good.

00:31:44.090 --> 00:31:46.048
AUDIENCE: --what were
some interesting examples

00:31:46.048 --> 00:31:48.240
of virtue ethics from games?

00:31:48.240 --> 00:31:49.240
JORDAN ERICA WEBBER: OK.

00:31:49.240 --> 00:31:51.740
So this wasn't in
my half of the book.

00:31:51.740 --> 00:31:53.160
I did read his half of the book.

00:31:53.160 --> 00:31:54.620
[LAUGHTER]

00:31:54.620 --> 00:31:56.160
We proofread each other's.

00:31:56.160 --> 00:31:58.640
Virtue ethics was in
one of these games

00:31:58.640 --> 00:32:01.590
whose name I couldn't remember,
which I'm going to look at.

00:32:01.590 --> 00:32:03.650
Oh, "Ultima," the
"Ultima" series.

00:32:03.650 --> 00:32:05.990
They were basically
built on virtue ethics.

00:32:05.990 --> 00:32:11.120
So the guy who calls himself
Lord British, Richard Garriott

00:32:11.120 --> 00:32:14.150
who wrote the "Ultima" games,
Dan interviewed him about it.

00:32:14.150 --> 00:32:18.680
And he basically-- he did like
a load of looking into virtues

00:32:18.680 --> 00:32:19.940
in different fiction.

00:32:19.940 --> 00:32:22.670
He looked at like you know
the 10 Commandments and all

00:32:22.670 --> 00:32:23.730
the different religions.

00:32:23.730 --> 00:32:25.396
And then he looked
at "The Wizard of Oz"

00:32:25.396 --> 00:32:29.630
and was like, ah,
bravery, heart, brain.

00:32:29.630 --> 00:32:33.650
And then he just made
his own list of virtues.

00:32:33.650 --> 00:32:35.350
And apparently all
of those games,

00:32:35.350 --> 00:32:39.230
none of which I've
played because I'm young,

00:32:39.230 --> 00:32:42.799
sorry, [LAUGHS] yeah are
basically about virtue ethics.

00:32:42.799 --> 00:32:44.090
And it's a really good chapter.

00:32:44.090 --> 00:32:46.173
He interviewed a good
friend of mine, Angie Hobbs,

00:32:46.173 --> 00:32:49.690
who's a philosopher
who does that stuff.

00:32:49.690 --> 00:32:50.620
So it's a good one.

00:32:50.620 --> 00:32:51.850
You should read it.

00:32:51.850 --> 00:32:55.194
Sorry, I can't be more helpful.

00:32:55.194 --> 00:32:56.860
AUDIENCE: So you
talked about some games

00:32:56.860 --> 00:32:58.600
that are intentionally
philosophical

00:32:58.600 --> 00:33:00.600
or they have some
philosophical choices in them.

00:33:00.600 --> 00:33:01.290
JORDAN ERICA WEBBER: Uh-huh.

00:33:01.290 --> 00:33:03.940
AUDIENCE: Do you think with
virtual reality or things

00:33:03.940 --> 00:33:06.220
like that, just by
means of technology

00:33:06.220 --> 00:33:08.976
we can maybe learn something
about any of the new games?

00:33:08.976 --> 00:33:11.350
For example, I mean, I can
think of a simulation argument

00:33:11.350 --> 00:33:13.240
or like solipsism or
something like that

00:33:13.240 --> 00:33:15.460
that you can just learn
by immersing yourself

00:33:15.460 --> 00:33:17.180
into these games
with virtual reality.

00:33:17.180 --> 00:33:17.980
I don't know if you have
any thoughts on that.

00:33:17.980 --> 00:33:19.646
JORDAN ERICA WEBBER:
I'm glad you asked.

00:33:19.646 --> 00:33:22.990
Chapter three, "Virtual
Reality, A Real Reality,"

00:33:22.990 --> 00:33:25.945
is all about whether virtual
reality counts as a reality.

00:33:25.945 --> 00:33:27.404
A philosopher called
David Chalmers

00:33:27.404 --> 00:33:29.444
has taken-- he doesn't
play a lot of video games,

00:33:29.444 --> 00:33:30.370
as far as I can tell.

00:33:30.370 --> 00:33:32.380
But he's taken a real
interest in virtual reality.

00:33:32.380 --> 00:33:34.171
And he has this really
interesting argument

00:33:34.171 --> 00:33:37.990
that I interviewed him
about where he says,

00:33:37.990 --> 00:33:39.690
virtual reality is--

00:33:39.690 --> 00:33:40.835
it's not an illusion.

00:33:40.835 --> 00:33:42.960
It's a reality that's just
made of different stuff.

00:33:42.960 --> 00:33:43.750
It's not physical.

00:33:43.750 --> 00:33:45.550
It's virtual.

00:33:45.550 --> 00:33:48.100
And the simulation
argument is mentioned

00:33:48.100 --> 00:33:49.840
in that chapter, and
also, in the chapter

00:33:49.840 --> 00:33:51.880
on epistemology and skepticism.

00:33:51.880 --> 00:33:55.490
The simulation argument is
referenced in a recent video

00:33:55.490 --> 00:33:59.200
game, called "No Man's Sky" by
Hello Games, which my co-author

00:33:59.200 --> 00:34:00.850
Dan actually worked on.

00:34:00.850 --> 00:34:03.800
So he wrote the simulation
argument into that game.

00:34:03.800 --> 00:34:05.901
So that's a good one to play.

00:34:05.901 --> 00:34:06.442
AUDIENCE: Hi.

00:34:06.442 --> 00:34:07.442
JORDAN ERICA WEBBER: Hi.

00:34:07.442 --> 00:34:10.510
AUDIENCE: So in your examples,
it seems like most of them,

00:34:10.510 --> 00:34:12.520
most of the decisions
were like built

00:34:12.520 --> 00:34:15.429
in the games as the
designers intended.

00:34:15.429 --> 00:34:19.570
But in lots of massive
multiplayer games,

00:34:19.570 --> 00:34:23.350
lots of the decisions
emerge form the player base.

00:34:23.350 --> 00:34:25.060
And economies develop.

00:34:25.060 --> 00:34:26.310
JORDAN ERICA WEBBER: Oh, yeah.

00:34:26.310 --> 00:34:29.870
AUDIENCE: And lots of
choices, yeah, happen there.

00:34:29.870 --> 00:34:31.580
Do you see some--

00:34:31.580 --> 00:34:34.050
do have some
thoughts about that?

00:34:34.050 --> 00:34:36.250
Can you observe some
philosophical decisions

00:34:36.250 --> 00:34:38.167
that appear in those contexts?

00:34:38.167 --> 00:34:39.250
JORDAN ERICA WEBBER: Yeah.

00:34:39.250 --> 00:34:41.208
I mean, I can't think of
any specific examples.

00:34:41.208 --> 00:34:45.590
But you're right that
multiplayer spaces online are

00:34:45.590 --> 00:34:47.739
fascinating social experiments.

00:34:47.739 --> 00:34:50.530
A lot of the stuff-- oh,
the political philosophy

00:34:50.530 --> 00:34:52.630
chapter in the book
that Dan wrote,

00:34:52.630 --> 00:34:54.699
he talks about "EVE
Online," which obviously,

00:34:54.699 --> 00:34:58.510
is a huge game where people
are behaving in really, really

00:34:58.510 --> 00:35:01.180
interesting ways because
of the like framework

00:35:01.180 --> 00:35:03.651
that they find themselves in.

00:35:03.651 --> 00:35:04.150
So yeah.

00:35:04.150 --> 00:35:07.136
I do think it's interesting
in a slightly different way,

00:35:07.136 --> 00:35:09.010
because it's not-- you're
right that it's not

00:35:09.010 --> 00:35:11.380
written into the game.

00:35:11.380 --> 00:35:13.900
I mean, we can't
ethically do an experiment

00:35:13.900 --> 00:35:16.540
where we put a load of
people in space or then go.

00:35:16.540 --> 00:35:18.340
But in a video game,
you know, they're

00:35:18.340 --> 00:35:20.650
putting themselves
in that virtual space

00:35:20.650 --> 00:35:21.800
by their own volition.

00:35:21.800 --> 00:35:24.050
And then you can just sit
back and watch what happens.

00:35:24.050 --> 00:35:26.597
And the developers of "EVE"
are really good about that.

00:35:26.597 --> 00:35:28.180
They don't really
have much of a hand.

00:35:28.180 --> 00:35:32.230
They just kind of observe, which
I think is really interesting.

00:35:32.230 --> 00:35:33.000
You're welcome.

00:35:35.670 --> 00:35:38.132
Oh, no, a follow-up.

00:35:38.132 --> 00:35:39.840
AUDIENCE: Actually,
a different question.

00:35:39.840 --> 00:35:41.830
JORDAN ERICA WEBBER: OK.

00:35:41.830 --> 00:35:43.270
AUDIENCE: So I'm
a game designer.

00:35:43.270 --> 00:35:45.490
And I'm really
interested in the way

00:35:45.490 --> 00:35:47.479
that the context
of the game shifts

00:35:47.479 --> 00:35:48.520
the player's perception--

00:35:48.520 --> 00:35:48.750
JORDAN ERICA WEBBER: Mhm.

00:35:48.750 --> 00:35:50.020
AUDIENCE: --of these choices.

00:35:50.020 --> 00:35:54.070
So I was just curious from
your own experience as a player

00:35:54.070 --> 00:35:58.240
how you found that things like
having an imposed goal on you

00:35:58.240 --> 00:36:02.250
as the player, or, say,
having your choices impact

00:36:02.250 --> 00:36:03.875
like statistics in the game?

00:36:03.875 --> 00:36:05.500
Like you make a
certain ethical choice,

00:36:05.500 --> 00:36:07.960
but it also has
other implications

00:36:07.960 --> 00:36:10.387
for like, say, what
skills your character gets

00:36:10.387 --> 00:36:11.220
or their appearance.

00:36:11.220 --> 00:36:11.440
JORDAN ERICA WEBBER: Mm.

00:36:11.440 --> 00:36:11.940
"BioShock"--

00:36:11.940 --> 00:36:14.890
AUDIENCE: Like, how
these other game elements

00:36:14.890 --> 00:36:18.040
you found in your
experience have an effect

00:36:18.040 --> 00:36:19.120
on the choices you make?

00:36:19.120 --> 00:36:20.620
JORDAN ERICA WEBBER:
Yeah, so you're

00:36:20.620 --> 00:36:22.240
right that that's
a kind of element

00:36:22.240 --> 00:36:26.470
that I didn't really
touch on in the talk.

00:36:26.470 --> 00:36:28.570
So we're obviously
in quite early days

00:36:28.570 --> 00:36:30.670
with philosophy and games.

00:36:30.670 --> 00:36:32.620
But some developers
are going further.

00:36:32.620 --> 00:36:36.490
So Pippin Barr's "Trolley
Problem" game, he

00:36:36.490 --> 00:36:41.530
was thinking about what
kinds of people game players

00:36:41.530 --> 00:36:43.000
are when he made that.

00:36:43.000 --> 00:36:44.846
So that's why the
game is so minimal,

00:36:44.846 --> 00:36:46.720
because he was trying
to see if you took away

00:36:46.720 --> 00:36:49.960
the like glorious blood and
gore effects of someone getting

00:36:49.960 --> 00:36:51.760
run over by a train,
would it affect

00:36:51.760 --> 00:36:54.160
how willing people were
to just run them over

00:36:54.160 --> 00:36:55.510
to see what happened?

00:36:55.510 --> 00:37:01.600
Because you're right that just
the feeling of being in a game

00:37:01.600 --> 00:37:04.490
can sometimes make people make
different kinds of decisions.

00:37:04.490 --> 00:37:07.460
So like the fact that people
go back and play a game again

00:37:07.460 --> 00:37:09.668
to see what the different
choices are, because that's

00:37:09.668 --> 00:37:12.157
just what game players do,
he works around that by--

00:37:12.157 --> 00:37:13.990
I, mean obviously, you
can work around this.

00:37:13.990 --> 00:37:15.985
But he made it so
that it's stored.

00:37:15.985 --> 00:37:17.080
It's like cookies, right?

00:37:17.080 --> 00:37:18.295
It's tech.

00:37:18.295 --> 00:37:19.489
[LAUGHTER]

00:37:19.489 --> 00:37:21.030
So it knows when
you played the game.

00:37:21.030 --> 00:37:24.080
And it supposedly won't
let you play again

00:37:24.080 --> 00:37:27.430
to kind of get around the fact
that players like to repeat

00:37:27.430 --> 00:37:28.810
choices and stuff like that.

00:37:28.810 --> 00:37:31.400
So yeah, there are
people thinking about it.

00:37:31.400 --> 00:37:33.642
We're just, yeah, early days.

00:37:33.642 --> 00:37:34.850
Hopefully, my book will help.

00:37:37.630 --> 00:37:38.890
SPEAKER: Any more questions?

00:37:38.890 --> 00:37:39.973
JORDAN ERICA WEBBER: Whoo.

00:37:39.973 --> 00:37:41.360
[LAUGHS]

00:37:41.360 --> 00:37:43.200
SPEAKER: If not,
we can close here.

00:37:43.200 --> 00:37:45.200
Again, thank you very
much, Erica Jordan Webber.

00:37:45.200 --> 00:37:48.250
[APPLAUSE]

