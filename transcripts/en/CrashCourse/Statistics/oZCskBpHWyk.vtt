WEBVTT
Kind: captions
Language: en

00:00:03.100 --> 00:00:07.520
Hi, I’m Adriene Hill, and Welcome back to
Crash Course Statistics. We ended the last

00:00:07.529 --> 00:00:13.389
episode by talking about Conditional Probabilities
which helped us find the probability of one

00:00:13.389 --> 00:00:16.240
event, given that a second event had already
happened.

00:00:16.240 --> 00:00:20.789
But now I want to give you a better idea of
why this is true and how this formula--with

00:00:20.789 --> 00:00:25.920
a few small tweaks--has revolutionized the
field of statistics.

00:00:25.920 --> 00:00:34.620
INTRO

00:00:34.620 --> 00:00:39.940
In general terms, Conditional Probability
says that the probability of an event, B,

00:00:39.940 --> 00:00:46.500
given that event A has already happened, is
the probability of A and B happening together,

00:00:46.500 --> 00:00:51.680
Divided by the probability of A happening
- that’s the general formula, but let’s

00:00:51.680 --> 00:00:54.789
give you a concrete example so we can visualize
it.

00:00:54.789 --> 00:00:58.980
Here’s a Venn Diagram of two events, An
Email containing the words “Nigerian Prince”

00:00:58.980 --> 00:01:01.100
and an Email being Spam.

00:01:01.100 --> 00:01:06.120
So I get an email that has the words “Nigerian
Prince” in it, and I want to know what the

00:01:06.120 --> 00:01:11.040
probability is that this email is Spam, given
that I already know the email contains the

00:01:11.040 --> 00:01:14.020
words “Nigerian Prince.” This is the equation.

00:01:14.020 --> 00:01:18.060
Alright, let’s take this part a little.
On the Venn Diagram, I can represent the fact

00:01:18.060 --> 00:01:23.550
that I know the words “Nigerian Prince”
already happened by only looking at the events

00:01:23.550 --> 00:01:26.940
where Nigerian Prince occurs, so just this
circle.

00:01:26.940 --> 00:01:31.990
Now inside this circle I have two areas, areas where the email is spam, and areas

00:01:31.990 --> 00:01:38.960
where it’s not. According to our formula,
the probability of spam given Nigerian Prince

00:01:38.970 --> 00:01:45.500
is the probability of spam AND Nigerian Prince
which is this region... where they overlap…divided

00:01:45.500 --> 00:01:50.400
by Probability of Nigerian Prince which is
the whole circle that we’re looking at.

00:01:50.400 --> 00:01:54.660
Now...if we want to know the proportion of
times when an email is Spam given that we

00:01:54.660 --> 00:01:59.150
already know it has the words “Nigerian
Prince”, we need to look at how much of

00:01:59.150 --> 00:02:05.390
the whole Nigerian Prince circle that the
region with both Spam and Nigerian Prince

00:02:05.390 --> 00:02:06.390
covers.

00:02:06.390 --> 00:02:11.849
And actually, some email servers use a slightly
more complex version of this example to filter

00:02:11.849 --> 00:02:16.870
spam. These filters are called Naive Bayes
filters, and thanks to them, you don’t have

00:02:16.870 --> 00:02:22.530
to worry about seeing the desperate pleas
of a surprisingly large number of Nigerian

00:02:22.530 --> 00:02:23.530
Princes.

00:02:23.530 --> 00:02:28.280
The Bayes in Naive Bayes comes from the Reverend
Thomas Bayes, a Presbyterian minister who

00:02:28.280 --> 00:02:33.120
broke up his days of prayer, with math. His
largest contribution to the field of math

00:02:33.120 --> 00:02:38.659
and statistics is a slightly expanded version
of our conditional probability formula.

00:02:38.660 --> 00:02:40.020
Bayes Theorem states that:

00:02:40.020 --> 00:02:46.540
The probability of B given A, is equal to
the Probability of A given B times the Probability

00:02:46.540 --> 00:02:50.100
of B all divided by the Probability of A

00:02:50.109 --> 00:02:54.220
You can see that this is just one step away
from our conditional probability formula.

00:02:54.220 --> 00:03:03.639
The only change is in the numerator where
P(A and B) is replaced with P(A|B)P(B). While

00:03:03.639 --> 00:03:09.840
the math of this equality is more than we’ll
go into here, you can see with some venn-diagram-algebra

00:03:09.840 --> 00:03:10.950
why this is the case.

00:03:10.950 --> 00:03:15.389
In this form, the equation is known as Bayes’
Theorem, and it has inspired a strong movement

00:03:15.389 --> 00:03:18.160
in both the statistics and science worlds.

00:03:18.160 --> 00:03:22.860
Just like with your emails, Bayes Theorem
allows us to figure out the probability that

00:03:22.860 --> 00:03:27.820
you have a piece of spam on your hands using
information that we already have, the presence

00:03:27.829 --> 00:03:29.689
of the words “Nigerian Prince”.

00:03:29.689 --> 00:03:33.989
We can also compare that probability to the
probability that you just got a perfectly

00:03:33.989 --> 00:03:38.430
valid email about Nigerian Princes. If you
just tried to guess your odds of an email

00:03:38.430 --> 00:03:44.480
being spam based on the rate of spam to non-spam
email, you’d be missing some pretty useful

00:03:44.480 --> 00:03:46.969
information--the actual words in the email!

00:03:46.969 --> 00:03:51.950
Bayesian statistics is all about UPDATING
your beliefs based on new information. When

00:03:51.950 --> 00:03:56.499
you receive an email, you don’t necessarily
think it’s spam, but once you see the word

00:03:56.499 --> 00:04:00.840
Nigerian you’re suspicious. It may just
be your Aunt Judy telling you what she saw

00:04:00.840 --> 00:04:05.879
on the news, but as soon as you see “Nigerian”
and “Prince” together, you’re pretty

00:04:05.879 --> 00:04:07.659
convinced that this is junkmail.

00:04:07.659 --> 00:04:11.749
Remember our Lady Tasting Tea example... where
a woman claimed to have superior taste buds

00:04:11.749 --> 00:04:16.850
...that allowed her to know--with one sip--whether
tea or milk was poured into a cup first? When

00:04:16.850 --> 00:04:21.730
you’re watching this lady predict whether
the tea or milk was poured first, each correct

00:04:21.730 --> 00:04:23.820
guess makes you believe her just a little
bit more.

00:04:23.820 --> 00:04:27.810
A few correct guesses may not convince you,
but each correct prediction is a little more

00:04:27.810 --> 00:04:31.780
evidence she has some weird super-tasting
tea powers.

00:04:31.780 --> 00:04:35.590
Reverend Bayes described this idea of “updating”
in a thought experiment.

00:04:35.590 --> 00:04:38.881
Say that you’re standing next to a pool
table but you’re faced away from it, so

00:04:38.881 --> 00:04:43.880
you can’t see anything on it. You then have
your friend randomly drop a ball onto the

00:04:43.880 --> 00:04:49.470
table, and this is a special, very even table,
so the ball has an equal chance of landing

00:04:49.470 --> 00:04:55.410
anywhere on it. Your mission--is to guess
how far to the right or left this ball is.

00:04:55.410 --> 00:04:58.850
You have your friend drop another ball onto
the table and report whether it’s to the

00:04:58.850 --> 00:05:02.650
left or to the right of the original ball.
The new ball is to the right of the original,

00:05:02.650 --> 00:05:06.090
so, we can update our belief about where the
ball is.

00:05:06.090 --> 00:05:10.470
If the original is more towards the left,
than most of the new balls will fall to the

00:05:10.470 --> 00:05:15.570
right of our original, just because there’s
more area there. And the further to the left

00:05:15.570 --> 00:05:19.690
it is, the higher the ratio of new rights
to lefts

00:05:19.690 --> 00:05:25.320
Since this new ball is to the right, that
means there’s a better chance that our original

00:05:25.320 --> 00:05:29.220
is more toward the left side of the table
than the right, since there would be more

00:05:29.220 --> 00:05:31.170
“room” for the new ball to land.

00:05:31.170 --> 00:05:35.770
Each ball that lands to the right of the original
is more evidence that our original is towards

00:05:35.770 --> 00:05:40.311
the left of the table. But, if we get a ball
landing on the left of our original, then

00:05:40.311 --> 00:05:46.650
we know the original is not at the very left
edge. Again, Each new piece of information

00:05:46.650 --> 00:05:51.610
allows us to change our beliefs about the
location of the ball, and changing beliefs

00:05:51.610 --> 00:05:53.950
is what Bayesian statistics is all about.

00:05:53.950 --> 00:05:58.160
Outside thought experiments, Bayesian Statistics
is being used in many different ways, from

00:05:58.160 --> 00:06:02.940
comparing treatments in medical trials, to
helping robots learn language. It’s being

00:06:02.940 --> 00:06:06.460
used by cancer researchers, ecologists, and
physicists.

00:06:06.460 --> 00:06:11.770
And this method of thinking about statistics...updating
existing information with what’s come before...may

00:06:11.770 --> 00:06:15.740
be different from the logic of some of the
statistical tests that you’ve heard of--like

00:06:15.740 --> 00:06:20.740
the t-test. Those Frequentist statistics can
sometimes be more like probability done in

00:06:20.740 --> 00:06:23.980
a vacuum. Less reliant on prior knowledge.

00:06:23.980 --> 00:06:29.020
When the math of probability gets hard to
wrap your head around, we can use simulations

00:06:29.020 --> 00:06:34.610
to help see these rules in action. Simulations
take rules and create a pretend universe that

00:06:34.610 --> 00:06:36.010
follows those rules.

00:06:36.010 --> 00:06:39.740
Let’s say you’re the boss of a company,
and you receive news that one of your employees,

00:06:39.740 --> 00:06:44.640
Joe, has failed a drug test. It’s hard to
believe. You remember seeing this thing on

00:06:44.640 --> 00:06:50.140
YouTube that told you how to figure out the
probability that Joe really is on drugs given

00:06:50.140 --> 00:06:51.670
that he got a positive test.

00:06:51.670 --> 00:06:56.320
You can’t remember exactly what the formula
is...but you could always run a simulation.

00:06:56.320 --> 00:06:59.240
Simulations are nice, because we can just
tell our computer some rules, and it will

00:06:59.240 --> 00:07:02.410
randomly generate data based on those rules.

00:07:02.410 --> 00:07:06.030
For example, we can tell it the base rate
of people in our state that are on drugs,

00:07:06.030 --> 00:07:11.510
the sensitivity (how many true positives we
get) of the drug test... and specificity (how

00:07:11.510 --> 00:07:17.100
many true negatives we get). Then we ask our
computer to generate 10,000 simulated people

00:07:17.100 --> 00:07:22.180
and tell us what percent of the time people
with positive drug tests were actually on

00:07:22.180 --> 00:07:23.180
drugs.

00:07:23.180 --> 00:07:27.890
If the drug Joe tested positive for--in this
case Glitterstim--is only used by about 5%

00:07:27.890 --> 00:07:34.840
of the population, and the test for Glitterstim
has a 90% sensitivity and 95% specificity,

00:07:34.840 --> 00:07:39.750
I can plug that in and ask the computer to
simulate 10,000 people according to these

00:07:39.750 --> 00:07:40.400
rules.

00:07:40.400 --> 00:07:46.020
And when we ran this simulation, only 49.2%
of the people who tested positive were actually

00:07:46.020 --> 00:07:51.190
using Glitterstim. So I should probably give
Joe another chance...or another test.

00:07:51.190 --> 00:07:56.070
And if I did the math, I’d see that 49.2%
is pretty close since the theoretical answer

00:07:56.070 --> 00:08:02.670
is around 48.6%. Simulations can help reveal
truths about probability, even without formulas.

00:08:02.670 --> 00:08:07.880
They’re a great way to demonstrate probability
and create intuition that can stand alone

00:08:07.880 --> 00:08:11.930
or build on top of more mathematical approaches
to probability.

00:08:11.930 --> 00:08:16.280
Let’s use one to demonstrate an important
concept in probability that makes it possible

00:08:16.280 --> 00:08:23.020
to use samples of data to make inferences
about a population: the Law of Large Numbers.

00:08:23.020 --> 00:08:27.480
In fact we were secretly relying on it when
we used empirical probabilities--like how

00:08:27.480 --> 00:08:33.150
many times I got tails when flipping a coin
10 times--to estimate theoretical probabilities--like

00:08:33.150 --> 00:08:35.700
the true probability of getting tails.

00:08:35.700 --> 00:08:40.520
In its weak form, Law of Large Numbers tells
us that as our samples of data get bigger

00:08:40.520 --> 00:08:45.800
and bigger, our sample mean will be ‘arbitrarily’ close to the true population mean.

00:08:45.800 --> 00:08:49.940
Before we go into more detail, let’s see
a simulation and if you want to follow along

00:08:49.940 --> 00:08:53.280
or run it on your own - instructions are in
the description below.

00:08:53.290 --> 00:08:57.310
In this simulation we’re picking values
from a new intelligence test--from the normal

00:08:57.310 --> 00:09:01.680
distribution, that has a mean of 50 and a
standard deviation of 20. When you have a

00:09:01.680 --> 00:09:06.389
very small sample size, say 2, your sample
means are all over the place.

00:09:06.389 --> 00:09:12.390
You can see that pretty much anything goes,
we see means between 5 and 95. And this makes

00:09:12.390 --> 00:09:16.589
sense, when we only have two data points in
our sample, it’s not that unlikely that

00:09:16.589 --> 00:09:21.529
we get two really small numbers, or two pretty
big numbers, which is why we see both low

00:09:21.529 --> 00:09:25.220
and high sample means.
Though we can tell that a lot of the means

00:09:25.220 --> 00:09:30.649
are around the true mean of 50 because the
histogram is the tallest at values around

00:09:30.649 --> 00:09:31.649
50.

00:09:31.649 --> 00:09:36.490
But once we increase the sample size, even
to just 100 values, you can see that the sample

00:09:36.490 --> 00:09:41.709
means are mostly around the real mean of 50.
In fact all of the sample means are within

00:09:41.709 --> 00:09:44.160
10 units of the true population mean.

00:09:44.160 --> 00:09:48.399
And when we go up to 1000, just about every
sample mean is very very close to the true

00:09:48.399 --> 00:09:53.769
mean. And when you run this simulation over
and over, you’ll see pretty similar results.

00:09:53.769 --> 00:09:58.529
The neat thing is that the Law of Large numbers
applies to almost any distribution as long

00:09:58.529 --> 00:10:01.640
as the distribution doesn’t have an infinite
variance.

00:10:01.640 --> 00:10:06.170
Take the uniform distribution which looks
like a rectangle. Imagine a 100-sided die,

00:10:06.170 --> 00:10:09.230
every single value is equally probable.

00:10:09.230 --> 00:10:13.980
Even the sample means that are selected from
a uniform distribution get closer and closer

00:10:13.980 --> 00:10:16.100
to the true mean of 50..

00:10:16.100 --> 00:10:20.769
The law of large numbers is the evidence we
need to feel confident that the mean of the

00:10:20.769 --> 00:10:25.370
samples we analyze is a pretty good guess
for the true population mean. And the bigger

00:10:25.370 --> 00:10:29.810
our samples are, the better we think the guess
is! This property allows us to make guesses

00:10:29.810 --> 00:10:32.329
about populations, based on samples.

00:10:32.329 --> 00:10:36.529
It also explains why casinos make money in
the long run over hundreds of thousands of

00:10:36.529 --> 00:10:42.160
payouts and losses, even if the experience
of each person varies a lot. The casino looks

00:10:42.160 --> 00:10:47.990
at a huge sample--every single bet and payout--whereas
your sample as an individual is smaller, and

00:10:47.990 --> 00:10:50.540
therefore less likely to be representative.

00:10:50.540 --> 00:10:54.959
Each of these concepts can help us another
way ...another way to look at the data around

00:10:54.959 --> 00:11:00.639
us. The Bayesian framework shows us that every
event or data point can and should “update”

00:11:00.639 --> 00:11:04.160
your beliefs but it doesn’t mean you need
to completely change your mind.

00:11:04.160 --> 00:11:08.670
And simulations allow us to build upon these
observations when the underlying mechanics

00:11:08.670 --> 00:11:09.800
aren’t so clear.

00:11:09.800 --> 00:11:14.459
We are continuously accumulating evidence
and modifying our beliefs everyday, adding

00:11:14.459 --> 00:11:19.360
today's events to our conception of how the
world works. And hey, maybe one day we’ll

00:11:19.360 --> 00:11:22.500
all start sincerely emailing each other about
Nigerian Princes.

00:11:22.500 --> 00:11:27.180
Then we’re gonna have to do some belief-updating. Thanks for watching. I’ll see you next time.

