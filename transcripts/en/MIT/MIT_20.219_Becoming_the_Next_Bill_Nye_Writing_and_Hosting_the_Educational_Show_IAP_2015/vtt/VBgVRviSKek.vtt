WEBVTT
Kind: captions
Language: en

00:00:00.090 --> 00:00:02.430
The following content is
provided under a Creative

00:00:02.430 --> 00:00:03.820
Commons license.

00:00:03.820 --> 00:00:06.050
Your support will help
MIT OpenCourseWare

00:00:06.050 --> 00:00:10.150
continue to offer high quality
educational resources for free.

00:00:10.150 --> 00:00:12.700
To make a donation or to
view additional materials

00:00:12.700 --> 00:00:16.600
from hundreds of MIT courses,
visit MIT OpenCourseWare

00:00:16.600 --> 00:00:17.265
at ocw.mit.edu.

00:00:27.350 --> 00:00:31.130
ELIZABETH CHOE: All right, so
everyone is here for 20.219,

00:00:31.130 --> 00:00:32.910
correct, Becoming
the Next Bill Nye?

00:00:32.910 --> 00:00:35.100
No one's in the wrong room?

00:00:35.100 --> 00:00:35.830
All right.

00:00:39.820 --> 00:00:41.860
OK, well, welcome to the class.

00:00:41.860 --> 00:00:45.210
I'm Elizabeth, I run
the K12 videos program.

00:00:45.210 --> 00:00:47.610
Maybe we can do a quick intro
with the staff over here.

00:00:47.610 --> 00:00:48.569
So Jamie, you want to--

00:00:48.569 --> 00:00:50.276
JAIME GOLDSTEIN: Hi,
I'm Jaime Goldstein.

00:00:50.276 --> 00:00:52.715
I run the communication lab
in Biological Engineering,

00:00:52.715 --> 00:00:54.840
and I oversee it in Nuclear
Science and Engineering

00:00:54.840 --> 00:00:56.305
as well.

00:00:56.305 --> 00:00:57.180
CERI RILEY: I'm Ceri.

00:00:57.180 --> 00:00:59.320
I am the TA for this class.

00:00:59.320 --> 00:01:04.690
I'm a junior in Comparative
Media Studies and Biology.

00:01:04.690 --> 00:01:06.000
JOSH GUNN: I'm Josh.

00:01:06.000 --> 00:01:08.650
I run an animation
studio here in Cambridge

00:01:08.650 --> 00:01:11.969
called Planet Nutshell.

00:01:11.969 --> 00:01:13.260
CHRIS BOEBEL: I'm Chris Boebel.

00:01:13.260 --> 00:01:16.940
I'm Media Development
Director at MITx,

00:01:16.940 --> 00:01:19.660
and I also teach a
class here at MIT

00:01:19.660 --> 00:01:22.226
called DV Lab on
documentary, and I'll

00:01:22.226 --> 00:01:25.450
be guest lecturing for
a couple of sessions.

00:01:25.450 --> 00:01:28.100
ELIZABETH CHOE: Come
on in, take a seat.

00:01:28.100 --> 00:01:30.330
So just logistics stuff.

00:01:30.330 --> 00:01:31.860
All the information
about this class

00:01:31.860 --> 00:01:34.460
is on our Tumblr, which I'll
email it out to you guys,

00:01:34.460 --> 00:01:37.630
but it's mit219.tumblr.com.

00:01:37.630 --> 00:01:40.710
And you'll find the class
syllabus, all the links,

00:01:40.710 --> 00:01:43.115
all the videos that I'll be
showing you during class,

00:01:43.115 --> 00:01:44.490
and basically
everything you need

00:01:44.490 --> 00:01:46.480
to know about just
homework assignments

00:01:46.480 --> 00:01:47.570
and things like that.

00:01:47.570 --> 00:01:51.500
So we're just going to go
ahead and dive right in.

00:01:51.500 --> 00:01:55.870
This class is about writing,
hosting, and producing video,

00:01:55.870 --> 00:02:00.910
short-form video, but in the
context of this sort of scary,

00:02:00.910 --> 00:02:04.510
amorphous blob that people
talk about a lot, the problems

00:02:04.510 --> 00:02:08.350
in science, technology, and
engineering and math education.

00:02:08.350 --> 00:02:10.190
And the specific
problems that we're

00:02:10.190 --> 00:02:11.840
going to be trying
to be thinking

00:02:11.840 --> 00:02:14.900
about in the context
of making these videos

00:02:14.900 --> 00:02:16.400
are these three
problems, which is

00:02:16.400 --> 00:02:18.860
that the culture that we
have right now, especially

00:02:18.860 --> 00:02:21.810
with video and science,
is that it kind of implies

00:02:21.810 --> 00:02:23.602
that the door to
science and engineering,

00:02:23.602 --> 00:02:25.310
whether or not you
want to be a scientist

00:02:25.310 --> 00:02:26.935
or whether or not
you want to study it,

00:02:26.935 --> 00:02:29.670
is only open to certain people.

00:02:29.670 --> 00:02:32.090
We also have this
issue of maintaining

00:02:32.090 --> 00:02:34.117
a love of lifelong learning.

00:02:34.117 --> 00:02:36.200
Josh I were just talking
about the dark ages, when

00:02:36.200 --> 00:02:37.800
you quit playing with LEGOs.

00:02:37.800 --> 00:02:40.960
But kids are very
curious creatures,

00:02:40.960 --> 00:02:43.930
and somehow our
educational system

00:02:43.930 --> 00:02:46.000
squelches that curiosity.

00:02:46.000 --> 00:02:48.630
And science and engineering
are these topics

00:02:48.630 --> 00:02:51.220
that I'm sure you guys
are very excited about.

00:02:51.220 --> 00:02:53.480
I'm very excited about it too.

00:02:53.480 --> 00:02:57.720
But somehow it becomes this
sort of boring subject,

00:02:57.720 --> 00:03:01.050
and especially in high school,
people think of chemistry

00:03:01.050 --> 00:03:03.180
as their least favorite class.

00:03:03.180 --> 00:03:05.760
It was my least favorite
class in high school.

00:03:05.760 --> 00:03:09.410
And then you have this
civic responsibility

00:03:09.410 --> 00:03:11.280
as scientists and
engineers to make sure

00:03:11.280 --> 00:03:15.580
that you're promoting STEM
literacy among the public.

00:03:15.580 --> 00:03:17.809
We don't want everyone
in our culture

00:03:17.809 --> 00:03:19.350
to become a scientist
or an engineer.

00:03:19.350 --> 00:03:21.850
That would be terrible,
it would be super boring.

00:03:21.850 --> 00:03:23.910
It wouldn't really be
helping our society at all.

00:03:23.910 --> 00:03:26.170
But at the same time,
science and engineering

00:03:26.170 --> 00:03:27.830
affects your daily life.

00:03:27.830 --> 00:03:30.810
Whether or not you're an
artist or you're an author,

00:03:30.810 --> 00:03:34.860
you're voting on issues that
require a certain knowledge

00:03:34.860 --> 00:03:36.430
of science and engineering.

00:03:36.430 --> 00:03:38.655
And as scientists
and engineers, we

00:03:38.655 --> 00:03:40.030
need to be making
sure that we're

00:03:40.030 --> 00:03:42.290
promoting a basic
level of literacy

00:03:42.290 --> 00:03:43.370
among the voting public.

00:03:43.370 --> 00:03:45.930
So it's a practical
thing for us,

00:03:45.930 --> 00:03:47.220
as scientists and engineers.

00:03:47.220 --> 00:03:50.120
It's also sharing that
excitement and love

00:03:50.120 --> 00:03:52.120
of learning with other
people that maybe they

00:03:52.120 --> 00:03:56.120
lost in a boring class
or something like that.

00:03:56.120 --> 00:03:59.210
So the idea of this class
is to bring together

00:03:59.210 --> 00:04:03.400
the best practices in education,
and some of these problems

00:04:03.400 --> 00:04:05.540
that I'm talking about
with STEM education,

00:04:05.540 --> 00:04:07.700
and bringing it together
with some of the tools

00:04:07.700 --> 00:04:09.190
that we have in entertainment.

00:04:09.190 --> 00:04:13.680
So how can we use video, how
can we leverage video to address

00:04:13.680 --> 00:04:16.050
that big, amorphous blob.

00:04:16.050 --> 00:04:18.649
So we're going to try to
occupy this middle space.

00:04:18.649 --> 00:04:23.560
But the problem is that the best
practices in this middle space

00:04:23.560 --> 00:04:25.240
have not really
been established.

00:04:25.240 --> 00:04:29.280
Part of that is because
there aren't really experts

00:04:29.280 --> 00:04:30.820
in edutainment, necessarily.

00:04:30.820 --> 00:04:32.990
It's not a super academic field.

00:04:32.990 --> 00:04:34.200
It's also pretty new.

00:04:34.200 --> 00:04:37.990
The advent of science
entertainment on the web,

00:04:37.990 --> 00:04:41.520
especially now it's exploding,
but it's all very new,

00:04:41.520 --> 00:04:44.720
so it's hard to establish
the best practices.

00:04:44.720 --> 00:04:47.850
And on top of that, the
best practices in education

00:04:47.850 --> 00:04:49.700
and the best practices
in entertainment

00:04:49.700 --> 00:04:50.580
don't always align.

00:04:50.580 --> 00:04:52.960
A lot of times they
conflict with each other.

00:04:52.960 --> 00:04:56.770
So a lot of this class
will be piecing together

00:04:56.770 --> 00:04:58.700
what's great about
these two disciplines,

00:04:58.700 --> 00:05:01.580
and it'll also be sort
of discovering on our own

00:05:01.580 --> 00:05:03.830
what are the pieces that we
want to take and implement

00:05:03.830 --> 00:05:04.330
ourselves.

00:05:08.110 --> 00:05:12.630
At this point, I wanted you guys
to think about this question,

00:05:12.630 --> 00:05:16.160
partially to inform us
and help us help you guys

00:05:16.160 --> 00:05:18.150
over the course of this month.

00:05:18.150 --> 00:05:21.000
But I wanted to get a
sense of why you all

00:05:21.000 --> 00:05:22.150
signed up for this class.

00:05:22.150 --> 00:05:25.680
Maybe it was because you needed
six extra units to graduate,

00:05:25.680 --> 00:05:27.370
which is totally fine.

00:05:27.370 --> 00:05:29.545
And also what you wanted
to get out of this class.

00:05:29.545 --> 00:05:31.170
If you're coming into
the class and you

00:05:31.170 --> 00:05:32.772
want to learn how
to record video,

00:05:32.772 --> 00:05:34.480
we want to know if
that's your objective.

00:05:34.480 --> 00:05:36.000
If you came in
because you thought

00:05:36.000 --> 00:05:39.410
it sounded interesting
or anything like that,

00:05:39.410 --> 00:05:40.650
we want to know, too.

00:05:40.650 --> 00:05:44.924
So you guys can think
about it, maybe share.

00:05:44.924 --> 00:05:47.340
If you don't want to share
right now, that's totally fine.

00:05:47.340 --> 00:05:49.274
But I will mention this
at the end of class,

00:05:49.274 --> 00:05:50.940
but every day you're
going to be writing

00:05:50.940 --> 00:05:52.609
blog posts and
daily reflections,

00:05:52.609 --> 00:05:54.900
so hopefully this is something
that you can incorporate

00:05:54.900 --> 00:05:56.960
into your reflection today.

00:05:56.960 --> 00:05:58.960
JAIME GOLDSTEIN: Elizabeth,
why don't you start?

00:05:58.960 --> 00:05:59.630
Why are you here?

00:05:59.630 --> 00:06:00.240
ELIZABETH CHOE: Why am I here?

00:06:00.240 --> 00:06:02.520
Well, I'm going to talk about
why I'm here after this,

00:06:02.520 --> 00:06:04.260
so I don't want to spoil it.

00:06:04.260 --> 00:06:05.726
But Jaime, why are you here?

00:06:05.726 --> 00:06:07.990
JAIME GOLDSTEIN: Oh, OK.

00:06:07.990 --> 00:06:09.490
Really good question.

00:06:09.490 --> 00:06:12.020
I run the communication lab
in Biological Engineering,

00:06:12.020 --> 00:06:13.290
and that was it.

00:06:13.290 --> 00:06:15.117
I oversee Nuclear
Science as well.

00:06:15.117 --> 00:06:17.700
And our goal is really to help
scientists learn to communicate

00:06:17.700 --> 00:06:19.350
more effectively.

00:06:19.350 --> 00:06:21.630
And that's what I do now.

00:06:21.630 --> 00:06:23.808
I mostly train graduate
students to talk

00:06:23.808 --> 00:06:26.860
to each other about their
science, and to undergraduates,

00:06:26.860 --> 00:06:31.060
about how do you tell people
about what you're doing.

00:06:31.060 --> 00:06:35.220
And when Elizabeth approached
me-- she was an MBE originally,

00:06:35.220 --> 00:06:37.027
so she knew about our lab.

00:06:37.027 --> 00:06:39.360
This was a perfect match for
me personally, this course,

00:06:39.360 --> 00:06:42.640
because prior to my
life here I taught

00:06:42.640 --> 00:06:45.260
middle school for many years,
among the many other things.

00:06:45.260 --> 00:06:47.690
I was a magazine editor
for a little while.

00:06:47.690 --> 00:06:50.810
So this to me is a perfect
intersection of things

00:06:50.810 --> 00:06:53.565
that I'm passionate about,
because your videos are

00:06:53.565 --> 00:06:54.940
targeted, that
you're going to be

00:06:54.940 --> 00:06:57.810
making for that middle
school population.

00:06:57.810 --> 00:07:00.150
And that's one that
I know very well

00:07:00.150 --> 00:07:01.680
and that I care about a lot.

00:07:01.680 --> 00:07:03.970
So I'm looking forward
to sharing with you

00:07:03.970 --> 00:07:07.680
what I know about the work that
I do now blended with the work

00:07:07.680 --> 00:07:08.430
that I used to do.

00:07:08.430 --> 00:07:11.038
So I'm excited to tap
into your creativity.

00:07:14.512 --> 00:07:16.970
ELIZABETH CHOE: Anyone else
want to share why they're here?

00:07:16.970 --> 00:07:17.700
No wrong answers.

00:07:23.145 --> 00:07:24.842
PAUL FOLINO: My
name's Paul Folino.

00:07:24.842 --> 00:07:27.670
I came here to, kind of
on what you were saying,

00:07:27.670 --> 00:07:30.590
just try to be able to
convey technical concepts

00:07:30.590 --> 00:07:34.050
in a simple way, so I
can explain to someone,

00:07:34.050 --> 00:07:36.720
whether it's one of
my friends or someone

00:07:36.720 --> 00:07:39.282
like my niece, what I do.

00:07:39.282 --> 00:07:40.281
ELIZABETH CHOE: Awesome.

00:07:43.090 --> 00:07:46.188
Anyone else?

00:07:46.188 --> 00:07:48.104
You will have to stay
it in your blog, though.

00:07:48.104 --> 00:07:50.231
JAIME GOLDSTEIN: I want
to hear from everyone.

00:07:50.231 --> 00:07:51.731
JOSH CHEONG: I'll
probably go first.

00:07:51.731 --> 00:07:53.204
JAIME GOLDSTEIN: Sure.

00:07:53.204 --> 00:07:54.186
ELIZABETH CHOE: And
what's your name?

00:07:54.186 --> 00:07:54.680
Sorry.

00:07:54.680 --> 00:07:55.690
JOSH CHEONG: My name is Joshua.

00:07:55.690 --> 00:07:56.350
ELIZABETH CHOE: Joshua.

00:07:56.350 --> 00:07:58.060
JOSH CHEONG: You
can call me Josh.

00:07:58.060 --> 00:07:59.020
I come from Singapore.

00:07:59.020 --> 00:08:04.120
So we're here on a really short
exchange for about a month.

00:08:04.120 --> 00:08:05.980
We come from
Singapore University

00:08:05.980 --> 00:08:07.660
of Technology and Design.

00:08:07.660 --> 00:08:12.010
It's a university that was
started in collaboration

00:08:12.010 --> 00:08:12.660
with MIT.

00:08:16.320 --> 00:08:20.820
Well, I came to this class
because we study OCW a lot,

00:08:20.820 --> 00:08:23.994
and that's because
we are probably

00:08:23.994 --> 00:08:25.946
the first [? special ?]
university and most

00:08:25.946 --> 00:08:27.740
of our curriculum
comes from MIT.

00:08:27.740 --> 00:08:33.330
And honestly, I feel like
close to 25% of my education

00:08:33.330 --> 00:08:35.070
comes from online.

00:08:35.070 --> 00:08:37.285
And I'm very
comfortable with it,

00:08:37.285 --> 00:08:41.070
but-- my mom is a
chemistry teacher,

00:08:41.070 --> 00:08:43.409
and she tells me that
students don't necessarily

00:08:43.409 --> 00:08:45.100
like stuff like Khan
Academy, because it

00:08:45.100 --> 00:08:47.810
might look too boring for them.

00:08:47.810 --> 00:08:50.660
And that's kind of my
curiosity right now,

00:08:50.660 --> 00:08:53.810
how do I convey something
that people might not

00:08:53.810 --> 00:08:57.233
find really interesting but
very important for them,

00:08:57.233 --> 00:08:59.320
and make it very interactive.

00:09:02.764 --> 00:09:04.240
ELIZABETH CHOE:
It's Yuliya, right?

00:09:04.240 --> 00:09:06.210
YULIYA KLOCHAN: Mm-hm.

00:09:06.210 --> 00:09:10.980
So I was very interested in
education in high school,

00:09:10.980 --> 00:09:16.392
and I noticed that kids don't
like STEM subjects, generally.

00:09:16.392 --> 00:09:20.820
And so I just wanted
to, as a career,

00:09:20.820 --> 00:09:23.772
pursue promotion
of STEM subjects.

00:09:23.772 --> 00:09:26.232
That's one of the
things I'd like to do.

00:09:31.795 --> 00:09:32.628
ELIZABETH CHOE: Yes.

00:09:32.628 --> 00:09:34.104
JONATHAN: Hi, I'm Jonathan.

00:09:34.104 --> 00:09:35.479
ELIZABETH CHOE:
Did you say John?

00:09:35.479 --> 00:09:36.072
Josh?

00:09:36.072 --> 00:09:36.564
JONATHAN: Jonathan.

00:09:36.564 --> 00:09:37.439
ELIZABETH CHOE: John.

00:09:37.439 --> 00:09:39.973
JONATHAN: John is fine, too.

00:09:39.973 --> 00:09:42.514
So I noticed there were a number
of videos on YouTube popping

00:09:42.514 --> 00:09:45.986
up, a number of
educational videos in range

00:09:45.986 --> 00:09:48.466
from exciting to pretty boring.

00:09:48.466 --> 00:09:50.450
And I think this is a
very powerful medium

00:09:50.450 --> 00:09:52.930
to reach kids who
wouldn't normally be

00:09:52.930 --> 00:09:54.914
interested in science, or math.

00:09:54.914 --> 00:09:57.890
And exposure, and
how you receive

00:09:57.890 --> 00:09:59.874
and where you get
information, usually

00:09:59.874 --> 00:10:02.354
tends to tip the scales as
far as who's into something

00:10:02.354 --> 00:10:03.346
and who's not.

00:10:03.346 --> 00:10:07.314
So I think this is a
really cool project.

00:10:07.314 --> 00:10:09.794
And I like to be on the other
side of the camera as well.

00:10:17.234 --> 00:10:19.714
ANDREA DESROSIERS: I
guess I'll go next.

00:10:19.714 --> 00:10:21.110
My name is Andrea.

00:10:21.110 --> 00:10:23.916
I'm a Sloan Fellow here at MIT.

00:10:23.916 --> 00:10:26.750
So I'm significantly older
than maybe everybody.

00:10:29.292 --> 00:10:31.500
What I've been doing for
the past 10 years of my life

00:10:31.500 --> 00:10:35.460
has been working in regulatory,
so doing medical device

00:10:35.460 --> 00:10:37.800
submissions to the FDA.

00:10:37.800 --> 00:10:41.860
So it's a lot of communicating
highly technical information

00:10:41.860 --> 00:10:44.530
to people who aren't
exactly laypeople,

00:10:44.530 --> 00:10:47.730
but they're not going to be
as familiar with the topic

00:10:47.730 --> 00:10:48.560
as, say, I am.

00:10:48.560 --> 00:10:50.050
So that's what I've been doing.

00:10:50.050 --> 00:10:53.380
And one of the things that
I'd really like to introduce

00:10:53.380 --> 00:10:56.942
is using video as another tool
to convey this information.

00:11:04.718 --> 00:11:06.662
NATHAN HERNANDEZ:
Hi, I'm Nathan.

00:11:06.662 --> 00:11:11.432
I think why I'm taking this
class is [INAUDIBLE] spread

00:11:11.432 --> 00:11:13.787
scientific information, too.

00:11:13.787 --> 00:11:16.340
At least for me, I think,
not necessarily people

00:11:16.340 --> 00:11:19.707
who adore the science, but
just people so they can

00:11:19.707 --> 00:11:22.112
be scientifically literate now.

00:11:22.112 --> 00:11:23.074
I don't know.

00:11:28.365 --> 00:11:32.690
KENNETH CHEAH: Hi, I'm
Kenneth, from SUTD as well.

00:11:32.690 --> 00:11:35.260
Back when I first graduated
from junior college,

00:11:35.260 --> 00:11:38.760
I actually went to have
a teaching internship

00:11:38.760 --> 00:11:40.790
for a period in
Singapore, and that's

00:11:40.790 --> 00:11:43.640
when I realized that most
students in Singapore

00:11:43.640 --> 00:11:48.890
do not really like blackboard
or whiteboard teaching.

00:11:48.890 --> 00:11:51.220
I realized that a
little-- like halfway

00:11:51.220 --> 00:11:53.440
into my first week of
doing the internship,

00:11:53.440 --> 00:11:56.160
so that's when I revised
everything that I had prepared,

00:11:56.160 --> 00:12:01.320
started creating multimedia
tools and animations.

00:12:01.320 --> 00:12:03.420
It's been like two,
three years since then.

00:12:03.420 --> 00:12:06.700
But the whole idea of
using multimedia as well

00:12:06.700 --> 00:12:09.495
as video tools has
still stuck around.

00:12:09.495 --> 00:12:10.870
I still regularly,
when I'm bored

00:12:10.870 --> 00:12:13.328
and I don't feel like doing my
homework, I'll go on YouTube

00:12:13.328 --> 00:12:14.830
and watch all these
random videos,

00:12:14.830 --> 00:12:17.070
because at least I learn
something; not relevant,

00:12:17.070 --> 00:12:19.730
but something.

00:12:19.730 --> 00:12:21.710
So this has always
been an interest.

00:12:24.692 --> 00:12:26.900
ELIZABETH CHOE: Does anyone
have any particular goals

00:12:26.900 --> 00:12:29.260
out of this month or something
that you want to get out

00:12:29.260 --> 00:12:30.285
of taking this class?

00:12:43.889 --> 00:12:44.780
That's OK.

00:12:44.780 --> 00:12:46.392
We'll give you
goals, don't worry.

00:12:49.560 --> 00:12:52.835
All right, well, I won't
torture you any further.

00:12:52.835 --> 00:12:54.376
JOSH GUNN: I'll just
mention that I'm

00:12:54.376 --> 00:12:55.594
excited about the class.

00:12:55.594 --> 00:12:58.690
I run an animation
studio, as I said,

00:12:58.690 --> 00:13:01.040
and we do this work every day.

00:13:01.040 --> 00:13:05.750
We're engaged in helping
biotechs and technology

00:13:05.750 --> 00:13:10.660
companies and educators
explain very complex things,

00:13:10.660 --> 00:13:15.129
and sometimes not-so-complex
things, to very young kids.

00:13:15.129 --> 00:13:16.670
But I certainly
don't have the market

00:13:16.670 --> 00:13:18.550
cornered on how to do this.

00:13:18.550 --> 00:13:21.390
And as you said, this isn't
really an academic field,

00:13:21.390 --> 00:13:23.956
and there's no grand
unified theory of how

00:13:23.956 --> 00:13:25.872
to do this most effectively.

00:13:25.872 --> 00:13:27.872
I think a lot of things
are out there right now,

00:13:27.872 --> 00:13:32.713
but I'm just excited
to be engaged

00:13:32.713 --> 00:13:35.671
in a conversation about
techniques and strategies

00:13:35.671 --> 00:13:38.629
for doing this, because
they'll help me in my own work,

00:13:38.629 --> 00:13:43.560
and help me understand the
perspective that you guys have

00:13:43.560 --> 00:13:44.065
as well.

00:13:44.065 --> 00:13:47.675
So thanks.

00:13:47.675 --> 00:13:48.870
ELIZABETH CHOE: Great.

00:13:48.870 --> 00:13:51.620
As I said in the beginning,
I run the K12 videos program,

00:13:51.620 --> 00:13:56.477
which is a fairly new initiative
out of the Office of Digital

00:13:56.477 --> 00:13:57.060
Learning here.

00:13:57.060 --> 00:13:58.580
So it's the same
group that oversees

00:13:58.580 --> 00:13:59.640
MITx and OpenCourseWare.

00:14:02.250 --> 00:14:05.050
I produce a series called
Science Out Loud, which

00:14:05.050 --> 00:14:10.680
is essentially trying to mix
education and entertainment,

00:14:10.680 --> 00:14:14.230
having students like you
guys be the face of science

00:14:14.230 --> 00:14:15.790
and the face of engineering.

00:14:15.790 --> 00:14:19.810
And to get people not only
educated and informed, but also

00:14:19.810 --> 00:14:21.930
inspired as well.

00:14:21.930 --> 00:14:25.170
So I've had an interest
in the intersection

00:14:25.170 --> 00:14:27.660
of all that stuff, I guess,
since I took Chris' class.

00:14:27.660 --> 00:14:30.710
When I was an undergrad
I took his DV Lab class.

00:14:30.710 --> 00:14:32.830
But I think it's a
very fascinating area.

00:14:32.830 --> 00:14:34.390
And like Josh said,
it's this market

00:14:34.390 --> 00:14:37.190
that I don't think anyone
really has cornered

00:14:37.190 --> 00:14:41.680
or really-- no one really has
a good grasp on what the best

00:14:41.680 --> 00:14:44.200
way to practice in it is.

00:14:44.200 --> 00:14:46.250
So I think it's a really
interesting problem,

00:14:46.250 --> 00:14:49.480
especially for people at
MIT to think about, as well.

00:14:52.560 --> 00:14:55.580
As some of you guys said,
videos have exploded

00:14:55.580 --> 00:14:57.470
in the last decade or so.

00:14:57.470 --> 00:15:00.020
These are all science
YouTube channels

00:15:00.020 --> 00:15:03.720
that have over a million
subscribers each.

00:15:03.720 --> 00:15:08.040
And it's not just video
exploding in a certain area.

00:15:08.040 --> 00:15:11.680
You have YouTube entertainment
slash educational shows,

00:15:11.680 --> 00:15:17.200
and then you have things that
are very lucrative in our pop

00:15:17.200 --> 00:15:17.700
culture.

00:15:17.700 --> 00:15:20.700
Cosmos was raking in like
five million viewers a week.

00:15:20.700 --> 00:15:24.070
Which isn't a whole
lot compared to some

00:15:24.070 --> 00:15:26.050
of the other primetime
network shows,

00:15:26.050 --> 00:15:30.900
but thinking about the fact
that a science-based show aired

00:15:30.900 --> 00:15:33.400
on the FOX Network
during a primetime slot

00:15:33.400 --> 00:15:36.130
and was raking in those
views is pretty amazing.

00:15:36.130 --> 00:15:38.440
And then you have movies
like Interstellar,

00:15:38.440 --> 00:15:42.540
which are addressing a lot
of real science topics,

00:15:42.540 --> 00:15:46.820
and is also making like $50
million during opening weekend.

00:15:46.820 --> 00:15:49.780
And then you have things
like edX and OpenCourseWare,

00:15:49.780 --> 00:15:52.450
and all these open
education resources that

00:15:52.450 --> 00:15:55.540
are video-based, and
are also reaching

00:15:55.540 --> 00:15:59.790
this incredible audience
and have a huge group

00:15:59.790 --> 00:16:01.730
of people investing in it.

00:16:01.730 --> 00:16:04.880
And these are all very, very
different styles of video,

00:16:04.880 --> 00:16:08.170
but they're all unified by this
theme that they're using video

00:16:08.170 --> 00:16:12.680
and they're accumulating
a huge database of users.

00:16:12.680 --> 00:16:16.070
So something must be
happening with video

00:16:16.070 --> 00:16:17.850
that's making it
compelling for people

00:16:17.850 --> 00:16:21.540
to use to learn
and to entertain.

00:16:21.540 --> 00:16:23.300
What can video do?

00:16:23.300 --> 00:16:25.090
What is it about
video that makes it

00:16:25.090 --> 00:16:27.530
so compelling to use as a tool?

00:16:27.530 --> 00:16:31.410
Educationally, you have stuff
like OpenCourseWare that's

00:16:31.410 --> 00:16:35.570
really great, because people
can pause the video whenever

00:16:35.570 --> 00:16:39.500
they want, they can rewind
and rewatch an explanation.

00:16:39.500 --> 00:16:41.180
And it's also super
scalable, so it

00:16:41.180 --> 00:16:44.330
means that you don't have to
be physically in Cambridge

00:16:44.330 --> 00:16:47.946
to hear Eric Lander talk about
genetics in the 7.012 class.

00:16:47.946 --> 00:16:49.320
You can be anywhere
in the world.

00:16:49.320 --> 00:16:51.010
You can be in Singapore.

00:16:51.010 --> 00:16:54.871
You don't have to be restricted
to the confines of room 26-100,

00:16:54.871 --> 00:16:55.370
right?

00:16:55.370 --> 00:16:59.910
It's a very scalable tool.

00:16:59.910 --> 00:17:03.840
And then in terms of movies,
I mean the thing about movies

00:17:03.840 --> 00:17:08.050
is we have this culture where
people say that the attention

00:17:08.050 --> 00:17:11.890
span for video is like less than
three minutes, yet you and I--

00:17:11.890 --> 00:17:15.210
or at least I spend
$10 to sit for two,

00:17:15.210 --> 00:17:17.130
three hours in a dark room.

00:17:17.130 --> 00:17:19.770
And it's because movies are
these completely immersive

00:17:19.770 --> 00:17:22.099
experiences that
give us a chance

00:17:22.099 --> 00:17:23.910
to sort of escape
into this other world.

00:17:23.910 --> 00:17:26.440
And you don't see
people paying $10

00:17:26.440 --> 00:17:29.750
to sit in a room to listen
to a radio podcast, right?

00:17:29.750 --> 00:17:31.840
There's something
about the integration

00:17:31.840 --> 00:17:34.210
of the visual with the
storytelling and the acting

00:17:34.210 --> 00:17:36.250
that totally immerses
you in this experience,

00:17:36.250 --> 00:17:42.670
and that's a very, very powerful
element that video can do.

00:17:42.670 --> 00:17:45.400
I also think it's a
window into a world

00:17:45.400 --> 00:17:48.000
that you don't necessarily
have access to.

00:17:48.000 --> 00:17:51.420
So whether it's
the world of 26-100

00:17:51.420 --> 00:17:53.660
where Eric Lander is
teaching or if it's

00:17:53.660 --> 00:17:57.950
the world of Middle
Earth-- I just

00:17:57.950 --> 00:18:01.810
went and saw Hobbit III--
you get this chance to look

00:18:01.810 --> 00:18:03.850
into this world that you
don't have access to,

00:18:03.850 --> 00:18:06.090
and that's what video can do.

00:18:06.090 --> 00:18:09.230
And then, finally, especially
in nonfiction video,

00:18:09.230 --> 00:18:11.800
there's this idea of
the trusted guide, which

00:18:11.800 --> 00:18:16.004
is a term that PBS Kids use
to think about new shows

00:18:16.004 --> 00:18:16.670
that they pitch.

00:18:16.670 --> 00:18:18.130
They think about
the person who's

00:18:18.130 --> 00:18:21.290
going to be the host, that it's
more than just the person who's

00:18:21.290 --> 00:18:24.080
going to stand and transfer
information to you.

00:18:24.080 --> 00:18:26.270
It's someone who's
relatable, somebody

00:18:26.270 --> 00:18:28.020
who's a role model,
someone who you really

00:18:28.020 --> 00:18:31.210
trust, that you end
up really growing up

00:18:31.210 --> 00:18:32.400
with people like Bill Nye.

00:18:32.400 --> 00:18:34.450
I don't know if
you guys have shows

00:18:34.450 --> 00:18:36.985
or show hosts that you
remember growing up as kids.

00:18:36.985 --> 00:18:37.860
Mine was Jeff Corwin.

00:18:37.860 --> 00:18:41.030
I'm like obsessed
with Jeff Corwin.

00:18:41.030 --> 00:18:43.240
Does anyone have a
figure that they really

00:18:43.240 --> 00:18:44.350
loved watching growing up?

00:18:47.410 --> 00:18:51.041
Did anyone watch the old
Cosmos with Carl Sagan?

00:18:51.041 --> 00:18:51.540
Yeah?

00:18:51.540 --> 00:18:54.960
I feel like that's a
big one for people here.

00:18:54.960 --> 00:18:57.490
So the trusted guide is
a really powerful thing

00:18:57.490 --> 00:18:59.750
that video can leverage.

00:18:59.750 --> 00:19:02.700
And I think that's a really
big reason why we're here,

00:19:02.700 --> 00:19:04.330
at least the reason
why I'm here,

00:19:04.330 --> 00:19:08.070
is because when you look at
the landscape of trusted guides

00:19:08.070 --> 00:19:12.020
right now on especially
science and technical TV,

00:19:12.020 --> 00:19:16.010
and not just TV but Hank Green
hosts SciShow on YouTube.

00:19:16.010 --> 00:19:19.550
And the landscape of trusted
guide looks very homogeneous.

00:19:19.550 --> 00:19:22.690
And I'm not saying that it's a
bad thing to be a guy at all,

00:19:22.690 --> 00:19:26.920
but I do think that we have
this opportunity with video

00:19:26.920 --> 00:19:31.470
to showcase who the scientists
and engineers really are.

00:19:31.470 --> 00:19:35.520
And this landscape
is building a group

00:19:35.520 --> 00:19:38.700
of advocates who
are going to be sort

00:19:38.700 --> 00:19:42.430
of being the ambassadors to
the public about what you're

00:19:42.430 --> 00:19:44.280
learning about and
what you're studying.

00:19:44.280 --> 00:19:48.180
And we have this opportunity
to create a landscape that's

00:19:48.180 --> 00:19:50.090
just as diverse as
the group of people

00:19:50.090 --> 00:19:52.580
it's trying to represent.

00:19:52.580 --> 00:19:55.930
And it's an opportunity that
I think hasn't necessarily

00:19:55.930 --> 00:19:57.840
been capitalized upon.

00:19:57.840 --> 00:20:00.350
Maybe it's because there
are political things

00:20:00.350 --> 00:20:04.940
and it's hard to invest in a
figure that looks different

00:20:04.940 --> 00:20:09.420
than the science hosts
that we're used to seeing.

00:20:09.420 --> 00:20:13.440
But we have a chance here
at MIT where the people are

00:20:13.440 --> 00:20:15.690
so diverse, not just in
ethnicity and gender,

00:20:15.690 --> 00:20:19.580
but in background and
personalities and interests.

00:20:19.580 --> 00:20:24.150
We have this huge landscape here
that we can tap into and start

00:20:24.150 --> 00:20:27.310
contributing to a picture
that looks a little bit more

00:20:27.310 --> 00:20:31.110
like what science and
engineering really is.

00:20:31.110 --> 00:20:34.140
And the other thing is literacy
in digital media, which

00:20:34.140 --> 00:20:36.420
is the whole idea
of understanding

00:20:36.420 --> 00:20:39.210
your video product as
something more than the thing

00:20:39.210 --> 00:20:40.890
that you just hit
play and watch,

00:20:40.890 --> 00:20:43.400
or understanding making
video as something

00:20:43.400 --> 00:20:46.730
more than just hitting
certain buttons to record

00:20:46.730 --> 00:20:50.090
the present moment, is something
that is going to become

00:20:50.090 --> 00:20:51.600
increasingly relevant.

00:20:51.600 --> 00:20:54.670
I don't know you guys
UROP in labs or anything,

00:20:54.670 --> 00:20:57.870
but a lot of labs right
now have their own cameras.

00:20:57.870 --> 00:20:59.730
Many of you will
probably end up having

00:20:59.730 --> 00:21:02.540
to give like a TED Talk
or some sort of talk

00:21:02.540 --> 00:21:06.160
to the public where it's going
to be more than just conveying

00:21:06.160 --> 00:21:06.730
information.

00:21:06.730 --> 00:21:07.900
Like people were
saying, you want

00:21:07.900 --> 00:21:09.274
to learn more
about how to engage

00:21:09.274 --> 00:21:13.080
an audience in a way that is
going to inspire and engage

00:21:13.080 --> 00:21:14.890
them.

00:21:14.890 --> 00:21:17.460
So at the end of
the day, this class

00:21:17.460 --> 00:21:20.150
is not about becoming
the next Bill Nye.

00:21:20.150 --> 00:21:22.020
That title is just
totally clickbait

00:21:22.020 --> 00:21:24.410
to get people to sign
up for the class.

00:21:24.410 --> 00:21:27.220
And it's not even really
about making videos,

00:21:27.220 --> 00:21:29.010
like I was saying.

00:21:29.010 --> 00:21:31.274
The eventual deliverable
of this class,

00:21:31.274 --> 00:21:32.940
the thing that we're
going to be working

00:21:32.940 --> 00:21:34.850
towards every single
day of this month,

00:21:34.850 --> 00:21:38.670
is to eventually create
around a three-minute episode

00:21:38.670 --> 00:21:42.567
that you host, that
you're on camera for,

00:21:42.567 --> 00:21:44.400
where you talk about a
science or technology

00:21:44.400 --> 00:21:47.790
or engineering/math subject
or topic that you're

00:21:47.790 --> 00:21:49.104
interested in.

00:21:49.104 --> 00:21:50.770
So that's the
deliverable, it's a video.

00:21:50.770 --> 00:21:53.640
But it's not
necessarily about what

00:21:53.640 --> 00:21:56.190
are the technical steps
I need to get there.

00:21:56.190 --> 00:21:59.000
Those are important,
but eventually it's

00:21:59.000 --> 00:22:02.960
about taking those skills
of being a producer

00:22:02.960 --> 00:22:05.310
and transferring them
into your everyday life.

00:22:05.310 --> 00:22:08.010
So maybe some of you
won't make a video

00:22:08.010 --> 00:22:09.944
after this month is
over, and that's OK,

00:22:09.944 --> 00:22:11.860
but hopefully the skills
that you've picked up

00:22:11.860 --> 00:22:14.940
along the way to becoming
an effective video producer

00:22:14.940 --> 00:22:17.700
will help you become a
great advocate for science

00:22:17.700 --> 00:22:18.790
and engineering later on.

00:22:21.570 --> 00:22:24.610
Every video that you guys
will make in every assignment

00:22:24.610 --> 00:22:27.370
that you make, and every
video that's online right now,

00:22:27.370 --> 00:22:28.720
has different objectives.

00:22:28.720 --> 00:22:32.370
Some of you may want to do a
video on physics, some of you

00:22:32.370 --> 00:22:34.860
may want to talk about math.

00:22:34.860 --> 00:22:38.230
But the thing that should
be the overarching objective

00:22:38.230 --> 00:22:40.690
of everything you
make during this month

00:22:40.690 --> 00:22:45.210
should be to address these
three problems in that amorphous

00:22:45.210 --> 00:22:47.600
STEM blob that I was talking
about earlier, that you want

00:22:47.600 --> 00:22:51.030
to open the door to
science and engineering,

00:22:51.030 --> 00:22:53.950
and really love of
learning to everyone.

00:22:53.950 --> 00:22:57.470
So a lot of that will
translate to making sure

00:22:57.470 --> 00:23:00.697
that your script isn't
condescending to your audience,

00:23:00.697 --> 00:23:02.280
making sure that
you're really meeting

00:23:02.280 --> 00:23:03.780
and knowing your
audience where they

00:23:03.780 --> 00:23:07.180
are, encouraging this
lifelong learning.

00:23:07.180 --> 00:23:10.900
We want curiosity to drive a lot
of what your objectives should

00:23:10.900 --> 00:23:11.400
be.

00:23:11.400 --> 00:23:14.690
You want your audience
to become curious.

00:23:14.690 --> 00:23:17.090
And then, of course,
we want your science

00:23:17.090 --> 00:23:19.349
to be legit so you're
educating the public,

00:23:19.349 --> 00:23:20.640
you're spreading STEM literacy.

00:23:23.950 --> 00:23:26.410
What makes a good video?

00:23:26.410 --> 00:23:30.390
Now, this is a quote from one
of the optional readings that's

00:23:30.390 --> 00:23:31.602
listed on the syllabus.

00:23:31.602 --> 00:23:33.060
It's actually really
great, we just

00:23:33.060 --> 00:23:36.170
don't have time in
class to cover it.

00:23:36.170 --> 00:23:37.467
But I love this quote.

00:23:37.467 --> 00:23:39.300
"Learning how to make
really effective video

00:23:39.300 --> 00:23:41.380
is like learning to
speak a second language.

00:23:41.380 --> 00:23:45.120
You have to learn not just what
to say but how what you say

00:23:45.120 --> 00:23:46.700
will be received by others.

00:23:46.700 --> 00:23:49.665
We understand video
better than any humans

00:23:49.665 --> 00:23:50.540
that have ever lived.

00:23:50.540 --> 00:23:53.600
Most of us just
don't speak it well."

00:23:53.600 --> 00:23:55.865
We consume video all the
time, like you were saying

00:23:55.865 --> 00:23:57.290
you watch YouTube videos.

00:23:57.290 --> 00:24:00.060
But that doesn't
necessarily transfer into us

00:24:00.060 --> 00:24:01.870
knowing how to make videos.

00:24:01.870 --> 00:24:03.954
It's the argument
of, oh, teaching

00:24:03.954 --> 00:24:05.870
can't be that hard because
I've been a student

00:24:05.870 --> 00:24:07.350
this whole time, right?

00:24:07.350 --> 00:24:09.680
It's very hard to
extrapolate what

00:24:09.680 --> 00:24:11.440
it is about the practice
of the video that

00:24:11.440 --> 00:24:14.490
makes it good when all
you are used to doing

00:24:14.490 --> 00:24:15.530
is being a consumer.

00:24:15.530 --> 00:24:18.120
So what makes a great video?

00:24:20.952 --> 00:24:22.410
Let's just take
this piece by piece

00:24:22.410 --> 00:24:25.680
and look at best practices
in established video realm.

00:24:25.680 --> 00:24:27.690
So educational videos.

00:24:27.690 --> 00:24:29.760
There was this task
force that MITx

00:24:29.760 --> 00:24:32.840
had a couple years
ago on what makes

00:24:32.840 --> 00:24:35.440
an effective educational
video, and the four traits

00:24:35.440 --> 00:24:39.340
that they came up with were,
one, that they were short,

00:24:39.340 --> 00:24:41.740
that they were digestible
modules, usually

00:24:41.740 --> 00:24:44.080
under 10 minutes.

00:24:44.080 --> 00:24:46.840
Another is that the
learner could interact

00:24:46.840 --> 00:24:51.100
with the speaker of the
video, so maybe the speaker

00:24:51.100 --> 00:24:53.570
would mention a topic
and it would be something

00:24:53.570 --> 00:24:56.120
that the viewer could end
up looking up on their own

00:24:56.120 --> 00:24:59.540
and interacting with.

00:24:59.540 --> 00:25:02.360
The other thing was that
the host had them engaged,

00:25:02.360 --> 00:25:07.230
so it wasn't just this passive
recording of them rambling on

00:25:07.230 --> 00:25:10.570
for an hour, the host would
actually tell the viewer,

00:25:10.570 --> 00:25:14.880
OK, now try this problem
at home, for instance.

00:25:14.880 --> 00:25:18.530
And then the host would
acknowledge the viewers,

00:25:18.530 --> 00:25:23.640
so it wasn't just, here's
this math problem sent out

00:25:23.640 --> 00:25:26.790
to this vague audience, it
was, you try this at home.

00:25:30.310 --> 00:25:33.820
And this is also what a lot of
what I call explainer videos

00:25:33.820 --> 00:25:35.090
do on YouTube.

00:25:35.090 --> 00:25:38.750
I don't know-- you guys must
be familiar with Khan Academy,

00:25:38.750 --> 00:25:41.380
but there are also things
like MIT BLOSSOMS, which

00:25:41.380 --> 00:25:45.630
is a set of videos that's
developed by a group here.

00:25:45.630 --> 00:25:48.230
There's Bozeman Science, who's
this high school teacher out

00:25:48.230 --> 00:25:52.020
in Montana, and he does tutorial
videos on all the AP science

00:25:52.020 --> 00:25:53.060
subjects.

00:25:53.060 --> 00:25:55.580
Tyler DeWitt, a former
grad student here, he

00:25:55.580 --> 00:25:57.140
does chemistry tutorial videos.

00:25:57.140 --> 00:25:59.820
And they're all
very, very successful

00:25:59.820 --> 00:26:03.380
because they take an
audience that's already

00:26:03.380 --> 00:26:05.890
motivated in learning
something and they're

00:26:05.890 --> 00:26:06.900
sort of one-stop shops.

00:26:06.900 --> 00:26:11.430
So how do I calculate the
molar mass of this compound?

00:26:11.430 --> 00:26:13.270
You can just go to
one of Tyler's videos

00:26:13.270 --> 00:26:15.500
and learn how to do it.

00:26:15.500 --> 00:26:20.370
It's very misleading sometimes,
though, because people see it

00:26:20.370 --> 00:26:24.030
and they often mistake it for
it being a direct recording

00:26:24.030 --> 00:26:25.260
of an instruction.

00:26:25.260 --> 00:26:28.790
And so they say, oh,
these explainer videos

00:26:28.790 --> 00:26:31.760
are much easier to do than
big budget productions.

00:26:31.760 --> 00:26:33.290
And that's not necessarily true.

00:26:33.290 --> 00:26:36.530
They still spend weeks
and weeks writing a script

00:26:36.530 --> 00:26:38.790
and developing exactly
what they're going to say.

00:26:38.790 --> 00:26:41.250
And they're so
effective because it's

00:26:41.250 --> 00:26:44.680
a very talented host, a
very talented teacher who

00:26:44.680 --> 00:26:47.330
is engaging their audience in
a way that helps them achieve

00:26:47.330 --> 00:26:48.590
mastery of the subject.

00:26:48.590 --> 00:26:50.470
So it gives them
learning confidence.

00:26:50.470 --> 00:26:53.220
People love Sal Khan
because they really

00:26:53.220 --> 00:26:55.560
feel connected to
him beyond sort

00:26:55.560 --> 00:26:58.120
of this robotic voice that's
telling them how to calculate

00:26:58.120 --> 00:26:59.790
the derivative of
something, and that's

00:26:59.790 --> 00:27:02.000
a very intentional thing
I think that he does.

00:27:06.000 --> 00:27:09.585
Now, for entertainment, even
within the world of YouTuber

00:27:09.585 --> 00:27:11.680
or within the world of
entertaining videos,

00:27:11.680 --> 00:27:15.070
there are subcategories that
have their own best practices.

00:27:15.070 --> 00:27:16.710
But in general,
for entertainment,

00:27:16.710 --> 00:27:20.040
the thing that is most
important, at least I think,

00:27:20.040 --> 00:27:22.580
is building an emotional
connection with your audience.

00:27:22.580 --> 00:27:26.030
And that's something that is
repeated by some of the folks

00:27:26.030 --> 00:27:28.480
that I'll be quoting
in a little bit.

00:27:28.480 --> 00:27:30.480
And in terms of
viral video, the way

00:27:30.480 --> 00:27:34.010
to best establish that
emotional connection

00:27:34.010 --> 00:27:37.240
is through authenticity.

00:27:37.240 --> 00:27:39.410
By authenticity I
mean when you see

00:27:39.410 --> 00:27:41.500
a video that goes
viral on YouTube,

00:27:41.500 --> 00:27:43.040
it's not necessarily
something that

00:27:43.040 --> 00:27:44.530
has a super corporate sheen.

00:27:44.530 --> 00:27:46.130
It's not really polished.

00:27:46.130 --> 00:27:49.610
A lot of times it just looks
like a very janky video

00:27:49.610 --> 00:27:51.620
that someone took
with their iPhone.

00:27:51.620 --> 00:27:54.190
And that in some
ways helps people

00:27:54.190 --> 00:27:57.402
feel really connected to the
material that they're watching.

00:27:57.402 --> 00:27:58.860
And you have to be
careful with it.

00:27:58.860 --> 00:28:02.620
But I did want to show a couple
clips of two science videos

00:28:02.620 --> 00:28:06.000
that have each raked-- I
think the first one has

00:28:06.000 --> 00:28:07.680
over six million
and the second one

00:28:07.680 --> 00:28:09.520
has almost 10 million views.

00:28:09.520 --> 00:28:12.300
And we'll just
watch part of each.

00:28:19.258 --> 00:28:21.510
CRAZY RUSSIAN HACKER: All
right, here is what we need.

00:28:21.510 --> 00:28:26.110
Empty soda cans and put
a little bit of water.

00:28:26.110 --> 00:28:30.850
Just a little bit, so it
will boil down, you know?

00:28:30.850 --> 00:28:35.030
And then turn on the stove.

00:28:35.030 --> 00:28:38.830
While this gets ready we're
going to make a nice bowl.

00:28:38.830 --> 00:28:45.070
So right here we've got
our ice water already.

00:28:45.070 --> 00:28:50.190
And you see how water is
boiling and steam coming out.

00:28:50.190 --> 00:28:52.670
I don't know if you can
see it, but this steam

00:28:52.670 --> 00:28:54.610
is coming out right now.

00:28:54.610 --> 00:28:58.430
So we're going to
get it and drop it.

00:28:58.430 --> 00:29:01.090
Use the tongs, don't use hands.

00:29:01.090 --> 00:29:05.020
Get it and drop it upside-down.

00:29:05.020 --> 00:29:08.150
That kind of fell.

00:29:08.150 --> 00:29:09.710
Let's start with this one.

00:29:13.830 --> 00:29:14.950
So are you guys ready?

00:29:23.800 --> 00:29:25.610
You see?

00:29:25.610 --> 00:29:27.630
They called this implosion.

00:29:27.630 --> 00:29:30.450
I want you to tell
me why that happens.

00:29:34.460 --> 00:29:36.600
Why does it implode like that?

00:29:36.600 --> 00:29:38.740
So we've got this pan.

00:29:38.740 --> 00:29:40.450
Here you go, a pan.

00:29:40.450 --> 00:29:43.210
And just we're going
to turn this on.

00:29:43.210 --> 00:29:45.660
But remember, safety is first.

00:29:45.660 --> 00:29:48.640
Kids, you're going to
need adults' permission.

00:29:48.640 --> 00:29:51.662
So and there we're going
to leave it for a minute.

00:29:51.662 --> 00:29:53.370
We're going to put a
little bit of water.

00:29:53.370 --> 00:29:56.530
Do you see how water is boiling
now because it's too hot?

00:30:06.710 --> 00:30:10.730
So all the water is
gone, boiled out.

00:30:10.730 --> 00:30:13.480
And let's leave it for
another two minutes.

00:30:13.480 --> 00:30:15.670
So it's been about two minutes.

00:30:15.670 --> 00:30:17.420
You see how hot it is?

00:30:17.420 --> 00:30:22.100
Let's put just a little bit
of water, just little drops.

00:30:25.180 --> 00:30:30.850
You see how all these drops just
like spinning around and not

00:30:30.850 --> 00:30:32.430
boiling out?

00:30:32.430 --> 00:30:35.300
I want you to comment
and tell me why.

00:30:35.300 --> 00:30:38.382
Let's drop some more.

00:30:38.382 --> 00:30:40.340
ELIZABETH CHOE: So the
thing is like 10 minutes

00:30:40.340 --> 00:30:41.990
long so I'm not
going to show it.

00:30:41.990 --> 00:30:44.900
But this video, which I
personally cannot stand

00:30:44.900 --> 00:30:47.980
watching, this thing has
gotten over five million views

00:30:47.980 --> 00:30:48.900
on YouTube.

00:30:48.900 --> 00:30:52.300
And Crazy Russian Hacker,
who's the user who created it,

00:30:52.300 --> 00:30:54.590
he has millions and
millions of subscribers.

00:30:54.590 --> 00:30:58.150
I have the co-worker
whose son is 12 years old

00:30:58.150 --> 00:31:01.540
and he loves Crazy
Russian Hacker.

00:31:01.540 --> 00:31:04.760
And I don't know how you
guys feel about the video.

00:31:04.760 --> 00:31:07.540
Were there any certain elements
that you noticed about it

00:31:07.540 --> 00:31:09.980
that either you liked
or you understood why

00:31:09.980 --> 00:31:11.520
people would like it so much?

00:31:17.520 --> 00:31:18.479
Yes, John.

00:31:18.479 --> 00:31:21.020
JONATHAN: He asked the audience
to explain what was going on,

00:31:21.020 --> 00:31:25.020
so that encouraged
feedback and more posts

00:31:25.020 --> 00:31:27.496
by commenting on the video.

00:31:27.496 --> 00:31:29.370
ELIZABETH CHOE: Yeah,
so there's that element

00:31:29.370 --> 00:31:33.300
of not only acknowledging
your audience but engaging it.

00:31:33.300 --> 00:31:36.280
And that's something that
a lot of YouTube videos do.

00:31:36.280 --> 00:31:38.810
Maybe it's to get more
comments, but it certainly

00:31:38.810 --> 00:31:40.620
works a lot of the time.

00:31:40.620 --> 00:31:41.220
Yes.

00:31:41.220 --> 00:31:42.040
PAUL FOLINO: That
video seemed like it

00:31:42.040 --> 00:31:44.010
was kind of-- it wasn't
necessarily scripted,

00:31:44.010 --> 00:31:46.070
so it kind of shows
that he really

00:31:46.070 --> 00:31:49.340
knows what he's talking
about, he's not robotically

00:31:49.340 --> 00:31:51.428
following a script.

00:31:51.428 --> 00:31:53.970
Shows he knows a little
bit about what he's doing.

00:31:53.970 --> 00:31:55.761
ELIZABETH CHOE: And
he's quite a character.

00:31:55.761 --> 00:31:58.110
I mean, Crazy Russian Hacker
has a huge brand, right?

00:31:58.110 --> 00:32:00.020
Like as soon as
he starts talking

00:32:00.020 --> 00:32:02.330
you know that it's a Crazy
Russian Hacker video.

00:32:02.330 --> 00:32:04.607
And he's kind of outrageous.

00:32:04.607 --> 00:32:06.190
Which is why it's
hard to repeat that.

00:32:06.190 --> 00:32:08.170
It would be hard--
if I replicated

00:32:08.170 --> 00:32:12.290
that exact same video, it
would probably not go viral.

00:32:12.290 --> 00:32:16.060
So his whole persona
and the way that he

00:32:16.060 --> 00:32:19.266
has this sort of unpolished
look about his videos

00:32:19.266 --> 00:32:21.640
is actually maybe one of the
reasons why it's compelling.

00:32:21.640 --> 00:32:23.122
Were you going to say
something, Yuliya?

00:32:23.122 --> 00:32:24.104
YULIYA KLOCHAN: Yeah, I
think it's also relatable.

00:32:24.104 --> 00:32:26.559
He dropped the can
the first time,

00:32:26.559 --> 00:32:30.547
so that tells the viewers that
they can also make mistakes.

00:32:30.547 --> 00:32:32.130
ELIZABETH CHOE: A
lot of online videos

00:32:32.130 --> 00:32:34.340
have this single-take format.

00:32:34.340 --> 00:32:37.580
So instead of having two
cameras like these guys

00:32:37.580 --> 00:32:40.410
set up where you're switching
back and forth between angles,

00:32:40.410 --> 00:32:43.340
he kind of just held his
iPhone where he was, right,

00:32:43.340 --> 00:32:45.360
or whatever camera,
and followed along.

00:32:45.360 --> 00:32:48.025
So you actually feel like
you're right there with him.

00:32:48.025 --> 00:32:50.220
You feel like you're in
the kitchen with him.

00:32:50.220 --> 00:32:53.400
There are no cuts back
and forth to him talking.

00:32:53.400 --> 00:32:55.650
It's just one long,
continuous take

00:32:55.650 --> 00:32:58.610
with just a couple mess-ups
taken out in between.

00:33:02.159 --> 00:33:03.950
JOSH CHEONG: Even though
he asked comments,

00:33:03.950 --> 00:33:06.930
I'm very sure these comments
are not all legitimate comments.

00:33:06.930 --> 00:33:10.060
I've very sure there will be
probably one or two people who

00:33:10.060 --> 00:33:11.990
purposely are trolls
and probably say,

00:33:11.990 --> 00:33:13.847
oh, this is black
magic or something,

00:33:13.847 --> 00:33:16.180
and then someone will comment,
and the virality probably

00:33:16.180 --> 00:33:18.390
gives him the extra
few million views.

00:33:18.390 --> 00:33:19.960
ELIZABETH CHOE: Yeah, yeah.

00:33:19.960 --> 00:33:23.120
Logan Smalley, who's the
head of TED-Ed-- you guys

00:33:23.120 --> 00:33:24.380
have seen TED Talks, right?

00:33:24.380 --> 00:33:27.060
Have you ever seen
TED-Ed videos?

00:33:27.060 --> 00:33:30.790
They do a spin-off where they
have animators and writers

00:33:30.790 --> 00:33:31.920
partner up.

00:33:31.920 --> 00:33:34.390
He's the one who
directs TED-Ed, and he

00:33:34.390 --> 00:33:38.460
had this talk where he was
saying how a video online has

00:33:38.460 --> 00:33:41.055
a beginning, middle, and end,
but the beginning, middle,

00:33:41.055 --> 00:33:43.000
and end isn't what's
in the video itself.

00:33:43.000 --> 00:33:45.470
The beginning is the tweet
that announces the video,

00:33:45.470 --> 00:33:47.570
the middle is the video
itself, and the end

00:33:47.570 --> 00:33:49.670
it is all the
conversation that takes

00:33:49.670 --> 00:33:53.660
place afterwards in the comments
online and social media.

00:33:53.660 --> 00:33:56.790
And so with things like
Crazy Russian Hacker,

00:33:56.790 --> 00:33:59.650
the end, the conversation,
is almost just as important

00:33:59.650 --> 00:34:01.630
or just as much a
part of the experience

00:34:01.630 --> 00:34:03.899
as the 10-minute video itself.

00:34:03.899 --> 00:34:05.440
I wanted to show
you one other video.

00:34:05.440 --> 00:34:10.199
This is from Smarter Every
Day, and this has also

00:34:10.199 --> 00:34:11.289
over five million views.

00:34:11.289 --> 00:34:12.830
DESTIN SANDLIN: Hey,
it's me, Destin.

00:34:12.830 --> 00:34:14.246
Welcome back to
Smarter Every Day.

00:34:14.246 --> 00:34:17.040
So you've probably observed
that cats almost always

00:34:17.040 --> 00:34:18.540
land on their feet.

00:34:18.540 --> 00:34:20.730
Today's question is why.

00:34:20.730 --> 00:34:23.389
Like most simple questions,
there's a very complex answer.

00:34:23.389 --> 00:34:25.380
For instance, let me
reword this question.

00:34:25.380 --> 00:34:28.060
How does a cat go
from feet up to feet

00:34:28.060 --> 00:34:30.650
down in a falling
reference frame

00:34:30.650 --> 00:34:32.780
without violating the
conservation of angular

00:34:32.780 --> 00:34:33.929
momentum?

00:34:33.929 --> 00:34:36.334
Now, I've studied free-falling
bodies-- my own, in fact--

00:34:36.334 --> 00:34:37.750
in several different
environments.

00:34:37.750 --> 00:34:39.889
And once I get my angular
rotation started in one

00:34:39.889 --> 00:34:41.746
direction, I can't stop it.

00:34:41.746 --> 00:34:43.620
Today we're going to
use a high-speed camera.

00:34:43.620 --> 00:34:45.350
We're not going to use Ally
because this is my daughter's

00:34:45.350 --> 00:34:46.558
cat, I don't want to hurt it.

00:34:46.558 --> 00:34:48.270
We're going to use a stunt cat.

00:34:48.270 --> 00:34:50.699
Let me introduce you
to Gigi, the stunt cat.

00:34:56.710 --> 00:34:59.250
I'll just flip
the video vertical

00:34:59.250 --> 00:35:00.630
and then motion-track the cat.

00:35:00.630 --> 00:35:02.714
It's just going to take a
lot more effort in post.

00:35:02.714 --> 00:35:04.421
We're going to try to
do it in a way that

00:35:04.421 --> 00:35:05.520
doesn't make anybody mad.

00:35:05.520 --> 00:35:08.580
That's pretty hard to do.

00:35:08.580 --> 00:35:09.871
You got to drop a cat.

00:35:09.871 --> 00:35:10.370
Ready, Gigi?

00:35:14.305 --> 00:35:16.179
Checking out the high-speed
data there, Gigi?

00:35:36.831 --> 00:35:38.830
OK, the first thing a cat
does when it's falling

00:35:38.830 --> 00:35:40.640
is try to figure
out which way is up.

00:35:40.640 --> 00:35:43.700
It does this either with a gyro
in the ear or with its eyes.

00:35:51.960 --> 00:35:53.610
Ready to talk cat physics?

00:35:53.610 --> 00:35:54.370
All right.

00:35:54.370 --> 00:35:56.786
So check out this footage I
captured with the Phantom Miro

00:35:56.786 --> 00:35:58.500
while Gigi goes to
get a drink of water.

00:35:58.500 --> 00:36:00.340
So here's what's interesting
about this to me.

00:36:00.340 --> 00:36:02.256
If you'll notice, at the
beginning of the drop

00:36:02.256 --> 00:36:03.760
the cat is not rotating.

00:36:03.760 --> 00:36:05.890
Halfway through the drop
the cat is rotating,

00:36:05.890 --> 00:36:09.130
and then at the very end
Gigi somehow stops rotating.

00:36:09.130 --> 00:36:11.630
Newton's first law says
that an object at rest

00:36:11.630 --> 00:36:14.780
will stay at rest unless
acted on by an external force.

00:36:14.780 --> 00:36:17.080
I see no external
forces on this cat.

00:36:17.080 --> 00:36:18.420
So what's happening here?

00:36:18.420 --> 00:36:19.950
It's not making sense to me.

00:36:19.950 --> 00:36:22.122
OK, so in order to really
get the right data,

00:36:22.122 --> 00:36:24.455
we're going to have to drop
her 90 degrees out of phase.

00:36:24.455 --> 00:36:25.770
Ready, girl?

00:36:25.770 --> 00:36:27.220
This time watch her tail.

00:36:27.220 --> 00:36:29.400
Three, two, one.

00:36:58.840 --> 00:37:00.530
OK, so you think
you figured it out?

00:37:00.530 --> 00:37:01.460
Check this out.

00:37:01.460 --> 00:37:04.480
You probably noticed that when
the cat was falling her tail

00:37:04.480 --> 00:37:06.800
was rotating in the
direction opposite of where

00:37:06.800 --> 00:37:08.230
her body was rotating.

00:37:08.230 --> 00:37:11.480
What's interesting about that
is that that's not how it works.

00:37:11.480 --> 00:37:14.410
In fact, even bobtail
cats can do this.

00:37:14.410 --> 00:37:16.020
It's called the cat
righting reflex.

00:37:16.020 --> 00:37:17.520
I'll prove it to you.

00:37:17.520 --> 00:37:19.280
I came across some
video from the '60s

00:37:19.280 --> 00:37:21.320
when the Air Force was
researching microgravity

00:37:21.320 --> 00:37:23.200
for future astronauts.

00:37:23.200 --> 00:37:26.110
Turns out they took some
cats up on parabolic flights.

00:37:26.110 --> 00:37:29.130
He turns to rotate his tail to
flip over, but it doesn't work.

00:37:29.130 --> 00:37:31.092
He just ends up nutating wildly.

00:37:31.092 --> 00:37:32.550
Then he does
something interesting.

00:37:32.550 --> 00:37:34.756
He takes his back
and he bends it.

00:37:34.756 --> 00:37:36.880
And when he bends his back
and then creates motion,

00:37:36.880 --> 00:37:38.713
something interesting happens.

00:37:38.713 --> 00:37:41.407
Ahhh, now we're
getting somewhere.

00:37:41.407 --> 00:37:43.490
So let me show you one
more cat flip with the Miro

00:37:43.490 --> 00:37:44.573
and we'll figure this out.

00:37:48.250 --> 00:37:50.762
OK, the arched back ends
up being pretty important.

00:37:50.762 --> 00:37:52.345
What he does is he
divides his body up

00:37:52.345 --> 00:37:54.115
into two separate
rotational axes that

00:37:54.115 --> 00:37:55.700
are tilted from one another.

00:37:55.700 --> 00:37:57.711
When he's released, he
pulls his front paws in

00:37:57.711 --> 00:37:58.960
and does the ice skater trick.

00:37:58.960 --> 00:38:01.220
He decreases his moment
of inertia in the front

00:38:01.220 --> 00:38:02.840
so he can spin fast up there.

00:38:02.840 --> 00:38:05.020
But in the back he pushes
his legs away from him,

00:38:05.020 --> 00:38:06.890
increasing his
moment of inertia.

00:38:06.890 --> 00:38:09.126
So a really large
twist in the front

00:38:09.126 --> 00:38:10.750
equals a really small
twist in the back

00:38:10.750 --> 00:38:13.520
in the opposite direction,
and the torques equal out.

00:38:13.520 --> 00:38:15.730
So as soon as he gets his
front paws in under him,

00:38:15.730 --> 00:38:17.834
all he has to do is
extend those legs back out

00:38:17.834 --> 00:38:19.250
to increase that
moment of inertia

00:38:19.250 --> 00:38:22.560
and stop the front twist,
and extend his back legs

00:38:22.560 --> 00:38:24.430
along that rear axis.

00:38:24.430 --> 00:38:26.650
That allows him to twist
those around really fast.

00:38:26.650 --> 00:38:28.233
And then all he has
to do is pull them

00:38:28.233 --> 00:38:31.520
back in under his body and
then extend all four legs,

00:38:31.520 --> 00:38:32.780
and brace for impact.

00:38:34.844 --> 00:38:36.260
ELIZABETH CHOE:
All right, so very

00:38:36.260 --> 00:38:39.800
different from Crazy Russian
Hacker but just as popular.

00:38:39.800 --> 00:38:42.070
I personally really
like Smarter Every Day.

00:38:42.070 --> 00:38:45.444
I think he's one of
the best hosts, period.

00:38:45.444 --> 00:38:47.360
You can disagree with
me, that's totally fine.

00:38:47.360 --> 00:38:49.930
But the thing I like about
him is even though he's

00:38:49.930 --> 00:38:51.360
maybe a little bit
more scripted--

00:38:51.360 --> 00:38:53.130
he doesn't say um a
lot, he doesn't really

00:38:53.130 --> 00:38:57.500
mess up as much-- I still feel
like Destin is talking to me,

00:38:57.500 --> 00:39:00.060
that it's just this random
guy in his backyard.

00:39:00.060 --> 00:39:03.360
He happens to be a
rocket scientist down

00:39:03.360 --> 00:39:07.470
at NASA or some similar
engineering firm in Alabama,

00:39:07.470 --> 00:39:09.220
so he obviously knows
his stuff very well.

00:39:09.220 --> 00:39:11.640
But there's something
about him that's still

00:39:11.640 --> 00:39:13.800
very relatable, very natural.

00:39:13.800 --> 00:39:16.280
He seems like who
he is on screen

00:39:16.280 --> 00:39:18.130
is who he is in real life.

00:39:18.130 --> 00:39:21.824
Did anyone have any particular
aspects about that video

00:39:21.824 --> 00:39:22.990
that they liked or disliked?

00:39:25.890 --> 00:39:27.140
Or anything that they noticed?

00:39:31.792 --> 00:39:33.167
KENNETH CHEAH: I
think he thought

00:39:33.167 --> 00:39:39.715
about how [INAUDIBLE] tail
was what affected the cat's

00:39:39.715 --> 00:39:43.152
movement, allowed the cat to--
but he mentioned that it wasn't

00:39:43.152 --> 00:39:45.442
the tail at all,
so then that made

00:39:45.442 --> 00:39:48.128
us more interested in wanting
to finish the rest of the video.

00:39:48.128 --> 00:39:49.044
ELIZABETH CHOE: Mm-hm.

00:39:49.044 --> 00:39:52.290
He anticipated the misconception
[INAUDIBLE] the cat.

00:39:52.290 --> 00:39:53.890
And that's actually
a really big tool

00:39:53.890 --> 00:39:56.560
that you can use in your
videos to hook people in.

00:39:56.560 --> 00:39:59.990
And Ceri, you take that
summer MIT course, right?

00:39:59.990 --> 00:40:01.740
Where you were
specifically addressing

00:40:01.740 --> 00:40:03.022
misconceptions in biology?

00:40:03.022 --> 00:40:05.355
CERI RILEY: Yeah, I actually
took a summer class at MIT,

00:40:05.355 --> 00:40:07.710
and I personally made a video.

00:40:07.710 --> 00:40:09.620
But our whole
objective of the class

00:40:09.620 --> 00:40:15.147
was to choose a topic in
science that people often

00:40:15.147 --> 00:40:16.230
have misconceptions about.

00:40:16.230 --> 00:40:20.350
So some people did videos
on you catch a cold

00:40:20.350 --> 00:40:21.910
if you're outside in the cold.

00:40:21.910 --> 00:40:25.150
And then mine was your
deoxygenated blood

00:40:25.150 --> 00:40:27.465
in diagrams is
always shown as blue

00:40:27.465 --> 00:40:29.930
and so people think our
blood is blue sometimes,

00:40:29.930 --> 00:40:32.980
but it's always
different shades of red.

00:40:32.980 --> 00:40:35.934
Yeah, and so our entire goal
was to figure out not only

00:40:35.934 --> 00:40:37.350
the real science
behind the topic,

00:40:37.350 --> 00:40:39.170
but how to explain
it in a way that

00:40:39.170 --> 00:40:41.181
debunks the myths or
the misconceptions

00:40:41.181 --> 00:40:42.769
that people have about them.

00:40:42.769 --> 00:40:44.310
ELIZABETH CHOE: And
I don't know what

00:40:44.310 --> 00:40:45.990
it is about
misconceptions, but it

00:40:45.990 --> 00:40:50.000
does seem to be something
that not necessary predicates

00:40:50.000 --> 00:40:55.530
but can help launch a video into
being something more engaging.

00:40:55.530 --> 00:40:59.800
And maybe it is because it
taps into the audience itself

00:40:59.800 --> 00:41:03.050
and it becomes more relatable,
because it's acknowledging,

00:41:03.050 --> 00:41:05.122
hey, this is what
you actually think.

00:41:05.122 --> 00:41:06.580
And it becomes
surprising and maybe

00:41:06.580 --> 00:41:08.740
more memorable in that way.

00:41:08.740 --> 00:41:13.170
That you're more likely to
remember that a cat doesn't use

00:41:13.170 --> 00:41:16.650
its tail to sort of
out-balance the rotation

00:41:16.650 --> 00:41:19.220
that it feels when it's flipping
but actually scrunches up.

00:41:19.220 --> 00:41:20.850
I mean, I'm going to
remember that way more

00:41:20.850 --> 00:41:23.280
than I'm going to remember a
single one of my 801 lectures

00:41:23.280 --> 00:41:26.424
on rotational physics.

00:41:26.424 --> 00:41:28.090
So that's just something
to think about.

00:41:30.671 --> 00:41:32.170
Now, something I
do want to mention,

00:41:32.170 --> 00:41:34.440
and this is a conversation
that Chris and I have

00:41:34.440 --> 00:41:40.510
a lot, which is that people
often confuse correlation

00:41:40.510 --> 00:41:41.660
for causation, right?

00:41:41.660 --> 00:41:44.450
They think, oh, well, all
these videos did really well

00:41:44.450 --> 00:41:46.620
so I just need to
make a crappy video

00:41:46.620 --> 00:41:48.810
and do really bad
lighting and just

00:41:48.810 --> 00:41:51.375
be really terrible on
camera, and it'll go viral,

00:41:51.375 --> 00:41:52.110
it'll be great.

00:41:52.110 --> 00:41:53.580
It'll be relatable
and authentic.

00:41:53.580 --> 00:41:55.210
And that's not
necessarily true, right?

00:41:55.210 --> 00:41:58.040
Low production value
is not equal to

00:41:58.040 --> 00:42:02.020
and does not predict
a viral video.

00:42:02.020 --> 00:42:05.420
If any of us tried to
recreate Crazy Russian Hacker

00:42:05.420 --> 00:42:07.784
it would probably not go
viral for the same reasons

00:42:07.784 --> 00:42:09.200
that I talked about
earlier, which

00:42:09.200 --> 00:42:11.690
is that there are a
lot of elements that

00:42:11.690 --> 00:42:16.980
go in play into creating
something beyond what you see

00:42:16.980 --> 00:42:19.810
on screen when
you're watching it.

00:42:19.810 --> 00:42:23.900
That it's OK to have
good production.

00:42:23.900 --> 00:42:25.790
Smarter Every Day is
actually pretty decent,

00:42:25.790 --> 00:42:27.930
and when you see his newer
videos, his camera work,

00:42:27.930 --> 00:42:28.780
it's pretty good.

00:42:28.780 --> 00:42:31.330
And you can tell that he's
gotten new equipment and things

00:42:31.330 --> 00:42:31.830
like that.

00:42:31.830 --> 00:42:34.060
And it doesn't take away
at all from the experience,

00:42:34.060 --> 00:42:36.790
from the authenticity
of the video.

00:42:36.790 --> 00:42:40.075
That authenticity starts
at the core of the host,

00:42:40.075 --> 00:42:42.490
at the way they're
creating it, the reasons

00:42:42.490 --> 00:42:43.980
why they're creating the video.

00:42:43.980 --> 00:42:47.170
And it's not created by the
conditions of the production

00:42:47.170 --> 00:42:48.620
itself, necessarily.

00:42:48.620 --> 00:42:53.170
It's just that the conditions
don't hinder the authenticity.

00:42:53.170 --> 00:42:55.220
But please don't mistake.

00:42:55.220 --> 00:42:59.230
Bad video production does not
help you get to viral video.

00:42:59.230 --> 00:43:03.600
It just doesn't stop
you from getting there.

00:43:03.600 --> 00:43:07.010
Now, for YouTube-- and we sort
of previewed this a little bit

00:43:07.010 --> 00:43:08.580
with the two videos
that we watched--

00:43:08.580 --> 00:43:10.496
there are a couple traits
about YouTube videos

00:43:10.496 --> 00:43:13.410
that I think make them
really great for learning

00:43:13.410 --> 00:43:16.950
and for educating,
and for successfully

00:43:16.950 --> 00:43:17.870
engaging an audience.

00:43:17.870 --> 00:43:20.470
The first being just
sort of the format

00:43:20.470 --> 00:43:21.900
in which they're written.

00:43:21.900 --> 00:43:26.350
A lot of viral YouTube videos
or videos that are well known,

00:43:26.350 --> 00:43:28.620
or a lot of SciShow
videos, for instance,

00:43:28.620 --> 00:43:31.410
they follow this format
of asking the why, what,

00:43:31.410 --> 00:43:32.720
and how questions.

00:43:32.720 --> 00:43:36.030
So you'll notice that the
Smarter Every Day video was not

00:43:36.030 --> 00:43:41.230
titled gravitational
physics, Newton's second law,

00:43:41.230 --> 00:43:42.900
or rotational dynamics, right?

00:43:42.900 --> 00:43:46.670
It was why does a cat fall on
its feet when it falls down,

00:43:46.670 --> 00:43:47.170
right?

00:43:47.170 --> 00:43:49.140
It's contextualizing
the question.

00:43:49.140 --> 00:43:50.790
It's making it relatable.

00:43:50.790 --> 00:43:53.960
It's sort of tapping
into the innate curiosity

00:43:53.960 --> 00:43:56.660
that people have, even
if they hate science.

00:43:56.660 --> 00:44:00.492
People who watch that video
are not physics majors.

00:44:00.492 --> 00:44:01.825
And it makes them more sharable.

00:44:01.825 --> 00:44:03.810
It makes them more memorable.

00:44:03.810 --> 00:44:07.150
And I think it makes it a
little bit more conducive

00:44:07.150 --> 00:44:08.940
to this idea of
retrieval learning,

00:44:08.940 --> 00:44:11.940
that people aren't going to
just end the video right there,

00:44:11.940 --> 00:44:12.440
right?

00:44:12.440 --> 00:44:13.990
They're going to maybe
share it with their friends

00:44:13.990 --> 00:44:14.790
or they're going
to talk about it

00:44:14.790 --> 00:44:16.380
with their teacher at school.

00:44:16.380 --> 00:44:20.610
Which is such a powerful
thing to happen with learning.

00:44:20.610 --> 00:44:23.190
I think that's what really
everyone's objective is

00:44:23.190 --> 00:44:24.710
as a teacher, or
a lot of teachers

00:44:24.710 --> 00:44:27.544
have this objective, that
they don't want the lessons

00:44:27.544 --> 00:44:28.960
that they're
teaching to just stop

00:44:28.960 --> 00:44:30.400
once people leave the room.

00:44:30.400 --> 00:44:32.200
They want people to
keep thinking about it

00:44:32.200 --> 00:44:34.810
and thinking about it in
the context of their life

00:44:34.810 --> 00:44:36.750
outside of the classroom.

00:44:36.750 --> 00:44:38.861
So this format really
aids in doing that.

00:44:38.861 --> 00:44:40.360
And I have a couple
of videos I want

00:44:40.360 --> 00:44:42.740
to show you guys, the first
being from AsapSCIENCE.

00:44:45.899 --> 00:44:46.940
ASAPSCIENCE: Ahhh, sleep.

00:44:46.940 --> 00:44:49.260
You can never have
enough of it, it seems.

00:44:49.260 --> 00:44:51.150
In fact, sometimes
it literally feels

00:44:51.150 --> 00:44:52.710
like you aren't getting enough.

00:44:52.710 --> 00:44:55.280
But what if you stopped
sleeping altogether?

00:44:55.280 --> 00:44:57.260
Strangely, science
understands relatively

00:44:57.260 --> 00:45:00.420
little about why we sleep or how
it evolved in the first place.

00:45:00.420 --> 00:45:03.310
After all, laying unconscious
and dormant for hours on end

00:45:03.310 --> 00:45:06.850
while predators lurk hardly
seems advantageous or smart.

00:45:06.850 --> 00:45:09.200
But we have discovered
a few correlations.

00:45:09.200 --> 00:45:11.990
For example, adults who sleep
between six to eight hours

00:45:11.990 --> 00:45:13.850
a night tend to live longer.

00:45:13.850 --> 00:45:16.610
Excessive sleep, however,
can lead to medical problems,

00:45:16.610 --> 00:45:19.420
including cardiovascular
disease and diabetes.

00:45:19.420 --> 00:45:21.870
Similarly, chronic
sleep deprivation

00:45:21.870 --> 00:45:24.750
has been linked to aspects
of cardiovascular disease,

00:45:24.750 --> 00:45:27.320
obesity, depression,
and even brain damage.

00:45:27.320 --> 00:45:29.650
But what if you stopped
sleeping right now?

00:45:29.650 --> 00:45:32.580
Well, after your first sleepless
night, your mesolimbic system

00:45:32.580 --> 00:45:35.480
becomes stimulated and
dopamine runs rampant.

00:45:35.480 --> 00:45:38.290
And this may actually trigger
some extra energy, motivation,

00:45:38.290 --> 00:45:40.490
positivity, and even sex drive.

00:45:40.490 --> 00:45:43.020
Sounds appealing, but
it's a slippery slope.

00:45:43.020 --> 00:45:44.680
Your brain slowly
begins to shut off

00:45:44.680 --> 00:45:47.050
the regions responsible
for planning and evaluating

00:45:47.050 --> 00:45:50.090
decisions, leading to
more impulsive behavior.

00:45:50.090 --> 00:45:52.180
Once exhaustion sets
in, you'll find yourself

00:45:52.180 --> 00:45:54.510
with slower reaction
times, and reduced

00:45:54.510 --> 00:45:56.590
perceptual and
cognitive functions.

00:45:56.590 --> 00:45:58.620
After a day or two
of no sleep, the body

00:45:58.620 --> 00:46:01.590
loses its ability to
properly metabolize glucose,

00:46:01.590 --> 00:46:03.890
and the immune system
stops working as well.

00:46:03.890 --> 00:46:06.120
In some cases, three
days of no sleep

00:46:06.120 --> 00:46:08.070
has led to hallucinations.

00:46:08.070 --> 00:46:09.220
Care about how you look?

00:46:09.220 --> 00:46:10.910
Studies have shown
a direct correlation

00:46:10.910 --> 00:46:14.340
between sleep deprivation and
a person's perceived beauty.

00:46:14.340 --> 00:46:16.730
That is to say,
sleep-deprived individuals

00:46:16.730 --> 00:46:19.330
appeared less healthy and
less attractive than when

00:46:19.330 --> 00:46:20.510
they were well-rested.

00:46:20.510 --> 00:46:23.170
The longest scientifically
documented case of being awake

00:46:23.170 --> 00:46:25.842
was 264 hours, or 11 days.

00:46:25.842 --> 00:46:27.300
And while they did
develop problems

00:46:27.300 --> 00:46:29.896
with concentration,
perception, and irritability,

00:46:29.896 --> 00:46:31.270
the surprising
truth is that they

00:46:31.270 --> 00:46:34.060
suffered no serious
long-term health effects.

00:46:34.060 --> 00:46:37.220
In fact, no individuals under
these documented conditions

00:46:37.220 --> 00:46:40.030
experienced medical,
physiological, neurological,

00:46:40.030 --> 00:46:41.710
or psychiatric problems.

00:46:41.710 --> 00:46:43.400
But there are limited
studies, and this

00:46:43.400 --> 00:46:45.070
doesn't mean permanent
damage couldn't

00:46:45.070 --> 00:46:46.990
be inflicted with more time.

00:46:46.990 --> 00:46:49.710
Sleep deprivation experiments
on rats, for example,

00:46:49.710 --> 00:46:52.110
generally lead to death
after about two weeks.

00:46:52.110 --> 00:46:53.696
But scientists
aren't totally sure

00:46:53.696 --> 00:46:55.320
if they're dying from
the lack of sleep

00:46:55.320 --> 00:46:57.960
or from the stress of
constantly being woken up.

00:46:57.960 --> 00:47:00.370
Perhaps we should look at
fatal familial insomnia

00:47:00.370 --> 00:47:02.680
for an answer, a rare
genetic disease of the brain

00:47:02.680 --> 00:47:05.080
which causes progressively
worsening insomnia,

00:47:05.080 --> 00:47:08.160
or sleeplessness, leading
to hallucinations, dementia,

00:47:08.160 --> 00:47:09.570
and ultimately death.

00:47:09.570 --> 00:47:12.550
This disease has only affected
around 100 people in the world,

00:47:12.550 --> 00:47:15.700
but their average survival
span was around 18 months.

00:47:15.700 --> 00:47:17.920
Over time, the lack
of sleep becomes worse

00:47:17.920 --> 00:47:20.150
and the body's organs
begin to shut down.

00:47:20.150 --> 00:47:23.100
So while lack of sleep won't
necessarily kill you quickly,

00:47:23.100 --> 00:47:25.120
continual sleep
deprivation will have

00:47:25.120 --> 00:47:26.970
a negative effect on your body.

00:47:26.970 --> 00:47:28.420
Sleep tight.

00:47:28.420 --> 00:47:30.201
But not too much.

00:47:30.201 --> 00:47:30.700
Got a--

00:47:32.917 --> 00:47:35.250
ELIZABETH CHOE: So were there
any elements of that video

00:47:35.250 --> 00:47:40.900
that you found striking, that
you liked, that you disliked?

00:47:40.900 --> 00:47:41.650
Yes, Yuliya.

00:47:41.650 --> 00:47:43.441
YULIYA KLOCHAN: I really
liked the movement

00:47:43.441 --> 00:47:45.152
and that he changed
his materials.

00:47:45.152 --> 00:47:47.610
ELIZABETH CHOE: Oh, like from
drawing to construction paper

00:47:47.610 --> 00:47:48.544
and things like that.

00:47:51.391 --> 00:47:53.016
What did you think
about the animation?

00:47:53.016 --> 00:47:54.646
Did you like it or not?

00:47:54.646 --> 00:47:56.020
JOSH GUNN: Oh,
are you asking me?

00:47:56.020 --> 00:47:56.320
ELIZABETH CHOE: Yeah.

00:47:56.320 --> 00:47:57.986
JOSH GUNN: Yeah, I
think it's effective.

00:47:57.986 --> 00:48:01.160
I think one of the things
about it that's nice

00:48:01.160 --> 00:48:07.940
is that the animation allowed
him to change to appeal to I

00:48:07.940 --> 00:48:13.320
think a current need for a
constant stream of images

00:48:13.320 --> 00:48:14.160
that are different.

00:48:14.160 --> 00:48:16.690
This kind of-- I think
we've been conditioned

00:48:16.690 --> 00:48:19.940
to be sort of
bombarded with images,

00:48:19.940 --> 00:48:24.510
and animation is great for that.

00:48:24.510 --> 00:48:26.010
ELIZABETH CHOE: I
mean, I personally

00:48:26.010 --> 00:48:28.850
am not a huge fan of
AsapSCIENCE style,

00:48:28.850 --> 00:48:31.142
but I also recognize
why it's super effective

00:48:31.142 --> 00:48:32.600
and why other people
would like it.

00:48:32.600 --> 00:48:35.210
Because like you said,
it's very engaging,

00:48:35.210 --> 00:48:39.932
if only for just the visual--

00:48:39.932 --> 00:48:41.640
JOSH GUNN: It's also
really well written.

00:48:41.640 --> 00:48:43.014
I actually think
that it's better

00:48:43.014 --> 00:48:45.830
written than it
is-- I mean, I think

00:48:45.830 --> 00:48:49.750
there are any number of ways
it could have been performed.

00:48:49.750 --> 00:48:51.460
But I think it's
really well written.

00:48:51.460 --> 00:48:52.680
It's very concise.

00:48:52.680 --> 00:48:53.900
ELIZABETH CHOE: Right.

00:48:53.900 --> 00:48:55.790
It's very shareable.

00:48:55.790 --> 00:48:57.830
It's sort of written
in this listicle form

00:48:57.830 --> 00:49:01.950
that is dominating
web media in general.

00:49:01.950 --> 00:49:04.620
It's like basically
taking a BuzzFeed article

00:49:04.620 --> 00:49:06.310
and putting it into a video.

00:49:06.310 --> 00:49:08.610
Yet with the visual
elements, there

00:49:08.610 --> 00:49:11.540
is a motivation for you
to watch versus just

00:49:11.540 --> 00:49:15.400
see it on text form, in
BuzzFeed, for instance.

00:49:15.400 --> 00:49:19.270
JOSH GUNN: I actually thought
that the cat video lost

00:49:19.270 --> 00:49:21.140
some of its
engagement for me when

00:49:21.140 --> 00:49:24.300
he was-- there was
this sort of stream

00:49:24.300 --> 00:49:27.070
of scientific information
and all you're doing

00:49:27.070 --> 00:49:30.030
is just watching this
cat in slow motion.

00:49:30.030 --> 00:49:34.180
And for me, it lost that
kind of key component

00:49:34.180 --> 00:49:37.250
of what makes something
engaging, which

00:49:37.250 --> 00:49:39.865
is the tight cohesion
between what you're seeing

00:49:39.865 --> 00:49:41.440
and what's being said.

00:49:41.440 --> 00:49:43.535
And also the streamlining
of scripting.

00:49:43.535 --> 00:49:44.910
ELIZABETH CHOE:
And that's always

00:49:44.910 --> 00:49:46.701
going to be a push-and-pull
that everyone's

00:49:46.701 --> 00:49:50.120
going to experience, too,
with-- at some point,

00:49:50.120 --> 00:49:52.500
are you explaining too
much to the viewer?

00:49:52.500 --> 00:49:55.594
Should you just
rely on the visual?

00:49:55.594 --> 00:49:57.260
Because you don't
want to be too jargony

00:49:57.260 --> 00:50:00.320
and end up alienating an
audience, but at the same time

00:50:00.320 --> 00:50:03.950
you have to cover-- you can't
cover everything, right?

00:50:03.950 --> 00:50:06.480
You can't go in it in detail
and explain everything.

00:50:06.480 --> 00:50:10.210
And that's a conflict that
we'll hit in later lectures,

00:50:10.210 --> 00:50:12.430
how you can use
animation to help you

00:50:12.430 --> 00:50:15.459
with that, some of the best
practices in that realm.

00:50:15.459 --> 00:50:17.000
But that is something
to think about,

00:50:17.000 --> 00:50:19.458
and I think that's a struggle
that everyone has with video,

00:50:19.458 --> 00:50:20.630
for sure.

00:50:20.630 --> 00:50:21.660
I have one more video.

00:50:21.660 --> 00:50:23.160
Did anyone else
want to say anything

00:50:23.160 --> 00:50:29.281
about what would happen
if you didn't sleep?

00:50:29.281 --> 00:50:29.781
Yes.

00:50:29.781 --> 00:50:31.489
JAIME GOLDSTEIN: You
know, I was watching

00:50:31.489 --> 00:50:32.919
and I was thinking
because so much

00:50:32.919 --> 00:50:37.560
of it is being shown
just sort of from Gary

00:50:37.560 --> 00:50:39.595
of these pictures
and these words,

00:50:39.595 --> 00:50:43.460
the thing that Crazy Russian
Hacker had and the cat guy had

00:50:43.460 --> 00:50:47.695
that this guy doesn't is that
you know they're not making

00:50:47.695 --> 00:50:49.380
anything up because
you can see the cat

00:50:49.380 --> 00:50:51.852
and you can see the
bubbles, whereas there

00:50:51.852 --> 00:50:53.425
are no references,
so how do I know

00:50:53.425 --> 00:50:55.320
that everything
that is being said

00:50:55.320 --> 00:50:57.192
is based on fact
upon fact upon fact.

00:50:57.192 --> 00:50:59.590
He could be making all of
this up, for all I know.

00:50:59.590 --> 00:51:01.996
And as I was watching
it, I was thinking,

00:51:01.996 --> 00:51:04.930
how do I know he's not-- like
where's the truth in here?

00:51:04.930 --> 00:51:05.472
I don't know.

00:51:05.472 --> 00:51:07.388
JOSH GUNN: Yeah, there
is some of that element

00:51:07.388 --> 00:51:09.770
of like the web has a lot of
information but what of it

00:51:09.770 --> 00:51:12.520
is validated, or where
does it come from.

00:51:12.520 --> 00:51:13.580
JAIME GOLDSTEIN: If there were
a little subtext somewhere even

00:51:13.580 --> 00:51:15.170
just referencing
any of the ideas,

00:51:15.170 --> 00:51:18.942
I'd feel more like, all
right, I can believe this guy.

00:51:18.942 --> 00:51:20.650
But as it is, it's
hard, because you just

00:51:20.650 --> 00:51:22.565
have a whiteboard and a
marker, and you think, well,

00:51:22.565 --> 00:51:23.960
how do I know they've
done their research.

00:51:23.960 --> 00:51:24.450
ELIZABETH CHOE: Right.

00:51:24.450 --> 00:51:25.400
And I mean, with
YouTube channels,

00:51:25.400 --> 00:51:27.691
a lot of them put in the
sources in their descriptions.

00:51:27.691 --> 00:51:31.940
But I think the thing that maybe
I enjoy less about AsapSCIENCE

00:51:31.940 --> 00:51:35.650
is you could switch the creator
out for any other person

00:51:35.650 --> 00:51:39.770
and have any-- you could have
Siri from your phone narrate

00:51:39.770 --> 00:51:42.240
the video for you and it
wouldn't be a completely

00:51:42.240 --> 00:51:43.279
different experience.

00:51:43.279 --> 00:51:45.320
I mean, it has its branding
because it was really

00:51:45.320 --> 00:51:47.370
one of the first
channels to do that style

00:51:47.370 --> 00:51:50.290
of hand-drawn animation,
so that's its thing.

00:51:50.290 --> 00:51:53.770
But it doesn't have the
compelling sort of authenticity

00:51:53.770 --> 00:51:55.930
that Crazy Russian
Hacker does, or Smarter

00:51:55.930 --> 00:51:56.897
Every Day, or SciShow.

00:51:56.897 --> 00:51:59.230
And I think a lot of it is
because you don't see someone

00:51:59.230 --> 00:52:01.063
on screen, you don't
see a person on screen.

00:52:01.063 --> 00:52:02.760
And maybe that's just
my personal taste,

00:52:02.760 --> 00:52:05.560
but I do think that makes
a really big difference.

00:52:05.560 --> 00:52:06.830
This video is from Vsauce.

00:52:06.830 --> 00:52:09.350
Has anyone ever seen
that channel before?

00:52:09.350 --> 00:52:09.850
Yeah.

00:52:09.850 --> 00:52:12.990
So I actually haven't
watched all of this video

00:52:12.990 --> 00:52:14.740
by myself because
I was scared to,

00:52:14.740 --> 00:52:19.250
but this is why I
think it's creepy.

00:52:19.250 --> 00:52:23.550
MICHAEL STEVENS: Hey,
Vsauce, Michael here.

00:52:23.550 --> 00:52:27.340
Fear gives us life.

00:52:27.340 --> 00:52:33.460
Being afraid of the right
things kept our ancestors alive.

00:52:33.460 --> 00:52:37.110
It makes sense to be
afraid of poisonous insects

00:52:37.110 --> 00:52:39.550
or hungry tigers.

00:52:39.550 --> 00:52:46.360
But what about fear when there
is no clear and obvious danger?

00:52:46.360 --> 00:52:52.458
For instance, a teddy bear
with a full set of human teeth.

00:52:55.400 --> 00:52:56.400
ELIZABETH CHOE: I can't.

00:52:56.400 --> 00:52:57.608
MICHAEL STEVENS: A smile.jpg.

00:53:00.610 --> 00:53:03.750
There's something a little
off about these images.

00:53:03.750 --> 00:53:06.970
Too much mystery
and strangeness.

00:53:06.970 --> 00:53:09.060
But no obvious
threat the way there

00:53:09.060 --> 00:53:10.824
is with a gun or a falling rock.

00:53:10.824 --> 00:53:16.230
But yet they still incite
fear because they are creepy.

00:53:16.230 --> 00:53:17.440
But why?

00:53:17.440 --> 00:53:19.350
What gives us the creeps?

00:53:19.350 --> 00:53:22.760
What causes something
to be creepy?

00:53:26.120 --> 00:53:28.530
We are now in my
bedroom, the bedroom

00:53:28.530 --> 00:53:30.893
I grew up in, in Kansas.

00:53:30.893 --> 00:53:34.680
Like a lot of children my age,
I was terrified of scary stories

00:53:34.680 --> 00:53:36.860
to tell in the dark.

00:53:36.860 --> 00:53:39.480
But the very first book
that ever scared me

00:53:39.480 --> 00:53:42.010
was the Curse of the Squirrel.

00:53:42.010 --> 00:53:45.310
To this day I still
haven't finished the book,

00:53:45.310 --> 00:53:46.960
but that's just me.

00:53:46.960 --> 00:53:49.870
Psychologist James
Geer developed the Fear

00:53:49.870 --> 00:53:53.540
Survey Schedule-II,
which he used to find out

00:53:53.540 --> 00:53:55.700
what scared us the most.

00:53:55.700 --> 00:53:58.880
Combined with the results of
a more recent Gallup poll,

00:53:58.880 --> 00:54:04.420
these are the things that
scare most of us the most.

00:54:04.420 --> 00:54:09.420
All of these things are
scary, but are they creepy?

00:54:09.420 --> 00:54:10.960
Let's get more specific.

00:54:10.960 --> 00:54:13.030
I love the way Stephen
King delineates

00:54:13.030 --> 00:54:15.730
three types of scary stuff.

00:54:15.730 --> 00:54:17.970
The first is the gross-out.

00:54:17.970 --> 00:54:21.810
This is something
disgusting, morbid, diseased.

00:54:21.810 --> 00:54:24.290
The second is horror.

00:54:24.290 --> 00:54:27.080
Horror, to King,
is the unnatural;

00:54:27.080 --> 00:54:30.990
a giant spider or being
grabbed in the dark when

00:54:30.990 --> 00:54:33.300
you thought you were alone.

00:54:33.300 --> 00:54:39.450
The third, terror, is
different, creepier.

00:54:39.450 --> 00:54:42.550
He says terror is
coming home to find

00:54:42.550 --> 00:54:46.200
that everything that
you own has been

00:54:46.200 --> 00:54:50.290
replaced with an exact copy.

00:54:50.290 --> 00:54:53.560
Terror is feeling
something behind you,

00:54:53.560 --> 00:54:56.940
its breath on your neck, knowing
that you will be grabbed,

00:54:56.940 --> 00:55:00.880
but then turning around to find
that there was never anything

00:55:00.880 --> 00:55:04.950
there in the first place.

00:55:04.950 --> 00:55:06.790
Not a lot of research
has been done

00:55:06.790 --> 00:55:10.120
on that feeling, the creeps.

00:55:10.120 --> 00:55:15.810
But many theories and ideas
involve vagueness, ambiguity.

00:55:15.810 --> 00:55:21.340
For instance, masks, and
why clowns are creepy.

00:55:21.340 --> 00:55:25.770
Claude Levi-Strauss wrote that
the facial disguise temporarily

00:55:25.770 --> 00:55:27.880
eliminates from
social intercourse

00:55:27.880 --> 00:55:31.500
the part of the body which
reveals personal feelings

00:55:31.500 --> 00:55:33.320
and attitudes.

00:55:33.320 --> 00:55:37.670
Part of the reason even
a neutral or happy mask

00:55:37.670 --> 00:55:40.300
can be creepy may have
to do with ambiguity.

00:55:40.300 --> 00:55:43.460
A mask hides the true
emotions and intentions

00:55:43.460 --> 00:55:45.280
of the person underneath.

00:55:45.280 --> 00:55:50.090
I don't know if the person
wearing that mask is a threat

00:55:50.090 --> 00:55:52.450
or not.

00:55:52.450 --> 00:55:56.340
Vagueness is creep when it
comes to the human form.

00:55:56.340 --> 00:56:00.280
This is the famous
uncanny valley.

00:56:00.280 --> 00:56:03.200
On a chart of humanness,
there's a zone

00:56:03.200 --> 00:56:05.340
where something can
be almost entirely

00:56:05.340 --> 00:56:07.910
human but off by just a little.

00:56:07.910 --> 00:56:12.820
Not so wrong that it's clear
fake or funny, or so good

00:56:12.820 --> 00:56:14.580
that it's indistinguishable.

00:56:14.580 --> 00:56:18.280
Instead, it's just troubling.

00:56:18.280 --> 00:56:20.090
The creepiness of
the uncanny valley

00:56:20.090 --> 00:56:24.560
is wonderfully demonstrated
by John Bergeron's singing

00:56:24.560 --> 00:56:25.980
androids.

00:56:25.980 --> 00:56:28.280
Watch these videos
when you're alone.

00:56:31.890 --> 00:56:36.230
A similar uneasy feeling
comes from Shaye Saint John,

00:56:36.230 --> 00:56:38.730
a character created
by Eric Fournier.

00:56:38.730 --> 00:56:43.580
Funny to some, nightmare
fuel to others.

00:56:43.580 --> 00:56:47.060
Uncanny humanoids,
like all creepy things,

00:56:47.060 --> 00:56:50.000
straddle a line
between two regions

00:56:50.000 --> 00:56:53.850
that we can understand
and explain with language.

00:56:53.850 --> 00:56:56.020
Francis T. McAndrew
and Sara Koehnke

00:56:56.020 --> 00:57:00.240
describe being creeped out
as an adaptive human response

00:57:00.240 --> 00:57:03.960
to the ambiguity of
threats from others.

00:57:03.960 --> 00:57:07.540
Creepy things are kind
of a threat maybe,

00:57:07.540 --> 00:57:10.570
but they're also kind
of not, so our brains

00:57:10.570 --> 00:57:11.950
don't know what to do.

00:57:11.950 --> 00:57:16.030
Some parts respond with fear
while other parts don't, and

00:57:16.030 --> 00:57:17.320
they don't know why.

00:57:17.320 --> 00:57:21.830
So instead of achieving a
typical fear response, horror,

00:57:21.830 --> 00:57:24.850
we simply feel uneasy.

00:57:24.850 --> 00:57:26.410
Terror.

00:57:26.410 --> 00:57:28.270
Creeped out.

00:57:28.270 --> 00:57:32.110
Between the mountains
of safety and danger,

00:57:32.110 --> 00:57:35.420
there is a valley
of creepiness, where

00:57:35.420 --> 00:57:38.850
the limits of our knowledge
and trust and security

00:57:38.850 --> 00:57:40.950
aren't very clear.

00:57:40.950 --> 00:57:46.324
Will looking at this cause
you to die one week later?

00:57:46.324 --> 00:57:47.710
Impossible, right?

00:57:50.490 --> 00:57:52.390
Maybe.

00:57:52.390 --> 00:57:56.160
That's the terror of ambiguity.

00:57:56.160 --> 00:57:59.300
We don't do well with ambiguity.

00:57:59.300 --> 00:58:03.490
When it involves our own
intentions, it can make us lie.

00:58:03.490 --> 00:58:04.760
And when it involves danger--

00:58:04.760 --> 00:58:06.390
ELIZABETH CHOE: Can I stop or
you guys want to keep watching?

00:58:06.390 --> 00:58:08.431
MICHAEL STEVENS: [INAUDIBLE]
recognizable threat,

00:58:08.431 --> 00:58:10.473
it can make us think and
feel some pretty weird--

00:58:10.473 --> 00:58:12.555
ELIZABETH CHOE: So he goes
on and talks more about

00:58:12.555 --> 00:58:14.650
like the actual
psychology behind this.

00:58:14.650 --> 00:58:17.670
The whole pop-up thing
is his trademark move.

00:58:17.670 --> 00:58:20.885
He does that between
all of his transitions.

00:58:20.885 --> 00:58:22.260
It's like a little
kitschy but it

00:58:22.260 --> 00:58:24.910
works since he was
the first to do it.

00:58:24.910 --> 00:58:27.260
But what did you guys
think about this one,

00:58:27.260 --> 00:58:29.160
especially in comparison
to AsapSCIENCE?

00:58:29.160 --> 00:58:33.380
Very similar format,
it's the why-what-how,

00:58:33.380 --> 00:58:34.900
but executed very differently.

00:58:37.600 --> 00:58:39.680
Or maybe was there
something about this video

00:58:39.680 --> 00:58:41.600
that you liked better
than AsapSCIENCE

00:58:41.600 --> 00:58:44.074
or that you disliked
compared to AsapSCIENCE.

00:58:44.074 --> 00:58:44.574
Yep.

00:58:44.574 --> 00:58:47.962
PAUL FOLINO: I think I got the
point maybe couple minutes in,

00:58:47.962 --> 00:58:50.382
but it seemed like the
next three or four minutes,

00:58:50.382 --> 00:58:53.300
he was just expounding on
that point that I already got.

00:58:53.300 --> 00:58:54.787
ELIZABETH CHOE: Yeah, so it
dragged a little bit more.

00:58:54.787 --> 00:58:57.172
PAUL FOLINO: Right, it never
really answered-- I mean,

00:58:57.172 --> 00:58:58.880
you didn't finish the
video, but it never

00:58:58.880 --> 00:59:00.770
seemed to answer the
question [INAUDIBLE].

00:59:00.770 --> 00:59:01.350
ELIZABETH CHOE: Yeah.

00:59:01.350 --> 00:59:02.810
I mean, he does
sort of eventually,

00:59:02.810 --> 00:59:07.350
but it does take him a little
bit longer to get there.

00:59:07.350 --> 00:59:07.850
Yes.

00:59:07.850 --> 00:59:09.600
YULIYA KLOCHAN: It
still kept my attention

00:59:09.600 --> 00:59:11.770
because he was very
close to the audience

00:59:11.770 --> 00:59:14.220
and he was an
interesting character,

00:59:14.220 --> 00:59:18.310
so I was interested
in knowing what

00:59:18.310 --> 00:59:20.141
he would say next, [INAUDIBLE].

00:59:20.141 --> 00:59:22.140
ELIZABETH CHOE: Yeah,
Michael Stevens definitely

00:59:22.140 --> 00:59:24.930
is a very memorable
persona on screen.

00:59:24.930 --> 00:59:26.820
And this is something
that we'll emphasize

00:59:26.820 --> 00:59:27.770
throughout the course.

00:59:27.770 --> 00:59:30.370
We don't want you
to feel like you

00:59:30.370 --> 00:59:32.630
have to exaggerate
yourself or sort

00:59:32.630 --> 00:59:35.417
of because this
persona on screen

00:59:35.417 --> 00:59:36.500
that you're not naturally.

00:59:36.500 --> 00:59:39.060
It's not about you
trying to adapt

00:59:39.060 --> 00:59:41.460
into a Bill Nye personality
or into a Michael Stevens

00:59:41.460 --> 00:59:42.394
personality.

00:59:42.394 --> 00:59:44.060
A lot of people find
him super annoying,

00:59:44.060 --> 00:59:45.740
and I don't blame them.

00:59:45.740 --> 00:59:49.500
It's really about
how to best capture

00:59:49.500 --> 00:59:51.510
who you are in real
life and just maintain

00:59:51.510 --> 00:59:54.920
that as much as possible
in front of a camera,

00:59:54.920 --> 00:59:57.550
because maybe he is a little
bit different in real life,

00:59:57.550 --> 01:00:00.330
but it doesn't seem super
unnatural when you watch,

01:00:00.330 --> 01:00:00.830
right?

01:00:00.830 --> 01:00:02.770
You're not like, this
guy is acting just

01:00:02.770 --> 01:00:04.660
like totally over the top.

01:00:04.660 --> 01:00:07.990
It's just part of his
brand, part of his persona

01:00:07.990 --> 01:00:10.750
to get his message across.

01:00:10.750 --> 01:00:14.320
I do think that something
that was effective about that

01:00:14.320 --> 01:00:16.960
video is it took all these
concepts that you learn

01:00:16.960 --> 01:00:18.940
in cognitive
psychology, but again,

01:00:18.940 --> 01:00:21.300
instead of doing
a video on here's

01:00:21.300 --> 01:00:24.300
the definition of uncanny
valley or things like that,

01:00:24.300 --> 01:00:26.060
he tapped into something
that resonates--

01:00:26.060 --> 01:00:27.560
at least it resonates
a lot with me,

01:00:27.560 --> 01:00:29.570
because I was super
creeped out by this video.

01:00:29.570 --> 01:00:32.400
But it taps into something
that we experience every day,

01:00:32.400 --> 01:00:36.580
that it's a very relatable
video, that it's contextual,

01:00:36.580 --> 01:00:39.080
that I don't feel
like I'm watching

01:00:39.080 --> 01:00:40.660
a lecture, necessarily, on it.

01:00:40.660 --> 01:00:44.280
I don't feel like I'm even
watching a Khan Academy video.

01:00:44.280 --> 01:00:46.580
That I just want to sit
there and learn more.

01:00:46.580 --> 01:00:49.660
I wanted to learn more for the
first two minutes, at least.

01:00:49.660 --> 01:00:52.770
I don't know if you
guys felt that way.

01:00:52.770 --> 01:00:54.050
Yes, no?

01:00:54.050 --> 01:00:54.688
Yeah.

01:00:54.688 --> 01:00:59.560
JOSH CHEONG: I felt like
I got pretty much what--

01:00:59.560 --> 01:01:01.646
after he showed me the
graph of the thing,

01:01:01.646 --> 01:01:03.574
I didn't really
understand the graph,

01:01:03.574 --> 01:01:06.466
but he kind of explained
it with like, oh,

01:01:06.466 --> 01:01:10.322
you need to be in between
two points to be creepy.

01:01:10.322 --> 01:01:14.696
Then after that, it's all about
trying to figure it myself.

01:01:14.696 --> 01:01:16.632
He does this
connect-the-dots thing.

01:01:16.632 --> 01:01:19.052
He doesn't really give
you the right answers.

01:01:19.052 --> 01:01:21.535
He seems to be seeding you.

01:01:21.535 --> 01:01:22.410
ELIZABETH CHOE: Yeah.

01:01:22.410 --> 01:01:25.370
The payoff happened, but it
takes a long time to get there.

01:01:25.370 --> 01:01:27.422
And maybe he loses
interest along the way.

01:01:27.422 --> 01:01:28.880
Again, that's
something that you're

01:01:28.880 --> 01:01:31.450
going to have to figure
out how to balance,

01:01:31.450 --> 01:01:34.327
how much tension do you want
to build up for the audience.

01:01:34.327 --> 01:01:36.910
Maybe you'll do it too much, to
the point where you lose them.

01:01:36.910 --> 01:01:41.300
Maybe you do it to just create
the buildup to the final reveal

01:01:41.300 --> 01:01:42.450
of your video.

01:01:45.730 --> 01:01:49.250
In addition to being these
digestible, listicle type

01:01:49.250 --> 01:01:51.470
chunks that are
shareable and contextual,

01:01:51.470 --> 01:01:54.070
YouTube videos are also
super searchable, right?

01:01:54.070 --> 01:01:56.710
So you can just go
on YouTube and search

01:01:56.710 --> 01:02:00.570
for literally anything you
want, and you'll have suggested

01:02:00.570 --> 01:02:02.340
videos that pop up at
the end, so there's

01:02:02.340 --> 01:02:06.990
this sort of inherent--
what was the thing I put?

01:02:06.990 --> 01:02:08.880
There's an inherent
vetting process

01:02:08.880 --> 01:02:11.370
that happens on
YouTube, that you

01:02:11.370 --> 01:02:15.070
have a compendium of
knowledge and compendium

01:02:15.070 --> 01:02:17.130
of resources available
to you, and you

01:02:17.130 --> 01:02:19.450
have things like
comments and suggested

01:02:19.450 --> 01:02:23.420
views and subscriptions to
help you decide what to watch.

01:02:23.420 --> 01:02:24.920
And everything's
at your fingertips.

01:02:24.920 --> 01:02:28.335
You can get whatever you
want, whenever you want it.

01:02:28.335 --> 01:02:30.210
Then there's this whole
trusted guide element

01:02:30.210 --> 01:02:32.650
that is really-- it's
just as present on YouTube

01:02:32.650 --> 01:02:33.690
as it is on TV.

01:02:33.690 --> 01:02:36.770
You have people like
Vsauce and Michael Stevens.

01:02:36.770 --> 01:02:38.850
Even with AsapSCIENCE,
you don't see the guy,

01:02:38.850 --> 01:02:41.360
but it has a really
strong brand.

01:02:41.360 --> 01:02:44.860
And it's one of
those things where

01:02:44.860 --> 01:02:46.810
if you replaced a
successful YouTube

01:02:46.810 --> 01:02:50.469
video with another person or
another narrator-- a litmus

01:02:50.469 --> 01:02:52.510
test that I like to think
of is if you replace it

01:02:52.510 --> 01:02:54.867
and it's just not really
a noticeable change,

01:02:54.867 --> 01:02:56.700
then maybe there's
something with your video

01:02:56.700 --> 01:02:58.460
that isn't very engaging.

01:02:58.460 --> 01:03:01.580
That if you swapped out any
of your classmates for it

01:03:01.580 --> 01:03:05.632
and it still sort of felt
like the same video, maybe

01:03:05.632 --> 01:03:07.340
there's more of your
inherent personality

01:03:07.340 --> 01:03:10.440
that you can highlight
more in the video.

01:03:10.440 --> 01:03:14.050
And then, with YouTube, there's
no invisible college, right?

01:03:14.050 --> 01:03:15.870
There's no gatekeeper
of knowledge.

01:03:15.870 --> 01:03:21.010
You don't have to pay $100 to
access a lecture course, right?

01:03:21.010 --> 01:03:22.510
Anybody can access
OpenCourseWare.

01:03:22.510 --> 01:03:25.550
Anybody can go watch
a Vsauce video.

01:03:25.550 --> 01:03:28.250
Anyone can comment, so
theoretically, anyone

01:03:28.250 --> 01:03:32.110
can contribute to that community
and landscape, and its products

01:03:32.110 --> 01:03:33.530
as well.

01:03:33.530 --> 01:03:35.510
I think we're starting
to see more of it.

01:03:35.510 --> 01:03:36.910
You see more female
creators, you

01:03:36.910 --> 01:03:41.610
see a little bit more diversity
in the YouTube environment

01:03:41.610 --> 01:03:43.110
than you do on TV, certainly.

01:03:43.110 --> 01:03:48.870
But again, there's a lot of
room to grow in that regard.

01:03:48.870 --> 01:03:51.060
And then finally,
for TV, TV is very

01:03:51.060 --> 01:03:53.720
different from online
video, which is something

01:03:53.720 --> 01:03:57.410
that I didn't actually realize
myself until fairly recently.

01:03:57.410 --> 01:03:59.060
I always kind of
thought if I want

01:03:59.060 --> 01:04:02.170
to make a good video online
then I should just sort of apply

01:04:02.170 --> 01:04:04.860
the best practices of
making a good video on TV

01:04:04.860 --> 01:04:07.180
and just shorten it to a
five-minute online video.

01:04:07.180 --> 01:04:09.130
But that's not
necessarily the case,

01:04:09.130 --> 01:04:11.350
because the priority
of TV, first of all,

01:04:11.350 --> 01:04:13.320
is to hold your attention.

01:04:13.320 --> 01:04:15.790
When you're watching TV, there
are going to be commercials,

01:04:15.790 --> 01:04:17.370
you can flip the channel.

01:04:17.370 --> 01:04:20.350
I guess you can do that
with online stuff as well,

01:04:20.350 --> 01:04:26.840
but the distractions
aren't necessarily as huge.

01:04:26.840 --> 01:04:28.560
When you go to a
commercial, you're

01:04:28.560 --> 01:04:30.610
going to want to
change the channel.

01:04:30.610 --> 01:04:33.720
So they really have to
hook your attention,

01:04:33.720 --> 01:04:36.490
and they do that a lot with
some of the production styles.

01:04:36.490 --> 01:04:40.990
On TV you'll tend to see a lot
more multi-camera type videos.

01:04:40.990 --> 01:04:44.310
You'll see a lot of quick
cuts, a lot of effects

01:04:44.310 --> 01:04:45.881
to sort of keep you engaged.

01:04:45.881 --> 01:04:48.380
I noticed that about the Hobbit,
there was like an explosion

01:04:48.380 --> 01:04:50.610
every other second.

01:04:50.610 --> 01:04:53.640
And they do that
because they have

01:04:53.640 --> 01:04:55.610
to have this really
big hold on you

01:04:55.610 --> 01:04:58.600
for a much longer
period of time.

01:04:58.600 --> 01:05:01.600
Whereas on online videos,
stuff like Smarter Every Day,

01:05:01.600 --> 01:05:03.310
it's just kind of the
same camera set up

01:05:03.310 --> 01:05:06.580
on a tripod that's shooting
you the whole time.

01:05:06.580 --> 01:05:09.580
And TV is very much
about narrative,

01:05:09.580 --> 01:05:10.920
about telling a story.

01:05:10.920 --> 01:05:12.510
And I think that
that is something

01:05:12.510 --> 01:05:15.570
that you should do in an online
video too, but it's not as much

01:05:15.570 --> 01:05:16.780
of a necessity.

01:05:16.780 --> 01:05:20.096
Things like-- I don't know,
any viral video that's

01:05:20.096 --> 01:05:21.970
not necessarily
science-related, most of them

01:05:21.970 --> 01:05:23.510
don't really have a story.

01:05:23.510 --> 01:05:26.779
It's more just like,
here's a naked celebrity.

01:05:26.779 --> 01:05:28.570
I guess you could create
a story out of it,

01:05:28.570 --> 01:05:30.361
but it's not
narrative-driven, necessarily,

01:05:30.361 --> 01:05:34.680
whereas TV very much is,
and movies are as well.

01:05:34.680 --> 01:05:37.010
I wanted to show
you another video,

01:05:37.010 --> 01:05:39.990
and this is from
Connections, which I never

01:05:39.990 --> 01:05:43.472
heard of until Chris showed
us this show in his class.

01:05:43.472 --> 01:05:44.180
But it's awesome.

01:05:44.180 --> 01:05:48.740
It's like one of the first
science TV shows in the UK.

01:05:48.740 --> 01:05:51.847
And this is from Connections 2,
and it's a whodunnit episode.

01:07:02.540 --> 01:07:06.130
JAMES BURKE: I suppose a
detective catches a crook

01:07:06.130 --> 01:07:09.980
because he follows a trail from
one uniquely relevant event

01:07:09.980 --> 01:07:12.390
or person to another,
until he finds

01:07:12.390 --> 01:07:14.320
a unique piece of
evidence that points

01:07:14.320 --> 01:07:18.190
to the only person in the world
who could've done the deed.

01:07:18.190 --> 01:07:21.672
And strangely
enough, the story I'm

01:07:21.672 --> 01:07:24.724
about to tell you about
why modern detectives are

01:07:24.724 --> 01:07:28.092
able to do that at all follows
exactly the same kind of tail,

01:07:28.092 --> 01:07:32.174
from one unique character
to another through history.

01:07:32.174 --> 01:07:35.570
Here's my first
unique character,

01:07:35.570 --> 01:07:38.915
Steve Davis, one of the best
snooker players in the world.

01:07:42.100 --> 01:07:44.750
ELIZABETH CHOE: Ah,
don't look at this.

01:07:44.750 --> 01:07:47.550
So that is a show that
aired-- I don't know,

01:07:47.550 --> 01:07:48.740
was that like the '70s?

01:07:48.740 --> 01:07:50.260
CHRIS BOEBEL: It's the
late '70s [INAUDIBLE].

01:07:50.260 --> 01:07:51.343
ELIZABETH CHOE: Late '70s?

01:07:51.343 --> 01:07:53.670
And this is Connections 2,
so maybe it's early '80s.

01:07:53.670 --> 01:07:56.970
I don't know about you, I
felt like that was so endless.

01:07:56.970 --> 01:08:01.710
It took him two whole minutes
to even just introduce

01:08:01.710 --> 01:08:04.110
the first character of
what he was talking about,

01:08:04.110 --> 01:08:05.070
and it felt--

01:08:05.070 --> 01:08:06.350
CHRIS BOEBEL: Isn't it
amazing how the pacing has

01:08:06.350 --> 01:08:07.420
changed, and our expectations?

01:08:07.420 --> 01:08:09.590
ELIZABETH CHOE: Right, it
felt agonizing, almost.

01:08:09.590 --> 01:08:12.780
And I'm sure if I watched it
on TV and I saw the rest of it,

01:08:12.780 --> 01:08:13.560
it would be fine.

01:08:13.560 --> 01:08:17.779
But I mean, compare that to
AsapSCIENCE, for instance.

01:08:17.779 --> 01:08:21.390
The priority of what
Connections producers were

01:08:21.390 --> 01:08:24.080
doing with that video is very
different than AsapSCIENCE,

01:08:24.080 --> 01:08:26.305
and you have a very
different effect.

01:08:26.305 --> 01:08:28.390
I actually really
enjoyed Connections,

01:08:28.390 --> 01:08:30.010
I really liked the show too.

01:08:30.010 --> 01:08:32.649
So I'm not saying it's a
bad thing, necessarily.

01:08:32.649 --> 01:08:35.979
But that's sort of what happens
when you're applying this best

01:08:35.979 --> 01:08:37.870
practices in TV
or movies and you

01:08:37.870 --> 01:08:41.300
think you can just move it
over to video on the web

01:08:41.300 --> 01:08:42.359
and just shorten it down.

01:08:42.359 --> 01:08:46.170
That's not necessarily going
to be the best approach,

01:08:46.170 --> 01:08:47.790
because some of
the best practices

01:08:47.790 --> 01:08:50.620
aren't going to
work, necessarily.

01:08:50.620 --> 01:08:52.390
So what I would
like you guys to do

01:08:52.390 --> 01:08:55.710
right now, if you can
access-- does everyone

01:08:55.710 --> 01:08:59.779
have a laptop with them or can
share a laptop with someone?

01:08:59.779 --> 01:09:05.590
If you go onto our class
site, it's mit219.tumblr.com.

01:09:05.590 --> 01:09:08.560
You'll see a post that I
just put up earlier today,

01:09:08.560 --> 01:09:13.072
and it has a link to a Google
doc that should look like this.

01:09:24.640 --> 01:09:26.899
Should look like this.

01:09:26.899 --> 01:09:31.670
And what I'd like you guys to
do for maybe the next like 20-25

01:09:31.670 --> 01:09:35.271
minutes-- and feel free to get
up and stretch during this time

01:09:35.271 --> 01:09:35.770
if you want.

01:09:35.770 --> 01:09:37.979
If you need to use the
restroom, feel free to head out.

01:09:37.979 --> 01:09:38.830
JAIME GOLDSTEIN: Can you
write the URL on the board?

01:09:38.830 --> 01:09:39.871
ELIZABETH CHOE: Oh, yeah.

01:09:43.060 --> 01:09:44.539
Can everyone see on this board?

01:09:57.290 --> 01:09:59.850
There should only be
one post, and it'll

01:09:59.850 --> 01:10:02.290
have a link to
the class syllabus

01:10:02.290 --> 01:10:06.150
that, again, has all the
videos that we've watched today

01:10:06.150 --> 01:10:09.617
and the assignments
for all the days.

01:10:09.617 --> 01:10:11.700
And then it should have a
link to this Google doc.

01:10:11.700 --> 01:10:13.210
And what I'd like
for you guys to do

01:10:13.210 --> 01:10:16.700
is to watch the videos
that I've listed here,

01:10:16.700 --> 01:10:19.930
and then record the exact
time code in which you

01:10:19.930 --> 01:10:23.110
want to stop watching the video,
and just be completely honest.

01:10:23.110 --> 01:10:26.580
And then afterwards we'll talk
about maybe some of the reasons

01:10:26.580 --> 01:10:29.360
why you thought certain
videos were more engaging.

01:10:29.360 --> 01:10:35.610
Think about why you might still
think that a video is good even

01:10:35.610 --> 01:10:38.040
if you wanted to turn it off.

01:10:38.040 --> 01:10:39.249
And we'll convene at the end.

01:10:39.249 --> 01:10:40.873
But again, feel free--
if you guys need

01:10:40.873 --> 01:10:43.610
to get up and stretch or go to
the bathroom during this time,

01:10:43.610 --> 01:10:44.690
feel free to do that too.

01:10:44.690 --> 01:10:46.523
And you guys can talk
to each other as well.

01:11:09.440 --> 01:11:11.750
All right, let's
go ahead and talk.

01:11:11.750 --> 01:11:14.840
I know you guys
are finishing up.

01:11:14.840 --> 01:11:18.310
Just so you know, every day
you'll do blog reflections,

01:11:18.310 --> 01:11:21.200
and if you want to talk a little
bit more about your thoughts

01:11:21.200 --> 01:11:23.780
on these videos in your blog
today, that's totally fine.

01:11:23.780 --> 01:11:25.690
I know we're not going
to get everything.

01:11:25.690 --> 01:11:27.950
But did anyone have
a favorite video?

01:11:33.357 --> 01:11:35.526
Yes.

01:11:35.526 --> 01:11:37.109
ANDREA DESROSIERS:
The Veritasium one.

01:11:37.109 --> 01:11:38.640
ELIZABETH CHOE: Oh, Veritasium,
you like that one the best?

01:11:38.640 --> 01:11:40.804
Yeah, actually, that
one's my favorite too.

01:11:40.804 --> 01:11:41.970
ANDREA DESROSIERS: And Asap.

01:11:41.970 --> 01:11:43.400
ELIZABETH CHOE: And Asap.

01:11:43.400 --> 01:11:46.070
What about those two videos
did you like, or maybe

01:11:46.070 --> 01:11:49.280
can you hit upon one thing
that you found particularly--

01:11:49.280 --> 01:11:53.462
ANDREA DESROSIERS: Veritasium,
very charismatic host,

01:11:53.462 --> 01:11:57.454
and kept the pace
not going so quickly,

01:11:57.454 --> 01:12:00.448
but not going too slowly.

01:12:00.448 --> 01:12:03.000
Then for AsapSCIENCE,
it was very crisp

01:12:03.000 --> 01:12:07.572
and conveyed the point very
succinctly and clearly.

01:12:07.572 --> 01:12:09.780
ELIZABETH CHOE: That's
interesting because I actually

01:12:09.780 --> 01:12:12.680
thought that those were the
two videos that I personally

01:12:12.680 --> 01:12:14.410
watched most of myself.

01:12:14.410 --> 01:12:17.490
And I'm not necessarily the
biggest fan of AsapSCIENCE,

01:12:17.490 --> 01:12:19.941
but I did want to
watch the whole thing.

01:12:19.941 --> 01:12:21.690
The thing about
Veritasium is interesting,

01:12:21.690 --> 01:12:26.310
because he's not using super
fancy equipment, per se.

01:12:26.310 --> 01:12:28.360
His stuff looks a lot
better than a lot of what's

01:12:28.360 --> 01:12:33.460
on YouTube, but he's using just
basic DSLR cameras, I think.

01:12:33.460 --> 01:12:37.290
But his background, he's a
physicist, that's his PhD.

01:12:37.290 --> 01:12:39.730
But he does physics
education as well,

01:12:39.730 --> 01:12:43.670
so he's very cognizant of the
role of video in education,

01:12:43.670 --> 01:12:45.920
and that's going to be one
of your reading assignments

01:12:45.920 --> 01:12:48.110
tonight, is watching
one of his videos.

01:12:48.110 --> 01:12:51.180
But I do think that he does a
very interesting job and a very

01:12:51.180 --> 01:12:54.490
good job of being very natural
on screen, charismatic,

01:12:54.490 --> 01:12:55.430
like you were saying.

01:12:55.430 --> 01:12:56.930
There's something
about his delivery

01:12:56.930 --> 01:13:00.410
that is-- he talks the way that
you would think he would just

01:13:00.410 --> 01:13:03.120
talk in real life,
which is actually

01:13:03.120 --> 01:13:05.490
really hard to do on video.

01:13:05.490 --> 01:13:08.070
Did anyone else-- let's
see what you guys thought

01:13:08.070 --> 01:13:11.310
about the Veritasium video.

01:13:11.310 --> 01:13:15.627
It looks like a lot of people
actually finished that one.

01:13:15.627 --> 01:13:17.960
And I didn't mention this
before, but maybe you noticed.

01:13:17.960 --> 01:13:20.050
All these videos are
talking about evolution

01:13:20.050 --> 01:13:22.460
or natural selection
in some way or another,

01:13:22.460 --> 01:13:25.810
but they're doing it
very different ways.

01:13:25.810 --> 01:13:27.830
What about anyone
else, let's see.

01:13:31.090 --> 01:13:33.480
Nathan, you finished SciShow.

01:13:33.480 --> 01:13:37.100
What was it about
SciShow that you liked?

01:13:39.325 --> 01:13:40.700
NATHAN HERNANDEZ:
I'd say I liked

01:13:40.700 --> 01:13:43.820
that there's a little bit
of humor in his video.

01:13:43.820 --> 01:13:45.420
I think that's
something that tends

01:13:45.420 --> 01:13:47.689
to keep my attention better.

01:13:47.689 --> 01:13:49.230
ELIZABETH CHOE:
Sorry, that you what?

01:13:49.230 --> 01:13:50.730
NATHAN HERNANDEZ:
Just when you have

01:13:50.730 --> 01:13:53.617
a little bit of humor inserted,
that keeps my attention better.

01:13:53.617 --> 01:13:56.200
ELIZABETH CHOE: And Hank Green
is a very neurotic host, right?

01:13:56.200 --> 01:13:58.650
He talks like this
and he has quick cuts

01:13:58.650 --> 01:14:01.110
and he's very
hyper all the time,

01:14:01.110 --> 01:14:03.110
and it works for him
because that's just

01:14:03.110 --> 01:14:04.400
who he is in real life.

01:14:04.400 --> 01:14:08.970
So again, being Hank Green
doesn't make you successful,

01:14:08.970 --> 01:14:11.510
it's that he's able to just be
himself on camera that works.

01:14:15.610 --> 01:14:20.540
Did anyone have a least favorite
video or one-- let's see,

01:14:20.540 --> 01:14:24.610
a lot of people
ended the TED-Ed one,

01:14:24.610 --> 01:14:26.820
or maybe a couple people
ended that one early,

01:14:26.820 --> 01:14:30.800
and the Khan Academy one early.

01:14:30.800 --> 01:14:33.090
Any thoughts about those?

01:14:33.090 --> 01:14:36.400
What is it that made
you-- I keep doing that.

01:14:36.400 --> 01:14:38.140
What is it about
those videos that

01:14:38.140 --> 01:14:39.415
made you turn them off early?

01:14:52.300 --> 01:14:56.750
Paul, you turned that
one off at 17 seconds.

01:14:56.750 --> 01:14:58.374
That's pretty early.

01:14:58.374 --> 01:14:59.290
PAUL FOLINO: What one?

01:14:59.290 --> 01:15:00.712
ELIZABETH CHOE: The
Khan Academy one.

01:15:00.712 --> 01:15:01.696
PAUL FOLINO: Oh, yeah.

01:15:01.696 --> 01:15:07.600
I just thought that was a bad
way of portraying evolution.

01:15:07.600 --> 01:15:11.044
I usually use Khan Academy
for math or something

01:15:11.044 --> 01:15:14.000
like that, because he is going
through all the hand motions

01:15:14.000 --> 01:15:15.470
and how to do an equation.

01:15:15.470 --> 01:15:15.765
ELIZABETH CHOE: Right.

01:15:15.765 --> 01:15:17.806
PAUL FOLINO: But I think
something like evolution

01:15:17.806 --> 01:15:21.160
that's kind of nebulous to begin
with, I'd like to see pictures,

01:15:21.160 --> 01:15:24.173
not really-- I don't know.

01:15:24.173 --> 01:15:25.985
That's just my personal opinion.

01:15:25.985 --> 01:15:27.750
ELIZABETH CHOE: Well,
yeah, I personally

01:15:27.750 --> 01:15:28.750
agree with that as well.

01:15:28.750 --> 01:15:31.440
I mean, I also feel
like Khan Academy works

01:15:31.440 --> 01:15:32.890
for a very certain
type of video,

01:15:32.890 --> 01:15:35.872
and that tends to be a
numbers and graph-driven one.

01:15:35.872 --> 01:15:37.830
And we'll talk about this
more in a little bit,

01:15:37.830 --> 01:15:41.030
but when you think about why
you want to make a video,

01:15:41.030 --> 01:15:44.460
you have to consider quite
a bit about the visuals

01:15:44.460 --> 01:15:46.380
that you're going to
use and how that's

01:15:46.380 --> 01:15:48.740
going to motivate the story
that you're going to tell,

01:15:48.740 --> 01:15:52.095
or trying to convey the message
that you're trying to convey.

01:15:52.095 --> 01:15:54.220
And I know-- I wish we
could talk a little bit more

01:15:54.220 --> 01:15:57.440
about this, but we are running
a little bit short on time

01:15:57.440 --> 01:15:59.320
and I want to leave
enough room for Chris.

01:15:59.320 --> 01:16:02.400
So if you can respond
a little bit more

01:16:02.400 --> 01:16:04.909
in your blog reflection tonight
about some of these videos,

01:16:04.909 --> 01:16:05.825
that would be awesome.

01:16:09.900 --> 01:16:14.570
So we've hit upon
some qualities of what

01:16:14.570 --> 01:16:16.990
makes a good video, a
good educational video,

01:16:16.990 --> 01:16:21.100
a good YouTube video,
a good TV video.

01:16:21.100 --> 01:16:23.620
But the question of
what is good, right?

01:16:23.620 --> 01:16:25.560
Because ultimately
we have to figure out

01:16:25.560 --> 01:16:28.700
what we're going to define
as success in this class,

01:16:28.700 --> 01:16:33.370
because otherwise there's going
to be no impetus to improve.

01:16:33.370 --> 01:16:37.130
It's a really hard question,
because what is good

01:16:37.130 --> 01:16:38.940
is really intangible.

01:16:38.940 --> 01:16:42.280
It's really inaccessible, at
least in the field of video,

01:16:42.280 --> 01:16:45.870
or whatever we're going to try
to do, because what is good

01:16:45.870 --> 01:16:49.060
is very much a matter of
personal taste, right?

01:16:49.060 --> 01:16:53.380
Like I personally don't really
like the AsapSCIENCE videos,

01:16:53.380 --> 01:16:56.197
but I recognize them as
being successful in what

01:16:56.197 --> 01:16:56.780
they're doing.

01:16:56.780 --> 01:17:00.790
They're engaging people,
they're spreading STEM literacy,

01:17:00.790 --> 01:17:02.544
they're getting
people to be curious.

01:17:02.544 --> 01:17:04.960
I'm not sure how much they're
opening the door to science,

01:17:04.960 --> 01:17:06.890
but I mean they're doing
good things even if I

01:17:06.890 --> 01:17:09.800
don't personally enjoy them.

01:17:09.800 --> 01:17:13.290
And a lot of people love
Hank Green from SciShow

01:17:13.290 --> 01:17:15.420
and a lot of people think
he's super annoying.

01:17:15.420 --> 01:17:19.100
So again, it's really hard
to define what is good.

01:17:19.100 --> 01:17:22.580
We often try to approximate
what is good by other measures,

01:17:22.580 --> 01:17:25.200
so a lot of times
we'll look at virality,

01:17:25.200 --> 01:17:27.635
how many views it has, how
many subscribers they have.

01:17:27.635 --> 01:17:32.840
But again, virality is something
that you can sort of assess

01:17:32.840 --> 01:17:35.390
in retrospect but
it's not necessarily

01:17:35.390 --> 01:17:38.240
the most predictive measure,
because so much of it

01:17:38.240 --> 01:17:40.252
rests on confounding
variables like what

01:17:40.252 --> 01:17:42.460
are the current events that
are happening at the time

01:17:42.460 --> 01:17:46.960
that the video comes out,
what's the personality like.

01:17:46.960 --> 01:17:50.940
Have you guys ever seen
the OK Go music videos?

01:17:50.940 --> 01:17:54.260
So they're this popular
alternative band,

01:17:54.260 --> 01:17:57.420
and their big breakout
video was them

01:17:57.420 --> 01:18:00.460
doing this huge choreographed
dance on four treadmills.

01:18:00.460 --> 01:18:02.160
And ever since then
they've sort of

01:18:02.160 --> 01:18:04.832
tried to do this similar
thing of a single take shot.

01:18:04.832 --> 01:18:06.540
I didn't actually show
any of the videos,

01:18:06.540 --> 01:18:09.060
but I can send you
guys the links later.

01:18:09.060 --> 01:18:12.600
They do these single cam,
continuous shots of just

01:18:12.600 --> 01:18:15.777
like outrageous dances,
and I don't even

01:18:15.777 --> 01:18:16.860
know how to describe them.

01:18:16.860 --> 01:18:19.530
But the first one was the
one where they struck gold.

01:18:19.530 --> 01:18:22.230
And they repeated the same
thing, it was the same people,

01:18:22.230 --> 01:18:24.300
but their later ones,
which are successful,

01:18:24.300 --> 01:18:26.650
aren't nearly as successful
as that treadmill one.

01:18:26.650 --> 01:18:29.610
So there are qualities
about viral video

01:18:29.610 --> 01:18:32.430
that are universal,
things like authenticity.

01:18:32.430 --> 01:18:34.570
A naked celebrity is
always going to go viral.

01:18:34.570 --> 01:18:37.660
But it's very hard to build
a predictive model based off

01:18:37.660 --> 01:18:41.549
of a regression that you're
looking at in the past.

01:18:41.549 --> 01:18:43.590
And then you have things
like learning objectives

01:18:43.590 --> 01:18:47.440
that you can use to
qualify something as good.

01:18:47.440 --> 01:18:51.350
You can say, oh, this video
hit upon all to the standards

01:18:51.350 --> 01:18:54.060
that seventh graders in the
US need to know about biology

01:18:54.060 --> 01:18:55.930
so it's a good video,
and maybe that's

01:18:55.930 --> 01:18:57.850
why Bozeman Science--
maybe that's

01:18:57.850 --> 01:18:59.040
why he makes good videos.

01:18:59.040 --> 01:19:01.300
But it only tells so
much of the picture.

01:19:01.300 --> 01:19:05.160
So what is going to be
our definition of good?

01:19:05.160 --> 01:19:08.390
And this is a question that
I still am struggling with

01:19:08.390 --> 01:19:11.300
and I am totally
open to us discussing

01:19:11.300 --> 01:19:13.230
as the class progresses.

01:19:13.230 --> 01:19:16.360
But I do think that
there are going

01:19:16.360 --> 01:19:19.380
to be certain qualities that we
should strive for, regardless

01:19:19.380 --> 01:19:22.690
of if your taste is in
really rapid delivery

01:19:22.690 --> 01:19:29.640
or if it's in very sort of
philosophical, grandiose type

01:19:29.640 --> 01:19:32.180
videos.

01:19:32.180 --> 01:19:34.280
This is a quote from a
reading that you guys

01:19:34.280 --> 01:19:37.259
are going to annotate on
tonight for your homework,

01:19:37.259 --> 01:19:39.050
from Hank Green, who's
the host of SciShow.

01:19:39.050 --> 01:19:42.030
But he says, "People who are
new to the medium are starting

01:19:42.030 --> 01:19:44.980
to think that online video is
not 'Just a little bit better

01:19:44.980 --> 01:19:48.050
than everything else on YouTube'
but 'Just a little bit worse

01:19:48.050 --> 01:19:50.140
than everything
that's on TV.'" And,

01:19:50.140 --> 01:19:53.000
"That perspective is a super
dangerous road to go down on."

01:19:53.000 --> 01:19:56.090
That's sort of hitting upon
what I was saying earlier about

01:19:56.090 --> 01:20:00.140
you can't take necessarily the
best practices in the realms

01:20:00.140 --> 01:20:04.380
that we're trying to combine and
transfer them over and expect

01:20:04.380 --> 01:20:05.920
great results, right?

01:20:05.920 --> 01:20:07.810
You can't try to
make a video like you

01:20:07.810 --> 01:20:10.260
would TV show, necessarily.

01:20:10.260 --> 01:20:11.310
So what is good?

01:20:11.310 --> 01:20:16.140
If good isn't the combined
practices of TV, education,

01:20:16.140 --> 01:20:19.950
YouTube, what is
good going to be?

01:20:19.950 --> 01:20:22.370
So this is a viral
video manifesto that's,

01:20:22.370 --> 01:20:24.117
again, optional reading.

01:20:24.117 --> 01:20:25.200
It's actually pretty good.

01:20:25.200 --> 01:20:28.590
It's from the guys who made
the Diet Coke and Mentos video?

01:20:28.590 --> 01:20:30.600
Have you ever seen
it, where they combine

01:20:30.600 --> 01:20:33.190
Mentos and Diet Coke and
there's this huge, choreographed

01:20:33.190 --> 01:20:34.550
explosion?

01:20:34.550 --> 01:20:35.980
They talk about four points.

01:20:35.980 --> 01:20:39.270
Be true, be authentic.

01:20:39.270 --> 01:20:40.740
Don't waste our time.

01:20:40.740 --> 01:20:42.460
On an online video,
you can't afford

01:20:42.460 --> 01:20:45.260
to do what Connections did
and take two whole minutes

01:20:45.260 --> 01:20:47.910
to set up the premise,
because that's sometimes

01:20:47.910 --> 01:20:49.140
the entirety of a video.

01:20:51.670 --> 01:20:53.890
Be unforgettable,
show us something

01:20:53.890 --> 01:20:55.420
that we've never seen before.

01:20:55.420 --> 01:20:58.360
And that honestly might be
the hardest thing for us

01:20:58.360 --> 01:21:00.380
here, at least it
was the hardest thing

01:21:00.380 --> 01:21:03.290
for a lot of the students that
we worked with on the first two

01:21:03.290 --> 01:21:06.370
seasons of Science Out Loud,
that it's very hard to take

01:21:06.370 --> 01:21:09.220
yourself out of the perspective
of being an MIT student,

01:21:09.220 --> 01:21:12.016
or being a student involved
in science and engineering.

01:21:12.016 --> 01:21:13.890
And remember that some
of the things that you

01:21:13.890 --> 01:21:16.240
take for granted and are
part of your everyday life

01:21:16.240 --> 01:21:20.060
are actually really awesome
and really cool, and things

01:21:20.060 --> 01:21:22.320
that most people
don't see every day.

01:21:22.320 --> 01:21:24.400
You may work at
the nuclear reactor

01:21:24.400 --> 01:21:27.240
here and think that it's
just another everyday thing,

01:21:27.240 --> 01:21:29.960
but that's a window
that you can create

01:21:29.960 --> 01:21:35.750
for people who would have
never, ever had access to it.

01:21:35.750 --> 01:21:38.019
And then ultimately,
it's about humanity,

01:21:38.019 --> 01:21:39.310
about the emotional connection.

01:21:39.310 --> 01:21:42.840
A lot of that comes
from the authenticity,

01:21:42.840 --> 01:21:49.500
that if we can swap you out
with just the computer voice

01:21:49.500 --> 01:21:51.890
and there's not that much
of a difference, then

01:21:51.890 --> 01:21:54.350
really rethink how you're
structuring and writing

01:21:54.350 --> 01:21:55.710
and producing your video.

01:21:58.530 --> 01:22:01.930
So there are going to be
four course values that'll

01:22:01.930 --> 01:22:05.390
guide all of the assignments
and all the things that we do.

01:22:05.390 --> 01:22:10.980
And the rubric is listed in the
syllabus that's on the website.

01:22:10.980 --> 01:22:13.760
We don't really
assign point values

01:22:13.760 --> 01:22:17.290
to did you do correct
lighting, did you do this,

01:22:17.290 --> 01:22:20.187
did you set up your
camera the right way,

01:22:20.187 --> 01:22:22.020
because we don't want
you guys to get bogged

01:22:22.020 --> 01:22:23.430
down in the minutia of it.

01:22:23.430 --> 01:22:27.550
Instead, there are going to be
these four overarching values

01:22:27.550 --> 01:22:31.471
that'll dictate what
is good, I guess,

01:22:31.471 --> 01:22:32.720
as we move along in the class.

01:22:32.720 --> 01:22:36.060
The first one is Spark.

01:22:36.060 --> 01:22:38.060
There's this quote, and
I think it's by Fellini,

01:22:38.060 --> 01:22:40.610
but something along
the lines of it's

01:22:40.610 --> 01:22:42.360
not what's inside the
camera that matters,

01:22:42.360 --> 01:22:45.020
so much as what's in
front of and behind it.

01:22:45.020 --> 01:22:47.610
So are you promoting curiosity?

01:22:47.610 --> 01:22:50.820
Is there a perceived love
of learning in your product?

01:22:56.060 --> 01:22:59.100
Right, is there a perceived love
of learning in your product?

01:22:59.100 --> 01:23:02.870
Is your passion and joy
evident in your delivery?

01:23:02.870 --> 01:23:06.516
This can be seen in your
script, in your final video.

01:23:06.516 --> 01:23:08.640
This doesn't mean that you
need to go over the top.

01:23:08.640 --> 01:23:11.120
It doesn't mean that you
have to pretend to be someone

01:23:11.120 --> 01:23:14.150
that you're naturally not or you
don't feel comfortable being.

01:23:14.150 --> 01:23:16.260
But I'm sure all
of us in this room

01:23:16.260 --> 01:23:18.010
have something that
they're excited about,

01:23:18.010 --> 01:23:22.790
so can we perceive that
excitement in your product?

01:23:22.790 --> 01:23:23.290
Clarity.

01:23:23.290 --> 01:23:26.270
So "Kill all of your darlings"
is one of my favorite sayings

01:23:26.270 --> 01:23:29.770
and something that dictates
a lot of the work that I do.

01:23:29.770 --> 01:23:34.950
But this will be learning how to
navigate the material you have

01:23:34.950 --> 01:23:37.440
and getting rid of stuff, maybe
getting rid of explanations

01:23:37.440 --> 01:23:39.920
that don't need to be there.

01:23:39.920 --> 01:23:41.940
Editing is going to
be a lot about this,

01:23:41.940 --> 01:23:45.390
and the last lecture is
a lot about this quote.

01:23:45.390 --> 01:23:49.340
But it's also about can
you convey your message

01:23:49.340 --> 01:23:50.640
in the most clear manner?

01:23:50.640 --> 01:23:52.890
Is your script tightly written?

01:23:52.890 --> 01:23:55.570
Is your delivery engaging?

01:23:55.570 --> 01:23:58.710
Have you realized your vision
as effectively as possible?

01:24:02.750 --> 01:24:04.500
Then we have
thoughtfulness, which

01:24:04.500 --> 01:24:06.330
is that every decision matters.

01:24:06.330 --> 01:24:08.250
Whether it's deciding
what background you're

01:24:08.250 --> 01:24:11.520
going to stand in front of to
deliver one of your scenes,

01:24:11.520 --> 01:24:15.600
or deciding what facts to
include in your final script,

01:24:15.600 --> 01:24:16.980
every single decision matters.

01:24:16.980 --> 01:24:18.830
And it's thoughtfulness
about what

01:24:18.830 --> 01:24:20.710
you decide to put in
front of the camera,

01:24:20.710 --> 01:24:24.630
but also how you decide
to talk to your audience.

01:24:24.630 --> 01:24:26.760
And again, it's outlined
more in the rubric.

01:24:31.710 --> 01:24:34.340
And then go big or go home.

01:24:34.340 --> 01:24:37.630
This is a hard one for
people, understandably.

01:24:37.630 --> 01:24:39.380
This is probably the
hardest one for me.

01:24:39.380 --> 01:24:42.170
But learning how to step
outside your comfort zone

01:24:42.170 --> 01:24:43.840
and getting creative.

01:24:43.840 --> 01:24:46.910
We do you want to
reward creative risks,

01:24:46.910 --> 01:24:52.460
so don't feel like you
can't try something new.

01:24:52.460 --> 01:24:55.910
Again, hopefully it's
an educated risk.

01:24:55.910 --> 01:24:57.990
But these are all
qualities that we're

01:24:57.990 --> 01:25:00.510
going to assess, not only
through your final products

01:25:00.510 --> 01:25:02.590
but through your
daily reflections,

01:25:02.590 --> 01:25:05.620
through a lot of the
iterative processes that

01:25:05.620 --> 01:25:09.589
will be happening on the
way to your final products.

01:25:09.589 --> 01:25:11.630
And this is where we're
going to integrate things

01:25:11.630 --> 01:25:16.060
like are things clearly lit,
but in the context of was

01:25:16.060 --> 01:25:17.180
this a clear message.

01:25:17.180 --> 01:25:18.596
Does that makes
sense to everyone?

01:25:22.000 --> 01:25:26.550
So if you want to make a
video, where do you start?

01:25:26.550 --> 01:25:29.140
The first thing is deciding
if you should make a video.

01:25:29.140 --> 01:25:31.231
And I think this
list of questions

01:25:31.231 --> 01:25:32.980
is one that everyone
should ask themselves

01:25:32.980 --> 01:25:34.120
before they make a video.

01:25:34.120 --> 01:25:36.400
Why am I making a video
in the first place,

01:25:36.400 --> 01:25:41.310
versus a BuzzFeed article
or versus a radio piece?

01:25:41.310 --> 01:25:42.980
Who is going to
watch this video?

01:25:42.980 --> 01:25:44.600
This will make a
very big difference

01:25:44.600 --> 01:25:47.120
in how you decide to
write your script,

01:25:47.120 --> 01:25:49.310
how you decide to deliver.

01:25:49.310 --> 01:25:51.740
For the most part,
our assignments

01:25:51.740 --> 01:25:55.600
will be assuming sort of a
middle school type science

01:25:55.600 --> 01:25:57.910
background.

01:25:57.910 --> 01:25:59.970
What visuals will I show?

01:25:59.970 --> 01:26:01.860
Again, this makes a
really big difference.

01:26:01.860 --> 01:26:06.460
As Paul was saying, the Khan
Academy video didn't really

01:26:06.460 --> 01:26:09.640
have the visuals that motivated
the lesson that he was wanting

01:26:09.640 --> 01:26:12.320
to learn, so thinking about what
visuals you're going to show

01:26:12.320 --> 01:26:14.230
are super important.

01:26:14.230 --> 01:26:17.010
What is the fact or
piece of information

01:26:17.010 --> 01:26:19.260
that the audience is really
going to remember the most

01:26:19.260 --> 01:26:20.750
or surprise them?

01:26:20.750 --> 01:26:23.740
In the Smarter Every Day
video about the cat flipping,

01:26:23.740 --> 01:26:26.480
it's just that whole
concept of a cat

01:26:26.480 --> 01:26:29.600
can seemingly defy
the laws of gravity,

01:26:29.600 --> 01:26:35.570
but it's really just a
modification of their torque

01:26:35.570 --> 01:26:37.760
or something that
actually makes them

01:26:37.760 --> 01:26:39.590
able to flip the way to do.

01:26:39.590 --> 01:26:43.020
And the biggest one is what
is the point of this video?

01:26:43.020 --> 01:26:45.410
Now, the guys who wrote
the viral video manifesto,

01:26:45.410 --> 01:26:48.040
they used to be circus
performers, so in their book

01:26:48.040 --> 01:26:52.220
they talk about how there's a
slideshow circus pitch, which

01:26:52.220 --> 01:26:54.610
is when you have the
ringleader around the side

01:26:54.610 --> 01:26:56.900
and he's like step right
up, step right up, come

01:26:56.900 --> 01:27:03.200
see the world's smallest person
next to the world's giant man

01:27:03.200 --> 01:27:04.450
or something like that, right?

01:27:04.450 --> 01:27:06.490
There should be some
sort of circus sideshow

01:27:06.490 --> 01:27:08.350
pitch to your video idea.

01:27:08.350 --> 01:27:11.070
So one of the
episodes we made was

01:27:11.070 --> 01:27:13.910
on farts, which
maybe our motivation

01:27:13.910 --> 01:27:16.610
was just that we wanted to
make a video about farts.

01:27:16.610 --> 01:27:20.320
But on the other hand, there's
this amazing biochemical

01:27:20.320 --> 01:27:22.630
process that's associated
with all of that,

01:27:22.630 --> 01:27:26.300
and it really reflects just
this incredible diversity

01:27:26.300 --> 01:27:30.450
of microbiomes that
exist in your body.

01:27:30.450 --> 01:27:33.359
And so it's not just step
right up, step right up,

01:27:33.359 --> 01:27:34.650
come watch a video about farts.

01:27:34.650 --> 01:27:36.030
It's like step right
up, step right up--

01:27:36.030 --> 01:27:37.071
what's the thing I wrote?

01:27:41.130 --> 01:27:43.850
Witness your body's countless
armies of lowly bacteria

01:27:43.850 --> 01:27:45.660
squeeze every drop of
energy from your gut

01:27:45.660 --> 01:27:48.480
and create horrendous
sounds and smells.

01:27:48.480 --> 01:27:52.150
So there should be some
sort of circus sideshow

01:27:52.150 --> 01:27:54.740
pitch to your
video, and Chris is

01:27:54.740 --> 01:27:59.620
going to help us realize
that in the actual way of how

01:27:59.620 --> 01:28:02.570
do I actually make that
video, how do I actually

01:28:02.570 --> 01:28:04.370
create that vision.

01:28:04.370 --> 01:28:07.180
So that's what we're going to
do for the last part of class.

01:28:07.180 --> 01:28:10.600
But be thinking about maybe
what your circus sideshow

01:28:10.600 --> 01:28:11.690
pitch is going to be.

01:28:11.690 --> 01:28:14.580
And eventually
tonight everyone is

01:28:14.580 --> 01:28:17.900
going to need to create
a very short, maybe

01:28:17.900 --> 01:28:20.070
two-minute video, one
to two-minute video,

01:28:20.070 --> 01:28:22.540
a science, technology,
engineering,

01:28:22.540 --> 01:28:26.190
math topic that
you're basically going

01:28:26.190 --> 01:28:27.560
to pitch through this video.

01:28:27.560 --> 01:28:31.145
It's going to be sort of a
trailer for your final project.

01:28:31.145 --> 01:28:35.070
All right, Chris, I
will let you take over.

