WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.000
[Brady] What are those zig-zaggy lines I keep seeing on videos on YouTube?

00:00:04.000 --> 00:00:05.300
[Prof] Wait, you mean ones like this?

00:00:05.339 --> 00:00:09.330
[Prof] So you can see on the BBC's news ticker here
we've got a lot of this sort of combing

00:00:09.330 --> 00:00:13.290
and ziggy-zag like effect on the
video what's going on that

00:00:13.290 --> 00:00:16.890
well this is an interesting problem but
the basic problem is that computer

00:00:16.890 --> 00:00:20.910
people don't understand video what
you're seeing there is an artifact of

00:00:20.910 --> 00:00:24.000
the way that the video system to put
together in the thirties when they

00:00:24.000 --> 00:00:28.619
developed the first video systems are
designed them using analog electronics

00:00:28.619 --> 00:00:32.969
remember this is about 10 years before
the first computer was invented the

00:00:32.969 --> 00:00:36.210
first electronic computer was invented
so they're having to develop the video

00:00:36.210 --> 00:00:40.410
system using pure analog electronics and
so they had to make sensible design

00:00:40.410 --> 00:00:44.879
decisions on that time to encode the
video so they could transmit it and get

00:00:44.879 --> 00:00:51.090
into people's homes where they can watch
it on the television screens that's all

00:00:51.090 --> 00:00:54.480
well and good but we've got modern
computers and we've been some movement

00:00:54.480 --> 00:00:59.010
back since then why if we got was
exactly like this and hopefully steps

00:00:59.010 --> 00:01:02.640
well we'll come to that was actually
look at what is actually happening how

00:01:02.640 --> 00:01:06.570
these things are put together now Sean's
hopefully give me a bit of computer

00:01:06.570 --> 00:01:11.010
listing paper which is great because
divided into lines so the way that the

00:01:11.010 --> 00:01:14.939
image was built up is that every 5000
second we talked about in the previous

00:01:14.939 --> 00:01:19.080
video why need to do it 50 frames per
second to get decent motion rendition

00:01:19.080 --> 00:01:25.560
the camera would scan the image from the
top left to the bottom right and it

00:01:25.560 --> 00:01:30.570
would go along the first line going back
to the beginning and go on the next line

00:01:30.570 --> 00:01:35.670
swing back and then go along the next
one and so on until eventually it comes

00:01:35.670 --> 00:01:39.990
to the end at which point it goes back
up to the beginning of the frame and

00:01:39.990 --> 00:01:43.079
starts during the same thing but there's
a problem

00:01:43.079 --> 00:01:47.460
the amount of day 2 there is generated
scanning was formed and five line TV

00:01:47.460 --> 00:01:52.439
back in 96 in the UK at 50 frames per
second was too much that could be

00:01:52.439 --> 00:01:55.500
reliably transmitted with the technology
of the time there's too much information

00:01:55.500 --> 00:01:59.399
that you need to transmit too much
bandwidth will be taken up so they need

00:01:59.399 --> 00:02:04.860
to do something they couldn't go down to
25 frames per second because then you

00:02:04.860 --> 00:02:08.700
would flicker like crazy as we talked
about in the last video so they couldn't

00:02:08.700 --> 00:02:11.530
reduce the frame rate this lot of
shooting for

00:02:11.530 --> 00:02:15.490
the frames per second to get the frame
rate so they came up with a trick which

00:02:15.490 --> 00:02:21.520
they call interlacing so if we start
again if we call the first warm align

00:02:21.520 --> 00:02:22.360
warm

00:02:22.360 --> 00:02:28.180
the second one is line 2 3 4 5 and so on
what they said was we will transmit

00:02:28.180 --> 00:02:30.160
first line one

00:02:30.160 --> 00:02:35.500
so you scan across Longbourn like so and
then we'll skip over line to and

00:02:35.500 --> 00:02:36.760
transmit line three

00:02:36.760 --> 00:02:40.120
so we fly back and we transmit Lyme
three and then we skip over the line for

00:02:40.120 --> 00:02:44.830
and transmit Lyme five and so you do all
that until you get down to the bottom of

00:02:44.830 --> 00:02:48.430
the image you transmitting only the
odd-numbered life so in that 50 the

00:02:48.430 --> 00:02:52.420
second one thing the whole frame you
send every of the line or half the frame

00:02:52.420 --> 00:02:57.819
and they refer to that as a field and
then you go back and scan the even

00:02:57.819 --> 00:03:05.319
numbered lines so 2 4 6 8 and so on to
scan all the even numbered lines in the

00:03:05.319 --> 00:03:11.440
next 50 per second so what you actually
ended up doing you send your first field

00:03:11.440 --> 00:03:14.860
which would be all the odd lines and
then offensive a second later you

00:03:14.860 --> 00:03:19.750
sending the second films that got all
the even lines in it and then you

00:03:19.750 --> 00:03:24.519
sending the third field which got all
the old lines in it again and so on so

00:03:24.519 --> 00:03:31.450
you sending all the guidelines for the
even lines or the outlines now because

00:03:31.450 --> 00:03:35.620
this is all been doing with analog
equipment you couldn't store the image

00:03:35.620 --> 00:03:39.519
and send the old lines and send even
live in the same point in time so when

00:03:39.519 --> 00:03:43.750
you capture the odd lines here this
would start at time zero when you start

00:03:43.750 --> 00:03:48.910
capturing the even lines it's a
54-second later so you capturing this 20

00:03:48.910 --> 00:03:53.140
milliseconds later and so on so each
field is sampled a different point in

00:03:53.140 --> 00:03:57.880
time so you've got 50 discreet images
captured but each of their only has half

00:03:57.880 --> 00:04:02.320
the number of lines and they have a
different half in that that's fine and

00:04:02.320 --> 00:04:06.010
you transmit that you can record that I
my loved video tape you can transmit you

00:04:06.010 --> 00:04:10.209
can do all sorts of processing with it
until you start coming to put into

00:04:10.209 --> 00:04:14.920
computers and because what happened was
is that people started to treat it

00:04:14.920 --> 00:04:19.000
always say well actually people still
talk about things being 25 frames per

00:04:19.000 --> 00:04:23.229
second in UK they never were they were
always 50 fields per second so when he

00:04:23.229 --> 00:04:25.100
gets pushed into the computer

00:04:25.100 --> 00:04:30.080
your computer will capture the first not
filled never capture the second even

00:04:30.080 --> 00:04:33.800
field and it will start to interlace
them back together to create a single

00:04:33.800 --> 00:04:39.350
frame about the other things in that in
the actual image and he puts them

00:04:39.350 --> 00:04:42.920
together and stores them in the
QuickTime file in the ABI whatever it is

00:04:42.920 --> 00:04:45.920
he using at 25 frames per second

00:04:47.240 --> 00:04:51.410
now that's fine because you can play
them back out of us or capture card and

00:04:51.410 --> 00:04:54.860
mid nineties back onto a TV and it
looked files because it wouldn't pick

00:04:54.860 --> 00:04:57.170
them and send them out in the right
order

00:04:57.170 --> 00:05:01.910
the problem comes if you then try to
display that image directly on screen in

00:05:01.910 --> 00:05:05.360
that because things are moving between
each of those things you get the sort of

00:05:05.360 --> 00:05:09.680
little zigzag effects because actually
this letter T here is moving

00:05:09.680 --> 00:05:13.790
horizontally so each time is captured
the lines of the different . so when you

00:05:13.790 --> 00:05:17.450
interlock them you get that sort of
carry me effect on the edge

00:05:17.450 --> 00:05:21.290
it's a pain how do you display it
properly you do ask difficult questions

00:05:21.290 --> 00:05:28.490
so what do you have to do well first of
all you need to think about it not as

00:05:28.490 --> 00:05:33.980
being a single frame that you interlace
by together but actually being separate

00:05:33.980 --> 00:05:39.110
crimes if we have the lines along here
and we have time along here we got zero

00:05:39.110 --> 00:05:46.880
there we got four field one here feel to
hear field three here field for field

00:05:46.880 --> 00:05:51.830
five on points0 we're capturing let's
say we do this with the odd ones we

00:05:51.830 --> 00:05:57.110
capture these lines here at it . one
actually capturing the bits in the

00:05:57.110 --> 00:06:02.360
middle catching that bit capturing that
bit capturing that bit capturing that

00:06:02.360 --> 00:06:04.550
bit capturing that bit

00:06:04.550 --> 00:06:11.240
character in that bit then it . to we're
capturing the there and so on . through

00:06:11.240 --> 00:06:16.670
were capturing hear it hear what they're
trying to do with interlaced is to

00:06:16.670 --> 00:06:20.750
reduce the amount of information they
need to transmit so you could think of

00:06:20.750 --> 00:06:24.710
it perhaps a bit like a sort of early
analog compression system been like mp3

00:06:24.710 --> 00:06:28.580
reduces the amount of information needs
to be store to store some audio

00:06:28.580 --> 00:06:31.670
interfaces doing the same thing with
videos reducing the amount of

00:06:31.670 --> 00:06:35.690
information but hopefully it's not
throwing away anything that you're going

00:06:35.690 --> 00:06:38.800
to see something static like a video
into this

00:06:38.800 --> 00:06:43.690
book very little is lost by transmitting
in an interlaced form over a

00:06:43.690 --> 00:06:48.099
non-interlaced from progressive form was
it be called would still see all that

00:06:48.099 --> 00:06:52.780
pretty much all the detail we see
between the two so we reduce the amount

00:06:52.780 --> 00:06:56.620
of information you transmit by half but
we're still effectively transmitting

00:06:56.620 --> 00:06:59.710
what looks the same to the end user when
they're viewing it on the television

00:06:59.710 --> 00:07:00.639
screen

00:07:00.639 --> 00:07:03.940
certainly the time when this was
developed but we're still free

00:07:03.940 --> 00:07:07.300
information where every sample . before
anyway half the information we could

00:07:07.300 --> 00:07:11.530
possibly have captured there and
actually what we're throwing away is the

00:07:11.530 --> 00:07:17.770
separation between vertical resolution I
how much detail we can represent and

00:07:17.770 --> 00:07:25.330
also temporal resolution what we've got
here is this is a single capture . 2.0

00:07:25.330 --> 00:07:31.479
we capture all the odd lines . when we
capture all the even lines now think

00:07:31.479 --> 00:07:37.840
about something like the piece of paper
i am capturing here 2.0 I capture this

00:07:37.840 --> 00:07:42.219
line here which is white and this launch
is white and so on all the way down so

00:07:42.219 --> 00:07:45.490
effectively what we captured each point
on here is a completely white field at

00:07:45.490 --> 00:07:48.940
this point though we capture this line
which is green we capture this line

00:07:48.940 --> 00:07:52.419
which is also green and we capture this
line which is also green and at this

00:07:52.419 --> 00:07:55.840
point in time we capture completely
greenfield the next point in time we go

00:07:55.840 --> 00:07:59.500
back and capture completely white field
and then we capture completely

00:07:59.500 --> 00:08:04.419
greenfield and if you display this what
you would see would not be a series of

00:08:04.419 --> 00:08:08.860
watching green lines but actually the
image flashing between white and green

00:08:08.860 --> 00:08:12.430
we've got to a situation where yes we've
reduced the amount of information that

00:08:12.430 --> 00:08:17.169
we need to transmit we've also
manipulated the information so that we

00:08:17.169 --> 00:08:21.129
cannot distinguish between
high-resolution vertical information

00:08:24.460 --> 00:08:30.100
it's eerie just to help try to help out
yet

00:08:31.810 --> 00:08:39.310
I'm sorry seriously you can't do a
computer file yet so effectively what

00:08:39.310 --> 00:08:43.300
we've got is we've mapped both the
high-frequency vertical information and

00:08:43.300 --> 00:08:47.380
also temporal information into the same
part of the encoding of the information

00:08:47.380 --> 00:08:52.630
and so there's no easy way to
distinguish between the two so high

00:08:52.630 --> 00:08:56.709
frequency information like this
oscillating white-and-green pattern is

00:08:56.709 --> 00:09:01.390
indistinguishable once we've interlaced
it from flashing white and green screen

00:09:01.390 --> 00:09:05.230
there's just no way you can deal with
that the way you get round this is

00:09:05.230 --> 00:09:09.970
inside the camera when you sample the
information you filter it vertically so

00:09:09.970 --> 00:09:13.480
that you don't have the high-resolution
image that so effectively an interlaced

00:09:13.480 --> 00:09:17.740
camera let's go slightly lower vertical
resolution and the progressive woman had

00:09:17.740 --> 00:09:22.300
but probably around seventy percent of
the vertical information is still there

00:09:22.300 --> 00:09:26.350
still better than you'd get if you are
you transmitted a smaller number of

00:09:26.350 --> 00:09:30.520
lines every frame so it gives you the
benefit but this still comes down to

00:09:30.520 --> 00:09:34.240
think how on earth do we display
interlace material on someone like a

00:09:34.240 --> 00:09:37.930
computer which has an inherently
progressive display without getting all

00:09:37.930 --> 00:09:41.110
the sort of it's exactly patterns

00:09:41.110 --> 00:09:48.399
well it's not an easy it's not an easy
problem to Seoul it can be in some

00:09:48.399 --> 00:09:51.430
situations so there's some of the
situations where it can be really easy

00:09:51.430 --> 00:09:57.279
to deal with for example film translated
onto a video film shot at 25 frames that

00:09:57.279 --> 00:10:02.170
we talked about in the other one when
that is transferred onto video tape is

00:10:02.170 --> 00:10:07.779
that you take the piece of film you scan
the ordinal bloodlines transmit that the

00:10:07.779 --> 00:10:10.779
fields can't even numbered lines
transmitted as a field then we want to

00:10:10.779 --> 00:10:14.320
the next frame is actually knows . the
two fields do come from the same point

00:10:14.320 --> 00:10:18.940
in time so actually the best way to get
them back together is literally to weave

00:10:18.940 --> 00:10:23.860
them together though and you get the
same film praying that you started with

00:10:23.860 --> 00:10:28.300
all the representation of what you get
all the detail so that's the best way to

00:10:28.300 --> 00:10:33.100
do it for fill material for something
like videos we've seen on the computer

00:10:33.100 --> 00:10:36.459
screen that doesn't work what you need
to do is actually

00:10:37.250 --> 00:10:42.590
only have information that should be it
. 0 displayed there and I've only have

00:10:42.590 --> 00:10:47.180
information . one displayed here and
then you have information . to displayed

00:10:47.180 --> 00:10:52.580
here however you go about that well this
several ways you could do it you could

00:10:52.580 --> 00:10:56.120
just say well okay I know it's gonna
fill in this gap here

00:10:56.120 --> 00:11:00.320
so what I'll do is I'll interpolate
between line worn on line three and work

00:11:00.320 --> 00:11:03.650
out what line to would be so i'll just
use the information inside . of time and

00:11:03.650 --> 00:11:09.200
just create a sort of that's the thing
there and then i'll do the same between

00:11:09.200 --> 00:11:13.880
three and five between five and seven
and so on the problem that happens here

00:11:13.880 --> 00:11:17.360
is that you immediately reduce the
resolution down to only being as high as

00:11:17.360 --> 00:11:20.330
the number of lines you've got in the
field so is there any way you can do

00:11:20.330 --> 00:11:24.230
this well yeah basically what you want
to do is to generate the information

00:11:24.230 --> 00:11:28.130
that would have been there if the camera
captured at that point and the way you

00:11:28.130 --> 00:11:33.590
can do that is not just use the line
above the line below but also realize

00:11:33.590 --> 00:11:38.930
that you know what was in that . 50-50
split second before and you could also

00:11:38.930 --> 00:11:45.230
know what's in that . 15-second in the
future if you delayed everything by a

00:11:45.230 --> 00:11:49.490
single field so what we doing instead of
actually trying to generate this frame

00:11:49.490 --> 00:11:54.320
here at point2 we store it digitally we
can do the computer quite easily until

00:11:54.320 --> 00:12:00.650
we get 2.3 at which point we've already
seen this information so we can use that

00:12:00.650 --> 00:12:04.580
we've got this information was just
arrived and we got these two bits of

00:12:04.580 --> 00:12:09.920
information and we can combine all that
together to generate the data that

00:12:09.920 --> 00:12:13.280
should be at this point and the data
that should be at this point and so on

00:12:13.280 --> 00:12:17.480
so we delay the video by field or two
fields and said that we now have more

00:12:17.480 --> 00:12:20.360
information we got something that's in
the future from the point where

00:12:20.360 --> 00:12:23.480
generating we've got the information in
the past we've already seen and the

00:12:23.480 --> 00:12:27.320
information that's on different lines as
well and we can combine all that in

00:12:27.320 --> 00:12:32.240
various different complicated algorithms
to generate the information and the more

00:12:32.240 --> 00:12:36.530
expensive your equipment the clever the
algorithm will be and the better it will

00:12:36.530 --> 00:12:41.420
do and so if we were to enable one of
them on our computer and VLC which is

00:12:41.420 --> 00:12:47.060
what I'm using here is got several
built-in then i'm going to enable yet

00:12:47.060 --> 00:12:50.690
another deinterlacing algorithm and

00:12:50.690 --> 00:12:56.600
if I turn it on and you will see that
suddenly instead of being zigzaggy it

00:12:56.600 --> 00:13:03.770
goes back to being straightforward text
most tvs these days are LCD panels on

00:13:03.770 --> 00:13:09.200
the younger or whatever maybe plasma so
are they doing this kind of stuff all

00:13:09.200 --> 00:13:11.540
the time that or do they use a different
method

00:13:11.540 --> 00:13:15.440
no that's why they're doing this inside
every LCD you'll get there will be a

00:13:15.440 --> 00:13:19.790
chip which will be taking the video and
processing it to produce progressive

00:13:19.790 --> 00:13:23.240
video from the interlaced video that's
coming in and depending on how much you

00:13:23.240 --> 00:13:29.240
pay for that chip but it's a 50p chip or
75p chip and that 50 p is the price not

00:13:29.240 --> 00:13:33.560
the resolution is a video is producing
it depends 250 pounds chip or fifty

00:13:33.560 --> 00:13:38.690
cents because it's probably worth more
these days then you are going to get a

00:13:38.690 --> 00:13:42.980
better quality out with hope you have on
this reprogramming but that cause even

00:13:42.980 --> 00:13:45.980
more money

00:13:48.960 --> 00:13:53.640
that's why we get ugly lines and that's
how you essentially fix them know that

00:13:53.640 --> 00:14:00.840
you didn't think it was gonna be that
simple did you all right let's go back

00:14:00.840 --> 00:14:07.170
to being so we the video signal coming
is a series of annual screen and then so

00:14:07.170 --> 00:14:10.770
we got a bit later on we move it up show
the next one and so on and so by doing

00:14:10.770 --> 00:14:13.980
that fast enough you get the appearance
of motion

