WEBVTT
Kind: captions
Language: en

00:00:00.420 --> 00:00:02.210
All right. So Charles, what do you think would some

00:00:02.210 --> 00:00:06.150
reasonable resources to try to manage in a learning algorithm?

00:00:06.150 --> 00:00:09.480
&gt;&gt; Okay, well I was thinking of three. Because three is my favorite

00:00:09.480 --> 00:00:12.440
number. Two of them are what you already have written up there. Time and

00:00:12.440 --> 00:00:16.149
space. After all, at the end of the day, it's still an algorithm.

00:00:16.149 --> 00:00:18.490
We need to be able to analyze algorithms in terms of time and space.

00:00:18.490 --> 00:00:22.300
&gt;&gt; That's right, so if in particular we have a learning algorithm and

00:00:22.300 --> 00:00:25.720
they, they do more or less the same things, but one runs in n-squared

00:00:25.720 --> 00:00:28.580
time and the other runs in exponential time, we'd really like

00:00:28.580 --> 00:00:31.300
to have the one that runs in the shorter amount of

00:00:31.300 --> 00:00:33.660
time. Or, in particular, if there's a, if we define a

00:00:33.660 --> 00:00:37.120
learning problem and we say well, We could do this computation, but

00:00:37.120 --> 00:00:41.220
its MP hard. Then maybe that's a problematic way of defining

00:00:41.220 --> 00:00:44.090
the problem. So yeah, time definitely matters. Space for the same

00:00:44.090 --> 00:00:47.100
reason. And those are the same things that happen in in,

00:00:47.100 --> 00:00:51.230
or that are relevant in regular algorithms. What about anything specific to

00:00:51.230 --> 00:00:52.110
the machine learning setting?

00:00:52.110 --> 00:00:54.880
&gt;&gt; Okay, so that was my third one. So The only thing that

00:00:54.880 --> 00:00:58.400
matters in machine learning or the most important thing in machine learning is

00:00:58.400 --> 00:01:02.880
data. So I would think that another resource that we care about is

00:01:02.880 --> 00:01:07.550
the data and in particular the set of training samples that we have.

00:01:07.550 --> 00:01:11.100
&gt;&gt; Yes I like the, I like the word samples. Though data

00:01:11.100 --> 00:01:15.540
is probably pretty good. Thing to stick in there as well or examples.

00:01:17.470 --> 00:01:18.350
Those should all be okay.

00:01:18.350 --> 00:01:21.380
&gt;&gt; Yes. Indeed. Yeah. We, we want to know, can

00:01:21.380 --> 00:01:24.510
we learn well with a small amount of samples. In

00:01:24.510 --> 00:01:27.100
particular if, our learning algorithm works great in terms of

00:01:27.100 --> 00:01:29.200
time and space, but in order to run it you

00:01:29.200 --> 00:01:33.950
actually have to give Examples of every possible input, then

00:01:33.950 --> 00:01:36.140
that's not going to be a very useful algorithm. So,

00:01:36.140 --> 00:01:38.880
the fewer samples that it can use, the more that

00:01:38.880 --> 00:01:41.650
it's generalizing effectively, and the better it is at learning.

00:01:41.650 --> 00:01:42.480
&gt;&gt; Oh, that makes sense.

