WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:03.350
Did you ever wonder what it
would take for mobile devices

00:00:03.350 --> 00:00:05.770
to use their camera to
understand their surroundings,

00:00:05.770 --> 00:00:07.270
like we do?

00:00:07.270 --> 00:00:09.280
Project Tango is a
computer vision platform

00:00:09.280 --> 00:00:12.300
that can do that by
tracking motion, recognizing

00:00:12.300 --> 00:00:16.320
spaces, and scanning
the surroundings in 3D.

00:00:16.320 --> 00:00:19.180
My name is Nicolai
and in this episode,

00:00:19.180 --> 00:00:22.190
we will talk about how motion
tracking gives mobile devices

00:00:22.190 --> 00:00:26.340
the power to track fine grain
movement and move with you.

00:00:26.340 --> 00:00:28.960
Motion tracking can follow
your motions smoothly,

00:00:28.960 --> 00:00:31.830
whether you're standing,
walking or biking.

00:00:31.830 --> 00:00:33.660
We found that it
works well on earth,

00:00:33.660 --> 00:00:36.740
but we took the testing
one step further.

00:00:36.740 --> 00:00:39.740
Project Tango was launched to
the International Space Station

00:00:39.740 --> 00:00:42.630
as part of the SPHERES
robots program.

00:00:42.630 --> 00:00:46.080
These were self-propelled robots
that floated around the space

00:00:46.080 --> 00:00:48.300
station, and Project
Tango was integrated

00:00:48.300 --> 00:00:51.180
to give live motion
tracking feedback.

00:00:51.180 --> 00:00:53.810
In this episode, we are
going to share with you

00:00:53.810 --> 00:00:55.510
how motion tracking
works and how

00:00:55.510 --> 00:00:58.200
you can get started with it.

00:00:58.200 --> 00:01:01.487
Imagine you had a virtual solar
system in your living room.

00:01:01.487 --> 00:01:03.070
With motion tracking,
you could simply

00:01:03.070 --> 00:01:05.209
walk from planet
to planet to have

00:01:05.209 --> 00:01:07.320
a closer look at each of them.

00:01:07.320 --> 00:01:10.540
Or you can use the device
to control a spaceship as it

00:01:10.540 --> 00:01:14.680
descends and flies around on the
surface of one of the planets.

00:01:14.680 --> 00:01:17.450
Whether you're building a
space game or something else,

00:01:17.450 --> 00:01:20.650
you can use motion tracking
to take the user on a journey

00:01:20.650 --> 00:01:22.810
through a virtual world.

00:01:22.810 --> 00:01:25.640
So how does motion
tracking work?

00:01:25.640 --> 00:01:28.300
Project Tango collects
data from a fisheye camera

00:01:28.300 --> 00:01:32.040
and an inertial
measurement unit, or IMU.

00:01:32.040 --> 00:01:33.630
The image from
the camera is used

00:01:33.630 --> 00:01:36.960
to identify visual features,
such as edges and corners,

00:01:36.960 --> 00:01:39.930
and track how much they move
between frames to determine

00:01:39.930 --> 00:01:41.260
distance traveled.

00:01:41.260 --> 00:01:43.390
This is called feature tracking.

00:01:43.390 --> 00:01:46.540
The IMU uses an
accelerometer and a gyroscope

00:01:46.540 --> 00:01:48.485
to track how fast a
device accelerates

00:01:48.485 --> 00:01:51.210
and in which direction
it's turning.

00:01:51.210 --> 00:01:54.970
Lastly, the images are fused
with the [INAUDIBLE] IMU

00:01:54.970 --> 00:01:58.720
sensor data to calculate how
much the device has moved.

00:01:58.720 --> 00:02:00.410
Did I mention that
this all happens

00:02:00.410 --> 00:02:05.190
on the device, in real time,
and up to 100 times per second?

00:02:05.190 --> 00:02:08.800
And since 60 images per second
is why motion tracking looks

00:02:08.800 --> 00:02:13.370
smooth to the human eye, users
get a seamless sense of motion.

00:02:13.370 --> 00:02:17.310
Now, one challenge is that the
human eye has a very wide field

00:02:17.310 --> 00:02:20.320
of view, almost
180 degrees, which

00:02:20.320 --> 00:02:24.520
greatly improves our ability to
see and run away from tigers.

00:02:24.520 --> 00:02:27.160
So in order to increase
motion tracking accuracy

00:02:27.160 --> 00:02:31.580
in mobile devices, Project Tango
uses wide angle fisheye lenses

00:02:31.580 --> 00:02:37.610
at up to 160 degrees to capture
details of the environment.

00:02:37.610 --> 00:02:39.740
Think about the
corner of a doorway.

00:02:39.740 --> 00:02:43.750
It has high contrast and can
be easily identified over time.

00:02:43.750 --> 00:02:45.610
For motion tracking
to work well,

00:02:45.610 --> 00:02:47.640
we need to identify
many of these features

00:02:47.640 --> 00:02:49.490
in the environment.

00:02:49.490 --> 00:02:51.800
And the wider the
camera angle, the better

00:02:51.800 --> 00:02:54.310
our chances to find
more such features,

00:02:54.310 --> 00:02:56.820
which in turn increases the
reliability and accuracy

00:02:56.820 --> 00:02:58.730
of motion tracking.

00:02:58.730 --> 00:03:00.840
In order to use
motion tracking, you

00:03:00.840 --> 00:03:03.410
need to understand Project
Tango's coordinate systems

00:03:03.410 --> 00:03:06.500
and the concept of
frame of reference.

00:03:06.500 --> 00:03:08.380
Project Tango tracks
the relative position

00:03:08.380 --> 00:03:10.160
of the device in
three dimensions

00:03:10.160 --> 00:03:11.920
from a starting point.

00:03:11.920 --> 00:03:15.430
This point is called the origin,
and it's always zero-zero-zero.

00:03:18.110 --> 00:03:19.740
The orientation of
the device is also

00:03:19.740 --> 00:03:22.250
tracked around the
same three axes.

00:03:22.250 --> 00:03:25.610
Since we can move and
rotate on each axis,

00:03:25.610 --> 00:03:29.220
we end up with six degrees
of freedom in total.

00:03:29.220 --> 00:03:31.370
Together, we refer
to the combination

00:03:31.370 --> 00:03:35.610
of precision and orientation
as the device post.

00:03:35.610 --> 00:03:39.040
The other important concept
is frame of reference.

00:03:39.040 --> 00:03:40.910
In motion tracking,
everything happens

00:03:40.910 --> 00:03:42.710
relative to where you start.

00:03:42.710 --> 00:03:44.040
This is the origin.

00:03:44.040 --> 00:03:47.120
The origin always coincides with
where you connect to and start

00:03:47.120 --> 00:03:49.050
your Project Tango service.

00:03:49.050 --> 00:03:50.570
We refer to the
frame of reference

00:03:50.570 --> 00:03:53.970
as the start of service frame.

00:03:53.970 --> 00:03:55.620
The start of service
frame in turn

00:03:55.620 --> 00:03:58.340
relates to the
frame of the device.

00:03:58.340 --> 00:04:00.020
When you combine
the two frames, you

00:04:00.020 --> 00:04:03.942
get the position and orientation
of the device in space.

00:04:03.942 --> 00:04:06.150
Project Tango supports many
more frames of reference,

00:04:06.150 --> 00:04:09.500
but for motion tracking,
this is all you need.

00:04:09.500 --> 00:04:11.340
Let's have a look at
Project Tango Explorer

00:04:11.340 --> 00:04:14.630
to see how motion tracking
works in practice.

00:04:14.630 --> 00:04:18.130
We are going to use Explorer in
its default mode, which shows

00:04:18.130 --> 00:04:20.079
the raw motion tracking data.

00:04:20.079 --> 00:04:23.680
The pyramid, also known
as the device frustum,

00:04:23.680 --> 00:04:25.770
displays the orientation
of the device,

00:04:25.770 --> 00:04:28.080
and the app shows the
position as a blue trace

00:04:28.080 --> 00:04:31.090
when you move around.

00:04:31.090 --> 00:04:33.350
If we walk in a
circle, the device

00:04:33.350 --> 00:04:35.150
will show a circle
on the screen.

00:04:35.150 --> 00:04:37.290
If we draw a circle with
the device in front of us,

00:04:37.290 --> 00:04:41.640
you will see it works
in all three dimensions.

00:04:41.640 --> 00:04:44.160
It is fundamental for
us to be able to move,

00:04:44.160 --> 00:04:45.990
yet currently
available devices only

00:04:45.990 --> 00:04:49.230
track orientation and
position at a coarse level.

00:04:49.230 --> 00:04:51.280
Motion tracking in
Project Tango is

00:04:51.280 --> 00:04:54.520
all about giving mobile devices
an understanding of movement

00:04:54.520 --> 00:04:57.100
that fully tracks
the way we move.

00:04:57.100 --> 00:04:59.830
Altogether, it lets the
device become a window

00:04:59.830 --> 00:05:03.150
into a virtual space,
enables augmented reality,

00:05:03.150 --> 00:05:07.500
and makes it possible to use the
device as a motion controller.

00:05:07.500 --> 00:05:10.470
While we continue to improve
the robustness of the system,

00:05:10.470 --> 00:05:12.670
APIs are available
so you can take

00:05:12.670 --> 00:05:16.980
advantage of motion tracking and
build truly mobile experiences.

00:05:16.980 --> 00:05:20.400
Visit our Google+ community
and join us on our journey.

00:05:20.400 --> 00:05:24.460
We are excited to see what you
will build with Project Tango.

