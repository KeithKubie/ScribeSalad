WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:01.482
MALE SPEAKER: Right.

00:00:01.482 --> 00:00:02.470
JON RONSON: Hello.

00:00:02.470 --> 00:00:03.761
MALE SPEAKER: Hello, everybody.

00:00:03.761 --> 00:00:06.916
It's my massive pleasure
to introduce Jon Ronson.

00:00:06.916 --> 00:00:08.398
We're incredibly
lucky to have him.

00:00:08.398 --> 00:00:10.735
He is in the middle of
doing five sold out nights

00:00:10.735 --> 00:00:13.990
at Leicester Square Theatre,
which, he just told me before,

00:00:13.990 --> 00:00:16.586
is taking its toll a little bit.

00:00:16.586 --> 00:00:19.859
JON RONSON: It's playing
havoc on my mental health.

00:00:19.859 --> 00:00:21.234
MALE SPEAKER: But
he also is very

00:00:21.234 --> 00:00:23.816
keen to stress that whilst
this is the current book,

00:00:23.816 --> 00:00:25.524
he's happy to take
questions on anything,

00:00:25.524 --> 00:00:29.180
and may even actually
appreciate some questions not

00:00:29.180 --> 00:00:32.906
on the current book, which
slightly throws my prep, but--

00:00:32.906 --> 00:00:33.656
JON RONSON: Oh no.

00:00:33.656 --> 00:00:35.648
That's fine too.

00:00:35.648 --> 00:00:38.636
Can I just say this is the most
beautifully designed place,

00:00:38.636 --> 00:00:41.292
but I've already
discovered a flaw, Which

00:00:41.292 --> 00:00:45.108
is that too much hand
sanitizer comes out.

00:00:45.108 --> 00:00:45.608
Yeah.

00:00:45.608 --> 00:00:49.269
There was a little mini-pond
of hand sanitizer in my hand.

00:00:49.269 --> 00:00:50.060
MALE SPEAKER: Yeah.

00:00:50.060 --> 00:00:50.559
That's--

00:00:50.559 --> 00:00:52.877
JON RONSON: Yeah.

00:00:52.877 --> 00:00:53.710
MALE SPEAKER: Right.

00:00:53.710 --> 00:00:54.460
Let's get started.

00:00:54.460 --> 00:00:56.310
We will wrap up
at one, because we

00:00:56.310 --> 00:00:58.564
know some people have
meetings to go to,

00:00:58.564 --> 00:01:01.690
so we have just the
best part of an hour.

00:01:01.690 --> 00:01:04.710
So I'd still like to start with
a couple questions on the book.

00:01:04.710 --> 00:01:07.084
JON RONSON: Sure.

00:01:07.084 --> 00:01:08.750
Well, Google gets a
mention in the book.

00:01:08.750 --> 00:01:10.458
MALE SPEAKER: It's
the most relevant book

00:01:10.458 --> 00:01:15.210
that you've done in terms of
the internet and social media.

00:01:15.210 --> 00:01:16.639
So let's start at the beginning.

00:01:16.639 --> 00:01:18.430
For those of you who
haven't read the book,

00:01:18.430 --> 00:01:21.038
the book starts with
this thing which

00:01:21.038 --> 00:01:23.090
Jon would call a
spambot-- three academics

00:01:23.090 --> 00:01:26.980
would call an infomorph-- which
impersonates Jon on Twitter.

00:01:26.980 --> 00:01:30.520
It moves very quickly
from a strange interest

00:01:30.520 --> 00:01:36.416
in fusion cooking to dreaming
about #time and #cock, which

00:01:36.416 --> 00:01:40.070
not unreasonably upsets the man.

00:01:40.070 --> 00:01:42.740
He interviews them, puts
the interview on YouTube,

00:01:42.740 --> 00:01:46.860
and then the comments
erupt under the video.

00:01:46.860 --> 00:01:49.246
And in the book,
you say you won.

00:01:49.246 --> 00:01:51.160
Why do you start with a victory?

00:01:51.160 --> 00:01:55.384
JON RONSON: Well,
because I hope that I'm

00:01:55.384 --> 00:01:58.536
using this word in the
right way-- Pyrrhic victory.

00:01:58.536 --> 00:01:59.922
It felt-- is that the right?

00:01:59.922 --> 00:02:00.880
MALE SPEAKER: Could be.

00:02:00.880 --> 00:02:02.154
JON RONSON: OK.

00:02:02.154 --> 00:02:03.495
MALE SPEAKER: You need to
say a bit more before I

00:02:03.495 --> 00:02:05.510
can qualify whether it's
a Pyrrhic victory or just

00:02:05.510 --> 00:02:06.009
a victory.

00:02:06.009 --> 00:02:07.500
JON RONSON: Because
it felt great.

00:02:07.500 --> 00:02:09.710
Suddenly, I say in the
book, I felt a lot braver.

00:02:09.710 --> 00:02:13.165
Basically, these three academics
created this Jon Ronson spam

00:02:13.165 --> 00:02:16.040
bot, which was being
followed by people

00:02:16.040 --> 00:02:17.210
who I knew from real life.

00:02:17.210 --> 00:02:20.150
And as you point out,
it was tweeting things

00:02:20.150 --> 00:02:22.609
like, I am dreaming something
about time and cock.

00:02:22.609 --> 00:02:24.525
So all these people that
I knew from real life

00:02:24.525 --> 00:02:28.300
were obviously wondering why I
had suddenly become so candid

00:02:28.300 --> 00:02:32.030
about dreaming about cock.

00:02:32.030 --> 00:02:35.970
And so I had a
confrontation with them.

00:02:35.970 --> 00:02:40.320
And they said at the time
that just brushed past me,

00:02:40.320 --> 00:02:43.220
but now I think was the most
important thing that they said.

00:02:43.220 --> 00:02:47.470
They said the internet
is not the real world.

00:02:47.470 --> 00:02:50.310
And this was in 2012, I think.

00:02:50.310 --> 00:02:54.790
And I think that was the
general view way back

00:02:54.790 --> 00:02:57.730
in 2012, that the internet
is not the real world.

00:02:57.730 --> 00:03:00.230
Could you hear everything that
I said just then, by the way?

00:03:00.230 --> 00:03:01.066
OK, good.

00:03:04.470 --> 00:03:07.070
And also, they were
basically look,

00:03:07.070 --> 00:03:10.780
my identity is not important.

00:03:10.780 --> 00:03:14.680
In this utopian
new age, identities

00:03:14.680 --> 00:03:16.670
kind of belong to everybody.

00:03:16.670 --> 00:03:18.410
And that really upset me.

00:03:18.410 --> 00:03:20.760
And it upset me way more
than it ought to have done,

00:03:20.760 --> 00:03:23.710
because it was just a
stupid Twitter spam bot.

00:03:23.710 --> 00:03:29.510
But it got to a profound thing--
our identity really matters.

00:03:29.510 --> 00:03:31.010
You spend your life
working out what

00:03:31.010 --> 00:03:32.810
movies you like,
what you care about,

00:03:32.810 --> 00:03:34.350
what you don't care about.

00:03:34.350 --> 00:03:38.000
And suddenly, all that
was hoisted away from me.

00:03:38.000 --> 00:03:41.420
And for me, it was like a tiny,
little, ridiculous spambot

00:03:41.420 --> 00:03:42.080
thing.

00:03:42.080 --> 00:03:45.980
But to leap forward for just a
second, the people whose lives

00:03:45.980 --> 00:03:50.490
are destroyed on social media,
that seizing of an identity

00:03:50.490 --> 00:03:53.359
is profoundly traumatizing.

00:03:53.359 --> 00:03:54.984
MALE SPEAKER: Yes,
and maybe let's move

00:03:54.984 --> 00:03:55.950
to that, because
that's obviously

00:03:55.950 --> 00:03:57.210
the central tenet of the book.

00:03:57.210 --> 00:04:02.220
It's around those people whose
lives are turned upside down.

00:04:02.220 --> 00:04:05.020
The next story
about a shaming is

00:04:05.020 --> 00:04:07.850
about a journalist,
a writer who is

00:04:07.850 --> 00:04:12.432
found to have made up some
quotes about Dylan and others.

00:04:12.432 --> 00:04:14.940
And when this story
breaks, his life

00:04:14.940 --> 00:04:18.829
pretty much collapses, at
least for a good while.

00:04:18.829 --> 00:04:21.020
But there's an interesting
section in there,

00:04:21.020 --> 00:04:23.520
where you're talking with the
other investigative journalist

00:04:23.520 --> 00:04:26.070
who'd found out the
mistakes that he'd made.

00:04:26.070 --> 00:04:29.880
And he's discussing the
actual pressing of send

00:04:29.880 --> 00:04:33.160
on the article, knowing what
it's going to do to this guy.

00:04:33.160 --> 00:04:36.480
And he describes the
process as fucking horrible.

00:04:36.480 --> 00:04:37.922
Have you ever had
similar dilemmas

00:04:37.922 --> 00:04:40.635
on anything you've written
about the impact of what

00:04:40.635 --> 00:04:41.260
you're writing?

00:04:41.260 --> 00:04:42.040
JON RONSON: Well, it's funny.

00:04:42.040 --> 00:04:43.676
I remember he said
to me, this guy

00:04:43.676 --> 00:04:45.860
Michael Moynihan, who
discovered this journalist had

00:04:45.860 --> 00:04:46.860
been fabricating quotes.

00:04:46.860 --> 00:04:50.510
This was a big successful,
Malcolm Gladwell-type writer,

00:04:50.510 --> 00:04:54.570
called Jonah Lehrer, And he
knew that if he pressed send,

00:04:54.570 --> 00:04:56.420
he would ruin this man's life.

00:04:59.780 --> 00:05:01.762
It was transgressions,
real transgressions.

00:05:01.762 --> 00:05:03.470
MALE SPEAKER: Proper
journalistic errors.

00:05:03.470 --> 00:05:06.122
JON RONSON: Yeah, but
he hadn't killed anyone.

00:05:06.122 --> 00:05:07.472
MALE SPEAKER: No.

00:05:07.472 --> 00:05:08.930
JON RONSON: But if
he pressed send,

00:05:08.930 --> 00:05:10.304
he would ruin this
person's life.

00:05:10.304 --> 00:05:12.787
And in fact, Michael said
the same thing to me.

00:05:12.787 --> 00:05:14.620
He said, have you ever
been in this position

00:05:14.620 --> 00:05:18.330
that if you press send, you
would ruin somebody's life?

00:05:18.330 --> 00:05:19.640
And I thought, have I?

00:05:19.640 --> 00:05:23.580
And I said to him, I don't know.

00:05:23.580 --> 00:05:25.080
Because journalists
are constantly

00:05:25.080 --> 00:05:28.139
playing psychological
tricks on themselves to make

00:05:28.139 --> 00:05:32.766
ourselves feel not so bad
about bad things that we do.

00:05:32.766 --> 00:05:34.432
But I don't think I
have ever done that.

00:05:34.432 --> 00:05:35.920
I don't think I've ever
ruined anyone's life.

00:05:35.920 --> 00:05:37.753
I mean, some people
have been upset with me.

00:05:37.753 --> 00:05:39.550
MALE SPEAKER: Sure.

00:05:39.550 --> 00:05:43.750
JON RONSON: A number of people
have been upset with me.

00:05:43.750 --> 00:05:45.642
But a huge number of
people have been very

00:05:45.642 --> 00:05:46.850
happy with what I've written.

00:05:46.850 --> 00:05:51.530
And obviously, those are
the stories I like more.

00:05:51.530 --> 00:05:53.760
What I particularly
like, by the way,

00:05:53.760 --> 00:05:58.180
is when opposing factions
both like what I wrote.

00:05:58.180 --> 00:06:00.540
And that happened quite
recently with Katie Hopkins.

00:06:00.540 --> 00:06:03.540
She loved it, and the people
who hate her loved it.

00:06:03.540 --> 00:06:07.120
That's when I feel I've
really done a good job.

00:06:07.120 --> 00:06:09.330
Because I'm not
about being a mugger.

00:06:09.330 --> 00:06:15.940
I'm about being curious and
finding common ground and so

00:06:15.940 --> 00:06:17.710
on.

00:06:17.710 --> 00:06:19.397
Yes.

00:06:19.397 --> 00:06:21.480
MALE SPEAKER: Moving through
the book at some pace

00:06:21.480 --> 00:06:23.688
so we get time, we will take
questions from the floor

00:06:23.688 --> 00:06:24.276
fairly soon.

00:06:24.276 --> 00:06:25.317
We'll come out with mics.

00:06:25.317 --> 00:06:27.930
So do wait for the
mics when we do that.

00:06:27.930 --> 00:06:30.310
The shamings take
another turn when

00:06:30.310 --> 00:06:32.530
you tell the story
of two tech guys

00:06:32.530 --> 00:06:35.650
at a developer conference
who get called out

00:06:35.650 --> 00:06:37.800
for making some jokes
between themselves

00:06:37.800 --> 00:06:40.960
by a female attendee
at that conference.

00:06:40.960 --> 00:06:44.420
And then the whole thing
turns, that actually she

00:06:44.420 --> 00:06:48.950
gets taken down much more
nastily, much more viciously

00:06:48.950 --> 00:06:51.150
than the two guys
in the first place.

00:06:51.150 --> 00:06:52.470
Why do you think happens?

00:06:52.470 --> 00:06:56.600
And why do you think it is that
the level of hatred directed

00:06:56.600 --> 00:06:59.020
at women is much nastier
than it is at men?

00:06:59.020 --> 00:07:01.000
JON RONSON: Yeah, I
mean there is no doubt

00:07:01.000 --> 00:07:05.795
that the range of insults is way
worse when it's a woman being

00:07:05.795 --> 00:07:08.024
shamed than it's a man.

00:07:08.024 --> 00:07:10.190
I mean, you get the odd--
I was thinking those three

00:07:10.190 --> 00:07:14.010
academics who I put on YouTube,
the comments underneath did

00:07:14.010 --> 00:07:20.290
include-- So men do
sometimes get that,

00:07:20.290 --> 00:07:22.820
but in general, I
would say women have it

00:07:22.820 --> 00:07:24.180
way worse than men.

00:07:24.180 --> 00:07:26.020
When a man is
getting shamed, it's

00:07:26.020 --> 00:07:27.160
I'm going to get you fired.

00:07:27.160 --> 00:07:28.626
When a woman's
getting shamed, it's

00:07:28.626 --> 00:07:29.800
rape threats and death threats.

00:07:29.800 --> 00:07:32.140
Actually, on stage last night,
I asked Bridget Christie

00:07:32.140 --> 00:07:33.875
that question.

00:07:33.875 --> 00:07:36.440
And she said-- you were
in the crowd, Nick.

00:07:36.440 --> 00:07:38.520
Can you remember what
he response was to that?

00:07:38.520 --> 00:07:39.623
MALE SPEAKER: You were too
busy taking notes, I think,

00:07:39.623 --> 00:07:40.622
weren't you?

00:07:40.622 --> 00:07:42.038
JON RONSON: Well,
it was basically

00:07:42.038 --> 00:07:43.410
that women are held responsible.

00:07:43.410 --> 00:07:47.720
Women have to be really good
at a million different things.

00:07:47.720 --> 00:07:51.200
And so I think this was
Bridget's explanation.

00:07:51.200 --> 00:07:53.840
So there's lots of different
ways you can attack women.

00:07:53.840 --> 00:07:56.980
Women have to be good at sex,
so you can attack them sexually.

00:07:56.980 --> 00:07:58.600
Women have to be
good at homemaking,

00:07:58.600 --> 00:08:01.400
so you can attack
them as a homemaker.

00:08:01.400 --> 00:08:04.400
So that was Bridget's
explanation.

00:08:04.400 --> 00:08:13.220
What I realized is that
whilst social justice is

00:08:13.220 --> 00:08:18.732
doing very well, there's also
a huge naissance of misogyny.

00:08:18.732 --> 00:08:21.190
And I suppose it's possible--
I'm thinking on my feet here,

00:08:21.190 --> 00:08:23.780
but I suppose it's possible that
the two things are connected,

00:08:23.780 --> 00:08:26.980
that people who are
against social justice

00:08:26.980 --> 00:08:31.410
are taking a ferocious
response-- men's rights

00:08:31.410 --> 00:08:35.360
activists battling feminists.

00:08:35.360 --> 00:08:37.759
Things have become
very polemical.

00:08:37.759 --> 00:08:41.059
So maybe those two
things are connected.

00:08:41.059 --> 00:08:42.600
MALE SPEAKER: This
comes up of couple

00:08:42.600 --> 00:08:47.070
times in the book, that people
say that they are now finding

00:08:47.070 --> 00:08:50.970
themselves being much quieter,
either on social media or even

00:08:50.970 --> 00:08:53.390
physically, saying that
they're not risking jokes,

00:08:53.390 --> 00:08:56.065
and they're tending
towards bland.

00:08:56.065 --> 00:09:01.250
And obviously, when you tell
the story of optimizing-- god,

00:09:01.250 --> 00:09:05.550
I've gone blank--
Lindsey, Lindsey Stone,

00:09:05.550 --> 00:09:08.610
down the Google rankings,
it's just a see of blandness,

00:09:08.610 --> 00:09:10.850
of liking cats and other stuff.

00:09:10.850 --> 00:09:12.950
Do you see that as a risk?

00:09:12.950 --> 00:09:14.820
And do you see that
that's happening?

00:09:14.820 --> 00:09:16.236
JON RONSON: I do
see it as a risk,

00:09:16.236 --> 00:09:18.090
but my argument
is a nuanced one.

00:09:18.090 --> 00:09:20.590
And the one thing that really
bugged me this last year

00:09:20.590 --> 00:09:25.050
was that a small group of people
decided to be ferociously,

00:09:25.050 --> 00:09:27.860
actively against the
book, because they saw it

00:09:27.860 --> 00:09:30.530
as an attack on social
justice, which it's not.

00:09:30.530 --> 00:09:32.224
And in fact, these
were people who

00:09:32.224 --> 00:09:33.640
hadn't read the
book, because it's

00:09:33.640 --> 00:09:35.473
impossible to criticize
the book in that way

00:09:35.473 --> 00:09:36.820
if you've actually read it.

00:09:36.820 --> 00:09:40.040
What this book is about
in terms of social justice

00:09:40.040 --> 00:09:45.490
is that it's a book against
what one person described

00:09:45.490 --> 00:09:48.200
as a cathartic alternative
to social justice.

00:09:48.200 --> 00:09:50.780
The destruction of
people like Justine Sacco

00:09:50.780 --> 00:09:53.466
is not social justice.

00:09:53.466 --> 00:09:57.560
It's this easy, nasty
imitation of social justice.

00:09:57.560 --> 00:10:00.180
So for me, it's very easy
to make that distinction,

00:10:00.180 --> 00:10:01.920
but what's happening
as a result of this

00:10:01.920 --> 00:10:08.292
is some people because the
attacks are no longer just

00:10:08.292 --> 00:10:10.750
on people who deserve it, but
also people who don't deserve

00:10:10.750 --> 00:10:13.580
it-- although, of
course, deserve,

00:10:13.580 --> 00:10:15.270
I'm just saying that
because it's easy.

00:10:15.270 --> 00:10:16.853
MALE SPEAKER: Yes,
there are certainly

00:10:16.853 --> 00:10:18.960
shades of gray about
who deserves, I think.

00:10:18.960 --> 00:10:21.960
JON RONSON: Yeah, a racist
cop who shoots somebody

00:10:21.960 --> 00:10:22.752
deserves it.

00:10:22.752 --> 00:10:24.710
A woman who makes a
liberal joke that comes out

00:10:24.710 --> 00:10:26.466
badly doesn't deserve it.

00:10:26.466 --> 00:10:29.500
They're being treated with
a similar level of ferocity

00:10:29.500 --> 00:10:32.320
literally.

00:10:32.320 --> 00:10:34.143
Both lives are being upended.

00:10:34.143 --> 00:10:36.510
Actually, the racist cops
tends to recover a lot quicker

00:10:36.510 --> 00:10:38.440
than the PR woman
with 170 Twitter

00:10:38.440 --> 00:10:42.620
followers who makes a liberal
joke that comes out badly.

00:10:42.620 --> 00:10:45.010
So yeah, as a result
of that, as a result

00:10:45.010 --> 00:10:49.610
of the people with the power,
i.e. us, abusing our power

00:10:49.610 --> 00:10:53.050
and going after everybody
because we just love to shame,

00:10:53.050 --> 00:10:55.882
and destroying people
who don't deserve it,

00:10:55.882 --> 00:10:57.361
everybody's nervous.

00:10:57.361 --> 00:10:59.629
It's a fearful time for people.

00:10:59.629 --> 00:11:02.170
So even when somebody's being
shamed and people are thinking,

00:11:02.170 --> 00:11:04.750
oh, I don't think that
person deserves it,

00:11:04.750 --> 00:11:05.640
nobody says anything.

00:11:05.640 --> 00:11:07.960
It's like the bully has
taken over the school.

00:11:07.960 --> 00:11:10.820
And as we saw, people
are killing themselves.

00:11:10.820 --> 00:11:15.212
And so I hooked Lindsey
Stone, who was a shamed woman,

00:11:15.212 --> 00:11:16.940
I hooked her up
with reputation.com,

00:11:16.940 --> 00:11:22.770
who are Google's enemy, Google's
nemesis, reputation.com,

00:11:22.770 --> 00:11:25.156
because they say, well,
Google's not got the right.

00:11:25.156 --> 00:11:29.100
Who gave Google the right to
basically do everything, do

00:11:29.100 --> 00:11:29.910
all of this?

00:11:29.910 --> 00:11:32.990
So reputation.com manipulates
the Google algorithms.

00:11:35.069 --> 00:11:36.610
I don't know how
successful they are.

00:11:36.610 --> 00:11:38.568
I think maybe sometimes
successfully, sometimes

00:11:38.568 --> 00:11:41.200
less so, because
it's a moving target.

00:11:41.200 --> 00:11:45.335
You're constantly changing your
algorithms, like Bond villains.

00:11:52.420 --> 00:11:56.720
And what I found really
sad was that Lindsey

00:11:56.720 --> 00:12:02.380
was this kind of audacious,
nice, really nice person.

00:12:02.380 --> 00:12:05.890
She worked with adults
with learning difficulties.

00:12:05.890 --> 00:12:08.475
You couldn't have
a nicer person.

00:12:08.475 --> 00:12:10.550
And she did this
stupid joke, which

00:12:10.550 --> 00:12:14.430
meant nothing and was destroyed
all over the internet,

00:12:14.430 --> 00:12:15.380
and was crushed.

00:12:15.380 --> 00:12:19.450
I mean, her mental health
was damaged more profoundly

00:12:19.450 --> 00:12:23.040
than anybody I met, because
she was a private individual,

00:12:23.040 --> 00:12:26.900
and believed, read tweet,
every Facebook comment,

00:12:26.900 --> 00:12:28.420
believed every single word.

00:12:28.420 --> 00:12:32.010
I mean, Jesus, I am a public
figure with pretty thick skin,

00:12:32.010 --> 00:12:35.380
and it still profoundly upsets
me when something like that

00:12:35.380 --> 00:12:36.317
happens to me.

00:12:36.317 --> 00:12:38.650
So for Lindsey, I mean, she
didn't leave home for a year

00:12:38.650 --> 00:12:44.570
and a half, suicidal thoughts,
anxiety, depression, insomnia.

00:12:44.570 --> 00:12:48.750
So I hooked her up
with reputation.com.

00:12:48.750 --> 00:12:50.490
And the way they
did it, as you said,

00:12:50.490 --> 00:12:55.050
was to swamp Google
with stuff that

00:12:55.050 --> 00:12:57.690
would supplant this silly
audacious joke, which

00:12:57.690 --> 00:12:58.750
meant nothing.

00:12:58.750 --> 00:13:02.290
And it was blogs about how
much Lindsey Stone loves cats

00:13:02.290 --> 00:13:05.190
and how much she's looking
forward to the new Lady Gaga

00:13:05.190 --> 00:13:09.504
video, and what her favorite
types of ice cream were.

00:13:09.504 --> 00:13:11.795
MALE SPEAKER: Yeah, just a
stream of innocuous content,

00:13:11.795 --> 00:13:12.120
basically.

00:13:12.120 --> 00:13:14.286
JON RONSON: Yeah, and it
just made me think, my god.

00:13:14.286 --> 00:13:16.950
Is this the society we've
created for ourselves, where

00:13:16.950 --> 00:13:19.210
the way to survive
is to be bland?

00:13:19.210 --> 00:13:23.410
Which isn't to say-- I say
that from the perspective

00:13:23.410 --> 00:13:26.220
of a politically correct person.

00:13:26.220 --> 00:13:27.890
None of this is me
saying let's return

00:13:27.890 --> 00:13:29.723
to a world where everybody
can be offensive.

00:13:29.723 --> 00:13:31.340
Because I don't feel that.

00:13:31.340 --> 00:13:32.491
It's a nuanced point.

00:13:32.491 --> 00:13:34.740
MALE SPEAKER: Do you think
comedians have more leeway?

00:13:34.740 --> 00:13:36.660
I've not really
picked up an example

00:13:36.660 --> 00:13:39.820
of a comedian getting slated.

00:13:39.820 --> 00:13:43.738
Frankie Boyle, maybe, actually,
now that I think about it.

00:13:43.738 --> 00:13:45.220
But Justine Sacco says it.

00:13:45.220 --> 00:13:47.255
She says, I'm not a
character in "South Park."

00:13:47.255 --> 00:13:48.992
I'm not a comedian.

00:13:48.992 --> 00:13:52.430
So she had no business
trying to attempt to a joke.

00:13:52.430 --> 00:13:55.350
Do comedians have a bit more
forgiveness, do you think?

00:13:55.350 --> 00:13:56.930
Their stock and trade is to
try and be funny and push

00:13:56.930 --> 00:13:57.920
some boundaries.

00:13:57.920 --> 00:13:59.503
JON RONSON: They
have more forgiveness

00:13:59.503 --> 00:14:02.300
because there's more
built-in context.

00:14:02.300 --> 00:14:04.826
But I don't blame Justine.

00:14:04.826 --> 00:14:07.879
I don't blame Justine for
anything that happened at all.

00:14:07.879 --> 00:14:09.420
The tweet, for people
who don't know,

00:14:09.420 --> 00:14:12.568
that got Justine destroyed
was, "going to Africa.

00:14:12.568 --> 00:14:13.810
Hope I don't get AIDS.

00:14:13.810 --> 00:14:14.440
Just kidding.

00:14:14.440 --> 00:14:15.240
I'm white."

00:14:15.240 --> 00:14:17.406
And then she got on the
plane, turned off her phone,

00:14:17.406 --> 00:14:20.650
and while she was asleep,
she was destroyed.

00:14:20.650 --> 00:14:24.250
Now obviously, it's a
terrible combination of words.

00:14:24.250 --> 00:14:27.400
But the joke was intended, like
"South Park," or Randy Newman,

00:14:27.400 --> 00:14:31.546
it was intended to mock her
own privilege, her own bubble

00:14:31.546 --> 00:14:32.722
of privilege.

00:14:32.722 --> 00:14:35.180
The way she described the joke
to me was, living in America

00:14:35.180 --> 00:14:37.209
puts us in a bubble
when it comes to what

00:14:37.209 --> 00:14:38.500
is going on in the third world.

00:14:38.500 --> 00:14:40.290
I was making fun of the bubble.

00:14:40.290 --> 00:14:43.120
So she was ridiculing herself.

00:14:43.120 --> 00:14:46.410
Now, it was her own fault
for not making that clear.

00:14:46.410 --> 00:14:48.784
But she only 170
Twitter followers.

00:14:48.784 --> 00:14:50.450
Nobody ever replied
to any of her jokes.

00:14:50.450 --> 00:14:52.854
She was a comedian
in an empty room.

00:14:52.854 --> 00:14:54.520
And yet while she was
asleep on a plane,

00:14:54.520 --> 00:14:57.460
she became the world wide,
number one trending topic

00:14:57.460 --> 00:14:58.210
on Twitter.

00:14:58.210 --> 00:15:02.545
She was googled one
million 220,000 times

00:15:02.545 --> 00:15:04.760
that night, whereas
the month before, he

00:15:04.760 --> 00:15:07.340
had been googled 40 times.

00:15:07.340 --> 00:15:09.752
MALE SPEAKER: She worked
in PR, which didn't help.

00:15:09.752 --> 00:15:11.210
JON RONSON: Definitely
didn't help.

00:15:11.210 --> 00:15:12.918
And I'll tell you what
else didn't help--

00:15:12.918 --> 00:15:14.450
the fact that she was blonde.

00:15:14.450 --> 00:15:15.825
In her Twitter
avatar, she looked

00:15:15.825 --> 00:15:18.770
like someone who had fun
and parties in New York.

00:15:18.770 --> 00:15:22.300
So misogynists hated that.

00:15:22.300 --> 00:15:24.510
She really united a lot
of disparate groups.

00:15:31.020 --> 00:15:33.680
So this is the thing that I
found most awful about this,

00:15:33.680 --> 00:15:36.020
and I thought the
world lost its mind.

00:15:36.020 --> 00:15:39.430
Which is that she was asleep
on a plane, unable to explain

00:15:39.430 --> 00:15:44.380
her joke, and not only did
that not matter to people,

00:15:44.380 --> 00:15:47.530
people loved that
about the situation.

00:15:47.530 --> 00:15:50.380
One person tweeted, we are about
to watch this Justine Sacco

00:15:50.380 --> 00:15:52.825
bitch get fired in real
time before she even knows.

00:15:52.825 --> 00:15:55.200
MALE SPEAKER: They were tracking
the plane, weren't they?

00:15:55.200 --> 00:15:57.520
JON RONSON: Yeah,
flight tracker website,

00:15:57.520 --> 00:16:00.375
#worldwide,
#hasjustinelandedyet?

00:16:00.375 --> 00:16:01.750
MALE SPEAKER:
Yeah, that's right.

00:16:01.750 --> 00:16:04.990
JON RONSON: People
were tweeting,

00:16:04.990 --> 00:16:08.190
"#hasjustinelandedyet may be
the best thing to ever happen

00:16:08.190 --> 00:16:10.670
to my Friday night" and so on.

00:16:10.670 --> 00:16:12.837
I mean, we're talking
100,000 tweets that night

00:16:12.837 --> 00:16:14.170
while she was asleep on a plane.

00:16:14.170 --> 00:16:17.205
So the fact was the
decontextualization

00:16:17.205 --> 00:16:20.340
of the tweet was
brilliant for people.

00:16:20.340 --> 00:16:21.490
People loved it.

00:16:21.490 --> 00:16:25.420
And in fact, if anybody said,
as indeed Helen Lewis, the "New

00:16:25.420 --> 00:16:29.180
Statesmen" writer said
that night on Twitter,

00:16:29.180 --> 00:16:32.160
I'm not sure that that joke
was intended to be racist.

00:16:32.160 --> 00:16:35.140
I'm not sure that this woman
deserves what she's getting,

00:16:35.140 --> 00:16:39.085
the response was, well, you're
just a privileged bitch too.

00:16:39.085 --> 00:16:44.370
Calling for waiting for evidence
was seen as pathetic weakness

00:16:44.370 --> 00:16:45.330
by us.

00:16:47.773 --> 00:16:50.106
MALE SPEAKER: Any questions
from the floor of the stage?

00:16:50.106 --> 00:16:51.647
I've got a ream of
questions, and I'm

00:16:51.647 --> 00:16:55.030
very happy to keep going, but
I don't want to monopolize it.

00:16:55.030 --> 00:16:56.014
One here, Adam.

00:16:56.014 --> 00:16:57.766
Can you just wait
for mic, please?

00:16:57.766 --> 00:16:59.515
We'll now have this
slightly awkward pause

00:16:59.515 --> 00:17:00.980
for the microphone.

00:17:00.980 --> 00:17:01.990
I'll try and fill.

00:17:01.990 --> 00:17:02.820
AUDIENCE: So when
you were talking,

00:17:02.820 --> 00:17:04.320
all I could think
about was remember

00:17:04.320 --> 00:17:05.420
that landlord in Bristol?

00:17:05.420 --> 00:17:06.969
A girl got murdered.

00:17:06.969 --> 00:17:09.905
And then he was just on the
front of all the papers.

00:17:09.905 --> 00:17:11.030
It was like, he's a weirdo.

00:17:11.030 --> 00:17:12.069
He did it.

00:17:12.069 --> 00:17:14.960
And actually he had nothing,
or he was just questioned.

00:17:14.960 --> 00:17:18.350
Now he's had to have a
haircut, dye his hair,

00:17:18.350 --> 00:17:20.380
he can't go out,
because people saw it.

00:17:20.380 --> 00:17:22.880
Even though they've convicted
a guy who's admitted doing it,

00:17:22.880 --> 00:17:25.660
and there's loads of evidence
that proves that he did do it,

00:17:25.660 --> 00:17:28.200
he cannot get this image--
he just cannot shift it.

00:17:28.200 --> 00:17:29.170
JON RONSON: Because
he didn't do it.

00:17:29.170 --> 00:17:29.910
AUDIENCE: Because
he didn't do it,

00:17:29.910 --> 00:17:32.275
and he was on the front
page of every paper.

00:17:32.275 --> 00:17:35.030
So the paper's apology was
pretty poor, I thought,

00:17:35.030 --> 00:17:38.840
but there's got to be a way
that the internet can be used

00:17:38.840 --> 00:17:40.597
for good in reputation
in some ways,

00:17:40.597 --> 00:17:43.180
because I was trying to think
of ways that it's gone the other

00:17:43.180 --> 00:17:44.854
way, but it's actually
bad that I can't.

00:17:44.854 --> 00:17:45.770
JON RONSON: Oh no, no.

00:17:45.770 --> 00:17:46.030
There are.

00:17:46.030 --> 00:17:47.550
There's lots of good
things that are happening.

00:17:47.550 --> 00:17:49.400
I mean, at the
moment, personally,

00:17:49.400 --> 00:17:51.890
I think the whole
Oscars so White campaign

00:17:51.890 --> 00:17:53.220
is really positive.

00:17:53.220 --> 00:17:54.580
That's really good.

00:17:54.580 --> 00:17:55.700
It needed to be shaken up.

00:17:55.700 --> 00:17:59.180
And there's countless
stories happening

00:17:59.180 --> 00:18:02.770
where civil rights
movements are doing well

00:18:02.770 --> 00:18:04.172
because of social media.

00:18:04.172 --> 00:18:05.880
I mean, I can think
of a million of them.

00:18:05.880 --> 00:18:09.440
Black Lives Matter
is really positive.

00:18:12.230 --> 00:18:15.950
But as you say,
with that guy, that

00:18:15.950 --> 00:18:20.580
was the mainstream media
taking a sliver of this person

00:18:20.580 --> 00:18:23.890
and building it into a total
profile of this person,

00:18:23.890 --> 00:18:25.790
that he liked poetry.

00:18:25.790 --> 00:18:28.194
He taught poetry, and--

00:18:28.194 --> 00:18:29.610
AUDIENCE: They
just focused on him

00:18:29.610 --> 00:18:32.910
having long, gray hair
and he wore a trench coat.

00:18:32.910 --> 00:18:36.390
JON RONSON: He had purple hair,
and he taught them poetry,

00:18:36.390 --> 00:18:42.110
and so that obviously meant
he was a kind of sex murderer.

00:18:42.110 --> 00:18:46.810
And what's
interesting, actually,

00:18:46.810 --> 00:18:49.069
is that-- I can't
remember who said this,

00:18:49.069 --> 00:18:50.360
but I think it was Marina Hyde.

00:18:50.360 --> 00:18:56.082
I was being shamed
around July of last year,

00:18:56.082 --> 00:19:00.040
and Marina Hyde said to
me, the "Guardian" writer,

00:19:00.040 --> 00:19:04.100
it's funny, for Twitter
purports to hate tabloids,

00:19:04.100 --> 00:19:06.420
but we are constantly
acting like a tabloid.

00:19:06.420 --> 00:19:08.470
We are constantly taking
a tiny little sliver

00:19:08.470 --> 00:19:10.270
of a bit of information.

00:19:10.270 --> 00:19:13.919
And Twitter is the world's worst
information swapping services.

00:19:13.919 --> 00:19:15.460
It's constantly
getting things wrong.

00:19:15.460 --> 00:19:18.660
I mean, just yesterday,
the day before yesterday,

00:19:18.660 --> 00:19:22.155
Kristin Stewart was being
destroyed all over Twitter

00:19:22.155 --> 00:19:23.530
for something that
she didn't do,

00:19:23.530 --> 00:19:24.960
for something that wasn't true.

00:19:24.960 --> 00:19:27.543
Over and over again, people have
been destroyed for something,

00:19:27.543 --> 00:19:29.543
and the next day, it was
like, oh, oh, oh, yeah.

00:19:29.543 --> 00:19:30.490
That was wrong.

00:19:30.490 --> 00:19:33.614
But then nobody learns from it.

00:19:33.614 --> 00:19:34.822
We just do it all over again.

00:19:37.196 --> 00:19:39.320
MALE SPEAKER: There's some
tough stuff in the book.

00:19:39.320 --> 00:19:41.020
A number of people
commit suicide

00:19:41.020 --> 00:19:43.834
as a result of the shame--
Ashley Madison leak victims.

00:19:43.834 --> 00:19:45.250
"News of the World"
sting victims,

00:19:45.250 --> 00:19:45.935
coming back to the press.

00:19:45.935 --> 00:19:47.065
We might come back to that.

00:19:47.065 --> 00:19:49.037
But probably most
harrowing is there's

00:19:49.037 --> 00:19:52.182
a teenage girl who
was raped, and you

00:19:52.182 --> 00:19:55.220
detail her cross-examination by
the prosecution lawyer, where

00:19:55.220 --> 00:19:57.370
he gives her a
really tough time.

00:19:57.370 --> 00:19:59.090
And this is a shaming
and humiliation

00:19:59.090 --> 00:20:01.070
in a closed environment,
a court room.

00:20:01.070 --> 00:20:04.580
Did you try and talk to the
lawyer about how he felt?

00:20:04.580 --> 00:20:06.050
JON RONSON: Yeah,
I wrote to him,

00:20:06.050 --> 00:20:07.675
the guy who did the
cross-examination--

00:20:07.675 --> 00:20:09.480
MALE SPEAKER: John
Carruthers, to name him.

00:20:09.480 --> 00:20:10.460
JON RONSON: Wrote
to him three times.

00:20:10.460 --> 00:20:10.950
MALE SPEAKER: And he wouldn't.

00:20:10.950 --> 00:20:12.470
JON RONSON: No, he
wouldn't talk to me.

00:20:12.470 --> 00:20:13.220
And you know what?

00:20:13.220 --> 00:20:14.464
I felt bad about naming him.

00:20:14.464 --> 00:20:17.380
Somebody said to me
when the book came out,

00:20:17.380 --> 00:20:19.504
why did you name him?

00:20:19.504 --> 00:20:22.420
And my thought was,
well, it's public record.

00:20:22.420 --> 00:20:28.020
But if I'm writing a book
that's against shaming,

00:20:28.020 --> 00:20:30.187
I shouldn't really be
outing the shamists, right?

00:20:30.187 --> 00:20:31.270
MALE SPEAKER: Interesting.

00:20:31.270 --> 00:20:33.770
So again, when we come back to
that question I asked earlier

00:20:33.770 --> 00:20:35.510
about pressing
send, you did think

00:20:35.510 --> 00:20:37.050
about that one a little bit?

00:20:37.050 --> 00:20:38.050
JON RONSON: Actually,
you know what?

00:20:38.050 --> 00:20:40.050
I didn't think about that until
after the book had come out.

00:20:40.050 --> 00:20:41.758
MALE SPEAKER: Oh,
after you pressed send.

00:20:42.945 --> 00:20:44.570
JON RONSON: I shouldn't
have named him.

00:20:44.570 --> 00:20:46.530
And in fact, if I'd
thought about it,

00:20:46.530 --> 00:20:49.420
I could have taken his
name out for the paperback,

00:20:49.420 --> 00:20:52.648
but I was in the midst of my
own shaming, so I didn't--

00:20:52.648 --> 00:20:54.773
MALE SPEAKER: Isn't there
a potential then actually

00:20:54.773 --> 00:20:57.276
that it just drives more people
to then find out about it?

00:20:57.276 --> 00:20:58.650
And then maybe if
they're online,

00:20:58.650 --> 00:21:00.950
they've looked in public record.

00:21:00.950 --> 00:21:03.710
It's the classic thing
of X-ing something out,

00:21:03.710 --> 00:21:06.710
actually makes it more--

00:21:06.710 --> 00:21:09.280
JON RONSON: Like the Google
right to be forgotten.

00:21:09.280 --> 00:21:11.453
I mean, when I read that
thing about the couple

00:21:11.453 --> 00:21:14.834
having sex on the train
invoking their right

00:21:14.834 --> 00:21:17.249
to be forgotten, obviously,
like everybody else,

00:21:17.249 --> 00:21:19.082
I thought, oh, I'd
forgotten all about that.

00:21:23.920 --> 00:21:26.726
Yeah, I mean luckily
in this book,

00:21:26.726 --> 00:21:29.900
very luckily, pretty
much everybody,

00:21:29.900 --> 00:21:32.494
almost everybody in the book
is delighted with the way

00:21:32.494 --> 00:21:33.810
that they came over.

00:21:33.810 --> 00:21:37.878
And in fact, the fact that
Justine's story became huge

00:21:37.878 --> 00:21:41.840
as a result of my
book, Justine's

00:21:41.840 --> 00:21:46.388
happy about that, because it's
supplanted the old narrative

00:21:46.388 --> 00:21:48.310
with a new narrative.

00:21:48.310 --> 00:21:50.758
And the same as
Lindsey Stone, she's

00:21:50.758 --> 00:21:56.304
very happy that the book's out
there, and people are hearing--

00:21:56.304 --> 00:21:57.720
MALE SPEAKER: Her
story, her side.

00:21:57.720 --> 00:22:00.101
JON RONSON: Yeah, exactly.

00:22:00.101 --> 00:22:02.600
MALE SPEAKER: I was reading the
book on holiday last summer,

00:22:02.600 --> 00:22:05.000
and the son of a
couple friends of mine

00:22:05.000 --> 00:22:06.780
picked it up, and devoured it.

00:22:06.780 --> 00:22:08.656
And I couldn't get
it back for two days.

00:22:08.656 --> 00:22:09.480
He's about 15.

00:22:09.480 --> 00:22:11.704
And so I talked to
him about it, and he

00:22:11.704 --> 00:22:16.122
said that he is very nervous
about publishing anything.

00:22:16.122 --> 00:22:18.200
You've got a teenage son.

00:22:18.200 --> 00:22:21.130
Do you advise him on his
social media profile?

00:22:21.130 --> 00:22:26.470
JON RONSON: He's quite-- my
son is quite unadvisable,

00:22:26.470 --> 00:22:27.422
because he's so--

00:22:27.422 --> 00:22:28.650
MALE SPEAKER: Well, maybe
let's separate family, then.

00:22:28.650 --> 00:22:29.250
If you were talking to--

00:22:29.250 --> 00:22:30.320
JON RONSON: Well, no,
actually, my son--

00:22:30.320 --> 00:22:31.695
MALE SPEAKER: If
you were talking

00:22:31.695 --> 00:22:34.420
to a bunch of teenagers that
weren't blood relatives,

00:22:34.420 --> 00:22:37.190
what would you say to them?

00:22:37.190 --> 00:22:43.230
JON RONSON: Well, at a talk,
when the book first came out,

00:22:43.230 --> 00:22:45.980
a child psychologist came up
to me in the signing queue.

00:22:45.980 --> 00:22:48.790
I was about to tell this story
when that guy started heckling,

00:22:48.790 --> 00:22:51.500
and so I never got to tell
this story onstage last night.

00:22:51.500 --> 00:22:54.570
This child psychologist came
up to me in the signing queue

00:22:54.570 --> 00:22:58.460
and said that every single--
she said either every single

00:22:58.460 --> 00:23:02.170
or almost every child
who comes to her damaged

00:23:02.170 --> 00:23:04.220
now is damaged as a
result of something that

00:23:04.220 --> 00:23:05.790
happened on social media.

00:23:05.790 --> 00:23:13.150
So my answer to that
question isn't necessarily

00:23:13.150 --> 00:23:15.380
the right answer,
But when I think

00:23:15.380 --> 00:23:17.052
about the destruction
of Justine Sacco,

00:23:17.052 --> 00:23:18.677
and I said this on
Twitter, by the way,

00:23:18.677 --> 00:23:20.080
and got a ferocious response.

00:23:20.080 --> 00:23:23.620
So I apologize if what I'm
about to say offends anybody.

00:23:23.620 --> 00:23:26.690
But when I think about Justine
Sacco and people saying to me,

00:23:26.690 --> 00:23:30.340
I'm going to send your book
to my children to show them,

00:23:30.340 --> 00:23:32.954
don't be like Justine
Sacco, don't tweet something

00:23:32.954 --> 00:23:38.290
that could be misconstrued,
be more careful,

00:23:38.290 --> 00:23:42.350
that reminds me of like,
girls at Saturday night,

00:23:42.350 --> 00:23:43.850
don't wear short skirts.

00:23:43.850 --> 00:23:46.198
It feels to me like
victim blaming.

00:23:46.198 --> 00:23:48.380
I think the people
who should be changing

00:23:48.380 --> 00:23:51.800
their behavior in the Justine
Sacco incident are the shamers.

00:23:51.800 --> 00:23:55.220
I mean, Justine was an idiot,
and my god, she paid the price.

00:23:55.220 --> 00:23:57.770
But she was asleep on a plane.

00:23:57.770 --> 00:24:00.160
The joke wasn't intended--
et cetera, et cetera.

00:24:00.160 --> 00:24:04.100
So I think that's what I
would say to teenagers.

00:24:04.100 --> 00:24:08.210
Of course, don't be offensive.

00:24:08.210 --> 00:24:09.980
As I said before,
I'm a firm believer

00:24:09.980 --> 00:24:11.380
in political correctness.

00:24:11.380 --> 00:24:16.085
I remember in the 1970s,
on Saturday night TV,

00:24:16.085 --> 00:24:18.840
it was wall-to-wall
racism and sexism.

00:24:18.840 --> 00:24:22.660
And political correctness
has solved that.

00:24:22.660 --> 00:24:25.900
So I'm not attacking
political correctness.

00:24:25.900 --> 00:24:31.012
But I am saying, don't
be like reputation.com

00:24:31.012 --> 00:24:33.142
had to be toward Lindsey Stone.

00:24:36.470 --> 00:24:37.864
Be audacious.

00:24:37.864 --> 00:24:39.240
Be open.

00:24:39.240 --> 00:24:41.135
And don't pile on people.

00:24:41.135 --> 00:24:42.010
That's the behavior--

00:24:42.010 --> 00:24:43.551
MALE SPEAKER: That's
the key message.

00:24:43.551 --> 00:24:46.330
And always look for
context and reason.

00:24:46.330 --> 00:24:50.821
JON RONSON: Curiosity, context,
nuance, compassion, empathy.

00:24:50.821 --> 00:24:51.320
Hello.

00:24:51.320 --> 00:24:52.120
Oh, yes.

00:24:52.120 --> 00:24:54.028
MALE SPEAKER: Yeah, please.

00:24:54.028 --> 00:24:55.936
JON RONSON: I hope
people are enjoying this.

00:24:55.936 --> 00:24:57.850
AUDIENCE: Very much.

00:24:57.850 --> 00:24:59.800
Yeah, a question
on exactly that,

00:24:59.800 --> 00:25:03.110
because if you look at the
anthropological evolution

00:25:03.110 --> 00:25:05.420
of humans, right,
everybody used to live

00:25:05.420 --> 00:25:08.890
in small communities, small
villages, towns, bigger cities.

00:25:08.890 --> 00:25:10.940
And reputation was
something that you

00:25:10.940 --> 00:25:13.590
had to keep amongst
your peers, and whenever

00:25:13.590 --> 00:25:15.810
somebody tried to
slander you, that

00:25:15.810 --> 00:25:19.470
could backfire to that person
some way along the way.

00:25:19.470 --> 00:25:21.960
Just give it time
in worst cases.

00:25:21.960 --> 00:25:26.070
Now the world is
your small town,

00:25:26.070 --> 00:25:31.360
and technology has allowed
us to become global

00:25:31.360 --> 00:25:34.960
very fast, which is something
that humans haven't necessarily

00:25:34.960 --> 00:25:37.650
evolved that fast to handle.

00:25:37.650 --> 00:25:41.050
How do you think it's
possible for the bullies

00:25:41.050 --> 00:25:43.350
and just the mentality
and the way that humans

00:25:43.350 --> 00:25:46.409
behave to evolve to match that?

00:25:46.409 --> 00:25:47.450
JON RONSON: You're right.

00:25:47.450 --> 00:25:48.460
We haven't caught up.

00:25:48.460 --> 00:25:50.730
What I noticed time
and time again,

00:25:50.730 --> 00:25:53.980
when I was writing this book,
was that we haven't caught up

00:25:53.980 --> 00:25:56.640
with the new circumstances.

00:25:56.640 --> 00:26:00.550
So on Twitter, we like to
see ourselves as powerless,

00:26:00.550 --> 00:26:04.940
but we are very, very powerful.

00:26:04.940 --> 00:26:07.400
If we tell a corporation that
we want that person fired,

00:26:07.400 --> 00:26:09.297
that person will be fired.

00:26:09.297 --> 00:26:10.880
I say in the book,
we're like toddlers

00:26:10.880 --> 00:26:12.088
crawling towards a gun.

00:26:14.620 --> 00:26:17.289
So honestly, because I don't
think you can regulate.

00:26:17.289 --> 00:26:19.830
I mean, personally, it's funny,
before I'd written this book,

00:26:19.830 --> 00:26:22.590
I would have knee-jerk
against the right

00:26:22.590 --> 00:26:24.090
to be forgotten,
because journalists

00:26:24.090 --> 00:26:26.260
are supposed to against
the right to be forgotten.

00:26:26.260 --> 00:26:28.182
And I don't feel
that way anymore.

00:26:28.182 --> 00:26:30.750
I'm all for the
right to be forgotten

00:26:30.750 --> 00:26:32.870
for private individuals,
like the couple having

00:26:32.870 --> 00:26:33.590
sex on the train.

00:26:33.590 --> 00:26:38.120
Because I've gone from
being a prosecution

00:26:38.120 --> 00:26:40.780
attorney to a defense
attorney over the years.

00:26:40.780 --> 00:26:42.926
And now I feel like
all defense attorneys

00:26:42.926 --> 00:26:45.175
do, that people shouldn't
be judged by the worst thing

00:26:45.175 --> 00:26:47.690
that they ever did, unless
it's something so terrible

00:26:47.690 --> 00:26:51.435
that it deserves to
swallow up their life.

00:26:51.435 --> 00:26:52.770
So I'm all for that.

00:26:52.770 --> 00:26:55.580
But basically, what I think is
we need to have conversations

00:26:55.580 --> 00:26:56.150
like this.

00:26:56.150 --> 00:27:01.250
Because every time people
think in a more holistic way

00:27:01.250 --> 00:27:04.960
about this kind of situation,
then hopefully when

00:27:04.960 --> 00:27:08.366
shamings happen, everything just
gets a little bit more nuanced,

00:27:08.366 --> 00:27:09.590
and voices back and forward.

00:27:09.590 --> 00:27:10.465
And that's democracy.

00:27:13.270 --> 00:27:15.729
MALE SPEAKER: Two at the
back there, and one there.

00:27:15.729 --> 00:27:17.020
And whoever gets the mic first.

00:27:18.860 --> 00:27:21.360
JON RONSON: Can I just quickly
add something about the right

00:27:21.360 --> 00:27:23.060
to be forgotten?

00:27:23.060 --> 00:27:28.420
Really, I just thought now
was that reputation.com,

00:27:28.420 --> 00:27:32.740
it costs quite a lot of money
to get your reputation scrubbed.

00:27:32.740 --> 00:27:34.900
I mean, they told me that
they were giving Lindsey

00:27:34.900 --> 00:27:36.954
hundreds of thousands of
dollars in free service.

00:27:36.954 --> 00:27:39.120
MALE SPEAKER: Yeah, that's
what it says in the book.

00:27:39.120 --> 00:27:43.079
JON RONSON: Whereas even
though social media is

00:27:43.079 --> 00:27:44.620
a leveling of the
playing field, it's

00:27:44.620 --> 00:27:46.290
still the
multi-millionaires that

00:27:46.290 --> 00:27:48.270
could afford to get their
reputations scrubbed.

00:27:48.270 --> 00:27:51.531
So the right to be forgotten
is a more egalitarian version

00:27:51.531 --> 00:27:52.030
of that.

00:27:52.030 --> 00:27:52.940
MALE SPEAKER: More
egalitarian, yes.

00:27:52.940 --> 00:27:53.880
Right, good.

00:27:53.880 --> 00:27:55.186
Who's got the mic?

00:27:55.186 --> 00:27:57.560
AUDIENCE: So it seems to
me there's two directions

00:27:57.560 --> 00:27:58.670
that it can go from here.

00:27:58.670 --> 00:28:00.860
One is one we've
already discussed,

00:28:00.860 --> 00:28:03.490
which is that people
become more bland.

00:28:03.490 --> 00:28:04.810
They become more innocuous.

00:28:04.810 --> 00:28:07.073
But it's perhaps
the other, and I

00:28:07.073 --> 00:28:08.656
was thinking about
this the other day,

00:28:08.656 --> 00:28:11.660
is that you're approaching
a generation that

00:28:11.660 --> 00:28:14.660
will reach middle age in the
next year 20, 30 years, who

00:28:14.660 --> 00:28:17.140
have grown up with this kind
of stuff all around them,

00:28:17.140 --> 00:28:19.870
and are used to having all
this information out there

00:28:19.870 --> 00:28:24.640
about them, and have to
recognize that everybody has

00:28:24.640 --> 00:28:27.470
some dirty, little secret that
is going to be aired in public,

00:28:27.470 --> 00:28:29.910
and everybody has an
opportunity to be shamed.

00:28:29.910 --> 00:28:32.900
And so it's like mutually
assured destruction,

00:28:32.900 --> 00:28:34.947
and everyone decides,
you know what?

00:28:34.947 --> 00:28:36.780
It's not worth picking
on that other person,

00:28:36.780 --> 00:28:38.240
because I'm sure
I have something

00:28:38.240 --> 00:28:40.025
that somebody could
make fun of and shame

00:28:40.025 --> 00:28:41.057
in exactly the same way.

00:28:41.057 --> 00:28:41.890
JON RONSON: Totally.

00:28:41.890 --> 00:28:44.389
AUDIENCE: Do you think there's
a sense of it going that way?

00:28:44.389 --> 00:28:47.705
JON RONSON: I totally agree
that that is the ideal.

00:28:47.705 --> 00:28:49.170
And it might happen.

00:28:52.120 --> 00:28:55.340
Someone said to me about
the Ashley Madison hack.

00:28:55.340 --> 00:28:59.230
Though this is slightly a
tangential thing, somebody

00:28:59.230 --> 00:29:02.980
who was pro the Ashley
Madison hack basically said,

00:29:02.980 --> 00:29:05.185
well all of our secrets
should be out in public.

00:29:05.185 --> 00:29:07.820
And my response to
that was, there's

00:29:07.820 --> 00:29:11.400
a massive difference
between being out and being

00:29:11.400 --> 00:29:15.040
outed, a profound difference.

00:29:15.040 --> 00:29:19.107
So what I've noticed
these days is

00:29:19.107 --> 00:29:26.310
that sometimes the people who
do the shaming most ferociously

00:29:26.310 --> 00:29:28.770
are people who are most afraid
that the same thing's going

00:29:28.770 --> 00:29:31.480
to happen to them.

00:29:31.480 --> 00:29:35.000
Jonah Lehrer got destroyed
by the journalistic community

00:29:35.000 --> 00:29:38.750
I'm sure in part because
everybody thought, there

00:29:38.750 --> 00:29:44.830
but for the grace of God
go I. So let's get him,

00:29:44.830 --> 00:29:49.765
like a Mayan deity
blood sacrifice.

00:29:49.765 --> 00:29:50.640
But I agree with you.

00:29:50.640 --> 00:29:52.920
I think it's possible.

00:29:52.920 --> 00:29:53.780
It's happening.

00:29:53.780 --> 00:29:56.310
Actually, I'm really
thinking on my feet here,

00:29:56.310 --> 00:29:58.170
but it's kind of
happening a bit in porn.

00:29:58.170 --> 00:30:00.960
I've been spending
some time in the porn

00:30:00.960 --> 00:30:07.220
community for this future
project, and a lot of women

00:30:07.220 --> 00:30:09.150
have said to me, a
lot of porn women

00:30:09.150 --> 00:30:15.080
have said to me, that everybody
wants to be in porn now.

00:30:15.080 --> 00:30:17.840
Honestly, the
market is saturated.

00:30:17.840 --> 00:30:20.390
One of the big
problems in porn now

00:30:20.390 --> 00:30:27.510
is that millions of 18-year-old
girls want to get into porn.

00:30:27.510 --> 00:30:30.900
And so everybody's fighting
really hard to build a career,

00:30:30.900 --> 00:30:33.174
because there's this
constant influx of new girls.

00:30:33.174 --> 00:30:35.340
And that's kind of what
you're talking about, right?

00:30:35.340 --> 00:30:37.900
When you grow up in a generation
where everybody is watching

00:30:37.900 --> 00:30:41.570
porn for free, it sort
of destigmatizes it

00:30:41.570 --> 00:30:43.489
for a lot of young people.

00:30:43.489 --> 00:30:44.030
So who knows?

00:30:44.030 --> 00:30:47.830
So Maybe it'll be a utopian
world where everyone's in porn.

00:30:52.115 --> 00:30:53.740
MALE SPEAKER: Linking
smoothly, Pia?

00:30:53.740 --> 00:30:56.577
AUDIENCE: I have a question,
but can you hear me?

00:30:56.577 --> 00:30:57.535
JON RONSON: It's quiet.

00:31:00.350 --> 00:31:00.950
AUDIENCE: No?

00:31:00.950 --> 00:31:01.450
No, sorry.

00:31:01.450 --> 00:31:03.158
AUDIENCE: We'll take
the back ways first.

00:31:03.158 --> 00:31:04.104
AUDIENCE: OK, yeah.

00:31:04.104 --> 00:31:06.020
AUDIENCE: I've got a
question about this book,

00:31:06.020 --> 00:31:07.230
but I've also got a
question about another book.

00:31:07.230 --> 00:31:08.150
It depends on what you'd prefer.

00:31:08.150 --> 00:31:08.830
JON RONSON: Oh, sure.

00:31:08.830 --> 00:31:09.170
Thank you.

00:31:09.170 --> 00:31:10.416
AUDIENCE: What would you prefer?

00:31:10.416 --> 00:31:12.082
MALE SPEAKER: This
book or another book?

00:31:12.082 --> 00:31:12.770
Change tack?

00:31:12.770 --> 00:31:14.040
JON RONSON: Oh, no, just--

00:31:14.040 --> 00:31:16.660
AUDIENCE: So a question
about this book, or "Them"

00:31:16.660 --> 00:31:17.680
was the other one I
wanted to ask about?

00:31:17.680 --> 00:31:19.160
JON RONSON: "Them," because I'm
doing a "Them" talk tonight.

00:31:19.160 --> 00:31:20.590
AUDIENCE: Also, I was trying
to work out which of your books

00:31:20.590 --> 00:31:21.900
would make the best porn title.

00:31:21.900 --> 00:31:24.747
And I think "The Men Who Stare
at Goats" is probably up there.

00:31:24.747 --> 00:31:25.830
MALE SPEAKER: Nicely done.

00:31:25.830 --> 00:31:28.840
AUDIENCE: In terms of
"Them," you write brilliantly

00:31:28.840 --> 00:31:30.290
about the Tottenham
Ayatollah, who

00:31:30.290 --> 00:31:32.270
sounds like a bundle of laughs.

00:31:32.270 --> 00:31:35.264
But what I wanted to ask is,
in the light of lot of changes

00:31:35.264 --> 00:31:36.680
that have happened
since you wrote

00:31:36.680 --> 00:31:39.700
the book, especially the
movement of a lot of people

00:31:39.700 --> 00:31:43.400
to Syria from the UK, was there
something darker happening

00:31:43.400 --> 00:31:44.790
underneath what was going on?

00:31:44.790 --> 00:31:47.630
Because it sounded so calamitous
when you wrote about it,

00:31:47.630 --> 00:31:50.730
but it sounds rather
better organized nowadays.

00:31:50.730 --> 00:31:52.440
JON RONSON: Yes.

00:31:52.440 --> 00:31:54.100
Or chaotic, when
I wrote about it.

00:31:54.100 --> 00:31:55.960
Yeah, I mean, I
can't deny the fact

00:31:55.960 --> 00:31:59.755
that I spent a year with
Omar Bakri Muhammad,

00:31:59.755 --> 00:32:03.090
and really, we treated
him as a humorous--

00:32:03.090 --> 00:32:04.410
we were products of our time.

00:32:04.410 --> 00:32:09.463
This was pre-9/11, and we
treated him as a humorous

00:32:09.463 --> 00:32:12.130
buffoon, I suppose.

00:32:12.130 --> 00:32:15.610
Like, oh, what a lovely jihad.

00:32:15.610 --> 00:32:19.485
And I spent a year with
him, and I got into scrapes,

00:32:19.485 --> 00:32:21.430
and it was all kind
of silly and funny.

00:32:21.430 --> 00:32:24.160
I remember he outed me as
a Jew at his jihad training

00:32:24.160 --> 00:32:27.586
camp in Crawley.

00:32:27.586 --> 00:32:32.890
And it was all silly and funny.

00:32:32.890 --> 00:32:37.789
And Yeah, since
then so many people,

00:32:37.789 --> 00:32:39.247
including people
who were literally

00:32:39.247 --> 00:32:41.800
at that jihad training
camp had gone on

00:32:41.800 --> 00:32:45.520
to become suicide
bombers and murderers.

00:32:45.520 --> 00:32:49.540
And I was accused of
missing the story.

00:32:49.540 --> 00:32:50.100
It's funny.

00:32:50.100 --> 00:32:54.340
There was a guy called Mike
Wine from the board of deputies

00:32:54.340 --> 00:32:56.382
of British Jews at the time.

00:32:56.382 --> 00:32:59.510
This was 1996.

00:32:59.510 --> 00:33:03.750
Said to me, the world
has not woken up

00:33:03.750 --> 00:33:06.957
to the dangers of
militant Islamism.

00:33:06.957 --> 00:33:08.165
And I was thinking, oh, Mike.

00:33:11.362 --> 00:33:12.770
There you go.

00:33:12.770 --> 00:33:14.996
However, what I would
say in defense of myself

00:33:14.996 --> 00:33:17.120
is that everything
I wrote was true.

00:33:17.120 --> 00:33:20.666
They weren't putting on a
fake, putting on a persona.

00:33:20.666 --> 00:33:25.030
And I remember Terry
Gross from "Fresh Air,"

00:33:25.030 --> 00:33:29.220
which is a big American radio
show, asked me that question.

00:33:29.220 --> 00:33:32.336
Said, you were
wrong, weren't you?

00:33:32.336 --> 00:33:34.650
And I said, that's in my
paranoid imagination, what

00:33:34.650 --> 00:33:35.150
she said.

00:33:35.150 --> 00:33:38.221
She might have said something
a bit nicer than that.

00:33:38.221 --> 00:33:41.140
And I said, though,
you can be a buffoon

00:33:41.140 --> 00:33:43.280
and you can still fly a
plane into a building.

00:33:43.280 --> 00:33:47.100
So I don't feel that
what he did was wrong.

00:33:47.100 --> 00:33:49.800
And you could argue
that it's valuable,

00:33:49.800 --> 00:33:52.240
because it was capturing
that moment in time

00:33:52.240 --> 00:33:55.200
just before things
started to turn horrific.

00:33:55.200 --> 00:33:57.650
Thank you.

00:33:57.650 --> 00:33:58.667
MALE SPEAKER: Pia.

00:33:58.667 --> 00:34:01.000
AUDIENCE: I have a question
that's not fully formulated,

00:34:01.000 --> 00:34:03.125
and it's really more
observations that confused me.

00:34:03.125 --> 00:34:06.130
And I was wondering if
you have thoughts on them.

00:34:06.130 --> 00:34:07.960
So when I was growing
up, I felt like there

00:34:07.960 --> 00:34:11.710
was an understanding of an
elite and then the masses.

00:34:11.710 --> 00:34:15.230
And I read books like "1984"
and "Brave New World."

00:34:15.230 --> 00:34:17.620
And now you, of
course, are talking

00:34:17.620 --> 00:34:21.960
about how there's almost this
move in society towards a more

00:34:21.960 --> 00:34:24.570
private society, so where
we're governed by our own laws

00:34:24.570 --> 00:34:26.750
and gay people can marry,
and everyone's equal,

00:34:26.750 --> 00:34:28.860
and everyone can basically
do whatever they want.

00:34:28.860 --> 00:34:30.360
But then we have
social media, which

00:34:30.360 --> 00:34:32.989
is introducing this new
public shaming, which, again,

00:34:32.989 --> 00:34:35.520
is giving back the power
to the masses to say,

00:34:35.520 --> 00:34:37.940
if you're not like
me, you're going down.

00:34:37.940 --> 00:34:40.800
And then we have the
daily news feeds,

00:34:40.800 --> 00:34:43.540
that our now daily and weekly,
which we didn't have before,

00:34:43.540 --> 00:34:45.290
saying celebrities,
they are just like us.

00:34:45.290 --> 00:34:46.164
They have cellulite like us.

00:34:46.164 --> 00:34:47.040
They cheat like us.

00:34:47.040 --> 00:34:49.400
So it's trying to create
a level playing field,

00:34:49.400 --> 00:34:51.210
but where everything
is based on the lowest

00:34:51.210 --> 00:34:54.254
common denominator rather than
the highest common denominator.

00:34:54.254 --> 00:34:55.962
And you have people
like the Kardashians,

00:34:55.962 --> 00:34:57.131
who are our new elite.

00:34:57.131 --> 00:34:58.755
And like you were
saying, lots of girls

00:34:58.755 --> 00:35:01.050
want to go into porn, or
lots of people on Instagram

00:35:01.050 --> 00:35:05.490
being extremely narcissistic
about posting 10 selfies a day.

00:35:05.490 --> 00:35:07.740
Where do you think we're
heading with this, basically?

00:35:07.740 --> 00:35:09.906
And do you think it's time
that we have a new elite?

00:35:09.906 --> 00:35:12.100
Or how do we construct an
elite out of the masses?

00:35:12.100 --> 00:35:13.330
What is happening, basically?

00:35:15.441 --> 00:35:17.857
MALE SPEAKER: I feel reasonably
confident you haven't been

00:35:17.857 --> 00:35:20.031
asked that question before.

00:35:20.031 --> 00:35:22.281
JON RONSON: I haven't been
asked that question before,

00:35:22.281 --> 00:35:25.381
however that question does
speak to something which

00:35:25.381 --> 00:35:29.190
I think I'm heading into in
a future project of mine.

00:35:29.190 --> 00:35:31.700
And the truth is, I
think it's interesting

00:35:31.700 --> 00:35:33.790
that you ask that
question where we

00:35:33.790 --> 00:35:38.890
are sitting right now, Google,
because there is a new elite.

00:35:38.890 --> 00:35:44.600
I say in the book-- I
asked an internet economist

00:35:44.600 --> 00:35:47.287
to try and work out for me
how much money Google made out

00:35:47.287 --> 00:35:48.787
of the destruction
of Justine Sacco.

00:35:52.603 --> 00:35:54.426
And the figure they
came back with, they

00:35:54.426 --> 00:35:56.430
said the conservative
figure they came back with

00:35:56.430 --> 00:36:01.730
was $120,000 Google made out
of Justine's annihilation

00:36:01.730 --> 00:36:02.980
that night.

00:36:02.980 --> 00:36:05.432
And please don't
ask me to say how

00:36:05.432 --> 00:36:07.390
they got their calculations,
because I honestly

00:36:07.390 --> 00:36:11.416
can't remember, although
it's in the book.

00:36:11.416 --> 00:36:13.790
Whereas, of course, those of
us doing the actual shaming,

00:36:13.790 --> 00:36:15.050
we got nothing.

00:36:15.050 --> 00:36:20.460
We were unpaid shaming interns
for Google and Twitter.

00:36:20.460 --> 00:36:25.050
So there is an elite,
and it's Silicon Valley.

00:36:25.050 --> 00:36:25.800
That is the elite.

00:36:25.800 --> 00:36:32.700
You see it happening with
Apple Music, or Spotify,

00:36:32.700 --> 00:36:34.700
with Google, with
Twitter, to a lesser

00:36:34.700 --> 00:36:37.770
extent, and other
companies, which

00:36:37.770 --> 00:36:39.929
I'm looking at for my
next project, which

00:36:39.929 --> 00:36:41.470
I don't want to
name, because I don't

00:36:41.470 --> 00:36:43.470
want to give away what it is.

00:36:43.470 --> 00:36:44.624
So there is an elite.

00:36:44.624 --> 00:36:48.592
We are all drones working
for this new elite.

00:36:48.592 --> 00:36:50.550
AUDIENCE: So what you're
saying is that instead

00:36:50.550 --> 00:36:53.650
of an elite of intellectuals,
for instance, as we had before,

00:36:53.650 --> 00:36:56.160
we now have an elite
that has created tools

00:36:56.160 --> 00:36:59.120
of mass distribution,
tools of mass publication,

00:36:59.120 --> 00:37:00.750
and that is the
elite, because they've

00:37:00.750 --> 00:37:02.250
given the power to the people?

00:37:02.250 --> 00:37:04.690
JON RONSON: Yeah, and
people don't care.

00:37:04.690 --> 00:37:06.225
Why do people not care?

00:37:06.225 --> 00:37:07.808
Because they're
getting everything for

00:37:07.808 --> 00:37:09.280
free on the internet.

00:37:09.280 --> 00:37:12.100
MALE SPEAKER: Do you think
there's-- because you

00:37:12.100 --> 00:37:14.080
approached Twitter when
the spam bot was up.

00:37:14.080 --> 00:37:17.710
Do you think there
is more of a role

00:37:17.710 --> 00:37:20.096
that the media company
should be taking?

00:37:20.096 --> 00:37:21.220
JON RONSON: Oh Jesus, yeah.

00:37:21.220 --> 00:37:23.376
Twitter I think have
behaved-- honestly,

00:37:23.376 --> 00:37:24.500
I mean, I hate to say this.

00:37:24.500 --> 00:37:26.556
I think Twitter have
behaved despicably.

00:37:26.556 --> 00:37:29.599
At one point, somebody
set up-- because

00:37:29.599 --> 00:37:31.640
of the kind of ferocious
response towards my book

00:37:31.640 --> 00:37:34.050
from a very, very
small number of people

00:37:34.050 --> 00:37:37.700
who hadn't read
my book, somebody

00:37:37.700 --> 00:37:41.950
set up a fake Jon Ronson
account in which I was always

00:37:41.950 --> 00:37:46.790
praising the white supremacist
who killed those people

00:37:46.790 --> 00:37:50.390
in South Carolina, Dylann Roof.

00:37:50.390 --> 00:37:52.490
And so for the first and
only time in my life,

00:37:52.490 --> 00:37:56.320
I complained to Twitter, and
I got a letter back saying,

00:37:56.320 --> 00:38:00.332
this is not in violation of
our impersonation policy.

00:38:00.332 --> 00:38:01.280
And then that was it.

00:38:01.280 --> 00:38:03.870
They shut me off.

00:38:03.870 --> 00:38:07.660
So I just felt this rage rage.

00:38:07.660 --> 00:38:10.710
We are unpaid shaming
interns for a company

00:38:10.710 --> 00:38:13.149
that doesn't give a
flying fuck about us.

00:38:13.149 --> 00:38:14.690
MALE SPEAKER: Come
here, Rob, I hink.

00:38:17.560 --> 00:38:20.030
AUDIENCE: Following on
from the previous point,

00:38:20.030 --> 00:38:24.790
in that example, media
companies and in particular tech

00:38:24.790 --> 00:38:27.980
companies like Google, do a
lot to distance themselves

00:38:27.980 --> 00:38:31.650
from those moral
scenarios, because we just

00:38:31.650 --> 00:38:33.740
provide the tools,
and it's up to people

00:38:33.740 --> 00:38:36.100
themselves to govern
how they use it.

00:38:36.100 --> 00:38:42.490
Do you think that there is
a potential future where

00:38:42.490 --> 00:38:44.520
not necessarily tech
companies but just

00:38:44.520 --> 00:38:49.070
there is a higher moral arbiter
which needs to be appealed to?

00:38:49.070 --> 00:38:50.460
Because in the
previous scenario,

00:38:50.460 --> 00:38:53.660
it was the
intellectuals, and you

00:38:53.660 --> 00:38:55.300
would appeal to
those people who were

00:38:55.300 --> 00:38:59.850
seen as the wizened
elders of the clan.

00:38:59.850 --> 00:39:03.180
Now, although the power
has been concentrated

00:39:03.180 --> 00:39:06.120
into different hands, it
seems like those companies,

00:39:06.120 --> 00:39:10.280
in this case, are less
willing to take that standard.

00:39:10.280 --> 00:39:13.100
JON RONSON: Yes,
and they absolutely

00:39:13.100 --> 00:39:14.615
should take that standard.

00:39:14.615 --> 00:39:16.490
And I'm not really
talking about regulations.

00:39:16.490 --> 00:39:18.740
As I said, I happen to think
the right to be forgotten

00:39:18.740 --> 00:39:20.090
is a good thing.

00:39:20.090 --> 00:39:22.700
And you can, of course,
regular against trolls

00:39:22.700 --> 00:39:24.650
who use extreme language.

00:39:24.650 --> 00:39:26.456
You can't regulate
against the millions

00:39:26.456 --> 00:39:28.580
of people who destroyed
Justine Sacco, because they

00:39:28.580 --> 00:39:30.700
were nice people like
us, trying to do good.

00:39:30.700 --> 00:39:32.510
It was trying to be
compassionate that

00:39:32.510 --> 00:39:36.557
lead so many people to the
profoundly uncompassionate act

00:39:36.557 --> 00:39:39.460
of destroying Justine while
she was asleep on a plane.

00:39:39.460 --> 00:39:43.050
So I don't think
regulation is the answer,

00:39:43.050 --> 00:39:45.380
but I do think responsibility.

00:39:45.380 --> 00:39:48.640
Honestly, I think
Twitter is acting

00:39:48.640 --> 00:39:50.860
so idiotically in
the way that it's

00:39:50.860 --> 00:39:54.210
seeming like this
kind of untouchable,

00:39:54.210 --> 00:39:59.170
uncaring elite hiding
behind libertarianism.

00:39:59.170 --> 00:40:01.900
Because people's lives
constantly are getting

00:40:01.900 --> 00:40:04.010
upended on Twitter.

00:40:04.010 --> 00:40:10.280
And for Twitter to take
this detached view-- getting

00:40:10.280 --> 00:40:16.070
that letter that I got, I
wrote back and I said, why not?

00:40:16.070 --> 00:40:17.750
And they never replied.

00:40:17.750 --> 00:40:20.120
AUDIENCE: But we definitely
do the same thing.

00:40:20.120 --> 00:40:22.350
On YouTube and
Facebook, they're all

00:40:22.350 --> 00:40:24.940
not responsible for the
content that's posted.

00:40:24.940 --> 00:40:29.790
So would you say that you would
advocate companies rather than

00:40:29.790 --> 00:40:35.490
governments not censoring
but at least providing

00:40:35.490 --> 00:40:37.822
stricter guidelines as to
what content is posted?

00:40:37.822 --> 00:40:38.780
JON RONSON: Definitely.

00:40:38.780 --> 00:40:40.520
I think it's top down.

00:40:40.520 --> 00:40:41.290
I really do.

00:40:44.150 --> 00:40:48.270
Really unexpected websites
can be really vicious,

00:40:48.270 --> 00:40:50.630
like Mumsnet.

00:40:54.080 --> 00:40:56.250
I mean, I know it's tough
to have a young kid,

00:40:56.250 --> 00:40:58.550
but still, you don't need
to take it out of me.

00:41:03.570 --> 00:41:05.840
And I think in a
situation like that,

00:41:05.840 --> 00:41:08.290
it's absolutely
incumbent on the people

00:41:08.290 --> 00:41:13.800
who run the message boards
to create an ambience that

00:41:13.800 --> 00:41:19.660
means that people don't feel
as ready to just destroy.

00:41:19.660 --> 00:41:21.215
And the "Guardian" does it.

00:41:21.215 --> 00:41:22.730
MALE SPEAKER: They moderate
pretty heavily, don't they.

00:41:22.730 --> 00:41:24.022
JON RONSON: Yeah, and good.

00:41:27.210 --> 00:41:31.732
My view's changed since I've
A, got older, and B, done

00:41:31.732 --> 00:41:33.070
this book about public shaming.

00:41:33.070 --> 00:41:35.430
I know it's in the
psychopath book.

00:41:35.430 --> 00:41:38.390
I don't believe in just
everybody doing whatever

00:41:38.390 --> 00:41:39.720
the hell they want.

00:41:39.720 --> 00:41:41.200
The internet is
not the real world.

00:41:41.200 --> 00:41:45.320
The internet is the real world,
and so I am all for people

00:41:45.320 --> 00:41:48.080
taking a heavy hand like
the "Guardian" does.

00:41:48.080 --> 00:41:49.080
MALE SPEAKER: Brilliant.

00:41:49.080 --> 00:41:50.560
We've got a question
over here, and then we'll

00:41:50.560 --> 00:41:52.030
have maybe two or three more.

00:41:52.030 --> 00:41:53.613
AUDIENCE: I've also
got two questions.

00:41:53.613 --> 00:41:56.267
One's really easy to answer, and
then one's more of an opinion.

00:41:56.267 --> 00:41:58.600
The first one is that "Them"
was a really good book when

00:41:58.600 --> 00:42:00.558
it came out, and I found
it really interesting.

00:42:00.558 --> 00:42:04.590
And I'd be really interested to
hear some of those stories now,

00:42:04.590 --> 00:42:06.211
10, 15 years later,
like Alex Jones

00:42:06.211 --> 00:42:08.460
who thinks everything's a
conspiracy, whatever happens

00:42:08.460 --> 00:42:09.890
is clearly a conspiracy theory.

00:42:09.890 --> 00:42:12.540
JON RONSON: Well, Alex Jones
is friends with Donald Trump.

00:42:12.540 --> 00:42:14.123
AUDIENCE: That was
my second question.

00:42:14.123 --> 00:42:17.080
And I wondered if
you had any plans

00:42:17.080 --> 00:42:20.980
to go back and write a sequel or
a new one to see those people.

00:42:20.980 --> 00:42:23.490
And the question was more
about in light of that,

00:42:23.490 --> 00:42:25.980
what do you think of [INAUDIBLE]
Trump and more so much

00:42:25.980 --> 00:42:28.650
Jeremy Corbyn over here, where
they're not political people.

00:42:28.650 --> 00:42:30.650
They're not necessarily
even loved by the press,

00:42:30.650 --> 00:42:33.024
but they seem to be hugely
popular and hugely successful,

00:42:33.024 --> 00:42:36.400
and are probably going to
win nominations and things,

00:42:36.400 --> 00:42:38.540
and that wouldn't have
happened 10, 15 years ago,

00:42:38.540 --> 00:42:39.430
whereas it can now.

00:42:39.430 --> 00:42:42.370
JON RONSON: Yeah, it all feels
like part of the same thing.

00:42:42.370 --> 00:42:48.000
On social media,
it's like a stage

00:42:48.000 --> 00:42:51.118
for constant artificial high
dramas, where everybody's

00:42:51.118 --> 00:42:53.640
either this magnificent hero
or the sickening villain,

00:42:53.640 --> 00:42:58.160
and the nuanced middle ground
has become unfashionable.

00:42:58.160 --> 00:43:00.452
Barbara Ellen wrote this
really nice in the "Guardian."

00:43:00.452 --> 00:43:02.993
I should say, I've been living
in New York for the last three

00:43:02.993 --> 00:43:04.990
or four years, so I'm
really not qualified

00:43:04.990 --> 00:43:06.640
to talk about Jeremy Corbyn.

00:43:06.640 --> 00:43:09.550
From where I'm standing,
some of the things he'd said

00:43:09.550 --> 00:43:13.310
I think seem like
a very good idea.

00:43:13.310 --> 00:43:16.310
I don't see the point of
Trident, for instance.

00:43:16.310 --> 00:43:20.876
But when Barbara Ellen
left the Labour Party,

00:43:20.876 --> 00:43:23.340
she wrote a column in "The
Observer," where she said,

00:43:23.340 --> 00:43:26.090
when did being moderate
become such a dirty word?

00:43:28.740 --> 00:43:32.100
And so it's bleeding out of
social media into politics,

00:43:32.100 --> 00:43:33.280
with Trump and with Corbyn.

00:43:33.280 --> 00:43:36.170
And for me, as a moderate
who just wants everything

00:43:36.170 --> 00:43:39.840
to be reasonable,
it's nightmarish.

00:43:39.840 --> 00:43:42.550
And in terms of
your first question,

00:43:42.550 --> 00:43:46.340
I don't think I would go back,
because I've just noticed that

00:43:46.340 --> 00:43:49.812
the only way I get to tell
stories is when I don't-- I

00:43:49.812 --> 00:43:51.520
like to go into a
world that I don't know

00:43:51.520 --> 00:43:55.020
and don't understand, and
try and solve the mystery.

00:43:55.020 --> 00:43:57.580
Once I feel like I
understand the world,

00:43:57.580 --> 00:44:00.110
I no longer have
any interest in it.

00:44:00.110 --> 00:44:03.210
And that's what happened to
me with the conspiracy world

00:44:03.210 --> 00:44:04.390
in "Them."

00:44:04.390 --> 00:44:07.310
I feel like I get Alex Jones.

00:44:07.310 --> 00:44:09.060
Alex Jones is an
interesting case, though,

00:44:09.060 --> 00:44:12.070
because suddenly he has power.

00:44:12.070 --> 00:44:15.640
It seems like he's influencing
Donald Trump, which

00:44:15.640 --> 00:44:19.650
is incredible, that
this guy who we star

00:44:19.650 --> 00:44:24.490
spotted 15, 20 years ago, this
crazy conspiracy guy suddenly

00:44:24.490 --> 00:44:27.819
seems to actually have power.

00:44:27.819 --> 00:44:29.610
But in general, I
wouldn't go back and redo

00:44:29.610 --> 00:44:31.545
a story for that reason.

00:44:31.545 --> 00:44:33.670
MALE SPEAKER: We've got a
question right over here,

00:44:33.670 --> 00:44:35.096
and then I'll come to you.

00:44:35.096 --> 00:44:36.220
AUDIENCE: Thanks very much.

00:44:36.220 --> 00:44:39.300
I don't know if anyone saw
"Troll Hunters" last night,

00:44:39.300 --> 00:44:41.970
presented by Em Ford,
who is one of YouTube's

00:44:41.970 --> 00:44:43.996
favorite anti-troll people.

00:44:43.996 --> 00:44:45.370
She did the "You
Look Disgusting"

00:44:45.370 --> 00:44:47.980
video that got over
17 million views.

00:44:47.980 --> 00:44:49.990
And it showed her
putting on her makeup

00:44:49.990 --> 00:44:51.680
with responses to
comments she got

00:44:51.680 --> 00:44:54.310
that went from very
negative to very positive.

00:44:54.310 --> 00:44:56.340
So in this documentary,
she went and interviewed

00:44:56.340 --> 00:44:59.930
trolls who had led to
suicide of specific people

00:44:59.930 --> 00:45:01.420
by their comments.

00:45:01.420 --> 00:45:05.020
And no matter how much she
tried to reason with them,

00:45:05.020 --> 00:45:08.050
these people were
never going to change.

00:45:08.050 --> 00:45:09.350
They were like, we don't care.

00:45:09.350 --> 00:45:12.970
We feel like we win
every time you respond.

00:45:12.970 --> 00:45:17.310
So my question is,
for these trolls,

00:45:17.310 --> 00:45:19.650
do you want our
silence, which we often

00:45:19.650 --> 00:45:21.580
construe as ignoring
something and taking

00:45:21.580 --> 00:45:24.760
the moral high ground because we
don't want to feed the trolls?

00:45:24.760 --> 00:45:26.490
Is that silence a
moral high ground

00:45:26.490 --> 00:45:29.285
from people who
don't engage in this?

00:45:29.285 --> 00:45:32.710
Or do you feel like we should
be challenging them and creating

00:45:32.710 --> 00:45:34.820
more debate for
people like Justine?

00:45:34.820 --> 00:45:37.150
She'll be torn apart more,
because the trolls will

00:45:37.150 --> 00:45:39.290
want us to respond.

00:45:39.290 --> 00:45:43.230
Is silence a moral
high ground, or is it

00:45:43.230 --> 00:45:46.170
being complicit in their
life being torn apart?

00:45:46.170 --> 00:45:47.860
So I don't think
there's a good answer.

00:45:47.860 --> 00:45:48.510
JON RONSON: No, I
hear what you're

00:45:48.510 --> 00:45:49.885
saying, although
what I would say

00:45:49.885 --> 00:45:52.412
is that I don't think
that this public shaming

00:45:52.412 --> 00:45:53.930
book is a book about trolls.

00:45:53.930 --> 00:45:57.440
I think trolls are like a
kind of extreme, ridiculous,

00:45:57.440 --> 00:46:01.750
ludicrous minority,
whereas if Justine

00:46:01.750 --> 00:46:04.354
had been piled into
just by trolls,

00:46:04.354 --> 00:46:06.520
I think her story would
have gone away very quickly.

00:46:06.520 --> 00:46:09.660
Because we've got a lot of crazy
trolls, misogynistic idiots.

00:46:09.660 --> 00:46:11.290
And there certainly
were a smattering

00:46:11.290 --> 00:46:12.760
of misogynistic idiots.

00:46:12.760 --> 00:46:17.334
I mean, somebody wrote
somebody HIV positive should

00:46:17.334 --> 00:46:19.000
rape this bitch, and
then we'll find out

00:46:19.000 --> 00:46:21.810
if her skin color
protects her from AIDS.

00:46:21.810 --> 00:46:27.870
That's horrific, but it wasn't
trolls who felled Justine.

00:46:27.870 --> 00:46:29.900
It was us.

00:46:29.900 --> 00:46:31.180
It was lovely people like us.

00:46:31.180 --> 00:46:32.846
So I suppose the
answer to your question

00:46:32.846 --> 00:46:36.550
is, as far as I'm concerned,
the dialogue should

00:46:36.550 --> 00:46:41.120
be with us, reasonable
compassionate people who

00:46:41.120 --> 00:46:48.270
started acting like trolls,
not ridiculous clowns.

00:46:48.270 --> 00:46:50.790
MALE SPEAKER: And then
this question over here.

00:46:50.790 --> 00:46:52.800
AUDIENCE: I just
wanted to ask if you

00:46:52.800 --> 00:46:57.566
think that all of this shaming
is because most of humanity,

00:46:57.566 --> 00:47:02.110
deep inside, sadly, feels
safer and easier when somebody

00:47:02.110 --> 00:47:04.490
else is in a worse
situation than they are,

00:47:04.490 --> 00:47:06.930
and social media is
just enabling it,

00:47:06.930 --> 00:47:08.770
whereas in the
past, they were just

00:47:08.770 --> 00:47:11.219
able to read it
in the newspapers?

00:47:11.219 --> 00:47:12.760
So do you think it's
because of that,

00:47:12.760 --> 00:47:15.357
and is there any way to fix it?

00:47:15.357 --> 00:47:16.565
JON RONSON: No, you're right.

00:47:16.565 --> 00:47:17.946
And I noticed this for
the first time when

00:47:17.946 --> 00:47:20.440
I was writing "The Psychopath
Test," which is an earlier

00:47:20.440 --> 00:47:25.680
book, where I met this
researcher, who used to work

00:47:25.680 --> 00:47:27.910
on the daytime TV
shows where everybody

00:47:27.910 --> 00:47:29.500
would scream at each other.

00:47:29.500 --> 00:47:32.110
And she told me that
she had a secret trick

00:47:32.110 --> 00:47:34.580
that she would utilize
when deciding which guests

00:47:34.580 --> 00:47:35.792
to book for the show.

00:47:35.792 --> 00:47:37.167
And the secret
trick was that she

00:47:37.167 --> 00:47:39.030
would ask them was
medication they were on.

00:47:39.030 --> 00:47:41.890
And if they were on a medication
for something scary-sounding,

00:47:41.890 --> 00:47:44.863
like lithium, she said I
wouldn't have them on the show,

00:47:44.863 --> 00:47:46.738
because you don't want
them to go on the show

00:47:46.738 --> 00:47:48.450
and then go off and
kill themselves.

00:47:48.450 --> 00:47:53.110
But if it was a medication for
a fun-sounding mental illness,

00:47:53.110 --> 00:47:58.390
like Prozac, she said
that's kind of perfect.

00:47:58.390 --> 00:48:00.090
And of course, that's
what she's doing.

00:48:00.090 --> 00:48:02.381
We're putting people on
television who are a little bit

00:48:02.381 --> 00:48:04.210
crazier than we
are, not so crazy

00:48:04.210 --> 00:48:07.570
that we feel bad about it.

00:48:07.570 --> 00:48:11.220
She said to me, we don't
want real exploitation.

00:48:11.220 --> 00:48:12.770
We don't want
overt exploitation.

00:48:12.770 --> 00:48:15.990
We want smoke and
mirrors exploitation.

00:48:15.990 --> 00:48:19.470
And yes, we want people who are
just a bit crazier than we are

00:48:19.470 --> 00:48:22.030
so we feel a bit
happier about ourselves,

00:48:22.030 --> 00:48:25.690
a little bit less
crazy, but not so crazy

00:48:25.690 --> 00:48:28.229
that we feel bad about it.

00:48:28.229 --> 00:48:29.770
MALE SPEAKER: One
last question here.

00:48:29.770 --> 00:48:30.740
AUDIENCE: Hi.

00:48:30.740 --> 00:48:32.490
I thought that was
really interesting what

00:48:32.490 --> 00:48:35.430
you were saying
about women getting

00:48:35.430 --> 00:48:37.830
shamed get way worse insults.

00:48:37.830 --> 00:48:40.070
And then I started
thinking, is it more likely

00:48:40.070 --> 00:48:42.107
a woman to shame or a man?

00:48:42.107 --> 00:48:43.565
I mean, are women
more into shaming

00:48:43.565 --> 00:48:45.273
or are men more into
shaming, or is there

00:48:45.273 --> 00:48:47.250
no kind of correlation?

00:48:47.250 --> 00:48:50.230
And then I was thinking
about "The Psychopath Test."

00:48:50.230 --> 00:48:52.860
And how I recall it,
I remember one woman

00:48:52.860 --> 00:48:55.400
who had mental health problems,
who was in the basement,

00:48:55.400 --> 00:48:57.550
and smeared shit
on the wall, but I

00:48:57.550 --> 00:49:00.590
don't remember you talking
about any female psychopaths.

00:49:00.590 --> 00:49:04.770
And then I started
thinking, it is a male thing

00:49:04.770 --> 00:49:06.644
to be a psychopath?

00:49:06.644 --> 00:49:09.610
Because maybe women have
more empathy or something,

00:49:09.610 --> 00:49:11.510
so we're less likely
to be a psychopath.

00:49:11.510 --> 00:49:13.870
JON RONSON: Well, I've
got an anecdotal answer

00:49:13.870 --> 00:49:16.320
to that second question,
which was there used to be.

00:49:16.320 --> 00:49:17.380
There aren't anymore.

00:49:17.380 --> 00:49:19.820
There used to be these
treatment centers in Britain

00:49:19.820 --> 00:49:23.430
called DSPD units, which were
basically treatment centers

00:49:23.430 --> 00:49:25.160
for psychopaths.

00:49:25.160 --> 00:49:30.270
DSPD means dangerous and
severe personality disorder.

00:49:30.270 --> 00:49:31.750
I'm going back into
my memory here,

00:49:31.750 --> 00:49:34.970
but I think there were
five of them in Britain,

00:49:34.970 --> 00:49:37.880
and four were for men
and one was for women.

00:49:37.880 --> 00:49:40.840
So maybe that's an
anecdotal way to show

00:49:40.840 --> 00:49:42.990
the breakdown between male
and female psychopaths.

00:49:42.990 --> 00:49:44.240
Why?

00:49:44.240 --> 00:49:46.440
I really don't know,
and I should also

00:49:46.440 --> 00:49:51.850
add that in my public shaming
book, the problem with people

00:49:51.850 --> 00:49:55.430
who are really into psychopathy
diagnoses, sometimes,

00:49:55.430 --> 00:49:59.200
is that they're not really that
interested in what happened

00:49:59.200 --> 00:50:01.220
to the person as a
child to make them

00:50:01.220 --> 00:50:03.850
that way, whereas in this book,
I talk about a psychiatrist

00:50:03.850 --> 00:50:07.570
called James Gilligan who
comes to the conclusion

00:50:07.570 --> 00:50:11.000
that all violence is an
attempt to replace shame

00:50:11.000 --> 00:50:13.440
with self-esteem.

00:50:13.440 --> 00:50:15.730
So he believes that
there are some people who

00:50:15.730 --> 00:50:18.930
are diagnosed as psychopaths
are actually not.

00:50:18.930 --> 00:50:22.265
They're people who are trying to
replace shame with self-esteem.

00:50:24.885 --> 00:50:28.340
Oh, and the male
and female thing,

00:50:28.340 --> 00:50:32.460
honestly, my guess,
and also a little bit

00:50:32.460 --> 00:50:34.642
from personal
experience, because I

00:50:34.642 --> 00:50:37.840
had some waves of shaming
over the course of 2015

00:50:37.840 --> 00:50:40.260
as a result of this book
from people who haven't read

00:50:40.260 --> 00:50:44.720
the book-- I don't know if
I mentioned that-- I didn't

00:50:44.720 --> 00:50:47.184
notice any gender differences.

00:50:47.184 --> 00:50:51.294
A helluva lot of
women were mean to me.

00:50:51.294 --> 00:50:53.210
MALE SPEAKER: We are,
I'm afraid, out of time.

00:50:53.210 --> 00:50:55.044
We could clearly go on
for a very long time.

00:50:55.044 --> 00:50:56.418
JON RONSON: I just
wanted to say,

00:50:56.418 --> 00:50:58.790
I aim to end every talk with
a helluva a lot of women

00:50:58.790 --> 00:51:00.654
were mean to me.

00:51:00.654 --> 00:51:03.334
MALE SPEAKER: Well, we've
ticked that box, then.

00:51:03.334 --> 00:51:06.025
So I would like to thank Rob
and Nick for putting it on,

00:51:06.025 --> 00:51:07.470
but most of all, I'd like
to thank Jon for giving up

00:51:07.470 --> 00:51:08.080
an hour to come in.

00:51:08.080 --> 00:51:08.680
Congratulations on the book.

00:51:08.680 --> 00:51:09.580
[APPLAUSE]

00:51:09.580 --> 00:51:11.130
JON RONSON: Thanks.

