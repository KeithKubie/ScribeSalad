WEBVTT
Kind: captions
Language: en

00:00:00.390 --> 00:00:04.655
To get back to the rendering Pipeline, our simplified view is this. The

00:00:04.655 --> 00:00:09.241
Application sends a triangle to the GPU. The GPU determines where the triangles

00:00:09.241 --> 00:00:13.376
vertices are on the screen, including the z-depth. Each pixel inside the

00:00:13.376 --> 00:00:17.294
triangle is shaded. If the pixel passes the z-buffer test It is then saved to

00:00:17.294 --> 00:00:21.482
the image and displayed at the end of the frame. Modern GPUs have parts of the

00:00:21.482 --> 00:00:25.975
Pipeline that are Programmable. The transformed screen part of the Pipeline is

00:00:25.975 --> 00:00:30.502
done by what is called a Vertex Shader. This Programmable element, essentially a

00:00:30.502 --> 00:00:35.073
little computer, processes each Vertex of the triangle. The Vertex Shader uses

00:00:35.073 --> 00:00:40.445
information provided to it to manipulate each Vertex in some way. For example,

00:00:40.445 --> 00:00:44.410
the color of the triangle at this point could be computed, or the vertexes

00:00:44.410 --> 00:00:48.375
position could be modified, if, for example, you wanted to have an object

00:00:48.375 --> 00:00:52.755
inflate or explode. One operation the vertex shader always does is to output a

00:00:52.755 --> 00:00:56.352
location of the vertex on the screen. The second half of our modern GPU

00:00:56.352 --> 00:01:00.994
Pipeline, we represent here by two stages. Triangle set up in the Fragment

00:01:00.994 --> 00:01:05.379
Shader. Triangle set up uses the three screen locations generated by the Vertex

00:01:05.379 --> 00:01:09.488
Shader for an incoming triangle. This forms a triangle in screen space. Each

00:01:09.488 --> 00:01:13.136
pixel covered by part of the triangle has what is called a Fragment generated

00:01:13.136 --> 00:01:17.298
for it. This process is called scan conversion. The Fragments generated are sent

00:01:17.298 --> 00:01:21.633
to the Fragment Shader. Well if you used Microsoft's Direct X API, this is

00:01:21.633 --> 00:01:26.138
called the Pixel Shader instead. The Fragment Shader is provide information by

00:01:26.138 --> 00:01:30.342
the triangle being processed. Some to the Vertex Shader the programmer can also

00:01:30.342 --> 00:01:34.175
feed in any other data desired. The Fragment Shader runs a program that

00:01:34.175 --> 00:01:38.170
typically a Color an a Z Depth value. This Z Depth value is then tested against

00:01:38.170 --> 00:01:42.282
the Z buffer as usual. If the surface is visible, the color is saved for that

00:01:42.282 --> 00:01:46.345
Pixel. The shade Pipeline is designed to compute the Color at each Pixel the

00:01:46.345 --> 00:01:49.710
surface covers. That's it's ultimate purpose after all, creation of an image.

00:01:49.710 --> 00:01:53.337
Everything done in the Pipeline comes down to this. How DO WE EFFICIENTLY

00:01:53.337 --> 00:01:57.110
CALCULATE THIS COLOR? That's what the last half of this unit is about, materials

00:01:57.110 --> 00:02:00.950
and how they work. Given a material and some incoming light you want to compute

00:02:00.950 --> 00:02:02.293
a Color off that material.

