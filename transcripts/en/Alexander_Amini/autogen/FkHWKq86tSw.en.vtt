WEBVTT
Kind: captions
Language: en

00:00:02.389 --> 00:00:07.210
thanks T so I'm Jean Ching and I'm like

00:00:07.210 --> 00:00:07.220
thanks T so I'm Jean Ching and I'm like
 

00:00:07.220 --> 00:00:09.549
thanks T so I'm Jean Ching and I'm like
the also at Google Cambridge office and

00:00:09.549 --> 00:00:09.559
the also at Google Cambridge office and
 

00:00:09.559 --> 00:00:11.770
the also at Google Cambridge office and
I'm one of the authors of tensor flow so

00:00:11.770 --> 00:00:11.780
I'm one of the authors of tensor flow so
 

00:00:11.780 --> 00:00:12.999
I'm one of the authors of tensor flow so
we're going to change topic and talk

00:00:12.999 --> 00:00:13.009
we're going to change topic and talk
 

00:00:13.009 --> 00:00:15.579
we're going to change topic and talk
about tensor flow so I read your course

00:00:15.579 --> 00:00:15.589
about tensor flow so I read your course
 

00:00:15.589 --> 00:00:17.200
about tensor flow so I read your course
material a little bit and I gathered

00:00:17.200 --> 00:00:17.210
material a little bit and I gathered
 

00:00:17.210 --> 00:00:18.910
material a little bit and I gathered
that you all use tensor flow in previous

00:00:18.910 --> 00:00:18.920
that you all use tensor flow in previous
 

00:00:18.920 --> 00:00:20.140
that you all use tensor flow in previous
parts of the lecture is there right

00:00:20.140 --> 00:00:20.150
parts of the lecture is there right
 

00:00:20.150 --> 00:00:21.480
parts of the lecture is there right
great

00:00:21.480 --> 00:00:21.490
great
 

00:00:21.490 --> 00:00:25.900
great
ok so my focus will be how to more

00:00:25.900 --> 00:00:25.910
ok so my focus will be how to more
 

00:00:25.910 --> 00:00:27.730
ok so my focus will be how to more
efficiently write and debug machine

00:00:27.730 --> 00:00:27.740
efficiently write and debug machine
 

00:00:27.740 --> 00:00:30.160
efficiently write and debug machine
learning models in tensor flow so the

00:00:30.160 --> 00:00:30.170
learning models in tensor flow so the
 

00:00:30.170 --> 00:00:32.560
learning models in tensor flow so the
question is um whether you need to debug

00:00:32.560 --> 00:00:32.570
question is um whether you need to debug
 

00:00:32.570 --> 00:00:34.509
question is um whether you need to debug
a machine learning model I think the

00:00:34.509 --> 00:00:34.519
a machine learning model I think the
 

00:00:34.519 --> 00:00:36.430
a machine learning model I think the
answer is yes of course machine learning

00:00:36.430 --> 00:00:36.440
answer is yes of course machine learning
 

00:00:36.440 --> 00:00:37.450
answer is yes of course machine learning
models are very different from

00:00:37.450 --> 00:00:37.460
models are very different from
 

00:00:37.460 --> 00:00:40.149
models are very different from
traditional programs but they are

00:00:40.149 --> 00:00:40.159
traditional programs but they are
 

00:00:40.159 --> 00:00:41.979
traditional programs but they are
software and they're code and if they're

00:00:41.979 --> 00:00:41.989
software and they're code and if they're
 

00:00:41.989 --> 00:00:43.299
software and they're code and if they're
software and code they will have bugs

00:00:43.299 --> 00:00:43.309
software and code they will have bugs
 

00:00:43.309 --> 00:00:45.490
software and code they will have bugs
and you need to debug your models from

00:00:45.490 --> 00:00:45.500
and you need to debug your models from
 

00:00:45.500 --> 00:00:47.710
and you need to debug your models from
time to time so hopefully after this

00:00:47.710 --> 00:00:47.720
time to time so hopefully after this
 

00:00:47.720 --> 00:00:49.119
time to time so hopefully after this
lecture you will know a little bit more

00:00:49.119 --> 00:00:49.129
lecture you will know a little bit more
 

00:00:49.129 --> 00:00:51.009
lecture you will know a little bit more
about how to more efficiently debug your

00:00:51.009 --> 00:00:51.019
about how to more efficiently debug your
 

00:00:51.019 --> 00:00:54.399
about how to more efficiently debug your
machine healing models in tensorflow so

00:00:54.399 --> 00:00:54.409
machine healing models in tensorflow so
 

00:00:54.409 --> 00:00:57.250
machine healing models in tensorflow so
before we dive into debugging I want to

00:00:57.250 --> 00:00:57.260
before we dive into debugging I want to
 

00:00:57.260 --> 00:00:58.600
before we dive into debugging I want to
talk about how machine learning models

00:00:58.600 --> 00:00:58.610
talk about how machine learning models
 

00:00:58.610 --> 00:01:02.259
talk about how machine learning models
are represented in a computer because

00:01:02.259 --> 00:01:02.269
are represented in a computer because
 

00:01:02.269 --> 00:01:04.240
are represented in a computer because
that turns out to be important for how

00:01:04.240 --> 00:01:04.250
that turns out to be important for how
 

00:01:04.250 --> 00:01:06.700
that turns out to be important for how
you write and debug your programs so

00:01:06.700 --> 00:01:06.710
you write and debug your programs so
 

00:01:06.710 --> 00:01:08.290
you write and debug your programs so
there are two ways in which a machine

00:01:08.290 --> 00:01:08.300
there are two ways in which a machine
 

00:01:08.300 --> 00:01:10.720
there are two ways in which a machine
learning model can be represented so

00:01:10.720 --> 00:01:10.730
learning model can be represented so
 

00:01:10.730 --> 00:01:12.510
learning model can be represented so
it's either a data structure or program

00:01:12.510 --> 00:01:12.520
it's either a data structure or program
 

00:01:12.520 --> 00:01:15.730
it's either a data structure or program
so if it's a data structure then when

00:01:15.730 --> 00:01:15.740
so if it's a data structure then when
 

00:01:15.740 --> 00:01:17.650
so if it's a data structure then when
you write code to for example define a

00:01:17.650 --> 00:01:17.660
you write code to for example define a
 

00:01:17.660 --> 00:01:20.170
you write code to for example define a
layer of neural network you're actually

00:01:20.170 --> 00:01:20.180
layer of neural network you're actually
 

00:01:20.180 --> 00:01:22.480
layer of neural network you're actually
building a graph and those lines of code

00:01:22.480 --> 00:01:22.490
building a graph and those lines of code
 

00:01:22.490 --> 00:01:23.920
building a graph and those lines of code
when they're executed they don't

00:01:23.920 --> 00:01:23.930
when they're executed they don't
 

00:01:23.930 --> 00:01:25.390
when they're executed they don't
actually do the computation they're just

00:01:25.390 --> 00:01:25.400
actually do the computation they're just
 

00:01:25.400 --> 00:01:27.040
actually do the computation they're just
building the graph and the graph means

00:01:27.040 --> 00:01:27.050
building the graph and the graph means
 

00:01:27.050 --> 00:01:28.960
building the graph and the graph means
to be later fed into some kind of

00:01:28.960 --> 00:01:28.970
to be later fed into some kind of
 

00:01:28.970 --> 00:01:31.390
to be later fed into some kind of
machinery kind of execution engine to

00:01:31.390 --> 00:01:31.400
machinery kind of execution engine to
 

00:01:31.400 --> 00:01:33.640
machinery kind of execution engine to
actually run the model and the second

00:01:33.640 --> 00:01:33.650
actually run the model and the second
 

00:01:33.650 --> 00:01:35.410
actually run the model and the second
way in which you can define a machine in

00:01:35.410 --> 00:01:35.420
way in which you can define a machine in
 

00:01:35.420 --> 00:01:37.300
way in which you can define a machine in
a model is to write it as a program so

00:01:37.300 --> 00:01:37.310
a model is to write it as a program so
 

00:01:37.310 --> 00:01:38.920
a model is to write it as a program so
that's more straightforward so those

00:01:38.920 --> 00:01:38.930
that's more straightforward so those
 

00:01:38.930 --> 00:01:41.140
that's more straightforward so those
lines of lines of code will actually do

00:01:41.140 --> 00:01:41.150
lines of lines of code will actually do
 

00:01:41.150 --> 00:01:43.630
lines of lines of code will actually do
the competition on either the CPU or GPU

00:01:43.630 --> 00:01:43.640
the competition on either the CPU or GPU
 

00:01:43.640 --> 00:01:45.399
the competition on either the CPU or GPU
depending on whether you have a GPU or

00:01:45.399 --> 00:01:45.409
depending on whether you have a GPU or
 

00:01:45.409 --> 00:01:49.000
depending on whether you have a GPU or
not um so the first paradigm is also

00:01:49.000 --> 00:01:49.010
not um so the first paradigm is also
 

00:01:49.010 --> 00:01:50.560
not um so the first paradigm is also
called arm symbolic execution or

00:01:50.560 --> 00:01:50.570
called arm symbolic execution or
 

00:01:50.570 --> 00:01:52.780
called arm symbolic execution or
deferred execution and the second one is

00:01:52.780 --> 00:01:52.790
deferred execution and the second one is
 

00:01:52.790 --> 00:01:54.730
deferred execution and the second one is
also called eager execution or

00:01:54.730 --> 00:01:54.740
also called eager execution or
 

00:01:54.740 --> 00:01:57.580
also called eager execution or
imperative execution so now the question

00:01:57.580 --> 00:01:57.590
imperative execution so now the question
 

00:01:57.590 --> 00:01:59.410
imperative execution so now the question
for you is whether tensorflow is the

00:01:59.410 --> 00:01:59.420
for you is whether tensorflow is the
 

00:01:59.420 --> 00:02:03.670
for you is whether tensorflow is the
first paradigm or the second paradigm so

00:02:03.670 --> 00:02:03.680
first paradigm or the second paradigm so
 

00:02:03.680 --> 00:02:08.949
first paradigm or the second paradigm so
I heard someone said first second both

00:02:08.949 --> 00:02:08.959
I heard someone said first second both
 

00:02:08.959 --> 00:02:10.510
I heard someone said first second both
yeah so I think it's a trick question

00:02:10.510 --> 00:02:10.520
yeah so I think it's a trick question
 

00:02:10.520 --> 00:02:13.300
yeah so I think it's a trick question
right so and the answer is both so if

00:02:13.300 --> 00:02:13.310
right so and the answer is both so if
 

00:02:13.310 --> 00:02:14.380
right so and the answer is both so if
you ask the question like half a year

00:02:14.380 --> 00:02:14.390
you ask the question like half a year
 

00:02:14.390 --> 00:02:16.390
you ask the question like half a year
ago then the answer will be only the

00:02:16.390 --> 00:02:16.400
ago then the answer will be only the
 

00:02:16.400 --> 00:02:18.580
ago then the answer will be only the
but in the latest version of tensorflow

00:02:18.580 --> 00:02:18.590
but in the latest version of tensorflow
 

00:02:18.590 --> 00:02:20.920
but in the latest version of tensorflow
we support both modes and I'm going to

00:02:20.920 --> 00:02:20.930
we support both modes and I'm going to
 

00:02:20.930 --> 00:02:21.850
we support both modes and I'm going to
give some examples in the following

00:02:21.850 --> 00:02:21.860
give some examples in the following
 

00:02:21.860 --> 00:02:25.240
give some examples in the following
slides so by default

00:02:25.240 --> 00:02:25.250
slides so by default
 

00:02:25.250 --> 00:02:27.100
slides so by default
tensorflow is the first mode so that's

00:02:27.100 --> 00:02:27.110
tensorflow is the first mode so that's
 

00:02:27.110 --> 00:02:31.060
tensorflow is the first mode so that's
the classical traditional kinds of low

00:02:31.060 --> 00:02:31.070
the classical traditional kinds of low
 

00:02:31.070 --> 00:02:34.180
the classical traditional kinds of low
style so just to give you a refresher of

00:02:34.180 --> 00:02:34.190
style so just to give you a refresher of
 

00:02:34.190 --> 00:02:36.010
style so just to give you a refresher of
how to use tensorflow to define a simple

00:02:36.010 --> 00:02:36.020
how to use tensorflow to define a simple
 

00:02:36.020 --> 00:02:38.950
how to use tensorflow to define a simple
model you import tensorflow stf and then

00:02:38.950 --> 00:02:38.960
model you import tensorflow stf and then
 

00:02:38.960 --> 00:02:40.780
model you import tensorflow stf and then
you define some constants or maybe some

00:02:40.780 --> 00:02:40.790
you define some constants or maybe some
 

00:02:40.790 --> 00:02:42.820
you define some constants or maybe some
variables as inputs and then you write a

00:02:42.820 --> 00:02:42.830
variables as inputs and then you write a
 

00:02:42.830 --> 00:02:44.950
variables as inputs and then you write a
line to say like you want to multiply x

00:02:44.950 --> 00:02:44.960
line to say like you want to multiply x
 

00:02:44.960 --> 00:02:48.070
line to say like you want to multiply x
MW and you want to add the result of the

00:02:48.070 --> 00:02:48.080
MW and you want to add the result of the
 

00:02:48.080 --> 00:02:50.410
MW and you want to add the result of the
multiplication to two another thing B

00:02:50.410 --> 00:02:50.420
multiplication to two another thing B
 

00:02:50.420 --> 00:02:52.270
multiplication to two another thing B
right so you can think of this as a very

00:02:52.270 --> 00:02:52.280
right so you can think of this as a very
 

00:02:52.280 --> 00:02:53.950
right so you can think of this as a very
simple linear regression model if you

00:02:53.950 --> 00:02:53.960
simple linear regression model if you
 

00:02:53.960 --> 00:02:56.230
simple linear regression model if you
will now the important thing here is

00:02:56.230 --> 00:02:56.240
will now the important thing here is
 

00:02:56.240 --> 00:02:59.560
will now the important thing here is
when this line is executed it's actually

00:02:59.560 --> 00:02:59.570
when this line is executed it's actually
 

00:02:59.570 --> 00:03:02.380
when this line is executed it's actually
not doing the computation so the

00:03:02.380 --> 00:03:02.390
not doing the computation so the
 

00:03:02.390 --> 00:03:04.210
not doing the computation so the
multiplication will not happen at this

00:03:04.210 --> 00:03:04.220
multiplication will not happen at this
 

00:03:04.220 --> 00:03:06.250
multiplication will not happen at this
point if you print the results of this

00:03:06.250 --> 00:03:06.260
point if you print the results of this
 

00:03:06.260 --> 00:03:08.680
point if you print the results of this
line why there you will see it's not 40

00:03:08.680 --> 00:03:08.690
line why there you will see it's not 40
 

00:03:08.690 --> 00:03:10.930
line why there you will see it's not 40
it's not 10 times 4 equals 40 instead

00:03:10.930 --> 00:03:10.940
it's not 10 times 4 equals 40 instead
 

00:03:10.940 --> 00:03:13.420
it's not 10 times 4 equals 40 instead
it's um it's like a abstract symbolic

00:03:13.420 --> 00:03:13.430
it's um it's like a abstract symbolic
 

00:03:13.430 --> 00:03:16.090
it's um it's like a abstract symbolic
thing so it's called a tensor and it

00:03:16.090 --> 00:03:16.100
thing so it's called a tensor and it
 

00:03:16.100 --> 00:03:17.740
thing so it's called a tensor and it
knows what kind of operation it needs to

00:03:17.740 --> 00:03:17.750
knows what kind of operation it needs to
 

00:03:17.750 --> 00:03:19.120
knows what kind of operation it needs to
do when it's actually executed in the

00:03:19.120 --> 00:03:19.130
do when it's actually executed in the
 

00:03:19.130 --> 00:03:22.570
do when it's actually executed in the
future so mall is that operation it also

00:03:22.570 --> 00:03:22.580
future so mall is that operation it also
 

00:03:22.580 --> 00:03:24.490
future so mall is that operation it also
needs some information about it also

00:03:24.490 --> 00:03:24.500
needs some information about it also
 

00:03:24.500 --> 00:03:26.080
needs some information about it also
knows information about like what its

00:03:26.080 --> 00:03:26.090
knows information about like what its
 

00:03:26.090 --> 00:03:28.600
knows information about like what its
dependencies are which are X and W in

00:03:28.600 --> 00:03:28.610
dependencies are which are X and W in
 

00:03:28.610 --> 00:03:31.060
dependencies are which are X and W in
this case but it's not shown in the

00:03:31.060 --> 00:03:31.070
this case but it's not shown in the
 

00:03:31.070 --> 00:03:33.370
this case but it's not shown in the
printed message here and likewise when

00:03:33.370 --> 00:03:33.380
printed message here and likewise when
 

00:03:33.380 --> 00:03:35.860
printed message here and likewise when
you do a TV ad when that line of code is

00:03:35.860 --> 00:03:35.870
you do a TV ad when that line of code is
 

00:03:35.870 --> 00:03:37.930
you do a TV ad when that line of code is
executed the addition will not happen is

00:03:37.930 --> 00:03:37.940
executed the addition will not happen is
 

00:03:37.940 --> 00:03:38.980
executed the addition will not happen is
going to happen later

00:03:38.980 --> 00:03:38.990
going to happen later
 

00:03:38.990 --> 00:03:42.280
going to happen later
so by later I mean a case the point at

00:03:42.280 --> 00:03:42.290
so by later I mean a case the point at
 

00:03:42.290 --> 00:03:44.530
so by later I mean a case the point at
which you create a session by calling TF

00:03:44.530 --> 00:03:44.540
which you create a session by calling TF
 

00:03:44.540 --> 00:03:47.020
which you create a session by calling TF
dot session and when TF duck session is

00:03:47.020 --> 00:03:47.030
dot session and when TF duck session is
 

00:03:47.030 --> 00:03:49.090
dot session and when TF duck session is
created it will basically automatically

00:03:49.090 --> 00:03:49.100
created it will basically automatically
 

00:03:49.100 --> 00:03:50.470
created it will basically automatically
pull in the graph you have already

00:03:50.470 --> 00:03:50.480
pull in the graph you have already
 

00:03:50.480 --> 00:03:52.810
pull in the graph you have already
already built in the previous lines of

00:03:52.810 --> 00:03:52.820
already built in the previous lines of
 

00:03:52.820 --> 00:03:55.270
already built in the previous lines of
code and then you tell the session like

00:03:55.270 --> 00:03:55.280
code and then you tell the session like
 

00:03:55.280 --> 00:03:57.520
code and then you tell the session like
which tensor which abstract symbol in

00:03:57.520 --> 00:03:57.530
which tensor which abstract symbol in
 

00:03:57.530 --> 00:03:59.200
which tensor which abstract symbol in
the graph you want to execute and then

00:03:59.200 --> 00:03:59.210
the graph you want to execute and then
 

00:03:59.210 --> 00:04:01.000
the graph you want to execute and then
it's going to basically analyze the

00:04:01.000 --> 00:04:01.010
it's going to basically analyze the
 

00:04:01.010 --> 00:04:03.040
it's going to basically analyze the
structure of the graph sort out all the

00:04:03.040 --> 00:04:03.050
structure of the graph sort out all the
 

00:04:03.050 --> 00:04:05.170
structure of the graph sort out all the
dependencies and topple logically

00:04:05.170 --> 00:04:05.180
dependencies and topple logically
 

00:04:05.180 --> 00:04:07.120
dependencies and topple logically
execute all the nodes in the graph to do

00:04:07.120 --> 00:04:07.130
execute all the nodes in the graph to do
 

00:04:07.130 --> 00:04:08.470
execute all the nodes in the graph to do
the multiplication first and undo the

00:04:08.470 --> 00:04:08.480
the multiplication first and undo the
 

00:04:08.480 --> 00:04:10.080
the multiplication first and undo the
addition next and then it's going to

00:04:10.080 --> 00:04:10.090
addition next and then it's going to
 

00:04:10.090 --> 00:04:12.810
addition next and then it's going to
give you the final result so which is 42

00:04:12.810 --> 00:04:12.820
give you the final result so which is 42
 

00:04:12.820 --> 00:04:15.160
give you the final result so which is 42
so you can think of TF da station as a

00:04:15.160 --> 00:04:15.170
so you can think of TF da station as a
 

00:04:15.170 --> 00:04:17.950
so you can think of TF da station as a
ng so it's going to run the model on CPU

00:04:17.950 --> 00:04:17.960
ng so it's going to run the model on CPU
 

00:04:17.960 --> 00:04:19.690
ng so it's going to run the model on CPU
if you only have a CPU it's going to run

00:04:19.690 --> 00:04:19.700
if you only have a CPU it's going to run
 

00:04:19.700 --> 00:04:25.230
if you only have a CPU it's going to run
the model on GPU if you have a GPU now

00:04:25.230 --> 00:04:25.240
the model on GPU if you have a GPU now
 

00:04:25.240 --> 00:04:28.659
the model on GPU if you have a GPU now
obviously um this paradigm of defining

00:04:28.659 --> 00:04:28.669
obviously um this paradigm of defining
 

00:04:28.669 --> 00:04:29.800
obviously um this paradigm of defining
our motto is not a most

00:04:29.800 --> 00:04:29.810
our motto is not a most
 

00:04:29.810 --> 00:04:31.450
our motto is not a most
straightforward because those lines of

00:04:31.450 --> 00:04:31.460
straightforward because those lines of
 

00:04:31.460 --> 00:04:32.980
straightforward because those lines of
codes that look like doing competition

00:04:32.980 --> 00:04:32.990
codes that look like doing competition
 

00:04:32.990 --> 00:04:35.710
codes that look like doing competition
is not doing any actual competition and

00:04:35.710 --> 00:04:35.720
is not doing any actual competition and
 

00:04:35.720 --> 00:04:37.750
is not doing any actual competition and
you need to learn a new API card here

00:04:37.750 --> 00:04:37.760
you need to learn a new API card here
 

00:04:37.760 --> 00:04:40.120
you need to learn a new API card here
that session so why does tensorflow do

00:04:40.120 --> 00:04:40.130
that session so why does tensorflow do
 

00:04:40.130 --> 00:04:43.300
that session so why does tensorflow do
it this way so obviously it's because

00:04:43.300 --> 00:04:43.310
it this way so obviously it's because
 

00:04:43.310 --> 00:04:46.690
it this way so obviously it's because
there are some advantages you can get so

00:04:46.690 --> 00:04:46.700
there are some advantages you can get so
 

00:04:46.700 --> 00:04:48.280
there are some advantages you can get so
the first advantage is because the model

00:04:48.280 --> 00:04:48.290
the first advantage is because the model
 

00:04:48.290 --> 00:04:50.200
the first advantage is because the model
is a data structure it's relatively easy

00:04:50.200 --> 00:04:50.210
is a data structure it's relatively easy
 

00:04:50.210 --> 00:04:52.870
is a data structure it's relatively easy
to serialize this and then deserialize

00:04:52.870 --> 00:04:52.880
to serialize this and then deserialize
 

00:04:52.880 --> 00:04:54.790
to serialize this and then deserialize
this somewhere else you can train your

00:04:54.790 --> 00:04:54.800
this somewhere else you can train your
 

00:04:54.800 --> 00:04:56.620
this somewhere else you can train your
model and you can load your model onto

00:04:56.620 --> 00:04:56.630
model and you can load your model onto
 

00:04:56.630 --> 00:04:58.810
model and you can load your model onto
some kind of other devices like mobile

00:04:58.810 --> 00:04:58.820
some kind of other devices like mobile
 

00:04:58.820 --> 00:05:00.790
some kind of other devices like mobile
devices or embedded devices like

00:05:00.790 --> 00:05:00.800
devices or embedded devices like
 

00:05:00.800 --> 00:05:04.690
devices or embedded devices like
raspberry pie or car or robot and you

00:05:04.690 --> 00:05:04.700
raspberry pie or car or robot and you
 

00:05:04.700 --> 00:05:07.060
raspberry pie or car or robot and you
can also serialize the model and then

00:05:07.060 --> 00:05:07.070
can also serialize the model and then
 

00:05:07.070 --> 00:05:09.040
can also serialize the model and then
load the model on like a faster hardware

00:05:09.040 --> 00:05:09.050
load the model on like a faster hardware
 

00:05:09.050 --> 00:05:10.590
load the model on like a faster hardware
like Google's TPU

00:05:10.590 --> 00:05:10.600
like Google's TPU
 

00:05:10.600 --> 00:05:13.210
like Google's TPU
so these things are hard hard to do if

00:05:13.210 --> 00:05:13.220
so these things are hard hard to do if
 

00:05:13.220 --> 00:05:14.650
so these things are hard hard to do if
your model is a Python right if your

00:05:14.650 --> 00:05:14.660
your model is a Python right if your
 

00:05:14.660 --> 00:05:16.420
your model is a Python right if your
model has a Python program because those

00:05:16.420 --> 00:05:16.430
model has a Python program because those
 

00:05:16.430 --> 00:05:18.010
model has a Python program because those
devices may not have Python and running

00:05:18.010 --> 00:05:18.020
devices may not have Python and running
 

00:05:18.020 --> 00:05:20.560
devices may not have Python and running
on them and even if those devices have

00:05:20.560 --> 00:05:20.570
on them and even if those devices have
 

00:05:20.570 --> 00:05:21.940
on them and even if those devices have
Python running on them that's probably

00:05:21.940 --> 00:05:21.950
Python running on them that's probably
 

00:05:21.950 --> 00:05:24.490
Python running on them that's probably
not what you want to use because python

00:05:24.490 --> 00:05:24.500
not what you want to use because python
 

00:05:24.500 --> 00:05:28.690
not what you want to use because python
is slow sometimes so I have those links

00:05:28.690 --> 00:05:28.700
is slow sometimes so I have those links
 

00:05:28.700 --> 00:05:31.210
is slow sometimes so I have those links
here in the slide so I'm going to send

00:05:31.210 --> 00:05:31.220
here in the slide so I'm going to send
 

00:05:31.220 --> 00:05:32.830
here in the slide so I'm going to send
those flies to the course of own answers

00:05:32.830 --> 00:05:32.840
those flies to the course of own answers
 

00:05:32.840 --> 00:05:34.659
those flies to the course of own answers
and you can click on those links if

00:05:34.659 --> 00:05:34.669
and you can click on those links if
 

00:05:34.669 --> 00:05:36.100
and you can click on those links if
you're interested in any of those topics

00:05:36.100 --> 00:05:36.110
you're interested in any of those topics
 

00:05:36.110 --> 00:05:37.930
you're interested in any of those topics
like deployments on mobile devices and

00:05:37.930 --> 00:05:37.940
like deployments on mobile devices and
 

00:05:37.940 --> 00:05:43.840
like deployments on mobile devices and
so on so the next advantage is because

00:05:43.840 --> 00:05:43.850
so on so the next advantage is because
 

00:05:43.850 --> 00:05:45.340
so on so the next advantage is because
your model is a data structure you are

00:05:45.340 --> 00:05:45.350
your model is a data structure you are
 

00:05:45.350 --> 00:05:46.930
your model is a data structure you are
not tied down to the language in which

00:05:46.930 --> 00:05:46.940
not tied down to the language in which
 

00:05:46.940 --> 00:05:49.240
not tied down to the language in which
the model is defined so nowadays most

00:05:49.240 --> 00:05:49.250
the model is defined so nowadays most
 

00:05:49.250 --> 00:05:50.440
the model is defined so nowadays most
machine learning models are written in

00:05:50.440 --> 00:05:50.450
machine learning models are written in
 

00:05:50.450 --> 00:05:52.960
machine learning models are written in
Python but maybe your application server

00:05:52.960 --> 00:05:52.970
Python but maybe your application server
 

00:05:52.970 --> 00:05:54.850
Python but maybe your application server
may be a web server is running Java or

00:05:54.850 --> 00:05:54.860
may be a web server is running Java or
 

00:05:54.860 --> 00:05:57.130
may be a web server is running Java or
C++ and you don't want to really write

00:05:57.130 --> 00:05:57.140
C++ and you don't want to really write
 

00:05:57.140 --> 00:06:00.100
C++ and you don't want to really write
the whole stack in in Python just to be

00:06:00.100 --> 00:06:00.110
the whole stack in in Python just to be
 

00:06:00.110 --> 00:06:01.420
the whole stack in in Python just to be
able to add some machine learning to

00:06:01.420 --> 00:06:01.430
able to add some machine learning to
 

00:06:01.430 --> 00:06:04.029
able to add some machine learning to
your stack right so if a model is a data

00:06:04.029 --> 00:06:04.039
your stack right so if a model is a data
 

00:06:04.039 --> 00:06:05.469
your stack right so if a model is a data
structure that you can save the model

00:06:05.469 --> 00:06:05.479
structure that you can save the model
 

00:06:05.479 --> 00:06:06.940
structure that you can save the model
after training and you can load it into

00:06:06.940 --> 00:06:06.950
after training and you can load it into
 

00:06:06.950 --> 00:06:09.610
after training and you can load it into
Java or C++ or C sharp or any of the

00:06:09.610 --> 00:06:09.620
Java or C++ or C sharp or any of the
 

00:06:09.620 --> 00:06:11.860
Java or C++ or C sharp or any of the
some supporting languages and you will

00:06:11.860 --> 00:06:11.870
some supporting languages and you will
 

00:06:11.870 --> 00:06:14.050
some supporting languages and you will
be ready to serve the train model from

00:06:14.050 --> 00:06:14.060
be ready to serve the train model from
 

00:06:14.060 --> 00:06:15.820
be ready to serve the train model from
your web server or application server

00:06:15.820 --> 00:06:15.830
your web server or application server
 

00:06:15.830 --> 00:06:19.240
your web server or application server
and the other nice thing about

00:06:19.240 --> 00:06:19.250
and the other nice thing about
 

00:06:19.250 --> 00:06:21.670
and the other nice thing about
representing data as a the model as a

00:06:21.670 --> 00:06:21.680
representing data as a the model as a
 

00:06:21.680 --> 00:06:24.250
representing data as a the model as a
data structure is you can distribute the

00:06:24.250 --> 00:06:24.260
data structure is you can distribute the
 

00:06:24.260 --> 00:06:25.870
data structure is you can distribute the
model very easily onto a number of

00:06:25.870 --> 00:06:25.880
model very easily onto a number of
 

00:06:25.880 --> 00:06:27.760
model very easily onto a number of
machines called workers and those

00:06:27.760 --> 00:06:27.770
machines called workers and those
 

00:06:27.770 --> 00:06:29.680
machines called workers and those
workers will basically use the same

00:06:29.680 --> 00:06:29.690
workers will basically use the same
 

00:06:29.690 --> 00:06:31.360
workers will basically use the same
graph and they're going to do the exact

00:06:31.360 --> 00:06:31.370
graph and they're going to do the exact
 

00:06:31.370 --> 00:06:34.510
graph and they're going to do the exact
the same competition but they're going

00:06:34.510 --> 00:06:34.520
the same competition but they're going
 

00:06:34.520 --> 00:06:35.980
the same competition but they're going
to do it on different slices of the

00:06:35.980 --> 00:06:35.990
to do it on different slices of the
 

00:06:35.990 --> 00:06:37.990
to do it on different slices of the
training data so this kind of training

00:06:37.990 --> 00:06:38.000
training data so this kind of training
 

00:06:38.000 --> 00:06:40.779
training data so this kind of training
in a distributed way is very important

00:06:40.779 --> 00:06:40.789
in a distributed way is very important
 

00:06:40.789 --> 00:06:43.140
in a distributed way is very important
for cases in which you need to train

00:06:43.140 --> 00:06:43.150
for cases in which you need to train
 

00:06:43.150 --> 00:06:45.900
for cases in which you need to train
a very large amount of data quickly the

00:06:45.900 --> 00:06:45.910
a very large amount of data quickly the
 

00:06:45.910 --> 00:06:47.310
a very large amount of data quickly the
kind of problem that Google sometimes

00:06:47.310 --> 00:06:47.320
kind of problem that Google sometimes
 

00:06:47.320 --> 00:06:51.570
kind of problem that Google sometimes
has to deal with so of course you have

00:06:51.570 --> 00:06:51.580
has to deal with so of course you have
 

00:06:51.580 --> 00:06:53.670
has to deal with so of course you have
to slightly modify your model graph so

00:06:53.670 --> 00:06:53.680
to slightly modify your model graph so
 

00:06:53.680 --> 00:06:55.440
to slightly modify your model graph so
that the shared things like the weights

00:06:55.440 --> 00:06:55.450
that the shared things like the weights
 

00:06:55.450 --> 00:06:57.540
that the shared things like the weights
variables in the model are shared on a

00:06:57.540 --> 00:06:57.550
variables in the model are shared on a
 

00:06:57.550 --> 00:07:00.900
variables in the model are shared on a
server called parameter server here but

00:07:00.900 --> 00:07:00.910
server called parameter server here but
 

00:07:00.910 --> 00:07:02.700
server called parameter server here but
that's basically distributed training

00:07:02.700 --> 00:07:02.710
that's basically distributed training
 

00:07:02.710 --> 00:07:04.380
that's basically distributed training
intensive flow in a nutshell

00:07:04.380 --> 00:07:04.390
intensive flow in a nutshell
 

00:07:04.390 --> 00:07:05.880
intensive flow in a nutshell
so again if you're interested you can

00:07:05.880 --> 00:07:05.890
so again if you're interested you can
 

00:07:05.890 --> 00:07:07.620
so again if you're interested you can
look at the slide and can click that

00:07:07.620 --> 00:07:07.630
look at the slide and can click that
 

00:07:07.630 --> 00:07:09.810
look at the slide and can click that
link to learn more about distributive

00:07:09.810 --> 00:07:09.820
link to learn more about distributive
 

00:07:09.820 --> 00:07:14.840
link to learn more about distributive
training any questions so far

00:07:14.840 --> 00:07:14.850
 

00:07:14.850 --> 00:07:19.920
okay okay so also because you are

00:07:19.920 --> 00:07:19.930
okay okay so also because you are
 

00:07:19.930 --> 00:07:21.210
okay okay so also because you are
representing your model as a data

00:07:21.210 --> 00:07:21.220
representing your model as a data
 

00:07:21.220 --> 00:07:23.670
representing your model as a data
structure you're not limited by the

00:07:23.670 --> 00:07:23.680
structure you're not limited by the
 

00:07:23.680 --> 00:07:25.770
structure you're not limited by the
speed or the concurrency of the language

00:07:25.770 --> 00:07:25.780
speed or the concurrency of the language
 

00:07:25.780 --> 00:07:27.360
speed or the concurrency of the language
in which the model is defined we know

00:07:27.360 --> 00:07:27.370
in which the model is defined we know
 

00:07:27.370 --> 00:07:28.950
in which the model is defined we know
that um python is slow sometimes and

00:07:28.950 --> 00:07:28.960
that um python is slow sometimes and
 

00:07:28.960 --> 00:07:31.560
that um python is slow sometimes and
even if you try to make python or

00:07:31.560 --> 00:07:31.570
even if you try to make python or
 

00:07:31.570 --> 00:07:33.900
even if you try to make python or
parallel parallel as by writing

00:07:33.900 --> 00:07:33.910
parallel parallel as by writing
 

00:07:33.910 --> 00:07:35.700
parallel parallel as by writing
multi-threading you will run into the

00:07:35.700 --> 00:07:35.710
multi-threading you will run into the
 

00:07:35.710 --> 00:07:37.140
multi-threading you will run into the
issue called python global interpreter

00:07:37.140 --> 00:07:37.150
issue called python global interpreter
 

00:07:37.150 --> 00:07:39.390
issue called python global interpreter
lock and that will slow your model down

00:07:39.390 --> 00:07:39.400
lock and that will slow your model down
 

00:07:39.400 --> 00:07:41.760
lock and that will slow your model down
especially for the kind of competition

00:07:41.760 --> 00:07:41.770
especially for the kind of competition
 

00:07:41.770 --> 00:07:43.310
especially for the kind of competition
that a deep learning model needs to do

00:07:43.310 --> 00:07:43.320
that a deep learning model needs to do
 

00:07:43.320 --> 00:07:45.390
that a deep learning model needs to do
so the way in which we solve this

00:07:45.390 --> 00:07:45.400
so the way in which we solve this
 

00:07:45.400 --> 00:07:48.260
so the way in which we solve this
problem in symbolic execution is by

00:07:48.260 --> 00:07:48.270
problem in symbolic execution is by
 

00:07:48.270 --> 00:07:50.340
problem in symbolic execution is by
sending the model as a data structure

00:07:50.340 --> 00:07:50.350
sending the model as a data structure
 

00:07:50.350 --> 00:07:52.950
sending the model as a data structure
from the layer of Python into C++ so

00:07:52.950 --> 00:07:52.960
from the layer of Python into C++ so
 

00:07:52.960 --> 00:07:55.860
from the layer of Python into C++ so
there are other layer of C++ you can use

00:07:55.860 --> 00:07:55.870
there are other layer of C++ you can use
 

00:07:55.870 --> 00:07:58.320
there are other layer of C++ you can use
to concurrency you can fully parallel

00:07:58.320 --> 00:07:58.330
to concurrency you can fully parallel
 

00:07:58.330 --> 00:08:00.000
to concurrency you can fully parallel
those things and that can benefits the

00:08:00.000 --> 00:08:00.010
those things and that can benefits the
 

00:08:00.010 --> 00:08:03.570
those things and that can benefits the
speed of the model okay so obviously

00:08:03.570 --> 00:08:03.580
speed of the model okay so obviously
 

00:08:03.580 --> 00:08:05.820
speed of the model okay so obviously
there are all those advantages but there

00:08:05.820 --> 00:08:05.830
there are all those advantages but there
 

00:08:05.830 --> 00:08:08.220
there are all those advantages but there
are also those like um shortcomings of

00:08:08.220 --> 00:08:08.230
are also those like um shortcomings of
 

00:08:08.230 --> 00:08:10.020
are also those like um shortcomings of
symbolic execution for example it's less

00:08:10.020 --> 00:08:10.030
symbolic execution for example it's less
 

00:08:10.030 --> 00:08:12.390
symbolic execution for example it's less
intuitive it's harder to learn so you

00:08:12.390 --> 00:08:12.400
intuitive it's harder to learn so you
 

00:08:12.400 --> 00:08:14.490
intuitive it's harder to learn so you
need to spend some time getting used to

00:08:14.490 --> 00:08:14.500
need to spend some time getting used to
 

00:08:14.500 --> 00:08:16.950
need to spend some time getting used to
the idea of you you you're defining our

00:08:16.950 --> 00:08:16.960
the idea of you you you're defining our
 

00:08:16.960 --> 00:08:18.480
the idea of you you you're defining our
model first and then run the model later

00:08:18.480 --> 00:08:18.490
model first and then run the model later
 

00:08:18.490 --> 00:08:21.210
model first and then run the model later
with TF data session and it's harder to

00:08:21.210 --> 00:08:21.220
with TF data session and it's harder to
 

00:08:21.220 --> 00:08:23.670
with TF data session and it's harder to
debug when your model goes wrong that's

00:08:23.670 --> 00:08:23.680
debug when your model goes wrong that's
 

00:08:23.680 --> 00:08:25.380
debug when your model goes wrong that's
because everything every actual

00:08:25.380 --> 00:08:25.390
because everything every actual
 

00:08:25.390 --> 00:08:27.090
because everything every actual
computation happens inside the TF dot

00:08:27.090 --> 00:08:27.100
computation happens inside the TF dot
 

00:08:27.100 --> 00:08:28.440
computation happens inside the TF dot
session and that's a single line of

00:08:28.440 --> 00:08:28.450
session and that's a single line of
 

00:08:28.450 --> 00:08:30.960
session and that's a single line of
Python code calling out to C++ so you

00:08:30.960 --> 00:08:30.970
Python code calling out to C++ so you
 

00:08:30.970 --> 00:08:33.480
Python code calling out to C++ so you
can't use usual kinds of Python debugger

00:08:33.480 --> 00:08:33.490
can't use usual kinds of Python debugger
 

00:08:33.490 --> 00:08:35.460
can't use usual kinds of Python debugger
to debug that but I'm going to show you

00:08:35.460 --> 00:08:35.470
to debug that but I'm going to show you
 

00:08:35.470 --> 00:08:36.660
to debug that but I'm going to show you
that they're actually very good tools

00:08:36.660 --> 00:08:36.670
that they're actually very good tools
 

00:08:36.670 --> 00:08:38.340
that they're actually very good tools
intensive flow that you can use to debug

00:08:38.340 --> 00:08:38.350
intensive flow that you can use to debug
 

00:08:38.350 --> 00:08:40.610
intensive flow that you can use to debug
things that happen in TF that session

00:08:40.610 --> 00:08:40.620
things that happen in TF that session
 

00:08:40.620 --> 00:08:45.120
things that happen in TF that session
and another shortcoming of symbolic

00:08:45.120 --> 00:08:45.130
and another shortcoming of symbolic
 

00:08:45.130 --> 00:08:46.620
and another shortcoming of symbolic
execution is that it's harder to write

00:08:46.620 --> 00:08:46.630
execution is that it's harder to write
 

00:08:46.630 --> 00:08:48.510
execution is that it's harder to write
control flow structures so by that I

00:08:48.510 --> 00:08:48.520
control flow structures so by that I
 

00:08:48.520 --> 00:08:50.910
control flow structures so by that I
mean structures like looping over a

00:08:50.910 --> 00:08:50.920
mean structures like looping over a
 

00:08:50.920 --> 00:08:53.700
mean structures like looping over a
number of things or if-else branches so

00:08:53.700 --> 00:08:53.710
number of things or if-else branches so
 

00:08:53.710 --> 00:08:54.720
number of things or if-else branches so
the kind of thing that we encounter

00:08:54.720 --> 00:08:54.730
the kind of thing that we encounter
 

00:08:54.730 --> 00:08:56.370
the kind of thing that we encounter
every day in programming languages but

00:08:56.370 --> 00:08:56.380
every day in programming languages but
 

00:08:56.380 --> 00:08:58.020
every day in programming languages but
some machine learning models also need

00:08:58.020 --> 00:08:58.030
some machine learning models also need
 

00:08:58.030 --> 00:08:59.460
some machine learning models also need
to do that right so like recurrent

00:08:59.460 --> 00:08:59.470
to do that right so like recurrent
 

00:08:59.470 --> 00:09:01.110
to do that right so like recurrent
neural networks need to loop over things

00:09:01.110 --> 00:09:01.120
neural networks need to loop over things
 

00:09:01.120 --> 00:09:04.470
neural networks need to loop over things
and some kind of like fancy um dynamic

00:09:04.470 --> 00:09:04.480
and some kind of like fancy um dynamic
 

00:09:04.480 --> 00:09:06.330
and some kind of like fancy um dynamic
models need to do if else branches and

00:09:06.330 --> 00:09:06.340
models need to do if else branches and
 

00:09:06.340 --> 00:09:08.190
models need to do if else branches and
so on I'm also going to show some slides

00:09:08.190 --> 00:09:08.200
so on I'm also going to show some slides
 

00:09:08.200 --> 00:09:11.190
so on I'm also going to show some slides
to show those concrete examples so it's

00:09:11.190 --> 00:09:11.200
to show those concrete examples so it's
 

00:09:11.200 --> 00:09:13.290
to show those concrete examples so it's
very hard to it's sometimes very hard to

00:09:13.290 --> 00:09:13.300
very hard to it's sometimes very hard to
 

00:09:13.300 --> 00:09:14.460
very hard to it's sometimes very hard to
write that kind of control flow

00:09:14.460 --> 00:09:14.470
write that kind of control flow
 

00:09:14.470 --> 00:09:16.680
write that kind of control flow
structures in symbolic execution but

00:09:16.680 --> 00:09:16.690
structures in symbolic execution but
 

00:09:16.690 --> 00:09:20.600
structures in symbolic execution but
it's much easier in ego execution so

00:09:20.600 --> 00:09:20.610
it's much easier in ego execution so
 

00:09:20.610 --> 00:09:23.520
it's much easier in ego execution so
with eager execution your program can be

00:09:23.520 --> 00:09:23.530
with eager execution your program can be
 

00:09:23.530 --> 00:09:25.140
with eager execution your program can be
more pythonic and it's easier to learn

00:09:25.140 --> 00:09:25.150
more pythonic and it's easier to learn
 

00:09:25.150 --> 00:09:27.090
more pythonic and it's easier to learn
and easier to read so here's an example

00:09:27.090 --> 00:09:27.100
and easier to read so here's an example
 

00:09:27.100 --> 00:09:29.280
and easier to read so here's an example
so on the Left you're seeing the same

00:09:29.280 --> 00:09:29.290
so on the Left you're seeing the same
 

00:09:29.290 --> 00:09:31.410
so on the Left you're seeing the same
code as before so we are using the

00:09:31.410 --> 00:09:31.420
code as before so we are using the
 

00:09:31.420 --> 00:09:33.510
code as before so we are using the
default symbolic execution of tensorflow

00:09:33.510 --> 00:09:33.520
default symbolic execution of tensorflow
 

00:09:33.520 --> 00:09:36.750
default symbolic execution of tensorflow
no now how do we switch to the new eager

00:09:36.750 --> 00:09:36.760
no now how do we switch to the new eager
 

00:09:36.760 --> 00:09:38.520
no now how do we switch to the new eager
execution so you just add two lines of

00:09:38.520 --> 00:09:38.530
execution so you just add two lines of
 

00:09:38.530 --> 00:09:40.950
execution so you just add two lines of
code you imports the eager module and

00:09:40.950 --> 00:09:40.960
code you imports the eager module and
 

00:09:40.960 --> 00:09:42.720
code you imports the eager module and
then you call a method called enable

00:09:42.720 --> 00:09:42.730
then you call a method called enable
 

00:09:42.730 --> 00:09:44.430
then you call a method called enable
eager execution and you don't have to

00:09:44.430 --> 00:09:44.440
eager execution and you don't have to
 

00:09:44.440 --> 00:09:45.990
eager execution and you don't have to
make any other change to your program in

00:09:45.990 --> 00:09:46.000
make any other change to your program in
 

00:09:46.000 --> 00:09:48.690
make any other change to your program in
this case but you will because of these

00:09:48.690 --> 00:09:48.700
this case but you will because of these
 

00:09:48.700 --> 00:09:50.730
this case but you will because of these
few lines you changed the semantics of

00:09:50.730 --> 00:09:50.740
few lines you changed the semantics of
 

00:09:50.740 --> 00:09:53.220
few lines you changed the semantics of
these two lines multiply and add so now

00:09:53.220 --> 00:09:53.230
these two lines multiply and add so now
 

00:09:53.230 --> 00:09:55.320
these two lines multiply and add so now
instead of building a graph this line is

00:09:55.320 --> 00:09:55.330
instead of building a graph this line is
 

00:09:55.330 --> 00:09:57.210
instead of building a graph this line is
actually doing the multiplication of ten

00:09:57.210 --> 00:09:57.220
actually doing the multiplication of ten
 

00:09:57.220 --> 00:09:58.800
actually doing the multiplication of ten
four and if you print while you will see

00:09:58.800 --> 00:09:58.810
four and if you print while you will see
 

00:09:58.810 --> 00:10:01.350
four and if you print while you will see
the value and if you print a value of Z

00:10:01.350 --> 00:10:01.360
the value and if you print a value of Z
 

00:10:01.360 --> 00:10:02.520
the value and if you print a value of Z
you will also see the value so

00:10:02.520 --> 00:10:02.530
you will also see the value so
 

00:10:02.530 --> 00:10:05.070
you will also see the value so
everything is like a flatter and easier

00:10:05.070 --> 00:10:05.080
everything is like a flatter and easier
 

00:10:05.080 --> 00:10:09.780
everything is like a flatter and easier
to understand now as I mentioned before

00:10:09.780 --> 00:10:09.790
to understand now as I mentioned before
 

00:10:09.790 --> 00:10:12.060
to understand now as I mentioned before
ego mode also makes it easier to write

00:10:12.060 --> 00:10:12.070
ego mode also makes it easier to write
 

00:10:12.070 --> 00:10:15.900
ego mode also makes it easier to write
control flow dependency and dynamic

00:10:15.900 --> 00:10:15.910
control flow dependency and dynamic
 

00:10:15.910 --> 00:10:18.960
control flow dependency and dynamic
models so here's an example so suppose

00:10:18.960 --> 00:10:18.970
models so here's an example so suppose
 

00:10:18.970 --> 00:10:20.550
models so here's an example so suppose
you want to write a recurrent neural

00:10:20.550 --> 00:10:20.560
you want to write a recurrent neural
 

00:10:20.560 --> 00:10:21.960
you want to write a recurrent neural
network which I think you have seen in

00:10:21.960 --> 00:10:21.970
network which I think you have seen in
 

00:10:21.970 --> 00:10:23.730
network which I think you have seen in
previous parts of the lecture before in

00:10:23.730 --> 00:10:23.740
previous parts of the lecture before in
 

00:10:23.740 --> 00:10:25.860
previous parts of the lecture before in
in the default mode of tensorflow

00:10:25.860 --> 00:10:25.870
in the default mode of tensorflow
 

00:10:25.870 --> 00:10:27.630
in the default mode of tensorflow
here is about the amount of code you

00:10:27.630 --> 00:10:27.640
here is about the amount of code you
 

00:10:27.640 --> 00:10:30.150
here is about the amount of code you
need to write so you cannot use the

00:10:30.150 --> 00:10:30.160
need to write so you cannot use the
 

00:10:30.160 --> 00:10:32.970
need to write so you cannot use the
default native for loop or while loop in

00:10:32.970 --> 00:10:32.980
default native for loop or while loop in
 

00:10:32.980 --> 00:10:34.830
default native for loop or while loop in
Python you have to use the tensorflow

00:10:34.830 --> 00:10:34.840
Python you have to use the tensorflow
 

00:10:34.840 --> 00:10:37.890
Python you have to use the tensorflow
special while loop and in order to use

00:10:37.890 --> 00:10:37.900
special while loop and in order to use
 

00:10:37.900 --> 00:10:39.990
special while loop and in order to use
it you have to define two functions one

00:10:39.990 --> 00:10:40.000
it you have to define two functions one
 

00:10:40.000 --> 00:10:41.430
it you have to define two functions one
for the termination condition of the

00:10:41.430 --> 00:10:41.440
for the termination condition of the
 

00:10:41.440 --> 00:10:43.770
for the termination condition of the
loop and one for the body of the loop

00:10:43.770 --> 00:10:43.780
loop and one for the body of the loop
 

00:10:43.780 --> 00:10:45.840
loop and one for the body of the loop
and then you need to feed those two

00:10:45.840 --> 00:10:45.850
and then you need to feed those two
 

00:10:45.850 --> 00:10:48.000
and then you need to feed those two
functions into in the while loop and get

00:10:48.000 --> 00:10:48.010
functions into in the while loop and get
 

00:10:48.010 --> 00:10:49.890
functions into in the while loop and get
tensors back and remember those tensors

00:10:49.890 --> 00:10:49.900
tensors back and remember those tensors
 

00:10:49.900 --> 00:10:52.140
tensors back and remember those tensors
are not actual values you have to send

00:10:52.140 --> 00:10:52.150
are not actual values you have to send
 

00:10:52.150 --> 00:10:53.820
are not actual values you have to send
those tensors into your session don't

00:10:53.820 --> 00:10:53.830
those tensors into your session don't
 

00:10:53.830 --> 00:10:54.420
those tensors into your session don't
run together

00:10:54.420 --> 00:10:54.430
run together
 

00:10:54.430 --> 00:10:55.860
run together
actual data so there are a few hoops to

00:10:55.860 --> 00:10:55.870
actual data so there are a few hoops to
 

00:10:55.870 --> 00:10:57.330
actual data so there are a few hoops to
jump through you know if you want to

00:10:57.330 --> 00:10:57.340
jump through you know if you want to
 

00:10:57.340 --> 00:10:59.910
jump through you know if you want to
write an RNN from scratch in the default

00:10:59.910 --> 00:10:59.920
write an RNN from scratch in the default
 

00:10:59.920 --> 00:11:00.660
write an RNN from scratch in the default
mode of tensorflow

00:11:00.660 --> 00:11:00.670
mode of tensorflow
 

00:11:00.670 --> 00:11:02.880
mode of tensorflow
but with execution the things becomes

00:11:02.880 --> 00:11:02.890
but with execution the things becomes
 

00:11:02.890 --> 00:11:05.130
but with execution the things becomes
much simpler so you can use the native

00:11:05.130 --> 00:11:05.140
much simpler so you can use the native
 

00:11:05.140 --> 00:11:06.530
much simpler so you can use the native
for loop in python

00:11:06.530 --> 00:11:06.540
for loop in python
 

00:11:06.540 --> 00:11:09.470
for loop in python
to loop over time steps in the input and

00:11:09.470 --> 00:11:09.480
to loop over time steps in the input and
 

00:11:09.480 --> 00:11:10.970
to loop over time steps in the input and
you don't have to worry about those

00:11:10.970 --> 00:11:10.980
you don't have to worry about those
 

00:11:10.980 --> 00:11:13.610
you don't have to worry about those
symbolic tensors or sessions on run the

00:11:13.610 --> 00:11:13.620
symbolic tensors or sessions on run the
 

00:11:13.620 --> 00:11:16.520
symbolic tensors or sessions on run the
the the variables you get from this for

00:11:16.520 --> 00:11:16.530
the the variables you get from this for
 

00:11:16.530 --> 00:11:22.090
the the variables you get from this for
loop is the result of the commutation so

00:11:22.090 --> 00:11:22.100
loop is the result of the commutation so
 

00:11:22.100 --> 00:11:24.410
loop is the result of the commutation so
eager mode makes it much easier to write

00:11:24.410 --> 00:11:24.420
eager mode makes it much easier to write
 

00:11:24.420 --> 00:11:26.330
eager mode makes it much easier to write
the so-called dynamic models so what do

00:11:26.330 --> 00:11:26.340
the so-called dynamic models so what do
 

00:11:26.340 --> 00:11:28.580
the so-called dynamic models so what do
we mean by static models in the dynamic

00:11:28.580 --> 00:11:28.590
we mean by static models in the dynamic
 

00:11:28.590 --> 00:11:30.530
we mean by static models in the dynamic
models so by static models we mean

00:11:30.530 --> 00:11:30.540
models so by static models we mean
 

00:11:30.540 --> 00:11:33.410
models so by static models we mean
models whose structure don't change with

00:11:33.410 --> 00:11:33.420
models whose structure don't change with
 

00:11:33.420 --> 00:11:35.720
models whose structure don't change with
the input data and I think you have seen

00:11:35.720 --> 00:11:35.730
the input data and I think you have seen
 

00:11:35.730 --> 00:11:37.790
the input data and I think you have seen
examples like that in the image model

00:11:37.790 --> 00:11:37.800
examples like that in the image model
 

00:11:37.800 --> 00:11:40.310
examples like that in the image model
sections of this lecture so the guitar

00:11:40.310 --> 00:11:40.320
sections of this lecture so the guitar
 

00:11:40.320 --> 00:11:42.500
sections of this lecture so the guitar
gram here shows the inception model in

00:11:42.500 --> 00:11:42.510
gram here shows the inception model in
 

00:11:42.510 --> 00:11:44.930
gram here shows the inception model in
tensorflow so the model can be very

00:11:44.930 --> 00:11:44.940
tensorflow so the model can be very
 

00:11:44.940 --> 00:11:46.550
tensorflow so the model can be very
complicated can have like hundreds of

00:11:46.550 --> 00:11:46.560
complicated can have like hundreds of
 

00:11:46.560 --> 00:11:48.710
complicated can have like hundreds of
layers and it can do can do like a

00:11:48.710 --> 00:11:48.720
layers and it can do can do like a
 

00:11:48.720 --> 00:11:50.840
layers and it can do can do like a
complicated competition like combination

00:11:50.840 --> 00:11:50.850
complicated competition like combination
 

00:11:50.850 --> 00:11:53.270
complicated competition like combination
pooling and dense multiplication and so

00:11:53.270 --> 00:11:53.280
pooling and dense multiplication and so
 

00:11:53.280 --> 00:11:55.340
pooling and dense multiplication and so
on but the structure of the model is

00:11:55.340 --> 00:11:55.350
on but the structure of the model is
 

00:11:55.350 --> 00:11:57.200
on but the structure of the model is
always the same no matter how the image

00:11:57.200 --> 00:11:57.210
always the same no matter how the image
 

00:11:57.210 --> 00:11:59.270
always the same no matter how the image
changes the image always has the same

00:11:59.270 --> 00:11:59.280
changes the image always has the same
 

00:11:59.280 --> 00:12:02.480
changes the image always has the same
size and the same color depth but the

00:12:02.480 --> 00:12:02.490
size and the same color depth but the
 

00:12:02.490 --> 00:12:04.250
size and the same color depth but the
model will always compute the same I

00:12:04.250 --> 00:12:04.260
model will always compute the same I
 

00:12:04.260 --> 00:12:05.540
model will always compute the same I
mean it will always do the same

00:12:05.540 --> 00:12:05.550
mean it will always do the same
 

00:12:05.550 --> 00:12:07.040
mean it will always do the same
competition regardless how the image

00:12:07.040 --> 00:12:07.050
competition regardless how the image
 

00:12:07.050 --> 00:12:09.260
competition regardless how the image
changes so that's what we mean by a

00:12:09.260 --> 00:12:09.270
changes so that's what we mean by a
 

00:12:09.270 --> 00:12:11.150
changes so that's what we mean by a
static model but there are also models

00:12:11.150 --> 00:12:11.160
static model but there are also models
 

00:12:11.160 --> 00:12:13.820
static model but there are also models
whose structure change with input data

00:12:13.820 --> 00:12:13.830
whose structure change with input data
 

00:12:13.830 --> 00:12:15.800
whose structure change with input data
so the recurrence neural network we have

00:12:15.800 --> 00:12:15.810
so the recurrence neural network we have
 

00:12:15.810 --> 00:12:17.090
so the recurrence neural network we have
seen it's actually an example of that

00:12:17.090 --> 00:12:17.100
seen it's actually an example of that
 

00:12:17.100 --> 00:12:18.830
seen it's actually an example of that
and the reason why it's changes is

00:12:18.830 --> 00:12:18.840
and the reason why it's changes is
 

00:12:18.840 --> 00:12:21.110
and the reason why it's changes is
because it needs to loop over things so

00:12:21.110 --> 00:12:21.120
because it needs to loop over things so
 

00:12:21.120 --> 00:12:22.970
because it needs to loop over things so
in the simplest kind of recurrent neural

00:12:22.970 --> 00:12:22.980
in the simplest kind of recurrent neural
 

00:12:22.980 --> 00:12:25.190
in the simplest kind of recurrent neural
network it will loop over items in the

00:12:25.190 --> 00:12:25.200
network it will loop over items in the
 

00:12:25.200 --> 00:12:28.550
network it will loop over items in the
sequence like words in a sentence so you

00:12:28.550 --> 00:12:28.560
sequence like words in a sentence so you
 

00:12:28.560 --> 00:12:29.930
sequence like words in a sentence so you
can say that that the length of the

00:12:29.930 --> 00:12:29.940
can say that that the length of the
 

00:12:29.940 --> 00:12:31.430
can say that that the length of the
model is proportional to the length of

00:12:31.430 --> 00:12:31.440
model is proportional to the length of
 

00:12:31.440 --> 00:12:33.710
model is proportional to the length of
the input sentence but there are also

00:12:33.710 --> 00:12:33.720
the input sentence but there are also
 

00:12:33.720 --> 00:12:35.720
the input sentence but there are also
more complicated changes of the model

00:12:35.720 --> 00:12:35.730
more complicated changes of the model
 

00:12:35.730 --> 00:12:38.750
more complicated changes of the model
structure with input data so some of the

00:12:38.750 --> 00:12:38.760
structure with input data so some of the
 

00:12:38.760 --> 00:12:39.440
structure with input data so some of the
state-of-the-art

00:12:39.440 --> 00:12:39.450
state-of-the-art
 

00:12:39.450 --> 00:12:41.000
state-of-the-art
models that deal with natural language

00:12:41.000 --> 00:12:41.010
models that deal with natural language
 

00:12:41.010 --> 00:12:43.430
models that deal with natural language
will actually take a parse tree of a

00:12:43.430 --> 00:12:43.440
will actually take a parse tree of a
 

00:12:43.440 --> 00:12:46.190
will actually take a parse tree of a
sentence as the input and the structure

00:12:46.190 --> 00:12:46.200
sentence as the input and the structure
 

00:12:46.200 --> 00:12:48.230
sentence as the input and the structure
of the model will reflect that parse

00:12:48.230 --> 00:12:48.240
of the model will reflect that parse
 

00:12:48.240 --> 00:12:51.410
of the model will reflect that parse
tree so as we have seen before it's

00:12:51.410 --> 00:12:51.420
tree so as we have seen before it's
 

00:12:51.420 --> 00:12:53.150
tree so as we have seen before it's
complicated to write our while loops or

00:12:53.150 --> 00:12:53.160
complicated to write our while loops or
 

00:12:53.160 --> 00:12:55.070
complicated to write our while loops or
control flow structures in in the

00:12:55.070 --> 00:12:55.080
control flow structures in in the
 

00:12:55.080 --> 00:12:57.320
control flow structures in in the
default symbolic mode now if you want to

00:12:57.320 --> 00:12:57.330
default symbolic mode now if you want to
 

00:12:57.330 --> 00:12:59.480
default symbolic mode now if you want to
write that kind of model it gets even

00:12:59.480 --> 00:12:59.490
write that kind of model it gets even
 

00:12:59.490 --> 00:13:01.220
write that kind of model it gets even
more complicated because there you will

00:13:01.220 --> 00:13:01.230
more complicated because there you will
 

00:13:01.230 --> 00:13:03.770
more complicated because there you will
need to nest conditional branches and

00:13:03.770 --> 00:13:03.780
need to nest conditional branches and
 

00:13:03.780 --> 00:13:05.750
need to nest conditional branches and
the while loops but it's much easier to

00:13:05.750 --> 00:13:05.760
the while loops but it's much easier to
 

00:13:05.760 --> 00:13:07.940
the while loops but it's much easier to
write in the ego remote because you can

00:13:07.940 --> 00:13:07.950
write in the ego remote because you can
 

00:13:07.950 --> 00:13:10.220
write in the ego remote because you can
just use the native for loops and while

00:13:10.220 --> 00:13:10.230
just use the native for loops and while
 

00:13:10.230 --> 00:13:11.750
just use the native for loops and while
loops and if-else statements in Python

00:13:11.750 --> 00:13:11.760
loops and if-else statements in Python
 

00:13:11.760 --> 00:13:15.020
loops and if-else statements in Python
so we actually have an example to show

00:13:15.020 --> 00:13:15.030
so we actually have an example to show
 

00:13:15.030 --> 00:13:16.540
so we actually have an example to show
you how to write

00:13:16.540 --> 00:13:16.550
you how to write
 

00:13:16.550 --> 00:13:18.940
you how to write
model starts take parse trees as input

00:13:18.940 --> 00:13:18.950
model starts take parse trees as input
 

00:13:18.950 --> 00:13:20.829
model starts take parse trees as input
and the process natural language so

00:13:20.829 --> 00:13:20.839
and the process natural language so
 

00:13:20.839 --> 00:13:22.660
and the process natural language so
please check that out if you want you

00:13:22.660 --> 00:13:22.670
please check that out if you want you
 

00:13:22.670 --> 00:13:26.130
please check that out if you want you
have a question

00:13:26.130 --> 00:13:26.140
 

00:13:26.140 --> 00:13:34.000
the tree is static yeah the tree is

00:13:34.000 --> 00:13:34.010
the tree is static yeah the tree is
 

00:13:34.010 --> 00:13:36.250
the tree is static yeah the tree is
static in this particular input but you

00:13:36.250 --> 00:13:36.260
static in this particular input but you
 

00:13:36.260 --> 00:13:37.750
static in this particular input but you
can have a longer sentence right it's

00:13:37.750 --> 00:13:37.760
can have a longer sentence right it's
 

00:13:37.760 --> 00:13:40.180
can have a longer sentence right it's
the the the grammar of the armed

00:13:40.180 --> 00:13:40.190
the the the grammar of the armed
 

00:13:40.190 --> 00:13:42.070
the the the grammar of the armed
sentence the parts of the of the

00:13:42.070 --> 00:13:42.080
sentence the parts of the of the
 

00:13:42.080 --> 00:13:43.540
sentence the parts of the of the
sentence can change from one sentence to

00:13:43.540 --> 00:13:43.550
sentence can change from one sentence to
 

00:13:43.550 --> 00:13:45.340
sentence can change from one sentence to
another right so that won't make the

00:13:45.340 --> 00:13:45.350
another right so that won't make the
 

00:13:45.350 --> 00:13:47.800
another right so that won't make the
model structure change as well so

00:13:47.800 --> 00:13:47.810
model structure change as well so
 

00:13:47.810 --> 00:13:49.210
model structure change as well so
basically you can't hard-code the

00:13:49.210 --> 00:13:49.220
basically you can't hard-code the
 

00:13:49.220 --> 00:13:50.680
basically you can't hard-code the
structure of the model you have to like

00:13:50.680 --> 00:13:50.690
structure of the model you have to like
 

00:13:50.690 --> 00:13:53.769
structure of the model you have to like
look at a parse tree and then like do

00:13:53.769 --> 00:13:53.779
look at a parse tree and then like do
 

00:13:53.779 --> 00:13:54.519
look at a parse tree and then like do
some kind of like

00:13:54.519 --> 00:13:54.529
some kind of like
 

00:13:54.529 --> 00:13:56.769
some kind of like
if-else statements and wild loops in

00:13:56.769 --> 00:13:56.779
if-else statements and wild loops in
 

00:13:56.779 --> 00:13:58.510
if-else statements and wild loops in
order to like turn the parse tree into

00:13:58.510 --> 00:13:58.520
order to like turn the parse tree into
 

00:13:58.520 --> 00:14:04.870
order to like turn the parse tree into
the model okay so we have seen that the

00:14:04.870 --> 00:14:04.880
the model okay so we have seen that the
 

00:14:04.880 --> 00:14:07.360
the model okay so we have seen that the
eager mode is very good for learning and

00:14:07.360 --> 00:14:07.370
eager mode is very good for learning and
 

00:14:07.370 --> 00:14:09.570
eager mode is very good for learning and
debugging and for writing control flow

00:14:09.570 --> 00:14:09.580
debugging and for writing control flow
 

00:14:09.580 --> 00:14:12.460
debugging and for writing control flow
structures but sometimes you may still

00:14:12.460 --> 00:14:12.470
structures but sometimes you may still
 

00:14:12.470 --> 00:14:14.110
structures but sometimes you may still
want to debug tensorflow programs

00:14:14.110 --> 00:14:14.120
want to debug tensorflow programs
 

00:14:14.120 --> 00:14:16.090
want to debug tensorflow programs
running in the default symbolic mode and

00:14:16.090 --> 00:14:16.100
running in the default symbolic mode and
 

00:14:16.100 --> 00:14:17.590
running in the default symbolic mode and
there are a few reasons for that first

00:14:17.590 --> 00:14:17.600
there are a few reasons for that first
 

00:14:17.600 --> 00:14:20.019
there are a few reasons for that first
you may be using some kind of old code

00:14:20.019 --> 00:14:20.029
you may be using some kind of old code
 

00:14:20.029 --> 00:14:21.940
you may be using some kind of old code
of tensorflow that hasn't been reported

00:14:21.940 --> 00:14:21.950
of tensorflow that hasn't been reported
 

00:14:21.950 --> 00:14:23.920
of tensorflow that hasn't been reported
to you remote yet and some high level

00:14:23.920 --> 00:14:23.930
to you remote yet and some high level
 

00:14:23.930 --> 00:14:25.780
to you remote yet and some high level
API is you might be using like TF learn

00:14:25.780 --> 00:14:25.790
API is you might be using like TF learn
 

00:14:25.790 --> 00:14:28.810
API is you might be using like TF learn
or Kara's or TF slim have not been put

00:14:28.810 --> 00:14:28.820
or Kara's or TF slim have not been put
 

00:14:28.820 --> 00:14:31.240
or Kara's or TF slim have not been put
into your mode yet and you may want to

00:14:31.240 --> 00:14:31.250
into your mode yet and you may want to
 

00:14:31.250 --> 00:14:32.889
into your mode yet and you may want to
stick to the default symbolic mode

00:14:32.889 --> 00:14:32.899
stick to the default symbolic mode
 

00:14:32.899 --> 00:14:34.600
stick to the default symbolic mode
because you care about speed because

00:14:34.600 --> 00:14:34.610
because you care about speed because
 

00:14:34.610 --> 00:14:36.130
because you care about speed because
eager mode is sometimes slower than then

00:14:36.130 --> 00:14:36.140
eager mode is sometimes slower than then
 

00:14:36.140 --> 00:14:39.310
eager mode is sometimes slower than then
the default mode so um the good news is

00:14:39.310 --> 00:14:39.320
the default mode so um the good news is
 

00:14:39.320 --> 00:14:40.840
the default mode so um the good news is
that we have a tool in terms of flow

00:14:40.840 --> 00:14:40.850
that we have a tool in terms of flow
 

00:14:40.850 --> 00:14:43.180
that we have a tool in terms of flow
that can help you like debug attends to

00:14:43.180 --> 00:14:43.190
that can help you like debug attends to
 

00:14:43.190 --> 00:14:45.760
that can help you like debug attends to
flow model running in the theater um TF

00:14:45.760 --> 00:14:45.770
flow model running in the theater um TF
 

00:14:45.770 --> 00:14:48.370
flow model running in the theater um TF
that session in the default mode and

00:14:48.370 --> 00:14:48.380
that session in the default mode and
 

00:14:48.380 --> 00:14:49.840
that session in the default mode and
that's always called TF d BG or

00:14:49.840 --> 00:14:49.850
that's always called TF d BG or
 

00:14:49.850 --> 00:14:50.500
that's always called TF d BG or
tensorflow

00:14:50.500 --> 00:14:50.510
tensorflow
 

00:14:50.510 --> 00:14:54.040
tensorflow
debugger so the way in which you you use

00:14:54.040 --> 00:14:54.050
debugger so the way in which you you use
 

00:14:54.050 --> 00:14:55.600
debugger so the way in which you you use
it is kind of similar to the way in

00:14:55.600 --> 00:14:55.610
it is kind of similar to the way in
 

00:14:55.610 --> 00:14:58.210
it is kind of similar to the way in
which use eager execution we import an

00:14:58.210 --> 00:14:58.220
which use eager execution we import an
 

00:14:58.220 --> 00:15:00.430
which use eager execution we import an
additional module and after you have

00:15:00.430 --> 00:15:00.440
additional module and after you have
 

00:15:00.440 --> 00:15:02.500
additional module and after you have
created the session object you will wrap

00:15:02.500 --> 00:15:02.510
created the session object you will wrap
 

00:15:02.510 --> 00:15:04.240
created the session object you will wrap
the session object where the wrapper in

00:15:04.240 --> 00:15:04.250
the session object where the wrapper in
 

00:15:04.250 --> 00:15:05.829
the session object where the wrapper in
this case is called local command line

00:15:05.829 --> 00:15:05.839
this case is called local command line
 

00:15:05.839 --> 00:15:08.590
this case is called local command line
interface debug wrapper so you don't

00:15:08.590 --> 00:15:08.600
interface debug wrapper so you don't
 

00:15:08.600 --> 00:15:10.030
interface debug wrapper so you don't
need to make any other change to your

00:15:10.030 --> 00:15:10.040
need to make any other change to your
 

00:15:10.040 --> 00:15:12.370
need to make any other change to your
code because this wrapped object has the

00:15:12.370 --> 00:15:12.380
code because this wrapped object has the
 

00:15:12.380 --> 00:15:14.590
code because this wrapped object has the
same interface as the unwrapped object

00:15:14.590 --> 00:15:14.600
same interface as the unwrapped object
 

00:15:14.600 --> 00:15:16.900
same interface as the unwrapped object
but basically you can you can think of

00:15:16.900 --> 00:15:16.910
but basically you can you can think of
 

00:15:16.910 --> 00:15:19.240
but basically you can you can think of
this as like an otoscope some kind of

00:15:19.240 --> 00:15:19.250
this as like an otoscope some kind of
 

00:15:19.250 --> 00:15:21.579
this as like an otoscope some kind of
instrument on your TF dart session which

00:15:21.579 --> 00:15:21.589
instrument on your TF dart session which
 

00:15:21.589 --> 00:15:24.850
instrument on your TF dart session which
is otherwise opaque so now once you have

00:15:24.850 --> 00:15:24.860
is otherwise opaque so now once you have
 

00:15:24.860 --> 00:15:27.640
is otherwise opaque so now once you have
wrapped that session when sessions are

00:15:27.640 --> 00:15:27.650
wrapped that session when sessions are
 

00:15:27.650 --> 00:15:29.590
wrapped that session when sessions are
run is called your going to drop into

00:15:29.590 --> 00:15:29.600
run is called your going to drop into
 

00:15:29.600 --> 00:15:30.160
run is called your going to drop into
the command line

00:15:30.160 --> 00:15:30.170
the command line
 

00:15:30.170 --> 00:15:31.780
the command line
interface you're going to see basically

00:15:31.780 --> 00:15:31.790
interface you're going to see basically
 

00:15:31.790 --> 00:15:34.449
interface you're going to see basically
a presentation of what

00:15:34.449 --> 00:15:34.459
a presentation of what
 

00:15:34.459 --> 00:15:36.430
a presentation of what
intermediate answers are executed in the

00:15:36.430 --> 00:15:36.440
intermediate answers are executed in the
 

00:15:36.440 --> 00:15:38.319
intermediate answers are executed in the
sessions are run and the structure in

00:15:38.319 --> 00:15:38.329
sessions are run and the structure in
 

00:15:38.329 --> 00:15:41.680
sessions are run and the structure in
the graph and so on so I encourage you

00:15:41.680 --> 00:15:41.690
the graph and so on so I encourage you
 

00:15:41.690 --> 00:15:44.129
the graph and so on so I encourage you
to play with that after the lecture

00:15:44.129 --> 00:15:44.139
to play with that after the lecture
 

00:15:44.139 --> 00:15:49.389
to play with that after the lecture
so the TF debugger is also very useful

00:15:49.389 --> 00:15:49.399
so the TF debugger is also very useful
 

00:15:49.399 --> 00:15:51.460
so the TF debugger is also very useful
for debugging a kind of bugs in your

00:15:51.460 --> 00:15:51.470
for debugging a kind of bugs in your
 

00:15:51.470 --> 00:15:52.540
for debugging a kind of bugs in your
machine learning models which will

00:15:52.540 --> 00:15:52.550
machine learning models which will
 

00:15:52.550 --> 00:15:54.250
machine learning models which will
probably occur those are called

00:15:54.250 --> 00:15:54.260
probably occur those are called
 

00:15:54.260 --> 00:15:56.170
probably occur those are called
numerical instability issues so by that

00:15:56.170 --> 00:15:56.180
numerical instability issues so by that
 

00:15:56.180 --> 00:15:58.480
numerical instability issues so by that
I mean sometimes values in the network

00:15:58.480 --> 00:15:58.490
I mean sometimes values in the network
 

00:15:58.490 --> 00:16:00.670
I mean sometimes values in the network
will become Nan's or infinities so nan

00:16:00.670 --> 00:16:00.680
will become Nan's or infinities so nan
 

00:16:00.680 --> 00:16:02.680
will become Nan's or infinities so nan
stands R stands for not a number

00:16:02.680 --> 00:16:02.690
stands R stands for not a number
 

00:16:02.690 --> 00:16:04.960
stands R stands for not a number
Nan's and infinities are like bad float

00:16:04.960 --> 00:16:04.970
Nan's and infinities are like bad float
 

00:16:04.970 --> 00:16:07.990
Nan's and infinities are like bad float
values that will sometimes happen now if

00:16:07.990 --> 00:16:08.000
values that will sometimes happen now if
 

00:16:08.000 --> 00:16:09.370
values that will sometimes happen now if
you don't have a specialized tool in

00:16:09.370 --> 00:16:09.380
you don't have a specialized tool in
 

00:16:09.380 --> 00:16:10.689
you don't have a specialized tool in
terms of law it can be difficult to

00:16:10.689 --> 00:16:10.699
terms of law it can be difficult to
 

00:16:10.699 --> 00:16:13.600
terms of law it can be difficult to
pinpoint the exact node which generates

00:16:13.600 --> 00:16:13.610
pinpoint the exact node which generates
 

00:16:13.610 --> 00:16:14.980
pinpoint the exact node which generates
the lens and infinities

00:16:14.980 --> 00:16:14.990
the lens and infinities
 

00:16:14.990 --> 00:16:16.870
the lens and infinities
but the debugger has a special command

00:16:16.870 --> 00:16:16.880
but the debugger has a special command
 

00:16:16.880 --> 00:16:18.910
but the debugger has a special command
with which you can run the model until

00:16:18.910 --> 00:16:18.920
with which you can run the model until
 

00:16:18.920 --> 00:16:21.340
with which you can run the model until
any nodes in the graph contains an ends

00:16:21.340 --> 00:16:21.350
any nodes in the graph contains an ends
 

00:16:21.350 --> 00:16:24.639
any nodes in the graph contains an ends
or infinities so in our experience that

00:16:24.639 --> 00:16:24.649
or infinities so in our experience that
 

00:16:24.649 --> 00:16:26.829
or infinities so in our experience that
happens quite often and the most common

00:16:26.829 --> 00:16:26.839
happens quite often and the most common
 

00:16:26.839 --> 00:16:29.170
happens quite often and the most common
causes of Nan's and infinities are in

00:16:29.170 --> 00:16:29.180
causes of Nan's and infinities are in
 

00:16:29.180 --> 00:16:31.540
causes of Nan's and infinities are in
the flow and overflow so for example if

00:16:31.540 --> 00:16:31.550
the flow and overflow so for example if
 

00:16:31.550 --> 00:16:33.310
the flow and overflow so for example if
there's under flow then a number will

00:16:33.310 --> 00:16:33.320
there's under flow then a number will
 

00:16:33.320 --> 00:16:35.319
there's under flow then a number will
become zero and when you use that number

00:16:35.319 --> 00:16:35.329
become zero and when you use that number
 

00:16:35.329 --> 00:16:36.850
become zero and when you use that number
in division or lock you will get

00:16:36.850 --> 00:16:36.860
in division or lock you will get
 

00:16:36.860 --> 00:16:39.189
in division or lock you will get
infinities and overflow can be caused by

00:16:39.189 --> 00:16:39.199
infinities and overflow can be caused by
 

00:16:39.199 --> 00:16:42.250
infinities and overflow can be caused by
learning rates being too high or by some

00:16:42.250 --> 00:16:42.260
learning rates being too high or by some
 

00:16:42.260 --> 00:16:43.689
learning rates being too high or by some
kind of bad training example that you

00:16:43.689 --> 00:16:43.699
kind of bad training example that you
 

00:16:43.699 --> 00:16:46.660
kind of bad training example that you
haven't sanitized or pre-processed but

00:16:46.660 --> 00:16:46.670
haven't sanitized or pre-processed but
 

00:16:46.670 --> 00:16:48.430
haven't sanitized or pre-processed but
under the debugger should help you find

00:16:48.430 --> 00:16:48.440
under the debugger should help you find
 

00:16:48.440 --> 00:16:49.630
under the debugger should help you find
the root cause of that kind of issues

00:16:49.630 --> 00:16:49.640
the root cause of that kind of issues
 

00:16:49.640 --> 00:16:55.180
the root cause of that kind of issues
more more quickly so the TF debugger is

00:16:55.180 --> 00:16:55.190
more more quickly so the TF debugger is
 

00:16:55.190 --> 00:16:57.310
more more quickly so the TF debugger is
a command-line tool it's nice it's low

00:16:57.310 --> 00:16:57.320
a command-line tool it's nice it's low
 

00:16:57.320 --> 00:16:59.920
a command-line tool it's nice it's low
footprint you can use it if you have

00:16:59.920 --> 00:16:59.930
footprint you can use it if you have
 

00:16:59.930 --> 00:17:01.389
footprint you can use it if you have
access to a computer only via a terminal

00:17:01.389 --> 00:17:01.399
access to a computer only via a terminal
 

00:17:01.399 --> 00:17:04.179
access to a computer only via a terminal
but obviously it's going to be even

00:17:04.179 --> 00:17:04.189
but obviously it's going to be even
 

00:17:04.189 --> 00:17:05.740
but obviously it's going to be even
nicer if we can debug the tensorflow

00:17:05.740 --> 00:17:05.750
nicer if we can debug the tensorflow
 

00:17:05.750 --> 00:17:08.890
nicer if we can debug the tensorflow
models in a graphical user interface so

00:17:08.890 --> 00:17:08.900
models in a graphical user interface so
 

00:17:08.900 --> 00:17:11.380
models in a graphical user interface so
I'm excited to tell you about a feature

00:17:11.380 --> 00:17:11.390
I'm excited to tell you about a feature
 

00:17:11.390 --> 00:17:12.610
I'm excited to tell you about a feature
of tensorflow that's upcoming

00:17:12.610 --> 00:17:12.620
of tensorflow that's upcoming
 

00:17:12.620 --> 00:17:14.559
of tensorflow that's upcoming
so it's called tensor board debugger

00:17:14.559 --> 00:17:14.569
so it's called tensor board debugger
 

00:17:14.569 --> 00:17:17.110
so it's called tensor board debugger
plugin or visual graphical debugger for

00:17:17.110 --> 00:17:17.120
plugin or visual graphical debugger for
 

00:17:17.120 --> 00:17:19.120
plugin or visual graphical debugger for
tensorflow so it's not included in the

00:17:19.120 --> 00:17:19.130
tensorflow so it's not included in the
 

00:17:19.130 --> 00:17:20.819
tensorflow so it's not included in the
latest release of

00:17:20.819 --> 00:17:20.829
latest release of
 

00:17:20.829 --> 00:17:23.409
latest release of
tensorflow which is 1.5 but it's coming

00:17:23.409 --> 00:17:23.419
tensorflow which is 1.5 but it's coming
 

00:17:23.419 --> 00:17:26.049
tensorflow which is 1.5 but it's coming
in the next release 1.6 it's available

00:17:26.049 --> 00:17:26.059
in the next release 1.6 it's available
 

00:17:26.059 --> 00:17:28.810
in the next release 1.6 it's available
for preview in Knightley's so you can

00:17:28.810 --> 00:17:28.820
for preview in Knightley's so you can
 

00:17:28.820 --> 00:17:30.370
for preview in Knightley's so you can
copy and paste the code from here

00:17:30.370 --> 00:17:30.380
copy and paste the code from here
 

00:17:30.380 --> 00:17:31.960
copy and paste the code from here
install those nightly builds of

00:17:31.960 --> 00:17:31.970
install those nightly builds of
 

00:17:31.970 --> 00:17:34.690
install those nightly builds of
tensorflow and pencil board and you can

00:17:34.690 --> 00:17:34.700
tensorflow and pencil board and you can
 

00:17:34.700 --> 00:17:36.460
tensorflow and pencil board and you can
use the feature so after you have

00:17:36.460 --> 00:17:36.470
use the feature so after you have
 

00:17:36.470 --> 00:17:39.310
use the feature so after you have
installed these packages you can run a

00:17:39.310 --> 00:17:39.320
installed these packages you can run a
 

00:17:39.320 --> 00:17:41.530
installed these packages you can run a
command so all the code in my slides are

00:17:41.530 --> 00:17:41.540
command so all the code in my slides are
 

00:17:41.540 --> 00:17:43.540
command so all the code in my slides are
copy paste executables

00:17:43.540 --> 00:17:43.550
copy paste executables
 

00:17:43.550 --> 00:17:44.800
copy paste executables
yeah so these are about the main

00:17:44.800 --> 00:17:44.810
yeah so these are about the main
 

00:17:44.810 --> 00:17:48.100
yeah so these are about the main
features of upcoming tool so if you're

00:17:48.100 --> 00:17:48.110
features of upcoming tool so if you're
 

00:17:48.110 --> 00:17:49.540
features of upcoming tool so if you're
interested please copy and paste these

00:17:49.540 --> 00:17:49.550
interested please copy and paste these
 

00:17:49.550 --> 00:17:52.990
interested please copy and paste these
code and try it out this light here is

00:17:52.990 --> 00:17:53.000
code and try it out this light here is
 

00:17:53.000 --> 00:17:54.820
code and try it out this light here is
just a reminder of the main features in

00:17:54.820 --> 00:17:54.830
just a reminder of the main features in
 

00:17:54.830 --> 00:17:58.870
just a reminder of the main features in
here ok so as a summary we see that

00:17:58.870 --> 00:17:58.880
here ok so as a summary we see that
 

00:17:58.880 --> 00:18:00.490
here ok so as a summary we see that
there are two ways to represent machine

00:18:00.490 --> 00:18:00.500
there are two ways to represent machine
 

00:18:00.500 --> 00:18:02.740
there are two ways to represent machine
learning models intensive flow or in any

00:18:02.740 --> 00:18:02.750
learning models intensive flow or in any
 

00:18:02.750 --> 00:18:04.870
learning models intensive flow or in any
deep learning framework either as a as a

00:18:04.870 --> 00:18:04.880
deep learning framework either as a as a
 

00:18:04.880 --> 00:18:07.360
deep learning framework either as a as a
data structure or as a program if it's a

00:18:07.360 --> 00:18:07.370
data structure or as a program if it's a
 

00:18:07.370 --> 00:18:08.380
data structure or as a program if it's a
data structure then you will get

00:18:08.380 --> 00:18:08.390
data structure then you will get
 

00:18:08.390 --> 00:18:10.750
data structure then you will get
symbolic execution and symbolic

00:18:10.750 --> 00:18:10.760
symbolic execution and symbolic
 

00:18:10.760 --> 00:18:12.510
symbolic execution and symbolic
execution is good for deployment

00:18:12.510 --> 00:18:12.520
execution is good for deployment
 

00:18:12.520 --> 00:18:15.430
execution is good for deployment
distribution and optimization and if

00:18:15.430 --> 00:18:15.440
distribution and optimization and if
 

00:18:15.440 --> 00:18:17.170
distribution and optimization and if
it's a program that you will get eager

00:18:17.170 --> 00:18:17.180
it's a program that you will get eager
 

00:18:17.180 --> 00:18:18.430
it's a program that you will get eager
execution it's good for prototyping

00:18:18.430 --> 00:18:18.440
execution it's good for prototyping
 

00:18:18.440 --> 00:18:21.010
execution it's good for prototyping
debugging and writing control flow

00:18:21.010 --> 00:18:21.020
debugging and writing control flow
 

00:18:21.020 --> 00:18:24.070
debugging and writing control flow
structures and it's also easier to learn

00:18:24.070 --> 00:18:24.080
structures and it's also easier to learn
 

00:18:24.080 --> 00:18:26.230
structures and it's also easier to learn
and the currently tensorflow supports

00:18:26.230 --> 00:18:26.240
and the currently tensorflow supports
 

00:18:26.240 --> 00:18:27.640
and the currently tensorflow supports
both modes so you can pick and choose

00:18:27.640 --> 00:18:27.650
both modes so you can pick and choose
 

00:18:27.650 --> 00:18:29.410
both modes so you can pick and choose
the best mode for you depending on your

00:18:29.410 --> 00:18:29.420
the best mode for you depending on your
 

00:18:29.420 --> 00:18:33.010
the best mode for you depending on your
need and we also went over tens of load

00:18:33.010 --> 00:18:33.020
need and we also went over tens of load
 

00:18:33.020 --> 00:18:34.900
need and we also went over tens of load
debugger both the command line interface

00:18:34.900 --> 00:18:34.910
debugger both the command line interface
 

00:18:34.910 --> 00:18:37.540
debugger both the command line interface
and the browser version which will help

00:18:37.540 --> 00:18:37.550
and the browser version which will help
 

00:18:37.550 --> 00:18:40.660
and the browser version which will help
you debug your model more efficiently so

00:18:40.660 --> 00:18:40.670
you debug your model more efficiently so
 

00:18:40.670 --> 00:18:42.360
you debug your model more efficiently so
with that I'm going to thank my

00:18:42.360 --> 00:18:42.370
with that I'm going to thank my
 

00:18:42.370 --> 00:18:44.650
with that I'm going to thank my
colleagues on the Google brain team both

00:18:44.650 --> 00:18:44.660
colleagues on the Google brain team both
 

00:18:44.660 --> 00:18:45.940
colleagues on the Google brain team both
in the Mountain View headquarters and

00:18:45.940 --> 00:18:45.950
in the Mountain View headquarters and
 

00:18:45.950 --> 00:18:48.550
in the Mountain View headquarters and
here in Cambridge Qi and Mahima are the

00:18:48.550 --> 00:18:48.560
here in Cambridge Qi and Mahima are the
 

00:18:48.560 --> 00:18:50.530
here in Cambridge Qi and Mahima are the
two collaborators with me on the tensor

00:18:50.530 --> 00:18:50.540
two collaborators with me on the tensor
 

00:18:50.540 --> 00:18:52.530
two collaborators with me on the tensor
board debugger plug-in project and

00:18:52.530 --> 00:18:52.540
board debugger plug-in project and
 

00:18:52.540 --> 00:18:54.400
board debugger plug-in project and
tensorflow is an open source project

00:18:54.400 --> 00:18:54.410
tensorflow is an open source project
 

00:18:54.410 --> 00:18:57.070
tensorflow is an open source project
there have been over 1,000 contributors

00:18:57.070 --> 00:18:57.080
there have been over 1,000 contributors
 

00:18:57.080 --> 00:18:58.750
there have been over 1,000 contributors
like you who have arm fixed bugs and

00:18:58.750 --> 00:18:58.760
like you who have arm fixed bugs and
 

00:18:58.760 --> 00:19:00.280
like you who have arm fixed bugs and
contributed new features so if you see

00:19:00.280 --> 00:19:00.290
contributed new features so if you see
 

00:19:00.290 --> 00:19:02.020
contributed new features so if you see
any interesting things that you can do

00:19:02.020 --> 00:19:02.030
any interesting things that you can do
 

00:19:02.030 --> 00:19:03.460
any interesting things that you can do
feel free to contribute to the tensor

00:19:03.460 --> 00:19:03.470
feel free to contribute to the tensor
 

00:19:03.470 --> 00:19:05.680
feel free to contribute to the tensor
flow on github if it has have questions

00:19:05.680 --> 00:19:05.690
flow on github if it has have questions
 

00:19:05.690 --> 00:19:09.130
flow on github if it has have questions
please email me and if you see any bugs

00:19:09.130 --> 00:19:09.140
please email me and if you see any bugs
 

00:19:09.140 --> 00:19:10.990
please email me and if you see any bugs
or feature requests about tensor flow or

00:19:10.990 --> 00:19:11.000
or feature requests about tensor flow or
 

00:19:11.000 --> 00:19:13.120
or feature requests about tensor flow or
tensor boards you can follow the bugs on

00:19:13.120 --> 00:19:13.130
tensor boards you can follow the bugs on
 

00:19:13.130 --> 00:19:16.450
tensor boards you can follow the bugs on
these links thank you very much for your

00:19:16.450 --> 00:19:16.460
these links thank you very much for your
 

00:19:16.460 --> 00:19:16.930
these links thank you very much for your
attention

00:19:16.930 --> 00:19:16.940
attention
 

00:19:16.940 --> 00:19:17.710
attention
questions

00:19:17.710 --> 00:19:17.720
questions
 

00:19:17.720 --> 00:19:20.910
questions
[Applause]

