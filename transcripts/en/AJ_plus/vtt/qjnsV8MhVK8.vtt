WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.640
So-called fake news

00:00:01.640 --> 00:00:03.900
can have real-world consequences…

00:00:07.000 --> 00:00:08.360
This is an arms race.

00:00:08.360 --> 00:00:10.240
They’re going to keep getting better at this,

00:00:10.300 --> 00:00:12.320
and we need to invest in keeping on

00:00:12.380 --> 00:00:12.940
getting better at this, too.

00:00:19.540 --> 00:00:21.320
How much responsibility does Facebook have

00:00:21.320 --> 00:00:22.380
for the content on the platform?

00:00:22.440 --> 00:00:25.400
So Facebook knew that this was happening,

00:00:25.400 --> 00:00:27.360
and you’re saying that they were profiting?

00:00:36.000 --> 00:00:37.300
I'm Ahmed Shihab-Eldin,

00:00:37.300 --> 00:00:39.500
and this is a story about fake news

00:00:39.500 --> 00:00:41.560
and the people profiting from it.

00:00:41.560 --> 00:00:45.160
In the three months leading up to the 2016 U.S. election,

00:00:45.160 --> 00:00:47.980
viral fake news stories generated more total

00:00:47.980 --> 00:00:50.040
engagement on Facebook than those from the top

00:00:50.060 --> 00:00:52.740
19 major news outlets combined.

00:00:52.760 --> 00:00:55.880
Some of these fake stories came from an unlikely place

00:00:55.880 --> 00:00:58.240
-- the Republic of North Macedonia,

00:00:58.240 --> 00:01:00.380
a country of about two million people

00:01:00.380 --> 00:01:01.460
just north of Greece.

00:01:01.840 --> 00:01:04.940
There’s all these stories about guys over in Macedonia

00:01:04.940 --> 00:01:06.600
who are running these fake news sites.

00:01:06.600 --> 00:01:09.500
We found a lot of different accounts

00:01:09.500 --> 00:01:10.520
coming from Macedonia.

00:01:10.600 --> 00:01:12.440
Hundreds of pro-Trump websites

00:01:12.440 --> 00:01:14.180
popped up all over the country.

00:01:14.280 --> 00:01:15.480
And teenagers

00:01:15.480 --> 00:01:17.820
– particularly in one poor former factory town  –

00:01:17.820 --> 00:01:21.400
purportedly made millions by duping American news consumers

00:01:21.400 --> 00:01:24.180
on social media sites like Facebook.

00:01:24.700 --> 00:01:27.540
I came to Macedonia to find out what the fake news

00:01:27.540 --> 00:01:28.860
industry here is like

00:01:28.860 --> 00:01:30.460
amid a tech industry crackdown

00:01:30.460 --> 00:01:33.260
and reports that trolls are already preparing

00:01:33.260 --> 00:01:36.960
to cash in on the next U.S. elections.

00:01:41.740 --> 00:01:45.640
Saska Cvetkovska is an investigative journalist in Skopje,

00:01:45.640 --> 00:01:46.980
Macedonia’s capital.

00:01:46.980 --> 00:01:49.200
She says it’s not a coincidence that

00:01:49.320 --> 00:01:51.240
Macedonia has become one of the world’s

00:01:51.240 --> 00:01:53.000
fake news hubs.

00:01:53.000 --> 00:01:55.400
It has a young, tech-savvy population,

00:01:55.400 --> 00:01:57.940
an unemployment rate of over 20 percent

00:01:57.940 --> 00:02:00.000
and the recently ousted government

00:02:00.000 --> 00:02:02.920
regularly blasted fake news through state-run media.

00:02:13.520 --> 00:02:16.260
She is investigating who is funding the fake news

00:02:16.260 --> 00:02:17.400
factories in the country.

00:02:26.940 --> 00:02:29.400
At the center of Macedonia’s fake news industry

00:02:29.400 --> 00:02:31.700
is a man named Mirko Ceselkoski.

00:02:31.900 --> 00:02:34.780
He calls himself an Internet marketing consultant

00:02:34.780 --> 00:02:36.140
and Facebook strategist,

00:02:36.220 --> 00:02:39.240
though he’s been referred to as a clickbait coach.

00:02:39.420 --> 00:02:44.180
He says he’s taught over a thousand young people here how to make content for an American audience.

00:02:44.480 --> 00:02:47.180
You refer to yourself as the man who accidentally

00:02:47.180 --> 00:02:49.740
helped Donald Trump win the U.S. election.

00:03:04.580 --> 00:03:06.840
Mirko started making money on the Internet

00:03:06.840 --> 00:03:09.600
in the early 2000s by writing stories about yachts

00:03:09.600 --> 00:03:10.720
and muscle cars.

00:03:10.720 --> 00:03:13.080
He insists it was purely by accident

00:03:13.080 --> 00:03:15.360
that his students stumbled upon the money pot

00:03:15.360 --> 00:03:18.040
that is U.S. partisan politics.

00:03:18.580 --> 00:03:21.140
Here’s how this works: Create a simple website

00:03:21.140 --> 00:03:22.700
through a site like WordPress.

00:03:22.700 --> 00:03:25.360
Choose a domain name that sounds like a mainstream

00:03:25.360 --> 00:03:27.880
American news organization.

00:03:27.920 --> 00:03:30.400
Copy and paste stories from alt-right sites

00:03:30.400 --> 00:03:31.900
like Breitbart and InfoWars.

00:03:32.560 --> 00:03:36.000
Then create or buy Facebook profiles, pages and likes.

00:03:36.620 --> 00:03:39.120
When readers click through from Facebook to the websites,

00:03:39.120 --> 00:03:41.660
they’re hit with dozens of ads.

00:03:41.660 --> 00:03:44.360
With each click, the ad revenue begins pouring in

00:03:44.360 --> 00:03:46.100
through automated advertising engines,

00:03:46.100 --> 00:03:47.520
like Google AdSense.

00:03:48.120 --> 00:03:50.340
The secret ingredients for a viral hit:

00:03:53.440 --> 00:03:56.080
Did your students know much about the U.S.

00:03:56.200 --> 00:03:59.280
or U.S. politics before they started writing these stories?

00:04:12.700 --> 00:04:13.520
From America.

00:04:15.120 --> 00:04:18.360
Mirko says his students often hire freelance writers

00:04:18.360 --> 00:04:20.860
in the United States through websites like Upwork.

00:04:34.440 --> 00:04:35.200
That’s a lot of money.

00:04:36.540 --> 00:04:41.060
Do you feel that there’s a moral or ethical concern

00:04:41.060 --> 00:04:43.900
to be making money off of convincing millions

00:04:43.900 --> 00:04:46.580
of Americans that something is real,

00:04:46.580 --> 00:04:49.400
that can then affect how they vote?

00:04:56.620 --> 00:04:58.320
Facebook’s crackdown on fake news

00:04:58.320 --> 00:04:59.540
has been bad for business here.

00:04:59.980 --> 00:05:01.740
In 2020 for example,

00:05:01.740 --> 00:05:04.160
there’s another huge election in America.

00:05:04.160 --> 00:05:06.580
You think there will be people doing the same thing?

00:05:12.720 --> 00:05:14.340
After meeting Mirko,

00:05:14.340 --> 00:05:17.220
I traveled to a small town that has become the epicenter

00:05:17.220 --> 00:05:18.780
of the fake news industry here.

00:05:18.940 --> 00:05:20.800
I’m here in Veles, Macedonia,

00:05:20.800 --> 00:05:22.980
a former factory town where young people,

00:05:22.980 --> 00:05:24.660
if they’re lucky to have a job at all,

00:05:24.660 --> 00:05:27.320
rarely earn over 300 Euros a month,

00:05:27.320 --> 00:05:28.860
but where fake news factories

00:05:28.860 --> 00:05:31.540
are now making some of them very rich.

00:05:31.720 --> 00:05:34.520
I’m on my way to meet a young man named “Boris”

00:05:34.520 --> 00:05:37.340
who has learned from Mirko's methods

00:05:37.340 --> 00:05:40.000
and works in a content factory along with 20 others.

00:05:41.220 --> 00:05:42.900
We weren’t invited inside.

00:05:42.900 --> 00:05:46.100
Instead, he agreed to meet me at an Internet café.

00:05:47.000 --> 00:05:49.540
Boris has asked that we conceal his identity

00:05:49.540 --> 00:05:52.200
because he’s afraid of legal action from the U.S.

00:05:53.420 --> 00:05:54.320
He didn’t want to share

00:05:54.460 --> 00:05:55.920
just how much money he’s made,

00:05:55.980 --> 00:05:58.140
worried it might reveal his identity.

00:05:58.160 --> 00:06:00.320
Generally you work at night, right?

00:06:15.240 --> 00:06:17.480
What do you think about these Americans

00:06:17.480 --> 00:06:19.020
who were reading all this fake news,

00:06:19.020 --> 00:06:20.580
the stuff you were publishing?

00:06:30.120 --> 00:06:31.680
And how did you know what Americans wanted?

00:06:33.080 --> 00:06:35.920
What Boris told me next caught me by surprise.

00:06:42.820 --> 00:06:45.780
So Facebook knew that this was happening?

00:07:04.100 --> 00:07:07.040
Boris is saying that in the days before the election,

00:07:07.040 --> 00:07:09.780
the price for promoting content that was pro-Trump

00:07:09.780 --> 00:07:11.420
on the pages he was managing

00:07:11.420 --> 00:07:12.380
dropped significantly,

00:07:13.280 --> 00:07:15.560
so he went all in to heavily promote Trump.

00:07:15.900 --> 00:07:17.820
What are your plans in the next election?

00:07:24.600 --> 00:07:27.700
My time in Macedonia left me with a lot of questions.

00:07:27.700 --> 00:07:30.760
so I returned to the U.S. in search of answers.

00:07:31.320 --> 00:07:33.140
We came here to Facebook’s headquarters

00:07:33.140 --> 00:07:36.100
to find out what went wrong in the 2016 elections

00:07:36.100 --> 00:07:38.620
and what their plans are to protect the integrity

00:07:38.620 --> 00:07:40.620
of future elections in the U.S. and abroad.

00:07:41.240 --> 00:07:44.040
Monika Bickert is head of content policy at Facebook.

00:07:44.760 --> 00:07:47.780
This is definitely an area where we’ve made mistakes

00:07:47.780 --> 00:07:50.320
and where we’re investing a lot in getting better.

00:07:50.320 --> 00:07:53.060
If you look back to 2016,

00:07:53.060 --> 00:07:56.200
for instance, our tools that identify fake accounts

00:07:56.200 --> 00:07:58.120
weren’t as good then as they are now.

00:07:58.580 --> 00:08:00.480
We’ve come across a lot of accounts

00:08:00.480 --> 00:08:03.540
that are Macedonian and Russian accounts

00:08:03.540 --> 00:08:05.620
that seem dubious to us

00:08:05.800 --> 00:08:09.000
throughout the reporting process but they’re still active.

00:08:09.000 --> 00:08:10.340
We won’t always be perfect

00:08:10.340 --> 00:08:12.360
but I can tell you it’s absolutely a priority

00:08:12.360 --> 00:08:16.540
to proactively find and remove those types of accounts.

00:08:17.620 --> 00:08:19.220
In the lead-up to the French

00:08:19.220 --> 00:08:21.320
and German elections in 2017,

00:08:21.320 --> 00:08:24.140
Facebook removed tens of thousands of fake accounts.

00:08:24.760 --> 00:08:26.460
But the company announced recently

00:08:26.460 --> 00:08:28.840
that there may be as many as 87 million fake accounts

00:08:28.840 --> 00:08:31.040
still on the platform.

00:08:31.540 --> 00:08:33.660
Facebook is hiring thousands of people

00:08:33.660 --> 00:08:36.620
to review content, developing artificial intelligence

00:08:36.620 --> 00:08:38.260
to detect fake news and accounts,

00:08:39.080 --> 00:08:40.900
and trying to contextualize articles

00:08:40.900 --> 00:08:43.220
that have been flagged as potential fakes

00:08:43.220 --> 00:08:45.060
so users can decide for themselves.

00:08:45.740 --> 00:08:48.060
What would you say to American Facebook users

00:08:48.060 --> 00:08:50.040
who are concerned about fake news

00:08:50.040 --> 00:08:52.500
and how it might influence the midterm elections?

00:08:53.120 --> 00:08:54.880
Facebook certainly has a role to play

00:08:54.880 --> 00:08:57.980
in removing inauthentic actors,

00:08:57.980 --> 00:09:00.420
fake accounts, people who are intentionally

00:09:00.420 --> 00:09:03.780
sharing disinformation to sow discord.

00:09:04.060 --> 00:09:05.760
At the same time,

00:09:05.760 --> 00:09:08.720
there’s also more than we can be doing as a society

00:09:08.740 --> 00:09:12.240
to identify when something is likely fake.

00:09:12.260 --> 00:09:14.640
I asked her about Boris’s allegations

00:09:14.640 --> 00:09:17.000
that Facebook was profiting off of content like his.

00:09:17.300 --> 00:09:19.060
He claims that Facebook knew,

00:09:19.060 --> 00:09:22.460
whether it was an algorithm’s decision or a human’s,

00:09:22.660 --> 00:09:26.084
that the price was all of a sudden dramatically cheaper

00:09:26.084 --> 00:09:28.120
to promote Trump content.

00:09:28.200 --> 00:09:29.880
Well, for advertising prices,

00:09:29.880 --> 00:09:31.280
I’d have to follow up with you on

00:09:31.280 --> 00:09:32.520
exactly how we set those.

00:09:33.240 --> 00:09:35.980
But we didn't receive an explanation on the record

00:09:35.980 --> 00:09:36.880
from the company,

00:09:36.880 --> 00:09:39.200
despite repeated attempts to obtain one.

00:09:39.780 --> 00:09:42.880
Former Facebook employee Antonio Garcia-Martinez

00:09:42.880 --> 00:09:45.000
has his own take on Boris’s claims.

00:09:45.560 --> 00:09:47.840
He was a product manager who helped develop the

00:09:47.840 --> 00:09:51.860
platform’s advertising side and left the company in 2013.

00:09:52.000 --> 00:09:53.340
What do you make of that,

00:09:53.340 --> 00:09:54.820
because it can be coincidence…

00:09:54.820 --> 00:09:55.760
It may not be. It may not be.

00:09:55.920 --> 00:09:59.300
If you employ a certain inflammatory rhetoric

00:09:59.300 --> 00:10:00.820
that gets people engaged with your thing,

00:10:00.820 --> 00:10:03.600
then your net media cost will be lower.

00:10:03.600 --> 00:10:05.860
That is how Facebook is designed to work.

00:10:06.100 --> 00:10:08.440
But it’s kind of problematic.

00:10:08.440 --> 00:10:10.060
Right … they didn’t come up with this.

00:10:10.060 --> 00:10:11.381
Google does the same thing.

00:10:11.381 --> 00:10:13.820
But yeah, in this context, I think you’re right,

00:10:13.820 --> 00:10:14.560
that maybe it is problematic, yes.

00:10:15.100 --> 00:10:17.640
It seems like everyone benefited that was in that game.

00:10:17.720 --> 00:10:20.980
That’s right. That’s right. As did the Trump campaign.

00:10:21.060 --> 00:10:23.240
Antonio is critical of the company’s early attempts

00:10:23.240 --> 00:10:25.440
to minimize the fake news problem.

00:10:25.600 --> 00:10:31.400
Personally, I think the idea that

00:10:31.420 --> 00:10:35.920
fake news on Facebook influenced

00:10:35.920 --> 00:10:38.980
the election in any way I think is a pretty crazy idea.

00:10:39.400 --> 00:10:41.180
To discard the possibility that Facebook could actually

00:10:41.180 --> 00:10:43.920
swing the election so quickly is obviously really

00:10:43.920 --> 00:10:45.600
disingenuous and, frankly not true.

00:10:45.680 --> 00:10:46.180
Why?

00:10:46.440 --> 00:10:50.480
So literally until like 72 hours before the election,

00:10:50.480 --> 00:10:52.520
there was a huge political ads sales force, which Facebook has,

00:10:52.520 --> 00:10:56.300
telling every politician with a marketing budget

00:10:56.300 --> 00:10:57.380
exactly the opposite,

00:10:57.380 --> 00:10:59.760
that Facebook could deliver them the election.

00:10:59.760 --> 00:11:04.780
Antonio says that the reason this matters comes down to a simple but fundamental question.

00:11:04.780 --> 00:11:06.920
How much responsibility does Facebook have

00:11:06.920 --> 00:11:08.140
for the content on the platform?

00:11:08.140 --> 00:11:09.360
That really is the big question.

00:11:09.360 --> 00:11:12.080
So how does the company fix this problem?

00:11:12.080 --> 00:11:14.360
Trillion dollar question.

00:11:14.360 --> 00:11:15.660
I don’t know, and I don't think Facebook

00:11:15.680 --> 00:11:16.260
knows the answer to it, either.

00:11:16.720 --> 00:11:18.240
In his recent Senate hearing,

00:11:18.240 --> 00:11:20.660
Mark Zuckerberg addressed the challenge of staying

00:11:20.660 --> 00:11:23.940
ahead of fake news before it impacts future elections.

00:11:23.940 --> 00:11:25.960
This is an arms race, right?

00:11:25.960 --> 00:11:27.300
I mean, they’re going to keep on getting better at this,

00:11:27.300 --> 00:11:28.600
and we need to invest in

00:11:28.600 --> 00:11:30.000
keeping on getting better at this, too.

00:11:41.660 --> 00:11:42.740
Hey, It's Ahmed,

00:11:42.740 --> 00:11:45.280
so as you just saw, some fake news producers

00:11:45.280 --> 00:11:46.900
are financially motivated,

00:11:46.900 --> 00:11:48.860
but others have political ends in sight.

00:11:48.860 --> 00:11:51.300
Be sure to check out this video,

00:11:51.300 --> 00:11:53.100
we did an interview with an investigative journalist

00:11:53.100 --> 00:11:56.740
in Russia who went under cover in a troll farm.

