WEBVTT
Kind: captions
Language: en

00:00:05.852 --> 00:00:07.310
CLAY BAVOR: Good
morning, everyone.

00:00:07.310 --> 00:00:09.665
[APPLAUSE]

00:00:12.020 --> 00:00:13.020
Great to see you.

00:00:13.020 --> 00:00:14.090
Thanks for being here.

00:00:14.090 --> 00:00:17.480
I like the people in
the second section

00:00:17.480 --> 00:00:21.110
getting an update on VR
and AR and a good suntan

00:00:21.110 --> 00:00:21.920
at the same time.

00:00:21.920 --> 00:00:23.240
That's cool.

00:00:23.240 --> 00:00:25.400
Good job.

00:00:25.400 --> 00:00:28.627
So hopefully, you caught
the news yesterday

00:00:28.627 --> 00:00:29.460
in the main keynote.

00:00:29.460 --> 00:00:31.280
Great momentum with
apps on Daydream,

00:00:31.280 --> 00:00:33.620
more Daydream-ready
phones on the way,

00:00:33.620 --> 00:00:37.480
standalone VR headsets with
inside-out positional tracking.

00:00:37.480 --> 00:00:39.980
A super precise indoor
location service

00:00:39.980 --> 00:00:42.830
we call VPS, and then
an update to Expeditions

00:00:42.830 --> 00:00:44.820
that we're really excited about.

00:00:44.820 --> 00:00:46.070
So I'm going to be brief here.

00:00:46.070 --> 00:00:48.261
And in a minute, we'll
turn it over to the people

00:00:48.261 --> 00:00:49.760
on our team who are
actually leading

00:00:49.760 --> 00:00:52.490
many of the projects you're
going to hear about today.

00:00:52.490 --> 00:00:54.740
But before I do
that, I wanted to put

00:00:54.740 --> 00:00:59.090
what we're doing in VR and AR
at Google in context, put some

00:00:59.090 --> 00:01:02.270
of the puzzle pieces together
for you so that you can better

00:01:02.270 --> 00:01:05.030
understand why we're
doing what we're doing,

00:01:05.030 --> 00:01:08.679
and as developers, what
you can expect from us.

00:01:08.679 --> 00:01:10.220
So if you've followed
what we've been

00:01:10.220 --> 00:01:11.820
up to over the
past several years,

00:01:11.820 --> 00:01:14.150
you've seen a bunch
of different pieces--

00:01:14.150 --> 00:01:17.930
Cardboard, Daydream,
Tango, Jump, VR apps,

00:01:17.930 --> 00:01:19.440
like Earth and Tilt Brush.

00:01:19.440 --> 00:01:20.960
We're working in VR.

00:01:20.960 --> 00:01:23.390
We're doing some work in AR.

00:01:23.390 --> 00:01:24.390
What's going on here?

00:01:24.390 --> 00:01:26.610
How do you think about this?

00:01:26.610 --> 00:01:28.640
So first of all, terminology.

00:01:28.640 --> 00:01:31.070
Over the past year,
especially, I've

00:01:31.070 --> 00:01:34.950
seen so many debates about
VR versus AR, which is going

00:01:34.950 --> 00:01:38.300
to win, what vocab to use.

00:01:38.300 --> 00:01:41.240
And to us, these terms
don't represent two

00:01:41.240 --> 00:01:42.770
separate and distinct things.

00:01:42.770 --> 00:01:46.280
They're just labels for
different points on a spectrum.

00:01:46.280 --> 00:01:48.260
And for lack of
a better name, we

00:01:48.260 --> 00:01:51.230
call that the Spectrum
of Immersive Computing.

00:01:51.230 --> 00:01:53.244
Fully immersive is at the right.

00:01:53.244 --> 00:01:55.160
That's where everything
is computer generated.

00:01:55.160 --> 00:01:56.720
That's virtual reality.

00:01:56.720 --> 00:02:00.890
And real reality, like
this, is at the left end

00:02:00.890 --> 00:02:01.970
of the spectrum.

00:02:01.970 --> 00:02:04.460
And AR, and whatever other
terms you want to use,

00:02:04.460 --> 00:02:06.040
are somewhere in the middle.

00:02:06.040 --> 00:02:08.900
What's important to us is
not the specific labels,

00:02:08.900 --> 00:02:10.340
but it's this whole spectrum.

00:02:10.340 --> 00:02:12.950
And we're doing work across it.

00:02:12.950 --> 00:02:13.520
But why?

00:02:13.520 --> 00:02:14.360
Why invest in this?

00:02:14.360 --> 00:02:16.050
Why is it important?

00:02:16.050 --> 00:02:20.060
Well, VR, AR, Immersive
Computing-- these technologies

00:02:20.060 --> 00:02:23.180
matter because they enable
us to experience computing

00:02:23.180 --> 00:02:24.950
more like we experience
the real world.

00:02:24.950 --> 00:02:28.610
They enable computing
to work more like we do.

00:02:28.610 --> 00:02:29.906
And we think that's a big idea.

00:02:29.906 --> 00:02:31.280
We think that's
really important.

00:02:31.280 --> 00:02:33.980
Because every time
computers have

00:02:33.980 --> 00:02:38.210
started to work more like we
do, good things have happened.

00:02:38.210 --> 00:02:41.450
If you think about moving from
punch cards to the command line

00:02:41.450 --> 00:02:45.740
to the GUI to touch screens,
with every progression,

00:02:45.740 --> 00:02:49.580
we became more able, more
capable with our computers.

00:02:49.580 --> 00:02:52.820
And we think VR and AR will
push this even further.

00:02:52.820 --> 00:02:54.830
They open up access to
an entirely new kind

00:02:54.830 --> 00:02:57.980
of information, a kind of
experiential information,

00:02:57.980 --> 00:03:01.280
or information that's anchored
physically to the real world.

00:03:01.280 --> 00:03:03.680
And we think this progression
is going to be powerful.

00:03:03.680 --> 00:03:07.520
And in time, it's going to
change how we work and play

00:03:07.520 --> 00:03:09.380
and live and learn.

00:03:09.380 --> 00:03:12.990
And we want to help push
this forward in two ways.

00:03:12.990 --> 00:03:15.020
So first, platforms.

00:03:15.020 --> 00:03:17.920
Just as Chrome made the
web faster, more secure,

00:03:17.920 --> 00:03:21.140
more powerful, and as Android
made mobile computing more

00:03:21.140 --> 00:03:24.110
widely available, we hope
that platforms like Daydream

00:03:24.110 --> 00:03:27.800
can push forward VR
and other technologies.

00:03:27.800 --> 00:03:29.720
And our goal here is
really to raise all boats

00:03:29.720 --> 00:03:32.360
by doing a lot of the heavy
lifting in the core system

00:03:32.360 --> 00:03:36.620
software, device standards,
reference hardware, and SDKs.

00:03:36.620 --> 00:03:40.242
And the second part
is building blocks.

00:03:40.242 --> 00:03:42.200
And by these, I mean the
enabling technologies,

00:03:42.200 --> 00:03:45.740
like Tango, Web VR, our
Jump VR Video Capture

00:03:45.740 --> 00:03:48.035
System, code samples, and more.

00:03:48.035 --> 00:03:49.550
And we also think
of the apps we've

00:03:49.550 --> 00:03:52.910
built, like Tilt Brush or
Earth VR or Expeditions,

00:03:52.910 --> 00:03:54.920
as building blocks
in that they're

00:03:54.920 --> 00:03:58.940
early examples of VR apps to
look at and to learn from.

00:03:58.940 --> 00:04:03.140
So this morning is about exactly
these two things, platforms

00:04:03.140 --> 00:04:04.670
and building blocks.

00:04:04.670 --> 00:04:06.500
And with that, I'd
like to turn it over

00:04:06.500 --> 00:04:08.810
to Johnny Lee, the founder
of the Tango project,

00:04:08.810 --> 00:04:11.600
to talk about one of our most
important building blocks.

00:04:11.600 --> 00:04:12.400
Thanks.

00:04:12.400 --> 00:04:14.750
[APPLAUSE]

00:04:17.110 --> 00:04:18.890
JOHNNY LEE: Hi, everyone.

00:04:18.890 --> 00:04:20.620
It's great to be here.

00:04:20.620 --> 00:04:21.880
My name is Johnny Lee.

00:04:21.880 --> 00:04:24.520
I'm the engineering
director of Tango.

00:04:24.520 --> 00:04:28.930
In 2013, a small group of us
got together with a belief

00:04:28.930 --> 00:04:32.890
that one day, our devices would
be able to sense 3D motion

00:04:32.890 --> 00:04:35.356
and space just like we can.

00:04:35.356 --> 00:04:36.730
And so with the
right combination

00:04:36.730 --> 00:04:40.600
of hardware and software,
Tango can give our devices

00:04:40.600 --> 00:04:43.510
this 3D sense of
motion-sensing capabilities,

00:04:43.510 --> 00:04:45.760
as well as the
ability to recognize

00:04:45.760 --> 00:04:48.020
places it's been before.

00:04:48.020 --> 00:04:50.920
And so this establishes
a shared sense

00:04:50.920 --> 00:04:55.270
of space and physical movement
between people and our devices.

00:04:55.270 --> 00:04:57.430
And it allowed us to
begin creating experiences

00:04:57.430 --> 00:05:00.220
that gave us an early
glimpse into how

00:05:00.220 --> 00:05:04.330
we could interact with digital
content in a physical way.

00:05:04.330 --> 00:05:06.940
Today, four years
later, we're starting

00:05:06.940 --> 00:05:10.775
to see new genre products
and both AR and VR that

00:05:10.775 --> 00:05:15.430
put 3D tracking and sensing as
a fundamental part of the user

00:05:15.430 --> 00:05:16.640
experience.

00:05:16.640 --> 00:05:20.830
And so Tango has evolved into
an enabling technology that's

00:05:20.830 --> 00:05:24.430
powering everything we're
doing within Daydream.

00:05:24.430 --> 00:05:26.770
Yesterday, you heard Clay
talk about our support

00:05:26.770 --> 00:05:28.870
for standalone VR headsets.

00:05:28.870 --> 00:05:31.150
And by building all the
hardware into the headset

00:05:31.150 --> 00:05:33.610
and taking advantage of
years of optimization work

00:05:33.610 --> 00:05:37.510
with Qualcomm, mobile
processors, low-cost tracking

00:05:37.510 --> 00:05:39.490
sensors, we can
enable a headset that

00:05:39.490 --> 00:05:41.410
responds to the
movement of the user's

00:05:41.410 --> 00:05:44.800
head, similar to desktop
VR systems we see today,

00:05:44.800 --> 00:05:47.020
but without all the
cables and setup.

00:05:47.020 --> 00:05:50.081
And we call this
technology WorldSense.

00:05:50.081 --> 00:05:52.330
And it's a version of Tango
that we've been working on

00:05:52.330 --> 00:05:54.010
specifically for VR.

00:05:54.010 --> 00:05:55.930
So let me show you a
little bit about how

00:05:55.930 --> 00:05:57.950
it works in a headset.

00:05:57.950 --> 00:05:59.710
There's two wide-angle
cameras that

00:05:59.710 --> 00:06:02.230
detect the movement of
features in the room.

00:06:02.230 --> 00:06:04.300
And these features
might be things

00:06:04.300 --> 00:06:07.270
like the corners of a
desk, items on the table,

00:06:07.270 --> 00:06:08.890
or texture on the floor.

00:06:08.890 --> 00:06:11.530
And it tracks the movement
of these features over time

00:06:11.530 --> 00:06:14.260
to get a sense of its
position in the room.

00:06:14.260 --> 00:06:17.500
We then tightly couple this
visual motion information

00:06:17.500 --> 00:06:19.360
with the motion
sensors on the phone

00:06:19.360 --> 00:06:22.600
to provide robust, low-latency
positional tracking.

00:06:22.600 --> 00:06:25.450
And we give this information
to games and applications

00:06:25.450 --> 00:06:27.700
all in less than
five milliseconds,

00:06:27.700 --> 00:06:29.800
achieving an overall
display latency

00:06:29.800 --> 00:06:31.902
of around 20 milliseconds.

00:06:31.902 --> 00:06:33.610
At the same time, the
system is building,

00:06:33.610 --> 00:06:36.040
of course, a 3D
model of the scene,

00:06:36.040 --> 00:06:37.870
recognizing features
it's seen before so

00:06:37.870 --> 00:06:42.160
that it can correct any drift
that may occur over time.

00:06:42.160 --> 00:06:44.320
You may have heard this
referred to as SLAM,

00:06:44.320 --> 00:06:47.320
or Simultaneous
Localization and Mapping.

00:06:47.320 --> 00:06:50.170
So that's a high-level
review of what WorldSense is.

00:06:50.170 --> 00:06:51.970
It eliminates one of
the major differences

00:06:51.970 --> 00:06:55.960
between desktop and
mobile VR today.

00:06:55.960 --> 00:06:59.290
Now, in smartphone
AR, AR applications

00:06:59.290 --> 00:07:02.427
require sensing even
more of the environment

00:07:02.427 --> 00:07:04.510
to be able to place digital
objects in front of us

00:07:04.510 --> 00:07:07.700
accurately enough to seem as
though they physically exist.

00:07:07.700 --> 00:07:10.510
And today, Tango phones
use additional sensors

00:07:10.510 --> 00:07:13.950
to enable a richer set of
augmented reality experiences

00:07:13.950 --> 00:07:16.990
than is possible with
a standard phone.

00:07:16.990 --> 00:07:19.240
We have a dedicated
depth sensor that

00:07:19.240 --> 00:07:22.330
allows games to understand the
difference between the floor,

00:07:22.330 --> 00:07:24.490
the table, and the
walls, and even

00:07:24.490 --> 00:07:27.490
lets the characters hide
behind things like couches.

00:07:27.490 --> 00:07:29.780
We have a wide-angle
camera for tracking

00:07:29.780 --> 00:07:32.640
that gives us the best view
of the features in the room,

00:07:32.640 --> 00:07:35.560
allowing very robust positional
tracking in the phone.

00:07:35.560 --> 00:07:37.330
And this also
improves our ability

00:07:37.330 --> 00:07:40.090
to quickly re-localize
so we can recognize where

00:07:40.090 --> 00:07:43.000
we are in the room, letting
you see AR content that

00:07:43.000 --> 00:07:46.300
was set there before or
even left by other people.

00:07:46.300 --> 00:07:48.970
So to give you an example
of the kind of experiences

00:07:48.970 --> 00:07:51.910
that you can do with all
this technology put together,

00:07:51.910 --> 00:07:53.770
I wanted to share
with you this project

00:07:53.770 --> 00:07:56.170
that we've been doing with
the Singapore Art and Science

00:07:56.170 --> 00:07:56.670
Museum.

00:08:00.700 --> 00:08:02.210
Do we have audio for the video?

00:08:02.210 --> 00:08:04.406
[VIDEO PLAYBACK]

00:08:04.406 --> 00:08:06.030
SPEAKER 1: Most people
living in cities

00:08:06.030 --> 00:08:08.580
have never been to a rainforest.

00:08:08.580 --> 00:08:11.130
So we decided to bring
a rainforest to a city

00:08:11.130 --> 00:08:14.010
and make it accessible
for everyone.

00:08:14.010 --> 00:08:17.230
For that, we needed a
new mobile technology.

00:08:17.230 --> 00:08:21.420
We were able to map 10,000
square feet of a museum space

00:08:21.420 --> 00:08:24.800
into a rainforest.

00:08:24.800 --> 00:08:26.790
Visitors experienced
what it's like to walk

00:08:26.790 --> 00:08:29.790
through a rainforest, learned
about endangered animals

00:08:29.790 --> 00:08:31.680
threatened by
deforestation and were

00:08:31.680 --> 00:08:33.100
tasked to plant a virtual tree.

00:08:36.149 --> 00:08:38.190
SPEAKER 2: We were able
to launch this experience

00:08:38.190 --> 00:08:42.240
on the first Tango-enabled
device, the Lenovo Phab 2 Pro,

00:08:42.240 --> 00:08:46.170
and bring AR at scale to
everyone, making "Into The

00:08:46.170 --> 00:08:48.750
Wild" the largest AR
experience in the world.

00:08:54.034 --> 00:08:55.700
JOHNNY LEE: So sorry
about missing the--

00:08:55.700 --> 00:08:56.690
oh, yeah, thanks.

00:08:56.690 --> 00:08:59.010
[APPLAUSE]

00:09:01.330 --> 00:09:03.670
So the exhibit actually
allows thousands of visitors

00:09:03.670 --> 00:09:06.762
to come and experience
a digital rainforest.

00:09:06.762 --> 00:09:09.220
And when they pledge a donation
to the World Wildlife Fund,

00:09:09.220 --> 00:09:11.530
they actually are
allowed to plant a tree,

00:09:11.530 --> 00:09:14.770
and other visitors can see
that tree grow in the museum.

00:09:14.770 --> 00:09:17.230
And the rainforest starts
to expand over time

00:09:17.230 --> 00:09:19.930
as visitors see the exhibit.

00:09:19.930 --> 00:09:21.940
We're still in the
early days of seeing

00:09:21.940 --> 00:09:24.010
how these experiences
will evolve,

00:09:24.010 --> 00:09:28.480
so this is just a glimpse
into what's possible today.

00:09:28.480 --> 00:09:30.910
The first phone featuring
Tango-enabled capabilities

00:09:30.910 --> 00:09:34.630
was the Lenovo Phab 2 Pro,
which hit shelves last fall.

00:09:34.630 --> 00:09:37.810
Our second phone is the
ZenFone AR from ASUS.

00:09:37.810 --> 00:09:40.097
And I'm really glad to
announce that customers

00:09:40.097 --> 00:09:41.680
will be able to
experience the ZenFone

00:09:41.680 --> 00:09:44.140
in Verizon stores
across the United States

00:09:44.140 --> 00:09:45.590
later this summer.

00:09:45.590 --> 00:09:47.050
And over the next
year, you'll see

00:09:47.050 --> 00:09:50.160
us bring Tango functionality
to many, many more phones.

00:09:50.160 --> 00:09:53.851
And we really just believe
this is the beginning.

00:09:53.851 --> 00:09:55.600
We've seen a variety
of great applications

00:09:55.600 --> 00:09:57.340
begin to appear
that take advantage

00:09:57.340 --> 00:09:59.680
of these new capabilities.

00:09:59.680 --> 00:10:01.240
For example, we
have tools that can

00:10:01.240 --> 00:10:03.650
help you measure the
size of the table in case

00:10:03.650 --> 00:10:07.030
you're interested in buying
one for your dining room.

00:10:07.030 --> 00:10:08.620
Or you can do things
like walk around

00:10:08.620 --> 00:10:11.920
your house with the tracking
sensors and the depth sensor

00:10:11.920 --> 00:10:15.070
to generate a heat map of
the Wi-Fi signal strength

00:10:15.070 --> 00:10:16.990
within your apartment
or in the building.

00:10:16.990 --> 00:10:20.350
And this actually lets
you help find dead spots,

00:10:20.350 --> 00:10:22.130
or where you might
want to put the router,

00:10:22.130 --> 00:10:24.700
or even buy a repeater.

00:10:24.700 --> 00:10:27.280
You can even use estimate
the square footage

00:10:27.280 --> 00:10:29.047
of your apartment,
which might actually

00:10:29.047 --> 00:10:31.630
come in handy if you're thinking
about moving into a new place

00:10:31.630 --> 00:10:35.000
or even renegotiating your rent.

00:10:35.000 --> 00:10:37.270
There's games like
"World" by Phenomena

00:10:37.270 --> 00:10:41.140
which allow you to carry
a toy box in your pocket.

00:10:41.140 --> 00:10:43.810
And yesterday, you heard about
the Visual Positioning Service

00:10:43.810 --> 00:10:47.140
from Clay, which opens
up many new experiences

00:10:47.140 --> 00:10:51.160
around indoor location
and navigation.

00:10:51.160 --> 00:10:52.780
With the permission
of each venue,

00:10:52.780 --> 00:10:54.940
we use the wide-angle
camera in the Tango phone

00:10:54.940 --> 00:10:57.500
to give us a broad view
of the environment.

00:10:57.500 --> 00:11:00.010
And this allows us to generate
large-scale descriptions

00:11:00.010 --> 00:11:01.180
of the space.

00:11:01.180 --> 00:11:04.120
And this enables
centimeter-scale accurate

00:11:04.120 --> 00:11:06.410
positioning within the building.

00:11:06.410 --> 00:11:07.360
It's a lot like GPS.

00:11:07.360 --> 00:11:09.100
But rather than
talking to satellites

00:11:09.100 --> 00:11:11.260
1,000 miles above
the Earth, it's

00:11:11.260 --> 00:11:13.180
using features that are
just a few feet away

00:11:13.180 --> 00:11:15.015
to calculate its position.

00:11:15.015 --> 00:11:17.140
This is what we actually
use in the Art and Science

00:11:17.140 --> 00:11:21.010
Museum that allows us to anchor
trees in the environment.

00:11:21.010 --> 00:11:24.250
In stores like
Lowe's, it can get

00:11:24.250 --> 00:11:26.740
you walking directions
directly to an item sitting

00:11:26.740 --> 00:11:28.160
on the shelf.

00:11:28.160 --> 00:11:30.340
We're still in the
early days of what

00:11:30.340 --> 00:11:32.840
we feel like will be possible
with these technologies,

00:11:32.840 --> 00:11:34.540
and it lets us see
things in new ways

00:11:34.540 --> 00:11:37.250
that we couldn't see before.

00:11:37.250 --> 00:11:40.270
So it helps us learn more
about the environment.

00:11:40.270 --> 00:11:43.300
It helps us find our way through
spaces and share knowledge

00:11:43.300 --> 00:11:46.780
with other people in a
physical and visual medium.

00:11:46.780 --> 00:11:48.760
But one of the
things it helps us do

00:11:48.760 --> 00:11:51.910
is learn better, especially when
we are able to make connections

00:11:51.910 --> 00:11:53.860
with those who are
seeing the same thing

00:11:53.860 --> 00:11:57.070
at the same time from their
own unique perspective.

00:11:57.070 --> 00:11:59.530
And in this way, the
power of AR isn't

00:11:59.530 --> 00:12:02.170
in just adding digital objects
to the camera view in front

00:12:02.170 --> 00:12:05.950
of us, but in adding shared
meaning to the interaction

00:12:05.950 --> 00:12:07.340
between people.

00:12:07.340 --> 00:12:10.630
So to tell you more about
how shared AR experiences can

00:12:10.630 --> 00:12:13.577
help in a classroom, let
me hand off to Jen Holland.

00:12:13.577 --> 00:12:14.551
Thanks.

00:12:14.551 --> 00:12:17.473
[APPLAUSE]

00:12:20.369 --> 00:12:21.660
JENNIFER HOLLAND: Hi, everyone.

00:12:21.660 --> 00:12:23.470
Thanks, Johnny.

00:12:23.470 --> 00:12:26.410
I'm Jennifer Holland, and I'm
the education program manager

00:12:26.410 --> 00:12:28.060
on Daydream.

00:12:28.060 --> 00:12:31.870
Johnny shared some updates
about the applications of Tango,

00:12:31.870 --> 00:12:34.270
as well as areas
where we think AR can

00:12:34.270 --> 00:12:37.570
have a big immediate impact.

00:12:37.570 --> 00:12:40.510
Education is just
one of those areas.

00:12:40.510 --> 00:12:43.750
And my team took advantage
of Tango's sensor stack

00:12:43.750 --> 00:12:46.630
and built a tool for
schools so that teachers

00:12:46.630 --> 00:12:48.190
could create
immersive experiences

00:12:48.190 --> 00:12:49.780
with their students.

00:12:49.780 --> 00:12:51.700
And that's the same
technology that's actually

00:12:51.700 --> 00:12:54.880
available to all of you.

00:12:54.880 --> 00:12:59.020
Two years ago, we
launched Expeditions VR.

00:12:59.020 --> 00:13:01.750
And we've built
more than 600 tours,

00:13:01.750 --> 00:13:04.150
and we've heard from
thousands of kids

00:13:04.150 --> 00:13:06.160
from around the world
who have sent us

00:13:06.160 --> 00:13:12.130
personal letters sharing how
Expeditions has inspired them.

00:13:12.130 --> 00:13:14.170
We've learned a great
deal from talking

00:13:14.170 --> 00:13:16.750
to the over 2 million
teachers and students

00:13:16.750 --> 00:13:18.880
who have actually used it.

00:13:18.880 --> 00:13:22.150
And one of the most important
things that my team learned

00:13:22.150 --> 00:13:25.210
was that you really need to
embrace the key functions

00:13:25.210 --> 00:13:26.590
of a classroom.

00:13:26.590 --> 00:13:29.710
That is, students
engaging, interacting,

00:13:29.710 --> 00:13:34.440
and learning with each other,
as well as their teacher.

00:13:34.440 --> 00:13:36.670
Tango's camera and
sensor are what

00:13:36.670 --> 00:13:40.240
makes this interaction
possible in real time.

00:13:40.240 --> 00:13:43.030
And no, I promise you
those kids are not

00:13:43.030 --> 00:13:46.870
taking selfies in their class.

00:13:46.870 --> 00:13:50.530
Teachers are able to accurately
map the physical classroom

00:13:50.530 --> 00:13:54.130
and place 3D objects, like
one of Michelangelo's statues,

00:13:54.130 --> 00:13:57.400
right on the student's desks
so that all students can

00:13:57.400 --> 00:14:01.210
look at the statue
together in real time.

00:14:01.210 --> 00:14:03.520
Students can move the
Tango-enabled phone

00:14:03.520 --> 00:14:06.220
to get up close
to see the detail

00:14:06.220 --> 00:14:09.190
or take a step back to
get a sense of the scale

00:14:09.190 --> 00:14:12.010
and be able to point out new
discoveries on the statue

00:14:12.010 --> 00:14:14.170
together.

00:14:14.170 --> 00:14:17.650
And that's powerful because
it's not each individual student

00:14:17.650 --> 00:14:21.760
looking at their own object,
like a whirling category 5

00:14:21.760 --> 00:14:22.960
hurricane.

00:14:22.960 --> 00:14:25.090
It's as if you actually
brought the hurricane

00:14:25.090 --> 00:14:27.770
into the classroom.

00:14:27.770 --> 00:14:32.260
Students can view any object,
from a strand of DNA to one

00:14:32.260 --> 00:14:34.480
of Saturn's rings, together.

00:14:34.480 --> 00:14:36.580
And those objects
don't disappear

00:14:36.580 --> 00:14:38.950
when the students look away.

00:14:38.950 --> 00:14:40.540
And a teacher is
able to point out

00:14:40.540 --> 00:14:45.630
specific things on the
object to suit the lesson.

00:14:45.630 --> 00:14:49.110
Just think how cool it
would be for a teacher

00:14:49.110 --> 00:14:52.110
to transform their
entire classroom

00:14:52.110 --> 00:14:55.890
into a world-class art
museum and display the works

00:14:55.890 --> 00:15:00.000
of van Gogh, Monet, or
even the "Mona Lisa" right

00:15:00.000 --> 00:15:03.180
on the same classroom walls.

00:15:03.180 --> 00:15:05.670
As an education
product team, we're

00:15:05.670 --> 00:15:08.350
committed to leveraging
the same Tango

00:15:08.350 --> 00:15:12.270
technology available to you
and tweaking it slightly

00:15:12.270 --> 00:15:14.520
to give teachers
a tool to create

00:15:14.520 --> 00:15:19.860
immersive experiences each and
every day in their classroom.

00:15:19.860 --> 00:15:22.590
And just like we did
with Expeditions VR,

00:15:22.590 --> 00:15:25.620
we're going to be bringing this
tool to schools through the AR

00:15:25.620 --> 00:15:27.680
Expeditions Pioneer Program.

00:15:27.680 --> 00:15:31.380
And schools can sign up if
they're interested for a visit.

00:15:31.380 --> 00:15:34.380
And if you're a developer
really excited about building

00:15:34.380 --> 00:15:37.620
AR lessons with us, let us
know by expressing interest

00:15:37.620 --> 00:15:39.960
on our partner page.

00:15:39.960 --> 00:15:42.150
That's Expeditions AR.

00:15:42.150 --> 00:15:45.270
That is just one thing
that you can do with Tango.

00:15:45.270 --> 00:15:49.260
And we're really excited to see
what all of you come up with.

00:15:49.260 --> 00:15:52.680
Now, let's switch gears
and talk about another part

00:15:52.680 --> 00:15:55.020
of the Immersive
Computing Spectrum.

00:15:55.020 --> 00:15:58.140
Let me welcome Mike to tell
you the latest about Daydream,

00:15:58.140 --> 00:16:01.670
our platform for
high-performance mobile VR.

00:16:01.670 --> 00:16:04.045
[APPLAUSE]

00:16:06.780 --> 00:16:07.530
MIKE JAZAYERI: Hi.

00:16:07.530 --> 00:16:08.589
Good morning, everyone.

00:16:08.589 --> 00:16:11.130
I'm Mike Jazayeri, and I'm the
director of product management

00:16:11.130 --> 00:16:12.200
for Daydream.

00:16:12.200 --> 00:16:14.790
Daydream serves as the
foundation of our investments

00:16:14.790 --> 00:16:16.350
in immersive computing.

00:16:16.350 --> 00:16:18.900
We began working on
Daydream in 2015,

00:16:18.900 --> 00:16:20.280
with the initial
goal of bringing

00:16:20.280 --> 00:16:23.610
high-performance
smartphone VR to Android.

00:16:23.610 --> 00:16:26.640
Today, I'm excited to tell you
about what's next for Daydream.

00:16:26.640 --> 00:16:29.560
But first, a quick refresher
on how we got here.

00:16:29.560 --> 00:16:32.130
So the first version of
Daydream launched in November

00:16:32.130 --> 00:16:34.410
and was built on
three core elements--

00:16:34.410 --> 00:16:37.800
the Daydream-ready specs for
phones, a high-performance VR

00:16:37.800 --> 00:16:40.560
mode in Android N, and
of course, the Daydream

00:16:40.560 --> 00:16:44.160
experience, including
Play Store in VR.

00:16:44.160 --> 00:16:46.350
We promised to create
a large ecosystem

00:16:46.350 --> 00:16:47.670
of Daydream-ready devices.

00:16:47.670 --> 00:16:50.250
And I'm very proud to say
that in just six months,

00:16:50.250 --> 00:16:53.280
there are eight Daydream-ready
devices on market.

00:16:53.280 --> 00:16:57.840
And as Clay announced yesterday,
Samsung's flagship S8 and S8

00:16:57.840 --> 00:17:00.120
Plus will soon be
Daydream-ready,

00:17:00.120 --> 00:17:01.810
with an update
coming this summer.

00:17:01.810 --> 00:17:03.310
They're fantastic
phones, and you're

00:17:03.310 --> 00:17:06.220
going to love the Daydream
experience on them.

00:17:06.220 --> 00:17:07.440
But that's not all.

00:17:07.440 --> 00:17:10.109
LG's next flagship
phone, launching

00:17:10.109 --> 00:17:14.040
in the second half of this year,
will also be Daydream-ready.

00:17:14.040 --> 00:17:15.960
In addition to
these new partners,

00:17:15.960 --> 00:17:19.200
existing partners,
including Motorola and ASUS,

00:17:19.200 --> 00:17:21.240
will have more
Daydream-ready phones.

00:17:21.240 --> 00:17:22.740
So when you put
all that together,

00:17:22.740 --> 00:17:25.429
there will be tens of millions
of Daydream-ready phones

00:17:25.429 --> 00:17:27.220
in consumers' hands by
the end of the year.

00:17:27.220 --> 00:17:28.595
I think that's a
really big deal.

00:17:28.595 --> 00:17:30.754
And I want to thank our
partners, who've been

00:17:30.754 --> 00:17:31.920
working really hard on that.

00:17:31.920 --> 00:17:33.870
[APPLAUSE]

00:17:33.870 --> 00:17:34.880
So that's the start.

00:17:34.880 --> 00:17:37.170
Now let's talk about
what's coming next.

00:17:37.170 --> 00:17:39.700
This year at Google I/O, we're
announcing two major updates

00:17:39.700 --> 00:17:41.050
to Daydream.

00:17:41.050 --> 00:17:43.710
The first is support
for a brand new category

00:17:43.710 --> 00:17:45.300
of standalone headsets.

00:17:45.300 --> 00:17:49.470
And second is a major update to
the Daydream software platform.

00:17:49.470 --> 00:17:53.130
We're going to call this 2.0
release Daydream Euphrates.

00:17:53.130 --> 00:17:56.100
Let's talk about both, and
let's start with headsets.

00:17:56.100 --> 00:17:58.500
So as Clay announced yesterday,
the standalone headset

00:17:58.500 --> 00:18:02.580
takes everything that we
love about smartphone VR

00:18:02.580 --> 00:18:04.200
and makes it even better.

00:18:04.200 --> 00:18:05.820
All you need for
VR-- the software,

00:18:05.820 --> 00:18:08.250
the hardware-- is in
one integrated device.

00:18:08.250 --> 00:18:11.330
It's much more immersive
because of WorldSense.

00:18:11.330 --> 00:18:13.360
And you can get into
VR in just seconds.

00:18:13.360 --> 00:18:15.360
You just put the headset
on, you're ready to go.

00:18:15.360 --> 00:18:18.960
No extra wires, PCs,
or setup required.

00:18:18.960 --> 00:18:20.700
Now, for these
standalone headsets,

00:18:20.700 --> 00:18:23.460
we wanted to create a
large ecosystem of devices

00:18:23.460 --> 00:18:26.770
and of content, and doing
so requires great hardware.

00:18:26.770 --> 00:18:28.650
So we've partnered
deeply with Qualcomm

00:18:28.650 --> 00:18:31.260
to create a reference
standalone headset.

00:18:31.260 --> 00:18:35.580
This is featuring this powerful
Snapdragon 835 chipset,

00:18:35.580 --> 00:18:37.530
custom-designed
tracking cameras,

00:18:37.530 --> 00:18:39.357
and high-performance sensors.

00:18:39.357 --> 00:18:41.190
Now, those tracking
cameras are particularly

00:18:41.190 --> 00:18:43.680
important because they enable
a much more immersive VR

00:18:43.680 --> 00:18:47.475
experience with WorldSense,
which Johnny just talked about.

00:18:47.475 --> 00:18:49.600
But a reference headset
isn't all that we're doing.

00:18:49.600 --> 00:18:51.810
We're also partnering with
two leading device makers

00:18:51.810 --> 00:18:54.240
to actually bring these
headsets to market starting

00:18:54.240 --> 00:18:56.490
at the end of the year.

00:18:56.490 --> 00:18:59.820
HTC really needs no
introduction in the world of VR.

00:18:59.820 --> 00:19:02.767
They're already a leader in this
space with the Vive headset.

00:19:02.767 --> 00:19:04.350
They're going to
bring their expertise

00:19:04.350 --> 00:19:07.500
in headset design, optics, and
building high-performance VR

00:19:07.500 --> 00:19:09.780
systems to Daydream.

00:19:09.780 --> 00:19:11.850
Our other partner is Lenovo.

00:19:11.850 --> 00:19:14.460
And they've been a
longtime partner of ours.

00:19:14.460 --> 00:19:16.560
And we worked together
to bring this first Tango

00:19:16.560 --> 00:19:17.670
phone to market.

00:19:17.670 --> 00:19:19.200
So they're already
a pioneer in AR,

00:19:19.200 --> 00:19:21.450
and they're going to bring
that same pioneering spirit

00:19:21.450 --> 00:19:23.010
to Daydream.

00:19:23.010 --> 00:19:24.540
So that's standalone headsets.

00:19:24.540 --> 00:19:27.892
But powerful hardware also
requires powerful software.

00:19:27.892 --> 00:19:29.850
And that's where the next
version of Daydream--

00:19:29.850 --> 00:19:31.710
Daydream Euphrates-- comes in.

00:19:31.710 --> 00:19:33.960
We focused on three
things for this release.

00:19:33.960 --> 00:19:35.730
First is all the
software support

00:19:35.730 --> 00:19:37.830
you need for
standalone headsets.

00:19:37.830 --> 00:19:41.070
Second is making VR content
front and center, the content

00:19:41.070 --> 00:19:44.460
that you've built. And third
is making it easy for users

00:19:44.460 --> 00:19:46.644
to share that VR content
with friends and family,

00:19:46.644 --> 00:19:48.060
whether they're
sitting right next

00:19:48.060 --> 00:19:49.660
to them or around the world.

00:19:49.660 --> 00:19:51.690
So let's talk about each one.

00:19:51.690 --> 00:19:53.280
Daydream Euphrates
takes advantage

00:19:53.280 --> 00:19:57.180
of even deeper support for
VR that's in Android O--

00:19:57.180 --> 00:19:58.890
in particular, the
capabilities needed

00:19:58.890 --> 00:20:00.900
to support standalone headsets.

00:20:00.900 --> 00:20:04.374
So if you think
about it, Android

00:20:04.374 --> 00:20:05.790
has been designed
for devices that

00:20:05.790 --> 00:20:08.400
primarily run touchscreens.

00:20:08.400 --> 00:20:11.520
But a standalone headset, by
definition, has no touchscreen.

00:20:11.520 --> 00:20:14.130
So we've had to build a
new VR window manager deep

00:20:14.130 --> 00:20:16.110
into Android so that
we have an operating

00:20:16.110 --> 00:20:20.712
system where all the system
UI will be accessible in VR.

00:20:20.712 --> 00:20:22.170
Also with Daydream
Euphrates, we're

00:20:22.170 --> 00:20:25.440
updating the Daydream home
experience for both smartphones

00:20:25.440 --> 00:20:27.270
and standalone headsets.

00:20:27.270 --> 00:20:29.460
First, we're going to
make it easy to discover

00:20:29.460 --> 00:20:30.780
the best content in VR.

00:20:30.780 --> 00:20:33.780
You'll see a curated list of
continuously updated stream

00:20:33.780 --> 00:20:35.970
of content with
thematic collections,

00:20:35.970 --> 00:20:39.120
mixing together thousands of
videos, experiences, games,

00:20:39.120 --> 00:20:40.147
and apps.

00:20:40.147 --> 00:20:41.730
Now, once you're in
the VR experience,

00:20:41.730 --> 00:20:43.688
we don't want to break
that sense of immersion.

00:20:43.688 --> 00:20:46.680
So Daydream Euphrates
also has a new dashboard

00:20:46.680 --> 00:20:48.900
that embraces the
immersive nature of VR

00:20:48.900 --> 00:20:51.000
and appears right
on top of any app.

00:20:51.000 --> 00:20:54.277
It's superfast to load
and lets you stay in VR.

00:20:54.277 --> 00:20:55.860
You won't have to
leave the experience

00:20:55.860 --> 00:20:58.590
to check a notification,
change settings, or even

00:20:58.590 --> 00:21:00.400
to switch apps.

00:21:00.400 --> 00:21:03.090
So now that we've made
it easy to stay in VR,

00:21:03.090 --> 00:21:06.000
we want to help you share that
experience with others, even

00:21:06.000 --> 00:21:08.210
if they're not
wearing a VR headset.

00:21:08.210 --> 00:21:10.880
So today, I'm excited to
announce Cast support is

00:21:10.880 --> 00:21:12.129
coming to Daydream.

00:21:12.129 --> 00:21:12.920
With this feature--

00:21:12.920 --> 00:21:13.530
[APPLAUSE]

00:21:13.530 --> 00:21:14.030
Thank you.

00:21:14.030 --> 00:21:14.720
Thank you.

00:21:14.720 --> 00:21:17.730
It's one of our
top-requested features.

00:21:17.730 --> 00:21:20.300
So with this feature, you'll be
able to pull up the dashboard

00:21:20.300 --> 00:21:22.610
and simply select a
casting destination.

00:21:22.610 --> 00:21:26.090
As you go from app to app,
your Cast station stays.

00:21:26.090 --> 00:21:28.100
Now, casting, what I
love about it is it

00:21:28.100 --> 00:21:30.680
changes the VR experience
from an individual experience

00:21:30.680 --> 00:21:32.540
to a shared experience
and really brings

00:21:32.540 --> 00:21:36.031
your friends and family
into the fun with you.

00:21:36.031 --> 00:21:38.530
Now, casting is good for people
who are physically near you.

00:21:38.530 --> 00:21:40.340
But what about everyone else?

00:21:40.340 --> 00:21:42.650
To help you share your
favorite moments in VR,

00:21:42.650 --> 00:21:44.330
we're also adding the
ability to capture

00:21:44.330 --> 00:21:47.600
a screenshot or a short video
of your Daydream experience

00:21:47.600 --> 00:21:50.510
and share it on your favorite
social media or messaging app.

00:21:50.510 --> 00:21:52.430
[APPLAUSE]

00:21:52.430 --> 00:21:53.556
Thank you.

00:21:53.556 --> 00:21:54.144
OK.

00:21:54.144 --> 00:21:56.810
So that's a quick look at what's
coming with Daydream Euphrates.

00:21:56.810 --> 00:21:59.580
In addition to this, there's
many, many other features,

00:21:59.580 --> 00:22:01.400
including many for developers.

00:22:01.400 --> 00:22:04.160
And you can learn more about
that in our other sessions

00:22:04.160 --> 00:22:06.830
or obviously on our
developer website.

00:22:06.830 --> 00:22:08.850
To sum it all up, we've
got tens of millions

00:22:08.850 --> 00:22:10.850
of Daydream-ready phones
by the end of the year,

00:22:10.850 --> 00:22:13.670
a new class of
standalone VR headsets,

00:22:13.670 --> 00:22:15.740
and a brand new update
to the Daydream software

00:22:15.740 --> 00:22:18.290
we call Euphrates that's
coming later this year

00:22:18.290 --> 00:22:22.280
for both smartphone VR and
for standalone headsets.

00:22:22.280 --> 00:22:24.110
So finally, I spoke
a little bit ago

00:22:24.110 --> 00:22:27.470
about making it easier to share
your VR experience with others.

00:22:27.470 --> 00:22:30.154
We think this is really critical
for users to keep them engaged

00:22:30.154 --> 00:22:32.570
and also where, perhaps, where
some of the most innovative

00:22:32.570 --> 00:22:34.310
experiences will come.

00:22:34.310 --> 00:22:36.269
So let me welcome Erin
from the YouTube VR team

00:22:36.269 --> 00:22:37.684
who's going to
tell you about some

00:22:37.684 --> 00:22:39.860
of the things YouTube VR
is doing to make shared

00:22:39.860 --> 00:22:41.280
experiences a reality.

00:22:41.280 --> 00:22:42.022
Thank you.

00:22:42.022 --> 00:22:44.432
[APPLAUSE]

00:22:48.780 --> 00:22:50.070
ERIN TEAGUE: Hi, everyone.

00:22:50.070 --> 00:22:51.120
I'm Erin.

00:22:51.120 --> 00:22:54.690
I'm a product manager from
the VR team at YouTube.

00:22:54.690 --> 00:22:58.800
We made an early bet on
360-degree and 3D video

00:22:58.800 --> 00:23:01.520
and thought a lot about
how to build the YouTube VR

00:23:01.520 --> 00:23:04.050
app from the ground
up for Daydream.

00:23:04.050 --> 00:23:07.110
It does everything you
love about YouTube,

00:23:07.110 --> 00:23:10.800
but in a way that feels
natural in a virtual world.

00:23:10.800 --> 00:23:15.960
Since we launched, people's
responses have blown us away.

00:23:15.960 --> 00:23:19.170
Every time I pop in, there's
something new to explore,

00:23:19.170 --> 00:23:22.650
from sports highlights
to historic landmarks,

00:23:22.650 --> 00:23:26.700
deep sea dives to
learning about dinosaurs.

00:23:26.700 --> 00:23:28.720
No matter what you're
passionate about,

00:23:28.720 --> 00:23:31.290
YouTube and VR can
take you there,

00:23:31.290 --> 00:23:34.320
thanks to the huge library
of hundreds of thousands

00:23:34.320 --> 00:23:36.450
of immersive videos.

00:23:36.450 --> 00:23:39.210
So there are all
these amazing places

00:23:39.210 --> 00:23:42.270
you can go, see,
and learn about.

00:23:42.270 --> 00:23:46.130
You probably want to share these
experiences with other people.

00:23:46.130 --> 00:23:48.450
It's just better that way.

00:23:48.450 --> 00:23:51.170
From co-watching parties
to creators engaging

00:23:51.170 --> 00:23:55.470
with their fans, YouTube already
has an incredible community

00:23:55.470 --> 00:23:57.780
that's built around its content.

00:23:57.780 --> 00:24:00.810
And we want to bring that to VR.

00:24:00.810 --> 00:24:03.480
So here's a sneak
peek into something

00:24:03.480 --> 00:24:05.400
that we're working on.

00:24:05.400 --> 00:24:07.350
Later this year,
we'll be rolling out

00:24:07.350 --> 00:24:09.960
an update that lets
you co-watch YouTube

00:24:09.960 --> 00:24:14.430
videos with other people,
talk about them live,

00:24:14.430 --> 00:24:18.600
and share the experience all
in the same virtual room.

00:24:18.600 --> 00:24:20.190
Everyone will be
able to customize

00:24:20.190 --> 00:24:22.380
the way that they look in VR.

00:24:22.380 --> 00:24:24.690
And with just a
click, you can sync in

00:24:24.690 --> 00:24:27.150
to watch what others
are watching, too.

00:24:27.150 --> 00:24:30.720
For example, anyone can connect
with other Gorillaz fans

00:24:30.720 --> 00:24:35.460
to watch their latest music
video in a virtual front row.

00:24:35.460 --> 00:24:39.780
For me, VR video goes well
beyond games, entertainment,

00:24:39.780 --> 00:24:41.220
and music.

00:24:41.220 --> 00:24:44.850
So many creators,
like this one, use

00:24:44.850 --> 00:24:48.600
VR to inspire empathy
and compassion.

00:24:48.600 --> 00:24:51.660
In fact, there is
no other technology

00:24:51.660 --> 00:24:54.480
that lets you walk in
someone else's shoes,

00:24:54.480 --> 00:24:57.360
experience things that
you can't in real life,

00:24:57.360 --> 00:24:59.385
and gain a new perspective
on important topics.

00:25:01.960 --> 00:25:05.590
With this update to YouTube
VR and the addition of casting

00:25:05.590 --> 00:25:08.200
and capture to Daydream,
which Mike announced,

00:25:08.200 --> 00:25:12.530
there will soon be more ways
for you to enjoy VR together.

00:25:12.530 --> 00:25:14.590
Now let me pass
this off to Andrey,

00:25:14.590 --> 00:25:17.320
who's going to talk to you a
bit about tools for VR and AR

00:25:17.320 --> 00:25:18.310
developers.

00:25:18.310 --> 00:25:19.666
Thank you.

00:25:19.666 --> 00:25:22.156
[APPLAUSE]

00:25:25.150 --> 00:25:27.010
ANDREY DORONICHEV:
Good morning, everyone.

00:25:27.010 --> 00:25:27.880
I'm Andrey.

00:25:27.880 --> 00:25:31.770
I lead apps and developer
tools at Daydream.

00:25:31.770 --> 00:25:35.500
Hey, so much exciting progress
on AR and VR platform side.

00:25:35.500 --> 00:25:38.980
But of course, platforms are
defined by the best experiences

00:25:38.980 --> 00:25:40.360
available in them--

00:25:40.360 --> 00:25:43.510
experiences built by
developers like you.

00:25:43.510 --> 00:25:46.600
To build great stuff,
you need great tools.

00:25:46.600 --> 00:25:49.240
So today, I want to tell
you about three new tools

00:25:49.240 --> 00:25:52.510
we developed to help
you iterate faster,

00:25:52.510 --> 00:25:54.820
push the limits of
mobile graphics,

00:25:54.820 --> 00:25:59.500
and bring your immersive
experiences to the whole world.

00:25:59.500 --> 00:26:02.590
First of all, let's talk
about iteration time.

00:26:02.590 --> 00:26:04.830
It's early days of
immersive computing,

00:26:04.830 --> 00:26:06.970
so it's all about experimenting.

00:26:06.970 --> 00:26:09.940
You need to be able to
try many new ideas as

00:26:09.940 --> 00:26:11.920
quickly as possible.

00:26:11.920 --> 00:26:14.650
And to evaluate VR
content, you really

00:26:14.650 --> 00:26:19.960
need to experience it firsthand
in the target hardware.

00:26:19.960 --> 00:26:22.440
But we know from many
mobile developers,

00:26:22.440 --> 00:26:26.460
it might take minutes from when
you make a change in the editor

00:26:26.460 --> 00:26:29.230
to when you see the
result on device.

00:26:29.230 --> 00:26:30.510
We timed it.

00:26:30.510 --> 00:26:33.130
It takes three minutes,
sometimes, but maybe five

00:26:33.130 --> 00:26:35.380
or seven for a larger project.

00:26:35.380 --> 00:26:38.710
I can hit Build, go
toast myself a bagel,

00:26:38.710 --> 00:26:41.110
and come back before
it's done deploying.

00:26:41.110 --> 00:26:43.420
So we knew we had to take
the iteration time down

00:26:43.420 --> 00:26:46.180
from minutes to seconds.

00:26:46.180 --> 00:26:49.660
And that is why we
built Instant Preview.

00:26:49.660 --> 00:26:53.350
This is a tool that lets you
make changes in your desktop

00:26:53.350 --> 00:26:57.880
and instantly see them
in your VR device.

00:26:57.880 --> 00:26:58.738
Thank you.

00:26:58.738 --> 00:27:01.130
[APPLAUSE]

00:27:01.130 --> 00:27:03.410
Instant Preview is
deeply integrated

00:27:03.410 --> 00:27:06.480
in both the editor
and the mobile device.

00:27:06.480 --> 00:27:10.160
We send the sensor data from
the headset and the controller

00:27:10.160 --> 00:27:14.240
to the PC, which emulates
and renders the scene.

00:27:14.240 --> 00:27:17.300
And the result is sent back to
the device as a stereo video

00:27:17.300 --> 00:27:18.740
stream.

00:27:18.740 --> 00:27:22.250
And the cool thing is that
we can do it with low latency

00:27:22.250 --> 00:27:25.670
so that you can comfortably
use it in VR while tweaking

00:27:25.670 --> 00:27:27.950
interactions in real time.

00:27:27.950 --> 00:27:32.810
The result is a continuous,
uninterrupted development flow.

00:27:32.810 --> 00:27:35.720
Instant Preview
is launching today

00:27:35.720 --> 00:27:37.621
for both Unity and Unreal.

00:27:37.621 --> 00:27:38.870
You can download it right now.

00:27:38.870 --> 00:27:39.411
Check it out.

00:27:39.411 --> 00:27:41.620
[APPLAUSE]

00:27:42.540 --> 00:27:46.140
Now let's talk about graphics.

00:27:46.140 --> 00:27:49.060
VR makes you feel like
you're somewhere else.

00:27:49.060 --> 00:27:51.780
So the visual fidelity of
the virtual environment

00:27:51.780 --> 00:27:53.820
matters a lot.

00:27:53.820 --> 00:27:56.220
And of course, with six
degree of freedom devices,

00:27:56.220 --> 00:27:59.190
you just can't get away
by wrapping a 360 panorama

00:27:59.190 --> 00:28:00.420
as a background.

00:28:00.420 --> 00:28:03.540
You have to render
a full 3D scene.

00:28:03.540 --> 00:28:07.050
However, what you can render in
real time depends on the amount

00:28:07.050 --> 00:28:08.910
of power you have available.

00:28:08.910 --> 00:28:12.870
There's a huge gap between what
you can do on a 4-watt mobile

00:28:12.870 --> 00:28:19.620
device, a 400-watt PC, or,
say, a 4,000-node render farm.

00:28:19.620 --> 00:28:22.140
But what if we could
bridge this gap?

00:28:22.140 --> 00:28:25.560
What if we could achieve
desktop-level graphics

00:28:25.560 --> 00:28:29.370
on a mobile VR headset,
like our standalone?

00:28:29.370 --> 00:28:31.380
We can't change the laws
of physics, of course,

00:28:31.380 --> 00:28:33.960
but we can be very clever.

00:28:33.960 --> 00:28:37.590
I want to introduce a
new tool we call Seurat,

00:28:37.590 --> 00:28:39.810
after the great French painter.

00:28:39.810 --> 00:28:43.560
With this tool, you can
take a high-fidelity scene,

00:28:43.560 --> 00:28:49.950
like one from a PC game, and run
it in mobile VR in real time.

00:28:49.950 --> 00:28:52.200
How does this work?

00:28:52.200 --> 00:28:54.900
As a developer,
you define a volume

00:28:54.900 --> 00:28:57.150
within which you want
the user to move around

00:28:57.150 --> 00:28:58.810
and view your scene.

00:28:58.810 --> 00:29:00.420
You also define
target parameters,

00:29:00.420 --> 00:29:03.030
like number of
polygons and overdraw.

00:29:03.030 --> 00:29:06.000
And then you let the
tool do its magic.

00:29:06.000 --> 00:29:09.090
It takes dozens of images
from different parts

00:29:09.090 --> 00:29:14.250
of this defined volume, and
then it automatically generates

00:29:14.250 --> 00:29:18.900
an entirely new 3D scene that
looks identical to the original

00:29:18.900 --> 00:29:20.490
but is dramatically simplified.

00:29:20.490 --> 00:29:22.250
[APPLAUSE]

00:29:22.250 --> 00:29:24.090
Yeah, it's pretty cool.

00:29:24.090 --> 00:29:27.130
And you still can have dynamic
interactive elements in it.

00:29:27.130 --> 00:29:29.640
So yeah, it's pretty cool.

00:29:29.640 --> 00:29:30.510
But wait a minute.

00:29:30.510 --> 00:29:33.130
If we can do
something like this,

00:29:33.130 --> 00:29:36.360
why would you stop at
desktop-level graphics?

00:29:36.360 --> 00:29:39.750
What if you take a scene so
complex it can't possibly

00:29:39.750 --> 00:29:43.440
run in real time, even
on the most powerful PC,

00:29:43.440 --> 00:29:46.680
like something from a movie?

00:29:46.680 --> 00:29:49.710
Let me show you a project
we worked on with ILM X

00:29:49.710 --> 00:29:51.930
Lab, the branch
of Lucasfilm that

00:29:51.930 --> 00:29:54.510
is focused on pioneering
next-generation immersive

00:29:54.510 --> 00:29:55.950
experiences.

00:29:55.950 --> 00:29:59.790
One of their goals is to bring
you inside of "Star Wars."

00:29:59.790 --> 00:30:02.100
Let's see what they've been
able to do with Seurat.

00:30:02.100 --> 00:30:04.846
Let's roll the video.

00:30:04.846 --> 00:30:12.081
[VIDEO PLAYBACK]

00:30:12.081 --> 00:30:13.780
VICKI DOBBS BECK:
ILM X Lab's mission

00:30:13.780 --> 00:30:16.870
is really to create
immersive, premium,

00:30:16.870 --> 00:30:19.810
story-based entertainment
experiences.

00:30:19.810 --> 00:30:21.370
And our goal is
for people to step

00:30:21.370 --> 00:30:24.610
inside the worlds of our
stories, and in this case,

00:30:24.610 --> 00:30:26.545
into the world of "Star Wars."

00:30:26.545 --> 00:30:31.581
JOHN KNOLL: When there are
events, locations, characters,

00:30:31.581 --> 00:30:33.080
something that has
to be fabricated,

00:30:33.080 --> 00:30:37.195
they turn to visual effects
to create that imagery.

00:30:37.195 --> 00:30:40.510
JOHN GAETA: The depth of
the world that we would

00:30:40.510 --> 00:30:46.240
like to step into is as
thoughtful and creative

00:30:46.240 --> 00:30:48.759
and exacting as anything
we might put in our films.

00:30:48.759 --> 00:30:50.800
MICHAEL KOPERWAS: This
new technology from Google

00:30:50.800 --> 00:30:52.570
is enabling us to do
something we've been

00:30:52.570 --> 00:30:53.920
trying to find for a while.

00:30:53.920 --> 00:30:56.842
We take high-quality
cinematic renders

00:30:56.842 --> 00:30:58.300
and we can turn
them into something

00:30:58.300 --> 00:31:00.610
that's real time consumable.

00:31:00.610 --> 00:31:02.890
LEWEY GESELOWITZ: When X Lab
was approached by Google,

00:31:02.890 --> 00:31:05.770
they said that they could
take our ILM renders

00:31:05.770 --> 00:31:09.410
and make them run in
real time on a VR phone.

00:31:09.410 --> 00:31:10.530
Turns out it's true.

00:31:10.530 --> 00:31:13.600
JOHN KNOLL: You can have
very dense, complex scenes

00:31:13.600 --> 00:31:17.020
with very sophisticated shading
that traditionally can't

00:31:17.020 --> 00:31:18.880
run in real time on an engine.

00:31:18.880 --> 00:31:21.125
LEWEY GESELOWITZ: When
I see people in our demo

00:31:21.125 --> 00:31:23.500
looking at the floor, and
going on their hands and knees,

00:31:23.500 --> 00:31:27.670
down to inspect the curvature
of every little bend and twist,

00:31:27.670 --> 00:31:29.950
I really think we're
on to something.

00:31:29.950 --> 00:31:32.560
JOHN GAETA: That
potentially opens the door

00:31:32.560 --> 00:31:36.905
to cinematic realism in VR.

00:31:40.976 --> 00:31:42.884
[APPLAUSE]

00:31:42.884 --> 00:31:43.838
[END PLAYBACK]

00:31:46.230 --> 00:31:48.390
ANDREY DORONICHEV:
So ILM X Lab brought

00:31:48.390 --> 00:31:51.240
the cinema-quality
world of "Rogue 1"

00:31:51.240 --> 00:31:54.030
onto our mobile VR headset.

00:31:54.030 --> 00:31:58.560
This scene is around 50 million
triangles and three gigabytes

00:31:58.560 --> 00:31:59.760
of textures.

00:31:59.760 --> 00:32:01.910
Normally, each frame
here takes an hour

00:32:01.910 --> 00:32:05.870
to render offline on a
high-performance machine.

00:32:05.870 --> 00:32:08.580
However, after
processing with Seurat,

00:32:08.580 --> 00:32:12.810
it now takes 13 milliseconds
per frame on a mobile GPU.

00:32:12.810 --> 00:32:15.280
[APPLAUSE]

00:32:17.750 --> 00:32:21.340
We reduced the texture
size by a factor of 300

00:32:21.340 --> 00:32:24.620
and the number of polygons
by a factor of 1,000.

00:32:24.620 --> 00:32:28.540
Now it's comfortably running in
real time on our standalone VR

00:32:28.540 --> 00:32:30.700
headset with six
degrees of freedom.

00:32:30.700 --> 00:32:32.620
And it looks as good
as the original.

00:32:32.620 --> 00:32:34.450
How cool is that?

00:32:34.450 --> 00:32:37.570
Well, with this technology,
you, as a developer,

00:32:37.570 --> 00:32:40.930
will be able to build
visually stunning experiences

00:32:40.930 --> 00:32:45.070
while still targeting
mobile VR hardware.

00:32:45.070 --> 00:32:48.034
Seurat already supports
Unity and Real and Maya,

00:32:48.034 --> 00:32:49.450
and we are currently
experimenting

00:32:49.450 --> 00:32:51.400
with a smaller set of partners.

00:32:51.400 --> 00:32:54.860
We'll start rolling out the tool
more broadly later this year.

00:32:54.860 --> 00:32:58.030
So please stay tuned.

00:32:58.030 --> 00:32:58.540
All right.

00:32:58.540 --> 00:33:02.470
Now let's talk about the
world's largest developer

00:33:02.470 --> 00:33:05.500
ecosystem, the web.

00:33:05.500 --> 00:33:09.910
Three years ago, we
coauthored Web VR Spec.

00:33:09.910 --> 00:33:13.270
It allowed developers to build
immersive 3D applications

00:33:13.270 --> 00:33:17.710
with JavaScript and Web GL
and run them in the browser.

00:33:17.710 --> 00:33:20.570
This way, you're leveraging
the strength of the web itself.

00:33:20.570 --> 00:33:23.010
Your code is
standards-based, it adapts

00:33:23.010 --> 00:33:24.970
to different kinds
of devices, and it's

00:33:24.970 --> 00:33:27.940
easy to distribute
it with a link.

00:33:27.940 --> 00:33:30.800
Now, imagine you're a
user in a VR headset.

00:33:30.800 --> 00:33:33.610
Where do you go to discover
a web VR experience?

00:33:33.610 --> 00:33:36.280
How do you surf the web in VR?

00:33:36.280 --> 00:33:39.370
Well, I'm excited to announce
we're bringing the full Chrome

00:33:39.370 --> 00:33:41.440
browser in VR.

00:33:41.440 --> 00:33:44.770
Let me show you a preview.

00:33:44.770 --> 00:33:47.670
You'll be able to use Daydream
controller to navigate

00:33:47.670 --> 00:33:50.170
any regular web page
and follow links.

00:33:50.170 --> 00:33:52.690
And for web VR
experiences, you just

00:33:52.690 --> 00:33:56.084
get transported into
fully-immersive worlds.

00:33:56.084 --> 00:33:58.000
And of course, you'll
be able to watch any web

00:33:58.000 --> 00:34:00.040
video in a theater-like
environment

00:34:00.040 --> 00:34:02.620
with a large screen.

00:34:02.620 --> 00:34:04.030
What I love about
Chrome in VR is

00:34:04.030 --> 00:34:07.540
that it's the same app I'm
using for browsing in 2D, which

00:34:07.540 --> 00:34:09.940
means all of my
bookmarks, history,

00:34:09.940 --> 00:34:11.440
and tabs are already there.

00:34:11.440 --> 00:34:15.250
I don't have to re-log into
my favorite websites in VR.

00:34:15.250 --> 00:34:17.020
Things just work.

00:34:17.020 --> 00:34:18.820
Browsing in VR feels
great, and it's

00:34:18.820 --> 00:34:23.590
coming to Chrome for
Android later this year.

00:34:23.590 --> 00:34:27.380
But the web is not only
for virtual reality.

00:34:27.380 --> 00:34:30.850
We actually see big
potential in the context

00:34:30.850 --> 00:34:33.150
of augmented reality, too.

00:34:33.150 --> 00:34:36.949
You see, web connects
the world's information,

00:34:36.949 --> 00:34:40.730
and AR connects information
with the physical world.

00:34:40.730 --> 00:34:45.010
So together, they can be applied
for solving real life problems.

00:34:45.010 --> 00:34:47.710
I want to show you what
AR features in the browser

00:34:47.710 --> 00:34:50.170
could look like.

00:34:50.170 --> 00:34:52.865
Let's say you're searching
for a new coffee table.

00:34:52.865 --> 00:34:54.489
You're probably
browsing online stores,

00:34:54.489 --> 00:34:57.340
and you're looking at some
pictures on your phone.

00:34:57.340 --> 00:34:59.440
But you don't really want
pictures on the phone.

00:34:59.440 --> 00:35:02.339
You want the furniture
in your room.

00:35:02.339 --> 00:35:04.630
This is one example where
connecting the physical world

00:35:04.630 --> 00:35:07.740
and information
would be very handy.

00:35:07.740 --> 00:35:10.960
With AR-enabled browser,
your favorite web site

00:35:10.960 --> 00:35:13.540
could ask you to mark the
physical space you have

00:35:13.540 --> 00:35:15.370
available, and
then it would only

00:35:15.370 --> 00:35:19.120
show you the items
that fit in this area.

00:35:19.120 --> 00:35:22.030
And of course, you'll be
able to preview search

00:35:22.030 --> 00:35:28.029
results in the context of your
actual room from any angle.

00:35:28.029 --> 00:35:29.070
And you know what's cool?

00:35:29.070 --> 00:35:30.010
[APPLAUSE]

00:35:30.010 --> 00:35:31.920
Thank you.

00:35:31.920 --> 00:35:32.980
You know what's cool?

00:35:32.980 --> 00:35:35.800
You didn't have to install
a new app just for that.

00:35:35.800 --> 00:35:39.050
Everything you've seen here is
built with JavaScript and Web

00:35:39.050 --> 00:35:43.040
GL, and it's running in
our experimental browser.

00:35:43.040 --> 00:35:47.620
So with the web, we
will enable developers

00:35:47.620 --> 00:35:52.990
to easily integrate AR features
into your existing websites.

00:35:52.990 --> 00:35:55.300
Just like we did
with web VR, we're

00:35:55.300 --> 00:35:57.670
starting by releasing
an experimental build

00:35:57.670 --> 00:36:00.280
of Chromium, which
exposes AR features

00:36:00.280 --> 00:36:02.740
like positional and depth data.

00:36:02.740 --> 00:36:03.640
It's available today.

00:36:03.640 --> 00:36:05.680
You can download it from GitHub.

00:36:05.680 --> 00:36:09.730
And we're excited to see what
the community does with it.

00:36:09.730 --> 00:36:15.310
Our goal is to make web VR and
web AR first-class citizens

00:36:15.310 --> 00:36:17.950
in all browsers.

00:36:17.950 --> 00:36:20.090
And that is it for
Developer Tools.

00:36:20.090 --> 00:36:22.600
Thanks so much for spending
some of your morning with us.

00:36:22.600 --> 00:36:24.460
We'll look forward to
partnering with you,

00:36:24.460 --> 00:36:27.670
making sure you have both
the platforms and the tools

00:36:27.670 --> 00:36:30.190
to bring your next
great idea to life.

00:36:30.190 --> 00:36:31.870
Make sure you check
out our other talks,

00:36:31.870 --> 00:36:34.300
and come over to the Tango
booth to check out the demo.

00:36:34.300 --> 00:36:35.515
Thank you very much.

00:36:35.515 --> 00:36:39.735
[APPLAUSE]

