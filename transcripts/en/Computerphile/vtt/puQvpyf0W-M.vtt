WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.360
We've had one or two comments and people asking the questions about how

00:00:04.680 --> 00:00:11.300
how easy or how difficult it must be to deanonymize data, so it's a problem, isn't it?

00:00:12.700 --> 00:00:21.280
Absolutely, I mean I think a few years ago 2013 there was a published study

00:00:21.580 --> 00:00:30.480
where they took 1.5 million phone records for in a small European country,

00:00:31.720 --> 00:00:34.420
probably Belgium from the one of the authors.

00:00:35.380 --> 00:00:38.900
And they
randomly selected four locations

00:00:39.000 --> 00:00:44.849
they would sort of locate the nearest cell tower and from that they could uniquely identify, re-identify

00:00:45.430 --> 00:00:52.000
95% of the database and by choosing 11 data points they got 100%

00:00:54.120 --> 00:00:57.580
They were able to uniquely identify who these people were.

00:00:58.780 --> 00:01:06.780
Underlying that is, you know, some simple observations about people tend to live somewhere, work somewhere

00:01:07.100 --> 00:01:14.900
and even those two data points are probably enough to uniquely identify folks.

00:01:14.940 --> 00:01:19.060
And then you can look for everything else tagged with that and you can probably track people around.

00:01:19.240 --> 00:01:24.780
So it's actually lots of examples of where what seems like a large amount of random data is not

00:01:24.920 --> 00:01:28.360
because it actually contains within it this huge amount of structure.

00:01:28.620 --> 00:01:33.580
It's always difficult to imagine how one can anonymize the data set

00:01:33.880 --> 00:01:38.120
and it's create a data set that has records which are associated with an individual

00:01:38.220 --> 00:01:42.920
where we essentially just delete the name or replace it with some code, a random number.

00:01:43.140 --> 00:01:48.380
It's very difficult to defend that against all possible future attacks

00:01:48.700 --> 00:01:55.200
because someone could turn up with another data set which includes, I don't know, three or four of the fields

00:01:55.360 --> 00:01:58.860
that are the same as the anonymous data set but with a name associated with it.

00:01:58.860 --> 00:02:04.240
And then by correlating those two data sets together you'll get a set, may not be a one-off,

00:02:04.420 --> 00:02:06.820
but you might get a set of candidates of

00:02:06.920 --> 00:02:13.400
"I Think the following four people, the following four anonymous records could be this person because they match on some other fields"

00:02:13.420 --> 00:02:18.760
And then you could start saying "Well, let's look at then an anonymous record what the other fields are

00:02:19.100 --> 00:02:26.700
and maybe there's something entertaining or scurrilous about that or privacy invasive that people wouldn't want to know".

00:02:26.860 --> 00:02:33.960
And this is very much the attack we saw on the film rating database where

00:02:34.140 --> 00:02:40.700
people rated films with their names on them and then an anonymized data set was published

00:02:40.840 --> 00:02:45.620
with so and so rented all these you know this anonymous person rented all these films

00:02:48.200 --> 00:02:53.019
give us a better recommendation algorithm for them. So there's a big record of all these anonymous identifiers.

00:02:53.140 --> 00:02:56.460
But of course you watch a film and you write a review,

00:02:56.560 --> 00:03:01.660
so even though this set of people who had published their reviews had not reviewed every film they watched,

00:03:02.180 --> 00:03:06.680
the fact that you could correlate they obviously rented these movies and then

00:03:06.920 --> 00:03:12.300
made their reviews probably shortly afterwards causes you to be able to take that and public identifier

00:03:12.420 --> 00:03:17.600
and associate it with all the movies they've watched including the ones perhaps they didn't want people to know about.

00:03:17.780 --> 00:03:22.600
The classic is politicians getting, you know, caught watching adult content and that's very embarrassing for them.

00:03:22.660 --> 00:03:28.540
And the thing is that if someone says here's anonymous data where the records still contain all the data

00:03:29.320 --> 00:03:34.720
And it's associated with an individual or maybe we could call that pseudo-analyzed

00:03:35.900 --> 00:03:41.800
It's very difficult to protect against all possible future databases that might arise

00:03:42.000 --> 00:03:45.900
with real names associated with them. And that's the very that's the problem with the

00:03:46.460 --> 00:03:50.680
deanonymization is a threat that's always there.

00:03:50.960 --> 00:03:55.820
So, that's a fundamental problem if what you have is a record per person,

00:03:56.630 --> 00:04:00.009
no matter what you do. I think there's another there's another thing as well which is perhaps

00:04:00.940 --> 00:04:07.820
mentioned in that space: sometimes the way in which people choose the anonymous identifier is pretty pretty dire really.

00:04:08.000 --> 00:04:14.080
So New York cab company decided to publish all the pick up an drop off points of all the yellow cabs

00:04:14.300 --> 00:04:18.460
and they anonymized the badge number of the driver.

00:04:18.660 --> 00:04:25.320
Now in fact there are just aren't that many badges, so someone computed all the possible hash values of the badges and hence

00:04:25.460 --> 00:04:30.660
you're able to just invert the whole thing and so you're able to reidentify. Because there was an algorithmic means

00:04:30.980 --> 00:04:35.469
to produce the "anonymous identifier". In fact what you really want to do is just

00:04:36.760 --> 00:04:40.560
If you do want to do this you really just need to then generate a random number.

00:04:40.880 --> 00:04:45.520
Do not make it a hash value when the space of values is not that large.

00:04:45.740 --> 00:04:48.880
Brute force attacks. It's a bit like cryptography

00:04:49.850 --> 00:04:51.170
you know

00:04:51.170 --> 00:04:56.709
It was really hard, it took a lot of work to break enigma during the Second World War, right?

00:04:57.200 --> 00:05:01.700
But these days your average PC would crack it in seconds if that.

00:05:01.800 --> 00:05:07.060
So, It's slowly increasing, you know, processing power that's available, and the fact that we have

00:05:07.300 --> 00:05:14.060
GPU cards with hundreds of GPUs on them or even more so cryptographic accelerators as we see in some of the

00:05:14.960 --> 00:05:18.820
some of the modern processors. If you have all of that those engines there

00:05:18.820 --> 00:05:23.540
then the challenge is that you simply have to keep making the problem harder and harder.

00:05:23.560 --> 00:05:25.660
So the next thing you could try to do is say well

00:05:25.820 --> 00:05:36.180
Why don't we do the sort of techniques that the Census adopt which is they don't publish per postcode data

00:05:36.400 --> 00:05:44.740
because even that's a too fine grid they they aggregate the data out such that the statistics that they publish

00:05:44.900 --> 00:05:54.000
are at the levels of you know hundreds of thousands of people and that doesn't completely prevent

00:05:54.200 --> 00:05:57.740
re-identification, but it certainly starts to make it substantially harder.

00:05:57.880 --> 00:06:03.880
And some of the times like cryptography the mission is to make it substantially harder and to put it beyond

00:06:04.420 --> 00:06:09.360
Reasonable computational resources. After all all cryptography falls into that category.

00:06:09.360 --> 00:06:12.960
It's not like you cannot break cryptography, you just do brute force.

00:06:13.120 --> 00:06:17.580
It just may take a thousand years, but remember: what was predicted to take a thousand years

00:06:18.240 --> 00:06:25.140
in 1945 is now, you know, milliseconds on a modern computer so you always go to factor in that.

00:06:26.320 --> 00:06:35.500
So the issue is how difficult to make this for people to re-identify.

00:06:35.680 --> 00:06:38.120
And of course essentially, you know, when you get down to it

00:06:38.120 --> 00:06:41.520
This is what intelligence agents would be doing for years, I mean, they'll be looking at all sorts of

00:06:41.660 --> 00:06:45.820
random sources of information and understanding how they all correlate together.

00:06:45.960 --> 00:06:53.660
So, even when you are aggregated, it may still be possible to to re-identify within that group.

00:06:53.880 --> 00:06:58.620
And it has to be not just that you aggregate to within say a hundred people or something,

00:06:58.720 --> 00:07:04.160
it also has to be that there can be no population of I don't know less than ten or twenty in that group.

00:07:04.600 --> 00:07:10.709
I mean my son was asked to fill in a survey at school, and they said "Oh, it's all completely anonymous"

00:07:10.709 --> 00:07:16.900
and they asked for his postcode. Now he sat at dinner long enough listening to me go on about this repeatedly

00:07:17.100 --> 00:07:20.480
And he simply he then put in a bogus postcode

00:07:20.800 --> 00:07:27.280
And he said "Well, that's ridiculous, because there's only two of us kids at school of a school age on this street".

00:07:27.340 --> 00:07:30.860
And I said "No, it's worse than that, son. He lives around the corner that's a different postcode

00:07:30.940 --> 00:07:36.960
because of the different street name". There's precisely one Fifteen year old child on this street.

00:07:37.160 --> 00:07:40.680
So it was uniquely identifying. And something that someone thought "Well that will be fine",

00:07:40.840 --> 00:07:44.820
you know, it wasn't because actually although there are a number of people living on our street,

00:07:45.100 --> 00:07:50.260
there's only one there was only one fifteen year old at the time, so it was uniquely identifying.

00:07:50.420 --> 00:07:59.400
So, It's a complex problem even when you aggregate to try to anonymize because you've got to think about

00:08:00.250 --> 00:08:04.500
is it a unique sample within that aggregate in which case it's still a problem

00:08:04.570 --> 00:08:08.120
So you find that the people have been doing this for years, which is people like

00:08:08.120 --> 00:08:13.360
the Office of National Statistics, they have tried and tested mechanisms

00:08:13.460 --> 00:08:18.720
where they've evaluated the risk of re-identification and that's how they publish things like census data

00:08:18.820 --> 00:08:23.920
and the data that they publish every month that comes out of the ONS. They're very careful about them.

00:08:24.140 --> 00:08:30.360
Now, this is something that actually has become, recently I've noticed become very

00:08:30.640 --> 00:08:33.787
interesting to lots of companies who are trying to deal with data protection:

00:08:33.787 --> 00:08:37.160
the new General Data Protection Regulation coming in the EU.

00:08:37.780 --> 00:08:40.160
Where they're saying "Well what on Earth could we possibly do

00:08:40.260 --> 00:08:43.540
because we were allowed to keep these synonymous records", but what does that mean?

00:08:43.580 --> 00:08:47.840
And I heard a very sensible colleague from a large company say:

00:08:47.980 --> 00:08:51.200
"Well, why don't we do what the ONS does because they've had a

00:08:52.279 --> 00:08:55.719
hundred years experience on this and they seem to know what they're doing and

00:08:56.120 --> 00:09:01.419
surely we can carry the same level of risk as they can". So it is a very subtle problem

00:09:02.360 --> 00:09:06.280
but like most of these things in the same way that I would simply say that

00:09:06.580 --> 00:09:12.760
there is no cryptography that is completely bulletproof, it's a question of just how difficult is it to crack the crypto

00:09:12.980 --> 00:09:18.660
When it comes to anonymization the question is how difficult is it to break the anonymization?

00:09:18.660 --> 00:09:25.400
And he's simply applying new interesting and different perspectives and different data assets

00:09:25.480 --> 00:09:29.260
to the original one, you know, things that the original creator never thought about

00:09:29.840 --> 00:09:35.600
will be the attacks so our mission always has to be simply to make it at least provably

00:09:35.780 --> 00:09:38.140
challenging computationally to do

00:09:39.680 --> 00:09:45.720
And that's and it should personally maybe some genius is gonna quote someone that really does work,

00:09:45.780 --> 00:09:51.240
but I've yet to see anyone who would believe that we truly can anonymize in the same way that

00:09:51.640 --> 00:09:58.060
other than one-time pads in cryptography we can't do a crypto that's not open to brute force attack.

00:10:00.290 --> 00:10:06.670
Doesn't really matter, but they started discriminating against that and a BitTorrent was the classic where lots of people were discriminate against BitTorrent

00:10:07.550 --> 00:10:11.470
But then of course it turns out that many people were using BitTorrent for perfectly legitimate reasons.

00:10:11.630 --> 00:10:15.910
Yes, there were BitTorrent file sharing and there still is plenty of it around

