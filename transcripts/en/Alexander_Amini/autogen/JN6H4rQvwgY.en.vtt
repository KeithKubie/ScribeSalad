WEBVTT
Kind: captions
Language: en

00:00:02.040 --> 00:00:04.240 align:start position:0%
 
good<00:00:02.639><c> morning</c><00:00:02.910><c> everyone</c><00:00:03.120><c> thank</c><00:00:03.929><c> you</c><00:00:03.990><c> for</c>

00:00:04.240 --> 00:00:04.250 align:start position:0%
good morning everyone thank you for
 

00:00:04.250 --> 00:00:06.320 align:start position:0%
good morning everyone thank you for
thank<00:00:05.250><c> you</c><00:00:05.310><c> all</c><00:00:05.460><c> for</c><00:00:05.609><c> joining</c><00:00:05.760><c> us</c>

00:00:06.320 --> 00:00:06.330 align:start position:0%
thank you all for joining us
 

00:00:06.330 --> 00:00:10.879 align:start position:0%
thank you all for joining us
this<00:00:06.690><c> is</c><00:00:06.900><c> MIT</c><00:00:07.879><c> six</c><00:00:08.879><c> s-191</c><00:00:09.870><c> and</c><00:00:10.170><c> we'd</c><00:00:10.740><c> like</c><00:00:10.860><c> to</c>

00:00:10.879 --> 00:00:10.889 align:start position:0%
this is MIT six s-191 and we'd like to
 

00:00:10.889 --> 00:00:13.070 align:start position:0%
this is MIT six s-191 and we'd like to
welcome<00:00:11.100><c> to</c><00:00:11.459><c> welcome</c><00:00:11.730><c> you</c><00:00:12.270><c> to</c><00:00:12.449><c> this</c><00:00:12.539><c> course</c><00:00:12.869><c> on</c>

00:00:13.070 --> 00:00:13.080 align:start position:0%
welcome to welcome you to this course on
 

00:00:13.080 --> 00:00:15.740 align:start position:0%
welcome to welcome you to this course on
introduction<00:00:13.469><c> to</c><00:00:13.680><c> deep</c><00:00:13.920><c> learning</c><00:00:14.420><c> so</c><00:00:15.420><c> in</c><00:00:15.600><c> this</c>

00:00:15.740 --> 00:00:15.750 align:start position:0%
introduction to deep learning so in this
 

00:00:15.750 --> 00:00:18.439 align:start position:0%
introduction to deep learning so in this
course<00:00:15.959><c> you'll</c><00:00:16.289><c> learn</c><00:00:16.500><c> how</c><00:00:16.890><c> to</c><00:00:17.449><c> build</c>

00:00:18.439 --> 00:00:18.449 align:start position:0%
course you'll learn how to build
 

00:00:18.449 --> 00:00:20.779 align:start position:0%
course you'll learn how to build
remarkable<00:00:19.170><c> algorithms</c><00:00:19.789><c> intelligent</c>

00:00:20.779 --> 00:00:20.789 align:start position:0%
remarkable algorithms intelligent
 

00:00:20.789 --> 00:00:23.630 align:start position:0%
remarkable algorithms intelligent
algorithms<00:00:21.740><c> capable</c><00:00:22.740><c> of</c><00:00:22.830><c> solving</c><00:00:23.279><c> very</c>

00:00:23.630 --> 00:00:23.640 align:start position:0%
algorithms capable of solving very
 

00:00:23.640 --> 00:00:25.999 align:start position:0%
algorithms capable of solving very
complex<00:00:24.240><c> problems</c><00:00:24.720><c> that</c><00:00:24.960><c> just</c><00:00:25.199><c> a</c><00:00:25.529><c> decade</c><00:00:25.949><c> ago</c>

00:00:25.999 --> 00:00:26.009 align:start position:0%
complex problems that just a decade ago
 

00:00:26.009 --> 00:00:29.560 align:start position:0%
complex problems that just a decade ago
were<00:00:26.429><c> not</c><00:00:26.460><c> even</c><00:00:27.259><c> feasible</c><00:00:28.259><c> to</c><00:00:28.710><c> solve</c><00:00:28.949><c> and</c>

00:00:29.560 --> 00:00:29.570 align:start position:0%
were not even feasible to solve and
 

00:00:29.570 --> 00:00:32.540 align:start position:0%
were not even feasible to solve and
let's<00:00:30.570><c> just</c><00:00:30.720><c> start</c><00:00:30.990><c> with</c><00:00:31.140><c> this</c><00:00:32.040><c> notion</c><00:00:32.279><c> of</c>

00:00:32.540 --> 00:00:32.550 align:start position:0%
let's just start with this notion of
 

00:00:32.550 --> 00:00:36.100 align:start position:0%
let's just start with this notion of
intelligence<00:00:33.680><c> so</c><00:00:34.680><c> at</c><00:00:35.010><c> a</c><00:00:35.160><c> very</c><00:00:35.190><c> high</c><00:00:35.489><c> level</c>

00:00:36.100 --> 00:00:36.110 align:start position:0%
intelligence so at a very high level
 

00:00:36.110 --> 00:00:38.720 align:start position:0%
intelligence so at a very high level
intelligence<00:00:37.110><c> is</c><00:00:37.379><c> the</c><00:00:37.800><c> ability</c><00:00:38.129><c> to</c><00:00:38.340><c> process</c>

00:00:38.720 --> 00:00:38.730 align:start position:0%
intelligence is the ability to process
 

00:00:38.730 --> 00:00:42.740 align:start position:0%
intelligence is the ability to process
information<00:00:40.070><c> so</c><00:00:41.070><c> that</c><00:00:41.100><c> it</c><00:00:41.489><c> can</c><00:00:41.520><c> be</c><00:00:41.730><c> used</c><00:00:42.000><c> to</c>

00:00:42.740 --> 00:00:42.750 align:start position:0%
information so that it can be used to
 

00:00:42.750 --> 00:00:45.069 align:start position:0%
information so that it can be used to
inform<00:00:43.230><c> future</c><00:00:43.350><c> predictions</c><00:00:44.219><c> and</c><00:00:44.460><c> decisions</c>

00:00:45.069 --> 00:00:45.079 align:start position:0%
inform future predictions and decisions
 

00:00:45.079 --> 00:00:48.250 align:start position:0%
inform future predictions and decisions
now<00:00:46.079><c> when</c><00:00:46.320><c> this</c><00:00:46.440><c> intelligence</c><00:00:47.039><c> is</c><00:00:47.280><c> not</c>

00:00:48.250 --> 00:00:48.260 align:start position:0%
now when this intelligence is not
 

00:00:48.260 --> 00:00:51.849 align:start position:0%
now when this intelligence is not
engineered<00:00:49.260><c> but</c><00:00:49.949><c> rather</c><00:00:50.129><c> a</c><00:00:50.309><c> biological</c>

00:00:51.849 --> 00:00:51.859 align:start position:0%
engineered but rather a biological
 

00:00:51.859 --> 00:00:55.910 align:start position:0%
engineered but rather a biological
inspiration<00:00:52.910><c> such</c><00:00:53.910><c> as</c><00:00:54.120><c> in</c><00:00:54.269><c> humans</c><00:00:54.920><c> it's</c>

00:00:55.910 --> 00:00:55.920 align:start position:0%
inspiration such as in humans it's
 

00:00:55.920 --> 00:00:57.830 align:start position:0%
inspiration such as in humans it's
called<00:00:56.190><c> human</c><00:00:56.579><c> intelligence</c><00:00:56.969><c> but</c><00:00:57.570><c> when</c><00:00:57.690><c> it's</c>

00:00:57.830 --> 00:00:57.840 align:start position:0%
called human intelligence but when it's
 

00:00:57.840 --> 00:00:59.660 align:start position:0%
called human intelligence but when it's
engineered<00:00:58.379><c> we</c><00:00:58.769><c> refer</c><00:00:58.980><c> to</c><00:00:59.010><c> it</c><00:00:59.190><c> as</c><00:00:59.250><c> artificial</c>

00:00:59.660 --> 00:00:59.670 align:start position:0%
engineered we refer to it as artificial
 

00:00:59.670 --> 00:01:02.240 align:start position:0%
engineered we refer to it as artificial
intelligence<00:01:00.329><c> so</c><00:01:01.320><c> this</c><00:01:01.500><c> course</c><00:01:01.769><c> is</c><00:01:01.949><c> a</c><00:01:01.980><c> course</c>

00:01:02.240 --> 00:01:02.250 align:start position:0%
intelligence so this course is a course
 

00:01:02.250 --> 00:01:04.009 align:start position:0%
intelligence so this course is a course
on<00:01:02.399><c> deep</c><00:01:02.609><c> learning</c><00:01:02.640><c> which</c><00:01:03.120><c> is</c><00:01:03.269><c> just</c><00:01:03.480><c> a</c><00:01:03.539><c> subset</c>

00:01:04.009 --> 00:01:04.019 align:start position:0%
on deep learning which is just a subset
 

00:01:04.019 --> 00:01:07.160 align:start position:0%
on deep learning which is just a subset
of<00:01:04.199><c> artificial</c><00:01:04.949><c> intelligence</c><00:01:05.190><c> and</c><00:01:06.170><c> really</c>

00:01:07.160 --> 00:01:07.170 align:start position:0%
of artificial intelligence and really
 

00:01:07.170 --> 00:01:08.720 align:start position:0%
of artificial intelligence and really
it's<00:01:07.260><c> just</c><00:01:07.320><c> a</c><00:01:07.500><c> subset</c><00:01:07.890><c> of</c><00:01:07.920><c> machine</c><00:01:08.370><c> learning</c>

00:01:08.720 --> 00:01:08.730 align:start position:0%
it's just a subset of machine learning
 

00:01:08.730 --> 00:01:10.840 align:start position:0%
it's just a subset of machine learning
which<00:01:08.850><c> involves</c><00:01:09.420><c> more</c><00:01:09.540><c> traditional</c><00:01:10.050><c> methods</c>

00:01:10.840 --> 00:01:10.850 align:start position:0%
which involves more traditional methods
 

00:01:10.850 --> 00:01:15.440 align:start position:0%
which involves more traditional methods
where<00:01:11.850><c> we</c><00:01:11.880><c> tried</c><00:01:12.360><c> to</c><00:01:12.510><c> learn</c><00:01:14.450><c> representations</c>

00:01:15.440 --> 00:01:15.450 align:start position:0%
where we tried to learn representations
 

00:01:15.450 --> 00:01:17.240 align:start position:0%
where we tried to learn representations
directly<00:01:16.050><c> from</c><00:01:16.260><c> data</c><00:01:16.470><c> and</c><00:01:16.860><c> we'll</c><00:01:16.950><c> talk</c><00:01:17.100><c> about</c>

00:01:17.240 --> 00:01:17.250 align:start position:0%
directly from data and we'll talk about
 

00:01:17.250 --> 00:01:20.600 align:start position:0%
directly from data and we'll talk about
this<00:01:17.550><c> more</c><00:01:17.820><c> in</c><00:01:18.060><c> detail</c><00:01:18.660><c> later</c><00:01:18.690><c> today</c><00:01:19.460><c> but</c><00:01:20.460><c> let</c>

00:01:20.600 --> 00:01:20.610 align:start position:0%
this more in detail later today but let
 

00:01:20.610 --> 00:01:22.160 align:start position:0%
this more in detail later today but let
me<00:01:20.730><c> first</c><00:01:20.940><c> just</c><00:01:21.060><c> start</c><00:01:21.570><c> by</c><00:01:21.720><c> talking</c><00:01:22.020><c> about</c>

00:01:22.160 --> 00:01:22.170 align:start position:0%
me first just start by talking about
 

00:01:22.170 --> 00:01:24.530 align:start position:0%
me first just start by talking about
some<00:01:22.320><c> of</c><00:01:22.560><c> the</c><00:01:22.710><c> amazing</c><00:01:23.160><c> successes</c><00:01:23.850><c> that</c><00:01:24.360><c> deep</c>

00:01:24.530 --> 00:01:24.540 align:start position:0%
some of the amazing successes that deep
 

00:01:24.540 --> 00:01:28.910 align:start position:0%
some of the amazing successes that deep
learning<00:01:24.720><c> has</c><00:01:25.020><c> had</c><00:01:25.260><c> in</c><00:01:25.530><c> the</c><00:01:25.830><c> past</c><00:01:26.010><c> so</c><00:01:26.840><c> in</c><00:01:27.920><c> 2012</c>

00:01:28.910 --> 00:01:28.920 align:start position:0%
learning has had in the past so in 2012
 

00:01:28.920 --> 00:01:31.280 align:start position:0%
learning has had in the past so in 2012
this<00:01:29.820><c> competition</c><00:01:30.420><c> called</c><00:01:30.570><c> imagenet</c><00:01:31.050><c> came</c>

00:01:31.280 --> 00:01:31.290 align:start position:0%
this competition called imagenet came
 

00:01:31.290 --> 00:01:34.250 align:start position:0%
this competition called imagenet came
out<00:01:31.470><c> which</c><00:01:31.860><c> tasked</c><00:01:32.370><c> AI</c><00:01:32.610><c> researchers</c><00:01:33.420><c> to</c><00:01:34.050><c> build</c>

00:01:34.250 --> 00:01:34.260 align:start position:0%
out which tasked AI researchers to build
 

00:01:34.260 --> 00:01:37.180 align:start position:0%
out which tasked AI researchers to build
an<00:01:34.590><c> AI</c><00:01:34.860><c> system</c><00:01:35.520><c> capable</c><00:01:36.090><c> of</c><00:01:36.150><c> recognizing</c>

00:01:37.180 --> 00:01:37.190 align:start position:0%
an AI system capable of recognizing
 

00:01:37.190 --> 00:01:40.490 align:start position:0%
an AI system capable of recognizing
images<00:01:38.190><c> objects</c><00:01:38.820><c> in</c><00:01:38.940><c> images</c><00:01:39.330><c> and</c><00:01:39.540><c> there</c><00:01:40.410><c> was</c>

00:01:40.490 --> 00:01:40.500 align:start position:0%
images objects in images and there was
 

00:01:40.500 --> 00:01:42.980 align:start position:0%
images objects in images and there was
millions<00:01:40.860><c> of</c><00:01:41.250><c> examples</c><00:01:41.910><c> in</c><00:01:42.210><c> this</c><00:01:42.450><c> data</c><00:01:42.690><c> set</c>

00:01:42.980 --> 00:01:42.990 align:start position:0%
millions of examples in this data set
 

00:01:42.990 --> 00:01:46.100 align:start position:0%
millions of examples in this data set
and<00:01:43.670><c> the</c><00:01:44.670><c> winner</c><00:01:44.850><c> in</c><00:01:45.000><c> 2012</c><00:01:45.660><c> for</c><00:01:45.840><c> the</c><00:01:45.930><c> first</c>

00:01:46.100 --> 00:01:46.110 align:start position:0%
and the winner in 2012 for the first
 

00:01:46.110 --> 00:01:47.780 align:start position:0%
and the winner in 2012 for the first
time<00:01:46.320><c> ever</c><00:01:46.500><c> was</c><00:01:46.980><c> a</c><00:01:47.010><c> deep</c><00:01:47.250><c> learning</c><00:01:47.610><c> based</c>

00:01:47.780 --> 00:01:47.790 align:start position:0%
time ever was a deep learning based
 

00:01:47.790 --> 00:01:49.700 align:start position:0%
time ever was a deep learning based
system<00:01:48.240><c> and</c><00:01:48.420><c> a</c><00:01:48.810><c> when</c><00:01:49.050><c> it</c><00:01:49.140><c> came</c><00:01:49.290><c> out</c><00:01:49.470><c> it</c>

00:01:49.700 --> 00:01:49.710 align:start position:0%
system and a when it came out it
 

00:01:49.710 --> 00:01:51.530 align:start position:0%
system and a when it came out it
absolutely<00:01:50.250><c> shattered</c><00:01:50.610><c> all</c><00:01:51.030><c> other</c>

00:01:51.530 --> 00:01:51.540 align:start position:0%
absolutely shattered all other
 

00:01:51.540 --> 00:01:54.370 align:start position:0%
absolutely shattered all other
competitors<00:01:52.530><c> and</c><00:01:53.040><c> crushed</c><00:01:53.550><c> the</c><00:01:54.180><c> competition</c>

00:01:54.370 --> 00:01:54.380 align:start position:0%
competitors and crushed the competition
 

00:01:54.380 --> 00:01:56.860 align:start position:0%
competitors and crushed the competition
across<00:01:55.380><c> the</c><00:01:55.560><c> country</c><00:01:55.920><c> crush</c><00:01:56.250><c> the</c><00:01:56.370><c> challenge</c>

00:01:56.860 --> 00:01:56.870 align:start position:0%
across the country crush the challenge
 

00:01:56.870 --> 00:02:00.020 align:start position:0%
across the country crush the challenge
and<00:01:57.870><c> today</c><00:01:58.800><c> these</c><00:01:59.340><c> deep</c><00:01:59.610><c> learning</c><00:01:59.760><c> based</c>

00:02:00.020 --> 00:02:00.030 align:start position:0%
and today these deep learning based
 

00:02:00.030 --> 00:02:01.970 align:start position:0%
and today these deep learning based
systems<00:02:00.420><c> have</c><00:02:00.600><c> actually</c><00:02:00.960><c> surpassed</c><00:02:01.470><c> human</c>

00:02:01.970 --> 00:02:01.980 align:start position:0%
systems have actually surpassed human
 

00:02:01.980 --> 00:02:04.160 align:start position:0%
systems have actually surpassed human
level<00:02:02.340><c> accuracy</c><00:02:02.640><c> on</c><00:02:03.090><c> the</c><00:02:03.780><c> image</c><00:02:03.990><c> net</c>

00:02:04.160 --> 00:02:04.170 align:start position:0%
level accuracy on the image net
 

00:02:04.170 --> 00:02:06.230 align:start position:0%
level accuracy on the image net
challenge<00:02:04.590><c> and</c><00:02:04.800><c> can</c><00:02:05.280><c> actually</c><00:02:05.700><c> recognize</c>

00:02:06.230 --> 00:02:06.240 align:start position:0%
challenge and can actually recognize
 

00:02:06.240 --> 00:02:10.789 align:start position:0%
challenge and can actually recognize
images<00:02:06.960><c> even</c><00:02:07.140><c> better</c><00:02:07.440><c> than</c><00:02:07.680><c> humans</c><00:02:08.009><c> can</c><00:02:09.799><c> now</c>

00:02:10.789 --> 00:02:10.799 align:start position:0%
images even better than humans can now
 

00:02:10.799 --> 00:02:12.170 align:start position:0%
images even better than humans can now
in<00:02:10.920><c> this</c><00:02:11.039><c> class</c><00:02:11.280><c> you'll</c><00:02:11.609><c> actually</c><00:02:11.760><c> learn</c><00:02:12.150><c> how</c>

00:02:12.170 --> 00:02:12.180 align:start position:0%
in this class you'll actually learn how
 

00:02:12.180 --> 00:02:14.839 align:start position:0%
in this class you'll actually learn how
to<00:02:12.480><c> build</c><00:02:12.870><c> complex</c><00:02:13.349><c> vision</c><00:02:13.980><c> systems</c><00:02:14.430><c> building</c>

00:02:14.839 --> 00:02:14.849 align:start position:0%
to build complex vision systems building
 

00:02:14.849 --> 00:02:15.710 align:start position:0%
to build complex vision systems building
a<00:02:14.879><c> computer</c><00:02:15.209><c> that</c>

00:02:15.710 --> 00:02:15.720 align:start position:0%
a computer that
 

00:02:15.720 --> 00:02:18.440 align:start position:0%
a computer that
how<00:02:15.990><c> to</c><00:02:16.050><c> see</c><00:02:16.380><c> and</c><00:02:16.760><c> just</c><00:02:17.760><c> tomorrow</c><00:02:18.180><c> you'll</c>

00:02:18.440 --> 00:02:18.450 align:start position:0%
how to see and just tomorrow you'll
 

00:02:18.450 --> 00:02:20.540 align:start position:0%
how to see and just tomorrow you'll
learn<00:02:18.600><c> how</c><00:02:18.660><c> to</c><00:02:18.840><c> build</c><00:02:19.050><c> an</c><00:02:19.770><c> algorithm</c><00:02:20.370><c> that</c>

00:02:20.540 --> 00:02:20.550 align:start position:0%
learn how to build an algorithm that
 

00:02:20.550 --> 00:02:24.620 align:start position:0%
learn how to build an algorithm that
will<00:02:21.300><c> take</c><00:02:21.600><c> as</c><00:02:21.780><c> input</c><00:02:22.040><c> x-ray</c><00:02:23.040><c> images</c><00:02:23.490><c> and</c><00:02:23.760><c> as</c>

00:02:24.620 --> 00:02:24.630 align:start position:0%
will take as input x-ray images and as
 

00:02:24.630 --> 00:02:27.080 align:start position:0%
will take as input x-ray images and as
output<00:02:25.140><c> it</c><00:02:25.320><c> will</c><00:02:25.410><c> detect</c><00:02:25.800><c> if</c><00:02:26.130><c> that</c><00:02:26.310><c> person</c><00:02:26.790><c> has</c>

00:02:27.080 --> 00:02:27.090 align:start position:0%
output it will detect if that person has
 

00:02:27.090 --> 00:02:29.840 align:start position:0%
output it will detect if that person has
a<00:02:27.120><c> pneumothorax</c><00:02:28.370><c> just</c><00:02:29.370><c> from</c><00:02:29.490><c> that</c><00:02:29.580><c> single</c>

00:02:29.840 --> 00:02:29.850 align:start position:0%
a pneumothorax just from that single
 

00:02:29.850 --> 00:02:34.250 align:start position:0%
a pneumothorax just from that single
input<00:02:30.750><c> image</c><00:02:32.270><c> you'll</c><00:02:33.270><c> even</c><00:02:33.540><c> make</c><00:02:33.870><c> the</c><00:02:34.080><c> network</c>

00:02:34.250 --> 00:02:34.260 align:start position:0%
input image you'll even make the network
 

00:02:34.260 --> 00:02:36.890 align:start position:0%
input image you'll even make the network
explain<00:02:34.860><c> to</c><00:02:35.100><c> you</c><00:02:35.220><c> why</c><00:02:35.460><c> it</c><00:02:35.520><c> decided</c><00:02:36.510><c> to</c>

00:02:36.890 --> 00:02:36.900 align:start position:0%
explain to you why it decided to
 

00:02:36.900 --> 00:02:39.560 align:start position:0%
explain to you why it decided to
diagnose<00:02:37.590><c> the</c><00:02:38.070><c> way</c><00:02:38.190><c> it</c><00:02:38.370><c> diagnosed</c><00:02:38.880><c> by</c><00:02:39.180><c> looking</c>

00:02:39.560 --> 00:02:39.570 align:start position:0%
diagnose the way it diagnosed by looking
 

00:02:39.570 --> 00:02:41.510 align:start position:0%
diagnose the way it diagnosed by looking
inside<00:02:39.840><c> the</c><00:02:40.050><c> network</c><00:02:40.380><c> and</c><00:02:40.740><c> understanding</c>

00:02:41.510 --> 00:02:41.520 align:start position:0%
inside the network and understanding
 

00:02:41.520 --> 00:02:45.710 align:start position:0%
inside the network and understanding
exactly<00:02:41.730><c> why</c><00:02:42.300><c> I</c><00:02:42.330><c> made</c><00:02:42.600><c> that</c><00:02:42.630><c> decision</c><00:02:44.720><c> deep</c>

00:02:45.710 --> 00:02:45.720 align:start position:0%
exactly why I made that decision deep
 

00:02:45.720 --> 00:02:47.570 align:start position:0%
exactly why I made that decision deep
neural<00:02:45.900><c> networks</c><00:02:46.290><c> can</c><00:02:46.590><c> also</c><00:02:47.010><c> be</c><00:02:47.250><c> used</c><00:02:47.430><c> to</c>

00:02:47.570 --> 00:02:47.580 align:start position:0%
neural networks can also be used to
 

00:02:47.580 --> 00:02:49.490 align:start position:0%
neural networks can also be used to
model<00:02:47.850><c> sequences</c><00:02:48.420><c> where</c><00:02:48.930><c> your</c><00:02:49.050><c> data</c><00:02:49.260><c> points</c>

00:02:49.490 --> 00:02:49.500 align:start position:0%
model sequences where your data points
 

00:02:49.500 --> 00:02:51.020 align:start position:0%
model sequences where your data points
are<00:02:49.680><c> not</c><00:02:49.800><c> just</c><00:02:50.010><c> single</c><00:02:50.190><c> images</c><00:02:50.670><c> but</c><00:02:50.880><c> rather</c>

00:02:51.020 --> 00:02:51.030 align:start position:0%
are not just single images but rather
 

00:02:51.030 --> 00:02:53.630 align:start position:0%
are not just single images but rather
temporally<00:02:51.780><c> dependent</c><00:02:52.380><c> so</c><00:02:53.100><c> for</c><00:02:53.310><c> this</c><00:02:53.370><c> you</c><00:02:53.520><c> can</c>

00:02:53.630 --> 00:02:53.640 align:start position:0%
temporally dependent so for this you can
 

00:02:53.640 --> 00:02:55.730 align:start position:0%
temporally dependent so for this you can
think<00:02:53.880><c> of</c><00:02:54.000><c> things</c><00:02:54.240><c> like</c><00:02:54.650><c> predicting</c><00:02:55.650><c> the</c>

00:02:55.730 --> 00:02:55.740 align:start position:0%
think of things like predicting the
 

00:02:55.740 --> 00:02:58.400 align:start position:0%
think of things like predicting the
stock<00:02:55.980><c> price</c><00:02:56.690><c> translating</c><00:02:57.690><c> sentences</c><00:02:57.870><c> from</c>

00:02:58.400 --> 00:02:58.410 align:start position:0%
stock price translating sentences from
 

00:02:58.410 --> 00:03:01.160 align:start position:0%
stock price translating sentences from
English<00:02:58.740><c> to</c><00:02:58.770><c> Spanish</c><00:02:58.950><c> or</c><00:02:59.720><c> even</c><00:03:00.720><c> generating</c>

00:03:01.160 --> 00:03:01.170 align:start position:0%
English to Spanish or even generating
 

00:03:01.170 --> 00:03:02.990 align:start position:0%
English to Spanish or even generating
new<00:03:01.290><c> music</c><00:03:01.680><c> so</c><00:03:02.070><c> actually</c><00:03:02.370><c> today</c><00:03:02.520><c> you'll</c><00:03:02.940><c> learn</c>

00:03:02.990 --> 00:03:03.000 align:start position:0%
new music so actually today you'll learn
 

00:03:03.000 --> 00:03:04.790 align:start position:0%
new music so actually today you'll learn
how<00:03:03.209><c> to</c><00:03:03.420><c> create</c><00:03:03.840><c> and</c><00:03:04.140><c> actually</c><00:03:04.410><c> you'll</c><00:03:04.560><c> create</c>

00:03:04.790 --> 00:03:04.800 align:start position:0%
how to create and actually you'll create
 

00:03:04.800 --> 00:03:07.970 align:start position:0%
how to create and actually you'll create
yourselves<00:03:05.400><c> an</c><00:03:05.520><c> algorithm</c><00:03:06.360><c> that</c><00:03:06.390><c> learns</c><00:03:06.980><c> that</c>

00:03:07.970 --> 00:03:07.980 align:start position:0%
yourselves an algorithm that learns that
 

00:03:07.980 --> 00:03:11.270 align:start position:0%
yourselves an algorithm that learns that
first<00:03:08.220><c> listens</c><00:03:08.700><c> to</c><00:03:08.850><c> hours</c><00:03:09.209><c> of</c><00:03:09.360><c> music</c><00:03:10.280><c> learns</c>

00:03:11.270 --> 00:03:11.280 align:start position:0%
first listens to hours of music learns
 

00:03:11.280 --> 00:03:13.490 align:start position:0%
first listens to hours of music learns
the<00:03:11.730><c> underlying</c><00:03:12.270><c> representation</c><00:03:13.140><c> of</c><00:03:13.350><c> the</c>

00:03:13.490 --> 00:03:13.500 align:start position:0%
the underlying representation of the
 

00:03:13.500 --> 00:03:15.260 align:start position:0%
the underlying representation of the
notes<00:03:14.130><c> that</c><00:03:14.310><c> are</c><00:03:14.430><c> being</c><00:03:14.670><c> played</c><00:03:14.910><c> in</c><00:03:15.120><c> those</c>

00:03:15.260 --> 00:03:15.270 align:start position:0%
notes that are being played in those
 

00:03:15.270 --> 00:03:18.020 align:start position:0%
notes that are being played in those
songs<00:03:15.600><c> and</c><00:03:15.990><c> then</c><00:03:16.770><c> learns</c><00:03:16.980><c> to</c><00:03:17.130><c> build</c><00:03:17.400><c> brand</c><00:03:17.880><c> new</c>

00:03:18.020 --> 00:03:18.030 align:start position:0%
songs and then learns to build brand new
 

00:03:18.030 --> 00:03:20.410 align:start position:0%
songs and then learns to build brand new
songs<00:03:18.300><c> that</c><00:03:18.510><c> have</c><00:03:18.630><c> never</c><00:03:18.840><c> been</c><00:03:19.110><c> heard</c><00:03:19.230><c> before</c>

00:03:20.410 --> 00:03:20.420 align:start position:0%
songs that have never been heard before
 

00:03:20.420 --> 00:03:23.420 align:start position:0%
songs that have never been heard before
and<00:03:21.650><c> there</c><00:03:22.650><c> are</c><00:03:22.709><c> really</c><00:03:22.860><c> so</c><00:03:23.100><c> many</c><00:03:23.160><c> other</c>

00:03:23.420 --> 00:03:23.430 align:start position:0%
and there are really so many other
 

00:03:23.430 --> 00:03:25.190 align:start position:0%
and there are really so many other
incredible<00:03:23.940><c> success</c><00:03:24.300><c> stories</c><00:03:24.690><c> of</c><00:03:24.930><c> deep</c>

00:03:25.190 --> 00:03:25.200 align:start position:0%
incredible success stories of deep
 

00:03:25.200 --> 00:03:27.470 align:start position:0%
incredible success stories of deep
learning<00:03:25.410><c> that</c><00:03:26.400><c> I</c><00:03:26.430><c> could</c><00:03:26.640><c> talk</c><00:03:26.790><c> for</c><00:03:27.300><c> many</c>

00:03:27.470 --> 00:03:27.480 align:start position:0%
learning that I could talk for many
 

00:03:27.480 --> 00:03:28.880 align:start position:0%
learning that I could talk for many
hours<00:03:27.630><c> about</c><00:03:27.959><c> and</c><00:03:28.140><c> will</c><00:03:28.230><c> try</c><00:03:28.410><c> to</c><00:03:28.440><c> cover</c><00:03:28.709><c> as</c>

00:03:28.880 --> 00:03:28.890 align:start position:0%
hours about and will try to cover as
 

00:03:28.890 --> 00:03:30.380 align:start position:0%
hours about and will try to cover as
many<00:03:29.070><c> of</c><00:03:29.220><c> these</c><00:03:29.310><c> as</c><00:03:29.370><c> possible</c><00:03:29.940><c> as</c><00:03:30.030><c> part</c><00:03:30.330><c> of</c>

00:03:30.380 --> 00:03:30.390 align:start position:0%
many of these as possible as part of
 

00:03:30.390 --> 00:03:32.210 align:start position:0%
many of these as possible as part of
this<00:03:30.510><c> course</c><00:03:30.810><c> but</c><00:03:31.050><c> I</c><00:03:31.680><c> just</c><00:03:31.860><c> wanted</c><00:03:32.040><c> to</c><00:03:32.100><c> give</c>

00:03:32.210 --> 00:03:32.220 align:start position:0%
this course but I just wanted to give
 

00:03:32.220 --> 00:03:33.979 align:start position:0%
this course but I just wanted to give
you<00:03:32.250><c> an</c><00:03:32.519><c> overview</c><00:03:32.820><c> of</c><00:03:33.000><c> some</c><00:03:33.150><c> of</c><00:03:33.420><c> the</c><00:03:33.540><c> amazing</c>

00:03:33.979 --> 00:03:33.989 align:start position:0%
you an overview of some of the amazing
 

00:03:33.989 --> 00:03:35.270 align:start position:0%
you an overview of some of the amazing
ones<00:03:34.140><c> that</c><00:03:34.290><c> we'll</c><00:03:34.410><c> be</c><00:03:34.560><c> covering</c><00:03:34.709><c> as</c><00:03:35.010><c> part</c><00:03:35.220><c> of</c>

00:03:35.270 --> 00:03:35.280 align:start position:0%
ones that we'll be covering as part of
 

00:03:35.280 --> 00:03:38.000 align:start position:0%
ones that we'll be covering as part of
the<00:03:35.370><c> labs</c><00:03:35.610><c> that</c><00:03:36.209><c> you'll</c><00:03:36.360><c> be</c><00:03:36.510><c> implementing</c><00:03:37.010><c> and</c>

00:03:38.000 --> 00:03:38.010 align:start position:0%
the labs that you'll be implementing and
 

00:03:38.010 --> 00:03:40.040 align:start position:0%
the labs that you'll be implementing and
that's<00:03:38.880><c> really</c><00:03:39.060><c> the</c><00:03:39.120><c> goal</c><00:03:39.269><c> of</c><00:03:39.330><c> what</c><00:03:39.690><c> we</c><00:03:39.810><c> want</c>

00:03:40.040 --> 00:03:40.050 align:start position:0%
that's really the goal of what we want
 

00:03:40.050 --> 00:03:41.780 align:start position:0%
that's really the goal of what we want
you<00:03:40.470><c> to</c><00:03:40.650><c> accomplish</c><00:03:40.890><c> as</c><00:03:41.250><c> part</c><00:03:41.459><c> of</c><00:03:41.489><c> this</c><00:03:41.610><c> class</c>

00:03:41.780 --> 00:03:41.790 align:start position:0%
you to accomplish as part of this class
 

00:03:41.790 --> 00:03:44.360 align:start position:0%
you to accomplish as part of this class
firstly<00:03:42.720><c> we</c><00:03:42.870><c> want</c><00:03:42.989><c> to</c><00:03:43.140><c> provide</c><00:03:43.410><c> you</c><00:03:43.470><c> with</c><00:03:43.650><c> the</c>

00:03:44.360 --> 00:03:44.370 align:start position:0%
firstly we want to provide you with the
 

00:03:44.370 --> 00:03:46.640 align:start position:0%
firstly we want to provide you with the
foundation<00:03:44.519><c> to</c><00:03:45.239><c> do</c><00:03:45.420><c> deep</c><00:03:46.290><c> learn</c><00:03:46.470><c> to</c>

00:03:46.640 --> 00:03:46.650 align:start position:0%
foundation to do deep learn to
 

00:03:46.650 --> 00:03:48.320 align:start position:0%
foundation to do deep learn to
understand<00:03:47.160><c> what</c><00:03:47.340><c> these</c><00:03:47.489><c> algorithms</c><00:03:47.820><c> are</c>

00:03:48.320 --> 00:03:48.330 align:start position:0%
understand what these algorithms are
 

00:03:48.330 --> 00:03:50.750 align:start position:0%
understand what these algorithms are
doing<00:03:49.080><c> underneath</c><00:03:49.530><c> the</c><00:03:49.739><c> hood</c><00:03:49.830><c> how</c><00:03:50.310><c> they</c><00:03:50.519><c> work</c>

00:03:50.750 --> 00:03:50.760 align:start position:0%
doing underneath the hood how they work
 

00:03:50.760 --> 00:03:54.500 align:start position:0%
doing underneath the hood how they work
and<00:03:51.000><c> why</c><00:03:51.209><c> they</c><00:03:51.239><c> work</c><00:03:52.910><c> we</c><00:03:53.910><c> will</c><00:03:54.060><c> provide</c><00:03:54.330><c> you</c>

00:03:54.500 --> 00:03:54.510 align:start position:0%
and why they work we will provide you
 

00:03:54.510 --> 00:03:56.210 align:start position:0%
and why they work we will provide you
some<00:03:54.720><c> of</c><00:03:54.810><c> the</c><00:03:54.870><c> practical</c><00:03:55.380><c> skills</c><00:03:55.799><c> to</c>

00:03:56.210 --> 00:03:56.220 align:start position:0%
some of the practical skills to
 

00:03:56.220 --> 00:03:57.860 align:start position:0%
some of the practical skills to
implement<00:03:56.489><c> these</c><00:03:56.820><c> algorithms</c><00:03:57.360><c> and</c><00:03:57.540><c> deploy</c>

00:03:57.860 --> 00:03:57.870 align:start position:0%
implement these algorithms and deploy
 

00:03:57.870 --> 00:04:00.830 align:start position:0%
implement these algorithms and deploy
them<00:03:58.110><c> on</c><00:03:58.230><c> your</c><00:03:58.380><c> own</c><00:03:58.530><c> machines</c><00:03:59.510><c> and</c><00:04:00.510><c> will</c><00:04:00.630><c> talk</c>

00:04:00.830 --> 00:04:00.840 align:start position:0%
them on your own machines and will talk
 

00:04:00.840 --> 00:04:02.960 align:start position:0%
them on your own machines and will talk
to<00:04:01.080><c> you</c><00:04:01.200><c> about</c><00:04:01.320><c> some</c><00:04:02.040><c> of</c><00:04:02.160><c> the</c><00:04:02.220><c> stating</c><00:04:02.610><c> state</c>

00:04:02.960 --> 00:04:02.970 align:start position:0%
to you about some of the stating state
 

00:04:02.970 --> 00:04:04.910 align:start position:0%
to you about some of the stating state
of<00:04:03.120><c> art</c><00:04:03.330><c> and</c><00:04:03.630><c> cutting</c><00:04:04.049><c> edge</c><00:04:04.200><c> research</c><00:04:04.410><c> that's</c>

00:04:04.910 --> 00:04:04.920 align:start position:0%
of art and cutting edge research that's
 

00:04:04.920 --> 00:04:07.640 align:start position:0%
of art and cutting edge research that's
happening<00:04:05.340><c> in</c><00:04:05.840><c> deep</c><00:04:06.840><c> learning</c><00:04:06.989><c> industries</c>

00:04:07.640 --> 00:04:07.650 align:start position:0%
happening in deep learning industries
 

00:04:07.650 --> 00:04:10.930 align:start position:0%
happening in deep learning industries
and<00:04:07.890><c> deep</c><00:04:08.100><c> learning</c><00:04:08.250><c> academia</c><00:04:09.120><c> institutions</c>

00:04:10.930 --> 00:04:10.940 align:start position:0%
and deep learning academia institutions
 

00:04:10.940 --> 00:04:13.850 align:start position:0%
and deep learning academia institutions
finally<00:04:11.940><c> the</c><00:04:12.450><c> main</c><00:04:12.660><c> purpose</c><00:04:13.140><c> of</c><00:04:13.260><c> this</c><00:04:13.380><c> course</c>

00:04:13.850 --> 00:04:13.860 align:start position:0%
finally the main purpose of this course
 

00:04:13.860 --> 00:04:16.219 align:start position:0%
finally the main purpose of this course
is<00:04:14.100><c> we</c><00:04:14.250><c> want</c><00:04:14.430><c> to</c><00:04:14.640><c> build</c><00:04:15.269><c> a</c><00:04:15.450><c> community</c><00:04:15.600><c> here</c><00:04:16.140><c> at</c>

00:04:16.219 --> 00:04:16.229 align:start position:0%
is we want to build a community here at
 

00:04:16.229 --> 00:04:19.340 align:start position:0%
is we want to build a community here at
MIT<00:04:16.530><c> that</c><00:04:16.950><c> is</c><00:04:17.850><c> devoted</c><00:04:18.330><c> to</c><00:04:18.359><c> advancing</c><00:04:18.810><c> the</c>

00:04:19.340 --> 00:04:19.350 align:start position:0%
MIT that is devoted to advancing the
 

00:04:19.350 --> 00:04:20.590 align:start position:0%
MIT that is devoted to advancing the
state<00:04:19.560><c> of</c><00:04:19.799><c> artificial</c><00:04:20.160><c> intelligence</c>

00:04:20.590 --> 00:04:20.600 align:start position:0%
state of artificial intelligence
 

00:04:20.600 --> 00:04:23.180 align:start position:0%
state of artificial intelligence
advancing<00:04:21.600><c> a</c><00:04:21.660><c> state</c><00:04:21.840><c> of</c><00:04:21.959><c> deep</c><00:04:22.140><c> learning</c><00:04:22.320><c> as</c>

00:04:23.180 --> 00:04:23.190 align:start position:0%
advancing a state of deep learning as
 

00:04:23.190 --> 00:04:25.219 align:start position:0%
advancing a state of deep learning as
part<00:04:23.970><c> of</c><00:04:24.030><c> this</c><00:04:24.210><c> course</c><00:04:24.479><c> we'll</c><00:04:24.720><c> cover</c><00:04:24.900><c> some</c><00:04:25.050><c> of</c>

00:04:25.219 --> 00:04:25.229 align:start position:0%
part of this course we'll cover some of
 

00:04:25.229 --> 00:04:27.260 align:start position:0%
part of this course we'll cover some of
the<00:04:25.380><c> limitations</c><00:04:26.070><c> of</c><00:04:26.400><c> these</c><00:04:26.700><c> algorithms</c>

00:04:27.260 --> 00:04:27.270 align:start position:0%
the limitations of these algorithms
 

00:04:27.270 --> 00:04:28.980 align:start position:0%
the limitations of these algorithms
there<00:04:27.960><c> are</c><00:04:28.050><c> many</c>

00:04:28.980 --> 00:04:28.990 align:start position:0%
there are many
 

00:04:28.990 --> 00:04:30.180 align:start position:0%
there are many
we<00:04:29.110><c> need</c><00:04:29.289><c> to</c><00:04:29.380><c> be</c><00:04:29.500><c> mindful</c><00:04:29.919><c> of</c><00:04:30.039><c> these</c>

00:04:30.180 --> 00:04:30.190 align:start position:0%
we need to be mindful of these
 

00:04:30.190 --> 00:04:31.710 align:start position:0%
we need to be mindful of these
limitations<00:04:30.639><c> so</c><00:04:31.030><c> that</c><00:04:31.210><c> we</c><00:04:31.330><c> as</c><00:04:31.449><c> a</c><00:04:31.479><c> community</c>

00:04:31.710 --> 00:04:31.720 align:start position:0%
limitations so that we as a community
 

00:04:31.720 --> 00:04:34.080 align:start position:0%
limitations so that we as a community
can<00:04:32.020><c> move</c><00:04:32.229><c> forward</c><00:04:32.590><c> and</c><00:04:32.770><c> create</c><00:04:33.090><c> more</c>

00:04:34.080 --> 00:04:34.090 align:start position:0%
can move forward and create more
 

00:04:34.090 --> 00:04:38.490 align:start position:0%
can move forward and create more
intelligent<00:04:34.660><c> systems</c><00:04:36.840><c> but</c><00:04:37.840><c> before</c><00:04:38.139><c> we</c><00:04:38.349><c> do</c>

00:04:38.490 --> 00:04:38.500 align:start position:0%
intelligent systems but before we do
 

00:04:38.500 --> 00:04:39.870 align:start position:0%
intelligent systems but before we do
that<00:04:38.530><c> let's</c><00:04:39.099><c> just</c><00:04:39.340><c> start</c><00:04:39.520><c> with</c><00:04:39.639><c> some</c>

00:04:39.870 --> 00:04:39.880 align:start position:0%
that let's just start with some
 

00:04:39.880 --> 00:04:43.559 align:start position:0%
that let's just start with some
administrative<00:04:40.660><c> details</c><00:04:41.050><c> in</c><00:04:41.440><c> this</c><00:04:41.860><c> course</c><00:04:42.569><c> so</c>

00:04:43.559 --> 00:04:43.569 align:start position:0%
administrative details in this course so
 

00:04:43.569 --> 00:04:45.990 align:start position:0%
administrative details in this course so
this<00:04:44.289><c> course</c><00:04:44.530><c> is</c><00:04:44.680><c> a</c><00:04:44.710><c> one-week</c><00:04:45.039><c> course</c><00:04:45.340><c> today</c>

00:04:45.990 --> 00:04:46.000 align:start position:0%
this course is a one-week course today
 

00:04:46.000 --> 00:04:48.360 align:start position:0%
this course is a one-week course today
is<00:04:46.060><c> the</c><00:04:46.240><c> first</c><00:04:46.449><c> lecture</c><00:04:46.870><c> we</c><00:04:47.650><c> meet</c><00:04:47.919><c> every</c><00:04:48.190><c> day</c>

00:04:48.360 --> 00:04:48.370 align:start position:0%
is the first lecture we meet every day
 

00:04:48.370 --> 00:04:52.189 align:start position:0%
is the first lecture we meet every day
this<00:04:48.580><c> week</c><00:04:48.750><c> 10:30</c><00:04:49.750><c> a.m.</c><00:04:49.870><c> to</c><00:04:50.319><c> 1:30</c><00:04:50.500><c> p.m.</c><00:04:50.800><c> and</c>

00:04:52.189 --> 00:04:52.199 align:start position:0%
this week 10:30 a.m. to 1:30 p.m. and
 

00:04:52.199 --> 00:04:54.480 align:start position:0%
this week 10:30 a.m. to 1:30 p.m. and
this<00:04:53.199><c> during</c><00:04:53.500><c> this</c><00:04:53.590><c> three</c><00:04:53.860><c> hour</c><00:04:53.979><c> time</c><00:04:54.280><c> slot</c>

00:04:54.480 --> 00:04:54.490 align:start position:0%
this during this three hour time slot
 

00:04:54.490 --> 00:04:57.600 align:start position:0%
this during this three hour time slot
were<00:04:54.789><c> broken</c><00:04:55.150><c> down</c><00:04:55.419><c> into</c><00:04:56.310><c> one</c><00:04:57.310><c> and</c><00:04:57.430><c> a</c><00:04:57.490><c> half</c>

00:04:57.600 --> 00:04:57.610 align:start position:0%
were broken down into one and a half
 

00:04:57.610 --> 00:05:00.330 align:start position:0%
were broken down into one and a half
hour<00:04:57.819><c> time</c><00:04:58.060><c> slots</c><00:04:58.360><c> around</c><00:04:59.110><c> 50%</c><00:04:59.860><c> of</c><00:05:00.039><c> the</c><00:05:00.130><c> course</c>

00:05:00.330 --> 00:05:00.340 align:start position:0%
hour time slots around 50% of the course
 

00:05:00.340 --> 00:05:06.240 align:start position:0%
hour time slots around 50% of the course
see<00:05:00.580><c> each</c><00:05:00.759><c> and</c><00:05:01.349><c> each</c><00:05:02.349><c> of</c><00:05:02.530><c> those</c><00:05:03.180><c> have</c><00:05:05.250><c> half</c>

00:05:06.240 --> 00:05:06.250 align:start position:0%
see each and each of those have half
 

00:05:06.250 --> 00:05:08.310 align:start position:0%
see each and each of those have half
sections<00:05:06.759><c> of</c><00:05:07.060><c> this</c><00:05:07.180><c> course</c><00:05:07.419><c> will</c><00:05:07.720><c> consist</c><00:05:08.139><c> of</c>

00:05:08.310 --> 00:05:08.320 align:start position:0%
sections of this course will consist of
 

00:05:08.320 --> 00:05:10.140 align:start position:0%
sections of this course will consist of
lectures<00:05:08.949><c> which</c><00:05:09.310><c> is</c><00:05:09.490><c> what</c><00:05:09.759><c> you're</c><00:05:09.880><c> in</c><00:05:09.970><c> right</c>

00:05:10.140 --> 00:05:10.150 align:start position:0%
lectures which is what you're in right
 

00:05:10.150 --> 00:05:12.210 align:start position:0%
lectures which is what you're in right
now<00:05:10.300><c> and</c><00:05:10.539><c> the</c><00:05:11.169><c> second</c><00:05:11.500><c> part</c><00:05:11.680><c> is</c><00:05:11.830><c> the</c><00:05:12.039><c> labs</c>

00:05:12.210 --> 00:05:12.220 align:start position:0%
now and the second part is the labs
 

00:05:12.220 --> 00:05:13.529 align:start position:0%
now and the second part is the labs
where<00:05:12.460><c> you'll</c><00:05:12.639><c> actually</c><00:05:12.820><c> get</c><00:05:13.150><c> practice</c>

00:05:13.529 --> 00:05:13.539 align:start position:0%
where you'll actually get practice
 

00:05:13.539 --> 00:05:17.540 align:start position:0%
where you'll actually get practice
implementing<00:05:14.169><c> what</c><00:05:14.680><c> you</c><00:05:14.800><c> learn</c><00:05:15.009><c> in</c><00:05:15.220><c> lectures</c>

00:05:17.540 --> 00:05:17.550 align:start position:0%
implementing what you learn in lectures
 

00:05:17.550 --> 00:05:20.070 align:start position:0%
implementing what you learn in lectures
we<00:05:18.550><c> have</c><00:05:18.669><c> an</c><00:05:18.759><c> amazing</c><00:05:19.150><c> set</c><00:05:19.330><c> of</c><00:05:19.360><c> lectures</c><00:05:19.780><c> lined</c>

00:05:20.070 --> 00:05:20.080 align:start position:0%
we have an amazing set of lectures lined
 

00:05:20.080 --> 00:05:20.640 align:start position:0%
we have an amazing set of lectures lined
up<00:05:20.229><c> for</c><00:05:20.380><c> you</c>

00:05:20.640 --> 00:05:20.650 align:start position:0%
up for you
 

00:05:20.650 --> 00:05:22.700 align:start position:0%
up for you
so<00:05:20.919><c> today</c><00:05:21.190><c> we're</c><00:05:21.460><c> going</c><00:05:21.580><c> to</c><00:05:21.669><c> be</c><00:05:21.759><c> talking</c><00:05:22.120><c> about</c>

00:05:22.700 --> 00:05:22.710 align:start position:0%
so today we're going to be talking about
 

00:05:22.710 --> 00:05:24.899 align:start position:0%
so today we're going to be talking about
some<00:05:23.710><c> of</c><00:05:23.740><c> the</c><00:05:23.919><c> introduction</c><00:05:24.520><c> to</c><00:05:24.639><c> neural</c>

00:05:24.899 --> 00:05:24.909 align:start position:0%
some of the introduction to neural
 

00:05:24.909 --> 00:05:26.670 align:start position:0%
some of the introduction to neural
networks<00:05:25.270><c> which</c><00:05:25.509><c> is</c><00:05:25.659><c> really</c><00:05:25.870><c> the</c><00:05:25.960><c> backbone</c><00:05:26.110><c> of</c>

00:05:26.670 --> 00:05:26.680 align:start position:0%
networks which is really the backbone of
 

00:05:26.680 --> 00:05:29.370 align:start position:0%
networks which is really the backbone of
deep<00:05:27.039><c> learning</c><00:05:27.810><c> we're</c><00:05:28.810><c> also</c><00:05:28.930><c> talking</c><00:05:29.199><c> about</c>

00:05:29.370 --> 00:05:29.380 align:start position:0%
deep learning we're also talking about
 

00:05:29.380 --> 00:05:31.710 align:start position:0%
deep learning we're also talking about
modeling<00:05:29.860><c> sequence</c><00:05:30.550><c> data</c><00:05:30.909><c> so</c><00:05:31.240><c> this</c><00:05:31.360><c> is</c><00:05:31.509><c> what</c><00:05:31.690><c> I</c>

00:05:31.710 --> 00:05:31.720 align:start position:0%
modeling sequence data so this is what I
 

00:05:31.720 --> 00:05:33.649 align:start position:0%
modeling sequence data so this is what I
was<00:05:31.840><c> mentioning</c><00:05:32.080><c> about</c><00:05:32.380><c> the</c><00:05:32.530><c> temporally</c>

00:05:33.649 --> 00:05:33.659 align:start position:0%
was mentioning about the temporally
 

00:05:33.659 --> 00:05:36.779 align:start position:0%
was mentioning about the temporally
dependent<00:05:34.659><c> data</c><00:05:35.340><c> tomorrow</c><00:05:36.340><c> we'll</c><00:05:36.490><c> talk</c><00:05:36.610><c> about</c>

00:05:36.779 --> 00:05:36.789 align:start position:0%
dependent data tomorrow we'll talk about
 

00:05:36.789 --> 00:05:38.490 align:start position:0%
dependent data tomorrow we'll talk about
computer<00:05:37.270><c> vision</c><00:05:37.570><c> and</c><00:05:37.720><c> deep</c><00:05:37.960><c> generative</c>

00:05:38.490 --> 00:05:38.500 align:start position:0%
computer vision and deep generative
 

00:05:38.500 --> 00:05:41.040 align:start position:0%
computer vision and deep generative
models<00:05:38.889><c> we</c><00:05:39.610><c> have</c><00:05:39.639><c> one</c><00:05:40.000><c> of</c><00:05:40.120><c> the</c><00:05:40.300><c> inventors</c><00:05:40.840><c> of</c>

00:05:41.040 --> 00:05:41.050 align:start position:0%
models we have one of the inventors of
 

00:05:41.050 --> 00:05:43.560 align:start position:0%
models we have one of the inventors of
generative<00:05:41.770><c> adversarial</c><00:05:42.580><c> networks</c><00:05:43.120><c> coming</c>

00:05:43.560 --> 00:05:43.570 align:start position:0%
generative adversarial networks coming
 

00:05:43.570 --> 00:05:45.270 align:start position:0%
generative adversarial networks coming
to<00:05:43.690><c> give</c><00:05:43.840><c> that</c><00:05:44.020><c> lecture</c><00:05:44.199><c> for</c><00:05:44.530><c> us</c><00:05:44.620><c> so</c><00:05:44.830><c> that's</c>

00:05:45.270 --> 00:05:45.280 align:start position:0%
to give that lecture for us so that's
 

00:05:45.280 --> 00:05:48.209 align:start position:0%
to give that lecture for us so that's
going<00:05:45.460><c> to</c><00:05:45.520><c> be</c><00:05:45.639><c> a</c><00:05:45.669><c> great</c><00:05:45.909><c> lecture</c><00:05:46.270><c> and</c><00:05:47.099><c> the</c><00:05:48.099><c> day</c>

00:05:48.209 --> 00:05:48.219 align:start position:0%
going to be a great lecture and the day
 

00:05:48.219 --> 00:05:49.200 align:start position:0%
going to be a great lecture and the day
after<00:05:48.310><c> that</c><00:05:48.460><c> we'll</c><00:05:48.699><c> touch</c><00:05:48.849><c> on</c><00:05:49.000><c> deep</c>

00:05:49.200 --> 00:05:49.210 align:start position:0%
after that we'll touch on deep
 

00:05:49.210 --> 00:05:50.909 align:start position:0%
after that we'll touch on deep
reinforcement<00:05:49.900><c> learning</c><00:05:50.020><c> and</c><00:05:50.560><c> some</c><00:05:50.770><c> of</c><00:05:50.830><c> the</c>

00:05:50.909 --> 00:05:50.919 align:start position:0%
reinforcement learning and some of the
 

00:05:50.919 --> 00:05:53.550 align:start position:0%
reinforcement learning and some of the
open<00:05:51.280><c> challenges</c><00:05:51.789><c> in</c><00:05:52.000><c> AI</c><00:05:52.210><c> and</c><00:05:52.630><c> how</c><00:05:53.259><c> we</c><00:05:53.320><c> can</c>

00:05:53.550 --> 00:05:53.560 align:start position:0%
open challenges in AI and how we can
 

00:05:53.560 --> 00:05:56.610 align:start position:0%
open challenges in AI and how we can
move<00:05:53.680><c> forward</c><00:05:53.919><c> past</c><00:05:54.699><c> this</c><00:05:54.909><c> course</c><00:05:55.620><c> we'll</c>

00:05:56.610 --> 00:05:56.620 align:start position:0%
move forward past this course we'll
 

00:05:56.620 --> 00:05:59.219 align:start position:0%
move forward past this course we'll
spend<00:05:57.039><c> the</c><00:05:57.130><c> final</c><00:05:57.370><c> two</c><00:05:57.759><c> days</c><00:05:58.060><c> of</c><00:05:58.330><c> this</c><00:05:58.509><c> course</c>

00:05:59.219 --> 00:05:59.229 align:start position:0%
spend the final two days of this course
 

00:05:59.229 --> 00:06:01.860 align:start position:0%
spend the final two days of this course
talking<00:05:59.800><c> or</c><00:06:00.099><c> hearing</c><00:06:00.460><c> from</c><00:06:00.729><c> some</c><00:06:01.509><c> of</c><00:06:01.539><c> the</c>

00:06:01.860 --> 00:06:01.870 align:start position:0%
talking or hearing from some of the
 

00:06:01.870 --> 00:06:04.709 align:start position:0%
talking or hearing from some of the
leading<00:06:02.560><c> industry</c><00:06:03.270><c> representatives</c><00:06:04.270><c> doing</c>

00:06:04.709 --> 00:06:04.719 align:start position:0%
leading industry representatives doing
 

00:06:04.719 --> 00:06:07.170 align:start position:0%
leading industry representatives doing
deep<00:06:05.530><c> learning</c><00:06:05.770><c> in</c><00:06:06.280><c> their</c><00:06:06.729><c> respective</c>

00:06:07.170 --> 00:06:07.180 align:start position:0%
deep learning in their respective
 

00:06:07.180 --> 00:06:09.450 align:start position:0%
deep learning in their respective
companies<00:06:07.750><c> and</c><00:06:08.199><c> these</c><00:06:08.979><c> are</c><00:06:09.130><c> bound</c><00:06:09.280><c> to</c><00:06:09.370><c> be</c>

00:06:09.450 --> 00:06:09.460 align:start position:0%
companies and these are bound to be
 

00:06:09.460 --> 00:06:11.310 align:start position:0%
companies and these are bound to be
extremely<00:06:09.849><c> interesting</c><00:06:10.360><c> or</c><00:06:10.960><c> extremely</c>

00:06:11.310 --> 00:06:11.320 align:start position:0%
extremely interesting or extremely
 

00:06:11.320 --> 00:06:13.050 align:start position:0%
extremely interesting or extremely
exciting<00:06:11.800><c> so</c><00:06:12.009><c> I</c><00:06:12.039><c> highly</c><00:06:12.340><c> recommend</c><00:06:12.370><c> attending</c>

00:06:13.050 --> 00:06:13.060 align:start position:0%
exciting so I highly recommend attending
 

00:06:13.060 --> 00:06:17.249 align:start position:0%
exciting so I highly recommend attending
these<00:06:13.180><c> as</c><00:06:13.389><c> well</c><00:06:15.690><c> for</c><00:06:16.690><c> those</c><00:06:16.780><c> of</c><00:06:16.960><c> you</c><00:06:17.050><c> who</c><00:06:17.199><c> are</c>

00:06:17.249 --> 00:06:17.259 align:start position:0%
these as well for those of you who are
 

00:06:17.259 --> 00:06:19.230 align:start position:0%
these as well for those of you who are
taking<00:06:17.440><c> this</c><00:06:17.710><c> course</c><00:06:17.919><c> for</c><00:06:18.159><c> credit</c><00:06:18.550><c> you</c><00:06:19.210><c> have</c>

00:06:19.230 --> 00:06:19.240 align:start position:0%
taking this course for credit you have
 

00:06:19.240 --> 00:06:21.930 align:start position:0%
taking this course for credit you have
two<00:06:19.840><c> options</c><00:06:20.349><c> to</c><00:06:20.469><c> fulfill</c><00:06:20.979><c> your</c><00:06:21.219><c> graders</c>

00:06:21.930 --> 00:06:21.940 align:start position:0%
two options to fulfill your graders
 

00:06:21.940 --> 00:06:25.709 align:start position:0%
two options to fulfill your graders
assignment<00:06:22.419><c> the</c><00:06:23.409><c> first</c><00:06:23.650><c> option</c><00:06:24.099><c> is</c><00:06:24.419><c> a</c><00:06:25.419><c> project</c>

00:06:25.709 --> 00:06:25.719 align:start position:0%
assignment the first option is a project
 

00:06:25.719 --> 00:06:27.719 align:start position:0%
assignment the first option is a project
proposal<00:06:26.409><c> it's</c><00:06:26.560><c> a</c><00:06:26.620><c> one-minute</c><00:06:27.099><c> project</c><00:06:27.520><c> pitch</c>

00:06:27.719 --> 00:06:27.729 align:start position:0%
proposal it's a one-minute project pitch
 

00:06:27.729 --> 00:06:31.100 align:start position:0%
proposal it's a one-minute project pitch
that<00:06:28.240><c> will</c><00:06:28.419><c> take</c><00:06:28.840><c> place</c><00:06:29.080><c> during</c><00:06:29.289><c> Friday</c><00:06:29.680><c> and</c>

00:06:31.100 --> 00:06:31.110 align:start position:0%
that will take place during Friday and
 

00:06:31.110 --> 00:06:33.270 align:start position:0%
that will take place during Friday and
for<00:06:32.110><c> this</c><00:06:32.229><c> you</c><00:06:32.409><c> have</c><00:06:32.530><c> to</c><00:06:32.650><c> work</c><00:06:32.800><c> in</c><00:06:32.949><c> groups</c><00:06:33.159><c> of</c>

00:06:33.270 --> 00:06:33.280 align:start position:0%
for this you have to work in groups of
 

00:06:33.280 --> 00:06:35.100 align:start position:0%
for this you have to work in groups of
three<00:06:33.520><c> or</c><00:06:33.550><c> four</c><00:06:33.759><c> and</c><00:06:34.300><c> what</c><00:06:34.509><c> you'll</c><00:06:34.659><c> be</c><00:06:34.870><c> tasked</c>

00:06:35.100 --> 00:06:35.110 align:start position:0%
three or four and what you'll be tasked
 

00:06:35.110 --> 00:06:37.290 align:start position:0%
three or four and what you'll be tasked
to<00:06:35.229><c> do</c><00:06:35.440><c> is</c><00:06:35.620><c> just</c><00:06:36.219><c> come</c><00:06:36.400><c> up</c><00:06:36.550><c> with</c><00:06:36.729><c> interesting</c>

00:06:37.290 --> 00:06:37.300 align:start position:0%
to do is just come up with interesting
 

00:06:37.300 --> 00:06:40.320 align:start position:0%
to do is just come up with interesting
deep<00:06:37.719><c> learning</c><00:06:37.870><c> idea</c><00:06:38.770><c> and</c><00:06:39.010><c> try</c><00:06:39.760><c> to</c><00:06:39.820><c> show</c><00:06:40.060><c> some</c>

00:06:40.320 --> 00:06:40.330 align:start position:0%
deep learning idea and try to show some
 

00:06:40.330 --> 00:06:42.810 align:start position:0%
deep learning idea and try to show some
sort<00:06:40.510><c> of</c><00:06:41.070><c> results</c><00:06:42.070><c> if</c><00:06:42.159><c> possible</c>

00:06:42.810 --> 00:06:42.820 align:start position:0%
sort of results if possible
 

00:06:42.820 --> 00:06:45.270 align:start position:0%
sort of results if possible
we<00:06:42.940><c> understand</c><00:06:43.390><c> that</c><00:06:43.540><c> one</c><00:06:43.750><c> week</c><00:06:43.960><c> is</c><00:06:44.280><c> extremely</c>

00:06:45.270 --> 00:06:45.280 align:start position:0%
we understand that one week is extremely
 

00:06:45.280 --> 00:06:47.010 align:start position:0%
we understand that one week is extremely
short<00:06:45.460><c> to</c><00:06:45.670><c> create</c><00:06:45.910><c> any</c><00:06:46.090><c> type</c><00:06:46.300><c> of</c><00:06:46.360><c> results</c><00:06:46.960><c> or</c>

00:06:47.010 --> 00:06:47.020 align:start position:0%
short to create any type of results or
 

00:06:47.020 --> 00:06:49.140 align:start position:0%
short to create any type of results or
even<00:06:47.290><c> come</c><00:06:47.440><c> up</c><00:06:47.470><c> with</c><00:06:47.620><c> a</c><00:06:47.790><c> interesting</c><00:06:48.790><c> idea</c><00:06:49.090><c> for</c>

00:06:49.140 --> 00:06:49.150 align:start position:0%
even come up with a interesting idea for
 

00:06:49.150 --> 00:06:52.140 align:start position:0%
even come up with a interesting idea for
that<00:06:49.420><c> matter</c><00:06:49.570><c> but</c><00:06:50.580><c> we're</c><00:06:51.580><c> going</c><00:06:51.700><c> to</c><00:06:51.790><c> be</c><00:06:51.910><c> giving</c>

00:06:52.140 --> 00:06:52.150 align:start position:0%
that matter but we're going to be giving
 

00:06:52.150 --> 00:06:54.570 align:start position:0%
that matter but we're going to be giving
out<00:06:52.210><c> some</c><00:06:52.390><c> amazing</c><00:06:52.780><c> prizes</c><00:06:53.070><c> so</c><00:06:54.070><c> including</c>

00:06:54.570 --> 00:06:54.580 align:start position:0%
out some amazing prizes so including
 

00:06:54.580 --> 00:07:00.210 align:start position:0%
out some amazing prizes so including
some<00:06:54.910><c> nvidia</c><00:06:55.870><c> gpus</c><00:06:56.380><c> and</c><00:06:57.040><c> google</c><00:06:57.490><c> homes</c><00:06:59.220><c> on</c>

00:07:00.210 --> 00:07:00.220 align:start position:0%
some nvidia gpus and google homes on
 

00:07:00.220 --> 00:07:02.040 align:start position:0%
some nvidia gpus and google homes on
friday<00:07:00.700><c> you'll</c><00:07:01.000><c> like</c><00:07:01.540><c> I</c><00:07:01.630><c> said</c><00:07:01.840><c> give</c><00:07:02.020><c> a</c>

00:07:02.040 --> 00:07:02.050 align:start position:0%
friday you'll like I said give a
 

00:07:02.050 --> 00:07:04.650 align:start position:0%
friday you'll like I said give a
one-minute<00:07:02.590><c> pitch</c><00:07:03.090><c> there's</c><00:07:04.090><c> somewhat</c><00:07:04.480><c> of</c><00:07:04.510><c> an</c>

00:07:04.650 --> 00:07:04.660 align:start position:0%
one-minute pitch there's somewhat of an
 

00:07:04.660 --> 00:07:08.040 align:start position:0%
one-minute pitch there's somewhat of an
arts<00:07:04.990><c> to</c><00:07:06.090><c> your</c><00:07:07.090><c> idea</c><00:07:07.390><c> in</c><00:07:07.510><c> just</c><00:07:07.660><c> one</c><00:07:07.900><c> minute</c>

00:07:08.040 --> 00:07:08.050 align:start position:0%
arts to your idea in just one minute
 

00:07:08.050 --> 00:07:10.260 align:start position:0%
arts to your idea in just one minute
even<00:07:08.320><c> though</c><00:07:08.530><c> it's</c><00:07:08.650><c> extremely</c><00:07:08.890><c> short</c><00:07:09.400><c> so</c><00:07:10.120><c> we</c>

00:07:10.260 --> 00:07:10.270 align:start position:0%
even though it's extremely short so we
 

00:07:10.270 --> 00:07:11.550 align:start position:0%
even though it's extremely short so we
will<00:07:10.450><c> be</c><00:07:10.600><c> holding</c><00:07:10.900><c> you</c><00:07:10.990><c> to</c><00:07:11.110><c> a</c><00:07:11.170><c> strict</c><00:07:11.440><c> deadline</c>

00:07:11.550 --> 00:07:11.560 align:start position:0%
will be holding you to a strict deadline
 

00:07:11.560 --> 00:07:13.880 align:start position:0%
will be holding you to a strict deadline
of<00:07:11.980><c> that</c><00:07:12.160><c> one</c><00:07:12.310><c> minute</c>

00:07:13.880 --> 00:07:13.890 align:start position:0%
of that one minute
 

00:07:13.890 --> 00:07:16.050 align:start position:0%
of that one minute
the<00:07:14.890><c> second</c><00:07:15.190><c> option</c><00:07:15.340><c> is</c><00:07:15.610><c> a</c><00:07:15.670><c> little</c><00:07:15.970><c> more</c>

00:07:16.050 --> 00:07:16.060 align:start position:0%
the second option is a little more
 

00:07:16.060 --> 00:07:17.640 align:start position:0%
the second option is a little more
boring<00:07:16.330><c> but</c><00:07:16.900><c> you'll</c><00:07:17.050><c> be</c><00:07:17.200><c> able</c><00:07:17.290><c> to</c><00:07:17.470><c> write</c><00:07:17.620><c> a</c>

00:07:17.640 --> 00:07:17.650 align:start position:0%
boring but you'll be able to write a
 

00:07:17.650 --> 00:07:19.740 align:start position:0%
boring but you'll be able to write a
one-page<00:07:17.890><c> paper</c><00:07:18.310><c> about</c><00:07:18.820><c> any</c><00:07:19.060><c> deep</c><00:07:19.570><c> learning</c>

00:07:19.740 --> 00:07:19.750 align:start position:0%
one-page paper about any deep learning
 

00:07:19.750 --> 00:07:21.620 align:start position:0%
one-page paper about any deep learning
paper<00:07:20.110><c> that</c><00:07:20.380><c> you</c><00:07:20.470><c> find</c><00:07:20.710><c> interesting</c><00:07:20.890><c> and</c>

00:07:21.620 --> 00:07:21.630 align:start position:0%
paper that you find interesting and
 

00:07:21.630 --> 00:07:23.670 align:start position:0%
paper that you find interesting and
really<00:07:22.630><c> that's</c><00:07:22.750><c> if</c><00:07:22.960><c> you</c><00:07:23.050><c> can't</c><00:07:23.290><c> do</c><00:07:23.440><c> the</c>

00:07:23.670 --> 00:07:23.680 align:start position:0%
really that's if you can't do the
 

00:07:23.680 --> 00:07:29.370 align:start position:0%
really that's if you can't do the
project<00:07:24.070><c> proposal</c><00:07:24.580><c> you</c><00:07:25.120><c> can</c><00:07:25.300><c> do</c><00:07:25.420><c> that</c><00:07:28.380><c> this</c>

00:07:29.370 --> 00:07:29.380 align:start position:0%
project proposal you can do that this
 

00:07:29.380 --> 00:07:31.770 align:start position:0%
project proposal you can do that this
class<00:07:29.680><c> has</c><00:07:30.010><c> a</c><00:07:30.040><c> lot</c><00:07:30.370><c> of</c><00:07:30.400><c> online</c><00:07:30.640><c> resources</c><00:07:31.000><c> you</c>

00:07:31.770 --> 00:07:31.780 align:start position:0%
class has a lot of online resources you
 

00:07:31.780 --> 00:07:33.660 align:start position:0%
class has a lot of online resources you
can<00:07:31.900><c> find</c><00:07:32.140><c> support</c><00:07:32.320><c> on</c><00:07:32.590><c> Piazza</c><00:07:32.890><c> please</c><00:07:33.370><c> post</c>

00:07:33.660 --> 00:07:33.670 align:start position:0%
can find support on Piazza please post
 

00:07:33.670 --> 00:07:35.730 align:start position:0%
can find support on Piazza please post
if<00:07:33.880><c> you</c><00:07:33.910><c> have</c><00:07:34.060><c> any</c><00:07:34.210><c> questions</c><00:07:34.690><c> about</c><00:07:34.960><c> the</c>

00:07:35.730 --> 00:07:35.740 align:start position:0%
if you have any questions about the
 

00:07:35.740 --> 00:07:38.340 align:start position:0%
if you have any questions about the
lectures<00:07:36.130><c> the</c><00:07:36.370><c> labs</c><00:07:37.020><c> installing</c><00:07:38.020><c> any</c><00:07:38.140><c> of</c><00:07:38.230><c> the</c>

00:07:38.340 --> 00:07:38.350 align:start position:0%
lectures the labs installing any of the
 

00:07:38.350 --> 00:07:41.850 align:start position:0%
lectures the labs installing any of the
software<00:07:38.770><c> etc</c><00:07:40.050><c> also</c><00:07:41.050><c> try</c><00:07:41.320><c> to</c><00:07:41.350><c> keep</c><00:07:41.530><c> up</c><00:07:41.710><c> to</c><00:07:41.740><c> date</c>

00:07:41.850 --> 00:07:41.860 align:start position:0%
software etc also try to keep up to date
 

00:07:41.860 --> 00:07:43.650 align:start position:0%
software etc also try to keep up to date
with<00:07:42.130><c> the</c><00:07:42.280><c> course</c><00:07:42.490><c> website</c><00:07:42.730><c> we'll</c><00:07:43.120><c> be</c><00:07:43.480><c> posting</c>

00:07:43.650 --> 00:07:43.660 align:start position:0%
with the course website we'll be posting
 

00:07:43.660 --> 00:07:47.520 align:start position:0%
with the course website we'll be posting
all<00:07:44.350><c> of</c><00:07:44.470><c> the</c><00:07:44.830><c> lectures</c><00:07:45.670><c> labs</c><00:07:46.270><c> and</c><00:07:46.810><c> video</c>

00:07:47.520 --> 00:07:47.530 align:start position:0%
all of the lectures labs and video
 

00:07:47.530 --> 00:07:52.260 align:start position:0%
all of the lectures labs and video
recordings<00:07:48.010><c> online</c><00:07:48.400><c> as</c><00:07:49.120><c> well</c><00:07:51.030><c> we</c><00:07:52.030><c> have</c><00:07:52.180><c> an</c>

00:07:52.260 --> 00:07:52.270 align:start position:0%
recordings online as well we have an
 

00:07:52.270 --> 00:07:54.090 align:start position:0%
recordings online as well we have an
amazing<00:07:52.360><c> team</c><00:07:52.720><c> that</c><00:07:53.500><c> you</c><00:07:53.590><c> can</c><00:07:53.740><c> reach</c><00:07:53.920><c> out</c><00:07:54.040><c> to</c>

00:07:54.090 --> 00:07:54.100 align:start position:0%
amazing team that you can reach out to
 

00:07:54.100 --> 00:07:56.310 align:start position:0%
amazing team that you can reach out to
at<00:07:54.580><c> any</c><00:07:54.730><c> time</c><00:07:54.970><c> in</c><00:07:55.690><c> case</c><00:07:55.930><c> you</c><00:07:56.050><c> have</c><00:07:56.170><c> any</c>

00:07:56.310 --> 00:07:56.320 align:start position:0%
at any time in case you have any
 

00:07:56.320 --> 00:07:57.930 align:start position:0%
at any time in case you have any
problems<00:07:56.650><c> with</c><00:07:56.680><c> anything</c><00:07:57.160><c> feel</c><00:07:57.730><c> free</c><00:07:57.760><c> to</c>

00:07:57.930 --> 00:07:57.940 align:start position:0%
problems with anything feel free to
 

00:07:57.940 --> 00:07:59.580 align:start position:0%
problems with anything feel free to
reach<00:07:58.240><c> out</c><00:07:58.360><c> to</c><00:07:58.420><c> any</c><00:07:58.660><c> of</c><00:07:58.750><c> us</c><00:07:58.900><c> and</c><00:07:59.140><c> we</c><00:07:59.260><c> wanted</c><00:07:59.500><c> to</c>

00:07:59.580 --> 00:07:59.590 align:start position:0%
reach out to any of us and we wanted to
 

00:07:59.590 --> 00:08:00.900 align:start position:0%
reach out to any of us and we wanted to
give<00:07:59.800><c> a</c><00:07:59.830><c> huge</c><00:08:00.040><c> thanks</c><00:08:00.460><c> to</c><00:08:00.490><c> all</c><00:08:00.610><c> of</c><00:08:00.700><c> our</c>

00:08:00.900 --> 00:08:00.910 align:start position:0%
give a huge thanks to all of our
 

00:08:00.910 --> 00:08:03.780 align:start position:0%
give a huge thanks to all of our
sponsors<00:08:01.320><c> who</c><00:08:02.320><c> without</c><00:08:02.560><c> this</c><00:08:02.800><c> without</c><00:08:03.520><c> their</c>

00:08:03.780 --> 00:08:03.790 align:start position:0%
sponsors who without this without their
 

00:08:03.790 --> 00:08:05.940 align:start position:0%
sponsors who without this without their
support<00:08:04.180><c> this</c><00:08:04.960><c> class</c><00:08:05.200><c> would</c><00:08:05.440><c> simply</c><00:08:05.800><c> not</c>

00:08:05.940 --> 00:08:05.950 align:start position:0%
support this class would simply not
 

00:08:05.950 --> 00:08:08.490 align:start position:0%
support this class would simply not
happened<00:08:06.340><c> the</c><00:08:06.430><c> way</c><00:08:06.930><c> the</c><00:08:07.930><c> way</c><00:08:08.020><c> it's</c><00:08:08.140><c> happening</c>

00:08:08.490 --> 00:08:08.500 align:start position:0%
happened the way the way it's happening
 

00:08:08.500 --> 00:08:11.850 align:start position:0%
happened the way the way it's happening
this<00:08:08.650><c> year</c><00:08:10.200><c> so</c><00:08:11.200><c> now</c><00:08:11.320><c> let's</c><00:08:11.470><c> start</c><00:08:11.560><c> with</c><00:08:11.740><c> the</c>

00:08:11.850 --> 00:08:11.860 align:start position:0%
this year so now let's start with the
 

00:08:11.860 --> 00:08:15.120 align:start position:0%
this year so now let's start with the
fun<00:08:12.010><c> stuff</c><00:08:12.570><c> and</c><00:08:13.570><c> let's</c><00:08:14.410><c> start</c><00:08:14.680><c> by</c><00:08:14.860><c> actually</c>

00:08:15.120 --> 00:08:15.130 align:start position:0%
fun stuff and let's start by actually
 

00:08:15.130 --> 00:08:18.330 align:start position:0%
fun stuff and let's start by actually
asking<00:08:15.430><c> ourselves</c><00:08:15.580><c> a</c><00:08:16.000><c> question</c><00:08:16.890><c> why</c><00:08:17.890><c> do</c><00:08:17.950><c> we</c>

00:08:18.330 --> 00:08:18.340 align:start position:0%
asking ourselves a question why do we
 

00:08:18.340 --> 00:08:21.180 align:start position:0%
asking ourselves a question why do we
even<00:08:18.460><c> care</c><00:08:18.640><c> about</c><00:08:19.120><c> deep</c><00:08:19.450><c> learning</c><00:08:19.710><c> so</c><00:08:20.710><c> why</c><00:08:20.980><c> now</c>

00:08:21.180 --> 00:08:21.190 align:start position:0%
even care about deep learning so why now
 

00:08:21.190 --> 00:08:24.780 align:start position:0%
even care about deep learning so why now
and<00:08:21.790><c> why</c><00:08:22.300><c> do</c><00:08:22.360><c> we</c><00:08:22.510><c> why</c><00:08:23.440><c> do</c><00:08:23.500><c> we</c><00:08:23.740><c> even</c><00:08:23.830><c> sit</c><00:08:24.550><c> in</c><00:08:24.580><c> this</c>

00:08:24.780 --> 00:08:24.790 align:start position:0%
and why do we why do we even sit in this
 

00:08:24.790 --> 00:08:28.710 align:start position:0%
and why do we why do we even sit in this
class<00:08:25.000><c> today</c><00:08:26.310><c> so</c><00:08:27.310><c> traditional</c><00:08:28.270><c> machine</c>

00:08:28.710 --> 00:08:28.720 align:start position:0%
class today so traditional machine
 

00:08:28.720 --> 00:08:31.500 align:start position:0%
class today so traditional machine
learning<00:08:29.110><c> algorithms</c><00:08:30.150><c> typically</c><00:08:31.150><c> define</c>

00:08:31.500 --> 00:08:31.510 align:start position:0%
learning algorithms typically define
 

00:08:31.510 --> 00:08:34.320 align:start position:0%
learning algorithms typically define
sets<00:08:31.870><c> of</c><00:08:32.080><c> pre-programmed</c><00:08:33.000><c> features</c><00:08:34.000><c> and</c><00:08:34.270><c> the</c>

00:08:34.320 --> 00:08:34.330 align:start position:0%
sets of pre-programmed features and the
 

00:08:34.330 --> 00:08:36.690 align:start position:0%
sets of pre-programmed features and the
data<00:08:34.540><c> and</c><00:08:34.840><c> they</c><00:08:35.680><c> work</c><00:08:35.890><c> to</c><00:08:36.099><c> extract</c><00:08:36.520><c> these</c>

00:08:36.690 --> 00:08:36.700 align:start position:0%
data and they work to extract these
 

00:08:36.700 --> 00:08:40.020 align:start position:0%
data and they work to extract these
features<00:08:37.210><c> as</c><00:08:37.570><c> part</c><00:08:38.229><c> of</c><00:08:38.320><c> their</c><00:08:38.530><c> pipeline</c><00:08:39.030><c> now</c>

00:08:40.020 --> 00:08:40.030 align:start position:0%
features as part of their pipeline now
 

00:08:40.030 --> 00:08:41.940 align:start position:0%
features as part of their pipeline now
the<00:08:40.120><c> key</c><00:08:40.450><c> differentiating</c><00:08:40.960><c> point</c><00:08:41.590><c> of</c><00:08:41.740><c> deep</c>

00:08:41.940 --> 00:08:41.950 align:start position:0%
the key differentiating point of deep
 

00:08:41.950 --> 00:08:43.860 align:start position:0%
the key differentiating point of deep
learning<00:08:42.130><c> is</c><00:08:42.640><c> that</c><00:08:42.880><c> it</c><00:08:42.970><c> recognizes</c><00:08:43.450><c> that</c><00:08:43.720><c> in</c>

00:08:43.860 --> 00:08:43.870 align:start position:0%
learning is that it recognizes that in
 

00:08:43.870 --> 00:08:46.680 align:start position:0%
learning is that it recognizes that in
many<00:08:44.110><c> practical</c><00:08:44.650><c> situations</c><00:08:45.300><c> these</c><00:08:46.300><c> features</c>

00:08:46.680 --> 00:08:46.690 align:start position:0%
many practical situations these features
 

00:08:46.690 --> 00:08:49.470 align:start position:0%
many practical situations these features
can<00:08:46.900><c> be</c><00:08:46.930><c> extremely</c><00:08:47.470><c> brittle</c><00:08:48.120><c> so</c><00:08:49.120><c> what</c><00:08:49.240><c> deep</c>

00:08:49.470 --> 00:08:49.480 align:start position:0%
can be extremely brittle so what deep
 

00:08:49.480 --> 00:08:52.320 align:start position:0%
can be extremely brittle so what deep
learning<00:08:49.630><c> tries</c><00:08:49.990><c> to</c><00:08:50.170><c> do</c><00:08:50.350><c> is</c><00:08:51.030><c> learn</c><00:08:52.030><c> these</c>

00:08:52.320 --> 00:08:52.330 align:start position:0%
learning tries to do is learn these
 

00:08:52.330 --> 00:08:54.510 align:start position:0%
learning tries to do is learn these
features<00:08:52.720><c> directly</c><00:08:53.320><c> from</c><00:08:53.440><c> data</c><00:08:53.740><c> as</c><00:08:54.040><c> opposed</c>

00:08:54.510 --> 00:08:54.520 align:start position:0%
features directly from data as opposed
 

00:08:54.520 --> 00:08:56.420 align:start position:0%
features directly from data as opposed
to<00:08:54.640><c> being</c><00:08:54.820><c> hand</c><00:08:55.360><c> engineered</c>

00:08:56.420 --> 00:08:56.430 align:start position:0%
to being hand engineered
 

00:08:56.430 --> 00:09:00.769 align:start position:0%
to being hand engineered
by<00:08:56.550><c> the</c><00:08:56.610><c> human</c><00:08:58.040><c> that</c><00:08:59.040><c> is</c><00:08:59.220><c> can</c><00:08:59.670><c> we</c><00:08:59.820><c> learn</c><00:09:00.060><c> if</c><00:09:00.420><c> we</c>

00:09:00.769 --> 00:09:00.779 align:start position:0%
by the human that is can we learn if we
 

00:09:00.779 --> 00:09:02.480 align:start position:0%
by the human that is can we learn if we
want<00:09:00.960><c> to</c><00:09:00.990><c> learn</c><00:09:01.200><c> to</c><00:09:01.260><c> detect</c><00:09:01.680><c> faces</c><00:09:02.130><c> can</c><00:09:02.339><c> we</c>

00:09:02.480 --> 00:09:02.490 align:start position:0%
want to learn to detect faces can we
 

00:09:02.490 --> 00:09:04.460 align:start position:0%
want to learn to detect faces can we
first<00:09:02.760><c> learn</c><00:09:03.060><c> automatically</c><00:09:03.690><c> from</c><00:09:03.930><c> data</c><00:09:04.170><c> that</c>

00:09:04.460 --> 00:09:04.470 align:start position:0%
first learn automatically from data that
 

00:09:04.470 --> 00:09:07.310 align:start position:0%
first learn automatically from data that
to<00:09:04.890><c> detect</c><00:09:05.250><c> faces</c><00:09:05.490><c> we</c><00:09:05.940><c> first</c><00:09:06.210><c> need</c><00:09:06.420><c> to</c><00:09:06.450><c> detect</c>

00:09:07.310 --> 00:09:07.320 align:start position:0%
to detect faces we first need to detect
 

00:09:07.320 --> 00:09:10.100 align:start position:0%
to detect faces we first need to detect
edges<00:09:07.500><c> in</c><00:09:07.860><c> the</c><00:09:07.950><c> image</c><00:09:08.510><c> compose</c><00:09:09.510><c> these</c><00:09:09.750><c> edges</c>

00:09:10.100 --> 00:09:10.110 align:start position:0%
edges in the image compose these edges
 

00:09:10.110 --> 00:09:12.949 align:start position:0%
edges in the image compose these edges
together<00:09:10.290><c> to</c><00:09:10.800><c> detect</c><00:09:11.130><c> eyes</c><00:09:11.399><c> and</c><00:09:11.760><c> ears</c><00:09:12.029><c> then</c>

00:09:12.949 --> 00:09:12.959 align:start position:0%
together to detect eyes and ears then
 

00:09:12.959 --> 00:09:14.870 align:start position:0%
together to detect eyes and ears then
compose<00:09:13.350><c> these</c><00:09:13.470><c> eyes</c><00:09:13.680><c> and</c><00:09:13.920><c> ears</c><00:09:14.100><c> together</c><00:09:14.610><c> to</c>

00:09:14.870 --> 00:09:14.880 align:start position:0%
compose these eyes and ears together to
 

00:09:14.880 --> 00:09:17.090 align:start position:0%
compose these eyes and ears together to
form<00:09:15.089><c> higher-level</c><00:09:15.600><c> facial</c><00:09:16.380><c> structure</c><00:09:16.830><c> and</c>

00:09:17.090 --> 00:09:17.100 align:start position:0%
form higher-level facial structure and
 

00:09:17.100 --> 00:09:19.400 align:start position:0%
form higher-level facial structure and
in<00:09:17.730><c> this</c><00:09:17.880><c> way</c><00:09:18.089><c> deep</c><00:09:18.600><c> learning</c><00:09:18.750><c> represents</c><00:09:19.350><c> a</c>

00:09:19.400 --> 00:09:19.410 align:start position:0%
in this way deep learning represents a
 

00:09:19.410 --> 00:09:22.280 align:start position:0%
in this way deep learning represents a
form<00:09:19.680><c> of</c><00:09:19.860><c> a</c><00:09:19.980><c> hierarchical</c><00:09:20.580><c> model</c><00:09:21.089><c> capable</c><00:09:21.839><c> of</c>

00:09:22.280 --> 00:09:22.290 align:start position:0%
form of a hierarchical model capable of
 

00:09:22.290 --> 00:09:24.740 align:start position:0%
form of a hierarchical model capable of
representing<00:09:23.070><c> different</c><00:09:23.790><c> levels</c><00:09:24.630><c> of</c>

00:09:24.740 --> 00:09:24.750 align:start position:0%
representing different levels of
 

00:09:24.750 --> 00:09:28.730 align:start position:0%
representing different levels of
abstraction<00:09:25.020><c> in</c><00:09:25.529><c> the</c><00:09:25.770><c> data</c><00:09:27.350><c> so</c><00:09:28.350><c> actually</c><00:09:28.649><c> the</c>

00:09:28.730 --> 00:09:28.740 align:start position:0%
abstraction in the data so actually the
 

00:09:28.740 --> 00:09:30.230 align:start position:0%
abstraction in the data so actually the
fundamental<00:09:29.190><c> building</c><00:09:29.399><c> blocks</c><00:09:29.790><c> of</c><00:09:29.970><c> deep</c>

00:09:30.230 --> 00:09:30.240 align:start position:0%
fundamental building blocks of deep
 

00:09:30.240 --> 00:09:32.930 align:start position:0%
fundamental building blocks of deep
learning<00:09:30.420><c> which</c><00:09:30.899><c> are</c><00:09:31.050><c> neural</c><00:09:31.380><c> networks</c><00:09:31.940><c> have</c>

00:09:32.930 --> 00:09:32.940 align:start position:0%
learning which are neural networks have
 

00:09:32.940 --> 00:09:35.120 align:start position:0%
learning which are neural networks have
actually<00:09:33.270><c> been</c><00:09:33.390><c> existing</c><00:09:33.959><c> have</c><00:09:34.709><c> actually</c>

00:09:35.120 --> 00:09:35.130 align:start position:0%
actually been existing have actually
 

00:09:35.130 --> 00:09:37.790 align:start position:0%
actually been existing have actually
existed<00:09:35.220><c> for</c><00:09:36.000><c> decades</c><00:09:36.200><c> so</c><00:09:37.200><c> why</c><00:09:37.649><c> are</c><00:09:37.709><c> we</c>

00:09:37.790 --> 00:09:37.800 align:start position:0%
existed for decades so why are we
 

00:09:37.800 --> 00:09:40.910 align:start position:0%
existed for decades so why are we
studying<00:09:38.040><c> this</c><00:09:38.220><c> now</c><00:09:38.459><c> well</c><00:09:39.300><c> there's</c><00:09:39.480><c> three</c><00:09:39.930><c> key</c>

00:09:40.910 --> 00:09:40.920 align:start position:0%
studying this now well there's three key
 

00:09:40.920 --> 00:09:44.180 align:start position:0%
studying this now well there's three key
points<00:09:41.220><c> here</c><00:09:41.399><c> the</c><00:09:42.360><c> first</c><00:09:42.570><c> is</c><00:09:42.720><c> that</c><00:09:42.930><c> data</c><00:09:43.709><c> has</c>

00:09:44.180 --> 00:09:44.190 align:start position:0%
points here the first is that data has
 

00:09:44.190 --> 00:09:48.350 align:start position:0%
points here the first is that data has
become<00:09:45.500><c> much</c><00:09:46.500><c> more</c><00:09:46.560><c> pervasive</c><00:09:47.029><c> we're</c><00:09:48.029><c> living</c>

00:09:48.350 --> 00:09:48.360 align:start position:0%
become much more pervasive we're living
 

00:09:48.360 --> 00:09:49.880 align:start position:0%
become much more pervasive we're living
in<00:09:48.450><c> a</c><00:09:48.540><c> big</c><00:09:48.839><c> data</c><00:09:49.020><c> environment</c><00:09:49.410><c> these</c>

00:09:49.880 --> 00:09:49.890 align:start position:0%
in a big data environment these
 

00:09:49.890 --> 00:09:51.889 align:start position:0%
in a big data environment these
algorithms<00:09:50.279><c> are</c><00:09:50.610><c> hungry</c><00:09:51.060><c> for</c><00:09:51.089><c> more</c><00:09:51.600><c> and</c><00:09:51.750><c> more</c>

00:09:51.889 --> 00:09:51.899 align:start position:0%
algorithms are hungry for more and more
 

00:09:51.899 --> 00:09:56.090 align:start position:0%
algorithms are hungry for more and more
data<00:09:52.110><c> and</c><00:09:54.200><c> accessing</c><00:09:55.200><c> that</c><00:09:55.320><c> data</c><00:09:55.560><c> has</c><00:09:55.770><c> become</c>

00:09:56.090 --> 00:09:56.100 align:start position:0%
data and accessing that data has become
 

00:09:56.100 --> 00:09:58.180 align:start position:0%
data and accessing that data has become
easier<00:09:56.520><c> than</c><00:09:56.760><c> ever</c><00:09:56.910><c> before</c>

00:09:58.180 --> 00:09:58.190 align:start position:0%
easier than ever before
 

00:09:58.190 --> 00:10:00.530 align:start position:0%
easier than ever before
second<00:09:59.190><c> these</c><00:09:59.459><c> algorithms</c><00:09:59.760><c> are</c><00:10:00.060><c> massively</c>

00:10:00.530 --> 00:10:00.540 align:start position:0%
second these algorithms are massively
 

00:10:00.540 --> 00:10:02.000 align:start position:0%
second these algorithms are massively
parallel<00:10:00.810><c> Liza</c><00:10:01.200><c> below</c><00:10:01.440><c> and</c><00:10:01.529><c> can</c><00:10:01.620><c> benefit</c>

00:10:02.000 --> 00:10:02.010 align:start position:0%
parallel Liza below and can benefit
 

00:10:02.010 --> 00:10:05.660 align:start position:0%
parallel Liza below and can benefit
tremendously<00:10:02.250><c> from</c><00:10:04.310><c> modern</c><00:10:05.310><c> GPU</c>

00:10:05.660 --> 00:10:05.670 align:start position:0%
tremendously from modern GPU
 

00:10:05.670 --> 00:10:07.579 align:start position:0%
tremendously from modern GPU
architectures<00:10:06.240><c> that</c><00:10:06.270><c> simply</c><00:10:06.900><c> just</c><00:10:07.230><c> did</c><00:10:07.470><c> not</c>

00:10:07.579 --> 00:10:07.589 align:start position:0%
architectures that simply just did not
 

00:10:07.589 --> 00:10:10.340 align:start position:0%
architectures that simply just did not
exist<00:10:08.130><c> just</c><00:10:08.730><c> less</c><00:10:09.420><c> more</c><00:10:09.870><c> than</c><00:10:09.990><c> a</c><00:10:10.020><c> decade</c><00:10:10.320><c> ago</c>

00:10:10.340 --> 00:10:10.350 align:start position:0%
exist just less more than a decade ago
 

00:10:10.350 --> 00:10:13.310 align:start position:0%
exist just less more than a decade ago
and<00:10:11.000><c> finally</c><00:10:12.000><c> due</c><00:10:12.330><c> to</c><00:10:12.360><c> open-source</c><00:10:12.870><c> tool</c>

00:10:13.310 --> 00:10:13.320 align:start position:0%
and finally due to open-source tool
 

00:10:13.320 --> 00:10:16.820 align:start position:0%
and finally due to open-source tool
boxes<00:10:13.740><c> like</c><00:10:13.920><c> tensor</c><00:10:14.279><c> flow</c><00:10:15.709><c> building</c><00:10:16.709><c> and</c>

00:10:16.820 --> 00:10:16.830 align:start position:0%
boxes like tensor flow building and
 

00:10:16.830 --> 00:10:18.829 align:start position:0%
boxes like tensor flow building and
deploying<00:10:16.920><c> these</c><00:10:17.250><c> algorithms</c><00:10:17.760><c> has</c><00:10:18.330><c> become</c><00:10:18.630><c> so</c>

00:10:18.829 --> 00:10:18.839 align:start position:0%
deploying these algorithms has become so
 

00:10:18.839 --> 00:10:20.900 align:start position:0%
deploying these algorithms has become so
streamlined<00:10:19.170><c> so</c><00:10:20.010><c> simple</c><00:10:20.400><c> that</c><00:10:20.490><c> we</c><00:10:20.550><c> can</c><00:10:20.760><c> teach</c>

00:10:20.900 --> 00:10:20.910 align:start position:0%
streamlined so simple that we can teach
 

00:10:20.910 --> 00:10:22.579 align:start position:0%
streamlined so simple that we can teach
it<00:10:21.060><c> in</c><00:10:21.180><c> a</c><00:10:21.270><c> one-week</c><00:10:21.630><c> course</c><00:10:21.870><c> like</c><00:10:22.140><c> this</c><00:10:22.320><c> and</c>

00:10:22.579 --> 00:10:22.589 align:start position:0%
it in a one-week course like this and
 

00:10:22.589 --> 00:10:25.790 align:start position:0%
it in a one-week course like this and
it's<00:10:23.010><c> become</c><00:10:23.250><c> extremely</c><00:10:24.080><c> deployable</c><00:10:25.080><c> for</c><00:10:25.740><c> the</c>

00:10:25.790 --> 00:10:25.800 align:start position:0%
it's become extremely deployable for the
 

00:10:25.800 --> 00:10:30.320 align:start position:0%
it's become extremely deployable for the
massive<00:10:26.400><c> public</c><00:10:28.040><c> so</c><00:10:29.040><c> let's</c><00:10:29.220><c> start</c><00:10:29.430><c> with</c><00:10:29.580><c> now</c>

00:10:30.320 --> 00:10:30.330 align:start position:0%
massive public so let's start with now
 

00:10:30.330 --> 00:10:31.430 align:start position:0%
massive public so let's start with now
looking<00:10:30.600><c> at</c><00:10:30.660><c> the</c><00:10:30.779><c> fundamental</c><00:10:31.260><c> building</c>

00:10:31.430 --> 00:10:31.440 align:start position:0%
looking at the fundamental building
 

00:10:31.440 --> 00:10:33.560 align:start position:0%
looking at the fundamental building
block<00:10:31.830><c> of</c><00:10:31.860><c> deep</c><00:10:32.580><c> learning</c><00:10:32.760><c> and</c><00:10:33.060><c> that's</c><00:10:33.150><c> the</c>

00:10:33.560 --> 00:10:33.570 align:start position:0%
block of deep learning and that's the
 

00:10:33.570 --> 00:10:36.019 align:start position:0%
block of deep learning and that's the
perceptron<00:10:34.050><c> this</c><00:10:34.740><c> is</c><00:10:34.860><c> really</c><00:10:35.100><c> just</c><00:10:35.339><c> a</c><00:10:35.520><c> single</c>

00:10:36.019 --> 00:10:36.029 align:start position:0%
perceptron this is really just a single
 

00:10:36.029 --> 00:10:41.269 align:start position:0%
perceptron this is really just a single
neuron<00:10:36.450><c> in</c><00:10:36.690><c> a</c><00:10:36.870><c> neural</c><00:10:37.020><c> network</c><00:10:39.620><c> so</c><00:10:40.620><c> the</c><00:10:41.010><c> idea</c>

00:10:41.269 --> 00:10:41.279 align:start position:0%
neuron in a neural network so the idea
 

00:10:41.279 --> 00:10:43.960 align:start position:0%
neuron in a neural network so the idea
of<00:10:41.339><c> a</c><00:10:41.400><c> perceptron</c><00:10:42.000><c> or</c><00:10:42.209><c> a</c><00:10:42.540><c> single</c><00:10:42.839><c> neuron</c><00:10:43.140><c> is</c>

00:10:43.960 --> 00:10:43.970 align:start position:0%
of a perceptron or a single neuron is
 

00:10:43.970 --> 00:10:47.180 align:start position:0%
of a perceptron or a single neuron is
extremely<00:10:44.970><c> simple</c><00:10:45.480><c> let's</c><00:10:46.230><c> start</c><00:10:46.529><c> by</c><00:10:46.680><c> talking</c>

00:10:47.180 --> 00:10:47.190 align:start position:0%
extremely simple let's start by talking
 

00:10:47.190 --> 00:10:48.860 align:start position:0%
extremely simple let's start by talking
about<00:10:47.339><c> the</c><00:10:47.610><c> forward</c><00:10:48.029><c> propagation</c><00:10:48.570><c> of</c>

00:10:48.860 --> 00:10:48.870 align:start position:0%
about the forward propagation of
 

00:10:48.870 --> 00:10:52.040 align:start position:0%
about the forward propagation of
information<00:10:49.470><c> through</c><00:10:49.860><c> this</c><00:10:50.070><c> data</c><00:10:50.310><c> unit</c><00:10:51.050><c> we</c>

00:10:52.040 --> 00:10:52.050 align:start position:0%
information through this data unit we
 

00:10:52.050 --> 00:10:54.680 align:start position:0%
information through this data unit we
define<00:10:52.320><c> a</c><00:10:52.350><c> set</c><00:10:52.560><c> of</c><00:10:52.649><c> inputs</c><00:10:53.070><c> x1</c><00:10:53.550><c> through</c><00:10:54.029><c> XM</c><00:10:54.480><c> on</c>

00:10:54.680 --> 00:10:54.690 align:start position:0%
define a set of inputs x1 through XM on
 

00:10:54.690 --> 00:10:58.910 align:start position:0%
define a set of inputs x1 through XM on
the<00:10:54.930><c> left</c><00:10:56.839><c> and</c><00:10:57.839><c> all</c><00:10:58.140><c> we</c><00:10:58.260><c> do</c><00:10:58.410><c> is</c><00:10:58.560><c> we</c><00:10:58.709><c> multiply</c>

00:10:58.910 --> 00:10:58.920 align:start position:0%
the left and all we do is we multiply
 

00:10:58.920 --> 00:11:00.680 align:start position:0%
the left and all we do is we multiply
each<00:10:59.399><c> of</c><00:10:59.430><c> these</c><00:10:59.670><c> inputs</c><00:10:59.880><c> by</c><00:11:00.510><c> their</c>

00:11:00.680 --> 00:11:00.690 align:start position:0%
each of these inputs by their
 

00:11:00.690 --> 00:11:02.750 align:start position:0%
each of these inputs by their
corresponding<00:11:00.959><c> weight</c><00:11:01.529><c> theta1</c><00:11:02.370><c> through</c>

00:11:02.750 --> 00:11:02.760 align:start position:0%
corresponding weight theta1 through
 

00:11:02.760 --> 00:11:06.110 align:start position:0%
corresponding weight theta1 through
theta<00:11:02.940><c> m</c><00:11:03.180><c> which</c><00:11:03.810><c> are</c><00:11:03.959><c> those</c><00:11:04.079><c> arrows</c><00:11:04.910><c> we</c><00:11:05.910><c> take</c>

00:11:06.110 --> 00:11:06.120 align:start position:0%
theta m which are those arrows we take
 

00:11:06.120 --> 00:11:08.740 align:start position:0%
theta m which are those arrows we take
this<00:11:06.270><c> weighted</c><00:11:06.750><c> we</c><00:11:07.380><c> take</c><00:11:08.010><c> this</c><00:11:08.160><c> weighted</c>

00:11:08.740 --> 00:11:08.750 align:start position:0%
this weighted we take this weighted
 

00:11:08.750 --> 00:11:10.220 align:start position:0%
this weighted we take this weighted
combination

00:11:10.220 --> 00:11:10.230 align:start position:0%
combination
 

00:11:10.230 --> 00:11:12.620 align:start position:0%
combination
of<00:11:10.380><c> all</c><00:11:10.530><c> of</c><00:11:10.650><c> our</c><00:11:10.770><c> inputs</c><00:11:11.060><c> sum</c><00:11:12.060><c> them</c><00:11:12.240><c> up</c><00:11:12.270><c> and</c>

00:11:12.620 --> 00:11:12.630 align:start position:0%
of all of our inputs sum them up and
 

00:11:12.630 --> 00:11:14.840 align:start position:0%
of all of our inputs sum them up and
pass<00:11:13.140><c> them</c><00:11:13.350><c> through</c><00:11:13.380><c> a</c><00:11:13.560><c> nonlinear</c><00:11:14.100><c> activation</c>

00:11:14.840 --> 00:11:14.850 align:start position:0%
pass them through a nonlinear activation
 

00:11:14.850 --> 00:11:18.290 align:start position:0%
pass them through a nonlinear activation
function<00:11:15.360><c> and</c><00:11:16.460><c> that</c><00:11:17.460><c> produces</c><00:11:17.880><c> our</c><00:11:18.000><c> output</c>

00:11:18.290 --> 00:11:18.300 align:start position:0%
function and that produces our output
 

00:11:18.300 --> 00:11:20.660 align:start position:0%
function and that produces our output
why<00:11:18.450><c> it's</c><00:11:18.840><c> that</c><00:11:18.930><c> simple</c><00:11:19.200><c> so</c><00:11:19.530><c> we</c><00:11:19.650><c> have</c><00:11:19.770><c> M</c><00:11:20.010><c> inputs</c>

00:11:20.660 --> 00:11:20.670 align:start position:0%
why it's that simple so we have M inputs
 

00:11:20.670 --> 00:11:24.170 align:start position:0%
why it's that simple so we have M inputs
one<00:11:21.330><c> output</c><00:11:21.600><c> number</c><00:11:22.170><c> and</c><00:11:22.760><c> you</c><00:11:23.760><c> can</c><00:11:23.850><c> see</c><00:11:24.090><c> it</c>

00:11:24.170 --> 00:11:24.180 align:start position:0%
one output number and you can see it
 

00:11:24.180 --> 00:11:27.080 align:start position:0%
one output number and you can see it
summarized<00:11:24.660><c> on</c><00:11:24.960><c> the</c><00:11:25.530><c> right-hand</c><00:11:26.310><c> side</c><00:11:26.400><c> as</c><00:11:26.850><c> a</c>

00:11:27.080 --> 00:11:27.090 align:start position:0%
summarized on the right-hand side as a
 

00:11:27.090 --> 00:11:29.590 align:start position:0%
summarized on the right-hand side as a
mathematic<00:11:27.630><c> single</c><00:11:27.930><c> mathematical</c><00:11:28.080><c> equation</c>

00:11:29.590 --> 00:11:29.600 align:start position:0%
mathematic single mathematical equation
 

00:11:29.600 --> 00:11:31.760 align:start position:0%
mathematic single mathematical equation
but<00:11:30.600><c> actually</c><00:11:30.870><c> I</c><00:11:30.900><c> left</c><00:11:31.020><c> that</c><00:11:31.230><c> one</c><00:11:31.380><c> important</c>

00:11:31.760 --> 00:11:31.770 align:start position:0%
but actually I left that one important
 

00:11:31.770 --> 00:11:34.910 align:start position:0%
but actually I left that one important
detail<00:11:32.570><c> that</c><00:11:33.570><c> makes</c><00:11:34.080><c> the</c><00:11:34.230><c> previous</c><00:11:34.590><c> slide</c><00:11:34.770><c> not</c>

00:11:34.910 --> 00:11:34.920 align:start position:0%
detail that makes the previous slide not
 

00:11:34.920 --> 00:11:35.870 align:start position:0%
detail that makes the previous slide not
exactly<00:11:35.280><c> correct</c>

00:11:35.870 --> 00:11:35.880 align:start position:0%
exactly correct
 

00:11:35.880 --> 00:11:38.750 align:start position:0%
exactly correct
so<00:11:36.030><c> I</c><00:11:36.360><c> left</c><00:11:37.170><c> that</c><00:11:37.320><c> this</c><00:11:37.500><c> notion</c><00:11:37.710><c> of</c><00:11:37.950><c> a</c><00:11:38.040><c> bias</c><00:11:38.310><c> a</c>

00:11:38.750 --> 00:11:38.760 align:start position:0%
so I left that this notion of a bias a
 

00:11:38.760 --> 00:11:42.290 align:start position:0%
so I left that this notion of a bias a
bias<00:11:39.660><c> is</c><00:11:39.960><c> a</c><00:11:40.130><c> that</c><00:11:41.130><c> green</c><00:11:41.460><c> term</c><00:11:41.730><c> you</c><00:11:41.910><c> see</c><00:11:42.060><c> on</c><00:11:42.150><c> the</c>

00:11:42.290 --> 00:11:42.300 align:start position:0%
bias is a that green term you see on the
 

00:11:42.300 --> 00:11:44.390 align:start position:0%
bias is a that green term you see on the
left<00:11:42.510><c> and</c><00:11:42.870><c> this</c><00:11:43.230><c> just</c><00:11:43.500><c> represents</c><00:11:43.650><c> some</c><00:11:44.280><c> way</c>

00:11:44.390 --> 00:11:44.400 align:start position:0%
left and this just represents some way
 

00:11:44.400 --> 00:11:47.510 align:start position:0%
left and this just represents some way
that<00:11:44.430><c> we</c><00:11:44.730><c> can</c><00:11:44.850><c> allow</c><00:11:45.120><c> our</c><00:11:45.300><c> model</c><00:11:45.720><c> to</c><00:11:45.990><c> learn</c><00:11:46.520><c> or</c>

00:11:47.510 --> 00:11:47.520 align:start position:0%
that we can allow our model to learn or
 

00:11:47.520 --> 00:11:49.340 align:start position:0%
that we can allow our model to learn or
we<00:11:47.790><c> can</c><00:11:47.910><c> allow</c><00:11:48.120><c> our</c><00:11:48.240><c> activation</c><00:11:48.840><c> function</c><00:11:49.230><c> to</c>

00:11:49.340 --> 00:11:49.350 align:start position:0%
we can allow our activation function to
 

00:11:49.350 --> 00:11:50.720 align:start position:0%
we can allow our activation function to
shift<00:11:49.620><c> to</c><00:11:49.830><c> the</c><00:11:49.860><c> left</c><00:11:49.950><c> or</c><00:11:50.310><c> right</c>

00:11:50.720 --> 00:11:50.730 align:start position:0%
shift to the left or right
 

00:11:50.730 --> 00:11:54.190 align:start position:0%
shift to the left or right
so<00:11:51.210><c> it</c><00:11:51.300><c> allows</c><00:11:51.540><c> if</c><00:11:51.930><c> we</c><00:11:52.590><c> provide</c><00:11:52.920><c> allows</c><00:11:53.670><c> us</c><00:11:53.850><c> to</c>

00:11:54.190 --> 00:11:54.200 align:start position:0%
so it allows if we provide allows us to
 

00:11:54.200 --> 00:11:57.290 align:start position:0%
so it allows if we provide allows us to
when<00:11:55.200><c> we</c><00:11:55.530><c> have</c><00:11:55.680><c> no</c><00:11:55.920><c> input</c><00:11:56.280><c> features</c><00:11:56.610><c> to</c><00:11:57.060><c> still</c>

00:11:57.290 --> 00:11:57.300 align:start position:0%
when we have no input features to still
 

00:11:57.300 --> 00:12:02.360 align:start position:0%
when we have no input features to still
provide<00:11:57.480><c> a</c><00:11:57.630><c> positive</c><00:11:58.140><c> output</c><00:12:00.770><c> so</c><00:12:01.770><c> on</c><00:12:02.070><c> this</c>

00:12:02.360 --> 00:12:02.370 align:start position:0%
provide a positive output so on this
 

00:12:02.370 --> 00:12:04.610 align:start position:0%
provide a positive output so on this
equation<00:12:02.910><c> on</c><00:12:03.000><c> the</c><00:12:03.090><c> right</c><00:12:03.200><c> we</c><00:12:04.200><c> can</c><00:12:04.380><c> actually</c>

00:12:04.610 --> 00:12:04.620 align:start position:0%
equation on the right we can actually
 

00:12:04.620 --> 00:12:07.120 align:start position:0%
equation on the right we can actually
rewrite<00:12:05.610><c> this</c><00:12:05.760><c> using</c><00:12:06.120><c> linear</c><00:12:06.390><c> algebra</c><00:12:06.870><c> and</c>

00:12:07.120 --> 00:12:07.130 align:start position:0%
rewrite this using linear algebra and
 

00:12:07.130 --> 00:12:10.420 align:start position:0%
rewrite this using linear algebra and
dot<00:12:08.130><c> products</c><00:12:08.490><c> to</c><00:12:09.300><c> make</c><00:12:09.420><c> this</c><00:12:09.570><c> a</c><00:12:09.600><c> lot</c><00:12:09.870><c> cleaner</c>

00:12:10.420 --> 00:12:10.430 align:start position:0%
dot products to make this a lot cleaner
 

00:12:10.430 --> 00:12:14.990 align:start position:0%
dot products to make this a lot cleaner
so<00:12:11.430><c> let's</c><00:12:11.610><c> do</c><00:12:11.790><c> that</c><00:12:11.820><c> let's</c><00:12:12.770><c> say</c><00:12:13.770><c> X</c><00:12:14.040><c> capital</c><00:12:14.820><c> X</c>

00:12:14.990 --> 00:12:15.000 align:start position:0%
so let's do that let's say X capital X
 

00:12:15.000 --> 00:12:17.690 align:start position:0%
so let's do that let's say X capital X
is<00:12:15.390><c> a</c><00:12:16.170><c> vector</c><00:12:16.530><c> containing</c><00:12:17.100><c> all</c><00:12:17.310><c> of</c><00:12:17.340><c> our</c><00:12:17.520><c> inputs</c>

00:12:17.690 --> 00:12:17.700 align:start position:0%
is a vector containing all of our inputs
 

00:12:17.700 --> 00:12:22.910 align:start position:0%
is a vector containing all of our inputs
x1<00:12:18.330><c> through</c><00:12:18.720><c> XM</c><00:12:20.180><c> capital</c><00:12:21.180><c> theta</c><00:12:21.360><c> is</c><00:12:22.320><c> now</c><00:12:22.620><c> just</c>

00:12:22.910 --> 00:12:22.920 align:start position:0%
x1 through XM capital theta is now just
 

00:12:22.920 --> 00:12:24.470 align:start position:0%
x1 through XM capital theta is now just
a<00:12:23.040><c> vector</c><00:12:23.220><c> containing</c><00:12:23.760><c> all</c><00:12:23.940><c> of</c><00:12:23.970><c> our</c><00:12:24.150><c> Thetas</c>

00:12:24.470 --> 00:12:24.480 align:start position:0%
a vector containing all of our Thetas
 

00:12:24.480 --> 00:12:27.770 align:start position:0%
a vector containing all of our Thetas
theta<00:12:24.870><c> 1</c><00:12:25.110><c> to</c><00:12:25.290><c> theta</c><00:12:25.320><c> M</c><00:12:26.210><c> we</c><00:12:27.210><c> can</c><00:12:27.240><c> rewrite</c><00:12:27.720><c> that</c>

00:12:27.770 --> 00:12:27.780 align:start position:0%
theta 1 to theta M we can rewrite that
 

00:12:27.780 --> 00:12:29.330 align:start position:0%
theta 1 to theta M we can rewrite that
equation<00:12:27.960><c> that</c><00:12:28.380><c> we</c><00:12:28.500><c> had</c><00:12:28.620><c> before</c><00:12:28.800><c> is</c><00:12:29.070><c> just</c>

00:12:29.330 --> 00:12:29.340 align:start position:0%
equation that we had before is just
 

00:12:29.340 --> 00:12:31.130 align:start position:0%
equation that we had before is just
applying<00:12:29.640><c> a</c><00:12:29.760><c> dot</c><00:12:29.970><c> product</c><00:12:30.240><c> between</c><00:12:30.480><c> X</c><00:12:30.870><c> and</c>

00:12:31.130 --> 00:12:31.140 align:start position:0%
applying a dot product between X and
 

00:12:31.140 --> 00:12:35.150 align:start position:0%
applying a dot product between X and
theta<00:12:31.370><c> adding</c><00:12:32.370><c> our</c><00:12:32.460><c> bias</c><00:12:32.700><c> theta</c><00:12:33.330><c> 0</c><00:12:33.630><c> and</c><00:12:34.160><c> apply</c>

00:12:35.150 --> 00:12:35.160 align:start position:0%
theta adding our bias theta 0 and apply
 

00:12:35.160 --> 00:12:40.610 align:start position:0%
theta adding our bias theta 0 and apply
our<00:12:35.310><c> non-linearity</c><00:12:36.000><c> G</c><00:12:39.260><c> now</c><00:12:40.260><c> you</c><00:12:40.350><c> might</c><00:12:40.500><c> be</c>

00:12:40.610 --> 00:12:40.620 align:start position:0%
our non-linearity G now you might be
 

00:12:40.620 --> 00:12:42.530 align:start position:0%
our non-linearity G now you might be
wondering<00:12:40.880><c> since</c><00:12:41.880><c> I've</c><00:12:42.060><c> mentioned</c><00:12:42.420><c> this</c><00:12:42.480><c> a</c>

00:12:42.530 --> 00:12:42.540 align:start position:0%
wondering since I've mentioned this a
 

00:12:42.540 --> 00:12:45.170 align:start position:0%
wondering since I've mentioned this a
couple<00:12:42.900><c> times</c><00:12:42.930><c> now</c><00:12:43.320><c> what</c><00:12:44.040><c> is</c><00:12:44.190><c> this</c><00:12:44.400><c> nonlinear</c>

00:12:45.170 --> 00:12:45.180 align:start position:0%
couple times now what is this nonlinear
 

00:12:45.180 --> 00:12:47.930 align:start position:0%
couple times now what is this nonlinear
function<00:12:45.840><c> G</c><00:12:46.190><c> well</c><00:12:47.190><c> I</c><00:12:47.220><c> said</c><00:12:47.490><c> it's</c><00:12:47.640><c> the</c>

00:12:47.930 --> 00:12:47.940 align:start position:0%
function G well I said it's the
 

00:12:47.940 --> 00:12:50.090 align:start position:0%
function G well I said it's the
activation<00:12:48.450><c> function</c><00:12:48.480><c> but</c><00:12:49.320><c> let's</c><00:12:49.920><c> see</c><00:12:50.040><c> an</c>

00:12:50.090 --> 00:12:50.100 align:start position:0%
activation function but let's see an
 

00:12:50.100 --> 00:12:52.820 align:start position:0%
activation function but let's see an
example<00:12:50.220><c> of</c><00:12:50.640><c> what</c><00:12:50.910><c> in</c><00:12:51.060><c> practice</c><00:12:51.650><c> G</c><00:12:52.650><c> actually</c>

00:12:52.820 --> 00:12:52.830 align:start position:0%
example of what in practice G actually
 

00:12:52.830 --> 00:12:56.420 align:start position:0%
example of what in practice G actually
could<00:12:53.220><c> be</c><00:12:53.960><c> so</c><00:12:54.960><c> one</c><00:12:55.140><c> very</c><00:12:55.380><c> popular</c><00:12:55.650><c> activation</c>

00:12:56.420 --> 00:12:56.430 align:start position:0%
could be so one very popular activation
 

00:12:56.430 --> 00:12:58.670 align:start position:0%
could be so one very popular activation
function<00:12:56.790><c> is</c><00:12:56.880><c> the</c><00:12:57.000><c> sigmoid</c><00:12:57.420><c> function</c><00:12:57.900><c> you</c><00:12:58.500><c> can</c>

00:12:58.670 --> 00:12:58.680 align:start position:0%
function is the sigmoid function you can
 

00:12:58.680 --> 00:13:00.440 align:start position:0%
function is the sigmoid function you can
see<00:12:58.920><c> a</c><00:12:59.160><c> plot</c><00:12:59.520><c> of</c><00:12:59.700><c> it</c><00:12:59.820><c> here</c><00:13:00.060><c> on</c><00:13:00.180><c> the</c><00:13:00.270><c> bottom</c>

00:13:00.440 --> 00:13:00.450 align:start position:0%
see a plot of it here on the bottom
 

00:13:00.450 --> 00:13:03.110 align:start position:0%
see a plot of it here on the bottom
right<00:13:01.130><c> and</c><00:13:02.130><c> this</c><00:13:02.460><c> is</c><00:13:02.610><c> a</c><00:13:02.640><c> function</c><00:13:02.850><c> that</c><00:13:03.030><c> takes</c>

00:13:03.110 --> 00:13:03.120 align:start position:0%
right and this is a function that takes
 

00:13:03.120 --> 00:13:06.470 align:start position:0%
right and this is a function that takes
its<00:13:03.540><c> input</c><00:13:04.220><c> any</c><00:13:05.220><c> real</c><00:13:05.490><c> number</c><00:13:05.820><c> on</c><00:13:06.000><c> the</c><00:13:06.120><c> x-axis</c>

00:13:06.470 --> 00:13:06.480 align:start position:0%
its input any real number on the x-axis
 

00:13:06.480 --> 00:13:09.320 align:start position:0%
its input any real number on the x-axis
and<00:13:06.990><c> transforms</c><00:13:07.740><c> it</c><00:13:07.890><c> to</c><00:13:07.920><c> an</c><00:13:08.070><c> output</c><00:13:08.430><c> between</c><00:13:08.790><c> 0</c>

00:13:09.320 --> 00:13:09.330 align:start position:0%
and transforms it to an output between 0
 

00:13:09.330 --> 00:13:12.170 align:start position:0%
and transforms it to an output between 0
and<00:13:09.600><c> 1</c><00:13:10.100><c> because</c><00:13:11.100><c> all</c><00:13:11.310><c> outputs</c><00:13:12.000><c> of</c><00:13:12.090><c> this</c>

00:13:12.170 --> 00:13:12.180 align:start position:0%
and 1 because all outputs of this
 

00:13:12.180 --> 00:13:13.760 align:start position:0%
and 1 because all outputs of this
function<00:13:12.240><c> are</c><00:13:12.570><c> between</c><00:13:12.750><c> 0</c><00:13:13.080><c> &amp;</c><00:13:13.200><c> 1</c><00:13:13.230><c> it</c><00:13:13.470><c> makes</c><00:13:13.620><c> it</c><00:13:13.710><c> a</c>

00:13:13.760 --> 00:13:13.770 align:start position:0%
function are between 0 &amp; 1 it makes it a
 

00:13:13.770 --> 00:13:16.070 align:start position:0%
function are between 0 &amp; 1 it makes it a
very<00:13:13.920><c> popular</c><00:13:14.550><c> choice</c><00:13:14.820><c> in</c><00:13:14.880><c> deep</c><00:13:15.210><c> learning</c><00:13:15.600><c> to</c>

00:13:16.070 --> 00:13:16.080 align:start position:0%
very popular choice in deep learning to
 

00:13:16.080 --> 00:13:21.140 align:start position:0%
very popular choice in deep learning to
represent<00:13:16.560><c> probabilities</c><00:13:18.440><c> in</c><00:13:19.730><c> fact</c><00:13:20.730><c> there</c>

00:13:21.140 --> 00:13:21.150 align:start position:0%
represent probabilities in fact there
 

00:13:21.150 --> 00:13:23.270 align:start position:0%
represent probabilities in fact there
are<00:13:21.240><c> many</c><00:13:21.450><c> types</c><00:13:21.870><c> of</c><00:13:22.080><c> nonlinear</c><00:13:22.770><c> activation</c>

00:13:23.270 --> 00:13:23.280 align:start position:0%
are many types of nonlinear activation
 

00:13:23.280 --> 00:13:24.110 align:start position:0%
are many types of nonlinear activation
functions<00:13:23.820><c> in</c>

00:13:24.110 --> 00:13:24.120 align:start position:0%
functions in
 

00:13:24.120 --> 00:13:25.850 align:start position:0%
functions in
Durrell<00:13:24.420><c> networks</c><00:13:24.720><c> and</c><00:13:25.080><c> here</c><00:13:25.589><c> are</c><00:13:25.650><c> some</c><00:13:25.770><c> of</c>

00:13:25.850 --> 00:13:25.860 align:start position:0%
Durrell networks and here are some of
 

00:13:25.860 --> 00:13:27.800 align:start position:0%
Durrell networks and here are some of
the<00:13:25.920><c> common</c><00:13:26.190><c> ones</c><00:13:26.660><c> throughout</c><00:13:27.660><c> this</c>

00:13:27.800 --> 00:13:27.810 align:start position:0%
the common ones throughout this
 

00:13:27.810 --> 00:13:29.720 align:start position:0%
the common ones throughout this
presentation<00:13:28.260><c> you'll</c><00:13:28.620><c> also</c><00:13:28.860><c> see</c><00:13:29.220><c> tensorflow</c>

00:13:29.720 --> 00:13:29.730 align:start position:0%
presentation you'll also see tensorflow
 

00:13:29.730 --> 00:13:31.850 align:start position:0%
presentation you'll also see tensorflow
code<00:13:30.210><c> snippets</c><00:13:30.720><c> like</c><00:13:30.900><c> the</c><00:13:31.350><c> ones</c><00:13:31.529><c> you</c><00:13:31.620><c> see</c><00:13:31.770><c> on</c>

00:13:31.850 --> 00:13:31.860 align:start position:0%
code snippets like the ones you see on
 

00:13:31.860 --> 00:13:32.990 align:start position:0%
code snippets like the ones you see on
the<00:13:31.950><c> bottom</c><00:13:32.070><c> here</c><00:13:32.430><c> since</c><00:13:32.670><c> we'll</c><00:13:32.790><c> be</c><00:13:32.820><c> using</c>

00:13:32.990 --> 00:13:33.000 align:start position:0%
the bottom here since we'll be using
 

00:13:33.000 --> 00:13:35.780 align:start position:0%
the bottom here since we'll be using
tensorflow<00:13:33.480><c> for</c><00:13:33.810><c> our</c><00:13:33.960><c> labs</c><00:13:34.170><c> and</c><00:13:34.980><c> well</c><00:13:35.520><c> this</c><00:13:35.640><c> is</c>

00:13:35.780 --> 00:13:35.790 align:start position:0%
tensorflow for our labs and well this is
 

00:13:35.790 --> 00:13:37.730 align:start position:0%
tensorflow for our labs and well this is
some<00:13:35.940><c> way</c><00:13:36.089><c> that</c><00:13:36.120><c> I</c><00:13:36.450><c> can</c><00:13:36.750><c> provide</c><00:13:36.900><c> to</c><00:13:37.380><c> you</c><00:13:37.500><c> to</c>

00:13:37.730 --> 00:13:37.740 align:start position:0%
some way that I can provide to you to
 

00:13:37.740 --> 00:13:39.170 align:start position:0%
some way that I can provide to you to
kind<00:13:38.040><c> of</c><00:13:38.100><c> link</c><00:13:38.370><c> the</c><00:13:38.670><c> material</c><00:13:39.060><c> in</c><00:13:39.150><c> our</c>

00:13:39.170 --> 00:13:39.180 align:start position:0%
kind of link the material in our
 

00:13:39.180 --> 00:13:40.400 align:start position:0%
kind of link the material in our
lectures<00:13:39.630><c> with</c><00:13:39.960><c> what</c><00:13:40.110><c> you'll</c><00:13:40.290><c> be</c>

00:13:40.400 --> 00:13:40.410 align:start position:0%
lectures with what you'll be
 

00:13:40.410 --> 00:13:43.820 align:start position:0%
lectures with what you'll be
implementing<00:13:40.860><c> in</c><00:13:41.070><c> labs</c><00:13:42.350><c> so</c><00:13:43.350><c> the</c><00:13:43.470><c> sigmoid</c>

00:13:43.820 --> 00:13:43.830 align:start position:0%
implementing in labs so the sigmoid
 

00:13:43.830 --> 00:13:45.290 align:start position:0%
implementing in labs so the sigmoid
activation<00:13:43.950><c> function</c><00:13:44.370><c> which</c><00:13:44.790><c> I</c><00:13:44.910><c> talked</c><00:13:45.120><c> about</c>

00:13:45.290 --> 00:13:45.300 align:start position:0%
activation function which I talked about
 

00:13:45.300 --> 00:13:48.880 align:start position:0%
activation function which I talked about
in<00:13:45.360><c> the</c><00:13:45.420><c> previous</c><00:13:45.600><c> slide</c><00:13:45.839><c> now</c><00:13:46.500><c> on</c><00:13:46.680><c> the</c><00:13:46.800><c> left</c><00:13:47.010><c> is</c>

00:13:48.880 --> 00:13:48.890 align:start position:0%
in the previous slide now on the left is
 

00:13:48.890 --> 00:13:51.050 align:start position:0%
in the previous slide now on the left is
it's<00:13:49.890><c> just</c><00:13:49.950><c> a</c><00:13:50.130><c> function</c><00:13:50.490><c> like</c><00:13:50.580><c> I</c><00:13:50.700><c> said</c><00:13:50.910><c> it's</c>

00:13:51.050 --> 00:13:51.060 align:start position:0%
it's just a function like I said it's
 

00:13:51.060 --> 00:13:53.690 align:start position:0%
it's just a function like I said it's
commonly<00:13:51.390><c> used</c><00:13:51.450><c> to</c><00:13:52.290><c> produce</c><00:13:52.980><c> probability</c>

00:13:53.690 --> 00:13:53.700 align:start position:0%
commonly used to produce probability
 

00:13:53.700 --> 00:13:55.610 align:start position:0%
commonly used to produce probability
outputs<00:13:54.089><c> each</c><00:13:54.750><c> of</c><00:13:54.960><c> these</c><00:13:55.080><c> activation</c>

00:13:55.610 --> 00:13:55.620 align:start position:0%
outputs each of these activation
 

00:13:55.620 --> 00:13:57.230 align:start position:0%
outputs each of these activation
functions<00:13:56.010><c> has</c><00:13:56.190><c> their</c><00:13:56.430><c> own</c><00:13:56.520><c> advantages</c><00:13:57.180><c> and</c>

00:13:57.230 --> 00:13:57.240 align:start position:0%
functions has their own advantages and
 

00:13:57.240 --> 00:14:00.050 align:start position:0%
functions has their own advantages and
disadvantages<00:13:57.390><c> on</c><00:13:58.380><c> the</c><00:13:58.980><c> right</c><00:13:59.190><c> a</c><00:13:59.400><c> very</c><00:13:59.580><c> common</c>

00:14:00.050 --> 00:14:00.060 align:start position:0%
disadvantages on the right a very common
 

00:14:00.060 --> 00:14:01.670 align:start position:0%
disadvantages on the right a very common
activation<00:14:00.570><c> function</c><00:14:00.839><c> is</c><00:14:00.930><c> the</c><00:14:01.080><c> rectified</c>

00:14:01.670 --> 00:14:01.680 align:start position:0%
activation function is the rectified
 

00:14:01.680 --> 00:14:04.880 align:start position:0%
activation function is the rectified
linear<00:14:01.890><c> unit</c><00:14:02.370><c> or</c><00:14:02.520><c> Lu</c><00:14:03.110><c> this</c><00:14:04.110><c> function</c><00:14:04.710><c> is</c><00:14:04.830><c> very</c>

00:14:04.880 --> 00:14:04.890 align:start position:0%
linear unit or Lu this function is very
 

00:14:04.890 --> 00:14:07.100 align:start position:0%
linear unit or Lu this function is very
popular<00:14:05.550><c> because</c><00:14:05.730><c> it's</c><00:14:06.120><c> extremely</c><00:14:06.630><c> simple</c><00:14:07.080><c> to</c>

00:14:07.100 --> 00:14:07.110 align:start position:0%
popular because it's extremely simple to
 

00:14:07.110 --> 00:14:09.260 align:start position:0%
popular because it's extremely simple to
compute<00:14:07.500><c> it's</c><00:14:07.980><c> piecewise</c><00:14:08.490><c> linear</c><00:14:08.730><c> it's</c><00:14:09.029><c> zero</c>

00:14:09.260 --> 00:14:09.270 align:start position:0%
compute it's piecewise linear it's zero
 

00:14:09.270 --> 00:14:12.530 align:start position:0%
compute it's piecewise linear it's zero
before<00:14:09.630><c> with</c><00:14:10.470><c> inputs</c><00:14:10.860><c> less</c><00:14:11.250><c> than</c><00:14:11.400><c> zero</c><00:14:11.640><c> it's</c><00:14:12.210><c> X</c>

00:14:12.530 --> 00:14:12.540 align:start position:0%
before with inputs less than zero it's X
 

00:14:12.540 --> 00:14:16.640 align:start position:0%
before with inputs less than zero it's X
with<00:14:12.930><c> any</c><00:14:13.110><c> input</c><00:14:13.529><c> greater</c><00:14:14.279><c> than</c><00:14:14.520><c> zero</c><00:14:15.270><c> and</c><00:14:15.650><c> the</c>

00:14:16.640 --> 00:14:16.650 align:start position:0%
with any input greater than zero and the
 

00:14:16.650 --> 00:14:18.200 align:start position:0%
with any input greater than zero and the
gradients<00:14:17.040><c> are</c><00:14:17.130><c> just</c><00:14:17.310><c> zero</c><00:14:17.520><c> or</c><00:14:17.760><c> one</c><00:14:18.000><c> with</c><00:14:18.180><c> a</c>

00:14:18.200 --> 00:14:18.210 align:start position:0%
gradients are just zero or one with a
 

00:14:18.210 --> 00:14:21.500 align:start position:0%
gradients are just zero or one with a
single<00:14:18.420><c> non-linearity</c><00:14:19.230><c> at</c><00:14:19.470><c> the</c><00:14:19.589><c> origin</c><00:14:20.510><c> and</c>

00:14:21.500 --> 00:14:21.510 align:start position:0%
single non-linearity at the origin and
 

00:14:21.510 --> 00:14:24.500 align:start position:0%
single non-linearity at the origin and
you<00:14:21.570><c> might</c><00:14:22.560><c> be</c><00:14:22.680><c> wondering</c><00:14:23.040><c> why</c><00:14:23.279><c> we</c><00:14:24.060><c> even</c><00:14:24.210><c> need</c>

00:14:24.500 --> 00:14:24.510 align:start position:0%
you might be wondering why we even need
 

00:14:24.510 --> 00:14:26.450 align:start position:0%
you might be wondering why we even need
activation<00:14:25.320><c> functions</c><00:14:25.770><c> why</c><00:14:25.980><c> can't</c><00:14:26.250><c> we</c><00:14:26.339><c> just</c>

00:14:26.450 --> 00:14:26.460 align:start position:0%
activation functions why can't we just
 

00:14:26.460 --> 00:14:28.310 align:start position:0%
activation functions why can't we just
take<00:14:26.670><c> our</c><00:14:26.790><c> dot</c><00:14:27.000><c> product</c><00:14:27.270><c> at</c><00:14:27.570><c> our</c><00:14:27.720><c> bias</c><00:14:27.960><c> and</c>

00:14:28.310 --> 00:14:28.320 align:start position:0%
take our dot product at our bias and
 

00:14:28.320 --> 00:14:30.170 align:start position:0%
take our dot product at our bias and
that's<00:14:28.709><c> our</c><00:14:28.890><c> output</c><00:14:29.010><c> why</c><00:14:29.760><c> do</c><00:14:29.820><c> we</c><00:14:29.940><c> need</c><00:14:30.060><c> the</c>

00:14:30.170 --> 00:14:30.180 align:start position:0%
that's our output why do we need the
 

00:14:30.180 --> 00:14:32.720 align:start position:0%
that's our output why do we need the
activation<00:14:30.630><c> function</c><00:14:31.310><c> activation</c><00:14:32.310><c> functions</c>

00:14:32.720 --> 00:14:32.730 align:start position:0%
activation function activation functions
 

00:14:32.730 --> 00:14:35.060 align:start position:0%
activation function activation functions
introduce<00:14:33.440><c> nonlinearities</c><00:14:34.440><c> into</c><00:14:34.980><c> the</c>

00:14:35.060 --> 00:14:35.070 align:start position:0%
introduce nonlinearities into the
 

00:14:35.070 --> 00:14:36.640 align:start position:0%
introduce nonlinearities into the
network<00:14:35.339><c> that's</c><00:14:35.580><c> the</c><00:14:35.700><c> whole</c><00:14:35.820><c> point</c><00:14:36.029><c> of</c><00:14:36.240><c> why</c>

00:14:36.640 --> 00:14:36.650 align:start position:0%
network that's the whole point of why
 

00:14:36.650 --> 00:14:41.240 align:start position:0%
network that's the whole point of why
activations<00:14:37.650><c> themselves</c><00:14:38.190><c> are</c><00:14:38.510><c> nonlinear</c><00:14:40.250><c> we</c>

00:14:41.240 --> 00:14:41.250 align:start position:0%
activations themselves are nonlinear we
 

00:14:41.250 --> 00:14:44.060 align:start position:0%
activations themselves are nonlinear we
want<00:14:41.459><c> to</c><00:14:41.610><c> model</c><00:14:42.230><c> nonlinear</c><00:14:43.230><c> data</c><00:14:43.560><c> in</c><00:14:43.890><c> the</c>

00:14:44.060 --> 00:14:44.070 align:start position:0%
want to model nonlinear data in the
 

00:14:44.070 --> 00:14:45.710 align:start position:0%
want to model nonlinear data in the
world<00:14:44.250><c> because</c><00:14:44.580><c> the</c><00:14:44.700><c> world</c><00:14:44.940><c> is</c><00:14:45.180><c> extremely</c>

00:14:45.710 --> 00:14:45.720 align:start position:0%
world because the world is extremely
 

00:14:45.720 --> 00:14:48.980 align:start position:0%
world because the world is extremely
nonlinear<00:14:47.150><c> but</c><00:14:48.150><c> suppose</c><00:14:48.390><c> I</c><00:14:48.510><c> gave</c><00:14:48.570><c> you</c><00:14:48.810><c> this</c>

00:14:48.980 --> 00:14:48.990 align:start position:0%
nonlinear but suppose I gave you this
 

00:14:48.990 --> 00:14:51.440 align:start position:0%
nonlinear but suppose I gave you this
this<00:14:49.800><c> plot</c><00:14:50.130><c> green</c><00:14:50.670><c> and</c><00:14:50.850><c> red</c><00:14:50.970><c> points</c><00:14:51.270><c> and</c><00:14:51.390><c> I</c>

00:14:51.440 --> 00:14:51.450 align:start position:0%
this plot green and red points and I
 

00:14:51.450 --> 00:14:54.350 align:start position:0%
this plot green and red points and I
asked<00:14:51.779><c> you</c><00:14:51.810><c> to</c><00:14:52.110><c> draw</c><00:14:52.380><c> a</c><00:14:52.620><c> single</c><00:14:53.279><c> line</c><00:14:53.490><c> not</c><00:14:54.330><c> a</c>

00:14:54.350 --> 00:14:54.360 align:start position:0%
asked you to draw a single line not a
 

00:14:54.360 --> 00:14:56.630 align:start position:0%
asked you to draw a single line not a
curve<00:14:54.660><c> just</c><00:14:54.930><c> a</c><00:14:55.080><c> line</c><00:14:55.320><c> between</c><00:14:55.800><c> the</c><00:14:56.400><c> green</c><00:14:56.610><c> and</c>

00:14:56.630 --> 00:14:56.640 align:start position:0%
curve just a line between the green and
 

00:14:56.640 --> 00:14:58.130 align:start position:0%
curve just a line between the green and
red<00:14:56.790><c> points</c><00:14:57.150><c> to</c><00:14:57.209><c> separate</c><00:14:57.600><c> them</c><00:14:57.779><c> perfectly</c>

00:14:58.130 --> 00:14:58.140 align:start position:0%
red points to separate them perfectly
 

00:14:58.140 --> 00:15:00.199 align:start position:0%
red points to separate them perfectly
you'd<00:14:58.980><c> find</c><00:14:59.220><c> this</c><00:14:59.339><c> really</c><00:14:59.550><c> difficult</c><00:14:59.760><c> and</c>

00:15:00.199 --> 00:15:00.209 align:start position:0%
you'd find this really difficult and
 

00:15:00.209 --> 00:15:02.090 align:start position:0%
you'd find this really difficult and
probably<00:15:00.420><c> you</c><00:15:00.720><c> could</c><00:15:00.870><c> get</c><00:15:01.380><c> as</c><00:15:01.560><c> best</c><00:15:01.890><c> as</c>

00:15:02.090 --> 00:15:02.100 align:start position:0%
probably you could get as best as
 

00:15:02.100 --> 00:15:04.010 align:start position:0%
probably you could get as best as
something<00:15:02.400><c> like</c><00:15:02.490><c> this</c><00:15:02.779><c> now</c><00:15:03.779><c> if</c><00:15:03.900><c> your</c>

00:15:04.010 --> 00:15:04.020 align:start position:0%
something like this now if your
 

00:15:04.020 --> 00:15:05.570 align:start position:0%
something like this now if your
activation<00:15:04.620><c> function</c><00:15:04.980><c> in</c><00:15:05.100><c> your</c><00:15:05.190><c> deep</c><00:15:05.400><c> neural</c>

00:15:05.570 --> 00:15:05.580 align:start position:0%
activation function in your deep neural
 

00:15:05.580 --> 00:15:08.390 align:start position:0%
activation function in your deep neural
network<00:15:06.029><c> was</c><00:15:06.750><c> linear</c><00:15:07.250><c> since</c><00:15:08.250><c> you're</c><00:15:08.370><c> just</c>

00:15:08.390 --> 00:15:08.400 align:start position:0%
network was linear since you're just
 

00:15:08.400 --> 00:15:10.160 align:start position:0%
network was linear since you're just
composing<00:15:09.089><c> linear</c><00:15:09.360><c> functions</c><00:15:09.720><c> with</c><00:15:09.870><c> linear</c>

00:15:10.160 --> 00:15:10.170 align:start position:0%
composing linear functions with linear
 

00:15:10.170 --> 00:15:11.840 align:start position:0%
composing linear functions with linear
functions<00:15:10.589><c> your</c><00:15:10.860><c> output</c><00:15:11.220><c> will</c><00:15:11.339><c> always</c><00:15:11.670><c> be</c>

00:15:11.840 --> 00:15:11.850 align:start position:0%
functions your output will always be
 

00:15:11.850 --> 00:15:13.850 align:start position:0%
functions your output will always be
linear<00:15:12.240><c> so</c><00:15:12.390><c> the</c><00:15:12.720><c> most</c><00:15:12.930><c> complicated</c><00:15:13.350><c> deep</c>

00:15:13.850 --> 00:15:13.860 align:start position:0%
linear so the most complicated deep
 

00:15:13.860 --> 00:15:15.350 align:start position:0%
linear so the most complicated deep
neural<00:15:14.010><c> network</c><00:15:14.339><c> no</c><00:15:14.459><c> matter</c><00:15:14.640><c> how</c><00:15:14.820><c> big</c><00:15:15.060><c> or</c><00:15:15.209><c> how</c>

00:15:15.350 --> 00:15:15.360 align:start position:0%
neural network no matter how big or how
 

00:15:15.360 --> 00:15:17.300 align:start position:0%
neural network no matter how big or how
deep<00:15:15.630><c> if</c><00:15:15.870><c> the</c><00:15:16.470><c> activation</c><00:15:16.800><c> function</c><00:15:16.980><c> is</c>

00:15:17.300 --> 00:15:17.310 align:start position:0%
deep if the activation function is
 

00:15:17.310 --> 00:15:19.760 align:start position:0%
deep if the activation function is
linear<00:15:17.490><c> your</c><00:15:18.390><c> output</c><00:15:18.779><c> can</c><00:15:19.170><c> only</c><00:15:19.350><c> look</c><00:15:19.620><c> like</c>

00:15:19.760 --> 00:15:19.770 align:start position:0%
linear your output can only look like
 

00:15:19.770 --> 00:15:21.410 align:start position:0%
linear your output can only look like
this<00:15:20.010><c> but</c><00:15:20.910><c> once</c><00:15:21.120><c> we</c><00:15:21.240><c> introduce</c>

00:15:21.410 --> 00:15:21.420 align:start position:0%
this but once we introduce
 

00:15:21.420 --> 00:15:24.890 align:start position:0%
this but once we introduce
nonlinearities<00:15:22.410><c> our</c><00:15:23.029><c> network</c><00:15:24.029><c> is</c><00:15:24.180><c> extremely</c>

00:15:24.890 --> 00:15:24.900 align:start position:0%
nonlinearities our network is extremely
 

00:15:24.900 --> 00:15:27.440 align:start position:0%
nonlinearities our network is extremely
more<00:15:25.140><c> as</c><00:15:25.740><c> the</c><00:15:26.190><c> capacity</c><00:15:26.790><c> of</c><00:15:26.820><c> our</c><00:15:26.940><c> network</c><00:15:27.240><c> has</c>

00:15:27.440 --> 00:15:27.450 align:start position:0%
more as the capacity of our network has
 

00:15:27.450 --> 00:15:29.750 align:start position:0%
more as the capacity of our network has
extremely<00:15:27.990><c> increased</c><00:15:28.589><c> we're</c><00:15:29.070><c> now</c><00:15:29.190><c> able</c><00:15:29.459><c> to</c>

00:15:29.750 --> 00:15:29.760 align:start position:0%
extremely increased we're now able to
 

00:15:29.760 --> 00:15:32.390 align:start position:0%
extremely increased we're now able to
model<00:15:30.089><c> much</c><00:15:30.720><c> more</c><00:15:30.930><c> complex</c><00:15:31.350><c> functions</c><00:15:31.529><c> we're</c>

00:15:32.390 --> 00:15:32.400 align:start position:0%
model much more complex functions we're
 

00:15:32.400 --> 00:15:33.829 align:start position:0%
model much more complex functions we're
able<00:15:32.490><c> to</c><00:15:32.730><c> draw</c><00:15:32.880><c> decision</c><00:15:33.450><c> boundaries</c><00:15:33.750><c> that</c>

00:15:33.829 --> 00:15:33.839 align:start position:0%
able to draw decision boundaries that
 

00:15:33.839 --> 00:15:36.110 align:start position:0%
able to draw decision boundaries that
were<00:15:34.079><c> not</c><00:15:34.320><c> possible</c><00:15:34.560><c> with</c><00:15:35.400><c> only</c><00:15:35.820><c> linear</c>

00:15:36.110 --> 00:15:36.120 align:start position:0%
were not possible with only linear
 

00:15:36.120 --> 00:15:36.680 align:start position:0%
were not possible with only linear
activation

00:15:36.680 --> 00:15:36.690 align:start position:0%
activation
 

00:15:36.690 --> 00:15:39.680 align:start position:0%
activation
options<00:15:38.060><c> let's</c><00:15:39.060><c> understand</c><00:15:39.450><c> this</c><00:15:39.540><c> with</c><00:15:39.660><c> a</c>

00:15:39.680 --> 00:15:39.690 align:start position:0%
options let's understand this with a
 

00:15:39.690 --> 00:15:41.990 align:start position:0%
options let's understand this with a
very<00:15:39.840><c> simple</c><00:15:40.140><c> example</c><00:15:40.460><c> imagine</c><00:15:41.460><c> I</c><00:15:41.700><c> gave</c><00:15:41.850><c> you</c><00:15:41.970><c> a</c>

00:15:41.990 --> 00:15:42.000 align:start position:0%
very simple example imagine I gave you a
 

00:15:42.000 --> 00:15:43.700 align:start position:0%
very simple example imagine I gave you a
train<00:15:42.300><c> to</c><00:15:42.480><c> network</c><00:15:42.810><c> like</c><00:15:43.140><c> the</c><00:15:43.260><c> one</c><00:15:43.410><c> we</c><00:15:43.560><c> saw</c>

00:15:43.700 --> 00:15:43.710 align:start position:0%
train to network like the one we saw
 

00:15:43.710 --> 00:15:45.740 align:start position:0%
train to network like the one we saw
before<00:15:43.740><c> sorry</c><00:15:44.400><c> a</c><00:15:44.430><c> trained</c><00:15:44.760><c> perceptron</c><00:15:45.360><c> not</c><00:15:45.600><c> in</c>

00:15:45.740 --> 00:15:45.750 align:start position:0%
before sorry a trained perceptron not in
 

00:15:45.750 --> 00:15:49.370 align:start position:0%
before sorry a trained perceptron not in
network<00:15:46.050><c> yet</c><00:15:46.230><c> just</c><00:15:46.590><c> a</c><00:15:46.740><c> single</c><00:15:47.040><c> node</c><00:15:47.250><c> and</c><00:15:48.380><c> the</c>

00:15:49.370 --> 00:15:49.380 align:start position:0%
network yet just a single node and the
 

00:15:49.380 --> 00:15:51.110 align:start position:0%
network yet just a single node and the
weights<00:15:49.560><c> are</c><00:15:49.710><c> on</c><00:15:49.770><c> the</c><00:15:49.890><c> top</c><00:15:50.070><c> right</c><00:15:50.340><c> so</c><00:15:50.580><c> theta</c><00:15:50.820><c> 0</c>

00:15:51.110 --> 00:15:51.120 align:start position:0%
weights are on the top right so theta 0
 

00:15:51.120 --> 00:15:54.200 align:start position:0%
weights are on the top right so theta 0
is<00:15:51.300><c> 1</c><00:15:51.630><c> and</c><00:15:51.810><c> the</c><00:15:52.770><c> theta</c><00:15:52.980><c> vector</c><00:15:53.280><c> is</c><00:15:53.610><c> 3</c><00:15:53.970><c> and</c>

00:15:54.200 --> 00:15:54.210 align:start position:0%
is 1 and the theta vector is 3 and
 

00:15:54.210 --> 00:15:58.070 align:start position:0%
is 1 and the theta vector is 3 and
negative<00:15:54.360><c> 2</c><00:15:55.400><c> the</c><00:15:56.400><c> network</c><00:15:56.730><c> has</c><00:15:56.940><c> two</c><00:15:57.450><c> inputs</c><00:15:57.870><c> X</c>

00:15:58.070 --> 00:15:58.080 align:start position:0%
negative 2 the network has two inputs X
 

00:15:58.080 --> 00:16:00.140 align:start position:0%
negative 2 the network has two inputs X
1<00:15:58.380><c> and</c><00:15:58.620><c> X</c><00:15:58.740><c> 2</c><00:15:58.890><c> and</c><00:15:59.250><c> if</c><00:15:59.580><c> we</c><00:15:59.670><c> want</c><00:15:59.850><c> to</c><00:15:59.940><c> get</c><00:16:00.060><c> the</c>

00:16:00.140 --> 00:16:00.150 align:start position:0%
1 and X 2 and if we want to get the
 

00:16:00.150 --> 00:16:02.420 align:start position:0%
1 and X 2 and if we want to get the
output<00:16:00.630><c> all</c><00:16:00.990><c> we</c><00:16:01.500><c> have</c><00:16:01.620><c> to</c><00:16:01.740><c> do</c><00:16:01.890><c> is</c><00:16:02.040><c> apply</c><00:16:02.310><c> the</c>

00:16:02.420 --> 00:16:02.430 align:start position:0%
output all we have to do is apply the
 

00:16:02.430 --> 00:16:04.970 align:start position:0%
output all we have to do is apply the
same<00:16:02.730><c> story</c><00:16:03.060><c> as</c><00:16:03.150><c> before</c><00:16:03.540><c> so</c><00:16:04.290><c> we</c><00:16:04.410><c> apply</c><00:16:04.620><c> the</c><00:16:04.650><c> dot</c>

00:16:04.970 --> 00:16:04.980 align:start position:0%
same story as before so we apply the dot
 

00:16:04.980 --> 00:16:07.610 align:start position:0%
same story as before so we apply the dot
product<00:16:05.400><c> of</c><00:16:05.550><c> X</c><00:16:05.760><c> and</c><00:16:06.060><c> theta</c><00:16:06.270><c> we</c><00:16:07.080><c> add</c><00:16:07.230><c> the</c><00:16:07.410><c> bias</c>

00:16:07.610 --> 00:16:07.620 align:start position:0%
product of X and theta we add the bias
 

00:16:07.620 --> 00:16:10.760 align:start position:0%
product of X and theta we add the bias
and<00:16:08.040><c> apply</c><00:16:08.820><c> our</c><00:16:08.880><c> non-linearity</c><00:16:09.660><c> but</c><00:16:10.620><c> let's</c>

00:16:10.760 --> 00:16:10.770 align:start position:0%
and apply our non-linearity but let's
 

00:16:10.770 --> 00:16:11.720 align:start position:0%
and apply our non-linearity but let's
take<00:16:10.920><c> a</c><00:16:10.950><c> look</c><00:16:11.130><c> at</c><00:16:11.220><c> what's</c><00:16:11.370><c> actually</c><00:16:11.490><c> inside</c>

00:16:11.720 --> 00:16:11.730 align:start position:0%
take a look at what's actually inside
 

00:16:11.730 --> 00:16:14.720 align:start position:0%
take a look at what's actually inside
before<00:16:12.300><c> we</c><00:16:12.600><c> apply</c><00:16:12.810><c> that</c><00:16:12.870><c> non-linearity</c><00:16:13.770><c> this</c>

00:16:14.720 --> 00:16:14.730 align:start position:0%
before we apply that non-linearity this
 

00:16:14.730 --> 00:16:16.910 align:start position:0%
before we apply that non-linearity this
looks<00:16:15.150><c> a</c><00:16:15.270><c> lot</c><00:16:15.480><c> like</c><00:16:15.660><c> just</c><00:16:15.960><c> a</c><00:16:16.050><c> 2d</c><00:16:16.380><c> line</c><00:16:16.590><c> because</c>

00:16:16.910 --> 00:16:16.920 align:start position:0%
looks a lot like just a 2d line because
 

00:16:16.920 --> 00:16:20.780 align:start position:0%
looks a lot like just a 2d line because
we<00:16:17.040><c> have</c><00:16:17.130><c> two</c><00:16:17.490><c> inputs</c><00:16:17.700><c> and</c><00:16:18.680><c> it</c><00:16:19.680><c> is</c><00:16:19.830><c> we</c><00:16:20.640><c> can</c>

00:16:20.780 --> 00:16:20.790 align:start position:0%
we have two inputs and it is we can
 

00:16:20.790 --> 00:16:22.340 align:start position:0%
we have two inputs and it is we can
actually<00:16:20.910><c> plot</c><00:16:21.270><c> this</c><00:16:21.480><c> line</c><00:16:21.540><c> when</c><00:16:21.930><c> it</c><00:16:22.050><c> equals</c>

00:16:22.340 --> 00:16:22.350 align:start position:0%
actually plot this line when it equals
 

00:16:22.350 --> 00:16:24.800 align:start position:0%
actually plot this line when it equals
zero<00:16:22.620><c> in</c><00:16:22.890><c> feature</c><00:16:23.520><c> space</c><00:16:23.970><c> so</c><00:16:24.210><c> this</c><00:16:24.360><c> is</c><00:16:24.540><c> space</c>

00:16:24.800 --> 00:16:24.810 align:start position:0%
zero in feature space so this is space
 

00:16:24.810 --> 00:16:27.140 align:start position:0%
zero in feature space so this is space
where<00:16:25.530><c> I'm</c><00:16:25.620><c> plotting</c><00:16:25.800><c> x1</c><00:16:26.430><c> one</c><00:16:26.910><c> of</c><00:16:27.030><c> our</c>

00:16:27.140 --> 00:16:27.150 align:start position:0%
where I'm plotting x1 one of our
 

00:16:27.150 --> 00:16:31.640 align:start position:0%
where I'm plotting x1 one of our
features<00:16:27.870><c> on</c><00:16:28.170><c> the</c><00:16:28.620><c> x-axis</c><00:16:28.950><c> and</c><00:16:29.420><c> x2</c><00:16:30.500><c> the</c><00:16:31.500><c> other</c>

00:16:31.640 --> 00:16:31.650 align:start position:0%
features on the x-axis and x2 the other
 

00:16:31.650 --> 00:16:34.010 align:start position:0%
features on the x-axis and x2 the other
feature<00:16:31.890><c> on</c><00:16:32.190><c> the</c><00:16:32.370><c> y-axis</c><00:16:32.580><c> we</c><00:16:33.150><c> plot</c><00:16:33.420><c> that</c><00:16:33.780><c> line</c>

00:16:34.010 --> 00:16:34.020 align:start position:0%
feature on the y-axis we plot that line
 

00:16:34.020 --> 00:16:35.420 align:start position:0%
feature on the y-axis we plot that line
it's<00:16:34.320><c> just</c><00:16:34.410><c> the</c><00:16:34.620><c> decision</c><00:16:35.070><c> boundary</c>

00:16:35.420 --> 00:16:35.430 align:start position:0%
it's just the decision boundary
 

00:16:35.430 --> 00:16:37.940 align:start position:0%
it's just the decision boundary
separating<00:16:35.970><c> our</c><00:16:36.570><c> entire</c><00:16:37.230><c> space</c><00:16:37.470><c> into</c><00:16:37.770><c> two</c>

00:16:37.940 --> 00:16:37.950 align:start position:0%
separating our entire space into two
 

00:16:37.950 --> 00:16:41.240 align:start position:0%
separating our entire space into two
subspaces<00:16:39.320><c> now</c><00:16:40.320><c> if</c><00:16:40.410><c> I</c><00:16:40.500><c> give</c><00:16:40.650><c> you</c><00:16:40.740><c> a</c><00:16:40.770><c> new</c><00:16:40.920><c> point</c>

00:16:41.240 --> 00:16:41.250 align:start position:0%
subspaces now if I give you a new point
 

00:16:41.250 --> 00:16:44.690 align:start position:0%
subspaces now if I give you a new point
negative<00:16:42.150><c> 1/2</c><00:16:42.780><c> and</c><00:16:42.990><c> plot</c><00:16:43.920><c> it</c><00:16:44.070><c> on</c><00:16:44.160><c> the</c><00:16:44.310><c> sub</c><00:16:44.520><c> in</c>

00:16:44.690 --> 00:16:44.700 align:start position:0%
negative 1/2 and plot it on the sub in
 

00:16:44.700 --> 00:16:46.700 align:start position:0%
negative 1/2 and plot it on the sub in
this<00:16:44.940><c> feature</c><00:16:45.120><c> space</c><00:16:45.530><c> depending</c><00:16:46.530><c> on</c><00:16:46.590><c> which</c>

00:16:46.700 --> 00:16:46.710 align:start position:0%
this feature space depending on which
 

00:16:46.710 --> 00:16:48.620 align:start position:0%
this feature space depending on which
side<00:16:46.980><c> of</c><00:16:47.010><c> the</c><00:16:47.220><c> line</c><00:16:47.340><c> it</c><00:16:47.520><c> falls</c><00:16:47.760><c> on</c><00:16:47.970><c> I</c><00:16:48.210><c> can</c>

00:16:48.620 --> 00:16:48.630 align:start position:0%
side of the line it falls on I can
 

00:16:48.630 --> 00:16:50.000 align:start position:0%
side of the line it falls on I can
automatically<00:16:49.170><c> determine</c><00:16:49.650><c> whether</c><00:16:49.830><c> our</c>

00:16:50.000 --> 00:16:50.010 align:start position:0%
automatically determine whether our
 

00:16:50.010 --> 00:16:52.760 align:start position:0%
automatically determine whether our
output<00:16:50.430><c> is</c><00:16:50.550><c> less</c><00:16:50.820><c> than</c><00:16:51.000><c> 0</c><00:16:51.240><c> or</c><00:16:51.510><c> greater</c><00:16:51.870><c> than</c><00:16:52.260><c> 0</c>

00:16:52.760 --> 00:16:52.770 align:start position:0%
output is less than 0 or greater than 0
 

00:16:52.770 --> 00:16:54.530 align:start position:0%
output is less than 0 or greater than 0
since<00:16:53.100><c> our</c><00:16:53.220><c> line</c><00:16:53.490><c> represents</c><00:16:54.090><c> a</c><00:16:54.150><c> decision</c>

00:16:54.530 --> 00:16:54.540 align:start position:0%
since our line represents a decision
 

00:16:54.540 --> 00:16:58.070 align:start position:0%
since our line represents a decision
boundary<00:16:54.840><c> equal</c><00:16:55.230><c> to</c><00:16:55.380><c> 0</c><00:16:55.590><c> now</c><00:16:56.810><c> we</c><00:16:57.810><c> can</c><00:16:57.960><c> follow</c>

00:16:58.070 --> 00:16:58.080 align:start position:0%
boundary equal to 0 now we can follow
 

00:16:58.080 --> 00:16:59.740 align:start position:0%
boundary equal to 0 now we can follow
the<00:16:58.320><c> math</c><00:16:58.500><c> on</c><00:16:58.710><c> the</c><00:16:58.800><c> bottom</c><00:16:59.100><c> and</c><00:16:59.280><c> see</c><00:16:59.460><c> that</c>

00:16:59.740 --> 00:16:59.750 align:start position:0%
the math on the bottom and see that
 

00:16:59.750 --> 00:17:01.910 align:start position:0%
the math on the bottom and see that
computing<00:17:00.750><c> the</c><00:17:00.900><c> inside</c><00:17:01.200><c> of</c><00:17:01.320><c> this</c><00:17:01.500><c> activation</c>

00:17:01.910 --> 00:17:01.920 align:start position:0%
computing the inside of this activation
 

00:17:01.920 --> 00:17:06.079 align:start position:0%
computing the inside of this activation
function<00:17:02.460><c> we</c><00:17:02.910><c> get</c><00:17:03.030><c> 1</c><00:17:03.360><c> minus</c><00:17:04.020><c> 3</c><00:17:04.350><c> minus</c><00:17:04.860><c> 2</c><00:17:05.370><c> sorry</c>

00:17:06.079 --> 00:17:06.089 align:start position:0%
function we get 1 minus 3 minus 2 sorry
 

00:17:06.089 --> 00:17:12.490 align:start position:0%
function we get 1 minus 3 minus 2 sorry
minus<00:17:08.329><c> 4</c><00:17:09.329><c> and</c><00:17:09.829><c> we</c><00:17:10.829><c> get</c><00:17:10.920><c> minus</c><00:17:11.160><c> 6</c><00:17:11.550><c> at</c><00:17:11.819><c> the</c><00:17:11.850><c> output</c>

00:17:12.490 --> 00:17:12.500 align:start position:0%
minus 4 and we get minus 6 at the output
 

00:17:12.500 --> 00:17:14.600 align:start position:0%
minus 4 and we get minus 6 at the output
before<00:17:13.500><c> we</c><00:17:13.800><c> apply</c><00:17:13.980><c> the</c><00:17:14.040><c> activation</c><00:17:14.579><c> function</c>

00:17:14.600 --> 00:17:14.610 align:start position:0%
before we apply the activation function
 

00:17:14.610 --> 00:17:16.579 align:start position:0%
before we apply the activation function
once<00:17:15.089><c> we</c><00:17:15.209><c> apply</c><00:17:15.360><c> the</c><00:17:15.449><c> activation</c><00:17:15.990><c> function</c><00:17:16.020><c> we</c>

00:17:16.579 --> 00:17:16.589 align:start position:0%
once we apply the activation function we
 

00:17:16.589 --> 00:17:20.079 align:start position:0%
once we apply the activation function we
get<00:17:16.740><c> zero</c><00:17:17.550><c> point</c><00:17:17.790><c> zero</c><00:17:17.850><c> zero</c><00:17:18.060><c> two</c><00:17:18.410><c> so</c><00:17:19.410><c> negative</c>

00:17:20.079 --> 00:17:20.089 align:start position:0%
get zero point zero zero two so negative
 

00:17:20.089 --> 00:17:22.730 align:start position:0%
get zero point zero zero two so negative
what<00:17:21.089><c> was</c><00:17:21.240><c> applied</c><00:17:21.540><c> to</c><00:17:21.839><c> the</c><00:17:21.990><c> activation</c>

00:17:22.730 --> 00:17:22.740 align:start position:0%
what was applied to the activation
 

00:17:22.740 --> 00:17:24.770 align:start position:0%
what was applied to the activation
function<00:17:22.949><c> is</c><00:17:23.339><c> negative</c><00:17:23.760><c> because</c><00:17:23.970><c> we</c><00:17:24.240><c> fell</c><00:17:24.510><c> on</c>

00:17:24.770 --> 00:17:24.780 align:start position:0%
function is negative because we fell on
 

00:17:24.780 --> 00:17:29.990 align:start position:0%
function is negative because we fell on
the<00:17:25.410><c> negative</c><00:17:25.800><c> piece</c><00:17:26.339><c> of</c><00:17:26.610><c> this</c><00:17:26.880><c> subspace</c><00:17:29.000><c> well</c>

00:17:29.990 --> 00:17:30.000 align:start position:0%
the negative piece of this subspace well
 

00:17:30.000 --> 00:17:31.460 align:start position:0%
the negative piece of this subspace well
if<00:17:30.060><c> we</c><00:17:30.180><c> remember</c><00:17:30.570><c> with</c><00:17:30.690><c> the</c><00:17:30.780><c> sigmoid</c><00:17:31.110><c> function</c>

00:17:31.460 --> 00:17:31.470 align:start position:0%
if we remember with the sigmoid function
 

00:17:31.470 --> 00:17:33.080 align:start position:0%
if we remember with the sigmoid function
it<00:17:31.530><c> actually</c><00:17:31.770><c> divides</c><00:17:32.070><c> our</c><00:17:32.370><c> space</c><00:17:32.610><c> into</c><00:17:32.940><c> two</c>

00:17:33.080 --> 00:17:33.090 align:start position:0%
it actually divides our space into two
 

00:17:33.090 --> 00:17:35.960 align:start position:0%
it actually divides our space into two
parts<00:17:33.420><c> greater</c><00:17:33.900><c> than</c><00:17:34.350><c> 0.5</c><00:17:34.890><c> and</c><00:17:35.280><c> less</c><00:17:35.460><c> than</c><00:17:35.610><c> 0.5</c>

00:17:35.960 --> 00:17:35.970 align:start position:0%
parts greater than 0.5 and less than 0.5
 

00:17:35.970 --> 00:17:37.490 align:start position:0%
parts greater than 0.5 and less than 0.5
since<00:17:36.210><c> we're</c><00:17:36.330><c> modeling</c><00:17:36.570><c> probabilities</c><00:17:37.260><c> and</c>

00:17:37.490 --> 00:17:37.500 align:start position:0%
since we're modeling probabilities and
 

00:17:37.500 --> 00:17:40.670 align:start position:0%
since we're modeling probabilities and
everything<00:17:37.950><c> is</c><00:17:38.040><c> between</c><00:17:38.280><c> 0</c><00:17:38.550><c> &amp;</c><00:17:38.760><c> 1</c><00:17:39.350><c> so</c><00:17:40.350><c> actually</c>

00:17:40.670 --> 00:17:40.680 align:start position:0%
everything is between 0 &amp; 1 so actually
 

00:17:40.680 --> 00:17:43.160 align:start position:0%
everything is between 0 &amp; 1 so actually
our<00:17:40.770><c> decision</c><00:17:41.160><c> boundary</c><00:17:41.460><c> where</c><00:17:41.970><c> the</c><00:17:42.420><c> input</c><00:17:43.050><c> to</c>

00:17:43.160 --> 00:17:43.170 align:start position:0%
our decision boundary where the input to
 

00:17:43.170 --> 00:17:46.400 align:start position:0%
our decision boundary where the input to
our<00:17:43.290><c> network</c><00:17:43.620><c> equals</c><00:17:44.310><c> 0</c><00:17:44.660><c> sorry</c><00:17:45.660><c> the</c><00:17:45.780><c> side</c><00:17:46.230><c> the</c>

00:17:46.400 --> 00:17:46.410 align:start position:0%
our network equals 0 sorry the side the
 

00:17:46.410 --> 00:17:48.050 align:start position:0%
our network equals 0 sorry the side the
input<00:17:46.710><c> to</c><00:17:46.800><c> our</c><00:17:46.890><c> activation</c><00:17:47.250><c> function</c><00:17:47.760><c> equals</c>

00:17:48.050 --> 00:17:48.060 align:start position:0%
input to our activation function equals
 

00:17:48.060 --> 00:17:50.460 align:start position:0%
input to our activation function equals
0<00:17:48.860><c> corresponds</c><00:17:49.860><c> to</c>

00:17:50.460 --> 00:17:50.470 align:start position:0%
0 corresponds to
 

00:17:50.470 --> 00:17:52.560 align:start position:0%
0 corresponds to
the<00:17:50.559><c> output</c><00:17:51.010><c> of</c><00:17:51.159><c> our</c><00:17:51.370><c> activation</c><00:17:52.240><c> function</c>

00:17:52.560 --> 00:17:52.570 align:start position:0%
the output of our activation function
 

00:17:52.570 --> 00:17:57.210 align:start position:0%
the output of our activation function
being<00:17:52.809><c> greater</c><00:17:53.110><c> than</c><00:17:53.320><c> or</c><00:17:53.470><c> less</c><00:17:53.500><c> than</c><00:17:53.830><c> 0.5</c><00:17:56.220><c> so</c>

00:17:57.210 --> 00:17:57.220 align:start position:0%
being greater than or less than 0.5 so
 

00:17:57.220 --> 00:17:58.830 align:start position:0%
being greater than or less than 0.5 so
now<00:17:57.309><c> that</c><00:17:57.370><c> we</c><00:17:57.549><c> have</c><00:17:57.640><c> an</c><00:17:57.760><c> idea</c><00:17:58.030><c> of</c><00:17:58.090><c> what</c><00:17:58.659><c> a</c>

00:17:58.830 --> 00:17:58.840 align:start position:0%
now that we have an idea of what a
 

00:17:58.840 --> 00:18:01.620 align:start position:0%
now that we have an idea of what a
perceptron<00:17:59.530><c> is</c><00:17:59.830><c> let's</c><00:18:00.580><c> just</c><00:18:00.820><c> start</c><00:18:01.090><c> now</c><00:18:01.299><c> by</c>

00:18:01.620 --> 00:18:01.630 align:start position:0%
perceptron is let's just start now by
 

00:18:01.630 --> 00:18:04.169 align:start position:0%
perceptron is let's just start now by
understanding<00:18:02.409><c> how</c><00:18:02.559><c> we</c><00:18:02.620><c> can</c><00:18:02.850><c> compose</c><00:18:03.850><c> these</c>

00:18:04.169 --> 00:18:04.179 align:start position:0%
understanding how we can compose these
 

00:18:04.179 --> 00:18:06.930 align:start position:0%
understanding how we can compose these
perceptrons<00:18:04.809><c> together</c><00:18:05.370><c> to</c><00:18:06.370><c> actually</c><00:18:06.520><c> build</c>

00:18:06.930 --> 00:18:06.940 align:start position:0%
perceptrons together to actually build
 

00:18:06.940 --> 00:18:10.320 align:start position:0%
perceptrons together to actually build
neural<00:18:07.390><c> networks</c><00:18:07.919><c> and</c><00:18:09.000><c> let's</c><00:18:10.000><c> see</c><00:18:10.120><c> how</c><00:18:10.210><c> this</c>

00:18:10.320 --> 00:18:10.330 align:start position:0%
neural networks and let's see how this
 

00:18:10.330 --> 00:18:11.760 align:start position:0%
neural networks and let's see how this
all<00:18:10.450><c> comes</c><00:18:10.510><c> together</c><00:18:10.809><c> so</c><00:18:11.080><c> let's</c><00:18:11.289><c> revisit</c><00:18:11.530><c> our</c>

00:18:11.760 --> 00:18:11.770 align:start position:0%
all comes together so let's revisit our
 

00:18:11.770 --> 00:18:15.210 align:start position:0%
all comes together so let's revisit our
previous<00:18:12.130><c> diagram</c><00:18:12.549><c> of</c><00:18:12.700><c> the</c><00:18:12.789><c> perceptron</c><00:18:14.220><c> now</c>

00:18:15.210 --> 00:18:15.220 align:start position:0%
previous diagram of the perceptron now
 

00:18:15.220 --> 00:18:16.409 align:start position:0%
previous diagram of the perceptron now
if<00:18:15.309><c> there's</c><00:18:15.490><c> a</c><00:18:15.549><c> few</c><00:18:15.730><c> things</c><00:18:15.970><c> that</c><00:18:16.059><c> you</c><00:18:16.179><c> learned</c>

00:18:16.409 --> 00:18:16.419 align:start position:0%
if there's a few things that you learned
 

00:18:16.419 --> 00:18:18.270 align:start position:0%
if there's a few things that you learned
from<00:18:16.510><c> this</c><00:18:16.720><c> class</c><00:18:17.020><c> let</c><00:18:17.470><c> this</c><00:18:17.590><c> be</c><00:18:17.799><c> one</c><00:18:17.950><c> of</c><00:18:18.100><c> them</c>

00:18:18.270 --> 00:18:18.280 align:start position:0%
from this class let this be one of them
 

00:18:18.280 --> 00:18:19.890 align:start position:0%
from this class let this be one of them
and<00:18:18.520><c> we'll</c><00:18:18.970><c> keep</c><00:18:19.120><c> repeating</c><00:18:19.419><c> it</c><00:18:19.600><c> over</c><00:18:19.750><c> and</c>

00:18:19.890 --> 00:18:19.900 align:start position:0%
and we'll keep repeating it over and
 

00:18:19.900 --> 00:18:23.370 align:start position:0%
and we'll keep repeating it over and
over<00:18:20.080><c> in</c><00:18:20.700><c> deep</c><00:18:21.700><c> learning</c><00:18:21.909><c> you</c><00:18:22.360><c> do</c><00:18:22.870><c> a</c><00:18:23.110><c> dot</c>

00:18:23.370 --> 00:18:23.380 align:start position:0%
over in deep learning you do a dot
 

00:18:23.380 --> 00:18:25.799 align:start position:0%
over in deep learning you do a dot
product<00:18:23.830><c> you</c><00:18:24.130><c> apply</c><00:18:24.610><c> a</c><00:18:24.640><c> bias</c><00:18:24.909><c> and</c><00:18:25.390><c> you</c><00:18:25.419><c> add</c>

00:18:25.799 --> 00:18:25.809 align:start position:0%
product you apply a bias and you add
 

00:18:25.809 --> 00:18:27.779 align:start position:0%
product you apply a bias and you add
your<00:18:25.840><c> non-linearity</c><00:18:26.679><c> you</c><00:18:26.890><c> keep</c><00:18:27.520><c> repeating</c>

00:18:27.779 --> 00:18:27.789 align:start position:0%
your non-linearity you keep repeating
 

00:18:27.789 --> 00:18:30.539 align:start position:0%
your non-linearity you keep repeating
that<00:18:27.970><c> many</c><00:18:28.480><c> many</c><00:18:28.720><c> times</c><00:18:29.020><c> three</c><00:18:29.620><c> each</c><00:18:30.130><c> node</c>

00:18:30.539 --> 00:18:30.549 align:start position:0%
that many many times three each node
 

00:18:30.549 --> 00:18:32.640 align:start position:0%
that many many times three each node
each<00:18:30.850><c> neuron</c><00:18:31.330><c> and</c><00:18:31.570><c> your</c><00:18:31.720><c> neural</c><00:18:32.169><c> network</c><00:18:32.470><c> and</c>

00:18:32.640 --> 00:18:32.650 align:start position:0%
each neuron and your neural network and
 

00:18:32.650 --> 00:18:36.720 align:start position:0%
each neuron and your neural network and
that's<00:18:33.580><c> a</c><00:18:33.669><c> neural</c><00:18:33.880><c> network</c><00:18:35.220><c> so</c><00:18:36.220><c> it's</c><00:18:36.340><c> simplify</c>

00:18:36.720 --> 00:18:36.730 align:start position:0%
that's a neural network so it's simplify
 

00:18:36.730 --> 00:18:38.630 align:start position:0%
that's a neural network so it's simplify
this<00:18:36.789><c> diagram</c><00:18:37.270><c> a</c><00:18:37.299><c> little</c><00:18:37.390><c> I</c><00:18:37.750><c> remove</c><00:18:38.260><c> the</c><00:18:38.409><c> bias</c>

00:18:38.630 --> 00:18:38.640 align:start position:0%
this diagram a little I remove the bias
 

00:18:38.640 --> 00:18:40.680 align:start position:0%
this diagram a little I remove the bias
since<00:18:39.640><c> we</c><00:18:39.760><c> were</c><00:18:39.880><c> going</c><00:18:39.909><c> to</c><00:18:40.210><c> always</c><00:18:40.360><c> have</c><00:18:40.659><c> that</c>

00:18:40.680 --> 00:18:40.690 align:start position:0%
since we were going to always have that
 

00:18:40.690 --> 00:18:42.510 align:start position:0%
since we were going to always have that
and<00:18:41.080><c> we</c><00:18:41.110><c> just</c><00:18:41.650><c> take</c><00:18:41.799><c> you</c><00:18:41.890><c> for</c><00:18:42.070><c> granted</c><00:18:42.100><c> from</c>

00:18:42.510 --> 00:18:42.520 align:start position:0%
and we just take you for granted from
 

00:18:42.520 --> 00:18:44.310 align:start position:0%
and we just take you for granted from
now<00:18:42.700><c> on</c><00:18:42.850><c> I'll</c><00:18:43.059><c> remove</c><00:18:43.659><c> all</c><00:18:43.900><c> of</c><00:18:44.020><c> the</c><00:18:44.140><c> weight</c>

00:18:44.310 --> 00:18:44.320 align:start position:0%
now on I'll remove all of the weight
 

00:18:44.320 --> 00:18:49.080 align:start position:0%
now on I'll remove all of the weight
labels<00:18:44.940><c> for</c><00:18:45.940><c> simplicity</c><00:18:46.480><c> and</c><00:18:47.309><c> note</c><00:18:48.309><c> that</c><00:18:48.520><c> Z</c><00:18:48.850><c> is</c>

00:18:49.080 --> 00:18:49.090 align:start position:0%
labels for simplicity and note that Z is
 

00:18:49.090 --> 00:18:51.210 align:start position:0%
labels for simplicity and note that Z is
just<00:18:49.809><c> the</c><00:18:49.990><c> input</c><00:18:50.260><c> to</c><00:18:50.830><c> our</c><00:18:50.919><c> activation</c>

00:18:51.210 --> 00:18:51.220 align:start position:0%
just the input to our activation
 

00:18:51.220 --> 00:18:53.850 align:start position:0%
just the input to our activation
function<00:18:51.730><c> so</c><00:18:51.880><c> that's</c><00:18:52.000><c> just</c><00:18:52.330><c> the</c><00:18:53.110><c> dot</c><00:18:53.409><c> product</c>

00:18:53.850 --> 00:18:53.860 align:start position:0%
function so that's just the dot product
 

00:18:53.860 --> 00:18:56.880 align:start position:0%
function so that's just the dot product
plus<00:18:53.950><c> our</c><00:18:54.429><c> bias</c><00:18:54.909><c> if</c><00:18:55.720><c> we</c><00:18:56.230><c> want</c><00:18:56.380><c> the</c><00:18:56.470><c> output</c><00:18:56.620><c> of</c>

00:18:56.880 --> 00:18:56.890 align:start position:0%
plus our bias if we want the output of
 

00:18:56.890 --> 00:18:58.919 align:start position:0%
plus our bias if we want the output of
the<00:18:56.950><c> network</c><00:18:57.100><c> Y</c><00:18:57.490><c> we</c><00:18:57.909><c> simply</c><00:18:58.240><c> take</c><00:18:58.419><c> Z</c><00:18:58.659><c> and</c><00:18:58.870><c> we</c>

00:18:58.919 --> 00:18:58.929 align:start position:0%
the network Y we simply take Z and we
 

00:18:58.929 --> 00:19:02.669 align:start position:0%
the network Y we simply take Z and we
apply<00:18:59.169><c> our</c><00:18:59.260><c> non-linearity</c><00:18:59.919><c> like</c><00:19:00.159><c> before</c><00:19:01.679><c> if</c>

00:19:02.669 --> 00:19:02.679 align:start position:0%
apply our non-linearity like before if
 

00:19:02.679 --> 00:19:04.049 align:start position:0%
apply our non-linearity like before if
we<00:19:02.770><c> want</c><00:19:02.919><c> to</c><00:19:02.980><c> define</c><00:19:03.220><c> a</c><00:19:03.400><c> multi</c><00:19:03.820><c> output</c>

00:19:04.049 --> 00:19:04.059 align:start position:0%
we want to define a multi output
 

00:19:04.059 --> 00:19:06.419 align:start position:0%
we want to define a multi output
perceptron<00:19:04.960><c> it's</c><00:19:05.440><c> very</c><00:19:05.650><c> simple</c><00:19:05.980><c> we</c><00:19:06.130><c> just</c><00:19:06.309><c> add</c>

00:19:06.419 --> 00:19:06.429 align:start position:0%
perceptron it's very simple we just add
 

00:19:06.429 --> 00:19:08.490 align:start position:0%
perceptron it's very simple we just add
another<00:19:06.730><c> perceptron</c><00:19:07.299><c> now</c><00:19:08.110><c> we</c><00:19:08.200><c> have</c><00:19:08.320><c> two</c>

00:19:08.490 --> 00:19:08.500 align:start position:0%
another perceptron now we have two
 

00:19:08.500 --> 00:19:09.990 align:start position:0%
another perceptron now we have two
outputs<00:19:08.860><c> y1</c><00:19:09.309><c> and</c><00:19:09.490><c> y2</c>

00:19:09.990 --> 00:19:10.000 align:start position:0%
outputs y1 and y2
 

00:19:10.000 --> 00:19:13.560 align:start position:0%
outputs y1 and y2
each<00:19:10.809><c> one</c><00:19:11.230><c> has</c><00:19:11.710><c> weight</c><00:19:12.460><c> matrices</c><00:19:12.850><c> it</c><00:19:13.419><c> has</c>

00:19:13.560 --> 00:19:13.570 align:start position:0%
each one has weight matrices it has
 

00:19:13.570 --> 00:19:16.470 align:start position:0%
each one has weight matrices it has
weight<00:19:13.840><c> vector</c><00:19:14.289><c> theta</c><00:19:14.940><c> corresponding</c><00:19:15.940><c> to</c><00:19:16.150><c> the</c>

00:19:16.470 --> 00:19:16.480 align:start position:0%
weight vector theta corresponding to the
 

00:19:16.480 --> 00:19:23.700 align:start position:0%
weight vector theta corresponding to the
weight<00:19:16.720><c> of</c><00:19:16.990><c> each</c><00:19:17.440><c> of</c><00:19:17.590><c> the</c><00:19:17.710><c> inputs</c><00:19:21.929><c> now</c><00:19:22.929><c> let's</c>

00:19:23.700 --> 00:19:23.710 align:start position:0%
weight of each of the inputs now let's
 

00:19:23.710 --> 00:19:25.169 align:start position:0%
weight of each of the inputs now let's
suppose<00:19:23.799><c> we</c><00:19:24.039><c> want</c><00:19:24.220><c> to</c><00:19:24.280><c> go</c><00:19:24.400><c> the</c><00:19:24.909><c> next</c><00:19:25.059><c> step</c>

00:19:25.169 --> 00:19:25.179 align:start position:0%
suppose we want to go the next step
 

00:19:25.179 --> 00:19:28.710 align:start position:0%
suppose we want to go the next step
deeper<00:19:25.950><c> we</c><00:19:26.950><c> want</c><00:19:27.159><c> to</c><00:19:27.250><c> create</c><00:19:27.909><c> now</c><00:19:28.120><c> a</c><00:19:28.150><c> single</c>

00:19:28.710 --> 00:19:28.720 align:start position:0%
deeper we want to create now a single
 

00:19:28.720 --> 00:19:31.890 align:start position:0%
deeper we want to create now a single
layered<00:19:28.929><c> neural</c><00:19:29.169><c> network</c><00:19:30.720><c> single</c><00:19:31.720><c> layered</c>

00:19:31.890 --> 00:19:31.900 align:start position:0%
layered neural network single layered
 

00:19:31.900 --> 00:19:33.570 align:start position:0%
layered neural network single layered
neural<00:19:32.049><c> networks</c><00:19:32.500><c> are</c><00:19:32.830><c> actually</c><00:19:33.190><c> not</c><00:19:33.340><c> deep</c>

00:19:33.570 --> 00:19:33.580 align:start position:0%
neural networks are actually not deep
 

00:19:33.580 --> 00:19:36.090 align:start position:0%
neural networks are actually not deep
networks<00:19:33.970><c> yet</c><00:19:34.179><c> they're</c><00:19:34.450><c> only</c><00:19:34.799><c> there's</c><00:19:35.799><c> still</c>

00:19:36.090 --> 00:19:36.100 align:start position:0%
networks yet they're only there's still
 

00:19:36.100 --> 00:19:37.740 align:start position:0%
networks yet they're only there's still
shallow<00:19:36.340><c> networks</c><00:19:36.789><c> they're</c><00:19:37.030><c> only</c><00:19:37.150><c> one</c><00:19:37.539><c> layer</c>

00:19:37.740 --> 00:19:37.750 align:start position:0%
shallow networks they're only one layer
 

00:19:37.750 --> 00:19:40.320 align:start position:0%
shallow networks they're only one layer
deep<00:19:38.020><c> but</c><00:19:38.860><c> let's</c><00:19:39.010><c> look</c><00:19:39.190><c> at</c><00:19:39.370><c> the</c><00:19:39.970><c> singledom</c>

00:19:40.320 --> 00:19:40.330 align:start position:0%
deep but let's look at the singledom
 

00:19:40.330 --> 00:19:43.140 align:start position:0%
deep but let's look at the singledom
layered<00:19:40.600><c> neural</c><00:19:40.840><c> network</c><00:19:41.230><c> where</c><00:19:42.159><c> now</c><00:19:42.789><c> all</c><00:19:42.820><c> we</c>

00:19:43.140 --> 00:19:43.150 align:start position:0%
layered neural network where now all we
 

00:19:43.150 --> 00:19:44.669 align:start position:0%
layered neural network where now all we
do<00:19:43.270><c> is</c><00:19:43.419><c> we</c><00:19:43.539><c> have</c><00:19:43.630><c> one</c><00:19:43.840><c> hidden</c><00:19:44.080><c> layer</c><00:19:44.200><c> between</c>

00:19:44.669 --> 00:19:44.679 align:start position:0%
do is we have one hidden layer between
 

00:19:44.679 --> 00:19:46.590 align:start position:0%
do is we have one hidden layer between
our<00:19:44.799><c> inputs</c><00:19:45.130><c> and</c><00:19:45.280><c> outputs</c><00:19:45.669><c> we</c><00:19:46.059><c> call</c><00:19:46.270><c> this</c><00:19:46.390><c> a</c>

00:19:46.590 --> 00:19:46.600 align:start position:0%
our inputs and outputs we call this a
 

00:19:46.600 --> 00:19:50.130 align:start position:0%
our inputs and outputs we call this a
hidden<00:19:47.049><c> layer</c><00:19:47.230><c> because</c><00:19:47.880><c> it's</c><00:19:48.880><c> states</c><00:19:49.659><c> are</c><00:19:49.960><c> not</c>

00:19:50.130 --> 00:19:50.140 align:start position:0%
hidden layer because it's states are not
 

00:19:50.140 --> 00:19:51.840 align:start position:0%
hidden layer because it's states are not
directly<00:19:50.559><c> observable</c><00:19:51.070><c> they're</c><00:19:51.429><c> not</c><00:19:51.549><c> directly</c>

00:19:51.840 --> 00:19:51.850 align:start position:0%
directly observable they're not directly
 

00:19:51.850 --> 00:19:56.549 align:start position:0%
directly observable they're not directly
enforced<00:19:52.450><c> by</c><00:19:53.320><c> by</c><00:19:54.190><c> the</c><00:19:54.250><c> AI</c><00:19:54.909><c> designer</c><00:19:55.510><c> we</c><00:19:56.169><c> only</c>

00:19:56.549 --> 00:19:56.559 align:start position:0%
enforced by by the AI designer we only
 

00:19:56.559 --> 00:19:59.039 align:start position:0%
enforced by by the AI designer we only
enforce<00:19:57.190><c> the</c><00:19:57.490><c> inputs</c><00:19:57.880><c> and</c><00:19:58.090><c> outputs</c><00:19:58.240><c> typically</c>

00:19:59.039 --> 00:19:59.049 align:start position:0%
enforce the inputs and outputs typically
 

00:19:59.049 --> 00:20:02.450 align:start position:0%
enforce the inputs and outputs typically
the<00:19:59.860><c> states</c><00:20:00.159><c> in</c><00:20:00.340><c> the</c><00:20:00.429><c> middle</c><00:20:00.700><c> are</c><00:20:00.909><c> hidden</c><00:20:01.480><c> and</c>

00:20:02.450 --> 00:20:02.460 align:start position:0%
the states in the middle are hidden and
 

00:20:02.460 --> 00:20:04.409 align:start position:0%
the states in the middle are hidden and
since<00:20:03.460><c> we</c><00:20:03.580><c> now</c><00:20:03.700><c> have</c><00:20:03.850><c> a</c><00:20:03.909><c> transformer</c>

00:20:04.409 --> 00:20:04.419 align:start position:0%
since we now have a transformer
 

00:20:04.419 --> 00:20:06.509 align:start position:0%
since we now have a transformer
to<00:20:04.690><c> go</c><00:20:04.779><c> from</c><00:20:04.960><c> our</c><00:20:05.080><c> input</c><00:20:05.499><c> space</c><00:20:05.739><c> to</c><00:20:06.249><c> our</c><00:20:06.340><c> hidden</c>

00:20:06.509 --> 00:20:06.519 align:start position:0%
to go from our input space to our hidden
 

00:20:06.519 --> 00:20:08.849 align:start position:0%
to go from our input space to our hidden
hidden<00:20:07.090><c> lair</c><00:20:07.389><c> space</c><00:20:07.720><c> and</c><00:20:08.019><c> from</c><00:20:08.470><c> our</c><00:20:08.590><c> hidden</c>

00:20:08.849 --> 00:20:08.859 align:start position:0%
hidden lair space and from our hidden
 

00:20:08.859 --> 00:20:11.820 align:start position:0%
hidden lair space and from our hidden
lair<00:20:09.009><c> space</c><00:20:09.309><c> to</c><00:20:09.759><c> our</c><00:20:09.879><c> output</c><00:20:10.090><c> layer</c><00:20:10.419><c> space</c><00:20:10.830><c> we</c>

00:20:11.820 --> 00:20:11.830 align:start position:0%
lair space to our output layer space we
 

00:20:11.830 --> 00:20:14.099 align:start position:0%
lair space to our output layer space we
actually<00:20:11.859><c> need</c><00:20:12.429><c> two</c><00:20:12.850><c> weight</c><00:20:13.179><c> matrices</c><00:20:13.570><c> theta</c>

00:20:14.099 --> 00:20:14.109 align:start position:0%
actually need two weight matrices theta
 

00:20:14.109 --> 00:20:16.440 align:start position:0%
actually need two weight matrices theta
1<00:20:14.409><c> and</c><00:20:14.710><c> theta</c><00:20:14.799><c> 2</c><00:20:15.119><c> corresponding</c><00:20:16.119><c> to</c><00:20:16.179><c> the</c>

00:20:16.440 --> 00:20:16.450 align:start position:0%
1 and theta 2 corresponding to the
 

00:20:16.450 --> 00:20:21.450 align:start position:0%
1 and theta 2 corresponding to the
weight<00:20:16.600><c> matrices</c><00:20:17.049><c> of</c><00:20:17.409><c> each</c><00:20:17.980><c> layer</c><00:20:20.249><c> now</c><00:20:21.249><c> if</c><00:20:21.369><c> we</c>

00:20:21.450 --> 00:20:21.460 align:start position:0%
weight matrices of each layer now if we
 

00:20:21.460 --> 00:20:23.249 align:start position:0%
weight matrices of each layer now if we
look<00:20:21.580><c> at</c><00:20:21.730><c> just</c><00:20:21.879><c> a</c><00:20:21.970><c> single</c><00:20:22.359><c> unit</c><00:20:22.809><c> in</c><00:20:23.019><c> that</c>

00:20:23.249 --> 00:20:23.259 align:start position:0%
look at just a single unit in that
 

00:20:23.259 --> 00:20:25.229 align:start position:0%
look at just a single unit in that
hidden<00:20:23.559><c> layer</c><00:20:23.739><c> it's</c><00:20:24.279><c> the</c><00:20:24.429><c> exact</c><00:20:24.789><c> same</c><00:20:24.970><c> story</c>

00:20:25.229 --> 00:20:25.239 align:start position:0%
hidden layer it's the exact same story
 

00:20:25.239 --> 00:20:27.720 align:start position:0%
hidden layer it's the exact same story
as<00:20:25.389><c> before</c><00:20:25.749><c> it's</c><00:20:25.899><c> one</c><00:20:26.080><c> perceptron</c><00:20:26.769><c> we</c><00:20:27.489><c> take</c>

00:20:27.720 --> 00:20:27.730 align:start position:0%
as before it's one perceptron we take
 

00:20:27.730 --> 00:20:29.460 align:start position:0%
as before it's one perceptron we take
its<00:20:27.879><c> top</c><00:20:28.090><c> product</c><00:20:28.480><c> with</c><00:20:28.629><c> all</c><00:20:28.779><c> of</c><00:20:28.869><c> the</c><00:20:28.960><c> X's</c><00:20:29.320><c> that</c>

00:20:29.460 --> 00:20:29.470 align:start position:0%
its top product with all of the X's that
 

00:20:29.470 --> 00:20:33.450 align:start position:0%
its top product with all of the X's that
came<00:20:29.649><c> before</c><00:20:29.799><c> it</c><00:20:30.009><c> and</c><00:20:30.929><c> we</c><00:20:31.929><c> apply</c><00:20:32.200><c> I'm</c><00:20:33.129><c> sorry</c><00:20:33.340><c> we</c>

00:20:33.450 --> 00:20:33.460 align:start position:0%
came before it and we apply I'm sorry we
 

00:20:33.460 --> 00:20:34.739 align:start position:0%
came before it and we apply I'm sorry we
take<00:20:33.609><c> the</c><00:20:33.700><c> dot</c><00:20:33.879><c> product</c><00:20:34.210><c> of</c><00:20:34.269><c> the</c><00:20:34.389><c> X's</c><00:20:34.659><c> that</c>

00:20:34.739 --> 00:20:34.749 align:start position:0%
take the dot product of the X's that
 

00:20:34.749 --> 00:20:36.269 align:start position:0%
take the dot product of the X's that
came<00:20:34.899><c> before</c><00:20:35.049><c> with</c><00:20:35.470><c> the</c><00:20:35.649><c> weight</c><00:20:35.799><c> matrices</c>

00:20:36.269 --> 00:20:36.279 align:start position:0%
came before with the weight matrices
 

00:20:36.279 --> 00:20:39.659 align:start position:0%
came before with the weight matrices
theta<00:20:36.669><c> is</c><00:20:36.820><c> theta</c><00:20:37.299><c> one</c><00:20:37.600><c> in</c><00:20:37.809><c> this</c><00:20:38.019><c> case</c><00:20:38.519><c> we</c><00:20:39.519><c> apply</c>

00:20:39.659 --> 00:20:39.669 align:start position:0%
theta is theta one in this case we apply
 

00:20:39.669 --> 00:20:42.720 align:start position:0%
theta is theta one in this case we apply
a<00:20:39.700><c> bias</c><00:20:40.059><c> to</c><00:20:40.899><c> get</c><00:20:41.019><c> Z</c><00:20:41.230><c> 2</c><00:20:41.470><c> and</c><00:20:41.739><c> if</c><00:20:42.249><c> we</c><00:20:42.340><c> look</c><00:20:42.489><c> we're</c>

00:20:42.720 --> 00:20:42.730 align:start position:0%
a bias to get Z 2 and if we look we're
 

00:20:42.730 --> 00:20:44.489 align:start position:0%
a bias to get Z 2 and if we look we're
to<00:20:42.820><c> look</c><00:20:42.970><c> at</c><00:20:43.059><c> a</c><00:20:43.090><c> different</c><00:20:43.299><c> hidden</c><00:20:43.960><c> unit</c><00:20:44.350><c> let's</c>

00:20:44.489 --> 00:20:44.499 align:start position:0%
to look at a different hidden unit let's
 

00:20:44.499 --> 00:20:47.279 align:start position:0%
to look at a different hidden unit let's
say<00:20:44.590><c> Z</c><00:20:44.799><c> 3</c><00:20:45.070><c> instead</c><00:20:45.539><c> we</c><00:20:46.539><c> would</c><00:20:46.659><c> just</c><00:20:46.809><c> take</c>

00:20:47.279 --> 00:20:47.289 align:start position:0%
say Z 3 instead we would just take
 

00:20:47.289 --> 00:20:50.070 align:start position:0%
say Z 3 instead we would just take
different<00:20:47.950><c> weight</c><00:20:48.220><c> matrices</c><00:20:48.700><c> different</c><00:20:49.299><c> our</c>

00:20:50.070 --> 00:20:50.080 align:start position:0%
different weight matrices different our
 

00:20:50.080 --> 00:20:52.499 align:start position:0%
different weight matrices different our
dot<00:20:50.799><c> product</c><00:20:51.039><c> to</c><00:20:51.220><c> change</c><00:20:51.519><c> our</c><00:20:51.700><c> bias</c><00:20:51.909><c> would</c>

00:20:52.499 --> 00:20:52.509 align:start position:0%
dot product to change our bias would
 

00:20:52.509 --> 00:20:55.200 align:start position:0%
dot product to change our bias would
change<00:20:52.840><c> but</c><00:20:53.499><c> and</c><00:20:54.399><c> this</c><00:20:54.580><c> means</c><00:20:54.789><c> that</c><00:20:54.879><c> Z</c><00:20:55.119><c> would</c>

00:20:55.200 --> 00:20:55.210 align:start position:0%
change but and this means that Z would
 

00:20:55.210 --> 00:20:56.519 align:start position:0%
change but and this means that Z would
change<00:20:55.419><c> which</c><00:20:55.570><c> means</c><00:20:55.779><c> this</c><00:20:55.869><c> activation</c><00:20:56.289><c> would</c>

00:20:56.519 --> 00:20:56.529 align:start position:0%
change which means this activation would
 

00:20:56.529 --> 00:20:59.519 align:start position:0%
change which means this activation would
also<00:20:56.710><c> be</c><00:20:57.070><c> different</c><00:20:57.929><c> so</c><00:20:58.929><c> from</c><00:20:59.109><c> now</c><00:20:59.230><c> on</c><00:20:59.350><c> I'm</c>

00:20:59.519 --> 00:20:59.529 align:start position:0%
also be different so from now on I'm
 

00:20:59.529 --> 00:21:02.519 align:start position:0%
also be different so from now on I'm
going<00:20:59.710><c> to</c><00:20:59.799><c> use</c><00:21:00.669><c> this</c><00:21:00.909><c> symbol</c><00:21:01.149><c> to</c><00:21:01.450><c> denote</c><00:21:01.659><c> what</c>

00:21:02.519 --> 00:21:02.529 align:start position:0%
going to use this symbol to denote what
 

00:21:02.529 --> 00:21:04.259 align:start position:0%
going to use this symbol to denote what
is<00:21:02.649><c> called</c><00:21:02.919><c> as</c><00:21:03.070><c> a</c><00:21:03.100><c> fully</c><00:21:03.369><c> connected</c><00:21:03.850><c> layer</c><00:21:04.090><c> and</c>

00:21:04.259 --> 00:21:04.269 align:start position:0%
is called as a fully connected layer and
 

00:21:04.269 --> 00:21:05.369 align:start position:0%
is called as a fully connected layer and
that's<00:21:04.389><c> what</c><00:21:04.539><c> we've</c><00:21:04.720><c> been</c><00:21:04.840><c> talking</c><00:21:05.019><c> about</c><00:21:05.139><c> so</c>

00:21:05.369 --> 00:21:05.379 align:start position:0%
that's what we've been talking about so
 

00:21:05.379 --> 00:21:07.619 align:start position:0%
that's what we've been talking about so
far<00:21:05.409><c> so</c><00:21:05.769><c> that's</c><00:21:05.859><c> every</c><00:21:06.519><c> node</c><00:21:06.730><c> and</c><00:21:06.759><c> one</c><00:21:07.119><c> layer</c>

00:21:07.619 --> 00:21:07.629 align:start position:0%
far so that's every node and one layer
 

00:21:07.629 --> 00:21:09.149 align:start position:0%
far so that's every node and one layer
is<00:21:07.869><c> connected</c><00:21:08.350><c> to</c><00:21:08.440><c> every</c><00:21:08.739><c> node</c><00:21:08.919><c> and</c><00:21:08.950><c> another</c>

00:21:09.149 --> 00:21:09.159 align:start position:0%
is connected to every node and another
 

00:21:09.159 --> 00:21:12.299 align:start position:0%
is connected to every node and another
layer<00:21:09.609><c> by</c><00:21:10.269><c> these</c><00:21:10.480><c> weight</c><00:21:10.690><c> matrices</c><00:21:11.080><c> and</c><00:21:11.470><c> this</c>

00:21:12.299 --> 00:21:12.309 align:start position:0%
layer by these weight matrices and this
 

00:21:12.309 --> 00:21:14.039 align:start position:0%
layer by these weight matrices and this
is<00:21:12.460><c> really</c><00:21:12.669><c> just</c><00:21:12.879><c> for</c><00:21:12.909><c> simplicity</c><00:21:13.570><c> so</c><00:21:13.840><c> I</c><00:21:13.869><c> don't</c>

00:21:14.039 --> 00:21:14.049 align:start position:0%
is really just for simplicity so I don't
 

00:21:14.049 --> 00:21:17.249 align:start position:0%
is really just for simplicity so I don't
have<00:21:14.109><c> to</c><00:21:14.230><c> keep</c><00:21:14.350><c> redrawing</c><00:21:14.739><c> those</c><00:21:14.980><c> lines</c><00:21:16.259><c> now</c>

00:21:17.249 --> 00:21:17.259 align:start position:0%
have to keep redrawing those lines now
 

00:21:17.259 --> 00:21:18.389 align:start position:0%
have to keep redrawing those lines now
if<00:21:17.350><c> we</c><00:21:17.440><c> want</c><00:21:17.590><c> to</c><00:21:17.649><c> create</c><00:21:17.799><c> a</c><00:21:17.889><c> deep</c><00:21:18.159><c> neural</c>

00:21:18.389 --> 00:21:18.399 align:start position:0%
if we want to create a deep neural
 

00:21:18.399 --> 00:21:21.450 align:start position:0%
if we want to create a deep neural
network<00:21:18.840><c> all</c><00:21:19.840><c> we</c><00:21:20.289><c> do</c><00:21:20.440><c> is</c><00:21:20.590><c> keep</c><00:21:20.739><c> stacking</c><00:21:21.100><c> these</c>

00:21:21.450 --> 00:21:21.460 align:start position:0%
network all we do is keep stacking these
 

00:21:21.460 --> 00:21:23.549 align:start position:0%
network all we do is keep stacking these
layers<00:21:21.759><c> and</c><00:21:22.059><c> fully</c><00:21:22.389><c> connected</c><00:21:22.929><c> weights</c>

00:21:23.549 --> 00:21:23.559 align:start position:0%
layers and fully connected weights
 

00:21:23.559 --> 00:21:26.279 align:start position:0%
layers and fully connected weights
between<00:21:24.369><c> the</c><00:21:24.489><c> layers</c><00:21:24.700><c> it's</c><00:21:25.179><c> that</c><00:21:25.419><c> simple</c><00:21:25.659><c> but</c>

00:21:26.279 --> 00:21:26.289 align:start position:0%
between the layers it's that simple but
 

00:21:26.289 --> 00:21:27.899 align:start position:0%
between the layers it's that simple but
the<00:21:26.440><c> underlying</c><00:21:26.859><c> building</c><00:21:27.429><c> block</c><00:21:27.639><c> is</c><00:21:27.850><c> that</c>

00:21:27.899 --> 00:21:27.909 align:start position:0%
the underlying building block is that
 

00:21:27.909 --> 00:21:31.039 align:start position:0%
the underlying building block is that
single<00:21:28.450><c> perceptron</c><00:21:29.169><c> set</c><00:21:29.769><c> single</c><00:21:30.190><c> dot</c><00:21:30.369><c> product</c>

00:21:31.039 --> 00:21:31.049 align:start position:0%
single perceptron set single dot product
 

00:21:31.049 --> 00:21:33.919 align:start position:0%
single perceptron set single dot product
non-linearity<00:21:32.049><c> and</c><00:21:32.200><c> bias</c><00:21:32.409><c> that's</c><00:21:32.919><c> it</c>

00:21:33.919 --> 00:21:33.929 align:start position:0%
non-linearity and bias that's it
 

00:21:33.929 --> 00:21:36.269 align:start position:0%
non-linearity and bias that's it
so<00:21:34.929><c> this</c><00:21:35.080><c> is</c><00:21:35.200><c> really</c><00:21:35.619><c> incredible</c><00:21:36.039><c> because</c>

00:21:36.269 --> 00:21:36.279 align:start position:0%
so this is really incredible because
 

00:21:36.279 --> 00:21:38.639 align:start position:0%
so this is really incredible because
something<00:21:36.609><c> so</c><00:21:36.850><c> simple</c><00:21:37.239><c> at</c><00:21:37.600><c> the</c><00:21:37.659><c> foundation</c><00:21:38.499><c> is</c>

00:21:38.639 --> 00:21:38.649 align:start position:0%
something so simple at the foundation is
 

00:21:38.649 --> 00:21:40.710 align:start position:0%
something so simple at the foundation is
still<00:21:38.859><c> able</c><00:21:39.100><c> to</c><00:21:39.460><c> create</c><00:21:39.759><c> such</c><00:21:39.999><c> incredible</c>

00:21:40.710 --> 00:21:40.720 align:start position:0%
still able to create such incredible
 

00:21:40.720 --> 00:21:43.200 align:start position:0%
still able to create such incredible
algorithms<00:21:41.710><c> and</c><00:21:41.950><c> now</c><00:21:42.669><c> let's</c><00:21:42.820><c> see</c><00:21:42.970><c> an</c><00:21:43.090><c> example</c>

00:21:43.200 --> 00:21:43.210 align:start position:0%
algorithms and now let's see an example
 

00:21:43.210 --> 00:21:44.940 align:start position:0%
algorithms and now let's see an example
of<00:21:43.539><c> how</c><00:21:43.720><c> we</c><00:21:43.779><c> can</c><00:21:44.049><c> actually</c><00:21:44.200><c> apply</c><00:21:44.409><c> neural</c>

00:21:44.940 --> 00:21:44.950 align:start position:0%
of how we can actually apply neural
 

00:21:44.950 --> 00:21:47.700 align:start position:0%
of how we can actually apply neural
networks<00:21:45.249><c> to</c><00:21:45.549><c> a</c><00:21:46.450><c> very</c><00:21:46.899><c> important</c><00:21:47.289><c> question</c>

00:21:47.700 --> 00:21:47.710 align:start position:0%
networks to a very important question
 

00:21:47.710 --> 00:21:50.159 align:start position:0%
networks to a very important question
that<00:21:47.739><c> I</c><00:21:47.950><c> know</c><00:21:48.070><c> you</c><00:21:48.700><c> are</c><00:21:48.820><c> all</c><00:21:49.169><c> extremely</c>

00:21:50.159 --> 00:21:50.169 align:start position:0%
that I know you are all extremely
 

00:21:50.169 --> 00:21:51.960 align:start position:0%
that I know you are all extremely
worried<00:21:50.919><c> about</c><00:21:51.009><c> you</c><00:21:51.460><c> care</c><00:21:51.730><c> a</c><00:21:51.759><c> lot</c><00:21:51.909><c> about</c>

00:21:51.960 --> 00:21:51.970 align:start position:0%
worried about you care a lot about
 

00:21:51.970 --> 00:21:54.930 align:start position:0%
worried about you care a lot about
here's<00:21:52.899><c> the</c><00:21:53.080><c> question</c><00:21:53.440><c> you</c><00:21:54.399><c> want</c><00:21:54.549><c> to</c><00:21:54.609><c> build</c><00:21:54.789><c> an</c>

00:21:54.930 --> 00:21:54.940 align:start position:0%
here's the question you want to build an
 

00:21:54.940 --> 00:21:57.419 align:start position:0%
here's the question you want to build an
AI<00:21:55.090><c> system</c><00:21:55.749><c> that</c><00:21:56.619><c> answers</c><00:21:56.950><c> the</c><00:21:57.129><c> following</c>

00:21:57.419 --> 00:21:57.429 align:start position:0%
AI system that answers the following
 

00:21:57.429 --> 00:21:59.909 align:start position:0%
AI system that answers the following
question<00:21:57.820><c> will</c><00:21:58.269><c> I</c><00:21:58.299><c> pass</c><00:21:58.570><c> this</c><00:21:58.869><c> class</c><00:21:59.049><c> yes</c><00:21:59.739><c> or</c>

00:21:59.909 --> 00:21:59.919 align:start position:0%
question will I pass this class yes or
 

00:21:59.919 --> 00:22:03.899 align:start position:0%
question will I pass this class yes or
no<00:22:00.070><c> one</c><00:22:00.759><c> or</c><00:22:00.909><c> zero</c><00:22:00.940><c> is</c><00:22:01.450><c> the</c><00:22:01.690><c> output</c><00:22:02.639><c> to</c><00:22:03.639><c> do</c><00:22:03.759><c> this</c>

00:22:03.899 --> 00:22:03.909 align:start position:0%
no one or zero is the output to do this
 

00:22:03.909 --> 00:22:06.539 align:start position:0%
no one or zero is the output to do this
let's<00:22:04.179><c> start</c><00:22:04.419><c> by</c><00:22:04.570><c> defining</c><00:22:04.749><c> a</c><00:22:05.169><c> simple</c><00:22:05.619><c> two</c>

00:22:06.539 --> 00:22:06.549 align:start position:0%
let's start by defining a simple two
 

00:22:06.549 --> 00:22:08.940 align:start position:0%
let's start by defining a simple two
feature<00:22:06.789><c> model</c><00:22:07.059><c> one</c><00:22:07.749><c> feature</c><00:22:07.960><c> is</c><00:22:08.320><c> the</c><00:22:08.710><c> number</c>

00:22:08.940 --> 00:22:08.950 align:start position:0%
feature model one feature is the number
 

00:22:08.950 --> 00:22:11.070 align:start position:0%
feature model one feature is the number
of<00:22:09.009><c> lectures</c><00:22:09.340><c> that</c><00:22:09.489><c> you</c><00:22:09.639><c> attend</c><00:22:09.999><c> the</c><00:22:10.720><c> second</c>

00:22:11.070 --> 00:22:11.080 align:start position:0%
of lectures that you attend the second
 

00:22:11.080 --> 00:22:12.299 align:start position:0%
of lectures that you attend the second
feature<00:22:11.169><c> is</c><00:22:11.320><c> the</c><00:22:11.440><c> number</c><00:22:11.679><c> of</c><00:22:11.739><c> hours</c><00:22:12.070><c> that</c><00:22:12.100><c> you</c>

00:22:12.299 --> 00:22:12.309 align:start position:0%
feature is the number of hours that you
 

00:22:12.309 --> 00:22:15.749 align:start position:0%
feature is the number of hours that you
spend<00:22:12.700><c> on</c><00:22:12.849><c> your</c><00:22:12.879><c> final</c><00:22:13.269><c> project</c><00:22:14.549><c> let's</c><00:22:15.549><c> plot</c>

00:22:15.749 --> 00:22:15.759 align:start position:0%
spend on your final project let's plot
 

00:22:15.759 --> 00:22:18.120 align:start position:0%
spend on your final project let's plot
this<00:22:15.940><c> data</c><00:22:16.210><c> in</c><00:22:16.539><c> our</c><00:22:17.049><c> feature</c><00:22:17.259><c> space</c>

00:22:18.120 --> 00:22:18.130 align:start position:0%
this data in our feature space
 

00:22:18.130 --> 00:22:20.340 align:start position:0%
this data in our feature space
reply<00:22:18.760><c> Greenpoint's</c><00:22:19.480><c> are</c><00:22:19.600><c> people</c><00:22:19.900><c> who</c><00:22:20.020><c> pass</c>

00:22:20.340 --> 00:22:20.350 align:start position:0%
reply Greenpoint's are people who pass
 

00:22:20.350 --> 00:22:23.580 align:start position:0%
reply Greenpoint's are people who pass
red<00:22:21.100><c> points</c><00:22:21.370><c> are</c><00:22:21.460><c> people</c><00:22:21.670><c> I</c><00:22:21.760><c> fail</c><00:22:22.290><c> we</c><00:22:23.290><c> want</c><00:22:23.500><c> to</c>

00:22:23.580 --> 00:22:23.590 align:start position:0%
red points are people I fail we want to
 

00:22:23.590 --> 00:22:26.910 align:start position:0%
red points are people I fail we want to
know<00:22:23.710><c> given</c><00:22:24.010><c> a</c><00:22:24.070><c> new</c><00:22:24.220><c> person</c><00:22:24.640><c> this</c><00:22:24.850><c> guy</c><00:22:25.920><c> he</c>

00:22:26.910 --> 00:22:26.920 align:start position:0%
know given a new person this guy he
 

00:22:26.920 --> 00:22:30.930 align:start position:0%
know given a new person this guy he
spent<00:22:27.250><c> ersity</c><00:22:27.970><c> they</c><00:22:28.390><c> spent</c><00:22:29.550><c> five</c><00:22:30.550><c> hours</c><00:22:30.580><c> on</c>

00:22:30.930 --> 00:22:30.940 align:start position:0%
spent ersity they spent five hours on
 

00:22:30.940 --> 00:22:33.090 align:start position:0%
spent ersity they spent five hours on
their<00:22:31.090><c> final</c><00:22:31.330><c> project</c><00:22:31.750><c> and</c><00:22:31.930><c> we</c><00:22:32.500><c> went</c><00:22:32.680><c> to</c><00:22:32.830><c> four</c>

00:22:33.090 --> 00:22:33.100 align:start position:0%
their final project and we went to four
 

00:22:33.100 --> 00:22:35.670 align:start position:0%
their final project and we went to four
lectures<00:22:33.510><c> we</c><00:22:34.510><c> want</c><00:22:34.690><c> to</c><00:22:34.810><c> know</c><00:22:34.930><c> did</c><00:22:35.200><c> that</c><00:22:35.410><c> person</c>

00:22:35.670 --> 00:22:35.680 align:start position:0%
lectures we want to know did that person
 

00:22:35.680 --> 00:22:37.740 align:start position:0%
lectures we want to know did that person
pass<00:22:36.430><c> or</c><00:22:36.640><c> failed</c><00:22:36.820><c> a</c><00:22:36.970><c> class</c><00:22:37.060><c> and</c><00:22:37.450><c> we</c><00:22:37.480><c> want</c><00:22:37.660><c> to</c>

00:22:37.740 --> 00:22:37.750 align:start position:0%
pass or failed a class and we want to
 

00:22:37.750 --> 00:22:38.970 align:start position:0%
pass or failed a class and we want to
build<00:22:37.960><c> a</c><00:22:38.170><c> neural</c><00:22:38.440><c> network</c><00:22:38.710><c> that</c><00:22:38.740><c> will</c>

00:22:38.970 --> 00:22:38.980 align:start position:0%
build a neural network that will
 

00:22:38.980 --> 00:22:43.200 align:start position:0%
build a neural network that will
determine<00:22:39.250><c> this</c><00:22:39.720><c> so</c><00:22:40.720><c> let's</c><00:22:40.900><c> do</c><00:22:41.080><c> it</c><00:22:42.090><c> we</c><00:22:43.090><c> have</c>

00:22:43.200 --> 00:22:43.210 align:start position:0%
determine this so let's do it we have
 

00:22:43.210 --> 00:22:45.720 align:start position:0%
determine this so let's do it we have
two<00:22:43.360><c> inputs</c><00:22:43.720><c> one</c><00:22:44.050><c> is</c><00:22:44.170><c> for</c><00:22:44.380><c> the</c><00:22:44.530><c> others</c><00:22:44.710><c> five</c><00:22:44.950><c> we</c>

00:22:45.720 --> 00:22:45.730 align:start position:0%
two inputs one is for the others five we
 

00:22:45.730 --> 00:22:47.160 align:start position:0%
two inputs one is for the others five we
have<00:22:45.850><c> one</c><00:22:46.030><c> hidden</c><00:22:46.210><c> layer</c><00:22:46.330><c> with</c><00:22:46.630><c> three</c><00:22:46.840><c> units</c>

00:22:47.160 --> 00:22:47.170 align:start position:0%
have one hidden layer with three units
 

00:22:47.170 --> 00:22:49.350 align:start position:0%
have one hidden layer with three units
and<00:22:47.350><c> we</c><00:22:47.590><c> want</c><00:22:47.770><c> to</c><00:22:47.860><c> see</c><00:22:48.130><c> the</c><00:22:48.850><c> final</c><00:22:49.210><c> output</c>

00:22:49.350 --> 00:22:49.360 align:start position:0%
and we want to see the final output
 

00:22:49.360 --> 00:22:51.360 align:start position:0%
and we want to see the final output
probability<00:22:50.050><c> of</c><00:22:50.140><c> passing</c><00:22:50.530><c> this</c><00:22:50.650><c> class</c><00:22:50.710><c> and</c><00:22:51.310><c> we</c>

00:22:51.360 --> 00:22:51.370 align:start position:0%
probability of passing this class and we
 

00:22:51.370 --> 00:22:55.440 align:start position:0%
probability of passing this class and we
computed<00:22:51.790><c> as</c><00:22:51.940><c> 0.1</c><00:22:52.840><c> or</c><00:22:53.320><c> 10%</c><00:22:54.330><c> well</c><00:22:55.330><c> that's</c>

00:22:55.440 --> 00:22:55.450 align:start position:0%
computed as 0.1 or 10% well that's
 

00:22:55.450 --> 00:22:57.120 align:start position:0%
computed as 0.1 or 10% well that's
really<00:22:55.630><c> bad</c><00:22:55.780><c> news</c><00:22:56.020><c> because</c><00:22:56.530><c> actually</c><00:22:56.920><c> this</c>

00:22:57.120 --> 00:22:57.130 align:start position:0%
really bad news because actually this
 

00:22:57.130 --> 00:22:59.460 align:start position:0%
really bad news because actually this
person<00:22:57.340><c> did</c><00:22:57.640><c> pass</c><00:22:57.820><c> the</c><00:22:57.850><c> class</c><00:22:58.210><c> they</c><00:22:58.990><c> passed</c><00:22:59.290><c> it</c>

00:22:59.460 --> 00:22:59.470 align:start position:0%
person did pass the class they passed it
 

00:22:59.470 --> 00:23:03.030 align:start position:0%
person did pass the class they passed it
with<00:22:59.560><c> probability</c><00:23:00.070><c> one</c><00:23:01.290><c> now</c><00:23:02.290><c> can</c><00:23:02.680><c> anyone</c><00:23:02.890><c> tell</c>

00:23:03.030 --> 00:23:03.040 align:start position:0%
with probability one now can anyone tell
 

00:23:03.040 --> 00:23:06.030 align:start position:0%
with probability one now can anyone tell
me<00:23:03.250><c> why</c><00:23:03.550><c> the</c><00:23:03.610><c> neural</c><00:23:04.150><c> network</c><00:23:04.420><c> got</c><00:23:04.750><c> this</c><00:23:05.080><c> such</c>

00:23:06.030 --> 00:23:06.040 align:start position:0%
me why the neural network got this such
 

00:23:06.040 --> 00:23:10.940 align:start position:0%
me why the neural network got this such
so<00:23:06.400><c> wrong</c><00:23:06.640><c> why</c><00:23:06.940><c> I</c><00:23:06.970><c> do</c><00:23:07.300><c> this</c><00:23:07.680><c> yeah</c><00:23:08.680><c> it</c><00:23:08.740><c> is</c>

00:23:10.940 --> 00:23:10.950 align:start position:0%
 
 

00:23:10.950 --> 00:23:14.400 align:start position:0%
 
exactly<00:23:11.950><c> so</c><00:23:12.880><c> this</c><00:23:13.090><c> network</c><00:23:13.360><c> has</c><00:23:13.840><c> never</c><00:23:14.260><c> been</c>

00:23:14.400 --> 00:23:14.410 align:start position:0%
exactly so this network has never been
 

00:23:14.410 --> 00:23:16.890 align:start position:0%
exactly so this network has never been
trained<00:23:14.740><c> it's</c><00:23:14.980><c> never</c><00:23:15.190><c> seen</c><00:23:15.400><c> any</c><00:23:15.550><c> data</c><00:23:15.900><c> it's</c>

00:23:16.890 --> 00:23:16.900 align:start position:0%
trained it's never seen any data it's
 

00:23:16.900 --> 00:23:18.780 align:start position:0%
trained it's never seen any data it's
basically<00:23:17.320><c> like</c><00:23:17.440><c> a</c><00:23:17.560><c> baby</c><00:23:17.860><c> it's</c><00:23:18.250><c> never</c><00:23:18.520><c> learned</c>

00:23:18.780 --> 00:23:18.790 align:start position:0%
basically like a baby it's never learned
 

00:23:18.790 --> 00:23:21.030 align:start position:0%
basically like a baby it's never learned
anything<00:23:19.120><c> so</c><00:23:20.020><c> we</c><00:23:20.140><c> can't</c><00:23:20.290><c> expect</c><00:23:20.410><c> it</c><00:23:20.770><c> to</c><00:23:20.860><c> solve</c>

00:23:21.030 --> 00:23:21.040 align:start position:0%
anything so we can't expect it to solve
 

00:23:21.040 --> 00:23:24.000 align:start position:0%
anything so we can't expect it to solve
a<00:23:21.130><c> problem</c><00:23:21.460><c> and</c><00:23:21.550><c> knows</c><00:23:21.700><c> nothing</c><00:23:22.030><c> about</c><00:23:22.500><c> so</c><00:23:23.500><c> to</c>

00:23:24.000 --> 00:23:24.010 align:start position:0%
a problem and knows nothing about so to
 

00:23:24.010 --> 00:23:26.070 align:start position:0%
a problem and knows nothing about so to
do<00:23:24.340><c> this</c><00:23:24.550><c> to</c><00:23:25.210><c> tackle</c><00:23:25.600><c> this</c><00:23:25.690><c> problem</c><00:23:25.750><c> of</c>

00:23:26.070 --> 00:23:26.080 align:start position:0%
do this to tackle this problem of
 

00:23:26.080 --> 00:23:27.780 align:start position:0%
do this to tackle this problem of
training<00:23:26.530><c> a</c><00:23:26.590><c> neural</c><00:23:26.710><c> network</c><00:23:26.980><c> we</c><00:23:27.580><c> have</c><00:23:27.610><c> to</c>

00:23:27.780 --> 00:23:27.790 align:start position:0%
training a neural network we have to
 

00:23:27.790 --> 00:23:29.220 align:start position:0%
training a neural network we have to
first<00:23:28.000><c> define</c><00:23:28.180><c> a</c><00:23:28.360><c> couple</c><00:23:28.570><c> of</c><00:23:28.690><c> things</c><00:23:28.870><c> so</c><00:23:29.020><c> first</c>

00:23:29.220 --> 00:23:29.230 align:start position:0%
first define a couple of things so first
 

00:23:29.230 --> 00:23:32.310 align:start position:0%
first define a couple of things so first
we'll<00:23:29.410><c> talk</c><00:23:29.530><c> about</c><00:23:29.770><c> the</c><00:23:29.920><c> loss</c><00:23:30.750><c> the</c><00:23:31.750><c> loss</c><00:23:31.990><c> of</c><00:23:32.200><c> a</c>

00:23:32.310 --> 00:23:32.320 align:start position:0%
we'll talk about the loss the loss of a
 

00:23:32.320 --> 00:23:37.050 align:start position:0%
we'll talk about the loss the loss of a
network<00:23:34.320><c> basically</c><00:23:35.320><c> tells</c><00:23:35.620><c> our</c><00:23:36.010><c> algorithm</c><00:23:36.850><c> or</c>

00:23:37.050 --> 00:23:37.060 align:start position:0%
network basically tells our algorithm or
 

00:23:37.060 --> 00:23:41.070 align:start position:0%
network basically tells our algorithm or
our<00:23:37.510><c> model</c><00:23:38.130><c> how</c><00:23:39.130><c> wrong</c><00:23:40.120><c> our</c><00:23:40.450><c> predictions</c><00:23:40.930><c> are</c>

00:23:41.070 --> 00:23:41.080 align:start position:0%
our model how wrong our predictions are
 

00:23:41.080 --> 00:23:44.280 align:start position:0%
our model how wrong our predictions are
from<00:23:41.290><c> the</c><00:23:41.410><c> ground</c><00:23:41.560><c> truth</c><00:23:42.930><c> so</c><00:23:43.930><c> you</c><00:23:43.960><c> can</c><00:23:44.140><c> think</c>

00:23:44.280 --> 00:23:44.290 align:start position:0%
from the ground truth so you can think
 

00:23:44.290 --> 00:23:46.500 align:start position:0%
from the ground truth so you can think
of<00:23:44.320><c> this</c><00:23:44.500><c> as</c><00:23:44.650><c> a</c><00:23:44.710><c> distance</c><00:23:45.280><c> between</c><00:23:45.880><c> our</c>

00:23:46.500 --> 00:23:46.510 align:start position:0%
of this as a distance between our
 

00:23:46.510 --> 00:23:48.630 align:start position:0%
of this as a distance between our
predicted<00:23:47.380><c> output</c><00:23:47.710><c> and</c><00:23:47.920><c> our</c><00:23:48.070><c> actual</c><00:23:48.460><c> output</c>

00:23:48.630 --> 00:23:48.640 align:start position:0%
predicted output and our actual output
 

00:23:48.640 --> 00:23:51.150 align:start position:0%
predicted output and our actual output
if<00:23:49.120><c> the</c><00:23:49.510><c> two</c><00:23:49.810><c> are</c><00:23:49.900><c> very</c><00:23:49.930><c> close</c><00:23:50.410><c> if</c><00:23:50.620><c> we</c><00:23:50.650><c> predict</c>

00:23:51.150 --> 00:23:51.160 align:start position:0%
if the two are very close if we predict
 

00:23:51.160 --> 00:23:52.680 align:start position:0%
if the two are very close if we predict
something<00:23:51.400><c> that</c><00:23:51.700><c> is</c><00:23:51.820><c> very</c><00:23:52.000><c> close</c><00:23:52.240><c> to</c><00:23:52.390><c> the</c><00:23:52.510><c> true</c>

00:23:52.680 --> 00:23:52.690 align:start position:0%
something that is very close to the true
 

00:23:52.690 --> 00:23:56.130 align:start position:0%
something that is very close to the true
output<00:23:52.900><c> our</c><00:23:53.590><c> loss</c><00:23:53.860><c> is</c><00:23:53.890><c> very</c><00:23:54.130><c> low</c><00:23:54.540><c> if</c><00:23:55.540><c> we</c>

00:23:56.130 --> 00:23:56.140 align:start position:0%
output our loss is very low if we
 

00:23:56.140 --> 00:23:58.680 align:start position:0%
output our loss is very low if we
predict<00:23:56.530><c> something</c><00:23:56.710><c> that</c><00:23:56.950><c> is</c><00:23:57.010><c> very</c><00:23:57.130><c> far</c><00:23:57.520><c> in</c><00:23:58.510><c> a</c>

00:23:58.680 --> 00:23:58.690 align:start position:0%
predict something that is very far in a
 

00:23:58.690 --> 00:24:01.220 align:start position:0%
predict something that is very far in a
high-level<00:23:59.110><c> sense</c><00:23:59.620><c> far</c><00:23:59.920><c> like</c><00:24:00.190><c> in</c><00:24:00.310><c> distance</c>

00:24:01.220 --> 00:24:01.230 align:start position:0%
high-level sense far like in distance
 

00:24:01.230 --> 00:24:03.870 align:start position:0%
high-level sense far like in distance
then<00:24:02.230><c> our</c><00:24:02.380><c> loss</c><00:24:02.770><c> is</c><00:24:03.010><c> very</c><00:24:03.040><c> high</c><00:24:03.400><c> and</c><00:24:03.610><c> we</c><00:24:03.670><c> want</c>

00:24:03.870 --> 00:24:03.880 align:start position:0%
then our loss is very high and we want
 

00:24:03.880 --> 00:24:05.580 align:start position:0%
then our loss is very high and we want
to<00:24:03.970><c> minimize</c><00:24:04.150><c> this</c><00:24:04.600><c> from</c><00:24:04.930><c> happening</c><00:24:05.350><c> as</c><00:24:05.530><c> much</c>

00:24:05.580 --> 00:24:05.590 align:start position:0%
to minimize this from happening as much
 

00:24:05.590 --> 00:24:08.520 align:start position:0%
to minimize this from happening as much
as<00:24:05.950><c> possible</c><00:24:06.810><c> now</c><00:24:07.810><c> let's</c><00:24:07.990><c> assume</c><00:24:08.230><c> we're</c><00:24:08.410><c> not</c>

00:24:08.520 --> 00:24:08.530 align:start position:0%
as possible now let's assume we're not
 

00:24:08.530 --> 00:24:10.290 align:start position:0%
as possible now let's assume we're not
given<00:24:08.770><c> just</c><00:24:08.950><c> one</c><00:24:09.130><c> data</c><00:24:09.370><c> point</c><00:24:09.640><c> one</c><00:24:09.820><c> student</c>

00:24:10.290 --> 00:24:10.300 align:start position:0%
given just one data point one student
 

00:24:10.300 --> 00:24:11.550 align:start position:0%
given just one data point one student
but<00:24:10.450><c> we're</c><00:24:10.600><c> given</c><00:24:10.840><c> a</c><00:24:10.900><c> whole</c><00:24:11.080><c> class</c><00:24:11.380><c> of</c>

00:24:11.550 --> 00:24:11.560 align:start position:0%
but we're given a whole class of
 

00:24:11.560 --> 00:24:13.890 align:start position:0%
but we're given a whole class of
students<00:24:12.040><c> so</c><00:24:12.670><c> as</c><00:24:12.820><c> previous</c><00:24:13.270><c> data</c><00:24:13.480><c> I</c><00:24:13.570><c> used</c><00:24:13.750><c> this</c>

00:24:13.890 --> 00:24:13.900 align:start position:0%
students so as previous data I used this
 

00:24:13.900 --> 00:24:16.500 align:start position:0%
students so as previous data I used this
entire<00:24:14.260><c> class</c><00:24:14.530><c> from</c><00:24:15.160><c> last</c><00:24:15.400><c> year</c><00:24:15.730><c> and</c><00:24:15.910><c> if</c><00:24:16.420><c> we</c>

00:24:16.500 --> 00:24:16.510 align:start position:0%
entire class from last year and if we
 

00:24:16.510 --> 00:24:17.730 align:start position:0%
entire class from last year and if we
want<00:24:16.690><c> to</c><00:24:16.750><c> quantify</c><00:24:17.080><c> what's</c><00:24:17.440><c> called</c><00:24:17.620><c> the</c>

00:24:17.730 --> 00:24:17.740 align:start position:0%
want to quantify what's called the
 

00:24:17.740 --> 00:24:18.890 align:start position:0%
want to quantify what's called the
empirical<00:24:18.310><c> loss</c>

00:24:18.890 --> 00:24:18.900 align:start position:0%
empirical loss
 

00:24:18.900 --> 00:24:21.360 align:start position:0%
empirical loss
now<00:24:19.900><c> we</c><00:24:19.960><c> care</c><00:24:20.380><c> about</c><00:24:20.470><c> how</c><00:24:20.650><c> the</c><00:24:20.710><c> model</c><00:24:21.040><c> did</c><00:24:21.160><c> on</c>

00:24:21.360 --> 00:24:21.370 align:start position:0%
now we care about how the model did on
 

00:24:21.370 --> 00:24:23.580 align:start position:0%
now we care about how the model did on
average<00:24:21.940><c> over</c><00:24:22.120><c> the</c><00:24:22.420><c> entire</c><00:24:22.720><c> data</c><00:24:22.990><c> set</c><00:24:23.230><c> not</c><00:24:23.380><c> for</c>

00:24:23.580 --> 00:24:23.590 align:start position:0%
average over the entire data set not for
 

00:24:23.590 --> 00:24:25.050 align:start position:0%
average over the entire data set not for
just<00:24:23.740><c> a</c><00:24:23.800><c> single</c><00:24:23.980><c> student</c><00:24:24.460><c> but</c><00:24:24.700><c> across</c><00:24:24.850><c> the</c>

00:24:25.050 --> 00:24:25.060 align:start position:0%
just a single student but across the
 

00:24:25.060 --> 00:24:26.430 align:start position:0%
just a single student but across the
entire<00:24:25.120><c> data</c><00:24:25.540><c> set</c><00:24:25.720><c> and</c><00:24:25.810><c> how</c><00:24:25.930><c> we</c><00:24:25.990><c> do</c><00:24:26.170><c> that</c><00:24:26.320><c> is</c>

00:24:26.430 --> 00:24:26.440 align:start position:0%
entire data set and how we do that is
 

00:24:26.440 --> 00:24:27.900 align:start position:0%
entire data set and how we do that is
very<00:24:26.590><c> simple</c><00:24:26.710><c> we</c><00:24:27.040><c> just</c><00:24:27.220><c> take</c><00:24:27.340><c> the</c><00:24:27.460><c> average</c><00:24:27.790><c> of</c>

00:24:27.900 --> 00:24:27.910 align:start position:0%
very simple we just take the average of
 

00:24:27.910 --> 00:24:30.420 align:start position:0%
very simple we just take the average of
the<00:24:28.030><c> loss</c><00:24:28.210><c> of</c><00:24:28.450><c> each</c><00:24:28.810><c> data</c><00:24:29.080><c> point</c><00:24:29.140><c> if</c><00:24:30.070><c> we</c><00:24:30.160><c> have</c><00:24:30.250><c> n</c>

00:24:30.420 --> 00:24:30.430 align:start position:0%
the loss of each data point if we have n
 

00:24:30.430 --> 00:24:31.620 align:start position:0%
the loss of each data point if we have n
students<00:24:31.030><c> it's</c><00:24:31.420><c> the</c>

00:24:31.620 --> 00:24:31.630 align:start position:0%
students it's the
 

00:24:31.630 --> 00:24:35.010 align:start position:0%
students it's the
average<00:24:32.020><c> over</c><00:24:32.380><c> end</c><00:24:32.590><c> data</c><00:24:33.070><c> points</c><00:24:33.840><c> this</c><00:24:34.840><c> has</c>

00:24:35.010 --> 00:24:35.020 align:start position:0%
average over end data points this has
 

00:24:35.020 --> 00:24:36.570 align:start position:0%
average over end data points this has
other<00:24:35.230><c> names</c><00:24:35.500><c> besides</c><00:24:35.920><c> empirical</c><00:24:36.340><c> law</c>

00:24:36.570 --> 00:24:36.580 align:start position:0%
other names besides empirical law
 

00:24:36.580 --> 00:24:37.710 align:start position:0%
other names besides empirical law
sometimes<00:24:36.970><c> people</c><00:24:37.270><c> call</c><00:24:37.390><c> it</c><00:24:37.480><c> the</c><00:24:37.570><c> objective</c>

00:24:37.710 --> 00:24:37.720 align:start position:0%
sometimes people call it the objective
 

00:24:37.720 --> 00:24:42.210 align:start position:0%
sometimes people call it the objective
function<00:24:38.440><c> the</c><00:24:38.950><c> cost</c><00:24:39.220><c> function</c><00:24:39.490><c> etc</c><00:24:41.130><c> all</c><00:24:42.130><c> of</c>

00:24:42.210 --> 00:24:42.220 align:start position:0%
function the cost function etc all of
 

00:24:42.220 --> 00:24:43.620 align:start position:0%
function the cost function etc all of
these<00:24:42.490><c> terms</c><00:24:42.820><c> are</c><00:24:42.970><c> completely</c><00:24:43.450><c> the</c><00:24:43.510><c> same</c>

00:24:43.620 --> 00:24:43.630 align:start position:0%
these terms are completely the same
 

00:24:43.630 --> 00:24:46.800 align:start position:0%
these terms are completely the same
thing<00:24:44.850><c> now</c><00:24:45.850><c> if</c><00:24:45.970><c> we</c><00:24:46.060><c> look</c><00:24:46.180><c> at</c><00:24:46.270><c> the</c><00:24:46.390><c> problem</c><00:24:46.720><c> of</c>

00:24:46.800 --> 00:24:46.810 align:start position:0%
thing now if we look at the problem of
 

00:24:46.810 --> 00:24:48.600 align:start position:0%
thing now if we look at the problem of
binary<00:24:47.200><c> classification</c><00:24:47.590><c> predicting</c><00:24:48.430><c> if</c><00:24:48.520><c> you</c>

00:24:48.600 --> 00:24:48.610 align:start position:0%
binary classification predicting if you
 

00:24:48.610 --> 00:24:52.190 align:start position:0%
binary classification predicting if you
pass<00:24:48.880><c> or</c><00:24:49.150><c> fail</c><00:24:49.180><c> this</c><00:24:49.480><c> class</c><00:24:49.660><c> yes</c><00:24:50.050><c> or</c><00:24:50.200><c> no</c><00:24:50.380><c> 1</c><00:24:50.980><c> or</c><00:24:51.160><c> 0</c>

00:24:52.190 --> 00:24:52.200 align:start position:0%
pass or fail this class yes or no 1 or 0
 

00:24:52.200 --> 00:24:54.540 align:start position:0%
pass or fail this class yes or no 1 or 0
we<00:24:53.200><c> can</c><00:24:53.350><c> actually</c><00:24:53.650><c> use</c><00:24:53.830><c> something</c><00:24:54.100><c> that's</c>

00:24:54.540 --> 00:24:54.550 align:start position:0%
we can actually use something that's
 

00:24:54.550 --> 00:24:57.440 align:start position:0%
we can actually use something that's
called<00:24:54.760><c> the</c><00:24:54.940><c> softmax</c><00:24:55.360><c> cross</c><00:24:55.870><c> entropy</c><00:24:56.110><c> loss</c>

00:24:57.440 --> 00:24:57.450 align:start position:0%
called the softmax cross entropy loss
 

00:24:57.450 --> 00:24:59.430 align:start position:0%
called the softmax cross entropy loss
now<00:24:58.450><c> for</c><00:24:58.660><c> those</c><00:24:58.810><c> of</c><00:24:58.870><c> you</c><00:24:59.050><c> who</c><00:24:59.200><c> aren't</c><00:24:59.350><c> familiar</c>

00:24:59.430 --> 00:24:59.440 align:start position:0%
now for those of you who aren't familiar
 

00:24:59.440 --> 00:25:02.070 align:start position:0%
now for those of you who aren't familiar
with<00:24:59.890><c> cross</c><00:25:00.220><c> entropy</c><00:25:00.430><c> or</c><00:25:00.910><c> entropy</c><00:25:01.270><c> this</c><00:25:01.930><c> is</c><00:25:02.050><c> a</c>

00:25:02.070 --> 00:25:02.080 align:start position:0%
with cross entropy or entropy this is a
 

00:25:02.080 --> 00:25:04.650 align:start position:0%
with cross entropy or entropy this is a
extremely<00:25:03.060><c> powerful</c><00:25:04.060><c> notion</c><00:25:04.270><c> that</c><00:25:04.540><c> was</c>

00:25:04.650 --> 00:25:04.660 align:start position:0%
extremely powerful notion that was
 

00:25:04.660 --> 00:25:06.630 align:start position:0%
extremely powerful notion that was
actually<00:25:04.930><c> developed</c><00:25:05.350><c> or</c><00:25:06.010><c> first</c><00:25:06.220><c> introduced</c>

00:25:06.630 --> 00:25:06.640 align:start position:0%
actually developed or first introduced
 

00:25:06.640 --> 00:25:11.040 align:start position:0%
actually developed or first introduced
here<00:25:06.880><c> at</c><00:25:06.970><c> MIT</c><00:25:07.500><c> over</c><00:25:08.500><c> 50</c><00:25:08.830><c> years</c><00:25:09.010><c> ago</c><00:25:09.190><c> by</c><00:25:10.050><c> Claude</c>

00:25:11.040 --> 00:25:11.050 align:start position:0%
here at MIT over 50 years ago by Claude
 

00:25:11.050 --> 00:25:14.790 align:start position:0%
here at MIT over 50 years ago by Claude
Shannon<00:25:11.970><c> and</c><00:25:12.970><c> his</c><00:25:13.090><c> master's</c><00:25:13.570><c> thesis</c><00:25:13.710><c> like</c><00:25:14.710><c> I</c>

00:25:14.790 --> 00:25:14.800 align:start position:0%
Shannon and his master's thesis like I
 

00:25:14.800 --> 00:25:17.130 align:start position:0%
Shannon and his master's thesis like I
said<00:25:14.950><c> this</c><00:25:15.040><c> was</c><00:25:15.220><c> 50</c><00:25:15.520><c> years</c><00:25:15.700><c> ago</c><00:25:15.850><c> it's</c><00:25:16.150><c> huge</c><00:25:16.930><c> in</c>

00:25:17.130 --> 00:25:17.140 align:start position:0%
said this was 50 years ago it's huge in
 

00:25:17.140 --> 00:25:18.810 align:start position:0%
said this was 50 years ago it's huge in
the<00:25:17.230><c> field</c><00:25:17.440><c> of</c><00:25:17.710><c> signal</c><00:25:18.460><c> processing</c>

00:25:18.810 --> 00:25:18.820 align:start position:0%
the field of signal processing
 

00:25:18.820 --> 00:25:21.300 align:start position:0%
the field of signal processing
thermodynamics<00:25:19.540><c> really</c><00:25:20.410><c> all</c><00:25:20.590><c> over</c><00:25:20.920><c> computer</c>

00:25:21.300 --> 00:25:21.310 align:start position:0%
thermodynamics really all over computer
 

00:25:21.310 --> 00:25:23.690 align:start position:0%
thermodynamics really all over computer
science<00:25:21.640><c> that</c><00:25:21.760><c> seen</c><00:25:22.000><c> in</c><00:25:22.180><c> information</c><00:25:22.780><c> theory</c>

00:25:23.690 --> 00:25:23.700 align:start position:0%
science that seen in information theory
 

00:25:23.700 --> 00:25:26.940 align:start position:0%
science that seen in information theory
now<00:25:24.730><c> instead</c><00:25:25.330><c> of</c><00:25:25.480><c> predicting</c><00:25:26.170><c> a</c><00:25:26.380><c> single</c><00:25:26.770><c> one</c>

00:25:26.940 --> 00:25:26.950 align:start position:0%
now instead of predicting a single one
 

00:25:26.950 --> 00:25:28.920 align:start position:0%
now instead of predicting a single one
or<00:25:26.980><c> zero</c><00:25:27.400><c> output</c><00:25:27.700><c> yes</c><00:25:28.060><c> or</c><00:25:28.210><c> no</c><00:25:28.360><c> let's</c><00:25:28.690><c> suppose</c>

00:25:28.920 --> 00:25:28.930 align:start position:0%
or zero output yes or no let's suppose
 

00:25:28.930 --> 00:25:32.100 align:start position:0%
or zero output yes or no let's suppose
we<00:25:29.080><c> want</c><00:25:29.260><c> to</c><00:25:29.290><c> predict</c><00:25:29.710><c> a</c><00:25:30.420><c> continuous</c><00:25:31.420><c> valued</c>

00:25:32.100 --> 00:25:32.110 align:start position:0%
we want to predict a continuous valued
 

00:25:32.110 --> 00:25:34.740 align:start position:0%
we want to predict a continuous valued
function<00:25:32.500><c> not</c><00:25:33.070><c> will</c><00:25:33.340><c> I</c><00:25:33.370><c> pass</c><00:25:33.670><c> this</c><00:25:33.880><c> class</c><00:25:34.150><c> but</c>

00:25:34.740 --> 00:25:34.750 align:start position:0%
function not will I pass this class but
 

00:25:34.750 --> 00:25:36.390 align:start position:0%
function not will I pass this class but
what's<00:25:34.960><c> the</c><00:25:35.140><c> grade</c><00:25:35.380><c> that</c><00:25:35.590><c> I</c><00:25:35.650><c> will</c><00:25:35.890><c> get</c><00:25:36.100><c> and</c>

00:25:36.390 --> 00:25:36.400 align:start position:0%
what's the grade that I will get and
 

00:25:36.400 --> 00:25:39.060 align:start position:0%
what's the grade that I will get and
then<00:25:37.240><c> as</c><00:25:37.330><c> a</c><00:25:37.360><c> percentage</c><00:25:37.870><c> let's</c><00:25:38.080><c> say</c><00:25:38.260><c> 0</c><00:25:38.560><c> to</c><00:25:38.740><c> 100</c>

00:25:39.060 --> 00:25:39.070 align:start position:0%
then as a percentage let's say 0 to 100
 

00:25:39.070 --> 00:25:40.860 align:start position:0%
then as a percentage let's say 0 to 100
now<00:25:39.190><c> we're</c><00:25:39.340><c> no</c><00:25:39.460><c> longer</c><00:25:39.610><c> limited</c><00:25:39.970><c> to</c><00:25:40.450><c> 0</c><00:25:40.660><c> to</c><00:25:40.840><c> 1</c>

00:25:40.860 --> 00:25:40.870 align:start position:0%
now we're no longer limited to 0 to 1
 

00:25:40.870 --> 00:25:42.930 align:start position:0%
now we're no longer limited to 0 to 1
but<00:25:41.530><c> can't</c><00:25:41.710><c> actually</c><00:25:41.860><c> output</c><00:25:42.310><c> any</c><00:25:42.550><c> real</c>

00:25:42.930 --> 00:25:42.940 align:start position:0%
but can't actually output any real
 

00:25:42.940 --> 00:25:46.050 align:start position:0%
but can't actually output any real
number<00:25:43.270><c> on</c><00:25:43.390><c> the</c><00:25:43.540><c> number</c><00:25:43.810><c> line</c><00:25:44.550><c> now</c><00:25:45.550><c> instead</c><00:25:46.000><c> of</c>

00:25:46.050 --> 00:25:46.060 align:start position:0%
number on the number line now instead of
 

00:25:46.060 --> 00:25:47.640 align:start position:0%
number on the number line now instead of
using<00:25:46.240><c> cross</c><00:25:46.540><c> entropy</c><00:25:46.750><c> we</c><00:25:47.140><c> might</c><00:25:47.320><c> want</c><00:25:47.530><c> to</c><00:25:47.590><c> use</c>

00:25:47.640 --> 00:25:47.650 align:start position:0%
using cross entropy we might want to use
 

00:25:47.650 --> 00:25:49.500 align:start position:0%
using cross entropy we might want to use
a<00:25:47.800><c> different</c><00:25:48.040><c> loss</c><00:25:48.370><c> and</c><00:25:48.790><c> for</c><00:25:49.150><c> this</c><00:25:49.270><c> let's</c>

00:25:49.500 --> 00:25:49.510 align:start position:0%
a different loss and for this let's
 

00:25:49.510 --> 00:25:50.790 align:start position:0%
a different loss and for this let's
think<00:25:49.660><c> of</c><00:25:49.810><c> something</c><00:25:50.020><c> like</c><00:25:50.200><c> a</c><00:25:50.260><c> mean</c><00:25:50.530><c> squared</c>

00:25:50.790 --> 00:25:50.800 align:start position:0%
think of something like a mean squared
 

00:25:50.800 --> 00:25:53.010 align:start position:0%
think of something like a mean squared
error<00:25:51.010><c> loss</c><00:25:51.070><c> whereas</c><00:25:52.060><c> your</c><00:25:52.330><c> predicted</c><00:25:52.840><c> and</c>

00:25:53.010 --> 00:25:53.020 align:start position:0%
error loss whereas your predicted and
 

00:25:53.020 --> 00:25:54.750 align:start position:0%
error loss whereas your predicted and
your<00:25:53.170><c> true</c><00:25:53.470><c> output</c><00:25:53.680><c> diverged</c><00:25:54.460><c> from</c><00:25:54.640><c> each</c>

00:25:54.750 --> 00:25:54.760 align:start position:0%
your true output diverged from each
 

00:25:54.760 --> 00:25:57.720 align:start position:0%
your true output diverged from each
other<00:25:54.940><c> the</c><00:25:55.780><c> loss</c><00:25:56.020><c> increases</c><00:25:56.650><c> as</c><00:25:57.010><c> a</c><00:25:57.040><c> quadratic</c>

00:25:57.720 --> 00:25:57.730 align:start position:0%
other the loss increases as a quadratic
 

00:25:57.730 --> 00:26:03.540 align:start position:0%
other the loss increases as a quadratic
function<00:26:00.360><c> ok</c><00:26:01.360><c> great</c><00:26:01.570><c> so</c><00:26:02.140><c> now</c><00:26:02.260><c> let's</c><00:26:03.220><c> put</c><00:26:03.400><c> this</c>

00:26:03.540 --> 00:26:03.550 align:start position:0%
function ok great so now let's put this
 

00:26:03.550 --> 00:26:05.790 align:start position:0%
function ok great so now let's put this
new<00:26:03.730><c> loss</c><00:26:03.940><c> information</c><00:26:04.240><c> to</c><00:26:05.230><c> the</c><00:26:05.350><c> test</c><00:26:05.590><c> and</c>

00:26:05.790 --> 00:26:05.800 align:start position:0%
new loss information to the test and
 

00:26:05.800 --> 00:26:07.620 align:start position:0%
new loss information to the test and
actually<00:26:05.860><c> learn</c><00:26:06.220><c> how</c><00:26:06.250><c> we</c><00:26:06.490><c> can</c><00:26:06.760><c> train</c><00:26:07.360><c> a</c><00:26:07.390><c> neural</c>

00:26:07.620 --> 00:26:07.630 align:start position:0%
actually learn how we can train a neural
 

00:26:07.630 --> 00:26:12.690 align:start position:0%
actually learn how we can train a neural
network<00:26:07.900><c> by</c><00:26:08.410><c> quantifying</c><00:26:08.950><c> its</c><00:26:09.280><c> loss</c><00:26:11.700><c> and</c>

00:26:12.690 --> 00:26:12.700 align:start position:0%
network by quantifying its loss and
 

00:26:12.700 --> 00:26:15.090 align:start position:0%
network by quantifying its loss and
really<00:26:12.940><c> if</c><00:26:13.030><c> we</c><00:26:13.180><c> go</c><00:26:13.600><c> back</c><00:26:13.810><c> to</c><00:26:13.990><c> what</c><00:26:14.350><c> the</c><00:26:14.590><c> loss</c><00:26:14.770><c> is</c>

00:26:15.090 --> 00:26:15.100 align:start position:0%
really if we go back to what the loss is
 

00:26:15.100 --> 00:26:17.760 align:start position:0%
really if we go back to what the loss is
at<00:26:15.460><c> the</c><00:26:15.670><c> very</c><00:26:16.000><c> high</c><00:26:16.180><c> level</c><00:26:16.210><c> the</c><00:26:16.990><c> loss</c><00:26:17.170><c> tells</c><00:26:17.530><c> us</c>

00:26:17.760 --> 00:26:17.770 align:start position:0%
at the very high level the loss tells us
 

00:26:17.770 --> 00:26:20.970 align:start position:0%
at the very high level the loss tells us
how<00:26:18.730><c> the</c><00:26:18.790><c> network</c><00:26:19.270><c> is</c><00:26:19.420><c> performing</c><00:26:19.570><c> right</c><00:26:20.080><c> that</c>

00:26:20.970 --> 00:26:20.980 align:start position:0%
how the network is performing right that
 

00:26:20.980 --> 00:26:22.830 align:start position:0%
how the network is performing right that
loss<00:26:21.220><c> tells</c><00:26:21.520><c> us</c><00:26:21.730><c> the</c><00:26:22.030><c> accuracy</c><00:26:22.600><c> of</c><00:26:22.630><c> the</c>

00:26:22.830 --> 00:26:22.840 align:start position:0%
loss tells us the accuracy of the
 

00:26:22.840 --> 00:26:25.290 align:start position:0%
loss tells us the accuracy of the
network<00:26:23.170><c> on</c><00:26:23.350><c> a</c><00:26:23.380><c> set</c><00:26:23.650><c> of</c><00:26:23.680><c> examples</c><00:26:24.130><c> and</c><00:26:24.670><c> what</c><00:26:25.180><c> we</c>

00:26:25.290 --> 00:26:25.300 align:start position:0%
network on a set of examples and what we
 

00:26:25.300 --> 00:26:27.600 align:start position:0%
network on a set of examples and what we
want<00:26:25.450><c> to</c><00:26:25.570><c> do</c><00:26:25.690><c> is</c><00:26:25.870><c> basically</c><00:26:25.990><c> minimize</c><00:26:26.800><c> the</c>

00:26:27.600 --> 00:26:27.610 align:start position:0%
want to do is basically minimize the
 

00:26:27.610 --> 00:26:31.770 align:start position:0%
want to do is basically minimize the
loss<00:26:27.850><c> over</c><00:26:28.420><c> our</c><00:26:28.570><c> entire</c><00:26:28.720><c> training</c><00:26:29.230><c> set</c><00:26:30.780><c> really</c>

00:26:31.770 --> 00:26:31.780 align:start position:0%
loss over our entire training set really
 

00:26:31.780 --> 00:26:34.110 align:start position:0%
loss over our entire training set really
we<00:26:31.960><c> want</c><00:26:32.170><c> to</c><00:26:32.320><c> find</c><00:26:32.680><c> the</c><00:26:33.610><c> set</c><00:26:33.820><c> of</c><00:26:33.940><c> parameters</c>

00:26:34.110 --> 00:26:34.120 align:start position:0%
we want to find the set of parameters
 

00:26:34.120 --> 00:26:37.410 align:start position:0%
we want to find the set of parameters
theta<00:26:34.830><c> such</c><00:26:35.830><c> that</c><00:26:35.860><c> that</c><00:26:36.220><c> loss</c><00:26:36.550><c> J</c><00:26:37.270><c> of</c><00:26:37.390><c> theta</c>

00:26:37.410 --> 00:26:37.420 align:start position:0%
theta such that that loss J of theta
 

00:26:37.420 --> 00:26:41.040 align:start position:0%
theta such that that loss J of theta
that's<00:26:38.050><c> our</c><00:26:38.170><c> empirical</c><00:26:38.560><c> loss</c><00:26:38.860><c> is</c><00:26:39.160><c> minimum</c><00:26:40.060><c> so</c>

00:26:41.040 --> 00:26:41.050 align:start position:0%
that's our empirical loss is minimum so
 

00:26:41.050 --> 00:26:43.470 align:start position:0%
that's our empirical loss is minimum so
remember<00:26:41.440><c> J</c><00:26:41.680><c> of</c><00:26:41.800><c> theta</c><00:26:41.830><c> takes</c><00:26:42.760><c> as</c><00:26:42.970><c> input</c><00:26:43.270><c> theta</c>

00:26:43.470 --> 00:26:43.480 align:start position:0%
remember J of theta takes as input theta
 

00:26:43.480 --> 00:26:45.450 align:start position:0%
remember J of theta takes as input theta
and<00:26:43.870><c> theta</c><00:26:44.530><c> is</c><00:26:44.710><c> just</c><00:26:44.770><c> our</c><00:26:45.040><c> weight</c>

00:26:45.450 --> 00:26:45.460 align:start position:0%
and theta is just our weight
 

00:26:45.460 --> 00:26:46.950 align:start position:0%
and theta is just our weight
so<00:26:45.909><c> these</c><00:26:46.059><c> are</c><00:26:46.210><c> the</c><00:26:46.330><c> things</c><00:26:46.510><c> that</c><00:26:46.570><c> actually</c>

00:26:46.950 --> 00:26:46.960 align:start position:0%
so these are the things that actually
 

00:26:46.960 --> 00:26:55.169 align:start position:0%
so these are the things that actually
define<00:26:47.350><c> our</c><00:26:47.620><c> network</c><00:26:53.010><c> remember</c><00:26:54.010><c> that</c><00:26:54.940><c> the</c>

00:26:55.169 --> 00:26:55.179 align:start position:0%
define our network remember that the
 

00:26:55.179 --> 00:26:57.210 align:start position:0%
define our network remember that the
loss<00:26:55.330><c> is</c><00:26:55.510><c> just</c><00:26:55.539><c> a</c><00:26:55.960><c> function</c><00:26:56.620><c> of</c><00:26:56.740><c> these</c><00:26:56.890><c> weights</c>

00:26:57.210 --> 00:26:57.220 align:start position:0%
loss is just a function of these weights
 

00:26:57.220 --> 00:27:00.810 align:start position:0%
loss is just a function of these weights
if<00:26:57.580><c> we</c><00:26:58.450><c> want</c><00:26:58.720><c> to</c><00:26:59.679><c> think</c><00:27:00.070><c> about</c><00:27:00.220><c> the</c><00:27:00.399><c> process</c><00:27:00.760><c> of</c>

00:27:00.810 --> 00:27:00.820 align:start position:0%
if we want to think about the process of
 

00:27:00.820 --> 00:27:03.570 align:start position:0%
if we want to think about the process of
training<00:27:01.289><c> we</c><00:27:02.289><c> can</c><00:27:02.440><c> imagine</c><00:27:02.620><c> this</c><00:27:02.919><c> landscape</c>

00:27:03.570 --> 00:27:03.580 align:start position:0%
training we can imagine this landscape
 

00:27:03.580 --> 00:27:05.220 align:start position:0%
training we can imagine this landscape
so<00:27:03.909><c> if</c><00:27:04.000><c> we</c><00:27:04.090><c> only</c><00:27:04.210><c> have</c><00:27:04.390><c> two</c><00:27:04.630><c> weights</c><00:27:04.870><c> we</c><00:27:05.080><c> can</c>

00:27:05.220 --> 00:27:05.230 align:start position:0%
so if we only have two weights we can
 

00:27:05.230 --> 00:27:08.370 align:start position:0%
so if we only have two weights we can
plot<00:27:05.409><c> this</c><00:27:05.649><c> nice</c><00:27:05.830><c> diagram</c><00:27:06.309><c> like</c><00:27:06.429><c> this</c><00:27:07.380><c> theta</c>

00:27:08.370 --> 00:27:08.380 align:start position:0%
plot this nice diagram like this theta
 

00:27:08.380 --> 00:27:10.080 align:start position:0%
plot this nice diagram like this theta
zero<00:27:08.740><c> and</c><00:27:08.799><c> theta</c><00:27:09.010><c> one</c><00:27:09.250><c> are</c><00:27:09.580><c> our</c><00:27:09.700><c> two</c><00:27:09.850><c> weights</c>

00:27:10.080 --> 00:27:10.090 align:start position:0%
zero and theta one are our two weights
 

00:27:10.090 --> 00:27:11.789 align:start position:0%
zero and theta one are our two weights
they're<00:27:10.570><c> on</c><00:27:10.659><c> the</c><00:27:10.840><c> four</c><00:27:11.260><c> they're</c><00:27:11.559><c> on</c><00:27:11.649><c> the</c>

00:27:11.789 --> 00:27:11.799 align:start position:0%
they're on the four they're on the
 

00:27:11.799 --> 00:27:14.310 align:start position:0%
they're on the four they're on the
planar<00:27:12.220><c> axis</c><00:27:12.610><c> on</c><00:27:12.730><c> the</c><00:27:12.820><c> bottom</c><00:27:13.140><c> J</c><00:27:14.140><c> of</c><00:27:14.289><c> theta</c>

00:27:14.310 --> 00:27:14.320 align:start position:0%
planar axis on the bottom J of theta
 

00:27:14.320 --> 00:27:17.909 align:start position:0%
planar axis on the bottom J of theta
zero<00:27:14.649><c> and</c><00:27:14.919><c> theta</c><00:27:15.039><c> one</c><00:27:15.309><c> are</c><00:27:15.760><c> plotted</c><00:27:16.270><c> on</c><00:27:16.390><c> the</c><00:27:16.919><c> z</c>

00:27:17.909 --> 00:27:17.919 align:start position:0%
zero and theta one are plotted on the z
 

00:27:17.919 --> 00:27:21.000 align:start position:0%
zero and theta one are plotted on the z
axis<00:27:19.169><c> what</c><00:27:20.169><c> we</c><00:27:20.289><c> want</c><00:27:20.470><c> to</c><00:27:20.559><c> do</c><00:27:20.740><c> is</c><00:27:20.860><c> basically</c>

00:27:21.000 --> 00:27:21.010 align:start position:0%
axis what we want to do is basically
 

00:27:21.010 --> 00:27:23.460 align:start position:0%
axis what we want to do is basically
find<00:27:21.610><c> the</c><00:27:21.820><c> minimum</c><00:27:22.240><c> of</c><00:27:22.390><c> this</c><00:27:22.750><c> loss</c><00:27:22.990><c> of</c><00:27:23.260><c> this</c>

00:27:23.460 --> 00:27:23.470 align:start position:0%
find the minimum of this loss of this
 

00:27:23.470 --> 00:27:25.350 align:start position:0%
find the minimum of this loss of this
landscape<00:27:23.799><c> if</c><00:27:24.190><c> we</c><00:27:24.580><c> can</c><00:27:24.700><c> find</c><00:27:24.909><c> the</c><00:27:25.000><c> minimum</c>

00:27:25.350 --> 00:27:25.360 align:start position:0%
landscape if we can find the minimum
 

00:27:25.360 --> 00:27:28.110 align:start position:0%
landscape if we can find the minimum
then<00:27:25.570><c> this</c><00:27:25.750><c> tells</c><00:27:25.990><c> us</c><00:27:26.230><c> where</c><00:27:26.470><c> our</c><00:27:26.500><c> loss</c><00:27:26.890><c> is</c><00:27:27.279><c> the</c>

00:27:28.110 --> 00:27:28.120 align:start position:0%
then this tells us where our loss is the
 

00:27:28.120 --> 00:27:30.600 align:start position:0%
then this tells us where our loss is the
smallest<00:27:28.419><c> and</c><00:27:28.809><c> this</c><00:27:28.899><c> tells</c><00:27:29.169><c> us</c><00:27:29.380><c> where</c><00:27:30.100><c> theta</c>

00:27:30.600 --> 00:27:30.610 align:start position:0%
smallest and this tells us where theta
 

00:27:30.610 --> 00:27:33.210 align:start position:0%
smallest and this tells us where theta
want<00:27:30.970><c> with</c><00:27:31.179><c> where</c><00:27:31.419><c> or</c><00:27:31.960><c> what</c><00:27:32.230><c> values</c><00:27:32.679><c> of</c><00:27:32.710><c> theta</c>

00:27:33.210 --> 00:27:33.220 align:start position:0%
want with where or what values of theta
 

00:27:33.220 --> 00:27:35.639 align:start position:0%
want with where or what values of theta
zero<00:27:33.549><c> and</c><00:27:33.669><c> theta</c><00:27:33.880><c> one</c><00:27:34.149><c> we</c><00:27:34.720><c> can</c><00:27:34.899><c> use</c><00:27:34.929><c> to</c><00:27:35.200><c> attain</c>

00:27:35.639 --> 00:27:35.649 align:start position:0%
zero and theta one we can use to attain
 

00:27:35.649 --> 00:27:40.789 align:start position:0%
zero and theta one we can use to attain
that<00:27:35.950><c> minimum</c><00:27:36.610><c> loss</c><00:27:38.880><c> so</c><00:27:39.880><c> how</c><00:27:39.970><c> do</c><00:27:40.029><c> we</c><00:27:40.120><c> do</c><00:27:40.270><c> this</c>

00:27:40.789 --> 00:27:40.799 align:start position:0%
that minimum loss so how do we do this
 

00:27:40.799 --> 00:27:45.299 align:start position:0%
that minimum loss so how do we do this
well<00:27:41.799><c> we</c><00:27:42.490><c> start</c><00:27:42.850><c> with</c><00:27:43.059><c> a</c><00:27:43.380><c> random</c><00:27:44.380><c> guess</c><00:27:44.740><c> we</c>

00:27:45.299 --> 00:27:45.309 align:start position:0%
well we start with a random guess we
 

00:27:45.309 --> 00:27:47.580 align:start position:0%
well we start with a random guess we
pick<00:27:45.640><c> a</c><00:27:45.669><c> point</c><00:27:45.760><c> theta</c><00:27:46.600><c> zero</c><00:27:46.870><c> theta</c><00:27:46.960><c> one</c><00:27:47.320><c> and</c><00:27:47.500><c> we</c>

00:27:47.580 --> 00:27:47.590 align:start position:0%
pick a point theta zero theta one and we
 

00:27:47.590 --> 00:27:50.370 align:start position:0%
pick a point theta zero theta one and we
start<00:27:47.860><c> there</c><00:27:48.210><c> we</c><00:27:49.210><c> compute</c><00:27:49.690><c> the</c><00:27:49.809><c> gradient</c><00:27:50.260><c> of</c>

00:27:50.370 --> 00:27:50.380 align:start position:0%
start there we compute the gradient of
 

00:27:50.380 --> 00:27:52.740 align:start position:0%
start there we compute the gradient of
this<00:27:50.590><c> point</c><00:27:50.919><c> on</c><00:27:51.190><c> the</c><00:27:51.789><c> lost</c><00:27:52.000><c> landscape</c><00:27:52.480><c> that's</c>

00:27:52.740 --> 00:27:52.750 align:start position:0%
this point on the lost landscape that's
 

00:27:52.750 --> 00:27:54.269 align:start position:0%
this point on the lost landscape that's
DJ<00:27:53.140><c> D</c><00:27:53.860><c> theta</c>

00:27:54.269 --> 00:27:54.279 align:start position:0%
DJ D theta
 

00:27:54.279 --> 00:27:56.610 align:start position:0%
DJ D theta
it's<00:27:54.970><c> how</c><00:27:55.179><c> the</c><00:27:55.240><c> loss</c><00:27:55.659><c> is</c><00:27:55.929><c> changing</c><00:27:56.470><c> with</c>

00:27:56.610 --> 00:27:56.620 align:start position:0%
it's how the loss is changing with
 

00:27:56.620 --> 00:28:00.480 align:start position:0%
it's how the loss is changing with
respect<00:27:56.649><c> to</c><00:27:57.130><c> each</c><00:27:57.370><c> of</c><00:27:57.640><c> the</c><00:27:58.000><c> weights</c><00:27:59.340><c> now</c><00:28:00.340><c> this</c>

00:28:00.480 --> 00:28:00.490 align:start position:0%
respect to each of the weights now this
 

00:28:00.490 --> 00:28:02.880 align:start position:0%
respect to each of the weights now this
gradient<00:28:01.480><c> tells</c><00:28:01.840><c> us</c><00:28:02.020><c> the</c><00:28:02.200><c> direction</c><00:28:02.350><c> of</c>

00:28:02.880 --> 00:28:02.890 align:start position:0%
gradient tells us the direction of
 

00:28:02.890 --> 00:28:05.460 align:start position:0%
gradient tells us the direction of
highest<00:28:03.610><c> ascent</c><00:28:04.059><c> not</c><00:28:04.630><c> descent</c><00:28:05.080><c> so</c><00:28:05.230><c> this</c><00:28:05.350><c> is</c>

00:28:05.460 --> 00:28:05.470 align:start position:0%
highest ascent not descent so this is
 

00:28:05.470 --> 00:28:07.710 align:start position:0%
highest ascent not descent so this is
telling<00:28:05.740><c> us</c><00:28:05.799><c> the</c><00:28:06.130><c> direction</c><00:28:06.580><c> going</c><00:28:07.029><c> towards</c>

00:28:07.710 --> 00:28:07.720 align:start position:0%
telling us the direction going towards
 

00:28:07.720 --> 00:28:10.560 align:start position:0%
telling us the direction going towards
the<00:28:07.809><c> top</c><00:28:08.020><c> of</c><00:28:08.049><c> the</c><00:28:08.289><c> mountain</c><00:28:09.240><c> so</c><00:28:10.240><c> let's</c><00:28:10.390><c> take</c><00:28:10.539><c> a</c>

00:28:10.560 --> 00:28:10.570 align:start position:0%
the top of the mountain so let's take a
 

00:28:10.570 --> 00:28:13.019 align:start position:0%
the top of the mountain so let's take a
small<00:28:10.750><c> step</c><00:28:11.140><c> in</c><00:28:11.260><c> the</c><00:28:11.409><c> opposite</c><00:28:11.860><c> direction</c><00:28:12.029><c> so</c>

00:28:13.019 --> 00:28:13.029 align:start position:0%
small step in the opposite direction so
 

00:28:13.029 --> 00:28:15.899 align:start position:0%
small step in the opposite direction so
we<00:28:13.149><c> negate</c><00:28:13.510><c> our</c><00:28:13.750><c> gradient</c><00:28:13.990><c> and</c><00:28:14.350><c> we</c><00:28:14.950><c> adjust</c><00:28:15.789><c> our</c>

00:28:15.899 --> 00:28:15.909 align:start position:0%
we negate our gradient and we adjust our
 

00:28:15.909 --> 00:28:17.580 align:start position:0%
we negate our gradient and we adjust our
weight<00:28:16.149><c> such</c><00:28:16.390><c> that</c><00:28:16.570><c> we</c><00:28:16.659><c> step</c><00:28:16.929><c> in</c><00:28:17.049><c> the</c><00:28:17.080><c> opposite</c>

00:28:17.580 --> 00:28:17.590 align:start position:0%
weight such that we step in the opposite
 

00:28:17.590 --> 00:28:19.710 align:start position:0%
weight such that we step in the opposite
direction<00:28:17.740><c> of</c><00:28:18.130><c> that</c><00:28:18.250><c> gradient</c><00:28:18.490><c> such</c><00:28:19.360><c> that</c><00:28:19.570><c> we</c>

00:28:19.710 --> 00:28:19.720 align:start position:0%
direction of that gradient such that we
 

00:28:19.720 --> 00:28:21.899 align:start position:0%
direction of that gradient such that we
move<00:28:20.020><c> continuously</c><00:28:20.470><c> towards</c><00:28:21.399><c> the</c><00:28:21.580><c> lowest</c>

00:28:21.899 --> 00:28:21.909 align:start position:0%
move continuously towards the lowest
 

00:28:21.909 --> 00:28:25.769 align:start position:0%
move continuously towards the lowest
point<00:28:22.179><c> in</c><00:28:22.390><c> this</c><00:28:22.929><c> landscape</c><00:28:23.890><c> until</c><00:28:24.610><c> we</c><00:28:25.450><c> finally</c>

00:28:25.769 --> 00:28:25.779 align:start position:0%
point in this landscape until we finally
 

00:28:25.779 --> 00:28:27.539 align:start position:0%
point in this landscape until we finally
converge<00:28:26.140><c> at</c><00:28:26.380><c> a</c><00:28:26.409><c> local</c><00:28:26.770><c> minima</c><00:28:27.100><c> and</c><00:28:27.279><c> then</c><00:28:27.460><c> we</c>

00:28:27.539 --> 00:28:27.549 align:start position:0%
converge at a local minima and then we
 

00:28:27.549 --> 00:28:30.870 align:start position:0%
converge at a local minima and then we
just<00:28:27.760><c> stop</c><00:28:28.950><c> so</c><00:28:29.950><c> let's</c><00:28:30.100><c> summarize</c><00:28:30.279><c> this</c><00:28:30.669><c> with</c>

00:28:30.870 --> 00:28:30.880 align:start position:0%
just stop so let's summarize this with
 

00:28:30.880 --> 00:28:32.130 align:start position:0%
just stop so let's summarize this with
some<00:28:31.059><c> pseudocode</c><00:28:31.360><c> so</c><00:28:31.690><c> we</c><00:28:31.809><c> randomly</c>

00:28:32.130 --> 00:28:32.140 align:start position:0%
some pseudocode so we randomly
 

00:28:32.140 --> 00:28:34.620 align:start position:0%
some pseudocode so we randomly
initialize<00:28:32.559><c> our</c><00:28:32.710><c> weights</c><00:28:33.090><c> we</c><00:28:34.090><c> loop</c><00:28:34.330><c> until</c>

00:28:34.620 --> 00:28:34.630 align:start position:0%
initialize our weights we loop until
 

00:28:34.630 --> 00:28:36.990 align:start position:0%
initialize our weights we loop until
convergence<00:28:34.840><c> the</c><00:28:35.350><c> following</c><00:28:35.799><c> we</c><00:28:36.520><c> compute</c><00:28:36.909><c> the</c>

00:28:36.990 --> 00:28:37.000 align:start position:0%
convergence the following we compute the
 

00:28:37.000 --> 00:28:39.450 align:start position:0%
convergence the following we compute the
gradient<00:28:37.419><c> at</c><00:28:37.539><c> that</c><00:28:37.570><c> point</c><00:28:38.020><c> and</c><00:28:38.860><c> simply</c><00:28:39.340><c> we</c>

00:28:39.450 --> 00:28:39.460 align:start position:0%
gradient at that point and simply we
 

00:28:39.460 --> 00:28:41.789 align:start position:0%
gradient at that point and simply we
apply<00:28:39.760><c> this</c><00:28:39.820><c> update</c><00:28:40.390><c> rule</c><00:28:40.419><c> where</c><00:28:41.350><c> the</c><00:28:41.380><c> update</c>

00:28:41.789 --> 00:28:41.799 align:start position:0%
apply this update rule where the update
 

00:28:41.799 --> 00:28:48.930 align:start position:0%
apply this update rule where the update
takes<00:28:42.299><c> as</c><00:28:43.299><c> input</c><00:28:43.750><c> the</c><00:28:43.960><c> negative</c><00:28:44.710><c> gradient</c><00:28:47.940><c> now</c>

00:28:48.930 --> 00:28:48.940 align:start position:0%
takes as input the negative gradient now
 

00:28:48.940 --> 00:28:50.639 align:start position:0%
takes as input the negative gradient now
let's<00:28:49.090><c> look</c><00:28:49.210><c> at</c><00:28:49.299><c> this</c><00:28:49.450><c> term</c><00:28:49.659><c> here</c><00:28:49.870><c> this</c><00:28:50.230><c> is</c><00:28:50.380><c> the</c>

00:28:50.639 --> 00:28:50.649 align:start position:0%
let's look at this term here this is the
 

00:28:50.649 --> 00:28:53.399 align:start position:0%
let's look at this term here this is the
gradient<00:28:50.919><c> like</c><00:28:51.549><c> I</c><00:28:51.669><c> said</c><00:28:51.850><c> it</c><00:28:51.970><c> explains</c><00:28:52.510><c> how</c><00:28:53.350><c> the</c>

00:28:53.399 --> 00:28:53.409 align:start position:0%
gradient like I said it explains how the
 

00:28:53.409 --> 00:28:55.889 align:start position:0%
gradient like I said it explains how the
lost<00:28:53.770><c> changes</c><00:28:54.279><c> with</c><00:28:54.490><c> respect</c><00:28:54.970><c> to</c><00:28:55.330><c> each</c><00:28:55.570><c> weight</c>

00:28:55.889 --> 00:28:55.899 align:start position:0%
lost changes with respect to each weight
 

00:28:55.899 --> 00:28:58.139 align:start position:0%
lost changes with respect to each weight
in<00:28:56.110><c> the</c><00:28:56.260><c> network</c><00:28:56.559><c> but</c><00:28:57.549><c> I</c><00:28:57.580><c> never</c><00:28:57.789><c> actually</c><00:28:58.000><c> told</c>

00:28:58.139 --> 00:28:58.149 align:start position:0%
in the network but I never actually told
 

00:28:58.149 --> 00:28:59.310 align:start position:0%
in the network but I never actually told
you<00:28:58.510><c> how</c><00:28:58.600><c> to</c><00:28:58.659><c> compute</c><00:28:58.990><c> this</c>

00:28:59.310 --> 00:28:59.320 align:start position:0%
you how to compute this
 

00:28:59.320 --> 00:29:01.710 align:start position:0%
you how to compute this
this<00:28:59.740><c> is</c><00:28:59.860><c> actually</c><00:29:00.160><c> a</c><00:29:00.190><c> big</c><00:29:00.370><c> big</c><00:29:01.330><c> issue</c><00:29:01.480><c> in</c>

00:29:01.710 --> 00:29:01.720 align:start position:0%
this is actually a big big issue in
 

00:29:01.720 --> 00:29:03.360 align:start position:0%
this is actually a big big issue in
neural<00:29:01.930><c> networks</c><00:29:01.990><c> I</c><00:29:02.560><c> just</c><00:29:02.920><c> kind</c><00:29:03.100><c> of</c><00:29:03.130><c> took</c><00:29:03.280><c> it</c>

00:29:03.360 --> 00:29:03.370 align:start position:0%
neural networks I just kind of took it
 

00:29:03.370 --> 00:29:05.640 align:start position:0%
neural networks I just kind of took it
for<00:29:03.520><c> granted</c><00:29:03.930><c> so</c><00:29:04.930><c> now</c><00:29:05.050><c> let's</c><00:29:05.200><c> talk</c><00:29:05.320><c> about</c><00:29:05.380><c> this</c>

00:29:05.640 --> 00:29:05.650 align:start position:0%
for granted so now let's talk about this
 

00:29:05.650 --> 00:29:07.020 align:start position:0%
for granted so now let's talk about this
process<00:29:06.130><c> of</c><00:29:06.220><c> actually</c><00:29:06.340><c> computing</c><00:29:06.910><c> this</c>

00:29:07.020 --> 00:29:07.030 align:start position:0%
process of actually computing this
 

00:29:07.030 --> 00:29:08.400 align:start position:0%
process of actually computing this
gradient<00:29:07.390><c> because</c><00:29:07.570><c> it's</c><00:29:07.690><c> not</c><00:29:07.810><c> that</c><00:29:07.960><c> gradient</c>

00:29:08.400 --> 00:29:08.410 align:start position:0%
gradient because it's not that gradient
 

00:29:08.410 --> 00:29:09.930 align:start position:0%
gradient because it's not that gradient
you<00:29:09.040><c> kind</c><00:29:09.220><c> of</c><00:29:09.310><c> helpless</c>

00:29:09.930 --> 00:29:09.940 align:start position:0%
you kind of helpless
 

00:29:09.940 --> 00:29:12.540 align:start position:0%
you kind of helpless
you<00:29:10.090><c> have</c><00:29:10.210><c> no</c><00:29:10.330><c> idea</c><00:29:10.360><c> which</c><00:29:10.750><c> way</c><00:29:10.930><c> down</c><00:29:11.890><c> is</c><00:29:12.190><c> you</c>

00:29:12.540 --> 00:29:12.550 align:start position:0%
you have no idea which way down is you
 

00:29:12.550 --> 00:29:15.230 align:start position:0%
you have no idea which way down is you
don't<00:29:12.700><c> know</c><00:29:12.790><c> where</c><00:29:13.090><c> to</c><00:29:13.120><c> go</c><00:29:13.420><c> in</c><00:29:13.690><c> your</c><00:29:13.810><c> landscape</c>

00:29:15.230 --> 00:29:15.240 align:start position:0%
don't know where to go in your landscape
 

00:29:15.240 --> 00:29:17.730 align:start position:0%
don't know where to go in your landscape
so<00:29:16.240><c> let's</c><00:29:16.390><c> consider</c><00:29:16.540><c> a</c><00:29:16.750><c> very</c><00:29:17.050><c> simple</c><00:29:17.290><c> neural</c>

00:29:17.730 --> 00:29:17.740 align:start position:0%
so let's consider a very simple neural
 

00:29:17.740 --> 00:29:19.710 align:start position:0%
so let's consider a very simple neural
network<00:29:18.040><c> probably</c><00:29:18.880><c> the</c><00:29:19.030><c> simplest</c><00:29:19.360><c> neural</c>

00:29:19.710 --> 00:29:19.720 align:start position:0%
network probably the simplest neural
 

00:29:19.720 --> 00:29:22.410 align:start position:0%
network probably the simplest neural
network<00:29:19.990><c> in</c><00:29:20.230><c> the</c><00:29:20.320><c> world</c><00:29:20.500><c> it</c><00:29:21.460><c> contains</c><00:29:21.910><c> one</c>

00:29:22.410 --> 00:29:22.420 align:start position:0%
network in the world it contains one
 

00:29:22.420 --> 00:29:24.720 align:start position:0%
network in the world it contains one
hidden<00:29:22.690><c> unit</c><00:29:23.110><c> one</c><00:29:23.560><c> hidden</c><00:29:23.770><c> layer</c><00:29:24.040><c> and</c><00:29:24.250><c> one</c>

00:29:24.720 --> 00:29:24.730 align:start position:0%
hidden unit one hidden layer and one
 

00:29:24.730 --> 00:29:28.980 align:start position:0%
hidden unit one hidden layer and one
output<00:29:24.910><c> unit</c><00:29:25.290><c> and</c><00:29:27.330><c> we</c><00:29:28.330><c> want</c><00:29:28.540><c> to</c><00:29:28.600><c> compute</c><00:29:28.900><c> the</c>

00:29:28.980 --> 00:29:28.990 align:start position:0%
output unit and we want to compute the
 

00:29:28.990 --> 00:29:31.980 align:start position:0%
output unit and we want to compute the
gradient<00:29:29.500><c> of</c><00:29:29.620><c> our</c><00:29:29.740><c> loss</c><00:29:29.950><c> J</c><00:29:30.610><c> of</c><00:29:30.760><c> theta</c><00:29:30.990><c> with</c>

00:29:31.980 --> 00:29:31.990 align:start position:0%
gradient of our loss J of theta with
 

00:29:31.990 --> 00:29:35.460 align:start position:0%
gradient of our loss J of theta with
respect<00:29:32.020><c> to</c><00:29:32.590><c> theta</c><00:29:32.890><c> to</c><00:29:33.430><c> just</c><00:29:34.150><c> data</c><00:29:34.300><c> to</c><00:29:34.570><c> for</c><00:29:35.380><c> now</c>

00:29:35.460 --> 00:29:35.470 align:start position:0%
respect to theta to just data to for now
 

00:29:35.470 --> 00:29:38.010 align:start position:0%
respect to theta to just data to for now
so<00:29:36.340><c> this</c><00:29:36.430><c> tells</c><00:29:36.670><c> us</c><00:29:36.850><c> how</c><00:29:36.910><c> a</c><00:29:37.240><c> small</c><00:29:37.570><c> change</c><00:29:37.630><c> in</c>

00:29:38.010 --> 00:29:38.020 align:start position:0%
so this tells us how a small change in
 

00:29:38.020 --> 00:29:39.960 align:start position:0%
so this tells us how a small change in
theta<00:29:38.140><c> 2</c><00:29:38.440><c> will</c><00:29:38.590><c> impact</c><00:29:38.950><c> our</c><00:29:39.190><c> final</c><00:29:39.610><c> loss</c><00:29:39.760><c> at</c>

00:29:39.960 --> 00:29:39.970 align:start position:0%
theta 2 will impact our final loss at
 

00:29:39.970 --> 00:29:43.040 align:start position:0%
theta 2 will impact our final loss at
the<00:29:40.150><c> output</c><00:29:40.510><c> so</c><00:29:41.170><c> let's</c><00:29:41.320><c> write</c><00:29:41.470><c> this</c><00:29:41.500><c> out</c><00:29:41.770><c> as</c><00:29:41.950><c> a</c>

00:29:43.040 --> 00:29:43.050 align:start position:0%
the output so let's write this out as a
 

00:29:43.050 --> 00:29:46.140 align:start position:0%
the output so let's write this out as a
derivative<00:29:44.340><c> we</c><00:29:45.340><c> can</c><00:29:45.370><c> start</c><00:29:45.730><c> by</c><00:29:45.820><c> just</c><00:29:45.850><c> applying</c>

00:29:46.140 --> 00:29:46.150 align:start position:0%
derivative we can start by just applying
 

00:29:46.150 --> 00:29:49.710 align:start position:0%
derivative we can start by just applying
a<00:29:46.360><c> chain</c><00:29:46.630><c> rule</c><00:29:46.870><c> because</c><00:29:48.150><c> J</c><00:29:49.150><c> of</c><00:29:49.300><c> theta</c><00:29:49.330><c> is</c>

00:29:49.710 --> 00:29:49.720 align:start position:0%
a chain rule because J of theta is
 

00:29:49.720 --> 00:29:53.070 align:start position:0%
a chain rule because J of theta is
dependent<00:29:50.320><c> on</c><00:29:50.500><c> Y</c><00:29:51.430><c> right</c><00:29:52.150><c> so</c><00:29:52.360><c> first</c><00:29:52.660><c> we</c><00:29:52.840><c> want</c><00:29:53.020><c> to</c>

00:29:53.070 --> 00:29:53.080 align:start position:0%
dependent on Y right so first we want to
 

00:29:53.080 --> 00:29:56.040 align:start position:0%
dependent on Y right so first we want to
back<00:29:53.680><c> propagate</c><00:29:54.280><c> through</c><00:29:54.700><c> Y</c><00:29:55.000><c> our</c><00:29:55.270><c> output</c><00:29:55.720><c> all</c>

00:29:56.040 --> 00:29:56.050 align:start position:0%
back propagate through Y our output all
 

00:29:56.050 --> 00:30:00.360 align:start position:0%
back propagate through Y our output all
the<00:29:56.770><c> way</c><00:29:56.890><c> back</c><00:29:57.100><c> to</c><00:29:57.850><c> theta</c><00:29:58.060><c> 2</c><00:29:58.830><c> we</c><00:29:59.830><c> can</c><00:29:59.980><c> do</c><00:30:00.160><c> this</c>

00:30:00.360 --> 00:30:00.370 align:start position:0%
the way back to theta 2 we can do this
 

00:30:00.370 --> 00:30:05.310 align:start position:0%
the way back to theta 2 we can do this
because<00:30:00.670><c> Y</c><00:30:01.450><c> our</c><00:30:01.720><c> output</c><00:30:02.230><c> Y</c><00:30:02.650><c> is</c><00:30:04.020><c> only</c><00:30:05.020><c> dependent</c>

00:30:05.310 --> 00:30:05.320 align:start position:0%
because Y our output Y is only dependent
 

00:30:05.320 --> 00:30:09.090 align:start position:0%
because Y our output Y is only dependent
on<00:30:05.770><c> the</c><00:30:06.400><c> input</c><00:30:06.820><c> and</c><00:30:07.000><c> theta</c><00:30:07.480><c> 2</c><00:30:07.750><c> that's</c><00:30:08.080><c> it</c><00:30:08.260><c> so</c>

00:30:09.090 --> 00:30:09.100 align:start position:0%
on the input and theta 2 that's it so
 

00:30:09.100 --> 00:30:10.890 align:start position:0%
on the input and theta 2 that's it so
we're<00:30:09.250><c> able</c><00:30:09.400><c> to</c><00:30:09.610><c> just</c><00:30:10.000><c> from</c><00:30:10.150><c> that</c><00:30:10.270><c> perceptron</c>

00:30:10.890 --> 00:30:10.900 align:start position:0%
we're able to just from that perceptron
 

00:30:10.900 --> 00:30:12.240 align:start position:0%
we're able to just from that perceptron
equation<00:30:11.290><c> that</c><00:30:11.380><c> we</c><00:30:11.530><c> wrote</c><00:30:11.560><c> on</c><00:30:11.860><c> the</c><00:30:11.950><c> previous</c>

00:30:12.240 --> 00:30:12.250 align:start position:0%
equation that we wrote on the previous
 

00:30:12.250 --> 00:30:15.150 align:start position:0%
equation that we wrote on the previous
slide<00:30:12.400><c> compute</c><00:30:13.090><c> a</c><00:30:13.150><c> closed-form</c><00:30:13.600><c> gradient</c><00:30:14.320><c> or</c>

00:30:15.150 --> 00:30:15.160 align:start position:0%
slide compute a closed-form gradient or
 

00:30:15.160 --> 00:30:17.870 align:start position:0%
slide compute a closed-form gradient or
closed<00:30:15.430><c> form</c><00:30:15.670><c> derivative</c><00:30:16.150><c> of</c><00:30:16.300><c> that</c><00:30:16.480><c> function</c>

00:30:17.870 --> 00:30:17.880 align:start position:0%
closed form derivative of that function
 

00:30:17.880 --> 00:30:20.640 align:start position:0%
closed form derivative of that function
now<00:30:18.880><c> let's</c><00:30:19.060><c> suppose</c><00:30:19.180><c> I</c><00:30:19.420><c> change</c><00:30:19.780><c> theta</c><00:30:20.140><c> to</c><00:30:20.440><c> 2</c>

00:30:20.640 --> 00:30:20.650 align:start position:0%
now let's suppose I change theta to 2
 

00:30:20.650 --> 00:30:23.520 align:start position:0%
now let's suppose I change theta to 2
theta<00:30:20.860><c> 1</c><00:30:21.100><c> and</c><00:30:21.700><c> I</c><00:30:21.790><c> want</c><00:30:21.910><c> to</c><00:30:22.030><c> compute</c><00:30:22.330><c> the</c><00:30:23.260><c> same</c>

00:30:23.520 --> 00:30:23.530 align:start position:0%
theta 1 and I want to compute the same
 

00:30:23.530 --> 00:30:25.770 align:start position:0%
theta 1 and I want to compute the same
thing<00:30:23.770><c> but</c><00:30:23.980><c> now</c><00:30:24.160><c> for</c><00:30:24.550><c> the</c><00:30:24.670><c> previous</c><00:30:25.090><c> layer</c><00:30:25.540><c> and</c>

00:30:25.770 --> 00:30:25.780 align:start position:0%
thing but now for the previous layer and
 

00:30:25.780 --> 00:30:30.110 align:start position:0%
thing but now for the previous layer and
the<00:30:26.260><c> previous</c><00:30:26.590><c> weight</c><00:30:27.810><c> all</c><00:30:28.810><c> we</c><00:30:29.080><c> need</c><00:30:29.230><c> to</c><00:30:29.380><c> do</c><00:30:29.560><c> is</c>

00:30:30.110 --> 00:30:30.120 align:start position:0%
the previous weight all we need to do is
 

00:30:30.120 --> 00:30:32.670 align:start position:0%
the previous weight all we need to do is
apply<00:30:31.120><c> the</c><00:30:31.210><c> chain</c><00:30:31.480><c> rule</c><00:30:31.510><c> one</c><00:30:31.900><c> more</c><00:30:32.080><c> time</c><00:30:32.320><c> back</c>

00:30:32.670 --> 00:30:32.680 align:start position:0%
apply the chain rule one more time back
 

00:30:32.680 --> 00:30:34.980 align:start position:0%
apply the chain rule one more time back
propagate<00:30:33.340><c> those</c><00:30:34.270><c> gradients</c><00:30:34.600><c> that</c><00:30:34.810><c> we</c>

00:30:34.980 --> 00:30:34.990 align:start position:0%
propagate those gradients that we
 

00:30:34.990 --> 00:30:37.490 align:start position:0%
propagate those gradients that we
previously<00:30:35.260><c> computed</c><00:30:35.740><c> one</c><00:30:36.220><c> layer</c><00:30:36.460><c> further</c>

00:30:37.490 --> 00:30:37.500 align:start position:0%
previously computed one layer further
 

00:30:37.500 --> 00:30:41.040 align:start position:0%
previously computed one layer further
it's<00:30:38.500><c> the</c><00:30:38.560><c> same</c><00:30:38.770><c> story</c><00:30:38.980><c> again</c><00:30:39.540><c> we</c><00:30:40.540><c> can</c><00:30:40.690><c> do</c><00:30:40.870><c> this</c>

00:30:41.040 --> 00:30:41.050 align:start position:0%
it's the same story again we can do this
 

00:30:41.050 --> 00:30:45.210 align:start position:0%
it's the same story again we can do this
for<00:30:41.770><c> the</c><00:30:41.890><c> same</c><00:30:42.100><c> reason</c><00:30:42.130><c> this</c><00:30:42.910><c> is</c><00:30:43.090><c> because</c><00:30:44.220><c> z1</c>

00:30:45.210 --> 00:30:45.220 align:start position:0%
for the same reason this is because z1
 

00:30:45.220 --> 00:30:49.500 align:start position:0%
for the same reason this is because z1
our<00:30:46.090><c> hidden</c><00:30:46.390><c> state</c><00:30:47.260><c> is</c><00:30:47.760><c> only</c><00:30:48.760><c> dependent</c><00:30:49.030><c> on</c>

00:30:49.500 --> 00:30:49.510 align:start position:0%
our hidden state is only dependent on
 

00:30:49.510 --> 00:30:53.190 align:start position:0%
our hidden state is only dependent on
our<00:30:50.080><c> previous</c><00:30:50.950><c> input</c><00:30:51.310><c> X</c><00:30:51.550><c> and</c><00:30:51.700><c> that</c><00:30:52.690><c> single</c>

00:30:53.190 --> 00:30:53.200 align:start position:0%
our previous input X and that single
 

00:30:53.200 --> 00:30:57.990 align:start position:0%
our previous input X and that single
weight<00:30:53.800><c> theta</c><00:30:54.310><c> one</c><00:30:56.100><c> now</c><00:30:57.100><c> the</c><00:30:57.160><c> process</c><00:30:57.670><c> of</c><00:30:57.760><c> back</c>

00:30:57.990 --> 00:30:58.000 align:start position:0%
weight theta one now the process of back
 

00:30:58.000 --> 00:31:02.280 align:start position:0%
weight theta one now the process of back
propagation<00:30:58.920><c> is</c><00:30:59.920><c> basically</c><00:31:00.460><c> you</c><00:31:01.450><c> repeat</c><00:31:02.050><c> this</c>

00:31:02.280 --> 00:31:02.290 align:start position:0%
propagation is basically you repeat this
 

00:31:02.290 --> 00:31:04.620 align:start position:0%
propagation is basically you repeat this
process<00:31:02.950><c> over</c><00:31:03.640><c> and</c><00:31:03.730><c> over</c><00:31:03.940><c> again</c><00:31:04.030><c> for</c><00:31:04.270><c> every</c>

00:31:04.620 --> 00:31:04.630 align:start position:0%
process over and over again for every
 

00:31:04.630 --> 00:31:06.810 align:start position:0%
process over and over again for every
way<00:31:04.810><c> in</c><00:31:04.990><c> your</c><00:31:05.140><c> network</c><00:31:05.440><c> until</c><00:31:06.340><c> you</c><00:31:06.460><c> compute</c>

00:31:06.810 --> 00:31:06.820 align:start position:0%
way in your network until you compute
 

00:31:06.820 --> 00:31:09.660 align:start position:0%
way in your network until you compute
that<00:31:06.850><c> gradient</c><00:31:07.390><c> DJ</c><00:31:07.930><c> D</c><00:31:08.170><c> theta</c><00:31:08.350><c> and</c><00:31:09.190><c> you</c><00:31:09.340><c> can</c><00:31:09.490><c> use</c>

00:31:09.660 --> 00:31:09.670 align:start position:0%
that gradient DJ D theta and you can use
 

00:31:09.670 --> 00:31:11.100 align:start position:0%
that gradient DJ D theta and you can use
that<00:31:09.850><c> as</c><00:31:10.030><c> part</c><00:31:10.240><c> of</c><00:31:10.330><c> your</c><00:31:10.420><c> optimization</c>

00:31:11.100 --> 00:31:11.110 align:start position:0%
that as part of your optimization
 

00:31:11.110 --> 00:31:12.330 align:start position:0%
that as part of your optimization
process

00:31:12.330 --> 00:31:12.340 align:start position:0%
process
 

00:31:12.340 --> 00:31:16.590 align:start position:0%
process
to<00:31:12.460><c> find</c><00:31:12.789><c> your</c><00:31:13.029><c> local</c><00:31:13.210><c> minimum</c><00:31:15.120><c> now</c><00:31:16.120><c> in</c><00:31:16.360><c> theory</c>

00:31:16.590 --> 00:31:16.600 align:start position:0%
to find your local minimum now in theory
 

00:31:16.600 --> 00:31:19.529 align:start position:0%
to find your local minimum now in theory
that<00:31:17.080><c> sounds</c><00:31:17.500><c> pretty</c><00:31:18.010><c> simple</c><00:31:18.250><c> I</c><00:31:18.460><c> hope</c><00:31:18.640><c> I</c><00:31:18.909><c> mean</c>

00:31:19.529 --> 00:31:19.539 align:start position:0%
that sounds pretty simple I hope I mean
 

00:31:19.539 --> 00:31:21.060 align:start position:0%
that sounds pretty simple I hope I mean
we<00:31:19.750><c> just</c><00:31:19.929><c> talked</c><00:31:20.169><c> about</c><00:31:20.260><c> some</c><00:31:20.559><c> basic</c><00:31:20.860><c> chain</c>

00:31:21.060 --> 00:31:21.070 align:start position:0%
we just talked about some basic chain
 

00:31:21.070 --> 00:31:23.700 align:start position:0%
we just talked about some basic chain
rules<00:31:21.600><c> but</c><00:31:22.600><c> let's</c><00:31:22.870><c> actually</c><00:31:23.049><c> touch</c><00:31:23.380><c> on</c><00:31:23.529><c> some</c>

00:31:23.700 --> 00:31:23.710 align:start position:0%
rules but let's actually touch on some
 

00:31:23.710 --> 00:31:26.399 align:start position:0%
rules but let's actually touch on some
insights<00:31:24.190><c> on</c><00:31:24.630><c> training</c><00:31:25.630><c> these</c><00:31:25.870><c> networks</c><00:31:26.260><c> and</c>

00:31:26.399 --> 00:31:26.409 align:start position:0%
insights on training these networks and
 

00:31:26.409 --> 00:31:28.019 align:start position:0%
insights on training these networks and
computing<00:31:26.740><c> back</c><00:31:26.919><c> propagation</c><00:31:27.490><c> in</c><00:31:27.610><c> practice</c>

00:31:28.019 --> 00:31:28.029 align:start position:0%
computing back propagation in practice
 

00:31:28.029 --> 00:31:30.720 align:start position:0%
computing back propagation in practice
now<00:31:28.929><c> the</c><00:31:29.710><c> picture</c><00:31:30.010><c> I</c><00:31:30.039><c> showed</c><00:31:30.220><c> you</c><00:31:30.309><c> before</c><00:31:30.460><c> is</c>

00:31:30.720 --> 00:31:30.730 align:start position:0%
now the picture I showed you before is
 

00:31:30.730 --> 00:31:32.279 align:start position:0%
now the picture I showed you before is
not<00:31:30.880><c> really</c><00:31:31.150><c> accurate</c><00:31:31.390><c> for</c><00:31:31.809><c> modern</c><00:31:32.110><c> deep</c>

00:31:32.279 --> 00:31:32.289 align:start position:0%
not really accurate for modern deep
 

00:31:32.289 --> 00:31:34.260 align:start position:0%
not really accurate for modern deep
neural<00:31:32.470><c> network</c><00:31:32.710><c> architectures</c><00:31:33.340><c> modern</c><00:31:34.120><c> deep</c>

00:31:34.260 --> 00:31:34.270 align:start position:0%
neural network architectures modern deep
 

00:31:34.270 --> 00:31:35.549 align:start position:0%
neural network architectures modern deep
neural<00:31:34.419><c> network</c><00:31:34.750><c> architectures</c><00:31:35.380><c> are</c>

00:31:35.549 --> 00:31:35.559 align:start position:0%
neural network architectures are
 

00:31:35.559 --> 00:31:38.850 align:start position:0%
neural network architectures are
extremely<00:31:36.070><c> non</c><00:31:36.909><c> convex</c><00:31:37.559><c> this</c><00:31:38.559><c> is</c><00:31:38.710><c> an</c>

00:31:38.850 --> 00:31:38.860 align:start position:0%
extremely non convex this is an
 

00:31:38.860 --> 00:31:41.159 align:start position:0%
extremely non convex this is an
illustration<00:31:39.250><c> or</c><00:31:39.460><c> a</c><00:31:39.520><c> visualization</c><00:31:40.299><c> of</c><00:31:40.539><c> the</c>

00:31:41.159 --> 00:31:41.169 align:start position:0%
illustration or a visualization of the
 

00:31:41.169 --> 00:31:43.230 align:start position:0%
illustration or a visualization of the
landscape<00:31:41.740><c> like</c><00:31:42.130><c> I've</c><00:31:42.279><c> plotted</c><00:31:42.520><c> before</c><00:31:43.000><c> but</c>

00:31:43.230 --> 00:31:43.240 align:start position:0%
landscape like I've plotted before but
 

00:31:43.240 --> 00:31:45.960 align:start position:0%
landscape like I've plotted before but
of<00:31:43.360><c> a</c><00:31:43.450><c> real</c><00:31:43.630><c> deep</c><00:31:43.929><c> neural</c><00:31:44.080><c> network</c><00:31:44.529><c> of</c><00:31:45.039><c> ResNet</c>

00:31:45.960 --> 00:31:45.970 align:start position:0%
of a real deep neural network of ResNet
 

00:31:45.970 --> 00:31:49.409 align:start position:0%
of a real deep neural network of ResNet
50<00:31:46.360><c> to</c><00:31:46.539><c> be</c><00:31:46.659><c> precise</c><00:31:47.490><c> this</c><00:31:48.490><c> was</c><00:31:48.730><c> actually</c><00:31:49.149><c> taken</c>

00:31:49.409 --> 00:31:49.419 align:start position:0%
50 to be precise this was actually taken
 

00:31:49.419 --> 00:31:52.260 align:start position:0%
50 to be precise this was actually taken
from<00:31:49.570><c> a</c><00:31:49.779><c> paper</c><00:31:49.960><c> published</c><00:31:50.850><c> about</c><00:31:51.850><c> a</c><00:31:51.880><c> month</c><00:31:52.149><c> ago</c>

00:31:52.260 --> 00:31:52.270 align:start position:0%
from a paper published about a month ago
 

00:31:52.270 --> 00:31:54.210 align:start position:0%
from a paper published about a month ago
where<00:31:52.779><c> the</c><00:31:52.899><c> authors</c><00:31:53.260><c> attempt</c><00:31:53.649><c> to</c><00:31:53.770><c> visualize</c>

00:31:54.210 --> 00:31:54.220 align:start position:0%
where the authors attempt to visualize
 

00:31:54.220 --> 00:31:57.120 align:start position:0%
where the authors attempt to visualize
the<00:31:54.789><c> lost</c><00:31:55.029><c> landscape</c><00:31:55.659><c> to</c><00:31:55.870><c> show</c><00:31:56.140><c> how</c><00:31:56.799><c> difficult</c>

00:31:57.120 --> 00:31:57.130 align:start position:0%
the lost landscape to show how difficult
 

00:31:57.130 --> 00:31:59.370 align:start position:0%
the lost landscape to show how difficult
gradient<00:31:57.820><c> descent</c><00:31:58.059><c> can</c><00:31:58.120><c> actually</c><00:31:58.570><c> be</c><00:31:58.809><c> so</c>

00:31:59.370 --> 00:31:59.380 align:start position:0%
gradient descent can actually be so
 

00:31:59.380 --> 00:32:00.840 align:start position:0%
gradient descent can actually be so
there's<00:31:59.649><c> a</c><00:31:59.710><c> possibility</c><00:32:00.159><c> that</c><00:32:00.399><c> you</c><00:32:00.549><c> can</c><00:32:00.700><c> get</c>

00:32:00.840 --> 00:32:00.850 align:start position:0%
there's a possibility that you can get
 

00:32:00.850 --> 00:32:02.700 align:start position:0%
there's a possibility that you can get
lost<00:32:01.149><c> in</c><00:32:01.419><c> any</c><00:32:01.630><c> one</c><00:32:01.870><c> of</c><00:32:01.990><c> these</c><00:32:02.140><c> local</c><00:32:02.350><c> minima</c>

00:32:02.700 --> 00:32:02.710 align:start position:0%
lost in any one of these local minima
 

00:32:02.710 --> 00:32:03.659 align:start position:0%
lost in any one of these local minima
there's<00:32:02.919><c> no</c><00:32:03.039><c> guarantee</c><00:32:03.429><c> that</c><00:32:03.460><c> you'll</c>

00:32:03.659 --> 00:32:03.669 align:start position:0%
there's no guarantee that you'll
 

00:32:03.669 --> 00:32:07.139 align:start position:0%
there's no guarantee that you'll
actually<00:32:03.850><c> find</c><00:32:04.120><c> a</c><00:32:04.299><c> true</c><00:32:04.510><c> global</c><00:32:04.899><c> minimum</c><00:32:06.149><c> so</c>

00:32:07.139 --> 00:32:07.149 align:start position:0%
actually find a true global minimum so
 

00:32:07.149 --> 00:32:08.760 align:start position:0%
actually find a true global minimum so
let's<00:32:07.299><c> recall</c><00:32:07.809><c> that</c><00:32:07.990><c> update</c><00:32:08.350><c> equation</c><00:32:08.679><c> that</c>

00:32:08.760 --> 00:32:08.770 align:start position:0%
let's recall that update equation that
 

00:32:08.770 --> 00:32:12.090 align:start position:0%
let's recall that update equation that
we<00:32:08.890><c> defined</c><00:32:09.279><c> during</c><00:32:09.460><c> gradient</c><00:32:09.909><c> descent</c><00:32:11.100><c> let's</c>

00:32:12.090 --> 00:32:12.100 align:start position:0%
we defined during gradient descent let's
 

00:32:12.100 --> 00:32:13.980 align:start position:0%
we defined during gradient descent let's
take<00:32:12.250><c> a</c><00:32:12.309><c> look</c><00:32:12.490><c> at</c><00:32:12.549><c> this</c><00:32:12.669><c> term</c><00:32:12.909><c> here</c><00:32:13.120><c> this</c><00:32:13.840><c> is</c>

00:32:13.980 --> 00:32:13.990 align:start position:0%
take a look at this term here this is
 

00:32:13.990 --> 00:32:15.570 align:start position:0%
take a look at this term here this is
the<00:32:14.140><c> learning</c><00:32:14.320><c> rate</c><00:32:14.590><c> I</c><00:32:14.799><c> didn't</c><00:32:15.190><c> talk</c><00:32:15.309><c> too</c><00:32:15.549><c> much</c>

00:32:15.570 --> 00:32:15.580 align:start position:0%
the learning rate I didn't talk too much
 

00:32:15.580 --> 00:32:18.690 align:start position:0%
the learning rate I didn't talk too much
about<00:32:16.000><c> it</c><00:32:16.470><c> but</c><00:32:17.470><c> this</c><00:32:17.710><c> basically</c><00:32:18.010><c> determines</c>

00:32:18.690 --> 00:32:18.700 align:start position:0%
about it but this basically determines
 

00:32:18.700 --> 00:32:21.090 align:start position:0%
about it but this basically determines
how<00:32:19.090><c> large</c><00:32:19.510><c> of</c><00:32:19.899><c> a</c><00:32:20.140><c> step</c><00:32:20.380><c> we</c><00:32:20.559><c> take</c><00:32:20.799><c> in</c><00:32:21.010><c> the</c>

00:32:21.090 --> 00:32:21.100 align:start position:0%
how large of a step we take in the
 

00:32:21.100 --> 00:32:23.430 align:start position:0%
how large of a step we take in the
direction<00:32:21.370><c> of</c><00:32:21.669><c> our</c><00:32:22.240><c> gradient</c><00:32:22.570><c> and</c><00:32:22.990><c> in</c>

00:32:23.430 --> 00:32:23.440 align:start position:0%
direction of our gradient and in
 

00:32:23.440 --> 00:32:25.529 align:start position:0%
direction of our gradient and in
practice<00:32:23.890><c> setting</c><00:32:24.760><c> this</c><00:32:24.880><c> learning</c><00:32:25.240><c> rate</c><00:32:25.360><c> it's</c>

00:32:25.529 --> 00:32:25.539 align:start position:0%
practice setting this learning rate it's
 

00:32:25.539 --> 00:32:27.570 align:start position:0%
practice setting this learning rate it's
just<00:32:25.690><c> a</c><00:32:25.779><c> number</c><00:32:26.140><c> but</c><00:32:26.409><c> setting</c><00:32:26.770><c> it</c><00:32:26.919><c> can</c><00:32:27.279><c> be</c><00:32:27.399><c> very</c>

00:32:27.570 --> 00:32:27.580 align:start position:0%
just a number but setting it can be very
 

00:32:27.580 --> 00:32:29.850 align:start position:0%
just a number but setting it can be very
difficult<00:32:27.820><c> if</c><00:32:28.570><c> we</c><00:32:29.080><c> set</c><00:32:29.380><c> the</c><00:32:29.500><c> learning</c><00:32:29.740><c> rate</c>

00:32:29.850 --> 00:32:29.860 align:start position:0%
difficult if we set the learning rate
 

00:32:29.860 --> 00:32:33.000 align:start position:0%
difficult if we set the learning rate
too<00:32:30.279><c> low</c><00:32:30.570><c> then</c><00:32:31.570><c> the</c><00:32:31.690><c> model</c><00:32:31.960><c> may</c><00:32:32.289><c> get</c><00:32:32.440><c> stuck</c><00:32:32.740><c> in</c>

00:32:33.000 --> 00:32:33.010 align:start position:0%
too low then the model may get stuck in
 

00:32:33.010 --> 00:32:34.470 align:start position:0%
too low then the model may get stuck in
a<00:32:33.130><c> local</c><00:32:33.279><c> minima</c><00:32:33.789><c> and</c><00:32:34.000><c> may</c><00:32:34.210><c> never</c><00:32:34.390><c> actually</c>

00:32:34.470 --> 00:32:34.480 align:start position:0%
a local minima and may never actually
 

00:32:34.480 --> 00:32:36.269 align:start position:0%
a local minima and may never actually
find<00:32:34.929><c> its</c><00:32:35.080><c> way</c><00:32:35.200><c> out</c><00:32:35.230><c> of</c><00:32:35.529><c> that</c><00:32:35.649><c> local</c><00:32:35.860><c> minima</c>

00:32:36.269 --> 00:32:36.279 align:start position:0%
find its way out of that local minima
 

00:32:36.279 --> 00:32:38.519 align:start position:0%
find its way out of that local minima
because<00:32:37.120><c> at</c><00:32:37.419><c> the</c><00:32:37.539><c> bottom</c><00:32:37.870><c> a</c><00:32:37.960><c> local</c><00:32:38.260><c> minima</c>

00:32:38.519 --> 00:32:38.529 align:start position:0%
because at the bottom a local minima
 

00:32:38.529 --> 00:32:40.230 align:start position:0%
because at the bottom a local minima
obviously<00:32:38.980><c> your</c><00:32:39.100><c> gradient</c><00:32:39.340><c> is</c><00:32:39.640><c> 0</c><00:32:39.850><c> so</c><00:32:40.120><c> it's</c>

00:32:40.230 --> 00:32:40.240 align:start position:0%
obviously your gradient is 0 so it's
 

00:32:40.240 --> 00:32:43.169 align:start position:0%
obviously your gradient is 0 so it's
just<00:32:40.419><c> going</c><00:32:40.539><c> to</c><00:32:40.659><c> stop</c><00:32:40.840><c> moving</c><00:32:41.340><c> if</c><00:32:42.340><c> I</c><00:32:42.700><c> set</c><00:32:42.970><c> the</c>

00:32:43.169 --> 00:32:43.179 align:start position:0%
just going to stop moving if I set the
 

00:32:43.179 --> 00:32:44.909 align:start position:0%
just going to stop moving if I set the
learning<00:32:43.450><c> rate</c><00:32:43.570><c> to</c><00:32:43.779><c> large</c><00:32:44.080><c> it</c><00:32:44.770><c> could</c>

00:32:44.909 --> 00:32:44.919 align:start position:0%
learning rate to large it could
 

00:32:44.919 --> 00:32:47.399 align:start position:0%
learning rate to large it could
overshoot<00:32:45.460><c> and</c><00:32:45.669><c> actually</c><00:32:46.210><c> diverge</c><00:32:46.720><c> our</c><00:32:47.049><c> model</c>

00:32:47.399 --> 00:32:47.409 align:start position:0%
overshoot and actually diverge our model
 

00:32:47.409 --> 00:32:52.769 align:start position:0%
overshoot and actually diverge our model
could<00:32:47.559><c> blow</c><00:32:47.710><c> up</c><00:32:49.409><c> ok</c><00:32:50.760><c> ideally</c><00:32:51.760><c> we</c><00:32:52.270><c> want</c><00:32:52.480><c> to</c><00:32:52.600><c> use</c>

00:32:52.769 --> 00:32:52.779 align:start position:0%
could blow up ok ideally we want to use
 

00:32:52.779 --> 00:32:54.630 align:start position:0%
could blow up ok ideally we want to use
learning<00:32:53.080><c> rates</c><00:32:53.350><c> that</c><00:32:53.860><c> are</c><00:32:53.919><c> large</c><00:32:54.340><c> enough</c><00:32:54.520><c> to</c>

00:32:54.630 --> 00:32:54.640 align:start position:0%
learning rates that are large enough to
 

00:32:54.640 --> 00:32:58.590 align:start position:0%
learning rates that are large enough to
avoid<00:32:55.890><c> local</c><00:32:56.890><c> minima</c><00:32:57.220><c> but</c><00:32:57.760><c> also</c><00:32:58.210><c> still</c>

00:32:58.590 --> 00:32:58.600 align:start position:0%
avoid local minima but also still
 

00:32:58.600 --> 00:33:00.299 align:start position:0%
avoid local minima but also still
converge<00:32:58.990><c> to</c><00:32:59.320><c> our</c><00:32:59.440><c> global</c><00:32:59.770><c> minima</c><00:33:00.039><c> so</c><00:33:00.190><c> they</c>

00:33:00.299 --> 00:33:00.309 align:start position:0%
converge to our global minima so they
 

00:33:00.309 --> 00:33:03.180 align:start position:0%
converge to our global minima so they
can<00:33:00.460><c> overshoot</c><00:33:00.970><c> just</c><00:33:01.210><c> enough</c><00:33:01.559><c> to</c><00:33:02.559><c> avoid</c><00:33:02.980><c> some</c>

00:33:03.180 --> 00:33:03.190 align:start position:0%
can overshoot just enough to avoid some
 

00:33:03.190 --> 00:33:05.220 align:start position:0%
can overshoot just enough to avoid some
local<00:33:03.460><c> local</c><00:33:03.730><c> minima</c><00:33:04.059><c> but</c><00:33:04.419><c> then</c><00:33:04.600><c> converge</c><00:33:05.020><c> to</c>

00:33:05.220 --> 00:33:05.230 align:start position:0%
local local minima but then converge to
 

00:33:05.230 --> 00:33:08.850 align:start position:0%
local local minima but then converge to
our<00:33:05.320><c> global</c><00:33:05.620><c> minima</c><00:33:06.450><c> now</c><00:33:07.649><c> how</c><00:33:08.649><c> can</c><00:33:08.710><c> we</c>

00:33:08.850 --> 00:33:08.860 align:start position:0%
our global minima now how can we
 

00:33:08.860 --> 00:33:11.250 align:start position:0%
our global minima now how can we
actually<00:33:09.100><c> set</c><00:33:09.490><c> the</c><00:33:09.610><c> learning</c><00:33:09.880><c> rate</c><00:33:10.029><c> well</c><00:33:10.870><c> one</c>

00:33:11.250 --> 00:33:11.260 align:start position:0%
actually set the learning rate well one
 

00:33:11.260 --> 00:33:12.720 align:start position:0%
actually set the learning rate well one
idea<00:33:11.409><c> is</c><00:33:11.740><c> let's</c><00:33:12.159><c> just</c><00:33:12.309><c> try</c><00:33:12.460><c> a</c><00:33:12.490><c> lot</c><00:33:12.700><c> of</c>

00:33:12.720 --> 00:33:12.730 align:start position:0%
idea is let's just try a lot of
 

00:33:12.730 --> 00:33:14.399 align:start position:0%
idea is let's just try a lot of
different<00:33:12.820><c> things</c><00:33:13.330><c> and</c><00:33:13.570><c> see</c><00:33:13.750><c> what</c><00:33:13.779><c> works</c><00:33:14.110><c> best</c>

00:33:14.399 --> 00:33:14.409 align:start position:0%
different things and see what works best
 

00:33:14.409 --> 00:33:16.620 align:start position:0%
different things and see what works best
but<00:33:15.340><c> I</c><00:33:15.520><c> don't</c><00:33:15.700><c> really</c><00:33:15.820><c> like</c><00:33:16.029><c> the</c><00:33:16.210><c> solution</c>

00:33:16.620 --> 00:33:16.630 align:start position:0%
but I don't really like the solution
 

00:33:16.630 --> 00:33:18.180 align:start position:0%
but I don't really like the solution
let's<00:33:17.020><c> try</c><00:33:17.230><c> and</c><00:33:17.350><c> see</c><00:33:17.470><c> if</c><00:33:17.559><c> we</c><00:33:17.590><c> can</c><00:33:17.799><c> be</c><00:33:17.919><c> a</c><00:33:17.950><c> little</c>

00:33:18.180 --> 00:33:18.190 align:start position:0%
let's try and see if we can be a little
 

00:33:18.190 --> 00:33:21.510 align:start position:0%
let's try and see if we can be a little
smarter<00:33:18.610><c> than</c><00:33:18.730><c> that</c><00:33:19.500><c> how</c><00:33:20.500><c> about</c><00:33:20.590><c> we</c><00:33:20.860><c> tried</c><00:33:21.340><c> to</c>

00:33:21.510 --> 00:33:21.520 align:start position:0%
smarter than that how about we tried to
 

00:33:21.520 --> 00:33:24.510 align:start position:0%
smarter than that how about we tried to
build<00:33:22.059><c> an</c><00:33:22.360><c> adaptive</c><00:33:22.929><c> algorithm</c><00:33:23.500><c> that</c><00:33:23.950><c> changes</c>

00:33:24.510 --> 00:33:24.520 align:start position:0%
build an adaptive algorithm that changes
 

00:33:24.520 --> 00:33:25.480 align:start position:0%
build an adaptive algorithm that changes
its<00:33:24.700><c> learning</c><00:33:24.970><c> rate</c>

00:33:25.480 --> 00:33:25.490 align:start position:0%
its learning rate
 

00:33:25.490 --> 00:33:28.690 align:start position:0%
its learning rate
as<00:33:25.550><c> training</c><00:33:26.420><c> happens</c><00:33:27.160><c> so</c><00:33:28.160><c> this</c><00:33:28.340><c> is</c><00:33:28.520><c> a</c>

00:33:28.690 --> 00:33:28.700 align:start position:0%
as training happens so this is a
 

00:33:28.700 --> 00:33:30.400 align:start position:0%
as training happens so this is a
learning<00:33:29.150><c> rate</c><00:33:29.270><c> that</c><00:33:29.450><c> actually</c><00:33:29.750><c> adapts</c><00:33:30.290><c> to</c>

00:33:30.400 --> 00:33:30.410 align:start position:0%
learning rate that actually adapts to
 

00:33:30.410 --> 00:33:33.010 align:start position:0%
learning rate that actually adapts to
the<00:33:30.650><c> landscape</c><00:33:31.130><c> that</c><00:33:31.280><c> it's</c><00:33:31.429><c> in</c><00:33:31.610><c> so</c><00:33:32.450><c> the</c>

00:33:33.010 --> 00:33:33.020 align:start position:0%
the landscape that it's in so the
 

00:33:33.020 --> 00:33:34.390 align:start position:0%
the landscape that it's in so the
learning<00:33:33.440><c> rate</c><00:33:33.530><c> is</c><00:33:33.620><c> no</c><00:33:33.740><c> longer</c><00:33:33.980><c> a</c><00:33:34.070><c> fixed</c>

00:33:34.390 --> 00:33:34.400 align:start position:0%
learning rate is no longer a fixed
 

00:33:34.400 --> 00:33:35.980 align:start position:0%
learning rate is no longer a fixed
number<00:33:34.700><c> it</c><00:33:34.820><c> can</c><00:33:34.940><c> change</c><00:33:35.240><c> it</c><00:33:35.420><c> can</c><00:33:35.540><c> go</c><00:33:35.660><c> up</c><00:33:35.840><c> and</c>

00:33:35.980 --> 00:33:35.990 align:start position:0%
number it can change it can go up and
 

00:33:35.990 --> 00:33:38.560 align:start position:0%
number it can change it can go up and
down<00:33:36.080><c> and</c><00:33:36.670><c> this</c><00:33:37.670><c> will</c><00:33:37.850><c> change</c><00:33:37.880><c> depending</c><00:33:38.330><c> on</c>

00:33:38.560 --> 00:33:38.570 align:start position:0%
down and this will change depending on
 

00:33:38.570 --> 00:33:42.280 align:start position:0%
down and this will change depending on
the<00:33:38.750><c> location</c><00:33:39.290><c> that</c><00:33:40.450><c> that</c><00:33:41.450><c> the</c><00:33:41.660><c> update</c><00:33:42.200><c> is</c>

00:33:42.280 --> 00:33:42.290 align:start position:0%
the location that that the update is
 

00:33:42.290 --> 00:33:44.200 align:start position:0%
the location that that the update is
currently<00:33:42.620><c> at</c><00:33:42.830><c> the</c><00:33:43.460><c> gradient</c><00:33:43.910><c> in</c><00:33:44.150><c> that</c>

00:33:44.200 --> 00:33:44.210 align:start position:0%
currently at the gradient in that
 

00:33:44.210 --> 00:33:46.750 align:start position:0%
currently at the gradient in that
location<00:33:45.170><c> may</c><00:33:45.830><c> be</c><00:33:45.860><c> how</c><00:33:46.100><c> fast</c><00:33:46.370><c> were</c><00:33:46.550><c> learning</c>

00:33:46.750 --> 00:33:46.760 align:start position:0%
location may be how fast were learning
 

00:33:46.760 --> 00:33:48.640 align:start position:0%
location may be how fast were learning
and<00:33:47.000><c> many</c><00:33:47.150><c> other</c><00:33:47.300><c> many</c><00:33:48.080><c> other</c><00:33:48.200><c> possible</c>

00:33:48.640 --> 00:33:48.650 align:start position:0%
and many other many other possible
 

00:33:48.650 --> 00:33:53.049 align:start position:0%
and many other many other possible
situations<00:33:49.429><c> in</c><00:33:50.320><c> fact</c><00:33:51.580><c> this</c><00:33:52.580><c> process</c><00:33:52.790><c> of</c>

00:33:53.049 --> 00:33:53.059 align:start position:0%
situations in fact this process of
 

00:33:53.059 --> 00:33:55.450 align:start position:0%
situations in fact this process of
optimization<00:33:53.480><c> in</c><00:33:54.020><c> in</c><00:33:54.530><c> deep</c><00:33:54.890><c> neural</c><00:33:55.010><c> networks</c>

00:33:55.450 --> 00:33:55.460 align:start position:0%
optimization in in deep neural networks
 

00:33:55.460 --> 00:33:58.060 align:start position:0%
optimization in in deep neural networks
and<00:33:55.670><c> non</c><00:33:56.360><c> convex</c><00:33:56.800><c> situation</c><00:33:57.800><c> has</c><00:33:57.920><c> been</c>

00:33:58.060 --> 00:33:58.070 align:start position:0%
and non convex situation has been
 

00:33:58.070 --> 00:34:00.850 align:start position:0%
and non convex situation has been
extremely<00:33:58.610><c> explored</c><00:33:59.150><c> there's</c><00:34:00.110><c> many</c><00:34:00.470><c> many</c>

00:34:00.850 --> 00:34:00.860 align:start position:0%
extremely explored there's many many
 

00:34:00.860 --> 00:34:04.150 align:start position:0%
extremely explored there's many many
many<00:34:01.309><c> algorithms</c><00:34:02.030><c> for</c><00:34:02.780><c> computing</c><00:34:03.160><c> adaptive</c>

00:34:04.150 --> 00:34:04.160 align:start position:0%
many algorithms for computing adaptive
 

00:34:04.160 --> 00:34:06.400 align:start position:0%
many algorithms for computing adaptive
learning<00:34:04.340><c> rates</c><00:34:04.670><c> and</c><00:34:05.200><c> here</c><00:34:06.200><c> are</c><00:34:06.290><c> some</c>

00:34:06.400 --> 00:34:06.410 align:start position:0%
learning rates and here are some
 

00:34:06.410 --> 00:34:08.710 align:start position:0%
learning rates and here are some
examples<00:34:06.920><c> that</c><00:34:07.160><c> we</c><00:34:07.280><c> encourage</c><00:34:08.179><c> you</c><00:34:08.360><c> to</c><00:34:08.389><c> try</c>

00:34:08.710 --> 00:34:08.720 align:start position:0%
examples that we encourage you to try
 

00:34:08.720 --> 00:34:11.050 align:start position:0%
examples that we encourage you to try
out<00:34:08.929><c> during</c><00:34:09.740><c> your</c><00:34:09.770><c> labs</c><00:34:10.129><c> to</c><00:34:10.580><c> see</c><00:34:10.730><c> what</c><00:34:10.879><c> works</c>

00:34:11.050 --> 00:34:11.060 align:start position:0%
out during your labs to see what works
 

00:34:11.060 --> 00:34:13.540 align:start position:0%
out during your labs to see what works
best<00:34:11.179><c> and</c><00:34:11.659><c> for</c><00:34:12.200><c> your</c><00:34:12.379><c> problems</c><00:34:12.830><c> especially</c>

00:34:13.540 --> 00:34:13.550 align:start position:0%
best and for your problems especially
 

00:34:13.550 --> 00:34:16.540 align:start position:0%
best and for your problems especially
real-world<00:34:14.179><c> problems</c><00:34:15.010><c> things</c><00:34:16.010><c> can</c><00:34:16.220><c> change</c><00:34:16.460><c> a</c>

00:34:16.540 --> 00:34:16.550 align:start position:0%
real-world problems things can change a
 

00:34:16.550 --> 00:34:18.070 align:start position:0%
real-world problems things can change a
lot<00:34:16.730><c> depending</c><00:34:17.450><c> on</c><00:34:17.510><c> what</c><00:34:17.659><c> you</c><00:34:17.750><c> learn</c><00:34:17.929><c> in</c>

00:34:18.070 --> 00:34:18.080 align:start position:0%
lot depending on what you learn in
 

00:34:18.080 --> 00:34:20.970 align:start position:0%
lot depending on what you learn in
lecture<00:34:18.440><c> and</c><00:34:19.040><c> what</c><00:34:19.220><c> really</c><00:34:19.369><c> works</c><00:34:19.669><c> in</c><00:34:19.850><c> lab</c><00:34:20.060><c> and</c>

00:34:20.970 --> 00:34:20.980 align:start position:0%
lecture and what really works in lab and
 

00:34:20.980 --> 00:34:23.710 align:start position:0%
lecture and what really works in lab and
we<00:34:21.980><c> encourage</c><00:34:22.490><c> you</c><00:34:22.520><c> to</c><00:34:22.760><c> just</c><00:34:22.940><c> experiment</c><00:34:23.360><c> get</c>

00:34:23.710 --> 00:34:23.720 align:start position:0%
we encourage you to just experiment get
 

00:34:23.720 --> 00:34:25.030 align:start position:0%
we encourage you to just experiment get
some<00:34:23.869><c> intuition</c><00:34:24.230><c> about</c><00:34:24.500><c> each</c><00:34:24.800><c> of</c><00:34:24.919><c> these</c>

00:34:25.030 --> 00:34:25.040 align:start position:0%
some intuition about each of these
 

00:34:25.040 --> 00:34:26.470 align:start position:0%
some intuition about each of these
learning<00:34:25.250><c> rates</c><00:34:25.580><c> and</c><00:34:25.790><c> really</c><00:34:26.030><c> understand</c>

00:34:26.470 --> 00:34:26.480 align:start position:0%
learning rates and really understand
 

00:34:26.480 --> 00:34:31.149 align:start position:0%
learning rates and really understand
them<00:34:26.690><c> at</c><00:34:27.080><c> a</c><00:34:27.200><c> higher</c><00:34:27.830><c> level</c><00:34:29.859><c> so</c><00:34:30.859><c> I</c><00:34:30.889><c> want</c><00:34:31.129><c> to</c>

00:34:31.149 --> 00:34:31.159 align:start position:0%
them at a higher level so I want to
 

00:34:31.159 --> 00:34:32.669 align:start position:0%
them at a higher level so I want to
continue<00:34:31.429><c> this</c><00:34:31.669><c> talk</c><00:34:31.909><c> and</c><00:34:32.149><c> really</c><00:34:32.240><c> talk</c><00:34:32.540><c> about</c>

00:34:32.669 --> 00:34:32.679 align:start position:0%
continue this talk and really talk about
 

00:34:32.679 --> 00:34:34.659 align:start position:0%
continue this talk and really talk about
more<00:34:33.679><c> of</c><00:34:33.710><c> the</c><00:34:33.770><c> practice</c><00:34:34.220><c> of</c><00:34:34.369><c> deep</c><00:34:34.520><c> neural</c>

00:34:34.659 --> 00:34:34.669 align:start position:0%
more of the practice of deep neural
 

00:34:34.669 --> 00:34:37.690 align:start position:0%
more of the practice of deep neural
networks<00:34:35.169><c> this</c><00:34:36.169><c> incredibly</c><00:34:36.830><c> powerful</c><00:34:37.129><c> notion</c>

00:34:37.690 --> 00:34:37.700 align:start position:0%
networks this incredibly powerful notion
 

00:34:37.700 --> 00:34:43.080 align:start position:0%
networks this incredibly powerful notion
of<00:34:38.119><c> mini</c><00:34:39.050><c> batching</c><00:34:39.500><c> and</c><00:34:39.970><c> I'll</c><00:34:40.970><c> focus</c><00:34:41.149><c> for</c><00:34:42.109><c> now</c>

00:34:43.080 --> 00:34:43.090 align:start position:0%
of mini batching and I'll focus for now
 

00:34:43.090 --> 00:34:45.820 align:start position:0%
of mini batching and I'll focus for now
if<00:34:44.090><c> we</c><00:34:44.359><c> go</c><00:34:44.600><c> back</c><00:34:44.840><c> to</c><00:34:44.869><c> this</c><00:34:45.230><c> gradient</c><00:34:45.530><c> descent</c>

00:34:45.820 --> 00:34:45.830 align:start position:0%
if we go back to this gradient descent
 

00:34:45.830 --> 00:34:47.349 align:start position:0%
if we go back to this gradient descent
algorithm<00:34:46.280><c> this</c><00:34:46.580><c> is</c><00:34:46.639><c> the</c><00:34:46.820><c> same</c><00:34:47.000><c> one</c><00:34:47.149><c> that</c><00:34:47.179><c> we</c>

00:34:47.349 --> 00:34:47.359 align:start position:0%
algorithm this is the same one that we
 

00:34:47.359 --> 00:34:49.840 align:start position:0%
algorithm this is the same one that we
saw<00:34:47.480><c> before</c><00:34:47.659><c> and</c><00:34:47.960><c> let's</c><00:34:48.340><c> look</c><00:34:49.340><c> at</c><00:34:49.490><c> this</c><00:34:49.639><c> term</c>

00:34:49.840 --> 00:34:49.850 align:start position:0%
saw before and let's look at this term
 

00:34:49.850 --> 00:34:51.700 align:start position:0%
saw before and let's look at this term
again<00:34:50.000><c> so</c><00:34:50.300><c> we</c><00:34:50.419><c> found</c><00:34:50.929><c> out</c><00:34:51.080><c> how</c><00:34:51.230><c> to</c><00:34:51.260><c> compute</c>

00:34:51.700 --> 00:34:51.710 align:start position:0%
again so we found out how to compute
 

00:34:51.710 --> 00:34:54.760 align:start position:0%
again so we found out how to compute
this<00:34:51.980><c> term</c><00:34:52.040><c> using</c><00:34:52.760><c> back</c><00:34:52.970><c> propagation</c><00:34:53.770><c> but</c>

00:34:54.760 --> 00:34:54.770 align:start position:0%
this term using back propagation but
 

00:34:54.770 --> 00:34:56.409 align:start position:0%
this term using back propagation but
actually<00:34:55.100><c> what</c><00:34:55.220><c> I</c><00:34:55.250><c> didn't</c><00:34:55.609><c> tell</c><00:34:55.760><c> you</c><00:34:55.820><c> is</c><00:34:56.359><c> that</c>

00:34:56.409 --> 00:34:56.419 align:start position:0%
actually what I didn't tell you is that
 

00:34:56.419 --> 00:34:58.960 align:start position:0%
actually what I didn't tell you is that
the<00:34:56.869><c> computation</c><00:34:57.200><c> here</c><00:34:57.800><c> is</c><00:34:57.950><c> extremely</c><00:34:58.760><c> calm</c>

00:34:58.960 --> 00:34:58.970 align:start position:0%
the computation here is extremely calm
 

00:34:58.970 --> 00:35:01.720 align:start position:0%
the computation here is extremely calm
is<00:34:59.180><c> extremely</c><00:34:59.810><c> expensive</c><00:35:00.080><c> we</c><00:35:01.070><c> have</c><00:35:01.100><c> a</c><00:35:01.250><c> lot</c><00:35:01.520><c> of</c>

00:35:01.720 --> 00:35:01.730 align:start position:0%
is extremely expensive we have a lot of
 

00:35:01.730 --> 00:35:03.940 align:start position:0%
is extremely expensive we have a lot of
data<00:35:02.270><c> points</c><00:35:02.570><c> potentially</c><00:35:03.230><c> in</c><00:35:03.320><c> our</c><00:35:03.440><c> data</c><00:35:03.680><c> set</c>

00:35:03.940 --> 00:35:03.950 align:start position:0%
data points potentially in our data set
 

00:35:03.950 --> 00:35:06.849 align:start position:0%
data points potentially in our data set
and<00:35:04.130><c> this</c><00:35:04.910><c> takes</c><00:35:05.270><c> as</c><00:35:05.420><c> input</c><00:35:05.840><c> a</c><00:35:06.050><c> summation</c><00:35:06.410><c> over</c>

00:35:06.849 --> 00:35:06.859 align:start position:0%
and this takes as input a summation over
 

00:35:06.859 --> 00:35:08.920 align:start position:0%
and this takes as input a summation over
all<00:35:07.250><c> of</c><00:35:07.460><c> those</c><00:35:07.609><c> data</c><00:35:07.820><c> points</c><00:35:07.910><c> so</c><00:35:08.210><c> if</c><00:35:08.390><c> our</c><00:35:08.510><c> data</c>

00:35:08.920 --> 00:35:08.930 align:start position:0%
all of those data points so if our data
 

00:35:08.930 --> 00:35:11.470 align:start position:0%
all of those data points so if our data
set<00:35:09.200><c> is</c><00:35:09.350><c> millions</c><00:35:10.160><c> of</c><00:35:10.340><c> examples</c><00:35:10.880><c> large</c><00:35:11.270><c> which</c>

00:35:11.470 --> 00:35:11.480 align:start position:0%
set is millions of examples large which
 

00:35:11.480 --> 00:35:13.870 align:start position:0%
set is millions of examples large which
is<00:35:11.510><c> not</c><00:35:12.320><c> that</c><00:35:12.500><c> large</c><00:35:12.740><c> and</c><00:35:13.070><c> the</c><00:35:13.490><c> realm</c><00:35:13.730><c> of</c>

00:35:13.870 --> 00:35:13.880 align:start position:0%
is not that large and the realm of
 

00:35:13.880 --> 00:35:16.540 align:start position:0%
is not that large and the realm of
today's<00:35:14.180><c> deep</c><00:35:14.390><c> neural</c><00:35:14.540><c> networks</c><00:35:15.340><c> but</c><00:35:16.340><c> this</c>

00:35:16.540 --> 00:35:16.550 align:start position:0%
today's deep neural networks but this
 

00:35:16.550 --> 00:35:18.220 align:start position:0%
today's deep neural networks but this
can<00:35:16.700><c> be</c><00:35:16.790><c> extremely</c><00:35:17.210><c> expensive</c><00:35:17.359><c> just</c><00:35:17.869><c> for</c><00:35:18.050><c> one</c>

00:35:18.220 --> 00:35:18.230 align:start position:0%
can be extremely expensive just for one
 

00:35:18.230 --> 00:35:19.510 align:start position:0%
can be extremely expensive just for one
iteration<00:35:18.680><c> so</c><00:35:18.800><c> we</c><00:35:18.890><c> can</c><00:35:19.040><c> compute</c><00:35:19.250><c> this</c><00:35:19.430><c> on</c>

00:35:19.510 --> 00:35:19.520 align:start position:0%
iteration so we can compute this on
 

00:35:19.520 --> 00:35:22.660 align:start position:0%
iteration so we can compute this on
every<00:35:19.730><c> iteration</c><00:35:19.880><c> instead</c><00:35:20.810><c> let's</c><00:35:21.500><c> create</c><00:35:22.460><c> a</c>

00:35:22.660 --> 00:35:22.670 align:start position:0%
every iteration instead let's create a
 

00:35:22.670 --> 00:35:24.040 align:start position:0%
every iteration instead let's create a
variant<00:35:23.180><c> of</c><00:35:23.270><c> this</c><00:35:23.390><c> algorithm</c><00:35:23.720><c> called</c>

00:35:24.040 --> 00:35:24.050 align:start position:0%
variant of this algorithm called
 

00:35:24.050 --> 00:35:26.260 align:start position:0%
variant of this algorithm called
stochastic<00:35:24.440><c> gradient</c><00:35:24.770><c> descent</c><00:35:25.180><c> where</c><00:35:26.180><c> we</c>

00:35:26.260 --> 00:35:26.270 align:start position:0%
stochastic gradient descent where we
 

00:35:26.270 --> 00:35:28.120 align:start position:0%
stochastic gradient descent where we
compute<00:35:26.600><c> the</c><00:35:26.690><c> gradient</c><00:35:26.720><c> just</c><00:35:27.320><c> using</c><00:35:27.680><c> a</c><00:35:27.800><c> single</c>

00:35:28.120 --> 00:35:28.130 align:start position:0%
compute the gradient just using a single
 

00:35:28.130 --> 00:35:31.660 align:start position:0%
compute the gradient just using a single
training<00:35:28.700><c> example</c><00:35:29.560><c> now</c><00:35:30.560><c> this</c><00:35:31.040><c> is</c><00:35:31.250><c> nice</c>

00:35:31.660 --> 00:35:31.670 align:start position:0%
training example now this is nice
 

00:35:31.670 --> 00:35:33.190 align:start position:0%
training example now this is nice
because<00:35:31.940><c> it's</c><00:35:32.240><c> really</c><00:35:32.390><c> easy</c><00:35:32.480><c> to</c><00:35:32.720><c> compute</c><00:35:33.050><c> the</c>

00:35:33.190 --> 00:35:33.200 align:start position:0%
because it's really easy to compute the
 

00:35:33.200 --> 00:35:34.270 align:start position:0%
because it's really easy to compute the
gradient<00:35:33.560><c> for</c><00:35:33.650><c> a</c><00:35:33.680><c> single</c><00:35:33.950><c> training</c><00:35:34.160><c> example</c>

00:35:34.270 --> 00:35:34.280 align:start position:0%
gradient for a single training example
 

00:35:34.280 --> 00:35:36.640 align:start position:0%
gradient for a single training example
it's<00:35:34.730><c> not</c><00:35:34.880><c> nearly</c><00:35:35.150><c> as</c><00:35:35.300><c> intense</c><00:35:35.810><c> as</c><00:35:36.050><c> over</c><00:35:36.530><c> the</c>

00:35:36.640 --> 00:35:36.650 align:start position:0%
it's not nearly as intense as over the
 

00:35:36.650 --> 00:35:39.310 align:start position:0%
it's not nearly as intense as over the
entire<00:35:36.920><c> training</c><00:35:37.220><c> set</c><00:35:37.490><c> but</c><00:35:37.760><c> as</c><00:35:38.690><c> the</c><00:35:38.960><c> name</c>

00:35:39.310 --> 00:35:39.320 align:start position:0%
entire training set but as the name
 

00:35:39.320 --> 00:35:41.110 align:start position:0%
entire training set but as the name
might<00:35:39.410><c> suggest</c><00:35:39.650><c> this</c><00:35:40.070><c> is</c><00:35:40.250><c> a</c><00:35:40.280><c> more</c><00:35:40.580><c> stochastic</c>

00:35:41.110 --> 00:35:41.120 align:start position:0%
might suggest this is a more stochastic
 

00:35:41.120 --> 00:35:44.500 align:start position:0%
might suggest this is a more stochastic
estimate<00:35:41.840><c> it's</c><00:35:42.500><c> much</c><00:35:42.680><c> more</c><00:35:42.830><c> noisy</c><00:35:43.310><c> it</c><00:35:44.300><c> can</c>

00:35:44.500 --> 00:35:44.510 align:start position:0%
estimate it's much more noisy it can
 

00:35:44.510 --> 00:35:46.450 align:start position:0%
estimate it's much more noisy it can
make<00:35:44.690><c> us</c><00:35:44.720><c> jump</c><00:35:45.320><c> around</c><00:35:45.440><c> the</c><00:35:45.710><c> landscape</c><00:35:46.220><c> in</c>

00:35:46.450 --> 00:35:46.460 align:start position:0%
make us jump around the landscape in
 

00:35:46.460 --> 00:35:48.190 align:start position:0%
make us jump around the landscape in
ways<00:35:46.610><c> that</c><00:35:46.820><c> we</c><00:35:46.940><c> didn't</c><00:35:47.390><c> anticipate</c><00:35:47.630><c> doesn't</c>

00:35:48.190 --> 00:35:48.200 align:start position:0%
ways that we didn't anticipate doesn't
 

00:35:48.200 --> 00:35:50.050 align:start position:0%
ways that we didn't anticipate doesn't
actually<00:35:48.440><c> represent</c><00:35:48.800><c> the</c><00:35:49.160><c> true</c><00:35:49.460><c> gradient</c><00:35:49.910><c> of</c>

00:35:50.050 --> 00:35:50.060 align:start position:0%
actually represent the true gradient of
 

00:35:50.060 --> 00:35:51.700 align:start position:0%
actually represent the true gradient of
our<00:35:50.210><c> data</c><00:35:50.420><c> set</c><00:35:50.690><c> because</c><00:35:51.110><c> it's</c><00:35:51.230><c> only</c><00:35:51.380><c> a</c><00:35:51.500><c> single</c>

00:35:51.700 --> 00:35:51.710 align:start position:0%
our data set because it's only a single
 

00:35:51.710 --> 00:35:54.760 align:start position:0%
our data set because it's only a single
point<00:35:52.240><c> so</c><00:35:53.240><c> what's</c><00:35:53.420><c> the</c><00:35:53.540><c> middle</c><00:35:53.690><c> ground</c><00:35:53.900><c> how</c>

00:35:54.760 --> 00:35:54.770 align:start position:0%
point so what's the middle ground how
 

00:35:54.770 --> 00:35:58.750 align:start position:0%
point so what's the middle ground how
about<00:35:54.950><c> we</c><00:35:55.130><c> define</c><00:35:56.030><c> a</c><00:35:56.500><c> mini</c><00:35:57.500><c> batch</c><00:35:57.740><c> of</c><00:35:58.100><c> B</c><00:35:58.460><c> data</c>

00:35:58.750 --> 00:35:58.760 align:start position:0%
about we define a mini batch of B data
 

00:35:58.760 --> 00:36:01.330 align:start position:0%
about we define a mini batch of B data
points<00:35:59.260><c> compute</c><00:36:00.260><c> the</c><00:36:00.470><c> average</c><00:36:00.710><c> gradient</c>

00:36:01.330 --> 00:36:01.340 align:start position:0%
points compute the average gradient
 

00:36:01.340 --> 00:36:04.150 align:start position:0%
points compute the average gradient
across<00:36:01.610><c> those</c><00:36:01.940><c> B</c><00:36:02.120><c> data</c><00:36:02.390><c> points</c><00:36:02.780><c> and</c><00:36:03.160><c> actually</c>

00:36:04.150 --> 00:36:04.160 align:start position:0%
across those B data points and actually
 

00:36:04.160 --> 00:36:06.070 align:start position:0%
across those B data points and actually
use<00:36:04.760><c> that</c><00:36:04.790><c> as</c><00:36:05.150><c> an</c><00:36:05.270><c> estimate</c><00:36:05.600><c> of</c><00:36:05.780><c> our</c><00:36:05.930><c> true</c>

00:36:06.070 --> 00:36:06.080 align:start position:0%
use that as an estimate of our true
 

00:36:06.080 --> 00:36:08.590 align:start position:0%
use that as an estimate of our true
gradient<00:36:06.490><c> now</c><00:36:07.490><c> this</c><00:36:07.640><c> is</c><00:36:07.790><c> much</c><00:36:08.180><c> faster</c><00:36:08.210><c> than</c>

00:36:08.590 --> 00:36:08.600 align:start position:0%
gradient now this is much faster than
 

00:36:08.600 --> 00:36:10.150 align:start position:0%
gradient now this is much faster than
computing<00:36:09.140><c> the</c><00:36:09.230><c> estimate</c><00:36:09.590><c> over</c><00:36:09.680><c> the</c><00:36:09.920><c> entire</c>

00:36:10.150 --> 00:36:10.160 align:start position:0%
computing the estimate over the entire
 

00:36:10.160 --> 00:36:11.500 align:start position:0%
computing the estimate over the entire
batch<00:36:10.370><c> because</c><00:36:10.580><c> B</c><00:36:10.880><c> is</c><00:36:11.000><c> usually</c><00:36:11.300><c> something</c>

00:36:11.500 --> 00:36:11.510 align:start position:0%
batch because B is usually something
 

00:36:11.510 --> 00:36:14.770 align:start position:0%
batch because B is usually something
like<00:36:11.750><c> 10</c><00:36:11.960><c> to</c><00:36:11.990><c> 100</c><00:36:12.530><c> and</c><00:36:13.540><c> it's</c><00:36:14.540><c> much</c><00:36:14.750><c> more</c>

00:36:14.770 --> 00:36:14.780 align:start position:0%
like 10 to 100 and it's much more
 

00:36:14.780 --> 00:36:17.020 align:start position:0%
like 10 to 100 and it's much more
accurate<00:36:15.080><c> than</c><00:36:15.440><c> SGD</c><00:36:15.920><c> because</c><00:36:16.580><c> we're</c><00:36:16.910><c> not</c>

00:36:17.020 --> 00:36:17.030 align:start position:0%
accurate than SGD because we're not
 

00:36:17.030 --> 00:36:18.490 align:start position:0%
accurate than SGD because we're not
taking<00:36:17.390><c> a</c><00:36:17.450><c> single</c><00:36:17.690><c> example</c><00:36:18.230><c> but</c><00:36:18.380><c> we're</c>

00:36:18.490 --> 00:36:18.500 align:start position:0%
taking a single example but we're
 

00:36:18.500 --> 00:36:20.680 align:start position:0%
taking a single example but we're
learning<00:36:18.650><c> over</c><00:36:18.950><c> a</c><00:36:19.280><c> smaller</c><00:36:19.700><c> batch</c><00:36:19.940><c> a</c><00:36:20.240><c> larger</c>

00:36:20.680 --> 00:36:20.690 align:start position:0%
learning over a smaller batch a larger
 

00:36:20.690 --> 00:36:24.250 align:start position:0%
learning over a smaller batch a larger
batch<00:36:20.840><c> sorry</c><00:36:22.210><c> now</c><00:36:23.210><c> the</c><00:36:23.540><c> more</c><00:36:23.720><c> accurate</c><00:36:24.170><c> our</c>

00:36:24.250 --> 00:36:24.260 align:start position:0%
batch sorry now the more accurate our
 

00:36:24.260 --> 00:36:27.490 align:start position:0%
batch sorry now the more accurate our
gradient<00:36:24.560><c> estimation</c><00:36:25.310><c> is</c><00:36:25.550><c> that</c><00:36:26.540><c> means</c><00:36:26.840><c> the</c>

00:36:27.490 --> 00:36:27.500 align:start position:0%
gradient estimation is that means the
 

00:36:27.500 --> 00:36:30.130 align:start position:0%
gradient estimation is that means the
more<00:36:27.710><c> or</c><00:36:28.160><c> the</c><00:36:28.790><c> easier</c><00:36:29.150><c> it</c><00:36:29.300><c> will</c><00:36:29.420><c> be</c><00:36:29.630><c> for</c><00:36:29.660><c> us</c><00:36:29.990><c> to</c>

00:36:30.130 --> 00:36:30.140 align:start position:0%
more or the easier it will be for us to
 

00:36:30.140 --> 00:36:33.520 align:start position:0%
more or the easier it will be for us to
converge<00:36:30.530><c> to</c><00:36:30.890><c> the</c><00:36:31.400><c> solution</c><00:36:31.520><c> faster</c><00:36:32.530><c> means</c>

00:36:33.520 --> 00:36:33.530 align:start position:0%
converge to the solution faster means
 

00:36:33.530 --> 00:36:35.470 align:start position:0%
converge to the solution faster means
will<00:36:33.740><c> converge</c><00:36:34.010><c> smoother</c><00:36:34.520><c> because</c><00:36:34.850><c> we'll</c>

00:36:35.470 --> 00:36:35.480 align:start position:0%
will converge smoother because we'll
 

00:36:35.480 --> 00:36:37.420 align:start position:0%
will converge smoother because we'll
actually<00:36:35.780><c> follow</c><00:36:36.230><c> the</c><00:36:36.440><c> true</c><00:36:36.650><c> landscape</c><00:36:37.190><c> that</c>

00:36:37.420 --> 00:36:37.430 align:start position:0%
actually follow the true landscape that
 

00:36:37.430 --> 00:36:39.790 align:start position:0%
actually follow the true landscape that
exists<00:36:38.200><c> it</c><00:36:39.200><c> also</c><00:36:39.320><c> means</c><00:36:39.590><c> that</c><00:36:39.650><c> we</c><00:36:39.770><c> can</c>

00:36:39.790 --> 00:36:39.800 align:start position:0%
exists it also means that we can
 

00:36:39.800 --> 00:36:41.500 align:start position:0%
exists it also means that we can
increase<00:36:40.190><c> our</c><00:36:40.400><c> learning</c><00:36:40.700><c> rate</c><00:36:40.850><c> to</c><00:36:40.970><c> trust</c><00:36:41.300><c> each</c>

00:36:41.500 --> 00:36:41.510 align:start position:0%
increase our learning rate to trust each
 

00:36:41.510 --> 00:36:45.520 align:start position:0%
increase our learning rate to trust each
update<00:36:41.750><c> more</c><00:36:43.930><c> this</c><00:36:44.930><c> also</c><00:36:45.170><c> allows</c><00:36:45.500><c> for</c>

00:36:45.520 --> 00:36:45.530 align:start position:0%
update more this also allows for
 

00:36:45.530 --> 00:36:47.980 align:start position:0%
update more this also allows for
massively<00:36:46.220><c> parallel</c><00:36:46.670><c> Liza</c><00:36:47.090><c> become</c><00:36:47.540><c> petition</c>

00:36:47.980 --> 00:36:47.990 align:start position:0%
massively parallel Liza become petition
 

00:36:47.990 --> 00:36:50.920 align:start position:0%
massively parallel Liza become petition
if<00:36:48.350><c> we</c><00:36:48.860><c> split</c><00:36:49.100><c> up</c><00:36:49.220><c> batches</c><00:36:49.790><c> on</c><00:36:50.030><c> different</c>

00:36:50.920 --> 00:36:50.930 align:start position:0%
if we split up batches on different
 

00:36:50.930 --> 00:36:53.350 align:start position:0%
if we split up batches on different
workers<00:36:51.200><c> on</c><00:36:51.680><c> different</c><00:36:52.220><c> GPUs</c><00:36:52.670><c> or</c><00:36:52.940><c> different</c>

00:36:53.350 --> 00:36:53.360 align:start position:0%
workers on different GPUs or different
 

00:36:53.360 --> 00:36:56.770 align:start position:0%
workers on different GPUs or different
threads<00:36:54.520><c> we</c><00:36:55.520><c> can</c><00:36:55.670><c> achieve</c><00:36:55.760><c> even</c><00:36:56.120><c> higher</c><00:36:56.270><c> speed</c>

00:36:56.770 --> 00:36:56.780 align:start position:0%
threads we can achieve even higher speed
 

00:36:56.780 --> 00:36:58.540 align:start position:0%
threads we can achieve even higher speed
ups<00:36:56.930><c> because</c><00:36:57.050><c> each</c><00:36:57.350><c> thread</c><00:36:57.950><c> can</c><00:36:58.190><c> handle</c><00:36:58.430><c> its</c>

00:36:58.540 --> 00:36:58.550 align:start position:0%
ups because each thread can handle its
 

00:36:58.550 --> 00:36:59.770 align:start position:0%
ups because each thread can handle its
own<00:36:58.640><c> batch</c><00:36:58.910><c> then</c><00:36:59.210><c> they</c><00:36:59.330><c> can</c><00:36:59.480><c> come</c><00:36:59.630><c> back</c>

00:36:59.770 --> 00:36:59.780 align:start position:0%
own batch then they can come back
 

00:36:59.780 --> 00:37:01.870 align:start position:0%
own batch then they can come back
together<00:37:00.020><c> and</c><00:37:00.440><c> aggregate</c><00:37:01.220><c> together</c><00:37:01.520><c> to</c>

00:37:01.870 --> 00:37:01.880 align:start position:0%
together and aggregate together to
 

00:37:01.880 --> 00:37:04.030 align:start position:0%
together and aggregate together to
basically<00:37:02.300><c> create</c><00:37:03.110><c> that</c><00:37:03.470><c> single</c><00:37:03.890><c> learning</c>

00:37:04.030 --> 00:37:04.040 align:start position:0%
basically create that single learning
 

00:37:04.040 --> 00:37:06.520 align:start position:0%
basically create that single learning
rate<00:37:04.280><c> or</c><00:37:04.490><c> completely</c><00:37:05.090><c> complete</c><00:37:05.930><c> that</c><00:37:06.110><c> single</c>

00:37:06.520 --> 00:37:06.530 align:start position:0%
rate or completely complete that single
 

00:37:06.530 --> 00:37:11.140 align:start position:0%
rate or completely complete that single
training<00:37:06.950><c> iteration</c><00:37:09.520><c> now</c><00:37:10.520><c> finally</c><00:37:10.880><c> the</c><00:37:11.000><c> last</c>

00:37:11.140 --> 00:37:11.150 align:start position:0%
training iteration now finally the last
 

00:37:11.150 --> 00:37:13.030 align:start position:0%
training iteration now finally the last
topic<00:37:11.420><c> I</c><00:37:11.600><c> want</c><00:37:11.780><c> to</c><00:37:11.840><c> talk</c><00:37:11.990><c> about</c><00:37:12.170><c> is</c><00:37:12.530><c> that</c><00:37:12.980><c> of</c>

00:37:13.030 --> 00:37:13.040 align:start position:0%
topic I want to talk about is that of
 

00:37:13.040 --> 00:37:17.410 align:start position:0%
topic I want to talk about is that of
overfitting<00:37:13.730><c> and</c><00:37:13.850><c> regularization</c><00:37:16.420><c> really</c>

00:37:17.410 --> 00:37:17.420 align:start position:0%
overfitting and regularization really
 

00:37:17.420 --> 00:37:19.480 align:start position:0%
overfitting and regularization really
this<00:37:17.600><c> is</c><00:37:17.720><c> a</c><00:37:17.750><c> problem</c><00:37:18.140><c> of</c><00:37:18.490><c> generalization</c>

00:37:19.480 --> 00:37:19.490 align:start position:0%
this is a problem of generalization
 

00:37:19.490 --> 00:37:23.380 align:start position:0%
this is a problem of generalization
which<00:37:20.210><c> is</c><00:37:20.540><c> one</c><00:37:20.930><c> of</c><00:37:21.790><c> the</c><00:37:22.790><c> most</c><00:37:23.090><c> fundamental</c>

00:37:23.380 --> 00:37:23.390 align:start position:0%
which is one of the most fundamental
 

00:37:23.390 --> 00:37:25.390 align:start position:0%
which is one of the most fundamental
problems<00:37:23.990><c> in</c><00:37:24.500><c> all</c><00:37:24.770><c> of</c><00:37:24.920><c> artificial</c>

00:37:25.390 --> 00:37:25.400 align:start position:0%
problems in all of artificial
 

00:37:25.400 --> 00:37:28.390 align:start position:0%
problems in all of artificial
intelligence<00:37:25.690><c> not</c><00:37:26.690><c> just</c><00:37:26.720><c> deep</c><00:37:27.050><c> learning</c><00:37:27.400><c> but</c>

00:37:28.390 --> 00:37:28.400 align:start position:0%
intelligence not just deep learning but
 

00:37:28.400 --> 00:37:31.600 align:start position:0%
intelligence not just deep learning but
all<00:37:28.550><c> of</c><00:37:28.640><c> artificial</c><00:37:29.150><c> intelligence</c><00:37:29.240><c> and</c><00:37:30.610><c> for</c>

00:37:31.600 --> 00:37:31.610 align:start position:0%
all of artificial intelligence and for
 

00:37:31.610 --> 00:37:32.890 align:start position:0%
all of artificial intelligence and for
those<00:37:31.700><c> of</c><00:37:31.760><c> you</c><00:37:31.940><c> who</c><00:37:32.060><c> aren't</c><00:37:32.210><c> familiar</c><00:37:32.330><c> let</c><00:37:32.780><c> me</c>

00:37:32.890 --> 00:37:32.900 align:start position:0%
those of you who aren't familiar let me
 

00:37:32.900 --> 00:37:34.630 align:start position:0%
those of you who aren't familiar let me
just<00:37:33.080><c> go</c><00:37:33.470><c> over</c><00:37:33.500><c> in</c><00:37:33.800><c> a</c><00:37:33.860><c> high</c><00:37:33.980><c> level</c><00:37:34.220><c> what</c>

00:37:34.630 --> 00:37:34.640 align:start position:0%
just go over in a high level what
 

00:37:34.640 --> 00:37:36.730 align:start position:0%
just go over in a high level what
overfitting<00:37:35.390><c> is</c><00:37:35.630><c> what</c><00:37:36.170><c> it</c><00:37:36.290><c> means</c><00:37:36.440><c> to</c>

00:37:36.730 --> 00:37:36.740 align:start position:0%
overfitting is what it means to
 

00:37:36.740 --> 00:37:39.580 align:start position:0%
overfitting is what it means to
generalize<00:37:37.990><c> ideally</c><00:37:38.990><c> in</c><00:37:39.170><c> machine</c><00:37:39.470><c> learning</c>

00:37:39.580 --> 00:37:39.590 align:start position:0%
generalize ideally in machine learning
 

00:37:39.590 --> 00:37:41.290 align:start position:0%
generalize ideally in machine learning
we<00:37:39.890><c> want</c><00:37:39.920><c> a</c><00:37:40.220><c> model</c><00:37:40.400><c> that</c><00:37:40.610><c> accurately</c>

00:37:41.290 --> 00:37:41.300 align:start position:0%
we want a model that accurately
 

00:37:41.300 --> 00:37:44.140 align:start position:0%
we want a model that accurately
describes<00:37:41.780><c> our</c><00:37:42.080><c> test</c><00:37:42.440><c> data</c><00:37:42.860><c> not</c><00:37:43.670><c> our</c><00:37:43.820><c> training</c>

00:37:44.140 --> 00:37:44.150 align:start position:0%
describes our test data not our training
 

00:37:44.150 --> 00:37:48.100 align:start position:0%
describes our test data not our training
data<00:37:44.330><c> but</c><00:37:44.780><c> our</c><00:37:44.900><c> test</c><00:37:45.170><c> data</c><00:37:46.750><c> said</c><00:37:47.750><c> differently</c>

00:37:48.100 --> 00:37:48.110 align:start position:0%
data but our test data said differently
 

00:37:48.110 --> 00:37:49.960 align:start position:0%
data but our test data said differently
we<00:37:48.320><c> want</c><00:37:48.500><c> to</c><00:37:48.650><c> build</c><00:37:48.800><c> models</c><00:37:49.340><c> that</c><00:37:49.610><c> can</c><00:37:49.760><c> learn</c>

00:37:49.960 --> 00:37:49.970 align:start position:0%
we want to build models that can learn
 

00:37:49.970 --> 00:37:53.170 align:start position:0%
we want to build models that can learn
representations<00:37:51.160><c> from</c><00:37:52.160><c> our</c><00:37:52.370><c> training</c><00:37:52.700><c> data</c>

00:37:53.170 --> 00:37:53.180 align:start position:0%
representations from our training data
 

00:37:53.180 --> 00:37:55.780 align:start position:0%
representations from our training data
still<00:37:53.510><c> generalized</c><00:37:54.200><c> well</c><00:37:54.440><c> on</c><00:37:54.650><c> unseen</c><00:37:55.280><c> test</c>

00:37:55.780 --> 00:37:55.790 align:start position:0%
still generalized well on unseen test
 

00:37:55.790 --> 00:37:58.690 align:start position:0%
still generalized well on unseen test
data<00:37:56.500><c> assume</c><00:37:57.500><c> we</c><00:37:57.589><c> want</c><00:37:57.710><c> to</c><00:37:57.890><c> build</c><00:37:58.130><c> a</c><00:37:58.250><c> line</c><00:37:58.520><c> to</c>

00:37:58.690 --> 00:37:58.700 align:start position:0%
data assume we want to build a line to
 

00:37:58.700 --> 00:38:00.940 align:start position:0%
data assume we want to build a line to
describe<00:37:59.030><c> these</c><00:37:59.180><c> points</c><00:37:59.650><c> under</c><00:38:00.650><c> fitting</c>

00:38:00.940 --> 00:38:00.950 align:start position:0%
describe these points under fitting
 

00:38:00.950 --> 00:38:03.040 align:start position:0%
describe these points under fitting
describes<00:38:01.309><c> the</c><00:38:01.460><c> process</c><00:38:01.819><c> on</c><00:38:01.970><c> the</c><00:38:02.059><c> left</c><00:38:02.270><c> where</c>

00:38:03.040 --> 00:38:03.050 align:start position:0%
describes the process on the left where
 

00:38:03.050 --> 00:38:05.349 align:start position:0%
describes the process on the left where
the<00:38:03.290><c> complexity</c><00:38:03.800><c> of</c><00:38:03.920><c> our</c><00:38:04.130><c> model</c><00:38:04.430><c> is</c><00:38:04.819><c> simply</c>

00:38:05.349 --> 00:38:05.359 align:start position:0%
the complexity of our model is simply
 

00:38:05.359 --> 00:38:07.210 align:start position:0%
the complexity of our model is simply
not<00:38:05.540><c> high</c><00:38:05.780><c> enough</c><00:38:05.809><c> to</c><00:38:06.079><c> capture</c><00:38:06.500><c> the</c><00:38:06.710><c> nuances</c>

00:38:07.210 --> 00:38:07.220 align:start position:0%
not high enough to capture the nuances
 

00:38:07.220 --> 00:38:10.089 align:start position:0%
not high enough to capture the nuances
of<00:38:07.280><c> our</c><00:38:07.490><c> data</c><00:38:08.109><c> if</c><00:38:09.109><c> we</c><00:38:09.319><c> go</c><00:38:09.410><c> to</c><00:38:09.470><c> overfitting</c><00:38:09.950><c> on</c>

00:38:10.089 --> 00:38:10.099 align:start position:0%
of our data if we go to overfitting on
 

00:38:10.099 --> 00:38:12.849 align:start position:0%
of our data if we go to overfitting on
the<00:38:10.190><c> right</c><00:38:10.369><c> we're</c><00:38:11.119><c> actually</c><00:38:11.300><c> having</c><00:38:12.290><c> to</c>

00:38:12.849 --> 00:38:12.859 align:start position:0%
the right we're actually having to
 

00:38:12.859 --> 00:38:14.740 align:start position:0%
the right we're actually having to
complex<00:38:13.309><c> of</c><00:38:13.430><c> a</c><00:38:13.490><c> model</c><00:38:13.819><c> and</c><00:38:14.000><c> actually</c><00:38:14.660><c> just</c>

00:38:14.740 --> 00:38:14.750 align:start position:0%
complex of a model and actually just
 

00:38:14.750 --> 00:38:16.900 align:start position:0%
complex of a model and actually just
memorizing<00:38:15.410><c> our</c><00:38:15.470><c> training</c><00:38:15.890><c> data</c><00:38:16.099><c> which</c><00:38:16.670><c> means</c>

00:38:16.900 --> 00:38:16.910 align:start position:0%
memorizing our training data which means
 

00:38:16.910 --> 00:38:18.400 align:start position:0%
memorizing our training data which means
that<00:38:17.119><c> if</c><00:38:17.240><c> we</c><00:38:17.270><c> introduce</c><00:38:17.690><c> a</c><00:38:17.780><c> new</c><00:38:17.809><c> test</c><00:38:18.170><c> data</c>

00:38:18.400 --> 00:38:18.410 align:start position:0%
that if we introduce a new test data
 

00:38:18.410 --> 00:38:20.319 align:start position:0%
that if we introduce a new test data
point<00:38:18.680><c> it's</c><00:38:19.190><c> not</c><00:38:19.430><c> going</c><00:38:19.579><c> to</c><00:38:19.670><c> generalize</c><00:38:20.059><c> well</c>

00:38:20.319 --> 00:38:20.329 align:start position:0%
point it's not going to generalize well
 

00:38:20.329 --> 00:38:22.240 align:start position:0%
point it's not going to generalize well
ideally<00:38:21.200><c> what</c><00:38:21.440><c> we</c><00:38:21.530><c> want</c><00:38:21.710><c> to</c><00:38:21.829><c> something</c><00:38:22.010><c> in</c><00:38:22.190><c> the</c>

00:38:22.240 --> 00:38:22.250 align:start position:0%
ideally what we want to something in the
 

00:38:22.250 --> 00:38:24.520 align:start position:0%
ideally what we want to something in the
middle<00:38:22.430><c> which</c><00:38:23.329><c> is</c><00:38:23.480><c> not</c><00:38:23.660><c> too</c><00:38:23.839><c> complex</c><00:38:24.260><c> to</c>

00:38:24.520 --> 00:38:24.530 align:start position:0%
middle which is not too complex to
 

00:38:24.530 --> 00:38:28.890 align:start position:0%
middle which is not too complex to
memorize<00:38:24.890><c> all</c><00:38:25.040><c> the</c><00:38:25.160><c> training</c><00:38:25.550><c> data</c><00:38:25.760><c> but</c><00:38:26.859><c> still</c>

00:38:28.890 --> 00:38:28.900 align:start position:0%
memorize all the training data but still
 

00:38:28.900 --> 00:38:31.569 align:start position:0%
memorize all the training data but still
contains<00:38:29.900><c> the</c><00:38:30.079><c> capacity</c><00:38:30.650><c> to</c><00:38:30.950><c> learn</c><00:38:31.160><c> some</c><00:38:31.550><c> of</c>

00:38:31.569 --> 00:38:31.579 align:start position:0%
contains the capacity to learn some of
 

00:38:31.579 --> 00:38:36.490 align:start position:0%
contains the capacity to learn some of
these<00:38:31.700><c> nuances</c><00:38:31.940><c> in</c><00:38:32.420><c> this</c><00:38:33.020><c> in</c><00:38:33.290><c> the</c><00:38:33.440><c> test</c><00:38:33.859><c> set</c><00:38:35.500><c> so</c>

00:38:36.490 --> 00:38:36.500 align:start position:0%
these nuances in this in the test set so
 

00:38:36.500 --> 00:38:38.170 align:start position:0%
these nuances in this in the test set so
address<00:38:36.770><c> to</c><00:38:37.190><c> address</c><00:38:37.280><c> this</c><00:38:37.579><c> problem</c><00:38:37.760><c> let's</c>

00:38:38.170 --> 00:38:38.180 align:start position:0%
address to address this problem let's
 

00:38:38.180 --> 00:38:39.730 align:start position:0%
address to address this problem let's
talk<00:38:38.450><c> about</c><00:38:38.630><c> this</c><00:38:39.140><c> technique</c><00:38:39.530><c> called</c>

00:38:39.730 --> 00:38:39.740 align:start position:0%
talk about this technique called
 

00:38:39.740 --> 00:38:42.730 align:start position:0%
talk about this technique called
regularization<00:38:40.930><c> now</c><00:38:41.930><c> regularization</c><00:38:42.290><c> is</c>

00:38:42.730 --> 00:38:42.740 align:start position:0%
regularization now regularization is
 

00:38:42.740 --> 00:38:45.220 align:start position:0%
regularization now regularization is
just<00:38:42.980><c> this</c><00:38:43.250><c> way</c><00:38:43.790><c> that</c><00:38:44.420><c> you</c><00:38:44.540><c> can</c><00:38:44.750><c> discourage</c>

00:38:45.220 --> 00:38:45.230 align:start position:0%
just this way that you can discourage
 

00:38:45.230 --> 00:38:47.790 align:start position:0%
just this way that you can discourage
your<00:38:45.589><c> models</c><00:38:45.980><c> from</c><00:38:46.130><c> becoming</c><00:38:46.670><c> too</c><00:38:47.000><c> complex</c>

00:38:47.790 --> 00:38:47.800 align:start position:0%
your models from becoming too complex
 

00:38:47.800 --> 00:38:51.700 align:start position:0%
your models from becoming too complex
and<00:38:49.119><c> absolutely</c><00:38:50.119><c> as</c><00:38:50.480><c> we've</c><00:38:50.809><c> seen</c><00:38:51.170><c> before</c><00:38:51.380><c> this</c>

00:38:51.700 --> 00:38:51.710 align:start position:0%
and absolutely as we've seen before this
 

00:38:51.710 --> 00:38:54.130 align:start position:0%
and absolutely as we've seen before this
is<00:38:51.770><c> extremely</c><00:38:52.280><c> critical</c><00:38:52.690><c> because</c><00:38:53.690><c> we</c><00:38:53.900><c> don't</c>

00:38:54.130 --> 00:38:54.140 align:start position:0%
is extremely critical because we don't
 

00:38:54.140 --> 00:38:56.530 align:start position:0%
is extremely critical because we don't
want<00:38:54.349><c> our</c><00:38:54.440><c> data</c><00:38:54.740><c> we</c><00:38:55.490><c> don't</c><00:38:55.640><c> want</c><00:38:55.940><c> our</c><00:38:56.000><c> models</c>

00:38:56.530 --> 00:38:56.540 align:start position:0%
want our data we don't want our models
 

00:38:56.540 --> 00:38:59.920 align:start position:0%
want our data we don't want our models
to<00:38:57.410><c> just</c><00:38:57.710><c> memorize</c><00:38:57.980><c> data</c><00:38:58.549><c> and</c><00:38:58.819><c> only</c><00:38:59.420><c> do</c><00:38:59.750><c> well</c>

00:38:59.920 --> 00:38:59.930 align:start position:0%
to just memorize data and only do well
 

00:38:59.930 --> 00:39:05.230 align:start position:0%
to just memorize data and only do well
in<00:39:00.079><c> our</c><00:39:00.170><c> training</c><00:39:00.500><c> set</c><00:39:03.760><c> one</c><00:39:04.760><c> of</c><00:39:04.880><c> the</c><00:39:05.030><c> most</c>

00:39:05.230 --> 00:39:05.240 align:start position:0%
in our training set one of the most
 

00:39:05.240 --> 00:39:07.660 align:start position:0%
in our training set one of the most
popular<00:39:05.720><c> techniques</c><00:39:06.440><c> for</c><00:39:06.859><c> regularization</c><00:39:07.190><c> in</c>

00:39:07.660 --> 00:39:07.670 align:start position:0%
popular techniques for regularization in
 

00:39:07.670 --> 00:39:10.240 align:start position:0%
popular techniques for regularization in
neural<00:39:07.910><c> networks</c><00:39:08.240><c> is</c><00:39:08.589><c> dropout</c><00:39:09.589><c> this</c><00:39:10.040><c> is</c><00:39:10.190><c> an</c>

00:39:10.240 --> 00:39:10.250 align:start position:0%
neural networks is dropout this is an
 

00:39:10.250 --> 00:39:12.910 align:start position:0%
neural networks is dropout this is an
extremely<00:39:10.730><c> simple</c><00:39:10.970><c> idea</c><00:39:11.480><c> let's</c><00:39:12.349><c> revisit</c><00:39:12.650><c> this</c>

00:39:12.910 --> 00:39:12.920 align:start position:0%
extremely simple idea let's revisit this
 

00:39:12.920 --> 00:39:14.410 align:start position:0%
extremely simple idea let's revisit this
picture<00:39:13.220><c> of</c><00:39:13.309><c> a</c><00:39:13.369><c> deep</c><00:39:13.520><c> neural</c><00:39:13.700><c> network</c><00:39:14.150><c> and</c>

00:39:14.410 --> 00:39:14.420 align:start position:0%
picture of a deep neural network and
 

00:39:14.420 --> 00:39:16.720 align:start position:0%
picture of a deep neural network and
then<00:39:14.510><c> drop</c><00:39:14.720><c> out</c><00:39:14.900><c> all</c><00:39:15.109><c> we</c><00:39:15.349><c> do</c><00:39:15.530><c> during</c><00:39:16.280><c> training</c>

00:39:16.720 --> 00:39:16.730 align:start position:0%
then drop out all we do during training
 

00:39:16.730 --> 00:39:20.640 align:start position:0%
then drop out all we do during training
on<00:39:16.880><c> every</c><00:39:17.270><c> iteration</c><00:39:17.390><c> we</c><00:39:17.960><c> randomly</c><00:39:18.470><c> drop</c><00:39:19.089><c> some</c>

00:39:20.640 --> 00:39:20.650 align:start position:0%
on every iteration we randomly drop some
 

00:39:20.650 --> 00:39:23.530 align:start position:0%
on every iteration we randomly drop some
proportion<00:39:21.650><c> of</c><00:39:21.829><c> the</c><00:39:22.099><c> hidden</c><00:39:22.849><c> neurons</c><00:39:23.059><c> with</c>

00:39:23.530 --> 00:39:23.540 align:start position:0%
proportion of the hidden neurons with
 

00:39:23.540 --> 00:39:25.960 align:start position:0%
proportion of the hidden neurons with
some<00:39:23.750><c> probability</c><00:39:23.960><c> P</c><00:39:24.559><c> so</c><00:39:25.400><c> let's</c><00:39:25.520><c> suppose</c><00:39:25.640><c> P</c>

00:39:25.960 --> 00:39:25.970 align:start position:0%
some probability P so let's suppose P
 

00:39:25.970 --> 00:39:28.210 align:start position:0%
some probability P so let's suppose P
equals<00:39:26.270><c> 0.5</c><00:39:26.599><c> that</c><00:39:26.720><c> means</c><00:39:27.020><c> we</c><00:39:27.230><c> dropped</c><00:39:27.440><c> 50%</c><00:39:27.829><c> of</c>

00:39:28.210 --> 00:39:28.220 align:start position:0%
equals 0.5 that means we dropped 50% of
 

00:39:28.220 --> 00:39:29.890 align:start position:0%
equals 0.5 that means we dropped 50% of
those<00:39:28.309><c> neurons</c><00:39:28.549><c> like</c><00:39:28.790><c> that</c><00:39:29.030><c> those</c>

00:39:29.890 --> 00:39:29.900 align:start position:0%
those neurons like that those
 

00:39:29.900 --> 00:39:32.589 align:start position:0%
those neurons like that those
activations<00:39:30.589><c> become</c><00:39:30.890><c> zero</c><00:39:31.250><c> and</c><00:39:31.599><c> effectively</c>

00:39:32.589 --> 00:39:32.599 align:start position:0%
activations become zero and effectively
 

00:39:32.599 --> 00:39:35.160 align:start position:0%
activations become zero and effectively
they're<00:39:32.809><c> no</c><00:39:32.960><c> longer</c><00:39:33.140><c> part</c><00:39:33.559><c> of</c><00:39:33.680><c> our</c><00:39:33.829><c> network</c>

00:39:35.160 --> 00:39:35.170 align:start position:0%
they're no longer part of our network
 

00:39:35.170 --> 00:39:38.559 align:start position:0%
they're no longer part of our network
this<00:39:36.170><c> forces</c><00:39:36.440><c> the</c><00:39:36.559><c> network</c><00:39:36.950><c> to</c><00:39:37.339><c> not</c><00:39:38.150><c> rely</c><00:39:38.540><c> on</c>

00:39:38.559 --> 00:39:38.569 align:start position:0%
this forces the network to not rely on
 

00:39:38.569 --> 00:39:41.530 align:start position:0%
this forces the network to not rely on
any<00:39:38.960><c> single</c><00:39:39.319><c> node</c><00:39:39.940><c> but</c><00:39:40.940><c> actually</c><00:39:41.270><c> find</c>

00:39:41.530 --> 00:39:41.540 align:start position:0%
any single node but actually find
 

00:39:41.540 --> 00:39:43.240 align:start position:0%
any single node but actually find
alternative<00:39:42.140><c> paths</c><00:39:42.380><c> through</c><00:39:42.740><c> the</c><00:39:42.890><c> network</c>

00:39:43.240 --> 00:39:43.250 align:start position:0%
alternative paths through the network
 

00:39:43.250 --> 00:39:45.460 align:start position:0%
alternative paths through the network
and<00:39:43.490><c> not</c><00:39:44.240><c> put</c><00:39:44.569><c> too</c><00:39:44.720><c> much</c><00:39:44.839><c> weight</c><00:39:45.079><c> on</c><00:39:45.140><c> any</c>

00:39:45.460 --> 00:39:45.470 align:start position:0%
and not put too much weight on any
 

00:39:45.470 --> 00:39:47.589 align:start position:0%
and not put too much weight on any
single<00:39:45.980><c> example</c><00:39:46.309><c> with</c><00:39:46.579><c> any</c><00:39:46.790><c> single</c><00:39:47.119><c> single</c>

00:39:47.589 --> 00:39:47.599 align:start position:0%
single example with any single single
 

00:39:47.599 --> 00:39:49.299 align:start position:0%
single example with any single single
node<00:39:47.780><c> so</c><00:39:47.930><c> it</c><00:39:48.020><c> discourages</c><00:39:48.589><c> memorization</c>

00:39:49.299 --> 00:39:49.309 align:start position:0%
node so it discourages memorization
 

00:39:49.309 --> 00:39:53.650 align:start position:0%
node so it discourages memorization
essentially<00:39:51.819><c> on</c><00:39:52.819><c> every</c><00:39:53.180><c> iteration</c><00:39:53.299><c> we</c>

00:39:53.650 --> 00:39:53.660 align:start position:0%
essentially on every iteration we
 

00:39:53.660 --> 00:39:56.589 align:start position:0%
essentially on every iteration we
randomly<00:39:54.440><c> drop</c><00:39:54.650><c> another</c><00:39:55.040><c> 50%</c><00:39:55.849><c> of</c><00:39:56.180><c> the</c><00:39:56.240><c> node</c><00:39:56.420><c> so</c>

00:39:56.589 --> 00:39:56.599 align:start position:0%
randomly drop another 50% of the node so
 

00:39:56.599 --> 00:39:58.150 align:start position:0%
randomly drop another 50% of the node so
on<00:39:56.720><c> this</c><00:39:56.869><c> iteration</c><00:39:57.290><c> I</c><00:39:57.319><c> may</c><00:39:57.500><c> drop</c><00:39:57.650><c> these</c><00:39:57.890><c> on</c>

00:39:58.150 --> 00:39:58.160 align:start position:0%
on this iteration I may drop these on
 

00:39:58.160 --> 00:40:00.099 align:start position:0%
on this iteration I may drop these on
the<00:39:58.339><c> next</c><00:39:58.549><c> iteration</c><00:39:58.640><c> I</c><00:39:59.089><c> may</c><00:39:59.329><c> drop</c><00:39:59.480><c> those</c><00:39:59.750><c> and</c>

00:40:00.099 --> 00:40:00.109 align:start position:0%
the next iteration I may drop those and
 

00:40:00.109 --> 00:40:01.510 align:start position:0%
the next iteration I may drop those and
since<00:40:00.559><c> it's</c><00:40:00.710><c> different</c><00:40:00.980><c> on</c><00:40:01.099><c> every</c><00:40:01.369><c> iteration</c>

00:40:01.510 --> 00:40:01.520 align:start position:0%
since it's different on every iteration
 

00:40:01.520 --> 00:40:03.730 align:start position:0%
since it's different on every iteration
you're<00:40:02.420><c> encouraging</c><00:40:02.900><c> the</c><00:40:03.260><c> network</c><00:40:03.530><c> to</c><00:40:03.710><c> find</c>

00:40:03.730 --> 00:40:03.740 align:start position:0%
you're encouraging the network to find
 

00:40:03.740 --> 00:40:07.290 align:start position:0%
you're encouraging the network to find
these<00:40:04.130><c> different</c><00:40:04.430><c> paths</c><00:40:04.640><c> to</c><00:40:04.970><c> its</c><00:40:05.510><c> answer</c>

00:40:07.290 --> 00:40:07.300 align:start position:0%
these different paths to its answer
 

00:40:07.300 --> 00:40:09.760 align:start position:0%
these different paths to its answer
the<00:40:08.300><c> second</c><00:40:08.660><c> technique</c><00:40:09.290><c> for</c><00:40:09.410><c> regularization</c>

00:40:09.760 --> 00:40:09.770 align:start position:0%
the second technique for regularization
 

00:40:09.770 --> 00:40:11.680 align:start position:0%
the second technique for regularization
that<00:40:10.490><c> we'll</c><00:40:10.610><c> talk</c><00:40:10.760><c> about</c><00:40:10.820><c> is</c><00:40:11.120><c> this</c><00:40:11.210><c> notion</c><00:40:11.420><c> of</c>

00:40:11.680 --> 00:40:11.690 align:start position:0%
that we'll talk about is this notion of
 

00:40:11.690 --> 00:40:14.740 align:start position:0%
that we'll talk about is this notion of
early<00:40:12.080><c> stopping</c><00:40:13.210><c> now</c><00:40:14.210><c> we</c><00:40:14.270><c> know</c><00:40:14.480><c> that</c><00:40:14.510><c> the</c>

00:40:14.740 --> 00:40:14.750 align:start position:0%
early stopping now we know that the
 

00:40:14.750 --> 00:40:17.020 align:start position:0%
early stopping now we know that the
definition<00:40:15.320><c> of</c><00:40:15.410><c> overfitting</c><00:40:15.890><c> actually</c><00:40:16.760><c> is</c>

00:40:17.020 --> 00:40:17.030 align:start position:0%
definition of overfitting actually is
 

00:40:17.030 --> 00:40:19.090 align:start position:0%
definition of overfitting actually is
just<00:40:17.690><c> when</c><00:40:18.080><c> our</c><00:40:18.110><c> model</c><00:40:18.530><c> starts</c><00:40:18.830><c> to</c><00:40:18.950><c> perform</c>

00:40:19.090 --> 00:40:19.100 align:start position:0%
just when our model starts to perform
 

00:40:19.100 --> 00:40:22.000 align:start position:0%
just when our model starts to perform
worse<00:40:19.550><c> and</c><00:40:19.880><c> worse</c><00:40:20.060><c> on</c><00:40:20.330><c> our</c><00:40:20.450><c> test</c><00:40:20.750><c> data</c><00:40:20.930><c> set</c><00:40:21.200><c> so</c>

00:40:22.000 --> 00:40:22.010 align:start position:0%
worse and worse on our test data set so
 

00:40:22.010 --> 00:40:23.950 align:start position:0%
worse and worse on our test data set so
let's<00:40:22.190><c> use</c><00:40:22.370><c> that</c><00:40:22.400><c> to</c><00:40:22.880><c> our</c><00:40:23.150><c> advantage</c><00:40:23.330><c> to</c>

00:40:23.950 --> 00:40:23.960 align:start position:0%
let's use that to our advantage to
 

00:40:23.960 --> 00:40:26.260 align:start position:0%
let's use that to our advantage to
create<00:40:24.290><c> this</c><00:40:24.560><c> early</c><00:40:24.950><c> stopping</c><00:40:25.190><c> algorithm</c><00:40:25.760><c> if</c>

00:40:26.260 --> 00:40:26.270 align:start position:0%
create this early stopping algorithm if
 

00:40:26.270 --> 00:40:28.150 align:start position:0%
create this early stopping algorithm if
we<00:40:26.570><c> set</c><00:40:26.750><c> aside</c><00:40:26.780><c> some</c><00:40:27.290><c> of</c><00:40:27.410><c> our</c><00:40:27.530><c> training</c><00:40:27.950><c> data</c>

00:40:28.150 --> 00:40:28.160 align:start position:0%
we set aside some of our training data
 

00:40:28.160 --> 00:40:29.950 align:start position:0%
we set aside some of our training data
and<00:40:28.340><c> use</c><00:40:28.580><c> it</c><00:40:28.730><c> only</c><00:40:28.850><c> as</c><00:40:29.090><c> test</c><00:40:29.330><c> data</c><00:40:29.510><c> we</c><00:40:29.690><c> don't</c>

00:40:29.950 --> 00:40:29.960 align:start position:0%
and use it only as test data we don't
 

00:40:29.960 --> 00:40:32.590 align:start position:0%
and use it only as test data we don't
train<00:40:30.200><c> with</c><00:40:30.380><c> that</c><00:40:30.410><c> data</c><00:40:30.790><c> we</c><00:40:31.790><c> can</c><00:40:31.970><c> use</c><00:40:32.210><c> it</c><00:40:32.420><c> to</c>

00:40:32.590 --> 00:40:32.600 align:start position:0%
train with that data we can use it to
 

00:40:32.600 --> 00:40:34.840 align:start position:0%
train with that data we can use it to
basically<00:40:32.930><c> monitor</c><00:40:33.410><c> the</c><00:40:33.980><c> progress</c><00:40:34.220><c> of</c><00:40:34.640><c> our</c>

00:40:34.840 --> 00:40:34.850 align:start position:0%
basically monitor the progress of our
 

00:40:34.850 --> 00:40:37.420 align:start position:0%
basically monitor the progress of our
model<00:40:35.180><c> on</c><00:40:35.330><c> unseen</c><00:40:35.780><c> data</c><00:40:35.930><c> so</c><00:40:36.890><c> we</c><00:40:36.980><c> can</c><00:40:37.070><c> plot</c><00:40:37.280><c> this</c>

00:40:37.420 --> 00:40:37.430 align:start position:0%
model on unseen data so we can plot this
 

00:40:37.430 --> 00:40:40.090 align:start position:0%
model on unseen data so we can plot this
curve<00:40:37.990><c> we're</c><00:40:38.990><c> on</c><00:40:39.080><c> the</c><00:40:39.200><c> x</c><00:40:39.350><c> axis</c><00:40:39.530><c> we</c><00:40:39.890><c> have</c><00:40:39.980><c> the</c>

00:40:40.090 --> 00:40:40.100 align:start position:0%
curve we're on the x axis we have the
 

00:40:40.100 --> 00:40:41.770 align:start position:0%
curve we're on the x axis we have the
training<00:40:40.370><c> iterations</c><00:40:41.000><c> on</c><00:40:41.210><c> the</c><00:40:41.300><c> y</c><00:40:41.390><c> axis</c><00:40:41.420><c> we</c>

00:40:41.770 --> 00:40:41.780 align:start position:0%
training iterations on the y axis we
 

00:40:41.780 --> 00:40:43.900 align:start position:0%
training iterations on the y axis we
have<00:40:41.810><c> the</c><00:40:41.900><c> loss</c><00:40:42.170><c> now</c><00:40:43.010><c> they</c><00:40:43.160><c> start</c><00:40:43.460><c> off</c><00:40:43.610><c> going</c>

00:40:43.900 --> 00:40:43.910 align:start position:0%
have the loss now they start off going
 

00:40:43.910 --> 00:40:45.790 align:start position:0%
have the loss now they start off going
down<00:40:44.120><c> together</c><00:40:44.540><c> this</c><00:40:44.930><c> is</c><00:40:45.110><c> great</c><00:40:45.350><c> because</c><00:40:45.560><c> it</c>

00:40:45.790 --> 00:40:45.800 align:start position:0%
down together this is great because it
 

00:40:45.800 --> 00:40:47.620 align:start position:0%
down together this is great because it
means<00:40:45.920><c> that</c><00:40:46.340><c> we're</c><00:40:46.490><c> learning</c><00:40:46.730><c> we're</c><00:40:47.360><c> training</c>

00:40:47.620 --> 00:40:47.630 align:start position:0%
means that we're learning we're training
 

00:40:47.630 --> 00:40:50.830 align:start position:0%
means that we're learning we're training
right<00:40:47.930><c> that's</c><00:40:48.740><c> great</c><00:40:49.510><c> there</c><00:40:50.510><c> comes</c><00:40:50.720><c> a</c><00:40:50.810><c> point</c>

00:40:50.830 --> 00:40:50.840 align:start position:0%
right that's great there comes a point
 

00:40:50.840 --> 00:40:54.250 align:start position:0%
right that's great there comes a point
though<00:40:51.340><c> where</c><00:40:52.340><c> the</c><00:40:52.460><c> testing</c><00:40:53.090><c> data</c><00:40:53.390><c> where</c><00:40:54.230><c> the</c>

00:40:54.250 --> 00:40:54.260 align:start position:0%
though where the testing data where the
 

00:40:54.260 --> 00:40:57.160 align:start position:0%
though where the testing data where the
testing<00:40:54.710><c> data</c><00:40:54.830><c> set</c><00:40:55.160><c> and</c><00:40:55.450><c> the</c><00:40:56.450><c> add</c><00:40:56.600><c> the</c><00:40:56.960><c> loss</c>

00:40:57.160 --> 00:40:57.170 align:start position:0%
testing data set and the add the loss
 

00:40:57.170 --> 00:41:01.030 align:start position:0%
testing data set and the add the loss
for<00:40:57.470><c> that</c><00:40:57.590><c> data</c><00:40:57.830><c> set</c><00:40:58.100><c> starts</c><00:40:58.940><c> to</c><00:40:59.060><c> Plateau</c><00:41:00.040><c> now</c>

00:41:01.030 --> 00:41:01.040 align:start position:0%
for that data set starts to Plateau now
 

00:41:01.040 --> 00:41:02.950 align:start position:0%
for that data set starts to Plateau now
if<00:41:01.130><c> we</c><00:41:01.250><c> look</c><00:41:01.370><c> a</c><00:41:01.490><c> little</c><00:41:01.670><c> further</c><00:41:01.880><c> the</c><00:41:02.480><c> training</c>

00:41:02.950 --> 00:41:02.960 align:start position:0%
if we look a little further the training
 

00:41:02.960 --> 00:41:05.260 align:start position:0%
if we look a little further the training
data<00:41:03.110><c> set</c><00:41:03.440><c> loss</c><00:41:03.860><c> will</c><00:41:04.130><c> always</c><00:41:04.520><c> continue</c><00:41:05.000><c> to</c><00:41:05.030><c> go</c>

00:41:05.260 --> 00:41:05.270 align:start position:0%
data set loss will always continue to go
 

00:41:05.270 --> 00:41:07.090 align:start position:0%
data set loss will always continue to go
down<00:41:05.510><c> as</c><00:41:05.750><c> long</c><00:41:06.140><c> as</c><00:41:06.320><c> our</c><00:41:06.470><c> model</c><00:41:06.800><c> has</c><00:41:06.920><c> the</c>

00:41:07.090 --> 00:41:07.100 align:start position:0%
down as long as our model has the
 

00:41:07.100 --> 00:41:09.580 align:start position:0%
down as long as our model has the
capacity<00:41:07.250><c> to</c><00:41:07.940><c> learn</c><00:41:08.540><c> and</c><00:41:08.870><c> memorize</c><00:41:08.990><c> some</c><00:41:09.500><c> of</c>

00:41:09.580 --> 00:41:09.590 align:start position:0%
capacity to learn and memorize some of
 

00:41:09.590 --> 00:41:11.020 align:start position:0%
capacity to learn and memorize some of
that<00:41:09.680><c> data</c><00:41:09.890><c> but</c><00:41:10.520><c> that</c><00:41:10.550><c> doesn't</c><00:41:10.880><c> mean</c><00:41:11.000><c> that</c>

00:41:11.020 --> 00:41:11.030 align:start position:0%
that data but that doesn't mean that
 

00:41:11.030 --> 00:41:12.460 align:start position:0%
that data but that doesn't mean that
it's<00:41:11.240><c> actually</c><00:41:11.330><c> generalizing</c><00:41:12.050><c> well</c><00:41:12.200><c> because</c>

00:41:12.460 --> 00:41:12.470 align:start position:0%
it's actually generalizing well because
 

00:41:12.470 --> 00:41:14.620 align:start position:0%
it's actually generalizing well because
we<00:41:12.590><c> can</c><00:41:12.710><c> see</c><00:41:12.950><c> that</c><00:41:12.980><c> the</c><00:41:13.250><c> testing</c><00:41:13.670><c> data</c><00:41:13.850><c> set</c><00:41:14.120><c> has</c>

00:41:14.620 --> 00:41:14.630 align:start position:0%
we can see that the testing data set has
 

00:41:14.630 --> 00:41:17.560 align:start position:0%
we can see that the testing data set has
actually<00:41:14.990><c> started</c><00:41:15.110><c> to</c><00:41:15.290><c> increase</c><00:41:16.570><c> this</c>

00:41:17.560 --> 00:41:17.570 align:start position:0%
actually started to increase this
 

00:41:17.570 --> 00:41:18.940 align:start position:0%
actually started to increase this
pattern<00:41:17.900><c> continues</c><00:41:18.050><c> for</c><00:41:18.500><c> the</c><00:41:18.590><c> rest</c><00:41:18.620><c> of</c>

00:41:18.940 --> 00:41:18.950 align:start position:0%
pattern continues for the rest of
 

00:41:18.950 --> 00:41:20.680 align:start position:0%
pattern continues for the rest of
training<00:41:19.370><c> but</c><00:41:19.790><c> I</c><00:41:19.820><c> want</c><00:41:20.000><c> to</c><00:41:20.090><c> focus</c><00:41:20.180><c> on</c><00:41:20.480><c> this</c>

00:41:20.680 --> 00:41:20.690 align:start position:0%
training but I want to focus on this
 

00:41:20.690 --> 00:41:23.650 align:start position:0%
training but I want to focus on this
point<00:41:20.960><c> here</c><00:41:21.520><c> this</c><00:41:22.520><c> is</c><00:41:22.640><c> the</c><00:41:22.760><c> point</c><00:41:23.060><c> where</c><00:41:23.510><c> you</c>

00:41:23.650 --> 00:41:23.660 align:start position:0%
point here this is the point where you
 

00:41:23.660 --> 00:41:25.690 align:start position:0%
point here this is the point where you
need<00:41:23.840><c> to</c><00:41:23.990><c> stop</c><00:41:24.260><c> training</c><00:41:24.770><c> because</c><00:41:25.220><c> after</c><00:41:25.550><c> this</c>

00:41:25.690 --> 00:41:25.700 align:start position:0%
need to stop training because after this
 

00:41:25.700 --> 00:41:28.480 align:start position:0%
need to stop training because after this
point<00:41:25.910><c> you</c><00:41:26.450><c> are</c><00:41:26.480><c> overfitting</c><00:41:27.110><c> and</c><00:41:27.380><c> your</c><00:41:28.250><c> model</c>

00:41:28.480 --> 00:41:28.490 align:start position:0%
point you are overfitting and your model
 

00:41:28.490 --> 00:41:30.070 align:start position:0%
point you are overfitting and your model
is<00:41:28.580><c> no</c><00:41:28.700><c> longer</c><00:41:28.970><c> performing</c><00:41:29.360><c> well</c><00:41:29.540><c> on</c><00:41:29.570><c> unseen</c>

00:41:30.070 --> 00:41:30.080 align:start position:0%
is no longer performing well on unseen
 

00:41:30.080 --> 00:41:32.170 align:start position:0%
is no longer performing well on unseen
data<00:41:30.140><c> if</c><00:41:31.010><c> you</c><00:41:31.100><c> stop</c><00:41:31.310><c> before</c><00:41:31.490><c> that</c><00:41:31.880><c> point</c>

00:41:32.170 --> 00:41:32.180 align:start position:0%
data if you stop before that point
 

00:41:32.180 --> 00:41:34.300 align:start position:0%
data if you stop before that point
you're<00:41:32.960><c> actually</c><00:41:33.080><c> under</c><00:41:33.380><c> fitting</c><00:41:33.860><c> and</c><00:41:34.100><c> you're</c>

00:41:34.300 --> 00:41:34.310 align:start position:0%
you're actually under fitting and you're
 

00:41:34.310 --> 00:41:36.220 align:start position:0%
you're actually under fitting and you're
not<00:41:34.490><c> utilizing</c><00:41:35.150><c> the</c><00:41:35.330><c> full</c><00:41:35.420><c> potential</c><00:41:36.080><c> the</c>

00:41:36.220 --> 00:41:36.230 align:start position:0%
not utilizing the full potential the
 

00:41:36.230 --> 00:41:40.750 align:start position:0%
not utilizing the full potential the
full<00:41:36.410><c> capacity</c><00:41:37.010><c> of</c><00:41:37.040><c> your</c><00:41:37.220><c> network</c><00:41:39.640><c> so</c><00:41:40.640><c> I'll</c>

00:41:40.750 --> 00:41:40.760 align:start position:0%
full capacity of your network so I'll
 

00:41:40.760 --> 00:41:43.000 align:start position:0%
full capacity of your network so I'll
conclude<00:41:40.940><c> this</c><00:41:41.240><c> lecture</c><00:41:41.450><c> by</c><00:41:42.010><c> summarizing</c>

00:41:43.000 --> 00:41:43.010 align:start position:0%
conclude this lecture by summarizing
 

00:41:43.010 --> 00:41:45.700 align:start position:0%
conclude this lecture by summarizing
three<00:41:43.550><c> key</c><00:41:43.760><c> points</c><00:41:44.020><c> that</c><00:41:45.020><c> we've</c><00:41:45.170><c> covered</c><00:41:45.410><c> so</c>

00:41:45.700 --> 00:41:45.710 align:start position:0%
three key points that we've covered so
 

00:41:45.710 --> 00:41:48.580 align:start position:0%
three key points that we've covered so
far<00:41:46.690><c> first</c><00:41:47.690><c> we've</c><00:41:47.990><c> learned</c><00:41:48.230><c> about</c><00:41:48.440><c> the</c>

00:41:48.580 --> 00:41:48.590 align:start position:0%
far first we've learned about the
 

00:41:48.590 --> 00:41:50.440 align:start position:0%
far first we've learned about the
fundamental<00:41:49.160><c> building</c><00:41:49.370><c> blocks</c><00:41:49.760><c> of</c><00:41:49.940><c> neural</c>

00:41:50.440 --> 00:41:50.450 align:start position:0%
fundamental building blocks of neural
 

00:41:50.450 --> 00:41:53.350 align:start position:0%
fundamental building blocks of neural
networks<00:41:50.780><c> called</c><00:41:51.380><c> the</c><00:41:51.560><c> perceptron</c><00:41:52.360><c> we've</c>

00:41:53.350 --> 00:41:53.360 align:start position:0%
networks called the perceptron we've
 

00:41:53.360 --> 00:41:56.770 align:start position:0%
networks called the perceptron we've
learned<00:41:53.660><c> about</c><00:41:53.960><c> stacking</c><00:41:54.500><c> these</c><00:41:55.390><c> units</c><00:41:56.390><c> these</c>

00:41:56.770 --> 00:41:56.780 align:start position:0%
learned about stacking these units these
 

00:41:56.780 --> 00:41:59.670 align:start position:0%
learned about stacking these units these
perceptrons<00:41:57.560><c> together</c><00:41:58.280><c> to</c><00:41:58.550><c> compose</c><00:41:58.880><c> very</c>

00:41:59.670 --> 00:41:59.680 align:start position:0%
perceptrons together to compose very
 

00:41:59.680 --> 00:42:03.850 align:start position:0%
perceptrons together to compose very
complex<00:42:00.680><c> hierarchical</c><00:42:01.340><c> models</c><00:42:01.970><c> and</c><00:42:02.860><c> we've</c>

00:42:03.850 --> 00:42:03.860 align:start position:0%
complex hierarchical models and we've
 

00:42:03.860 --> 00:42:05.980 align:start position:0%
complex hierarchical models and we've
learned<00:42:04.520><c> how</c><00:42:04.760><c> to</c><00:42:04.790><c> mathematically</c><00:42:05.510><c> optimize</c>

00:42:05.980 --> 00:42:05.990 align:start position:0%
learned how to mathematically optimize
 

00:42:05.990 --> 00:42:08.740 align:start position:0%
learned how to mathematically optimize
these<00:42:06.230><c> models</c><00:42:06.650><c> using</c><00:42:06.980><c> a</c><00:42:07.040><c> process</c><00:42:07.340><c> called</c><00:42:07.820><c> back</c>

00:42:08.740 --> 00:42:08.750 align:start position:0%
these models using a process called back
 

00:42:08.750 --> 00:42:11.320 align:start position:0%
these models using a process called back
row<00:42:08.990><c> back</c><00:42:09.710><c> propagation</c><00:42:10.190><c> and</c><00:42:10.580><c> gradient</c>

00:42:11.320 --> 00:42:11.330 align:start position:0%
row back propagation and gradient
 

00:42:11.330 --> 00:42:14.410 align:start position:0%
row back propagation and gradient
descent<00:42:12.610><c> finally</c><00:42:13.610><c> we</c><00:42:13.760><c> adjust</c><00:42:14.060><c> some</c><00:42:14.180><c> of</c><00:42:14.210><c> the</c>

00:42:14.410 --> 00:42:14.420 align:start position:0%
descent finally we adjust some of the
 

00:42:14.420 --> 00:42:16.120 align:start position:0%
descent finally we adjust some of the
practical<00:42:14.930><c> challenges</c><00:42:15.500><c> of</c><00:42:15.680><c> training</c><00:42:16.010><c> these</c>

00:42:16.120 --> 00:42:16.130 align:start position:0%
practical challenges of training these
 

00:42:16.130 --> 00:42:18.940 align:start position:0%
practical challenges of training these
models<00:42:16.580><c> in</c><00:42:17.480><c> real</c><00:42:17.990><c> life</c><00:42:18.260><c> that</c><00:42:18.650><c> you'll</c><00:42:18.770><c> find</c>

00:42:18.940 --> 00:42:18.950 align:start position:0%
models in real life that you'll find
 

00:42:18.950 --> 00:42:20.260 align:start position:0%
models in real life that you'll find
useful<00:42:19.130><c> for</c><00:42:19.490><c> the</c><00:42:19.550><c> labs</c><00:42:19.730><c> today</c>

00:42:20.260 --> 00:42:20.270 align:start position:0%
useful for the labs today
 

00:42:20.270 --> 00:42:22.030 align:start position:0%
useful for the labs today
such<00:42:20.720><c> as</c><00:42:20.840><c> using</c><00:42:21.020><c> adaptive</c><00:42:21.350><c> learning</c><00:42:21.680><c> rates</c>

00:42:22.030 --> 00:42:22.040 align:start position:0%
such as using adaptive learning rates
 

00:42:22.040 --> 00:42:24.730 align:start position:0%
such as using adaptive learning rates
batching<00:42:22.880><c> and</c><00:42:23.060><c> regularization</c><00:42:23.870><c> to</c><00:42:24.350><c> combat</c>

00:42:24.730 --> 00:42:24.740 align:start position:0%
batching and regularization to combat
 

00:42:24.740 --> 00:42:31.150 align:start position:0%
batching and regularization to combat
overfitting<00:42:27.070><c> thank</c><00:42:28.070><c> you</c><00:42:28.220><c> and</c><00:42:29.770><c> I'd</c><00:42:30.770><c> be</c><00:42:30.920><c> happy</c>

00:42:31.150 --> 00:42:31.160 align:start position:0%
overfitting thank you and I'd be happy
 

00:42:31.160 --> 00:42:32.920 align:start position:0%
overfitting thank you and I'd be happy
to<00:42:31.190><c> answer</c><00:42:31.310><c> any</c><00:42:31.610><c> questions</c><00:42:31.640><c> now</c><00:42:32.210><c> otherwise</c>

00:42:32.920 --> 00:42:32.930 align:start position:0%
to answer any questions now otherwise
 

00:42:32.930 --> 00:42:34.120 align:start position:0%
to answer any questions now otherwise
we'll<00:42:33.410><c> have</c><00:42:33.440><c> Ferrini</c>

00:42:34.120 --> 00:42:34.130 align:start position:0%
we'll have Ferrini
 

00:42:34.130 --> 00:42:36.640 align:start position:0%
we'll have Ferrini
talk<00:42:34.550><c> to</c><00:42:34.700><c> us</c><00:42:34.790><c> about</c><00:42:34.910><c> some</c><00:42:35.210><c> of</c><00:42:35.330><c> the</c><00:42:35.650><c> deep</c>

00:42:36.640 --> 00:42:36.650 align:start position:0%
talk to us about some of the deep
 

00:42:36.650 --> 00:42:38.680 align:start position:0%
talk to us about some of the deep
sequence<00:42:37.100><c> models</c><00:42:37.520><c> for</c><00:42:37.790><c> modeling</c><00:42:38.210><c> temporal</c>

00:42:38.680 --> 00:42:38.690 align:start position:0%
sequence models for modeling temporal
 

00:42:38.690 --> 00:42:40.900 align:start position:0%
sequence models for modeling temporal
data

