1
00:00:02,410 --> 00:00:05,950
Okay. So we'll, should I just improvise
something? Sure. Hey, this is jad.

2
00:00:05,951 --> 00:00:10,720
Before we launch into this
week's podcast, uh, I want to,

3
00:00:11,030 --> 00:00:15,940
uh, make you aware of, uh, well our
friends down the hall, Brooke, my friend,

4
00:00:15,970 --> 00:00:19,690
our friends, uh, on the media,
Brooke Gladstone is here with me. Uh,

5
00:00:19,720 --> 00:00:23,050
having a new show coming out
that I'm, I think I might be in,

6
00:00:23,410 --> 00:00:26,640
I'm excited to be in, but I'm
certainly excited about. So what is it?

7
00:00:26,830 --> 00:00:28,960
You are going to be in
it? It's an episode,

8
00:00:28,990 --> 00:00:32,090
although you don't want to say show
because on radio lab that generally means

9
00:00:32,150 --> 00:00:36,220
that you're launching a whole
new style new enterprise. Yeah.

10
00:00:36,250 --> 00:00:39,310
This is an episode on twitch,

11
00:00:45,790 --> 00:00:49,120
which some people know as if,

12
00:00:50,050 --> 00:00:53,230
as if it were part of their
family or like what? Yeah.

13
00:00:53,231 --> 00:00:57,340
Is that something you need medication
for? So it depends where you're situated,

14
00:00:57,341 --> 00:01:02,341
but what we are going to do is examine
how it came to be and how it points to

15
00:01:04,091 --> 00:01:07,270
the future of where our culture's going.

16
00:01:07,540 --> 00:01:10,390
And for the people who don't
know what is twitch. Most people,

17
00:01:10,560 --> 00:01:11,500
if they've ever heard of it,

18
00:01:11,680 --> 00:01:16,680
they know it's about watching and
commenting in real time on people playing

19
00:01:19,060 --> 00:01:19,893
video games.

20
00:01:23,280 --> 00:01:24,113
No

21
00:01:24,440 --> 00:01:28,530
trap rap. And you guys,

22
00:01:28,860 --> 00:01:30,960
from what I hear profile one
of these twitch superstars,

23
00:01:30,961 --> 00:01:35,280
the main character in that story is
Ninja who makes something like half a

24
00:01:35,280 --> 00:01:38,940
million dollars a month.
What bought on twitch? Yes.

25
00:01:39,000 --> 00:01:44,000
Through contributors who say say this out
loud or point to me mention my name is

26
00:01:46,680 --> 00:01:47,513
online

27
00:01:49,740 --> 00:01:52,020
and at the same time
he's playing the game.

28
00:01:52,580 --> 00:01:57,580
He's even giving advice to
young boys with girlfriends.

29
00:01:58,750 --> 00:02:01,150
Don't act like, you know, don't make,
don't make her seem, it's like her fault.

30
00:02:01,151 --> 00:02:02,280
You just need to be like
they like we need have,

31
00:02:02,420 --> 00:02:05,430
we need to have a talk and be like,
don't worry, everything's fine, you know,

32
00:02:05,770 --> 00:02:08,650
reassure that. But then you just need to
be like, I really feel like I'm trying,

33
00:02:08,651 --> 00:02:11,830
like putting in more effort in
this relationship. And then like,

34
00:02:12,700 --> 00:02:15,340
then I feel like you are, and I
want him to I and then just be like,

35
00:02:15,370 --> 00:02:16,510
I just want to make sure that you're just,

36
00:02:16,511 --> 00:02:19,120
you're just as invested in this as I am.

37
00:02:19,160 --> 00:02:23,150
I think it's something
new. I want to hear that.

38
00:02:24,230 --> 00:02:28,370
Well, thank you. Thank you for letting
me in the top of your shell. Absolutely.

39
00:02:28,410 --> 00:02:33,000
So a twitch on, on the media,
on the media.org. Check it out.

40
00:02:33,030 --> 00:02:35,400
I'm in there. It's going to be
amazing, but not just because of me,

41
00:02:35,910 --> 00:02:39,870
cause of you Brooke. Thanks for
dropping in and Bob and Bob. Bye. Bye.

42
00:02:42,220 --> 00:02:43,053
Oh wait, you're listening.

43
00:02:48,640 --> 00:02:53,640
I adore listening to radio
lab radio from W N Y C E.

44
00:03:00,030 --> 00:03:03,030
Hey, I'm Jen. I boom Rod. I'm
Robert Krulwich, Radiolab.

45
00:03:03,060 --> 00:03:08,060
And today we have a story about
what we can say and what we can't.

46
00:03:09,330 --> 00:03:10,270
And by the way, um,

47
00:03:10,320 --> 00:03:12,580
there's going to be a smattering of
curse words here that we're not going to

48
00:03:12,890 --> 00:03:15,240
bleep, I think makes sense.
Given the content of this story.

49
00:03:15,241 --> 00:03:19,770
And also there's some graphic scenes
that, uh, if you've got kids with a,

50
00:03:19,771 --> 00:03:22,200
you may want to mess with
this one out. Yeah. Anyway,

51
00:03:22,201 --> 00:03:25,200
the story comes to us from producers,
Simon Adler. So let's start,

52
00:03:25,201 --> 00:03:28,350
can we start in 2008? Sure. How about
with a song? Yes, please. [inaudible]

53
00:03:32,010 --> 00:03:35,510
[inaudible] man, Facebook
sees Sarah Oppressive way,

54
00:03:35,970 --> 00:03:40,920
rise up, rise and put
bad guy. Shake chairs,

55
00:03:41,250 --> 00:03:41,720
red now.

56
00:03:41,720 --> 00:03:45,440
So, uh, December 27th, a
sunny Saturday morning, uh,

57
00:03:45,550 --> 00:03:49,100
this group of young to middle aged
women gathered in downtown. Yeah.

58
00:03:49,170 --> 00:03:51,830
Palo Alto, cyberspace free.

59
00:03:54,990 --> 00:03:55,440
[inaudible]

60
00:03:55,440 --> 00:04:00,000
they're wearing these colorful hats and
are thinking and swaying directly in

61
00:04:00,001 --> 00:04:01,890
front of the glass toward headquarters of,

62
00:04:02,320 --> 00:04:06,990
yeah, it's nice. And one or graphics.
Facebook is their phone call.

63
00:04:09,490 --> 00:04:10,323
Yes.

64
00:04:11,020 --> 00:04:15,160
It was a humble gathering of
a few dozen women and babies.

65
00:04:15,340 --> 00:04:16,660
That right there. Are you,

66
00:04:16,661 --> 00:04:19,960
the organizer tonight is one of
the organizers of the gathering,

67
00:04:21,130 --> 00:04:21,190
Stephanie Mujer.

68
00:04:21,190 --> 00:04:24,840
And what, what are you calling the
event? Um, it's a Facebook nursing

69
00:04:24,940 --> 00:04:27,100
nursing as in like breastfeeding.

70
00:04:27,460 --> 00:04:32,460
The intent was really just to be visible
and be peaceful and make a quiet point.

71
00:04:34,120 --> 00:04:36,220
What a, what point were
they trying to make?

72
00:04:36,380 --> 00:04:39,050
Well, uh, so Stephanie, in this
group of mothers, you know,

73
00:04:39,051 --> 00:04:43,670
they were on Facebook as many people
were and they'd have photos taken of

74
00:04:43,671 --> 00:04:46,220
themselves occasionally
breastfeeding their babies.

75
00:04:46,310 --> 00:04:48,410
They wanted to share with their
friends what was going on.

76
00:04:48,411 --> 00:04:53,411
So they would upload those
photos to Facebook and these
pictures would get taken

77
00:04:53,871 --> 00:04:58,040
down and they would receive a warning
from Facebook for uploading, um,

78
00:04:58,070 --> 00:05:02,480
pornographic content. And people were
really getting their backs up over this.

79
00:05:03,350 --> 00:05:06,920
They wanted Facebook to stop taking
their photos down to say that, well,

80
00:05:06,921 --> 00:05:10,820
nudity is not allowed.
Breastfeeding is exempt, period

81
00:05:11,590 --> 00:05:15,780
and goes back [inaudible]

82
00:05:17,110 --> 00:05:22,110
now what Stephanie couldn't have
known at the time was that this

83
00:05:23,000 --> 00:05:23,180
small,

84
00:05:23,180 --> 00:05:28,180
peaceful protest would turn out to be
this morning of face off on Facebook.

85
00:05:28,910 --> 00:05:30,530
One of the opening shots.

86
00:05:30,560 --> 00:05:34,730
Facebook triggered a Hornet's nest
in what would become a loud fuck you

87
00:05:34,731 --> 00:05:39,680
Facebook. [inaudible] Facebook
Rawkus fuck you, Facebook, fuck you.

88
00:05:39,830 --> 00:05:44,300
And global battle in battles. Facebook
CEO's book today playing defense.

89
00:05:44,390 --> 00:05:48,770
And now I'm not talking about all the
things you've recently heard about Russian

90
00:05:48,771 --> 00:05:52,430
interference in election
meddling or data breaches, but,

91
00:05:52,431 --> 00:05:55,200
but rather something
that I think is a is deep

92
00:05:55,530 --> 00:05:58,320
then both of those free speech, Facebook,

93
00:05:58,320 --> 00:06:00,190
his minute Hughes are facilitating. Yeah,

94
00:06:00,250 --> 00:06:04,870
violence against Rohingya Muslims we
can say and what we can't say but again,

95
00:06:04,871 --> 00:06:05,830
Facebook vine,

96
00:06:06,030 --> 00:06:10,420
this iconic photographs we can see and
what we can see Mueller rape kids in

97
00:06:10,421 --> 00:06:10,980
front of people.

98
00:06:10,980 --> 00:06:12,210
Do you want to close this one?

99
00:06:12,540 --> 00:06:13,373
Hear me.

100
00:06:16,360 --> 00:06:18,690
[inaudible] you are fucking theses yet.

101
00:06:22,190 --> 00:06:26,870
Thank you Mr Chairman. Uh, Mr
Zuckerberg got gotta ask you,

102
00:06:27,350 --> 00:06:31,130
do you subjectively
prioritized or censor speech?

103
00:06:33,400 --> 00:06:34,233
Congresswoman,

104
00:06:34,300 --> 00:06:39,300
we don't think about what we're doing
is censoring speech but there are types

105
00:06:40,331 --> 00:06:42,370
of, what really grabbed me was,

106
00:06:42,970 --> 00:06:47,970
was discovering that underneath
all of this is an actual rule book,

107
00:06:49,390 --> 00:06:54,390
a text document that dictates
what I can say on Facebook.

108
00:06:54,760 --> 00:06:59,760
What you can say on Facebook and what
all 2.2 billion of us can say on Facebook

109
00:07:00,670 --> 00:07:03,470
for everyone in the entire
globe for everyone. One,

110
00:07:03,550 --> 00:07:07,710
one set of rules that all 2.2
billion of us are expected to follow.

111
00:07:08,700 --> 00:07:09,850
This is an actual document.

112
00:07:10,000 --> 00:07:12,490
It's a digital document, but
yes, it's about 50 pages.

113
00:07:12,491 --> 00:07:17,230
If you print it off and a in bullet
points and if then statements,

114
00:07:17,260 --> 00:07:20,410
it spells out sort of a first
amendment for the globe,

115
00:07:21,220 --> 00:07:25,240
which made me wonder like
what are these rules?

116
00:07:25,600 --> 00:07:30,040
How were they written? And can you even
have one rule book? Right, exactly.

117
00:07:30,190 --> 00:07:30,850
And so I,

118
00:07:30,850 --> 00:07:35,850
I dove into this rule book and dug up
some stories that really put it to the

119
00:07:36,461 --> 00:07:37,294
test.

120
00:07:37,440 --> 00:07:39,960
Hm. Okay. Yeah, I'm interested in
with the stories we're going to hear.

121
00:07:39,961 --> 00:07:43,000
We are going to three ish.
Three ish. Okay. Okay. Alright.

122
00:07:43,190 --> 00:07:45,120
I'm particular interested in the ish,
but let's go ahead with the first one.

123
00:07:45,140 --> 00:07:49,280
Well, so, uh, let's start back,
uh, on that morning in 2008,

124
00:07:49,400 --> 00:07:51,620
the morning that you could
argue started at all,

125
00:07:52,170 --> 00:07:54,250
right? Right. Cause

126
00:07:54,600 --> 00:07:57,060
building right behind
those protesting mothers,

127
00:07:57,150 --> 00:08:01,650
there was a group of Facebook employees
sitting in a conference room trying to

128
00:08:01,651 --> 00:08:04,620
figure out what to do. Um, cool. So if I,

129
00:08:04,830 --> 00:08:06,780
so I'm just gonna switch to just read.

130
00:08:06,781 --> 00:08:10,200
So I was able to get in touch with a
couple of former Facebook employees,

131
00:08:10,500 --> 00:08:13,050
one of whom was actually in
that room at that moment.

132
00:08:13,680 --> 00:08:16,590
And now neither of these two were
comfortable being identified,

133
00:08:16,591 --> 00:08:20,640
but they did give us permission to quote
them extensively. How's that? Well,

134
00:08:20,641 --> 00:08:23,370
they'll take work for you. It sounded
great. Um, cool. Just so we have it,

135
00:08:23,660 --> 00:08:25,630
let's, so what you're
going to hear here is,

136
00:08:25,631 --> 00:08:29,520
is an actor we brought in to read quotes
taken directly from interviews that we

137
00:08:29,521 --> 00:08:33,660
did with these two different former
Facebook in place. [inaudible] all right,

138
00:08:33,661 --> 00:08:37,380
ready? So at the time when I joined them,

139
00:08:37,381 --> 00:08:39,750
there was a smaller group, 12 of us,

140
00:08:39,751 --> 00:08:43,800
mostly recent college grads who were
sort of called the site integrity team.

141
00:08:43,890 --> 00:08:45,750
Again, keep in mind, this
was in the early [inaudible]

142
00:08:45,980 --> 00:08:49,250
thousands seismic changes this
week in the Internet hierarchy.

143
00:08:49,280 --> 00:08:51,230
This was like the deep, dark past.

144
00:08:51,510 --> 00:08:55,980
My space.com is now the most visited
website in the U. Of course, Facebook

145
00:08:56,220 --> 00:08:58,800
had somewhere in the
neighborhood of 10 million users.

146
00:08:58,920 --> 00:09:02,460
We were smaller than my space. The
vast majority of them, college kids.

147
00:09:02,730 --> 00:09:05,350
And so in those early days,
those 12 people, they would,

148
00:09:05,351 --> 00:09:09,510
they would sit around in
a sort of conference like
room with a big long table,

149
00:09:09,900 --> 00:09:11,750
each of them in front
of their own computer

150
00:09:11,860 --> 00:09:15,490
and things would come up onto
their screen flagged to Facebook.

151
00:09:16,120 --> 00:09:16,910
And I'm like

152
00:09:16,910 --> 00:09:19,840
meaning like I a user saw something
that I thought was wrong. Okay.

153
00:09:19,910 --> 00:09:23,150
Exactly like a reporting a piece of
content that you think violates the

154
00:09:23,151 --> 00:09:24,110
community standards.

155
00:09:24,200 --> 00:09:25,220
This is Kate clonic,

156
00:09:25,221 --> 00:09:29,570
she's a professor of law at St John's
and she spent a lot of time studying this

157
00:09:29,571 --> 00:09:30,800
very thing and,

158
00:09:30,840 --> 00:09:35,180
and she says in those early days what
would happen is a user would flag a piece

159
00:09:35,181 --> 00:09:38,940
of content and then that content
along with an alert would,

160
00:09:39,100 --> 00:09:41,990
would get sent to one of those
people sitting in that room.

161
00:09:42,050 --> 00:09:43,820
It would just pop up on their screen.

162
00:09:43,910 --> 00:09:48,910
Most of what you were seeing was either
naked people blown off heads or things

163
00:09:49,761 --> 00:09:51,920
that there was no clear reason
why someone had reported,

164
00:09:52,130 --> 00:09:56,450
cause it was like a photo of a golden
retriever and people are just annoying.

165
00:09:56,540 --> 00:09:58,820
And every time something
popped up onto the screen,

166
00:09:58,821 --> 00:10:02,510
the person sitting at that computer
would have to make a decision whether to

167
00:10:02,511 --> 00:10:05,420
leave that thing up or take
it down. And at the time,

168
00:10:05,421 --> 00:10:08,930
if you didn't know what to do, you
would turn to your pod leader who was,

169
00:10:08,960 --> 00:10:09,440
you know,

170
00:10:09,440 --> 00:10:12,800
somebody who had been around nine months
longer than you and ask what do I do

171
00:10:12,801 --> 00:10:13,634
with this?

172
00:10:14,210 --> 00:10:18,050
And they would either have seen it
before and explain it to you or you both

173
00:10:18,240 --> 00:10:20,420
would know and you'd Google some things.

174
00:10:20,540 --> 00:10:23,210
It really was just kind
of an ad hoc approach.

175
00:10:23,250 --> 00:10:27,390
Was there any sort of written standard
or any common standard? A well kind of,

176
00:10:27,510 --> 00:10:31,080
they had a set of community standards
that they, at the end of the day,

177
00:10:31,081 --> 00:10:34,580
they were just kind of, that was one
page long and it was not very specific.

178
00:10:34,610 --> 00:10:38,330
Sorry. The, the guidelines were really
one page long. They were one page long.

179
00:10:38,660 --> 00:10:43,580
And basically all this page said
was nudity is bad, so is Hitler.

180
00:10:43,690 --> 00:10:46,480
And um, if it makes you
feel bad, take it down.

181
00:10:46,740 --> 00:10:50,250
And so when one of the people sitting
in that room would have a breastfeeding

182
00:10:50,340 --> 00:10:53,760
picture pop up on the screen in
front of them, they'd be like,

183
00:10:54,270 --> 00:10:57,420
I can see a female breast.
So I guess that's nudity.

184
00:10:57,450 --> 00:10:59,150
And they would take it down until

185
00:11:00,870 --> 00:11:04,530
rise up, fight for the
rights to have breastfeeding.

186
00:11:05,340 --> 00:11:09,500
Anyway, now a dozen or so people in
front of their offices on a Saturday.

187
00:11:09,630 --> 00:11:14,250
It probably wasn't causing Facebook too
much heartache, but I thought, you know,

188
00:11:14,251 --> 00:11:16,260
hey, we have an opportunity
here with, you know,

189
00:11:16,261 --> 00:11:19,160
over 10,000 members in our group.
According to Stephanie Mirror.

190
00:11:19,180 --> 00:11:24,180
Those protesters were just a tiny fraction
of a much larger online group who had

191
00:11:24,871 --> 00:11:27,140
organized, ironically
enough through Facebook.

192
00:11:27,210 --> 00:11:29,910
So to coincide with the live protest,

193
00:11:29,940 --> 00:11:34,940
I just typed up a little blurb encouraging
our members that were in the group to

194
00:11:35,761 --> 00:11:39,870
do a virtual nurse in a
virtual nursing, right.

195
00:11:39,960 --> 00:11:43,820
What we did, they posted a message
asking their members to for

196
00:11:44,510 --> 00:11:44,840
[inaudible],

197
00:11:44,840 --> 00:11:49,840
changed their profile Avatar to an image
of breastfeeding and then changed their

198
00:11:51,171 --> 00:11:53,890
status to the of our group.

199
00:11:54,070 --> 00:11:58,420
Hey, Facebook. Breastfeeding is
not obscene and it caught on.

200
00:11:58,450 --> 00:12:02,710
A social networking website is under
fire for its policy on photos of women

201
00:12:02,711 --> 00:12:03,990
breastfeeding their children.

202
00:12:04,400 --> 00:12:08,950
12,000 members participated and the
media requests and started pouring in the

203
00:12:08,951 --> 00:12:11,640
Facebook group call. Hey, Facebook.
Breastfeeding is not good.

204
00:12:11,860 --> 00:12:16,780
I did hundreds of interviews for
print, Chicago Tribune, Miami Herald,

205
00:12:16,810 --> 00:12:20,690
Time magazine, New York
Times, Washington Post. No,

206
00:12:20,710 --> 00:12:24,220
the Internet is an interesting
phenomenon. Dr Phil.

207
00:12:24,490 --> 00:12:26,170
It was a media storm

208
00:12:27,040 --> 00:12:31,810
and eventually perhaps as a result
of our group and our efforts,

209
00:12:31,840 --> 00:12:36,840
Facebook was forced to get much
more specific about their rules.

210
00:12:38,500 --> 00:12:41,770
So for example, by then, nudity was
already not allowed on the site,

211
00:12:41,950 --> 00:12:45,490
but they had no definition for
nudity. They just said no nudity.

212
00:12:45,520 --> 00:12:48,580
And so the site integrity team,
the those 12 people at the time,

213
00:12:48,640 --> 00:12:52,180
they realized they had to start
spelling out exactly what they meant.

214
00:12:52,280 --> 00:12:55,700
It's precisely all of these people at
Facebook were in charge of trying to

215
00:12:55,701 --> 00:12:56,690
define nudity.

216
00:12:56,760 --> 00:12:58,250
So I mean, yeah, the first cutout,

217
00:12:58,290 --> 00:13:03,290
it was visible male and female genitalia
and then visible female breasts.

218
00:13:04,230 --> 00:13:06,600
And then the question is, well, okay,

219
00:13:06,601 --> 00:13:10,170
how much of a breast needs to be showing
before it's nude and the thing that we

220
00:13:10,171 --> 00:13:13,830
landed on was if you could see
essentially the nipple and Areola,

221
00:13:14,160 --> 00:13:16,830
then that's nudity and it
would have to be taken down,

222
00:13:17,340 --> 00:13:18,630
which theoretically at least

223
00:13:18,690 --> 00:13:23,340
would appease these protesters because
you know now when a picture would pop up

224
00:13:23,670 --> 00:13:24,660
of a mother breastfeeding,

225
00:13:25,200 --> 00:13:28,860
as long as the child was blocking the
view of the nipple and the Areola,

226
00:13:29,000 --> 00:13:30,900
they they could say, cool, no problem.

227
00:13:30,990 --> 00:13:35,040
Then you start getting pictures that are
women with just their babies on their

228
00:13:35,041 --> 00:13:38,970
chest with their breasts
bare. Like for example,

229
00:13:38,971 --> 00:13:42,570
maybe baby was sleeping on the chest of
a bare breasted woman and not actively

230
00:13:42,571 --> 00:13:43,100
breastfeeding.

231
00:13:43,100 --> 00:13:46,850
Okay. Now what? Like is this
actually breastfeeding? No,

232
00:13:46,851 --> 00:13:48,020
it's actually not breastfeeding.

233
00:13:48,021 --> 00:13:50,450
The woman is just holding the
baby and she has her top off.

234
00:13:50,830 --> 00:13:53,050
No, but she was clearly
just breastfeeding the baby.

235
00:13:53,420 --> 00:13:54,800
Well like it was before.

236
00:13:55,310 --> 00:13:58,070
Well I would say it's sort of
like kicking a soccer ball,

237
00:13:58,250 --> 00:14:00,950
like a photo of someone who has
just kicked the soccer ball.

238
00:14:00,951 --> 00:14:02,540
You can tell the ball is in the air,

239
00:14:02,541 --> 00:14:05,960
but there was no contact between
the foot and the ball in that moment

240
00:14:05,961 --> 00:14:09,410
potentially. So although it is a photo
of someone kicking a soccer ball,

241
00:14:09,411 --> 00:14:12,590
they are not in fact kicking
the soccer ball in that photo.

242
00:14:13,400 --> 00:14:14,330
That's a good in this,

243
00:14:14,390 --> 00:14:19,130
this became the procedure or the protocol
or the approach for all these things

244
00:14:19,131 --> 00:14:22,970
was we have to base it purely
on what we can see in the image

245
00:14:23,120 --> 00:14:27,650
and so it didn't allow that to stay up
under the rules because it could be too

246
00:14:27,651 --> 00:14:31,430
easily exploited for other types of
content like nudity or pornography.

247
00:14:31,550 --> 00:14:32,231
W We got to,

248
00:14:32,231 --> 00:14:34,870
the only way you could objective only
say that the baby and the mother were

249
00:14:34,871 --> 00:14:39,010
engaged in breastfeeding is if the baby's
lips were touching a woman's nipple.

250
00:14:39,130 --> 00:14:42,490
So they included what you could
call like an attachment clause.

251
00:14:42,640 --> 00:14:47,200
But as soon as they got that rule in
place, like you would see, you know,

252
00:14:47,560 --> 00:14:50,800
a 25 year old woman and a
teenager looking boy. Right.

253
00:14:50,860 --> 00:14:52,760
And like what the hell is going on there?

254
00:14:52,850 --> 00:14:53,360
Oh yeah.

255
00:14:53,360 --> 00:14:56,990
It gets really weird if you like start
entering into like child age and it

256
00:14:56,991 --> 00:14:58,790
wasn't even gonna bring that
up cause it's kind of gross.

257
00:14:59,330 --> 00:15:01,370
It's like breastfeeding
porn, is that a thing?

258
00:15:01,430 --> 00:15:04,580
Are there sites like half
apparently. And so this team,

259
00:15:04,581 --> 00:15:08,480
they realized they needed to have a new
duty rule that allowed for breastfeeding

260
00:15:08,780 --> 00:15:10,970
but also had some kind of an age cap.

261
00:15:11,320 --> 00:15:15,850
So, so, uh, so then we were saying, okay,
once you've progressed past infancy,

262
00:15:15,851 --> 00:15:16,970
then we believe that it's an approval

263
00:15:17,300 --> 00:15:17,570
Britt.

264
00:15:17,570 --> 00:15:21,410
But then pictures would start popping
up on their screen and they'd be like,

265
00:15:21,411 --> 00:15:25,580
wait, is that an infant? Like where's
the line between infant and toddler?

266
00:15:25,680 --> 00:15:29,310
And so the thing that we landed on was
if it looked like the child could walk on

267
00:15:29,311 --> 00:15:32,490
his or her own, then too
old, big enough to walk

268
00:15:32,720 --> 00:15:34,820
too big to breastfeed. Oh that
could be [inaudible]. Yeah,

269
00:15:34,821 --> 00:15:36,890
that's like a year old
in some cases. Yeah.

270
00:15:36,950 --> 00:15:40,730
And like the World Health Organization
recommends breastfeeding until you know,

271
00:15:40,731 --> 00:15:42,470
like 18 months or two years,

272
00:15:42,920 --> 00:15:47,920
which meant there were a lot of photos
still being taken down within you know,

273
00:15:48,201 --> 00:15:49,034
days.

274
00:15:49,100 --> 00:15:54,020
We continuing to hear reports from
people that their photographs were still

275
00:15:54,021 --> 00:15:55,700
being targeted. But

276
00:15:56,370 --> 00:15:59,790
Facebook did offer a statement saying
that's where we're going to draw the

277
00:16:09,300 --> 00:16:09,490
line@facebookusingbudgetingonitpolicyandkeepinmindthroughthiswholeepisodeisthisperhapsthenextbigthingandthefacebook.com

278
00:16:09,490 --> 00:16:11,380
the company was growing
really, really fast.

279
00:16:11,500 --> 00:16:14,060
It seems like almost
everyone is on it and it's,

280
00:16:14,120 --> 00:16:17,150
and there just got to
be a lot more content.

281
00:16:17,210 --> 00:16:19,190
When we first launched we
were hoping for, you know,

282
00:16:19,191 --> 00:16:23,960
maybe 400 500 people and now we're at
100,000 so who knows where we're going

283
00:16:23,961 --> 00:16:27,320
now? [inaudible] more people
are joining Facebook every day,

284
00:16:27,321 --> 00:16:32,120
60 million users so far with a projection
of 200 million by the end of the year

285
00:16:32,121 --> 00:16:35,300
and now more people on Facebook
than the entire us population.

286
00:16:35,301 --> 00:16:38,540
Not just within the United States,
but also it was growing rapidly.

287
00:16:38,541 --> 00:16:41,970
More International, you know,
you were getting spokes in India,

288
00:16:42,770 --> 00:16:47,090
India and Turkey. Facebook,
Facebook is going to ran this.

289
00:16:47,430 --> 00:16:51,620
Butch was getting big throughout
the EU. Korea's joined the Facebook.

290
00:16:51,680 --> 00:16:55,550
So they have more and more content coming
in from all these different places,

291
00:16:55,551 --> 00:16:57,010
in all different languages.

292
00:16:58,470 --> 00:17:00,840
How are we going to keep
everybody on the same page?

293
00:17:02,820 --> 00:17:07,350
And so once they saw that this was the
operational method for dealing with this,

294
00:17:07,770 --> 00:17:11,940
creating this like nesting
set of exceptions and rules
and these clear things

295
00:17:11,941 --> 00:17:12,920
that had to be there,

296
00:17:12,990 --> 00:17:15,990
had to not be there in order to
keep content up or take it down,

297
00:17:16,350 --> 00:17:18,690
that I think became their procedure.

298
00:17:18,930 --> 00:17:22,530
And so this small team at Facebook
got a little bigger and bigger,

299
00:17:22,770 --> 00:17:27,240
jumped up to 60 people and then a hundred
and they set out to create rules and

300
00:17:27,241 --> 00:17:29,970
definitions for everything. Huh?

301
00:17:30,000 --> 00:17:33,570
Can we go through some of sort of the
ridiculous examples? Let's go over here.

302
00:17:33,990 --> 00:17:37,500
Hey, so Gore Gore, you mean
violence? [inaudible] yes.

303
00:17:37,770 --> 00:17:39,120
So the Gore Standard was

304
00:17:39,330 --> 00:17:42,180
headline. We don't allow
graphic violence and Gore.

305
00:17:42,270 --> 00:17:46,070
And then the shorthand definition they
used was no insides on the [inaudible].

306
00:17:46,620 --> 00:17:50,310
No guts, no blood pouring out
of [inaudible] was a separate

307
00:17:50,310 --> 00:17:51,390
issue. There was, uh,

308
00:17:51,440 --> 00:17:55,980
an excessive blood rule and to come
up with rules about bodily fluids,

309
00:17:56,340 --> 00:17:58,650
semen for example, would be
allowed in like a clinical setting.

310
00:17:58,651 --> 00:18:01,650
But like what does a clinical
setting mean? And you know,

311
00:18:01,651 --> 00:18:03,720
does that mean if
someone is in a lab coat?

312
00:18:04,330 --> 00:18:08,090
Hmm. At one of my favorite examples
is like, how do you define art?

313
00:18:08,170 --> 00:18:10,060
Because as these people are moderating,

314
00:18:10,180 --> 00:18:15,180
they would see images of naked people
that were paintings or sculptures come up.

315
00:18:16,930 --> 00:18:20,800
And so what they decided to do is
say art with nakedness can stay up.

316
00:18:20,870 --> 00:18:24,830
Like it stays up if it is made
out of wood made out of metal.

317
00:18:24,980 --> 00:18:28,040
Made out of stone. Really? Yeah.

318
00:18:28,070 --> 00:18:31,520
Because how else do you define
art? You have to just be like,

319
00:18:32,060 --> 00:18:35,060
is this what you can see with your
eyeballs? And so from then on,

320
00:18:35,061 --> 00:18:36,470
as they run into problems,

321
00:18:36,500 --> 00:18:40,300
those rules just constantly get
updated or constant amendments. Yeah.

322
00:18:40,340 --> 00:18:41,420
Constant amendments,

323
00:18:41,820 --> 00:18:46,050
new problem, new rule, another
new problem. Updated rule.

324
00:18:46,380 --> 00:18:48,390
In fact, at this point, they,

325
00:18:48,391 --> 00:18:53,160
they're amending these rules up
to 20 times a month. Wow. Really?

326
00:18:53,161 --> 00:18:55,590
Yeah. Take for example those
rules about breastfeeding.

327
00:18:55,680 --> 00:19:00,680
In 2013 they removed the attachment clause
so the baby no longer needed to have

328
00:19:03,091 --> 00:19:07,650
its mouth physically touching the
nipple of the woman. Oh. And in fact,

329
00:19:08,140 --> 00:19:08,240
uh,

330
00:19:08,240 --> 00:19:13,240
one nipple and or areola
could be visible in the photo,

331
00:19:13,350 --> 00:19:14,760
but not too only one.

332
00:19:14,910 --> 00:19:19,910
Then 2014 they make it so
that both nipples or both
Areola may be present in the

333
00:19:21,331 --> 00:19:24,710
photo. So this is what happens in American
law all the time. It's very thing.

334
00:19:24,770 --> 00:19:28,520
Yes. Yeah, yeah. You know, it
sounds a lot like common law.

335
00:19:29,400 --> 00:19:33,810
So common law is the system dating back
to early England where individual judges

336
00:19:33,811 --> 00:19:36,120
would make a ruling, which
would sort of be a law,

337
00:19:36,180 --> 00:19:39,480
but then that law would be amended
or evolved by other judges.

338
00:19:40,240 --> 00:19:44,620
So the body of law was sort of constantly
flushed out and face of new facts.

339
00:19:46,020 --> 00:19:49,740
Literally every time this team at Facebook
would come up with a rule that they

340
00:19:49,741 --> 00:19:53,010
thought was airtight come, plop something,

341
00:19:53,380 --> 00:19:55,980
something would show up that day
that they weren't prepared for that,

342
00:19:56,370 --> 00:20:00,480
that the rule hadn't accounted a, as
soon as you think, yeah, this is good.

343
00:20:00,481 --> 00:20:02,970
Like the next day something
shows up to show you. Yeah,

344
00:20:02,971 --> 00:20:05,010
you didn't think about this. For example,

345
00:20:05,040 --> 00:20:08,390
sometime around 2011 this
content moderator is, is,

346
00:20:08,391 --> 00:20:10,410
is going through a queue of things

347
00:20:10,660 --> 00:20:14,470
except reject, except escalate.

348
00:20:15,070 --> 00:20:15,903
Except

349
00:20:16,030 --> 00:20:17,380
she comes upon this image.

350
00:20:17,780 --> 00:20:18,613
Oh my God.

351
00:20:19,450 --> 00:20:21,400
The photo itself was a teenage girl,

352
00:20:21,700 --> 00:20:26,410
African by dress and skin
breastfeeding a goat of baby goats.

353
00:20:26,790 --> 00:20:30,340
Hm. And the moderator throws their hands
up and says, what the fuck is this?

354
00:20:30,430 --> 00:20:34,810
And we googled breastfeeding goats
and found that this was a thing.

355
00:20:35,080 --> 00:20:38,740
It turns out it's a survival practice
according to what they found.

356
00:20:38,741 --> 00:20:42,310
This is a tradition in Kenya
that goes back centuries,

357
00:20:42,340 --> 00:20:44,200
that in a drought,

358
00:20:44,670 --> 00:20:49,660
a known way to help your herd through
the drought is to, uh, if you,

359
00:20:49,661 --> 00:20:54,370
if you have a woman who's lactating, to
have her nurse, the kid, the baby goat,

360
00:20:54,490 --> 00:20:59,350
along with her human kit. Hmm. And
so there's nothing sexual about it,

361
00:20:59,351 --> 00:21:02,650
just good for business.
Good. And theoretically,

362
00:21:02,830 --> 00:21:07,630
if we go point by point through
this list, it's an infant.

363
00:21:08,640 --> 00:21:11,010
It's SORTA could walk. So maybe
there's an issue there, but there,

364
00:21:11,011 --> 00:21:14,080
there's physical contact between
the mouth and the nipple. But,

365
00:21:14,950 --> 00:21:18,310
but obviously breastfeeding
as we intended anyway,

366
00:21:18,311 --> 00:21:23,230
meant human infants. And so in that
moment, what they decided to do is,

367
00:21:23,690 --> 00:21:24,220
uh,

368
00:21:24,220 --> 00:21:27,940
remove the photo and there
was an amendment and asterick
under the rule stating

369
00:21:27,941 --> 00:21:31,150
animals are not babies. We added
that. So in any future cases,

370
00:21:31,151 --> 00:21:33,670
people would know what to do,
who they removed. They, they,

371
00:21:33,970 --> 00:21:37,540
they discover it was culturally
appropriate and a thing that people do.

372
00:21:37,660 --> 00:21:40,660
And they decide to remove the photo.
Yeah. That outraged individuals,

373
00:21:40,840 --> 00:21:43,300
our editors who are in wheeler. Why?
Why didn't we make an exception?

374
00:21:43,330 --> 00:21:47,500
Because because when a problem grows large
enough, you have to change the rules.

375
00:21:47,530 --> 00:21:50,140
If not, we don't, this was
not one of those cases.

376
00:21:50,500 --> 00:21:55,090
The juice wasn't worth the squeeze. And
like if they were to allow this picture,

377
00:21:55,091 --> 00:21:59,170
then they'd have to make some rule
about when it was okay to breastfeed and

378
00:21:59,171 --> 00:22:03,460
animal and when it wasn't okay.
This is a utilitarian document.

379
00:22:03,820 --> 00:22:06,280
It's not about being
right 100% of the time.

380
00:22:06,490 --> 00:22:09,370
It's about being able
to execute effectively.

381
00:22:12,450 --> 00:22:13,110
In other words,

382
00:22:13,110 --> 00:22:16,770
we're not trying to be perfect here and
we're not even necessarily trying to be

383
00:22:16,920 --> 00:22:21,420
100% just or fair. We're just
trying to make something that works.

384
00:22:24,420 --> 00:22:26,430
One, two, three, four, five, six, seven,

385
00:22:26,431 --> 00:22:31,431
eight and when you step back and look at
what Facebook has become like from 2008

386
00:22:32,580 --> 00:22:34,020
to now in just 10 years,

387
00:22:34,330 --> 00:22:35,430
Simon, um,

388
00:22:35,470 --> 00:22:40,420
I've just arrived at the
Accenture tower here in Manila.

389
00:22:40,600 --> 00:22:43,010
I don't know how many
floors. It is one too

390
00:22:43,480 --> 00:22:47,970
idea of a single set of rules that
works that can be applied fairly. Yes.

391
00:22:47,980 --> 00:22:49,850
Just a crazy, crazy concept.

392
00:22:50,070 --> 00:22:51,720
Just 1516 or 17

393
00:22:52,070 --> 00:22:56,090
they've gone from something like
70 million users to 2.2 billion.

394
00:22:56,230 --> 00:22:59,580
It's hard to take camp. I
would say it's about 30 floors.

395
00:22:59,690 --> 00:23:03,590
They've gone from 12 folks sitting in a
room deciding what to take down or leave

396
00:23:03,591 --> 00:23:06,230
up to somewhere around 16,000 people.

397
00:23:06,650 --> 00:23:11,600
So there's a floor in this building where
Facebook supposedly outsources content

398
00:23:11,601 --> 00:23:12,434
moderators.

399
00:23:12,750 --> 00:23:17,010
And so around 2010 they decided to start
outsourcing some of this work to places

400
00:23:17,011 --> 00:23:21,420
like Manila where you just heard
reporter Aurora almond drawl as well as,

401
00:23:21,840 --> 00:23:22,081
I mean,

402
00:23:22,081 --> 00:23:25,470
I would guess that there are thousands
of people in this building Dublin where

403
00:23:25,530 --> 00:23:28,010
we sent reporter Gareth's stack Oh,

404
00:23:28,150 --> 00:23:30,600
can see in where they get their
delicious Facebook treats cooked.

405
00:23:30,870 --> 00:23:31,890
Everybody's beavering away.

406
00:23:32,100 --> 00:23:35,310
And we sent them there to try to talk
to some of these people too for living,

407
00:23:35,311 --> 00:23:39,600
sit at a computer and collectively click
through around a million flagged bits

408
00:23:39,601 --> 00:23:43,180
of content that pop up onto their
screen every day. Wow. What a,

409
00:23:43,260 --> 00:23:45,060
I'm just curious. Like
what's, what's that?

410
00:23:46,050 --> 00:23:49,300
Well, um, can I ask you some questions?

411
00:23:51,120 --> 00:23:53,590
[inaudible] we'd found out
pretty quickly the work floor.

412
00:23:53,650 --> 00:23:56,930
None of these folks are willing to
talk to us about what they do. Um,

413
00:23:56,980 --> 00:23:59,640
so there's a lot of, uh,
running away from me happening.

414
00:23:59,670 --> 00:24:02,540
Hey, let's sir, sorry to bother you. Do
you guys work in Facebook? I'm sorry.

415
00:24:02,840 --> 00:24:06,320
You have to work in Facebook anytime. I,
sorry to bother you. Do you reconcile?

416
00:24:06,390 --> 00:24:09,420
No. Sorry. Do you work in Facebook? No.

417
00:24:10,230 --> 00:24:14,550
I mean like you just came out of
there. I know you're lying. In fact,

418
00:24:14,880 --> 00:24:18,060
people wouldn't even admit they work
for the company. Like what's the,

419
00:24:18,150 --> 00:24:21,660
is there something wrong about being
in navy? Like an NDA that they signed?

420
00:24:21,920 --> 00:24:25,680
Well, yeah, so, so when I finally
did find someone willing, uh,

421
00:24:25,860 --> 00:24:29,030
willing to talk to me, do you
want to be named or do you know,

422
00:24:29,160 --> 00:24:30,390
or do you not want to be named?

423
00:24:30,480 --> 00:24:32,160
I'd rather not.

424
00:24:33,370 --> 00:24:34,070
That's totally fine.

425
00:24:34,070 --> 00:24:35,290
You know, I'm just
kinda like the industry.

426
00:24:35,291 --> 00:24:37,000
I don't want to lose like
up on this shit. Yeah.

427
00:24:37,420 --> 00:24:41,170
He explained that he and all the other
moderators like him were forced to sign

428
00:24:41,171 --> 00:24:45,320
these nondisclosure agreements
stating they weren't allowed to, uh,

429
00:24:45,400 --> 00:24:47,470
admit that they work for Facebook.

430
00:24:47,710 --> 00:24:49,720
They're not allowed to talk
about the work they do.

431
00:24:49,790 --> 00:24:50,623
My contract,

432
00:24:51,090 --> 00:24:54,890
I hated to prohibit any from tackler
about what content moderation was.

433
00:24:55,000 --> 00:24:58,660
Why? Several reasons. One
is that up until recently,

434
00:24:58,661 --> 00:25:02,380
Facebook wanted to keep secret what
these rules were so that they couldn't be

435
00:25:02,381 --> 00:25:04,570
gamed. At the same time, it,

436
00:25:04,660 --> 00:25:08,530
it creates a sort of separation
between these workers and the company,

437
00:25:08,590 --> 00:25:10,750
which if you're Facebook, you might want,

438
00:25:11,030 --> 00:25:14,120
yeah, I, I knew I signed up
to monitor with graphic images

439
00:25:14,230 --> 00:25:15,910
just given the nature of the job.

440
00:25:16,310 --> 00:25:17,570
Right. You know, I
didn't really, you know,

441
00:25:17,571 --> 00:25:22,460
you don't really know the impact that
that's gonna have on you until you got

442
00:25:22,461 --> 00:25:22,960
through it.

443
00:25:22,960 --> 00:25:24,150
This guy talked to he,

444
00:25:24,151 --> 00:25:27,520
he got his first contract doing this
work several years back and for the

445
00:25:27,521 --> 00:25:30,700
duration of it, about a year, he'd
show up to his desk every morning,

446
00:25:30,730 --> 00:25:34,630
put on his headphones. Okay, click, click,
click, click, click, ignore, delete,

447
00:25:35,080 --> 00:25:35,520
delete.

448
00:25:35,520 --> 00:25:36,900
Case by case by case by case.

449
00:25:37,200 --> 00:25:41,870
45 5,000 kids every day was just
image and decision, image decision.

450
00:25:41,950 --> 00:25:44,380
Which five, 5,000 a day you just said.

451
00:25:44,480 --> 00:25:46,240
Yeah. It was like, there
was a lot of cases. Yes.

452
00:25:46,470 --> 00:25:49,950
He, he said basically he'd have to go
through an image or some other piece of

453
00:25:49,951 --> 00:25:54,240
content every three or four
seconds. Wow. All Day long. All Day.

454
00:25:54,300 --> 00:25:55,133
Eight hours a day.

455
00:25:55,770 --> 00:25:56,603
Wow.

456
00:26:01,860 --> 00:26:05,190
Well, if I can ask, what
kind of things did you see?

457
00:26:05,870 --> 00:26:07,590
Oh, I don't know if this is even a,

458
00:26:07,591 --> 00:26:11,490
I don't know if this is like
radio is worthy. Um, it's true.

459
00:26:11,491 --> 00:26:13,610
I think the accelerated, uh, no

460
00:26:13,920 --> 00:26:16,980
clicking through, he came
across unspeakable things.

461
00:26:17,370 --> 00:26:21,530
Some had exploded into, you know,
get the little squashed by a tank to,

462
00:26:21,560 --> 00:26:23,810
you know, people in cages
being drowned too. Like

463
00:26:26,690 --> 00:26:29,990
a 13 year old girl. Um,

464
00:26:30,200 --> 00:26:34,190
having sex with an eight year
old boy and it's not just one,

465
00:26:34,490 --> 00:26:36,800
it's over. I know. Right. Oh, right. Over

466
00:26:38,050 --> 00:26:40,920
when did you, did this like keep
you up at night or did you did this

467
00:26:41,230 --> 00:26:45,350
absolutely, absolutely 100%. Um,

468
00:26:46,050 --> 00:26:47,700
and kept me up at night, uh,

469
00:26:47,880 --> 00:26:50,850
catch himself thinking about these
videos and photos when he was trying to

470
00:26:50,851 --> 00:26:53,070
relax. He had to start avoiding things.

471
00:26:53,190 --> 00:26:56,490
Yeah, there were, there were specific
like movies that I couldn't watch.

472
00:26:56,730 --> 00:26:57,160
It was fine.

473
00:26:57,160 --> 00:27:01,890
I can pay for the Clinton Terrell's no
one [inaudible] and I see it. I was like,

474
00:27:01,891 --> 00:27:05,640
okay, turn it on. I was like, like,
heads were exploding. I was like, nope,

475
00:27:06,120 --> 00:27:09,540
nope. I have to walk away.
And I just, I had to,

476
00:27:09,570 --> 00:27:13,950
I chose it was too real. I saw that.

477
00:27:15,700 --> 00:27:16,880
It's classic. Good. Yesterday

478
00:27:18,930 --> 00:27:22,920
a different moderator I spoke to
described it as seeing the worst side of

479
00:27:22,921 --> 00:27:23,754
humanity.

480
00:27:24,060 --> 00:27:29,060
You see all of the stuff that you and I
don't have to see because they are going

481
00:27:30,391 --> 00:27:34,400
around playing cleanup. Yeah.
What a job. Oh Wow. Yeah. And it,

482
00:27:34,410 --> 00:27:38,280
and it's worth noting that I'm more and
more of this work is being done in an

483
00:27:38,281 --> 00:27:39,330
automated fashion,

484
00:27:39,570 --> 00:27:44,370
particularly with content like a
gore or terrorist propaganda. Uh,

485
00:27:44,450 --> 00:27:47,220
they're getting better automate
that. They, yeah, they, uh,

486
00:27:47,250 --> 00:27:51,960
through computer vision they're
able to detect hallmarks of, of,

487
00:27:52,280 --> 00:27:56,520
of a terrorist video or of a gory image.
And, uh, with terrorist propaganda,

488
00:27:56,521 --> 00:28:01,521
they now take down 99% of it
before anyone flags it on Facebook.

489
00:28:03,250 --> 00:28:07,680
Oh. But, uh, moving onto
our second story here,

490
00:28:07,910 --> 00:28:09,990
there is a type of content that they, uh,

491
00:28:09,991 --> 00:28:14,910
that they are having an incredibly
hard time. Uh, not just automating,

492
00:28:14,911 --> 00:28:19,911
but even getting their rules straight
on and that surrounding hate speech.

493
00:28:20,910 --> 00:28:25,140
Oh, good. Some more laughs coming up.
Well, there will be laughter. Oh really?

494
00:28:25,350 --> 00:28:29,070
There will be comedians. There will
be jokes. Hey. All right. Okay.

495
00:28:29,700 --> 00:28:31,260
Should we take a break and
then come right back? No,

496
00:28:31,261 --> 00:28:32,640
I think we're going to keep going. Okay.

497
00:28:33,190 --> 00:28:35,500
Testing one, two, three, four, five.
Testing. One, two, three, four, five.

498
00:28:35,501 --> 00:28:36,340
I'm Simon Adler,

499
00:28:36,710 --> 00:28:41,210
so a couple months back. I think it's
working great. We sent our pair of intern,

500
00:28:41,470 --> 00:28:45,560
it's on the left 60 feet, Carter Hodge.

501
00:28:45,670 --> 00:28:49,010
Here we go at this standing
room and lazy Gieger

502
00:28:51,100 --> 00:28:55,670
tickets for tonight. Anywhere on the
guest list. Okay. To this cramped,

503
00:28:56,230 --> 00:28:58,850
sorry. Narrow little comedy club.

504
00:28:59,240 --> 00:29:02,860
The kind of place with
like a super, yeah, I know.

505
00:29:03,260 --> 00:29:05,990
$15 smashed rosemary cocktails.

506
00:29:08,210 --> 00:29:12,380
None of it. We do not need to get up.
And that is the fine high top tables.

507
00:29:12,740 --> 00:29:17,330
The acs dripping on me, but still
kind of a die is good. Yeah.

508
00:29:20,290 --> 00:29:25,120
Sent them there to check out someone else
who'd found a fault line in Facebook's

509
00:29:25,121 --> 00:29:25,954
rule book,

510
00:29:26,220 --> 00:29:29,000
deciding where to keep it moving right
along the next two you come to stage,

511
00:29:29,030 --> 00:29:31,150
please give it up for Marcia Belsky.

512
00:29:34,740 --> 00:29:38,870
Yes, I get so mad. I feel like
my personal into the city.

513
00:29:38,871 --> 00:29:41,920
I was such a carefree Brat, you know,

514
00:29:41,921 --> 00:29:46,390
I was young and I had these older friends,
which I thought was like very cool.

515
00:29:46,630 --> 00:29:49,300
And then you just realize
that they're alcoholics

516
00:29:49,800 --> 00:29:50,633
know

517
00:29:53,510 --> 00:29:55,890
he's got dark curly hair
was raised in Oklahoma,

518
00:29:56,080 --> 00:29:59,590
you know, and I think I was raised
Jewish. So when you're raised Jewish,

519
00:29:59,591 --> 00:30:02,740
you read about Anne Frank a
lot, you know a lot, a lot.

520
00:30:02,970 --> 00:30:06,860
And when you read about Anne Frank
like this, we'll get funny [inaudible]

521
00:30:10,160 --> 00:30:12,560
how did you decide to
become a comedian? You know,

522
00:30:12,561 --> 00:30:14,720
it was kind of the only thing
that ever clicked with me.

523
00:30:14,900 --> 00:30:17,660
And especially political comedy, you know,

524
00:30:17,661 --> 00:30:22,661
I used to watch the daily show every
day and back in 2016 she started this

525
00:30:22,910 --> 00:30:27,910
political running bit that I think can
be called sort of a absurdist feminist

526
00:30:28,370 --> 00:30:28,970
comedy.

527
00:30:28,970 --> 00:30:33,350
No, a lot of people think that I'm like
an angry feminist. Um, which is weird.

528
00:30:33,351 --> 00:30:37,190
This guy called me a militant feminist
the other day and I'm like, okay,

529
00:30:37,191 --> 00:30:42,110
just because I am training a
militia women in the woods.

530
00:30:46,130 --> 00:30:50,540
At first I just had this running
bit online on Facebook and Twitter.

531
00:30:50,600 --> 00:30:52,490
She was tweeting and
posting jokes, you know,

532
00:30:52,491 --> 00:30:56,450
like we have all the buffalo wild wings
surrounded, you know, things like that.

533
00:30:56,600 --> 00:30:59,530
Eventually took this bid on
stage, even wrote [inaudible]

534
00:31:00,490 --> 00:31:02,020
Hey, I'm older,

535
00:31:02,260 --> 00:31:05,460
I tend to dive on my dad.

536
00:31:07,520 --> 00:31:09,310
No, no, no. My Dad.

537
00:31:13,060 --> 00:31:16,180
Anyhow, so about a year
into this running bit, uh,

538
00:31:16,660 --> 00:31:20,590
Marsha was bored at work one day
and uh, logs onto Facebook. But, uh,

539
00:31:20,591 --> 00:31:23,320
instead of seeing her
at normal newsfeed, uh,

540
00:31:23,321 --> 00:31:25,180
there was this message that pops up.

541
00:31:25,240 --> 00:31:29,650
It says you posted something that
discriminated along the lines of race,

542
00:31:29,890 --> 00:31:34,490
gender, or ethnicity group.
And so we removed that post.

543
00:31:34,780 --> 00:31:39,040
And so I'm like, what could I
possibly have post it? I really,

544
00:31:39,041 --> 00:31:40,450
I thought it was like a glitch,

545
00:31:40,480 --> 00:31:45,340
but then she clicked continue and they're
highlighted was the violating post.

546
00:31:45,830 --> 00:31:49,150
It was a photo of hers. What, what
is the picture? Can you describe it?

547
00:31:49,151 --> 00:31:53,050
The photo is me as look can
only be described as the Cherub,

548
00:31:53,110 --> 00:31:56,800
cute little seven year old with big
curly hair and she's wearing this blue

549
00:31:56,801 --> 00:31:57,880
floral dress.

550
00:31:57,940 --> 00:32:02,410
Her teeth are all messed up and into
the photo Marcia had edited in a speech

551
00:32:02,411 --> 00:32:07,060
bubble that just says kill all men. And
so it's funny, you know, cause I hit,

552
00:32:07,150 --> 00:32:11,500
I hit, it's funny, you know,
I trust me, whatever. So, um,

553
00:32:11,620 --> 00:32:15,100
I thought it was ridiculous because she
searched through her library of photos

554
00:32:15,101 --> 00:32:20,101
and found that kill all men image and
I post it again immediately after like,

555
00:32:20,801 --> 00:32:25,210
yeah. And it got removed again and
this time there were consequences.

556
00:32:25,240 --> 00:32:27,670
I got banned for three days after that.

557
00:32:27,730 --> 00:32:31,900
Then after several other bands
shoot forward, this is months later,

558
00:32:31,960 --> 00:32:35,560
a friend of hers had posted an article
and underneath it in the comment section,

559
00:32:35,561 --> 00:32:38,320
there were guys posting
just really nasty stuff.

560
00:32:38,350 --> 00:32:43,100
So I commented underneath
those comments, men are scum,

561
00:32:43,580 --> 00:32:47,250
which was very quickly removed. How,

562
00:32:47,270 --> 00:32:51,330
how long did you get banned for
this time? 30 days. Wow. Yeah,

563
00:32:51,630 --> 00:32:53,970
I was dumbfounded.

564
00:32:54,330 --> 00:32:58,950
So there's a rule somewhere
that if I type men are scum,

565
00:32:59,490 --> 00:33:02,340
you take it down. Yes.
And like what could it be?

566
00:33:02,790 --> 00:33:07,770
Okay. And so Marsha called on
her quote militia of women.

567
00:33:07,830 --> 00:33:10,290
Exactly. To find out like is this just me?

568
00:33:10,530 --> 00:33:13,380
Female Comedians who are sort
of like mad on my behalf,

569
00:33:14,040 --> 00:33:15,750
started experimenting,

570
00:33:15,810 --> 00:33:20,460
posting men are scum to see how quickly
you would get removed and if it would be

571
00:33:20,461 --> 00:33:21,720
removed every time.

572
00:33:22,080 --> 00:33:26,220
And it was so they started
trying other words. Yeah,

573
00:33:26,630 --> 00:33:28,290
to find out where the line was.

574
00:33:28,380 --> 00:33:31,950
My friend put men are
dusk up that got removed.

575
00:33:32,220 --> 00:33:37,110
Men are the worst removed to band.
This one girl put men are septic fluid

576
00:33:38,700 --> 00:33:39,280
band,

577
00:33:39,280 --> 00:33:41,320
but we're only at the middle of the saga.

578
00:33:41,650 --> 00:33:44,380
It doesn't end there because
there's no, she's really like,

579
00:33:44,381 --> 00:33:46,750
what the hell is going on is this sexism.

580
00:33:46,780 --> 00:33:51,780
So I just start doing the most bare
minimum amount of investigating.

581
00:33:52,870 --> 00:33:54,110
She's googling around

582
00:33:54,160 --> 00:33:57,380
trying to figure out what these
policies are in. Pretty quick,

583
00:33:57,381 --> 00:34:00,140
she comes across this
leaked Facebook document.

584
00:34:00,500 --> 00:34:02,480
This is when I lose my mind.

585
00:34:03,470 --> 00:34:08,150
This is when Mark Zuckerberg becomes my
sworn nemesis for the rest of my life.

586
00:34:08,210 --> 00:34:12,620
Because what she'd found was a document
Facebook used to train their moderators

587
00:34:12,920 --> 00:34:17,480
and inside of it in a section detailing
who Facebook protected from hate speech,

588
00:34:17,840 --> 00:34:22,010
there was a multiple choice question
that said, uh, who do we protect?

589
00:34:22,430 --> 00:34:24,590
White men or black children?

590
00:34:25,280 --> 00:34:29,150
And the correct answer was
white men, not black children.

591
00:34:29,630 --> 00:34:34,220
Not even kidding. Why we're
protecting black children are not.

592
00:34:34,880 --> 00:34:38,760
That's not a good look racist.
Something's going on here.

593
00:34:38,910 --> 00:34:43,910
There is absolutely some sort of
unaddressed bias or systematic issue at

594
00:34:45,601 --> 00:34:46,434
Facebook.

595
00:34:47,060 --> 00:34:51,090
Great. Hello, I'm doing well.
Thank you so much for being here.

596
00:34:52,080 --> 00:34:54,350
Yeah, so not long after
sitting down with Marsha,

597
00:34:54,500 --> 00:34:59,150
Facebook invited me to come out to their
offices in California and sit down with

598
00:34:59,151 --> 00:35:03,020
them. I'm going to eat one cookie
and then, oh, they're little.

599
00:35:03,310 --> 00:35:06,910
I think I get to typing.
Can I just get your,

600
00:35:06,911 --> 00:35:11,420
your name and your title and I'm Monica
Bickert and I lead the policies for

601
00:35:11,421 --> 00:35:15,350
Facebook. Monica Bickert is in
charge of all of Facebook's rules,

602
00:35:15,500 --> 00:35:19,370
including their policies on hate
speech. And so I asked her like,

603
00:35:19,371 --> 00:35:24,110
why would there be a rule that protects
white men but not black children?

604
00:35:25,010 --> 00:35:29,150
We have, we have made
our hate speech policies.

605
00:35:30,110 --> 00:35:31,460
Let me, let me rephrase that.

606
00:35:31,730 --> 00:35:35,750
Our hate speech policies have
become more detailed over time,

607
00:35:35,960 --> 00:35:40,960
but our main is you can't attack a
person or a group of people based on a

608
00:35:40,981 --> 00:35:44,550
protected characteristic, a characteristic
like race, religion, or gender.

609
00:35:44,760 --> 00:35:47,550
So this takes a couple of beats to
explain, but the gist of it is that, uh,

610
00:35:47,820 --> 00:35:52,230
the Facebook borrowed this idea of
protected classes, uh, straight from us,

611
00:35:52,231 --> 00:35:53,700
anti-discrimination law.

612
00:35:53,850 --> 00:35:58,410
These are the laws that make it so that
you can't not hire someone say based on

613
00:35:58,411 --> 00:36:03,180
like their religion, their
ethnicity, their race, and so on,

614
00:36:03,270 --> 00:36:07,830
on Facebook. You can't attack someone
based on one of these characteristics.

615
00:36:08,140 --> 00:36:12,640
Meaning you can't say men are trash,
nor could you say women are trash. Uh,

616
00:36:12,670 --> 00:36:17,480
because essentially you're attacking
all men for being men. Oh, is,

617
00:36:17,590 --> 00:36:21,910
is it the all, can I say Bob is
trash? Yeah, you can say Bob is trash.

618
00:36:21,940 --> 00:36:23,860
Because as my story is explained to me,

619
00:36:23,920 --> 00:36:28,030
the distinction is that in the first
instance, you're attacking a category.

620
00:36:28,300 --> 00:36:30,430
In the second instance,
you're attacking a person,

621
00:36:30,431 --> 00:36:34,330
but it's not clear that you're attacking
that person because they are a member

622
00:36:34,331 --> 00:36:36,130
of a protected category. Oh.

623
00:36:36,131 --> 00:36:39,350
So Bob might be trashed for reasons
that have nothing to do with him being a

624
00:36:39,351 --> 00:36:44,260
man. He just might be annoying. Right.
Okay. So that explains why you take down,

625
00:36:44,261 --> 00:36:48,070
men are scum, but why would you
leave up? Black children are scum.

626
00:36:48,180 --> 00:36:50,380
Why would that not get taken down?

627
00:36:50,590 --> 00:36:55,590
So traditionally we allowed speech once
there was some other word in it that

628
00:36:56,291 --> 00:36:59,830
made it about something other than it
protected characteristic in Facebook

629
00:36:59,831 --> 00:37:02,680
jargon. These are referred to as a, uh,

630
00:37:02,740 --> 00:37:07,150
a non-protected modifier
just means literally nothing.

631
00:37:08,560 --> 00:37:12,010
Give us an example of this.
So traditionally if you said,

632
00:37:12,040 --> 00:37:15,430
I don't like this religion, cab drivers,

633
00:37:15,640 --> 00:37:20,640
cab driver would be the non-protected
modifier because employment is not a

634
00:37:21,491 --> 00:37:25,990
protected category. Huh? And so
what the rule stated was, uh,

635
00:37:26,200 --> 00:37:31,200
when you add this non-protected
modifier to a protected category,

636
00:37:32,170 --> 00:37:34,420
in this case the cab drivers religion,

637
00:37:34,450 --> 00:37:38,860
we would allow it because we can't assume
that you're hating this person because

638
00:37:38,861 --> 00:37:42,070
of his religion. And you actually
just may not like the cab drivers.

639
00:37:42,190 --> 00:37:44,200
So in the case of black children,

640
00:37:44,230 --> 00:37:48,010
children is modifying the
protected category of black.

641
00:37:48,880 --> 00:37:53,440
And so children Trump's black
age is a non protected category.

642
00:37:54,100 --> 00:37:54,431
Okay.

643
00:37:54,431 --> 00:37:59,431
So a children becomes a
non-protected modifier and their,

644
00:38:01,871 --> 00:38:05,170
their, their childness
trumps their blackness.

645
00:38:05,610 --> 00:38:08,190
You can say whatever you
want about black children.

646
00:38:08,520 --> 00:38:11,880
Whereas in the case of
white men, uh, you've got a,

647
00:38:11,881 --> 00:38:16,740
you've got gender and race both
protected, you can't attack them.

648
00:38:17,220 --> 00:38:18,690
That's just a bizarre rule.

649
00:38:19,020 --> 00:38:23,310
I would think you would go the other
direction that the protected class would

650
00:38:23,311 --> 00:38:24,850
outweigh the modifier. Well, they,

651
00:38:24,860 --> 00:38:29,790
they made this decision as they explained
to me because their default was to

652
00:38:29,791 --> 00:38:31,230
allow speech.

653
00:38:31,290 --> 00:38:36,040
They were really trying to incorporate
or nod to the American speech tradition.

654
00:38:36,250 --> 00:38:38,980
And so there's a whole lot of stuff out
there that none of us would defend as a

655
00:38:39,340 --> 00:38:42,970
valuable speech. But didn't, didn't rise
to the level of stuff that we'd say,

656
00:38:42,971 --> 00:38:46,570
this is so bad, we're going to
take it down. And uh, in this case,

657
00:38:46,571 --> 00:38:49,120
their concern was we're all
members of like, you know,

658
00:38:49,121 --> 00:38:52,360
at least half a dozen protected
categories. Like we all have gender,

659
00:38:52,361 --> 00:38:55,330
we all have sexual
orientation. And if you may,

660
00:38:55,331 --> 00:39:00,331
if the rule is that anytime a
protected class is mentioned,

661
00:39:01,000 --> 00:39:02,950
it could be hate speech.

662
00:39:03,310 --> 00:39:07,870
What you are doing at that point is
opening up just about every comment that's

663
00:39:07,871 --> 00:39:11,920
ever made about anyone on Facebook
to potentially be hate speech.

664
00:39:12,040 --> 00:39:15,730
Then you're not left with anything,
right? No matter where we draw this line,

665
00:39:15,980 --> 00:39:18,310
they're going to be sad. Some
outcomes that we don't like,

666
00:39:18,570 --> 00:39:20,320
there are always going to be casualties.

667
00:39:20,530 --> 00:39:23,200
That's why we continue to change
the policies. And in fact,

668
00:39:23,350 --> 00:39:26,800
since Marsha's debacle, they've
actually updated this rule.

669
00:39:27,070 --> 00:39:32,070
So now black children are protected from
what they considered the worst forms of

670
00:39:32,201 --> 00:39:32,830
hate speech.

671
00:39:32,830 --> 00:39:37,830
Now our reviewers take how severe
the attack is into consideration.

672
00:39:38,830 --> 00:39:39,820
But despite this,

673
00:39:39,821 --> 00:39:43,450
there are still plenty of people that
is flawed because you are a social

674
00:39:43,451 --> 00:39:47,710
network, including Marcia who, who
think this still just isn't good enough.

675
00:39:47,770 --> 00:39:52,770
There are not systematic efforts to
eliminate white men in the way that there

676
00:39:53,591 --> 00:39:56,530
are other groups. That's why
you have protected groups.

677
00:39:56,680 --> 00:40:00,430
She thinks white men and
heterosexual should not be protected,

678
00:40:00,460 --> 00:40:04,300
protect the groups who are
actually victims of hate speech.

679
00:40:04,460 --> 00:40:07,680
Makes Sense. Well, yeah, because
in sort of hate speech, uh,

680
00:40:07,720 --> 00:40:10,930
or thinking about hate speech
and there's this idea of,

681
00:40:11,200 --> 00:40:15,100
of privileged or of historically
disadvantaged groups and that those

682
00:40:15,101 --> 00:40:19,420
historically disadvantaged groups
should have more protection, uh,

683
00:40:19,450 --> 00:40:22,870
because of being
historically disadvantaged.

684
00:40:23,770 --> 00:40:27,280
And the challenge with that, uh,
that was presented to me was okay,

685
00:40:27,310 --> 00:40:30,360
why the thousands new Japanese
reinforcements [inaudible]

686
00:40:30,450 --> 00:40:31,620
in the 1940s

687
00:40:31,930 --> 00:40:34,260
do cut off the Chinese
and pay and [inaudible]

688
00:40:34,340 --> 00:40:36,470
you had Japanese soldiers,

689
00:40:37,420 --> 00:40:41,480
tens of thousands of Chinese killing
millions of Chinese during World War II.

690
00:40:43,590 --> 00:40:47,190
At that same time you had
Japanese American citizens,

691
00:40:47,470 --> 00:40:52,090
a thousand persons of Japanese
ancestry, all of them would have to move

692
00:40:52,200 --> 00:40:54,330
being put into internment camps.

693
00:40:54,600 --> 00:40:56,580
And so we had to ask
ourselves the question like,

694
00:40:56,910 --> 00:41:01,560
are the Japanese and historically
advantaged or disadvantaged group? Huh?

695
00:41:01,650 --> 00:41:05,280
Japanese Americans pretty easy to make
a case that they were disadvantaged.

696
00:41:05,520 --> 00:41:08,280
But in China it's a
totally different story.

697
00:41:08,620 --> 00:41:12,200
And this happened at the
exact same moment. So you've
got two different places,

698
00:41:12,380 --> 00:41:17,180
two different cultural stories and when
you have a website like Facebook that's

699
00:41:17,630 --> 00:41:18,770
trans national community,

700
00:41:19,190 --> 00:41:24,170
they realized where they decided that
ideas of privilege are so geographically

701
00:41:24,171 --> 00:41:29,171
bound that there is no way to effectively
weigh and consider who is privileged,

702
00:41:33,200 --> 00:41:34,010
who and

703
00:41:34,010 --> 00:41:38,960
decided therefore that we are not
going to allow historical advantage or

704
00:41:38,961 --> 00:41:42,230
historical privilege, uh,
into the equation at all.

705
00:41:45,200 --> 00:41:45,320
[inaudible]

706
00:41:45,320 --> 00:41:49,410
and I think it's very important
to keep in mind here Americans,

707
00:41:49,730 --> 00:41:52,250
these moderators only have
like four or five seconds

708
00:41:54,020 --> 00:41:57,550
come to make a decision [inaudible]

709
00:41:59,090 --> 00:42:01,820
in those four seconds,
is there enough time to,

710
00:42:01,821 --> 00:42:03,950
to figure out where in
the world someone is,

711
00:42:04,130 --> 00:42:07,430
particularly given IP
addresses can easily be masked.

712
00:42:07,760 --> 00:42:09,410
Go back where you came from.

713
00:42:09,590 --> 00:42:12,140
Is it enough time to figure
out a person's ethnicity?

714
00:42:12,200 --> 00:42:16,370
White children are better than
black children. On top of that,

715
00:42:16,371 --> 00:42:21,371
we often don't know an individual's race
straight people stuck other categories

716
00:42:21,770 --> 00:42:24,050
or even less clear like sexual orientation

717
00:42:24,350 --> 00:42:24,800
and they,

718
00:42:24,800 --> 00:42:28,280
they just realized it would be next to
impossible to get anybody to be able to

719
00:42:28,281 --> 00:42:30,530
run these, run these
calculations effectively.

720
00:42:30,840 --> 00:42:33,510
When we were building that framework,

721
00:42:33,511 --> 00:42:37,860
we did a lot of tasks and we saw some
times that it was just too hard for our

722
00:42:37,861 --> 00:42:42,861
reviewers to implement a more
detailed policy consistently.

723
00:42:43,290 --> 00:42:44,820
They just couldn't do it accurately.

724
00:42:45,030 --> 00:42:49,980
So we want the policies to be sufficiently
detailed to take into account all

725
00:42:49,981 --> 00:42:51,660
different types of scenarios,

726
00:42:51,960 --> 00:42:56,960
but simple enough that we can apply them
consistently and accurately around the

727
00:42:57,961 --> 00:43:02,760
world. And the reality is anytime that
the policies become more complicated,

728
00:43:02,880 --> 00:43:04,590
we see dips in our consistency.

729
00:43:05,000 --> 00:43:08,540
What Facebook's trying to do
is take the first amendment,

730
00:43:08,570 --> 00:43:10,070
this high minded,

731
00:43:10,071 --> 00:43:14,690
lofty legal concept and convert it into a,

732
00:43:14,700 --> 00:43:19,700
an engineering manual that can be executed
every four seconds for any piece of

733
00:43:20,451 --> 00:43:25,160
content from anywhere on the globe.
And when you've got to move that fast,

734
00:43:25,820 --> 00:43:27,980
sometimes justice loses.

735
00:43:28,230 --> 00:43:30,570
That's the, um, that's the tension here.

736
00:43:34,230 --> 00:43:34,590
[inaudible]

737
00:43:34,590 --> 00:43:39,590
and I just want to make sure I
emphasize that these policies,

738
00:43:39,960 --> 00:43:41,940
they're not going to please
everybody. They often don't.

739
00:43:41,941 --> 00:43:45,240
Don't please everybody that's working
on the policy team at Facebook,

740
00:43:45,300 --> 00:43:49,200
but if we want to have one line
that we enforce consistently,

741
00:43:49,590 --> 00:43:54,590
then it means we have to have some
pretty objective black and white rules.

742
00:44:06,770 --> 00:44:07,910
[inaudible] Coca-Cola,

743
00:44:19,450 --> 00:44:19,680
[inaudible]

744
00:44:19,680 --> 00:44:24,610
Oh, when we come back, those
rules, they get toppled.

745
00:44:31,950 --> 00:44:32,783
[inaudible]

746
00:44:33,620 --> 00:44:35,660
this is Danny from Denver, Colorado.

747
00:44:36,020 --> 00:44:40,370
Radiolab is supported in part by the
Alfred p Sloan Foundation enhancing public

748
00:44:40,371 --> 00:44:42,920
understanding of science and
technology in the modern world.

749
00:44:43,160 --> 00:44:47,060
More information
aboutSloan@wwwdotsloan.org

750
00:44:49,790 --> 00:44:52,810
hi, I'm Tracy and I'm a
reporter here at radio lab.

751
00:44:53,120 --> 00:44:56,240
I wanted to take a quick second to tell
you about something that I think is

752
00:44:56,241 --> 00:45:00,410
pretty cool that we make here
at the show. Besides the show,

753
00:45:00,770 --> 00:45:04,460
we have a newsletter and I can
already hear you say big deal.

754
00:45:04,490 --> 00:45:07,250
Everybody has a newsletter,
but ours is really,

755
00:45:07,251 --> 00:45:11,600
really good and worth your time and
probably more worth your time than other

756
00:45:11,601 --> 00:45:15,530
people's newsletters. So
here it is. First of all,

757
00:45:15,531 --> 00:45:17,810
it lets you know when to
release a new episode.

758
00:45:18,410 --> 00:45:23,240
And secondly there's this whole other
section of our staff picks and that's just

759
00:45:23,241 --> 00:45:26,600
a list of things that the Radiolab team
have come across that were just really

760
00:45:26,601 --> 00:45:30,500
excited about. And it could be something
like, you know Rachel keepsake,

761
00:45:30,501 --> 00:45:31,580
our producer, you know,

762
00:45:31,581 --> 00:45:36,581
she just worked on goon ads and she found
out about this really cool frozen zoo.

763
00:45:36,950 --> 00:45:41,160
And then there's our other producer
Andy McCune and she kind of tells,

764
00:45:41,180 --> 00:45:44,930
told everybody to Google horse mustaches
and it is definitely worth your time to

765
00:45:44,931 --> 00:45:47,330
Google that. So go do that right now.

766
00:45:47,810 --> 00:45:50,060
Or it'll be me talking about you know,

767
00:45:50,061 --> 00:45:54,080
the joys or rewatching like my
favorite TV show living single.

768
00:45:54,470 --> 00:45:58,820
So I hope you'll sign up. It takes
about 30 seconds and it's free.

769
00:45:59,060 --> 00:46:04,060
So go to radiolab.org back slash
newsletter or you can text RL news as in a

770
00:46:06,170 --> 00:46:11,150
Radiolab news two seven zero one zero
one that's r l news two seven zero one

771
00:46:11,151 --> 00:46:12,920
zero one and thanks.

772
00:46:14,650 --> 00:46:19,520
They are doors that once
open can never be closed.

773
00:46:21,510 --> 00:46:25,050
W NYC studios and snap judge
with underground layer.

774
00:46:25,320 --> 00:46:27,570
Scoop two is here,

775
00:46:27,990 --> 00:46:31,380
starting this August every
week until Halloween.

776
00:46:32,250 --> 00:46:37,110
Be Afraid, but don't turn out the lights.

777
00:46:39,500 --> 00:46:42,200
Listen to speed wherever
you get your podcasts.

778
00:46:48,010 --> 00:46:51,520
Chad, Robert Radiolab, back to
Simon Adler, Facebook free speech.

779
00:46:51,760 --> 00:46:53,470
So as we just heard before the break,

780
00:46:53,740 --> 00:46:57,010
Facebook is trying to do two
competing things at once.

781
00:46:57,670 --> 00:46:59,440
They're trying to make
rules that are just,

782
00:46:59,500 --> 00:47:03,670
but at the same time can be reliably
executed by thousands of people spread

783
00:47:03,671 --> 00:47:06,910
across the globe in ways
that are fair and consistent.

784
00:47:07,270 --> 00:47:10,570
And I would argue that this
balancing act was put to the test.

785
00:47:11,020 --> 00:47:12,970
April 15th, 2013.

786
00:47:13,530 --> 00:47:18,220
Hey Carlos. Rhonda, Carlos [inaudible]
get up. Thank you. We have some break.

787
00:47:18,230 --> 00:47:21,990
We have some breaking news. Otherwise I
wouldn't cut you off so abruptly. Carla.

788
00:47:22,040 --> 00:47:25,420
Monday the 15th 2013 just
before three in the afternoon.

789
00:47:29,080 --> 00:47:29,913
[inaudible]

790
00:47:33,460 --> 00:47:34,930
to pressure cooker bombs

791
00:47:38,760 --> 00:47:42,760
with through the crowd near the
finish line. The Boston marathon

792
00:47:45,940 --> 00:47:46,773
and

793
00:47:46,930 --> 00:47:49,150
yeah, as sort of the
dust begins to settle.

794
00:47:52,170 --> 00:47:53,003
Oh my God.

795
00:47:54,450 --> 00:47:56,770
People are springing into action. Uh,

796
00:47:57,390 --> 00:48:01,350
does one man in a cowboy hat sees this
spectator who, who's been injured,

797
00:48:01,680 --> 00:48:05,950
picks him up, throws him in a wheelchair
and as they're pushing him through the,

798
00:48:06,120 --> 00:48:08,220
this sort of ashy cloud, the,

799
00:48:08,221 --> 00:48:10,650
there's this photographer
there and he snaps this phone

800
00:48:14,520 --> 00:48:18,690
and the photo show is the runner in the
cowboy hat and these two other people

801
00:48:18,720 --> 00:48:20,880
pushing this man who, uh,

802
00:48:21,120 --> 00:48:24,060
his face is Ashen from all of the debris.

803
00:48:24,330 --> 00:48:28,440
His hair is sort of standing on end and
you can tell that actually the force of

804
00:48:28,441 --> 00:48:30,600
the blast and then the,
the particles that got in,

805
00:48:30,720 --> 00:48:35,400
they're actually holding it in this sort
of wedge shape and one of his legs is

806
00:48:35,401 --> 00:48:40,401
completely blown off and the second
one is blown off below the knee,

807
00:48:40,471 --> 00:48:44,770
other than the femur bone sticking out
and then sort of skin and muscle and

808
00:48:45,300 --> 00:48:48,840
tendons, it's, it's horrific. Meanwhile,

809
00:48:48,860 --> 00:48:53,390
Hulu, CBS B area studio on the other
side of the country, x five new,

810
00:48:53,660 --> 00:48:57,290
I remember snippets of the
day. Facebook employees,

811
00:48:57,450 --> 00:49:00,960
we're clustering around several desks
staring at the computer screens,

812
00:49:00,990 --> 00:49:02,280
watching the news break.

813
00:49:02,450 --> 00:49:05,810
This has occurred just in
the last half hour or so.

814
00:49:05,840 --> 00:49:09,530
I have memories of of watching
some of the coverage Schilling,

815
00:49:09,531 --> 00:49:12,560
new images just released
of the Boston bombings.

816
00:49:12,680 --> 00:49:15,890
I remember seeing the photo published
online and it wasn't long after that

817
00:49:17,150 --> 00:49:20,390
someone had posted on Facebook
from the folks I spoke to.

818
00:49:20,391 --> 00:49:22,910
The order of events here
are a little fuzzy, but

819
00:49:24,560 --> 00:49:27,200
pretty quickly this photos going viral

820
00:49:29,400 --> 00:49:31,980
and we realized we're going
to have to deal with it.

821
00:49:32,220 --> 00:49:35,880
This image is spreading like
wildfire across their platform.

822
00:49:36,240 --> 00:49:38,970
It appears to be way outside
the rules they'd written,

823
00:49:38,971 --> 00:49:42,060
but it's in this totally new context.

824
00:49:42,540 --> 00:49:45,960
So they got their team together, sat
down in a conference room. I don't know,

825
00:49:45,961 --> 00:49:50,280
there was probably eight or 10 people
thinking about like should we allow it or

826
00:49:50,281 --> 00:49:53,580
should they take it down
according to their rules? Yeah.

827
00:49:53,581 --> 00:49:57,720
So if you recall the no insides on the
outside stuff inition that we had in

828
00:49:57,721 --> 00:50:02,400
place, meaning you can't see like
people's organs or that sort of thing.

829
00:50:02,790 --> 00:50:05,400
And if you can then we
wouldn't allow it. And in this,

830
00:50:06,000 --> 00:50:07,410
in this photo you could see,

831
00:50:07,800 --> 00:50:11,550
you could definitely see bone and so
by the rules the photo should obviously

832
00:50:11,551 --> 00:50:15,900
come down. Yup. However,
half the room says no.

833
00:50:16,020 --> 00:50:18,870
The other people are
saying this is newsworthy.

834
00:50:20,880 --> 00:50:24,570
Essentially this photos being posted
everywhere else. It's important.

835
00:50:24,870 --> 00:50:28,640
We need to suspend the rules.
We need make an exception

836
00:50:28,670 --> 00:50:30,980
which immediately received pushback. Well,

837
00:50:30,981 --> 00:50:35,750
I was saying that what we've
prided ourselves on was
not making those calls and

838
00:50:35,751 --> 00:50:40,070
there are no exceptions. There is
either either mistakes or improvements.

839
00:50:40,250 --> 00:50:44,450
We made the guidelines for moments like
this to which the other side shoots

840
00:50:44,451 --> 00:50:46,010
back. Oh my God, are you kidding me?

841
00:50:46,011 --> 00:50:48,800
Like the Boston Globe is publishing this
all over the place and we're taking it

842
00:50:48,801 --> 00:50:51,710
down like, are you fucking
kidding me? Damn the guidelines.

843
00:50:51,711 --> 00:50:53,630
Let's just have common
sense here. Let's be humans.

844
00:50:53,631 --> 00:50:58,400
We know that this is important and
yeah, they're kind of there. Right?

845
00:50:58,730 --> 00:51:03,620
But the reality is like if you say, well,
we allowed it because it's newsworthy.

846
00:51:04,610 --> 00:51:05,443
How?

847
00:51:06,080 --> 00:51:09,620
How do you answer any of the questions
about any of the rest of the stuff?

848
00:51:11,740 --> 00:51:15,160
In other words, this is a
Pandora's box. And in fact,

849
00:51:15,280 --> 00:51:18,130
for reasons that are totally
clear, team consistency,

850
00:51:18,160 --> 00:51:22,450
team follow the rules eventually wins
the day they decide to take the photo

851
00:51:22,451 --> 00:51:24,940
down. But before they can pull the lever,

852
00:51:25,180 --> 00:51:28,930
word starts making its way up the
chain. And internally within Facebook,

853
00:51:29,140 --> 00:51:32,620
according to my sources and executive
under Zuckerberg sent down in order,

854
00:51:33,010 --> 00:51:36,250
we were essentially
told, make the exception

855
00:51:39,280 --> 00:51:39,660
[inaudible]

856
00:51:39,660 --> 00:51:43,260
I don't care what your guidelines
say, I don't care what your reason is,

857
00:51:43,410 --> 00:51:46,050
the photo standards, you're
not taking this down.

858
00:51:47,840 --> 00:51:50,210
Yes. Um, yes. That's what happened.

859
00:51:52,120 --> 00:51:56,800
This decision means that Facebook
has just become a publisher.

860
00:51:56,940 --> 00:51:59,200
W they don't think maybe they have,

861
00:51:59,650 --> 00:52:04,480
but they've made a news judgment and
just willy nilly they've become CBS,

862
00:52:04,481 --> 00:52:07,090
ABC, New York Times, Herald
Tribune, Atlantic monthly,

863
00:52:07,091 --> 00:52:10,450
and all these other things all at once.
They just become a news organization.

864
00:52:10,480 --> 00:52:15,460
Yeah. And this brings up a legal question
that that's at the center of this

865
00:52:15,461 --> 00:52:17,170
conversation about free speech.

866
00:52:17,380 --> 00:52:22,240
Like is Facebook a sort of collective
scrapbook for assault or is it a public

867
00:52:22,241 --> 00:52:26,680
square where you should be able
to say whatever you want or, yeah.

868
00:52:26,681 --> 00:52:29,530
Is it now a news organization
adds transparency?

869
00:52:29,550 --> 00:52:31,350
I, let me get, let me get
a, I'm sorry to interrupt,

870
00:52:31,351 --> 00:52:34,110
but let me get to one final question that
kind of relates to what you're talking

871
00:52:34,111 --> 00:52:37,350
about in terms of what
exactly Facebook is.

872
00:52:37,500 --> 00:52:40,920
And this question has been popping
up a lot recently. In fact,

873
00:52:40,921 --> 00:52:45,030
it even came up this past April when
Zuckerberg was testifying in front of

874
00:52:45,031 --> 00:52:45,864
Congress.

875
00:52:46,090 --> 00:52:50,220
I think about 140 million Americans
get their news from Facebook.

876
00:52:50,820 --> 00:52:53,760
So which are you, are you a tech company?

877
00:52:53,770 --> 00:52:58,500
Are you the world's largest
publisher? Senator? This is,

878
00:52:59,030 --> 00:53:03,690
uh, I view us as a tech company because
the primary thing that we do is build

879
00:53:03,691 --> 00:53:06,180
technology and products that you're
responsible for your content,

880
00:53:06,240 --> 00:53:09,900
which makes it of a
publisher, right? Well,

881
00:53:10,050 --> 00:53:12,120
I agree that we're
responsible for the content,

882
00:53:12,480 --> 00:53:15,780
but I don't think that that's incompatible
with fundamentally yet at our core

883
00:53:15,990 --> 00:53:19,470
being a technology company where the main
thing that we do is have engineers and

884
00:53:19,471 --> 00:53:20,304
build products.

885
00:53:20,440 --> 00:53:23,170
Basically Zuckerberg and others
at the company are arguing, no,

886
00:53:23,500 --> 00:53:27,450
they're not a news organization. Why?
What would be the downside of that? Well,

887
00:53:27,451 --> 00:53:32,360
Facebook currently sits on this
little idyllic legal island where, uh,

888
00:53:32,760 --> 00:53:35,220
they can't be held liable
for much of anything.

889
00:53:35,260 --> 00:53:38,400
They're subjected to few
regulations, however,

890
00:53:38,700 --> 00:53:42,060
we're where they to be seen in the eyes
of the court as a media organization

891
00:53:42,720 --> 00:53:45,210
that could change. But setting that aside,

892
00:53:45,211 --> 00:53:48,520
what w what really strikes
me about all of this is,

893
00:53:48,550 --> 00:53:52,650
is here you have a company that
really, uh, up until this point has,

894
00:53:52,680 --> 00:53:57,680
has been crafting a set of rules that
are both as objective as possible and can

895
00:53:59,311 --> 00:54:01,950
be executed as consistently as possible.

896
00:54:02,700 --> 00:54:06,820
And they've been willing to
sacrifice rather large ideas in,

897
00:54:06,821 --> 00:54:10,030
in the name of this. They, for example,
privilege, which we talked about,

898
00:54:10,130 --> 00:54:15,060
they decided was too geographically
bound to allow for one consistent rule.

899
00:54:15,450 --> 00:54:19,380
But if you ask me,
there's nothing more, uh,

900
00:54:19,410 --> 00:54:24,410
subjective or geographically bound
than what people find interesting or

901
00:54:24,541 --> 00:54:28,000
important. What, what
people find newsworthy. Hmm.

902
00:54:28,260 --> 00:54:31,110
And I'll give and I'll give you a, and
I'll give you a great example of this.

903
00:54:31,830 --> 00:54:32,040
Uh,

904
00:54:32,040 --> 00:54:36,030
that happened just six months after the
Boston marathon bombing when this video

905
00:54:36,031 --> 00:54:41,031
starts being circulated out of
northern Mexico and it's a video of a,

906
00:54:41,131 --> 00:54:46,131
of a woman being grabbed and forced
onto her knees in front of a camera.

907
00:54:46,860 --> 00:54:50,430
And then a man with his face
covered, grabs her head,

908
00:54:50,850 --> 00:54:54,360
pulled her head back and slices her
head off right in front of the camera.

909
00:54:54,630 --> 00:54:56,250
And this video starts being spread.

910
00:54:56,430 --> 00:54:59,730
I can't count how many times, like just
reading my Twitter feed, I've been like,

911
00:54:59,760 --> 00:55:00,870
ah, you know,

912
00:55:00,871 --> 00:55:04,860
like one person who came across this
video or at least dozens of others like it

913
00:55:05,040 --> 00:55:09,210
was Shannon Young. My name is Shannon
Young. I am a freelance radio reporter.

914
00:55:09,211 --> 00:55:14,070
I've been living here in Mexico for many
years now and then is covering the drug

915
00:55:14,071 --> 00:55:17,700
war. In doing so years back, she
noticed this strange phenomenon.

916
00:55:18,060 --> 00:55:22,560
It first caught my attention in early
2010 should be checking social media.

917
00:55:22,620 --> 00:55:25,470
You know, you're scrolling
through your feed and you know,

918
00:55:25,471 --> 00:55:27,330
you'd see all this news, people say, Nah.

919
00:55:27,331 --> 00:55:31,040
There was this three hour gun battle
and intense fighting all weekend long.

920
00:55:31,130 --> 00:55:35,060
Folks were posting about clashes between
drug cartels and government forces.

921
00:55:35,570 --> 00:55:38,090
But then when Shannon
would watch the news, yeah,

922
00:55:38,090 --> 00:55:42,890
that night, yes, I got [inaudible],

923
00:55:43,250 --> 00:55:46,220
she'd see reports on the
economy and soccer results,

924
00:55:46,221 --> 00:55:50,180
but the media wasn't covering it.
There'd be no mention of these attacks.

925
00:55:50,270 --> 00:55:52,640
Nothing to do with the violence.

926
00:55:52,700 --> 00:55:55,790
And so she and other journalists
tried to get to the bottom of this.

927
00:55:55,820 --> 00:55:59,390
Reporters and Mexico City would contact
the state authorities and you know,

928
00:55:59,391 --> 00:56:02,180
public information officer and
they'd be like, shootings, bombings,

929
00:56:02,181 --> 00:56:05,330
what are you talking about? Nothing's
going on. We have no reports of anything.

930
00:56:05,630 --> 00:56:07,220
These are just internet rumors.

931
00:56:07,250 --> 00:56:10,100
The government even coined a
term for these sorts of posts.

932
00:56:10,160 --> 00:56:14,600
The famous phrase at the time
was collective psychosis.
These people are crazy

933
00:56:14,640 --> 00:56:18,000
because, you know, they didn't want
the situation to seem out of control,

934
00:56:18,900 --> 00:56:20,820
but then the video was posted.

935
00:56:23,230 --> 00:56:24,063
Yeah,

936
00:56:27,100 --> 00:56:30,160
it opens looking out the windshield
of a car. On a sunny day,

937
00:56:30,310 --> 00:56:34,300
the landscape is dry, dusty,
and the video itself is shaky,

938
00:56:34,510 --> 00:56:35,980
clearly shot on a phone.

939
00:56:37,600 --> 00:56:38,200
[inaudible]

940
00:56:38,200 --> 00:56:39,033
so

941
00:56:40,980 --> 00:56:45,190
[inaudible] go and taping
starts talking. And this woman,

942
00:56:45,250 --> 00:56:49,120
she just narrates as they
drive along this highway

943
00:56:51,900 --> 00:56:52,940
[inaudible] she can

944
00:56:53,160 --> 00:56:57,930
phone from the passenger window to
the uh, to the windshield ideas,

945
00:56:58,050 --> 00:57:01,470
not focusing in on these two
silver destroyed pickup trucks.

946
00:57:02,550 --> 00:57:05,900
[inaudible] and she's saying, look at
these cars over here or there, you know,

947
00:57:05,901 --> 00:57:10,010
shot up and [inaudible] oh
look here, look here. You know,

948
00:57:10,011 --> 00:57:13,050
this 18 wheeler is, you know,
totally abandoned. It got shot up

949
00:57:14,400 --> 00:57:15,240
at one point, she

950
00:57:16,890 --> 00:57:20,130
sticks the phone out the window
to show all of the bullet casings,

951
00:57:20,280 --> 00:57:21,240
littering the ground

952
00:57:21,620 --> 00:57:25,580
and she just, you know, turned the,
the official denial on its head.

953
00:57:27,130 --> 00:57:31,390
The government was saying there's no
violence here were cars riddled with

954
00:57:31,391 --> 00:57:35,110
bullets. It was impossible
to dismiss. And from

955
00:57:35,190 --> 00:57:38,760
then on you had more and more citizens,

956
00:57:40,380 --> 00:57:45,380
citizen journalists uploading
anonymously video of the violence.

957
00:57:49,380 --> 00:57:50,213
[inaudible]

958
00:57:50,270 --> 00:57:51,890
low fi shaky shots of

959
00:57:52,200 --> 00:57:55,150
shootouts. This member minutes,

960
00:57:58,160 --> 00:58:01,290
he headings, I mean bodies hanging,

961
00:58:02,040 --> 00:58:03,560
dangling off of overpasses

962
00:58:07,990 --> 00:58:08,630
[inaudible]

963
00:58:08,630 --> 00:58:11,360
to prove to the world that
this was really happening.

964
00:58:16,220 --> 00:58:17,600
Let's say we're not crazy.

965
00:58:21,490 --> 00:58:23,290
It's a cry for help. Yeah.

966
00:58:24,730 --> 00:58:28,780
Which brings us back to that beheading
video we mentioned a bit earlier. Yeah.

967
00:58:28,810 --> 00:58:32,200
That video of the beheading, a
lot of people were uploading it,

968
00:58:32,201 --> 00:58:35,560
condemning the violence of the drug
cartels and when it started showing up on

969
00:58:35,561 --> 00:58:40,270
Facebook, much like with
the Boston marathon bombing
photo, this team of people,

970
00:58:40,271 --> 00:58:44,110
they sat down in a room, looked at
the policy, wait, the arguments,

971
00:58:44,200 --> 00:58:48,010
and my argument was it was okay by
the rules during the Boston bombing.

972
00:58:48,280 --> 00:58:51,490
Why isn't it okay now? Particularly
given that it could help?

973
00:58:51,520 --> 00:58:54,610
Leaving this up means we warn hundreds
of thousands of people of the brutality

974
00:58:54,611 --> 00:58:58,180
of these cartels, and so we kept it up.

975
00:59:00,150 --> 00:59:00,983
However,

976
00:59:01,240 --> 00:59:03,370
it's fucking, it's wow.

977
00:59:03,400 --> 00:59:07,320
I think it's utterly irresponsible and
in fact quite despicable of them to put

978
00:59:07,400 --> 00:59:08,233
people found out.

979
00:59:08,680 --> 00:59:12,810
I have little neighbor kids that don't
need to see shit like that backlash

980
00:59:12,930 --> 00:59:16,030
should they really any justification
for allowing these videos to people.

981
00:59:16,120 --> 00:59:19,540
As powerful as David Cameron
weigh in on this decision today,

982
00:59:19,541 --> 00:59:21,980
the prime minister strongly the move

983
00:59:21,980 --> 00:59:25,820
saying we have to protect children
from this stuff. David Cameron tweeted,

984
00:59:25,970 --> 00:59:29,780
it's irresponsible of Facebook
to post beheading videos. Yeah.

985
00:59:29,910 --> 00:59:32,600
Especially people were really upset
because of what it was showing.

986
00:59:32,750 --> 00:59:34,640
And so according to my sources,

987
00:59:35,000 --> 00:59:38,540
some of the folks involved in making
this decision to leave it up were once

988
00:59:38,541 --> 00:59:42,530
again taken into an executives
office. And so we went up and,

989
00:59:42,560 --> 00:59:45,500
and there was a lot of
internal pressure to remove it.

990
00:59:45,710 --> 00:59:49,910
And I'd go to my boss and say, Hey,
look, uh, this is the decision we made.

991
00:59:50,030 --> 00:59:51,500
I recognize this is controversial.

992
00:59:51,501 --> 00:59:54,860
I want to let you know why we made these
decisions. And they made their case.

993
00:59:54,890 --> 00:59:58,490
There are valid and important human rights
reasons why you would want this to be

994
00:59:58,491 --> 01:00:03,470
out there to show the kind of savagery.
And she vehemently disagreed with that.

995
01:00:03,920 --> 01:00:06,920
They took another approach
arguing that if we take this down,

996
01:00:07,010 --> 01:00:10,070
you're deciding to punish people who
are trying to raise awareness again.

997
01:00:10,160 --> 01:00:14,120
She wasn't budging and just
didn't get, didn't get past that.

998
01:00:14,720 --> 01:00:16,580
And ultimately, um,

999
01:00:16,910 --> 01:00:19,730
I was overruled and we removed it

1000
01:00:21,150 --> 01:00:21,580
[inaudible]

1001
01:00:21,580 --> 01:00:23,800
just because there was pressure to do so.

1002
01:00:23,950 --> 01:00:27,370
The same people that six months prior
told them to leave it up because it was

1003
01:00:27,640 --> 01:00:30,250
news worthy said, take the video down.

1004
01:00:30,430 --> 01:00:31,330
Facebook this week,

1005
01:00:31,750 --> 01:00:35,230
reversed the decision and banned a video
posted to the site of a woman being

1006
01:00:35,290 --> 01:00:38,470
beheaded in a segment. Facebook
said quote, when we were [inaudible]

1007
01:00:38,580 --> 01:00:42,310
if you want the one from Boston and you
probably should have the one from Mexico

1008
01:00:42,311 --> 01:00:44,440
in, right. It was a mistake.

1009
01:00:46,030 --> 01:00:50,250
Yeah. I think it was a mistake because I,

1010
01:00:50,610 --> 01:00:54,810
I felt like like why do we have these
rules in place in the first place?

1011
01:00:55,770 --> 01:00:59,130
And, and, and it's not the,
it's not the only reason,

1012
01:00:59,910 --> 01:01:03,450
but decisions like that or the
thing that precipitated me leaving,

1013
01:01:06,270 --> 01:01:07,560
leaving. Yeah.

1014
01:01:07,920 --> 01:01:12,090
Not too long after that incident of few
members of the team decided to quit.

1015
01:01:13,320 --> 01:01:18,320
And what I think this story shows is that
Facebook has become too many different

1016
01:01:19,711 --> 01:01:24,330
things at the same time. So Facebook
is now sort of a playground.

1017
01:01:24,570 --> 01:01:27,690
It's also an r rated movie theater,

1018
01:01:27,960 --> 01:01:31,830
and now it's the front page of a
newspaper. That's all those things.

1019
01:01:31,831 --> 01:01:35,430
At the same time, it's all those things
at the same time. And in what we,

1020
01:01:35,790 --> 01:01:40,230
the users are demanding of them is that
they create a set of policies that are

1021
01:01:40,231 --> 01:01:45,231
just in the reality is justice means a
very different thing in each one of these

1022
01:01:45,571 --> 01:01:46,160
settings.

1023
01:01:46,160 --> 01:01:50,240
Justice would mean that the person in
Mexico gets told the truth in Mexico by

1024
01:01:50,241 --> 01:01:54,410
Facebook and the little boy in England
doesn't have to look at something gory

1025
01:01:54,411 --> 01:01:55,670
and horrible in England,

1026
01:01:56,390 --> 01:02:00,470
but you can't put them together
because they clash. Exactly.

1027
01:02:00,530 --> 01:02:02,090
So how do you solve that?

1028
01:02:03,570 --> 01:02:08,540
I don't know. I think it's important
to keep in mind that a, you,

1029
01:02:08,541 --> 01:02:11,710
even if you have the perfect
set of policies that,

1030
01:02:11,740 --> 01:02:15,400
that somehow manage to be just in
different settings and that can be

1031
01:02:15,401 --> 01:02:20,280
consistently enforced. The people at
the end of the day making decisions,

1032
01:02:20,430 --> 01:02:21,760
they're still, uh,

1033
01:02:24,540 --> 01:02:28,890
there's still people. They're still human
beings. Is the, is this working or no?

1034
01:02:29,050 --> 01:02:33,850
I can hear you. Yeah. Great. Okay.
At long last we figured it out,

1035
01:02:33,851 --> 01:02:35,740
Huh? Yeah. Yeah. They yearly.

1036
01:02:36,310 --> 01:02:38,800
I spoke to one woman who
did this work for Facebook.

1037
01:02:38,900 --> 01:02:41,150
I just wanted to be anonymous.

1038
01:02:41,210 --> 01:02:46,160
I don't want them to even know that I'm
doing it because they might file charges

1039
01:02:46,161 --> 01:02:46,994
against me.

1040
01:02:47,000 --> 01:02:48,290
Well, call her Marie.

1041
01:02:48,470 --> 01:02:51,620
She's from the Philippines where
she grew up on a coffee farm.

1042
01:02:51,890 --> 01:02:52,700
Yeah.

1043
01:02:52,700 --> 01:02:57,700
That's my father's Gra and I didn't
know that coffee was only for adults.

1044
01:02:59,730 --> 01:03:02,070
She said many afternoons
while she was growing up,

1045
01:03:02,160 --> 01:03:06,930
she and her mother would sit together
like outside sipping their coffee and

1046
01:03:07,020 --> 01:03:08,820
tuning into their short wave radio.

1047
01:03:09,030 --> 01:03:12,360
This is the voice of
America or Washington d C

1048
01:03:12,590 --> 01:03:16,850
and they'd sit there listening
to the voice of America silence.

1049
01:03:17,780 --> 01:03:20,990
I'm going to ask that we
all bow our heads in prayer.

1050
01:03:21,080 --> 01:03:24,860
She said one of her favorite things to
catch on voice of America were Billy

1051
01:03:24,860 --> 01:03:25,693
Graham sermons.

1052
01:03:26,690 --> 01:03:28,250
Billy Graham, one of
the great evangelists.

1053
01:03:28,740 --> 01:03:31,580
Oh father, we thank thee
for this love of God

1054
01:03:33,610 --> 01:03:38,200
that reaches around the world
and in gulfs all of mankind,

1055
01:03:39,100 --> 01:03:39,933
but then

1056
01:03:44,440 --> 01:03:48,940
fast forward 50 years to 2010 and Marie
is consuming a very different sort of

1057
01:03:48,941 --> 01:03:49,774
American media.

1058
01:03:50,210 --> 01:03:52,190
The videos were the ones that affected me.

1059
01:03:53,120 --> 01:03:57,710
There were times when I felt really bad
that I am a Christian and then I look

1060
01:03:57,711 --> 01:03:58,970
into this things.

1061
01:03:59,250 --> 01:04:03,330
She became a content moderator back in
2010 and was actually one of the first

1062
01:04:03,331 --> 01:04:05,460
people in the Philippines doing this work.

1063
01:04:05,710 --> 01:04:10,710
I usually had the night shift in the
early morning or in the at dawn from 2:00

1064
01:04:13,810 --> 01:04:15,040
AM to 4:00 AM

1065
01:04:15,160 --> 01:04:17,400
she worked from home and
despite it being dark out,

1066
01:04:17,690 --> 01:04:21,370
she put blankets up over the windows
so no one could see in at what she was

1067
01:04:21,371 --> 01:04:24,280
looking at. She locked the
door to keep her kids out.

1068
01:04:24,810 --> 01:04:29,620
Oh, you have to drive them away or I
would tell them that it's adult thing they

1069
01:04:29,621 --> 01:04:30,460
cannot watch

1070
01:04:30,650 --> 01:04:34,010
and she and the other moderators on
her team who lived throughout the

1071
01:04:34,011 --> 01:04:37,460
Philippines, they were trained on
the guidelines on this rule book.

1072
01:04:37,790 --> 01:04:40,670
There were policies that
we have to adhere to,

1073
01:04:40,700 --> 01:04:45,650
but some of us where we're
just clicking pass, pass, pass,

1074
01:04:45,651 --> 01:04:49,010
even if it's not really
passed, just to finish,

1075
01:04:49,110 --> 01:04:53,070
just to get through the content fast
enough and in some cases she thinks

1076
01:04:53,130 --> 01:04:57,780
a number of the moderators are doing
it as a form of retaliation for the low

1077
01:04:57,840 --> 01:04:58,673
rate

1078
01:04:58,690 --> 01:05:02,040
people were pissed at the low
pay. If I can ask how much, what,

1079
01:05:02,050 --> 01:05:04,420
how much were you making
an hour doing this?

1080
01:05:04,650 --> 01:05:06,600
As far as I remember it,

1081
01:05:07,350 --> 01:05:11,730
we were paid like $2
and 50 cents per hour.

1082
01:05:12,600 --> 01:05:16,790
Marie wouldn't say whether or not this
low wage led her to just let things

1083
01:05:16,810 --> 01:05:18,940
through, but she did say,

1084
01:05:19,280 --> 01:05:22,460
based on my conservative background,

1085
01:05:22,490 --> 01:05:26,480
there are things that that
I cannot look objectively,

1086
01:05:27,950 --> 01:05:32,950
so I reject many of the things that
I think are not acceptable really.

1087
01:05:36,230 --> 01:05:37,070
Of course

1088
01:05:37,220 --> 01:05:41,930
she said whether something was outside
the rules or not. If her gut told her to,

1089
01:05:42,350 --> 01:05:43,550
she just took it down.

1090
01:05:43,840 --> 01:05:45,700
Whenever it affects me a lot,

1091
01:05:45,850 --> 01:05:50,850
I would click the button now like it's
a violation because if it's going to

1092
01:05:51,431 --> 01:05:55,180
disturb the young audience
then it should not be there.

1093
01:05:55,360 --> 01:05:58,870
So like if there's a new person,

1094
01:05:59,020 --> 01:06:03,430
whether it was a breastfeeding photo
or an anatomy video or a piece of art,

1095
01:06:03,800 --> 01:06:08,800
I would consider it as pornography
and then click right away.

1096
01:06:10,720 --> 01:06:15,490
It's a violation. You took the line
to your own hands, you went vigilante.

1097
01:06:16,230 --> 01:06:18,690
Yeah. Or something.

1098
01:06:20,630 --> 01:06:21,441
So yeah,

1099
01:06:21,441 --> 01:06:26,441
I have to protect kids from those evil uh,

1100
01:06:30,560 --> 01:06:31,490
side of humankind.

1101
01:07:02,780 --> 01:07:03,613
[inaudible] [inaudible]

1102
01:07:13,340 --> 01:07:13,620
[inaudible]

1103
01:07:13,620 --> 01:07:15,450
where does that leave you feeling?
They don't leave you feeling it.

1104
01:07:15,451 --> 01:07:18,830
This is just I'm at the
end. This is just um,

1105
01:07:19,520 --> 01:07:22,850
undoable. Um, I,

1106
01:07:23,210 --> 01:07:25,700
I think they will inevitably fail,

1107
01:07:25,730 --> 01:07:28,610
but they have to try and, and,

1108
01:07:28,700 --> 01:07:31,100
and I think we should
all be rooting for them.

1109
01:08:00,550 --> 01:08:01,383
[inaudible] [inaudible]

1110
01:08:01,410 --> 01:08:05,910
this episode was reported by Simon Adler
with help from Tracy Hunt and produced

1111
01:08:05,911 --> 01:08:08,580
by Simon with help from Bethel hop. Tay.

1112
01:08:08,730 --> 01:08:12,600
Big thanks to Sarah Roberts whose research
into commercial content moderation

1113
01:08:12,601 --> 01:08:16,370
got us going a big time and we thank
her very, very much for that. Thanks.

1114
01:08:16,371 --> 01:08:20,540
Also to Jeffrey Rosen who helped us in
our thinking about what Facebook is true.

1115
01:08:21,440 --> 01:08:21,470
Michael Churnis,

1116
01:08:21,470 --> 01:08:26,180
whose voice we used to mask other people's
voices to Caroline Glanville Rashika

1117
01:08:26,400 --> 01:08:30,290
booed, Raja Ryan Dougan, Ellen silver,
James Mitchell and Guy Rosen of course,

1118
01:08:30,620 --> 01:08:34,760
to all the content moderators who
took the time to talk to us and uh,

1119
01:08:34,940 --> 01:08:38,810
threw out to sign off. Yeah, I guess you
said, Huh? Ready? You want to go first?

1120
01:08:38,840 --> 01:08:41,990
Yeah. I'm Chad. I boom, rod. I
remember college. Thanks to listen.

