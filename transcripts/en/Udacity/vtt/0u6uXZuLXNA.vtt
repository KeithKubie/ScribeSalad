WEBVTT
Kind: captions
Language: en

00:00:00.250 --> 00:00:01.780
So basically planning is hard.

00:00:01.780 --> 00:00:04.460
So I assume reinforcement
learning is also hard.

00:00:04.460 --> 00:00:06.500
&gt;&gt; So the results that we have for

00:00:06.500 --> 00:00:10.430
reinforcement learning in POMDPs are
more empirical and algorithmic results,

00:00:10.430 --> 00:00:11.900
they're not really formal results.

00:00:11.900 --> 00:00:14.070
But still something that
people try to do sometimes.

00:00:14.070 --> 00:00:16.460
If you have some kind
of robotic system or

00:00:16.460 --> 00:00:19.710
agent system that's trying to figure
out what to do, and the world

00:00:19.710 --> 00:00:24.025
that it's in is partially observable,
then you have to do something like this.

00:00:24.025 --> 00:00:25.720
&gt;&gt; Yes, solve the halting problem.

00:00:25.720 --> 00:00:28.650
&gt;&gt; Well, no, no,
getting the exact optimal answer

00:00:28.650 --> 00:00:29.970
is undecidable
&gt;&gt; Well,

00:00:29.970 --> 00:00:32.350
then is it decidable that
you can get it near optimal?

00:00:32.350 --> 00:00:33.880
&gt;&gt; Yes
&gt;&gt; Okay, well, I feel better.

00:00:33.880 --> 00:00:36.360
Why don't you stop depressing me and
tell me what to do, so

00:00:36.360 --> 00:00:38.930
that I can sort of feel better
about this whole approach?

00:00:38.930 --> 00:00:41.450
Sure, no problem,
I'm going to to ask you what to do.

00:00:41.450 --> 00:00:44.430
Okay, so in particular, do you remember
we had kind of two main flavors of

00:00:44.430 --> 00:00:46.270
reinforcement learning algorithms for
MDPs.

00:00:46.270 --> 00:00:47.690
Do you remember what those were?

00:00:47.690 --> 00:00:49.730
&gt;&gt; There's value iteration and
policy iteration, right?

00:00:49.730 --> 00:00:53.666
&gt;&gt; Yeah, those are planning algorithms,
but for reinforcement learning in

00:00:53.666 --> 00:00:57.700
an MDP, the two main branches,
model-based RL and model-free RL.

00:00:57.700 --> 00:00:58.730
&gt;&gt; Yeah, sure, right.

00:00:58.730 --> 00:00:59.555
Well, that was obvious.

00:00:59.555 --> 00:01:02.180
&gt;&gt; Uh-huh, and do you remember
[LAUGH] the distinction between them?

00:01:02.180 --> 00:01:04.379
&gt;&gt; Well, one used the model and
one didn't.

00:01:04.379 --> 00:01:06.250
&gt;&gt; One learned a model and one didn't.

00:01:06.250 --> 00:01:07.200
&gt;&gt; Okay, well, same thing.

00:01:07.200 --> 00:01:09.460
You can't use a model if you don't
learn it if you didn't know it.

00:01:09.460 --> 00:01:11.680
&gt;&gt; [LAUGH] That's true,
that's very well said.

00:01:11.680 --> 00:01:13.680
&gt;&gt; So you learn a model and
then you use it.

00:01:13.680 --> 00:01:16.230
Versus don't bother to learn
the model and just do it.

00:01:16.230 --> 00:01:19.790
I think the little quip was,
the world is your model.

00:01:19.790 --> 00:01:20.540
&gt;&gt; Whose quip is that?

00:01:20.540 --> 00:01:21.860
&gt;&gt; Probably Rob Brooks.

00:01:21.860 --> 00:01:24.526
&gt;&gt; All right, so we can actually use
this same kind of distinction, this

00:01:24.526 --> 00:01:29.769
model-based RL and model-free based RL,
or model-free RL, in the POMDP setting.

00:01:29.769 --> 00:01:34.900
Where in model-based RL you actually
try to learn the POMDP and then

00:01:34.900 --> 00:01:40.674
you plan in it, and in model-free RL
we try to map observations to actions.

00:01:40.674 --> 00:01:44.021
And we do that iteratively over time, so
we don't actually build the model, but

00:01:44.021 --> 00:01:47.180
we do try to figure out, okay, when I
see this, this is a good thing to do.

00:01:47.180 --> 00:01:49.760
&gt;&gt; Well can I ask you a question
while where here before we jump in?

00:01:49.760 --> 00:01:54.810
So, one of the things that we know
we learned in AI class 150 years ago

00:01:54.810 --> 00:01:57.580
is that if you don't
know what's going on,

00:01:57.580 --> 00:02:01.710
you can often figure out what's going
on by taking specific actions that

00:02:01.710 --> 00:02:05.730
guarantee you end up in some
state that you actually know.

00:02:05.730 --> 00:02:06.320
&gt;&gt; Sure.

00:02:06.320 --> 00:02:10.479
&gt;&gt; So even if you're blind and
you're trying to get to

00:02:10.479 --> 00:02:13.290
a particular place in the room,
you could do stuff like, well,

00:02:13.290 --> 00:02:17.010
I'm just going to go left for 15 minutes
and then I know no matter what happens,

00:02:17.010 --> 00:02:19.420
I'm going to be against the left wall,
then I know where I am.

00:02:19.420 --> 00:02:20.030
&gt;&gt; Yes.

00:02:20.030 --> 00:02:21.172
&gt;&gt; And then I can do things.

00:02:21.172 --> 00:02:24.557
Do either of these methods
do the equivalent of that or

00:02:24.557 --> 00:02:25.930
an analogue of that?

00:02:25.930 --> 00:02:27.370
&gt;&gt; Either could, in fact.

00:02:27.370 --> 00:02:29.430
&gt;&gt; Well, okay, well, that's good.

00:02:29.430 --> 00:02:32.712
&gt;&gt; Again, the guarantees on whether
things actually work in this space

00:02:32.712 --> 00:02:35.985
are nonexistent, so it's not the case
that we can always say, yeah,

00:02:35.985 --> 00:02:37.035
it's always going to do the right thing.

00:02:37.035 --> 00:02:40.085
It's going to figure out the simplest
way of getting to a known state and

00:02:40.085 --> 00:02:41.035
then behave from there.

00:02:41.035 --> 00:02:43.685
But yeah, I mean I've seen both
these kinds of algorithms do

00:02:43.685 --> 00:02:44.625
that kind of thing.

00:02:44.625 --> 00:02:46.016
&gt;&gt; Okay, good, good,
well, that's promising.

