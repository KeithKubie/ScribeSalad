WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:04.040
The final type of optimization for
reducing the miss rate that we will look

00:00:04.040 --> 00:00:10.360
at is a so called loop interchange which
is one of the compiler optimizations

00:00:10.360 --> 00:00:14.570
that can be done to transform the code
into code that has better locality.

00:00:14.570 --> 00:00:20.630
So suppose that we are initializing a
matrix like this by having an outer loop

00:00:20.630 --> 00:00:26.350
and an inner loop and then we initialize
the element and then loop like this.

00:00:26.350 --> 00:00:29.590
The layout of this matrix in memory

00:00:29.590 --> 00:00:33.500
if it's a C array is such
that it begins with a[0][0].

00:00:33.500 --> 00:00:37.880
The next element in memory
will be a[0][1], and so on.

00:00:39.150 --> 00:00:43.800
Eventually we have the last
element of this row.

00:00:43.800 --> 00:00:48.910
And only now we will have a[1][0] and
so on.

00:00:48.910 --> 00:00:53.820
So now let's look at how this
loop accesses these elements.

00:00:53.820 --> 00:00:56.170
i and j are both 0 at first.

00:00:56.170 --> 00:00:58.120
So we will access this element.

00:00:58.120 --> 00:01:00.740
Next, j will be incremented, so

00:01:00.740 --> 00:01:05.489
we will access this element, and
then this element, and so on.

00:01:05.489 --> 00:01:10.090
We will access all of the rows of
the matrix before we come back, and

00:01:10.090 --> 00:01:13.290
start accessing the second
element in each row.

00:01:13.290 --> 00:01:17.310
So the problem is, when this is
accessed, we fetch an entire cache

00:01:17.310 --> 00:01:21.650
block worth of stuff into the cache
just to use this one element.

00:01:21.650 --> 00:01:25.240
Then we're going to fetch a block
here to use this one element.

00:01:25.240 --> 00:01:28.080
And by the time we reach
the end of the matrix and

00:01:28.080 --> 00:01:32.200
look back here, we might have
run out of space in the cache.

00:01:32.200 --> 00:01:36.490
And the block that we would now use
has been kicked out of the cache.

00:01:36.490 --> 00:01:39.710
So we fetch it again,
use this one element, and so on.

00:01:39.710 --> 00:01:42.140
So we have one miss per access here.

00:01:42.140 --> 00:01:46.960
So a good compiler will detect
that the order of these loops

00:01:46.960 --> 00:01:51.250
doesn't match the layout in memory and
it's going to perform what is called

00:01:51.250 --> 00:01:56.080
a loop interchange which amounts
to simply sloping the two loops.

00:01:56.080 --> 00:02:02.430
So now the inner loop is the one that
moves to the next element in memory.

00:02:02.430 --> 00:02:06.320
So once we fetch a block from memory
we end up using the whole block.

00:02:06.320 --> 00:02:08.687
Only then we move to the next block and
so on.

00:02:08.687 --> 00:02:10.979
Once we are done with the row,
we move on to the next next row,

00:02:10.979 --> 00:02:14.830
so now we are nicely sequentially
accessing this matrix.

00:02:14.830 --> 00:02:18.894
Not only does it improve locality
because now we end up accessing

00:02:18.894 --> 00:02:23.334
the entire cache block at the time,
but also it makes the access nicely

00:02:23.334 --> 00:02:27.115
sequential so one of the prefetchers
can do a good job on it.

00:02:27.115 --> 00:02:30.919
So this works really well, it
dramatically improves the hit rate that

00:02:30.919 --> 00:02:33.582
we're getting, but
it is not always possible.

00:02:33.582 --> 00:02:37.690
You cannot just take any two nested
loops and transform form them this way.

00:02:37.690 --> 00:02:41.100
The compiler has to
prove that this code and

00:02:41.100 --> 00:02:44.830
this code are equivalent, which it
does by proving that there are no

00:02:44.830 --> 00:02:47.680
dependencies between
iterations of these loops.

