WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.970
[MUSIC PLAYING]

00:00:08.200 --> 00:00:09.450
OSCAR WAHLTINEZ: Hi, everyone.

00:00:09.450 --> 00:00:10.540
Thank you all for coming.

00:00:10.540 --> 00:00:12.870
Great to see so
many people here.

00:00:12.870 --> 00:00:14.070
My name is Oscar.

00:00:14.070 --> 00:00:16.077
I am from the Developer
Relations Team.

00:00:16.077 --> 00:00:17.910
And today we're going
to speak about Camera.

00:00:20.500 --> 00:00:23.680
And this session will
cover three major topics.

00:00:23.680 --> 00:00:26.940
First, we're going to talk about
the inner workings of camera

00:00:26.940 --> 00:00:27.900
on Android.

00:00:27.900 --> 00:00:30.210
Second, Snap is
here with us today.

00:00:30.210 --> 00:00:31.710
They're going to
showcase how they

00:00:31.710 --> 00:00:33.150
use the Camera
APIs in production

00:00:33.150 --> 00:00:35.030
to millions of users.

00:00:35.030 --> 00:00:37.710
And we're going to close with
our vision of the future of how

00:00:37.710 --> 00:00:41.250
Camera API should evolve and
the ecosystem that goes with it.

00:00:44.220 --> 00:00:45.860
Let's jump right in.

00:00:45.860 --> 00:00:49.520
Developing Camera app is
a series of compromises.

00:00:49.520 --> 00:00:52.850
Some are outside your
control as a developer.

00:00:52.850 --> 00:00:54.740
But understanding
those will help

00:00:54.740 --> 00:00:57.110
you make better decisions
where you have control

00:00:57.110 --> 00:00:57.997
within your app.

00:01:01.130 --> 00:01:05.209
Let's go over how Camera
works at the physical level.

00:01:05.209 --> 00:01:07.130
As any decent
photographer knows,

00:01:07.130 --> 00:01:10.730
it is a biplane of steps
at the physical level.

00:01:10.730 --> 00:01:13.430
Visible light goes
through a lens

00:01:13.430 --> 00:01:16.760
that directs it to filters,
which passes the light

00:01:16.760 --> 00:01:19.910
onto millions of light sensors.

00:01:19.910 --> 00:01:22.070
Then that converts
the light, finally,

00:01:22.070 --> 00:01:24.050
into a 2D matrix of pixels.

00:01:24.050 --> 00:01:27.220
When you think light
sensors, the first thing

00:01:27.220 --> 00:01:30.020
that may come to mind
is the almighty CCD.

00:01:30.020 --> 00:01:33.420
Nowadays, we have many other
kinds, such a CMOS or APS,

00:01:33.420 --> 00:01:35.180
that are actually
more commonly used

00:01:35.180 --> 00:01:39.860
in today's modern cameras,
DSLRs, phones, et cetera.

00:01:39.860 --> 00:01:43.480
From now on, we refer to this
component as the Camera Module.

00:01:46.130 --> 00:01:50.140
The output of the Camera
Module is our raw picture,

00:01:50.140 --> 00:01:51.350
a raw frame.

00:01:51.350 --> 00:01:54.260
It is not entirely
unprocessed, but it has not

00:01:54.260 --> 00:01:59.030
been processed outside of the
Camera Module at this stage.

00:01:59.030 --> 00:02:00.560
You can think of
the Camera Module

00:02:00.560 --> 00:02:05.360
as a black box that
dispatches these frames.

00:02:05.360 --> 00:02:09.190
In early hardware, we
had three physical pins

00:02:09.190 --> 00:02:11.840
for different kinds of pictures.

00:02:11.840 --> 00:02:14.810
Nowadays, the modern
designs, we have a single pin

00:02:14.810 --> 00:02:16.690
thanks to tricks
like multiplexing,

00:02:16.690 --> 00:02:18.740
and higher clock
speeds, and so forth.

00:02:18.740 --> 00:02:23.660
But the conceptual model remains
as having separate processing

00:02:23.660 --> 00:02:27.020
pipelines for each
kind of image.

00:02:27.020 --> 00:02:30.590
We have, generally speaking,
three broad use cases--

00:02:30.590 --> 00:02:33.980
video preview, photo,
and video recording.

00:02:33.980 --> 00:02:35.361
We'll cover those separately.

00:02:41.140 --> 00:02:43.600
The Camera Module, as
I said, is a black box.

00:02:43.600 --> 00:02:47.890
And it contains an increasing
amount of smarts within,

00:02:47.890 --> 00:02:52.170
some of which are in a
closed feedback loop.

00:02:52.170 --> 00:02:54.460
We, as developers, will
have very little visibility

00:02:54.460 --> 00:02:57.130
into what goes on in there.

00:02:57.130 --> 00:03:01.105
To give you an example, when
you set, say, auto focus or auto

00:03:01.105 --> 00:03:02.920
white balance, the
Camera Module may

00:03:02.920 --> 00:03:05.830
be looking for faces to
see how to better optimize

00:03:05.830 --> 00:03:06.700
those settings.

00:03:06.700 --> 00:03:10.360
And you don't really have
any control over that.

00:03:10.360 --> 00:03:14.080
From a framework
standpoint, all developers

00:03:14.080 --> 00:03:19.892
do is send one configuration
in, and you get one frame out.

00:03:19.892 --> 00:03:21.100
This is very, very important.

00:03:21.100 --> 00:03:23.800
You send one configuration
in, one frame out.

00:03:23.800 --> 00:03:25.840
For each frame, there
is a configuration

00:03:25.840 --> 00:03:28.210
that goes with it.

00:03:28.210 --> 00:03:31.216
To help you with this, we have a
set of template configurations.

00:03:31.216 --> 00:03:32.590
We'll cover those
later, as well.

00:03:35.820 --> 00:03:40.100
So let's zoom into the preview
pipeline, the one on top.

00:03:40.100 --> 00:03:43.250
As I said, each biplane
shown is a broad use case.

00:03:43.250 --> 00:03:45.290
When it comes to preview,
you can think of it

00:03:45.290 --> 00:03:47.000
as the viewfinder.

00:03:47.000 --> 00:03:49.490
So whenever somebody is
holding their phone up

00:03:49.490 --> 00:03:51.972
and you want to see
what the camera sees,

00:03:51.972 --> 00:03:53.680
this is the use case
we're talking about.

00:03:58.390 --> 00:04:00.306
We need to compromise
on some things.

00:04:00.306 --> 00:04:02.680
Obviously, the camera can only
do so many things at once.

00:04:02.680 --> 00:04:04.138
When it comes to
preview, we choose

00:04:04.138 --> 00:04:05.590
to compromise on quality.

00:04:05.590 --> 00:04:07.930
We care much more about latency.

00:04:07.930 --> 00:04:09.910
We want the user to
be able to see what

00:04:09.910 --> 00:04:13.480
the camera sees much faster.

00:04:13.480 --> 00:04:16.180
This just generally
results in better latency,

00:04:16.180 --> 00:04:18.079
because we're able to
compromise, as I said,

00:04:18.079 --> 00:04:20.390
on quality.

00:04:20.390 --> 00:04:22.900
Some of those compromises come
in the form of, for example,

00:04:22.900 --> 00:04:26.907
reduced motion stabilization
or less noise reduction.

00:04:29.590 --> 00:04:31.930
Moving onto the
photo pipeline, you

00:04:31.930 --> 00:04:37.900
may want to enable our users
to capture high-quality images.

00:04:37.900 --> 00:04:43.210
Keep in mind, as I said before,
one frame configuration in,

00:04:43.210 --> 00:04:44.350
one frame out.

00:04:44.350 --> 00:04:45.820
Different frame
configuration may

00:04:45.820 --> 00:04:49.270
mean that you will not be able
to reuse the same raw frame.

00:04:49.270 --> 00:04:50.890
One example of
this is if you are

00:04:50.890 --> 00:04:54.600
requesting different exposure.

00:04:54.600 --> 00:04:56.230
So at the physical
level, the sensor

00:04:56.230 --> 00:04:58.750
needs to expose the frame for
a different period of time.

00:04:58.750 --> 00:05:00.250
That means that
you're going to have

00:05:00.250 --> 00:05:01.870
a different frame entirely.

00:05:01.870 --> 00:05:04.150
If you are mindful while
you set up your pipelines,

00:05:04.150 --> 00:05:08.450
you may be able to avoid
this compromise entirely.

00:05:08.450 --> 00:05:10.190
So when it comes
to photos, we care

00:05:10.190 --> 00:05:13.670
much more about the quality,
a lot less about the speed.

00:05:13.670 --> 00:05:17.240
So we choose to compromise on
that latency in lieu of having

00:05:17.240 --> 00:05:18.530
much better-quality image.

00:05:21.022 --> 00:05:22.480
Lastly, we have
the video pipeline.

00:05:22.480 --> 00:05:25.660
This is for the video
record use case.

00:05:25.660 --> 00:05:28.540
As the diagram indicates, you're
saying that all these pipelines

00:05:28.540 --> 00:05:30.670
should be parallel, in theory.

00:05:30.670 --> 00:05:33.700
In practice, we have a
number of bottlenecks.

00:05:33.700 --> 00:05:36.610
And frames can only come
so fast out of the camera.

00:05:36.610 --> 00:05:39.910
Some of those bottlenecks
include the exposure time.

00:05:39.910 --> 00:05:43.812
Some of them can be the
processing power, memory,

00:05:43.812 --> 00:05:45.770
bandwidth limits, and a
number of other things.

00:05:48.890 --> 00:05:50.640
In the video pipeline,
it's almost a blend

00:05:50.640 --> 00:05:51.840
of the previous two.

00:05:51.840 --> 00:05:52.890
We care about the speed.

00:05:52.890 --> 00:05:55.950
We definitely need to have
frames coming consistently

00:05:55.950 --> 00:05:57.880
out of the camera
at a certain rate.

00:05:57.880 --> 00:06:00.000
But at the same time, we
also care about quality.

00:06:00.000 --> 00:06:03.000
So it is very important that,
in this kind of use case,

00:06:03.000 --> 00:06:05.760
we find the right balance.

00:06:05.760 --> 00:06:10.050
Generally speaking, we can
only test for so many things.

00:06:10.050 --> 00:06:12.990
Android runs in many, many
devices, not just the high end,

00:06:12.990 --> 00:06:15.720
but you're talking
about the low end, too.

00:06:15.720 --> 00:06:19.560
Unfortunately, we can only
test, as I said, so many things.

00:06:19.560 --> 00:06:23.130
In general, the
best test scenario

00:06:23.130 --> 00:06:25.110
is when you have
preview pipeline running

00:06:25.110 --> 00:06:26.035
plus one other.

00:06:26.035 --> 00:06:27.660
You're going to have
a really hard time

00:06:27.660 --> 00:06:29.618
if you want to have all
three pipelines running

00:06:29.618 --> 00:06:30.763
simultaneously.

00:06:34.220 --> 00:06:37.580
So we discussed trade-offs
made by the hardware.

00:06:37.580 --> 00:06:40.589
We discussed trade-offs
made by the framework.

00:06:40.589 --> 00:06:42.880
And now we're going to dive
into the application layer,

00:06:42.880 --> 00:06:44.171
what we, as developers, can do.

00:06:47.150 --> 00:06:50.630
Let's walk through the
end-to-end process of a frame,

00:06:50.630 --> 00:06:53.220
from the creation of a request
until the pictures are finally

00:06:53.220 --> 00:06:55.330
in memory, ready for us to use.

00:06:55.330 --> 00:06:59.570
Follow the steps, [? USC-ABC, ?]
and then profit will just fall

00:06:59.570 --> 00:07:00.507
in your lap.

00:07:00.507 --> 00:07:02.090
If you don't believe
me, ask Snapchat.

00:07:06.487 --> 00:07:08.570
The first decision you
have to make as a developer

00:07:08.570 --> 00:07:11.120
is selecting the right
device out of the ones

00:07:11.120 --> 00:07:13.280
available on your list.

00:07:13.280 --> 00:07:16.130
Device here means the
Camera Module, not

00:07:16.130 --> 00:07:17.450
devices in the phone device.

00:07:17.450 --> 00:07:20.175
Each phone may have
multiple cameras.

00:07:20.175 --> 00:07:22.550
Generally speaking, you probably
have at least one front,

00:07:22.550 --> 00:07:24.630
one back.

00:07:24.630 --> 00:07:28.680
This is especially important now
that we have Multi-Camera APIs.

00:07:28.680 --> 00:07:33.109
You may have multiple devices
that are, say, back facing

00:07:33.109 --> 00:07:34.150
that you can choose from.

00:07:34.150 --> 00:07:36.390
So you will have to go
through all those devices

00:07:36.390 --> 00:07:38.180
and see which one fits
your use case best.

00:07:41.740 --> 00:07:44.080
Once you've successfully
opened the camera,

00:07:44.080 --> 00:07:46.450
you're going to get the
camera device instance.

00:07:46.450 --> 00:07:49.180
And that is necessary
to proceed forward

00:07:49.180 --> 00:07:53.104
in the open camera callback.

00:07:53.104 --> 00:07:54.520
You can use the
very same callback

00:07:54.520 --> 00:07:58.300
to monitor the status
of your camera device.

00:07:58.300 --> 00:07:59.980
It is entirely possible
that the camera

00:07:59.980 --> 00:08:02.800
may be yanked from you if
a higher-priority process

00:08:02.800 --> 00:08:04.081
requires the device.

00:08:04.081 --> 00:08:06.580
This could happen very easily
in a multi-window environment,

00:08:06.580 --> 00:08:07.080
for example.

00:08:10.280 --> 00:08:12.870
Second step, you need to
allocate your camera output

00:08:12.870 --> 00:08:13.627
targets.

00:08:13.627 --> 00:08:15.710
This is where each of the
pipelines that we showed

00:08:15.710 --> 00:08:20.210
earlier are going to copy your
frames in the form of buffers.

00:08:20.210 --> 00:08:21.749
The memory may
already be allocated.

00:08:21.749 --> 00:08:23.540
Then all you need to
do is to get reference

00:08:23.540 --> 00:08:26.700
to the underlying surface
and pass it as a target.

00:08:26.700 --> 00:08:29.390
Otherwise, you may have
to wait for a callback.

00:08:29.390 --> 00:08:32.510
Once the targets are
ready, the capture session,

00:08:32.510 --> 00:08:35.429
which is specific to the device
that you open, can be created.

00:08:40.510 --> 00:08:42.809
It is worth noting
that, as I said,

00:08:42.809 --> 00:08:45.604
the camera capture session
is specific to that device

00:08:45.604 --> 00:08:46.520
that you open earlier.

00:08:50.170 --> 00:08:53.610
Once the session is ready, you
can build a capture request.

00:08:53.610 --> 00:08:56.580
One of the predefined
templates must be used.

00:08:56.580 --> 00:08:59.490
If you don't want to take any
of the hints from the system,

00:08:59.490 --> 00:09:02.870
you can use template
manual for full control.

00:09:02.870 --> 00:09:04.320
Otherwise, the
framework is going

00:09:04.320 --> 00:09:05.940
to provide a set
of templates that

00:09:05.940 --> 00:09:09.270
closely align to the camera
conceptual model we discussed

00:09:09.270 --> 00:09:09.790
earlier.

00:09:09.790 --> 00:09:11.470
So you have templates for video.

00:09:11.470 --> 00:09:12.690
You have templates for photo.

00:09:12.690 --> 00:09:14.106
And you have
templates for record.

00:09:17.800 --> 00:09:22.000
The capture request contains
specific frame configuration

00:09:22.000 --> 00:09:23.200
and the output target.

00:09:23.200 --> 00:09:27.750
Recall, frame configuration
in, output frame out.

00:09:27.750 --> 00:09:30.610
A couple of things to
know is the output target

00:09:30.610 --> 00:09:32.860
must be one of the
previously defined ones.

00:09:32.860 --> 00:09:35.330
You cannot just use another
surface here and attach it.

00:09:35.330 --> 00:09:36.746
It needs to be one
of the surfaces

00:09:36.746 --> 00:09:41.500
that you declare first
as part of the session.

00:09:41.500 --> 00:09:43.200
This is the configuration
part of it--

00:09:43.200 --> 00:09:44.750
of the configuration
in, frame out.

00:09:48.080 --> 00:09:51.200
To recap, we've chosen the
camera device that we want.

00:09:51.200 --> 00:09:53.900
We created the camera session
for that particular device.

00:09:53.900 --> 00:09:56.050
And now we built a
capture request that

00:09:56.050 --> 00:09:58.490
will be used in that session.

00:09:58.490 --> 00:10:01.190
We can finally ask
for a camera frame.

00:10:01.190 --> 00:10:04.280
We send the capture
request to the session,

00:10:04.280 --> 00:10:06.410
and then we wait
for the callback.

00:10:06.410 --> 00:10:08.820
We can do this in two ways.

00:10:08.820 --> 00:10:10.820
We can send the
request once, or we can

00:10:10.820 --> 00:10:12.620
make it a repeating request.

00:10:12.620 --> 00:10:15.140
This makes more sense in
use cases like, for example,

00:10:15.140 --> 00:10:16.141
preview or video record.

00:10:16.141 --> 00:10:18.098
You don't want to be
sending that configuration

00:10:18.098 --> 00:10:19.130
for every single frame.

00:10:19.130 --> 00:10:21.470
This is a very easy way to
just send one configuration

00:10:21.470 --> 00:10:23.469
and ask the framework to
continuously repeat it.

00:10:26.550 --> 00:10:28.740
Now, which callback do
you want to listen to?

00:10:28.740 --> 00:10:31.470
That really depends on what
you want to get out of it.

00:10:31.470 --> 00:10:33.540
If you want to get
the frame metadata,

00:10:33.540 --> 00:10:37.420
you should look inside
of the capture callback.

00:10:40.200 --> 00:10:42.970
If you want to get the
frame for CPU processing,

00:10:42.970 --> 00:10:45.290
one of the options is
using image reader.

00:10:47.990 --> 00:10:50.800
Generally speaking, you can just
get whatever pixel information

00:10:50.800 --> 00:10:52.880
out of the output surface
that you had set up.

00:10:52.880 --> 00:10:55.835
Image reader is just one of
the easiest ways to do it.

00:10:55.835 --> 00:10:58.210
If you want to get
that into the GPU,

00:10:58.210 --> 00:11:00.860
a great idea is running
script allocations.

00:11:00.860 --> 00:11:02.540
Obviously, that's
not the only choice.

00:11:02.540 --> 00:11:05.990
You can also use OpenGL,
text, or buffers.

00:11:05.990 --> 00:11:09.220
And this is the cycle,
step one through five,

00:11:09.220 --> 00:11:12.290
that we need to go through
for every single frame.

00:11:12.290 --> 00:11:16.182
Recall, one configuration in,
one frame out, and a bunch

00:11:16.182 --> 00:11:17.390
of trade-offs in the process.

00:11:23.400 --> 00:11:26.310
MUSTAFA ABRAR: All
right, thanks, Oscar.

00:11:26.310 --> 00:11:27.780
My name is Mustafa Abrar.

00:11:27.780 --> 00:11:30.060
I'm a software engineer at Snap.

00:11:30.060 --> 00:11:32.070
And so I work on
the Snapchat app.

00:11:32.070 --> 00:11:35.790
Today what I want to do is take
what Oscar said about the lower

00:11:35.790 --> 00:11:38.730
layers of the camera,
and work up to your app,

00:11:38.730 --> 00:11:40.620
and design choices
that you make,

00:11:40.620 --> 00:11:43.896
and how they influence how
you interact with the camera.

00:11:43.896 --> 00:11:45.270
We'll talk about
some trade-offs,

00:11:45.270 --> 00:11:48.690
in terms of architecture, how to
architect the camera framework

00:11:48.690 --> 00:11:49.950
inside of your app.

00:11:49.950 --> 00:11:53.550
And we'll talk about specific
challenges in a more narrow use

00:11:53.550 --> 00:11:55.860
case.

00:11:55.860 --> 00:11:58.770
So nowadays, if you've
ever used Snapchat--

00:11:58.770 --> 00:12:00.480
I'm hoping everyone has--

00:12:00.480 --> 00:12:02.550
the first thing that
happens is it opens directly

00:12:02.550 --> 00:12:03.900
into the camera.

00:12:03.900 --> 00:12:07.110
And the reason for this is
that people use the camera now

00:12:07.110 --> 00:12:08.521
as a means of communication.

00:12:08.521 --> 00:12:10.020
They're taking a
picture, or they're

00:12:10.020 --> 00:12:12.720
adding metadata creativity,
and then sending it.

00:12:12.720 --> 00:12:15.390
And so it's really
like the cursor,

00:12:15.390 --> 00:12:18.060
where what you have to say
and trying to get that out

00:12:18.060 --> 00:12:23.250
as quickly as possible is
the thing we really value.

00:12:23.250 --> 00:12:26.520
There are a few key
camera design decisions

00:12:26.520 --> 00:12:28.740
that we've made, and
these will influence how

00:12:28.740 --> 00:12:30.030
we interact with the camera.

00:12:30.030 --> 00:12:32.730
The first of those
is full screen.

00:12:32.730 --> 00:12:36.150
In video, in pictures,
front camera, rear camera,

00:12:36.150 --> 00:12:37.860
all of them are full screen.

00:12:37.860 --> 00:12:40.410
Now you typically don't see
this on a lot of cameras.

00:12:40.410 --> 00:12:42.540
If you take your camera
out, usually picture mode

00:12:42.540 --> 00:12:44.640
is 4 by 3 aspect ratio.

00:12:44.640 --> 00:12:47.910
Because a lot of times,
you share it online.

00:12:47.910 --> 00:12:51.340
The camera actually optimized
for specific aspect ratios.

00:12:51.340 --> 00:12:54.750
And so, since your display
is usually 16 by 9,

00:12:54.750 --> 00:12:58.370
or some other aspect
ratio that might not

00:12:58.370 --> 00:13:01.860
be available for picture mode,
we have to make a trade-off.

00:13:01.860 --> 00:13:04.960
Usually, the devices will
have something that matches,

00:13:04.960 --> 00:13:07.110
but it might be really
high resolution.

00:13:07.110 --> 00:13:10.260
And to just encode that
and create a JPEG out of it

00:13:10.260 --> 00:13:11.560
just takes a long time.

00:13:11.560 --> 00:13:13.935
So we have to make trade-offs,
in terms of the resolution

00:13:13.935 --> 00:13:18.190
we select for taking pictures
and video, and so forth.

00:13:18.190 --> 00:13:19.980
The second part is single mode.

00:13:19.980 --> 00:13:21.100
There's no video mode.

00:13:21.100 --> 00:13:23.730
You don't swipe and
enter a video mode.

00:13:23.730 --> 00:13:25.590
And when you have
this design choice,

00:13:25.590 --> 00:13:27.330
it leads to a set
of optimizations

00:13:27.330 --> 00:13:28.390
you can't take advantage.

00:13:28.390 --> 00:13:31.890
For example, videos, there's
a recording hint on Android

00:13:31.890 --> 00:13:34.750
that you can tell the system
the user is about to record.

00:13:34.750 --> 00:13:37.210
There's a lot of optimizations
that you can set.

00:13:37.210 --> 00:13:38.970
But if you don't know
the user's intent,

00:13:38.970 --> 00:13:41.070
if they long press, it's
a video, if they just

00:13:41.070 --> 00:13:44.190
take a picture, a single
tap, you don't know ahead.

00:13:44.190 --> 00:13:47.580
So you can't decide upfront
what configurations are always

00:13:47.580 --> 00:13:48.420
going to work.

00:13:48.420 --> 00:13:50.640
We try to do static
configurations that

00:13:50.640 --> 00:13:52.490
are good in a lot of scenarios.

00:13:52.490 --> 00:13:54.240
And then we have certain
that are dynamic,

00:13:54.240 --> 00:13:58.770
and we update those depending
on what the user's intent is.

00:13:58.770 --> 00:14:01.230
The other part is, for
a long time, Snapchat

00:14:01.230 --> 00:14:04.050
has offered lenses, a lot of
interactive features inside

00:14:04.050 --> 00:14:05.070
of the camera.

00:14:05.070 --> 00:14:07.620
And each of those things
forces certain trade-offs.

00:14:07.620 --> 00:14:11.730
For example, if there's a lot
of motion, your face is moving,

00:14:11.730 --> 00:14:14.580
and you're trying to track
a user's face, optical image

00:14:14.580 --> 00:14:17.317
stabilization-- there's a lot of
things that might not work well

00:14:17.317 --> 00:14:19.650
with these other things that
want to keep track of where

00:14:19.650 --> 00:14:20.970
the user is.

00:14:20.970 --> 00:14:23.160
Also, it has a lot
of memory overhead.

00:14:23.160 --> 00:14:25.090
There's a lot of
GPU work going on.

00:14:25.090 --> 00:14:28.830
And you need to balance
all the work that you do.

00:14:28.830 --> 00:14:31.350
The last part is
you can't cheat.

00:14:31.350 --> 00:14:33.620
You have to capture the
picture in front of the users

00:14:33.620 --> 00:14:36.790
so they can get their message
out as fast as possible.

00:14:36.790 --> 00:14:40.650
Most cameras, if you take a
picture, it hides the latency

00:14:40.650 --> 00:14:41.980
and it saves in the background.

00:14:41.980 --> 00:14:42.813
So you don't see it.

00:14:42.813 --> 00:14:44.310
It just kind of falls away.

00:14:44.310 --> 00:14:46.980
And you don't really see
how long it actually takes.

00:14:46.980 --> 00:14:50.280
But for us-- because the
real meat is when users edit

00:14:50.280 --> 00:14:53.130
the canvas of their
image or their video--

00:14:53.130 --> 00:14:54.900
we have to do it
right there and then.

00:14:54.900 --> 00:14:57.930
And so you have to make certain
trade-offs to have low latency

00:14:57.930 --> 00:14:59.380
to get there.

00:14:59.380 --> 00:15:02.640
Now to support these
and some other features,

00:15:02.640 --> 00:15:05.310
you need to think about how
the overall architecture

00:15:05.310 --> 00:15:07.080
of your app is going
to be if you truly

00:15:07.080 --> 00:15:09.480
want it to be universal.

00:15:09.480 --> 00:15:13.230
So there's a few best
practices that I'll share.

00:15:13.230 --> 00:15:15.810
Some of them really just
help and broaden the width

00:15:15.810 --> 00:15:17.640
of devices that
you're able to target,

00:15:17.640 --> 00:15:20.370
and also how well they
perform on those devices.

00:15:20.370 --> 00:15:21.930
And over time,
you're going to add

00:15:21.930 --> 00:15:23.932
features, lenses, interaction.

00:15:23.932 --> 00:15:26.390
So you want a framework that's
extensible so that you could

00:15:26.390 --> 00:15:29.157
plug and play different things.

00:15:29.157 --> 00:15:30.990
So the first thing you
have to interact with

00:15:30.990 --> 00:15:32.980
is the API that Oscar mentioned.

00:15:32.980 --> 00:15:35.240
It's the part you
interact with the camera.

00:15:35.240 --> 00:15:36.630
And there's a set of APIs.

00:15:36.630 --> 00:15:37.870
There's two versions.

00:15:37.870 --> 00:15:39.570
There's Camera1.

00:15:39.570 --> 00:15:41.400
And it's been around
for many years.

00:15:41.400 --> 00:15:45.030
And then there's also
a Camera2, a newer API.

00:15:45.030 --> 00:15:48.030
Although Camera1
is deprecated, when

00:15:48.030 --> 00:15:50.590
you have hundreds of
millions of users,

00:15:50.590 --> 00:15:53.370
it's a big chunk that's
still on Camera1.

00:15:53.370 --> 00:15:55.050
So you need to
support it, regardless

00:15:55.050 --> 00:15:58.140
of what the device says.

00:15:58.140 --> 00:16:01.080
The second part is there's
different modes for Camera2.

00:16:01.080 --> 00:16:04.410
For OEMs to slowly adapt,
they have a legacy mode,

00:16:04.410 --> 00:16:07.560
which is simply we've
made our API work.

00:16:07.560 --> 00:16:09.900
But under the hood,
it's really Camera1.

00:16:09.900 --> 00:16:11.970
And also, Camera2
varies by device.

00:16:11.970 --> 00:16:15.240
Some devices say, yep,
Camera2 works great here.

00:16:15.240 --> 00:16:18.480
But in reality, deep
down, it's still Camera1.

00:16:18.480 --> 00:16:21.430
And so the performance you get
might vary even across devices.

00:16:21.430 --> 00:16:24.330
So you really need to know
each of the different products

00:16:24.330 --> 00:16:26.460
that you want to target.

00:16:26.460 --> 00:16:28.440
And so what we do
is we support both.

00:16:28.440 --> 00:16:32.940
Since 2016, we've written
both Camera1 and Camera2,

00:16:32.940 --> 00:16:34.230
in terms of code.

00:16:34.230 --> 00:16:37.170
And then what we do is we add
a layer on top that's basically

00:16:37.170 --> 00:16:39.840
what our application
sees to just unify

00:16:39.840 --> 00:16:41.400
what it looks like underneath.

00:16:41.400 --> 00:16:43.360
And then if you have
shared code, for example,

00:16:43.360 --> 00:16:45.300
picking resolution,
it doesn't really

00:16:45.300 --> 00:16:47.040
matter which version
you're using.

00:16:47.040 --> 00:16:49.620
The logic for the full
screen that I mentioned

00:16:49.620 --> 00:16:50.580
can be shared by both.

00:16:50.580 --> 00:16:51.960
So there's some shared code.

00:16:51.960 --> 00:16:54.800
But the application
deals with the top part.

00:16:54.800 --> 00:16:57.320
The next part is there's
millions of devices.

00:16:57.320 --> 00:16:58.820
A lot of them have bugs.

00:16:58.820 --> 00:17:01.050
They say they support
a certain feature.

00:17:01.050 --> 00:17:02.000
It doesn't work.

00:17:02.000 --> 00:17:05.270
You zoom in beyond
99%, some bug comes.

00:17:05.270 --> 00:17:06.950
So we have a lot
of configuration

00:17:06.950 --> 00:17:09.839
that allows us to decide
on specific devices

00:17:09.839 --> 00:17:13.290
and models what behavior,
what configuration, to adopt.

00:17:13.290 --> 00:17:15.530
And so this remote
configuration is really key.

00:17:15.530 --> 00:17:17.119
And over time, you
have to groom it.

00:17:17.119 --> 00:17:18.470
You have to maintain it.

00:17:18.470 --> 00:17:23.520
It's a very key part of
something that's just code.

00:17:23.520 --> 00:17:25.099
Now let's build up
this architecture.

00:17:25.099 --> 00:17:28.339
So I've talked a bit about
the camera interaction,

00:17:28.339 --> 00:17:30.950
the code that talks to
the camera server, which

00:17:30.950 --> 00:17:34.520
is the Android system process
that manages the camera.

00:17:34.520 --> 00:17:36.530
And it talks through
binder IPC, which

00:17:36.530 --> 00:17:39.710
is a form of intraprocess
communication.

00:17:39.710 --> 00:17:42.150
But if you expose this
to your applications,

00:17:42.150 --> 00:17:43.070
it's a little too raw.

00:17:43.070 --> 00:17:46.140
Because you might have a
video chat feature, a camera,

00:17:46.140 --> 00:17:47.200
and video node.

00:17:47.200 --> 00:17:48.950
And if they all try
to talk to the camera,

00:17:48.950 --> 00:17:51.470
they could do things that sort
of conflict with each other.

00:17:51.470 --> 00:17:54.300
There's life cycling, a lot of
things you need to be aware of.

00:17:54.300 --> 00:17:57.890
And so what we do is we
have an operation queue that

00:17:57.890 --> 00:18:00.680
allows us to coalesce
things that are redundant,

00:18:00.680 --> 00:18:03.560
allows us to manage
invalid states.

00:18:03.560 --> 00:18:05.810
And so we avoid a lot
of conflicting things

00:18:05.810 --> 00:18:08.810
across features by having an
operation queue and a thread

00:18:08.810 --> 00:18:10.610
that processes them.

00:18:10.610 --> 00:18:12.980
And the next part
is-- so everything

00:18:12.980 --> 00:18:18.200
on your right, the gray
side, is really about the UI.

00:18:18.200 --> 00:18:22.160
The shutter button you see,
the autofocus, the animations,

00:18:22.160 --> 00:18:22.821
all that.

00:18:22.821 --> 00:18:24.570
And then it has a state
machine that says,

00:18:24.570 --> 00:18:26.720
OK, the user tapped autofocus.

00:18:26.720 --> 00:18:27.770
Let's do the animation.

00:18:27.770 --> 00:18:30.260
Let's ask the
camera to autofocus.

00:18:30.260 --> 00:18:32.480
And then it saves
your intent in memory

00:18:32.480 --> 00:18:34.940
and tries to drive the
asynchronous process

00:18:34.940 --> 00:18:36.030
to get it done.

00:18:36.030 --> 00:18:38.071
And so the right-hand side
and the left-hand side

00:18:38.071 --> 00:18:39.860
have different responsibilities.

00:18:39.860 --> 00:18:41.960
And then over time,
your surface comes in.

00:18:41.960 --> 00:18:44.530
That's the preview frames
that Oscar was saying.

00:18:44.530 --> 00:18:46.620
It starts showing
up on your screen.

00:18:46.620 --> 00:18:48.360
If you have interactive
features enabled,

00:18:48.360 --> 00:18:51.480
like lenses, they get
composited on top of it.

00:18:51.480 --> 00:18:53.360
And this is done in OpenGL.

00:18:53.360 --> 00:18:55.130
And we try to do it
synchronously and not

00:18:55.130 --> 00:18:57.560
avoid copying anything large.

00:18:57.560 --> 00:19:00.440
And then ultimately, your
UI is composited on top.

00:19:00.440 --> 00:19:02.330
And so, as far as the
user is concerned,

00:19:02.330 --> 00:19:03.680
it all looks integrated.

00:19:03.680 --> 00:19:05.360
But in reality,
it's multiple layers

00:19:05.360 --> 00:19:06.900
that are coming together.

00:19:06.900 --> 00:19:09.200
Now, if you look at this
architecture, what you notice

00:19:09.200 --> 00:19:12.200
is that the left and the
right have different things

00:19:12.200 --> 00:19:14.210
that you're concerned about.

00:19:14.210 --> 00:19:17.720
And one way to think about it
is client server architecture.

00:19:17.720 --> 00:19:20.060
The right-hand side
is like the client.

00:19:20.060 --> 00:19:23.949
The left-hand side is your
runtime, your processing.

00:19:23.949 --> 00:19:25.240
And the concerns are different.

00:19:25.240 --> 00:19:27.530
So from a performance
perspective,

00:19:27.530 --> 00:19:31.010
the left-hand side needs to
worry about processing frames

00:19:31.010 --> 00:19:32.070
really fast.

00:19:32.070 --> 00:19:34.760
It needs to worry about
stability, a lot of things.

00:19:34.760 --> 00:19:38.210
And the right-hand side is
really about animations,

00:19:38.210 --> 00:19:40.970
new features, a
lot of the candy,

00:19:40.970 --> 00:19:43.580
in terms of how the user
interacts with the camera.

00:19:43.580 --> 00:19:45.770
And so one cool
thing you can do is,

00:19:45.770 --> 00:19:47.930
if you ever work
with client server,

00:19:47.930 --> 00:19:49.577
sometimes a server is slow.

00:19:49.577 --> 00:19:51.410
It takes hundreds of
milliseconds, sometimes

00:19:51.410 --> 00:19:52.350
some issues.

00:19:52.350 --> 00:19:55.970
So what we do is we have
ways of replacing components.

00:19:55.970 --> 00:19:56.890
You can use Dagger.

00:19:56.890 --> 00:19:58.556
You have other
approaches where you say,

00:19:58.556 --> 00:20:00.710
OK, let's just
abstract out the camera

00:20:00.710 --> 00:20:04.010
so that the UI thinks it's
talking to the real thing.

00:20:04.010 --> 00:20:06.830
And we'll just mock the
APIs to the Android system

00:20:06.830 --> 00:20:09.860
and maybe do a no op, or
send black frames-- whatever

00:20:09.860 --> 00:20:10.970
we want to do.

00:20:10.970 --> 00:20:13.250
And one place where we
take advantage of this

00:20:13.250 --> 00:20:15.210
is performance testing.

00:20:15.210 --> 00:20:18.530
So for example, if
you add new UI logic

00:20:18.530 --> 00:20:20.030
and you want to
see if it regresses

00:20:20.030 --> 00:20:22.250
the camera in any way,
you don't care how long

00:20:22.250 --> 00:20:24.020
the camera operations take.

00:20:24.020 --> 00:20:26.180
And because they're
variable-- if, let's say,

00:20:26.180 --> 00:20:29.120
it takes 100 milliseconds
to open the camera,

00:20:29.120 --> 00:20:32.810
and it's variable because
it's a system service--

00:20:32.810 --> 00:20:34.520
then, over time,
you might not be

00:20:34.520 --> 00:20:36.800
able to catch
10-millisecond regressions.

00:20:36.800 --> 00:20:38.720
And so in this example
here, what I'm showing

00:20:38.720 --> 00:20:41.810
is a startup regression
test with a mock camera.

00:20:41.810 --> 00:20:43.280
So the camera has
been mocked out.

00:20:43.280 --> 00:20:45.530
It's starting the app
repeatedly and saying,

00:20:45.530 --> 00:20:48.530
OK, let's collect the metrics
and see how long it's taking

00:20:48.530 --> 00:20:50.000
to get to a stable point.

00:20:50.000 --> 00:20:51.860
And then we can actually
catch regressions

00:20:51.860 --> 00:20:54.230
across several
commits to see what

00:20:54.230 --> 00:20:56.460
change might have caused it.

00:20:56.460 --> 00:20:59.390
Another example is, instead
of replacing the whole camera,

00:20:59.390 --> 00:21:00.590
you can replace part of it.

00:21:00.590 --> 00:21:03.207
You could say, the frames
that are coming out,

00:21:03.207 --> 00:21:05.540
let's just replace them with
something else, rather than

00:21:05.540 --> 00:21:06.248
the whole camera.

00:21:06.248 --> 00:21:08.200
You could keep other
functionality intact.

00:21:08.200 --> 00:21:11.330
And so in this case here,
we could replace the frames

00:21:11.330 --> 00:21:12.750
with a video file.

00:21:12.750 --> 00:21:16.430
And so this is very useful in
situations where, let's say,

00:21:16.430 --> 00:21:20.270
you're automatically
testing your face tracking.

00:21:20.270 --> 00:21:23.150
In the lab environment where
you run integration tests,

00:21:23.150 --> 00:21:23.870
there's no faces.

00:21:23.870 --> 00:21:26.270
There's no people in the
lab to look at the camera.

00:21:26.270 --> 00:21:29.480
And so what we do is we
actually use the video files

00:21:29.480 --> 00:21:30.680
to drive that interaction.

00:21:30.680 --> 00:21:33.020
So here's a picture of
me running some lenses

00:21:33.020 --> 00:21:35.330
testing where the frames
have been mocked out

00:21:35.330 --> 00:21:36.530
from a video file.

00:21:36.530 --> 00:21:38.090
And so there's me.

00:21:38.090 --> 00:21:40.304
Hello, I/O.

00:21:40.304 --> 00:21:41.720
And you can see
the paper showing.

00:21:41.720 --> 00:21:42.740
It's not the camera.

00:21:42.740 --> 00:21:44.120
It's just the video.

00:21:44.120 --> 00:21:45.350
But everything else is real.

00:21:45.350 --> 00:21:46.850
It took a snap.

00:21:46.850 --> 00:21:47.560
It edits it.

00:21:47.560 --> 00:21:48.560
It does a lot of things.

00:21:48.560 --> 00:21:50.900
So you can mock out
parts of the camera

00:21:50.900 --> 00:21:53.030
to allow you to add
new features and just

00:21:53.030 --> 00:21:55.680
test things in isolation.

00:21:55.680 --> 00:21:56.900
And so this is--

00:21:56.900 --> 00:21:59.080
in terms of an architecture,
it's one way to do it.

00:21:59.080 --> 00:21:59.960
There's many ways.

00:21:59.960 --> 00:22:02.001
But this gives you the
performance considerations

00:22:02.001 --> 00:22:03.890
on the left, the
remote configuration

00:22:03.890 --> 00:22:06.780
to get a wide range
of devices supported,

00:22:06.780 --> 00:22:10.400
to have different
cameras, multiple cameras,

00:22:10.400 --> 00:22:12.410
front-facing, rear.

00:22:12.410 --> 00:22:14.990
And so the remote configurations
for that, the performance

00:22:14.990 --> 00:22:17.850
considerations in the UI
and the extensibility.

00:22:17.850 --> 00:22:21.212
Now let's jump into
a specific use case.

00:22:21.212 --> 00:22:21.920
Snapchat's known.

00:22:21.920 --> 00:22:24.920
The majority of our
media is just images.

00:22:24.920 --> 00:22:27.650
And everyone always asks,
how do you guys take photos?

00:22:27.650 --> 00:22:29.270
How does it all work?

00:22:29.270 --> 00:22:31.380
And we break it up
into several stages.

00:22:31.380 --> 00:22:35.780
The first stage is capturing,
quickly capturing the content

00:22:35.780 --> 00:22:37.790
so that you can actually
process and allow

00:22:37.790 --> 00:22:39.470
the user to be creative.

00:22:39.470 --> 00:22:41.300
Once they add all
their creatives,

00:22:41.300 --> 00:22:44.420
you composite all of the
different layers of creativity

00:22:44.420 --> 00:22:46.190
that they've done
and you transcode it

00:22:46.190 --> 00:22:49.040
into something that is
efficient to transport over

00:22:49.040 --> 00:22:50.840
the network to the recipient.

00:22:50.840 --> 00:22:52.620
And the last part is rendering.

00:22:52.620 --> 00:22:55.460
That's the part where the
recipient looks at the content.

00:22:55.460 --> 00:22:57.034
And depending on
the choices you make

00:22:57.034 --> 00:22:59.450
in your player can really
affect the quality of the images

00:22:59.450 --> 00:23:00.620
that they see.

00:23:00.620 --> 00:23:02.780
And all of these are
complicated things.

00:23:02.780 --> 00:23:04.820
And we have teams
dedicated to each one.

00:23:04.820 --> 00:23:08.630
But I'll just touch on the
capturing one for today.

00:23:08.630 --> 00:23:11.720
Now, Oscar mentioned you
tell the camera, hey, capture

00:23:11.720 --> 00:23:12.260
a frame.

00:23:12.260 --> 00:23:13.160
And you wait back.

00:23:13.160 --> 00:23:14.660
And your callback is called.

00:23:14.660 --> 00:23:18.260
But there's a lot of latency
involved in this step.

00:23:18.260 --> 00:23:21.560
In Camera1, the API is
called Take Picture.

00:23:21.560 --> 00:23:24.470
And it takes 400 milliseconds
on a really high-end phone

00:23:24.470 --> 00:23:25.565
from last year.

00:23:25.565 --> 00:23:27.440
Whereas, if you take
the preview frame that's

00:23:27.440 --> 00:23:31.440
optimized for low latency, it's
an order of magnitude smaller.

00:23:31.440 --> 00:23:33.730
And you can see the
P90s are quite high.

00:23:33.730 --> 00:23:36.020
And so what we do is,
periodically, we'll

00:23:36.020 --> 00:23:39.890
optimize, as much as we can,
our code for specific devices

00:23:39.890 --> 00:23:42.440
that we feel are
pretty good latency.

00:23:42.440 --> 00:23:45.590
And we enable it remotely
for users on those devices.

00:23:45.590 --> 00:23:47.270
And users are delighted.

00:23:47.270 --> 00:23:49.065
Wow, the quality went up.

00:23:49.065 --> 00:23:49.940
It looks really cool.

00:23:49.940 --> 00:23:51.080
It just happened today.

00:23:51.080 --> 00:23:52.910
People notice it right away.

00:23:52.910 --> 00:23:55.820
But also, they notice the delay.

00:23:55.820 --> 00:23:57.590
And if you're trying
to communicate

00:23:57.590 --> 00:23:59.300
and there's any
lag, or anything,

00:23:59.300 --> 00:24:02.004
you'll notice it right away.

00:24:02.004 --> 00:24:03.920
And so what we do is we
try to do a trade-off.

00:24:03.920 --> 00:24:04.580
We do both.

00:24:04.580 --> 00:24:07.366
We'll take picture and
screenshot in certain devices.

00:24:07.366 --> 00:24:09.740
And if it takes too long, we
fall back to the screenshot.

00:24:09.740 --> 00:24:13.170
So we have a lot of tricks
to work around this.

00:24:13.170 --> 00:24:16.070
You can see examples here where
the quality, when you really

00:24:16.070 --> 00:24:17.840
zoom in, is noticeable.

00:24:17.840 --> 00:24:20.000
But it's not always a slam dunk.

00:24:20.000 --> 00:24:23.960
In this case here, Take Picture
on the left is causing noise.

00:24:23.960 --> 00:24:26.390
And sometimes the algorithms
might overcompensate,

00:24:26.390 --> 00:24:27.590
and you'll see speckling.

00:24:27.590 --> 00:24:29.810
So it's not always
just turn it on.

00:24:29.810 --> 00:24:32.540
Certain front-facing
cameras, we disable it,

00:24:32.540 --> 00:24:34.700
even though it can
sometimes result

00:24:34.700 --> 00:24:37.100
in higher quality, especially
in low-light conditions.

00:24:37.100 --> 00:24:39.620
So we balance that.

00:24:39.620 --> 00:24:42.740
And so, really, it's a
hierarchy of trade-offs.

00:24:42.740 --> 00:24:44.730
Oscar talked about
the low level.

00:24:44.730 --> 00:24:46.910
You've got the design
choices of what

00:24:46.910 --> 00:24:49.760
you've decided in your
application and, ultimately,

00:24:49.760 --> 00:24:50.510
user intent.

00:24:50.510 --> 00:24:53.900
Is the user sending a picture
to someone that's disappearing

00:24:53.900 --> 00:24:56.000
and you want to favor
latency, versus is

00:24:56.000 --> 00:24:57.350
the user preserving something?

00:24:57.350 --> 00:24:59.510
So hopefully, some of
the tips we've shared

00:24:59.510 --> 00:25:01.700
will help you guys build
a better Camera app.

00:25:01.700 --> 00:25:02.486
Thank you.

00:25:02.486 --> 00:25:05.888
[APPLAUSE]

00:25:10.270 --> 00:25:11.500
VINIT MODI: Thanks, Mustafa.

00:25:11.500 --> 00:25:12.470
Hi, everyone.

00:25:12.470 --> 00:25:13.950
My name is Vinit Modi.

00:25:13.950 --> 00:25:16.870
I'm the Android
Camera Platform PM.

00:25:16.870 --> 00:25:19.240
Oscar, earlier,
identified a series

00:25:19.240 --> 00:25:22.420
of trade-offs required
to use the Camera2 APIs.

00:25:22.420 --> 00:25:25.480
Mustafa further
elaborated on that theme

00:25:25.480 --> 00:25:27.460
on how they applied
those trade-offs

00:25:27.460 --> 00:25:29.710
in the real-world situations.

00:25:29.710 --> 00:25:31.760
I'm going to change
the conversation a bit

00:25:31.760 --> 00:25:33.820
and talk about how,
working together,

00:25:33.820 --> 00:25:37.510
we can truly elevate both the
developer and the end user

00:25:37.510 --> 00:25:40.120
experience.

00:25:40.120 --> 00:25:42.760
The camera is evolving today.

00:25:42.760 --> 00:25:45.400
It's moved on from
mere photography

00:25:45.400 --> 00:25:47.560
as an immersive medium.

00:25:47.560 --> 00:25:50.470
A great example of this
is what was demonstrated

00:25:50.470 --> 00:25:53.440
in the keynote by [? Parna, ?]
where the camera is now

00:25:53.440 --> 00:25:57.100
used to do geonavigation.

00:25:57.100 --> 00:26:00.160
In addition, cameras
are everywhere today,

00:26:00.160 --> 00:26:01.690
from IoT devices--

00:26:01.690 --> 00:26:04.210
there's a great example in
the Android Things booth--

00:26:04.210 --> 00:26:09.250
to your laptops, to
multiple cameras on devices.

00:26:09.250 --> 00:26:13.960
And that's a trend that I
want you all to take away.

00:26:13.960 --> 00:26:19.090
Devices with more than two
cameras are becoming the norm.

00:26:19.090 --> 00:26:22.030
Recall the Camera
Model that Oscar talked

00:26:22.030 --> 00:26:23.920
about earlier in the talk.

00:26:23.920 --> 00:26:29.560
How do you extend that model
in a multi-camera situation?

00:26:29.560 --> 00:26:31.490
Let's walk through an example.

00:26:31.490 --> 00:26:34.960
Imagine a device with
three back cameras.

00:26:34.960 --> 00:26:37.930
The native Camera
app today has access

00:26:37.930 --> 00:26:41.710
to the physical streams
from each of these sensors.

00:26:41.710 --> 00:26:44.140
In addition, the
native Camera app

00:26:44.140 --> 00:26:46.810
has something called
the Logical Camera.

00:26:46.810 --> 00:26:48.370
This is a virtual camera.

00:26:48.370 --> 00:26:51.280
It's made up of all
the physical sensors.

00:26:51.280 --> 00:26:53.830
It is a combined fused stream.

00:26:53.830 --> 00:26:56.320
And it takes care of
some of the trade-offs

00:26:56.320 --> 00:26:58.510
that Oscar and
Mustafa alluded to,

00:26:58.510 --> 00:27:02.600
in terms of power,
performance, and latency.

00:27:02.600 --> 00:27:05.410
So in the native Camera
app, you actually

00:27:05.410 --> 00:27:10.180
have four cameras, one
virtual, three physical,

00:27:10.180 --> 00:27:12.320
in a three-camera device.

00:27:12.320 --> 00:27:16.670
But as developers, you only
get access to one of them.

00:27:16.670 --> 00:27:20.200
This often depends on the
different types of devices.

00:27:20.200 --> 00:27:23.440
And in this case, you
end up making trade-offs.

00:27:23.440 --> 00:27:26.650
You're using the
APIs differently

00:27:26.650 --> 00:27:28.900
from the native Camera app.

00:27:28.900 --> 00:27:32.230
So we're pleased to announce
that, starting with Android P,

00:27:32.230 --> 00:27:34.870
you'll get access
to all the cameras,

00:27:34.870 --> 00:27:38.500
from the Logical Camera to
all the physical streams.

00:27:38.500 --> 00:27:43.139
This applies to both the front
and back sensors, as well as

00:27:43.139 --> 00:27:44.305
many different form factors.

00:27:47.750 --> 00:27:49.720
Here's some example use cases.

00:27:49.720 --> 00:27:52.090
The lady in the picture--

00:27:52.090 --> 00:27:53.950
this is an image
of a bokeh mode.

00:27:53.950 --> 00:27:56.590
You can use this
new Multi-Camera API

00:27:56.590 --> 00:27:59.380
for depth, optical
vision, getting

00:27:59.380 --> 00:28:02.650
monochrome frames directly
from the sensor, and many more.

00:28:02.650 --> 00:28:05.470
But most of all, we're
excited of the use cases

00:28:05.470 --> 00:28:08.330
that you guys are
going to build.

00:28:08.330 --> 00:28:11.290
So let's walk through
this API real quick.

00:28:11.290 --> 00:28:13.390
The first thing you would
do is check the camera

00:28:13.390 --> 00:28:15.910
characteristics and check
if the device supports

00:28:15.910 --> 00:28:18.760
the logical Multi-Camera API.

00:28:18.760 --> 00:28:23.020
Next, you would check to see
which physical cameras make up

00:28:23.020 --> 00:28:24.910
this logical device.

00:28:24.910 --> 00:28:28.330
Today, we start support
for RGB and monochrome.

00:28:28.330 --> 00:28:30.480
And we're looking to add more.

00:28:30.480 --> 00:28:32.800
Here, it gets very
interesting when

00:28:32.800 --> 00:28:35.170
you have a logical camera
that is abstracting

00:28:35.170 --> 00:28:38.560
one front and one back sensor.

00:28:38.560 --> 00:28:41.770
Finally, you would check to
see if the frames from all

00:28:41.770 --> 00:28:44.800
of these sensors
are synchronized.

00:28:44.800 --> 00:28:46.150
So I know what you're thinking.

00:28:46.150 --> 00:28:47.920
Great, new API.

00:28:47.920 --> 00:28:49.540
Which devices will support it?

00:28:49.540 --> 00:28:54.070
Is it worth your time to
invest in this new API?

00:28:54.070 --> 00:28:55.510
The answer is yes.

00:28:55.510 --> 00:28:58.750
Starting with Android
P, all new devices

00:28:58.750 --> 00:29:00.640
will support this new API.

00:29:00.640 --> 00:29:02.740
And we're working
with many partners

00:29:02.740 --> 00:29:07.390
to ensure that upgrade
devices also support this API.

00:29:07.390 --> 00:29:09.340
So let me call out
a few partners.

00:29:09.340 --> 00:29:11.260
We worked very
closely with Huawei

00:29:11.260 --> 00:29:14.650
to ensure that monochrome
sensors are supported.

00:29:14.650 --> 00:29:18.190
They actually helped
us test this API.

00:29:18.190 --> 00:29:20.830
We worked with Xiaomi to
ensure that a majority

00:29:20.830 --> 00:29:24.080
of their devices support
this API, as well.

00:29:24.080 --> 00:29:25.810
So later this year,
you'll see devices

00:29:25.810 --> 00:29:28.000
from both Huawei and
Xiaomi supporting

00:29:28.000 --> 00:29:32.630
this new Multi-Camera API
on upgraded new devices.

00:29:32.630 --> 00:29:34.460
And finally, the Android1 team.

00:29:34.460 --> 00:29:36.430
We worked with
manufacturers from this team

00:29:36.430 --> 00:29:41.320
to ensure that this API works
across all tiers of Android,

00:29:41.320 --> 00:29:46.090
and is not exclusive
to just the high tier.

00:29:46.090 --> 00:29:49.570
I want to share that,
together, we really can

00:29:49.570 --> 00:29:51.520
elevate the camera experience.

00:29:51.520 --> 00:29:54.950
Working with you, our
partners, our manufacturers,

00:29:54.950 --> 00:29:57.070
we're really trying
to make sure that we

00:29:57.070 --> 00:29:59.680
can bring amazing experiences.

00:29:59.680 --> 00:30:02.530
And most of all, we're
very excited to see

00:30:02.530 --> 00:30:05.590
what you're going to
build with these new APIs,

00:30:05.590 --> 00:30:10.480
knowing what trade-offs you
need to make using these APIs.

00:30:10.480 --> 00:30:12.770
We'd love to continue the
conversation in the after

00:30:12.770 --> 00:30:14.320
session meeting space.

00:30:14.320 --> 00:30:16.480
And thank you,
Oscar and Mustafa,

00:30:16.480 --> 00:30:18.200
for sharing their insights.

00:30:18.200 --> 00:30:19.810
Thank you, Snap,
for giving a glimpse

00:30:19.810 --> 00:30:23.152
on how millions of users
get a delightful experience.

00:30:23.152 --> 00:30:24.610
Thank you, everyone,
for attending.

00:30:24.610 --> 00:30:25.750
Enjoy I/O.

00:30:25.750 --> 00:30:27.694
[APPLAUSE]

00:30:27.694 --> 00:30:33.318
[MUSIC PLAYING]

