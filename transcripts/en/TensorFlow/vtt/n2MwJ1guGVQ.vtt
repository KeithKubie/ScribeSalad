WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.425
[MUSIC PLAYING]

00:00:07.352 --> 00:00:08.560
JON MALMAUD: Hello, everyone.

00:00:08.560 --> 00:00:10.320
My name's Jon, and
I'll be talking today

00:00:10.320 --> 00:00:13.680
about TensorFlow.jl, an
interface between Julia

00:00:13.680 --> 00:00:15.730
and TensorFlow.

00:00:15.730 --> 00:00:16.597
So what is Julia?

00:00:16.597 --> 00:00:18.430
Some of you have probably
never heard of it.

00:00:18.430 --> 00:00:21.250
It's a really dynamic yet
performant programming language

00:00:21.250 --> 00:00:24.080
developed at MIT since
around 10 years ago.

00:00:24.080 --> 00:00:26.560
It's a fresh rethinking of
what a scientific programming

00:00:26.560 --> 00:00:27.970
language can be like.

00:00:27.970 --> 00:00:30.580
And version 1.0 was
finally realized last year

00:00:30.580 --> 00:00:33.568
to this cheering
audience from JuliaCon.

00:00:33.568 --> 00:00:35.610
So I'm going to give you
a whirlwind tour of what

00:00:35.610 --> 00:00:39.100
Julia is and then talk to
you about TensorFlow.jl.

00:00:39.100 --> 00:00:40.740
So here's a very
simple Julia program.

00:00:40.740 --> 00:00:42.750
I think anyone with
a Python background

00:00:42.750 --> 00:00:45.750
can guess what this is doing,
except this @show business,

00:00:45.750 --> 00:00:48.570
but that's actually a macro.

00:00:48.570 --> 00:00:49.760
And what is Jon?

00:00:49.760 --> 00:00:51.150
I'm finishing my PhD at MIT.

00:00:51.150 --> 00:00:54.120
I do machine learning
by day and open source

00:00:54.120 --> 00:00:56.040
software by night
and sometimes by day,

00:00:56.040 --> 00:00:59.040
too, to the chagrin
of my advisor.

00:00:59.040 --> 00:01:00.750
So why consider Julia?

00:01:00.750 --> 00:01:02.970
For one thing, it's got
an ultrafast just-in-time

00:01:02.970 --> 00:01:03.930
compiler.

00:01:03.930 --> 00:01:07.260
So here I'm running an
autoregressive process

00:01:07.260 --> 00:01:09.510
using for loops, which I
think is the most natural way

00:01:09.510 --> 00:01:10.860
to express them.

00:01:10.860 --> 00:01:13.920
And why don't we just run that
for 100 million iterations

00:01:13.920 --> 00:01:15.300
in Julia and Python.

00:01:15.300 --> 00:01:19.200
And you can see the syntax looks
pretty similar between them.

00:01:19.200 --> 00:01:21.650
Well, Python takes
about 13 seconds.

00:01:21.650 --> 00:01:23.870
C takes about 0.9 seconds.

00:01:23.870 --> 00:01:26.720
Julia takes about 0.95 seconds.

00:01:26.720 --> 00:01:28.380
Not bad.

00:01:28.380 --> 00:01:29.970
And you have powerful
metaprogramming.

00:01:29.970 --> 00:01:32.340
So anyone from a LISP
background will appreciate this.

00:01:32.340 --> 00:01:34.920
You can write a macro that
takes in Julius syntax

00:01:34.920 --> 00:01:36.820
and outputs Julia syntax.

00:01:36.820 --> 00:01:38.910
So here's just a
trivial toy macro

00:01:38.910 --> 00:01:40.620
that checks if a number
is less than zero

00:01:40.620 --> 00:01:41.855
and prints out a warning.

00:01:41.855 --> 00:01:43.230
And note that
since it's a macro,

00:01:43.230 --> 00:01:44.970
it can print out the
name of the variable

00:01:44.970 --> 00:01:47.040
and change the
variable in place.

00:01:47.040 --> 00:01:50.310
You can't really do that with
a normal Python function.

00:01:50.310 --> 00:01:52.890
And there's this really nice
multiple dispatch system

00:01:52.890 --> 00:01:55.560
where you can define multiple
versions of a function,

00:01:55.560 --> 00:01:56.970
and the one that's
called depends

00:01:56.970 --> 00:01:59.980
on the types of all the
arguments at runtime.

00:01:59.980 --> 00:02:02.460
So here's a really cool
rock-paper-scissor example

00:02:02.460 --> 00:02:04.460
that someone from the
community created.

00:02:04.460 --> 00:02:07.260
And what's nice is I can
say that for any shape,

00:02:07.260 --> 00:02:12.960
if shape A beats shape B,
then shape B loses to shape A.

00:02:12.960 --> 00:02:17.780
And I can encode that
information with one line.

00:02:17.780 --> 00:02:19.300
And Julia's growing fast.

00:02:19.300 --> 00:02:22.230
We've about doubled in GitHub
stars in the last year alone.

00:02:22.230 --> 00:02:24.637
We're probably above 20,000 now.

00:02:24.637 --> 00:02:26.220
Things have really
started to take off

00:02:26.220 --> 00:02:28.620
since 1.0 was finalized.

00:02:28.620 --> 00:02:30.060
And now TensorFlow.jl.

00:02:30.060 --> 00:02:32.130
So here's a quick
glimpse of its syntax.

00:02:32.130 --> 00:02:36.390
It's clearly inspired by Keras
and the whole Tensor 2.0 world.

00:02:36.390 --> 00:02:39.660
We're now eager by default,
but graph mode is available.

00:02:39.660 --> 00:02:42.610
If you choose to use graph
mode, macros will help you out.

00:02:42.610 --> 00:02:45.660
So here a macro is transforming
native Julia, the control flow,

00:02:45.660 --> 00:02:49.230
with this while loop into
a graph mode while loop.

00:02:49.230 --> 00:02:51.200
And macros can do other
nice things for you.

00:02:51.200 --> 00:02:54.548
Here we're visualizing a
program with TensorBoard.

00:02:54.548 --> 00:02:56.090
And note that the
labels on the nodes

00:02:56.090 --> 00:02:58.850
are automatically inferred
from the variable names, which

00:02:58.850 --> 00:03:00.580
is what macros enable.

00:03:00.580 --> 00:03:02.190
Macros can do other cool things.

00:03:02.190 --> 00:03:05.120
So Francois of Keras fame
posted this really nice example

00:03:05.120 --> 00:03:08.455
of implementing
a model in Keras.

00:03:08.455 --> 00:03:09.830
But someone replied
to the tweet,

00:03:09.830 --> 00:03:12.140
being this is really pretty,
except why are there all these

00:03:12.140 --> 00:03:12.740
x's?

00:03:12.740 --> 00:03:14.180
I wish we could eliminate those.

00:03:14.180 --> 00:03:15.890
And I've highlighted
those in red.

00:03:15.890 --> 00:03:18.530
And luckily, there's a Julia
macro that will automatically

00:03:18.530 --> 00:03:20.370
thread a variable
through a program,

00:03:20.370 --> 00:03:23.850
and so we don't need
those x's in Julia.

00:03:23.850 --> 00:03:25.590
I think that's pretty elegant.

00:03:25.590 --> 00:03:28.960
And you can benefit from
really fast preprocessing.

00:03:28.960 --> 00:03:31.110
So if I want to
tokenize my corpus,

00:03:31.110 --> 00:03:33.060
maybe it's got 100
million tokens,

00:03:33.060 --> 00:03:35.310
and I have a custom
tokenization scheme,

00:03:35.310 --> 00:03:37.000
I can just write
that as a for loop,

00:03:37.000 --> 00:03:39.510
and I can trust Julia's
just-in-time compiler

00:03:39.510 --> 00:03:40.523
to do the right thing.

00:03:40.523 --> 00:03:41.940
You don't want to
write a for loop

00:03:41.940 --> 00:03:45.030
in Python that goes over
100 million elements.

00:03:45.030 --> 00:03:46.140
You can try.

00:03:46.140 --> 00:03:48.960
If you're worried about
leaving Python, don't be.

00:03:48.960 --> 00:03:51.270
We have lots of good
scientific computing languages

00:03:51.270 --> 00:03:52.690
right in Julia.

00:03:52.690 --> 00:03:55.140
If you need to use Python,
we have a very good Python

00:03:55.140 --> 00:03:56.040
interface.

00:03:56.040 --> 00:03:59.010
So here's an example
of calling into ScyPi.

00:03:59.010 --> 00:04:01.397
If I didn't tell you those
last two lines were Julia,

00:04:01.397 --> 00:04:03.480
you'd probably think you
were just writing Python.

00:04:03.480 --> 00:04:04.930
It's very simple.

00:04:04.930 --> 00:04:07.650
And we're compatible with the
whole TensorFlow ecosystem.

00:04:07.650 --> 00:04:09.490
TensorBoard works.

00:04:09.490 --> 00:04:11.790
Note again that the label
on the TensorBoard graph

00:04:11.790 --> 00:04:14.310
is automatically inferred
from the variable.

00:04:14.310 --> 00:04:16.800
You can save graphs
in Julia, load them

00:04:16.800 --> 00:04:18.180
in Python, and vice versa.

00:04:18.180 --> 00:04:20.740
And soon you could do that
for save models as well.

00:04:20.740 --> 00:04:22.980
So if some of your
collaborators are using Python,

00:04:22.980 --> 00:04:24.960
don't think you have
to switch to Julia.

00:04:24.960 --> 00:04:26.760
You can use Julia
yourself and still

00:04:26.760 --> 00:04:28.870
work with your Python friends.

00:04:28.870 --> 00:04:30.900
And someday they
might use Julia.

00:04:30.900 --> 00:04:32.730
If you want to define
a custom operation

00:04:32.730 --> 00:04:35.310
and use Julia's just-in-time
compiler to make it fast,

00:04:35.310 --> 00:04:36.240
you can do that.

00:04:36.240 --> 00:04:38.070
Maybe you want to
write a ray tracer.

00:04:38.070 --> 00:04:40.462
You can use Julia's
really easy C form

00:04:40.462 --> 00:04:42.420
and function interface,
if that's a part of it,

00:04:42.420 --> 00:04:44.590
and define a gradient in that.

00:04:44.590 --> 00:04:45.840
And just a little case study.

00:04:45.840 --> 00:04:49.020
You can even use Julia's
differential equations package,

00:04:49.020 --> 00:04:51.990
and that all just works because
of Julia's multiple dispatch.

00:04:51.990 --> 00:04:53.970
So if you wanted to
do a [INAUDIBLE],,

00:04:53.970 --> 00:04:55.970
like you might have seen
at [INAUDIBLE],, that's

00:04:55.970 --> 00:04:57.060
very simple.

00:04:57.060 --> 00:05:01.110
All right, so we still want
to do a lot more Keras.

00:05:01.110 --> 00:05:02.543
We need your help.

00:05:02.543 --> 00:05:04.710
Come check out our GitHub,
come join our Slack chat,

00:05:04.710 --> 00:05:06.585
and download Julia today.

00:05:06.585 --> 00:05:08.460
So I just want to thank
all my collaborators,

00:05:08.460 --> 00:05:12.440
especially Lyndon,
who's in the audience,

00:05:12.440 --> 00:05:14.330
and everyone in the
TensorFlow world.

00:05:14.330 --> 00:05:16.010
And I want to thank you.

00:05:16.010 --> 00:05:17.210
[APPLAUSE]

00:05:17.210 --> 00:05:19.360
[MUSIC PLAYING]

