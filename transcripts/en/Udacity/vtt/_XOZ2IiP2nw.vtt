WEBVTT
Kind: captions
Language: en

00:00:00.269 --> 00:00:02.937
More interesting from the GPU context is a merge sort.

00:00:02.937 --> 00:00:06.746
And it's really interesting to discuss how to map this efficiently to a GPU

00:00:06.746 --> 00:00:10.681
because it's a great instance of a divide-and-conquer approach to the problem.

00:00:10.681 --> 00:00:16.186
So here's a tree that represents our merge sort, and what's particularly interesting about mapping this to a GPU

00:00:16.186 --> 00:00:20.563
is that the problem starts off with tons of little tiny parallel problems,

00:00:20.563 --> 00:00:27.246
and then as the algorithm proceeds, we eventually end up with only 1 very large problem to solve,

00:00:27.246 --> 00:00:31.198
and that's the final merge. This is more challenging many of the algorithms we've discussed,

00:00:31.198 --> 00:00:35.305
where we have the luxury of being able to solve lots of little parallel problems

00:00:35.305 --> 00:00:37.841
independently throughout the whole computation.

00:00:37.841 --> 00:00:40.678
So what we do at each stage of this tree is the same.

00:00:40.678 --> 00:00:46.498
The only operation that we need is merging 2 sorted lists together into 1 sorted list.

00:00:46.498 --> 00:00:51.855
We begin with n items, which we treat as n sorted 1-element lists,

00:00:51.855 --> 00:00:57.791
then we run n over 2 merges to create n over 2, sorted 2-element lists.

00:00:57.791 --> 00:01:04.031
Then we run n over 4 merges to create n over 4, sorted 4-element lists, and so on.

00:01:04.031 --> 00:01:09.668
Overall this is log n stages, and in each stage we merge a total of n elements,

00:01:09.668 --> 00:01:14.975
so the overall number of operations that were complexity is order of n log n.

00:01:14.975 --> 00:01:20.083
This algorithmic exposes a lot of parallelism within each step, each individual merge:

00:01:20.083 --> 00:01:24.854
this merge, this merge, this merge, this merge, and so on can proceed in parallel.

00:01:24.854 --> 00:01:28.828
Now the hard part about mapping this to the GPU is that the number

00:01:28.828 --> 00:01:34.429
and size of merge as we do on each step differs greatly between the first step and the last.

00:01:34.429 --> 00:01:39.408
So I'm going to talk about a GPU implementation that has 3 stages.

00:01:39.408 --> 00:01:47.042
The first stage, this blue stage here, is merging a very large number of very short sequences.

00:01:48.944 --> 00:01:50.847
Because we have many, many tasks and each is very small,

00:01:50.847 --> 00:01:53.983
we might choose to assign 1 merge to 1 thread,

00:01:53.983 --> 00:01:58.422
which can perform each individual merge using a serial algorithm on that thread.

00:01:58.422 --> 00:02:03.279
We might get better memory coalescing performance if we use shared memories as staging area to read many

00:02:03.279 --> 00:02:06.393
input elements or store many output elements at the same time.

00:02:06.393 --> 00:02:09.452
I'd say it's more common, though, at the start of a large merge sort,

00:02:09.452 --> 00:02:14.424
to just sort a block of elements, say, 1024 within shared memory and then start the merge sort

00:02:14.424 --> 00:02:20.063
with sorted chunks of size 1024. In other words, if we're actually doing this in practice,

00:02:20.063 --> 00:02:23.735
we're probably going to use a different algorithm to do this blue stage here

00:02:23.735 --> 00:02:28.605
with lots of little tiny tasks and then use merge sort to do the last 2 stages here,

00:02:28.605 --> 00:02:33.878
and we're going to see a good algorithm for an in block sort after we finish the discussion on merge sort.

00:02:33.878 --> 00:02:35.512
Now we move on to stage 2.

00:02:35.512 --> 00:02:41.227
Now we have lots of small sorted blocks, and we need to merge these small sorted blocks together.

00:02:41.227 --> 00:02:46.618
On the GPU for these intermediate merges, we would usually assign 1 merge to 1 thread block.

00:02:46.618 --> 00:02:50.642
Now, the obvious way to merge 2 sorted sequences is a serial algorithm.

00:02:50.642 --> 00:02:54.262
So let's take a little bit of a closer look at the algorithm that we choose to use here,

00:02:54.262 --> 00:02:56.942
and we'll come back to this diagram a little bit later.

00:02:56.942 --> 00:03:00.705
The obvious way to merge 2 sorted sequences is a serial algorithm,

00:03:00.705 --> 00:03:02.807
and here's our little serial processor here.

00:03:02.807 --> 00:03:07.409
The input to this algorithm is 2 sorted sequences, and the output is 1 sorted sequence.

00:03:07.409 --> 00:03:13.650
And so the algorithm is that the serial processor looks at the head of each one of the sorted sequences,

00:03:13.650 --> 00:03:19.561
chooses whichever element is smaller, outputs it on to the tail of the output sequence,

00:03:19.561 --> 00:03:24.661
and then advances the input sequence from which he took the previous element.

00:03:24.661 --> 00:03:27.125
However, this would be a poor match for the GPU

00:03:27.125 --> 00:03:30.133
because this is a serial algorithm and it wouldn't keep all of our hardware busy.

00:03:30.133 --> 00:03:35.816
So it's instructive to look another way, a better way, a more parallel way to merge 2 sorted sequences.

