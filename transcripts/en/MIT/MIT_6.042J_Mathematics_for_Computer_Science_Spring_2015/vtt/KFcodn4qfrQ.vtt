WEBVTT
Kind: captions
Language: en

00:00:01.197 --> 00:00:03.030
PROFESSOR: So we've
been saving for the last

00:00:03.030 --> 00:00:06.140
the property that makes
expectation calculating

00:00:06.140 --> 00:00:10.750
really easy and short circuits
a lot of the ingenious methods

00:00:10.750 --> 00:00:15.790
that we've used up until now--
namely, expectation is linear.

00:00:15.790 --> 00:00:19.060
So what that means is that if
you have two random variables R

00:00:19.060 --> 00:00:22.790
and S and two constants a and
b, the expectation function

00:00:22.790 --> 00:00:23.290
is linear.

00:00:23.290 --> 00:00:26.550
That is, you take a linear
combination of R and S-- aR

00:00:26.550 --> 00:00:30.640
plus bS, and that's equal
to the corresponding linear

00:00:30.640 --> 00:00:32.949
combination of the expectations.

00:00:32.949 --> 00:00:33.740
I'll read it again.

00:00:33.740 --> 00:00:37.510
Expectation of aR plus
bS is equal to a times

00:00:37.510 --> 00:00:42.380
the expectation of R plus
b times the expectation S.

00:00:42.380 --> 00:00:44.280
Expectation is linear.

00:00:44.280 --> 00:00:46.090
OK.

00:00:46.090 --> 00:00:47.960
That's an absolutely
fundamental formula

00:00:47.960 --> 00:00:51.070
that you should be
comfortable with and remember.

00:00:51.070 --> 00:00:54.670
It extends actually not only to
any finite number of variables,

00:00:54.670 --> 00:00:56.650
but with some
convergence conditions,

00:00:56.650 --> 00:00:59.930
it actually extends even to
accountable sum of variables.

00:00:59.930 --> 00:01:03.080
But let's just settle for
the two random variables

00:01:03.080 --> 00:01:05.180
case for today.

00:01:05.180 --> 00:01:08.170
Now, the crucial thing that
makes it so powerful and useful

00:01:08.170 --> 00:01:12.750
is that this fact has nothing
to do with independence.

00:01:12.750 --> 00:01:18.070
Whether R and S are independent
or equal, it doesn't matter.

00:01:18.070 --> 00:01:21.840
This linearity holds.

00:01:21.840 --> 00:01:25.000
The proof is not
terribly informative.

00:01:25.000 --> 00:01:28.490
It's just manipulating terms
and rearranging terms into sum,

00:01:28.490 --> 00:01:30.170
but let's go through
the exercise.

00:01:30.170 --> 00:01:32.480
Again, something I would
never do in lecture.

00:01:32.480 --> 00:01:35.170
But in a video where you
can skip it or fast forward

00:01:35.170 --> 00:01:39.650
or replay it, I think
it might be worth doing,

00:01:39.650 --> 00:01:41.700
And it is a proof, by
the way, that I think

00:01:41.700 --> 00:01:43.230
you should be responsible for.

00:01:43.230 --> 00:01:45.190
So let's go through it.

00:01:45.190 --> 00:01:45.800
OK.

00:01:45.800 --> 00:01:47.470
We're interested
in the expectation

00:01:47.470 --> 00:01:49.540
of the random
variable that you get

00:01:49.540 --> 00:01:51.910
by multiplying the
random variable A

00:01:51.910 --> 00:01:57.190
by little a and the random
variable B by little b.

00:01:57.190 --> 00:01:59.530
All right.

00:01:59.530 --> 00:02:01.790
One of the definitions
of expectation

00:02:01.790 --> 00:02:07.510
is that you get this expectation
by taking the sum over all

00:02:07.510 --> 00:02:11.820
the outcomes of the value
of this linear combination

00:02:11.820 --> 00:02:15.310
at the outcome omega times
the probability of omega.

00:02:15.310 --> 00:02:19.025
So what's the value of the
linear combination aA plus bB?

00:02:19.025 --> 00:02:23.620
At omega, it's simply a
times A of omega plus b

00:02:23.620 --> 00:02:25.440
times B of omega.

00:02:25.440 --> 00:02:26.390
OK.

00:02:26.390 --> 00:02:31.180
Now I've got a sum of these
terms summing over omega.

00:02:31.180 --> 00:02:34.230
I can split them
into two groups.

00:02:34.230 --> 00:02:38.730
I can take the sum over
the aA's at omega times

00:02:38.730 --> 00:02:42.860
probability of omega
and bB of omega times

00:02:42.860 --> 00:02:43.980
probability of omega.

00:02:43.980 --> 00:02:48.720
In other words, I'm multiplying
by probability of omega

00:02:48.720 --> 00:02:51.010
here to get a sum of
two terms, and then I'm

00:02:51.010 --> 00:02:54.160
rearranging all of the
capital A terms first,

00:02:54.160 --> 00:02:56.230
followed by all the
capital B terms.

00:02:56.230 --> 00:03:01.080
The result is that I wind
up with the sum over omega

00:03:01.080 --> 00:03:03.570
of the A terms times the
probability of omega--

00:03:03.570 --> 00:03:07.210
and I factored out the little
a-- plus b times the sum

00:03:07.210 --> 00:03:11.320
over all omega of B of omega
times the probability of omega.

00:03:11.320 --> 00:03:14.380
It's just rearranging
the terms in this sum

00:03:14.380 --> 00:03:18.230
after I've multiplied through
by probability of omega.

00:03:18.230 --> 00:03:21.420
Well, of course, this is
equal by definition to a times

00:03:21.420 --> 00:03:24.520
the expectation of A. Notice
this is the expectation of A,

00:03:24.520 --> 00:03:27.710
and that's the
expectation of B times b.

00:03:27.710 --> 00:03:29.700
And the proof is done.

00:03:29.700 --> 00:03:34.110
Not inspiring, but routine
if you use the alternative

00:03:34.110 --> 00:03:37.480
definition of
expectation in terms

00:03:37.480 --> 00:03:38.760
of summing over the outcomes.

00:03:38.760 --> 00:03:41.150
It's a messier proof
if you have to use

00:03:41.150 --> 00:03:42.830
the definition of
the expectation,

00:03:42.830 --> 00:03:47.897
being the value
times the probability

00:03:47.897 --> 00:03:49.355
that the variable
takes that value.

00:03:49.355 --> 00:03:52.660
And you wind up having
to convert that formula

00:03:52.660 --> 00:03:56.080
into this formula in order to
carry through the proof nicely.

00:03:56.080 --> 00:03:57.574
And we're done.

00:03:57.574 --> 00:03:58.690
OK.

00:03:58.690 --> 00:04:00.002
Let's make use of it.

00:04:00.002 --> 00:04:01.460
And in order to do
that, let's make

00:04:01.460 --> 00:04:03.810
a really trivial
but a very important

00:04:03.810 --> 00:04:06.450
remark about the expectation
of an indicator variable.

00:04:06.450 --> 00:04:09.520
So remember I sub A is three
random variables that's

00:04:09.520 --> 00:04:11.900
equal to 1 if the
event A occurs and 0

00:04:11.900 --> 00:04:13.930
if the even A doesn't occur.

00:04:13.930 --> 00:04:18.459
So what is the expectation
of the indicator variable?

00:04:18.459 --> 00:04:21.490
Well, by definition, it's
1 times the probability

00:04:21.490 --> 00:04:24.050
that it equals 1 plus
0 times the probability

00:04:24.050 --> 00:04:24.850
that it equals 0.

00:04:24.850 --> 00:04:27.160
Those are the only two
values it can take.

00:04:27.160 --> 00:04:29.850
Well, we can forget this
term in 0 times something.

00:04:29.850 --> 00:04:34.740
But what is the probability
that I A is equal to 1?

00:04:34.740 --> 00:04:36.635
That's exactly the
probability of A,

00:04:36.635 --> 00:04:39.680
and that's the fundamental
formula that we want to notice.

00:04:39.680 --> 00:04:42.770
The expectation of the indicator
variable for the event A

00:04:42.770 --> 00:04:46.430
is nothing but the
probability that A occurs.

00:04:46.430 --> 00:04:47.550
File that away.

00:04:47.550 --> 00:04:51.160
We're about to use
it multiple times.

00:04:51.160 --> 00:04:54.010
So let's go back to the
expected number of heads in n

00:04:54.010 --> 00:04:57.790
flips which we've now seen
at least two ways to do-- one

00:04:57.790 --> 00:05:02.120
by generating function argument,
another by a recursive argument

00:05:02.120 --> 00:05:05.450
using total expectation.

00:05:05.450 --> 00:05:08.490
Now where we're going to knock
it off very elegantly using

00:05:08.490 --> 00:05:13.620
linearity because let Hi
be the indicator variable

00:05:13.620 --> 00:05:15.426
for having a head on ith flip.

00:05:15.426 --> 00:05:16.550
So we look at the ith flip.

00:05:16.550 --> 00:05:19.160
Hi is 1 if the ith
flip comes up head

00:05:19.160 --> 00:05:24.460
and Hi is 0 if the ith
flip does not come up head.

00:05:24.460 --> 00:05:27.040
Then we can make the
following crucial remark,

00:05:27.040 --> 00:05:29.700
and this is a trick
that we'll use regularly

00:05:29.700 --> 00:05:31.560
by expressing some
quantity that we're

00:05:31.560 --> 00:05:34.720
interested in as a sum
of indicator variables.

00:05:34.720 --> 00:05:37.110
The total number of
heads-- the random variable

00:05:37.110 --> 00:05:39.720
equal to the total number
of heads in n flips--

00:05:39.720 --> 00:05:41.970
is equal to the sum
of the indicator

00:05:41.970 --> 00:05:44.802
variables for whether there's
a head on the first flip plus

00:05:44.802 --> 00:05:46.510
whether there's a head
on the second flip

00:05:46.510 --> 00:05:50.100
up through whether there's
a head on the n flip.

00:05:50.100 --> 00:05:54.580
So suddenly the random
variable that I want to compute

00:05:54.580 --> 00:05:59.590
is a sum of n random variables,
in fact, n indicator variables.

00:05:59.590 --> 00:06:00.450
All right.

00:06:00.450 --> 00:06:02.830
Well, that tells me
that the expectation

00:06:02.830 --> 00:06:05.720
of the number of heads is
the expectation of the sum.

00:06:05.720 --> 00:06:07.390
After all, it's
equal to the sum.

00:06:07.390 --> 00:06:10.290
But the expectation
of the sum is

00:06:10.290 --> 00:06:13.990
going to be the sum of the
expectations by linearity.

00:06:13.990 --> 00:06:15.660
So it's simply the
expectation of H 1

00:06:15.660 --> 00:06:21.280
plus the expectation of H 2 out
through the expectation of H n.

00:06:21.280 --> 00:06:24.167
But what's the expectation of
getting a head on ith flip?

00:06:24.167 --> 00:06:25.500
Well, the flips are independent.

00:06:25.500 --> 00:06:28.140
It's simply the
expectation of a head.

00:06:28.140 --> 00:06:30.750
So what I have
is-- each of these

00:06:30.750 --> 00:06:33.830
is equal to the probability of
a head, and there's n of them.

00:06:33.830 --> 00:06:37.850
So the total is n times the
probability of Head, or np,

00:06:37.850 --> 00:06:40.100
which is a formula
that we had derived

00:06:40.100 --> 00:06:41.460
two other ways previously.

00:06:41.460 --> 00:06:44.140
And now it really falls
out very elegantly

00:06:44.140 --> 00:06:47.620
with hardly any ingenuity
other than the wonderful idea

00:06:47.620 --> 00:06:51.095
of expressing the number of
heads as a sum of indicators.

00:06:53.650 --> 00:06:59.600
Let's look at one example
and a very related example

00:06:59.600 --> 00:07:04.570
of asking about the probability
of the expected number of hats

00:07:04.570 --> 00:07:05.650
that are returned.

00:07:05.650 --> 00:07:10.050
When n men check their
hats at a hat check

00:07:10.050 --> 00:07:11.730
and then the hats
get all scrambled up

00:07:11.730 --> 00:07:15.110
by incompetent staff
and then they're

00:07:15.110 --> 00:07:17.920
given out again in such a
way that the probability

00:07:17.920 --> 00:07:21.210
that the ith man gets his
own hat back is 1 over n.

00:07:21.210 --> 00:07:27.270
What you could say is that all
possible permutations of the n

00:07:27.270 --> 00:07:29.440
hats are equally likely.

00:07:29.440 --> 00:07:33.870
And we ask with all
permutations equally likely,

00:07:33.870 --> 00:07:36.890
how many of them is it
the case that the ith

00:07:36.890 --> 00:07:39.180
man gets his own hat back?

00:07:39.180 --> 00:07:41.780
And there's a 1 out of n
chance that the ith man

00:07:41.780 --> 00:07:44.290
is going to get his own hat
back because there's n hats,

00:07:44.290 --> 00:07:46.481
and he's equally likely
to get all of them.

00:07:46.481 --> 00:07:46.980
OK.

00:07:49.660 --> 00:07:52.150
How many men do we expect
will get their hat back

00:07:52.150 --> 00:07:53.350
in this setting?

00:07:53.350 --> 00:07:56.950
Well, let's let our Ri be
the indicator variable for

00:07:56.950 --> 00:08:01.170
whether or not the ith man got
his hat returned-- R i for hat

00:08:01.170 --> 00:08:04.000
returned to the ith man.

00:08:04.000 --> 00:08:08.120
Now, notice that Ri and
Rj are not independent.

00:08:08.120 --> 00:08:10.184
In the previous case,
those H's were independent

00:08:10.184 --> 00:08:11.850
because the coin flips
were independent.

00:08:11.850 --> 00:08:14.530
But here, if I
know, for example,

00:08:14.530 --> 00:08:17.660
that R 1 got his hat
back, the probability

00:08:17.660 --> 00:08:20.510
that R 2 got his hat back
has changed from 1 over n

00:08:20.510 --> 00:08:24.030
to 1 over n minus 1 because
1 is out of the picture,

00:08:24.030 --> 00:08:28.380
and R 2 is going to get his hat
back among the remaining hats 2

00:08:28.380 --> 00:08:30.807
through and n is
n minus 1 of them.

00:08:30.807 --> 00:08:33.980
And he's got a 1
minus 1 over n minus 1

00:08:33.980 --> 00:08:35.210
chance of getting his hat.

00:08:35.210 --> 00:08:37.630
His probability
has changed given

00:08:37.630 --> 00:08:39.340
that R 1 got his hat back.

00:08:39.340 --> 00:08:42.130
So they're not independent.

00:08:42.130 --> 00:08:43.220
All right.

00:08:43.220 --> 00:08:46.940
Nevertheless, independence
doesn't matter for linearity.

00:08:46.940 --> 00:08:50.400
So I can still say that
the expected number of hats

00:08:50.400 --> 00:08:53.700
returned is equal
to the expectation

00:08:53.700 --> 00:08:56.620
of the sum of the indicator
variables for each man

00:08:56.620 --> 00:08:58.460
getting his hat back.

00:08:58.460 --> 00:09:01.320
And of course, the
expectation of that sum

00:09:01.320 --> 00:09:04.180
is the sum of the expectations.

00:09:04.180 --> 00:09:07.140
And the expectation of each
of these-- we figured out--

00:09:07.140 --> 00:09:08.800
was 1 over n, and
there's n of them.

00:09:08.800 --> 00:09:12.200
So it's n times 1 over n, or 1.

00:09:12.200 --> 00:09:14.600
I expect when all the
hats are scrambled

00:09:14.600 --> 00:09:18.150
and all permutations of the
hats are equally likely,

00:09:18.150 --> 00:09:21.170
that one man is going
to get his hat back.

00:09:21.170 --> 00:09:23.600
None of the others will.

00:09:23.600 --> 00:09:24.100
OK.

00:09:24.100 --> 00:09:27.940
Now let's change the
situation a little bit.

00:09:27.940 --> 00:09:30.640
And think instead of
scrambling the hats in a way

00:09:30.640 --> 00:09:34.250
that all possible permutations
of hats are equally likely,

00:09:34.250 --> 00:09:36.140
let's think about
a Chinese banquet.

00:09:36.140 --> 00:09:37.740
So Chinese banquets
are traditionally

00:09:37.740 --> 00:09:41.740
done with a table
of nine in a circle,

00:09:41.740 --> 00:09:43.910
and there's a lazy
Susan that spins around

00:09:43.910 --> 00:09:46.820
where there's dishes of food
in front of each person.

00:09:46.820 --> 00:09:48.590
But let's generalize it to n.

00:09:48.590 --> 00:09:50.220
Suppose that n
people are sitting

00:09:50.220 --> 00:09:52.920
around a spinning
table-- a lazy-Susan)

00:09:52.920 --> 00:09:56.580
with n different dishes, one
dish in front of each person.

00:09:56.580 --> 00:10:00.860
And now we spin the
lazy Susan randomly,

00:10:00.860 --> 00:10:04.640
and we ask how many
people do we expect

00:10:04.640 --> 00:10:06.820
will wind up with the
same dish that they

00:10:06.820 --> 00:10:10.600
started with after the spin?

00:10:10.600 --> 00:10:14.690
Well, now we can let Ri
indicate that the ith

00:10:14.690 --> 00:10:17.960
person got the same dish back.

00:10:17.960 --> 00:10:20.650
And now these Ris,
which are different

00:10:20.650 --> 00:10:22.950
from the previous ones
about hat returns,

00:10:22.950 --> 00:10:26.250
these are Ris are totally
dependent-- much more

00:10:26.250 --> 00:10:29.480
so than the other ones
work because they're all 1

00:10:29.480 --> 00:10:30.640
or they're all 0.

00:10:30.640 --> 00:10:33.250
If one person gets
their hat back,

00:10:33.250 --> 00:10:35.810
it means that the
spinning table got

00:10:35.810 --> 00:10:38.940
back to where it used to be, and
everybody has their hat back.

00:10:38.940 --> 00:10:42.040
And if one person doesn't
have their hat back,

00:10:42.040 --> 00:10:44.800
then the table is shifted
off where it was originally

00:10:44.800 --> 00:10:47.670
and nobody has
the original dish.

00:10:47.670 --> 00:10:48.220
I said hats.

00:10:48.220 --> 00:10:50.750
I meant the dish that
they started with.

00:10:50.750 --> 00:10:53.250
So everybody gets
the same dish back,

00:10:53.250 --> 00:10:55.220
or nobody gets the
same dish back.

00:10:55.220 --> 00:10:58.990
These variables are as dependent
as they possibly could be,

00:10:58.990 --> 00:11:03.760
but it doesn't matter because
linearity still holds.

00:11:03.760 --> 00:11:06.710
And that means that
the previous argument

00:11:06.710 --> 00:11:10.900
about the expected number
of dishes that get back

00:11:10.900 --> 00:11:13.440
to the person that
they started with

00:11:13.440 --> 00:11:18.150
is still 1 even though
all the Ris are equal.

00:11:21.840 --> 00:11:25.710
Well, that's so much for the
lovely rule about linearity

00:11:25.710 --> 00:11:29.430
of expectation which holds
regardless of assumptions

00:11:29.430 --> 00:11:31.950
about independence or not.

00:11:31.950 --> 00:11:35.950
There is a rule for products,
but it requires independence.

00:11:35.950 --> 00:11:38.530
So the independent product
rule says, sure enough

00:11:38.530 --> 00:11:41.150
that the expectation
of a product of two

00:11:41.150 --> 00:11:45.340
random variables, x
and y, is the product

00:11:45.340 --> 00:11:49.750
of their expectations, providing
that they are independent.

00:11:49.750 --> 00:11:52.110
And this extends
to many variables

00:11:52.110 --> 00:11:55.710
if they're mutually independent.

00:11:55.710 --> 00:11:58.530
Again, the proof by rearranging
terms in the defining

00:11:58.530 --> 00:12:00.410
sum for the expectation of xy.

00:12:00.410 --> 00:12:01.280
Let's go through it.

00:12:01.280 --> 00:12:03.321
And again, you can fast
forward or skip this part

00:12:03.321 --> 00:12:06.630
if you don't want to watch
equations being manipulated.

00:12:06.630 --> 00:12:10.360
So by definition, the
expectation of the product xy

00:12:10.360 --> 00:12:13.450
is the sum over all
the possible values

00:12:13.450 --> 00:12:16.330
of x and y of the
value of the product

00:12:16.330 --> 00:12:20.050
xy times the probability that
the first variable, capital X,

00:12:20.050 --> 00:12:22.520
equals little x and
the second variable Y

00:12:22.520 --> 00:12:24.700
is equal to little y.

00:12:24.700 --> 00:12:28.890
This is by definition, the
expectation of the product--

00:12:28.890 --> 00:12:30.960
by the first definition.

00:12:30.960 --> 00:12:32.970
Not the one in
terms of outcomes.

00:12:32.970 --> 00:12:34.620
Now, using
independence, this term

00:12:34.620 --> 00:12:38.200
here can be split into a product
of X equals x and Y equals y.

00:12:38.200 --> 00:12:39.240
So let's do that.

00:12:39.240 --> 00:12:42.150
So this is the sum of
xy times the probability

00:12:42.150 --> 00:12:45.800
that X equals x times the
probability that Y equals y.

00:12:45.800 --> 00:12:49.290
Now I'm going to do a
fairly standard trick, which

00:12:49.290 --> 00:12:52.900
is I'm going to organize
this sum in a clean way.

00:12:52.900 --> 00:12:55.970
Right now it's an unordered sum
over all possible pairs of x

00:12:55.970 --> 00:13:01.220
and y in the range of
the variables x and y,

00:13:01.220 --> 00:13:04.400
but I'm going to do the
sum so I first sum over all

00:13:04.400 --> 00:13:07.070
the y's, and then for each
y, I'm going to sum over all

00:13:07.070 --> 00:13:09.200
the x's.

00:13:09.200 --> 00:13:11.271
This is an unordered
some really.

00:13:11.271 --> 00:13:13.770
There's no order here, but now
I'm giving you an arrangement

00:13:13.770 --> 00:13:18.420
which says that I'm going to
lump together the sums over all

00:13:18.420 --> 00:13:23.050
the x's, and then for each of
those I'm going to sum up over

00:13:23.050 --> 00:13:25.900
the y's.

00:13:25.900 --> 00:13:28.570
Well, when I do it
this way, what I've got

00:13:28.570 --> 00:13:30.070
is an interesting thing here.

00:13:30.070 --> 00:13:33.190
I've got a sum over x, and
there's some y terms here

00:13:33.190 --> 00:13:34.670
that don't depend on x.

00:13:34.670 --> 00:13:38.590
I can factor them out because
they don't change with x.

00:13:38.590 --> 00:13:42.990
So if I factor out this y and
probability of Y equals y,

00:13:42.990 --> 00:13:47.840
I wind up with the sum over y
of this factored out term-- y

00:13:47.840 --> 00:13:52.120
times probability Y equals
y-- times the sum over x's x

00:13:52.120 --> 00:13:55.430
times the probability
that X equals x.

00:13:55.430 --> 00:13:59.660
Now, this is the
same term that is

00:13:59.660 --> 00:14:02.100
the coefficient of every
one of these y terms

00:14:02.100 --> 00:14:05.420
that depends on y, and this
term does not depend on y.

00:14:05.420 --> 00:14:07.910
So I can factor it out.

00:14:07.910 --> 00:14:11.740
And if I do that, I
wind up with the sum

00:14:11.740 --> 00:14:13.920
over x of x times
the probability

00:14:13.920 --> 00:14:18.250
that X equals x times
the sum over y of y times

00:14:18.250 --> 00:14:19.950
the probability that Y equals y.

00:14:19.950 --> 00:14:21.100
And guess what.

00:14:21.100 --> 00:14:24.600
This is by definition
the expectation of X,

00:14:24.600 --> 00:14:27.690
and this is by definition
the expectation of Y.

00:14:27.690 --> 00:14:30.220
And by that chain
of equalities, I've

00:14:30.220 --> 00:14:33.270
proved, sure enough, that
the expectation of XY

00:14:33.270 --> 00:14:39.160
is equal to the expectation of X
times the expectation of Y QED.

00:14:39.160 --> 00:14:41.260
So the key step here
was where independence

00:14:41.260 --> 00:14:44.770
was used at the very first step
when I split up the probability

00:14:44.770 --> 00:14:47.862
that X equaled x and Y
equaled y into the product

00:14:47.862 --> 00:14:49.320
of the corresponding
probabilities.

00:14:51.960 --> 00:14:53.840
Now, let me just
end with a warning

00:14:53.840 --> 00:14:57.810
about a couple of blunders
that people make all the time.

00:14:57.810 --> 00:15:00.460
So first of all, don't
forget independence

00:15:00.460 --> 00:15:05.100
as a crucial condition on the
product rule for expectations.

00:15:05.100 --> 00:15:09.830
It can hold in some cases where
the variables are dependent.

00:15:09.830 --> 00:15:11.700
Independent is not a
necessary condition.

00:15:11.700 --> 00:15:14.460
It's efficient, but
you need some kind

00:15:14.460 --> 00:15:18.840
of a condition in order for
the product rule to hold.

00:15:18.840 --> 00:15:21.760
So if you're not
careful, it won't if you

00:15:21.760 --> 00:15:24.490
forget to check for
independence or something that

00:15:24.490 --> 00:15:25.620
is tantamount to it.

00:15:25.620 --> 00:15:27.940
So let's just take an
easy example remember what

00:15:27.940 --> 00:15:29.430
happens if independence fails.

00:15:29.430 --> 00:15:32.680
Suppose I have a variable X--
a random variable X-- which

00:15:32.680 --> 00:15:35.780
takes positive and negative
values with equal probability.

00:15:35.780 --> 00:15:38.780
So it takes 1 and minus
1 with equal probability.

00:15:38.780 --> 00:15:41.580
It takes pi and minus pi
with equal probability.

00:15:41.580 --> 00:15:43.290
I don't really care
what those values are

00:15:43.290 --> 00:15:46.760
as long as it's taking some
positive and negative values,

00:15:46.760 --> 00:15:49.370
and it takes a positive
value at the same probability

00:15:49.370 --> 00:15:52.100
that it takes that
value negated.

00:15:52.100 --> 00:15:54.970
Well, that automatically means
that the expectation of X

00:15:54.970 --> 00:15:58.140
is 0 because when I
add up all these terms,

00:15:58.140 --> 00:16:00.410
the positive and negative
terms cancel because they

00:16:00.410 --> 00:16:01.670
have the same probability.

00:16:01.670 --> 00:16:08.780
So any such X that's symmetric
about 0 has expectations 0.

00:16:08.780 --> 00:16:11.180
On the other hand,
if I square X,

00:16:11.180 --> 00:16:15.070
then all of those positive
and negative values

00:16:15.070 --> 00:16:16.140
become positive.

00:16:16.140 --> 00:16:19.020
And so I'm taking
the expectation

00:16:19.020 --> 00:16:22.770
of a variable that's
strictly positive-- at least

00:16:22.770 --> 00:16:25.910
with nonzero probability
at a bunch of outcomes.

00:16:25.910 --> 00:16:30.520
And therefore, the expectation
of X squared is positive.

00:16:30.520 --> 00:16:32.920
So the expectation of X
is 0, but the expectation

00:16:32.920 --> 00:16:34.090
of X squared is positive.

00:16:34.090 --> 00:16:36.340
Well, of course, if I
multiply expectation

00:16:36.340 --> 00:16:39.210
of X times expectation
of X, that's still 0.

00:16:39.210 --> 00:16:40.940
So here's a counter example.

00:16:40.940 --> 00:16:43.110
Expectation of X
times expectation of X

00:16:43.110 --> 00:16:45.590
is equal to 0, which is
less than the expectation

00:16:45.590 --> 00:16:47.690
of the square of X. Of
course this is about as

00:16:47.690 --> 00:16:49.740
dependent as it could
possibly be because it's

00:16:49.740 --> 00:16:52.630
the same random variable,
but it illustrates

00:16:52.630 --> 00:16:56.440
the failure of the
product rule if you

00:16:56.440 --> 00:16:58.850
don't have some kind of a
condition like independence

00:16:58.850 --> 00:17:00.290
around.

00:17:00.290 --> 00:17:03.100
There's a second blunder
that's more interesting

00:17:03.100 --> 00:17:07.810
and that people can fall in
because there's a temptation

00:17:07.810 --> 00:17:10.660
to assume that if the
product rule holds

00:17:10.660 --> 00:17:13.690
for independence, then so
should the reciprocal rule.

00:17:13.690 --> 00:17:17.440
That is, you might think that
the expectation of X over Y

00:17:17.440 --> 00:17:20.900
is equal to the expectation
of X over the expectation of Y

00:17:20.900 --> 00:17:22.970
when X and Y are independent.

00:17:22.970 --> 00:17:23.990
But it's not true.

00:17:23.990 --> 00:17:27.060
Even when they're
independent, the expectation

00:17:27.060 --> 00:17:31.550
of X divided by Y is in general,
not equal to the expectation

00:17:31.550 --> 00:17:34.820
of X divided by the
expectation of Y. In fact,

00:17:34.820 --> 00:17:38.860
the counterexample is if X is
the constant 1, the expectation

00:17:38.860 --> 00:17:39.690
of 1 over Y

00:17:39.690 --> 00:17:42.170
[AUDIO OUT]

00:18:15.150 --> 00:18:16.900
PROFESSOR: [INAUDIBLE]
complex instruction

00:18:16.900 --> 00:18:20.630
set code was better than risk.

00:18:20.630 --> 00:18:25.080
So I won't mention names,
but prominent people

00:18:25.080 --> 00:18:26.360
have made this blunder.

00:18:26.360 --> 00:18:28.070
You shouldn't.

