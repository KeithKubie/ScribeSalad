WEBVTT
Kind: captions
Language: en

00:00:00.610 --> 00:00:01.830
JUSTIN UBERTI: Hi everyone.

00:00:01.830 --> 00:00:04.720
Thanks for coming to the
session on WebRTC for

00:00:04.720 --> 00:00:07.260
plugin-free realtime
communication.

00:00:07.260 --> 00:00:10.900
I'm Justin Uberti, tech lead
for WebRTC at Google.

00:00:10.900 --> 00:00:14.370
And with me today is-- hey,
has anyone seen Sam?

00:00:18.650 --> 00:00:19.040
SAM DUTTON: Hey.

00:00:19.040 --> 00:00:21.630
JUSTIN UBERTI: Sam Dutton,
coming to you live from WebRTC

00:00:21.630 --> 00:00:25.230
on Chrome for Android.

00:00:25.230 --> 00:00:25.420
[APPLAUSE]

00:00:25.420 --> 00:00:26.670
SAM DUTTON: On a beautiful
Nexus 7.

00:00:29.600 --> 00:00:33.070
We got this low-res to cope
with the Wi-Fi here.

00:00:33.070 --> 00:00:36.910
That seems to be working
pretty well.

00:00:36.910 --> 00:00:37.480
JUSTIN UBERTI: That was
quite an entrance.

00:00:37.480 --> 00:00:39.190
Why don't you come up here
and introduce yourself?

00:00:39.190 --> 00:00:40.080
SAM DUTTON: Yeah.

00:00:40.080 --> 00:00:40.650
Hey.

00:00:40.650 --> 00:00:41.470
I'm Sam Dutton.

00:00:41.470 --> 00:00:44.420
I'm a developer advocate
for Chrome.

00:00:47.160 --> 00:00:48.640
JUSTIN UBERTI: So we're here to
talk to you today about the

00:00:48.640 --> 00:00:51.070
great things that WebRTC's been
working on and how you

00:00:51.070 --> 00:00:52.650
can use them.

00:00:52.650 --> 00:00:54.790
So what is WebRTC?

00:00:54.790 --> 00:00:57.600
In a nutshell, it's what we call
realtime communication--

00:00:57.600 --> 00:00:59.140
RTC--

00:00:59.140 --> 00:01:02.310
the ability to communicate
live with somebody or

00:01:02.310 --> 00:01:04.980
something as if you were right
there next to them.

00:01:04.980 --> 00:01:09.350
And this can mean audio,
video, or even just

00:01:09.350 --> 00:01:12.450
peer-to-peer data.

00:01:12.450 --> 00:01:15.740
And we think WebRTC
is really cool.

00:01:15.740 --> 00:01:18.020
But there's a lot of other
people who are really excited

00:01:18.020 --> 00:01:19.810
about WebRTC as well.

00:01:19.810 --> 00:01:23.880
And one of the reasons is that
WebRTC fills a critical gap in

00:01:23.880 --> 00:01:27.750
the web platform, where
previously, a native

00:01:27.750 --> 00:01:30.460
proprietary app like Skype could
do something the web

00:01:30.460 --> 00:01:31.940
just couldn't.

00:01:31.940 --> 00:01:34.620
But now we've turned that around
and changed that so we

00:01:34.620 --> 00:01:38.070
have a web of connected WebRTC
devices that can communicate

00:01:38.070 --> 00:01:43.060
in realtime just by loading
a web page.

00:01:43.060 --> 00:01:46.180
So here's what we're trying to
do with WebRTC, to build the

00:01:46.180 --> 00:01:50.510
key APIs for realtime
communication into the web, to

00:01:50.510 --> 00:01:54.030
make an amazing media stack in
Chrome so that developers can

00:01:54.030 --> 00:01:59.130
build great experiences, and
to use this network of

00:01:59.130 --> 00:02:01.670
connected WebRTC devices
to create a new

00:02:01.670 --> 00:02:04.200
communications ecosystem.

00:02:04.200 --> 00:02:07.380
And these kind of seem
like lofty goals.

00:02:07.380 --> 00:02:11.690
But take this quote from the
current CTO of the FCC who

00:02:11.690 --> 00:02:14.920
said he sees traditional
telephony fading away as voice

00:02:14.920 --> 00:02:16.558
just becomes another web app.

00:02:19.490 --> 00:02:21.840
So we're trying to live
up to that promise.

00:02:21.840 --> 00:02:25.460
And right now, you can build a
single app with WebRTC that

00:02:25.460 --> 00:02:30.360
connects Chrome, Chrome for
Android, Firefox, and very

00:02:30.360 --> 00:02:32.280
soon, Opera.

00:02:32.280 --> 00:02:35.290
I'm especially excited to
announce the as of this week,

00:02:35.290 --> 00:02:38.590
Firefox 22 is going to beta,
which is the very first

00:02:38.590 --> 00:02:41.690
WebRTC-enabled version
of Firefox.

00:02:41.690 --> 00:02:47.570
So within a matter of weeks, we
will have over one billion

00:02:47.570 --> 00:02:51.111
users using a WebRTC-enabled
browser.

00:02:51.111 --> 00:02:56.770
[APPLAUSE]

00:02:56.770 --> 00:02:59.560
JUSTIN UBERTI: And I think that
just gives a good idea of

00:02:59.560 --> 00:03:02.010
the size of the opportunity
here.

00:03:02.010 --> 00:03:04.560
And we respect that number to
grow very significantly as

00:03:04.560 --> 00:03:07.720
both Chrome and Firefox get
increased adoption.

00:03:07.720 --> 00:03:10.770
For places where we don't have
WebRTC-enabled browsers, we're

00:03:10.770 --> 00:03:15.180
providing native, supported,
official tool kits on both

00:03:15.180 --> 00:03:20.460
Android, and very soon, iOS,
that can interoperate with

00:03:20.460 --> 00:03:21.620
WebRTC in the browser.

00:03:21.620 --> 00:03:27.610
[APPLAUSE]

00:03:27.610 --> 00:03:29.270
JUSTIN UBERTI: So here are
just a handful of the

00:03:29.270 --> 00:03:32.240
companies that see the
opportunity in WebRTC and are

00:03:32.240 --> 00:03:34.305
building their business
around it.

00:03:37.700 --> 00:03:39.980
So that's the vision
for WebRTC.

00:03:39.980 --> 00:03:43.630
Now let's dig into the APIs.

00:03:43.630 --> 00:03:48.220
There are remain categories of
API that exist in WebRTC.

00:03:48.220 --> 00:03:52.410
First, getting access
to input devices--

00:03:52.410 --> 00:03:55.670
accessing the microphone,
accessing the webcam, getting

00:03:55.670 --> 00:03:58.350
a stream of media from
either of them.

00:03:58.350 --> 00:04:01.380
Secondly, being able to connect
to another WebRTC

00:04:01.380 --> 00:04:04.460
endpoint across the internet,
and to send this audio and

00:04:04.460 --> 00:04:06.180
video in realtime.

00:04:06.180 --> 00:04:09.000
And third, the ability to do
this not just for audio and

00:04:09.000 --> 00:04:12.190
video, but for arbitrary
application data.

00:04:12.190 --> 00:04:16.370
And we think this one is
especially interesting.

00:04:16.370 --> 00:04:17.700
So because there's
three categories,

00:04:17.700 --> 00:04:19.060
we have three objects.

00:04:19.060 --> 00:04:21.959
Three primary objects in WebRTC
to access this stuff.

00:04:21.959 --> 00:04:25.890
The first one, MediaStream, for
getting access to media,

00:04:25.890 --> 00:04:28.740
then RTCPeerConnection
and RTCDataChannel.

00:04:28.740 --> 00:04:32.270
And we'll get into each one
of these individually.

00:04:32.270 --> 00:04:35.130
Sam, why don't you tell
us about MediaStream?

00:04:35.130 --> 00:04:35.740
SAM DUTTON: Yeah, sure.

00:04:35.740 --> 00:04:41.300
So MediaStream represents a
single source of synchronized

00:04:41.300 --> 00:04:43.570
audio or video or both.

00:04:43.570 --> 00:04:49.420
Each MediaStream contains one
or more MediaStream tracks.

00:04:49.420 --> 00:04:53.900
For example, on your laptop,
you've got a webcam and a

00:04:53.900 --> 00:04:57.220
microphone providing video and
audio streams, and they're

00:04:57.220 --> 00:04:58.900
synchronized.

00:04:58.900 --> 00:05:04.160
We get access to these local
devices using the getUserMedia

00:05:04.160 --> 00:05:05.770
method of Navigator.

00:05:05.770 --> 00:05:09.430
So we just look at the code for
that, just highlight that.

00:05:09.430 --> 00:05:12.540
And you can see that
getUserMedia there, it takes

00:05:12.540 --> 00:05:14.950
three parameters, three
arguments there.

00:05:14.950 --> 00:05:17.550
And the first one, if we look
at the constraints argument

00:05:17.550 --> 00:05:21.160
I've got, you can see I'm just
specifying I want video.

00:05:21.160 --> 00:05:21.980
That's all I'm saying.

00:05:21.980 --> 00:05:24.440
Just give me video
and nothing else.

00:05:24.440 --> 00:05:27.410
And then in the success
callback, we're setting the

00:05:27.410 --> 00:05:33.460
source of a video using the
stream that's returned by

00:05:33.460 --> 00:05:34.910
getUserMedia.

00:05:34.910 --> 00:05:38.770
Let's see that in action, really
simple example here.

00:05:38.770 --> 00:05:43.730
And you can see when we fire
the getUserMedia method, we

00:05:43.730 --> 00:05:47.110
get the allow permissions
bar at the top there.

00:05:47.110 --> 00:05:50.640
Now, this means that users have
to explicitly opt in to

00:05:50.640 --> 00:05:52.940
allowing access to their
microphone and camera.

00:05:52.940 --> 00:05:53.760
And yeah, there we have it.

00:05:53.760 --> 00:05:56.010
Using that code,
we've got video

00:05:56.010 --> 00:05:57.570
displayed in a video element.

00:05:57.570 --> 00:05:58.830
Great.

00:05:58.830 --> 00:06:02.940
What really excites me about
these APIs is when they come

00:06:02.940 --> 00:06:06.250
up against each other,
like in this example.

00:06:06.250 --> 00:06:09.600
What's happening is, that we've
got getUserMedia being

00:06:09.600 --> 00:06:13.160
piped into a canvas element,
and then the canvas element

00:06:13.160 --> 00:06:16.880
being analyzed, and then
producing ASCII, just like

00:06:16.880 --> 00:06:19.873
that, which could make a
good codec, I think.

00:06:19.873 --> 00:06:20.620
JUSTIN UBERTI: It would
be a good codec.

00:06:20.620 --> 00:06:22.210
You can press it using
just gzip.

00:06:22.210 --> 00:06:26.820
SAM DUTTON: Yeah, smaller font
sizes, high resolution.

00:06:26.820 --> 00:06:29.930
Also, another example of
this from Facekat.

00:06:29.930 --> 00:06:33.520
Now what's happening here is
that it's using the head

00:06:33.520 --> 00:06:38.600
tracker JavaScript library to
track the position of my head.

00:06:38.600 --> 00:06:42.240
And when I move around, you can
see I'm moving through the

00:06:42.240 --> 00:06:49.340
game and trying to stay alive,
which is quite difficult.

00:06:49.340 --> 00:06:50.760
God, this is painful.

00:06:50.760 --> 00:06:52.490
Anyway--

00:06:52.490 --> 00:06:54.220
whoa.

00:06:54.220 --> 00:06:58.090
OK, I think I've flipped
into hyperspace there.

00:06:58.090 --> 00:07:00.740
And an old favorite, you've may
well have seen a webcam

00:07:00.740 --> 00:07:03.670
toy which gives us access to the
camera, kind of photobooth

00:07:03.670 --> 00:07:10.240
app, uses WebGL to create a
bunch of slightly psychedelic

00:07:10.240 --> 00:07:11.300
effects there.

00:07:11.300 --> 00:07:13.560
I quite this old movie
one, so I'll take

00:07:13.560 --> 00:07:18.870
that and get a snapshot.

00:07:18.870 --> 00:07:21.400
And I can share that with my
friends, so beautiful work

00:07:21.400 --> 00:07:23.790
from Paul Neave there.

00:07:23.790 --> 00:07:27.450
Now you might remember I said
that we can use the

00:07:27.450 --> 00:07:28.370
constraints object.

00:07:28.370 --> 00:07:30.990
The simple example there was
just saying, use the video,

00:07:30.990 --> 00:07:31.780
nothing else.

00:07:31.780 --> 00:07:33.650
Well, we can do more interesting
things with

00:07:33.650 --> 00:07:35.670
constraints than that.

00:07:35.670 --> 00:07:38.600
We can do stuff like specify
the resolution or the frame

00:07:38.600 --> 00:07:40.670
rate, a whole stack of
things that we want

00:07:40.670 --> 00:07:42.630
from our local devices.

00:07:42.630 --> 00:07:46.130
A little example from that,
if we go over here.

00:07:46.130 --> 00:07:48.630
Now, let's look at the
code, actually.

00:07:48.630 --> 00:07:51.370
If we go to the dev tools there,
you can see that I've

00:07:51.370 --> 00:07:55.860
got three different constraints
objects, one for

00:07:55.860 --> 00:07:56.860
each resolution.

00:07:56.860 --> 00:08:01.280
So when I press the buttons,
I use the QVGA constraints,

00:08:01.280 --> 00:08:04.730
getUserMedia, and then with the
VGA one, I'm getting high

00:08:04.730 --> 00:08:05.610
resolution.

00:08:05.610 --> 00:08:12.500
And for HD, I'm getting
the full 1280 by 720.

00:08:12.500 --> 00:08:17.330
We can also use getUserMedia
now for input from our

00:08:17.330 --> 00:08:18.230
microphone.

00:08:18.230 --> 00:08:21.540
In other words, we can use
getUserMedia to provide a

00:08:21.540 --> 00:08:23.790
source node for web audio.

00:08:23.790 --> 00:08:26.380
And there's a huge amount of
interesting stuff we can do

00:08:26.380 --> 00:08:30.160
with that processing audio using
web audio, from the mic

00:08:30.160 --> 00:08:30.680
or wherever.

00:08:30.680 --> 00:08:33.496
A little example
of that here--

00:08:33.496 --> 00:08:36.105
I'll just allowed access to the
mic, and you can see, I'm

00:08:36.105 --> 00:08:38.210
getting a nice little
visualization there in the

00:08:38.210 --> 00:08:39.530
canvas element.

00:08:39.530 --> 00:08:41.360
And I can start to
record this, blah

00:08:41.360 --> 00:08:42.770
blah blah blah blah--

00:08:42.770 --> 00:08:43.075
[AUDIO PLAYBACK]

00:08:43.075 --> 00:08:45.055
-To record this, blah blah
blah blah blah--

00:08:45.055 --> 00:08:45.750
[END AUDIO PLAYBACK]

00:08:45.750 --> 00:08:49.230
SAM DUTTON: And yeah, you can
see that's used recorder.js to

00:08:49.230 --> 00:08:50.480
save that locally to disk.

00:08:53.090 --> 00:08:55.740
GetUserMedia also now-- this is
kind of experimental, but

00:08:55.740 --> 00:08:59.470
we can use getUserMedia to get
a screen capture, in other

00:08:59.470 --> 00:09:03.990
words data coming directly from
what we see on screen,

00:09:03.990 --> 00:09:08.190
not from the audio video from
the mic and the camera.

00:09:08.190 --> 00:09:09.820
Probably the simplest if I show
you an example of this,

00:09:09.820 --> 00:09:12.950
so yeah, a little application
here.

00:09:12.950 --> 00:09:19.140
And when I click to make the
call, allow, and you can see

00:09:19.140 --> 00:09:23.610
there that I get this kind of
crazy hall of mirrors effect,

00:09:23.610 --> 00:09:26.790
because I'm capturing the screen
that I'm capturing, and

00:09:26.790 --> 00:09:28.980
so on and so on.

00:09:28.980 --> 00:09:30.900
Now that's quite nice.

00:09:30.900 --> 00:09:34.700
But it would be really useful
if we could take that screen

00:09:34.700 --> 00:09:39.980
capture and then transmit that
to another computer.

00:09:39.980 --> 00:09:44.450
And for that, we have
RTCPeerConnection.

00:09:44.450 --> 00:09:45.360
JUSTIN UBERTI: Thanks, Sam.

00:09:45.360 --> 00:09:48.880
So as the name implies,
RTCPeerConnection is all about

00:09:48.880 --> 00:09:53.210
making a connection to another
peer and over this peer

00:09:53.210 --> 00:09:54.770
connection, we can actually
then go and

00:09:54.770 --> 00:09:56.370
send audio and video.

00:09:56.370 --> 00:09:59.360
And the way we do this is we
take the media streams that

00:09:59.360 --> 00:10:02.380
we've got from getUserMedia, and
we plug them into the peer

00:10:02.380 --> 00:10:05.910
connection, and send them
off to the other side.

00:10:05.910 --> 00:10:08.100
When the other side receives
them, they'll pop out as a new

00:10:08.100 --> 00:10:10.470
media stream on their
peer connection.

00:10:10.470 --> 00:10:12.290
And they can then plug that
into a video element to

00:10:12.290 --> 00:10:13.920
display on the page.

00:10:13.920 --> 00:10:16.480
And so both sides of a peer
connection, they both get

00:10:16.480 --> 00:10:19.230
streams from getUserMedia, they
plug them in, and then

00:10:19.230 --> 00:10:22.140
those media streams pop out
magically encoded and decoded

00:10:22.140 --> 00:10:23.890
on the other side.

00:10:23.890 --> 00:10:26.570
Now under the hood,
peer connection is

00:10:26.570 --> 00:10:28.510
doing a ton of stuff--

00:10:28.510 --> 00:10:31.840
signal processing to remove
noise from audio and video;

00:10:31.840 --> 00:10:34.070
codec selection and compression
and decompression

00:10:34.070 --> 00:10:36.790
of the actual audio and video;
finding the actual

00:10:36.790 --> 00:10:39.590
peer-to-peer route through
firewalls, through NATs,

00:10:39.590 --> 00:10:43.040
through relays; encrypting the
data so that a user's data is

00:10:43.040 --> 00:10:46.070
fully protected at all times;
and then actually managing the

00:10:46.070 --> 00:10:49.100
bandwidth so that if you have
two megabits, we use it.

00:10:49.100 --> 00:10:51.880
If you have 200 kilobits,
that's all we use.

00:10:51.880 --> 00:10:55.680
But we do everything we can hide
this complexity from that

00:10:55.680 --> 00:10:57.840
web developer.

00:10:57.840 --> 00:11:01.930
And so the main thing is that
you get your media streams,

00:11:01.930 --> 00:11:03.660
you plug them in via
Adstream to peer

00:11:03.660 --> 00:11:05.840
connection, and off you go.

00:11:05.840 --> 00:11:08.850
And here's a little
example of this.

00:11:08.850 --> 00:11:12.210
SAM DUTTON: Yeah, so you can see
here that we've created a

00:11:12.210 --> 00:11:14.580
new RTCPeerConnection.

00:11:14.580 --> 00:11:18.360
And when the stream is received,
the callback for

00:11:18.360 --> 00:11:22.710
that in gotRemoteStream there
attaches the media we're

00:11:22.710 --> 00:11:26.120
getting from a video element
to the stream.

00:11:26.120 --> 00:11:29.390
Now, at the same time, we're
also creating what's called an

00:11:29.390 --> 00:11:32.930
offer, giving information about
media, and we're setting

00:11:32.930 --> 00:11:36.150
that as the local description,
and then sending that to the

00:11:36.150 --> 00:11:38.820
callee, so that they can set
the remote description.

00:11:38.820 --> 00:11:42.590
You can see that in the
gotAnswer function there.

00:11:42.590 --> 00:11:46.280
Let's have a little look at
RTCPeerConnection on one page,

00:11:46.280 --> 00:11:48.850
a very simple example here.

00:11:48.850 --> 00:11:54.730
So what we've got here
is getUserMedia here,

00:11:54.730 --> 00:11:55.665
just start that up.

00:11:55.665 --> 00:11:59.090
So it's getting video from the
local camera here, displaying

00:11:59.090 --> 00:12:00.210
it on the left there.

00:12:00.210 --> 00:12:05.320
Now when I press call, it's
using RTCPeerConnection to

00:12:05.320 --> 00:12:08.660
communicate that video
to the other--

00:12:08.660 --> 00:12:10.880
yeah, the other video element
on the page there.

00:12:10.880 --> 00:12:13.370
This is a great place to start
to get your head around

00:12:13.370 --> 00:12:14.770
RTCPeerConnection.

00:12:14.770 --> 00:12:18.940
And if we look in the code
there, you can see that it's

00:12:18.940 --> 00:12:19.710
really simple.

00:12:19.710 --> 00:12:22.420
There's not a lot of code there
to do that, to transmit

00:12:22.420 --> 00:12:24.820
video from one peer
to another.

00:12:27.370 --> 00:12:28.440
JUSTIN UBERTI: So that's
really cool stuff.

00:12:28.440 --> 00:12:31.310
A full video chat client in a
single web page, and just

00:12:31.310 --> 00:12:33.210
about 15 lines of JavaScript.

00:12:33.210 --> 00:12:35.250
And we talked a bit quickly
through the whole thing around

00:12:35.250 --> 00:12:37.350
how we set up the parameter of
the call, the offers and

00:12:37.350 --> 00:12:39.840
answers, but I'll come
back to that later.

00:12:39.840 --> 00:12:42.820
The next thing I want to talk
about is RTCDataChannel.

00:12:42.820 --> 00:12:45.540
And this says, if we have a peer
connection which already

00:12:45.540 --> 00:12:47.940
creates our peer-to-peer link
for us, can we send arbitrary

00:12:47.940 --> 00:12:49.520
application data over it?

00:12:49.520 --> 00:12:52.140
And this is the mechanism
that we use to do so.

00:12:52.140 --> 00:12:55.270
Now one example where we would
do this would be in a game.

00:12:55.270 --> 00:12:56.160
Like, take this game.

00:12:56.160 --> 00:12:58.500
I think it's called Jank
Wars or something.

00:12:58.500 --> 00:13:01.350
And we have all these ships
floating around onscreen.

00:13:01.350 --> 00:13:03.810
Now, when a ship moves, we
want to make sure that's

00:13:03.810 --> 00:13:06.680
communicated to the other player
as quickly as possible.

00:13:06.680 --> 00:13:09.650
And so we have this little JSON
object that contains the

00:13:09.650 --> 00:13:13.720
parameters and the position and
the velocity of the ships.

00:13:13.720 --> 00:13:16.880
And we can just take that object
and stuff it into the

00:13:16.880 --> 00:13:19.685
send method, and it will shoot
it across the other side where

00:13:19.685 --> 00:13:21.630
it pops out as onMessage.

00:13:21.630 --> 00:13:23.490
And the other side can
do the same thing.

00:13:23.490 --> 00:13:26.430
It can call send on its data
channel, and it works pretty

00:13:26.430 --> 00:13:28.860
much just like a WebSocket.

00:13:28.860 --> 00:13:30.140
That's not an accident.

00:13:30.140 --> 00:13:32.410
And we tried to design it that
way, so that people familiar

00:13:32.410 --> 00:13:35.490
with using WebSockets could
also use a similar API for

00:13:35.490 --> 00:13:37.020
RTCDataChannel.

00:13:37.020 --> 00:13:39.770
And the benefit is that here,
we have a peer-to-peer

00:13:39.770 --> 00:13:43.050
connection with the lowest
possible latency for doing

00:13:43.050 --> 00:13:44.540
this communication.

00:13:44.540 --> 00:13:46.460
In addition, RTCDataChannel.

00:13:46.460 --> 00:13:49.370
can be either unreliable
or reliable.

00:13:49.370 --> 00:13:53.140
And we can think about this kind
of like UDP versus TCP.

00:13:53.140 --> 00:13:55.200
If you're doing a game, it's
more important that your

00:13:55.200 --> 00:13:56.930
packets get there quickly
than they're

00:13:56.930 --> 00:13:58.310
guaranteed to get there.

00:13:58.310 --> 00:14:01.500
Whereas if you're doing a file
transfer, the files are only

00:14:01.500 --> 00:14:03.920
any good if the entire
file is delivered.

00:14:03.920 --> 00:14:07.230
So you can choose this as the
app developer, which mode you

00:14:07.230 --> 00:14:10.140
want to use, either unreliable
or reliable.

00:14:10.140 --> 00:14:13.130
And lastly, everything
is fully secure.

00:14:13.130 --> 00:14:16.580
We use standard DTLS encryption
to make sure that

00:14:16.580 --> 00:14:18.850
the packages you send across
the data channel are fully

00:14:18.850 --> 00:14:21.620
encrypted on their way
to the destination.

00:14:21.620 --> 00:14:24.240
And you can do this either with
audio and video, or if

00:14:24.240 --> 00:14:26.570
you want to make a peer
connection for just data, you

00:14:26.570 --> 00:14:29.120
can do that as well.

00:14:29.120 --> 00:14:31.500
So Sam's going to show us
how this actually works.

00:14:31.500 --> 00:14:33.800
SAM DUTTON: Yeah, so again,
another really simple example.

00:14:33.800 --> 00:14:38.330
We're creating a peer connection
here, and once the

00:14:38.330 --> 00:14:41.550
data channel is received, in
the callback to that, we're

00:14:41.550 --> 00:14:44.060
setting the receive
channel using the

00:14:44.060 --> 00:14:46.950
event.channel object.

00:14:46.950 --> 00:14:49.890
Now, when the receive channel
gets a message, kind of like

00:14:49.890 --> 00:14:55.670
WebSocket really, we're just
putting some text in a local

00:14:55.670 --> 00:14:57.910
div there, using event.data.

00:14:57.910 --> 00:15:00.360
Now, the send channel
was created with

00:15:00.360 --> 00:15:01.770
createDataChannel.

00:15:01.770 --> 00:15:03.770
And then we got a send button.

00:15:03.770 --> 00:15:07.280
When that's clicked, we get the
data from a text area, and

00:15:07.280 --> 00:15:10.580
we use the send channel to send
that to the other peer.

00:15:10.580 --> 00:15:12.800
Again, let's see
this in action.

00:15:12.800 --> 00:15:16.760
This is, again, a good place to
start-- one page demo, with

00:15:16.760 --> 00:15:19.245
all the code for RTCDataChannel,
so type in

00:15:19.245 --> 00:15:23.320
some text, and we hit send, and
it's transmitting it to

00:15:23.320 --> 00:15:25.850
the other text area.

00:15:25.850 --> 00:15:28.160
A great place to start
if you're looking at

00:15:28.160 --> 00:15:30.280
RTCDataChannel.

00:15:30.280 --> 00:15:32.750
Something a little more
useful here, a

00:15:32.750 --> 00:15:35.850
great app from Sharefest.

00:15:35.850 --> 00:15:39.170
Now, Sharefest is using
RTCDataChannel.

00:15:39.170 --> 00:15:40.790
to enable us to do
file sharing.

00:15:40.790 --> 00:15:43.600
I think I'm going to select a
nice photo here I've got of

00:15:43.600 --> 00:15:45.130
some cherries.

00:15:45.130 --> 00:15:47.130
And it's popeye, is the URL.

00:15:47.130 --> 00:15:51.400
And now Justin is going to try
and get that up on screen on

00:15:51.400 --> 00:15:54.000
his side, just to check that
that's gone through.

00:15:54.000 --> 00:15:57.470
So like I say, this is doing
file sharing using

00:15:57.470 --> 00:16:00.200
RTCDataChannel, and there's
a huge amount

00:16:00.200 --> 00:16:00.680
of potential there.

00:16:00.680 --> 00:16:00.930
There we go.

00:16:00.930 --> 00:16:01.960
Those are the cherries.

00:16:01.960 --> 00:16:03.400
JUSTIN UBERTI: I
love cherries.

00:16:03.400 --> 00:16:04.750
SAM DUTTON: These are beautiful
Mountain View

00:16:04.750 --> 00:16:05.370
cherries, actually.

00:16:05.370 --> 00:16:07.485
They were really, really nice.

00:16:07.485 --> 00:16:09.450
JUSTIN UBERTI: All this data
is being sent peer-to-peer,

00:16:09.450 --> 00:16:12.480
and anybody else who connects to
the same URL will download

00:16:12.480 --> 00:16:15.140
that data peer-to-peer
from Sam's machine.

00:16:15.140 --> 00:16:18.270
And so none of this has to
touch Sharefest servers.

00:16:18.270 --> 00:16:19.850
And I think that's pretty
interesting if you think about

00:16:19.850 --> 00:16:22.470
things like file transfer and
bulk video distribution.

00:16:31.390 --> 00:16:34.130
OK, so we talked a lot about
how we can do really clever

00:16:34.130 --> 00:16:38.080
peer-to-peer stuff with
RTCPeerConnection.

00:16:38.080 --> 00:16:40.090
But it turns out we need servers
to kind of get the

00:16:40.090 --> 00:16:41.960
process kicked off.

00:16:41.960 --> 00:16:44.790
And the first part of it is
actually making sure that both

00:16:44.790 --> 00:16:48.220
sides can agree to actually
conduct the session.

00:16:48.220 --> 00:16:51.800
And this is the process that
we call signaling.

00:16:51.800 --> 00:16:54.950
The signaling in WebRTC is
abstract, which means that

00:16:54.950 --> 00:16:56.660
there's no fully-defined
protocol on

00:16:56.660 --> 00:16:58.650
exactly how you do it.

00:16:58.650 --> 00:17:01.530
The key part is that you just
have to exchange session

00:17:01.530 --> 00:17:02.500
description objects.

00:17:02.500 --> 00:17:05.869
And if you think about this kind
of like a telephone call,

00:17:05.869 --> 00:17:07.990
when you make a call to someone,
the telephone network

00:17:07.990 --> 00:17:10.420
sends a message to the person
you're calling, telling them

00:17:10.420 --> 00:17:13.260
there's an incoming call and
the phone should ring.

00:17:13.260 --> 00:17:16.220
Then, when they answer the call,
they send a message back

00:17:16.220 --> 00:17:19.099
that says, the call
is now active.

00:17:19.099 --> 00:17:21.980
Now, these messages also contain
parameters around what

00:17:21.980 --> 00:17:24.880
media format to use, where the
person is on the network, and

00:17:24.880 --> 00:17:26.760
the same is true for WebRTC.

00:17:26.760 --> 00:17:28.580
And these things, these session
description objects,

00:17:28.580 --> 00:17:33.250
contain parameters like, what
codecs to use, what security

00:17:33.250 --> 00:17:35.750
keys to use, the network
information for setting up the

00:17:35.750 --> 00:17:37.360
peer-to-peer route.

00:17:37.360 --> 00:17:39.350
And the only important thing is
that you just send it from

00:17:39.350 --> 00:17:41.800
your side to the other
side, and vice versa.

00:17:41.800 --> 00:17:44.140
You can use any mechanism
you want--

00:17:44.140 --> 00:17:47.610
WebSockets, Google Cloud
Messaging, XHR.

00:17:47.610 --> 00:17:50.840
You can use any protocol, even
just send it as JSON, or you

00:17:50.840 --> 00:17:54.250
can use a standard protocols
like SIP or XMPP.

00:17:54.250 --> 00:17:57.490
Here's a picture of how
this all works.

00:17:57.490 --> 00:18:00.490
The app gets a session
description from the browser

00:18:00.490 --> 00:18:03.370
and sends it across through the
cloud to the other side.

00:18:03.370 --> 00:18:05.470
Once it gets the message back
from the other side with the

00:18:05.470 --> 00:18:08.870
other side's session
description, and both sessions

00:18:08.870 --> 00:18:12.380
consider passed down to WebRTC
in the browser, WebRTC can

00:18:12.380 --> 00:18:15.170
then set up and conduct the
media link peer-to-peer.

00:18:17.950 --> 00:18:21.250
So we do a lot to try to hide
the details of what's inside

00:18:21.250 --> 00:18:23.590
the RTCSessionDescription,
because this includes a whole

00:18:23.590 --> 00:18:24.830
bunch of parameters--

00:18:24.830 --> 00:18:26.810
as I said, codecs, network
information,

00:18:26.810 --> 00:18:27.700
all sorts of stuff--

00:18:27.700 --> 00:18:30.190
this is just a snippet of what's
contained inside a

00:18:30.190 --> 00:18:32.150
session description right now.

00:18:32.150 --> 00:18:34.950
Really advanced apps can do
complex behaviors by modifying

00:18:34.950 --> 00:18:38.650
this, but we designed API so
that regular apps just don't

00:18:38.650 --> 00:18:39.900
have to think about it.

00:18:43.840 --> 00:18:47.170
The other thing that we need
servers for is to actually get

00:18:47.170 --> 00:18:49.840
the peer-to-peer session
fully routed.

00:18:49.840 --> 00:18:54.062
And in the old days, this
wouldn't be a problem.

00:18:54.062 --> 00:18:59.150
A long time ago, each side
had a public IP address.

00:18:59.150 --> 00:19:01.190
They send each other's IP
address to each other through

00:19:01.190 --> 00:19:03.560
the cloud, and we make the link

00:19:03.560 --> 00:19:05.410
directly between the peers.

00:19:05.410 --> 00:19:09.690
Well, in the age of NAT, things
are more complicated.

00:19:09.690 --> 00:19:12.430
NATs hand out what's called a
private IP address, and these

00:19:12.430 --> 00:19:14.990
IP addresses are not useful
for communication.

00:19:14.990 --> 00:19:17.990
There's no way we can make the
link actually peer-to-peer

00:19:17.990 --> 00:19:21.320
unless we have public address.

00:19:21.320 --> 00:19:24.720
So this is where we bring a
technology called STUN.

00:19:24.720 --> 00:19:28.250
The STUN server we can contact
from WebRTC, and we say,

00:19:28.250 --> 00:19:30.180
what's my public IP address?

00:19:30.180 --> 00:19:32.650
And basically, the request comes
into the STUN server, it

00:19:32.650 --> 00:19:35.440
sees the address that that
request came from, puts the

00:19:35.440 --> 00:19:37.650
address into the packet,
and sends it back.

00:19:37.650 --> 00:19:41.000
So now WebRTC knows its public
IP address, and the STUN

00:19:41.000 --> 00:19:43.550
server doesn't have to be in
the party anymore, doesn't

00:19:43.550 --> 00:19:45.560
have to have media flowing
through it.

00:19:45.560 --> 00:19:48.910
So here, if you look at this
example, each side has

00:19:48.910 --> 00:19:51.620
contacted that STUN server to
find out what its public IP

00:19:51.620 --> 00:19:52.530
address is.

00:19:52.530 --> 00:19:55.750
And then it's sent the traffic
to the other IP address

00:19:55.750 --> 00:19:59.400
through its NAT, and the data
still flows peer-to-peer.

00:19:59.400 --> 00:20:03.720
So this is kind of magic stuff,
and it usually works.

00:20:03.720 --> 00:20:06.720
Usually we can make sure that
the data all flows properly

00:20:06.720 --> 00:20:09.420
peer-to-peer, but not
in every case.

00:20:09.420 --> 00:20:12.120
And for that, we have a
technology called TURN built

00:20:12.120 --> 00:20:14.020
into WebRTC.

00:20:14.020 --> 00:20:18.310
This turn things around and
provides a cloud fallback when

00:20:18.310 --> 00:20:21.940
a peer-to-peer link is
impossible, basically asks for

00:20:21.940 --> 00:20:25.040
a relay in the cloud, saying,
give me a public address.

00:20:25.040 --> 00:20:26.870
And because this public address
is in the cloud,

00:20:26.870 --> 00:20:30.300
anybody can contact it, which
means the call always sets up,

00:20:30.300 --> 00:20:32.460
even if you're behind
a restrictive, or

00:20:32.460 --> 00:20:34.890
even behind a proxy.

00:20:34.890 --> 00:20:37.130
The downside is that since the
data actually is being relayed

00:20:37.130 --> 00:20:39.850
through the server, there is
an operational cost to it.

00:20:39.850 --> 00:20:41.520
But it does mean the call
works in almost all

00:20:41.520 --> 00:20:43.030
environments.

00:20:43.030 --> 00:20:46.860
Now, on one hand, we have STUN,
which is super cheap,

00:20:46.860 --> 00:20:47.790
but doesn't always work.

00:20:47.790 --> 00:20:49.900
And we have TURN, which
always works, but has

00:20:49.900 --> 00:20:51.090
some cost to it.

00:20:51.090 --> 00:20:55.260
How do we make sure we get
the best of both worlds?

00:20:55.260 --> 00:20:59.710
Here's TURN in action, where
we try to use STUN and STUN

00:20:59.710 --> 00:21:00.885
didn't work.

00:21:00.885 --> 00:21:02.600
And we couldn't get the
things to actually

00:21:02.600 --> 00:21:03.600
penetrate the NATs.

00:21:03.600 --> 00:21:04.880
So instead, we fell back.

00:21:04.880 --> 00:21:08.470
Only then did we use TURN, and
sent the media from our one

00:21:08.470 --> 00:21:11.190
peer, through the NAT, through
the TURN server, and to the

00:21:11.190 --> 00:21:12.740
other side.

00:21:12.740 --> 00:21:15.960
And this is all done by a
technology called ICE.

00:21:15.960 --> 00:21:19.640
ICE knows about STUN and TURN,
and tries all the things in

00:21:19.640 --> 00:21:22.690
parallel to figure out the
best path for the call.

00:21:22.690 --> 00:21:24.990
If it can do STUN,
it does STUN.

00:21:24.990 --> 00:21:27.620
If it can do TURN, well then
I'll fall back to TURN, but

00:21:27.620 --> 00:21:28.920
I'll do so quickly.

00:21:28.920 --> 00:21:31.810
And we have stats from a
deployed WebRTC application

00:21:31.810 --> 00:21:34.850
that says 86% of the time,
we can make things

00:21:34.850 --> 00:21:36.930
work with just STUN.

00:21:36.930 --> 00:21:39.130
So only one out of seven calls
actually have to run through a

00:21:39.130 --> 00:21:41.550
TURN server.

00:21:41.550 --> 00:21:44.000
So how do you deploy TURN
for your application?

00:21:44.000 --> 00:21:48.940
Well, we have some testing
servers, a testing STUN server

00:21:48.940 --> 00:21:51.400
that you can use, plus we make
source code available for our

00:21:51.400 --> 00:21:52.620
own STUN and TURN server
as part of

00:21:52.620 --> 00:21:54.540
the WebRTC code package.

00:21:54.540 --> 00:21:57.050
But the thing I would really
recommend is the long name,

00:21:57.050 --> 00:21:58.290
but really good product--

00:21:58.290 --> 00:22:01.320
rfc5766-turn-server--

00:22:01.320 --> 00:22:04.170
which has Amazon VM images
that you can just take,

00:22:04.170 --> 00:22:07.270
download, and deploy into the
cloud, and you've got your

00:22:07.270 --> 00:22:09.880
TURN server provisioned for all
your users right there.

00:22:09.880 --> 00:22:12.900
I also recommend restund,
another TURN server that we've

00:22:12.900 --> 00:22:14.150
used with excellent results.

00:22:18.160 --> 00:22:20.590
One question that comes up
around WebRTC is, how is

00:22:20.590 --> 00:22:22.620
security handled?

00:22:22.620 --> 00:22:25.070
And the great thing is that
security has been built into

00:22:25.070 --> 00:22:27.850
WebRTC from the very beginning,
and so this means

00:22:27.850 --> 00:22:29.860
several different things.

00:22:29.860 --> 00:22:32.040
It means we have mandatory
encryption for

00:22:32.040 --> 00:22:34.070
both media and data.

00:22:34.070 --> 00:22:36.560
So all the data that's being
sent by WebRTC is being

00:22:36.560 --> 00:22:40.300
encrypted using standard
AES encryption.

00:22:40.300 --> 00:22:42.540
We also have secure UI, meaning
the user's camera

00:22:42.540 --> 00:22:45.030
microphone can only be accessed
if they've explicitly

00:22:45.030 --> 00:22:47.860
opted in to making that
functionality available.

00:22:47.860 --> 00:22:51.050
And last, WebRTC runs inside
the Chrome sandbox.

00:22:51.050 --> 00:22:53.720
So even if somebody tries to
attack WebRTC inside of

00:22:53.720 --> 00:22:56.395
Chrome, the browser and the user
will be fully protected.

00:22:58.930 --> 00:23:00.660
So here's what you need to do
to take advantage of the

00:23:00.660 --> 00:23:03.260
security in WebRTC,
is really simple.

00:23:03.260 --> 00:23:05.705
Your app just needs
to use HTTPS for

00:23:05.705 --> 00:23:07.070
actually doing the signaling.

00:23:07.070 --> 00:23:09.710
As long as the signaling goes
over a secure conduit, the

00:23:09.710 --> 00:23:12.410
data will be fully secured as
well using the standard

00:23:12.410 --> 00:23:16.550
protocols of SRTP for media
or Datagram TLS

00:23:16.550 --> 00:23:17.800
for the data channel.

00:23:21.000 --> 00:23:23.710
One more question that comes
up is around making a

00:23:23.710 --> 00:23:25.810
multi-party call, a
conference call.

00:23:25.810 --> 00:23:28.860
How should I architect
my application?

00:23:28.860 --> 00:23:31.210
In the simple two-party
case, it's easy.

00:23:31.210 --> 00:23:33.200
We just have a peer-to-peer
link.

00:23:33.200 --> 00:23:35.800
But as you start adding more
peers into the mix, things get

00:23:35.800 --> 00:23:37.270
a bit more complicated.

00:23:37.270 --> 00:23:40.510
And one approach that people use
is a mesh, where basically

00:23:40.510 --> 00:23:43.220
every peer connects to
every other peer.

00:23:43.220 --> 00:23:45.790
And this is really simple,
because there's no servers or

00:23:45.790 --> 00:23:49.380
anything involved, other than
the signaling stuff.

00:23:49.380 --> 00:23:52.090
But every peer has to send
and copy this data

00:23:52.090 --> 00:23:53.220
to every other peer.

00:23:53.220 --> 00:23:56.960
So this has a corresponding
CPU and bandwidth cost.

00:23:56.960 --> 00:23:59.140
So depending on the media
you're trying to send--

00:23:59.140 --> 00:24:00.350
for audio, it can be
kind of higher.

00:24:00.350 --> 00:24:02.520
For video, it's going to be
less-- the number of peers you

00:24:02.520 --> 00:24:05.680
can support in this topology is
fairly limited, especially

00:24:05.680 --> 00:24:09.390
if one of the peers is
on a mobile device.

00:24:09.390 --> 00:24:11.650
To deal with that another
architecture that can be used

00:24:11.650 --> 00:24:13.730
is the star architecture.

00:24:13.730 --> 00:24:16.970
And here, you can pick the most
capable device to be what

00:24:16.970 --> 00:24:18.820
we call the focus
for the call.

00:24:18.820 --> 00:24:20.970
And the focus is the part that's
actually responsible

00:24:20.970 --> 00:24:23.610
for taking the data and sending
a copy to each of the

00:24:23.610 --> 00:24:26.020
other endpoints.

00:24:26.020 --> 00:24:29.510
But as we get to handing
multiple HD video streams, the

00:24:29.510 --> 00:24:31.860
job for a focus becomes
pretty difficult.

00:24:31.860 --> 00:24:35.150
And so for the most robust
conferencing architecture, we

00:24:35.150 --> 00:24:40.300
recommend an MCU, or multipoint
control unit.

00:24:40.300 --> 00:24:43.970
And this is a server that's
custom made for relaying large

00:24:43.970 --> 00:24:45.540
amounts of audio and video.

00:24:45.540 --> 00:24:46.810
And it can do various things.

00:24:46.810 --> 00:24:49.140
It can do selective
stream forwarding.

00:24:49.140 --> 00:24:51.660
It can actually mix the
audio or video data.

00:24:51.660 --> 00:24:53.700
It can also do things
like recording.

00:24:53.700 --> 00:24:56.370
And so if one peer drops out, it
doesn't interrupt the whole

00:24:56.370 --> 00:24:58.505
conference, because the MCU is
taking care of everything.

00:25:02.530 --> 00:25:05.280
So WebRTC is made with
standards in mind.

00:25:05.280 --> 00:25:06.880
And so you can connect
things that

00:25:06.880 --> 00:25:09.380
aren't even WebRTC devices.

00:25:09.380 --> 00:25:13.160
And one thing that people want
to talk from WebRTC is phones.

00:25:13.160 --> 00:25:14.792
And there's a bunch of easy
things they can be dropped

00:25:14.792 --> 00:25:16.920
into your web page to
make this happen.

00:25:16.920 --> 00:25:20.030
There's a sipML5, which is
a way to talk to various

00:25:20.030 --> 00:25:23.710
standard SIP devices, Phono, and
what we're going to show

00:25:23.710 --> 00:25:26.861
you now, a widget from Zingaya
to make a phone call.

00:25:30.550 --> 00:25:35.950
SAM DUTTON: OK, so we've got a
special guest joining us a

00:25:35.950 --> 00:25:37.440
little bit later in
the presentation.

00:25:37.440 --> 00:25:40.130
I just wanted to give him a call
to see if he's available.

00:25:40.130 --> 00:25:44.890
So let's use the Zingaya
WebRTC phone app now.

00:25:44.890 --> 00:25:47.240
And you could see, it's
accessing my microphone.

00:25:47.240 --> 00:25:48.090
[PHONE DIALING AND RINGING]

00:25:48.090 --> 00:25:49.210
SAM DUTTON: Calling someone.

00:25:49.210 --> 00:25:50.510
I hope it's the person I want.

00:25:50.510 --> 00:25:54.166
[PHONE RINGING]

00:25:54.166 --> 00:25:55.416
SAM DUTTON: See if he's there.

00:25:59.640 --> 00:26:00.610
CHRIS WILSON: Hello?

00:26:00.610 --> 00:26:02.000
SAM DUTTON: Hey.

00:26:02.000 --> 00:26:02.830
Is that you, Chris?

00:26:02.830 --> 00:26:03.320
CHRIS WILSON: Hey, Sam.

00:26:03.320 --> 00:26:03.950
How's it going?

00:26:03.950 --> 00:26:04.290
It is.

00:26:04.290 --> 00:26:04.970
SAM DUTTON: Hey.

00:26:04.970 --> 00:26:06.260
Fantastic.

00:26:06.260 --> 00:26:10.541
I just want to check you're
ready for your gig later on.

00:26:10.541 --> 00:26:11.960
CHRIS WILSON: I'm ready
whenever you are.

00:26:11.960 --> 00:26:12.970
SAM DUTTON: That's fantastic.

00:26:12.970 --> 00:26:14.280
OK, speak to you soon, Chris.

00:26:14.280 --> 00:26:14.740
Thanks.

00:26:14.740 --> 00:26:15.060
Bye bye.

00:26:15.060 --> 00:26:15.990
CHRIS WILSON: Talk
to you soon.

00:26:15.990 --> 00:26:16.640
Bye.

00:26:16.640 --> 00:26:18.920
SAM DUTTON: Cheers.

00:26:18.920 --> 00:26:20.590
JUSTIN UBERTI: It's great--
no plugins, realtime

00:26:20.590 --> 00:26:21.840
communication.

00:26:26.840 --> 00:26:29.230
SAM DUTTON: Yeah, that
situation, we had

00:26:29.230 --> 00:26:30.770
a guy with a telephone.

00:26:30.770 --> 00:26:33.630
Something we were thinking
about is situations where

00:26:33.630 --> 00:26:36.790
there is no telephone network.

00:26:36.790 --> 00:26:40.100
Now, Voxio demonstrated this
with something called Tethr,

00:26:40.100 --> 00:26:44.020
which is kind of disaster
communications in a box.

00:26:44.020 --> 00:26:48.410
It uses the open BTS cell
framework-- you can see, it's

00:26:48.410 --> 00:26:51.630
that little box there-- to
enable calls between feature

00:26:51.630 --> 00:26:57.630
phones via the open BTS cell
through WebRTC to computers.

00:26:57.630 --> 00:27:00.920
You can imagine this is kind
of fun to get a license for

00:27:00.920 --> 00:27:02.780
this in downtown San Francisco,
but this is

00:27:02.780 --> 00:27:07.560
incredibly useful in situations
where there is no

00:27:07.560 --> 00:27:09.670
infrastructure.

00:27:09.670 --> 00:27:11.420
Yeah, this is like telephony
without a

00:27:11.420 --> 00:27:12.875
carrier, which is amazing.

00:27:15.810 --> 00:27:17.660
JUSTIN UBERTI: So we have a code
lab this afternoon that I

00:27:17.660 --> 00:27:19.220
hope you can come to, where
I'll really go into the

00:27:19.220 --> 00:27:23.220
details of exactly how to build
a WebRTC application.

00:27:23.220 --> 00:27:24.940
But now we're going to talk
about some resources that I

00:27:24.940 --> 00:27:27.430
think are really useful.

00:27:27.430 --> 00:27:31.050
The first one is something
called WebRTC Internals.

00:27:31.050 --> 00:27:34.030
And this is a page you can open
up just by going to this

00:27:34.030 --> 00:27:35.950
URL while you're in
a WebRTC call.

00:27:35.950 --> 00:27:38.920
And it'll show all sorts of
great statistics about what's

00:27:38.920 --> 00:27:42.340
actually happening
inside your call.

00:27:42.340 --> 00:27:46.820
This would be things like packet
loss, bandwidth, video

00:27:46.820 --> 00:27:48.450
resolution and sizes.

00:27:48.450 --> 00:27:51.370
And there's also a full log of
all the calls made to the

00:27:51.370 --> 00:27:54.510
WebRTC API that you can
download and export.

00:27:54.510 --> 00:27:57.840
So if a customer's reporting
problems with their call, you

00:27:57.840 --> 00:27:59.930
can easily get this debugging
information from them.

00:28:02.450 --> 00:28:04.520
Another thing is, the
WebRTC spec has been

00:28:04.520 --> 00:28:06.520
updating fairly rapidly.

00:28:06.520 --> 00:28:09.660
And so in a given browser, the
API might not always match the

00:28:09.660 --> 00:28:10.550
latest spec.

00:28:10.550 --> 00:28:13.990
Well, adapter.js is something
that's there to insulate the

00:28:13.990 --> 00:28:16.680
web developer from the
differences between browsers

00:28:16.680 --> 00:28:18.600
and the differences
between versions.

00:28:18.600 --> 00:28:21.180
And so we make sure that
adapter.js always implements

00:28:21.180 --> 00:28:25.060
the latest spec, and then thunks
down to whatever the

00:28:25.060 --> 00:28:26.900
version supports.

00:28:26.900 --> 00:28:29.730
So as new APIs are added, we
polyfill them to make sure

00:28:29.730 --> 00:28:32.100
that you don't have to write
custom version code or custom

00:28:32.100 --> 00:28:33.480
browser code for each browser.

00:28:33.480 --> 00:28:34.830
And we use this in our
own applications.

00:28:37.590 --> 00:28:41.840
SAM DUTTON: OK, if all this is
too much for you, good news

00:28:41.840 --> 00:28:44.660
is, we've got some fantastic
JavaScript frameworks come up

00:28:44.660 --> 00:28:48.130
in the last few months, really
great abstraction libraries to

00:28:48.130 --> 00:28:51.940
make it really, really simple to
build WebRTC apps just with

00:28:51.940 --> 00:28:53.320
a few lines of code.

00:28:53.320 --> 00:28:56.240
Example here from SimpleWebRTC,
a little bit of

00:28:56.240 --> 00:29:00.370
JavaScript there to specify a
video element that represents

00:29:00.370 --> 00:29:02.820
local video, and one that
represents the remote video

00:29:02.820 --> 00:29:04.120
stream coming in.

00:29:04.120 --> 00:29:07.590
And then join a room just by
calling the joinRoom method

00:29:07.590 --> 00:29:08.670
with a room name--

00:29:08.670 --> 00:29:10.450
really, really simple.

00:29:10.450 --> 00:29:13.840
PeerJS does something similar
for RTCDataChannel--

00:29:13.840 --> 00:29:16.660
create a peer, and then on
connection, you can send

00:29:16.660 --> 00:29:22.740
messages, receive messages, so
really, really easy to use.

00:29:22.740 --> 00:29:25.280
JUSTIN UBERTI: So JavaScript
frameworks go a long way, but

00:29:25.280 --> 00:29:26.440
they don't cover the production

00:29:26.440 --> 00:29:27.710
aspects of the service--

00:29:27.710 --> 00:29:30.420
the signaling, the STUN and TURN
service we talked about.

00:29:30.420 --> 00:29:34.115
But fortunately, we have things
from both OpenTok and

00:29:34.115 --> 00:29:37.350
Vline that are basically turnkey
WebRTC services that

00:29:37.350 --> 00:29:39.512
handle all this stuff for you.

00:29:39.512 --> 00:29:42.930
You basically sign up for the
service, get an API key, and

00:29:42.930 --> 00:29:44.830
then you can make calls
using their production

00:29:44.830 --> 00:29:46.210
infrastructure, which is spread

00:29:46.210 --> 00:29:48.420
throughout the entire globe.

00:29:48.420 --> 00:29:50.860
They also make UI widgets that
can be easily dropped into

00:29:50.860 --> 00:29:52.040
your WebRTC app.

00:29:52.040 --> 00:29:57.200
So you get up and running
with WebRTC super fast.

00:29:57.200 --> 00:30:01.080
Now, we've got a special
treat for you today.

00:30:01.080 --> 00:30:03.640
Chris Wilson, a colleague of
ours, and a developer in the

00:30:03.640 --> 00:30:06.690
original Mosaic browser, and
an occasional musician as

00:30:06.690 --> 00:30:10.720
well, is going to be joining us
courtesy of WebRTC to show

00:30:10.720 --> 00:30:14.820
off the HD video quality and
full-band audio quality that

00:30:14.820 --> 00:30:18.850
we're now able to offer in the
latest version of Chrome.

00:30:18.850 --> 00:30:20.960
Take it away, Chris.

00:30:20.960 --> 00:30:21.600
CHRIS WILSON: Hey, guys.

00:30:21.600 --> 00:30:22.350
SAM DUTTON: Hey, Chris.

00:30:22.350 --> 00:30:23.362
How's it going?

00:30:23.362 --> 00:30:24.040
CHRIS WILSON: I'm good.

00:30:24.040 --> 00:30:24.670
How are you?

00:30:24.670 --> 00:30:25.860
SAM DUTTON: Yeah, good.

00:30:25.860 --> 00:30:28.840
Have you got some kind of
musical instrument with you?

00:30:28.840 --> 00:30:29.380
CHRIS WILSON: I do.

00:30:29.380 --> 00:30:31.620
You know, originally
you asked me for a

00:30:31.620 --> 00:30:33.810
face-melting guitar solo.

00:30:33.810 --> 00:30:35.530
But I'm a little more
relaxed now.

00:30:35.530 --> 00:30:37.150
I/O is starting to wind down.

00:30:37.150 --> 00:30:39.190
You can tell I've already got
my Hawaiian shirt on.

00:30:39.190 --> 00:30:40.630
I'm not ready for
some vacation.

00:30:40.630 --> 00:30:44.170
So I figured I'd bring my
ukulele and hook it up through

00:30:44.170 --> 00:30:48.120
a nice microphone here, so we
can listen to how that sounds.

00:30:48.120 --> 00:30:48.670
SAM DUTTON: Take it away.

00:30:48.670 --> 00:30:50.710
Melt my face, Chris.

00:30:50.710 --> 00:30:55.430
[PLAYING UKULELE]

00:30:55.430 --> 00:30:57.192
SAM DUTTON: That's
pretty good.

00:30:57.192 --> 00:30:58.442
JUSTIN UBERTI: He's
pretty good.

00:31:03.110 --> 00:31:03.400
All right.

00:31:03.400 --> 00:31:04.410
SAM DUTTON: That
was beautiful.

00:31:04.410 --> 00:31:05.228
Thank you, Chris.

00:31:05.228 --> 00:31:06.980
[APPLAUSE]

00:31:06.980 --> 00:31:08.300
CHRIS WILSON: All right, guys.

00:31:08.300 --> 00:31:09.490
JUSTIN UBERTI: Chris
Wilson, everybody.

00:31:09.490 --> 00:31:11.490
SAM DUTTON: The audience
has gone crazy, Chris.

00:31:11.490 --> 00:31:14.830
Thank you very much.

00:31:14.830 --> 00:31:16.720
JUSTIN UBERTI: You want
to finish up?

00:31:16.720 --> 00:31:17.240
SAM DUTTON: Yeah.

00:31:17.240 --> 00:31:20.810
So, we've had-- well, a fraction
over 30 minutes to

00:31:20.810 --> 00:31:22.380
cover a really big topic.

00:31:22.380 --> 00:31:26.010
There's a great lot of more
information out there online,

00:31:26.010 --> 00:31:29.270
some good stuff on HTML5 Rocks,
and a really good

00:31:29.270 --> 00:31:32.140
e-book too, if you want to
take a look at that.

00:31:32.140 --> 00:31:34.860
There are several ways
to contact us.

00:31:34.860 --> 00:31:36.570
There's a great Google group--

00:31:36.570 --> 00:31:38.280
discuss-webrtc--

00:31:38.280 --> 00:31:40.320
post your technical questions.

00:31:40.320 --> 00:31:43.670
All the kind of new news for
WebRTC comes through on

00:31:43.670 --> 00:31:46.040
Google+ and Twitter stream.

00:31:46.040 --> 00:31:49.140
And we're really grateful of
all the people, all of you

00:31:49.140 --> 00:31:52.550
who've submitted feature
requests and bugs.

00:31:52.550 --> 00:31:56.600
And please keep them coming,
and the URL for that is

00:31:56.600 --> 00:31:58.650
crbug.com/new.

00:31:58.650 --> 00:32:01.620
So thank you for that.

00:32:01.620 --> 00:32:06.500
[APPLAUSE]

00:32:06.500 --> 00:32:08.260
JUSTIN UBERTI: And so we've
built this stuff into the web

00:32:08.260 --> 00:32:10.980
platform to make realtime
communication

00:32:10.980 --> 00:32:12.470
accessible to everyone.

00:32:12.470 --> 00:32:15.510
And we're super excited because
we can't wait to see

00:32:15.510 --> 00:32:17.410
what you all are
going to build.

00:32:17.410 --> 00:32:19.460
So thank you for coming.

00:32:19.460 --> 00:32:22.500
Once again, the link.

00:32:22.500 --> 00:32:24.310
And now, if you have any
questions, we'll be happy to

00:32:24.310 --> 00:32:25.310
try to answer them.

00:32:25.310 --> 00:32:26.160
Thank you very much.

00:32:26.160 --> 00:32:26.530
SAM DUTTON: Yeah.

00:32:26.530 --> 00:32:27.050
Thank you.

00:32:27.050 --> 00:32:38.430
[APPLAUSE]

00:32:38.430 --> 00:32:38.610
AUDIENCE: Hi.

00:32:38.610 --> 00:32:40.450
My name is Mark.

00:32:40.450 --> 00:32:43.740
I like to know, because I'm
using Linux and Ubuntu, how

00:32:43.740 --> 00:32:46.890
finally can I get rid of the
talk plugin for using Hangouts

00:32:46.890 --> 00:32:49.790
in Google+?

00:32:49.790 --> 00:32:51.870
JUSTIN UBERTI: The question
is, when can we get rid of

00:32:51.870 --> 00:32:53.420
that Hangouts plug-in?

00:32:53.420 --> 00:32:55.950
And so unfortunately, we
can only talk about

00:32:55.950 --> 00:32:57.010
WebRTC matters today.

00:32:57.010 --> 00:32:58.090
That's handled by
another team.

00:32:58.090 --> 00:32:59.820
But let's say that there
are many of us who

00:32:59.820 --> 00:33:01.210
have the same feeling.

00:33:01.210 --> 00:33:01.485
AUDIENCE: OK.

00:33:01.485 --> 00:33:02.210
Great.

00:33:02.210 --> 00:33:05.360
[LAUGHTER]

00:33:05.360 --> 00:33:07.920
AUDIENCE: Can you make any
comments on Microsoft's

00:33:07.920 --> 00:33:11.630
competing standard, considering
they kind of hold

00:33:11.630 --> 00:33:16.670
the cards with Skype, and how
maybe we can go forward

00:33:16.670 --> 00:33:20.430
supporting both or maybe
converge the two, or just your

00:33:20.430 --> 00:33:22.230
thoughts on that?

00:33:22.230 --> 00:33:26.110
JUSTIN UBERTI: So Microsoft
has actually been a great

00:33:26.110 --> 00:33:27.560
participant in standards.

00:33:27.560 --> 00:33:30.460
They have several people they
sent from their team.

00:33:30.460 --> 00:33:33.140
And although they don't see
things exactly the same way

00:33:33.140 --> 00:33:37.110
that we do, I think that the API
differences are sort of,

00:33:37.110 --> 00:33:39.290
theirs is a lot more low-level,
geared for expert

00:33:39.290 --> 00:33:39.800
developers.

00:33:39.800 --> 00:33:41.990
Ours is a little more
high-level, geared for web

00:33:41.990 --> 00:33:42.920
developers.

00:33:42.920 --> 00:33:46.020
And I think that really what
you can do is you can

00:33:46.020 --> 00:33:48.830
implement the high-level one on
top of the low-level one,

00:33:48.830 --> 00:33:50.360
maybe even vice versa.

00:33:50.360 --> 00:33:55.190
So Microsoft is a little more
secretive about what they do.

00:33:55.190 --> 00:33:57.300
So we don't know exactly
what their timeframe

00:33:57.300 --> 00:33:58.670
is relative to IE.

00:33:58.670 --> 00:34:00.500
But they're fully
participating.

00:34:00.500 --> 00:34:02.470
And obviously, they're very
interested in Skype.

00:34:02.470 --> 00:34:06.070
So I'm very optimistic that
we'll see a version of IE that

00:34:06.070 --> 00:34:09.170
supports this technology in the
not-too-distant future.

00:34:09.170 --> 00:34:09.679
AUDIENCE: Very good to hear.

00:34:09.679 --> 00:34:10.929
Thank you.

00:34:12.909 --> 00:34:15.500
AUDIENCE: My question would be,
I think you mentioned it

00:34:15.500 --> 00:34:16.540
quickly in the beginning.

00:34:16.540 --> 00:34:20.090
So if I wanted to communicate
with WebRTC, but one, I'm

00:34:20.090 --> 00:34:21.679
using a different environment
than the browser.

00:34:21.679 --> 00:34:24.800
Let's say I want a web
application to speak to a

00:34:24.800 --> 00:34:25.510
native Android app.

00:34:25.510 --> 00:34:29.550
So what would be the approach to
integrate that with WebRTC?

00:34:29.550 --> 00:34:31.620
JUSTIN UBERTI: As I mentioned
earlier, we have a fully

00:34:31.620 --> 00:34:35.780
supported official native
version of pure connection,

00:34:35.780 --> 00:34:38.420
PureConnection.Java, which is
open source, and you can

00:34:38.420 --> 00:34:40.330
download, and you can build
that into your native

00:34:40.330 --> 00:34:41.179
application.

00:34:41.179 --> 00:34:42.159
And it interoperates.

00:34:42.159 --> 00:34:43.790
We have a demo app that
interoperates with

00:34:43.790 --> 00:34:45.670
our AppRTC demo app.

00:34:45.670 --> 00:34:51.340
So I think that using Chrome for
Android in a web view is

00:34:51.340 --> 00:34:52.639
one thing you can think about.

00:34:52.639 --> 00:34:54.969
But if that doesn't work for
you, we have a native version

00:34:54.969 --> 00:34:56.360
that works great.

00:34:56.360 --> 00:34:56.659
AUDIENCE: OK.

00:34:56.659 --> 00:34:58.890
Thank you.

00:34:58.890 --> 00:34:59.460
AUDIENCE: Hi.

00:34:59.460 --> 00:35:02.690
My question would be, are there
any things that to be

00:35:02.690 --> 00:35:05.370
taken care between cross-browser
compatibility

00:35:05.370 --> 00:35:08.550
for this Firefox Chrome?

00:35:08.550 --> 00:35:10.170
Anything specific that
needs to be taken

00:35:10.170 --> 00:35:12.750
care, or it just works?

00:35:12.750 --> 00:35:14.480
JUSTIN UBERTI: There are
some minor differences.

00:35:14.480 --> 00:35:17.720
I mentioned adapter.js covers
some of the things where the

00:35:17.720 --> 00:35:21.190
API isn't quite in sync
in both places.

00:35:21.190 --> 00:35:25.470
One specific thing is that
Firefox only supports the opus

00:35:25.470 --> 00:35:28.780
codec, and they only support
DTLS encryption.

00:35:28.780 --> 00:35:32.040
They don't support something
called S-DES,

00:35:32.040 --> 00:35:33.290
that we also support.

00:35:33.290 --> 00:35:37.880
So for right now, you have to
set one parameter in the API,

00:35:37.880 --> 00:35:42.500
and you can see that in our app
RTC source code, to make

00:35:42.500 --> 00:35:44.870
sure that communication
actually uses

00:35:44.870 --> 00:35:46.370
those compatible protocols.

00:35:46.370 --> 00:35:48.530
We actually have a document,
though, on our web page, the

00:35:48.530 --> 00:35:51.130
documents exactly what you have
to do, which is really

00:35:51.130 --> 00:35:53.890
setting a single constraint
parameter when you're creating

00:35:53.890 --> 00:35:55.020
your peer connection object.

00:35:55.020 --> 00:35:55.480
SAM DUTTON: Yeah.

00:35:55.480 --> 00:35:58.120
If you go to webrtc.org/interop.

00:35:58.120 --> 00:35:58.450
JUSTIN UBERTI: Yeah.

00:35:58.450 --> 00:36:00.280
That works at org/interop.

00:36:00.280 --> 00:36:00.700
AUDIENCE: OK.

00:36:00.700 --> 00:36:03.170
Thank you.

00:36:03.170 --> 00:36:05.180
AUDIENCE: When a peer connection
is made and it

00:36:05.180 --> 00:36:11.020
falls back to TURN, does the
TURN server, is it capable of

00:36:11.020 --> 00:36:14.740
unencrypting the messages that
go between the two endpoints?

00:36:14.740 --> 00:36:15.170
JUSTIN UBERTI: No.

00:36:15.170 --> 00:36:17.480
The TURN server is just
a packet relay.

00:36:17.480 --> 00:36:19.340
So this stuff is fully
encrypted.

00:36:19.340 --> 00:36:21.150
It doesn't have the keying
information to

00:36:21.150 --> 00:36:21.860
do anything to it.

00:36:21.860 --> 00:36:25.285
So the TURN server just takes a
byte, sends a byte, takes a

00:36:25.285 --> 00:36:28.260
packet, sends a packet.

00:36:28.260 --> 00:36:30.960
AUDIENCE: So for keeping data
in sync with low latency

00:36:30.960 --> 00:36:34.670
between, say, an Android
application and the server,

00:36:34.670 --> 00:36:42.210
how would both the native
and the Android Chrome

00:36:42.210 --> 00:36:46.770
implementations of WebRTC fare
in terms of battery life?

00:36:46.770 --> 00:36:50.900
JUSTIN UBERTI: I don't really
have a good answer for that.

00:36:50.900 --> 00:36:52.410
I wouldn't think there would
be much difference.

00:36:52.410 --> 00:36:54.010
I mean, the key things that
are going to be driving

00:36:54.010 --> 00:36:55.990
battery consumption
in this case--

00:36:55.990 --> 00:36:57.180
are you talking about data,
or are you talking

00:36:57.180 --> 00:36:58.910
about audio and video?

00:36:58.910 --> 00:37:00.150
AUDIENCE: Data.

00:37:00.150 --> 00:37:01.800
JUSTIN UBERTI: For data, the
key drivers of your power

00:37:01.800 --> 00:37:04.330
consumption are going to be the
screen and the network.

00:37:04.330 --> 00:37:07.490
And so I think those should be
comparable between Chrome for

00:37:07.490 --> 00:37:09.900
Android and the native
application.

00:37:09.900 --> 00:37:10.620
AUDIENCE: OK, cool.

00:37:10.620 --> 00:37:11.870
Thanks.

00:37:14.370 --> 00:37:18.380
AUDIENCE: With two computers
running Chrome, or what have

00:37:18.380 --> 00:37:22.180
you seen glass-to-glass
latency?

00:37:22.180 --> 00:37:23.240
JUSTIN UBERTI: Repeat?

00:37:23.240 --> 00:37:25.790
AUDIENCE: Glass-to-glass, so
from the camera to the LCD.

00:37:25.790 --> 00:37:27.040
JUSTIN UBERTI: Oh, yeah.

00:37:29.270 --> 00:37:32.700
So it depends on a platform,
because the camera can have a

00:37:32.700 --> 00:37:36.290
large delay built
into it itself.

00:37:36.290 --> 00:37:41.060
Also, some of the audio
things have higher

00:37:41.060 --> 00:37:41.590
latencies than others.

00:37:41.590 --> 00:37:44.770
But the overall target is 150
milliseconds end-to-end.

00:37:44.770 --> 00:37:48.530
And we've seen lower than 100
milliseconds in best case

00:37:48.530 --> 00:37:51.286
solutions for glass-to-glass
type latency.

00:37:51.286 --> 00:37:51.640
AUDIENCE: OK.

00:37:51.640 --> 00:37:56.495
And how are you ensuring
priority of your data across

00:37:56.495 --> 00:37:58.780
the network?

00:37:58.780 --> 00:38:00.880
JUSTIN UBERTI: That's a complex

00:38:00.880 --> 00:38:03.150
question with a long answer.

00:38:03.150 --> 00:38:05.720
But the basic thing, are you
saying, how do we compete with

00:38:05.720 --> 00:38:06.965
cat videos?

00:38:06.965 --> 00:38:11.340
AUDIENCE: No, just within the
WebRTC, are you just--

00:38:11.340 --> 00:38:14.350
how are you tagging
your packets?

00:38:14.350 --> 00:38:18.590
JUSTIN UBERTI: Right, so there
is something called DSCP where

00:38:18.590 --> 00:38:21.290
we can mark QoS bits-- and this
isn't yet implemented in

00:38:21.290 --> 00:38:24.040
WebRTC, but it's on the roadmap,
to be able to tag

00:38:24.040 --> 00:38:26.710
things like audio as higher
priority than, say, video, and

00:38:26.710 --> 00:38:30.100
that as a higher priority
than cat videos.

00:38:30.100 --> 00:38:32.390
AUDIENCE: So it's not today,
but will be done?

00:38:32.390 --> 00:38:32.820
JUSTIN UBERTI: It
will be done.

00:38:32.820 --> 00:38:37.070
We also have things for doing
FEC type mechanisms to protect

00:38:37.070 --> 00:38:38.580
things at the application
layer.

00:38:38.580 --> 00:38:42.490
But the expectation is that as
WebRTC becomes more pervasive,

00:38:42.490 --> 00:38:47.540
carriers will support DSCP at
least on the bit from coming

00:38:47.540 --> 00:38:49.500
off the computer and going
onto their network.

00:38:49.500 --> 00:38:52.110
And we have that DSCP does
help going through Wi-Fi

00:38:52.110 --> 00:38:55.240
access points, because Wi-Fi
access points to give priority

00:38:55.240 --> 00:38:56.900
to DSCP-marked traffic.

00:38:56.900 --> 00:38:58.150
AUDIENCE: Thank you.

00:39:00.410 --> 00:39:04.640
AUDIENCE: So in Chrome for iOS
being limited to UI web view

00:39:04.640 --> 00:39:08.110
and with other restrictions, how
much of WebRTC will you be

00:39:08.110 --> 00:39:10.310
able to implement?

00:39:10.310 --> 00:39:12.820
JUSTIN UBERTI: So that's a
really interesting question.

00:39:12.820 --> 00:39:16.220
They haven't made it easy for
us, but the Chrome for iOS

00:39:16.220 --> 00:39:18.660
team has already done some
amazing things to deliver the

00:39:18.660 --> 00:39:20.470
Chrome experience that
exists there now.

00:39:20.470 --> 00:39:23.470
And so we're pretty optimistic
that one way or another, we

00:39:23.470 --> 00:39:25.130
can find some way to
make that work.

00:39:25.130 --> 00:39:29.680
No commitment to the
time frame, though.

00:39:29.680 --> 00:39:32.480
AUDIENCE: What are the
mechanisms for a saving video

00:39:32.480 --> 00:39:38.600
and audio that's broadcast with
WebRTC, like making video

00:39:38.600 --> 00:39:41.120
recordings from it?

00:39:41.120 --> 00:39:43.590
JUSTIN UBERTI: So if you have
the media stream, you can then

00:39:43.590 --> 00:39:46.290
take the media stream and plug
it into things like the Web

00:39:46.290 --> 00:39:48.700
Rdio API, where you can actually
get the raw samples,

00:39:48.700 --> 00:39:51.450
and then make a wave file
and save that out.

00:39:51.450 --> 00:39:53.600
On the video side, you can go
into a canvas, and then

00:39:53.600 --> 00:39:55.880
extract the frames from a
canvas, and you can save that.

00:39:55.880 --> 00:40:00.250
There isn't really any way to
sort of save it as a .MP4,

00:40:00.250 --> 00:40:03.440
.WEBM file yet.

00:40:03.440 --> 00:40:06.480
But if you want to make a thing
that just captures audio

00:40:06.480 --> 00:40:09.390
from the computer then it stores
on a server, you could

00:40:09.390 --> 00:40:11.300
basically make a custom server
that could do that recording.

00:40:11.300 --> 00:40:12.720
That's one option.

00:40:12.720 --> 00:40:14.180
AUDIENCE: So the TURN
server is open--

00:40:14.180 --> 00:40:17.760
but you said the TURN server
doesn't capture.

00:40:17.760 --> 00:40:17.880
JUSTIN UBERTI: No.

00:40:17.880 --> 00:40:19.420
AUDIENCE: It can't act
as an endpoint.

00:40:19.420 --> 00:40:21.810
Do you have server technology
that acts as an endpoint?

00:40:21.810 --> 00:40:22.720
JUSTIN UBERTI: There
are people building

00:40:22.720 --> 00:40:25.170
this sort of stuff.

00:40:25.170 --> 00:40:29.370
Vline might be one particular
vendor who does this, but

00:40:29.370 --> 00:40:31.780
there's something where you can
basically have an MCU, and

00:40:31.780 --> 00:40:33.850
the MCU that receives the media
could then do things

00:40:33.850 --> 00:40:36.280
like compositing or recording
of that media.

00:40:36.280 --> 00:40:39.020
AUDIENCE: So presumably, the
libraries for Java or

00:40:39.020 --> 00:40:41.400
Objective C could be used
to create a server

00:40:41.400 --> 00:40:41.720
implementation?

00:40:41.720 --> 00:40:42.210
JUSTIN UBERTI: Exactly.

00:40:42.210 --> 00:40:45.130
That's what they're doing.

00:40:45.130 --> 00:40:47.330
AUDIENCE: Hi, kind of two-part
question that has to do around

00:40:47.330 --> 00:40:49.800
codecs, specifically
on the video side,

00:40:49.800 --> 00:40:52.260
currently VP8, WebM.

00:40:52.260 --> 00:40:54.530
Is there plans for H.264,
and also what's the

00:40:54.530 --> 00:40:56.630
timeline for VP9?

00:40:56.630 --> 00:40:58.560
JUSTIN UBERTI: Our plans are
around the VP family of

00:40:58.560 --> 00:41:00.240
codecs, so we support VP8.

00:41:00.240 --> 00:41:03.600
And VP9, you may have heard that
it's sort of trying to

00:41:03.600 --> 00:41:05.620
finalize the bit stream
right now.

00:41:05.620 --> 00:41:07.880
So we are very much looking
forward to taking advantage of

00:41:07.880 --> 00:41:11.280
VP9 with all its new coding
techniques, once it's both

00:41:11.280 --> 00:41:13.980
finished and also optimized
for realtime.

00:41:13.980 --> 00:41:16.580
AUDIENCE: And H.264, not
really on the plan?

00:41:16.580 --> 00:41:20.050
JUSTIN UBERTI: We think that
VP9 provides much better

00:41:20.050 --> 00:41:22.550
compression and overall
performance than H.264, so we

00:41:22.550 --> 00:41:24.596
have no plans as far as
H.264 at this time.

00:41:24.596 --> 00:41:25.846
AUDIENCE: OK.

00:41:27.720 --> 00:41:30.540
AUDIENCE: Running WebRTC on
Chrome or Android for mobile

00:41:30.540 --> 00:41:35.020
and tablets, how does it
compare with native

00:41:35.020 --> 00:41:38.270
performance, like Hangouts
on Android?

00:41:38.270 --> 00:41:39.970
JUSTIN UBERTI: We think that
we provide a comparable

00:41:39.970 --> 00:41:43.080
performance to any native
application right now.

00:41:43.080 --> 00:41:44.860
We're always trying to
make things better.

00:41:44.860 --> 00:41:47.960
We still have Chrome for
Android, the WebRTC's behind a

00:41:47.960 --> 00:41:50.800
flag because we still have work
to do around improving

00:41:50.800 --> 00:41:52.640
audio, improvement some
of the performance.

00:41:52.640 --> 00:41:54.520
But we think we can deliver
equivalent performance on the

00:41:54.520 --> 00:41:55.600
web browser.

00:41:55.600 --> 00:41:57.580
And we're also working on taking
advantage of hardware

00:41:57.580 --> 00:42:00.520
acceleration, in cases where
there's hardware decoders like

00:42:00.520 --> 00:42:03.980
there is on Nexus 10, and making
that so we can get the

00:42:03.980 --> 00:42:06.515
same sort of down-to-the-metal
performance that you could get

00:42:06.515 --> 00:42:07.765
from a native app.

00:42:10.720 --> 00:42:13.490
AUDIENCE: So the Google Talk
plugin is using not just

00:42:13.490 --> 00:42:19.050
H.264, but H.264 SVC optimized
for the needs of

00:42:19.050 --> 00:42:19.690
videoconferencing.

00:42:19.690 --> 00:42:23.540
Is VP8 and VP9 going to
be similarly optimized

00:42:23.540 --> 00:42:27.860
specifically in an SVC-like
fashion for video conferencing

00:42:27.860 --> 00:42:31.942
versus just the versions
for file encoding?

00:42:31.942 --> 00:42:35.010
JUSTIN UBERTI: So VP8 already
supports temporal scalability

00:42:35.010 --> 00:42:38.590
in the S part of SVC.

00:42:38.590 --> 00:42:41.550
VP9 supports additional
scalability modes as well.

00:42:41.550 --> 00:42:43.805
So we're very excited about the
new coding techniques that

00:42:43.805 --> 00:42:46.150
are coming in VP9.

00:42:46.150 --> 00:42:50.620
AUDIENCE: So we want to use
WebRTC to do live streaming

00:42:50.620 --> 00:42:55.370
from, let's say, cameras,
hardware cameras.

00:42:55.370 --> 00:43:00.790
And what are the things that
we should take care of such

00:43:00.790 --> 00:43:02.070
kind of an application?

00:43:02.070 --> 00:43:04.640
And when you mentioned
VP8 and VP9 support,

00:43:04.640 --> 00:43:06.340
H.264 is not supported.

00:43:06.340 --> 00:43:09.430
Assuming your hardware supports
only H.264, WebRTC

00:43:09.430 --> 00:43:12.440
can be used with Chrome
in that case?

00:43:12.440 --> 00:43:16.200
JUSTIN UBERTI: We are building
up support for hardware VP8,

00:43:16.200 --> 00:43:17.845
and later, VP9 encoders.

00:43:20.810 --> 00:43:24.380
So you can make a media
streaming application like you

00:43:24.380 --> 00:43:28.875
described, but we're expecting
that all the major SSE vendors

00:43:28.875 --> 00:43:31.580
are now shipping hardware
with built-in VP8

00:43:31.580 --> 00:43:33.120
encoders and decoders.

00:43:33.120 --> 00:43:35.720
So as this stuff gets into
market, you're going to see

00:43:35.720 --> 00:43:39.540
this stuff become the most
efficient way to record and

00:43:39.540 --> 00:43:41.190
compress data.

00:43:41.190 --> 00:43:44.095
AUDIENCE: So the only way is
to support VP8 in hardware

00:43:44.095 --> 00:43:45.345
right now, right?

00:43:48.750 --> 00:43:52.290
JUSTIN UBERTI: If you want
hardware compression, the only

00:43:52.290 --> 00:43:55.810
things that we support right
now will be VP8 encoders.

00:43:55.810 --> 00:43:57.590
AUDIENCE: That's on the device
side, you know, the camera

00:43:57.590 --> 00:43:58.970
which is on--

00:43:58.970 --> 00:44:00.310
JUSTIN UBERTI: Right.

00:44:00.310 --> 00:44:02.670
If you're having encoding from
a device that you want to be

00:44:02.670 --> 00:44:08.030
decoded within the browser, I
advise you to do it in VP8.

00:44:08.030 --> 00:44:09.280
AUDIENCE: Thank you.

00:44:11.330 --> 00:44:12.430
JUSTIN UBERTI: Thank
you all for coming.

00:44:12.430 --> 00:44:13.030
SAM DUTTON: Yeah, thank you.

00:44:13.030 --> 00:44:16.965
[APPLAUSE]

