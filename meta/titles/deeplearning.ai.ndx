U1bIc6pFdw4tOnes To Watch: Christine Payne 
eMh5YqKopjEtdeeplearning.ai's Heroes of Deep Learning: Dawn Song 
JS12eb1cTLEtdeeplearning.ai's Heroes of Deep Learning: Yann LeCun 
quoGRI-1l0AtC5W3L08 Attention Model 
vm2SI8AJY0stC5W3L09 SpeechRecog 
y_-Gh3iARJMtC5W3L11 Summary and Thank You 
Zqx_hbTmN6AtC5W3L10 Trigger Word Detection 
SysgYptB198tC5W3L07 Attention Model Intuition 
DejHQYAGb7QtC5W3L06 Bleu Score (Optional) 
ZGUZwk7xIwktC5W3L05 Error Analysis of Beam Search 
gb__z7LlN_4tC5W3L04 Refining Beam Search 
RLWuzLLSIgwtC5W3L03 Beam Search 
Er2ucMxjdHEtC5W3L02 Picking the most likely sentence 
_i3aqgKVNQItC5W3L01 Basic Models 
Cn8AtS-9NwctC4W4L11 1D and 3D Generalizations 
QgkLfjfGul8tC4W4L10 Style Cost Function 
b1I5X3UfEYItC4W4L09 Content Cost Function 
xY-DMAJpIP4tC4W4L08 Cost Function 
ChoV5h7tw5AtC4W4L07 What are deep CNs learning? 
R39tWYYKNcItC4W4L006 What is neural style transfer? 
0NSLgoEtdnwtC4W4L05 Face Verification 
d2XB5-tuCWUtC4W4L04 Triplet loss 
6jfw8MuKwpItC4W4L03 Siamese Network 
96b_weTZb2wtC4W4L02 One Shot Learning 
-FfMVnwXrZ0tC4W4L01 What is face recognition 
6ykvU9WuIwstC4W3L10 Region Proposals 
9s_FpMpdYW8tC4W3L09 YOLO Algorithm 
RTlwl2bv0TgtC4W3L08 Anchor Boxes 
VAo84c1hQX8tC4W3L07 Nonmax Suppression 
ANIzQ5G-XPEtC4W3L06 Intersection Over Union 
XdsmlBGOK-ktC4W3L04 Convolutional Implementation Sliding Windows 
5e5pjeojznktC4W3L03 Object Detection 
rRB9iymNy1wtC4W3L02 Landmark Detection 
GSwYGkTfOKktC4W3L01 Object Localization 
c3zw6KI6dLctC4W2L11 State of Computer Vision 
JI8saFjK84otC4W2L10 Data Augmentation 
FQM13HkEfBktC4W2L09 Transfer Learning 
cFFu__mcoIwtC4W2L08 Using Open Source Implementation 
KfV8CJh7hE0tC4W2L07 Inception Network 
C86ZXvgpejMtC4W2L06 Inception Network Motivation 
c1RBQzKsDCktC4W2L05 Network In Network 
RYth6EbBUqMtC4W2L04 Why ResNets Work 
ZILIbUvp5lktC4W2L03 Resnets 
dZVkygnKh1MtC4W2L02 Classic Network 
-bvTzZCEOdMtC4W2L01 Why look at case studies? 
ay3zYUeuyhUtC4W1L11 Why Convolutions 
bXJx7y51cl0tC4W1L10 CNN Example 
8oOgPUO-TBYtC4W1L09 Pooling Layers 
3PyJA9AfwSktC4W1L08 Simple Convolutional Network Example 
jPOAS7uCODQtC4W1L07 One Layer of a Convolutional Net 
KTB_OFoAQcctC4W1L06 Convolutions Over Volumes 
tQYZaDn_kSgtC4W1L05 Strided Convolutions 
smHa2442Ah4tC4W1L04 Padding 
am36dePheDctC4W1L03 More Edge Detection 
XuD4C8vJzEQtC4W1L02 Edge Detection Examples 
ArPaAX_PhIstC4W1L01 Computer Vision 
NyG-7nRpsW8tWhy Regularization Reduces Overfitting (C2W1L05) 
6g0t3Phly2MtRegularization (C2W1L04) 
y1xoI7mBtOctNumerical Approximations of Gradients (C2W1L12) 
s2coXdufOzEtWeight Initialization in a Deep Network (C2W1L11) 
C1N_PDHuJ6QtBasic Recipe for Machine Learning (C2W1L03) 
SjQyLhQIXSMtBias/Variance (C2W1L02) 
qhXZsFVxGKotVanishing/Exploding Gradients (C2W1L10) 
D8PJAL-MZv8tDropout Regularization (C2W1L06) 
FDCfw-YqWTEtNormalizing Inputs (C2W1L09) 
BOCLq2gpcGUtOther Regularization Methods (C2W1L08) 
1waHlpKiNyYtTrain/Dev/Test Sets (C2W1L01) 
VTE2KlfoO3QtParameters vs Hyperparameters (C1W4L07) 
ARq74QuavAotUnderstanding Dropout (C2W1L07) 
B7-iPbddhswtBuilding Blocks of a Deep Neural Network (C1W4L06) 
S9ElPZupUsEtTensorFlow (C2W3L11) 
5dWp1mw_XNktWhy Deep Representations? (C1W4L05) 
AK6r-llqoggtDeep Learning Frameworks (C2W3L10) 
ueO_Ph0PyqktTraining Softmax Classifier (C2W3L09) 
LLux1SW--oMtSoftmax Regression (C2W3L08) 
5qefnAek8OAtBatch Norm At Test Time (C2W3L07) 
nUUqwaxLnWstWhy Does Batch Norm Work? (C2W3L06) 
em6dfRxYkYUtFitting Batch Norm Into Neural Networks (C2W3L05) 
JXQT_vxqwIstAdam Optimization Algorithm (C2W2L08) 
_e-LFe_ignotRMSProp (C2W2L07) 
tNIpEZLv_egtNormalizing Activations in a Network (C2W3L04) 
wKkcBPp3F1YtHyperparameter Tuning in Practice (C2W3L03) 
k8fTYJPd3_ItGradient Descent With Momentum (C2W2L06) 
AXDByU3D1hAtTuning Process (C2W3L01) 
lWzo8CajF5stBias Correction of Exponentially Weighted Averages (C2W2L05) 
NxTFlzBjS-4tUnderstanding Exponentially Weighted Averages (C2W2L04) 
-_4Zi8fCZO4tUnderstanding Mini-Batch Gradient Dexcent (C2W2L02) 
fODpu1-lNTwtThe Problem of Local Optima (C2W2L10) 
lAq96T8FkTwtExponentially Weighted Averages (C2W2L03) 
4qJaSmvhxi8tMini Batch Gradient Descent (C2W2L01) 
QzulmoOg2JEtLearning Rate Decay (C2W2L09) 
4Ct3Yujl1dktGradient Checking Implementation Notes (C2W1L14) 
QrzApibhohYtGradient Checking (C2W1L13) 
cSoK_6RkbfgtUsing an Appropriate Scale (C2W3L03) 
xxu4IqwKw0wtdeeplearning.ai's Heroes of Deep Learning: Andrej Karpathy 
LpAiPYNnxW0tdeeplearning.ai's Heroes of Deep Learning: Pieter Abbel 
dqwx-F7Eitstdeeplearning.ai's Heroes of Deep Learning: Ian Goodfellow 
oJFShOfCZiAtdeeplearning.ai's Heroes of Deep Learning: Yoshua Bengio 
OT91E6_Qm1Atdeeplearning.ai's Heroes of Deep Learning: Ruslan Salakhutdinov 
dwFcodBz_2Itdeeplearning.ai's Heroes of Deep Learning: Yuanqing Lin 
qzPQ8cEsVK8tForward and Backward Propagation (C1W4L02) 
sfk5h0yC67otTraining and Testing on Different Distributions (C3W2L04) 
HfM8UIohGE0tBuild First System Quickly, Then Iterate (C3W2L03) 
jyjJ-RpQ5zQtCleaning Up Incorrectly Labelled Data (C3W2L02) 
JoAxZsdw_3wtCarrying Out Error Analysis (C3W2L01) 
zg26t-BH7aotImproving Model Performance (C3W1L12) 
dM0exrbVZ08tSurpassing Human-Level Performance (C3W1L11) 
NUmbgp1h64EtUnderstanding Human-Level Performance? (C3W1L10) 
CZf3oo0fuh0tAvoidable Bias (C3W1L09) 
J3HHOwcrkK8tC3W1L08 WhyHumanLevelPerformance 
DFUqMbWs5d8tWhen to Change Dev/Test Sets (C3W1L07) 
_Fe5kKmFiegtSizeof Dev and Test Sets (C3W1L06) 
M3qpIzy4MQktTrain/Dev/Test Set Distributions (C3W1L05) 
BH9mlmdXzzItSatisficing and Optimizing Metrics (C3W1L04) 
sofffBNhVSotSingle Number Evaluation Metric (C3W1L03) 
UEtvV1D6B3stOrthogonalization (C3W1L02 ) 
dFX8k1kXhOwtImproving Model Performance (C3W1L01) 
2BkqApHKwn0tVectorizing Logistic Regression's Gradient Computation (C1W2L14) 
okpqeEUdEkYtVectorizing Logistic Regression (C1W2L13) 
GzphoJOVEcEtDerivatives (C1W2L05) 
nJyUyKN-XBQtDerivatives With Computation Graphs (C1W2L08) 
k_S5fnKjO-4tExplanation of Logistic Regression's Cost Function (C1W2L18) 
uJryes5Vk1otGradient Descent (C1W2L04) 
SHEPb1JHw5otLogistic Regression Cost Function (C1W2L03) 
hCP1vGoCdYUtComputation Graph (C1W2L07) 
hjrYrynGWGAtLogistic Regression (C1W2L02) 
0S9c7nHoDwstQuick Tour of Jupyter/iPython Notebooks (C1W2L17) 
5H7M5Vd3-pktMore Derivative Examples (C1W2L16) 
pYWASRauTzstMore Vectorization Examples (C1W2L12) 
eqEc66RFY0ItBinary Classification (C1W2L01) 
V2QlTmh6P2YtA Note on Python/Numpy Vectors (C1W2L16) 
tKcLaGdvabMtBroadcasting in Python (C1W2L15) 
qsIrQi0fzbYtVectorization (C1W2L11) 
KKfZLXcF-aEtGradient Descent on m Examples (C1W2L10) 
ysnIDax71yYtAbout This Course (C1W1L05) 
xflCLdJh0n0tWhy is deep learning taking off? (C1W1L04) 
z_xiwjEdAC4tLogistic Regression Gradient Descent (C1W2L09) 
BYGpKPY9pO0tSupervised Learning with a Neural Network (C1W1L03) 
n1l-9lIMW7EtWhat is a Neural Network? (C1W1L02) 
CS4cs9xVecgtWelcome (C1W1L01) 
7AZjh2VXD6EtCourse Resources (C1W1L06) 
l_-CUyEx_x4tWhether to Use End-To-End Deep Learning (C3W2L10) 
ImUoubi_t7stWhat is end-to-end deep learning? (C3W2L09) 
UdXfsAr4GjwtMultitask Learning (C3W2L08) 
yofjFQddwHEtTransfer Learning (C3W2L07) 
sn_QSB7T1xotAddressing Data Mismatch (C3W2L06) 
2BH49JG_sTstBias and Variance With Mismatched Data (C3W2L05) 
a8i2eJin0lYtForward Propagation in a Deep Network (C1W4L03) 
2zgon7XfN4ItWhat does this have to do with the brain? (C1W4L08) 
2gw5tE2ziqAtDeep L-Layer Neural Network (C1W4L01) 
P7_jFxTtJEotDerivatives Of Activation Functions (C1W3L08) 
xy5MOQpx3aQtVectorizing Across Multiple Examples (C1W3L04) 
6by6Xas_KhotRandom Initialization (C1W3L11) 
NkOv_k7r6notWhy Non-linear Activation Functions (C1W3L07) 
rMOdrD61IoUtComputing Neural Network Output (C1W3L03) 
yXcQ4B-YSjQtBackpropagation Intuition (C1W3L10) 
yslMo3hSbqEtGetting Matrix Dimensions Right (C1W4L04) 
Xvg00QnyaIYtActivation Functions (C1W3L06) 
kkWRbIb42MstExplanation For Vectorized Implementation (C1W3L05) 
7bLEWDZng_MtGradient Descent For Neural Networks (C1W3L09) 
CcRkHl75Z-YtNeural Network Representations (C1W3L02) 
fXOsFF95ifktNeural Network Overview (C1W3L01) 
