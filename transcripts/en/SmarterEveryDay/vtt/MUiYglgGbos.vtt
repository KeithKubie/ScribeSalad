WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:02.730
- My internet newsfeed is mostly crap.

00:00:02.730 --> 00:00:03.820
I try to be smart, right?

00:00:03.820 --> 00:00:06.260
And discern what I'm
reading online and make sure

00:00:06.260 --> 00:00:08.510
that it's lining up with
truth, but for the most part,

00:00:08.510 --> 00:00:11.850
it seems like everyone has an
agenda or everything's biased.

00:00:11.850 --> 00:00:13.750
So how do you figure out what's real?

00:00:13.750 --> 00:00:16.450
A technique that I used to
use was I would read something

00:00:16.450 --> 00:00:18.270
on one side of the aisle and
then I'd go read something

00:00:18.270 --> 00:00:20.210
on the other side of the
aisle and then I would assume

00:00:20.210 --> 00:00:21.350
that the truth is in the middle.

00:00:21.350 --> 00:00:22.770
Truth is truth.

00:00:22.770 --> 00:00:24.560
It doesn't have to be on that spectrum,

00:00:24.560 --> 00:00:26.050
it's its own separate thing.

00:00:26.050 --> 00:00:27.940
Recently I've been
tricked a couple of times.

00:00:27.940 --> 00:00:30.110
I've seen a story and I've read about it

00:00:30.110 --> 00:00:31.147
and was like, ooh, that's
pretty interesting.

00:00:31.147 --> 00:00:34.560
And the more I dig, the more
I see this narrative happening

00:00:34.560 --> 00:00:37.940
and then suddenly a couple
of days later, it comes out

00:00:37.940 --> 00:00:40.020
that what I was reading wasn't true,

00:00:40.020 --> 00:00:41.900
even though a lot of
people thought it was.

00:00:41.900 --> 00:00:44.550
If I can be fooled by a
story like that from a couple

00:00:44.550 --> 00:00:47.610
of different sources, how much
is getting through my filter?

00:00:47.610 --> 00:00:50.150
What's even scarier is
I share things online.

00:00:50.150 --> 00:00:53.400
So how much of the stuff
that I share is not true?

00:00:53.400 --> 00:00:55.030
Like, am I part of the problem?

00:00:55.030 --> 00:00:56.760
'Cause I wanna be a good guy, I wanna be,

00:00:56.760 --> 00:00:58.090
like, part of the solutions.

00:00:58.090 --> 00:00:59.420
So here's how it works in engineering.

00:00:59.420 --> 00:01:01.460
If there's a process
that's failing, you find

00:01:01.460 --> 00:01:03.670
the root cause of that
failure and you try to fix it.

00:01:03.670 --> 00:01:05.890
In this case, my failure is the ability

00:01:05.890 --> 00:01:08.200
to discern fact from fiction online.

00:01:08.200 --> 00:01:11.030
There's a well respected
nonprofit school for journalism,

00:01:11.030 --> 00:01:12.520
it's called the Poynter Institute.

00:01:12.520 --> 00:01:14.700
And they are the experts
for good journalism.

00:01:14.700 --> 00:01:17.250
Poynter has created this
program called MediaWise,

00:01:17.250 --> 00:01:19.330
and it's supported by
Google to help people learn

00:01:19.330 --> 00:01:22.380
how to see what's true and
what's not true online.

00:01:22.380 --> 00:01:25.593
I've partnered with
MediaWise to make this video

00:01:25.593 --> 00:01:27.840
to figure out how I can
help myself and other people

00:01:27.840 --> 00:01:30.080
learn how to separate
fact from fiction online.

00:01:30.080 --> 00:01:32.290
As part of this partnership
I traveled to Austin, Texas

00:01:32.290 --> 00:01:35.410
to talk about misinformation
online at South by Southwest.

00:01:35.410 --> 00:01:37.530
I want to introduce you to Katy Byron,

00:01:37.530 --> 00:01:39.240
who runs the MediaWise project.

00:01:39.240 --> 00:01:40.750
This is Katy.

00:01:40.750 --> 00:01:42.864
We're buddies.
(Katy laughs)

00:01:42.864 --> 00:01:44.340
And she's been a journalist for 15 years.

00:01:44.340 --> 00:01:46.990
The goal here is to get
people more intelligent

00:01:46.990 --> 00:01:49.381
about how they use the internet, right?

00:01:49.381 --> 00:01:50.385
- Yes.

00:01:50.385 --> 00:01:51.280
- Katy is smart, she
really knows her stuff.

00:01:51.280 --> 00:01:53.140
And she told me there's three easy steps

00:01:53.140 --> 00:01:55.270
to figuring out if
something is true online.

00:01:55.270 --> 00:01:56.900
To see this is in action
I pulled up a tweet

00:01:56.900 --> 00:01:58.650
I knew Katy would personally like.

00:01:58.650 --> 00:02:01.070
She's a third generation
journalist, so I tried to pull

00:02:01.070 --> 00:02:03.010
at her heartstrings and show her a tweet

00:02:03.010 --> 00:02:05.050
that made journalists look really good.

00:02:05.050 --> 00:02:06.510
Let's see what she does to engage

00:02:06.510 --> 00:02:08.520
to figure out if this is true or not.

00:02:08.520 --> 00:02:10.260
I saw this tweet.

00:02:10.260 --> 00:02:12.260
And it makes me feel things, right?

00:02:12.260 --> 00:02:14.180
- Makes me feel things true.

00:02:14.180 --> 00:02:15.997
I love journalism. (laughs)

00:02:15.997 --> 00:02:16.830
- It's talking about
these dudes, that, like,

00:02:16.830 --> 00:02:19.240
basically helped expose the lies.

00:02:19.240 --> 00:02:20.838
And, you know, they're watching--

00:02:20.838 --> 00:02:21.671
- Bob Woodward and Carl Bernstein.

00:02:21.671 --> 00:02:22.880
- Are they famous journalists?

00:02:22.880 --> 00:02:23.713
- Yes, very.

00:02:23.713 --> 00:02:24.970
- Okay, I don't know a whole lot about it.

00:02:24.970 --> 00:02:26.940
- All the President's Men,
the movie, the old movie?

00:02:26.940 --> 00:02:27.773
It's about them.

00:02:27.773 --> 00:02:30.670
And this is actually a
scene from that time.

00:02:30.670 --> 00:02:32.620
- I wanna retweet that, right?

00:02:32.620 --> 00:02:33.883
Should I retweet it?

00:02:33.883 --> 00:02:34.716
- It's very retweetable. (laughs)

00:02:34.716 --> 00:02:35.850
- Should I retweet it?

00:02:35.850 --> 00:02:38.620
- I mean, I think, number one I would

00:02:38.620 --> 00:02:40.680
look at who is Don Wislow?

00:02:40.680 --> 00:02:42.760
- Step one, you can see
that she tries to figure out

00:02:42.760 --> 00:02:44.510
who is behind the information.

00:02:44.510 --> 00:02:46.410
- I hope he's not somebody
really important that I should

00:02:46.410 --> 00:02:47.540
know who he is.
(Destin laughs)

00:02:47.540 --> 00:02:50.090
Don Winslow, number one, who
is behind the information?

00:02:50.090 --> 00:02:51.110
We need to figure that out.

00:02:51.110 --> 00:02:52.547
- [Destin] He's an author.

00:02:52.547 --> 00:02:53.380
- New York Times number one

00:02:53.380 --> 00:02:56.070
international bestselling
author of The Cartel.

00:02:56.070 --> 00:03:00.680
He's not necessarily an expert
on the topic of journalism.

00:03:00.680 --> 00:03:02.830
That to me is not enough for the retweet.

00:03:02.830 --> 00:03:04.859
So next step, after I looked that up--

00:03:04.859 --> 00:03:06.580
- So you would not
retweet it at this point?

00:03:06.580 --> 00:03:08.340
- No, no. (laughs)

00:03:08.340 --> 00:03:09.520
- So now what I do I do?

00:03:09.520 --> 00:03:11.270
- There's no link to any
additional information,

00:03:11.270 --> 00:03:14.060
and that to me is always
a red flag, always.

00:03:14.060 --> 00:03:17.080
So find more information
about what they're saying.

00:03:17.080 --> 00:03:18.410
- Number two, what's the evidence?

00:03:18.410 --> 00:03:20.140
This is the most important step for Katy.

00:03:20.140 --> 00:03:22.500
And one thing I found was
interesting is she didn't stop

00:03:22.500 --> 00:03:24.680
at just, is the story
true, she went further.

00:03:24.680 --> 00:03:27.090
She wanted to see if the photo was real.

00:03:27.090 --> 00:03:29.280
To do this, she used a
really clever technique,

00:03:29.280 --> 00:03:31.630
it's just a Google reverse imagine search.

00:03:31.630 --> 00:03:34.610
- Use a reverse Google
image search and write click

00:03:34.610 --> 00:03:36.600
and search Google for image,
it's as simple as that.

00:03:36.600 --> 00:03:39.260
This is one of my favorite tools.

00:03:39.260 --> 00:03:40.592
- [Destin] Oh, wow, okay.

00:03:40.592 --> 00:03:43.614
- [Katy] So first search results--

00:03:43.614 --> 00:03:47.880
- [Destin] Reddit,
Twitter, Blogspot, Tumblr.

00:03:47.880 --> 00:03:50.190
- [Katy] Scoopnest, I
don't know what that is.

00:03:50.190 --> 00:03:51.880
- So I'm simply looking for things

00:03:51.880 --> 00:03:53.400
that I recognize as reputable--

00:03:53.400 --> 00:03:55.610
- And I spend all my days lateral reading,

00:03:55.610 --> 00:03:56.830
and I don't know any of these.

00:03:56.830 --> 00:03:58.451
- [Destin] So all this is looking--

00:03:58.451 --> 00:04:02.010
- These are all not reputable
names or well known sources,

00:04:02.010 --> 00:04:04.161
so that is a red flag in itself.

00:04:04.161 --> 00:04:05.520
- [Destin] What if I went
this, what if I went up here

00:04:05.520 --> 00:04:10.520
to tools and I searched, like,
let's say, like, last year.

00:04:11.130 --> 00:04:12.660
I should get an old source now,

00:04:12.660 --> 00:04:14.270
so maybe I can find the first person.

00:04:14.270 --> 00:04:16.590
- [Katy] Washington Post, what is this?

00:04:16.590 --> 00:04:18.520
So that's a good sign, NPR.

00:04:18.520 --> 00:04:19.940
- [Destin] Washington Post.

00:04:19.940 --> 00:04:23.530
- So this is a panel, but
not showing the photo, right?

00:04:23.530 --> 00:04:24.580
So that's--

00:04:24.580 --> 00:04:27.190
- [Woman] His resignation
felt like to you?

00:04:27.190 --> 00:04:28.337
Elizabeth?

00:04:28.337 --> 00:04:31.323
- This is the night he announced
he was going to resign.

00:04:31.323 --> 00:04:32.705
- [Woman] The night he
announced he was resigning.

00:04:32.705 --> 00:04:33.770
- He was gonna resign, and it was

00:04:33.770 --> 00:04:36.010
the next day that was truly bizarre.

00:04:36.010 --> 00:04:38.360
- I think most people probably
aren't gonna sit through

00:04:38.360 --> 00:04:39.830
a five minute video to find out, right?

00:04:39.830 --> 00:04:42.050
So I think I'd go back
to the search results.

00:04:42.050 --> 00:04:43.937
And see what else we got.
- Okay.

00:04:43.937 --> 00:04:46.830
But that was an original
source, those were the guys.

00:04:46.830 --> 00:04:49.110
- Yes, but we're talking,
we're trying to verify

00:04:49.110 --> 00:04:50.520
the veracity of the photo, right?

00:04:50.520 --> 00:04:51.670
- [Destin] Got it, because somebody

00:04:51.670 --> 00:04:53.510
could have photoshopped in--

00:04:53.510 --> 00:04:54.611
- Nixon's image.

00:04:54.611 --> 00:04:55.900
- You think differently than me.

00:04:55.900 --> 00:04:56.793
(Katy laughs)

00:04:56.793 --> 00:04:58.240
I've been, like, yeah,
they were there, retweet.

00:04:58.240 --> 00:05:00.570
But you're trying to make
sure that the image is real.

00:05:00.570 --> 00:05:04.860
You have a higher level of
fidelity that's required--

00:05:04.860 --> 00:05:06.235
- And skepticism, you know.

00:05:06.235 --> 00:05:07.115
- Skepticism.

00:05:07.115 --> 00:05:08.170
- I think that, because
the internet is full

00:05:08.170 --> 00:05:09.930
of a lot of garbage. (laughs)

00:05:09.930 --> 00:05:12.120
- Number three, what do other sources say?

00:05:12.120 --> 00:05:14.350
Katy told me a really
interesting technique

00:05:14.350 --> 00:05:15.930
called lateral reading.

00:05:15.930 --> 00:05:18.600
- Basically that means
instead of reading vertically

00:05:18.600 --> 00:05:19.730
and just looking at your newsfeed--

00:05:19.730 --> 00:05:21.667
- Yeah, 'cause I'm just
scrolling on my phone, yeah.

00:05:21.667 --> 00:05:24.920
- And you stop at a tweet or
you stop at a Instagram meme

00:05:24.920 --> 00:05:27.450
or whatever, instead of
reading vertically and just

00:05:27.450 --> 00:05:29.200
trying to figure out is
this legitimate or not,

00:05:29.200 --> 00:05:32.410
just by looking at that,
you need to open up tabs

00:05:32.410 --> 00:05:36.200
on your browser and
literally read laterally.

00:05:36.200 --> 00:05:37.350
- Sometimes when you
get to the end of this

00:05:37.350 --> 00:05:40.070
three step process you're pretty
sure that the thing is real

00:05:40.070 --> 00:05:41.990
and you wanna tweet it because
it makes you feel things

00:05:41.990 --> 00:05:43.710
and you want other people to feel things,

00:05:43.710 --> 00:05:46.520
but at that point, if you don't know 100%,

00:05:46.520 --> 00:05:48.880
this is the moment that you
have to decide if you're

00:05:48.880 --> 00:05:51.610
gonna be part of the problem
of misinformation online

00:05:51.610 --> 00:05:53.220
or if you're gonna be
part of the solution.

00:05:53.220 --> 00:05:56.080
You have to do something that
she calls click restraint.

00:05:56.080 --> 00:05:58.790
Okay, well, I can't find the actual image.

00:05:58.790 --> 00:06:01.470
Okay, so, to me that's
just generally a red flag,

00:06:01.470 --> 00:06:03.820
and it's not something
to be discouraged by,

00:06:03.820 --> 00:06:05.690
it's also telling you something.

00:06:05.690 --> 00:06:07.936
It's telling you that
you can't find this image

00:06:07.936 --> 00:06:11.894
anywhere else, so it could
be doctored, number one.

00:06:11.894 --> 00:06:14.323
Number two, I'm not gonna
feed that out, I'm not gonna

00:06:14.323 --> 00:06:16.390
retweet that, I'm not gonna
share that on my social media.

00:06:16.390 --> 00:06:17.470
- But those are your homies.

00:06:17.470 --> 00:06:18.800
They're like, talking
about how journalism--

00:06:18.800 --> 00:06:20.550
- I know, it's really
tempting, this is like

00:06:20.550 --> 00:06:22.525
chocolate for a journalist,
that tweet, you know?

00:06:22.525 --> 00:06:24.620
(laughter)

00:06:24.620 --> 00:06:27.140
But I'm going to exert my click restraint

00:06:27.140 --> 00:06:28.730
and I am not going to reshare that.

00:06:28.730 --> 00:06:29.563
- Really?

00:06:29.563 --> 00:06:31.020
So now that we're armed
with these techniques:

00:06:31.020 --> 00:06:32.090
who's behind the information?

00:06:32.090 --> 00:06:33.140
What does the evidence say?

00:06:33.140 --> 00:06:35.020
And what do other sources say?

00:06:35.020 --> 00:06:36.550
Katy wanted me to take a shot at it.

00:06:36.550 --> 00:06:37.830
She found something online that was

00:06:37.830 --> 00:06:40.390
a little bit controversial,
it's the kind of thing

00:06:40.390 --> 00:06:41.720
that gets people stirred up online.

00:06:41.720 --> 00:06:43.540
And she wanted me to take
a crack at figuring out

00:06:43.540 --> 00:06:44.880
if it was true or not.

00:06:44.880 --> 00:06:46.050
Right, you're gonna send it to me?

00:06:46.050 --> 00:06:46.930
- I sent it to you.

00:06:46.930 --> 00:06:48.160
- [Destin] How do I fact check that?

00:06:48.160 --> 00:06:50.090
- [Katy] Memes are kinda
tricky, because you need to do

00:06:50.090 --> 00:06:52.490
a screenshot that takes away the text.

00:06:52.490 --> 00:06:55.610
Google Image Search, drag and drop.

00:06:55.610 --> 00:06:58.700
- [Destin] Arctic sea
ice minimum, is that it?

00:06:58.700 --> 00:06:59.700
- [Katy] You could try that, that's NASA,

00:06:59.700 --> 00:07:01.060
so that's always a good sign.

00:07:01.060 --> 00:07:02.532
Okay, so this is the image, right?

00:07:02.532 --> 00:07:03.405
- [Destin] There it is.

00:07:03.405 --> 00:07:04.279
- [Katy] Bingo.

00:07:04.279 --> 00:07:05.112
The dates are wrong, so this,

00:07:05.112 --> 00:07:06.323
which is really important to the story.

00:07:06.323 --> 00:07:08.730
- Look at that, they blotted out the date

00:07:08.730 --> 00:07:11.040
to put whatever date they wanted on there.

00:07:11.040 --> 00:07:11.950
Punks.

00:07:11.950 --> 00:07:14.641
It's called just facts page too.

00:07:14.641 --> 00:07:15.604
(Katy laughs)

00:07:15.604 --> 00:07:17.390
Like, ultimately, the
person that made that post

00:07:17.390 --> 00:07:20.200
was trying to say, like,
hey, global warming is real

00:07:20.200 --> 00:07:22.070
and if you don't believe it you suck.

00:07:22.070 --> 00:07:25.720
But ultimately they undermined
what they were trying to do

00:07:25.720 --> 00:07:29.210
because they showed false
data and then somebody

00:07:29.210 --> 00:07:31.770
on the other side that's
a climate change denier

00:07:31.770 --> 00:07:34.700
or whatever terminology you
wanna use to get excited about,

00:07:34.700 --> 00:07:38.650
that person can say, see,
you doctored the photos.

00:07:38.650 --> 00:07:41.850
So it muddies the waters,
and it makes truth

00:07:41.850 --> 00:07:45.220
this difficult thing to
find, and so ultimately

00:07:45.220 --> 00:07:47.660
even if you're trying to
put an exclamation point

00:07:47.660 --> 00:07:49.840
beside the thing that you believe,

00:07:49.840 --> 00:07:51.990
you can undercut your very cause.

00:07:51.990 --> 00:07:54.250
- Exactly, I mean, it's
like feeding the beast.

00:07:54.250 --> 00:07:56.390
- Something I've been giving
a lot of thought to recently

00:07:56.390 --> 00:07:59.190
is that in the developing
moments of a new news story,

00:07:59.190 --> 00:08:01.170
that is the most likely
time that I'm gonna

00:08:01.170 --> 00:08:03.030
get misinformation online.

00:08:03.030 --> 00:08:05.150
I think it has to do
with the speed at which

00:08:05.150 --> 00:08:08.650
the news cycle occurs, and to
explain this I have a metaphor

00:08:08.650 --> 00:08:11.190
for something I learned about
fighter jets in the '50s.

00:08:11.190 --> 00:08:12.690
There was this colonel
in the Air Force named

00:08:12.690 --> 00:08:15.420
Colonel John Boyd who
developed the decision cycle

00:08:15.420 --> 00:08:16.610
called the OODA loop.

00:08:16.610 --> 00:08:20.520
He figured out if you can
observe, orient, decide, and act

00:08:20.520 --> 00:08:23.810
first, you would complete your
OODA loop before the enemy

00:08:23.810 --> 00:08:26.570
and you would almost
always score hits and win.

00:08:26.570 --> 00:08:28.610
I asked my buddy Ben to make a simulation

00:08:28.610 --> 00:08:30.610
to help me illustrate this point.

00:08:30.610 --> 00:08:32.070
Here we have two fighter jets,

00:08:32.070 --> 00:08:34.350
they're constantly trying
to out maneuver each other.

00:08:34.350 --> 00:08:36.090
The only difference in the
jets is that the red one

00:08:36.090 --> 00:08:38.780
is able to get through
its decision cycle first.

00:08:38.780 --> 00:08:41.010
The blue one takes his time
getting through its OODA loop,

00:08:41.010 --> 00:08:43.320
and as a result, it's
always too slow and ends up

00:08:43.320 --> 00:08:46.110
reaching to information
that's already changed.

00:08:46.110 --> 00:08:48.190
This means that no matter
how many times I restart

00:08:48.190 --> 00:08:50.610
the simulation, the red
jet is always gonna be

00:08:50.610 --> 00:08:52.850
the one that scores the big hits.

00:08:52.850 --> 00:08:54.810
Now think of your social media newsfeed

00:08:54.810 --> 00:08:55.950
like it's a war zone.

00:08:55.950 --> 00:08:58.790
It's not unlike the dogfights
seen in aerial combat.

00:08:58.790 --> 00:09:00.450
It's a hyper competitive environment where

00:09:00.450 --> 00:09:03.060
the stakes are high and
reaction time matters.

00:09:03.060 --> 00:09:06.650
Instead of observe, orient,
decide, act, let's change

00:09:06.650 --> 00:09:09.917
the decision cycle to how
people make news posts online.

00:09:09.917 --> 00:09:13.570
People observe things, they
may or may not verify them,

00:09:13.570 --> 00:09:16.840
they write a social media post,
and then they click publish.

00:09:16.840 --> 00:09:19.430
Often times, whoever publishes first gets

00:09:19.430 --> 00:09:21.940
the most views, the most
followers, which eventually

00:09:21.940 --> 00:09:24.070
turns into more advertising dollars.

00:09:24.070 --> 00:09:26.750
People are rewarded for posting fast.

00:09:26.750 --> 00:09:29.800
The problem today is that your
modern newsfeed is driven by

00:09:29.800 --> 00:09:32.560
social media, which rewards
whoever can post first.

00:09:32.560 --> 00:09:33.700
And unlike when traditional,

00:09:33.700 --> 00:09:36.460
high quality journalism
dominated, on social media,

00:09:36.460 --> 00:09:39.840
there are no editors to verify the truth.

00:09:39.840 --> 00:09:42.830
In fact, many people
intentionally skip this step

00:09:42.830 --> 00:09:44.070
so they can can post quicker in order

00:09:44.070 --> 00:09:46.230
to be the first one to get the views.

00:09:46.230 --> 00:09:48.050
Unfortunately what this means is now

00:09:48.050 --> 00:09:50.550
you must verify the truth,
because unless it's coming

00:09:50.550 --> 00:09:54.520
from a reputable source, it is
not going to be fact checked.

00:09:54.520 --> 00:09:57.020
So how do we break this
cycle of misinformation?

00:09:57.020 --> 00:09:59.250
First of all, you need to
read the entire article,

00:09:59.250 --> 00:10:00.480
not just the title.

00:10:00.480 --> 00:10:02.440
If there's nobody
willing to put their name

00:10:02.440 --> 00:10:05.180
next to the information and
there's no sources cited,

00:10:05.180 --> 00:10:06.860
that is a crap news source.

00:10:06.860 --> 00:10:09.850
They care more about views
and clicks than telling you

00:10:09.850 --> 00:10:12.700
the truth, you should
unsubscribe to that news source

00:10:12.700 --> 00:10:15.060
or that social media
account, and you should

00:10:15.060 --> 00:10:17.080
clean up your news timeline.

00:10:17.080 --> 00:10:19.360
Good journalists exist, they do.

00:10:19.360 --> 00:10:21.160
You have to find them,
you have to follow them,

00:10:21.160 --> 00:10:22.580
reward them for their work.

00:10:22.580 --> 00:10:24.830
Share their work, tell
people, hey, this is

00:10:24.830 --> 00:10:27.760
a well sourced article, you
should follow this person.

00:10:27.760 --> 00:10:29.070
Do some lateral reading.

00:10:29.070 --> 00:10:31.160
Use Google to get to the heart of where

00:10:31.160 --> 00:10:32.260
that image came from.

00:10:32.260 --> 00:10:35.600
And most important of all,
think before you click

00:10:35.600 --> 00:10:37.050
and share something online.

00:10:37.050 --> 00:10:39.950
Do some digging, try to
fact check it yourself,

00:10:39.950 --> 00:10:43.010
and only then should you
share information online.

00:10:43.010 --> 00:10:45.040
Do not spread misinformation.

00:10:45.040 --> 00:10:47.780
Let's be part of the solution,
not part of the problem.

00:10:47.780 --> 00:10:50.300
- If you see something on
social media that you're not

00:10:50.300 --> 00:10:52.370
sure about and you really
want some help figuring out

00:10:52.370 --> 00:10:55.570
if it's legitimate or not,
just share it with a hashtag

00:10:55.570 --> 00:10:58.550
or reply with the hashtag is this legit?

00:10:58.550 --> 00:11:01.300
And tag @mediawise, and my team and I will

00:11:01.300 --> 00:11:02.470
help you figure it out.

00:11:02.470 --> 00:11:05.035
- There you go, so, hashtag is this legit?

00:11:05.035 --> 00:11:06.440
You know we're just gonna totally flood

00:11:06.440 --> 00:11:07.930
your Twitter account, right?

00:11:07.930 --> 00:11:08.763
(Katy laughs)

00:11:08.763 --> 00:11:09.596
Or your Instagram.

00:11:09.596 --> 00:11:10.429
- We're ready.

00:11:10.429 --> 00:11:11.262
- You're ready?

00:11:11.262 --> 00:11:12.190
Okay, hashtag is this legit?

00:11:12.190 --> 00:11:14.860
You should be doing the
lateral reading yourself first,

00:11:14.860 --> 00:11:16.684
but if you really can't figure it out,

00:11:16.684 --> 00:11:18.580
this is the lady to talk to.

00:11:18.580 --> 00:11:19.660
- We'll help you figure it out.

00:11:19.660 --> 00:11:23.160
Also, follow us on all,
across social, @mediawise,

00:11:23.160 --> 00:11:26.080
we have some really cool fact
checking content that teaches

00:11:26.080 --> 00:11:27.730
a lot of the things we've
been talking about today.

00:11:27.730 --> 00:11:30.530
- Huge thanks to MediaWise
for supporting the creation

00:11:30.530 --> 00:11:32.590
of this video, and I
wanted to let you know

00:11:32.590 --> 00:11:35.400
about an upcoming series
on Smarter Every Day.

00:11:35.400 --> 00:11:40.380
I'm doing a very unique,
well researched series,

00:11:40.380 --> 00:11:43.500
I guess you would call it,
on algorithm manipulation.

00:11:43.500 --> 00:11:46.380
I went to YouTube, I went to
Twitter, I went to Facebook,

00:11:46.380 --> 00:11:49.320
I talked to the people in
charge of these things,

00:11:49.320 --> 00:11:52.330
the people that develop
countermeasures to try to fight

00:11:52.330 --> 00:11:54.960
the misinformation that
we experience online.

00:11:54.960 --> 00:11:56.730
I got to go talk to the
people that are in charge

00:11:56.730 --> 00:11:59.830
of those things, and
it is very fascinating.

00:11:59.830 --> 00:12:01.580
That is a, I mean, it's unlike

00:12:01.580 --> 00:12:04.520
anything I've ever seen
online, so, if you haven't

00:12:04.520 --> 00:12:07.810
subscribed to Smarter Every
Day, please help me spread

00:12:07.810 --> 00:12:09.800
the message on this by subscribing

00:12:09.800 --> 00:12:11.850
and sharing those videos
when they come out.

00:12:11.850 --> 00:12:14.180
I'm Destin, you're
getting smarter every day.

00:12:14.180 --> 00:12:15.013
Have a good one.

