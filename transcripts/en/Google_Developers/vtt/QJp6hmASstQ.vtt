WEBVTT
Kind: captions
Language: en

00:00:01.750 --> 00:00:03.710
So now, I'd like to
discuss App Engine

00:00:03.710 --> 00:00:06.000
Architecture and Services.

00:00:06.000 --> 00:00:09.480
So before I get started, I'd
like to warn you one thing.

00:00:09.480 --> 00:00:12.560
Google App Engine can be
dangerous for developers

00:00:12.560 --> 00:00:14.910
because it can change
your life.

00:00:14.910 --> 00:00:17.790
I found that I no longer was
interested in ordinary,

00:00:17.790 --> 00:00:21.310
traditional web application
technology anymore.

00:00:21.310 --> 00:00:25.670
After the App Engine project, I
had to build another typical

00:00:25.670 --> 00:00:28.460
MySQL kind of web server
with applications.

00:00:28.460 --> 00:00:30.960
And I was so tired
of doing that.

00:00:30.960 --> 00:00:34.290
So this job is very dangerous
and will change the way you

00:00:34.290 --> 00:00:37.700
approach web application
development.

00:00:37.700 --> 00:00:41.680
In this lesson, I'd like to
discuss about three things.

00:00:41.680 --> 00:00:45.480
One is the scalability and
reliability that's provided by

00:00:45.480 --> 00:00:47.280
Google App Engine.

00:00:47.280 --> 00:00:50.190
And I'd like to compare that
between the traditional way of

00:00:50.190 --> 00:00:54.300
designing web applications and
the App Engine design.

00:00:54.300 --> 00:00:56.970
I'd also like to discuss two
major components that are

00:00:56.970 --> 00:00:59.590
running inside the
App Engine stack.

00:00:59.590 --> 00:01:02.660
One is the Front End and how
the Front End works.

00:01:02.660 --> 00:01:07.100
And another is the App Server
and how it works.

00:01:07.100 --> 00:01:10.920
The first topic, "Designing for
Scale and Reliability." So

00:01:10.920 --> 00:01:14.130
here's an excellent example of
an App Engine application

00:01:14.130 --> 00:01:16.970
that's called Real time
Earthquake Monitor.

00:01:16.970 --> 00:01:19.350
And it's built by the NIED,
developed by the

00:01:19.350 --> 00:01:21.060
public sector in Japan.

00:01:21.060 --> 00:01:22.950
This is the actual
app running.

00:01:22.950 --> 00:01:26.600
You can see that there are many
blinking dots, blue dots

00:01:26.600 --> 00:01:29.040
or green dots, on the
map of Japan.

00:01:29.040 --> 00:01:32.280
Each dot represents the
acceleration of the ground

00:01:32.280 --> 00:01:34.440
surface right now in Japan.

00:01:34.440 --> 00:01:36.400
So if you're having an
earthquake right now, you'll

00:01:36.400 --> 00:01:40.050
be seeing yellow or red dots
will be spreading out all over

00:01:40.050 --> 00:01:41.830
that region.

00:01:41.830 --> 00:01:44.300
And I have another demonstration
that shows you

00:01:44.300 --> 00:01:48.700
how it worked in the 3/11
disaster we had last year.

00:01:48.700 --> 00:01:53.040
So you'll be able to see red and
yellow dots spreading out

00:01:53.040 --> 00:01:55.410
from the northern
part of Japan.

00:01:55.410 --> 00:01:59.400
Yes, that's what happened on
the 3/11 disaster we had.

00:01:59.400 --> 00:02:02.270
So let's discuss how the
app is designed for

00:02:02.270 --> 00:02:04.170
this kind of system.

00:02:04.170 --> 00:02:07.120
So this system is built with the
App Engine as well as the

00:02:07.120 --> 00:02:10.676
data center which is
hosted by the NIED.

00:02:10.676 --> 00:02:12.870
It has many sensors on
the surface of the

00:02:12.870 --> 00:02:14.640
ground all over Japan.

00:02:14.640 --> 00:02:17.470
And all the metrics will be
collected by them at the data

00:02:17.470 --> 00:02:21.010
centers for us where they can
create an image file.

00:02:21.010 --> 00:02:24.770
They ping and publish it in the
Google App Engine every

00:02:24.770 --> 00:02:26.400
one second.

00:02:26.400 --> 00:02:29.200
And then the client, the
browsers, the users, are

00:02:29.200 --> 00:02:31.980
polling that image every
two seconds.

00:02:31.980 --> 00:02:35.630
So that means at peak rate,
since there are about 20,000

00:02:35.630 --> 00:02:39.910
people, the App Engine will be
getting about 10,000 requests

00:02:39.910 --> 00:02:43.350
per second at peak.

00:02:43.350 --> 00:02:48.320
So what are the important
requirements for this app?

00:02:48.320 --> 00:02:53.660
We can summarize these as
scalability, reliability, and

00:02:53.660 --> 00:02:55.650
cost efficiency.

00:02:55.650 --> 00:02:59.510
So scalability because this site
will be getting a spike

00:02:59.510 --> 00:03:01.990
of traffic in the event
of the earthquake.

00:03:01.990 --> 00:03:04.490
So it has to provide more
scalability than

00:03:04.490 --> 00:03:06.510
your ordinary website.

00:03:06.510 --> 00:03:10.610
And also, it has to provide
these so high of a reliability

00:03:10.610 --> 00:03:13.700
because the people will be using
this site only when they

00:03:13.700 --> 00:03:14.900
have the disaster.

00:03:14.900 --> 00:03:17.695
If you're connecting to this
site and it's down because of

00:03:17.695 --> 00:03:20.630
the disaster, then it doesn't
mean anything.

00:03:20.630 --> 00:03:23.860
And also, it has to be more
efficient on cost.

00:03:23.860 --> 00:03:26.450
If you're preparing for the old
hardware resources that

00:03:26.450 --> 00:03:30.080
will be required to provide the
scalability, then it means

00:03:30.080 --> 00:03:31.880
that almost all the
time that hardware

00:03:31.880 --> 00:03:34.090
resource will be resting.

00:03:34.090 --> 00:03:36.410
Nobody's connecting
using that.

00:03:36.410 --> 00:03:38.600
So you have to be scalable
enough to provide enough

00:03:38.600 --> 00:03:42.490
server resources, but you don't
have that much money to

00:03:42.490 --> 00:03:45.430
buy all the hardware
resources itself.

00:03:45.430 --> 00:03:48.090
So how do we design a web
service like that that's

00:03:48.090 --> 00:03:49.390
scalable and reliable?

00:03:52.110 --> 00:03:55.100
This is how you do it in a
traditional way of web

00:03:55.100 --> 00:03:56.730
application design.

00:03:56.730 --> 00:03:59.960
Because it should be reliable
and scalable, you may have

00:03:59.960 --> 00:04:03.390
multiple instances
of Apache with a

00:04:03.390 --> 00:04:06.560
server or MySQL instances.

00:04:06.560 --> 00:04:08.540
But if you have a single
hardware failure on the

00:04:08.540 --> 00:04:11.140
server, that should failover
instantly.

00:04:11.140 --> 00:04:14.890
It means you also have to be
prepared for load balances or

00:04:14.890 --> 00:04:16.440
reverse proxies.

00:04:16.440 --> 00:04:19.260
And we'd need to buy two
or three of them.

00:04:19.260 --> 00:04:21.750
And if you have a traffic spike,
then the load should be

00:04:21.750 --> 00:04:25.220
balanced among the multiple
instances of the server.

00:04:25.220 --> 00:04:28.540
And if you are handling big
data and if it's growing

00:04:28.540 --> 00:04:32.060
rapidly, then it means you have
to have multiple MySQL.

00:04:32.060 --> 00:04:36.350
And you have to design a
sharded MySQL instance.

00:04:36.350 --> 00:04:38.610
And this can be very hard.

00:04:38.610 --> 00:04:41.730
If you have experience
developing this, then you know

00:04:41.730 --> 00:04:44.330
you have to configure
and test everything,

00:04:44.330 --> 00:04:46.200
every possible pattern.

00:04:46.200 --> 00:04:48.930
What if you have a failure
on the reverse proxy?

00:04:48.930 --> 00:04:52.000
What if you have multiple
failures on your web service?

00:04:52.000 --> 00:04:53.970
You have to configure
and test them all.

00:04:53.970 --> 00:04:56.800
And don't forget that you have
to hire the people who have

00:04:56.800 --> 00:04:57.990
this experience.

00:04:57.990 --> 00:05:01.140
It all costs so much.

00:05:01.140 --> 00:05:04.740
So App Engine provides them all,
allows you to build that

00:05:04.740 --> 00:05:06.960
kind of cluster and encapsulate
it in an App

00:05:06.960 --> 00:05:09.560
Engine application,
all running on

00:05:09.560 --> 00:05:11.580
Google's data centers.

00:05:11.580 --> 00:05:14.540
You don't need to administer
that anymore, like if you have

00:05:14.540 --> 00:05:17.160
a hardware failure on one
server, your application will

00:05:17.160 --> 00:05:18.390
not stop at all.

00:05:18.390 --> 00:05:22.160
If you have a traffic spike, the
app service automatically

00:05:22.160 --> 00:05:25.360
will add more instances on
demand based on the daily

00:05:25.360 --> 00:05:27.190
number of the request.

00:05:27.190 --> 00:05:30.070
If you're having so much big
data that it's growing

00:05:30.070 --> 00:05:32.930
rapidly, automatically,
Datastores will be splitting

00:05:32.930 --> 00:05:36.740
your data into multiple shards
of Datastore servers.

00:05:36.740 --> 00:05:38.660
And you can start using
App Engine without

00:05:38.660 --> 00:05:40.050
any money up front.

00:05:40.050 --> 00:05:42.250
You don't need to hire expensive
administrators to

00:05:42.250 --> 00:05:45.080
operate this massive cluster.

00:05:45.080 --> 00:05:48.150
After migrating onto App Engine,
you don't have to have

00:05:48.150 --> 00:05:51.480
a dedicated experienced Linux
administrator anymore.

00:05:51.480 --> 00:05:53.860
And let them focus on
the more business

00:05:53.860 --> 00:05:56.690
essential thing to do.

00:05:56.690 --> 00:05:59.930
To appreciate this App Engine
design more fully, you have to

00:05:59.930 --> 00:06:02.970
understand what is the
design goal behind

00:06:02.970 --> 00:06:04.510
the App Engine stack.

00:06:04.510 --> 00:06:06.750
It's not just the hosting
environment.

00:06:06.750 --> 00:06:09.150
And it's not just
the data center.

00:06:09.150 --> 00:06:12.120
Google App Engine encourages
you to use Google's best

00:06:12.120 --> 00:06:15.710
practices to design
your applications.

00:06:15.710 --> 00:06:18.420
So if you have experience in
producing a project that is

00:06:18.420 --> 00:06:21.430
using App Engine, you may have
noticed that there are certain

00:06:21.430 --> 00:06:24.590
restrictions, rules, and
practices to follow.

00:06:24.590 --> 00:06:27.730
But these are important best
practices to make your

00:06:27.730 --> 00:06:30.960
application design in the
Googly way; scalable and

00:06:30.960 --> 00:06:34.670
reliable, like the
non-relational data model.

00:06:34.670 --> 00:06:36.360
When you're using Datastore--

00:06:36.360 --> 00:06:39.380
not Cloud SQL or MySQL
instances--

00:06:39.380 --> 00:06:42.050
you have to design your data
model that can be sharded.

00:06:42.050 --> 00:06:46.320
And sometimes, you may want to
use the techniques, like in

00:06:46.320 --> 00:06:48.150
data normalization.

00:06:48.150 --> 00:06:51.080
That may sound like a downside,
but if you're an

00:06:51.080 --> 00:06:53.630
experienced web application
developer, you probably

00:06:53.630 --> 00:06:57.150
realize that this is actually
a best practice to make any

00:06:57.150 --> 00:07:00.020
scalable and reliable website.

00:07:00.020 --> 00:07:03.250
So the most important point is
that you have to make your

00:07:03.250 --> 00:07:06.640
application portable
and fine-grained.

00:07:06.640 --> 00:07:09.780
By designing your application
in this way, you can use the

00:07:09.780 --> 00:07:12.060
whole data center
as the computer.

00:07:12.060 --> 00:07:15.730
You are not writing your code on
a specific server anymore.

00:07:15.730 --> 00:07:18.400
You are writing code for the
data center or the group of

00:07:18.400 --> 00:07:20.510
data centers.

00:07:20.510 --> 00:07:24.130
You may notice when you're
using these APIs, like

00:07:24.130 --> 00:07:28.020
Datastore APIs or Memcache with
App Engine, that these

00:07:28.020 --> 00:07:31.180
APIs are abstracting a whole
bunch of data centers.

00:07:31.180 --> 00:07:34.570
It's not just an API running
on a single server.

00:07:34.570 --> 00:07:37.830
So in that way, you can utilize
the server resources

00:07:37.830 --> 00:07:42.030
at a very high utilization
rate.

00:07:42.030 --> 00:07:46.140
That ultimately means you get
significantly lower Total Cost

00:07:46.140 --> 00:07:47.080
of Ownership.

00:07:47.080 --> 00:07:49.790
You can leverage the scale of
economy because your App

00:07:49.790 --> 00:07:54.590
Engine is sharing the exactly
the same Google infrastructure

00:07:54.590 --> 00:07:57.070
that's used by other Google
services, such as Google

00:07:57.070 --> 00:07:58.950
Search or Maps.

00:07:58.950 --> 00:08:03.530
Google's SREs or site
reliability engineers will be

00:08:03.530 --> 00:08:06.410
watching your systems 24 by 7.

00:08:06.410 --> 00:08:09.960
And actually, Google SREs are
one of the premium roles in

00:08:09.960 --> 00:08:11.820
Google's entire company.

00:08:11.820 --> 00:08:14.580
It's very hard to hire
these kind of people.

00:08:14.580 --> 00:08:17.150
So to utilize and realize
benefits--

00:08:17.150 --> 00:08:19.660
getting benefits from those
goals are design principles

00:08:19.660 --> 00:08:21.470
behind the App Engine stack--

00:08:21.470 --> 00:08:25.530
you have to understand how
things are working inside the

00:08:25.530 --> 00:08:28.700
Google App Engine stack.

00:08:28.700 --> 00:08:31.980
Now, I'd like to go deeper and
dive into the two major

00:08:31.980 --> 00:08:33.190
components.

00:08:33.190 --> 00:08:34.740
One is the Front End.

00:08:34.740 --> 00:08:36.770
And the other is
the App Server.

00:08:36.770 --> 00:08:39.440
These parts, right here.

00:08:39.440 --> 00:08:44.850
So now, to the second topic,
"How the Front End works."

00:08:44.850 --> 00:08:47.520
Actually, I really like this
diagram because it tells so

00:08:47.520 --> 00:08:49.880
much to me about what's
happening inside the App

00:08:49.880 --> 00:08:51.680
Engine stack.

00:08:51.680 --> 00:08:56.170
So we'll refer back to it
throughout this lesson.

00:08:56.170 --> 00:08:58.980
What benefits would the
Front End provide?

00:08:58.980 --> 00:09:02.470
So here, you have the actual
graph that I have taken from

00:09:02.470 --> 00:09:05.470
the Earthquake Real time
Monitor applications.

00:09:05.470 --> 00:09:08.240
And you can see that the number
of requests per second

00:09:08.240 --> 00:09:11.530
on the site is getting most of
the time, it's around 1,000

00:09:11.530 --> 00:09:13.990
requests per second if
you're not having an

00:09:13.990 --> 00:09:15.400
earthquake or event.

00:09:15.400 --> 00:09:18.920
So it's still a very big
number of requests.

00:09:18.920 --> 00:09:21.110
And you can see the blue line.

00:09:21.110 --> 00:09:23.930
This is actually the number
of requests routed to the

00:09:23.930 --> 00:09:25.860
application instance.

00:09:25.860 --> 00:09:28.910
It's like 1/10 or 1/12.

00:09:28.910 --> 00:09:30.100
There's a huge difference.

00:09:30.100 --> 00:09:32.190
And it means that you don't
have to pay for this

00:09:32.190 --> 00:09:32.990
difference.

00:09:32.990 --> 00:09:35.800
You can just pay for
the blue request.

00:09:35.800 --> 00:09:37.430
So how do they do that?

00:09:37.430 --> 00:09:40.980
Earthquake site broadcasts the
image to thousands of users

00:09:40.980 --> 00:09:43.860
without handling all the
requests by the app.

00:09:43.860 --> 00:09:45.110
How can you do that?

00:09:47.380 --> 00:09:50.390
So the secret is in
the Front End.

00:09:50.390 --> 00:09:52.850
In the Front End component,
there are actually two

00:09:52.850 --> 00:09:55.100
different components.

00:09:55.100 --> 00:09:56.940
One is called the Google
Front End.

00:09:56.940 --> 00:10:00.530
And another thing is called
the App Engine Front End.

00:10:00.530 --> 00:10:03.460
And Google Front End resides
in a data center which is

00:10:03.460 --> 00:10:05.070
closest to the user.

00:10:05.070 --> 00:10:08.540
So if you have global users,
then all the data centers

00:10:08.540 --> 00:10:12.050
worldwide we have in each
region will be accepting

00:10:12.050 --> 00:10:15.770
requests from those users
because we have so many close

00:10:15.770 --> 00:10:17.350
relationship pairings--

00:10:17.350 --> 00:10:20.180
our relationship with
the major ISPs--

00:10:20.180 --> 00:10:23.060
most of the requests users will
be sending to us will be

00:10:23.060 --> 00:10:27.020
accepted, received by the
closest data center.

00:10:27.020 --> 00:10:28.640
And Google's Front
End is running

00:10:28.640 --> 00:10:31.080
inside that data center.

00:10:31.080 --> 00:10:34.050
And that's shared by most of
the other Google services,

00:10:34.050 --> 00:10:36.050
like Google Search
or Google Maps.

00:10:36.050 --> 00:10:39.840
And it also has the edge
caching capabilities.

00:10:39.840 --> 00:10:41.620
This is the key technology.

00:10:41.620 --> 00:10:45.830
And afterwards, because it's
received by Google, that

00:10:45.830 --> 00:10:48.380
request will be routed to other
data centers that's

00:10:48.380 --> 00:10:50.740
running the actual App
Engine services.

00:10:50.740 --> 00:10:52.810
We have Google's fibre
backbone, so it

00:10:52.810 --> 00:10:54.550
will be routed fast.

00:10:54.550 --> 00:10:57.240
And that second data center is
running another Front End

00:10:57.240 --> 00:11:00.730
called our App Engine Front End
that will provide the load

00:11:00.730 --> 00:11:04.230
balancing among the multiple
instances of the app servers

00:11:04.230 --> 00:11:06.530
as well as the static servers.

00:11:06.530 --> 00:11:08.780
So here, the key
points are edge

00:11:08.780 --> 00:11:11.830
caching and load balancing.

00:11:11.830 --> 00:11:15.120
So how do you enable the
edge caching feature?

00:11:15.120 --> 00:11:16.940
There are two ways of
using edge caching.

00:11:16.940 --> 00:11:19.460
One is setting the cache-control
header on your

00:11:19.460 --> 00:11:21.900
HTTP request.

00:11:21.900 --> 00:11:25.680
Then another one is using the
Static content configuration.

00:11:25.680 --> 00:11:28.280
You can just set these kinds
of headers and set the

00:11:28.280 --> 00:11:31.720
expiration period, like whatever
amount you want, to

00:11:31.720 --> 00:11:35.690
tell Google's Front End
to cache the content.

00:11:35.690 --> 00:11:37.450
And also, there's another
way that you can

00:11:37.450 --> 00:11:39.300
define a Static content.

00:11:39.300 --> 00:11:42.670
So if you have a static HTML
file or an image file on your

00:11:42.670 --> 00:11:47.150
applications, those are all
served by the App Server, from

00:11:47.150 --> 00:11:49.720
an App Server to the browsers.

00:11:49.720 --> 00:11:51.050
So it costs you.

00:11:51.050 --> 00:11:54.050
Instead, you can define a Static
content, like this, in

00:11:54.050 --> 00:11:57.940
the configuration file so that
all the content will be served

00:11:57.940 --> 00:12:00.380
by the static servers.

00:12:00.380 --> 00:12:06.400
So the last topic is, "How the
App Server works." Now, let's

00:12:06.400 --> 00:12:08.260
look at the App Server
in detail.

00:12:08.260 --> 00:12:11.740
What if the App Server can
dynamically increase the

00:12:11.740 --> 00:12:15.890
number of your app instances
based on the load you get?

00:12:15.890 --> 00:12:18.710
And the App Engine developer
needs to know how you can

00:12:18.710 --> 00:12:22.470
control it and get the best
cost-performance efficiency.

00:12:22.470 --> 00:12:25.520
The App Server is our server
that provides our runtime

00:12:25.520 --> 00:12:28.230
environment for your application
instances.

00:12:28.230 --> 00:12:30.520
Just like the virtual machines,
like when you're

00:12:30.520 --> 00:12:34.430
deploying a new application on
App Engine, the App Master

00:12:34.430 --> 00:12:38.040
will initially ask App Servers
to host that particular

00:12:38.040 --> 00:12:38.920
application.

00:12:38.920 --> 00:12:41.900
And if your application is
getting many requests from

00:12:41.900 --> 00:12:45.780
users, then the App Master
directs App Servers to have

00:12:45.780 --> 00:12:49.130
more application instances
to scale out.

00:12:49.130 --> 00:12:52.630
And also, App Master tells the
App Engine Front End the

00:12:52.630 --> 00:12:54.470
location of the App
Server where your

00:12:54.470 --> 00:12:56.300
application is running.

00:12:56.300 --> 00:13:00.160
So the App Master orchestrates
the whole load balancing or

00:13:00.160 --> 00:13:03.500
scaling out; whereas, the App
Server provides runtime

00:13:03.500 --> 00:13:07.230
environment for the application
instance.

00:13:07.230 --> 00:13:10.690
Application instances in App
Engine is very similar to

00:13:10.690 --> 00:13:12.040
virtual machines.

00:13:12.040 --> 00:13:15.680
And also, just like in virtual
machines, has a dedicated

00:13:15.680 --> 00:13:17.770
memory for your application.

00:13:17.770 --> 00:13:21.150
But the biggest difference
is it's fully managed.

00:13:21.150 --> 00:13:24.640
You don't have to bear the
burden of managing the whole

00:13:24.640 --> 00:13:27.330
operating system or
application stack.

00:13:27.330 --> 00:13:29.690
You don't have to care about
what version of the device

00:13:29.690 --> 00:13:32.500
driver you're using or what
kind of security patches

00:13:32.500 --> 00:13:35.730
you've applied to the OS or what
versions of the libraries

00:13:35.730 --> 00:13:38.780
or application services
you're using.

00:13:38.780 --> 00:13:40.560
You don't have to queue
them all up.

00:13:40.560 --> 00:13:42.750
Everything's taken care
of by Google.

00:13:42.750 --> 00:13:45.160
So that's the huge difference.

00:13:45.160 --> 00:13:48.520
And also importantly, if you're
running always inside

00:13:48.520 --> 00:13:51.600
the virtual machine, there is
a certain big overhead for

00:13:51.600 --> 00:13:54.940
that because you're running
different OS images on

00:13:54.940 --> 00:13:56.890
different virtual machine
instances.

00:13:56.890 --> 00:14:01.000
It is a certain overhead, like
it can be an overhead in terms

00:14:01.000 --> 00:14:04.450
of the CPU hours, for example.

00:14:04.450 --> 00:14:07.080
So application instances
in App Engine

00:14:07.080 --> 00:14:08.900
doesn't have that overhead.

00:14:08.900 --> 00:14:11.420
And also, it's fully managed.

00:14:11.420 --> 00:14:13.780
You have to understand there
are two different types of

00:14:13.780 --> 00:14:15.670
application instances.

00:14:15.670 --> 00:14:18.050
One is a Frontend instance.

00:14:18.050 --> 00:14:20.500
And another is a Backend
instance.

00:14:20.500 --> 00:14:22.920
In Frontend instance, it's
suitable for processing

00:14:22.920 --> 00:14:25.520
short-lived requests, like when
you click a button on

00:14:25.520 --> 00:14:26.720
your web application.

00:14:26.720 --> 00:14:29.780
And your request should be
handled within a few seconds.

00:14:29.780 --> 00:14:31.640
Those kinds of requests
should be handled by

00:14:31.640 --> 00:14:33.560
the Frontend, generally.

00:14:33.560 --> 00:14:37.250
Instead Backends should be used
for long-lived requests,

00:14:37.250 --> 00:14:38.760
like batch processing,
that should be

00:14:38.760 --> 00:14:40.740
running during the night.

00:14:40.740 --> 00:14:46.270
Or if the process would take 10
minutes or 10's of minutes.

00:14:46.270 --> 00:14:48.020
And Frontend instances will be

00:14:48.020 --> 00:14:50.460
dynamically created and deleted.

00:14:50.460 --> 00:14:54.440
It means you can minimize the
costs of the CPU hours where

00:14:54.440 --> 00:14:56.700
the Backend instances
will be statically--

00:14:56.700 --> 00:14:58.530
not totally statically.

00:14:58.530 --> 00:15:01.590
There are some dynamic
characteristics of the Backend

00:15:01.590 --> 00:15:02.750
instance, too.

00:15:02.750 --> 00:15:06.970
But it can be a higher cost
value Frontend instance.

00:15:06.970 --> 00:15:09.960
Frontend instances, as you
may know, there's a big

00:15:09.960 --> 00:15:11.150
limitation--

00:15:11.150 --> 00:15:13.720
the 60-second limitation
on that.

00:15:13.720 --> 00:15:17.350
So you have to design your
systems to process everything,

00:15:17.350 --> 00:15:20.850
to process every request
within 60 seconds.

00:15:20.850 --> 00:15:22.980
And also, you want to make
your application in a

00:15:22.980 --> 00:15:26.300
stateless design; whereas, the
Backend instance, there's no

00:15:26.300 --> 00:15:28.080
limit for a response time.

00:15:28.080 --> 00:15:30.070
So you can spend like
10's of minutes to

00:15:30.070 --> 00:15:32.610
handle a single request.

00:15:32.610 --> 00:15:34.950
And you can rely on
the statefulness

00:15:34.950 --> 00:15:38.150
of the server instance.

00:15:38.150 --> 00:15:42.140
But currently, we are having the
separation between them.

00:15:42.140 --> 00:15:44.590
And I'd like to show you how the
Frontend instance will be

00:15:44.590 --> 00:15:46.290
scaling out.

00:15:46.290 --> 00:15:50.200
App Engine are watching the
status of the Pending Requests

00:15:50.200 --> 00:15:53.910
Queues that's held by each
application instance.

00:15:53.910 --> 00:15:57.610
Each application instance has
a queue that will be holding

00:15:57.610 --> 00:15:59.180
the request from the users.

00:15:59.180 --> 00:16:01.660
So if you're getting a spike
of traffic, that means the

00:16:01.660 --> 00:16:04.130
queue will be filled up
with many requests.

00:16:04.130 --> 00:16:07.450
In that case, the App Engine
detects it and is trying to

00:16:07.450 --> 00:16:10.410
add more and more Frontend
instances.

00:16:10.410 --> 00:16:13.250
Once you have processed all the
requests from the queue,

00:16:13.250 --> 00:16:15.670
then App Engine tries to reduce
the number of Frontend

00:16:15.670 --> 00:16:17.240
instances--

00:16:17.240 --> 00:16:21.290
so dynamically scaling
out and scaling in.

00:16:21.290 --> 00:16:23.970
And the important thing to
notice is that there are two

00:16:23.970 --> 00:16:25.480
important parameters.

00:16:25.480 --> 00:16:27.540
One is the Pending Latency.

00:16:27.540 --> 00:16:31.070
And the other is
Idle Instances.

00:16:31.070 --> 00:16:32.395
What is Pending Latency?

00:16:35.200 --> 00:16:38.930
Pending Latency is the time
to hold the largest in the

00:16:38.930 --> 00:16:41.430
pending queue before creating
a new instance.

00:16:41.430 --> 00:16:44.130
It means if you are setting a
very short time period to

00:16:44.130 --> 00:16:47.200
these parameters, then App
Engine will be creating more

00:16:47.200 --> 00:16:50.540
and more instances instantly
without waiting for a certain

00:16:50.540 --> 00:16:51.920
amount of time.

00:16:51.920 --> 00:16:54.420
If you're setting this amount to
be a very big amount, like

00:16:54.420 --> 00:16:56.230
15 seconds, then your

00:16:56.230 --> 00:16:58.740
application can respond slowly.

00:16:58.740 --> 00:17:01.660
Plus, you can save your cost
for the instance hours.

00:17:01.660 --> 00:17:04.400
So you can have a balance
between the trade-offs,

00:17:04.400 --> 00:17:08.369
between the cost and
the responsiveness.

00:17:08.369 --> 00:17:10.609
Also, there's another important
parameter called

00:17:10.609 --> 00:17:14.520
Idle Instances, which is the
number of the instances you

00:17:14.520 --> 00:17:17.869
will be having even if your
application is not getting any

00:17:17.869 --> 00:17:19.900
requests from users.

00:17:19.900 --> 00:17:23.230
If you set this number to
something, like 10 instances,

00:17:23.230 --> 00:17:27.230
10 idle instances, then it means
even if you're getting

00:17:27.230 --> 00:17:30.230
no requests from users, there
will be 10 application

00:17:30.230 --> 00:17:32.490
instances running
all the time.

00:17:32.490 --> 00:17:35.890
It will cost you higher, but it
can respond to the sudden

00:17:35.890 --> 00:17:39.270
spike of traffic much
more quickly.

00:17:39.270 --> 00:17:42.400
How long will it take for
creating a new instance?

00:17:42.400 --> 00:17:45.150
Whenever a server tries to
create a new application

00:17:45.150 --> 00:17:48.450
instance, the App Server will
actually be reading the .class

00:17:48.450 --> 00:17:52.470
file or the .py file of the
application loading it, so the

00:17:52.470 --> 00:17:54.790
instance can do the
initialization.

00:17:54.790 --> 00:17:57.280
Normally, it would be
under one second.

00:17:57.280 --> 00:18:01.450
But if you're using so many
libraries throughout, then

00:18:01.450 --> 00:18:04.870
sometimes, like using the Spring
Framework for example,

00:18:04.870 --> 00:18:07.970
it sometimes takes 30 seconds
or 60 seconds.

00:18:07.970 --> 00:18:10.570
And you'll be seeing exceptions
in that case.

00:18:10.570 --> 00:18:13.570
So every App Engine developer
has to be careful about the

00:18:13.570 --> 00:18:16.810
loading request and what latency
you will get when your

00:18:16.810 --> 00:18:18.170
application will be
instantiated.

00:18:21.620 --> 00:18:22.730
Key Takeaways.

00:18:22.730 --> 00:18:26.160
App Engine encapsulates all
the cost and the effort to

00:18:26.160 --> 00:18:29.360
build scalable and available
applications on its cluster.

00:18:29.360 --> 00:18:31.920
It's not just a hosting
platform.

00:18:31.920 --> 00:18:34.650
It's a platform that encourages
users to design

00:18:34.650 --> 00:18:38.110
your system in Google's best
practices for scalability and

00:18:38.110 --> 00:18:39.800
reliability.

00:18:39.800 --> 00:18:41.120
The Front End provides the Edge

00:18:41.120 --> 00:18:42.960
Caching and Load Balancing.

00:18:42.960 --> 00:18:45.850
These are very important
technologies to utilize.

00:18:45.850 --> 00:18:48.140
And the App Server controls
the scalability of the

00:18:48.140 --> 00:18:51.060
Frontend instance and the
Backend instances.

00:18:51.060 --> 00:18:54.730
Pending Latencies and Idle
Instances are key parameters

00:18:54.730 --> 00:18:56.200
to use for controlling
that behavior.

