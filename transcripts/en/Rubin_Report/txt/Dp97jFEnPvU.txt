Speaker 1:          00:00          [inaudible]

Speaker 2:          00:04          joining me today is the author of the New York Times best seller rise of the robots technology and the threat of a jobless future. Martin Ford. Welcome to the Rubin report. Thanks for having me. I'm glad to have you here sir. Because dystopian futures, robots, skynet, all of it very much in my wheelhouse. And I want you to explain it all to me. Are you ready? Yes, definitely. All right, let's do it. So, uh, first off before we dive directly into robots and AI and all that, uh, just tell me a little bit about your background. What brought you to writing a book? Like?

Speaker 1:          00:35          Okay, so I studied computer engineering in college and then I worked as an engineer, design engineer for several years. Um, then I went back and studied business. Eventually I ended up starting and running a small software company up in Silicon Valley. And I ran that for many years. But even in the course of running that, I saw the impact that all this technology was having on, on jobs at my business and businesses like it. And that really got me thinking about this issue. And so about 10 years ago in 20, um, 2009, I wrote, uh, my first book called delights in the tunnel, which really argued that artificial intelligence was going to be the next big thing in computing and that it was going to have a dramatic impact in particular on the job market. And that book did well enough that it led to an opportunity to write this book in 2015 which really got, you know, quite a bit of attention. And since then I've kind of shifted my career to really be a futurist focused on what AI and robotics means for society and for the economy and especially for the job market. So I think they're going to be some huge challenges there for us.

Speaker 2:          01:37          Right. So we're going to unpack all of that stuff. But when you were writing about this in 2009 where people say are now, this is just pure science.

Speaker 1:          01:45          Yeah, I mean, I, I, this was initiative is very much off the radar back then. Um, it came with a fair amount of stigma and stigma. And the reason is that this concern or fear that machines might take a lot of jobs and there might be unemployment, it's, it's an old issue, has come up many times in the past going all the way back to the Luddites, right in England 200 years ago. And so there's actually this term neo luddite for, for a person that that is once again worrying about this issue. And so it was quite stigmatized. Um, so in 2009 when I wrote the book, um, you know, I was one of the, the earliest people to get out there with this. But since then things have definitely changed and I see a lot of people much more concerned about this even professional economists and so forth. So there definitely has been a shift in mentality over this last 10 years when we've seen things like, like the advent of, of self driving cars that look like they're going to be arriving soon. So forth.

Speaker 2:          02:40          What were, what markers where you seeing back in 2009 or a little bit before that even that were sort of pushing you in.

Speaker 1:          02:47          But the most important thing is what you might call Moore's law. The fact that that the power of computers is accelerating doubling every two years. And it was obvious that computers were going to get dramatically more powerful and there had to be an application for that. It has to be something you can do with that. And it became obvious to me that artificial intelligence was going to be the thing. And, and AI means essentially solving the same kinds of problems that the human brain can solve, right? And it means machines that in a limited sense are taking on cognitive capability to beginning to think. And that means that technology is going to begin to compete with and substitute for human being a human beings in, in a unique way. Something that we've never seen before. And is that scales across the whole economy has all kinds of jobs, skilled jobs and unskilled jobs. I think that, um, it becomes pretty clear that the, you know, it's going to have dramatic implications.

Speaker 2:          03:40          So when people think about robots, I think like there's a, there's a few different ways you can think about it, that you can sort of think about AI, which is sort of the same morphous thing that people sort of don't contextualize it to a physical object. Then they think of robots. They think of like, you know, c three Po and R Two d two and everything else. Um,

Speaker 1:          03:58          what

Speaker 2:          03:59          if you were just saying robots, what exactly are you

Speaker 1:          04:03          right? I, especially in this book, rise of the robust, I used a very broad meaning for that. I stay to mean anything that is, is automating something and taking over, you know, things that people can do. And very often that's just going to be software. Um, if you want to be more precise and technical. A robot is when you take artificial intelligence and you put it into a physical machine that can physically manipulate the environment. But what we're talking about is much broader than that. Um, so we're gonna, you know, we're, we're already seeing people like lawyers and doctors being impacted and it's not physical robots. It's often just software, artificial intelligence. Um, and actually the, you know, building physical robots that have dexterity that can manipulate the environment. That's actually one of the hardest aspects of this. And in some ways that where it may be where progress is going to be slowest, where in knowledge type work, you know, someone that's sitting in front of a computer doing some routine tasks, cranking out the same report again and again, that may actually be much easier to automate them then something physical.

Speaker 2:          05:03          So That's interesting. So the, the idea part of it is easier to replicate than the physical part, even though you'd think that just building a robot that can move the way you want it to move or something that seems technically easier than figuring out how to think like humans.

Speaker 1:          05:17          It seems like that from our perspective very often the reason is that to do these knowledge based jobs requires a lot of education and training, right? Um, but actually once you implement the technology, it actually can often be the reverse. The hardest thing to do is to build a physical robot that has dexterity, that has visual perception, that can can move around the way a person does it take to build, as you said, to kind of robot like c three Po from Star Trek. That's totally science fiction. We don't have anything remotely like that.

Speaker 2:          05:48          It seems like we're caught every now and again you'll see a video on youtube where they're getting a little closer. You know, they've got a robot, you know, jumping over something and ducking under something. Exactly.

Speaker 1:          05:56          You see those robots in particular from a company called Boston dynamics is doing very impressive things, but those videos are highly choreographed. The robots are controlled by someone that's outside the picture. This is not a thinking autonomous robot running around doing stuff by itself.

Speaker 2:          06:11          Okay. Terminator land just yet.

Speaker 1:          06:14          Not, not anytime soon at all. That's far in the future, but that, you know, we shouldn't allow, we shouldn't be distracted from the fact that the are things happening now that are going to have a really dramatic impact, but it's not the science fiction stuff that you see in the I robot movie and, and stuff like.

Speaker 2:          06:30          Right. So how much of the conversation is about all of this is about what you referenced a moment ago about just the speed of technology and that every two years the power doubles and all that, that we're all walking around with iPhones or cell, you know, we have super computers in our pocket and the way we can transmit information across the globe like that. And just how much of this is just related to speed

Speaker 1:          06:53          more than, I know that's a very big part of it. It is not just the speed of computers that have gotten faster and smaller of course, and now during our iPhones, but, um, it's the speed of communications, bandwidth, it's memory capacity. So we've seen this very broad based acceleration in technology and that's a huge part of it. Um, the other things is that there have been some breakthroughs in artificial intelligence, especially in the hottest area of Ai, which is called deep learning or deep neural networks. We've seen dramatic progress there and that's the thing that's really revolutionizing the field. And, and the other thing that's happened is that we are now throughout our whole economy and society collecting huge amounts of data, right? There's all this data out there that wasn't there before. And this data is basically the resource that is used to train these smart algorithms. And that's what artificial intelligence looks like right now. It's primarily machine learning. Um, and then he's just going to be incredibly disruptive.

Speaker 2:          07:50          Yeah. So as part of the potential problem here that we're building things that will be more powerful than us and we don't really understand that. So it's like we're putting so much information in our brains all the time. Maybe our actual physical brains can't take all this in. Like we don't have enough ram and our physical brains for all of the information that we're constantly slamming ourselves.

Speaker 1:          08:13          Well, it is definitely true that these smart algorithms, I mean they can look at, you know, huge amounts of data, millions and millions and millions of data points, right? Which no human being could do. So we already have our rhythms that in a very narrow sense in terms of doing very specific things are superhuman, right? They can vastly outperform, um, want any person does. Um, and they do things that we don't really understand it. Good example of that would be Wall Street, right? Where you've got these trading algorithms that can actually look at machine readable news. I mean, companies like Bloomberg actually make a news products that are designed for machines, not for people. These algorithms can read that news and then analyze it and then on it within, you know, tiny fractions of a second. So that would be an example of, of where technology is already getting ahead of what we can understand.

Speaker 1:          09:03          Uh, what do we do to rein some of it back in occasionally? Well, I, you know, if there are any lower or is it just once we start the process with anything like this, we just don't know where it is. It's a difficult question. Um, you know, they're going to be places where we're going to need regulation. Um, you can't just rein it in. I mean it's progress. It's happening. It says happening in part because of a competitive dynamic, right? Within capitalism between companies, between Google and Facebook and Goldman Sachs all competing to build, um, the latest technology. There is also a competition between United States and China. Um, all of that is going to push it forward relentlessly and trying to stop it. Um, it's probably kind of a fool's errand. Um, it's probably not possible and, and probably not, not really advisable. What I think we have to do are find ways to adapt to all of this progress.

Speaker 1:          09:55          And in some places that may mean certainly regulation. Um, and in other cases it will mean finding ways to address issues like unemployment in inequality that will, um, result from all of this progress. So let's just define some basic terms cause I think we ended up throwing out a lot of big terms here and then people are confused. So just when people are talking about the algorithm, can you just explain in simple terms what is the algorithm? Well and that was, we're doing this on youtube right now, right? We're always obsessed with the algorithm and algorithm. It's just essentially a computer program. It's something that goes step by step and does something. Um, what we've seen recently though is the emergence of a new kind of algorithm called machine learning algorithms. And this is what's really disruptive and the difference between a machine learning algorithm and a traditional computer programming a algorithm is that, you know, historically some programmer has, has sat down and told the computer to do what to do step by step with machine learning.

Speaker 1:          10:54          Instead you've got a smart algorithm that looks at lots and lots of data and then figures out for itself what to do. So in essence, it's kind of programming, it's programming itself, right? Yeah. Um, so, so is there a way to control it then? Well you his interest actually uncontrollable because once, once it's learned enough it just doesn't need the player. It's not so much that it's uncontrollable, but that, you know, we don't really want to control it. The whole point is to to unleash it and let it learn and do things. That doesn't mean that it's in any sense out of control or it's a danger to us or anything like, well the reason I was asking was sort of through through Youtube Algorithm Lens. Like one of the things we're finding out is they just want to keep you clicking all the time. You know where we put out a long form show, people are going to watch a full hour of our discussion. That's not really what the algorithm wants. It wants you from the way we understand it from some insiders, they want you to constantly be clicking on videos and basically fall into this click hole to just keep the machine

Speaker 2:          11:54          going. More and more and more. Now I understand why they want that sort of attention going in different places and all that. Um, but for what I do, I don't love the algorithm at the moment,

Speaker 1:          12:05          right? Right. So that depends on how they optimize the algorithm. But what's happening now is that you've got millions and millions of people watching youtube videos. And if they watch an entire video, then that will create a data point that says, you know, they were really interested in this. If they, if they start watching and you know, for a brief time and then they click away, then it'll show that they're less interested and then an algorithm comes around and looks at millions of those data points and can make recommendations for other videos. And as you said, I think what we've seen is that the video shown to people become more extreme, right? So if you're interested in something and then you'll get a more extreme version of that. And that's how to get people to Click. And a lot of people have been, you know, raising the alarm over that because that is kind of radicalizing people, right?

Speaker 2:          12:49          So what do you do about that? If you're, if you're a programmer and you're at youtube and you don't want people to be radicalized or just, you don't, even if you just don't want people to have to just be endlessly clicking, like there's this game to keep people addicted to all of these things. And it's like, I understand that we could put out a zillion clips so I could, you know, I could chop everything into two minute things and we could put them out and it would probably help us in terms of views and all of those things. Um, but I just don't want to play that game too.

Speaker 1:          13:14          Right, right. Technically I don't think that's a difficult problem that that depends on what the designer wants to do that. But the whole problem is that the algorithms are designed to make the most money for Google. Right? Right. And that's what's driving that. So it's not a, I don't think it's a computer design problem. It's, it's a capitalism problem, a profitability problem. It's the fact that that Google is a publicly traded companies. It, you know, it's, investors want it to make as much money as possible. And that's what drives it to design algorithms that maximize profitability. So keep your clicker. That may be the kind of place where maybe some regulation has to come in and say, you know, well, you're going to have to put some constraints on this. Um, if, if Google doesn't make the decision to do that itself.

Speaker 2:          13:58          Yes. I mean this is where I'm not a regulation guy, but it's like they're pushing me to my limits. I mean, this is what I keep saying about all the tech companies right now when it comes to censorship and everything else, it's like they're not giving us much of a choice here.

Speaker 1:          14:12          Right? I mean, it's a challenging problem for sure too, to figure out, you know, for AI to figure out what's in the video and in terms of is there something there, then it should be censored or not. That's the decision they're making. And that's, that's quite different from just optimizing, getting people to watch videos, because in order to do that, you know, you don't care what's in the video. That's the whole problem. Right? Right. It's just tracking statistics. But if you actually want to analyze what's in the video, is there something in there it dangerous or you inciting people to violence or something like that for artificial intelligence to figure that out, it's still much, much harder. And that's why we're running into this problem. I think.

Speaker 2:          14:49          How is deep learning different than artificial intelligence? That's, yeah, that's just the next level of order.

Speaker 1:          14:53          Official intelligence facing is a kind of, of artificial intelligence is right now the hottest area of AI and deep learning or deep neural networks basically means a system that is loosely designed on the way a brain would work. It has artificial neurons that are roughly similar to to the neurons in your brain. And that's the way it works. Um, and this is an idea that's been around, you know, for, since the 1950s at least. Um, but just within the last six years or so, we've seen just an explosion in this technology. Um, and we've now got systems that can translate languages, um, from Chinese to English that can do better than people at recognizing visual images. We've got radiology systems that can look at medical images and find cancer there and in some cases can do that better than human doctors. So this is absolutely, absolutely the hardest area of Ai. It's, um, also what's enabling self driving cars, for example. Um,

Speaker 2:          15:51          so is this the great catch 22 of, of all of robotics is that it's doing these incredible things and then as you talk about in the book, it's going to put a lot of people out of work.

Speaker 1:          15:59          Well, I think that's one of the real problems with it. I mean, and you know, we're ultimately going to have to make a choice as to whether we want to allow that progress to continue and get the enormous benefits of that progress. But if that's going to come at a cost of, of making some set of our population unemployable or, or maybe deskilling jobs to the point where people just don't have adequate incomes, even if they don't, even if they do have a job, um, then we've got to find a way to adapt to that. Right? And that's why, for example, I've talked a lot about a universal basic income as one possible approach to that. Um, but I'm very much against the idea that we should stop progress because this is where we are, you know, this is what progress is going to look like in the future and we don't want to stop it because progress is the thing that is made us better off over.

Speaker 2:          16:46          Is there any evidence that you are ever in history? You could stop progress actually. And even if we want it to stop it right now, let's say you laid out the greatest case why this thing is going to run out of control. It's going to put half of us out of business, you know, income inequality is going to go crazy, poverty, et cetera, et cetera. Is there any case where technology existed that we somehow put the, put the brakes on it?

Speaker 1:          17:07          I'd be quite skeptical that we'd be able to do that. Um, again, in part because of competition, not just between companies but between countries. Maybe we would do it, but then China didn't put the brakes on and they would pretty soon be vastly ahead of us. Right. So that would be a problem.

Speaker 2:          17:23          Is that the catch 22 then for regulation because it's like we may try to regulate some of it, but if China's not regulating it or,

Speaker 1:          17:29          exactly. Yeah. One of that's one of the biggest problems is that you would, you would put your country at a disadvantage unless you could do it on a global basis. And of course, doing anything on a global basis is incredibly hard as you see with climate change, for example. Um, so again, my perspective is that rather than trying to slow it down, what we should do is find a way to adapt to a ledge, just let it run, but understand what the implications are going to be and figure out a way to adapt to that. And that's where the idea of a basic income comes in. So I want to talk a little bit more about ubi, but before we do that, can you talk a little bit just about how this has affected certain industries and how some industries haven't quite been affected yet?

Speaker 1:          18:09          Right. So in general, the point that I'd make is that it's going to affect everything. I mean, artificial intelligence is going to be like a utility. It's going to be like electricity, right? And no one says what industries are most impacted by electricity, right? I mean, you know, everything relies on electricity, right? And the same will be true of artificial intelligence and machine learning. So, um, in the long run, it's everywhere. Um, in the near term, clearly, you know, manufacturing has already been impacted by automation. Generally. We've seen a dramatic decrease in advanced countries and the number of people employed in manufacturing, and that's going to continue, uh, the robots and the automation used in factories are going to get a lot more effective, more dexterous. There'll be able to do the jobs that, that right now only people can do. Um, but it's gonna scale to many, many other areas in finance.

Speaker 1:          18:56          Um, it's going to have a dramatic impact. A lot of white collar jobs there where people are sitting in front of a computer cracking out reports or something. Right? Um, recently I saw something that the CEO of a Deutscha Bank, one of the big bank said he thought he could get rid of half of his employees in the relatively near future using using this technology. Um, healthcare is, and it's an area where it's going to be slower because it's really hard. You've got doctors and nurses that need to engage with patients on a one on one basis, right? And provide a lot of individual human like service. Um, and it's been, and that's one of the reasons that healthcare costs are so high in the United States right now because we have not seen the kind of productivity increases there that we've seen in say manufacturing. So what, what could we do to see that we're, we're, we're beginning to see evidence of that.

Speaker 1:          19:49          As I mentioned, you've got systems now that can read medical images. So you're going to begin to see, uh, the introduction of artificial intelligence in medicine. I don't think that it will for the most part, at least in the near term, it's not going to completely replace doctors, but it will become kind of a second opinion. Um, it will run alongside a doctor, you know, we'll always be there. We will make, um, every doctor be able to perform at the level of the best doctor, right? Because, because there'll be this incredible intelligence there. So that will be an enormous benefit. Um, there are lower and then eventually if you just extrapolate that down the road, he could replace the doctor too. Right? I mean, I like in the movie alien in a million other things. Exactly. I'm, although I would say in general, doctors are relatively safe because they are highly regulated, right?

Speaker 1:          20:34          There are all kinds of rules about medicine and you need to have a doctor or, or a pharmacist there and, and those, so those roles are relatively protected, protected where if you're a white collar job and some corporations sitting in a cubicle somewhere, you don't have any protections at all. So for that reason, um, I would worry a bit less about doctors a disappearing in the near term. But you know, in healthcare there definitely are going to be lots of applications. You already see robots in hospitals delivering things. Um, you see robots beginning to be used in elder care looking after older people, which is certainly one of the biggest opportunities because we have this aging population. Um, pharmacy robots are, are huge things. They're already robots that do, you know, thousands and thousands of per Chris Prescriptions in, in hospitals and so forth, very efficiently. So this is coming.

Speaker 1:          21:22          Um, it will take a little bit longer in healthcare than in some other areas. Um, but eventually it's going to be everywhere. Um, in retail, you know, they're, they're, uh, Walmart is beginning to introduce, uh, robots and of course, retail in general is migrating more and more toward Amazon. Um, which in theory means that jobs, you know, they might move from a retail store to an Amazon warehouse, but once the jobs go to that Amazon warehouse, now they're in a very controlled environment and there are already lots of robots there. And those robots are going to get dramatically better in the next five or 10 years, you know? So in effect, you could have a giant Amazon warehouse that we've all driven by one of these, these huge monstrosities and it could basically be run by all robots. And you're getting very close to that.

Speaker 1:          22:08          And definitely a lot fewer people. I mean, right now inside those robots, inside those warehouses, you have huge numbers of robots and the robots will do something like bring a whole shelf of inventory to a worker, but then the workers got to reach in there and grab the item off the shelf and put it in the box because the robot right now can't do that. It doesn't have the visual perception and the dexterity to do that. But that will change over the next five to 10 years. And so those environments are going to become a lot less labor intensive. That's not to say they'll be fully automated, but there are going to be fewer jobs there. And that's something to worry about because this is one of the brightest areas right now for job creation. Right? So we're gonna so we're going to watch a certain sector or many sectors of jobs just disappear altogether.

Speaker 1:          22:50          And yet at the same time, I guess the counter argument or the people that would say, we shouldn't be so alarmed about this, we'd say, well, all the costs of everything will go down because the robots will be able to do things at a much more efficient, cheaper level. Right. So people won't need as much disposable income, that sort of thing. That's right. I mean that's absolutely true there. I am very skeptical that that's kind of solves the problem though. Me, you can think about it. If you don't have a job at all, then your income is zero. It doesn't matter how matter, how cheap stuff is. The other thing is that the really big ticket items, the things that really are putting people under water, our housing, education, health care, and these are exactly the areas where, um, technology is at least in the short and medium term going to have the least impact, right?

Speaker 1:          23:37          I mean housing in particular, some day we might have big three d printers that make it really cheap to produce housing, but, but there's still a problem with land right in the, if you're in Los Angeles or, or up in San Francisco, then there's no land left, right? It's already know, you know, it's already very scarce and, and that's what drives property values so high. So you can't solve that problem and necessarily just with technology. So as incomes fall, um, you know, many people are not going to have the income to really cover the basics and that that's going to be a big problem.

Speaker 2:          24:08          Okay. So that's the right transition then to universal basic income. So my, my default position on UBI, and I've heard arguments on both sides and I think I told you I have Andrew Yang coming in soon and we'll discuss it further. My default position is that if you give people just enough to survive, that you're sort of stealing just like the most basic human right of just like go get something for yourself and that it's going to create this class of people sort of not by their own fault that we'll just have the bare minimum to get by and then there'll be able to stay at home and play video games and watch porn and basically do nothing all day long and will, and that's actually taking something from them rather than giving something to them. That's sort of my sort of like high level philosophic position on it.

Speaker 1:          24:56          Right. I, I, the argument I would make is that once the society reaches a certain level of prosperity as we have, um, if you want to continue to have capitalism and a market is very important to have the kind of incentive that, that you're alluding to there. But I would argue that maybe the incentive doesn't have to be so daunting that if you don't work, you're living on the street or eating out of garbage cans, right. That maybe it's enough to say that you can basically survive if you're not motivated, but you're not going to have a terrific life. You're not going to have a great life. And I think that that a number of studies have been done with basic income that showed that when you give people this money, they don't in fact just drop out and stay home and do nothing. They are actually motivated to do something more. Um, they invest in their family and education. They work if they can, they may be start a small business. So actually if you give people that basic safety net, um, you can create an environment where people are actually more willing to take risks. So for example, they might start a new business. They might be willing to leave a safe job where they're not learning anything. They're not growing and work for a startup company, do something more risky. Right.

Speaker 2:          26:05          Um, but as the inherent problem that then if they start getting some success, then they lose the ubi.

Speaker 1:          26:11          No, no, no. See that's, that's the whole solution to a basic income. And that's what makes it different from other forms of safety is that it is unconditional in a sense that everyone gets it. Now what that means is that if I get my basic income and I choose to just play video games, then I'll have that basic income. But if someone else is more ambitious, they get their basic income and they go and work, even if it's only part time, they start a small business, then they, they get the basic income and they also get that additional income. We don't tax it away, at least not at the lower level. So the key point is that the person that is productive that is willing to do something to work will always be better off than the person that does nothing. Right? And that's really key to it because, um, the problem with our existing social safety net is exactly what you said, that if you do something, find a job, then you lose those benefits.

Speaker 2:          27:06          The cliff has to be really high. They need to be willing to leave. Yeah.

Speaker 1:          27:09          Right. Right. And that's exactly what it's called, a poverty trap. Right? As you get into a situation where you look at the options around you and, and anything you do, does it make you better offer you gonna makes you work softened. So you're stuck there. He can't move. The worst possible example of that in United States is the social security disability program, right? Which is intended for people that are injured on the job and then they can't work. But actually a lot of people now are gaming it probably because they're desperate. They need an income. And so they'll go and tell their doctor they've got pain in their back or something and they'll get through the loops and they'll get onto this program, which gives you an income. But once you get there, you can't even be seen to be able bodied. People are worried even to go and work in their garden or something because someone will see them and then they'll lose their benefits. Right. Um, so that's a really terrible example of this kind of income where basic income, we give it to everyone and it's unconditional. And then we, we encourage people to do more. Right. And that, that, that's really important. That's one of the strongest arguments for a basic income scheme.

Speaker 2:          28:11          Yeah. So let's get into some of the nuts and bolts of it. First off, do you view it as something that would have to be done federally? Because obviously if you live in Los Angeles or San Francisco, your cost of living is way higher than say if you live in Missouri. So is this a, is this a federal program? Are we throwing this to the states?

Speaker 1:          28:27          Yeah, I would imagine it needs to be done on a national level. Um, and the reason is what you can think of as kind of like the kind of adverse selection problem you get in in insurance, right? If, if Los Angeles has a basic income, then people all over the country are going to move to Los Angeles to get that right. And they're going to show up here and, and, and overwhelming the system. So it needs to be national rather than, than local. Right.

Speaker 2:          28:51          But what do you do about the disparity in cost of living

Speaker 1:          28:53          and all these places? Well, you know, one issue there is that a basic income is mobile, right? So maybe you don't have to live in Los Angeles or San Francisco. You can take your basic income and you can move to Detroit, right? And Dare you might have a pretty decent life. Um, you, you, you can have housing. They're much cheaper. Right? So the difference between a basic income and a job is that you can take it everywhere. So people would kind of readjust and they might, some people might choose to leave, leave high cost areas and, and live in cheaper places and so forth.

Speaker 2:          29:25          So how do you find all this? That always is the big one. Are you scrapping all the social programs that exist right now or are your tax and billionaires out the Wazoo?

Speaker 1:          29:32          Well, combination there. Nobody think definitely you need to raise more revenue. Um, I think inevitably one of the things that we are seeing with the economy largely as a result of, of technology is that more and more income is going to capital unless it's going to labor. So businesses and investors and people like that are getting more income and average working people are getting less. So what that means for the future. I think it's inevitable that we're going to have to tax capital more and labor less. Um, and that may involve higher business taxes are taxes on the wealthiest people that have access a lot. Lots of capital mean that's as a libertarian, you might find that objectionable, but I think it's inevitable. You ultimately, if you're going to have a taxation scheme, you have to tax the people that have the money, right? You can't, you can't get blood from a rock as they say.

Speaker 1:          30:24          Right? So how do you decide what the level is now? I get you could live in La and the cost of living's high and then maybe you'd say, all right, well I can't, I can't make it here in a way I wanted to do. So I want to go somewhere cheap. But how do you figure out, well, what is it that is the basic stuff. I mean, we're called UBI. So what is the basic stuff that people are supposed to have? Well, I mean the, in terms of the level of the income, most people are talking about around a thousand dollars a month. Um, Finland had a, an experiment where it was like 600 euros or something. So these are pretty low amounts. I mean, you know, try, can you imagine living on $1,000 a month? Right? I used to do it. Yeah, it was not fun. It's not so easy.

Speaker 1:          31:06          So I think one advantage of these programs is that they're going to start at a, at a low level, and we can imagine that as technology advances and society becomes more prosperous, that that could be raised over time. But initially it's going to be a very low level. So I don't think we have to worry too much about destroying the incentive for people to work and so forth. It's going to give people a very, very minimal cushion. Um, but they're still gonna have that incentive to work. Right. So interesting because it just does set all my libertarian bells off that well, the second you give it to somebody, so we give 1000 bucks to everybody. Well, immediately you're going to have politicians saying this isn't enough and we have to make it more and we have to make it more in that. Then that becomes the cycle where [inaudible] is shifting money around and it's just because no one's ever gonna no matter what basic level we get most people who no one's ever going to be like, all right, well they were okay then that's a real concern.

Speaker 1:          32:01          Um, I would say though that, you know, a basic income or, or there are other flavors of and a guaranteed minimum income, a negative income tax. These are ideas that in the past have been embraced by Libertarians. Friedrich Hayak was a big proponent of, of a guaranteed minimum income. Um, Milton Friedman was for a negative income tax and the idea is that you're creating really a market based safety net, right? Rather than having government, um, how's people feed people, uh, control industries or try to take over businesses and run them in a way that artificially creates jobs and so forth. Rather doing that, just give people some money, let them go out and participate in the market. So it actually is a market oriented libertarian approach to having some kind of safety net. But I think you're the idea of it being politicized. That's a real concern.

Speaker 1:          32:53          And one, one thing I actually have suggested in some of my writing is that we might set up a separate institution to kind of manage that. Maybe something like the Federal Reserve do it would be independent and not part of the political process and might manage the level of, of a basic income because you could actually use it also to, to respond to recessions. For example, if there's an economic downturn, maybe pay people a bit more and then that would help you get out of the recession. Right? It would be kind of a Keynesian response to it. Um, so I think there are a lot of possibilities there, but you're right, we don't, we don't want every politician running on the platform of I will increase your basic income, right. That that wouldn't be good. So that's something that just strikes me as sort of real politic related to all this is just the way people are.

Speaker 1:          33:38          Once you give them something, they want more. I don't blame people for that. It's just sort of, exactly. So that's the way politics works. So that's something that we need to think about from the beginning. As I said, you know, maybe you put it in the hands of a separate institution. One other thing I proposed is that maybe we can build incentives into a basic income. Um, if people stay in school, paid them a bit more than people that just play video games where people go and work in the community, you know, help other people pay, pay them a bit more. So that, I think it's really important to have sort of a ladder for people that they feel they can somehow do better. Because that, I mean, the issue you raised everywhere, arrays. Before that we could create this class of people that just do nothing is something to be concerned about. But there are ideas that we can, I think employee to, to really address that.