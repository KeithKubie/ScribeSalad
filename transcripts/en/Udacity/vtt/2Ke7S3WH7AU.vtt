WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.000
So we're going to provide a start on this code

00:00:02.000 --> 00:00:05.000
and then we'll leave the crucial part of it

00:00:05.000 --> 00:00:07.000
for you to do, as a quiz.

00:00:07.000 --> 00:00:09.000
You should feel free, at any point,

00:00:09.000 --> 00:00:11.000
to stop and try to figure out more of the code on your own.

00:00:11.000 --> 00:00:13.000
There are lots of different ways to do this

00:00:13.000 --> 00:00:15.000
and we'll show you one--

00:00:15.000 --> 00:00:17.000
and you'll finish that as a quiz.

00:00:17.000 --> 00:00:20.000
So the first thing we're going to do is define 2 constants.

00:00:20.000 --> 00:00:23.000
So we're going to use "d" as the damping factor.

00:00:23.000 --> 00:00:27.000
And I'll use 0.8 as my damping factor.

00:00:27.000 --> 00:00:31.000
That's the probability, thinking about our random Web surfer--

00:00:31.000 --> 00:00:33.000
that she selects the link on the current page,

00:00:33.000 --> 00:00:36.000
rather than starting over with a new random page.

00:00:36.000 --> 00:00:38.000
The other constant I'm going to define here,

00:00:38.000 --> 00:00:40.000
we'll call "numloops".

00:00:40.000 --> 00:00:44.000
That's the number of times we're going to go through the relaxation.

00:00:44.000 --> 00:00:46.000
What we're computing is the value of rank

00:00:46.000 --> 00:00:48.000
at some time step.

00:00:48.000 --> 00:00:51.000
The number of times we go through that

00:00:51.000 --> 00:00:53.000
is going to determine the accuracy of our ranks.

00:00:53.000 --> 00:00:55.000
We'll use 10 as the number of loops.

00:00:55.000 --> 00:00:57.000
You can experiment with changing that

00:00:57.000 --> 00:00:59.000
and one of the questions in the homework assignment

00:00:59.000 --> 00:01:02.000
will ask you to think about what happens when you change that.

00:01:02.000 --> 00:01:04.000
So now we need to start--we said, initially,

00:01:04.000 --> 00:01:08.000
the rank of each URL is 1 divided by the number of pages.

00:01:08.000 --> 00:01:10.000
and so the dictionary ranks,

00:01:10.000 --> 00:01:12.000
we want to initialize with those values.

00:01:12.000 --> 00:01:16.000
So we're going to create and empty dictionary--we'll call it ranks.

00:01:16.000 --> 00:01:20.000
The number of pages--the number of pages, we can get from the graph.

00:01:20.000 --> 00:01:22.000
The graph has a dictionary of nodes

00:01:22.000 --> 00:01:25.000
and len(graph) will tell us the number of entries in that dictionary.

00:01:25.000 --> 00:01:28.000
So that's the number of nodes in the graph,

00:01:28.000 --> 00:01:30.000
which is the number of pages that we crawled.

00:01:30.000 --> 00:01:32.000
And now we want to go through the pages,

00:01:32.000 --> 00:01:37.000
initializing each page to the value, 1.0 / npages.

00:01:37.000 --> 00:01:39.000
And I'm remembering to use 1.0 here,

00:01:39.000 --> 00:01:42.000
to make sure the division is done as floating point division

00:01:42.000 --> 00:01:44.000
and we get an accurate number,

00:01:44.000 --> 00:01:46.000
rather than integer division.

00:01:46.000 --> 00:01:48.000
So now we've initialized the ranks.

00:01:48.000 --> 00:01:51.000
We have a dictionary that maps each page to its current rank,

00:01:51.000 --> 00:01:53.000
which is the 1.0 / npages.

00:01:53.000 --> 00:01:55.000
So now we get to the interesting part.

00:01:55.000 --> 00:01:57.000
We need a loop

00:01:57.000 --> 00:01:59.000
that's going to go through

00:01:59.000 --> 00:02:02.000
the number of times of numloops.

00:02:02.000 --> 00:02:04.000
Each time through this loop what we want to do

00:02:04.000 --> 00:02:06.000
is update the newranks,

00:02:06.000 --> 00:02:09.000
based on this formula--using the oldranks.

00:02:09.000 --> 00:02:11.000
And then, at the end of the loop, we're going to make

00:02:11.000 --> 00:02:14.000
the variable ranks hold what was previously newranks--

00:02:14.000 --> 00:02:16.000
and that way we can keep going.

00:02:16.000 --> 00:02:18.000
Each time, we're going to get a new value for newranks.

00:02:18.000 --> 00:02:20.000
At the end of doing all the updates

00:02:20.000 --> 00:02:24.000
we're going to update ranks to refer to whatever newranks did.

00:02:24.000 --> 00:02:26.000
So that means, each time through this loop,

00:02:26.000 --> 00:02:29.000
we're going to create a new dictionary, called newranks,

00:02:29.000 --> 00:02:31.000
that starts as empty

00:02:31.000 --> 00:02:34.000
and we're going to add all the pages to newranks

00:02:34.000 --> 00:02:36.000
as we update their rank.

00:02:36.000 --> 00:02:39.000
So to do that, we need to go through the pages in the graph,

00:02:39.000 --> 00:02:42.000
and for each page, what we want to do is compute

00:02:42.000 --> 00:02:44.000
the newrank for that page.

00:02:44.000 --> 00:02:46.000
And the first thing we'll do is this part--

00:02:46.000 --> 00:02:52.000
The newrank is: (1 - d) / npages plus this summation.

00:02:52.000 --> 00:02:55.000
So the first thing we'll do is introduce a new variable.

00:02:55.000 --> 00:02:58.000
We'll call it newrank, and we'll assign it to this value.

00:02:58.000 --> 00:03:00.000
Then we're going to update it, as we go through

00:03:00.000 --> 00:03:04.000
the pages that link into this page.

00:03:04.000 --> 00:03:09.000
So we'll start by initializing newrank as (1 -d) / npages.

00:03:09.000 --> 00:03:12.000
So then what we need to do is update for the summation.

00:03:12.000 --> 00:03:15.000
And I'm going to leave this blank, and I'm going to skip that for now.

00:03:15.000 --> 00:03:17.000
This is going to be left, as a quiz.

00:03:17.000 --> 00:03:19.000
We'll finish the rest of the code,

00:03:19.000 --> 00:03:21.000
and then your quiz will be to finish this part of the code,

00:03:21.000 --> 00:03:26.000
which is really the most interesting part of computing the Page Ranks.

00:03:26.000 --> 00:03:28.000
Once we've done that--so we use newrank as our variable

00:03:28.000 --> 00:03:30.000
to keep track of the rank for this page.

00:03:30.000 --> 00:03:32.000
But we want to update our dictionary

00:03:32.000 --> 00:03:36.000
so we're going to add an entry, newranks.

00:03:36.000 --> 00:03:38.000
We're still within the foreloop--you're going to

00:03:38.000 --> 00:03:41.000
put your code that sums up all the links here.

00:03:41.000 --> 00:03:43.000
Once we've done that,

00:03:43.000 --> 00:03:46.000
we've got the value of newrank that reflects both

00:03:46.000 --> 00:03:49.000
the probability of starting from that page

00:03:49.000 --> 00:03:52.000
and the popularity, from all the inlinks.

00:03:52.000 --> 00:03:54.000
And so we'll update this to be newrank.

00:03:54.000 --> 00:03:56.000
We've added that to our dictionary.

00:03:56.000 --> 00:03:59.000
So once we've finished looping through all the pages in the graph--

00:03:59.000 --> 00:04:02.000
well now we're ready for the next step.

00:04:02.000 --> 00:04:05.000
So that means we want to make the variable, ranks,

00:04:05.000 --> 00:04:07.000
refer to the newranks--

00:04:07.000 --> 00:04:10.000
so we've changed the time step to the next time step.

00:04:10.000 --> 00:04:12.000
And now we're going to go back through this loop.

00:04:12.000 --> 00:04:15.000
And we go through this loop the number of loops times.

00:04:15.000 --> 00:04:18.000
Each time, we're updating the ranks and when we're done,

00:04:18.000 --> 99:59:59.000
what we want to return is ranks--that's the dictionary that maps each page to its rank.

