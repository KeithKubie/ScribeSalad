WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.395
[MUSIC PLAYING]

00:00:06.227 --> 00:00:08.622
[APPLAUSE]

00:00:10.314 --> 00:00:11.480
PATRICIA SCANLAN: Thank you.

00:00:11.480 --> 00:00:14.930
Thanks for the
invitation to come here.

00:00:14.930 --> 00:00:18.160
So I'll just talk to you
about the company SoapBox Labs

00:00:18.160 --> 00:00:19.810
to start with.

00:00:19.810 --> 00:00:23.614
We do children's speech
recognition technologies.

00:00:23.614 --> 00:00:32.772
So 2017 and 2018 were, like,
huge years for voice assistance

00:00:32.772 --> 00:00:33.480
across the world.

00:00:33.480 --> 00:00:37.190
It started, I think it was
in 2015 when Amazon first

00:00:37.190 --> 00:00:38.952
released the Alexa
into the US market,

00:00:38.952 --> 00:00:41.410
and it's taken a long time to
get to the side of the ocean.

00:00:41.410 --> 00:00:43.760
And since then we've
seen newcomers come on.

00:00:43.760 --> 00:00:46.190
But more recent,
we know that Google

00:00:46.190 --> 00:00:51.011
came on the heels of
Alexa, Apple this year--

00:00:51.011 --> 00:00:53.510
Facebook are talking about a
device by the end of this year.

00:00:53.510 --> 00:00:57.180
They postponed it, but still
looks like it's coming out.

00:00:57.180 --> 00:00:59.420
And what's changed over
the last couple of years

00:00:59.420 --> 00:01:01.730
is people are beginning to
see the utility of voice

00:01:01.730 --> 00:01:02.990
assistance.

00:01:02.990 --> 00:01:07.100
A couple of years ago, speech
recognition technologies

00:01:07.100 --> 00:01:11.550
were probably working
in the 80% accuracy.

00:01:11.550 --> 00:01:14.590
So that meant they were still
quite frustrating to work with.

00:01:14.590 --> 00:01:16.320
So people began--
just kind of doubted

00:01:16.320 --> 00:01:17.750
it would every really take off.

00:01:17.750 --> 00:01:20.840
But myself, I've been working
in this area for over 20 years,

00:01:20.840 --> 00:01:23.150
and it was kind of a case
of once deep learning,

00:01:23.150 --> 00:01:25.250
vast volumes of data
and GPU's and all that

00:01:25.250 --> 00:01:27.830
came together, we could
see the scale of it,

00:01:27.830 --> 00:01:29.930
and we could see the utility.

00:01:29.930 --> 00:01:33.290
I spent some time working
on IBM a long time ago--

00:01:33.290 --> 00:01:34.040
IBM Research.

00:01:34.040 --> 00:01:36.050
And back in 2004,
we actually saw

00:01:36.050 --> 00:01:38.264
a demo of the voice assistant.

00:01:38.264 --> 00:01:40.430
The idea was somebody would
be driving in their car,

00:01:40.430 --> 00:01:42.830
and they would want
to go to a restaurant,

00:01:42.830 --> 00:01:44.130
and the car would ask them--

00:01:44.130 --> 00:01:47.320
the assistant would ask
about what kind of restaurant

00:01:47.320 --> 00:01:49.940
did you want to go
to, and give them

00:01:49.940 --> 00:01:53.090
real time feedback on traffic,
and direct them to where to go.

00:01:53.090 --> 00:01:56.640
And it was 2003, I think, 2004.

00:01:56.640 --> 00:01:59.910
So when I was there, and I was a
research assistant at the time,

00:01:59.910 --> 00:02:01.610
I said that was imminent.

00:02:01.610 --> 00:02:03.774
This is what they were
going to put in cars.

00:02:03.774 --> 00:02:05.440
And our understanding
was a year or two,

00:02:05.440 --> 00:02:07.310
and it's actually
taken this long

00:02:07.310 --> 00:02:10.150
to get real voice
assistance of real utility.

00:02:10.150 --> 00:02:11.750
And what's happened
there is accuracy.

00:02:11.750 --> 00:02:13.262
It's actually less frustrating.

00:02:13.262 --> 00:02:14.720
So if you tried it
a few years ago,

00:02:14.720 --> 00:02:15.950
it was extremely frustrating.

00:02:15.950 --> 00:02:17.850
It got it wrong too often.

00:02:17.850 --> 00:02:18.350
That's all.

00:02:18.350 --> 00:02:19.730
It wasn't that it was getting
it wrong all the time,

00:02:19.730 --> 00:02:20.870
but just too often.

00:02:20.870 --> 00:02:22.580
That was a frustrating
experience.

00:02:22.580 --> 00:02:25.530
And that's what's
changed in recent years.

00:02:25.530 --> 00:02:29.340
But it's not just the
voice assistance, right.

00:02:29.340 --> 00:02:31.640
There's any number
of these companies

00:02:31.640 --> 00:02:35.370
that are seriously doing speech
recognition technologies.

00:02:35.370 --> 00:02:38.600
So I think Tech
Crunch late 2016 said

00:02:38.600 --> 00:02:40.549
there was like 29
companies in the US

00:02:40.549 --> 00:02:41.840
alone doing speech recognition.

00:02:41.840 --> 00:02:43.590
So that's not counting
Asia; it's not

00:02:43.590 --> 00:02:45.710
counting European companies,
and it's not counting

00:02:45.710 --> 00:02:47.240
what's happened in 2018, right.

00:02:47.240 --> 00:02:49.132
That's a year and a half ago.

00:02:49.132 --> 00:02:51.340
But all these companies are
doing spectacular things,

00:02:51.340 --> 00:02:54.054
so you're seeing
voice assistance.

00:02:54.054 --> 00:02:55.970
You know, when we had
them first, it was Siri,

00:02:55.970 --> 00:02:59.030
and it OK, Google, and it
was on your personal device.

00:02:59.030 --> 00:03:01.520
But they've taken a leap
from the personal device

00:03:01.520 --> 00:03:05.030
into the home, and that's really
interesting from my perspective

00:03:05.030 --> 00:03:06.320
what's happened there.

00:03:06.320 --> 00:03:09.330
You know it's something we all
have to pay close attention to,

00:03:09.330 --> 00:03:11.795
because it's just the
tip of the iceberg.

00:03:11.795 --> 00:03:14.170
I mean, people think wow, look
at this amazing technology

00:03:14.170 --> 00:03:17.120
and what it's going do
for them, but to my mind,

00:03:17.120 --> 00:03:18.620
this is just the start.

00:03:18.620 --> 00:03:21.530
It will be, even from
our own experiences

00:03:21.530 --> 00:03:22.830
of the last couple of years--

00:03:22.830 --> 00:03:26.616
it will be on your
fridge, your TV, your car.

00:03:26.616 --> 00:03:27.990
It could be in a
vending machine.

00:03:27.990 --> 00:03:30.500
It's not just that
it's a voice assistant.

00:03:30.500 --> 00:03:34.310
It's actually going to be the
stage that speech technology--

00:03:34.310 --> 00:03:37.580
voice technology is going
to replace keyboards, touch,

00:03:37.580 --> 00:03:40.430
swipe, gesture, all these
things, because it's

00:03:40.430 --> 00:03:41.630
the natural interface.

00:03:41.630 --> 00:03:42.860
It's how humans communicate.

00:03:42.860 --> 00:03:45.065
So it only makes sense that
if technology can do it

00:03:45.065 --> 00:03:47.940
to that stage, why are we all
still typing, and clicking,

00:03:47.940 --> 00:03:50.600
and you know, we have to do that
because the technology wasn't

00:03:50.600 --> 00:03:52.946
there to begin with.

00:03:52.946 --> 00:03:55.420
But what happens with
that is when we actually

00:03:55.420 --> 00:03:59.210
start replacing interface,
and voice becomes the norm,

00:03:59.210 --> 00:04:03.170
you have to recognize the fact
that you've put it in the home,

00:04:03.170 --> 00:04:04.670
and children will use it.

00:04:04.670 --> 00:04:05.940
I mean, that's just a given.

00:04:05.940 --> 00:04:07.660
It's not about what
you want or whatever.

00:04:07.660 --> 00:04:09.200
If you volunteer
to take something

00:04:09.200 --> 00:04:14.630
and put it into the home,
it will engage children,

00:04:14.630 --> 00:04:16.350
because, number one, it's fun.

00:04:16.350 --> 00:04:18.600
What child isn't going to
try it the moment you do it.

00:04:18.600 --> 00:04:21.019
They're going to do it
immediately after you.

00:04:21.019 --> 00:04:23.510
But it's also easier for them
than clicking and typing,

00:04:23.510 --> 00:04:25.510
because a lot of times
they're even pre-literate

00:04:25.510 --> 00:04:27.530
or they struggle with dexterity.

00:04:27.530 --> 00:04:29.820
It's actually a great
interface for children as well,

00:04:29.820 --> 00:04:30.780
and it's already there.

00:04:30.780 --> 00:04:32.380
So the question is,
how do we handle it?

00:04:32.380 --> 00:04:33.230
What's the utility?

00:04:33.230 --> 00:04:36.110
So in every place that you
could see an adult using

00:04:36.110 --> 00:04:39.020
speech technology other
than dictating your business

00:04:39.020 --> 00:04:42.172
documents, you're going to see
that children will use it, too,

00:04:42.172 --> 00:04:44.630
especially when you take it
outside the office environment,

00:04:44.630 --> 00:04:47.390
and you're going to see
that they're using it.

00:04:47.390 --> 00:04:52.060
Other application areas we
see for it in particular is--

00:04:52.060 --> 00:04:54.070
and what we started
with, actually,

00:04:54.070 --> 00:04:57.170
SoapBox Labs originally, our
mission statement back in 2013

00:04:57.170 --> 00:04:58.820
was more around education.

00:04:58.820 --> 00:05:01.956
So if you think about how
a child learns to read,

00:05:01.956 --> 00:05:03.830
the most effective way
a child learns to read

00:05:03.830 --> 00:05:06.450
is one-to-one,
oral-guided reading.

00:05:06.450 --> 00:05:11.210
So that means a helpful adult
working alongside a child.

00:05:11.210 --> 00:05:13.970
And if you think, do you ever
watch a parent or a teacher

00:05:13.970 --> 00:05:17.720
teaching a child to read,
they listen, they correct,

00:05:17.720 --> 00:05:19.910
they prompt, they
encourage, and they assess.

00:05:19.910 --> 00:05:22.280
And it's that
one-to-one, actually--

00:05:22.280 --> 00:05:24.940
it's more than 10 minutes a day,
but between 10 and 20 minutes

00:05:24.940 --> 00:05:27.340
a day is recommended
for a child to get to--

00:05:27.340 --> 00:05:30.210
to accelerate the reading
to a decent level.

00:05:30.210 --> 00:05:32.900
But in the world
today, literacy levels

00:05:32.900 --> 00:05:34.730
have stagnated over
the last 10 years.

00:05:34.730 --> 00:05:36.460
In the US, 60% of
kids at age eight

00:05:36.460 --> 00:05:38.870
are not reading at
a proficient level.

00:05:38.870 --> 00:05:42.080
And a child that doesn't read
at a proficient level of age

00:05:42.080 --> 00:05:44.810
eight, it's a key indicator
of their future success;

00:05:44.810 --> 00:05:46.490
it's quite a key
moment, because it's

00:05:46.490 --> 00:05:48.680
when most kids stop
learning to read,

00:05:48.680 --> 00:05:50.610
and they start reading to learn.

00:05:50.610 --> 00:05:53.822
So if you are
struggling before that,

00:05:53.822 --> 00:05:55.280
it's going to get
harder and harder

00:05:55.280 --> 00:05:57.330
to catch up with your peers.

00:05:57.330 --> 00:06:00.140
So one of the ways we've been
looking at this over the years

00:06:00.140 --> 00:06:04.950
is that if you know the one
way to increase the reading is

00:06:04.950 --> 00:06:07.920
one-to-one engagement,
you're not suddenly

00:06:07.920 --> 00:06:10.740
going to find funding to stick
more teachers into homes,

00:06:10.740 --> 00:06:13.470
or suddenly free up parents'
time, or get private tutors.

00:06:13.470 --> 00:06:16.972
But what you can do is provide
a scalable, cost-effective

00:06:16.972 --> 00:06:18.930
solution in speech
technology that can actually

00:06:18.930 --> 00:06:21.750
act as a helpful adult,
listening as the child reads,

00:06:21.750 --> 00:06:24.810
the cat sat on the mat,
and correcting, prompting,

00:06:24.810 --> 00:06:27.210
and assessing, and do
that personalized learning

00:06:27.210 --> 00:06:28.380
journey for them.

00:06:28.380 --> 00:06:30.570
And the same goes for
English language learning,

00:06:30.570 --> 00:06:34.560
or other language learning,
depending on where your from.

00:06:34.560 --> 00:06:36.405
The same thing-- it's
that guided or really

00:06:36.405 --> 00:06:38.280
personalized learning,
personalized education

00:06:38.280 --> 00:06:39.901
is a huge area in
the world today.

00:06:39.901 --> 00:06:42.150
But actually nobody has a
solution really for reading.

00:06:42.150 --> 00:06:44.360
And they can do it for maths,
and science, and geography,

00:06:44.360 --> 00:06:45.720
but they can't do
it for reading.

00:06:45.720 --> 00:06:47.400
They can't do it from
language learning.

00:06:47.400 --> 00:06:50.400
And the statistics
about poor reading

00:06:50.400 --> 00:06:53.130
is actually masking a
big, much worse problem

00:06:53.130 --> 00:06:56.010
for disadvantaged children
and immigrant children,

00:06:56.010 --> 00:06:59.550
because those kids are actually
two years behind their peers

00:06:59.550 --> 00:07:02.107
in PISA studies.

00:07:02.107 --> 00:07:04.440
So they're the kids that
probably would benefit the most

00:07:04.440 --> 00:07:06.773
from these type of technologies
that are cost-effective,

00:07:06.773 --> 00:07:07.860
that are scalable.

00:07:07.860 --> 00:07:10.220
And all they required is
a cheap Android device,

00:07:10.220 --> 00:07:14.450
and means to one
of those devices.

00:07:14.450 --> 00:07:16.409
So that's one of the
areas we're focused on.

00:07:16.409 --> 00:07:18.950
Another area that we've had a
huge amount of inbound interest

00:07:18.950 --> 00:07:20.835
in social robots, it's
called, or robotics

00:07:20.835 --> 00:07:23.210
for fun, entertainment, get
them to move around, but also

00:07:23.210 --> 00:07:25.310
social robots to
engage to learn--

00:07:25.310 --> 00:07:28.230
engage them in an educational
way, or a lot of times,

00:07:28.230 --> 00:07:31.270
kids with learning
difficulties as well.

00:07:31.270 --> 00:07:33.200
But again, voice
technology to have

00:07:33.200 --> 00:07:36.130
that meaningful interaction
is really important.

00:07:36.130 --> 00:07:39.000
The more fun stuff like in VR,
which also can be educational,

00:07:39.000 --> 00:07:41.170
but it also can be just
pure entertainment,

00:07:41.170 --> 00:07:43.560
and then just pure
gaming as well.

00:07:43.560 --> 00:07:46.330
Anywhere you see voice
technology for adults

00:07:46.330 --> 00:07:47.130
could then--

00:07:47.130 --> 00:07:50.640
the solutions for children
as well make sense.

00:07:50.640 --> 00:07:53.000
So I'm just going to show
you a quick video here,

00:07:53.000 --> 00:07:56.040
and this is one
of the reasons why

00:07:56.040 --> 00:08:00.560
our focus in the last five years
have been somewhat different.

00:08:00.560 --> 00:08:03.400
I'll just play this for you, and
you'll understand what I mean.

00:08:03.400 --> 00:08:06.840
So this is when you stick a
voice assistant into the home,

00:08:06.840 --> 00:08:08.290
and what can go wrong.

00:08:08.290 --> 00:08:09.230
[VIDEO PLAYBACK]

00:08:09.230 --> 00:08:12.050
- Alexa, play "Digger, Digger."

00:08:14.870 --> 00:08:18.131
- I can't find the
song, "T Good Ticker."

00:08:18.131 --> 00:08:19.125
- Alexa--

00:08:19.125 --> 00:08:20.447
- Alexa, play [INAUDIBLE]

00:08:20.447 --> 00:08:21.113
- Let him do it.

00:08:21.113 --> 00:08:26.580
- Alexa, play "Digger, Digger."

00:08:26.580 --> 00:08:31.534
Alexa, play "Digger, Digger."

00:08:31.534 --> 00:08:33.659
Bobby, can you tell it to
play "Wheels on the Bus"?

00:08:33.659 --> 00:08:35.200
- You want to hear
a station for porn

00:08:35.200 --> 00:08:38.527
detective, porno ringtone,
hot chick amateur girl quality

00:08:38.527 --> 00:08:39.026
sex--

00:08:39.026 --> 00:08:39.525
- No no no.

00:08:39.525 --> 00:08:40.370
- No.

00:08:40.370 --> 00:08:41.679
- Pussy anal dildo ringtone.

00:08:41.679 --> 00:08:42.419
- Alexa, stop.

00:08:42.419 --> 00:08:43.119
[END PLAYBACK]

00:08:43.119 --> 00:08:45.327
PATRICIA SCANLAN: So it's
a funny, cute video, right,

00:08:45.327 --> 00:08:48.810
but it actually indicates
kind of more serious problems

00:08:48.810 --> 00:08:50.750
they have when you put
a device into the home.

00:08:50.750 --> 00:08:52.160
Where is the filter?

00:08:52.160 --> 00:08:54.994
You know, you can say it's
not designed for kids;

00:08:54.994 --> 00:08:57.410
it's not marketed to kids; I
didn't put it there for kids.

00:08:57.410 --> 00:08:59.210
But kids are going to use it,
and we have to face up to that,

00:08:59.210 --> 00:09:00.350
right.

00:09:00.350 --> 00:09:02.600
So some of the focus of our
company over the last five

00:09:02.600 --> 00:09:07.340
years has been accuracy
for children's voices,

00:09:07.340 --> 00:09:11.690
systems environments that are
fit for kids, and data privacy.

00:09:11.690 --> 00:09:13.852
So accuracy, why is
speech technology

00:09:13.852 --> 00:09:14.810
difficult for children?

00:09:17.360 --> 00:09:20.750
Most systems have been built
with adult data, modeling adult

00:09:20.750 --> 00:09:24.020
behaviors, physical
and otherwise.

00:09:24.020 --> 00:09:27.037
But children are physically
different from adults,

00:09:27.037 --> 00:09:28.370
particularly in the vocal tract.

00:09:28.370 --> 00:09:30.090
They're thinner and shorter.

00:09:30.090 --> 00:09:31.820
So where men's voices
might be lower,

00:09:31.820 --> 00:09:33.320
women's are
overlapping but higher,

00:09:33.320 --> 00:09:35.360
and then let's says
a tween, teenager,

00:09:35.360 --> 00:09:36.620
is kind of overlapping women.

00:09:36.620 --> 00:09:40.550
And as they get younger,
the physical differences

00:09:40.550 --> 00:09:44.030
get further and further
away from an adult,

00:09:44.030 --> 00:09:46.117
and that happens around age 12.

00:09:46.117 --> 00:09:48.200
And the younger you get,
the more different it is.

00:09:48.200 --> 00:09:49.575
And that actually
just physically

00:09:49.575 --> 00:09:52.225
causes confusion about what
actually has been said.

00:09:52.225 --> 00:09:53.600
The behaviors, on
the other hand,

00:09:53.600 --> 00:09:55.520
are just wildly different.

00:09:55.520 --> 00:09:57.780
Kids are wildly unpredictable.

00:09:57.780 --> 00:10:01.730
They stutter, they repeat, they
shout, they whisper, they sing.

00:10:01.730 --> 00:10:07.450
Like, you know, they punctuate
their words an awful lot more

00:10:07.450 --> 00:10:12.590
than their more fluent older
siblings, and other children,

00:10:12.590 --> 00:10:13.090
and adults.

00:10:13.090 --> 00:10:15.548
And that actually is a real
problem for endpoint detection,

00:10:15.548 --> 00:10:17.210
if anybody's ever
worked on that,

00:10:17.210 --> 00:10:19.650
because they don't just
behave the same way.

00:10:19.650 --> 00:10:21.870
And what you end up
doing is seeing that

00:10:21.870 --> 00:10:24.640
a system that has been
designed for adults,

00:10:24.640 --> 00:10:26.950
or using adult data, or
modeling adult behavior,

00:10:26.950 --> 00:10:28.580
it's extremely
frustrating for a child,

00:10:28.580 --> 00:10:30.830
and the younger the child,
the more frustrating it is.

00:10:30.830 --> 00:10:33.060
It has a negative effect
on brand in some ways,

00:10:33.060 --> 00:10:35.707
because people associate
that technology.

00:10:35.707 --> 00:10:37.290
A lot of people don't
process the fact

00:10:37.290 --> 00:10:38.760
that it's just different voices.

00:10:38.760 --> 00:10:40.926
They just think the product
isn't working very well.

00:10:40.926 --> 00:10:42.740
And you know, I had
a pain in my head

00:10:42.740 --> 00:10:45.680
from my younger son
asking me, can you

00:10:45.680 --> 00:10:49.560
ask Alexa, when
we got her first.

00:10:49.560 --> 00:10:54.930
So what we've done is spend the
last five years concentrating

00:10:54.930 --> 00:10:59.980
on child-specific models.

00:10:59.980 --> 00:11:03.260
So what we did was look at
data from children as young

00:11:03.260 --> 00:11:04.330
as four--

00:11:04.330 --> 00:11:09.910
but the data was conversational,
prompted, read, spontaneous--

00:11:09.910 --> 00:11:13.510
and built models that were very
specific to young children.

00:11:13.510 --> 00:11:15.640
We spent time studying
how children converse,

00:11:15.640 --> 00:11:17.974
how children speak
to technology,

00:11:17.974 --> 00:11:20.140
the variance in that, and
how do you cope with that,

00:11:20.140 --> 00:11:22.265
and how do you build a
system specifically designed

00:11:22.265 --> 00:11:23.350
for children.

00:11:23.350 --> 00:11:25.300
We collected data in
real world environments.

00:11:25.300 --> 00:11:28.270
So that mean, you
know, where children

00:11:28.270 --> 00:11:30.410
are in their homes
and their schools.

00:11:30.410 --> 00:11:33.100
And so you can
actually understand

00:11:33.100 --> 00:11:37.990
that children don't
use technology

00:11:37.990 --> 00:11:40.810
in a quiet lab-like environment.

00:11:40.810 --> 00:11:43.360
And if you build your
speech technology

00:11:43.360 --> 00:11:46.360
on data that's been collected in
a lab-like, quiet environment,

00:11:46.360 --> 00:11:48.616
it will only ever work
in those environments.

00:11:48.616 --> 00:11:50.740
So to move away from that,
you have to be able to--

00:11:50.740 --> 00:11:53.198
and get away from headset mics,
and get away from all that,

00:11:53.198 --> 00:11:55.630
and then let children just
be natural with how they want

00:11:55.630 --> 00:11:57.370
to interact with technology.

00:11:57.370 --> 00:12:00.295
And then it's more up to
us to change our technology

00:12:00.295 --> 00:12:02.140
than the child to
change their behaviors,

00:12:02.140 --> 00:12:03.880
because you won't
find a five year old

00:12:03.880 --> 00:12:05.546
that's going to modify
their behavior as

00:12:05.546 --> 00:12:06.550
much as an adult will.

00:12:06.550 --> 00:12:08.133
And that's how we've
been getting away

00:12:08.133 --> 00:12:10.500
with a lot with voice
technology and assistance,

00:12:10.500 --> 00:12:11.950
that we know that
adults sometimes

00:12:11.950 --> 00:12:13.870
modify their behaviors
to get a response.

00:12:13.870 --> 00:12:18.750
Children are less
likely to do so.

00:12:18.750 --> 00:12:22.669
So another issue is, is the
system fit for children,

00:12:22.669 --> 00:12:23.710
and are they appropriate?

00:12:23.710 --> 00:12:26.280
So two examples I
can give you of this

00:12:26.280 --> 00:12:30.930
is that Sarah Huckabee Sanders,
the press secretary for Donald

00:12:30.930 --> 00:12:35.600
Trump, recently tweeted that
her three year old ordered

00:12:35.600 --> 00:12:40.699
a Batman on Amazon Alexa,
because she shouted Batman

00:12:40.699 --> 00:12:42.990
at the device three times,
and suddenly it got ordered.

00:12:42.990 --> 00:12:45.210
So I call that
somewhat into question

00:12:45.210 --> 00:12:47.880
that the UI works like
that, but it kind of

00:12:47.880 --> 00:12:49.620
did flag up an issue.

00:12:49.620 --> 00:12:53.670
If a child uses a device that
has access to purchasing power,

00:12:53.670 --> 00:12:55.529
why is that child able to do it?

00:12:55.529 --> 00:12:57.820
That's not appropriate behavior
for a child interacting

00:12:57.820 --> 00:13:00.180
with a device in the home.

00:13:00.180 --> 00:13:04.350
Similarly, my daughter
was-- she's eight now--

00:13:04.350 --> 00:13:08.220
she was using my phone, and
you know, I had it locked,

00:13:08.220 --> 00:13:10.470
but she got onto the Siri
thing, and she was just

00:13:10.470 --> 00:13:13.800
sitting with me and using
Siri to ask questions.

00:13:13.800 --> 00:13:15.900
Siri misunderstood, and
thought she said, bitch.

00:13:15.900 --> 00:13:18.660
She didn't, but my
daughter was shocked,

00:13:18.660 --> 00:13:21.660
and showed me the phone with
the word printed to the screen.

00:13:21.660 --> 00:13:23.490
And Siri replied
with an, oh, there's

00:13:23.490 --> 00:13:26.110
no need for that, which
is very amusing and nice,

00:13:26.110 --> 00:13:28.750
but why didn't it recognize
that was a child voice,

00:13:28.750 --> 00:13:31.230
and not print that to screen?

00:13:31.230 --> 00:13:36.450
So I think when you consider
the fact of the first video

00:13:36.450 --> 00:13:38.160
with the child
potentially accessing

00:13:38.160 --> 00:13:41.910
inappropriate material,
inappropriate lyrics, songs,

00:13:41.910 --> 00:13:46.080
purchasing power,
inappropriate words,

00:13:46.080 --> 00:13:48.210
potentially accessing
your contact list

00:13:48.210 --> 00:13:49.914
and doing video
calling or whatever--

00:13:49.914 --> 00:13:52.080
what needs to happen is,
and what we've been working

00:13:52.080 --> 00:13:53.550
with clients to
do, is to recognize

00:13:53.550 --> 00:13:57.082
at the point of the
voice interaction--

00:13:57.082 --> 00:13:59.040
whether it's a child or
whether it's an adult--

00:13:59.040 --> 00:14:00.360
and act appropriately.

00:14:00.360 --> 00:14:03.870
Route the child to a different,
child-safe environment,

00:14:03.870 --> 00:14:06.150
and not to the wide
web where they can do

00:14:06.150 --> 00:14:08.320
an open search and such things.

00:14:08.320 --> 00:14:11.250
And that's important when we
put these devices in the homes,

00:14:11.250 --> 00:14:13.050
and in the cars, and
in all the places

00:14:13.050 --> 00:14:15.470
that children will access them.

00:14:15.470 --> 00:14:18.450
So data privacy-- the really
thorny issue of data privacy.

00:14:18.450 --> 00:14:22.580
This is obviously such a hot
topic in the last few weeks.

00:14:22.580 --> 00:14:27.140
But interestingly, the US are
way ahead of Europe on this.

00:14:27.140 --> 00:14:30.800
Going back to 2012,
the US COPPA laws

00:14:30.800 --> 00:14:34.640
explicitly stated that voice
was personally identifiable

00:14:34.640 --> 00:14:37.350
information, much like
video and images were,

00:14:37.350 --> 00:14:40.400
and therefore you needed
to have explicit permission

00:14:40.400 --> 00:14:42.960
from the parents
to collect data.

00:14:42.960 --> 00:14:44.750
And explicit is
very explicit; it's

00:14:44.750 --> 00:14:47.090
like using their credit
card to make a purchase,

00:14:47.090 --> 00:14:50.212
or having the parent put
in their email address,

00:14:50.212 --> 00:14:52.670
email sent to the parent, the
parents had to click consent,

00:14:52.670 --> 00:14:53.780
and then you have to
remind them that they

00:14:53.780 --> 00:14:55.730
consented, and written
in language that they

00:14:55.730 --> 00:14:57.540
can understand.

00:14:57.540 --> 00:15:01.490
It was very explicit--
and warranted, right?

00:15:01.490 --> 00:15:09.770
But with the advent of these
voice assistants in the home,

00:15:09.770 --> 00:15:13.370
the FTC relaxed the
rules only very recently,

00:15:13.370 --> 00:15:17.750
and said, OK, we understand that
these devices are in the home,

00:15:17.750 --> 00:15:20.600
so therefore if it
replaces the voice,

00:15:20.600 --> 00:15:22.940
replaces what would
have been typed,

00:15:22.940 --> 00:15:25.820
it's OK to use it for
only that purpose,

00:15:25.820 --> 00:15:27.450
and as long as it
deleted immediately.

00:15:27.450 --> 00:15:28.160
So it's great.

00:15:28.160 --> 00:15:30.440
So that meant, in most
people's minds, OK,

00:15:30.440 --> 00:15:32.630
we're good to use
it in the home.

00:15:32.630 --> 00:15:34.790
But what it was not
considering was--

00:15:34.790 --> 00:15:41.650
a couple of issues is what
happens on the back end.

00:15:41.650 --> 00:15:45.280
You collect data from
a child; is the data

00:15:45.280 --> 00:15:48.070
deleted immediately, which
meant you need a gate for child

00:15:48.070 --> 00:15:49.660
or not-child data.

00:15:49.660 --> 00:15:51.160
Is the data deleted immediately?

00:15:51.160 --> 00:15:52.555
Is there data
extracted for that?

00:15:52.555 --> 00:15:54.910
Is the data extracted
used for other purposes?

00:15:54.910 --> 00:15:56.530
What's that data used for?

00:15:56.530 --> 00:16:00.610
So while we can
somewhat say that we're

00:16:00.610 --> 00:16:02.740
addressing some of
these issues, it

00:16:02.740 --> 00:16:05.515
has been very unclear to
date exactly what data

00:16:05.515 --> 00:16:08.200
has been collected, exactly
when the data is being deleted,

00:16:08.200 --> 00:16:09.950
and what's the data used for.

00:16:09.950 --> 00:16:12.460
And that is, because
it's an exploding area,

00:16:12.460 --> 00:16:14.440
and the area is
growing so quickly,

00:16:14.440 --> 00:16:17.100
it's often hard for
the laws and the FTC

00:16:17.100 --> 00:16:19.600
to really struggle with this,
and kind of came up very short

00:16:19.600 --> 00:16:22.150
in it about what to do.

00:16:22.150 --> 00:16:24.790
What happens if you've given
permission to your child

00:16:24.790 --> 00:16:26.950
to use the device, and
the data they collected,

00:16:26.950 --> 00:16:29.050
but the child's friend
visits the house.

00:16:29.050 --> 00:16:30.220
What happens to that data?

00:16:30.220 --> 00:16:31.780
Is that being addressed?

00:16:31.780 --> 00:16:34.780
What if you just take the device
out of the box and put it here?

00:16:34.780 --> 00:16:37.300
You know, is everybody
being sure that the data is

00:16:37.300 --> 00:16:39.580
being deleted immediately?

00:16:39.580 --> 00:16:40.970
And that's really
a thorny issue.

00:16:40.970 --> 00:16:42.590
So the FTC relaxed the rule.

00:16:42.590 --> 00:16:44.590
So a lot of people are
now in gray water, going,

00:16:44.590 --> 00:16:46.270
they think we're OK--

00:16:46.270 --> 00:16:50.170
we, the public who have
put that device in the home

00:16:50.170 --> 00:16:52.860
are unsure when the data
is being deleted exactly.

00:16:52.860 --> 00:16:56.230
The EU and the GDPR--

00:16:56.230 --> 00:16:59.140
the much-feared
GDPR, in May 2018,

00:16:59.140 --> 00:17:01.270
have not relaxed the rule.

00:17:01.270 --> 00:17:03.913
That means that data is
not allowed to be collected

00:17:03.913 --> 00:17:05.079
without explicit permission.

00:17:05.079 --> 00:17:06.476
So you take a device,
you pull it out,

00:17:06.476 --> 00:17:08.309
you put it in your home,
and you plug it in.

00:17:08.309 --> 00:17:09.650
A child uses it.

00:17:09.650 --> 00:17:11.790
Where is the responsibility?

00:17:11.790 --> 00:17:14.530
Is everybody
immediately reacting,

00:17:14.530 --> 00:17:16.920
recognizing that a child
has spoken versus an adult,

00:17:16.920 --> 00:17:18.800
and reacting appropriately?

00:17:18.800 --> 00:17:23.319
So the problem here is that
because the FTC kind of took

00:17:23.319 --> 00:17:26.650
a bit of a backstep and a blind
eye for for a couple of years,

00:17:26.650 --> 00:17:31.510
and then it got
sorted out, the idea

00:17:31.510 --> 00:17:35.730
that the EU would do the same
is a little bit less clear.

00:17:35.730 --> 00:17:38.490
One reason I would say
that is because last year,

00:17:38.490 --> 00:17:42.730
the Cayla doll was recalled
from the market in Germany.

00:17:42.730 --> 00:17:45.900
And not just was it
recalled, what came out

00:17:45.900 --> 00:17:49.680
was that parents should destroy
this doll because the doll is

00:17:49.680 --> 00:17:51.460
listening to your
children at all times,

00:17:51.460 --> 00:17:54.690
and sending the voice
data to a company that

00:17:54.690 --> 00:17:56.960
has links to the US military.

00:17:56.960 --> 00:17:59.497
And that company was
Nuance, which you know,

00:17:59.497 --> 00:18:01.080
it's a very reputable
voice technology

00:18:01.080 --> 00:18:02.070
company, around for
a long time, and they

00:18:02.070 --> 00:18:03.160
have done DARPA projects.

00:18:03.160 --> 00:18:07.410
So technically it was correct,
but the reaction from Germany

00:18:07.410 --> 00:18:10.500
was so polar opposite to
what we've seen already

00:18:10.500 --> 00:18:12.280
in the FTC and the
US that I think

00:18:12.280 --> 00:18:15.180
it should give us all pause
to say, how are we doing this?

00:18:15.180 --> 00:18:16.560
Are we doing it appropriately?

00:18:16.560 --> 00:18:19.890
And I don't think that they're
going to see a blind eye.

00:18:19.890 --> 00:18:22.200
So in that case,
somewhat we have

00:18:22.200 --> 00:18:25.097
to re-envision how people
are using these technologies.

00:18:25.097 --> 00:18:27.180
A part of what we do is
we have advised companies,

00:18:27.180 --> 00:18:30.790
and we have solutions to bid
to help companies better comply

00:18:30.790 --> 00:18:33.499
with global data
privacy regulations.

00:18:33.499 --> 00:18:35.040
So this is just some
of the company--

00:18:35.040 --> 00:18:37.070
I mean, we can chat more
about it in a little while,

00:18:37.070 --> 00:18:39.278
but this is just on what's
happened with the company.

00:18:39.278 --> 00:18:40.840
We started back in 2013.

00:18:40.840 --> 00:18:44.700
In 2018 we've raised a
couple rounds of funding

00:18:44.700 --> 00:18:47.082
privately and from
the EU as well.

00:18:47.082 --> 00:18:49.290
And we've got some great
coverage from "Tech Crunch,"

00:18:49.290 --> 00:18:53.500
and "Wired," and "The Next Web,"
and in recent months as well.

00:18:53.500 --> 00:18:55.380
So we were 10 at
the end of the year;

00:18:55.380 --> 00:18:57.675
we're 13 as of from
this month, and then

00:18:57.675 --> 00:19:00.360
we're scaling quite
rapidly this year.

00:19:00.360 --> 00:19:04.258
So I can leave it there,
and thank you for listening.

00:19:04.258 --> 00:19:06.728
[APPLAUSE]

00:19:10.850 --> 00:19:12.850
SPEAKER 1: So thank you,
Patricia, and thank you

00:19:12.850 --> 00:19:13.750
for that overview.

00:19:13.750 --> 00:19:15.805
You talked a lot
about your company,

00:19:15.805 --> 00:19:17.430
so I want to take a
few minutes to talk

00:19:17.430 --> 00:19:19.940
about you and your
journey, and sort of share

00:19:19.940 --> 00:19:22.410
how you've gotten to where
you've gotten to here.

00:19:22.410 --> 00:19:23.660
Phenomenal to hear the story--

00:19:23.660 --> 00:19:29.340
2013, pure tech, built in
Ireland, scaling company.

00:19:29.340 --> 00:19:30.590
So well done on that.

00:19:30.590 --> 00:19:33.350
But maybe give us a little
bit of your background,

00:19:33.350 --> 00:19:35.970
I mean, the journey
to date, right up

00:19:35.970 --> 00:19:37.610
to the start of SoapBox Labs.

00:19:37.610 --> 00:19:39.050
PATRICIA SCANLAN: Yeah, sure.

00:19:39.050 --> 00:19:43.654
So I qualified as a software
engineer back in '97.

00:19:43.654 --> 00:19:44.570
It's been a while ago.

00:19:44.570 --> 00:19:47.111
And I spent a couple of years
working as a software engineer,

00:19:47.111 --> 00:19:49.240
and worked a bit on
signal processing.

00:19:49.240 --> 00:19:51.680
And then about 2000,
I went back to college

00:19:51.680 --> 00:19:54.360
to do a PhD in speech
recognition technology, which

00:19:54.360 --> 00:19:55.430
was--

00:19:55.430 --> 00:19:56.820
it wasn't that it was new.

00:19:56.820 --> 00:20:00.310
We've been doing speech tech
since the '70s properly.

00:20:00.310 --> 00:20:02.900
But it was so different
to how we do it now,

00:20:02.900 --> 00:20:05.150
and the volumes we do it
with, and the approaches were

00:20:05.150 --> 00:20:07.965
so different, and the
ambition was different.

00:20:09.920 --> 00:20:11.450
I started in UCD,
but I spent time

00:20:11.450 --> 00:20:14.130
in New York in
Columbia University,

00:20:14.130 --> 00:20:18.260
but then also in IBM Research
in the Yorktown Heights research

00:20:18.260 --> 00:20:19.240
facility.

00:20:19.240 --> 00:20:20.750
And then when I
finished my PhD, I

00:20:20.750 --> 00:20:24.730
started in Bell Labs, which
is now Nokia Bell Labs,

00:20:24.730 --> 00:20:28.169
and I spent seven years there
working on research, but then

00:20:28.169 --> 00:20:30.710
more and more, as time went on,
in just the commercialization

00:20:30.710 --> 00:20:34.010
of research innovations,
and trying to--

00:20:34.010 --> 00:20:37.160
I was always kind of pushing
for new technologies,

00:20:37.160 --> 00:20:39.410
or new research we should
do, and new products

00:20:39.410 --> 00:20:41.410
we could bring to market--

00:20:41.410 --> 00:20:44.870
as I was saying,
in some ways kind

00:20:44.870 --> 00:20:48.160
of pitching ideas and
raising value propositions,

00:20:48.160 --> 00:20:52.100
and trying to get resources
and funding to fund projects

00:20:52.100 --> 00:20:54.090
within the organization.

00:20:54.090 --> 00:20:58.156
But by 2013 I'd identified the
fairly significant gap which

00:20:58.156 --> 00:20:59.530
was children's
speech recognition

00:20:59.530 --> 00:21:05.250
that I felt like I needed
to invest time in, and try

00:21:05.250 --> 00:21:06.750
and figure out what
the problem was,

00:21:06.750 --> 00:21:11.991
and it was something I needed to
do myself, so I quit Bell Labs

00:21:11.991 --> 00:21:14.740
and founded SoapBox
Labs in 2013.

00:21:14.740 --> 00:21:16.660
SPEAKER 1: And was that
an aha moment, or was

00:21:16.660 --> 00:21:19.650
it one of these kind of you
build up to see the problem,

00:21:19.650 --> 00:21:20.640
and identified the gap?

00:21:20.640 --> 00:21:24.010
How exactly did you come
across this specific problem?

00:21:24.010 --> 00:21:27.360
PATRICIA SCANLAN: It was all
my experience up to that point

00:21:27.360 --> 00:21:29.820
led me to the aha
moment, if you want.

00:21:29.820 --> 00:21:32.790
I was working with my daughter
who was three at the time--

00:21:32.790 --> 00:21:34.860
she's now eight--

00:21:34.860 --> 00:21:37.290
downloading apps
and web services,

00:21:37.290 --> 00:21:38.294
and kind of looking at--

00:21:38.294 --> 00:21:41.220
I think I was trying phonics,
and reading apps and stuff

00:21:41.220 --> 00:21:43.900
like that, because you get
cute little maths apps.

00:21:43.900 --> 00:21:46.483
And then I kind of looked at the
phonics stuff and the reading

00:21:46.483 --> 00:21:48.700
stuff, and it was just
always multi-choice.

00:21:48.700 --> 00:21:50.760
Anything to do with reading and
language learning was always

00:21:50.760 --> 00:21:52.500
multi-choice, because
I kind of figure out--

00:21:52.500 --> 00:21:54.210
I went they have no way
of assessing whether she

00:21:54.210 --> 00:21:55.450
could get this right or not.

00:21:55.450 --> 00:21:58.530
So she was playing
these beautiful games.

00:21:58.530 --> 00:22:00.656
They're all done-- the
pedagogy was great,

00:22:00.656 --> 00:22:03.030
in the [INAUDIBLE] app, but
they had no way of assessing.

00:22:03.030 --> 00:22:04.530
And I remember asking her--

00:22:04.530 --> 00:22:08.421
she'd completed a level
or whatever it was,

00:22:08.421 --> 00:22:10.680
and I was asking, you
just finished that?

00:22:10.680 --> 00:22:12.930
And then, you know, I'd
ask her what the sound was,

00:22:12.930 --> 00:22:14.260
what the word was, and
she'd go, I don't know.

00:22:14.260 --> 00:22:15.410
And then I started watching
what she was doing.

00:22:15.410 --> 00:22:17.034
She was just gaming
them, because she'd

00:22:17.034 --> 00:22:18.130
got around the first time.

00:22:18.130 --> 00:22:19.935
She just knew the next time
how to do the other one.

00:22:19.935 --> 00:22:21.480
And she had no clue
what they were--

00:22:21.480 --> 00:22:22.580
you know, she didn't
know what the sound was;

00:22:22.580 --> 00:22:24.954
she had no ability to recall,
and she wasn't able to read

00:22:24.954 --> 00:22:26.990
the sound or the word.

00:22:26.990 --> 00:22:28.759
And to my mind that
meant there was--

00:22:28.759 --> 00:22:31.050
why has nobody done anything
on this, because you know,

00:22:31.050 --> 00:22:32.220
I'd been working on
speech recognition

00:22:32.220 --> 00:22:34.110
for so long at that
point, and I knew

00:22:34.110 --> 00:22:36.960
where we were going with
adult speech recognition.

00:22:36.960 --> 00:22:38.885
The writing was on
the wall that we'd be

00:22:38.885 --> 00:22:40.901
at this voice assistance stage.

00:22:40.901 --> 00:22:43.150
So it was just baffling to
me that nobody had actually

00:22:43.150 --> 00:22:45.900
put any-- not that they hadn't
put effort into it; they have.

00:22:45.900 --> 00:22:49.722
They just hadn't got
to the same stage.

00:22:49.722 --> 00:22:52.110
And that's why I spent
quite a bit of time trying

00:22:52.110 --> 00:22:53.940
to figure out what
the problem was,

00:22:53.940 --> 00:22:56.820
and why nobody had done that.

00:22:56.820 --> 00:22:58.660
So it was definitely
my experience

00:22:58.660 --> 00:23:01.040
coupled with sitting with
my daughter and going,

00:23:01.040 --> 00:23:02.760
ah, right, there--
and then realizing

00:23:02.760 --> 00:23:05.137
it was actually bigger than
I thought, the problem.

00:23:05.137 --> 00:23:05.720
SPEAKER 1: OK.

00:23:05.720 --> 00:23:07.428
And then the last five
years-- so I mean,

00:23:07.428 --> 00:23:11.310
you spent a lot of time working
with some of the biggest names.

00:23:11.310 --> 00:23:14.170
Certainly IBM, Bell
Labs-- you're now

00:23:14.170 --> 00:23:15.460
in a startup environment.

00:23:15.460 --> 00:23:18.142
What have you taken
from that time

00:23:18.142 --> 00:23:19.350
in the corporate environment?

00:23:19.350 --> 00:23:22.050
So many of us here are
working in big companies.

00:23:22.050 --> 00:23:24.662
We'd like to think we're a
startup in many ways in Google.

00:23:24.662 --> 00:23:26.370
But what have you
taken, and what are you

00:23:26.370 --> 00:23:28.610
applying in your
current role today

00:23:28.610 --> 00:23:31.050
that you've learned in
your corporate time.

00:23:31.050 --> 00:23:32.370
PATRICIA SCANLAN: So we're B2B.

00:23:32.370 --> 00:23:35.220
So we don't bring products
to market ourselves.

00:23:35.220 --> 00:23:36.420
We license our technology.

00:23:36.420 --> 00:23:39.003
So it was one of my learnings,
probably from my Bell Labs days

00:23:39.003 --> 00:23:41.340
that, you know, it's
such a big ecosystem.

00:23:41.340 --> 00:23:43.934
To possibly say I was going
to do everything myself.

00:23:43.934 --> 00:23:45.600
Every bit of funding
I would have raised

00:23:45.600 --> 00:23:47.530
would have gone way too thin.

00:23:47.530 --> 00:23:51.450
And I realized that in order
to develop the technology

00:23:51.450 --> 00:23:53.730
we needed-- and I
actually realized slowly

00:23:53.730 --> 00:23:55.230
over time how big
a problem it was,

00:23:55.230 --> 00:23:58.920
and how difficult a problem it
was, that the minute we started

00:23:58.920 --> 00:24:01.910
going to the end user, and
we started going to B2C,

00:24:01.910 --> 00:24:04.800
we have to invest a huge amount
of technology in that end of it

00:24:04.800 --> 00:24:07.770
as well-- sorry funding,
actually, and resources.

00:24:07.770 --> 00:24:10.391
So when we were in Bell
Labs, one of the thinking

00:24:10.391 --> 00:24:11.890
was, and part of
the corporate thing

00:24:11.890 --> 00:24:13.564
is, you don't have
to do everything.

00:24:13.564 --> 00:24:14.980
You know, you can
partner, and you

00:24:14.980 --> 00:24:18.300
can actually just decide and
laser focus on this problem,

00:24:18.300 --> 00:24:20.920
and then find partners, because
that's what big companies do;

00:24:20.920 --> 00:24:22.490
they partner--

00:24:22.490 --> 00:24:24.630
where it makes sense.

00:24:24.630 --> 00:24:30.060
But what I learned also was
how to talk to corporates,

00:24:30.060 --> 00:24:31.710
and to know what
their problems were,

00:24:31.710 --> 00:24:34.087
and their pain points, and
realize actually sometimes

00:24:34.087 --> 00:24:36.420
the left hand doesn't know
what the right hand is doing.

00:24:36.420 --> 00:24:37.710
So you know, what we've
discovered-- sometimes

00:24:37.710 --> 00:24:40.376
we go to a big organization, get
a contact, and talk to someone.

00:24:40.376 --> 00:24:42.270
They might not think
they have a problem,

00:24:42.270 --> 00:24:47.100
realize they have a problem, or
that person is just too busy.

00:24:47.100 --> 00:24:48.866
Or they haven't put
it as a priority.

00:24:48.866 --> 00:24:50.740
You might actually talk
to a different person

00:24:50.740 --> 00:24:54.210
at the organization, and
this is their pain point,

00:24:54.210 --> 00:24:56.340
and they will talk to you,
and you start engaging.

00:24:56.340 --> 00:24:58.890
So I think sometimes people,
you talk to them in corporate,

00:24:58.890 --> 00:25:01.460
you get one thanks, we're all
right, and you think that's it,

00:25:01.460 --> 00:25:02.550
and you walk away.

00:25:02.550 --> 00:25:05.472
But you know, realizing
that very big corporations,

00:25:05.472 --> 00:25:06.930
it's just not
possible to know what

00:25:06.930 --> 00:25:08.596
every part of the
organization is doing.

00:25:08.596 --> 00:25:09.730
It's served us well.

00:25:09.730 --> 00:25:12.020
And then realizing where
in the organization

00:25:12.020 --> 00:25:15.259
to try and get contacts into.

00:25:15.259 --> 00:25:16.800
It's definitely
relationship building

00:25:16.800 --> 00:25:17.760
over the last couple of years.

00:25:17.760 --> 00:25:19.968
And we kind of use a lot of
our professional contacts

00:25:19.968 --> 00:25:22.630
in the last 20 years,
and to help getting

00:25:22.630 --> 00:25:23.940
to talk to the right people.

00:25:23.940 --> 00:25:25.192
That's important to do.

00:25:25.192 --> 00:25:26.400
SPEAKER 1: Any big surprises?

00:25:26.400 --> 00:25:28.740
I mean, in 2013 to
today I'm sure there's

00:25:28.740 --> 00:25:30.750
been lots of ups and
downs in the journey.

00:25:30.750 --> 00:25:32.550
But what's kind of
surprised you most

00:25:32.550 --> 00:25:35.490
that you weren't thinking before
you took the leap into starting

00:25:35.490 --> 00:25:37.740
a company?

00:25:37.740 --> 00:25:39.660
PATRICIA SCANLAN: I was
full sure at the start

00:25:39.660 --> 00:25:41.660
that I'd have more
competitors right now.

00:25:41.660 --> 00:25:44.160
But I then, in my two, three
years, four years into it,

00:25:44.160 --> 00:25:46.110
oh, that's why, this
is really bloody hard.

00:25:46.110 --> 00:25:49.344
[LAUGHS] Well, those
people will go fry

00:25:49.344 --> 00:25:51.010
bigger fish like
before they'll do this.

00:25:51.010 --> 00:25:53.350
But we've been very
focused on [INAUDIBLE]..

00:25:53.350 --> 00:25:55.714
But yeah, I think
two things happened.

00:25:55.714 --> 00:25:58.380
I'm surprised it took as long as
it did for the voice assistance

00:25:58.380 --> 00:25:59.972
to take off.

00:25:59.972 --> 00:26:00.930
But that's fair enough.

00:26:00.930 --> 00:26:03.870
There's always many
factors for that.

00:26:03.870 --> 00:26:05.737
And then in the child's
speech, I definitely

00:26:05.737 --> 00:26:07.320
think people are
waking up to the fact

00:26:07.320 --> 00:26:08.800
that it's a problem today.

00:26:08.800 --> 00:26:10.970
Again, thought that would
have happened earlier.

00:26:10.970 --> 00:26:12.290
But that's fine.

00:26:12.290 --> 00:26:14.097
We're in a great
position at the moment.

00:26:14.097 --> 00:26:15.430
SPEAKER 1: Good problems, there.

00:26:15.430 --> 00:26:15.690
Good surprises to find there.

00:26:15.690 --> 00:26:17.680
PATRICIA SCANLAN: It's
not a bad problem.

00:26:17.680 --> 00:26:19.780
SPEAKER 1: In terms of
yourself, your own time--

00:26:19.780 --> 00:26:22.113
and one of the things that
we talk a lot about at Google

00:26:22.113 --> 00:26:24.936
is work/life balance, trying to
figure out how you prioritize.

00:26:24.936 --> 00:26:26.560
I mean, you've got
a lot on your plate.

00:26:26.560 --> 00:26:27.654
You've got the tech side.

00:26:27.654 --> 00:26:28.570
You've got the vision.

00:26:28.570 --> 00:26:30.430
You've got the business.

00:26:30.430 --> 00:26:32.520
How do you determine
your priorities

00:26:32.520 --> 00:26:34.426
on a given week,
or a given month,

00:26:34.426 --> 00:26:35.800
in terms of what
you specifically

00:26:35.800 --> 00:26:38.290
are doing versus
your team, given

00:26:38.290 --> 00:26:40.650
the opportunity from what
you've described earlier on

00:26:40.650 --> 00:26:42.520
is just so big?

00:26:42.520 --> 00:26:45.560
PATRICIA SCANLAN: I wish I
had said I know how I do that.

00:26:45.560 --> 00:26:46.550
I don't.

00:26:46.550 --> 00:26:48.640
We prioritize on the fly.

00:26:48.640 --> 00:26:52.900
I mean, my job is CEO,
and it changes by the day.

00:26:52.900 --> 00:26:57.190
I mean, honestly, I'd
be bucking the painter,

00:26:57.190 --> 00:26:58.960
because we just moved
into a new office

00:26:58.960 --> 00:27:02.440
where I'll be talking to legal,
or talking to accountancy,

00:27:02.440 --> 00:27:05.750
or flying into San
Francisco, or to New York.

00:27:05.750 --> 00:27:08.920
And every week is
completely different.

00:27:08.920 --> 00:27:12.010
And you're just
constantly just weighing

00:27:12.010 --> 00:27:14.742
up stuff in your
head dynamically.

00:27:14.742 --> 00:27:16.450
What you told us was
a priority last week

00:27:16.450 --> 00:27:20.100
suddenly drops, because
something else just happened.

00:27:20.100 --> 00:27:22.330
But just having a good
team, and everybody.

00:27:22.330 --> 00:27:25.080
I think what helps
priorities is always

00:27:25.080 --> 00:27:26.780
having the vision in mind.

00:27:26.780 --> 00:27:28.790
And one thing
we've never changed

00:27:28.790 --> 00:27:32.080
is that the voice
technology, getting

00:27:32.080 --> 00:27:34.090
the best possible
platform, that serves

00:27:34.090 --> 00:27:37.940
into our different verticals.

00:27:37.940 --> 00:27:39.850
That is a system that
everybody can use,

00:27:39.850 --> 00:27:42.430
and we don't have to
custom for everybody.

00:27:42.430 --> 00:27:44.770
All those things have
been a focal point for us.

00:27:44.770 --> 00:27:46.960
So if we have a number
of different clients,

00:27:46.960 --> 00:27:48.910
and they're all looking
for different things,

00:27:48.910 --> 00:27:51.080
we actually say no a lot.

00:27:51.080 --> 00:27:54.010
That helps, not being
afraid to say no.

00:27:54.010 --> 00:27:56.500
Because just because you
want it, if nobody else,

00:27:56.500 --> 00:28:01.030
no other client wants it, that's
probably not a priority for us.

00:28:01.030 --> 00:28:02.590
So we try and build
something that's

00:28:02.590 --> 00:28:05.000
a useful product to as
many people as possible.

00:28:05.000 --> 00:28:06.490
And things like
that, always having

00:28:06.490 --> 00:28:10.210
that in mind when you're
making your priority

00:28:10.210 --> 00:28:12.670
list for the week.

00:28:12.670 --> 00:28:15.310
SPEAKER 1: Pivoting
back into the business,

00:28:15.310 --> 00:28:16.900
you presented a
whole lot of logos

00:28:16.900 --> 00:28:19.150
at the very, very start,
some of the biggest companies

00:28:19.150 --> 00:28:20.580
in the world all in this space.

00:28:20.580 --> 00:28:25.030
And commercialization
of voice technology.

00:28:25.030 --> 00:28:27.870
Where do you see,
five, 10 years going?

00:28:27.870 --> 00:28:30.340
What's your perspective on
the revenue streams that

00:28:30.340 --> 00:28:32.970
are going to come out of
these technologies for all

00:28:32.970 --> 00:28:34.880
these companies?

00:28:34.880 --> 00:28:38.080
PATRICIA SCANLAN: I think
a lot of the conversation

00:28:38.080 --> 00:28:41.042
now is about winning the home.

00:28:41.042 --> 00:28:43.000
I think that's what's a
driver for most people.

00:28:43.000 --> 00:28:45.120
I mean, they're not
charging for it.

00:28:45.120 --> 00:28:50.740
But what people
are trying to do,

00:28:50.740 --> 00:28:53.450
I think is to draw
you into an ecosystem,

00:28:53.450 --> 00:28:58.800
and have that ecosystem be
as useful as possible to you.

00:28:58.800 --> 00:29:01.790
It's not about the
voice technology per se.

00:29:01.790 --> 00:29:03.960
It's about you using
one device over another,

00:29:03.960 --> 00:29:06.070
paying for the
hardware, or maybe you

00:29:06.070 --> 00:29:11.230
do you're buying there, or
maybe your services that you

00:29:11.230 --> 00:29:14.750
enlist, who's giving
you the best experience.

00:29:14.750 --> 00:29:17.040
And that's where you go.

00:29:17.040 --> 00:29:20.320
And what most of these bigger
companies have realized

00:29:20.320 --> 00:29:23.950
is that I'm on an Apple fan.

00:29:23.950 --> 00:29:24.940
I've got an iPhone.

00:29:24.940 --> 00:29:26.630
I've got a MacBook.

00:29:26.630 --> 00:29:29.950
And I will probably get the
HomePod if they ever fix Siri.

00:29:29.950 --> 00:29:30.880
Those type of things.

00:29:36.040 --> 00:29:37.990
It's kind of like being
a McDonald's lifer.

00:29:37.990 --> 00:29:42.070
That's why I kind of see where
people are viewing the utility

00:29:42.070 --> 00:29:44.170
and revenue streams.

00:29:44.170 --> 00:29:47.110
But that's not to say it's
not going to change, either.

00:29:47.110 --> 00:29:50.050
I think it's going to be a case
if your product will look less

00:29:50.050 --> 00:29:53.560
for not having good voice
technology as an interface,

00:29:53.560 --> 00:29:57.730
you'll look like
antiquated technology.

00:29:57.730 --> 00:30:00.250
And there's cars
that are partnering

00:30:00.250 --> 00:30:04.610
with some pretty big speech
technology companies to bring

00:30:04.610 --> 00:30:07.090
[INAUDIBLE].

00:30:07.090 --> 00:30:10.521
The Tesla's got pretty good
speech recognition technology

00:30:10.521 --> 00:30:11.020
going.

00:30:11.020 --> 00:30:14.170
You can't bring out a quality
product now without it.

00:30:14.170 --> 00:30:18.220
So over time it's going to
just become more of the norm.

00:30:18.220 --> 00:30:20.775
And everything you sell
them, the majority of it

00:30:20.775 --> 00:30:21.779
will be done by voice.

00:30:21.779 --> 00:30:24.070
SPEAKER 1: And has that
evolution changed your thinking

00:30:24.070 --> 00:30:26.350
on how SoapBox are approaching
the market over the last five

00:30:26.350 --> 00:30:27.040
years?

00:30:27.040 --> 00:30:30.464
Things have moved very,
very fast in the market.

00:30:30.464 --> 00:30:31.380
Have you had to pivot?

00:30:31.380 --> 00:30:33.370
Have you had to twist,
have you had to change,

00:30:33.370 --> 00:30:36.844
or is your approach
still the same?

00:30:36.844 --> 00:30:39.010
PATRICIA SCANLAN: We started
using the word "skills"

00:30:39.010 --> 00:30:39.660
in the last year.

00:30:39.660 --> 00:30:40.618
I think that's changed.

00:30:40.618 --> 00:30:44.050
But it's literally an app
on a voice device like so.

00:30:44.050 --> 00:30:46.837
But in some ways
we always designed

00:30:46.837 --> 00:30:48.670
it to be an underlying
technology that would

00:30:48.670 --> 00:30:51.910
serve into education, gaming.

00:30:51.910 --> 00:30:53.912
We always had the
utility box there,

00:30:53.912 --> 00:30:55.536
which is I think that
whole advice when

00:30:55.536 --> 00:30:59.500
you talk about voice control,
robotics, the AR VR, all that.

00:30:59.500 --> 00:31:02.560
Toys is a big one as well.

00:31:02.560 --> 00:31:06.667
What changed a lot for us is
over the years that we started

00:31:06.667 --> 00:31:09.250
putting a stronger and stronger
focus on data privacy and data

00:31:09.250 --> 00:31:10.660
protection, and what that means.

00:31:10.660 --> 00:31:12.910
And we want to be sure that
we were leading the field,

00:31:12.910 --> 00:31:14.750
and that we know how it works.

00:31:14.750 --> 00:31:16.250
And we want to make
sure that we can

00:31:16.250 --> 00:31:19.009
help other people be compliant.

00:31:19.009 --> 00:31:21.425
To my mind, it was knowing
that was going to be a problem.

00:31:21.425 --> 00:31:25.617
And you better hit those
things head-on earlier.

00:31:25.617 --> 00:31:26.200
SPEAKER 1: OK.

00:31:26.200 --> 00:31:29.432
And maybe going a bit more
specific on the offering.

00:31:29.432 --> 00:31:30.890
So sitting underneath
SoapBox Labs,

00:31:30.890 --> 00:31:34.970
there's obviously some IP
in terms of development.

00:31:34.970 --> 00:31:37.460
How have you gotten there
in terms of really getting

00:31:37.460 --> 00:31:39.170
something unique and
something different

00:31:39.170 --> 00:31:40.836
that's not available
in the marketplace,

00:31:40.836 --> 00:31:43.639
so the ideas, the
[INAUDIBLE] the technologies.

00:31:43.639 --> 00:31:44.930
What exactly is under the hood?

00:31:46.485 --> 00:31:48.610
PATRICIA SCANLAN: As I kind
of pointed a little bit

00:31:48.610 --> 00:31:51.710
in the talk was about the data.

00:31:51.710 --> 00:31:54.785
We use state-of-the-art
deep-learning technologies.

00:31:57.800 --> 00:31:59.530
We've over eight
years' experience

00:31:59.530 --> 00:32:00.920
in the team in speech
recognition technology.

00:32:00.920 --> 00:32:01.710
That's actually growing.

00:32:01.710 --> 00:32:02.918
We might have to add to that.

00:32:05.390 --> 00:32:09.200
We concentrated on
quality data first.

00:32:09.200 --> 00:32:14.810
I recognized that problem after
my experience in Bell Labs.

00:32:14.810 --> 00:32:18.590
Actually, it was Google
back in the early 2000s that

00:32:18.590 --> 00:32:20.510
started a really
clever data collection

00:32:20.510 --> 00:32:25.700
program, these GOOG-411 that
you'd ring and ask for advice.

00:32:25.700 --> 00:32:28.980
You'd get free information call
if you used voice technology

00:32:28.980 --> 00:32:30.124
back in the early 2000s.

00:32:30.124 --> 00:32:31.790
And it was actually
a very effective way

00:32:31.790 --> 00:32:34.310
of collecting data.

00:32:34.310 --> 00:32:37.180
GOOG started a long
time before anyone else.

00:32:37.180 --> 00:32:40.160
But my own experience, I worked
a number of different projects

00:32:40.160 --> 00:32:44.140
in the Bell Labs days, where
lab-like data versus real-world

00:32:44.140 --> 00:32:44.870
data--

00:32:44.870 --> 00:32:46.310
actually, in IBM as well--

00:32:46.310 --> 00:32:48.530
was that you can collect
all the data in the world,

00:32:48.530 --> 00:32:50.780
and build a very
efficient system.

00:32:50.780 --> 00:32:52.430
But if it's not
representative of where

00:32:52.430 --> 00:32:58.495
you expect to use the voice
technology, it won't work.

00:32:58.495 --> 00:33:02.270
And all those
learnings have lead

00:33:02.270 --> 00:33:04.920
us to do things in
a different order

00:33:04.920 --> 00:33:06.680
than other people were doing it.

00:33:06.680 --> 00:33:09.520
We were concentrating
on quality data,

00:33:09.520 --> 00:33:11.990
understanding the problem,
understanding the application

00:33:11.990 --> 00:33:13.190
areas.

00:33:13.190 --> 00:33:15.620
And then [INAUDIBLE]
state-of-the-art technology,

00:33:15.620 --> 00:33:17.995
and our cloud-based API,
and making it available,

00:33:17.995 --> 00:33:18.870
and all those things.

00:33:18.870 --> 00:33:20.570
So there's kind
of multiple areas

00:33:20.570 --> 00:33:24.860
of expertise from the team and
our own experience as well.

00:33:24.860 --> 00:33:28.040
People who came [INAUDIBLE],,
how we do it, how we address

00:33:28.040 --> 00:33:29.370
behaviors.

00:33:29.370 --> 00:33:31.895
All that, as well as
the thousands of hours

00:33:31.895 --> 00:33:34.030
of data that we acquired.

00:33:34.030 --> 00:33:35.030
SPEAKER 1: Good to hear.

00:33:35.030 --> 00:33:36.000
A lot in there.

00:33:36.000 --> 00:33:39.050
Maybe open it to the floor.

00:33:39.050 --> 00:33:41.570
Any questions for Patrica?

00:33:41.570 --> 00:33:42.230
AUDIENCE: Hi.

00:33:42.230 --> 00:33:43.330
Thanks for the talk.

00:33:43.330 --> 00:33:45.260
Very interesting.

00:33:45.260 --> 00:33:48.080
I was wondering if you
could share some information

00:33:48.080 --> 00:33:52.150
about the effect that it has
on children, too, especially

00:33:52.150 --> 00:33:53.480
on their behavior, right?

00:33:53.480 --> 00:33:57.350
So with the products that
are on the market now,

00:33:57.350 --> 00:33:59.840
it's very often that
all that is needed

00:33:59.840 --> 00:34:02.610
is a command or an
order, basically.

00:34:02.610 --> 00:34:05.800
So you say, hey Google, do this.

00:34:05.800 --> 00:34:07.695
But you never say,
please, or thank

00:34:07.695 --> 00:34:09.199
you, or anything like that.

00:34:09.199 --> 00:34:11.449
So what kind of
impact does that have

00:34:11.449 --> 00:34:15.559
on the behavior of a child that
they think that that's normal?

00:34:15.559 --> 00:34:18.739
And when they ask someone
else do something else,

00:34:18.739 --> 00:34:22.770
to someone else, are they going
to copy that behavior as well?

00:34:22.770 --> 00:34:25.587
Or do they realize that they're
not talking to technology?

00:34:25.587 --> 00:34:28.170
PATRICIA SCANLAN: It depends on
the age of the child, I guess.

00:34:28.170 --> 00:34:32.125
As a parent, I would
always advocate

00:34:32.125 --> 00:34:33.489
you say "please" regardless.

00:34:33.489 --> 00:34:35.030
So it comes from the parent.

00:34:35.030 --> 00:34:39.020
I mean, as much as the child
could be rude to another human,

00:34:39.020 --> 00:34:41.159
I think you teach those
behaviors in some ways.

00:34:41.159 --> 00:34:43.429
The fact that Alexa will do,
or Google Home will do it

00:34:43.429 --> 00:34:48.320
regardless, maybe that's a
little add-on, or a little

00:34:48.320 --> 00:34:50.239
opt-in that you got to do.

00:34:50.239 --> 00:34:52.997
She won't do it unless
you say, please.

00:34:52.997 --> 00:34:55.440
I'll push that back in
Google to address that issue.

00:34:58.250 --> 00:35:00.440
AUDIENCE: My question
is about the product.

00:35:00.440 --> 00:35:02.960
Is it more like a classifier
for a kid's voice,

00:35:02.960 --> 00:35:06.840
or is it speech
cognition including kids?

00:35:06.840 --> 00:35:08.805
PATRICIA SCANLAN:
A classifier--?

00:35:08.805 --> 00:35:09.680
AUDIENCE: --for kids.

00:35:09.680 --> 00:35:10.470
For a kid's voice.

00:35:10.470 --> 00:35:12.440
For instance is you're
trying to predict

00:35:12.440 --> 00:35:14.880
if this is a kid speaking,
or children speaking.

00:35:14.880 --> 00:35:17.960
Or is it more speech recognition
including kids, trying

00:35:17.960 --> 00:35:19.310
to understand what they say?

00:35:19.310 --> 00:35:20.518
PATRICIA SCANLAN: We do both.

00:35:20.518 --> 00:35:23.167
So we recognize adult versus
child as a classification.

00:35:23.167 --> 00:35:25.250
And then there's also a
speech recognizer as well.

00:35:25.250 --> 00:35:27.380
AUDIENCE: And for
the classifier,

00:35:27.380 --> 00:35:29.090
how do you classify?

00:35:29.090 --> 00:35:33.010
What is the threshold for being
a voice as a children voice,

00:35:33.010 --> 00:35:35.140
or adult voice?

00:35:35.140 --> 00:35:36.860
PATRICIA SCANLAN: So
traditionally it's

00:35:36.860 --> 00:35:38.740
kind of a well-recognized
problem that

00:35:38.740 --> 00:35:42.305
under the age of 12 is when
you find the voice starting

00:35:42.305 --> 00:35:44.270
to differentiate the most.

00:35:44.270 --> 00:35:47.570
So that depends on
the client, let's say,

00:35:47.570 --> 00:35:50.480
coming to us about what
their specification is,

00:35:50.480 --> 00:35:51.740
what would they rather happen.

00:35:51.740 --> 00:35:52.530
It's not going to be binary.

00:35:52.530 --> 00:35:54.110
It's not going to
be black and white.

00:35:54.110 --> 00:35:57.220
So you're not going to be able
to say, I have a cut-off at 13,

00:35:57.220 --> 00:35:58.130
because you're going to
have some 11 year olds that

00:35:58.130 --> 00:35:59.690
are going to speak like a 13
year old and a 13 year old's

00:35:59.690 --> 00:36:01.148
going to speak like
an 11 year old.

00:36:01.148 --> 00:36:04.260
So you will have that
little gray area there.

00:36:04.260 --> 00:36:09.070
But it's quite clear once you
start going anywhere younger.

00:36:09.070 --> 00:36:11.890
AUDIENCE: And can
I ask the accuracy?

00:36:11.890 --> 00:36:12.880
PATRICIA SCANLAN: Of--?

00:36:12.880 --> 00:36:14.330
AUDIENCE: --of the
classification.

00:36:14.330 --> 00:36:17.400
Are you saying this is kid's
voice, or not kid's voice,

00:36:17.400 --> 00:36:19.330
and for the age, for instance?

00:36:19.330 --> 00:36:21.538
PATRICIA SCANLAN: I can
share more information but it

00:36:21.538 --> 00:36:24.137
would very much depend on--

00:36:24.137 --> 00:36:25.720
I think, like you
say, if you're going

00:36:25.720 --> 00:36:28.303
to say, can I recognize a four
or five year old from an adult,

00:36:28.303 --> 00:36:29.777
I'd say 100% accuracy.

00:36:29.777 --> 00:36:31.360
If you're going to
start saying, can I

00:36:31.360 --> 00:36:35.440
recognize a 12 year old from
an adult, that gets harder.

00:36:35.440 --> 00:36:38.230
It's very easy to separate
young children from adults.

00:36:38.230 --> 00:36:40.450
I'll say that for [INAUDIBLE].

00:36:40.450 --> 00:36:41.570
AUDIENCE: Thank you.

00:36:41.570 --> 00:36:43.528
ALEXA: You mentioned you
have an Alexa at home.

00:36:43.528 --> 00:36:46.180
Do you have any other
voice assistance at home?

00:36:46.180 --> 00:36:48.374
PATRICIA SCANLAN: No, I don't.

00:36:48.374 --> 00:36:52.150
We have a Bixby and a
Siri on our home devices.

00:36:52.150 --> 00:36:54.610
AUDIENCE: And is it purely
out of professional interest

00:36:54.610 --> 00:36:56.530
that you have it at
home, or do you actually

00:36:56.530 --> 00:36:58.932
use it for queries?

00:36:58.932 --> 00:37:00.640
PATRICIA SCANLAN:
Yeah, it was definitely

00:37:00.640 --> 00:37:02.490
bought as a research
piece of equipment.

00:37:02.490 --> 00:37:04.990
I think I bought it from the
US, because I wanted to have it

00:37:04.990 --> 00:37:07.135
back in 2015 or 2016.

00:37:07.135 --> 00:37:09.720
And then I have access
to a Google Homes.

00:37:09.720 --> 00:37:12.150
We've been testing that as well.

00:37:12.150 --> 00:37:13.220
We use it.

00:37:13.220 --> 00:37:18.310
We definitely use it as
usually timers, alarms.

00:37:18.310 --> 00:37:21.880
Playing music is a
big one in our house.

00:37:21.880 --> 00:37:25.460
How do you spell this.

00:37:25.460 --> 00:37:28.000
General knowledge, just
for fun, sometimes.

00:37:28.000 --> 00:37:29.540
I think the utility
can be better.

00:37:29.540 --> 00:37:31.090
I think we haven't
quite seen it yet.

00:37:31.090 --> 00:37:32.350
I think it's quite limited.

00:37:32.350 --> 00:37:34.810
And sometimes on an Amazon,
like if you actually

00:37:34.810 --> 00:37:37.670
see it working in somewhere
like the US, or London,

00:37:37.670 --> 00:37:40.240
where you've got Uber, and
you've got your deliveries.

00:37:40.240 --> 00:37:42.670
The way you've got
"Call me an Uber."

00:37:42.670 --> 00:37:44.260
That's what I want
to be able to do.

00:37:44.260 --> 00:37:45.440
We can't do that
here in Ireland.

00:37:45.440 --> 00:37:47.315
So I think in Ireland
we're somewhat limited,

00:37:47.315 --> 00:37:50.392
because they only just
released it for Ireland.

00:37:50.392 --> 00:37:52.100
And it depends on what
it's connected to,

00:37:52.100 --> 00:37:54.121
and what apps you enable.

00:37:54.121 --> 00:37:55.620
I think we're
somewhat limited here.

00:37:55.620 --> 00:37:58.690
I've definitely seen
better utility in the US.

00:37:58.690 --> 00:38:00.460
ALEXA: And from your
personal experience,

00:38:00.460 --> 00:38:01.970
which one do you
find more accurate,

00:38:01.970 --> 00:38:03.876
the Alexa or the Google Home?

00:38:03.876 --> 00:38:05.250
[LAUGHTER]

00:38:05.250 --> 00:38:07.790
PATRICIA SCANLAN: I would say
Google in the natural language

00:38:07.790 --> 00:38:09.430
understanding for sure.

00:38:13.180 --> 00:38:17.310
You get way too many "I don't
know what that means" on Alexa.

00:38:17.310 --> 00:38:20.039
But I think that's an
understood problem.

00:38:20.039 --> 00:38:21.580
And then there's
problems vice versa.

00:38:21.580 --> 00:38:23.700
I think both of them
have their strengths.

00:38:23.700 --> 00:38:25.396
It depends on what
you're linked into.

00:38:25.396 --> 00:38:26.770
Depends on what
you need as well.

00:38:26.770 --> 00:38:28.540
I think actually,
people, you never

00:38:28.540 --> 00:38:31.990
really hear one's going to be
that strong over the other.

00:38:31.990 --> 00:38:35.380
I think when it comes to
kid's speech, I won't say.

00:38:35.380 --> 00:38:38.660
We've done our own empirical
research on that one.

00:38:38.660 --> 00:38:40.510
AUDIENCE: Thank you.

00:38:40.510 --> 00:38:43.150
AUDIENCE: You talk about
speech recognition, of course,

00:38:43.150 --> 00:38:48.050
but is there a lot of focus
also on the other side?

00:38:48.050 --> 00:38:50.700
So I mean for me,
it's really weird

00:38:50.700 --> 00:38:53.680
that we have this advanced
speech recognition everywhere.

00:38:53.680 --> 00:38:55.720
But the system that
asks-- especially

00:38:55.720 --> 00:38:59.230
in this [? AVR ?] system is
very clunky still, very robotic.

00:38:59.230 --> 00:39:01.960
And very if you want
blah, blah, [INAUDIBLE]..

00:39:01.960 --> 00:39:04.430
So is there anything going
on, especially for kids,

00:39:04.430 --> 00:39:06.190
on how this is served?

00:39:06.190 --> 00:39:10.404
This is a fun assistant, and he
doesn't ask and answer in a way

00:39:10.404 --> 00:39:11.320
that you might expect.

00:39:11.320 --> 00:39:13.430
So a bit more
human-like, or maybe

00:39:13.430 --> 00:39:15.184
throwing a joke in,
or presenting it

00:39:15.184 --> 00:39:16.975
in a different way, or
is this completely--

00:39:16.975 --> 00:39:19.142
are these two
separate fields or is

00:39:19.142 --> 00:39:22.116
this the same kind of companies
that work [INAUDIBLE]??

00:39:22.116 --> 00:39:23.860
PATRICIA SCANLAN: Kind of like
chat bot type thing with voice.

00:39:23.860 --> 00:39:24.850
Is that what you mean?

00:39:24.850 --> 00:39:27.060
AUDIENCE: So the
assistant being more

00:39:27.060 --> 00:39:29.944
of a person than just
a piece of technical.

00:39:29.944 --> 00:39:31.110
I can relate to that person.

00:39:31.110 --> 00:39:33.400
He has some silly
jokes, and I program him

00:39:33.400 --> 00:39:35.067
for the personality,
that kind of thing.

00:39:35.067 --> 00:39:37.316
PATRICIA SCANLAN: There's
nothing really on the market

00:39:37.316 --> 00:39:38.290
that's blown us away.

00:39:38.290 --> 00:39:40.539
But we know there's a huge
amount of companies looking

00:39:40.539 --> 00:39:43.772
at this, and not a huge
amount of research done on it,

00:39:43.772 --> 00:39:44.730
actually, funny enough.

00:39:44.730 --> 00:39:47.840
We've looked, and we've
been asked about it recently

00:39:47.840 --> 00:39:51.287
about that exactly, that
what would that voice

00:39:51.287 --> 00:39:53.620
assistant, or chat bot for
child, what makes more sense.

00:39:53.620 --> 00:39:55.280
Because kids use
different language.

00:39:55.280 --> 00:39:56.890
Their concepts are simpler.

00:39:56.890 --> 00:39:59.570
You can't use a lot of what
you would use for an adult

00:39:59.570 --> 00:40:01.716
with a child, because
they won't get it.

00:40:01.716 --> 00:40:03.200
And it's not
appropriate sometimes.

00:40:03.200 --> 00:40:05.158
Even the concept can be
just too much for them.

00:40:05.158 --> 00:40:06.520
They don't get subtleties.

00:40:06.520 --> 00:40:08.353
And then again, it
depends on the age group.

00:40:08.353 --> 00:40:12.895
You're talking about 4 to 7, or
are you talking about 9 to 12?

00:40:12.895 --> 00:40:13.770
Very little actually.

00:40:13.770 --> 00:40:14.854
Very little has been done.

00:40:14.854 --> 00:40:16.978
But then again, you think
about the whole chat bot,

00:40:16.978 --> 00:40:18.430
that kind of
automated assistant,

00:40:18.430 --> 00:40:19.600
that natural
language, understand,

00:40:19.600 --> 00:40:20.933
it's still quite new for adults.

00:40:20.933 --> 00:40:23.580
We're only getting
better at it now.

00:40:23.580 --> 00:40:25.210
And what I've seen
is quite a lag

00:40:25.210 --> 00:40:27.510
on what will happen for kids.

00:40:27.510 --> 00:40:28.480
It will happen.

00:40:28.480 --> 00:40:30.340
We've seen a lot of
people working on it.

00:40:33.040 --> 00:40:34.917
AUDIENCE: Thanks a lot
for the presentation.

00:40:34.917 --> 00:40:36.500
Because of the nature
of your company,

00:40:36.500 --> 00:40:39.680
I guess you have collective
access to a lot of data,

00:40:39.680 --> 00:40:43.470
and voice samples
of little kids.

00:40:43.470 --> 00:40:46.550
So if you could share how do you
approach gathering this data,

00:40:46.550 --> 00:40:49.069
collecting this, or buying
this, getting access to it.

00:40:49.069 --> 00:40:51.110
And how do you make sure
it is compliant with all

00:40:51.110 --> 00:40:54.270
of the privacy regulations
that you just mentioned?

00:40:54.270 --> 00:40:56.450
PATRICIA SCANLAN: So we
just do it ourselves.

00:40:56.450 --> 00:40:58.740
We don't talk too much
about how we do it.

00:40:58.740 --> 00:41:02.000
But from the get-go
in 2013, we've

00:41:02.000 --> 00:41:05.850
been fully compliant
with COPPA because I

00:41:05.850 --> 00:41:07.210
started the company myself.

00:41:07.210 --> 00:41:10.770
So I made sure I was engaged
with privacy lawyers,

00:41:10.770 --> 00:41:12.010
and understanding this.

00:41:12.010 --> 00:41:14.066
And more so understanding
that we didn't really

00:41:14.066 --> 00:41:15.940
have an obligation to
do it in the beginning.

00:41:15.940 --> 00:41:18.620
But it was one of
those things I really

00:41:18.620 --> 00:41:20.471
thought was going
to be an issue,

00:41:20.471 --> 00:41:22.720
and it should be an issue,
and it should be addressed.

00:41:22.720 --> 00:41:24.830
So for a small
company, I don't think

00:41:24.830 --> 00:41:27.140
it's worth taking risks
on something like that.

00:41:27.140 --> 00:41:29.260
So we've done
everything ourselves.

00:41:29.260 --> 00:41:32.756
And I'm glad about that as
well, because it actually

00:41:32.756 --> 00:41:34.130
wasn't even possible
to buy data,

00:41:34.130 --> 00:41:36.400
because there isn't anything
equivalent out there.

00:41:36.400 --> 00:41:39.600
Not in real world data, not in
[INAUDIBLE] on a mobile device,

00:41:39.600 --> 00:41:42.877
not in a real environment,
not in uncontrolled ways.

00:41:42.877 --> 00:41:44.710
And to my mind, everything
else was useless.

00:41:44.710 --> 00:41:48.950
Because again, like I said,
if the only data you could buy

00:41:48.950 --> 00:41:52.987
was fairly lab-like environment,
and controlled by an adult

00:41:52.987 --> 00:41:55.320
or a parent sitting there
making a child read something,

00:41:55.320 --> 00:41:57.130
that's not real-world stuff.

00:41:57.130 --> 00:42:01.610
So we've been very careful
to do it ourselves.

00:42:01.610 --> 00:42:05.920
We've been careful to
be compliant globally.

00:42:05.920 --> 00:42:08.170
And to that end, that's
another value to us.

00:42:08.170 --> 00:42:10.364
It's means we can stand
over what we've done.

00:42:10.364 --> 00:42:11.030
AUDIENCE: Right.

00:42:11.030 --> 00:42:12.140
That's a a lot of
effort, I guess,

00:42:12.140 --> 00:42:12.785
to gather this type of data.

00:42:12.785 --> 00:42:13.743
PATRICIA SCANLAN: Yeah.

00:42:13.743 --> 00:42:15.210
It was a huge [INAUDIBLE].

00:42:15.210 --> 00:42:17.450
AUDIENCE: So one
follow-up question, then.

00:42:17.450 --> 00:42:21.150
Do you then take
into consideration

00:42:21.150 --> 00:42:23.260
to make sure you
collect the samples

00:42:23.260 --> 00:42:25.540
from different countries,
different cultures,

00:42:25.540 --> 00:42:27.730
just to avoid the
cultural country bias?

00:42:27.730 --> 00:42:28.688
PATRICIA SCANLAN: Yeah.

00:42:28.688 --> 00:42:30.630
We have data from over
170 countries now,

00:42:30.630 --> 00:42:36.140
and tens of thousands, or we're
actually more than that now.

00:42:36.140 --> 00:42:38.460
That was huge, as well,
actually to be honest.

00:42:38.460 --> 00:42:42.650
Because I lived in the
US for quite a bit,

00:42:42.650 --> 00:42:43.520
in different areas.

00:42:43.520 --> 00:42:44.700
And one of the
things I always noted

00:42:44.700 --> 00:42:46.170
was if you live in
New York, or if you

00:42:46.170 --> 00:42:47.730
drop a pin on a
school in New York,

00:42:47.730 --> 00:42:50.040
I'm sure you're not going
to get more than 20%

00:42:50.040 --> 00:42:51.630
of New York accent.

00:42:51.630 --> 00:42:55.410
So why just build a
system with US accents?

00:42:55.410 --> 00:42:57.660
And that was really
key, that if a system's

00:42:57.660 --> 00:42:59.560
going to work
everywhere, the world

00:42:59.560 --> 00:43:00.990
doesn't work like that anymore.

00:43:00.990 --> 00:43:03.840
You've got such flow
of people, whatever.

00:43:03.840 --> 00:43:07.350
And to be honest, deep learning
and all those technologies,

00:43:07.350 --> 00:43:08.840
the advent of that
has allowed us

00:43:08.840 --> 00:43:13.490
to be able to add multiple
variations in pronunciation

00:43:13.490 --> 00:43:17.010
to the system, whereas when
I started this back in 2000,

00:43:17.010 --> 00:43:20.245
you'd probably have a
model from mid-Western US,

00:43:20.245 --> 00:43:21.880
and [INAUDIBLE].

00:43:21.880 --> 00:43:23.995
And even at that,
you probably have

00:43:23.995 --> 00:43:26.370
to break it into different
dialects and accents and stuff

00:43:26.370 --> 00:43:28.110
like that, because
the systems couldn't

00:43:28.110 --> 00:43:31.541
cope with the variation, where
we can now, which is amazing.

00:43:36.251 --> 00:43:37.142
AUDIENCE: Hey.

00:43:37.142 --> 00:43:38.100
Thank you for the talk.

00:43:38.100 --> 00:43:39.070
Really interesting.

00:43:39.070 --> 00:43:42.200
I actually got interested in
the topic because of "AdWeek"

00:43:42.200 --> 00:43:45.960
and a talk about that as
well, on the future of search.

00:43:45.960 --> 00:43:48.800
So it had a lot of
similar implications

00:43:48.800 --> 00:43:51.500
in terms of what happens
if a child is in the room,

00:43:51.500 --> 00:43:54.470
and also what does that mean
for advertising in voice search.

00:43:54.470 --> 00:43:57.530
Do you have any take on the
combination of advertising

00:43:57.530 --> 00:44:00.140
in voice search in the future,
and children being in the room?

00:44:00.140 --> 00:44:02.660
Because there's a lot of
regulations and problems

00:44:02.660 --> 00:44:03.285
with that, too.

00:44:03.285 --> 00:44:04.784
PATRICIA SCANLAN:
Yeah, I think it'd

00:44:04.784 --> 00:44:07.020
be much like I said about
the appropriateness,

00:44:07.020 --> 00:44:14.080
that for advertisers,
I think you don't want

00:44:14.080 --> 00:44:17.580
to waste time
advertising to children,

00:44:17.580 --> 00:44:20.200
because they're not the buyers.

00:44:20.200 --> 00:44:22.990
So I mean as much
as you ethically

00:44:22.990 --> 00:44:25.630
need to be able to make it
an appropriate experience

00:44:25.630 --> 00:44:30.730
for a child, you
also commercially

00:44:30.730 --> 00:44:33.017
shouldn't be wasting
advertising dollars

00:44:33.017 --> 00:44:34.100
on advertising to a child.

00:44:34.100 --> 00:44:37.480
So I think again the simple
adult/child classifiers

00:44:37.480 --> 00:44:40.300
for different age groups
as well is appropriate.

00:44:40.300 --> 00:44:43.630
Even on apps now
these days, there's

00:44:43.630 --> 00:44:45.422
quite strict regulations--
not regulations,

00:44:45.422 --> 00:44:47.296
more like guidelines as
well-- about what you

00:44:47.296 --> 00:44:48.670
should advertise to children.

00:44:48.670 --> 00:44:52.230
So while some apps are free,
you can slot in static ads.

00:44:52.230 --> 00:44:54.655
But it should be an
ad on Lego or Barbie.

00:44:54.655 --> 00:44:58.480
But it shouldn't be an ad
on something inappropriate.

00:44:58.480 --> 00:45:02.701
And I think that's just
business sense, really, as well.

00:45:02.701 --> 00:45:04.450
I mean, there's one
side that regulation's

00:45:04.450 --> 00:45:06.575
going to force us all to
do these things correctly.

00:45:06.575 --> 00:45:08.580
It's about time.

00:45:08.580 --> 00:45:11.550
But on the other side, there's
definitely just good sense

00:45:11.550 --> 00:45:16.230
about as much as you target your
ads to different demographics

00:45:16.230 --> 00:45:16.730
I think.

00:45:16.730 --> 00:45:19.630
Yeah.

00:45:19.630 --> 00:45:20.820
SPEAKER 1: OK.

00:45:20.820 --> 00:45:24.884
One more question?

00:45:24.884 --> 00:45:27.346
I'll take the last one.

00:45:27.346 --> 00:45:29.000
Usually people start
running at 5:00

00:45:29.000 --> 00:45:30.070
to get to their next
meetings, and I'm

00:45:30.070 --> 00:45:32.290
guessing a lot of people
here will be doing that.

00:45:32.290 --> 00:45:34.030
We've talked a lot about
the hard work to date,

00:45:34.030 --> 00:45:36.488
the problems you're solving,
the things you're going after.

00:45:36.488 --> 00:45:38.340
Let's look out in
10 years, your hope

00:45:38.340 --> 00:45:42.490
for SoapBox Labs, where you'll
be, what you'll be doing.

00:45:42.490 --> 00:45:44.740
Would you like to share
any of the future--

00:45:44.740 --> 00:45:46.870
PATRICIA SCANLAN:
Yeah, I mean initially

00:45:46.870 --> 00:45:48.640
for the next few
years, anyway, we've

00:45:48.640 --> 00:45:50.830
got a big focus on multilingual.

00:45:50.830 --> 00:45:52.240
I think that's a huge thing.

00:45:52.240 --> 00:45:54.280
We can't just
continue to expect--

00:45:54.280 --> 00:45:56.950
It's been such a hard slog to
get anything quality out there

00:45:56.950 --> 00:45:57.550
in English.

00:45:57.550 --> 00:45:59.530
But we've learned so much.

00:45:59.530 --> 00:46:00.545
We've got our pipelines.

00:46:00.545 --> 00:46:01.820
We've got our processes.

00:46:01.820 --> 00:46:04.346
We can accelerate
now adding languages.

00:46:04.346 --> 00:46:06.470
And that's what we raised
EU funding for, actually.

00:46:06.470 --> 00:46:10.020
We raised quite considerable
funding at the end of last year

00:46:10.020 --> 00:46:11.850
to take our platform
multi-lingual.

00:46:11.850 --> 00:46:16.120
So that's going to be a
massive focus of the company.

00:46:16.120 --> 00:46:19.000
And eventually there's lots
of different variations

00:46:19.000 --> 00:46:21.180
of speech, all types of
voice technology, where

00:46:21.180 --> 00:46:22.180
voice comes into it.

00:46:22.180 --> 00:46:22.840
And it's kids.

00:46:22.840 --> 00:46:23.899
That's where we'll be.

00:46:23.899 --> 00:46:25.690
And we're already
building up our expertise

00:46:25.690 --> 00:46:28.180
in a number of different
areas, do more natural language

00:46:28.180 --> 00:46:30.815
understanding as well around
children, things like that.

00:46:30.815 --> 00:46:33.190
And we listen a lot to what
our clients are saying to us,

00:46:33.190 --> 00:46:37.100
and what they want to be
able to bring to market.

00:46:37.100 --> 00:46:40.870
So as much as we'll do certain
amounts of it at the moment,

00:46:40.870 --> 00:46:43.130
but we're listening all
the time to what they want,

00:46:43.130 --> 00:46:46.570
and but without going
into too much detail,

00:46:46.570 --> 00:46:48.232
we're responding to that.

00:46:48.232 --> 00:46:50.440
And right now we have a
great position in the market,

00:46:50.440 --> 00:46:55.499
because we have quite a
lead, because we focus solely

00:46:55.499 --> 00:46:57.790
on that we haven't diversified
over the last five years

00:46:57.790 --> 00:46:59.104
on kids.

00:46:59.104 --> 00:47:00.520
But there's so
many opportunities.

00:47:00.520 --> 00:47:01.660
Globally there's so
many opportunities

00:47:01.660 --> 00:47:02.660
in this [INAUDIBLE].

00:47:02.660 --> 00:47:04.877
So yeah, we'll just
keep those [INAUDIBLE]..

00:47:04.877 --> 00:47:06.710
SPEAKER 1: Well, great
space, great company.

00:47:06.710 --> 00:47:08.650
And thank you very much
for taking the time,

00:47:08.650 --> 00:47:11.050
coming in to talk to us
here, sharing your journey,

00:47:11.050 --> 00:47:12.790
sharing the SoapBox Lab journey.

00:47:12.790 --> 00:47:14.140
Best wishes for the future.

00:47:14.140 --> 00:47:16.139
I mean, I know pretty
much everyone in this room

00:47:16.139 --> 00:47:18.190
is probably excited about
where voice is going,

00:47:18.190 --> 00:47:19.280
where the technology is going.

00:47:19.280 --> 00:47:21.930
And it's great to see an Irish
company, an indigenous company,

00:47:21.930 --> 00:47:24.460
doing real tech work
here with an ambition

00:47:24.460 --> 00:47:26.210
to go global as well.

00:47:26.210 --> 00:47:28.120
So thank you very much.

00:47:28.120 --> 00:47:32.370
[APPLAUSE]

