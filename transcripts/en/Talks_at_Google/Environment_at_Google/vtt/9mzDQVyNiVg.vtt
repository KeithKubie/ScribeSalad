WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.988
[MUSIC PLAYING]

00:00:09.481 --> 00:00:14.880
PETER KOHLER: We're here
to talk about how we're

00:00:14.880 --> 00:00:16.635
revealing an ocean under siege.

00:00:19.900 --> 00:00:22.910
And as Florian said, how we're
sort of using technologies

00:00:22.910 --> 00:00:26.920
in science and machine
learning and combining

00:00:26.920 --> 00:00:29.980
that in a really innovative and
sort of cutting edge way to try

00:00:29.980 --> 00:00:36.370
and reveal just how much
this ocean is under siege.

00:00:36.370 --> 00:00:39.830
But first, I want to start
where it started for me.

00:00:39.830 --> 00:00:45.850
So I was fortunate enough
to go to the South Pacific,

00:00:45.850 --> 00:00:48.120
find a skipper who
needed some crew,

00:00:48.120 --> 00:00:49.850
and jump on board
for four months.

00:00:49.850 --> 00:00:52.480
And I spent four months sailing
around what you can only

00:00:52.480 --> 00:00:53.750
describe as a paradise.

00:00:53.750 --> 00:00:58.300
I mean, it really was the
picture postcard ideal of it.

00:00:58.300 --> 00:01:00.850
But it was a
paradise under siege,

00:01:00.850 --> 00:01:03.010
and we could see
that everywhere.

00:01:03.010 --> 00:01:07.111
And perhaps the
most, you know, I

00:01:07.111 --> 00:01:08.860
don't know if this
video is going to work.

00:01:08.860 --> 00:01:13.930
So you have this off the
bow of the boat, dolphins

00:01:13.930 --> 00:01:15.130
jumping around.

00:01:15.130 --> 00:01:17.830
It is pure,
beautiful blue as you

00:01:17.830 --> 00:01:21.990
are [? sees ?] and
the next thing which

00:01:21.990 --> 00:01:24.390
you can't help but
not see, I mean

00:01:24.390 --> 00:01:26.260
this is actually in the UK.

00:01:26.260 --> 00:01:29.700
But-- if it loads,
will it load--

00:01:29.700 --> 00:01:34.280
is quite literally a plastic
tide, a tide of litter

00:01:34.280 --> 00:01:35.410
washing up on the beach.

00:01:35.410 --> 00:01:37.870
And you can see this
from this drone footage.

00:01:37.870 --> 00:01:40.990
You can see all the litter
items just washed up.

00:01:40.990 --> 00:01:43.400
And this was everywhere.

00:01:43.400 --> 00:01:46.630
So every tropical remote
island you went to--

00:01:46.630 --> 00:01:49.150
and I'm sure you've all heard
it in the news, but you know,

00:01:49.150 --> 00:01:52.630
this was back in 2008.

00:01:52.630 --> 00:01:58.030
So when I came back, it really
was something that bothered me.

00:01:58.030 --> 00:02:01.590
I wanted to know how much this
is affecting us and the world.

00:02:01.590 --> 00:02:03.760
And so I started
looking into it,

00:02:03.760 --> 00:02:06.010
and I started finding ways
in which I can do something

00:02:06.010 --> 00:02:08.020
about it.

00:02:08.020 --> 00:02:09.850
And very quickly,
I found that it was

00:02:09.850 --> 00:02:11.570
a massively growing problem.

00:02:11.570 --> 00:02:16.270
So this is-- it costs around,
the world economy, around $8

00:02:16.270 --> 00:02:17.680
billion a year at least.

00:02:17.680 --> 00:02:22.510
You'll see a World Bank estimate
that's closer to $12 billion.

00:02:22.510 --> 00:02:25.840
It's an exponential increase
in global plastic production.

00:02:25.840 --> 00:02:29.980
So by 2050, we're looking
at 1.8 billion tons a year.

00:02:29.980 --> 00:02:32.680
And then I'm sure you probably
heard some of these quotes.

00:02:32.680 --> 00:02:34.930
This is from
MacArthur Foundation.

00:02:34.930 --> 00:02:39.150
By 2050, there could be as much
plastic in the ocean as fish,

00:02:39.150 --> 00:02:40.570
20% of our oil
production will be

00:02:40.570 --> 00:02:43.450
devoted to plastic
production, and something

00:02:43.450 --> 00:02:45.710
like 15% of the global
carbon footprint

00:02:45.710 --> 00:02:47.680
be because of plastics.

00:02:47.680 --> 00:02:50.410
So they're quite harrowing
figures, but what

00:02:50.410 --> 00:02:52.780
sort of impact does that have?

00:02:52.780 --> 00:02:55.190
This is the actual
impact, and apology.

00:02:55.190 --> 00:02:57.660
I probably should have warned
you guys ahead of that.

00:02:57.660 --> 00:03:03.730
But we've got plastics inside
fishes' digestive tracts.

00:03:03.730 --> 00:03:05.410
So this is out in the Pacific.

00:03:05.410 --> 00:03:07.630
I think this is an albatross.

00:03:07.630 --> 00:03:09.460
Seals entangled and
whales entangled.

00:03:09.460 --> 00:03:11.645
So that's the reality.

00:03:11.645 --> 00:03:15.340
But it also impacts
us through something

00:03:15.340 --> 00:03:16.600
called bio-accumulation.

00:03:16.600 --> 00:03:20.470
And not a lot is known about
the toxicity for humans.

00:03:20.470 --> 00:03:24.620
The biggest concern is
that with micro-plastics,

00:03:24.620 --> 00:03:27.670
as the plastics break down,
they turn into micro-plastics.

00:03:27.670 --> 00:03:31.390
Those micro-plastics
act as magnets

00:03:31.390 --> 00:03:35.140
to attract pollutants--
persistent organic pollutants

00:03:35.140 --> 00:03:36.610
in the water.

00:03:36.610 --> 00:03:39.040
And there's a lot of
interest as to what happens.

00:03:39.040 --> 00:03:45.850
Do they move from the digestive
tract into the fish's flesh?

00:03:45.850 --> 00:03:49.240
And then if we eat that, then
do we take on some of that

00:03:49.240 --> 00:03:49.970
ourselves?

00:03:49.970 --> 00:03:53.720
Does it accumulate up
through the food chains?

00:03:53.720 --> 00:03:56.586
So there's a lot of concern
around that at the moment,

00:03:56.586 --> 00:03:58.210
as well, and there's
a lot of research.

00:03:58.210 --> 00:04:01.080
It's a research priority.

00:04:01.080 --> 00:04:05.950
Just some other key facts,
which I'll just throw up there.

00:04:05.950 --> 00:04:07.840
There's a particularly
telling one.

00:04:07.840 --> 00:04:10.450
8.3 billion metric
tons of plastic

00:04:10.450 --> 00:04:13.180
have been made since forever.

00:04:13.180 --> 00:04:19.740
79% of that has gone to
landfills or the environment.

00:04:19.740 --> 00:04:20.740
By the way, I apologize.

00:04:20.740 --> 00:04:22.350
My voice is quite squeaky.

00:04:22.350 --> 00:04:25.540
If I sound like a
teenager, I'm sorry.

00:04:25.540 --> 00:04:26.800
It [INAUDIBLE] it should last.

00:04:30.290 --> 00:04:32.330
So yeah, those are just
some facts and figures

00:04:32.330 --> 00:04:33.280
up there for you.

00:04:33.280 --> 00:04:37.130
And so it is a complex problem.

00:04:37.130 --> 00:04:39.200
There's no silver
bullet to it, right?

00:04:39.200 --> 00:04:41.380
You'll hear lots of
things, like oh, we've

00:04:41.380 --> 00:04:43.334
solved it by having
worms that eat plastic.

00:04:43.334 --> 00:04:45.250
I think the most recent
one was an enzyme that

00:04:45.250 --> 00:04:46.240
dissolves plastic.

00:04:46.240 --> 00:04:48.670
But that's just the
end result. There's

00:04:48.670 --> 00:04:52.180
still a systemic
failure in a way

00:04:52.180 --> 00:04:54.894
that plastic is
leaking and used for--

00:04:54.894 --> 00:04:56.560
for example, single
use, plastics as you

00:04:56.560 --> 00:04:57.268
would have heard.

00:04:59.324 --> 00:05:01.740
So when I was tackling this
problem, I was thinking, well,

00:05:01.740 --> 00:05:02.610
where does it start?

00:05:02.610 --> 00:05:03.720
Where do I even start?

00:05:03.720 --> 00:05:09.010
It's a huge issue with
many facets to it.

00:05:09.010 --> 00:05:11.859
But then one fact
struck me the most,

00:05:11.859 --> 00:05:13.900
and this is actually from
one of-- a paper by one

00:05:13.900 --> 00:05:15.070
of our science advisors--

00:05:15.070 --> 00:05:16.930
Dr. Erik van Sebille.

00:05:16.930 --> 00:05:20.140
99% of the plastic is missing.

00:05:20.140 --> 00:05:22.882
Once it enters the ocean,
we know about where 1% is,

00:05:22.882 --> 00:05:23.965
and that's on the surface.

00:05:26.960 --> 00:05:28.650
It's basically unaccounted for.

00:05:28.650 --> 00:05:32.810
We don't know the precise
mechanisms of where it goes.

00:05:32.810 --> 00:05:36.550
It's believed that
this may just sink

00:05:36.550 --> 00:05:41.090
to the ocean floor, coastlines,
the upper ocean or the surface,

00:05:41.090 --> 00:05:42.840
or in the biota submarine life.

00:05:42.840 --> 00:05:50.360
So we sort of want to build a
3D picture of how this is setup.

00:05:53.150 --> 00:05:56.660
And that is important
because it helps us resolve

00:05:56.660 --> 00:05:58.880
the impacts that plastics make.

00:05:58.880 --> 00:06:03.360
So this is a quote
from a paper in 2014.

00:06:03.360 --> 00:06:06.570
Knowing where it goes, where it
ends up, where it concentrates

00:06:06.570 --> 00:06:09.030
is key for us to understanding
what the impacts are.

00:06:09.030 --> 00:06:10.309
How does it impact human life?

00:06:10.309 --> 00:06:11.600
How does it impact marine life?

00:06:11.600 --> 00:06:15.315
How does it impact plankton?

00:06:18.700 --> 00:06:23.070
And a lot more papers
struggle to identify--

00:06:23.070 --> 00:06:26.890
so the problem is that
there's not enough good data

00:06:26.890 --> 00:06:31.090
to sort of quantify those
concentrations in those sinks.

00:06:31.090 --> 00:06:34.310
And especially in
regards to coastlines.

00:06:34.310 --> 00:06:41.080
So because of our inability
to collect data accurately--

00:06:41.080 --> 00:06:43.600
there are estimates there where
we could be underestimating

00:06:43.600 --> 00:06:45.910
the amount of plastic by
an order of magnitude,

00:06:45.910 --> 00:06:47.080
potentially, on beaches.

00:06:47.080 --> 00:06:49.580
So the problem could be far
worse than we think it is.

00:06:49.580 --> 00:06:54.310
And this really struck home to
me, having been on the beaches

00:06:54.310 --> 00:06:58.420
in the South Pacific and
having seen it firsthand.

00:06:58.420 --> 00:07:01.900
This missing element to it
really tweaked my curiosity

00:07:01.900 --> 00:07:03.400
because at the time,
I just wondered

00:07:03.400 --> 00:07:04.608
where it could all come from.

00:07:04.608 --> 00:07:08.350
I mean, you'd find things like
flip flops and toothbrushes

00:07:08.350 --> 00:07:10.480
and all sorts of
things on beaches--

00:07:10.480 --> 00:07:13.210
even the bow of a ship, which
had washed up somewhere.

00:07:13.210 --> 00:07:16.750
So it's really
incredible what you find.

00:07:16.750 --> 00:07:23.120
So that led me to found the
Plastic Tide, where we're

00:07:23.120 --> 00:07:28.242
trying to identify where those
plastics come from-- where they

00:07:28.242 --> 00:07:29.450
accumulate, where do they go?

00:07:29.450 --> 00:07:30.283
What are the fluxes?

00:07:32.720 --> 00:07:36.260
So our vision is striving
for a plastic-free ocean

00:07:36.260 --> 00:07:38.030
for humanity.

00:07:38.030 --> 00:07:42.490
So by understanding
where that plastic is,

00:07:42.490 --> 00:07:43.910
it can lead to our mission.

00:07:43.910 --> 00:07:47.240
So it's to reveal how
our ocean is under siege

00:07:47.240 --> 00:07:51.020
and to use that knowledge
to better inform

00:07:51.020 --> 00:07:54.740
cleanup operations, to better
inform the damage limitation--

00:07:54.740 --> 00:07:55.570
impact limitation.

00:07:55.570 --> 00:07:58.220
And we'll go on to a bit
more about that later

00:07:58.220 --> 00:08:00.170
and the preventative efforts.

00:08:00.170 --> 00:08:02.420
And so who are we?

00:08:02.420 --> 00:08:04.530
As we can see, so
this is our team.

00:08:04.530 --> 00:08:06.350
We've got a team of trustees.

00:08:06.350 --> 00:08:08.350
Ellie and Dirk are here with us.

00:08:08.350 --> 00:08:09.060
No, sorry.

00:08:09.060 --> 00:08:10.680
Ellie's here with us.

00:08:10.680 --> 00:08:15.050
Stefan, of course, and Dr.
Arturo Castillo is here.

00:08:15.050 --> 00:08:17.792
But we've also got Dr.
Kayleigh Wyles, who's

00:08:17.792 --> 00:08:20.000
been doing some research
with us on the environmental

00:08:20.000 --> 00:08:22.749
psychological
impacts of beaches,

00:08:22.749 --> 00:08:25.040
as well as Erik, who's really
interested in those ocean

00:08:25.040 --> 00:08:26.110
circulation aspects.

00:08:29.970 --> 00:08:31.570
So how are we doing this?

00:08:31.570 --> 00:08:34.049
How do we detect the plastics?

00:08:34.049 --> 00:08:38.960
How do we find out where
that 99% is missing?

00:08:38.960 --> 00:08:41.600
Essentially, it's
turning what this

00:08:41.600 --> 00:08:45.440
is-- so this is Janie, who
was out with me and Ellie

00:08:45.440 --> 00:08:49.520
on Calgary beach on the
Isle of Mull, manually

00:08:49.520 --> 00:08:51.650
cataloging plastics
that I collected.

00:08:51.650 --> 00:08:52.820
Very time consuming.

00:08:52.820 --> 00:08:54.800
Takes a lot of time.

00:08:54.800 --> 00:08:57.200
No one wants to do it who's
cleaning beaches because they

00:08:57.200 --> 00:08:58.340
just want to clean the beach.

00:08:58.340 --> 00:08:59.840
They don't want to
have to sit there

00:08:59.840 --> 00:09:02.660
for hours figuring how it is.

00:09:02.660 --> 00:09:04.890
And as a result, we found--

00:09:04.890 --> 00:09:07.280
Ellie and I found that
people in Cornwall

00:09:07.280 --> 00:09:10.880
would classify what we thought
was the same plastic completely

00:09:10.880 --> 00:09:13.390
differently to someone
up in Scotland, even

00:09:13.390 --> 00:09:15.140
though these people
are both professionals

00:09:15.140 --> 00:09:16.910
and they both know
what they're doing.

00:09:16.910 --> 00:09:20.510
So there's a real problem in
getting that clear picture

00:09:20.510 --> 00:09:22.340
of the concentrations
of plastic, which

00:09:22.340 --> 00:09:26.810
will help us understand the
fluxes and the dynamics,

00:09:26.810 --> 00:09:31.492
which can then inform
campaigns and inform policies

00:09:31.492 --> 00:09:32.450
and that sort of stuff.

00:09:32.450 --> 00:09:35.370
Again, we'll talk about
more of that in a second.

00:09:35.370 --> 00:09:37.960
So we set out--

00:09:37.960 --> 00:09:40.970
and yes, so replacing
that with drone surveys.

00:09:40.970 --> 00:09:46.640
And so we set out to create
a vision from the skies,

00:09:46.640 --> 00:09:49.460
basically, where,
as you can see here,

00:09:49.460 --> 00:09:52.160
Ellie is collecting
and surveying beaches--

00:09:52.160 --> 00:09:55.210
Rhossili in Wales-- for
plastics and litter.

00:09:55.210 --> 00:09:58.582
That gets uploaded to a platform
called Zooniverse, which

00:09:58.582 --> 00:10:00.290
is, as I said, in
Science Universe, which

00:10:00.290 --> 00:10:02.180
you can log onto right now.

00:10:02.180 --> 00:10:04.460
And you tag any plastics
that you see in that image.

00:10:04.460 --> 00:10:07.250
I just uploaded a fresh
batch from some US beaches

00:10:07.250 --> 00:10:08.960
last night.

00:10:08.960 --> 00:10:10.730
So it's nice and
steaming hot for you.

00:10:10.730 --> 00:10:13.790
And then we apply machine
learning, which Stefan

00:10:13.790 --> 00:10:15.030
will talk about in a bit.

00:10:15.030 --> 00:10:17.180
And then from that, we
can identify plastics.

00:10:17.180 --> 00:10:20.090
And this is the results
from our sort of prototype.

00:10:20.090 --> 00:10:22.810
But eventually, we
want to sort of cut out

00:10:22.810 --> 00:10:24.560
the machine learning
and the training bit,

00:10:24.560 --> 00:10:27.860
and go straight to the automatic
and autonomous identification.

00:10:27.860 --> 00:10:29.570
And that's the sort
of end goal, is

00:10:29.570 --> 00:10:32.330
to have this algorithm
that we can then

00:10:32.330 --> 00:10:38.810
deploy using drone platforms
and scale up that monitoring

00:10:38.810 --> 00:10:40.010
and detection effort.

00:10:40.010 --> 00:10:43.962
AUDIENCE: Sorry, how did you
say this platform is called?

00:10:43.962 --> 00:10:44.920
PETER KOHLER: This one?

00:10:44.920 --> 00:10:46.190
AUDIENCE: Zooniverse?

00:10:46.190 --> 00:10:47.060
PETER KOHLER: Yeah,
this is Zooniverse.

00:10:47.060 --> 00:10:47.650
Yeah.

00:10:47.650 --> 00:10:48.830
I'll send some links.

00:10:48.830 --> 00:10:50.810
There's some links
at the end, and I'll

00:10:50.810 --> 00:10:52.070
send some to Florian, as well.

00:10:54.720 --> 00:10:57.770
So these are the 33
beaches around the UK

00:10:57.770 --> 00:10:59.600
that we collected data from.

00:10:59.600 --> 00:11:02.600
Some of them were
our prototype beaches

00:11:02.600 --> 00:11:03.870
and others were the main ones.

00:11:03.870 --> 00:11:05.520
So you can see--

00:11:05.520 --> 00:11:07.040
so we go to the
beach, scan them,

00:11:07.040 --> 00:11:08.870
and then we did a
clean afterwards.

00:11:08.870 --> 00:11:11.914
Every scan we do, we
follow with a clean.

00:11:11.914 --> 00:11:14.330
That journey led to us finding
some of the strange things.

00:11:14.330 --> 00:11:17.000
So the child wasn't the strange
thing to find on the beach,

00:11:17.000 --> 00:11:18.070
by the way.

00:11:18.070 --> 00:11:20.590
The little Lego cutlass,
which he found here,

00:11:20.590 --> 00:11:22.340
was-- and that has a story.

00:11:22.340 --> 00:11:24.980
So that was a very rare
piece item, which--

00:11:24.980 --> 00:11:27.890
something like 5
million, ironically

00:11:27.890 --> 00:11:32.000
enough, marine themed Lego
pieces fell into the Atlantic

00:11:32.000 --> 00:11:35.480
just off the coast of
Cornwall 20 years ago,

00:11:35.480 --> 00:11:39.150
and they're still showing up all
over the southwest of England

00:11:39.150 --> 00:11:42.120
and as far as the Gulf of
Mexico and even Melbourne,

00:11:42.120 --> 00:11:43.580
in Australia.

00:11:43.580 --> 00:11:45.480
So if you do go to
the beach holiday,

00:11:45.480 --> 00:11:48.110
keep a lookout for these
because they are collectible.

00:11:48.110 --> 00:11:51.140
We gave it to Josh
here because Ellie

00:11:51.140 --> 00:11:53.720
and I wanted him to be a sort
of future ocean guardian.

00:11:53.720 --> 00:11:56.000
And we're happy to
say that Josh is

00:11:56.000 --> 00:11:58.100
extremely enthusiastic
about cleaning beaches.

00:11:58.100 --> 00:12:00.832
So one day, he might be coming
here and doing a presentation

00:12:00.832 --> 00:12:01.790
to you guys, hopefully.

00:12:01.790 --> 00:12:04.970
But we also found a
solar powered mushroom.

00:12:04.970 --> 00:12:07.640
Not quite sure why.

00:12:07.640 --> 00:12:11.430
And we found a toilet
seat, which was great.

00:12:11.430 --> 00:12:13.520
But we also found
the bad and the ugly.

00:12:13.520 --> 00:12:18.856
So this is a Russian
mouthwash from Lever Brothers.

00:12:18.856 --> 00:12:20.300
A bit of brand naming there.

00:12:20.300 --> 00:12:22.370
Apologies.

00:12:22.370 --> 00:12:26.030
We found that in Norfolk.

00:12:26.030 --> 00:12:28.820
Phosphoric acid containers--
four of them on the beach,

00:12:28.820 --> 00:12:30.590
just sitting there.

00:12:30.590 --> 00:12:34.019
And a medical
catheter in Scotland.

00:12:34.019 --> 00:12:35.060
And that's just a sample.

00:12:35.060 --> 00:12:36.720
And then a syringe
on the far right.

00:12:36.720 --> 00:12:39.380
And that's just a sample
of what you'd find.

00:12:39.380 --> 00:12:40.470
That leads to this.

00:12:40.470 --> 00:12:43.250
So this is an example
of a scanned image.

00:12:43.250 --> 00:12:45.177
This is cut up and
Stefan will probably

00:12:45.177 --> 00:12:46.260
talk about it in a second.

00:12:46.260 --> 00:12:48.620
This is cut up
into smaller tiles

00:12:48.620 --> 00:12:50.090
and then uploaded
on to Zooniverse,

00:12:50.090 --> 00:12:53.680
where you can then tag it.

00:12:53.680 --> 00:12:55.290
This is an example of tagging.

00:12:55.290 --> 00:12:58.900
So you draw a little box, select
which from the dropdown list,

00:12:58.900 --> 00:13:02.420
press OK, and
that's one tag done.

00:13:02.420 --> 00:13:05.480
And without further ado,
I hand it over to Stefan

00:13:05.480 --> 00:13:08.065
now, who's our science advisor
and lecturer in robotics

00:13:08.065 --> 00:13:09.440
and computer vision.

00:13:09.440 --> 00:13:10.335
Thank you.

00:13:10.335 --> 00:13:12.315
[APPLAUSE]

00:13:13.800 --> 00:13:15.790
STEFAN LEUTENEGGER: Thank
you very much, Pete.

00:13:15.790 --> 00:13:16.350
OK.

00:13:16.350 --> 00:13:20.010
So I decided to give a bit of
a general perspective first

00:13:20.010 --> 00:13:22.800
on what we're actually
doing at Imperial College,

00:13:22.800 --> 00:13:25.740
and how this all feeds
into efforts, in relation

00:13:25.740 --> 00:13:27.180
to the Plastic Tide.

00:13:27.180 --> 00:13:30.930
So my interest, and
that is collaborating

00:13:30.930 --> 00:13:34.680
with a lot of researchers,
especially professor Andrew

00:13:34.680 --> 00:13:39.780
Davison at Imperial College,
is to work with mobile robots.

00:13:39.780 --> 00:13:43.716
A lot of things can be
classified as mobile robots.

00:13:43.716 --> 00:13:45.090
We work on the
kind of technology

00:13:45.090 --> 00:13:47.430
behind mobile robots
that can be applied

00:13:47.430 --> 00:13:50.520
to all kinds of scenarios.

00:13:50.520 --> 00:13:52.710
Talking about
domestic robotics, we

00:13:52.710 --> 00:13:56.370
have some funding from
Dyson, the vacuum cleaner

00:13:56.370 --> 00:14:02.760
company, for instance Drones
is a big interest of mine,

00:14:02.760 --> 00:14:06.870
but obviously, also,
in autonomous driving--

00:14:06.870 --> 00:14:09.350
in principle, this is
an autonomous robot

00:14:09.350 --> 00:14:14.470
that needs very much similar
technologies for autonomous

00:14:14.470 --> 00:14:15.450
operation.

00:14:15.450 --> 00:14:18.330
We're also very interested
in advanced manipulation,

00:14:18.330 --> 00:14:20.100
and things like
environmental monitoring

00:14:20.100 --> 00:14:24.640
is one of these
applications, as well.

00:14:24.640 --> 00:14:29.400
So if you want to deploy a robot
in a fully autonomous way, then

00:14:29.400 --> 00:14:34.060
kind of traditionally, you have
to solve a couple of problems.

00:14:34.060 --> 00:14:36.060
And a typical real
time control loop

00:14:36.060 --> 00:14:39.870
that would be running on a
robot looks a bit like that.

00:14:39.870 --> 00:14:43.260
You have a kind of
perception module here

00:14:43.260 --> 00:14:47.040
that senses the outer
world, and then you

00:14:47.040 --> 00:14:48.930
interpret all of this data--

00:14:48.930 --> 00:14:52.290
maybe also some internal fencing
to try and answer questions

00:14:52.290 --> 00:14:53.650
like, where am I?

00:14:53.650 --> 00:14:56.700
What does the world
around me look like?

00:14:56.700 --> 00:14:58.890
And with this basis,
you can feed that

00:14:58.890 --> 00:15:01.950
into some kind of higher
level intelligence, cognition,

00:15:01.950 --> 00:15:05.610
planning of actual motion, kind
of addressing the questions

00:15:05.610 --> 00:15:09.450
about what should the robot do
and where should the robot go?

00:15:09.450 --> 00:15:12.720
And then finally, you'll have
to come up with actual signals

00:15:12.720 --> 00:15:15.600
that you sent to the motors
to make the robot move

00:15:15.600 --> 00:15:18.830
and to actually achieve
what was planned,

00:15:18.830 --> 00:15:21.810
such that it will
then change its state

00:15:21.810 --> 00:15:23.420
and the whole thing
repeats, right?

00:15:26.180 --> 00:15:28.890
And so this can be really quite
difficult to do because we

00:15:28.890 --> 00:15:31.990
have to do it in real time.

00:15:31.990 --> 00:15:34.650
This can potentially run
something like 20, 30 times

00:15:34.650 --> 00:15:35.610
a second.

00:15:35.610 --> 00:15:38.382
We have to process the data
and everything on board.

00:15:38.382 --> 00:15:40.590
We wouldn't want to rely--
for these critical things,

00:15:40.590 --> 00:15:43.950
you wouldn't want to rely on
sending something to a server

00:15:43.950 --> 00:15:45.150
and waiting for a response.

00:15:45.150 --> 00:15:47.550
And that my fail.

00:15:47.550 --> 00:15:49.980
So we have to have
efficient algorithms.

00:15:49.980 --> 00:15:51.287
They have to be also robust.

00:15:51.287 --> 00:15:53.370
They have to be also
accurate enough, such that we

00:15:53.370 --> 00:15:56.160
can achieve a certain task.

00:15:56.160 --> 00:16:00.180
And I would say the kind
of specialty of our labs

00:16:00.180 --> 00:16:04.320
is somewhat on this
side of things.

00:16:04.320 --> 00:16:06.480
Where the whole thing begins--

00:16:06.480 --> 00:16:11.310
the cycle begin-- its all
around simultaneously localizing

00:16:11.310 --> 00:16:15.680
a robot and understanding
mapping the world.

00:16:15.680 --> 00:16:19.660
So this is a bit of a chicken
and egg problem, and just a bit

00:16:19.660 --> 00:16:24.340
of a summary of how we usually
tackle that is given here.

00:16:24.340 --> 00:16:28.290
So there's one piece of
research, which is all about--

00:16:28.290 --> 00:16:30.660
it's mostly centered
around accurately

00:16:30.660 --> 00:16:33.000
determining position
and orientation

00:16:33.000 --> 00:16:35.590
of the mobile robot.

00:16:35.590 --> 00:16:36.150
OK.

00:16:36.150 --> 00:16:40.110
So you use several sensors.

00:16:40.110 --> 00:16:44.100
We definitely rely heavily
on computer vision here,

00:16:44.100 --> 00:16:47.890
but we might combine it with
inertial sensing, for instance.

00:16:47.890 --> 00:16:52.290
We build kind of a sparse map
of just a couple of landmarks

00:16:52.290 --> 00:16:54.000
in the 3D scene, and
at the same time,

00:16:54.000 --> 00:16:57.280
try to find out where the
robot here represented

00:16:57.280 --> 00:16:59.850
with this kind of
coordinate frame--

00:16:59.850 --> 00:17:04.140
where it is located in
a kind of global frame.

00:17:04.140 --> 00:17:05.420
Of course you might have GPS.

00:17:05.420 --> 00:17:08.099
You might have
certain aides that

00:17:08.099 --> 00:17:10.280
help a lot in this problem.

00:17:10.280 --> 00:17:13.230
But in a general case-- for
instance in the robotics,

00:17:13.230 --> 00:17:14.550
you wouldn't have that.

00:17:14.550 --> 00:17:17.460
In the context of the Plastic
Tide, we do leverage GPS.

00:17:17.460 --> 00:17:19.170
Of course I would
always argue when

00:17:19.170 --> 00:17:23.250
you have these kind of things
available, then you should.

00:17:23.250 --> 00:17:25.680
So that's kind of
the first level.

00:17:25.680 --> 00:17:28.150
You can already do
quite a few things,

00:17:28.150 --> 00:17:32.820
but when it comes to, for
instance, avoiding terrain, not

00:17:32.820 --> 00:17:36.450
crashing into something,
doing safe kind of autonomous

00:17:36.450 --> 00:17:38.070
navigation in
unknown environments,

00:17:38.070 --> 00:17:40.890
then you need some form of
a [INAUDIBLE] kind of a map.

00:17:40.890 --> 00:17:43.630
You need a geometric
understanding of the world.

00:17:43.630 --> 00:17:46.150
So this is the kind of next
level that we are addressing.

00:17:46.150 --> 00:17:49.260
I will be just showing a
little bit of examples here.

00:17:49.260 --> 00:17:53.250
And then I think
that the third level,

00:17:53.250 --> 00:17:56.220
with enabling somewhat
higher level understanding,

00:17:56.220 --> 00:17:57.600
is a semantic one.

00:17:57.600 --> 00:18:00.600
You don't want to only
understand where stuff is.

00:18:00.600 --> 00:18:02.820
You want to understand
what stuff is.

00:18:02.820 --> 00:18:06.270
And that very much now ties
in with the Plastic Tide.

00:18:06.270 --> 00:18:09.450
We want to have a mapping
system that identifies

00:18:09.450 --> 00:18:11.220
the semantics behind things.

00:18:11.220 --> 00:18:15.420
This is an indoor example, but
it employs very much similar

00:18:15.420 --> 00:18:16.920
techniques as what
I'll be showing

00:18:16.920 --> 00:18:18.790
applied to the Plastic Tide.

00:18:18.790 --> 00:18:21.120
So we leverage
deep learning here

00:18:21.120 --> 00:18:25.350
that enables us to
give us proposals

00:18:25.350 --> 00:18:29.225
for if something is bad or
if something is the floor.

00:18:29.225 --> 00:18:30.600
And you can probably
see how this

00:18:30.600 --> 00:18:32.460
could be extremely
valuable for all kinds

00:18:32.460 --> 00:18:35.070
of robotic applications, where
now, the robot can actually

00:18:35.070 --> 00:18:39.630
figure out what to do in
relation to these objects,

00:18:39.630 --> 00:18:42.330
where we can have
human interaction that

00:18:42.330 --> 00:18:45.030
relates to these objects
that are identified.

00:18:49.160 --> 00:18:49.820
OK.

00:18:49.820 --> 00:18:53.510
So I don't know how
technical you all

00:18:53.510 --> 00:18:56.810
are, but I assume some of
you are exposed to machine

00:18:56.810 --> 00:18:59.850
learning-- deep learning.

00:18:59.850 --> 00:19:04.330
So let me just talk
about this a little bit.

00:19:04.330 --> 00:19:06.650
I think there is
a bit of a split

00:19:06.650 --> 00:19:11.030
in the community between
using models, using kind

00:19:11.030 --> 00:19:12.620
of more engineering
based approaches,

00:19:12.620 --> 00:19:17.420
versus deep learning--
everything using data driven

00:19:17.420 --> 00:19:20.240
approaches and kind of treat
that as an end to end black box

00:19:20.240 --> 00:19:22.590
problem that you want to solve.

00:19:22.590 --> 00:19:26.390
So I often find myself a little
bit in a defensive position

00:19:26.390 --> 00:19:28.040
for models.

00:19:28.040 --> 00:19:30.260
So let me start with that.

00:19:30.260 --> 00:19:32.840
I think models are still
very useful, even these days.

00:19:32.840 --> 00:19:34.460
They're very compact.

00:19:34.460 --> 00:19:36.110
With very few
parameters, you can

00:19:36.110 --> 00:19:38.210
explain an awful lot of things.

00:19:38.210 --> 00:19:41.130
They generalize, also, well
beyond the training set.

00:19:41.130 --> 00:19:42.950
So just to give
an example here, I

00:19:42.950 --> 00:19:45.810
would argue that
discovering physics--

00:19:45.810 --> 00:19:46.700
the law of physics--

00:19:46.700 --> 00:19:49.240
kind of very low
parametric models

00:19:49.240 --> 00:19:51.880
have allowed us to do things
that are definitely not found

00:19:51.880 --> 00:19:55.460
in any training data
set before that.

00:19:58.820 --> 00:20:05.900
And kind of seemingly applied to
the spatial perception problem,

00:20:05.900 --> 00:20:10.130
the kind of traditional
models-- geometric models,

00:20:10.130 --> 00:20:11.630
probabilistic models--

00:20:11.630 --> 00:20:14.030
they have really been the
success story for a very long

00:20:14.030 --> 00:20:15.950
time to enable robotics.

00:20:15.950 --> 00:20:19.180
But on the other hand, use
of learning-- deep learning--

00:20:19.180 --> 00:20:23.690
is absolutely really amazing.

00:20:23.690 --> 00:20:26.720
And this is fairly
new how powerful

00:20:26.720 --> 00:20:29.620
we see these methods can be.

00:20:29.620 --> 00:20:31.700
I would argue that
it can be used

00:20:31.700 --> 00:20:36.920
in a very much complementary
way, learning relationships

00:20:36.920 --> 00:20:39.110
that are simply too
complex to model.

00:20:39.110 --> 00:20:41.740
You need to extract
it from data.

00:20:41.740 --> 00:20:45.590
Especially kind of doing things
like semantic understanding--

00:20:45.590 --> 00:20:48.830
that's absolutely the way to go,
and we should combine the two

00:20:48.830 --> 00:20:49.760
things together.

00:20:49.760 --> 00:20:52.670
And this is very much the
same spirit of what we're

00:20:52.670 --> 00:20:55.670
doing with the Plastic Tide
is to combine these things

00:20:55.670 --> 00:20:58.250
together, to combine
mapping and semantic

00:20:58.250 --> 00:21:00.080
understanding together.

00:21:00.080 --> 00:21:03.290
But just to show what we can
do using only the kind of more

00:21:03.290 --> 00:21:08.220
traditional, but still kind of
modern model based approach,

00:21:08.220 --> 00:21:10.850
this is a fully autonomous
drone that we have put together.

00:21:10.850 --> 00:21:12.990
I kind of chose the
whole cycle that I've

00:21:12.990 --> 00:21:14.900
shown in the very beginning--

00:21:14.900 --> 00:21:17.870
everything operating here.

00:21:17.870 --> 00:21:22.610
This is a fully autonomous drone
without the need for any GPS

00:21:22.610 --> 00:21:25.150
or any other external
kind of sensing.

00:21:25.150 --> 00:21:31.610
It has a color and
depth camera, including

00:21:31.610 --> 00:21:33.560
inertial sensing here.

00:21:33.560 --> 00:21:37.490
And then we have a kind of
Intel Nook computer here.

00:21:37.490 --> 00:21:40.100
It's relatively standard,
so this is actually

00:21:40.100 --> 00:21:43.710
assembled from quite
standard components without--

00:21:43.710 --> 00:21:45.740
it's not a very expensive drone.

00:21:45.740 --> 00:21:47.610
Downward looking
camera, as well.

00:21:47.610 --> 00:21:49.220
So what we are
doing here is we're

00:21:49.220 --> 00:21:56.420
trying to land on
a moving platform,

00:21:56.420 --> 00:21:59.900
and so this is deployed in
real-- this is completely

00:21:59.900 --> 00:22:01.910
without any human interaction.

00:22:01.910 --> 00:22:04.412
It's just a one button
press for the takeoff,

00:22:04.412 --> 00:22:05.870
and then someone
has to run around.

00:22:05.870 --> 00:22:08.850
That used to be me, normally.

00:22:08.850 --> 00:22:10.640
So it flies to that
hovering point,

00:22:10.640 --> 00:22:15.650
and then it automatically
detects and tracks the moving

00:22:15.650 --> 00:22:18.150
target, and it will
land on it safely.

00:22:18.150 --> 00:22:21.080
And the tricky bit is it
doesn't have to just work once.

00:22:21.080 --> 00:22:23.915
It has to work under different
environmental conditions,

00:22:23.915 --> 00:22:26.330
even on a nice, sunny day.

00:22:26.330 --> 00:22:27.680
Wind and so on.

00:22:27.680 --> 00:22:30.224
So don't just do it once
for a paper-- you submit it

00:22:30.224 --> 00:22:30.890
and you're done.

00:22:30.890 --> 00:22:32.300
This has to work
really robustly.

00:22:32.300 --> 00:22:33.800
I guess that's the
main challenge here.

00:22:33.800 --> 00:22:34.591
But it can be done.

00:22:34.591 --> 00:22:36.665
So there's absolutely
no learning involved.

00:22:38.746 --> 00:22:40.120
But at the same
time, I guess, we

00:22:40.120 --> 00:22:43.010
have to understand the limits.

00:22:43.010 --> 00:22:46.850
So let me just
bring up this slide.

00:22:46.850 --> 00:22:49.260
I won't go into too
much technical details,

00:22:49.260 --> 00:22:53.390
but effectively, the kind
of traditional approach

00:22:53.390 --> 00:22:55.520
to simultaneous
localization and mapping--

00:22:55.520 --> 00:23:00.110
SLAM-- consists of very
much building these models.

00:23:00.110 --> 00:23:03.250
So what we do is we model
out the measurements

00:23:03.250 --> 00:23:06.540
as samples from
probability distribution,

00:23:06.540 --> 00:23:09.680
and then we're trying to
find the values that best

00:23:09.680 --> 00:23:12.050
explain all the measurements.

00:23:12.050 --> 00:23:14.300
This is instantiations
of a maximum likelihood

00:23:14.300 --> 00:23:16.960
or maximum a posterior
problem, usually.

00:23:16.960 --> 00:23:19.680
And we have to take a couple
of engineering decisions.

00:23:19.680 --> 00:23:22.810
We have to decide how we
want to represent the robot,

00:23:22.810 --> 00:23:26.190
where it is positioned,
what orientation, and so on,

00:23:26.190 --> 00:23:29.420
as well as how we represent
the environment-- the map.

00:23:29.420 --> 00:23:32.240
Then we have to model
these distributions,

00:23:32.240 --> 00:23:34.940
and then here is the
most engineering, really.

00:23:34.940 --> 00:23:37.340
We have to choose a lot
of approximations-- ways

00:23:37.340 --> 00:23:39.260
of how to solve
this optimization

00:23:39.260 --> 00:23:42.200
problem, for instance,
or a filtering problem.

00:23:42.200 --> 00:23:44.090
We have to find, also,
some way to initialize

00:23:44.090 --> 00:23:48.560
to bootstrap to get started.

00:23:48.560 --> 00:23:51.570
And so that's a traditional
way of doing it.

00:23:51.570 --> 00:23:54.380
And now we can
bring in learning.

00:23:54.380 --> 00:23:56.005
We can bring in
learning, for instance,

00:23:56.005 --> 00:23:59.000
to have the semantic map
layer that I mentioned before.

00:24:02.400 --> 00:24:04.490
We also can find
representations that

00:24:04.490 --> 00:24:07.530
are sort of aware of
the semantics behind it.

00:24:07.530 --> 00:24:11.520
It's very wasteful
to try and represent

00:24:11.520 --> 00:24:15.020
a map with just millions
and billions of points.

00:24:15.020 --> 00:24:16.640
For instance, how
we can try and find

00:24:16.640 --> 00:24:18.800
more compact representations.

00:24:18.800 --> 00:24:20.220
We can also learn geometry.

00:24:20.220 --> 00:24:24.830
So this is another
very interesting field

00:24:24.830 --> 00:24:26.900
at the moment where
deep learning can

00:24:26.900 --> 00:24:31.880
be leveraged to actually
understand geometric priors

00:24:31.880 --> 00:24:33.260
from just looking at an image.

00:24:37.290 --> 00:24:39.020
OK.

00:24:39.020 --> 00:24:41.090
So just to give you
an example-- so this

00:24:41.090 --> 00:24:46.520
is how we would, for instance,
represent the state of a drone.

00:24:46.520 --> 00:24:49.880
So this could be a drone as
it is being flown autonomously

00:24:49.880 --> 00:24:51.992
to inspect a beach.

00:24:51.992 --> 00:24:53.450
At the moment, in
the Plastic Tide,

00:24:53.450 --> 00:24:57.200
we were still using
manually controlled drones,

00:24:57.200 --> 00:25:01.460
I should say, but this is now
our fully autonomous drone

00:25:01.460 --> 00:25:02.840
that we have at the lab.

00:25:02.840 --> 00:25:05.210
So we would usually have
a kind of a combination

00:25:05.210 --> 00:25:08.170
of this is position and
orientation of the drone--

00:25:08.170 --> 00:25:10.100
a combination of
kind of physical

00:25:10.100 --> 00:25:11.870
states that we
need to control it.

00:25:11.870 --> 00:25:13.640
Also, the velocity here.

00:25:13.640 --> 00:25:16.400
But then things like
online calibration

00:25:16.400 --> 00:25:18.050
to calibrate the
cameras, with respect

00:25:18.050 --> 00:25:20.120
to each other, even
in the real time

00:25:20.120 --> 00:25:24.170
operation, as well as some
sensor intrinsic kind of biases

00:25:24.170 --> 00:25:25.640
that we need to estimate.

00:25:25.640 --> 00:25:28.190
So you can see this kind
of just shows a little bit

00:25:28.190 --> 00:25:30.200
this kind of first choice
that we have to make,

00:25:30.200 --> 00:25:33.284
in terms of how to
represent the state.

00:25:33.284 --> 00:25:34.700
And then here's
the second choice,

00:25:34.700 --> 00:25:38.510
and I think this is
also super critical,

00:25:38.510 --> 00:25:42.230
and it really depends on the
application you want to target.

00:25:42.230 --> 00:25:45.230
On how to represent
the environment,

00:25:45.230 --> 00:25:49.580
traditionally, things like
point clouds were used.

00:25:49.580 --> 00:25:50.669
We also see fully--

00:25:50.669 --> 00:25:51.210
[CHIME SOUND]

00:25:51.210 --> 00:25:52.530
Oh, sorry about that.

00:25:52.530 --> 00:25:57.110
We see fully
volumetric approaches.

00:25:57.110 --> 00:25:57.739
We see meshes.

00:25:57.739 --> 00:25:59.780
They all have their
advantages and disadvantages,

00:25:59.780 --> 00:26:02.480
so I'll show a couple
of examples about that.

00:26:05.370 --> 00:26:08.960
And so in the most
traditional kind of way,

00:26:08.960 --> 00:26:10.610
we might just
represent the world

00:26:10.610 --> 00:26:14.220
as a couple of sparse 3D points.

00:26:14.220 --> 00:26:18.050
So when you now try to do the
mapping process or the SLAM--

00:26:18.050 --> 00:26:21.110
the simultaneous localization
and mapping process--

00:26:21.110 --> 00:26:23.840
you have to first identify
corresponding points

00:26:23.840 --> 00:26:27.330
from one image to the next,
or just between images.

00:26:27.330 --> 00:26:29.330
So this is an example of
how this is being done.

00:26:29.330 --> 00:26:31.010
You have to detect
points and then

00:26:31.010 --> 00:26:33.220
you have to find a
way to match them

00:26:33.220 --> 00:26:35.556
with some kind of
local descriptors.

00:26:35.556 --> 00:26:36.680
So this is the vision side.

00:26:36.680 --> 00:26:38.690
So the vision side of
things gives you some kind

00:26:38.690 --> 00:26:40.390
of spatial information, right?

00:26:40.390 --> 00:26:42.140
Gives you, ultimately,
information

00:26:42.140 --> 00:26:45.980
about how the camera
has moved as a relative

00:26:45.980 --> 00:26:48.716
pose-- how the
camera has changed.

00:26:48.716 --> 00:26:50.090
And now, we can
also combine that

00:26:50.090 --> 00:26:53.990
with complementary sensing,
like inertial ones.

00:26:53.990 --> 00:26:56.310
And this really is the
backbone of any kind

00:26:56.310 --> 00:26:58.890
of autonomous drone
operation these days,

00:26:58.890 --> 00:27:00.390
is to combine these two.

00:27:00.390 --> 00:27:05.160
So here is just some
work that does that.

00:27:05.160 --> 00:27:10.350
You can see here
how the camera is--

00:27:10.350 --> 00:27:12.030
how images are matched.

00:27:12.030 --> 00:27:14.970
How key points are matched
with respect to life-- image

00:27:14.970 --> 00:27:18.430
here with respect to a
key-frame in the past.

00:27:18.430 --> 00:27:22.830
And on the right hand side, you
can see how now, this estimator

00:27:22.830 --> 00:27:27.630
estimates where these 3D points
or 3D points are in the world,

00:27:27.630 --> 00:27:31.480
as well as where the drone is
located as it's flying around,

00:27:31.480 --> 00:27:32.904
including the orientation.

00:27:32.904 --> 00:27:34.570
And again, this has
to run in real time.

00:27:34.570 --> 00:27:36.736
It has to run in real time
on relatively constrained

00:27:36.736 --> 00:27:38.700
platforms.

00:27:38.700 --> 00:27:40.770
We're still talking
about a kind of i7 here,

00:27:40.770 --> 00:27:42.630
so it's not as bad
as it could be.

00:27:46.440 --> 00:27:48.690
And then it has to be accurate.

00:27:48.690 --> 00:27:51.960
It has to be robust, also, when
you have aggressive motion--

00:27:51.960 --> 00:27:53.280
motion blur, potentially.

00:27:57.270 --> 00:28:01.500
And low lighting, difficult
lighting conditions here.

00:28:05.124 --> 00:28:06.030
OK.

00:28:06.030 --> 00:28:08.177
And then at some point,
the drone is coming back,

00:28:08.177 --> 00:28:10.260
and you will see that it's
pretty much coming back

00:28:10.260 --> 00:28:13.890
to the same position in the end.

00:28:13.890 --> 00:28:16.868
I'll skip the rest here.

00:28:16.868 --> 00:28:21.720
But this is the kind of
missions that we can do now.

00:28:21.720 --> 00:28:24.690
If we sort of know
where it is safe to fly,

00:28:24.690 --> 00:28:26.820
we can completely autonomously
create the mission.

00:28:26.820 --> 00:28:28.860
We can send the
drone to way-points

00:28:28.860 --> 00:28:34.780
and do something
complete autonomously.

00:28:34.780 --> 00:28:35.550
OK.

00:28:35.550 --> 00:28:37.710
So that was the
kind of first layer

00:28:37.710 --> 00:28:40.770
of simultaneous
localization and mapping.

00:28:40.770 --> 00:28:43.230
Clearly, we would like
to go beyond that.

00:28:43.230 --> 00:28:45.930
We would like to enable
avoidance of collision.

00:28:45.930 --> 00:28:49.260
We would like to deploy
these robots in environments

00:28:49.260 --> 00:28:52.630
that are not as trivial.

00:28:52.630 --> 00:28:55.950
And so we've also created
some dense mapping approaches

00:28:55.950 --> 00:29:01.050
where now, this is actually
using depth cameras.

00:29:01.050 --> 00:29:04.800
So we have-- as an input, you'll
see that in a second here,

00:29:04.800 --> 00:29:07.290
the RGB image-- the live
feed, as well as the depth

00:29:07.290 --> 00:29:11.460
images from the camera, and the
camera is being moved around.

00:29:11.460 --> 00:29:15.030
And we kind of stitched together
these little snapshots of a map

00:29:15.030 --> 00:29:18.060
by simultaneously
finding out in a kind

00:29:18.060 --> 00:29:19.380
of alternate fashion here--

00:29:19.380 --> 00:29:21.990
first, we tried to find out
how the camera is moved,

00:29:21.990 --> 00:29:24.000
and then you put
the new information

00:29:24.000 --> 00:29:25.940
into a very dense map.

00:29:25.940 --> 00:29:28.290
And we can actually
also correct drift.

00:29:28.290 --> 00:29:30.180
This is something that
will always happen.

00:29:30.180 --> 00:29:31.950
Once you move it
around in a loop or so,

00:29:31.950 --> 00:29:34.369
you come back to a place
that you've seen before.

00:29:34.369 --> 00:29:35.910
You will have some
accumulated drift.

00:29:35.910 --> 00:29:39.840
You will start to remap
the same instance again,

00:29:39.840 --> 00:29:42.430
and here we can detect that
and we can make corrections.

00:29:42.430 --> 00:29:45.100
We can actually deform
the map and have

00:29:45.100 --> 00:29:48.120
a consistent map over a long
time that we put together.

00:29:50.770 --> 00:29:51.270
OK.

00:29:53.810 --> 00:29:55.700
So this is the kind
of technologies

00:29:55.700 --> 00:29:58.730
that you can use now to
have a second level that

00:29:58.730 --> 00:30:02.090
enables collision avoidance
and path planning.

00:30:02.090 --> 00:30:05.780
But let's now get to
semantics because this is also

00:30:05.780 --> 00:30:09.380
what we are leveraging
into Plastic Tide.

00:30:09.380 --> 00:30:13.700
So once you have a method
that lets you create a map

00:30:13.700 --> 00:30:15.920
and potentially
simultaneously tracking

00:30:15.920 --> 00:30:20.720
the motion of a camera,
now we can augment the map

00:30:20.720 --> 00:30:22.220
using some kind of semantics.

00:30:22.220 --> 00:30:25.100
So here, we are using exactly
this kind of process I've just

00:30:25.100 --> 00:30:26.330
shown on the slide before.

00:30:29.250 --> 00:30:30.940
OK.

00:30:30.940 --> 00:30:34.110
So here, it runs in parallel.

00:30:34.110 --> 00:30:40.040
And then we run deep learning
enabled semantic segmentation

00:30:40.040 --> 00:30:41.120
on top of that.

00:30:41.120 --> 00:30:43.910
So the principle will
just show in a second.

00:30:46.480 --> 00:30:48.750
So we use the live feed
from the camera RGB

00:30:48.750 --> 00:30:50.970
image plus depth image.

00:30:50.970 --> 00:30:55.130
We do a reconstruction--
a dense map.

00:30:55.130 --> 00:31:00.360
And now we use, in
parallel, the same inputs,

00:31:00.360 --> 00:31:03.370
feed them through a
convolutional neural network.

00:31:03.370 --> 00:31:04.870
And the convolutional
neural network

00:31:04.870 --> 00:31:07.980
was previously trained
with lots of data.

00:31:07.980 --> 00:31:09.010
That's the key here.

00:31:09.010 --> 00:31:11.475
We need lots of
data to train it,

00:31:11.475 --> 00:31:13.350
such that it can then
make these predictions.

00:31:13.350 --> 00:31:17.130
It can interpret the data and
it can find out, OK, well, this

00:31:17.130 --> 00:31:18.480
is floor.

00:31:18.480 --> 00:31:19.620
This is sofa.

00:31:19.620 --> 00:31:23.660
And it will give us these
maps as probability maps,

00:31:23.660 --> 00:31:25.230
essentially, where
we can interpret

00:31:25.230 --> 00:31:29.280
the output after the
training as probability maps.

00:31:29.280 --> 00:31:30.930
And we can fuse
this information.

00:31:30.930 --> 00:31:33.870
We can accumulate this
information into the 3D world,

00:31:33.870 --> 00:31:37.870
so we get a semantic
map in the end.

00:31:37.870 --> 00:31:40.740
So in some sense,
this is already

00:31:40.740 --> 00:31:45.180
kind of how I see how the
Plastic Tide, version 2.0 could

00:31:45.180 --> 00:31:50.400
work, where we have a very
accurate, very dense 3D

00:31:50.400 --> 00:31:52.260
representation of the world.

00:31:52.260 --> 00:31:55.470
And we have annotations
about what these things are.

00:31:55.470 --> 00:31:57.330
So here, this is an
indoor environment.

00:31:57.330 --> 00:32:01.687
It was trained with things like
floor and windows and chairs,

00:32:01.687 --> 00:32:03.270
but you could imagine
that these could

00:32:03.270 --> 00:32:04.920
be-- with the right
training data sets,

00:32:04.920 --> 00:32:07.470
these could be different
kinds of plastic pieces

00:32:07.470 --> 00:32:10.380
that we can very
accurately now localize

00:32:10.380 --> 00:32:12.445
and map in the 3D world.

00:32:12.445 --> 00:32:16.200
I'll somewhat keep
that data here.

00:32:16.200 --> 00:32:19.000
The interesting bit
is that actually,

00:32:19.000 --> 00:32:22.770
accumulating this semantic
information in the 3D world

00:32:22.770 --> 00:32:24.030
helps you--

00:32:24.030 --> 00:32:27.180
getting more accurate in
your semantic segmentation

00:32:27.180 --> 00:32:29.550
when you just project
it to the 2D image.

00:32:29.550 --> 00:32:32.450
So it was an
interesting finding.

00:32:32.450 --> 00:32:33.960
OK.

00:32:33.960 --> 00:32:37.500
So now, linking that
to the Plastic Tide.

00:32:37.500 --> 00:32:39.750
It's a very much
similar process, right?

00:32:39.750 --> 00:32:41.440
So we accumulate.

00:32:41.440 --> 00:32:45.704
We now have to get
very specific data.

00:32:45.704 --> 00:32:47.370
That's the trick about
machine learning.

00:32:47.370 --> 00:32:50.520
We need to find the environment
in which we want to deploy

00:32:50.520 --> 00:32:51.880
the system, ultimately.

00:32:51.880 --> 00:32:54.520
We need to create
training data there.

00:32:54.520 --> 00:32:56.940
And so this is--

00:32:56.940 --> 00:33:01.920
thanks to Pete and Ellie here
that went around and collected

00:33:01.920 --> 00:33:03.450
a lot of drone footage.

00:33:03.450 --> 00:33:05.610
Again, this is
manually controlled,

00:33:05.610 --> 00:33:06.990
but it really doesn't matter.

00:33:06.990 --> 00:33:08.720
It's just a matter of
creating a lot of--

00:33:08.720 --> 00:33:09.907
[CHIME SOUND]

00:33:09.907 --> 00:33:10.740
I switched this off.

00:33:10.740 --> 00:33:12.930
Somehow, it doesn't
seem to care.

00:33:12.930 --> 00:33:15.810
Sorry.

00:33:15.810 --> 00:33:18.930
So you have to create
a lot of imagery,

00:33:18.930 --> 00:33:21.260
and then it has to be tagged.

00:33:21.260 --> 00:33:22.430
We have some--

00:33:22.430 --> 00:33:25.320
Pete has all the statistics
about how many tags we have.

00:33:25.320 --> 00:33:28.400
We had to split up the
original high resolution drone

00:33:28.400 --> 00:33:33.280
images into tiles, then they
are presented to the taggers.

00:33:33.280 --> 00:33:36.450
We got a lot of ground
truth annotations,

00:33:36.450 --> 00:33:38.230
and we train our network.

00:33:38.230 --> 00:33:41.820
In our case, it is
the YOLO, version 2,

00:33:41.820 --> 00:33:44.850
simultaneous bounding box
detection and classification

00:33:44.850 --> 00:33:45.840
algorithm that we use.

00:33:45.840 --> 00:33:47.460
So we didn't--

00:33:47.460 --> 00:33:48.900
I'm not a deep learning expert.

00:33:48.900 --> 00:33:51.357
We didn't kind of try and
change the architecture

00:33:51.357 --> 00:33:53.940
of this network, but the way you
can think about it, for those

00:33:53.940 --> 00:33:56.790
who are not experts
in machine learning,

00:33:56.790 --> 00:34:02.990
is that you have this network
that effectively consists

00:34:02.990 --> 00:34:06.070
of a lot a lot of parameters--

00:34:06.070 --> 00:34:11.699
probably millions of parameters
that are then being learned.

00:34:16.530 --> 00:34:17.760
It fits the data, right?

00:34:17.760 --> 00:34:22.770
That when you input the data
here, that will be an image,

00:34:22.770 --> 00:34:26.010
such that you actually
get the kind of outputs

00:34:26.010 --> 00:34:27.659
that you give in training.

00:34:27.659 --> 00:34:31.290
So you're trying-- you're giving
it a lot of examples like this,

00:34:31.290 --> 00:34:35.699
and ultimately, it will be
able to autonomously detect

00:34:35.699 --> 00:34:37.630
these kind of plastic pieces.

00:34:37.630 --> 00:34:41.554
So here, this is a level of just
bounding boxes that we get out.

00:34:41.554 --> 00:34:44.489
The example before
showed segmentation.

00:34:44.489 --> 00:34:46.500
So that's where we
want to ultimately get

00:34:46.500 --> 00:34:49.440
to, as well, but I think this
is a very important starting

00:34:49.440 --> 00:34:51.560
point-- to just
have bounding boxes

00:34:51.560 --> 00:34:55.350
and kind of a rough idea of
where these pieces of plastics

00:34:55.350 --> 00:34:57.250
are actually located.

00:34:57.250 --> 00:35:01.330
So here's a couple of examples
of how that actually then works

00:35:01.330 --> 00:35:02.640
in practice.

00:35:02.640 --> 00:35:03.990
This is very much ongoing work.

00:35:03.990 --> 00:35:06.730
We're trying to improve
that at the moment.

00:35:06.730 --> 00:35:08.720
And so this is just
at the level of when

00:35:08.720 --> 00:35:13.320
imaging, what kind of plastics
can we detect in the image?

00:35:13.320 --> 00:35:15.840
You can see here that's now--

00:35:15.840 --> 00:35:17.610
just to emphasize
that one more time,

00:35:17.610 --> 00:35:19.330
this is now not training data.

00:35:19.330 --> 00:35:21.647
That is what the
network has learned.

00:35:21.647 --> 00:35:22.980
So this is completely automatic.

00:35:22.980 --> 00:35:24.649
You give it an image--
it will tell you

00:35:24.649 --> 00:35:26.440
where all the plastic
pieces-- and it finds

00:35:26.440 --> 00:35:29.430
some really quite surprisingly
small things, as well.

00:35:29.430 --> 00:35:31.320
But it also makes
mistakes, right?

00:35:31.320 --> 00:35:34.060
So here, for instance, you
see it has kind of double

00:35:34.060 --> 00:35:36.000
detected the same thing.

00:35:36.000 --> 00:35:37.680
Here, as well.

00:35:37.680 --> 00:35:40.410
I think here, it's
missed something.

00:35:40.410 --> 00:35:42.870
Although I can barely
see that on the screen,

00:35:42.870 --> 00:35:44.700
so it does miss certain things.

00:35:44.700 --> 00:35:48.220
They're also actually
difficult to see for people.

00:35:48.220 --> 00:35:50.680
So I'm confident that
with enough data,

00:35:50.680 --> 00:35:52.930
we can train an algorithm
that will be at least as

00:35:52.930 --> 00:35:54.410
good as people are.

00:35:54.410 --> 00:35:56.200
So that should be
really the goal, right?

00:35:56.200 --> 00:36:00.640
That we can automate this
process of then ultimately

00:36:00.640 --> 00:36:03.200
mapping these pieces, right?

00:36:03.200 --> 00:36:04.930
So this is the idea--
that we can now

00:36:04.930 --> 00:36:07.240
put the kind of
mapping infrastructure

00:36:07.240 --> 00:36:10.240
that I've shown before--
we can put that together.

00:36:10.240 --> 00:36:13.350
Assuming we have, now, the
very precise localizations

00:36:13.350 --> 00:36:15.400
for where these
images were taken,

00:36:15.400 --> 00:36:18.570
we can triangulate them
into the real world,

00:36:18.570 --> 00:36:20.770
combine that with
GPS knowledge, and we

00:36:20.770 --> 00:36:25.060
will have a very accurate map of
where there are plastic pieces.

00:36:25.060 --> 00:36:29.550
At the moment, still just
kind of bounding boxes

00:36:29.550 --> 00:36:35.260
kind of in 3D in the end, but
the goal is to go beyond that.

00:36:35.260 --> 00:36:37.660
I will skip this for a
second and I will just

00:36:37.660 --> 00:36:38.710
mention this, as well.

00:36:38.710 --> 00:36:43.240
So just talking about training
data in the case of the Plastic

00:36:43.240 --> 00:36:46.420
Tide, we made a lot of
effort to actually get

00:36:46.420 --> 00:36:48.070
this training data--

00:36:48.070 --> 00:36:50.040
real training data out there.

00:36:50.040 --> 00:36:52.150
Indoors, in the lab,
we work with, also,

00:36:52.150 --> 00:36:54.020
synthetic training data.

00:36:54.020 --> 00:36:56.980
So this is a sort
of way around it.

00:36:56.980 --> 00:36:59.140
For these machine
learning algorithms,

00:36:59.140 --> 00:37:00.490
you need a lot of training data.

00:37:00.490 --> 00:37:03.790
You need hundreds of thousands
and millions, maybe, of images.

00:37:03.790 --> 00:37:06.760
But we can get the way
to some degree, at least,

00:37:06.760 --> 00:37:08.410
with simulating, actually.

00:37:08.410 --> 00:37:09.900
So we have built
some simulators,

00:37:09.900 --> 00:37:11.620
simulating indoor
environments that

00:37:11.620 --> 00:37:13.820
gave us perfect ground truth.

00:37:13.820 --> 00:37:16.360
But of course, there's always
a question about how realistic

00:37:16.360 --> 00:37:17.705
these images are.

00:37:17.705 --> 00:37:20.230
So a bit of a messy
room here, actually.

00:37:20.230 --> 00:37:23.080
You would hope to not
necessarily see that, really.

00:37:23.080 --> 00:37:25.120
But we want to
train the algorithms

00:37:25.120 --> 00:37:29.050
to be able to deal with
any kind of situation.

00:37:29.050 --> 00:37:32.350
OK, so this is kind
of open training data

00:37:32.350 --> 00:37:33.622
sets that we have.

00:37:33.622 --> 00:37:37.250
We are also moving
somewhat beyond that

00:37:37.250 --> 00:37:40.780
with very realistic-- trying
to get more realistic training

00:37:40.780 --> 00:37:43.690
data sets with having very
professionally designed

00:37:43.690 --> 00:37:45.910
interior design
kind of elements,

00:37:45.910 --> 00:37:48.910
and then we can render
scenes like that.

00:37:48.910 --> 00:37:51.670
But you can imagine that
replicating this process

00:37:51.670 --> 00:37:53.950
is probably quite difficult
for a specific setting

00:37:53.950 --> 00:37:56.740
like outdoors and beaches,
where there's just

00:37:56.740 --> 00:37:59.930
very little understanding,
also, about what's going on.

00:37:59.930 --> 00:38:02.560
So here, we can leverage
designs that people

00:38:02.560 --> 00:38:06.080
have made in the past.

00:38:06.080 --> 00:38:08.390
And maybe a bit, also,
more interestingly

00:38:08.390 --> 00:38:09.940
in the robotic
context, if you want

00:38:09.940 --> 00:38:11.689
to have a ground robot,
what we can do now

00:38:11.689 --> 00:38:18.450
is we can render the scene from
a quite unusual perspective.

00:38:18.450 --> 00:38:21.340
And I think this is, again,
kind of in the same spirit,

00:38:21.340 --> 00:38:22.990
as I mentioned before--

00:38:22.990 --> 00:38:25.782
you have to make this specific
for the application, right?

00:38:25.782 --> 00:38:27.240
You have to have
the right training

00:38:27.240 --> 00:38:29.469
data for the right application.

00:38:29.469 --> 00:38:31.260
So if you have a ground
robot, you probably

00:38:31.260 --> 00:38:34.260
want some kind of ground
robot type footage.

00:38:34.260 --> 00:38:36.600
If you want a drone that
finds plastic pieces,

00:38:36.600 --> 00:38:42.080
you need training data from
plastic pieces on the beach.

00:38:42.080 --> 00:38:43.260
OK.

00:38:43.260 --> 00:38:47.850
So I think I'll close on that
note and hand over back to Pete

00:38:47.850 --> 00:38:50.640
to explain, a little bit,
the next steps, I believe,

00:38:50.640 --> 00:38:52.060
of the Plastic Tide.

00:38:52.060 --> 00:38:53.228
Thank you.

00:38:53.228 --> 00:38:55.224
[APPLAUSE]

00:38:57.312 --> 00:38:58.520
PETER KOHLER: Thanks, Stefan.

00:38:58.520 --> 00:39:01.080
So that's a really
fascinating, in-depth look

00:39:01.080 --> 00:39:03.777
at sort of what's happening
behind the scenes.

00:39:03.777 --> 00:39:05.610
So when we're talking
about machine learning

00:39:05.610 --> 00:39:08.227
and how we apply
it, that's the sort

00:39:08.227 --> 00:39:09.810
of output and the
type of things we're

00:39:09.810 --> 00:39:12.340
aiming for for
that algorithm 2.0.

00:39:12.340 --> 00:39:15.810
So for our sort of
production algorithm that we

00:39:15.810 --> 00:39:18.210
want to get to, which
we're working on now,

00:39:18.210 --> 00:39:20.220
is sort of being
able to localize,

00:39:20.220 --> 00:39:24.000
identify where the
plastic item is

00:39:24.000 --> 00:39:27.750
in its location, what size
it is, what kind it is,

00:39:27.750 --> 00:39:29.910
eventually.

00:39:29.910 --> 00:39:31.080
Also, the sort of volume--

00:39:31.080 --> 00:39:37.060
using the SLAM techniques
that Stefan was talking about,

00:39:37.060 --> 00:39:41.040
as well as having autonomous
platform to scale.

00:39:41.040 --> 00:39:42.830
So you're not just--

00:39:42.830 --> 00:39:44.250
we'll talk about
it in a second--

00:39:44.250 --> 00:39:44.750
scaling.

00:39:44.750 --> 00:39:47.370
But as long as that's
within the sort

00:39:47.370 --> 00:39:49.100
of legal and safe framework.

00:39:49.100 --> 00:39:51.900
So I think there's a bit of
human interaction at the start

00:39:51.900 --> 00:39:54.630
to ensure that those
platforms operate

00:39:54.630 --> 00:39:58.140
within safe environments,
especially given

00:39:58.140 --> 00:40:03.180
congested airspace like is
around Southeast England.

00:40:03.180 --> 00:40:04.780
So what does it all mean?

00:40:04.780 --> 00:40:05.730
So great.

00:40:05.730 --> 00:40:09.060
We've got the scanning, we've
got the data, but how will

00:40:09.060 --> 00:40:10.650
this have an impact?

00:40:10.650 --> 00:40:16.650
What I saw at the very beginning
and my journey to that broader

00:40:16.650 --> 00:40:18.990
understanding of the problem
of where plastics are,

00:40:18.990 --> 00:40:22.920
and then eventually, how
we can help prevent--

00:40:22.920 --> 00:40:24.870
how revealing-- how
all this technology

00:40:24.870 --> 00:40:26.610
that reveals the
extent of the problem

00:40:26.610 --> 00:40:29.520
can help prevent the
problem in the first place,

00:40:29.520 --> 00:40:30.720
as well as help clean it up.

00:40:30.720 --> 00:40:33.660
And so the first thing is
the localization and trend

00:40:33.660 --> 00:40:34.560
analysis.

00:40:34.560 --> 00:40:37.410
So this data is actually
data that we manually

00:40:37.410 --> 00:40:42.030
collected, but eventually,
through the algorithm outputs,

00:40:42.030 --> 00:40:44.850
we'll be able to
sort of heat map--

00:40:44.850 --> 00:40:48.690
analyze concentrations
of plastics,

00:40:48.690 --> 00:40:51.240
and then sort of pull from
that data about the types

00:40:51.240 --> 00:40:55.020
of plastics all
sorts of analysis,

00:40:55.020 --> 00:40:57.180
again, depending
on the requirement.

00:40:57.180 --> 00:41:01.080
And this data is the thing
that's missing at the moment.

00:41:01.080 --> 00:41:02.910
This sort of scale,
because it only

00:41:02.910 --> 00:41:05.310
happens in very localized ways.

00:41:05.310 --> 00:41:08.790
It's very hard for the person
to get the exact same volunteers

00:41:08.790 --> 00:41:10.440
to go to the exact
same beach that they

00:41:10.440 --> 00:41:15.260
were before and recorded
it in the exact same way,

00:41:15.260 --> 00:41:19.290
whereas the algorithm, although
it's not going to be perfect--

00:41:19.290 --> 00:41:21.730
we don't think we can
get it up to 100% at all,

00:41:21.730 --> 00:41:24.240
but at least if
there are errors,

00:41:24.240 --> 00:41:26.640
they're more consistent,
which allows scientists

00:41:26.640 --> 00:41:28.754
to understand that background.

00:41:28.754 --> 00:41:30.420
And that sort of thing
can inform things

00:41:30.420 --> 00:41:33.570
like legal monitoring
enforcement.

00:41:33.570 --> 00:41:35.130
So there's all
sorts of conventions

00:41:35.130 --> 00:41:37.930
now from the UNCLOS--

00:41:37.930 --> 00:41:40.290
the United Nations
Law of the Sea, which

00:41:40.290 --> 00:41:44.430
is all about monitoring impact.

00:41:44.430 --> 00:41:47.250
So if there's
leakage into the sea,

00:41:47.250 --> 00:41:50.340
member states have an obligation
to then monitor how that

00:41:50.340 --> 00:41:52.440
is impacting the environment.

00:41:52.440 --> 00:41:55.260
That has then been
transposed to EU regulations

00:41:55.260 --> 00:42:01.800
for the European Environmental
Strategic Marine Framework

00:42:01.800 --> 00:42:05.645
Directive, and they've got
a policy cycle here, again,

00:42:05.645 --> 00:42:06.770
where they need to monitor.

00:42:06.770 --> 00:42:09.191
So guess is good
environmental standard.

00:42:09.191 --> 00:42:11.190
Lots of things involved
in that, but one of them

00:42:11.190 --> 00:42:13.560
is, again, marine
litter on beaches.

00:42:13.560 --> 00:42:16.950
So when you go to a beach and
you see lots of marine litter,

00:42:16.950 --> 00:42:18.750
legally now, that
shouldn't be there.

00:42:18.750 --> 00:42:22.040
All states should be monitoring
that and putting plans in

00:42:22.040 --> 00:42:22.846
to prevent it.

00:42:22.846 --> 00:42:24.720
So this is part of the
strategy, and that all

00:42:24.720 --> 00:42:26.490
comes under the
Honolulu strategy, which

00:42:26.490 --> 00:42:32.610
was a big effort to get not just
policy people in governments,

00:42:32.610 --> 00:42:36.270
but also companies
involved in that

00:42:36.270 --> 00:42:42.302
design and the appreciation
of how do plastics break down?

00:42:42.302 --> 00:42:43.260
What are the most ones?

00:42:43.260 --> 00:42:46.890
How can we identify which
are the most offending ones?

00:42:46.890 --> 00:42:49.670
And this is a lot of sort
of Dr. Arturo's work here-

00:42:49.670 --> 00:42:52.750
Dr. Castillo's work.

00:42:52.750 --> 00:42:55.150
To quantify risk to wildlife.

00:42:55.150 --> 00:42:57.985
So as you saw, some of
these pictures-- this is one

00:42:57.985 --> 00:42:58.860
that someone sent in.

00:42:58.860 --> 00:43:01.090
The seagull-- he caught a
Seagull eating a bit of plastic

00:43:01.090 --> 00:43:02.506
on the beach right
in front of him

00:43:02.506 --> 00:43:04.930
as he was doing a drone scan.

00:43:04.930 --> 00:43:07.450
So if we understand the sizes
of plastics and where they

00:43:07.450 --> 00:43:09.616
concentrate-- and there are
some [INAUDIBLE] calls--

00:43:09.616 --> 00:43:11.140
some research calls
now about this

00:43:11.140 --> 00:43:14.620
and using the
localization and SLAM--

00:43:14.620 --> 00:43:17.836
the semantic segmentation--
we can understand the sizes

00:43:17.836 --> 00:43:19.210
and types, and
that will allow us

00:43:19.210 --> 00:43:22.550
to sort of map that with, say,
feeding patterns of albatross.

00:43:22.550 --> 00:43:25.750
So we can then identify
those marine environments

00:43:25.750 --> 00:43:31.610
that are most vulnerable
to plastic contamination.

00:43:31.610 --> 00:43:33.737
But also, to quantify
the risk to humans.

00:43:33.737 --> 00:43:34.570
So this is in Tonga.

00:43:34.570 --> 00:43:35.440
This is Nuku'alofa.

00:43:35.440 --> 00:43:41.080
This is not far from where
I was in the South Pacific,

00:43:41.080 --> 00:43:43.520
and it helps us understand
the risks to humans.

00:43:43.520 --> 00:43:45.880
So whilst we don't
yet understand

00:43:45.880 --> 00:43:48.940
the transfer of toxins and
that subject for intense study

00:43:48.940 --> 00:43:51.170
at the moment,
the UN is advising

00:43:51.170 --> 00:43:52.420
it a precautionary principle.

00:43:52.420 --> 00:43:56.350
So rather than waiting for
the stuff to hit the fan,

00:43:56.350 --> 00:43:59.140
we do something about it now.

00:43:59.140 --> 00:44:01.590
And so it's really important,
understanding with something

00:44:01.590 --> 00:44:02.090
like--

00:44:02.090 --> 00:44:06.400
I think it's half the world's
population lives within 100

00:44:06.400 --> 00:44:08.120
kilometers of the coast.

00:44:08.120 --> 00:44:10.400
So there's an important
interaction going on here.

00:44:10.400 --> 00:44:12.760
It allows us to quantify that.

00:44:12.760 --> 00:44:14.890
Economic damage to shipping.

00:44:14.890 --> 00:44:18.899
Here's a ship's propeller
tangled with a netting.

00:44:18.899 --> 00:44:20.190
And that ship is then disabled.

00:44:20.190 --> 00:44:21.735
That ship is then vulnerable.

00:44:21.735 --> 00:44:23.110
If it was in a
storm, it would be

00:44:23.110 --> 00:44:25.666
vulnerable to capsizing that.

00:44:25.666 --> 00:44:29.020
To the tourist industry.

00:44:29.020 --> 00:44:31.960
I've got friends
who've gone to Phuket,

00:44:31.960 --> 00:44:34.820
and they now see plastic
all over the place.

00:44:34.820 --> 00:44:36.820
And that impacts-- no one
wants to go to a beach

00:44:36.820 --> 00:44:40.330
and sit in, basically,
a rubbish heap.

00:44:40.330 --> 00:44:44.350
So there's a lot of interest
in there, as well as below

00:44:44.350 --> 00:44:47.710
is the sort of economic
environment affecting

00:44:47.710 --> 00:44:49.030
harbors and ships.

00:44:51.920 --> 00:44:54.789
So there's lots of potential
applications in that area.

00:44:54.789 --> 00:44:56.330
And then that can
lead to, obviously,

00:44:56.330 --> 00:44:58.970
coordinating the removal.

00:44:58.970 --> 00:45:01.120
So this is the group of us here.

00:45:01.120 --> 00:45:04.730
This is the final beach
clean in Dovercourt in Essex.

00:45:04.730 --> 00:45:09.770
And help more effective-- from
local organizations, volunteer

00:45:09.770 --> 00:45:13.460
groups, all the way up to
sort of governmental level

00:45:13.460 --> 00:45:15.860
to help pinpoint the best
areas-- you know, the most

00:45:15.860 --> 00:45:17.110
effective areas to clean.

00:45:17.110 --> 00:45:19.560
Because if we know
how much of the litter

00:45:19.560 --> 00:45:21.970
is coming in from the
sea, how much of it

00:45:21.970 --> 00:45:26.390
is coming from the land,
where it accumulates--

00:45:26.390 --> 00:45:28.430
it will help us
tackle that aspect.

00:45:28.430 --> 00:45:32.240
It could help us identify what
types of plastic, which then

00:45:32.240 --> 00:45:34.580
leads onto the next sort of
element, which is informing

00:45:34.580 --> 00:45:36.620
campaigns and effectiveness.

00:45:36.620 --> 00:45:39.935
So if you say, all
right, well we're

00:45:39.935 --> 00:45:41.560
going to ban all
drink bottles or we're

00:45:41.560 --> 00:45:43.870
going to instigate a
deposit return scheme.

00:45:43.870 --> 00:45:47.600
Well, how do you measure
how successful that is?

00:45:47.600 --> 00:45:51.150
Without that data, it's
difficult to lobby.

00:45:51.150 --> 00:45:53.080
There's one less, as well.

00:45:53.080 --> 00:45:56.120
There's Sky now is passing
single use plastic.

00:45:56.120 --> 00:45:57.110
Passing plastics.

00:45:57.110 --> 00:45:59.582
There's some great
campaigns out there,

00:45:59.582 --> 00:46:01.790
but we need to understand
what sort of impact they're

00:46:01.790 --> 00:46:05.300
having on the environment
to ensure that they're

00:46:05.300 --> 00:46:08.540
the best they can be to
really help get to that end

00:46:08.540 --> 00:46:11.540
goal of a cleaner ocean.

00:46:11.540 --> 00:46:13.946
Some of the impacts,
and then not long now.

00:46:13.946 --> 00:46:14.820
It's nearly finished.

00:46:14.820 --> 00:46:17.340
We've done over 33 beaches
with over 100 volunteers.

00:46:17.340 --> 00:46:19.170
A ton of litter.

00:46:19.170 --> 00:46:20.877
14,000 drone images.

00:46:20.877 --> 00:46:23.210
I think we've probably got--
because each drone image is

00:46:23.210 --> 00:46:26.505
divided into about 25 tiles
because of the resolution,

00:46:26.505 --> 00:46:28.380
and each tile is then
uploaded to Zooniverse.

00:46:28.380 --> 00:46:32.300
So I think we're more in the
region of half a million images

00:46:32.300 --> 00:46:34.160
that we've gone through.

00:46:34.160 --> 00:46:36.070
We've had over
10,000 volunteers.

00:46:36.070 --> 00:46:39.950
We're nearly at 4
million tags now.

00:46:39.950 --> 00:46:42.260
Last week, for British Science
Week a couple weeks ago,

00:46:42.260 --> 00:46:47.420
we got 1 and 1/2 million in
five days, which was incredible.

00:46:47.420 --> 00:46:48.830
Tens to hundreds of schools--

00:46:48.830 --> 00:46:50.980
we know lots of schools got in.

00:46:50.980 --> 00:46:54.380
The demand peaked during school
hours form 10:00 to 3:00 PM.

00:46:54.380 --> 00:46:56.570
We were getting something
like 1,000 tags a minute

00:46:56.570 --> 00:46:57.528
or something like that.

00:46:57.528 --> 00:47:00.740
It was incredible.

00:47:00.740 --> 00:47:02.990
And it's national, and
eventually international.

00:47:02.990 --> 00:47:05.750
And then tomorrow-- so
this is the phase two.

00:47:05.750 --> 00:47:09.560
This is sort of 2.0, which
we were talking about.

00:47:09.560 --> 00:47:11.780
The production algorithm--
a global database.

00:47:11.780 --> 00:47:13.170
All of that imagery--

00:47:13.170 --> 00:47:15.620
that data gets uploaded
to a map online,

00:47:15.620 --> 00:47:19.460
where you can then view,
visualize, and query the data.

00:47:19.460 --> 00:47:21.810
Eventually, autonomous
drone platforms--

00:47:21.810 --> 00:47:22.310
open-source.

00:47:22.310 --> 00:47:25.670
So we want to release as
much as we can open source--

00:47:25.670 --> 00:47:28.220
as open source licenses.

00:47:28.220 --> 00:47:30.845
Extending it to the sea floor,
sea surface, and rivers.

00:47:30.845 --> 00:47:32.720
So you remember that
diagram at the beginning

00:47:32.720 --> 00:47:34.730
where we looked
at all the fluxes.

00:47:34.730 --> 00:47:37.640
So retraining the dataset.

00:47:37.640 --> 00:47:41.810
And we're working on prototypes
now for the sea floor,

00:47:41.810 --> 00:47:44.000
for example, so keep
an eye out for that.

00:47:44.000 --> 00:47:47.930
Moving to multi-spectral
and hyper-spectral imagery.

00:47:47.930 --> 00:47:50.540
Then satellite sensing--
potentially even

00:47:50.540 --> 00:47:52.330
gamifying the citizen
science element.

00:47:52.330 --> 00:47:55.270
So that's a very dry
interaction at the moment.

00:47:55.270 --> 00:47:56.880
It's only great on computers.

00:47:56.880 --> 00:47:58.490
It's not great on
mobiles because it's

00:47:58.490 --> 00:47:59.600
a volunteer platform.

00:47:59.600 --> 00:48:02.165
They do it free of charge.

00:48:02.165 --> 00:48:02.915
That's Zooniverse.

00:48:02.915 --> 00:48:04.850
It's part of Oxford.

00:48:04.850 --> 00:48:06.890
And sort of drone
survey standards--

00:48:06.890 --> 00:48:10.370
it's setting up an international
standard for drone surveying,

00:48:10.370 --> 00:48:11.330
which we are--

00:48:11.330 --> 00:48:13.647
we've set up a marina to
drone net to support that.

00:48:13.647 --> 00:48:15.230
We've got people
from around the world

00:48:15.230 --> 00:48:18.770
on that, which we're
launching on Sunday,

00:48:18.770 --> 00:48:20.819
which is World Earth Day.

00:48:20.819 --> 00:48:22.610
And then just a little
about the timelines.

00:48:22.610 --> 00:48:25.220
Rough approximation of
the sort of timelines

00:48:25.220 --> 00:48:27.063
in which we're looking at that.

00:48:30.710 --> 00:48:31.670
How to get involved.

00:48:31.670 --> 00:48:36.340
I'll send some links
around to Florian.

00:48:36.340 --> 00:48:39.660
Numero uno is get tagging.

00:48:39.660 --> 00:48:43.970
Also, I think we're now
registered with Google Giving,

00:48:43.970 --> 00:48:44.750
I think it is.

00:48:44.750 --> 00:48:47.750
Yeah, so if you want to
give some of your time

00:48:47.750 --> 00:48:50.110
or some of your
efforts, you can tag.

00:48:50.110 --> 00:48:52.130
We'll be setting up
beach cleans, as well.

00:48:52.130 --> 00:48:57.350
So go to our website,
www.ThePlasticTide.com,

00:48:57.350 --> 00:48:59.680
and you'll see all the latest
things that we're doing.

00:48:59.680 --> 00:49:05.030
I've got a talk next
Tuesday at a conference.

00:49:05.030 --> 00:49:06.990
Yeah, I think that's it.

00:49:06.990 --> 00:49:10.140
So I think any questions,
and thank everyone.

00:49:10.140 --> 00:49:10.912
Thank you.

00:49:10.912 --> 00:49:12.880
[APPLAUSE]

00:49:17.800 --> 00:49:19.000
AUDIENCE: Oh.

00:49:19.000 --> 00:49:19.751
So did you say--

00:49:19.751 --> 00:49:22.000
I thought a couple of slides
back that we can actually

00:49:22.000 --> 00:49:25.450
go down and take our own drone
images, which we can then

00:49:25.450 --> 00:49:27.329
get people to tag?

00:49:27.329 --> 00:49:28.120
PETER KOHLER: Yeah.

00:49:28.120 --> 00:49:28.840
AUDIENCE: Yeah.

00:49:28.840 --> 00:49:30.131
PETER KOHLER: Potentially, yes.

00:49:30.131 --> 00:49:31.130
We do that.

00:49:31.130 --> 00:49:36.190
Ellie and I set up a sort of
standard where you can donate.

00:49:36.190 --> 00:49:39.730
We have a structure where you
basically-- it gives the images

00:49:39.730 --> 00:49:41.600
and then we upload them.

00:49:41.600 --> 00:49:44.820
But eventually, once we've got
enough of that training data,

00:49:44.820 --> 00:49:47.440
we'll be moving away from that.

00:49:47.440 --> 00:49:49.260
But there are areas
where we can explore it

00:49:49.260 --> 00:49:50.520
for further citizen science.

00:49:50.520 --> 00:49:53.620
So we know that when people
have had to look closely

00:49:53.620 --> 00:49:57.550
on the tagging side, you then
start to see a lot more of it

00:49:57.550 --> 00:49:59.140
outside.

00:49:59.140 --> 00:50:01.732
And that starts to change
your behavior, and so we've--

00:50:01.732 --> 00:50:03.190
like I said, we've
got a researcher

00:50:03.190 --> 00:50:04.357
who's looking into that now.

00:50:04.357 --> 00:50:04.981
AUDIENCE: Cool.

00:50:04.981 --> 00:50:06.560
And for the image
quality, do they

00:50:06.560 --> 00:50:09.359
need to be of a specific image
quality-- the drone images?

00:50:09.359 --> 00:50:10.150
PETER KOHLER: Yeah.

00:50:10.150 --> 00:50:12.566
AUDIENCE: I was wondering how
flexible your platform would

00:50:12.566 --> 00:50:15.490
be for other forms of
environmental aerial survey.

00:50:15.490 --> 00:50:17.020
So I know that, for
instance, people

00:50:17.020 --> 00:50:19.420
are looking at the
spread of sudden--

00:50:19.420 --> 00:50:22.906
tree diseases, say,
from canopy surveys.

00:50:22.906 --> 00:50:24.280
And I wondered
whether-- it seems

00:50:24.280 --> 00:50:25.660
like a lot of the
platform, you would

00:50:25.660 --> 00:50:26.980
have already built for this.

00:50:26.980 --> 00:50:29.950
And maybe it's just the final
bit of visual machine learning

00:50:29.950 --> 00:50:32.320
that would be required to
be changed to do things

00:50:32.320 --> 00:50:34.750
like handling
multi-spectral images

00:50:34.750 --> 00:50:37.700
and looking at tree health.

00:50:37.700 --> 00:50:39.290
STEFAN LEUTENEGGER:
Yeah, I guess

00:50:39.290 --> 00:50:41.450
this is somewhat a question
for both of us, right?

00:50:41.450 --> 00:50:43.790
But I mean, from
the machine learning

00:50:43.790 --> 00:50:45.740
perspective and the
robotics perspective,

00:50:45.740 --> 00:50:46.740
you're absolutely right.

00:50:46.740 --> 00:50:50.240
It doesn't really change
the principles behind it.

00:50:50.240 --> 00:50:52.606
But at the same time, you
still need the training data

00:50:52.606 --> 00:50:54.780
that is specific to
that application.

00:50:54.780 --> 00:50:57.440
And I think that's-- yeah,
that's when the Plastic Tide

00:50:57.440 --> 00:51:01.580
kind of set up the need to come
in for a different application.

00:51:01.580 --> 00:51:04.650
But yeah, in principle,
it would be ready, right?

00:51:04.650 --> 00:51:08.710
Also, Zooniverse or other
platforms that enable tagging--

00:51:08.710 --> 00:51:11.180
they are out there.

00:51:11.180 --> 00:51:15.330
PETER KOHLER: There are or there
were canopy tagging platforms

00:51:15.330 --> 00:51:16.090
on that.

00:51:16.090 --> 00:51:18.786
And we're sort of
talking about--

00:51:18.786 --> 00:51:21.160
when we're doing the seafloor
monitoring and potentially,

00:51:21.160 --> 00:51:23.450
on the beaches, as
well as perhaps looking

00:51:23.450 --> 00:51:26.800
at marine life in
keystone species.

00:51:26.800 --> 00:51:29.690
But again, it's very
difficult because you've

00:51:29.690 --> 00:51:33.050
got to think about the
tagger on the other side

00:51:33.050 --> 00:51:34.400
and their level of expertise.

00:51:34.400 --> 00:51:35.657
So it's quite a balancing act.

00:51:35.657 --> 00:51:36.990
You don't want to overload them.

00:51:36.990 --> 00:51:38.624
Otherwise, you're just not
going to get the volume

00:51:38.624 --> 00:51:39.592
that you need.

00:51:42.634 --> 00:51:44.800
AUDIENCE: Thank you for an
interesting presentation.

00:51:44.800 --> 00:51:49.510
I wonder if the technology
enables us today

00:51:49.510 --> 00:51:52.060
to scan the ocean--

00:51:52.060 --> 00:51:57.430
all the seas and to get the
exact picture, because you

00:51:57.430 --> 00:51:59.780
mentioned that 99%--

00:51:59.780 --> 00:52:02.440
it goes and sinks to the
oceans or the water, right?

00:52:02.440 --> 00:52:04.060
And that 1% is--

00:52:04.060 --> 00:52:06.640
it's kind of rough
calculation, maybe.

00:52:06.640 --> 00:52:10.160
But if the technology
enables us today,

00:52:10.160 --> 00:52:13.780
and another is how we
influence all the-- once

00:52:13.780 --> 00:52:16.690
we get all the data, how we
influence to that, because you

00:52:16.690 --> 00:52:18.480
mentioned the policy.

00:52:18.480 --> 00:52:22.540
How we influence policy
makers or the consumers

00:52:22.540 --> 00:52:25.840
in the future to kind of
restrain from the plastic use

00:52:25.840 --> 00:52:27.460
or to ban the plastic
for the future

00:52:27.460 --> 00:52:29.300
because I know they
are the [INAUDIBLE]

00:52:29.300 --> 00:52:32.470
I think that France
introduced the policy where

00:52:32.470 --> 00:52:35.330
they ban the plastics,
and some of the countries

00:52:35.330 --> 00:52:37.309
are in the queue, as well.

00:52:37.309 --> 00:52:39.100
STEFAN LEUTENEGGER:
Just today, actually, I

00:52:39.100 --> 00:52:41.710
think there was news
that for the UK,

00:52:41.710 --> 00:52:43.150
plastic straws will be banned.

00:52:45.890 --> 00:52:46.631
Oh.

00:52:46.631 --> 00:52:47.130
OK.

00:52:47.130 --> 00:52:48.720
PETER KOHLER: Got rid of
plastic straws, apparently.

00:52:48.720 --> 00:52:49.400
There you go.

00:52:49.400 --> 00:52:50.900
STEFAN LEUTENEGGER:
They are banned.

00:52:50.900 --> 00:52:54.906
So definitely, I think
politics are waking up.

00:52:54.906 --> 00:52:57.520
There still needs a lot more
waking up, and then actual

00:52:57.520 --> 00:52:59.530
action to follow.

00:52:59.530 --> 00:53:00.310
But yeah.

00:53:00.310 --> 00:53:01.930
I hope we can feed some of that.

00:53:01.930 --> 00:53:03.922
Data but that's
probably more of your--

00:53:03.922 --> 00:53:05.380
PETER KOHLER: Yeah,
I think-- well,

00:53:05.380 --> 00:53:07.213
we've got an expert in
the house right here.

00:53:07.213 --> 00:53:10.150
So I think if we can pass
the microphone to Arturo.

00:53:10.150 --> 00:53:14.160
So Dr. Arturo is an Imperial--

00:53:14.160 --> 00:53:17.200
ARTURO CASTILLO: So we know
what the policy making cycle is,

00:53:17.200 --> 00:53:21.450
and it all starts with, also,
sentiment monitoring of people.

00:53:21.450 --> 00:53:25.150
So politicians and
policymakers don't

00:53:25.150 --> 00:53:27.430
move unless they
know that there is

00:53:27.430 --> 00:53:30.910
a demand and the need
for all these policies

00:53:30.910 --> 00:53:32.440
to actually take place.

00:53:32.440 --> 00:53:34.690
And the way the
Plastic Tide can do

00:53:34.690 --> 00:53:36.760
that is by informing
what are the trends, what

00:53:36.760 --> 00:53:40.420
is the frequency and the hot
spots of all this damage that

00:53:40.420 --> 00:53:42.820
is accumulating, and
raising the awareness.

00:53:42.820 --> 00:53:45.770
So this is very important
that this has two elements.

00:53:45.770 --> 00:53:48.190
One is the monitoring, but the
other one is the education.

00:53:48.190 --> 00:53:50.110
And the moment that
people are educated,

00:53:50.110 --> 00:53:53.470
then both the demand and the
welcoming of the policies

00:53:53.470 --> 00:53:55.810
will be much easier.

00:53:59.887 --> 00:54:01.470
MODERATOR: We are
running out of time,

00:54:01.470 --> 00:54:03.910
so if you close here--
again, thank you very much.

00:54:03.910 --> 00:54:04.350
PETER KOHLER: Thank you.

00:54:04.350 --> 00:54:05.600
STEFAN LEUTENEGGER: Thank you.

00:54:05.600 --> 00:54:07.400
[APPLAUSE]

