WEBVTT
Kind: captions
Language: en

00:00:00.360 --> 00:00:01.450
&gt;&gt; Okay Michael, so we've done our little

00:00:01.450 --> 00:00:05.390
example. I want to ask you a quick question

00:00:05.390 --> 00:00:07.260
and try to talk something through with you

00:00:07.260 --> 00:00:09.270
and then we can start to wrap up. Okay.

00:00:09.270 --> 00:00:09.720
&gt;&gt; Awesome.

00:00:09.720 --> 00:00:14.880
&gt;&gt; Alright, so, here is my quick question. Now, in the reading, which I know

00:00:14.880 --> 00:00:20.100
you've read, there's a proof. That shows that boosting not

00:00:20.100 --> 00:00:25.610
only, you know, does pretty things with axis of line semi-planes, but also

00:00:25.610 --> 00:00:29.210
that it will converge to good answers and that it will

00:00:29.210 --> 00:00:33.390
find good combined hypotheses. You know, we could go look at

00:00:33.390 --> 00:00:36.110
the reading and write down a proof that shows that boosting

00:00:36.110 --> 00:00:38.892
does well. Umm. And there's one in the reading. Or we

00:00:38.892 --> 00:00:41.380
could talk about an intuition. So if someone were to come

00:00:41.380 --> 00:00:44.172
up to you. If a student were to find you somewhere

00:00:44.172 --> 00:00:47.592
and said, I read the proof, I'm kind of getting it,

00:00:47.592 --> 00:00:50.632
but do you have a good sort of intuition about why

00:00:50.632 --> 00:00:54.450
boosting tends will do well? What do you think you would tell them?

00:00:54.450 --> 00:00:57.240
Could you think of something simple? I've been struggling with this for a while.

00:00:57.240 --> 00:00:59.400
&gt;&gt; No. [LAUGH].

00:00:59.400 --> 00:01:01.870
&gt;&gt; Okay, well, then let me try something on you and you can tell

00:01:01.870 --> 00:01:05.074
me if it sort of makes sense. So this is just an intuition for why,

00:01:05.074 --> 00:01:10.000
for why boosting pins will do well. Okay, so what does boosting do? Okay.

00:01:10.000 --> 00:01:13.090
Boosting basically says, if I have some

00:01:13.090 --> 00:01:15.990
examples that I haven't been able to classify

00:01:15.990 --> 00:01:21.210
well, I'm going to re-rate all my examples. So that the ones

00:01:21.210 --> 00:01:23.030
I don't do well become increasingly

00:01:23.030 --> 00:01:25.160
important. Right, that's what boosting does. Yes?

00:01:25.160 --> 00:01:25.480
&gt;&gt; Yes.

00:01:25.480 --> 00:01:30.965
&gt;&gt; Right, that's what this whole, whole bit of D is all about. It's all about

00:01:30.965 --> 00:01:36.560
re-weighting based on difficulty and hardest. And we know that

00:01:36.560 --> 00:01:41.040
we have the notion of a weak learner. That no matter what happens for

00:01:41.040 --> 00:01:45.160
whatever distribution, we're always going to be able to find

00:01:45.160 --> 00:01:48.280
some hypothesis that does well. So, if I'm trying to

00:01:48.280 --> 00:01:51.980
understand why boosting in the end, why the final hypothesis

00:01:51.980 --> 00:01:54.620
that I get at the end, is going to do well.

00:01:54.620 --> 00:01:56.330
I can try to get a feeling for that by

00:01:56.330 --> 00:02:00.250
asking, well. Under what circumstances would it not do well? So,

00:02:00.250 --> 00:02:02.990
if it doesn't do well, then that means there has

00:02:02.990 --> 00:02:07.170
to be a bunch of examples that it's getting wrong, right?

00:02:07.170 --> 00:02:07.830
&gt;&gt; Mm hm.

00:02:07.830 --> 00:02:09.800
&gt;&gt; That's what it would mean not to do well, agreed?

00:02:09.800 --> 00:02:10.288
&gt;&gt; Yeah.

00:02:10.288 --> 00:02:16.670
&gt;&gt; Okay. So how many things could it not get right? How many things could it

00:02:16.670 --> 00:02:19.640
misclassify? How many things could it get incorrect?

00:02:19.640 --> 00:02:21.780
Well, I'm going to argue Michael, that, that

00:02:21.780 --> 00:02:25.780
number has to be small. There cannot be a lot of examples that it gets wrong.

00:02:25.780 --> 00:02:27.920
So do you want to know why? Do you want to know my reasoning for why?

00:02:27.920 --> 00:02:29.170
&gt;&gt; Yeah.

00:02:29.170 --> 00:02:32.400
&gt;&gt; So, here's my reasoning, let's imagine I had a

00:02:32.400 --> 00:02:35.230
number of examples at the end of this whole process.

00:02:35.230 --> 00:02:38.150
I've done it T times. I've gone through this many times

00:02:38.150 --> 00:02:40.020
and I have some number of examples that I'm getting

00:02:40.020 --> 00:02:43.610
wrong. If I were getting those examples wrong, then I was

00:02:43.610 --> 00:02:47.080
getting them wrong in the last time step, right? And,

00:02:47.080 --> 00:02:51.170
since I have a distribution and I re-normalize, and it has

00:02:51.170 --> 00:02:54.880
to be the case that at least half of the time,

00:02:54.880 --> 00:02:57.750
more than half of the time I am correct, that number

00:02:57.750 --> 00:03:00.230
of things I'm getting wrong has to be getting smaller over

00:03:00.230 --> 00:03:02.720
time. Because let's imagine that was at a stage where I

00:03:02.720 --> 00:03:05.000
had a whole bunch of them wrong. Well, then I would

00:03:05.000 --> 00:03:09.680
naturally renormalize them with a distribution so that all of those things

00:03:09.680 --> 00:03:12.270
are important. But if they were all important, the ones that

00:03:12.270 --> 00:03:14.930
I was getting wrong, the next time I run a learner, I

00:03:14.930 --> 00:03:16.690
am going to have to get at least half of them

00:03:16.690 --> 00:03:19.086
right, more than half of them are right. Is that make sense?

00:03:19.086 --> 00:03:22.810
&gt;&gt; It does, but it, but what scares me is, okay, why can't

00:03:22.810 --> 00:03:25.810
it just be the case that the previous ones which were getting right

00:03:25.810 --> 00:03:29.910
start to get more wrong as we shift our energy towards the errors.

00:03:29.910 --> 00:03:30.910
&gt;&gt; Yeah, why is that?

00:03:30.910 --> 00:03:36.080
&gt;&gt; I don't know. But did you wanna, are we, we working up to some kind of you

00:03:36.080 --> 00:03:39.880
know, log n kind of thing where each time

00:03:39.880 --> 00:03:42.100
you are knocking off half of them and therefore.

00:03:42.100 --> 00:03:43.820
&gt;&gt; I don't know. Do you remember the proof.

00:03:43.820 --> 00:03:44.130
&gt;&gt; The proof.

00:03:44.130 --> 00:03:45.050
&gt;&gt; I mean what goes on is that

00:03:45.050 --> 00:03:48.380
you get, sort of, this exponentially aggressive weighting over

00:03:48.380 --> 00:03:49.200
examples, right?

00:03:49.200 --> 00:03:50.270
&gt;&gt; Yeah.

00:03:50.270 --> 00:03:53.520
&gt;&gt; And you're driving down the number of things you get wrong. Sort of

00:03:53.520 --> 00:03:55.980
exponentially quickly, over time. That's why boosting

00:03:55.980 --> 00:03:57.200
works so well and works so fast.

00:03:57.200 --> 00:04:01.410
&gt;&gt; I get that we're, the we're quickly ramping up the weights on the hard

00:04:01.410 --> 00:04:05.710
ones. I don't get why that's causing us to get fewer things wrong over time.

00:04:05.710 --> 00:04:10.300
So like, when you should, in your, in your example that you worked through, that

00:04:10.300 --> 00:04:13.500
had the error in the alphas and the errors kept going down and the alphas

00:04:13.500 --> 00:04:14.180
kept going up.

00:04:14.180 --> 00:04:15.050
&gt;&gt; Right.

00:04:15.050 --> 00:04:18.120
&gt;&gt; Like, is that necessarily the case?

00:04:18.120 --> 00:04:20.540
&gt;&gt; Well, what would be the circumstances under

00:04:20.540 --> 00:04:22.300
which it isn't the case? How would you

00:04:22.300 --> 00:04:24.880
ever go back and forth between examples? Well,

00:04:24.880 --> 00:04:26.430
certainly it's the case that if you keep getting

00:04:26.430 --> 00:04:31.120
something, right, you will, get them. Well, so

00:04:31.120 --> 00:04:32.660
here's what happens over time, right. Is that over

00:04:32.660 --> 00:04:36.040
time, every new hypothesis, it gets to get

00:04:36.040 --> 00:04:38.680
a vote, based upon how well it does on

00:04:38.680 --> 00:04:43.470
the last, difficult let's say, distribution. So the

00:04:43.470 --> 00:04:47.810
ones that are even if the ones that

00:04:47.810 --> 00:04:49.420
you were getting right you start to get

00:04:49.420 --> 00:04:52.480
wrong, they are going to, if you get them

00:04:52.480 --> 00:04:55.720
increasingly wrong, that error's going to go down and

00:04:55.720 --> 00:04:59.130
you're going to get less of a vote, right.

00:04:59.130 --> 00:05:00.990
Because e sub T is over the current

00:05:00.990 --> 00:05:03.842
distribution. And it's not over the sum of the

00:05:03.842 --> 00:05:07.500
voted, over all the examples you've ever seen.

00:05:07.500 --> 00:05:08.080
&gt;&gt; Understand.

00:05:08.080 --> 00:05:11.020
&gt;&gt; So does that make sense? Is that right?

00:05:11.020 --> 00:05:13.872
&gt;&gt; I don't know. I don't have the intuition, it seems like

00:05:13.872 --> 00:05:16.620
it could be, you know, could we keep shifting the distribution. It

00:05:16.620 --> 00:05:18.820
could be that the error is going up. Like if the error

00:05:18.820 --> 00:05:21.680
could be low, why can't we just make it low from the beginning.

00:05:21.680 --> 00:05:22.340
&gt;&gt; Right.

00:05:22.340 --> 00:05:24.030
&gt;&gt; Like, I feel like the error should be going up,

00:05:24.030 --> 00:05:26.810
because we're, we're asking it harder and harder questions as we go.

00:05:26.810 --> 00:05:29.090
&gt;&gt; No, no, no, because we're asking it harder and

00:05:29.090 --> 00:05:32.160
harder questions, but even though we're

00:05:32.160 --> 00:05:34.140
asking it harder and harder questions, it's

00:05:34.140 --> 00:05:37.770
forced to be able to do well on those hard questions. It's forced

00:05:37.770 --> 00:05:41.600
to, because it's a weak learner. I mean that's why having, being able

00:05:41.600 --> 00:05:44.610
to always, that's why having a weak learner is such a powerful thing.

00:05:44.610 --> 00:05:46.690
&gt;&gt; But why couldn't we like on, on

00:05:46.690 --> 00:05:50.350
iteration 17, have something where the weak learner works

00:05:50.350 --> 00:05:51.890
right at the edge of it's abilities, and

00:05:51.890 --> 00:05:54.240
it just comes back with something that's a half

00:05:54.240 --> 00:05:55.720
minus epsilon.

00:05:55.720 --> 00:05:58.020
&gt;&gt; That's fine. But it has to always be able to do that. If it's

00:05:58.020 --> 00:05:59.480
a half minus epsilon, the things it's getting

00:05:59.480 --> 00:06:01.800
wrong will have to go back down again.

00:06:01.800 --> 00:06:03.140
&gt;&gt; No, no I understand that. What I'm saying

00:06:03.140 --> 00:06:06.620
is that, why would the error go down each iteration.

00:06:06.620 --> 00:06:08.537
&gt;&gt; Well, it doesn't have to, but it shouldn't be getting bigger.

00:06:08.537 --> 00:06:09.488
&gt;&gt; Why shouldn't it be getting bigger?

00:06:09.488 --> 00:06:11.227
&gt;&gt; So, imagine, imagine, imagine the case that you're

00:06:11.227 --> 00:06:13.960
getting, right. You, you are working at the edge of

00:06:13.960 --> 00:06:16.910
your abilities. You get half of them right. Roughly and

00:06:16.910 --> 00:06:19.290
half of them wrong, the ones you got wrong would

00:06:19.290 --> 00:06:21.200
become more important, so the next time round you're going

00:06:21.200 --> 00:06:24.180
to get those right, versus the other ones. So you could

00:06:24.180 --> 00:06:26.510
cycle back and forth I suppose, in the worst case,

00:06:26.510 --> 00:06:29.000
but then you're just going to be sitting around, always having

00:06:29.000 --> 00:06:31.120
a little bit more information. So your error will not

00:06:31.120 --> 00:06:33.910
get worse, you'll just have different ones that are able to

00:06:33.910 --> 00:06:37.520
vote on that do well on different parts of the space.

00:06:37.520 --> 00:06:40.090
Right? Because you're always forced to do better than chance. So.

00:06:40.090 --> 00:06:42.070
&gt;&gt; Yeah but that, that's not the same as saying

00:06:42.070 --> 00:06:44.500
that we're forced to get better and better each iteration.

00:06:44.500 --> 00:06:45.240
&gt;&gt; That's right, it's not.

00:06:45.240 --> 00:06:49.380
&gt;&gt; So it's, yeah again, I don't see that, that property just falling out.

00:06:49.380 --> 00:06:51.310
&gt;&gt; Well, I don't see it falling out either, but then

00:06:51.310 --> 00:06:54.154
I haven't read the proof in like seven, eight, nine years.

00:06:54.154 --> 00:06:56.780
&gt;&gt; Well, I feel like it should be, it should be something like, look we

00:06:56.780 --> 00:07:01.130
had, look at what the, so okay, so we generate a new distribution, what is

00:07:01.130 --> 00:07:03.370
the previous, what's the previous classified error

00:07:03.370 --> 00:07:05.880
on this distribution, it better be the case.

00:07:05.880 --> 00:07:09.870
I mean if it were the case that we always return the best classifier that

00:07:09.870 --> 00:07:11.870
I could imagine trying to use that but.

00:07:11.870 --> 00:07:13.808
&gt;&gt; Well we, well we don't, we don't require that.

00:07:13.808 --> 00:07:15.800
&gt;&gt; Yeah, I mean, it's just finding one

00:07:15.800 --> 00:07:20.370
that's epsilon minus, or a half minus epsilon.

00:07:20.370 --> 00:07:22.300
&gt;&gt; Right, so let's, let's see if we can take the simple case,

00:07:22.300 --> 00:07:27.040
we got three examples, right, and you're bouncing back and forth and you want

00:07:27.040 --> 00:07:30.112
to construct something so that you always do well on two of them.

00:07:30.112 --> 00:07:34.750
And then poorly on one, kind of a thing, and that you keep bouncing

00:07:34.750 --> 00:07:38.410
back and forth. So let's imagine that you have one-third, one-third, one-third,

00:07:38.410 --> 00:07:41.100
and your first thing gets the first two right and the last one

00:07:41.100 --> 00:07:44.460
wrong. So you have an error of a third. And you make that

00:07:44.460 --> 00:07:49.770
last one more likely and the other two less likely. Suitably normalized, right?

00:07:49.770 --> 00:07:50.760
&gt;&gt; Yep.

00:07:50.760 --> 00:07:53.570
&gt;&gt; So now, your next one, you want to somehow

00:07:53.570 --> 00:07:56.430
bounce back and have it decide that it can miss,

00:07:56.430 --> 00:07:58.160
so let's say you missed the third one. So you,

00:07:58.160 --> 00:07:59.930
you get the third one right. You get the second

00:07:59.930 --> 00:08:03.000
one right but you get the first one wrong. What's going

00:08:03.000 --> 00:08:06.540
to happen? Well, three is going to go down. You're still going to,

00:08:06.540 --> 00:08:09.780
well you won't have a third error actually. You'll have less than

00:08:09.780 --> 00:08:12.190
a third error because you had to get one of the ones

00:08:12.190 --> 00:08:13.990
you were getting right wrong, you had to get the one

00:08:13.990 --> 00:08:17.330
you were getting wrong right. So your error is going to be

00:08:17.330 --> 00:08:21.860
at least an example I just gave. Less than a third. So,

00:08:21.860 --> 00:08:25.260
if your error is less and a third, then the weighting goes

00:08:25.260 --> 00:08:28.980
up more. And so, the one that you just got wrong

00:08:28.980 --> 00:08:31.340
goes up, doesn't go back to where it was before. It

00:08:31.340 --> 00:08:33.876
becomes even more important than it was when you had a

00:08:33.876 --> 00:08:38.480
uniform distribution. So the next time around, you have to get

00:08:38.480 --> 00:08:41.940
that one right, but it's not enough to break a half.

00:08:41.940 --> 00:08:44.750
So you're going to have to get something else right as well,

00:08:44.750 --> 00:08:46.550
and the one in the middle that you were getting right

00:08:46.550 --> 00:08:49.830
isn't enough. So you'll have to get number three right as well.

00:08:49.830 --> 00:08:50.610
&gt;&gt; Interesting.

00:08:50.610 --> 00:08:54.980
&gt;&gt; Right? And so, it's really hard to cycle

00:08:54.980 --> 00:08:59.475
back and forth between different examples, because you're exponentially

00:08:59.475 --> 00:09:02.160
weighting how important they are. Which means, you're always

00:09:02.160 --> 00:09:04.140
going to have to pick up something along the way.

00:09:05.210 --> 00:09:07.790
Because the ones that you, coicidentally, got right two

00:09:07.790 --> 00:09:10.710
times in a row. Become so unimportant. It doesn't

00:09:10.710 --> 00:09:12.950
help you to get those right. Whereas, the ones

00:09:12.950 --> 00:09:15.430
that you've gotten wrong, in the past. You've got to,

00:09:15.430 --> 00:09:19.940
on these cycles. Pick up some of them in order to get you over a half.

00:09:19.940 --> 00:09:20.490
&gt;&gt; Mmm

00:09:20.490 --> 00:09:22.850
&gt;&gt; And so, it is very difficult for you to cycle back and forth.

00:09:22.850 --> 00:09:24.660
&gt;&gt; Interesting.

00:09:24.660 --> 00:09:26.570
&gt;&gt; And that kind of makes sense, right? If

00:09:26.570 --> 00:09:28.520
you think about it in kind of an information gain

00:09:28.520 --> 00:09:31.180
sense, because what's going on there is you're, you're

00:09:31.180 --> 00:09:34.590
basically saying you must pick up information all the time.

00:09:34.590 --> 00:09:38.020
&gt;&gt; Hm. And then your non uni. Well uniform is

00:09:38.020 --> 00:09:40.001
the wrong word but you are kind of. You know,

00:09:40.001 --> 00:09:43.680
non-linearly using that information in some way. So that kind of

00:09:43.680 --> 00:09:47.910
works. It makes some sense to me, but I think that

00:09:47.910 --> 00:09:51.650
in the end what has to happen is you. You, there

00:09:51.650 --> 00:09:54.920
must be just a few examples in a kind of weighted sense

00:09:54.920 --> 00:09:57.920
that you're getting wrong. And so if I'm right, that as

00:09:57.920 --> 00:10:00.410
you, as you move through each of these cycles, you're weighting

00:10:00.410 --> 00:10:02.490
in such a way that you have to be picking up

00:10:02.490 --> 00:10:04.880
things you've gotten wrong in the past. So in other words,

00:10:04.880 --> 00:10:07.380
it's not enough to say, only the things that are

00:10:07.380 --> 00:10:10.560
hard in the last set, are the ones that I

00:10:10.560 --> 00:10:12.840
have to do better. You must also be picking up

00:10:12.840 --> 00:10:17.160
some of the things that you've gotten wrong earlier more

00:10:17.160 --> 00:10:19.980
than you were getting right. Because there's just not enough

00:10:19.980 --> 00:10:21.750
information in the one's that you're getting right all the

00:10:21.750 --> 00:10:24.890
time, because by the time you get that far along,

00:10:24.890 --> 00:10:26.690
the weight on them is near zero and they don't matter.

00:10:26.690 --> 00:10:28.850
&gt;&gt; Interesting.

00:10:28.850 --> 00:10:29.930
&gt;&gt; And then if you say, well, Charles,

00:10:29.930 --> 00:10:32.230
I could cycle back by always getting those wrong,

00:10:32.230 --> 00:10:34.450
yes, but then if you're getting those wrong, they're going to

00:10:34.450 --> 00:10:35.860
pull up and you're going to have to start getting

00:10:35.860 --> 00:10:38.440
those right too. And so, over time, you've gotta not

00:10:38.440 --> 00:10:39.860
just pick out things that do better than a

00:10:39.860 --> 00:10:42.218
half. But things that do well on a lot of

00:10:42.218 --> 00:10:45.710
the data. Because there's no way for all of the

00:10:45.710 --> 00:10:48.780
possible distributions for you to do better than chance otherwise.

00:10:48.780 --> 00:10:49.340
&gt;&gt; Cool.

