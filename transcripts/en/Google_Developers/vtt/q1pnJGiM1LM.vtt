WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:15.345
[MUSIC PLAYING]

00:00:15.345 --> 00:00:17.100
MICHAEL MANOOCHEHRI: Hello,
data developers.

00:00:17.100 --> 00:00:19.590
Welcome to Google
Developers Live.

00:00:19.590 --> 00:00:21.330
My name is Michael
Manoochehri.

00:00:21.330 --> 00:00:23.860
I work with the Developer
Relations team, supporting

00:00:23.860 --> 00:00:25.730
data products like BigQuery.

00:00:25.730 --> 00:00:29.760
And today, I'm joined by Kim
Cameron, a developer relations

00:00:29.760 --> 00:00:32.659
person working in Seattle
with the BigQuery team.

00:00:32.659 --> 00:00:33.020
Hi, Kim.

00:00:33.020 --> 00:00:35.488
How are you?

00:00:35.488 --> 00:00:36.533
KIM CAMERON: No, I'm doing
well, Michael.

00:00:36.533 --> 00:00:37.250
How are you?

00:00:37.250 --> 00:00:37.540
MICHAEL MANOOCHEHRI:
That's great.

00:00:37.540 --> 00:00:38.180
I'm doing great.

00:00:38.180 --> 00:00:41.120
What's the weather
like in Seattle?

00:00:41.120 --> 00:00:41.910
KIM CAMERON: It is
rainy, Michael.

00:00:41.910 --> 00:00:43.396
I know this is a shock.

00:00:43.396 --> 00:00:45.380
MICHAEL MANOOCHEHRI: [LAUGHS]

00:00:45.380 --> 00:00:46.920
So cool.

00:00:46.920 --> 00:00:48.260
It's usually raining
in Seattle.

00:00:48.260 --> 00:00:50.460
Today we're going to be
talking about some new

00:00:50.460 --> 00:00:51.800
BigQuery features.

00:00:51.800 --> 00:00:55.500
But for those who haven't used
it yet, BigQuery is an API

00:00:55.500 --> 00:00:58.880
that allows you to ask
questions, run queries, on

00:00:58.880 --> 00:01:01.720
very large data sets.

00:01:01.720 --> 00:01:05.190
We're talking things like
gigabytes and terabytes.

00:01:05.190 --> 00:01:07.830
Now one of the things we've
tried to do with Google

00:01:07.830 --> 00:01:12.350
BigQuery is to simplify the
lives of data developers.

00:01:12.350 --> 00:01:15.370
When you're normally working
with very large data sets, you

00:01:15.370 --> 00:01:19.240
often have to manage your own
infrastructure, buy expensive

00:01:19.240 --> 00:01:21.672
equipment, or do data
transformations.

00:01:21.672 --> 00:01:24.890
And with BigQuery, one of the
advantages to using it is that

00:01:24.890 --> 00:01:27.360
the service is hosted on
our infrastructure.

00:01:27.360 --> 00:01:31.440
And by using the SQL LIKE
queries, it allows you to run

00:01:31.440 --> 00:01:34.330
these queries very easily.

00:01:34.330 --> 00:01:37.100
So today we're going to talk a
little bit about some of the

00:01:37.100 --> 00:01:39.250
new features that we're
launching today.

00:01:39.250 --> 00:01:41.240
And Kim, do you want to tell
us some of the new features

00:01:41.240 --> 00:01:42.855
that we're going to
be talking about?

00:01:42.855 --> 00:01:43.660
KIM CAMERON: Absolutely.

00:01:43.660 --> 00:01:45.900
So we're going to talk about
four features today.

00:01:45.900 --> 00:01:50.360
First of all, we now have the
ability to use the timestamp

00:01:50.360 --> 00:01:52.480
data type instead
of regular Unix

00:01:52.480 --> 00:01:54.060
timestamps and date strings.

00:01:54.060 --> 00:01:56.840
You can now add columns to
your tables schemas.

00:01:56.840 --> 00:01:59.320
And we have two really important
updates to the JOIN

00:01:59.320 --> 00:02:02.037
and GROUP BY operations
that Michael is going

00:02:02.037 --> 00:02:03.085
to talk about first.

00:02:03.085 --> 00:02:03.800
MICHAEL MANOOCHEHRI: Yes.

00:02:03.800 --> 00:02:05.450
So let's talk about joins.

00:02:05.450 --> 00:02:08.720
So when you're dealing with a
lot of data, very large data

00:02:08.720 --> 00:02:11.330
sets, what we try to do with
BigQuery is allow you to run

00:02:11.330 --> 00:02:14.140
these queries very quickly
on these data sets.

00:02:14.140 --> 00:02:16.900
Imagine if you're an e-commerce
site and you've got

00:02:16.900 --> 00:02:20.140
millions or thousands of user
IDs, and you have another data

00:02:20.140 --> 00:02:22.520
set full of transactions,
purchases.

00:02:22.520 --> 00:02:24.460
And you want to gain some
insight by combining these

00:02:24.460 --> 00:02:26.160
data sets together.

00:02:26.160 --> 00:02:29.660
Now this kind of data process
is usually something in the

00:02:29.660 --> 00:02:31.490
realm of data transformation.

00:02:31.490 --> 00:02:34.850
You'd use something like
Hadoop, MapReduce.

00:02:34.850 --> 00:02:38.650
You may be using a lot of
expensive infrastructure or

00:02:38.650 --> 00:02:41.690
even waiting a long time for
these things to happen.

00:02:41.690 --> 00:02:44.960
But relational database people
are very used to running JOINS

00:02:44.960 --> 00:02:49.010
across different tables
or grouping by

00:02:49.010 --> 00:02:50.650
many different buckets.

00:02:50.650 --> 00:02:53.950
So with BigQuery, we've tried
to make this simpler.

00:02:53.950 --> 00:02:55.200
We want to extend.

00:02:55.200 --> 00:02:57.350
We've heard from our developers
who have told us

00:02:57.350 --> 00:02:59.880
they want to extend the
simplicity of BigQuery to

00:02:59.880 --> 00:03:01.000
other use cases.

00:03:01.000 --> 00:03:03.840
And one of the most common use
cases we've heard from is to

00:03:03.840 --> 00:03:06.650
extend BigQuery's ability to run
these queries, not just on

00:03:06.650 --> 00:03:09.230
one large data set,
but multiple.

00:03:09.230 --> 00:03:11.280
In the past, BigQuery has
supported what we call small

00:03:11.280 --> 00:03:14.880
joins, which is a large table
joined with a smaller table,

00:03:14.880 --> 00:03:16.140
like a look-up table.

00:03:16.140 --> 00:03:19.760
But today we're announcing a new
feature called Big JOIN,

00:03:19.760 --> 00:03:22.890
which allows you to actually
merge data results from two

00:03:22.890 --> 00:03:24.190
large data sets.

00:03:24.190 --> 00:03:27.210
We're also rolling out a new
feature we call Big Group

00:03:27.210 --> 00:03:30.730
Aggregations, which allows you
to group by a very large

00:03:30.730 --> 00:03:33.730
amount of individual
common records.

00:03:33.730 --> 00:03:35.950
For example, grouping results
by each of the

00:03:35.950 --> 00:03:39.410
individual user records.

00:03:39.410 --> 00:03:41.790
And to do this, we've added a
new clause that Kim's going to

00:03:41.790 --> 00:03:43.036
talk about.

00:03:43.036 --> 00:03:45.450
KIM CAMERON: So that's actually
the keyword, EACH.

00:03:45.450 --> 00:03:47.560
Which you can add
to your queries.

00:03:47.560 --> 00:03:50.230
And that activates these
new features.

00:03:50.230 --> 00:03:52.080
And this isn't to say that you
wouldn't want to use the

00:03:52.080 --> 00:03:54.050
regular GROUP BY or the
regular JOIN anymore.

00:03:54.050 --> 00:03:56.820
There are use cases for using
one or the other.

00:03:56.820 --> 00:03:57.350
MICHAEL MANOOCHEHRI: Yeah.

00:03:57.350 --> 00:03:58.100
That's right.

00:03:58.100 --> 00:04:00.900
Like I said before, the original
JOIN was really great

00:04:00.900 --> 00:04:02.970
when you had a large table
and a small table.

00:04:02.970 --> 00:04:05.650
And when you have that actual
use case, you should still use

00:04:05.650 --> 00:04:08.300
JOIN without JOIN EACH,
or GROUP BY

00:04:08.300 --> 00:04:09.870
without GROUP EACH BY.

00:04:09.870 --> 00:04:10.960
And I'll demonstrate
some of these

00:04:10.960 --> 00:04:12.960
queries in just a second.

00:04:12.960 --> 00:04:16.680
When you have a lot of different
keys, you're going

00:04:16.680 --> 00:04:18.140
to have to use the JOIN EACH.

00:04:18.140 --> 00:04:19.579
And let me demonstrate
that right now.

00:04:19.579 --> 00:04:22.010
So why don't we go to the query
window, and Kim I will

00:04:22.010 --> 00:04:25.360
demonstrate an example
of this query.

00:04:25.360 --> 00:04:28.860
So here, if you can see,
our BigQuery WebUI--

00:04:28.860 --> 00:04:30.820
when you sign up for BigQuery,
you have access to this web

00:04:30.820 --> 00:04:33.150
interface to run your
own queries.

00:04:33.150 --> 00:04:35.410
We also have public data sets
that you can query.

00:04:35.410 --> 00:04:36.960
I'm going to show you a
public data set here.

00:04:36.960 --> 00:04:39.920
It's our Google Books
Ngrams data set.

00:04:39.920 --> 00:04:42.130
It has trigrams, which are
really just collections of

00:04:42.130 --> 00:04:43.070
three words.

00:04:43.070 --> 00:04:47.350
And this particular data set
we have is 258 gigabytes.

00:04:47.350 --> 00:04:51.060
And I'm going to run a query
that matches, merges data by

00:04:51.060 --> 00:04:54.300
common key with our Wikipedia
revision data set.

00:04:54.300 --> 00:04:56.220
That data set's about
35 gigabytes.

00:04:56.220 --> 00:04:58.720
So we're going to
do a JOIN query.

00:04:58.720 --> 00:05:00.780
Now let me run this without
JOIN EACH, and

00:05:00.780 --> 00:05:01.550
you'll see what I mean.

00:05:01.550 --> 00:05:04.360
JOIN is for a large
query running--

00:05:04.360 --> 00:05:07.050
joining with a smaller table.

00:05:07.050 --> 00:05:08.460
So let's run this.

00:05:08.460 --> 00:05:09.460
So it's going to
throw an error.

00:05:09.460 --> 00:05:12.120
It's going to say, this
table is too large

00:05:12.120 --> 00:05:14.090
for a regular JOIN.

00:05:14.090 --> 00:05:17.000
So now let's use the
JOIN EACH clause.

00:05:17.000 --> 00:05:17.910
And we'll let this run.

00:05:17.910 --> 00:05:19.440
And we'll talk about
what's happening.

00:05:19.440 --> 00:05:21.640
So this is adding an additional
processing step,

00:05:21.640 --> 00:05:25.240
which is actually making sure
that we can join these two

00:05:25.240 --> 00:05:29.380
tables by the common key, which
is the Wikipedia title

00:05:29.380 --> 00:05:31.100
and a particular Ngram.

00:05:31.100 --> 00:05:34.810
I've thrown in a string function
here to actually

00:05:34.810 --> 00:05:36.270
normalize the data.

00:05:36.270 --> 00:05:38.490
Some of the Wikipedia titles
have title case.

00:05:38.490 --> 00:05:40.410
And some of the Ngrams
have lowercase.

00:05:40.410 --> 00:05:43.100
So I'm just running that over
all the records that we're

00:05:43.100 --> 00:05:43.990
joining against.

00:05:43.990 --> 00:05:46.950
And I'm saying, return
the top five.

00:05:46.950 --> 00:05:47.410
And there we go.

00:05:47.410 --> 00:05:51.230
That took merely 27 seconds.

00:05:51.230 --> 00:05:53.090
It processed all of that data.

00:05:53.090 --> 00:05:56.910
And it's given us the five
examples of Ngrams that are

00:05:56.910 --> 00:06:00.770
also popularly revised
Wikipedia titles.

00:06:00.770 --> 00:06:01.430
So now you know.

00:06:01.430 --> 00:06:03.300
This is just using the
public data sets.

00:06:03.300 --> 00:06:05.590
I think a better example would
be what Kim was talking about

00:06:05.590 --> 00:06:07.470
earlier with some of these
e-commerce examples.

00:06:07.470 --> 00:06:08.970
So Kim, can you tell us a little
bit about what you

00:06:08.970 --> 00:06:11.080
might do in an e-commerce
example that would

00:06:11.080 --> 00:06:12.210
make sense with this?

00:06:12.210 --> 00:06:15.650
KIM CAMERON: So, one example
would be let's say I store

00:06:15.650 --> 00:06:18.980
user information in one data
set and then I also store

00:06:18.980 --> 00:06:20.760
order information in
other data set.

00:06:20.760 --> 00:06:23.660
So each of those orders is going
to have an associated

00:06:23.660 --> 00:06:24.810
customer ID.

00:06:24.810 --> 00:06:27.040
And now, what happens if I want
to aggregate all of that

00:06:27.040 --> 00:06:28.050
information about a customer?

00:06:28.050 --> 00:06:30.730
I'm going to have to join two
really big data sets,

00:06:30.730 --> 00:06:33.970
especially if I'm a really big
e-commerce site, and I have

00:06:33.970 --> 00:06:35.770
millions of users.

00:06:35.770 --> 00:06:37.780
And that's going to be a
challenge to use with the

00:06:37.780 --> 00:06:38.495
regular JOIN.

00:06:38.495 --> 00:06:39.110
MICHAEL MANOOCHEHRI: Yeah.

00:06:39.110 --> 00:06:40.930
And I think a lot of people have
been using things like

00:06:40.930 --> 00:06:43.930
MapReduce or some kind of
transformation tool to first

00:06:43.930 --> 00:06:45.650
denormalize this data,
so they could put it

00:06:45.650 --> 00:06:47.120
in a tool like BigQuery.

00:06:47.120 --> 00:06:49.270
But I think this really
enables you to do a

00:06:49.270 --> 00:06:50.480
different use case.

00:06:50.480 --> 00:06:52.210
It's something that stems
that simplistic

00:06:52.210 --> 00:06:54.070
model in larger tables.

00:06:54.070 --> 00:06:55.360
And I think it really
opens up a lot of

00:06:55.360 --> 00:06:58.281
new ways to use BigQuery.

00:06:58.281 --> 00:07:00.520
KIM CAMERON: And how about
the GROUP BY example?

00:07:00.520 --> 00:07:01.100
Do you have one of those.

00:07:01.100 --> 00:07:01.580
MICHAEL MANOOCHEHRI: Yeah.

00:07:01.580 --> 00:07:03.750
So the GROUP BY is actually
almost exactly the same.

00:07:03.750 --> 00:07:06.670
And another example, we
could do things like--

00:07:06.670 --> 00:07:08.020
I don't actually have one
queued up-- but we could

00:07:08.020 --> 00:07:11.140
actually do things like run a
query where we want to look at

00:07:11.140 --> 00:07:15.010
every Wikipedia title and
group something by each

00:07:15.010 --> 00:07:16.060
Wikipedia title.

00:07:16.060 --> 00:07:19.180
In the past, BigQuery didn't
support this type of grouping.

00:07:19.180 --> 00:07:20.730
The GROUP BY had a limit.

00:07:20.730 --> 00:07:24.320
But now, if you use GROUP EACH
BY, that kind of query doesn't

00:07:24.320 --> 00:07:25.470
actually have a limit.

00:07:25.470 --> 00:07:28.810
You can pipe out sort of any
amount of bucketing that you

00:07:28.810 --> 00:07:30.540
want, as long as it
fits within our

00:07:30.540 --> 00:07:33.310
maximum result set size.

00:07:33.310 --> 00:07:33.690
So that's it.

00:07:33.690 --> 00:07:35.040
You can use them in conjunction
as well.

00:07:35.040 --> 00:07:36.270
So it's really interesting.

00:07:36.270 --> 00:07:38.950
You can create these joined
table results and then run a

00:07:38.950 --> 00:07:40.740
GROUP BY on the resulting
table.

00:07:40.740 --> 00:07:43.390
There's lots of great things
you can do with this.

00:07:43.390 --> 00:07:45.660
Really great for mobile game
developers and, as you said,

00:07:45.660 --> 00:07:46.400
e-commerce sites.

00:07:46.400 --> 00:07:47.184
KIM CAMERON: Absolutely.

00:07:47.184 --> 00:07:48.860
MICHAEL MANOOCHEHRI: Really
interesting use cases there.

00:07:48.860 --> 00:07:51.030
KIM CAMERON: So next let's
talk about timestamp.

00:07:51.030 --> 00:07:54.930
So in the past, BigQuery has had
date and time functions to

00:07:54.930 --> 00:07:57.580
deal with things like Unix
timestamps and also date

00:07:57.580 --> 00:08:01.466
strings, ways to parse date
strings, et cetera.

00:08:01.466 --> 00:08:02.430
And this is good.

00:08:02.430 --> 00:08:04.570
You could technically get that
information from Unix

00:08:04.570 --> 00:08:06.820
timestamps or date strings.

00:08:06.820 --> 00:08:09.310
But let's say you wanted to
store timestamp data on your

00:08:09.310 --> 00:08:11.280
end, and you wanted to put
that into BigQuery.

00:08:11.280 --> 00:08:13.180
In the past, you haven't
been able to do this.

00:08:13.180 --> 00:08:15.120
And you've had to do
one of two things.

00:08:15.120 --> 00:08:18.010
One, you could actually change
the data in your database.

00:08:18.010 --> 00:08:21.500
So you could start storing Unix
timestamps instead of a

00:08:21.500 --> 00:08:24.940
timestamp data type
like in MySQL.

00:08:24.940 --> 00:08:25.890
So that's option one.

00:08:25.890 --> 00:08:28.780
Option two is you could actually
transform your data

00:08:28.780 --> 00:08:30.760
before you load it
into BIgQuery.

00:08:30.760 --> 00:08:32.870
And then that's an additional
step that you'd have to do

00:08:32.870 --> 00:08:34.100
every single time.

00:08:34.100 --> 00:08:36.870
So again, we wanted to listen
to you as developers and try

00:08:36.870 --> 00:08:38.090
to make your lives
easier with this.

00:08:38.090 --> 00:08:39.740
So we've rolled out
the addition of a

00:08:39.740 --> 00:08:41.299
timestamp data type.

00:08:41.299 --> 00:08:43.289
And what that means is, now you
can keep your timestamps

00:08:43.289 --> 00:08:44.500
in your database.

00:08:44.500 --> 00:08:48.020
And you can load them into
BigQuery as time stamps.

00:08:48.020 --> 00:08:50.340
There's a few advantages
to doing this.

00:08:50.340 --> 00:08:52.780
First of all, obviously, you
don't have to do that

00:08:52.780 --> 00:08:55.860
transformation step, which is
going to save you time.

00:08:55.860 --> 00:08:58.810
Additionally, you can specify a
time zone when you load your

00:08:58.810 --> 00:09:00.430
data into Big Query.

00:09:00.430 --> 00:09:03.160
So you can preserve that
bit of metadata.

00:09:03.160 --> 00:09:06.540
Additionally, if you ever stored
your data as a date

00:09:06.540 --> 00:09:09.566
string, it's kind of tricky to
parse that information out, if

00:09:09.566 --> 00:09:12.130
you wanted to really easily get
things like, what's the

00:09:12.130 --> 00:09:13.940
month, what's the year.

00:09:13.940 --> 00:09:18.100
So by using BigQuery's built-in
timestamp functions,

00:09:18.100 --> 00:09:19.590
you can just say, month.

00:09:19.590 --> 00:09:20.850
And you can get the month
of the timestamp.

00:09:20.850 --> 00:09:21.230
So that makes your life--

00:09:21.230 --> 00:09:23.860
MICHAEL MANOOCHEHRI: Yeah,
I like this use case that

00:09:23.860 --> 00:09:26.870
supports the idea that you can
have different time zones in

00:09:26.870 --> 00:09:27.710
your timestamps.

00:09:27.710 --> 00:09:29.750
Maybe you're collecting data
from different servers, like

00:09:29.750 --> 00:09:31.280
one on the East Coast of
the United States,

00:09:31.280 --> 00:09:32.717
one on the West Coast.

00:09:32.717 --> 00:09:34.180
KIM CAMERON: Absolutely.

00:09:34.180 --> 00:09:36.070
And finally, it's a
lot more readable.

00:09:36.070 --> 00:09:38.850
So I don't know about you, but
unless you're a math savant

00:09:38.850 --> 00:09:39.590
like Michael--

00:09:39.590 --> 00:09:40.510
MICHAEL MANOOCHEHRI:
Or like Kim.

00:09:40.510 --> 00:09:44.620
KIM CAMERON: --reading Unix
timestamps in records is not

00:09:44.620 --> 00:09:45.250
very readable.

00:09:45.250 --> 00:09:47.820
So let's say you want to query
your data in BigQuery and you

00:09:47.820 --> 00:09:50.145
want to see the date actually
in the result.

00:09:50.145 --> 00:09:51.970
By keeping it in timestamp
format,

00:09:51.970 --> 00:09:53.530
it's going to be readable.

00:09:53.530 --> 00:09:56.140
So those are some of the reasons
why timestamp, we

00:09:56.140 --> 00:09:57.480
think, is going to be helpful.

00:09:57.480 --> 00:09:58.470
And Michael has an example.

00:09:58.470 --> 00:09:59.050
MICHAEL MANOOCHEHRI: Yeah.

00:09:59.050 --> 00:10:02.200
So if we go back to the BigQuery
WebUI, I'll show you

00:10:02.200 --> 00:10:04.090
one of my favorite things about
the new timestamp data

00:10:04.090 --> 00:10:05.760
type that Kim just
talked about.

00:10:05.760 --> 00:10:09.270
One is you can cast strings
to timestamp.

00:10:09.270 --> 00:10:10.520
And I'll show you an
example of that.

00:10:10.520 --> 00:10:12.000
I'm actually going to
run three things

00:10:12.000 --> 00:10:13.070
in one quick query.

00:10:13.070 --> 00:10:16.130
You can cast to a timestamp
data type.

00:10:16.130 --> 00:10:18.800
You can also timeshift, which
I think is very cool.

00:10:18.800 --> 00:10:22.600
You can say, give me the
timestamp that is one hour or

00:10:22.600 --> 00:10:26.060
one year away from a particular
timestamp.

00:10:26.060 --> 00:10:27.570
So here I'm just going
to do that.

00:10:27.570 --> 00:10:29.290
I picked a random timestamp.

00:10:29.290 --> 00:10:32.270
And I'm going to show you the
string turn into a timestamp.

00:10:32.270 --> 00:10:35.820
And as you can see here, we
list UTC at the bottom.

00:10:35.820 --> 00:10:40.050
And then I've just selected a
date that's one hour ahead and

00:10:40.050 --> 00:10:41.750
a date that's one year ahead.

00:10:41.750 --> 00:10:44.170
Now Kim, I believe if you want
it to go backwards, you can

00:10:44.170 --> 00:10:45.230
just add a negative number.

00:10:45.230 --> 00:10:48.010
So I can re-run this query
with the same date.

00:10:48.010 --> 00:10:52.170
And I'm going to say, give me
something one hour before and

00:10:52.170 --> 00:10:52.960
one year before.

00:10:52.960 --> 00:10:53.830
And there we go.

00:10:53.830 --> 00:10:55.770
The query has just run.

00:10:55.770 --> 00:10:57.410
And now I can actually
do timeshift.

00:10:57.410 --> 00:11:02.420
So I can say things like, give
me everything from this date

00:11:02.420 --> 00:11:04.840
to another date, so
within a range.

00:11:04.840 --> 00:11:06.740
You can do things like that.

00:11:06.740 --> 00:11:09.680
It's very useful for those
kind of applications.

00:11:09.680 --> 00:11:11.920
And now let's take another
look at some real data.

00:11:11.920 --> 00:11:14.970
We're going to go back to one
of our public data sets.

00:11:14.970 --> 00:11:18.980
It's one of our most popular
that was curated by a Googler

00:11:18.980 --> 00:11:19.690
on the Chrome team, [? Ilya ?]

00:11:19.690 --> 00:11:20.270
[? Gregorich. ?]

00:11:20.270 --> 00:11:23.180
It's our GitHub commit
history data set.

00:11:23.180 --> 00:11:25.190
Here I'm just going to look
at the timestamps there.

00:11:25.190 --> 00:11:27.290
We have these timestamps
in that data set

00:11:27.290 --> 00:11:28.480
currently as strings.

00:11:28.480 --> 00:11:31.470
And as Kim said, it's really
useful to change these into

00:11:31.470 --> 00:11:34.840
timestamp data type, so we can
actually run the hour method,

00:11:34.840 --> 00:11:37.660
which will pull out the hour of
the day that that timestamp

00:11:37.660 --> 00:11:38.600
pertains to.

00:11:38.600 --> 00:11:41.280
So here I'm going to look at all
of the records in GitHub,

00:11:41.280 --> 00:11:41.975
when they were created--

00:11:41.975 --> 00:11:44.130
I'm sorry, these are
events in GitHub--

00:11:44.130 --> 00:11:45.060
when they were created.

00:11:45.060 --> 00:11:49.210
And we're going to take the
timestamp, change it into the

00:11:49.210 --> 00:11:51.590
timestamp data type, and
then pull out the hour.

00:11:51.590 --> 00:11:54.150
And so what we're doing here is
we're trying to find which

00:11:54.150 --> 00:11:58.070
hour of the day is most popular
for GitHub events?

00:11:58.070 --> 00:11:59.780
And of course, this is in UTC.

00:11:59.780 --> 00:12:01.080
Look, the queries here.

00:12:01.080 --> 00:12:07.090
Looks like 1300 hours is UTC,
14, 16 is about the most

00:12:07.090 --> 00:12:09.940
popular time for these
GitHub events.

00:12:09.940 --> 00:12:11.490
You'd have to do a little
more data analysis

00:12:11.490 --> 00:12:12.250
to figure out why.

00:12:12.250 --> 00:12:15.720
But you can use this kind of
query to find out things like

00:12:15.720 --> 00:12:17.446
that on your own data.

00:12:17.446 --> 00:12:19.530
KIM CAMERON: And for any of
these functions, you can look

00:12:19.530 --> 00:12:20.770
at the query reference.

00:12:20.770 --> 00:12:23.210
There's a new section called
Date and Time Functions.

00:12:23.210 --> 00:12:26.400
And that contains both all of
the old Unix timestamp data

00:12:26.400 --> 00:12:29.330
string functions, as well as the
new timestamp functions.

00:12:29.330 --> 00:12:32.230
And we've also added a new
column that has an example

00:12:32.230 --> 00:12:34.780
query that you can run as
well as the result.

00:12:34.780 --> 00:12:37.170
So if you want to remember how
to do the negative numbers or

00:12:37.170 --> 00:12:38.835
any of these, you can just check
out the query reference

00:12:38.835 --> 00:12:39.570
at any time.

00:12:39.570 --> 00:12:40.020
MICHAEL MANOOCHEHRI: Yeah.

00:12:40.020 --> 00:12:41.030
I like those samples a lot.

00:12:41.030 --> 00:12:43.250
In fact, the samples I just ran,
I literally pulled some

00:12:43.250 --> 00:12:44.380
of those right from the
new documentation.

00:12:44.380 --> 00:12:46.244
So I'm pretty happy
about those.

00:12:46.244 --> 00:12:47.150
KIM CAMERON: Oh great.

00:12:47.150 --> 00:12:49.370
And then let's talk about the
column schema example.

00:12:49.370 --> 00:12:53.480
So let's say you store your data
in either datastore, on

00:12:53.480 --> 00:12:56.070
App Engine, or a
NoSQL solution.

00:12:56.070 --> 00:12:58.230
And you do that, probably
because you want the

00:12:58.230 --> 00:13:00.740
flexibility to be able to
add data on the fly.

00:13:00.740 --> 00:13:03.250
So going back to the e-commerce
example, let's say

00:13:03.250 --> 00:13:06.190
you store customer data and
you store zip codes.

00:13:06.190 --> 00:13:08.570
And later on, you decide you
want to add the four-digit

00:13:08.570 --> 00:13:10.570
extension as a new column.

00:13:10.570 --> 00:13:11.920
You can do that on your end.

00:13:11.920 --> 00:13:14.380
In the past, that wasn't
possible in BigQuery, because

00:13:14.380 --> 00:13:17.568
once you load your data into
BigQuery, you're stuck with

00:13:17.568 --> 00:13:18.840
that table schema.

00:13:18.840 --> 00:13:20.710
We fixed that today.

00:13:20.710 --> 00:13:24.350
And moving forward, by letting
you just update your tables

00:13:24.350 --> 00:13:25.910
schema with the new column.

00:13:25.910 --> 00:13:28.325
And it's just going to work.

00:13:28.325 --> 00:13:28.870
MICHAEL MANOOCHEHRI: Yeah.

00:13:28.870 --> 00:13:30.970
So to do this, you could
actually just reuse the

00:13:30.970 --> 00:13:34.560
BigQuery API's Tables
Update method.

00:13:34.560 --> 00:13:37.690
And all you have to do is run
that method on your table and

00:13:37.690 --> 00:13:41.630
pass in the new schema, with the
additional columns added.

00:13:41.630 --> 00:13:44.040
Records that you've already
had there are unaffected.

00:13:44.040 --> 00:13:45.950
They become null values.

00:13:45.950 --> 00:13:48.790
And you're able to have the
data in there before that

00:13:48.790 --> 00:13:51.320
didn't have that schema and
extend that schema for the new

00:13:51.320 --> 00:13:52.550
data coming in.

00:13:52.550 --> 00:13:53.520
It's pretty great.

00:13:53.520 --> 00:13:55.790
Another thing we're working on
is adding that functionality

00:13:55.790 --> 00:13:57.610
to the BQ command-line tool.

00:13:57.610 --> 00:13:59.750
This is the command-line
tool for BigQuery.

00:13:59.750 --> 00:14:01.400
So we'll have that
out soon as well.

00:14:01.400 --> 00:14:03.000
KIM CAMERON: And we'll
definitely keep you updated

00:14:03.000 --> 00:14:04.950
once that's available.

00:14:04.950 --> 00:14:07.100
So yeah, I think those are the
four features we wanted to

00:14:07.100 --> 00:14:08.070
talk about.

00:14:08.070 --> 00:14:09.960
One last piece of
info for you--

00:14:09.960 --> 00:14:11.980
we've also been trying to
make information in the

00:14:11.980 --> 00:14:14.350
documentation a lot more
accessible, especially for

00:14:14.350 --> 00:14:17.138
things that are important to
you, like we know the query

00:14:17.138 --> 00:14:18.130
reference is important to you.

00:14:18.130 --> 00:14:20.750
And in the past it's been a
little bit buried in the docs.

00:14:20.750 --> 00:14:23.460
So we're rolling out some new
doc changes today as well.

00:14:23.460 --> 00:14:24.680
There is an overall plan.

00:14:24.680 --> 00:14:25.670
It's going to get
a lot better.

00:14:25.670 --> 00:14:28.730
For now, we've launched a few
new nodes in the top-level

00:14:28.730 --> 00:14:29.740
navigation.

00:14:29.740 --> 00:14:32.380
One is the loading data
in the BigQuery node.

00:14:32.380 --> 00:14:34.720
This contains a few new
topics like preparing

00:14:34.720 --> 00:14:35.820
your data for BigQuery.

00:14:35.820 --> 00:14:38.750
So this gives examples of things
you might want to do on

00:14:38.750 --> 00:14:41.210
your database and before
you load it.

00:14:41.210 --> 00:14:44.550
We also have some content
on loading from

00:14:44.550 --> 00:14:46.170
various data stores.

00:14:46.170 --> 00:14:48.190
We also have a new
exporting topic.

00:14:48.190 --> 00:14:50.056
And then, we've moved
the query reference

00:14:50.056 --> 00:14:51.820
up to the top level.

00:14:51.820 --> 00:14:53.710
It's now called Querying Data.

00:14:53.710 --> 00:14:56.130
So you should be able to access
that a lot easier.

00:14:56.130 --> 00:14:58.530
And if you have any feedback at
all in the documentation--

00:14:58.530 --> 00:15:01.920
on things you like, things you
dislike, things you think are

00:15:01.920 --> 00:15:04.200
hidden and you'd like them
[? bundled ?] up--

00:15:04.200 --> 00:15:06.620
there's a Send Feedback link on
every documentation page.

00:15:06.620 --> 00:15:09.140
And we do personally
read that feedback.

00:15:09.140 --> 00:15:11.220
And we use it to make your
experience better.

00:15:11.220 --> 00:15:14.072
So we really encourage
you to do that.

00:15:14.072 --> 00:15:14.580
MICHAEL MANOOCHEHRI: Yeah.

00:15:14.580 --> 00:15:17.290
And before we go, let's talk
about how you can reach us in

00:15:17.290 --> 00:15:17.840
other ways.

00:15:17.840 --> 00:15:20.410
If you have developer questions,
you can ask them on

00:15:20.410 --> 00:15:23.700
our official developer support
area, which is Stack Overflow.

00:15:23.700 --> 00:15:26.110
We use the tag Google-BigQuery.

00:15:26.110 --> 00:15:27.960
So just ask your questions
about BigQuery.

00:15:27.960 --> 00:15:28.790
Tag them that way.

00:15:28.790 --> 00:15:31.280
We have, not only us, but other
Google engineers read

00:15:31.280 --> 00:15:32.520
that thread as well.

00:15:32.520 --> 00:15:33.490
And we'd be happy
to talk to you.

00:15:33.490 --> 00:15:36.650
Also, don't forget to follow
us on the Google Cloud

00:15:36.650 --> 00:15:38.940
Platform Developers
Google+ page.

00:15:38.940 --> 00:15:40.940
We're always posting there with
new features, new things

00:15:40.940 --> 00:15:42.290
like that, and we'd
love to get your

00:15:42.290 --> 00:15:44.900
feedback there as well.

00:15:44.900 --> 00:15:45.210
So great.

00:15:45.210 --> 00:15:47.040
So that wraps up our
new features.

00:15:47.040 --> 00:15:48.300
Please send us feedback.

00:15:48.300 --> 00:15:49.370
I hope you enjoy them.

00:15:49.370 --> 00:15:52.775
And we'll be back again for
another data developers GDL.

00:15:52.775 --> 00:15:53.216
KIM CAMERON: Indeed.

00:15:53.216 --> 00:15:54.580
MICHAEL MANOOCHEHRI: I'm
Michael Manoochehri.

00:15:54.580 --> 00:15:55.460
KIM CAMERON: I am Kim Cameron.

00:15:55.460 --> 00:15:56.040
MICHAEL MANOOCHEHRI:
All right.

00:15:56.040 --> 00:15:58.680
Thank you very much.

00:16:05.280 --> 00:16:07.367
[MUSIC PLAYING]

